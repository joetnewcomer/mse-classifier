,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"""How many public playgrounds exist in the United States?"" How to answer using statistics and probability","""How many public playgrounds exist in the United States?"" How to answer using statistics and probability",,"I have a goal of estimating how many public playgrounds exist in the United States. There are many methods of gathering real data about playgrounds, but, unfortunately, there is no single authority that can answer this question or provide a comprehensive list. Contacting every city in the nation would be too prohibitive, and other options such as working with regional park & rec departments have proven to show how little information those departments have. (Edit: I should also note that parks != playgrounds, but playgrounds may be contained inside parks). This problem is akin to the old interview question: How many gas stations are there in Los Angeles? How would one go about constructing a valid estimate on the total number of public playgrounds in the United States, with a margin of error <= 5%? Can the community think of such a methodology that is purely grounded in math? If you propose a solution, can you calculate what your result is for comparison with the others?","I have a goal of estimating how many public playgrounds exist in the United States. There are many methods of gathering real data about playgrounds, but, unfortunately, there is no single authority that can answer this question or provide a comprehensive list. Contacting every city in the nation would be too prohibitive, and other options such as working with regional park & rec departments have proven to show how little information those departments have. (Edit: I should also note that parks != playgrounds, but playgrounds may be contained inside parks). This problem is akin to the old interview question: How many gas stations are there in Los Angeles? How would one go about constructing a valid estimate on the total number of public playgrounds in the United States, with a margin of error <= 5%? Can the community think of such a methodology that is purely grounded in math? If you propose a solution, can you calculate what your result is for comparison with the others?",,"['probability', 'statistics']"
1,"A multinomial problem (balls, bins, etc.)","A multinomial problem (balls, bins, etc.)",,"Consider the well known multinomial setting: there are L balls, thrown at random at n bins so that the probability that a ball falls in bin i is $p_i$, independent of the other balls (the $p_i$’s are all positive and sum to 1). Let $X_i$ be the number of balls in the ith bin.  It is straightforward to show that for any k distinct indices $i_1, i_2,\ldots, i_k$, the events $\lbrace X_{i_1} > 0\rbrace, \lbrace X_{i_2} > 0\rbrace,\ldots, \lbrace X_{i_k} > 0\rbrace$ are negatively dependent in the sense that $P(X_{i_1} > 0, X_{i_2} > 0,\ldots, X_{i_k} > 0) < P(X_{i_1} > 0)P(X_{i_2} > 0)\ldots P(X_{i_k} > 0)$ The proof is by induction over k: for k = 2, the probability on the LHS is $1 – [(1 - p_{i_1})^L + (1 - p_{i_2})^L - (1 - p_{i_1} - p_{i_2})^L]$, and on the RHS it’s $[1 - (1 – p_{i_1})^L] [1 - (1 – p_{i_2})^L]$.  Elementary manipulations show that the inequality holds, and the induction step is easily proven using the multiplication rule $P(A \cap B) = P(A)P(B | A)$. This negative dependence is also intuitively clear: if we know that there is at least one ball in bin i, there is at least one ball that will surely not fall into bin j, so the probability of bin j being non-empty decreases. So that was easy.  However, for proving a certain bound in my research, I need to do something similar, but for random k indices: suppose that after the balls were thrown into the bins, somebody comes and chooses randomly k distinct bins (so that each set of k bins has the same probability to be chosen, namely, 1/(n choose k)).  Let $i_1, i_2, \ldots, i_k$ be the chosen indices, and again, I need to show that the inequality (below the second paragraph above) holds. I thought to repeat the outline of the previous proof, but had a problem with proving the k = 2 case (the induction step is no problem).  To compute each of the sides of the inequality I conditioned on the choice of the two indices (law of total probability), but even though many terms got cancelled, I couldn’t prove the inequality. I am quite confident that the inequality holds, both by intuition (basically the same argument as in the non-random indices case) and because of numerical calculations. Any ideas what to do here?  I’d be grateful for any help.","Consider the well known multinomial setting: there are L balls, thrown at random at n bins so that the probability that a ball falls in bin i is $p_i$, independent of the other balls (the $p_i$’s are all positive and sum to 1). Let $X_i$ be the number of balls in the ith bin.  It is straightforward to show that for any k distinct indices $i_1, i_2,\ldots, i_k$, the events $\lbrace X_{i_1} > 0\rbrace, \lbrace X_{i_2} > 0\rbrace,\ldots, \lbrace X_{i_k} > 0\rbrace$ are negatively dependent in the sense that $P(X_{i_1} > 0, X_{i_2} > 0,\ldots, X_{i_k} > 0) < P(X_{i_1} > 0)P(X_{i_2} > 0)\ldots P(X_{i_k} > 0)$ The proof is by induction over k: for k = 2, the probability on the LHS is $1 – [(1 - p_{i_1})^L + (1 - p_{i_2})^L - (1 - p_{i_1} - p_{i_2})^L]$, and on the RHS it’s $[1 - (1 – p_{i_1})^L] [1 - (1 – p_{i_2})^L]$.  Elementary manipulations show that the inequality holds, and the induction step is easily proven using the multiplication rule $P(A \cap B) = P(A)P(B | A)$. This negative dependence is also intuitively clear: if we know that there is at least one ball in bin i, there is at least one ball that will surely not fall into bin j, so the probability of bin j being non-empty decreases. So that was easy.  However, for proving a certain bound in my research, I need to do something similar, but for random k indices: suppose that after the balls were thrown into the bins, somebody comes and chooses randomly k distinct bins (so that each set of k bins has the same probability to be chosen, namely, 1/(n choose k)).  Let $i_1, i_2, \ldots, i_k$ be the chosen indices, and again, I need to show that the inequality (below the second paragraph above) holds. I thought to repeat the outline of the previous proof, but had a problem with proving the k = 2 case (the induction step is no problem).  To compute each of the sides of the inequality I conditioned on the choice of the two indices (law of total probability), but even though many terms got cancelled, I couldn’t prove the inequality. I am quite confident that the inequality holds, both by intuition (basically the same argument as in the non-random indices case) and because of numerical calculations. Any ideas what to do here?  I’d be grateful for any help.",,['probability']
2,"Asymptotically, how many rolls of an $n$-sided die will multiply to a perfect square for the first time?","Asymptotically, how many rolls of an -sided die will multiply to a perfect square for the first time?",n,"This is a generalization of this question , which I found amusing. My generalization is as follows: You have an $n$ -sided die. You roll at least once, and keep rolling until the product of all the rolls equals a perfect square. For instance, the following roll sequences are complete and don't contain any complete proper prefixes: $2$ - $1$ - $6$ - $3$ , yielding $36 = 6^2$ the single roll $4 = 2^2$ $5$ - $2$ - $2$ - $4$ - $5$ , yielding $400 = 20^2$ Let $r(n)$ be the expected number of rolls needed to multiply to a perfect square for the first time. The quoted question asks for $r(6)$ . I'd like to find the asymptotic behavior of $r(n)$ as $n \to \infty$ , as closely as possible. I don't see a duplicate, but I'm not $100$ percent sure there isn't one. I have a simple approach (which I haven't completed working on yet) based on a continuous approximation to $\pi(n)$ , the prime-counting function, but I have a vague suspicion that there's something better out there. Any thoughts?","This is a generalization of this question , which I found amusing. My generalization is as follows: You have an -sided die. You roll at least once, and keep rolling until the product of all the rolls equals a perfect square. For instance, the following roll sequences are complete and don't contain any complete proper prefixes: - - - , yielding the single roll - - - - , yielding Let be the expected number of rolls needed to multiply to a perfect square for the first time. The quoted question asks for . I'd like to find the asymptotic behavior of as , as closely as possible. I don't see a duplicate, but I'm not percent sure there isn't one. I have a simple approach (which I haven't completed working on yet) based on a continuous approximation to , the prime-counting function, but I have a vague suspicion that there's something better out there. Any thoughts?",n 2 1 6 3 36 = 6^2 4 = 2^2 5 2 2 4 5 400 = 20^2 r(n) r(6) r(n) n \to \infty 100 \pi(n),"['probability', 'prime-numbers']"
3,"Why is there Symmetry (Equality) between ""the first marble being blue"" and ""the second marble being blue"" here?","Why is there Symmetry (Equality) between ""the first marble being blue"" and ""the second marble being blue"" here?",,"This problem is of my own construction, which I have constructed to understand Symmetry better. Say that we have three bags, each having blue and red marbles. In the bag 1, $1 \over 2$ of the marbles are blue; in bag 2, $1 \over 3$ of the marbles are blue; in bag 3, $1 \over 4$ of the marbles are blue. Say our experiment consists of first randomly choosing a bag, grabbing a marble from it, and then choosing another bag, and grabbing a marble from this new bag. When considering the probability of the first marble we pick being blue, I am trying to understand why this is the same as the probability of the second marble we pick being blue, by a symmetrical argument (not just a brute force calculation of the probabilities to show they are equal). So far, I have tried to show that every sample point in the event of the first marble being blue corresponds to a sample point of equal probability in the event of the second marble being blue - and I show such correspondence by switching the first marble we have grabbed with the second. And then the bijection is straightforward to prove. However, I am struggling with arguing that when we swap which marble we have grabbed in the first and second spots, that this necessarily has the same probability of us sampling it - although I certainly feel intuitively that this is so, I can't explain why it is so at all. So why is there Symmetry between ""the first marble being blue"" and ""the second marble being blue"" here? EDIT: Is it valid to justify why the experiments of picking from the first bag and picking from the second bag after it are the same by saying that because we know nothing of the first bag and marble drawn before we drew the second, we act as if it never happened when drawing from the second bag? As if we say that the second experiment was different than the first, then given this we could possibly say what more likely happened on the first picking of the bag, in such a way that would contradict the probabilities we have for the first picking of the bag and marble?","This problem is of my own construction, which I have constructed to understand Symmetry better. Say that we have three bags, each having blue and red marbles. In the bag 1, of the marbles are blue; in bag 2, of the marbles are blue; in bag 3, of the marbles are blue. Say our experiment consists of first randomly choosing a bag, grabbing a marble from it, and then choosing another bag, and grabbing a marble from this new bag. When considering the probability of the first marble we pick being blue, I am trying to understand why this is the same as the probability of the second marble we pick being blue, by a symmetrical argument (not just a brute force calculation of the probabilities to show they are equal). So far, I have tried to show that every sample point in the event of the first marble being blue corresponds to a sample point of equal probability in the event of the second marble being blue - and I show such correspondence by switching the first marble we have grabbed with the second. And then the bijection is straightforward to prove. However, I am struggling with arguing that when we swap which marble we have grabbed in the first and second spots, that this necessarily has the same probability of us sampling it - although I certainly feel intuitively that this is so, I can't explain why it is so at all. So why is there Symmetry between ""the first marble being blue"" and ""the second marble being blue"" here? EDIT: Is it valid to justify why the experiments of picking from the first bag and picking from the second bag after it are the same by saying that because we know nothing of the first bag and marble drawn before we drew the second, we act as if it never happened when drawing from the second bag? As if we say that the second experiment was different than the first, then given this we could possibly say what more likely happened on the first picking of the bag, in such a way that would contradict the probabilities we have for the first picking of the bag and marble?",1 \over 2 1 \over 3 1 \over 4,"['probability', 'discrete-mathematics', 'symmetry']"
4,Smallest constant $C$ to bound $\mathbb{E}[\mathrm{tr}((\overline{X}_n + I)^{-1})] \leq C~\mathrm{tr}((\mathbb{E}[X] + I)^{-1})$?,Smallest constant  to bound ?,C \mathbb{E}[\mathrm{tr}((\overline{X}_n + I)^{-1})] \leq C~\mathrm{tr}((\mathbb{E}[X] + I)^{-1}),"Let $X_1, \dots, X_n$ be random real-valued symmetric rank-one matrices, $$ X_i = x_i \otimes x_i,  $$ where $x_i$ are such that the standard Euclidean norm satisfies $\|x_i\|^2 \leq a$ almost surely. Assume that $x_i$ are independently and identically distributed and let $M = \mathbb{E}[X_i] = \mathbb{E}[x_i \otimes x_i]$ , denote their common mean. Define their average $\overline{X}_{n} = n^{-1} S_n$ where $S_n = \sum_{i=1}^n X_i$ . Let $f(T) := \mathrm{trace}((T + I)^{-1})$ . Question: What is the smallest constant $C = C_d(a, n) \geq 1$ such that we have $$ \mathbb{E}[f(\overline{X}_n)] \leq C~f(M)? $$ It should be emphasized that the constant $C$ is universal: it is valid for any law of $x_i$ , supported on the Euclidean ball of (squared) radius $a$ . It should be dependent only on $a, n$ and the dimension $d$ . Comments: Necessarily $C \geq 1$ . Note that by Jensen's inequality, we have the following inequality, $ \mathbb{E}[f(\overline{X}_n)] \geq f(M),  $ since $f$ is a convex function on the symmetric positive definite matrices. In the case $d = 1$ , I was able to solve this problem and calculate the extremal distribution. See this post .","Let be random real-valued symmetric rank-one matrices, where are such that the standard Euclidean norm satisfies almost surely. Assume that are independently and identically distributed and let , denote their common mean. Define their average where . Let . Question: What is the smallest constant such that we have It should be emphasized that the constant is universal: it is valid for any law of , supported on the Euclidean ball of (squared) radius . It should be dependent only on and the dimension . Comments: Necessarily . Note that by Jensen's inequality, we have the following inequality, since is a convex function on the symmetric positive definite matrices. In the case , I was able to solve this problem and calculate the extremal distribution. See this post .","X_1, \dots, X_n 
X_i = x_i \otimes x_i, 
 x_i \|x_i\|^2 \leq a x_i M = \mathbb{E}[X_i] = \mathbb{E}[x_i \otimes x_i] \overline{X}_{n} = n^{-1} S_n S_n = \sum_{i=1}^n X_i f(T) := \mathrm{trace}((T + I)^{-1}) C = C_d(a, n) \geq 1 
\mathbb{E}[f(\overline{X}_n)] \leq C~f(M)?
 C x_i a a, n d C \geq 1 
\mathbb{E}[f(\overline{X}_n)] \geq f(M), 
 f d = 1","['probability', 'inequality', 'expected-value', 'trace', 'positive-semidefinite']"
5,"Reflection principle, brownian motion","Reflection principle, brownian motion",,"Let $(B_t)_{t \ge 0}$ be a Brownian motion and define its maximal function on a interval $M_a^b = \sup_{a \le s \le b} B_s$ . By the reflection principle, I have shown that for $t \in (0,1)$ , we have $$\mathbb{P}(B_1 \le -1, M_{t}^1 \ge 1 \ |\   \mathcal{F}_t) = \mathbb{P}(B_1 \ge 3 \  | \ \mathcal{F}_t) = 1-\phi\left(\frac{3-B_t}{\sqrt{1-t}}\right), $$ which I hope is correct. Now, is it possible to calculate in a similar manner the following probability: $$\mathbb{P}(B_1 > -1, M_{t}^1 < 1, M_{1}^2 \ge 1 \ |\   \mathcal{F}_t) = \ ?$$ I started by conditioning on $\mathcal{F}_1$ and got to the point $2\mathbb{E}\left((1 - \phi(1-B_1))1_{\lbrace B_1 > -1, M_{t}^1 < 1\rbrace} \ | \ \mathcal{F}_t\right)$ , but I don't know how to proceed further. Edit. I've decided to check the case $t=0$ first. So using the joint distribution of $(B_1, M_0^1)$ , omitting the constant $2$ and taking $\phi(1-B_1)$ instead of $1-\phi(1-B_1)$ just for simplicity, I have the following integral to calculate $$\int_{0}^1 \int_{-1}^b \int_{-\infty}^{1-a} \frac{1}{\pi}(2b-a)e^{-\frac{(2b-a)^2}{2}}e^{-\frac{x^2}{2}} \mbox{d}x\mbox{d}a\mbox{d}b.$$ Is it correct? And is it possible to simplify this expression?","Let be a Brownian motion and define its maximal function on a interval . By the reflection principle, I have shown that for , we have which I hope is correct. Now, is it possible to calculate in a similar manner the following probability: I started by conditioning on and got to the point , but I don't know how to proceed further. Edit. I've decided to check the case first. So using the joint distribution of , omitting the constant and taking instead of just for simplicity, I have the following integral to calculate Is it correct? And is it possible to simplify this expression?","(B_t)_{t \ge 0} M_a^b = \sup_{a \le s \le b} B_s t \in (0,1) \mathbb{P}(B_1 \le -1, M_{t}^1 \ge 1 \ |\   \mathcal{F}_t) = \mathbb{P}(B_1 \ge 3 \  | \ \mathcal{F}_t) = 1-\phi\left(\frac{3-B_t}{\sqrt{1-t}}\right),  \mathbb{P}(B_1 > -1, M_{t}^1 < 1, M_{1}^2 \ge 1 \ |\   \mathcal{F}_t) = \ ? \mathcal{F}_1 2\mathbb{E}\left((1 - \phi(1-B_1))1_{\lbrace B_1 > -1, M_{t}^1 < 1\rbrace} \ | \ \mathcal{F}_t\right) t=0 (B_1, M_0^1) 2 \phi(1-B_1) 1-\phi(1-B_1) \int_{0}^1 \int_{-1}^b \int_{-\infty}^{1-a} \frac{1}{\pi}(2b-a)e^{-\frac{(2b-a)^2}{2}}e^{-\frac{x^2}{2}} \mbox{d}x\mbox{d}a\mbox{d}b.","['probability', 'probability-theory', 'stochastic-processes', 'brownian-motion']"
6,Under which probabilistic assumptions is this estimation approach correct?,Under which probabilistic assumptions is this estimation approach correct?,,"trying to tackle a problem, I ended up having built a model $ p(\boldsymbol{x}_{i}|\boldsymbol{y}_{i,j}, \boldsymbol{x}_{j}) $ which gives me for different $ \boldsymbol{y}_{i,j} $ observations made by $ \boldsymbol{x}_{j} $ , a new PDF of $ \boldsymbol{x}_{i} $ . My ultimate goal is to obtain the best estimate for it, $ \hat{\boldsymbol{x}_{i}} $ , given my $ \boldsymbol{y}_{i,j} $ observations. The most typical approach I have seen being used (from others who faced the same problem and made other models) is the: \begin{equation} \widehat{\boldsymbol{x}_{i}}=\arg \max_{\boldsymbol{x}_{i}} f(\boldsymbol{x}_{i}) \prod_{j \in \mathcal{O}} f(\boldsymbol{y}_{i,j} \mid \boldsymbol{x}_{i}, \boldsymbol{x}_{j}) \end{equation} However, I tried using instead simply the following and it worked just fine: \begin{equation} \widehat{\boldsymbol{x}_{i}}=\arg \max_{\boldsymbol{x}_{i}} \prod_{j \in \mathcal{O}} p(\boldsymbol{x}_{i} \mid \boldsymbol{y}_{i,j}, \boldsymbol{x}_{j}) \end{equation} I would like to ask why is that happening? What does the fact that both appear to work, suggest about their relationship? I did not mention the underlying assumptions (because I am not quite sure), therefore, I would like some help in identifying mathematically those. Thank you for your time. *Some further information regarding $ \boldsymbol{x}_{i} $ , $ \boldsymbol{y}_{i,j} $ , $ \boldsymbol{x}_j $ and their relation: $ \boldsymbol{x}_{i} $ is the position of some node in 3D space. Assume that this node is emitting one single impulse signal. $ \boldsymbol{y}_{i,j} $ is the measurement of that signal from another node (namely node $ j $ ), whose position is ""known"" to us. A measurement depends only on the distance between the transmitting and the receiving node (the model of this dependency is the same for all receiving nodes). Therefore, given some measurement $ \boldsymbol{y}_{i,j} $ and the position of the receiver $ \boldsymbol{x}_j $ , there is a distribution about where $ \boldsymbol{x}_{i} $ is. The following graph depicts my system where my actual goal is to find the best position estimation for all nodes $ \boldsymbol{X} $ (their positions are independent to each other) because, in fact, I do not have any prior knowledge about them (the knowledge gets built iteratively via my optimization process). So in fact, after optimizing $ \boldsymbol{x}_{i} $ , I continue optimizing iteratively one by one all the rest of $ \boldsymbol{x}_{j} $ 's (which become the new $ \boldsymbol{x}_{i} $ on each step) using the previous estimations of the $ \boldsymbol{x}_{j} $ 's when available (else I am using a random position). I have practically seen that this method converges to a correct solution where nodes are in a relative reference system (since my initial positions are random) placed.","trying to tackle a problem, I ended up having built a model which gives me for different observations made by , a new PDF of . My ultimate goal is to obtain the best estimate for it, , given my observations. The most typical approach I have seen being used (from others who faced the same problem and made other models) is the: However, I tried using instead simply the following and it worked just fine: I would like to ask why is that happening? What does the fact that both appear to work, suggest about their relationship? I did not mention the underlying assumptions (because I am not quite sure), therefore, I would like some help in identifying mathematically those. Thank you for your time. *Some further information regarding , , and their relation: is the position of some node in 3D space. Assume that this node is emitting one single impulse signal. is the measurement of that signal from another node (namely node ), whose position is ""known"" to us. A measurement depends only on the distance between the transmitting and the receiving node (the model of this dependency is the same for all receiving nodes). Therefore, given some measurement and the position of the receiver , there is a distribution about where is. The following graph depicts my system where my actual goal is to find the best position estimation for all nodes (their positions are independent to each other) because, in fact, I do not have any prior knowledge about them (the knowledge gets built iteratively via my optimization process). So in fact, after optimizing , I continue optimizing iteratively one by one all the rest of 's (which become the new on each step) using the previous estimations of the 's when available (else I am using a random position). I have practically seen that this method converges to a correct solution where nodes are in a relative reference system (since my initial positions are random) placed."," p(\boldsymbol{x}_{i}|\boldsymbol{y}_{i,j}, \boldsymbol{x}_{j})   \boldsymbol{y}_{i,j}   \boldsymbol{x}_{j}   \boldsymbol{x}_{i}   \hat{\boldsymbol{x}_{i}}   \boldsymbol{y}_{i,j}  \begin{equation}
\widehat{\boldsymbol{x}_{i}}=\arg \max_{\boldsymbol{x}_{i}} f(\boldsymbol{x}_{i}) \prod_{j \in \mathcal{O}} f(\boldsymbol{y}_{i,j} \mid \boldsymbol{x}_{i}, \boldsymbol{x}_{j})
\end{equation} \begin{equation}
\widehat{\boldsymbol{x}_{i}}=\arg \max_{\boldsymbol{x}_{i}} \prod_{j \in \mathcal{O}} p(\boldsymbol{x}_{i} \mid \boldsymbol{y}_{i,j}, \boldsymbol{x}_{j})
\end{equation}  \boldsymbol{x}_{i}   \boldsymbol{y}_{i,j}   \boldsymbol{x}_j   \boldsymbol{x}_{i}   \boldsymbol{y}_{i,j}   j   \boldsymbol{y}_{i,j}   \boldsymbol{x}_j   \boldsymbol{x}_{i}   \boldsymbol{X}   \boldsymbol{x}_{i}   \boldsymbol{x}_{j}   \boldsymbol{x}_{i}   \boldsymbol{x}_{j} ","['probability', 'probability-theory', 'probability-distributions', 'conditional-probability', 'bayesian']"
7,Sum of two independent random variables: distribution function and quantile function,Sum of two independent random variables: distribution function and quantile function,,"If $X,Y$ are two independent random variables with CDFs $F_X,F_Y$ , their sum has CDF $F_X \star F_Y$ ( $\star$ is the convolution product). What can be said about the quantile function of $X+Y$ ? The quantile function should be the inverse of $F_X \star F_Y$ . Can we express that using the CDFs, quantiles (or even densities) of $X$ and $Y$ ?","If are two independent random variables with CDFs , their sum has CDF ( is the convolution product). What can be said about the quantile function of ? The quantile function should be the inverse of . Can we express that using the CDFs, quantiles (or even densities) of and ?","X,Y F_X,F_Y F_X \star F_Y \star X+Y F_X \star F_Y X Y","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'quantile-function']"
8,An inequality involving two i.i.d. standard Gaussians.,An inequality involving two i.i.d. standard Gaussians.,,"Short question : Let $ r,t,h\ge0 $ and $ G_1,G_2 $ be i.i.d. standard Gaussians. Is it true that $$ \Pr[\{(r+G_1)^2\le t\}\cup\{(r+G_1)^2+G_2^2\le h\}]\le\Pr[\{G_2^2\le t\}\cup\{(r+G_1)^2+G_2^2\le h\}]. $$ Motivation : I formulated the inequality in such a way since there is nice geometry behind it. In the following figure, $\mathcal{D}_0$ denotes the green disk and $\mathcal{D}_1,\mathcal{D}_2$ denote the vertical and horizontal (infinite) bands with the disk clipped out, respectively. Then the LHS of the inequality is the probability that $(G_1,G_2)$ falls into the region $\mathcal{D}_1\sqcup\mathcal{D}_0$ , and the RHS is the probability that $(G_1,G_2)$ falls into the region $\mathcal{D}_2\sqcup\mathcal{D}_0$ . The inequality is nontrivial only when $r>0$ and $t>0$ . It's clearly true when $t\ge h$ since the disk is contained in the bands. According to numerics, I believe it's true for any $r,t,h\ge0$ . However, I could not prove it. Any help is much appreciated. Disclaimer : This is not a HW question. It arises in a research project on high-dimensional statistics.","Short question : Let and be i.i.d. standard Gaussians. Is it true that Motivation : I formulated the inequality in such a way since there is nice geometry behind it. In the following figure, denotes the green disk and denote the vertical and horizontal (infinite) bands with the disk clipped out, respectively. Then the LHS of the inequality is the probability that falls into the region , and the RHS is the probability that falls into the region . The inequality is nontrivial only when and . It's clearly true when since the disk is contained in the bands. According to numerics, I believe it's true for any . However, I could not prove it. Any help is much appreciated. Disclaimer : This is not a HW question. It arises in a research project on high-dimensional statistics."," r,t,h\ge0   G_1,G_2   \Pr[\{(r+G_1)^2\le t\}\cup\{(r+G_1)^2+G_2^2\le h\}]\le\Pr[\{G_2^2\le t\}\cup\{(r+G_1)^2+G_2^2\le h\}].  \mathcal{D}_0 \mathcal{D}_1,\mathcal{D}_2 (G_1,G_2) \mathcal{D}_1\sqcup\mathcal{D}_0 (G_1,G_2) \mathcal{D}_2\sqcup\mathcal{D}_0 r>0 t>0 t\ge h r,t,h\ge0","['probability', 'inequality', 'gaussian']"
9,How are Markov Kernels Related to SDEs,How are Markov Kernels Related to SDEs,,"(Disclaimer: I've been working with SDEs for some years now but have not worked with general Markov processes before... so I'm trying to reconcile some ideas with this post. ) I recently read the definition of a Markov kernel $K$ on a measurable space $(\Omega,\mathcal{F})$ as being a map $K:\Omega,\times \mathcal{F}\rightarrow [0,1]$ satisfying: $\omega \mapsto K(\omega,A)$ is measurable, for any $A \in \mathcal{F}$ , $K(\omega,\cdot)$ is a probability measure on $(\Omega,\mathcal{F})$ for any $\omega \in \Omega$ . Suppose that $(X_t)_{0\leq t\leq 1}$ is an $\mathbb{R}$ -valued solution to the SDE: $$ X_t = \mu(t,X_t)dt + \sigma(t,X_t)dW_t, $$ for some Brownian motion $(W_t)_{0\leq t\leq 1}$ and some smooth Lipschitz functions $\mu$ and $\sigma$ .  I know that $(X_t)_{0\leq t\leq 1}$ has the Markov property, but how  does this to relate this to a Markov kernel ? In other words... what is the Markov kernel determining $(X_t)_{0\leq t\leq 1}$ . (Excuse me if the question is silly, but I'm self-teaching Markov processes...)","(Disclaimer: I've been working with SDEs for some years now but have not worked with general Markov processes before... so I'm trying to reconcile some ideas with this post. ) I recently read the definition of a Markov kernel on a measurable space as being a map satisfying: is measurable, for any , is a probability measure on for any . Suppose that is an -valued solution to the SDE: for some Brownian motion and some smooth Lipschitz functions and .  I know that has the Markov property, but how  does this to relate this to a Markov kernel ? In other words... what is the Markov kernel determining . (Excuse me if the question is silly, but I'm self-teaching Markov processes...)","K (\Omega,\mathcal{F}) K:\Omega,\times \mathcal{F}\rightarrow [0,1] \omega \mapsto K(\omega,A) A \in \mathcal{F} K(\omega,\cdot) (\Omega,\mathcal{F}) \omega \in \Omega (X_t)_{0\leq t\leq 1} \mathbb{R} 
X_t = \mu(t,X_t)dt + \sigma(t,X_t)dW_t,
 (W_t)_{0\leq t\leq 1} \mu \sigma (X_t)_{0\leq t\leq 1} (X_t)_{0\leq t\leq 1}","['probability', 'probability-theory', 'markov-chains', 'markov-process', 'stochastic-differential-equations']"
10,$|𝐸[𝑋]|+𝜌(𝑋)≥1$?,?,|𝐸[𝑋]|+𝜌(𝑋)≥1,"Suppose $X_1, X_2, ... \sim X$ are i.i.d. random variables on $\mathbb{Z}$ . Then the sequence $\{P(\sum_{i=1}^{d(X)n} X_i = 0)^{\frac{1}{d(X)n}}\}_{n=1}^\infty$ converges to some constant $\rho(X) \in [0;1]$ almost surely by Kingman’s subadditive ergodic theorem. Here $d(X) = \min\{d \in \mathbb{N}|P(\sum_{i=1}^{d} X_i = 0)>0\}$ . For some random variables $X$ the value $\rho(X)$ can easily be calculated. For example: If $P(X \geq 0) = 1$ or $P(X \leq 0) = 1$ , then $\rho(X) = P(X = 0)$ trivially. If $$X = \begin{cases} -a & \quad \text{ with probability } p \\ b & \quad \text{ with probability } 1-p \end{cases}$$ where $a, b \in \mathbb{N}$ , $p \in (0;1)$ , then $\rho(X)=\frac{p^{1-x}(1-p)^{x}}{x^x(1-x)^{1-x}}$ , where $x = \frac{a}{a+b}$ . That is due to the fact, that $P(\sum_{i=1}^{(a+b)n} X_i = 0) = C^a_{a+b}p^ac^b$ . I want to determine, whether the inequality $|E[X]| + \rho(X) \geq 1$ holds for all random variables $X$ on $\mathbb{Z}$ . So far I only managed to ""prove"" it in three trivial cases: If $P(X \geq 0) = 1$ . Then, by Markov inequality $1 - \rho(X) = 1-P(X=0) = P(X \geq 1) \leq E[X] = |E[X]|$ . If $P(X \leq 0) = 1$ . Then, by Markov inequality $1 - \rho(X) = 1-P(X=0) = P(-X \geq 1) \leq -E[X] = |E[X]|$ . If $|E[X]| \geq 1$ . That is because $\rho(X) \in [0;1]$ However, I do not know how to prove this inequality in general case. Neither have I found any counterexamples. Related question on upper bound for $\rho(X)$ : $\rho(X)E[X]^2 \leq Var[X]$?","Suppose are i.i.d. random variables on . Then the sequence converges to some constant almost surely by Kingman’s subadditive ergodic theorem. Here . For some random variables the value can easily be calculated. For example: If or , then trivially. If where , , then , where . That is due to the fact, that . I want to determine, whether the inequality holds for all random variables on . So far I only managed to ""prove"" it in three trivial cases: If . Then, by Markov inequality . If . Then, by Markov inequality . If . That is because However, I do not know how to prove this inequality in general case. Neither have I found any counterexamples. Related question on upper bound for : $\rho(X)E[X]^2 \leq Var[X]$?","X_1, X_2, ... \sim X \mathbb{Z} \{P(\sum_{i=1}^{d(X)n} X_i = 0)^{\frac{1}{d(X)n}}\}_{n=1}^\infty \rho(X) \in [0;1] d(X) = \min\{d \in \mathbb{N}|P(\sum_{i=1}^{d} X_i = 0)>0\} X \rho(X) P(X \geq 0) = 1 P(X \leq 0) = 1 \rho(X) = P(X = 0) X = \begin{cases} -a & \quad \text{ with probability } p \\ b & \quad \text{ with probability } 1-p \end{cases} a, b \in \mathbb{N} p \in (0;1) \rho(X)=\frac{p^{1-x}(1-p)^{x}}{x^x(1-x)^{1-x}} x = \frac{a}{a+b} P(\sum_{i=1}^{(a+b)n} X_i = 0) = C^a_{a+b}p^ac^b |E[X]| + \rho(X) \geq 1 X \mathbb{Z} P(X \geq 0) = 1 1 - \rho(X) = 1-P(X=0) = P(X \geq 1) \leq E[X] = |E[X]| P(X \leq 0) = 1 1 - \rho(X) = 1-P(X=0) = P(-X \geq 1) \leq -E[X] = |E[X]| |E[X]| \geq 1 \rho(X) \in [0;1] \rho(X)","['probability', 'probability-theory', 'inequality', 'stochastic-processes', 'random-walk']"
11,"Probability that $\int_0^tX_s\,dW_s$ lies within $1/t$ of $X_t$",Probability that  lies within  of,"\int_0^tX_s\,dW_s 1/t X_t","Consider the inequality $$f(x)-\frac1x\le f’(x)\le f(x)+\frac1x$$ on the positive axis. This tells us that $f(x)\sim e^x$ with infinitesimal deviation, and we can use identities such as Grönwall's inequality to establish bounds on $f(x)$ . As there is no randomness in the function, this problem is deterministic. In the random scenario, consider a stochastic process $X_t$ under Brownian motion (BM); that is, $$dX_t=\mu(t,X_t)\,dt+\sigma(t,X_t)\,dW_t.$$ The problem thus becomes evaluating the value of $$F_{X_t}(t)=\operatorname P\left(\int_0^tX_s\,dW_s-\frac1t\le X_t\le\int_0^tX_sdW_s+\frac1t\right)\tag1$$ for any $t>0$ . Note that the analogous version of $f(x)\sim e^x$ can be described through geometric Brownian motion (GBM). If $X_t=W_t$ , we expect $F(t)\to0$ as $t\to\infty$ . Indeed, we have \begin{align}F_{W_t}(t)&=\operatorname P\left(-\frac12t-\frac1t+W_t^2\le W_t\le-\frac12t+\frac1t+W_t^2\right)\end{align} using Itô's lemma. This can be rewritten as $$F_{W_t}(t)=\operatorname P\left(\frac{2t^2+t-4}{4t}\le\left(W_t-\frac12\right)^2\le\frac{2t^2+t+4}{4t}\right)$$ to the form $\operatorname P\left(g(t)\le W_t\le h(t)\right)$ , which can then be converted to a standard Normal. But how about in the case of GBM (where $F(t)\to1$ with an appropriate choice of $\mu,\sigma$ ), or more generally any $X_t$ ?","Consider the inequality on the positive axis. This tells us that with infinitesimal deviation, and we can use identities such as Grönwall's inequality to establish bounds on . As there is no randomness in the function, this problem is deterministic. In the random scenario, consider a stochastic process under Brownian motion (BM); that is, The problem thus becomes evaluating the value of for any . Note that the analogous version of can be described through geometric Brownian motion (GBM). If , we expect as . Indeed, we have using Itô's lemma. This can be rewritten as to the form , which can then be converted to a standard Normal. But how about in the case of GBM (where with an appropriate choice of ), or more generally any ?","f(x)-\frac1x\le f’(x)\le f(x)+\frac1x f(x)\sim e^x f(x) X_t dX_t=\mu(t,X_t)\,dt+\sigma(t,X_t)\,dW_t. F_{X_t}(t)=\operatorname P\left(\int_0^tX_s\,dW_s-\frac1t\le X_t\le\int_0^tX_sdW_s+\frac1t\right)\tag1 t>0 f(x)\sim e^x X_t=W_t F(t)\to0 t\to\infty \begin{align}F_{W_t}(t)&=\operatorname P\left(-\frac12t-\frac1t+W_t^2\le W_t\le-\frac12t+\frac1t+W_t^2\right)\end{align} F_{W_t}(t)=\operatorname P\left(\frac{2t^2+t-4}{4t}\le\left(W_t-\frac12\right)^2\le\frac{2t^2+t+4}{4t}\right) \operatorname P\left(g(t)\le W_t\le h(t)\right) F(t)\to1 \mu,\sigma X_t","['probability', 'stochastic-processes', 'asymptotics', 'stochastic-calculus', 'brownian-motion']"
12,How are category theory and probability theory related?,How are category theory and probability theory related?,,"How are category theory and probability theory related ? Category theory seems very useful for understanding objects with definite relationships, whereas probability theory (particular Bayesian methods), can be applied to areas where there is uncertainty. My question is, what attempts have been made to combine these disciplines ? Are there areas of category theory which focus upon probabilistic situations ? Have there been approaches using Bayesian methods etc. to build category theoretic representations of data ? Are there applications of category theory to probabilistic programming ?","How are category theory and probability theory related ? Category theory seems very useful for understanding objects with definite relationships, whereas probability theory (particular Bayesian methods), can be applied to areas where there is uncertainty. My question is, what attempts have been made to combine these disciplines ? Are there areas of category theory which focus upon probabilistic situations ? Have there been approaches using Bayesian methods etc. to build category theoretic representations of data ? Are there applications of category theory to probabilistic programming ?",,"['probability', 'category-theory', 'statistical-inference', 'machine-learning', 'bayesian']"
13,Linear reward-inaction algorithm for two-armed bandit,Linear reward-inaction algorithm for two-armed bandit,,"Suppose there are two slot-machines. When playing one of them, you win with probability $p$ and while playing the other you win with probability $q$ , where $0 < q < p <1$ . A gambler approaches them. He does not know the probabilities of victory for either of slot-machines. However, he has recently read ""Theories of Learning"" by Hilgard and Bower and has therefore decided to employ the following algorithm from that book: Suppose $p_n$ is the probability of choosing the first slot-machine on $n$ -th pull. Then $p_0 = \frac{1}{2}$ and for $n \geq 1$ $p_{n} = \alpha + (1 - \alpha) p_{n-1}$ if he pulled the lever of the first slot-machine and won, $p_{n} = (1-\alpha)p_{n-1}$ if he pulled the lever of the second slot-machine and won and $p_{n} = p_{n-1}$ otherwise. Here $\alpha \in [0;1]$ is some constant. What is the expected number of wins the gambler scores if the number of pulls he makes is geometrically distributed with parameter $\gamma$ ? What have I tried: The expected number of wins is $\sum_{n=0}^{\infty} \gamma^n E[q_n]$ , where $q_n$ is the probability of winning after $n$ -th pull. Because $q_n = p_np + (1 - p_n)q = q + p_n(p - q)$ . Thus the expected number of wins is $\frac{q}{1-\gamma} + (p-q)\sum_{n=0}^{\infty} \gamma^n E[p_n]$ . So, all we need is to find $E[p_n]$ . For $p_n$ we have the following recurrence: $$p_0 = \frac{1}{2}$$ $$p_n = \begin{cases}  \alpha + (1 - \alpha) p_{n-1} & \quad \text{ with probability } p_{n-1}p \\ (1-\alpha)p_{n-1}  & \quad \text{ with probability } (1 - p_{n-1})q \\ p_{n-1}  & \quad \text{ with probability } 1 - q - p_{n-1}(p - q) \end{cases}$$ However, because this recurrence is non-linear it can not be easily translated into recurrence for expectations. And here I am stuck.","Suppose there are two slot-machines. When playing one of them, you win with probability and while playing the other you win with probability , where . A gambler approaches them. He does not know the probabilities of victory for either of slot-machines. However, he has recently read ""Theories of Learning"" by Hilgard and Bower and has therefore decided to employ the following algorithm from that book: Suppose is the probability of choosing the first slot-machine on -th pull. Then and for if he pulled the lever of the first slot-machine and won, if he pulled the lever of the second slot-machine and won and otherwise. Here is some constant. What is the expected number of wins the gambler scores if the number of pulls he makes is geometrically distributed with parameter ? What have I tried: The expected number of wins is , where is the probability of winning after -th pull. Because . Thus the expected number of wins is . So, all we need is to find . For we have the following recurrence: However, because this recurrence is non-linear it can not be easily translated into recurrence for expectations. And here I am stuck.",p q 0 < q < p <1 p_n n p_0 = \frac{1}{2} n \geq 1 p_{n} = \alpha + (1 - \alpha) p_{n-1} p_{n} = (1-\alpha)p_{n-1} p_{n} = p_{n-1} \alpha \in [0;1] \gamma \sum_{n=0}^{\infty} \gamma^n E[q_n] q_n n q_n = p_np + (1 - p_n)q = q + p_n(p - q) \frac{q}{1-\gamma} + (p-q)\sum_{n=0}^{\infty} \gamma^n E[p_n] E[p_n] p_n p_0 = \frac{1}{2} p_n = \begin{cases}  \alpha + (1 - \alpha) p_{n-1} & \quad \text{ with probability } p_{n-1}p \\ (1-\alpha)p_{n-1}  & \quad \text{ with probability } (1 - p_{n-1})q \\ p_{n-1}  & \quad \text{ with probability } 1 - q - p_{n-1}(p - q) \end{cases},"['probability', 'stochastic-processes', 'recurrence-relations', 'expected-value']"
14,"In optimal transport, what is the difference between the Hungarian and Sinkhorn algorithms?","In optimal transport, what is the difference between the Hungarian and Sinkhorn algorithms?",,"Optimal assignment using the Hungarian algorithm was found to be improved for optimal transport using the Sinkhorn algorithm. Intuitively I cannot make out why. More fundamentally, how optimal assignment is different from optimal transport, if it even is. If an explanation of the title question can be made based on the differences between the Hungarian objective function and the Sinkhorn objective function/protocol, this might help with understanding. Also, does Sinkhorn algorithm = Sinkhorn-Knopp algorithm = Sinkhorn's theorem?","Optimal assignment using the Hungarian algorithm was found to be improved for optimal transport using the Sinkhorn algorithm. Intuitively I cannot make out why. More fundamentally, how optimal assignment is different from optimal transport, if it even is. If an explanation of the title question can be made based on the differences between the Hungarian objective function and the Sinkhorn objective function/protocol, this might help with understanding. Also, does Sinkhorn algorithm = Sinkhorn-Knopp algorithm = Sinkhorn's theorem?",,"['probability', 'probability-distributions', 'optimization', 'algorithms', 'optimal-transport']"
15,How much are $\sum_n X_n$ and $\sum_n X_n X_{n+1}$ independent in a random walk?,How much are  and  independent in a random walk?,\sum_n X_n \sum_n X_n X_{n+1},"I was thinking about a problem in combinatorics and came up with an idea of estimating the joint probability distribution of multiple quantities related to a Markov chain. Let's say $(X_n)_{1 \leq n \leq N}$ is a Markov chain with a finite state space $S$ . The quantities I am interested in have the form $$\sum_{1 \leq n_1 < n_2 < \cdots < n_k \leq N} f(X_{n_1}, X_{n_2}, \cdots, X_{n_k}),$$ for some function $f : S^k \rightarrow \{ +1, 0, -1 \}$ . These are very complicated sums, so I would like to start by considering a simplified model. Let $(X_n)_{1 \leq n \leq N}$ be i.i.d. random variables which take values $\pm 1$ with probability $1/2$ each. Consider the two quantities $$S_N = \sum_{1 \leq n \leq N} X_n \quad \text{and} \quad T_N = \sum_{1 \leq n \leq N-1} X_n X_{n+1}.$$ Of course, they are not independent; $S_N = \pm N$ forces $T_N = N-1$ and vice versa. But for moderate values of $S_N$ and $T_N$ (say, of magnitude $O(\sqrt N)$ ), I expect them to be nearly independent in the sense that $$\mathbb{P}(S_N = s, T_N = t) \approx \mathbb{P}(S_N = s) \cdot \mathbb{P}(T_N = t) \quad (s, t = O(\sqrt N)).$$ How much are $S_N$ and $T_N$ independent in the limit $N \rightarrow \infty$ ? Would it be possible to give a bound for $$\left| \frac{\mathbb{P}(S_N = s, T_N = t)}{\mathbb{P}(S_N = s) \cdot \mathbb{P}(T_N = t)} - 1 \right|$$ or the mutual information of $S_N$ and $T_N$ ? (Or any other measures of dependency?)","I was thinking about a problem in combinatorics and came up with an idea of estimating the joint probability distribution of multiple quantities related to a Markov chain. Let's say is a Markov chain with a finite state space . The quantities I am interested in have the form for some function . These are very complicated sums, so I would like to start by considering a simplified model. Let be i.i.d. random variables which take values with probability each. Consider the two quantities Of course, they are not independent; forces and vice versa. But for moderate values of and (say, of magnitude ), I expect them to be nearly independent in the sense that How much are and independent in the limit ? Would it be possible to give a bound for or the mutual information of and ? (Or any other measures of dependency?)","(X_n)_{1 \leq n \leq N} S \sum_{1 \leq n_1 < n_2 < \cdots < n_k \leq N} f(X_{n_1}, X_{n_2}, \cdots, X_{n_k}), f : S^k \rightarrow \{ +1, 0, -1 \} (X_n)_{1 \leq n \leq N} \pm 1 1/2 S_N = \sum_{1 \leq n \leq N} X_n \quad \text{and} \quad T_N = \sum_{1 \leq n \leq N-1} X_n X_{n+1}. S_N = \pm N T_N = N-1 S_N T_N O(\sqrt N) \mathbb{P}(S_N = s, T_N = t) \approx \mathbb{P}(S_N = s) \cdot \mathbb{P}(T_N = t) \quad (s, t = O(\sqrt N)). S_N T_N N \rightarrow \infty \left| \frac{\mathbb{P}(S_N = s, T_N = t)}{\mathbb{P}(S_N = s) \cdot \mathbb{P}(T_N = t)} - 1 \right| S_N T_N","['probability', 'probability-theory', 'random-variables', 'markov-chains', 'random-walk']"
16,Definition of Random Measures,Definition of Random Measures,,"Introducing the notion of a random measure, textbooks usually start with a locally compact second countable Hausdorff space. Where does this requirement come from? I would like to have a motivation for this requirement. That is, I would like to define a random measure on a general measurable space $(X,\mathcal{B})$ simply as a kernel from a probability space to $(X,\mathcal{B}).$ Additional structure of $(X,\mathcal{B})$ should then be motivated by e.g. counterintuitive examples. For example, in the book of Last and Penrose (2017) http://www.math.kit.edu/stoch/~last/seite/lectures_on_the_poisson_process/media/lastpenrose2017.pdf Exercise 2.5 yields that point measures usually do not have the representation with a Dirac measures. Are there other examples, (intuitive) motivations and reasons to use a locally compact (!) second countable (!) Hausdorff space?","Introducing the notion of a random measure, textbooks usually start with a locally compact second countable Hausdorff space. Where does this requirement come from? I would like to have a motivation for this requirement. That is, I would like to define a random measure on a general measurable space simply as a kernel from a probability space to Additional structure of should then be motivated by e.g. counterintuitive examples. For example, in the book of Last and Penrose (2017) http://www.math.kit.edu/stoch/~last/seite/lectures_on_the_poisson_process/media/lastpenrose2017.pdf Exercise 2.5 yields that point measures usually do not have the representation with a Dirac measures. Are there other examples, (intuitive) motivations and reasons to use a locally compact (!) second countable (!) Hausdorff space?","(X,\mathcal{B}) (X,\mathcal{B}). (X,\mathcal{B})","['probability', 'probability-theory', 'stochastic-processes', 'geometric-probability', 'point-processes']"
17,Looking for more properties & references for what I call backward harmonic functions,Looking for more properties & references for what I call backward harmonic functions,,"While analyzing a discrete version if Ito's Lemma, I became interested in a family of functions defined by the following: $$ f(n, k) = \frac{f(n+1, k+1) + f(n+1, k-1)}{2} \tag{$1$} $$ If $f$ satisfies (1), then we call $f$ a backwards harmonic function. For example, $f(k, n) = k^2 - n$ satisfies the above, as does $f(n, k) = k$ and $f(n, k) = \text{const}$ . I've been able to prove the following about backward harmonic functions: Extreme values: If $f$ satisfies equation (1), then $f$ has its maximum value and minimum value on the boundary ${(n, ·)}$ . Vector space: If $g$ and $h$ are backwards harmonic functions and $a, b \in R$ , then $a · g + b · h$ is also a backward harmonic function. Uniqueness: If $f$ and $g$ are backwards harmonic and $f(N, ·) = g(N, ·)$ , then $f(m, k) = g(m, k), 0 \le m \le N, \forall k$ Suppose $f(n, k)$ is backwards harmonic and satisfies $f(n + 1, k) = f(n, k)$ for all $n, k$ , then $f(n, k) = (f_0 − f(n, −1))\cdot k + f_0$ for any $n$ What more can we learn about these functions? Are they already studied under a different name? The reason I am interested in these functions is related to another theorem I have proved. If $B_n$ is a random walk defined by $B_0=0$ and $P(\Delta B_n = 1) = P(\Delta B_n = -1) = 0.5$ , then $f$ is a backwards harmonic function iff $f(n, B_n)$ is a martingale with respect to $B_n$ . If $f$ is a backwards harmonic function, then $E[|f(n + 1, B_{n+1})|] \ge E[|f(n, B_n)|]$ Edit 1. The question When is a polynomial of an unbiased random walk a martingale? gives other polynomials, which generally seem to be related to Hermite polynomials. (Correction: see Edit 2.) There are other, non-polynomials that satisfy this that I've found: $$ f(n,k) = \begin{cases}     1,& \text{if } n = 0\\     2^{n-1},  & n > 0 \;\text{and}\; (k = n \;\text{or}\; k = -n) \\     0,  & \text{otherwise} \end{cases} $$ 00                            [1]                             sum=1 01                           [1, 1]                           sum=2 02                         [2, 0, 2]                          sum=4 03                        [4, 0, 0, 4]                        sum=8 04                      [8, 0, 0, 0, 8]                       sum=16 05                    [16, 0, 0, 0, 0, 16]                    sum=32 06                  [32, 0, 0, 0, 0, 0, 32]                   sum=64 07                 [64, 0, 0, 0, 0, 0, 0, 64]                 sum=128 08              [128, 0, 0, 0, 0, 0, 0, 0, 128]               sum=256 09             [256, 0, 0, 0, 0, 0, 0, 0, 0, 256]             sum=512 10           [512, 0, 0, 0, 0, 0, 0, 0, 0, 0, 512]            sum=1024 Edit 2. There is a family of polynomial solutions that look like Hermite polynomials, but are different (perhaps a discrete form of them?). Define $$ f_0(n,k) = 1, \\f_1(n, k) = k $$ Define $$ f_m(n, k) = kf_{m-1}(n, k) + n\sum_{j=1}^{\frac{m}{2}} (-1)^j \cdot \text{Tan}(j)\cdot{m-1\choose 2j-1}\cdot f_{m - 2j}(n,k) $$ where $\text{Tan}(n)$ is a tangent number . I claim that $f_m(n,k)$ is also backwards harmonic. This generates the sequence of polynomials as in When is a polynomial of an unbiased random walk a martingale? $$ \begin{align} f_2(n, k) &= k^{2} - n\\ f_3(n, k) &= k^{3} - 3 k n\\ f_4(n, k) &= k^{4} - 6 k^{2} n + 3 n^{2} + 2 n\\ f_5(n, k) &= k^{5} - 10 k^{3} n + 15 k n^{2} + 10 k n\\ f_6(n, k) &= k^{6} - 15 k^{4} n + 45 k^{2} n^{2} + 30 k^{2} n - 15 n^{3} - 30 n^{2} - 16 n\\ f_7(n, k) &= k^{7} - 21 k^{5} n + 105 k^{3} n^{2} + 70 k^{3} n - 105 k n^{3} - 210 k n^{2} - 112 k n \end{align} $$ Some properties: $f_m(n, x + y) = \sum_{i=0}^m {m\choose i}f_{m-i}(n, x) y^{i}$ Equivalent to above: $\frac{d}{dx}f_m(n, x) = m f_{m-1}(n, x)$ $f_m(n+1, k)$ looks to be related to the Swiss-Knife polynomials","While analyzing a discrete version if Ito's Lemma, I became interested in a family of functions defined by the following: If satisfies (1), then we call a backwards harmonic function. For example, satisfies the above, as does and . I've been able to prove the following about backward harmonic functions: Extreme values: If satisfies equation (1), then has its maximum value and minimum value on the boundary . Vector space: If and are backwards harmonic functions and , then is also a backward harmonic function. Uniqueness: If and are backwards harmonic and , then Suppose is backwards harmonic and satisfies for all , then for any What more can we learn about these functions? Are they already studied under a different name? The reason I am interested in these functions is related to another theorem I have proved. If is a random walk defined by and , then is a backwards harmonic function iff is a martingale with respect to . If is a backwards harmonic function, then Edit 1. The question When is a polynomial of an unbiased random walk a martingale? gives other polynomials, which generally seem to be related to Hermite polynomials. (Correction: see Edit 2.) There are other, non-polynomials that satisfy this that I've found: 00                            [1]                             sum=1 01                           [1, 1]                           sum=2 02                         [2, 0, 2]                          sum=4 03                        [4, 0, 0, 4]                        sum=8 04                      [8, 0, 0, 0, 8]                       sum=16 05                    [16, 0, 0, 0, 0, 16]                    sum=32 06                  [32, 0, 0, 0, 0, 0, 32]                   sum=64 07                 [64, 0, 0, 0, 0, 0, 0, 64]                 sum=128 08              [128, 0, 0, 0, 0, 0, 0, 0, 128]               sum=256 09             [256, 0, 0, 0, 0, 0, 0, 0, 0, 256]             sum=512 10           [512, 0, 0, 0, 0, 0, 0, 0, 0, 0, 512]            sum=1024 Edit 2. There is a family of polynomial solutions that look like Hermite polynomials, but are different (perhaps a discrete form of them?). Define Define where is a tangent number . I claim that is also backwards harmonic. This generates the sequence of polynomials as in When is a polynomial of an unbiased random walk a martingale? Some properties: Equivalent to above: looks to be related to the Swiss-Knife polynomials","
f(n, k) = \frac{f(n+1, k+1) + f(n+1, k-1)}{2}
\tag{1}
 f f f(k, n) = k^2 - n f(n, k) = k f(n, k) = \text{const} f f {(n, ·)} g h a, b \in R a · g + b · h f g f(N, ·) = g(N, ·) f(m, k) = g(m, k), 0 \le m \le N, \forall k f(n, k) f(n + 1, k) = f(n, k) n, k f(n, k) = (f_0 − f(n, −1))\cdot k + f_0 n B_n B_0=0 P(\Delta B_n = 1) = P(\Delta B_n = -1) = 0.5 f f(n, B_n) B_n f E[|f(n + 1, B_{n+1})|] \ge E[|f(n, B_n)|] 
f(n,k) = \begin{cases}
    1,& \text{if } n = 0\\
    2^{n-1},  & n > 0 \;\text{and}\; (k = n \;\text{or}\; k = -n) \\
    0,  & \text{otherwise}
\end{cases}
 
f_0(n,k) = 1, \\f_1(n, k) = k
 
f_m(n, k) = kf_{m-1}(n, k) + n\sum_{j=1}^{\frac{m}{2}} (-1)^j \cdot \text{Tan}(j)\cdot{m-1\choose 2j-1}\cdot f_{m - 2j}(n,k)
 \text{Tan}(n) f_m(n,k) 
\begin{align}
f_2(n, k) &= k^{2} - n\\
f_3(n, k) &= k^{3} - 3 k n\\
f_4(n, k) &= k^{4} - 6 k^{2} n + 3 n^{2} + 2 n\\
f_5(n, k) &= k^{5} - 10 k^{3} n + 15 k n^{2} + 10 k n\\
f_6(n, k) &= k^{6} - 15 k^{4} n + 45 k^{2} n^{2} + 30 k^{2} n - 15 n^{3} - 30 n^{2} - 16 n\\
f_7(n, k) &= k^{7} - 21 k^{5} n + 105 k^{3} n^{2} + 70 k^{3} n - 105 k n^{3} - 210 k n^{2} - 112 k n
\end{align}
 f_m(n, x + y) = \sum_{i=0}^m {m\choose i}f_{m-i}(n, x) y^{i} \frac{d}{dx}f_m(n, x) = m f_{m-1}(n, x) f_m(n+1, k)","['probability', 'discrete-mathematics', 'recurrence-relations', 'functional-equations', 'random-walk']"
18,Optimal strategy in three-player number-picking game,Optimal strategy in three-player number-picking game,,"Consider a game in which there are three players. Call them Player $1$ , Player $2$ , and Player $3$ . Here are the rules: Each player is supposed to select an integer between $1$ and $100$ . Player $1$ 's number is randomly generated. Player $2$ and Player $3$ both know that Player $1$ 's number is randomly generated. The person with the largest number has to pay the other two people the number that each one of them said (i.e. say Player $1$ picks $5$ , Player $2$ picks $70$ and Player $3$ picks $90$ . In this case, Player $3$ pays $5$ to Player $1$ and $70$ to Player $2$ ). Let's suppose you are Player $3$ . Furthermore, suppose that Player $2$ plays optimally. What's the best strategy if you want to maximize profit? I solved the $n = 2$ (two-player game) case here: Optimal strategy in probability-based game I want to extend it to $n = 3$ , but I can't figure it out. I would appreciate any help.","Consider a game in which there are three players. Call them Player , Player , and Player . Here are the rules: Each player is supposed to select an integer between and . Player 's number is randomly generated. Player and Player both know that Player 's number is randomly generated. The person with the largest number has to pay the other two people the number that each one of them said (i.e. say Player picks , Player picks and Player picks . In this case, Player pays to Player and to Player ). Let's suppose you are Player . Furthermore, suppose that Player plays optimally. What's the best strategy if you want to maximize profit? I solved the (two-player game) case here: Optimal strategy in probability-based game I want to extend it to , but I can't figure it out. I would appreciate any help.",1 2 3 1 100 1 2 3 1 1 5 2 70 3 90 3 5 1 70 2 3 2 n = 2 n = 3,"['probability', 'game-theory']"
19,Proving $|P(A\cap B)-P(A)P(B)|\leq \frac{1}4$,Proving,|P(A\cap B)-P(A)P(B)|\leq \frac{1}4,"Let $A$ and $B$ be two events of a probability space. Prove that  $\displaystyle|P(A\cap B)-P(A)P(B)|\leq \frac{1}4$ I think it's a very challenging problem, and I've made no progress so far ... Can someone give me a hint ?","Let $A$ and $B$ be two events of a probability space. Prove that  $\displaystyle|P(A\cap B)-P(A)P(B)|\leq \frac{1}4$ I think it's a very challenging problem, and I've made no progress so far ... Can someone give me a hint ?",,"['probability', 'inequality']"
20,Interesting limit with Poisson and Chi-squared Distribution,Interesting limit with Poisson and Chi-squared Distribution,,"I am stuck with computing the following limit: \begin{align}  \lim_{ n \to \infty} E \left[ \left(E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}} \, \Big  | \, U  \right] \right)^2 \right]. \end{align} In the above expression, $X$ given $U$ follows Poisson with parameter $U$ and where $U$ is a Chi-square of degree $n$ . Here is what I tried: Suppose we let \begin{align} V_n =\left(E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}}  \, \Big | \, U  \right] \right)^2 \end{align} Then, using Jensen's inequality \begin{align} V_n  \le E \left[  \frac{X}{n} + \frac{1}{2} \,  \Big | U \,  \right] =  \frac{U}{n}+\frac{1}{2} \end{align} Moreover, we have that $E \left[  \frac{U}{n}+\frac{1}{2}   \right]=1+\frac{1}{2}$ . Therefore, by the dominated convergence theorem we have that \begin{align} \lim_{n \to \infty}  E[  V_n ]=   E[   \lim_{n \to \infty}  V_n ] \end{align} Therefore, assuming everything up to here is correct, to compute the limit we have to  find \begin{align}  \lim_{n \to \infty}  V_n&=  \lim_{n \to \infty}   \left(E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}}  \, \Big | \, U  \right] \right)^2\\ &=  \left(  \lim_{n \to \infty}  E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}}  \, \Big | \, U  \right] \right)^2 \end{align} This is the place where I am stuck.  Is it simply another applications dominated convergence theorem?  If so, then I think the answer is \begin{align}  \lim_{ n \to \infty} E \left[ \left(E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}} \, \Big  | \, U  \right] \right)^2 \right]=\frac{1}{2}. \end{align} What I mean by another application of dominating convergence theorem is that for every $u>0$ \begin{align} E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}} \, \Big  | \, U=u  \right] &\le  \sqrt{ E \left[   \frac{X}{n} + \frac{1}{2} \, \Big  | \, U=u  \right]}\\ &=   \sqrt{  \frac{u}{n} + \frac{1}{2} }\\ &= \sqrt{  u + \frac{1}{2}} \end{align} Therefore, \begin{align} E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}} \, \Big  | \, U=u  \right]=  E \left[  \lim_{n \to \infty}  \sqrt{ \frac{X}{n} + \frac{1}{2}} \, \Big  | \, U=u  \right]=  \frac{1}{2}. \end{align} Is this a correct sequence of steps?  I feel a bit uneasy about the second application of the dominated convergence theorem.","I am stuck with computing the following limit: In the above expression, given follows Poisson with parameter and where is a Chi-square of degree . Here is what I tried: Suppose we let Then, using Jensen's inequality Moreover, we have that . Therefore, by the dominated convergence theorem we have that Therefore, assuming everything up to here is correct, to compute the limit we have to  find This is the place where I am stuck.  Is it simply another applications dominated convergence theorem?  If so, then I think the answer is What I mean by another application of dominating convergence theorem is that for every Therefore, Is this a correct sequence of steps?  I feel a bit uneasy about the second application of the dominated convergence theorem.","\begin{align}
 \lim_{ n \to \infty} E \left[ \left(E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}} \, \Big  | \, U  \right] \right)^2 \right].
\end{align} X U U U n \begin{align}
V_n =\left(E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}}  \, \Big | \, U  \right] \right)^2
\end{align} \begin{align}
V_n  \le E \left[  \frac{X}{n} + \frac{1}{2} \,  \Big | U \,  \right] =  \frac{U}{n}+\frac{1}{2}
\end{align} E \left[  \frac{U}{n}+\frac{1}{2}   \right]=1+\frac{1}{2} \begin{align}
\lim_{n \to \infty}  E[  V_n ]=   E[   \lim_{n \to \infty}  V_n ]
\end{align} \begin{align}
 \lim_{n \to \infty}  V_n&=  \lim_{n \to \infty}   \left(E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}}  \, \Big | \, U  \right] \right)^2\\
&=  \left(  \lim_{n \to \infty}  E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}}  \, \Big | \, U  \right] \right)^2
\end{align} \begin{align}
 \lim_{ n \to \infty} E \left[ \left(E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}} \, \Big  | \, U  \right] \right)^2 \right]=\frac{1}{2}.
\end{align} u>0 \begin{align}
E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}} \, \Big  | \, U=u  \right] &\le  \sqrt{ E \left[   \frac{X}{n} + \frac{1}{2} \, \Big  | \, U=u  \right]}\\
&=   \sqrt{  \frac{u}{n} + \frac{1}{2} }\\
&= \sqrt{  u + \frac{1}{2}}
\end{align} \begin{align}
E \left[  \sqrt{ \frac{X}{n} + \frac{1}{2}} \, \Big  | \, U=u  \right]=  E \left[  \lim_{n \to \infty}  \sqrt{ \frac{X}{n} + \frac{1}{2}} \, \Big  | \, U=u  \right]=  \frac{1}{2}.
\end{align}","['probability', 'convergence-divergence', 'conditional-expectation', 'expected-value']"
21,Elementary proof that a binomial distribution with $p\ne \frac12$ is almost symmetric?,Elementary proof that a binomial distribution with  is almost symmetric?,p\ne \frac12,"I am looking for an elementary explanation of why a loaded coin gets more and less than the expected number of heads approximately equiprobably, in other words, mean = median . Mathematically speaking, if $X\sim B(n,p)$ is a Binomial random variable, then $P(X<np)\approx P(X>np)$ for large $n$ . When $p=\frac12$ , this is obvious because of the exact symmetry of the distribution around $\frac{n}{2}$ . For a general $0<p<1$ this follows from convergence of $X$ to the Gaussian Normal distribution. Is there an elementary intuitive explanation?","I am looking for an elementary explanation of why a loaded coin gets more and less than the expected number of heads approximately equiprobably, in other words, mean = median . Mathematically speaking, if is a Binomial random variable, then for large . When , this is obvious because of the exact symmetry of the distribution around . For a general this follows from convergence of to the Gaussian Normal distribution. Is there an elementary intuitive explanation?","X\sim B(n,p) P(X<np)\approx P(X>np) n p=\frac12 \frac{n}{2} 0<p<1 X",['probability']
22,Absolute sum of partitioned Rademacher variables,Absolute sum of partitioned Rademacher variables,,"$     \newcommand{\E}{\mathop{\mathbb{E}}}   $ Hi, this is the first time I post a question here, so I'd be glad to have comments to make it better. So here it goes. The problem I am looking to compute the Rademacher complexity of a class of function and I have reduced the problem to this. Let $\vec{\sigma} \in \{\pm 1\}^m$ be a set of $m$ Rademacher variables (i.e. taking value $\pm 1$ with probability $\frac{1}{2}$ each). Split $\vec{\sigma}$ in two consecutive sequences: sum each sequence individually, then take the absolute value of these sums before summing them together. I am looking for the split which will achieve the maximum value for this operation. More formally, we write: \begin{align} T(\vec{\sigma}) = \displaystyle\sup_{1 \leq i < m} \left( \left| \sum_{k \leq i} \sigma_k \right| + \left| \sum_{k > i} \sigma_k \right| \right). \end{align} We need to take the expectation over $\vec{\sigma}$ of this expression to obtain the Rademacher complexity: \begin{align} R_m = \E_{\vec{\sigma}} \left[ T(\vec{\sigma}) \right]. \end{align} I am looking for an analytical expression for $R_m$ . Questions Is this problem known or equivalent to another one? If yes, I'd like references. If not, is there a way to compute exactly $R_m$ ? If not, is it possible to upper bound it non-trivially? (A trivial bound would be $R_m \leq m$ .) Any insight about how to tackle the problem would be appreciated, and could be accepted as an answer if none of the above is provided. What I've tried I have computed the sum over all $\vec{\sigma}$ up to $m=12$ to find a pattern, without success. Here they are: \begin{equation} \begin{array}\\ m & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12\\ 2^m R_m & 2 & 8 & 20 & 48 & 112 & 248 & 548 & 1184 & 2540 & 5408 & 11420 & 24048 \end{array} \end{equation} This sequence is not in the OEIS, so no luck there. I have tried to express $R_m$ in terms of $R_{m-1}$ . I was not able to find a pattern there either. Finally, I have tried to express the numbers $2^m R_m$ as a sum by counting the number of $\vec{\sigma}$ for which $T(\vec{\sigma})$ would give $m$ , then how many would give $m-2$ , then $m-4$ , etc. up to $m=2$ or $1$ (if $m$ is even or odd). (It is easy to convince yourself that $m$ minus an odd number is not possible.) Mathematically speaking, we have: \begin{align} 2^m R_m = \sum_{i=0}^{\lfloor \frac{m}{2} \rfloor} a^m_i (m-2i). \end{align} I have found that: for all $m\geq 1$ , $a^m_0 = 2m$ for all $m\geq 4$ , $a^m_1 = 2m(m-3)$ for all $m\geq 7$ , $a^m_2 = m(m^2 -7m +8)$ for all even $m=2n$ , the last coefficient is $a^m_{n-1} = 2^{n+1}$ for all odd $m=2n+1$ , the last coefficient is $a^m_n = 2$ I have yet to find a general formula for $a^m_i$ , but it would be a nice starting point. Related problem I have considered the following related simpler problem \begin{align} T^0(\vec{\sigma}) = \left| \sum_{k=1}^m \sigma_k \right|, \qquad R^0_m = \E_{\vec{\sigma}} \left[ T^0(\vec{\sigma}) \right]. \end{align} We have that for all $\vec{\sigma}$ , $T^0(\vec{\sigma}) \leq T(\vec{\sigma})$ . This problem has an exact solution. We have that \begin{align} 2^m R_m = \sum_{i=0}^{\lfloor \frac{m}{2} \rfloor} 2 \binom{m}{i} (m-2i) = 2m \binom{m-1}{\lfloor \frac{m}{2} \rfloor}. \end{align} Just to give an idea, this function is upper bounded by \begin{align} 2m \binom{m-1}{\lfloor \frac{m}{2} \rfloor} \leq \sqrt{\frac{2}{\pi}} \frac{2^m m}{\sqrt{m+\frac{1}{2}}}. \end{align} Hope this can give some insights.","Hi, this is the first time I post a question here, so I'd be glad to have comments to make it better. So here it goes. The problem I am looking to compute the Rademacher complexity of a class of function and I have reduced the problem to this. Let be a set of Rademacher variables (i.e. taking value with probability each). Split in two consecutive sequences: sum each sequence individually, then take the absolute value of these sums before summing them together. I am looking for the split which will achieve the maximum value for this operation. More formally, we write: We need to take the expectation over of this expression to obtain the Rademacher complexity: I am looking for an analytical expression for . Questions Is this problem known or equivalent to another one? If yes, I'd like references. If not, is there a way to compute exactly ? If not, is it possible to upper bound it non-trivially? (A trivial bound would be .) Any insight about how to tackle the problem would be appreciated, and could be accepted as an answer if none of the above is provided. What I've tried I have computed the sum over all up to to find a pattern, without success. Here they are: This sequence is not in the OEIS, so no luck there. I have tried to express in terms of . I was not able to find a pattern there either. Finally, I have tried to express the numbers as a sum by counting the number of for which would give , then how many would give , then , etc. up to or (if is even or odd). (It is easy to convince yourself that minus an odd number is not possible.) Mathematically speaking, we have: I have found that: for all , for all , for all , for all even , the last coefficient is for all odd , the last coefficient is I have yet to find a general formula for , but it would be a nice starting point. Related problem I have considered the following related simpler problem We have that for all , . This problem has an exact solution. We have that Just to give an idea, this function is upper bounded by Hope this can give some insights.","
    \newcommand{\E}{\mathop{\mathbb{E}}}
   \vec{\sigma} \in \{\pm 1\}^m m \pm 1 \frac{1}{2} \vec{\sigma} \begin{align}
T(\vec{\sigma}) = \displaystyle\sup_{1 \leq i < m} \left( \left| \sum_{k \leq i} \sigma_k \right| + \left| \sum_{k > i} \sigma_k \right| \right).
\end{align} \vec{\sigma} \begin{align}
R_m = \E_{\vec{\sigma}} \left[ T(\vec{\sigma}) \right].
\end{align} R_m R_m R_m \leq m \vec{\sigma} m=12 \begin{equation}
\begin{array}\\
m & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12\\
2^m R_m & 2 & 8 & 20 & 48 & 112 & 248 & 548 & 1184 & 2540 & 5408 & 11420 & 24048
\end{array}
\end{equation} R_m R_{m-1} 2^m R_m \vec{\sigma} T(\vec{\sigma}) m m-2 m-4 m=2 1 m m \begin{align}
2^m R_m = \sum_{i=0}^{\lfloor \frac{m}{2} \rfloor} a^m_i (m-2i).
\end{align} m\geq 1 a^m_0 = 2m m\geq 4 a^m_1 = 2m(m-3) m\geq 7 a^m_2 = m(m^2 -7m +8) m=2n a^m_{n-1} = 2^{n+1} m=2n+1 a^m_n = 2 a^m_i \begin{align}
T^0(\vec{\sigma}) = \left| \sum_{k=1}^m \sigma_k \right|, \qquad R^0_m = \E_{\vec{\sigma}} \left[ T^0(\vec{\sigma}) \right].
\end{align} \vec{\sigma} T^0(\vec{\sigma}) \leq T(\vec{\sigma}) \begin{align}
2^m R_m = \sum_{i=0}^{\lfloor \frac{m}{2} \rfloor} 2 \binom{m}{i} (m-2i) = 2m \binom{m-1}{\lfloor \frac{m}{2} \rfloor}.
\end{align} \begin{align}
2m \binom{m-1}{\lfloor \frac{m}{2} \rfloor} \leq \sqrt{\frac{2}{\pi}} \frac{2^m m}{\sqrt{m+\frac{1}{2}}}.
\end{align}","['probability', 'combinatorics', 'machine-learning']"
23,Probabilities maximizing products,Probabilities maximizing products,,"Given is an expression of the form $P=P_1\times P_2\times\dots\times P_n$, where each $P_i$ is a sum of some distinct elements from $\{x_1,x_2,\dots,x_k\}$. (For example, $P=x_1(x_1+x_2)(x_1+x_3)$.) We want to maximize this expression subject to the constraints $x_i\geq 0$ for all $i$, and $\sum_{i=1}^k x_i=1$. Let $A$ be the value of $P_1$ at the maximum. Let $B$ be the value of $P_1$ at the maximum if we instead maximize the expression $P'=P_2\times P_3\times\dots\times P_n$, subject to the same constraints. Is it true that $A\geq \frac{n-1}{n}B+\frac{1}{n}$?","Given is an expression of the form $P=P_1\times P_2\times\dots\times P_n$, where each $P_i$ is a sum of some distinct elements from $\{x_1,x_2,\dots,x_k\}$. (For example, $P=x_1(x_1+x_2)(x_1+x_3)$.) We want to maximize this expression subject to the constraints $x_i\geq 0$ for all $i$, and $\sum_{i=1}^k x_i=1$. Let $A$ be the value of $P_1$ at the maximum. Let $B$ be the value of $P_1$ at the maximum if we instead maximize the expression $P'=P_2\times P_3\times\dots\times P_n$, subject to the same constraints. Is it true that $A\geq \frac{n-1}{n}B+\frac{1}{n}$?",,"['probability', 'inequality', 'optimization']"
24,The probability of rolling $N$ 10-sided dice and forming groups that add at least 10,The probability of rolling  10-sided dice and forming groups that add at least 10,N,"I'm trying to answer this question for an RPG game. The player (or the GM) has to roll $N$ 10-sided dice and then she has to form groups that sum at least 10 (I'll call them Raises, using the game term). As an example, if I roll 3d10 and get 10, 7 and 3, I get two Raises: {10}, {7,3}. If I roll 3d10 and get 2, 9 and 9, I get only one Raise: {2,9}. I'm interested in computing the probability of getting $R$ Raises by rolling $N$ d10, either in a closed form or recursively (I'm thinking of putting this in a script to compute the expected value for some fixed values of $N$). I'm trying to use this entry on Wolfram MathWorld to solve the problem, but I'm still stuck. Any help will be appreciated. This is by no means an assignment or a homework or a life-saving problem. I'm doing it just out of curiosity. Thank you very much in advance! Edit: to clarify, the player should choose the largest number of Raises. For example, if I roll four dice and get 4, 5, 6, 10, although {4, 5, 6, 10} is one Raise, {4, 6} and {10} (or {5, 6} and {10}) are two Raises. In this case the player should choose the second alternative.","I'm trying to answer this question for an RPG game. The player (or the GM) has to roll $N$ 10-sided dice and then she has to form groups that sum at least 10 (I'll call them Raises, using the game term). As an example, if I roll 3d10 and get 10, 7 and 3, I get two Raises: {10}, {7,3}. If I roll 3d10 and get 2, 9 and 9, I get only one Raise: {2,9}. I'm interested in computing the probability of getting $R$ Raises by rolling $N$ d10, either in a closed form or recursively (I'm thinking of putting this in a script to compute the expected value for some fixed values of $N$). I'm trying to use this entry on Wolfram MathWorld to solve the problem, but I'm still stuck. Any help will be appreciated. This is by no means an assignment or a homework or a life-saving problem. I'm doing it just out of curiosity. Thank you very much in advance! Edit: to clarify, the player should choose the largest number of Raises. For example, if I roll four dice and get 4, 5, 6, 10, although {4, 5, 6, 10} is one Raise, {4, 6} and {10} (or {5, 6} and {10}) are two Raises. In this case the player should choose the second alternative.",,"['probability', 'dice']"
25,How to get the general form of the solution of exercise 5.4-2 of CLRS as showed in wikipedia?,How to get the general form of the solution of exercise 5.4-2 of CLRS as showed in wikipedia?,,"Exercise Suppose that we toss balls into b bins until some bin contains two balls. Each toss is independent, and each ball is equally likely to end up in any bin. What is the expected number of ball tosses? Answer It seems that this is quite a simple question, and every answers I have found through Google asks me to refer to the Birthday Paradox #Average number of people . Yet the section specifically deals with the same problem, which directly tells me the final answer(the expected number) is $$1 + \sum_{k=1}^{b}\frac{b!}{(b-k)!*b^k}$$ But the thing is that I don't understand where this form is from? Is there a more detailed explanation? My thought Assume $S_k$ means after $k_{th}$ tosses, there exists two balls in one same bin. As a result, $$P(S_k) = \frac{b!*(k-1)}{(b-k+1)! * b^k} (2 \le k \le b+1)$$ Thus, the expected number is $$\sum_{k=2}^{b+1}P(S_k) * k$$ which is $$\sum_{k=2}^{b+1}\frac{b!*(k-1)*k}{(b-k+1)! * b^k}\\=\sum_{k=1}^{b}\frac{b!*k*(k+1)}{(b-k)! * b^{k+1}}$$ Considering that $$\sum_{k=2}^{b+1}P(S_k)=\sum_{k=2}^{b+1}\frac{b!*(k-1)}{(b-k+1)! * b^k}=\sum_{k=1}^{b}\frac{b!*k}{(b-k)! * b^{k+1}}=1$$ I could simplify the former expect number as $$1+\sum_{k=1}^{b}\frac{b!*k^2}{(b-k)! * b^{k+1}}$$ But this form does not seem to me the same as what shows in wiki (or at least not as simplified), even though I have checked a few small numbers(2,3) showing that they are equal (!! I have just checked these two values, I am not sure for a bigger b. So please note that they are possibly not the same ). However, I fail to understand how to simplify my form further as in wiki, or it simply uses another way to approach that answer? Any ideas?","Exercise Suppose that we toss balls into b bins until some bin contains two balls. Each toss is independent, and each ball is equally likely to end up in any bin. What is the expected number of ball tosses? Answer It seems that this is quite a simple question, and every answers I have found through Google asks me to refer to the Birthday Paradox #Average number of people . Yet the section specifically deals with the same problem, which directly tells me the final answer(the expected number) is $$1 + \sum_{k=1}^{b}\frac{b!}{(b-k)!*b^k}$$ But the thing is that I don't understand where this form is from? Is there a more detailed explanation? My thought Assume $S_k$ means after $k_{th}$ tosses, there exists two balls in one same bin. As a result, $$P(S_k) = \frac{b!*(k-1)}{(b-k+1)! * b^k} (2 \le k \le b+1)$$ Thus, the expected number is $$\sum_{k=2}^{b+1}P(S_k) * k$$ which is $$\sum_{k=2}^{b+1}\frac{b!*(k-1)*k}{(b-k+1)! * b^k}\\=\sum_{k=1}^{b}\frac{b!*k*(k+1)}{(b-k)! * b^{k+1}}$$ Considering that $$\sum_{k=2}^{b+1}P(S_k)=\sum_{k=2}^{b+1}\frac{b!*(k-1)}{(b-k+1)! * b^k}=\sum_{k=1}^{b}\frac{b!*k}{(b-k)! * b^{k+1}}=1$$ I could simplify the former expect number as $$1+\sum_{k=1}^{b}\frac{b!*k^2}{(b-k)! * b^{k+1}}$$ But this form does not seem to me the same as what shows in wiki (or at least not as simplified), even though I have checked a few small numbers(2,3) showing that they are equal (!! I have just checked these two values, I am not sure for a bigger b. So please note that they are possibly not the same ). However, I fail to understand how to simplify my form further as in wiki, or it simply uses another way to approach that answer? Any ideas?",,"['probability', 'statistics', 'balls-in-bins']"
26,Going Through Yellows,Going Through Yellows,,"I have observed that I am almost never the last car through a traffic light. Sometimes I stop (because it is yellow or red), in which case, of course, the car behind me also stops and the car in front of me proves the last car through. And sometimes I go (because it is green or yellow), in which case, usually, the car behind me follows me through. I long felt that this showed that I am more likely (than other people) to stop at a light; I am relatively cautious. Otherwise, why should I rarely be last through? But this conclusion came with a guilty conscience. Because it seemed obvious that I couldn’t know, from my own experience alone, whether other drivers felt the same way about themselves, apparently making me typical after all. I’m re-thinking that guilt, and this is to ask your help. On the one hand, if I observe that I’m late to work 5% of the time, this gives me no information about whether I’m late to work more often that the average person or less often. For that conclusion, I would need to gather data about other people. But on the other hand, suppose that I observe that in the last 50 cases in which I reached a yellow light, in 40 cases I stopped, in 9 cases I went through followed by another car, and in 1 case I went through alone. I see that I have stopped in (40/50)=80% of the cases while the fellow behind me stopped in only (1/10)=10% of cases. (I think that I'm here ignoring the fact that the driver behind me is reaching this yellow light later than I did, increasing his probability of stopping. Should I?) Is there some sort of problem of independence here, such that the people behind me when I go through do not represent all drivers? I realize that if the numbers 9 and 1 were switched -- so that I stopped in (40/50)=80% of cases, I went through alone in 9 cases, and I went through followed by a car in 1 case -- we could not make the opposite inference that I am relatively reckless – could we? Because of the complicated problem of dealing with instances in which I go but there is simply no car behind me, stopping or proceeding? Or for some other reason? Is there some standard nomenclature for the issue I'm raising, distinguishing the late-to-work analysis from the traffic-light analysis?","I have observed that I am almost never the last car through a traffic light. Sometimes I stop (because it is yellow or red), in which case, of course, the car behind me also stops and the car in front of me proves the last car through. And sometimes I go (because it is green or yellow), in which case, usually, the car behind me follows me through. I long felt that this showed that I am more likely (than other people) to stop at a light; I am relatively cautious. Otherwise, why should I rarely be last through? But this conclusion came with a guilty conscience. Because it seemed obvious that I couldn’t know, from my own experience alone, whether other drivers felt the same way about themselves, apparently making me typical after all. I’m re-thinking that guilt, and this is to ask your help. On the one hand, if I observe that I’m late to work 5% of the time, this gives me no information about whether I’m late to work more often that the average person or less often. For that conclusion, I would need to gather data about other people. But on the other hand, suppose that I observe that in the last 50 cases in which I reached a yellow light, in 40 cases I stopped, in 9 cases I went through followed by another car, and in 1 case I went through alone. I see that I have stopped in (40/50)=80% of the cases while the fellow behind me stopped in only (1/10)=10% of cases. (I think that I'm here ignoring the fact that the driver behind me is reaching this yellow light later than I did, increasing his probability of stopping. Should I?) Is there some sort of problem of independence here, such that the people behind me when I go through do not represent all drivers? I realize that if the numbers 9 and 1 were switched -- so that I stopped in (40/50)=80% of cases, I went through alone in 9 cases, and I went through followed by a car in 1 case -- we could not make the opposite inference that I am relatively reckless – could we? Because of the complicated problem of dealing with instances in which I go but there is simply no car behind me, stopping or proceeding? Or for some other reason? Is there some standard nomenclature for the issue I'm raising, distinguishing the late-to-work analysis from the traffic-light analysis?",,"['probability', 'statistical-inference']"
27,Implications of inequalities,Implications of inequalities,,"For $i=1,2,3$, consider a random variable $Y_i$ taking value in  $$ \mathcal{Y}:=\{(1,1), (1,0), (0,1), (0,0)\} $$ and a random closed set $S_i$ taking value in $\mathcal{S}$ that is the power set of $\mathcal{Y}$ (without the empty set), i.e. $$ \mathcal{S}:=\{\{(1,1)\}, \{(1,0)\}, \{(0,1)\}, \{(0,0)\},\\ \{(1,1), (1,0)\}, \{(1,1), (0,1)\}, \{(1,1), (0,0)\}, \{(1,0), (0,1)\}, \{(1,0), (0,0)\}, \{(0,1), (0,0)\},\\ \{(1,1), (1,0), (0,1)\}, \{(1,1), (1,0), (0,0)\}, \{(1,1), (0,1), (0,0)\}, \{(1,0), (0,1), (0,0)\},\\ \{(1,1), (1,0), (0,1), (0,0)\}\} $$ $Y_i,S_i$ are defined on the same probability space $(\Omega, \mathcal{F}, P)$. Also, $Y_1, Y_2, Y_3$ are independent, $S_1, S_2, S_3$ are independent. Suppose that $$ P(Y_i\in K)\leq P(S_i\cap K\neq \emptyset) \text{ } \forall K \in \mathcal{S} \text{ for } i=1,2,3 $$ For example, for $K=\{(1,1), (0,1)\}$ and $i=1$ $$ P(Y_1=(1,1))+P(Y_1=(0,1))\leq \\ P(S_1=\{(1,1)\})+P(S_1=\{(0,1)\})\\+P(S_1=\{(1,1), (1,0)\})+P(S_1= \{(1,1), (0,1)\})\\+P(S_1=\{(1,1), (0,0)\})+P(S_1=\{(1,0), (0,1)\})+P(S_1=\{(0,1), (0,0)\})\\+P(S_1= \{(1,1), (1,0), (0,1)\})+P(S_1=\{(1,1), (1,0), (0,0)\})\\+P(S_1= \{(1,1), (0,1), (0,0)\})+P(S_1= \{(1,0), (0,1), (0,0)\})\\+P(S_1= \{(1,1), (1,0), (0,1), (0,0)\}) $$ I would like your help to show that $$ (\star) \hspace{1cm} P(Y_1=(1,1))\times P(Y_2=(1,1))\times P(Y_3=(1,1)) +\\P(Y_1=(0,0))\times P(Y_2=(0,0))\times P(Y_3=(0,0))\leq\\  P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}\neq \emptyset \text{ OR }\\  S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}\neq \emptyset) $$ My attempt (A) I take the inequalities referred to $K=\{(1,1), (0,0)\}$ for $i=1,2,3$ and multiply them across $i$:  $$ [P(Y_1=(1,1))+P(Y_1=(0,0))]\times [P(Y_2=(1,1))+P(Y_2=(0,0))]\times [P(Y_3=(1,1))+P(Y_3=(0,0))]\leq\\ [P(S_1\cap \{(1,1),(0,0)\}\neq \emptyset)]\times [P(S_2\cap \{(1,1),(0,0)\}\neq \emptyset)]\times [P(S_3\cap \{(1,1),(0,0)\}\neq \emptyset)] $$ (B) On the lhs the terms ""in excess"" with respect to $(\star)$ are $$ P(Y_1=(1,1))\times P(Y_2=(0,0))\times P(Y_3=(0,0))+\\ P(Y_1=(0,0))\times P(Y_2=(1,1))\times P(Y_3=(0,0))+\\ P(Y_1=(0,0))\times P(Y_2=(0,0))\times P(Y_3=(1,1))+\\ P(Y_1=(1,1))\times P(Y_2=(1,1))\times P(Y_3=(0,0))+\\ P(Y_1=(1,1))\times P(Y_2=(0,0))\times P(Y_3=(1,1))+\\ P(Y_1=(0,0))\times P(Y_2=(1,1))\times P(Y_3=(1,1)) $$ (C) On the rhs the terms ""in excess"" with respect to $(\star)$ are $$ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}\neq\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}\neq\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}\neq \emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}\neq \emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}= \emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}\neq\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}= \emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}\neq\emptyset) $$ (D) One strategy could be to show that (B) $\geq $ (C), and, hence, because of (A), $(\star)$ holds. However, I am unable to do it. (E) What I have shown, instead, is that $$ 1-P(Y_1=(0,0))=P(Y_1=(1,1))+P(Y_1=(1,0))+P(Y_1=(0,1))\geq\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset) $$ and $$ P(Y_1=(1,1))\geq P(S_1=\{(1,1)\}) $$ and $$ P(Y_1=(1,1))+P(Y_1=(0,0))\geq P(S_1\cap\{(1,1)\}\neq \emptyset \text{ and } S_1\cap\{(0,0)\}\neq \emptyset\}) $$ and $$ P(Y_1=(1,1))+P(Y_1=(0,0))\geq P(S_1\cap\{(0,1),(1,0)\}=\emptyset) $$ which, however, do not seem to be useful.","For $i=1,2,3$, consider a random variable $Y_i$ taking value in  $$ \mathcal{Y}:=\{(1,1), (1,0), (0,1), (0,0)\} $$ and a random closed set $S_i$ taking value in $\mathcal{S}$ that is the power set of $\mathcal{Y}$ (without the empty set), i.e. $$ \mathcal{S}:=\{\{(1,1)\}, \{(1,0)\}, \{(0,1)\}, \{(0,0)\},\\ \{(1,1), (1,0)\}, \{(1,1), (0,1)\}, \{(1,1), (0,0)\}, \{(1,0), (0,1)\}, \{(1,0), (0,0)\}, \{(0,1), (0,0)\},\\ \{(1,1), (1,0), (0,1)\}, \{(1,1), (1,0), (0,0)\}, \{(1,1), (0,1), (0,0)\}, \{(1,0), (0,1), (0,0)\},\\ \{(1,1), (1,0), (0,1), (0,0)\}\} $$ $Y_i,S_i$ are defined on the same probability space $(\Omega, \mathcal{F}, P)$. Also, $Y_1, Y_2, Y_3$ are independent, $S_1, S_2, S_3$ are independent. Suppose that $$ P(Y_i\in K)\leq P(S_i\cap K\neq \emptyset) \text{ } \forall K \in \mathcal{S} \text{ for } i=1,2,3 $$ For example, for $K=\{(1,1), (0,1)\}$ and $i=1$ $$ P(Y_1=(1,1))+P(Y_1=(0,1))\leq \\ P(S_1=\{(1,1)\})+P(S_1=\{(0,1)\})\\+P(S_1=\{(1,1), (1,0)\})+P(S_1= \{(1,1), (0,1)\})\\+P(S_1=\{(1,1), (0,0)\})+P(S_1=\{(1,0), (0,1)\})+P(S_1=\{(0,1), (0,0)\})\\+P(S_1= \{(1,1), (1,0), (0,1)\})+P(S_1=\{(1,1), (1,0), (0,0)\})\\+P(S_1= \{(1,1), (0,1), (0,0)\})+P(S_1= \{(1,0), (0,1), (0,0)\})\\+P(S_1= \{(1,1), (1,0), (0,1), (0,0)\}) $$ I would like your help to show that $$ (\star) \hspace{1cm} P(Y_1=(1,1))\times P(Y_2=(1,1))\times P(Y_3=(1,1)) +\\P(Y_1=(0,0))\times P(Y_2=(0,0))\times P(Y_3=(0,0))\leq\\  P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}\neq \emptyset \text{ OR }\\  S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}\neq \emptyset) $$ My attempt (A) I take the inequalities referred to $K=\{(1,1), (0,0)\}$ for $i=1,2,3$ and multiply them across $i$:  $$ [P(Y_1=(1,1))+P(Y_1=(0,0))]\times [P(Y_2=(1,1))+P(Y_2=(0,0))]\times [P(Y_3=(1,1))+P(Y_3=(0,0))]\leq\\ [P(S_1\cap \{(1,1),(0,0)\}\neq \emptyset)]\times [P(S_2\cap \{(1,1),(0,0)\}\neq \emptyset)]\times [P(S_3\cap \{(1,1),(0,0)\}\neq \emptyset)] $$ (B) On the lhs the terms ""in excess"" with respect to $(\star)$ are $$ P(Y_1=(1,1))\times P(Y_2=(0,0))\times P(Y_3=(0,0))+\\ P(Y_1=(0,0))\times P(Y_2=(1,1))\times P(Y_3=(0,0))+\\ P(Y_1=(0,0))\times P(Y_2=(0,0))\times P(Y_3=(1,1))+\\ P(Y_1=(1,1))\times P(Y_2=(1,1))\times P(Y_3=(0,0))+\\ P(Y_1=(1,1))\times P(Y_2=(0,0))\times P(Y_3=(1,1))+\\ P(Y_1=(0,0))\times P(Y_2=(1,1))\times P(Y_3=(1,1)) $$ (C) On the rhs the terms ""in excess"" with respect to $(\star)$ are $$ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}\neq\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}=\emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}\neq\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}=\emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}\neq \emptyset)\times P(S_3\cap \{(0,0)\}\neq \emptyset \text{ and } S_3\cap \{(1,1)\}=\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}\neq \emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}=\emptyset)+\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset)\times P(S_2\cap \{(0,0)\}\neq \emptyset \text{ and } S_2\cap \{(1,1)\}= \emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}\neq\emptyset)+\\ P(S_1\cap \{(0,0)\}\neq \emptyset \text{ and } S_1\cap \{(1,1)\}=\emptyset)\times P(S_2\cap \{(1,1)\}\neq \emptyset \text{ and } S_2\cap \{(0,0)\}= \emptyset)\times P(S_3\cap \{(1,1)\}\neq \emptyset \text{ and } S_3\cap \{(0,0)\}\neq\emptyset) $$ (D) One strategy could be to show that (B) $\geq $ (C), and, hence, because of (A), $(\star)$ holds. However, I am unable to do it. (E) What I have shown, instead, is that $$ 1-P(Y_1=(0,0))=P(Y_1=(1,1))+P(Y_1=(1,0))+P(Y_1=(0,1))\geq\\ P(S_1\cap \{(1,1)\}\neq \emptyset \text{ and } S_1\cap \{(0,0)\}=\emptyset) $$ and $$ P(Y_1=(1,1))\geq P(S_1=\{(1,1)\}) $$ and $$ P(Y_1=(1,1))+P(Y_1=(0,0))\geq P(S_1\cap\{(1,1)\}\neq \emptyset \text{ and } S_1\cap\{(0,0)\}\neq \emptyset\}) $$ and $$ P(Y_1=(1,1))+P(Y_1=(0,0))\geq P(S_1\cap\{(0,1),(1,0)\}=\emptyset) $$ which, however, do not seem to be useful.",,"['probability', 'inequality']"
28,Expectation of maximum of minimums of permutations,Expectation of maximum of minimums of permutations,,"Assume $n$ random permutations $\pi_1,\pi_2,\ldots,\pi_n: \lbrace 1,2,\ldots,m \rbrace \rightarrow \lbrace 1,2,\ldots,m \rbrace$. Let $X_i = \min(\pi_1(i),\pi_2(i),\ldots,\pi_n(i))$ and $Y = \max(X_1, X_2, \ldots, X_m)$. What is the expectation of $Y$, $E(Y)$, as function of $n$? An upper bound approximation for $E(Y)$ would also be very helpful. Obviously,  we have $E(Y)=m$ for $n=1$ and $E(Y)=1$ for $n\rightarrow\infty$. I know that the distribution of $X_i$ is given by  $P(X_i\leq k) = 1 - \left(1-\frac{k}{m}\right)^n$. However, since $X_1,X_2,\ldots,X_m$ are not independent, it is not possible to get the distribution of $Y$ by $P(Y \leq k) = P(X_1 \leq k \wedge X_2 \leq k \wedge \ldots \wedge X_m\leq k) \neq P(X_1 \leq k)  \cdot P(X_2 \leq k)  \cdot\ldots \cdot P(X_m \leq k)$.","Assume $n$ random permutations $\pi_1,\pi_2,\ldots,\pi_n: \lbrace 1,2,\ldots,m \rbrace \rightarrow \lbrace 1,2,\ldots,m \rbrace$. Let $X_i = \min(\pi_1(i),\pi_2(i),\ldots,\pi_n(i))$ and $Y = \max(X_1, X_2, \ldots, X_m)$. What is the expectation of $Y$, $E(Y)$, as function of $n$? An upper bound approximation for $E(Y)$ would also be very helpful. Obviously,  we have $E(Y)=m$ for $n=1$ and $E(Y)=1$ for $n\rightarrow\infty$. I know that the distribution of $X_i$ is given by  $P(X_i\leq k) = 1 - \left(1-\frac{k}{m}\right)^n$. However, since $X_1,X_2,\ldots,X_m$ are not independent, it is not possible to get the distribution of $Y$ by $P(Y \leq k) = P(X_1 \leq k \wedge X_2 \leq k \wedge \ldots \wedge X_m\leq k) \neq P(X_1 \leq k)  \cdot P(X_2 \leq k)  \cdot\ldots \cdot P(X_m \leq k)$.",,"['probability', 'statistics', 'permutations']"
29,Events A and B are independent such that $P(A)=6P(B)$,Events A and B are independent such that,P(A)=6P(B),"Events A and B are independent such that $P(A)=6P(B)$ and $P(A \cup B) =0.915.$ Find P(B). I know that $P(A \cup B)= P(A) + P(B) -P(A)P(B)$ Then $0.915=6P(B)+P(B)-6P(B)P(B)  \\  \rightarrow 0.915=7P(B)-6P(B)^2$. $-6P(B)^2+7P(B)-0.915=0$ Letting $a=-6, b=7, \& c=-0.915$ I can use the quadratic formula: $\frac{-b \pm \sqrt{b^2-4ac}}{2a}.$ Which gives me the roots of $1.0166..$ and $0.15$, since the $P(B) < 1$ then $P(B)$ is $0.15?$ Am I taking this the correct direction?","Events A and B are independent such that $P(A)=6P(B)$ and $P(A \cup B) =0.915.$ Find P(B). I know that $P(A \cup B)= P(A) + P(B) -P(A)P(B)$ Then $0.915=6P(B)+P(B)-6P(B)P(B)  \\  \rightarrow 0.915=7P(B)-6P(B)^2$. $-6P(B)^2+7P(B)-0.915=0$ Letting $a=-6, b=7, \& c=-0.915$ I can use the quadratic formula: $\frac{-b \pm \sqrt{b^2-4ac}}{2a}.$ Which gives me the roots of $1.0166..$ and $0.15$, since the $P(B) < 1$ then $P(B)$ is $0.15?$ Am I taking this the correct direction?",,['probability']
30,Intuition behind why the expected time of first return is infinite for symmetric random walk?,Intuition behind why the expected time of first return is infinite for symmetric random walk?,,"The generating function is $F_0(s) = \sum_{n=1}^{\infty}f_0(n)s^n$. $f_0(n)$ is the probability of ""first"" return after n steps. If the particle is certain to return to origin, i.e. $F_0(1) = \sum_{n=1}^{\infty}f_0(n) = 1$ So the expected time is infinity. $F_0^{'}(1) = \sum_{n=1}^{\infty}nf_0(n) = \infty$ However, I lack the intuition why it is infinity but not finite number. I understand for nonsymmetric it is infinity, but wonder what is the intuition that for symmetric it is also infinity.","The generating function is $F_0(s) = \sum_{n=1}^{\infty}f_0(n)s^n$. $f_0(n)$ is the probability of ""first"" return after n steps. If the particle is certain to return to origin, i.e. $F_0(1) = \sum_{n=1}^{\infty}f_0(n) = 1$ So the expected time is infinity. $F_0^{'}(1) = \sum_{n=1}^{\infty}nf_0(n) = \infty$ However, I lack the intuition why it is infinity but not finite number. I understand for nonsymmetric it is infinity, but wonder what is the intuition that for symmetric it is also infinity.",,"['probability', 'probability-theory']"
31,Maximum Elo Rating.,Maximum Elo Rating.,,"I'm trying to implement a variant of the Elo system, for a game I'm working on.  Giving two players $A$ and $B$ with ratings $R_A$ and $R_B$ respectively, the expectation of $A; E_A$ is given by the formula: $$E_A = \frac{1}{1+10^{\frac{R_B-R_A}{Y}}}\tag{*}$$ The expectation of $B$ is similarly given by: $$E_B = \frac{1}{1+10^{\frac{R_A-R_B}{Y}}}$$ The different possible game outcomes are given scores: A win is $1.0$, a loss is: $0.0$, and a draw is $0.5$. The actual score of $A$ is $S_A$. After a match between $A$ and $B$, the new ranking of $A; R'_A$ is given by:  $$R'_A = R_A + K(S_A - E_A)$$ Question: Given a sample with a population size of $n$ in which each player reveives an initial rating of $c$. Assuming that the players actively cooperate, what's the maximum possible rating that one player can receive? A simpler question is: Is it possible to increase the rating of all players in the sample? I think the answer is 'No' (since the rating gain of each player is deducted from another player). However if it was 'Yes' then there would be no limit, since by induction it will be possible to prove that if a strategy to increase all player's rankings from $c$ to $g \{g: c \lt g\}$ existed, then same strategy could be used to improve all rankings from $a$ to $b$ $\{a,b: g \le a \lt b\}$ and there would be no maximum value. My system doesn't implement the concept of floors or ceilings. $K$ is constant throughout all rankings.  The maximum possible ranking is trivially $\le n\cdot c$, but I want a better upper bound. (As @Sil points down below: $R'_A+R'_B = R_A+R_B$ (since $S_A+S_B=1$ and $E_A+E_B=1$), so the overall ELO sum should remain the same after match as it was before it. $\tag{**}$ The overall ELO sum in this case being: $n \cdot c$ As for a lower bound for max rankings, I'm thinking of a binary search: $n/2$ people win the first $n$ matches. Their new rating will be calculated as  $$R' = R + K(1-0.5)$$ $$R' = R + .5K$$ The set will be reduced to $n/2$, and this will continue till set $= 1$. The number of matches $m$ played this way wilk be approx $\lg n$. Max ranking through this method, will be: $$c + \frac{K}{2}\cdot \lg n$$ While that provides a lower bound, thus is one scenario in which I think a binary search is suboptimal in increasing rankings. I think increasing average ratings, may work, but I'm not sure. I would appreciate an answer where the maximum rating is given as a function of $K, c \& n$. I'm currently using $K = \sqrt{Y}$ $(*)$ Most chess Elo algorithms use a value of $Y = 400$ $(**)$ By this argument, it is possible to prove that $\not\exists$ a strategy to increase ratings of all players. It isalso possible to prove that it is impossible to improve average player rankings. (The average rating will always remain $1000$)","I'm trying to implement a variant of the Elo system, for a game I'm working on.  Giving two players $A$ and $B$ with ratings $R_A$ and $R_B$ respectively, the expectation of $A; E_A$ is given by the formula: $$E_A = \frac{1}{1+10^{\frac{R_B-R_A}{Y}}}\tag{*}$$ The expectation of $B$ is similarly given by: $$E_B = \frac{1}{1+10^{\frac{R_A-R_B}{Y}}}$$ The different possible game outcomes are given scores: A win is $1.0$, a loss is: $0.0$, and a draw is $0.5$. The actual score of $A$ is $S_A$. After a match between $A$ and $B$, the new ranking of $A; R'_A$ is given by:  $$R'_A = R_A + K(S_A - E_A)$$ Question: Given a sample with a population size of $n$ in which each player reveives an initial rating of $c$. Assuming that the players actively cooperate, what's the maximum possible rating that one player can receive? A simpler question is: Is it possible to increase the rating of all players in the sample? I think the answer is 'No' (since the rating gain of each player is deducted from another player). However if it was 'Yes' then there would be no limit, since by induction it will be possible to prove that if a strategy to increase all player's rankings from $c$ to $g \{g: c \lt g\}$ existed, then same strategy could be used to improve all rankings from $a$ to $b$ $\{a,b: g \le a \lt b\}$ and there would be no maximum value. My system doesn't implement the concept of floors or ceilings. $K$ is constant throughout all rankings.  The maximum possible ranking is trivially $\le n\cdot c$, but I want a better upper bound. (As @Sil points down below: $R'_A+R'_B = R_A+R_B$ (since $S_A+S_B=1$ and $E_A+E_B=1$), so the overall ELO sum should remain the same after match as it was before it. $\tag{**}$ The overall ELO sum in this case being: $n \cdot c$ As for a lower bound for max rankings, I'm thinking of a binary search: $n/2$ people win the first $n$ matches. Their new rating will be calculated as  $$R' = R + K(1-0.5)$$ $$R' = R + .5K$$ The set will be reduced to $n/2$, and this will continue till set $= 1$. The number of matches $m$ played this way wilk be approx $\lg n$. Max ranking through this method, will be: $$c + \frac{K}{2}\cdot \lg n$$ While that provides a lower bound, thus is one scenario in which I think a binary search is suboptimal in increasing rankings. I think increasing average ratings, may work, but I'm not sure. I would appreciate an answer where the maximum rating is given as a function of $K, c \& n$. I'm currently using $K = \sqrt{Y}$ $(*)$ Most chess Elo algorithms use a value of $Y = 400$ $(**)$ By this argument, it is possible to prove that $\not\exists$ a strategy to increase ratings of all players. It isalso possible to prove that it is impossible to improve average player rankings. (The average rating will always remain $1000$)",,"['probability', 'functions', 'probability-distributions']"
32,"Supposing joint normality, is a pair of asymptotically uncorrelated sequences also asymptotically independent?","Supposing joint normality, is a pair of asymptotically uncorrelated sequences also asymptotically independent?",,"Let's say there are two sequences of random variables $(X_n, Y_n)$ and we know that For each $n$, $(X_n, Y_n)$ is normally distributed. $\mathrm{cov}(X_n, Y_n) \rightarrow 0$ as $n \rightarrow \infty$. I am wondering if we can conclude that $X_n$ and $Y_n$ are asymptotically independent (maybe not?), that is, for any Borel sets $A$ and $B$, $$ \mathbb{P}(X_n \in A, Y_n \in B) - \mathbb{P}(X_n \in A)\mathbb{P}(Y_n \in B) \longrightarrow 0,\text{  as } n \rightarrow \infty $$ By the two conditions, we know that for any $\theta_1$, $\theta_2$, $$ \mathbb{E}[e^{i(\theta_1 X_n + \theta_2 Y_n)}]-\mathbb{E}[e^{i\theta_1 X_n}]\mathbb{E}[e^{i\theta_2 Y_n}] \longrightarrow 0 $$ Then it seems we might deduce that for any periodic and bounded functions $\phi$ and $\varphi$,  $$ \mathbb{E}[\varphi(X_n)\phi(Y_n)]-\mathbb{E}[\varphi(X_n)]\mathbb{E}[\phi(Y_n)] \longrightarrow 0 $$ But I have no idea if we can proceed to further replace $\varphi$ and $\phi$ with indicator functions (or functions in $C_0$ space?).. Any hint will be appreciated :-)","Let's say there are two sequences of random variables $(X_n, Y_n)$ and we know that For each $n$, $(X_n, Y_n)$ is normally distributed. $\mathrm{cov}(X_n, Y_n) \rightarrow 0$ as $n \rightarrow \infty$. I am wondering if we can conclude that $X_n$ and $Y_n$ are asymptotically independent (maybe not?), that is, for any Borel sets $A$ and $B$, $$ \mathbb{P}(X_n \in A, Y_n \in B) - \mathbb{P}(X_n \in A)\mathbb{P}(Y_n \in B) \longrightarrow 0,\text{  as } n \rightarrow \infty $$ By the two conditions, we know that for any $\theta_1$, $\theta_2$, $$ \mathbb{E}[e^{i(\theta_1 X_n + \theta_2 Y_n)}]-\mathbb{E}[e^{i\theta_1 X_n}]\mathbb{E}[e^{i\theta_2 Y_n}] \longrightarrow 0 $$ Then it seems we might deduce that for any periodic and bounded functions $\phi$ and $\varphi$,  $$ \mathbb{E}[\varphi(X_n)\phi(Y_n)]-\mathbb{E}[\varphi(X_n)]\mathbb{E}[\phi(Y_n)] \longrightarrow 0 $$ But I have no idea if we can proceed to further replace $\varphi$ and $\phi$ with indicator functions (or functions in $C_0$ space?).. Any hint will be appreciated :-)",,"['probability', 'probability-theory', 'measure-theory']"
33,Geometric distribution obtained from exponential distribution,Geometric distribution obtained from exponential distribution,,"I was trying to solve the following: Let $\lambda>0$ and $X$ a random variable with $X \sim exp(\lambda)$. Show that $Y=[X]+1$ has geometric distribution of parameter $p=1-e^{-\lambda}$, where $[x]$ denotes the integer part of a number. I did the following: $$P(Y=n)=P([X]+1=n)$$$$=P(n-1 \leq X <n)$$$$=F_X(n)-F_X(n-1)$$$$=1-e^{-\lambda n}-(1-e^{-\lambda (n-1)})$$$$=e^{-\lambda (n-1)}-e^{-\lambda n}$$$$=e^{-\lambda (n-1)}(1-e^{-\lambda})$$ If I call $p=1-e^{-\lambda}$, then we have $$P(Y=n)=(1-p)^{n-1}p$$ which is exactly the density function of a geometric random variable with parameter $p=1-e^{-\lambda}$. I was having doubts with my solution, could anyone tell me if my answer is correct?","I was trying to solve the following: Let $\lambda>0$ and $X$ a random variable with $X \sim exp(\lambda)$. Show that $Y=[X]+1$ has geometric distribution of parameter $p=1-e^{-\lambda}$, where $[x]$ denotes the integer part of a number. I did the following: $$P(Y=n)=P([X]+1=n)$$$$=P(n-1 \leq X <n)$$$$=F_X(n)-F_X(n-1)$$$$=1-e^{-\lambda n}-(1-e^{-\lambda (n-1)})$$$$=e^{-\lambda (n-1)}-e^{-\lambda n}$$$$=e^{-\lambda (n-1)}(1-e^{-\lambda})$$ If I call $p=1-e^{-\lambda}$, then we have $$P(Y=n)=(1-p)^{n-1}p$$ which is exactly the density function of a geometric random variable with parameter $p=1-e^{-\lambda}$. I was having doubts with my solution, could anyone tell me if my answer is correct?",,"['probability', 'probability-distributions']"
34,Probability of a minesweeper grid being solvable,Probability of a minesweeper grid being solvable,,"Suppose we have an $m\times n$ minesweeper grid containing $k$ mines (for example the beginner grid is $8\times 8$ with $10$ mines). I have the following related questions: What is the probability of solving the grid if we play optimally? What is the probability of being able to solve the grid without guessing , if we are given that the first click reveals an opening? What is the expected number of mines that would be hit if we had infinite lives, if again we were to play optimally? I don't hold out much hope for an exact formula for any of these, but any kind of approximation or bound would be good. How would we approach such problems? I am aware of the option of using a customized minesweeper solver to play many games and get approximate answers via this method, and may well try this one day, but for now I am interested in the mathematical approach. Perhaps a reasonable simplification would be to treat the grid as infinite with a mine density of $\rho$ (normally $\rho\approx 0.2$) and attempt to calculate the above problems for an area of cells (not necessarily in a rectangle?). It's simple for very small grids or numbers of mines, or when $k\approx m\times n$, but I would like to get a rough idea for the standard difficulty levels which are: Beginner $8\times 8$ with $10$ mines; Intermediate $16\times 16$ with $40$ mines; Expert $16\times 30$ with $99$ mines.","Suppose we have an $m\times n$ minesweeper grid containing $k$ mines (for example the beginner grid is $8\times 8$ with $10$ mines). I have the following related questions: What is the probability of solving the grid if we play optimally? What is the probability of being able to solve the grid without guessing , if we are given that the first click reveals an opening? What is the expected number of mines that would be hit if we had infinite lives, if again we were to play optimally? I don't hold out much hope for an exact formula for any of these, but any kind of approximation or bound would be good. How would we approach such problems? I am aware of the option of using a customized minesweeper solver to play many games and get approximate answers via this method, and may well try this one day, but for now I am interested in the mathematical approach. Perhaps a reasonable simplification would be to treat the grid as infinite with a mine density of $\rho$ (normally $\rho\approx 0.2$) and attempt to calculate the above problems for an area of cells (not necessarily in a rectangle?). It's simple for very small grids or numbers of mines, or when $k\approx m\times n$, but I would like to get a rough idea for the standard difficulty levels which are: Beginner $8\times 8$ with $10$ mines; Intermediate $16\times 16$ with $40$ mines; Expert $16\times 30$ with $99$ mines.",,"['probability', 'recreational-mathematics']"
35,Probability of an Indisputable winner at Texas Holdem,Probability of an Indisputable winner at Texas Holdem,,"What are the fraction of hands that can be classified as ""indisputable winners"" (aka ""the nuts"") after the river is revealed in Texas Holdem? By ""hand"" I mean the 2 hole cards you have that no one else can see plus the 5 cards on the table. An indisputable winner is a hand that cannot lose.  A clear example would be: you are holding the A,K of spades, and the Q,J,10 of spades are on the table.  No one can beat you, no matter what they are holding.  For clarity, there are ${47 \choose 2}$ hands that meet this exact criteria in each suit. A hand that could be tied would be: you are holding A,K, the table has Q,J,10,7,2, with all four suits represented.  No one can get better than a straight, and you have the best possible straight.  Others could tie you, but you cannot lose.  These are also considered ""indisputable winners"" as there is no risk to betting. Bonus Question: Of the hands that qualify as indisputable, what are the distributions of types of winners?  Straight-flush vs. 4-of-a-kind vs. full-house vs. flush vs. straight vs. 3-of-a-kind. I'll take estimates if the exact calculations are too complex.","What are the fraction of hands that can be classified as ""indisputable winners"" (aka ""the nuts"") after the river is revealed in Texas Holdem? By ""hand"" I mean the 2 hole cards you have that no one else can see plus the 5 cards on the table. An indisputable winner is a hand that cannot lose.  A clear example would be: you are holding the A,K of spades, and the Q,J,10 of spades are on the table.  No one can beat you, no matter what they are holding.  For clarity, there are ${47 \choose 2}$ hands that meet this exact criteria in each suit. A hand that could be tied would be: you are holding A,K, the table has Q,J,10,7,2, with all four suits represented.  No one can get better than a straight, and you have the best possible straight.  Others could tie you, but you cannot lose.  These are also considered ""indisputable winners"" as there is no risk to betting. Bonus Question: Of the hands that qualify as indisputable, what are the distributions of types of winners?  Straight-flush vs. 4-of-a-kind vs. full-house vs. flush vs. straight vs. 3-of-a-kind. I'll take estimates if the exact calculations are too complex.",,"['probability', 'poker']"
36,Normalizing factor for product of Gaussian densities - interpretation with Bayes theorem,Normalizing factor for product of Gaussian densities - interpretation with Bayes theorem,,"The normalizing factor for the product of two multivariate Gaussian densities, $f(x)$ and $g(x)$ with mean vectors $a$ and $b$ respectively, and covariance matrices $A$ and $B$ respectively, is itself a Gaussian with exponent: $-0.5(a-b)^T(A+B)^{-1}(a-b)$ i.e. the normalizing factor $c$ is: $c=\cfrac{1}{\sqrt{2\pi\begin{vmatrix}A+B\end{vmatrix}}}e^{-\cfrac{1}{2}(a-b)^T(A+B)^{-1}(a-b)}$ At first sight, I'd hence interpret the normalizing factor as the value of a (hypothetical) density function with mean $b$ and covariance matrix $A+B$, evaluated at $a$. Consider now an example, where $f(x)$ and $g(x)$ represent densities of two different statisticians' estimates for $x$. Statistician $A$ whose estimate has density $f(x)$ decides to update his estimate, after he saw the estimate for $x$ from the other statistician, named $B$: $x_b$. $A's$ new estimate, i.e. an estimate conditional on $x_b$ has the density: $f(x_a|x_b)$. Now $B$ would in turn use $A's$ initial estimate to update her own estimate. The new estimate of $B$, conditional on the estimate of $A$ would have the density: $g(x_b|x_a)$. Applying the Bayes rule for densities: $g(x_b|x_a)=\cfrac{f(x_a|x_b)g(x_b)}{f(x_a)}$ So here, the normalizing factor is (also) $f(x_a)$ the unconditional (marginal) density of $x_a$. Unfortunately, I cannot see the link between $-0.5(a-b)^T(A+B)^{-1}(a-b)$ and that marginal density.  What am I missing? P.S.:  how to derive the expression above is indicated in the answer to the question given here: Product of two multivariate Gaussian pdfs - normalizing constant - where online references are given as well.","The normalizing factor for the product of two multivariate Gaussian densities, $f(x)$ and $g(x)$ with mean vectors $a$ and $b$ respectively, and covariance matrices $A$ and $B$ respectively, is itself a Gaussian with exponent: $-0.5(a-b)^T(A+B)^{-1}(a-b)$ i.e. the normalizing factor $c$ is: $c=\cfrac{1}{\sqrt{2\pi\begin{vmatrix}A+B\end{vmatrix}}}e^{-\cfrac{1}{2}(a-b)^T(A+B)^{-1}(a-b)}$ At first sight, I'd hence interpret the normalizing factor as the value of a (hypothetical) density function with mean $b$ and covariance matrix $A+B$, evaluated at $a$. Consider now an example, where $f(x)$ and $g(x)$ represent densities of two different statisticians' estimates for $x$. Statistician $A$ whose estimate has density $f(x)$ decides to update his estimate, after he saw the estimate for $x$ from the other statistician, named $B$: $x_b$. $A's$ new estimate, i.e. an estimate conditional on $x_b$ has the density: $f(x_a|x_b)$. Now $B$ would in turn use $A's$ initial estimate to update her own estimate. The new estimate of $B$, conditional on the estimate of $A$ would have the density: $g(x_b|x_a)$. Applying the Bayes rule for densities: $g(x_b|x_a)=\cfrac{f(x_a|x_b)g(x_b)}{f(x_a)}$ So here, the normalizing factor is (also) $f(x_a)$ the unconditional (marginal) density of $x_a$. Unfortunately, I cannot see the link between $-0.5(a-b)^T(A+B)^{-1}(a-b)$ and that marginal density.  What am I missing? P.S.:  how to derive the expression above is indicated in the answer to the question given here: Product of two multivariate Gaussian pdfs - normalizing constant - where online references are given as well.",,"['probability', 'probability-distributions', 'normal-distribution', 'bayesian', 'bayes-theorem']"
37,Show that there is a probability such that $P_n$ converges weakly/in distribution as $n \to \infty$.,Show that there is a probability such that  converges weakly/in distribution as .,P_n n \to \infty,"Suppose that $P_n$ $n \ge 1$ is a sequence of probabilities concentrated on $[a,b]$. Suppose that one may show for each positive integer $r$ that $\int_{[a,b]}x^rP_n(dx) \to m_r \in R$ as $n \to \infty$. Show that there is a probability $P$ such that $P_n \Rightarrow P$ as $n \to \infty$ and $\int_{[a,b]}x^rP(dx) = m_r$ for each $r \ge 1$. My attempt at a solution: I believe that because we are looking at probabilities on $[a,b]$, we automatically have that the sequence is tight. At which point I would like to apply Prohorov's Theorem, which would implies that the weak closure of the sequence is compact in the weak topology. But I have no idea what to do from here. Edit 1: I have made some progress. So, for a subsequence that converges weakly to $P$, say, $P_{n_k}$, whose existence we are guaranteed by Prohorov's Theorem, that subsequence converges weakly to some $P_k$. Therefore, for all continuous, bounded functions $f$ on $[a,b]$, we have that  $$\int_{[a,b]} f(x)P_{n_k}(dx) \to \int_{[a,b]}f(x)P_k(dx)$$ I'm thinking that from here we'll want to apply Weierstrass (all continuous, bounded functions can be approximated by polynomials) but I don't quite know how to do it.","Suppose that $P_n$ $n \ge 1$ is a sequence of probabilities concentrated on $[a,b]$. Suppose that one may show for each positive integer $r$ that $\int_{[a,b]}x^rP_n(dx) \to m_r \in R$ as $n \to \infty$. Show that there is a probability $P$ such that $P_n \Rightarrow P$ as $n \to \infty$ and $\int_{[a,b]}x^rP(dx) = m_r$ for each $r \ge 1$. My attempt at a solution: I believe that because we are looking at probabilities on $[a,b]$, we automatically have that the sequence is tight. At which point I would like to apply Prohorov's Theorem, which would implies that the weak closure of the sequence is compact in the weak topology. But I have no idea what to do from here. Edit 1: I have made some progress. So, for a subsequence that converges weakly to $P$, say, $P_{n_k}$, whose existence we are guaranteed by Prohorov's Theorem, that subsequence converges weakly to some $P_k$. Therefore, for all continuous, bounded functions $f$ on $[a,b]$, we have that  $$\int_{[a,b]} f(x)P_{n_k}(dx) \to \int_{[a,b]}f(x)P_k(dx)$$ I'm thinking that from here we'll want to apply Weierstrass (all continuous, bounded functions can be approximated by polynomials) but I don't quite know how to do it.",,"['probability', 'probability-theory', 'weak-convergence']"
38,Probability no two pairs are grouped together twice in a row?,Probability no two pairs are grouped together twice in a row?,,"There is a room with 48 people divided into 16 groups of 3 in round 1. In round 2, the group is again randomly divided into 16 groups. What is the probability that no two groupmates in round one are in the same group again in round two? Progress I thought at first that if you label two arbitrary people A and B then the probability that they will not be in the same group in round two if they were in round one is $1/21$ (from $3/63$ ). From there I thought maybe do $1 - (1/21)*$ the number of possible pairs, but that will yield a negative answer.","There is a room with 48 people divided into 16 groups of 3 in round 1. In round 2, the group is again randomly divided into 16 groups. What is the probability that no two groupmates in round one are in the same group again in round two? Progress I thought at first that if you label two arbitrary people A and B then the probability that they will not be in the same group in round two if they were in round one is (from ). From there I thought maybe do the number of possible pairs, but that will yield a negative answer.",1/21 3/63 1 - (1/21)*,"['probability', 'combinatorics', 'discrete-mathematics']"
39,Random walk around circle [duplicate],Random walk around circle [duplicate],,"This question already has answers here : Random walk on $n$-cycle (4 answers) Closed 8 years ago . For one of the exercises of my homework I need to answer the following question, but I am not sure how I should apply gamblers ruin theory to solve this problem (it is stated as a hint, not that I must use it). The problem is as follows: A mouse is in a room in a circular hallway with $N+1$ rooms. In the the other $N$ rooms there is a cheese. He has a chance of $\frac{1}{2}$ to go either way every step. If he enters a room with a cheese he eats the cheese. Prove that all cheeses have an equal chance of being eaten last, namely $\frac{1}{N}$. I see that eating the $i^{\textrm{th}}$ cheese as last has two possibilities, first mouse walks to $i+1$ and then goes to $i-1$ without passing $i$, and the other way around. But I am at loss what to do next.","This question already has answers here : Random walk on $n$-cycle (4 answers) Closed 8 years ago . For one of the exercises of my homework I need to answer the following question, but I am not sure how I should apply gamblers ruin theory to solve this problem (it is stated as a hint, not that I must use it). The problem is as follows: A mouse is in a room in a circular hallway with $N+1$ rooms. In the the other $N$ rooms there is a cheese. He has a chance of $\frac{1}{2}$ to go either way every step. If he enters a room with a cheese he eats the cheese. Prove that all cheeses have an equal chance of being eaten last, namely $\frac{1}{N}$. I see that eating the $i^{\textrm{th}}$ cheese as last has two possibilities, first mouse walks to $i+1$ and then goes to $i-1$ without passing $i$, and the other way around. But I am at loss what to do next.",,"['probability', 'random-walk']"
40,Taking Seats on a Plane,Taking Seats on a Plane,,"This is a neat little problem that I was discussing today with my lab group out at lunch. Not particularly difficult but interesting implications nonetheless Imagine there are a 100 people in line to board a plane that seats 100. The first person in line, Alice, realizes she lost her boarding pass, so when she boards she decides to take a random seat instead. Every person that boards the plane after her will either take their ""proper"" seat, or if that seat is taken, a random seat instead. Question: What is the probability that the last person that boards will end up in their proper seat? Moreover, and this is the part I'm still pondering about. Can you think of a physical system that would follow this combinatorial statistics? Maybe a spin wave function in a crystal etc...","This is a neat little problem that I was discussing today with my lab group out at lunch. Not particularly difficult but interesting implications nonetheless Imagine there are a 100 people in line to board a plane that seats 100. The first person in line, Alice, realizes she lost her boarding pass, so when she boards she decides to take a random seat instead. Every person that boards the plane after her will either take their ""proper"" seat, or if that seat is taken, a random seat instead. Question: What is the probability that the last person that boards will end up in their proper seat? Moreover, and this is the part I'm still pondering about. Can you think of a physical system that would follow this combinatorial statistics? Maybe a spin wave function in a crystal etc...",,"['probability', 'combinatorics', 'puzzle']"
41,Expectation conditioned on an event and a sigma algebra,Expectation conditioned on an event and a sigma algebra,,"Suppose we have a probability space $(\Omega, \mathcal{F}, P)$ and $\mathcal{F}$-measurable random variables  $X$ and $Z$ on this space. Suppose  $Z$ is discrete and let $\mathcal{G}=\sigma(Z)$ The random variable $\mathbf{E}[X \mid Z]$ is the same as the random variable $\mathbf{E}[X \mid \mathcal{G}]$. But now suppose $A$ is an event, then $\mathbf{E}[X \mid A,  Z]$ is interpreted to be a random variable, which is a function $f(Z)$ of $Z$. When $Z=z$, it has value $\mathbf{E}[X \mid A \cap  \{Z=z\}]$. What would be a good to write this using the sigma algebra notation? For example, we have  $$ \mathbf{E}[X \mid A,  Z] =\frac{\mathbf{E}[X1_{A}\mid \mathcal{G}]}{\mathbf{E}[1_A \mid \mathcal{G}]  } $$ where, for $\omega \in \Omega$, $1_A(\omega)=1$ if $\omega \in A$ and $1_A(\omega)=0$ otherwise. The RHS seems of the above is not intuitive. If it was written by itself, it is not clear what it would mean, whereas the LHS is clear. A first attempt may write $\mathbf{E}[X \mid A \cap \mathcal{G}]$, but $ A \cap \mathcal{G}$ is not a sigma algebra over $\Omega$. So is there a standard, if not intuitive way to write the random variable $\mathbf{E}[X \mid A,  Z]$ using the sigma algebra generated by $Z$?","Suppose we have a probability space $(\Omega, \mathcal{F}, P)$ and $\mathcal{F}$-measurable random variables  $X$ and $Z$ on this space. Suppose  $Z$ is discrete and let $\mathcal{G}=\sigma(Z)$ The random variable $\mathbf{E}[X \mid Z]$ is the same as the random variable $\mathbf{E}[X \mid \mathcal{G}]$. But now suppose $A$ is an event, then $\mathbf{E}[X \mid A,  Z]$ is interpreted to be a random variable, which is a function $f(Z)$ of $Z$. When $Z=z$, it has value $\mathbf{E}[X \mid A \cap  \{Z=z\}]$. What would be a good to write this using the sigma algebra notation? For example, we have  $$ \mathbf{E}[X \mid A,  Z] =\frac{\mathbf{E}[X1_{A}\mid \mathcal{G}]}{\mathbf{E}[1_A \mid \mathcal{G}]  } $$ where, for $\omega \in \Omega$, $1_A(\omega)=1$ if $\omega \in A$ and $1_A(\omega)=0$ otherwise. The RHS seems of the above is not intuitive. If it was written by itself, it is not clear what it would mean, whereas the LHS is clear. A first attempt may write $\mathbf{E}[X \mid A \cap \mathcal{G}]$, but $ A \cap \mathcal{G}$ is not a sigma algebra over $\Omega$. So is there a standard, if not intuitive way to write the random variable $\mathbf{E}[X \mid A,  Z]$ using the sigma algebra generated by $Z$?",,"['probability', 'measure-theory']"
42,Renyi entropy of prime gaps,Renyi entropy of prime gaps,,"Denote with $p_n$ the $n$-th prime number and let $$ h_N(d) = |\{ n : p_{n+1} < N, p_{n+1} - p_n = d \}| $$ be the number of times that prime gap $d$ happens for primes less than $N$. Let $H = \sum_{d \in {\mathbb Z}} h_N(d)$ and let $$ f_N(d) = \frac{h_N(d)}{H} $$ be the relative frequency of gap $d$. (Yes, actually $H=\pi(N)-1$, where $\pi(N)$ is the number of primes less than $N$.)  I would like to have an estimate for the sum of squares of $f_N(d)$ $$ S = \sum_{d \in {\mathbb Z}} f_N^2(d) $$ when $N$ gets large (very large, say $N=2^{512}, 2^{1024}$).  Alternatively, I could use an estimate of the Renyi entropy $-\log_2 S$. Are you aware of some  result about this problem? I looked around a bit and I found a work by Marek Wolf where it is conjectured that $h_N(d)$ can be approximated by $$ 2 c_2 \frac{\pi^2(N)}{N} \prod_{p | d} \frac{p-1}{p-2} e^{-d\pi(N)/N} $$ I tried to use this approximation, ignoring the product of (p-1)/(p-2) terms for simplicity, but the results are not totally convincing.  I am not sure if it is because I discarded the product or because of some problem that comes out at very large $N$.","Denote with $p_n$ the $n$-th prime number and let $$ h_N(d) = |\{ n : p_{n+1} < N, p_{n+1} - p_n = d \}| $$ be the number of times that prime gap $d$ happens for primes less than $N$. Let $H = \sum_{d \in {\mathbb Z}} h_N(d)$ and let $$ f_N(d) = \frac{h_N(d)}{H} $$ be the relative frequency of gap $d$. (Yes, actually $H=\pi(N)-1$, where $\pi(N)$ is the number of primes less than $N$.)  I would like to have an estimate for the sum of squares of $f_N(d)$ $$ S = \sum_{d \in {\mathbb Z}} f_N^2(d) $$ when $N$ gets large (very large, say $N=2^{512}, 2^{1024}$).  Alternatively, I could use an estimate of the Renyi entropy $-\log_2 S$. Are you aware of some  result about this problem? I looked around a bit and I found a work by Marek Wolf where it is conjectured that $h_N(d)$ can be approximated by $$ 2 c_2 \frac{\pi^2(N)}{N} \prod_{p | d} \frac{p-1}{p-2} e^{-d\pi(N)/N} $$ I tried to use this approximation, ignoring the product of (p-1)/(p-2) terms for simplicity, but the results are not totally convincing.  I am not sure if it is because I discarded the product or because of some problem that comes out at very large $N$.",,"['probability', 'reference-request', 'prime-numbers', 'prime-gaps']"
43,I need help about some compactness arguments,I need help about some compactness arguments,,"I need help to find some compact sets for my engineering problem. Through this page I learned quite much about it however since I have neither read a book yet nor have an experience I am not able to evaluate the situation in an optimal way. I hope you can help me. In a question that I asked, Is this set compact? I learned that The set $$ {\cal{F}}=\{g:S(g,f)\leq \epsilon\} $$ based on the squared Hellinger distance $$ S(g,f)=H^2(g,f)=\frac{1}{2}\int_{\mathbb{R}}\left(\sqrt{g(y)}-\sqrt{f(y)}\right)^2 \mbox{d}y $$ is not compact. My first question : what is/are missing here to get a compact set? In other words what  modification can I make to get it compact? according to counterexamples it seems that even Hellinger distance, which is a metric, will not give me a compact set. In another question How to prove that the space created by pointwise Bernoulli random variables are compact I learned that the set of all decision rules $\Delta$ seems also non-compact. In short a decision rule $\delta\in\Delta$ is a non decreasing continuous function which is $0$ for $y\in(-\infty,y_l)$, increasing in $[0,1]$ for $y\in[y_l,y_u)$, and $1$ for $y\in(y_u,\infty)$. Now I am in a trouble because I have the minimax theorem which holds for compact sets for the existence of a unique solution. According to Von Neumann's minimax theorem, I have $$\max_{x\in X} \min_{y\in Y}f(x,y)=\min_{y\in Y} \max_{x\in X} f(x,y)$$ for some compact sets $X$ and $Y$ in my problem $X={\cal{F}}$ and $Y=\Delta$ where $\Delta$ is the set of all decision rules $\delta\in\Delta$. However In this paper http://arxiv.org/pdf/0707.2926.pdf with a slight difference, where $X$ is constructed by means of KL-divergence instead of squared Hellinger distance, it is claimed that there exists a unique solution for Von Neumann's minimax theorem! His argument for the compactness of $\Delta$ was that it satisfies infinity norm. However $y^2/(y^2+1)$ as an example given by @did shows that the maximum does not exist. Now I want to get something working but all I get is something not working. My second question : What minimal assumptions I can have such that X and Y are compact   sets or at least one of them is compact. Normally whenever I get some nominal density $f$ and construct ${\cal{F}}$, and choose a decision function $\delta$ for the minimization, the solution is unique. However I have mathematically either incorrect or incomplete expressions if I try to type the things as I observe. I would really appreciate your help in this matter. Thank you very much.","I need help to find some compact sets for my engineering problem. Through this page I learned quite much about it however since I have neither read a book yet nor have an experience I am not able to evaluate the situation in an optimal way. I hope you can help me. In a question that I asked, Is this set compact? I learned that The set $$ {\cal{F}}=\{g:S(g,f)\leq \epsilon\} $$ based on the squared Hellinger distance $$ S(g,f)=H^2(g,f)=\frac{1}{2}\int_{\mathbb{R}}\left(\sqrt{g(y)}-\sqrt{f(y)}\right)^2 \mbox{d}y $$ is not compact. My first question : what is/are missing here to get a compact set? In other words what  modification can I make to get it compact? according to counterexamples it seems that even Hellinger distance, which is a metric, will not give me a compact set. In another question How to prove that the space created by pointwise Bernoulli random variables are compact I learned that the set of all decision rules $\Delta$ seems also non-compact. In short a decision rule $\delta\in\Delta$ is a non decreasing continuous function which is $0$ for $y\in(-\infty,y_l)$, increasing in $[0,1]$ for $y\in[y_l,y_u)$, and $1$ for $y\in(y_u,\infty)$. Now I am in a trouble because I have the minimax theorem which holds for compact sets for the existence of a unique solution. According to Von Neumann's minimax theorem, I have $$\max_{x\in X} \min_{y\in Y}f(x,y)=\min_{y\in Y} \max_{x\in X} f(x,y)$$ for some compact sets $X$ and $Y$ in my problem $X={\cal{F}}$ and $Y=\Delta$ where $\Delta$ is the set of all decision rules $\delta\in\Delta$. However In this paper http://arxiv.org/pdf/0707.2926.pdf with a slight difference, where $X$ is constructed by means of KL-divergence instead of squared Hellinger distance, it is claimed that there exists a unique solution for Von Neumann's minimax theorem! His argument for the compactness of $\Delta$ was that it satisfies infinity norm. However $y^2/(y^2+1)$ as an example given by @did shows that the maximum does not exist. Now I want to get something working but all I get is something not working. My second question : What minimal assumptions I can have such that X and Y are compact   sets or at least one of them is compact. Normally whenever I get some nominal density $f$ and construct ${\cal{F}}$, and choose a decision function $\delta$ for the minimization, the solution is unique. However I have mathematically either incorrect or incomplete expressions if I try to type the things as I observe. I would really appreciate your help in this matter. Thank you very much.",,"['probability', 'probability-distributions', 'convergence-divergence', 'nonlinear-optimization', 'uniform-convergence']"
44,How can I find the limiting value of a time-dependent PDE?,How can I find the limiting value of a time-dependent PDE?,,"I've managed to reduce a question in probability to the following simple looking PDE: $$ u_t = -t u_x + \frac{1}{2} u_{xx}, {\rm ~for~} x>0, \, t \in \mathbb{R} \;, $$ with a limiting initial condition: $$ u(x,t) \to 1, {\rm ~as~} t \to -\infty \;, $$ a boundary condition at $x=0$: $$ u_x(0,t) = \left\{ \begin{array}{lc} -2 a t u(0,t) \;, & t \le 0 \\ 0 \;, & t \ge 0 \end{array} \right. \;, $$ where $a > 0$ is a constant, and a suitable boundary condition as $x \to \infty$: either $u \to 1$ or $u$ is bounded. All I want is an exact expression for $p = \lim_{t \to \infty} u(0,t)$, which represents the particular probability that I am after, but I don't know how to do this or if it's possible. I'm hoping there's some sort of method out there that I don't know about to derive $p$ without having to solve the whole boundary value problem. Any ideas? A few comments: 1) I've solved it numerically (with finite differences) and $u(x,t)$ looks nice and smooth and only takes values between 0 and 1. 2) I don't expect the piecewise nature of the boundary condition at $x=0$ to be a major issue. Presumably we can solve up to $t=0$, pause, and then solve for $t>0$. For $t \le 0$, the boundary condition is a time-dependent Robin boundary condition, which I've never seen dealt with before. 3) To me the major problem seems to be the explicit time-dependency in the PDE and the boundary condition at $x=0$. I can get rid of the time-dependency in the PDE by defining $$ v(x,t) = {\rm e}^{\frac{1}{6} t^3 - t x} u(x,t) \;, $$ which gives $$ v_t = -x v + \frac{1}{2} v_{xx} \;, $$ $$ v_x(0,t) = \left\{ \begin{array}{lc} -(1+2a)tv(0,t) \;, & t \le 0 \\ -tv(0,t) \;, & t \ge 0 \end{array} \right. \;. $$ 4) To the boundary value problem in $v$, I can't get separation of variables, or Laplace transforms in time, or some sort of half Fourier transform in space, to work. 5) Incidentally, $\lim_{t \to \infty} u(x,t)$, should be independent of $x$, that is, pointwise, $u(x,t)$ approaches the constant value $p$.","I've managed to reduce a question in probability to the following simple looking PDE: $$ u_t = -t u_x + \frac{1}{2} u_{xx}, {\rm ~for~} x>0, \, t \in \mathbb{R} \;, $$ with a limiting initial condition: $$ u(x,t) \to 1, {\rm ~as~} t \to -\infty \;, $$ a boundary condition at $x=0$: $$ u_x(0,t) = \left\{ \begin{array}{lc} -2 a t u(0,t) \;, & t \le 0 \\ 0 \;, & t \ge 0 \end{array} \right. \;, $$ where $a > 0$ is a constant, and a suitable boundary condition as $x \to \infty$: either $u \to 1$ or $u$ is bounded. All I want is an exact expression for $p = \lim_{t \to \infty} u(0,t)$, which represents the particular probability that I am after, but I don't know how to do this or if it's possible. I'm hoping there's some sort of method out there that I don't know about to derive $p$ without having to solve the whole boundary value problem. Any ideas? A few comments: 1) I've solved it numerically (with finite differences) and $u(x,t)$ looks nice and smooth and only takes values between 0 and 1. 2) I don't expect the piecewise nature of the boundary condition at $x=0$ to be a major issue. Presumably we can solve up to $t=0$, pause, and then solve for $t>0$. For $t \le 0$, the boundary condition is a time-dependent Robin boundary condition, which I've never seen dealt with before. 3) To me the major problem seems to be the explicit time-dependency in the PDE and the boundary condition at $x=0$. I can get rid of the time-dependency in the PDE by defining $$ v(x,t) = {\rm e}^{\frac{1}{6} t^3 - t x} u(x,t) \;, $$ which gives $$ v_t = -x v + \frac{1}{2} v_{xx} \;, $$ $$ v_x(0,t) = \left\{ \begin{array}{lc} -(1+2a)tv(0,t) \;, & t \le 0 \\ -tv(0,t) \;, & t \ge 0 \end{array} \right. \;. $$ 4) To the boundary value problem in $v$, I can't get separation of variables, or Laplace transforms in time, or some sort of half Fourier transform in space, to work. 5) Incidentally, $\lim_{t \to \infty} u(x,t)$, should be independent of $x$, that is, pointwise, $u(x,t)$ approaches the constant value $p$.",,"['probability', 'limits', 'partial-differential-equations']"
45,(Game Theory) Incomplete Information extension of the 'Centipede' Game,(Game Theory) Incomplete Information extension of the 'Centipede' Game,,"This question is an extension of the Centipede Game . My prof. posed this to me in class and I can't figure out how to approach this problem. Imagine in this game, there is an alternative possibility (with very low probability, 0.0001, 0.0000001, etc.) that the first player is irrational, and always goes right instead of down. If this were true, it would make sense for player 2 to always go right (except at the last node) to achieve the highest payoff. The tricky part for me is: now assume that P1 and P2 are both rational, and that they know that each other are rational, but P1 does not know that P2 knows that P1 is rational — how does that affect the game (with regards to the equilibrium outcome)? Backwards induction is pretty straightforward in the original form of the game, is there an alternative method that can be better used for this incomplete information version? (I was thinking of assigning probabilities — starting from the second-to-last node — that would make the payouts equivalent for P2's response to an irrational/rational version of P1, but that seems quite tedious for the ~100 nodes, and I feel there must be come generalized approach to this.)","This question is an extension of the Centipede Game . My prof. posed this to me in class and I can't figure out how to approach this problem. Imagine in this game, there is an alternative possibility (with very low probability, 0.0001, 0.0000001, etc.) that the first player is irrational, and always goes right instead of down. If this were true, it would make sense for player 2 to always go right (except at the last node) to achieve the highest payoff. The tricky part for me is: now assume that P1 and P2 are both rational, and that they know that each other are rational, but P1 does not know that P2 knows that P1 is rational — how does that affect the game (with regards to the equilibrium outcome)? Backwards induction is pretty straightforward in the original form of the game, is there an alternative method that can be better used for this incomplete information version? (I was thinking of assigning probabilities — starting from the second-to-last node — that would make the payouts equivalent for P2's response to an irrational/rational version of P1, but that seems quite tedious for the ~100 nodes, and I feel there must be come generalized approach to this.)",,"['probability', 'game-theory']"
46,"If $Y$ is a nonnegative absolutely continuous random variable and $E[X|Y]=Y/2$, is $E[X|Y=-1]=-1/2$? Is $E[X|Y=2]=1$?","If  is a nonnegative absolutely continuous random variable and , is ? Is ?",Y E[X|Y]=Y/2 E[X|Y=-1]=-1/2 E[X|Y=2]=1,"One of the definitions I learned for $E[X|Y=y]$ is the following: $$ E[X|Y=y]=\int_{\mathbb{R}} x\,P_{X|Y=y}(dx), $$ where $P_{X|Y=y}$ a probability verifying  $$ P(X\in A, Y\in B)=\int_B P_{X|Y=y}(A)\,P_Y(dy), \;\;(*)$$ for all $A,B\in\mathcal{B}(\mathbb{R})$. This probability $P_{X|Y=y}$ is unique in the following sense: if $Q_{X|Y=y}$ is another probability satisfying $(*)$, then $P_{X|Y=y}(C)=Q_{X|Y=y}(C)$ for all $C\in\mathcal{B}(\mathbb{R})$ and $y\notin N$, with $P_Y(N)=0$. Let $Y$ be a nonnegative absolutely continuous random variable with $E[X|Y]=Y/2$. Let $N=(-\infty,0)\cup \{2\}$. We have $P_Y(N)=0$, so in principle $P_{X|Y=y}$ may be any probability on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$ for $y\in N$, right? Then $E[X|Y=y]$ could be any value for $y\in N$, right? I am totally confused. Intuitively, $E[X|Y=2]$ should be $1$ and $E[X|Y=-1]$ should not be defined, since $Y$ is nonnegative. As you can see in this question , in Lemma 5.22 of the book An Introduction to Computational Stochastic PDEs , it is stated that $E[W(t)|W(1)]=t\,W(1)$ implies that $E[W(t)|W(1)=0]=0$, where $W$ is a Brownian motion and $0\leq t\leq 1$. But $P(W(1)=0)$, so $E[W(t)|W(1)=0]$ is not uniqueley defined, it may be any value. I mean, $y\mapsto E[W(t)|W(1)=y]$ is defined $P_{W(1)}$-a.s., so at $y=0$ there is not a unique definition. It is like stating something about $f(0)$ when $f$ is a real function defined a.e.","One of the definitions I learned for $E[X|Y=y]$ is the following: $$ E[X|Y=y]=\int_{\mathbb{R}} x\,P_{X|Y=y}(dx), $$ where $P_{X|Y=y}$ a probability verifying  $$ P(X\in A, Y\in B)=\int_B P_{X|Y=y}(A)\,P_Y(dy), \;\;(*)$$ for all $A,B\in\mathcal{B}(\mathbb{R})$. This probability $P_{X|Y=y}$ is unique in the following sense: if $Q_{X|Y=y}$ is another probability satisfying $(*)$, then $P_{X|Y=y}(C)=Q_{X|Y=y}(C)$ for all $C\in\mathcal{B}(\mathbb{R})$ and $y\notin N$, with $P_Y(N)=0$. Let $Y$ be a nonnegative absolutely continuous random variable with $E[X|Y]=Y/2$. Let $N=(-\infty,0)\cup \{2\}$. We have $P_Y(N)=0$, so in principle $P_{X|Y=y}$ may be any probability on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$ for $y\in N$, right? Then $E[X|Y=y]$ could be any value for $y\in N$, right? I am totally confused. Intuitively, $E[X|Y=2]$ should be $1$ and $E[X|Y=-1]$ should not be defined, since $Y$ is nonnegative. As you can see in this question , in Lemma 5.22 of the book An Introduction to Computational Stochastic PDEs , it is stated that $E[W(t)|W(1)]=t\,W(1)$ implies that $E[W(t)|W(1)=0]=0$, where $W$ is a Brownian motion and $0\leq t\leq 1$. But $P(W(1)=0)$, so $E[W(t)|W(1)=0]$ is not uniqueley defined, it may be any value. I mean, $y\mapsto E[W(t)|W(1)=y]$ is defined $P_{W(1)}$-a.s., so at $y=0$ there is not a unique definition. It is like stating something about $f(0)$ when $f$ is a real function defined a.e.",,"['probability', 'probability-theory', 'measure-theory', 'conditional-expectation']"
47,Discover where Bob is sleeping using hidden Markov chains,Discover where Bob is sleeping using hidden Markov chains,,"Bob lives in four different houses $A, B, C$ and $D$ that are connected like the following graph shows: Bob likes to sleep in any of his houses, but they are far apart so he only sleeps in a house adjacent to the one in which he slept the previous night. To clarify, this means that if Bob slept in house $A$ on night $1$, he may sleep in house $A$, $B$ or $C$ on night $2$ (not house $D$). The probability of each case is the same (one third); on each day, Bob takes a random walk from where stayed the previous night (and he might stay put). Now Bob is a wanted criminal so on a given night the FBI would like to estimate where Bob is sleeping. Data from a satellite gives us the following probabilities of where Bob is sleeping on night $1$ and night $2$ (and any subsequent nights): Night 1   Night 2   ... House A  0.8       0.05      ... House B  0.1       0.4       ... House C  0.05      0.05      ... House D  0.05      0.5       ... How can we use this data to calculate the probability of where Bob was sleeping on night $2$, for example calculating the probability Bob slept in house A? Could we use that method iteratively to calculate where Bob was sleeping on night $n$ if we continue to receive satellite data for each night? Note: I made up this problem to understand better how hidden Markov chains work because I am interested in seeing the calculations on a concrete example. Many thanks for any input.","Bob lives in four different houses $A, B, C$ and $D$ that are connected like the following graph shows: Bob likes to sleep in any of his houses, but they are far apart so he only sleeps in a house adjacent to the one in which he slept the previous night. To clarify, this means that if Bob slept in house $A$ on night $1$, he may sleep in house $A$, $B$ or $C$ on night $2$ (not house $D$). The probability of each case is the same (one third); on each day, Bob takes a random walk from where stayed the previous night (and he might stay put). Now Bob is a wanted criminal so on a given night the FBI would like to estimate where Bob is sleeping. Data from a satellite gives us the following probabilities of where Bob is sleeping on night $1$ and night $2$ (and any subsequent nights): Night 1   Night 2   ... House A  0.8       0.05      ... House B  0.1       0.4       ... House C  0.05      0.05      ... House D  0.05      0.5       ... How can we use this data to calculate the probability of where Bob was sleeping on night $2$, for example calculating the probability Bob slept in house A? Could we use that method iteratively to calculate where Bob was sleeping on night $n$ if we continue to receive satellite data for each night? Note: I made up this problem to understand better how hidden Markov chains work because I am interested in seeing the calculations on a concrete example. Many thanks for any input.",,"['probability', 'markov-process']"
48,Recurrence of a certain class of $2$-$d$ random walks,Recurrence of a certain class of - random walks,2 d,"As is well known, a symmetric random walk on $\mathbb{Z}^d$ (the lattice of $d$ dimensional vectors with integer components) is recurrent if and only if $d=1,2$. In particular it is transient for $d=3$. What about a random walk on $\mathbb{Z}^2$, where the probability to move right is equal to the probability to move left, and the probability to move forward is equal to the probability to move backward, but they are not necessary all $0.25$? (They do sum to $1$ of course). Well it turns out that this is recurrent as well. My question is this: Is there a non-computational proof of this? i.e. can one show in some rigorous sense that this is ""the same"" as a truly symmetric $2$-$d$ random walk and thus recurrent? edit: perhaps I should replace ""non computational"" with ""slick"" or ""short"". I was given a problem on an exam that required as a lemma the fact that these walks are recurrent. When I went over the official solution, I was surprised that the lecturer stated without proof that in this type of walk the probability of returning to the origin at time n is of order 1/n, as though this was some immediate corollary of the symmetric case (where this holds). I guess he was just being sloppy...","As is well known, a symmetric random walk on $\mathbb{Z}^d$ (the lattice of $d$ dimensional vectors with integer components) is recurrent if and only if $d=1,2$. In particular it is transient for $d=3$. What about a random walk on $\mathbb{Z}^2$, where the probability to move right is equal to the probability to move left, and the probability to move forward is equal to the probability to move backward, but they are not necessary all $0.25$? (They do sum to $1$ of course). Well it turns out that this is recurrent as well. My question is this: Is there a non-computational proof of this? i.e. can one show in some rigorous sense that this is ""the same"" as a truly symmetric $2$-$d$ random walk and thus recurrent? edit: perhaps I should replace ""non computational"" with ""slick"" or ""short"". I was given a problem on an exam that required as a lemma the fact that these walks are recurrent. When I went over the official solution, I was surprised that the lecturer stated without proof that in this type of walk the probability of returning to the origin at time n is of order 1/n, as though this was some immediate corollary of the symmetric case (where this holds). I guess he was just being sloppy...",,"['probability', 'probability-theory', 'random-walk']"
49,How to calculate probability of these two pair-of-sums ($S_{n}$ and $T_{n}$) and ($SEvenF_{n}$ and $SOddF_{n}$) being the same?,How to calculate probability of these two pair-of-sums ( and ) and ( and ) being the same?,S_{n} T_{n} SEvenF_{n} SOddF_{n},"Say we have a sequence of $n$ positive integers, we can assume they're randomly chosen, let's call it $U_{n}$. Let $S_{n}$ = sum of $U_{n}$ from $1$ to $n$. Let $T_{n}$ = sum of $n$ from $1$ to $n$. In other words, $T_{n}$ is the triangle number $T_{n} = \frac{1}{2}n(n+1)$. Define $F_{n} = U_{n} + n$. (note that $SF_{n}$, sum of $F_{n}$, is equal to $S_{n} + T_{n}$) Define two sets $EvenSet$ and $OddSet$ containing $F_{n}$ when it is even and odd respectively. Let $SEvenF_{n}$ be the sum of numbers in $EvenSet$ and $SOddF_{n}$ be the sum of numbers in $OddSet$. (note that $SEvenF_{n} + SOddF_{n} = SF_{n} = S_{n} + T_{n}$) What is the probability of the two pairs ($S_{n}$ and $T_{n}$) and ($SEvenF_{n}$ and $SOddF_{n}$) are the same pairs? In other words, either ""$S_{n} = SEvenF_{n}$ thus $T_{n} = SOddF_{n}$"" or ""$S_{n} = SOddF_{n}$ thus $T_{n} = SEvenF_{n}$"". How to calculate this probability? PS: I have a sample data with $n = 114$ in here http://goo.gl/k96FZ PS2: Is there a way or an algorithm to generate such sequence? PS3: @ZefChonoles has correctly pointed a concern about Probability Measure. Originally I intended this question to have no restriction on the positive integer set, that is to work on the infinite set of $\mathbb Z^{+}$. But I believe you are free to impose certain restriction to this problem, as long as you can share insights on approaches in solving this problem. For example, you can restrict $U_{n}$ and $F_{n}$ to be within $[1, 400]$ for the $n=114$ case. Or you can restrict them to be within $[1, Cn]$ with some constant $C$ for the general case. Or within $[1, Tn]$. Anything that helps, basically. Thanks!","Say we have a sequence of $n$ positive integers, we can assume they're randomly chosen, let's call it $U_{n}$. Let $S_{n}$ = sum of $U_{n}$ from $1$ to $n$. Let $T_{n}$ = sum of $n$ from $1$ to $n$. In other words, $T_{n}$ is the triangle number $T_{n} = \frac{1}{2}n(n+1)$. Define $F_{n} = U_{n} + n$. (note that $SF_{n}$, sum of $F_{n}$, is equal to $S_{n} + T_{n}$) Define two sets $EvenSet$ and $OddSet$ containing $F_{n}$ when it is even and odd respectively. Let $SEvenF_{n}$ be the sum of numbers in $EvenSet$ and $SOddF_{n}$ be the sum of numbers in $OddSet$. (note that $SEvenF_{n} + SOddF_{n} = SF_{n} = S_{n} + T_{n}$) What is the probability of the two pairs ($S_{n}$ and $T_{n}$) and ($SEvenF_{n}$ and $SOddF_{n}$) are the same pairs? In other words, either ""$S_{n} = SEvenF_{n}$ thus $T_{n} = SOddF_{n}$"" or ""$S_{n} = SOddF_{n}$ thus $T_{n} = SEvenF_{n}$"". How to calculate this probability? PS: I have a sample data with $n = 114$ in here http://goo.gl/k96FZ PS2: Is there a way or an algorithm to generate such sequence? PS3: @ZefChonoles has correctly pointed a concern about Probability Measure. Originally I intended this question to have no restriction on the positive integer set, that is to work on the infinite set of $\mathbb Z^{+}$. But I believe you are free to impose certain restriction to this problem, as long as you can share insights on approaches in solving this problem. For example, you can restrict $U_{n}$ and $F_{n}$ to be within $[1, 400]$ for the $n=114$ case. Or you can restrict them to be within $[1, Cn]$ with some constant $C$ for the general case. Or within $[1, Tn]$. Anything that helps, basically. Thanks!",,"['probability', 'number-theory', 'summation']"
50,Does pi's decimal expansion certainly repeat once (of course not infinitely many times)??,Does pi's decimal expansion certainly repeat once (of course not infinitely many times)??,,"My 8-year-old asked me this and I could see arguments for either answer. Is pi guaranteed to have an expansion of the form 3.NNM where N is a finite sequence of digits?  For example, 3.14151415696745... (N=1415) or 3.1415926141592696033... (N=1415926).  Of course these are not the true value of N. Argument for: At any position P in the expansion, The chance of the next P digits being equal to the first P is nonzero. Since there are an infinite number of positions P, eventually we will succeed. Argument against: The chance of succeeding at P=1 is 1 in 10.  (We fail, as pi does not begin with 3.11). The chance of succeeding at P=2 is 1 in 100. (Fail again: pi does not begin with 3.1414).  Etc.  If I play a game where I attempt to succeed at P=1, and then at P=2, and repeat infinitely until I succeed, the fact that the chance at each step becomes 10 times less causes the total probability to converge on a number less than 100%. Which argument is correct, if either? If it's the latter, what is the overall probability that we converge upon?","My 8-year-old asked me this and I could see arguments for either answer. Is pi guaranteed to have an expansion of the form 3.NNM where N is a finite sequence of digits?  For example, 3.14151415696745... (N=1415) or 3.1415926141592696033... (N=1415926).  Of course these are not the true value of N. Argument for: At any position P in the expansion, The chance of the next P digits being equal to the first P is nonzero. Since there are an infinite number of positions P, eventually we will succeed. Argument against: The chance of succeeding at P=1 is 1 in 10.  (We fail, as pi does not begin with 3.11). The chance of succeeding at P=2 is 1 in 100. (Fail again: pi does not begin with 3.1414).  Etc.  If I play a game where I attempt to succeed at P=1, and then at P=2, and repeat infinitely until I succeed, the fact that the chance at each step becomes 10 times less causes the total probability to converge on a number less than 100%. Which argument is correct, if either? If it's the latter, what is the overall probability that we converge upon?",,"['probability', 'sequences-and-series', 'pi']"
51,Explicit formula for tournament sequence,Explicit formula for tournament sequence,,"I am looking for an explicit formula for a sequence. The sequence is generated as follows: There is a tournament with $10$ teams. In the beginning, all teams have a 0-0 win-loss record. The teams are paired up, and when the first round concludes, $5$ of the teams have a 0-1 record and $5$ of the teams have a 1-0 record. The second round is arranged so that only teams with the same win-loss record are allowed to face each other, and when there are an odd number of teams having a certain win-loss record, the extra team from one win-loss record plays the extra team from the nearby win-loss record. This means that for the second round, four of the 0-1 teams are paired up with each other, $4$ of the 1-0 teams are paired up with each other, and there is one pairing between a 0-1 team and a 1-0 team. We also assume that when there is a pairing across different win-loss records, the team with the better record always wins. This means that at the end of round 2, there will be $3$ teams with a 0-2 record, there will be $4$ teams with a 1-1 record, and $3$ teams with a 2-0 record. I am looking for an explicit formula giving the win-loss record distribution at round $r$ . I am also looking for a general formula for $T$ teams (I used ""10"" earlier just for illustration purposes). I have python code which explicitly calculates this sequence for $T$ teams and round $r$ , but I would like a mathematical expression for this. I have an explicit formula for the first $4$ rows using ceiling/floor functions, but the formula does not work beyond $4$ rows. I also have an explicit formula giving the win-loss record in the long term, but it only works after about $T^2$ rows. In terms of problem solving techniques that I've tried, I've tried various generating series approaches. For example, for the case of $10$ teams, I wrote round $0$ as $$f_0(x,y) = y^0 + y^1 + y^2 + ... + y^9$$ and round $1$ as $$f_1(x,y) = y^0 + y^1 + y^2 + y^3 + y^ 4 + (y^5 + y^6 + y^7 + y^8 + y^9)x$$ and round $2$ as $$f_2(x,y) = y^0 + y^1 + y^2 + (y^3 + y^4 + y^5 + y^6)x + (y^7 + y^8 + y^9)x^2$$ and so on. I don't have a method for moving from $f_k$ to $f_{k+1}$ , but I have lots of near misses. I have also tried using a probabilistic approach. I have started from several invariants, and I have a function that when minimized gives a (sometimes) close approximation. The invariants are as follows: The number of teams $T$ does not change from round to round. The number of total wins at each round is always $T r / 2$ . The win-loss record is symmetric around $r/2$ . These invariants restrict the number of possible choices for round $r$ . I then took the choice that most nearly matches a binomial distribution (using the euclidean distance as a metric, although any similarity metric could work). This metric isn't best, since I believe the win-loss records become ""less binomial"" over time. Another thing I tried was various kinds of graphing. I can post some graphs if requested. I am open to any approach, I look forward to seeing your ideas. Updates and extra information Here are the first few terms of the sequence for $T=10$ : $$10$$ $$5, 5$$ $$3, 4, 3$$ $$2, 3, 3, 2$$ $$1, 3, 2, 3, 1$$ $$1, 1, 3, 3, 1, 1$$ $$1, 0, 3, 2, 3, 0, 1$$ $$1, 0, 1, 3, 3, 1, 0, 1$$ $$1, 0, 0, 3, 2, 3, 0, 0, 1$$ $$1, 0, 0, 1, 3, 3, 1, 0, 0, 1$$ $$...$$ Another clarification is that the number of teams $T$ must be even. Also, I would like to add the formula for the long-term behavior of the sequences. The long-term behavior shows a 2-term repetition, and this repetition depends on the value of $T \pmod 8$ . Here are the four cases: Case 1. ( $T \equiv 0 \pmod 8$ ): $1444...444...441$ , $3444...4444....443$ Case 2. ( $T \equiv 2 \pmod 8$ ): $3444...424...443$ , $1444...4334....441$ Case 3. ( $T \equiv 4 \pmod 8$ ): $3444...444...443$ , $1444...4444....441$ Case 4. ( $T \equiv 6 \pmod{8}$ ): $1444...424...441$ , $3444...4334....443$ Note that I have left off the preceding $1000...$ and the trailing $...0001$ , since the number of zeros can be easily calculated. Not also that the number of $4$ s can be calculated easily from the original number of teams $T$ . Regarding the generating series idea previously, one thing I found is that if we have for example $$f_2(x,y) = y^0 + y^1 + y^2 + (y^3 + y^4 + y^5 + y^6)x + (y^7 + y^8 + y^9)x^2$$ then we can calculate something very close to $f_3(x,y)$ by performing the following steps: $$\frac{f_2(x,y) + f_2(x,-y)}{2} = y^0 + y^2 + (y^4 + y^6)x + (y^8)x^2$$ $$\frac{f_2(x,y) - f_2(x,-y)}{2} \cdot x = y^1 x + (y^3 + y^5) x^2 + (y^7 + y^9) x^3$$ $$\widetilde{f}_3(x,y) = \frac{f_2(x,y) + f_2(x,-y)}{2} + \frac{f_2(x,y) - f_2(x,-y)}{2} \cdot x = y^0 + y^2 + (y^1 + y^4 + y^6)x + (y^3 + y^5 + y^8)x^2 + (y^7 + y^9)x^3$$ which when evaluated at $y = 1$ gives the correct sequence $2,3,3,2$ . It is not exactly correct, since the $y$ terms are no longer ordered in terms of exponents, so this process is not repeatable unless we improve on it somehow. Another Update Let's add a variant to the original rules. The variant will be called ""underdog"", whereas the original rules will be called ""overdog"". The ""overdog"" rules stipulate that the team with the higher win-loss record will always win when it crosses over and faces a team with a lower win-loss ratio; in contrast, the ""underdog"" rules stipulate that the team with the lower win-loss ratio will win. Let's call the overdog sequence with $T$ teams the sequence $O(T)$ , and each term in the sequence will be identified as $O_{r,w}(T)$ where $r$ denotes the round and $w$ denotes the number of wins at that round. For the underdog variant, we define $U(T)$ and $U_{r,w}(T)$ in the same way. I just discovered the following properties: $$O(2^k + 2) = U(2^k) + O(2)$$ $$O(2^k + 4) = U(2^k) + U(2) + O(2)$$ This is helpful since $U(2^k)$ and $O(2^k)$ are easy to calculate for $k$ rows, and $O(2)$ and $U(2)$ are easily calculated for all rows. I'm wondering if we can use the binary representation of $T$ and some kind of summing procedure to improve the number of rows that we can directly calculate. It would be fascinating to try to reduce $O(T)$ and $U(T)$ to the sum of terms of the form $U(2^K)$ or $O(2^K)$ for any arbitrarily large $K >> 0$ . This would give us a way to calculate arbitrarily many rows for any $T$ . Correction to Previous Update I should edit my previous update to be more precise. The powers of two were a bit of a red herring — all that matters is $T \pmod{4}$ . Here are the updated relations: $O(4k + 2) = U(4k) + O(2)$ . $U(4k + 2) = U(4k) + U(2)$ . $O(4k + 4) = U(4k) + U(2) + O(2)$ . This means that the problem is essentially reduced to finding $U(4k)$ instead of finding $U(2k)$ . Not much of a reduction, but it's progress!","I am looking for an explicit formula for a sequence. The sequence is generated as follows: There is a tournament with teams. In the beginning, all teams have a 0-0 win-loss record. The teams are paired up, and when the first round concludes, of the teams have a 0-1 record and of the teams have a 1-0 record. The second round is arranged so that only teams with the same win-loss record are allowed to face each other, and when there are an odd number of teams having a certain win-loss record, the extra team from one win-loss record plays the extra team from the nearby win-loss record. This means that for the second round, four of the 0-1 teams are paired up with each other, of the 1-0 teams are paired up with each other, and there is one pairing between a 0-1 team and a 1-0 team. We also assume that when there is a pairing across different win-loss records, the team with the better record always wins. This means that at the end of round 2, there will be teams with a 0-2 record, there will be teams with a 1-1 record, and teams with a 2-0 record. I am looking for an explicit formula giving the win-loss record distribution at round . I am also looking for a general formula for teams (I used ""10"" earlier just for illustration purposes). I have python code which explicitly calculates this sequence for teams and round , but I would like a mathematical expression for this. I have an explicit formula for the first rows using ceiling/floor functions, but the formula does not work beyond rows. I also have an explicit formula giving the win-loss record in the long term, but it only works after about rows. In terms of problem solving techniques that I've tried, I've tried various generating series approaches. For example, for the case of teams, I wrote round as and round as and round as and so on. I don't have a method for moving from to , but I have lots of near misses. I have also tried using a probabilistic approach. I have started from several invariants, and I have a function that when minimized gives a (sometimes) close approximation. The invariants are as follows: The number of teams does not change from round to round. The number of total wins at each round is always . The win-loss record is symmetric around . These invariants restrict the number of possible choices for round . I then took the choice that most nearly matches a binomial distribution (using the euclidean distance as a metric, although any similarity metric could work). This metric isn't best, since I believe the win-loss records become ""less binomial"" over time. Another thing I tried was various kinds of graphing. I can post some graphs if requested. I am open to any approach, I look forward to seeing your ideas. Updates and extra information Here are the first few terms of the sequence for : Another clarification is that the number of teams must be even. Also, I would like to add the formula for the long-term behavior of the sequences. The long-term behavior shows a 2-term repetition, and this repetition depends on the value of . Here are the four cases: Case 1. ( ): , Case 2. ( ): , Case 3. ( ): , Case 4. ( ): , Note that I have left off the preceding and the trailing , since the number of zeros can be easily calculated. Not also that the number of s can be calculated easily from the original number of teams . Regarding the generating series idea previously, one thing I found is that if we have for example then we can calculate something very close to by performing the following steps: which when evaluated at gives the correct sequence . It is not exactly correct, since the terms are no longer ordered in terms of exponents, so this process is not repeatable unless we improve on it somehow. Another Update Let's add a variant to the original rules. The variant will be called ""underdog"", whereas the original rules will be called ""overdog"". The ""overdog"" rules stipulate that the team with the higher win-loss record will always win when it crosses over and faces a team with a lower win-loss ratio; in contrast, the ""underdog"" rules stipulate that the team with the lower win-loss ratio will win. Let's call the overdog sequence with teams the sequence , and each term in the sequence will be identified as where denotes the round and denotes the number of wins at that round. For the underdog variant, we define and in the same way. I just discovered the following properties: This is helpful since and are easy to calculate for rows, and and are easily calculated for all rows. I'm wondering if we can use the binary representation of and some kind of summing procedure to improve the number of rows that we can directly calculate. It would be fascinating to try to reduce and to the sum of terms of the form or for any arbitrarily large . This would give us a way to calculate arbitrarily many rows for any . Correction to Previous Update I should edit my previous update to be more precise. The powers of two were a bit of a red herring — all that matters is . Here are the updated relations: . . . This means that the problem is essentially reduced to finding instead of finding . Not much of a reduction, but it's progress!","10 5 5 4 3 4 3 r T T r 4 4 T^2 10 0 f_0(x,y) = y^0 + y^1 + y^2 + ... + y^9 1 f_1(x,y) = y^0 + y^1 + y^2 + y^3 + y^ 4 + (y^5 + y^6 + y^7 + y^8 + y^9)x 2 f_2(x,y) = y^0 + y^1 + y^2 + (y^3 + y^4 + y^5 + y^6)x + (y^7 + y^8 + y^9)x^2 f_k f_{k+1} T T r / 2 r/2 r T=10 10 5, 5 3, 4, 3 2, 3, 3, 2 1, 3, 2, 3, 1 1, 1, 3, 3, 1, 1 1, 0, 3, 2, 3, 0, 1 1, 0, 1, 3, 3, 1, 0, 1 1, 0, 0, 3, 2, 3, 0, 0, 1 1, 0, 0, 1, 3, 3, 1, 0, 0, 1 ... T T \pmod 8 T \equiv 0 \pmod 8 1444...444...441 3444...4444....443 T \equiv 2 \pmod 8 3444...424...443 1444...4334....441 T \equiv 4 \pmod 8 3444...444...443 1444...4444....441 T \equiv 6 \pmod{8} 1444...424...441 3444...4334....443 1000... ...0001 4 T f_2(x,y) = y^0 + y^1 + y^2 + (y^3 + y^4 + y^5 + y^6)x + (y^7 + y^8 + y^9)x^2 f_3(x,y) \frac{f_2(x,y) + f_2(x,-y)}{2} = y^0 + y^2 + (y^4 + y^6)x + (y^8)x^2 \frac{f_2(x,y) - f_2(x,-y)}{2} \cdot x = y^1 x + (y^3 + y^5) x^2 + (y^7 + y^9) x^3 \widetilde{f}_3(x,y) = \frac{f_2(x,y) + f_2(x,-y)}{2} + \frac{f_2(x,y) - f_2(x,-y)}{2} \cdot x = y^0 + y^2 + (y^1 + y^4 + y^6)x + (y^3 + y^5 + y^8)x^2 + (y^7 + y^9)x^3 y = 1 2,3,3,2 y T O(T) O_{r,w}(T) r w U(T) U_{r,w}(T) O(2^k + 2) = U(2^k) + O(2) O(2^k + 4) = U(2^k) + U(2) + O(2) U(2^k) O(2^k) k O(2) U(2) T O(T) U(T) U(2^K) O(2^K) K >> 0 T T \pmod{4} O(4k + 2) = U(4k) + O(2) U(4k + 2) = U(4k) + U(2) O(4k + 4) = U(4k) + U(2) + O(2) U(4k) U(2k)","['probability', 'combinatorics', 'number-theory', 'generating-functions', 'integer-sequences']"
52,A fair coin is flipped 2k times. What is the probability that it comes up tails more often than it comes up heads? [duplicate],A fair coin is flipped 2k times. What is the probability that it comes up tails more often than it comes up heads? [duplicate],,This question already has an answer here : Probability a coin comes up heads more often than tails (1 answer) Closed 10 years ago . I'm studying for a probability exam and came across this question. I watched the video solution to it but I don't really understand it. I was hoping someone could explain this problem to me. Are there different ways to go about this?,This question already has an answer here : Probability a coin comes up heads more often than tails (1 answer) Closed 10 years ago . I'm studying for a probability exam and came across this question. I watched the video solution to it but I don't really understand it. I was hoping someone could explain this problem to me. Are there different ways to go about this?,,"['probability', 'combinatorics', 'probability-theory', 'probability-distributions']"
53,Calculate the probability of a collision between these two functions?,Calculate the probability of a collision between these two functions?,,$f(x) =$ Choose a random number between $1$ and $100$ (inclusive) $g(x) =$ Choose a random number between $1$ and $200$ (inclusive) What is the probability that $f(x) = g(x)$? Here is my working: $$P(f_1(x) = f_2(x)) = \frac1{100}$$ $$P(g(x) = f(x)) = \frac{100}{200} \cdot \frac1{200} = \frac1{400}$$ Is my working correct?,$f(x) =$ Choose a random number between $1$ and $100$ (inclusive) $g(x) =$ Choose a random number between $1$ and $200$ (inclusive) What is the probability that $f(x) = g(x)$? Here is my working: $$P(f_1(x) = f_2(x)) = \frac1{100}$$ $$P(g(x) = f(x)) = \frac{100}{200} \cdot \frac1{200} = \frac1{400}$$ Is my working correct?,,"['probability', 'probability-theory']"
54,You are dealt five cards from a standard deck. What is the probability that you'll have at most three kings in your hand?,You are dealt five cards from a standard deck. What is the probability that you'll have at most three kings in your hand?,,"You are dealt five cards from a standard and shuffled deck of playing cards. Note that a standard deck has 52 cards and four of those are kings. What is the probability that you'll have at most three kings in your hand? I know that the answer is $\frac{54144}{54145}$ from the answer key, and I know that the sample space is ${^{52}\mathrm C_5}$. What I don't get is how to find the event. Do I just add the combination for each number of kings together (${^5\mathrm C_2} + {^5\mathrm C_3}$)? Or do I need to multiply as well to account for the other cards in the 5-card hand?","You are dealt five cards from a standard and shuffled deck of playing cards. Note that a standard deck has 52 cards and four of those are kings. What is the probability that you'll have at most three kings in your hand? I know that the answer is $\frac{54144}{54145}$ from the answer key, and I know that the sample space is ${^{52}\mathrm C_5}$. What I don't get is how to find the event. Do I just add the combination for each number of kings together (${^5\mathrm C_2} + {^5\mathrm C_3}$)? Or do I need to multiply as well to account for the other cards in the 5-card hand?",,"['probability', 'combinatorics', 'combinations']"
55,Is integration by parts the best method for $\int_0^1 x^3(1-x)^6 dx$?,Is integration by parts the best method for ?,\int_0^1 x^3(1-x)^6 dx,"It came up when finding a constant such that the integral is equal to 1 and thus behaves like a pdf. I used the parts method but have made an error, just curious how others might approach the problem.","It came up when finding a constant such that the integral is equal to 1 and thus behaves like a pdf. I used the parts method but have made an error, just curious how others might approach the problem.",,"['probability', 'self-learning']"
56,"If you roll a fair six sided die twice, what's the probability that you get the same number both times? [closed]","If you roll a fair six sided die twice, what's the probability that you get the same number both times? [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question So I know that rolling a fair six-sided die twice would mean the total possible outcomes would be 36, and rolling the same number twice would be 2/36 or 1/18, but I feel like that's wrong. What am I doing that isn't right?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question So I know that rolling a fair six-sided die twice would mean the total possible outcomes would be 36, and rolling the same number twice would be 2/36 or 1/18, but I feel like that's wrong. What am I doing that isn't right?",,"['probability', 'dice']"
57,If I buy 2 lottery tickets do I double my chance of winning? [closed],If I buy 2 lottery tickets do I double my chance of winning? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question There's a lottery.  There are 6 balls chosen randomly from 49 and you have to match all the balls to win. I buy one ticket.   If I buy two tickets with different numbers for the same draw, do I double my chance of winning the jackpot. What's the correct formula here?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question There's a lottery.  There are 6 balls chosen randomly from 49 and you have to match all the balls to win. I buy one ticket.   If I buy two tickets with different numbers for the same draw, do I double my chance of winning the jackpot. What's the correct formula here?",,"['probability', 'combinatorics']"
58,why is the PDF of the sum of two continuous random variables the convolution of the PDF's?,why is the PDF of the sum of two continuous random variables the convolution of the PDF's?,,"I have taken a probability course last year but we didn't cover that notion. I do know the steps in the discrete case. finding the support of $X + Y$... calculating the the probability of each element of the support... dressing a table. however this process is very intuitive and self-explanatory. the convolution is very useful when taking inverse of product of Laplace/Fourier transforms which is why it's hard for me to think of an analogy between taking the inverse of integral and computing the PDF of the sum of two random variables. I'd like to know the intuition behind : $$f_Z(z)=\int^{\infty}_{-\infty}f(x,z-x)dx$$ or just $$f_Z(z) = \int_{- \infty}^{\infty} f_X(x)f_Y(z-x)\;dx $$ when they are independent not a proof as I already found some on this site and elsewhere.","I have taken a probability course last year but we didn't cover that notion. I do know the steps in the discrete case. finding the support of $X + Y$... calculating the the probability of each element of the support... dressing a table. however this process is very intuitive and self-explanatory. the convolution is very useful when taking inverse of product of Laplace/Fourier transforms which is why it's hard for me to think of an analogy between taking the inverse of integral and computing the PDF of the sum of two random variables. I'd like to know the intuition behind : $$f_Z(z)=\int^{\infty}_{-\infty}f(x,z-x)dx$$ or just $$f_Z(z) = \int_{- \infty}^{\infty} f_X(x)f_Y(z-x)\;dx $$ when they are independent not a proof as I already found some on this site and elsewhere.",,"['probability', 'probability-distributions', 'random-variables', 'intuition']"
59,Probability of success and failure,Probability of success and failure,,"I've an interesting question on my hand which I've approach several others but all of them gives me different insights to this probability question. Here it is, The incidence of a suspicious transaction in a bank is 1 in 149 . They are able to correctly identify a legitimate transaction 92% of the time. However, this bank is also able to correctly pinpoint a suspicious transaction 92% of the time. One day, the bank identify a transaction as suspicious. What is the exact probability of the transaction actually being legitimate? From my personal point of view, if the question ask for the probability of the transaction actually being legitimate, states that the rate is  148⁄ 149 . The bank is able to correctly identify (which they fail to) a legitimate and suspicious transaction. Therefore, the failure % should be (8% * 8%) which is 0.08 * 0.08 = 0.0064. Hence, the probability of it actually being legitimate is 148⁄ 149 * 0.0064 = 0.00636 . However, i asked various people of their opinion and some states that the probability should be just 148⁄ 149 * 0.08 . Therefore, what should be the most probable answer to problems like this.","I've an interesting question on my hand which I've approach several others but all of them gives me different insights to this probability question. Here it is, The incidence of a suspicious transaction in a bank is 1 in 149 . They are able to correctly identify a legitimate transaction 92% of the time. However, this bank is also able to correctly pinpoint a suspicious transaction 92% of the time. One day, the bank identify a transaction as suspicious. What is the exact probability of the transaction actually being legitimate? From my personal point of view, if the question ask for the probability of the transaction actually being legitimate, states that the rate is  148⁄ 149 . The bank is able to correctly identify (which they fail to) a legitimate and suspicious transaction. Therefore, the failure % should be (8% * 8%) which is 0.08 * 0.08 = 0.0064. Hence, the probability of it actually being legitimate is 148⁄ 149 * 0.0064 = 0.00636 . However, i asked various people of their opinion and some states that the probability should be just 148⁄ 149 * 0.08 . Therefore, what should be the most probable answer to problems like this.",,['probability']
60,Two people A and B throwing dice,Two people A and B throwing dice,,"A begins by throwing a dice until he gets $6$, then B does the same thing. What is the probability that A throws more times than B? I try to solve it, but I got 2 different answers: 1. We mark: $X=$How many times A throws, $Y$=How many times B throws. $$P(X>n|Y=n)=\frac{P(X>n)\cdot P(Y=n)}{P(Y=n)}=P(X>n)\\ \sum_{k=n}^\infty\left(\frac56\right)^{k-1}\cdot \left(\frac16\right)=\left(\frac65\right)^{1-n}=\left(\frac56\right)^{n-1}$$ 2. The second way is: We can say that ""B throw less times than A"", so let's assume that A throws the dice $n$ times. So: $$P(Y<n)=\sum_{k=1}^{n-1}\left(\frac56\right)^{k-1}\cdot \left(\frac16\right)=1-\left(\frac56\right)^{n}$$ They are opposite, and I don't know which one of them is correct or both of them are incorrect.. Please help with this. Thank you!","A begins by throwing a dice until he gets $6$, then B does the same thing. What is the probability that A throws more times than B? I try to solve it, but I got 2 different answers: 1. We mark: $X=$How many times A throws, $Y$=How many times B throws. $$P(X>n|Y=n)=\frac{P(X>n)\cdot P(Y=n)}{P(Y=n)}=P(X>n)\\ \sum_{k=n}^\infty\left(\frac56\right)^{k-1}\cdot \left(\frac16\right)=\left(\frac65\right)^{1-n}=\left(\frac56\right)^{n-1}$$ 2. The second way is: We can say that ""B throw less times than A"", so let's assume that A throws the dice $n$ times. So: $$P(Y<n)=\sum_{k=1}^{n-1}\left(\frac56\right)^{k-1}\cdot \left(\frac16\right)=1-\left(\frac56\right)^{n}$$ They are opposite, and I don't know which one of them is correct or both of them are incorrect.. Please help with this. Thank you!",,['probability']
61,Probability of collecting all 5 buying 7 chocolates,Probability of collecting all 5 buying 7 chocolates,,"I'm struggling to find where I made a mistake on the way to solving the following problem. Problem description : A grocery sells chocolates bars. There are $5$ kinds of stickers. Each chocolate is sold with $1$ sticker of one of these $5$ kinds. The probability to find any kind of stickers in any chocolate bar is the same. What's the probability of collecting all $5$ types of stickers if you buy $7$ chocolates at once? My solution : since the order of chocolate bars that I've bought is irrelevant, the total number of 7-chocolate bar sets that I can buy equals $$\left(\binom{5}{7}\right)=\binom{7+5-1}{7}=\binom{11}{7}=330$$ Now I'm solving the reverse problem: let's calculate the probability of failing to collect all $5$ kinds of stickers. To do that I need to calculate the number of 7-chocolate bar sets that have less than $5$ kinds of stickers, which means that I need sets with only $1$ kind of stickers, $2$ , $3$ and $4$ . Since, again, the order of chocolate bars doesn't matter, the number of such sets is $$\left(\binom{4}{7}\right)=\binom{7+4-1}{7}=\binom{10}{7}=120$$ Finally, my answer to the initial problem should be $P = 1 - \frac{120}{330}= 0.6363636364$ The answer key says it's $\approx 0.215$ Where's the flaw in my solution? I appreciate any help.","I'm struggling to find where I made a mistake on the way to solving the following problem. Problem description : A grocery sells chocolates bars. There are kinds of stickers. Each chocolate is sold with sticker of one of these kinds. The probability to find any kind of stickers in any chocolate bar is the same. What's the probability of collecting all types of stickers if you buy chocolates at once? My solution : since the order of chocolate bars that I've bought is irrelevant, the total number of 7-chocolate bar sets that I can buy equals Now I'm solving the reverse problem: let's calculate the probability of failing to collect all kinds of stickers. To do that I need to calculate the number of 7-chocolate bar sets that have less than kinds of stickers, which means that I need sets with only kind of stickers, , and . Since, again, the order of chocolate bars doesn't matter, the number of such sets is Finally, my answer to the initial problem should be The answer key says it's Where's the flaw in my solution? I appreciate any help.",5 1 5 5 7 \left(\binom{5}{7}\right)=\binom{7+5-1}{7}=\binom{11}{7}=330 5 5 1 2 3 4 \left(\binom{4}{7}\right)=\binom{7+4-1}{7}=\binom{10}{7}=120 P = 1 - \frac{120}{330}= 0.6363636364 \approx 0.215,"['probability', 'combinatorics']"
62,Frequency of the Prime Numbers,Frequency of the Prime Numbers,,"Suppose I took all natural numbers less than or equal to $x$ and I picked one at random. Is there a way that we know of to express the probability that my number is prime in terms of $x$, for all $x$? For example, for $x=12$, the prime numbers less than or equal to $x$ are $2,3,5,7$ and $11$, so my probability is $5/12$.","Suppose I took all natural numbers less than or equal to $x$ and I picked one at random. Is there a way that we know of to express the probability that my number is prime in terms of $x$, for all $x$? For example, for $x=12$, the prime numbers less than or equal to $x$ are $2,3,5,7$ and $11$, so my probability is $5/12$.",,"['probability', 'number-theory', 'prime-numbers']"
63,What is the probability that white balls will be in the same box? [closed],What is the probability that white balls will be in the same box? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I have trouble computing a probability, I wish someone can help me with this. This is not a homework or anything like that. So there are $71$ balls, and two of them are white, the rest are black. The balls are randomly distributed between $14$ boxes. $5$ balls in each box, one box will have $6$ balls. What is the probability that white balls will be in the same box?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I have trouble computing a probability, I wish someone can help me with this. This is not a homework or anything like that. So there are $71$ balls, and two of them are white, the rest are black. The balls are randomly distributed between $14$ boxes. $5$ balls in each box, one box will have $6$ balls. What is the probability that white balls will be in the same box?",,['probability']
64,How to prove independence is not a transitive relation?,How to prove independence is not a transitive relation?,,"Suppose $A$ and $B$ are independent, and $B$ and $C$ are independent. Is $B$ independent of $A \cap C$?  Is $B$ independent of $A \cup C$? If so, prove. If not so, give a counterexample. Could someone give some hints on how to prove them? I am quite confused about them.","Suppose $A$ and $B$ are independent, and $B$ and $C$ are independent. Is $B$ independent of $A \cap C$?  Is $B$ independent of $A \cup C$? If so, prove. If not so, give a counterexample. Could someone give some hints on how to prove them? I am quite confused about them.",,"['probability', 'independence']"
65,Sum of conditional probabilities equals 1?,Sum of conditional probabilities equals 1?,,"Assuming that sum of probabilities for all possible events that can occur should sum to 1, how does one denote this for a conditional probability? Is it $P(A|E_1) + P(A|E_2) + ... = 1$, where $E_i$ is a specific event to be conditioned on? Or is the answer something else entirely?","Assuming that sum of probabilities for all possible events that can occur should sum to 1, how does one denote this for a conditional probability? Is it $P(A|E_1) + P(A|E_2) + ... = 1$, where $E_i$ is a specific event to be conditioned on? Or is the answer something else entirely?",,"['probability', 'probability-theory', 'conditional-probability']"
66,Probability that the two segments intersect,Probability that the two segments intersect,,P and Q are uniformly distributed in a square of side AB. What is the probability that segments AP and BQ  intersect?,P and Q are uniformly distributed in a square of side AB. What is the probability that segments AP and BQ  intersect?,,"['probability', 'geometry']"
67,Calculate probability density function from moment generating function,Calculate probability density function from moment generating function,,"I have moment generating function $$ M_z (t) = \dfrac {\lambda^2} {(\lambda-at) (\lambda-t)}, $$ and I'm trying to calculate the PDF from this function. I feel like some kind of inverse transform is required here, but I can't figure it out.","I have moment generating function $$ M_z (t) = \dfrac {\lambda^2} {(\lambda-at) (\lambda-t)}, $$ and I'm trying to calculate the PDF from this function. I feel like some kind of inverse transform is required here, but I can't figure it out.",,"['probability', 'statistics']"
68,Proof of Chebyshev Inequality,Proof of Chebyshev Inequality,,I was going through the proof of the Chebyshev Inequality here . And I seem to be facing some trouble in the approximation stage. I can't seem to follow how $\epsilon$ has been approximated to $(t-\mu)$.,I was going through the proof of the Chebyshev Inequality here . And I seem to be facing some trouble in the approximation stage. I can't seem to follow how $\epsilon$ has been approximated to $(t-\mu)$.,,"['probability', 'inequality']"
69,An unbiased coin is tossed six times in a row. Which statement describing the last two coin tosses has the highest probability of being correct?,An unbiased coin is tossed six times in a row. Which statement describing the last two coin tosses has the highest probability of being correct?,,"An unbiased coin is tossed six times in a row and four different such trials are conducted. One trial implies six tosses of the coin. If H stands for head and T stands for tail, the following are the observations from the four trials:   $$\text{(1) HTHTHT}\quad\text{(2) TTHHHT}\quad\text{(3) HTTHHT}\quad\text{(4) HHHT_ _}$$   Which statement describing the last two coin tosses of the fourth trial has the highest probability of being correct? (A) Two $\text T$ will occur. (B) One $\text H$ and one $\text T$ will occur. (C) Two $\text H$ will occur. (D) One $\text H$ will be followed by one $\text T$. I think option A is correct and the reason is statistical regularity. Am I correct? If not then please help me how to do this problem. Any help would be appreciated. Thanks in advance.","An unbiased coin is tossed six times in a row and four different such trials are conducted. One trial implies six tosses of the coin. If H stands for head and T stands for tail, the following are the observations from the four trials:   $$\text{(1) HTHTHT}\quad\text{(2) TTHHHT}\quad\text{(3) HTTHHT}\quad\text{(4) HHHT_ _}$$   Which statement describing the last two coin tosses of the fourth trial has the highest probability of being correct? (A) Two $\text T$ will occur. (B) One $\text H$ and one $\text T$ will occur. (C) Two $\text H$ will occur. (D) One $\text H$ will be followed by one $\text T$. I think option A is correct and the reason is statistical regularity. Am I correct? If not then please help me how to do this problem. Any help would be appreciated. Thanks in advance.",,"['probability', 'combinatorics']"
70,A fair coin is tossed untill head appears for the first time. What is probability that the number of tosses required is odd? [duplicate],A fair coin is tossed untill head appears for the first time. What is probability that the number of tosses required is odd? [duplicate],,This question already has answers here : A fair coin is tossed until a head comes up for the first time. The probability of this happening on an odd number toss is? (3 answers) Closed 3 years ago . Q. A fair coin is tossed untill head appears for the first time. What is probability that the number of tosses required is odd? My work: suppose that head comes in first toss so probability of getting head in the first toss $=\dfrac{1}{2}$ suppose that first & second tosses show tails & third toss shows head so  probability of getting head in the third toss $=(1-\dfrac12)(1-\dfrac12)\dfrac{1}{2}$ $=\dfrac1{2^3}$ suppose that first 4 tosses show tails & fifth toss shows head so  probability of getting head in the fifth toss $=(1-\dfrac12)^4\dfrac{1}{2}$ $=\dfrac1{2^5}$ suppose that first 6 tosses show tails & seventh toss shows head so  probability of getting head in the fifth toss $=(1-\dfrac12)^6\dfrac{1}{2}$ $=\dfrac1{2^7}$ ……………. and so on But I am not able to find the final probability of getting head first time so that the number of tosses required is odd.  what should do I next to it? please help me.,This question already has answers here : A fair coin is tossed until a head comes up for the first time. The probability of this happening on an odd number toss is? (3 answers) Closed 3 years ago . Q. A fair coin is tossed untill head appears for the first time. What is probability that the number of tosses required is odd? My work: suppose that head comes in first toss so probability of getting head in the first toss suppose that first & second tosses show tails & third toss shows head so  probability of getting head in the third toss suppose that first 4 tosses show tails & fifth toss shows head so  probability of getting head in the fifth toss suppose that first 6 tosses show tails & seventh toss shows head so  probability of getting head in the fifth toss ……………. and so on But I am not able to find the final probability of getting head first time so that the number of tosses required is odd.  what should do I next to it? please help me.,=\dfrac{1}{2} =(1-\dfrac12)(1-\dfrac12)\dfrac{1}{2} =\dfrac1{2^3} =(1-\dfrac12)^4\dfrac{1}{2} =\dfrac1{2^5} =(1-\dfrac12)^6\dfrac{1}{2} =\dfrac1{2^7},['probability']
71,Why probability of picking a random prime is 0? [duplicate],Why probability of picking a random prime is 0? [duplicate],,"This question already has answers here : Why does ""the probability of a random natural number being prime"" make no sense? (5 answers) Closed 5 years ago . ""It's well known that there are infinitely many prime numbers, but   they become rare, even by the time you get to the 100s,"" Ono explains.   ""In fact, out of the first 100,000 numbers, only 9,592 are prime   numbers, or roughly 9.5 percent. And they rapidly become rarer from   there. The probability of picking a number at random and having it   be prime is zero. It almost never happens."" --Source: phys.org I feel really skeptical about the statement in bold above. I think the probability tends to approach zero but can never be zero. Please explain how the probability is being calculated mathematically?","This question already has answers here : Why does ""the probability of a random natural number being prime"" make no sense? (5 answers) Closed 5 years ago . ""It's well known that there are infinitely many prime numbers, but   they become rare, even by the time you get to the 100s,"" Ono explains.   ""In fact, out of the first 100,000 numbers, only 9,592 are prime   numbers, or roughly 9.5 percent. And they rapidly become rarer from   there. The probability of picking a number at random and having it   be prime is zero. It almost never happens."" --Source: phys.org I feel really skeptical about the statement in bold above. I think the probability tends to approach zero but can never be zero. Please explain how the probability is being calculated mathematically?",,"['probability', 'number-theory', 'prime-numbers', 'analytic-number-theory']"
72,Drawing without replacement: why is the order of draw irrelevant?,Drawing without replacement: why is the order of draw irrelevant?,,"I am trying to wrap my head around this problem: Daniel randomly chooses balls from the group of $6$ red and $4$ green. What is the probability that he picks $2$ red and $3$ green if balls are drawn without replacement. What I remember from my college days that the probability is found by this formula: $$P(A)=\frac{\binom{6}{2}\binom{4}{3}}{\binom{10}{5}}=\frac{5}{21}$$ Is this correct? I am trying to understand why this works. Wouldn't probability depend on the order of balls drawn as the number of balls is changing after each draw? I get how we obtain numerator and denominator, I just feel that the probability should be dependent on the order. For example, the probability to pick red first is $\frac{6}{10}$ so the probability for the second draw becomes $\frac{5}{9}$ for red and $\frac{4}{9}$ for green. But if the first picked ball is green, the probability for the second draw becomes $\frac{6}{9}$ for red and $\frac{3}{9}$ for green. What am I missing?","I am trying to wrap my head around this problem: Daniel randomly chooses balls from the group of red and green. What is the probability that he picks red and green if balls are drawn without replacement. What I remember from my college days that the probability is found by this formula: Is this correct? I am trying to understand why this works. Wouldn't probability depend on the order of balls drawn as the number of balls is changing after each draw? I get how we obtain numerator and denominator, I just feel that the probability should be dependent on the order. For example, the probability to pick red first is so the probability for the second draw becomes for red and for green. But if the first picked ball is green, the probability for the second draw becomes for red and for green. What am I missing?",6 4 2 3 P(A)=\frac{\binom{6}{2}\binom{4}{3}}{\binom{10}{5}}=\frac{5}{21} \frac{6}{10} \frac{5}{9} \frac{4}{9} \frac{6}{9} \frac{3}{9},"['probability', 'probability-theory']"
73,Average wait time arriving at subway randomly,Average wait time arriving at subway randomly,,"If the subway comes every 10 minutes on average, what is the expected wait time if I arrive at the station randomly?  Can someone help me mathematically understand this problem?","If the subway comes every 10 minutes on average, what is the expected wait time if I arrive at the station randomly?  Can someone help me mathematically understand this problem?",,"['probability', 'statistics']"
74,"Given 4 red, 3 white and 5 black balls. Picking balls one by one without replacement, find the chance that red balls are exhausted first.","Given 4 red, 3 white and 5 black balls. Picking balls one by one without replacement, find the chance that red balls are exhausted first.",,"We need to find the probability that all the red balls are exhausted before the white or black balls are exhausted. So, we can still pick white or black balls, but we cannot pick ALL of the white/black balls. I tried going case by case but quickly realized there are way too many cases for that. I'm not very good at permutations and combinations so I can't figure out how to get in all the cases. Few example cases can be: R R R W B W B R, B B B W B R R R R, etc.","We need to find the probability that all the red balls are exhausted before the white or black balls are exhausted. So, we can still pick white or black balls, but we cannot pick ALL of the white/black balls. I tried going case by case but quickly realized there are way too many cases for that. I'm not very good at permutations and combinations so I can't figure out how to get in all the cases. Few example cases can be: R R R W B W B R, B B B W B R R R R, etc.",,"['probability', 'combinations']"
75,Probability of a number being rational,Probability of a number being rational,,"If $x \in [0, 1]$ , what is $\text{P}(x\in \mathbb Q)$ ?    In other words, what is the probability that $x$ is rational? This is what I tried: $$\begin{array}{rcl}\text{P}(x \in \mathbb Q) &=& \displaystyle \int^1_0 f(x)\,dx \end{array}$$ where $$f(x) = \begin{cases}1, & x \in \mathbb Q\\0, & x\notin\mathbb Q\end{cases}$$ However, the function is not Riemann-integrable. I want to try comparing the cardinalities of the rational set and the irrational set by using a one-to-one mapping between the two sets. But I don't have idea how I can do it. Can anyone give a hint?","If , what is ?    In other words, what is the probability that is rational? This is what I tried: where However, the function is not Riemann-integrable. I want to try comparing the cardinalities of the rational set and the irrational set by using a one-to-one mapping between the two sets. But I don't have idea how I can do it. Can anyone give a hint?","x \in [0, 1] \text{P}(x\in \mathbb Q) x \begin{array}{rcl}\text{P}(x \in \mathbb Q) &=& \displaystyle \int^1_0 f(x)\,dx
\end{array} f(x) = \begin{cases}1, & x \in \mathbb Q\\0, & x\notin\mathbb Q\end{cases}","['probability', 'integration', 'elementary-set-theory', 'rational-numbers']"
76,A die is rolled 3 times. What is the probability that a five is rolled at least twice?,A die is rolled 3 times. What is the probability that a five is rolled at least twice?,,"The probability of not getting a five is $(\frac56)^3$, and I figure the probability of getting at least one 5 is $1-(\frac56)^3$, but I don't know how to figure out if it is rolled at least twice. Thoughts? Thanks in advance!","The probability of not getting a five is $(\frac56)^3$, and I figure the probability of getting at least one 5 is $1-(\frac56)^3$, but I don't know how to figure out if it is rolled at least twice. Thoughts? Thanks in advance!",,"['probability', 'combinatorics', 'discrete-mathematics']"
77,"Probability that given a 1000 page book with 1000 misprints, a page will have 3 misprints.","Probability that given a 1000 page book with 1000 misprints, a page will have 3 misprints.",,Setting A book of 1000 pages contains 1000 misprints. Estimate the chances that a given page contains at least three misprints. Solution My solution is $$\binom{1000}{1}\left(\frac{1}{1000}\right)^3\left(\frac{999}{1000}\right)^{1000 - 3}$$ Please confirm?,Setting A book of 1000 pages contains 1000 misprints. Estimate the chances that a given page contains at least three misprints. Solution My solution is $$\binom{1000}{1}\left(\frac{1}{1000}\right)^3\left(\frac{999}{1000}\right)^{1000 - 3}$$ Please confirm?,,"['probability', 'probability-distributions', 'binomial-coefficients']"
78,What's the probability that the other side of the coin is gold?,What's the probability that the other side of the coin is gold?,,"4 coins are in a bucket: 1 is gold on both sides, 1 is silver on both sides, and 2 are gold on one side and silver on the other side. I randomly grab a coin from the bucket and see that the side facing me is gold. What is the probability that the other side of the coin is gold? I had thought that the probability is $\frac{1}{3}$ because there are 3 coins with at least one side of gold, and only 1 of these 3 coins can be gold on the other side. However, I suspect that the sides might be unique, which derails my previous logic.","4 coins are in a bucket: 1 is gold on both sides, 1 is silver on both sides, and 2 are gold on one side and silver on the other side. I randomly grab a coin from the bucket and see that the side facing me is gold. What is the probability that the other side of the coin is gold? I had thought that the probability is $\frac{1}{3}$ because there are 3 coins with at least one side of gold, and only 1 of these 3 coins can be gold on the other side. However, I suspect that the sides might be unique, which derails my previous logic.",,['probability']
79,What are the odds of rolling a 3 number straight throwing 6d6,What are the odds of rolling a 3 number straight throwing 6d6,,"If you throw six fair dice, what are the odds that at least three dice make a straight (i.e. 123, 234, 345, or 456) I am certain that I am making a mistake in calculating it?","If you throw six fair dice, what are the odds that at least three dice make a straight (i.e. 123, 234, 345, or 456) I am certain that I am making a mistake in calculating it?",,['probability']
80,Convergence of Student's t-distribution to a standard normal,Convergence of Student's t-distribution to a standard normal,,"I was looking at this question where it is shown that a Student's t-distribution converges to a standard normal distribution as the degrees of freedom tend to infinity.We start with the Student's t-distribution: $$f_T(t) = \frac{\Gamma\left(\frac{k+1}{2}\right)}{\sqrt{k\pi}\Gamma\left(\frac{k}{2}\right)}\left(1+\frac{t^2}{k}\right)^{-\frac{k+1}{2}}$$ for $t\in \mathbb{R}$ and where $k$ represent the degrees of freedom. Then let $k \to \infty$ so \begin{align} \lim_{k \to \infty} f_T(t) &= \lim_{k \to \infty} \frac{\Gamma\left(\frac{k+1}{2}\right)}{\sqrt{k\pi}\Gamma\left(\frac{k}{2}\right)}\left(1+\frac{t^2}{k}\right)^{-\frac{k+1}{2}}\\ &= \lim_{k \to \infty}\frac{\Gamma\left(\frac{k+1}{2}\right)}{\sqrt{k\pi}\Gamma\left(\frac{k}{2}\right)}\cdot \lim_{k \to \infty}\left(1+\frac{t^2}{k}\right)^{-\frac{k+1}{2}} \end{align} and then the answer suggests that using Stirlings approximation gets us that $$\lim_{k \to \infty}\frac{\Gamma\left(\frac{k+1}{2}\right)}{\sqrt{k\pi}\Gamma\left(\frac{k}{2}\right)}=\frac{1}{\sqrt{\pi}}\lim_{k \to \infty} \frac{\sqrt{k/2}}{\sqrt{k}} \tag{1}$$ I tried using the fact that, for big $k$ we have that $$\Gamma(k) \approx \sqrt{\frac{2 \pi}{k}}\left(\frac{k}{e} \right)^k $$ but simply couldn't make the algebra work. How can we see that $(1)$ is true? Any help is appreciated.","I was looking at this question where it is shown that a Student's t-distribution converges to a standard normal distribution as the degrees of freedom tend to infinity.We start with the Student's t-distribution: for and where represent the degrees of freedom. Then let so and then the answer suggests that using Stirlings approximation gets us that I tried using the fact that, for big we have that but simply couldn't make the algebra work. How can we see that is true? Any help is appreciated.","f_T(t) = \frac{\Gamma\left(\frac{k+1}{2}\right)}{\sqrt{k\pi}\Gamma\left(\frac{k}{2}\right)}\left(1+\frac{t^2}{k}\right)^{-\frac{k+1}{2}} t\in \mathbb{R} k k \to \infty \begin{align}
\lim_{k \to \infty} f_T(t) &= \lim_{k \to \infty} \frac{\Gamma\left(\frac{k+1}{2}\right)}{\sqrt{k\pi}\Gamma\left(\frac{k}{2}\right)}\left(1+\frac{t^2}{k}\right)^{-\frac{k+1}{2}}\\
&= \lim_{k \to \infty}\frac{\Gamma\left(\frac{k+1}{2}\right)}{\sqrt{k\pi}\Gamma\left(\frac{k}{2}\right)}\cdot \lim_{k \to \infty}\left(1+\frac{t^2}{k}\right)^{-\frac{k+1}{2}}
\end{align} \lim_{k \to \infty}\frac{\Gamma\left(\frac{k+1}{2}\right)}{\sqrt{k\pi}\Gamma\left(\frac{k}{2}\right)}=\frac{1}{\sqrt{\pi}}\lim_{k \to \infty} \frac{\sqrt{k/2}}{\sqrt{k}} \tag{1} k \Gamma(k) \approx \sqrt{\frac{2 \pi}{k}}\left(\frac{k}{e} \right)^k  (1)","['probability', 'proof-explanation']"
81,Monty Hall Problem-Probability Paradox,Monty Hall Problem-Probability Paradox,,"I just learned about the Monty Hall Problem and it seemed pretty much amazing to me.I am just a bit confused with it. So,according to the problem we are on a game show, and we are given the choice of three doors: Behind one of them is a car and behind the others are goats. We start by picking one of the doors. After our selection, the host, who knows what's behind the doors reaveals one of the other two doors that has a goat. Now we are asked if we want to change our mind or stay with our initial pick. According to Probabilities, if we don't swap and keep our first selection we get $(1/3)$ $33.3\% $ chance of wining the car since the elimination of the door that was opened by the host doesn't affect the probability of our door having the car which remains $33.3\%$ as it is at the initial problem. On the other hand, if we switch the door with the other one left , then we get $(2/3)$ $66.6\%$ chances of wining the car since only two doors are remaining and the fact that the host revealed a goat in one of the unchosen doors changed nothing about the initial probability of our door having the car. Till this point it makes pretty much sense to me. But what about assuming we have a man in the audience that makes a different initial choice in his head. For instance, let's say that the contestant picked door number $1$ and he picked door number $2$ . If door number $3$ is the door that is being revealed by the host (has a goat) then both doors $1$ and $2$ remain in the game. For the contestant door number $2$ has $66.6\%$ chances of having the car when for the man in the audience door number $1$ has $66.6\%$ chances of having the car. Isn't that weird? From two different perspectives we get two different probabilities about the same unopened doors. How's that possible?","I just learned about the Monty Hall Problem and it seemed pretty much amazing to me.I am just a bit confused with it. So,according to the problem we are on a game show, and we are given the choice of three doors: Behind one of them is a car and behind the others are goats. We start by picking one of the doors. After our selection, the host, who knows what's behind the doors reaveals one of the other two doors that has a goat. Now we are asked if we want to change our mind or stay with our initial pick. According to Probabilities, if we don't swap and keep our first selection we get chance of wining the car since the elimination of the door that was opened by the host doesn't affect the probability of our door having the car which remains as it is at the initial problem. On the other hand, if we switch the door with the other one left , then we get chances of wining the car since only two doors are remaining and the fact that the host revealed a goat in one of the unchosen doors changed nothing about the initial probability of our door having the car. Till this point it makes pretty much sense to me. But what about assuming we have a man in the audience that makes a different initial choice in his head. For instance, let's say that the contestant picked door number and he picked door number . If door number is the door that is being revealed by the host (has a goat) then both doors and remain in the game. For the contestant door number has chances of having the car when for the man in the audience door number has chances of having the car. Isn't that weird? From two different perspectives we get two different probabilities about the same unopened doors. How's that possible?",(1/3) 33.3\%  33.3\% (2/3) 66.6\% 1 2 3 1 2 2 66.6\% 1 66.6\%,"['probability', 'bayes-theorem', 'monty-hall']"
82,Having difficulty understanding probabilities in this question,Having difficulty understanding probabilities in this question,,"Question: Given $5$ people in an elevator on the ground floor, and the buttons for the second, third, and forth floors are lit, what is the probability that two people will exit the elevator at floor $3$? Maths noob here. I have spent about $10$ minutes trying to come up with a solution to this question. I intuitively think the answer is $0.6$ but I lack the tools to reason about it properly. Any help? Apologies for the ""please do my work for me"" question.","Question: Given $5$ people in an elevator on the ground floor, and the buttons for the second, third, and forth floors are lit, what is the probability that two people will exit the elevator at floor $3$? Maths noob here. I have spent about $10$ minutes trying to come up with a solution to this question. I intuitively think the answer is $0.6$ but I lack the tools to reason about it properly. Any help? Apologies for the ""please do my work for me"" question.",,['probability']
83,High-School level probability and logic problem,High-School level probability and logic problem,,"So the other day I took a math test, (not for class, its just an optional test, so this isn't and kind of cheating) which included all kinds of logical and problem solving exercises, among others this one: -""Given a deck of cards with N cards in it and each card is numbered (so the cards are 1, 2, 3, 4, ... nth card). Two cards are drawn one after each other. What is the probability that the when a third card is drawn, that this third cards number is in between the first card's and the second card's number."" I had done most of this test without problems but I just couldn't get around the fact that N (the number of cards) is unknown, so I'm not sure if the result should be a function of N or whether its an independent number. Any kind of help is greatly appreciated!  I can post some more of the questions if anyone is willing to see, the exam is something a teacher does for those students who want to stay after school and test out their logical and problem solving skills","So the other day I took a math test, (not for class, its just an optional test, so this isn't and kind of cheating) which included all kinds of logical and problem solving exercises, among others this one: -""Given a deck of cards with N cards in it and each card is numbered (so the cards are 1, 2, 3, 4, ... nth card). Two cards are drawn one after each other. What is the probability that the when a third card is drawn, that this third cards number is in between the first card's and the second card's number."" I had done most of this test without problems but I just couldn't get around the fact that N (the number of cards) is unknown, so I'm not sure if the result should be a function of N or whether its an independent number. Any kind of help is greatly appreciated!  I can post some more of the questions if anyone is willing to see, the exam is something a teacher does for those students who want to stay after school and test out their logical and problem solving skills",,"['probability', 'problem-solving']"
84,How awful is the awful magician?,How awful is the awful magician?,,"There is a magician (who is totally not me), who shuffles a standard deck of cards (52 cards, four suits). A volunteer from the crowds chooses a card at random, reinserts into the package, and reshuffles. The awful magician, being awful, starts from the top of the pack. ""Is this your card?"" ""No."" The next card, and the question repeats. On and on, until finally, the volunteer's card reveals itself. Much to the excitement of everyone, that they get to go home. In this scenario, which is totally not based on real life, what is the expected value of attempts by the awful magician before they manage to bedazzle their audience? Just to make things slightly more mathematical, the volunteer picks a card at random, then reshuffles the pack. So the question can be recast as given a number $n$ between $1$ and $52$ , and a permutation $\pi$ of $\{1,\dots,52\}$ , what is the expected value for $\pi^{-1}(n)$ ? (The questions comes from playing with a deck of cards, and thinking about Michael Stevens' Vsauce video regarding card tricks, where he cites Scott Czepiel about $52!$ .)","There is a magician (who is totally not me), who shuffles a standard deck of cards (52 cards, four suits). A volunteer from the crowds chooses a card at random, reinserts into the package, and reshuffles. The awful magician, being awful, starts from the top of the pack. ""Is this your card?"" ""No."" The next card, and the question repeats. On and on, until finally, the volunteer's card reveals itself. Much to the excitement of everyone, that they get to go home. In this scenario, which is totally not based on real life, what is the expected value of attempts by the awful magician before they manage to bedazzle their audience? Just to make things slightly more mathematical, the volunteer picks a card at random, then reshuffles the pack. So the question can be recast as given a number between and , and a permutation of , what is the expected value for ? (The questions comes from playing with a deck of cards, and thinking about Michael Stevens' Vsauce video regarding card tricks, where he cites Scott Czepiel about .)","n 1 52 \pi \{1,\dots,52\} \pi^{-1}(n) 52!","['probability', 'expected-value']"
85,Sum of two independent geometric random variables,Sum of two independent geometric random variables,,"Let X and Y be independent random variables, $  P(X = k) = P(Y = k) = p(1 - p)^{k-1} $ How do you show that the pmf of $ Z = X + Y $, is negative binomial, and how do you find $ P(X = Y) $?","Let X and Y be independent random variables, $  P(X = k) = P(Y = k) = p(1 - p)^{k-1} $ How do you show that the pmf of $ Z = X + Y $, is negative binomial, and how do you find $ P(X = Y) $?",,"['probability', 'statistics']"
86,What is the tail $\sigma$-field?,What is the tail -field?,\sigma,"In the book ""probability : example and application"", they define a tail $\sigma$ -field as $\mathcal T=\bigcap_{n=1}^\infty \mathcal F_n'$ where $\mathcal F_n'=\sigma (X_n,X_{n+1},...)$ . They call $\mathcal t$ remote future and say that $A\in \mathcal T$ if and only if changing a finite number of value do not affect the occurrence of the event. I don't really understand what they want to say by this last sentence. Changing an infinite value of what ? of $A$ ? Could someone explain me better what represent $\mathcal T$ and in hat it is interesting ? I have as example, If $B_n\in \mathcal B(\mathbb R)$ , then $\{X_n\in B_n\ \ i.o.\}\in \mathcal T$ , but I don't really understand why. Also, if $S_n=X_1+...+X_n$ , then $\{\lim_{n\to \infty }S_n\ exist\}\in \mathcal T$ but $\{\limsup_{n\to \infty }S_n>0\}\notin \mathcal T$ , and I also don't understand why.","In the book ""probability : example and application"", they define a tail -field as where . They call remote future and say that if and only if changing a finite number of value do not affect the occurrence of the event. I don't really understand what they want to say by this last sentence. Changing an infinite value of what ? of ? Could someone explain me better what represent and in hat it is interesting ? I have as example, If , then , but I don't really understand why. Also, if , then but , and I also don't understand why.","\sigma \mathcal T=\bigcap_{n=1}^\infty \mathcal F_n' \mathcal F_n'=\sigma (X_n,X_{n+1},...) \mathcal t A\in \mathcal T A \mathcal T B_n\in \mathcal B(\mathbb R) \{X_n\in B_n\ \ i.o.\}\in \mathcal T S_n=X_1+...+X_n \{\lim_{n\to \infty }S_n\ exist\}\in \mathcal T \{\limsup_{n\to \infty }S_n>0\}\notin \mathcal T",['probability']
87,Is it possible that two independent variables become dependent conditioning on a third random variable,Is it possible that two independent variables become dependent conditioning on a third random variable,,"Is that possible that random variables $X$ and $Y$ are independent but they are no longer independent if condition on another random variable $Z$? Is there a mathematical example and an approximate real life example for it? What does it mean intuitively that two random variables are independent but condition on another random variable, these two old random variables suddenly have relation? I was thinking about the following real life example.  Say a doctor wants to know if a new medicine is effective of reduce the blood pressure of the population (for all men and women). Let $Y_{1i}$ be the random variable represents the distribution of the blood pressure of the population if they all take the medicine and $Y_{0i}$ be the random variable represents the distribution of the blood pressure of the population if they all did not take the medicine. Let $D_i$ be the random outcome of the $i^{th}$ coin flip. So if it is head, then subject $i$ takes the medicine and if it is tail, then subject $i$ drinks pure water. So in this case, $D_i$ is independent of $Y_{1i}$, i.e., learning the value of $D_i$ does not help you to know better about the distribution of $Y_{1i}$. But now, what if I tell you subject $i$ is male, then condition on this information, will $D_i$ and $Y_{1i}$ be independent?","Is that possible that random variables $X$ and $Y$ are independent but they are no longer independent if condition on another random variable $Z$? Is there a mathematical example and an approximate real life example for it? What does it mean intuitively that two random variables are independent but condition on another random variable, these two old random variables suddenly have relation? I was thinking about the following real life example.  Say a doctor wants to know if a new medicine is effective of reduce the blood pressure of the population (for all men and women). Let $Y_{1i}$ be the random variable represents the distribution of the blood pressure of the population if they all take the medicine and $Y_{0i}$ be the random variable represents the distribution of the blood pressure of the population if they all did not take the medicine. Let $D_i$ be the random outcome of the $i^{th}$ coin flip. So if it is head, then subject $i$ takes the medicine and if it is tail, then subject $i$ drinks pure water. So in this case, $D_i$ is independent of $Y_{1i}$, i.e., learning the value of $D_i$ does not help you to know better about the distribution of $Y_{1i}$. But now, what if I tell you subject $i$ is male, then condition on this information, will $D_i$ and $Y_{1i}$ be independent?",,"['probability', 'probability-theory', 'independence']"
88,60 balls in a bag,60 balls in a bag,,"I have a question, but I also have the solution. My problem is that I don't understand the solution! Question: There are 10 red, 20 blue, 30 green balls in a bag. You keep removing balls at random. What is the probability that when you take the last red one out there is at least one green one and one blue ball remaining? Answer: The easy way to do this is to reverse the order. The question is then what is the probability that a blue ball and a green ball are drawn before the first red ball. Once a ball of a given colour is drawn, it can be ignored as further draws don't affect the problem. The solution then calculates the probability to this reverse order question to be 17/24. How does this reverse order question relate to the original question?","I have a question, but I also have the solution. My problem is that I don't understand the solution! Question: There are 10 red, 20 blue, 30 green balls in a bag. You keep removing balls at random. What is the probability that when you take the last red one out there is at least one green one and one blue ball remaining? Answer: The easy way to do this is to reverse the order. The question is then what is the probability that a blue ball and a green ball are drawn before the first red ball. Once a ball of a given colour is drawn, it can be ignored as further draws don't affect the problem. The solution then calculates the probability to this reverse order question to be 17/24. How does this reverse order question relate to the original question?",,['probability']
89,"Is there a symbol for ""dependent""?","Is there a symbol for ""dependent""?",,"For random variables $A$ and $B$ , $A \perp B$ is sometimes used to denote ""A is independent of B"".  Is there a symbol that is commonly used to mean ""A is not independent of B""?","For random variables and , is sometimes used to denote ""A is independent of B"".  Is there a symbol that is commonly used to mean ""A is not independent of B""?",A B A \perp B,"['probability', 'notation']"
90,Does $Var(X^2) \geq (VarX)^2$ hold?,Does  hold?,Var(X^2) \geq (VarX)^2,"It is well known that $E(X^2) \geq (EX)^2$, but I was wondering if there is a similar result for variances, e.g. is $Var(X^2) \geq (VarX)^2$? I was doing some research and came up with that inequality, but I can’t prove it. I’ve done simulations in R for several known distributions (e.g. bernoulli, binomial, poisson, normal, gamma, t, exponential, all for few parameters) and they seem to show that it really does hold, but I’m not sure whether it holds generally. If this doesn’t hold, is there any other result that somehow links $Var(X^2)$ and $(VarX)^2$? EDIT: So, as H. H. Rugh showed in his answer, it can't hold generally, but it often does. I'm still interested in a reference to a different result that gives a certain link between the two expressions, or perhaps some sufficient conditions for the inequality, etc.","It is well known that $E(X^2) \geq (EX)^2$, but I was wondering if there is a similar result for variances, e.g. is $Var(X^2) \geq (VarX)^2$? I was doing some research and came up with that inequality, but I can’t prove it. I’ve done simulations in R for several known distributions (e.g. bernoulli, binomial, poisson, normal, gamma, t, exponential, all for few parameters) and they seem to show that it really does hold, but I’m not sure whether it holds generally. If this doesn’t hold, is there any other result that somehow links $Var(X^2)$ and $(VarX)^2$? EDIT: So, as H. H. Rugh showed in his answer, it can't hold generally, but it often does. I'm still interested in a reference to a different result that gives a certain link between the two expressions, or perhaps some sufficient conditions for the inequality, etc.",,['probability']
91,variance of the number of coin toss to get N heads in row,variance of the number of coin toss to get N heads in row,,The expected value of the number of coin toss to get N heads in a row is discussed here: How many flips of a fair coin does it take until you get N heads in a row? How can we find the variance?,The expected value of the number of coin toss to get N heads in a row is discussed here: How many flips of a fair coin does it take until you get N heads in a row? How can we find the variance?,,"['probability', 'probability-theory', 'probability-distributions']"
92,Median $\neq$ expectation,Median  expectation,\neq,Do you have an example of real random variable such that its median is remarkably different from its expectation? I'd like an example where it is obvious that they are different.,Do you have an example of real random variable such that its median is remarkably different from its expectation? I'd like an example where it is obvious that they are different.,,"['probability', 'expectation', 'median']"
93,Probability question about chords on a circle [closed],Probability question about chords on a circle [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Four points are chosen independently and at random on a circle. Find the probability that chords X1X2 and X3X4 intersect a) without calculation using a symmetry argument and b) from the definition by an integral I'm lost here. I'm thinking of using some kind of angle argument, but not sure how to go about it.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Four points are chosen independently and at random on a circle. Find the probability that chords X1X2 and X3X4 intersect a) without calculation using a symmetry argument and b) from the definition by an integral I'm lost here. I'm thinking of using some kind of angle argument, but not sure how to go about it.",,[]
94,Martingale / local martingale : some confusion,Martingale / local martingale : some confusion,,"For me, a stochastic $(M_t)_{t\in [0,T]}$ is a martingale (w.r.t. $(\Omega ,(\mathcal F_t)_t,\mathbb P)$ ) if $M_t$ is $\mathcal F_t$ adapted and $$\mathbb E[M_t\mid \mathcal F_s]=M_s,\quad s\leq t.$$ A local martingale is a stochastic process $(M_t)_t$ s.t. there are stoping times $(\tau_n)$ almost increasing s.t. $\tau_n\to \infty$ a.s. and s.t. $(M_{t\wedge \tau_n})_{t\geq 0}$ is a martingale for all $n$ . Q1) So at the end, if $(M_t)_{t\in [0,T]}$ is a martingale for all $T>0$ , then $(M_t)_{t\geq 0}$ is a local Martingale, right ? Q2) If $(M_t)_{t\in [0,T]}$ is not a martingale, can it be a local martingale in the sense that there are stopping time $(\tau_n)_n$ that are a.s. increasing s.t. $\tau_n\to t$ and $(M_{t\wedge \tau_n})_{t\geq 0}$ or not really ?","For me, a stochastic is a martingale (w.r.t. ) if is adapted and A local martingale is a stochastic process s.t. there are stoping times almost increasing s.t. a.s. and s.t. is a martingale for all . Q1) So at the end, if is a martingale for all , then is a local Martingale, right ? Q2) If is not a martingale, can it be a local martingale in the sense that there are stopping time that are a.s. increasing s.t. and or not really ?","(M_t)_{t\in [0,T]} (\Omega ,(\mathcal F_t)_t,\mathbb P) M_t \mathcal F_t \mathbb E[M_t\mid \mathcal F_s]=M_s,\quad s\leq t. (M_t)_t (\tau_n) \tau_n\to \infty (M_{t\wedge \tau_n})_{t\geq 0} n (M_t)_{t\in [0,T]} T>0 (M_t)_{t\geq 0} (M_t)_{t\in [0,T]} (\tau_n)_n \tau_n\to t (M_{t\wedge \tau_n})_{t\geq 0}","['probability', 'martingales']"
95,Need help interpreting this statement regarding probability,Need help interpreting this statement regarding probability,,"I was reading this text on probability and I have confusion interpreting a statement. The text reads as follows: Sampling is a very common technique for estimating the fraction of   elements in a set that have a certain property. For example, suppose   that you would like to know how many Americans plan to vote for the   Republican candidate in the next presidential election. It is   infeasible to ask every American how they intend to vote, so pollsters   will typically contact n Americans selected at random and then compute   the fraction of those Americans that will vote republican. This value   is then used as the estimate of the number of all Americans that will   vote Republican. For example, if 45% of the n contacted voters report   that they will vote Republican, the pollster reports that 45% of all   Americans will vote Republican. In addition, the pollster will usually   also provide some sort of qualifying statement such as ""There is a 95% probability that the poll is accurate to within (+/-)   4 percentage points."" Many people interpret the qualifying statement to mean that there is a   95% chance that between 41% and 49% of Americans intend to vote   Republican. But this is wrong! Later they do a bit of math and conclude with the actual meaning of that qualifying statement and thus say that: There is a 95% chance that the sample group will produce an estimate   that is within (+/-) 4 percentage points of the correct value for the   overall population. So either we were “unlucky” in selecting the   people to poll or the results of the poll will be correct to within   (+/-) 4 points. I don't see any difference between the two interpretations. Can anyone please help? What I understand from their last statement is that there is a 95% chance that the result they obtained from that particular sample group (i.e., 45% of Americans will vote Republican) is within (+/-) 4 % of the correct fraction (Let it be p). So in other words there is 95% chance that 'p' is between 0.41 and 0.49, which is precisely what the first interpretation (which they consider wrong) meant.","I was reading this text on probability and I have confusion interpreting a statement. The text reads as follows: Sampling is a very common technique for estimating the fraction of   elements in a set that have a certain property. For example, suppose   that you would like to know how many Americans plan to vote for the   Republican candidate in the next presidential election. It is   infeasible to ask every American how they intend to vote, so pollsters   will typically contact n Americans selected at random and then compute   the fraction of those Americans that will vote republican. This value   is then used as the estimate of the number of all Americans that will   vote Republican. For example, if 45% of the n contacted voters report   that they will vote Republican, the pollster reports that 45% of all   Americans will vote Republican. In addition, the pollster will usually   also provide some sort of qualifying statement such as ""There is a 95% probability that the poll is accurate to within (+/-)   4 percentage points."" Many people interpret the qualifying statement to mean that there is a   95% chance that between 41% and 49% of Americans intend to vote   Republican. But this is wrong! Later they do a bit of math and conclude with the actual meaning of that qualifying statement and thus say that: There is a 95% chance that the sample group will produce an estimate   that is within (+/-) 4 percentage points of the correct value for the   overall population. So either we were “unlucky” in selecting the   people to poll or the results of the poll will be correct to within   (+/-) 4 points. I don't see any difference between the two interpretations. Can anyone please help? What I understand from their last statement is that there is a 95% chance that the result they obtained from that particular sample group (i.e., 45% of Americans will vote Republican) is within (+/-) 4 % of the correct fraction (Let it be p). So in other words there is 95% chance that 'p' is between 0.41 and 0.49, which is precisely what the first interpretation (which they consider wrong) meant.",,"['probability', 'probability-theory', 'discrete-mathematics', 'sampling']"
96,Knockout tournament.,Knockout tournament.,,"P1, P2, P3, P4, P5, P6, P7, P8, P9, P10, P11, P12, P13, P14, P15, P16 are 16 players who play a knockout tournament. In any match between P(i) and P(j), P(i) wins if i is less than j. Find the probability that P6 reaches the final. I tried making cases, but they seem endless. We know for sure that P1 will win the tournament and P16 will be eliminated in the first round. But there are many other cases for the first round only. Please help.","P1, P2, P3, P4, P5, P6, P7, P8, P9, P10, P11, P12, P13, P14, P15, P16 are 16 players who play a knockout tournament. In any match between P(i) and P(j), P(i) wins if i is less than j. Find the probability that P6 reaches the final. I tried making cases, but they seem endless. We know for sure that P1 will win the tournament and P16 will be eliminated in the first round. But there are many other cases for the first round only. Please help.",,"['probability', 'probability-theory']"
97,The 9 step problem,The 9 step problem,,"A man can take a step forward, backward,left and right with equal probability. Find the probability that after 9 steps he will be just 1 step away from his initial point. I have done similar questions with movement restricted to forward and backward only ,but this one just blows my mind.","A man can take a step forward, backward,left and right with equal probability. Find the probability that after 9 steps he will be just 1 step away from his initial point. I have done similar questions with movement restricted to forward and backward only ,but this one just blows my mind.",,"['probability', 'combinatorics', 'summation']"
98,Probability that binomial random variable is even,Probability that binomial random variable is even,,"Suppose $X$ is binomial $B(n,p)$. How can I find the probability that $X$ is even ? I know $$P(X = k ) = \frac{ n!}{(n-k)!k!} p^k(1-p)^{n-k} $$ where $X=1,....,n$. Are they just asking to find $P(X = 2m )$ for some $m > 0$ ?","Suppose $X$ is binomial $B(n,p)$. How can I find the probability that $X$ is even ? I know $$P(X = k ) = \frac{ n!}{(n-k)!k!} p^k(1-p)^{n-k} $$ where $X=1,....,n$. Are they just asking to find $P(X = 2m )$ for some $m > 0$ ?",,[]
99,n people & n hats: probability that at least 1 person has his own hat,n people & n hats: probability that at least 1 person has his own hat,,"Suppose n people take n hats at random. What is the probability that   at least 1 person has his own hat? The proposed solution uses inclusion-exclusion principle and gives the answer: $$\sum^{n}_{r=1} (-1)^{r-1} \frac{1}{r!}$$ But I think there is simpler solution: let's calculate the complement, i.e. no one gets his own hat. Total number of ways of distribution hats = number of permutations of hats, i.e. $n!$ Number of ways when no one gets his own hat is calculated as follows: fix a person, he can choose among n-1 hats, then, fix another person, he has n-2 hats at his disposal, and so on. This leads to $(n-1)!$ Therefore, my answer is $1 - \frac{(n-1)!}{n!} = 1 - \frac{1}{n}$ which is wrong. My question is where did I make a mistake?","Suppose n people take n hats at random. What is the probability that   at least 1 person has his own hat? The proposed solution uses inclusion-exclusion principle and gives the answer: $$\sum^{n}_{r=1} (-1)^{r-1} \frac{1}{r!}$$ But I think there is simpler solution: let's calculate the complement, i.e. no one gets his own hat. Total number of ways of distribution hats = number of permutations of hats, i.e. $n!$ Number of ways when no one gets his own hat is calculated as follows: fix a person, he can choose among n-1 hats, then, fix another person, he has n-2 hats at his disposal, and so on. This leads to $(n-1)!$ Therefore, my answer is $1 - \frac{(n-1)!}{n!} = 1 - \frac{1}{n}$ which is wrong. My question is where did I make a mistake?",,"['probability', 'probability-theory']"
