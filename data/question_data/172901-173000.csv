,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Binomial Hypothesis Test,Binomial Hypothesis Test,,"The proportion of deaths due to lung cancer in working males aged 15-64   in Australia between 1970 and 1972 was 10%. There is reason to believe   that working in a chemical plant for an extended period can increase your   risk of lung cancer. Several Australian chemical plants were investigated,   and it was found that of 90 deaths in working males aged 15-64, 19 were   due to lung cancer. Is there evidence of increased risk of developing lung cancer if you work in   a chemical plant? For this hypothesis test, we are required to provide a statement of the null and alternative hypothesis, a test statistic, the observed value and the estimated $p$-value. My Attempt: let $p$ be the probability of developing lung cancer in a chemical plant. Therefore, $$H_0:p=0.1 \ \ \ \ \ \ \text{vs} \ \ \ \ \ \ \ H_1:p>0.1$$ Our test statistic is $$Z=\frac{\hat{p}-p}{\sqrt{\frac{p(1-p)}{n}}} \ \ \ \ \ \ \text{where} \ Z\sim N(0,1)$$ Our observed value is therefore $$\frac{\frac{\hat{p}}{n}-p}{\sqrt{\frac{p(1-p)}{n}}} =\frac{\frac{19}{90}-0.1}{\sqrt{\frac{0.1(1-0.1)}{90}}}=3.51$$ Hence our p-value is  $$\mathbb{P}(Z>\text{observed value})=\mathbb{P}(Z>3.51)<0.0001$$ Hence we reject $H_0$. Is my hypothesis test correct?","The proportion of deaths due to lung cancer in working males aged 15-64   in Australia between 1970 and 1972 was 10%. There is reason to believe   that working in a chemical plant for an extended period can increase your   risk of lung cancer. Several Australian chemical plants were investigated,   and it was found that of 90 deaths in working males aged 15-64, 19 were   due to lung cancer. Is there evidence of increased risk of developing lung cancer if you work in   a chemical plant? For this hypothesis test, we are required to provide a statement of the null and alternative hypothesis, a test statistic, the observed value and the estimated $p$-value. My Attempt: let $p$ be the probability of developing lung cancer in a chemical plant. Therefore, $$H_0:p=0.1 \ \ \ \ \ \ \text{vs} \ \ \ \ \ \ \ H_1:p>0.1$$ Our test statistic is $$Z=\frac{\hat{p}-p}{\sqrt{\frac{p(1-p)}{n}}} \ \ \ \ \ \ \text{where} \ Z\sim N(0,1)$$ Our observed value is therefore $$\frac{\frac{\hat{p}}{n}-p}{\sqrt{\frac{p(1-p)}{n}}} =\frac{\frac{19}{90}-0.1}{\sqrt{\frac{0.1(1-0.1)}{90}}}=3.51$$ Hence our p-value is  $$\mathbb{P}(Z>\text{observed value})=\mathbb{P}(Z>3.51)<0.0001$$ Hence we reject $H_0$. Is my hypothesis test correct?",,"['probability', 'statistics']"
1,statistical errors associated to Monte Carlo sampling,statistical errors associated to Monte Carlo sampling,,I have $n$ successive observation $A_\mu  $  of a quantity $A$ and I need to understand how  the expectation values of the square of the statistical error depends from the  autocorrelation time but a single step in the demonstration is giving me trouble. the author of the book (Monte Carlo simulations in statistical physics -Binder) wrote : \begin{align*} \langle {(\delta A)^2} \rangle  &= \bigg\langle \bigg[\frac{1}{n} \sum_{\mu =1}^n (A_\mu - \langle A \rangle) \bigg]^2 \bigg\rangle \\ &= \frac{1}{n^2} \sum_{\mu=1}^n \langle(A_\mu -\langle A \rangle)^2 \rangle + \frac{2}{n^2}\sum_{ \mu_1= 1}^n \sum_{\mu_2 = \mu_1 +1}^n \bigg(\langle A_{\mu_1} A_{\mu_2} \rangle- \langle A\rangle \bigg) \end{align*} changing the summation index $\mu_2 $ to  $\mu_1 +\mu $  with $ \mu = \mu_2 - \mu_1$this equation can be rewritten as : $$ \langle {(\delta A)^2} \rangle   = \frac{1}{n} \bigg[\langle A^2\rangle  - \langle A \rangle  ^2 + 2 \sum_{\mu =1}^n \bigg( 1-\frac{\mu}{n} \bigg) \bigg(\langle A_0 A_\mu \rangle - \langle A \rangle  \bigg) \bigg]        $$ how does this change in the summation index works? please help me understand this passage,I have $n$ successive observation $A_\mu  $  of a quantity $A$ and I need to understand how  the expectation values of the square of the statistical error depends from the  autocorrelation time but a single step in the demonstration is giving me trouble. the author of the book (Monte Carlo simulations in statistical physics -Binder) wrote : \begin{align*} \langle {(\delta A)^2} \rangle  &= \bigg\langle \bigg[\frac{1}{n} \sum_{\mu =1}^n (A_\mu - \langle A \rangle) \bigg]^2 \bigg\rangle \\ &= \frac{1}{n^2} \sum_{\mu=1}^n \langle(A_\mu -\langle A \rangle)^2 \rangle + \frac{2}{n^2}\sum_{ \mu_1= 1}^n \sum_{\mu_2 = \mu_1 +1}^n \bigg(\langle A_{\mu_1} A_{\mu_2} \rangle- \langle A\rangle \bigg) \end{align*} changing the summation index $\mu_2 $ to  $\mu_1 +\mu $  with $ \mu = \mu_2 - \mu_1$this equation can be rewritten as : $$ \langle {(\delta A)^2} \rangle   = \frac{1}{n} \bigg[\langle A^2\rangle  - \langle A \rangle  ^2 + 2 \sum_{\mu =1}^n \bigg( 1-\frac{\mu}{n} \bigg) \bigg(\langle A_0 A_\mu \rangle - \langle A \rangle  \bigg) \bigg]        $$ how does this change in the summation index works? please help me understand this passage,,"['statistics', 'monte-carlo']"
2,"Total variation distance, bayesian networks and dependence","Total variation distance, bayesian networks and dependence",,"Consider the following bayesian network depicted below If $X_{1:L}$ are i.i.d. random variables where, for any $i \in [1:L]$, $X_i \in \mathcal{X}$ is uniformly distributed, we can factorize $q^{(1)}_{Z_1\dots Z_L}$ as \begin{equation} q^{(1)}_{Z_1\dots Z_L} = \frac{1}{|\mathcal{X}|^L} \sum_{x_{1:L}} \prod_{i=1}^L p_{Z|AB}(z_i|x_i,x_{i-1}). \end{equation} Now, consider a new bayesian network, where, for all $i \in [1:L]$, the dependency between $X_{i-1}$ and $Z_{i}$ is removed, and $X_{i-1}$ is replaced by a new r.v. $\bar{X}_{i-1}$ equally distributed and connected to $Z_{i}$. In this case, we have \begin{align} q^{(2)}_{Z_1\dots Z_L} & = \frac{1}{|\mathcal{X}|^{2L}} \sum_{x_{1:L}}\prod_{i=1}^L \sum_{\bar{x}_{i-1}} p_{Z|AB}(z_i|x_i,\bar{x}_{i-1}) \end{align} The total variation distance between $q^{(1)}_{Z_1\dots Z_L}$ and $q^{(2)}_{Z_1\dots Z_L}$ is \begin{align} & d_{TV}(q^{(2)}_{Z_1\dots Z_L},q^{(1)}_{Z_1\dots Z_L}) \\ & \quad = \sum_{z_{1:L}} \bigg| q^{(2)}_{Z_1\dots Z_L}(z_{1:L}) - q^{(1)}_{Z_1\dots Z_L}(z_{1:L}) \bigg| \\ & \quad = \sum_{z_{1:L}} \bigg| \frac{1}{|\mathcal{X}|^{2L}} \sum_{x_{1:L}}  \prod_{i=1}^L \sum_{\bar{x}_{i-1}} p_{Z|AB}(z_i|x_i,\bar{x}_{i-1})  -  \frac{1}{|\mathcal{X}|^L} \sum_{x_{1:L}} \prod_{i=1}^L p_{Z|AB}(z_i|x_i,x_{i-1}) \bigg| \end{align} If $p_{Z|AB}(z|a,b) = p_{Z|AB}(z|a,b^{\prime})$ for any $a,b,b^{\prime} \in \mathcal{X}$ (that is, $Z$ is determined only by $A$), we have \begin{align} & d_{TV}(q^{(2)}_{Z_1\dots Z_L},q^{(1)}_{Z_1\dots Z_L}) \\ & \quad = \sum_{z_{1:L}} \bigg| \frac{1}{|\mathcal{X}|^{2L}} \sum_{x_{1:L}}  \prod_{i=1}^L |\mathcal{X}| p_{Z|AB}(z_i|x_i,x^{\prime})  -  \frac{1}{|\mathcal{X}|^L} \sum_{x_{1:L}} \prod_{i=1}^L p_{Z|AB}(z_i|x_i,x^{\prime}) \bigg| \\ & \quad = \sum_{z_{1:L}} \bigg| \frac{1}{|\mathcal{X}|^{L}} \sum_{x_{1:L}}  \prod_{i=1}^L  p_{Z|AB}(z_i|x_i,x^{\prime})  -  \frac{1}{|\mathcal{X}|^L} \sum_{x_{1:L}} \prod_{i=1}^L p_{Z|AB}(z_i|x_i,x^{\prime}) \bigg| \\ & \quad = 0. \end{align} QUESTION: Is it also true that $d_{TV}(q^{(2)}_{Z_1\dots Z_L},q^{(1)}_{Z_1\dots Z_L}) = 0$ implies $p_{Z|AB}(z|a,b) = p_{Z|AB}(z|a,b^{\prime})$ for any $a,b,b^{\prime} \in \mathcal{X}$.","Consider the following bayesian network depicted below If $X_{1:L}$ are i.i.d. random variables where, for any $i \in [1:L]$, $X_i \in \mathcal{X}$ is uniformly distributed, we can factorize $q^{(1)}_{Z_1\dots Z_L}$ as \begin{equation} q^{(1)}_{Z_1\dots Z_L} = \frac{1}{|\mathcal{X}|^L} \sum_{x_{1:L}} \prod_{i=1}^L p_{Z|AB}(z_i|x_i,x_{i-1}). \end{equation} Now, consider a new bayesian network, where, for all $i \in [1:L]$, the dependency between $X_{i-1}$ and $Z_{i}$ is removed, and $X_{i-1}$ is replaced by a new r.v. $\bar{X}_{i-1}$ equally distributed and connected to $Z_{i}$. In this case, we have \begin{align} q^{(2)}_{Z_1\dots Z_L} & = \frac{1}{|\mathcal{X}|^{2L}} \sum_{x_{1:L}}\prod_{i=1}^L \sum_{\bar{x}_{i-1}} p_{Z|AB}(z_i|x_i,\bar{x}_{i-1}) \end{align} The total variation distance between $q^{(1)}_{Z_1\dots Z_L}$ and $q^{(2)}_{Z_1\dots Z_L}$ is \begin{align} & d_{TV}(q^{(2)}_{Z_1\dots Z_L},q^{(1)}_{Z_1\dots Z_L}) \\ & \quad = \sum_{z_{1:L}} \bigg| q^{(2)}_{Z_1\dots Z_L}(z_{1:L}) - q^{(1)}_{Z_1\dots Z_L}(z_{1:L}) \bigg| \\ & \quad = \sum_{z_{1:L}} \bigg| \frac{1}{|\mathcal{X}|^{2L}} \sum_{x_{1:L}}  \prod_{i=1}^L \sum_{\bar{x}_{i-1}} p_{Z|AB}(z_i|x_i,\bar{x}_{i-1})  -  \frac{1}{|\mathcal{X}|^L} \sum_{x_{1:L}} \prod_{i=1}^L p_{Z|AB}(z_i|x_i,x_{i-1}) \bigg| \end{align} If $p_{Z|AB}(z|a,b) = p_{Z|AB}(z|a,b^{\prime})$ for any $a,b,b^{\prime} \in \mathcal{X}$ (that is, $Z$ is determined only by $A$), we have \begin{align} & d_{TV}(q^{(2)}_{Z_1\dots Z_L},q^{(1)}_{Z_1\dots Z_L}) \\ & \quad = \sum_{z_{1:L}} \bigg| \frac{1}{|\mathcal{X}|^{2L}} \sum_{x_{1:L}}  \prod_{i=1}^L |\mathcal{X}| p_{Z|AB}(z_i|x_i,x^{\prime})  -  \frac{1}{|\mathcal{X}|^L} \sum_{x_{1:L}} \prod_{i=1}^L p_{Z|AB}(z_i|x_i,x^{\prime}) \bigg| \\ & \quad = \sum_{z_{1:L}} \bigg| \frac{1}{|\mathcal{X}|^{L}} \sum_{x_{1:L}}  \prod_{i=1}^L  p_{Z|AB}(z_i|x_i,x^{\prime})  -  \frac{1}{|\mathcal{X}|^L} \sum_{x_{1:L}} \prod_{i=1}^L p_{Z|AB}(z_i|x_i,x^{\prime}) \bigg| \\ & \quad = 0. \end{align} QUESTION: Is it also true that $d_{TV}(q^{(2)}_{Z_1\dots Z_L},q^{(1)}_{Z_1\dots Z_L}) = 0$ implies $p_{Z|AB}(z|a,b) = p_{Z|AB}(z|a,b^{\prime})$ for any $a,b,b^{\prime} \in \mathcal{X}$.",,"['statistics', 'probability-distributions', 'information-theory', 'independence', 'bayesian-network']"
3,Categorical data: Testing difference between two experiments,Categorical data: Testing difference between two experiments,,"I have the following experimental setup: Protein A is capable of cutting protein B in small fragments. The small fragments are identified and the nature of the last amino acid in each fragment is counted. Thus, in one experiment it is possible to detect all 20 amino acids but with a different total count. The total count depends on the nature of Protein A and the conditions of the experiment. At the end, for the two conditions tested I end up with a table like this: Amino-acid  Exp1   Exp2 A             0      3 R            20     12 G            10     15 H            14     22 E             5      0 with entries for all 20 amino acids and I also know the total number of fragments from Protein B that were identified in each condition. The question I need to answer is: Are the amino acids frequencies significantly different under the two experimental conditions? First I thought to use a chi-square test since with the chi-square test I can take into account the different number of fragments that were identified in the two conditions. But inevitably I will end up with expected values being 0 and thus I cannot use the chi-square test. Could you please point me in the direction of the test that can be used in this case? Thanks a lot in advance.","I have the following experimental setup: Protein A is capable of cutting protein B in small fragments. The small fragments are identified and the nature of the last amino acid in each fragment is counted. Thus, in one experiment it is possible to detect all 20 amino acids but with a different total count. The total count depends on the nature of Protein A and the conditions of the experiment. At the end, for the two conditions tested I end up with a table like this: Amino-acid  Exp1   Exp2 A             0      3 R            20     12 G            10     15 H            14     22 E             5      0 with entries for all 20 amino acids and I also know the total number of fragments from Protein B that were identified in each condition. The question I need to answer is: Are the amino acids frequencies significantly different under the two experimental conditions? First I thought to use a chi-square test since with the chi-square test I can take into account the different number of fragments that were identified in the two conditions. But inevitably I will end up with expected values being 0 and thus I cannot use the chi-square test. Could you please point me in the direction of the test that can be used in this case? Thanks a lot in advance.",,"['statistics', 'hypothesis-testing', 'chi-squared']"
4,understanding an inequality with the p-th moment,understanding an inequality with the p-th moment,,"I am trying to understand how bound of the p-th moment is coming from the concentration inequality. In general, we would have, say, $S=\sum_{i=1}^na_ix_i$, where $x_i$ are random variables and $a_i$ are in $R$. Then, the concentration inequality can be written: $$ E(S-ES)^p\leq Cp^p\|a\|_2. $$ In order to bound the $p$-th moment, one would write: $$ E(|S|^p)^{1/p}\leq E|S| +Cp^p\|a\|_2. $$ I cannot understand which inequality used here to get this last line? Would it be Minkovsky?","I am trying to understand how bound of the p-th moment is coming from the concentration inequality. In general, we would have, say, $S=\sum_{i=1}^na_ix_i$, where $x_i$ are random variables and $a_i$ are in $R$. Then, the concentration inequality can be written: $$ E(S-ES)^p\leq Cp^p\|a\|_2. $$ In order to bound the $p$-th moment, one would write: $$ E(|S|^p)^{1/p}\leq E|S| +Cp^p\|a\|_2. $$ I cannot understand which inequality used here to get this last line? Would it be Minkovsky?",,"['probability', 'statistics', 'expectation']"
5,Bayes decision theory - step in derivation,Bayes decision theory - step in derivation,,"I am self studying Bayes Decision theory from these lecture notes page 30 / 31 and there is a step a struggle to understand mathematically Background context Given Bayes risk defined as: $$ r_B(\pi, \hat \theta) = \int_{\Theta} R(\theta, \hat \theta) \ \pi(\theta) \ d \theta$$ Prior distribution $\theta \sim \pi(\theta)$ Distribution of data given $\theta$ $z | \theta \sim f(z | \theta)$ Marginal distribution of $z$ : $m(z) = \int f(z | \theta) \pi (\theta) \ d\theta$ Posterior distribution of $\theta$ $\pi(\theta | z) = \frac{f(z | \theta) \pi(\theta)}{m(z)}$ Frequentist risk $R$ : $R(\theta, \hat \theta) = E[L(\theta, \hat \theta)| \theta]$ We can express Bayes Risk in terms of the posterior risk, a function of $z$ $$ r_B(\pi, \hat \theta) = \int_{\mathcal{Z}}  r(\hat \theta | z) m(z) dz$$ Which means that the Bayes decision rule can be obtained as \begin{aligned} 	r_b(\pi, \hat \theta_\pi^{Bayes}) &= \inf_{\hat \theta} r_b(\pi, \hat \theta) 	\\ 	&= \inf_{\hat \theta} \int_{\mathcal{Z}}  r(\hat \theta | z) m(z) dz \end{aligned} Step I don't grasp The above theorem implies that the Bayes rule can be obtained by taking the Bayes action for each particular $z$. For each fixed $z$ we choose $\hat \theta(z)$ to minimize the posterior risk $r(\hat \theta | z)$. $$ \arg \min_{\hat \theta} \ r(\hat \theta | z) =  \int L(\theta, \hat \theta(z)) \pi(\theta | z) \ d\theta $$ This guarantees us to minimize the integrand at every $z$ and hence minimize Bayes risk. How do we get from the inf to the argmin and why does one minimize the other ? I feel this is a stupid question but I am missing something... thanks !","I am self studying Bayes Decision theory from these lecture notes page 30 / 31 and there is a step a struggle to understand mathematically Background context Given Bayes risk defined as: $$ r_B(\pi, \hat \theta) = \int_{\Theta} R(\theta, \hat \theta) \ \pi(\theta) \ d \theta$$ Prior distribution $\theta \sim \pi(\theta)$ Distribution of data given $\theta$ $z | \theta \sim f(z | \theta)$ Marginal distribution of $z$ : $m(z) = \int f(z | \theta) \pi (\theta) \ d\theta$ Posterior distribution of $\theta$ $\pi(\theta | z) = \frac{f(z | \theta) \pi(\theta)}{m(z)}$ Frequentist risk $R$ : $R(\theta, \hat \theta) = E[L(\theta, \hat \theta)| \theta]$ We can express Bayes Risk in terms of the posterior risk, a function of $z$ $$ r_B(\pi, \hat \theta) = \int_{\mathcal{Z}}  r(\hat \theta | z) m(z) dz$$ Which means that the Bayes decision rule can be obtained as \begin{aligned} 	r_b(\pi, \hat \theta_\pi^{Bayes}) &= \inf_{\hat \theta} r_b(\pi, \hat \theta) 	\\ 	&= \inf_{\hat \theta} \int_{\mathcal{Z}}  r(\hat \theta | z) m(z) dz \end{aligned} Step I don't grasp The above theorem implies that the Bayes rule can be obtained by taking the Bayes action for each particular $z$. For each fixed $z$ we choose $\hat \theta(z)$ to minimize the posterior risk $r(\hat \theta | z)$. $$ \arg \min_{\hat \theta} \ r(\hat \theta | z) =  \int L(\theta, \hat \theta(z)) \pi(\theta | z) \ d\theta $$ This guarantees us to minimize the integrand at every $z$ and hence minimize Bayes risk. How do we get from the inf to the argmin and why does one minimize the other ? I feel this is a stupid question but I am missing something... thanks !",,"['statistics', 'self-learning', 'bayesian', 'bayes-theorem', 'decision-theory']"
6,Proving Two Statements on Independence and Mutual Exclusion,Proving Two Statements on Independence and Mutual Exclusion,,"GIVEN $P(A)>0$ and $P(B)>0$. If $A$ and $B$ are independent, then they cannot be mutually exclusive. My proof: Let $A$ and $B$ be two independent sets such that $\mathbb{P}(A)>0$ and $\mathbb{P}(B)>0 $.  $$\Rightarrow \mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B)>0$$ Now suppose that $A$ and $B$ are mutually exclusive, then $$\mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B)=0$$ But this is a contradiction, as $\mathbb{P}(A)\mathbb{P}(B)>0$ by design. Hence $A$ and $B$ cannot be mutually exclusive. If $A$ and $B$ are mutually exclusive, then they cannot be independent. My proof: Let $A$ and $B$ be two sets such that $\mathbb{P}(A)>0$ and $\mathbb{P}(B)>0 $. If $A$ and $B$ are mutually exclusive, then  $$\mathbb{P}(A\cap B)=0$$ Now suppose $A$ and $B$ are independent, then $$\mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B)=0$$ $$\Rightarrow \mathbb{P}(A)=0 \ \ \  \text{and/or} \ \ \ \mathbb{P}(B)=0$$ But this is a contradiction, as $\mathbb{P}(A)>0$ and $\mathbb{P}(B)>0$ by design. Hence $A$ and $B$ cannot be independent. Are these proofs correct? I have tried to make them simple, but are they too simple that they fail to prove each relevant statement?","GIVEN $P(A)>0$ and $P(B)>0$. If $A$ and $B$ are independent, then they cannot be mutually exclusive. My proof: Let $A$ and $B$ be two independent sets such that $\mathbb{P}(A)>0$ and $\mathbb{P}(B)>0 $.  $$\Rightarrow \mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B)>0$$ Now suppose that $A$ and $B$ are mutually exclusive, then $$\mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B)=0$$ But this is a contradiction, as $\mathbb{P}(A)\mathbb{P}(B)>0$ by design. Hence $A$ and $B$ cannot be mutually exclusive. If $A$ and $B$ are mutually exclusive, then they cannot be independent. My proof: Let $A$ and $B$ be two sets such that $\mathbb{P}(A)>0$ and $\mathbb{P}(B)>0 $. If $A$ and $B$ are mutually exclusive, then  $$\mathbb{P}(A\cap B)=0$$ Now suppose $A$ and $B$ are independent, then $$\mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B)=0$$ $$\Rightarrow \mathbb{P}(A)=0 \ \ \  \text{and/or} \ \ \ \mathbb{P}(B)=0$$ But this is a contradiction, as $\mathbb{P}(A)>0$ and $\mathbb{P}(B)>0$ by design. Hence $A$ and $B$ cannot be independent. Are these proofs correct? I have tried to make them simple, but are they too simple that they fail to prove each relevant statement?",,"['probability', 'statistics']"
7,Conditional mean squared error vs unconditional mean squared error,Conditional mean squared error vs unconditional mean squared error,,"Suppose you are trying to predict $Y$ from a set of predictors $X$. When you considered $E[Y-\hat{Y}]^2$ or $E[(Y-\hat{Y})^2|X]$, the minimizer is $E[Y|X]$. As $E[Y|X]$ is hard to compute we can rely on a linear predictor $\tilde{Y} = a + b[X-E[X]]$. To find the values of $a$ and $b$, we usually minimize $E[Y - \tilde{Y}]^2$ not $E[(Y-\tilde{Y})^2|X]$. I get that if we minimize the latter it results a function of $E[Y|X]$. Is it the only reason to minimize the former over latter in the case of linear predictors?","Suppose you are trying to predict $Y$ from a set of predictors $X$. When you considered $E[Y-\hat{Y}]^2$ or $E[(Y-\hat{Y})^2|X]$, the minimizer is $E[Y|X]$. As $E[Y|X]$ is hard to compute we can rely on a linear predictor $\tilde{Y} = a + b[X-E[X]]$. To find the values of $a$ and $b$, we usually minimize $E[Y - \tilde{Y}]^2$ not $E[(Y-\tilde{Y})^2|X]$. I get that if we minimize the latter it results a function of $E[Y|X]$. Is it the only reason to minimize the former over latter in the case of linear predictors?",,"['linear-algebra', 'statistics', 'conditional-expectation']"
8,Interpreting the constant when performing a fixed effect panel data regression in Stata,Interpreting the constant when performing a fixed effect panel data regression in Stata,,"Dear Stackexchange community, I am running a panel data regression on 20 years of monthly historical excess returns of the stocks in the S&P 500 at 31/12/2017. I like to test the effectiveness of several factor models, however I am having difficulty interpreting the constant that Stata provides. If I recall correctly, when using a fixed effect model the equation when using one independent variable is as follows. $$Y_{i,t}=βX_{i,t}+α_i+u_{i,t}$$ where $\alpha_i$ is an individual intercept per stock. When I perform a fixed effect panel data regression of my dataset on the monthly excess market return provided by Kenneth French on his website, stata gives me a constant. How should I interpret that? My regression result was as follows: My regression then would follow this equation right?: $$r_{i,t}-r[\text{risk free}]_t= β(r[mkt]_t-r[\text{risk free}]_t)+α_i+u_{i,t}$$ my regression result is the following: panel data regression result (xtreg, fe) as you can see, it includes a constant. How do I interpret this? any help would be greatly appreciated! kind regards, Marinus","Dear Stackexchange community, I am running a panel data regression on 20 years of monthly historical excess returns of the stocks in the S&P 500 at 31/12/2017. I like to test the effectiveness of several factor models, however I am having difficulty interpreting the constant that Stata provides. If I recall correctly, when using a fixed effect model the equation when using one independent variable is as follows. where is an individual intercept per stock. When I perform a fixed effect panel data regression of my dataset on the monthly excess market return provided by Kenneth French on his website, stata gives me a constant. How should I interpret that? My regression result was as follows: My regression then would follow this equation right?: my regression result is the following: panel data regression result (xtreg, fe) as you can see, it includes a constant. How do I interpret this? any help would be greatly appreciated! kind regards, Marinus","Y_{i,t}=βX_{i,t}+α_i+u_{i,t} \alpha_i r_{i,t}-r[\text{risk free}]_t= β(r[mkt]_t-r[\text{risk free}]_t)+α_i+u_{i,t}","['statistics', 'finance', 'data-analysis']"
9,Can a weakly consistent estimator beat a strongly consistent one?,Can a weakly consistent estimator beat a strongly consistent one?,,"Suppose we have two estimators $\hat{\theta}_1$ and $\hat{\theta}_2$ of $\theta$, both with the same bias. If we have $$ \begin{align} &\hat{\theta}_1 \xrightarrow{a.s.}\ \theta  \\ &\hat{\theta}_2 \nrightarrow_{a.s}\ \theta \text{  but }\hat{\theta}_2 \xrightarrow{p}\ \theta  \end{align} $$ Question : Do we necessarily have $$ Avar(\hat{\theta}_1) \le Avar(\hat{\theta}_2)?$$ Here, $Avar$ denotes the asymptotic variance. That is, is a strongly consistent always (asymptotically) preferable to one that is known not to be strongly consistent?","Suppose we have two estimators $\hat{\theta}_1$ and $\hat{\theta}_2$ of $\theta$, both with the same bias. If we have $$ \begin{align} &\hat{\theta}_1 \xrightarrow{a.s.}\ \theta  \\ &\hat{\theta}_2 \nrightarrow_{a.s}\ \theta \text{  but }\hat{\theta}_2 \xrightarrow{p}\ \theta  \end{align} $$ Question : Do we necessarily have $$ Avar(\hat{\theta}_1) \le Avar(\hat{\theta}_2)?$$ Here, $Avar$ denotes the asymptotic variance. That is, is a strongly consistent always (asymptotically) preferable to one that is known not to be strongly consistent?",,"['statistics', 'statistical-inference', 'parameter-estimation']"
10,Binomial coefficient real life example.,Binomial coefficient real life example.,,"I'm sitting with a task, in which I got the answer already. The task is the following: ""At a university, $15$ juniors and $20$ seniors volunteer to serve as a special committee that requires $8$ members. A lottery is used to select the committee from among the volunteers. Suppose the chosen students consists of six juniors and two seniors. (a) For a test of homogeneity, what are the expected counts? This question I understand. (b) If the selection had been random, what is the probability of the committee having exactly two seniors? My answer was that the probability is binomial, with Binom$(k=2, n=8, p=0.57)$, but this is apparently wrong. Instead the correct answer is: $$\frac{\binom{20}{2}\binom{15}{6}}{\binom{35}{8}}$$. Can anyone explain the difference between this and standard binomial distribution?","I'm sitting with a task, in which I got the answer already. The task is the following: ""At a university, $15$ juniors and $20$ seniors volunteer to serve as a special committee that requires $8$ members. A lottery is used to select the committee from among the volunteers. Suppose the chosen students consists of six juniors and two seniors. (a) For a test of homogeneity, what are the expected counts? This question I understand. (b) If the selection had been random, what is the probability of the committee having exactly two seniors? My answer was that the probability is binomial, with Binom$(k=2, n=8, p=0.57)$, but this is apparently wrong. Instead the correct answer is: $$\frac{\binom{20}{2}\binom{15}{6}}{\binom{35}{8}}$$. Can anyone explain the difference between this and standard binomial distribution?",,"['probability', 'statistics', 'binomial-coefficients']"
11,Exclude worst value from weighted arithmetic mean,Exclude worst value from weighted arithmetic mean,,"I'm working on a tournament rating, that is calculated as a weighted arithmetic mean, i.e. the formula is: $$ R = \frac{a_1 x_1+a_2 x_2+\cdots+a_n x_n}{a_1+a_2+\cdots+a_n} $$ $a_i$ is a positive tournament weight. $x_i$ is a non-negative tournament score. The formula has one particularity, though: one or a few worst results  (let's say 10% of them) are excluded from it. In other words, I need to find which values to exclude (i.e. set $a_i=0$) to maximize the $R$ value. How can I find which values to exclude without brute-force search?","I'm working on a tournament rating, that is calculated as a weighted arithmetic mean, i.e. the formula is: $$ R = \frac{a_1 x_1+a_2 x_2+\cdots+a_n x_n}{a_1+a_2+\cdots+a_n} $$ $a_i$ is a positive tournament weight. $x_i$ is a non-negative tournament score. The formula has one particularity, though: one or a few worst results  (let's say 10% of them) are excluded from it. In other words, I need to find which values to exclude (i.e. set $a_i=0$) to maximize the $R$ value. How can I find which values to exclude without brute-force search?",,"['statistics', 'average', 'means']"
12,Some properties of convex functions $ g : \mathbb{R} \rightarrow \mathbb{R}$.,Some properties of convex functions ., g : \mathbb{R} \rightarrow \mathbb{R},"In my lecture we proved Jensen's inequality: For any convex and measurable function $g : \mathbb{R} \rightarrow \mathbb{R}$ and random variable $x \in \mathbb{R}$ , it holds that: $$\mathbb{E}(g(x)) \geq g(\mathbb{E}(x)) $$ Here is our short proof:  Linearize the function $g$ in $\mathbb{E}(x)$ . Note that $g$ is measurable, so the expected value $\mathbb{E}$ doesn't make a problem. We know that $g$ is convex, so there are $s,t \in \mathbb{R} $ with: $g(x) \geq sx + t  \ \forall x \in \mathbb{R}$ and $g(\mathbb{E}(x)) = s\mathbb{E}(x) + t $ . Now $\mathbb{E}(g(x)) \geq \mathbb{E}(sx+t) = s\mathbb{E}(x)+ t =g(\mathbb{E}(x))$ . So I don't know how to prove why a convex function $g$ is measurable and I don't know how to prove why there are $s,t \in \mathbb{R}$ with $g(x) \geq sx + t  \ \forall x \in \mathbb{R}$ and $g(\mathbb{E}(x)) = s\mathbb{E}(x) + t $ . Here is my attempt : For the first claim : If we want to check measurability of $g$ , we have to check if { $g < \alpha$ } $\in {B}(\mathbb{R}) $ ( Borel - $\sigma$ - algebra ). We know that $g$ is convex, so it holds that: $g(cx +(1-c)y) \leq cg(x) + (1-c)g(y) \  \forall x,y \in \mathbb{R} $ and $ \forall c \in [0,1] $ . If $g(x) \geq \alpha$ ,{ $g < \alpha$ } is the empty set $ \in {B}(\mathbb{R}) $ and if $g(x), g(y) < \alpha$ for some $x,y \in \mathbb{R}$ , we have $ g(cx +(1-c)y) \leq cg(x) + (1-c)g(y) < \alpha$ ? maybe this could help somehow? Moreover I read that the inverse image of a convex function is convex, and thus an interval  (without proof). Maybe this could be useful, if we prove that?  Like you see I really need help here. For the second claim : For all $ x < u < y $ , we have $u = cx + (1-c)y$ with $c = \frac{y-u}{y-x}$ Thus $ g(u) \leq cg(x) + (1-c)g(y) $ , which implies $\frac{g(u)-g(x)}{u-x} \leq \frac{g(y)-g(u)}{y-u}$ . Thus, taking $\sup_{x<u} \frac{g(u)-g(x)}{u-x} \leq s \leq \inf_{u<y} \frac{g(y)-g(u)}{y-u} $ , we have that for all $x < y \in \mathbb{R}$ , $g(x) \geq s(x-u) + g(u) = sx + (g(u)-su)$ . For the second part of the second claim: I need your help again.","In my lecture we proved Jensen's inequality: For any convex and measurable function and random variable , it holds that: Here is our short proof:  Linearize the function in . Note that is measurable, so the expected value doesn't make a problem. We know that is convex, so there are with: and . Now . So I don't know how to prove why a convex function is measurable and I don't know how to prove why there are with and . Here is my attempt : For the first claim : If we want to check measurability of , we have to check if { } ( Borel - - algebra ). We know that is convex, so it holds that: and . If ,{ } is the empty set and if for some , we have ? maybe this could help somehow? Moreover I read that the inverse image of a convex function is convex, and thus an interval  (without proof). Maybe this could be useful, if we prove that?  Like you see I really need help here. For the second claim : For all , we have with Thus , which implies . Thus, taking , we have that for all , . For the second part of the second claim: I need your help again.","g : \mathbb{R} \rightarrow \mathbb{R} x \in \mathbb{R} \mathbb{E}(g(x)) \geq g(\mathbb{E}(x))  g \mathbb{E}(x) g \mathbb{E} g s,t \in \mathbb{R}  g(x) \geq sx + t  \ \forall x \in \mathbb{R} g(\mathbb{E}(x)) = s\mathbb{E}(x) + t  \mathbb{E}(g(x)) \geq \mathbb{E}(sx+t) = s\mathbb{E}(x)+ t =g(\mathbb{E}(x)) g s,t \in \mathbb{R} g(x) \geq sx + t  \ \forall x \in \mathbb{R} g(\mathbb{E}(x)) = s\mathbb{E}(x) + t  g g < \alpha \in {B}(\mathbb{R})  \sigma g g(cx +(1-c)y) \leq cg(x) + (1-c)g(y) \  \forall x,y \in \mathbb{R}   \forall c \in [0,1]  g(x) \geq \alpha g < \alpha  \in {B}(\mathbb{R})  g(x), g(y) < \alpha x,y \in \mathbb{R}  g(cx +(1-c)y) \leq cg(x) + (1-c)g(y) < \alpha  x < u < y  u = cx + (1-c)y c = \frac{y-u}{y-x}  g(u) \leq cg(x) + (1-c)g(y)  \frac{g(u)-g(x)}{u-x} \leq \frac{g(y)-g(u)}{y-u} \sup_{x<u} \frac{g(u)-g(x)}{u-x} \leq s \leq \inf_{u<y} \frac{g(y)-g(u)}{y-u}  x < y \in \mathbb{R} g(x) \geq s(x-u) + g(u) = sx + (g(u)-su)","['real-analysis', 'probability', 'statistics', 'convex-analysis', 'measurable-functions']"
13,What are tolerance intervals for linear regression?,What are tolerance intervals for linear regression?,,"What are tolerance intervals for linear regression.  I am trying to break down this paper into general terms, not a specific problem.  What are they used for?  What is the basic principles behind this technique, and how does it differ from other statistical analysis?: https://projecteuclid.org/download/pdf_1/euclid.bsmsp/1200500218","What are tolerance intervals for linear regression.  I am trying to break down this paper into general terms, not a specific problem.  What are they used for?  What is the basic principles behind this technique, and how does it differ from other statistical analysis?: https://projecteuclid.org/download/pdf_1/euclid.bsmsp/1200500218",,"['statistics', 'regression', 'linear-regression']"
14,Distribution of exponential $x_i$s : $\sum_{i=1}^n x_i$,Distribution of exponential s :,x_i \sum_{i=1}^n x_i,"Exercise : Let $X_1, \dots, X_n$ be a random sample from the Exponential Distribution with unknown parameter $\theta$ . (i) Find a sufficient and complete statistics function $T$ , for $\theta$ . (ii) Using without proof known formulas, find the distribution of $T$ . Attempt : (i) The p.d.f. for the sample is given as : $$f(x;\theta) = \begin{cases} \theta e^{-\theta x}, & x \geq 0 \\ 0, & x<0 \end{cases}$$ Thus $f(x;\theta) = \theta e^{-\theta x}\mathbb{I}_{[0,+\infty]}(x) $ which belongs to the Exponential Family of Distributions, thus the function: $$ T = \sum_{i=1}^nx_i$$ is a sufficient and complete statistics function for $\theta$ . (ii) Question : How would one proceed with finding the distribution of $T$ now ?","Exercise : Let be a random sample from the Exponential Distribution with unknown parameter . (i) Find a sufficient and complete statistics function , for . (ii) Using without proof known formulas, find the distribution of . Attempt : (i) The p.d.f. for the sample is given as : Thus which belongs to the Exponential Family of Distributions, thus the function: is a sufficient and complete statistics function for . (ii) Question : How would one proceed with finding the distribution of now ?","X_1, \dots, X_n \theta T \theta T f(x;\theta) = \begin{cases} \theta e^{-\theta x}, & x \geq 0 \\ 0, & x<0 \end{cases} f(x;\theta) = \theta e^{-\theta x}\mathbb{I}_{[0,+\infty]}(x)   T = \sum_{i=1}^nx_i \theta T","['probability', 'statistics', 'probability-distributions', 'exponential-distribution']"
15,What is meant by this useage of the $\mathcal{O}$ notation in statistics,What is meant by this useage of the  notation in statistics,\mathcal{O},"I'm reading this statistics paper, and one of the theorems reads ( emphasis mine ) Theorem: Let $(\mathcal{X},\mathcal{A},P)$ be an arbitrary probability space, $\mathcal{F}$ a class of real-valued functions on $\mathcal{X}$ with $||f||_{\infty} \leq 1$. Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of i.i.d. random variables drawn according to $P$, and $(P_n)_{n \in \mathbb{N}}$ the corresponding empirical distributions. Then there exists some constant $c > 0$ such that, for all $n\in \mathbb{N}$ with probability at least $\boldsymbol{1−\delta}$,   $$\operatorname{sup}_{f \in \mathcal{F}} \left| P_n - Pf \right| \leq \frac{c}{\sqrt{n}} \int_0^{\infty}\sqrt{\operatorname{log} N(\mathcal{F}, \varepsilon, L_2(P_n))} d\varepsilon + \sqrt{\frac{1}{2n}\operatorname{log}\boldsymbol{\frac{1}\delta}}.$$ The paper then goes on to say that We can see that if $\int_0^{\infty}\sqrt{\operatorname{log} N(\mathcal{F}, \varepsilon, L_2(P_n))} d\varepsilon  < \infty$, then the whole expression scales as $\mathcal{O}(1/√n)$ They then show that indeed, the integral is finite. They conclude: ( emphasis mine ) Let $X$ be compact subset of $\mathbb{R}^d$ and $k(x,y) = \operatorname{exp}(−||x−y||^2/\sigma^2)$. Then the eigenvectors in Theorem 16 converge with rate $\boldsymbol{\mathcal{O}(1/\sqrt{n})}$ where Theorem 16 states [...] such that,   $$||a_n u_n - u||_{\infty} \leq C' \operatorname{sup}_{f \in \mathcal{F}} \left| P_n - Pf \right|$$ which holds almost surely and $u_n$ are the eigenvectors mentioned in the preceeding quote. My question is what they mean by ""the eigenvectors converge with rate ${\mathcal{O}(1/\sqrt{n})}$"". In my eyes, the statement seems to imply that the eigenvectors converge almost surely with a rate of ${\mathcal{O}(1/\sqrt{n})}$, since the inequality in theorem 16 holds almost surely and nowhere do they mention that the convergence is meant to be in probabilty. However, the theorem seems to only give us that $$\mathbb{P}\left( \operatorname{sup}_{f \in \mathcal{F}} \left| P_n - Pf \right| > \frac{C}{\sqrt{n}} (1 + \operatorname{log}\frac{1}{\delta}) \right) \leq \delta,$$ which would give us that  $$||a_n u_n - u||_{\infty} \in \mathcal{O}_p \left(\frac{1}{\sqrt{n}}\right),$$ i.e. the eigenvectors are stochastically bounded. Here i used the Wikipedia definition of $\mathcal{O}_p$. My guess is that one of the following explanations applies here: In this context it is customary to mean $\mathcal{O}_p$ when writing $\mathcal{O}$. Because in our context $\mathcal{X}$ is compact and $\mathcal{F}$ is a Glivenko-Cantelli class , by some magic the statement of the theorem holds almost surely and independent of $\delta$. Since, for Glivenko-Cantelli classes, convergence in probabilty imples almost surely convergence, i can see this somehow working out. However i don't understand why the rate of convergence in probabilty would translate directly to the rate of almost surely convergence. I made some other conceptual mistake. Thank you for helping!","I'm reading this statistics paper, and one of the theorems reads ( emphasis mine ) Theorem: Let $(\mathcal{X},\mathcal{A},P)$ be an arbitrary probability space, $\mathcal{F}$ a class of real-valued functions on $\mathcal{X}$ with $||f||_{\infty} \leq 1$. Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of i.i.d. random variables drawn according to $P$, and $(P_n)_{n \in \mathbb{N}}$ the corresponding empirical distributions. Then there exists some constant $c > 0$ such that, for all $n\in \mathbb{N}$ with probability at least $\boldsymbol{1−\delta}$,   $$\operatorname{sup}_{f \in \mathcal{F}} \left| P_n - Pf \right| \leq \frac{c}{\sqrt{n}} \int_0^{\infty}\sqrt{\operatorname{log} N(\mathcal{F}, \varepsilon, L_2(P_n))} d\varepsilon + \sqrt{\frac{1}{2n}\operatorname{log}\boldsymbol{\frac{1}\delta}}.$$ The paper then goes on to say that We can see that if $\int_0^{\infty}\sqrt{\operatorname{log} N(\mathcal{F}, \varepsilon, L_2(P_n))} d\varepsilon  < \infty$, then the whole expression scales as $\mathcal{O}(1/√n)$ They then show that indeed, the integral is finite. They conclude: ( emphasis mine ) Let $X$ be compact subset of $\mathbb{R}^d$ and $k(x,y) = \operatorname{exp}(−||x−y||^2/\sigma^2)$. Then the eigenvectors in Theorem 16 converge with rate $\boldsymbol{\mathcal{O}(1/\sqrt{n})}$ where Theorem 16 states [...] such that,   $$||a_n u_n - u||_{\infty} \leq C' \operatorname{sup}_{f \in \mathcal{F}} \left| P_n - Pf \right|$$ which holds almost surely and $u_n$ are the eigenvectors mentioned in the preceeding quote. My question is what they mean by ""the eigenvectors converge with rate ${\mathcal{O}(1/\sqrt{n})}$"". In my eyes, the statement seems to imply that the eigenvectors converge almost surely with a rate of ${\mathcal{O}(1/\sqrt{n})}$, since the inequality in theorem 16 holds almost surely and nowhere do they mention that the convergence is meant to be in probabilty. However, the theorem seems to only give us that $$\mathbb{P}\left( \operatorname{sup}_{f \in \mathcal{F}} \left| P_n - Pf \right| > \frac{C}{\sqrt{n}} (1 + \operatorname{log}\frac{1}{\delta}) \right) \leq \delta,$$ which would give us that  $$||a_n u_n - u||_{\infty} \in \mathcal{O}_p \left(\frac{1}{\sqrt{n}}\right),$$ i.e. the eigenvectors are stochastically bounded. Here i used the Wikipedia definition of $\mathcal{O}_p$. My guess is that one of the following explanations applies here: In this context it is customary to mean $\mathcal{O}_p$ when writing $\mathcal{O}$. Because in our context $\mathcal{X}$ is compact and $\mathcal{F}$ is a Glivenko-Cantelli class , by some magic the statement of the theorem holds almost surely and independent of $\delta$. Since, for Glivenko-Cantelli classes, convergence in probabilty imples almost surely convergence, i can see this somehow working out. However i don't understand why the rate of convergence in probabilty would translate directly to the rate of almost surely convergence. I made some other conceptual mistake. Thank you for helping!",,"['statistics', 'asymptotics']"
16,Show $ \int g$ d$\mathbb{P}_n = \frac{1}{n} \sum_{i=1}^n g(y_i) $ for any measurable function $g$.,Show  d for any measurable function ., \int g \mathbb{P}_n = \frac{1}{n} \sum_{i=1}^n g(y_i)  g,"We want : $ \int g$ d$\mathbb{P}_n = \frac{1}{n} \sum_{i=1}^n g(y_i) $ . Important for this exercise : $\mathbb{P}_n (A)  = \frac{1}{n} \sum_{i=1}^n 1_{y_i}(A) $ , with  $1_{y_i}$ point measures. So $1_{y_i}(A) =1 $, if $ y_i \in A $ and $1_{y_i}(A) = 0$ otherwise. I already show this claim for $g : \mathbb{R} \rightarrow \mathbb{R} $ with $g(a) = 𝟙[a \in B]$ ( indicator function ) for a set B $\in \mathbb{B}$ ( Borel). Here: $ \int g$ d$\mathbb{P}_n  =  \mathbb{P}_n(B)  = \frac{1}{n} \sum_{i=1}^n 1_{y_i}(B) =\frac{1}{n} \sum_{i=1}^n 𝟙[y_i \in B] = \frac{1}{n} \sum_{i=1}^n g(y_i)  $. With the help of integration techniques I want to generalize this now for any measurable function $g$. Here is my start: We know $g$ is measurable. So $g^{+}$, and $g^{-}$ are integrable (non-negative and measurable ). Now we know there are  increasing sequences $(h_j)_{j \in \mathbb{N}}$ and $(k_j)_{j \in \mathbb{N}}$ of nonnegative simple functions with $(h_j) \nearrow g^{+}$ and  $(k_j) \nearrow g^{-}$. So  $ \int g^{+}$ d$\mathbb{P}_n  = \lim_{j \rightarrow \infty} \int h_j  $ d$\mathbb{P}_n$ and $ \int g^{-}$ d$\mathbb{P}_n  = \lim_{j \rightarrow \infty} \int k_j  $ d$\mathbb{P}_n$.","We want : $ \int g$ d$\mathbb{P}_n = \frac{1}{n} \sum_{i=1}^n g(y_i) $ . Important for this exercise : $\mathbb{P}_n (A)  = \frac{1}{n} \sum_{i=1}^n 1_{y_i}(A) $ , with  $1_{y_i}$ point measures. So $1_{y_i}(A) =1 $, if $ y_i \in A $ and $1_{y_i}(A) = 0$ otherwise. I already show this claim for $g : \mathbb{R} \rightarrow \mathbb{R} $ with $g(a) = 𝟙[a \in B]$ ( indicator function ) for a set B $\in \mathbb{B}$ ( Borel). Here: $ \int g$ d$\mathbb{P}_n  =  \mathbb{P}_n(B)  = \frac{1}{n} \sum_{i=1}^n 1_{y_i}(B) =\frac{1}{n} \sum_{i=1}^n 𝟙[y_i \in B] = \frac{1}{n} \sum_{i=1}^n g(y_i)  $. With the help of integration techniques I want to generalize this now for any measurable function $g$. Here is my start: We know $g$ is measurable. So $g^{+}$, and $g^{-}$ are integrable (non-negative and measurable ). Now we know there are  increasing sequences $(h_j)_{j \in \mathbb{N}}$ and $(k_j)_{j \in \mathbb{N}}$ of nonnegative simple functions with $(h_j) \nearrow g^{+}$ and  $(k_j) \nearrow g^{-}$. So  $ \int g^{+}$ d$\mathbb{P}_n  = \lim_{j \rightarrow \infty} \int h_j  $ d$\mathbb{P}_n$ and $ \int g^{-}$ d$\mathbb{P}_n  = \lim_{j \rightarrow \infty} \int k_j  $ d$\mathbb{P}_n$.",,"['integration', 'analysis', 'statistics', 'measurable-functions']"
17,How can I calculate the joint probability for three variable?,How can I calculate the joint probability for three variable?,,"I am a student studying the joint probability density function with multi variables. I understand how to obtain a joint probability density function when two uniform distributions have the following joint distribution like below. The distribution $f_V$(v) can be determined based on the distribution of $t$, denoted as $f_T$(t),and that of $c_i$, denoted by $f_C$(c). The distributions $f_T$(t) and $f_C$(c) are available, e.g., based on the previous observations. Assume that variables $t$ and $c$ are independent from each other and follow uniform distributions, i.e., $t$~ $U[t_{min}; t_{max}]$ and $c$~  $U[c_{min}; c_{max}]$, $c_{min}$ > 0. Then, $f_V$ (v) is determined as follows. Let, z = c, v = $\frac{t}{c}$ and we have t = vz and c = z. Jacobian determinant $J_D$ among t, c, v and z is given by $J_D$ = z. So, the PDF for joint distribution $(v,z)$ is given by $f_{V,Z}$(v,z) = $f_T$(v,z)$f_C$(z)$|J_D|$ = $\frac{1}{(t_{max} - t_{min})(c_{max}-c_{min})}|z|$. So, the distribution of $v$, $f_V$(v) is determined by  $f_V$(v) = $\int_{-\infty}^\infty$ $f_{V,Z}$(v,z) $dz$ =  $\int_{c_{min}}^{c_{max}}$ $f_{V,Z}$(v,z)$dz$ = $\frac{c_{min}+c_{max}}{2(t_{max}-t_{min})}$ The question is based on above understanding, I try to do calculations when there are 3 variables. The distribution $f_V$(v) can be determined based on the distribution of $t$, denoted as $f_T$(t), that of $c$, denoted by $f_C$(c) and that of $L$, denoted by $f_L$(l). The distributions $f_T$(t), $f_C$(c), and $f_L$(l) are available. Assume that variables $t$,$c$ and $l$ are independent from each other and follow uniform distributions, i.e., $t$~ $U[t_{min}; t_{max}]$ and $c$~  $U[c_{min}; c_{max}]$, $c_{min}$ > 0, $l$~  $U[l_{min}; l_{max}]$. Then, how can i determined $f_V$ (v)? Can I get a guide for determining this joint probability function or some materials i can follow the step for this? Let z = c, v = $\frac{t}{c*l}$ and we have t = $vzl$ and c = z.","I am a student studying the joint probability density function with multi variables. I understand how to obtain a joint probability density function when two uniform distributions have the following joint distribution like below. The distribution $f_V$(v) can be determined based on the distribution of $t$, denoted as $f_T$(t),and that of $c_i$, denoted by $f_C$(c). The distributions $f_T$(t) and $f_C$(c) are available, e.g., based on the previous observations. Assume that variables $t$ and $c$ are independent from each other and follow uniform distributions, i.e., $t$~ $U[t_{min}; t_{max}]$ and $c$~  $U[c_{min}; c_{max}]$, $c_{min}$ > 0. Then, $f_V$ (v) is determined as follows. Let, z = c, v = $\frac{t}{c}$ and we have t = vz and c = z. Jacobian determinant $J_D$ among t, c, v and z is given by $J_D$ = z. So, the PDF for joint distribution $(v,z)$ is given by $f_{V,Z}$(v,z) = $f_T$(v,z)$f_C$(z)$|J_D|$ = $\frac{1}{(t_{max} - t_{min})(c_{max}-c_{min})}|z|$. So, the distribution of $v$, $f_V$(v) is determined by  $f_V$(v) = $\int_{-\infty}^\infty$ $f_{V,Z}$(v,z) $dz$ =  $\int_{c_{min}}^{c_{max}}$ $f_{V,Z}$(v,z)$dz$ = $\frac{c_{min}+c_{max}}{2(t_{max}-t_{min})}$ The question is based on above understanding, I try to do calculations when there are 3 variables. The distribution $f_V$(v) can be determined based on the distribution of $t$, denoted as $f_T$(t), that of $c$, denoted by $f_C$(c) and that of $L$, denoted by $f_L$(l). The distributions $f_T$(t), $f_C$(c), and $f_L$(l) are available. Assume that variables $t$,$c$ and $l$ are independent from each other and follow uniform distributions, i.e., $t$~ $U[t_{min}; t_{max}]$ and $c$~  $U[c_{min}; c_{max}]$, $c_{min}$ > 0, $l$~  $U[l_{min}; l_{max}]$. Then, how can i determined $f_V$ (v)? Can I get a guide for determining this joint probability function or some materials i can follow the step for this? Let z = c, v = $\frac{t}{c*l}$ and we have t = $vzl$ and c = z.",,"['probability', 'statistics', 'probability-distributions', 'uniform-distribution', 'density-function']"
18,The expected number of random variables that should be drawn without replacement whose sum exceeds some threshold.,The expected number of random variables that should be drawn without replacement whose sum exceeds some threshold.,,"Say we have a finite population of $N$ points $\{x_1,\dots,x_N\}$, and we draw samples at random without replacement until their sum exceeds some threshold $t$. We may assume that:  $\forall i\ $ $0<x_i<1$, $\sum_{i=1}^{N} x_i=k$  for a known $k$, and that $0<t<k$ is known. What is the expected number of draws? Is there a generalization of Wald’s Equation that applies to this case? Non-trivial bounds would be helpful too.","Say we have a finite population of $N$ points $\{x_1,\dots,x_N\}$, and we draw samples at random without replacement until their sum exceeds some threshold $t$. We may assume that:  $\forall i\ $ $0<x_i<1$, $\sum_{i=1}^{N} x_i=k$  for a known $k$, and that $0<t<k$ is known. What is the expected number of draws? Is there a generalization of Wald’s Equation that applies to this case? Non-trivial bounds would be helpful too.",,"['probability', 'probability-theory', 'statistics']"
19,Limiting distribution of MLE for uniform distribution,Limiting distribution of MLE for uniform distribution,,"We consider iid random variables $X_1,X_2,\ldots,X_n\sim\mathcal{U}_{[0,\theta]}$ and are interested in the asymptotic behaviour of the corresponding MLE for $\theta$, i.e. $$M_n:=\mathrm{max}_{i\in\{1,2,\ldots,n\}}X_i.$$ More precisely, I would like to confirm explicitly that $M_n$ converges (in some sense) to a reversed-Weibull-distributed rv in distribution and I suppose that I am just missing some computational detail/trick/idea... I thought I should try studying a standardised version of $M_n$ since that's what seems to be done in extreme value theory and more generally when studying limiting distributions. We know that $$\mathbb{E}_{\theta}[M_n]=\frac{n}{n+1}\theta,~~\mathbb{Var}_\theta[M_n]=\frac{n}{(n+1)^2(n+2)}\theta^2,$$ so I consider the cdf of $$Z_n=\frac{M_n-\mathbb{E}_\theta[M_n]}{\sqrt{\mathbb{Var}_\theta[M_n]}}~~\mathrm{or}~~Z_n'=\frac{M_n-\theta}{\sqrt{\mathbb{Var}_\theta[M_n]}},$$ which leads to $$\mathbb{P}_\theta(Z_n'\leq x)=\left(1+\frac{\sqrt{n}}{(n+1)\sqrt{n+2}}x\right)^n$$ and $$\mathbb{P}_\theta(Z_n\leq x)=\left(1-\frac{1}{n+1}\left(1-\frac{\sqrt{n}}{\sqrt{n+2}}x\right)\right)^n$$ for $x\leq 0$ and $x\leq \theta/(n+1)$ respectively. However, I don't see how the limit with respect to $n$ takes the form $$\exp\left(-\left(\frac{1}{1+\xi x}\right)^{1/\xi}\right)$$ for some $\xi<0$ here. (I know that $\lim_{n\rightarrow\infty}(1+x/n)^n=\exp(x)$) How can I resolve this? Is it maybe just a clever alternative for the denominator $\sqrt{\mathbb{Var}_\theta[M_n]}$?","We consider iid random variables $X_1,X_2,\ldots,X_n\sim\mathcal{U}_{[0,\theta]}$ and are interested in the asymptotic behaviour of the corresponding MLE for $\theta$, i.e. $$M_n:=\mathrm{max}_{i\in\{1,2,\ldots,n\}}X_i.$$ More precisely, I would like to confirm explicitly that $M_n$ converges (in some sense) to a reversed-Weibull-distributed rv in distribution and I suppose that I am just missing some computational detail/trick/idea... I thought I should try studying a standardised version of $M_n$ since that's what seems to be done in extreme value theory and more generally when studying limiting distributions. We know that $$\mathbb{E}_{\theta}[M_n]=\frac{n}{n+1}\theta,~~\mathbb{Var}_\theta[M_n]=\frac{n}{(n+1)^2(n+2)}\theta^2,$$ so I consider the cdf of $$Z_n=\frac{M_n-\mathbb{E}_\theta[M_n]}{\sqrt{\mathbb{Var}_\theta[M_n]}}~~\mathrm{or}~~Z_n'=\frac{M_n-\theta}{\sqrt{\mathbb{Var}_\theta[M_n]}},$$ which leads to $$\mathbb{P}_\theta(Z_n'\leq x)=\left(1+\frac{\sqrt{n}}{(n+1)\sqrt{n+2}}x\right)^n$$ and $$\mathbb{P}_\theta(Z_n\leq x)=\left(1-\frac{1}{n+1}\left(1-\frac{\sqrt{n}}{\sqrt{n+2}}x\right)\right)^n$$ for $x\leq 0$ and $x\leq \theta/(n+1)$ respectively. However, I don't see how the limit with respect to $n$ takes the form $$\exp\left(-\left(\frac{1}{1+\xi x}\right)^{1/\xi}\right)$$ for some $\xi<0$ here. (I know that $\lim_{n\rightarrow\infty}(1+x/n)^n=\exp(x)$) How can I resolve this? Is it maybe just a clever alternative for the denominator $\sqrt{\mathbb{Var}_\theta[M_n]}$?",,"['statistics', 'uniform-distribution', 'probability-limit-theorems', 'maximum-likelihood']"
20,One sided bound for Lipschitz functions for gaussian variables,One sided bound for Lipschitz functions for gaussian variables,,"Let $(X_1, . . . , X_n)$ be a vector of i.i.d. standard Gaussian variables, and let $f : R^n → R$ be L-Lipschitz with respect to the Euclidean norm. Then the variable $f(X) − E[f(X)]$ is sub-Gaussian with parameter at most L, and hence $$ P\left[|f(X)-E[f(X)]| \geq t \right] \leq 2e^{\frac{t^2}{2L^2}}$$ Is there an equivalent bound for the one sided equivalent? $$ P\left[f(X)-E[f(X)] \geq t \right]$$","Let $(X_1, . . . , X_n)$ be a vector of i.i.d. standard Gaussian variables, and let $f : R^n → R$ be L-Lipschitz with respect to the Euclidean norm. Then the variable $f(X) − E[f(X)]$ is sub-Gaussian with parameter at most L, and hence $$ P\left[|f(X)-E[f(X)]| \geq t \right] \leq 2e^{\frac{t^2}{2L^2}}$$ Is there an equivalent bound for the one sided equivalent? $$ P\left[f(X)-E[f(X)] \geq t \right]$$",,"['real-analysis', 'probability', 'functional-analysis', 'statistics', 'lipschitz-functions']"
21,"What is the justification for $\lim_{m \rightarrow \infty} \frac 1 m \sum_{i = 1}^m X_i= \int_{-\infty}^{\infty} x f(x) \, dx = \operatorname EX$",What is the justification for,"\lim_{m \rightarrow \infty} \frac 1 m \sum_{i = 1}^m X_i= \int_{-\infty}^{\infty} x f(x) \, dx = \operatorname EX","I am reading Explaining the Gibbs Sampler . What I have understood so far is that this sampler allows us to generate $X_1, \ldots, X_m$ with density $f(x)$ without actually knowing what $f(x)$ is. The author says that if we wanted to calculate the mean of $f(x)$ we could use this fact, $$\lim_{m \rightarrow \infty} \frac 1 m \sum_{i=1}^m X_i = \int_{-\infty}^\infty x f(x) \, dx = \operatorname EX.$$ I've never seen the first equality in any text when the topic of expectation of a random variable is introduced. How exactly is the first equality true?","I am reading Explaining the Gibbs Sampler . What I have understood so far is that this sampler allows us to generate $X_1, \ldots, X_m$ with density $f(x)$ without actually knowing what $f(x)$ is. The author says that if we wanted to calculate the mean of $f(x)$ we could use this fact, $$\lim_{m \rightarrow \infty} \frac 1 m \sum_{i=1}^m X_i = \int_{-\infty}^\infty x f(x) \, dx = \operatorname EX.$$ I've never seen the first equality in any text when the topic of expectation of a random variable is introduced. How exactly is the first equality true?",,"['probability', 'probability-theory', 'statistics', 'expectation']"
22,Poisson Sample Mean Wald Test,Poisson Sample Mean Wald Test,,"Let $X_1,\ldots,X_n\sim\text{Poisson}(\lambda)$, $H_0:\lambda=\lambda_0$, and $H_1:\lambda\neq\lambda_0$ for $\lambda_0>0$. Compute the size $\alpha$ Wald test, estimating $\lambda$ by $\overline{X}_n$. The size $\alpha$ Wald test rejects $H_0$ if and only if $\left|\tfrac{\hat{\lambda}-\lambda_0}{\operatorname{se}(\hat{\lambda})}\right| > \Phi^{-1}\left(1-\dfrac{\alpha}{2}\right)$. $\hat{\lambda}=\overline{X}_n$, so $\mathbb{V}(\hat{\lambda})=\tfrac{\mathbb{V}(X_i)}{n}=\tfrac{\lambda}{n}$, so $\operatorname{se}(\hat{\lambda})=\sqrt{\tfrac{\lambda}{n}}$, which we can estimate by $\sqrt{\tfrac{\hat{\lambda}}{n}}=\sqrt{\tfrac{\overline{X}_n}{n}}$. I notice in The Wald test with Poisson distribution the second answer uses $\sqrt{\tfrac{\lambda_0}{n}}$ instead, which seems fine because we're assuming $H_0$. Of course if we assume $H_0$ completely then we'd know $\lambda=\lambda_0$, but the second answer only assumes $H_0$ partially, if that makes sense. Are both of our methods valid?","Let $X_1,\ldots,X_n\sim\text{Poisson}(\lambda)$, $H_0:\lambda=\lambda_0$, and $H_1:\lambda\neq\lambda_0$ for $\lambda_0>0$. Compute the size $\alpha$ Wald test, estimating $\lambda$ by $\overline{X}_n$. The size $\alpha$ Wald test rejects $H_0$ if and only if $\left|\tfrac{\hat{\lambda}-\lambda_0}{\operatorname{se}(\hat{\lambda})}\right| > \Phi^{-1}\left(1-\dfrac{\alpha}{2}\right)$. $\hat{\lambda}=\overline{X}_n$, so $\mathbb{V}(\hat{\lambda})=\tfrac{\mathbb{V}(X_i)}{n}=\tfrac{\lambda}{n}$, so $\operatorname{se}(\hat{\lambda})=\sqrt{\tfrac{\lambda}{n}}$, which we can estimate by $\sqrt{\tfrac{\hat{\lambda}}{n}}=\sqrt{\tfrac{\overline{X}_n}{n}}$. I notice in The Wald test with Poisson distribution the second answer uses $\sqrt{\tfrac{\lambda_0}{n}}$ instead, which seems fine because we're assuming $H_0$. Of course if we assume $H_0$ completely then we'd know $\lambda=\lambda_0$, but the second answer only assumes $H_0$ partially, if that makes sense. Are both of our methods valid?",,"['statistics', 'poisson-distribution', 'means', 'hypothesis-testing', 'maximum-likelihood']"
23,Expected value and Standard deviation- Cards,Expected value and Standard deviation- Cards,,"Suppose that we've decided to test Clara, who works at the Psychic Center, to see if she really has psychic abilities. While talking to her on the phone, we'll thoroughly shuffle a standard deck of $52$ cards (which is made up of $13$ hearts,$13$ spades,$13$ diamonds, and $13$ clubs) and draw one card at random. We'll ask Clara to name the suit (heart, spade, diamond, or club) of the card we drew. After getting her guess, we'll return the card to the deck, thoroughly shuffle the deck, draw another card, and get her guess for the suit of this second card. We'll repeat this process until we've drawn a total of $14$ cards and gotten her suit guesses for each. Assume that Clara is not clairvoyant, that is, assume that she randomly guesses on each card. a.Estimate the number of cards in the sample for which Clara correctly guesses the suit by giving the mean of the relevant distribution (that is, the expectation of the relevant random variable). Do not round your response. b.Quantify the uncertainty of your estimate by giving the standard deviation of the distribution. Round your response to at least three decimal places. My answer a) $E(X)=np= 14(1/4) =3.5.$ b) $SD(X) = \sqrt{npq}=\sqrt{14(1/4)(3/4)}= 1.620.$","Suppose that we've decided to test Clara, who works at the Psychic Center, to see if she really has psychic abilities. While talking to her on the phone, we'll thoroughly shuffle a standard deck of $52$ cards (which is made up of $13$ hearts,$13$ spades,$13$ diamonds, and $13$ clubs) and draw one card at random. We'll ask Clara to name the suit (heart, spade, diamond, or club) of the card we drew. After getting her guess, we'll return the card to the deck, thoroughly shuffle the deck, draw another card, and get her guess for the suit of this second card. We'll repeat this process until we've drawn a total of $14$ cards and gotten her suit guesses for each. Assume that Clara is not clairvoyant, that is, assume that she randomly guesses on each card. a.Estimate the number of cards in the sample for which Clara correctly guesses the suit by giving the mean of the relevant distribution (that is, the expectation of the relevant random variable). Do not round your response. b.Quantify the uncertainty of your estimate by giving the standard deviation of the distribution. Round your response to at least three decimal places. My answer a) $E(X)=np= 14(1/4) =3.5.$ b) $SD(X) = \sqrt{npq}=\sqrt{14(1/4)(3/4)}= 1.620.$",,"['probability', 'statistics', 'discrete-mathematics', 'probability-distributions']"
24,What is the rationale behind transformation of a subspace in machine learning,What is the rationale behind transformation of a subspace in machine learning,,"Suppose we have a random vector $\textbf{x}\subset \mathbb{R}^n$ with known probabilistic characteristics. We want to find a $\theta$ which makes the vector $z=H\theta$ as close as possible to $\textbf{x}$ where $H\in\mathbb{R}^{n\times p}$ is a full rank matrix with $p<n$ and $\theta\in\mathbb{R}^{p\times 1}$. One can find the desired $\theta$ by writing the least square errors as $$J(\theta)=(\textbf{x}-H\theta)^T(\textbf{x}-H\theta)$$ The answer for the best $\theta$ which minimizes the above norm is $$\hat\theta=(H^TH)^{-1}H^T\textbf{x}$$ which means the best $\theta$ is the one that makes orthogonal projection of $\textbf{x}$ onto the subspace spanned by $H$. However, the weighted form of the error can be written as  $$J(\theta)=(\textbf{x}-H\theta)^TW(\textbf{x}-H\theta)$$ If $W$ is a positive definite matrix, by substituting $W=LL^T$ (Cholescky decompostion) the above can be written as $$J(\theta)=(L\textbf{x}-LH\theta)^T(L\textbf{x}-LH\theta)$$ Having the above notion in mind, and letting $y=L\textbf{x}$ one can say, the best $\theta$ is the one that makes orthogonal projection of $y$ onto the subspace spanned by $LH$. The last step means we have a subspace spanned by $H$ but to find the least error we change the subspace to Range($LH$) and our measurement to $L\textbf{x}$ and try to find the orthogonal projection of new measurement onto the new subspace. Why do we change our subspace to new subspace? What is the best $W$ or $L$? Does this change relate to data shape?","Suppose we have a random vector $\textbf{x}\subset \mathbb{R}^n$ with known probabilistic characteristics. We want to find a $\theta$ which makes the vector $z=H\theta$ as close as possible to $\textbf{x}$ where $H\in\mathbb{R}^{n\times p}$ is a full rank matrix with $p<n$ and $\theta\in\mathbb{R}^{p\times 1}$. One can find the desired $\theta$ by writing the least square errors as $$J(\theta)=(\textbf{x}-H\theta)^T(\textbf{x}-H\theta)$$ The answer for the best $\theta$ which minimizes the above norm is $$\hat\theta=(H^TH)^{-1}H^T\textbf{x}$$ which means the best $\theta$ is the one that makes orthogonal projection of $\textbf{x}$ onto the subspace spanned by $H$. However, the weighted form of the error can be written as  $$J(\theta)=(\textbf{x}-H\theta)^TW(\textbf{x}-H\theta)$$ If $W$ is a positive definite matrix, by substituting $W=LL^T$ (Cholescky decompostion) the above can be written as $$J(\theta)=(L\textbf{x}-LH\theta)^T(L\textbf{x}-LH\theta)$$ Having the above notion in mind, and letting $y=L\textbf{x}$ one can say, the best $\theta$ is the one that makes orthogonal projection of $y$ onto the subspace spanned by $LH$. The last step means we have a subspace spanned by $H$ but to find the least error we change the subspace to Range($LH$) and our measurement to $L\textbf{x}$ and try to find the orthogonal projection of new measurement onto the new subspace. Why do we change our subspace to new subspace? What is the best $W$ or $L$? Does this change relate to data shape?",,"['linear-algebra', 'geometry']"
25,Normal distribution governed by a Bernoulli distribution,Normal distribution governed by a Bernoulli distribution,,"How would I find the distributional characteristics (mean, variance) of the following scenario: A Bernoulli random variable $X \sim B(1,p)$. If the $X = 1$, then $Y \sim N(\mu_1, \sigma_1^2)$. If the $X = 0$, then $Y \sim N(\mu_0, \sigma_0^2)$. One random variable is conditional on another. I know the mean of this scenario is $p \mu_1 +(1-p) \mu_0$, but what is the variance? Thank you so much. edit -- based on further research, this is what I have come up with: $Y | X=1 \sim N(\mu_1, \sigma_1^2)$ $Y | X=0 \sim N(\mu_0, \sigma_0^2)$ $E(Y) = E(E(Y|X)) = p \times E(Y|X=1) + (1-p) \times E(Y|X=0) = p \mu_1 + (1-p)  \mu_0$ And, $Var(Y) = E(V(Y|X)) +V(E(Y|X))$ $E(V(Y|X)) = p \sigma_1^2 + (1-p) \sigma_0^2$ $V(E(Y|X)) = E(E(Y|X)^2) - E(E(Y|X))^2 =E(E(Y|X)^2) - E(Y)^2$ $ = p \mu_1^2 + (1-p) \mu_0^2 - (p \mu_1 + (1-p) \mu_0)^2$ $ = p(1-p) \mu_1^2 + p(1-p) \mu_0^2 - 2p(1-p) \mu_1 \mu_0 $ Hopefully this is correct?","How would I find the distributional characteristics (mean, variance) of the following scenario: A Bernoulli random variable $X \sim B(1,p)$. If the $X = 1$, then $Y \sim N(\mu_1, \sigma_1^2)$. If the $X = 0$, then $Y \sim N(\mu_0, \sigma_0^2)$. One random variable is conditional on another. I know the mean of this scenario is $p \mu_1 +(1-p) \mu_0$, but what is the variance? Thank you so much. edit -- based on further research, this is what I have come up with: $Y | X=1 \sim N(\mu_1, \sigma_1^2)$ $Y | X=0 \sim N(\mu_0, \sigma_0^2)$ $E(Y) = E(E(Y|X)) = p \times E(Y|X=1) + (1-p) \times E(Y|X=0) = p \mu_1 + (1-p)  \mu_0$ And, $Var(Y) = E(V(Y|X)) +V(E(Y|X))$ $E(V(Y|X)) = p \sigma_1^2 + (1-p) \sigma_0^2$ $V(E(Y|X)) = E(E(Y|X)^2) - E(E(Y|X))^2 =E(E(Y|X)^2) - E(Y)^2$ $ = p \mu_1^2 + (1-p) \mu_0^2 - (p \mu_1 + (1-p) \mu_0)^2$ $ = p(1-p) \mu_1^2 + p(1-p) \mu_0^2 - 2p(1-p) \mu_1 \mu_0 $ Hopefully this is correct?",,"['probability', 'statistics']"
26,How to derive the put-call parity?,How to derive the put-call parity?,,"The following solution seems quite vague to me as I am not too sure how they thought of putting the terms on the right hand side together and similarly for lhs. I know that max(..) is the payoff, but why are we adding the strike to it? Any help would be really appreciated!","The following solution seems quite vague to me as I am not too sure how they thought of putting the terms on the right hand side together and similarly for lhs. I know that max(..) is the payoff, but why are we adding the strike to it? Any help would be really appreciated!",,"['probability', 'probability-theory', 'statistics', 'finance']"
27,MSE of computing PCA in a dataset,MSE of computing PCA in a dataset,,"I'm computing PCA of a dataset. My matrix $X$ has dimension $D\times I$, I'm trying to do a dimensionality reduce using PCA so I have $\Phi$ the matrix of the eigenvectors of the covariance matrix. We can approximate the data by $x = \Phi h$. And we do a dimensionality reduction if we select the fist $K$ columns $x \approx \Phi_{k} h$. I want to prove that the MSE that I'm doing by this approximation is $\sum^{D}_{i=K+1} \lambda_{i}$ where $\lambda$ are the eigenvalues of the covariance matrix. My approach is to do this: $MSE = \sum_{i} (x_{i} - \hat{x}_{i})^{2} = \sum_{i} (\Phi h_{i} - \Phi_{K} h_{i})^{2} = \sum_{i} (\sum^{D}_{j=1} \phi_{ij} h_{j} - \sum^{K}_{j=1} \phi_{ij} h_{j})^{2} = \sum_{i} (\sum^{D}_{j=K+1} \phi_{ij} h_{j})^{2} = \sum^{D}_{j=K+1}( \sum_{i} \phi_{ij} h_{j})^{2}$ So $¿\sum_{i} \phi_{ij} h_{j}^{2} = \lambda_{j}?$ Can anybody help me to discern this?","I'm computing PCA of a dataset. My matrix $X$ has dimension $D\times I$, I'm trying to do a dimensionality reduce using PCA so I have $\Phi$ the matrix of the eigenvectors of the covariance matrix. We can approximate the data by $x = \Phi h$. And we do a dimensionality reduction if we select the fist $K$ columns $x \approx \Phi_{k} h$. I want to prove that the MSE that I'm doing by this approximation is $\sum^{D}_{i=K+1} \lambda_{i}$ where $\lambda$ are the eigenvalues of the covariance matrix. My approach is to do this: $MSE = \sum_{i} (x_{i} - \hat{x}_{i})^{2} = \sum_{i} (\Phi h_{i} - \Phi_{K} h_{i})^{2} = \sum_{i} (\sum^{D}_{j=1} \phi_{ij} h_{j} - \sum^{K}_{j=1} \phi_{ij} h_{j})^{2} = \sum_{i} (\sum^{D}_{j=K+1} \phi_{ij} h_{j})^{2} = \sum^{D}_{j=K+1}( \sum_{i} \phi_{ij} h_{j})^{2}$ So $¿\sum_{i} \phi_{ij} h_{j}^{2} = \lambda_{j}?$ Can anybody help me to discern this?",,"['probability', 'statistics', 'proof-verification']"
28,Finding Probability of on arrangement,Finding Probability of on arrangement,,"In a box, there are $100$ tickets numbered $1,\cdots, 100$. Let five tickets are taken out randomly one by one and kept in same order. Let $x_1, x_2, x_3, x_4,x_5$  be the numbers on the tickets $1,2,3,4,5$ respectively. Find the probability  $$ a) P(x_1<x_2<x_3<x_4<x_5)?$$  $$ b) P(x_1<x_2<x_3>x_4>x_5)? $$ I am facing hard time solving this problem. If anyone helps that is well appreciated.","In a box, there are $100$ tickets numbered $1,\cdots, 100$. Let five tickets are taken out randomly one by one and kept in same order. Let $x_1, x_2, x_3, x_4,x_5$  be the numbers on the tickets $1,2,3,4,5$ respectively. Find the probability  $$ a) P(x_1<x_2<x_3<x_4<x_5)?$$  $$ b) P(x_1<x_2<x_3>x_4>x_5)? $$ I am facing hard time solving this problem. If anyone helps that is well appreciated.",,"['probability', 'probability-theory', 'statistics']"
29,"$ n $ different variances, same mean, what is the maximum-likelihood estimator of $ \mu $?","different variances, same mean, what is the maximum-likelihood estimator of ?", n   \mu ,"Observations $ X_1, X_2,\ldots,X_n$ are drawn from normal populations with the same mean $ \mu $ but with different variances $ \sigma_1^2, \sigma_2^2,\ldots, \sigma_n^2 $. Is it possible to estimate all the parameters? If we assume that the $ \sigma_i^2 $ are known, what is the maximum-likelihood estimator of $ \mu $? My attempt: The likelihood function is $$ L(x_1,\ldots,x_n; \mu, \sigma_1,\ldots, \sigma_n) = \frac 1 {(2\pi)^{n/2}} \prod_{i=1}^n \dfrac 1 {\sigma_i} e^{-\sum_{i=1}^n \dfrac{(x_i-\mu)^2}{2\sigma_i^2} }$$ Then we take the natural logarithm. We derive with respect to $ \sigma_i$  and we equate these derivatives to zero. We obtain $$ -\frac 1 {\sigma_i} + \frac{(x_i-\mu)^2}{\sigma_i^3} = 0 $$ From here we get that $$ \widehat{\sigma_i} = X_i - \mu$$ Is this correct? Analogously for the other question but now we derive with respect to $ \mu $.","Observations $ X_1, X_2,\ldots,X_n$ are drawn from normal populations with the same mean $ \mu $ but with different variances $ \sigma_1^2, \sigma_2^2,\ldots, \sigma_n^2 $. Is it possible to estimate all the parameters? If we assume that the $ \sigma_i^2 $ are known, what is the maximum-likelihood estimator of $ \mu $? My attempt: The likelihood function is $$ L(x_1,\ldots,x_n; \mu, \sigma_1,\ldots, \sigma_n) = \frac 1 {(2\pi)^{n/2}} \prod_{i=1}^n \dfrac 1 {\sigma_i} e^{-\sum_{i=1}^n \dfrac{(x_i-\mu)^2}{2\sigma_i^2} }$$ Then we take the natural logarithm. We derive with respect to $ \sigma_i$  and we equate these derivatives to zero. We obtain $$ -\frac 1 {\sigma_i} + \frac{(x_i-\mu)^2}{\sigma_i^3} = 0 $$ From here we get that $$ \widehat{\sigma_i} = X_i - \mu$$ Is this correct? Analogously for the other question but now we derive with respect to $ \mu $.",,"['statistics', 'estimation', 'maximum-likelihood']"
30,Data analysis over geometric distribution sample with R (statistics pack),Data analysis over geometric distribution sample with R (statistics pack),,"Problem : The following observations are the number of tries $21$ football players had to make until they succeeded in scoring a penalty kick. Consider that all players have equal skills. $$3 \quad 2 \quad 1 \quad 3 \quad 2 \quad 1 \quad 1 \quad 2 \quad 3 \quad 4 \quad 2 \quad 2 \quad 2 \quad 5 \quad 3 \quad 4 \quad 1 \quad 2 \quad 5 \quad 2 \quad 3$$ (i) Find analytically the Maximum Likelihood Estimator of the success rate of each player regarding the penalty kicks. (ii) Find graphically the Maximum Likelihood Estimator of the success rateo f each player regarding the penalty kicks, with the help of $\mathbf{R}$ (statistics pack-language) Attempt : (ii) One can easily see that the case of the specific problem leads to the conclusion that the observations follow the Geometric Distribution as it follows exactly by its definition (the number of trials $x$ needed until the first success). Thus, the Maximum Likelihood Estimator can be found us (Loglikelihood) : Let $X_1, X_2, \dots, X_n$ with p.d.f. $f(x;p)=(1-p)^{x_1}p, \; x=1,2,\dots$ .The likelihood function is given by :   $$L\left(p \right)={\left(1-p \right)}^{{x}_{1}-1}p {\left(1-p \right)}^{{x}_{2}-1}p...{\left(1-p \right)}^{{x}_{n}-1}p ={p}^{n}{\left(1-p \right)}^{\sum_{1}^{n}{x}_{i}-n}$$   By applying the natural logarithm, we get :   $$\ln L\left(p \right)= n\ln{p}+\left(\sum_{1}^{n}{x}_{i}-n \right)\ln{\left(1-p \right)}$$   Following differentiation and equaling to zero, we yield :   $$\frac{d\left[\ln L\left(p \right)\right]}{dp}=\frac{n}{p} -\frac{\left(\sum_{1}^{n}{x}_{i}-n \right)}{\left(1-p \right)}=0 \Rightarrow p=\frac{n}{\left(\sum_{1}^{n}{x}_{i} \right)}$$   which means that the Maximum Likelihood Estimator (Loglikelihood as we applied the logarithm) is :   $$P = \frac{n}{\left(\sum_{1}^{n}{x}_{i} \right)} =  \frac{1}{\bar{X}}$$ With the help of the statistics pack $\mathbf{R}$, we can write a short function to compute any Geometric Distribution Loglikelihood we'd like : which when we execute for a given vector $\mathbf{trials}$ with the given observations, it returns the wanted result. Question : My question is about part (ii) though, as I am completely at loss on how to proceed on estimating-calculating the Maximum Likelihood Estimator graphically with $\mathbf{R}$, especially since this is a case of a discrete distribution. I would really appreciate any hint or thorough explanation on how to proceed with it.","Problem : The following observations are the number of tries $21$ football players had to make until they succeeded in scoring a penalty kick. Consider that all players have equal skills. $$3 \quad 2 \quad 1 \quad 3 \quad 2 \quad 1 \quad 1 \quad 2 \quad 3 \quad 4 \quad 2 \quad 2 \quad 2 \quad 5 \quad 3 \quad 4 \quad 1 \quad 2 \quad 5 \quad 2 \quad 3$$ (i) Find analytically the Maximum Likelihood Estimator of the success rate of each player regarding the penalty kicks. (ii) Find graphically the Maximum Likelihood Estimator of the success rateo f each player regarding the penalty kicks, with the help of $\mathbf{R}$ (statistics pack-language) Attempt : (ii) One can easily see that the case of the specific problem leads to the conclusion that the observations follow the Geometric Distribution as it follows exactly by its definition (the number of trials $x$ needed until the first success). Thus, the Maximum Likelihood Estimator can be found us (Loglikelihood) : Let $X_1, X_2, \dots, X_n$ with p.d.f. $f(x;p)=(1-p)^{x_1}p, \; x=1,2,\dots$ .The likelihood function is given by :   $$L\left(p \right)={\left(1-p \right)}^{{x}_{1}-1}p {\left(1-p \right)}^{{x}_{2}-1}p...{\left(1-p \right)}^{{x}_{n}-1}p ={p}^{n}{\left(1-p \right)}^{\sum_{1}^{n}{x}_{i}-n}$$   By applying the natural logarithm, we get :   $$\ln L\left(p \right)= n\ln{p}+\left(\sum_{1}^{n}{x}_{i}-n \right)\ln{\left(1-p \right)}$$   Following differentiation and equaling to zero, we yield :   $$\frac{d\left[\ln L\left(p \right)\right]}{dp}=\frac{n}{p} -\frac{\left(\sum_{1}^{n}{x}_{i}-n \right)}{\left(1-p \right)}=0 \Rightarrow p=\frac{n}{\left(\sum_{1}^{n}{x}_{i} \right)}$$   which means that the Maximum Likelihood Estimator (Loglikelihood as we applied the logarithm) is :   $$P = \frac{n}{\left(\sum_{1}^{n}{x}_{i} \right)} =  \frac{1}{\bar{X}}$$ With the help of the statistics pack $\mathbf{R}$, we can write a short function to compute any Geometric Distribution Loglikelihood we'd like : which when we execute for a given vector $\mathbf{trials}$ with the given observations, it returns the wanted result. Question : My question is about part (ii) though, as I am completely at loss on how to proceed on estimating-calculating the Maximum Likelihood Estimator graphically with $\mathbf{R}$, especially since this is a case of a discrete distribution. I would really appreciate any hint or thorough explanation on how to proceed with it.",,"['statistics', 'probability-distributions', 'computational-mathematics', 'data-analysis']"
31,Metric for calculating lopsided distributions,Metric for calculating lopsided distributions,,"I have a list of ~20 numbers: 1200, 1200, 360, 360, 300, 250, 180, 180, 180, 180, 180, 90, 90, 90, 90, 45, 10, 0, 0 I am looking for a metric that determines the lopsidedness (maybe skewness) of this distribution. For the above example, I would want to be able to highlight that the sum of the first 2 numbers (2400) make up nearly 50% of the total sum (4985). But there could also be other examples where the top 4 or 5 numbers make up a big percentage (say, greater than 50%) of the total sum. Should I just calculate skewness or are there other better metrics that fulfill my requirement?","I have a list of ~20 numbers: 1200, 1200, 360, 360, 300, 250, 180, 180, 180, 180, 180, 90, 90, 90, 90, 45, 10, 0, 0 I am looking for a metric that determines the lopsidedness (maybe skewness) of this distribution. For the above example, I would want to be able to highlight that the sum of the first 2 numbers (2400) make up nearly 50% of the total sum (4985). But there could also be other examples where the top 4 or 5 numbers make up a big percentage (say, greater than 50%) of the total sum. Should I just calculate skewness or are there other better metrics that fulfill my requirement?",,['statistics']
32,What is the probability that the inequality $Y_{(m')}<X_{(m+1)}<Y_{(m'+1)}$ will hold?,What is the probability that the inequality  will hold?,Y_{(m')}<X_{(m+1)}<Y_{(m'+1)},"$X_1,X_2,...X_n$ and $Y_1,Y_2,..Y_n$ are independent random samples taken from the same continuous distribution with distribution function $F$.What is the probability that the inequality $Y_{(m')}<X_{(m+1)}<Y_{(m'+1)}$ where $0<m<n, 0<m'<n'$ will hold? My approach: I wrote $P[Y_{(m')}<X_{(m+1)}<Y_{(m'+1)}]=\int P(Y_{(m')}<X_{(m+1)}<Y_{(m'+1)}|X_{(m+1)}=x)f_{(m+1)}(x) \text{dx}$ $ \implies \int P(Y_{(m')}<x<Y_{(m'+1)})f_{(m+1)}(x) \text{dx}$ Now I know the expression for the pdf $f_{m+1}(x)\\$. Is $P(Y_{(m')}<x<Y_{(m'+1)})={n \choose m'}(F(x))^{m'}(1-F(x))^{n-m'}?$ And is my approach correct?","$X_1,X_2,...X_n$ and $Y_1,Y_2,..Y_n$ are independent random samples taken from the same continuous distribution with distribution function $F$.What is the probability that the inequality $Y_{(m')}<X_{(m+1)}<Y_{(m'+1)}$ where $0<m<n, 0<m'<n'$ will hold? My approach: I wrote $P[Y_{(m')}<X_{(m+1)}<Y_{(m'+1)}]=\int P(Y_{(m')}<X_{(m+1)}<Y_{(m'+1)}|X_{(m+1)}=x)f_{(m+1)}(x) \text{dx}$ $ \implies \int P(Y_{(m')}<x<Y_{(m'+1)})f_{(m+1)}(x) \text{dx}$ Now I know the expression for the pdf $f_{m+1}(x)\\$. Is $P(Y_{(m')}<x<Y_{(m'+1)})={n \choose m'}(F(x))^{m'}(1-F(x))^{n-m'}?$ And is my approach correct?",,"['probability', 'probability-theory']"
33,In conditional probability why does conditioning on a specific one yield a very different answer to conditioning on at least one,In conditional probability why does conditioning on a specific one yield a very different answer to conditioning on at least one,,"I was watching the Harvard stat110 course and there was this question pick a random 2 card hand from a standard deck. what is the probability that it's 2 ace given you have one ace what is the probability that it's 2 ace given you have ace of spade the result for Q1 is $\frac{1}{33}$ and the result for Q2 is $\frac{1}{17}$ in the lecture he mentioned a hint that it's because one is dealing with at least one while the other is a specific one, but I can't get my head around the intuition behind this idea.","I was watching the Harvard stat110 course and there was this question pick a random 2 card hand from a standard deck. what is the probability that it's 2 ace given you have one ace what is the probability that it's 2 ace given you have ace of spade the result for Q1 is $\frac{1}{33}$ and the result for Q2 is $\frac{1}{17}$ in the lecture he mentioned a hint that it's because one is dealing with at least one while the other is a specific one, but I can't get my head around the intuition behind this idea.",,"['probability', 'statistics']"
34,Probability that the experiment was performed using given die,Probability that the experiment was performed using given die,,"I have coin $A$ and coin $B$, and probabilities of obtaining heads are  $\theta_A=0.79$ for coin $A$ and $\theta_B=0.58$ for coin $B$. Given that the result of the experiment of $10$ tosses of one of the two coin was $HTTHHHTTHT$ which coin is more likely to produce it. I have met this problem when taking expectation maximisation module. I am really struggling to understand how to use empirical observation to calculate the chances of using each die.","I have coin $A$ and coin $B$, and probabilities of obtaining heads are  $\theta_A=0.79$ for coin $A$ and $\theta_B=0.58$ for coin $B$. Given that the result of the experiment of $10$ tosses of one of the two coin was $HTTHHHTTHT$ which coin is more likely to produce it. I have met this problem when taking expectation maximisation module. I am really struggling to understand how to use empirical observation to calculate the chances of using each die.",,"['probability', 'statistics']"
35,martingale central limit theorem,martingale central limit theorem,,"Suppose $(X_{n},\mathcal{F}_n)_{n\ge 1}$ be a martingale with $\sigma_n:= \|{X_n}\|_2<\infty$, and $\Delta_n=X_n-X_{n-1}$. Under the following assumptions (i) $\sigma_n \to \infty$ as $n\to\infty$, (ii) for any $\varepsilon >0$, $\frac{1}{\sigma_n^2}\sum_{i=1}^n E\left( \Delta_i^2\mathbb{1}_{\{|\Delta_i| \ge \varepsilon \sigma_n \}}\right) \to 0 \text{ as } n\to\infty$ . (iii) Define $G_n^2:= \sum_{i=1}^n E(\Delta_i^{2}\mid\mathcal{F}_{i-1})$, we have $ \sigma_n^{-2}G_n^2\to 1$ in Prob as $n\to\infty$. (iv) $\sup_n\sigma_n^{-2}G_n^2\le a<\infty$ a.s. Show that $ \frac{X_n}{\sigma_n}\Rightarrow \text{N}(0,1)\text{ as } n\to\infty. $ I got a hint that using Lindeberg technique to prove $E\exp(i t \sigma_n^{-1}X_n + \frac12\sigma_n^{-2}G_n^2t^2) \to 1$ as $n\to\infty$ for all $t\in\mathbb R$. Is this one type of martingale CLT? How I can prove it under the assumption (i)-(iv)?","Suppose $(X_{n},\mathcal{F}_n)_{n\ge 1}$ be a martingale with $\sigma_n:= \|{X_n}\|_2<\infty$, and $\Delta_n=X_n-X_{n-1}$. Under the following assumptions (i) $\sigma_n \to \infty$ as $n\to\infty$, (ii) for any $\varepsilon >0$, $\frac{1}{\sigma_n^2}\sum_{i=1}^n E\left( \Delta_i^2\mathbb{1}_{\{|\Delta_i| \ge \varepsilon \sigma_n \}}\right) \to 0 \text{ as } n\to\infty$ . (iii) Define $G_n^2:= \sum_{i=1}^n E(\Delta_i^{2}\mid\mathcal{F}_{i-1})$, we have $ \sigma_n^{-2}G_n^2\to 1$ in Prob as $n\to\infty$. (iv) $\sup_n\sigma_n^{-2}G_n^2\le a<\infty$ a.s. Show that $ \frac{X_n}{\sigma_n}\Rightarrow \text{N}(0,1)\text{ as } n\to\infty. $ I got a hint that using Lindeberg technique to prove $E\exp(i t \sigma_n^{-1}X_n + \frac12\sigma_n^{-2}G_n^2t^2) \to 1$ as $n\to\infty$ for all $t\in\mathbb R$. Is this one type of martingale CLT? How I can prove it under the assumption (i)-(iv)?",,"['probability', 'probability-theory', 'statistics', 'measure-theory', 'stochastic-processes']"
36,Distribution of maximum of i.i.d. Chi-Square random variables with degree-of-freedom 2,Distribution of maximum of i.i.d. Chi-Square random variables with degree-of-freedom 2,,"I wondering how the probability distribution of the maximum of i.i.d. Chi-square (two degrees-of-freedom) random variables $X_i \sim \chi^2(2)$ has the same distribution as $\sum_{i=1}^K \frac{X_i}{i}$, i.e., $$\max_{i=1,\ldots,K} X_i \ \stackrel{d}{=} \ \sum_{i=1}^K \frac{X_i}i .$$ Can anyone help me to prove this? Thank you","I wondering how the probability distribution of the maximum of i.i.d. Chi-square (two degrees-of-freedom) random variables $X_i \sim \chi^2(2)$ has the same distribution as $\sum_{i=1}^K \frac{X_i}{i}$, i.e., $$\max_{i=1,\ldots,K} X_i \ \stackrel{d}{=} \ \sum_{i=1}^K \frac{X_i}i .$$ Can anyone help me to prove this? Thank you",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
37,Statistics: Hypothesis Testing,Statistics: Hypothesis Testing,,"Hypothesis Testing I have 4 groups of data for four different locations i.e. A, B, C and D (close to each other). In each group, there are 3 columns of data (x, y, z) showing the temperature at the location taken by thermometer at a different height i.e. 50, 100, 150 cm above ground at that location. How would I use Excel to write some hypotheses to investigate what differences there may be between the temperature measurements at the different locations and heights? I am thinking about descriptive statistics / T-testing.","Hypothesis Testing I have 4 groups of data for four different locations i.e. A, B, C and D (close to each other). In each group, there are 3 columns of data (x, y, z) showing the temperature at the location taken by thermometer at a different height i.e. 50, 100, 150 cm above ground at that location. How would I use Excel to write some hypotheses to investigate what differences there may be between the temperature measurements at the different locations and heights? I am thinking about descriptive statistics / T-testing.",,['statistics']
38,Are two proportions significantly different? [closed],Are two proportions significantly different? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question everyone! The questions below I need help from are from 3-6. Here it is: Risk Factors for Low Birth Weight: Rates of infant mortality, birth defect, and premature labor are high for babies with low birth weight. There are many factors that may contribute to low birth weight. In this activity, we use data from a random sample of women who participated in a study in 1986 at the Baystate Medical Center in Springfield, MA. (Source: Hosmer and Lemeshow (2000), Applied Logistic Regression: Second Edition.) For the 30 women in the study with a history of premature labor, a proportion of 18/30 = 0.60 (60%) had babies with low birth weight. For the remaining 159 women, a proportion of 41/159 = 0.26 (26%) had babies with low birth weight. We now investigate the following research question: do the data provide evidence that the proportion of babies born with low birth weight is higher for women with a history of premature labor? This question is answered with a hypothesis test. To conduct the test we use a 1% level of significance. Question 3: We will test the claim that the proportion of women with low birth weight babies is higher among women with a history of premature labor. What are the null and alternative hypotheses? Question 4: Are the criteria for approximate normality satisfied? Question 5: State the test statistic and P-value. Interpret these values. Question 6: Give a conclusion in context, and discuss whether a causal conclusion is appropriate.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question everyone! The questions below I need help from are from 3-6. Here it is: Risk Factors for Low Birth Weight: Rates of infant mortality, birth defect, and premature labor are high for babies with low birth weight. There are many factors that may contribute to low birth weight. In this activity, we use data from a random sample of women who participated in a study in 1986 at the Baystate Medical Center in Springfield, MA. (Source: Hosmer and Lemeshow (2000), Applied Logistic Regression: Second Edition.) For the 30 women in the study with a history of premature labor, a proportion of 18/30 = 0.60 (60%) had babies with low birth weight. For the remaining 159 women, a proportion of 41/159 = 0.26 (26%) had babies with low birth weight. We now investigate the following research question: do the data provide evidence that the proportion of babies born with low birth weight is higher for women with a history of premature labor? This question is answered with a hypothesis test. To conduct the test we use a 1% level of significance. Question 3: We will test the claim that the proportion of women with low birth weight babies is higher among women with a history of premature labor. What are the null and alternative hypotheses? Question 4: Are the criteria for approximate normality satisfied? Question 5: State the test statistic and P-value. Interpret these values. Question 6: Give a conclusion in context, and discuss whether a causal conclusion is appropriate.",,"['statistics', 'statistical-inference']"
39,Variance in the number of triangles in a random graph of size n,Variance in the number of triangles in a random graph of size n,,"Consider the set $V=\{1,2,…,n\}$ and let $p$ be a real number with $0<p<1$. We construct a graph $G=(V,E)$ with vertex set $V$, whose edge set $E$ is determined by the following random process: Each unordered pair $\{i,j\}$ of vertices, where $i≠j$, occurs as an edge in E with probability $p$, independently of the other unordered pairs. A triangle in G is an unordered triple $\{i,j,k\}$ of distinct vertices, such that $\{i,j\}$, $\{j,k\}$, and $\{k,i\}$ are edges in $G$. Define the random variable $X$ to be the total number of triangles in the graph $G$. Determine $var(X)$. I need help because I can't think of a random variable without making it independent.","Consider the set $V=\{1,2,…,n\}$ and let $p$ be a real number with $0<p<1$. We construct a graph $G=(V,E)$ with vertex set $V$, whose edge set $E$ is determined by the following random process: Each unordered pair $\{i,j\}$ of vertices, where $i≠j$, occurs as an edge in E with probability $p$, independently of the other unordered pairs. A triangle in G is an unordered triple $\{i,j,k\}$ of distinct vertices, such that $\{i,j\}$, $\{j,k\}$, and $\{k,i\}$ are edges in $G$. Define the random variable $X$ to be the total number of triangles in the graph $G$. Determine $var(X)$. I need help because I can't think of a random variable without making it independent.",,"['probability', 'combinatorics', 'statistics', 'expectation', 'variance']"
40,Complete Statistics for Uniform Distribution,Complete Statistics for Uniform Distribution,,"Let $X_1, X_2, ..., X_n$ be independent and identically distributed uniform $U(0, \theta)$ distribution where $0 < \theta < \infty $. Show that $T(X)=max X_i$ is a complete statistics. My biggest problem here is how to find the uniform distribution? Is it either: a) The pdf is $f(x; \theta )$=$ \frac{1}{ \theta -0 }$=$ \frac{1}{ \theta }$ or b) $f(x; \theta )$=$ \frac{1}{ \theta_2 - \theta_1 }$=$ \frac{1}{ \sqrt{3 \theta} + \sqrt{3 \theta } }$ = $ \frac{1}{ 2 \sqrt{3 \theta} }$ because the mean is $0$ and variance $ \theta $, where I find the value of $ \theta_1 $ and $ \theta_2 $ from it. Then to find the complete statistics, I need to find the likelihood function and because it's need to show the maximum value, so I need to find it using order statistics $f_{Y_n}$ But, I can't continue since I'm not sure with my pdf of Uniform distribution. Really appreciated if anyone could clear up the way to find the pdf of the Uniform distribution?","Let $X_1, X_2, ..., X_n$ be independent and identically distributed uniform $U(0, \theta)$ distribution where $0 < \theta < \infty $. Show that $T(X)=max X_i$ is a complete statistics. My biggest problem here is how to find the uniform distribution? Is it either: a) The pdf is $f(x; \theta )$=$ \frac{1}{ \theta -0 }$=$ \frac{1}{ \theta }$ or b) $f(x; \theta )$=$ \frac{1}{ \theta_2 - \theta_1 }$=$ \frac{1}{ \sqrt{3 \theta} + \sqrt{3 \theta } }$ = $ \frac{1}{ 2 \sqrt{3 \theta} }$ because the mean is $0$ and variance $ \theta $, where I find the value of $ \theta_1 $ and $ \theta_2 $ from it. Then to find the complete statistics, I need to find the likelihood function and because it's need to show the maximum value, so I need to find it using order statistics $f_{Y_n}$ But, I can't continue since I'm not sure with my pdf of Uniform distribution. Really appreciated if anyone could clear up the way to find the pdf of the Uniform distribution?",,"['statistics', 'probability-distributions', 'statistical-inference', 'uniform-distribution', 'order-statistics']"
41,Generating good data for linear regression,Generating good data for linear regression,,"I would like to generate a good big data set for a linear regression exercise for my students. We will try to explain the salary (continuous variable) of 50 people in terms of their results high school results (/20, we suppose that those are continuous) in 5 subjects, for example maths, physics, chemistry, English, German. What I mean by a good data set is: -It satisfies usual conditions for linear regression -It has some logic to it, that is if you're good in maths, you're likely to be good in physics , and not bad in chemistry. If you're extremely good in a few subjects, then you'll unlikely fail an exam (<10/20). -Not obvious, so students can see the importance of the linear regression. What I mean is that if I generate 1 vector of salary, 5 vectors of results, and for each vector, order it from the smallest value, to the highest and put all of them in a matrix, we don't really need linear regression to see a pattern, it is too obvious. Does a tool exists for such generation ? How can one proceed ? Preferably in R or matlab.","I would like to generate a good big data set for a linear regression exercise for my students. We will try to explain the salary (continuous variable) of 50 people in terms of their results high school results (/20, we suppose that those are continuous) in 5 subjects, for example maths, physics, chemistry, English, German. What I mean by a good data set is: -It satisfies usual conditions for linear regression -It has some logic to it, that is if you're good in maths, you're likely to be good in physics , and not bad in chemistry. If you're extremely good in a few subjects, then you'll unlikely fail an exam (<10/20). -Not obvious, so students can see the importance of the linear regression. What I mean is that if I generate 1 vector of salary, 5 vectors of results, and for each vector, order it from the smallest value, to the highest and put all of them in a matrix, we don't really need linear regression to see a pattern, it is too obvious. Does a tool exists for such generation ? How can one proceed ? Preferably in R or matlab.",,"['probability', 'statistics', 'statistical-inference', 'regression']"
42,Monty Hall Variant Game,Monty Hall Variant Game,,"There are three doors, behind each is either a car, or a goat.  Unlike the original Monty Hall problem, there are 8, equally likely possibilites for the setup of the doors.  The possibility sample space can be represented by all possible 3-element long sequences using a 0 (a goat), or a 1 (a car).  The sequence 011 represents a goat in the left door, and a car in the remaining two.  Also unlike the original problem, Monty will randomly choose one of the two doors you did not pick.  If Monty opens a door with a car, you can not get the car from that door.  This means that there are possibilities (besides 000 ), where you can not win anything.  There is also the possibility of 111 , where you have a 100% chance of winning a car. The original door you pick is always the left one.  I took the liberty of creating a table with all the possible outcomes, given which door is opened by Monty. In the picture, D m , and D r represent Monty opening the middle and right doors, repectively.  Depending on what is behind the door Monty opens, 1/2 of the sequences are elimated from the sample space of door setups you have.  However, all remaining sequences are still equally likely. My question is this: what is the probability of you winning any giving game?  Does it boil down to 50% Also, if you played repeately, what is the expected value for the number of cars you are expected to win in any given game? What is the value for the number of games you have to play to have ~100% of winning one game?  8?","There are three doors, behind each is either a car, or a goat.  Unlike the original Monty Hall problem, there are 8, equally likely possibilites for the setup of the doors.  The possibility sample space can be represented by all possible 3-element long sequences using a 0 (a goat), or a 1 (a car).  The sequence 011 represents a goat in the left door, and a car in the remaining two.  Also unlike the original problem, Monty will randomly choose one of the two doors you did not pick.  If Monty opens a door with a car, you can not get the car from that door.  This means that there are possibilities (besides 000 ), where you can not win anything.  There is also the possibility of 111 , where you have a 100% chance of winning a car. The original door you pick is always the left one.  I took the liberty of creating a table with all the possible outcomes, given which door is opened by Monty. In the picture, D m , and D r represent Monty opening the middle and right doors, repectively.  Depending on what is behind the door Monty opens, 1/2 of the sequences are elimated from the sample space of door setups you have.  However, all remaining sequences are still equally likely. My question is this: what is the probability of you winning any giving game?  Does it boil down to 50% Also, if you played repeately, what is the expected value for the number of cars you are expected to win in any given game? What is the value for the number of games you have to play to have ~100% of winning one game?  8?",,"['probability', 'sequences-and-series', 'statistics', 'discrete-mathematics', 'monty-hall']"
43,"What are the implicit assumptions that justify the usage of the ""relative error""?","What are the implicit assumptions that justify the usage of the ""relative error""?",,"In applied statistics, for example, analyzing data from a science experiment, we sometimes use ""absolute error"" while at the most of time, we calculate the ""relative error"". Generally, under what circumstances should we use the ""relative error"" instead of ""the absolute error""? If we use relative error, are we basically implicitly assuming that the variance of the sample distribution is positively correlated with the value of the mean? Is there a fundamental axiom in mathematics or statistics called ""scale independence""? It is same in the financial math literature, the variance of the random variable $X_t$ is usually correlated with the exact value of $X_{t-1}$. If $X_{t-1}$ is greater, the variance of $X_t$ is greater. This often leads to something like a Lognormal distribution.","In applied statistics, for example, analyzing data from a science experiment, we sometimes use ""absolute error"" while at the most of time, we calculate the ""relative error"". Generally, under what circumstances should we use the ""relative error"" instead of ""the absolute error""? If we use relative error, are we basically implicitly assuming that the variance of the sample distribution is positively correlated with the value of the mean? Is there a fundamental axiom in mathematics or statistics called ""scale independence""? It is same in the financial math literature, the variance of the random variable $X_t$ is usually correlated with the exact value of $X_{t-1}$. If $X_{t-1}$ is greater, the variance of $X_t$ is greater. This often leads to something like a Lognormal distribution.",,"['statistics', 'probability-distributions']"
44,How to compute a prediction interval for an exponentially distributed random variable.,How to compute a prediction interval for an exponentially distributed random variable.,,"I have fitted an exponential model to some data using maximum likelihood estimation and am now trying to compute a prediction interval for a new observation, $P$, which has a corresponding explanatory variable equal to $70$. Under my model, $P \sim \text{Exp}(e^{\beta_1 + \beta_2 \times 70})$ and I have estimated $\hat{\beta}_1 = -4.317$ and $\hat{\beta}_2 = -0.028$. Further, the inverse observed fisher information for the model is: $$-H(\boldsymbol{\hat{\theta}})^{-1} = \begin{bmatrix} 0.615 & -0.009 \\ -0.009 & 0.00017 \end{bmatrix}$$ My question is, how can I create a $95\%$ prediction interval for $P$ using this information?","I have fitted an exponential model to some data using maximum likelihood estimation and am now trying to compute a prediction interval for a new observation, $P$, which has a corresponding explanatory variable equal to $70$. Under my model, $P \sim \text{Exp}(e^{\beta_1 + \beta_2 \times 70})$ and I have estimated $\hat{\beta}_1 = -4.317$ and $\hat{\beta}_2 = -0.028$. Further, the inverse observed fisher information for the model is: $$-H(\boldsymbol{\hat{\theta}})^{-1} = \begin{bmatrix} 0.615 & -0.009 \\ -0.009 & 0.00017 \end{bmatrix}$$ My question is, how can I create a $95\%$ prediction interval for $P$ using this information?",,"['statistics', 'statistical-inference', 'mathematical-modeling', 'maximum-likelihood']"
45,Exercise 2.20 from “Mathematical Statistics - Jun Shao”,Exercise 2.20 from “Mathematical Statistics - Jun Shao”,,"Let ${ \left\{ X_{ i } \right\}  }_{ i=1 }^{ n } \sim E(a,\theta)$   where $a \in {\rm I\!R}$, and $\theta > 0$. Show that the smallest   order statistic, $X_{(1)}$, has the exponential distribution   $E(a,\theta/n)$ and that $2\sum _{ i=1 }^{ n }{ (X_{ i }-X_{ (1) }) }  /\theta \sim { \chi  }_{ 2n-2 }^{ 2 }$. I have shown that the smallest order statistic $X_{(1)} \sim E(a,\theta/n)$. But I'm struggling in the second part. I think I can use the Basu Theorem, but I believe that there are other simpler option. Any hint?","Let ${ \left\{ X_{ i } \right\}  }_{ i=1 }^{ n } \sim E(a,\theta)$   where $a \in {\rm I\!R}$, and $\theta > 0$. Show that the smallest   order statistic, $X_{(1)}$, has the exponential distribution   $E(a,\theta/n)$ and that $2\sum _{ i=1 }^{ n }{ (X_{ i }-X_{ (1) }) }  /\theta \sim { \chi  }_{ 2n-2 }^{ 2 }$. I have shown that the smallest order statistic $X_{(1)} \sim E(a,\theta/n)$. But I'm struggling in the second part. I think I can use the Basu Theorem, but I believe that there are other simpler option. Any hint?",,"['statistics', 'statistical-inference', 'order-statistics']"
46,$L_2$ norm of the generalized inverse of the empirical cumulative distribution function,norm of the generalized inverse of the empirical cumulative distribution function,L_2,"Can anyone give me some insight on how to solve this problem? Any help would be greatly appreciated ! Let $(X_n)_{n \geq 1}$ an i.i.d. sequence of real valued r.v.'s with c.d.f. $F$ which is stricly increasing and has two derivatives everywhere. Let $F_n(x) = \frac{1}{n}\sum_{i=1}^n {\bf 1}_{X_i \leq x}$ be the empirical c.d.f., $F_n^{(-1)}(u) = \inf\{x \in \mathbb{R} | F_n(x) \geq u\}$ be the generalized inverse of the empirical cumulative distribution function and $F^{-1}$ be the inverse of $F$. Note that $F_n^{(-1)}(u) = X_{(k_n)}$ where $k_n = \lceil nu \rceil$. Is this true that under the above hypothesis,  \begin{equation} \mathbb{E}\big[\big(F_n^{(-1)}(u) - F^{-1}(u)\big)^2\big] \end{equation} is uniformly bounded? Thank you","Can anyone give me some insight on how to solve this problem? Any help would be greatly appreciated ! Let $(X_n)_{n \geq 1}$ an i.i.d. sequence of real valued r.v.'s with c.d.f. $F$ which is stricly increasing and has two derivatives everywhere. Let $F_n(x) = \frac{1}{n}\sum_{i=1}^n {\bf 1}_{X_i \leq x}$ be the empirical c.d.f., $F_n^{(-1)}(u) = \inf\{x \in \mathbb{R} | F_n(x) \geq u\}$ be the generalized inverse of the empirical cumulative distribution function and $F^{-1}$ be the inverse of $F$. Note that $F_n^{(-1)}(u) = X_{(k_n)}$ where $k_n = \lceil nu \rceil$. Is this true that under the above hypothesis,  \begin{equation} \mathbb{E}\big[\big(F_n^{(-1)}(u) - F^{-1}(u)\big)^2\big] \end{equation} is uniformly bounded? Thank you",,"['probability-theory', 'statistics', 'asymptotics', 'normed-spaces']"
47,"Markov's inequality, unclear Wikipedia intuition","Markov's inequality, unclear Wikipedia intuition",,"Search for the word ""intuitive"" here . I do not understand how $$E[X]=0\cdot \bar{a}+\frac{E[X]}{a}\cdot a$$ shows anything at all. I would like to see an intuitive proof of an upper bound of $P(x\geq a)$ which should be $$P(x\geq a)\leq \frac{E[X]}{a}.$$","Search for the word ""intuitive"" here . I do not understand how $$E[X]=0\cdot \bar{a}+\frac{E[X]}{a}\cdot a$$ shows anything at all. I would like to see an intuitive proof of an upper bound of $P(x\geq a)$ which should be $$P(x\geq a)\leq \frac{E[X]}{a}.$$",,"['probability', 'statistics', 'inequality', 'means']"
48,Higher moments are minimized around WHAT point?,Higher moments are minimized around WHAT point?,,"It is well known that the 2nd moment (physics: moment of inertia) is minimized when centered around the mean (physics: center of mass).  However, I recently realized that higher moments are NOT minimized at the same point.  Specifically let me ask the 1-dimensional, discrete version of the question: Given point masses $\{m_i\}$ all lying along the $x$-axis, with positions $\{x_i\}$.  What value of $x$ would minimize $\sum m_i |x-x_i|^k$, for values of $k>2$?  (If we normalize $\sum m_i=1$, then an equivalent interpretation is a real-valued random variable $X$ taking value $x_i$ with probability $m_i$.) Here are some partial solutions: (A) For $k=2$, the optimal $x$ is the (weighted) mean, aka center of mass, $x^* = \frac{\sum m_i x_i}{\sum m_i}$. (B) For $k \rightarrow \infty$, the optimal $x$ is the point that minimizes the maximum individual ""deviation"" $d_i = |x-x_i|$, so the optimum is halfway between the leftmost and rightmost points, i.e. $x^* = (\min_i x_i + \max_i x_i)/2$ (C) For any $k\ge2$, if there are just two point masses, the optimal $x$ is the value satisfying: $m_1 d_1^{k-1} = m_2 d_2^{k-1}$, where $d_i = |x-x_i|$.  (Easy proof by differentiating $m_1 d_1^k + m_2 d_2^k$.) Any idea how to solve the general problem? (Updated Note: For odd $k$, a different version of the problem would be to minimize $\sum m_i (x - x_i)^k$ -- but that sum has no minimum because $\sum m_i (x - x_i)^k \rightarrow -\infty$ as $x \rightarrow -\infty$.)","It is well known that the 2nd moment (physics: moment of inertia) is minimized when centered around the mean (physics: center of mass).  However, I recently realized that higher moments are NOT minimized at the same point.  Specifically let me ask the 1-dimensional, discrete version of the question: Given point masses $\{m_i\}$ all lying along the $x$-axis, with positions $\{x_i\}$.  What value of $x$ would minimize $\sum m_i |x-x_i|^k$, for values of $k>2$?  (If we normalize $\sum m_i=1$, then an equivalent interpretation is a real-valued random variable $X$ taking value $x_i$ with probability $m_i$.) Here are some partial solutions: (A) For $k=2$, the optimal $x$ is the (weighted) mean, aka center of mass, $x^* = \frac{\sum m_i x_i}{\sum m_i}$. (B) For $k \rightarrow \infty$, the optimal $x$ is the point that minimizes the maximum individual ""deviation"" $d_i = |x-x_i|$, so the optimum is halfway between the leftmost and rightmost points, i.e. $x^* = (\min_i x_i + \max_i x_i)/2$ (C) For any $k\ge2$, if there are just two point masses, the optimal $x$ is the value satisfying: $m_1 d_1^{k-1} = m_2 d_2^{k-1}$, where $d_i = |x-x_i|$.  (Easy proof by differentiating $m_1 d_1^k + m_2 d_2^k$.) Any idea how to solve the general problem? (Updated Note: For odd $k$, a different version of the problem would be to minimize $\sum m_i (x - x_i)^k$ -- but that sum has no minimum because $\sum m_i (x - x_i)^k \rightarrow -\infty$ as $x \rightarrow -\infty$.)",,"['probability', 'statistics', 'moment-problem']"
49,Conditional cases of uniformly distributed shapes of unknown area,Conditional cases of uniformly distributed shapes of unknown area,,"Consider a disk centered at the origin.  Let $X$ and $Y$ be uniformly distributed on the disk.  The conditional distribution of $Y$ given $X=x$ can be found as shown below. $$f(x,y)=\frac{1}{\pi r^{2}},-\sqrt{r^{2}-x^{2}} \leq y\leq \sqrt{r^{2}-x^{2}}.$$ $$f_{Y|X}(y|x)=\frac{f(x,y)}{f_{x}(x)}.$$ $${f_{x}(x)}=\int_{a}^{b}f(x,y)dy=\int_{-\sqrt{r^{2}-x^{2}}}^{\sqrt{r^{2}-x^{2}}}\frac{1}{\pi r^{2}}dy = \frac{2\sqrt{r^{2}-x^{2}}}{\pi r^{2}}.$$ $$\frac{f(x,y)}{f_{x}(x)} =\frac{\frac{1}{\pi r^{2}}}{\frac{2\sqrt{r^{2}-x^{2}}}{\pi r^{2}}} = \frac{1}{2\sqrt{r^{2}-x^{2}}}.$$ I find it interesting that the area of the circle cancels out when calculating this conditional distribution.  The conditional distribution only depends on the radius.  This raises the question: If we have a polygon with $n$ sides and an unknown area, can we use this previous calculation to derive its conditional distribution if $X$ and $Y$ are uniformly distributed on the space? A general formula may look something like: $$\frac{1}{Ubound-Lbound}.$$","Consider a disk centered at the origin.  Let $X$ and $Y$ be uniformly distributed on the disk.  The conditional distribution of $Y$ given $X=x$ can be found as shown below. $$f(x,y)=\frac{1}{\pi r^{2}},-\sqrt{r^{2}-x^{2}} \leq y\leq \sqrt{r^{2}-x^{2}}.$$ $$f_{Y|X}(y|x)=\frac{f(x,y)}{f_{x}(x)}.$$ $${f_{x}(x)}=\int_{a}^{b}f(x,y)dy=\int_{-\sqrt{r^{2}-x^{2}}}^{\sqrt{r^{2}-x^{2}}}\frac{1}{\pi r^{2}}dy = \frac{2\sqrt{r^{2}-x^{2}}}{\pi r^{2}}.$$ $$\frac{f(x,y)}{f_{x}(x)} =\frac{\frac{1}{\pi r^{2}}}{\frac{2\sqrt{r^{2}-x^{2}}}{\pi r^{2}}} = \frac{1}{2\sqrt{r^{2}-x^{2}}}.$$ I find it interesting that the area of the circle cancels out when calculating this conditional distribution.  The conditional distribution only depends on the radius.  This raises the question: If we have a polygon with $n$ sides and an unknown area, can we use this previous calculation to derive its conditional distribution if $X$ and $Y$ are uniformly distributed on the space? A general formula may look something like: $$\frac{1}{Ubound-Lbound}.$$",,['probability']
50,Notation for a sequence of normal random variables with changing mean and variance.,Notation for a sequence of normal random variables with changing mean and variance.,,"What would be an accurate mathematical notation for the following: A sequence of $T$ random variables, where each element up to $\kappa$ is a normally distributed with mean $\mu_1$ and variance $\sigma^2_1$, and each element from $\kappa$ to $T$ is a normally distributed with mean $\mu_2$ and variance $\sigma^2_2$. I came up with something like: $X = \{x_t:t=1,\dots,\kappa,\dots T\}$ where $x_t \sim \operatorname{N}(\mu_1,\sigma^2_1)$ if $t \leq \kappa$ and $x_t \sim \operatorname{N}(\mu_2,\sigma^2_2)$ if $t> \kappa$. But I have no idea if that is correct. Does anyone know an elegant way to write this? Thanks in advance!","What would be an accurate mathematical notation for the following: A sequence of $T$ random variables, where each element up to $\kappa$ is a normally distributed with mean $\mu_1$ and variance $\sigma^2_1$, and each element from $\kappa$ to $T$ is a normally distributed with mean $\mu_2$ and variance $\sigma^2_2$. I came up with something like: $X = \{x_t:t=1,\dots,\kappa,\dots T\}$ where $x_t \sim \operatorname{N}(\mu_1,\sigma^2_1)$ if $t \leq \kappa$ and $x_t \sim \operatorname{N}(\mu_2,\sigma^2_2)$ if $t> \kappa$. But I have no idea if that is correct. Does anyone know an elegant way to write this? Thanks in advance!",,"['sequences-and-series', 'statistics', 'notation', 'time-series']"
51,How can one quantify the convergence of relative frequency to probability?,How can one quantify the convergence of relative frequency to probability?,,"I have a rather basic question about statistics but I am unable to find an answer in the literature I have at hand. Say I run a simple Bernoulli trial a number of times and compute the relative frequency for success. Clearly the relative frequency should represent the underlying probability for success better the more experiments I run. My question is this: Is there any way to say how close the two values are given the number of times the experiment was run? For example if I run the experiment $N$ times, what is the expected deviation of the relative frequency and the probability? Or turning the question around: If I want to know the probability up to an uncertainty of $\varepsilon$, how many experiments do I have to run? Any pointers to results in this direction would be appreciated.","I have a rather basic question about statistics but I am unable to find an answer in the literature I have at hand. Say I run a simple Bernoulli trial a number of times and compute the relative frequency for success. Clearly the relative frequency should represent the underlying probability for success better the more experiments I run. My question is this: Is there any way to say how close the two values are given the number of times the experiment was run? For example if I run the experiment $N$ times, what is the expected deviation of the relative frequency and the probability? Or turning the question around: If I want to know the probability up to an uncertainty of $\varepsilon$, how many experiments do I have to run? Any pointers to results in this direction would be appreciated.",,"['probability-theory', 'statistics', 'statistical-inference', 'descriptive-statistics', 'confidence-interval']"
52,Expectation and Variance of $\bar{X}/S$ [closed],Expectation and Variance of  [closed],\bar{X}/S,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I got stuck on the following problem: Let $X_1 , \dots , X_n$ be iid from  $N(\mu,\sigma^2)$. How can I obtain E$(\bar{X}/S)$, E$((\bar{X}/S)^2)$ and E$(\bar{X}^2)$, E$((\bar{X}^2)^2)$? $\bar{X}$ is the sample mean and $S^2$ sample variance. I've tried jacobian method for the first without success, and no idea on how to deal with the second. Thanks for your help","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I got stuck on the following problem: Let $X_1 , \dots , X_n$ be iid from  $N(\mu,\sigma^2)$. How can I obtain E$(\bar{X}/S)$, E$((\bar{X}/S)^2)$ and E$(\bar{X}^2)$, E$((\bar{X}^2)^2)$? $\bar{X}$ is the sample mean and $S^2$ sample variance. I've tried jacobian method for the first without success, and no idea on how to deal with the second. Thanks for your help",,"['probability', 'statistics', 'statistical-inference']"
53,How does Law of Total Probability apply here?,How does Law of Total Probability apply here?,,Cumulative Distribution Function for Sum of Continuous Distributions That means $X\in x$ is a partition of $X+Y$ ? But how could that be? It only accounts for the $X$ part.,Cumulative Distribution Function for Sum of Continuous Distributions That means is a partition of ? But how could that be? It only accounts for the part.,X\in x X+Y X,['statistics']
54,Probability that two consecutively generated integers with normal distribution are the same,Probability that two consecutively generated integers with normal distribution are the same,,"Given a random number generator that generates numbers $x\in\mathbb{R}$ with a normal probability distribution, with mean $\mu$ and standard deviation $\sigma$, and then rounds these numbers to the closest integer $y=\lfloor x+\frac{1}{2}\rfloor$. I'd like to know if there's a way (other than simulation) to calculate the probability that two consecutive values generated by the generator are the same? For example, if $\mu = 100.0$, $\sigma = 50.0$ and $y = 123$, what's the probability of this occurrence? That is to say, what's the combined probability of two two consecutively generated raw numbers of the generator to be in the range $[y-\frac{1}{2},y+\frac{1}{2})$? I'm guessing something like $(\Phi(y-\frac{1}{2})-\Phi(y+\frac{1}{2}))^2$ or a scaled version thereof?","Given a random number generator that generates numbers $x\in\mathbb{R}$ with a normal probability distribution, with mean $\mu$ and standard deviation $\sigma$, and then rounds these numbers to the closest integer $y=\lfloor x+\frac{1}{2}\rfloor$. I'd like to know if there's a way (other than simulation) to calculate the probability that two consecutive values generated by the generator are the same? For example, if $\mu = 100.0$, $\sigma = 50.0$ and $y = 123$, what's the probability of this occurrence? That is to say, what's the combined probability of two two consecutively generated raw numbers of the generator to be in the range $[y-\frac{1}{2},y+\frac{1}{2})$? I'm guessing something like $(\Phi(y-\frac{1}{2})-\Phi(y+\frac{1}{2}))^2$ or a scaled version thereof?",,"['statistics', 'normal-distribution']"
55,Is a two dimensional rotationally symmetric probability density function equivalent to a radial one dimensional density function??,Is a two dimensional rotationally symmetric probability density function equivalent to a radial one dimensional density function??,,"Assume that $f(x,y)$ is a two dimensional rotationally symmetric p.d.f.,  $f(x,y)=\tilde{f}(\sqrt{x^2+y^2})$. In the polar coordinates, $x=r \cos\varphi$, $y=r\sin\varphi$, we can average out the azimuthal angle to find a one dimensional radial p.d.f as follows, $$ p(r)= r\int_{0}^{2\pi}d\varphi\, \tilde{f}(r)=2\pi r\, \tilde{f}(r).\qquad\qquad\qquad \qquad     (1)$$ The generating function of the distribution $f(x,y)$ is written as $\mathbb{E}[e^{i\mathbf{k}\cdot \mathbf{x}}]$ where $\mathbf{x}=(x,y)$ and $\mathbf{k}=(k_x,k_y)$ are two dimensional vectors. Here $\mathbb{E}[\cdots]=\int dx dy \cdots \,f(x,y)$. Then the generating function for a rotationally symmetric distribution is given by $$  \mathbb{E}[e^{i\mathbf{k}\cdot \mathbf{x}}]=\int_{0}^{\infty}\int_{0}^{2\pi}r dr d\varphi\,e^{i k r \cos(\varphi-\varphi_k)}\tilde{f}(r)=2\pi\int_{0}^{\infty}r dr\, \tilde{f}(r)\,J_0(kr)=\int_0^{\infty} dr\, p(r) J_0(k r), $$ where in the above $k=\sqrt{k_x^2+k_y^2}$ and $\varphi_k=\text{atan2}(k_x,k_y)$ and $J_0(x)$ is the modified Bessel-Function of the first kind. If I define the averaging with respect to $p(r)$ as $\tilde{\mathbb{E}}[\cdots]=\int_0^{\infty} dr\cdots p(r)$ then we have the following: $$ \mathbb{E}[e^{i\mathbf{k}\cdot \mathbf{x}}] \equiv \tilde{\mathbb{E}}[J_0(k r)]=1-\frac{1}{4}k^2\tilde{\mathbb{E}}[r^2]+\frac{1}{64}k^4\tilde{\mathbb{E}}[r^4]+\cdots\,.$$ Question: Based on the above, the characteristic function of a 2D rotationally symmetric p.d.f. can be obtained only from even moments ( $\tilde{\mathbb{E}}[r^{2k}]$) of the p.d.f. $p(r)$ which is defined in the range $[0,\infty)$. On the other hand, the characteristic function of $p(r)$ can be written as  $\tilde{\mathbb{E}}[e^{i t r}]$ where $t\in(-\infty,\infty)$( What is the characteristic function of a p.d.f with $\mathbb{R}^+$ support? ). It simply means that  $\tilde{\mathbb{E}}[r^{2k+1}]$ are moments of $p(r)$ too. Now I am a bit confused. If I know all $\tilde{\mathbb{E}}[r^{2k}]$ then I know $f(x,y)$. However, in order to know $p(r)$ I should know about $\tilde{\mathbb{E}}[r^{k}]$ for odd $k$  as well as even $k$. On the other hand, $f(x,y)$ and $p(r)$ are uniquelly related to each other from equation (1). My Guess: I think I am missing something obvious! My guess is that $p(r)$ and rotatinaly symmetric $f(x,y)$ are not equivalent, and I can use them interchangeably if I replace the characteristic function  $\tilde{\mathbb{E}}[e^{i t r}]$ to  $\tilde{\mathbb{E}}[J_0(k r)]$ for $p(r)$.","Assume that $f(x,y)$ is a two dimensional rotationally symmetric p.d.f.,  $f(x,y)=\tilde{f}(\sqrt{x^2+y^2})$. In the polar coordinates, $x=r \cos\varphi$, $y=r\sin\varphi$, we can average out the azimuthal angle to find a one dimensional radial p.d.f as follows, $$ p(r)= r\int_{0}^{2\pi}d\varphi\, \tilde{f}(r)=2\pi r\, \tilde{f}(r).\qquad\qquad\qquad \qquad     (1)$$ The generating function of the distribution $f(x,y)$ is written as $\mathbb{E}[e^{i\mathbf{k}\cdot \mathbf{x}}]$ where $\mathbf{x}=(x,y)$ and $\mathbf{k}=(k_x,k_y)$ are two dimensional vectors. Here $\mathbb{E}[\cdots]=\int dx dy \cdots \,f(x,y)$. Then the generating function for a rotationally symmetric distribution is given by $$  \mathbb{E}[e^{i\mathbf{k}\cdot \mathbf{x}}]=\int_{0}^{\infty}\int_{0}^{2\pi}r dr d\varphi\,e^{i k r \cos(\varphi-\varphi_k)}\tilde{f}(r)=2\pi\int_{0}^{\infty}r dr\, \tilde{f}(r)\,J_0(kr)=\int_0^{\infty} dr\, p(r) J_0(k r), $$ where in the above $k=\sqrt{k_x^2+k_y^2}$ and $\varphi_k=\text{atan2}(k_x,k_y)$ and $J_0(x)$ is the modified Bessel-Function of the first kind. If I define the averaging with respect to $p(r)$ as $\tilde{\mathbb{E}}[\cdots]=\int_0^{\infty} dr\cdots p(r)$ then we have the following: $$ \mathbb{E}[e^{i\mathbf{k}\cdot \mathbf{x}}] \equiv \tilde{\mathbb{E}}[J_0(k r)]=1-\frac{1}{4}k^2\tilde{\mathbb{E}}[r^2]+\frac{1}{64}k^4\tilde{\mathbb{E}}[r^4]+\cdots\,.$$ Question: Based on the above, the characteristic function of a 2D rotationally symmetric p.d.f. can be obtained only from even moments ( $\tilde{\mathbb{E}}[r^{2k}]$) of the p.d.f. $p(r)$ which is defined in the range $[0,\infty)$. On the other hand, the characteristic function of $p(r)$ can be written as  $\tilde{\mathbb{E}}[e^{i t r}]$ where $t\in(-\infty,\infty)$( What is the characteristic function of a p.d.f with $\mathbb{R}^+$ support? ). It simply means that  $\tilde{\mathbb{E}}[r^{2k+1}]$ are moments of $p(r)$ too. Now I am a bit confused. If I know all $\tilde{\mathbb{E}}[r^{2k}]$ then I know $f(x,y)$. However, in order to know $p(r)$ I should know about $\tilde{\mathbb{E}}[r^{k}]$ for odd $k$  as well as even $k$. On the other hand, $f(x,y)$ and $p(r)$ are uniquelly related to each other from equation (1). My Guess: I think I am missing something obvious! My guess is that $p(r)$ and rotatinaly symmetric $f(x,y)$ are not equivalent, and I can use them interchangeably if I replace the characteristic function  $\tilde{\mathbb{E}}[e^{i t r}]$ to  $\tilde{\mathbb{E}}[J_0(k r)]$ for $p(r)$.",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
56,Equal standard deviations for maximum probability of positive value?,Equal standard deviations for maximum probability of positive value?,,"An investor wishes to invest $\$700$. There are two independent stocks the investor can choose to invest in, both of which are currently trading at the same share price. The daily returns of the first stock are historically normally distributed with a mean of $3\%$ and a standard deviation of $1.5\%$. The daily returns of the second stock are historically normally distributed with a mean of $4\%$ and a standard deviation of $2\%$. How much should the investor choose to invest (in dollars) in the first stock to maximize his probability of having a positive profit over the course of a day? The answer says when the standard deviations of returns are the same, the probability of profiting is maximized. Suppose he invests \$$x$ into the first stock, then $1.5x = 2(700-x)$, so $x = 400$. But why does this happen when the standard deviations are equal?","An investor wishes to invest $\$700$. There are two independent stocks the investor can choose to invest in, both of which are currently trading at the same share price. The daily returns of the first stock are historically normally distributed with a mean of $3\%$ and a standard deviation of $1.5\%$. The daily returns of the second stock are historically normally distributed with a mean of $4\%$ and a standard deviation of $2\%$. How much should the investor choose to invest (in dollars) in the first stock to maximize his probability of having a positive profit over the course of a day? The answer says when the standard deviations of returns are the same, the probability of profiting is maximized. Suppose he invests \$$x$ into the first stock, then $1.5x = 2(700-x)$, so $x = 400$. But why does this happen when the standard deviations are equal?",,"['statistics', 'standard-deviation']"
57,Find the posterior distribution,Find the posterior distribution,,"Suppose that $X_1,\ldots,X_n$ is a random sample from $U(θ,θ+1),$ and further assume $θ$ has a prior distribution as the discrete uniform distribution on the integers $1,2,\ldots,n$ where $n$ is known. Obtain the posterior distribution of $θ.$ The problem is that as the joint distribution has an indicator function, then I don't know how to integrate the product of this times $1/n$ (the prior distribution). Any one could help me with that? Thank you in advance.","Suppose that $X_1,\ldots,X_n$ is a random sample from $U(θ,θ+1),$ and further assume $θ$ has a prior distribution as the discrete uniform distribution on the integers $1,2,\ldots,n$ where $n$ is known. Obtain the posterior distribution of $θ.$ The problem is that as the joint distribution has an indicator function, then I don't know how to integrate the product of this times $1/n$ (the prior distribution). Any one could help me with that? Thank you in advance.",,['statistics']
58,Proof verification : Establishing an inequality between joint distribution function and the product of marginal distribution functions,Proof verification : Establishing an inequality between joint distribution function and the product of marginal distribution functions,,"THE PROBLEM : Source : Rohatgi, Saleh. p.$114$. Problem $16$. This is my attempt to construct a solution. I'd be grateful if anyone checks whether or not it is technically alright. Also, I'd like to request to provide any shorter method, if available, to solve the problem. Thanks in advance. I use the shorthand $\int_{a}^{b} \int_{c}^{d}$ to mean $\int_{a}^{b} \int_{c}^{d} f(x,y)dxdy$ Then, $F_1(a)F_2(b)=\int_{-\infty}^{\infty} \int_{-\infty}^{a} \times \int_{-\infty}^{b} \int_{-\infty}^{\infty} = (\int_{-\infty}^{b} \int_{-\infty}^{a}+\int_{b}^{\infty} \int_{-\infty}^{a}) \times (\int_{-\infty}^{b} \int_{-\infty}^{a}+\int_{-\infty}^{b} \int_{a}^{\infty})$ This breaks up into four components : $(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{-\infty}^{a})+(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{a}^{\infty})+(\int_{b}^{\infty} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{-\infty}^{a})+(\int_{b}^{\infty} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{a}^{\infty})$ Adding and subtracting $(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{a}^{\infty} \int_{b}^{\infty})$ and noting that probability measure sums up to $1$, we have $(\int_{-\infty}^{b} \int_{-\infty}^{a})+(\int_{b}^{\infty} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{a}^{\infty})-(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{b}^{\infty} \int_{a}^{\infty})$ The extra term is : $(\int_{b}^{\infty} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{a}^{\infty})-(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{b}^{\infty} \int_{a}^{\infty})$ We shall show that this is $\geq 0$ $[$which will give us the proof since $F(a,b)=(\int_{-\infty}^{b} \int_{-\infty}^{a})]$ Now, $(\int_{b}^{\infty} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{a}^{\infty})=(\int_{b}^{\infty} \int_{-\infty}^{a}f(x_1,y_2)dx_1dy_2)(\int_{-\infty}^{b} \int_{a}^{\infty}f(x_2,y_1)dx_2dy_1)$ $=\int_{b}^{\infty} \int_{-\infty}^{a} \int_{-\infty}^{b} \int_{a}^{\infty} f(x_1,y_2) f(x_2,y_1) dx_2dy_1dx_1dy_2$ By the condition given in the question, this quantity is greater than $\int_{b}^{\infty} \int_{-\infty}^{a} \int_{-\infty}^{b} \int_{a}^{\infty} f(x_1,y_1) f(x_2,y_2) dx_2dy_1dx_1dy_2$ $=\int_{-\infty}^{b} \int_{-\infty}^{a} \int_{b}^{\infty} \int_{a}^{\infty} f(x_1,y_1) f(x_2,y_2) dx_2dy_2dx_1dy_1$ $=(\int_{-\infty}^{b} \int_{-\infty}^{a} f(x_1,y_1) dx_1dy_1) \times (\int_{b}^{\infty} \int_{a}^{\infty} f(x_2,y_2) dx_2dy_2)=(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{b}^{\infty} \int_{a}^{\infty})$ Hence the extra term is positive. Hence the proof.","THE PROBLEM : Source : Rohatgi, Saleh. p.$114$. Problem $16$. This is my attempt to construct a solution. I'd be grateful if anyone checks whether or not it is technically alright. Also, I'd like to request to provide any shorter method, if available, to solve the problem. Thanks in advance. I use the shorthand $\int_{a}^{b} \int_{c}^{d}$ to mean $\int_{a}^{b} \int_{c}^{d} f(x,y)dxdy$ Then, $F_1(a)F_2(b)=\int_{-\infty}^{\infty} \int_{-\infty}^{a} \times \int_{-\infty}^{b} \int_{-\infty}^{\infty} = (\int_{-\infty}^{b} \int_{-\infty}^{a}+\int_{b}^{\infty} \int_{-\infty}^{a}) \times (\int_{-\infty}^{b} \int_{-\infty}^{a}+\int_{-\infty}^{b} \int_{a}^{\infty})$ This breaks up into four components : $(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{-\infty}^{a})+(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{a}^{\infty})+(\int_{b}^{\infty} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{-\infty}^{a})+(\int_{b}^{\infty} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{a}^{\infty})$ Adding and subtracting $(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{a}^{\infty} \int_{b}^{\infty})$ and noting that probability measure sums up to $1$, we have $(\int_{-\infty}^{b} \int_{-\infty}^{a})+(\int_{b}^{\infty} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{a}^{\infty})-(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{b}^{\infty} \int_{a}^{\infty})$ The extra term is : $(\int_{b}^{\infty} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{a}^{\infty})-(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{b}^{\infty} \int_{a}^{\infty})$ We shall show that this is $\geq 0$ $[$which will give us the proof since $F(a,b)=(\int_{-\infty}^{b} \int_{-\infty}^{a})]$ Now, $(\int_{b}^{\infty} \int_{-\infty}^{a})(\int_{-\infty}^{b} \int_{a}^{\infty})=(\int_{b}^{\infty} \int_{-\infty}^{a}f(x_1,y_2)dx_1dy_2)(\int_{-\infty}^{b} \int_{a}^{\infty}f(x_2,y_1)dx_2dy_1)$ $=\int_{b}^{\infty} \int_{-\infty}^{a} \int_{-\infty}^{b} \int_{a}^{\infty} f(x_1,y_2) f(x_2,y_1) dx_2dy_1dx_1dy_2$ By the condition given in the question, this quantity is greater than $\int_{b}^{\infty} \int_{-\infty}^{a} \int_{-\infty}^{b} \int_{a}^{\infty} f(x_1,y_1) f(x_2,y_2) dx_2dy_1dx_1dy_2$ $=\int_{-\infty}^{b} \int_{-\infty}^{a} \int_{b}^{\infty} \int_{a}^{\infty} f(x_1,y_1) f(x_2,y_2) dx_2dy_2dx_1dy_1$ $=(\int_{-\infty}^{b} \int_{-\infty}^{a} f(x_1,y_1) dx_1dy_1) \times (\int_{b}^{\infty} \int_{a}^{\infty} f(x_2,y_2) dx_2dy_2)=(\int_{-\infty}^{b} \int_{-\infty}^{a})(\int_{b}^{\infty} \int_{a}^{\infty})$ Hence the extra term is positive. Hence the proof.",,"['probability-theory', 'statistics', 'inequality', 'probability-distributions']"
59,Covariance of two truncated random variables,Covariance of two truncated random variables,,"Assume that $X=(X_1,X_2)^T$ is a random vector that is multivariate normal with mean vector $\mu$ and variance-covariance matrix $\Sigma$. I.e. we have $$ X \sim N_2(\mu, \Sigma).$$ I am interested in the truncated version of this normal distribution and assume that $X_1$ and $X_2$ are smaller than some threshold $c$. Hence I am searching for $X^*=(X_1^*,X_2^*)^T$ that is jointly trucnated normal $$ X^*~\sim TN_2(\mu, \Sigma,c)$$ While there are formulas for the expectation and the variance of the univariate truncated normal I do not know how to compute the covariance of $X_1^*$ and $X_2^*$: $\operatorname{Cov}(X_1^*,X_2^*)= \operatorname{Cov}(X_1,X_2\mid X_1<c,X_2<c)$.","Assume that $X=(X_1,X_2)^T$ is a random vector that is multivariate normal with mean vector $\mu$ and variance-covariance matrix $\Sigma$. I.e. we have $$ X \sim N_2(\mu, \Sigma).$$ I am interested in the truncated version of this normal distribution and assume that $X_1$ and $X_2$ are smaller than some threshold $c$. Hence I am searching for $X^*=(X_1^*,X_2^*)^T$ that is jointly trucnated normal $$ X^*~\sim TN_2(\mu, \Sigma,c)$$ While there are formulas for the expectation and the variance of the univariate truncated normal I do not know how to compute the covariance of $X_1^*$ and $X_2^*$: $\operatorname{Cov}(X_1^*,X_2^*)= \operatorname{Cov}(X_1,X_2\mid X_1<c,X_2<c)$.",,"['statistics', 'normal-distribution', 'covariance']"
60,Chi-square probabilities,Chi-square probabilities,,"How are the values in chi-square distribution tables derived for different values of $\alpha$ and degrees of freedom, given the PDF? Any help appreciated.","How are the values in chi-square distribution tables derived for different values of $\alpha$ and degrees of freedom, given the PDF? Any help appreciated.",,"['statistics', 'probability-distributions', 'chi-squared']"
61,"Probability of throwing two dice twice, and getting a $7$ on the first throw","Probability of throwing two dice twice, and getting a  on the first throw",7,"This one is pretty simple, but the textbook answer is way off from mine. Getting a $7$ on a $2$-dice throw is $\frac 6{36} =\frac16$, and since it doesn't care about the second throw it should be $\frac16$, right? The textbook says it's $\frac5{18}$, but I don't know from where.","This one is pretty simple, but the textbook answer is way off from mine. Getting a $7$ on a $2$-dice throw is $\frac 6{36} =\frac16$, and since it doesn't care about the second throw it should be $\frac16$, right? The textbook says it's $\frac5{18}$, but I don't know from where.",,"['probability', 'statistics', 'dice']"
62,Why would $L \ + \frac{f_{m}-f_{m-1}}{(f_{m}-f_{m-1}) + f_{m}-f_{m+1}} \cdot w$ correspond to the mode of grouped frequencies? [duplicate],Why would  correspond to the mode of grouped frequencies? [duplicate],L \ + \frac{f_{m}-f_{m-1}}{(f_{m}-f_{m-1}) + f_{m}-f_{m+1}} \cdot w,"This question already has answers here : Derivation of Mode of grouped data (2 answers) Closed 3 years ago . $\text{Mode} = L \ + \frac{f_{m}-f_{m-1}}{(f_{m}-f_{m-1}) + f_{m}-f_{m+1}} \cdot w$ where, • L is the lower class boundary of the modal group. • fm-1 is the frequency of the group before the modal group. • fm is the frequency of the modal group. • fm+1 is the frequency of the group after the modal group. • w is the group width. Mode is the most frequently occurring value in a data set - I don't understand why this formula would give the mode of grouped frequencies. Why would the mode even be in the modal group? It could be inside any other group, right!?","This question already has answers here : Derivation of Mode of grouped data (2 answers) Closed 3 years ago . $\text{Mode} = L \ + \frac{f_{m}-f_{m-1}}{(f_{m}-f_{m-1}) + f_{m}-f_{m+1}} \cdot w$ where, • L is the lower class boundary of the modal group. • fm-1 is the frequency of the group before the modal group. • fm is the frequency of the modal group. • fm+1 is the frequency of the group after the modal group. • w is the group width. Mode is the most frequently occurring value in a data set - I don't understand why this formula would give the mode of grouped frequencies. Why would the mode even be in the modal group? It could be inside any other group, right!?",,['statistics']
63,"Upper bound on P(S_n > a) by mgf, Strong Law Large Numbers Proof Casella, Berger","Upper bound on P(S_n > a) by mgf, Strong Law Large Numbers Proof Casella, Berger",,"Having trouble coming up with a proof for a problem related to SLLN using MGFS. I found Strong Law of Numbers for $S_{n}$ Bounded Casella Berger 5.38 but the answer doesn't seem to hint at how we could establish some lower bound. I've put my effort below, but it feels cheap , are there other methods in which I can approach this problem? Problem statement:  Let $X_1,...,X_n$ be iid random variables with mgf $M_X(t),-h<t<h$, let $S_n=\sum_{i=1}^nX_i$ and $\bar{X}=\frac{1}{n}S_n$ I've already via Markov inequality shown that $$P(S_n>a)\le e^{-at}[M_X(t)]^n$$ and $$P(S_n \le a) \le e^{-at}[M_X(t)]^n$$ Now we must prove that for $E[X]<0$ and $M_X(0)=1$ there exists $0<c<1$ s.t $P(S_n>a) \le c^n$. Now my first instinct is to use a Taylor expansion: $$M_X(t) \approx M_X(0) + M_X'(0)t =1 + tE[X]$$ However I can only see this bringing us to the upperbound in the link mentioned earlier:  $$M_X(t) \le 1 + t\frac{E[X]}{2} \le 1$$ Since $E[X]$ is negative, or the second derivative of the mgf is negative near 0. Taking t=0 gives us the 1 as the final upperbound. The nth power of the mgf retains the property of 1 as an upperbound. Since we are confident of the upper-bound on $M_X(t)$ in the neighbourhood of 0 couldn't we just use: $$P(S_n>a) \le c^n = \left[ e^{-at/n}*M_X(t) \right]^n?$$ We've shown that from $E[X]<0$, $M_X(t)$ is bounded above by 1 in the neighbourhood of 0. In addition as n grows, since $0<c<1$, then $0<c^n<1$. Am I missing something here? I should note that nothing about the nature of $a$ is given, I assumed it was positive above. Hints would be appreciated, my analysis skill-set is limited and something I'm working on!","Having trouble coming up with a proof for a problem related to SLLN using MGFS. I found Strong Law of Numbers for $S_{n}$ Bounded Casella Berger 5.38 but the answer doesn't seem to hint at how we could establish some lower bound. I've put my effort below, but it feels cheap , are there other methods in which I can approach this problem? Problem statement:  Let $X_1,...,X_n$ be iid random variables with mgf $M_X(t),-h<t<h$, let $S_n=\sum_{i=1}^nX_i$ and $\bar{X}=\frac{1}{n}S_n$ I've already via Markov inequality shown that $$P(S_n>a)\le e^{-at}[M_X(t)]^n$$ and $$P(S_n \le a) \le e^{-at}[M_X(t)]^n$$ Now we must prove that for $E[X]<0$ and $M_X(0)=1$ there exists $0<c<1$ s.t $P(S_n>a) \le c^n$. Now my first instinct is to use a Taylor expansion: $$M_X(t) \approx M_X(0) + M_X'(0)t =1 + tE[X]$$ However I can only see this bringing us to the upperbound in the link mentioned earlier:  $$M_X(t) \le 1 + t\frac{E[X]}{2} \le 1$$ Since $E[X]$ is negative, or the second derivative of the mgf is negative near 0. Taking t=0 gives us the 1 as the final upperbound. The nth power of the mgf retains the property of 1 as an upperbound. Since we are confident of the upper-bound on $M_X(t)$ in the neighbourhood of 0 couldn't we just use: $$P(S_n>a) \le c^n = \left[ e^{-at/n}*M_X(t) \right]^n?$$ We've shown that from $E[X]<0$, $M_X(t)$ is bounded above by 1 in the neighbourhood of 0. In addition as n grows, since $0<c<1$, then $0<c^n<1$. Am I missing something here? I should note that nothing about the nature of $a$ is given, I assumed it was positive above. Hints would be appreciated, my analysis skill-set is limited and something I'm working on!",,"['real-analysis', 'probability-theory', 'statistics', 'moment-generating-functions', 'law-of-large-numbers']"
64,"Can we assume that every possible ""process"" has an underlying probability distribution?","Can we assume that every possible ""process"" has an underlying probability distribution?",,"To make the question clearer, I will write the context in which I formulated it myself. I was studying the twelve coin puzzle , in which you are given 12 coins and by using a balance certain number of times you need to decide something about the coins. The details actually don't matter. The problem I wanted to solve was not the puzzle itself but giving a bound on the maximum number of coins $n$ you can have if you want to solve the puzzle using the balance $k$ times. This is a classical problem, which can be approached using techniques from combinatorics, for example. For my approach, however, I used Information Theory to get the bound. My argument started like this: Let $X$ be the random variable representing the possible states of the coins. What we want is to be able to determine $X$ out from $k$ uses of a balance, for any distribution of $X$ .... What remains of the proof, just like the details of this problem itself, are not relevant. What matters is the question I made to myself at this point: Is it OK to assume some kind of distribution from the states of the coins? This looks weird, because even though the proof gives the same bound you can get with combinatorial methods, these do not assume anything about the underlying distribution of the coins. On the other hand, I'm assuming that the coins must have some kind of distribution! Even if we don't know it, it must be there. I am aware of other contexts where you assume data distributions must exist. In Machine Learning for example, you make predictions based on the assumption that the underlying data has some distribution, which although unknown, is there! (So statistical arguments can be applied). The question I will do my best to abstract my question in a concise way out from my examples above. Is it natural to regard any outcome from a process as a random variable with an underlying distribution? Are there some studies in this direction? Is this beyond the scope of Mathematics/Statistics itself (and more related to how we interpret results in these fields in ""real life"")?","To make the question clearer, I will write the context in which I formulated it myself. I was studying the twelve coin puzzle , in which you are given 12 coins and by using a balance certain number of times you need to decide something about the coins. The details actually don't matter. The problem I wanted to solve was not the puzzle itself but giving a bound on the maximum number of coins you can have if you want to solve the puzzle using the balance times. This is a classical problem, which can be approached using techniques from combinatorics, for example. For my approach, however, I used Information Theory to get the bound. My argument started like this: Let be the random variable representing the possible states of the coins. What we want is to be able to determine out from uses of a balance, for any distribution of .... What remains of the proof, just like the details of this problem itself, are not relevant. What matters is the question I made to myself at this point: Is it OK to assume some kind of distribution from the states of the coins? This looks weird, because even though the proof gives the same bound you can get with combinatorial methods, these do not assume anything about the underlying distribution of the coins. On the other hand, I'm assuming that the coins must have some kind of distribution! Even if we don't know it, it must be there. I am aware of other contexts where you assume data distributions must exist. In Machine Learning for example, you make predictions based on the assumption that the underlying data has some distribution, which although unknown, is there! (So statistical arguments can be applied). The question I will do my best to abstract my question in a concise way out from my examples above. Is it natural to regard any outcome from a process as a random variable with an underlying distribution? Are there some studies in this direction? Is this beyond the scope of Mathematics/Statistics itself (and more related to how we interpret results in these fields in ""real life"")?",n k X X k X,"['statistics', 'soft-question', 'random', 'information-theory']"
65,Computing sample proportion,Computing sample proportion,,Was never really taught the use and interpretation of sample proportions  explicitly. I tried to work through the first part of this problem above. Did I go wrong at any point?,Was never really taught the use and interpretation of sample proportions  explicitly. I tried to work through the first part of this problem above. Did I go wrong at any point?,,['statistics']
66,Why does sum of independent uncertainties in General Propagation of Error equal to zero?,Why does sum of independent uncertainties in General Propagation of Error equal to zero?,,"In my physics class, we've been doing uncertainty problems with the General Error Propagation Equation. However, I felt uncomfortable using the equation without understanding its derivation. So I was reading this webpage ( https://www.deanza.edu/faculty/marshburnthomas/pdf/ErrorPropagation.pdf ) which was fine until the following portion: $$\sigma^2 =  \frac{(\partial f)} {(\partial x)}^2 \Sigma \frac{(\Delta x)^2}{n} + \frac{(\partial f)} {(\partial y)}^2 \Sigma \frac{(\Delta y)^2}{n} + \frac{(\partial f)} {(\partial z)}^2 \Sigma \frac{(\Delta z)^2}{n} + 2\frac{(\partial f)} {(\partial x)} \frac{(\partial f)} {(\partial y)} \frac{1}{n}\Sigma \Delta x\Delta y + 2\frac{(\partial f)} {(\partial x)} \frac{(\partial f)} {(\partial z)} \frac{1}{n}\Sigma \Delta x\Delta z + 2\frac{(\partial f)} {(\partial y)} \frac{(\partial f)} {(\partial z)}\frac{1}{n}\Sigma \Delta y\Delta z$$ ""Since the uncertainties in the measurement x, y and z are random and independent, then $$\Sigma\Delta x\Delta y = 0$$ $$\Sigma\Delta x\Delta z = 0$$ $$\Sigma\Delta y\Delta z = 0$$ Therefore,  $$\sigma^2 = \frac{(\partial f)} {(\partial x)}^2 (\sigma _x)^2 + \frac{(\partial f)} {(\partial y)}^2 (\sigma _y)^2 + \frac{(\partial f)} {(\partial z)}^2 (\sigma _z)^2$$ What I'm having trouble grasping is why the sum of the products of the uncertainties is 0. Thank you for your help.","In my physics class, we've been doing uncertainty problems with the General Error Propagation Equation. However, I felt uncomfortable using the equation without understanding its derivation. So I was reading this webpage ( https://www.deanza.edu/faculty/marshburnthomas/pdf/ErrorPropagation.pdf ) which was fine until the following portion: $$\sigma^2 =  \frac{(\partial f)} {(\partial x)}^2 \Sigma \frac{(\Delta x)^2}{n} + \frac{(\partial f)} {(\partial y)}^2 \Sigma \frac{(\Delta y)^2}{n} + \frac{(\partial f)} {(\partial z)}^2 \Sigma \frac{(\Delta z)^2}{n} + 2\frac{(\partial f)} {(\partial x)} \frac{(\partial f)} {(\partial y)} \frac{1}{n}\Sigma \Delta x\Delta y + 2\frac{(\partial f)} {(\partial x)} \frac{(\partial f)} {(\partial z)} \frac{1}{n}\Sigma \Delta x\Delta z + 2\frac{(\partial f)} {(\partial y)} \frac{(\partial f)} {(\partial z)}\frac{1}{n}\Sigma \Delta y\Delta z$$ ""Since the uncertainties in the measurement x, y and z are random and independent, then $$\Sigma\Delta x\Delta y = 0$$ $$\Sigma\Delta x\Delta z = 0$$ $$\Sigma\Delta y\Delta z = 0$$ Therefore,  $$\sigma^2 = \frac{(\partial f)} {(\partial x)}^2 (\sigma _x)^2 + \frac{(\partial f)} {(\partial y)}^2 (\sigma _y)^2 + \frac{(\partial f)} {(\partial z)}^2 (\sigma _z)^2$$ What I'm having trouble grasping is why the sum of the products of the uncertainties is 0. Thank you for your help.",,['statistics']
67,$O_p$ and $o_p$ notations in asymptotic normality proof,and  notations in asymptotic normality proof,O_p o_p,"I'm reading the proof of Theorem 5.21 (asymptotic normality of M-estimators) in van den Vaarts book ""Asymptotic Statistics"" (see the attached picture). (The theorem assumes that $\hat{\theta}_n \to \theta_0$ in probability as $n\to \infty$; i.e., the estimator $\hat{\theta}_n$ is asymptotically consistent.) I do not understand the last paragraph of the proof. How did he go from the $\sqrt{n}$-consistency to the last conclusion? In particular, I do not see where the inequality in page 53 coming from? how the $o_p$ term of the last equation in page 52 vanished (I guess it      is represented now with the $o_p$ on the right hand side of that       equation). It seems to me that the presentation (somehow) implies that $$ O_p(1) + o_p(\sqrt{n} \|\hat{\theta}_n - \theta_0  \|) = O_p(1)\quad ? $$ Does this hold? My understanding is that this should instead be $O_p(\max(1,\sqrt{n} \|\hat{\theta}_n - \theta_0  \| ))$. However, if it does hold, then it will follow that  $$\sqrt{n} \|\hat{\theta}_n - \theta_0  \| = O_p(1)$$  (we know that this is true if the LHS converges in distribution; however, this is something that we are trying to prove!) and therefore,   $$ o_p(\sqrt{n} \|\hat{\theta}_n - \theta_0  \| ) = o_p(O_p(1)) = o_p(1).$$","I'm reading the proof of Theorem 5.21 (asymptotic normality of M-estimators) in van den Vaarts book ""Asymptotic Statistics"" (see the attached picture). (The theorem assumes that $\hat{\theta}_n \to \theta_0$ in probability as $n\to \infty$; i.e., the estimator $\hat{\theta}_n$ is asymptotically consistent.) I do not understand the last paragraph of the proof. How did he go from the $\sqrt{n}$-consistency to the last conclusion? In particular, I do not see where the inequality in page 53 coming from? how the $o_p$ term of the last equation in page 52 vanished (I guess it      is represented now with the $o_p$ on the right hand side of that       equation). It seems to me that the presentation (somehow) implies that $$ O_p(1) + o_p(\sqrt{n} \|\hat{\theta}_n - \theta_0  \|) = O_p(1)\quad ? $$ Does this hold? My understanding is that this should instead be $O_p(\max(1,\sqrt{n} \|\hat{\theta}_n - \theta_0  \| ))$. However, if it does hold, then it will follow that  $$\sqrt{n} \|\hat{\theta}_n - \theta_0  \| = O_p(1)$$  (we know that this is true if the LHS converges in distribution; however, this is something that we are trying to prove!) and therefore,   $$ o_p(\sqrt{n} \|\hat{\theta}_n - \theta_0  \| ) = o_p(O_p(1)) = o_p(1).$$",,"['statistics', 'asymptotics', 'statistical-inference']"
68,Mutation probability,Mutation probability,,"Say we have a sample of DNA from  population A and population B as shown below. (Both samples taken from today). Find the following $$ \mathbb{P}(M>0 | T_2,...,Tn) $$ where $T_i$ is the length of branch $i$ , and $M$ is the total number of mutations happening on the branch with a solid line in the above picture. Hence, find $ \mathbb{P}(M>0) $ . I know that: $T_i$ are independent exponential random variables with parameter $i \choose{2}$ $l$ is the total tree length: $l = 2T_2 + 3T_3 + \ldots nT_n$ . The mutations occur as a Poisson process along the edges of the tree at rate $\frac{\theta}{2}$ (meaning in total it is of rate $\frac{\theta l}{2}$ ) My guess: $$ \mathbb{P}(M>0 | T_2,...,Tn) = 1- \mathbb{P}(M=0 | T_2,...,Tn) = 1-e^{-\theta l/2} \sim exp\left(\frac{\theta l }{2}\right)$$ Is this right? If so how would we find $P(M>0)$ ?","Say we have a sample of DNA from  population A and population B as shown below. (Both samples taken from today). Find the following where is the length of branch , and is the total number of mutations happening on the branch with a solid line in the above picture. Hence, find . I know that: are independent exponential random variables with parameter is the total tree length: . The mutations occur as a Poisson process along the edges of the tree at rate (meaning in total it is of rate ) My guess: Is this right? If so how would we find ?"," \mathbb{P}(M>0 | T_2,...,Tn)  T_i i M  \mathbb{P}(M>0)  T_i i \choose{2} l l = 2T_2 + 3T_3 + \ldots nT_n \frac{\theta}{2} \frac{\theta l}{2}  \mathbb{P}(M>0 | T_2,...,Tn) = 1- \mathbb{P}(M=0 | T_2,...,Tn) = 1-e^{-\theta l/2} \sim exp\left(\frac{\theta l }{2}\right) P(M>0)","['probability', 'statistics', 'biology']"
69,"Find the pdf $f_W(w)$ if the joint pdf of $X,Y>0$ is $f(x,y)$ and $W=Y/X$",Find the pdf  if the joint pdf of  is  and,"f_W(w) X,Y>0 f(x,y) W=Y/X","Exercise : Let $X>0$ and $Y>0$ continuous random variables with joint probability density function (pdf) $f(x,y)$. If $W=Y/X$, then find the pdf $f_W(w)$. What happens to $f_W(w)$ and its expression when $X,Y$ are independent ? Attempt-Question : $$F_W(w)=P\{W \leq w\} = P\{Y/X \leq w\}=\int \int_Df(x,y)dxdy$$ $$\Rightarrow$$ $$F_W(w) = \int\bigg[\int f(x,y)dx\bigg]dy$$ It is : $Y/X \leq w \Leftrightarrow Y \leq wX$ since $X>0$. This means that on a $X-Y$ axis system, we'll need every value below $wX$. $$=\int_{-\infty}^{ωx}\bigg[\int_{-\infty}^{+\infty}f(x,y)dx\bigg]dy$$ Which leads to : $$f_W(w) = \frac{dF_W(w)}{dw} = \frac{d}{dw}\int_{-\infty}^{ωx}\bigg[\int_{-\infty}^{+\infty}f(x,y)dx\bigg]dy = \int_{-\infty}^\infty\bigg[\frac{d}{dw}\int_{-\infty}^{wx}f(x,y)dy\bigg]dx$$ Question : Is my approach and the integral bounds correct ? How would I take it one step further from then on ?","Exercise : Let $X>0$ and $Y>0$ continuous random variables with joint probability density function (pdf) $f(x,y)$. If $W=Y/X$, then find the pdf $f_W(w)$. What happens to $f_W(w)$ and its expression when $X,Y$ are independent ? Attempt-Question : $$F_W(w)=P\{W \leq w\} = P\{Y/X \leq w\}=\int \int_Df(x,y)dxdy$$ $$\Rightarrow$$ $$F_W(w) = \int\bigg[\int f(x,y)dx\bigg]dy$$ It is : $Y/X \leq w \Leftrightarrow Y \leq wX$ since $X>0$. This means that on a $X-Y$ axis system, we'll need every value below $wX$. $$=\int_{-\infty}^{ωx}\bigg[\int_{-\infty}^{+\infty}f(x,y)dx\bigg]dy$$ Which leads to : $$f_W(w) = \frac{dF_W(w)}{dw} = \frac{d}{dw}\int_{-\infty}^{ωx}\bigg[\int_{-\infty}^{+\infty}f(x,y)dx\bigg]dy = \int_{-\infty}^\infty\bigg[\frac{d}{dw}\int_{-\infty}^{wx}f(x,y)dy\bigg]dx$$ Question : Is my approach and the integral bounds correct ? How would I take it one step further from then on ?",,"['probability', 'integration', 'probability-theory', 'statistics', 'probability-distributions']"
70,Tail Sum Formula: Expected Maximum,Tail Sum Formula: Expected Maximum,,"Tail Sum Formula states that: For $X$ with possible values $\{0, 1, 2, \ldots , n\}$, $$\operatorname E(X) = \sum_{j=1}^n P(X \ge j)$$ Suppose that 4 dice are rolled. Find the expected maximum $\operatorname E(M)$ of the   4 rolls. $M$ has possible values $\{1, 2, \ldots, 6\}$ all consecutive. Thus, we can use the Tail Sum Formula. \begin{align} \operatorname E(M) & = \sum_{j=1}^{6}P(M \ge j) \\[10pt] & = P(M \ge 1) + P(M \ge 2) + P(M \ge 3) + P(M \ge 4) + P(M \ge 5) + P(M \ge 6) \\[10pt] & = \left(\frac 6 6 \right)^4 + \left(\frac 5 6 \right)^4 + \left(\frac 4 6 \right)^4 + \left(\frac 3 6 \right)^4 + \left(\frac 2 6 \right)^4 + \left(\frac 1 6 \right)^4 \\[10pt] & = 1.755 \end{align} But the expected minimum is also $1.755$! Edit 1: Let $X_i$ be the value obtained on roll $i$, $1 \le i \le 4$. $P(M \ge j) = $ Probability that the maxium of these 4 rolls is $\ge$ j $= 1 - P(M \lt j)$ $= 1 - P(M \le j-1)$ Probability that the maxium of these 4 rolls is $\le$ j $= 1 - P(X_1 \le j - 1, X_2 \le j - 1, ..., X_6 \le j - 1)$ Since each roll is independent... $= 1 - P(X_1 \le j - 1) P(X_2 \le j - 1) ... P(X_6 \le j - 1)$ $= 1-(\frac{j-1}{6})^4$ \begin{align} \operatorname E(M) & = \sum_{j=1}^{6}P(M \ge j) \\[10pt] & = P(M \ge 1) + P(M \ge 2) + P(M \ge 3) + P(M \ge 4) + P(M \ge 5) + P(M \ge 6) \\[10pt] & = \left(1- (\frac 0 6)^4 \right) + \left(1- (\frac 1 6)^4 \right) + \left(1- (\frac 2 6)^4 \right) + \left(1- (\frac 3 6)^4 \right) + \left(1- (\frac 4 6)^4 \right) + \left(1- (\frac 5 6)^4 \right) \\[10pt] & = 5.244598765 \end{align}","Tail Sum Formula states that: For $X$ with possible values $\{0, 1, 2, \ldots , n\}$, $$\operatorname E(X) = \sum_{j=1}^n P(X \ge j)$$ Suppose that 4 dice are rolled. Find the expected maximum $\operatorname E(M)$ of the   4 rolls. $M$ has possible values $\{1, 2, \ldots, 6\}$ all consecutive. Thus, we can use the Tail Sum Formula. \begin{align} \operatorname E(M) & = \sum_{j=1}^{6}P(M \ge j) \\[10pt] & = P(M \ge 1) + P(M \ge 2) + P(M \ge 3) + P(M \ge 4) + P(M \ge 5) + P(M \ge 6) \\[10pt] & = \left(\frac 6 6 \right)^4 + \left(\frac 5 6 \right)^4 + \left(\frac 4 6 \right)^4 + \left(\frac 3 6 \right)^4 + \left(\frac 2 6 \right)^4 + \left(\frac 1 6 \right)^4 \\[10pt] & = 1.755 \end{align} But the expected minimum is also $1.755$! Edit 1: Let $X_i$ be the value obtained on roll $i$, $1 \le i \le 4$. $P(M \ge j) = $ Probability that the maxium of these 4 rolls is $\ge$ j $= 1 - P(M \lt j)$ $= 1 - P(M \le j-1)$ Probability that the maxium of these 4 rolls is $\le$ j $= 1 - P(X_1 \le j - 1, X_2 \le j - 1, ..., X_6 \le j - 1)$ Since each roll is independent... $= 1 - P(X_1 \le j - 1) P(X_2 \le j - 1) ... P(X_6 \le j - 1)$ $= 1-(\frac{j-1}{6})^4$ \begin{align} \operatorname E(M) & = \sum_{j=1}^{6}P(M \ge j) \\[10pt] & = P(M \ge 1) + P(M \ge 2) + P(M \ge 3) + P(M \ge 4) + P(M \ge 5) + P(M \ge 6) \\[10pt] & = \left(1- (\frac 0 6)^4 \right) + \left(1- (\frac 1 6)^4 \right) + \left(1- (\frac 2 6)^4 \right) + \left(1- (\frac 3 6)^4 \right) + \left(1- (\frac 4 6)^4 \right) + \left(1- (\frac 5 6)^4 \right) \\[10pt] & = 5.244598765 \end{align}",,"['probability', 'statistics', 'expectation', 'dice']"
71,joint asymptotic distribution of the parameters in the shifted exponential random variable,joint asymptotic distribution of the parameters in the shifted exponential random variable,,"This is a exercise question in Dr. Van der Vaart's asymptotic statistics note. The question is : Let $X_1$,...,$X_n$ be i.i.d. with density $f_{\lambda,\alpha}(x) = \lambda e^{-\lambda(x-\alpha)}1\{x\geq\alpha\}$ where the parameters $\lambda>0$ and $\alpha \in R$ are unknown. Calculate the maximum likelihood estimator of $(\hat{\lambda}_n, \hat{\alpha}_n)$ of $(\lambda, \alpha)$ and derive the asymptotic property. My idea is : First you have the MLE for both parameters : $$ \left\{ \begin{array}{ccc} \hat{\lambda} &= &\frac{1}{\bar{x} - \hat{\alpha}}\\ \hat{\alpha} &= &x_{(1)} \end{array} \right. $$ With Delta method we know that : $$ \sqrt{n}\left[\bar{x} - (\alpha+\frac{1}{\lambda})\right] \xrightarrow{d} n(0,\frac{1}{\lambda^2}) $$ Also $$ \left. P\left(x_{(1)}\leq \alpha +\frac{t}{n}\right) \right\vert_{n\rightarrow \infty} \rightarrow 1-e^{-\lambda t} $$ Thus we have : $$  n\left[ x_{(1)} - \alpha\right] \xrightarrow{d} \exp(\lambda) $$ Then I get stuck here. Since to apply bivariate Delta method, we need to know the covariance of $x_{(1)}$ and $\bar{x}$ that is $Cov(x_{(1)}, \bar{x})$. I cannot think of a way to calculate that. And also, the factor in front of these two statistics is different,  one is $\sqrt{n}$ and another is $n$. Even we find the covariance how could we apply the delta method? I'm really appreciate anyone who could provide me some hint.","This is a exercise question in Dr. Van der Vaart's asymptotic statistics note. The question is : Let $X_1$,...,$X_n$ be i.i.d. with density $f_{\lambda,\alpha}(x) = \lambda e^{-\lambda(x-\alpha)}1\{x\geq\alpha\}$ where the parameters $\lambda>0$ and $\alpha \in R$ are unknown. Calculate the maximum likelihood estimator of $(\hat{\lambda}_n, \hat{\alpha}_n)$ of $(\lambda, \alpha)$ and derive the asymptotic property. My idea is : First you have the MLE for both parameters : $$ \left\{ \begin{array}{ccc} \hat{\lambda} &= &\frac{1}{\bar{x} - \hat{\alpha}}\\ \hat{\alpha} &= &x_{(1)} \end{array} \right. $$ With Delta method we know that : $$ \sqrt{n}\left[\bar{x} - (\alpha+\frac{1}{\lambda})\right] \xrightarrow{d} n(0,\frac{1}{\lambda^2}) $$ Also $$ \left. P\left(x_{(1)}\leq \alpha +\frac{t}{n}\right) \right\vert_{n\rightarrow \infty} \rightarrow 1-e^{-\lambda t} $$ Thus we have : $$  n\left[ x_{(1)} - \alpha\right] \xrightarrow{d} \exp(\lambda) $$ Then I get stuck here. Since to apply bivariate Delta method, we need to know the covariance of $x_{(1)}$ and $\bar{x}$ that is $Cov(x_{(1)}, \bar{x})$. I cannot think of a way to calculate that. And also, the factor in front of these two statistics is different,  one is $\sqrt{n}$ and another is $n$. Even we find the covariance how could we apply the delta method? I'm really appreciate anyone who could provide me some hint.",,"['statistics', 'asymptotics']"
72,Finding ACVF of An AR(3) Process,Finding ACVF of An AR(3) Process,,"I am currently doing an online course on Time Series and this is a self-assessment question from the homework, I won't see the answer until I submit, so I would appreciate hints/leads. I have made my attempt at the question, but I didn't think I went down the right path. This course is following Introduction To Time Series and Forecasting by Brockwell and Davis. I am using 3rd Edition. here is the question: Find the autocovariance function of the AR(3) process: $(1 - 0.5B)(1 - 0.4B)(1 - 0.1B)X_{t} = Z_{t},   Z_{t} \sim  WN{\lbrace0,\sigma^{2} \rbrace}$ I could think of 2 ways of doing this: I could solve the autoregressive polynomial and prove the roots are greater than 1 in absolute value, which then prove the AR(3) is causal (in book 3.1.5); once this is done, I could then calculate the coefficients for $Z_{t}$, according to $X_{t}=\sum_{j=0}^{\infty}\psi_{j}Z_{t-j}$ for all t, where $\psi_{j} = \theta_{j} + \sum_{j=0}^{p}\phi_{k}\psi_{j-k}, j=0,1,.....$, $(1)$ I normally rewrite it as $\psi_{j} = (\theta_{k}+\phi_{k})\phi^{j-1}, \psi^{0} = 1$ $k=1,2,....p$ $j=1,2,.....,$ in the context of the problem, we could think of it as ARMA process where moving average polynomial $\theta(z) \equiv 1$ To do this I wrote the l.h.s in its expanded form so the backward operators are removed and this gives me: $X_{t}-X_{t-1}+0.29X_{t-2}-0.02X_{t-3}=Z_{t}$ $(2)$ and solve: $ 1 - z + 0.29z^{2} - 0.02z^{3} = 0$ we could go ahead solve this cubic equation but I don't really think that is the way of solving this problem, it requires way too much calculation. Another way I thought about was to use recursion where I rewrite $X_{t-1}$ and probably also $X_{t-2}$ in formula and plug them back into $(2)$, expecting the limit of the sum of all X_{t} terms to be zero and leaving us with only the $Z_{t}$ terms. this way we could also get all the coefficients of $Z_{t}$ and then solve it using $(1)$. But what I've got wasn't what I expected, I can't seem to get the limit of $x_{t}$ terms. Could anyone see this from a different angle that I apparently missed out?","I am currently doing an online course on Time Series and this is a self-assessment question from the homework, I won't see the answer until I submit, so I would appreciate hints/leads. I have made my attempt at the question, but I didn't think I went down the right path. This course is following Introduction To Time Series and Forecasting by Brockwell and Davis. I am using 3rd Edition. here is the question: Find the autocovariance function of the AR(3) process: $(1 - 0.5B)(1 - 0.4B)(1 - 0.1B)X_{t} = Z_{t},   Z_{t} \sim  WN{\lbrace0,\sigma^{2} \rbrace}$ I could think of 2 ways of doing this: I could solve the autoregressive polynomial and prove the roots are greater than 1 in absolute value, which then prove the AR(3) is causal (in book 3.1.5); once this is done, I could then calculate the coefficients for $Z_{t}$, according to $X_{t}=\sum_{j=0}^{\infty}\psi_{j}Z_{t-j}$ for all t, where $\psi_{j} = \theta_{j} + \sum_{j=0}^{p}\phi_{k}\psi_{j-k}, j=0,1,.....$, $(1)$ I normally rewrite it as $\psi_{j} = (\theta_{k}+\phi_{k})\phi^{j-1}, \psi^{0} = 1$ $k=1,2,....p$ $j=1,2,.....,$ in the context of the problem, we could think of it as ARMA process where moving average polynomial $\theta(z) \equiv 1$ To do this I wrote the l.h.s in its expanded form so the backward operators are removed and this gives me: $X_{t}-X_{t-1}+0.29X_{t-2}-0.02X_{t-3}=Z_{t}$ $(2)$ and solve: $ 1 - z + 0.29z^{2} - 0.02z^{3} = 0$ we could go ahead solve this cubic equation but I don't really think that is the way of solving this problem, it requires way too much calculation. Another way I thought about was to use recursion where I rewrite $X_{t-1}$ and probably also $X_{t-2}$ in formula and plug them back into $(2)$, expecting the limit of the sum of all X_{t} terms to be zero and leaving us with only the $Z_{t}$ terms. this way we could also get all the coefficients of $Z_{t}$ and then solve it using $(1)$. But what I've got wasn't what I expected, I can't seem to get the limit of $x_{t}$ terms. Could anyone see this from a different angle that I apparently missed out?",,"['statistics', 'recurrence-relations', 'self-learning', 'time-series']"
73,How to calculate t-statistic for portfolio [closed],How to calculate t-statistic for portfolio [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I recently did a portfolio sort. I had following data: Time FIRM return size   1  1       0.2   5   2  1       0.1   6   1  2       0.1   7   2  2       0.1   8   .  .         .   .   .  .         .   .   .  .         .   . Every month I sorted the date according to their size into 5 buckets (p1..p5) and calculated the average return of each bucket, giving me: Time p1  p2    p3   p4   p5    p5-p1  1  0.5  0.4  0.3  0.2   0.1   -0.4  2  0.5  0.4  0.3  0.2   0.1   -0.4  3   .    .    .    .    .      .  4   .    .    .    .    .      .  5   .    .    .    .    .      . In the end I calculate the Average return of each bucket: p1  p2    p3   p4   p5    p5-p1 0.5  0.4  0.3  0.2   0.1   -0.4 Now, I want to know if these average return and especially if p5-p1 is statistically significant. Do you guys have an idea how I could do this?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I recently did a portfolio sort. I had following data: Time FIRM return size   1  1       0.2   5   2  1       0.1   6   1  2       0.1   7   2  2       0.1   8   .  .         .   .   .  .         .   .   .  .         .   . Every month I sorted the date according to their size into 5 buckets (p1..p5) and calculated the average return of each bucket, giving me: Time p1  p2    p3   p4   p5    p5-p1  1  0.5  0.4  0.3  0.2   0.1   -0.4  2  0.5  0.4  0.3  0.2   0.1   -0.4  3   .    .    .    .    .      .  4   .    .    .    .    .      .  5   .    .    .    .    .      . In the end I calculate the Average return of each bucket: p1  p2    p3   p4   p5    p5-p1 0.5  0.4  0.3  0.2   0.1   -0.4 Now, I want to know if these average return and especially if p5-p1 is statistically significant. Do you guys have an idea how I could do this?",,"['statistics', 'finance']"
74,Can anyone suggest well written books for learning basic statistics/ probability?,Can anyone suggest well written books for learning basic statistics/ probability?,,"I'm in final year high-school, (which is grade 13 where I live), and, as the title suggests, I'm seeking a book which introduces statistic/ probability with little prerequisites other than mastery of basic arithmetic and a good command and understanding of basic Algebra. I will be self studying this, so ideally, the book should elucidate rather well written explanations for basic statistical notions.","I'm in final year high-school, (which is grade 13 where I live), and, as the title suggests, I'm seeking a book which introduces statistic/ probability with little prerequisites other than mastery of basic arithmetic and a good command and understanding of basic Algebra. I will be self studying this, so ideally, the book should elucidate rather well written explanations for basic statistical notions.",,"['probability', 'statistics', 'self-learning']"
75,How to find approximation of variance of $i^\text{th}$ order statistic [closed],How to find approximation of variance of  order statistic [closed],i^\text{th},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Given PDF and CDF of a distribution, how does one find an approximation of $(\operatorname{Var}(X_i))$ using a normal approximation of $(X_i)$? According to ""Mathematica Laboratories for Mathematical Statistics"" by Jenny Baglivo (Theorem 9.1 on page 120), it is said that: $\operatorname{Var}(X_i) \approx p(1-p) / (n+2)f(x)^2$ where $f$ is PDF, $x$ is $p^\text{th}$ quantile of the $X$ distribution, and $p = i/(n+1)$ I have $0$ ideas on how we get to this result. I am absolutely drawing at a blank. Help is very much appreciated!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Given PDF and CDF of a distribution, how does one find an approximation of $(\operatorname{Var}(X_i))$ using a normal approximation of $(X_i)$? According to ""Mathematica Laboratories for Mathematical Statistics"" by Jenny Baglivo (Theorem 9.1 on page 120), it is said that: $\operatorname{Var}(X_i) \approx p(1-p) / (n+2)f(x)^2$ where $f$ is PDF, $x$ is $p^\text{th}$ quantile of the $X$ distribution, and $p = i/(n+1)$ I have $0$ ideas on how we get to this result. I am absolutely drawing at a blank. Help is very much appreciated!",,"['statistics', 'variance', 'order-statistics']"
76,the distribution of $\frac{(X_1 +X_2)^2}{(X_1 -X_2)^2}$,the distribution of,\frac{(X_1 +X_2)^2}{(X_1 -X_2)^2},"If $X_1$ and $X_2$ are random sample of size $2$ from a $N(0, 1)$ population, then the distribution of $\frac{(X_1 +X_2)^2}{(X_1 -X_2)^2}$ My work: I find the expectation of $E(X_1 +X_2)^2 = E(X_1 -X_2)^2 =2$, but after that how do I proceed?","If $X_1$ and $X_2$ are random sample of size $2$ from a $N(0, 1)$ population, then the distribution of $\frac{(X_1 +X_2)^2}{(X_1 -X_2)^2}$ My work: I find the expectation of $E(X_1 +X_2)^2 = E(X_1 -X_2)^2 =2$, but after that how do I proceed?",,"['probability', 'statistics']"
77,Mean of experiment results is the maximum likelihood estimator only when the distribution of error is gaussian.,Mean of experiment results is the maximum likelihood estimator only when the distribution of error is gaussian.,,We want to find parameter $\mu$ . So we have done some experiments. Let the error of measurements be i.i.d. Prove the mean of the results is the maximum likelihood for $\mu$ only when the distribution of errors is Gaussian (let the distribution of error be differentiable as much as necessary).,We want to find parameter . So we have done some experiments. Let the error of measurements be i.i.d. Prove the mean of the results is the maximum likelihood for only when the distribution of errors is Gaussian (let the distribution of error be differentiable as much as necessary).,\mu \mu,"['probability', 'statistics', 'maximum-likelihood']"
78,Simulate a random variable by the given density,Simulate a random variable by the given density,,"Given is the density $$f(x)=\begin{cases} \frac{3}{4}\left(2x-x^2\right)&\mbox{if }x \in (0,2) \\  0&\mbox{else}\end{cases}$$ Find a random variable for the density. There are probably several methods for doing this but I only know of inverse transform and I like to try to use it here. Firstly, we need the distribution function of the density. It is (just assume this is correct): $$F(x)=\begin{cases} \frac{3}{4}x^2-\frac{1}{4}x^3&\mbox{if }0<x\leq 2 \\ 1 &\mbox{if }x>2\\  0 &\mbox{if }x<0\end{cases}$$ Now we need to inverse this distribution function: $$y=\frac{3}{4}x^2-\frac{1}{4}x^3$$ I used a software for this one because it got very complicated when I tried to do it by hand :( $$x= \sqrt[3]{2\sqrt{y^2-y}-2y+1}+\frac{1}{\sqrt[3]{2\sqrt{y^2-y}-2y+1}}$$ While the other party of the distribution function didn't need any change except for the cases, so for the inverse we have $$F^{-1}(y)=\begin{cases} \sqrt[3]{2\sqrt{y^2-y}-2y+1}+\frac{1}{\sqrt[3]{2\sqrt{y^2-y}-2y+1}}&\mbox{if }\\ 1 &\mbox{if }\\  0 &\mbox{if }\end{cases}$$ I didn't expect it will end up that complicated, I don't even know what cases I need to use and how the inverse of $0$ will be treated as it doesn't seem to be defined : / Maybe there is an easier way of solving the problem or did I miss an important step / did a mistake somewhere? :s","Given is the density $$f(x)=\begin{cases} \frac{3}{4}\left(2x-x^2\right)&\mbox{if }x \in (0,2) \\  0&\mbox{else}\end{cases}$$ Find a random variable for the density. There are probably several methods for doing this but I only know of inverse transform and I like to try to use it here. Firstly, we need the distribution function of the density. It is (just assume this is correct): $$F(x)=\begin{cases} \frac{3}{4}x^2-\frac{1}{4}x^3&\mbox{if }0<x\leq 2 \\ 1 &\mbox{if }x>2\\  0 &\mbox{if }x<0\end{cases}$$ Now we need to inverse this distribution function: $$y=\frac{3}{4}x^2-\frac{1}{4}x^3$$ I used a software for this one because it got very complicated when I tried to do it by hand :( $$x= \sqrt[3]{2\sqrt{y^2-y}-2y+1}+\frac{1}{\sqrt[3]{2\sqrt{y^2-y}-2y+1}}$$ While the other party of the distribution function didn't need any change except for the cases, so for the inverse we have $$F^{-1}(y)=\begin{cases} \sqrt[3]{2\sqrt{y^2-y}-2y+1}+\frac{1}{\sqrt[3]{2\sqrt{y^2-y}-2y+1}}&\mbox{if }\\ 1 &\mbox{if }\\  0 &\mbox{if }\end{cases}$$ I didn't expect it will end up that complicated, I don't even know what cases I need to use and how the inverse of $0$ will be treated as it doesn't seem to be defined : / Maybe there is an easier way of solving the problem or did I miss an important step / did a mistake somewhere? :s",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
79,About Algebraic Statistics,About Algebraic Statistics,,"Recently, I find that the website of professor Bernd Sturmfels in Berkeley mentions Algebraic Statistics. I am quite interested in both Algebra and Statistics. But I have never know the cross field between them. Can anyone introduce some reccent work about Algebraic Statistics ?","Recently, I find that the website of professor Bernd Sturmfels in Berkeley mentions Algebraic Statistics. I am quite interested in both Algebra and Statistics. But I have never know the cross field between them. Can anyone introduce some reccent work about Algebraic Statistics ?",,"['statistics', 'algebraic-geometry']"
80,Trouble understanding the Lindeberg-Feller Central Limit Theorem,Trouble understanding the Lindeberg-Feller Central Limit Theorem,,"I am having trouble understanding the notation in the following Lindeberg-Feller CLT. The notation isn't defined anywhere else in the text so I would like to clarify a few things. Firstly, what is $y_{ni}$? Is $i$ indexing the observation? E.g., if there are 5 observations in the sample, then we have $y_{n1}, \cdots, y_{n5}$? What does the subscript $n$ mean? How is the sample average $\overline{y}$ defined? Is it $\frac{1}{m}\sum_{i=1}^{m} y_{ni}$ where $m$ is the total number of observations?","I am having trouble understanding the notation in the following Lindeberg-Feller CLT. The notation isn't defined anywhere else in the text so I would like to clarify a few things. Firstly, what is $y_{ni}$? Is $i$ indexing the observation? E.g., if there are 5 observations in the sample, then we have $y_{n1}, \cdots, y_{n5}$? What does the subscript $n$ mean? How is the sample average $\overline{y}$ defined? Is it $\frac{1}{m}\sum_{i=1}^{m} y_{ni}$ where $m$ is the total number of observations?",,"['probability', 'statistics', 'central-limit-theorem']"
81,Compare the variance of two unbiased estimators,Compare the variance of two unbiased estimators,,"Two unbiased estimators of $Y_i\sim N(\beta x_i, \sigma^2)$ with $\sigma$ known are $\tilde\beta=\dfrac{S_{xy}}{S_{xx}}=\dfrac{\sum_{i=1}^n(x_i-\overline x)Y_i}{\sum_{i=1}^n(x_i-\overline x)x_i}$ and $\tilde{\tilde\beta}=\dfrac{\overline Y}{\overline x}$. How can I show $\operatorname{Var}(\tilde B)\le \text{Var}(\tilde{\tilde\beta})$? I have gotten as far as determining $\text{Var}(\tilde\beta)=\dfrac{\sigma^2}{\sum_{i=1}^n(x_i-\overline x)^2}=\dfrac{\sigma^2}{\sum_{i=1}^n(x_i-\overline x)x_i}$ and $\operatorname{Var}(\tilde{\tilde\beta})=\dfrac{\sigma^2}{n\cdot\overline x^2}=\dfrac{n\sigma^2}{\left(\sum_{i=1}^nx_i\right)^2}$ but am unsure how to make a proper comparison.","Two unbiased estimators of $Y_i\sim N(\beta x_i, \sigma^2)$ with $\sigma$ known are $\tilde\beta=\dfrac{S_{xy}}{S_{xx}}=\dfrac{\sum_{i=1}^n(x_i-\overline x)Y_i}{\sum_{i=1}^n(x_i-\overline x)x_i}$ and $\tilde{\tilde\beta}=\dfrac{\overline Y}{\overline x}$. How can I show $\operatorname{Var}(\tilde B)\le \text{Var}(\tilde{\tilde\beta})$? I have gotten as far as determining $\text{Var}(\tilde\beta)=\dfrac{\sigma^2}{\sum_{i=1}^n(x_i-\overline x)^2}=\dfrac{\sigma^2}{\sum_{i=1}^n(x_i-\overline x)x_i}$ and $\operatorname{Var}(\tilde{\tilde\beta})=\dfrac{\sigma^2}{n\cdot\overline x^2}=\dfrac{n\sigma^2}{\left(\sum_{i=1}^nx_i\right)^2}$ but am unsure how to make a proper comparison.",,"['statistics', 'descriptive-statistics']"
82,Bad Luck Protection (Probability question from playing a video game) [closed],Bad Luck Protection (Probability question from playing a video game) [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 6 years ago . Improve this question So this is a probability/statistics problem that I got from playing a video game called World of Warcraft. I only have a basic knowledge of probability and statistics so I was wondering if anyone could help me to a solution. Basically in the video game there are ""legendaries"" that you can acquire based on a hidden probability. Every time you partake in an activity, you get a chance of getting a ""legendary"". There is a set number of legendaries but having more or less does not affect the chances. On top of that you can only acquire one legendary at a time. The makers of World of Warcraft implemented a system called ""Bad Luck Protection"" that basically ""protects"" people from having extremely bad luck and long periods between getting legendaries. Every activity you do without getting a legendary increases your chances until you finally get one and the probability resets back to the original value. Now there are multiple activities you can do to get a chance at these legendaries but each one gives a different amount of bad luck protection. My primary goal is to find out how one can calculate how much each activity gives in terms of bad luck protection. I would be given a lot of data that lists how many of each activity a player took part in before they got a legendary. Again I'd like to reiterate that I am not great at probability and I'm not even sure there exists an algorithm to solve this problem but really wanted to ask somebody. Thank you!","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 6 years ago . Improve this question So this is a probability/statistics problem that I got from playing a video game called World of Warcraft. I only have a basic knowledge of probability and statistics so I was wondering if anyone could help me to a solution. Basically in the video game there are ""legendaries"" that you can acquire based on a hidden probability. Every time you partake in an activity, you get a chance of getting a ""legendary"". There is a set number of legendaries but having more or less does not affect the chances. On top of that you can only acquire one legendary at a time. The makers of World of Warcraft implemented a system called ""Bad Luck Protection"" that basically ""protects"" people from having extremely bad luck and long periods between getting legendaries. Every activity you do without getting a legendary increases your chances until you finally get one and the probability resets back to the original value. Now there are multiple activities you can do to get a chance at these legendaries but each one gives a different amount of bad luck protection. My primary goal is to find out how one can calculate how much each activity gives in terms of bad luck protection. I would be given a lot of data that lists how many of each activity a player took part in before they got a legendary. Again I'd like to reiterate that I am not great at probability and I'm not even sure there exists an algorithm to solve this problem but really wanted to ask somebody. Thank you!",,"['probability', 'statistics', 'statistical-inference']"
83,Stochastic decision problem with normal distribution,Stochastic decision problem with normal distribution,,"Suppose the decision maker receives a piece of information (signal) $s=\theta+e$, where the true parameter $\theta$ and error $r$ are normally distributed, and makes decision $d\ge 0$ in order to maximize  $$-Pr(\theta<T-d|s)W-d,$$ with $W>0$ and $T\in\mathbb{R}$ being scalars. Suppose the optimal decision is expressed as function $d(s)$: $$d(s):=\arg\max_{d\ge 0} -Pr(\theta<T-d|s)W-d.$$ Then here is my problem: Is the term $s+d(s)$ always (i.e., for all $W,T$) strictly increasing, and how to show this? The problem is nasty because the optimization problem is not globally concave in $d$, so the first order condition does not always determine the optimum. What can I show? Well, if $W$ is small enough, then the corner solution is $d=0$ for all $s$, and then $s+d(s)=s$ is always invertible. However, if $W$ is large enough, then for some interval an interior solution $d(s)>0$ holds. I plotted an example of $d(s)$ in such a case: The downward sloping part is the interval where the first order condition holds $$1=-\frac{\partial Pr(\theta<T-d|s)}{\partial d}W.$$ I was able to get an explicit expression for this interior $d(s)$: $$d(s)=T-PDF^{-1}(1/W)$$ $$=T+\sqrt{-2\sigma^2 \log(1/W \sqrt{2\pi\sigma^2})}-\mu(s),$$ where $PDF^{-1}$ is the inverse of the left side of the normal probability density function, $\sigma^2$ is the variance and $\mu(s)$ is the mean of the posterior normal distribution which depends on information $s$. Because $s$ enters only in the mean, the slope of $d(s)$ is greater than $-1$, so $s+d(s)$ is always strictly increasing whenever $d(s)$ is determined by the first order condition. But perhaps it could still be that there is a discontinuity when $d(s)>0$ switches from the interior solution to a corner solution $d(s)=0$ (around $s=9$ in the plot) for some parameter values $W,T$, which would then introduce a downward jump in $s+d(s)$, making it non-monotone. This is obviously not the case in the plot, but can this happen, or if not, how to show it cannot happen (so that $s+d(s)$ really is always strictly increasing)? I would appreciate any help, either with another approach or by finishing that (hopefully) last step in my approach. Thanks!","Suppose the decision maker receives a piece of information (signal) $s=\theta+e$, where the true parameter $\theta$ and error $r$ are normally distributed, and makes decision $d\ge 0$ in order to maximize  $$-Pr(\theta<T-d|s)W-d,$$ with $W>0$ and $T\in\mathbb{R}$ being scalars. Suppose the optimal decision is expressed as function $d(s)$: $$d(s):=\arg\max_{d\ge 0} -Pr(\theta<T-d|s)W-d.$$ Then here is my problem: Is the term $s+d(s)$ always (i.e., for all $W,T$) strictly increasing, and how to show this? The problem is nasty because the optimization problem is not globally concave in $d$, so the first order condition does not always determine the optimum. What can I show? Well, if $W$ is small enough, then the corner solution is $d=0$ for all $s$, and then $s+d(s)=s$ is always invertible. However, if $W$ is large enough, then for some interval an interior solution $d(s)>0$ holds. I plotted an example of $d(s)$ in such a case: The downward sloping part is the interval where the first order condition holds $$1=-\frac{\partial Pr(\theta<T-d|s)}{\partial d}W.$$ I was able to get an explicit expression for this interior $d(s)$: $$d(s)=T-PDF^{-1}(1/W)$$ $$=T+\sqrt{-2\sigma^2 \log(1/W \sqrt{2\pi\sigma^2})}-\mu(s),$$ where $PDF^{-1}$ is the inverse of the left side of the normal probability density function, $\sigma^2$ is the variance and $\mu(s)$ is the mean of the posterior normal distribution which depends on information $s$. Because $s$ enters only in the mean, the slope of $d(s)$ is greater than $-1$, so $s+d(s)$ is always strictly increasing whenever $d(s)$ is determined by the first order condition. But perhaps it could still be that there is a discontinuity when $d(s)>0$ switches from the interior solution to a corner solution $d(s)=0$ (around $s=9$ in the plot) for some parameter values $W,T$, which would then introduce a downward jump in $s+d(s)$, making it non-monotone. This is obviously not the case in the plot, but can this happen, or if not, how to show it cannot happen (so that $s+d(s)$ really is always strictly increasing)? I would appreciate any help, either with another approach or by finishing that (hopefully) last step in my approach. Thanks!",,"['probability', 'statistics', 'optimization', 'decision-theory']"
84,How to compare competing players with different number of games?,How to compare competing players with different number of games?,,"I hope this is the right place, because the basic problem is mathematical. Regularly my flatmates and I play a card game. But we are playing this in different player constellations and not always with the same number of players. But I want to compare how good or bad a player was and to choose a winner e.g. after X games. What would be a good and fair way to calculate this? My base idea was to weight the victories with the relative number of games they played. But I didn't come up with a good solution. Is there an existing formula or a similar problem already solved?","I hope this is the right place, because the basic problem is mathematical. Regularly my flatmates and I play a card game. But we are playing this in different player constellations and not always with the same number of players. But I want to compare how good or bad a player was and to choose a winner e.g. after X games. What would be a good and fair way to calculate this? My base idea was to weight the victories with the relative number of games they played. But I didn't come up with a good solution. Is there an existing formula or a similar problem already solved?",,"['statistics', 'game-theory']"
85,derive the expectation of exponential function $e^{-\left\Vert \mathbf{x} - V\mathbf{x}+\mathbf{a}\right\Vert^2}$ or its upper bound,derive the expectation of exponential function  or its upper bound,e^{-\left\Vert \mathbf{x} - V\mathbf{x}+\mathbf{a}\right\Vert^2},"I need to analyze this expectation with respect to $n$-dimensional random vectors $\mathbf{x} \in \mathbb{C}^n$. $$E=\int_\mathbf{x} e^{-\left\Vert \mathbf{x} - V\mathbf{x}+\mathbf{a}\right\Vert^2} p_\mathbf{X}(\mathbf{x}) d\mathbf{x}$$ where $V$ is a fixed $n\times n$ unitary matrix and $\mathbf{a}$ is a fixed $n\times 1$ vector. Note that $V$ is not positive definite. It is clear that $E$ must be a function of $\mathbf{a}$ and $V$. 1) Is there any non trivial distribution $p_\mathbf{X}(\mathbf{x})$ that can facilite the calculation of $E$ ? I have tried the uniform distribution over a fixed $(n-1)$-sphere without success. 2) Is there any inequality that can yield upper bound $E$ by a function of $\mathbf{a}$ and $V$. I mean something like  $E = f(\mathbf{a},V) < g(\mathbf{a},V)$ without having $f(\mathbf{a},V)$ ? I appreciate any hints and references.","I need to analyze this expectation with respect to $n$-dimensional random vectors $\mathbf{x} \in \mathbb{C}^n$. $$E=\int_\mathbf{x} e^{-\left\Vert \mathbf{x} - V\mathbf{x}+\mathbf{a}\right\Vert^2} p_\mathbf{X}(\mathbf{x}) d\mathbf{x}$$ where $V$ is a fixed $n\times n$ unitary matrix and $\mathbf{a}$ is a fixed $n\times 1$ vector. Note that $V$ is not positive definite. It is clear that $E$ must be a function of $\mathbf{a}$ and $V$. 1) Is there any non trivial distribution $p_\mathbf{X}(\mathbf{x})$ that can facilite the calculation of $E$ ? I have tried the uniform distribution over a fixed $(n-1)$-sphere without success. 2) Is there any inequality that can yield upper bound $E$ by a function of $\mathbf{a}$ and $V$. I mean something like  $E = f(\mathbf{a},V) < g(\mathbf{a},V)$ without having $f(\mathbf{a},V)$ ? I appreciate any hints and references.",,"['probability', 'integration', 'statistics', 'exponential-function', 'normed-spaces']"
86,Fisher information of sufficient statistic,Fisher information of sufficient statistic,,Why is it true that if $X \sim f_{\theta}(x) $ (let's assume for simplicty that theta is one dimensional) is some random variable and $T(X)$ a sufficient statistic then $I_{X}(\theta)$ (Fisher information ) is equal to $I_{T(X)}(\theta) $? It is said that it can be derived from factorization theorem ($f_{\theta}(x) = g_{\theta}(T(x)) \cdot h(x) $) but I can't see how exactly since we don't know the distribution of $T$.,Why is it true that if $X \sim f_{\theta}(x) $ (let's assume for simplicty that theta is one dimensional) is some random variable and $T(X)$ a sufficient statistic then $I_{X}(\theta)$ (Fisher information ) is equal to $I_{T(X)}(\theta) $? It is said that it can be derived from factorization theorem ($f_{\theta}(x) = g_{\theta}(T(x)) \cdot h(x) $) but I can't see how exactly since we don't know the distribution of $T$.,,"['statistics', 'fisher-information']"
87,"Discrete, finite L-moment problem","Discrete, finite L-moment problem",,"Suppose that we have a real-valued discrete random variable, whose probability distribution has finite support on some set $S$ of real numbers. Then if $N = |S|$, we know that we can construct the entire distribution from the first $N$ raw moments, as described in this paper: https://www.sciencedirect.com/science/article/pii/0166218X9090068N The transformation is a simple Vandermonde matrix that converts from moments to probabilities. Suppose that we instead want to use the L-moments. Is there an analogous result where we can completely reconstruct the distribution using only the first $N$ L-moments, and if so, what does the resulting matrix look like? To be specific, I am looking for the basis specified by the matrix that solves this problem in the discrete, finite case. For the classical (raw) moments, the basis is the monomials up to order $N$. I know that Bernstein polynomials are often mentioned in connection with the L-moments, although I'm not sure if this helps here. I also understand that we can use the L-moments to reconstruct the quantile function, but I'm not sure how many L-moments are needed to reconstruct the entire thing, nor how this translates into a basis for the discrete finite probability distribution.","Suppose that we have a real-valued discrete random variable, whose probability distribution has finite support on some set $S$ of real numbers. Then if $N = |S|$, we know that we can construct the entire distribution from the first $N$ raw moments, as described in this paper: https://www.sciencedirect.com/science/article/pii/0166218X9090068N The transformation is a simple Vandermonde matrix that converts from moments to probabilities. Suppose that we instead want to use the L-moments. Is there an analogous result where we can completely reconstruct the distribution using only the first $N$ L-moments, and if so, what does the resulting matrix look like? To be specific, I am looking for the basis specified by the matrix that solves this problem in the discrete, finite case. For the classical (raw) moments, the basis is the monomials up to order $N$. I know that Bernstein polynomials are often mentioned in connection with the L-moments, although I'm not sure if this helps here. I also understand that we can use the L-moments to reconstruct the quantile function, but I'm not sure how many L-moments are needed to reconstruct the entire thing, nor how this translates into a basis for the discrete finite probability distribution.",,"['statistics', 'order-statistics', 'moment-problem']"
88,Optimality of the MSE in gaussian linear regression,Optimality of the MSE in gaussian linear regression,,"Let's call $\hat{\beta}$ the least squares estimator of $\beta$ in the regression problem $Y = X\beta + \epsilon$ where $\epsilon \sim \mathcal{N}(0, \sigma^2)$ . In a statistics course, I get this statement: The MSE of $\beta$ : $\hat{\beta} = (X^TX)^{-1}X^TY$ is the unique minimum variance unbiased estimator of $\beta$ . Where does this come from? It thought about the Crame-Rao lower bound, but it is a tight bound only in the case of a one-parameter exponential family and in our case ( $\beta$ , $\sigma^2$ ) are two parameters. It would not even account for the claimed uniqueness. Moreover, it does not use the Gauss-Markov theorem because, after stating the above, we demonstrate that, if we drop the Gaussian hypothesis and only keep moments assumption, then this theorem is valid.","Let's call the least squares estimator of in the regression problem where . In a statistics course, I get this statement: The MSE of : is the unique minimum variance unbiased estimator of . Where does this come from? It thought about the Crame-Rao lower bound, but it is a tight bound only in the case of a one-parameter exponential family and in our case ( , ) are two parameters. It would not even account for the claimed uniqueness. Moreover, it does not use the Gauss-Markov theorem because, after stating the above, we demonstrate that, if we drop the Gaussian hypothesis and only keep moments assumption, then this theorem is valid.","\hat{\beta} \beta Y = X\beta + \epsilon \epsilon \sim \mathcal{N}(0, \sigma^2) \beta \hat{\beta} = (X^TX)^{-1}X^TY \beta \beta \sigma^2",['statistics']
89,"$X \sim U(0,\theta)$. Find the distribution of $X_1\mid \max (X_i)$",. Find the distribution of,"X \sim U(0,\theta) X_1\mid \max (X_i)","The problem is to find the distribution of $X_1\mid M$ where $M$ is the maximum of the i.i.d. random variables $X \sim U(0,\theta)$. I have a complete solution but am having trouble justifying one step. We use Bayes' Theorem for CDF's to get started: $$ P(X_1 < x_1 \mid M < m) = \frac{P(M < m \mid X_1 < x_1) P(X_1 < x_1)}{P(M < m)} $$ The cdf's for $M$ and $X_1$ are $(m/\theta)^n$, by independence, and $x_1/\theta$. The cdf for $M\mid X_1$ is $(m/\theta)^{n-1} {\bf 1} [x_1 \leq m]$. The justification I have is that if the observed value $x_1$ is greater than $m$, then $m$ cannot be the maximum. So, I threw the indicator on the cdf in order to justify that $M\mid X_1$ is just the distribution of the maximum excluding $X_1$. So, $$ \frac{P(M < m \mid X_1 < x_1) P(X_1 < x_1)}{P(M < m)} = \frac{(x_1/\theta) (m/\theta)^{n-1}}{(m/\theta)^n} = \frac{x_1}{m} $$ It follows that $X_1\mid M \sim U(0,m)$. Is my justification for the distribution of $M\mid X_1$ correct? I believe my final answer is intuitive.","The problem is to find the distribution of $X_1\mid M$ where $M$ is the maximum of the i.i.d. random variables $X \sim U(0,\theta)$. I have a complete solution but am having trouble justifying one step. We use Bayes' Theorem for CDF's to get started: $$ P(X_1 < x_1 \mid M < m) = \frac{P(M < m \mid X_1 < x_1) P(X_1 < x_1)}{P(M < m)} $$ The cdf's for $M$ and $X_1$ are $(m/\theta)^n$, by independence, and $x_1/\theta$. The cdf for $M\mid X_1$ is $(m/\theta)^{n-1} {\bf 1} [x_1 \leq m]$. The justification I have is that if the observed value $x_1$ is greater than $m$, then $m$ cannot be the maximum. So, I threw the indicator on the cdf in order to justify that $M\mid X_1$ is just the distribution of the maximum excluding $X_1$. So, $$ \frac{P(M < m \mid X_1 < x_1) P(X_1 < x_1)}{P(M < m)} = \frac{(x_1/\theta) (m/\theta)^{n-1}}{(m/\theta)^n} = \frac{x_1}{m} $$ It follows that $X_1\mid M \sim U(0,m)$. Is my justification for the distribution of $M\mid X_1$ correct? I believe my final answer is intuitive.",,"['probability', 'statistics', 'order-statistics']"
90,Exponential families: convergence in distribution implies convergence in mean?,Exponential families: convergence in distribution implies convergence in mean?,,"Various results in statistics are about asymptotic distribution of certain estimators. For example, central limit theorem states that $$\sqrt{n}\left(\widehat{\theta}_{\text{MLE},n} -\theta_0\right) \overset{d}\to \mathcal{N}(0,V)$$ We also have $$ 2 \left[\ell\left(\widehat{\theta}_{\text{MLE},n}\right) - \ell(\theta_0)\right] \overset{d}\to \chi^2_1 $$ where $\ell$ is the log-likelihood. Of course, for them to hold, we will need some assumptions. Common assumptions include $\hat{\theta}_{\text{MLE},n} \overset{p}\to \theta_0$ , $\hat{\theta}_{\text{MLE},n}$ is a zero for the derivative of log-likelihood, minimizer of log-likelihood is unique and an interior point of the support, third order derivative of log-likelihood $\ell \left( x_1, \ldots, x_n, \theta \right)$ is dominated by some function, etc. My question is , assuming all those assumptions hold (sometimes it's called the Classical Conditions, like in Van der Vaart), when can we go from ""convergence in distribution"" to ""convergence in expectation""? As an example where statisticians make such conclusion, here is an excerpt from the book Akaike Information Criterion Statistics: ... Thus we have $\ell^*(\theta_n) = \ell^*(\theta^*) - \frac{1}{2} \sqrt{n} (\theta_n - \theta^*)^T J_* \sqrt{n} (\theta_n - \theta^*) + o_p(1)$ . (there is no $o_p(1)$ in the original text). From asymptotic normality of MLE and relation between normal r.v. and chi-square r.v., $n (\theta_n - \theta^*)^T J_* (\theta_n - \theta^*)$ is asymptotically distributed as chi-square with $K$ degrees of freedom. Consequently, since mean of the chi-square r.v. is $K$ , it is approximately true, for large $n$ , that $$\mathbb{E}[ \ell^*(\theta_n)] = \mathbb{E}[ \ell^*(\theta^*)] - \frac{K}{2}$$ In the last step, author is saying something like ""since $X_n\overset{p}\to W$ , $\mathbb{E}[X_n] \to \mathbb{E}[W]$ "", which is not true in the most general cases. But what about in this case?","Various results in statistics are about asymptotic distribution of certain estimators. For example, central limit theorem states that We also have where is the log-likelihood. Of course, for them to hold, we will need some assumptions. Common assumptions include , is a zero for the derivative of log-likelihood, minimizer of log-likelihood is unique and an interior point of the support, third order derivative of log-likelihood is dominated by some function, etc. My question is , assuming all those assumptions hold (sometimes it's called the Classical Conditions, like in Van der Vaart), when can we go from ""convergence in distribution"" to ""convergence in expectation""? As an example where statisticians make such conclusion, here is an excerpt from the book Akaike Information Criterion Statistics: ... Thus we have . (there is no in the original text). From asymptotic normality of MLE and relation between normal r.v. and chi-square r.v., is asymptotically distributed as chi-square with degrees of freedom. Consequently, since mean of the chi-square r.v. is , it is approximately true, for large , that In the last step, author is saying something like ""since , "", which is not true in the most general cases. But what about in this case?","\sqrt{n}\left(\widehat{\theta}_{\text{MLE},n} -\theta_0\right) \overset{d}\to \mathcal{N}(0,V)  2 \left[\ell\left(\widehat{\theta}_{\text{MLE},n}\right) - \ell(\theta_0)\right] \overset{d}\to \chi^2_1  \ell \hat{\theta}_{\text{MLE},n} \overset{p}\to \theta_0 \hat{\theta}_{\text{MLE},n} \ell \left( x_1, \ldots, x_n, \theta \right) \ell^*(\theta_n) = \ell^*(\theta^*) - \frac{1}{2} \sqrt{n} (\theta_n - \theta^*)^T J_* \sqrt{n} (\theta_n - \theta^*) + o_p(1) o_p(1) n (\theta_n - \theta^*)^T J_* (\theta_n - \theta^*) K K n \mathbb{E}[ \ell^*(\theta_n)] = \mathbb{E}[ \ell^*(\theta^*)] - \frac{K}{2} X_n\overset{p}\to W \mathbb{E}[X_n] \to \mathbb{E}[W]","['real-analysis', 'statistics', 'measure-theory']"
91,Test the hypothesis,Test the hypothesis,,"A new medicine was invented to threat a serious disease. An experiment on $5000$ women and $4000$ men showed that the mean of effect is $10.2$ in women group and $10$ in men group. If samples were drawn down from the normal population with variance $3$, test on $10$% level significance a hypothesis that the effect for women is significantly more than for men. We assume that samples are independent. Denote $\xi_1 \sim N(a_1,3)$ - women results, $\xi_2 \sim N(a_1,3)$- men results. I used t-test with $$ H_0: a_1=a_2,$$ $$ H_1: a_1> a_2.$$ Test statistic: $$t= \frac{10.2-10}{\sqrt{3}\sqrt{\frac{1}{5000}+\frac{1}{4000}}} \approx 5.44$$ As samples drawn from normal distribution, $t \sim N(0,1),$ then $$A_{crit} = [z_{1-\alpha},+\infty) \approx [1.282, +\infty)$$ So we reject a null-hypothesis in favour to alternative. Is this a correct solution?","A new medicine was invented to threat a serious disease. An experiment on $5000$ women and $4000$ men showed that the mean of effect is $10.2$ in women group and $10$ in men group. If samples were drawn down from the normal population with variance $3$, test on $10$% level significance a hypothesis that the effect for women is significantly more than for men. We assume that samples are independent. Denote $\xi_1 \sim N(a_1,3)$ - women results, $\xi_2 \sim N(a_1,3)$- men results. I used t-test with $$ H_0: a_1=a_2,$$ $$ H_1: a_1> a_2.$$ Test statistic: $$t= \frac{10.2-10}{\sqrt{3}\sqrt{\frac{1}{5000}+\frac{1}{4000}}} \approx 5.44$$ As samples drawn from normal distribution, $t \sim N(0,1),$ then $$A_{crit} = [z_{1-\alpha},+\infty) \approx [1.282, +\infty)$$ So we reject a null-hypothesis in favour to alternative. Is this a correct solution?",,"['probability', 'statistics', 'proof-verification', 'statistical-inference']"
92,Weighted Rank Data Analysis,Weighted Rank Data Analysis,,"I have a data set that looks like the following: x1    x2    x3    x4   Weight  Factor1    1     3     10     1     4  Factor2    3     4      2     9     1 Factor3    3     5      6     1     3 Factor4    4     3      1     5     3 Factor5    5     8      4     8     2 Where x represents people and factor represents the treatment variable. The values in the first 4 columns represent risk on a scale from 1 through 10 and the weight column represents the weighted importance (1-5) of that value. I would like to create a meaningful analysis to see which x has the greatest risk based on the various factors and their weights but am unsure of how I should approach this. Since I know this is ranked data, I thought that a Friedman Test would make sense. I would also like to analyze this in R.","I have a data set that looks like the following: x1    x2    x3    x4   Weight  Factor1    1     3     10     1     4  Factor2    3     4      2     9     1 Factor3    3     5      6     1     3 Factor4    4     3      1     5     3 Factor5    5     8      4     8     2 Where x represents people and factor represents the treatment variable. The values in the first 4 columns represent risk on a scale from 1 through 10 and the weight column represents the weighted importance (1-5) of that value. I would like to create a meaningful analysis to see which x has the greatest risk based on the various factors and their weights but am unsure of how I should approach this. Since I know this is ranked data, I thought that a Friedman Test would make sense. I would also like to analyze this in R.",,"['statistics', 'order-statistics', 'chi-squared']"
93,Interpretation of the Allan deviation,Interpretation of the Allan deviation,,"The Allan variance can be defined as: $$\sigma^2_y(\tau)=\frac{1}{2} \left\langle (\Delta y)^2 \right\rangle \quad y(t)=\frac{f(t)-f_n}{f_n}$$ with $f(t)$ being the frequency of some clock at time $t$ , and $f_n$ being the nominal frequency of that clock. If $f(t_0)$ is known, is it correct to derive the distribution of $f(t_0+\tau)$ from that relation? $$\sigma^2_y(\tau) \approx \frac{1}{2} (y(t_0+\tau)-y(t_0))^2$$ $$y(t_0+\tau) \sim \mathcal{N}\left(y(t_0),\sqrt{2}\sigma_y(\tau)\right) $$ $$ f(t_0+\tau) \sim \mathcal{N}\left(f(t_0),f_n\sqrt{2}\sigma_y(\tau)\right)$$","The Allan variance can be defined as: with being the frequency of some clock at time , and being the nominal frequency of that clock. If is known, is it correct to derive the distribution of from that relation?","\sigma^2_y(\tau)=\frac{1}{2} \left\langle (\Delta y)^2 \right\rangle \quad y(t)=\frac{f(t)-f_n}{f_n} f(t) t f_n f(t_0) f(t_0+\tau) \sigma^2_y(\tau) \approx \frac{1}{2} (y(t_0+\tau)-y(t_0))^2 y(t_0+\tau) \sim \mathcal{N}\left(y(t_0),\sqrt{2}\sigma_y(\tau)\right)   f(t_0+\tau) \sim \mathcal{N}\left(f(t_0),f_n\sqrt{2}\sigma_y(\tau)\right)","['statistics', 'random-variables', 'normal-distribution', 'physics']"
94,"EDIT: Looking up critical values for ANOVA, with large value for degrees of freedom","EDIT: Looking up critical values for ANOVA, with large value for degrees of freedom",,"EDIT: Sorry, this post was rambly before - this is my first question and the instructions said to explain exactly what you were doing. I hope it is clear what I was asking now. And I hope it is appropriate to ask for this help (just need a one word answer really). QUESTION: I have 87 degrees of freedom. I have to look up the critical value in an F-table. It has 60 and 100 for the second degree of freedom. Should I round up, or down, or interpolate?","EDIT: Sorry, this post was rambly before - this is my first question and the instructions said to explain exactly what you were doing. I hope it is clear what I was asking now. And I hope it is appropriate to ask for this help (just need a one word answer really). QUESTION: I have 87 degrees of freedom. I have to look up the critical value in an F-table. It has 60 and 100 for the second degree of freedom. Should I round up, or down, or interpolate?",,"['statistics', 'hypothesis-testing']"
95,How to find $E(Y|X)$,How to find,E(Y|X),"I have the joint PDF of $X$ and $Y$ as follows: $$f_{X, Y}(x,y) = \begin{cases} \frac{1}{2} e^{-\frac{x}{y}-y}, & x \ge 0, y>0 \\[2ex] 0, & \text{otherwise} \end{cases}$$ I calculated $E(X|Y) = y$ but I can't manage calculating $E(Y|X)$ because im not sure as to how to start it. In the process of calculating $E(X|Y)$ I also calculated $$f_{X|Y}(x|y) = \frac{1}{y} e^{-\frac{x}{y}}, x \ge 0$$ and $$f_Y(y) = e^{-y} , y>0$$ thanks","I have the joint PDF of $X$ and $Y$ as follows: $$f_{X, Y}(x,y) = \begin{cases} \frac{1}{2} e^{-\frac{x}{y}-y}, & x \ge 0, y>0 \\[2ex] 0, & \text{otherwise} \end{cases}$$ I calculated $E(X|Y) = y$ but I can't manage calculating $E(Y|X)$ because im not sure as to how to start it. In the process of calculating $E(X|Y)$ I also calculated $$f_{X|Y}(x|y) = \frac{1}{y} e^{-\frac{x}{y}}, x \ge 0$$ and $$f_Y(y) = e^{-y} , y>0$$ thanks",,"['probability', 'statistics']"
96,A problem on estimability of parameters.,A problem on estimability of parameters.,,"Let $Y_1,Y_2,Y_3$ and $Y_4$ be four random variables such that $E(Y_1)=\theta_1-\theta_3;\space\space E(Y_2)=\theta_1+\theta_2-\theta_3;\space\space E(Y_3)=\theta_1-\theta_3;\space\space E(Y_4)=\theta_1-\theta_2-\theta_3$, where $\theta_1,\theta_2,\theta_3$ are unknown parameters. Also assume that $Var(Y_i)=\sigma^2$, $i=1,2,3,4.$ Then which one is true? A. $\theta_1,\theta_2,\theta_3$ are estimable. B. $\theta_1+\theta_3$ is estimable. C. $\theta_1-\theta_3$ is estimable and $\dfrac{1}{2}(Y_1+Y_3)$ is the best linear unbiased estimate of $\theta_1-\theta_3$. D. $\theta_2$ is estimable. The answer is given is C which looks strange to me (because I got D). Why I got D? Since, $E(Y_2-Y_4)=2\theta_2$. Why I don't understand that C could be an answer? Ok, I can see, $\dfrac{Y_1+Y_2+Y_3+Y_4}{4}$ is an unbiased estimator of $\theta_1-\theta_3$, and its' variance is less than $\dfrac{Y_1+Y_3}{2}$. Please tell me where am I doing wrong. Any help appreciated. Thanks! Also posted here: https://stats.stackexchange.com/questions/319117/a-problem-on-estimability-of-parameters I recently reviewed the question and their is nothing written about $Y_i$'s being uncorrelated. So, please assume that $Y_i$'s are uncorrelated. Please!","Let $Y_1,Y_2,Y_3$ and $Y_4$ be four random variables such that $E(Y_1)=\theta_1-\theta_3;\space\space E(Y_2)=\theta_1+\theta_2-\theta_3;\space\space E(Y_3)=\theta_1-\theta_3;\space\space E(Y_4)=\theta_1-\theta_2-\theta_3$, where $\theta_1,\theta_2,\theta_3$ are unknown parameters. Also assume that $Var(Y_i)=\sigma^2$, $i=1,2,3,4.$ Then which one is true? A. $\theta_1,\theta_2,\theta_3$ are estimable. B. $\theta_1+\theta_3$ is estimable. C. $\theta_1-\theta_3$ is estimable and $\dfrac{1}{2}(Y_1+Y_3)$ is the best linear unbiased estimate of $\theta_1-\theta_3$. D. $\theta_2$ is estimable. The answer is given is C which looks strange to me (because I got D). Why I got D? Since, $E(Y_2-Y_4)=2\theta_2$. Why I don't understand that C could be an answer? Ok, I can see, $\dfrac{Y_1+Y_2+Y_3+Y_4}{4}$ is an unbiased estimator of $\theta_1-\theta_3$, and its' variance is less than $\dfrac{Y_1+Y_3}{2}$. Please tell me where am I doing wrong. Any help appreciated. Thanks! Also posted here: https://stats.stackexchange.com/questions/319117/a-problem-on-estimability-of-parameters I recently reviewed the question and their is nothing written about $Y_i$'s being uncorrelated. So, please assume that $Y_i$'s are uncorrelated. Please!",,"['statistics', 'estimation']"
97,Probability of no moves in solitaire [closed],Probability of no moves in solitaire [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question I was playing a standard solitaire game on my mobile app and I came across a round where I couldn't perform a single move thus resulting in a loss. I was then thinking as to what the probability of this event to happen in a single game. Would anybody know this probability and show the calculations given a standard deck of 52 cards? Here is a link to the rules: https://www.wikihow.com/Play-Solitaire Note: There are three cards turned at a time but you can only play the second card after you played the top card. Also, the game is klondike.","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question I was playing a standard solitaire game on my mobile app and I came across a round where I couldn't perform a single move thus resulting in a loss. I was then thinking as to what the probability of this event to happen in a single game. Would anybody know this probability and show the calculations given a standard deck of 52 cards? Here is a link to the rules: https://www.wikihow.com/Play-Solitaire Note: There are three cards turned at a time but you can only play the second card after you played the top card. Also, the game is klondike.",,"['probability', 'statistics']"
98,Making conclusions from data with mixed up labels?,Making conclusions from data with mixed up labels?,,"We have a question which asks something strange, something which seems like it would prevent any conclusions being made from the data. The question is as follows: The subjects of a study came from a genetically pure strain of rats. From each litter, one rat was selected at random for the treatment and one for the control group. Each animal in the treatment group lived with 11 others in a large cage, furnished with playthings which were changed daily. Animals in the control group lived in isolation, with no toys. After a month, the experimental animals were killed and their cortex weights (in milligrams) were recorded. We are then given a table of data - one column with the treatment group and one with the control group and several rows of recorded weights. The first two questions involve finding if there is an association between the treatment and cortex weights, they were no problem. However, the third question is as follows: After doing this analysis you are told that the lab assistant who recorded the weights had mixed up the labels that identified the pairs of siblings. Test whether treatment affects the cortex weight of rats using appropriate graphical methods and a parametric statistical test. Check that the assumptions of the test are satisfied. I cannot think of how we can use the data if the labels of the rats have been mixed up. It is worded as if the labels aren't simply swapped but rather the results are mixed. Surely if they were mixed up then the data is jumbled together and we cannot make any meaningful conclusions as we cannot separate the control and treatment? I would really appreciate if anyone could shed some light on what this question is expecting. All the best!","We have a question which asks something strange, something which seems like it would prevent any conclusions being made from the data. The question is as follows: The subjects of a study came from a genetically pure strain of rats. From each litter, one rat was selected at random for the treatment and one for the control group. Each animal in the treatment group lived with 11 others in a large cage, furnished with playthings which were changed daily. Animals in the control group lived in isolation, with no toys. After a month, the experimental animals were killed and their cortex weights (in milligrams) were recorded. We are then given a table of data - one column with the treatment group and one with the control group and several rows of recorded weights. The first two questions involve finding if there is an association between the treatment and cortex weights, they were no problem. However, the third question is as follows: After doing this analysis you are told that the lab assistant who recorded the weights had mixed up the labels that identified the pairs of siblings. Test whether treatment affects the cortex weight of rats using appropriate graphical methods and a parametric statistical test. Check that the assumptions of the test are satisfied. I cannot think of how we can use the data if the labels of the rats have been mixed up. It is worded as if the labels aren't simply swapped but rather the results are mixed. Surely if they were mixed up then the data is jumbled together and we cannot make any meaningful conclusions as we cannot separate the control and treatment? I would really appreciate if anyone could shed some light on what this question is expecting. All the best!",,['statistics']
99,"Can L, the square lattice on the plane, be partitioned into finitely many subsets that (up to translation) are contained in a rotated version of L?","Can L, the square lattice on the plane, be partitioned into finitely many subsets that (up to translation) are contained in a rotated version of L?",,"I ran into this interesting problem while thinking about some stats models the other day. The context was efficient estimation of anisotropic covariance structures in geostatistical models, but it appears to be more of a geometry or number theory problem. This is really not my area, so please forgive any abuse of notation: Let $L_{(0,1)}$ be a square lattice in the Euclidean plane with unit spacing and let $L_{(\theta,d)}$ be the lattice obtained by rotating $L_{(0,1)}$ by angle $\theta$ and scaling (increasing the spacing) by factor $d\geq1$. Now suppose we partition $L_{(0,1)}$ into subsets that, up to translation, are perfectly aligned with $L_{(\theta,d)}$. To make this precise, let $S(\theta,d)$ be the set of partitions $P = \left\lbrace L_1, L_2, ... \right\rbrace$ of $L_{(0,1)}$ that satisfy: $$ \forall L_i \in P, \quad \exists \quad (x_i, y_i) \in R^2 \quad \text{such that} \quad L_i + (x_i, y_i) \subseteq L_{(\theta,d)} $$ The set $S(\theta,d)$ is nonempty, since it always contains the partition of singletons (which can be shuffled around however we like). Sometimes it also contains partitions of finite cardinality. Symmetry in the square lattice provides some easy examples: with a right angle and no scaling we can just use the trivial partition, $$ \left\lbrace  L_{(0,1)} \right\rbrace \in S \left( \frac{\pi}{2},1 \right), $$ and when $\theta$ is a multiple of $\pi/4$ we can scale by $\sqrt{2}$ and get a partition of cardinality 2, $$ \left\lbrace \left\lbrace (i,j) \in L_{(0,1)} \mid |i-j| \text{ odd} \right\rbrace,   \left\lbrace (i,j) \in L_{(0,1)} \mid |i-j| \text{ even} \right\rbrace \right\rbrace \in S \left( \frac{\pi}{4},\sqrt{2} \right). $$ I would like to know in general when $S(\theta,d)$ will contain a partition of finite cardinality (and for my application, I'm really interested in special angles for which we get partitions of low cardinality, say less than 10). Any insights or references to help me better understand the problem are appreciated, but I do have these specific questions: Is there any theory that concisely characterizes the relationship between $(\theta$, $d)$ and $S(\theta,d)$? When does a partition of finite cardinality exist? When does a partition of minimal cardinality exist? Is it unique? Is it easy to find? My intuition is that if $\theta = \arctan(p/q)$ for integers $p$ and $q$ then the set $$ S \left( \theta,\sqrt{p^2 + q^2} \right)  $$ should contain a partition of cardinality $p^2 + q^2$, and this would be minimal. But I'm really not sure if this is true, nor how to approach the problem rigorously. Thanks! Here is an example diagram for the case $p=2$, $q=1$. The dotted blue lines are $L_{(0,1)}$ and the dashed green is $L_{(\theta,\sqrt{5})}$. The green box is the rotated and scaled version of the blue box. I count $5 = 1^2 + 2^2$ points (one blue and four green) representing subsets of $L_{(0,1)}$ (together, a partition) that can be translated to lie on the lattice $L_{(\theta,\sqrt{5})}$.","I ran into this interesting problem while thinking about some stats models the other day. The context was efficient estimation of anisotropic covariance structures in geostatistical models, but it appears to be more of a geometry or number theory problem. This is really not my area, so please forgive any abuse of notation: Let $L_{(0,1)}$ be a square lattice in the Euclidean plane with unit spacing and let $L_{(\theta,d)}$ be the lattice obtained by rotating $L_{(0,1)}$ by angle $\theta$ and scaling (increasing the spacing) by factor $d\geq1$. Now suppose we partition $L_{(0,1)}$ into subsets that, up to translation, are perfectly aligned with $L_{(\theta,d)}$. To make this precise, let $S(\theta,d)$ be the set of partitions $P = \left\lbrace L_1, L_2, ... \right\rbrace$ of $L_{(0,1)}$ that satisfy: $$ \forall L_i \in P, \quad \exists \quad (x_i, y_i) \in R^2 \quad \text{such that} \quad L_i + (x_i, y_i) \subseteq L_{(\theta,d)} $$ The set $S(\theta,d)$ is nonempty, since it always contains the partition of singletons (which can be shuffled around however we like). Sometimes it also contains partitions of finite cardinality. Symmetry in the square lattice provides some easy examples: with a right angle and no scaling we can just use the trivial partition, $$ \left\lbrace  L_{(0,1)} \right\rbrace \in S \left( \frac{\pi}{2},1 \right), $$ and when $\theta$ is a multiple of $\pi/4$ we can scale by $\sqrt{2}$ and get a partition of cardinality 2, $$ \left\lbrace \left\lbrace (i,j) \in L_{(0,1)} \mid |i-j| \text{ odd} \right\rbrace,   \left\lbrace (i,j) \in L_{(0,1)} \mid |i-j| \text{ even} \right\rbrace \right\rbrace \in S \left( \frac{\pi}{4},\sqrt{2} \right). $$ I would like to know in general when $S(\theta,d)$ will contain a partition of finite cardinality (and for my application, I'm really interested in special angles for which we get partitions of low cardinality, say less than 10). Any insights or references to help me better understand the problem are appreciated, but I do have these specific questions: Is there any theory that concisely characterizes the relationship between $(\theta$, $d)$ and $S(\theta,d)$? When does a partition of finite cardinality exist? When does a partition of minimal cardinality exist? Is it unique? Is it easy to find? My intuition is that if $\theta = \arctan(p/q)$ for integers $p$ and $q$ then the set $$ S \left( \theta,\sqrt{p^2 + q^2} \right)  $$ should contain a partition of cardinality $p^2 + q^2$, and this would be minimal. But I'm really not sure if this is true, nor how to approach the problem rigorously. Thanks! Here is an example diagram for the case $p=2$, $q=1$. The dotted blue lines are $L_{(0,1)}$ and the dashed green is $L_{(\theta,\sqrt{5})}$. The green box is the rotated and scaled version of the blue box. I count $5 = 1^2 + 2^2$ points (one blue and four green) representing subsets of $L_{(0,1)}$ (together, a partition) that can be translated to lie on the lattice $L_{(\theta,\sqrt{5})}$.",,"['geometry', 'number-theory', 'statistics', 'multigrid']"
