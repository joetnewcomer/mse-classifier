,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Covering spaces of $S^1 \vee S^1$.,Covering spaces of .,S^1 \vee S^1,"I can show that $\pi_1(S^1 \vee S^1)$ is the free group $\mathbb{Z} * \mathbb{Z}$, i.e. I can prove van Kampen's theorem, which boils down to 1. equivalence of categories between covers of a manifold, and sets with an action of the fundamental group, and 2. gluing of covers. Question. For each of the following covering spaces of $S^1 \vee S^1$, what is the corresponding subgroup of $\pi_1(S^1 \vee S^1) \cong \mathbb{Z} * \mathbb{Z}$, and is the cover is regular (i.e. normal) or not?","I can show that $\pi_1(S^1 \vee S^1)$ is the free group $\mathbb{Z} * \mathbb{Z}$, i.e. I can prove van Kampen's theorem, which boils down to 1. equivalence of categories between covers of a manifold, and sets with an action of the fundamental group, and 2. gluing of covers. Question. For each of the following covering spaces of $S^1 \vee S^1$, what is the corresponding subgroup of $\pi_1(S^1 \vee S^1) \cong \mathbb{Z} * \mathbb{Z}$, and is the cover is regular (i.e. normal) or not?",,"['abstract-algebra', 'general-topology']"
1,"Two subgroups $H_1, H_2$ of a group $G$ are conjugate iff $G/H_1$ and $G/H_2$ are isomorphic",Two subgroups  of a group  are conjugate iff  and  are isomorphic,"H_1, H_2 G G/H_1 G/H_2","Let $H_1$ and $H_2$ be subgroups of some group $G$. Prove that the left $G$-sets   $G/H_1$ and $G/H_2$ are isomorphic (as left $G$-sets) iff the subgroups $H_1$ and $H_2$ are conjugate. If $H_1$ and $H_2$ are conjugate, then they are isomorphic, thus $G/H_1 \cong G/H_2$. I am having problems with the other direction!","Let $H_1$ and $H_2$ be subgroups of some group $G$. Prove that the left $G$-sets   $G/H_1$ and $G/H_2$ are isomorphic (as left $G$-sets) iff the subgroups $H_1$ and $H_2$ are conjugate. If $H_1$ and $H_2$ are conjugate, then they are isomorphic, thus $G/H_1 \cong G/H_2$. I am having problems with the other direction!",,"['abstract-algebra', 'group-theory', 'group-actions']"
2,Groups of order $pqr$ and their normal subgroups,Groups of order  and their normal subgroups,pqr,"We want to prove that a group, say $G$, of order $pqr$ where $p \gt q \gt r$ has a normal Sylow $p$-subgroup and deduce that it has a normal subgroup of order $pq$. I know how to show $G$ has a normal Sylow $p$-subgroup or normal Sylow $q$-subgroup, but not the rest. Thanks for your advices.","We want to prove that a group, say $G$, of order $pqr$ where $p \gt q \gt r$ has a normal Sylow $p$-subgroup and deduce that it has a normal subgroup of order $pq$. I know how to show $G$ has a normal Sylow $p$-subgroup or normal Sylow $q$-subgroup, but not the rest. Thanks for your advices.",,"['abstract-algebra', 'group-theory', 'sylow-theory']"
3,Free modules are projective.,Free modules are projective.,,"Free modules are projective. Let $M$ be a free module. We have the diagram below (where the second row is exact) Since $M$ is free, it has a basis (call it $X$). For every $x_i \in X$, there exists $b_i \in B$ such that $f(x_i)=b_i$. But since $g$ is surjective, there exists $a_i \in A$ such that $g(a_i)=b_i$. So I was planning to define the funtion $\bar{f} : M \rightarrow A$ by $\bar{f}(x_i) = a_i$ such that $f(x_i)=b_i$ and $g(a_i)=b_i$. But then I remembered that $g$ was not necessarily injective...so one element in $M$ can be sent to more than one element in $A$, right? And that would mean that $\bar{f}$ is not well-defined. So I was just wondering if there was a way to resolve this issue... Thanks in advance.","Free modules are projective. Let $M$ be a free module. We have the diagram below (where the second row is exact) Since $M$ is free, it has a basis (call it $X$). For every $x_i \in X$, there exists $b_i \in B$ such that $f(x_i)=b_i$. But since $g$ is surjective, there exists $a_i \in A$ such that $g(a_i)=b_i$. So I was planning to define the funtion $\bar{f} : M \rightarrow A$ by $\bar{f}(x_i) = a_i$ such that $f(x_i)=b_i$ and $g(a_i)=b_i$. But then I remembered that $g$ was not necessarily injective...so one element in $M$ can be sent to more than one element in $A$, right? And that would mean that $\bar{f}$ is not well-defined. So I was just wondering if there was a way to resolve this issue... Thanks in advance.",,['abstract-algebra']
4,Prove the isomorphism of cyclic groups $C_{mn}\cong C_m\times C_n$ via categorical considerations,Prove the isomorphism of cyclic groups  via categorical considerations,C_{mn}\cong C_m\times C_n,"As the title suggests, I am trying to prove $C_{mn}\cong C_m\times C_n$ when $\gcd{(m,n)}=1$, where $C_n$ denotes the cyclic group of order $n$, using categorical considerations. Specifically, I am trying to show $C_{mn}$ satisfies the characteristic property of group product, which would then imply an isomorphism since both objects would be final objects in the same category. $C_{mn}$ does come with projection homomorpisms, namely the maps $\pi^{mn}_m: C_{mn} \rightarrow C_m$ and $\pi^{mn}_n: C_{mn} \rightarrow C_n$ which are defined by mapping elements of $C_{mn}$ to the redisue classes mod subscript. From here I have gotten a bit lost though, as I cannot see where $m$ and $n$ being relatively prime comes in. I am guessing it would make the product map commute, but I cannot see it. Any ideas? Note This is not homework. Also, I understand there are other ways to prove this, namely by considering the cyclic subgroup generated by the element $(1_m,1_n) \in C_m\times C_n$ and noting that the order of this element is the least common multiple of $m$ and $n$ and then using it's relation to $\gcd{(m,n)}$. This then shows $\langle (1_m,1_n)\rangle$ has order $mn$ and is cyclic, hence must be isomorphic to $C_{mn}$. Also, $C_{mn}\cong C_m\times C_n$ has order $mn$, so $C_{mn}\cong C_m\times C_n=\langle (1_m,1_n)\rangle$, which completes the proof.","As the title suggests, I am trying to prove $C_{mn}\cong C_m\times C_n$ when $\gcd{(m,n)}=1$, where $C_n$ denotes the cyclic group of order $n$, using categorical considerations. Specifically, I am trying to show $C_{mn}$ satisfies the characteristic property of group product, which would then imply an isomorphism since both objects would be final objects in the same category. $C_{mn}$ does come with projection homomorpisms, namely the maps $\pi^{mn}_m: C_{mn} \rightarrow C_m$ and $\pi^{mn}_n: C_{mn} \rightarrow C_n$ which are defined by mapping elements of $C_{mn}$ to the redisue classes mod subscript. From here I have gotten a bit lost though, as I cannot see where $m$ and $n$ being relatively prime comes in. I am guessing it would make the product map commute, but I cannot see it. Any ideas? Note This is not homework. Also, I understand there are other ways to prove this, namely by considering the cyclic subgroup generated by the element $(1_m,1_n) \in C_m\times C_n$ and noting that the order of this element is the least common multiple of $m$ and $n$ and then using it's relation to $\gcd{(m,n)}$. This then shows $\langle (1_m,1_n)\rangle$ has order $mn$ and is cyclic, hence must be isomorphic to $C_{mn}$. Also, $C_{mn}\cong C_m\times C_n$ has order $mn$, so $C_{mn}\cong C_m\times C_n=\langle (1_m,1_n)\rangle$, which completes the proof.",,"['abstract-algebra', 'group-theory', 'category-theory']"
5,Tensor products commute with inductive limit,Tensor products commute with inductive limit,,"How to prove, that tensor products commute with direct limits, if the main ring is not the same? For every $i$ we have modules $L_i$ and $M_i$ over a ring $A_i$, and for every $i \geq j$ homomorphisms $f^i_j: L_i \rightarrow L_j$, $g^i_j: M_i \rightarrow M_j$, $u^i_j: A_i \rightarrow A_j$, such that $f^i_j (al) = u^i_j(a)f^i_j(l)$, $g^i_j(am) = u^i_j (a) g^i_j (m)$ for every $a \in A_i,\,  l\in L_i, \, m \in M_i$. To prove, that $\varinjlim (L_i \otimes_{A_i} M_i) = (\varinjlim L_i)\otimes_{\varinjlim A_i} (\varinjlim M_i)$.","How to prove, that tensor products commute with direct limits, if the main ring is not the same? For every $i$ we have modules $L_i$ and $M_i$ over a ring $A_i$, and for every $i \geq j$ homomorphisms $f^i_j: L_i \rightarrow L_j$, $g^i_j: M_i \rightarrow M_j$, $u^i_j: A_i \rightarrow A_j$, such that $f^i_j (al) = u^i_j(a)f^i_j(l)$, $g^i_j(am) = u^i_j (a) g^i_j (m)$ for every $a \in A_i,\,  l\in L_i, \, m \in M_i$. To prove, that $\varinjlim (L_i \otimes_{A_i} M_i) = (\varinjlim L_i)\otimes_{\varinjlim A_i} (\varinjlim M_i)$.",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'category-theory']"
6,"Can the ideal $(X_1, X_2, \dots, X_n) $ be generated by fewer polynomials over the field $K[X_1, X_2, \dots, X_n]$?",Can the ideal  be generated by fewer polynomials over the field ?,"(X_1, X_2, \dots, X_n)  K[X_1, X_2, \dots, X_n]","My algebra teacher asked whether the ideal $(X_1, X_2, \dots, X_n) $ can be generated by fewer polynomials over the field $K[X_1, X_2, \dots, X_n]$. My intuition tells me that it can't, so I tried to suppose the opposite. If it could, then there would be $P_1, P_2, \dots, P_{n-1} \in K[X_1, X_2, \dots, X_n]$ such that $(P_1, P_2, \dots, P_{n-1}) = (X_1, X_2, \dots, X_n)$ (if fewer than n-1 polynomials suffice, I could just pick some more out of ${X_1, X_2, \dots, X_n}$). It follows that there are some polynomials $Q_{ij} \in K[X_1, X_2, \dots, X_n],\space i \in \{1, \dots n\},\space j \in \{1, \dots n-1\}$ such that: $P_1 \times Q_{1,1} + P_2 \times Q_{1,2} + \dots + P_{n-1} \times Q_{1,n-1} = X_1$ $\dots$ $P_1 \times Q_{n,1} + P_2 \times Q_{n,2} + \dots + P_{n-1} \times Q_{n,n-1} = X_n$ Here I kinda got stuck so I would appreciate any help. :)","My algebra teacher asked whether the ideal $(X_1, X_2, \dots, X_n) $ can be generated by fewer polynomials over the field $K[X_1, X_2, \dots, X_n]$. My intuition tells me that it can't, so I tried to suppose the opposite. If it could, then there would be $P_1, P_2, \dots, P_{n-1} \in K[X_1, X_2, \dots, X_n]$ such that $(P_1, P_2, \dots, P_{n-1}) = (X_1, X_2, \dots, X_n)$ (if fewer than n-1 polynomials suffice, I could just pick some more out of ${X_1, X_2, \dots, X_n}$). It follows that there are some polynomials $Q_{ij} \in K[X_1, X_2, \dots, X_n],\space i \in \{1, \dots n\},\space j \in \{1, \dots n-1\}$ such that: $P_1 \times Q_{1,1} + P_2 \times Q_{1,2} + \dots + P_{n-1} \times Q_{1,n-1} = X_1$ $\dots$ $P_1 \times Q_{n,1} + P_2 \times Q_{n,2} + \dots + P_{n-1} \times Q_{n,n-1} = X_n$ Here I kinda got stuck so I would appreciate any help. :)",,"['abstract-algebra', 'polynomials', 'ideals']"
7,Philosophy of simple field extensions,Philosophy of simple field extensions,,"In B. L. van der Waerden's Algebra stuck on the problem 6.9: The polynomial $f(x) = x^4 + 1$ is irreducible in the field of rationals.   Adjoin a root $\theta$ and resolve the polynomial in the extended   field $\mathbb Q (\theta)$ into prime factors. Seems like I haven't nailed the idea of extending fields, so I'm asking to control my thoughts and help with troubled places. We can obtain the desired extension by two ways: either we use the fact, which states that we know, in which field would that polynomial have a root ( nonsymbolic adjunction ), or we can build residue class field modulo that polynomial ( symbolic adjunction ). I don't realize what I'm supposed to do in both cases. In nonsymbolic way, should I just completely factorize $f(x)$ over $\mathbb C$ , or am I to find only one (any shall do) root? I can write $f(x) = (x^2-i)(x^2+i) = (x-\sqrt i)(x + \sqrt i)(x - \sqrt{-i})(x + \sqrt{-i})$ but what would that give me? Or I could simply say that $\theta = \sqrt{\sqrt{-1}}$ is an obvious root, divide $f(x)$ by $(x - \theta)$ and think hard what to do next with the quotient $x^3 + \theta x^2 + {\theta}^2 x + {\theta}^3$ ? In symbolic way, I have to find residue class field modulo $f(x)$ . Is this possible at all? I haven't seen yet a single example of making that with polynomials. I'm really sorry for the size of the question. The systematic ignorance reminds of itself. However, I feel, that a proper answer will amend many other problems in my knowledge. I am really grateful at least for the time you spent on reading it.","In B. L. van der Waerden's Algebra stuck on the problem 6.9: The polynomial is irreducible in the field of rationals.   Adjoin a root and resolve the polynomial in the extended   field into prime factors. Seems like I haven't nailed the idea of extending fields, so I'm asking to control my thoughts and help with troubled places. We can obtain the desired extension by two ways: either we use the fact, which states that we know, in which field would that polynomial have a root ( nonsymbolic adjunction ), or we can build residue class field modulo that polynomial ( symbolic adjunction ). I don't realize what I'm supposed to do in both cases. In nonsymbolic way, should I just completely factorize over , or am I to find only one (any shall do) root? I can write but what would that give me? Or I could simply say that is an obvious root, divide by and think hard what to do next with the quotient ? In symbolic way, I have to find residue class field modulo . Is this possible at all? I haven't seen yet a single example of making that with polynomials. I'm really sorry for the size of the question. The systematic ignorance reminds of itself. However, I feel, that a proper answer will amend many other problems in my knowledge. I am really grateful at least for the time you spent on reading it.",f(x) = x^4 + 1 \theta \mathbb Q (\theta) f(x) \mathbb C f(x) = (x^2-i)(x^2+i) = (x-\sqrt i)(x + \sqrt i)(x - \sqrt{-i})(x + \sqrt{-i}) \theta = \sqrt{\sqrt{-1}} f(x) (x - \theta) x^3 + \theta x^2 + {\theta}^2 x + {\theta}^3 f(x),"['abstract-algebra', 'polynomials', 'extension-field']"
8,How many different figures can be formed with a regular polygon of $n$ vertices and a number $d$ of diagonals of this polygon?,How many different figures can be formed with a regular polygon of  vertices and a number  of diagonals of this polygon?,n d,"Here we have a simple, but a very hard problem: How many different figures (or graphs) can be formed with a regular polygon of n vertices and a number d of diagonals of this polygon? Consider T ( n,d ) the total number of distinct figures formed by the polygon of n vertices and d diagonals. The question is: how to determine T ( n,d )? The figure below shows some examples for the pentagon (n=5) and hexagon (n=6), to better understand the problem: OBS: Rotated or reflected figures will also be considered the same! I thought about using Polya´s Enumeration  Theory, but I didn't understand how I can do that. There seems to be a similarity with the method of counting graphs by  Polya´s Counting Theory, or still similar to the circular coloring problem solved by Polya. Does anyone have any ideas or methods to solve this problem?","Here we have a simple, but a very hard problem: How many different figures (or graphs) can be formed with a regular polygon of n vertices and a number d of diagonals of this polygon? Consider T ( n,d ) the total number of distinct figures formed by the polygon of n vertices and d diagonals. The question is: how to determine T ( n,d )? The figure below shows some examples for the pentagon (n=5) and hexagon (n=6), to better understand the problem: OBS: Rotated or reflected figures will also be considered the same! I thought about using Polya´s Enumeration  Theory, but I didn't understand how I can do that. There seems to be a similarity with the method of counting graphs by  Polya´s Counting Theory, or still similar to the circular coloring problem solved by Polya. Does anyone have any ideas or methods to solve this problem?",,"['abstract-algebra', 'combinatorics', 'geometry', 'graph-theory', 'combinations']"
9,Making sense of the commutator,Making sense of the commutator,,"For a group $G$, the commutator of two elements is defined as $[a,b]=aba^{-1}b^{-1}$, and is usually said to measure the extent to which the elements $a$ and $b$ fail to commute. I'm having some trouble making sense of the last bit: I understand that if $a$ and $b$ commute, then $[a,b]=e$. But if $a$ and $b$ don't commute, in what sense is the commutator actually capturing the extent of their failure to commute, since there is no way to talk about how ""far"" an element $g\in G$ is from the identity? Am I just interpreting the word ""measure"" too literally here, or is there actually a way to think about commutators that makes it clear in what sense they compare the way two pairs of elements fail to commute?","For a group $G$, the commutator of two elements is defined as $[a,b]=aba^{-1}b^{-1}$, and is usually said to measure the extent to which the elements $a$ and $b$ fail to commute. I'm having some trouble making sense of the last bit: I understand that if $a$ and $b$ commute, then $[a,b]=e$. But if $a$ and $b$ don't commute, in what sense is the commutator actually capturing the extent of their failure to commute, since there is no way to talk about how ""far"" an element $g\in G$ is from the identity? Am I just interpreting the word ""measure"" too literally here, or is there actually a way to think about commutators that makes it clear in what sense they compare the way two pairs of elements fail to commute?",,"['abstract-algebra', 'group-theory']"
10,Surjective exponentials for algebraically closed fields,Surjective exponentials for algebraically closed fields,,"The existence of the exponential on $\mathbb{C}$ has a very basic, yet very strong consequence : $(\mathbb{C}^*,\cdot)$ is a quotient of $(\mathbb{C},+)$. This question is concerned with fields $K$ such that $K^*$ is a quotient of $K$ ; that is, with the existence of a surjective group morphism $K\to K^*$. I will refer to such morphisms as ""exponentials"" on $K$. (I know that the notion of exponential fields exists, but I only consider the surjective case.) The existence of such a map is not benign : since the additive group $K$ is $q$-divisible for all $q\neq char(K)$, it implies that $K^*$ is also $q$-divisible. In characteristic $0$, this actually implies that $K$ is algebraically closed (I suspect that in characteristic $p$ this implies that $K$ is separably closed, but I'll focus on zero characteristic for now). EDIT : That was false, but it doesn't really matter since Eric's answer gives a construction when $K^*$ is divisible. Question 1: It's a basic fact that algebraically closed fields of characteristic zero and with the same transcendance degree over $\mathbb{Q}$ are isomorphic. So $\mathbb{C}_p \simeq \mathbb{C}$ for all $p$, and thus $\mathbb{C}_p$ admits (at least one) exponential map. On the other hand, isomorphisms $\mathbb{C}\to \mathbb{C}_p$ are highly non-constructible objects, so this does not give us any clue about what an exponential on $\mathbb{C}_p$ may look like. Can such an exponential map $\mathbb{C}_p\to \mathbb{C}_p^*$ be explicitly defined ? In particular, does it exist without the axiom of choice (or with only a weak version) ? Question 2: If we put the axiom of choice back on : For any countable cardinal $\kappa$, do algebraically closed fields of transcendance degree $\kappa$ over $\mathbb{Q}$ admit a surjective exponential ? (In particular, what about $\overline{\mathbb{Q}}$ ?) We already know from $\mathbb{C}$ that this is true for $\kappa = 2^{\aleph_0}$ so since ""algebraically closed fields of characteristic zero with a surjective exponential"" may be countably axiomatized in first-order logic, Löwenheim-Skolem implies that there are models of all infinite cardinality, so in particular question 2 has a positive answer for all uncountable $\kappa$, and for some countable $\kappa$. But since all countable $\kappa$ give models of the same cardinality $\aleph_0$, we cannot use that remark to answer the question.","The existence of the exponential on $\mathbb{C}$ has a very basic, yet very strong consequence : $(\mathbb{C}^*,\cdot)$ is a quotient of $(\mathbb{C},+)$. This question is concerned with fields $K$ such that $K^*$ is a quotient of $K$ ; that is, with the existence of a surjective group morphism $K\to K^*$. I will refer to such morphisms as ""exponentials"" on $K$. (I know that the notion of exponential fields exists, but I only consider the surjective case.) The existence of such a map is not benign : since the additive group $K$ is $q$-divisible for all $q\neq char(K)$, it implies that $K^*$ is also $q$-divisible. In characteristic $0$, this actually implies that $K$ is algebraically closed (I suspect that in characteristic $p$ this implies that $K$ is separably closed, but I'll focus on zero characteristic for now). EDIT : That was false, but it doesn't really matter since Eric's answer gives a construction when $K^*$ is divisible. Question 1: It's a basic fact that algebraically closed fields of characteristic zero and with the same transcendance degree over $\mathbb{Q}$ are isomorphic. So $\mathbb{C}_p \simeq \mathbb{C}$ for all $p$, and thus $\mathbb{C}_p$ admits (at least one) exponential map. On the other hand, isomorphisms $\mathbb{C}\to \mathbb{C}_p$ are highly non-constructible objects, so this does not give us any clue about what an exponential on $\mathbb{C}_p$ may look like. Can such an exponential map $\mathbb{C}_p\to \mathbb{C}_p^*$ be explicitly defined ? In particular, does it exist without the axiom of choice (or with only a weak version) ? Question 2: If we put the axiom of choice back on : For any countable cardinal $\kappa$, do algebraically closed fields of transcendance degree $\kappa$ over $\mathbb{Q}$ admit a surjective exponential ? (In particular, what about $\overline{\mathbb{Q}}$ ?) We already know from $\mathbb{C}$ that this is true for $\kappa = 2^{\aleph_0}$ so since ""algebraically closed fields of characteristic zero with a surjective exponential"" may be countably axiomatized in first-order logic, Löwenheim-Skolem implies that there are models of all infinite cardinality, so in particular question 2 has a positive answer for all uncountable $\kappa$, and for some countable $\kappa$. But since all countable $\kappa$ give models of the same cardinality $\aleph_0$, we cannot use that remark to answer the question.",,"['abstract-algebra', 'field-theory', 'model-theory']"
11,"What is the Galois group of $\mathbb{Q}_p[\zeta] / \mathbb{Q}_p$, where $\zeta$ is a $p^r$th root of unity?","What is the Galois group of , where  is a th root of unity?",\mathbb{Q}_p[\zeta] / \mathbb{Q}_p \zeta p^r,"Let $\zeta$ be a $p^r$-th root of unity and $\mathbb{Q}_p$ the p-adic numbers. I would like to know the Galois automorphisms of $\mathbb{Q}_p[\zeta] / \mathbb{Q}_p$. I already know, the degree of that extension is $\varphi(p^r) = p^{r-1} (p-1)$ the extension is totally ramified Furthermore I think the automorphisms are the same as in the global extension $\mathbb{Q}[\zeta] / \mathbb{Q}$ (namely, $\sigma_k: \zeta \mapsto \zeta^k$), but I do not know why. Furthermore this should be wrong if you switch to the $n$-th root of unity, where $n$ is not a prime power, but I also dont see any reason for this. I hope anyone can help. Thanks Laura","Let $\zeta$ be a $p^r$-th root of unity and $\mathbb{Q}_p$ the p-adic numbers. I would like to know the Galois automorphisms of $\mathbb{Q}_p[\zeta] / \mathbb{Q}_p$. I already know, the degree of that extension is $\varphi(p^r) = p^{r-1} (p-1)$ the extension is totally ramified Furthermore I think the automorphisms are the same as in the global extension $\mathbb{Q}[\zeta] / \mathbb{Q}$ (namely, $\sigma_k: \zeta \mapsto \zeta^k$), but I do not know why. Furthermore this should be wrong if you switch to the $n$-th root of unity, where $n$ is not a prime power, but I also dont see any reason for this. I hope anyone can help. Thanks Laura",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory', 'galois-theory', 'p-adic-number-theory']"
12,Number of homomorphisms from $D_n$ to $S_n$,Number of homomorphisms from  to,D_n S_n,"Calculate the number of homomorphisms from $D_n$ (dihedral group of order $2n$) to $S_n$ (symmetric group of order $n!$). For example, I calculated for $D_3$ to $S_3$ and it came to $10$ and for $D_4$ to $S_4$ it came to $124$.","Calculate the number of homomorphisms from $D_n$ (dihedral group of order $2n$) to $S_n$ (symmetric group of order $n!$). For example, I calculated for $D_3$ to $S_3$ and it came to $10$ and for $D_4$ to $S_4$ it came to $124$.",,['abstract-algebra']
13,Proof for maximal ideals in $\mathbb{Z}[x]$ [duplicate],Proof for maximal ideals in  [duplicate],\mathbb{Z}[x],"This question already has an answer here : Classification of prime ideals of $\mathbb{Z}[X]$ (1 answer) Closed 4 years ago . I have been trying to prove the following theorem: Every maximal ideal in $\mathbb{Z}[x]$ has the form $(p, f(x))$ where $p$ is prime integer and $f$ is primitive integer polynomial that is irreducible modulo $p$ . Idea: I tried to establish a homomorphism $\phi: \mathbb{Z}[x] \rightarrow \mathbb{F}$ . Since $\mathbb{F}$ is a field it has characteristic $p$ and so integer prime p are mapped to 0 in $\mathbb{F}$ . Hence $p\in \ker \phi$ . Next we consider $\phi': \mathbb{Z}[x] \rightarrow \mathbb{Z_p}[x]$ and pick an arbitrary maximal ideal $M\in \mathbb{Z}[x]$ . So, $\phi'(M)$ is maximal as long as $p \in M$ by correspondence. But now I am stuck at this stage and do not know how to proceed. I guess we might have to use primitivity given in problem but dont know how.","This question already has an answer here : Classification of prime ideals of $\mathbb{Z}[X]$ (1 answer) Closed 4 years ago . I have been trying to prove the following theorem: Every maximal ideal in has the form where is prime integer and is primitive integer polynomial that is irreducible modulo . Idea: I tried to establish a homomorphism . Since is a field it has characteristic and so integer prime p are mapped to 0 in . Hence . Next we consider and pick an arbitrary maximal ideal . So, is maximal as long as by correspondence. But now I am stuck at this stage and do not know how to proceed. I guess we might have to use primitivity given in problem but dont know how.","\mathbb{Z}[x] (p, f(x)) p f p \phi: \mathbb{Z}[x] \rightarrow \mathbb{F} \mathbb{F} p \mathbb{F} p\in \ker \phi \phi': \mathbb{Z}[x] \rightarrow \mathbb{Z_p}[x] M\in \mathbb{Z}[x] \phi'(M) p \in M","['abstract-algebra', 'ring-theory', 'ideals', 'factoring', 'principal-ideal-domains']"
14,Prove $f=x^p-a$ either irreducible or has a root. (arbitrary characteristic) (without using the field norm) [duplicate],Prove  either irreducible or has a root. (arbitrary characteristic) (without using the field norm) [duplicate],f=x^p-a,"This question already has answers here : Irreducibility of a polynomial if it has no root (Capelli) [duplicate] (3 answers) Closed 10 years ago . Let $K$ be an arbitrary field, $p$ a prime and $a\in K$. Show $f=x^p-a$ is either irreducible in   $K[x]$ or has a root in $K$. My strategy was to split this up into a case for each characteristic. The characteristic $p$ case is easy. Assume $f$ is reducible $=gh$ both smaller degree $g$ irreducible, with $\alpha$ a root of $g$. Then in $K(\alpha)[x]$, $f=(x-\alpha)^p$. So $g=(x-\alpha)^k$, and all the other factors of $f$ are of the same form. Hence they are all equal to the $minpoly(\alpha)$ and the degree of $minpoly(\alpha)|p$ so it is $1$ or $p$ and we are done. The characteristic $0$ case  and characteristic $q\ne p$ I get stuck on. If $K$ contains a primitive $p$th root of unity $\zeta$, then over $K(\alpha)$, $f$ splits into linear factors. So the degree of the field extension for any root of $f$ is the same, so the degree of such a root is either $1$ or $p$. If $K$ does not have a primitive $p$th root of unity, then simply adjoin one. We know $[K(\zeta):K]|p-1$ and by the previous step either $f$ is irreducible over $K(\zeta)$ or splits into linear factors. If it is irreducible we are done, if not we have it splits into linear factors of the form $x-\zeta^ia^{1/p}$, but I am unsure what to do from here. The characteristic $q$ case seems similar to the characteristic $0$ case but again I am stuck trying to finish the proof. Some googling has lead me to believe that this problem is generally approached using the field norm and if an accessible online reference exists I would love to see it, but I feel that in the context I have seen it should be entirely possible that this is done without needing the norm. As I have not seen the field norm before, I would like to know if there is a possible way to prove this without using it and hopefully that follows in the same vein my attempt at a proof did.","This question already has answers here : Irreducibility of a polynomial if it has no root (Capelli) [duplicate] (3 answers) Closed 10 years ago . Let $K$ be an arbitrary field, $p$ a prime and $a\in K$. Show $f=x^p-a$ is either irreducible in   $K[x]$ or has a root in $K$. My strategy was to split this up into a case for each characteristic. The characteristic $p$ case is easy. Assume $f$ is reducible $=gh$ both smaller degree $g$ irreducible, with $\alpha$ a root of $g$. Then in $K(\alpha)[x]$, $f=(x-\alpha)^p$. So $g=(x-\alpha)^k$, and all the other factors of $f$ are of the same form. Hence they are all equal to the $minpoly(\alpha)$ and the degree of $minpoly(\alpha)|p$ so it is $1$ or $p$ and we are done. The characteristic $0$ case  and characteristic $q\ne p$ I get stuck on. If $K$ contains a primitive $p$th root of unity $\zeta$, then over $K(\alpha)$, $f$ splits into linear factors. So the degree of the field extension for any root of $f$ is the same, so the degree of such a root is either $1$ or $p$. If $K$ does not have a primitive $p$th root of unity, then simply adjoin one. We know $[K(\zeta):K]|p-1$ and by the previous step either $f$ is irreducible over $K(\zeta)$ or splits into linear factors. If it is irreducible we are done, if not we have it splits into linear factors of the form $x-\zeta^ia^{1/p}$, but I am unsure what to do from here. The characteristic $q$ case seems similar to the characteristic $0$ case but again I am stuck trying to finish the proof. Some googling has lead me to believe that this problem is generally approached using the field norm and if an accessible online reference exists I would love to see it, but I feel that in the context I have seen it should be entirely possible that this is done without needing the norm. As I have not seen the field norm before, I would like to know if there is a possible way to prove this without using it and hopefully that follows in the same vein my attempt at a proof did.",,"['abstract-algebra', 'polynomials', 'field-theory']"
15,$G/Z$ cannot be isomorphic to quaternion group,cannot be isomorphic to quaternion group,G/Z,"Let $Q_8$ be the quaternion group. Show that $G/Z$ can never be isomorphic to $Q_8$ , where $Z$ is the center of $G$ . Hint: if $G/Z\cong Q_8$ , show that $G$ has two abelian subgroups of index $2$ . I'm trying to prove the hint by looking at the canonical homomorphism $\pi:G\rightarrow G/Z$ . Well, $Q_8$ has some abelian subgroups of index $2$ , such as $H=\{1,-1,i,-i\}$ , but that doesn't seem to map to abelian subgroups of index $2$ of $G$ . (We know that $\pi(ab)=\pi(a)\pi(b)=\pi(b)\pi(a)=\pi(ba)$ for $a,b$ in $\pi^{-1}(H)$ , but that only yields $aba^{-1}b^{-1}\in Z$ , not $aba^{-1}b^{-1}=1$ .)","Let be the quaternion group. Show that can never be isomorphic to , where is the center of . Hint: if , show that has two abelian subgroups of index . I'm trying to prove the hint by looking at the canonical homomorphism . Well, has some abelian subgroups of index , such as , but that doesn't seem to map to abelian subgroups of index of . (We know that for in , but that only yields , not .)","Q_8 G/Z Q_8 Z G G/Z\cong Q_8 G 2 \pi:G\rightarrow G/Z Q_8 2 H=\{1,-1,i,-i\} 2 G \pi(ab)=\pi(a)\pi(b)=\pi(b)\pi(a)=\pi(ba) a,b \pi^{-1}(H) aba^{-1}b^{-1}\in Z aba^{-1}b^{-1}=1","['abstract-algebra', 'group-theory']"
16,What can we say about the size of $HK\cap KH$ when $HK\neq KH$?,What can we say about the size of  when ?,HK\cap KH HK\neq KH,"If $G$ is a finite group, and $H$, $K$ are proper subgroups of $G$, then it is not necessary that $HK=KH$. But, these two subsets have same size. The question I would like to ask, then,  is If $HK\neq KH$, then what can we say about the size of $HK\cap KH$? (Note that $H\cup K\subseteq HK\cap KH$.)","If $G$ is a finite group, and $H$, $K$ are proper subgroups of $G$, then it is not necessary that $HK=KH$. But, these two subsets have same size. The question I would like to ask, then,  is If $HK\neq KH$, then what can we say about the size of $HK\cap KH$? (Note that $H\cup K\subseteq HK\cap KH$.)",,"['abstract-algebra', 'combinatorics', 'group-theory', 'finite-groups']"
17,Completion as a functor between topological rings,Completion as a functor between topological rings,,"In the following all rings are assumed to be commutative and unitary. Preliminaries: For any topological ring $R$ we can form its completion $\widehat{R}$ by taking all Cauchy sequences modulo null sequences. This is again a ring and we can consider completion as a functor $\textbf{RingTop} \to \textbf{Ring}$. If $R$ is even a linear topological ring - i.e. it admits a fundamental system of neighborhoods of 0 consisting of ideals, say $R \supseteq I_1 \supseteq I_2 \supseteq \dots$ - then $\widehat{R}$ carries a canonical linear topology given by $\widehat{R} \supseteq \widehat{I_1} \supseteq \widehat{I_2} \supseteq \dots$ which turns completion into a functor $\textbf{LRingTop} \to \textbf{LRingTop}$ between linear topological rings. Question: Is it possible to spare linearity and turn completion into a functor $\textbf{RingTop} \to \textbf{RingTop}$ in a canonical way which covers the above considerations and additionally has $\widehat{\mathbb{Q}} \cong \mathbb{R}$ as special case? If not: is there a counterexample which illustrates the difficulties in defining a canonical topology on $\widehat{R}$ which turns completion into a functor in the non-linear case? Thanks for any help!","In the following all rings are assumed to be commutative and unitary. Preliminaries: For any topological ring $R$ we can form its completion $\widehat{R}$ by taking all Cauchy sequences modulo null sequences. This is again a ring and we can consider completion as a functor $\textbf{RingTop} \to \textbf{Ring}$. If $R$ is even a linear topological ring - i.e. it admits a fundamental system of neighborhoods of 0 consisting of ideals, say $R \supseteq I_1 \supseteq I_2 \supseteq \dots$ - then $\widehat{R}$ carries a canonical linear topology given by $\widehat{R} \supseteq \widehat{I_1} \supseteq \widehat{I_2} \supseteq \dots$ which turns completion into a functor $\textbf{LRingTop} \to \textbf{LRingTop}$ between linear topological rings. Question: Is it possible to spare linearity and turn completion into a functor $\textbf{RingTop} \to \textbf{RingTop}$ in a canonical way which covers the above considerations and additionally has $\widehat{\mathbb{Q}} \cong \mathbb{R}$ as special case? If not: is there a counterexample which illustrates the difficulties in defining a canonical topology on $\widehat{R}$ which turns completion into a functor in the non-linear case? Thanks for any help!",,"['abstract-algebra', 'general-topology', 'commutative-algebra', 'category-theory']"
18,Does every Poisson bracket on a commutative algebra come from a second-order deformation?,Does every Poisson bracket on a commutative algebra come from a second-order deformation?,,"Let $A$ be a commutative algebra over a field $k$ (of characteristic not equal to $2$ to be safe). Recall that $f : A \otimes A \to A$ is a Hochschild $2$-cocycle if it satisfies $$f(ab, c) + f(a, b) c = f(a, bc) + a f(b, c)$$ and recall that $\{ -, - \} : A \otimes A \to A$ is a Poisson bracket if it is a Lie bracket such that $\{ a, bc \} = \{ a, b \} c + b \{ a, c \}.$ Until recently I was pretty sure that if $f$ is a $2$-cocycle, then $f(a, b) - f(b, a)$ is a Poisson bracket (which only depends on the image of $f$ in $H^2(A, A)$). I can prove that $f(a, b) - f(b, a)$ is alternating and satisfies the Leibniz rule, but I can't prove the Jacobi identity and now I'm no longer sure it holds in general, although I don't know how to construct a counterexample. What's a counterexample to this statement? The correct statement seems to be that $f(a, b) - f(b, a)$ satisfies the Jacobi identity if the first-order deformation of $A$ $$a \star b = ab + \epsilon f(a, b)$$ defined by $f$ extends to a second-order deformation. Is this condition necessary? That is, Does every Poisson bracket on $A$ extend to a second-order deformation? I recall that there is a nice way of checking whether $f$ extends in this way involving $H^3(A, A)$, but I don't remember where I saw it or what it was. (Edit: it can be found in Gerstenhaber's original paper on the subject. I think the answer to the question ought to be ""no,"" but I don't know an explicit counterexample.) Also, is there a nice name for an alternating bilinear map on an algebra that satisfies the Leibniz rule but not the Jacobi identity? An alternating biderivation? A quasi-Poisson bracket?","Let $A$ be a commutative algebra over a field $k$ (of characteristic not equal to $2$ to be safe). Recall that $f : A \otimes A \to A$ is a Hochschild $2$-cocycle if it satisfies $$f(ab, c) + f(a, b) c = f(a, bc) + a f(b, c)$$ and recall that $\{ -, - \} : A \otimes A \to A$ is a Poisson bracket if it is a Lie bracket such that $\{ a, bc \} = \{ a, b \} c + b \{ a, c \}.$ Until recently I was pretty sure that if $f$ is a $2$-cocycle, then $f(a, b) - f(b, a)$ is a Poisson bracket (which only depends on the image of $f$ in $H^2(A, A)$). I can prove that $f(a, b) - f(b, a)$ is alternating and satisfies the Leibniz rule, but I can't prove the Jacobi identity and now I'm no longer sure it holds in general, although I don't know how to construct a counterexample. What's a counterexample to this statement? The correct statement seems to be that $f(a, b) - f(b, a)$ satisfies the Jacobi identity if the first-order deformation of $A$ $$a \star b = ab + \epsilon f(a, b)$$ defined by $f$ extends to a second-order deformation. Is this condition necessary? That is, Does every Poisson bracket on $A$ extend to a second-order deformation? I recall that there is a nice way of checking whether $f$ extends in this way involving $H^3(A, A)$, but I don't remember where I saw it or what it was. (Edit: it can be found in Gerstenhaber's original paper on the subject. I think the answer to the question ought to be ""no,"" but I don't know an explicit counterexample.) Also, is there a nice name for an alternating bilinear map on an algebra that satisfies the Leibniz rule but not the Jacobi identity? An alternating biderivation? A quasi-Poisson bracket?",,"['abstract-algebra', 'homology-cohomology', 'deformation-theory']"
19,Relation between semiring of sets and semiring in abstract algebra.,Relation between semiring of sets and semiring in abstract algebra.,,"Let a $\mathcal R$ be a family of subsets in $\Omega$ that is closed under finite union and relative complement. We say that $\mathcal R$ is a ring of sets in $\Omega$. Symbolically, for any $A,B\in\mathcal R$ we have $$\begin{align} &1.)\quad A\cup B \in \mathcal R\\ &2.)\quad A\backslash B \in \mathcal R. \end{align}$$ It follows that $\mathcal R$ is also closed under symmetric difference $\Delta$ and finite intersection $\cap$, and that $(\mathcal R,\Delta,\cap)$ is a ring in the sense of abstract algebra. However, a semiring of sets is defined as a family $\mathcal S$ of subsets in $X$ such that for any $A,B\in\mathcal S$ $$\begin{align} &1.)\quad \emptyset \in\mathcal S \\ &2.)\quad A\cap B \in \mathcal S\\ &3.)\quad A\backslash B = \bigcup_{i=1}^n A_i\quad\text{for some disjoint}\ A_i\in\mathcal S. \end{align}$$ What is the relation between a semiring of sets and a semiring in the abstract algebra sense? $\mathcal S$ is not even closed under $\Delta$, so we cannot think of it as a semiring $(\mathcal S,\Delta,\cap)$, where $(\mathcal S,\Delta)$ is a commutative monoid. I tagged measure theory because this structure is commonly found in an introductory chapter on construction of Lebesgue measure on $\Bbb R^n$. $\mathcal S$ is the family of $n-$dimensional intervals of the form $[a,b)$.","Let a $\mathcal R$ be a family of subsets in $\Omega$ that is closed under finite union and relative complement. We say that $\mathcal R$ is a ring of sets in $\Omega$. Symbolically, for any $A,B\in\mathcal R$ we have $$\begin{align} &1.)\quad A\cup B \in \mathcal R\\ &2.)\quad A\backslash B \in \mathcal R. \end{align}$$ It follows that $\mathcal R$ is also closed under symmetric difference $\Delta$ and finite intersection $\cap$, and that $(\mathcal R,\Delta,\cap)$ is a ring in the sense of abstract algebra. However, a semiring of sets is defined as a family $\mathcal S$ of subsets in $X$ such that for any $A,B\in\mathcal S$ $$\begin{align} &1.)\quad \emptyset \in\mathcal S \\ &2.)\quad A\cap B \in \mathcal S\\ &3.)\quad A\backslash B = \bigcup_{i=1}^n A_i\quad\text{for some disjoint}\ A_i\in\mathcal S. \end{align}$$ What is the relation between a semiring of sets and a semiring in the abstract algebra sense? $\mathcal S$ is not even closed under $\Delta$, so we cannot think of it as a semiring $(\mathcal S,\Delta,\cap)$, where $(\mathcal S,\Delta)$ is a commutative monoid. I tagged measure theory because this structure is commonly found in an introductory chapter on construction of Lebesgue measure on $\Bbb R^n$. $\mathcal S$ is the family of $n-$dimensional intervals of the form $[a,b)$.",,"['abstract-algebra', 'measure-theory', 'elementary-set-theory', 'ring-theory']"
20,Irreducibility of cyclotomic polynomials over number fields,Irreducibility of cyclotomic polynomials over number fields,,"Let $K$ be a number field, i.e., a finite extension of $\mathbb{Q}$. For a positive integer $n$, let $\Phi_n(X)$ denote the $n$-th cyclotomic polynomial. Is it possible to say that there exist at most finitely many $n$ such that $\Phi_n(X)$ is reducible over $K$, i.e., all but finitely many $\Phi_n(X)$'s are irreducible over $K$? If not, then can we at least say that there are infinitely many $n$ such that $\Phi_n(X)$ is irreducible over $K$?","Let $K$ be a number field, i.e., a finite extension of $\mathbb{Q}$. For a positive integer $n$, let $\Phi_n(X)$ denote the $n$-th cyclotomic polynomial. Is it possible to say that there exist at most finitely many $n$ such that $\Phi_n(X)$ is reducible over $K$, i.e., all but finitely many $\Phi_n(X)$'s are irreducible over $K$? If not, then can we at least say that there are infinitely many $n$ such that $\Phi_n(X)$ is irreducible over $K$?",,"['abstract-algebra', 'field-theory', 'algebraic-number-theory', 'irreducible-polynomials', 'cyclotomic-polynomials']"
21,$5$ dimensional space over $\mathbb{R}$,dimensional space over,5 \mathbb{R},"When coming up with a double cover of $SO(5)$, I used conjugation by matrices of the form $$\begin{pmatrix} r & q\\ \overline{q} & r \end{pmatrix}$$ where $r\in\mathbb{R}$ and $q$ is a quaternion. These matrices are clearly $5$ dimensional over $\mathbb{R}$, but I'm wondering if someone can identify this space by name so that I can find more information. Edit: I should have also added that for any matrix $A$ of this form, $A=A^*$ where $*$ denotes conjugate transpose. However, this requirement follows from how $A$ was defined, so mentioning it again doesn't add information, but rather is a (potentially) useful observation.","When coming up with a double cover of $SO(5)$, I used conjugation by matrices of the form $$\begin{pmatrix} r & q\\ \overline{q} & r \end{pmatrix}$$ where $r\in\mathbb{R}$ and $q$ is a quaternion. These matrices are clearly $5$ dimensional over $\mathbb{R}$, but I'm wondering if someone can identify this space by name so that I can find more information. Edit: I should have also added that for any matrix $A$ of this form, $A=A^*$ where $*$ denotes conjugate transpose. However, this requirement follows from how $A$ was defined, so mentioning it again doesn't add information, but rather is a (potentially) useful observation.",,"['abstract-algebra', 'matrices', 'vector-spaces', 'lie-groups']"
22,A group of order $120$ has a subgroup of index $3$ or $5$ (or both),A group of order  has a subgroup of index  or  (or both),120 3 5,"What I have tried that number of $2$-sylow subgroup can be $1,3,5$ or $15$.I have solved the problem when the number of $2$-sylow subgroup is $1,3,5$. But I am not able to solve it for $15$. Any help will be appreciated..","What I have tried that number of $2$-sylow subgroup can be $1,3,5$ or $15$.I have solved the problem when the number of $2$-sylow subgroup is $1,3,5$. But I am not able to solve it for $15$. Any help will be appreciated..",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
23,"Prove that the cyclic subgroup $\langle a\rangle$ of a group $G$ is normal if and only if for each $g\in G$, $ga=a^kg$ for some $k\in\Bbb{Z}$.","Prove that the cyclic subgroup  of a group  is normal if and only if for each ,  for some .",\langle a\rangle G g\in G ga=a^kg k\in\Bbb{Z},"Prove that the cyclic subgroup $\langle a \rangle$ of a group $G$ is normal if and only if for each $g \in G$, $ga = a^k g$ for some $k \in \mathbb{Z}$. Suppose $\langle a \rangle$ is normal in $G$. Then $\langle a \rangle g = g \langle a \rangle$, for all $g \in G$. This implies $a^k g \in g \langle a \rangle$ for some $k \in \mathbb{Z}$. (How can I make the connection from this point onward to the conclusion of the proof in the forward direction?) Conversely, suppose $ga = a^k g$. Then $ga \in \langle a \rangle g$ and so $g \langle a \rangle \subseteq \langle a \rangle g$. Now $a^k g = ga$ implies $a^k g \in g \langle a \rangle$, and so $\langle a \rangle g\subseteq  g \langle a \rangle$. We finally get $\langle a \rangle g = g \langle a \rangle$.","Prove that the cyclic subgroup $\langle a \rangle$ of a group $G$ is normal if and only if for each $g \in G$, $ga = a^k g$ for some $k \in \mathbb{Z}$. Suppose $\langle a \rangle$ is normal in $G$. Then $\langle a \rangle g = g \langle a \rangle$, for all $g \in G$. This implies $a^k g \in g \langle a \rangle$ for some $k \in \mathbb{Z}$. (How can I make the connection from this point onward to the conclusion of the proof in the forward direction?) Conversely, suppose $ga = a^k g$. Then $ga \in \langle a \rangle g$ and so $g \langle a \rangle \subseteq \langle a \rangle g$. Now $a^k g = ga$ implies $a^k g \in g \langle a \rangle$, and so $\langle a \rangle g\subseteq  g \langle a \rangle$. We finally get $\langle a \rangle g = g \langle a \rangle$.",,"['abstract-algebra', 'group-theory', 'normal-subgroups']"
24,Fully factored integer polynomials with constant differences,Fully factored integer polynomials with constant differences,,"Given a degree $d$, it is possible to construct a pair $(F,\delta),$ where $F$ is a polynomial in $\mathbb{Z}[X]$ and $\delta$ a non-zero integer, such that $F(X)$ and $F(X)+\delta$ both split into linear factors over $\mathbb{Z}[X]$ ? This is easy for $d=2$, as shown by the pair $F(X)=X^2$ and $\delta=-a^2$ (for an arbitrary integer $a$). Indeed, $F(X)=X \cdot X$ and $F(X)+\delta=(X-a)\cdot (X+a).$ What can be said for $d>2$ ?","Given a degree $d$, it is possible to construct a pair $(F,\delta),$ where $F$ is a polynomial in $\mathbb{Z}[X]$ and $\delta$ a non-zero integer, such that $F(X)$ and $F(X)+\delta$ both split into linear factors over $\mathbb{Z}[X]$ ? This is easy for $d=2$, as shown by the pair $F(X)=X^2$ and $\delta=-a^2$ (for an arbitrary integer $a$). Indeed, $F(X)=X \cdot X$ and $F(X)+\delta=(X-a)\cdot (X+a).$ What can be said for $d>2$ ?",,"['abstract-algebra', 'polynomials', 'roots']"
25,Generating Elements of Galois Group,Generating Elements of Galois Group,,"I am trying to prove the following: Let $K=\mathbb{Q}(\sqrt{p_1},\ldots,\sqrt{p_n})$. Show that $K/\mathbb{Q}$ is Galois with Galois group $(\mathbb{Z}/2\mathbb{Z})^n$. I have attached my proof below not as a means of verifying it, only as a means of making my question as clear as possible. My question is: Is it correct to say that that $\tau_i$'s generate $\operatorname{Gal}(K/\mathbb{Q})$, and therefore that we can decompose elements of $\operatorname{Gal}(K/\mathbb{Q})$ into compositions of these functions. My proof is as follows: To show $K/\mathbb{Q}$ is Galois we need to show it is the splitting field of a separable polynomial. The field $\mathbb{Q}(\sqrt{p_1},\ldots,\sqrt{p_n})$ is obtained by an $n$ step process where step $i$ consists of adjoining $\sqrt{p_i}$ to the field $Q_{i-1}=\mathbb{Q}(\sqrt{p_1},\ldots,\sqrt{p_{i-1}})$ and $Q_0$ is defined to be $\mathbb{Q}$. This gives the following tower of extensions $$\mathbb{Q}\subset \mathbb{Q}(\sqrt{p_1})\subset \mathbb{Q}(\sqrt{p_1},\sqrt{p_2})\subset \cdots\subset \mathbb{Q}(\sqrt{p_1},\ldots,\sqrt{p_n}).$$ Note that $Q_i\neq Q_{i+1}$, because $\sqrt{p_{i+1}} \not \in Q_{i}$ for all $i$; the fact the $\sqrt{p_1},\ldots,\sqrt{p_n}$ are distinct primes insures this. Since none of the $p_j$ are squares (because they are prime) we know $\sqrt{p_j} \not \in \mathbb{Q}$. Furthermore, the distinctness of the $p_j$ insure that $\sqrt{p_i} \neq \sqrt{p_j}$ for all $i \neq j$. The minimal polynomial of the extension $Q_{i+1}/Q_i$ is $f_{i+1}(X)=X^2-p_{i+1}$, which is separable with roots $\pm\sqrt{p_{i+1}}$. From this we see that the polynomial we are concerned with is $$f(X)=f_1(X)\cdots f_n(X)=(X^2-p_1)\cdots(X^2-p_n),$$ also a separable polynomial. $K$ is a splitting field for this separable polynomial over $\mathbb{Q}$, and thus $K/\mathbb{Q}$ is Galois. From the tower of fields above we see they $[K:\mathbb{Q}]=2^n$, since the degree of each $Q_i/Q_{i-1}$ is 2. From this we can deduce that $\operatorname{Gal}(K/\mathbb{Q})=2^n$. As with before, $\operatorname{Gal}(K/\mathbb{Q})$ is determined by its action on the roots of $f(X)$, which are $$\{\pm \sqrt{p_1},\ldots,\pm \sqrt{p_n}\},$$ or, more correctly, on the roots of the minimal polynomial of each of these roots. Consider the map \begin{equation*}     \tau_{(a_1,\ldots,a_n)}= \begin{cases}       \sqrt{p_1}& \mapsto \pm \sqrt{p_1},\\       \sqrt{p_2}& \mapsto \pm \sqrt{p_2},\\ 	& \vdots\\       \sqrt{p_n}& \mapsto \pm \sqrt{p_n},     \end{cases} \end{equation*} where $a_i\in \{0,1\}$ and $a_i=0$ means $\sqrt{p_i} \mapsto \sqrt{p_i}$ and $a_i=1$ means $\sqrt{p_i} \mapsto \sqrt{p_i}$.  This gives $2n$ possible maps which take roots of the $f_i(X)$ to roots of $f_i(X)$ (note that these are all such maps as well). Since $|\operatorname{Gal}(K/\mathbb{Q})|=2^n$ all of these maps must be automorphisms of $K$. What remains to be seen is that $\operatorname{Gal}(K/\mathbb{Q}) \cong (\mathbb{Z}/2\mathbb{Z})^n$. We can decompose $\tau_{(a_1,\ldots,a_n)}$ into a composition of the maps $\tau_i:K\rightarrow K$ defined by \begin{equation*} \tau_i = \begin{cases} \tau_i\left(\sqrt{p_j}\right) = -\sqrt{p_i} & \text{for } i=j,\\ \tau_i\left(\sqrt{p_j}\right) = \sqrt{p_j} & \text{for } i\neq j, \end{cases} \end{equation*} where $\tau_{(a_1,\ldots,a_n)}=\tau_1^{a_1}\circ \cdots \circ \tau_n^{a_n}$. We see that every element of $\operatorname{Gal}(K/\mathbb{Q})$ can be obtained through the composition of $\tau_i$'s and therefore $\{\tau_1,\ldots,\tau_n\}$ generates $\operatorname{Gal}(K/\mathbb{Q})$. Let $\tau \in \operatorname{Gal}(K/\mathbb{Q})$ such that $\tau_1^{a_1}\circ \cdots \circ \tau_n^{a_n}$. Define the map $\chi: \operatorname{Gal}(K/\mathbb{Q}) \rightarrow \{\pm 1\}^n$ by first defining the action of $\chi$ on each $\tau_i$ by $$\chi(\tau_i) \mapsto \tau_i(\sqrt{p_i})/\sqrt{p_i},$$ and then defining  \begin{align*} \chi(\tau)&=\chi(\tau_1^{a_1}\circ \cdots \circ \tau_n^{a_n})\\ &=(\chi(\tau_1^{a_1}),\ldots,\chi(\tau_n^{a_n})). \end{align*} Once we show this map is injective we are done, as any injective map between finite sets of the same cardinality is surjective. Assume $(a_1,\ldots,a_n)=(b_1,\ldots,b_n)$. Then clearly $\tau_1^{a_1}\circ \cdots\circ \tau_n^{a_n}=\tau_1^{b_1}\circ \cdots \circ \tau_n^{b_n}$, since $a_i=b_i$ for all $i$. Now, $\{\pm 1\}$ is isomorphic to $\mathbb{Z}/2\mathbb{Z}$, as the map $\varphi: \{\pm 1\} \rightarrow \mathbb{Z}/2\mathbb{Z}$ by $\varphi(-1)=1$ and $\varphi(1)=0$ is an injective homormorphism. Therefore $$\operatorname{Gal}(K/\mathbb{Q})\cong (\mathbb{Z}/2\mathbb{Z})^n.$$ Attempted proof of Martin Brandenburg's Claim: Claim: For all $i<n$ and $i<k_1<\ldots<k_s\leq n$, $\sqrt{p_{k_1}\ldots p_{k_s}} \not \in Q_i$. Proceed by induction on $n$. If $i=0$, then we must show that $\sqrt{p_{k_1}\ldots p_{k_s}} \not \in \mathbb{Q}$, where $0<k_1<\ldots<k_s\leq n$. This is equivalent to showing that $p_{k_1}\ldots p_{k_s}$ is not a square, which is clear since $p_{k_1}, \ldots ,p_{k_s}$ are prime numbers. Assume the result is true for all $i<n-1$ and consider $i=n-1$. We need to show $\sqrt{p_n}\not \in Q_{n-1}$. Assume the contrary, that $\sqrt{p_n} \in Q_{n-1}$. Then $$\sqrt{p_n}=\sum_{(\alpha_1,...,\alpha_{n-1})} a_{(\alpha_1,...,\alpha_{n-1})} \sqrt{{p_1}^{\alpha_1} \ldots p_{n-1}^{\alpha_{n-1}}}, \quad \dagger$$ where $\alpha_i \in \{0,1\}$ and $a_{(\alpha_1,...,\alpha_{n-1})}\in \mathbb{Q}$. Multiplying both sides of $(\dagger)$ by $\sqrt{p_n}$ gives $$p_n=\sum_{(\alpha_1,...,\alpha_{n-1})} a_{(\alpha_1,...,\alpha_{n-1})} \sqrt{{p_1}^{\alpha_1} \ldots p_{n-1}^{\alpha_{n-1}}p_n},$$ contradicting the fact $\sqrt{{p_1}^{\alpha_1} \ldots p_{n-1}^{\alpha_{n-1}}p_n} \not \in \mathbb{Q}$. Therefore $\sqrt{p_n} \not \in Q_{n-1}$.","I am trying to prove the following: Let $K=\mathbb{Q}(\sqrt{p_1},\ldots,\sqrt{p_n})$. Show that $K/\mathbb{Q}$ is Galois with Galois group $(\mathbb{Z}/2\mathbb{Z})^n$. I have attached my proof below not as a means of verifying it, only as a means of making my question as clear as possible. My question is: Is it correct to say that that $\tau_i$'s generate $\operatorname{Gal}(K/\mathbb{Q})$, and therefore that we can decompose elements of $\operatorname{Gal}(K/\mathbb{Q})$ into compositions of these functions. My proof is as follows: To show $K/\mathbb{Q}$ is Galois we need to show it is the splitting field of a separable polynomial. The field $\mathbb{Q}(\sqrt{p_1},\ldots,\sqrt{p_n})$ is obtained by an $n$ step process where step $i$ consists of adjoining $\sqrt{p_i}$ to the field $Q_{i-1}=\mathbb{Q}(\sqrt{p_1},\ldots,\sqrt{p_{i-1}})$ and $Q_0$ is defined to be $\mathbb{Q}$. This gives the following tower of extensions $$\mathbb{Q}\subset \mathbb{Q}(\sqrt{p_1})\subset \mathbb{Q}(\sqrt{p_1},\sqrt{p_2})\subset \cdots\subset \mathbb{Q}(\sqrt{p_1},\ldots,\sqrt{p_n}).$$ Note that $Q_i\neq Q_{i+1}$, because $\sqrt{p_{i+1}} \not \in Q_{i}$ for all $i$; the fact the $\sqrt{p_1},\ldots,\sqrt{p_n}$ are distinct primes insures this. Since none of the $p_j$ are squares (because they are prime) we know $\sqrt{p_j} \not \in \mathbb{Q}$. Furthermore, the distinctness of the $p_j$ insure that $\sqrt{p_i} \neq \sqrt{p_j}$ for all $i \neq j$. The minimal polynomial of the extension $Q_{i+1}/Q_i$ is $f_{i+1}(X)=X^2-p_{i+1}$, which is separable with roots $\pm\sqrt{p_{i+1}}$. From this we see that the polynomial we are concerned with is $$f(X)=f_1(X)\cdots f_n(X)=(X^2-p_1)\cdots(X^2-p_n),$$ also a separable polynomial. $K$ is a splitting field for this separable polynomial over $\mathbb{Q}$, and thus $K/\mathbb{Q}$ is Galois. From the tower of fields above we see they $[K:\mathbb{Q}]=2^n$, since the degree of each $Q_i/Q_{i-1}$ is 2. From this we can deduce that $\operatorname{Gal}(K/\mathbb{Q})=2^n$. As with before, $\operatorname{Gal}(K/\mathbb{Q})$ is determined by its action on the roots of $f(X)$, which are $$\{\pm \sqrt{p_1},\ldots,\pm \sqrt{p_n}\},$$ or, more correctly, on the roots of the minimal polynomial of each of these roots. Consider the map \begin{equation*}     \tau_{(a_1,\ldots,a_n)}= \begin{cases}       \sqrt{p_1}& \mapsto \pm \sqrt{p_1},\\       \sqrt{p_2}& \mapsto \pm \sqrt{p_2},\\ 	& \vdots\\       \sqrt{p_n}& \mapsto \pm \sqrt{p_n},     \end{cases} \end{equation*} where $a_i\in \{0,1\}$ and $a_i=0$ means $\sqrt{p_i} \mapsto \sqrt{p_i}$ and $a_i=1$ means $\sqrt{p_i} \mapsto \sqrt{p_i}$.  This gives $2n$ possible maps which take roots of the $f_i(X)$ to roots of $f_i(X)$ (note that these are all such maps as well). Since $|\operatorname{Gal}(K/\mathbb{Q})|=2^n$ all of these maps must be automorphisms of $K$. What remains to be seen is that $\operatorname{Gal}(K/\mathbb{Q}) \cong (\mathbb{Z}/2\mathbb{Z})^n$. We can decompose $\tau_{(a_1,\ldots,a_n)}$ into a composition of the maps $\tau_i:K\rightarrow K$ defined by \begin{equation*} \tau_i = \begin{cases} \tau_i\left(\sqrt{p_j}\right) = -\sqrt{p_i} & \text{for } i=j,\\ \tau_i\left(\sqrt{p_j}\right) = \sqrt{p_j} & \text{for } i\neq j, \end{cases} \end{equation*} where $\tau_{(a_1,\ldots,a_n)}=\tau_1^{a_1}\circ \cdots \circ \tau_n^{a_n}$. We see that every element of $\operatorname{Gal}(K/\mathbb{Q})$ can be obtained through the composition of $\tau_i$'s and therefore $\{\tau_1,\ldots,\tau_n\}$ generates $\operatorname{Gal}(K/\mathbb{Q})$. Let $\tau \in \operatorname{Gal}(K/\mathbb{Q})$ such that $\tau_1^{a_1}\circ \cdots \circ \tau_n^{a_n}$. Define the map $\chi: \operatorname{Gal}(K/\mathbb{Q}) \rightarrow \{\pm 1\}^n$ by first defining the action of $\chi$ on each $\tau_i$ by $$\chi(\tau_i) \mapsto \tau_i(\sqrt{p_i})/\sqrt{p_i},$$ and then defining  \begin{align*} \chi(\tau)&=\chi(\tau_1^{a_1}\circ \cdots \circ \tau_n^{a_n})\\ &=(\chi(\tau_1^{a_1}),\ldots,\chi(\tau_n^{a_n})). \end{align*} Once we show this map is injective we are done, as any injective map between finite sets of the same cardinality is surjective. Assume $(a_1,\ldots,a_n)=(b_1,\ldots,b_n)$. Then clearly $\tau_1^{a_1}\circ \cdots\circ \tau_n^{a_n}=\tau_1^{b_1}\circ \cdots \circ \tau_n^{b_n}$, since $a_i=b_i$ for all $i$. Now, $\{\pm 1\}$ is isomorphic to $\mathbb{Z}/2\mathbb{Z}$, as the map $\varphi: \{\pm 1\} \rightarrow \mathbb{Z}/2\mathbb{Z}$ by $\varphi(-1)=1$ and $\varphi(1)=0$ is an injective homormorphism. Therefore $$\operatorname{Gal}(K/\mathbb{Q})\cong (\mathbb{Z}/2\mathbb{Z})^n.$$ Attempted proof of Martin Brandenburg's Claim: Claim: For all $i<n$ and $i<k_1<\ldots<k_s\leq n$, $\sqrt{p_{k_1}\ldots p_{k_s}} \not \in Q_i$. Proceed by induction on $n$. If $i=0$, then we must show that $\sqrt{p_{k_1}\ldots p_{k_s}} \not \in \mathbb{Q}$, where $0<k_1<\ldots<k_s\leq n$. This is equivalent to showing that $p_{k_1}\ldots p_{k_s}$ is not a square, which is clear since $p_{k_1}, \ldots ,p_{k_s}$ are prime numbers. Assume the result is true for all $i<n-1$ and consider $i=n-1$. We need to show $\sqrt{p_n}\not \in Q_{n-1}$. Assume the contrary, that $\sqrt{p_n} \in Q_{n-1}$. Then $$\sqrt{p_n}=\sum_{(\alpha_1,...,\alpha_{n-1})} a_{(\alpha_1,...,\alpha_{n-1})} \sqrt{{p_1}^{\alpha_1} \ldots p_{n-1}^{\alpha_{n-1}}}, \quad \dagger$$ where $\alpha_i \in \{0,1\}$ and $a_{(\alpha_1,...,\alpha_{n-1})}\in \mathbb{Q}$. Multiplying both sides of $(\dagger)$ by $\sqrt{p_n}$ gives $$p_n=\sum_{(\alpha_1,...,\alpha_{n-1})} a_{(\alpha_1,...,\alpha_{n-1})} \sqrt{{p_1}^{\alpha_1} \ldots p_{n-1}^{\alpha_{n-1}}p_n},$$ contradicting the fact $\sqrt{{p_1}^{\alpha_1} \ldots p_{n-1}^{\alpha_{n-1}}p_n} \not \in \mathbb{Q}$. Therefore $\sqrt{p_n} \not \in Q_{n-1}$.",,"['abstract-algebra', 'group-theory', 'field-theory', 'galois-theory']"
26,Irreducible representations of a tensor product,Irreducible representations of a tensor product,,"Let $A, B$ be finitely generated (noncommutative) algebras over a field $k$ (say, algebraically closed). Can we get all irreducible representations of $A \otimes_k B$ from tensoring representations of $A$ with representations of $B$? I'm especially interested in the case where $A, B$ are the enveloping algebras of finite-dimensional Lie algebras.","Let $A, B$ be finitely generated (noncommutative) algebras over a field $k$ (say, algebraically closed). Can we get all irreducible representations of $A \otimes_k B$ from tensoring representations of $A$ with representations of $B$? I'm especially interested in the case where $A, B$ are the enveloping algebras of finite-dimensional Lie algebras.",,"['abstract-algebra', 'representation-theory', 'tensor-products']"
27,Is there a nice way to characterize this subset of $Z_n$?,Is there a nice way to characterize this subset of ?,Z_n,"This is a problem I played around with several years ago.  I proved a few things, but the proofs were long and messy and not worth reproducing here. Given a positive integer $n$ and a set $S$ such that $S \subset Z_n$, define a focal point of $n$ and $S$ to be any $a \in Z_n$ such that for each $x \in S$, there exists $y \in S$ such that $x+y \equiv a \mod n$.  It is possible to have $x = y$. Example 1. $n=15$, $S_1=\{1,2,6,7,10,11,12,13\}$.  Then $n$ and $S_1$ have the focal point $8$ because $1+7 = 2+6 = 10+13 = 11+12 = 8$.  By exhaustion one can show that there are no others. Example 2: $n=15$, $S_2=\{1,2,6,7,11,12,13\}$.  These have no focal points, even though $S_2$ is simply $S_1$ with $10$ removed.  In fact, removing any element from $S_1$ results in a set that has no focal points with $n$. Example 3: $n = 15$, $S_3=\{1,2,6,7,11,12\}$.  $S_3$ is obtained by removing both $10$ and $13$ from $S_1$.  $S_3$ and $n$ have 3 focal points: $3, 8$, and $13$. Let $F(n,S)$ be the set of focal points of $n$ and $S$.  My questions are these: What can we say about the size of $F(n,S)$?  I was able to prove that it must be $0$ or a divisor of $n$, but surely one can say more. Even better, is there a nice way to characterize $F(n,S)$? My hunch is that the right algebraic structure will make what's going on here crystal clear.  Unfortunately, my algebra is quite rusty. Added : One thing to observe is that in the case of Example 3, $S_3$ splits nicely into residue classes $\bmod 5$: $\{1, 6, 11\}$ and $\{2, 7, 12\}$.  If $n_4 = 5$ and $S_4 = \{1,2\}$, then clearly $n_4$ and $S_4$ have one focal point: $3$.  Surely it's not a coincidence, then, that $n_3 = 15$ and $S_3=\{1,2,6,7,11,12\}$ have 3 focal points.  So perhaps there's a characterization that has to do with when $S$ can be divided into residue classes modulo a divisor of $n$?","This is a problem I played around with several years ago.  I proved a few things, but the proofs were long and messy and not worth reproducing here. Given a positive integer $n$ and a set $S$ such that $S \subset Z_n$, define a focal point of $n$ and $S$ to be any $a \in Z_n$ such that for each $x \in S$, there exists $y \in S$ such that $x+y \equiv a \mod n$.  It is possible to have $x = y$. Example 1. $n=15$, $S_1=\{1,2,6,7,10,11,12,13\}$.  Then $n$ and $S_1$ have the focal point $8$ because $1+7 = 2+6 = 10+13 = 11+12 = 8$.  By exhaustion one can show that there are no others. Example 2: $n=15$, $S_2=\{1,2,6,7,11,12,13\}$.  These have no focal points, even though $S_2$ is simply $S_1$ with $10$ removed.  In fact, removing any element from $S_1$ results in a set that has no focal points with $n$. Example 3: $n = 15$, $S_3=\{1,2,6,7,11,12\}$.  $S_3$ is obtained by removing both $10$ and $13$ from $S_1$.  $S_3$ and $n$ have 3 focal points: $3, 8$, and $13$. Let $F(n,S)$ be the set of focal points of $n$ and $S$.  My questions are these: What can we say about the size of $F(n,S)$?  I was able to prove that it must be $0$ or a divisor of $n$, but surely one can say more. Even better, is there a nice way to characterize $F(n,S)$? My hunch is that the right algebraic structure will make what's going on here crystal clear.  Unfortunately, my algebra is quite rusty. Added : One thing to observe is that in the case of Example 3, $S_3$ splits nicely into residue classes $\bmod 5$: $\{1, 6, 11\}$ and $\{2, 7, 12\}$.  If $n_4 = 5$ and $S_4 = \{1,2\}$, then clearly $n_4$ and $S_4$ have one focal point: $3$.  Surely it's not a coincidence, then, that $n_3 = 15$ and $S_3=\{1,2,6,7,11,12\}$ have 3 focal points.  So perhaps there's a characterization that has to do with when $S$ can be divided into residue classes modulo a divisor of $n$?",,"['number-theory', 'abstract-algebra', 'group-theory']"
28,Is an infinite field always isomorphic to a non-trivial fraction field?,Is an infinite field always isomorphic to a non-trivial fraction field?,,"Out of the blue, I asked myself the following question: Is an infinite field always isomorphic to the fraction field of an integral domain which is itself not a field? Please note that the above setup avoid answering by a field is its own fraction field . I think this question is natural as it is kind of a converse to the following: Proposition. The rings which can be embedded into some field are exactly the integral domains. As fraction fields have no characteristic properties that I am aware of, I am lost on how to tackle this problem. Any enlightenment will be greatly appreciated! Edit 1. My question only involves infinite field as a finite integral domain is itself a field and the result failed to be true in this case. - pointed out by carmichael561 in the comments below. Edit 2. The result holds for field of characteristic zero . - link provided by Arthur . As for now, the interesting question is the following: Is an infinite field of prime characteristic isomorphic to a non-trivial fraction field?","Out of the blue, I asked myself the following question: Is an infinite field always isomorphic to the fraction field of an integral domain which is itself not a field? Please note that the above setup avoid answering by a field is its own fraction field . I think this question is natural as it is kind of a converse to the following: Proposition. The rings which can be embedded into some field are exactly the integral domains. As fraction fields have no characteristic properties that I am aware of, I am lost on how to tackle this problem. Any enlightenment will be greatly appreciated! Edit 1. My question only involves infinite field as a finite integral domain is itself a field and the result failed to be true in this case. - pointed out by carmichael561 in the comments below. Edit 2. The result holds for field of characteristic zero . - link provided by Arthur . As for now, the interesting question is the following: Is an infinite field of prime characteristic isomorphic to a non-trivial fraction field?",,"['abstract-algebra', 'field-theory', 'integral-domain']"
29,How many subgroups of order 17 does $S_{17}$ have?,How many subgroups of order 17 does  have?,S_{17},"How many subgroups of order 17 does $S_{17}$ have ? My attempt : An order 17 group is of prime order, hence cyclic and each element in it is a generator and of order 17. In $S_{17}$ group we can get an order 17 element only through a 17-cycle. Number of elements of order 17 in $S_{17}$ is $\frac{17!}{17} = 16!$. Now given that two sylow 17 subgroups have only a trivial intersection. We can conclude that 16 of these elements fall into each sylow 17 subgroup. Hence the number of sylow 17 subgroups would be $\frac{16!}{16} = 15!$","How many subgroups of order 17 does $S_{17}$ have ? My attempt : An order 17 group is of prime order, hence cyclic and each element in it is a generator and of order 17. In $S_{17}$ group we can get an order 17 element only through a 17-cycle. Number of elements of order 17 in $S_{17}$ is $\frac{17!}{17} = 16!$. Now given that two sylow 17 subgroups have only a trivial intersection. We can conclude that 16 of these elements fall into each sylow 17 subgroup. Hence the number of sylow 17 subgroups would be $\frac{16!}{16} = 15!$",,"['abstract-algebra', 'group-theory', 'proof-verification', 'finite-groups', 'sylow-theory']"
30,Is there a field extension $K / \Bbb Q$ such that $\text{Aut}_{\Bbb Q}(K) \cong \Bbb Z$?,Is there a field extension  such that ?,K / \Bbb Q \text{Aut}_{\Bbb Q}(K) \cong \Bbb Z,"I'm not requiring this extension to be Galois, that's why I wrote $\text{Aut}$ instead of $\text{Gal}$. I'm not very familiar with infinite extensions nor with profinite groups. I don't know if my question is part of of the inverse Galois problem, since this problem is generally related to finite groups. To start with the ""basic"" infinite extension $\Bbb Q(X)$, I know that $\text{Aut}_{\Bbb Q}(\Bbb Q(X)) \cong \text{PGL}_2(\Bbb Q)$, which is far from being $\Bbb Z$. Notice that this question is not really related to mine. Thanks for your help!","I'm not requiring this extension to be Galois, that's why I wrote $\text{Aut}$ instead of $\text{Gal}$. I'm not very familiar with infinite extensions nor with profinite groups. I don't know if my question is part of of the inverse Galois problem, since this problem is generally related to finite groups. To start with the ""basic"" infinite extension $\Bbb Q(X)$, I know that $\text{Aut}_{\Bbb Q}(\Bbb Q(X)) \cong \text{PGL}_2(\Bbb Q)$, which is far from being $\Bbb Z$. Notice that this question is not really related to mine. Thanks for your help!",,"['abstract-algebra', 'field-theory', 'galois-theory', 'examples-counterexamples']"
31,Neat way to find the kernel of a ring homomorphism,Neat way to find the kernel of a ring homomorphism,,"I'm trying to solve an exercise in Commutative Algebra in which I need the kernel of the following homomorphism: Consider the homomorphism $ \phi :k[[x,y,z]] \to k[[t]]$ which sends $x \to t^3,y \to t^4, z \to t^5$. Find $\ker(\phi)$. It is clear that $ (x^3-yz,y^2-xz,z^2-x^2y) \subseteq \ker(\phi)$. Any hints/ideas to prove the converse?","I'm trying to solve an exercise in Commutative Algebra in which I need the kernel of the following homomorphism: Consider the homomorphism $ \phi :k[[x,y,z]] \to k[[t]]$ which sends $x \to t^3,y \to t^4, z \to t^5$. Find $\ker(\phi)$. It is clear that $ (x^3-yz,y^2-xz,z^2-x^2y) \subseteq \ker(\phi)$. Any hints/ideas to prove the converse?",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals']"
32,Is every multiplicative function from the matrix ring $\text{Mat}_n(R)$ to $R$ a function of $\text{det}$?,Is every multiplicative function from the matrix ring  to  a function of ?,\text{Mat}_n(R) R \text{det},"Suppose that $R$ is a commutative ring with $1$, and for $n \in \mathbb{N}$, let $\text{Mat}_n(R)$ be the set of $n \times n$ matrices with entries in $R$. It is well known that the determinant function $\text{det} : \text{Mat}_n(R) \rightarrow R$ is multiplicative, i.e. $$ \text{det}(AB) = \text{det}(A) \text{det}(B) $$ $\text{det}$ is certainly not unique in this respect; there are lots of functions $g : \text{Mat}_n(R) \rightarrow R$ which are multiplicative. For a start, there are the constant $1$ and constant $0$ functions, as well as the indicator function of ""is invertible"". More strangely, for $R = \mathbb{R}$, are the functions $$ g(A) =  \begin{cases} e^{f(\log(\left|\det(A)\right|))} &\text{if} \det(A) \neq 0 \\ 0 &\text{if} \det(A) = 0 \end{cases} $$ where $f : \mathbb{R} \rightarrow \mathbb{R}$ is any solution of the Cauchy functional equation $f(x+y) = f(x)+f(y)$ : non-continuous solutions to this equation are really badly behaved. However, I have not found any examples of multiplicative functions which are not themselves a function of $\det$. Is there any such function which is not a function of det? That is, is there a ring $R$, an $n \in \mathbb{N}$ and $g : \text{Mat}_n(R) \rightarrow R$ which is multiplicative, and not a function of det, i.e. there exist $A,B \in \text{Mat}_n(R)$ such that $$ \begin{align} \det(A) &= \det(B) \\ g(A) &\neq g(B) \end{align} $$","Suppose that $R$ is a commutative ring with $1$, and for $n \in \mathbb{N}$, let $\text{Mat}_n(R)$ be the set of $n \times n$ matrices with entries in $R$. It is well known that the determinant function $\text{det} : \text{Mat}_n(R) \rightarrow R$ is multiplicative, i.e. $$ \text{det}(AB) = \text{det}(A) \text{det}(B) $$ $\text{det}$ is certainly not unique in this respect; there are lots of functions $g : \text{Mat}_n(R) \rightarrow R$ which are multiplicative. For a start, there are the constant $1$ and constant $0$ functions, as well as the indicator function of ""is invertible"". More strangely, for $R = \mathbb{R}$, are the functions $$ g(A) =  \begin{cases} e^{f(\log(\left|\det(A)\right|))} &\text{if} \det(A) \neq 0 \\ 0 &\text{if} \det(A) = 0 \end{cases} $$ where $f : \mathbb{R} \rightarrow \mathbb{R}$ is any solution of the Cauchy functional equation $f(x+y) = f(x)+f(y)$ : non-continuous solutions to this equation are really badly behaved. However, I have not found any examples of multiplicative functions which are not themselves a function of $\det$. Is there any such function which is not a function of det? That is, is there a ring $R$, an $n \in \mathbb{N}$ and $g : \text{Mat}_n(R) \rightarrow R$ which is multiplicative, and not a function of det, i.e. there exist $A,B \in \text{Mat}_n(R)$ such that $$ \begin{align} \det(A) &= \det(B) \\ g(A) &\neq g(B) \end{align} $$",,"['abstract-algebra', 'matrices', 'group-theory']"
33,Why do you need to introduce complex numbers in order to solve cubics by radicals?,Why do you need to introduce complex numbers in order to solve cubics by radicals?,,"Historically, complex numbers were first introduced (by Bombelli) in order to provide a method for solving the cubic by radicals.  As far as I can tell, previous solutions of the cubic by radicals didn't use complex numbers, but instead used some incredibly complicated reasoning that is basically equivalent to introducing complex numbers. Later on, it turned out that cubics over the complex numbers had particularly nice properties; in particular, they always had three roots in the complex plane (up to multiplicity). But the original guys weren't interested in cubics over the complex plane.  They wanted to find real roots of cubics with real coefficients, and intermediate complex numbers turned out to be a way to do that.  Indeed, the cubic formula uses complex numbers like $-\frac12+\frac{\sqrt3}2i$, but it still gives you three real numbers if you substitute in the coefficients of a real cubic with three real roots. So my question is: why is this necessary?  To be more specific: Let $K\subset\mathbb R$ be a field, and let $P$ be a polynomial in $K[X]$.  Do there exist fields $K=K_1\subset\dots\subset K_n\subset\mathbb R$, real numbers $\beta_i$ and natural numbers $m_i$ such that $\beta_i^{m_i}\in K_i$, $K_{i+1}=K_i(\beta_i)$ for each $i$, and all real roots of $P$ are contained in $K_n$? [Note that the extensions $K_{i+1}/K_i$ are not necessarily Galois extensions (indeed, they are not Galois extensions if they have degree greater than $2$).] If $P$ is a quadratic rather than a cubic, then the answer is 'yes'.  I imagine that the answer for a cubic or quartic is probably 'no' (and it is definitely 'no' for polynomials of higher degree).  But why? Before anyone says it: yes, I know you can solve cubics over the real numbers by using trigonometric or hyperbolic substitutions.  I'm only interested in solution by radicals.","Historically, complex numbers were first introduced (by Bombelli) in order to provide a method for solving the cubic by radicals.  As far as I can tell, previous solutions of the cubic by radicals didn't use complex numbers, but instead used some incredibly complicated reasoning that is basically equivalent to introducing complex numbers. Later on, it turned out that cubics over the complex numbers had particularly nice properties; in particular, they always had three roots in the complex plane (up to multiplicity). But the original guys weren't interested in cubics over the complex plane.  They wanted to find real roots of cubics with real coefficients, and intermediate complex numbers turned out to be a way to do that.  Indeed, the cubic formula uses complex numbers like $-\frac12+\frac{\sqrt3}2i$, but it still gives you three real numbers if you substitute in the coefficients of a real cubic with three real roots. So my question is: why is this necessary?  To be more specific: Let $K\subset\mathbb R$ be a field, and let $P$ be a polynomial in $K[X]$.  Do there exist fields $K=K_1\subset\dots\subset K_n\subset\mathbb R$, real numbers $\beta_i$ and natural numbers $m_i$ such that $\beta_i^{m_i}\in K_i$, $K_{i+1}=K_i(\beta_i)$ for each $i$, and all real roots of $P$ are contained in $K_n$? [Note that the extensions $K_{i+1}/K_i$ are not necessarily Galois extensions (indeed, they are not Galois extensions if they have degree greater than $2$).] If $P$ is a quadratic rather than a cubic, then the answer is 'yes'.  I imagine that the answer for a cubic or quartic is probably 'no' (and it is definitely 'no' for polynomials of higher degree).  But why? Before anyone says it: yes, I know you can solve cubics over the real numbers by using trigonometric or hyperbolic substitutions.  I'm only interested in solution by radicals.",,"['abstract-algebra', 'polynomials', 'galois-theory']"
34,Characteristic of a finite ring with $34$ units,Characteristic of a finite ring with  units,34,"Let $R$ be a finite ring such that the group of units of $R$, $U(R)$, has $34$ elements. I would like to find the characteristic of $R$. Let $k:= \mathrm{Char}(R)$. If $\varphi$ denotes the Euler totient, then $\varphi(k)$ divides $34$, hence $k\in \{2,3,4,6\}$. I think it is possible to rule out some of these values, but I'm not sure how. And if we could rule them all out, even better, then there is no such ring. Any idea is appreciated.","Let $R$ be a finite ring such that the group of units of $R$, $U(R)$, has $34$ elements. I would like to find the characteristic of $R$. Let $k:= \mathrm{Char}(R)$. If $\varphi$ denotes the Euler totient, then $\varphi(k)$ divides $34$, hence $k\in \{2,3,4,6\}$. I think it is possible to rule out some of these values, but I'm not sure how. And if we could rule them all out, even better, then there is no such ring. Any idea is appreciated.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'totient-function', 'positive-characteristic']"
35,"Prove that the ring $(\{0\},+,\cdot)$ is a subring of any ring $(R,+,\cdot).$",Prove that the ring  is a subring of any ring,"(\{0\},+,\cdot) (R,+,\cdot).","I have to prove that the ring $(\{0\},+,\cdot)$ is a subring of any ring $(R,+,\cdot).$ Let $S = (\{0\},+,\cdot)$ and $R = (R,+,\cdot)$ then $S$ is a subring of $R$ iff $(R,+,\cdot)$ is a ring and $S \subseteq R$ and $S$ is a ring with the same operations. As we know $S$ has an identity element of $0 \to 0+0=0$. It has an additive inverse of $0 \to 0-0=0$. It is commutative and associative, and it is distributive over addition. So my only problem is that I am having difficulties cleaning this up and putting it into a proof. Maybe you can help me.","I have to prove that the ring $(\{0\},+,\cdot)$ is a subring of any ring $(R,+,\cdot).$ Let $S = (\{0\},+,\cdot)$ and $R = (R,+,\cdot)$ then $S$ is a subring of $R$ iff $(R,+,\cdot)$ is a ring and $S \subseteq R$ and $S$ is a ring with the same operations. As we know $S$ has an identity element of $0 \to 0+0=0$. It has an additive inverse of $0 \to 0-0=0$. It is commutative and associative, and it is distributive over addition. So my only problem is that I am having difficulties cleaning this up and putting it into a proof. Maybe you can help me.",,"['abstract-algebra', 'group-theory']"
36,Are these two definitions of a semimodule basis equivalent?,Are these two definitions of a semimodule basis equivalent?,,"This question is related to this one . This will be quite a long post. Section ""Introduction"" may be skipped at first. I will refer to it later but it may be easier to only skim that section first (especially given that it's common knowledge). Preliminary definitons A semiring is a set with two operations $+$ and $\cdot$ which satisfy all axioms of a unitary ring except the axiom demanding the existence of additive inverses. A left semimodule over a semiring $R$ is a commutative monoid $M$ (whose operation is denoted by $+$ too) with a function $ R\times M\longrightarrow M$ satisfying all axioms of a module over a ring except the axiom demanding the existence of additive inverses. A right semimodule is defined analogously. Introduction There are two equivalent definitions of a basis of a left $R$-module $M$ for a nontrivial unitary ring $R$. Definition 1. A set $X\subset M$ is a basis of $M$ when $X$ is linearly independent (that is a linear combination of elements of $X$ is zero iff its coefficients are all zero), and $X$ generates $M$. Definition 2. A set $X\subset M$ is a basis of $M$ when for every left $R$-module $N$ and every function $f:X\longrightarrow N$ there exists a unique $R$-module homomorphism $\bar f:M\longrightarrow N$ such that $\bar f|_X=f.$ I will prove the equivalence of these definitions now so that I can show where I have problems with the analogous defintions for semimodules. Proof. Suppose $X$ satisfies Definition 1. Let $N$ be a left $R$-module and $f:X\longrightarrow N.$ We define $\bar f:M\longrightarrow N$ by $$\bar f\left(\sum_{i=1}^nr_ix_i\right)=\sum_{i=1}^nr_if(x_i).$$ Since $X$ generates $M$, this defines $\bar f$ for every $m\in M$. We have to show that it is well defined. Suppose $$\sum_{i=1}^nr_ix_i=\sum_{i=1}^ns_ix_i.$$ Then, by the linear independence of $X$, $$r_i=s_i$$ for all $i=1,\ldots,n.$ Therefore, $$\bar f\left(\sum_{i=1}^nr_ix_i\right)=\sum_{i=1}^nr_if(x_i)=\sum_{i=1}^ns_if(x_i)=\bar f\left(\sum_{i=1}^ns_ix_i\right).$$ We have proved the existence of $\bar f$. We need to show its uniqueness. Suppose $g:M\longrightarrow N$ is a homomorphism, and $g|_X=f$. Then $$g\left(\sum_{i=1}^nr_ix_i\right)=\sum_{i=1}^nr_ig(x_i)=\sum_{i=1}^nr_if(x_i)=\bar f\left(\sum_{i=1}^nr_ix_i\right),$$ and since $X$ generates $M,$ this proves the uniqueness of $\bar f.$ Conversely, suppose $X$ satisfies Definition 2. We will first prove that $X$ is linearly independent. Suppose $$\sum_{i=1}^nr_ix_i=0,$$ and $r_1\neq 0$. Let $f:X\longrightarrow R$ be defined by $$f(x)=\begin{cases}1 & \text {for } x=x_1,\\0 & \text {otherwise.}\end{cases}$$ Then there exists an $R$-module homomorphism $\bar f:M\longrightarrow R$ such that $\bar f|_X=f.$ We have $$0=\bar f(0)=\bar f\left(\sum_{i=1}^nr_ix_i\right)=\sum_{i=1}^nr_if(x_i)=r_1.$$ This is a contradiction, and $X$ must be linearly independent. We need to show that $X$ generates $M$. Let $M_1\subseteq M$ be the submodule generated by $X.$ Let $\bar f:M\longrightarrow M/M_1$ be the canonical homomorphism. Clearly, for all $x\in X,$ we have $\bar f(x)=0.$ Then $\bar f$ and the zero homomorphism restricted to $X$ are equal, and must therefore be equal. Hence $M/M_1=0,$ and so $M=M_1,$ which ends the proof. $\square$ Question As said in the question I linked to at the beginning, the definition of linear independence in semimodules requires a bit of tweaking. If I understand correctly what Bill Cook wrote in his answer and what I later read in a book on semirings, the correct definition is this: Definition 3. For a semiring $R$ and a left $R$-semimodule $M,$ a set $X\subset M$ is linearly independent iff for any two linear combinations of elements of $X$, their equality implies the equality of their coefficients. This gives us two possible definitions of a basis of a left $R$-semimodule $M$ over a semiring $R$ obtained by re-writing Definition 1 and Definition 2, but now considering $M$ to be a semimodule over a semiring $R$. Let's call these definitions Definition 1 s and Definition 2 s . Are these definitions also equivalent? I think they should be. Definition 1 s is part of the definition of a free semimodule given by J. S. Golan in Semirings and Their Applications . But a definition of a free semimodule using Definition 2 s should also be possible. However, it's difficult for me to generalize the proof I gave above. Most of it generalizes easily. I will not write those parts again, now for semimodules, but it is easy to check that Definition 1 s implies Definition 2 s by imitating the proof above. It also allows one to prove that Definition 2 s implies the linear independence of $X$. What doesn't seem to be working is the proof that Definition 2 s implies that $X$ generates $M$. The problem is that quotient structures are not very nice for semimodules. When we quotient out a submodule of a module over a ring, we use subtraction implicitly -- $m, m'$ being in the same coset means that $m-m'\in M_1.$ Quotient semimodules are generally defined not by subsemimodules, but by congruences. (As it is the case for semigroups.) I've found a definition of a quotient semimodule $M/N$ for a subsemimodule $N\subseteq M$, but I don't think it works here. It is defined by the so-called Bourne relation. Definition 4. Let $R$ be a semiring and $M$ a left $R$-semimodule. Let $N\subseteq M$ be a subsemimodule. We define the relation $\equiv_N$ on $M$ by $$m\equiv_N m'\iff (\exists n,n'\in N)\; m+n=m'+n'.$$ This relation can be shown to be a congruence. Now we simply define $M/N$ as $M/\equiv_N.$ This is easily seen to be equivalent to the standard definition in the case of modules over a ring. However, as far as I can see, under this definition, $M/N=0$ doesn't imply $M=N$ in the general case. And this is what we want to use...","This question is related to this one . This will be quite a long post. Section ""Introduction"" may be skipped at first. I will refer to it later but it may be easier to only skim that section first (especially given that it's common knowledge). Preliminary definitons A semiring is a set with two operations $+$ and $\cdot$ which satisfy all axioms of a unitary ring except the axiom demanding the existence of additive inverses. A left semimodule over a semiring $R$ is a commutative monoid $M$ (whose operation is denoted by $+$ too) with a function $ R\times M\longrightarrow M$ satisfying all axioms of a module over a ring except the axiom demanding the existence of additive inverses. A right semimodule is defined analogously. Introduction There are two equivalent definitions of a basis of a left $R$-module $M$ for a nontrivial unitary ring $R$. Definition 1. A set $X\subset M$ is a basis of $M$ when $X$ is linearly independent (that is a linear combination of elements of $X$ is zero iff its coefficients are all zero), and $X$ generates $M$. Definition 2. A set $X\subset M$ is a basis of $M$ when for every left $R$-module $N$ and every function $f:X\longrightarrow N$ there exists a unique $R$-module homomorphism $\bar f:M\longrightarrow N$ such that $\bar f|_X=f.$ I will prove the equivalence of these definitions now so that I can show where I have problems with the analogous defintions for semimodules. Proof. Suppose $X$ satisfies Definition 1. Let $N$ be a left $R$-module and $f:X\longrightarrow N.$ We define $\bar f:M\longrightarrow N$ by $$\bar f\left(\sum_{i=1}^nr_ix_i\right)=\sum_{i=1}^nr_if(x_i).$$ Since $X$ generates $M$, this defines $\bar f$ for every $m\in M$. We have to show that it is well defined. Suppose $$\sum_{i=1}^nr_ix_i=\sum_{i=1}^ns_ix_i.$$ Then, by the linear independence of $X$, $$r_i=s_i$$ for all $i=1,\ldots,n.$ Therefore, $$\bar f\left(\sum_{i=1}^nr_ix_i\right)=\sum_{i=1}^nr_if(x_i)=\sum_{i=1}^ns_if(x_i)=\bar f\left(\sum_{i=1}^ns_ix_i\right).$$ We have proved the existence of $\bar f$. We need to show its uniqueness. Suppose $g:M\longrightarrow N$ is a homomorphism, and $g|_X=f$. Then $$g\left(\sum_{i=1}^nr_ix_i\right)=\sum_{i=1}^nr_ig(x_i)=\sum_{i=1}^nr_if(x_i)=\bar f\left(\sum_{i=1}^nr_ix_i\right),$$ and since $X$ generates $M,$ this proves the uniqueness of $\bar f.$ Conversely, suppose $X$ satisfies Definition 2. We will first prove that $X$ is linearly independent. Suppose $$\sum_{i=1}^nr_ix_i=0,$$ and $r_1\neq 0$. Let $f:X\longrightarrow R$ be defined by $$f(x)=\begin{cases}1 & \text {for } x=x_1,\\0 & \text {otherwise.}\end{cases}$$ Then there exists an $R$-module homomorphism $\bar f:M\longrightarrow R$ such that $\bar f|_X=f.$ We have $$0=\bar f(0)=\bar f\left(\sum_{i=1}^nr_ix_i\right)=\sum_{i=1}^nr_if(x_i)=r_1.$$ This is a contradiction, and $X$ must be linearly independent. We need to show that $X$ generates $M$. Let $M_1\subseteq M$ be the submodule generated by $X.$ Let $\bar f:M\longrightarrow M/M_1$ be the canonical homomorphism. Clearly, for all $x\in X,$ we have $\bar f(x)=0.$ Then $\bar f$ and the zero homomorphism restricted to $X$ are equal, and must therefore be equal. Hence $M/M_1=0,$ and so $M=M_1,$ which ends the proof. $\square$ Question As said in the question I linked to at the beginning, the definition of linear independence in semimodules requires a bit of tweaking. If I understand correctly what Bill Cook wrote in his answer and what I later read in a book on semirings, the correct definition is this: Definition 3. For a semiring $R$ and a left $R$-semimodule $M,$ a set $X\subset M$ is linearly independent iff for any two linear combinations of elements of $X$, their equality implies the equality of their coefficients. This gives us two possible definitions of a basis of a left $R$-semimodule $M$ over a semiring $R$ obtained by re-writing Definition 1 and Definition 2, but now considering $M$ to be a semimodule over a semiring $R$. Let's call these definitions Definition 1 s and Definition 2 s . Are these definitions also equivalent? I think they should be. Definition 1 s is part of the definition of a free semimodule given by J. S. Golan in Semirings and Their Applications . But a definition of a free semimodule using Definition 2 s should also be possible. However, it's difficult for me to generalize the proof I gave above. Most of it generalizes easily. I will not write those parts again, now for semimodules, but it is easy to check that Definition 1 s implies Definition 2 s by imitating the proof above. It also allows one to prove that Definition 2 s implies the linear independence of $X$. What doesn't seem to be working is the proof that Definition 2 s implies that $X$ generates $M$. The problem is that quotient structures are not very nice for semimodules. When we quotient out a submodule of a module over a ring, we use subtraction implicitly -- $m, m'$ being in the same coset means that $m-m'\in M_1.$ Quotient semimodules are generally defined not by subsemimodules, but by congruences. (As it is the case for semigroups.) I've found a definition of a quotient semimodule $M/N$ for a subsemimodule $N\subseteq M$, but I don't think it works here. It is defined by the so-called Bourne relation. Definition 4. Let $R$ be a semiring and $M$ a left $R$-semimodule. Let $N\subseteq M$ be a subsemimodule. We define the relation $\equiv_N$ on $M$ by $$m\equiv_N m'\iff (\exists n,n'\in N)\; m+n=m'+n'.$$ This relation can be shown to be a congruence. Now we simply define $M/N$ as $M/\equiv_N.$ This is easily seen to be equivalent to the standard definition in the case of modules over a ring. However, as far as I can see, under this definition, $M/N=0$ doesn't imply $M=N$ in the general case. And this is what we want to use...",,[]
37,Constructing a finite field,Constructing a finite field,,"I'm looking for constructive ways to obtain finite fields, for any given size $q=p^n$. For example, I know it suffices to find an irreducible polynomial of degree $n$ over $\mathbb{Z}_p$ (and then obtain the field as its quotient ring), but how can such polynomial be efficiently found? Also, I know there are more ways to represent elements of finite fields - are they easier to use than the irreducible polynomial method? What is done in practice in computational mathematical libraries?","I'm looking for constructive ways to obtain finite fields, for any given size $q=p^n$. For example, I know it suffices to find an irreducible polynomial of degree $n$ over $\mathbb{Z}_p$ (and then obtain the field as its quotient ring), but how can such polynomial be efficiently found? Also, I know there are more ways to represent elements of finite fields - are they easier to use than the irreducible polynomial method? What is done in practice in computational mathematical libraries?",,"['abstract-algebra', 'finite-fields', 'computational-mathematics']"
38,Ideals and filters,Ideals and filters,,"The notions of a filter and an ideal on a poset make intuitive sense to me, and I can understand why they are dual: A subset $I\subset P$ of a poset $P$ is an ideal if: for all $x\in I$, $y\leq x$ implies $y\in I$ for all $x,y\in I$ there exists $z\in I$ with $x\leq z$ and $y\leq z$ and a filter is the same thing with all inequalities reversed. I feel like this should correspond to the notion of a ring ideal, where for a ring $R$ we have $I\subset R$ being a ring ideal if: for all $x,y\in I$ we have $x+y\in I$ for all $x\in I$ and $r\in R$ we have $rx\in I$ and $xr\in I$ but I would like some clarification on this point. Following on, my main question is: is there a corresponding notion of a 'ring filter' which is dual to the notion of a ring ideal in the same way that a filter in a poset is dual to an ideal? Or is there no relation at all except for a coincidence in naming?","The notions of a filter and an ideal on a poset make intuitive sense to me, and I can understand why they are dual: A subset $I\subset P$ of a poset $P$ is an ideal if: for all $x\in I$, $y\leq x$ implies $y\in I$ for all $x,y\in I$ there exists $z\in I$ with $x\leq z$ and $y\leq z$ and a filter is the same thing with all inequalities reversed. I feel like this should correspond to the notion of a ring ideal, where for a ring $R$ we have $I\subset R$ being a ring ideal if: for all $x,y\in I$ we have $x+y\in I$ for all $x\in I$ and $r\in R$ we have $rx\in I$ and $xr\in I$ but I would like some clarification on this point. Following on, my main question is: is there a corresponding notion of a 'ring filter' which is dual to the notion of a ring ideal in the same way that a filter in a poset is dual to an ideal? Or is there no relation at all except for a coincidence in naming?",,"['abstract-algebra', 'ring-theory', 'order-theory']"
39,Is there a trick to prove injectivity for maps out of tensor products?,Is there a trick to prove injectivity for maps out of tensor products?,,"For a ring $R$, an $R$-right-module $M$, an $R$-left-module $N$, and an abelian group $P$, one can use the universal property of the tensor product to construct maps $$ M\otimes_R N\to P. $$ It concrete cases, it is often easy to see that the constructed map is surjective by just writing down pre-images. It seems to be harder to verify that the map is injective, because then one has to consider general sums of elementary tensors in $M\otimes_R N$. Are there any tricks to avoid this, and to achieve injectivity more elegantly? More concretely, an example I have in mind is the following: I have a pre-additive category $C$ with finitely many objects. I consider modules over this category (that is, functors from $C$ to Abelian groups; or, equivalently, modules over the category ring of $C$). Now, I consider the ""free $C$-right-module $Q_Y$ over an object $Y$ in $C$"" which is the hom functor $C(\bullet,Y)$. I want to show that for an arbitrary left-module $M$: $$ Q_Y\otimes_C M\cong M(Y) $$ as abelian groups. Using the module structure of $M$, I can accomplish a natural epimorphism $Q_Y\otimes_C M\to M(Y)$ which should be injective. Currently I think that the formula $$ M(Y)\to Q_Y\otimes_C M;\quad m\mapsto\mathrm{id}_Y\otimes m $$ gives indeed a (two-sided) inverse. Is this correct?","For a ring $R$, an $R$-right-module $M$, an $R$-left-module $N$, and an abelian group $P$, one can use the universal property of the tensor product to construct maps $$ M\otimes_R N\to P. $$ It concrete cases, it is often easy to see that the constructed map is surjective by just writing down pre-images. It seems to be harder to verify that the map is injective, because then one has to consider general sums of elementary tensors in $M\otimes_R N$. Are there any tricks to avoid this, and to achieve injectivity more elegantly? More concretely, an example I have in mind is the following: I have a pre-additive category $C$ with finitely many objects. I consider modules over this category (that is, functors from $C$ to Abelian groups; or, equivalently, modules over the category ring of $C$). Now, I consider the ""free $C$-right-module $Q_Y$ over an object $Y$ in $C$"" which is the hom functor $C(\bullet,Y)$. I want to show that for an arbitrary left-module $M$: $$ Q_Y\otimes_C M\cong M(Y) $$ as abelian groups. Using the module structure of $M$, I can accomplish a natural epimorphism $Q_Y\otimes_C M\to M(Y)$ which should be injective. Currently I think that the formula $$ M(Y)\to Q_Y\otimes_C M;\quad m\mapsto\mathrm{id}_Y\otimes m $$ gives indeed a (two-sided) inverse. Is this correct?",,"['abstract-algebra', 'tensor-products']"
40,Explicit examples of (co)limit arguments in other fields,Explicit examples of (co)limit arguments in other fields,,"Over the past weeks, I have noticed that high level lecture notes in subjects like algebraic geometry, algebra, and algebraic topology often sketch proofs in the following form: Proof sketch for a ""simple"" case e.g Noetherian ring/scheme, CW complex, finitely generated subobject ""Magically"" get the general case by ' the usual (co)limit arguments ' Unless I am mistaken ""(co)limit arguments"" just mean exactness properties of all kinds of functors. The thing is, though, I can hardly think of any specific examples of proofs of relatively basic facts from these exactness properties. So... I'd like to compile a big list of specific examples of proofs in which the general case can be obtained from a simple case along with explicit mention of the (co)limits involved. I know any mathematician will be tempted to say that this method of proof pervades all of mathematics - and I'm sure it does - but I want to explicitly see the functors and (co)limits involved; too often I hear ""this is really the continuity of the functor $F$"" in disguise"" without understanding the details. Update: Let me broaden what I mean by ' the usual (co)limit arguments ' in hopes this will inspire some answers. Apart from exactness, some categories have the property that arrows into certain (co)limits factor through one of the components. For instance, in Grothendieck abelian category, I'm pretty sure a map into a filtered colimit of monos factors through one of them. This can be used to construct functorial injective resolutions. So what are some more interesting cases and applications of ""an arrow   $A\rightarrow \varinjlim _\alpha B_\alpha$ factors through some   $A\rightarrow B_\alpha$"" type results?","Over the past weeks, I have noticed that high level lecture notes in subjects like algebraic geometry, algebra, and algebraic topology often sketch proofs in the following form: Proof sketch for a ""simple"" case e.g Noetherian ring/scheme, CW complex, finitely generated subobject ""Magically"" get the general case by ' the usual (co)limit arguments ' Unless I am mistaken ""(co)limit arguments"" just mean exactness properties of all kinds of functors. The thing is, though, I can hardly think of any specific examples of proofs of relatively basic facts from these exactness properties. So... I'd like to compile a big list of specific examples of proofs in which the general case can be obtained from a simple case along with explicit mention of the (co)limits involved. I know any mathematician will be tempted to say that this method of proof pervades all of mathematics - and I'm sure it does - but I want to explicitly see the functors and (co)limits involved; too often I hear ""this is really the continuity of the functor $F$"" in disguise"" without understanding the details. Update: Let me broaden what I mean by ' the usual (co)limit arguments ' in hopes this will inspire some answers. Apart from exactness, some categories have the property that arrows into certain (co)limits factor through one of the components. For instance, in Grothendieck abelian category, I'm pretty sure a map into a filtered colimit of monos factors through one of them. This can be used to construct functorial injective resolutions. So what are some more interesting cases and applications of ""an arrow   $A\rightarrow \varinjlim _\alpha B_\alpha$ factors through some   $A\rightarrow B_\alpha$"" type results?",,"['abstract-algebra', 'algebraic-geometry', 'algebraic-topology', 'category-theory', 'big-list']"
41,Original Formulation of Hilbert's 14th Problem,Original Formulation of Hilbert's 14th Problem,,"I have a problem seeing how the original formulation of Hilbert's 14th Problem is ""the same"" as the one found on wikipedia . Hopefully someone in here can help me with that. Let me quote Hilbert first: Es sei eine Anzahl $m$ von ganzen rationalen Funktionen $X_1,\dots,X_m$ der $n$ Variablen $x_1,\dots,x_n$ vorgelegt:   \begin{equation}\begin{split}X_1&=f_1(x_1,\dots,x_n)\\&\vdots\\X_m&=f_m(x_1,\dots,x_n).\end{split}\end{equation}   (He calls this system of substitutions (S)). Jede ganze rationale Verbindung von $X_1,\dots,X_m$ wird offenbar durch Eintragung dieser Ausdrücke notwendig stets eine ganze rationale Funktion von $x_1,\dots,x_n$. Es kann jedoch sehr wohl gebrochene rationale Funktionen von $X_1,\dots,X_m$ geben, die nach Ausführung jener Substitution (S) zu ganzen Funktionen in $x_1,\dots,x_n$ werden. Eine jede solche rationale Funktion von $X_1,\dots,X_m$, die nach Ausführung der Substitution (S) ganz in $x_1,\dots,x_n$ wird, möchte ich eine relativganze Funktion von $X_1,\dots,X_m$ nennen. Jede ganze Funktion von $X_1,\dots,X_m$ ist offenbar auch relativganz; ferner ist die Summe, die Differenz und das Produkt relativganzer Funktionen stets wiederum relativganz. Das entstehende Problem ist nun: zu entscheiden, ob es stets möglich ist, ein endliches System von relativganzen Funktionen von $X_1,\dots,X_m$ aufzufinden, durch die sich jede andere relativganze Funktion in ganzer rationaler Weise zusammensetzen läßt. Okay, unfortunately this is in German. Here's what I made out of it, but can't guarantee it is right: Start with $f_1,\dots,f_m\in k[x_1,...,x_n]$ for some field $k$. For every $g\in k[X_1,\dots,X_m]$, $g(f_1,\dots,f_m)$ is then a polynomial in the $x_i$. But there can be $\varphi\in k(X_1,\dots,X_m)$ such that $\varphi(f_1,\dots,f_m)\in k[x_1,\dots,x_n]$, which Hilbert calls ""relativganz"". Every polynomial in the $X_i$ is of course already relativganz, as well as sum, difference, and product of functions which are relativganz. The problem: Is it always possible to find finitely many r-g functions $g_1,\dots,g_s$ in $k(X_1,\dots,X_m)$ such that every r-g function $\varphi$ can be expressed in the $g_i$ in a polynomial way? Now the formulation as it is mentioned on wikipedia: Let $k$ be a field, and $K\subseteq k(x_1,\dots,x_n)$ be a subfield. Is the ring $R=K\cap k[x_1,\dots,x_n]$ finitely generated as a ring? So, as for the original formulation, we can choose $R$ to be the ring of r-g functions. But what is $K$ in this case? I feel like the choice of $f_1,\dots,f_m$ should correspond one-to-one to the choice of the subfield $K$. Is it possible, given the second formulation, to translate this back to the notion of ""relativganz"", i.e., can I always interpret $R$ as a ring of r-g functions? Are they really equivalent? Sorry for the many question in this last paragraph, but I want to really understand how to translate between those two seemingly different formulations :-) Thank you very much in advance!","I have a problem seeing how the original formulation of Hilbert's 14th Problem is ""the same"" as the one found on wikipedia . Hopefully someone in here can help me with that. Let me quote Hilbert first: Es sei eine Anzahl $m$ von ganzen rationalen Funktionen $X_1,\dots,X_m$ der $n$ Variablen $x_1,\dots,x_n$ vorgelegt:   \begin{equation}\begin{split}X_1&=f_1(x_1,\dots,x_n)\\&\vdots\\X_m&=f_m(x_1,\dots,x_n).\end{split}\end{equation}   (He calls this system of substitutions (S)). Jede ganze rationale Verbindung von $X_1,\dots,X_m$ wird offenbar durch Eintragung dieser Ausdrücke notwendig stets eine ganze rationale Funktion von $x_1,\dots,x_n$. Es kann jedoch sehr wohl gebrochene rationale Funktionen von $X_1,\dots,X_m$ geben, die nach Ausführung jener Substitution (S) zu ganzen Funktionen in $x_1,\dots,x_n$ werden. Eine jede solche rationale Funktion von $X_1,\dots,X_m$, die nach Ausführung der Substitution (S) ganz in $x_1,\dots,x_n$ wird, möchte ich eine relativganze Funktion von $X_1,\dots,X_m$ nennen. Jede ganze Funktion von $X_1,\dots,X_m$ ist offenbar auch relativganz; ferner ist die Summe, die Differenz und das Produkt relativganzer Funktionen stets wiederum relativganz. Das entstehende Problem ist nun: zu entscheiden, ob es stets möglich ist, ein endliches System von relativganzen Funktionen von $X_1,\dots,X_m$ aufzufinden, durch die sich jede andere relativganze Funktion in ganzer rationaler Weise zusammensetzen läßt. Okay, unfortunately this is in German. Here's what I made out of it, but can't guarantee it is right: Start with $f_1,\dots,f_m\in k[x_1,...,x_n]$ for some field $k$. For every $g\in k[X_1,\dots,X_m]$, $g(f_1,\dots,f_m)$ is then a polynomial in the $x_i$. But there can be $\varphi\in k(X_1,\dots,X_m)$ such that $\varphi(f_1,\dots,f_m)\in k[x_1,\dots,x_n]$, which Hilbert calls ""relativganz"". Every polynomial in the $X_i$ is of course already relativganz, as well as sum, difference, and product of functions which are relativganz. The problem: Is it always possible to find finitely many r-g functions $g_1,\dots,g_s$ in $k(X_1,\dots,X_m)$ such that every r-g function $\varphi$ can be expressed in the $g_i$ in a polynomial way? Now the formulation as it is mentioned on wikipedia: Let $k$ be a field, and $K\subseteq k(x_1,\dots,x_n)$ be a subfield. Is the ring $R=K\cap k[x_1,\dots,x_n]$ finitely generated as a ring? So, as for the original formulation, we can choose $R$ to be the ring of r-g functions. But what is $K$ in this case? I feel like the choice of $f_1,\dots,f_m$ should correspond one-to-one to the choice of the subfield $K$. Is it possible, given the second formulation, to translate this back to the notion of ""relativganz"", i.e., can I always interpret $R$ as a ring of r-g functions? Are they really equivalent? Sorry for the many question in this last paragraph, but I want to really understand how to translate between those two seemingly different formulations :-) Thank you very much in advance!",,"['abstract-algebra', 'commutative-algebra', 'math-history', 'invariant-theory']"
42,Non-Isomorphic Group Extensions,Non-Isomorphic Group Extensions,,"This is a question from a problem set on group cohomology, a subject I've just begun to learn. Let $B$ be a finite group and $A$ be abelian. I am looking for two groups $G_1$ and $G_2$ such that $G_1$ and $G_2$ are isomorphic as groups but $$1\rightarrow A\rightarrow G_1\rightarrow B\rightarrow 1$$ and $$1\rightarrow A\rightarrow G_2\rightarrow B\rightarrow 1$$ are not isomorphic as extensions. It has been suggested that I use $A=C_3^2$ and $B=C_2$. However, since the orders of $A$ and $B$ are relatively prime in this case, doesn't the Shur-Zassenhaus Lemma guarantee that the sequence splits so that there is only one extension? If this is the case, then how could we produce two non-isomorphic extensions? If someone could point out where I'm confused, I'd be very grateful. Thanks.","This is a question from a problem set on group cohomology, a subject I've just begun to learn. Let $B$ be a finite group and $A$ be abelian. I am looking for two groups $G_1$ and $G_2$ such that $G_1$ and $G_2$ are isomorphic as groups but $$1\rightarrow A\rightarrow G_1\rightarrow B\rightarrow 1$$ and $$1\rightarrow A\rightarrow G_2\rightarrow B\rightarrow 1$$ are not isomorphic as extensions. It has been suggested that I use $A=C_3^2$ and $B=C_2$. However, since the orders of $A$ and $B$ are relatively prime in this case, doesn't the Shur-Zassenhaus Lemma guarantee that the sequence splits so that there is only one extension? If this is the case, then how could we produce two non-isomorphic extensions? If someone could point out where I'm confused, I'd be very grateful. Thanks.",,"['abstract-algebra', 'group-cohomology', 'group-extensions']"
43,Roots of unity in non-Abelian groups: when do they form subgroups?,Roots of unity in non-Abelian groups: when do they form subgroups?,,"I haven't studied group theory in earnest beyond first courses, so my notation may be nonstandard and my question may be a 'standard fact', so bear with me: Consider a group $G$, and for each natural number $n \in \mathbb{N}$ define $$G_n := \{g \in G : g^n = 1\}$$ to be the set of $n^\text{th}$ roots of unity in $G$. If $G$ is Abelian, then each $G_n$ is a subgroup of $G$, but in general this may not be the case: for example, taking  $$G = D_3 = \langle \sigma, \tau : \sigma^2 = \tau^3 = 1, \tau \sigma = \sigma \tau^2 \rangle,$$ we can compute that $$ G_2 = \{1,\sigma,\sigma \tau, \sigma \tau^2\}$$ which is not a subgroup of $D_3$. This leads to the first question, which I've already answered: Are there any non-Abelian groups $G$ such that every $G_n$ is a subgroup of $G$? The smallest such $G$ is the quaternion group, assuming my calculations are correct. So we refine this question: Which non-Abelian groups $G$ are such that every $G_n$ is a subgroup of $G$? I haven't made any calculations for groups larger than the quaternion group, but I thought I'd throw this question out into the open. However, the calculation above for $D_3$ shows that no dihedral groups $D_n$ with $n \geq 3$ satisfy this property, since $$(D_n)_2 = \{1,\sigma,\sigma \tau, \ldots, \sigma \tau^{n-1}\}$$ is not a subgroup of $D_n$. Have at it!","I haven't studied group theory in earnest beyond first courses, so my notation may be nonstandard and my question may be a 'standard fact', so bear with me: Consider a group $G$, and for each natural number $n \in \mathbb{N}$ define $$G_n := \{g \in G : g^n = 1\}$$ to be the set of $n^\text{th}$ roots of unity in $G$. If $G$ is Abelian, then each $G_n$ is a subgroup of $G$, but in general this may not be the case: for example, taking  $$G = D_3 = \langle \sigma, \tau : \sigma^2 = \tau^3 = 1, \tau \sigma = \sigma \tau^2 \rangle,$$ we can compute that $$ G_2 = \{1,\sigma,\sigma \tau, \sigma \tau^2\}$$ which is not a subgroup of $D_3$. This leads to the first question, which I've already answered: Are there any non-Abelian groups $G$ such that every $G_n$ is a subgroup of $G$? The smallest such $G$ is the quaternion group, assuming my calculations are correct. So we refine this question: Which non-Abelian groups $G$ are such that every $G_n$ is a subgroup of $G$? I haven't made any calculations for groups larger than the quaternion group, but I thought I'd throw this question out into the open. However, the calculation above for $D_3$ shows that no dihedral groups $D_n$ with $n \geq 3$ satisfy this property, since $$(D_n)_2 = \{1,\sigma,\sigma \tau, \ldots, \sigma \tau^{n-1}\}$$ is not a subgroup of $D_n$. Have at it!",,['abstract-algebra']
44,Is $S_R$ finitely generated?,Is  finitely generated?,S_R,"Suppose $S_R$ -  is the set of all total recursive bijections on $\mathbb{N}$ . It is not hard to see that this set forms a group with respect to composition, and that $|S_R| = \aleph_0$ . Is $S_R$ finitely generated? The group $S_R$ contains the group $S_\infty$ (the group of finitely based bijections) as its subgroup, which is infinitely generated. However, there exists $S_\infty < H \leq S_R$ , such that $H$ is finitely generated. The $H$ can be described as $\langle (01), f \rangle$ , where $f$ is defined by formula: $$f(x) = \begin{cases} 0 & \quad x = 0 \\ 2 & \quad x = 1 \\ x + 2 & \quad x \geq 2 \text{ and is even} \\ x - 2 & \quad x \geq 2 \text{ and is odd} \end{cases}$$ Indeed, $\forall x = 2n+1$ $(0x)=(01)f^{n}$ and $\forall x = 2n$ $(0x)=(01)f^{-n}$ . Hovever, this does not give us the answer to the question as $H$ is most likely a proper subgroup of $S_R$ (though, i do not know for sure).","Suppose -  is the set of all total recursive bijections on . It is not hard to see that this set forms a group with respect to composition, and that . Is finitely generated? The group contains the group (the group of finitely based bijections) as its subgroup, which is infinitely generated. However, there exists , such that is finitely generated. The can be described as , where is defined by formula: Indeed, and . Hovever, this does not give us the answer to the question as is most likely a proper subgroup of (though, i do not know for sure).","S_R \mathbb{N} |S_R| = \aleph_0 S_R S_R S_\infty S_\infty < H \leq S_R H H \langle (01), f \rangle f f(x) = \begin{cases} 0 & \quad x = 0 \\ 2 & \quad x = 1 \\ x + 2 & \quad x \geq 2 \text{ and is even} \\ x - 2 & \quad x \geq 2 \text{ and is odd} \end{cases} \forall x = 2n+1 (0x)=(01)f^{n} \forall x = 2n (0x)=(01)f^{-n} H S_R","['abstract-algebra', 'group-theory', 'symmetric-groups', 'computability', 'finitely-generated']"
45,"Aside from the obvious stuff, do the partial functions that solve the quadratic equation have any interesting properties?","Aside from the obvious stuff, do the partial functions that solve the quadratic equation have any interesting properties?",,"Let us define partial functions $$f_+,f_- : \mathbb{R} \leftarrow \mathbb{R} \times \mathbb{R} \times \mathbb{R}$$ so as to return the zeros of the quadratic $ax^2+bx+c$ whenever they exist, such that if $a > 0$, then $f_+(a,b,c)$ is the larger of the two roots, and $f_-(a,b,c)$ is the smaller of the two. In particular, we define: $$f_+(a,b,c) = \frac{-b + \sqrt{b^2-4ac}}{2a}, \qquad f_-(a,b,c) = \frac{-b - \sqrt{b^2-4ac}}{2a}$$ So $f_+(a,b,c)$ and $f_-(a,b,c)$ are proper iff $b^2 \geq 4ac$ and $a \neq 0$. For example, $f_+(1,-1,-1)$ is the golden ratio. Question. Apart from the obvious stuff, like $(2af_+(a,b,c)+b)^2 = b^2-4ac$ $(2af_-(a,b,c)+b)^2 = -(b^2-4ac)$ $a(f_+(a,b,c)+f_-(a,b,c))=-b$ whenever both sides of the equation are proper, do $f_+$ and $f_-$ satisfy any other interesting identities and/or relationships to each other and/or to addition and multiplication? For example, can we say anything interesting about $f_+(a+a',b,c)$ or $f_+(aa',b,c)$ or $f_+(f_+(a,b,c),d,e)$, etc? Furthermore, does $\mathbb{R}$ equipped with these partial functions and possibly one or two others form an interesting partial algebraic structure in its own right, and live naturally in a well-behaved category of similar such structures?","Let us define partial functions $$f_+,f_- : \mathbb{R} \leftarrow \mathbb{R} \times \mathbb{R} \times \mathbb{R}$$ so as to return the zeros of the quadratic $ax^2+bx+c$ whenever they exist, such that if $a > 0$, then $f_+(a,b,c)$ is the larger of the two roots, and $f_-(a,b,c)$ is the smaller of the two. In particular, we define: $$f_+(a,b,c) = \frac{-b + \sqrt{b^2-4ac}}{2a}, \qquad f_-(a,b,c) = \frac{-b - \sqrt{b^2-4ac}}{2a}$$ So $f_+(a,b,c)$ and $f_-(a,b,c)$ are proper iff $b^2 \geq 4ac$ and $a \neq 0$. For example, $f_+(1,-1,-1)$ is the golden ratio. Question. Apart from the obvious stuff, like $(2af_+(a,b,c)+b)^2 = b^2-4ac$ $(2af_-(a,b,c)+b)^2 = -(b^2-4ac)$ $a(f_+(a,b,c)+f_-(a,b,c))=-b$ whenever both sides of the equation are proper, do $f_+$ and $f_-$ satisfy any other interesting identities and/or relationships to each other and/or to addition and multiplication? For example, can we say anything interesting about $f_+(a+a',b,c)$ or $f_+(aa',b,c)$ or $f_+(f_+(a,b,c),d,e)$, etc? Furthermore, does $\mathbb{R}$ equipped with these partial functions and possibly one or two others form an interesting partial algebraic structure in its own right, and live naturally in a well-behaved category of similar such structures?",,"['abstract-algebra', 'quadratics', 'universal-algebra']"
46,"Are there ""differential equations"" involving derivations in the sense of abstract algebra?","Are there ""differential equations"" involving derivations in the sense of abstract algebra?",,"There is this abstract notion of a derivation, which really only cares about the property $$D(ab)=aD(b)+D(a)b,$$ where $a,b$ are elements of some algebra. This only tangents the ideas, which lead to $\frac{\text d}{\text d x}$ for functions on the real line. I wonder if there is such a thing as as differential equations in abstract algebra? I guess I can just write down an equation $D(aD(ab))=abaa$ or $D(a)=-ca$ for some algebra and some $D$ and try to figure out if there are actually elements, which satisfy this relation, but I wonder if peolpe are actually doing such things and what their insights turn out to be. Are there investigations of e.g. initially physically motivated equations in terms of this abstract concepts? The only related variant I can think of are equations of Lie-Groups, however, it seems these can be expressed in terms of the usual derivative as well (since they also carry the manifold structure), so it's not really something new.","There is this abstract notion of a derivation, which really only cares about the property $$D(ab)=aD(b)+D(a)b,$$ where $a,b$ are elements of some algebra. This only tangents the ideas, which lead to $\frac{\text d}{\text d x}$ for functions on the real line. I wonder if there is such a thing as as differential equations in abstract algebra? I guess I can just write down an equation $D(aD(ab))=abaa$ or $D(a)=-ca$ for some algebra and some $D$ and try to figure out if there are actually elements, which satisfy this relation, but I wonder if peolpe are actually doing such things and what their insights turn out to be. Are there investigations of e.g. initially physically motivated equations in terms of this abstract concepts? The only related variant I can think of are equations of Lie-Groups, however, it seems these can be expressed in terms of the usual derivative as well (since they also carry the manifold structure), so it's not really something new.",,"['abstract-algebra', 'ordinary-differential-equations', 'derivatives']"
47,Analog to the primitive element theorem for transcendental extensions?,Analog to the primitive element theorem for transcendental extensions?,,"The Primitive Element Theorem states that if $E/F$ is a finite separable field extension, then there exists an element $a$ such that $E=F(a)$. There's a similar result I found, that I don't quite fully understand. For instance, let $F$ be a field and $F[a_1,\dots,a_n]$ be a finite separable extension. Suppose also that $F_u=F(u_1,\dots,u_n)$ is a purely transcendental extension of $F$, with $u_1,\dots,u_n$ algebraically independent over $F$. Why is it true that $F_u[a_1,\dots,a_n]=F_u[u_1a_1+\cdots+u_na_n]$? I get that $u_1a_1+\cdots+u_na_n\in F_u[a_1,\dots,a_n]$, and so $F_u[u_1a_1+\cdots+u_na_n]\subseteq F_u[a_1,\dots,a_n]$. However, why is the converse true? I tried reproducing the argument for the primitive element theorem without success. Thank you. Since the $u_i$ are algebraically independent over $F$, and $F_u[a_1,\dots,a_n]$ is finitely generated over $F_u$, I was trying to use the corollary Bill Cook pointed me to, to conclude that by setting $y_1=\sum_{j=1}^n u_ja_j$, then $F_u[a_1,\dots,a_n]$ is integral over $F_u[y_1]$. From this can I conclude the equality? I wary of how to proceed, as I do not know where separability comes into use.","The Primitive Element Theorem states that if $E/F$ is a finite separable field extension, then there exists an element $a$ such that $E=F(a)$. There's a similar result I found, that I don't quite fully understand. For instance, let $F$ be a field and $F[a_1,\dots,a_n]$ be a finite separable extension. Suppose also that $F_u=F(u_1,\dots,u_n)$ is a purely transcendental extension of $F$, with $u_1,\dots,u_n$ algebraically independent over $F$. Why is it true that $F_u[a_1,\dots,a_n]=F_u[u_1a_1+\cdots+u_na_n]$? I get that $u_1a_1+\cdots+u_na_n\in F_u[a_1,\dots,a_n]$, and so $F_u[u_1a_1+\cdots+u_na_n]\subseteq F_u[a_1,\dots,a_n]$. However, why is the converse true? I tried reproducing the argument for the primitive element theorem without success. Thank you. Since the $u_i$ are algebraically independent over $F$, and $F_u[a_1,\dots,a_n]$ is finitely generated over $F_u$, I was trying to use the corollary Bill Cook pointed me to, to conclude that by setting $y_1=\sum_{j=1}^n u_ja_j$, then $F_u[a_1,\dots,a_n]$ is integral over $F_u[y_1]$. From this can I conclude the equality? I wary of how to proceed, as I do not know where separability comes into use.",,"['abstract-algebra', 'field-theory']"
48,What are all the intermediate fields of $\mathbb{Q}\big(\sqrt{3+\sqrt{5}}\big)$ containing $\mathbb{Q}$?,What are all the intermediate fields of  containing ?,\mathbb{Q}\big(\sqrt{3+\sqrt{5}}\big) \mathbb{Q},"I've come to a fork in the road, and it is sending me on wild goose chases.  This question comes from a final exam for an Intermediate Abstract Algebra course I just took this past Spring. I'm re-working the questions to which there were two problems that require using the Galois correspondence.  The second I have yet to start, because I'm trying to finish the final aspect of the first, and I'm almost finished with this except I'm stuck between one of two ways to proceed (if, indeed, I'm correct regarding my work below). Details & Preliminary Work (Somewhat Rough) :  We are working in $\mathbb{Q}\subset\mathbb{Q}\big(\sqrt{3+\sqrt{5}}\big)\subset\mathbb{R}$. Let $\alpha=\sqrt{3+\sqrt{5}}\in\mathbb{R}$, then the minimal/irreducible polynomial over $\mathbb{Q}$ is $f(x)=x^{4}-6x^{2}+4=\text{irr}(\alpha,\mathbb{Q})\in\mathbb{Q}[x]$. So, $[\mathbb{Q}(\alpha):\mathbb{Q}]=\text{deg}(\alpha,\mathbb{Q})=\text{deg}\big(f(x)\big)=4$. I've previously proved that $\sqrt{3-\sqrt{5}}\in\mathbb{Q}(\alpha)$, so $\mathbb{Q}(\alpha)$ is a splitting field for the separable polynomial $f(x)\in\mathbb{Q}[x]$ (as the roots of $f(x)\in\mathbb{Q}[x]$, mentioned below, are all simple [i.e. the roots are distinct]). Hence, the extension $\mathbb{Q}\subset\mathbb{Q}(\alpha)$ must be a Galois extension. Furthermore, $\sigma\in\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)$ is uniquely determined by its values of $\sigma\big(\sqrt{3+\sqrt{5}}\big)\in\big\{\sqrt{3+\sqrt{5}},-\sqrt{3+\sqrt{5}},\sqrt{3-\sqrt{5}},-\sqrt{3-\sqrt{5}}\big\}$, so the $\big|\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)\big|=4$ since all four possibilities must occur. Label the roots as such: $\alpha=\alpha_{1}=\sqrt{3+\sqrt{5}}=-\alpha_{2}$, and $\alpha_{3}=\sqrt{3-\sqrt{5}}=-\alpha_{4}$. We now define $\sigma,\tau\in\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)$ as followed: $\sigma(\alpha_{1})=\alpha_{2}$ $\sigma(\alpha_{2})=\sigma(-\alpha_{1})=-\alpha_{2}=\alpha_{1}$ $\sigma(\alpha_{3})=\sigma\bigg(\dfrac{\pm 2}{\alpha_{1}}\bigg)=\dfrac{\pm 2}{\alpha_{2}}=\alpha_{4}$; where $\alpha_{1}\alpha_{3}=\pm 2=\sqrt{4}=\alpha_{2}\alpha_{4}$ $\sigma(\alpha_{4})=\alpha_{3}$. And: $\tau(\alpha_{1})=\alpha_{3}$ $\tau(\alpha_{2})=\tau(-\alpha_{1})=-\alpha_{3}=\alpha_{4}$ $\tau(\alpha_{3})=\tau\bigg(\dfrac{\pm 2}{\alpha_{1}}\bigg)=\dfrac{\pm 2}{\alpha_{3}}=\alpha_{1}$ $\tau(\alpha_{4})=\alpha_{2}$. Finally, above gives that: $\sigma\tau(\alpha_{1})=\alpha_{4}$ $\sigma\tau(\alpha_{2})=\alpha_{3}$ $\sigma\tau(\alpha_{3})=\alpha_{2}$ $\sigma\tau(\alpha_{4})=\alpha_{1}$; whereas the $\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)=\big\{e,\sigma,\tau,\sigma\tau\big\}$. My issue resides with the mappings for $\sigma$ and $\tau$ above. The Galois group is isomorphic to a subgroup of $S_{4}$. Also, the Galois group is of order $4$, so it is isomorphic to either the Klein $4$-group, $V_{4}$, or the cyclic group $\mathbb{Z}/4\mathbb{Z}$; however we have the maps above give that the Galois group is isomorphic to $V_{4}$, and $\sigma\mapsto(1,2)(3,4)$, $\tau\mapsto(1,3)(2,4)$, $\sigma\tau\mapsto(1,4)(2,3)$ which are all (even) permutations in $S_{4}$. As $f(x)\in\mathbb{Q}[x]$ is irreducible, the action by the Galois group on the set $\big\{\alpha_{1},\alpha_{2}, \alpha_{3}, \alpha_{4}\big\}$ is a transitive action, and the maps above justify this transitive action. The Klein $4$-group has three, proper subgroups, so the Galois group must also have three, proper subgroups being $\langle\sigma\rangle$, $\langle\tau\rangle$, $\langle\sigma\tau\rangle\subset\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)$. If I am correct above, then the Galois correspondence gives that $\langle\sigma\rangle$ will map to $\mathbb{Q}(\sqrt{5})$, but here is my MAIN problem (again if everything above is correct - especially the automorphisms in the Galois group defined above) - what are the fixed fields that correspond to $\langle\tau\rangle$ and $\langle\sigma\tau\rangle$!? I keep re-working things, and I still can't arrive to even an educated guess, requiring verification, in regards to the fixed fields that $\langle\tau\rangle$ and $\langle\sigma\tau\rangle$ map to by the Galois correspondence. Any help, suggestions, recommendations, hints, tips, etc. will be greatly appreciated. In one attempt, I tried using a basis for $\mathbb{Q}(\alpha)=\mathbb{Q}\big(\sqrt{3+\sqrt{5}}\big)$ as a $\mathbb{Q}$-vector space, and I still can't seem to see what remains fixed - take any $\beta\in\mathbb{Q}(\alpha)$, for $\tau(\beta)$ to remain fixed we must have that $\tau(\beta)=\beta$ whereas $\beta=a_{0}+a_{1}\alpha_{1}+a_{2}\alpha_{1}^{2}+a_{3}\alpha_{1}^{3}$ for some $a_{i}\in\mathbb{Q}$, $i=0,1,2,3$, for example. Moreover, as the $\big|\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)\big|=4$, the only other possibility is that $\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)\cong\mathbb{Z}/4\mathbb{Z}$, and we are done in this case (?). Lastly, I'm very happy to provide additional details, side-work, explanations, etc., on anything that is above if need be.  The test gives this question with several sub-questions, and I'm stumped on the very last part. That being said, I tried to provide somewhat of a sketch on how I arrived to the last part of the question (which is exactly my Question stated in the title). Overall, thank you for your time, and anything provided to set me straight on this is GREATLY APPRECIATED!","I've come to a fork in the road, and it is sending me on wild goose chases.  This question comes from a final exam for an Intermediate Abstract Algebra course I just took this past Spring. I'm re-working the questions to which there were two problems that require using the Galois correspondence.  The second I have yet to start, because I'm trying to finish the final aspect of the first, and I'm almost finished with this except I'm stuck between one of two ways to proceed (if, indeed, I'm correct regarding my work below). Details & Preliminary Work (Somewhat Rough) :  We are working in $\mathbb{Q}\subset\mathbb{Q}\big(\sqrt{3+\sqrt{5}}\big)\subset\mathbb{R}$. Let $\alpha=\sqrt{3+\sqrt{5}}\in\mathbb{R}$, then the minimal/irreducible polynomial over $\mathbb{Q}$ is $f(x)=x^{4}-6x^{2}+4=\text{irr}(\alpha,\mathbb{Q})\in\mathbb{Q}[x]$. So, $[\mathbb{Q}(\alpha):\mathbb{Q}]=\text{deg}(\alpha,\mathbb{Q})=\text{deg}\big(f(x)\big)=4$. I've previously proved that $\sqrt{3-\sqrt{5}}\in\mathbb{Q}(\alpha)$, so $\mathbb{Q}(\alpha)$ is a splitting field for the separable polynomial $f(x)\in\mathbb{Q}[x]$ (as the roots of $f(x)\in\mathbb{Q}[x]$, mentioned below, are all simple [i.e. the roots are distinct]). Hence, the extension $\mathbb{Q}\subset\mathbb{Q}(\alpha)$ must be a Galois extension. Furthermore, $\sigma\in\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)$ is uniquely determined by its values of $\sigma\big(\sqrt{3+\sqrt{5}}\big)\in\big\{\sqrt{3+\sqrt{5}},-\sqrt{3+\sqrt{5}},\sqrt{3-\sqrt{5}},-\sqrt{3-\sqrt{5}}\big\}$, so the $\big|\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)\big|=4$ since all four possibilities must occur. Label the roots as such: $\alpha=\alpha_{1}=\sqrt{3+\sqrt{5}}=-\alpha_{2}$, and $\alpha_{3}=\sqrt{3-\sqrt{5}}=-\alpha_{4}$. We now define $\sigma,\tau\in\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)$ as followed: $\sigma(\alpha_{1})=\alpha_{2}$ $\sigma(\alpha_{2})=\sigma(-\alpha_{1})=-\alpha_{2}=\alpha_{1}$ $\sigma(\alpha_{3})=\sigma\bigg(\dfrac{\pm 2}{\alpha_{1}}\bigg)=\dfrac{\pm 2}{\alpha_{2}}=\alpha_{4}$; where $\alpha_{1}\alpha_{3}=\pm 2=\sqrt{4}=\alpha_{2}\alpha_{4}$ $\sigma(\alpha_{4})=\alpha_{3}$. And: $\tau(\alpha_{1})=\alpha_{3}$ $\tau(\alpha_{2})=\tau(-\alpha_{1})=-\alpha_{3}=\alpha_{4}$ $\tau(\alpha_{3})=\tau\bigg(\dfrac{\pm 2}{\alpha_{1}}\bigg)=\dfrac{\pm 2}{\alpha_{3}}=\alpha_{1}$ $\tau(\alpha_{4})=\alpha_{2}$. Finally, above gives that: $\sigma\tau(\alpha_{1})=\alpha_{4}$ $\sigma\tau(\alpha_{2})=\alpha_{3}$ $\sigma\tau(\alpha_{3})=\alpha_{2}$ $\sigma\tau(\alpha_{4})=\alpha_{1}$; whereas the $\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)=\big\{e,\sigma,\tau,\sigma\tau\big\}$. My issue resides with the mappings for $\sigma$ and $\tau$ above. The Galois group is isomorphic to a subgroup of $S_{4}$. Also, the Galois group is of order $4$, so it is isomorphic to either the Klein $4$-group, $V_{4}$, or the cyclic group $\mathbb{Z}/4\mathbb{Z}$; however we have the maps above give that the Galois group is isomorphic to $V_{4}$, and $\sigma\mapsto(1,2)(3,4)$, $\tau\mapsto(1,3)(2,4)$, $\sigma\tau\mapsto(1,4)(2,3)$ which are all (even) permutations in $S_{4}$. As $f(x)\in\mathbb{Q}[x]$ is irreducible, the action by the Galois group on the set $\big\{\alpha_{1},\alpha_{2}, \alpha_{3}, \alpha_{4}\big\}$ is a transitive action, and the maps above justify this transitive action. The Klein $4$-group has three, proper subgroups, so the Galois group must also have three, proper subgroups being $\langle\sigma\rangle$, $\langle\tau\rangle$, $\langle\sigma\tau\rangle\subset\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)$. If I am correct above, then the Galois correspondence gives that $\langle\sigma\rangle$ will map to $\mathbb{Q}(\sqrt{5})$, but here is my MAIN problem (again if everything above is correct - especially the automorphisms in the Galois group defined above) - what are the fixed fields that correspond to $\langle\tau\rangle$ and $\langle\sigma\tau\rangle$!? I keep re-working things, and I still can't arrive to even an educated guess, requiring verification, in regards to the fixed fields that $\langle\tau\rangle$ and $\langle\sigma\tau\rangle$ map to by the Galois correspondence. Any help, suggestions, recommendations, hints, tips, etc. will be greatly appreciated. In one attempt, I tried using a basis for $\mathbb{Q}(\alpha)=\mathbb{Q}\big(\sqrt{3+\sqrt{5}}\big)$ as a $\mathbb{Q}$-vector space, and I still can't seem to see what remains fixed - take any $\beta\in\mathbb{Q}(\alpha)$, for $\tau(\beta)$ to remain fixed we must have that $\tau(\beta)=\beta$ whereas $\beta=a_{0}+a_{1}\alpha_{1}+a_{2}\alpha_{1}^{2}+a_{3}\alpha_{1}^{3}$ for some $a_{i}\in\mathbb{Q}$, $i=0,1,2,3$, for example. Moreover, as the $\big|\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)\big|=4$, the only other possibility is that $\text{Gal}\big(\mathbb{Q}(\alpha)/\mathbb{Q}\big)\cong\mathbb{Z}/4\mathbb{Z}$, and we are done in this case (?). Lastly, I'm very happy to provide additional details, side-work, explanations, etc., on anything that is above if need be.  The test gives this question with several sub-questions, and I'm stumped on the very last part. That being said, I tried to provide somewhat of a sketch on how I arrived to the last part of the question (which is exactly my Question stated in the title). Overall, thank you for your time, and anything provided to set me straight on this is GREATLY APPRECIATED!",,"['abstract-algebra', 'galois-theory']"
49,Classifying groups of order 60,Classifying groups of order 60,,"I want to solve the following problem from Dummit & Foote's Abstract Algebra text (p. 185, Exercise 14): This exercise classifies the groups of order $60$ (there are thirteen isomorphism types). Let $G$ be a group of order 60, let $P$ be a Sylow 5-subgroup of $G$ and let $Q$ be a Sylow 3-subgroup of $G$. (a) Prove that if $P$ is not normal in $G$ then $G \cong A_5$. [See Section 4.5.] (b) Prove that if $P \trianglelefteq G$ but $Q$ is not normal in $G$ then $G \cong A_4 \times Z_5$. [Show in this case that $P \leq Z(G)$,$G/P \cong A_4$, a Sylow 2-subgroup $T$ of $G$ is normal and $TQ \cong A_4$.] (c) Prove that if both $P$ and $Q$ are normal in $G$ then $G \cong Z_{15} \rtimes T$ where $T \cong Z_4$ or $Z_2 \times Z_2$. Show in this case that there are six isomorphism types when $T$ is cyclic (one abelian) and there are five isomorphism types when $T$ is the Klein 4-group (one abelian). [Use the same ideas as in the classifications of groups of orders 30 and 20.] My attempt: (a) If $n_5(G)>1$ then $G$ is simple by Proposition 21 of Section 4. Proposition 23 of the same section gives $G \cong A_5$. (b) If $P \trianglelefteq G$ but $Q \not \trianglelefteq G$, Sylow's Theorem part (iii) gives $n_3(G) \geq 4$. Let $Q_1,Q_2,Q_3,Q_4$ be four distinct Sylow 3-subgroups. The groups $PQ_i$ are all cyclic and intersect (pairwise) at $P$ (since they have $2$ elements of order $3$). Thus $C_G(P)$ contains at least $15+10+10+10=45$ elements. Lagrange's Theorem gives $|C_G(P)|=60$ and consequently $Z(G) \geq P$. The quotient $G/P$ is of order $12=2^2 \cdot 3$. We know that for groups of order 12 either $n_2=1$ or $n_3=1$. Suppose by way of contradiction that $n_3=1$. As the group $Q_1P/P$ is a Sylow 3-subgroup it is normal. The Fourth Isomorphism Theorem gives that $Q_1P \trianglelefteq G$. However, let $g$ be an element of $G$ conjugating $Q_1$ to $Q_2$ (which exists by Sylow's Theorem part (ii)). We have $gQ_1Pg^{-1}=gQ_1g^{-1}gPg^{-1}=Q_2P \neq Q_1P$. Thus $n_3 \neq 1$ and consequently $n_2=1$. The discussion on pages 182-183 gives $G/P \cong A_4$. The Fourth Isomorphism Theorem applied again gives that a Sylow 2-subgroup of $G$, $T$ is normal. Thus $TQ \leq G$ is a subgroup of order $12$. If $Q \trianglelefteq TQ$ then since $Q$ is normalised by $TQ$ as well as the elements of the central subgroup $P$, we find that $Q \trianglelefteq G$ which is a contradiction. Thus $n_3(TQ) \neq 1$ and consequently $TQ \cong A_4$. Now, since $P \trianglelefteq G$ and $P \cap TQ=1$, we have that $G \cong P \rtimes_\varphi TQ \cong Z_5 \rtimes_\varphi A_4$ for some homomorphism $\varphi$. Since $A_4$ is generated by the 3-cycles, and since $\text{Aut}(Z_5) \cong Z_4$ has no elements of order 3, we find that $\varphi$ is trivial. Hence $G \cong Z_5 \times A_4$ in that case. (c) If $P,Q \trianglelefteq G$, then $PQ \trianglelefteq G$ is a normal subgroup, with complement $T$, a Sylow 2-subgroup of $G$. $PQ$ is a group of order $15$, so it must be isomorphic to $Z_{5} \times Z_3=\langle a \rangle \times \langle b \rangle$, while $T$ has two possible isomorphism types: $Z_4$ and $Z_2 \times Z_2$. The semidirect product criterion gives $G \cong (Z_{5} \times Z_3) \rtimes_\varphi T$ for some homomorphism $\varphi:T \to \text{Aut}(Z_{5} \times Z_3) \cong Z_4 \times Z_2$. We begin with the case where $T =\langle x \rangle \cong Z_4$ is cyclic. $\varphi$ is then determined by $\varphi(x)$ which can have orders $1,2$ or $4$. If $|\varphi(x)|=1$ we get the direct product $Z_{15} \times Z_4$.  If $|\varphi(x)|=2$, since we have 3 elements of order 2 in $\text{Aut}(PQ)$ as listed on page 182. If $\varphi(x)$ sends $a \mapsto a$ and $b \mapsto b^{-1}$ we get the following presentation \begin{equation} G_1=\langle a,b,x| a^5=b^3=x^4=1|bab^{-1}=a,xax^{-1}=a,xbx^{-1}=b^{-1} \rangle \end{equation} which can be factored as $G_1 \cong \langle a \rangle \times \langle b,x \rangle$. Since $\langle b,x \rangle$ is a group of order $12$ which has $n_3=1$, it is isomorphic to the one of example 2 on page 178. This is pretty much where I get stuck... I can get presentations for the other semidirect products, but I can't see which ones are isomorphic to each other. I am aware of the solution here , yet I think it uses too many unnatural lemmas. My questions are: Are my solutions to parts (a) and (b) correct? Can you please help me solve part (c)? Simple solutions are preferred (that is, ones using tools from earlier in the text.) Thank you!","I want to solve the following problem from Dummit & Foote's Abstract Algebra text (p. 185, Exercise 14): This exercise classifies the groups of order $60$ (there are thirteen isomorphism types). Let $G$ be a group of order 60, let $P$ be a Sylow 5-subgroup of $G$ and let $Q$ be a Sylow 3-subgroup of $G$. (a) Prove that if $P$ is not normal in $G$ then $G \cong A_5$. [See Section 4.5.] (b) Prove that if $P \trianglelefteq G$ but $Q$ is not normal in $G$ then $G \cong A_4 \times Z_5$. [Show in this case that $P \leq Z(G)$,$G/P \cong A_4$, a Sylow 2-subgroup $T$ of $G$ is normal and $TQ \cong A_4$.] (c) Prove that if both $P$ and $Q$ are normal in $G$ then $G \cong Z_{15} \rtimes T$ where $T \cong Z_4$ or $Z_2 \times Z_2$. Show in this case that there are six isomorphism types when $T$ is cyclic (one abelian) and there are five isomorphism types when $T$ is the Klein 4-group (one abelian). [Use the same ideas as in the classifications of groups of orders 30 and 20.] My attempt: (a) If $n_5(G)>1$ then $G$ is simple by Proposition 21 of Section 4. Proposition 23 of the same section gives $G \cong A_5$. (b) If $P \trianglelefteq G$ but $Q \not \trianglelefteq G$, Sylow's Theorem part (iii) gives $n_3(G) \geq 4$. Let $Q_1,Q_2,Q_3,Q_4$ be four distinct Sylow 3-subgroups. The groups $PQ_i$ are all cyclic and intersect (pairwise) at $P$ (since they have $2$ elements of order $3$). Thus $C_G(P)$ contains at least $15+10+10+10=45$ elements. Lagrange's Theorem gives $|C_G(P)|=60$ and consequently $Z(G) \geq P$. The quotient $G/P$ is of order $12=2^2 \cdot 3$. We know that for groups of order 12 either $n_2=1$ or $n_3=1$. Suppose by way of contradiction that $n_3=1$. As the group $Q_1P/P$ is a Sylow 3-subgroup it is normal. The Fourth Isomorphism Theorem gives that $Q_1P \trianglelefteq G$. However, let $g$ be an element of $G$ conjugating $Q_1$ to $Q_2$ (which exists by Sylow's Theorem part (ii)). We have $gQ_1Pg^{-1}=gQ_1g^{-1}gPg^{-1}=Q_2P \neq Q_1P$. Thus $n_3 \neq 1$ and consequently $n_2=1$. The discussion on pages 182-183 gives $G/P \cong A_4$. The Fourth Isomorphism Theorem applied again gives that a Sylow 2-subgroup of $G$, $T$ is normal. Thus $TQ \leq G$ is a subgroup of order $12$. If $Q \trianglelefteq TQ$ then since $Q$ is normalised by $TQ$ as well as the elements of the central subgroup $P$, we find that $Q \trianglelefteq G$ which is a contradiction. Thus $n_3(TQ) \neq 1$ and consequently $TQ \cong A_4$. Now, since $P \trianglelefteq G$ and $P \cap TQ=1$, we have that $G \cong P \rtimes_\varphi TQ \cong Z_5 \rtimes_\varphi A_4$ for some homomorphism $\varphi$. Since $A_4$ is generated by the 3-cycles, and since $\text{Aut}(Z_5) \cong Z_4$ has no elements of order 3, we find that $\varphi$ is trivial. Hence $G \cong Z_5 \times A_4$ in that case. (c) If $P,Q \trianglelefteq G$, then $PQ \trianglelefteq G$ is a normal subgroup, with complement $T$, a Sylow 2-subgroup of $G$. $PQ$ is a group of order $15$, so it must be isomorphic to $Z_{5} \times Z_3=\langle a \rangle \times \langle b \rangle$, while $T$ has two possible isomorphism types: $Z_4$ and $Z_2 \times Z_2$. The semidirect product criterion gives $G \cong (Z_{5} \times Z_3) \rtimes_\varphi T$ for some homomorphism $\varphi:T \to \text{Aut}(Z_{5} \times Z_3) \cong Z_4 \times Z_2$. We begin with the case where $T =\langle x \rangle \cong Z_4$ is cyclic. $\varphi$ is then determined by $\varphi(x)$ which can have orders $1,2$ or $4$. If $|\varphi(x)|=1$ we get the direct product $Z_{15} \times Z_4$.  If $|\varphi(x)|=2$, since we have 3 elements of order 2 in $\text{Aut}(PQ)$ as listed on page 182. If $\varphi(x)$ sends $a \mapsto a$ and $b \mapsto b^{-1}$ we get the following presentation \begin{equation} G_1=\langle a,b,x| a^5=b^3=x^4=1|bab^{-1}=a,xax^{-1}=a,xbx^{-1}=b^{-1} \rangle \end{equation} which can be factored as $G_1 \cong \langle a \rangle \times \langle b,x \rangle$. Since $\langle b,x \rangle$ is a group of order $12$ which has $n_3=1$, it is isomorphic to the one of example 2 on page 178. This is pretty much where I get stuck... I can get presentations for the other semidirect products, but I can't see which ones are isomorphic to each other. I am aware of the solution here , yet I think it uses too many unnatural lemmas. My questions are: Are my solutions to parts (a) and (b) correct? Can you please help me solve part (c)? Simple solutions are preferred (that is, ones using tools from earlier in the text.) Thank you!",,"['abstract-algebra', 'group-theory', 'semidirect-product']"
50,Direct combinatorial proof of a sum identity on formal Lagrange polynomials,Direct combinatorial proof of a sum identity on formal Lagrange polynomials,,"Let $k$ be a field and $K=k(x_0,x_1,\ldots, x_n)[x]$.  Define $$\mathcal{L}_k(x)\triangleq \prod_{\substack{j=0\\  j\ne k}}^n\frac{x-x_j}{x_k-x_j}.$$ Is there a purely combinatorial way to show that   $$\sum_{k=0}^n\mathcal{L}_k(x)=1?$$ That is, I would like to consider the $\mathcal{L}_k(x)$ as formal polynomials, not as functions. I am aware of proof by interpolation, but I think there must be an interesting combinatorial proof using counting arguments with the indices. My attempt. To directly add the summands together, we need a common denominator.  Let $R_n=\{0,\ldots, n\}$, $S=\{(i,j)\in R_n\times R_n |j<i\}$, and $S_k=\{(i,j)\in S | i=k\text{ or }j=k\}$. First, note that $$\begin{eqnarray*}\prod_{\substack{j=0\\  j\ne k}}^n\frac{1}{x_k-x_j}&=& \prod_{\substack{j=0\\  j< k}}^n\frac{1}{x_k-x_j}\prod_{\substack{j=0\\  j> k}}^n\frac{1}{-(x_j-x_k)}\\&=&\prod_{j=0}^{k-1}\frac{1}{x_k-x_j}\prod_{j=k+1}^n\frac{1}{-(x_j-x_k)}\\ &=&(-1)^{n-k}\prod_{(i,j)\in S_k}\frac{1}{x_i-x_j} \end{eqnarray*}$$ To get a common denominator, we therfore multiply each term by $$\frac{\prod_{(i,j)\in S\setminus S_k}x_i-x_j}{\prod_{(i,j)\in S\setminus S_k}x_i-x_j}$$ to obtain $$\prod_{j<i}\frac{1}{x_i-x_j}\sum_{k=0}^n\left((-1)^{n-k}\prod_{\substack{j=0\\ j\ne k}}^n(x-x_j)\prod_{(i,j)\in S\setminus S_k}(x_i-x_j)\right)$$ ...and here is where I can't get stuck, can't think of a how to continue.","Let $k$ be a field and $K=k(x_0,x_1,\ldots, x_n)[x]$.  Define $$\mathcal{L}_k(x)\triangleq \prod_{\substack{j=0\\  j\ne k}}^n\frac{x-x_j}{x_k-x_j}.$$ Is there a purely combinatorial way to show that   $$\sum_{k=0}^n\mathcal{L}_k(x)=1?$$ That is, I would like to consider the $\mathcal{L}_k(x)$ as formal polynomials, not as functions. I am aware of proof by interpolation, but I think there must be an interesting combinatorial proof using counting arguments with the indices. My attempt. To directly add the summands together, we need a common denominator.  Let $R_n=\{0,\ldots, n\}$, $S=\{(i,j)\in R_n\times R_n |j<i\}$, and $S_k=\{(i,j)\in S | i=k\text{ or }j=k\}$. First, note that $$\begin{eqnarray*}\prod_{\substack{j=0\\  j\ne k}}^n\frac{1}{x_k-x_j}&=& \prod_{\substack{j=0\\  j< k}}^n\frac{1}{x_k-x_j}\prod_{\substack{j=0\\  j> k}}^n\frac{1}{-(x_j-x_k)}\\&=&\prod_{j=0}^{k-1}\frac{1}{x_k-x_j}\prod_{j=k+1}^n\frac{1}{-(x_j-x_k)}\\ &=&(-1)^{n-k}\prod_{(i,j)\in S_k}\frac{1}{x_i-x_j} \end{eqnarray*}$$ To get a common denominator, we therfore multiply each term by $$\frac{\prod_{(i,j)\in S\setminus S_k}x_i-x_j}{\prod_{(i,j)\in S\setminus S_k}x_i-x_j}$$ to obtain $$\prod_{j<i}\frac{1}{x_i-x_j}\sum_{k=0}^n\left((-1)^{n-k}\prod_{\substack{j=0\\ j\ne k}}^n(x-x_j)\prod_{(i,j)\in S\setminus S_k}(x_i-x_j)\right)$$ ...and here is where I can't get stuck, can't think of a how to continue.",,"['abstract-algebra', 'combinatorics', 'polynomials', 'alternative-proof']"
51,Generalizing the natural numbers - has this been studied before?,Generalizing the natural numbers - has this been studied before?,,"The ordinals numbers generalize the natural numbers and satisfy a generalized induction principle. However, the algebraic properties of the ordinal numbers aren't so good. For example, ordinal sums are neither commutative, nor left-cancellative. It was pointed out in the comments that these deficiencies can be remedied by working with the Hessenberg sum of ordinals. However, this introduces a new problem, which is that despite the fact that $1 \leq \omega$, nonetheless the equation $1 \boxplus x = \omega$ has no ordinal-valued solution (intuitively, it would have be $x = \omega - 1$). Here I am using $\boxplus$ to denote the Hessenberg sum. So, I was trying to generalize the natural numbers in a different way, sacrificing proof by induction but preserving all those nice algebraic properties. I came up with the following idea, but haven't seen it anywhere. Has the following idea been studied? In what follows, lets take $\mathbb{N}$ to start at $1$. So $$\mathbb{N} = \{1,2,3,\cdots\}.$$ Also, let $\mathbb{M}$ denote the positive rational numbers, with the convention $0 \notin \mathbb{M}.$ Then $\mathbb{N}$ embeds naturally into $\mathbb{Z}$ and $\mathbb{M},$ each of which embed naturally into $\mathbb{Q}$. We will try to recreate this system of embeddings. Note that what follows is highly speculative, and there may be severe mistakes. Let $\mathbb{N}'$ denote the set of all (non-zero) univariate integer polynomials with positive leading coefficient, ordered lexicographically. Then $\mathbb{N}'$ is closed under addition and multiplication, and these operations are commutative and associative on $\mathbb{N}'.$ We also have distributivity of multiplication over addition. Furthermore, for all $a,b \in \mathbb{N}',$ I believe the following hold. If $a < b,$ then for all $x \in \mathbb{N}'$ we have $x+a < x+b$ and $xa < xb.$ The following are equivalent. In particular, i implies ii and ii implies iii. i. There exists $x$ satisfying $x+a=b$. ii. $a < b$ iii. There exists unique $x$ satisfying $x+a=b$. For all $x \in \mathbb{N}'$ we have the following. If $x+a=x+b$, then $a=b.$ If $xa=xb$, then $a=b.$ Now let $\mathbb{Z}'$ denote the set of all univariate integer polynomials, ordered lexicographically. Thus $\mathbb{N}' = \{x \in \mathbb{Z}' \mid x > 0\}.$ Also, $\mathbb{Z}'$ is an integral domain. Furthermore, for all $a,b \in \mathbb{Z}',$ I believe the following hold. If $a < b,$ then for all $x \in \mathbb{Z}'$ we have $x+a < x+b.$ If $a < b,$ then for all $x \in \mathbb{N}'$ we have $xa < xb.$ There exists $x \in \mathbb{Z}'$ satisfying $x+a = 0.$ For all non-zero $x \in \mathbb{Z}'$ such that $xa=xb$, we have $a=b.$ Now recall that $\mathbb{M}$ is our notation for the positive rational numbers. By analogy, let $\mathbb{M}'$ denote the set of all equivalence classes of ordered pairs $(a,b) \in \mathbb{N}'$ with equivalence defined such that $$(a,b) \sim (a',b') \;\Leftrightarrow \; ab' = a'b.$$ Most likely, the set $\mathbb{M}'$ can be equipped with addition, multiplication in the usual way. Furthermore, define $$[(a,b)] < [(a',b')] \Leftrightarrow ab' < a'b.$$ I'm guessing that this is well-defined, and that the order relation interacts nicely with addition and multiplication. Finally, we can construct an ordered field $\mathbb{Q}'$ in at least two different ways. One way is to replace $\mathbb{N}'$ with $\mathbb{Z}'$ above. The order relation also needs to be defined in a more complicated way; presumably, the following definition will do the trick. $$[(a,b)] < [(a',b')] \Leftrightarrow (bb' > 0 \wedge ab' < a'b) \vee (bb' < 0 \wedge a'b < ab').$$ This is basically just the definition I got off Wikipedia's section on the formal construction of the rational numbers . Another, most likely simpler approach would be to define $\mathbb{Q}'$ by gluing together two copies of $\mathbb{M}'$ with an element $0$ wedged between them. Presumably, both approaches to constructing $\mathbb{Q}'$ give us the same result, and this would be our first major theorem. Finally, I'm guessing that we get the usual system of embeddings. So $\mathbb{N}'$ embeds naturally into $\mathbb{Z}'$ and $\mathbb{M}',$ and both these structures embed naturally into $\mathbb{Q}'.$ Indeed, its probably safe to view these embeddings as inclusions.","The ordinals numbers generalize the natural numbers and satisfy a generalized induction principle. However, the algebraic properties of the ordinal numbers aren't so good. For example, ordinal sums are neither commutative, nor left-cancellative. It was pointed out in the comments that these deficiencies can be remedied by working with the Hessenberg sum of ordinals. However, this introduces a new problem, which is that despite the fact that $1 \leq \omega$, nonetheless the equation $1 \boxplus x = \omega$ has no ordinal-valued solution (intuitively, it would have be $x = \omega - 1$). Here I am using $\boxplus$ to denote the Hessenberg sum. So, I was trying to generalize the natural numbers in a different way, sacrificing proof by induction but preserving all those nice algebraic properties. I came up with the following idea, but haven't seen it anywhere. Has the following idea been studied? In what follows, lets take $\mathbb{N}$ to start at $1$. So $$\mathbb{N} = \{1,2,3,\cdots\}.$$ Also, let $\mathbb{M}$ denote the positive rational numbers, with the convention $0 \notin \mathbb{M}.$ Then $\mathbb{N}$ embeds naturally into $\mathbb{Z}$ and $\mathbb{M},$ each of which embed naturally into $\mathbb{Q}$. We will try to recreate this system of embeddings. Note that what follows is highly speculative, and there may be severe mistakes. Let $\mathbb{N}'$ denote the set of all (non-zero) univariate integer polynomials with positive leading coefficient, ordered lexicographically. Then $\mathbb{N}'$ is closed under addition and multiplication, and these operations are commutative and associative on $\mathbb{N}'.$ We also have distributivity of multiplication over addition. Furthermore, for all $a,b \in \mathbb{N}',$ I believe the following hold. If $a < b,$ then for all $x \in \mathbb{N}'$ we have $x+a < x+b$ and $xa < xb.$ The following are equivalent. In particular, i implies ii and ii implies iii. i. There exists $x$ satisfying $x+a=b$. ii. $a < b$ iii. There exists unique $x$ satisfying $x+a=b$. For all $x \in \mathbb{N}'$ we have the following. If $x+a=x+b$, then $a=b.$ If $xa=xb$, then $a=b.$ Now let $\mathbb{Z}'$ denote the set of all univariate integer polynomials, ordered lexicographically. Thus $\mathbb{N}' = \{x \in \mathbb{Z}' \mid x > 0\}.$ Also, $\mathbb{Z}'$ is an integral domain. Furthermore, for all $a,b \in \mathbb{Z}',$ I believe the following hold. If $a < b,$ then for all $x \in \mathbb{Z}'$ we have $x+a < x+b.$ If $a < b,$ then for all $x \in \mathbb{N}'$ we have $xa < xb.$ There exists $x \in \mathbb{Z}'$ satisfying $x+a = 0.$ For all non-zero $x \in \mathbb{Z}'$ such that $xa=xb$, we have $a=b.$ Now recall that $\mathbb{M}$ is our notation for the positive rational numbers. By analogy, let $\mathbb{M}'$ denote the set of all equivalence classes of ordered pairs $(a,b) \in \mathbb{N}'$ with equivalence defined such that $$(a,b) \sim (a',b') \;\Leftrightarrow \; ab' = a'b.$$ Most likely, the set $\mathbb{M}'$ can be equipped with addition, multiplication in the usual way. Furthermore, define $$[(a,b)] < [(a',b')] \Leftrightarrow ab' < a'b.$$ I'm guessing that this is well-defined, and that the order relation interacts nicely with addition and multiplication. Finally, we can construct an ordered field $\mathbb{Q}'$ in at least two different ways. One way is to replace $\mathbb{N}'$ with $\mathbb{Z}'$ above. The order relation also needs to be defined in a more complicated way; presumably, the following definition will do the trick. $$[(a,b)] < [(a',b')] \Leftrightarrow (bb' > 0 \wedge ab' < a'b) \vee (bb' < 0 \wedge a'b < ab').$$ This is basically just the definition I got off Wikipedia's section on the formal construction of the rational numbers . Another, most likely simpler approach would be to define $\mathbb{Q}'$ by gluing together two copies of $\mathbb{M}'$ with an element $0$ wedged between them. Presumably, both approaches to constructing $\mathbb{Q}'$ give us the same result, and this would be our first major theorem. Finally, I'm guessing that we get the usual system of embeddings. So $\mathbb{N}'$ embeds naturally into $\mathbb{Z}'$ and $\mathbb{M}',$ and both these structures embed naturally into $\mathbb{Q}'.$ Indeed, its probably safe to view these embeddings as inclusions.",,"['abstract-algebra', 'reference-request', 'ring-theory']"
52,clarification on the definition of meaningful product,clarification on the definition of meaningful product,,"I am studying Hungerford's book ""Algebra"". In the page 27 he defines the meaningful product as follows. Given any sequence of elements of a semigroup $G, > \{a_{1},a_{2},\dots\}$ define inductively a meaningful product (in   this order) as follows. If $n=1$, then the only meaningful product is   $a_{1}$. If $n>1$, then a meaningful product is defined to be any   product of the form $(a_{1}\cdots a_{m})(a_{m+1}\cdots a_{n})$ where   $m< n$ and $(a_{1}\cdots a_{m})$ and $(a_{m+1}\cdots a_{n})$ are   meaningful products of $m$ and $n-m$ elements respectively. He notes next the following: To show that this definition is in the fact well defined requires a   stronger version of Recursion Theorem 6.2 of the Introduction; see   C.W. Burril: Foundations of Real Numbers. I don't have access to this book, so I would like to know this version and see how to use it, or a reference if possible. I've never seen this definition before. Is it really necessary to define a meaningful product in order to prove that Generalized Associative law holds on a semigroup? Thanks for your help.","I am studying Hungerford's book ""Algebra"". In the page 27 he defines the meaningful product as follows. Given any sequence of elements of a semigroup $G, > \{a_{1},a_{2},\dots\}$ define inductively a meaningful product (in   this order) as follows. If $n=1$, then the only meaningful product is   $a_{1}$. If $n>1$, then a meaningful product is defined to be any   product of the form $(a_{1}\cdots a_{m})(a_{m+1}\cdots a_{n})$ where   $m< n$ and $(a_{1}\cdots a_{m})$ and $(a_{m+1}\cdots a_{n})$ are   meaningful products of $m$ and $n-m$ elements respectively. He notes next the following: To show that this definition is in the fact well defined requires a   stronger version of Recursion Theorem 6.2 of the Introduction; see   C.W. Burril: Foundations of Real Numbers. I don't have access to this book, so I would like to know this version and see how to use it, or a reference if possible. I've never seen this definition before. Is it really necessary to define a meaningful product in order to prove that Generalized Associative law holds on a semigroup? Thanks for your help.",,"['abstract-algebra', 'group-theory']"
53,Non-surjective but injective real polynomial functions $\mathbb{R}^n\to \mathbb{R}^n$,Non-surjective but injective real polynomial functions,\mathbb{R}^n\to \mathbb{R}^n,"Over algebraically closed fields $K$, the Ax–Grothendieck theorem (see also this thread ) states that injective polynomial functions $K^n \to K^n$ in $n$ variables are surjective. Is there a simple counterexample for this statement for real polynomial functions i.e. $K=\mathbb{R}$?","Over algebraically closed fields $K$, the Ax–Grothendieck theorem (see also this thread ) states that injective polynomial functions $K^n \to K^n$ in $n$ variables are surjective. Is there a simple counterexample for this statement for real polynomial functions i.e. $K=\mathbb{R}$?",,"['abstract-algebra', 'algebraic-geometry', 'polynomials']"
54,Finitely generated group has only finitely many subgroups of given index,Finitely generated group has only finitely many subgroups of given index,,"In my previous question i have got a comment that : If a group is finitely generated, then there are finitely many subgroups of a given finite index. I do not yet see the beauty of this problem but, i wanted to prove this atleast. So,what i have tried is : I fix $n\in \mathbb{N}$ and assume $H\leq G$ with $|G/H|=n$ As we have $H\leq G$ of finite index, we have the action of $G$ on left cosets of $H$ and we get $\eta: G\rightarrow S_n$ I assume $\{g_1,g_2,\dots, g_r\}$ generate $G$ what i am thinking is once $H$ is fixed, the homomorphism is fixed $\eta$ (after all it is left multiplication of cosets of H). (otherway may not be true.. i dont see it immediately) and any homomorphism of $G$ is fixed by all these $g_i :1\leq i\leq r$ each $g_i$ have $n!$ possibilities as its image. So all $g_i : 1\leq i\leq r$ would have $n!n!\dots n!$ repeating $r$ times i.e., $(n!)^r$ times.. and as these homomorphism (i am not sure but somethings may not correspond to H) are finite. Thus , I see that No.of $H$ should be atmost $(n!)^r$ (after excludind some useless cases) So, I would like to say that If a group is finitely generated, then there are finitely many subgroups of a given finite index. I am very much sure that there are some gaps which i am unable to see.. please help e to fill this in detail (if this way is partially true)by giving some hints or please suggest me another approach (if this is a blunder). Thank you","In my previous question i have got a comment that : If a group is finitely generated, then there are finitely many subgroups of a given finite index. I do not yet see the beauty of this problem but, i wanted to prove this atleast. So,what i have tried is : I fix $n\in \mathbb{N}$ and assume $H\leq G$ with $|G/H|=n$ As we have $H\leq G$ of finite index, we have the action of $G$ on left cosets of $H$ and we get $\eta: G\rightarrow S_n$ I assume $\{g_1,g_2,\dots, g_r\}$ generate $G$ what i am thinking is once $H$ is fixed, the homomorphism is fixed $\eta$ (after all it is left multiplication of cosets of H). (otherway may not be true.. i dont see it immediately) and any homomorphism of $G$ is fixed by all these $g_i :1\leq i\leq r$ each $g_i$ have $n!$ possibilities as its image. So all $g_i : 1\leq i\leq r$ would have $n!n!\dots n!$ repeating $r$ times i.e., $(n!)^r$ times.. and as these homomorphism (i am not sure but somethings may not correspond to H) are finite. Thus , I see that No.of $H$ should be atmost $(n!)^r$ (after excludind some useless cases) So, I would like to say that If a group is finitely generated, then there are finitely many subgroups of a given finite index. I am very much sure that there are some gaps which i am unable to see.. please help e to fill this in detail (if this way is partially true)by giving some hints or please suggest me another approach (if this is a blunder). Thank you",,['abstract-algebra']
55,when are graded injective modules graded and injective?,when are graded injective modules graded and injective?,,"Define a graded injective module over a graded ring $R$ to be an injective object in $GrMod-R$ (the category of right graded $R$ -modules). From the little research I have done, a graded injective module is not necessarily injective. However, if it is graded and injective then it is graded injective. Question Under what conditions on $R$ , the graded injective modules are exactly the modules that are graded and injective? I know that the latter always holds for graded projectives. Probably my question holds for Artin rings, or perhaps fd algebras (?), but I can't find a reference in the literature ,nor I can prove it...","Define a graded injective module over a graded ring to be an injective object in (the category of right graded -modules). From the little research I have done, a graded injective module is not necessarily injective. However, if it is graded and injective then it is graded injective. Question Under what conditions on , the graded injective modules are exactly the modules that are graded and injective? I know that the latter always holds for graded projectives. Probably my question holds for Artin rings, or perhaps fd algebras (?), but I can't find a reference in the literature ,nor I can prove it...",R GrMod-R R R,"['abstract-algebra', 'homological-algebra', 'noncommutative-algebra', 'injective-module', 'graded-modules']"
56,Is there an elementary way to prove that the algebraic integers are a Bézout domain?,Is there an elementary way to prove that the algebraic integers are a Bézout domain?,,"Well, the title of my question says all, but let me give some context. Right now I'm writing some lecture notes on ring theory with a little of commutative algebra. I wrote a few results about integral extensions and that led me to define the algebraic integers $\overline{\Bbb Z}$ as the integral closure of the extension $\Bbb Z\subseteq \Bbb C$. Since I included a topic on factorization in integral domains where I defined what is a Bézout domain, it seems very natural to me to show that $\overline{\Bbb Z}$ is an example of a Bézout domain. However,  and here comes my problem, I haven't found an elementary proof of the above fact. The only reference that I have is a theorem in Kaplansky's book ""Commutative rings"". I checked the proof given in that book, but I can't understand it very well, moreover Kaplansky uses terminology from Algebraic Number Theory as ""class group"" and certainly I can't use any of that in my notes because they are aimed to cover a basic/intermediate course of ring theory. In summary, is there a ring-theoretic way to prove that the ring of algebraic integers is a Bézout domain? P.S. I'm aware of this post and the only answer uses Algebraic Number Theory, which as I said, I can't use.","Well, the title of my question says all, but let me give some context. Right now I'm writing some lecture notes on ring theory with a little of commutative algebra. I wrote a few results about integral extensions and that led me to define the algebraic integers $\overline{\Bbb Z}$ as the integral closure of the extension $\Bbb Z\subseteq \Bbb C$. Since I included a topic on factorization in integral domains where I defined what is a Bézout domain, it seems very natural to me to show that $\overline{\Bbb Z}$ is an example of a Bézout domain. However,  and here comes my problem, I haven't found an elementary proof of the above fact. The only reference that I have is a theorem in Kaplansky's book ""Commutative rings"". I checked the proof given in that book, but I can't understand it very well, moreover Kaplansky uses terminology from Algebraic Number Theory as ""class group"" and certainly I can't use any of that in my notes because they are aimed to cover a basic/intermediate course of ring theory. In summary, is there a ring-theoretic way to prove that the ring of algebraic integers is a Bézout domain? P.S. I'm aware of this post and the only answer uses Algebraic Number Theory, which as I said, I can't use.",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'alternative-proof']"
57,Diophantine equation: $13^x+3=y^2$,Diophantine equation:,13^x+3=y^2,"$x,y$ are positive integers. $$13^x+3=y^2\iff \left(4+\sqrt{3}\right)^x\left(4-\sqrt{3}\right)^x=\left(y+\sqrt3\right)\left(y-\sqrt3\right)$$ $\gcd\left(y+\sqrt3, y-\sqrt3\right)=1$, therefore $y+\sqrt3=\left(4+\sqrt{3}\right)^x$ (implies $x=1$), since $\Bbb Z\left[\sqrt{3}\right]$ is a UFD and $4+\sqrt{3}$ is prime (since $4^2-3=13$ is prime) and $y-\sqrt{3}$ has negative $\sqrt3$ part. My question: why can't RHS have units, e.g. $y+\sqrt3=\left(2+\sqrt3\right)\left(4+\sqrt{3}\right)^x$. (then $y-\sqrt3=\left(2-\sqrt3\right)\left(4-\sqrt{3}\right)^x$) Solution found in Introduction to Diophatine Equations by Andreescu Titu (page $315$).","$x,y$ are positive integers. $$13^x+3=y^2\iff \left(4+\sqrt{3}\right)^x\left(4-\sqrt{3}\right)^x=\left(y+\sqrt3\right)\left(y-\sqrt3\right)$$ $\gcd\left(y+\sqrt3, y-\sqrt3\right)=1$, therefore $y+\sqrt3=\left(4+\sqrt{3}\right)^x$ (implies $x=1$), since $\Bbb Z\left[\sqrt{3}\right]$ is a UFD and $4+\sqrt{3}$ is prime (since $4^2-3=13$ is prime) and $y-\sqrt{3}$ has negative $\sqrt3$ part. My question: why can't RHS have units, e.g. $y+\sqrt3=\left(2+\sqrt3\right)\left(4+\sqrt{3}\right)^x$. (then $y-\sqrt3=\left(2-\sqrt3\right)\left(4-\sqrt{3}\right)^x$) Solution found in Introduction to Diophatine Equations by Andreescu Titu (page $315$).",,"['abstract-algebra', 'number-theory', 'diophantine-equations', 'unique-factorization-domains']"
58,"On the group of all complex roots of unity whose orders are powers of $p$, prime number [closed]","On the group of all complex roots of unity whose orders are powers of , prime number [closed]",p,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question $A=\{z\in\mathbb{C}: z^{p^n}=1\;\mathrm{for\;some\;integer}\;n\geq1\}$. I have to prove: 1) Every proper subgroup of $A$ is cyclic, 2) if $B,C$ are subgroups of $A$ then $B\subseteq C$ or $C\subseteq B$, 3) for every $n\geq0$ there exists an unique subgroup of $A$ with $p^n$ elements. Could you help me please?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question $A=\{z\in\mathbb{C}: z^{p^n}=1\;\mathrm{for\;some\;integer}\;n\geq1\}$. I have to prove: 1) Every proper subgroup of $A$ is cyclic, 2) if $B,C$ are subgroups of $A$ then $B\subseteq C$ or $C\subseteq B$, 3) for every $n\geq0$ there exists an unique subgroup of $A$ with $p^n$ elements. Could you help me please?",,['group-theory']
59,Is there difference between finitely presented groups and finitely generated groups?,Is there difference between finitely presented groups and finitely generated groups?,,A group is said to be finitely generated if it can be generated by a finite set of generators. Question : Is there difference between finitely presented groups and finitely generated groups?,A group is said to be finitely generated if it can be generated by a finite set of generators. Question : Is there difference between finitely presented groups and finitely generated groups?,,['group-theory']
60,Example of a Ring that has nothing to do with numbers,Example of a Ring that has nothing to do with numbers,,"What is an example of a ring that has nothing to do with numbers? For example, for groups, we have dihedral groups, quaternions, etc. I'm missing the analogue of the characteristic of a ring, when the ring is not related to numbers (complex, real, integers,...). Part of why I want this example is because I want to see if the characteristic of a ring must be an element of the ring itself.","What is an example of a ring that has nothing to do with numbers? For example, for groups, we have dihedral groups, quaternions, etc. I'm missing the analogue of the characteristic of a ring, when the ring is not related to numbers (complex, real, integers,...). Part of why I want this example is because I want to see if the characteristic of a ring must be an element of the ring itself.",,"['abstract-algebra', 'ring-theory']"
61,"If $a^3 b = ba^3$ and if $ a $ has order 7, show that $ab = ba$","If  and if  has order 7, show that",a^3 b = ba^3  a  ab = ba,"In a lecture my professor quickly went over the problem: Let $ a $ and $ b $ be elements of a group G. If $ a^3 b = ba^3 $ and if a has order 7, show that $ ab = ba $ . The sketch of a proof he wrote out went like this (this is what I have in my notes) Does $ (a^3)^2 = a^6 $ commute with $ b $ ? Well, $ a^6 = a^{-1} $ because $ a^7 = e $ So $ a^{-1}b = b a^{-1} $ so $ b = aba^{-1} $ so $ ba = ab $ I don't completely follow. It seems like this should be basic, but it isn't for me. By writing out $ (a^3)^2 $ it seem to imply that he could substitute $ (a^3)^2 $ for $ a^3 $ and put it into the original equation. That doesn't make sense to me because I figured $ a^3 $ is a distinct element, not a variable. I am not sure how he is synthesizing the premises with $ a^6 = a^{-1} $ to find $ a^{-1}b = b a^{-1} $ . I am hoping for some help with that.","In a lecture my professor quickly went over the problem: Let and be elements of a group G. If and if a has order 7, show that . The sketch of a proof he wrote out went like this (this is what I have in my notes) Does commute with ? Well, because So so so I don't completely follow. It seems like this should be basic, but it isn't for me. By writing out it seem to imply that he could substitute for and put it into the original equation. That doesn't make sense to me because I figured is a distinct element, not a variable. I am not sure how he is synthesizing the premises with to find . I am hoping for some help with that.", a   b   a^3 b = ba^3   ab = ba   (a^3)^2 = a^6   b   a^6 = a^{-1}   a^7 = e   a^{-1}b = b a^{-1}   b = aba^{-1}   ba = ab   (a^3)^2   (a^3)^2   a^3   a^3   a^6 = a^{-1}   a^{-1}b = b a^{-1} ,"['abstract-algebra', 'group-theory']"
62,If $R$ and $S$ are rings then $R \times S$ is never a field (or domain),If  and  are rings then  is never a field (or domain),R S R \times S,"This question is from the book ""Abstract Algebra"" by Dummit and Foote.(Exercise: 7.6.4): Problem: Prove that if $R$ and $S$ are any two non-zero rings then $R \times S$ is never a field. My problem with this question is that it doesn't feel right. If $R$ and $S$ are rings then $R \times S$ is also so. (The addition and multiplication on $R \times S$ is defined as $(r_1,s_1)+(r_2,s_2)=(r_1+r_2,s_1+s_2)$ and $(r_1,s_1)(r_2,s_2)=(r_1r_2,s_1s_2)$ respectively where $(r_1,s_1),(r_2,s_2) \in R \times S$.) So proving that $R \times S$ is a field reduces to proving commutativity of multiplication, existence of multiplicative indentity and existence of multiplicative inverse for each element of it. Now, if the two rings are fields themselves then multiplication is commutative, the identy is $(1_R,1_S)$ and inverse of an element $(r,s)$ is $(r^{-1},s^{-1})$. So $R \times S$ is also a field. Am I right? Please help. Update: The question comes from a section about the Chinese Remainder Theorem. Is it possible to prove this fact using Chinese Remainder Theorem?","This question is from the book ""Abstract Algebra"" by Dummit and Foote.(Exercise: 7.6.4): Problem: Prove that if $R$ and $S$ are any two non-zero rings then $R \times S$ is never a field. My problem with this question is that it doesn't feel right. If $R$ and $S$ are rings then $R \times S$ is also so. (The addition and multiplication on $R \times S$ is defined as $(r_1,s_1)+(r_2,s_2)=(r_1+r_2,s_1+s_2)$ and $(r_1,s_1)(r_2,s_2)=(r_1r_2,s_1s_2)$ respectively where $(r_1,s_1),(r_2,s_2) \in R \times S$.) So proving that $R \times S$ is a field reduces to proving commutativity of multiplication, existence of multiplicative indentity and existence of multiplicative inverse for each element of it. Now, if the two rings are fields themselves then multiplication is commutative, the identy is $(1_R,1_S)$ and inverse of an element $(r,s)$ is $(r^{-1},s^{-1})$. So $R \times S$ is also a field. Am I right? Please help. Update: The question comes from a section about the Chinese Remainder Theorem. Is it possible to prove this fact using Chinese Remainder Theorem?",,"['abstract-algebra', 'ring-theory']"
63,Why doesn't this proof show that the operation on a factor group is well-defined?,Why doesn't this proof show that the operation on a factor group is well-defined?,,"Suppose $G$ is a group and let $H \triangleleft G$ . Consider the factor group $G/H$ where the relation is $aHbH = abH$ for all $a,b \in G$ . Suppose we wanted to show that the above relation is well-defined. Then we would pick some elements $a,b,c,d \in G$ such that $aH = cH$ and $bH = dH$ . I then would have to show that $aHbH = cHdH$ , which is the same as showing that $abH = cdH$ . Question . Couldn't we begin with the left hand side of the equation $aHbH = cHdH$ and substitute $cH$ for $aH$ and $dH$ for $bH$ ? This would result in $$aHbH = (cH)(dH) = cHdH$$ The proof in the book doesn't proceed in this way, and although I understand the author's proof, I don't understand why the above method wouldn't work. I have looked at other questions regarding this, but my question is addressing why we can't substitute our assumed equations $aH=cH$ and $bH=dH$ into the expression $aHbH$ ? Thanks!","Suppose is a group and let . Consider the factor group where the relation is for all . Suppose we wanted to show that the above relation is well-defined. Then we would pick some elements such that and . I then would have to show that , which is the same as showing that . Question . Couldn't we begin with the left hand side of the equation and substitute for and for ? This would result in The proof in the book doesn't proceed in this way, and although I understand the author's proof, I don't understand why the above method wouldn't work. I have looked at other questions regarding this, but my question is addressing why we can't substitute our assumed equations and into the expression ? Thanks!","G H \triangleleft G G/H aHbH = abH a,b \in G a,b,c,d \in G aH = cH bH = dH aHbH = cHdH abH = cdH aHbH = cHdH cH aH dH bH aHbH = (cH)(dH) = cHdH aH=cH bH=dH aHbH","['abstract-algebra', 'fake-proofs']"
64,Why is $Q[\pi]$ not a field?,Why is  not a field?,Q[\pi],I am having trouble seeing how to apply the definition of transcendental to see this. Thanks!,I am having trouble seeing how to apply the definition of transcendental to see this. Thanks!,,['abstract-algebra']
65,"If $R$ and $S$ are fields, either prove or disprove that $R\times S$ is a field","If  and  are fields, either prove or disprove that  is a field",R S R\times S,"That's the question from my homework. I am thinking $R\times S$ is not a field, but I'm not sure. I understand the definition of a field, but I am not sure how to proceed.","That's the question from my homework. I am thinking $R\times S$ is not a field, but I'm not sure. I understand the definition of a field, but I am not sure how to proceed.",,['abstract-algebra']
66,Explanation for why $1\neq 0$ is explicitly mentioned in Chapter 1 of Spivak's Calculus for properties of numbers.,Explanation for why  is explicitly mentioned in Chapter 1 of Spivak's Calculus for properties of numbers.,1\neq 0,"During the first few pages of Spivak's Calculus (Third edition) in chapter 1 it mentions six properties about numbers. (P1) If $a,b,c$ are any numbers, then $a+(b+c)=(a+b)+c$ (P2) If $a$ is any number then $a+0=0+a=a$ (P3) For every number $a$, there is a number $-a$ such that $a+(-a)=(-a)+a=0$ (P4) If $a$ and $b$ are any numbers, then $a+b=b+a$ (P5) If $a,b$ and $c$ are any numbers, then $a\cdot(b\cdot c)=(a\cdot b)\cdot c$ (P6) If $a$ is any number, then $a\cdot 1=1\cdot a=a$ Then it further states that $1\neq 0$. In the book it says that it was an important fact to list because there is no way that it could be proven on the basis of the $6$ properties listed above - these properties would all hold if there were only one number, namely $0$. Questions: 1) How does one rigorously prove that $1\neq0$ cannot be proven from the $6$ properties listed? 2) It says that ""these properties would all hold if there were only one number, namely $0$."" Is a reason as to why this is explicitly mentioned is to avoid this trivial case where we only have the number $0$? Is there another deeper reason as to why this sentence was mentioned in relation to $1\neq 0$? NB: Can someone please check if the tags are appropriate and edit if necessary? Thanks.","During the first few pages of Spivak's Calculus (Third edition) in chapter 1 it mentions six properties about numbers. (P1) If $a,b,c$ are any numbers, then $a+(b+c)=(a+b)+c$ (P2) If $a$ is any number then $a+0=0+a=a$ (P3) For every number $a$, there is a number $-a$ such that $a+(-a)=(-a)+a=0$ (P4) If $a$ and $b$ are any numbers, then $a+b=b+a$ (P5) If $a,b$ and $c$ are any numbers, then $a\cdot(b\cdot c)=(a\cdot b)\cdot c$ (P6) If $a$ is any number, then $a\cdot 1=1\cdot a=a$ Then it further states that $1\neq 0$. In the book it says that it was an important fact to list because there is no way that it could be proven on the basis of the $6$ properties listed above - these properties would all hold if there were only one number, namely $0$. Questions: 1) How does one rigorously prove that $1\neq0$ cannot be proven from the $6$ properties listed? 2) It says that ""these properties would all hold if there were only one number, namely $0$."" Is a reason as to why this is explicitly mentioned is to avoid this trivial case where we only have the number $0$? Is there another deeper reason as to why this sentence was mentioned in relation to $1\neq 0$? NB: Can someone please check if the tags are appropriate and edit if necessary? Thanks.",,['abstract-algebra']
67,Does a Conjugacy Class always contain an element and its inverse?,Does a Conjugacy Class always contain an element and its inverse?,,"The definition of a conjugate element We say that $x$ is conjugate to $y$ in $G$ if $y = g^{-1}xg $  for some $g \in G$ Now for the group  $G=Q_8$ , we have the group presentation $$Q_8 = \big<a,b: a^4 =1,b^2 = a^2, b^{-1}ab = a^{-1} \big>$$ Now the elements of $Q_8$ are $\{1,a,a^2,a^3,ab,a^2b,a^3b,b\}$ and after some calculation we would get $5$ different conjugacy classes, namely $a^G = \{a,a^3\}$ where $a^G$ denotes the conjugacy class of $a$ in $G = Q_8$, also we have $1^G = \{1 \}$, ${a^2}^G = \{ a^2 \}$, ${(a^2b)}^G = \{a^2b,b \}$ and ${(ab)}^G = \{ab,a^3b\}$ Of course , there is no surpise that for every element $x \in G$ we have $x \in x^G$ because $x = 1^{-1}x1$. However, we see that all the conjugacy classes for $Q_8$ contain the element and it's inverse. Like $a^{-1} = a^3$, ${(a^2)}^{-1} = a^2$, ${(a^2b)}^{-1} = b$ and so on. My question is does this hold true for all groups ? More formally , Is it true that for an element $x \in G$ then $x,x^{-1} \in x^G$ ?","The definition of a conjugate element We say that $x$ is conjugate to $y$ in $G$ if $y = g^{-1}xg $  for some $g \in G$ Now for the group  $G=Q_8$ , we have the group presentation $$Q_8 = \big<a,b: a^4 =1,b^2 = a^2, b^{-1}ab = a^{-1} \big>$$ Now the elements of $Q_8$ are $\{1,a,a^2,a^3,ab,a^2b,a^3b,b\}$ and after some calculation we would get $5$ different conjugacy classes, namely $a^G = \{a,a^3\}$ where $a^G$ denotes the conjugacy class of $a$ in $G = Q_8$, also we have $1^G = \{1 \}$, ${a^2}^G = \{ a^2 \}$, ${(a^2b)}^G = \{a^2b,b \}$ and ${(ab)}^G = \{ab,a^3b\}$ Of course , there is no surpise that for every element $x \in G$ we have $x \in x^G$ because $x = 1^{-1}x1$. However, we see that all the conjugacy classes for $Q_8$ contain the element and it's inverse. Like $a^{-1} = a^3$, ${(a^2)}^{-1} = a^2$, ${(a^2b)}^{-1} = b$ and so on. My question is does this hold true for all groups ? More formally , Is it true that for an element $x \in G$ then $x,x^{-1} \in x^G$ ?",,"['abstract-algebra', 'group-theory', 'group-presentation']"
68,Minimal Polynomial of $\sqrt{2}+\sqrt{3}+\sqrt{5}$,Minimal Polynomial of,\sqrt{2}+\sqrt{3}+\sqrt{5},"To find the above minimal polynomial, let  $$x=\sqrt{2}+\sqrt{3}+\sqrt{5}$$ $$x^2=10+2\sqrt{6}+2\sqrt{10}+2\sqrt{15}$$ Subtracting 10 and squaring gives $$x^4-20x^2+100=4(31+2\sqrt{60}+2\sqrt{90}+2\sqrt{150})$$ $$x^4-20x^2+100=4(31+4\sqrt{15}+6\sqrt{10}+10\sqrt{6})$$ $$x^4-20x^2-24=40\sqrt{6}+24\sqrt{10}+16\sqrt{15}$$ $$x^4-20x^2-24=8(2\sqrt{6}+2\sqrt{10}+2\sqrt{15})+24\sqrt{6}+8\sqrt{10}$$ $$x^4-20x^2-24=8(x^2-10)+24\sqrt{6}+8\sqrt{10}$$ $$x^4-28x^2-104=24\sqrt{6}+8\sqrt{10}$$ Again, squaring both sides $$x^8-56x^6+576x^4+5428x^2+10816=4096+765\sqrt{6}$$ But if I square again, I will get a degree 16 polynomial.  Mathematica says the minimal polynomial is degree 8, which would make sense since elements of $\mathbb{Q}[\sqrt{2},\sqrt{3},\sqrt{5}]$ look like $$a+b\sqrt{2}+c\sqrt{3}+d\sqrt{5}+e\sqrt{6}+f\sqrt{10}+g\sqrt{15}+h\sqrt{30}$$ Where am I making mistakes?","To find the above minimal polynomial, let  $$x=\sqrt{2}+\sqrt{3}+\sqrt{5}$$ $$x^2=10+2\sqrt{6}+2\sqrt{10}+2\sqrt{15}$$ Subtracting 10 and squaring gives $$x^4-20x^2+100=4(31+2\sqrt{60}+2\sqrt{90}+2\sqrt{150})$$ $$x^4-20x^2+100=4(31+4\sqrt{15}+6\sqrt{10}+10\sqrt{6})$$ $$x^4-20x^2-24=40\sqrt{6}+24\sqrt{10}+16\sqrt{15}$$ $$x^4-20x^2-24=8(2\sqrt{6}+2\sqrt{10}+2\sqrt{15})+24\sqrt{6}+8\sqrt{10}$$ $$x^4-20x^2-24=8(x^2-10)+24\sqrt{6}+8\sqrt{10}$$ $$x^4-28x^2-104=24\sqrt{6}+8\sqrt{10}$$ Again, squaring both sides $$x^8-56x^6+576x^4+5428x^2+10816=4096+765\sqrt{6}$$ But if I square again, I will get a degree 16 polynomial.  Mathematica says the minimal polynomial is degree 8, which would make sense since elements of $\mathbb{Q}[\sqrt{2},\sqrt{3},\sqrt{5}]$ look like $$a+b\sqrt{2}+c\sqrt{3}+d\sqrt{5}+e\sqrt{6}+f\sqrt{10}+g\sqrt{15}+h\sqrt{30}$$ Where am I making mistakes?",,"['abstract-algebra', 'polynomials', 'ring-theory', 'field-theory', 'minimal-polynomials']"
69,"If an ideal contains the multiplicative identity, then it is the whole ring","If an ideal contains the multiplicative identity, then it is the whole ring",,"I have to prove that if $I\subseteq R$ is an ideal, and $1\in I$ , then $I=R\,$ . So I know $I\subseteq R$ is an ideal if $a,b\in I$ implies $a+b\in I$ , and if $a\in I$ , $r\in R$ , then $ra\in I$ . I'm finding it hard to put this into words. Since $1\in I$ and $I\subseteq R$ is an ideal, then let $a=1$ and $r=1$ so $1\cdot 1\in R\,?$","I have to prove that if is an ideal, and , then . So I know is an ideal if implies , and if , , then . I'm finding it hard to put this into words. Since and is an ideal, then let and so","I\subseteq R 1\in I I=R\, I\subseteq R a,b\in I a+b\in I a\in I r\in R ra\in I 1\in I I\subseteq R a=1 r=1 1\cdot 1\in R\,?","['abstract-algebra', 'ring-theory', 'ideals']"
70,Is $\mathbb{Z}^2$ cyclic?,Is  cyclic?,\mathbb{Z}^2,Is $\mathbb{Z}^2$ cyclic? What does it mean for a group to be cyclic? Is it just that it has one generator? Thanks,Is $\mathbb{Z}^2$ cyclic? What does it mean for a group to be cyclic? Is it just that it has one generator? Thanks,,"['abstract-algebra', 'group-theory', 'abelian-groups', 'cyclic-groups']"
71,Non-unital module over a ring with identity?,Non-unital module over a ring with identity?,,"Is there a nontrivial example of a non-unital module over a ring with identity?  By trivial, I mean modules  with $rm = 0$ for all $r$ and $m$. Just an idle question.  (Why is there no tag for that?)","Is there a nontrivial example of a non-unital module over a ring with identity?  By trivial, I mean modules  with $rm = 0$ for all $r$ and $m$. Just an idle question.  (Why is there no tag for that?)",,"['abstract-algebra', 'ring-theory', 'modules']"
72,Relationship between algebraically closed fields and complete metric spaces?,Relationship between algebraically closed fields and complete metric spaces?,,"I've been reading recently about algebraically closed fields and complete metric spaces, and it seems to me that they are very similar ideas. Is there some more general mathematical concept which these two ideas are both instantiations of? Also, I am sure that $\mathbb R$ is a complete metric space, but is not algebraically closed, while $\mathbb C$ is both. Is it possible to construct an algebraically closed metric space which is not complete? Thanks in advance!","I've been reading recently about algebraically closed fields and complete metric spaces, and it seems to me that they are very similar ideas. Is there some more general mathematical concept which these two ideas are both instantiations of? Also, I am sure that $\mathbb R$ is a complete metric space, but is not algebraically closed, while $\mathbb C$ is both. Is it possible to construct an algebraically closed metric space which is not complete? Thanks in advance!",,"['abstract-algebra', 'general-topology']"
73,Should a ring be closed under multiplication?,Should a ring be closed under multiplication?,,"In the definition of a ring, it is nowhere stated that it must be closed under multiplication. But it seems to be true for all the examples of rings that I've seen so far. So, is this implicitly assumed in the definition or can it be proved?","In the definition of a ring, it is nowhere stated that it must be closed under multiplication. But it seems to be true for all the examples of rings that I've seen so far. So, is this implicitly assumed in the definition or can it be proved?",,"['abstract-algebra', 'ring-theory']"
74,Prove that $HK$ is a subgroup iff $HK=KH$. [closed],Prove that  is a subgroup iff . [closed],HK HK=KH,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $H$ and $K$ be subgroups of a group $G$, and let $HK=\{hk: h \in H, k \in K\}$, $KH=\{kh: k \in K, h \in H\}$. How can we prove that $HK$ is a subgroup iff $HK=KH$?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $H$ and $K$ be subgroups of a group $G$, and let $HK=\{hk: h \in H, k \in K\}$, $KH=\{kh: k \in K, h \in H\}$. How can we prove that $HK$ is a subgroup iff $HK=KH$?",,"['abstract-algebra', 'group-theory']"
75,A question on definition of field of fractions,A question on definition of field of fractions,,"Wikipedia defines the field of fractions of a domain as The field of fractions or field of quotients of an integral domain is the ""smallest"" field in which it can be embedded. What does ""smallest"" mean mathematically in this context? Is it possible to embed an integral domain in two different fields which have no elements in common?","Wikipedia defines the field of fractions of a domain as The field of fractions or field of quotients of an integral domain is the ""smallest"" field in which it can be embedded. What does ""smallest"" mean mathematically in this context? Is it possible to embed an integral domain in two different fields which have no elements in common?",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'definition']"
76,What are the prerequisites for taking introductory abstract algebra? [closed],What are the prerequisites for taking introductory abstract algebra? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 5 years ago . Improve this question I am a maths student in my second year of university. I have taken and done quite well in Calculus I, II, III as well as a linear algebra (application focused) class. I have not worked much with proofs. My school's course catalog lists Abstract Algebra as one of the next courses but suggests a remedial ""introduction to mathematical proofs"" class for some. My question is if the community thinks it would be doable to go ahead with Abstract. Our Abstract Algebra class is at the level of Thomas Hungerfords ""Abstract Algebra: An Introduction"".","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 5 years ago . Improve this question I am a maths student in my second year of university. I have taken and done quite well in Calculus I, II, III as well as a linear algebra (application focused) class. I have not worked much with proofs. My school's course catalog lists Abstract Algebra as one of the next courses but suggests a remedial ""introduction to mathematical proofs"" class for some. My question is if the community thinks it would be doable to go ahead with Abstract. Our Abstract Algebra class is at the level of Thomas Hungerfords ""Abstract Algebra: An Introduction"".",,"['abstract-algebra', 'education', 'advice']"
77,Algebraically closed field with characteristics $0$ versus $\mathbb{C}$,Algebraically closed field with characteristics  versus,0 \mathbb{C},"We know that $\mathbb C$ is an algebraically closed field with characteristic $0$. It seems that if a proposition that can be expressed in the language of first-order logic is true for an algebraically closed field with characteristic $0$, then it is true for $\mathbb C$ (and for every algebraically closed field with characteristic $0$). I am looking for interesting results that would be true over $\mathbb C$ but not true over some algebraically closed field with characteristic $0$. I am more interested in ""applied"" results than results in field theory. Additional comment: The initial question is vague (but on purpose). Here is what triggered that question in my mind. Sudbery proved the following result: Let $f(z)$ be a polynomial of degree $N$ with complex coefficients, and let $f^{(r)}(z)$ denote the $r$th derivative of $f(z)$. If $f(z)$ has two or more distinct roots, then $\prod_{i=0}^{N}f^{(r)}(z)$ has at least $N+1$ distinct roots. This result does not seem to generalize easily to algebraically closed fields with characteristic $0$.","We know that $\mathbb C$ is an algebraically closed field with characteristic $0$. It seems that if a proposition that can be expressed in the language of first-order logic is true for an algebraically closed field with characteristic $0$, then it is true for $\mathbb C$ (and for every algebraically closed field with characteristic $0$). I am looking for interesting results that would be true over $\mathbb C$ but not true over some algebraically closed field with characteristic $0$. I am more interested in ""applied"" results than results in field theory. Additional comment: The initial question is vague (but on purpose). Here is what triggered that question in my mind. Sudbery proved the following result: Let $f(z)$ be a polynomial of degree $N$ with complex coefficients, and let $f^{(r)}(z)$ denote the $r$th derivative of $f(z)$. If $f(z)$ has two or more distinct roots, then $\prod_{i=0}^{N}f^{(r)}(z)$ has at least $N+1$ distinct roots. This result does not seem to generalize easily to algebraically closed fields with characteristic $0$.",,"['abstract-algebra', 'algebraic-topology']"
78,Proving that $G/N$ is an abelian group,Proving that  is an abelian group,G/N,"Let $G$ be the group  of all $2 \times 2$ matrices of the form $\begin{pmatrix} a & b \\ 0 & d\end{pmatrix}$ where $ad \neq 0$ under matrix multiplication. Let  $N=\left\{A \in G \; \colon \; A = \begin{pmatrix}1 & b \\ 0 & 1\end{pmatrix} \right\}$ be  a subset  of the group $G$. Prove that  $N$ is  a normal subgroup of $G$ and prove that  $G/N$ is abelian group. Here is my attempt! To prove $N$ is normal I consider  the group homomorphism $f \colon G \to \mathbb R^*$ given by $f(B) = \det(B)$ for all $B$ in $G$. And I see that $f(N)$ is all the singleton $\{1\}$ since $\{1\}$ as a subgroup of $\mathbb R^*$  is normal, it follows that $N$ is also normal. Is this proof helpful  here? Then how to prove that $G/N$ is Abelian? I know $G/N$ is a collection of left cosets. Thank you.","Let $G$ be the group  of all $2 \times 2$ matrices of the form $\begin{pmatrix} a & b \\ 0 & d\end{pmatrix}$ where $ad \neq 0$ under matrix multiplication. Let  $N=\left\{A \in G \; \colon \; A = \begin{pmatrix}1 & b \\ 0 & 1\end{pmatrix} \right\}$ be  a subset  of the group $G$. Prove that  $N$ is  a normal subgroup of $G$ and prove that  $G/N$ is abelian group. Here is my attempt! To prove $N$ is normal I consider  the group homomorphism $f \colon G \to \mathbb R^*$ given by $f(B) = \det(B)$ for all $B$ in $G$. And I see that $f(N)$ is all the singleton $\{1\}$ since $\{1\}$ as a subgroup of $\mathbb R^*$  is normal, it follows that $N$ is also normal. Is this proof helpful  here? Then how to prove that $G/N$ is Abelian? I know $G/N$ is a collection of left cosets. Thank you.",,"['abstract-algebra', 'group-theory', 'normal-subgroups']"
79,Progress on a conjecture of Burnside...,Progress on a conjecture of Burnside...,,"Given a group $G $ , the set of automorphisms of $G $ also forms a group, $\rm {Aut}(G) $ ,with composition as the operation (recall that an automorphism of a group is a bijective endomorphism) . An inner automorphism is one determined by conjugation by some element $g\in G $ .  That's we have the automorphism $i_g $ given by $i_g (h)=ghg^{-1}\,\forall h $ . I learned from a comment by @LeeMosher on this site that Burnside once conjectured that any class-preserving automorphism is inner.  Does anyone know about any progress on this? Of course the converse is trivial. (Btw, the reference here is to conjugacy classes.  Of course the class equation gives the sizes of these classes.  For example,  in the case of an abelian group,  the class equation consists in all ones.) For reference,  this would have been early in the $20$ -th century.","Given a group , the set of automorphisms of also forms a group, ,with composition as the operation (recall that an automorphism of a group is a bijective endomorphism) . An inner automorphism is one determined by conjugation by some element .  That's we have the automorphism given by . I learned from a comment by @LeeMosher on this site that Burnside once conjectured that any class-preserving automorphism is inner.  Does anyone know about any progress on this? Of course the converse is trivial. (Btw, the reference here is to conjugacy classes.  Of course the class equation gives the sizes of these classes.  For example,  in the case of an abelian group,  the class equation consists in all ones.) For reference,  this would have been early in the -th century.","G  G  \rm {Aut}(G)  g\in G  i_g  i_g (h)=ghg^{-1}\,\forall h  20","['abstract-algebra', 'group-theory']"
80,Are fields flat $\mathbb Z$-modules?,Are fields flat -modules?,\mathbb Z,"This is probably one of those questions with a super obvious counterexample, but here goes. Is a field necessarily a flat $\mathbb Z$-module?","This is probably one of those questions with a super obvious counterexample, but here goes. Is a field necessarily a flat $\mathbb Z$-module?",,['abstract-algebra']
81,All Sylow $p$-subgroups of $GL_2(\mathbb F_p)$?,All Sylow -subgroups of ?,p GL_2(\mathbb F_p),"How would I use Sylow's 2nd theorem to write down all the Sylow $p$-subgroups of $GL_2(\mathbb F_p)$? How many Sylow $p$-subgroups of $GL_2(\mathbb F_p)$ are there? Struggling with these questions, any step-by-step solutions offered would really help my understanding.","How would I use Sylow's 2nd theorem to write down all the Sylow $p$-subgroups of $GL_2(\mathbb F_p)$? How many Sylow $p$-subgroups of $GL_2(\mathbb F_p)$ are there? Struggling with these questions, any step-by-step solutions offered would really help my understanding.",,"['abstract-algebra', 'group-theory']"
82,Prove that any non-zero-divisor of a finite dimensional algebra has an inverse,Prove that any non-zero-divisor of a finite dimensional algebra has an inverse,,"Let $A$ be a finite dimensional algebra. Prove that an element of $A$ is invertible iff it is not a zero divisor. Let $a$ be an invertible element, then there exists an element $b$ such that $ab=1$ and assyme that $a$ is a zero divisor, then there exists an element $c  \neq 0$ such that $ac=0$ and i don't know.","Let $A$ be a finite dimensional algebra. Prove that an element of $A$ is invertible iff it is not a zero divisor. Let $a$ be an invertible element, then there exists an element $b$ such that $ab=1$ and assyme that $a$ is a zero divisor, then there exists an element $c  \neq 0$ such that $ac=0$ and i don't know.",,['abstract-algebra']
83,Non-UFD integral domain such that prime is equivalent to irreducible?,Non-UFD integral domain such that prime is equivalent to irreducible?,,"In the integral domain every prime is irreducible. But the converse is not true, for example, $1+\sqrt{-3}$ is an irreducible but not a prime in ${\Bbb Z}[\sqrt{-3}]$. In a UFD, ""prime"" and ""irreducible"" are equivalent. Here is my question : Is there a non-UFD integral domain such that prime is equivalent to irreducible?","In the integral domain every prime is irreducible. But the converse is not true, for example, $1+\sqrt{-3}$ is an irreducible but not a prime in ${\Bbb Z}[\sqrt{-3}]$. In a UFD, ""prime"" and ""irreducible"" are equivalent. Here is my question : Is there a non-UFD integral domain such that prime is equivalent to irreducible?",,['abstract-algebra']
84,"Is it possible to learn ring theory if one's familiar, but not good at group theory? [closed]","Is it possible to learn ring theory if one's familiar, but not good at group theory? [closed]",,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . Improve this question Is it possible to learn ring theory if one is familiar with but not good at group theory? Background: I’m using Dummit and Foote's Abstract Algebra , and I am an undergrad.","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . Improve this question Is it possible to learn ring theory if one is familiar with but not good at group theory? Background: I’m using Dummit and Foote's Abstract Algebra , and I am an undergrad.",,"['abstract-algebra', 'group-theory', 'ring-theory', 'advice']"
85,Prove that $x-1$ is a factor of $x^n-1$,Prove that  is a factor of,x-1 x^n-1,Prove that $x-1$ is a factor of $x^n-1$. My problem: I already proved it by factor theorem † and by simply dividing them. I need another approach to prove it. Is there any other third approach to prove it? If yes please share it. I will be very thankful to you. Thanks. † : Factor Theorem : $x -r$ is a factor of $f(x)$ if and only if $f(r) = 0$.,Prove that $x-1$ is a factor of $x^n-1$. My problem: I already proved it by factor theorem † and by simply dividing them. I need another approach to prove it. Is there any other third approach to prove it? If yes please share it. I will be very thankful to you. Thanks. † : Factor Theorem : $x -r$ is a factor of $f(x)$ if and only if $f(r) = 0$.,,"['abstract-algebra', 'polynomials', 'alternative-proof']"
86,Are groups algebras over an operad?,Are groups algebras over an operad?,,"I'm trying to understand a little bit about operads. I think I understand that monoids are algebras over the associative operad in sets, but can groups be realised as algebras over some operad? In other words, can we require the existence of inverses in the structure of the operad? Similarly one could ask the same question about (skew-)fields.","I'm trying to understand a little bit about operads. I think I understand that monoids are algebras over the associative operad in sets, but can groups be realised as algebras over some operad? In other words, can we require the existence of inverses in the structure of the operad? Similarly one could ask the same question about (skew-)fields.",,"['abstract-algebra', 'general-topology', 'category-theory', 'universal-algebra', 'operads']"
87,Definitions of direct product and of direct sum,Definitions of direct product and of direct sum,,"I was wondering if there are some general definitions for direct product and for direct sum, for example in category theory or in set theory, so that the concepts for vector spaces, Abelian groups, rings can be unified, or in other words, the common features of those specific concepts can be abstracted? In particular, the following quotes from Wikipedia ( direct sum and direct product ) seem to make attempts to reveal their relation to Cartesian product in set theory and (co)product in category theory, but also say that the relation is not always true. one can often define a direct product of objects already known,   giving a new one. This is generally the Cartesian product of the   underlying sets, together with a suitably defined structure on the   product set. More abstractly, one talks about the product in   category theory, which formalizes these notions. one can often define a direct sum of objects already known, giving   a new one. This is generally the Cartesian product of the underlying   sets (or some subset of it), together with a suitably defined   structure. More abstractly, the direct sum is often, but not always ,   the coproduct in the category in question. Thanks and regards!","I was wondering if there are some general definitions for direct product and for direct sum, for example in category theory or in set theory, so that the concepts for vector spaces, Abelian groups, rings can be unified, or in other words, the common features of those specific concepts can be abstracted? In particular, the following quotes from Wikipedia ( direct sum and direct product ) seem to make attempts to reveal their relation to Cartesian product in set theory and (co)product in category theory, but also say that the relation is not always true. one can often define a direct product of objects already known,   giving a new one. This is generally the Cartesian product of the   underlying sets, together with a suitably defined structure on the   product set. More abstractly, one talks about the product in   category theory, which formalizes these notions. one can often define a direct sum of objects already known, giving   a new one. This is generally the Cartesian product of the underlying   sets (or some subset of it), together with a suitably defined   structure. More abstractly, the direct sum is often, but not always ,   the coproduct in the category in question. Thanks and regards!",,"['abstract-algebra', 'category-theory', 'definition']"
88,Can ring homomorphisms be characterized as ring maps such that preimage of any ideal is an ideal?,Can ring homomorphisms be characterized as ring maps such that preimage of any ideal is an ideal?,,"It's a well know fact that preimage of ideals by ring homomorphism are also ideals. Is the reciprocal true? I.e., let $f:R\to S$ be a map between the rings $R$ and $S$ s.t. $f^{-1}(I)\vartriangleleft R$ if $I\vartriangleleft S$. Then is $f$ a ring homomorphism?","It's a well know fact that preimage of ideals by ring homomorphism are also ideals. Is the reciprocal true? I.e., let $f:R\to S$ be a map between the rings $R$ and $S$ s.t. $f^{-1}(I)\vartriangleleft R$ if $I\vartriangleleft S$. Then is $f$ a ring homomorphism?",,"['abstract-algebra', 'ring-theory', 'ideals', 'ring-homomorphism']"
89,proper subgroups of finite p-groups are properly contained in the normalizer,proper subgroups of finite p-groups are properly contained in the normalizer,,"I am trying to prove the following, Let $G$ be a finite $p$-group and let $H$ be a proper subgroup. Then there exists a subgroup $H'$ such that    $$ H\lneq H'\leq G $$   and $H\triangleleft H'$. Obviously, the natural choice for $H'$ would be the normalizer $N_G(H)$ of $H$ in $G$. However, one needs to prove then that $H\lneq N_G(H)$ in finite $p$-groups. I am aware of a proof of this fact by induction on the order of $G$. However, I was wondering if there was another proof which only used group actions?","I am trying to prove the following, Let $G$ be a finite $p$-group and let $H$ be a proper subgroup. Then there exists a subgroup $H'$ such that    $$ H\lneq H'\leq G $$   and $H\triangleleft H'$. Obviously, the natural choice for $H'$ would be the normalizer $N_G(H)$ of $H$ in $G$. However, one needs to prove then that $H\lneq N_G(H)$ in finite $p$-groups. I am aware of a proof of this fact by induction on the order of $G$. However, I was wondering if there was another proof which only used group actions?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'p-groups']"
90,Is $\mathbb{Q}[2^{1/3}]$ a field?,Is  a field?,\mathbb{Q}[2^{1/3}],"Is $\mathbb{Q}[2^{1/3}]=\{a+b2^{1/3}+c2^{2/3};a,b,c \in \mathbb{Q}\}$ a field? I have checked that $b2^{1/3}$ and $c2^{2/3}$ both have inverses, $\frac{2^{2/3}}{2b}$ and $\frac{2^{1/3}}{2c}$, respectively. There are some elements with $a,b,c \neq 0$ that have inverses, as $1+1*2^{1/3}+1*2^{2/3}$, whose inverse is $2^{1/3}-1$. My problem is that is that I can't seem to find a formula for the inverse, but I also can't seem to find someone who doesn't have an inverse. Thanks for your time.","Is $\mathbb{Q}[2^{1/3}]=\{a+b2^{1/3}+c2^{2/3};a,b,c \in \mathbb{Q}\}$ a field? I have checked that $b2^{1/3}$ and $c2^{2/3}$ both have inverses, $\frac{2^{2/3}}{2b}$ and $\frac{2^{1/3}}{2c}$, respectively. There are some elements with $a,b,c \neq 0$ that have inverses, as $1+1*2^{1/3}+1*2^{2/3}$, whose inverse is $2^{1/3}-1$. My problem is that is that I can't seem to find a formula for the inverse, but I also can't seem to find someone who doesn't have an inverse. Thanks for your time.",,"['abstract-algebra', 'field-theory']"
91,Why do people study algebraic extension?,Why do people study algebraic extension?,,"Yesterday, I learned Kronecker’s theorem and a finite extension. And now I’m studying the next chapter, Algebraic extension. I think the next theorem shows how important algebraic extension is Let $E$ be an extension field of a field $F$. Let $α$ be an element of $E$. If $α$ is algebraic over $F$, there exists a unique monic irreducible polynomial $p(x)$ in $F[x]$ such that $p(α)=0$ in $E$. But I’m wondering there is another important reason why we should study algebraic extensions. Thanks for your help.","Yesterday, I learned Kronecker’s theorem and a finite extension. And now I’m studying the next chapter, Algebraic extension. I think the next theorem shows how important algebraic extension is Let $E$ be an extension field of a field $F$. Let $α$ be an element of $E$. If $α$ is algebraic over $F$, there exists a unique monic irreducible polynomial $p(x)$ in $F[x]$ such that $p(α)=0$ in $E$. But I’m wondering there is another important reason why we should study algebraic extensions. Thanks for your help.",,"['abstract-algebra', 'field-theory', 'extension-field']"
92,What is a simple example of a free group?,What is a simple example of a free group?,,"Can someone give me a simple example of a free group with a basis, given the definition below? I don't think I'm understanding the definition clearly. For example if $F= (\Bbb Z, +)$, $X = \{0\}$, $\phi\colon\{0\} \rightarrow G$ is any function, then there should exist a unique homomorphism $\tilde \phi\colon \Bbb Z \rightarrow G$ such that $\tilde \phi(0) = \phi(0)$. But if $\phi\colon\{0\} \mapsto \text{non identity element of $G$}$, then there's no way any homomorphism exists because identities of one group are mapped to the other group.","Can someone give me a simple example of a free group with a basis, given the definition below? I don't think I'm understanding the definition clearly. For example if $F= (\Bbb Z, +)$, $X = \{0\}$, $\phi\colon\{0\} \rightarrow G$ is any function, then there should exist a unique homomorphism $\tilde \phi\colon \Bbb Z \rightarrow G$ such that $\tilde \phi(0) = \phi(0)$. But if $\phi\colon\{0\} \mapsto \text{non identity element of $G$}$, then there's no way any homomorphism exists because identities of one group are mapped to the other group.",,"['abstract-algebra', 'group-theory', 'definition', 'examples-counterexamples', 'free-groups']"
93,"What are the generators of $(\mathbb{R},+)$?",What are the generators of ?,"(\mathbb{R},+)","The real numbers as a group under addition are an infinitely-generated group. I'm not sure what those generators are though (or if it even makes sense to ask the question). For example, could we say that the generators are $1, 0.1,0.01,\dots$ as a real number can be defined as a limit $\sum_i^n w_i 10^{-i}$ for some $w$?","The real numbers as a group under addition are an infinitely-generated group. I'm not sure what those generators are though (or if it even makes sense to ask the question). For example, could we say that the generators are $1, 0.1,0.01,\dots$ as a real number can be defined as a limit $\sum_i^n w_i 10^{-i}$ for some $w$?",,"['abstract-algebra', 'group-theory']"
94,Groups where no elements commute except for the trivial cases,Groups where no elements commute except for the trivial cases,,"Let $G$ be a group. Write $e$ for its neutral element and write $\langle g\rangle$ for the subgroup generated by an element $g \in G$ . Assume that $G$ has the following properties: For all $g\in G\setminus\{e\}$ and $h\in G\setminus \langle g \rangle$ we have $gh \neq hg$ . Property 1. is non-vacuous (as it would be e.g. for $G=\{e\}$ ). Do such groups exist? If so, do they have any interesting/important properties? Note that this is a follow-up to this very similar question in response to one of the comments there.","Let be a group. Write for its neutral element and write for the subgroup generated by an element . Assume that has the following properties: For all and we have . Property 1. is non-vacuous (as it would be e.g. for ). Do such groups exist? If so, do they have any interesting/important properties? Note that this is a follow-up to this very similar question in response to one of the comments there.",G e \langle g\rangle g \in G G g\in G\setminus\{e\} h\in G\setminus \langle g \rangle gh \neq hg G=\{e\},"['abstract-algebra', 'group-theory', 'finite-groups']"
95,Number system with $e^x = 0$ for some $x$,Number system with  for some,e^x = 0 x,"It is well known that $e^x \ne 0$ for all $x \in \mathbb{R}$ as well as $x \in \mathbb{C}$.  Upon reading this article and doing a bit of research I have found that this also applies to the quaternions $\mathbb{H}$, the octonions $\mathbb{O}$ as well as the space of $m$ by $n$ matrices with real or complex entries. My question is whether there is ANY number system at all for which $e^x = 0$ for some $x$, that is, $\log 0$ is defined and has a finite value.  Preferably the example should be finite-dimensional and should not be constructed by arbitrarily assigning a value to $\log 0$, such as $\log 0 := 42.$ Additionally, for the purposes of this question, none of the usual properties of arithmetic or the exponential function are assumed true, though I suppose this makes my question somewhat meaningless. Edit : I am intrigued at Yuriy S's idea of defining $e^x = 0$ for all $x$. My question now is what is the most ""well behaved"" algebra we can come up with if $e^x$ is required to be identically zero?","It is well known that $e^x \ne 0$ for all $x \in \mathbb{R}$ as well as $x \in \mathbb{C}$.  Upon reading this article and doing a bit of research I have found that this also applies to the quaternions $\mathbb{H}$, the octonions $\mathbb{O}$ as well as the space of $m$ by $n$ matrices with real or complex entries. My question is whether there is ANY number system at all for which $e^x = 0$ for some $x$, that is, $\log 0$ is defined and has a finite value.  Preferably the example should be finite-dimensional and should not be constructed by arbitrarily assigning a value to $\log 0$, such as $\log 0 := 42.$ Additionally, for the purposes of this question, none of the usual properties of arithmetic or the exponential function are assumed true, though I suppose this makes my question somewhat meaningless. Edit : I am intrigued at Yuriy S's idea of defining $e^x = 0$ for all $x$. My question now is what is the most ""well behaved"" algebra we can come up with if $e^x$ is required to be identically zero?",,"['abstract-algebra', 'complex-numbers', 'logarithms', 'exponential-function']"
96,"Prove that if $a^{2}=e$ and $ab^{4}a=b^{7}$, then $b^{33}=e$, where $e$ is the identity of a group $G$","Prove that if  and , then , where  is the identity of a group",a^{2}=e ab^{4}a=b^{7} b^{33}=e e G,"Let $G$ be a group and $a,b \in G$. Prove that if $a^{2}=e$ and $ab^{4}a=b^{7}$, then $b^{33}=e$, where $e$ is the identity of a group $G$.","Let $G$ be a group and $a,b \in G$. Prove that if $a^{2}=e$ and $ab^{4}a=b^{7}$, then $b^{33}=e$, where $e$ is the identity of a group $G$.",,"['abstract-algebra', 'group-theory']"
97,"The word ""distinguished"" in algebra","The word ""distinguished"" in algebra",,"When we define something like a ring, we often say that the elements $0$ and $1$ are ""distinguished elements"". What does this mean? It obviously doesn't mean they are distinct.","When we define something like a ring, we often say that the elements $0$ and $1$ are ""distinguished elements"". What does this mean? It obviously doesn't mean they are distinct.",,['abstract-algebra']
98,Dependence of Axioms of Equivalence Relation? [duplicate],Dependence of Axioms of Equivalence Relation? [duplicate],,"This question already has answers here : Examples and Counterexamples of Relations which Satisfy Certain Properties (2 answers) Closed 3 years ago . This question is problem 11(a) in chapter 1 in 'Topics in Algebra' by I.N. Herstein. These are the properties of equivalence relation given in this book. Prop 1 $a \sim a$ Prop 2 $a \sim b$ implies $b \sim a$. Prop 3 $(a \sim b$ and $b \sim c)$ imply $a \sim c$. Statement Property 2 of an equivalence relation states that if $a \sim b$ then $b \sim a$. By property 3, we have the transitivity i.e. $a \sim b$, and $b \sim c$ then $a \sim c$. What is wrong with following proof that property 2 and 3 imply property 1? Let $a \sim b$; then $b \sim a$, whence by property 3 (using $a = c$), $a \sim a$. I think I can prove this to be wrong. Without proving equivalence relation first, one can not use $a = c$. Right? After all, equality is equivalent to 'equivalence relation' and 'axiom of substitution' are satisfied. If this is right, then I have trouble with the next part of this problem. Part 2 Can you suggest an alternative of property 1 which will insure us that prop 2 and prop 3 do imply 1? Can one give such a formulation without using the idea of '=' or otherwise? EDIT : Italics are my comments. Rest is as it appeared in the book. Notion of Equality I have read in Terry 'Analysis 1' in Appendix A.7 published by Hindustan Book Agency that there are four axioms of 'equality'. First 3 are same as equivalence relation where $\sim $ in replaced by $ = $. The fourth one is known as axiom of substitution. Given any two objects $x$ and $y$ of some type, if $ x = y $, then $f(x) = f(y) $ for all functions or operations $f$.","This question already has answers here : Examples and Counterexamples of Relations which Satisfy Certain Properties (2 answers) Closed 3 years ago . This question is problem 11(a) in chapter 1 in 'Topics in Algebra' by I.N. Herstein. These are the properties of equivalence relation given in this book. Prop 1 $a \sim a$ Prop 2 $a \sim b$ implies $b \sim a$. Prop 3 $(a \sim b$ and $b \sim c)$ imply $a \sim c$. Statement Property 2 of an equivalence relation states that if $a \sim b$ then $b \sim a$. By property 3, we have the transitivity i.e. $a \sim b$, and $b \sim c$ then $a \sim c$. What is wrong with following proof that property 2 and 3 imply property 1? Let $a \sim b$; then $b \sim a$, whence by property 3 (using $a = c$), $a \sim a$. I think I can prove this to be wrong. Without proving equivalence relation first, one can not use $a = c$. Right? After all, equality is equivalent to 'equivalence relation' and 'axiom of substitution' are satisfied. If this is right, then I have trouble with the next part of this problem. Part 2 Can you suggest an alternative of property 1 which will insure us that prop 2 and prop 3 do imply 1? Can one give such a formulation without using the idea of '=' or otherwise? EDIT : Italics are my comments. Rest is as it appeared in the book. Notion of Equality I have read in Terry 'Analysis 1' in Appendix A.7 published by Hindustan Book Agency that there are four axioms of 'equality'. First 3 are same as equivalence relation where $\sim $ in replaced by $ = $. The fourth one is known as axiom of substitution. Given any two objects $x$ and $y$ of some type, if $ x = y $, then $f(x) = f(y) $ for all functions or operations $f$.",,"['abstract-algebra', 'elementary-set-theory', 'relations', 'equivalence-relations']"
99,Every prime ideal of height 1 in a UFD is principal,Every prime ideal of height 1 in a UFD is principal,,"If $R$ is a   UFD, then every prime ideal of height 1 in $R$ is principal. I find this is a direct consequence of Kaplansky's theorem. But the proof of Kaplansky's theorem is difficult for me.  So I wonder how to prove the statement directly.","If $R$ is a   UFD, then every prime ideal of height 1 in $R$ is principal. I find this is a direct consequence of Kaplansky's theorem. But the proof of Kaplansky's theorem is difficult for me.  So I wonder how to prove the statement directly.",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'unique-factorization-domains']"
