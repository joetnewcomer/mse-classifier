,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Probability of winning the lottery the more you play it?,Probability of winning the lottery the more you play it?,,"Recently I was having a conversation with a philosophy student on gambling and it intrigued me because of what the person was saying. Before I say what the person said, I remember learning in class that the probability of something occurring does not increase as you use it. For example, if I flipped a fair coin, no matter how many times I flip the coin it will always have a 50% chance of landing heads or tails. However according to the person, he said that the more times I play a lottery machine, my chances of winning will increase as well. Can someone explain to me the difference between my statement and his? I am thinking that my statement only refers to single events, but his refers to total probability?","Recently I was having a conversation with a philosophy student on gambling and it intrigued me because of what the person was saying. Before I say what the person said, I remember learning in class that the probability of something occurring does not increase as you use it. For example, if I flipped a fair coin, no matter how many times I flip the coin it will always have a 50% chance of landing heads or tails. However according to the person, he said that the more times I play a lottery machine, my chances of winning will increase as well. Can someone explain to me the difference between my statement and his? I am thinking that my statement only refers to single events, but his refers to total probability?",,['probability']
1,Arranging $n$ balls in $k$ bins so that $m$ consecutive bins are empty,Arranging  balls in  bins so that  consecutive bins are empty,n k m,"This question is inspired by the following problem: Randomly place seven balls into ten bins, with no bin containing more than one ball. What is the probability that there will be (at least) two consecutive bins that are empty? Note that this is not a circular arrangement, although that could make for an interesting (if simpler) question. The actual question I have is the same as the one above, but with the numbers written in emphasized text generalized as positive integers $n$ , $k$ , and $m$ , respectively. Question: Randomly place $n$ balls into $k$ bins, with no bin containing more than one ball. What is the probability that there will be (at least) $m$ consecutive bins that are empty? I suspect that this is a known counting problem (as framed, or through some equivalent rephrase), so I include a reference-request tag. An original solution would, of course, be welcome as well! As in an already included answer: Specific cases (e.g., $m=2$ ) would be helpful, too.","This question is inspired by the following problem: Randomly place seven balls into ten bins, with no bin containing more than one ball. What is the probability that there will be (at least) two consecutive bins that are empty? Note that this is not a circular arrangement, although that could make for an interesting (if simpler) question. The actual question I have is the same as the one above, but with the numbers written in emphasized text generalized as positive integers , , and , respectively. Question: Randomly place balls into bins, with no bin containing more than one ball. What is the probability that there will be (at least) consecutive bins that are empty? I suspect that this is a known counting problem (as framed, or through some equivalent rephrase), so I include a reference-request tag. An original solution would, of course, be welcome as well! As in an already included answer: Specific cases (e.g., ) would be helpful, too.",n k m n k m m=2,"['probability', 'combinatorics', 'discrete-mathematics', 'reference-request', 'balls-in-bins']"
2,Sub sub sequences and a relation between convergence in probability and a.s convergence,Sub sub sequences and a relation between convergence in probability and a.s convergence,,"I am trying to understand an answer to this question (specifically Siméon's answer) Convergence in probability of the product of two random variables Im struggling with the statement ""$X_{n}$ tends to X in probability if and only if , every subsequence of $X_{n}$ has a sub sub sequence that tends to $X$ a.s"" I felt like the above statement deserved a question in itself. If this is true I can see how the proof follows.","I am trying to understand an answer to this question (specifically Siméon's answer) Convergence in probability of the product of two random variables Im struggling with the statement ""$X_{n}$ tends to X in probability if and only if , every subsequence of $X_{n}$ has a sub sub sequence that tends to $X$ a.s"" I felt like the above statement deserved a question in itself. If this is true I can see how the proof follows.",,"['probability', 'sequences-and-series', 'convergence-divergence']"
3,Probability two students are paired,Probability two students are paired,,I'm wondering why my answer here is incorrect. The question is: John and Steve are members of a class of $20$ students. What is the probability that they are paired together? My thought was simply $1$ way to pair John and Steve and $20 \choose 2$ total pairs so $\frac{1}{190}$. But the correct answer is $\frac{1}{19}$. How is it that my method doesn't work?,I'm wondering why my answer here is incorrect. The question is: John and Steve are members of a class of $20$ students. What is the probability that they are paired together? My thought was simply $1$ way to pair John and Steve and $20 \choose 2$ total pairs so $\frac{1}{190}$. But the correct answer is $\frac{1}{19}$. How is it that my method doesn't work?,,['probability']
4,Can an observed event in fact be of zero probability?,Can an observed event in fact be of zero probability?,,"Can an observed event in fact be of zero probability? Of course, I know that there exist non-empty events of zero probability. Mu question is the reverse: given that we have observed an event (and we have no other information about it, just the fact that it has been observed), is it possible that the event has in fact zero probability? Or does an observation necessarily mean that the probability is strictly positive? Example context for the question: Suppose $x_i$ (countably many) are i.i.d on $[0,1]$, but we do not know the distribution they come from. It may be uniform on $[0,1]$, may be discrete, may be any legitimate distribution (discrete or continuous). Just imagine we have some sort of a machine that shows us one by one a list of randomly drawn numbers between $0$ and $1$. We are comparing the observed numbers one by one to some special number chosen beforehand, for example $\frac12$. Now, given that at some iteration we have observed that special number at least once, does that mean that $\frac12$ has some positive probability under that (unknown) distribution? And if the probability can be zero, can we nevertheless say that we will necessarily observe $\frac12$ again later, if we continue the experiment ad infimum? Also, disregard the ""real world limitations"" such as an inability to produce truly uniformly distibuted numbers, or rounding errors or any such thing.","Can an observed event in fact be of zero probability? Of course, I know that there exist non-empty events of zero probability. Mu question is the reverse: given that we have observed an event (and we have no other information about it, just the fact that it has been observed), is it possible that the event has in fact zero probability? Or does an observation necessarily mean that the probability is strictly positive? Example context for the question: Suppose $x_i$ (countably many) are i.i.d on $[0,1]$, but we do not know the distribution they come from. It may be uniform on $[0,1]$, may be discrete, may be any legitimate distribution (discrete or continuous). Just imagine we have some sort of a machine that shows us one by one a list of randomly drawn numbers between $0$ and $1$. We are comparing the observed numbers one by one to some special number chosen beforehand, for example $\frac12$. Now, given that at some iteration we have observed that special number at least once, does that mean that $\frac12$ has some positive probability under that (unknown) distribution? And if the probability can be zero, can we nevertheless say that we will necessarily observe $\frac12$ again later, if we continue the experiment ad infimum? Also, disregard the ""real world limitations"" such as an inability to produce truly uniformly distibuted numbers, or rounding errors or any such thing.",,"['probability', 'probability-theory']"
5,Order statistics finding the expectation and variance of the maximum,Order statistics finding the expectation and variance of the maximum,,"Let $X_1,X_2,\ldots,X_n$ be a collection of independent uniformly distributed random variables on the interval from $0$ to $\theta$. The question has three parts. Find the CDF of $F_{x_n}$(x) of $X_n = \max{\{X_1,\ldots,X_n}\}$ I know that distribution for the uniform distribution is $\frac{1}{b-a}$. In this case $b=\theta$ and $a=0$. So the pdf is $\frac{1}{\theta}$. Then the pdf for $X_n$ should be $\left(\frac 1 \theta \right)^n$. The PDF is then $n\left(\frac 1 \theta \right)^{n-1}$ . Part c asks to calculate the mean and variance for $X_n$. I'm confused on how to do this. Since it is a uniform distribution should I just use the uniform distribution pdf to calculate the expectation and variance?","Let $X_1,X_2,\ldots,X_n$ be a collection of independent uniformly distributed random variables on the interval from $0$ to $\theta$. The question has three parts. Find the CDF of $F_{x_n}$(x) of $X_n = \max{\{X_1,\ldots,X_n}\}$ I know that distribution for the uniform distribution is $\frac{1}{b-a}$. In this case $b=\theta$ and $a=0$. So the pdf is $\frac{1}{\theta}$. Then the pdf for $X_n$ should be $\left(\frac 1 \theta \right)^n$. The PDF is then $n\left(\frac 1 \theta \right)^{n-1}$ . Part c asks to calculate the mean and variance for $X_n$. I'm confused on how to do this. Since it is a uniform distribution should I just use the uniform distribution pdf to calculate the expectation and variance?",,"['probability', 'statistics']"
6,PDF of a sum of exponential random variables [closed],PDF of a sum of exponential random variables [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $X_i$ for $i=1,2,...$ be a sequence of i.i.d exponential random variables with common parameter $\lambda$. Let $N$ be a geometric random variable with parameter $p$ that is independent of the sequence $X_i$. What is the pdf of the random variable $Y=\Sigma_{i=1}^N X_i$.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $X_i$ for $i=1,2,...$ be a sequence of i.i.d exponential random variables with common parameter $\lambda$. Let $N$ be a geometric random variable with parameter $p$ that is independent of the sequence $X_i$. What is the pdf of the random variable $Y=\Sigma_{i=1}^N X_i$.",,['probability']
7,What are the odds of getting heads 7 times in a row in 40 tries of flipping a coin?,What are the odds of getting heads 7 times in a row in 40 tries of flipping a coin?,,"I know if you flip a coin $7$ times, the odds of getting $7$ heads in a row is $1$ in $2^7$ or $1$ in $128$ . But if you flip a coin $40$ times, what are the odds of getting $7$ heads in a row in those $40$ tries? I only want to know the first time there are $7$ heads in a row and not count duplicates. Thanks.","I know if you flip a coin times, the odds of getting heads in a row is in or in . But if you flip a coin times, what are the odds of getting heads in a row in those tries? I only want to know the first time there are heads in a row and not count duplicates. Thanks.",7 7 1 2^7 1 128 40 7 40 7,['probability']
8,What is the problem in this solution to the Two Child Problem?,What is the problem in this solution to the Two Child Problem?,,"The Two Child Problem states In a family with two children, what are the chances, if at least one of the   children is a girl, that both children are girls? It is well attested that the answer is 1 in 3 . You can view the other question for an explanation why. I thought up this solution to the same problem, but since the answer is not the same, there must be some part of my reasoning that is unsound, but I can't quite figure out where the problem is. This is my reasoning: If it is given that the older child is a girl, the probability that the younger child is also a girl, and thus that both children are girls, is 1 in 2. Similarly, if it is given that the younger child is a girl, the probability that the older child is also a girl, and thus that both children are girls, is also 1 in 2. If we know that one of the children is a girl, then it can easily be concluded that either the younger child or the older child is a girl. Either way, the probability is still 1 in 2 . Where have I gone wrong?","The Two Child Problem states In a family with two children, what are the chances, if at least one of the   children is a girl, that both children are girls? It is well attested that the answer is 1 in 3 . You can view the other question for an explanation why. I thought up this solution to the same problem, but since the answer is not the same, there must be some part of my reasoning that is unsound, but I can't quite figure out where the problem is. This is my reasoning: If it is given that the older child is a girl, the probability that the younger child is also a girl, and thus that both children are girls, is 1 in 2. Similarly, if it is given that the younger child is a girl, the probability that the older child is also a girl, and thus that both children are girls, is also 1 in 2. If we know that one of the children is a girl, then it can easily be concluded that either the younger child or the older child is a girl. Either way, the probability is still 1 in 2 . Where have I gone wrong?",,"['probability', 'fake-proofs']"
9,How to generate REAL random numbers with some random and pseudo random,How to generate REAL random numbers with some random and pseudo random,,"I'm doing (with Java) a very simple simulator (Queueing Systems..) that needs many random numbers (more than $10^5$). I know that Java Random class would give me all the random numbers I need, and they pass all the test I'm doing, but.. they are pseudo-random! I don't like it. I know that random number web site gives real random numbers from atmospheric noise (or something like that) but it limits the download. In particular you cannot download more than 10000 numbers with one HTTP request. So the question is: is there a way to generate more than $X$ random numbers with $X$ random numbers and infinite (...) pseudo-random?","I'm doing (with Java) a very simple simulator (Queueing Systems..) that needs many random numbers (more than $10^5$). I know that Java Random class would give me all the random numbers I need, and they pass all the test I'm doing, but.. they are pseudo-random! I don't like it. I know that random number web site gives real random numbers from atmospheric noise (or something like that) but it limits the download. In particular you cannot download more than 10000 numbers with one HTTP request. So the question is: is there a way to generate more than $X$ random numbers with $X$ random numbers and infinite (...) pseudo-random?",,"['probability', 'random']"
10,Bivariate Normal Conditional Variance,Bivariate Normal Conditional Variance,,"I am given the parameters for a bivariate normal distribution ($\mu_x, \mu_y, \sigma_x, \sigma_y,$ and $\rho$). How would I go about finding the Var($Y|X=x$)? I was able to find E[$Y|X=x$] by writing $X$ and $Y$ in terms of two standard normal variables and finding the expectation in such a manner. I am unsure how to do this for the variance. Also, how do I find the probability that both $X$ and $Y$ exceed their mean values (i.e., $P(X>\mu_x, Y > \mu_y)$)? Thanks for the help!","I am given the parameters for a bivariate normal distribution ($\mu_x, \mu_y, \sigma_x, \sigma_y,$ and $\rho$). How would I go about finding the Var($Y|X=x$)? I was able to find E[$Y|X=x$] by writing $X$ and $Y$ in terms of two standard normal variables and finding the expectation in such a manner. I am unsure how to do this for the variance. Also, how do I find the probability that both $X$ and $Y$ exceed their mean values (i.e., $P(X>\mu_x, Y > \mu_y)$)? Thanks for the help!",,"['probability', 'statistics']"
11,Infinite dice roll problem,Infinite dice roll problem,,"The following is an interview question: Two players A and B play a game rolling a fair die. If A rolls a 1, he immediately reroll, and if the reroll is less than 4 then A wins. Otherwise, B rolls. If B rolls a 6, he win, otherwise A rolls again, and so on. What is the probability A wins? My approach: I have 4 states S (initial starting state), 1, 1-{1,2,3}, 6,  and this is my markov chain matrix (note that 1-{1,2,3} is the state where Person A rolls a 1 then either 1,2,3) $ \begin{array}{c|cccc}     & \text{S} & \text{1} & \text{1-{1,2,3}} & \text{6} \\     \hline     \text{S} &  4/6 & 1/6 & 0 & 1/6 \\     \text{1} & 33/36 & 0 & 3/36 & 0 \\     \text{1-{1,2,3}} & 0 & 0 & 1 & 0 \\     \text{6} & 0 & 0 & 0 & 1 \\ \end{array} $ Using this I calculate probability of absorption to state 1-{1,2,3} and get 0.0769. Is this matrix the right set up? And is there a simpler way of doing this? Thank you!","The following is an interview question: Two players A and B play a game rolling a fair die. If A rolls a 1, he immediately reroll, and if the reroll is less than 4 then A wins. Otherwise, B rolls. If B rolls a 6, he win, otherwise A rolls again, and so on. What is the probability A wins? My approach: I have 4 states S (initial starting state), 1, 1-{1,2,3}, 6,  and this is my markov chain matrix (note that 1-{1,2,3} is the state where Person A rolls a 1 then either 1,2,3) Using this I calculate probability of absorption to state 1-{1,2,3} and get 0.0769. Is this matrix the right set up? And is there a simpler way of doing this? Thank you!","
\begin{array}{c|cccc}
    & \text{S} & \text{1} & \text{1-{1,2,3}} & \text{6} \\
    \hline
    \text{S} &  4/6 & 1/6 & 0 & 1/6 \\
    \text{1} & 33/36 & 0 & 3/36 & 0 \\
    \text{1-{1,2,3}} & 0 & 0 & 1 & 0 \\
    \text{6} & 0 & 0 & 0 & 1 \\
\end{array}
","['probability', 'dice']"
12,"The n-person hat matching problem in probability for n=3, doesn't match derangement formula","The n-person hat matching problem in probability for n=3, doesn't match derangement formula",,"Suppose all $n$ people at a party throw their hats in the center of the room. Each person then randomly selects a hat. The probability that none of the $n$ people selects their own hat is $$1/2! - 1/3! + 1/4! - ... + (-1)^n/n!$$ The formula aligns with what one could derive by using derangements. I try to compute it for $n = 3$ . Let $E_i$ be the event that the $i$ th person picks the wrong hat and $E_{ij}$ be the event that the $i$ th person picks the wrong hat by picking the $j$ th person's hat. We are looking for $P(E_1 \cap E_2 \cap E_3)$ . We know $P(E_1 \cap E_2 \cap E_3)$ = $P(E_1) * P(E_2|E_1) * P(E_3|E_1 \cap E_2)$ . We have: $P(E_1) = 2/3$ $P(E_2|E_1) = P(E_2 \cap E_1)/P(E_1)$ [Letting P(E_ij) be the probability that the ith person wrongly picks the jth person's hat.] Then, $$P(E_2 \cap E_1) = P(E_2 \cap (E_{12} \cup E_{13}))$$ $$= P((E_2 \cap E_{12}) \cup (E_2 \cap E_{13}))$$ $$= P((E_2 \cap E_{12})) + P((E_2 \cap E_{13})) - P((E_2 \cap E_{12}) \cap (E_2 \cap E_{13}))$$ $$= P((E_2 \cap E_{12})) + P((E_2 \cap E_{13}))$$ $$= P(E_{12}) * P(E_2) + P(E_{13}) *P(E_2)$$ $$= 1/3 * 1 + 1/3 *1/2$$ $$= 1/3 + 1/6$$ $$= 1/2$$ As a result, $P(E_2 | E_1) = P(E_2 \cap E_1)/P(E_1) = 1/2 * 3/2 = 3/4$ . Of course, $P(E_3|E_1 \cap E_2) = 1$ . Finally, this leads to $P(E_1 \cap E_2 \cap E_3) = 2/3 * 3/4 * 1 = 1/2$ . But according to the formula, $P(E_1 \cap E_2 \cap E_3) = 1/3$ , which is right and can be arrived at via going to complement route, i.e. by finding the probability that at least 1 person picks the right hat and subtracting that from 1. Can someone help in pointing out where I am going wrong in the derivation above? EDIT: As pointed out by the comment, the issue is in computing $P(E_3|E_1 \cap E_2)$ . Here, person 1 can pick 2's hat and 2 picks 1's hat, then 3 gets their hat for sure. Then, $P(E_3|E_1 \cap E_2) = 1 - P(E_{33}|E_{12} \cap E_{21})$ . Note that $P(E_{33}|E_{12} \cap E_{21}) = (1/3 * 1/3 * 1/3)/(1/3 * 1/3)$ . As a result, $P(E_3|E_1 \cap E_2) = 1 - 1/3 = 2/3$ . Then, we match the formula perfectly.","Suppose all people at a party throw their hats in the center of the room. Each person then randomly selects a hat. The probability that none of the people selects their own hat is The formula aligns with what one could derive by using derangements. I try to compute it for . Let be the event that the th person picks the wrong hat and be the event that the th person picks the wrong hat by picking the th person's hat. We are looking for . We know = . We have: [Letting P(E_ij) be the probability that the ith person wrongly picks the jth person's hat.] Then, As a result, . Of course, . Finally, this leads to . But according to the formula, , which is right and can be arrived at via going to complement route, i.e. by finding the probability that at least 1 person picks the right hat and subtracting that from 1. Can someone help in pointing out where I am going wrong in the derivation above? EDIT: As pointed out by the comment, the issue is in computing . Here, person 1 can pick 2's hat and 2 picks 1's hat, then 3 gets their hat for sure. Then, . Note that . As a result, . Then, we match the formula perfectly.",n n 1/2! - 1/3! + 1/4! - ... + (-1)^n/n! n = 3 E_i i E_{ij} i j P(E_1 \cap E_2 \cap E_3) P(E_1 \cap E_2 \cap E_3) P(E_1) * P(E_2|E_1) * P(E_3|E_1 \cap E_2) P(E_1) = 2/3 P(E_2|E_1) = P(E_2 \cap E_1)/P(E_1) P(E_2 \cap E_1) = P(E_2 \cap (E_{12} \cup E_{13})) = P((E_2 \cap E_{12}) \cup (E_2 \cap E_{13})) = P((E_2 \cap E_{12})) + P((E_2 \cap E_{13})) - P((E_2 \cap E_{12}) \cap (E_2 \cap E_{13})) = P((E_2 \cap E_{12})) + P((E_2 \cap E_{13})) = P(E_{12}) * P(E_2) + P(E_{13}) *P(E_2) = 1/3 * 1 + 1/3 *1/2 = 1/3 + 1/6 = 1/2 P(E_2 | E_1) = P(E_2 \cap E_1)/P(E_1) = 1/2 * 3/2 = 3/4 P(E_3|E_1 \cap E_2) = 1 P(E_1 \cap E_2 \cap E_3) = 2/3 * 3/4 * 1 = 1/2 P(E_1 \cap E_2 \cap E_3) = 1/3 P(E_3|E_1 \cap E_2) P(E_3|E_1 \cap E_2) = 1 - P(E_{33}|E_{12} \cap E_{21}) P(E_{33}|E_{12} \cap E_{21}) = (1/3 * 1/3 * 1/3)/(1/3 * 1/3) P(E_3|E_1 \cap E_2) = 1 - 1/3 = 2/3,"['probability', 'combinatorics', 'derangements']"
13,Probability of picking a uniquely colored ball successively without replacement,Probability of picking a uniquely colored ball successively without replacement,,"In a bucket, there are five different colors of balls, two of each color, making 10 in total. If you pick three balls at random without replacement, what is the probability that you pick a different colored ball each time? What is the probability that you only pick two different colored balls? I just made up a simple random scenario that demonstrates the principle/type of problem that I am trying to figure out. With the skills I acquired in pre-calculus, I would be able to solve this if it was with replacement, not without replacement. Also having several unique colors, but identical balls within each color group adds an extra layer of complexity that confuses me. What is the process to solve the problem? And, if I was to increase the number of colors, number of balls per color, or the number of times a ball is picked, could the same formula/process still be applied?","In a bucket, there are five different colors of balls, two of each color, making 10 in total. If you pick three balls at random without replacement, what is the probability that you pick a different colored ball each time? What is the probability that you only pick two different colored balls? I just made up a simple random scenario that demonstrates the principle/type of problem that I am trying to figure out. With the skills I acquired in pre-calculus, I would be able to solve this if it was with replacement, not without replacement. Also having several unique colors, but identical balls within each color group adds an extra layer of complexity that confuses me. What is the process to solve the problem? And, if I was to increase the number of colors, number of balls per color, or the number of times a ball is picked, could the same formula/process still be applied?",,"['probability', 'recreational-mathematics']"
14,Is the kth central moment less than the kth raw moment for even k?,Is the kth central moment less than the kth raw moment for even k?,,"If $X$ is a real-valued random variable, then the $k$th raw moment is $\mathbb{E}[X^k]$, while the $k$th central moment is $\mathbb{E}[(X-\mathbb{E}[X])^k]$.  If $k$ is even, is the $k$th central moment always bounded above the $k$th raw moment? When $k = 2$, then $\mathbb{E}[(X-\mathbb{E}[X])^2] = \mathbb{E}[X^2]-\mathbb{E}[X]^2$, and because $\mathbb{E}[X]^2$ is always positive, it follows that this is less than or equal to $\mathbb{E}[X^2]$.  But I'm having trouble extending this to larger moments.","If $X$ is a real-valued random variable, then the $k$th raw moment is $\mathbb{E}[X^k]$, while the $k$th central moment is $\mathbb{E}[(X-\mathbb{E}[X])^k]$.  If $k$ is even, is the $k$th central moment always bounded above the $k$th raw moment? When $k = 2$, then $\mathbb{E}[(X-\mathbb{E}[X])^2] = \mathbb{E}[X^2]-\mathbb{E}[X]^2$, and because $\mathbb{E}[X]^2$ is always positive, it follows that this is less than or equal to $\mathbb{E}[X^2]$.  But I'm having trouble extending this to larger moments.",,"['probability', 'inequality', 'expectation']"
15,"Probability ""Brain Teaser"" [duplicate]","Probability ""Brain Teaser"" [duplicate]",,"This question already has answers here : Taking Seats on a Plane (21 answers) Closed 9 years ago . I came across a ""brain teaser"" which goes like this: Bruna was first to arrive at a 100 seat theatre. She forgot her seat   number and picks a random seat for herself. After this, every single person who get to the theatre sits on his   seat if its available else chooses any available seat at random.   Neymar is last to enter the theatre and 99 seats were occupied. What's the probability what Neymar gets to sit in his own seat? The solution was $1/2$, their reasoning being that there are two possibilities, Neymar either gets his seat or not. This seems very flawed thinking to me because nothing says the two possibilities have equal probability. I calculated it as $1/100 + 1/99$, but I think this is still wrong. My reasoning was there are two scenarios which result in Neymar's seat being available, either: Bruna sits in the right seat in which case everyone also sits in their correct seat, this has a $1/100$ chance; or, Bruna sits in the wrong seat and there's a $98/99$ chance it is not Neymar's seat, then the next person has a $97/98$ chance of not sitting in Neymar's seat, and so on. Which gives $98!/99!$ or $1/99$. My confusion lies in the fact that the subsequent people in the second scenario do not always take their seat at random, they only select a random seat if their seat is occupied. How would I go about solving something like this?","This question already has answers here : Taking Seats on a Plane (21 answers) Closed 9 years ago . I came across a ""brain teaser"" which goes like this: Bruna was first to arrive at a 100 seat theatre. She forgot her seat   number and picks a random seat for herself. After this, every single person who get to the theatre sits on his   seat if its available else chooses any available seat at random.   Neymar is last to enter the theatre and 99 seats were occupied. What's the probability what Neymar gets to sit in his own seat? The solution was $1/2$, their reasoning being that there are two possibilities, Neymar either gets his seat or not. This seems very flawed thinking to me because nothing says the two possibilities have equal probability. I calculated it as $1/100 + 1/99$, but I think this is still wrong. My reasoning was there are two scenarios which result in Neymar's seat being available, either: Bruna sits in the right seat in which case everyone also sits in their correct seat, this has a $1/100$ chance; or, Bruna sits in the wrong seat and there's a $98/99$ chance it is not Neymar's seat, then the next person has a $97/98$ chance of not sitting in Neymar's seat, and so on. Which gives $98!/99!$ or $1/99$. My confusion lies in the fact that the subsequent people in the second scenario do not always take their seat at random, they only select a random seat if their seat is occupied. How would I go about solving something like this?",,['probability']
16,The probabilty of a new arrangement of 52 cards deck?,The probabilty of a new arrangement of 52 cards deck?,,"I just read this article , it claims that if you just shuffle a 52 card deck, you will mostly be creating an arrangement that no human have ever seen before. But this doesn't seem right since every time we create a new arrangement, this one is now a candidate to happen again, so every time we fail, the odds increase. How can we mathematically review this claim?","I just read this article , it claims that if you just shuffle a 52 card deck, you will mostly be creating an arrangement that no human have ever seen before. But this doesn't seem right since every time we create a new arrangement, this one is now a candidate to happen again, so every time we fail, the odds increase. How can we mathematically review this claim?",,"['probability', 'recreational-mathematics', 'card-games']"
17,Understanding a basic permutation problem,Understanding a basic permutation problem,,"I am failing to wrap my head around a solution to a rather basic problem: At a party, n men and m women put their drinks on a table and go out on the floor to dance. When they return, none of them recognizes his or her drink, so everyone takes a drink at random. What is the probability that each man selects his own drink? The solution is: $$\frac{m!}{(n+m)!}$$ From what I intuit, $n!$ is the total permutations of the drinks among the men, and the above solution is the probability that all men get another man's drink, not necessarily that each one gets his own . My solution was, there is a $\frac{1}{n+m}$ probability of the first man getting his drink, then $\frac{1}{n+m-1}$ for the second, $\frac{1}{n+m-2}$ for the third, ... , $\frac{1}{m+1}$ for the $n^{th}$ . Resulting in a probability of $\prod\limits_{i=0}^{n-1} \frac{1}{n+m-i}$ . Can someone explain their thinking when approaching this problem? EDIT Issue arose from confusing variables and failing to identify that $$ \begin{align} \frac{m!}{(n+m)!} &= \frac{m!}{(n+m)(n+m-1)...(n+m-(n-1))(m!)}\\ &= \prod\limits_{i=0}^{n-1} \frac{1}{n+m-i}\\ \end{align} $$","I am failing to wrap my head around a solution to a rather basic problem: At a party, n men and m women put their drinks on a table and go out on the floor to dance. When they return, none of them recognizes his or her drink, so everyone takes a drink at random. What is the probability that each man selects his own drink? The solution is: From what I intuit, is the total permutations of the drinks among the men, and the above solution is the probability that all men get another man's drink, not necessarily that each one gets his own . My solution was, there is a probability of the first man getting his drink, then for the second, for the third, ... , for the . Resulting in a probability of . Can someone explain their thinking when approaching this problem? EDIT Issue arose from confusing variables and failing to identify that","\frac{m!}{(n+m)!} n! \frac{1}{n+m} \frac{1}{n+m-1} \frac{1}{n+m-2} \frac{1}{m+1} n^{th} \prod\limits_{i=0}^{n-1} \frac{1}{n+m-i} 
\begin{align}
\frac{m!}{(n+m)!} &= \frac{m!}{(n+m)(n+m-1)...(n+m-(n-1))(m!)}\\
&= \prod\limits_{i=0}^{n-1} \frac{1}{n+m-i}\\
\end{align}
","['probability', 'permutations']"
18,"Why is $\operatorname{Var}[X]≤(b−a)^2/4$ if $X$ is a random variable with values between $[a,b]$",Why is  if  is a random variable with values between,"\operatorname{Var}[X]≤(b−a)^2/4 X [a,b]",I don't know how to start here. I tried to proof it with $$\operatorname{Var}(X) =  E(X^2) - [E(X)]^2$$ but this wasn't a good idea in the end.,I don't know how to start here. I tried to proof it with $$\operatorname{Var}(X) =  E(X^2) - [E(X)]^2$$ but this wasn't a good idea in the end.,,"['probability', 'variance']"
19,Translating mathematical problem statement into natural language,Translating mathematical problem statement into natural language,,"Let us consider following problem : One thousand tickets are sold at $\$1$ each for a color television valued at $\$350$. What is the expected value of the gain if you purchase one ticket? I would like to describe my basic problem related to this task. English is not my native language therefore I did not understand  logic of statement. What I know is that  we had $1000$ tickets that are sold at $\$1$ each. This means that  the total revenue from $1000$ tickets is $\$1000$. Is this correct? We have a color television that costs $\$350$. My question is: What is the expected value of the gain if you purchase one ticket, really I don't understand the connection of purchase=buy. If I bought one ticket that cost  $\$1$, and if I bought a television which costs $\$350$, then my  gain will be $\$349$ correct? If I lost, then my gain will be  $\$-1$ because I  paid this $\$1$. What about their probability? If the probability that out of $\$1000$ I will  win  is $0.001$, then the probability that I will loose is $0.999$, so expected value will be $$349\times 0.001+(-1)\times 0.999=-0.65$$ But still I do not understand logically this statement, could you  describe please in a  simple manner this  problem?","Let us consider following problem : One thousand tickets are sold at $\$1$ each for a color television valued at $\$350$. What is the expected value of the gain if you purchase one ticket? I would like to describe my basic problem related to this task. English is not my native language therefore I did not understand  logic of statement. What I know is that  we had $1000$ tickets that are sold at $\$1$ each. This means that  the total revenue from $1000$ tickets is $\$1000$. Is this correct? We have a color television that costs $\$350$. My question is: What is the expected value of the gain if you purchase one ticket, really I don't understand the connection of purchase=buy. If I bought one ticket that cost  $\$1$, and if I bought a television which costs $\$350$, then my  gain will be $\$349$ correct? If I lost, then my gain will be  $\$-1$ because I  paid this $\$1$. What about their probability? If the probability that out of $\$1000$ I will  win  is $0.001$, then the probability that I will loose is $0.999$, so expected value will be $$349\times 0.001+(-1)\times 0.999=-0.65$$ But still I do not understand logically this statement, could you  describe please in a  simple manner this  problem?",,['probability']
20,"If X is independent to Y and Z, does it imply that X is independent to YZ ?","If X is independent to Y and Z, does it imply that X is independent to YZ ?",,"After years of mathematics, I am struggling with this simple question. If we have 3 r.v. $X,Y,Z$ and we have $X$ independent to $Y$ and to $Z$, then do we have that $X$ is also independent to $YZ$ ? At first sight, I thought that if $X$ is independent to $Y$ and $Z$, it is also independent to the sigma-algebra generated by $Y$ and to $Z$ and hence $YZ$ but the example below made me confused : https://en.wikipedia.org/wiki/Pairwise_independence If someone can make this clear... Thank you very much in advance !","After years of mathematics, I am struggling with this simple question. If we have 3 r.v. $X,Y,Z$ and we have $X$ independent to $Y$ and to $Z$, then do we have that $X$ is also independent to $YZ$ ? At first sight, I thought that if $X$ is independent to $Y$ and $Z$, it is also independent to the sigma-algebra generated by $Y$ and to $Z$ and hence $YZ$ but the example below made me confused : https://en.wikipedia.org/wiki/Pairwise_independence If someone can make this clear... Thank you very much in advance !",,"['probability', 'probability-theory', 'independence']"
21,How do I transform an r.v. using the floor function? (exponential distribution),How do I transform an r.v. using the floor function? (exponential distribution),,"Just had a bash at this question for my Intro to Maths Stats module...I got to the end with a probability density function rather than a probability mass function, namely $f_Y(y) = \lambda a e^{-\lambda a y}.$ Obviously I'm missing some subtleties with the floor function that makes the new r.v. into a probability mass function instead. Anyways, here it is... Suppose $X$ is an $\text{exponential}(\lambda)$ r.v. given by 0 for $x$ < 0 and $\lambda e^{-\lambda x}$ for $x \geq 0$ . Recall the function $\lfloor x\rfloor$ is defined as the largest integer $n \leq x.$ Let $Y$ be defined by $ Y = \lfloor \frac{X}{a} \rfloor$ , where $a$ > 0. Find the probability mass function of $Y$ and hence deduce that $Y$ is a geometric r.v., stating its parameter. Thanks in advance (should be a quick one!) Sam","Just had a bash at this question for my Intro to Maths Stats module...I got to the end with a probability density function rather than a probability mass function, namely Obviously I'm missing some subtleties with the floor function that makes the new r.v. into a probability mass function instead. Anyways, here it is... Suppose is an r.v. given by 0 for < 0 and for . Recall the function is defined as the largest integer Let be defined by , where > 0. Find the probability mass function of and hence deduce that is a geometric r.v., stating its parameter. Thanks in advance (should be a quick one!) Sam",f_Y(y) = \lambda a e^{-\lambda a y}. X \text{exponential}(\lambda) x \lambda e^{-\lambda x} x \geq 0 \lfloor x\rfloor n \leq x. Y  Y = \lfloor \frac{X}{a} \rfloor a Y Y,"['probability', 'probability-distributions', 'exponential-distribution']"
22,Probability of getting exactly 2 heads in 3 coins tossed with order not important?,Probability of getting exactly 2 heads in 3 coins tossed with order not important?,,"I have been thinking of this problem for the post 3-4 hours, I have come up with this problem it is not a home work exercise Let's say I have 3 coins and I toss them, Here order is not important so possible sample space should be 0 H, 1 H, 2 HH, 3 HHH (H being heads)   TTT, HTT, HHT, HHH since P(T) and P(H) =1/2; Here we have fair coins only, Since each and every outcome is equally likely, answer should be 1/4 (is this correct) and if that is correct, all of the probabilities don't add up to one, will I have to do the manipulation to make it add up to one, or I am doing anything wrong. EDIT In my opinion, with order being not important, there should be only 4 possible outcomes. All of the answers have ignored that condition.","I have been thinking of this problem for the post 3-4 hours, I have come up with this problem it is not a home work exercise Let's say I have 3 coins and I toss them, Here order is not important so possible sample space should be 0 H, 1 H, 2 HH, 3 HHH (H being heads)   TTT, HTT, HHT, HHH since P(T) and P(H) =1/2; Here we have fair coins only, Since each and every outcome is equally likely, answer should be 1/4 (is this correct) and if that is correct, all of the probabilities don't add up to one, will I have to do the manipulation to make it add up to one, or I am doing anything wrong. EDIT In my opinion, with order being not important, there should be only 4 possible outcomes. All of the answers have ignored that condition.",,['probability']
23,Top 3 of 4 Dice Rolls,Top 3 of 4 Dice Rolls,,"I'm trying to prove why the mean of the distribution of sums of the top 3 out of 4 fair 6 sided dice is rolls 12.25.  Anybody who's rolled a D&D character knows the idea. $r_n = Rand([1,6])$ $x = \frac{\sum_{i=1}^4{r_i} - min(r_i)}{3}$ Pardon the notation, I wasn't sure how to properly define the problem. So, I came to derive 12.25 with a computer program that just does several million iterations and comes up with something that's approaching 12.25.  I just don't know why or how to prove it.  I thought of splitting the interval [1,6] into 4 equal subsets and add the midpoint of the top 3.  But that didn't work.  Can someone explain why it's 12.25 and how to prove it?","I'm trying to prove why the mean of the distribution of sums of the top 3 out of 4 fair 6 sided dice is rolls 12.25.  Anybody who's rolled a D&D character knows the idea. $r_n = Rand([1,6])$ $x = \frac{\sum_{i=1}^4{r_i} - min(r_i)}{3}$ Pardon the notation, I wasn't sure how to properly define the problem. So, I came to derive 12.25 with a computer program that just does several million iterations and comes up with something that's approaching 12.25.  I just don't know why or how to prove it.  I thought of splitting the interval [1,6] into 4 equal subsets and add the midpoint of the top 3.  But that didn't work.  Can someone explain why it's 12.25 and how to prove it?",,"['probability', 'probability-theory', 'probability-distributions']"
24,Expectation of number of trials before success in an urn problem without replacement [duplicate],Expectation of number of trials before success in an urn problem without replacement [duplicate],,This question already has answers here : Closed 12 years ago . Possible Duplicate: Expected number of draws until the first good element is chosen An urn contains $b$ blue balls and $r$ red balls. Balls are removed at random without replacement until the first blue ball is drawn. What is the expectation of the total number of balls drawn? The answer should be $\frac{b+r+1}{b+1}$ but I have not been able to prove it. I know that this seems like an easy/classic problem but I tried brute force (definition of expectation) and got a sum that I'm not able to simplify. Then I tried looking up well known distributions but none of them works for this problem.,This question already has answers here : Closed 12 years ago . Possible Duplicate: Expected number of draws until the first good element is chosen An urn contains $b$ blue balls and $r$ red balls. Balls are removed at random without replacement until the first blue ball is drawn. What is the expectation of the total number of balls drawn? The answer should be $\frac{b+r+1}{b+1}$ but I have not been able to prove it. I know that this seems like an easy/classic problem but I tried brute force (definition of expectation) and got a sum that I'm not able to simplify. Then I tried looking up well known distributions but none of them works for this problem.,,['probability']
25,Risk of AIDS Infection - Overestimation?,Risk of AIDS Infection - Overestimation?,,"As an example of a probability misunderstanding, the book ""Mathematics Statistics and Data Analysis"" by John A. Rice gives the following quote from the Los Angeles Times: ""Several studies of sexual partners of people infected with the virus show that a single act of unprotected vaginal intercourse has a surprisingly low risk of infecting the uninfected partner--perhaps one in 100 to one in 1,000. For an average, consider the risk to be one in 500. If there are 100 acts of intercourse with an infected partner, the odds of infection increase to one in five. Statistically, 500 acts of intercourse with one infected partner or 100 acts with five different infected partners lead to a 100% probability of infection (statistically, not necessarily in reality)."" The full article is here . Rice explains that this is flawed by considering just two acts of intercourse: if we let $A_1$ denote the event that infection occurs on the first act and $A_2$ the event infection occurs on the second, then the event that infection occurs is $B = A_1\cup A_2$ and $$P(B) = P(A_1) + P(A_2) - P(A_1\cap A_2) \leq P(A_1) + P(A_2) = {2 \over 500}$$ But I'm still confused: I understand that the above is trying to show that the article is overestimating, but surely the probability of $A_1 \cap A_2$ is $0$ ? You can only be infected with AIDS once... as far as I know. And even if it is not $0$ , what's stopping us from exceeding the $P = 1$ threshold eventually if we take enough events (which clearly seems nonsensical since its intuitively its clear that someone might avoid AIDS indefinitely)? Just to clarify, I'm not disagreeing that the article is flawed, I'm just struggling to locate the exact flaw. Many thanks.","As an example of a probability misunderstanding, the book ""Mathematics Statistics and Data Analysis"" by John A. Rice gives the following quote from the Los Angeles Times: ""Several studies of sexual partners of people infected with the virus show that a single act of unprotected vaginal intercourse has a surprisingly low risk of infecting the uninfected partner--perhaps one in 100 to one in 1,000. For an average, consider the risk to be one in 500. If there are 100 acts of intercourse with an infected partner, the odds of infection increase to one in five. Statistically, 500 acts of intercourse with one infected partner or 100 acts with five different infected partners lead to a 100% probability of infection (statistically, not necessarily in reality)."" The full article is here . Rice explains that this is flawed by considering just two acts of intercourse: if we let denote the event that infection occurs on the first act and the event infection occurs on the second, then the event that infection occurs is and But I'm still confused: I understand that the above is trying to show that the article is overestimating, but surely the probability of is ? You can only be infected with AIDS once... as far as I know. And even if it is not , what's stopping us from exceeding the threshold eventually if we take enough events (which clearly seems nonsensical since its intuitively its clear that someone might avoid AIDS indefinitely)? Just to clarify, I'm not disagreeing that the article is flawed, I'm just struggling to locate the exact flaw. Many thanks.",A_1 A_2 B = A_1\cup A_2 P(B) = P(A_1) + P(A_2) - P(A_1\cap A_2) \leq P(A_1) + P(A_2) = {2 \over 500} A_1 \cap A_2 0 0 P = 1,['probability']
26,What is a Borel set?,What is a Borel set?,,"I am reading DeGroot's book titled 'Optimal Statistical Decisions' in which he says the following: If $S$ is the $n$ -dimensional space $\mathbb{R}^n$ , then the $\sigma$ -field will be taken to be the $\sigma$ -field of Borel sets, i.e. , the smallest $\sigma$ -field containing all $n$ -dimensional intervals. and If the function $g$ is measurable with respect to a $\sigma$ -field and $B$ is any Borel set on the real line, then the subset $g^{-1}(B)$ of $S$ , defined by the relation $g^{-1}(B)=\{s:g(s)\in B\}$ , also belongs to the $\sigma$ -field. I have no prior exposure to measure theory and topology, hence I find these two statements difficult to comprehend. However, I do understand what a $\sigma$ -field is and the three properties that a collection of subsets of sample space $S$ must fulfill in order to become a $\sigma$ -field. I hope someone can provide a simple and concise explanation of what a Borel set is, so that I can develop a deeper understanding of these two statements above. I only want to learn from a probabilistic standpoint right now and would appreciate it if the explanation would leave out measure theory and topology altogether. Thanks.","I am reading DeGroot's book titled 'Optimal Statistical Decisions' in which he says the following: If is the -dimensional space , then the -field will be taken to be the -field of Borel sets, i.e. , the smallest -field containing all -dimensional intervals. and If the function is measurable with respect to a -field and is any Borel set on the real line, then the subset of , defined by the relation , also belongs to the -field. I have no prior exposure to measure theory and topology, hence I find these two statements difficult to comprehend. However, I do understand what a -field is and the three properties that a collection of subsets of sample space must fulfill in order to become a -field. I hope someone can provide a simple and concise explanation of what a Borel set is, so that I can develop a deeper understanding of these two statements above. I only want to learn from a probabilistic standpoint right now and would appreciate it if the explanation would leave out measure theory and topology altogether. Thanks.",S n \mathbb{R}^n \sigma \sigma \sigma n g \sigma B g^{-1}(B) S g^{-1}(B)=\{s:g(s)\in B\} \sigma \sigma S \sigma,"['probability', 'measure-theory', 'borel-sets']"
27,Arranging items in strictly increasing order,Arranging items in strictly increasing order,,"""We throw 3 dice one by one. What is the probability that we obtain 3 points in strictly increasing order""? Isn't the answer just $1/6$ as there are $3!$ possible permutations and only 1 permutation in which the 3 dice will be in strictly increasing order. However, the answer in my book is $5/54$. Similarly, for the question of ""what is the probability of 10 people being seated in strictly increasing order of age at a table?"" Wouldn't the solution be $20/10!$ as direction of the increasing order has not been specified. I think this answer is correct whilst my answer for the previous question is wrong even though I am using the same logic and I can't see why this is, when they are effectively very similar questions. Thank You","""We throw 3 dice one by one. What is the probability that we obtain 3 points in strictly increasing order""? Isn't the answer just $1/6$ as there are $3!$ possible permutations and only 1 permutation in which the 3 dice will be in strictly increasing order. However, the answer in my book is $5/54$. Similarly, for the question of ""what is the probability of 10 people being seated in strictly increasing order of age at a table?"" Wouldn't the solution be $20/10!$ as direction of the increasing order has not been specified. I think this answer is correct whilst my answer for the previous question is wrong even though I am using the same logic and I can't see why this is, when they are effectively very similar questions. Thank You",,['probability']
28,A couple has 2 children. What is the probability that both are girls if the eldest is a girl?,A couple has 2 children. What is the probability that both are girls if the eldest is a girl?,,"This is another question like this one . And by the same reason, the book only has the final answer, I'd like to check if my reasoning is right. A couple has 2 children. What is the probability that both are girls if the eldest is a girl?","This is another question like this one . And by the same reason, the book only has the final answer, I'd like to check if my reasoning is right. A couple has 2 children. What is the probability that both are girls if the eldest is a girl?",,"['probability', 'conditional-probability']"
29,Variance of Binomial Distribution $E[X^2]$,Variance of Binomial Distribution,E[X^2],"so I'm trying to use the equation: $Var(X) = E[X^2] - (E[x])^2$, And for the $E[X^2]$ part, I'm trying to use the method of indicators... However, when I do that, I get the same value as with $E[X]$... Is it wrong to try to use the method of indicators for this case? Basically, I end up with $Var(X) = np(1-np)$,  when it should be $Var(X) = np(1-p)$.","so I'm trying to use the equation: $Var(X) = E[X^2] - (E[x])^2$, And for the $E[X^2]$ part, I'm trying to use the method of indicators... However, when I do that, I get the same value as with $E[X]$... Is it wrong to try to use the method of indicators for this case? Basically, I end up with $Var(X) = np(1-np)$,  when it should be $Var(X) = np(1-p)$.",,['probability']
30,How to prove Boole’s inequality,How to prove Boole’s inequality,,I am trying to prove Boole’s inequality $$P\left(\ \bigcup_{i=1}^\infty A_i\right) \leq \sum_{i=1}^\infty P(A_i).$$ I can show it of any finite $n$ using induction. What to do for $\infty$ ?,I am trying to prove Boole’s inequality $$P\left(\ \bigcup_{i=1}^\infty A_i\right) \leq \sum_{i=1}^\infty P(A_i).$$ I can show it of any finite $n$ using induction. What to do for $\infty$ ?,,['probability']
31,How to calculate Pr(Diseased | 2 Positive Tests)?,How to calculate Pr(Diseased | 2 Positive Tests)?,,"Diagnosed with a rare disease, you know that there is only a 1% chance of getting it. Abbreviate D as the event ""you have the disease"" and T as ""you test positive for the disease."" The test is imperfect: $\Pr(T | D) = 0.98$ and $\Pr(T^C | D^C) = 0.95.$ $\large{A.}$ Given that you test positive, what is the probability that you really have the disease? $\large{B.}$  You obtain a second opinion: an independent repetition of the test. You test positive again. given two positive tests, what is the probability that you really have the disease? So, first question I have is this: Does $\Pr(T | D^C) = 1 - 0.95 = 0.05$? This would mean that $P(T) = P(T | D) + P (T | D^C) = 0.98 + 0.05 = 1.03$ ...? This can't be right...P(T) can't be 1.03! Is there an error in this question? Then, here's my strategy for solving part A: Calculate $\Pr(D | T) = \dfrac{P(T \cap D) }{ P(T) } = \dfrac{ P(T | D) \times P(D) }{ P(T) } $ UPDATE: Here is a hint from the professor: During office hours today, the following hint came up that I thought would be good to share with the entire class for part B above. Let's define two events T (first test positive) and S (second test positive). When you use Bayes' rule, you are going to need to figure out how to compute the total probability $\Pr(T \cap S)$. To do this, you should assume that these two tests are independent, and therefore you will get: $\Pr(T \cap S | D) = P(T | D) * P(S | D) \quad$ and $\quad \Pr(T \cap S | D^c) = P(T | D^c) * P(S | D^c)$. A point to remember here is that the rules of probability stay the same for conditional probability if the event on the right of the ""|"" stays constant. For instance, the complement rule looks like this: $P(A^c | B) = 1 - P(A | B)$. The other rules we have learned work out similarly.","Diagnosed with a rare disease, you know that there is only a 1% chance of getting it. Abbreviate D as the event ""you have the disease"" and T as ""you test positive for the disease."" The test is imperfect: $\Pr(T | D) = 0.98$ and $\Pr(T^C | D^C) = 0.95.$ $\large{A.}$ Given that you test positive, what is the probability that you really have the disease? $\large{B.}$  You obtain a second opinion: an independent repetition of the test. You test positive again. given two positive tests, what is the probability that you really have the disease? So, first question I have is this: Does $\Pr(T | D^C) = 1 - 0.95 = 0.05$? This would mean that $P(T) = P(T | D) + P (T | D^C) = 0.98 + 0.05 = 1.03$ ...? This can't be right...P(T) can't be 1.03! Is there an error in this question? Then, here's my strategy for solving part A: Calculate $\Pr(D | T) = \dfrac{P(T \cap D) }{ P(T) } = \dfrac{ P(T | D) \times P(D) }{ P(T) } $ UPDATE: Here is a hint from the professor: During office hours today, the following hint came up that I thought would be good to share with the entire class for part B above. Let's define two events T (first test positive) and S (second test positive). When you use Bayes' rule, you are going to need to figure out how to compute the total probability $\Pr(T \cap S)$. To do this, you should assume that these two tests are independent, and therefore you will get: $\Pr(T \cap S | D) = P(T | D) * P(S | D) \quad$ and $\quad \Pr(T \cap S | D^c) = P(T | D^c) * P(S | D^c)$. A point to remember here is that the rules of probability stay the same for conditional probability if the event on the right of the ""|"" stays constant. For instance, the complement rule looks like this: $P(A^c | B) = 1 - P(A | B)$. The other rules we have learned work out similarly.",,['probability']
32,Finding the probability that at least 8 houses in a row are of same colour.,Finding the probability that at least 8 houses in a row are of same colour.,,"There are 400 houses in a row. Each house is to be coloured with any of the following five colours: red, blue, green, yellow, and white. The colour of each house is to be chosen randomly from among these five colours and independent of any other selection. Now, what is the probability that at least 8 houses in a row will have the same colour? My idea is to first calculate the number of ways in which there are at least 8 red-coloured houses in a row. Then do the same for green, then blue, yellow and white ( ${R}\to{G}\to{B}\to{Y}\to{W}$ ). Suppose, $ n(R) $ denotes the number of ways that there are 8 red-coloured houses in a row. So, $$n(R) = (number\ of\ ways\ to\ choose\ one\ row\ of\ 8\ houses\ from\ 400\ houses)\times(number\ of\ ways\ rest\ of\ the\ houses\ can\ be\ painted) = \mathrm{393}\!\cdot\!\mathrm{5^{392}} $$ Now, $$ n(R) = n(G) = n(B) = n(Y) = n(W)$$ Initially I was careless to conclude that the required probility will be, $$ p = \frac{n(R) + n(G) + n(B) + n(Y) + n(W)}{5^{400}}$$ But a few moments later I realised that there is a lot of double-counting in this solution. (For example, when calculating $n(R)$ , you can take 1st 8 houses to be red, and the rest the 392 houses are randomly coloured. This will include the case that last 8 houses in a row are red. So, when you come to choose last 8 houses to be red, there will be an occasion when first 8 houses become red-coloured. Similarly there are so many ways that double counting is happening.) What should be done?","There are 400 houses in a row. Each house is to be coloured with any of the following five colours: red, blue, green, yellow, and white. The colour of each house is to be chosen randomly from among these five colours and independent of any other selection. Now, what is the probability that at least 8 houses in a row will have the same colour? My idea is to first calculate the number of ways in which there are at least 8 red-coloured houses in a row. Then do the same for green, then blue, yellow and white ( ). Suppose, denotes the number of ways that there are 8 red-coloured houses in a row. So, Now, Initially I was careless to conclude that the required probility will be, But a few moments later I realised that there is a lot of double-counting in this solution. (For example, when calculating , you can take 1st 8 houses to be red, and the rest the 392 houses are randomly coloured. This will include the case that last 8 houses in a row are red. So, when you come to choose last 8 houses to be red, there will be an occasion when first 8 houses become red-coloured. Similarly there are so many ways that double counting is happening.) What should be done?",{R}\to{G}\to{B}\to{Y}\to{W}  n(R)  n(R) = (number\ of\ ways\ to\ choose\ one\ row\ of\ 8\ houses\ from\ 400\ houses)\times(number\ of\ ways\ rest\ of\ the\ houses\ can\ be\ painted) = \mathrm{393}\!\cdot\!\mathrm{5^{392}}   n(R) = n(G) = n(B) = n(Y) = n(W)  p = \frac{n(R) + n(G) + n(B) + n(Y) + n(W)}{5^{400}} n(R),"['probability', 'combinatorics', 'combinations']"
33,Probability about switching choices,Probability about switching choices,,"This question is similar to the Monty Hall problem, but this problem I don't understand: There are $99$ doors where $33$ doors have cars and $66$ have goats, and you can only choose one door to win a car. After you make your choice, $33$ other doors are opened to reveal goats. Does your probability of winning a car increase if you decide to switch your door choice? So obviously in the beginning your one door has a $\frac{33}{99}$ or $\frac{1}{3}$ chance of having a car. But I can't tell if switching doors in this case will be better or not, since we don't know what the groupings of the doors are (otherwise we would've won by knowing which group the $33$ cars are in).","This question is similar to the Monty Hall problem, but this problem I don't understand: There are $99$ doors where $33$ doors have cars and $66$ have goats, and you can only choose one door to win a car. After you make your choice, $33$ other doors are opened to reveal goats. Does your probability of winning a car increase if you decide to switch your door choice? So obviously in the beginning your one door has a $\frac{33}{99}$ or $\frac{1}{3}$ chance of having a car. But I can't tell if switching doors in this case will be better or not, since we don't know what the groupings of the doors are (otherwise we would've won by knowing which group the $33$ cars are in).",,"['probability', 'monty-hall']"
34,Probability of 4 consecutive heads in 10 coin tosses [duplicate],Probability of 4 consecutive heads in 10 coin tosses [duplicate],,"This question already has answers here : Probability of tossing a fair coin with at least $k$ consecutive heads (5 answers) Closed 5 years ago . I am trying to compute the probability of having 4 (or more) consecutive heads in 10 coin tosses. I tried using recursion but it led to a complicated expression so i think i did not quite manage. I saw similar questions asked here that were solved with difficult approaches, but this problem looks like it could be solved in a couple of lines so I must be doing something wrong. If anyone could help me understand it or propose a different approach for solving the problem i would be very grateful. Have a nice day!","This question already has answers here : Probability of tossing a fair coin with at least $k$ consecutive heads (5 answers) Closed 5 years ago . I am trying to compute the probability of having 4 (or more) consecutive heads in 10 coin tosses. I tried using recursion but it led to a complicated expression so i think i did not quite manage. I saw similar questions asked here that were solved with difficult approaches, but this problem looks like it could be solved in a couple of lines so I must be doing something wrong. If anyone could help me understand it or propose a different approach for solving the problem i would be very grateful. Have a nice day!",,"['probability', 'probability-theory', 'discrete-mathematics']"
35,"Probability Theory, Symmetric Difference","Probability Theory, Symmetric Difference",,"I'm trying to show this property of the symmetric difference between two sets defined for two sets in a universe $A$ and $B$ by $$ A\Delta B=(A\cap B^{c})\cup(B\cap A^{c}) $$ I need to show that  $$ \mathbb{P}(A\Delta C)\leq \mathbb{P}(A\Delta B)+\mathbb{P}(B\Delta C) $$ for sets $A, B,$ and $C$ in the universe. I showed in the first part of the problem that  $$ \mathbb{P}(A\Delta B)=\mathbb{P}(A)+\mathbb{P}(B)-2\mathbb{P}(A\cap B) $$ My idea was to note that $$ \mathbb{P}(A\Delta C)\leq\mathbb{P}(A\cap C^{c})+\mathbb{P}(C\cap A^{c}) $$ by probability laws and then leverage the fact that for any set I can write it as a union with another set. That is $$ \mathbb{P}(A)=\mathbb{P}(A\cap B)+\mathbb{P}(B^{c}\cap A) $$ and likewise for $C$ to substitute in for $P(A)$ and $P(B)$ terms. However, I end up running in circles. My TA did say I was on the right track, though. Any suggestions would be helpful. Thanks.","I'm trying to show this property of the symmetric difference between two sets defined for two sets in a universe $A$ and $B$ by $$ A\Delta B=(A\cap B^{c})\cup(B\cap A^{c}) $$ I need to show that  $$ \mathbb{P}(A\Delta C)\leq \mathbb{P}(A\Delta B)+\mathbb{P}(B\Delta C) $$ for sets $A, B,$ and $C$ in the universe. I showed in the first part of the problem that  $$ \mathbb{P}(A\Delta B)=\mathbb{P}(A)+\mathbb{P}(B)-2\mathbb{P}(A\cap B) $$ My idea was to note that $$ \mathbb{P}(A\Delta C)\leq\mathbb{P}(A\cap C^{c})+\mathbb{P}(C\cap A^{c}) $$ by probability laws and then leverage the fact that for any set I can write it as a union with another set. That is $$ \mathbb{P}(A)=\mathbb{P}(A\cap B)+\mathbb{P}(B^{c}\cap A) $$ and likewise for $C$ to substitute in for $P(A)$ and $P(B)$ terms. However, I end up running in circles. My TA did say I was on the right track, though. Any suggestions would be helpful. Thanks.",,"['probability', 'elementary-set-theory']"
36,"If $P(A \ \cup \ B) = P(A) + P(B)$, is it the case that $A$ and $B$ are disjoint?","If , is it the case that  and  are disjoint?",P(A \ \cup \ B) = P(A) + P(B) A B,"I know that if $A$ and $B$ are disjoint events, then $P(A \cup \ B) = P(A) + P(B)$. However, is the converse true as well? Thanks.","I know that if $A$ and $B$ are disjoint events, then $P(A \cup \ B) = P(A) + P(B)$. However, is the converse true as well? Thanks.",,['probability']
37,Probability that $A$ need more coin tosses to get two consecutive heads than $B$ need to get three consecutive heads,Probability that  need more coin tosses to get two consecutive heads than  need to get three consecutive heads,A B,Two people $A$ and $B$ throw fair coins independently. Let $M$ be the number of coin tosses until $A$ gets two consecutive heads. Let $N$ be the number of coin tosses until $B$ gets three consecutive heads. What is the probability that $M>N$?,Two people $A$ and $B$ throw fair coins independently. Let $M$ be the number of coin tosses until $A$ gets two consecutive heads. Let $N$ be the number of coin tosses until $B$ gets three consecutive heads. What is the probability that $M>N$?,,['probability']
38,Probability of Defective coins,Probability of Defective coins,,Among 100 coins one is defective: it has two heads. One chooses a coin (a good or bad one) and tosses it 10  times. It turns out that the head comes out all 10 times. What is the probability that the head comes out again  when the coin is tossed one more time?,Among 100 coins one is defective: it has two heads. One chooses a coin (a good or bad one) and tosses it 10  times. It turns out that the head comes out all 10 times. What is the probability that the head comes out again  when the coin is tossed one more time?,,['probability']
39,Probability of difference of random variables,Probability of difference of random variables,,"How can I compute this probability? I do not know what to do since it involves two random variables. Let $X$ and $Y$ be uniform random variables on $(0,1)$. How can I compute this? $$ P(|X-Y| < 0.25). $$ I tried to do it using an integral $$ \int_0^1 P(|X-y| < 0.25) \,dy $$ but I do not know what to do next. edit: I forgot to mention the independence of the random variables. Thanks for warning.","How can I compute this probability? I do not know what to do since it involves two random variables. Let $X$ and $Y$ be uniform random variables on $(0,1)$. How can I compute this? $$ P(|X-Y| < 0.25). $$ I tried to do it using an integral $$ \int_0^1 P(|X-y| < 0.25) \,dy $$ but I do not know what to do next. edit: I forgot to mention the independence of the random variables. Thanks for warning.",,"['probability', 'uniform-distribution']"
40,Multiple Conditioning on Event Probabilities,Multiple Conditioning on Event Probabilities,,"I am trying to understand what's wrong with the following logic related to ""multiple conditioning."" Why is the probability of [(A given B) given C] not the same as the probability of [A given (B and C)] ? I know it's not true, but only because numbers disagree. I am having a hard time parsing what's wrong with the logic.","I am trying to understand what's wrong with the following logic related to ""multiple conditioning."" Why is the probability of [(A given B) given C] not the same as the probability of [A given (B and C)] ? I know it's not true, but only because numbers disagree. I am having a hard time parsing what's wrong with the logic.",,"['probability', 'nonclassical-logic']"
41,Probability for twelve dice,Probability for twelve dice,,"In 'An Introduction to Probability Theory and Applications' by W. Feller I encountered this apparently innocuous problem. A throw of twelve dice can result in   $6^{12}$ different outcomes, to all of   which we attribute equal   probabilities. The event that each   face appears twice can occur in as   many ways as twelve dice can be   arranged in six groups of two each.   Hence the probability of the event is   $\displaystyle \frac{12!}{2^{6}6^{12}}=0.003438$. The reasoning is that by doing that you're grouping two 1's, two 2's, ..., two 6's (each group using one partition in the multinomial) and the result is the number of different partitions that can be found with that particular characteristic. However, I had doubts about that answer. To understand better that problem, I did a simpler example with $4$ dice instead of $12$ (in this case, the event is the number of ways in which two faces appear twice). Using the same result I get as the probability $\displaystyle \frac{4!}{2^{2}6^{4}}=$ 0.46 $0.0046$. Then, to see if that's true I ran a little simulation of this case in Mathematica: dice = Table[Table[Random[Integer, {1, 6}], {i, 1, 4}],  {j, 1, 1000000}]; i=0; f[{a_, b_, c_, d_}] := Which[a === b && c === d && a != c,  i++, a === c && b === d && a != b,  i++, a === d && b === c && a != b, i++;]; Map[f, dice, {1}]; After $1000000$ steps I got $69687$ cases in which two faces appear twice. This is equivalent to a probability of $0.069687$. Far smaller than what I expected based on the calculation above. Since this latter example is much more manageable than the one with twelve dice, I did the following With four dice we have the following: Partition $r_{1}$ contains the first and second dice and partition $r_{2}$ contains the third and fourth dice. Partition $r_{1}$ contains the second and fourth dice and partition $r_{2}$ contains the first and fourth third. Partition $r_{1}$ contains the first and fourth dice and partition $r_{2}$ contains the second and third dice. Partition $r_{2}$ contains the first and second dice and partition $r_{1}$ contains the third and fourth dice. Partition $r_{2}$ contains the second and fourth dice and partition $r_{1}$ contains the first and fourth third. Partition $r_{2}$ contains the first and fourth dice and partition $r_{1}$ contains the second and third dice. For each case, we can have $30$ outcomes in which two faces appear two times. For example, for the first case we have $1122, 1133, 1144, 1 155, 1166, 2211, 2233, 2244,2255, 2266,... 6611, 6622, 6633, 6644, 6655$. However, such outcomes are repeated twice (particularly, the outcomes of case 1 repeat the outcomes of case 4, etc). Therefore, the number of different outcomes which produce two faces appearing two times are $\frac{6}{2}6*5=90$. Since there are $6^{4}$ outcomes, we have a probability of $\frac{90}{6^{4}}=0.0694444$, which is the result that produces the simulation in Mathematica. Is it wrong the first reasoning? If so, is there a general approach to use the multinomial coefficient to solve this kind of problems. For instance, it appears that this only happens for $r_{1}=r_{2}=r_{k}$. Otherwise, there are not repeated outcomes.","In 'An Introduction to Probability Theory and Applications' by W. Feller I encountered this apparently innocuous problem. A throw of twelve dice can result in   $6^{12}$ different outcomes, to all of   which we attribute equal   probabilities. The event that each   face appears twice can occur in as   many ways as twelve dice can be   arranged in six groups of two each.   Hence the probability of the event is   $\displaystyle \frac{12!}{2^{6}6^{12}}=0.003438$. The reasoning is that by doing that you're grouping two 1's, two 2's, ..., two 6's (each group using one partition in the multinomial) and the result is the number of different partitions that can be found with that particular characteristic. However, I had doubts about that answer. To understand better that problem, I did a simpler example with $4$ dice instead of $12$ (in this case, the event is the number of ways in which two faces appear twice). Using the same result I get as the probability $\displaystyle \frac{4!}{2^{2}6^{4}}=$ 0.46 $0.0046$. Then, to see if that's true I ran a little simulation of this case in Mathematica: dice = Table[Table[Random[Integer, {1, 6}], {i, 1, 4}],  {j, 1, 1000000}]; i=0; f[{a_, b_, c_, d_}] := Which[a === b && c === d && a != c,  i++, a === c && b === d && a != b,  i++, a === d && b === c && a != b, i++;]; Map[f, dice, {1}]; After $1000000$ steps I got $69687$ cases in which two faces appear twice. This is equivalent to a probability of $0.069687$. Far smaller than what I expected based on the calculation above. Since this latter example is much more manageable than the one with twelve dice, I did the following With four dice we have the following: Partition $r_{1}$ contains the first and second dice and partition $r_{2}$ contains the third and fourth dice. Partition $r_{1}$ contains the second and fourth dice and partition $r_{2}$ contains the first and fourth third. Partition $r_{1}$ contains the first and fourth dice and partition $r_{2}$ contains the second and third dice. Partition $r_{2}$ contains the first and second dice and partition $r_{1}$ contains the third and fourth dice. Partition $r_{2}$ contains the second and fourth dice and partition $r_{1}$ contains the first and fourth third. Partition $r_{2}$ contains the first and fourth dice and partition $r_{1}$ contains the second and third dice. For each case, we can have $30$ outcomes in which two faces appear two times. For example, for the first case we have $1122, 1133, 1144, 1 155, 1166, 2211, 2233, 2244,2255, 2266,... 6611, 6622, 6633, 6644, 6655$. However, such outcomes are repeated twice (particularly, the outcomes of case 1 repeat the outcomes of case 4, etc). Therefore, the number of different outcomes which produce two faces appearing two times are $\frac{6}{2}6*5=90$. Since there are $6^{4}$ outcomes, we have a probability of $\frac{90}{6^{4}}=0.0694444$, which is the result that produces the simulation in Mathematica. Is it wrong the first reasoning? If so, is there a general approach to use the multinomial coefficient to solve this kind of problems. For instance, it appears that this only happens for $r_{1}=r_{2}=r_{k}$. Otherwise, there are not repeated outcomes.",,"['probability', 'dice']"
42,Why Is The Fisher Information Important?,Why Is The Fisher Information Important?,,"I am struggling to understand the relationship between the Fisher Information and the Variance. So far, what I understand: Given a specific choice of Probability Distribution Function, the partial derivative of the Natural Logarithm of the corresponding Likelihood Function is called the Score Function If we square the Score Function and take its Expected Value - this is the Fisher Information (note: when there are multiple parameters, the Fisher Information will be a Matrix) Now, the important result from the above, is that apparently: The (Negative) Inverse of The Fisher Information is equal to Variance As an example, suppose you successfully evaluate the Fisher Information and have a Matrix containing the Fisher Information for all parameters (i.e. if the original Probability Distribution Function has ""p"" parameters, this will be a ""p x p"" Matrix) - if you can somehow manage to take the Inverse of this Matrix, the diagonal components of this matrix will contain the Variance Formulae for each of these parameters. This seems to be a very important fact which is likely very useful in calculating the variance estimates for any probability distribution - but I am not sure why this is true. I tried to consult different references online (e.g. videos, university lecture notes), but I could not come across a source which demonstrated why this result is true. Can someone please help me (i.e. walk me through the math) behind why the (Negative) Inverse of the Fisher Information is equal to the Variance? Is there a proof for this? Thanks!","I am struggling to understand the relationship between the Fisher Information and the Variance. So far, what I understand: Given a specific choice of Probability Distribution Function, the partial derivative of the Natural Logarithm of the corresponding Likelihood Function is called the Score Function If we square the Score Function and take its Expected Value - this is the Fisher Information (note: when there are multiple parameters, the Fisher Information will be a Matrix) Now, the important result from the above, is that apparently: The (Negative) Inverse of The Fisher Information is equal to Variance As an example, suppose you successfully evaluate the Fisher Information and have a Matrix containing the Fisher Information for all parameters (i.e. if the original Probability Distribution Function has ""p"" parameters, this will be a ""p x p"" Matrix) - if you can somehow manage to take the Inverse of this Matrix, the diagonal components of this matrix will contain the Variance Formulae for each of these parameters. This seems to be a very important fact which is likely very useful in calculating the variance estimates for any probability distribution - but I am not sure why this is true. I tried to consult different references online (e.g. videos, university lecture notes), but I could not come across a source which demonstrated why this result is true. Can someone please help me (i.e. walk me through the math) behind why the (Negative) Inverse of the Fisher Information is equal to the Variance? Is there a proof for this? Thanks!",,"['probability', 'statistics', 'fisher-information']"
43,The way to produce a random but ordered series of numbers?,The way to produce a random but ordered series of numbers?,,"(Assume that ""Rand()"" can produce truly random real number so we can only produce truly random number through this function.) The common way is to produce a disordered sequence firstly and then sort them. But my question is, can we find a faster way to do this? Since it's ordered, maybe we can let an initial number grow bigger randomly and then we get an ordered sequence directly with no need to sort it, but it is difficult to guarantee its randomness. Is it possible? I am a high school student and just curious about the answer.","(Assume that ""Rand()"" can produce truly random real number so we can only produce truly random number through this function.) The common way is to produce a disordered sequence firstly and then sort them. But my question is, can we find a faster way to do this? Since it's ordered, maybe we can let an initial number grow bigger randomly and then we get an ordered sequence directly with no need to sort it, but it is difficult to guarantee its randomness. Is it possible? I am a high school student and just curious about the answer.",,"['probability', 'computational-complexity']"
44,Find the probability that the card number 18 is the second jack that you deal.,Find the probability that the card number 18 is the second jack that you deal.,,"You deal from a well-shuffled $52$ -card deck, one card at a time. Find the probability that the card number 18 is the second jack that you deal. Include at least $4$ digits after the decimal point in your answer. I have tried this numerous different ways, but I cant seem to get it. I've tried $$\frac{\dbinom{48}{16} \cdot \dfrac{4}{52}}{\dbinom{52}{16} \cdot \dfrac{3}{35}}$$ and I don't know why this doesn't work.","You deal from a well-shuffled -card deck, one card at a time. Find the probability that the card number 18 is the second jack that you deal. Include at least digits after the decimal point in your answer. I have tried this numerous different ways, but I cant seem to get it. I've tried and I don't know why this doesn't work.",52 4 \frac{\dbinom{48}{16} \cdot \dfrac{4}{52}}{\dbinom{52}{16} \cdot \dfrac{3}{35}},"['probability', 'combinatorics']"
45,Correlated joint normal distribution: calculating a probability,Correlated joint normal distribution: calculating a probability,,"Given $$ f_{XY}(x,y) = \frac{1}{2\pi \sqrt{1-\rho^2}} \exp \left( -\frac{x^2 +y^2 - 2\rho xy}{2(1-\rho^2)} \right) $$ $Y = Z\sqrt{1-\rho^2} + \rho X$ And $$ f_{XZ}(x,z) = \frac{1}{2\pi } \exp \left( -\frac{x^2 +z^2}{2} \right) $$ Show that $P(X>0,Y>0)= \frac{1}{4}+\frac{1}{2\pi}(\arcsin \rho) $ I'm supposed to use the fact that X and Z are independent standard normal random variables, but I don't quite understand how. Any help would be greatly appreciated.","Given $$ f_{XY}(x,y) = \frac{1}{2\pi \sqrt{1-\rho^2}} \exp \left( -\frac{x^2 +y^2 - 2\rho xy}{2(1-\rho^2)} \right) $$ $Y = Z\sqrt{1-\rho^2} + \rho X$ And $$ f_{XZ}(x,z) = \frac{1}{2\pi } \exp \left( -\frac{x^2 +z^2}{2} \right) $$ Show that $P(X>0,Y>0)= \frac{1}{4}+\frac{1}{2\pi}(\arcsin \rho) $ I'm supposed to use the fact that X and Z are independent standard normal random variables, but I don't quite understand how. Any help would be greatly appreciated.",,"['probability', 'probability-theory', 'random-variables', 'normal-distribution']"
46,"Independent coin tosses , double or halve current sum","Independent coin tosses , double or halve current sum",,"(Quant job Interviews - Questions and Answers - Joshi et al, Question 3.5) Suppose you have a fair coin. You start with 1 dollar, and if you toss a H your position doubles, if you toss a T your position halves. What is the expected value of the money you have if you toss the coin to infinity ? Now the answer is stated as follows: We work out what happens with one toss, then $n$ tosses and then let $n$ tend to infinity.  Let $X$ denote a toss then: $$\mathbb E (X) = \frac{1}{2} \cdot 2 + \frac{1}{2} \cdot 0.5= {5\over4} $$ Provided the tosses are independent, the product of expectations is the expectation of the product. Let $X_j$ be the effect of toss $j$ . This means that $$ \mathbb E \left(\prod_{j=1}^n X_j\right) = \prod_{j=1}^n \mathbb E (X_j) = \left({5\over4}\right)^n$$ this clearly tends to infinity as $n$ tends to infinity Now, I don't understand this answer :( First, the way the answer is written out, surely the ${5\over4}$ is the expectation of the outcome of the first toss $X_1$ , not that of a toss $X_j , j \ge 1$ ? Secondly, whilst I do understand that the tosses are independent, it would seem that the $X_{j+1}$ is actually quite heavily dependent on the $X_{j}$ before it ? So then why is it so obvious that $\mathbb E ( X_{j+1} ) = \mathbb E ( X_j)$ ?","(Quant job Interviews - Questions and Answers - Joshi et al, Question 3.5) Suppose you have a fair coin. You start with 1 dollar, and if you toss a H your position doubles, if you toss a T your position halves. What is the expected value of the money you have if you toss the coin to infinity ? Now the answer is stated as follows: We work out what happens with one toss, then tosses and then let tend to infinity.  Let denote a toss then: Provided the tosses are independent, the product of expectations is the expectation of the product. Let be the effect of toss . This means that this clearly tends to infinity as tends to infinity Now, I don't understand this answer :( First, the way the answer is written out, surely the is the expectation of the outcome of the first toss , not that of a toss ? Secondly, whilst I do understand that the tosses are independent, it would seem that the is actually quite heavily dependent on the before it ? So then why is it so obvious that ?","n n X \mathbb E (X) = \frac{1}{2} \cdot 2 + \frac{1}{2} \cdot 0.5= {5\over4}  X_j j  \mathbb E \left(\prod_{j=1}^n X_j\right) = \prod_{j=1}^n \mathbb E (X_j) = \left({5\over4}\right)^n n {5\over4} X_1 X_j , j \ge 1 X_{j+1} X_{j} \mathbb E ( X_{j+1} ) = \mathbb E ( X_j)","['probability', 'expected-value']"
47,Mean and Variance of the Weibull Distribution,Mean and Variance of the Weibull Distribution,,"The density of the Weibull Distribution is given by: $$f(x) = \alpha x^{\alpha-1}e^{-x^{\alpha}}$$ The Gamma function is defined as: $$\Gamma(\alpha)=\int_{0}^{\infty}x^{\alpha-1}e^{-x} \,dx$$ Show that $E(X)=\Gamma(\frac{1}{\alpha}+1)$ and $Var(X)=\Gamma(\frac{2}{\alpha}+1)-\Gamma^2(\frac{1}{\alpha} + 1)$","The density of the Weibull Distribution is given by: $$f(x) = \alpha x^{\alpha-1}e^{-x^{\alpha}}$$ The Gamma function is defined as: $$\Gamma(\alpha)=\int_{0}^{\infty}x^{\alpha-1}e^{-x} \,dx$$ Show that $E(X)=\Gamma(\frac{1}{\alpha}+1)$ and $Var(X)=\Gamma(\frac{2}{\alpha}+1)-\Gamma^2(\frac{1}{\alpha} + 1)$",,['probability']
48,Expected number of triangles in a random graph of size $n$,Expected number of triangles in a random graph of size,n,"Consider the set $V = \{1,2,\ldots,n\}$ and let $p$ be a real number with  $0<p<1$. We construct a graph $G=(V,E)$ with vertex set $V$, whose  edge set $E$ is determined by the following random process:  Each unordered pair $\{i,j\}$ of vertices, where $i \neq j$, occurs as  an edge in $E$ with probability $p$, independently of the other  unordered pairs. A triangle in $G$ is an unordered triple $\{i,j,k\}$ of distinct  vertices, such that $\{i,j\}$, $\{j,k\}$, and $\{k,i\}$ are edges in $G$. Define the random variable $X$ to be the total number of  triangles in the graph $G$. Determine the expected value $E(X)$.","Consider the set $V = \{1,2,\ldots,n\}$ and let $p$ be a real number with  $0<p<1$. We construct a graph $G=(V,E)$ with vertex set $V$, whose  edge set $E$ is determined by the following random process:  Each unordered pair $\{i,j\}$ of vertices, where $i \neq j$, occurs as  an edge in $E$ with probability $p$, independently of the other  unordered pairs. A triangle in $G$ is an unordered triple $\{i,j,k\}$ of distinct  vertices, such that $\{i,j\}$, $\{j,k\}$, and $\{k,i\}$ are edges in $G$. Define the random variable $X$ to be the total number of  triangles in the graph $G$. Determine the expected value $E(X)$.",,"['probability', 'expectation', 'random-graphs']"
49,"If $X$ is normal, is $\exp(X)$ still normal? How to find its mean and variance?","If  is normal, is  still normal? How to find its mean and variance?",X \exp(X),"$X$ is a random variable for normal distribution: $X\sim N(\mu, \sigma^2)$ . What is the mean and variance of $e^{X}$ ? My attempt: $$E[e^{X}]=e^{E[x]} \text{, by the invariance property?}$$ $$\operatorname{var}(e^{x})=e^{\operatorname{var}(x)}, \text{ similarly}$$ This looks too easy, probably not right. Should I look at $e^{X}$ as a whole.  use moment generating function? But normal pdf requires $e^{x^2}$ .  I'm stuck.","is a random variable for normal distribution: . What is the mean and variance of ? My attempt: This looks too easy, probably not right. Should I look at as a whole.  use moment generating function? But normal pdf requires .  I'm stuck.","X X\sim N(\mu, \sigma^2) e^{X} E[e^{X}]=e^{E[x]} \text{, by the invariance property?} \operatorname{var}(e^{x})=e^{\operatorname{var}(x)}, \text{ similarly} e^{X} e^{x^2}","['probability', 'probability-distributions', 'normal-distribution', 'moment-generating-functions']"
50,What does the notation $P[X\in dx]$ mean?,What does the notation  mean?,P[X\in dx],"I am studying probability, specifically regular conditional distributions, and came across the notation $P[X\in dx]$. What does this mean? Here, $X$ is a random variable and $P$ is a probability measure. I am also curious about $$\frac{P[Y\in dy\ |\ X=x]}{dy}.$$","I am studying probability, specifically regular conditional distributions, and came across the notation $P[X\in dx]$. What does this mean? Here, $X$ is a random variable and $P$ is a probability measure. I am also curious about $$\frac{P[Y\in dy\ |\ X=x]}{dy}.$$",,"['probability', 'notation']"
51,Finding the moment generating function of the product of two standard normal distributions,Finding the moment generating function of the product of two standard normal distributions,,"The following question is on my homework assignment that I cannot figure out: Let U and V be independent random variables, each having a normal distribution with mean zero and variance one. Find the moment generating function of the random variable W = UV . I have looked around online, and cannot find an answer to this question. In fact, the only answers I can find that even relate to the product of standard normal random variables are using techniques that we never covered in my class. We covered in class how to find the MGF for linear combinations of random variables, by W isn't linear, its a product of two normals. So that technique won't work. What am I supposed to do? I am completely at a loss. I have tried multiplying the MGFs of U and V together, but that leaves me with something ugly that I can't reduce.","The following question is on my homework assignment that I cannot figure out: Let U and V be independent random variables, each having a normal distribution with mean zero and variance one. Find the moment generating function of the random variable W = UV . I have looked around online, and cannot find an answer to this question. In fact, the only answers I can find that even relate to the product of standard normal random variables are using techniques that we never covered in my class. We covered in class how to find the MGF for linear combinations of random variables, by W isn't linear, its a product of two normals. So that technique won't work. What am I supposed to do? I am completely at a loss. I have tried multiplying the MGFs of U and V together, but that leaves me with something ugly that I can't reduce.",,"['probability', 'probability-distributions', 'moment-generating-functions']"
52,Probability of choosing the same number,Probability of choosing the same number,,"Assume $n$ people choose a number between $1$ and $k$ uniformly at random, simultaneously. What is the probability that any two of the $n$ people get the same number? I tried: The probability that two people choose the same number is $\frac1k$. There are $\binom{n}{2}$ different pairs. How to proceed from this? Thanks.","Assume $n$ people choose a number between $1$ and $k$ uniformly at random, simultaneously. What is the probability that any two of the $n$ people get the same number? I tried: The probability that two people choose the same number is $\frac1k$. There are $\binom{n}{2}$ different pairs. How to proceed from this? Thanks.",,['probability']
53,Why is probability density function is always positive?,Why is probability density function is always positive?,,I saw that one of the properties of probability density function is that it is always positive. But I am not sure how to prove that?,I saw that one of the properties of probability density function is that it is always positive. But I am not sure how to prove that?,,"['probability', 'probability-theory']"
54,Probability Puzzle : Robot and coins,Probability Puzzle : Robot and coins,,"Someone walks into your room and dumps a huge bag of quarters all over the floor. They spread them out so no quarters are on top of any other quarters. a robot then comes into the room and is programmed such that if it sees a head, it flips it to tails. If it sees a tail, it throws it in the air. the robot moves around randomly forever. Will there be a convergence in distribution of heads vs. tails? I am trying this puzzle for the past two days . But got lot of confusions !! As i don't know what is convergence in probability,i cannot proceed further. Please don't provide a link to wikipedia for convergence in probability.Can someone give me a simple definition of convergence in probability and explain the solution to the puzzle ?","Someone walks into your room and dumps a huge bag of quarters all over the floor. They spread them out so no quarters are on top of any other quarters. a robot then comes into the room and is programmed such that if it sees a head, it flips it to tails. If it sees a tail, it throws it in the air. the robot moves around randomly forever. Will there be a convergence in distribution of heads vs. tails? I am trying this puzzle for the past two days . But got lot of confusions !! As i don't know what is convergence in probability,i cannot proceed further. Please don't provide a link to wikipedia for convergence in probability.Can someone give me a simple definition of convergence in probability and explain the solution to the puzzle ?",,"['probability', 'convergence-divergence', 'puzzle']"
55,probability of getting a double six ($2$ dice) rolling them $24$ times,probability of getting a double six ( dice) rolling them  times,2 24,"This is what I got. $\dfrac{1}{6} \cdot \dfrac{1}{6} = 2.78\% \cdot 24 = 66.72\%$ I believe that since it is a six sided dice, since you roll both of them simultaneously it would be $\dfrac{1}{6} \cdot \dfrac{1}{6}$. So since they are rolling them $24$ times, I would just multiply it by $24$, so $2.78\% * 24$ would be $66.72\%$, which would mean I have a  $67.7\%$ chance of rolling a double six. Do you think this is correct? Am i doing this correctly?","This is what I got. $\dfrac{1}{6} \cdot \dfrac{1}{6} = 2.78\% \cdot 24 = 66.72\%$ I believe that since it is a six sided dice, since you roll both of them simultaneously it would be $\dfrac{1}{6} \cdot \dfrac{1}{6}$. So since they are rolling them $24$ times, I would just multiply it by $24$, so $2.78\% * 24$ would be $66.72\%$, which would mean I have a  $67.7\%$ chance of rolling a double six. Do you think this is correct? Am i doing this correctly?",,['probability']
56,Probability of winning an arbitrary game,Probability of winning an arbitrary game,,"I would like to know how to find the answer to this probability problem. Two players, $A$ and $B$, are playing an arbitrary game (no draw is possible). The winner is the player who wins two consecutive games. Player $A$ has $2/3$ chances of winning a single game and player $B$ $1/3$. Example: Player $A$ loses the first game, but wins the two next games, so he wins the overall game. What is the probability that Player $A$ wins the overall game?","I would like to know how to find the answer to this probability problem. Two players, $A$ and $B$, are playing an arbitrary game (no draw is possible). The winner is the player who wins two consecutive games. Player $A$ has $2/3$ chances of winning a single game and player $B$ $1/3$. Example: Player $A$ loses the first game, but wins the two next games, so he wins the overall game. What is the probability that Player $A$ wins the overall game?",,['probability']
57,Repeating something with (1/n)th chance of success n times,Repeating something with (1/n)th chance of success n times,,"Is there anything that can be said about how many attempts it will take to correctly guess a random number out of 1000 numbers? If the number wouldn't change the probability would just increase every guess, giving in the end a probability of 1. If the number changes every guess tough, you just have a 1/1000th chance everytime. Can it be calculated how many attempts it would probably take, on average? (I'm sorry, i'm not very skilled in probability maths)","Is there anything that can be said about how many attempts it will take to correctly guess a random number out of 1000 numbers? If the number wouldn't change the probability would just increase every guess, giving in the end a probability of 1. If the number changes every guess tough, you just have a 1/1000th chance everytime. Can it be calculated how many attempts it would probably take, on average? (I'm sorry, i'm not very skilled in probability maths)",,"['probability', 'probability-theory', 'probability-distributions', 'random']"
58,Probability Question: Would A always have a greater chance of $A\cap B$?,Probability Question: Would A always have a greater chance of ?,A\cap B,"My professor assigned a completely random question on our problem set. Basically, it goes: Sophie is 30 years old and majored in philosophy. As a student, she participated in anti-nuclear demonstrations and was deeply concerned with social justice. Which is more probable? 1. Sophie is a bank teller. 2. Sophie is a bank teller and is active in the feminist movement. I'm guessing the point the prof was trying to get across is that assuming you have two different events $A$ and $B$,  $A\cap B$ would always have a smaller probability than either. Is this correct?","My professor assigned a completely random question on our problem set. Basically, it goes: Sophie is 30 years old and majored in philosophy. As a student, she participated in anti-nuclear demonstrations and was deeply concerned with social justice. Which is more probable? 1. Sophie is a bank teller. 2. Sophie is a bank teller and is active in the feminist movement. I'm guessing the point the prof was trying to get across is that assuming you have two different events $A$ and $B$,  $A\cap B$ would always have a smaller probability than either. Is this correct?",,['probability']
59,What are my chances of winning this card game,What are my chances of winning this card game,,"I shuffle a standard deck and guess that I will pick an ace at my first draw. If it is indeed an ace, I win the game immediately and stop. If it is not an ace, I will claim that the next card drawn from the deck (now only 51 cards remaining) is a 2. If it is a 2, I win the game and stop. If not, I will go on: I will go though all ranks this way and if I guess the 13th card drawn incorrectly (i.e., it was not a King), then I lose the game. I simulated this game and I got a winning probability of around .65, but now I want to solve for it mathematically. I think the exact way is too complicated (the probability that I get the fifth card right will depend on how many of it have already been drawn beforehand). So, I am satisfied with an approximate way to solve for it.","I shuffle a standard deck and guess that I will pick an ace at my first draw. If it is indeed an ace, I win the game immediately and stop. If it is not an ace, I will claim that the next card drawn from the deck (now only 51 cards remaining) is a 2. If it is a 2, I win the game and stop. If not, I will go on: I will go though all ranks this way and if I guess the 13th card drawn incorrectly (i.e., it was not a King), then I lose the game. I simulated this game and I got a winning probability of around .65, but now I want to solve for it mathematically. I think the exact way is too complicated (the probability that I get the fifth card right will depend on how many of it have already been drawn beforehand). So, I am satisfied with an approximate way to solve for it.",,"['probability', 'combinatorics']"
60,Liminf and Limsup of a sequence of sets,Liminf and Limsup of a sequence of sets,,"I am attempting to learn some measure theory and am starting with liminf and limsup of sequences of sets. I found an example that is as follows: $$A_n=\left\{\frac0n, \frac1n, \dots , \frac{n^2}n\right\}$$ and I am trying to find the limsup and liminf. My understanding is that both deal with the tail sequences, and that limsup involves values that appear ""infinitely often"" and liminf covers values that appear ""all but finitely often"". Also I understand that $\liminf A_n\subset\limsup A_n$. For the above example, if I enumerate the first few sets, it is clearly evident that ${0}$ appears i.o. It also seems (to me) that as $n\to\infty$, all of the positive rational numbers appear. I am having trouble seeing the limits. For example, no matter how large I choose $N$, there is some $n\ge N$ in which all of the rationals appear, right? Obviously I am confused (this is all self-taught), so any explanation would be greatly appreciated. I seem to be able to make sense of liminf and limsup when the sequence is of a form similar to $[0, n/(n+1))$ and other examples, but I'm struggling with this example. One simple question: does an event have to ""not"" show up sometimes to be part of the liminf, or is it just that it is allowed to be missing finitely often? Assuming for a moment that the former is true, it appears to me that {0} is definitely in both liminf and limsup: that is, no matter how large I select N, {0} is in some (in this case, all) A_n with n>N. Moving on from there, it is clear to me that the integers begin to appear over and over again, and as n-->infinity, the rationals begin to ""fill out"" as well. Where I seem to be getting stuck is that the integers only show up equal to ""n"" and it is not clear to me how to handle the fact that the sequence is unbounded. Intuitively, all of the (positive) integers eventually show up (always), but they are far from the only values that do. {1/2} shows up always, for example. I'm not sure if {Q_+} eventually shows up, and this may be due to a lack of formal construction of Q in my past. What I recall is that Q is essentially all real numbers that can be expressed as m/n with m and n members of Z. Thank you.","I am attempting to learn some measure theory and am starting with liminf and limsup of sequences of sets. I found an example that is as follows: $$A_n=\left\{\frac0n, \frac1n, \dots , \frac{n^2}n\right\}$$ and I am trying to find the limsup and liminf. My understanding is that both deal with the tail sequences, and that limsup involves values that appear ""infinitely often"" and liminf covers values that appear ""all but finitely often"". Also I understand that $\liminf A_n\subset\limsup A_n$. For the above example, if I enumerate the first few sets, it is clearly evident that ${0}$ appears i.o. It also seems (to me) that as $n\to\infty$, all of the positive rational numbers appear. I am having trouble seeing the limits. For example, no matter how large I choose $N$, there is some $n\ge N$ in which all of the rationals appear, right? Obviously I am confused (this is all self-taught), so any explanation would be greatly appreciated. I seem to be able to make sense of liminf and limsup when the sequence is of a form similar to $[0, n/(n+1))$ and other examples, but I'm struggling with this example. One simple question: does an event have to ""not"" show up sometimes to be part of the liminf, or is it just that it is allowed to be missing finitely often? Assuming for a moment that the former is true, it appears to me that {0} is definitely in both liminf and limsup: that is, no matter how large I select N, {0} is in some (in this case, all) A_n with n>N. Moving on from there, it is clear to me that the integers begin to appear over and over again, and as n-->infinity, the rationals begin to ""fill out"" as well. Where I seem to be getting stuck is that the integers only show up equal to ""n"" and it is not clear to me how to handle the fact that the sequence is unbounded. Intuitively, all of the (positive) integers eventually show up (always), but they are far from the only values that do. {1/2} shows up always, for example. I'm not sure if {Q_+} eventually shows up, and this may be due to a lack of formal construction of Q in my past. What I recall is that Q is essentially all real numbers that can be expressed as m/n with m and n members of Z. Thank you.",,"['probability', 'measure-theory']"
61,Is $t\mapsto \left|\cos (t)\right|$ a characteristic function?,Is  a characteristic function?,t\mapsto \left|\cos (t)\right|,Can anyone explain how I can prove that either $\phi(t) = \left|\cos (t)\right|$ is characteristic function or not? And which random variable has this characteristic function? Thanks in advance.,Can anyone explain how I can prove that either $\phi(t) = \left|\cos (t)\right|$ is characteristic function or not? And which random variable has this characteristic function? Thanks in advance.,,"['probability', 'probability-theory', 'probability-distributions', 'characteristic-functions']"
62,expected number of coin flips given a condition,expected number of coin flips given a condition,,"I have a fair coin, and I flip it until the following condition is met: #heads - #tails = N  OR  #tails - #heads = N where $N \geqslant 2$. What is the expected number of times I flip the coin?","I have a fair coin, and I flip it until the following condition is met: #heads - #tails = N  OR  #tails - #heads = N where $N \geqslant 2$. What is the expected number of times I flip the coin?",,['probability']
63,Kolmogorov's maximal inequality for random number composition,Kolmogorov's maximal inequality for random number composition,,"The Kolmogorov's maximal inequality states that when $X_1,\dots,X_n$ are mutually independent random variables, each with finite variance. Set $S_j=X_1+\cdots+X_j, 1 \le j\le n.$ Then, for each $\epsilon>0$,  $$\Pr(\max_{1 \le j \le n}|S_j-\mathbb{E}(S_j)| \ge \epsilon) \le \frac{Var(S_n)}{\epsilon^2}$$ I consider the following question, given a number $n$, a random composition (strong) of this number into $k$ positive parts. So we can get $k$ random variable $Y_1, Y_2,\dots, Y_k$ with $$Y_1+Y_2+\cdots+Y_k=n$$ Apparently, in my case, the random variables are dependent. So how to apply Kolmogorov's Inequality or some other related inequality for these random variables? That is let $S_j'=Y_1+\cdots+Y_j$, give a bound of $\Pr(\max_{1 \le j \le k} |S_j'-\mathbb{E}(S_j')| \ge \epsilon)$  for some $\epsilon \ge 0$.","The Kolmogorov's maximal inequality states that when $X_1,\dots,X_n$ are mutually independent random variables, each with finite variance. Set $S_j=X_1+\cdots+X_j, 1 \le j\le n.$ Then, for each $\epsilon>0$,  $$\Pr(\max_{1 \le j \le n}|S_j-\mathbb{E}(S_j)| \ge \epsilon) \le \frac{Var(S_n)}{\epsilon^2}$$ I consider the following question, given a number $n$, a random composition (strong) of this number into $k$ positive parts. So we can get $k$ random variable $Y_1, Y_2,\dots, Y_k$ with $$Y_1+Y_2+\cdots+Y_k=n$$ Apparently, in my case, the random variables are dependent. So how to apply Kolmogorov's Inequality or some other related inequality for these random variables? That is let $S_j'=Y_1+\cdots+Y_j$, give a bound of $\Pr(\max_{1 \le j \le k} |S_j'-\mathbb{E}(S_j')| \ge \epsilon)$  for some $\epsilon \ge 0$.",,"['probability', 'combinatorics']"
64,Expectation of an event,Expectation of an event,,"Let $A$ be an array of length 1000 with all entries 0. I want to fill up $A$ with ones using the following approach: At each iteration I take three random integers $(j_1,j_2,j_3)$ from [1,1000] with replacement and do the following: Set $A[j_1]=1$ 2a. If $A[j_2]=1$ and $A[j_3]=0$, then set $A[j_3]=1$ 2b. if $A[j_2]=0$ and $A[j_3]=1$, then set $A[j_2]=1$ 2c. If $A[j_2]=A[j_3]=0$, do nothing What is the expected number of such trials to fill up A with all ones? With replacement means $j_2$ may be equal to $j_3$ or any previous $j_2$ etc.","Let $A$ be an array of length 1000 with all entries 0. I want to fill up $A$ with ones using the following approach: At each iteration I take three random integers $(j_1,j_2,j_3)$ from [1,1000] with replacement and do the following: Set $A[j_1]=1$ 2a. If $A[j_2]=1$ and $A[j_3]=0$, then set $A[j_3]=1$ 2b. if $A[j_2]=0$ and $A[j_3]=1$, then set $A[j_2]=1$ 2c. If $A[j_2]=A[j_3]=0$, do nothing What is the expected number of such trials to fill up A with all ones? With replacement means $j_2$ may be equal to $j_3$ or any previous $j_2$ etc.",,['probability']
65,Monkeys and Typewriters,Monkeys and Typewriters,,"Suppose that there is a certain collected works of plays that is N symbols long in the following sense: a ""symbol"" is one of the 26 letters of the alphabet, a line break, period, space, or a colon; in other words there are 30 possible symbols. If ""a monkey"" randomly ""types"" 1 of these 30 symbols at a rate of one per second, how long will it take M monkeys working at this rate, on average, for one of them to randomly write this specific N symbol long collected works? For clarity let me state that I am assuming each monkey ceaselessly types random symbols at this rate, and unless a monkey immediately types the right things, the collected works will be preceded by gibberish.","Suppose that there is a certain collected works of plays that is N symbols long in the following sense: a ""symbol"" is one of the 26 letters of the alphabet, a line break, period, space, or a colon; in other words there are 30 possible symbols. If ""a monkey"" randomly ""types"" 1 of these 30 symbols at a rate of one per second, how long will it take M monkeys working at this rate, on average, for one of them to randomly write this specific N symbol long collected works? For clarity let me state that I am assuming each monkey ceaselessly types random symbols at this rate, and unless a monkey immediately types the right things, the collected works will be preceded by gibberish.",,['probability']
66,Deal or no deal: does one switch (to avoid a goat)?/ Should deal or no deal be 10 minutes shorter?,Deal or no deal: does one switch (to avoid a goat)?/ Should deal or no deal be 10 minutes shorter?,,"Okay so this question reminded me of one my brother asked me a while back about the hit day-time novelty-worn-off-now snoozathon Deal or no deal . For the uninitiated: In playing deal or no deal, the player is presented with one of 22 boxes (randomly selected) each containing different sums of money, he then asks in turn for each of the 21 remaining boxes to be opened, occasionally receiving an offer (from a wholly unconvincing 'banker' figure) for the mystery amount in his box. If he rejects all of the offers along the way, the player is allowed to work his way through several (for some unfathomable reason, emotionally charged) box openings until there remain only two unopened boxes: one of which is his own, the other not. He is then given a choice to stick or switch (take the contents of his own box or the other), something he then agonises pointlessly over for the next 10 minutes. Monty hall [If you have not seen the monty hall 'paradox' check out this wikipedia link and prepare to be baffled, then enlightened, then disappointed that the whole thing is so trivial. After which feel free to read on.] There is a certain similarity, you will agree, between the situation a deal or no deal player finds himself in having rejected all offers and the dilemma of Monty's contestant in the classic problem: several 'bad choices' have been eliminated and he is left with a choice between a better and worse choice with no way of knowing between them. So??? Question: The solution to the monty hall problem is that it is, in fact, better to switch- does the same apply here? Does this depend upon the money in the boxes? Should every player opt for 'switch', cutting the 10 minutes of agonising away???","Okay so this question reminded me of one my brother asked me a while back about the hit day-time novelty-worn-off-now snoozathon Deal or no deal . For the uninitiated: In playing deal or no deal, the player is presented with one of 22 boxes (randomly selected) each containing different sums of money, he then asks in turn for each of the 21 remaining boxes to be opened, occasionally receiving an offer (from a wholly unconvincing 'banker' figure) for the mystery amount in his box. If he rejects all of the offers along the way, the player is allowed to work his way through several (for some unfathomable reason, emotionally charged) box openings until there remain only two unopened boxes: one of which is his own, the other not. He is then given a choice to stick or switch (take the contents of his own box or the other), something he then agonises pointlessly over for the next 10 minutes. Monty hall [If you have not seen the monty hall 'paradox' check out this wikipedia link and prepare to be baffled, then enlightened, then disappointed that the whole thing is so trivial. After which feel free to read on.] There is a certain similarity, you will agree, between the situation a deal or no deal player finds himself in having rejected all offers and the dilemma of Monty's contestant in the classic problem: several 'bad choices' have been eliminated and he is left with a choice between a better and worse choice with no way of knowing between them. So??? Question: The solution to the monty hall problem is that it is, in fact, better to switch- does the same apply here? Does this depend upon the money in the boxes? Should every player opt for 'switch', cutting the 10 minutes of agonising away???",,"['probability', 'game-theory']"
67,Conditional distribution of sum of squared iid uniforms,Conditional distribution of sum of squared iid uniforms,,"Is it true, that if $U_{1}$ and $U_{2}$ are iid uniform distributed variables on $\left[-1,1\right]$ , then the sum of $U_{1}^{2}$ and $U_{2}^{2}$ is still uniform distributed conditioned on the set that this sum is not greater than $1$ ? Other words: $$X\dot{=}U_{1}^{2}+U_{2}^{2}|U_{1}^{2}+U_{2}^{2}\leq1\sim Uni\left[0,1\right]?$$ I've read this in a book and for first glance this hasn't been clear. I guess we have to compare some kind of “conditional charachteristic” functions to decide this question.","Is it true, that if and are iid uniform distributed variables on , then the sum of and is still uniform distributed conditioned on the set that this sum is not greater than ? Other words: I've read this in a book and for first glance this hasn't been clear. I guess we have to compare some kind of “conditional charachteristic” functions to decide this question.","U_{1} U_{2} \left[-1,1\right] U_{1}^{2} U_{2}^{2} 1 X\dot{=}U_{1}^{2}+U_{2}^{2}|U_{1}^{2}+U_{2}^{2}\leq1\sim Uni\left[0,1\right]?","['probability', 'probability-theory', 'probability-distributions', 'conditional-probability', 'uniform-distribution']"
68,Probability that the sum of $n$ unit vectors (2D dimention) has length less than one,Probability that the sum of  unit vectors (2D dimention) has length less than one,n,"It is easy to show that the probability that the length of the sum of two random unit vector in a 2D-plane is less than one is $\frac13$ . As the picture above, assume the first vector is $\bar{AB}$ (by symmetricity, the direction of first vector could be any), and the second vector is any radius of circle B. So only when the head of the 2nd vector is in the red arc, the length of sum vector is less than 1. So the probability is $\frac13$ . Using a computer, it seems that the probability of the length of the sum of n random unit vectors being less than one is $\frac1{n+1}$ . #include <stdio.h> #include <stdlib.h> #include <time.h> #include <math.h>  int n=5; int m=10000; int main(int argc, char *argv[]){         if(argc>=2){             n=atoi(argv[1]);         }         if(argc>=3){                 m=atoi(argv[2]);         }         srand(time(NULL));         printf(""Test %d jump (total %d times)\n"",n,m);         int i,j;         int c=0;         for(i=0;i<m;i++){                 double sx=0.0,sy=0.0;                 for(j=0;j<n;j++){                         double t=rand();                         sx+=cos(t);                         sy+=sin(t);                 }                 if(sx*sx+sy*sy<=1.0){                         c++;                 }         }         printf(""%d times in circle (ratio %f)\n"", c, (double)c/m);         return 0; } $ ./sa 5 1000000 Test 5 jump (total 1000000 times) 166728 times in circle (ratio 0.166728) $ ./sa 5 10000000 Test 5 jump (total 10000000 times) 1667138 times in circle (ratio 0.166714) $ ./sa 7 10000000 Test 7 jump (total 10000000 times) 1248881 times in circle (ratio 0.124888) ./sa 7 10000000 Test 7 jump (total 10000000 times) 1249432 times in circle (ratio 0.124943) ./sa 9 10000000 Test 9 jump (total 10000000 times) 1001222 times in circle (ratio 0.100122) ./sa 9 10000000 Test 9 jump (total 10000000 times) 999595 times in circle (ratio 0.099960) That's, given n i.i.d random variables $x_k$ which are uniform distributed in [0,1), could we prove that $P(\left|\sum_{k=1}^n \exp(2\pi i x_k)\right|<1)=\frac1{n+1}$ .","It is easy to show that the probability that the length of the sum of two random unit vector in a 2D-plane is less than one is . As the picture above, assume the first vector is (by symmetricity, the direction of first vector could be any), and the second vector is any radius of circle B. So only when the head of the 2nd vector is in the red arc, the length of sum vector is less than 1. So the probability is . Using a computer, it seems that the probability of the length of the sum of n random unit vectors being less than one is . #include <stdio.h> #include <stdlib.h> #include <time.h> #include <math.h>  int n=5; int m=10000; int main(int argc, char *argv[]){         if(argc>=2){             n=atoi(argv[1]);         }         if(argc>=3){                 m=atoi(argv[2]);         }         srand(time(NULL));         printf(""Test %d jump (total %d times)\n"",n,m);         int i,j;         int c=0;         for(i=0;i<m;i++){                 double sx=0.0,sy=0.0;                 for(j=0;j<n;j++){                         double t=rand();                         sx+=cos(t);                         sy+=sin(t);                 }                 if(sx*sx+sy*sy<=1.0){                         c++;                 }         }         printf(""%d times in circle (ratio %f)\n"", c, (double)c/m);         return 0; } ./sa 5 10000000 Test 5 jump (total 10000000 times) 1667138 times in circle (ratio 0.166714) $ ./sa 7 10000000 Test 7 jump (total 10000000 times) 1248881 times in circle (ratio 0.124888) ./sa 7 10000000 Test 7 jump (total 10000000 times) 1249432 times in circle (ratio 0.124943) ./sa 9 10000000 Test 9 jump (total 10000000 times) 1001222 times in circle (ratio 0.100122) ./sa 9 10000000 Test 9 jump (total 10000000 times) 999595 times in circle (ratio 0.099960) That's, given n i.i.d random variables which are uniform distributed in [0,1), could we prove that .","\frac13 \bar{AB} \frac13 \frac1{n+1}  ./sa 5 1000000
Test 5 jump (total 1000000 times)
166728 times in circle (ratio 0.166728)
 x_k P(\left|\sum_{k=1}^n \exp(2\pi i x_k)\right|<1)=\frac1{n+1}","['probability', 'geometric-probability']"
69,Symmetrization and Contraction Principle of Random Variables,Symmetrization and Contraction Principle of Random Variables,,"I was reading a paper and came across the terms symmetrization and contraction principle of random variables. I tried to extract the statements as follows: Symmetrization: Let $X_1,\dots,X_n$ be independent zero-mean random variables and $p\geq 2$ , then $$\left\|\sum_{i=1}^n a_i X_i\right\|_p \leq 2 \left\|\sum_{i=1}^n a_i \varepsilon_i X_i\right\|_p$$ where $a_i$ are real numbers and $\varepsilon_i$ denote a sequence of symmetric independent Rademacher random variables (also independent of the $X_i$ 's). Contraction Principle: Let $X_1,\dots,X_n$ be independent non-negative random variables and $p\geq 2$ . Further, suppose for each $i$ , we have $\mathbb{P}(Y_i\geq t)\geq \mathbb{P}(X_i\geq t)$ for all $t>0$ , where $Y_1,\dots, Y_n$ are also non-negative random variables. Then we have $$\left\|\sum_{i=1}^n a_i \varepsilon_i X_i\right\|_p \leq \left\|\sum_{i=1}^n a_i \varepsilon_i Y_i\right\|_p$$ where $a_i$ are real numbers and $\varepsilon_i$ denote a sequence of Rademacher random variables. There might be more general statements of these results that exist but the paper does not really cite them, and I am having trouble finding references to exact statements and proofs. If anybody can provide a reference (preferably a textbook) or a hint, that would be greatly appreciated! For reference, the paper and argument cited is here , on page 12. Edit: I am looking for a reference to read, not a direct solution or anything like that.","I was reading a paper and came across the terms symmetrization and contraction principle of random variables. I tried to extract the statements as follows: Symmetrization: Let be independent zero-mean random variables and , then where are real numbers and denote a sequence of symmetric independent Rademacher random variables (also independent of the 's). Contraction Principle: Let be independent non-negative random variables and . Further, suppose for each , we have for all , where are also non-negative random variables. Then we have where are real numbers and denote a sequence of Rademacher random variables. There might be more general statements of these results that exist but the paper does not really cite them, and I am having trouble finding references to exact statements and proofs. If anybody can provide a reference (preferably a textbook) or a hint, that would be greatly appreciated! For reference, the paper and argument cited is here , on page 12. Edit: I am looking for a reference to read, not a direct solution or anything like that.","X_1,\dots,X_n p\geq 2 \left\|\sum_{i=1}^n a_i X_i\right\|_p \leq 2 \left\|\sum_{i=1}^n a_i \varepsilon_i X_i\right\|_p a_i \varepsilon_i X_i X_1,\dots,X_n p\geq 2 i \mathbb{P}(Y_i\geq t)\geq \mathbb{P}(X_i\geq t) t>0 Y_1,\dots, Y_n \left\|\sum_{i=1}^n a_i \varepsilon_i X_i\right\|_p \leq \left\|\sum_{i=1}^n a_i \varepsilon_i Y_i\right\|_p a_i \varepsilon_i","['probability', 'measure-theory', 'lp-spaces']"
70,Probability of pushing buttons in elevator,Probability of pushing buttons in elevator,,"I am considering the following problem from Introduction to Probability by Blitzstein and Hwang (Exercise 23 of Chapter 1). Three people get into an empty elevator at the first floor of a   building that has 10 floors. Each presses the button for their desired   floor. Assume that are equally likely to want to get to floors 2   through 10 (independently of each other). What is the probability that   the buttons for 3 consecutive floors are pressed. My thoughts There are 3 people A, B and C in the elevator. If A pushes a, B pushes b and C pushes c (a triple (a,b,c) where b=a+1 and c=b+1), then the number of total triples that can be formed from a sample of $9$ elements is $\binom93=84$ . I do not see why the sample space should be $ 9\cdot9\cdot9$ since we are only interested in the triples and more specifically we are interested in the ordered triples. The favorable outcomes are (2,3,4), (3,4,5), (4,5,6), (5,6,7), (6,7,8), (7,8,9), (8,9,10), i.e. 7 in total. The probability that the buttons for three consecutive floors are pressed is therefore $\dfrac{7}{84} $ . Is the above correct?","I am considering the following problem from Introduction to Probability by Blitzstein and Hwang (Exercise 23 of Chapter 1). Three people get into an empty elevator at the first floor of a   building that has 10 floors. Each presses the button for their desired   floor. Assume that are equally likely to want to get to floors 2   through 10 (independently of each other). What is the probability that   the buttons for 3 consecutive floors are pressed. My thoughts There are 3 people A, B and C in the elevator. If A pushes a, B pushes b and C pushes c (a triple (a,b,c) where b=a+1 and c=b+1), then the number of total triples that can be formed from a sample of elements is . I do not see why the sample space should be since we are only interested in the triples and more specifically we are interested in the ordered triples. The favorable outcomes are (2,3,4), (3,4,5), (4,5,6), (5,6,7), (6,7,8), (7,8,9), (8,9,10), i.e. 7 in total. The probability that the buttons for three consecutive floors are pressed is therefore . Is the above correct?","9 \binom93=84  9\cdot9\cdot9 \dfrac{7}{84}
","['probability', 'combinatorics']"
71,"I have a bag with 3 coins in it. One of them is a fair coin, but the others are biased trick coins.","I have a bag with 3 coins in it. One of them is a fair coin, but the others are biased trick coins.",,"When flipped, the three coins come up heads with probability 0.5, 0.3, 0.6 respectively. Suppose that I pick one of these three coins entirely at random and flip it three times. 1. What is P(HTT)? (i.e., it comes up heads on the first flip and tails on the last two flips.) 2.Assuming that the three flips, in order, are HTT, what is the probability that the coin that I picked was the fair coin? Don't need to reduce fractions Work: 1. ((.5*.5)/(.5*.5))/3 + ((.3*.5)/(.7*.5))/3+ ((.6*.5)/(.4*.5))/3 - I think this is wrong 2. I dont know how to do","When flipped, the three coins come up heads with probability 0.5, 0.3, 0.6 respectively. Suppose that I pick one of these three coins entirely at random and flip it three times. 1. What is P(HTT)? (i.e., it comes up heads on the first flip and tails on the last two flips.) 2.Assuming that the three flips, in order, are HTT, what is the probability that the coin that I picked was the fair coin? Don't need to reduce fractions Work: 1. ((.5*.5)/(.5*.5))/3 + ((.3*.5)/(.7*.5))/3+ ((.6*.5)/(.4*.5))/3 - I think this is wrong 2. I dont know how to do",,['probability']
72,"Dealing cards, derangements, and probability: Is the Riddler Express solution incorrect?","Dealing cards, derangements, and probability: Is the Riddler Express solution incorrect?",,"Edit. The error was noted in a subsequent Riddler entry with a reference to an earlier MSE post: The most recent Riddler Express says: But suppose you had this same question with only one suit (say, hearts): What is the probability that you get through the 13 hearts without what you say ever matching what you deal? It seems to me that the method above would suggest computing $(12/13)^{13} = 0.3532\ldots$ This cannot be right, though; the modified question is essentially asking about derangements for a set of $13$ elements. Checking the derangement sequence at OEIS yields as its thirteenth term $2290792932$ ; among the $13!$ combinations, this would yield a probability of winning the modified game equal to $2290792932/13! = 0.3678\ldots$ The numbers are not very different, but they are certainly different. Back to the main question: Is the solution for the ""Riddler Express"" above incorrect? [I strongly believe it is...] If so: What is the correct solution, and how does one show this? I had thought it would require a modification of the derangement formula using the Inclusion-Exclusion Principle or some such thing (cf. this MO answer from Richard Stanley). In fact, I computed it as $0.01623\ldots$ Again, this is ""about 1.6 percent"" (as in the solution write-up) but the methods are very different and the actual numerical results are not the same. Am I overthinking? Is the Riddler underthinking? What gives?","Edit. The error was noted in a subsequent Riddler entry with a reference to an earlier MSE post: The most recent Riddler Express says: But suppose you had this same question with only one suit (say, hearts): What is the probability that you get through the 13 hearts without what you say ever matching what you deal? It seems to me that the method above would suggest computing This cannot be right, though; the modified question is essentially asking about derangements for a set of elements. Checking the derangement sequence at OEIS yields as its thirteenth term ; among the combinations, this would yield a probability of winning the modified game equal to The numbers are not very different, but they are certainly different. Back to the main question: Is the solution for the ""Riddler Express"" above incorrect? [I strongly believe it is...] If so: What is the correct solution, and how does one show this? I had thought it would require a modification of the derangement formula using the Inclusion-Exclusion Principle or some such thing (cf. this MO answer from Richard Stanley). In fact, I computed it as Again, this is ""about 1.6 percent"" (as in the solution write-up) but the methods are very different and the actual numerical results are not the same. Am I overthinking? Is the Riddler underthinking? What gives?",(12/13)^{13} = 0.3532\ldots 13 2290792932 13! 2290792932/13! = 0.3678\ldots 0.01623\ldots,"['probability', 'proof-verification', 'recreational-mathematics', 'problem-solving']"
73,Meeting probability of two bankers: uniform distribution puzzle,Meeting probability of two bankers: uniform distribution puzzle,,"Two bankers each arrive at the station at some random time between 5PM   and 6PM (arrival time for each of them is uniformly distributed). They   stay exactly five minutes and then leave. What is the probability that   they will meet on a given day? I am not sure how to go about modelling this problem as uniform distribution and solving it. Appreciate any help. Here is how I start with it: Assume banker A arrives X minutes after 5PM and B arrives Y minutes after 5PM. Both X and Y are uniformly distributed between 5PM and 6PM. So pdf of X, Y is $\frac{1}{60}$. Now A and B will meet if $|X - Y| < 5$. So required probability is $P(|X - Y| < 5)$ = Integral of joint distribution function of $|X - Y|$ from $0$ to $5$? Now not sure how to write the equation from this point onwards and solve it. Answer: $\frac {23}{144}$","Two bankers each arrive at the station at some random time between 5PM   and 6PM (arrival time for each of them is uniformly distributed). They   stay exactly five minutes and then leave. What is the probability that   they will meet on a given day? I am not sure how to go about modelling this problem as uniform distribution and solving it. Appreciate any help. Here is how I start with it: Assume banker A arrives X minutes after 5PM and B arrives Y minutes after 5PM. Both X and Y are uniformly distributed between 5PM and 6PM. So pdf of X, Y is $\frac{1}{60}$. Now A and B will meet if $|X - Y| < 5$. So required probability is $P(|X - Y| < 5)$ = Integral of joint distribution function of $|X - Y|$ from $0$ to $5$? Now not sure how to write the equation from this point onwards and solve it. Answer: $\frac {23}{144}$",,"['probability', 'probability-distributions', 'puzzle', 'uniform-distribution']"
74,Expected number of rolls for an unfair die to get all possibile values at least once,Expected number of rolls for an unfair die to get all possibile values at least once,,"Suppose that we have a 6-sided unfair dice, where rolling a 1 is twice as likely as rolling any other number, and the other numbers have the same likelihood. What is the expected number of rolls to get each value at least once? Thus, $$p(1) = 2/7\qquad p(2) = p(3) = \cdots = p(6) = 1/7$$ I understand how to approach this when the probabilities are the same, as it's just the Coupon collector's problem, but throwing in a non-uniform probability distribution throws me off. I know there is a general solution for this problem, but I can't seem to get any intuition as to why it's the case.","Suppose that we have a 6-sided unfair dice, where rolling a 1 is twice as likely as rolling any other number, and the other numbers have the same likelihood. What is the expected number of rolls to get each value at least once? Thus, $$p(1) = 2/7\qquad p(2) = p(3) = \cdots = p(6) = 1/7$$ I understand how to approach this when the probabilities are the same, as it's just the Coupon collector's problem, but throwing in a non-uniform probability distribution throws me off. I know there is a general solution for this problem, but I can't seem to get any intuition as to why it's the case.",,"['probability', 'probability-distributions', 'coupon-collector']"
75,Product of two distribution functions.,Product of two distribution functions.,,"Let F and G be two distribution functions, does the product FG still a distribution function?","Let F and G be two distribution functions, does the product FG still a distribution function?",,"['probability', 'probability-distributions']"
76,"$X,Y$ independent then $X+Y$, $X-Y$ independent as well?","independent then ,  independent as well?","X,Y X+Y X-Y","My question is simple: If $X$, $Y$ are independent random variables then $X+Y$, $X-Y$ independent as well?","My question is simple: If $X$, $Y$ are independent random variables then $X+Y$, $X-Y$ independent as well?",,"['probability', 'random-variables']"
77,"If I know the probability of something happening after n trials is X, how can I estimate the probability of it happening for each individual trial.","If I know the probability of something happening after n trials is X, how can I estimate the probability of it happening for each individual trial.",,"This is assuming each trial has an independent probability. In other words, lets say that I perform $50$ trials a $100$ times. I know that the event happened only in $5\%$ of those hundred $50$-trial sets. How can I estimate the probability of it happening in any given single trial? Also, this probably has a well known name and solution. I would be happy to be pointed to it and reading more.","This is assuming each trial has an independent probability. In other words, lets say that I perform $50$ trials a $100$ times. I know that the event happened only in $5\%$ of those hundred $50$-trial sets. How can I estimate the probability of it happening in any given single trial? Also, this probably has a well known name and solution. I would be happy to be pointed to it and reading more.",,"['probability', 'reference-request']"
78,Sum of two truncated gaussian,Sum of two truncated gaussian,,"What is the CDF and the PDF (or approximation) of the sum of two independent truncated gaussian random variable $X \sim TN_x(\mu_x,\sigma_x;a_x,b_x)$ and $Y \sim TN_y(\mu_y,\sigma_y;a_y,b_y)$ ? $TN(\mu,\sigma;a,b)$ denotes the truncated normal distribution, where a and b are the the lower and upper bounds of the truncation, respectively.","What is the CDF and the PDF (or approximation) of the sum of two independent truncated gaussian random variable and ? denotes the truncated normal distribution, where a and b are the the lower and upper bounds of the truncation, respectively.","X \sim TN_x(\mu_x,\sigma_x;a_x,b_x) Y \sim TN_y(\mu_y,\sigma_y;a_y,b_y) TN(\mu,\sigma;a,b)","['probability', 'probability-distributions', 'normal-distribution']"
79,Please recommend a nice and concise math book on probability theory.,Please recommend a nice and concise math book on probability theory.,,"My intention is neither to learn basic probability concepts, nor to learn applications of the theory. My background is at the graduate level of having completed all engineering courses in probability/statistics -- mostly oriented toward the applications without much emphasis on mathematical rigor. Now I am very interested in learning the core logic and mathematical framework of probability theory, as a math branch. More specifically, I would like to learn answers to the following questions: (1) What are the necessary axioms from which we can build probability theory? (2) What are the core theorems and results in the mathematical theory of probability? (3) What are the derived rules for reasoning/inference, based on the theorems/results in probability theory? So I am seeking a book that covers the ""heart"" of mathematical probability theory -- not needing much on applications, or discussion on extended topics. I would like to appreciate your patience for reading my post and any informative responses. Regards, user36125","My intention is neither to learn basic probability concepts, nor to learn applications of the theory. My background is at the graduate level of having completed all engineering courses in probability/statistics -- mostly oriented toward the applications without much emphasis on mathematical rigor. Now I am very interested in learning the core logic and mathematical framework of probability theory, as a math branch. More specifically, I would like to learn answers to the following questions: (1) What are the necessary axioms from which we can build probability theory? (2) What are the core theorems and results in the mathematical theory of probability? (3) What are the derived rules for reasoning/inference, based on the theorems/results in probability theory? So I am seeking a book that covers the ""heart"" of mathematical probability theory -- not needing much on applications, or discussion on extended topics. I would like to appreciate your patience for reading my post and any informative responses. Regards, user36125",,"['probability', 'reference-request', 'axioms']"
80,Question about the Irwin-Hall Distribution (Uniform Sum Distribution),Question about the Irwin-Hall Distribution (Uniform Sum Distribution),,"So I have been reading about the Irwin-Hall distribution online, it is a sum of uniform distributions on $[0,1]$, and it seems very interesting: http://en.wikipedia.org/wiki/Irwin%E2%80%93Hall_distribution On the Wikipedia article above they derive pdf for the special cases n = 1,2,3,4, and 5.  n = 1 is trivial, for n = 2 we are drawing points from a square $U_1 \times U_2$. Then we compute the probability of picking points under a line in that square, take its derivative and then derive the triangular distribution. For n = 3, we are drawing points from the cube $U_1 \times U_2 \times U_3$ and compute the probability of picking points under a plane and can intuitively see the parabolic distribution (since the volume under the plane on the cube will be of third degree, then we takes its derivative to get pdf). In general we see the pdf will have n pieces with each piece of degree k-1. My question here is deriving the formulas for the n = 3,4,5 case don't seem easy as they are shown in the Wikipedia article, what would be the approach to get the equations? Secondly, intuitively we would think due to the central limit theorem that this distribution approaches the normal distribution, but they give a general version of the pdf in the Wikipedia article, and I don't see how that is going to converge to the normal distribution. For n = 3, I know how to get pdf when $x \in [0,1]$ and $x \in [2,3]$, but not sure about when $x \in [1,2]$.","So I have been reading about the Irwin-Hall distribution online, it is a sum of uniform distributions on $[0,1]$, and it seems very interesting: http://en.wikipedia.org/wiki/Irwin%E2%80%93Hall_distribution On the Wikipedia article above they derive pdf for the special cases n = 1,2,3,4, and 5.  n = 1 is trivial, for n = 2 we are drawing points from a square $U_1 \times U_2$. Then we compute the probability of picking points under a line in that square, take its derivative and then derive the triangular distribution. For n = 3, we are drawing points from the cube $U_1 \times U_2 \times U_3$ and compute the probability of picking points under a plane and can intuitively see the parabolic distribution (since the volume under the plane on the cube will be of third degree, then we takes its derivative to get pdf). In general we see the pdf will have n pieces with each piece of degree k-1. My question here is deriving the formulas for the n = 3,4,5 case don't seem easy as they are shown in the Wikipedia article, what would be the approach to get the equations? Secondly, intuitively we would think due to the central limit theorem that this distribution approaches the normal distribution, but they give a general version of the pdf in the Wikipedia article, and I don't see how that is going to converge to the normal distribution. For n = 3, I know how to get pdf when $x \in [0,1]$ and $x \in [2,3]$, but not sure about when $x \in [1,2]$.",,"['probability', 'probability-theory', 'probability-distributions', 'normal-distribution', 'uniform-distribution']"
81,Dice probability over multiple rolls.,Dice probability over multiple rolls.,,"What is the probability of rolling one or more 6's using 3 six sided dice (1...6) that are rolled three times? How does multiple rolls influence the probability, is it simply 3 times the probability of a single roll? Please simplify ; )","What is the probability of rolling one or more 6's using 3 six sided dice (1...6) that are rolled three times? How does multiple rolls influence the probability, is it simply 3 times the probability of a single roll? Please simplify ; )",,"['probability', 'dice']"
82,Dealt 3 cards. Odds of being dealt any pair?,Dealt 3 cards. Odds of being dealt any pair?,,"This is not to aid a gambling habit.  I am simply curious how to do this math. You get dealt 3 cards.  What are the odds of having any pair?  (We can exclude 3 of a kind) Total number of hands = $\begin{pmatrix}52 \\ 3\end{pmatrix}$  = 22100 What do I do next?  (Added from response below) How many ways can I get a pair of 2's, for example? $\begin{pmatrix}4 \\ 2\end{pmatrix}$  = 6 And there are 13 types of pairs I can get. So, 13x6 = 72. So, there is only a 72/22100 chance of being dealt a pair? Supplemental:  If there are 5 players, what are the odds at least 1 person is holding a pair?","This is not to aid a gambling habit.  I am simply curious how to do this math. You get dealt 3 cards.  What are the odds of having any pair?  (We can exclude 3 of a kind) Total number of hands = $\begin{pmatrix}52 \\ 3\end{pmatrix}$  = 22100 What do I do next?  (Added from response below) How many ways can I get a pair of 2's, for example? $\begin{pmatrix}4 \\ 2\end{pmatrix}$  = 6 And there are 13 types of pairs I can get. So, 13x6 = 72. So, there is only a 72/22100 chance of being dealt a pair? Supplemental:  If there are 5 players, what are the odds at least 1 person is holding a pair?",,"['probability', 'combinatorics', 'card-games']"
83,How variance is defined?,How variance is defined?,,"The variance of a random variable $X$ is defined as $E[(x-\mu )^2]$. Why can't it be defined as $E[|x-\mu |]$. i.e., What is the basic idea behind this definition. Thank you.","The variance of a random variable $X$ is defined as $E[(x-\mu )^2]$. Why can't it be defined as $E[|x-\mu |]$. i.e., What is the basic idea behind this definition. Thank you.",,"['probability', 'probability-theory']"
84,Sleeping Mathematician (Sleeping Beauty),Sleeping Mathematician (Sleeping Beauty),,"I came across the following thought experiment, and I would like to understand whether the controversy around it is justified. Imagine an experiment in which a mathematician is put to sleep with some kind of drug. He is located in a room that is designed in such a way as to keep him completely isolated from any kind of external information. The researchers have a sleep inducing drug that is able to put you to sleep and make you forget it was even administered. After the researchers have put the mathematician to sleep with this drug, they toss a fair coin. If it comes up heads they will wake the mathematician up once and administer the drug again. If it comes up tail they will wake him up twice, each time administering the drug again. Whenever the mathematician is awoken during the experiment, they will ask him for his best guess regarding the result of the coin toss. Eventually the experiment ends, and the researchers will awaken the mathematician a final time and tell him the experiment has ended. During the experiment, what answer should the mathematician give as his best guess for the result of the coin toss ? I think he should say that odds are the coin came up tail, but I am very curious what other people make of it, and whether there are any grounds for dissent at all.","I came across the following thought experiment, and I would like to understand whether the controversy around it is justified. Imagine an experiment in which a mathematician is put to sleep with some kind of drug. He is located in a room that is designed in such a way as to keep him completely isolated from any kind of external information. The researchers have a sleep inducing drug that is able to put you to sleep and make you forget it was even administered. After the researchers have put the mathematician to sleep with this drug, they toss a fair coin. If it comes up heads they will wake the mathematician up once and administer the drug again. If it comes up tail they will wake him up twice, each time administering the drug again. Whenever the mathematician is awoken during the experiment, they will ask him for his best guess regarding the result of the coin toss. Eventually the experiment ends, and the researchers will awaken the mathematician a final time and tell him the experiment has ended. During the experiment, what answer should the mathematician give as his best guess for the result of the coin toss ? I think he should say that odds are the coin came up tail, but I am very curious what other people make of it, and whether there are any grounds for dissent at all.",,"['probability', 'soft-question', 'probability-theory']"
85,Reverse Markov Inequality for non-negative unbounded random variables,Reverse Markov Inequality for non-negative unbounded random variables,,I need to lower bound the tail probability of a non-negative random variable. I have a lower bound on its expected value. I am aware of a reverse markov's inequality that does the job when the random variable is bounded above. Unfortunately that is not my case. Is there any other inequality that may be useful to me in this regard? thanks NR,I need to lower bound the tail probability of a non-negative random variable. I have a lower bound on its expected value. I am aware of a reverse markov's inequality that does the job when the random variable is bounded above. Unfortunately that is not my case. Is there any other inequality that may be useful to me in this regard? thanks NR,,"['probability', 'inequality']"
86,bounds on normal distribution [duplicate],bounds on normal distribution [duplicate],,"This question already has answers here : Closed 12 years ago . Possible Duplicate: Proof of upper-tail inequality for standard normal distribution Proof that $x \Phi(x) + \Phi'(x) \geq 0$ $\forall x$, where $\Phi$ is the normal CDF Let $X$ be a normal $N(0,1)$ randon variable.  Show that $\mathbb{P}(X>t)\le\frac{1}{\sqrt{2\pi}t}e^{-\frac{t^2}{2}}$, for $t>0$. Using markov inequality shows that $P(X>t)\le \frac{\mathbb{E}(X)}{t}$ but I dont know how to bound the expected value","This question already has answers here : Closed 12 years ago . Possible Duplicate: Proof of upper-tail inequality for standard normal distribution Proof that $x \Phi(x) + \Phi'(x) \geq 0$ $\forall x$, where $\Phi$ is the normal CDF Let $X$ be a normal $N(0,1)$ randon variable.  Show that $\mathbb{P}(X>t)\le\frac{1}{\sqrt{2\pi}t}e^{-\frac{t^2}{2}}$, for $t>0$. Using markov inequality shows that $P(X>t)\le \frac{\mathbb{E}(X)}{t}$ but I dont know how to bound the expected value",,"['probability', 'probability-distributions']"
87,Total variation inequality for the product measure,Total variation inequality for the product measure,,"Let $\mu_i,\nu_i$ be probability measure on a finite space $\Omega_i,i=1,2,\dots,n$. Define $\mu=\prod\limits_{i=1}^{n}\mu_i$ and $\nu=\prod\limits_{i=1}^{n}\nu_i$ on $\Omega=\prod\limits_{i=1}^{n}\Omega_i$, show that  $$\|\mu-\nu\| \le \sum\limits_{i=1}^{n}\|\mu_i-\nu_i\|$$ where $\|\mu-\nu\|$ denote the total variation distance between $\mu$ and $\nu$. I know how to do this using coupling, is there a way to do it without coupling? I try to write $$\|\mu-\nu\|={1 \over 2}\sum\limits_{x=(x_1,x_2,\dots,x_n) \in \Omega}|\prod\limits_{i=1}^{n}\mu_i(x_i)-\prod\limits_{i=1}^{n}\nu_i(x_i)|$$ and use the fact that $\prod\limits_{i=1}^{n}\mu_i \le \sum\limits_{i=1}^{n}\mu_i$ and $\prod\limits_{i=1}^{n}\nu_i \le \sum\limits_{i=1}^{n}\nu_i$, but I didn't succeed.","Let $\mu_i,\nu_i$ be probability measure on a finite space $\Omega_i,i=1,2,\dots,n$. Define $\mu=\prod\limits_{i=1}^{n}\mu_i$ and $\nu=\prod\limits_{i=1}^{n}\nu_i$ on $\Omega=\prod\limits_{i=1}^{n}\Omega_i$, show that  $$\|\mu-\nu\| \le \sum\limits_{i=1}^{n}\|\mu_i-\nu_i\|$$ where $\|\mu-\nu\|$ denote the total variation distance between $\mu$ and $\nu$. I know how to do this using coupling, is there a way to do it without coupling? I try to write $$\|\mu-\nu\|={1 \over 2}\sum\limits_{x=(x_1,x_2,\dots,x_n) \in \Omega}|\prod\limits_{i=1}^{n}\mu_i(x_i)-\prod\limits_{i=1}^{n}\nu_i(x_i)|$$ and use the fact that $\prod\limits_{i=1}^{n}\mu_i \le \sum\limits_{i=1}^{n}\mu_i$ and $\prod\limits_{i=1}^{n}\nu_i \le \sum\limits_{i=1}^{n}\nu_i$, but I didn't succeed.",,['probability']
88,How long does it take for every node of a graph to become infected?,How long does it take for every node of a graph to become infected?,,"Consider the following stochastic process. We begin with an undirected graph on $n$ vertices, exactly one of which is ''infected.'' Now at every time step, each infected node infects one of its non-infected neighbors uniformly at random. For example, if a given node has $3$ neighbors that are infected and $5$ that are not, then it infects exactly one of those latter $5$, each of which has probability $1/5$ of being the one chosen. Now its clear that after $n-1$ steps every node becomes infected, since at every step at least one non-infected node becomes infected. However, I suspect that the infection actually spreads faster, because as the number of infected nodes grows, more and more non-infected nodes become infected at every stage. My question : Is it actually true that every node is infected after $O(D)$ steps, where $D$ is the diameter of the graph?","Consider the following stochastic process. We begin with an undirected graph on $n$ vertices, exactly one of which is ''infected.'' Now at every time step, each infected node infects one of its non-infected neighbors uniformly at random. For example, if a given node has $3$ neighbors that are infected and $5$ that are not, then it infects exactly one of those latter $5$, each of which has probability $1/5$ of being the one chosen. Now its clear that after $n-1$ steps every node becomes infected, since at every step at least one non-infected node becomes infected. However, I suspect that the infection actually spreads faster, because as the number of infected nodes grows, more and more non-infected nodes become infected at every stage. My question : Is it actually true that every node is infected after $O(D)$ steps, where $D$ is the diameter of the graph?",,"['probability', 'graph-theory', 'stochastic-processes']"
89,Expected number of neighbors,Expected number of neighbors,,"Given a row of 16 houses where 10 are red and 6 are blue, what is the expected number of neigbors of a different color?","Given a row of 16 houses where 10 are red and 6 are blue, what is the expected number of neigbors of a different color?",,"['combinatorics', 'probability']"
90,"Let $X_n \leq Y_n$ and both converge in distribution $X_n, Y_n \overset{d}{\longrightarrow}F$. Does $|Y_n - X_n| \overset{p}{\longrightarrow} 0\,$?",Let  and both converge in distribution . Does ?,"X_n \leq Y_n X_n, Y_n \overset{d}{\longrightarrow}F |Y_n - X_n| \overset{p}{\longrightarrow} 0\,","Let $(X_n)$ and $(Y_n)$ be sequences of random variables such that $X_n \leq Y_n$ for all $n \in \mathbb N$ . Let $F$ be an arbitrary distribution function. Suppose both sequences converge in distribution to $F$ , i.e. $$ P(X_n \leq c) \underset{n \to \infty}{\longrightarrow} F(c) \quad \text{and} \quad P(Y_n \leq c) \underset{n \to \infty}{\longrightarrow} F(c) $$ for all continuity points $c$ of $F$ . Does it then hold that $|Y_n - X_n| \overset{p}{\longrightarrow} 0\,$ ? Thoughts I'm aware that the weak convergence of random sequences to the same distribution doesn't generally imply this convergence in probability. (Just set $X_n := X$ and $Y_n := Y$ for i.i.d. $X$ and $Y$ with a non-degenerate distribution.) But I'm curious whether it does under the inequality assumption $X_n \leq Y_n$ . This seems intuitive, and I'm having trouble thinking up a counterexample. On the other hand, I haven't been able to prove the statement. So maybe it's time to add yet another counterexample to my collection ;)","Let and be sequences of random variables such that for all . Let be an arbitrary distribution function. Suppose both sequences converge in distribution to , i.e. for all continuity points of . Does it then hold that ? Thoughts I'm aware that the weak convergence of random sequences to the same distribution doesn't generally imply this convergence in probability. (Just set and for i.i.d. and with a non-degenerate distribution.) But I'm curious whether it does under the inequality assumption . This seems intuitive, and I'm having trouble thinking up a counterexample. On the other hand, I haven't been able to prove the statement. So maybe it's time to add yet another counterexample to my collection ;)","(X_n) (Y_n) X_n \leq Y_n n \in \mathbb N F F 
P(X_n \leq c) \underset{n \to \infty}{\longrightarrow} F(c) \quad \text{and} \quad P(Y_n \leq c) \underset{n \to \infty}{\longrightarrow} F(c)
 c F |Y_n - X_n| \overset{p}{\longrightarrow} 0\, X_n := X Y_n := Y X Y X_n \leq Y_n","['probability', 'probability-theory', 'random-variables']"
91,"Four of a kind combinatorics, why is my logic incorrect?","Four of a kind combinatorics, why is my logic incorrect?",,"I'm going through a probability textbook and getting stuck on a simple question. From a standard deck of 52 cards, what is the probability of getting a 4 of a kind? I've seen many of the answers, and I understand how to get there. The straightforward way of answering the question is just to realize there's $ 13$ four of a kinds with $48$ choices for the 5th card so the solution is just $$ \frac {13 *48} {52 \choose 5} = \frac {624} {52 \choose 5}$$ I understand how to get to this answer. My question is, why is the following approach incorrect? For the first card we can draw any of the 52 cards, we must draw the remaining cards with the same rank. This equates to : $$52 * 3 * 2 * 1$$ Then for the 5th card we have 48 remaining cards so we have: $$52*3*2*1 * 48$$ Now, furthermore, these 5 cards can be arranged in any manner. So for the total number of ways we have: $$ \frac {52 *3 *2 *1 * 48} {5!} $$ Then we simply divide by ${52 \choose 5}$ to get our final probability. Now it turns out this answer is wrong, but I cannot figure out why? The mistake is obviously in this step: $$ \frac {52 *3 *2 *1 * 48} {5!} $$ But for the life of me I cannot figure out why. It seems the correct answer is to divide by $4!$ factorial instead of $5! $ , but why? We have 5 cards, they can be arranged in $5!$ ways","I'm going through a probability textbook and getting stuck on a simple question. From a standard deck of 52 cards, what is the probability of getting a 4 of a kind? I've seen many of the answers, and I understand how to get there. The straightforward way of answering the question is just to realize there's four of a kinds with choices for the 5th card so the solution is just I understand how to get to this answer. My question is, why is the following approach incorrect? For the first card we can draw any of the 52 cards, we must draw the remaining cards with the same rank. This equates to : Then for the 5th card we have 48 remaining cards so we have: Now, furthermore, these 5 cards can be arranged in any manner. So for the total number of ways we have: Then we simply divide by to get our final probability. Now it turns out this answer is wrong, but I cannot figure out why? The mistake is obviously in this step: But for the life of me I cannot figure out why. It seems the correct answer is to divide by factorial instead of , but why? We have 5 cards, they can be arranged in ways", 13 48  \frac {13 *48} {52 \choose 5} = \frac {624} {52 \choose 5} 52 * 3 * 2 * 1 52*3*2*1 * 48  \frac {52 *3 *2 *1 * 48} {5!}  {52 \choose 5}  \frac {52 *3 *2 *1 * 48} {5!}  4! 5!  5!,"['probability', 'combinatorics', 'solution-verification']"
92,"Are two events independent, if occurrence of one event alters possible outcomes of the other's, but still maintains the same probability?","Are two events independent, if occurrence of one event alters possible outcomes of the other's, but still maintains the same probability?",,"Let's assume a group of $80$ friends where $40$ of them plays baseball, $20$ of them plays football and $10$ of them plays both the game. Without any further information, if a random person is chosen, the probability of him playing football is $20/80 = 1/4$ Now let's say, we introduce one more information that the chosen person plays baseball. Now the sample space is halved (currently having only $40$ people) but so is the event space (currently $10$ ). So probability stays the same ( $1/4$ ) This example was shown to me by one of my friends and he claimed, here One person playing baseball and One person playing football is independent of each other. Because the occurrence of one event is not changing other's probability. But I thought, if one event reduces other's possible outcomes (Here $10$ friends leaves the equation when I apply condition), how can they be considered independent. If these events are indeed independent, the same example with different numbers, would surely change the probability. Will the same example then be considered having dependent events? The Wikipedia article on Conditional Probability says, If P(A|B) = P(A), then events A and B are said to be independent: in such a case, knowledge about either event does not alter the likelihood of each other Then should I always calculate the answer of any probability question to determine what formula to use? Then how will I get to the answer in the first place? Edit Fine tuned terminologies to match with what I wanted to say","Let's assume a group of friends where of them plays baseball, of them plays football and of them plays both the game. Without any further information, if a random person is chosen, the probability of him playing football is Now let's say, we introduce one more information that the chosen person plays baseball. Now the sample space is halved (currently having only people) but so is the event space (currently ). So probability stays the same ( ) This example was shown to me by one of my friends and he claimed, here One person playing baseball and One person playing football is independent of each other. Because the occurrence of one event is not changing other's probability. But I thought, if one event reduces other's possible outcomes (Here friends leaves the equation when I apply condition), how can they be considered independent. If these events are indeed independent, the same example with different numbers, would surely change the probability. Will the same example then be considered having dependent events? The Wikipedia article on Conditional Probability says, If P(A|B) = P(A), then events A and B are said to be independent: in such a case, knowledge about either event does not alter the likelihood of each other Then should I always calculate the answer of any probability question to determine what formula to use? Then how will I get to the answer in the first place? Edit Fine tuned terminologies to match with what I wanted to say",80 40 20 10 20/80 = 1/4 40 10 1/4 10,"['probability', 'conditional-probability']"
93,Why is flipping a head then a tail a different outcome than flipping a tail then a head?,Why is flipping a head then a tail a different outcome than flipping a tail then a head?,,"In either case, one coin flip resulted in a head and the other resulted in a tail. Why is {H,T} a different outcome than {T,H}? Is this simply how we've defined an ""outcome"" in probability? My main problem with {H,T} being a different outcome than {T,H} is that we apply binomial coefficients (i.e. we count subsets of sets) in some common probability problems. But if we take {H,T} and {T,H} to be different outcomes, then our ""sets"" are ordered, but sets are by definition unordered... I feel as though the fact that I'm confused about something so basic means that I am missing something fundamental. Any help or insight whatsoever is greatly appreciated!","In either case, one coin flip resulted in a head and the other resulted in a tail. Why is {H,T} a different outcome than {T,H}? Is this simply how we've defined an ""outcome"" in probability? My main problem with {H,T} being a different outcome than {T,H} is that we apply binomial coefficients (i.e. we count subsets of sets) in some common probability problems. But if we take {H,T} and {T,H} to be different outcomes, then our ""sets"" are ordered, but sets are by definition unordered... I feel as though the fact that I'm confused about something so basic means that I am missing something fundamental. Any help or insight whatsoever is greatly appreciated!",,"['probability', 'combinatorics', 'discrete-mathematics', 'binomial-coefficients']"
94,Fair gambler's ruin problem intuition,Fair gambler's ruin problem intuition,,"In a fair gambler's ruin problem, where the gambler starts with k dollars, wins \$1 with probability 1/2 and loses \$1 with probability 1/2, and stops when he/she reaches \$n or \$0. In the solution (from Dobrow's Introduction to Stochastic Processes with R), they let $p_k$ be defined as the probability of reaching \$n with \$k in one's inventory. Then they use the fact that $p_k - p_{k-1} = p_{k-1} - p_{k-2} = ... = p_1 - p_0 = p_1$ . Intuitively this means the probability of reaching \$n with \$k minus the probability of reaching \$n with \$k-1 is equivalent to the probability of reaching \$n with only \$1. Is there an intuitive reason why this is the case?","In a fair gambler's ruin problem, where the gambler starts with k dollars, wins \$1 with probability 1/2 and loses \$1 with probability 1/2, and stops when he/she reaches \$n or \$0. In the solution (from Dobrow's Introduction to Stochastic Processes with R), they let be defined as the probability of reaching \$n with \$k in one's inventory. Then they use the fact that . Intuitively this means the probability of reaching \$n with \$k minus the probability of reaching \$n with \$k-1 is equivalent to the probability of reaching \$n with only \$1. Is there an intuitive reason why this is the case?",p_k p_k - p_{k-1} = p_{k-1} - p_{k-2} = ... = p_1 - p_0 = p_1,"['probability', 'stochastic-processes', 'intuition']"
95,"You roll a die until you get a $5$, what is the expected value of the minimum value rolled?","You roll a die until you get a , what is the expected value of the minimum value rolled?",5,"I am struggling to work out a simple way to answer this, and a rationale behind this approach using tail sum (as I do not understand): $$E\left( x\right) =\sum ^{5}_{k=1}P\left( x\geq k\right) =\dfrac {1}{6}\sum ^{5}_{k=1}\left( \sum ^{\infty }_{i=0}\left( \dfrac {k}{6}\right) ^{i}\right)  = \frac{137}{60}.$$ Does this always hold? $$E\left( x\right)=\sum ^{n}_{k=1}kP\left( x= k\right)  =\sum ^{n}_{k=1}P\left( x\geq k\right)$$ I have never seen this formula, but working through it I understand. EDIT: I can get the right answer with a long winded method, calculating each probability separately, which I believe the Tails sum speeds up: This is my long winded approach. $$E\left( X_{\min }\right) = 5P\left( x= 5\right) +\ldots +1P(x=1)$$ $$=5\left( \dfrac {1}{6}\sum ^{\infty }_{i=0}\left( \dfrac {1}{6}\right) ^{i}\right) +4\left( \dfrac {1}{6}\sum ^{\infty }_{i=1}\left( \dfrac {2}{6}\right) ^{i}- \dfrac {1}{6}\sum ^{\infty }_{i=1}\left( \dfrac {1}{6}\right) ^{i}\right)+\ldots$$ $$+1\left( \dfrac {1}{6}\sum ^{\infty }_{i=1}\left( \dfrac {5}{6}\right) ^{i}- \dfrac {1}{6}\sum ^{\infty }_{i=1}\left( \dfrac {4}{6}\right) ^{i}\right),$$ where $\dfrac {1}{6}$ represents getting a $5$ , so the first sum is all the possibilities of getting repeated $6$ s and then a $5$ , or just rolling a $5$ . The next sum is all the possibilities of getting a $4$ or a $6$ , then a $5$ , minus all the possibilities of just getting a $6$ then a $5$ . So it represents all the strings of just $4$ s or $6$ s before getting a $5$ , so all the possibilities of minimum value being a $4$ .","I am struggling to work out a simple way to answer this, and a rationale behind this approach using tail sum (as I do not understand): Does this always hold? I have never seen this formula, but working through it I understand. EDIT: I can get the right answer with a long winded method, calculating each probability separately, which I believe the Tails sum speeds up: This is my long winded approach. where represents getting a , so the first sum is all the possibilities of getting repeated s and then a , or just rolling a . The next sum is all the possibilities of getting a or a , then a , minus all the possibilities of just getting a then a . So it represents all the strings of just s or s before getting a , so all the possibilities of minimum value being a .","E\left( x\right) =\sum ^{5}_{k=1}P\left( x\geq k\right) =\dfrac {1}{6}\sum ^{5}_{k=1}\left( \sum ^{\infty }_{i=0}\left( \dfrac {k}{6}\right) ^{i}\right)  = \frac{137}{60}. E\left( x\right)=\sum ^{n}_{k=1}kP\left( x= k\right)  =\sum ^{n}_{k=1}P\left( x\geq k\right) E\left( X_{\min }\right) = 5P\left( x= 5\right) +\ldots +1P(x=1) =5\left( \dfrac {1}{6}\sum ^{\infty }_{i=0}\left( \dfrac {1}{6}\right) ^{i}\right) +4\left( \dfrac {1}{6}\sum ^{\infty }_{i=1}\left( \dfrac {2}{6}\right) ^{i}- \dfrac {1}{6}\sum ^{\infty }_{i=1}\left( \dfrac {1}{6}\right) ^{i}\right)+\ldots +1\left( \dfrac {1}{6}\sum ^{\infty }_{i=1}\left( \dfrac {5}{6}\right) ^{i}- \dfrac {1}{6}\sum ^{\infty }_{i=1}\left( \dfrac {4}{6}\right) ^{i}\right), \dfrac {1}{6} 5 6 5 5 4 6 5 6 5 4 6 5 4","['probability', 'algebra-precalculus', 'expected-value', 'dice']"
96,Probability of symmetric difference,Probability of symmetric difference,,"How do we prove the following inequality? $$\mathbb{P}[A\triangle B ]\geq \max\left \{ \mathbb{P}[A-B],\mathbb{P}[B-A] \right \}$$ I already proved that $$\mathbb{P}[A\triangle B ]=\mathbb{P}[A]+\mathbb{P}[B]-2\mathbb{P}[A\cap B]$$ $$\left | \mathbb{P}[A]-\mathbb{P}[B] \right |\leq \mathbb{P}[A\triangle B ]$$","How do we prove the following inequality? $$\mathbb{P}[A\triangle B ]\geq \max\left \{ \mathbb{P}[A-B],\mathbb{P}[B-A] \right \}$$ I already proved that $$\mathbb{P}[A\triangle B ]=\mathbb{P}[A]+\mathbb{P}[B]-2\mathbb{P}[A\cap B]$$ $$\left | \mathbb{P}[A]-\mathbb{P}[B] \right |\leq \mathbb{P}[A\triangle B ]$$",,"['probability', 'proof-writing']"
97,What is a countably generated $\sigma$-algebra? Can't find a definition online [closed],What is a countably generated -algebra? Can't find a definition online [closed],\sigma,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question What is a countably generated $\sigma$-algebra? Is Borel $\sigma$-algebra countably generated?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question What is a countably generated $\sigma$-algebra? Is Borel $\sigma$-algebra countably generated?",,"['probability', 'general-topology', 'measure-theory']"
98,Algorithm for calculating the mutual information between continuous variables,Algorithm for calculating the mutual information between continuous variables,,I'm trying to use the notion of mutual information between continuous variables in a software. https://en.wikipedia.org/wiki/Mutual_information The inputs of the algorithm would be two lists l1 and l2 of n real numbers and the output would be a real number m that represents the mutual information between the values in l1 and l2. But I don't know how can I translate that formula in an algorithm. Can you help me? Best regards.,I'm trying to use the notion of mutual information between continuous variables in a software. https://en.wikipedia.org/wiki/Mutual_information The inputs of the algorithm would be two lists l1 and l2 of n real numbers and the output would be a real number m that represents the mutual information between the values in l1 and l2. But I don't know how can I translate that formula in an algorithm. Can you help me? Best regards.,,"['probability', 'computer-science', 'information-theory', 'computational-mathematics']"
99,What is the standard deviation of dice rolling?,What is the standard deviation of dice rolling?,,"When trying to find how to simulate rolling a variable amount of dice with a variable but unique number of sides, I read that the mean is $\dfrac{sides+1}{2}$, and that the standard deviation is $\sqrt{\dfrac{quantity\times(sides^2-1)}{12}}$. I doubt that the $12$  comes from the formula because it seems strongly linked with the examples of using two six-sided dice. Is the formula for the standard deviation correct? If not what is it?","When trying to find how to simulate rolling a variable amount of dice with a variable but unique number of sides, I read that the mean is $\dfrac{sides+1}{2}$, and that the standard deviation is $\sqrt{\dfrac{quantity\times(sides^2-1)}{12}}$. I doubt that the $12$  comes from the formula because it seems strongly linked with the examples of using two six-sided dice. Is the formula for the standard deviation correct? If not what is it?",,['probability']
