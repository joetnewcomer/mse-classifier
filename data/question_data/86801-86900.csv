,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Orthonormal basis of the Hilbert space $L^2(\left[0,+\infty\right[, dx)$? [closed]",Orthonormal basis of the Hilbert space ? [closed],"L^2(\left[0,+\infty\right[, dx)","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I am searching for an orthonormal basis of the Hilbert space $L^2(\left[0,+\infty\right[, dx)$. Thank you in advance","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I am searching for an orthonormal basis of the Hilbert space $L^2(\left[0,+\infty\right[, dx)$. Thank you in advance",,"['calculus', 'real-analysis', 'functional-analysis', 'hilbert-spaces']"
1,Exchanging limits with norms and linear functionals,Exchanging limits with norms and linear functionals,,"In a normed vector space $X$, when can we say: $\lim\|x_n\|=\|\lim x_n\|$ and further, if $f\in X^{*}$, when can we say: $\lim fx_n=f(\lim x_n)$?","In a normed vector space $X$, when can we say: $\lim\|x_n\|=\|\lim x_n\|$ and further, if $f\in X^{*}$, when can we say: $\lim fx_n=f(\lim x_n)$?",,"['real-analysis', 'functional-analysis', 'limits', 'normed-spaces']"
2,Distributional derivative of absolute value function,Distributional derivative of absolute value function,,"I'm tying to understand distributional derivatives. That's why I'm trying to calculate the distributional derivative of $|x|$, but I got a little confused. I know that a weak derivative would be $\operatorname{sgn}(x)$, but not only I'm not finding that one in my calculations, I ended up with a wrong solution and in my other attempt I got stuck pretty quickly. Could someone tell me where my error in reasoning occurs or what I missed? First attempt $$ (T_{|x|}(\phi))' = T_{|x|'}(\phi) =\int_{\mathbb{R}_+} \phi(x) dx - \int_{\mathbb{R}_-} \phi(x) dx = const. $$ Second attempt $$ (T_{|x|}(\phi))' = -T_{|x|}(\phi') = -\int_\mathbb{R} |x| \phi'(x) dx =-\int_{\mathbb{R}_+} x \phi'(x) dx + \int_{\mathbb{R}_-} x \phi'(x) dx $$","I'm tying to understand distributional derivatives. That's why I'm trying to calculate the distributional derivative of $|x|$, but I got a little confused. I know that a weak derivative would be $\operatorname{sgn}(x)$, but not only I'm not finding that one in my calculations, I ended up with a wrong solution and in my other attempt I got stuck pretty quickly. Could someone tell me where my error in reasoning occurs or what I missed? First attempt $$ (T_{|x|}(\phi))' = T_{|x|'}(\phi) =\int_{\mathbb{R}_+} \phi(x) dx - \int_{\mathbb{R}_-} \phi(x) dx = const. $$ Second attempt $$ (T_{|x|}(\phi))' = -T_{|x|}(\phi') = -\int_\mathbb{R} |x| \phi'(x) dx =-\int_{\mathbb{R}_+} x \phi'(x) dx + \int_{\mathbb{R}_-} x \phi'(x) dx $$",,"['functional-analysis', 'distribution-theory', 'weak-derivatives']"
3,How to show that $L^p$ norm is monotone increasing?,How to show that  norm is monotone increasing?,L^p,"I am trying to solve the following (very standard) exercise: Let $(X,\mathcal M,\mu)$ be a measure space and $f\in L^r\cap L^\infty$ for some $1\leqslant r<\infty$. Then $f\in L^p$ for $1\leqslant p < r$ and $$\lim_{p\to\infty} \|f\|_p = \|f\|_\infty.$$ I have worked through the proof here: Limit of $L^p$ norm and find it satisfactory, however I am trying to take a different approach. I'd like to show that $$r\leqslant p \implies \|f\|_r\leqslant \|f\|_p$$ and then use monotone convergence to prove the result. I am stuck on how to prove this inequality though.","I am trying to solve the following (very standard) exercise: Let $(X,\mathcal M,\mu)$ be a measure space and $f\in L^r\cap L^\infty$ for some $1\leqslant r<\infty$. Then $f\in L^p$ for $1\leqslant p < r$ and $$\lim_{p\to\infty} \|f\|_p = \|f\|_\infty.$$ I have worked through the proof here: Limit of $L^p$ norm and find it satisfactory, however I am trying to take a different approach. I'd like to show that $$r\leqslant p \implies \|f\|_r\leqslant \|f\|_p$$ and then use monotone convergence to prove the result. I am stuck on how to prove this inequality though.",,"['functional-analysis', 'convergence-divergence', 'lp-spaces']"
4,Is $A=\{x \in \ell^2 \mid \sum_{n=1}^{\infty} \frac{x_n}{n}=0 \}$ dense in $\ell^2$,Is  dense in,A=\{x \in \ell^2 \mid \sum_{n=1}^{\infty} \frac{x_n}{n}=0 \} \ell^2,"I think that the answer is no I thought quite a bit about this problem. My idea was to build a sequence $(y_n)_{n \in \mathbb{N}} \subset A$ such that given  a $x \in \ell^2$ we pick the first N components of $y \in A$ as $(y_1,y_2, \dots, y_N)=(x_1, \dots, x_N)$ and try to make $\|x-y\|  < \varepsilon$. $$ \|x-y\|^2=\sum_{n=1}^\infty |x_n-y_n|^2=\sum_{n=N+1}^\infty |x_n-y_n|^2 \leq 2\sum_{n=N+1}^\infty x_n^2+y_n^2$$ Now as $y \in A$ it also has to satisfy the condition $\sum_{n=1}^\infty \frac{y_n}{n}=0$ But from Cauchy-Schwarz inequality (as both $y \in \ell^2$ and $\frac{1}{n} \in \ell^2$ we have that $\sum_{n=1}^\infty \frac{y_n}{n} \leq (\sum_{n=1}^\infty y_n^2)^{\frac{1}{2}} (\sum_{n=1}^\infty \frac{1}{n^2})^{\frac{1}{2}}$ and therefore if $\sum_{n=1}^{N}\frac{y_n} {n}=-a$ $\implies$ $\sum_{n=N+1}^\infty \frac{y_n} {n}=a$ And it therefore follows that $a \leq (\sum_{n=N+1}^\infty y_n^2)^{\frac{1}{2}} \pi/{\sqrt{6}}$ Now as $y \in \ell^2 \implies \lim_{n\ \to \infty} y_n =0$ and if $a$ is large enough we cannot approximate $x$ by $y$ because I need both $\sum_{n=N+1}^{\infty} x_n^2 <\epsilon/4$ and $\sum_{n=N+1}^{\infty} y_n^2 <\epsilon/4$. In the case of $(x_n)_n$ we can always choose an $N$ large enough but because of the aforementioned argument , we cannot ensure that such a $y \in A$ exists. Is the idea of the proof correct? What is bothering me is that there could be another way of constructing the sequence $(y_n)_n$ which could work. Thanks","I think that the answer is no I thought quite a bit about this problem. My idea was to build a sequence $(y_n)_{n \in \mathbb{N}} \subset A$ such that given  a $x \in \ell^2$ we pick the first N components of $y \in A$ as $(y_1,y_2, \dots, y_N)=(x_1, \dots, x_N)$ and try to make $\|x-y\|  < \varepsilon$. $$ \|x-y\|^2=\sum_{n=1}^\infty |x_n-y_n|^2=\sum_{n=N+1}^\infty |x_n-y_n|^2 \leq 2\sum_{n=N+1}^\infty x_n^2+y_n^2$$ Now as $y \in A$ it also has to satisfy the condition $\sum_{n=1}^\infty \frac{y_n}{n}=0$ But from Cauchy-Schwarz inequality (as both $y \in \ell^2$ and $\frac{1}{n} \in \ell^2$ we have that $\sum_{n=1}^\infty \frac{y_n}{n} \leq (\sum_{n=1}^\infty y_n^2)^{\frac{1}{2}} (\sum_{n=1}^\infty \frac{1}{n^2})^{\frac{1}{2}}$ and therefore if $\sum_{n=1}^{N}\frac{y_n} {n}=-a$ $\implies$ $\sum_{n=N+1}^\infty \frac{y_n} {n}=a$ And it therefore follows that $a \leq (\sum_{n=N+1}^\infty y_n^2)^{\frac{1}{2}} \pi/{\sqrt{6}}$ Now as $y \in \ell^2 \implies \lim_{n\ \to \infty} y_n =0$ and if $a$ is large enough we cannot approximate $x$ by $y$ because I need both $\sum_{n=N+1}^{\infty} x_n^2 <\epsilon/4$ and $\sum_{n=N+1}^{\infty} y_n^2 <\epsilon/4$. In the case of $(x_n)_n$ we can always choose an $N$ large enough but because of the aforementioned argument , we cannot ensure that such a $y \in A$ exists. Is the idea of the proof correct? What is bothering me is that there could be another way of constructing the sequence $(y_n)_n$ which could work. Thanks",,"['functional-analysis', 'lp-spaces']"
5,"If $T: \ell^2 \to \ell^2 $ is defined as $Tx = (\frac{x_i}{i})$, find $\lVert T \rVert$.","If  is defined as , find .",T: \ell^2 \to \ell^2  Tx = (\frac{x_i}{i}) \lVert T \rVert,Here $(x_i) \in \ell^2$. All I have on paper right now is $$\rVert Tx\rVert = \sqrt{\sum_{i=1}^{\infty} \frac{x_i ^2}{i^2}}$$ and I'm not sure about what's next. Please help.,Here $(x_i) \in \ell^2$. All I have on paper right now is $$\rVert Tx\rVert = \sqrt{\sum_{i=1}^{\infty} \frac{x_i ^2}{i^2}}$$ and I'm not sure about what's next. Please help.,,['functional-analysis']
6,Dirac delta distribution & integration against locally integrable function,Dirac delta distribution & integration against locally integrable function,,"I was reading the a lecture note online about distribution theory and it said: The Dirac delta distribution $\delta \in D'$ is defined as $\delta(\varphi)= \varphi(0) $, and there's no locally integrable function $f$ such that $T_f=\delta$, namely, $\int_{R^n}=f(x)\varphi(x)ds=\varphi(0)$, for all $\varphi \in D$. I was trying to construct a proof about it but failed... Can anyone help ?","I was reading the a lecture note online about distribution theory and it said: The Dirac delta distribution $\delta \in D'$ is defined as $\delta(\varphi)= \varphi(0) $, and there's no locally integrable function $f$ such that $T_f=\delta$, namely, $\int_{R^n}=f(x)\varphi(x)ds=\varphi(0)$, for all $\varphi \in D$. I was trying to construct a proof about it but failed... Can anyone help ?",,"['functional-analysis', 'measure-theory', 'distribution-theory', 'lebesgue-measure']"
7,How to show that the Volterra operator is not normal,How to show that the Volterra operator is not normal,,"How to show that the Volterra operator: $$V:L_2(0,1)\rightarrow L_2(0,1): x\mapsto \int^t_0 x(s) \, ds$$ is not normal.  $t\in (0,1)$ Could you please help with this question.","How to show that the Volterra operator: $$V:L_2(0,1)\rightarrow L_2(0,1): x\mapsto \int^t_0 x(s) \, ds$$ is not normal.  $t\in (0,1)$ Could you please help with this question.",,"['real-analysis', 'functional-analysis', 'operator-theory']"
8,Inner product on direct sum of Hilbert spaces,Inner product on direct sum of Hilbert spaces,,Let $H_1$ and $H_2$ are two different Hilbert spaces then how can we define the inner product on $H_1\oplus H_2$,Let $H_1$ and $H_2$ are two different Hilbert spaces then how can we define the inner product on $H_1\oplus H_2$,,['functional-analysis']
9,Is every Hilbert space an $L^2$ space?,Is every Hilbert space an  space?,L^2,"Let $H$ be any Hilbert space. Must there exist a measure space $(X,\scr{M},\mu)$ such that we have a Hilbert space isomorphism: $$H\cong L^2(\mu)$$ Thank you","Let $H$ be any Hilbert space. Must there exist a measure space $(X,\scr{M},\mu)$ such that we have a Hilbert space isomorphism: $$H\cong L^2(\mu)$$ Thank you",,"['functional-analysis', 'measure-theory', 'hilbert-spaces', 'examples-counterexamples']"
10,"Differences between $C_c^\infty[0,T]$ and $C_c^\infty(0,T)$",Differences between  and,"C_c^\infty[0,T] C_c^\infty(0,T)","I believe it is true that: If $f \in C_c^\infty(0,T)$, then $f(T)=f(0)=0$. $C_c^\infty(0,T) \subset C_c^\infty[0,T]$ $C^\infty(0,T) \subset C_c^\infty[0,T]$ If $f \in C_c^\infty[0,T]$, it doesn't necessarily mean that $f(T)=f(0)=0$. Finally, what happen if I define weak derivative as $$\int_0^T u\phi' = -\int_0^T u'\phi$$ for all $\phi \in C_c^\infty[0,T]$, instead of $C_c^\infty(0,T)$. I will think more on this but maybe somebody has already studied it. Anyway, more information about these differences would be appreciated.","I believe it is true that: If $f \in C_c^\infty(0,T)$, then $f(T)=f(0)=0$. $C_c^\infty(0,T) \subset C_c^\infty[0,T]$ $C^\infty(0,T) \subset C_c^\infty[0,T]$ If $f \in C_c^\infty[0,T]$, it doesn't necessarily mean that $f(T)=f(0)=0$. Finally, what happen if I define weak derivative as $$\int_0^T u\phi' = -\int_0^T u'\phi$$ for all $\phi \in C_c^\infty[0,T]$, instead of $C_c^\infty(0,T)$. I will think more on this but maybe somebody has already studied it. Anyway, more information about these differences would be appreciated.",,"['functional-analysis', 'partial-differential-equations', 'continuity', 'distribution-theory', 'weak-derivatives']"
11,How to show that $\|T\|^2=\|T^*T\|$ for a bounded linear operator $T$?,How to show that  for a bounded linear operator ?,\|T\|^2=\|T^*T\| T,"I need to show that for a bounded linear operator, $T$, on a Hilbert space: \begin{align*} \|T\|^2=\|T^*T\| \end{align*} All I have so far: \begin{align*} \|T^*T\|&=\sup\{|\langle T^*Tf,g \rangle |:\|f\|\le1,\|g\|\le1\} \\ &= \sup\{|\langle Tf,Tg \rangle|:\|f\|\le1,\|g\|\le1\} \\ &\le \sup_{\|f\|\le1}\|Tf\|\sup_{\|g\|\le1}\|Tg\| \end{align*} Not too sure what to do from here (or even if this is right so far) Any help is appreciated.","I need to show that for a bounded linear operator, $T$, on a Hilbert space: \begin{align*} \|T\|^2=\|T^*T\| \end{align*} All I have so far: \begin{align*} \|T^*T\|&=\sup\{|\langle T^*Tf,g \rangle |:\|f\|\le1,\|g\|\le1\} \\ &= \sup\{|\langle Tf,Tg \rangle|:\|f\|\le1,\|g\|\le1\} \\ &\le \sup_{\|f\|\le1}\|Tf\|\sup_{\|g\|\le1}\|Tg\| \end{align*} Not too sure what to do from here (or even if this is right so far) Any help is appreciated.",,"['real-analysis', 'functional-analysis', 'hilbert-spaces', 'normed-spaces', 'adjoint-operators']"
12,Hilbert Schmidt operators as an ideal in operators.,Hilbert Schmidt operators as an ideal in operators.,,"Let $H$ be a Hilbert space. For $\{e_n\}$ an orthonormal basis of $H$, we call $T\in B(H)$, a Hilbert Schmidt operator if  $ \|T\|_2^2:=\sum_n \|Te_n\|^2 <\infty.$ I have seen somewhere before that $ \|ST\|_2 \leq \|S\|_{B(H)} \|T\|_2 $ for all $S\in B(H)$ arbitrary. In other words, the space of Hilbert Schmidt is an ideal in $B(H)$. Where can I find this? Where can I find it for Matrices?","Let $H$ be a Hilbert space. For $\{e_n\}$ an orthonormal basis of $H$, we call $T\in B(H)$, a Hilbert Schmidt operator if  $ \|T\|_2^2:=\sum_n \|Te_n\|^2 <\infty.$ I have seen somewhere before that $ \|ST\|_2 \leq \|S\|_{B(H)} \|T\|_2 $ for all $S\in B(H)$ arbitrary. In other words, the space of Hilbert Schmidt is an ideal in $B(H)$. Where can I find this? Where can I find it for Matrices?",,"['functional-analysis', 'hilbert-spaces']"
13,On the properties of the Sobolev Spaces $H^s$,On the properties of the Sobolev Spaces,H^s,"Let $H^s(\mathbb{R}^d):= \{ u \in \mathcal{S}' : (1+|\xi|^2)^{s/2}\hat{u}(\xi) \in L^2(\mathbb{R}^d)\}$. It can be shown that this space is a Hilbert space and that $H^s \subset H^t$ if $t \leq s$. Now suppose we have $t > s>0$ such that $H^s \subsetneq H^t$. Then we know that $(H^s)^* \supsetneq (H^t)^*$, where $^*$ denotes the dual. At the same time, since $H^s$ is a Hilbert space, the Riesz Representation theorem tells us that $H^s \cong (H^s)^*$ and similarly, $H^t \cong (H^t)^*$. But then doesn't $(H^s)^* \supsetneq (H^t)^*$ imply that $H^s \supsetneq H^t$, which contradicts our earlier statement that $H^s \subsetneq H^t$? What part of the argument here falls apart?","Let $H^s(\mathbb{R}^d):= \{ u \in \mathcal{S}' : (1+|\xi|^2)^{s/2}\hat{u}(\xi) \in L^2(\mathbb{R}^d)\}$. It can be shown that this space is a Hilbert space and that $H^s \subset H^t$ if $t \leq s$. Now suppose we have $t > s>0$ such that $H^s \subsetneq H^t$. Then we know that $(H^s)^* \supsetneq (H^t)^*$, where $^*$ denotes the dual. At the same time, since $H^s$ is a Hilbert space, the Riesz Representation theorem tells us that $H^s \cong (H^s)^*$ and similarly, $H^t \cong (H^t)^*$. But then doesn't $(H^s)^* \supsetneq (H^t)^*$ imply that $H^s \supsetneq H^t$, which contradicts our earlier statement that $H^s \subsetneq H^t$? What part of the argument here falls apart?",,['functional-analysis']
14,$\omega$ - space of all sequences with Fréchet metric,- space of all sequences with Fréchet metric,\omega,"I'm working on to prove the following: Show that the convergence in the space $\omega$ (space of all sequences with respect to the Fréchet metric) is the coordinate convergence. Any hint is appreciated, thanks.","I'm working on to prove the following: Show that the convergence in the space $\omega$ (space of all sequences with respect to the Fréchet metric) is the coordinate convergence. Any hint is appreciated, thanks.",,['functional-analysis']
15,Compactness of an Integral operator,Compactness of an Integral operator,,"Let $K(s,t)$ be a real-valued function of two real variables, and let $T: L^2(\mathbb{R}) \to L^2(\mathbb{R})$ be defined by $(Tf)(s) = \int_\mathbb{R} K(s,t) f(t) dt$. If $||K||_{L^2({\mathbb{R}^2})} < \infty$, can we say that $T$ is a compact operator? I think this is true if we are looking at a bounded domain for $K$ and $f$ (by an application of the Arzela-Ascoli theorem), but I am not sure if it is true in general.","Let $K(s,t)$ be a real-valued function of two real variables, and let $T: L^2(\mathbb{R}) \to L^2(\mathbb{R})$ be defined by $(Tf)(s) = \int_\mathbb{R} K(s,t) f(t) dt$. If $||K||_{L^2({\mathbb{R}^2})} < \infty$, can we say that $T$ is a compact operator? I think this is true if we are looking at a bounded domain for $K$ and $f$ (by an application of the Arzela-Ascoli theorem), but I am not sure if it is true in general.",,['functional-analysis']
16,Left adjoint to the forgetful functor from Hilbert spaces to topological spaces,Left adjoint to the forgetful functor from Hilbert spaces to topological spaces,,"I'm trying to generalize a method which can solve a problem involving discrete group to continuous group. And the method involve construct a ""free vector space"" from discrete space. So I'm trying to find a way to construct some kind of ""free Hilbert space"" from a topological space. But I have no idea how to achieve this goal. Then I find that one can get a free group or free vector space by considering the left adjoint of forgetful functor, so I wonder if one can go this way to get ""free Hilbert space"". But I don't know how to construct this adjoint. Let $\mathbf{Hil}$ be the category of Hilbert spaces, $\mathbf{Top}$ be the category of topological spacces, and consider the forgetful functor $ F : \mathbf{Hil} \to \mathbf{Top}.$ Does this functor $F$ have a left adjoint? If it does, what is this left adjoint?","I'm trying to generalize a method which can solve a problem involving discrete group to continuous group. And the method involve construct a ""free vector space"" from discrete space. So I'm trying to find a way to construct some kind of ""free Hilbert space"" from a topological space. But I have no idea how to achieve this goal. Then I find that one can get a free group or free vector space by considering the left adjoint of forgetful functor, so I wonder if one can go this way to get ""free Hilbert space"". But I don't know how to construct this adjoint. Let be the category of Hilbert spaces, be the category of topological spacces, and consider the forgetful functor Does this functor have a left adjoint? If it does, what is this left adjoint?",\mathbf{Hil} \mathbf{Top}  F : \mathbf{Hil} \to \mathbf{Top}. F,"['functional-analysis', 'category-theory', 'adjoint-functors']"
17,"Example of a sequence that is Cauchy in a stronger norm and convergent in a weaker norm, but not convergent in the stronger norm?","Example of a sequence that is Cauchy in a stronger norm and convergent in a weaker norm, but not convergent in the stronger norm?",,"A norm $\|\cdot\|_1$ on a normed vector space is called stronger than $\|\cdot\|_2$ when $\|x\|_2\leq M\|x\|_1$ for some $M>0$ and all $x$ . It is a standard trick (e.g. in proving completeness) to find the limit in a weaker sense first, and then prove that it is a stronger limit, e.g. Cauchy in Norm and Weakly converge Implies Norm convergent . But it always uses some extra information beyond one convergence being weaker than the other. Examples in Cauchy sequence converge for one metric while not converging for another? are not for norm metrics, hence the question.","A norm on a normed vector space is called stronger than when for some and all . It is a standard trick (e.g. in proving completeness) to find the limit in a weaker sense first, and then prove that it is a stronger limit, e.g. Cauchy in Norm and Weakly converge Implies Norm convergent . But it always uses some extra information beyond one convergence being weaker than the other. Examples in Cauchy sequence converge for one metric while not converging for another? are not for norm metrics, hence the question.",\|\cdot\|_1 \|\cdot\|_2 \|x\|_2\leq M\|x\|_1 M>0 x,"['functional-analysis', 'convergence-divergence', 'normed-spaces', 'cauchy-sequences']"
18,"Let $X, Y$ be Hilbert spaces. Is $\mathcal L(X, Y)$ togerther with the operator norm a Hilbert space?",Let  be Hilbert spaces. Is  togerther with the operator norm a Hilbert space?,"X, Y \mathcal L(X, Y)","Let $(X, |\cdot|_1)$ and $(Y, |\cdot|_2)$ be Banach spaces. Let $\mathcal L(X, Y)$ be the space of all continuous linear maps from $X$ to $Y$ . We endow $\mathcal L(X, Y)$ with the operator norm $\|\cdot\|$ . Then $(\mathcal L(X, Y), \|\cdot\|)$ is a Banach space. I would like to ask if the following statement is true, i.e., Statement If $X, Y$ are Hilbert spaces, then so is $\mathcal L(X, Y)$ . If $Y =\mathbb R$ , the statement is true by Riesz representation theorem. Thank you so much for your elaboration!","Let and be Banach spaces. Let be the space of all continuous linear maps from to . We endow with the operator norm . Then is a Banach space. I would like to ask if the following statement is true, i.e., Statement If are Hilbert spaces, then so is . If , the statement is true by Riesz representation theorem. Thank you so much for your elaboration!","(X, |\cdot|_1) (Y, |\cdot|_2) \mathcal L(X, Y) X Y \mathcal L(X, Y) \|\cdot\| (\mathcal L(X, Y), \|\cdot\|) X, Y \mathcal L(X, Y) Y =\mathbb R","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
19,"Why is $C_0(X)$ not $C_b(X)$ for $X$ locally compact the ""prototypical"" abelian $C^*$ Algebra","Why is  not  for  locally compact the ""prototypical"" abelian  Algebra",C_0(X) C_b(X) X C^*,"Take $X$ to be a locally compact Hausdorf space, $C_b(X)$ to be bounded continuous functions and $C_0(X)$ to be bounded continuous functions that vanish at infinity. If $X$ is compact these notions coincide but in the case of say $\mathbb{R}$ the latter is a subalgebra of the former. As far as I can tell, both of these are abelian C* algebras. However, $C_0(X)$ seems to be preferred as the prototypical example. From wikipedia on C* algebras: Another important class of non-Hilbert C*-algebras includes the algebra $C_0(X)$ of complex-valued continuous functions on X that vanish at infinity, where X is a locally compact Hausdorff space. From https://math.dartmouth.edu/~dana/bookspapers/cstar.pdf The Banach algebras $C_0(X)$ (for X locally compact Hausdorff) will be our favorite example of a commutative Banach algebra. Is this simply because $C_b(X)$ is a bit more unruly? It seems like the ""goal"" of this it to show via the Gelfand Representation that all abelian C* Algebras are in some sense functions on a compact space, is the point that $C_0(X)$ is ""the same as"" $C(X\cup{\infty})$ (the one point compactification), but the same is not true for $C_b(X)$ ?","Take to be a locally compact Hausdorf space, to be bounded continuous functions and to be bounded continuous functions that vanish at infinity. If is compact these notions coincide but in the case of say the latter is a subalgebra of the former. As far as I can tell, both of these are abelian C* algebras. However, seems to be preferred as the prototypical example. From wikipedia on C* algebras: Another important class of non-Hilbert C*-algebras includes the algebra of complex-valued continuous functions on X that vanish at infinity, where X is a locally compact Hausdorff space. From https://math.dartmouth.edu/~dana/bookspapers/cstar.pdf The Banach algebras (for X locally compact Hausdorff) will be our favorite example of a commutative Banach algebra. Is this simply because is a bit more unruly? It seems like the ""goal"" of this it to show via the Gelfand Representation that all abelian C* Algebras are in some sense functions on a compact space, is the point that is ""the same as"" (the one point compactification), but the same is not true for ?",X C_b(X) C_0(X) X \mathbb{R} C_0(X) C_0(X) C_0(X) C_b(X) C_0(X) C(X\cup{\infty}) C_b(X),"['functional-analysis', 'c-star-algebras']"
20,Why bother with the space $\mathcal{L}^1$ for integration when we can abstractly deal with the completion of a semi-normed space,Why bother with the space  for integration when we can abstractly deal with the completion of a semi-normed space,\mathcal{L}^1,"I'm studying the Bochner-Lebesue integral, and while I understand the general construction, I have a few questions about the way it is being presented. Typically, the story goes like this: We start with a measure space $(X,\mathcal{A}, \mu)$ , and a Banach space $E$ (over $\Bbb{R}$ or $\Bbb{C}$ ). Then, we can define the space $S$ of simple functions $X\to E$ , and for such simple functions, we can define an integral $I(\cdot):= \int_X (\cdot) \, d\mu : S \to E$ in the usual way. Then, we can define a semi-norm $\lVert\cdot \rVert_1$ on $S$ by setting $\lVert \phi \rVert_1 := \int_X|\phi|\, d\mu$ (this is to be thought of as integration when the Banach space is $E=\Bbb{R}$ , which is of course well-defined). Thus, we have a semi-normed space $(S, \lVert \cdot \rVert_1)$ . At this point, we note that $S$ need not be complete, which of course very undesirable for analysis. So, all the presentations I've seen start by defining $\mathcal{L}^1$ as the space of functions $X\to E$ which are the almost-everywhere pointwise limit of Cauchy sequences in $S$ . Then, one proves that under these hypotheses, we can extend the integral to a map (pardon the reuse of notation) $I(\cdot)\equiv \int_X(\cdot)\, d\mu:\mathcal{L}^1 \to E$ , and also extend the seminorm $\lVert \cdot \rVert_1$ to $\mathcal{L}^1$ , such that integration is still a continuous map (with operator norm $\leq 1$ ), and that finally, $(\mathcal{L}^1, \lVert \cdot \rVert_1)$ is a complete semi-normed space containing the simple functions $S$ as a dense subspace. Therefore, by taking the quotient space of $\mathcal{L}^1/\{\phi\in \mathcal{L}^1: \, \lVert \phi\rVert_1 = 0\}$ , and calling this $L^1$ , this becomes a Banach space (because by taking this quotient, the semi-norm induces a norm, which is easily verified to be complete). Finally, it is a simple matter of linear algebra to see that we can ""transfer"" the integration map in the sense that we get a map $\tilde{I}:L^1 \to E$ , such that $I = \tilde{I}\circ \pi$ ( $\pi$ being the quotient map $\mathcal{L}^1 \to L^1$ ). The result is that we have an integration operator $\tilde{I}$ , defined on a Banach space $L^1$ , which naturally reduces to what we'd like it to be on simple functions. Now, my question is that why do we bother to introduce the space $\mathcal{L}^1$ along the way. My thinking is that just as every metric space has a completion, which is uniquely determined up to isometry, we can do a similar thing for semi-normed spaces, in the form of this theorem: Theorem Let $(S, \lVert \cdot \rVert)$ be a semi-normed space (over real or complex field), and let $S_0$ be the subspace of elements with $0$ semi-norm. Then, there exists a completion of $S$ , i.e a pair $(V,\gamma)$ , where $V$ is a Banach space (over the same field), and $\gamma:S\to V$ is a map such that $\gamma$ is linear $\ker(\gamma) = S_0$ $\text{image}(\gamma)$ is a dense subspace of $V$ $\gamma$ preserves seminorms and norms; i.e for all $s\in S$ , $\lVert\gamma(s) \rVert_V = \lVert s \rVert_S$ . Also, this completion is determined up to isomorphism (i.e if we had another such pair, then we can make a nice commutative diagram and then obtain an isomorphism of Banach spaces simply by extending the relevant maps from the dense subspaces to the whole space). So, when we have the space of simple functions $S$ , we could apply this theorem to get the Banach space $V$ (which is up to isomorphism the same as $L^1$ constructed above), and using similar linear algebra trickery, we can induce an integral $\tilde{I}$ on a dense subspace of $V$ , and then extend by continuity to the whole space. My questions/concerns: I realize that by the uniqueness aspect of the completion, both these methods give us the same final outcome: a Banach space, and some type of notion of integral, and of course, the first approach is much more concrete and easier to appreciate on first glance. However, I recently read up about completions of metric (semi-)normed spaces, which is why I thought of the second approach. So I guess my question boils down to: is there anything we gain significantly (besides a bit of concreteness) by realizing $L^1$ as a certain quotient space of functions, rather than just thinking of $L^1$ as an abstract completion of the space of simple functions? Is it perhaps because thinking of Banach spaces as being (almost) a space of functions, rather than some abstract construction (like equivalence classes of Cauchy sequences) makes it significantly easier to analyze the space in some sense (hence the term ""functional"" analyis)? If this is the case, I'd appreciate if you could elaborate on why specifically thinking in terms of function spaces makes the analysis easier/clearer/preferable (I'm not too sure what word I should use here).","I'm studying the Bochner-Lebesue integral, and while I understand the general construction, I have a few questions about the way it is being presented. Typically, the story goes like this: We start with a measure space , and a Banach space (over or ). Then, we can define the space of simple functions , and for such simple functions, we can define an integral in the usual way. Then, we can define a semi-norm on by setting (this is to be thought of as integration when the Banach space is , which is of course well-defined). Thus, we have a semi-normed space . At this point, we note that need not be complete, which of course very undesirable for analysis. So, all the presentations I've seen start by defining as the space of functions which are the almost-everywhere pointwise limit of Cauchy sequences in . Then, one proves that under these hypotheses, we can extend the integral to a map (pardon the reuse of notation) , and also extend the seminorm to , such that integration is still a continuous map (with operator norm ), and that finally, is a complete semi-normed space containing the simple functions as a dense subspace. Therefore, by taking the quotient space of , and calling this , this becomes a Banach space (because by taking this quotient, the semi-norm induces a norm, which is easily verified to be complete). Finally, it is a simple matter of linear algebra to see that we can ""transfer"" the integration map in the sense that we get a map , such that ( being the quotient map ). The result is that we have an integration operator , defined on a Banach space , which naturally reduces to what we'd like it to be on simple functions. Now, my question is that why do we bother to introduce the space along the way. My thinking is that just as every metric space has a completion, which is uniquely determined up to isometry, we can do a similar thing for semi-normed spaces, in the form of this theorem: Theorem Let be a semi-normed space (over real or complex field), and let be the subspace of elements with semi-norm. Then, there exists a completion of , i.e a pair , where is a Banach space (over the same field), and is a map such that is linear is a dense subspace of preserves seminorms and norms; i.e for all , . Also, this completion is determined up to isomorphism (i.e if we had another such pair, then we can make a nice commutative diagram and then obtain an isomorphism of Banach spaces simply by extending the relevant maps from the dense subspaces to the whole space). So, when we have the space of simple functions , we could apply this theorem to get the Banach space (which is up to isomorphism the same as constructed above), and using similar linear algebra trickery, we can induce an integral on a dense subspace of , and then extend by continuity to the whole space. My questions/concerns: I realize that by the uniqueness aspect of the completion, both these methods give us the same final outcome: a Banach space, and some type of notion of integral, and of course, the first approach is much more concrete and easier to appreciate on first glance. However, I recently read up about completions of metric (semi-)normed spaces, which is why I thought of the second approach. So I guess my question boils down to: is there anything we gain significantly (besides a bit of concreteness) by realizing as a certain quotient space of functions, rather than just thinking of as an abstract completion of the space of simple functions? Is it perhaps because thinking of Banach spaces as being (almost) a space of functions, rather than some abstract construction (like equivalence classes of Cauchy sequences) makes it significantly easier to analyze the space in some sense (hence the term ""functional"" analyis)? If this is the case, I'd appreciate if you could elaborate on why specifically thinking in terms of function spaces makes the analysis easier/clearer/preferable (I'm not too sure what word I should use here).","(X,\mathcal{A}, \mu) E \Bbb{R} \Bbb{C} S X\to E I(\cdot):= \int_X (\cdot) \, d\mu : S \to E \lVert\cdot \rVert_1 S \lVert \phi \rVert_1 := \int_X|\phi|\, d\mu E=\Bbb{R} (S,
\lVert \cdot \rVert_1) S \mathcal{L}^1 X\to E S I(\cdot)\equiv \int_X(\cdot)\, d\mu:\mathcal{L}^1 \to E \lVert \cdot \rVert_1 \mathcal{L}^1 \leq 1 (\mathcal{L}^1, \lVert \cdot \rVert_1) S \mathcal{L}^1/\{\phi\in \mathcal{L}^1: \, \lVert \phi\rVert_1 = 0\} L^1 \tilde{I}:L^1 \to E I = \tilde{I}\circ \pi \pi \mathcal{L}^1 \to L^1 \tilde{I} L^1 \mathcal{L}^1 (S, \lVert \cdot \rVert) S_0 0 S (V,\gamma) V \gamma:S\to V \gamma \ker(\gamma) = S_0 \text{image}(\gamma) V \gamma s\in S \lVert\gamma(s) \rVert_V = \lVert s \rVert_S S V L^1 \tilde{I} V L^1 L^1","['functional-analysis', 'measure-theory', 'lebesgue-integral', 'banach-spaces', 'complete-spaces']"
21,"If it exists, the inverse of a compact linear operator in infinite dimensional space cannot be bouded","If it exists, the inverse of a compact linear operator in infinite dimensional space cannot be bouded",,"I have been reading some posts on here that I think are related such as this and this . I am still having a tough time coming up with a nice proof for my question. Question: If a compact linear operator $T:X \rightarrow X$ on an infinite dimensional normed space $X$ has an inverse which is defined on all of $X$, show that the inverse cannot be bounded. I found this in $8.3.8$ of Erwin Kreyszig functional analysis.","I have been reading some posts on here that I think are related such as this and this . I am still having a tough time coming up with a nice proof for my question. Question: If a compact linear operator $T:X \rightarrow X$ on an infinite dimensional normed space $X$ has an inverse which is defined on all of $X$, show that the inverse cannot be bounded. I found this in $8.3.8$ of Erwin Kreyszig functional analysis.",,"['functional-analysis', 'inverse', 'compact-operators']"
22,The sequence of polynomials that generates $\sqrt{ x}$,The sequence of polynomials that generates,\sqrt{ x},"Let $A$ be a unital C*-algebra, and $x\in A^+$. We know $\sqrt{x}$ is a unique square root of $x$, is limit of polynomials generated by $x$. My question: What is the representation of these polynomials? I think about using Functional calculus, and find the polynomials that generated the function $\sqrt{x}$. Thought about Maclaurin series, but I could not find anything. Please advise me. Thanks a lot.","Let $A$ be a unital C*-algebra, and $x\in A^+$. We know $\sqrt{x}$ is a unique square root of $x$, is limit of polynomials generated by $x$. My question: What is the representation of these polynomials? I think about using Functional calculus, and find the polynomials that generated the function $\sqrt{x}$. Thought about Maclaurin series, but I could not find anything. Please advise me. Thanks a lot.",,"['functional-analysis', 'operator-theory', 'c-star-algebras']"
23,What does reasonably behaved function mean in the context of mathematics?,What does reasonably behaved function mean in the context of mathematics?,,"I was reading through computer networks, and I saw an expression that I had never seen before when discussing Fourier transformations: “ reasonably behaved function .” What does this mean about a function? I am not able to find an explanation online. Is this expression commonly used? EDIT: The actual question used in the book: In the early 19th century, the French mathematician Jean-Baptiste Fourier proved that any reasonably behaved periodic function, $g(t)$ with period $T$ can be constructed as the sum of a (possibly infinite) number of sines and cosines.","I was reading through computer networks, and I saw an expression that I had never seen before when discussing Fourier transformations: “ reasonably behaved function .” What does this mean about a function? I am not able to find an explanation online. Is this expression commonly used? EDIT: The actual question used in the book: In the early 19th century, the French mathematician Jean-Baptiste Fourier proved that any reasonably behaved periodic function, $g(t)$ with period $T$ can be constructed as the sum of a (possibly infinite) number of sines and cosines.",,"['calculus', 'real-analysis', 'functional-analysis', 'functions', 'terminology']"
24,Why we define topology on vector space in functional analysis,Why we define topology on vector space in functional analysis,,"It is said that functional analysis is just infinite dimensional version of linear algebra. However, I am quite puzzled by this statement since we are mainly doing analysis on it. Another question is that why we want to define topology on vector space, is it because we can let the function to be continuous so that we can gain some benefit from it, e.x. the continuous map of a compact set is bounded. In other words, what we really care is just mapping itself regardless of the topology","It is said that functional analysis is just infinite dimensional version of linear algebra. However, I am quite puzzled by this statement since we are mainly doing analysis on it. Another question is that why we want to define topology on vector space, is it because we can let the function to be continuous so that we can gain some benefit from it, e.x. the continuous map of a compact set is bounded. In other words, what we really care is just mapping itself regardless of the topology",,['functional-analysis']
25,Example when equality holds in Bessel Inequality,Example when equality holds in Bessel Inequality,,"Example of $x\in l^2$ such that $\sum_{k=1}^{\infty}|\langle x,e_k\rangle|^2\leq \|x\|^2$ has strict inequality where $(e_k)$ is an orthonormal sequence in $l^2$ . My thinking: I think it's not possible As $\|x\|\ _{2}=\left(\sum_{k=1}^{\infty}|x_k|^2\right)^{1/2}$ and so by Bessel inequality we have $$ \sum_{k=1}^{\infty}|\langle x,e_k\rangle|^2\leq \left(\left(\sum_{k=1}^{\infty}|x_k|^2\right)^{1/2}\right)^2 $$ $$ \sum_{k=1}^{\infty}|\langle x,e_k\rangle|^2\leq \left(\sum_{k=1}^{\infty}|x_k|^2\right)$$ But aren't both the things same, I mean there should be an equality Kreyzig: Introduction to Functional Analysis, Ch-3, 3.4 Ques 4","Example of such that has strict inequality where is an orthonormal sequence in . My thinking: I think it's not possible As and so by Bessel inequality we have But aren't both the things same, I mean there should be an equality Kreyzig: Introduction to Functional Analysis, Ch-3, 3.4 Ques 4","x\in l^2 \sum_{k=1}^{\infty}|\langle x,e_k\rangle|^2\leq \|x\|^2 (e_k) l^2 \|x\|\ _{2}=\left(\sum_{k=1}^{\infty}|x_k|^2\right)^{1/2} 
\sum_{k=1}^{\infty}|\langle x,e_k\rangle|^2\leq \left(\left(\sum_{k=1}^{\infty}|x_k|^2\right)^{1/2}\right)^2
 
\sum_{k=1}^{\infty}|\langle x,e_k\rangle|^2\leq \left(\sum_{k=1}^{\infty}|x_k|^2\right)",['functional-analysis']
26,Dual space - bounded functionals?,Dual space - bounded functionals?,,"I'm taking a course on functional analysis at the moment and the lecturer has defined the dual space of a normed space $X$ to be the space of all bounded linear functionals and denoted it $X^*$. However if I look at other references (such as Wikipedia or Wolfram MathWorld) the definition of the dual space is given to be the space of all linear functionals (ie, they don't specify that they have to be bounded). Does this imply that any linear functional is necessarily bounded, or is my lecturer giving an unusual definition, or is the definition on Wikipedia wrong? I'm just a bit confused about this.","I'm taking a course on functional analysis at the moment and the lecturer has defined the dual space of a normed space $X$ to be the space of all bounded linear functionals and denoted it $X^*$. However if I look at other references (such as Wikipedia or Wolfram MathWorld) the definition of the dual space is given to be the space of all linear functionals (ie, they don't specify that they have to be bounded). Does this imply that any linear functional is necessarily bounded, or is my lecturer giving an unusual definition, or is the definition on Wikipedia wrong? I'm just a bit confused about this.",,['functional-analysis']
27,How to show that the disc algebra $A(D)$ is a Banach space?,How to show that the disc algebra  is a Banach space?,A(D),I just know that $A(D)$ is a space of functions analytic on the open unit disc and it is a subspace of $H^\infty$ and $H^\infty$ is an hardy space while $H^\infty$ is defined as the vector space of bounded holomorphic functions on the disk. How can I show the disc algebra  is a Banach space? I would be so appreciated if you help me.,I just know that is a space of functions analytic on the open unit disc and it is a subspace of and is an hardy space while is defined as the vector space of bounded holomorphic functions on the disk. How can I show the disc algebra  is a Banach space? I would be so appreciated if you help me.,A(D) H^\infty H^\infty H^\infty,"['functional-analysis', 'banach-spaces']"
28,Compute operator norm of $l^1$ bounded operator,Compute operator norm of  bounded operator,l^1,"I have a problem with the following exercise: We have the operator $T: l^1 \to l^1$ given by $$T(x_1,x_2,x_3,\dots)=\left(\left(1-\frac11\right)x_1, \left(1-\frac12\right)x_2, \dots\right)$$  for $(x_1,x_2,x_3,\dots)$ in $l^1$. Showing that this operator is bounded is easy, but  I am really desperate with showing that the norm $\|T\| = 1$. I know that for bounded operators the norm is defined as $\|T\|=\sup{\left\{\|T(x)\|: \|x\| \le 1\right\}}$. I am also wondering if there exists a x in $ l^1$ such that $\|x\|=1 $ and $\|T(x)\|= \|T\|$ Thank you! :)","I have a problem with the following exercise: We have the operator $T: l^1 \to l^1$ given by $$T(x_1,x_2,x_3,\dots)=\left(\left(1-\frac11\right)x_1, \left(1-\frac12\right)x_2, \dots\right)$$  for $(x_1,x_2,x_3,\dots)$ in $l^1$. Showing that this operator is bounded is easy, but  I am really desperate with showing that the norm $\|T\| = 1$. I know that for bounded operators the norm is defined as $\|T\|=\sup{\left\{\|T(x)\|: \|x\| \le 1\right\}}$. I am also wondering if there exists a x in $ l^1$ such that $\|x\|=1 $ and $\|T(x)\|= \|T\|$ Thank you! :)",,"['functional-analysis', 'operator-theory', 'normed-spaces']"
29,Banach-Space-Valued Analytic Functions,Banach-Space-Valued Analytic Functions,,"This is Chapter VII, $\S$3, exercise 4, from Conway's book: A Course in Functional Analysis: Let $X$ be a Banach space and $G\subset \mathbb{C}$ an open subset. We say that $f: G \to X$ is analytic if the limit $$\lim_{h \to 0} \frac{ f(z+h)-f(z)}{h}$$ exist in $X$ for all $z \in G$. Prove that if $f: G \to X$ is a function such that for each $x^* \in X^*$, the function $x^*\circ f : G \to \mathbb{C}$ is analytic (in the usual way), then $f$ is analytic . Since weak convergence does not imply the strong one, I feel that I am missing something to prove this. Any thoughts? Thanks in advance.","This is Chapter VII, $\S$3, exercise 4, from Conway's book: A Course in Functional Analysis: Let $X$ be a Banach space and $G\subset \mathbb{C}$ an open subset. We say that $f: G \to X$ is analytic if the limit $$\lim_{h \to 0} \frac{ f(z+h)-f(z)}{h}$$ exist in $X$ for all $z \in G$. Prove that if $f: G \to X$ is a function such that for each $x^* \in X^*$, the function $x^*\circ f : G \to \mathbb{C}$ is analytic (in the usual way), then $f$ is analytic . Since weak convergence does not imply the strong one, I feel that I am missing something to prove this. Any thoughts? Thanks in advance.",,"['complex-analysis', 'functional-analysis', 'banach-spaces', 'analytic-functions']"
30,When is a norm induced by an inner product? [duplicate],When is a norm induced by an inner product? [duplicate],,"This question already has answers here : Norms Induced by Inner Products and the Parallelogram Law (5 answers) Closed 4 years ago . Do inner products come from a norm,  or norms come from an inner product? How do I prove that this is true? Just want to know what comes from what, the chicken or the egg came first kind of thing.","This question already has answers here : Norms Induced by Inner Products and the Parallelogram Law (5 answers) Closed 4 years ago . Do inner products come from a norm,  or norms come from an inner product? How do I prove that this is true? Just want to know what comes from what, the chicken or the egg came first kind of thing.",,"['linear-algebra', 'functional-analysis']"
31,What can be said about $f$?,What can be said about ?,f,"I faced this question in an interview yesterday. QUESTION: We have a function $f$ depending on three variables $x_1,x_2,x_3$. Now the gradient of $f$ is perpendicular at any point   $(x_1,x_2,x_3)$, or in mathematical language , $$\vec r \cdot \nabla f  =0$$ Now what can be said about $f$ from this information? I could not make out anything from this. And I failed to proceed since I did not know the relation between $x_1,x_2,x_3$. I was given the hint that I should consider the function $f(t\vec r)$ where $t$ is a scalar and differentiate it with respect to $t$. I calculated it as: $$\frac{d}{dt}\left[f(t\vec r)\right]=f'(t\vec r) \vec r$$ I was still unable to make any interpretation. I was asked what the $f'$ thing meant. I said that it was a derivative but he asked me what it signified. But I had no clue. Can anybody help me? P.S. You can take $\vec r=(x_1,x_2,x_3)$. The interviewer said nothing about this. So I think it will be that way only.","I faced this question in an interview yesterday. QUESTION: We have a function $f$ depending on three variables $x_1,x_2,x_3$. Now the gradient of $f$ is perpendicular at any point   $(x_1,x_2,x_3)$, or in mathematical language , $$\vec r \cdot \nabla f  =0$$ Now what can be said about $f$ from this information? I could not make out anything from this. And I failed to proceed since I did not know the relation between $x_1,x_2,x_3$. I was given the hint that I should consider the function $f(t\vec r)$ where $t$ is a scalar and differentiate it with respect to $t$. I calculated it as: $$\frac{d}{dt}\left[f(t\vec r)\right]=f'(t\vec r) \vec r$$ I was still unable to make any interpretation. I was asked what the $f'$ thing meant. I said that it was a derivative but he asked me what it signified. But I had no clue. Can anybody help me? P.S. You can take $\vec r=(x_1,x_2,x_3)$. The interviewer said nothing about this. So I think it will be that way only.",,"['calculus', 'functional-analysis', 'multivariable-calculus', 'vectors', 'vector-analysis']"
32,Examples of infinite dimensional normed vector spaces,Examples of infinite dimensional normed vector spaces,,"In my notes on functional analysis it mentions that $C([0,1]),\ell^p$ and, $\ell^\infty$ are normed vector spaces, and gives some examples of norms that we can define on them. However, it then simply states that these three spaces are infinite-dimensional normed vector spaces. The only thing mentioned in my notes so far is in relation to finite-dimensional vector spaces, namely, that a vector space is finite-dimensional if it has a finite basis. My question(s): how is it exactly that one understands these spaces to be infinite-dimensional; what does it mean to say that they are infinite-dimensional and how do they differ from an example of a finite-dimensional vector space, say, $\mathbb R^n$. Going on what I know about finite-dimensional spaces, is it simply then that an infinite-dimensional space has an infinite basis? How would one visualize this? Can anybody show me why the examples I gave above are indeed infinite-dimensional?","In my notes on functional analysis it mentions that $C([0,1]),\ell^p$ and, $\ell^\infty$ are normed vector spaces, and gives some examples of norms that we can define on them. However, it then simply states that these three spaces are infinite-dimensional normed vector spaces. The only thing mentioned in my notes so far is in relation to finite-dimensional vector spaces, namely, that a vector space is finite-dimensional if it has a finite basis. My question(s): how is it exactly that one understands these spaces to be infinite-dimensional; what does it mean to say that they are infinite-dimensional and how do they differ from an example of a finite-dimensional vector space, say, $\mathbb R^n$. Going on what I know about finite-dimensional spaces, is it simply then that an infinite-dimensional space has an infinite basis? How would one visualize this? Can anybody show me why the examples I gave above are indeed infinite-dimensional?",,"['linear-algebra', 'functional-analysis', 'vector-spaces', 'normed-spaces']"
33,Norm of the integral operator in $L^2(\mathbb{R})$.,Norm of the integral operator in .,L^2(\mathbb{R}),"Suppose we have an integral operator $A$ such that $$Af(x) = \frac{1}{\sqrt{2\pi}}\int\limits_{\mathbb{R}}e^{-\frac{(x-y)^2}{2}}f(y)dy$$ To find $\|A\|$ we can use the unitary Fourier transform $F$, as it saves the norm of a function and hence $\|A\|=\|FA\|$. Due to the convolution theorem we have: $$FAf(x) = e^{-\frac{x^2}{2}}Ff(x)$$ So $FAf(x)$ is a composition of the unitary Fourier transform $F$ and the multiplication operator $M$ by the function $e^{-\frac{x^2}{2}}$. Norm of the latter in $L^2(\mathbb{R})$ equals to $\mathrm{ess\,sup}\left(e^{-\frac{x^2}{2}}\right) = 1$. And the norm of $F$ is surely also $1$. That means that $\|A\| \leq 1$ The quastion is how one proves that $\|A\|=1$ (or is it so)? My guess of $\|A\|=1$ bases on the fact that if $f\equiv 1$, than $Af \equiv 1$. But we can't use it straightforward, since $f \equiv 1$ does not lie in $L^2(\mathbb{R})$. Even if we consider sequance $f_n=\chi[-n,n]$ - indicators of $[-n,n]$, that doesn't do much. While finding such sequince $\{f_n\}$ that $\|Af_n\|/\|f_n\| \to 1$ is one way to prove the equility, I wonder if it somehow follows from the fact that $F$ is unitary operator and not just have unity norm. And so it somehow is evident that oparator $FAf(x) = e^{-x^2}Ff(x)$ has a unity norm and not just $\leq 1$. Any suggestion is appreciated.","Suppose we have an integral operator $A$ such that $$Af(x) = \frac{1}{\sqrt{2\pi}}\int\limits_{\mathbb{R}}e^{-\frac{(x-y)^2}{2}}f(y)dy$$ To find $\|A\|$ we can use the unitary Fourier transform $F$, as it saves the norm of a function and hence $\|A\|=\|FA\|$. Due to the convolution theorem we have: $$FAf(x) = e^{-\frac{x^2}{2}}Ff(x)$$ So $FAf(x)$ is a composition of the unitary Fourier transform $F$ and the multiplication operator $M$ by the function $e^{-\frac{x^2}{2}}$. Norm of the latter in $L^2(\mathbb{R})$ equals to $\mathrm{ess\,sup}\left(e^{-\frac{x^2}{2}}\right) = 1$. And the norm of $F$ is surely also $1$. That means that $\|A\| \leq 1$ The quastion is how one proves that $\|A\|=1$ (or is it so)? My guess of $\|A\|=1$ bases on the fact that if $f\equiv 1$, than $Af \equiv 1$. But we can't use it straightforward, since $f \equiv 1$ does not lie in $L^2(\mathbb{R})$. Even if we consider sequance $f_n=\chi[-n,n]$ - indicators of $[-n,n]$, that doesn't do much. While finding such sequince $\{f_n\}$ that $\|Af_n\|/\|f_n\| \to 1$ is one way to prove the equility, I wonder if it somehow follows from the fact that $F$ is unitary operator and not just have unity norm. And so it somehow is evident that oparator $FAf(x) = e^{-x^2}Ff(x)$ has a unity norm and not just $\leq 1$. Any suggestion is appreciated.",,"['functional-analysis', 'operator-theory', 'normed-spaces', 'integral-operators']"
34,Prove that an infinite matrix defines a compact operator on $l^2$.,Prove that an infinite matrix defines a compact operator on .,l^2,"Let $(a(i))_{i=1}^\infty$ be an absolutely summable sequence, i.e., $\sum_{i=1}^\infty |a(i)|<\infty$, and consider the infinite matrix $$A=\begin{bmatrix} a(1)&a(2)&a(3)&\cdots\\ a(2)&a(3)&a(4)&\cdots\\ a(3)&a(4)&a(5)&\cdots\\ \vdots&\vdots&\vdots&\ddots\end{bmatrix}.$$ My problem is to show that $A$ defines a bounded compact operator on $l^2=l^2(\mathbb{N})$. Namely, the operator $A$ defines is given by, for every $x=(x_j)_{j=1}^\infty\in l^2$, $A(x)=(\sum_i a(i+j-1)x_i)_{j=1}^\infty$. At first, I thought it would be similar to this other problem: "" a compact operator on $l^2$ defined by an infinite matrix "", but the only part that I managed to do is to prove that the sequence $(\sum_i a(i+j-1)x_i)_{j=1}^\infty$ is well-defined: Indeed, since $(a(i))$ is absolutely summable then it is also square-summable, and it follows from Holder's inequality that the series $\sum_i a(i+j-1)x_i$ converges whenever $(x_i)\in l^2$. I can't even prove that the operator $A$ has image in $l^2$. One of the initial problems is that the entries of the infinite matrix are not necessarily square summable (for example, take your favorite summable sequence $(a(i))$ and put lots of zeros between consecutive entries). Any help is welcome.","Let $(a(i))_{i=1}^\infty$ be an absolutely summable sequence, i.e., $\sum_{i=1}^\infty |a(i)|<\infty$, and consider the infinite matrix $$A=\begin{bmatrix} a(1)&a(2)&a(3)&\cdots\\ a(2)&a(3)&a(4)&\cdots\\ a(3)&a(4)&a(5)&\cdots\\ \vdots&\vdots&\vdots&\ddots\end{bmatrix}.$$ My problem is to show that $A$ defines a bounded compact operator on $l^2=l^2(\mathbb{N})$. Namely, the operator $A$ defines is given by, for every $x=(x_j)_{j=1}^\infty\in l^2$, $A(x)=(\sum_i a(i+j-1)x_i)_{j=1}^\infty$. At first, I thought it would be similar to this other problem: "" a compact operator on $l^2$ defined by an infinite matrix "", but the only part that I managed to do is to prove that the sequence $(\sum_i a(i+j-1)x_i)_{j=1}^\infty$ is well-defined: Indeed, since $(a(i))$ is absolutely summable then it is also square-summable, and it follows from Holder's inequality that the series $\sum_i a(i+j-1)x_i$ converges whenever $(x_i)\in l^2$. I can't even prove that the operator $A$ has image in $l^2$. One of the initial problems is that the entries of the infinite matrix are not necessarily square summable (for example, take your favorite summable sequence $(a(i))$ and put lots of zeros between consecutive entries). Any help is welcome.",,['functional-analysis']
35,Why $L^1$ is not reflexive [duplicate],Why  is not reflexive [duplicate],L^1,"This question already has answers here : $L^1(μ)$ is finite dimensional if it is reflexive (2 answers) Closed 9 years ago . We already known that $$ (L^p(\Omega))^* = L^q(\Omega), $$ for all $1\le p < \infty $ and $q$ is the exponent conjugate to $p$. So that, $L^p(\Omega)$ is reflexive with $1<p<\infty$. However, $L^1(\Omega)$ is not, due to $$ (L^\infty(\Omega))^* \supset L^1(\Omega), $$ but I don't know why. Can we find a element $f\in (L^\infty(\Omega))^*$ and $f \notin L^1(\Omega)$?","This question already has answers here : $L^1(μ)$ is finite dimensional if it is reflexive (2 answers) Closed 9 years ago . We already known that $$ (L^p(\Omega))^* = L^q(\Omega), $$ for all $1\le p < \infty $ and $q$ is the exponent conjugate to $p$. So that, $L^p(\Omega)$ is reflexive with $1<p<\infty$. However, $L^1(\Omega)$ is not, due to $$ (L^\infty(\Omega))^* \supset L^1(\Omega), $$ but I don't know why. Can we find a element $f\in (L^\infty(\Omega))^*$ and $f \notin L^1(\Omega)$?",,"['functional-analysis', 'banach-spaces']"
36,Hermitian and self-adjoint operators on infinite-dimensional Hilbert spaces,Hermitian and self-adjoint operators on infinite-dimensional Hilbert spaces,,"I am a physicist and I am trying to get a grasp on the following terms from functional analysis: As I understand, an operator is Hermitian if it is symmetric and bounded (domains of A and A* don't need to be equal in this case.) An operator is selfadjoint if it is symmetric and the domains of A and A* are equal, D(A) = D(A*), so A = A*. My question is, is the boundedness here an artefact of the finiteness of the Hilbert space? I.e., in the finite Hilbert spaces we can 'safely' work with the Hermitian operators, but in the infinite Hilbert spaces we lose the notion of boundedness, so we need to start to work with self-adjoint operators? Or, if I am completely wrong here, what is the difference between the self-adjoint and Hermitian operator, in the context of finite vs. infinite Hilbert space?","I am a physicist and I am trying to get a grasp on the following terms from functional analysis: As I understand, an operator is Hermitian if it is symmetric and bounded (domains of A and A* don't need to be equal in this case.) An operator is selfadjoint if it is symmetric and the domains of A and A* are equal, D(A) = D(A*), so A = A*. My question is, is the boundedness here an artefact of the finiteness of the Hilbert space? I.e., in the finite Hilbert spaces we can 'safely' work with the Hermitian operators, but in the infinite Hilbert spaces we lose the notion of boundedness, so we need to start to work with self-adjoint operators? Or, if I am completely wrong here, what is the difference between the self-adjoint and Hermitian operator, in the context of finite vs. infinite Hilbert space?",,"['functional-analysis', 'hilbert-spaces']"
37,Gel'fand representation of a non-unital Banach space: what's wrong with this argument,Gel'fand representation of a non-unital Banach space: what's wrong with this argument,,"My argument below is hacked together from pages 5-6 of Davidson's ""$C^*$ algebras by example"". Theorem: The multiplicative linear functionals on a unital abelian Banach algebra are continuous of norm 1. Proof: Let $\varphi$ be a multiplicative linear functional on $\mathfrak A$, and $A \in \mathfrak A$. Suppose towards a contradiction that $\|A\| < \varphi(A)$; by considering instead $A'=A/\varphi(A)$ if necessary, we can assume $\varphi(A)=1$.  Let $B = \sum_{n \geq 1} A^n$; then $A+AB=B$, and as a result, $\varphi(B)=\varphi(A)+\varphi(A)\varphi(B)=1+\varphi(B)$, which is nonsense. So $\|\varphi\| \leq 1$. Since $\varphi(I)=1$, that's an equality. If $\mathfrak A$ is non-unital, it seems to me the early part of that argument still applies, so that $\|\varphi\| \leq 1$. In either case $\mathfrak{A}$ is a subspace of the unit ball in $\mathfrak{A}^*$. We topologize the set of multiplicative linear functionals $\mathcal{M_{\mathfrak A}}$ as a subspace of the dual space $\mathfrak A^*$. Now weak-* convergence of nets is just pointwise convergence. As a result it's clear that the weak-* limit of multiplicative linear functionals is a multiplicative linear functional. (As is standard in mathematics, the part where I say 'it's clear' is where I think there's likeliest to be a problem.) So $\mathcal{M_{\mathfrak A}}$ is a closed subset of the unit ball of $\mathfrak A^*$; Banach-Alaoglu says that it's compact. On the other hand, I know that $\mathcal{M_{\mathfrak A}}$ is not compact for $\mathfrak A$ non-unital, but rather only locally compact. So something in the above argument is wrong. What is it? As mentioned, I think it's the ""clear"" bit. Because we can extend the 0 functional in a unique way, and every other functional extends uniquely, it seems likely to me that there's a net of multiplicative functionals that weak-* converge to the 0 functional. I'd like to see such a net. (It actually is clear in the unital case: since the functionals have norm 1, they're bounded away from the 0 functional, so this can't happen. They're not bounded away from the 0 functional in the non-unital case, so this is almost certainly the failure of this argument.","My argument below is hacked together from pages 5-6 of Davidson's ""$C^*$ algebras by example"". Theorem: The multiplicative linear functionals on a unital abelian Banach algebra are continuous of norm 1. Proof: Let $\varphi$ be a multiplicative linear functional on $\mathfrak A$, and $A \in \mathfrak A$. Suppose towards a contradiction that $\|A\| < \varphi(A)$; by considering instead $A'=A/\varphi(A)$ if necessary, we can assume $\varphi(A)=1$.  Let $B = \sum_{n \geq 1} A^n$; then $A+AB=B$, and as a result, $\varphi(B)=\varphi(A)+\varphi(A)\varphi(B)=1+\varphi(B)$, which is nonsense. So $\|\varphi\| \leq 1$. Since $\varphi(I)=1$, that's an equality. If $\mathfrak A$ is non-unital, it seems to me the early part of that argument still applies, so that $\|\varphi\| \leq 1$. In either case $\mathfrak{A}$ is a subspace of the unit ball in $\mathfrak{A}^*$. We topologize the set of multiplicative linear functionals $\mathcal{M_{\mathfrak A}}$ as a subspace of the dual space $\mathfrak A^*$. Now weak-* convergence of nets is just pointwise convergence. As a result it's clear that the weak-* limit of multiplicative linear functionals is a multiplicative linear functional. (As is standard in mathematics, the part where I say 'it's clear' is where I think there's likeliest to be a problem.) So $\mathcal{M_{\mathfrak A}}$ is a closed subset of the unit ball of $\mathfrak A^*$; Banach-Alaoglu says that it's compact. On the other hand, I know that $\mathcal{M_{\mathfrak A}}$ is not compact for $\mathfrak A$ non-unital, but rather only locally compact. So something in the above argument is wrong. What is it? As mentioned, I think it's the ""clear"" bit. Because we can extend the 0 functional in a unique way, and every other functional extends uniquely, it seems likely to me that there's a net of multiplicative functionals that weak-* converge to the 0 functional. I'd like to see such a net. (It actually is clear in the unital case: since the functionals have norm 1, they're bounded away from the 0 functional, so this can't happen. They're not bounded away from the 0 functional in the non-unital case, so this is almost certainly the failure of this argument.",,['analysis']
38,Inequality for compact operator between Banach spaces,Inequality for compact operator between Banach spaces,,"I've been pondering about the following Lemma for a while now, but can't think of a proof. In fact, I can't even think of a way to prove it. Let $E$, $F$ and $G$ be Banach spaces, $T \in \mathcal{K}(E,F)$ (e.g. a compact operator) and $S \in \mathcal{L}(F,G)$ injective. Then for each $\epsilon \gt 0$ there is a $c_\epsilon \gt 0$ such that for all $x \in E$ holds $$\|Tx\| \le \epsilon \|x\| + c_\epsilon \|STx\|.$$ I have no idea what properties to use here. How can I see that this holds?","I've been pondering about the following Lemma for a while now, but can't think of a proof. In fact, I can't even think of a way to prove it. Let $E$, $F$ and $G$ be Banach spaces, $T \in \mathcal{K}(E,F)$ (e.g. a compact operator) and $S \in \mathcal{L}(F,G)$ injective. Then for each $\epsilon \gt 0$ there is a $c_\epsilon \gt 0$ such that for all $x \in E$ holds $$\|Tx\| \le \epsilon \|x\| + c_\epsilon \|STx\|.$$ I have no idea what properties to use here. How can I see that this holds?",,"['functional-analysis', 'compact-operators']"
39,How can I show that it's a Banach space?,How can I show that it's a Banach space?,,"Let $I=[a,b]$ (where $a<b$) be a compact interval on $\mathbb{R}$, $0<\alpha\leq1$. and $$\mathrm{Lip}(\alpha)=\left\{f:I \to \mathbb{C} \;\bigg|\; M_f=\sup_{s\neq t} \frac{|f(s)-f(t)|}{|s-t|^{\alpha}}  < \infty \right\}$$ 1) Show that $\mathrm{Lip}(\alpha)$ space is a Banach space with the norm $\|f\|_1=\sup_{t \in I}|f(t)|+M_f$. 2) Show that $\mathrm{Lip}(\alpha)$ space is also a Banach space with the norm $\|f\|_2=|f(a)|+M_f$. Hint: Show that $\|\cdot\|_1$ and $\|\cdot\|_2$ are equivalent norms on $\mathrm{Lip}(\alpha)$ space. Thanks. PD: I must show the first one. So, if someone can explain me this, I'll be great.","Let $I=[a,b]$ (where $a<b$) be a compact interval on $\mathbb{R}$, $0<\alpha\leq1$. and $$\mathrm{Lip}(\alpha)=\left\{f:I \to \mathbb{C} \;\bigg|\; M_f=\sup_{s\neq t} \frac{|f(s)-f(t)|}{|s-t|^{\alpha}}  < \infty \right\}$$ 1) Show that $\mathrm{Lip}(\alpha)$ space is a Banach space with the norm $\|f\|_1=\sup_{t \in I}|f(t)|+M_f$. 2) Show that $\mathrm{Lip}(\alpha)$ space is also a Banach space with the norm $\|f\|_2=|f(a)|+M_f$. Hint: Show that $\|\cdot\|_1$ and $\|\cdot\|_2$ are equivalent norms on $\mathrm{Lip}(\alpha)$ space. Thanks. PD: I must show the first one. So, if someone can explain me this, I'll be great.",,['functional-analysis']
40,"How to show that $C[a,b]$ is infinite dimensional?",How to show that  is infinite dimensional?,"C[a,b]","How can we give a rigorous proof of the fact that the space $C[a,b]$ of all continuous real (or complex)-valued functions defined on a closed interval $[a,b]$, where $a$, $b$ are any two given real numbers such that $a<b$, is infinite-dimensional? We of course take the following norm: $$ ||x|| := \max_{a\leq t \leq b} |x(t)|$$ for any $x \in C[a,b]$, the vector addition and saclar multiplication being defined pointwise as usual.","How can we give a rigorous proof of the fact that the space $C[a,b]$ of all continuous real (or complex)-valued functions defined on a closed interval $[a,b]$, where $a$, $b$ are any two given real numbers such that $a<b$, is infinite-dimensional? We of course take the following norm: $$ ||x|| := \max_{a\leq t \leq b} |x(t)|$$ for any $x \in C[a,b]$, the vector addition and saclar multiplication being defined pointwise as usual.",,"['functional-analysis', 'normed-spaces']"
41,Is $\ell^p \mathbb N \subset \ell^q \mathbb N$ inclusion compact ?,Is  inclusion compact ?,\ell^p \mathbb N \subset \ell^q \mathbb N,"This question just struck me, is it true that if $1 <p <q <\infty$ , is the inclusion map $$\ell^p \mathbb N \subset \ell^q \mathbb N$$compact ? Hölders inequality gives us that the inclusion is continuous . But for compactness it doesn't seem very direct . Thank you for ur help  .","This question just struck me, is it true that if $1 <p <q <\infty$ , is the inclusion map $$\ell^p \mathbb N \subset \ell^q \mathbb N$$compact ? Hölders inequality gives us that the inclusion is continuous . But for compactness it doesn't seem very direct . Thank you for ur help  .",,"['functional-analysis', 'lp-spaces', 'compact-operators']"
42,How is it that the derivative operator is a closed linear operator?,How is it that the derivative operator is a closed linear operator?,,"By definition , if the derivative operator $D:C^1[-1,1]\to C^1[-1,1]$ is closed, then it should be the case that, given any sequence $\{x_n\}$ in $C^1[-1,1]$, and given that $x_n\to x$ as $n\to\infty$ for some $x\in C[-1,1]$, we should conclude that $x$ is in $C^1[-1,1]$. But it seems that this is not the case. Consider $x_n(t)=\sqrt{n^{-2}+x^2}$, clearly $x_n$ are in $C^1[-1,1]$, and we know that $x_n\to x(t)=|x|$, which is not in $C^1[-1,1]$, and doesn't it show that $D$ is not a closed linear operator?","By definition , if the derivative operator $D:C^1[-1,1]\to C^1[-1,1]$ is closed, then it should be the case that, given any sequence $\{x_n\}$ in $C^1[-1,1]$, and given that $x_n\to x$ as $n\to\infty$ for some $x\in C[-1,1]$, we should conclude that $x$ is in $C^1[-1,1]$. But it seems that this is not the case. Consider $x_n(t)=\sqrt{n^{-2}+x^2}$, clearly $x_n$ are in $C^1[-1,1]$, and we know that $x_n\to x(t)=|x|$, which is not in $C^1[-1,1]$, and doesn't it show that $D$ is not a closed linear operator?",,['functional-analysis']
43,Characterization of small Banach subalgebras,Characterization of small Banach subalgebras,,"Let $A$ be a unital Banach algebra and $x \in A$ nonzero. We can consider the subalgebra $B$ of $A$ generated by $\{1,x\}$. This is the norm closure of the subspace of polynomials in $x$. So for any $y \in B$ there exists a sequence of polynomials $p_n(z) \in \mathbb C[z]$ such that $$\lim_{n\rightarrow \infty} ||p_n(x) - y||=0. $$ In particular we notice that any power series with radius of convergence less than $||x||$ evaluated at $x$ is in $B$. My question is whether or not every element of $B$ can be written as a power series in $x$. It seems like this might follow easily from the classical proof that a normed vector space is complete if and only if every absolutely convergent series converges, but I haven't been able to work through the details.","Let $A$ be a unital Banach algebra and $x \in A$ nonzero. We can consider the subalgebra $B$ of $A$ generated by $\{1,x\}$. This is the norm closure of the subspace of polynomials in $x$. So for any $y \in B$ there exists a sequence of polynomials $p_n(z) \in \mathbb C[z]$ such that $$\lim_{n\rightarrow \infty} ||p_n(x) - y||=0. $$ In particular we notice that any power series with radius of convergence less than $||x||$ evaluated at $x$ is in $B$. My question is whether or not every element of $B$ can be written as a power series in $x$. It seems like this might follow easily from the classical proof that a normed vector space is complete if and only if every absolutely convergent series converges, but I haven't been able to work through the details.",,"['functional-analysis', 'banach-algebras']"
44,The image of orthonormal basis under compact operator,The image of orthonormal basis under compact operator,,"I need a help to prove that statement: if $\{e_n\}$ an orthonormal basis in Hilbert space $H$ and $A$ is a compact operator from $H$ to $H$, then $Ae_n\rightarrow 0$. Thx for any help.","I need a help to prove that statement: if $\{e_n\}$ an orthonormal basis in Hilbert space $H$ and $A$ is a compact operator from $H$ to $H$, then $Ae_n\rightarrow 0$. Thx for any help.",,"['functional-analysis', 'hilbert-spaces', 'compact-operators']"
45,Tensor products and vector valued functions,Tensor products and vector valued functions,,"Given a non-empty set $S$ and a Banach space $X$. Let $B(S,X)$ be the space of all bounded maps from $S$ to $X$. Can we identify $B(S,X)$ with $\ell^\infty(S) \otimes X$, where $\otimes$ is some kind of tensor product of Banach spaces?","Given a non-empty set $S$ and a Banach space $X$. Let $B(S,X)$ be the space of all bounded maps from $S$ to $X$. Can we identify $B(S,X)$ with $\ell^\infty(S) \otimes X$, where $\otimes$ is some kind of tensor product of Banach spaces?",,"['functional-analysis', 'banach-spaces', 'tensor-products']"
46,Paradox or Error: On the inclusion of dense subspaces into Hilbert spaces,Paradox or Error: On the inclusion of dense subspaces into Hilbert spaces,,"the following observations are very simple, but I suppose they contain an error, which I haven't been able to find it so far. Maybe somebody can help how to fix it: Let $H$ be a Hilbert space, $U$ be a dense subspace. Assume we can equip $U$ with another Hilbert space norm by itself. We denote this space by $\mathcal U$, to avoid misunderstandings. We then have the linear inclusion $ i : \mathcal U \rightarrow H$ with image dense in $H$. Assume furthermore, $i$ is bounded. Let us now inspect the dual arrow, which acts on the topological dual spaces:     $i^\ast : H^\ast \rightarrow \mathcal U^\ast, \;\; w( \cdot) \mapsto w( i \cdot )$ As $i$ is a bounded injection, $i^\ast$ is now a bounded surjection. What is the kernel of $i^\ast$? We have $\ker i^\ast = \{ w \in H^\ast : w(x) = 0, x \in \operatorname{Im} i \}$ But then $\ker i^\ast = (\operatorname{Im} i)^\perp = U^\perp = H^\perp = \{0\}$, so $i^\ast$ is injective. Hence it is an isomorphism. Strange: But if we dualize $i^\ast$ again, we then see $i$ is an isomorphism, too. Furthermore, as $H$ and $\mathcal U$ are Hilbert spaces, we are given (isometric) isomorphisms $H \simeq H^\ast$, $\mathcal U \simeq \mathcal U^\ast$. We can compose these morphisms. Strange: We obtain $\mathcal U \simeq H$, where the injection is in fact an isomorphism. So this eventually means, if we equip any dense subspace of a Hilbert space with a stronger topology, then the injection $i$ as above is an isomorphism. This seems paradoxical, and I suppose there is an error in the above. For example, this implies the injection $H^1(\mathbb R) \rightarrow L^2(\mathbb R)$ is an isomorphism. So, can anybody please either: (a) Point out where I have been wrong (b) Point out how to interpret this paradox?","the following observations are very simple, but I suppose they contain an error, which I haven't been able to find it so far. Maybe somebody can help how to fix it: Let $H$ be a Hilbert space, $U$ be a dense subspace. Assume we can equip $U$ with another Hilbert space norm by itself. We denote this space by $\mathcal U$, to avoid misunderstandings. We then have the linear inclusion $ i : \mathcal U \rightarrow H$ with image dense in $H$. Assume furthermore, $i$ is bounded. Let us now inspect the dual arrow, which acts on the topological dual spaces:     $i^\ast : H^\ast \rightarrow \mathcal U^\ast, \;\; w( \cdot) \mapsto w( i \cdot )$ As $i$ is a bounded injection, $i^\ast$ is now a bounded surjection. What is the kernel of $i^\ast$? We have $\ker i^\ast = \{ w \in H^\ast : w(x) = 0, x \in \operatorname{Im} i \}$ But then $\ker i^\ast = (\operatorname{Im} i)^\perp = U^\perp = H^\perp = \{0\}$, so $i^\ast$ is injective. Hence it is an isomorphism. Strange: But if we dualize $i^\ast$ again, we then see $i$ is an isomorphism, too. Furthermore, as $H$ and $\mathcal U$ are Hilbert spaces, we are given (isometric) isomorphisms $H \simeq H^\ast$, $\mathcal U \simeq \mathcal U^\ast$. We can compose these morphisms. Strange: We obtain $\mathcal U \simeq H$, where the injection is in fact an isomorphism. So this eventually means, if we equip any dense subspace of a Hilbert space with a stronger topology, then the injection $i$ as above is an isomorphism. This seems paradoxical, and I suppose there is an error in the above. For example, this implies the injection $H^1(\mathbb R) \rightarrow L^2(\mathbb R)$ is an isomorphism. So, can anybody please either: (a) Point out where I have been wrong (b) Point out how to interpret this paradox?",,"['functional-analysis', 'hilbert-spaces', 'sobolev-spaces']"
47,"Analysing a Lebesgue integral inequality for $|t^{-n} \phi(x/t)|$, where $\phi \in C_c^\infty \cap L^1$ with $\| \phi \|_1 = 1$.","Analysing a Lebesgue integral inequality for , where  with .",|t^{-n} \phi(x/t)| \phi \in C_c^\infty \cap L^1 \| \phi \|_1 = 1,"Context. Let $C^k(\mathbb R^n)$ denote the space of functions defined on $\mathbb R^n$ that are $k$ times continuously differentiable, where $k \geqslant 1$ is an integer. As usual, define $C^\infty(\mathbb R^n)$ to be the intersection of all $C^k(\mathbb R^n)$ and let $C_c(\mathbb R^n)$ denote the space of continuous functions on $\mathbb R^n$ with compact support. Furthermore, let $C_c^\infty(\mathbb R^n) = C_c(\mathbb R^n) \cap C^\infty(\mathbb R^n).$ Consider the usual Euclidean space $\mathbb R^n$ equipped with the Lebesgue measure. Furthermore, let $\phi \in C_c^\infty(\mathbb R^n)$ be a kernel with unitary norm, that is, $\| \phi \|_1 = 1$ (here, $\| \phi \|_1$ stands for the $L^1$ -norm of $\phi$ ) and define the dillations $$ \phi_t(x) = t^{-n} \phi\left( \frac{x}{t} \right), $$ for every $x \in \mathbb R^n$ and $t > 0$ . Finally, let $\delta > 0$ be an arbitrary fixed constant. In an article I am reading, the authors claim the following. Now, we use the very well-known inequality $$ \int_{|z| \geqslant \delta}|\phi_t(z)| \, dz \leqslant c \, \int_{|z| \geqslant \delta} \frac{t}{|z|^{n+1}} \, dz \leqslant c \, t, $$ where the constant $c$ is independet of $t$ . Basically, I am wondering where this inequality comes from and if anyone has a reference that approaches this result. For what it's worth, under these conditions I am already aware that $\phi_t \in C_c^\infty(\mathbb R^n)$ with $\| \phi_t \|_1 = 1$ (for details about this, see this post ). Thanks for any help in advance.","Context. Let denote the space of functions defined on that are times continuously differentiable, where is an integer. As usual, define to be the intersection of all and let denote the space of continuous functions on with compact support. Furthermore, let Consider the usual Euclidean space equipped with the Lebesgue measure. Furthermore, let be a kernel with unitary norm, that is, (here, stands for the -norm of ) and define the dillations for every and . Finally, let be an arbitrary fixed constant. In an article I am reading, the authors claim the following. Now, we use the very well-known inequality where the constant is independet of . Basically, I am wondering where this inequality comes from and if anyone has a reference that approaches this result. For what it's worth, under these conditions I am already aware that with (for details about this, see this post ). Thanks for any help in advance.","C^k(\mathbb R^n) \mathbb R^n k k \geqslant 1 C^\infty(\mathbb R^n) C^k(\mathbb R^n) C_c(\mathbb R^n) \mathbb R^n C_c^\infty(\mathbb R^n) = C_c(\mathbb R^n) \cap C^\infty(\mathbb R^n). \mathbb R^n \phi \in C_c^\infty(\mathbb R^n) \| \phi \|_1 = 1 \| \phi \|_1 L^1 \phi  \phi_t(x) = t^{-n} \phi\left( \frac{x}{t} \right),  x \in \mathbb R^n t > 0 \delta > 0  \int_{|z| \geqslant \delta}|\phi_t(z)| \, dz \leqslant c \, \int_{|z| \geqslant \delta} \frac{t}{|z|^{n+1}} \, dz \leqslant c \, t,  c t \phi_t \in C_c^\infty(\mathbb R^n) \| \phi_t \|_1 = 1","['real-analysis', 'functional-analysis', 'functions', 'reference-request', 'lebesgue-integral']"
48,Projection with same rank,Projection with same rank,,"Let $H$ be a Hilbert space (over $\mathbb{R}$ or $\mathbb{C}$ ), and $P$ , $Q$ are two projections over $H$ such that $\|P-Q\|<1$ . I am searching for a simple proof for $$ \dim\operatorname{Ran}P=\dim\operatorname{Ran}Q,\quad \dim\operatorname{Ran}(I-P)=\dim\operatorname{Ran}(I-Q). $$ To handle with this, we can define $R=(P-Q)^2$ and $U_1=QP+(I-Q)(I-P)$ , $V_1=PQ+(I-P)(I-Q)$ . Then it is easy to verify that $$ U_1V_1=V_1U_1=I-R,\quad U_1^*=V_1,\quad V_1^*=U_1. $$ Since $\|R\|<1$ , $T=(I-R)^{-\frac12}$ makes sense (e.g. define it with series) and it commutes with $P$ , $Q$ . Set $$ U=U_1T,\quad V=V_1T, $$ then $UV=VU=I$ and $$ Q=UPU^{-1},\quad P=VQV^{-1}. $$ but this proof is too long and complicated, compared with the given condition. Therefore, I want to find an intuitive way to show that.","Let be a Hilbert space (over or ), and , are two projections over such that . I am searching for a simple proof for To handle with this, we can define and , . Then it is easy to verify that Since , makes sense (e.g. define it with series) and it commutes with , . Set then and but this proof is too long and complicated, compared with the given condition. Therefore, I want to find an intuitive way to show that.","H \mathbb{R} \mathbb{C} P Q H \|P-Q\|<1 
\dim\operatorname{Ran}P=\dim\operatorname{Ran}Q,\quad \dim\operatorname{Ran}(I-P)=\dim\operatorname{Ran}(I-Q).
 R=(P-Q)^2 U_1=QP+(I-Q)(I-P) V_1=PQ+(I-P)(I-Q) 
U_1V_1=V_1U_1=I-R,\quad U_1^*=V_1,\quad V_1^*=U_1.
 \|R\|<1 T=(I-R)^{-\frac12} P Q 
U=U_1T,\quad V=V_1T,
 UV=VU=I 
Q=UPU^{-1},\quad P=VQV^{-1}.
","['functional-analysis', 'projection']"
49,Find the eingenvalues for a specific integral operator,Find the eingenvalues for a specific integral operator,,"So i've been reading a book on func analysis and in the examples section there is a problem in which it is stated Find the eigenvalues for $y = Kx$ , where $$y(t)=\int_{-1}^{1}(1-t\tau)x(\tau)d\tau.$$ In my undergrad linear algebra we did find eigenvalues, but only for matrix equations of the form $Tx=\alpha x$ where one looks for the eingenvalue of $det(T-I\lambda)=0$ , where $T$ is some linear mapping. Then one obtains a characteristic polynomial from which one obtains eigenvalue and then eigenvectors. I don't know how to begin here.","So i've been reading a book on func analysis and in the examples section there is a problem in which it is stated Find the eigenvalues for , where In my undergrad linear algebra we did find eigenvalues, but only for matrix equations of the form where one looks for the eingenvalue of , where is some linear mapping. Then one obtains a characteristic polynomial from which one obtains eigenvalue and then eigenvectors. I don't know how to begin here.",y = Kx y(t)=\int_{-1}^{1}(1-t\tau)x(\tau)d\tau. Tx=\alpha x det(T-I\lambda)=0 T,"['linear-algebra', 'functional-analysis', 'analysis']"
50,Failure of Banach Alaoglu in $L^1$,Failure of Banach Alaoglu in,L^1,"We know that dual of $L^{\infty}(\mathbb{R})$ is not $L^{1}(\mathbb{R})$ and hence Banach Alaoglu theorem is not applicable for the $(L^1,L^{\infty})$ pairing. In other words if $\{f_n\}$ is a uniformly bounded sequence in $L^1(\mathbb{R})$ (i.e. $||f_n||_{L^1(\mathbb{R})} \leq C ),$ then there may not exist subsequence $f_{n_k}$ and an $f\in L^1(\mathbb{R})$ such that $\int\limits_{\mathbb{R}} f_{n_k}(x)g(x) dx \rightarrow \int\limits_{\mathbb{R}}f(x)g(x)dx$ for all $g\in L^{\infty}(\mathbb{R}).$ Is there any simple counter example which demonstrates this?",We know that dual of is not and hence Banach Alaoglu theorem is not applicable for the pairing. In other words if is a uniformly bounded sequence in (i.e. then there may not exist subsequence and an such that for all Is there any simple counter example which demonstrates this?,"L^{\infty}(\mathbb{R}) L^{1}(\mathbb{R}) (L^1,L^{\infty}) \{f_n\} L^1(\mathbb{R}) ||f_n||_{L^1(\mathbb{R})} \leq C ), f_{n_k} f\in L^1(\mathbb{R}) \int\limits_{\mathbb{R}} f_{n_k}(x)g(x) dx \rightarrow \int\limits_{\mathbb{R}}f(x)g(x)dx g\in L^{\infty}(\mathbb{R}).","['functional-analysis', 'measure-theory', 'weak-convergence']"
51,"$\langle Tx,x\rangle$ is continuous if and only if that $T$ is continuous.",is continuous if and only if that  is continuous.,"\langle Tx,x\rangle T","$H$ is a Hilbert space , $T:H \longrightarrow H$ is a linear map , use $T$ to define a functional $$\phi_T:H \longrightarrow \mathbb C \quad, \quad\quad\phi_T(x)=\langle Tx,x\rangle$$ Then $\phi_T $ is continuous if and only if $T$ is continuous. "" $\Longleftarrow$ ""Use the continuity of inner product. "" $\Longrightarrow$ ""Feng gives a very beautiful proof below,using The Closed Graph Theorem.","is a Hilbert space , is a linear map , use to define a functional Then is continuous if and only if is continuous. "" ""Use the continuity of inner product. "" ""Feng gives a very beautiful proof below,using The Closed Graph Theorem.","H T:H \longrightarrow H T \phi_T:H \longrightarrow \mathbb C \quad, \quad\quad\phi_T(x)=\langle Tx,x\rangle \phi_T  T \Longleftarrow \Longrightarrow","['functional-analysis', 'hilbert-spaces']"
52,"Closed subspace of $L^{p}( [a,b])$ consisting of continuous functions",Closed subspace of  consisting of continuous functions,"L^{p}( [a,b])","I'm wondering if a closed subspace of $L^p [a,b](1\leq p<\infty)$ consisting of continuous functions must be finite-dimensional? I already know it's true for $L^2([a,b]): $ this question",I'm wondering if a closed subspace of consisting of continuous functions must be finite-dimensional? I already know it's true for this question,"L^p [a,b](1\leq p<\infty) L^2([a,b]): ","['functional-analysis', 'analysis', 'measure-theory']"
53,"Normal bounded operator in Hilbert space, whose spectrum is real, is self-adjoint","Normal bounded operator in Hilbert space, whose spectrum is real, is self-adjoint",,"Let $T$ be a bounded normal operator in Hilbert space such that the spectrum $\sigma(T)$ is contained in the real axis. By the Gelfand-Naimark theorem for commutative $C^*$ -algebras the $C^*$ -algebra generated by $T$ and $I$ is isometrically isomorphic to $C(\sigma(T)),$ the algebra of complex valued  continuous functions on $\sigma(T)\subset \mathbb{R}.$ The operator $T$ corresponds to multiplication by $x$ in $C(\sigma(T)),$ therefore $T$ is self-adjoint . I would like to prove that fact  in a straightforward way, but I could not come up with any idea. When $T$ is a compact operator the proof is relatively easy. Assume by contradiction that $T^*-T\neq 0.$ Then one of the numbers $\lambda:=\pm{1\over 2}\|T^*-T\|\neq 0$ is the eigenvalue of the self-adjoint operator $B:={i\over 2}(T^*-T).$ Let $V_\lambda$ denote the eigenspace of the operator $B$ corresponding to $\lambda.$ As $T$ and $T^*$ commute with $B,$ the subspace $V_\lambda$ is invariant for $A={1\over 2}(T+T^*).$ The operator $T=A+iB$ restricted to $V_\lambda$ is of the form $A+i\lambda I.$ Therefore $\sigma(T)\subsetneq \mathbb{R},$ which gives a contradiction.","Let be a bounded normal operator in Hilbert space such that the spectrum is contained in the real axis. By the Gelfand-Naimark theorem for commutative -algebras the -algebra generated by and is isometrically isomorphic to the algebra of complex valued  continuous functions on The operator corresponds to multiplication by in therefore is self-adjoint . I would like to prove that fact  in a straightforward way, but I could not come up with any idea. When is a compact operator the proof is relatively easy. Assume by contradiction that Then one of the numbers is the eigenvalue of the self-adjoint operator Let denote the eigenspace of the operator corresponding to As and commute with the subspace is invariant for The operator restricted to is of the form Therefore which gives a contradiction.","T \sigma(T) C^* C^* T I C(\sigma(T)), \sigma(T)\subset \mathbb{R}. T x C(\sigma(T)), T T T^*-T\neq 0. \lambda:=\pm{1\over 2}\|T^*-T\|\neq 0 B:={i\over 2}(T^*-T). V_\lambda B \lambda. T T^* B, V_\lambda A={1\over 2}(T+T^*). T=A+iB V_\lambda A+i\lambda I. \sigma(T)\subsetneq \mathbb{R},","['functional-analysis', 'operator-theory']"
54,Prove that $\Lambda$ is not compact,Prove that  is not compact,\Lambda,"On the Banach space $X=C[0,1]$ , consider the linear operator $\Lambda:X\rightarrow X$ defined by $$ (\Lambda f)(0)=f(0),(\Lambda f)(t)=\frac{1}{t}\int_0^tf(s)ds,\forall t>0 $$ Prove that $\Lambda$ is not compact. My idea: Assume that $\Lambda$ is compact, I am trying to find counterexample. First, let $x_n(t)=t^n$ , the norm of $x_n$ is 1, I hope that $\{\Lambda x_n\}$ is not pre-compact. Unfortunely, $\lim_{n\to \infty}\|\Lambda x_n\|=0$ . Then I do not know what to do.","On the Banach space , consider the linear operator defined by Prove that is not compact. My idea: Assume that is compact, I am trying to find counterexample. First, let , the norm of is 1, I hope that is not pre-compact. Unfortunely, . Then I do not know what to do.","X=C[0,1] \Lambda:X\rightarrow X 
(\Lambda f)(0)=f(0),(\Lambda f)(t)=\frac{1}{t}\int_0^tf(s)ds,\forall t>0
 \Lambda \Lambda x_n(t)=t^n x_n \{\Lambda x_n\} \lim_{n\to \infty}\|\Lambda x_n\|=0","['functional-analysis', 'compact-operators']"
55,Non-unital $C^\star$ subalgebra of a unital $C^\star$ algebra,Non-unital  subalgebra of a unital  algebra,C^\star C^\star,"Straightforward techniques exist for unitizing a given non-unital $C^\star$ algebra, that is, viewing it as a $C^\star$ subalgebra (in fact, a closed ideal) of a unital $C^\star$ algebra. I am trying to see if something of a similar sort can be done in the opposite direction. Given a unital $C^\star$ algebra $\mathcal{A}$ , when does it contain a $C^\star$ subalgebra (i.e., a norm closed subalgebra) $\mathcal{B}$ that is not unital? How to find such subalgebras, when they exist? Note: The subalgebra $\mathcal{B}$ might fail to contain the multiplicative identity of the full algebra $\mathcal{A}$ , $\mathbb{1}_\mathcal{A}$ , and still end up being unital. Some other element than $\mathbb{1}_\mathcal{A}$ , might end up serving as $\mathbb{1}_\mathcal{B}$ . Partial solution: Such subalgebras can never exist in finite dimensions. It is easy to see from several different arguments (eg, the Artin-Wedderburn theorem, compactness of the unit ball in finite dimensions), that every finite-dimensional $C^\star$ algebra is unital. In the infinite dimensional commutative case, consider $\mathcal{A}\cong C(X)$ for some compact Hausdorff space $X$ such that $X$ contains a limit point $x_0$ . Then $\hat{X}:= X \backslash \{x_0\}$ is a noncompact but locally compact Hausdorff space, and $C_0(\hat{X})$ is (isomorphic to) a closed proper ideal of $C(X)$ , and a non-unital $C^\star$ subalgebra. For $\mathcal{B(H)}$ , of course, $\mathcal{K(H)}$ comes to the rescue (for infinite dimensional $\mathcal{H}$ , $\mathcal{B(H)}$ is unital, while the closed subalgebra (ideal) of compact operators $\mathcal{K(H)}$ is non-unital). How should I proceed in the general case? Otherwise, how to proceed for a) infinite dimensional noncommutative $C^\star$ algebras? b) infinite dimensional commutative $C^\star$ algebras where the spectrum does not contain a limit point? I don't think GNS and step 3) from above will be of much help here, since I don't know if compactness passes on through $\star$ -homomorphisms in a natural way (I don't think it does, but I don't know, really...)","Straightforward techniques exist for unitizing a given non-unital algebra, that is, viewing it as a subalgebra (in fact, a closed ideal) of a unital algebra. I am trying to see if something of a similar sort can be done in the opposite direction. Given a unital algebra , when does it contain a subalgebra (i.e., a norm closed subalgebra) that is not unital? How to find such subalgebras, when they exist? Note: The subalgebra might fail to contain the multiplicative identity of the full algebra , , and still end up being unital. Some other element than , might end up serving as . Partial solution: Such subalgebras can never exist in finite dimensions. It is easy to see from several different arguments (eg, the Artin-Wedderburn theorem, compactness of the unit ball in finite dimensions), that every finite-dimensional algebra is unital. In the infinite dimensional commutative case, consider for some compact Hausdorff space such that contains a limit point . Then is a noncompact but locally compact Hausdorff space, and is (isomorphic to) a closed proper ideal of , and a non-unital subalgebra. For , of course, comes to the rescue (for infinite dimensional , is unital, while the closed subalgebra (ideal) of compact operators is non-unital). How should I proceed in the general case? Otherwise, how to proceed for a) infinite dimensional noncommutative algebras? b) infinite dimensional commutative algebras where the spectrum does not contain a limit point? I don't think GNS and step 3) from above will be of much help here, since I don't know if compactness passes on through -homomorphisms in a natural way (I don't think it does, but I don't know, really...)",C^\star C^\star C^\star C^\star \mathcal{A} C^\star \mathcal{B} \mathcal{B} \mathcal{A} \mathbb{1}_\mathcal{A} \mathbb{1}_\mathcal{A} \mathbb{1}_\mathcal{B} C^\star \mathcal{A}\cong C(X) X X x_0 \hat{X}:= X \backslash \{x_0\} C_0(\hat{X}) C(X) C^\star \mathcal{B(H)} \mathcal{K(H)} \mathcal{H} \mathcal{B(H)} \mathcal{K(H)} C^\star C^\star \star,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
56,Identity map between two Banach spaces always bounded,Identity map between two Banach spaces always bounded,,"Let $X$ be a Banach spaces, $\| \cdot \|_1$ and $\| \cdot \|_2$ be two different norms. Suppose that $\| x\|_1 \leq M\| x\|_2$ for all $x\in X$ . I've seen many places that say that the identity map $I: (X, \| \cdot \|_1) \rightarrow (X, \|\cdot \|_2)$ is always bounded, i.e. continuous. But I'm not sure why it's true. And where does it use the completeness? This is how I have attempted to prove it. Let $x\in X$ . Then $\|I(x) \|_1= \|x \| _2 \leq \| I\|_1 \| x\|_1 \leq M\| x\|_2$ . Not sure how to proceed. Thank you.","Let be a Banach spaces, and be two different norms. Suppose that for all . I've seen many places that say that the identity map is always bounded, i.e. continuous. But I'm not sure why it's true. And where does it use the completeness? This is how I have attempted to prove it. Let . Then . Not sure how to proceed. Thank you.","X \| \cdot \|_1 \| \cdot \|_2 \| x\|_1 \leq M\| x\|_2 x\in X I: (X, \| \cdot \|_1) \rightarrow (X, \|\cdot \|_2) x\in X \|I(x) \|_1= \|x \| _2 \leq \| I\|_1 \| x\|_1 \leq M\| x\|_2","['functional-analysis', 'banach-spaces']"
57,Banach spaces admitting a coarser topology for which the closed unit ball is compact.,Banach spaces admitting a coarser topology for which the closed unit ball is compact.,,"Let $X$ be a Banach space and let $B$ be its closed unit ball. It is well known that $B$ is compact in the weak topology provided $B$ is reflexive.   Otherwise,   if $X$ is at least a  dual space, then $B$ is compact in the weak* topology. These examples show that, in many situations, there exists a Hausdorff locally convex topology on $X$ , coarser than the norm topology,  relative to which $B$ is compact. For $X=c_0$ , I cannot think of such a topology and I doubt it exists.  The reason is I feel the sequence $\{x_n\}_n$ given by $$   x_n= (1,1,\ldots, 1,0,0, 0\ldots)   $$ ( $n$ ones) cannot possibly have a cluster point in any sensible topology. Question .  Given a Banach space $X$ ,  is there always  a Hausdorff locally convex topology on $X$ , coarser than the norm topology, relative to which the closed unit ball is compact? Can one characterize the spaces for which this is true? What if $X=c_0$ ?","Let be a Banach space and let be its closed unit ball. It is well known that is compact in the weak topology provided is reflexive.   Otherwise,   if is at least a  dual space, then is compact in the weak* topology. These examples show that, in many situations, there exists a Hausdorff locally convex topology on , coarser than the norm topology,  relative to which is compact. For , I cannot think of such a topology and I doubt it exists.  The reason is I feel the sequence given by ( ones) cannot possibly have a cluster point in any sensible topology. Question .  Given a Banach space ,  is there always  a Hausdorff locally convex topology on , coarser than the norm topology, relative to which the closed unit ball is compact? Can one characterize the spaces for which this is true? What if ?","X B B B X B X B X=c_0 \{x_n\}_n 
  x_n= (1,1,\ldots, 1,0,0, 0\ldots)
   n X X X=c_0","['functional-analysis', 'banach-spaces', 'locally-convex-spaces', 'weak-topology', 'reflexive-space']"
58,How to prove that $\frac{2^{\sqrt{n}}}{n!}\left(\frac{n}{e}\right)^n$ diverges as $n \rightarrow \infty$?,How to prove that  diverges as ?,\frac{2^{\sqrt{n}}}{n!}\left(\frac{n}{e}\right)^n n \rightarrow \infty,"Consider the limit $$\lim_{n\to +\infty} \frac{2^{\sqrt{n}}}{n!}\left(\frac{n}{e}\right)^n.$$ How to show that this limit is $+\infty$ ? I just tried square criterion but it doesn’t work. Moreover, Stirling’s formula is not allowed (requested in the assignment). Could anyone please help? Thank you in advance!","Consider the limit How to show that this limit is ? I just tried square criterion but it doesn’t work. Moreover, Stirling’s formula is not allowed (requested in the assignment). Could anyone please help? Thank you in advance!",\lim_{n\to +\infty} \frac{2^{\sqrt{n}}}{n!}\left(\frac{n}{e}\right)^n. +\infty,"['real-analysis', 'functional-analysis', 'limits']"
59,"Proving $\exp (T + S) = \exp (T) \exp (S) = \exp (S) \exp (T)$ for $T,S\in\mathcal{L}(E)$",Proving  for,"\exp (T + S) = \exp (T) \exp (S) = \exp (S) \exp (T) T,S\in\mathcal{L}(E)","Let $E$ be a Banach space and $T,S \in \mathcal L (E)$ be two commuting maps i.e., $TS = ST.$ Then, $$\exp (T + S) = \exp (T) \exp (S) = \exp (S) \exp (T).$$ I can able to prove it using the formula for exponential but the proof is very clumsy. Is there any easier way to prove the above equality? Any help in this regard will be appreciated. Thanks in advance.","Let be a Banach space and be two commuting maps i.e., Then, I can able to prove it using the formula for exponential but the proof is very clumsy. Is there any easier way to prove the above equality? Any help in this regard will be appreciated. Thanks in advance.","E T,S \in \mathcal L (E) TS = ST. \exp (T + S) = \exp (T) \exp (S) = \exp (S) \exp (T).","['functional-analysis', 'operator-theory']"
60,Equivalent condition to an operator $T$ on a complex Hilbert space being compact,Equivalent condition to an operator  on a complex Hilbert space being compact,T,"Let $H$ be a complex Hilbert space and let $T:H\rightarrow H$ be a bounded linear map. The problem asks to show $T$ is compact if and only if for any sequence $x_n$ weakly converging to $0$ , $\langle Tx_n,x_n \rangle\rightarrow 0$ . While the forward implication seem to be relatively straightforward, I'm having trouble proving the reverse implication. By reflexivity of $H$ it suffices to show that $\langle Tx_n,x_n\rangle \rightarrow 0$ implies $\|Tx_n\|\rightarrow 0$ . Also because the problem sort of suggests that something might be different for real Hilbert spaces, I tried using the polarization identity (but couldn't make it work). Any help would be appreciated. Thanks in advance!","Let be a complex Hilbert space and let be a bounded linear map. The problem asks to show is compact if and only if for any sequence weakly converging to , . While the forward implication seem to be relatively straightforward, I'm having trouble proving the reverse implication. By reflexivity of it suffices to show that implies . Also because the problem sort of suggests that something might be different for real Hilbert spaces, I tried using the polarization identity (but couldn't make it work). Any help would be appreciated. Thanks in advance!","H T:H\rightarrow H T x_n 0 \langle Tx_n,x_n \rangle\rightarrow 0 H \langle Tx_n,x_n\rangle \rightarrow 0 \|Tx_n\|\rightarrow 0","['functional-analysis', 'hilbert-spaces', 'weak-convergence', 'compact-operators']"
61,An example for a seminorm on $\mathbb{R}^n$,An example for a seminorm on,\mathbb{R}^n,"Can any one come up with an example of a seminorm that is not a norm on $\mathbb{R}^n$ ? A seminorm on a real vector space $V$ is a function $N:V\rightarrow \mathbb{R}$ that satisfies that 1) $N(x)\geq 0$ , $x\in V$ 2) $N(\alpha x)=|\alpha|N(x)$ , $x\in V$ , $\alpha\in \mathbb{R}$ 3) $N(x+y)\leq N(x)+N(y)$ , $x,y\in V$ So a seminorm generalizes a norm as it does not require the condition $$N(x)=0\Longrightarrow x=0$$ .","Can any one come up with an example of a seminorm that is not a norm on ? A seminorm on a real vector space is a function that satisfies that 1) , 2) , , 3) , So a seminorm generalizes a norm as it does not require the condition .","\mathbb{R}^n V N:V\rightarrow \mathbb{R} N(x)\geq 0 x\in V N(\alpha x)=|\alpha|N(x) x\in V \alpha\in \mathbb{R} N(x+y)\leq N(x)+N(y) x,y\in V N(x)=0\Longrightarrow x=0","['linear-algebra', 'functional-analysis', 'approximation-theory']"
62,inverse via functional calculus,inverse via functional calculus,,Let $H$ be a positive definit self-adjoint operator. Can someone explain to me why $$\int_{0}^{\infty}{e^{-tH}dt}=H^{-1}?$$ Thanks in advance!,Let be a positive definit self-adjoint operator. Can someone explain to me why Thanks in advance!,H \int_{0}^{\infty}{e^{-tH}dt}=H^{-1}?,['functional-analysis']
63,"Given a closed linear subspace, is there always a projection that maps onto it?","Given a closed linear subspace, is there always a projection that maps onto it?",,"Given a closed linear subspace, is there always a projection that maps onto it? Here, a projection $P$ should be a linear and continuous mapping and satisfies $P^2 = P$ .","Given a closed linear subspace, is there always a projection that maps onto it? Here, a projection should be a linear and continuous mapping and satisfies .",P P^2 = P,"['functional-analysis', 'map-projections']"
64,"No non-negative continuous function on $[a,b]$ such that $\int_a^b f(t)dt=1, \int_a^b tf(t)dt=c, \int_a^b t^2f(t)dt=c^2$ for $c\in\mathbb{R}$.",No non-negative continuous function on  such that  for .,"[a,b] \int_a^b f(t)dt=1, \int_a^b tf(t)dt=c, \int_a^b t^2f(t)dt=c^2 c\in\mathbb{R}","Show that there exists no non-negative continuous function $f$ defined on the interval $[a,b]$ such that it satisfies the following conditions: $$\int_a^b f(t)dt=1 \quad \int_a^b tf(t)dt = c \quad \int_a^b t^2f(t)dt = c^2,$$ for some $c\in\mathbb{R}$ . I was given a hint that I need to use Cauchy-Schwarz inequality, and I am familiar with Cauchy-Schwarz, I just do not see how to apply it to this problem. Cauchy-Schwarz inequality states that if $u$ and $v$ are elements of an inner product space then, $\| \langle u,v \rangle \| \leq \| u \| \| v \|$ . So I guess here I have the inner product space of $C([a,b])$ , continuous functions on $[a,b]$ , and I have that $$\langle f, 1 \rangle = 1 \quad \langle f,t\rangle = c \quad \langle f,t^2 \rangle = c^2$$ I don't know how to piece it together though. Any help would be appreciated!","Show that there exists no non-negative continuous function defined on the interval such that it satisfies the following conditions: for some . I was given a hint that I need to use Cauchy-Schwarz inequality, and I am familiar with Cauchy-Schwarz, I just do not see how to apply it to this problem. Cauchy-Schwarz inequality states that if and are elements of an inner product space then, . So I guess here I have the inner product space of , continuous functions on , and I have that I don't know how to piece it together though. Any help would be appreciated!","f [a,b] \int_a^b f(t)dt=1 \quad \int_a^b tf(t)dt = c \quad \int_a^b t^2f(t)dt = c^2, c\in\mathbb{R} u v \| \langle u,v \rangle \| \leq \| u \| \| v \| C([a,b]) [a,b] \langle f, 1 \rangle = 1 \quad \langle f,t\rangle = c \quad \langle f,t^2 \rangle = c^2","['real-analysis', 'functional-analysis', 'analysis', 'hilbert-spaces']"
65,"Prove that $ \|x\|=\sup\{|f(x)|:f\in X^*, \,\|f\|=1\},$ where $x\in X$ and $X^*$ denotes the dual space of $X$.",Prove that  where  and  denotes the dual space of .," \|x\|=\sup\{|f(x)|:f\in X^*, \,\|f\|=1\}, x\in X X^* X","Let $x$ be an element of a normed linear space $X$ and let $X^*$ denote the dual space of $X$ . Prove that \begin{align} \|x\|=\sup\{|f(x)|:f\in X^*, \,\|f\|=1\} \end{align} MY TRIAL It suffices to show that \begin{align} \forall\;\epsilon>0,\;\exists\;|f(x_{\epsilon})|\in \{|f(x)|:f\in X^*, \,\|f\|=1\}\;\;\text{such that}\end{align} \begin{align} \|x\|-\epsilon< |f(x_{\epsilon})|\leq \|x\|.\end{align} Let $x\in X$ such that $x\neq 0.$ Otherwise, $\|f\|=0$ . Then, by Hanh-Banach Theorem, there exists a linear functional $f$ on $X$ such that \begin{align} \|f\|=1 \;\;\;\text{and}\;\;\;|f(x)|= \|x\|\leq \|x\|.\end{align} Please, I'm I right thus far? If yes, I am stuck here as I don't know how to arrive at \begin{align} \|x\|-\epsilon< |f(x)|.\end{align} If no, can you help fix my wrong(s)?","Let be an element of a normed linear space and let denote the dual space of . Prove that MY TRIAL It suffices to show that Let such that Otherwise, . Then, by Hanh-Banach Theorem, there exists a linear functional on such that Please, I'm I right thus far? If yes, I am stuck here as I don't know how to arrive at If no, can you help fix my wrong(s)?","x X X^* X \begin{align} \|x\|=\sup\{|f(x)|:f\in X^*, \,\|f\|=1\} \end{align} \begin{align} \forall\;\epsilon>0,\;\exists\;|f(x_{\epsilon})|\in \{|f(x)|:f\in X^*, \,\|f\|=1\}\;\;\text{such that}\end{align} \begin{align} \|x\|-\epsilon< |f(x_{\epsilon})|\leq \|x\|.\end{align} x\in X x\neq 0. \|f\|=0 f X \begin{align} \|f\|=1 \;\;\;\text{and}\;\;\;|f(x)|= \|x\|\leq \|x\|.\end{align} \begin{align} \|x\|-\epsilon< |f(x)|.\end{align}","['functional-analysis', 'analysis']"
66,Proving that $f(x)=0$ in all points of continuity if $f$ is orthogonal to all polynomials,Proving that  in all points of continuity if  is orthogonal to all polynomials,f(x)=0 f,"Suppose that the function $f$ is: 1) Riemann integrable (not necessarily continuous) function on $\big[a,b \big]$ ; 2) $\forall n \geq 0$ $\int_{a}^{b}{f(x) x^n} = 0$ (in particular, it means that the function is orthogonal to all polynomials). Prove that $f(x) = 0$ in all points of continuity $f$ .","Suppose that the function is: 1) Riemann integrable (not necessarily continuous) function on ; 2) (in particular, it means that the function is orthogonal to all polynomials). Prove that in all points of continuity .","f \big[a,b \big] \forall n \geq 0 \int_{a}^{b}{f(x) x^n} = 0 f(x) = 0 f","['real-analysis', 'functional-analysis', 'riemann-integration']"
67,infimum implies existence of a sequence,infimum implies existence of a sequence,,"I am following 'Introductory Functional Analysis' by Kreyszig. Theorem 3.3-1 says that Let $X$ be an inner product space and $M\neq\phi$ a convex subset which is complete (in the metric induced by inner-product). Then for every given $x\in X$ there exists a unique $y\in M$ such that  $$\delta=\inf_{y'\in M}||x-y'||=||x-y||.$$ In the proof of this theorem, he has written that By the definition of infimum there is a sequence $(y_n)$ in $M$ such that $\delta_n$ approaches $\delta$ where $\delta_n=||x-y_n||.$ I don't understand this statement because definition of infimum does not say anything about the existence of a sequence. For example, I can have a set {1} which has infimum equal to 1, but there is no sequence which converges to 1. So what does he mean in this proof? Am I missing something here?","I am following 'Introductory Functional Analysis' by Kreyszig. Theorem 3.3-1 says that Let $X$ be an inner product space and $M\neq\phi$ a convex subset which is complete (in the metric induced by inner-product). Then for every given $x\in X$ there exists a unique $y\in M$ such that  $$\delta=\inf_{y'\in M}||x-y'||=||x-y||.$$ In the proof of this theorem, he has written that By the definition of infimum there is a sequence $(y_n)$ in $M$ such that $\delta_n$ approaches $\delta$ where $\delta_n=||x-y_n||.$ I don't understand this statement because definition of infimum does not say anything about the existence of a sequence. For example, I can have a set {1} which has infimum equal to 1, but there is no sequence which converges to 1. So what does he mean in this proof? Am I missing something here?",,"['real-analysis', 'functional-analysis', 'proof-explanation', 'supremum-and-infimum']"
68,Bounded projection,Bounded projection,,"I have a problem proving the following: Consider a banach space $X$. A projection is bounded if and only if $\mathrm{Im} (P)= \{ Px : x \in X\}$ nd $\mathrm{Ker}(P) = \{x \in X: Px =0\}$ are closed subspaces of $X$. So we know that a linear operator,say P is a projection if $P^2=P$.  Assume first that the projection is bounded. Then $\exists M$  s.t $||Px||\leq M||x||$ for all $x \in X$. Then, since we know that $X$ is a Banach space, take a sequence say $\{x_n\}_n$ then we know that it is convergent. Say x is the limit. Apply P on $\{x_n\}_n$. Assume $\{Px_n\}$ sonverges to y. Then $x_n - Px_n = (I-P)x_n$ converges to $x - y$. It follows that $y \in \mathrm{Im}(P)$ and $x-y \in \mathrm{Ker}(P)$, so $y = Py = Px$. Hence the conclusion follows from the closed graph theorem. Is it true what I wrote? I mean does it really proof the theorem? How to proceed next?","I have a problem proving the following: Consider a banach space $X$. A projection is bounded if and only if $\mathrm{Im} (P)= \{ Px : x \in X\}$ nd $\mathrm{Ker}(P) = \{x \in X: Px =0\}$ are closed subspaces of $X$. So we know that a linear operator,say P is a projection if $P^2=P$.  Assume first that the projection is bounded. Then $\exists M$  s.t $||Px||\leq M||x||$ for all $x \in X$. Then, since we know that $X$ is a Banach space, take a sequence say $\{x_n\}_n$ then we know that it is convergent. Say x is the limit. Apply P on $\{x_n\}_n$. Assume $\{Px_n\}$ sonverges to y. Then $x_n - Px_n = (I-P)x_n$ converges to $x - y$. It follows that $y \in \mathrm{Im}(P)$ and $x-y \in \mathrm{Ker}(P)$, so $y = Py = Px$. Hence the conclusion follows from the closed graph theorem. Is it true what I wrote? I mean does it really proof the theorem? How to proceed next?",,"['functional-analysis', 'operator-theory', 'projection']"
69,Possible error in a proof in Jost's Riemannian Geometry and Geometric Analysis,Possible error in a proof in Jost's Riemannian Geometry and Geometric Analysis,,"I am reading Jost's Riemannian Geometry and Geometric Analysis , sixth edition. I suspect that there is an error in a proof. First let's define the following: Let $M$ be a compact, connected, oriented Riemannian manifold. Define an inner product on the set of $p$ -forms on $M$ by $$(\alpha,\beta):=\int_M\alpha\wedge\star\beta,$$ where $\star$ is the Hodge star operator. In the book, page 116, there is the following statement: Corollary 3.4.1. There exists a constant $c$ , depending only on the Riemannian metric of $M$ , with the property that for all closed forms $\beta$ that are orthogonal to the kernel of $d^*$ , $$(\beta,\beta)\le c(d^*\beta,d^*\beta).$$ Note $d^*=(-1)^{n(p+1)+1}\star d\star$ when acting on $p$ -form, where $n$ is the dimension of $M$ . Later on, on page 118, when trying to prove that the linear functional $\ell:d^*(\Omega^p(M))\to\Bbb R$ , $\ell(d^*\varphi)=(\eta,\varphi)$ is bounded for a certain $\eta$ , there is the following construction: For $\varphi\in\Omega^p(M)$ , let $\pi(\varphi)$ be the orthogonal projection onto the kernel of $d^*$ , and $\psi:=\varphi-\pi(\varphi)$ ; in particular $d^*\varphi=d^*\psi$ . Since $\psi$ is orthogonal to the kernel of $d^*$ , by Corollary 3.4.1, $\lVert \psi\rVert_{L^2}\le c\lVert d^*\psi\rVert_{L^2}=c\lVert d^*\varphi\rVert_{L^2}$ . I am not sure if the use of Corollary 3.4.1 for deducing the last inequality is correct, because I do not know if $\psi$ is closed. Can we prove that $\psi$ is actually closed? If not, how can we fix the proof? Edit : note that the proof in the book comes before Hodge decomposition theorem, so I cannot use this theorem.","I am reading Jost's Riemannian Geometry and Geometric Analysis , sixth edition. I suspect that there is an error in a proof. First let's define the following: Let be a compact, connected, oriented Riemannian manifold. Define an inner product on the set of -forms on by where is the Hodge star operator. In the book, page 116, there is the following statement: Corollary 3.4.1. There exists a constant , depending only on the Riemannian metric of , with the property that for all closed forms that are orthogonal to the kernel of , Note when acting on -form, where is the dimension of . Later on, on page 118, when trying to prove that the linear functional , is bounded for a certain , there is the following construction: For , let be the orthogonal projection onto the kernel of , and ; in particular . Since is orthogonal to the kernel of , by Corollary 3.4.1, . I am not sure if the use of Corollary 3.4.1 for deducing the last inequality is correct, because I do not know if is closed. Can we prove that is actually closed? If not, how can we fix the proof? Edit : note that the proof in the book comes before Hodge decomposition theorem, so I cannot use this theorem.","M p M (\alpha,\beta):=\int_M\alpha\wedge\star\beta, \star c M \beta d^* (\beta,\beta)\le c(d^*\beta,d^*\beta). d^*=(-1)^{n(p+1)+1}\star d\star p n M \ell:d^*(\Omega^p(M))\to\Bbb R \ell(d^*\varphi)=(\eta,\varphi) \eta \varphi\in\Omega^p(M) \pi(\varphi) d^* \psi:=\varphi-\pi(\varphi) d^*\varphi=d^*\psi \psi d^* \lVert \psi\rVert_{L^2}\le c\lVert d^*\psi\rVert_{L^2}=c\lVert d^*\varphi\rVert_{L^2} \psi \psi","['functional-analysis', 'differential-geometry', 'riemannian-geometry']"
70,"Spectrum of the operator $(Ax)(t) = x(0) + t x(1)$ for $A: C[0,1] \to C[0,1]$.",Spectrum of the operator  for .,"(Ax)(t) = x(0) + t x(1) A: C[0,1] \to C[0,1]","I have a question: How can we find the spectrum and resolvent of the operator $A: C[0,1] \to C[0,1]$ which defines as  $(Ax)(t) = x(0) + t x(1)$? $\textbf{Some definitions and facts:}$ The resolvent set of $A$ is: $$\rho(A) = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is invertible} \} = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is bijective} \} $$ And the spectrum of $A$ is: $$\sigma(A) = \mathbb{C}\ \rho(A) = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is not invertible} \} = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is not bijective} \} $$. And we know that $A$ is a positive and a compact operator. If needed I will prove it. Can you please give me the idea on how to find its spectrum? Thanks!","I have a question: How can we find the spectrum and resolvent of the operator $A: C[0,1] \to C[0,1]$ which defines as  $(Ax)(t) = x(0) + t x(1)$? $\textbf{Some definitions and facts:}$ The resolvent set of $A$ is: $$\rho(A) = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is invertible} \} = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is bijective} \} $$ And the spectrum of $A$ is: $$\sigma(A) = \mathbb{C}\ \rho(A) = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is not invertible} \} = \{ \lambda \in \mathbb{C} \mid A - \lambda I ~ \text{is not bijective} \} $$. And we know that $A$ is a positive and a compact operator. If needed I will prove it. Can you please give me the idea on how to find its spectrum? Thanks!",,"['real-analysis', 'functional-analysis', 'operator-theory']"
71,"How can i prove that linear function does not form a vector space basis of $\mathcal{C}\bigl([0,1]\bigr)$ over $\mathbb R$?",How can i prove that linear function does not form a vector space basis of  over ?,"\mathcal{C}\bigl([0,1]\bigr) \mathbb R","Prove that the linear function does not form a vector space  basis  of $\mathcal{C}\bigl([0,1]\bigr)$ over $\mathbb R$? i was trying this question many times but i could not get it. i was taking   the  scalar  multiplication and  addition property it was showing that this vector  form  vector space ie  it contain the zero vector i dont know from where i have to start if anybody help me , i would be very thankful to him","Prove that the linear function does not form a vector space  basis  of $\mathcal{C}\bigl([0,1]\bigr)$ over $\mathbb R$? i was trying this question many times but i could not get it. i was taking   the  scalar  multiplication and  addition property it was showing that this vector  form  vector space ie  it contain the zero vector i dont know from where i have to start if anybody help me , i would be very thankful to him",,"['linear-algebra', 'functional-analysis', 'vector-spaces', 'linear-transformations']"
72,A question concerning pointwise convergence,A question concerning pointwise convergence,,"Let $\{f_k\}_{k\ge 0}$ be a sequence of continuous and bounded functions $f_k\colon \mathbb{R}\to \mathbb{R},\ x\mapsto f_k(x)$, converging pointwise to $f$. Suppose that there exists a sequence of increasing integers $k_1,k_2,\dots$ and a corresponding convergent sequence $x_1,x_2,\dots$ such that $\displaystyle\lim_{\ell\to\infty}x_\ell = x$ and $\displaystyle\lim_{\ell\to\infty} f_{k_\ell}(x_\ell)$ exists. My question: Is it true that   $$ \lim_{\ell\to\infty} f_{k_\ell}(x_\ell) = f(x)\ \ \ ? $$ I apologize if this is a silly question. Any help is very appreciated.","Let $\{f_k\}_{k\ge 0}$ be a sequence of continuous and bounded functions $f_k\colon \mathbb{R}\to \mathbb{R},\ x\mapsto f_k(x)$, converging pointwise to $f$. Suppose that there exists a sequence of increasing integers $k_1,k_2,\dots$ and a corresponding convergent sequence $x_1,x_2,\dots$ such that $\displaystyle\lim_{\ell\to\infty}x_\ell = x$ and $\displaystyle\lim_{\ell\to\infty} f_{k_\ell}(x_\ell)$ exists. My question: Is it true that   $$ \lim_{\ell\to\infty} f_{k_\ell}(x_\ell) = f(x)\ \ \ ? $$ I apologize if this is a silly question. Any help is very appreciated.",,"['functional-analysis', 'convergence-divergence']"
73,Strong operator convergence of an uncountable series,Strong operator convergence of an uncountable series,,"Let $X$ be a Banach space and $\{T_{\alpha}\}_{\alpha\in I}\subset B(X)$ be a (possible uncountable) family of bounded linear operators on $X$ such that $\sum T_{\alpha}$ converges to the identity operator in the strong operator topology. This means that $\sum T_{\alpha} x=x \ \forall x\in X$. We know that for any summable series, all but countably many of the terms must be $0$. Hence for each $x\in X$, $T_{\alpha}x=0$ for all but countably many terms. Can we then conclude that all but countably many of the $T_{\alpha}$  themselves are $0$? This should happen, for example if $X$ is a separable Hilbert space. What about a separable Banach space? Is there an example of a space where this need not happen? Thanks in advance.","Let $X$ be a Banach space and $\{T_{\alpha}\}_{\alpha\in I}\subset B(X)$ be a (possible uncountable) family of bounded linear operators on $X$ such that $\sum T_{\alpha}$ converges to the identity operator in the strong operator topology. This means that $\sum T_{\alpha} x=x \ \forall x\in X$. We know that for any summable series, all but countably many of the terms must be $0$. Hence for each $x\in X$, $T_{\alpha}x=0$ for all but countably many terms. Can we then conclude that all but countably many of the $T_{\alpha}$  themselves are $0$? This should happen, for example if $X$ is a separable Hilbert space. What about a separable Banach space? Is there an example of a space where this need not happen? Thanks in advance.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'banach-spaces']"
74,Spectrum of the Resolvent of a Self-Adjoint Operator,Spectrum of the Resolvent of a Self-Adjoint Operator,,"Let $\mathcal{H}$ be a Hilbert space, and $A$ a self-adjoint operator with domain $D_{A} \subseteq \mathcal{H}$. Assume that $\lambda_0 \in \rho(A)$, where $\rho(A)$ is the resolvent set of $A$. For any $z \in \rho(A)$, let $R_{A}(z)=(A - z I)^{-1}$ be the resolvent of $A$. Choose $\lambda \neq \lambda_0$. Then it is well known that $\lambda \in \rho(A)$ if and only if $(\lambda - \lambda_0)^{-1} \in \rho(R_{A}(\lambda_0))$ (see e.g. Schmudgen, Unbounded Self-adjoint operators on Hilbert Space, Proposition 2.10). So we have (note that by the spectral theorem $\sigma(A)$ is nonempty): \begin{equation} \sigma(R_{A}(\lambda_0)) \backslash \{0\} = \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \}. \end{equation} If $A$ is a bounded operator on $\mathcal{H}$, then $0 \in \rho(R_{A}(\lambda_0))$, so that in this case, being $\sigma(A)$ closed, we have \begin{equation} \sigma(R_{A}(\lambda_0)) = \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \} = \text{closure}  \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \}. \end{equation} Now suppose that $A$ is unbounded. In this case $0 \in \sigma(R_{A}(\lambda_0))$. If we could prove that $0$ is not an isolated point of $\sigma(R_{A}(\lambda_0))$ (which is the same to say that $\sigma(A)$ is not bounded), we could conclude also in this case that  \begin{equation} \sigma(R_{A}(\lambda_0)) =  \text{closure}  \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \}. \end{equation} So my question is the following: if $A$ is unbounded, can $\sigma(A)$ be bounded? PS This question arouse from the answer given by TrialAndError in this post Norm of the Resolvent","Let $\mathcal{H}$ be a Hilbert space, and $A$ a self-adjoint operator with domain $D_{A} \subseteq \mathcal{H}$. Assume that $\lambda_0 \in \rho(A)$, where $\rho(A)$ is the resolvent set of $A$. For any $z \in \rho(A)$, let $R_{A}(z)=(A - z I)^{-1}$ be the resolvent of $A$. Choose $\lambda \neq \lambda_0$. Then it is well known that $\lambda \in \rho(A)$ if and only if $(\lambda - \lambda_0)^{-1} \in \rho(R_{A}(\lambda_0))$ (see e.g. Schmudgen, Unbounded Self-adjoint operators on Hilbert Space, Proposition 2.10). So we have (note that by the spectral theorem $\sigma(A)$ is nonempty): \begin{equation} \sigma(R_{A}(\lambda_0)) \backslash \{0\} = \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \}. \end{equation} If $A$ is a bounded operator on $\mathcal{H}$, then $0 \in \rho(R_{A}(\lambda_0))$, so that in this case, being $\sigma(A)$ closed, we have \begin{equation} \sigma(R_{A}(\lambda_0)) = \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \} = \text{closure}  \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \}. \end{equation} Now suppose that $A$ is unbounded. In this case $0 \in \sigma(R_{A}(\lambda_0))$. If we could prove that $0$ is not an isolated point of $\sigma(R_{A}(\lambda_0))$ (which is the same to say that $\sigma(A)$ is not bounded), we could conclude also in this case that  \begin{equation} \sigma(R_{A}(\lambda_0)) =  \text{closure}  \left \{ \frac{1}{\mu - \lambda_0} : \mu \in \sigma(A) \right \}. \end{equation} So my question is the following: if $A$ is unbounded, can $\sigma(A)$ be bounded? PS This question arouse from the answer given by TrialAndError in this post Norm of the Resolvent",,"['functional-analysis', 'operator-theory']"
75,Existence of rotations between two points,Existence of rotations between two points,,"Let $x,y\in\mathbb R^n$ ($n\in\mathbb N$) be two given points with the same Euclidean norm: $\|x\|=\|y\|$. Does there, in this case, exist an orthogonal matrix $U\in\mathbb R^{n\times n}$ such that $$Ux=y\quad\text{ and }\quad U^{\mathsf T}U=I?$$ I don’t need an explicit construction, just mere existence. Would the Gram–Schmidt procedure help construct an appropriate orthonormal basis as the columns of $U$?","Let $x,y\in\mathbb R^n$ ($n\in\mathbb N$) be two given points with the same Euclidean norm: $\|x\|=\|y\|$. Does there, in this case, exist an orthogonal matrix $U\in\mathbb R^{n\times n}$ such that $$Ux=y\quad\text{ and }\quad U^{\mathsf T}U=I?$$ I don’t need an explicit construction, just mere existence. Would the Gram–Schmidt procedure help construct an appropriate orthonormal basis as the columns of $U$?",,"['linear-algebra', 'functional-analysis', 'hilbert-spaces']"
76,Connection between weak topology in probability and weak* topology in functional analysis,Connection between weak topology in probability and weak* topology in functional analysis,,"In functional analysis, Definition A: for any normed linear space $(X, \| \cdot \| )$ , the weak star topology $\sigma (X^*, X)$ on $X^*$ is generated by the collection of seminorms $\{ p_x \, | \, x \in X\}$ , defined by $$p_x (f) = |f(x)|.$$ In probability theory (more specifically from the book ""Probability measures on Metric Spaces"" written by Parthasarathy), Definition B: for any metric space $X$ , let $\mathcal{M} (X)$ denote the space of measures defined on $\mathcal{B} (X)$ and let $C(X)$ be the space of all bounded real valued continuous functions on $X$ , equipped with the sup norm. Then the weak topology on the space $\mathcal{M} (X)$ is generated by the base of open neighbourhoods at a point $\mu$ defined by $$ \bigg\{ \nu \in \mathcal{M} (X) \, \Bigg| \, \,  \bigg| \int_X f_i \, d \nu - \int_X f_i \, d \mu \bigg| < \epsilon_i, \, \, i= 1,2,\ldots, k \bigg\},$$ where $f_1, \ldots, f_k \in C(X)$ and $\epsilon_1 , \ldots, \epsilon_k >0$ . Here is what I don't understand: If $X$ is a compact metric space, then by the representation theorem of bounded linear functionals on $C(X)^*$ , then for any $\Lambda \in C(X)^*$ , there exists a unique Borel measure $\mu \in \mathcal{M}(X)$ such that $$ \Lambda_\mu (f) := \Lambda (f) = \int_X f \,d \mu, \quad \forall f \in C(X),$$ and that $$\| \Lambda_\mu \| = \mu (X).$$ Thus, if we identify each element $\mu \in \mathcal{M} (X)$ by $\Lambda_\mu \in C(X)^*$ , Definitions A and B are the same. However, for any general metric space $X$ that is NOT necessarily compact, $\mathcal{M} (X)$ and $C(X)^*$ are not necessarily in isometric isomorphism. (Or is there a representation result in greater generality?) Is Definition B slightly more general than Definition A to cater for the needs in probability theory? If this is the case, then some functional analytic results might not be applicable to weak convergence theory in probability..... Any ideas?","In functional analysis, Definition A: for any normed linear space , the weak star topology on is generated by the collection of seminorms , defined by In probability theory (more specifically from the book ""Probability measures on Metric Spaces"" written by Parthasarathy), Definition B: for any metric space , let denote the space of measures defined on and let be the space of all bounded real valued continuous functions on , equipped with the sup norm. Then the weak topology on the space is generated by the base of open neighbourhoods at a point defined by where and . Here is what I don't understand: If is a compact metric space, then by the representation theorem of bounded linear functionals on , then for any , there exists a unique Borel measure such that and that Thus, if we identify each element by , Definitions A and B are the same. However, for any general metric space that is NOT necessarily compact, and are not necessarily in isometric isomorphism. (Or is there a representation result in greater generality?) Is Definition B slightly more general than Definition A to cater for the needs in probability theory? If this is the case, then some functional analytic results might not be applicable to weak convergence theory in probability..... Any ideas?","(X, \| \cdot \| ) \sigma (X^*, X) X^* \{ p_x \, | \, x \in X\} p_x (f) = |f(x)|. X \mathcal{M} (X) \mathcal{B} (X) C(X) X \mathcal{M} (X) \mu  \bigg\{ \nu \in \mathcal{M} (X) \, \Bigg| \, \,  \bigg| \int_X f_i \, d \nu - \int_X f_i \, d \mu \bigg| < \epsilon_i, \, \, i= 1,2,\ldots, k \bigg\}, f_1, \ldots, f_k \in C(X) \epsilon_1 , \ldots, \epsilon_k >0 X C(X)^* \Lambda \in C(X)^* \mu \in \mathcal{M}(X)  \Lambda_\mu (f) := \Lambda (f) = \int_X f \,d \mu, \quad \forall f \in C(X), \| \Lambda_\mu \| = \mu (X). \mu \in \mathcal{M} (X) \Lambda_\mu \in C(X)^* X \mathcal{M} (X) C(X)^*","['analysis', 'functional-analysis', 'probability-theory', 'metric-spaces', 'weak-convergence']"
77,Properties of Asymptotic analysis,Properties of Asymptotic analysis,,"I have a simple question. We usually use ~ notation if two functions are asymptotically equivalent. My question is, does summation, subtraction, multiplication, and composition of functions preserve the ~ notation? i.e. if $f_1(x)\sim g_1(x)$ and $f_2(x) \sim g_2(x)$ , is it true that $f_1+f_2 \sim g_1+g_2$ , $f_1-f_2 \sim g_1-g_2 $ , $f_1*f_2 \sim g_1*g_2$ , and $f_1(f_2)\sim g_1(g_2)$ ?","I have a simple question. We usually use ~ notation if two functions are asymptotically equivalent. My question is, does summation, subtraction, multiplication, and composition of functions preserve the ~ notation? i.e. if and , is it true that , , , and ?",f_1(x)\sim g_1(x) f_2(x) \sim g_2(x) f_1+f_2 \sim g_1+g_2 f_1-f_2 \sim g_1-g_2  f_1*f_2 \sim g_1*g_2 f_1(f_2)\sim g_1(g_2),"['real-analysis', 'analysis', 'functional-analysis', 'functions', 'asymptotics']"
78,In the proof that $L^{1}$ norm and $L^{2}$ norm are equivalent.,In the proof that  norm and  norm are equivalent.,L^{1} L^{2},"To  prove  that  $L^{1}$  norm , denoted  by  $||\ \ ||_{1}$  and  $L^{2}$  norm , denoted  by  $||\ \ ||_{2}$  are  equivalent we  have  to  find  constants   $C_{1},\ \ C_{2}$   that  satisfies   the  following :$$C_{1} ||x||_{1}\le ||x||_{2}\le C_{2} ||x||_{1}$$ Or  according to  my  book  I  have  to  prove  that  $${{1}\over {\sqrt{n}}}\ \ ||x||_{1} \le\ \  ||x||_{2} \ \ \le \ \sqrt n\ \  ||x||_{1}$$ But  I  am  getting  a  different  result.    $$||x||_{1}=\sum_{i=1}^{n} |x_{i}|  \ \ \ ;\ \ \ \ \ \  ||x||_{2}=\sqrt{ \sum_{i=1}^{n} x_{i}^{2}}$$ Then $$||x||_{1}^{2} = \sum _{i=1}^{n} |x_{i}|^2 \ge \sum_{i=1}^{n}{x_{i}^{2}}= ||x||_{2}^{2}$$  or  $$||x||_{1}\ge ||x||_{2}$$ On  the  other  hand , we  know  $$|x_{i}|\le ||x||_{2}$$i.e. $$\sum_{i=1}^{n} {|x_{i}}| \le n ||x||_{2}$$ or  $$||x||_{1} \le  n||x||_{2}$$  So ,  combining  them  we  get $$||x||_{1} \ \le \ \  n||x||_{2}\ \ \le\ \  n||x||_{1}$$ or $${{1}\over{ n}}||x||_{1} \ \le \ \ ||x||_{2}\ \ \le\ \ ||x||_{1}$$ So  did  I  make  any  mistake  or  that  was  a  simple  printing  mistake  in  my  book $?$ Thanks  for  your  help.","To  prove  that  $L^{1}$  norm , denoted  by  $||\ \ ||_{1}$  and  $L^{2}$  norm , denoted  by  $||\ \ ||_{2}$  are  equivalent we  have  to  find  constants   $C_{1},\ \ C_{2}$   that  satisfies   the  following :$$C_{1} ||x||_{1}\le ||x||_{2}\le C_{2} ||x||_{1}$$ Or  according to  my  book  I  have  to  prove  that  $${{1}\over {\sqrt{n}}}\ \ ||x||_{1} \le\ \  ||x||_{2} \ \ \le \ \sqrt n\ \  ||x||_{1}$$ But  I  am  getting  a  different  result.    $$||x||_{1}=\sum_{i=1}^{n} |x_{i}|  \ \ \ ;\ \ \ \ \ \  ||x||_{2}=\sqrt{ \sum_{i=1}^{n} x_{i}^{2}}$$ Then $$||x||_{1}^{2} = \sum _{i=1}^{n} |x_{i}|^2 \ge \sum_{i=1}^{n}{x_{i}^{2}}= ||x||_{2}^{2}$$  or  $$||x||_{1}\ge ||x||_{2}$$ On  the  other  hand , we  know  $$|x_{i}|\le ||x||_{2}$$i.e. $$\sum_{i=1}^{n} {|x_{i}}| \le n ||x||_{2}$$ or  $$||x||_{1} \le  n||x||_{2}$$  So ,  combining  them  we  get $$||x||_{1} \ \le \ \  n||x||_{2}\ \ \le\ \  n||x||_{1}$$ or $${{1}\over{ n}}||x||_{1} \ \le \ \ ||x||_{2}\ \ \le\ \ ||x||_{1}$$ So  did  I  make  any  mistake  or  that  was  a  simple  printing  mistake  in  my  book $?$ Thanks  for  your  help.",,"['functional-analysis', 'normed-spaces']"
79,Possible ways to induce norm from inner product,Possible ways to induce norm from inner product,,"Let $ S $ be a normed vector space (over $\mathbb{R}$, say, for simplicity) with norm $ \lVert\cdot\rVert$. Can this norm be induced from inner product only through $\lVert \cdot \rVert = \sqrt{\langle \cdot, \cdot \rangle}$ ? As to prove the if part of ""A norm is induced by inner product iff the norm satisfies parallelogram equality"", $\lVert \cdot \rVert = \sqrt{\langle \cdot, \cdot \rangle}$ is used.","Let $ S $ be a normed vector space (over $\mathbb{R}$, say, for simplicity) with norm $ \lVert\cdot\rVert$. Can this norm be induced from inner product only through $\lVert \cdot \rVert = \sqrt{\langle \cdot, \cdot \rangle}$ ? As to prove the if part of ""A norm is induced by inner product iff the norm satisfies parallelogram equality"", $\lVert \cdot \rVert = \sqrt{\langle \cdot, \cdot \rangle}$ is used.",,"['functional-analysis', 'normed-spaces', 'inner-products']"
80,Predual of $l^1(\Gamma)$,Predual of,l^1(\Gamma),"Let $\Gamma$ be an uncountable index set. For example $\Gamma=\mathbb R$. Let  $l^1(\Gamma)$ be the set of functions with countable support and finite sum: $$ \sum_{a\in\Gamma}|f(a)|<\infty. $$ The space $l^1(\Gamma)$ is a Banach space with the norm $\|f\|:=\sum_{a\in\Gamma}|f(a)|$. It is not separable. My question is: does $l^1(\Gamma)$ have a separable pre-dual space? I have seen statements that $l^1(\Gamma)$ is isometric to the dual space of $c_0(\Gamma)$, however I did not found a definition of $c_0(\Gamma)$ nor a statement about its separability. The usual Krein-Milman based argument does not fail as in the $L^1$ case (the unit ball of $l^1(\Gamma)$ is the closed convex hull of its extreme points).","Let $\Gamma$ be an uncountable index set. For example $\Gamma=\mathbb R$. Let  $l^1(\Gamma)$ be the set of functions with countable support and finite sum: $$ \sum_{a\in\Gamma}|f(a)|<\infty. $$ The space $l^1(\Gamma)$ is a Banach space with the norm $\|f\|:=\sum_{a\in\Gamma}|f(a)|$. It is not separable. My question is: does $l^1(\Gamma)$ have a separable pre-dual space? I have seen statements that $l^1(\Gamma)$ is isometric to the dual space of $c_0(\Gamma)$, however I did not found a definition of $c_0(\Gamma)$ nor a statement about its separability. The usual Krein-Milman based argument does not fail as in the $L^1$ case (the unit ball of $l^1(\Gamma)$ is the closed convex hull of its extreme points).",,"['functional-analysis', 'measure-theory', 'lp-spaces']"
81,Inverse of laplacian operator,Inverse of laplacian operator,,"I recently read a paper, the author treats  $$\int_{\mathbb{R}^d}f(y)\cdot \frac{1}{|x-y|^{d-2}}\,dx = (- \Delta)^{-1} f(y)$$ up to a constant in $\mathbb{R}^d$. I am not familiar with unbounded operator, so my question is: Under what condition can one take the inverse of an unbounded operator like above? Can anyone refer some references? Thanks!","I recently read a paper, the author treats  $$\int_{\mathbb{R}^d}f(y)\cdot \frac{1}{|x-y|^{d-2}}\,dx = (- \Delta)^{-1} f(y)$$ up to a constant in $\mathbb{R}^d$. I am not familiar with unbounded operator, so my question is: Under what condition can one take the inverse of an unbounded operator like above? Can anyone refer some references? Thanks!",,"['real-analysis', 'functional-analysis', 'operator-theory', 'distribution-theory', 'compact-operators']"
82,Square root of unbounded operator,Square root of unbounded operator,,"Let $T: \operatorname{dom}(T) \subset H \rightarrow H$ be a positive self-adjoint unbounded operator, then I want to define a UNIQUE(!) operator $A$ such that $A^{*}A = T$. Actually, this construction is nothing new, but I am uncertain about the DOMAIN(!) of $A$ in the case of unbounded operators. Therefore, I was wondering if anybody here knows a good reference that treats this ""polar decomposition"" also in the case of unbounded operators. Alternatively, if somebody wants to comment on this problem, I would highly appreciate this. I mean, one is somehow tempted to say $\operatorname{dom}(A) = \operatorname{dom}(T)$ and then it is necessary that $\{Ax:x \in \operatorname{dom}(T)\} \subseteq\operatorname{dom}(A^*)$, but how can I see this or is this completely wrong?","Let $T: \operatorname{dom}(T) \subset H \rightarrow H$ be a positive self-adjoint unbounded operator, then I want to define a UNIQUE(!) operator $A$ such that $A^{*}A = T$. Actually, this construction is nothing new, but I am uncertain about the DOMAIN(!) of $A$ in the case of unbounded operators. Therefore, I was wondering if anybody here knows a good reference that treats this ""polar decomposition"" also in the case of unbounded operators. Alternatively, if somebody wants to comment on this problem, I would highly appreciate this. I mean, one is somehow tempted to say $\operatorname{dom}(A) = \operatorname{dom}(T)$ and then it is necessary that $\{Ax:x \in \operatorname{dom}(T)\} \subseteq\operatorname{dom}(A^*)$, but how can I see this or is this completely wrong?",,"['real-analysis', 'analysis']"
83,Show that the Open Mapping Theorem requires both spaces to be complete,Show that the Open Mapping Theorem requires both spaces to be complete,,"I am trying to show counter examples to the Open Mapping Theorem. In this particular case, I am trying to show that both spaces need to be Banach. First the OMT: Let $X, Y$ be Banach spaces. Let $T : X \rightarrow Y$ be a surjective   bounded linear operator. $T$ is an open mapping. Now, for the counterexample, let $X = l^1$ equipped with $||\cdot||_1$. Let $Y = l^1$ equipped with $||\cdot||_\infty$. Claim: Y is not complete. Let $T: X \rightarrow Y$ be the identity operator defined by $Tx = x$. Clearly T is bijection and is bounded (thus continuous). Claim : T is not an open mapping. Basically, the main question is that $X$ is Banach, $Y$ is not and I want to show that the operator is not an open mapping. I am also having a hard time proving that $Y$ is not complete (I know its not, I just cant prove it).","I am trying to show counter examples to the Open Mapping Theorem. In this particular case, I am trying to show that both spaces need to be Banach. First the OMT: Let $X, Y$ be Banach spaces. Let $T : X \rightarrow Y$ be a surjective   bounded linear operator. $T$ is an open mapping. Now, for the counterexample, let $X = l^1$ equipped with $||\cdot||_1$. Let $Y = l^1$ equipped with $||\cdot||_\infty$. Claim: Y is not complete. Let $T: X \rightarrow Y$ be the identity operator defined by $Tx = x$. Clearly T is bijection and is bounded (thus continuous). Claim : T is not an open mapping. Basically, the main question is that $X$ is Banach, $Y$ is not and I want to show that the operator is not an open mapping. I am also having a hard time proving that $Y$ is not complete (I know its not, I just cant prove it).",,['functional-analysis']
84,Does weak convergence in $L^{q}$ imply weak convergence in $L^{p}$,Does weak convergence in  imply weak convergence in,L^{q} L^{p},"Assume we have $u_{k} \rightharpoonup u$ in $L^{q}(\Omega)$, does it then follow that $u_{k} \rightharpoonup u$ in $L^{p}(\Omega)$, given that $q > p$ and $\Omega \subset \mathbb{R}^{n}$ is bounded? I know strong convergence $u_{k} \rightarrow u$ in $L^{q}(\Omega)$ implies strong convergence $u_{k} \rightarrow u$ in $L^{p}(\Omega)$ given that $\Omega \subset \mathbb{R}^{n}$ is bounded. (using Jensen's Inequality to prove) Thanks.","Assume we have $u_{k} \rightharpoonup u$ in $L^{q}(\Omega)$, does it then follow that $u_{k} \rightharpoonup u$ in $L^{p}(\Omega)$, given that $q > p$ and $\Omega \subset \mathbb{R}^{n}$ is bounded? I know strong convergence $u_{k} \rightarrow u$ in $L^{q}(\Omega)$ implies strong convergence $u_{k} \rightarrow u$ in $L^{p}(\Omega)$ given that $\Omega \subset \mathbb{R}^{n}$ is bounded. (using Jensen's Inequality to prove) Thanks.",,"['real-analysis', 'functional-analysis']"
85,Characterization of compact subsets in the metric space of all complex-valued sequences,Characterization of compact subsets in the metric space of all complex-valued sequences,,"Here's the statement of the Problem 4 after Section 2.5 in Introductory Functional Analysis With Applications by Erwine Kryszeg: Show that for an infinite subset $M$ in the space $s$ to be compact, it is necessary that there are numbers $\gamma_1$, $\gamma_2$, $\ldots$ such that for all $x = (\xi_k(x)) \in M$, we have $\vert\xi_k(x)\vert \leq \gamma_k$. (It can be shown that the condition is also sufficient for the compactness of $M$.) What does this condition say? How to show this condition to be necessary and sufficient for compactness of the set  $M$? I know that $s$ is the metric space consisting of all sequences $x \colon= (\xi_i)$, $y \colon= (\eta_i)$ of complex numbers with the metric $d$ defined as follows:  $$d(x,y) \colon= \sum_{i=1}^\infty \frac{\vert \xi_i - \eta_i \vert}{2^i(1+ \vert \xi_i - \eta_i \vert)}. $$","Here's the statement of the Problem 4 after Section 2.5 in Introductory Functional Analysis With Applications by Erwine Kryszeg: Show that for an infinite subset $M$ in the space $s$ to be compact, it is necessary that there are numbers $\gamma_1$, $\gamma_2$, $\ldots$ such that for all $x = (\xi_k(x)) \in M$, we have $\vert\xi_k(x)\vert \leq \gamma_k$. (It can be shown that the condition is also sufficient for the compactness of $M$.) What does this condition say? How to show this condition to be necessary and sufficient for compactness of the set  $M$? I know that $s$ is the metric space consisting of all sequences $x \colon= (\xi_i)$, $y \colon= (\eta_i)$ of complex numbers with the metric $d$ defined as follows:  $$d(x,y) \colon= \sum_{i=1}^\infty \frac{\vert \xi_i - \eta_i \vert}{2^i(1+ \vert \xi_i - \eta_i \vert)}. $$",,"['real-analysis', 'functional-analysis', 'metric-spaces', 'compactness', 'normed-spaces']"
86,Spectral radius of an element in a C*-algebra,Spectral radius of an element in a C*-algebra,,"The  following is an proposition of Takesaki's Operator Theory: For any element $x$ of a Banach algebra ${\cal A}$, we have  $$||x||_{sp}=\lim_{n\to \infty}||x^n||^{\frac{1}{n}}$$ Proof: My question: Why does he use bounded linear functionals of ${\cal A}$ to  show that the sequence $\{\frac{x^n}{\lambda^{n+1}}\}$ is bounded? I  think because the power series $f(\lambda)=(\lambda -  x)^{-1}=\sum_{n\geq 0}\frac{x^n} {\lambda^{n+1}}$ convergences, then  $\frac{x^n}{\lambda^{n+1}}\to 0 $ and therefore this sequence is  bounded. Am I right? Please help me. Thanks in advance.","The  following is an proposition of Takesaki's Operator Theory: For any element $x$ of a Banach algebra ${\cal A}$, we have  $$||x||_{sp}=\lim_{n\to \infty}||x^n||^{\frac{1}{n}}$$ Proof: My question: Why does he use bounded linear functionals of ${\cal A}$ to  show that the sequence $\{\frac{x^n}{\lambda^{n+1}}\}$ is bounded? I  think because the power series $f(\lambda)=(\lambda -  x)^{-1}=\sum_{n\geq 0}\frac{x^n} {\lambda^{n+1}}$ convergences, then  $\frac{x^n}{\lambda^{n+1}}\to 0 $ and therefore this sequence is  bounded. Am I right? Please help me. Thanks in advance.",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'banach-algebras']"
87,Continuous spectral theorem example,Continuous spectral theorem example,,"The spectral theorem can be explicitly expressed for an hermitian matrix by providing its eigen decomposition. In the more general case of a bounded self-adjoint operator with a continuous spectrum, the expression of the spectral theorem is $Ax=\int \lambda dF(\lambda) x$. This expression is rather abstract. Can someone provide a simple example of the continuous case, taking $x$ from a space of function, a differential operator A, and the detailed expressions of $F(\lambda)$ and $dF(\lambda)$ ?","The spectral theorem can be explicitly expressed for an hermitian matrix by providing its eigen decomposition. In the more general case of a bounded self-adjoint operator with a continuous spectrum, the expression of the spectral theorem is $Ax=\int \lambda dF(\lambda) x$. This expression is rather abstract. Can someone provide a simple example of the continuous case, taking $x$ from a space of function, a differential operator A, and the detailed expressions of $F(\lambda)$ and $dF(\lambda)$ ?",,"['functional-analysis', 'operator-theory']"
88,"The ""Circle"" is a Vector Space?","The ""Circle"" is a Vector Space?",,"Consider the set of angles $C = [0, \ 2\pi)$ and, for all $x,y \in C$, define the $sum$ operation as the sum modulo $[0, \ 2\pi)$. The identity element of the addition is the angle $0$. The inverse element exists. Associativity and Commutativity hold. I am not sure about the operation of $scalar \  multiplication$ $\cdot$. 1) Can I define the scalar multiplication (with identity element $1$) as $a \cdot x \ \text{mod } [0, \ 2\pi)$ for all $a \in \mathbb{R}$ and $x \in C$? If so, seems that $a ( b \cdot x)  = (a b) \cdot x $ for all $a,b \in \mathbb{R}$ and $x \in C$. Also seems that distributivity holds. 2) Is $(C,+,\cdot)$ a vector space then? 3) Is $(C,+,\cdot)$ metric for some distance function $d$?","Consider the set of angles $C = [0, \ 2\pi)$ and, for all $x,y \in C$, define the $sum$ operation as the sum modulo $[0, \ 2\pi)$. The identity element of the addition is the angle $0$. The inverse element exists. Associativity and Commutativity hold. I am not sure about the operation of $scalar \  multiplication$ $\cdot$. 1) Can I define the scalar multiplication (with identity element $1$) as $a \cdot x \ \text{mod } [0, \ 2\pi)$ for all $a \in \mathbb{R}$ and $x \in C$? If so, seems that $a ( b \cdot x)  = (a b) \cdot x $ for all $a,b \in \mathbb{R}$ and $x \in C$. Also seems that distributivity holds. 2) Is $(C,+,\cdot)$ a vector space then? 3) Is $(C,+,\cdot)$ metric for some distance function $d$?",,"['analysis', 'functional-analysis', 'vector-spaces', 'metric-spaces', 'circles']"
89,What exactly is a product measure?,What exactly is a product measure?,,"If we have $(X \times Y, \overline{\Sigma \times \tau}, \lambda)$ a complete measure space with underlying complete spaces $(X, \Sigma, \mu)$ and $(Y, \tau, \nu)$, and $\lambda = \mu \times \nu$, what exactly is a product measure? The reason I am asking this is that if we have a function $f \in L^{1}(d\lambda)$, then clearly $\int \limits_{X \times Y} |f| \,d\lambda < \infty$.  But we can say $f = f\chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} }$, where $\chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} }$ is the characteristic function of $ \{ (x,y) \mid f(x,y) \neq 0 \}$. Since the two functions are equal, we get that $\int \limits_{X \times Y} |f| \,d\lambda = \int \limits_{X \times Y} |f\chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} }| \,d\lambda = \int \limits_{X \times Y} |f| \,d( \chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} } \,d\lambda)$. This means that $f \in L^{1}(d( \chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} } \,d\lambda))$. But my professor said that the measure $\chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} } \,d\lambda$ is a $\sigma$-finite measure, but not necessarily a product measure .  What does that mean?  Why can we integrate with it over $X \times Y$ if it is not a product measure? Does it possibly mean that the measure is not necessarily defined on the product $\sigma$-algebra?  This measure is defined on the product $\sigma$-algebra, so that can't be it... Note that if $E \in \overline{\Sigma \times \tau}$, then the measure of $E$ with respect to $\chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} } \,d\lambda$ is defined to be $\int \limits_{E} \chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} } \,d\lambda$.","If we have $(X \times Y, \overline{\Sigma \times \tau}, \lambda)$ a complete measure space with underlying complete spaces $(X, \Sigma, \mu)$ and $(Y, \tau, \nu)$, and $\lambda = \mu \times \nu$, what exactly is a product measure? The reason I am asking this is that if we have a function $f \in L^{1}(d\lambda)$, then clearly $\int \limits_{X \times Y} |f| \,d\lambda < \infty$.  But we can say $f = f\chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} }$, where $\chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} }$ is the characteristic function of $ \{ (x,y) \mid f(x,y) \neq 0 \}$. Since the two functions are equal, we get that $\int \limits_{X \times Y} |f| \,d\lambda = \int \limits_{X \times Y} |f\chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} }| \,d\lambda = \int \limits_{X \times Y} |f| \,d( \chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} } \,d\lambda)$. This means that $f \in L^{1}(d( \chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} } \,d\lambda))$. But my professor said that the measure $\chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} } \,d\lambda$ is a $\sigma$-finite measure, but not necessarily a product measure .  What does that mean?  Why can we integrate with it over $X \times Y$ if it is not a product measure? Does it possibly mean that the measure is not necessarily defined on the product $\sigma$-algebra?  This measure is defined on the product $\sigma$-algebra, so that can't be it... Note that if $E \in \overline{\Sigma \times \tau}$, then the measure of $E$ with respect to $\chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} } \,d\lambda$ is defined to be $\int \limits_{E} \chi_{ \{ (x,y) \mid f(x,y) \neq 0 \} } \,d\lambda$.",,"['real-analysis', 'functional-analysis', 'measure-theory']"
90,Proof that $(L^1)\neq(L^\infty)^\ast$,Proof that,(L^1)\neq(L^\infty)^\ast,"I have seen a ""proof"" that  $L^1\neq(L^\infty)^\ast$ which goes as follows: show that there is an element of $(L^\infty)^\ast$ which is not in the image of the canonical map $L^1\rightarrow(L^\infty)^\ast$. From this they conclude that $(L^1)\neq(L^\infty)^\ast$, how does this follow? I mean simply because the canonical map is not an isomorphism it does not follow that they are not isomorphic (isometrically), isn't it? We must somehow distinguish them by properties (reflexive, separable etc) isn't it?","I have seen a ""proof"" that  $L^1\neq(L^\infty)^\ast$ which goes as follows: show that there is an element of $(L^\infty)^\ast$ which is not in the image of the canonical map $L^1\rightarrow(L^\infty)^\ast$. From this they conclude that $(L^1)\neq(L^\infty)^\ast$, how does this follow? I mean simply because the canonical map is not an isomorphism it does not follow that they are not isomorphic (isometrically), isn't it? We must somehow distinguish them by properties (reflexive, separable etc) isn't it?",,"['real-analysis', 'functional-analysis', 'measure-theory', 'banach-spaces', 'lp-spaces']"
91,"Compact operators, injectivity and closed range","Compact operators, injectivity and closed range",,"Let $X$ be a an infinite dimensional Banach space. $A\in B(X)$ is a compact operator. If its range $\operatorname{Im}(A)$ is closed in $X$ then $A$ cannot be injective because $A:X\to \operatorname{Im}(A)$ would be a compact bijection between Banach spaces and the unit ball $B_X=A^{-1}AB_X$ would be compact. Now if $A$ is not injective, can we say that $\operatorname{Im}(A)$ must be closed ? Or if this is false, can we find a non injective compact operator with non closed range (i.e. infinite dimensional range) ?","Let $X$ be a an infinite dimensional Banach space. $A\in B(X)$ is a compact operator. If its range $\operatorname{Im}(A)$ is closed in $X$ then $A$ cannot be injective because $A:X\to \operatorname{Im}(A)$ would be a compact bijection between Banach spaces and the unit ball $B_X=A^{-1}AB_X$ would be compact. Now if $A$ is not injective, can we say that $\operatorname{Im}(A)$ must be closed ? Or if this is false, can we find a non injective compact operator with non closed range (i.e. infinite dimensional range) ?",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
92,Which is the relationship between weak convergence and pointwise convergence?,Which is the relationship between weak convergence and pointwise convergence?,,In one of my indipendent works at functional analysis course have to come up with an explicit way of telling which is the relationshpip between weak and pointwise convergence for $C(K)$ where $K$ is a compact Hausdorff space. I searched some articles but didn't find anything which is enough helpfull. The theory behind is kind of complicated and I don't think I have the necessary background to understand it. Can somebody guide me to get to the right point? Till now I have been working with Eberlein-Smulian theorem and weak compactness.,In one of my indipendent works at functional analysis course have to come up with an explicit way of telling which is the relationshpip between weak and pointwise convergence for $C(K)$ where $K$ is a compact Hausdorff space. I searched some articles but didn't find anything which is enough helpfull. The theory behind is kind of complicated and I don't think I have the necessary background to understand it. Can somebody guide me to get to the right point? Till now I have been working with Eberlein-Smulian theorem and weak compactness.,,"['functional-analysis', 'banach-spaces']"
93,"A linear operator between $C[0,1]$ and $C[0,1]$ defined as $Tf = f + \int f$; Show $T$ is an isomorphism",A linear operator between  and  defined as ; Show  is an isomorphism,"C[0,1] C[0,1] Tf = f + \int f T","Define a linear operator $T:C[0,1] \to C[0,1]$ as follows: $$Tf(x) = f(x) + \int_0^x f(u)du$$ It is easy to show that $T$ is a bounded linear operator. The statement also (1) claims that $T$ is one-to-one and onto, and (2) asks to compute $T^{-1}$. (Hence $T$ is an isomorphism due to a corollary of Open Mapping Theorem) I need help to prove $T$ is onto: given any $g \in C[0,1]$, how to decompose it into a sum between a continuous $f$ and its antiderivative. I have trouble decomposing $g(x)=|x|$, not to mention bizarre functions like Weierstrass function. It seems impossible. Thanks in advance for help!","Define a linear operator $T:C[0,1] \to C[0,1]$ as follows: $$Tf(x) = f(x) + \int_0^x f(u)du$$ It is easy to show that $T$ is a bounded linear operator. The statement also (1) claims that $T$ is one-to-one and onto, and (2) asks to compute $T^{-1}$. (Hence $T$ is an isomorphism due to a corollary of Open Mapping Theorem) I need help to prove $T$ is onto: given any $g \in C[0,1]$, how to decompose it into a sum between a continuous $f$ and its antiderivative. I have trouble decomposing $g(x)=|x|$, not to mention bizarre functions like Weierstrass function. It seems impossible. Thanks in advance for help!",,"['real-analysis', 'functional-analysis', 'continuity']"
94,Phillips spectral theorem,Phillips spectral theorem,,"In Reed-Simon (see References) the following theorem due to Phillips is cited (but not proved): Theorem (Phillips). Let $X$ be a Banach space, $T \in \mathcal L(X)$. Then $\sigma(T) = \sigma(T')$ and $R_\lambda(T') = R_\lambda(T)'$. If $\mathcal H$ is in a Hilbert space, then $\sigma(T^*) = \{ \lambda : \bar\lambda \in \sigma(T) \}$ and $R_\lambda(T^*) = R_\lambda(T)^*$. Now, the Hilbert space part is quite easy (is a standard result in many books) while the Banach space one looks more difficult. Considering that $\rho(T) = \{ \lambda : T_\lambda := T - \lambda I \, \mbox{is an isomorphism} \}$ and $\sigma(T) := \mathbb C \setminus \rho(T)$, the first claim seems true if was true that Claim (?). $T$ isomorphism $\implies T'$ isomorphism. I don't think this statement holds (maybe I'm wrong, but it doesn't sound familiar). Indeed, it is true that Proposition. $T$ isometric isomorphism $\iff T'$ isometric isomorphism. The proof of this proposition is not completely trivial (although is not too hard) and can be found, for example, in Costara-Popa. The property ""$T$ isometry"" is essential to get $T'$ isometry and hence injective, so it can't be weakened keeping the same argument for the remainder. On the other hand, from definition of $T'$, I don't see other ways to go. Does anyone know the proof of the Phillips theorem or can provide a reference? And can anyone prove or disprove the claim? Notation. $T'$ is the dual operator of $T$ (in the sense of Banach spaces), $T^*$ is the adjoint of $T$ (in the sense of Hilbert spaces), $\sigma(T)$ spectrum of $T$, $\rho(T)$ is the resolvent set and $R_\lambda(T)$ is the resolvent of $T$. References Reed-Simon, Methods of modern mathematical physics, Functional analysis , Thm VI.7; Costara-Popa, Exercises in Functional Analysis , Chp. 2, Ex. 28.","In Reed-Simon (see References) the following theorem due to Phillips is cited (but not proved): Theorem (Phillips). Let $X$ be a Banach space, $T \in \mathcal L(X)$. Then $\sigma(T) = \sigma(T')$ and $R_\lambda(T') = R_\lambda(T)'$. If $\mathcal H$ is in a Hilbert space, then $\sigma(T^*) = \{ \lambda : \bar\lambda \in \sigma(T) \}$ and $R_\lambda(T^*) = R_\lambda(T)^*$. Now, the Hilbert space part is quite easy (is a standard result in many books) while the Banach space one looks more difficult. Considering that $\rho(T) = \{ \lambda : T_\lambda := T - \lambda I \, \mbox{is an isomorphism} \}$ and $\sigma(T) := \mathbb C \setminus \rho(T)$, the first claim seems true if was true that Claim (?). $T$ isomorphism $\implies T'$ isomorphism. I don't think this statement holds (maybe I'm wrong, but it doesn't sound familiar). Indeed, it is true that Proposition. $T$ isometric isomorphism $\iff T'$ isometric isomorphism. The proof of this proposition is not completely trivial (although is not too hard) and can be found, for example, in Costara-Popa. The property ""$T$ isometry"" is essential to get $T'$ isometry and hence injective, so it can't be weakened keeping the same argument for the remainder. On the other hand, from definition of $T'$, I don't see other ways to go. Does anyone know the proof of the Phillips theorem or can provide a reference? And can anyone prove or disprove the claim? Notation. $T'$ is the dual operator of $T$ (in the sense of Banach spaces), $T^*$ is the adjoint of $T$ (in the sense of Hilbert spaces), $\sigma(T)$ spectrum of $T$, $\rho(T)$ is the resolvent set and $R_\lambda(T)$ is the resolvent of $T$. References Reed-Simon, Methods of modern mathematical physics, Functional analysis , Thm VI.7; Costara-Popa, Exercises in Functional Analysis , Chp. 2, Ex. 28.",,"['functional-analysis', 'operator-theory']"
95,What is a good definition of Hilbert space?,What is a good definition of Hilbert space?,,"Motivation of my question: in my opinion, in view of the common definition , the statement ""$\ell_p$ is a Hilbert space if and only if $p=2$"" makes no sense because there is no inner product in the common definition of the $\ell_p$ space. So, my question is: Is a Hilbert space (i) ""an inner product space that is complete with respect to the norm induced by the inner product"" or (ii) ""a complete space with respect to a norm induced by some inner product""? Notice that (i) is the common definition and (ii) is a definition for which the mentioned statement makes sense. Thanks.","Motivation of my question: in my opinion, in view of the common definition , the statement ""$\ell_p$ is a Hilbert space if and only if $p=2$"" makes no sense because there is no inner product in the common definition of the $\ell_p$ space. So, my question is: Is a Hilbert space (i) ""an inner product space that is complete with respect to the norm induced by the inner product"" or (ii) ""a complete space with respect to a norm induced by some inner product""? Notice that (i) is the common definition and (ii) is a definition for which the mentioned statement makes sense. Thanks.",,"['functional-analysis', 'soft-question', 'hilbert-spaces', 'definition']"
96,Invertibility of Laplace operator for smooth functions,Invertibility of Laplace operator for smooth functions,,"Is the Laplacian $\triangle:C^\infty(\Omega) \to C^\infty(\Omega)$, $\Omega\subseteq \mathbb{R}^n$, invertible? I have read Invertibility of laplacian operator which talks about thinking of the Laplacian as an operator on distributions. I do not know much about distributions, so I am looking for an answer which sticks to honest functions. I know that (if $\overline{\Omega}$ is compact) for harmonic functions $u_1,u_2$ which agree on $\partial \Omega$ we must have $u_1=u_2$. (Folland PDE, 2.15) So let us assume $\Omega$ satisfies that condition. Now if $\triangle u = \triangle v$ then $\triangle(u-v)=0$. But we can't say $u=v$ because we don't know they agree on the boundary. Indeed, adding a constant to $u$ preserves all the other equalities so we are dead if we don't make another assumption. Let us assume then that we have a fixed boundary condition $u = f$ on $\partial \Omega$. Then we definitely have $u=v$. What about surjectivity? If I prescribe a $w \in C^\infty$, is there a $u$ satisfying the boundary condition such that $\triangle u = w$?","Is the Laplacian $\triangle:C^\infty(\Omega) \to C^\infty(\Omega)$, $\Omega\subseteq \mathbb{R}^n$, invertible? I have read Invertibility of laplacian operator which talks about thinking of the Laplacian as an operator on distributions. I do not know much about distributions, so I am looking for an answer which sticks to honest functions. I know that (if $\overline{\Omega}$ is compact) for harmonic functions $u_1,u_2$ which agree on $\partial \Omega$ we must have $u_1=u_2$. (Folland PDE, 2.15) So let us assume $\Omega$ satisfies that condition. Now if $\triangle u = \triangle v$ then $\triangle(u-v)=0$. But we can't say $u=v$ because we don't know they agree on the boundary. Indeed, adding a constant to $u$ preserves all the other equalities so we are dead if we don't make another assumption. Let us assume then that we have a fixed boundary condition $u = f$ on $\partial \Omega$. Then we definitely have $u=v$. What about surjectivity? If I prescribe a $w \in C^\infty$, is there a $u$ satisfying the boundary condition such that $\triangle u = w$?",,"['functional-analysis', 'partial-differential-equations']"
97,The Banach-Mazur distance is not reached,The Banach-Mazur distance is not reached,,"Let $X,Y$ be isomorphic Banach spaces. The Banach-Mazur distance: $$ d(X,Y)=\inf\{\|T\| \cdot \|T^{-1}\|: T:X\longrightarrow Y \ \text{is an isomorphism} \}$$ can be rewritten as: $$ d(X,Y)=\inf\{\|T^{-1}\|: T:X\longrightarrow Y \ \text{is an isomorphism}, \|T\|=1\} $$ If $X,Y$ are finite dimensional spaces the infimum is reached. But if $X,Y$ are infinite dimensional spaces the infimum is reached ? Any hints would be appreciated.","Let $X,Y$ be isomorphic Banach spaces. The Banach-Mazur distance: $$ d(X,Y)=\inf\{\|T\| \cdot \|T^{-1}\|: T:X\longrightarrow Y \ \text{is an isomorphism} \}$$ can be rewritten as: $$ d(X,Y)=\inf\{\|T^{-1}\|: T:X\longrightarrow Y \ \text{is an isomorphism}, \|T\|=1\} $$ If $X,Y$ are finite dimensional spaces the infimum is reached. But if $X,Y$ are infinite dimensional spaces the infimum is reached ? Any hints would be appreciated.",,"['functional-analysis', 'banach-spaces']"
98,Is this operator bounded? Hilbert space projection,Is this operator bounded? Hilbert space projection,,"Let $V \subset H$ be Hilbert spaces (different inner products) with $V$ dense in $H$. Let $b_n$ be an orthonormal basis for $H$ and an orthogonal basis for $V$. Define $$P_n:H \to \text{span}(b_1,...,b_n)$$ by $$P_n h = \sum_{i=1}^n (h,b_j)_Hb_j$$ by truncation. Is it true that $$P_n:V \to V$$ is bounded? How do I show that? If not, what assumptions does one need? Thanks.","Let $V \subset H$ be Hilbert spaces (different inner products) with $V$ dense in $H$. Let $b_n$ be an orthonormal basis for $H$ and an orthogonal basis for $V$. Define $$P_n:H \to \text{span}(b_1,...,b_n)$$ by $$P_n h = \sum_{i=1}^n (h,b_j)_Hb_j$$ by truncation. Is it true that $$P_n:V \to V$$ is bounded? How do I show that? If not, what assumptions does one need? Thanks.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
99,Does there exist such a closed subspace of normed linear space,Does there exist such a closed subspace of normed linear space,,"let $(X,|| || )$ be a norm linear space. And $M$ be a closed subspace of norm linear space .does there exist a closed subspace $N$ such that $X=M \oplus N $ . I know such an subspace $N$ exist .but i am not conform about such an $N$ is closed or not .","let $(X,|| || )$ be a norm linear space. And $M$ be a closed subspace of norm linear space .does there exist a closed subspace $N$ such that $X=M \oplus N $ . I know such an subspace $N$ exist .but i am not conform about such an $N$ is closed or not .",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
