,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Can we evaluate the integral $ I(a)=\int_0^{\infty} \frac{\sin x}{x^a} e^{-x} d x, $ without Gamma functions?",Can we evaluate the integral  without Gamma functions?," I(a)=\int_0^{\infty} \frac{\sin x}{x^a} e^{-x} d x, ","Encountering the integral in the post stating that $$ \int_{0}^{\infty} \frac{e^{-x} \sin(x)}{x}\,dx=\frac\pi4, $$ I started to investigate the integral in a more general form as $$ I(a)=\int_0^{\infty} \frac{\sin x}{x^a} e^{-x} d x, $$ where $1<a<2$ . Using the Euler’s identity: $e^{xi}=\cos x+i\sin x$ , we have $$ \begin{aligned} I(a) & = \Im \int_0^{\infty} \frac{e^{xi} \cdot e^{-x}}{x^a} d x \\ & = \Im\int_0^{\infty} \frac{e^{-(1-i) x}}{x^a} d x \\ & = \Im \int_0^{\infty} x^{-a} e^{-(1-i) x} d x \\ & =\Im\left[\frac{\Gamma(1-a)}{(1-i)^{1-a}}\right] \end{aligned} $$ By expressing the denominator in polar form, we have $$ \frac{1}{(1-i)^{1-a}}=\left(\sqrt{2} e^{-\frac{\pi}{4} i}\right)^{a-1} =2^{\frac{a-1}{2}} e^{\frac{(1-a) \pi}{4}i}  $$ Now we can conclude that $$ \boxed{I(a)=2^{\frac{a-1}{2}} \Gamma(1-a) \sin \frac{(1-a) \pi}{4}} $$ For example, $$ I\left(\frac{3}{2}\right) =2^{\frac{1}{4}} (-2 \sqrt{\pi})\left(-\sin \frac{\pi}{8}\right) =2\sqrt[4]{2}\cdot\frac{\sqrt{(2-\sqrt{2} )\pi}}{2}=\sqrt{2(\sqrt{2}-1)\pi} $$ Do we have any other methods to evaluate the integral? Your comments and alternative methods are highly appreciated.","Encountering the integral in the post stating that I started to investigate the integral in a more general form as where . Using the Euler’s identity: , we have By expressing the denominator in polar form, we have Now we can conclude that For example, Do we have any other methods to evaluate the integral? Your comments and alternative methods are highly appreciated.","
\int_{0}^{\infty} \frac{e^{-x} \sin(x)}{x}\,dx=\frac\pi4,
 
I(a)=\int_0^{\infty} \frac{\sin x}{x^a} e^{-x} d x,
 1<a<2 e^{xi}=\cos x+i\sin x 
\begin{aligned}
I(a) & = \Im \int_0^{\infty} \frac{e^{xi} \cdot e^{-x}}{x^a} d x \\
& = \Im\int_0^{\infty} \frac{e^{-(1-i) x}}{x^a} d x \\
& = \Im \int_0^{\infty} x^{-a} e^{-(1-i) x} d x \\
& =\Im\left[\frac{\Gamma(1-a)}{(1-i)^{1-a}}\right]
\end{aligned}
 
\frac{1}{(1-i)^{1-a}}=\left(\sqrt{2} e^{-\frac{\pi}{4} i}\right)^{a-1} =2^{\frac{a-1}{2}} e^{\frac{(1-a) \pi}{4}i} 
 
\boxed{I(a)=2^{\frac{a-1}{2}} \Gamma(1-a) \sin \frac{(1-a) \pi}{4}}
 
I\left(\frac{3}{2}\right) =2^{\frac{1}{4}} (-2 \sqrt{\pi})\left(-\sin \frac{\pi}{8}\right) =2\sqrt[4]{2}\cdot\frac{\sqrt{(2-\sqrt{2} )\pi}}{2}=\sqrt{2(\sqrt{2}-1)\pi}
","['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'gamma-function']"
1,Integral $\int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx$,Integral,\int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx,"$$I=\int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx$$ $$I=2\int_{0}^{1}\frac{\ln\left(x\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx$$ Substituting $x\to\frac{1}{x}$ : $$I=-2\int_{1}^{\infty}\frac{\ln\left(x\right)}{\left(x^{2}+1\right)\left(\pi^{2}+\ln^{2}x\right)}dx$$ This would imply: $$\int_{0}^{\infty}\frac{\ln\left(x\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx=0$$ After searching the Integral on Approach0, I found various sources where an Incorrect Value is given: $$\int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx=\ln2-\frac{1}{2}$$ This is wrong, as can be checked numerically. But a user on AoPS gave the following Correction ( AoPS ) with the Solution as Well: $$\int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1\color{red}{-}x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx=\frac{1}{2}-\ln2$$ Trying out the Solution Step by Step, I was able to get till here: $$I=-2\int_{0}^{\infty}e^{-\pi u}\sum_{n=0}^{\infty}\left(\left(-1\right)^{n}\frac{u}{u^{2}+\left(2n+1\right)^{2}}\right)du$$ Now the problem is that factor of $(-1)^n$ which is not present in the corrected problem, without it the sum evaluates to: $$\sum_{n=0}^{\infty}\left(\frac{u}{u^{2}+\left(2n+1\right)^{2}}\right)=\frac{\pi}{4}\tanh\left(\frac{\pi u}{2}\right)$$ But I am not sure how to evaluate it with the $(-1)^n$ factor. Wolfram only gives a Partial Sum Formula in terms of Lerch Transcendent. In the Post Here ( AoPS ), the Integral has a Series form as follows: $$I=-\frac{4}{\pi}\sum_{m=0}^{\infty}\left(\frac{\left(-1\right)^{m}\left(2m+1\right)}{\left(2m+1\right)^{2}-4}\ln\left(m+\frac{1}{2}\right)\right)$$ Another Post where the Wrong Integral Equality is given: Problem #67 I also think I saw this Integral before on MSE, but I am not able to find it.","Substituting : This would imply: After searching the Integral on Approach0, I found various sources where an Incorrect Value is given: This is wrong, as can be checked numerically. But a user on AoPS gave the following Correction ( AoPS ) with the Solution as Well: Trying out the Solution Step by Step, I was able to get till here: Now the problem is that factor of which is not present in the corrected problem, without it the sum evaluates to: But I am not sure how to evaluate it with the factor. Wolfram only gives a Partial Sum Formula in terms of Lerch Transcendent. In the Post Here ( AoPS ), the Integral has a Series form as follows: Another Post where the Wrong Integral Equality is given: Problem #67 I also think I saw this Integral before on MSE, but I am not able to find it.",I=\int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx I=2\int_{0}^{1}\frac{\ln\left(x\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx x\to\frac{1}{x} I=-2\int_{1}^{\infty}\frac{\ln\left(x\right)}{\left(x^{2}+1\right)\left(\pi^{2}+\ln^{2}x\right)}dx \int_{0}^{\infty}\frac{\ln\left(x\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx=0 \int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1+x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx=\ln2-\frac{1}{2} \int_{0}^{1}\frac{\ln\left(x^2\right)}{\left(1\color{red}{-}x^{2}\right)\left(\pi^{2}+\ln^{2}x\right)}dx=\frac{1}{2}-\ln2 I=-2\int_{0}^{\infty}e^{-\pi u}\sum_{n=0}^{\infty}\left(\left(-1\right)^{n}\frac{u}{u^{2}+\left(2n+1\right)^{2}}\right)du (-1)^n \sum_{n=0}^{\infty}\left(\frac{u}{u^{2}+\left(2n+1\right)^{2}}\right)=\frac{\pi}{4}\tanh\left(\frac{\pi u}{2}\right) (-1)^n I=-\frac{4}{\pi}\sum_{m=0}^{\infty}\left(\frac{\left(-1\right)^{m}\left(2m+1\right)}{\left(2m+1\right)^{2}-4}\ln\left(m+\frac{1}{2}\right)\right),"['calculus', 'integration', 'definite-integrals']"
2,Evaluating $\int \sqrt{\frac{x^2+1}{x^2(1-x^2)}}dx$,Evaluating,\int \sqrt{\frac{x^2+1}{x^2(1-x^2)}}dx,"Today I came across the following integral $$\int \sqrt{\frac{x^2+1}{x^2(1-x^2)}}dx$$ Here's my work: $$\begin{align}\int \sqrt{\frac{x^2+1}{x^2(1-x^2)}}dx& = \int\frac{1}{x} \sqrt{\frac{1+x^2}{1-x^2}}\ dx \\ & =  -\int \sqrt{\frac{1+\cos(2\theta)}{1 - \cos(2\theta)}} \tan(2\theta) \ d\theta\tag{$*$}\\& = -\int \sqrt{\frac{2\cos^2(\theta)}{2\sin^2(\theta)}}\cdot \frac{\sin(2\theta)}{\cos(2\theta)} \ d\theta\\& = - \int\frac{\cos(\theta)}{\sin(\theta)}\cdot \frac{2\sin(\theta)\cos(\theta)}{\cos^2\theta - \sin^2\theta}\ d\theta\\& = - \int \frac{(\cos^2\theta + \sin^2\theta) + (\cos^2\theta - \sin^2\theta)}{\cos^2\theta - \sin^2\theta}\ d\theta\\& = - \int \sec(2\theta) + 1 \ d\theta\tag{1}\\& =-\frac{1}2 \ln|\sec(2\theta) + \tan(2\theta)| + \theta + C\tag{2}\\& = - \frac{1}{2} \ln\left|\sec(\cos^{-1}(x^2)) + \tan(\cos^{-1}(x^2))\right|  + \frac12 \cos^{-1}(x^2) + C\\& = - \frac12\ln\left|\frac1{x^2} + \frac{\sqrt{1 - x^4}}{x^2}\right| + \frac12 \cos^{-1}(x^2) + C\\& = - \frac12\ln\left|\frac{1 + \sqrt{1 - x^4}}{x^2}\right| + \frac12 \cos^{-1}(x^2) + C\end{align}$$ $(*)$ Here I've made a substitution $x^2 = \cos(2\theta)$ so that $\dfrac{dx}{x} = - \tan(2\theta)\ d\theta$ . But this answer seems to be wrong! I differentiated my answer but didn't get the original integrand. Wolframalpha results this expression and I'm not sure about it. I'm just unable to figure out what's actually wrong with my method. Edit: With Bob Dobbs's comment, I got that I did wrong moving from step $(1)$ to step $(2)$ .","Today I came across the following integral Here's my work: Here I've made a substitution so that . But this answer seems to be wrong! I differentiated my answer but didn't get the original integrand. Wolframalpha results this expression and I'm not sure about it. I'm just unable to figure out what's actually wrong with my method. Edit: With Bob Dobbs's comment, I got that I did wrong moving from step to step .",\int \sqrt{\frac{x^2+1}{x^2(1-x^2)}}dx \begin{align}\int \sqrt{\frac{x^2+1}{x^2(1-x^2)}}dx& = \int\frac{1}{x} \sqrt{\frac{1+x^2}{1-x^2}}\ dx \\ & =  -\int \sqrt{\frac{1+\cos(2\theta)}{1 - \cos(2\theta)}} \tan(2\theta) \ d\theta\tag{*}\\& = -\int \sqrt{\frac{2\cos^2(\theta)}{2\sin^2(\theta)}}\cdot \frac{\sin(2\theta)}{\cos(2\theta)} \ d\theta\\& = - \int\frac{\cos(\theta)}{\sin(\theta)}\cdot \frac{2\sin(\theta)\cos(\theta)}{\cos^2\theta - \sin^2\theta}\ d\theta\\& = - \int \frac{(\cos^2\theta + \sin^2\theta) + (\cos^2\theta - \sin^2\theta)}{\cos^2\theta - \sin^2\theta}\ d\theta\\& = - \int \sec(2\theta) + 1 \ d\theta\tag{1}\\& =-\frac{1}2 \ln|\sec(2\theta) + \tan(2\theta)| + \theta + C\tag{2}\\& = - \frac{1}{2} \ln\left|\sec(\cos^{-1}(x^2)) + \tan(\cos^{-1}(x^2))\right|  + \frac12 \cos^{-1}(x^2) + C\\& = - \frac12\ln\left|\frac1{x^2} + \frac{\sqrt{1 - x^4}}{x^2}\right| + \frac12 \cos^{-1}(x^2) + C\\& = - \frac12\ln\left|\frac{1 + \sqrt{1 - x^4}}{x^2}\right| + \frac12 \cos^{-1}(x^2) + C\end{align} (*) x^2 = \cos(2\theta) \dfrac{dx}{x} = - \tan(2\theta)\ d\theta (1) (2),"['calculus', 'integration', 'indefinite-integrals']"
3,How do I integrate $\int_0^{\infty} \frac{\log(t+1)}{t^2+a^2} \mathrm{d}t$?,How do I integrate ?,\int_0^{\infty} \frac{\log(t+1)}{t^2+a^2} \mathrm{d}t,"How do I integrate the following integral: $$\int_0^{\infty} \frac{\log(t+1)}{t^2+a^2} \mathrm{d}t$$ Where $a$ is some parameter? I know that the solution includes Lerch Transcendents and logs (which is what I'm trying to arrive at); however, I've tried integrating this function, but failed. I've already tried using simplifying it using series, which yielded a bunch of integrals as follows: $$-\sum_{k \geq 1} \frac{(-1)^k}{k} \int_0^1 \frac{t^k} {t^2+a^2} \mathrm{d}t - \frac{1}{a^2} \sum_{k \geq 1} \frac{(-1)^k}{k} \int_0^1 \frac{t^k} {t^2+\frac{1}{a^2}} \mathrm{d}t + \frac{1}{a^2} \sum_{k \geq 1} \frac{(-1)^k}{k} \int_0^1 \frac{\log(t)} {t^2+\frac{1}{a^2}} \mathrm{d}t$$ However, I don't know how I'd proceed forwards from here.","How do I integrate the following integral: Where is some parameter? I know that the solution includes Lerch Transcendents and logs (which is what I'm trying to arrive at); however, I've tried integrating this function, but failed. I've already tried using simplifying it using series, which yielded a bunch of integrals as follows: However, I don't know how I'd proceed forwards from here.",\int_0^{\infty} \frac{\log(t+1)}{t^2+a^2} \mathrm{d}t a -\sum_{k \geq 1} \frac{(-1)^k}{k} \int_0^1 \frac{t^k} {t^2+a^2} \mathrm{d}t - \frac{1}{a^2} \sum_{k \geq 1} \frac{(-1)^k}{k} \int_0^1 \frac{t^k} {t^2+\frac{1}{a^2}} \mathrm{d}t + \frac{1}{a^2} \sum_{k \geq 1} \frac{(-1)^k}{k} \int_0^1 \frac{\log(t)} {t^2+\frac{1}{a^2}} \mathrm{d}t,"['calculus', 'integration', 'logarithms']"
4,"A contour integration approach for $\int_{0}^{\infty} \frac{\ln \left(x^{4}+2 x^{2} \cos 2 a+1\right)}{1+x^{2}} \, d x$",A contour integration approach for,"\int_{0}^{\infty} \frac{\ln \left(x^{4}+2 x^{2} \cos 2 a+1\right)}{1+x^{2}} \, d x","Background In this week, I am tackling the integral $$\int_{0}^{\infty} \frac{\ln \left(1-x+x^{2}\right)}{1+x^{2}} d x$$ and found that a general formula below in my post , $$ \begin{aligned} J(a)= \int_{0}^{\infty} \frac{\ln \left(1+2 x \sin a+x^{2}\right)}{1+x^{2}} d x=& \pi\left(\ln \left(2 \cos \frac{a}{2}\right)\right)+|a| \ln \left(\tan \frac{|a|}{2}\right)-2 \operatorname{sgn} (a) \int_{0}^{\frac{|a|}{2}} \ln (\tan x) d x \end{aligned} $$ by which, I found a decent formula for the quartic one, $$ \boxed{I(a)=\int_{0}^{\infty} \frac{\ln \left(x^{4}+2 x^{2} \cos 2 a+1\right)}{1+x^{2}} d x=2 \pi \ln \left(2 \cos \frac{a}{2}\right)} $$ Proof: $$ \begin{aligned} I(a)&=\int_{0}^{\infty} \frac{\ln \left(x^{4}+2 x^{2} \cos 2 a+1\right)}{1+x^{2}} d x\\ &=\int_{0}^{\infty} \frac{\ln \left[\left(x^{2}+1\right)^{2}+2 x^{2}(\cos 2 a-1)+1\right]}{1+x^{2}} d x\\ &=\int_{0}^{\infty} \frac{\ln \left[\left(x^{2}+1\right)^{2}-4 x^{2} \sin ^{2} a\right]}{1+x^{2}} d x\\ &=\int_{0}^{\infty} \frac{\ln \left(x^{2}+2 x \sin a+1\right)}{1+x^{2}}+\int_{0}^{\infty} \frac{\ln \left(x^{2}-2 x \sin a+1\right)}{1+x^{2}} d x\\& =J\left(\frac{a}{2}\right)+J\left(-\frac{a}{2}\right)\\& =2 \pi \ln \left(2 \cos \frac{a}{2}\right) \end{aligned} $$ For examples: $$ K=\int_{0}^{\infty} \frac{\ln \left(x^{4}+1\right)}{1+x^{2}} d x= I\left(\frac{\pi}{4}\right)=2 \pi \ln \left(2 \cos \frac{\pi}{8}\right)= \pi \ln (2+\sqrt{2}) $$ $$ \begin{aligned} L=\int_{0}^{\infty} \frac{\ln \left(x^{4}+x^{2}+1\right)}{1+x^{2}} d x&=I\left(\frac{\pi}{6}\right)=2 \pi \ln \left(2 \cos \frac{\pi}{12}\right)=\pi\ln (2+\sqrt{3}) \end{aligned} $$ $$ \begin{aligned} M=\int_{0}^{\infty} \frac{\ln \left(x^{4}-x^{2}+1\right)}{1+x^{2}} d x&=I\left(\frac{\pi}{3}\right)=2 \pi \ln \left(2 \cos \frac{\pi}{6}\right)=\pi\ln 3 \end{aligned} $$ $$ \begin{aligned} N=&\int_{0}^{\infty} \frac{\ln \left(x^{8}+x^{4}+1\right)}{1+x^{2}} dx = L+M=\pi \ln (6+3 \sqrt{3}) \end{aligned} $$ Last but not least, $$ \boxed{\int_{0}^{\infty} \frac{\ln \left(x^{4}+b x^{2}+1\right)}{1+x^{2}} d x = 2 \pi \ln \left[2 \cos \left(\frac{1}{4} \cos ^{-1}\left(\frac{b}{2}\right)\right)\right]} $$ $$ \begin{aligned} \int_{0}^{\infty} \frac{\ln \left(x^{8}+1\right)}{1+x^{2}}=& \int_{0}^{\infty} \frac{\ln \left(x^{4}+\sqrt{2} x+1\right)}{1+x^{2}} d x +\int_{0}^{\infty} \frac{\ln \left(x^{4}-\sqrt{2} x+1\right)}{1+x^{2}} d x \\ =& 2 \pi \ln \left[2 \cos \frac{1}{4} \cos ^{-1}\left(\frac{\sqrt{2}}{2}\right)\right] +2 \pi \ln \left[2 \cos \frac{1}{4} \cos ^{-1}\left(-\frac{\sqrt{2}}{2}\right)\right] \\ =& 2 \pi \ln \left(2 \cos \frac{\pi}{16}\right)+2 \pi \ln \left(2 \cos \frac{3 \pi}{16}\right)\\ =& 2 \pi \ln \left(2^2 \cos \frac{\pi}{16} \cos \frac{3 \pi}{16}\right)\\=& 2 \pi \ln (\sqrt{2}+\sqrt{2+\sqrt{2}}) \end{aligned} $$ Eager to know whether it can be proved by contour integration. Your help and solutions are highly appreciated!","Background In this week, I am tackling the integral and found that a general formula below in my post , by which, I found a decent formula for the quartic one, Proof: For examples: Last but not least, Eager to know whether it can be proved by contour integration. Your help and solutions are highly appreciated!","\int_{0}^{\infty} \frac{\ln \left(1-x+x^{2}\right)}{1+x^{2}} d x 
\begin{aligned}
J(a)= \int_{0}^{\infty} \frac{\ln \left(1+2 x \sin a+x^{2}\right)}{1+x^{2}} d x=& \pi\left(\ln \left(2 \cos \frac{a}{2}\right)\right)+|a| \ln \left(\tan \frac{|a|}{2}\right)-2 \operatorname{sgn} (a) \int_{0}^{\frac{|a|}{2}} \ln (\tan x) d x
\end{aligned}
 
\boxed{I(a)=\int_{0}^{\infty} \frac{\ln \left(x^{4}+2 x^{2} \cos 2 a+1\right)}{1+x^{2}} d x=2 \pi \ln \left(2 \cos \frac{a}{2}\right)}
 
\begin{aligned}
I(a)&=\int_{0}^{\infty} \frac{\ln \left(x^{4}+2 x^{2} \cos 2 a+1\right)}{1+x^{2}} d x\\
&=\int_{0}^{\infty} \frac{\ln \left[\left(x^{2}+1\right)^{2}+2 x^{2}(\cos 2 a-1)+1\right]}{1+x^{2}} d x\\
&=\int_{0}^{\infty} \frac{\ln \left[\left(x^{2}+1\right)^{2}-4 x^{2} \sin ^{2} a\right]}{1+x^{2}} d x\\
&=\int_{0}^{\infty} \frac{\ln \left(x^{2}+2 x \sin a+1\right)}{1+x^{2}}+\int_{0}^{\infty} \frac{\ln \left(x^{2}-2 x \sin a+1\right)}{1+x^{2}} d x\\& =J\left(\frac{a}{2}\right)+J\left(-\frac{a}{2}\right)\\& =2 \pi \ln \left(2 \cos \frac{a}{2}\right)
\end{aligned}
 
K=\int_{0}^{\infty} \frac{\ln \left(x^{4}+1\right)}{1+x^{2}} d x= I\left(\frac{\pi}{4}\right)=2 \pi \ln \left(2 \cos \frac{\pi}{8}\right)= \pi \ln (2+\sqrt{2})
 
\begin{aligned}
L=\int_{0}^{\infty} \frac{\ln \left(x^{4}+x^{2}+1\right)}{1+x^{2}} d x&=I\left(\frac{\pi}{6}\right)=2 \pi \ln \left(2 \cos \frac{\pi}{12}\right)=\pi\ln (2+\sqrt{3})
\end{aligned}
 
\begin{aligned}
M=\int_{0}^{\infty} \frac{\ln \left(x^{4}-x^{2}+1\right)}{1+x^{2}} d x&=I\left(\frac{\pi}{3}\right)=2 \pi \ln \left(2 \cos \frac{\pi}{6}\right)=\pi\ln 3
\end{aligned}
 
\begin{aligned}
N=&\int_{0}^{\infty} \frac{\ln \left(x^{8}+x^{4}+1\right)}{1+x^{2}} dx = L+M=\pi \ln (6+3 \sqrt{3})
\end{aligned}
 
\boxed{\int_{0}^{\infty} \frac{\ln \left(x^{4}+b x^{2}+1\right)}{1+x^{2}} d x = 2 \pi \ln \left[2 \cos \left(\frac{1}{4} \cos ^{-1}\left(\frac{b}{2}\right)\right)\right]}
 
\begin{aligned}
\int_{0}^{\infty} \frac{\ln \left(x^{8}+1\right)}{1+x^{2}}=& \int_{0}^{\infty} \frac{\ln \left(x^{4}+\sqrt{2} x+1\right)}{1+x^{2}} d x +\int_{0}^{\infty} \frac{\ln \left(x^{4}-\sqrt{2} x+1\right)}{1+x^{2}} d x \\
=& 2 \pi \ln \left[2 \cos \frac{1}{4} \cos ^{-1}\left(\frac{\sqrt{2}}{2}\right)\right] +2 \pi \ln \left[2 \cos \frac{1}{4} \cos ^{-1}\left(-\frac{\sqrt{2}}{2}\right)\right] \\
=& 2 \pi \ln \left(2 \cos \frac{\pi}{16}\right)+2 \pi \ln \left(2 \cos \frac{3 \pi}{16}\right)\\
=& 2 \pi \ln \left(2^2 \cos \frac{\pi}{16} \cos \frac{3 \pi}{16}\right)\\=& 2 \pi \ln (\sqrt{2}+\sqrt{2+\sqrt{2}})
\end{aligned}
","['calculus', 'integration', 'improper-integrals', 'complex-integration', 'trigonometric-integrals']"
5,How to find the integral of $\frac{(1+x\ln(x)) (1+\ln(x))}{x^2 \ln(x) (1+\ln(x))+1}$,How to find the integral of,\frac{(1+x\ln(x)) (1+\ln(x))}{x^2 \ln(x) (1+\ln(x))+1},"$$\int \frac{\ln{\left( \mathrm{e}\,x^{x+1} \right)} + \left[ \ln{ \left( x^{\sqrt{x}} \right) } \right]^2 }{1 + x\ln{ \left( x \right) } \ln{ \left( \mathrm{e}^x\,x^x \right) }}dx=f(x)+C $$ where $f(1)=0$ , then $e^{e^{f(2)}-1}$ is equal to? $\displaystyle \begin{align*} \frac{\ln{\left( \mathrm{e}\,x^{x+1} \right)} + \left[ \ln{ \left( x^{\sqrt{x}} \right) } \right]^2 }{1 + x\ln{ \left( x \right) } \ln{ \left( \mathrm{e}^x\,x^x \right) }} &= \frac{ \ln{\left( \mathrm{e} \right) } + \ln{ \left( x^{x+1} \right) } + \left[ \sqrt{x} \, \ln{ \left( x \right) } \right] ^2 }{ 1 + x\ln{ \left( x \right) } \left[ \ln{\left( \mathrm{e}^x \right) } + \ln{ \left( x^x \right) } \right] } \\ &= \frac{ 1 + \left( x + 1 \right) \ln{ \left( x \right) } + x \, \left[ \ln{ \left( x \right) } \right] ^2 }{ 1 + x \ln{ \left( x \right) } \left[ x + x\ln{ \left( x \right) } \right] } \end{align*}$ , but could not solve it further.","where , then is equal to? , but could not solve it further.","\int \frac{\ln{\left( \mathrm{e}\,x^{x+1} \right)} + \left[ \ln{ \left( x^{\sqrt{x}} \right) } \right]^2 }{1 + x\ln{ \left( x \right) } \ln{ \left( \mathrm{e}^x\,x^x \right) }}dx=f(x)+C  f(1)=0 e^{e^{f(2)}-1} \displaystyle \begin{align*} \frac{\ln{\left( \mathrm{e}\,x^{x+1} \right)} + \left[ \ln{ \left( x^{\sqrt{x}} \right) } \right]^2 }{1 + x\ln{ \left( x \right) } \ln{ \left( \mathrm{e}^x\,x^x \right) }} &= \frac{ \ln{\left( \mathrm{e} \right) } + \ln{ \left( x^{x+1} \right) } + \left[ \sqrt{x} \, \ln{ \left( x \right) } \right] ^2 }{ 1 + x\ln{ \left( x \right) } \left[ \ln{\left( \mathrm{e}^x \right) } + \ln{ \left( x^x \right) } \right] } \\ &= \frac{ 1 + \left( x + 1 \right) \ln{ \left( x \right) } + x \, \left[ \ln{ \left( x \right) } \right] ^2 }{ 1 + x \ln{ \left( x \right) } \left[ x + x\ln{ \left( x \right) } \right] } \end{align*}","['calculus', 'integration', 'indefinite-integrals']"
6,"Find $\int_{0}^{\infty} \frac{\sin x}{x+x\cos^2 x }\,\mathrm{d}x$",Find,"\int_{0}^{\infty} \frac{\sin x}{x+x\cos^2 x }\,\mathrm{d}x","I have just done these, but I don't know what to do next...... \begin{align} \int \frac{\sin x}{x+x\cos^2 x}\,\mathrm{d}x & = \int \frac{1}{x}\cdot\frac{\sin  x}{1+\cos^2 x}\,\mathrm{d}x\\ &=\int \frac{1}{x}\,\mathrm{d}(\arctan(-\cos x))\\\ &=\frac{1}{x} \arctan(-\cos x)-\int -\frac{1}{x^2} \arctan(-\cos x)\,\mathrm{d}x \\ &=\frac{1}{x} \arctan(-\cos x)-\int \frac{\arctan(\cos x)}{x^2}\,\mathrm{d}x \end{align}","I have just done these, but I don't know what to do next......","\begin{align}
\int \frac{\sin x}{x+x\cos^2 x}\,\mathrm{d}x & = \int \frac{1}{x}\cdot\frac{\sin  x}{1+\cos^2 x}\,\mathrm{d}x\\
&=\int \frac{1}{x}\,\mathrm{d}(\arctan(-\cos x))\\\
&=\frac{1}{x} \arctan(-\cos x)-\int -\frac{1}{x^2} \arctan(-\cos x)\,\mathrm{d}x \\
&=\frac{1}{x} \arctan(-\cos x)-\int \frac{\arctan(\cos x)}{x^2}\,\mathrm{d}x
\end{align}","['calculus', 'integration', 'definite-integrals']"
7,How do I imagine why divergence of curl and curl of gradient is $0$?,How do I imagine why divergence of curl and curl of gradient is ?,0,"I tried watching several videos on YouTube, but I failed to gain intuition. I tried to solve it by myself by imagining water flow but I was unsuccessful and got stuck. How do I imagine why divergence of curl and curl of gradient is $0$ ?","I tried watching several videos on YouTube, but I failed to gain intuition. I tried to solve it by myself by imagining water flow but I was unsuccessful and got stuck. How do I imagine why divergence of curl and curl of gradient is ?",0,"['derivatives', 'vector-fields', 'calculus']"
8,Solve integral $\int^1_0 \frac{1-x^2}{{(1+x^2)}\sqrt{1+x^4}}dx$ using subsituition $\sqrt{1+x^4} = {(1+x^2)}\cos{\theta}$,Solve integral  using subsituition,\int^1_0 \frac{1-x^2}{{(1+x^2)}\sqrt{1+x^4}}dx \sqrt{1+x^4} = {(1+x^2)}\cos{\theta},"Hi this question has been posed in my integration book where it has been asked to solve it using the given substitution or any other substitution, I've found identical question posted here {1} with different substitutions The problem is when using the given substitution I end up with integral $$\int^{\pi/4}_0 \frac{\sin{\theta}}{2x}d\theta $$ Solving for $x$ : $\sqrt{1+x^4} = {(1+x^2)}\cos{\theta}$ According to WolframAlpha: $$x = \frac{|\csc{\theta}||1 \pm \sqrt{\cos{2\theta}}|}{\sqrt{2}} $$ I do know the sign for x is $+ve$ so I'll take $+ve$ solutions after opening the modulus, I do not know which sign to prefer in $ \pm \sqrt{\cos{2\theta}} $ term Eitherway, I solved for both cases : $$  \frac{1}{\sqrt{2}}\int^{\pi/4}_0\frac{\sin^2{\theta}}{1 + \sqrt{\cos{2\theta}}} d\theta -(I) $$ $$  \frac{1}{\sqrt{2}}\int^{\pi/4}_0\frac{\sin^2{\theta}}{1 - \sqrt{\cos{2\theta}}} d\theta -(II) $$ Which leads to : $$  \frac{1}{\sqrt{2}}\int^{\pi/4}_0 1 \pm \sqrt{\cos{2\theta}} d\theta = \frac{\pi}{4\sqrt{2}} \pm\frac{\Gamma(\frac{3}{4})^2}{2\sqrt{2}} $$ Here I cheated and used WolframAlpha as I was exhausted. Both the cases lead to a similar answer with difference of a function unknown to me: $\pm\frac{\Gamma(\frac{3}{4})^2}{2\sqrt{2}}$ The correct answer is : $$\frac{\pi}{4\sqrt{2}}$$ My main questions are: What am I doing wrong? How did author arrive at this ingenious  substitution $\sqrt{1+x^4} = {(1+x^2)}\cos{\theta}$ , this doesn't appear to me trial n' error kind of substitution , I have spent hours doing algebraic transformation on this and no matter how you procced and plug the variable your integrand will only have one of these terms only $2x$ , $1-x^2$ , $1+x^2$ and $ \sqrt{1+x^4}$ and $2x$ being the simplest. Related question: How do I integrate the following? $\int{\frac{(1+x^{2})\mathrm dx}{(1-x^{2})\sqrt{1+x^{4}}}}$","Hi this question has been posed in my integration book where it has been asked to solve it using the given substitution or any other substitution, I've found identical question posted here {1} with different substitutions The problem is when using the given substitution I end up with integral Solving for : According to WolframAlpha: I do know the sign for x is so I'll take solutions after opening the modulus, I do not know which sign to prefer in term Eitherway, I solved for both cases : Which leads to : Here I cheated and used WolframAlpha as I was exhausted. Both the cases lead to a similar answer with difference of a function unknown to me: The correct answer is : My main questions are: What am I doing wrong? How did author arrive at this ingenious  substitution , this doesn't appear to me trial n' error kind of substitution , I have spent hours doing algebraic transformation on this and no matter how you procced and plug the variable your integrand will only have one of these terms only , , and and being the simplest. Related question: How do I integrate the following?","\int^{\pi/4}_0 \frac{\sin{\theta}}{2x}d\theta  x \sqrt{1+x^4} = {(1+x^2)}\cos{\theta} x = \frac{|\csc{\theta}||1 \pm \sqrt{\cos{2\theta}}|}{\sqrt{2}}  +ve +ve  \pm \sqrt{\cos{2\theta}}    \frac{1}{\sqrt{2}}\int^{\pi/4}_0\frac{\sin^2{\theta}}{1 + \sqrt{\cos{2\theta}}} d\theta -(I)    \frac{1}{\sqrt{2}}\int^{\pi/4}_0\frac{\sin^2{\theta}}{1 - \sqrt{\cos{2\theta}}} d\theta -(II)    \frac{1}{\sqrt{2}}\int^{\pi/4}_0 1 \pm \sqrt{\cos{2\theta}} d\theta = \frac{\pi}{4\sqrt{2}}
\pm\frac{\Gamma(\frac{3}{4})^2}{2\sqrt{2}}  \pm\frac{\Gamma(\frac{3}{4})^2}{2\sqrt{2}} \frac{\pi}{4\sqrt{2}} \sqrt{1+x^4} = {(1+x^2)}\cos{\theta} 2x 1-x^2 1+x^2  \sqrt{1+x^4} 2x \int{\frac{(1+x^{2})\mathrm dx}{(1-x^{2})\sqrt{1+x^{4}}}}","['calculus', 'integration', 'definite-integrals']"
9,Find $f(x)$ such that: $ f'(x) + f(x^2) = 2x + 1 $,Find  such that:,f(x)  f'(x) + f(x^2) = 2x + 1 ,"How to find the function $f(x)$ that is derivable on $\mathbb{R}$ and satisfies the equation: $$ f'(x) + f(x^2) = 2x + 1 \text{ } \text{ } \forall x \in \mathbb{R}$$ My attempt: Substitute $-x$ for $x$ in the equation, we have a system of 2 equations : \begin{cases}  f'(x) + f(x^2) &= 2x + 1\\  f'(-x) + f(x^2) &= -2x + 1 \end{cases} Take the difference of them, we have: $$ f'(x) - f'(-x) =4x $$ Integrate both sides: $$ f(x) + f(x) = 2x^2 + C_1 $$ Therefore, we have: $$ f(x) = x^2 + C_2 $$ However, this method results in an invalid solution to the original equation. I wonder whether there is another way to solve this problem or why my solution is wrong. Thanks in advance.","How to find the function that is derivable on and satisfies the equation: My attempt: Substitute for in the equation, we have a system of 2 equations : Take the difference of them, we have: Integrate both sides: Therefore, we have: However, this method results in an invalid solution to the original equation. I wonder whether there is another way to solve this problem or why my solution is wrong. Thanks in advance.","f(x) \mathbb{R}  f'(x) + f(x^2) = 2x + 1 \text{ } \text{ } \forall x \in \mathbb{R} -x x \begin{cases} 
f'(x) + f(x^2) &= 2x + 1\\ 
f'(-x) + f(x^2) &= -2x + 1
\end{cases}  f'(x) - f'(-x) =4x   f(x) + f(x) = 2x^2 + C_1   f(x) = x^2 + C_2 ","['calculus', 'integration', 'ordinary-differential-equations']"
10,"Analogies between $(\tan, \sec)$ and $(\sinh, \cosh)$",Analogies between  and,"(\tan, \sec) (\sinh, \cosh)","The pair of functions $(\tan, \sec)$ shares some interesting properties with the pair $(\sinh, \cosh)$. First of all, they satisfy the same quadratic equation, namely $$\sec^2 x - \tan^2 x = 1 \qquad \cosh^2 x - \sinh^2 x = 1$$ for any $x$ in the respective domains. Moreover, $\tan$ and $\sinh$ are both odd functions, while $\sec$ and $\cosh$ are both even functions. Now, suppose that we define a binary operation $\oplus$ on some subset of real numbers such that $$\tan (x \oplus y) = \tan x \sec y + \sec x \tan y$$ whenever $x \oplus y$ is defined. Then one can prove that $$\sec(x \oplus y) = \sec x \sec y + \tan x \tan y$$ and these two formulas look exactly like the addition formulas for the hyperbolic functions. (For the subtraction formulas it is enough to let $x \ominus y = x \oplus (-y)$ whenever it is defined.) There's more: one can also prove that an analogue to De Moivre's formula holds, i.e., $$(\sec x + \tan x)^n = \sec (\mathring n x) + \tan (\mathring n x)$$ where $\mathring n x$ denotes $x \oplus x \oplus \dotsb \oplus x$ with $n$ addends. Finally, if we define an analogue of the derivative with this new operation by letting $$\mathring D f(x) = \lim_{h \to 0} \frac {f(x \oplus h) - f(x)} h$$ then we obtain $$\mathring D \tan x = \sec x \qquad \mathring D \sec x = \tan x$$ similarly to what happens with the hyperbolic functions. My questions are: Is there a way to make this correspondence precise so that one can give a simple unique explanation for all of these analogies (and possibly others that might hold)? How can we interpret the operation $\oplus$?","The pair of functions $(\tan, \sec)$ shares some interesting properties with the pair $(\sinh, \cosh)$. First of all, they satisfy the same quadratic equation, namely $$\sec^2 x - \tan^2 x = 1 \qquad \cosh^2 x - \sinh^2 x = 1$$ for any $x$ in the respective domains. Moreover, $\tan$ and $\sinh$ are both odd functions, while $\sec$ and $\cosh$ are both even functions. Now, suppose that we define a binary operation $\oplus$ on some subset of real numbers such that $$\tan (x \oplus y) = \tan x \sec y + \sec x \tan y$$ whenever $x \oplus y$ is defined. Then one can prove that $$\sec(x \oplus y) = \sec x \sec y + \tan x \tan y$$ and these two formulas look exactly like the addition formulas for the hyperbolic functions. (For the subtraction formulas it is enough to let $x \ominus y = x \oplus (-y)$ whenever it is defined.) There's more: one can also prove that an analogue to De Moivre's formula holds, i.e., $$(\sec x + \tan x)^n = \sec (\mathring n x) + \tan (\mathring n x)$$ where $\mathring n x$ denotes $x \oplus x \oplus \dotsb \oplus x$ with $n$ addends. Finally, if we define an analogue of the derivative with this new operation by letting $$\mathring D f(x) = \lim_{h \to 0} \frac {f(x \oplus h) - f(x)} h$$ then we obtain $$\mathring D \tan x = \sec x \qquad \mathring D \sec x = \tan x$$ similarly to what happens with the hyperbolic functions. My questions are: Is there a way to make this correspondence precise so that one can give a simple unique explanation for all of these analogies (and possibly others that might hold)? How can we interpret the operation $\oplus$?",,"['calculus', 'trigonometry', 'hyperbolic-functions']"
11,Fourier transform of sigmoid function,Fourier transform of sigmoid function,,"I am wondering if there exists a closed form formula for the Fourier transform of the sigmoid function $f(x) = \frac{e^{x}}{(1 + e^{x}}$. More specifically I would need to calculate $F(w) = \int_{-\infty}^{\infty}(f(x)  e^{-iwx} dx)$. This can be expressed as   $F(w) = \int_{-\infty}^{\infty}(\frac{e^{x(1 - iw)}}{(1 + e^{x})}dx$. How would I go from here, or would there be a better way of finding the Fourier transform of the Sigmoid function? I have tried obtaining a result using the in-built $fourier$ matlab function, it did however not find a solution.","I am wondering if there exists a closed form formula for the Fourier transform of the sigmoid function $f(x) = \frac{e^{x}}{(1 + e^{x}}$. More specifically I would need to calculate $F(w) = \int_{-\infty}^{\infty}(f(x)  e^{-iwx} dx)$. This can be expressed as   $F(w) = \int_{-\infty}^{\infty}(\frac{e^{x(1 - iw)}}{(1 + e^{x})}dx$. How would I go from here, or would there be a better way of finding the Fourier transform of the Sigmoid function? I have tried obtaining a result using the in-built $fourier$ matlab function, it did however not find a solution.",,"['calculus', 'fourier-analysis', 'fourier-transform']"
12,Solving higher order logarithms integrals without the beta function,Solving higher order logarithms integrals without the beta function,,"Prove the following $$\int^1_0 \frac{\log(x)^3}{\sqrt{x(1-x)}}dx= -\pi (12 \zeta(3) +  \log^3(4) + \pi^2 \log(4))$$ The basic approach is differentiating the beta function three times which I am trying to avoid here.A contour method would be nice. Question 1 Hence how to solve the integral without having to differentiate the beta function ? My question can be generalized to any problem involving higher order logarithms. Question 2 Is there a general formula for $$\frac{\partial^n \partial^m}{\partial x^n \partial y^m} B(x,y)$$","Prove the following $$\int^1_0 \frac{\log(x)^3}{\sqrt{x(1-x)}}dx= -\pi (12 \zeta(3) +  \log^3(4) + \pi^2 \log(4))$$ The basic approach is differentiating the beta function three times which I am trying to avoid here.A contour method would be nice. Question 1 Hence how to solve the integral without having to differentiate the beta function ? My question can be generalized to any problem involving higher order logarithms. Question 2 Is there a general formula for $$\frac{\partial^n \partial^m}{\partial x^n \partial y^m} B(x,y)$$",,"['calculus', 'integration', 'definite-integrals', 'special-functions']"
13,Is there a set of axioms governing the properties of derivatives in calculus that include this particular axiom and what would it be?,Is there a set of axioms governing the properties of derivatives in calculus that include this particular axiom and what would it be?,,"Moved from Math Overflow due to not being regarded as a high degree of research Note: I am looking in particular at real valued/real input functions at all values regardless of differentiability. In this question a series of axioms or postulates governing calculus are proposed. Granted, that is abstract calculus rather than real number calculus. Is there any known way to write a similar set of postulates governing real number calculus involving derivatives, integrals, and (ideally) allowing the construction of differential equations but with the following statement selected as one of the axioms without redundancy or contradiction? ""if and only if a function is constant does it have a derivative of 0 for all real numbers"" My ultimate purpose is to negate the aforementioned axiom and so having a complete set of axioms would make it convenient for me to convey the actual meaning behind negating the statement since one can ultimately fall back upon the statements similar to how we developed non-Euclidean geometry. Some potential axioms that might be relevant that I thought of were: ""All elements of a derivation set are the inverse of the antiderivative where defined"" (might be better proposed as a conjecture) The derivation set of any function may not equal the empty set. Update: After discussing this with a few others more deeply, and noticing some non-uniqueness properties and things I've realized that the derivative need not be unique given the sort of things I would want to exist. Therefore, the following definitions deal with that issue: A derivation set is a set of a functions that can potentially result from differentiation being applied to some function. A derivative is an operator whose results from being applied to some function is some element of the derivation set for that function. In this sense altered forms of derivatives would be solutions sets of functions that satisfy some equation rather than necessarily a unique operator. However, the equation itself is probably not something trivially apparent by my guess or something one could derive in a quick manner.","Moved from Math Overflow due to not being regarded as a high degree of research Note: I am looking in particular at real valued/real input functions at all values regardless of differentiability. In this question a series of axioms or postulates governing calculus are proposed. Granted, that is abstract calculus rather than real number calculus. Is there any known way to write a similar set of postulates governing real number calculus involving derivatives, integrals, and (ideally) allowing the construction of differential equations but with the following statement selected as one of the axioms without redundancy or contradiction? ""if and only if a function is constant does it have a derivative of 0 for all real numbers"" My ultimate purpose is to negate the aforementioned axiom and so having a complete set of axioms would make it convenient for me to convey the actual meaning behind negating the statement since one can ultimately fall back upon the statements similar to how we developed non-Euclidean geometry. Some potential axioms that might be relevant that I thought of were: ""All elements of a derivation set are the inverse of the antiderivative where defined"" (might be better proposed as a conjecture) The derivation set of any function may not equal the empty set. Update: After discussing this with a few others more deeply, and noticing some non-uniqueness properties and things I've realized that the derivative need not be unique given the sort of things I would want to exist. Therefore, the following definitions deal with that issue: A derivation set is a set of a functions that can potentially result from differentiation being applied to some function. A derivative is an operator whose results from being applied to some function is some element of the derivation set for that function. In this sense altered forms of derivatives would be solutions sets of functions that satisfy some equation rather than necessarily a unique operator. However, the equation itself is probably not something trivially apparent by my guess or something one could derive in a quick manner.",,"['calculus', 'derivatives', 'axioms', 'research']"
14,Chain rule proof - Apostol,Chain rule proof - Apostol,,"Apostol calculus I page 174-175 has the proof of chain rule. Theorem states: Let f be the composition of two functions u and v, say $f=u \circ v$. Suppose that both derivatives $v'(x)$ and $u'(y)$ exist, where $y=v(x)$. Then derivative $f'(x)$ also exists and is given by the formula $f'(x)=u'(y).v'(x)$. Proof: The difference quotient for f is (4.12): $\frac{f(x+h)-f(x)}{h}=\frac{u[v(x+h)]-u[v(x)]}{h}$ . Let $y=v(x)$ and let $k=v(x+h)-v(x)$. Then we have $v(x+h)=y+k$ and (4.12) becomes (4.13): $\frac{f(x+h)-f(x)}{h}=\frac{u(y+k)-u(y)}{h}$ . If $k\neq0$,then we multiply and divide by k and obtain (4.14): $\frac{u(y+k)-u(y)}{h}\frac{k}{k}=\frac{u(y+k)-u(y)}{k}\frac{v(x+h)-v(x)}{h}$. When h goes to 0, last quotient on right becomes $v'(x)$. Also, as $h$ goes to $0$, $k$ also goes to $0$ because $k=v(x+h)-v(x)$ and $v$ is continuous at $x$. Therefore the first quotient on the right approaches $u'(y)$ as $h$ tends to zero and this proves the result. $\square$ Although the foregoing argument seems to be the most natural way to proceed, it is not completely general. Since $k=v(x+h)-v(x)$, it may happen that $k=0$ for infinitely many values of $h$ as $h$ tends to zero in which case the passage from (4.13) to (4.14) is not valid. My doubt:  I have trouble understanding the line ""it may happen that $k=0$ for infinitely many values of $h$ as $h$ tends to zero"" What is this line trying to convey and why is the proof incorrect? Thanks in advance.","Apostol calculus I page 174-175 has the proof of chain rule. Theorem states: Let f be the composition of two functions u and v, say $f=u \circ v$. Suppose that both derivatives $v'(x)$ and $u'(y)$ exist, where $y=v(x)$. Then derivative $f'(x)$ also exists and is given by the formula $f'(x)=u'(y).v'(x)$. Proof: The difference quotient for f is (4.12): $\frac{f(x+h)-f(x)}{h}=\frac{u[v(x+h)]-u[v(x)]}{h}$ . Let $y=v(x)$ and let $k=v(x+h)-v(x)$. Then we have $v(x+h)=y+k$ and (4.12) becomes (4.13): $\frac{f(x+h)-f(x)}{h}=\frac{u(y+k)-u(y)}{h}$ . If $k\neq0$,then we multiply and divide by k and obtain (4.14): $\frac{u(y+k)-u(y)}{h}\frac{k}{k}=\frac{u(y+k)-u(y)}{k}\frac{v(x+h)-v(x)}{h}$. When h goes to 0, last quotient on right becomes $v'(x)$. Also, as $h$ goes to $0$, $k$ also goes to $0$ because $k=v(x+h)-v(x)$ and $v$ is continuous at $x$. Therefore the first quotient on the right approaches $u'(y)$ as $h$ tends to zero and this proves the result. $\square$ Although the foregoing argument seems to be the most natural way to proceed, it is not completely general. Since $k=v(x+h)-v(x)$, it may happen that $k=0$ for infinitely many values of $h$ as $h$ tends to zero in which case the passage from (4.13) to (4.14) is not valid. My doubt:  I have trouble understanding the line ""it may happen that $k=0$ for infinitely many values of $h$ as $h$ tends to zero"" What is this line trying to convey and why is the proof incorrect? Thanks in advance.",,"['calculus', 'chain-rule']"
15,Determining from its graph whether a vector field is conservative,Determining from its graph whether a vector field is conservative,,"Given the graph of a vector field, how can I tell whether it is conservative or non-conservative?","Given the graph of a vector field, how can I tell whether it is conservative or non-conservative?",,"['calculus', 'multivariable-calculus', 'vector-fields']"
16,How to bound $\int_{0}^{a}{\frac{1-\cos x}{x^2}}$?,How to bound ?,\int_{0}^{a}{\frac{1-\cos x}{x^2}},"I was trying to prove $$\left|\int_{0}^{a}{\frac{1-\cos{x}}{x^2}}dx-\frac{\pi}{2}\right|\leq \frac{3}{a}$$ or $\leq \frac{2}{a}$. My work: I would like to use Fubini's theorem to prove it. I notice that $\frac{1}{x^2}=\int^{\infty}_{0}{ue^{-xu}}du$. Then, I got $\int_{0}^{a}{\frac{1-\cos{x}}{x^2}}dx=\int_{0}^{\infty}u\int_{0}^{a}{(1-\cos{x})e^{-xu}}dxdu$. Then, I got $\int_{0}^{a}{(1-\cos{x})e^{-xu}}dx=-e^{-au}u+\frac{1}{u+u^3}+e^{-au}\frac{u^2\cos{a}-u\sin{a}}{u+u^3}$. Then, $\int_{0}^{a}{\frac{1-\cos{x}}{x^2}}dx=\int_0^{\infty}u(\frac{e^{au}-1}{u}+\frac{u-e^{au}(u\cos{a}+\sin{a})}{1+u^2})du\\=\int_0^{\infty}({e^{au}+\frac{-ue^{au}(u\cos{a}+\sin{a}-2)}{1+u^2}})du+\frac{\pi}{2}.$ I was trying to show $|\int_0^{\infty}({e^{au}+\frac{-ue^{au}(u\cos{a}+\sin{a}-2)}{1+u^2}})du|\leq\frac{3}{a}$ or $\frac{2}{a}$. But I do not have a clue. Can some give me hints?","I was trying to prove $$\left|\int_{0}^{a}{\frac{1-\cos{x}}{x^2}}dx-\frac{\pi}{2}\right|\leq \frac{3}{a}$$ or $\leq \frac{2}{a}$. My work: I would like to use Fubini's theorem to prove it. I notice that $\frac{1}{x^2}=\int^{\infty}_{0}{ue^{-xu}}du$. Then, I got $\int_{0}^{a}{\frac{1-\cos{x}}{x^2}}dx=\int_{0}^{\infty}u\int_{0}^{a}{(1-\cos{x})e^{-xu}}dxdu$. Then, I got $\int_{0}^{a}{(1-\cos{x})e^{-xu}}dx=-e^{-au}u+\frac{1}{u+u^3}+e^{-au}\frac{u^2\cos{a}-u\sin{a}}{u+u^3}$. Then, $\int_{0}^{a}{\frac{1-\cos{x}}{x^2}}dx=\int_0^{\infty}u(\frac{e^{au}-1}{u}+\frac{u-e^{au}(u\cos{a}+\sin{a})}{1+u^2})du\\=\int_0^{\infty}({e^{au}+\frac{-ue^{au}(u\cos{a}+\sin{a}-2)}{1+u^2}})du+\frac{\pi}{2}.$ I was trying to show $|\int_0^{\infty}({e^{au}+\frac{-ue^{au}(u\cos{a}+\sin{a}-2)}{1+u^2}})du|\leq\frac{3}{a}$ or $\frac{2}{a}$. But I do not have a clue. Can some give me hints?",,"['calculus', 'inequality']"
17,"If $ I = \int_{0}^{1}x^{1004}\cdot (1-x)^{1004}dx$ and $J=\int_{0}^{1}x^{1004}\cdot \left(1-x^{2010}\right)^{1004}dx\;,$ Then $I/J$",If  and  Then," I = \int_{0}^{1}x^{1004}\cdot (1-x)^{1004}dx J=\int_{0}^{1}x^{1004}\cdot \left(1-x^{2010}\right)^{1004}dx\;, I/J","If $\displaystyle I = \int_{0}^{1}x^{1004}\cdot (1-x)^{1004}dx$ and $\displaystyle J=\int_{0}^{1}x^{1004}\cdot \left(1-x^{2010}\right)^{1004}dx\;,$ Then Relation between $I$ and $J.$ $\bf{My\; Try::}$ Given $$\displaystyle J = \int_{0}^{1}x^{1004}\cdot (1-x^{2010})^{1004}dx\;,$$ Now Put $\displaystyle x^{1005}=t\;,$ Then $1005x^{1004}dx = dt$ And Changing Limit, We get $$\displaystyle J=\frac{1}{1005}\int_{0}^{1}(1-t^2)^{1004}dt = \frac{1}{1005}\int_{0}^{1}\left[1-(1-t)^2\right]^{1004}dt$$ So we get $$\displaystyle J=\frac{1}{1005}\int_{0}^{1}t^{1004}\cdot (2-t)^{1004}dt$$ Now How can I solve after that , Help me Thanks","If and Then Relation between and Given Now Put Then And Changing Limit, We get So we get Now How can I solve after that , Help me Thanks","\displaystyle I = \int_{0}^{1}x^{1004}\cdot (1-x)^{1004}dx \displaystyle J=\int_{0}^{1}x^{1004}\cdot \left(1-x^{2010}\right)^{1004}dx\;, I J. \bf{My\; Try::} \displaystyle J = \int_{0}^{1}x^{1004}\cdot (1-x^{2010})^{1004}dx\;, \displaystyle x^{1005}=t\;, 1005x^{1004}dx = dt \displaystyle J=\frac{1}{1005}\int_{0}^{1}(1-t^2)^{1004}dt = \frac{1}{1005}\int_{0}^{1}\left[1-(1-t)^2\right]^{1004}dt \displaystyle J=\frac{1}{1005}\int_{0}^{1}t^{1004}\cdot (2-t)^{1004}dt",['calculus']
18,Finding the $1000$-th decimal of $\sqrt{1111...111}$,Finding the -th decimal of,1000 \sqrt{1111...111},"As I was cleaning up my desk, I found my Calculus exam from almost a year ago. I remember there was only a bonus task that required either a tad more wit, either a bit more time. It goes like this : $$ \text{Find the 1000-th  decimal of }\underbrace{\sqrt{1111...111}}_{1998 \text{ times}} . $$ I remember noticing $11 = \frac{10^2-1}{9}$, building up a general case upon this observation and representing it via series using the  binomial theorem, but nothing actually led me to the actual answer. Any ideas ?","As I was cleaning up my desk, I found my Calculus exam from almost a year ago. I remember there was only a bonus task that required either a tad more wit, either a bit more time. It goes like this : $$ \text{Find the 1000-th  decimal of }\underbrace{\sqrt{1111...111}}_{1998 \text{ times}} . $$ I remember noticing $11 = \frac{10^2-1}{9}$, building up a general case upon this observation and representing it via series using the  binomial theorem, but nothing actually led me to the actual answer. Any ideas ?",,"['calculus', 'radicals', 'decimal-expansion']"
19,Intuition for gradient when you only have one variable?,Intuition for gradient when you only have one variable?,,"I am learning about gradient. I understand how gradient is a vector that represents the sum of the rates of change for each component variable of a function. I am able to follow the Khan Academy video showing the gradient of f(x,y). I am also able to imagine (if not visualize) what gradient would be if you had more variables. But what if you only have one variable? Like for the function $f(x) = x^2$ Do you just have a one dimensional vector? What would it look like in the case of $f(x) = x^2$?","I am learning about gradient. I understand how gradient is a vector that represents the sum of the rates of change for each component variable of a function. I am able to follow the Khan Academy video showing the gradient of f(x,y). I am also able to imagine (if not visualize) what gradient would be if you had more variables. But what if you only have one variable? Like for the function $f(x) = x^2$ Do you just have a one dimensional vector? What would it look like in the case of $f(x) = x^2$?",,['calculus']
20,A definite integral related to Ahmed's integral,A definite integral related to Ahmed's integral,,"Further work on a recent question which has just been answered leads me to make this conjecture: $$ \int_0^1 \frac{\tan^{-1}\left(\frac{1}{\sqrt{2 + x^2}}\right)} {(1 + x^2)\sqrt{2 + x^2}}\,du = \frac{\pi^2}{32}. $$ I haven't made any effort to prove it (and I wouldn't even know how to begin), but I'll explain the connection with the other problem (later, by editing this question), if anyone expresses an interest. Hasty update: I should have looked again at more of the references I looked at yesterday! Google Books shows pages 190 to 193 (your mileage may vary) of the book by Paul J. Nahin, Inside Interesting Integrals , in which this very integral occurs in the course of an evaluation of Ahmed's integral. (Indeed, with hindsight, I have to admit that the connection is ""obvious"", especially because it follows from an elementary trigonometric identity I already used yesterday.) What is the etiquette for a situation like this?  Should I simply delete this question, or should I explain the details of how this integral is related to Ahmed's integral, and to the other MathSE question I referred to? (Please excuse a blundering old newbie!)","Further work on a recent question which has just been answered leads me to make this conjecture: $$ \int_0^1 \frac{\tan^{-1}\left(\frac{1}{\sqrt{2 + x^2}}\right)} {(1 + x^2)\sqrt{2 + x^2}}\,du = \frac{\pi^2}{32}. $$ I haven't made any effort to prove it (and I wouldn't even know how to begin), but I'll explain the connection with the other problem (later, by editing this question), if anyone expresses an interest. Hasty update: I should have looked again at more of the references I looked at yesterday! Google Books shows pages 190 to 193 (your mileage may vary) of the book by Paul J. Nahin, Inside Interesting Integrals , in which this very integral occurs in the course of an evaluation of Ahmed's integral. (Indeed, with hindsight, I have to admit that the connection is ""obvious"", especially because it follows from an elementary trigonometric identity I already used yesterday.) What is the etiquette for a situation like this?  Should I simply delete this question, or should I explain the details of how this integral is related to Ahmed's integral, and to the other MathSE question I referred to? (Please excuse a blundering old newbie!)",,"['calculus', 'integration', 'definite-integrals']"
21,Closed form of $\int_{0}^{\eta}\cos nt\log\left(\frac{\cos(t/2)+\sqrt{\cos^2(t/2) -\cos^2(\eta/2)}}{\cos(\eta/2)}\right) dt$,Closed form of,\int_{0}^{\eta}\cos nt\log\left(\frac{\cos(t/2)+\sqrt{\cos^2(t/2) -\cos^2(\eta/2)}}{\cos(\eta/2)}\right) dt,"I am reading a paper (sorry, no e-copy) with a number of infinite series, in which each term of the series is an integral of a complicated transcendental function like the one in the title. There are no fewer than a dozen of these infinite sums of integrals in the paper. For instance, the authors define $$ I_1(\eta) = \sum_{n=2,3,4}^{\infty} \dfrac{n}{n^2-1} \int_{0}^{\eta} \cos nt \log \left( \dfrac{\cos(t/2) + \sqrt{\cos^2(t/2) - \cos^2(\eta/2)}}{\cos(\eta/2)}\right) dt $$  where $0 \leq \eta < \pi$. The authors then assert that $$ I_1(\eta) = \frac{\pi}{8} \left( (2\cos\eta -2) \log \sin \frac{\eta}{2}  + \frac{1}{2}\cos\eta -\frac{1}{2}\right) $$ without any proof or derivation (the results are simply listed in an Appendix). I confess I am stumped as to how the authors arrived at their results. Any advice or help would be greatly appreciated.","I am reading a paper (sorry, no e-copy) with a number of infinite series, in which each term of the series is an integral of a complicated transcendental function like the one in the title. There are no fewer than a dozen of these infinite sums of integrals in the paper. For instance, the authors define $$ I_1(\eta) = \sum_{n=2,3,4}^{\infty} \dfrac{n}{n^2-1} \int_{0}^{\eta} \cos nt \log \left( \dfrac{\cos(t/2) + \sqrt{\cos^2(t/2) - \cos^2(\eta/2)}}{\cos(\eta/2)}\right) dt $$  where $0 \leq \eta < \pi$. The authors then assert that $$ I_1(\eta) = \frac{\pi}{8} \left( (2\cos\eta -2) \log \sin \frac{\eta}{2}  + \frac{1}{2}\cos\eta -\frac{1}{2}\right) $$ without any proof or derivation (the results are simply listed in an Appendix). I confess I am stumped as to how the authors arrived at their results. Any advice or help would be greatly appreciated.",,"['calculus', 'integration', 'sequences-and-series', 'definite-integrals', 'closed-form']"
22,Finding $\frac{\mathrm d}{\mathrm dx} x!$,Finding,\frac{\mathrm d}{\mathrm dx} x!,"I'm trying to differentiate $x!$ but I just can't seem to do it right. I define the function as follows: $$x! = \prod_{r = 0}^{x}(x-r) \quad,\quad x \in \mathbb N$$ I've tried attempted to try it by the first principle, but that was a dead end. The following is a more fruitful attempt although it provides no conclusive result: $$\frac{\mathrm d}{\mathrm dx} x! = \frac{\mathrm d}{\mathrm dx}x(x-1)!\\  = x\frac{\mathrm d}{\mathrm dx}(x-1)! + (x-1)!\\ = x( (x-1)\frac{\mathrm d}{\mathrm dx}(x-2)!  + (x-2)! ) + (x-1)!\\ = x((x-1)((x-2)\frac{\mathrm d}{\mathrm dx} (x-3)! + (x-3)!) + (x-2)!) + (x-1)!\\ = \dots$$ This pattern just goes on repeating, and I can't even find a good way to express the pattern. I tried opening the brackets and rearranging but even then I don't see any pattern which holds. Maybe there isn't a derivative? I don't know. Can you help me out? Edit : Thanks to @Belgi and others, I have realized that it is not possible to differentiate the factorial function by the definition I had given (silly me!) and now, I understand why the digamma function is required. But, as noted in the comments by @WarrenHill, the computational engine WolframAlpha says the following : $$\frac{\mathrm d}{\mathrm dx} (x!) = \Gamma(x+1)\Psi^{(0)}(x+1) $$ Please justify all aspects of this answer.","I'm trying to differentiate $x!$ but I just can't seem to do it right. I define the function as follows: $$x! = \prod_{r = 0}^{x}(x-r) \quad,\quad x \in \mathbb N$$ I've tried attempted to try it by the first principle, but that was a dead end. The following is a more fruitful attempt although it provides no conclusive result: $$\frac{\mathrm d}{\mathrm dx} x! = \frac{\mathrm d}{\mathrm dx}x(x-1)!\\  = x\frac{\mathrm d}{\mathrm dx}(x-1)! + (x-1)!\\ = x( (x-1)\frac{\mathrm d}{\mathrm dx}(x-2)!  + (x-2)! ) + (x-1)!\\ = x((x-1)((x-2)\frac{\mathrm d}{\mathrm dx} (x-3)! + (x-3)!) + (x-2)!) + (x-1)!\\ = \dots$$ This pattern just goes on repeating, and I can't even find a good way to express the pattern. I tried opening the brackets and rearranging but even then I don't see any pattern which holds. Maybe there isn't a derivative? I don't know. Can you help me out? Edit : Thanks to @Belgi and others, I have realized that it is not possible to differentiate the factorial function by the definition I had given (silly me!) and now, I understand why the digamma function is required. But, as noted in the comments by @WarrenHill, the computational engine WolframAlpha says the following : $$\frac{\mathrm d}{\mathrm dx} (x!) = \Gamma(x+1)\Psi^{(0)}(x+1) $$ Please justify all aspects of this answer.",,"['calculus', 'algebra-precalculus', 'derivatives', 'factorial', 'products']"
23,Is the sequence $x_{n+1} = \frac{x_n + \alpha}{x_n + 1}$ convergent?,Is the sequence  convergent?,x_{n+1} = \frac{x_n + \alpha}{x_n + 1},"Fix $\alpha > 1$, and consider the sequence $(x_n)_n \geq 0$ defined by $x_0 >  \sqrt \alpha$ and $$x_{n+1} = \frac{x_n + \alpha}{x_n + 1}, n = 0, 1, 2, \dots$$   Does this sequence converge, and if, to what? I tried to get the difference between $x_n$ and $x_{n+1}$, it didn't work out. How do I go about solving it?","Fix $\alpha > 1$, and consider the sequence $(x_n)_n \geq 0$ defined by $x_0 >  \sqrt \alpha$ and $$x_{n+1} = \frac{x_n + \alpha}{x_n + 1}, n = 0, 1, 2, \dots$$   Does this sequence converge, and if, to what? I tried to get the difference between $x_n$ and $x_{n+1}$, it didn't work out. How do I go about solving it?",,"['calculus', 'recurrence-relations']"
24,Convergence of $\sum^\infty_{n=1}\frac{a_n}{1+n^2a_n}$,Convergence of,\sum^\infty_{n=1}\frac{a_n}{1+n^2a_n},"We have a positive series $\displaystyle\sum^\infty_{n=1}a_n$. is the following series converge or diverge ?$$\displaystyle\sum^\infty_{n=1}\frac{a_n}{1+n^2a_n}$$ Suppose $\displaystyle\sum^\infty_{n=1}a_n$ does converge, so by the comparsion test the given series also converge. Suppose $\displaystyle\sum^\infty_{n=1}a_n$ does not converge: If $a_n$ is a bounded sequence with a bound $M$ then: $\forall n \  a_n\le M \Rightarrow \large\frac{a_n}{1+n^2a_n}>\frac{a_n}{1+M}\to\infty$ So the given series diverge. If $a_n$ isn't bounded, it has a subsequence that tends to infinity, so we have:  $\displaystyle\frac{a_{n_k}}{1+{n_k}^2a_{n_k}}\longrightarrow^{k\to\infty}\infty$ so the given series will diverge. (Couldn't find the tex for the limit with arrow)","We have a positive series $\displaystyle\sum^\infty_{n=1}a_n$. is the following series converge or diverge ?$$\displaystyle\sum^\infty_{n=1}\frac{a_n}{1+n^2a_n}$$ Suppose $\displaystyle\sum^\infty_{n=1}a_n$ does converge, so by the comparsion test the given series also converge. Suppose $\displaystyle\sum^\infty_{n=1}a_n$ does not converge: If $a_n$ is a bounded sequence with a bound $M$ then: $\forall n \  a_n\le M \Rightarrow \large\frac{a_n}{1+n^2a_n}>\frac{a_n}{1+M}\to\infty$ So the given series diverge. If $a_n$ isn't bounded, it has a subsequence that tends to infinity, so we have:  $\displaystyle\frac{a_{n_k}}{1+{n_k}^2a_{n_k}}\longrightarrow^{k\to\infty}\infty$ so the given series will diverge. (Couldn't find the tex for the limit with arrow)",,"['calculus', 'sequences-and-series', 'convergence-divergence', 'solution-verification']"
25,$\tan(\pi/2)$ is undefined but $\cot(\pi/2)$ is defined,is undefined but  is defined,\tan(\pi/2) \cot(\pi/2),"We know that $\tan(\pi/2)$ is undefined, and $\cot(\pi/2) = 0$. But $\cot(x) = \frac{\cos(x)}{\sin(x)} = \frac{1}{\tan(x)}$. So how is it possible that for some value $x$, $\tan(x)$ is undefined but $\,1/\tan(x)$ is defined?","We know that $\tan(\pi/2)$ is undefined, and $\cot(\pi/2) = 0$. But $\cot(x) = \frac{\cos(x)}{\sin(x)} = \frac{1}{\tan(x)}$. So how is it possible that for some value $x$, $\tan(x)$ is undefined but $\,1/\tan(x)$ is defined?",,"['calculus', 'trigonometry']"
26,Fundamental theorem of calculus proof?,Fundamental theorem of calculus proof?,,"To give you background, I have been studying calculus from Stewart. In the Integrals chapter, he proved the Evaluation Therorem by applying the mean value theorem on the Riemann sum of a continous function $f$: $$\int_a^bf(x)dx = F(b)−F(a).$$ Now when I studying the Fundamental Theorem of Calculus, I think that it is just a corollary of the theorem above. Then why does he go through the proof using some other method? It is really something that is bothering me.","To give you background, I have been studying calculus from Stewart. In the Integrals chapter, he proved the Evaluation Therorem by applying the mean value theorem on the Riemann sum of a continous function $f$: $$\int_a^bf(x)dx = F(b)−F(a).$$ Now when I studying the Fundamental Theorem of Calculus, I think that it is just a corollary of the theorem above. Then why does he go through the proof using some other method? It is really something that is bothering me.",,"['calculus', 'integration']"
27,Understanding the syntax for derivatives - dy/dx,Understanding the syntax for derivatives - dy/dx,,"I'm new to calculus, and I'm trying to understand the syntax of derivatives: $$\frac {dy}{dx}$$ At a glance it implies some kind of division and some variable ""d"" has entered the picture. Does this reflect some deep relationship between division and derivatives or is it just misleading? The syntax for higher order derivatives seems even stranger: $$\frac {d^2y}{dx^2}  ... \frac {d^3y}{dx^3} ... \frac {d^4y}{dx^4} ...$$ This seems to imply that some exponents are now involved. Again is this reflective of deeper relationships or just an overlap of syntax choice? Does more advanced calculus ever involve different numbers as follows? $$\frac {d^3y}{dx^2} ... \frac {d^5y}{dx^3} $$","I'm new to calculus, and I'm trying to understand the syntax of derivatives: $$\frac {dy}{dx}$$ At a glance it implies some kind of division and some variable ""d"" has entered the picture. Does this reflect some deep relationship between division and derivatives or is it just misleading? The syntax for higher order derivatives seems even stranger: $$\frac {d^2y}{dx^2}  ... \frac {d^3y}{dx^3} ... \frac {d^4y}{dx^4} ...$$ This seems to imply that some exponents are now involved. Again is this reflective of deeper relationships or just an overlap of syntax choice? Does more advanced calculus ever involve different numbers as follows? $$\frac {d^3y}{dx^2} ... \frac {d^5y}{dx^3} $$",,"['calculus', 'derivatives']"
28,Two notions of total derivative.,Two notions of total derivative.,,"Let $f:\mathbb R^n\rightarrow \mathbb R^m$ be a function. By definition, $f$ is differentiable at $a$ if there exists a linear map $D_af:\mathbb R^n\rightarrow\mathbb R^m$ such that $$\lim_{h\rightarrow 0}\dfrac{||f(a+h)-f(a)-D_af(h)||}{||h||}=0$$. When this limit exists, we call $D_af$ the total derivative of $f$ at $a$ and we call the corresponding matrix with respect to usual basis, the Jacobian matrix $J_af$. Now $f$ can be written as $f=(f_1,\cdots,f_m)$ where each $f_i:\mathbb R^n\rightarrow \mathbb R$ and $f(x)=(f_1(x),\cdots,f_m(x))$. We define the partial derivative of $f_i$ at $a=(a_1,\cdots,a_n)$ in the direction of $x_j$ by the real number (if it exists) $$\dfrac{\partial f_i}{\partial x_j}(a)=\lim_{h\rightarrow 0}\dfrac{f_i(a_1,\cdots,a_j+h,\cdots,a_n)-f_i(a)}{h}$$ And we show that when $f$ is differentiable at $a$ then all the real numbers $\dfrac{\partial f_i}{\partial x_j}(a)$ exist and the matrix elements $(J_af)_{i,j}=\dfrac{\partial f_i}{\partial x_j}(a)$. Now I see in wikipedia articles that they give the name total derivative also for some other notion: given a map $g:\mathbb R^n\rightarrow \mathbb R$ then the total derivative of $g$ with respect to $x_j$ is  $$\dfrac{dg}{dx_j}=\dfrac{\partial g}{\partial x_1}\dfrac{dx_1}{dx_j}+\cdots+\dfrac{\partial g}{\partial x_n}\dfrac{dx_n}{dx_j}$$ My questions: 1) Is the formula above a definition for $\dfrac{dg}{dx_j}$ ? 2) Is the notion of $\dfrac{dg}{dx_j}$ reserved only for real valued maps $g:\mathbb R^n\rightarrow \mathbb R$ since it has partial derivatives in its definition formula? 3) How does these two notions of total derivative relate?","Let $f:\mathbb R^n\rightarrow \mathbb R^m$ be a function. By definition, $f$ is differentiable at $a$ if there exists a linear map $D_af:\mathbb R^n\rightarrow\mathbb R^m$ such that $$\lim_{h\rightarrow 0}\dfrac{||f(a+h)-f(a)-D_af(h)||}{||h||}=0$$. When this limit exists, we call $D_af$ the total derivative of $f$ at $a$ and we call the corresponding matrix with respect to usual basis, the Jacobian matrix $J_af$. Now $f$ can be written as $f=(f_1,\cdots,f_m)$ where each $f_i:\mathbb R^n\rightarrow \mathbb R$ and $f(x)=(f_1(x),\cdots,f_m(x))$. We define the partial derivative of $f_i$ at $a=(a_1,\cdots,a_n)$ in the direction of $x_j$ by the real number (if it exists) $$\dfrac{\partial f_i}{\partial x_j}(a)=\lim_{h\rightarrow 0}\dfrac{f_i(a_1,\cdots,a_j+h,\cdots,a_n)-f_i(a)}{h}$$ And we show that when $f$ is differentiable at $a$ then all the real numbers $\dfrac{\partial f_i}{\partial x_j}(a)$ exist and the matrix elements $(J_af)_{i,j}=\dfrac{\partial f_i}{\partial x_j}(a)$. Now I see in wikipedia articles that they give the name total derivative also for some other notion: given a map $g:\mathbb R^n\rightarrow \mathbb R$ then the total derivative of $g$ with respect to $x_j$ is  $$\dfrac{dg}{dx_j}=\dfrac{\partial g}{\partial x_1}\dfrac{dx_1}{dx_j}+\cdots+\dfrac{\partial g}{\partial x_n}\dfrac{dx_n}{dx_j}$$ My questions: 1) Is the formula above a definition for $\dfrac{dg}{dx_j}$ ? 2) Is the notion of $\dfrac{dg}{dx_j}$ reserved only for real valued maps $g:\mathbb R^n\rightarrow \mathbb R$ since it has partial derivatives in its definition formula? 3) How does these two notions of total derivative relate?",,"['calculus', 'multivariable-calculus']"
29,How prove this limit $\lim_{\alpha\to n}\frac{J_{\alpha}(x)\cos{(\alpha \pi)}-J_{-\alpha}(x)}{\sin{\alpha\pi}}$?,How prove this limit ?,\lim_{\alpha\to n}\frac{J_{\alpha}(x)\cos{(\alpha \pi)}-J_{-\alpha}(x)}{\sin{\alpha\pi}},"Let $$J_{\alpha}(x)=\sum_{m=0}^{\infty}\dfrac{(-1)^m}{m!\Gamma{(m+\alpha+1)}}\left(\dfrac{x}{2}\right)^{2m+\alpha}$$ show that： \begin{align*}&\lim_{\alpha\to n}\dfrac{J_{\alpha}(x)\cos{(\alpha \pi)}-J_{-\alpha}(x)}{\sin{\alpha\pi}}\\ &=\dfrac{2}{\pi}J_{n}(x)\left(\ln{\dfrac{x}{2}}+\gamma\right)-\dfrac{1}{\pi}\sum_{m=0}^{n-1}\dfrac{(n-m-1)!}{m!}\left(\dfrac{x}{2}\right)^{2m-n}-\dfrac{1}{\pi}\sum_{m=0}^{\infty}\dfrac{(-1)^m\left(\dfrac{x}{2}\right)^{n+2m}}{m!(n+m)!}\left(\sum_{k=0}^{n+m-1}\dfrac{1}{k+1}+\sum_{k=0}^{m-1}\dfrac{1}{k+1}\right) \end{align*} where $$\gamma=\left(1+\dfrac{1}{2}+\dfrac{1}{3}+\cdots+\dfrac{1}{n}-\ln{n}\right)=0.5772\cdots$$ call Eluer constant. and where $J_{\alpha}(x)$ is Bessel function: http://en.wikipedia.org/wiki/Bessel_function This problem is from a book,My book say this proof  use L'Hôpital's rule and it is very very  trouble,so we can't post all solution, only post reslut,so I hope see solution,Thank you someone can help","Let show that： where call Eluer constant. and where is Bessel function: http://en.wikipedia.org/wiki/Bessel_function This problem is from a book,My book say this proof  use L'Hôpital's rule and it is very very  trouble,so we can't post all solution, only post reslut,so I hope see solution,Thank you someone can help","J_{\alpha}(x)=\sum_{m=0}^{\infty}\dfrac{(-1)^m}{m!\Gamma{(m+\alpha+1)}}\left(\dfrac{x}{2}\right)^{2m+\alpha} \begin{align*}&\lim_{\alpha\to n}\dfrac{J_{\alpha}(x)\cos{(\alpha \pi)}-J_{-\alpha}(x)}{\sin{\alpha\pi}}\\
&=\dfrac{2}{\pi}J_{n}(x)\left(\ln{\dfrac{x}{2}}+\gamma\right)-\dfrac{1}{\pi}\sum_{m=0}^{n-1}\dfrac{(n-m-1)!}{m!}\left(\dfrac{x}{2}\right)^{2m-n}-\dfrac{1}{\pi}\sum_{m=0}^{\infty}\dfrac{(-1)^m\left(\dfrac{x}{2}\right)^{n+2m}}{m!(n+m)!}\left(\sum_{k=0}^{n+m-1}\dfrac{1}{k+1}+\sum_{k=0}^{m-1}\dfrac{1}{k+1}\right)
\end{align*} \gamma=\left(1+\dfrac{1}{2}+\dfrac{1}{3}+\cdots+\dfrac{1}{n}-\ln{n}\right)=0.5772\cdots J_{\alpha}(x)","['calculus', 'limits', 'special-functions']"
30,Changing operator to polar coordinates,Changing operator to polar coordinates,,"Let $$\Delta=\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}$$ be the Laplace operator on the $(x,y)$-plane. Consider the polar coordinates with $x=r\cos\theta$ and $y=r\sin\theta$. Show that $$\Delta=\frac{\partial^2}{\partial r^2}+\frac1r\frac\partial{\partial r}+\frac1{r^2}\frac{\partial^2}{\partial \theta^2}.$$ I don't know how to change the coordinates for an operator like this one. What is the method that should be used?","Let $$\Delta=\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}$$ be the Laplace operator on the $(x,y)$-plane. Consider the polar coordinates with $x=r\cos\theta$ and $y=r\sin\theta$. Show that $$\Delta=\frac{\partial^2}{\partial r^2}+\frac1r\frac\partial{\partial r}+\frac1{r^2}\frac{\partial^2}{\partial \theta^2}.$$ I don't know how to change the coordinates for an operator like this one. What is the method that should be used?",,"['calculus', 'polar-coordinates', 'partial-derivative']"
31,Solve $\int_{0}^{\infty}\frac{\sin^{2}x}{x}\ dx$,Solve,\int_{0}^{\infty}\frac{\sin^{2}x}{x}\ dx,"I have this problem $\displaystyle \int_{0}^{\infty}\frac{\sin^{2}x}{x}\ dx$ I think it diverges, but I cannot prove it. (I'm in my first calculus course, so I don't know of any more advanced methods than u-substitution (including trig subs) integration by parts","I have this problem $\displaystyle \int_{0}^{\infty}\frac{\sin^{2}x}{x}\ dx$ I think it diverges, but I cannot prove it. (I'm in my first calculus course, so I don't know of any more advanced methods than u-substitution (including trig subs) integration by parts",,"['calculus', 'integration']"
32,How to integrate a binomial expression without expanding it before?,How to integrate a binomial expression without expanding it before?,,"Let $(3-x^2)^3$ be a binomial expression. What is the integral of such expression? First I tried integration by substitution, because there is a composition of two functions. But$\displaystyle\frac{d}{dx}(3-x^2)=2x$ and I learned that this method only works if the integrand has the derivative of the inner function, multiplied by a constant. Then I used what I learned about power series: $$(3-x^2)^3=\binom{3}{0}3^3+\binom{3}{1}3^2(-x^2)+\binom{3}{2}3(-x^2)^2+\binom{3}{3}(-x^2)^3$$ And so, \begin{align} (3-x^2)^3&=27-27x^2+9x^4-x^6\\ \int(3-x^2)^3\,\mathrm dx&=\int(27-27x^2+9x^4-x^6) dx \end{align} Finally: $$\displaystyle\int(3-x^2)^3dx=27x-9x^3+\frac{9}{5}x^5-\frac{1}{7}x^7+C$$ But imagine that the power is $10$, or maybe $20$? There is any way to integrate this kind of expression without expand it? Thanks.","Let $(3-x^2)^3$ be a binomial expression. What is the integral of such expression? First I tried integration by substitution, because there is a composition of two functions. But$\displaystyle\frac{d}{dx}(3-x^2)=2x$ and I learned that this method only works if the integrand has the derivative of the inner function, multiplied by a constant. Then I used what I learned about power series: $$(3-x^2)^3=\binom{3}{0}3^3+\binom{3}{1}3^2(-x^2)+\binom{3}{2}3(-x^2)^2+\binom{3}{3}(-x^2)^3$$ And so, \begin{align} (3-x^2)^3&=27-27x^2+9x^4-x^6\\ \int(3-x^2)^3\,\mathrm dx&=\int(27-27x^2+9x^4-x^6) dx \end{align} Finally: $$\displaystyle\int(3-x^2)^3dx=27x-9x^3+\frac{9}{5}x^5-\frac{1}{7}x^7+C$$ But imagine that the power is $10$, or maybe $20$? There is any way to integrate this kind of expression without expand it? Thanks.",,['calculus']
33,"Integration of $\displaystyle \int\frac{1}{1+x^8}\,dx$",Integration of,"\displaystyle \int\frac{1}{1+x^8}\,dx","Compute the indefinite integral   $$ \int\frac{1}{1+x^8}\,dx $$ My Attempt: First we will factor $1+x^8$ $$ \begin{align} 1+x^8 &= 1^2+(x^4)^2+2x^4-2x^4\\ &= (1+x^4)^2-(\sqrt{2}x^2)^2\\ &= (x^4+\sqrt{2}x^2+1)(x^4-\sqrt{2}x^2+1) \end{align} $$ Then we can rewrite the integral as $$ \int\frac{1}{1+x^8}\,dx = \int \frac{1}{(x^4+\sqrt{2}x^2+1)(x^4-\sqrt{2}x^2+1)}\,dx$$ To use partial fractions let $t = x^2$ to get $$ \frac {1}{(t^2+\sqrt{2}t+1)(t^2-\sqrt{2}t+1)} = \frac{At+B}{t^2+\sqrt{2}t+1}+\frac{Ct+D}{t^2-\sqrt{2}t+1} $$ This method of solving the problem becomes very complex. Is there a less complex approach to the problem?","Compute the indefinite integral   $$ \int\frac{1}{1+x^8}\,dx $$ My Attempt: First we will factor $1+x^8$ $$ \begin{align} 1+x^8 &= 1^2+(x^4)^2+2x^4-2x^4\\ &= (1+x^4)^2-(\sqrt{2}x^2)^2\\ &= (x^4+\sqrt{2}x^2+1)(x^4-\sqrt{2}x^2+1) \end{align} $$ Then we can rewrite the integral as $$ \int\frac{1}{1+x^8}\,dx = \int \frac{1}{(x^4+\sqrt{2}x^2+1)(x^4-\sqrt{2}x^2+1)}\,dx$$ To use partial fractions let $t = x^2$ to get $$ \frac {1}{(t^2+\sqrt{2}t+1)(t^2-\sqrt{2}t+1)} = \frac{At+B}{t^2+\sqrt{2}t+1}+\frac{Ct+D}{t^2-\sqrt{2}t+1} $$ This method of solving the problem becomes very complex. Is there a less complex approach to the problem?",,['calculus']
34,Finding the volume of a tetrahedron by given vertices.,Finding the volume of a tetrahedron by given vertices.,,"Please help me with the problem below. Find the volume of a tetrahedron with vertices: $O(0,0,0)$, $A(1,2,3)$, $B(-2,1,5)$, $C(3,7,1)$ by using triple integral. Hint: First find the the equations of the planes. Note: My professor told me that I can use change of variables (which I need to calculate the Jacobian and then the volume of a ""simpler"" tetrahedron).","Please help me with the problem below. Find the volume of a tetrahedron with vertices: $O(0,0,0)$, $A(1,2,3)$, $B(-2,1,5)$, $C(3,7,1)$ by using triple integral. Hint: First find the the equations of the planes. Note: My professor told me that I can use change of variables (which I need to calculate the Jacobian and then the volume of a ""simpler"" tetrahedron).",,"['calculus', 'multivariable-calculus', 'definite-integrals', 'volume']"
35,Application of fundamental theorem of calculus,Application of fundamental theorem of calculus,,"I have this problem: $$ \frac{d}{dx} \left( \int_{\sqrt{x}}^{x^2-3x} \tan(t) dt \right) $$ I know how found the derivative of the integral from constant $a$ to variable $x$ so: $$ \frac{d}{dx} \left( \int_a^x f(t) dt  \right) $$ but I don't know how make it between two variables, in this case from $\sqrt{x}$ to $x^2-3x$ Thanks so much.","I have this problem: $$ \frac{d}{dx} \left( \int_{\sqrt{x}}^{x^2-3x} \tan(t) dt \right) $$ I know how found the derivative of the integral from constant $a$ to variable $x$ so: $$ \frac{d}{dx} \left( \int_a^x f(t) dt  \right) $$ but I don't know how make it between two variables, in this case from $\sqrt{x}$ to $x^2-3x$ Thanks so much.",,"['calculus', 'derivatives', 'definite-integrals']"
36,Stirling's Series Derivation,Stirling's Series Derivation,,"I was reading this paper and at the top of page 9 it says that as $n\to\infty$, $$\left(1+\frac{1}{n}\right)^{n+1/2}e^{-1}\left(1+\frac{a_1}{(n+1)}+\frac{a_2}{(n+1)^2}+\cdots \right)=1+\frac{a_1}{n}+\frac {a_2-a_1+1/12}{n^2}+\frac{(13/12) a_1-2a_2+a_3-1/12}{n^3}...$$ I just do not understand where the $1/12,~13/12,~\text{etc.}$ come from, so can anybody enlighten me? And something else: If I have shown the exact relation $n!= \sqrt{n}(n/e)^n e^{1-E(n)}$ where $$E(n)=\sum\limits_{k=1}^{n-1} \biggl[\left(\frac {2k+1}{2}\right)\ln \left(\frac{k+1}{k}\right)-1\biggl]$$ that after some working gets to $$\sum\limits_{k=1}^{n-1} \biggl[\left(\frac{1}{3(2k+1)^2}+\frac{1}{5(2k+1)^4}+ \cdots\right)\biggl]<\frac{n-1}{12n},$$ can I use this in any way to derive Stirling's series (the series, not the first term)? I know that I can derive the series using the Euler-Maclaurin formula but I want this for an essay and I am well off the word limit to introduce a new result. Thank you.","I was reading this paper and at the top of page 9 it says that as $n\to\infty$, $$\left(1+\frac{1}{n}\right)^{n+1/2}e^{-1}\left(1+\frac{a_1}{(n+1)}+\frac{a_2}{(n+1)^2}+\cdots \right)=1+\frac{a_1}{n}+\frac {a_2-a_1+1/12}{n^2}+\frac{(13/12) a_1-2a_2+a_3-1/12}{n^3}...$$ I just do not understand where the $1/12,~13/12,~\text{etc.}$ come from, so can anybody enlighten me? And something else: If I have shown the exact relation $n!= \sqrt{n}(n/e)^n e^{1-E(n)}$ where $$E(n)=\sum\limits_{k=1}^{n-1} \biggl[\left(\frac {2k+1}{2}\right)\ln \left(\frac{k+1}{k}\right)-1\biggl]$$ that after some working gets to $$\sum\limits_{k=1}^{n-1} \biggl[\left(\frac{1}{3(2k+1)^2}+\frac{1}{5(2k+1)^4}+ \cdots\right)\biggl]<\frac{n-1}{12n},$$ can I use this in any way to derive Stirling's series (the series, not the first term)? I know that I can derive the series using the Euler-Maclaurin formula but I want this for an essay and I am well off the word limit to introduce a new result. Thank you.",,"['calculus', 'sequences-and-series', 'numerical-methods']"
37,"Definition of $\pi$, $\lim\limits_{n \to \infty}{n \sin\left(\frac{180^o}{n}\right)}$","Definition of ,",\pi \lim\limits_{n \to \infty}{n \sin\left(\frac{180^o}{n}\right)},"I'm learning mathematical analysis recently. My book gave the definition of $\pi$ as the limit of sequence $\left\{n \sin \frac{180^o}{n}\right\}$. The way it prove this sequence is convergent is quite strange to me. It first showed the sequence is smaller than 4, then monotonically increasing. The latter part is confusing. It first let $t = \frac{180^o}{n(n+1)} $, and proved $\tan nt \ge n\tan t$ for $nt \le 45^o$, so $$ \sin(n+1)t = \sin nt \cos t + \cos nt \sin t = \sin nt \cos t\left(1 + \frac{\tan t}{\tan nt}\right) \le \frac{n+1}{n} \sin nt $$ then $$ n \sin \frac{180^o}{n} \le (n+1) \sin \frac{180^o}{n+1} $$ This is perfectly correct, but how can I come up with a $t$ like this? If I'm to prove this, is there a way to figure out what the $t$ should be like? Or all I can do is just memorize it? Alternately, do you guys have a more intuitive proof?","I'm learning mathematical analysis recently. My book gave the definition of $\pi$ as the limit of sequence $\left\{n \sin \frac{180^o}{n}\right\}$. The way it prove this sequence is convergent is quite strange to me. It first showed the sequence is smaller than 4, then monotonically increasing. The latter part is confusing. It first let $t = \frac{180^o}{n(n+1)} $, and proved $\tan nt \ge n\tan t$ for $nt \le 45^o$, so $$ \sin(n+1)t = \sin nt \cos t + \cos nt \sin t = \sin nt \cos t\left(1 + \frac{\tan t}{\tan nt}\right) \le \frac{n+1}{n} \sin nt $$ then $$ n \sin \frac{180^o}{n} \le (n+1) \sin \frac{180^o}{n+1} $$ This is perfectly correct, but how can I come up with a $t$ like this? If I'm to prove this, is there a way to figure out what the $t$ should be like? Or all I can do is just memorize it? Alternately, do you guys have a more intuitive proof?",,"['calculus', 'sequences-and-series', 'limits', 'pi']"
38,Integral with 4 radicals-hat,Integral with 4 radicals-hat,,"I'd like to find out a simple way for calculating the value of: $$\int_{0}^{1}\sqrt{1+\sqrt{1 + {\sqrt{1+ \sqrt{x}}}}}\,dx .$$ Of course, I thought of some variable change, but it seems pretty complicated.  On the other hand, I wonder if there can be made a generalization when having  to deal with the expression with $k$ radicals, $k>1$.","I'd like to find out a simple way for calculating the value of: $$\int_{0}^{1}\sqrt{1+\sqrt{1 + {\sqrt{1+ \sqrt{x}}}}}\,dx .$$ Of course, I thought of some variable change, but it seems pretty complicated.  On the other hand, I wonder if there can be made a generalization when having  to deal with the expression with $k$ radicals, $k>1$.",,"['calculus', 'definite-integrals']"
39,"What is the simplest way to show that $\cos(r \pi)$ is irrational if $r$ is rational and $r \in (0,1/2)\setminus\{1/3\}$?",What is the simplest way to show that  is irrational if  is rational and ?,"\cos(r \pi) r r \in (0,1/2)\setminus\{1/3\}","What is the simplest way to show that $\cos(r \pi)$ is irrational if $r$ is rational and $\displaystyle r \in \left(0,\frac{1}{2} \right)\setminus \left\{\frac{1}{3} \right\}$? I proved it using the following sequence $x_1 = \cos(r \pi)$; $x_{k} = 2 x_{k-1}^2-1$ and periodicity of the cosine function. Is there any proof that is based on definition of rational numbers and trigonometric identities only? Thanks!","What is the simplest way to show that $\cos(r \pi)$ is irrational if $r$ is rational and $\displaystyle r \in \left(0,\frac{1}{2} \right)\setminus \left\{\frac{1}{3} \right\}$? I proved it using the following sequence $x_1 = \cos(r \pi)$; $x_{k} = 2 x_{k-1}^2-1$ and periodicity of the cosine function. Is there any proof that is based on definition of rational numbers and trigonometric identities only? Thanks!",,['calculus']
40,"Wrong solution for $\int \frac{1 - e^x}{e^x}\, dx$",Wrong solution for,"\int \frac{1 - e^x}{e^x}\, dx",The solution book gives this as an answer: $$\int \frac{1-e^x}{e^x}dx = \int \frac{1}{e^x}-\frac{e^x}{e^x}dx = -e^{-x} + C$$ I would think it would be solved this way: $$\int \frac{1-e^x}{e^x} dx = \int \frac{1}{e^x} -1 \; dx = -e^{-x}-x + C$$,The solution book gives this as an answer: $$\int \frac{1-e^x}{e^x}dx = \int \frac{1}{e^x}-\frac{e^x}{e^x}dx = -e^{-x} + C$$ I would think it would be solved this way: $$\int \frac{1-e^x}{e^x} dx = \int \frac{1}{e^x} -1 \; dx = -e^{-x}-x + C$$,,['calculus']
41,Solving $\int_{-\infty}^{\infty}{\frac{1}{(4+x^2)\sqrt{4+x^2}} \space dx}$,Solving,\int_{-\infty}^{\infty}{\frac{1}{(4+x^2)\sqrt{4+x^2}} \space dx},I'm trying to solve $$\int_{-\infty}^{\infty}{\frac{1}{(4+x^2)\sqrt{4+x^2}} \space dx}$$ By substituting $x=2\tan{t}$. I get as far as: $$\int_{x \space = -\infty}^{x \space = \infty}{\frac{1}{(4+(\underbrace{2\tan{t}}_{x})^2)\sqrt{4+(\underbrace{2\tan{t}}_{x})^2}} \cdot \underbrace{2(1+\tan^2t) \space dt}_{dx}} = \dots$$ $$\dots = \frac{1}{4} \cdot \int_{t \space = -\infty}^{t \space = \infty}{\frac{1}{\sqrt{1+\tan^2t}} \space dt}$$ Now what? Have I done anything wrong? I don't see how I could continue from now on.,I'm trying to solve $$\int_{-\infty}^{\infty}{\frac{1}{(4+x^2)\sqrt{4+x^2}} \space dx}$$ By substituting $x=2\tan{t}$. I get as far as: $$\int_{x \space = -\infty}^{x \space = \infty}{\frac{1}{(4+(\underbrace{2\tan{t}}_{x})^2)\sqrt{4+(\underbrace{2\tan{t}}_{x})^2}} \cdot \underbrace{2(1+\tan^2t) \space dt}_{dx}} = \dots$$ $$\dots = \frac{1}{4} \cdot \int_{t \space = -\infty}^{t \space = \infty}{\frac{1}{\sqrt{1+\tan^2t}} \space dt}$$ Now what? Have I done anything wrong? I don't see how I could continue from now on.,,"['calculus', 'integration', 'trigonometry', 'definite-integrals']"
42,Summation formula name,Summation formula name,,"What is the name of the following summation formula? $$\sum_{k = 1}^n f(k)) = \int_1^{n + 1} f - \frac{f(n + 1) + f(0)}2 + \int_1^{n + 1} f'w,$$ where $w$ is the “sawtooth” function, defined by $w(x) = (x – (k + 1/2))$, for $k < x <= k + 1$, if $k$ is an integer. From this formula one can obtain the sum of the first $n$ $k$-th powers. No guessing is necessary, you just turn the crank. However, you have to start at 1 and work your way up. So, if you want the formula for the sum of the first $n$ cubes, say, then you first use this formula to find the formula for the sum of the first $n$ 1-st powers, and then use all this information to find the formula for the sum of the first $n$ squares, and then, finally, use all this information to find the formula for the sum of the first $n$ cubes. I’ve been calling it Gauss’s Summation Formula, but attributions are often variable, and there might be a more appropriate one that I should be using. I got taken to the woodshed over this. Here is the woodshed link: Prove that $\sum\limits_{k=1}^nk^2 = \frac{n(n+1)(2n+1)}{6}$?","What is the name of the following summation formula? $$\sum_{k = 1}^n f(k)) = \int_1^{n + 1} f - \frac{f(n + 1) + f(0)}2 + \int_1^{n + 1} f'w,$$ where $w$ is the “sawtooth” function, defined by $w(x) = (x – (k + 1/2))$, for $k < x <= k + 1$, if $k$ is an integer. From this formula one can obtain the sum of the first $n$ $k$-th powers. No guessing is necessary, you just turn the crank. However, you have to start at 1 and work your way up. So, if you want the formula for the sum of the first $n$ cubes, say, then you first use this formula to find the formula for the sum of the first $n$ 1-st powers, and then use all this information to find the formula for the sum of the first $n$ squares, and then, finally, use all this information to find the formula for the sum of the first $n$ cubes. I’ve been calling it Gauss’s Summation Formula, but attributions are often variable, and there might be a more appropriate one that I should be using. I got taken to the woodshed over this. Here is the woodshed link: Prove that $\sum\limits_{k=1}^nk^2 = \frac{n(n+1)(2n+1)}{6}$?",,"['calculus', 'sequences-and-series', 'reference-request', 'terminology']"
43,Approximations Involving Exponential Functions,Approximations Involving Exponential Functions,,"I am reading a text and I am curious to know how certain approximations were reached. The first function approximations is: $$ 1- \frac{1}{2p}((1+p)e^{\frac{-y}{x(1+p)}} - (1-p)e^{\frac{-y}{x(1-p)}}) \approx \frac{y^2}{2x^2 (1-p^2)}$$ ,when $y \ll x$. Note that I tried using the approximation $e^x \approx 1+x$, when x is small, but all I got was the conclusion that $1- \frac{1}{2p}((1+p)e^{\frac{-y}{x(1+p)}} - (1-p)e^{\frac{-y}{x(1-p)}}) \approx 0$. The second function approximation is: $$ 1-e^{\frac{-y}{x}}(1-Q(a,b)+Q(b,a)) \approx \frac{y^2}{x^2 (1-p^2)}$$ ,when $y \ll x$, where $Q(a,b) = \int_b^\infty e^{-\frac12 (a^2 + u^2)} I_0(au) u \, du$, $b = \sqrt{\frac{2y}{x(1-p^2)}}$, $a = bp$, $I_0$ is a modified Bessel Function of the first kind. It is also a known fact that $$ Q(b,0) = 1$$ and $$ Q(0,b) = e^{-\frac{b^2}{2}}$$ I have tried to assume $$ a = 0$$, since $a = bp$  and $b$ is small, $ p$ is a number between 0 and 1. However, it is not clear how $(1-p^2)$ is in the denominator and not $(1-p^2)^2 $, which would be closer to the traditional $e^x$ approximation. Any hints on how these approximations were derived would be appreciated. Thanks.","I am reading a text and I am curious to know how certain approximations were reached. The first function approximations is: $$ 1- \frac{1}{2p}((1+p)e^{\frac{-y}{x(1+p)}} - (1-p)e^{\frac{-y}{x(1-p)}}) \approx \frac{y^2}{2x^2 (1-p^2)}$$ ,when $y \ll x$. Note that I tried using the approximation $e^x \approx 1+x$, when x is small, but all I got was the conclusion that $1- \frac{1}{2p}((1+p)e^{\frac{-y}{x(1+p)}} - (1-p)e^{\frac{-y}{x(1-p)}}) \approx 0$. The second function approximation is: $$ 1-e^{\frac{-y}{x}}(1-Q(a,b)+Q(b,a)) \approx \frac{y^2}{x^2 (1-p^2)}$$ ,when $y \ll x$, where $Q(a,b) = \int_b^\infty e^{-\frac12 (a^2 + u^2)} I_0(au) u \, du$, $b = \sqrt{\frac{2y}{x(1-p^2)}}$, $a = bp$, $I_0$ is a modified Bessel Function of the first kind. It is also a known fact that $$ Q(b,0) = 1$$ and $$ Q(0,b) = e^{-\frac{b^2}{2}}$$ I have tried to assume $$ a = 0$$, since $a = bp$  and $b$ is small, $ p$ is a number between 0 and 1. However, it is not clear how $(1-p^2)$ is in the denominator and not $(1-p^2)^2 $, which would be closer to the traditional $e^x$ approximation. Any hints on how these approximations were derived would be appreciated. Thanks.",,"['calculus', 'approximation']"
44,"Divergence of Gradient of the Unit Normal, and Curvature Equation","Divergence of Gradient of the Unit Normal, and Curvature Equation",,"The curvature equation for implicit functions, level sets is usually given in two forms: one is the divergence of the gradient of the unit normal: $\kappa = \bigtriangledown \cdot \frac{\bigtriangledown \phi}{|\bigtriangledown \phi|}$ and the other is $\kappa = \frac{\phi_{xx}\phi_y^2 - 2\phi_x\phi_y\phi_{xy} + \phi_{yy}\phi_x^2}{(\phi_x^2+\phi_y^2)^{3/2}}$ How do we derive the second equation from the first?","The curvature equation for implicit functions, level sets is usually given in two forms: one is the divergence of the gradient of the unit normal: $\kappa = \bigtriangledown \cdot \frac{\bigtriangledown \phi}{|\bigtriangledown \phi|}$ and the other is $\kappa = \frac{\phi_{xx}\phi_y^2 - 2\phi_x\phi_y\phi_{xy} + \phi_{yy}\phi_x^2}{(\phi_x^2+\phi_y^2)^{3/2}}$ How do we derive the second equation from the first?",,"['calculus', 'differential-geometry', 'multivariable-calculus', 'curvature']"
45,Relation between torsion of a curve and the curl of a vector field,Relation between torsion of a curve and the curl of a vector field,,The torsion of a curve in $\mathbb{R}^3$ indicates how much it twists around. The curl of a vector field indicates how much the vector field twists around. Is there a relation between the curl of a vector field and the torsion of a curve through that vector field at a given point?,The torsion of a curve in $\mathbb{R}^3$ indicates how much it twists around. The curl of a vector field indicates how much the vector field twists around. Is there a relation between the curl of a vector field and the torsion of a curve through that vector field at a given point?,,['calculus']
46,A formula for $\pi$,A formula for,\pi,"I discovered in an exercise that $$\boxed{\pi=12\int_{0}^{2-\sqrt3}\frac{dt}{1+t^2}}$$ since $\frac{\pi}{12}=\arctan( 2-\sqrt3)$ , what we were made to demonstrate with formulas with half angles. I tried the following $$\forall |t|<1, \frac{1}{1+t^2}=1-t^2+t^4-t^6+...$$ So $$\pi\approx12\left( \alpha-\frac{\alpha^3}{3}+\frac{\alpha^5}{5} \right)\approx 3.1418$$ with $\alpha=2-\sqrt3$ Since it's an alternating series, we get $$|\pi-12(\alpha+...+(-1)^n\frac{\alpha^{2n+1}}{2n+1}|\leq \frac {12}{2n+3}\frac{3^{2n+3}}{10^{2n+3}}$$ since $\alpha<0.3$ For example, with $n=5$ , $$3.1415925<\pi<3.1415928$$ with $n=8$ , $$\frac{88081345207880}{51051} - \frac{84756313789596 \sqrt3}{85085}= 3.141592653...$$ As far as I can judge, one advantage of this process is that it gives approximations of type $a+b\sqrt3,(a,b)\in \mathbb Q^2$ and thus reduces the approximation of $\pi$ to that of $\sqrt3$ . What are some mathematical arguments for mathematically criticizing what I probably naively call "" one advantage""?","I discovered in an exercise that since , what we were made to demonstrate with formulas with half angles. I tried the following So with Since it's an alternating series, we get since For example, with , with , As far as I can judge, one advantage of this process is that it gives approximations of type and thus reduces the approximation of to that of . What are some mathematical arguments for mathematically criticizing what I probably naively call "" one advantage""?","\boxed{\pi=12\int_{0}^{2-\sqrt3}\frac{dt}{1+t^2}} \frac{\pi}{12}=\arctan( 2-\sqrt3) \forall |t|<1, \frac{1}{1+t^2}=1-t^2+t^4-t^6+... \pi\approx12\left( \alpha-\frac{\alpha^3}{3}+\frac{\alpha^5}{5} \right)\approx 3.1418 \alpha=2-\sqrt3 |\pi-12(\alpha+...+(-1)^n\frac{\alpha^{2n+1}}{2n+1}|\leq \frac {12}{2n+3}\frac{3^{2n+3}}{10^{2n+3}} \alpha<0.3 n=5 3.1415925<\pi<3.1415928 n=8 \frac{88081345207880}{51051} - \frac{84756313789596 \sqrt3}{85085}= 3.141592653... a+b\sqrt3,(a,b)\in \mathbb Q^2 \pi \sqrt3","['calculus', 'power-series']"
47,About the Integral $\int\arcsin\left(\sin^{2}x\right)dx$,About the Integral,\int\arcsin\left(\sin^{2}x\right)dx,"$$\int\arcsin\left(\sin^{2}x\right)dx$$ I am not able to find a closed form elementary solution for this, though I have no reason to believe it exists. But trying out the Definite Integral as follows: $$I=\int_{0}^{\frac{\pi}{2}}\arcsin\left(\sin^{2}x\right)dx$$ Using the Series Expansion for $\arcsin(x)$ : $$\arcsin(x)=\sum_{n=0}^{\infty}\frac{\left(2n\right)!}{2^{2n}\left(n!\right)^{2}}\ \frac{x^{2n+1}}{2n+1}$$ $$\arcsin\left(\sin^{2}x\right)=\sum_{n=0}^{\infty}\frac{\left(2n\right)!}{2^{2n}\left(n!\right)^{2}}\ \frac{\left(\sin x\right)^{4n+2}}{2n+1}$$ $$I=\sum_{n=0}^{\infty}\frac{\left(2n\right)!}{2^{2n}\left(n!\right)^{2}\left(2n+1\right)}\ \int_{0}^{\frac{\pi}{2}}\left(\sin x\right)^{4n+2}dx$$ We are aware of the closed form of the Integral: $$\int_{0}^{\frac{\pi}{2}}\left(\sin x\right)^{a}dx=\frac{\sqrt \pi}{2}\frac{\Gamma\left(\frac{a+1}{2}\right)}{\Gamma\left(\frac{a}{2}+1\right)}$$ $$I=\frac{\sqrt \pi}{2}\sum_{n=0}^{\infty}\frac{\left(2n\right)!}{2^{2n}\left(n!\right)^{2}\left(2n+1\right)}\ \frac{\Gamma\left(\frac{4n+3}{2}\right)}{(2n+1)!}$$ $$I=\frac{\sqrt{\pi}}{2}\sum_{n=0}^{\infty}\frac{\Gamma\left(\frac{4n+3}{2}\right)}{2^{2n}\left(n!\right)^{2}\left(2n+1\right)^{2}}\ $$ Wolfram Gives a Closed Form for the Summation in terms of Hypergeometric Function as follows: $$\sum_{n=0}^{\infty}\frac{\Gamma\left(\frac{4n+3}{2}\right)}{2^{2n}\left(n!\right)^{2}\left(2n+1\right)^{2}}\ =\frac{\sqrt{\pi}}{2}\,_{4}F_{3}\left(\frac{1}{2},\frac{1}{2},\frac{3}{4},\frac{5}{4};1,\frac{3}{2},\frac{3}{2};1\right)$$ Hence, $$I=\frac{\pi}{4}\,_{4}F_{3}\left(\frac{1}{2},\frac{1}{2},\frac{3}{4},\frac{5}{4};1,\frac{3}{2},\frac{3}{2};1\right)$$ I have seen some cases where these hypergeometric functions end up in terms of closed form expressions. Well my question is: Whether the Indefinite Integral has a solution. Whether the Definite Integral has a Closed Form Solution. Whether the Hypergeometric Series has a Closed Form, which will lead us directly to the Definite Integral.","I am not able to find a closed form elementary solution for this, though I have no reason to believe it exists. But trying out the Definite Integral as follows: Using the Series Expansion for : We are aware of the closed form of the Integral: Wolfram Gives a Closed Form for the Summation in terms of Hypergeometric Function as follows: Hence, I have seen some cases where these hypergeometric functions end up in terms of closed form expressions. Well my question is: Whether the Indefinite Integral has a solution. Whether the Definite Integral has a Closed Form Solution. Whether the Hypergeometric Series has a Closed Form, which will lead us directly to the Definite Integral.","\int\arcsin\left(\sin^{2}x\right)dx I=\int_{0}^{\frac{\pi}{2}}\arcsin\left(\sin^{2}x\right)dx \arcsin(x) \arcsin(x)=\sum_{n=0}^{\infty}\frac{\left(2n\right)!}{2^{2n}\left(n!\right)^{2}}\ \frac{x^{2n+1}}{2n+1} \arcsin\left(\sin^{2}x\right)=\sum_{n=0}^{\infty}\frac{\left(2n\right)!}{2^{2n}\left(n!\right)^{2}}\ \frac{\left(\sin x\right)^{4n+2}}{2n+1} I=\sum_{n=0}^{\infty}\frac{\left(2n\right)!}{2^{2n}\left(n!\right)^{2}\left(2n+1\right)}\ \int_{0}^{\frac{\pi}{2}}\left(\sin x\right)^{4n+2}dx \int_{0}^{\frac{\pi}{2}}\left(\sin x\right)^{a}dx=\frac{\sqrt \pi}{2}\frac{\Gamma\left(\frac{a+1}{2}\right)}{\Gamma\left(\frac{a}{2}+1\right)} I=\frac{\sqrt \pi}{2}\sum_{n=0}^{\infty}\frac{\left(2n\right)!}{2^{2n}\left(n!\right)^{2}\left(2n+1\right)}\ \frac{\Gamma\left(\frac{4n+3}{2}\right)}{(2n+1)!} I=\frac{\sqrt{\pi}}{2}\sum_{n=0}^{\infty}\frac{\Gamma\left(\frac{4n+3}{2}\right)}{2^{2n}\left(n!\right)^{2}\left(2n+1\right)^{2}}\  \sum_{n=0}^{\infty}\frac{\Gamma\left(\frac{4n+3}{2}\right)}{2^{2n}\left(n!\right)^{2}\left(2n+1\right)^{2}}\ =\frac{\sqrt{\pi}}{2}\,_{4}F_{3}\left(\frac{1}{2},\frac{1}{2},\frac{3}{4},\frac{5}{4};1,\frac{3}{2},\frac{3}{2};1\right) I=\frac{\pi}{4}\,_{4}F_{3}\left(\frac{1}{2},\frac{1}{2},\frac{3}{4},\frac{5}{4};1,\frac{3}{2},\frac{3}{2};1\right)","['calculus', 'integration', 'special-functions', 'closed-form', 'hypergeometric-function']"
48,A special class of integrals: $\int_0^\infty \frac{f(x)}{1+x^2}dx$,A special class of integrals:,\int_0^\infty \frac{f(x)}{1+x^2}dx,"Consider the integral $$I=\int_0^\infty \frac{f(x)}{1+x^2}\mathrm{d}x$$ now make a change of variable to $x=\dfrac{1}{t}$ , and so $\mathrm{d}x=-\dfrac{1}{t^2}\mathrm{d}t$ . The integral becomes $$I=\int_0^\infty \frac{f\left(\frac{1}{t}\right)}{1+t^2}\mathrm{d}t$$ and so $$I=\frac{1}{2}\int_0^\infty \frac{f(x)+f\left(\frac{1}{x}\right)}{1+x^2}\mathrm{d}x$$ Hence the question: what are the functions $f(x)$ such that the quantity $L(f)=f(x)+f\left(\frac{1}{x}\right)$ has a ""nice"" value that makes the integral easy? For example, some uninteresting cases are: $L(\ln(x))=0$ that provides $\displaystyle\int_0^\infty \dfrac{\ln(x)}{1+x^2}\mathrm{d}x=0$ $L(\arctan(x))=\frac{\pi}{2}$ that provides $\displaystyle\int_0^\infty \dfrac{\arctan(x)}{1+x^2}\mathrm{d}x=\dfrac{\pi^2}{8}$ $L(\sin(\ln(x)))=0$ then $\displaystyle\int_0^\infty \dfrac{\sin(\ln(x))}{1+x^2}\mathrm{d}x=0$ and in general every time $g(x)$ is odd and the integral still converges, then $\displaystyle\int_0^\infty \dfrac{g(\ln(x))}{1+x^2}\mathrm{d}x=0$ I wonder if there are some other special or lesser known functions that have the charateric of having a nice $L(f)$ . Tell me if you come up with something.","Consider the integral now make a change of variable to , and so . The integral becomes and so Hence the question: what are the functions such that the quantity has a ""nice"" value that makes the integral easy? For example, some uninteresting cases are: that provides that provides then and in general every time is odd and the integral still converges, then I wonder if there are some other special or lesser known functions that have the charateric of having a nice . Tell me if you come up with something.",I=\int_0^\infty \frac{f(x)}{1+x^2}\mathrm{d}x x=\dfrac{1}{t} \mathrm{d}x=-\dfrac{1}{t^2}\mathrm{d}t I=\int_0^\infty \frac{f\left(\frac{1}{t}\right)}{1+t^2}\mathrm{d}t I=\frac{1}{2}\int_0^\infty \frac{f(x)+f\left(\frac{1}{x}\right)}{1+x^2}\mathrm{d}x f(x) L(f)=f(x)+f\left(\frac{1}{x}\right) L(\ln(x))=0 \displaystyle\int_0^\infty \dfrac{\ln(x)}{1+x^2}\mathrm{d}x=0 L(\arctan(x))=\frac{\pi}{2} \displaystyle\int_0^\infty \dfrac{\arctan(x)}{1+x^2}\mathrm{d}x=\dfrac{\pi^2}{8} L(\sin(\ln(x)))=0 \displaystyle\int_0^\infty \dfrac{\sin(\ln(x))}{1+x^2}\mathrm{d}x=0 g(x) \displaystyle\int_0^\infty \dfrac{g(\ln(x))}{1+x^2}\mathrm{d}x=0 L(f),"['calculus', 'integration']"
49,How do I integrate $\int_0^1\arctan(x)\log(\frac{1-x}{1+x})\mathrm{d}x$?,How do I integrate ?,\int_0^1\arctan(x)\log(\frac{1-x}{1+x})\mathrm{d}x,"I've recently come across an interesting integral, which is of the form: $$\int_0^1\arctan(x)\log\left(\frac{1-x}{1+x}\right)\mathrm{d}x$$ To start, I expanded the arctangent into its series expansion, then utilized the Weierstraß substitution in order to remove the fractional term from the logarithm: $$t = \frac{1-x}{1+x}$$ Finally, I'm left with this integral: $$2 \sum_{k \geq 0} \frac{(-1)^k}{2k+1} \int_0^1 \frac{(1-t)^{2k+1}}{(1+t)^{2k+3}} \log(t)\mathrm{d}t$$ Which looks an awful lot like the beta function, namely: $$B(x, y) = (1-a)^y \int_0^1 \frac{(1-t)^{x-1} t^{y-1}}{(1-at)^{x+y}} \mathrm{d}t, \quad a \leq 1$$ For the following values, the integrals are nearly identical: $$a=-1,$$ $$x=2k+2,$$ $$y=1$$ However, this is the bit where I fail to make progress. I see that the integrals are clearly just off by that logarithm, but I cannot find a relation between them in order to progress with this integral. I've tried differentiating with respect to the parameter $y$ in order to bring in that logarithm, but that obviously doesn't do much - as the parameter also lies in the denominator and causes unwanted trouble. I've also tried constructing integrals which are similar to this one, but only have the parameter $y$ in the numerator; however, I haven't been able to make much progress doing that either. These integrals end up looking nothing like the beta function.","I've recently come across an interesting integral, which is of the form: To start, I expanded the arctangent into its series expansion, then utilized the Weierstraß substitution in order to remove the fractional term from the logarithm: Finally, I'm left with this integral: Which looks an awful lot like the beta function, namely: For the following values, the integrals are nearly identical: However, this is the bit where I fail to make progress. I see that the integrals are clearly just off by that logarithm, but I cannot find a relation between them in order to progress with this integral. I've tried differentiating with respect to the parameter in order to bring in that logarithm, but that obviously doesn't do much - as the parameter also lies in the denominator and causes unwanted trouble. I've also tried constructing integrals which are similar to this one, but only have the parameter in the numerator; however, I haven't been able to make much progress doing that either. These integrals end up looking nothing like the beta function.","\int_0^1\arctan(x)\log\left(\frac{1-x}{1+x}\right)\mathrm{d}x t = \frac{1-x}{1+x} 2 \sum_{k \geq 0} \frac{(-1)^k}{2k+1} \int_0^1 \frac{(1-t)^{2k+1}}{(1+t)^{2k+3}} \log(t)\mathrm{d}t B(x, y) = (1-a)^y \int_0^1 \frac{(1-t)^{x-1} t^{y-1}}{(1-at)^{x+y}} \mathrm{d}t, \quad a \leq 1 a=-1, x=2k+2, y=1 y y","['calculus', 'integration', 'definite-integrals', 'logarithms']"
50,Integration by parts using Dirac delta functions,Integration by parts using Dirac delta functions,,"From my notes I have some background information on Canonical Commutation Relations: I can prove the first question. Though I cannot prove the next question: I will typeset this question also just in case the image is a bit hard to read: Perform the following change of variables in the integral $p^{\prime} = p + \hbar s$ and then expand the integrand in powers of $\hbar$ . Prove that to ﬁrst order in $\hbar$ we have $$\left(A_c \ast B_c\right)(x, p)=A_c\left(x,p\right)B_c\left(x,p\right)-i\hbar\frac{\partial A_c}{\partial p}\frac{\partial B_c}{\partial x}+\mathcal{O}\left(\hbar^2\right)\tag{9}$$ (Hint, you will need to remember that the Dirac delta function can be represented by $$\delta(x-x^{\prime})=\int_{-\infty}^{\infty}\frac{dk}{\left(2\pi\right)}\,e^{ik\left(x-x^{\prime}\right)}\tag{10} $$ You will also need to perform an integration by parts over the variable $x^{\prime}$ .) Here is my attempt at trying to prove eqn. $(9)$ : The previous result, (eqn. $(8)$ ) can be re-written as - $$\left(A_c \ast B_c\right)(x, p)=\int_{-\infty}^{\infty}dx^\prime\int_{-\infty}^{\infty}\frac{dp^{\prime}}{2\pi \hbar}A_c\left(x, p^{\prime}\right)B_c\left(x^\prime,p\right)e^{i\left(p^\prime-p\right)\left(x-x^\prime\right)/\hbar}$$ Now $p^{\prime}=p+hs$ , where $s$ is the new integration variable, therefore, $dp^{\prime}=\hbar ds$ , here $p$ is a constant as it is not being integrated over. Therefore, $$\left(A_c \ast B_c\right)(x, p)=\int_{-\infty}^{\infty}dx^{\prime}\int_{-\infty}^{\infty}\frac{ds}{2\pi}A_c\left(x, p+\hbar s\right)B_c\left(x^{\prime},p\right)e^{is\left(x-x^{\prime}\right)}$$ Taylor expanding the integrand in powers of $\hbar$ , $$\left(A_c \ast B_c\right)(x, p)=\int_{-\infty}^{\infty}dx^{\prime}\int_{-\infty}^{\infty}\frac{ds}{2\pi}\Big[A_c\left(x, p\right)+\hbar s\frac{\partial}{\partial p}\Big(A_c \left(x,p\right)\Big)+\mathcal{O}\left(\hbar^2\right)\Big]B_c\left(x^{\prime},p\right)e^{is\left(x-x^{\prime}\right)}$$ $$=\frac{1}{2\pi}A_c\left(x,p\right)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\int_{-\infty}^{\infty}ds\,e^{is\left(x-x^{\prime}\right)}\tag{a}$$ $$+\frac{1}{2\pi}\hbar\frac{\partial}{\partial p}\Big(A_c \left(x,p\right)\Big)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\color{blue}{\int_{-\infty}^{\infty}ds\,se^{is\left(x-x^{\prime}\right)}}\tag{b}$$ $$+\frac{1}{2\pi}\mathcal{O}\left(\hbar^2\right)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\int_{-\infty}^{\infty}ds\,e^{is\left(x-x^{\prime}\right)}\tag{c}$$ Where I have taken out factors that don't depend on the integration variables $x^{\prime}$ and $s$ and multiplied out the integral into $3$ terms, it is the integrals over $s$ I would like to focus on now: I note that $$i\frac{\partial}{\partial x^{\prime}}\left(e^{is\left(x-x^{\prime}\right)}\right)=se^{is\left(x-x^{\prime}\right)}\tag{d}$$ and the hint given in the question is, $$\delta(x-x^{\prime})=\frac{1}{2\pi}\int_{-\infty}^{\infty}ds\,e^{is\left(x-x^{\prime}\right)}\tag{e}$$ Starting with the first term, I can make use of eqn. $(e)$ , so $(\mathrm {a})$ becomes, $$\frac{1}{2\pi}A_c\left(x,p\right)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)2\pi\,\delta\left(x-x^{\prime}\right)=A_c\left(x,p\right)B_c\left(x,p\right)$$ by the sifting property of the Dirac delta 'function', which sets $x^\prime=x$ , and is the required first term in eqn. $(9)$ . Using the same logic for the third term, $(\mathrm{c})$ , things do not work out as required: $$\begin{align}\frac{1}{2\pi}\mathcal{O}\left(\hbar^2\right)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\int_{-\infty}^{\infty}ds\,e^{is\left(x-x^{\prime}\right)}&=\frac{1}{2\pi}\mathcal{O}\left(\hbar^2\right)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)2\pi\delta\left(x-x^{\prime}\right)\\&=\mathcal{O}\left(\hbar^2\right)B_c\left(x,p\right)\end{align}$$ It gets worse for the second term, $(\mathrm{b})$ , and I can't figure out what to do. I'm sure this should be done via integration by parts and using eqn. $(\mathrm{d})$ somehow along with eqn. $(\mathrm{e})$ . Just for clarity, I will focus solely on the integral of the product of functions of $s$ , marked blue in $(\mathrm{b})$ , this is what I find: $$\begin{align}\color{blue}{\int_{-\infty}^{\infty}ds\,se^{is\left(x-x^{\prime}\right)}}&=\tag{f}\bigg[-\frac{i}{x-x^{\prime}}se^{i\left(x-x^{\prime}\right)}\bigg]_{s=-\infty}^\infty-\int_{s=-\infty}^{\infty}ds\bigg[-\frac{i}{x-x^{\prime}}e^{is\left(x-x^\prime\right)}\bigg]\\&=\tag{g}\bigg[\frac{1}{x-x^{\prime}}\frac{\partial}{\partial x^{\prime}}\left(e^{is \left(x-x^{\prime}\right)}\right)\bigg]_{s=-\infty}^\infty+\frac{i}{x-x^{\prime}}\int_{s=-\infty}^{\infty}ds\,e^{is\left(x-x^\prime\right)}\\&=\tag{h}\bigg[\frac{1}{x-x^{\prime}}\frac{\partial}{\partial x^{\prime}}\left(e^{is \left(x-x^{\prime}\right)}\right)\bigg]_{s=-\infty}^\infty+\frac{2\pi i}{x-x^{\prime}}\delta\left(x-x^\prime\right)\end{align}$$ In $(\mathrm{f})$ I have used the formula for integration by parts, $$\int_{v=-\infty}^\infty udv=\Big[uv\Big]_{v=-\infty}^{\infty}-\int_{v=-\infty}^\infty vdu$$ Where, in the first term on the RHS of $(\mathrm{g})$ I used eqn. $(\mathrm{d})$ , $$se^{is\left(x-x^{\prime}\right)}=i\frac{\partial}{\partial x^{\prime}}\left(e^{is\left(x-x^{\prime}\right)}\right)$$ Lastly, in the second term of $(\mathrm{h})$ I made use of eqn. $(\mathrm{e})$ , $$\int_{-\infty}^{\infty}ds\,e^{is\left(x-x^{\prime}\right)}=2\pi\,\delta(x-x^{\prime})$$ Of course, this has all gone horribly wrong as even if I reinstate the full form of $(\mathrm{b})$ , $$\frac{1}{2\pi}\hbar\frac{\partial}{\partial p}\Big(A_c \left(x,p\right)\Big)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\color{blue}{\int_{-\infty}^{\infty}ds\,se^{is\left(x-x^{\prime}\right)}}$$ $$=\frac{1}{2\pi}\hbar\frac{\partial}{\partial p}\Big(A_c \left(x,p\right)\Big)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\color{blue}{\Bigg\{}\bigg[\frac{1}{x-x^{\prime}}\frac{\partial}{\partial x^{\prime}}\left(e^{is \left(x-x^{\prime}\right)}\right)\bigg]_{s=-\infty}^\infty+\frac{2\pi i}{x-x^{\prime}}\delta\left(x-x^\prime\right)\color{blue}{\Bigg\}}$$ both the terms in the blue curly braces are undefined, the first because of the limits and the second because the Dirac delta function sets $x=x^{\prime}$ which causes problems for the denominator. Please may I have some hints or tips on how to get the correct terms, $(\mathrm{b})$ and $(\mathrm{c})$ and hence reach the correct expression, $(9)$ ? In other words, how can I show that $$\left(A_c \ast B_c\right)(x, p)=A_c\left(x,p\right)B_c\left(x,p\right)-i\hbar\frac{\partial A_c}{\partial p}\frac{\partial B_c}{\partial x}+\mathcal{O}\left(\hbar^2\right)\,\,?$$ For reference, the part of the handwritten solution involving the Taylor expansion is written as $$\left(A_c \ast B_c\right)(x, p)=\int_{-\infty}^{\infty}dx^{\prime}\int_{-\infty}^{\infty}\frac{ds}{2\pi}\Big[A_c\left(x, p\right)+\hbar s\frac{\partial}{\partial p}\Big(A_c\left(x,p\right)\Big)\Big]B_c\left(x^{\prime},p\right)e^{is\left(x-x^{\prime}\right)}+\mathcal{O}\left(\hbar^2\right).$$ But this just seems nonsensical to me since the question specifically asked for the integrand to be Taylor expanded, so putting $\mathcal{O}\left(\hbar^2\right)$ outside the integral is not a Taylor expansion of the integrand. What have I overlooked here?","From my notes I have some background information on Canonical Commutation Relations: I can prove the first question. Though I cannot prove the next question: I will typeset this question also just in case the image is a bit hard to read: Perform the following change of variables in the integral and then expand the integrand in powers of . Prove that to ﬁrst order in we have (Hint, you will need to remember that the Dirac delta function can be represented by You will also need to perform an integration by parts over the variable .) Here is my attempt at trying to prove eqn. : The previous result, (eqn. ) can be re-written as - Now , where is the new integration variable, therefore, , here is a constant as it is not being integrated over. Therefore, Taylor expanding the integrand in powers of , Where I have taken out factors that don't depend on the integration variables and and multiplied out the integral into terms, it is the integrals over I would like to focus on now: I note that and the hint given in the question is, Starting with the first term, I can make use of eqn. , so becomes, by the sifting property of the Dirac delta 'function', which sets , and is the required first term in eqn. . Using the same logic for the third term, , things do not work out as required: It gets worse for the second term, , and I can't figure out what to do. I'm sure this should be done via integration by parts and using eqn. somehow along with eqn. . Just for clarity, I will focus solely on the integral of the product of functions of , marked blue in , this is what I find: In I have used the formula for integration by parts, Where, in the first term on the RHS of I used eqn. , Lastly, in the second term of I made use of eqn. , Of course, this has all gone horribly wrong as even if I reinstate the full form of , both the terms in the blue curly braces are undefined, the first because of the limits and the second because the Dirac delta function sets which causes problems for the denominator. Please may I have some hints or tips on how to get the correct terms, and and hence reach the correct expression, ? In other words, how can I show that For reference, the part of the handwritten solution involving the Taylor expansion is written as But this just seems nonsensical to me since the question specifically asked for the integrand to be Taylor expanded, so putting outside the integral is not a Taylor expansion of the integrand. What have I overlooked here?","p^{\prime} = p + \hbar s \hbar \hbar \left(A_c \ast B_c\right)(x, p)=A_c\left(x,p\right)B_c\left(x,p\right)-i\hbar\frac{\partial A_c}{\partial p}\frac{\partial B_c}{\partial x}+\mathcal{O}\left(\hbar^2\right)\tag{9} \delta(x-x^{\prime})=\int_{-\infty}^{\infty}\frac{dk}{\left(2\pi\right)}\,e^{ik\left(x-x^{\prime}\right)}\tag{10}
 x^{\prime} (9) (8) \left(A_c \ast B_c\right)(x, p)=\int_{-\infty}^{\infty}dx^\prime\int_{-\infty}^{\infty}\frac{dp^{\prime}}{2\pi \hbar}A_c\left(x, p^{\prime}\right)B_c\left(x^\prime,p\right)e^{i\left(p^\prime-p\right)\left(x-x^\prime\right)/\hbar} p^{\prime}=p+hs s dp^{\prime}=\hbar ds p \left(A_c \ast B_c\right)(x, p)=\int_{-\infty}^{\infty}dx^{\prime}\int_{-\infty}^{\infty}\frac{ds}{2\pi}A_c\left(x, p+\hbar s\right)B_c\left(x^{\prime},p\right)e^{is\left(x-x^{\prime}\right)} \hbar \left(A_c \ast B_c\right)(x, p)=\int_{-\infty}^{\infty}dx^{\prime}\int_{-\infty}^{\infty}\frac{ds}{2\pi}\Big[A_c\left(x, p\right)+\hbar s\frac{\partial}{\partial p}\Big(A_c \left(x,p\right)\Big)+\mathcal{O}\left(\hbar^2\right)\Big]B_c\left(x^{\prime},p\right)e^{is\left(x-x^{\prime}\right)} =\frac{1}{2\pi}A_c\left(x,p\right)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\int_{-\infty}^{\infty}ds\,e^{is\left(x-x^{\prime}\right)}\tag{a} +\frac{1}{2\pi}\hbar\frac{\partial}{\partial p}\Big(A_c \left(x,p\right)\Big)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\color{blue}{\int_{-\infty}^{\infty}ds\,se^{is\left(x-x^{\prime}\right)}}\tag{b} +\frac{1}{2\pi}\mathcal{O}\left(\hbar^2\right)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\int_{-\infty}^{\infty}ds\,e^{is\left(x-x^{\prime}\right)}\tag{c} x^{\prime} s 3 s i\frac{\partial}{\partial x^{\prime}}\left(e^{is\left(x-x^{\prime}\right)}\right)=se^{is\left(x-x^{\prime}\right)}\tag{d} \delta(x-x^{\prime})=\frac{1}{2\pi}\int_{-\infty}^{\infty}ds\,e^{is\left(x-x^{\prime}\right)}\tag{e} (e) (\mathrm {a}) \frac{1}{2\pi}A_c\left(x,p\right)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)2\pi\,\delta\left(x-x^{\prime}\right)=A_c\left(x,p\right)B_c\left(x,p\right) x^\prime=x (9) (\mathrm{c}) \begin{align}\frac{1}{2\pi}\mathcal{O}\left(\hbar^2\right)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\int_{-\infty}^{\infty}ds\,e^{is\left(x-x^{\prime}\right)}&=\frac{1}{2\pi}\mathcal{O}\left(\hbar^2\right)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)2\pi\delta\left(x-x^{\prime}\right)\\&=\mathcal{O}\left(\hbar^2\right)B_c\left(x,p\right)\end{align} (\mathrm{b}) (\mathrm{d}) (\mathrm{e}) s (\mathrm{b}) \begin{align}\color{blue}{\int_{-\infty}^{\infty}ds\,se^{is\left(x-x^{\prime}\right)}}&=\tag{f}\bigg[-\frac{i}{x-x^{\prime}}se^{i\left(x-x^{\prime}\right)}\bigg]_{s=-\infty}^\infty-\int_{s=-\infty}^{\infty}ds\bigg[-\frac{i}{x-x^{\prime}}e^{is\left(x-x^\prime\right)}\bigg]\\&=\tag{g}\bigg[\frac{1}{x-x^{\prime}}\frac{\partial}{\partial x^{\prime}}\left(e^{is \left(x-x^{\prime}\right)}\right)\bigg]_{s=-\infty}^\infty+\frac{i}{x-x^{\prime}}\int_{s=-\infty}^{\infty}ds\,e^{is\left(x-x^\prime\right)}\\&=\tag{h}\bigg[\frac{1}{x-x^{\prime}}\frac{\partial}{\partial x^{\prime}}\left(e^{is \left(x-x^{\prime}\right)}\right)\bigg]_{s=-\infty}^\infty+\frac{2\pi i}{x-x^{\prime}}\delta\left(x-x^\prime\right)\end{align} (\mathrm{f}) \int_{v=-\infty}^\infty udv=\Big[uv\Big]_{v=-\infty}^{\infty}-\int_{v=-\infty}^\infty vdu (\mathrm{g}) (\mathrm{d}) se^{is\left(x-x^{\prime}\right)}=i\frac{\partial}{\partial x^{\prime}}\left(e^{is\left(x-x^{\prime}\right)}\right) (\mathrm{h}) (\mathrm{e}) \int_{-\infty}^{\infty}ds\,e^{is\left(x-x^{\prime}\right)}=2\pi\,\delta(x-x^{\prime}) (\mathrm{b}) \frac{1}{2\pi}\hbar\frac{\partial}{\partial p}\Big(A_c \left(x,p\right)\Big)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\color{blue}{\int_{-\infty}^{\infty}ds\,se^{is\left(x-x^{\prime}\right)}} =\frac{1}{2\pi}\hbar\frac{\partial}{\partial p}\Big(A_c \left(x,p\right)\Big)\int_{-\infty}^{\infty}dx^{\prime}B_c\left(x^{\prime},p\right)\color{blue}{\Bigg\{}\bigg[\frac{1}{x-x^{\prime}}\frac{\partial}{\partial x^{\prime}}\left(e^{is \left(x-x^{\prime}\right)}\right)\bigg]_{s=-\infty}^\infty+\frac{2\pi i}{x-x^{\prime}}\delta\left(x-x^\prime\right)\color{blue}{\Bigg\}} x=x^{\prime} (\mathrm{b}) (\mathrm{c}) (9) \left(A_c \ast B_c\right)(x, p)=A_c\left(x,p\right)B_c\left(x,p\right)-i\hbar\frac{\partial A_c}{\partial p}\frac{\partial B_c}{\partial x}+\mathcal{O}\left(\hbar^2\right)\,\,? \left(A_c \ast B_c\right)(x, p)=\int_{-\infty}^{\infty}dx^{\prime}\int_{-\infty}^{\infty}\frac{ds}{2\pi}\Big[A_c\left(x, p\right)+\hbar s\frac{\partial}{\partial p}\Big(A_c\left(x,p\right)\Big)\Big]B_c\left(x^{\prime},p\right)e^{is\left(x-x^{\prime}\right)}+\mathcal{O}\left(\hbar^2\right). \mathcal{O}\left(\hbar^2\right)","['calculus', 'integration', 'solution-verification', 'taylor-expansion', 'dirac-delta']"
51,Does $ln(x) +2$ composed with itself infinitely have a limit?,Does  composed with itself infinitely have a limit?,ln(x) +2,"I was bored and playing around with my calculator, and I decided to take a number, take its natural log, add 2, and then repeat. I tried numbers as small as 5 and numbers larger than a billion, and they all seemed to end the same way. The numbers basically stopped decreasing when they get to between 1 and 4, and then stay in that interval. If $f^{{\circ}n}(x)$ is $f(x)$ composed with itself $n$ times and $f(x)=ln(x)+2$ , then does this limit exist? $$\lim_{n\to{\infty}}f^{{\circ}n}(x)$$ And if it does, what happens if you replace 2 with an arbitrary constant? By the way, the last Calc class I completed was Calc 2, if you need to know what math level I'm at.","I was bored and playing around with my calculator, and I decided to take a number, take its natural log, add 2, and then repeat. I tried numbers as small as 5 and numbers larger than a billion, and they all seemed to end the same way. The numbers basically stopped decreasing when they get to between 1 and 4, and then stay in that interval. If is composed with itself times and , then does this limit exist? And if it does, what happens if you replace 2 with an arbitrary constant? By the way, the last Calc class I completed was Calc 2, if you need to know what math level I'm at.",f^{{\circ}n}(x) f(x) n f(x)=ln(x)+2 \lim_{n\to{\infty}}f^{{\circ}n}(x),"['calculus', 'limits']"
52,Is there any other method to show that $\int_{0}^{\frac{\pi}{2}} x \ln (\sin x) d x =-\frac{\pi^{2}}{8} \ln 2+\frac{7}{16}\zeta(3)?$,Is there any other method to show that,\int_{0}^{\frac{\pi}{2}} x \ln (\sin x) d x =-\frac{\pi^{2}}{8} \ln 2+\frac{7}{16}\zeta(3)?,"Noting that the evaluation of the integral can be simplified by the Fourier series of $\ln(\sin x)$ , $$\ln (\sin x)+\ln 2=-\sum_{k=1}^{\infty} \frac{\cos (2 k x)}{k}$$ Multiplying the equation by $x$ followed by integration from $0$ to $\infty$ , we have $$ \begin{aligned} \int_{0}^{\frac{\pi}{2}} x \ln (\sin x) d x+\int_{0}^{\frac{\pi}{2}} x\ln 2 d x&=-\sum_{k=1}^{\infty} \int_{0}^{\frac{\pi}{2}} \frac{x \cos (2 k x)}{k} d x\\ \int_{0}^{\frac{\pi}{2}} x \ln (\sin x) d x+\left[\frac{x^{2}}{2} \ln 2\right]_{0}^{\frac{\pi}{2}}&=-\sum_{k=1}^{\infty} \frac{1}{2 k^{2}} \int_{0}^{\frac{\pi}{2}} x d(\sin 2 k x)\\ \int_{0}^{\frac{\pi}{2}} x \ln (\sin x) d x&=-\frac{\pi^{2}}{8} \ln 2-\frac{1}{2} \sum_{k=1}^{\infty} \frac{1}{k^{2}}\left[\frac{\cos 2(x)}{2 k}\right]_{0}^{\frac{\pi}{2}} \\ &=-\frac{\pi^{2}}{8} \ln 2-\frac{1}{4} \sum_{k=1}^{\infty} \frac{(-1)^{k}-1}{k^{3}}\\ &=-\frac{\pi^{2}}{8} \ln 2+\frac{1}{4}\left(\sum_{k=1}^{\infty} \frac{2}{(2 k+1)^{3}}\right)\\ &=-\frac{\pi^{2}}{8} \ln 2+\frac{1}{2}\left[\sum_{k=1}^{\infty} \frac{1}{k^{3}}-\sum_{k=1}^{\infty} \frac{1}{(2 k)^{3}}\right]\\ &=-\frac{\pi^{2}}{8} \ln 2+\frac{7}{16}\zeta(3) \blacksquare \end{aligned} $$ Furthermore, $$ \begin{aligned} \int_0^{\frac{\pi}{2}} x \ln (\cos x) d x&=\frac{\pi}{2} \int_0^{\frac{\pi}{2}} \ln (\sin x)-\int_0^{\frac{\pi}{2}} x \ln (\sin x) d x \\ &=-\frac{\pi^2}{4} \ln 2-\left(-\frac{\pi^2}{8} \ln 2+\frac{7}{16}\zeta(3)\right) \\ &=-\frac{\pi^2}{8} \ln 2-\frac{7}{16} \zeta(3) \end{aligned} $$ and $$ \int_0^{\frac{\pi}{2}} x \ln (\tan x) d x=\int_0^{\frac{\pi}{2}} x \ln (\sin x) d x-\int_0^{\frac{\pi}{2}} x \ln (\cos x) d x=\frac{7}{8}\zeta(3) $$","Noting that the evaluation of the integral can be simplified by the Fourier series of , Multiplying the equation by followed by integration from to , we have Furthermore, and","\ln(\sin x) \ln (\sin x)+\ln 2=-\sum_{k=1}^{\infty} \frac{\cos (2 k x)}{k} x 0 \infty 
\begin{aligned}
\int_{0}^{\frac{\pi}{2}} x \ln (\sin x) d x+\int_{0}^{\frac{\pi}{2}} x\ln 2 d x&=-\sum_{k=1}^{\infty} \int_{0}^{\frac{\pi}{2}} \frac{x \cos (2 k x)}{k} d x\\
\int_{0}^{\frac{\pi}{2}} x \ln (\sin x) d x+\left[\frac{x^{2}}{2} \ln 2\right]_{0}^{\frac{\pi}{2}}&=-\sum_{k=1}^{\infty} \frac{1}{2 k^{2}} \int_{0}^{\frac{\pi}{2}} x d(\sin 2 k x)\\
\int_{0}^{\frac{\pi}{2}} x \ln (\sin x) d x&=-\frac{\pi^{2}}{8} \ln 2-\frac{1}{2} \sum_{k=1}^{\infty} \frac{1}{k^{2}}\left[\frac{\cos 2(x)}{2 k}\right]_{0}^{\frac{\pi}{2}} \\
&=-\frac{\pi^{2}}{8} \ln 2-\frac{1}{4} \sum_{k=1}^{\infty} \frac{(-1)^{k}-1}{k^{3}}\\
&=-\frac{\pi^{2}}{8} \ln 2+\frac{1}{4}\left(\sum_{k=1}^{\infty} \frac{2}{(2 k+1)^{3}}\right)\\
&=-\frac{\pi^{2}}{8} \ln 2+\frac{1}{2}\left[\sum_{k=1}^{\infty} \frac{1}{k^{3}}-\sum_{k=1}^{\infty} \frac{1}{(2 k)^{3}}\right]\\
&=-\frac{\pi^{2}}{8} \ln 2+\frac{7}{16}\zeta(3) \blacksquare
\end{aligned}
 
\begin{aligned}
\int_0^{\frac{\pi}{2}} x \ln (\cos x) d x&=\frac{\pi}{2} \int_0^{\frac{\pi}{2}} \ln (\sin x)-\int_0^{\frac{\pi}{2}} x \ln (\sin x) d x \\
&=-\frac{\pi^2}{4} \ln 2-\left(-\frac{\pi^2}{8} \ln 2+\frac{7}{16}\zeta(3)\right) \\
&=-\frac{\pi^2}{8} \ln 2-\frac{7}{16} \zeta(3)
\end{aligned}
 
\int_0^{\frac{\pi}{2}} x \ln (\tan x) d x=\int_0^{\frac{\pi}{2}} x \ln (\sin x) d x-\int_0^{\frac{\pi}{2}} x \ln (\cos x) d x=\frac{7}{8}\zeta(3)
","['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'zeta-functions']"
53,Expected length of sum of vectors,Expected length of sum of vectors,,"Suppose we have $n$ arbitrary unit vectors $v_1, v_2, v_3, \dots, v_n$ . (Here, a ""random"" unit vector is defined as $\langle \cos(x), \sin(x) \rangle$ for a random $x$ such that $0 \leq x < 2 \pi$ ). Evaluate the expected value of $$\left|\sum_{i=1}^{n}v_i\right|$$ where $|v|$ denotes the magnitude of $v$ . For $1$ vector, the answer is trivially $1$ . For $2$ vectors, we could fix $v_1$ to the $x$ axis, and the answer would be $$\frac{1}{2\pi} \int_{0}^{2\pi}\left(\sqrt{\left(1+\cos\left(x\right)\right)^{2}+\sin\left(x\right)^{2}}\right)dx$$ First, let us evaluate the numerator. $$\begin{align}&\int_{0}^{2\pi}\left(\sqrt{\left(1+\cos\left(x\right)\right)^{2}+\sin\left(x\right)^{2}}\right)dx \\ &=\int_{0}^{2\pi}\left(\sqrt{2+2\cos\left(x\right)}\right)dx \\ &=2\cdot\int_{0}^{2\pi}\left(\sqrt{\frac{1+\cos\left(x\right)}{2}}\right)dx \\ &=2\cdot\int_{0}^{2\pi}\left(\left|\cos\left(\frac{x}{2}\right)\right|\right)dx \\ &=2\cdot\int_{-\pi}^{\pi}\left(\cos\left(\frac{x}{2}\right)\right)dx \\ &=4\sin\left(\frac{\pi}{2}\right)-4\sin\left(-\frac{\pi}{2}\right) \\ &=8 \end{align}$$ Then, our answer for $2$ vectors would be $\frac{8}{2\pi} = \frac{4}{\pi}$ . For $3$ vectors, we have $$\frac{1}{4\pi^{2}} \int_{0}^{2\pi}\int_{0}^{2\pi}\left(\sqrt{\left(1+\cos\left(x\right)+\cos\left(y\right)\right)^{2}+\left(\sin\left(x\right)+\sin\left(y\right)\right)^{2}}\right)dx\ dy$$ This seems hard to understand, does it have an elementary answer or a way of approaching?","Suppose we have arbitrary unit vectors . (Here, a ""random"" unit vector is defined as for a random such that ). Evaluate the expected value of where denotes the magnitude of . For vector, the answer is trivially . For vectors, we could fix to the axis, and the answer would be First, let us evaluate the numerator. Then, our answer for vectors would be . For vectors, we have This seems hard to understand, does it have an elementary answer or a way of approaching?","n v_1, v_2, v_3, \dots, v_n \langle \cos(x), \sin(x) \rangle x 0 \leq x < 2 \pi \left|\sum_{i=1}^{n}v_i\right| |v| v 1 1 2 v_1 x \frac{1}{2\pi} \int_{0}^{2\pi}\left(\sqrt{\left(1+\cos\left(x\right)\right)^{2}+\sin\left(x\right)^{2}}\right)dx \begin{align}&\int_{0}^{2\pi}\left(\sqrt{\left(1+\cos\left(x\right)\right)^{2}+\sin\left(x\right)^{2}}\right)dx \\
&=\int_{0}^{2\pi}\left(\sqrt{2+2\cos\left(x\right)}\right)dx \\
&=2\cdot\int_{0}^{2\pi}\left(\sqrt{\frac{1+\cos\left(x\right)}{2}}\right)dx \\
&=2\cdot\int_{0}^{2\pi}\left(\left|\cos\left(\frac{x}{2}\right)\right|\right)dx \\
&=2\cdot\int_{-\pi}^{\pi}\left(\cos\left(\frac{x}{2}\right)\right)dx \\
&=4\sin\left(\frac{\pi}{2}\right)-4\sin\left(-\frac{\pi}{2}\right) \\
&=8 \end{align} 2 \frac{8}{2\pi} = \frac{4}{\pi} 3 \frac{1}{4\pi^{2}} \int_{0}^{2\pi}\int_{0}^{2\pi}\left(\sqrt{\left(1+\cos\left(x\right)+\cos\left(y\right)\right)^{2}+\left(\sin\left(x\right)+\sin\left(y\right)\right)^{2}}\right)dx\ dy","['calculus', 'linear-algebra', 'multivariable-calculus', 'expected-value']"
54,Finding the asymptotic behavior of a function defined implicitly,Finding the asymptotic behavior of a function defined implicitly,,"I encountered this when trying to solve a number theory problem. I have two variables $x,y$ related by $$(\ln(x))^{y+1}=(\ln(xy))^y$$ and I want to know how big $y(x)$ is as $x\to\infty$ . Ideally I want to know that $y(x)\sim\ln(x)$ or $y(x)\sim \sqrt{x}$ or whatever it is. But if that's not possible, a tight lower bound would suffice. I've messed with this expression enough that I managed to convince myself it isn't possible to isolate either variable, except maybe using something like Lambert's W function, and even that I wasn't able to do. So the remaining alternative is to try to solve it as a problem about an implicit function. This sounds like something that is possible with standard calculus tools.","I encountered this when trying to solve a number theory problem. I have two variables related by and I want to know how big is as . Ideally I want to know that or or whatever it is. But if that's not possible, a tight lower bound would suffice. I've messed with this expression enough that I managed to convince myself it isn't possible to isolate either variable, except maybe using something like Lambert's W function, and even that I wasn't able to do. So the remaining alternative is to try to solve it as a problem about an implicit function. This sounds like something that is possible with standard calculus tools.","x,y (\ln(x))^{y+1}=(\ln(xy))^y y(x) x\to\infty y(x)\sim\ln(x) y(x)\sim \sqrt{x}","['calculus', 'asymptotics', 'implicit-function']"
55,Why do the antiderivatives of $y=1$ follow $e^{x}$?,Why do the antiderivatives of  follow ?,y=1 e^{x},"If you integrate $y=1$ , you get $x$ . If you integrate that , you get $\frac{x^{2}}{2}$ , following the power rule. If you continue this, integrating over and over, the antiderivatives are: $1$ , $x$ , $\frac{x^{2}}{2}$ , $\frac{x^{3}}{6}$ , $\frac{x^{4}}{24}$ , and so on. It follows the pattern of $\frac{x^{n}}{n!}$ , which happens to be the infinite polynomial of $e^{x}$ . Just by integrating $y=1$ , you follow the $exp()$ function. Is there any intuitive way why this is?","If you integrate , you get . If you integrate that , you get , following the power rule. If you continue this, integrating over and over, the antiderivatives are: , , , , , and so on. It follows the pattern of , which happens to be the infinite polynomial of . Just by integrating , you follow the function. Is there any intuitive way why this is?",y=1 x \frac{x^{2}}{2} 1 x \frac{x^{2}}{2} \frac{x^{3}}{6} \frac{x^{4}}{24} \frac{x^{n}}{n!} e^{x} y=1 exp(),"['calculus', 'integration', 'exponential-function', 'indefinite-integrals']"
56,Prove $\ln x\ln(1-x)\le \ln^2 2$.,Prove .,\ln x\ln(1-x)\le \ln^2 2,"Define $f(x)=\ln x\ln(1-x)$ where $x \in (0,1)$ . Note that $f(x)$ is symmetric with respect to $x=\frac{1}{2}$ .Thus we may only study the range of $f(x)$ over $\left(0,\frac{1}{2}\right]$ . Now, by differentiating we obtain $$f'(x)=\frac{(1-x)\ln(1-x)-x\ln x}{x(1-x)}.$$ Obviously, $f'(x)$ has a zero at $x=\frac{1}{2}$ . But can we conclude that this is unique？","Define where . Note that is symmetric with respect to .Thus we may only study the range of over . Now, by differentiating we obtain Obviously, has a zero at . But can we conclude that this is unique？","f(x)=\ln x\ln(1-x) x \in (0,1) f(x) x=\frac{1}{2} f(x) \left(0,\frac{1}{2}\right] f'(x)=\frac{(1-x)\ln(1-x)-x\ln x}{x(1-x)}. f'(x) x=\frac{1}{2}","['calculus', 'inequality']"
57,A Difficult Area Problem involving a Circle and a Square,A Difficult Area Problem involving a Circle and a Square,,"A few days ago, I encountered the following problem: After a little bit of thinking, I managed to come up with the following solution: Rotate the square $90^\circ$ clockwise and let the new bottom left corner of the square be $(0,0)$ . The circle inscribed in the square is hence centered at $(5,5)$ with a radius of $5$ . The circle equation thus becomes $(x-5)^{2} + (y-5)^{2} = 25 \Rightarrow y = 5 + \sqrt{25 - (x-5)^{2}}$ in the first quadrant. Similarly for the quarter circle, the equation becomes $y = \sqrt{100-x^2}$ . The graph hence looks like this: My intention is to find the shaded area in the above graph. To do so, first I find $X$ by equating $5 + \sqrt{25 - (x-5)^{2}} = \sqrt{100-x^2} \Rightarrow x=\frac{25 - 5\sqrt{7}}{4}$ . From this, I calculate the area of the shaded region as follows: $$\text{Area} = (10 \cdot \frac{25 - 5\sqrt{7}}{4} - \int_0^\frac{25 - 5\sqrt{7}}{4} \sqrt{100-x^2} \,\mathrm{d}x) + (10 \cdot (5 - \frac{25 - 5\sqrt{7}}{4}) - \int_\frac{25 - 5\sqrt{7}}{4}^5 5 + \sqrt{25 - (x-5)^{2}} \,\mathrm{d}x) \approx 0.7285$$ Now, the diagram looks like this: From here, I figured out the shaded area as follows: $$\text{Area} \approx 10^{2} - \frac{\pi(10^{2})}{4} - (\frac{10^{2} - \pi(5^{2})}{4} + 2 \times 0.7285) \approx \boxed{14.6 \:  \text{cm}^{2}}$$ While I did figure out the correct solution, I find my approach to be rather lengthy. I was wondering if there is a quicker, simpler and more concise method (that probably does not require Calculus) that one can use and I would highly appreciate any answers pertaining to the same.","A few days ago, I encountered the following problem: After a little bit of thinking, I managed to come up with the following solution: Rotate the square clockwise and let the new bottom left corner of the square be . The circle inscribed in the square is hence centered at with a radius of . The circle equation thus becomes in the first quadrant. Similarly for the quarter circle, the equation becomes . The graph hence looks like this: My intention is to find the shaded area in the above graph. To do so, first I find by equating . From this, I calculate the area of the shaded region as follows: Now, the diagram looks like this: From here, I figured out the shaded area as follows: While I did figure out the correct solution, I find my approach to be rather lengthy. I was wondering if there is a quicker, simpler and more concise method (that probably does not require Calculus) that one can use and I would highly appreciate any answers pertaining to the same.","90^\circ (0,0) (5,5) 5 (x-5)^{2} + (y-5)^{2} = 25 \Rightarrow y = 5 + \sqrt{25 - (x-5)^{2}} y = \sqrt{100-x^2} X 5 + \sqrt{25 - (x-5)^{2}} = \sqrt{100-x^2} \Rightarrow x=\frac{25 - 5\sqrt{7}}{4} \text{Area} = (10 \cdot \frac{25 - 5\sqrt{7}}{4} - \int_0^\frac{25 - 5\sqrt{7}}{4} \sqrt{100-x^2} \,\mathrm{d}x) + (10 \cdot (5 - \frac{25 - 5\sqrt{7}}{4}) - \int_\frac{25 - 5\sqrt{7}}{4}^5 5 + \sqrt{25 - (x-5)^{2}} \,\mathrm{d}x) \approx 0.7285 \text{Area} \approx 10^{2} - \frac{\pi(10^{2})}{4} - (\frac{10^{2} - \pi(5^{2})}{4} + 2 \times 0.7285) \approx \boxed{14.6 \:  \text{cm}^{2}}","['calculus', 'algebra-precalculus']"
58,Solving $\frac{dy}{dx}=1+(a_mx^m+a_{m-1}x^{m-1}+...+a_0)y^2$,Solving,\frac{dy}{dx}=1+(a_mx^m+a_{m-1}x^{m-1}+...+a_0)y^2,"I have a problem with the following equation, $\frac{dy}{dx}=1+P_m(x)y^2$ Where $P_m(x)$ is a polynomial function. I have solution for $P_m(x)=x$ using Mathematica, and Prof @Claude Leibovici solved for me the special case when $P_m(x)=x^n$ . Regrading to Prof @Claude Leibovici useful answer, I need a much general solution for $P_m(x)=a_mx^m+a_{m-1}x^{m-1}+...+a_0$ The equation can be rewritten by parametrizeing $y=\frac{u}{u'}$ as $u''+P_m(x)u=0$ ; i want declare that problem i introduced is a simplified form from  such equation! I need absoulte solution (not approximate) for the case $P_m(x)=a_mx^m+a_{m-1}x^{m-1}+...+a_0$ . And its ok if the solution is in special functions (becacuse, actually, its the only way to do it). Can anyone here help me please? Thank you guys","I have a problem with the following equation, Where is a polynomial function. I have solution for using Mathematica, and Prof @Claude Leibovici solved for me the special case when . Regrading to Prof @Claude Leibovici useful answer, I need a much general solution for The equation can be rewritten by parametrizeing as ; i want declare that problem i introduced is a simplified form from  such equation! I need absoulte solution (not approximate) for the case . And its ok if the solution is in special functions (becacuse, actually, its the only way to do it). Can anyone here help me please? Thank you guys",\frac{dy}{dx}=1+P_m(x)y^2 P_m(x) P_m(x)=x P_m(x)=x^n P_m(x)=a_mx^m+a_{m-1}x^{m-1}+...+a_0 y=\frac{u}{u'} u''+P_m(x)u=0 P_m(x)=a_mx^m+a_{m-1}x^{m-1}+...+a_0,"['calculus', 'ordinary-differential-equations']"
59,Challenging Sum: compute $\sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)$,Challenging Sum: compute,\sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right),"How to prove $$\sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)=\frac74\zeta(2)\zeta(3)-\frac{279}{16}\zeta(5)+\frac43\ln^3(2)\zeta(2)-7\ln^2(2)\zeta(3)\\+\frac{53}4\ln(2)\zeta(4)-\frac2{15}\ln^5(2)+16\operatorname{Li}_5\left(\frac12\right)$$ where $H_n^{(q)}=\sum_{k=1}^n\frac{1}{k^q}$ is the generalized harmonic number, $\operatorname{Li}_a(x)=\sum_{k=1}^\infty\frac{x^k}{k^a}$ is the polylogarithmic function and $\zeta$ is the Riemann zeta function. This problem was proposed by Cornel and no solution has been submitted yet. I managed to convert it to a double integral but it seems tough to crack. Here is what I did: Using the integral representation of the polygamma function: $$\int_0^1\frac{x^n\ln^a(x)}{1-x}dx=-\psi^{(a)}(n+1)=(-1)^a a!\left(\zeta(a+1)-H_n^{(a+1)}\right)$$ With $a=2$ we have $$\zeta(3)-H_n^{(3)}=\frac12\int_0^1\frac{x^n\ln^2(x)}{1-x}dx\overset{x=y^2}{=}4\int_0^1\frac{y^{2n+1}\ln^2(y)}{1-y^2}dy$$ multiply both sides by $\frac{H_n}{2n+1}$ then sum up we get $$\sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)=4\int_0^1\frac{\ln^2(y)}{1-y^2}\left(\sum_{n=1}^\infty\frac{y^{2n+1}H_n}{2n+1}\right)dy$$ we have $$\sum_{n=1}^\infty \frac{y^{2n+1}H_n}{2n+1}=-\int_0^y\frac{\ln(1-x^2)}{1-x^2}dx$$ which follows from integrating $\sum_{n=1}^\infty x^{2n}H_n=-\frac{\ln(1-x^2)}{1-x^2}$ from $x=0$ to $x=y$ . so $$\sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)=-4\int_0^1\int_0^y\frac{\ln^2(y)\ln(1-x^2)}{(1-y^2)(1-x^2)}dxdy$$ $$=-4\int_0^1\frac{\ln(1-x^2)}{1-x^2}\left(\int_x^1\frac{\ln^2(y)}{1-y^2}dy\right)dx$$ For the inner integral, Mathematica gives $$\int_x^1\frac{\ln^2(y)}{1-y^2}dy\\=\operatorname{Li}_3(-x)-\operatorname{Li}_3(x)-\ln(x)\operatorname{Li}_2(-x)+\ln(x)\operatorname{Li}_2(x)-\ln^2(x)\tanh^{-1}(x)+\frac74\zeta(3)$$ and the integral turned out very complicated. So any good idea how to approach the harmonic series or the integral? Thank you.","How to prove where is the generalized harmonic number, is the polylogarithmic function and is the Riemann zeta function. This problem was proposed by Cornel and no solution has been submitted yet. I managed to convert it to a double integral but it seems tough to crack. Here is what I did: Using the integral representation of the polygamma function: With we have multiply both sides by then sum up we get we have which follows from integrating from to . so For the inner integral, Mathematica gives and the integral turned out very complicated. So any good idea how to approach the harmonic series or the integral? Thank you.",\sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)=\frac74\zeta(2)\zeta(3)-\frac{279}{16}\zeta(5)+\frac43\ln^3(2)\zeta(2)-7\ln^2(2)\zeta(3)\\+\frac{53}4\ln(2)\zeta(4)-\frac2{15}\ln^5(2)+16\operatorname{Li}_5\left(\frac12\right) H_n^{(q)}=\sum_{k=1}^n\frac{1}{k^q} \operatorname{Li}_a(x)=\sum_{k=1}^\infty\frac{x^k}{k^a} \zeta \int_0^1\frac{x^n\ln^a(x)}{1-x}dx=-\psi^{(a)}(n+1)=(-1)^a a!\left(\zeta(a+1)-H_n^{(a+1)}\right) a=2 \zeta(3)-H_n^{(3)}=\frac12\int_0^1\frac{x^n\ln^2(x)}{1-x}dx\overset{x=y^2}{=}4\int_0^1\frac{y^{2n+1}\ln^2(y)}{1-y^2}dy \frac{H_n}{2n+1} \sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)=4\int_0^1\frac{\ln^2(y)}{1-y^2}\left(\sum_{n=1}^\infty\frac{y^{2n+1}H_n}{2n+1}\right)dy \sum_{n=1}^\infty \frac{y^{2n+1}H_n}{2n+1}=-\int_0^y\frac{\ln(1-x^2)}{1-x^2}dx \sum_{n=1}^\infty x^{2n}H_n=-\frac{\ln(1-x^2)}{1-x^2} x=0 x=y \sum_{n=1}^\infty\frac{H_n}{2n+1}\left(\zeta(3)-H_n^{(3)}\right)=-4\int_0^1\int_0^y\frac{\ln^2(y)\ln(1-x^2)}{(1-y^2)(1-x^2)}dxdy =-4\int_0^1\frac{\ln(1-x^2)}{1-x^2}\left(\int_x^1\frac{\ln^2(y)}{1-y^2}dy\right)dx \int_x^1\frac{\ln^2(y)}{1-y^2}dy\\=\operatorname{Li}_3(-x)-\operatorname{Li}_3(x)-\ln(x)\operatorname{Li}_2(-x)+\ln(x)\operatorname{Li}_2(x)-\ln^2(x)\tanh^{-1}(x)+\frac74\zeta(3),"['calculus', 'integration', 'sequences-and-series', 'harmonic-numbers', 'polylogarithm']"
60,Why do connected oriented manifolds have compactly supported forms with integral one but with support contained in a given open proper subset?,Why do connected oriented manifolds have compactly supported forms with integral one but with support contained in a given open proper subset?,,"My book is From Calculus to Cohomology by Ib Madsen and Jørgen Tornehave. It seems to be claimed In the proof of Lemma 10.17 : For every proper open subset $W$ of $\mathbb R^n$ , there is an $\omega \in \Omega_c^{n}(\mathbb R^n)$ , namely the "" $\omega_1$ "" in the proof, where $\int_{\mathbb R^n} \omega = 1$ and $\text{supp} \ \omega \subseteq W$ . In the proof of Theorem 11.9 : For a compact connected oriented smooth n-manifold $M$ and for every open subset $U$ of $M$ , there is an $\omega \in \Omega_c^{n}(M) = \Omega^{n}(M)$ , where $\int_M \omega = 1$ and $\text{supp} \ \omega \subseteq U$ (I don't believe this is dependent on the particular $U$ from Lemma 11.8 ). Question : Why? Please try to answer using the tools in the book such as Theorem 10.13 (or Corollary 10.14) , Lemma 10.15 , the last sentence of this or Lemma 10.3(ii) . I think I'm missing something obvious about how such $\omega$ exists because the authors state it so naturally. Is the fact of the existence of such $\omega$ actually not obvious to the reader at this point in the text? For non-obvious facts, I think authors would usually say something like ""First/next, observe that (insert fact), the proof of which is left to the reader/to the exercises"". Here are my thoughts (assuming I understand right): I think (2) follows from Theorem 10.13 (or Corollary 10.14) . I get $\tau \in \Omega_c^{n}(M)$ , where $\int_{M} \tau = 1$ and $\text{supp} \ \tau \subseteq M$ . Choose $\omega$ to be the zero extension of $\tau|_{U}$ to $\tilde{\tau|_{U}} = \tau|_{U}1_{U} + 0 \ 1_{U^c}$ . Similarly, (1) would follow from Lemma 10.15 : I get $\tau \in \Omega_c^{n}(\mathbb R^n)$ , $\int_{\mathbb R^n} \tau = 1$ , $\text{supp} \ \tau \subseteq \mathbb R^n$ , and then $\omega = \tilde{\tau|_{W}} = \tau|_{W}1_{W} + 0 \ 1_{W^c}$ . For (2), instead of applying Theorem 10.13 to $M$ , I'll apply Theorem 10.13 to $U$ , where the proof of Theorem 11.9 says we may actually be assume $U$ to be connected. We get $\gamma \in \Omega_c^n(U)$ , where $\int_{U} \gamma = 1$ and $\text{supp} \ \gamma \subseteq U$ . Let $\psi = \gamma|_{\text{supp} \gamma}$ , the restriction of $\gamma$ to its support. Denote the zero extensions of $\gamma$ and $\psi$ as $\tilde{\gamma} = \gamma 1_{U} + 0 \ 1_{M \setminus U}$ and $\tilde{\psi} = \psi 1_{\text{supp} \gamma} + 0 \ 1_{M \setminus \text{supp} \gamma}$ . Observe $\tilde{\psi} = \tilde{\gamma}$ (like here ), and both are smooth by the last sentence of this . Choose $\omega = \tilde{\psi} = \tilde{\gamma}$ : As $\omega = \tilde{\psi}$ , $\omega$ will satisfy $\text{supp} \ \omega \subseteq U$ . As $\omega = \tilde{\gamma}$ , $\omega$ will satisfy $\int_{M} \omega = 1$ because $\int_{M} \tilde{\gamma} = \int_{U} \gamma$ by Lemma 10.3(ii) . But with this method, how do we argue similarly for (1), where the proof of Lemma 10.17 does not say that we may assume $W$ is connected?","My book is From Calculus to Cohomology by Ib Madsen and Jørgen Tornehave. It seems to be claimed In the proof of Lemma 10.17 : For every proper open subset of , there is an , namely the "" "" in the proof, where and . In the proof of Theorem 11.9 : For a compact connected oriented smooth n-manifold and for every open subset of , there is an , where and (I don't believe this is dependent on the particular from Lemma 11.8 ). Question : Why? Please try to answer using the tools in the book such as Theorem 10.13 (or Corollary 10.14) , Lemma 10.15 , the last sentence of this or Lemma 10.3(ii) . I think I'm missing something obvious about how such exists because the authors state it so naturally. Is the fact of the existence of such actually not obvious to the reader at this point in the text? For non-obvious facts, I think authors would usually say something like ""First/next, observe that (insert fact), the proof of which is left to the reader/to the exercises"". Here are my thoughts (assuming I understand right): I think (2) follows from Theorem 10.13 (or Corollary 10.14) . I get , where and . Choose to be the zero extension of to . Similarly, (1) would follow from Lemma 10.15 : I get , , , and then . For (2), instead of applying Theorem 10.13 to , I'll apply Theorem 10.13 to , where the proof of Theorem 11.9 says we may actually be assume to be connected. We get , where and . Let , the restriction of to its support. Denote the zero extensions of and as and . Observe (like here ), and both are smooth by the last sentence of this . Choose : As , will satisfy . As , will satisfy because by Lemma 10.3(ii) . But with this method, how do we argue similarly for (1), where the proof of Lemma 10.17 does not say that we may assume is connected?",W \mathbb R^n \omega \in \Omega_c^{n}(\mathbb R^n) \omega_1 \int_{\mathbb R^n} \omega = 1 \text{supp} \ \omega \subseteq W M U M \omega \in \Omega_c^{n}(M) = \Omega^{n}(M) \int_M \omega = 1 \text{supp} \ \omega \subseteq U U \omega \omega \tau \in \Omega_c^{n}(M) \int_{M} \tau = 1 \text{supp} \ \tau \subseteq M \omega \tau|_{U} \tilde{\tau|_{U}} = \tau|_{U}1_{U} + 0 \ 1_{U^c} \tau \in \Omega_c^{n}(\mathbb R^n) \int_{\mathbb R^n} \tau = 1 \text{supp} \ \tau \subseteq \mathbb R^n \omega = \tilde{\tau|_{W}} = \tau|_{W}1_{W} + 0 \ 1_{W^c} M U U \gamma \in \Omega_c^n(U) \int_{U} \gamma = 1 \text{supp} \ \gamma \subseteq U \psi = \gamma|_{\text{supp} \gamma} \gamma \gamma \psi \tilde{\gamma} = \gamma 1_{U} + 0 \ 1_{M \setminus U} \tilde{\psi} = \psi 1_{\text{supp} \gamma} + 0 \ 1_{M \setminus \text{supp} \gamma} \tilde{\psi} = \tilde{\gamma} \omega = \tilde{\psi} = \tilde{\gamma} \omega = \tilde{\psi} \omega \text{supp} \ \omega \subseteq U \omega = \tilde{\gamma} \omega \int_{M} \omega = 1 \int_{M} \tilde{\gamma} = \int_{U} \gamma W,"['calculus', 'integration']"
61,A trig integral with a tangent substitution,A trig integral with a tangent substitution,,"From Complex Function Theory by Palka, an example shows for positive integers $n$ that $$\int_0^\pi \sin^{2n}t \; dt=\frac{\pi}{4}\binom{2n}{n}$$ using the Residue Thm, and I understood his derivation. But he went on to say that this can be found using familiar techniques, he mentions the substitution $u= \tan (t/2)$ and to do partial fractions. I like attempting to evaluate integrals b/c they often involve clever tricks (that I usually can't think of, but appreciate once I see), so I wanted to give this one a try. Using the suggested substitution $$\cos t=2 \cos^2 \frac{t}{2}-1= \frac{2}{u^2+1}-1$$ and $2du= \sec^2(t/2)$ $\leftrightarrow$ $dt=2du/(u^2+1)$ (converting from tan to cos I drew a right triangle w/ legs 1 and $u$ ), so $$ \begin{split} \int_0^\pi \sin^{2n}t \; dt =& \int_0^\pi ( \sin^2t)^n \; dt= \int_0^\pi \big( \frac{1- \cos 2t}{2}\big)^n \; dt \\ =&  \frac{1}{2^{n+1}}\int_0^{2 \pi}(1- \cos t)^n \; dt = \frac{1}{2^{n+1}}\int_{- \pi}^\pi (1- \cos t)^n \; dt \\ =& \frac{1}{2^{n+1}}\int_{- \infty}^\infty \big( 1- \frac{2}{u^2+1}+1 \big)^n \frac{2}{u^2+1}\; du \\ =& \int_{- \infty}^\infty \frac{u^{2n}}{(u^2+1)^{n+1}}\; du \end{split}$$ but the integrand doesn't look any easier to deal with. How should I proceed from here? Partial fractions should result in a linear combination of terms $1/(u^2+1)^k$ , so even assuming I can do the decomp for general $n$ , I realize I don't know how to integrate it for $k \neq 1$ . Thanks a lot in advance for any help.","From Complex Function Theory by Palka, an example shows for positive integers that using the Residue Thm, and I understood his derivation. But he went on to say that this can be found using familiar techniques, he mentions the substitution and to do partial fractions. I like attempting to evaluate integrals b/c they often involve clever tricks (that I usually can't think of, but appreciate once I see), so I wanted to give this one a try. Using the suggested substitution and (converting from tan to cos I drew a right triangle w/ legs 1 and ), so but the integrand doesn't look any easier to deal with. How should I proceed from here? Partial fractions should result in a linear combination of terms , so even assuming I can do the decomp for general , I realize I don't know how to integrate it for . Thanks a lot in advance for any help.","n \int_0^\pi \sin^{2n}t \; dt=\frac{\pi}{4}\binom{2n}{n} u= \tan (t/2) \cos t=2 \cos^2 \frac{t}{2}-1= \frac{2}{u^2+1}-1 2du= \sec^2(t/2) \leftrightarrow dt=2du/(u^2+1) u  \begin{split}
\int_0^\pi \sin^{2n}t \; dt =& \int_0^\pi ( \sin^2t)^n \; dt= \int_0^\pi \big( \frac{1- \cos 2t}{2}\big)^n \; dt \\
=&  \frac{1}{2^{n+1}}\int_0^{2 \pi}(1- \cos t)^n \; dt = \frac{1}{2^{n+1}}\int_{- \pi}^\pi (1- \cos t)^n \; dt \\
=& \frac{1}{2^{n+1}}\int_{- \infty}^\infty \big( 1- \frac{2}{u^2+1}+1 \big)^n \frac{2}{u^2+1}\; du \\
=& \int_{- \infty}^\infty \frac{u^{2n}}{(u^2+1)^{n+1}}\; du
\end{split} 1/(u^2+1)^k n k \neq 1","['calculus', 'integration', 'definite-integrals']"
62,Differentiation under the integral sign - what transformations to use?,Differentiation under the integral sign - what transformations to use?,,Need some help with this integral $$I (\alpha) = \int_1^\infty  {\arctan(\alpha x) \over x^2\sqrt{x^2-1}} dx$$ Taking the first derivative with respect to $\alpha$ $$I' (\alpha) = \int_1^\infty { dx\over (1+\alpha^2 x^2) x\sqrt{x^2-1} }$$ What transformations to use in order to solve $I'(\alpha)$ ?,Need some help with this integral Taking the first derivative with respect to What transformations to use in order to solve ?,I (\alpha) = \int_1^\infty  {\arctan(\alpha x) \over x^2\sqrt{x^2-1}} dx \alpha I' (\alpha) = \int_1^\infty { dx\over (1+\alpha^2 x^2) x\sqrt{x^2-1} } I'(\alpha),"['calculus', 'integration']"
63,Show that $\left|\int_a^b f(x) dx\right|\leqslant \frac{M}{12}(b-a)^3$?,Show that ?,\left|\int_a^b f(x) dx\right|\leqslant \frac{M}{12}(b-a)^3,"$f$ is second order diffierentiable over $[a,b]$, $f(a)=f(b)=0$, $|f''(x)|\leqslant M$, Show that $\left|\displaystyle\int_a^b f(x) dx\right|\leqslant \dfrac{M}{12}(b-a)^3$? To make out the coefficient $\dfrac{1}{12}$, I tried this way: Write that $c=\dfrac{a+b}{2}$, according to the Taylor's formula,  $$f(x)=f(c)+f'(c)(x-c)+\dfrac{f''(\eta)}{2}(x-c)^2,$$ Putting $x=a, x=b$, notice that $f(a)=f(b)=0$, then $$ 			      \begin{split} 				      0&=f(c)+f'(c)(a-c)+\dfrac{f''(\eta_1)}{2}(a-c)^2,\\ 				      0&=f(c)+f'(c)(b-c)+\dfrac{f''(\eta_2)}{2}(b-c)^2,\\ 			      \end{split} $$ Then according to Darboux theorem, there exists $\zeta$ such that $$f(c)=-\dfrac{(b-a)^2}{16}(f''(\eta_1)+f''(\eta_2))=-\dfrac{(b-a)^2}{8}f''(\zeta).$$ Then  $$f(x)=\color{red}{{-\dfrac{(b-a)^2}{8}f''(\zeta)}}+\color{blue}{f'(c)(x-c)}+\color{green}{\dfrac{f''(\eta)}{2}(x-c)^2}.$$ Integrate both sides, the red part gives $-\dfrac{1}{8}$, the blue part gives zero, and the green part gives $\dfrac{1}{24}$, then the coeffcient $\dfrac{1}{12}$ shows up. However, I cannot get a proper inequality from this.","$f$ is second order diffierentiable over $[a,b]$, $f(a)=f(b)=0$, $|f''(x)|\leqslant M$, Show that $\left|\displaystyle\int_a^b f(x) dx\right|\leqslant \dfrac{M}{12}(b-a)^3$? To make out the coefficient $\dfrac{1}{12}$, I tried this way: Write that $c=\dfrac{a+b}{2}$, according to the Taylor's formula,  $$f(x)=f(c)+f'(c)(x-c)+\dfrac{f''(\eta)}{2}(x-c)^2,$$ Putting $x=a, x=b$, notice that $f(a)=f(b)=0$, then $$ 			      \begin{split} 				      0&=f(c)+f'(c)(a-c)+\dfrac{f''(\eta_1)}{2}(a-c)^2,\\ 				      0&=f(c)+f'(c)(b-c)+\dfrac{f''(\eta_2)}{2}(b-c)^2,\\ 			      \end{split} $$ Then according to Darboux theorem, there exists $\zeta$ such that $$f(c)=-\dfrac{(b-a)^2}{16}(f''(\eta_1)+f''(\eta_2))=-\dfrac{(b-a)^2}{8}f''(\zeta).$$ Then  $$f(x)=\color{red}{{-\dfrac{(b-a)^2}{8}f''(\zeta)}}+\color{blue}{f'(c)(x-c)}+\color{green}{\dfrac{f''(\eta)}{2}(x-c)^2}.$$ Integrate both sides, the red part gives $-\dfrac{1}{8}$, the blue part gives zero, and the green part gives $\dfrac{1}{24}$, then the coeffcient $\dfrac{1}{12}$ shows up. However, I cannot get a proper inequality from this.",,"['calculus', 'integration', 'derivatives', 'definite-integrals', 'integral-inequality']"
64,How to evaluate the integral $\int_{0}^{1} \frac{\log x}{\sqrt {1+x^2}}dx$,How to evaluate the integral,\int_{0}^{1} \frac{\log x}{\sqrt {1+x^2}}dx,"$$I=\int_{0}^{1} \frac{\log x}{\sqrt {1+x^2}}dx$$ My attempt:$$I=\int_{0}^{1}\log x d(\log(x+\sqrt{1+x^2}))$$ $$=\log x\log(x+\sqrt{1+x^2})|_0^1-\int_{0}^{1}\frac{\log(x+\sqrt{1+x^2})}{x}dx$$ I don't know how to proceed below, please help me. That is different to me.","$$I=\int_{0}^{1} \frac{\log x}{\sqrt {1+x^2}}dx$$ My attempt:$$I=\int_{0}^{1}\log x d(\log(x+\sqrt{1+x^2}))$$ $$=\log x\log(x+\sqrt{1+x^2})|_0^1-\int_{0}^{1}\frac{\log(x+\sqrt{1+x^2})}{x}dx$$ I don't know how to proceed below, please help me. That is different to me.",,"['calculus', 'integration', 'definite-integrals']"
65,Evaluating $\int_{0}^{1}{\frac{3x^3 - x^2 + 2x - 4}{\sqrt{x^2 -3x+2}}dx}$,Evaluating,\int_{0}^{1}{\frac{3x^3 - x^2 + 2x - 4}{\sqrt{x^2 -3x+2}}dx},"I've got one integration question which I first felt was not a hard nut to crack. But, as I proceeded, difficulties arose. This is the one: $\displaystyle\int_{0}^{1}{\frac{3x^3 - x^2 + 2x - 4}{\sqrt{x^2 -3x+2}}dx}$ I went ahead simplifying the two expressions and ultimately I reached this step: $\displaystyle\int_{0}^{1}{\sqrt{\frac{x-1}{x-2}} \ (3x^2 + 2x + 4) \ dx}$ I don't now what to do now, had I followed the correct pathway? Is there any other simpler method?","I've got one integration question which I first felt was not a hard nut to crack. But, as I proceeded, difficulties arose. This is the one: $\displaystyle\int_{0}^{1}{\frac{3x^3 - x^2 + 2x - 4}{\sqrt{x^2 -3x+2}}dx}$ I went ahead simplifying the two expressions and ultimately I reached this step: $\displaystyle\int_{0}^{1}{\sqrt{\frac{x-1}{x-2}} \ (3x^2 + 2x + 4) \ dx}$ I don't now what to do now, had I followed the correct pathway? Is there any other simpler method?",,"['calculus', 'integration', 'definite-integrals']"
66,Multivariate Faà di Bruno's formula,Multivariate Faà di Bruno's formula,,"I'm attempting to implement a computer algebra function using the combinatoric version of Faà di Bruno's formula presented by Michael Hardy in Combinatorics of Partial Derivatives that ""collapses"" partitions to account for multiple variables. The paper is mostly very well-written and intelligible (its examples are used in the Wikipedia article) but there's one thing I'm unclear about. To give an example: I do the following: Compute the integer partition of the order represented as nested sequences Take the unmixed partial of f at the order corresponding the number of blocks in each partition Compose it with g Multiply the composition with the mixed partials of f corresponding to the blocks in the partition Sum the functions corresponding to each partition I'm currently distributing the multiplication at each order/partition rather than collapsing partitions and multiplying by a scalar, so I'm duplicating some work but am just trying to get it correct right now). I think the problem is that I'm misunderstanding the composition at each order, i.e. that f'''(y) in Hardy's example is not , if fact, the unmixed second-order partial of f composed with g. I just can't think of anything else that could be meant by notation like f''(y)(dy/x1 * dy^2/dx2xdx3). Any clarification would be greatly appreciated.","I'm attempting to implement a computer algebra function using the combinatoric version of Faà di Bruno's formula presented by Michael Hardy in Combinatorics of Partial Derivatives that ""collapses"" partitions to account for multiple variables. The paper is mostly very well-written and intelligible (its examples are used in the Wikipedia article) but there's one thing I'm unclear about. To give an example: I do the following: Compute the integer partition of the order represented as nested sequences Take the unmixed partial of f at the order corresponding the number of blocks in each partition Compose it with g Multiply the composition with the mixed partials of f corresponding to the blocks in the partition Sum the functions corresponding to each partition I'm currently distributing the multiplication at each order/partition rather than collapsing partitions and multiplying by a scalar, so I'm duplicating some work but am just trying to get it correct right now). I think the problem is that I'm misunderstanding the composition at each order, i.e. that f'''(y) in Hardy's example is not , if fact, the unmixed second-order partial of f composed with g. I just can't think of anything else that could be meant by notation like f''(y)(dy/x1 * dy^2/dx2xdx3). Any clarification would be greatly appreciated.",,"['calculus', 'combinatorics', 'multivariable-calculus', 'algorithms', 'analytic-combinatorics']"
67,Maximum number of circle packing into a rectangle,Maximum number of circle packing into a rectangle,,"I'm asked to pack the maximum number of 10m^2 circle into a 257 x 157m rectangle . After a lot of research, I found out that there are no optimal solution. So, i try to pack as many as possible (taking this website as reference): 1) First, I tried to place them in rectangular pattern : I had the width 257/d (diameter) -> I got about 72.024 --> So along the width, i can place 72 circle . I had the height 157/d (diameter) -> I got about 43.999 --> So along the height, i can place 43 circle . --> That means in this case, i can fit in 43*72= 3096 circles 2) Then I try triangular pattern , which can fit more circles, 3575 circles. However, I find my math calculation kinda inefficient, long, and not correct in any other cases. So my question is : Did I calculate it in a correct way? Are there any other more effective calculation methods? Because in later question, it asks me to find the area of the circle to so that we get the maximum profit . Giving the profit of each circle is: P(a) = 200 - 200/a (a is the area of the circle)","I'm asked to pack the maximum number of 10m^2 circle into a 257 x 157m rectangle . After a lot of research, I found out that there are no optimal solution. So, i try to pack as many as possible (taking this website as reference): 1) First, I tried to place them in rectangular pattern : I had the width 257/d (diameter) -> I got about 72.024 --> So along the width, i can place 72 circle . I had the height 157/d (diameter) -> I got about 43.999 --> So along the height, i can place 43 circle . --> That means in this case, i can fit in 43*72= 3096 circles 2) Then I try triangular pattern , which can fit more circles, 3575 circles. However, I find my math calculation kinda inefficient, long, and not correct in any other cases. So my question is : Did I calculate it in a correct way? Are there any other more effective calculation methods? Because in later question, it asks me to find the area of the circle to so that we get the maximum profit . Giving the profit of each circle is: P(a) = 200 - 200/a (a is the area of the circle)",,"['calculus', 'packing-problem']"
68,Is this integral defined? $\int_0^0\frac 1x\:dx$,Is this integral defined?,\int_0^0\frac 1x\:dx,"$\displaystyle\int_0^0\frac 1x\:dx$ Is this integral defined? If it define, what is the value?","Is this integral defined? If it define, what is the value?",\displaystyle\int_0^0\frac 1x\:dx,"['calculus', 'analysis']"
69,"The Functional Inequality $f(x) \ge x+1$, $f(x)f(y)\le f(x+y)$","The Functional Inequality ,",f(x) \ge x+1 f(x)f(y)\le f(x+y),"Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function that satisfies the following conditons. $$f(x)f(y)\le f(x+y)$$ $$f(x)\ge x+1$$ What is $f(x)$? It is not to difficult to find that $f(0)=1$. If $f(x)$ is differentiable, we can further these results so that $f'(0)=1$, and $f(x)=f'(x)$. However, I was not able to go any further than this. I believe that $f(x)=e^x$, but cannot prove it. Any help would be appreciated.","Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function that satisfies the following conditons. $$f(x)f(y)\le f(x+y)$$ $$f(x)\ge x+1$$ What is $f(x)$? It is not to difficult to find that $f(0)=1$. If $f(x)$ is differentiable, we can further these results so that $f'(0)=1$, and $f(x)=f'(x)$. However, I was not able to go any further than this. I believe that $f(x)=e^x$, but cannot prove it. Any help would be appreciated.",,"['calculus', 'functional-inequalities']"
70,Show that $f_n\to f$ uniformly on $\mathbb{R}$,Show that  uniformly on,f_n\to f \mathbb{R},"Let $$P_n(x) = \frac{n}{1+n^2x^2}$$. First, I had to prove that $$\int_{-\infty}^\infty P_n(x)\ dx = \pi$$ And that for any $\delta > 0$: $$\lim_{n\to\infty} \int_\delta^\infty P_n(x)\ dx = \lim_{n\to\infty} \int_{-\infty}^{-\delta} P_n(x)\ dx = 0$$ I've done that easily. Now I need to prove that for $f:\mathbb{R}\to\mathbb{C}$ which is $2\pi$ periodic and continuous and: $$f_n(x) = \frac{1}{\pi} \int_{-\infty}^\infty f(x-t)P_n(t)\ dt$$ $f_n\to f$, uniformly on $\mathbb{R}$. We learned in class about convolution and about Dirichlet/Fejer kernels. Also, we learned that the trigonometric polynomials, $\{e^{inx}\}_{n\in\mathbb{Z}}$ are a dense set on $C(\mathbb{T})$ and the density is uniform. Meaning, there's a $P_n(x)=\sum c_n e^{inx}$ converges uniformly to $f$ where $f\in C(\mathbb{T})$. note: $f\in C(\mathbb{T})$ is a continuous and $2\pi$ periodic function (T is for Torus).","Let $$P_n(x) = \frac{n}{1+n^2x^2}$$. First, I had to prove that $$\int_{-\infty}^\infty P_n(x)\ dx = \pi$$ And that for any $\delta > 0$: $$\lim_{n\to\infty} \int_\delta^\infty P_n(x)\ dx = \lim_{n\to\infty} \int_{-\infty}^{-\delta} P_n(x)\ dx = 0$$ I've done that easily. Now I need to prove that for $f:\mathbb{R}\to\mathbb{C}$ which is $2\pi$ periodic and continuous and: $$f_n(x) = \frac{1}{\pi} \int_{-\infty}^\infty f(x-t)P_n(t)\ dt$$ $f_n\to f$, uniformly on $\mathbb{R}$. We learned in class about convolution and about Dirichlet/Fejer kernels. Also, we learned that the trigonometric polynomials, $\{e^{inx}\}_{n\in\mathbb{Z}}$ are a dense set on $C(\mathbb{T})$ and the density is uniform. Meaning, there's a $P_n(x)=\sum c_n e^{inx}$ converges uniformly to $f$ where $f\in C(\mathbb{T})$. note: $f\in C(\mathbb{T})$ is a continuous and $2\pi$ periodic function (T is for Torus).",,"['calculus', 'integration', 'fourier-analysis', 'fourier-series']"
71,Defining vertical tangent lines,Defining vertical tangent lines,,"In looking at the definition of vertical tangent lines in some popular calculus texts, I noticed that there are a few different definitions for this term, including the following: A function $f$ has a vertical tangent line at $a$ if $\textbf{1)}$ $\;f$ is continuous at $a$ and $\displaystyle\lim_{x\to a}\;\lvert f^{\prime}(x)\rvert=\infty$ $\textbf{2)}$ $\;f$ is continuous at $a$ and $\displaystyle\lim_{x\to a} f^{\prime}(x)=\infty$ or $\displaystyle\lim_{x\to a} f^{\prime}(x)=-\infty$ $\textbf{3)}$ $\;\displaystyle\lim_{h\to0}\frac{f(a+h)-f(a)}{h}=\pm\infty$ I would like to ask if there is a standard definition of this term, and whether or not the definition should include continuity at $a$ and should not include the situation where the graph has a vertical cusp at $a$. Here are some examples where these definitions lead to different conclusions: a) $\;f(x)=x^{2/3}$ b) $\;f(x)=\begin{cases}1&\mbox{, if }x>0\\0&\mbox{, if }x=0\\-1&\mbox{, if }x<0\end{cases}$ (This question has also been posted on Math Educators Stack Exchange.)","In looking at the definition of vertical tangent lines in some popular calculus texts, I noticed that there are a few different definitions for this term, including the following: A function $f$ has a vertical tangent line at $a$ if $\textbf{1)}$ $\;f$ is continuous at $a$ and $\displaystyle\lim_{x\to a}\;\lvert f^{\prime}(x)\rvert=\infty$ $\textbf{2)}$ $\;f$ is continuous at $a$ and $\displaystyle\lim_{x\to a} f^{\prime}(x)=\infty$ or $\displaystyle\lim_{x\to a} f^{\prime}(x)=-\infty$ $\textbf{3)}$ $\;\displaystyle\lim_{h\to0}\frac{f(a+h)-f(a)}{h}=\pm\infty$ I would like to ask if there is a standard definition of this term, and whether or not the definition should include continuity at $a$ and should not include the situation where the graph has a vertical cusp at $a$. Here are some examples where these definitions lead to different conclusions: a) $\;f(x)=x^{2/3}$ b) $\;f(x)=\begin{cases}1&\mbox{, if }x>0\\0&\mbox{, if }x=0\\-1&\mbox{, if }x<0\end{cases}$ (This question has also been posted on Math Educators Stack Exchange.)",,"['calculus', 'soft-question', 'definition']"
72,"False notion of Limit in Stewart's ""Calculus""","False notion of Limit in Stewart's ""Calculus""",,"In calculus, when we take limits of functions, say $\lim_{x\to a}f(x),$ do we require that $x$ tends to $a$ from within the domain? For example, I would say $\lim_{x\to 0} \sqrt{x}=0$ since I am under the assumption that by ""$\lim_{x\to 0}$"" we mean that $x\to 0$ and $x$ is in the domain. However, this is not consistent with Stewart's ""Calculus."" So at this level, should I say that $\lim_{x\to 0}\sqrt{x}$ is undefined?","In calculus, when we take limits of functions, say $\lim_{x\to a}f(x),$ do we require that $x$ tends to $a$ from within the domain? For example, I would say $\lim_{x\to 0} \sqrt{x}=0$ since I am under the assumption that by ""$\lim_{x\to 0}$"" we mean that $x\to 0$ and $x$ is in the domain. However, this is not consistent with Stewart's ""Calculus."" So at this level, should I say that $\lim_{x\to 0}\sqrt{x}$ is undefined?",,"['calculus', 'limits', 'soft-question', 'education']"
73,Is reading old calculus books still beneficial for undergraduate students today?,Is reading old calculus books still beneficial for undergraduate students today?,,"this is really a question about math and not books. I am mainly wondering if reading really old calculus books is still beneficial for undrgraduate students today. I was told that the material covered won't be of much benefit, things like curves, various mechanical integration methods, etc., and that I would be better off studying a 'calculus with an intro to analysis' type book like Apostol or Spivak's calculus. Is this true? Some specific examples of old books I have in mind are: Edwards: https://archive.org/details/anelementarytre01edwagoog Todhunter: https://archive.org/details/atreatiseondiff06todhgoog Williamson: https://archive.org/details/anelementarytre20willgoog One thing's for sure: The problems in these books are much harder than in modern books, which is very appealing to me coming from an olympiad background. So they aren't as far back as say Cauchy, but still are fairly old. I would still be interested however in knowing if something like Cauchy's Calcul Differentiel et Integral (I can read french!) is worth studying today; I know that Clerk Maxwell studied it at Edinburgh University for instance (before ""going up"" to Cambridge): https://archive.org/details/leonsdecalculdi02goog Thanks","this is really a question about math and not books. I am mainly wondering if reading really old calculus books is still beneficial for undrgraduate students today. I was told that the material covered won't be of much benefit, things like curves, various mechanical integration methods, etc., and that I would be better off studying a 'calculus with an intro to analysis' type book like Apostol or Spivak's calculus. Is this true? Some specific examples of old books I have in mind are: Edwards: https://archive.org/details/anelementarytre01edwagoog Todhunter: https://archive.org/details/atreatiseondiff06todhgoog Williamson: https://archive.org/details/anelementarytre20willgoog One thing's for sure: The problems in these books are much harder than in modern books, which is very appealing to me coming from an olympiad background. So they aren't as far back as say Cauchy, but still are fairly old. I would still be interested however in knowing if something like Cauchy's Calcul Differentiel et Integral (I can read french!) is worth studying today; I know that Clerk Maxwell studied it at Edinburgh University for instance (before ""going up"" to Cambridge): https://archive.org/details/leonsdecalculdi02goog Thanks",,"['calculus', 'reference-request']"
74,Is there a difference between $y=\frac{\sqrt{1-x}}{\sqrt{1+x}}$ and $y=\sqrt{\frac{1-x}{1+x}}$,Is there a difference between  and,y=\frac{\sqrt{1-x}}{\sqrt{1+x}} y=\sqrt{\frac{1-x}{1+x}},"Is there a difference between $$y=\frac{\sqrt{1-x}}{\sqrt{1+x}}$$ and $$y=\sqrt{\frac{1-x}{1+x}}$$ If there is a difference, why when I give the square for both equations, they will be equal.","Is there a difference between $$y=\frac{\sqrt{1-x}}{\sqrt{1+x}}$$ and $$y=\sqrt{\frac{1-x}{1+x}}$$ If there is a difference, why when I give the square for both equations, they will be equal.",,[]
75,Continued fraction of $e^{-2\pi n}$,Continued fraction of,e^{-2\pi n},"I found this problem on a well-known problem solving website. It is apparently from Ramanujan. With   $$\LARGE{a = \frac{1}{1 + \frac{e^{-2\pi}}{1 + \frac{e^{-4\pi}}{1 + \ddots}}}},$$   what is $a$? The basic methods I know for questions of this type were not helpful to me. I do not require a full solution, but feel free to post one if you would like. Hints or lecture notes on how to solve problems of this nature would be appreciated. Keep in mind that I am at an undergraduate level in mathematics.","I found this problem on a well-known problem solving website. It is apparently from Ramanujan. With   $$\LARGE{a = \frac{1}{1 + \frac{e^{-2\pi}}{1 + \frac{e^{-4\pi}}{1 + \ddots}}}},$$   what is $a$? The basic methods I know for questions of this type were not helpful to me. I do not require a full solution, but feel free to post one if you would like. Hints or lecture notes on how to solve problems of this nature would be appreciated. Keep in mind that I am at an undergraduate level in mathematics.",,['calculus']
76,Reference request: calculus of variations,Reference request: calculus of variations,,I am searching for a good book to self-study calculus of variations. It should be fairly complete; build up gradually from the very basics; offer detailed explanations; have some emphasis on applications of variational methods.,I am searching for a good book to self-study calculus of variations. It should be fairly complete; build up gradually from the very basics; offer detailed explanations; have some emphasis on applications of variational methods.,,"['calculus', 'reference-request', 'soft-question', 'calculus-of-variations', 'book-recommendation']"
77,A series involving $\prod_1^n k^k$,A series involving,\prod_1^n k^k,"Is this series $$\sum_{n\geq 1}\left(\prod_{k=1}^{n}k^k\right)^{\!-\frac{4}{n^2}} $$ convergent or divergent? My attempt was to use the comparison test, but I'm stuck at finding the behaviour of $\displaystyle \prod_1^n k^k$ as $n$ goes to infinity. Thanks in advance.","Is this series $$\sum_{n\geq 1}\left(\prod_{k=1}^{n}k^k\right)^{\!-\frac{4}{n^2}} $$ convergent or divergent? My attempt was to use the comparison test, but I'm stuck at finding the behaviour of $\displaystyle \prod_1^n k^k$ as $n$ goes to infinity. Thanks in advance.",,"['calculus', 'integration', 'sequences-and-series', 'convergence-divergence', 'asymptotics']"
78,"Prove $\int_0^{2\pi}\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}\mathrm{d}\theta = \int_0^{2\pi}\frac{\cos \theta}{(1-a\cos \theta)^3}\,\mathrm{d}\theta$",Prove,"\int_0^{2\pi}\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}\mathrm{d}\theta = \int_0^{2\pi}\frac{\cos \theta}{(1-a\cos \theta)^3}\,\mathrm{d}\theta","While doing some mathematical modelling of planetary orbits I have come up with two definite integrals $D_1$ and $D_2$ which appear to produce the same result when I test (using www.WolframAlpha.com) for various values of $a$  where $0<a<1$. $$ D_1 \, =\, \int_0^{2\pi}f_1\,\mathrm{d}\theta \, =\, \int_0^{2\pi}\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}\mathrm{d}\theta \,=\, \frac{3a\pi}{(1-a^2)^{5/2}} \, =\,R $$ and $$ D_2 \, =\, \int_0^{2\pi}f_2\,\mathrm{d}\theta \, =\, \int_0^{2\pi}\frac{\cos \theta}{(1-a\cos \theta)^3}\,\mathrm{d}\theta \, =\, \frac{3a\pi}{(1-a^2)^{5/2}} \, =\,R $$ How could I go about proving:- (1) $D_1$ = $D_2$, (SOLVED, I think, by my two answers below, but using WolframAlpha to obtain integral solutions) $$$$ (2) $D_1$ = $R$ or $D_2$ = $R$. (MOVED to a separate question: Prove $\int_0^{2\pi}\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}$ or $\int_0^{2\pi}\frac{\cos\theta}{(1-a\cos\theta)^3}=\frac{3a\pi}{(1-a^2)^{5/2}}$ ). UPDATE 1 You can see how WolframAlpha produces these results by inputting the following input texts:- For Eqtn 1 with a=0.1 input: integrate (3*0.1(sinx)^2)/((1-0.1*cosx)^4) from x=0 to 2*pi For Eqtn 2 with a=0.1 input: integrate (cosx)/((1-0.1*cosx)^3) from x=0 to 2*pi for Result with a=0.1 input: evaluate 3 0.1 pi/(1-0.1^2)^(5/2) UPDATE 2 WolframAlpha also computes expressions for the indefinite integrals as follows:- $$I_1 \, =\, \int\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}\mathrm{d}\theta \,=\, $$ $$constant1 + \frac {a\,\sqrt{a^2-1}\sin\theta\,[-(2a^3+a)\cos^2\theta+3(a^2+1)cos\theta+a(2a^2-5)]} {2(a^2-1)^{5/2}(a\cos\theta-1)^3} $$ $$-\frac {6a\,(a\cos\theta-1)^3\,\tanh^-1 \left( \frac{(a+1)\tan(\theta/2)}{\sqrt{a^2-1}} \right) } {(2(a^2-1)^{5/2}\,(a\cos\theta-1)^3} $$ $$$$ $$$$ $$I_2 \, =\, \int\frac{\cos \theta}{(1-a\cos \theta)^3}\,\mathrm{d}\theta \, =\, $$ $$constant2 - \frac {2a^2\sin\theta-sin\theta} {2(a^2-1)^2(a\cos\theta-1)} -\frac {\sin\theta} {2(a^2-1)(a\cos\theta-1)^2} $$ $$ -\frac {3a\tanh^-1\left(\frac{(a+1)\tan(\theta/2)}{\sqrt{a^2-1}}\right)} {(a^2-1)^{5/2}} $$ Note that the final terms of each expression are equivalent to each other.  This could be useful. For example we can define a difference function $f_3 = f_1-f_2$ whose indefinite integral $I_3 = I_1-I_2$ will exclude the common awkward third term. Let us assume that $f_3$ is continuously integrable over the range $0,2\pi$ (we cannot be sure by inspection alone, but it can be shown, see my answer below).  Then, if $D_1=D_2$ over the range $0,2\pi$ then $D_1-D_2=0$ and so $D_3$ (=$\int_0^{2\pi}f_3\,d\theta$) should have value zero.  This is expanded on in my answer below.","While doing some mathematical modelling of planetary orbits I have come up with two definite integrals $D_1$ and $D_2$ which appear to produce the same result when I test (using www.WolframAlpha.com) for various values of $a$  where $0<a<1$. $$ D_1 \, =\, \int_0^{2\pi}f_1\,\mathrm{d}\theta \, =\, \int_0^{2\pi}\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}\mathrm{d}\theta \,=\, \frac{3a\pi}{(1-a^2)^{5/2}} \, =\,R $$ and $$ D_2 \, =\, \int_0^{2\pi}f_2\,\mathrm{d}\theta \, =\, \int_0^{2\pi}\frac{\cos \theta}{(1-a\cos \theta)^3}\,\mathrm{d}\theta \, =\, \frac{3a\pi}{(1-a^2)^{5/2}} \, =\,R $$ How could I go about proving:- (1) $D_1$ = $D_2$, (SOLVED, I think, by my two answers below, but using WolframAlpha to obtain integral solutions) $$$$ (2) $D_1$ = $R$ or $D_2$ = $R$. (MOVED to a separate question: Prove $\int_0^{2\pi}\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}$ or $\int_0^{2\pi}\frac{\cos\theta}{(1-a\cos\theta)^3}=\frac{3a\pi}{(1-a^2)^{5/2}}$ ). UPDATE 1 You can see how WolframAlpha produces these results by inputting the following input texts:- For Eqtn 1 with a=0.1 input: integrate (3*0.1(sinx)^2)/((1-0.1*cosx)^4) from x=0 to 2*pi For Eqtn 2 with a=0.1 input: integrate (cosx)/((1-0.1*cosx)^3) from x=0 to 2*pi for Result with a=0.1 input: evaluate 3 0.1 pi/(1-0.1^2)^(5/2) UPDATE 2 WolframAlpha also computes expressions for the indefinite integrals as follows:- $$I_1 \, =\, \int\frac{3a\sin^2\theta}{(1-a\cos \theta)^4}\mathrm{d}\theta \,=\, $$ $$constant1 + \frac {a\,\sqrt{a^2-1}\sin\theta\,[-(2a^3+a)\cos^2\theta+3(a^2+1)cos\theta+a(2a^2-5)]} {2(a^2-1)^{5/2}(a\cos\theta-1)^3} $$ $$-\frac {6a\,(a\cos\theta-1)^3\,\tanh^-1 \left( \frac{(a+1)\tan(\theta/2)}{\sqrt{a^2-1}} \right) } {(2(a^2-1)^{5/2}\,(a\cos\theta-1)^3} $$ $$$$ $$$$ $$I_2 \, =\, \int\frac{\cos \theta}{(1-a\cos \theta)^3}\,\mathrm{d}\theta \, =\, $$ $$constant2 - \frac {2a^2\sin\theta-sin\theta} {2(a^2-1)^2(a\cos\theta-1)} -\frac {\sin\theta} {2(a^2-1)(a\cos\theta-1)^2} $$ $$ -\frac {3a\tanh^-1\left(\frac{(a+1)\tan(\theta/2)}{\sqrt{a^2-1}}\right)} {(a^2-1)^{5/2}} $$ Note that the final terms of each expression are equivalent to each other.  This could be useful. For example we can define a difference function $f_3 = f_1-f_2$ whose indefinite integral $I_3 = I_1-I_2$ will exclude the common awkward third term. Let us assume that $f_3$ is continuously integrable over the range $0,2\pi$ (we cannot be sure by inspection alone, but it can be shown, see my answer below).  Then, if $D_1=D_2$ over the range $0,2\pi$ then $D_1-D_2=0$ and so $D_3$ (=$\int_0^{2\pi}f_3\,d\theta$) should have value zero.  This is expanded on in my answer below.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
79,How to show $\int_{0}^{\pi / 2} \ln\left(\tan x - \sqrt{2 \tan x} + 1\right){d}x = 0 $,How to show,\int_{0}^{\pi / 2} \ln\left(\tan x - \sqrt{2 \tan x} + 1\right){d}x = 0 ,"Problem: Show that $$\int_{0}^{\pi / 2} \ln\left(\tan x - \sqrt{2 \tan x} + 1\right)\,\mathrm{d}x = 0 $$ If possible, I would like to use regular single-variable calculus methods, with only substitutions, IBP, partial fractions and so on, which does not involve series manipulation. Thanks.","Problem: Show that If possible, I would like to use regular single-variable calculus methods, with only substitutions, IBP, partial fractions and so on, which does not involve series manipulation. Thanks.","\int_{0}^{\pi / 2} \ln\left(\tan x - \sqrt{2 \tan x} + 1\right)\,\mathrm{d}x = 0 ","['calculus', 'integration', 'improper-integrals', 'trigonometric-integrals']"
80,Continuous functions that satisfies $f(x) + f(1-x) + f(\sqrt{x^2+(1-x)}) = 0$ and $f(\frac12)=0$,Continuous functions that satisfies  and,f(x) + f(1-x) + f(\sqrt{x^2+(1-x)}) = 0 f(\frac12)=0,"$f:[0,1]\rightarrow \mathbb{R}$ is a continuous function which satisfies $$ f(x) + f(1-x) + f\left(\sqrt{x^2+(1-x)}\right) = 0 \text{ and } f\left(\tfrac12\right)=0. $$ Can someone give explicit examples of $f$, apart from the trivial solution, $f(x)=0$? And are there infinitely many solutions for $f$? I can derive some properties like $f(\frac{\sqrt3}2)=0$ or $f(0)=-2f(1)$, but I can't generate particular examples. Continuity seems important here, but I can't see how to use it, for if we take $f(x)=0$, for $x\in (0,1)$, and $f(1)=1$, $f(0)=-2$ also works.","$f:[0,1]\rightarrow \mathbb{R}$ is a continuous function which satisfies $$ f(x) + f(1-x) + f\left(\sqrt{x^2+(1-x)}\right) = 0 \text{ and } f\left(\tfrac12\right)=0. $$ Can someone give explicit examples of $f$, apart from the trivial solution, $f(x)=0$? And are there infinitely many solutions for $f$? I can derive some properties like $f(\frac{\sqrt3}2)=0$ or $f(0)=-2f(1)$, but I can't generate particular examples. Continuity seems important here, but I can't see how to use it, for if we take $f(x)=0$, for $x\in (0,1)$, and $f(1)=1$, $f(0)=-2$ also works.",,"['calculus', 'functions', 'functional-equations']"
81,Proof that Limit of the Log is the Log of the Limit,Proof that Limit of the Log is the Log of the Limit,,Proof that Limit of the Log is the Log of the Limit. What is the intuition behind this statement?,Proof that Limit of the Log is the Log of the Limit. What is the intuition behind this statement?,,"['calculus', 'limits']"
82,Which book among these would you recommend for first year calculus?,Which book among these would you recommend for first year calculus?,,"I'm struggling a bit with functions(limits, squeeze theorem, etc). I have done some research and found a list of books on calculus but I'm not sure which one would be better suited for me, so I would appreciate if some experienced people here could advise me which books would be better to master the basics so I can move on with derivatives, etc. Limits is my main problem, so I need a book which explain this in depth so I can master it. Then I'll keep going on with the same book for other chapters. Below is the list which I found here : Apostol T.M. Calculus Vol. 1 Burn R.P. Numbers and Functions: Steps into Analysis Courant R. and John F. Introduction to Calculus and Analysis I - One of the better calculus text in print. Crowell B. Calculus Dawkins, P Calculus I and Calculus II Garrett P. Calculus Ghorpade S.R. and Limaye B.V. A Course in Calculus and Real Analysis Gill G.S. Calculus Bible Guichard D. Whitman Calculu. Hardy G.H. A Course of Pure Mathematics Hwang A.D. Calculus for Mathematicians, Computer Scientists, and Physicists: An Introduction to Abstract Mathematics Santos D. Differential Calculus Shapiro B.E. Calculus and Analysis Spivak M. Calculus Strang G. Calculus Thomas G.B. and Finney R.L. Calculus and Analytic Geometry Tranter C.J. Advanced Level Pure Mathematics Tranter C.J. Techniques of Mathematical Analysis Veeh J.A. Lectures Notes on Calculus So far I narrowed my list down to Hardy, Spivak and Apostol based on further research, but I haven't got my hands on these books yet to compare them and I'm not sure if these books will be good for me. Thanks.","I'm struggling a bit with functions(limits, squeeze theorem, etc). I have done some research and found a list of books on calculus but I'm not sure which one would be better suited for me, so I would appreciate if some experienced people here could advise me which books would be better to master the basics so I can move on with derivatives, etc. Limits is my main problem, so I need a book which explain this in depth so I can master it. Then I'll keep going on with the same book for other chapters. Below is the list which I found here : Apostol T.M. Calculus Vol. 1 Burn R.P. Numbers and Functions: Steps into Analysis Courant R. and John F. Introduction to Calculus and Analysis I - One of the better calculus text in print. Crowell B. Calculus Dawkins, P Calculus I and Calculus II Garrett P. Calculus Ghorpade S.R. and Limaye B.V. A Course in Calculus and Real Analysis Gill G.S. Calculus Bible Guichard D. Whitman Calculu. Hardy G.H. A Course of Pure Mathematics Hwang A.D. Calculus for Mathematicians, Computer Scientists, and Physicists: An Introduction to Abstract Mathematics Santos D. Differential Calculus Shapiro B.E. Calculus and Analysis Spivak M. Calculus Strang G. Calculus Thomas G.B. and Finney R.L. Calculus and Analytic Geometry Tranter C.J. Advanced Level Pure Mathematics Tranter C.J. Techniques of Mathematical Analysis Veeh J.A. Lectures Notes on Calculus So far I narrowed my list down to Hardy, Spivak and Apostol based on further research, but I haven't got my hands on these books yet to compare them and I'm not sure if these books will be good for me. Thanks.",,"['calculus', 'reference-request', 'soft-question', 'self-learning', 'book-recommendation']"
83,Is there a proof for the following series to diverge/converge?,Is there a proof for the following series to diverge/converge?,,"I was wondering weather the series $$\sum_{n=1}^{\infty} \frac {\tan(n)} {n^b}$$ diverges or converges whenever $b \geq 1$ is an integer. Does anyone have a proof for either statement? Does it converge for some positive integers but not for others? In that case, which are they?","I was wondering weather the series $$\sum_{n=1}^{\infty} \frac {\tan(n)} {n^b}$$ diverges or converges whenever $b \geq 1$ is an integer. Does anyone have a proof for either statement? Does it converge for some positive integers but not for others? In that case, which are they?",,['calculus']
84,Prove inequality of generalized means,Prove inequality of generalized means,,"Consider the generalized (power) mean of positive numbers $a_1, \dotsc, a_n$ $$M_p(a_1, \dotsc, a_n)=\left(\frac{a_1^p + \dotsb + a_n^p}{n}\right)^{1/p}\qquad p\in \mathbb{R}$$ where for $p=0$ we use the geometric mean. The generalized mean inequality says that  $$ p < q \implies M_p(a_1, \dotsc, a_n) \leq M_q(a_1, \dotsc, a_n),$$ with equality holding iff $a_1 = \dotsb = a_n$. On Wikipedia it says that one can prove this by differentiating with respect to $p$ and using Jensen's inequality, and noting that $\partial_p M_p(a_1, \dotsc, a_n)>0$. When I do so, I get: $$\partial_p \left(\left(\frac{a_1^p + \dotsb + a_n^p}{n}\right)^{1/p}\right)\\= \left(\frac{a_1^p + \dotsb + a_n^p}{n}\right)^{1/p} \partial _p \left( \frac1p \log (a_1^p + \dotsb + a_n^p) - \frac1p \log n  \right),$$ which is positive iff $\partial _p \left( \frac1p \log (a_1^p + \dotsb + a_n^p) - \frac1p \log n  \right)$ is positive. $$\partial _p \left( \frac1p \log (a_1^p + \dotsb + a_n^p) - \frac1p \log n  \right) \\= \left(\frac{-1}{p^2}\right) \log (a_1^p + \dotsb + a_n^p)+ \frac1p \frac{a_1^p \log a_1+ \dotsb + a_n^p \log a_n }{a_1^p + \dotsb + a_n^p}+\frac{1}{p^2}\log n.$$ I'm trying to show that this is positive. When I think about what Jensen's equality would tell me, I note that $$\frac{a_1^p\log a_1 + \dotsb + a_n^p \log a_n}{a_1^p + \dotsb + a_n^p} \\ \leq  \log \left(  \frac{a_1^p}{a_1^p + \dotsb + a_n^p}a_1 + \dotsb +  \frac{a_n^p}{a_1^p + \dotsb + a_n^p}a_n \right) \\ = \log \left(  \frac{a_1^{p+1} + \dotsb + a_n^{p+1}}{a_1^p + \dotsb + a_n^p} \right),$$ or we could try to bring the factor $\frac1p$ of the term in question into the mix and make a similar estimate. Anyone have an idea?","Consider the generalized (power) mean of positive numbers $a_1, \dotsc, a_n$ $$M_p(a_1, \dotsc, a_n)=\left(\frac{a_1^p + \dotsb + a_n^p}{n}\right)^{1/p}\qquad p\in \mathbb{R}$$ where for $p=0$ we use the geometric mean. The generalized mean inequality says that  $$ p < q \implies M_p(a_1, \dotsc, a_n) \leq M_q(a_1, \dotsc, a_n),$$ with equality holding iff $a_1 = \dotsb = a_n$. On Wikipedia it says that one can prove this by differentiating with respect to $p$ and using Jensen's inequality, and noting that $\partial_p M_p(a_1, \dotsc, a_n)>0$. When I do so, I get: $$\partial_p \left(\left(\frac{a_1^p + \dotsb + a_n^p}{n}\right)^{1/p}\right)\\= \left(\frac{a_1^p + \dotsb + a_n^p}{n}\right)^{1/p} \partial _p \left( \frac1p \log (a_1^p + \dotsb + a_n^p) - \frac1p \log n  \right),$$ which is positive iff $\partial _p \left( \frac1p \log (a_1^p + \dotsb + a_n^p) - \frac1p \log n  \right)$ is positive. $$\partial _p \left( \frac1p \log (a_1^p + \dotsb + a_n^p) - \frac1p \log n  \right) \\= \left(\frac{-1}{p^2}\right) \log (a_1^p + \dotsb + a_n^p)+ \frac1p \frac{a_1^p \log a_1+ \dotsb + a_n^p \log a_n }{a_1^p + \dotsb + a_n^p}+\frac{1}{p^2}\log n.$$ I'm trying to show that this is positive. When I think about what Jensen's equality would tell me, I note that $$\frac{a_1^p\log a_1 + \dotsb + a_n^p \log a_n}{a_1^p + \dotsb + a_n^p} \\ \leq  \log \left(  \frac{a_1^p}{a_1^p + \dotsb + a_n^p}a_1 + \dotsb +  \frac{a_n^p}{a_1^p + \dotsb + a_n^p}a_n \right) \\ = \log \left(  \frac{a_1^{p+1} + \dotsb + a_n^{p+1}}{a_1^p + \dotsb + a_n^p} \right),$$ or we could try to bring the factor $\frac1p$ of the term in question into the mix and make a similar estimate. Anyone have an idea?",,"['calculus', 'derivatives', 'average']"
85,So close yet so far Finding $\int \frac {\sec x \tan x}{3x+5} dx$,So close yet so far Finding,\int \frac {\sec x \tan x}{3x+5} dx,"Cruising the old questions I came across juantheron asking for $\int \frac {\sec x\tan x}{3x+5}\,dx$ He tried using $(3x+5)^{-1}$ for $U$ and $\sec x \tan x$ for $dv$while integrating by parts.  below is his work. How can I calculate $$ \int {\sec\left(x\right)\tan\left(x\right)  \over 3x + 5}\,{\rm d}x $$ My Try:: $\displaystyle \int \frac{1}{3x+5}\left(\sec x\tan x \right)\,\mathrm dx$ Now Using Integration by Parts:: We get $$= \frac{1}{3x+5}\sec x +\int  \frac{3}{(3x+5)^2}\sec x\,\mathrm  dx$$ Here he hit his road block. I tried the opposite tactic Taking the other approach by parts. let $$U= \sec x \tan x$$ then$$ du= \tan^2 x \sec x +\sec^3 x$$ and $$dv=(3x+5)^{-1}$$ then $$v=\frac 1 3 \ln(3x+5)$$ Thus $$\int \frac {\sec x \tan x}{3x+5}\,dx= \frac {\ln(3x+5)\sec x \tan x}{3} - \int \frac {\ln(3x+5) [\tan^2 x \sec x +\sec^3 x]}{3} \,dx$$ As you can see I got no further than he did. So how many times do you have to complete integration by parts to get the integral of the original $\frac {\sec x \tan x}{3x+5} \, dx$ or is there a better way?","Cruising the old questions I came across juantheron asking for $\int \frac {\sec x\tan x}{3x+5}\,dx$ He tried using $(3x+5)^{-1}$ for $U$ and $\sec x \tan x$ for $dv$while integrating by parts.  below is his work. How can I calculate $$ \int {\sec\left(x\right)\tan\left(x\right)  \over 3x + 5}\,{\rm d}x $$ My Try:: $\displaystyle \int \frac{1}{3x+5}\left(\sec x\tan x \right)\,\mathrm dx$ Now Using Integration by Parts:: We get $$= \frac{1}{3x+5}\sec x +\int  \frac{3}{(3x+5)^2}\sec x\,\mathrm  dx$$ Here he hit his road block. I tried the opposite tactic Taking the other approach by parts. let $$U= \sec x \tan x$$ then$$ du= \tan^2 x \sec x +\sec^3 x$$ and $$dv=(3x+5)^{-1}$$ then $$v=\frac 1 3 \ln(3x+5)$$ Thus $$\int \frac {\sec x \tan x}{3x+5}\,dx= \frac {\ln(3x+5)\sec x \tan x}{3} - \int \frac {\ln(3x+5) [\tan^2 x \sec x +\sec^3 x]}{3} \,dx$$ As you can see I got no further than he did. So how many times do you have to complete integration by parts to get the integral of the original $\frac {\sec x \tan x}{3x+5} \, dx$ or is there a better way?",,"['calculus', 'integration', 'recreational-mathematics', 'indefinite-integrals']"
86,Definite integral of a product of normal pdf and cdf,Definite integral of a product of normal pdf and cdf,,"Denote the pdf of the standard normal distribution as $\phi(x)$ and cdf as $\Phi(x)$. Does anyone know how to calculate $\int_{-\infty}^y \phi(x)\Phi(\frac{x−b}{a})dx$? Notice that this question is similar to an existing one, https://mathoverflow.net/questions/101469/integration-of-the-product-of-pdf-cdf-of-normal-distribution the only difference being that I'm computing the integral over $(-\infty, y)$ for some real $y$, rather than over the entire real line. Thank you!","Denote the pdf of the standard normal distribution as $\phi(x)$ and cdf as $\Phi(x)$. Does anyone know how to calculate $\int_{-\infty}^y \phi(x)\Phi(\frac{x−b}{a})dx$? Notice that this question is similar to an existing one, https://mathoverflow.net/questions/101469/integration-of-the-product-of-pdf-cdf-of-normal-distribution the only difference being that I'm computing the integral over $(-\infty, y)$ for some real $y$, rather than over the entire real line. Thank you!",,"['calculus', 'integration']"
87,Evaluate $\lim_{x\to 0} (\ln(1-x)-\sin x)/(1-\cos^2 x)$,Evaluate,\lim_{x\to 0} (\ln(1-x)-\sin x)/(1-\cos^2 x),"I've got this limit: $$\displaystyle\lim_{x\to 0} \frac{\ln(1-x)-\sin x}{1-\cos^2 x}$$ and the problem is that it doesn't exist. But I am not very perceptive and I didn't avoid catching in a trap and I started to trying solve this with L'Hôpital's rule. And my question is: are there any ways to notice that given limit doesn't exist in time? If I had been given such a limit on a test, what is the ideal way to solve it?","I've got this limit: $$\displaystyle\lim_{x\to 0} \frac{\ln(1-x)-\sin x}{1-\cos^2 x}$$ and the problem is that it doesn't exist. But I am not very perceptive and I didn't avoid catching in a trap and I started to trying solve this with L'Hôpital's rule. And my question is: are there any ways to notice that given limit doesn't exist in time? If I had been given such a limit on a test, what is the ideal way to solve it?",,"['calculus', 'limits']"
88,The Supremum and Bounded Functions [duplicate],The Supremum and Bounded Functions [duplicate],,"This question already has answers here : How can I show that $\sup(AB)\geq\sup A\sup B$ for $A,B\subset\mathbb{R}$ where $A\cup B$ is positive and bounded? (8 answers) Closed 10 years ago . I'm trying to show that this is true: Let $X$ be a set and suppose $f$ and $g$ are bounded (real-valued) functions defined on $X$. Then, $$ \sup_{x \in X}|f(x)g(x)| \leq \sup_{x \in X}|f(x)|\sup_{x \in X}|g(x)| $$ I think I'm pretty close but I'm not sure about the last step. First, since $f$ and $g$ are bounded, all involved suprema exist and are finite. If $a = \sup|f(x)|$ and  $b = \sup|f(x)|$ then it is true that  $$ a \geq |f(x)| \;\;\;\;\;\; b \geq |g(x)| $$ for every $x \in X$. Since none of the quantities involved are negative, this implies $$ a b \geq |f(x)|\cdot |g(x)| \implies \sup|f(x)|\sup|g(x)| \geq |f(x)|\cdot |g(x)| $$ Can I say now that since this last inequality holds for all $x$ that $$ \sup_{x \in X}|f(x)g(x)| = \sup_{x \in X} \left(|f(x)|\cdot |g(x)|\right) \leq \sup_{x \in X}|f(x)|\sup_{x \in X}|g(x)|? $$ Thanks.","This question already has answers here : How can I show that $\sup(AB)\geq\sup A\sup B$ for $A,B\subset\mathbb{R}$ where $A\cup B$ is positive and bounded? (8 answers) Closed 10 years ago . I'm trying to show that this is true: Let $X$ be a set and suppose $f$ and $g$ are bounded (real-valued) functions defined on $X$. Then, $$ \sup_{x \in X}|f(x)g(x)| \leq \sup_{x \in X}|f(x)|\sup_{x \in X}|g(x)| $$ I think I'm pretty close but I'm not sure about the last step. First, since $f$ and $g$ are bounded, all involved suprema exist and are finite. If $a = \sup|f(x)|$ and  $b = \sup|f(x)|$ then it is true that  $$ a \geq |f(x)| \;\;\;\;\;\; b \geq |g(x)| $$ for every $x \in X$. Since none of the quantities involved are negative, this implies $$ a b \geq |f(x)|\cdot |g(x)| \implies \sup|f(x)|\sup|g(x)| \geq |f(x)|\cdot |g(x)| $$ Can I say now that since this last inequality holds for all $x$ that $$ \sup_{x \in X}|f(x)g(x)| = \sup_{x \in X} \left(|f(x)|\cdot |g(x)|\right) \leq \sup_{x \in X}|f(x)|\sup_{x \in X}|g(x)|? $$ Thanks.",,['calculus']
89,Finding an addition formula without trigonometry,Finding an addition formula without trigonometry,,"I'm trying to understand better the following addition formula: $$\int_0^a \frac{\mathrm{d}x}{\sqrt{1-x^2}} + \int_0^b \frac{\mathrm{d}x}{\sqrt{1-x^2}} = \int_0^{a\sqrt{1-b^2}+b\sqrt{1-a^2}} \frac{\mathrm{d}x}{\sqrt{1-x^2}}$$ The term $a\sqrt{1-b^2}+b\sqrt{1-a^2}$ can be derived from trigonometry (since $\sin(t) = \sqrt{1 - \cos^2(t)}$) but I have not been able to find any way to derive this formula without trigonometry, how could it be done? edit: fixed a mistake in my formula.","I'm trying to understand better the following addition formula: $$\int_0^a \frac{\mathrm{d}x}{\sqrt{1-x^2}} + \int_0^b \frac{\mathrm{d}x}{\sqrt{1-x^2}} = \int_0^{a\sqrt{1-b^2}+b\sqrt{1-a^2}} \frac{\mathrm{d}x}{\sqrt{1-x^2}}$$ The term $a\sqrt{1-b^2}+b\sqrt{1-a^2}$ can be derived from trigonometry (since $\sin(t) = \sqrt{1 - \cos^2(t)}$) but I have not been able to find any way to derive this formula without trigonometry, how could it be done? edit: fixed a mistake in my formula.",,[]
90,Minimum number of terms to approximate $\pi=4\sum_{n=1}^\infty\frac{(-1)^{n-1}}{2n-1}$,Minimum number of terms to approximate,\pi=4\sum_{n=1}^\infty\frac{(-1)^{n-1}}{2n-1},"Consider the Leibniz formula for $\pi$ $$ \pi=4\sum_{n=1}^\infty\frac{(-1)^{n-1}}{2n-1}. $$ What is the minimum number of terms needed to calculate $\pi$ accurate to $k$ decimal places? My attempt: Let's consider $k=2$ decimal places for example and set $a_n=\frac{4}{2n-1}$ . One way to think about this is to consider the remainder of the series and simply use $$ |R_n|\leq a_{n+1}\Leftrightarrow |R_n|\leq \frac{4}{2n+1}\leq 10^{-2} $$ which holds for $n\geq 200$ . Alternatively, Calabrese's error bound yields $$ \frac{a_{n+1}}{2} < |R_n| < \frac{a_n}{2}\Leftrightarrow \frac{2}{2n+1} < |R_n| < \frac{2}{2n-1} $$ which leads to $99.5<n<100.5$ and thus $n=100$ , a refined number. Indeed, either term order satisfies $$ \begin{align} R_{200}&=4\sum_{n=201}^\infty\frac{(-1)^{n-1}}{2n-1}\simeq 0.004999968751 \leq 10^{-2}\\ R_{100}&=4\sum_{n=101}^\infty\frac{(-1)^{n-1}}{2n-1}\simeq 0.009999750031 \leq 10^{-2} \end{align} $$ However, the partial sums give $$ \begin{align} S_{200}&=4\sum_{n=1}^{200}\frac{(-1)^{n-1}}{2n-1}\simeq 3.136592685\\ S_{100}&=4\sum_{n=1}^{100}\frac{(-1)^{n-1}}{2n-1}\simeq 3.131592904 \end{align} $$ which are not accurate to two decimal places ( $\pi\simeq 3.14...$ ). In fact, the minimum value of $n$ I found (computationally) that gives an accuracy to two decimal places was $n=119$ . Indeed, $$ \begin{align} S_{119}&=4\sum_{n=1}^{119}\frac{(-1)^{n-1}}{2n-1}\simeq 3.149995867\\ R_{119}&=4\sum_{n=120}^{\infty}\frac{(-1)^{n-1}}{2n-1}\simeq -0.008403213004 \end{align} $$ Is there an analytical way of determining the minimum number of terms for any accuracy $k$ ? Comment: Out of curiosity, I have calculated the first $10$ minima for ""accuracies"" $k=0,...,9$ . Respectively, I got $$ (3,19,119,167,10794,136121,1530012,18660304,155973051,1700659132) $$ On a log plot, we get","Consider the Leibniz formula for What is the minimum number of terms needed to calculate accurate to decimal places? My attempt: Let's consider decimal places for example and set . One way to think about this is to consider the remainder of the series and simply use which holds for . Alternatively, Calabrese's error bound yields which leads to and thus , a refined number. Indeed, either term order satisfies However, the partial sums give which are not accurate to two decimal places ( ). In fact, the minimum value of I found (computationally) that gives an accuracy to two decimal places was . Indeed, Is there an analytical way of determining the minimum number of terms for any accuracy ? Comment: Out of curiosity, I have calculated the first minima for ""accuracies"" . Respectively, I got On a log plot, we get","\pi 
\pi=4\sum_{n=1}^\infty\frac{(-1)^{n-1}}{2n-1}.
 \pi k k=2 a_n=\frac{4}{2n-1} 
|R_n|\leq a_{n+1}\Leftrightarrow |R_n|\leq \frac{4}{2n+1}\leq 10^{-2}
 n\geq 200 
\frac{a_{n+1}}{2} < |R_n| < \frac{a_n}{2}\Leftrightarrow \frac{2}{2n+1} < |R_n| < \frac{2}{2n-1}
 99.5<n<100.5 n=100 
\begin{align}
R_{200}&=4\sum_{n=201}^\infty\frac{(-1)^{n-1}}{2n-1}\simeq 0.004999968751 \leq 10^{-2}\\
R_{100}&=4\sum_{n=101}^\infty\frac{(-1)^{n-1}}{2n-1}\simeq 0.009999750031 \leq 10^{-2}
\end{align}
 
\begin{align}
S_{200}&=4\sum_{n=1}^{200}\frac{(-1)^{n-1}}{2n-1}\simeq 3.136592685\\
S_{100}&=4\sum_{n=1}^{100}\frac{(-1)^{n-1}}{2n-1}\simeq 3.131592904
\end{align}
 \pi\simeq 3.14... n n=119 
\begin{align}
S_{119}&=4\sum_{n=1}^{119}\frac{(-1)^{n-1}}{2n-1}\simeq 3.149995867\\
R_{119}&=4\sum_{n=120}^{\infty}\frac{(-1)^{n-1}}{2n-1}\simeq -0.008403213004
\end{align}
 k 10 k=0,...,9 
(3,19,119,167,10794,136121,1530012,18660304,155973051,1700659132)
","['calculus', 'sequences-and-series', 'taylor-expansion', 'approximation', 'pi']"
91,Integral Representation of $\zeta^2(3)$ based on $\int_{0}^{1}\frac{\ln^ms\cdot\ln^n(1+s)}{1+s}ds$,Integral Representation of  based on,\zeta^2(3) \int_{0}^{1}\frac{\ln^ms\cdot\ln^n(1+s)}{1+s}ds,"Using Integer Relation Algorithms, I was able to arrive at the following : $$12\zeta^2(3)=-40\int_{0}^{1}\frac{\ln s\ln^{4}(1+s)}{1+s}ds+40\int_{0}^{1}\frac{\ln^{2}s\ln^{3}(1+s)}{1+s}ds-44\int_{0}^{1}\frac{\ln^{3}s\ln^{2}(1+s)}{1+s}ds+23\int_{0}^{1}\frac{\ln^{4}s\ln(1+s)}{1+s}ds$$ Is it possible to simplify the Right Hand Side so that we have a nice Integral Representation for $\zeta^2(3)?$ Maybe we can apply some Powerful Substitution. The Coefficients do have Alternating Signs. I thought to make a pattern appear by removing the powers of $2$ as : $$5\cdot2^3,\ 10\cdot2^2,\ 22\cdot2^1,\ 23\cdot2^0$$ But this does not appear to be binomial. Also, I do not expect it to be feasible considering the Coefficients do not exhibit any Binomial Pattern.","Using Integer Relation Algorithms, I was able to arrive at the following : Is it possible to simplify the Right Hand Side so that we have a nice Integral Representation for Maybe we can apply some Powerful Substitution. The Coefficients do have Alternating Signs. I thought to make a pattern appear by removing the powers of as : But this does not appear to be binomial. Also, I do not expect it to be feasible considering the Coefficients do not exhibit any Binomial Pattern.","12\zeta^2(3)=-40\int_{0}^{1}\frac{\ln s\ln^{4}(1+s)}{1+s}ds+40\int_{0}^{1}\frac{\ln^{2}s\ln^{3}(1+s)}{1+s}ds-44\int_{0}^{1}\frac{\ln^{3}s\ln^{2}(1+s)}{1+s}ds+23\int_{0}^{1}\frac{\ln^{4}s\ln(1+s)}{1+s}ds \zeta^2(3)? 2 5\cdot2^3,\ 10\cdot2^2,\ 22\cdot2^1,\ 23\cdot2^0","['calculus', 'integration', 'definite-integrals']"
92,Prove that $\lim _{n \rightarrow \infty} \sqrt{n} \cdot\sin^{\circ n}(\frac{1}{\sqrt{n}})=\frac{\sqrt{3}}{2}$ [duplicate],Prove that  [duplicate],\lim _{n \rightarrow \infty} \sqrt{n} \cdot\sin^{\circ n}(\frac{1}{\sqrt{n}})=\frac{\sqrt{3}}{2},This question already has an answer here : iterated sine function on different arguments (1 answer) Closed 8 months ago . It's known that $\lim _{n \rightarrow \infty} \sqrt{n} \cdot \sin^{\circ n}(x)=\sqrt{3}$ for any $x>0$ . And I found a new conclusion $\lim _{n \rightarrow \infty} \sqrt{n} \cdot \sin^{\circ n}(\frac{1}{\sqrt{n}})=\frac{\sqrt{3}}{2}$ by Python. But I can't prove it because I can't use the same method to solve. Can anyone give me some methods?,This question already has an answer here : iterated sine function on different arguments (1 answer) Closed 8 months ago . It's known that for any . And I found a new conclusion by Python. But I can't prove it because I can't use the same method to solve. Can anyone give me some methods?,\lim _{n \rightarrow \infty} \sqrt{n} \cdot \sin^{\circ n}(x)=\sqrt{3} x>0 \lim _{n \rightarrow \infty} \sqrt{n} \cdot \sin^{\circ n}(\frac{1}{\sqrt{n}})=\frac{\sqrt{3}}{2},"['calculus', 'limits', 'analysis', 'functions']"
93,How to evaluate the integral $\int_1^9\frac{dx}{x\sqrt{81-x^2}}$,How to evaluate the integral,\int_1^9\frac{dx}{x\sqrt{81-x^2}},"So I was recently looking at a new book on Calculus [1] that I got and decided to look at the techniques for integration that it listed. I then decided after a while to make my own integral and evaluate it using the techniques that it listed. Here is the integral I came up with [2] : $$\int_1^{9}\dfrac{dx}{x\sqrt{81-x^2}}$$ which I thought that I might be able to evaluate. Here is my attempt at doing so: We use the substitution $x=9\sin(\theta)\implies\theta=\sin^{-1}\left(\dfrac x9\right)$ , and then we can have $dx=9\cos(\theta)d\theta$ , and then $\sqrt{81-x^2}$ becomes [3] $$\sqrt{81-81\sin^2(\theta)}=9\sqrt{\sin^2\theta}\implies9\sqrt{\cos^2(\theta)}\implies9|\cos(\theta)|=\sqrt{81-\dfrac{x^2}9}$$ $$\because|\cos(\theta)|=\sqrt{a^2-\dfrac{x^2}a}\because\text{the inverse sine function}$$ $$\text{oscillates between }-\dfrac\pi2\text{ and }\dfrac\pi2\text{ which implies}$$ $$\cos(\theta)=|\cos(\theta)|=\sqrt{a^2-\dfrac{x^2}a}=\sqrt{81-\dfrac{x^2}9}$$ This implies the integral $I(t)$ is now $$\int_1^9\dfrac{\require{cancel}\cancel{9\cos(\theta)}d\theta}{9\sin(\theta)\cancel{(9\cos(\theta))}}$$ $$=\dfrac19\int_1^9\csc(\theta)d\theta$$ Now there’s only one problem: Here’s what we get when we evaluate the integral: $$\dfrac19\left[\operatorname{Ln}\left(\sin\left(\dfrac\theta2\right)\right)-\operatorname{Ln}\left(\cos\left(\dfrac\theta2\right)\right)\right]_1^9$$ There’s only one problem. I know how to evaluate any $\sin(\dfrac x2)$ , but I don’t know how to evaluate any $\cos(\dfrac x2)$ . Then, I decided to go back in the book to the part on trigonometric functions and saw definition ( $16.13$ ): ( $16.13$ ) $\quad\cos^2(u)=\dfrac{1+\cos u}2$ This was great because now I could finally integrate the function. Then, $$\dfrac19\left[\operatorname{Ln}\left(\sin\left(\dfrac\theta2\right)\right)-\operatorname{Ln}\left(\cos\left(\dfrac\theta2\right)\right)\right]_1^9$$ $$=\dfrac19\left[\ln\left(\sqrt{\dfrac12(1-\cos(\theta))}\right)-\ln\left(\sqrt{\dfrac12(1+\cos(\theta))}\right)\right]_1^9$$ $$\dfrac1{18}\left[\ln\left(\dfrac{1-\cos(\theta)}2\right)-\ln\left(\dfrac{1+\cos(\theta)}2\right)\right]_1^9$$ $$\implies\dfrac1{18}\left[\ln\left(\dfrac{1-\cos(\theta)}{1+\cos(\theta)}\right)\right]_1^9$$ $$\implies\dfrac1{18}\left[\ln\left(\dfrac{9-\sqrt{81-x^2}}{9+\sqrt{81-x^2}}\right)\right]_1^9$$ which converges to $$-\dfrac1{18}\ln\left(\dfrac{(9-\sqrt{80})^2}{161}\right)$$ or approximately $0.603108$ My question Did I evaluate the integral correctly, or what could I do to evaluate it correctly? Notes [1] Calculus by Elliot Mendelson, PHD. [2] Based off of Chapter $32$ “Techniques of Integration II” example $32.12$ [3] This is done using Strategy II: “If $\sqrt{a^2-x^2}$ occurs in an integrated, try the substitution $x=a\sin\theta$ .”","So I was recently looking at a new book on Calculus [1] that I got and decided to look at the techniques for integration that it listed. I then decided after a while to make my own integral and evaluate it using the techniques that it listed. Here is the integral I came up with [2] : which I thought that I might be able to evaluate. Here is my attempt at doing so: We use the substitution , and then we can have , and then becomes [3] This implies the integral is now Now there’s only one problem: Here’s what we get when we evaluate the integral: There’s only one problem. I know how to evaluate any , but I don’t know how to evaluate any . Then, I decided to go back in the book to the part on trigonometric functions and saw definition ( ): ( ) This was great because now I could finally integrate the function. Then, which converges to or approximately My question Did I evaluate the integral correctly, or what could I do to evaluate it correctly? Notes [1] Calculus by Elliot Mendelson, PHD. [2] Based off of Chapter “Techniques of Integration II” example [3] This is done using Strategy II: “If occurs in an integrated, try the substitution .”",\int_1^{9}\dfrac{dx}{x\sqrt{81-x^2}} x=9\sin(\theta)\implies\theta=\sin^{-1}\left(\dfrac x9\right) dx=9\cos(\theta)d\theta \sqrt{81-x^2} \sqrt{81-81\sin^2(\theta)}=9\sqrt{\sin^2\theta}\implies9\sqrt{\cos^2(\theta)}\implies9|\cos(\theta)|=\sqrt{81-\dfrac{x^2}9} \because|\cos(\theta)|=\sqrt{a^2-\dfrac{x^2}a}\because\text{the inverse sine function} \text{oscillates between }-\dfrac\pi2\text{ and }\dfrac\pi2\text{ which implies} \cos(\theta)=|\cos(\theta)|=\sqrt{a^2-\dfrac{x^2}a}=\sqrt{81-\dfrac{x^2}9} I(t) \int_1^9\dfrac{\require{cancel}\cancel{9\cos(\theta)}d\theta}{9\sin(\theta)\cancel{(9\cos(\theta))}} =\dfrac19\int_1^9\csc(\theta)d\theta \dfrac19\left[\operatorname{Ln}\left(\sin\left(\dfrac\theta2\right)\right)-\operatorname{Ln}\left(\cos\left(\dfrac\theta2\right)\right)\right]_1^9 \sin(\dfrac x2) \cos(\dfrac x2) 16.13 16.13 \quad\cos^2(u)=\dfrac{1+\cos u}2 \dfrac19\left[\operatorname{Ln}\left(\sin\left(\dfrac\theta2\right)\right)-\operatorname{Ln}\left(\cos\left(\dfrac\theta2\right)\right)\right]_1^9 =\dfrac19\left[\ln\left(\sqrt{\dfrac12(1-\cos(\theta))}\right)-\ln\left(\sqrt{\dfrac12(1+\cos(\theta))}\right)\right]_1^9 \dfrac1{18}\left[\ln\left(\dfrac{1-\cos(\theta)}2\right)-\ln\left(\dfrac{1+\cos(\theta)}2\right)\right]_1^9 \implies\dfrac1{18}\left[\ln\left(\dfrac{1-\cos(\theta)}{1+\cos(\theta)}\right)\right]_1^9 \implies\dfrac1{18}\left[\ln\left(\dfrac{9-\sqrt{81-x^2}}{9+\sqrt{81-x^2}}\right)\right]_1^9 -\dfrac1{18}\ln\left(\dfrac{(9-\sqrt{80})^2}{161}\right) 0.603108 32 32.12 \sqrt{a^2-x^2} x=a\sin\theta,"['calculus', 'integration', 'solution-verification', 'definite-integrals']"
94,Derivative of $\arcsin(\cos x)$,Derivative of,\arcsin(\cos x),"In my calculus course, my teacher asked me to differentiate the function $$f(x) = \arcsin(\cos x).$$ My work looked like so, $$ f'(x)=\frac{1}{\sqrt{1-\cos^2x}}\cdot-\sin x = -\frac{\sin x}{\sqrt{\sin^2 x}} = -\frac{\sin x}{|\sin x|} = -\frac{|\sin x|}{\sin x}. $$ However, as I went to confirm my answer with my instructor, they claimed that my answer was incorrect. Instead, they claimed my work should have gone like so: $$ f'(x)=\frac{1}{\sqrt{1-\cos^2x}}\cdot-\sin x = -\frac{\sin x}{\sqrt{\sin^2 x}} = -\frac{\sin x}{\sin x} = -1. $$ I attempted to explain how I thought $\sqrt{x^2}$ simplified to $|x|$ , but they keep asserting I'm incorrect, claiming that the function $\arcsin x$ does not exist for $|x|>\frac{\pi}{2}$ , and that therefore $-1$ should indeed be the correct answer within the domain of the function, which they said was $|x|<\frac{\pi}{2}$ . This has just left my confused about the whole matter. Can anyone explain which derivative is right here, and why?","In my calculus course, my teacher asked me to differentiate the function My work looked like so, However, as I went to confirm my answer with my instructor, they claimed that my answer was incorrect. Instead, they claimed my work should have gone like so: I attempted to explain how I thought simplified to , but they keep asserting I'm incorrect, claiming that the function does not exist for , and that therefore should indeed be the correct answer within the domain of the function, which they said was . This has just left my confused about the whole matter. Can anyone explain which derivative is right here, and why?","f(x) = \arcsin(\cos x). 
f'(x)=\frac{1}{\sqrt{1-\cos^2x}}\cdot-\sin x
= -\frac{\sin x}{\sqrt{\sin^2 x}}
= -\frac{\sin x}{|\sin x|} = -\frac{|\sin x|}{\sin x}.
 
f'(x)=\frac{1}{\sqrt{1-\cos^2x}}\cdot-\sin x
= -\frac{\sin x}{\sqrt{\sin^2 x}}
= -\frac{\sin x}{\sin x}
= -1.
 \sqrt{x^2} |x| \arcsin x |x|>\frac{\pi}{2} -1 |x|<\frac{\pi}{2}","['calculus', 'derivatives', 'trigonometry']"
95,"Minimizing $\int_{0}^{1} (f'(x))^2 \, dx$ with constraints",Minimizing  with constraints,"\int_{0}^{1} (f'(x))^2 \, dx","Problem. Given that $f \in C^{(1)} [0,1]$ , $f(0) = a$ , $\int_{0}^{1} f(x) \, dx = 0$ , find minimum value of $\int_{0}^{1} (f'(x))^2 \, dx$ . I've tried applying Cauchy-Schwarz, but only got the lower bound of $a^2$ . I also could construct an example where the value is $4a^2$ , but couldn't make any progress after that. My Attempt. With Cauchy we have $$ \left| \int_{0}^{c} f(x) g(x) \, dx \right|^2 \leq \left( \int_{0}^{c} f^2(x) \, dx \right) \left( \int_{0}^{c} g^2(x) \, dx \right), $$ where we can substitute $f(x) = f'(x)$ , $g(x) = 1$ , so: $$ \left| \int_{0}^{c} f'(x) \, dx \right|^2 \leq \int_{0}^{c} f'^2(x) \, dx. $$ For some $c$ in $[0,1]$ we have $f(c) \leq 0$ , so we can choose $c$ such that left side is at least $(f(c) - f(0))^2 = a^2$ . The right part doesn't decrease while increasing $c$ , so that's why the lower bound is $a^2$ . $a^2$ can also be the answer, but I couldn't find such an example.","Problem. Given that , , , find minimum value of . I've tried applying Cauchy-Schwarz, but only got the lower bound of . I also could construct an example where the value is , but couldn't make any progress after that. My Attempt. With Cauchy we have where we can substitute , , so: For some in we have , so we can choose such that left side is at least . The right part doesn't decrease while increasing , so that's why the lower bound is . can also be the answer, but I couldn't find such an example.","f \in C^{(1)} [0,1] f(0) = a \int_{0}^{1} f(x) \, dx = 0 \int_{0}^{1} (f'(x))^2 \, dx a^2 4a^2  \left| \int_{0}^{c} f(x) g(x) \, dx \right|^2
\leq \left( \int_{0}^{c} f^2(x) \, dx \right) \left( \int_{0}^{c} g^2(x) \, dx \right),  f(x) = f'(x) g(x) = 1  \left| \int_{0}^{c} f'(x) \, dx \right|^2 \leq \int_{0}^{c} f'^2(x) \, dx.  c [0,1] f(c) \leq 0 c (f(c) - f(0))^2 = a^2 c a^2 a^2","['calculus', 'integration', 'analysis']"
96,"What makes $\frac{x(x+1)}{2}$ a ""better"" interpolant of the sum of the first $n$ positive integers than any other, and likewise in similar cases?","What makes  a ""better"" interpolant of the sum of the first  positive integers than any other, and likewise in similar cases?",\frac{x(x+1)}{2} n,"A long-time interest of mine has been trying to determine if there is some ""natural"" criterion by which we can characterize various interpolants of functions that are at first only defined for integer or positive-integer inputs, such as exponentiation and the factorial function, which generalize to the exponential and gamma functions. The aim ultimately is to create an explicit and efficient series formula for the interpolation of tetration $$^n a = \underbrace{a^{a^{a^{\cdots^a}}}}_\text{$n$ copies of $a$}$$ to noninteger values of $n$ , in some suitably natural manner. But before we can get there, it seems more profitable to first look at simpler cases, and one of the simplest such cases seems to be interpolating discrete sums. For example, consider $$f(n) = \sum_{k=1}^{n} k.$$ As written, this definition makes no sense for, say, $f\left(\frac{1}{2}\right)$ . However, it is not hard to see that this can be converted into a ""closed form"" that, even better, doubles as an interpolative extension: $$\sum_{k=1}^{n} k = \frac{n(n+1)}{2}$$ which allows us to expand to real $x$ ""lengths"" via $$\sum_{k=1}^{x} k := \frac{x(x+1)}{2}, x \in \mathbb{R}$$ (or even $x \in \mathbb{C}$ !) And then we can find $$\sum_{k=1}^{1/2} k = f\left(\frac{1}{2}\right) = \frac{3}{8}.$$ Another example where we can find such a sum is in the case of exponential functions. Consider $$\sum_{k=0}^{n-1} 2^k$$ for positive integer $n$ . It is easy to see this sums to $$\sum_{k=0}^{n-1} 2^k = 2^n - 1$$ which lets us find that $$\sum_{k=0}^{1/2} 2^k\ \text{""should be""}\ \sqrt{8} - 1 \approx 1.8284.$$ And of course for arbitrary $b$ , we have the geometric series $$\sum_{k=0}^{n-1} b^k = \frac{b^n - 1}{b - 1}.$$ However, what about for more general functions $f$ ? The fundamental problem is that, strictly speaking , these interpolants are not unique: most generally, we can ""connect the dots"" with any curves we like. Even if we impose some ""natural"" restrictions, say that $$\sum_{k=0}^{x} f(k) = f(x) + \sum_{k=0}^{x-1} f(k)$$ it isn't enough - the above reduces that freedom to now just an arbitrary 1-cyclic shift.  Yet, ""for some intuitive reason"", the above interpolants ""seem just right"": they are simple, comparable to the functions they came from, and are suitably ""graceful"", while other interpolants are necessarily more ""wiggly"" owing to the 1-cyclic displacement just mentioned. But is there something rigorous that both singles them out over all others, and which allows us to do similar interpolations on a very general range of functions $f$ , with such interpolations considered their analogues? Or to make it simpler, what distinguishes $\frac{x(x+1)}{2}$ uniquely from, say, $\frac{x(x+1)}{2} + \sin(2\pi x) -  \pi^{\gamma \Gamma\left(\frac{5}{3}\right)} \cos(4\pi x)$ or something, as an interpolant of that particular sum and which it shares with $2^x - 1$ (up to translation) versus $2^x$ ?","A long-time interest of mine has been trying to determine if there is some ""natural"" criterion by which we can characterize various interpolants of functions that are at first only defined for integer or positive-integer inputs, such as exponentiation and the factorial function, which generalize to the exponential and gamma functions. The aim ultimately is to create an explicit and efficient series formula for the interpolation of tetration to noninteger values of , in some suitably natural manner. But before we can get there, it seems more profitable to first look at simpler cases, and one of the simplest such cases seems to be interpolating discrete sums. For example, consider As written, this definition makes no sense for, say, . However, it is not hard to see that this can be converted into a ""closed form"" that, even better, doubles as an interpolative extension: which allows us to expand to real ""lengths"" via (or even !) And then we can find Another example where we can find such a sum is in the case of exponential functions. Consider for positive integer . It is easy to see this sums to which lets us find that And of course for arbitrary , we have the geometric series However, what about for more general functions ? The fundamental problem is that, strictly speaking , these interpolants are not unique: most generally, we can ""connect the dots"" with any curves we like. Even if we impose some ""natural"" restrictions, say that it isn't enough - the above reduces that freedom to now just an arbitrary 1-cyclic shift.  Yet, ""for some intuitive reason"", the above interpolants ""seem just right"": they are simple, comparable to the functions they came from, and are suitably ""graceful"", while other interpolants are necessarily more ""wiggly"" owing to the 1-cyclic displacement just mentioned. But is there something rigorous that both singles them out over all others, and which allows us to do similar interpolations on a very general range of functions , with such interpolations considered their analogues? Or to make it simpler, what distinguishes uniquely from, say, or something, as an interpolant of that particular sum and which it shares with (up to translation) versus ?","^n a = \underbrace{a^{a^{a^{\cdots^a}}}}_\text{n copies of a} n f(n) = \sum_{k=1}^{n} k. f\left(\frac{1}{2}\right) \sum_{k=1}^{n} k = \frac{n(n+1)}{2} x \sum_{k=1}^{x} k := \frac{x(x+1)}{2}, x \in \mathbb{R} x \in \mathbb{C} \sum_{k=1}^{1/2} k = f\left(\frac{1}{2}\right) = \frac{3}{8}. \sum_{k=0}^{n-1} 2^k n \sum_{k=0}^{n-1} 2^k = 2^n - 1 \sum_{k=0}^{1/2} 2^k\ \text{""should be""}\ \sqrt{8} - 1 \approx 1.8284. b \sum_{k=0}^{n-1} b^k = \frac{b^n - 1}{b - 1}. f \sum_{k=0}^{x} f(k) = f(x) + \sum_{k=0}^{x-1} f(k) f \frac{x(x+1)}{2} \frac{x(x+1)}{2} + \sin(2\pi x) -  \pi^{\gamma \Gamma\left(\frac{5}{3}\right)} \cos(4\pi x) 2^x - 1 2^x","['calculus', 'analysis', 'special-functions', 'functional-equations', 'interpolation']"
97,Finding $\lim_{x \to 0+}(2\sin \sqrt x + \sqrt x \sin \frac{1}{x})^x$,Finding,\lim_{x \to 0+}(2\sin \sqrt x + \sqrt x \sin \frac{1}{x})^x,"I need to compute a limit: $$\lim_{x \to 0+}(2\sin \sqrt x + \sqrt x \sin \frac{1}{x})^x$$ I tried to apply the L'Hôpital rule, but the emerging terms become too complicated and doesn't seem to simplify. $$ \lim_{x \to 0+}(2\sin \sqrt x + \sqrt x \sin \frac{1}{x})^x \\ = \exp (\lim_{x \to 0+} x \ln (2\sin \sqrt x + \sqrt x \sin \frac{1}{x})) \\ = \exp (\lim_{x \to 0+} \frac  {\ln (2\sin \sqrt x + \sqrt x \sin \frac{1}{x})}  {\frac 1 x}) \\ = \exp \lim_{x \to 0+} \dfrac  {\dfrac {\cos \sqrt x} {x} + \dfrac {\sin \dfrac 1 x} {2 \sqrt x}  - \dfrac {\cos \dfrac 1 x} {x^{3/2}}}  {- \dfrac {1} {x^2} \left(2\sin \sqrt x + \sqrt x \sin \frac{1}{x} \right)}  $$ I've calculated several values of this function, and it seems to have a limit of $1$ .","I need to compute a limit: I tried to apply the L'Hôpital rule, but the emerging terms become too complicated and doesn't seem to simplify. I've calculated several values of this function, and it seems to have a limit of .","\lim_{x \to 0+}(2\sin \sqrt x + \sqrt x \sin \frac{1}{x})^x 
\lim_{x \to 0+}(2\sin \sqrt x + \sqrt x \sin \frac{1}{x})^x \\
= \exp (\lim_{x \to 0+} x \ln (2\sin \sqrt x + \sqrt x \sin \frac{1}{x})) \\
= \exp (\lim_{x \to 0+} \frac 
{\ln (2\sin \sqrt x + \sqrt x \sin \frac{1}{x})} 
{\frac 1 x}) \\
= \exp \lim_{x \to 0+} \dfrac 
{\dfrac {\cos \sqrt x} {x} + \dfrac {\sin \dfrac 1 x} {2 \sqrt x} 
- \dfrac {\cos \dfrac 1 x} {x^{3/2}}} 
{- \dfrac {1} {x^2} \left(2\sin \sqrt x + \sqrt x \sin \frac{1}{x} \right)} 
 1","['calculus', 'limits']"
98,Maximum ellipse inscribed in Witch of Agnesi curve,Maximum ellipse inscribed in Witch of Agnesi curve,,"An ellipse with variable $(2a,2b)$ axes parallel to the $(x,y)$ coordinate axes is inscribed inside fixed curve of equation. $$ y=\pm\dfrac{1}{1+x^2}$$ Show that maximum ellipse area occurs when it touches the curve at its inflection point. I am looking to generalizing a variable ellipse contact point with a curve having an inflection, like in the recent Bell Curve post. My intuition needs to be validated or disproved later using simple methods of differential calculus.","An ellipse with variable axes parallel to the coordinate axes is inscribed inside fixed curve of equation. Show that maximum ellipse area occurs when it touches the curve at its inflection point. I am looking to generalizing a variable ellipse contact point with a curve having an inflection, like in the recent Bell Curve post. My intuition needs to be validated or disproved later using simple methods of differential calculus.","(2a,2b) (x,y)  y=\pm\dfrac{1}{1+x^2}","['calculus', 'geometry']"
99,Line integral over conservative vector field not independent of path?,Line integral over conservative vector field not independent of path?,,"I have a vector field $$F(x,y) = \langle x^2 + y^2, 2xy\rangle$$ which is conservative. I also have a curve $C$ defined as the boundary of the region between the two curves $y = x+2$ and $y = x^2$ . Since $F$ is conservative, I know that the circulation of $F$ over $C$ must be zero. However, if I wanted arrive at this conclusion using strict computation (without Green's theorem), I could try the following. Break $C$ into pieces using curves $C_1$ and $C_2$ ; here, $C_1$ has the parameterization $r(t) = \langle t, t^2\rangle$ where $t$ flows from $-1$ to $2$ , and $C_2$ has the parameterization $s(t) = \langle t, t+2\rangle$ where $t$ flows from $2$ to $-1$ . I'll compute the circulation as: $$\oint_C F = \int_{-1}^2 [F(r(t))\cdot r'(t)]~dt + \int_2^{-1} [F(s(t))\cdot s'(t)]~dt.$$ I find that evaluating $F$ at these parameterizations results in $$F(r(t)) = \langle t^2 + t^4, 2t^3\rangle; \quad F(s(t)) = \langle 2t^2 + 2t + 4, 2t^2 + 4t\rangle.$$ Since the derivative of my parameterizations are $r'(t) = \langle 1,2t\rangle$ and $s'(t) = \langle 1, 1\rangle$ , I can compute the corresponding dot products and I get the expression $$\oint_C F = \int_{-1}^2 (5t^4 + t^2)~dt - \int_{-1}^2 (4t^2 + 6t + 4)~dt = \int_{-1}^2 (5t^4 - 3t^2 - 6t - 4)~dt.$$ Curiously enough, this evaluates to $3$ and not $0$ . What am I doing wrong here?","I have a vector field which is conservative. I also have a curve defined as the boundary of the region between the two curves and . Since is conservative, I know that the circulation of over must be zero. However, if I wanted arrive at this conclusion using strict computation (without Green's theorem), I could try the following. Break into pieces using curves and ; here, has the parameterization where flows from to , and has the parameterization where flows from to . I'll compute the circulation as: I find that evaluating at these parameterizations results in Since the derivative of my parameterizations are and , I can compute the corresponding dot products and I get the expression Curiously enough, this evaluates to and not . What am I doing wrong here?","F(x,y) = \langle x^2 + y^2, 2xy\rangle C y = x+2 y = x^2 F F C C C_1 C_2 C_1 r(t) = \langle t, t^2\rangle t -1 2 C_2 s(t) = \langle t, t+2\rangle t 2 -1 \oint_C F = \int_{-1}^2 [F(r(t))\cdot r'(t)]~dt + \int_2^{-1} [F(s(t))\cdot s'(t)]~dt. F F(r(t)) = \langle t^2 + t^4, 2t^3\rangle; \quad F(s(t)) = \langle 2t^2 + 2t + 4, 2t^2 + 4t\rangle. r'(t) = \langle 1,2t\rangle s'(t) = \langle 1, 1\rangle \oint_C F = \int_{-1}^2 (5t^4 + t^2)~dt - \int_{-1}^2 (4t^2 + 6t + 4)~dt = \int_{-1}^2 (5t^4 - 3t^2 - 6t - 4)~dt. 3 0","['calculus', 'multivariable-calculus', 'line-integrals']"
