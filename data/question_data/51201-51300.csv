,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Two similar integration about continued fractions,Two similar integration about continued fractions,,"Prove that \begin{align*} \int_0^{+\infty} \cfrac{\sin nx}{x + \cfrac{1}{x + \cfrac{2}{x + \cfrac{3}{x + \cdots}}}} \, dx &= \cfrac{\sqrt {\cfrac{\pi }{2}} }{n + \cfrac{1}{n + \cfrac{2}{n + \cfrac{3}{n + \cdots}}}}\\ \int_0^{+\infty} \cfrac{\sin \cfrac{n\pi x}{2}}{x + \cfrac{1^2}{x + \cfrac{2^2}{x + \cfrac{3^2}{x + \cdots}}}} \, dx  &= \cfrac{1}{n + \cfrac{1^2}{n + \cfrac{2^2}{n + \cfrac{3^2}{n + \cdots}}}}.\end{align*} We can follow this : For the first one, we use $$\cfrac{1}{x + \cfrac{1}{x + \cfrac{2}{x + \cdots}}} = e^{x^2/2} \int_x^\infty e^{-t^2/2} \, dt .$$ Then we must prove $$\int_0^{+\infty} \sin nx \cdot e^{x^2/2} \, dx \int_x^\infty e^{-t^2/2 \, dt}  = \sqrt {\cfrac{\pi }{2}}  \cdot e^{n^2/2} \int_n^\infty e^{-t^2/2} \, dt .$$ For the second one, we use $$\cfrac{1}{x + \cfrac{1^2}{x + \cfrac{2^2}{x + \cfrac{3^2}{x +  \cdots }}}} = 2\sum_{n = 1}^\infty \cfrac{(-1)^{n + 1}}{x + 2n - 1} = 2 \int_0^1 \cfrac{t^x}{1 + t^2} \, dt.$$ We need to show $$\int_0^1 \cfrac{2n\pi}{(1 + x^2)(n^2 \pi ^2 + 4\ln^2 x)}dx = \int_0^1 \frac{x^n}{1 + x^2} \, dx .$$ But how can we continue?","Prove that \begin{align*} \int_0^{+\infty} \cfrac{\sin nx}{x + \cfrac{1}{x + \cfrac{2}{x + \cfrac{3}{x + \cdots}}}} \, dx &= \cfrac{\sqrt {\cfrac{\pi }{2}} }{n + \cfrac{1}{n + \cfrac{2}{n + \cfrac{3}{n + \cdots}}}}\\ \int_0^{+\infty} \cfrac{\sin \cfrac{n\pi x}{2}}{x + \cfrac{1^2}{x + \cfrac{2^2}{x + \cfrac{3^2}{x + \cdots}}}} \, dx  &= \cfrac{1}{n + \cfrac{1^2}{n + \cfrac{2^2}{n + \cfrac{3^2}{n + \cdots}}}}.\end{align*} We can follow this : For the first one, we use $$\cfrac{1}{x + \cfrac{1}{x + \cfrac{2}{x + \cdots}}} = e^{x^2/2} \int_x^\infty e^{-t^2/2} \, dt .$$ Then we must prove $$\int_0^{+\infty} \sin nx \cdot e^{x^2/2} \, dx \int_x^\infty e^{-t^2/2 \, dt}  = \sqrt {\cfrac{\pi }{2}}  \cdot e^{n^2/2} \int_n^\infty e^{-t^2/2} \, dt .$$ For the second one, we use $$\cfrac{1}{x + \cfrac{1^2}{x + \cfrac{2^2}{x + \cfrac{3^2}{x +  \cdots }}}} = 2\sum_{n = 1}^\infty \cfrac{(-1)^{n + 1}}{x + 2n - 1} = 2 \int_0^1 \cfrac{t^x}{1 + t^2} \, dt.$$ We need to show $$\int_0^1 \cfrac{2n\pi}{(1 + x^2)(n^2 \pi ^2 + 4\ln^2 x)}dx = \int_0^1 \frac{x^n}{1 + x^2} \, dx .$$ But how can we continue?",,"['calculus', 'integration', 'continued-fractions']"
1,Dirac delta - sifting,Dirac delta - sifting,,"We know $\int_{-\infty}^\infty \delta(x-a)f(x) \, dx=f(a)  $ Is this still true for: $\int_{-\infty}^\infty \delta(a-x)f(x) \, dx=f(a)  $ In general, can we call dirac delta even function?","We know $\int_{-\infty}^\infty \delta(x-a)f(x) \, dx=f(a)  $ Is this still true for: $\int_{-\infty}^\infty \delta(a-x)f(x) \, dx=f(a)  $ In general, can we call dirac delta even function?",,"['integration', 'dirac-delta']"
2,"The distance to smooth boundary, raised to a power between $-1$ and $0$, is integrable","The distance to smooth boundary, raised to a power between  and , is integrable",-1 0,"Let $\Omega$ be a bounded domain of $\mathbb{R}^N$ with smooth boundary.  Show that ${\rm dist}(x,\partial \Omega)^{-\vartheta} \in L^1(\Omega)$ if $\vartheta \in (0,1)$. I can see why if $\Omega$ is a ball centred at the origin.  I don't know how to show it though if it isn't (or indeed, if the assumption that $\Omega$ has a smooth boundary is necessary). Edit: just some minor clarifications","Let $\Omega$ be a bounded domain of $\mathbb{R}^N$ with smooth boundary.  Show that ${\rm dist}(x,\partial \Omega)^{-\vartheta} \in L^1(\Omega)$ if $\vartheta \in (0,1)$. I can see why if $\Omega$ is a ball centred at the origin.  I don't know how to show it though if it isn't (or indeed, if the assumption that $\Omega$ has a smooth boundary is necessary). Edit: just some minor clarifications",,"['real-analysis', 'integration', 'lp-spaces']"
3,Prove that the series $\frac{x!}{x^x}$ converges using the integral test,Prove that the series  converges using the integral test,\frac{x!}{x^x},"The series $\sum\limits_{n=1}^{\infty}\frac{n!}{n^n}$ is clearly positive and decreasing, but how does one go about integrating $\int\frac{x!}{x^x} dx$ ?","The series $\sum\limits_{n=1}^{\infty}\frac{n!}{n^n}$ is clearly positive and decreasing, but how does one go about integrating $\int\frac{x!}{x^x} dx$ ?",,"['calculus', 'integration']"
4,How does this 'chain rule manipulation' work?,How does this 'chain rule manipulation' work?,,"PS- this is a ""physics"" question, but mathematical in nature... if I should ask on physics SE instead, please let me know Looking back through my physics books, I found a derivation of Kinetic Energy, where it begins by defining work ($W$) as the integral of the sum of all forces acting on an object over the distance that the object moves: $$W = \int_{x_i}^{x_f}\sum\vec{F}\,\mathrm{d}x$$ It then goes through some manipulations (using Newton's second law ($F = ma$) and acceleration being the derivative of velocity) to perform the following: $$W = \int_{x_i}^{x_f}ma\,\mathrm{d}x = \int_{x_i}^{x_f}m\frac{\mathrm{d}v}{\mathrm{d}t}\,\mathrm{d}x $$ And then it claims that it uses ""chain rule manipulations"" to do this: $$\int_{x_i}^{x_f}m\frac{\mathrm{d}v}{\mathrm{d}t}\,\mathrm{d}x = \int_{x_i}^{x_f}m\frac{\mathrm{d}v}{\mathrm{d}x}\frac{\mathrm{d}x}{\mathrm{d}t}\,\mathrm{d}x=\int_{v_i}^{v_f}mv\,\mathrm{d}v$$ What's going on here, exactly? Why were they able to use the definition of the chain rule? (Under what conditions could you do this?) Why did the integrand compress into $v\,\mathrm{d}v$? Does the fact that $\frac{\mathrm{d}v}{\mathrm{d}t}$ became $\frac{\mathrm{d}v}{\mathrm{d}x}\frac{\mathrm{d}x}{\mathrm{d}t}$ tell us that $v$ is a function of $x$, and $x$ is a function of $t$? Why is there a change of variable in the limits of integration?","PS- this is a ""physics"" question, but mathematical in nature... if I should ask on physics SE instead, please let me know Looking back through my physics books, I found a derivation of Kinetic Energy, where it begins by defining work ($W$) as the integral of the sum of all forces acting on an object over the distance that the object moves: $$W = \int_{x_i}^{x_f}\sum\vec{F}\,\mathrm{d}x$$ It then goes through some manipulations (using Newton's second law ($F = ma$) and acceleration being the derivative of velocity) to perform the following: $$W = \int_{x_i}^{x_f}ma\,\mathrm{d}x = \int_{x_i}^{x_f}m\frac{\mathrm{d}v}{\mathrm{d}t}\,\mathrm{d}x $$ And then it claims that it uses ""chain rule manipulations"" to do this: $$\int_{x_i}^{x_f}m\frac{\mathrm{d}v}{\mathrm{d}t}\,\mathrm{d}x = \int_{x_i}^{x_f}m\frac{\mathrm{d}v}{\mathrm{d}x}\frac{\mathrm{d}x}{\mathrm{d}t}\,\mathrm{d}x=\int_{v_i}^{v_f}mv\,\mathrm{d}v$$ What's going on here, exactly? Why were they able to use the definition of the chain rule? (Under what conditions could you do this?) Why did the integrand compress into $v\,\mathrm{d}v$? Does the fact that $\frac{\mathrm{d}v}{\mathrm{d}t}$ became $\frac{\mathrm{d}v}{\mathrm{d}x}\frac{\mathrm{d}x}{\mathrm{d}t}$ tell us that $v$ is a function of $x$, and $x$ is a function of $t$? Why is there a change of variable in the limits of integration?",,"['integration', 'derivatives', 'physics']"
5,How to find the integral $\int_0^z \exp(ax)x^{b-1}(1-x)^{c-1}dx$?,How to find the integral ?,\int_0^z \exp(ax)x^{b-1}(1-x)^{c-1}dx,"How to find the integral $\int_0^z \exp(ax)x^{b-1}(1-x)^{c-1}\text{d}x$ where $b,c\in \mathbb{C}, \Re(b)>0, \Re(c)>0$?","How to find the integral $\int_0^z \exp(ax)x^{b-1}(1-x)^{c-1}\text{d}x$ where $b,c\in \mathbb{C}, \Re(b)>0, \Re(c)>0$?",,"['integration', 'hypergeometric-function']"
6,Definite integral $1/(x^2-b^2)$ over the real axis,Definite integral  over the real axis,1/(x^2-b^2),"I'm interested in the definite integral \begin{align} I\equiv\int_{-\infty}^{\infty} \frac{1}{x^2-b^2}=\int_{-\infty}^{\infty} \frac{1}{(x+b) (x-b)}.\tag{1} \end{align} Obviously, it has two poles ($x=b, x=-b$) on the real axes and is thus singular. I tried to apply the contour integration methods mentioned here , where they discuss the integral \begin{align} \int_{-\infty}^{\infty}\frac{e^{iax}}{x^2 - b^2}dx = -\frac{\pi}{b}\sin(ab),\tag{2} \end{align} where the r.h.s. is the solution derivable in multiple ways as shown in the above thread (e.g. circumventing the poles with infinitesimal arcs). However, since in the seemingly more simple case (1) the nominator is symmetric in constrast to the situation in (2), I obtain $$I=0,$$ as the residues equal up to different signs. E.g. consider the limit $a\rightarrow 0$ in (2) which gives $\sin(ab)\rightarrow 0$. Based on some literature (in the context in which the integral is appearing) it seems that one should obtain \begin{align} I=-\frac{i\pi}{b}. \end{align} Of course, this can be realized by considering the modified integral \begin{align} I_{mod}\equiv\lim_{\eta\rightarrow 0^+} \int_{-\infty}^{\infty} dx \frac{1}{x^2-b^2+i\eta}, \end{align} and closing the contour (e.g. a box closed at infinity) in the lower half plane. However, in this approach one seems to have some freedom (sign of the infinitesimal contribution, why shift one pole upwards and another pole downwards and not e.g. both upwards?) So let me explicitly phrase my questions: Is the value of the definite integral in (1) well-defined? Is it equal to zero? In any case, why would I include an infinitesimal shift as in (2) and not in another way? Thank you very much in advance!","I'm interested in the definite integral \begin{align} I\equiv\int_{-\infty}^{\infty} \frac{1}{x^2-b^2}=\int_{-\infty}^{\infty} \frac{1}{(x+b) (x-b)}.\tag{1} \end{align} Obviously, it has two poles ($x=b, x=-b$) on the real axes and is thus singular. I tried to apply the contour integration methods mentioned here , where they discuss the integral \begin{align} \int_{-\infty}^{\infty}\frac{e^{iax}}{x^2 - b^2}dx = -\frac{\pi}{b}\sin(ab),\tag{2} \end{align} where the r.h.s. is the solution derivable in multiple ways as shown in the above thread (e.g. circumventing the poles with infinitesimal arcs). However, since in the seemingly more simple case (1) the nominator is symmetric in constrast to the situation in (2), I obtain $$I=0,$$ as the residues equal up to different signs. E.g. consider the limit $a\rightarrow 0$ in (2) which gives $\sin(ab)\rightarrow 0$. Based on some literature (in the context in which the integral is appearing) it seems that one should obtain \begin{align} I=-\frac{i\pi}{b}. \end{align} Of course, this can be realized by considering the modified integral \begin{align} I_{mod}\equiv\lim_{\eta\rightarrow 0^+} \int_{-\infty}^{\infty} dx \frac{1}{x^2-b^2+i\eta}, \end{align} and closing the contour (e.g. a box closed at infinity) in the lower half plane. However, in this approach one seems to have some freedom (sign of the infinitesimal contribution, why shift one pole upwards and another pole downwards and not e.g. both upwards?) So let me explicitly phrase my questions: Is the value of the definite integral in (1) well-defined? Is it equal to zero? In any case, why would I include an infinitesimal shift as in (2) and not in another way? Thank you very much in advance!",,"['calculus', 'integration', 'definite-integrals', 'contour-integration']"
7,Integral of monomial and logarithm: is this true? $\lim_{k\to -1}\frac{x^{k+1}}{k+1} = \log|x|$,Integral of monomial and logarithm: is this true?,\lim_{k\to -1}\frac{x^{k+1}}{k+1} = \log|x|,"It is well know that: $$\int x^k \text{d}x = \begin{cases} \displaystyle\frac{x^{k+1}}{k+1} + c & k \neq -1\\ \\ \log|x| + c & k = -1\end{cases}$$ My guess is: $$\lim_{k\to -1}\frac{x^{k+1}}{k+1} = \log|x| ???$$ Apparently, this limit goes to infinity when $x>0$. Having said that, is there something that ""join"" monomial to logarithm? I mean, why the integral of a monomial is a monomial except for the case $k=-1$? Addition I know very well that this is because  $$\frac{\text{d}}{\text{d}x} \log(x) = \lim_{h \to 0^+} \frac{\log(x+h)-\log(x)}{h} =  \frac{1}{x}.$$ Anyway, the scheme ""integral of monomial is a monomial"" is somehow broken. What is the ""deep"" reason for this situation?","It is well know that: $$\int x^k \text{d}x = \begin{cases} \displaystyle\frac{x^{k+1}}{k+1} + c & k \neq -1\\ \\ \log|x| + c & k = -1\end{cases}$$ My guess is: $$\lim_{k\to -1}\frac{x^{k+1}}{k+1} = \log|x| ???$$ Apparently, this limit goes to infinity when $x>0$. Having said that, is there something that ""join"" monomial to logarithm? I mean, why the integral of a monomial is a monomial except for the case $k=-1$? Addition I know very well that this is because  $$\frac{\text{d}}{\text{d}x} \log(x) = \lim_{h \to 0^+} \frac{\log(x+h)-\log(x)}{h} =  \frac{1}{x}.$$ Anyway, the scheme ""integral of monomial is a monomial"" is somehow broken. What is the ""deep"" reason for this situation?",,"['integration', 'limits']"
8,"Prove $ \lim\limits_{n\to\infty}\int_0^1 f(x)g(nx)\,dx=\int_0^1 f(x)\,dx\int_0^1 g(x) \, dx $ [duplicate]",Prove  [duplicate]," \lim\limits_{n\to\infty}\int_0^1 f(x)g(nx)\,dx=\int_0^1 f(x)\,dx\int_0^1 g(x) \, dx ","This question already has answers here : Putnam 1967 problem, integration (3 answers) Closed 9 years ago . Let $f$ and $g$ be a real valued continuous functions on $\mathbb{R}$ such that $f(x+1)=f(x)$ and $g(x+1)=g(x)$ for all $x\in \mathbb{R}$. Prove that $$ \lim_{n\to\infty}\int_0^1 f(x)g(nx)\,dx=\int_0^1 f(x)\,dx\int_0^1 g(x)\,dx. $$","This question already has answers here : Putnam 1967 problem, integration (3 answers) Closed 9 years ago . Let $f$ and $g$ be a real valued continuous functions on $\mathbb{R}$ such that $f(x+1)=f(x)$ and $g(x+1)=g(x)$ for all $x\in \mathbb{R}$. Prove that $$ \lim_{n\to\infty}\int_0^1 f(x)g(nx)\,dx=\int_0^1 f(x)\,dx\int_0^1 g(x)\,dx. $$",,"['real-analysis', 'integration']"
9,What are some tips/techniques that might help me solve this (brutal) differential equation?,What are some tips/techniques that might help me solve this (brutal) differential equation?,,"I've been working on a certain physics problem involving differential equation for two years. I've made some progress on it recently, but I've come across another roadblock, namely an integral that I have no idea how to compute. What are some tips or techniques that might help me evaluate it? I've been having trouble with it because I've nev taken a diff-eq class, although I'm also aware that this is a difficult problem in itself (non-linear second order equation). Please note: I do NOT want the solution the the problem, just the tools to solve it myself. Here's the problem: There is a fixed massive body at the origin and another object on the x axis with some initial velocity in the x direction. Find an equation that describes the position of the orbiting object with respect to time. Here is my work so far. Let me know if I've made a mistake. Note that a is the derivative of v, which is the derivative of r, and G,M, and m are constants. Start with $F=ma$ The gravitational force between two objects is $$F_g=-\frac{GMm}{r^2},$$ so $$-\frac{GMm}{r^2}=ma$$ and $$-\frac{GM}{r^2}=a.$$ Now, $$a=\frac{dv}{dt}=\frac{dv}{dr}\frac{dr}{dt}=v\frac{dv}{dr},$$ so $$-\frac{GM}{r^2}=v\frac{dv}{dr}$$ $$-\frac{GM}{r^2}dr=vdv$$ Integrating both sides I get $$\int_{r_o}^{r}-\frac{GM}{r^2}dr=\int_{v_o}^{v}vdv$$ where $r_o$ and $v_o$ are initial radius and velocity. This becomes $$\frac{GM}{r}-\frac{GM}{r_o}=\frac{1}{2}(v^2-v_o^2)$$ $$\pm\sqrt{\frac{2GMr_o-2GMr+v^2_or_or}{rr_o}}=\frac{dr}{dt}$$ $$\pm\int_{r_0}^{r}\sqrt{\frac{r_or}{2GMr_o-2GMr+v^2_or_or}}dr=\int_{0}^{t}dt$$ $$\pm\int_{r_0}^{r}\sqrt{\frac{r_or}{2GMr_o-2GMr+v^2_or_or}}dr=t$$ Which is obscene. I just have no idea how to do this. I've tried rewriting it all sorts of ways with little to no luck. What can I do?","I've been working on a certain physics problem involving differential equation for two years. I've made some progress on it recently, but I've come across another roadblock, namely an integral that I have no idea how to compute. What are some tips or techniques that might help me evaluate it? I've been having trouble with it because I've nev taken a diff-eq class, although I'm also aware that this is a difficult problem in itself (non-linear second order equation). Please note: I do NOT want the solution the the problem, just the tools to solve it myself. Here's the problem: There is a fixed massive body at the origin and another object on the x axis with some initial velocity in the x direction. Find an equation that describes the position of the orbiting object with respect to time. Here is my work so far. Let me know if I've made a mistake. Note that a is the derivative of v, which is the derivative of r, and G,M, and m are constants. Start with The gravitational force between two objects is so and Now, so Integrating both sides I get where and are initial radius and velocity. This becomes Which is obscene. I just have no idea how to do this. I've tried rewriting it all sorts of ways with little to no luck. What can I do?","F=ma F_g=-\frac{GMm}{r^2}, -\frac{GMm}{r^2}=ma -\frac{GM}{r^2}=a. a=\frac{dv}{dt}=\frac{dv}{dr}\frac{dr}{dt}=v\frac{dv}{dr}, -\frac{GM}{r^2}=v\frac{dv}{dr} -\frac{GM}{r^2}dr=vdv \int_{r_o}^{r}-\frac{GM}{r^2}dr=\int_{v_o}^{v}vdv r_o v_o \frac{GM}{r}-\frac{GM}{r_o}=\frac{1}{2}(v^2-v_o^2) \pm\sqrt{\frac{2GMr_o-2GMr+v^2_or_or}{rr_o}}=\frac{dr}{dt} \pm\int_{r_0}^{r}\sqrt{\frac{r_or}{2GMr_o-2GMr+v^2_or_or}}dr=\int_{0}^{t}dt \pm\int_{r_0}^{r}\sqrt{\frac{r_or}{2GMr_o-2GMr+v^2_or_or}}dr=t","['integration', 'ordinary-differential-equations', 'physics']"
10,How we can find an equivalent of $\sum_{i=0}^n2^{2^i} $,How we can find an equivalent of,\sum_{i=0}^n2^{2^i} ,"How can we find an equivalent of the following sum: $$\sum_{i=0}^n2^{2^i}$$ Because using integrals I have been recently able to determine equivalences for a lot of sums using Riemann's theorem (sum to intgeral) but I'm not able to tackle this one. Any help, suggestions?","How can we find an equivalent of the following sum: $$\sum_{i=0}^n2^{2^i}$$ Because using integrals I have been recently able to determine equivalences for a lot of sums using Riemann's theorem (sum to intgeral) but I'm not able to tackle this one. Any help, suggestions?",,"['integration', 'sequences-and-series']"
11,"How to show $\int_0^{\infty} \frac{\sin(bx)\sin(x)}{x^2} \prod_{k=1}^n \cos^{p_k}(a_kx) \, \text{d} x= \frac{\pi}{2}$?",How to show ?,"\int_0^{\infty} \frac{\sin(bx)\sin(x)}{x^2} \prod_{k=1}^n \cos^{p_k}(a_kx) \, \text{d} x= \frac{\pi}{2}","I have found the following complicated integral in Table of Integrals, Series and Products (page 469; No. 37); the interesting thing about this integral is that for arbitrary parameters $p_k,a_k>0$ and arbitrary natural number $n$ it has the value $\frac{\pi}{2}$: $$\int_0^{\infty} \frac{\sin(bx)\sin(x)}{x^2} \prod_{k=1}^n \cos^{p_k}(a_kx) \text{d} x= \frac{\pi}{2}$$ A large integral that has only one value when integrated over the interval $[0, \infty]$, but how I can prove this interesting fact? Series expansion in the trigonometric functions does not make sense, I think. Can I use induction for proving this identity? The previous link to a PDF of the book no longer works.","I have found the following complicated integral in Table of Integrals, Series and Products (page 469; No. 37); the interesting thing about this integral is that for arbitrary parameters $p_k,a_k>0$ and arbitrary natural number $n$ it has the value $\frac{\pi}{2}$: $$\int_0^{\infty} \frac{\sin(bx)\sin(x)}{x^2} \prod_{k=1}^n \cos^{p_k}(a_kx) \text{d} x= \frac{\pi}{2}$$ A large integral that has only one value when integrated over the interval $[0, \infty]$, but how I can prove this interesting fact? Series expansion in the trigonometric functions does not make sense, I think. Can I use induction for proving this identity? The previous link to a PDF of the book no longer works.",,"['calculus', 'integration', 'definite-integrals']"
12,Evaluating $\int_{0}^{\infty}\frac{e^{-x^2}-e^{-x}}{x}dx $ [duplicate],Evaluating  [duplicate],\int_{0}^{\infty}\frac{e^{-x^2}-e^{-x}}{x}dx ,"This question already has answers here : Unusual integral (2 answers) Closed 9 years ago . I am working on this improper integral, $$\int_{0}^{\infty}\frac{e^{-x^2}-e^{-x}}{x}dx$$ First, I separate the integral into two pieces, I have $$\int_{0}^{\infty}\frac{e^{-x^2}}{x}dx -\int_{0}^{\infty}\frac{e^{-x}}{x}dx=I_1+I_2$$ I know that $I_2$ can use double integral, $$ I_2=\int_0^\infty  \int _1^\infty e^{-tx}  dt dx = \int _1^\infty \frac{1}{t}dt $$ $$ \int_0^\infty   (\frac{e^{-tx}}{-x}) \Bigg|_{1}^\infty   dx = \int_1^\infty \frac{1}{t}dt =\ln t \Bigg|_{1}^{\infty}=\infty$$ But I don't know how to do $I_1$, can someone give me a hit or suggestion? Thanks!","This question already has answers here : Unusual integral (2 answers) Closed 9 years ago . I am working on this improper integral, $$\int_{0}^{\infty}\frac{e^{-x^2}-e^{-x}}{x}dx$$ First, I separate the integral into two pieces, I have $$\int_{0}^{\infty}\frac{e^{-x^2}}{x}dx -\int_{0}^{\infty}\frac{e^{-x}}{x}dx=I_1+I_2$$ I know that $I_2$ can use double integral, $$ I_2=\int_0^\infty  \int _1^\infty e^{-tx}  dt dx = \int _1^\infty \frac{1}{t}dt $$ $$ \int_0^\infty   (\frac{e^{-tx}}{-x}) \Bigg|_{1}^\infty   dx = \int_1^\infty \frac{1}{t}dt =\ln t \Bigg|_{1}^{\infty}=\infty$$ But I don't know how to do $I_1$, can someone give me a hit or suggestion? Thanks!",,"['calculus', 'integration', 'analysis']"
13,Mollifiers: Integral Bound,Mollifiers: Integral Bound,,Desirable is an example such that: $$\varphi_0\in\mathcal{C}^\infty_0:\quad\int_0^\infty\left|\varphi_0^{(n)}(s)\right|\mathrm{d}s\leq2^n$$ (It should not exist as one would obtain entire elements for generators of semigroups.) How to prove that they must always exceed the bound?,Desirable is an example such that: $$\varphi_0\in\mathcal{C}^\infty_0:\quad\int_0^\infty\left|\varphi_0^{(n)}(s)\right|\mathrm{d}s\leq2^n$$ (It should not exist as one would obtain entire elements for generators of semigroups.) How to prove that they must always exceed the bound?,,"['real-analysis', 'integration', 'functional-analysis']"
14,Quadratic Expressions: Advanced techniques of Integration,Quadratic Expressions: Advanced techniques of Integration,,"$$\int \frac{x}{\sqrt{5+12x-9x^2}}\,dx$$ After two steps I arrive at $\displaystyle{ \int \frac{x}{\sqrt{9-(3x-2)^2}}}\,dx$ Using trigonometric substitution, we have a triangle with a cosine of $\theta$ of $\displaystyle{\sqrt{9-(3x-2)^2}\over 3}$ and a $\sin(\theta$) of $(3x-2)\over (3)$. The final two steps of solving give $\displaystyle {\frac{-1}{3}\cos(\theta) + \frac{2}{9}\theta +C}$ Therefore -$\displaystyle{\sqrt{9-(3x-2)^2}\over 9}$ Wolfram alpha says that there should be a positive sign, i.e. -$\displaystyle{\sqrt{9+(3x-2)^2}\over 9}$ How can that be possible given the value for cosine of theta?","$$\int \frac{x}{\sqrt{5+12x-9x^2}}\,dx$$ After two steps I arrive at $\displaystyle{ \int \frac{x}{\sqrt{9-(3x-2)^2}}}\,dx$ Using trigonometric substitution, we have a triangle with a cosine of $\theta$ of $\displaystyle{\sqrt{9-(3x-2)^2}\over 3}$ and a $\sin(\theta$) of $(3x-2)\over (3)$. The final two steps of solving give $\displaystyle {\frac{-1}{3}\cos(\theta) + \frac{2}{9}\theta +C}$ Therefore -$\displaystyle{\sqrt{9-(3x-2)^2}\over 9}$ Wolfram alpha says that there should be a positive sign, i.e. -$\displaystyle{\sqrt{9+(3x-2)^2}\over 9}$ How can that be possible given the value for cosine of theta?",,"['calculus', 'integration', 'indefinite-integrals']"
15,Integrate a periodic absolute value function,Integrate a periodic absolute value function,,\begin{equation} \int_{0}^t \left|\cos(t)\right|dt = \sin\left(t-\pi\left\lfloor{\frac{t}{\pi}+\frac{1}{2}}\right\rfloor\right)+2\left\lfloor{\frac{t}{\pi}+\frac{1}{2}}\right\rfloor \end{equation} I got the above integral from https://www.physicsforums.com/threads/closed-form-integral-of-abs-cos-x.761872/ . It seems to hold and the way I approached it was to see that the integrand was periodic and $\int_{\frac{\pi}{2}}^\frac{3\pi}{2} -\cos(t)dt=\int_{\frac{3\pi}{2}}^{\frac{5\pi}{2}} \cos(t)dt=\ldots=2$. I need to evaluate a similar integral. \begin{equation} \int_{0}^t \sin\left(\frac{1}{2}(s-t)\right)\left|\sin\left(\frac{1}{2}s\right)\right|ds \end{equation} Here too the integrand is periodic but I am unable to get the closed form. Can someone help me out?,\begin{equation} \int_{0}^t \left|\cos(t)\right|dt = \sin\left(t-\pi\left\lfloor{\frac{t}{\pi}+\frac{1}{2}}\right\rfloor\right)+2\left\lfloor{\frac{t}{\pi}+\frac{1}{2}}\right\rfloor \end{equation} I got the above integral from https://www.physicsforums.com/threads/closed-form-integral-of-abs-cos-x.761872/ . It seems to hold and the way I approached it was to see that the integrand was periodic and $\int_{\frac{\pi}{2}}^\frac{3\pi}{2} -\cos(t)dt=\int_{\frac{3\pi}{2}}^{\frac{5\pi}{2}} \cos(t)dt=\ldots=2$. I need to evaluate a similar integral. \begin{equation} \int_{0}^t \sin\left(\frac{1}{2}(s-t)\right)\left|\sin\left(\frac{1}{2}s\right)\right|ds \end{equation} Here too the integrand is periodic but I am unable to get the closed form. Can someone help me out?,,"['integration', 'functions', 'absolute-value', 'periodic-functions']"
16,How to integrate $\int \frac{1}{\sqrt{1+29x^2+100x^4}}dx$ and $\int \frac{1}{\sqrt{1-2x^2-8x^4}}dx$ using elliptic functions?,How to integrate  and  using elliptic functions?,\int \frac{1}{\sqrt{1+29x^2+100x^4}}dx \int \frac{1}{\sqrt{1-2x^2-8x^4}}dx,"How to integrate $$\int \frac{1}{\sqrt{1+29x^2+100x^4}}dx$$ and $$\int\frac{1}{\sqrt{1-2x^2-8x^4}}dx$$  using elliptic functions? I have tried to use them, but I got incorrect formula $$\frac{1}{\sqrt{2}}F(arctan(\sqrt{2}x)∣3)$$ for the first one (second argument should be less or equal 1). Could anyone solve it? Thanks","How to integrate $$\int \frac{1}{\sqrt{1+29x^2+100x^4}}dx$$ and $$\int\frac{1}{\sqrt{1-2x^2-8x^4}}dx$$  using elliptic functions? I have tried to use them, but I got incorrect formula $$\frac{1}{\sqrt{2}}F(arctan(\sqrt{2}x)∣3)$$ for the first one (second argument should be less or equal 1). Could anyone solve it? Thanks",,"['calculus', 'integration', 'indefinite-integrals']"
17,"Evaluate $\int t^2 e^{-2i\pi nt}\,dt$",Evaluate,"\int t^2 e^{-2i\pi nt}\,dt","I need to get $$\int t^2 e^{-2i\pi nt}\,dt$$ I'm thinking to use integration by parts, but $\int e^{-2i\pi nt}\,dt$ is tripping me up. Can anybody help? Thanks!","I need to get $$\int t^2 e^{-2i\pi nt}\,dt$$ I'm thinking to use integration by parts, but $\int e^{-2i\pi nt}\,dt$ is tripping me up. Can anybody help? Thanks!",,"['calculus', 'integration', 'complex-numbers', 'indefinite-integrals']"
18,A Cosine Integral,A Cosine Integral,,"What is the value of the Cosine integral \begin{align} \int_{0}^{\infty} \cos\left( \frac{x (x^{2}-a^{2})}{x^{2}-b^{2}} \right) \, \frac{dx}{x^{2} + p^{2}} \, \, \, ? \end{align}","What is the value of the Cosine integral \begin{align} \int_{0}^{\infty} \cos\left( \frac{x (x^{2}-a^{2})}{x^{2}-b^{2}} \right) \, \frac{dx}{x^{2} + p^{2}} \, \, \, ? \end{align}",,"['integration', 'definite-integrals', 'contour-integration']"
19,Evaluate $\int_2^4\frac{\sqrt{x^2-4}}{x^2}\mathrm dx$,Evaluate,\int_2^4\frac{\sqrt{x^2-4}}{x^2}\mathrm dx,Evaluate $$\int\limits_2^4\frac{\sqrt{x^2-4}}{x^2}\mathrm dx$$ My working: $x=2\sec\theta\quad\Rightarrow\quad\theta=\arccos\left(\frac{2}{x}\right)$ $dx=2\sec\theta\tan\theta d\theta$ $I=\int\frac{\sqrt{4\sec^2\theta-4}}{4\sec^2\theta}2\sec\theta\tan\theta d\theta=\int\frac{\tan^2\theta}{\sec\theta}d\theta=\int\frac{\sin^2\theta}{\cos\theta}d\theta=\int\sec\theta d\theta-\int\cos\theta d\theta\\=\ln|\sec\theta+\tan\theta|-\sin\theta+C\\=\left.\ln\left|\frac{x}{2}+\frac{\sqrt{1-(2/x)^2}}{2/x}\right|-\sqrt{1-\left(\frac{2}{x}\right)^2}\right]_2^4$ EDIT $=\ln\left|\frac{4+\sqrt{12}}{2}\right|-\sqrt{1-\frac{1}{4}}-\ln\left|\frac{2+\sqrt{0}}{2}\right|-\sqrt{1-1}\\=\ln|2+\sqrt{3}|-\frac{\sqrt{3}}{2}\qquad\blacksquare$,Evaluate $$\int\limits_2^4\frac{\sqrt{x^2-4}}{x^2}\mathrm dx$$ My working: $x=2\sec\theta\quad\Rightarrow\quad\theta=\arccos\left(\frac{2}{x}\right)$ $dx=2\sec\theta\tan\theta d\theta$ $I=\int\frac{\sqrt{4\sec^2\theta-4}}{4\sec^2\theta}2\sec\theta\tan\theta d\theta=\int\frac{\tan^2\theta}{\sec\theta}d\theta=\int\frac{\sin^2\theta}{\cos\theta}d\theta=\int\sec\theta d\theta-\int\cos\theta d\theta\\=\ln|\sec\theta+\tan\theta|-\sin\theta+C\\=\left.\ln\left|\frac{x}{2}+\frac{\sqrt{1-(2/x)^2}}{2/x}\right|-\sqrt{1-\left(\frac{2}{x}\right)^2}\right]_2^4$ EDIT $=\ln\left|\frac{4+\sqrt{12}}{2}\right|-\sqrt{1-\frac{1}{4}}-\ln\left|\frac{2+\sqrt{0}}{2}\right|-\sqrt{1-1}\\=\ln|2+\sqrt{3}|-\frac{\sqrt{3}}{2}\qquad\blacksquare$,,['integration']
20,what are and why are sine and cosine modulated integrals used?,what are and why are sine and cosine modulated integrals used?,,"I have found the definition of the following formulas in a paper regarding active vibration control, where they are called sine and cosine modulated integrals. $y$ is measurement signal with a strong periodic component of frequency $N\Omega$ $$y^{(i)}_{Nc}=\frac{2}{T}\int^{T}_{0}y^{(i)}(ϕ)\cos(Nϕ)dϕ$$ $$y^{(i)}_{Ns}=\frac{2}{T}\int^{T}_{0}y^{(i)}(ϕ)\sin(Nϕ)dϕ$$ where $\phi=\Omega t$ . From these the vector $y_N^{(i)}$ is defined as $y_N^{(i)} = \begin{bmatrix} y_{Nc}^{(1)}\\ y_{Ns}^{(1)}\\\vdots\end{bmatrix}$ The same is done for the control input(s) $u$ . Then a quadratic cost function to be minimised at each step is defined using these newly introduced signals in this way: $$J(k) = y^T_NQy_N+u^T_NRu_N $$ where $Q$ and $R$ are just two weighing matrices. They should extract the harmonic component considered but is anybody able to explain them a little bit further? Here the link for the paper Another question: suppose I have the value $y_N$ : how can I invert the relationship to get $y^{(i)}$ Here the link for the paper.","I have found the definition of the following formulas in a paper regarding active vibration control, where they are called sine and cosine modulated integrals. is measurement signal with a strong periodic component of frequency where . From these the vector is defined as The same is done for the control input(s) . Then a quadratic cost function to be minimised at each step is defined using these newly introduced signals in this way: where and are just two weighing matrices. They should extract the harmonic component considered but is anybody able to explain them a little bit further? Here the link for the paper Another question: suppose I have the value : how can I invert the relationship to get Here the link for the paper.",y N\Omega y^{(i)}_{Nc}=\frac{2}{T}\int^{T}_{0}y^{(i)}(ϕ)\cos(Nϕ)dϕ y^{(i)}_{Ns}=\frac{2}{T}\int^{T}_{0}y^{(i)}(ϕ)\sin(Nϕ)dϕ \phi=\Omega t y_N^{(i)} y_N^{(i)} = \begin{bmatrix} y_{Nc}^{(1)}\\ y_{Ns}^{(1)}\\\vdots\end{bmatrix} u J(k) = y^T_NQy_N+u^T_NRu_N  Q R y_N y^{(i)},"['integration', 'definition']"
21,Requirements for integration by parts/ Divergence theorem,Requirements for integration by parts/ Divergence theorem,,"In order to use the integration by parts formula(or more generally the divergence theorem) for functions of several variables $$\int_{\Omega} \nabla u\cdot v d \Omega = \int_{\partial \Omega}(u(v \cdot \nu))d \Omega - \int_{\Omega}u\nabla \cdot v d\Omega$$ is it required that $\Omega$ is compact or at least just bounded subset of $\mathbb{R}^{n}$? Is it required that $\partial \Omega$ is at least Lipschitz continuous? If not, are there any restrictions on $\Omega$ and $\partial \Omega$? This question was inspired by the wiki entry 'integration by parts' and 'divergence theorem'. Thanks for any assistance.","In order to use the integration by parts formula(or more generally the divergence theorem) for functions of several variables $$\int_{\Omega} \nabla u\cdot v d \Omega = \int_{\partial \Omega}(u(v \cdot \nu))d \Omega - \int_{\Omega}u\nabla \cdot v d\Omega$$ is it required that $\Omega$ is compact or at least just bounded subset of $\mathbb{R}^{n}$? Is it required that $\partial \Omega$ is at least Lipschitz continuous? If not, are there any restrictions on $\Omega$ and $\partial \Omega$? This question was inspired by the wiki entry 'integration by parts' and 'divergence theorem'. Thanks for any assistance.",,"['calculus', 'integration']"
22,"Evaluate: $\int_{W(-1/\gamma)}^{W(1/\gamma)}\frac{e^{-u} \,\text{d}u}{\sqrt{1-(\gamma u e^{u})^2}}$",Evaluate:,"\int_{W(-1/\gamma)}^{W(1/\gamma)}\frac{e^{-u} \,\text{d}u}{\sqrt{1-(\gamma u e^{u})^2}}","Evaluate the integral $$ P(\gamma)=\int_{W(-1/\gamma)}^{W(1/\gamma)}\frac{e^{-u} \,\text{d}u}{\sqrt{1-(\gamma u e^{u})^2}} $$ where $\gamma$ is a real number not equal to $0$ and has whatever properties it needs to have to make the product logs in the limits defined. Note that the limits are exactly where the denominator of the integrand goes to zero. No way there's an elementary anti-derivative so there's probably some sort of contour integration involved but I can't quite figure it out. I can express the integral as an infinite sum of special functions by expanding the square root, but I was wondering if there was a more compact form.","Evaluate the integral $$ P(\gamma)=\int_{W(-1/\gamma)}^{W(1/\gamma)}\frac{e^{-u} \,\text{d}u}{\sqrt{1-(\gamma u e^{u})^2}} $$ where $\gamma$ is a real number not equal to $0$ and has whatever properties it needs to have to make the product logs in the limits defined. Note that the limits are exactly where the denominator of the integrand goes to zero. No way there's an elementary anti-derivative so there's probably some sort of contour integration involved but I can't quite figure it out. I can express the integral as an infinite sum of special functions by expanding the square root, but I was wondering if there was a more compact form.",,"['integration', 'definite-integrals', 'contour-integration']"
23,Solve $\int\frac{\sqrt{(x-5)(x+3)}}{(x-1)(x^2-25)}\ dx$,Solve,\int\frac{\sqrt{(x-5)(x+3)}}{(x-1)(x^2-25)}\ dx,I have some problems with the task. How to evaluate $$\int\frac{\sqrt{(x-5)(x+3)}}{(x-1)(x^2-25)}\ \mathrm{d}x$$ I have absolutely no idea. Help me please. Thank you.,I have some problems with the task. How to evaluate $$\int\frac{\sqrt{(x-5)(x+3)}}{(x-1)(x^2-25)}\ \mathrm{d}x$$ I have absolutely no idea. Help me please. Thank you.,,"['integration', 'indefinite-integrals']"
24,Is there a useful relationship between pointwise and $L^2$ distance?,Is there a useful relationship between pointwise and  distance?,L^2,"It would be really convenient to get a bound on the point-wise closeness of functions by knowing their $L^2$ distance. Clearly, if two functions are close in the $L^2$ sense, you cannot get a general bound on their point-wise distance, but maybe they are close along some parts of their domain. In my mind a theorem might go something like this: Given a measurable, bounded function $f:U\rightarrow\mathbb{R}$, if $||f||_2<\varepsilon$ then there is some 'small'  $\delta > 0$ and a set $V\subset U$ where $|f(x)|<\delta \ \forall\  x\in V,$ and $ \mu(V)\geq\mu(U)-\eta_{\varepsilon, \ \delta}$ Then if we had $f_1,f_2\ni||f_1-f_2||_2<\varepsilon$ there would be a 'fairly large' set $V$ where $|f_1-f_2| < \varepsilon$ throughout $V$. Do theorems like this exist?","It would be really convenient to get a bound on the point-wise closeness of functions by knowing their $L^2$ distance. Clearly, if two functions are close in the $L^2$ sense, you cannot get a general bound on their point-wise distance, but maybe they are close along some parts of their domain. In my mind a theorem might go something like this: Given a measurable, bounded function $f:U\rightarrow\mathbb{R}$, if $||f||_2<\varepsilon$ then there is some 'small'  $\delta > 0$ and a set $V\subset U$ where $|f(x)|<\delta \ \forall\  x\in V,$ and $ \mu(V)\geq\mu(U)-\eta_{\varepsilon, \ \delta}$ Then if we had $f_1,f_2\ni||f_1-f_2||_2<\varepsilon$ there would be a 'fairly large' set $V$ where $|f_1-f_2| < \varepsilon$ throughout $V$. Do theorems like this exist?",,"['real-analysis', 'integration', 'measure-theory', 'hilbert-spaces', 'normed-spaces']"
25,Problematic integral $\int_0^\pi \frac{x\sin x}{1+\cos^2x}\ dx$,Problematic integral,\int_0^\pi \frac{x\sin x}{1+\cos^2x}\ dx,"How to calculate $$\int_0^\pi \frac{x\sin x}{1+\cos^2x}\ dx\ ?$$ I wish I could say I ran out of ideas, but actually I have none.","How to calculate $$\int_0^\pi \frac{x\sin x}{1+\cos^2x}\ dx\ ?$$ I wish I could say I ran out of ideas, but actually I have none.",,"['integration', 'definite-integrals']"
26,Trigonometric substitution for $\int\frac{1}{x^2\sqrt{4-x^2}}dx$,Trigonometric substitution for,\int\frac{1}{x^2\sqrt{4-x^2}}dx,"I'm reviewing my quizzes to study for midterm tomorrow, and I came across a problem where I'm supposed to integrate: $$\int\frac{1}{x^2\sqrt{4-x^2}}dx$$ I used Mathematica to solve the problem and I'm sure it gave me the correct answer, which is: $$-\frac{\sqrt{4-x^2}}{4x}$$ I used $ x = 2\sin{\theta}$ and $dx = 2\cos{\theta}$ $d\theta$ to solve the problem, and I only got to $$\frac{1}{8}\int{\frac{1}{\sin^2{\theta}\cos{\theta}}}d\theta$$ Looking at step-by-step solution via WolframAlpha, they used $\theta = \arcsin{\frac{x}{2}}$ to solve the problem which I do not know how to. I don't think there is a need for $\theta = \arcsin{\frac{x}{2}}$ to solve the problem, and I'm wondering if anyone can show me how to solve this step by step without the use of $\theta = \arcsin{\frac{x}{2}}$? Maybe help me understand how to? Trigonometric substitution is the only method that I'm struggling with, and any tips on improving trig sub skill would be appreciated too. Thanks.","I'm reviewing my quizzes to study for midterm tomorrow, and I came across a problem where I'm supposed to integrate: $$\int\frac{1}{x^2\sqrt{4-x^2}}dx$$ I used Mathematica to solve the problem and I'm sure it gave me the correct answer, which is: $$-\frac{\sqrt{4-x^2}}{4x}$$ I used $ x = 2\sin{\theta}$ and $dx = 2\cos{\theta}$ $d\theta$ to solve the problem, and I only got to $$\frac{1}{8}\int{\frac{1}{\sin^2{\theta}\cos{\theta}}}d\theta$$ Looking at step-by-step solution via WolframAlpha, they used $\theta = \arcsin{\frac{x}{2}}$ to solve the problem which I do not know how to. I don't think there is a need for $\theta = \arcsin{\frac{x}{2}}$ to solve the problem, and I'm wondering if anyone can show me how to solve this step by step without the use of $\theta = \arcsin{\frac{x}{2}}$? Maybe help me understand how to? Trigonometric substitution is the only method that I'm struggling with, and any tips on improving trig sub skill would be appreciated too. Thanks.",,"['calculus', 'integration', 'trigonometry']"
27,Definite integral $\int_{R_0}^{R}\frac{dr}{r^2\sqrt{\frac{R_0-R_S}{R_0^3}-\frac{1}{r^2}\left(1-\frac{R_{s}}{r}\right)}}$,Definite integral,\int_{R_0}^{R}\frac{dr}{r^2\sqrt{\frac{R_0-R_S}{R_0^3}-\frac{1}{r^2}\left(1-\frac{R_{s}}{r}\right)}},"In general relativity, null geodesics (in the unbounded case) can be written under the following form : $$\frac{d\varphi}{dr}=\frac{1}{r^2\sqrt{\frac{R_0-R_S}{R_0^3}-\frac{1}{r^2}\left(1-\frac{R_{s}}{r}\right)}}$$ with: $\left(r, \varphi\right)$ the polar coordinates of the photon $R_S$ the Schwarschild radius of the central object ($R_S\in\mathbb{R^{+}_{*}}$) $R_0$ the distance of closest approach ($R_0 > \frac{3\sqrt{3}}{2}R_S$) Consequently, to compute the exact trajectory up to a radius $R$ (with $R > R_0$), one can evaluate: $$\varphi\left(R\right)=\int_{R_0}^{R}\frac{dr}{r^2\sqrt{\frac{R_0-R_S}{R_0^3}-\frac{1}{r^2}\left(1-\frac{R_{s}}{r}\right)}}$$ And now comes my question : is there an analytical formula (in terms of special functions for example) corresponding to this integral ? (I would like to compute this integral numerically and an expression in terms of special functions would help a lot).","In general relativity, null geodesics (in the unbounded case) can be written under the following form : $$\frac{d\varphi}{dr}=\frac{1}{r^2\sqrt{\frac{R_0-R_S}{R_0^3}-\frac{1}{r^2}\left(1-\frac{R_{s}}{r}\right)}}$$ with: $\left(r, \varphi\right)$ the polar coordinates of the photon $R_S$ the Schwarschild radius of the central object ($R_S\in\mathbb{R^{+}_{*}}$) $R_0$ the distance of closest approach ($R_0 > \frac{3\sqrt{3}}{2}R_S$) Consequently, to compute the exact trajectory up to a radius $R$ (with $R > R_0$), one can evaluate: $$\varphi\left(R\right)=\int_{R_0}^{R}\frac{dr}{r^2\sqrt{\frac{R_0-R_S}{R_0^3}-\frac{1}{r^2}\left(1-\frac{R_{s}}{r}\right)}}$$ And now comes my question : is there an analytical formula (in terms of special functions for example) corresponding to this integral ? (I would like to compute this integral numerically and an expression in terms of special functions would help a lot).",,"['integration', 'special-functions', 'improper-integrals', 'indefinite-integrals', 'general-relativity']"
28,Compute a multiple integral.,Compute a multiple integral.,,"A friend of mine asked me to help compute the multiple integral:$$\iint_{(D)} \frac{x^2 y^2}{4+9x^4 y^4}\text{d}\sigma, \ \ D:x^2+y^2\le2.$$ But I find it extremely hard. Is there a simpler way to compute it?","A friend of mine asked me to help compute the multiple integral:$$\iint_{(D)} \frac{x^2 y^2}{4+9x^4 y^4}\text{d}\sigma, \ \ D:x^2+y^2\le2.$$ But I find it extremely hard. Is there a simpler way to compute it?",,"['integration', 'multivariable-calculus']"
29,Does this integral have any closed form? $\int\frac{1}{x+\sin(x+1)}\mathop{\mathrm dx}$,Does this integral have any closed form?,\int\frac{1}{x+\sin(x+1)}\mathop{\mathrm dx},"Does this integral have any closed form? $$\int\frac{1}{x+\sin(x+1)}\mathop{\mathrm dx}$$ I think the substitution $x=(u-1)+2\pi$ will do it, no?","Does this integral have any closed form? $$\int\frac{1}{x+\sin(x+1)}\mathop{\mathrm dx}$$ I think the substitution $x=(u-1)+2\pi$ will do it, no?",,"['calculus', 'integration', 'indefinite-integrals', 'closed-form']"
30,Need help evaluating $\lim\limits_{n \to \infty} \frac{1}{n} \int_1^n \Vert\frac{n}{x}\Vert dx$,Need help evaluating,\lim\limits_{n \to \infty} \frac{1}{n} \int_1^n \Vert\frac{n}{x}\Vert dx,"$$ \mbox{Evaluate}\quad \lim_{n \to \infty}{1 \over n}\int_{1}^{n}\left\Vert\,n \over x\,\right\Vert \,{\rm d}x $$ Where $\left\vert\left\vert\, x\,\right\vert\right\vert : \mathbb{R} \to \mathbb{R}$ denotes the [distance to the] closest integer to $x$. As an explicit example, $\left\Vert\, 4.7\,\right\Vert = 0.3 = \left\Vert\, 5.3\,\right\Vert$ I'm taking an advanced integration course at a mathematics academy and this is a problem in the problem set. I'd like to say that I've made some progress but I haven't. I'm not really sure what I could do to get started on the right track.","$$ \mbox{Evaluate}\quad \lim_{n \to \infty}{1 \over n}\int_{1}^{n}\left\Vert\,n \over x\,\right\Vert \,{\rm d}x $$ Where $\left\vert\left\vert\, x\,\right\vert\right\vert : \mathbb{R} \to \mathbb{R}$ denotes the [distance to the] closest integer to $x$. As an explicit example, $\left\Vert\, 4.7\,\right\Vert = 0.3 = \left\Vert\, 5.3\,\right\Vert$ I'm taking an advanced integration course at a mathematics academy and this is a problem in the problem set. I'd like to say that I've made some progress but I haven't. I'm not really sure what I could do to get started on the right track.",,['integration']
31,Compute $\zeta(2) = \frac{\pi^2}6$,Compute,\zeta(2) = \frac{\pi^2}6,"It is well known that $$\int_0^1\frac{\log{x}}{1 - x}\,\mathrm{d}x = -\frac{\pi^2}{6} $$ This is generally proved by expanding the geometric series. My question is: can this be done in reverse? Can we evaluate the integral $\int_0^1\frac{\log{x}}{1 - x}dx$ using other method, for example, differentiation under the integral sign, and thus prove $\zeta(2) = \frac{\pi^2}6$ ?","It is well known that This is generally proved by expanding the geometric series. My question is: can this be done in reverse? Can we evaluate the integral using other method, for example, differentiation under the integral sign, and thus prove ?","\int_0^1\frac{\log{x}}{1 - x}\,\mathrm{d}x = -\frac{\pi^2}{6}  \int_0^1\frac{\log{x}}{1 - x}dx \zeta(2) = \frac{\pi^2}6","['integration', 'definite-integrals', 'riemann-zeta']"
32,Evaluation of improper integrals,Evaluation of improper integrals,,"Let $f(x)$ be a real-valued function of real variable $x$, whose anti-derivative is difficult to obtain. Suppose we wish to compute the definite integral $$I=\int_a^\infty f(x)\text{d}x,$$ where $a$ is finite. Assuming all standard attempts to evaluate the integral have failed, is the following method plausible and/or known? : Compute the power series of $f(x)$ at $\infty$ (so that we obtain a power series in terms of powers of $1/x$). Integrate the the resulting power series, possibly (?) over an interval, say $[0,y]$ or $[1,y]$, so as to avoid constants of integration, and assuming convergence, let $y\longrightarrow 0$. This should (?) give the limit of the anti-derivative of $f(x)$ at $\infty$. Compute the lower limit in a similar way. Subtract the two limits. The result should be the real number $I$.","Let $f(x)$ be a real-valued function of real variable $x$, whose anti-derivative is difficult to obtain. Suppose we wish to compute the definite integral $$I=\int_a^\infty f(x)\text{d}x,$$ where $a$ is finite. Assuming all standard attempts to evaluate the integral have failed, is the following method plausible and/or known? : Compute the power series of $f(x)$ at $\infty$ (so that we obtain a power series in terms of powers of $1/x$). Integrate the the resulting power series, possibly (?) over an interval, say $[0,y]$ or $[1,y]$, so as to avoid constants of integration, and assuming convergence, let $y\longrightarrow 0$. This should (?) give the limit of the anti-derivative of $f(x)$ at $\infty$. Compute the lower limit in a similar way. Subtract the two limits. The result should be the real number $I$.",,"['integration', 'definite-integrals', 'improper-integrals']"
33,Passing limit inside integral for functions in $L^1+L^2$ norm,Passing limit inside integral for functions in  norm,L^1+L^2,"Let $f\in L^1(\mathbb{R})\cap L^2(\mathbb{R})$, and let $f_k$ be functions in the Schwartz class such that $\|f-f_k\|_1+\|f-f_k\|_2\rightarrow 0$ as $k\rightarrow\infty$. Define $$g_k(t)=\int_\mathbb{R}f_k(x)e^{-itx}dx \text{    and    } g(t)=\int_\mathbb{R}f(x)e^{-itx}dx$$ Show that $\lim_{k\rightarrow\infty}g_k(t)=g(t)$ for all $t$. I want to use something like dominated convergence thm to pass the limit inside the integral. But here it is not clear, because we only have convergence in $L^1+L^2$ norm. We don't know whether $f_k(x)\rightarrow f(x)$ at point $x$. What can we do?","Let $f\in L^1(\mathbb{R})\cap L^2(\mathbb{R})$, and let $f_k$ be functions in the Schwartz class such that $\|f-f_k\|_1+\|f-f_k\|_2\rightarrow 0$ as $k\rightarrow\infty$. Define $$g_k(t)=\int_\mathbb{R}f_k(x)e^{-itx}dx \text{    and    } g(t)=\int_\mathbb{R}f(x)e^{-itx}dx$$ Show that $\lim_{k\rightarrow\infty}g_k(t)=g(t)$ for all $t$. I want to use something like dominated convergence thm to pass the limit inside the integral. But here it is not clear, because we only have convergence in $L^1+L^2$ norm. We don't know whether $f_k(x)\rightarrow f(x)$ at point $x$. What can we do?",,"['real-analysis', 'integration', 'limits']"
34,Differentiation under integral sign help,Differentiation under integral sign help,,Question is: If $$f(a)= \int_0^\infty e^{-t^2}\cdot \cos(at)~dt$$ then I have to show that $f'(a)=-\dfrac{a}{2}\cdot f(a)$. I know that $\displaystyle\frac{d}{da}f(a)=\int_0^\infty\frac{\partial}{\partial{a}}(\cos(at))\cdot e^{-t^{2}}~dt=-a\int_0^\infty e^{-t^2}\sin(at)~dt$ . How to finish it off from here?,Question is: If $$f(a)= \int_0^\infty e^{-t^2}\cdot \cos(at)~dt$$ then I have to show that $f'(a)=-\dfrac{a}{2}\cdot f(a)$. I know that $\displaystyle\frac{d}{da}f(a)=\int_0^\infty\frac{\partial}{\partial{a}}(\cos(at))\cdot e^{-t^{2}}~dt=-a\int_0^\infty e^{-t^2}\sin(at)~dt$ . How to finish it off from here?,,"['integration', 'derivatives', 'definite-integrals', 'improper-integrals']"
35,Integrating non-elementary functions,Integrating non-elementary functions,,"An elementary function is a function that can be represented by a finite number of exponentials, logarithms, nth roots, and constants through composition. Clearly, an non-elementary function that is not elementary. There are plenty of elementary functions such that integrating said function results in a non-elementary functions. Some quick ones that come to mind are $e^{x^2}$, $x^x$, and $\frac{1}{\ln{x}}$. My question: Is it possible to find a non-elementary function $f(x)$ such that $\int f(x)dx$ is an elementary function? My intuition tells me no , but he's been wrong plenty of times before.","An elementary function is a function that can be represented by a finite number of exponentials, logarithms, nth roots, and constants through composition. Clearly, an non-elementary function that is not elementary. There are plenty of elementary functions such that integrating said function results in a non-elementary functions. Some quick ones that come to mind are $e^{x^2}$, $x^x$, and $\frac{1}{\ln{x}}$. My question: Is it possible to find a non-elementary function $f(x)$ such that $\int f(x)dx$ is an elementary function? My intuition tells me no , but he's been wrong plenty of times before.",,"['integration', 'special-functions', 'elementary-functions']"
36,Evaluate $\int_{-\infty}^\infty x\exp(-x^2/2)\sin(\xi x)\ \mathrm dx$,Evaluate,\int_{-\infty}^\infty x\exp(-x^2/2)\sin(\xi x)\ \mathrm dx,"Evaluate $\int_{-\infty}^\infty x\exp(-x^2/2)\sin(\xi x)\ \mathrm dx$ The answer given by Wolfram Alpha is $\sqrt{2\pi}\xi\exp(-\xi^2/2)$. Observe how this is related to the Fourier transform of $x\exp(-x^2/2)$: the part $\int_{-\infty}^{\infty}x\exp(-x^2/2)\cos\xi x \ \mathrm dx=0$ since the integrand is odd. In addition, what are the Fourier transforms of $x^k\exp(-x^2/2)$ for $k=2,3$? Related: How do I compute $\int_{-\infty}^\infty e^{-\frac{x^2}{2t}} e^{-ikx} \, \mathrm dx$ for $t \in \mathbb{R}_{>0}$ and $k \in \mathbb{R}$?","Evaluate $\int_{-\infty}^\infty x\exp(-x^2/2)\sin(\xi x)\ \mathrm dx$ The answer given by Wolfram Alpha is $\sqrt{2\pi}\xi\exp(-\xi^2/2)$. Observe how this is related to the Fourier transform of $x\exp(-x^2/2)$: the part $\int_{-\infty}^{\infty}x\exp(-x^2/2)\cos\xi x \ \mathrm dx=0$ since the integrand is odd. In addition, what are the Fourier transforms of $x^k\exp(-x^2/2)$ for $k=2,3$? Related: How do I compute $\int_{-\infty}^\infty e^{-\frac{x^2}{2t}} e^{-ikx} \, \mathrm dx$ for $t \in \mathbb{R}_{>0}$ and $k \in \mathbb{R}$?",,"['real-analysis', 'integration', 'analysis', 'fourier-analysis', 'improper-integrals']"
37,Mean value staying in a convex or a subspace,Mean value staying in a convex or a subspace,,"Let $f : \mathbb{R}^n \to \mathbb{R}^m$ such that $\forall x\in \mathbb{R}^n$, $f(x)\in C$ where $C$ is a convex set of $\mathbb{R}^m$ (respectively $f(x)\in F$ where $F$ is a linear subspace of $\mathbb{R}^m$) and $f$ is in $L^1_{\text{loc}}(\mathbb{R}^n,\mathbb{R}^m)$. Then it seems quite natural that for all $K$ compact convex set of $\mathbb{R}^n$, $$\frac{1}{\text{mes}(K)}\int_K f(x)\text{d} x \in C\text{ (resp. } \in F).$$ But is it true ? And if it is, how to prove it ?","Let $f : \mathbb{R}^n \to \mathbb{R}^m$ such that $\forall x\in \mathbb{R}^n$, $f(x)\in C$ where $C$ is a convex set of $\mathbb{R}^m$ (respectively $f(x)\in F$ where $F$ is a linear subspace of $\mathbb{R}^m$) and $f$ is in $L^1_{\text{loc}}(\mathbb{R}^n,\mathbb{R}^m)$. Then it seems quite natural that for all $K$ compact convex set of $\mathbb{R}^n$, $$\frac{1}{\text{mes}(K)}\int_K f(x)\text{d} x \in C\text{ (resp. } \in F).$$ But is it true ? And if it is, how to prove it ?",,"['integration', 'convex-analysis']"
38,Express integral over curve as integral over unit ball,Express integral over curve as integral over unit ball,,Let $A$ be the region in $\mathbb{R}^2$ bounded by the curve $x^2-xy+2y^2=1$. Express the integral $\int_Axy$ as an integral over the unit ball in $\mathbb{R}^2$ centered at $0$. So I rearranged $x^2-xy+2y^2=(x-\sqrt{2}y)^2+(2\sqrt{2}-1)xy$. It might be helpful to change the variables from $x$ and $y$ to $x-\sqrt{2}y$ and $xy$ or something similar. But I can't see how I would be able to get an integral over the unit ball.,Let $A$ be the region in $\mathbb{R}^2$ bounded by the curve $x^2-xy+2y^2=1$. Express the integral $\int_Axy$ as an integral over the unit ball in $\mathbb{R}^2$ centered at $0$. So I rearranged $x^2-xy+2y^2=(x-\sqrt{2}y)^2+(2\sqrt{2}-1)xy$. It might be helpful to change the variables from $x$ and $y$ to $x-\sqrt{2}y$ and $xy$ or something similar. But I can't see how I would be able to get an integral over the unit ball.,,"['calculus', 'integration']"
39,Calculation of integral with Bessel function,Calculation of integral with Bessel function,,"I have a trouble with to calculating (or bounding from above) the following integral: $$ \int_{-\infty}^{\infty}\left(\frac{J_2(x)}{x^2}\right)^p\, dx, \quad p\geq 1, $$ where $J_2(x)$ is a Bessel function { http://en.wikipedia.org/wiki/Bessel_function }. Any ideas would be very helpful. Thank you.","I have a trouble with to calculating (or bounding from above) the following integral: $$ \int_{-\infty}^{\infty}\left(\frac{J_2(x)}{x^2}\right)^p\, dx, \quad p\geq 1, $$ where $J_2(x)$ is a Bessel function { http://en.wikipedia.org/wiki/Bessel_function }. Any ideas would be very helpful. Thank you.",,"['integration', 'inequality', 'numerical-methods', 'bessel-functions']"
40,Evaluate complex integrals involving cosine,Evaluate complex integrals involving cosine,,"Evaluate the integrals $$\int_{|z|=1}\dfrac{\cos z}{z-3}dz$$ and $$\int_{|z|=10}\dfrac{\cos z}{z-3}dz$$ The first one should be $0$, since the function $\dfrac{\cos z}{z-3}$ is holomorphic in the open disk $|z|<3$. I've tried parametrizing $z=10e^{i\theta}$ for $\theta\in[0,2\pi]$. The second integral becomes $$\int_0^{2\pi}\dfrac{\cos (10e^{i\theta})}{10e^{i\theta}-3}\cdot 10ie^{i\theta}d\theta$$ and I don't know how to continue from here. Or perhaps I should use Cauchy's integral formula, which says that the integral is equal to $$2\pi i\cdot f(3)\cdot n(\gamma,3) = \cos(3)\cdot \int_{|z|=10}\dfrac{1}{z-3}dz$$ How can I integrate this last one?","Evaluate the integrals $$\int_{|z|=1}\dfrac{\cos z}{z-3}dz$$ and $$\int_{|z|=10}\dfrac{\cos z}{z-3}dz$$ The first one should be $0$, since the function $\dfrac{\cos z}{z-3}$ is holomorphic in the open disk $|z|<3$. I've tried parametrizing $z=10e^{i\theta}$ for $\theta\in[0,2\pi]$. The second integral becomes $$\int_0^{2\pi}\dfrac{\cos (10e^{i\theta})}{10e^{i\theta}-3}\cdot 10ie^{i\theta}d\theta$$ and I don't know how to continue from here. Or perhaps I should use Cauchy's integral formula, which says that the integral is equal to $$2\pi i\cdot f(3)\cdot n(\gamma,3) = \cos(3)\cdot \int_{|z|=10}\dfrac{1}{z-3}dz$$ How can I integrate this last one?",,"['complex-analysis', 'integration']"
41,Meaning of the following integal,Meaning of the following integal,,"What does $\int d^3 x $ mean? I found this in a lecture on quantum field theory, and it was not explained.","What does $\int d^3 x $ mean? I found this in a lecture on quantum field theory, and it was not explained.",,"['integration', 'notation']"
42,Fourier-Bessel series coefficients,Fourier-Bessel series coefficients,,"When finding the coefficients of a Fourier-Bessel series, the Bessel functions satisfies, for $k_1$and $k_2$ both zeroes of $J_n(t)$,  the orthogonality relation given by: $$\int_0^1 J_n(k_1r)J_n(k_2r)rdr = 0, (k_1≠k_2)$$ and for $k_1 = k_2 = k$: $$\int_0^1 J_n^2(kr)rdr = \frac12J_n^{'2}(k)$$ I understand how to get the first result since the Bessel's equation can be interpreted as a Sturm-Liouville problem, but how can I show the second one?","When finding the coefficients of a Fourier-Bessel series, the Bessel functions satisfies, for $k_1$and $k_2$ both zeroes of $J_n(t)$,  the orthogonality relation given by: $$\int_0^1 J_n(k_1r)J_n(k_2r)rdr = 0, (k_1≠k_2)$$ and for $k_1 = k_2 = k$: $$\int_0^1 J_n^2(kr)rdr = \frac12J_n^{'2}(k)$$ I understand how to get the first result since the Bessel's equation can be interpreted as a Sturm-Liouville problem, but how can I show the second one?",,"['integration', 'special-functions', 'fourier-series']"
43,Using Green's theorem: Area of Descartes' folium,Using Green's theorem: Area of Descartes' folium,,"I am trying to calculate the area of the loop in the folium of Descartes using Green's theorem. The loop can be parameterized $x = \frac{3at}{1+t^3}$, $y=\frac{3at^2}{1+t^3}$, $0\leq t < \infty$. $$\iint_F 1=\int_{\partial F}x\,dy=\int_{0}^\infty \left(\frac{3at}{1+t^3}\right)\left(\frac{6at(1+t^3)-3t^2(3at^2)}{(1+t^3)^2}dt\right)$$ $$=\int_{0}^\infty\frac{18a^2t^2 (1+t^3)-27a^2t^5}{(1+t^3)^3}=\int_{0}^\infty\frac{9a^2t^2(2(1+t^3)-3t^3)}{(1+t^3)^3},$$and the book tells me the answer is $$\int_0^\infty \frac{t^2}{(1+t^3)^2}.$$ Where is my error?","I am trying to calculate the area of the loop in the folium of Descartes using Green's theorem. The loop can be parameterized $x = \frac{3at}{1+t^3}$, $y=\frac{3at^2}{1+t^3}$, $0\leq t < \infty$. $$\iint_F 1=\int_{\partial F}x\,dy=\int_{0}^\infty \left(\frac{3at}{1+t^3}\right)\left(\frac{6at(1+t^3)-3t^2(3at^2)}{(1+t^3)^2}dt\right)$$ $$=\int_{0}^\infty\frac{18a^2t^2 (1+t^3)-27a^2t^5}{(1+t^3)^3}=\int_{0}^\infty\frac{9a^2t^2(2(1+t^3)-3t^3)}{(1+t^3)^3},$$and the book tells me the answer is $$\int_0^\infty \frac{t^2}{(1+t^3)^2}.$$ Where is my error?",,"['calculus', 'integration', 'multivariable-calculus']"
44,integral involving modified bessel,integral involving modified bessel,,"I want to integrate this: $$\int_0^{\infty} dt \exp{\left ( a \, t^b\right)} \, I_v {\left ( a \, t^b\right)} $$ where $I_v(.)$ is the modified bessel function of arbitrary order $v$. Can someone help me with this please?","I want to integrate this: $$\int_0^{\infty} dt \exp{\left ( a \, t^b\right)} \, I_v {\left ( a \, t^b\right)} $$ where $I_v(.)$ is the modified bessel function of arbitrary order $v$. Can someone help me with this please?",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
45,Integrating pressure with respect to time,Integrating pressure with respect to time,,"I am trying to work through the math derivation presented in a paper about gas flowing through rock due to a pressure differential across the length of rock.  This is my first post so forgive me if I am going about this the wrong way.  My question is about how to perform the math between two steps in the derivation in the paper, but I feel that the steps leading up to the steps in question are necessary since and idea of what the pressures are in relation to the system being evaluated is useful in the math derivation. To begin, the volumetric isothermal flow rate of nitrogen, which behaves as an ideal gas, from a storage tank at pressure $P_0$ is: \begin{equation} q_o(t)=\frac{M}{\rho_o(t)}\frac{-dn}{dt}=\frac{-MV_t}{\rho_o(t)RT}\frac{dP_o}{dt}   \end{equation} But density is given by: $$\rho_o(t)=\frac{MP_o(t)}{RT}$$ Therefore, $$q_o(t)=\frac{-V_t}{P_o(t)}\frac{dP_o}{dt}$$ Assume for the moment that at any instant in time the mass velocity throughout the length of the core is constant (this is not rigorously true).  As nitrogen flows through a rock core, it expands, such that $$q(x,t)=\frac{q_o(t)P_o(t)}{p(x,t)}=\frac{-V_t}{p(x,t)}\frac{dP_o}{dt}$$ Klinkenberg's relationship for permeability to gas, expressed as a point function of both time and position, is: $$k(x,t)=k_l\left(1+\frac{b}{p(x,t)+Pa}\right)$$ Darcy's relation for fluid flow in a porous medium in 1D is: $$q = \frac{-kA}{\mu}\frac{dP}{dx}$$ Substituting our volumetric relation and Klinkenberg's relationship into Darcy's equation for one-dimensional flow yields: $$\frac{-V_tP'_o(t)}{p(x,t)}=\frac{-k_lA(1+b/p(x,t))}{\mu}\frac{\partial{p(x,t)}}{\partial{x}}$$ If this equation is integrated with respect to length and divided by $1/2(P_l-P_o)$, it becomes: $$\frac{-2V_t\mu P'_o(t)L}{k_lA(P_o-P_l)}=P_l+P_o+2b$$ Pressures in all equations above have been absolute pressures, expressed in atmospheres and permeability in darcies.  If we now switch to gauge pressure (psig), and express permeability in millidarcies, our equation becomes (since $P_l = 0$ psig): $$\frac{-V_tP'_o(t)}{P_o(t)}=\frac{k_lA}{2000*14.696 \mu L}(P_o(t)+2P_a+2b)$$ set $$m=\frac{k_lA}{29,390 \mu L}$$  and $$i=2(P_a+b)m$$ we have an equation of a straight line with intercept $i$ and slope $m$: $$\frac{-V_tP'_o(t)}{P_o(t)}=i+mP_o(t)$$ Now here is the part that I would like a math explanation.  The paper states that our equation can be rearranged and integrated with respect to time to give: $$\frac{V_t}{i/m} \ln \frac{P_1(P_2+i/m)}{P_2(P_1+i/m)}=m(t_2-t_1)$$ How exactly was this step done?  Thanks in advance for any help.","I am trying to work through the math derivation presented in a paper about gas flowing through rock due to a pressure differential across the length of rock.  This is my first post so forgive me if I am going about this the wrong way.  My question is about how to perform the math between two steps in the derivation in the paper, but I feel that the steps leading up to the steps in question are necessary since and idea of what the pressures are in relation to the system being evaluated is useful in the math derivation. To begin, the volumetric isothermal flow rate of nitrogen, which behaves as an ideal gas, from a storage tank at pressure $P_0$ is: \begin{equation} q_o(t)=\frac{M}{\rho_o(t)}\frac{-dn}{dt}=\frac{-MV_t}{\rho_o(t)RT}\frac{dP_o}{dt}   \end{equation} But density is given by: $$\rho_o(t)=\frac{MP_o(t)}{RT}$$ Therefore, $$q_o(t)=\frac{-V_t}{P_o(t)}\frac{dP_o}{dt}$$ Assume for the moment that at any instant in time the mass velocity throughout the length of the core is constant (this is not rigorously true).  As nitrogen flows through a rock core, it expands, such that $$q(x,t)=\frac{q_o(t)P_o(t)}{p(x,t)}=\frac{-V_t}{p(x,t)}\frac{dP_o}{dt}$$ Klinkenberg's relationship for permeability to gas, expressed as a point function of both time and position, is: $$k(x,t)=k_l\left(1+\frac{b}{p(x,t)+Pa}\right)$$ Darcy's relation for fluid flow in a porous medium in 1D is: $$q = \frac{-kA}{\mu}\frac{dP}{dx}$$ Substituting our volumetric relation and Klinkenberg's relationship into Darcy's equation for one-dimensional flow yields: $$\frac{-V_tP'_o(t)}{p(x,t)}=\frac{-k_lA(1+b/p(x,t))}{\mu}\frac{\partial{p(x,t)}}{\partial{x}}$$ If this equation is integrated with respect to length and divided by $1/2(P_l-P_o)$, it becomes: $$\frac{-2V_t\mu P'_o(t)L}{k_lA(P_o-P_l)}=P_l+P_o+2b$$ Pressures in all equations above have been absolute pressures, expressed in atmospheres and permeability in darcies.  If we now switch to gauge pressure (psig), and express permeability in millidarcies, our equation becomes (since $P_l = 0$ psig): $$\frac{-V_tP'_o(t)}{P_o(t)}=\frac{k_lA}{2000*14.696 \mu L}(P_o(t)+2P_a+2b)$$ set $$m=\frac{k_lA}{29,390 \mu L}$$  and $$i=2(P_a+b)m$$ we have an equation of a straight line with intercept $i$ and slope $m$: $$\frac{-V_tP'_o(t)}{P_o(t)}=i+mP_o(t)$$ Now here is the part that I would like a math explanation.  The paper states that our equation can be rearranged and integrated with respect to time to give: $$\frac{V_t}{i/m} \ln \frac{P_1(P_2+i/m)}{P_2(P_1+i/m)}=m(t_2-t_1)$$ How exactly was this step done?  Thanks in advance for any help.",,"['integration', 'physics', 'fluid-dynamics']"
46,Find the following integral: [duplicate],Find the following integral: [duplicate],,"This question already has answers here : How can I compute the integral $\int_{0}^{\infty} \frac{dt}{1+t^4}$? (7 answers) Is there a quicker way of doing this integral? (2 answers) Closed 11 years ago . Find $$\int \sqrt{\tan x}dx$$ My attempt: $$\text{Let}\ I=\int \sqrt{\tan(x)}dx$$ $$\text{Let}\ u=\tan(x), du=(1+\tan^{2}(x))dx$$ $$I=\int \frac{\sqrt{u}}{u^{2}+1}$$ $$\text{Let}\ v=\sqrt{u}, dv=\frac{du}{2\sqrt{u}}$$ $$I=2\int \frac{v^{2}}{v^{4}+1}$$ $$\int_0^\infty\frac{x^2}{1+x^4}dx$$ $$\text{Let}\ t=\frac{1}{v} \therefore dt=\frac{-dv}{v^2}$$ $$\therefore I=\int \frac{\frac{1}{t^2}}{1+\frac{1}{t^4}}\times\frac{-dt}{t^2}$$ $$I=-\int \frac{dt}{1+t^4}$$ Where do I go from here?","This question already has answers here : How can I compute the integral $\int_{0}^{\infty} \frac{dt}{1+t^4}$? (7 answers) Is there a quicker way of doing this integral? (2 answers) Closed 11 years ago . Find $$\int \sqrt{\tan x}dx$$ My attempt: $$\text{Let}\ I=\int \sqrt{\tan(x)}dx$$ $$\text{Let}\ u=\tan(x), du=(1+\tan^{2}(x))dx$$ $$I=\int \frac{\sqrt{u}}{u^{2}+1}$$ $$\text{Let}\ v=\sqrt{u}, dv=\frac{du}{2\sqrt{u}}$$ $$I=2\int \frac{v^{2}}{v^{4}+1}$$ $$\int_0^\infty\frac{x^2}{1+x^4}dx$$ $$\text{Let}\ t=\frac{1}{v} \therefore dt=\frac{-dv}{v^2}$$ $$\therefore I=\int \frac{\frac{1}{t^2}}{1+\frac{1}{t^4}}\times\frac{-dt}{t^2}$$ $$I=-\int \frac{dt}{1+t^4}$$ Where do I go from here?",,"['calculus', 'trigonometry', 'integration', 'partial-fractions']"
47,Complex Integral using Residues theorem: $\int_0^{2\pi}{d\theta \over1+8\cos^2\theta} $,Complex Integral using Residues theorem:,\int_0^{2\pi}{d\theta \over1+8\cos^2\theta} ,"This is the question: Find the integral using residue theorem. $$\int_0^{2\pi}{d\theta \over1+8\cos^2\theta} $$ I solved it like this : $$\int_0^{2\pi}{d\theta \over1+8\cos^2\theta}=\int_0^{2 \pi} {d\phi \over 5+4\cos\phi} $$ using $$2\cos^2\theta=\cos 2\theta+1 \quad\quad and \quad 2\theta=\phi$$ Then i took $z=e^{i\phi}$ , so th integral now becomes : $$\int_C {1 \over (2z^2+5z+2)} {dz \over iz} \quad c:|z|=1$$ Now using the residue theorem on the obtained poles i get answer as $$4\pi \over 3$$ Can someone please verify it","This is the question: Find the integral using residue theorem. $$\int_0^{2\pi}{d\theta \over1+8\cos^2\theta} $$ I solved it like this : $$\int_0^{2\pi}{d\theta \over1+8\cos^2\theta}=\int_0^{2 \pi} {d\phi \over 5+4\cos\phi} $$ using $$2\cos^2\theta=\cos 2\theta+1 \quad\quad and \quad 2\theta=\phi$$ Then i took $z=e^{i\phi}$ , so th integral now becomes : $$\int_C {1 \over (2z^2+5z+2)} {dz \over iz} \quad c:|z|=1$$ Now using the residue theorem on the obtained poles i get answer as $$4\pi \over 3$$ Can someone please verify it",,"['integration', 'complex-analysis', 'definite-integrals', 'residue-calculus']"
48,Integral calculus proof,Integral calculus proof,,"If $f(x)$ is continuous in $[a,b]$, prove that $ \displaystyle \lim_{n \to \infty} \dfrac{b-a}{n} \displaystyle \sum^n _{k=1} f\left( a + \dfrac{k(b-a)}{n} \right) = \displaystyle \int_a ^ b f(x)dx$ This is my first time I'm exposed to these type of math problems (being a high schooler), so I don't really know how to tackle this. Can anyone point me in the right direction? What I tried: I just tried to see the logic behind the RHS. I see that $\dfrac{b-a}{n}$ divides the interval a,b into n rectangles. What I totally don't understand is why the height of these rectangles is given by the summation of $ f\left(a + \dfrac{k (b-a)}{n}\right)$","If $f(x)$ is continuous in $[a,b]$, prove that $ \displaystyle \lim_{n \to \infty} \dfrac{b-a}{n} \displaystyle \sum^n _{k=1} f\left( a + \dfrac{k(b-a)}{n} \right) = \displaystyle \int_a ^ b f(x)dx$ This is my first time I'm exposed to these type of math problems (being a high schooler), so I don't really know how to tackle this. Can anyone point me in the right direction? What I tried: I just tried to see the logic behind the RHS. I see that $\dfrac{b-a}{n}$ divides the interval a,b into n rectangles. What I totally don't understand is why the height of these rectangles is given by the summation of $ f\left(a + \dfrac{k (b-a)}{n}\right)$",,"['integration', 'proof-writing']"
49,Integration Antiderivative vertical bar [duplicate],Integration Antiderivative vertical bar [duplicate],,"This question already has answers here : Closed 11 years ago . Possible Duplicate: What is the name of the vertical bar? When taking a definite integral, the first step is finding the anti-derivative. Once you have gone through all the steps to complete that, you need to evaluate the anti-derivative. This is often written with the formula for the anti-derivative then a vertical bar after that formula with the upper and lower bounds, much like the integration symbol. What is this vertical bar called? Does it have a name? For that matter, does the integration symbol have a name? This isn't for homework, but neither is it just out of curiosity. I have a reason for wanting to know this, but it would take a while to explain.","This question already has answers here : Closed 11 years ago . Possible Duplicate: What is the name of the vertical bar? When taking a definite integral, the first step is finding the anti-derivative. Once you have gone through all the steps to complete that, you need to evaluate the anti-derivative. This is often written with the formula for the anti-derivative then a vertical bar after that formula with the upper and lower bounds, much like the integration symbol. What is this vertical bar called? Does it have a name? For that matter, does the integration symbol have a name? This isn't for homework, but neither is it just out of curiosity. I have a reason for wanting to know this, but it would take a while to explain.",,"['integration', 'notation', 'definite-integrals']"
50,"Proof $\int\Re(f(x))\,\mathrm{d}x=\Re(\int f(x)\,\mathrm{d}x)$",Proof,"\int\Re(f(x))\,\mathrm{d}x=\Re(\int f(x)\,\mathrm{d}x)","I have a function $f: \mathbb{R}\to\mathbb{C}$. How can I proof/argue that $$\int\Re(f(x))\,\mathrm{d}x=\Re\left(\int f(x)\,\mathrm{d}x\right)$$ (and the same for the imaginary part)? I'm afraid I don't have any idea how to start… The reason I ask is that I need to proof $\widehat{\overline{f}}(n)=\overline{\widehat{f}(-n)}$ and I'm coming to a point where I need the step from $\frac{1}{2\pi}\int_{-\pi}^\pi\overline{f(x)e^{inx}}\,\mathrm{d}x$ to $\frac{1}{2\pi}\overline{\int_{-\pi}^\pi f(x)e^{inx}\,\mathrm{d}x}$.","I have a function $f: \mathbb{R}\to\mathbb{C}$. How can I proof/argue that $$\int\Re(f(x))\,\mathrm{d}x=\Re\left(\int f(x)\,\mathrm{d}x\right)$$ (and the same for the imaginary part)? I'm afraid I don't have any idea how to start… The reason I ask is that I need to proof $\widehat{\overline{f}}(n)=\overline{\widehat{f}(-n)}$ and I'm coming to a point where I need the step from $\frac{1}{2\pi}\int_{-\pi}^\pi\overline{f(x)e^{inx}}\,\mathrm{d}x$ to $\frac{1}{2\pi}\overline{\int_{-\pi}^\pi f(x)e^{inx}\,\mathrm{d}x}$.",,"['integration', 'complex-numbers']"
51,A proof problem from a first time real analysis course,A proof problem from a first time real analysis course,,"Given a continuous function $g:[a,b]\to\Bbb R$, if there exists a number $K>0$ s.t. for all $x\in[a,b]$, $|g(x)| \le K \int_a^x |g|$, prove $g(x)=0$ for all $x\in[a,b]$. And I tried to derive some contradiction around $\inf g^{-1}(\Bbb R-\{0\})$ assuming $g\ne 0$, under given hypothesis, but I wasn't succesful.","Given a continuous function $g:[a,b]\to\Bbb R$, if there exists a number $K>0$ s.t. for all $x\in[a,b]$, $|g(x)| \le K \int_a^x |g|$, prove $g(x)=0$ for all $x\in[a,b]$. And I tried to derive some contradiction around $\inf g^{-1}(\Bbb R-\{0\})$ assuming $g\ne 0$, under given hypothesis, but I wasn't succesful.",,"['real-analysis', 'inequality', 'integration']"
52,How can I find the area of the shadow?,How can I find the area of the shadow?,,"Consider a lit candle placed on a cylinder. If the candle is placed at the center of the top surface, let the distance from the origin (center of the surface) to the end of the shadow be $r$. In this case the area of the shadow can easily be calculated by the difference of 2 circular areas ie:- $\pi r^2-$ Area of cylinder's base. Now suppose we shift the candle from the origin & place it at some point $(x,y)$ on the circular surface, how do we calculate the area of the shadow? The dimensions of the cylinder are known. The length of the candle at the particular instant is known. Further, what is the equation the shape of the shadow? Thanks in advance.","Consider a lit candle placed on a cylinder. If the candle is placed at the center of the top surface, let the distance from the origin (center of the surface) to the end of the shadow be $r$. In this case the area of the shadow can easily be calculated by the difference of 2 circular areas ie:- $\pi r^2-$ Area of cylinder's base. Now suppose we shift the candle from the origin & place it at some point $(x,y)$ on the circular surface, how do we calculate the area of the shadow? The dimensions of the cylinder are known. The length of the candle at the particular instant is known. Further, what is the equation the shape of the shadow? Thanks in advance.",,['integration']
53,Evaluate $\int_1^\infty \cosh^{-1}(x) \ln(x^2-1) \exp \left(- \frac{x}{T} \right) dx $,Evaluate,\int_1^\infty \cosh^{-1}(x) \ln(x^2-1) \exp \left(- \frac{x}{T} \right) dx ,"I would be interested in any clue on how to evaluate the following integral $$\int_1^\infty \cosh^{-1}(x) \ln(x^2-1) \exp \left(- \frac{x}{T} \right) dx   $$ I have tried integration by parts but it seems to lead only to other integrals of the same form, with additional powers of $x$ in the integrand.","I would be interested in any clue on how to evaluate the following integral $$\int_1^\infty \cosh^{-1}(x) \ln(x^2-1) \exp \left(- \frac{x}{T} \right) dx   $$ I have tried integration by parts but it seems to lead only to other integrals of the same form, with additional powers of $x$ in the integrand.",,['integration']
54,"Double integral $\int_{z=u}^{+\infty}\int_{t=u}^{+\infty}\frac{e^{-Az}}{z+B}\frac{te^{-tD}}{t-zC}\,dtdz$",Double integral,"\int_{z=u}^{+\infty}\int_{t=u}^{+\infty}\frac{e^{-Az}}{z+B}\frac{te^{-tD}}{t-zC}\,dtdz","I am doing research, and while calculating a closed form expression, I got a form of integration like the following: $$\int_{z=u}^{+\infty}\int_{t=u}^{+\infty}\frac{e^{-Az}}{z+B}\frac{te^{-tD}}{t-zC}dtdz$$ where $A$, $B$, $C$, $D$ and $u$ are positive reals. I don't know if there is way to get the closed form of it or we have to rely on some approximations.","I am doing research, and while calculating a closed form expression, I got a form of integration like the following: $$\int_{z=u}^{+\infty}\int_{t=u}^{+\infty}\frac{e^{-Az}}{z+B}\frac{te^{-tD}}{t-zC}dtdz$$ where $A$, $B$, $C$, $D$ and $u$ are positive reals. I don't know if there is way to get the closed form of it or we have to rely on some approximations.",,"['integration', 'improper-integrals']"
55,Arc Length under change of parameter,Arc Length under change of parameter,,"This is from Apostol's Calculus Vol. I, Section 14.13 #21: Let $C$ be a curve described by two equivalent functions $X$ and $Y$, where $Y(t)=X[u(t)]$ for $c\le t\le d$. If the function $u$ which defines a change of parameter has a continuous derivative in $[c,d]$ prove that $$\int_{u(c)}^{u(d)} \! ||X'(u)||\,\mathrm du=\int_c^d \! ||Y'(t)||\, \mathrm d t$$ and deduce that the arc length of $C$ is invariant under such a change of parameter. I believe that the condition placed on the derivative of $u$ should not have been continuity but rather non-negativity. First a counter-example: $$Y(t)=t\boldsymbol i\,,\quad X(t)=-t\boldsymbol i \, , \quad u(t)=-t\,.$$ Then $Y(t)=X[u(t)]$ over, say, $0\le t\le 1$ and $u'(t)=-1$ is certainly continuous. Now $||X'(t)||=1$ and $||Y'(t)||=1$ but $$\int_{u(0)}^{u(1)} \! ||X'(u)||\,\mathrm du=\int_0^{-1}\!\mathrm d u=-1$$ and $$\int_0^1 \! ||Y'(t)||\,\mathrm dt=\int_0^1\!\mathrm d t=1\,.$$ On the other hand, if we require $u'(t)\ge0$ (and I don't think we even need continuity, do we?) then we can write $$\begin{align}Y'(t)&=X'[u(t)]u'(t)\\ ||Y'(t)||&=||X'[u(t)]u'(t)||\\ &=||X'[u(t)]||\cdot |u'(t)|\\ &=||X'[u(t)]||u'(t)\\ \implies\int_c^d\!||Y'(t)||\,\mathrm d t&=\int_c^d \!||X'[u(t)]||u'(t)\,\mathrm d t\\ &=\int_{u(c)}^{u(d)}\!||X'(u)||\,\mathrm d u \end{align}$$ Is this correct? Should the condition on $u'$ be non-negativity, rather than continuity, or do I need non-negativity in addition to continuity? I don't see anything in my proof at the end that requires continuity, but maybe I'm glossing over it.","This is from Apostol's Calculus Vol. I, Section 14.13 #21: Let $C$ be a curve described by two equivalent functions $X$ and $Y$, where $Y(t)=X[u(t)]$ for $c\le t\le d$. If the function $u$ which defines a change of parameter has a continuous derivative in $[c,d]$ prove that $$\int_{u(c)}^{u(d)} \! ||X'(u)||\,\mathrm du=\int_c^d \! ||Y'(t)||\, \mathrm d t$$ and deduce that the arc length of $C$ is invariant under such a change of parameter. I believe that the condition placed on the derivative of $u$ should not have been continuity but rather non-negativity. First a counter-example: $$Y(t)=t\boldsymbol i\,,\quad X(t)=-t\boldsymbol i \, , \quad u(t)=-t\,.$$ Then $Y(t)=X[u(t)]$ over, say, $0\le t\le 1$ and $u'(t)=-1$ is certainly continuous. Now $||X'(t)||=1$ and $||Y'(t)||=1$ but $$\int_{u(0)}^{u(1)} \! ||X'(u)||\,\mathrm du=\int_0^{-1}\!\mathrm d u=-1$$ and $$\int_0^1 \! ||Y'(t)||\,\mathrm dt=\int_0^1\!\mathrm d t=1\,.$$ On the other hand, if we require $u'(t)\ge0$ (and I don't think we even need continuity, do we?) then we can write $$\begin{align}Y'(t)&=X'[u(t)]u'(t)\\ ||Y'(t)||&=||X'[u(t)]u'(t)||\\ &=||X'[u(t)]||\cdot |u'(t)|\\ &=||X'[u(t)]||u'(t)\\ \implies\int_c^d\!||Y'(t)||\,\mathrm d t&=\int_c^d \!||X'[u(t)]||u'(t)\,\mathrm d t\\ &=\int_{u(c)}^{u(d)}\!||X'(u)||\,\mathrm d u \end{align}$$ Is this correct? Should the condition on $u'$ be non-negativity, rather than continuity, or do I need non-negativity in addition to continuity? I don't see anything in my proof at the end that requires continuity, but maybe I'm glossing over it.",,"['calculus', 'integration']"
56,Discontinuity in function; order of integration matters,Discontinuity in function; order of integration matters,,"I'm struggling a bit with Chapter 10 of Rudin's ""Principles of Mathematical Analysis,"" and I was hoping to get some help here. I'll post the problem and my current progress. Exercise 2: For $i = 1, 2, \ldots$ let $\phi_i \in \mathcal{C}(\mathbb{R}^1)$ have support in $(2^{-i}, 2^{1-i})$ such that $\int \phi_i = 1$. Let  $f(x, y) = \displaystyle\sum_{i=1}^\infty [\phi_i (x) - \phi_{i+1} (x)] \phi_i (y)$. Then $f$ has compact support in $\mathbb{R}^2$, $f$ is continuous except at $(0, 0)$, and $\int dy \int f(x, y) dx = 0$ but $\int dx \int f(x, y) dy = 1$. Observe that $f$ is unbounded in every neighborhood of $(0, 0)$. Progress First, note that the supports of the $\phi_i$ are disjoint. Suppose $\phi_i (x) \neq 0$ on the set $S_i$ for each $i$. Then if $x \not\in \displaystyle\cup_{i = 1}^\infty S_i$, or if $y \not\in \displaystyle\cup_{i = 1}^\infty S_i$ we have $f(x, y) = 0$. If $x \in S_i$ for some $i$ then $x \not\in S_j$ for $j \neq i$, so $f(x, y) = -\phi_i (x) \phi_{i-1} (y) + \phi_i (x) \phi_{i} (y) = \phi_i(x) [\phi_{i} (y) - \phi_{i-1} (y)]$. Note that $f(0, 0) = 0$ since $0$ is not in the support of any $\phi_i$. Then if we can show that $f$ is unbounded in every neighborhood of $(0, 0)$, by the epsilon-delta definition of continuity we know that $f$ is not continuous at $(0, 0)$. Since $\int \phi_i = 1$ we know that the support for each $\phi_i$ must be non-empty. Examine the neighborhood of radius $r$ centered at $(0, 0)$. If we can show that $f$ is unbounded on any neighborhood of radius $r < 1$ centered at $(0, 0)$, then by extension it is unbounded on any neighborhood of radius $r \ge 1$ centered at $(0, 0)$. Then suppose $2^{-a} \le r < 2^{1-a}$. Suppose for sake of contradiction that $f$ is bounded in this neighborhood. Then let $\alpha, \beta$ be the values in $\mathbb{R}^1$ such that $f(\alpha, \beta) \ge f(x, y)$ for all $x, y \in \mathbb{R}^1$ with $|(x, y) - (0, 0)| < r$. Suppose $\alpha \in S_i$. We must then have $\beta \in S_{i-1}$ or $\beta \in S_{i}$. If $\beta \in S_{i-1}$ then $f(\alpha, \beta) = -\phi_i (\alpha) \phi_{i-1} (\beta)$, and if $\beta \in S_i$ then $f(\alpha, \beta) = \phi_i (\alpha) \phi_i (\beta)$. ( ~~~ I don't know how to proceed from here. I need to generate an ordered pair in $\mathbb{R}^2$ that creates a larger value for $f$, but I don't know how to judge the magnitude of $\phi_i (\alpha), \phi_i (\beta)$, or $\phi_{i-1} (\beta)$. I think I need to use $\int \phi_i = 1$, but to be totally honest I don't know what that means, or how to use it. ~~~ ) Since the $\phi_i$ are continuous, we know that the $S_i$ are collections of intervals. Then $(0, 1) \backslash \cup_{i = 1}^\infty S_i$ is also a collection of intervals. We showed earlier that $f(x, y) \neq 0$ iff for some $i$ we have $x \in S_i$ and $y \in S_{i} \cup S_{i - 1}$. Then $f(x, y) \neq 0$ over a set whose closure is a collection of $2$-cells, implying by definition that the support of $f(x, y)$ is a collection of $2$-cells. Since $2$-cells are compact and the union of a collection of compact sets is compact, the support of $f(x, y)$ is compact. To show that $f$ is continuous (other than at the origin), we can examine $f$'s behavior in cases. If $x > 1$ or $x < 0$ and $y > 1$ or $y < 0$, then we can construct a disc in $\mathbb{R}^2$ centered at $(x, y)$ that does not intersect the set determined by $0 < x, y < 1$, so $f(x, y) = 0$ on this neighborhood since $\cup_{i = 1}^\infty S_i \subseteq (0, 1)$; this satisfies the epsilon-delta definition of continuity. If $x = 1$ or $y = 1$ then $f(x, y) = 0$. Since $S_1$ is a collection of intervals in $\mathbb{R}^1$, it has a maximum; let it be $s$. Since $\overline{S_1} \in (1/2, 1)$, and since $\overline{S_1}$ is a collection of closed intervals, we know that $s < 1$. Then if $x = 1$ or $y = 1$, we have that $f(x, y) = 0$ on the neighborhood centered at $(x, y)$ with radius $1-s$. This satisfies the epsilon-delta definition of continuity. Else if $x = 0$ and $y \neq 0$ then $f(x, y) = 0$. Suppose $y \in S_i$ for some $i$; then it is in some interval $[a, b] \in S_i$. Then consider the region defined by $(x', y') : x' < 2^{-(i+1)}, y' \in [a, b]$. We can inscribe a disk in this region centered at $(x, y)$, and we have $f(x', y') = 0$ over this region. This satisfies the epsilon-delta definition of continuity. On the other hand, suppose $y \not\in S_i$ for any $i$; then it is in some interval $[a, b]$ such that $\phi_i (y) = 0$ for all $y \in [a, b]$. Through a similar construction we can create a disk over which $f$ takes the value of zero alone. This satisfies the epsilon-delta definition of continuity. Else if $y = 0$ and $x \neq 0$ then $f(x, y) = 0$. Suppose $x \in S_i$ for some $i$; then it is in some interval $[a, b] \in S_i$. Then consider the region defined by $(x', y') : x' \in [a, b], y' < 2^{-i}$. We can inscribe a disk in this region centered at $(x, y)$, and we have $f(x', y') = 0$ over this region. This satisfies the epsilon-delta definition of continuity. On the other hand, suppose $x \not\in S_i$ for any $i$; then it is in some interval $[a, b]$ such that $\phi_i (x) = 0$ for all $x \in [a, b]$. Through a similar construction we can create a disk over which $f$ takes the value of zero alone. This satisfies the epsilon-delta definition of continuity. This shows the continuity of $f$ on all points other than $(0, 0)$. ( ~~~ I don't know what the notation $\int dx \int f(x, y) dy$ means... ~~~ ) Thanks so, so, so, so much for your help!","I'm struggling a bit with Chapter 10 of Rudin's ""Principles of Mathematical Analysis,"" and I was hoping to get some help here. I'll post the problem and my current progress. Exercise 2: For $i = 1, 2, \ldots$ let $\phi_i \in \mathcal{C}(\mathbb{R}^1)$ have support in $(2^{-i}, 2^{1-i})$ such that $\int \phi_i = 1$. Let  $f(x, y) = \displaystyle\sum_{i=1}^\infty [\phi_i (x) - \phi_{i+1} (x)] \phi_i (y)$. Then $f$ has compact support in $\mathbb{R}^2$, $f$ is continuous except at $(0, 0)$, and $\int dy \int f(x, y) dx = 0$ but $\int dx \int f(x, y) dy = 1$. Observe that $f$ is unbounded in every neighborhood of $(0, 0)$. Progress First, note that the supports of the $\phi_i$ are disjoint. Suppose $\phi_i (x) \neq 0$ on the set $S_i$ for each $i$. Then if $x \not\in \displaystyle\cup_{i = 1}^\infty S_i$, or if $y \not\in \displaystyle\cup_{i = 1}^\infty S_i$ we have $f(x, y) = 0$. If $x \in S_i$ for some $i$ then $x \not\in S_j$ for $j \neq i$, so $f(x, y) = -\phi_i (x) \phi_{i-1} (y) + \phi_i (x) \phi_{i} (y) = \phi_i(x) [\phi_{i} (y) - \phi_{i-1} (y)]$. Note that $f(0, 0) = 0$ since $0$ is not in the support of any $\phi_i$. Then if we can show that $f$ is unbounded in every neighborhood of $(0, 0)$, by the epsilon-delta definition of continuity we know that $f$ is not continuous at $(0, 0)$. Since $\int \phi_i = 1$ we know that the support for each $\phi_i$ must be non-empty. Examine the neighborhood of radius $r$ centered at $(0, 0)$. If we can show that $f$ is unbounded on any neighborhood of radius $r < 1$ centered at $(0, 0)$, then by extension it is unbounded on any neighborhood of radius $r \ge 1$ centered at $(0, 0)$. Then suppose $2^{-a} \le r < 2^{1-a}$. Suppose for sake of contradiction that $f$ is bounded in this neighborhood. Then let $\alpha, \beta$ be the values in $\mathbb{R}^1$ such that $f(\alpha, \beta) \ge f(x, y)$ for all $x, y \in \mathbb{R}^1$ with $|(x, y) - (0, 0)| < r$. Suppose $\alpha \in S_i$. We must then have $\beta \in S_{i-1}$ or $\beta \in S_{i}$. If $\beta \in S_{i-1}$ then $f(\alpha, \beta) = -\phi_i (\alpha) \phi_{i-1} (\beta)$, and if $\beta \in S_i$ then $f(\alpha, \beta) = \phi_i (\alpha) \phi_i (\beta)$. ( ~~~ I don't know how to proceed from here. I need to generate an ordered pair in $\mathbb{R}^2$ that creates a larger value for $f$, but I don't know how to judge the magnitude of $\phi_i (\alpha), \phi_i (\beta)$, or $\phi_{i-1} (\beta)$. I think I need to use $\int \phi_i = 1$, but to be totally honest I don't know what that means, or how to use it. ~~~ ) Since the $\phi_i$ are continuous, we know that the $S_i$ are collections of intervals. Then $(0, 1) \backslash \cup_{i = 1}^\infty S_i$ is also a collection of intervals. We showed earlier that $f(x, y) \neq 0$ iff for some $i$ we have $x \in S_i$ and $y \in S_{i} \cup S_{i - 1}$. Then $f(x, y) \neq 0$ over a set whose closure is a collection of $2$-cells, implying by definition that the support of $f(x, y)$ is a collection of $2$-cells. Since $2$-cells are compact and the union of a collection of compact sets is compact, the support of $f(x, y)$ is compact. To show that $f$ is continuous (other than at the origin), we can examine $f$'s behavior in cases. If $x > 1$ or $x < 0$ and $y > 1$ or $y < 0$, then we can construct a disc in $\mathbb{R}^2$ centered at $(x, y)$ that does not intersect the set determined by $0 < x, y < 1$, so $f(x, y) = 0$ on this neighborhood since $\cup_{i = 1}^\infty S_i \subseteq (0, 1)$; this satisfies the epsilon-delta definition of continuity. If $x = 1$ or $y = 1$ then $f(x, y) = 0$. Since $S_1$ is a collection of intervals in $\mathbb{R}^1$, it has a maximum; let it be $s$. Since $\overline{S_1} \in (1/2, 1)$, and since $\overline{S_1}$ is a collection of closed intervals, we know that $s < 1$. Then if $x = 1$ or $y = 1$, we have that $f(x, y) = 0$ on the neighborhood centered at $(x, y)$ with radius $1-s$. This satisfies the epsilon-delta definition of continuity. Else if $x = 0$ and $y \neq 0$ then $f(x, y) = 0$. Suppose $y \in S_i$ for some $i$; then it is in some interval $[a, b] \in S_i$. Then consider the region defined by $(x', y') : x' < 2^{-(i+1)}, y' \in [a, b]$. We can inscribe a disk in this region centered at $(x, y)$, and we have $f(x', y') = 0$ over this region. This satisfies the epsilon-delta definition of continuity. On the other hand, suppose $y \not\in S_i$ for any $i$; then it is in some interval $[a, b]$ such that $\phi_i (y) = 0$ for all $y \in [a, b]$. Through a similar construction we can create a disk over which $f$ takes the value of zero alone. This satisfies the epsilon-delta definition of continuity. Else if $y = 0$ and $x \neq 0$ then $f(x, y) = 0$. Suppose $x \in S_i$ for some $i$; then it is in some interval $[a, b] \in S_i$. Then consider the region defined by $(x', y') : x' \in [a, b], y' < 2^{-i}$. We can inscribe a disk in this region centered at $(x, y)$, and we have $f(x', y') = 0$ over this region. This satisfies the epsilon-delta definition of continuity. On the other hand, suppose $x \not\in S_i$ for any $i$; then it is in some interval $[a, b]$ such that $\phi_i (x) = 0$ for all $x \in [a, b]$. Through a similar construction we can create a disk over which $f$ takes the value of zero alone. This satisfies the epsilon-delta definition of continuity. This shows the continuity of $f$ on all points other than $(0, 0)$. ( ~~~ I don't know what the notation $\int dx \int f(x, y) dy$ means... ~~~ ) Thanks so, so, so, so much for your help!",,"['real-analysis', 'analysis', 'integration']"
57,How to evaluate $\displaystyle\int {1\over (1+kx^2)^{3/2}}dx$,How to evaluate,\displaystyle\int {1\over (1+kx^2)^{3/2}}dx,What change of variable should I use to integrate $$\displaystyle\int {1\over (1+kx^2)^{3/2}}dx$$ I know the answer is $$\displaystyle x\over \sqrt{kx^2+1}.$$ Maybe a trig or hyperbolic function?,What change of variable should I use to integrate $$\displaystyle\int {1\over (1+kx^2)^{3/2}}dx$$ I know the answer is $$\displaystyle x\over \sqrt{kx^2+1}.$$ Maybe a trig or hyperbolic function?,,['integration']
58,Continuous functions question,Continuous functions question,,I am stuck on the problem: Find all continuous functions $h$ satisfying    $$\int_{0}^{x}h(y)dy=\left [ h(x) \right ]^{2}+C$$   for some constant $C$.,I am stuck on the problem: Find all continuous functions $h$ satisfying    $$\int_{0}^{x}h(y)dy=\left [ h(x) \right ]^{2}+C$$   for some constant $C$.,,"['calculus', 'integration']"
59,How can we approximate $\sum_{j=0}^n{\sum_{k=0}^j{c^j k^{1/2}}}$ by integrals?,How can we approximate  by integrals?,\sum_{j=0}^n{\sum_{k=0}^j{c^j k^{1/2}}},"""Difference Equations"" by Walter G. Kelley and Allan C. Peterson, 2nd Edition, gives an example on how to approximate $\sum_{k=1}^n{k^{1/2}}$ using integrals and Bernoulli numbers. I'm interested in nesting summations and using integrals to approximate them.  So I cooked up a relatively simple example: $$\sum_{j=0}^n{\sum_{k=0}^j{c^j k^{1/2}}}$$ I'm mainly interested in knowing how to include an estimate from nested integrals.  The book gives the Euler summation formula: $$\displaystyle\sum_{k=1}^n{f(k)} = $$ $$\displaystyle\int_1^n{f(t)dt}+\frac{f(n)+f(1)}{2} + $$ $$\displaystyle\sum_{i=1}^m{\frac{B_{2i}}{(2i)!}\left(f^{(2i-1)}(n)-f^{(2i-1)}(1)\right)} - $$ $$\displaystyle\frac{1}{(2m)!}\int_1^n{f^{(2m)}(t)B_{2m}(t-\lfloor t \rfloor)dt}$$ where $B_i$ represents the $i$th Bernoulli number.  This formula allows one to estimate a summation by using integrals and Bernoulli numbers.  More information can also be found here, in Wikipedia's entry on it . I'm gussing what I can do is start with $\sum_j \sum_k f(j,k)$ and plug in $\sum_k f(j,k)$ into the Euler summation formula to get half of a big formula.  Then plug that in, along with $\sum_j$, into a second Euler summation formula. QUESTION Can someone please show me how I can approximate the solutions by using Euler summations?  It would help me a great deal, so I'd be very greatful!  Thanks for reading.","""Difference Equations"" by Walter G. Kelley and Allan C. Peterson, 2nd Edition, gives an example on how to approximate $\sum_{k=1}^n{k^{1/2}}$ using integrals and Bernoulli numbers. I'm interested in nesting summations and using integrals to approximate them.  So I cooked up a relatively simple example: $$\sum_{j=0}^n{\sum_{k=0}^j{c^j k^{1/2}}}$$ I'm mainly interested in knowing how to include an estimate from nested integrals.  The book gives the Euler summation formula: $$\displaystyle\sum_{k=1}^n{f(k)} = $$ $$\displaystyle\int_1^n{f(t)dt}+\frac{f(n)+f(1)}{2} + $$ $$\displaystyle\sum_{i=1}^m{\frac{B_{2i}}{(2i)!}\left(f^{(2i-1)}(n)-f^{(2i-1)}(1)\right)} - $$ $$\displaystyle\frac{1}{(2m)!}\int_1^n{f^{(2m)}(t)B_{2m}(t-\lfloor t \rfloor)dt}$$ where $B_i$ represents the $i$th Bernoulli number.  This formula allows one to estimate a summation by using integrals and Bernoulli numbers.  More information can also be found here, in Wikipedia's entry on it . I'm gussing what I can do is start with $\sum_j \sum_k f(j,k)$ and plug in $\sum_k f(j,k)$ into the Euler summation formula to get half of a big formula.  Then plug that in, along with $\sum_j$, into a second Euler summation formula. QUESTION Can someone please show me how I can approximate the solutions by using Euler summations?  It would help me a great deal, so I'd be very greatful!  Thanks for reading.",,"['integration', 'approximation', 'recurrence-relations', 'bernoulli-numbers']"
60,Dyson series and T product (II),Dyson series and T product (II),,"After reading the previous posts related to the Dyson series, I have decided to open a new thread because there is something that I am still not understanding. It concerns the expression: $$ ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})] = $$ $$ ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''}) +  ∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′}) $$ that is assumed in many text books. I wonder if it can be derived from the definition of the Time-ordered operator: $$ \hat{T}[ \hat{H}(t^{′}) \hat{H}(t^{''})]=θ(t^{′}−t^{''}) \hat{H}(t') \hat{H}(t^{''}) + θ(t^{''}−t^{'}) \hat{H}(t^{''}) \hat{H}(t^{'}) $$ and its natural extension to products of integrals: $$ \hat{T}∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{'})\hat{H}(t^{''}) = ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})] = $$ $$ = θ(t^{'}−t^{''}) ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''}) +  θ(t^{''}−t^{′}) ∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′}) $$ If I am right, the step-function θ$(t)$ must cancel one of the terms leading to: $$ ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})] =∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''})  \qquad \text{if $t'>t^{''}$} $$  or: $$ ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})] =∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′}) \qquad \text{if $t'< t^{''}$} $$ but in any case it leads to the combination of both:  $$ ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''}) +  ∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′}) $$ What I am missing? Thanks in advance","After reading the previous posts related to the Dyson series, I have decided to open a new thread because there is something that I am still not understanding. It concerns the expression: $$ ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})] = $$ $$ ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''}) +  ∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′}) $$ that is assumed in many text books. I wonder if it can be derived from the definition of the Time-ordered operator: $$ \hat{T}[ \hat{H}(t^{′}) \hat{H}(t^{''})]=θ(t^{′}−t^{''}) \hat{H}(t') \hat{H}(t^{''}) + θ(t^{''}−t^{'}) \hat{H}(t^{''}) \hat{H}(t^{'}) $$ and its natural extension to products of integrals: $$ \hat{T}∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{'})\hat{H}(t^{''}) = ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})] = $$ $$ = θ(t^{'}−t^{''}) ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''}) +  θ(t^{''}−t^{′}) ∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′}) $$ If I am right, the step-function θ$(t)$ must cancel one of the terms leading to: $$ ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})] =∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''})  \qquad \text{if $t'>t^{''}$} $$  or: $$ ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{T}[\hat{H}(t^{'})\hat{H}(t^{''})] =∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′}) \qquad \text{if $t'< t^{''}$} $$ but in any case it leads to the combination of both:  $$ ∫_{t_0}^{t}dt^{′}∫_{t_0}^{t^{′}}dt^{''}\hat{H}(t^{′})\hat{H}(t^{''}) +  ∫_{t_0}^{t}dt^{''}∫_{t_0}^{t^{′}}dt^{'}\hat{H}(t^{''})\hat{H}(t^{′}) $$ What I am missing? Thanks in advance",,"['integration', 'physics', 'products']"
61,Finding power series representation of $ \int_0^{\frac{\pi }{2}} \frac{1}{\sqrt {1 - k^2\sin^2{x}}}\;{dx}$,Finding power series representation of, \int_0^{\frac{\pi }{2}} \frac{1}{\sqrt {1 - k^2\sin^2{x}}}\;{dx},"I want to show that $\displaystyle \int_0^{\frac{\pi }{2}} \frac{1}{\sqrt {1 - k^2\sin^2{x}}}\;{dx} = \frac{\pi}{2}\sum_{n \ge 0}k^{2n}\left({\frac{{1 \cdot 3 \cdots \left( {2n - 1} \right)}} {{2 \cdot 4 \cdots \cdot 2n}}} \right)$, where $ -1 < k < 1$. Here is what I did: $$\displaystyle \begin{aligned}\int_0^{\frac{\pi }{2}} \frac{1}{{\sqrt {1 - k^2\sin^2{x}}}}\;{dx} & = \int_{0}^{\pi/2}\sum_{n \ge 0} \frac{k^{2n}}{2^{2n}}\binom{2n}{n}\sin^{2n}{x}\;{dx} \\& = \sum_{n \ge 0}\int_{0}^{\pi/2} \frac{k^{2n}}{2^{2n}}\binom{2n}{n}\sin^{2n}{x}\;{dx}  \\& = \frac{\pi}{2} \sum_{n \ge 0} ~ k^{2n} \bigg(\frac{1}{2^{2n}}\binom{2n}{n}\prod_{1 \le r \le n}\frac{2r-1}{2r} \bigg) \\& = \frac{\pi}{2} \sum_{n \ge 0} ~ k^{2n} \bigg(\prod_{1 \le r \le n}\frac{2r-1}{2r} \cdot \prod_{1 \le r \le n}\frac{2r-1}{2r} \bigg) \\& = \frac{\pi}{2}\sum_{n \ge 0}k^{2n}\bigg(\prod_{1 \le r \le n}\frac{2r-1}{2r}\bigg)^2.\end{aligned}$$ However, there no power on the coefficients in the given series, so they obviously don't match, and I couldn't whatsoever discern a mistake in my calculations. Thanks in advance.","I want to show that $\displaystyle \int_0^{\frac{\pi }{2}} \frac{1}{\sqrt {1 - k^2\sin^2{x}}}\;{dx} = \frac{\pi}{2}\sum_{n \ge 0}k^{2n}\left({\frac{{1 \cdot 3 \cdots \left( {2n - 1} \right)}} {{2 \cdot 4 \cdots \cdot 2n}}} \right)$, where $ -1 < k < 1$. Here is what I did: $$\displaystyle \begin{aligned}\int_0^{\frac{\pi }{2}} \frac{1}{{\sqrt {1 - k^2\sin^2{x}}}}\;{dx} & = \int_{0}^{\pi/2}\sum_{n \ge 0} \frac{k^{2n}}{2^{2n}}\binom{2n}{n}\sin^{2n}{x}\;{dx} \\& = \sum_{n \ge 0}\int_{0}^{\pi/2} \frac{k^{2n}}{2^{2n}}\binom{2n}{n}\sin^{2n}{x}\;{dx}  \\& = \frac{\pi}{2} \sum_{n \ge 0} ~ k^{2n} \bigg(\frac{1}{2^{2n}}\binom{2n}{n}\prod_{1 \le r \le n}\frac{2r-1}{2r} \bigg) \\& = \frac{\pi}{2} \sum_{n \ge 0} ~ k^{2n} \bigg(\prod_{1 \le r \le n}\frac{2r-1}{2r} \cdot \prod_{1 \le r \le n}\frac{2r-1}{2r} \bigg) \\& = \frac{\pi}{2}\sum_{n \ge 0}k^{2n}\bigg(\prod_{1 \le r \le n}\frac{2r-1}{2r}\bigg)^2.\end{aligned}$$ However, there no power on the coefficients in the given series, so they obviously don't match, and I couldn't whatsoever discern a mistake in my calculations. Thanks in advance.",,"['sequences-and-series', 'integration', 'power-series']"
62,Sum of derivative of integrals: $f(x)=\left(\int\limits_0 ^{x} e^{-t^2}dt\right)^2$ and $g(x)=\int\limits_{0}^{1}\frac{e^{-x^2(t^2+1)}}{t^2+1}dt$,Sum of derivative of integrals:  and,f(x)=\left(\int\limits_0 ^{x} e^{-t^2}dt\right)^2 g(x)=\int\limits_{0}^{1}\frac{e^{-x^2(t^2+1)}}{t^2+1}dt,"For all $x$ in $\mathbb R$ define $\displaystyle f(x)=\left(\int_0 ^{x} e^{-t^2}dt\right)^2$ and $\displaystyle g(x)=\int_{0}^{1}\frac{e^{-x^2(t^2+1)}}{t^2+1}dt$. Show that for all $x$ in $\mathbb R$   $f'(x)+g'(x)=0$ I did: $\displaystyle f'(x)=2\left( \int_{0}^{x}e^{-t^2}dt\right)e^{-x^2}$ and $\displaystyle g'(x)=\int_{0}^{1}e^{-x^2(t^2+1)}(-2x)dt$ then changing $xt\rightarrow t$ $\displaystyle g'(x)=-2x e^{-x^2}\int_{0}^{x}e^{t^2}dt$ , finally $\displaystyle f'(x)+g'(x)=2(1-x)e^{-x^2}\int_{0}^{x}e^{t^2}dt$ then this is equal to zero only if x=1. Am i missing something? thanks beforehand.","For all $x$ in $\mathbb R$ define $\displaystyle f(x)=\left(\int_0 ^{x} e^{-t^2}dt\right)^2$ and $\displaystyle g(x)=\int_{0}^{1}\frac{e^{-x^2(t^2+1)}}{t^2+1}dt$. Show that for all $x$ in $\mathbb R$   $f'(x)+g'(x)=0$ I did: $\displaystyle f'(x)=2\left( \int_{0}^{x}e^{-t^2}dt\right)e^{-x^2}$ and $\displaystyle g'(x)=\int_{0}^{1}e^{-x^2(t^2+1)}(-2x)dt$ then changing $xt\rightarrow t$ $\displaystyle g'(x)=-2x e^{-x^2}\int_{0}^{x}e^{t^2}dt$ , finally $\displaystyle f'(x)+g'(x)=2(1-x)e^{-x^2}\int_{0}^{x}e^{t^2}dt$ then this is equal to zero only if x=1. Am i missing something? thanks beforehand.",,"['calculus', 'integration']"
63,"How to integrate $\int_0^1\frac{\ln^3(1+x)\,\ln^3x}x\mathrm{d}x$",How to integrate,"\int_0^1\frac{\ln^3(1+x)\,\ln^3x}x\mathrm{d}x","How to integrate $$\displaystyle{\Large\displaystyle \int_0^1\frac{\ln^3(1+x)\,\ln^3x}x\mathrm{d}x}$$ My idea \begin{align*} \int_{0}^{1} \frac{\ln^3 (1+x) \ln^3 x}{x} \, \mathrm{d}x &= -18 \sum_{n=1}^{\infty} \left ( -1 \right )^{n+1} \left ( \mathcal{H}_{n+1}^2 - \mathcal{H}_{n+1}^{(2)} \right ) \frac{1}{\left (n+2  \right )^4}  \\ &= 18 \sum_{n=1}^{\infty} (-1)^n \left ( \mathcal{H}_{n+1}^2 - \mathcal{H}_{n+1}^{(2)} \right ) \frac{1}{\left ( n+2 \right )^4} \\ &= 18 \sum_{n=2}^{\infty} (-1)^{n-1} \left ( \mathcal{H}_{n}^2 -  \mathcal{H}_{n+1}^{(2)} \right ) \frac{1}{\left ( n+1 \right )^4} \end{align*}",How to integrate My idea,"\displaystyle{\Large\displaystyle \int_0^1\frac{\ln^3(1+x)\,\ln^3x}x\mathrm{d}x} \begin{align*}
\int_{0}^{1} \frac{\ln^3 (1+x) \ln^3 x}{x} \, \mathrm{d}x &= -18 \sum_{n=1}^{\infty} \left ( -1 \right )^{n+1} \left ( \mathcal{H}_{n+1}^2 - \mathcal{H}_{n+1}^{(2)} \right ) \frac{1}{\left (n+2  \right )^4}  \\
&= 18 \sum_{n=1}^{\infty} (-1)^n \left ( \mathcal{H}_{n+1}^2 - \mathcal{H}_{n+1}^{(2)} \right ) \frac{1}{\left ( n+2 \right )^4} \\
&= 18 \sum_{n=2}^{\infty} (-1)^{n-1} \left ( \mathcal{H}_{n}^2 -  \mathcal{H}_{n+1}^{(2)} \right ) \frac{1}{\left ( n+1 \right )^4}
\end{align*}","['calculus', 'integration', 'definite-integrals', 'harmonic-functions', 'euler-sums']"
64,An exotic integral,An exotic integral,,"Good evening, We were playing with a friend on Desmos, and we came to $x \longmapsto \arctan\left(\exp\left(-\displaystyle\frac{1}{\sqrt{1-x^2}}\right) \right)$ . Here is the graph : And we have : $$\int_{-1}^1 \arctan\left(\exp\left(-\displaystyle\frac{1}{\sqrt{1-x^2}}\right) \right) \hspace{0.1cm} \mathrm{d}x \approx 0.529797566526076$$ We were wondering if it was calculable ? There is very few chance but hey, we never know. Best regards.","Good evening, We were playing with a friend on Desmos, and we came to . Here is the graph : And we have : We were wondering if it was calculable ? There is very few chance but hey, we never know. Best regards.",x \longmapsto \arctan\left(\exp\left(-\displaystyle\frac{1}{\sqrt{1-x^2}}\right) \right) \int_{-1}^1 \arctan\left(\exp\left(-\displaystyle\frac{1}{\sqrt{1-x^2}}\right) \right) \hspace{0.1cm} \mathrm{d}x \approx 0.529797566526076,['integration']
65,How to find the coefficient of $x^k$ in the expression $\prod_{p=1}^n (x^p+1)^p$?,How to find the coefficient of  in the expression ?,x^k \prod_{p=1}^n (x^p+1)^p,"This Question asked on math over flow I tried to find the indefinite integral $$ f_n(x)=\int \prod_{k=1}^n \cos^k(kx)dx$$ by using Euler's formula and put $x=\frac{\ln y}{2i}$ I got $$ f_n(x)=-i2^{-\frac{n(n+1)}{2}-1}\int y^{-\frac{n(n+1)(2n+1)}{12}-1} \prod_{k=1}^n (y^k+1)^k dy$$ now lets define $a(n,k)$ as the coefficient of $x^k$ in the expression $\prod_{p=1}^n (x^p+1)^p$ then $$ \prod_{k=1}^n (y^k+1)^k =\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} a(n,k) y^k$$ So $$ f_n(x)=2^{-\frac{n(n+1)}{2}-1}\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} \frac{a(n,k)}{k-\frac{n(n+1)(2n+1)}{12}} (-i)\exp\left(-2x\left(k-\frac{n(n+1)(2n+1)}{12}\right) i\right)+c $$ and where $f_n(x)$ is real So we will take the real part of the result and get $$ f_n(x)=2^{-\frac{n(n+1)}{2}-1}\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} \frac{a(n,k)}{k-\frac{n(n+1)(2n+1)}{12}}\sin\left(2x\left(k-\frac{n(n+1)(2n+1)}{12}\right)\right)+c $$ and if $k=\frac{n(n+1)(2n+1)}{12}$ then take limit to get $\frac{\sin(2ax)}{a}=2x , a\to0$ finally if we know $$ a(n,k)=a\left(n,\frac{n(n+1)(2n+1)}{6}-k\right)$$ then $$ f_n(x)=2^{-\frac{n(n+1)}{2}} a\left(n,\frac{N}{2}\right) x+2^{-\frac{n(n+1)}{2}-1}\sum_{k=1}^{\frac{N}{2}} \frac{a\left(n,\frac{N}{2}-k\right)}{k} \sin\left(2kx\right)+c ,\text{if  } N \text{   is even}$$ and $$ f_n(x)=2^{-\frac{n(n+1)}{2}+1}a\left(n,\frac{N-1}{2}\right)\sin\left(x\right)+2^{-\frac{n(n+1)}{2}}\sum_{k=1}^{\frac{N-1}{2}} \frac{a\left(n,\frac{N-1}{2}-k\right)}{2k+1} \sin\left((2k+1)x\right)+c   ,\text{if  } N \text{   is odd}$$ where $N=\frac{n(n+1)(2n+1)}{6} $ now my QUESTIONS How to calculate $a(n,k)$ or even what is the recurrence relation? also How to prove that $a(n,k)=a\left(n,\frac{n(n+1)(2n+1)}{6}-k\right)$ ? and when we took the real part if we took the imaginary part it will be zero So How to prove $$\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} \frac{a(n,k)}{k-\frac{n(n+1)(2n+1)}{12}}\cos\left(2x\left(k-\frac{n(n+1)(2n+1)}{12}\right)\right)=c $$",This Question asked on math over flow I tried to find the indefinite integral by using Euler's formula and put I got now lets define as the coefficient of in the expression then So and where is real So we will take the real part of the result and get and if then take limit to get finally if we know then and where now my QUESTIONS How to calculate or even what is the recurrence relation? also How to prove that ? and when we took the real part if we took the imaginary part it will be zero So How to prove," f_n(x)=\int \prod_{k=1}^n \cos^k(kx)dx x=\frac{\ln y}{2i}  f_n(x)=-i2^{-\frac{n(n+1)}{2}-1}\int y^{-\frac{n(n+1)(2n+1)}{12}-1} \prod_{k=1}^n (y^k+1)^k dy a(n,k) x^k \prod_{p=1}^n (x^p+1)^p  \prod_{k=1}^n (y^k+1)^k =\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} a(n,k) y^k  f_n(x)=2^{-\frac{n(n+1)}{2}-1}\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} \frac{a(n,k)}{k-\frac{n(n+1)(2n+1)}{12}} (-i)\exp\left(-2x\left(k-\frac{n(n+1)(2n+1)}{12}\right) i\right)+c  f_n(x)  f_n(x)=2^{-\frac{n(n+1)}{2}-1}\sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} \frac{a(n,k)}{k-\frac{n(n+1)(2n+1)}{12}}\sin\left(2x\left(k-\frac{n(n+1)(2n+1)}{12}\right)\right)+c  k=\frac{n(n+1)(2n+1)}{12} \frac{\sin(2ax)}{a}=2x , a\to0  a(n,k)=a\left(n,\frac{n(n+1)(2n+1)}{6}-k\right)  f_n(x)=2^{-\frac{n(n+1)}{2}} a\left(n,\frac{N}{2}\right) x+2^{-\frac{n(n+1)}{2}-1}\sum_{k=1}^{\frac{N}{2}} \frac{a\left(n,\frac{N}{2}-k\right)}{k} \sin\left(2kx\right)+c ,\text{if  } N \text{   is even}  f_n(x)=2^{-\frac{n(n+1)}{2}+1}a\left(n,\frac{N-1}{2}\right)\sin\left(x\right)+2^{-\frac{n(n+1)}{2}}\sum_{k=1}^{\frac{N-1}{2}} \frac{a\left(n,\frac{N-1}{2}-k\right)}{2k+1} \sin\left((2k+1)x\right)+c   ,\text{if  } N \text{   is odd} N=\frac{n(n+1)(2n+1)}{6}  a(n,k) a(n,k)=a\left(n,\frac{n(n+1)(2n+1)}{6}-k\right) \sum_{k=0}^{\frac{n(n+1)(2n+1)}{6}} \frac{a(n,k)}{k-\frac{n(n+1)(2n+1)}{12}}\cos\left(2x\left(k-\frac{n(n+1)(2n+1)}{12}\right)\right)=c ","['calculus', 'integration', 'recurrence-relations', 'indefinite-integrals', 'products']"
66,Can real integrals that are computed using complex contour integration depend on the choice of contour?,Can real integrals that are computed using complex contour integration depend on the choice of contour?,,"I am studying the following integral: $$\int_{-\infty}^\infty \frac{1}{2\pi i} \frac{-e^{-ix(a-b)}}{x^2 - c^2} dx$$ where $a, b, c > 0$ are real constants. The integrand has poles along the real axis when viewed as a complex function. My approach to solving this integral was to create a contour with two semicircles of radius $\epsilon$ and close the contour by creating a big semicircle. In other words, we would have a contour like the one in the figure below: but instead of having a semicircle cutout near the origin there would be two at $\pm c$ . One can then use the residue theorem. I made a post about this integral on physics SE: https://physics.stackexchange.com/q/800770/288281 . In that post I was surprised to find out that the choice of contour does matter and will give different answers, in contrast to something like $$\int_{-\infty}^\infty \frac{\sin(x)}{x}dx$$ which does not depend on the choice of contour. This is briefly discussed in this question: When does the value of a complex contour integral depend on the choice of the contour of integration? . I have two questions: When does the value of an integral over the real line, when computed using complex contour integration, depend on the choice of contour and why? The approach used to solve this integral in physics textbooks is also to use the residue theorem, but they first push the poles slightly above or below the real axis and then take a limit. So the integral becomes $$\lim_{\epsilon \rightarrow 0} \int_{-\infty}^\infty \frac{1}{2\pi i} \frac{-e^{-ix(a-b)}}{x^2 - c^2 + i\epsilon} dx.$$ Why is it necessary to push the poles above/below the real axis? What is wrong with the contour approach I described above which keeps the poles on the real axis? Is this because the integral is not well defined?","I am studying the following integral: where are real constants. The integrand has poles along the real axis when viewed as a complex function. My approach to solving this integral was to create a contour with two semicircles of radius and close the contour by creating a big semicircle. In other words, we would have a contour like the one in the figure below: but instead of having a semicircle cutout near the origin there would be two at . One can then use the residue theorem. I made a post about this integral on physics SE: https://physics.stackexchange.com/q/800770/288281 . In that post I was surprised to find out that the choice of contour does matter and will give different answers, in contrast to something like which does not depend on the choice of contour. This is briefly discussed in this question: When does the value of a complex contour integral depend on the choice of the contour of integration? . I have two questions: When does the value of an integral over the real line, when computed using complex contour integration, depend on the choice of contour and why? The approach used to solve this integral in physics textbooks is also to use the residue theorem, but they first push the poles slightly above or below the real axis and then take a limit. So the integral becomes Why is it necessary to push the poles above/below the real axis? What is wrong with the contour approach I described above which keeps the poles on the real axis? Is this because the integral is not well defined?","\int_{-\infty}^\infty \frac{1}{2\pi i} \frac{-e^{-ix(a-b)}}{x^2 - c^2} dx a, b, c > 0 \epsilon \pm c \int_{-\infty}^\infty \frac{\sin(x)}{x}dx \lim_{\epsilon \rightarrow 0} \int_{-\infty}^\infty \frac{1}{2\pi i} \frac{-e^{-ix(a-b)}}{x^2 - c^2 + i\epsilon} dx.","['integration', 'complex-analysis', 'contour-integration', 'residue-calculus']"
67,Inequality resulted from $f''$ bounded,Inequality resulted from  bounded,f'',"Let $f$ of $C^2$ class in $[-a,a]$ with $a>0$ , and let $M=\sup_{x\in[-a,a]}|f''(x)|$ . Prove that for all $x\in[-a,a]$ we have $|f'(x)|\leq\dfrac{1}{2a}|f(a)-f(-a)|+\dfrac{a^2+x^2}{2a}M$ I tried using various methods such as a Taylor expansion with integral remainder, and integrating from $-a$ to $t$ , and from $t$ to $a$ for all $t\in[a,b]$ in the inequality $|f''(x)|\leq M$ , though it seems that there is something tricky that I am not seeing.","Let of class in with , and let . Prove that for all we have I tried using various methods such as a Taylor expansion with integral remainder, and integrating from to , and from to for all in the inequality , though it seems that there is something tricky that I am not seeing.","f C^2 [-a,a] a>0 M=\sup_{x\in[-a,a]}|f''(x)| x\in[-a,a] |f'(x)|\leq\dfrac{1}{2a}|f(a)-f(-a)|+\dfrac{a^2+x^2}{2a}M -a t t a t\in[a,b] |f''(x)|\leq M","['integration', 'analysis', 'derivatives']"
68,"Is the function $x \mapsto \mu(A+x)$ continuous, where $\mu$ is a finite Borel measure on $\mathbb R^n$ and $A \in \mathcal B(\mathbb R^n)$","Is the function  continuous, where  is a finite Borel measure on  and",x \mapsto \mu(A+x) \mu \mathbb R^n A \in \mathcal B(\mathbb R^n),"Let $\mu$ be a finite regular Borel measure on $\mathbb R^n$ and $A$ is a Borel set. I am trying to prove that $x \mapsto \mu(A+x)$ is continuous. Here $\mu$ is regular means it satisfies assumptions in this link . In fact, there are several posts on this site similar to this question, but they all assume $\mu$ is ab. continuous w.r.t Lebesgue measure $m$ . I found myself a proof without assuming this but couldn't find something wrong with it. Also, there is an answer by John Dawkins poitning out that if $\mu$ is not ab. continuous w.r.t $m$ then $x \mapsto \mu(A+x)$ is not continuous. I hope you can help me find what's wrong in my proof. Here is it: Since $\mu$ is finite and regular, $C_c(\mathbb R^n)$ is dense in $L^p(\mathbb R^n, \mu)$ . To prove $x \mapsto \mu(A+x)$ is continuous, fix one $y \in \mathbb R^n$ I use $$ |\mu(A+x) - \mu(A+y)| \leq \int |1_{A+y}(u+y-x)- 1_{A+y}(u)| \mu(du) $$ Let $g \in C_c(\mathbb R^n)$ be such that $ \| g - 1_{A+y} \|_{L^1(\mathbb R^n, \mu)} \leq \epsilon$ and since $g$ is uniformly continuous so when $h = y-x$ is going to 0, we have \begin{align*} \int |1_{A+y}(u+h)- 1_{A+y}(u)| \mu(du) &\leq \| g - 1_{A+y} \|_{L^1(\mathbb R^n, \mu)}  + \int |g(u+h)- g(x)| \mu(du)\\ &\qquad + \int |1_{A+y}(u+h)- g(u+h)| \mu(du) \\ &< 3 \epsilon. \end{align*} So that $x \mapsto \mu(A+x)$ is continuous. In particular, I would like to chose $\mu = \delta_{0}$ , the Dirac measure at 0, and $A$ is an open set so that $ x \mapsto \delta_{0}(A+x):= \phi(x)$ is continuous. However, $\phi^{-1}(-\infty, 1/2) = - \bar A$ is closed, which I suspect something is off but counldn't tell what went wrong","Let be a finite regular Borel measure on and is a Borel set. I am trying to prove that is continuous. Here is regular means it satisfies assumptions in this link . In fact, there are several posts on this site similar to this question, but they all assume is ab. continuous w.r.t Lebesgue measure . I found myself a proof without assuming this but couldn't find something wrong with it. Also, there is an answer by John Dawkins poitning out that if is not ab. continuous w.r.t then is not continuous. I hope you can help me find what's wrong in my proof. Here is it: Since is finite and regular, is dense in . To prove is continuous, fix one I use Let be such that and since is uniformly continuous so when is going to 0, we have So that is continuous. In particular, I would like to chose , the Dirac measure at 0, and is an open set so that is continuous. However, is closed, which I suspect something is off but counldn't tell what went wrong","\mu \mathbb R^n A x \mapsto \mu(A+x) \mu \mu m \mu m x \mapsto \mu(A+x) \mu C_c(\mathbb R^n) L^p(\mathbb R^n, \mu) x \mapsto \mu(A+x) y \in \mathbb R^n  |\mu(A+x) - \mu(A+y)| \leq \int |1_{A+y}(u+y-x)- 1_{A+y}(u)| \mu(du)  g \in C_c(\mathbb R^n)  \| g - 1_{A+y} \|_{L^1(\mathbb R^n, \mu)} \leq \epsilon g h = y-x \begin{align*}
\int |1_{A+y}(u+h)- 1_{A+y}(u)| \mu(du) &\leq \| g - 1_{A+y} \|_{L^1(\mathbb R^n, \mu)}  + \int |g(u+h)- g(x)| \mu(du)\\
&\qquad + \int |1_{A+y}(u+h)- g(u+h)| \mu(du) \\ &< 3 \epsilon.
\end{align*} x \mapsto \mu(A+x) \mu = \delta_{0} A  x \mapsto \delta_{0}(A+x):= \phi(x) \phi^{-1}(-\infty, 1/2) = - \bar A","['real-analysis', 'integration', 'functional-analysis', 'measure-theory', 'lp-spaces']"
69,Integral for area under a sphere bound by a square,Integral for area under a sphere bound by a square,,"I need to calculate the volume under a sphere of radius R centered on the origin bounded by a square, also centered on the origin in the X-Y plane, with sides of length A. Sphere of radius R bounded by square of size A I first tried to set it up in cylindrical and integrated $\frac{1}{8}$ of the volume by bounding as follows: $$\theta \in \left[0,\frac{\pi}{4}\right],\,r\in\left[0\,,\frac{A}{2 \cos\theta}\right]$$ then integrating as follows: $$8\int_{\theta=0}^{\frac{\pi}{4}}\int_{r = 0}^{\frac{A}{2 \cos\theta}} \sqrt{R^2-r^2}   r dr d\theta =$$ $$-\frac{8}{3}\int_{\theta=0}^{\frac{\pi}{4}}\left(R^2-r^2\right)^\frac{3}{2}\rvert_0^\frac{A}{2 \cos\theta}  d\theta =$$ $$-\frac{8}{3}\int_{\theta=0}^{\frac{\pi}{4}} \left(R^2-\left(\frac{A \sec\theta}{2}\right)^2\right)^\frac{3}{2} d\theta + \frac{2 R^3\pi}{3}$$ where I get stuck on how to integrate the first term. So, I tried it in spherical coordinates with bounds as follows: $$\theta \in \left[0,\frac{\pi}{4}\right],\,\rho\in[0,R],\,\phi\in\left[0\,,\arcsin\left(\frac{A}{2 R \cos\theta}\right)\right]$$ then integrating as follows: $$8\int_{r=0}^R\int_{\theta = 0}^\frac{\pi}{4} \int_{\phi=0}^{\arcsin\left(\frac{A}{2 R \cos\theta}\right)} r^2\sin\theta d\phi d\theta dr$$ $$8\int_{r=0}^R r^2\int_{\theta = 0}^\frac{\pi}{4} \sin\theta\phi\rvert_{\phi=0}^{\arcsin\left(\frac{A}{2 R \cos\theta}\right)} d\theta dr$$ $$8\int_{r=0}^R r^2\int_{\theta = 0}^\frac{\pi}{4} \sin\theta\arcsin\left(\frac{A}{2 R \cos\theta}\right) d\theta dr$$ where I get stuck again. I suspect I'm setting this integral up incorrectly. Can anyone make a suggestion? [EDIT] Cartesian is where I started (and I'll admit my integration is rusty), but the only move I could see was a substitution where $g=R^2-y^2$ and then a trig substitution $x=\sin{\theta}\sqrt{g}$ . So , the integral becomes: $$4\int_{y=0}^{\frac{A}{2}}\int_{x = 0}^{\frac{A}{2}} \sqrt{R^2-x^2-y^2} dx dy =$$ $$4\int_{y=0}^{\frac{A}{2}}\int_{\theta = 0}^{\arcsin\frac{A}{2\sqrt{g}}} g\cos^2\theta d\theta dy =$$ $$4\int_{y=0}^{\frac{A}{2}}\frac{g}{2}\int_{\theta = 0}^{\arcsin\frac{A}{2\sqrt{g}}}\left(1+\cos2\theta\right) d\theta dy =$$ $$4\int_{y=0}^{\frac{A}{2}}\frac{g}{2}\left(\theta+\frac{\sin2\theta}{2}\right)\rvert_{\theta = 0}^{\arcsin\frac{A}{2\sqrt{g}}} dy =$$ $$4\int_{y=0}^{\frac{A}{2}}\frac{g}{2}\left(\arcsin\left(\frac{A}{2\sqrt{g}}\right)+\left(\frac{A}{2\sqrt{g}}\right)\cos\left(\arcsin\left(\frac{A}{2\sqrt{g}}\right)\right)\right) dy$$ and, while I could undo the substitution and simplify slightly, I'm stuck again. I also tried it by parts with $u=\sqrt{R^2-x^2-y^2}, dv=dx$ , but the $\int{udv}$ eventually leads me back where my trig substitution did.","I need to calculate the volume under a sphere of radius R centered on the origin bounded by a square, also centered on the origin in the X-Y plane, with sides of length A. Sphere of radius R bounded by square of size A I first tried to set it up in cylindrical and integrated of the volume by bounding as follows: then integrating as follows: where I get stuck on how to integrate the first term. So, I tried it in spherical coordinates with bounds as follows: then integrating as follows: where I get stuck again. I suspect I'm setting this integral up incorrectly. Can anyone make a suggestion? [EDIT] Cartesian is where I started (and I'll admit my integration is rusty), but the only move I could see was a substitution where and then a trig substitution . So , the integral becomes: and, while I could undo the substitution and simplify slightly, I'm stuck again. I also tried it by parts with , but the eventually leads me back where my trig substitution did.","\frac{1}{8} \theta \in \left[0,\frac{\pi}{4}\right],\,r\in\left[0\,,\frac{A}{2 \cos\theta}\right] 8\int_{\theta=0}^{\frac{\pi}{4}}\int_{r = 0}^{\frac{A}{2 \cos\theta}} \sqrt{R^2-r^2} 
 r dr d\theta = -\frac{8}{3}\int_{\theta=0}^{\frac{\pi}{4}}\left(R^2-r^2\right)^\frac{3}{2}\rvert_0^\frac{A}{2 \cos\theta}  d\theta = -\frac{8}{3}\int_{\theta=0}^{\frac{\pi}{4}} \left(R^2-\left(\frac{A \sec\theta}{2}\right)^2\right)^\frac{3}{2} d\theta + \frac{2 R^3\pi}{3} \theta \in \left[0,\frac{\pi}{4}\right],\,\rho\in[0,R],\,\phi\in\left[0\,,\arcsin\left(\frac{A}{2 R \cos\theta}\right)\right] 8\int_{r=0}^R\int_{\theta = 0}^\frac{\pi}{4} \int_{\phi=0}^{\arcsin\left(\frac{A}{2 R \cos\theta}\right)} r^2\sin\theta d\phi d\theta dr 8\int_{r=0}^R r^2\int_{\theta = 0}^\frac{\pi}{4} \sin\theta\phi\rvert_{\phi=0}^{\arcsin\left(\frac{A}{2 R \cos\theta}\right)} d\theta dr 8\int_{r=0}^R r^2\int_{\theta = 0}^\frac{\pi}{4} \sin\theta\arcsin\left(\frac{A}{2 R \cos\theta}\right) d\theta dr g=R^2-y^2 x=\sin{\theta}\sqrt{g} 4\int_{y=0}^{\frac{A}{2}}\int_{x = 0}^{\frac{A}{2}} \sqrt{R^2-x^2-y^2} dx dy = 4\int_{y=0}^{\frac{A}{2}}\int_{\theta = 0}^{\arcsin\frac{A}{2\sqrt{g}}} g\cos^2\theta d\theta dy = 4\int_{y=0}^{\frac{A}{2}}\frac{g}{2}\int_{\theta = 0}^{\arcsin\frac{A}{2\sqrt{g}}}\left(1+\cos2\theta\right) d\theta dy = 4\int_{y=0}^{\frac{A}{2}}\frac{g}{2}\left(\theta+\frac{\sin2\theta}{2}\right)\rvert_{\theta = 0}^{\arcsin\frac{A}{2\sqrt{g}}} dy = 4\int_{y=0}^{\frac{A}{2}}\frac{g}{2}\left(\arcsin\left(\frac{A}{2\sqrt{g}}\right)+\left(\frac{A}{2\sqrt{g}}\right)\cos\left(\arcsin\left(\frac{A}{2\sqrt{g}}\right)\right)\right) dy u=\sqrt{R^2-x^2-y^2}, dv=dx \int{udv}","['integration', 'multivariable-calculus']"
70,Does anyone have good logarithmic integrals? And logarithmic integral identities?,Does anyone have good logarithmic integrals? And logarithmic integral identities?,,"I have recently taken an interest in evaluating logarithmic integrals and would really love practice problems and especially, theorems, series expansions, and identities that have helped any of ya’ll in evaluating integrals like these, especially ones with products of logarithms with different argument combined with ratios of polynomials. To hopefully give a sense as to the level I am at in the evaluation of these, I can evaluate integrals like: $$\int_{0}^{\frac{\pi}{4}}\log(\cos(x))\,dx$$ $$\int_{0}^{1}\frac{\log^n(x)}{x^2+1}\,dx$$ $$\int_{0}^{1}\log(x)\log(1\pm x)\,dx$$ $$\int_{0}^{1}\frac{\log(x)}{1-x^2}\,dx$$ $$\int_{0}^{\infty}\frac{\log(x^4+x^2+1)}{x^2+1}\,dx$$ $$\int_{0}^{\infty}\frac{\log(x)\sin(x)}{x}\,dx$$ $$\int_{0}^{\infty}\log(x)e^{-x^2}\,dx$$ $$\int_{0}^{1}\log(x)\arctan(x)\,dx$$ Anything is appreciated!","I have recently taken an interest in evaluating logarithmic integrals and would really love practice problems and especially, theorems, series expansions, and identities that have helped any of ya’ll in evaluating integrals like these, especially ones with products of logarithms with different argument combined with ratios of polynomials. To hopefully give a sense as to the level I am at in the evaluation of these, I can evaluate integrals like: Anything is appreciated!","\int_{0}^{\frac{\pi}{4}}\log(\cos(x))\,dx \int_{0}^{1}\frac{\log^n(x)}{x^2+1}\,dx \int_{0}^{1}\log(x)\log(1\pm x)\,dx \int_{0}^{1}\frac{\log(x)}{1-x^2}\,dx \int_{0}^{\infty}\frac{\log(x^4+x^2+1)}{x^2+1}\,dx \int_{0}^{\infty}\frac{\log(x)\sin(x)}{x}\,dx \int_{0}^{\infty}\log(x)e^{-x^2}\,dx \int_{0}^{1}\log(x)\arctan(x)\,dx","['integration', 'definite-integrals', 'logarithms', 'harmonic-numbers']"
71,Average area of intersection between two regular n-sided polygons,Average area of intersection between two regular n-sided polygons,,"I want to find the average area of intersection between two regular polygons constructed as such: we uniformly choose any random point $M$ on the interior of the first n-sided polygon and reflect the entire polygon about $M$ , so in the figure below the center $O$ of the first polygon becomes $O'$ . I want to find the integral of this area over all possible points $M$ and divide it by the area, which if I'm not mistaken gives the average area. My figure below is not so accurate, but the overlapping area should be symmetric across the perpendicular bisector of $OO'$ . I assume that the apothem of the polygon is 1. Using numerical methods I got the value of $\frac{A}{4}$ , where $A$ is the area of the polygon. However, I want a proof of this for all values $n\geq3$ . I do not know whether there exists a closed form formula to calculate the area of the intersection, but that might help in calculating the integral. The integral could also be split over $2n$ symmetrical triangular areas within the polygon. Other than that, I have no idea how to start proving this, or whether a proof even exists. Edit: After reconsidering the problem requirements, I exclusively want a non-recursive formula for the intersection area, or a confirmation that it is impossible to find.","I want to find the average area of intersection between two regular polygons constructed as such: we uniformly choose any random point on the interior of the first n-sided polygon and reflect the entire polygon about , so in the figure below the center of the first polygon becomes . I want to find the integral of this area over all possible points and divide it by the area, which if I'm not mistaken gives the average area. My figure below is not so accurate, but the overlapping area should be symmetric across the perpendicular bisector of . I assume that the apothem of the polygon is 1. Using numerical methods I got the value of , where is the area of the polygon. However, I want a proof of this for all values . I do not know whether there exists a closed form formula to calculate the area of the intersection, but that might help in calculating the integral. The integral could also be split over symmetrical triangular areas within the polygon. Other than that, I have no idea how to start proving this, or whether a proof even exists. Edit: After reconsidering the problem requirements, I exclusively want a non-recursive formula for the intersection area, or a confirmation that it is impossible to find.",M M O O' M OO' \frac{A}{4} A n\geq3 2n,"['integration', 'geometry']"
72,Find range of $f(\sqrt 2)$ for $f(x)=e^{\frac{x^2}{2}}+\int_0^x tf(t)dt$,Find range of  for,f(\sqrt 2) f(x)=e^{\frac{x^2}{2}}+\int_0^x tf(t)dt,"Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a continuous function satisfying $$f(x)=e^{\frac{x^2}{2}}+\int_0^x tf(t)\mathrm{d}t$$ Then which of the following is correct: (A) $5<f(\sqrt 2)<6$ (B) $2<f(\sqrt 2)<3$ (C) $3<f(\sqrt 2)<4$ (D) $4<f(\sqrt 2)<5$ My attempts so far: Taking derivative of $f(x)$ we get $$f'(x)=x.e^{\frac{x^2}{2}}+x.f(x)$$ $$\frac{f'(x)}{x}-e^{\frac{x^2}{2}}=f(x)$$ On solving the differential equation we get $$f(x)=\left(C+\frac{x^2}{2}\right)e^{\frac{x^2}{2}}$$ And putting $x=\sqrt 2$ we get $f(\sqrt 2)=(C+1)e$ but I can't figure out the value of $C$ . Other attempts include writing $f(x)$ in terms of its derivative like above and putting it inside the integral, but upon solving it simply yields $f(x)$ . I also tried finding $f(2)$ and $f(1)$ as $\sqrt 2$ lies between 1 and 2 and tried finding their difference to see if it yields any insight. $$f(1)= \sqrt e + \int_0^1tf(t)dt $$ $$f(2)= e^2 + \int_0^2tf(t)dt $$ $$ e^2 +\int_0^1tf(t)dt+ \int_1^2tf(t)dt= e^2 +\int_0^1tf(t)dt+ \int_0^1(t-1)f(t-1)dt$$ Subtracting both these equations yields: $$f(2)-f(1)=e^2- \sqrt e + \int_0^1 (t-1)f(t-1)$$ I am at a loss on how to proceed further with this problem, any hints/ insights would be really appreciated. Edit: From comment of @Annebauval $f(0)=C=1$ and putting it in solution of differential equation we get $f(\sqrt 2)=2e \approx 5.43\,$ hence the correct answer is (A) option.","Let be a continuous function satisfying Then which of the following is correct: (A) (B) (C) (D) My attempts so far: Taking derivative of we get On solving the differential equation we get And putting we get but I can't figure out the value of . Other attempts include writing in terms of its derivative like above and putting it inside the integral, but upon solving it simply yields . I also tried finding and as lies between 1 and 2 and tried finding their difference to see if it yields any insight. Subtracting both these equations yields: I am at a loss on how to proceed further with this problem, any hints/ insights would be really appreciated. Edit: From comment of @Annebauval and putting it in solution of differential equation we get hence the correct answer is (A) option.","f:\mathbb{R}\rightarrow\mathbb{R} f(x)=e^{\frac{x^2}{2}}+\int_0^x tf(t)\mathrm{d}t 5<f(\sqrt 2)<6 2<f(\sqrt 2)<3 3<f(\sqrt 2)<4 4<f(\sqrt 2)<5 f(x) f'(x)=x.e^{\frac{x^2}{2}}+x.f(x) \frac{f'(x)}{x}-e^{\frac{x^2}{2}}=f(x) f(x)=\left(C+\frac{x^2}{2}\right)e^{\frac{x^2}{2}} x=\sqrt 2 f(\sqrt 2)=(C+1)e C f(x) f(x) f(2) f(1) \sqrt 2 f(1)= \sqrt e + \int_0^1tf(t)dt  f(2)= e^2 + \int_0^2tf(t)dt   e^2 +\int_0^1tf(t)dt+ \int_1^2tf(t)dt= e^2 +\int_0^1tf(t)dt+ \int_0^1(t-1)f(t-1)dt f(2)-f(1)=e^2- \sqrt e + \int_0^1 (t-1)f(t-1) f(0)=C=1 f(\sqrt 2)=2e \approx 5.43\,","['integration', 'ordinary-differential-equations']"
73,Computing a limit on the unit sphere: Riemann Lebesgue?,Computing a limit on the unit sphere: Riemann Lebesgue?,,"Let $u\in L^1(\mathbb{S}^{d-1})$ . I want to show that \begin{align*} \lim_{|\xi|\to \infty} \int_{\mathbb{S}^{d-1}}(1-\cos(\xi\cdot w))u(w)d \sigma_{d-1}(w) = \int_{\mathbb{S}^{d-1}}u(w)d \sigma_{d-1}(w).  \end{align*} Basically, the question can be reduced into showing that \begin{align*} \lim_{|\xi|\to \infty} \int_{\mathbb{S}^{d-1}}\cos(\xi\cdot w)u(w)d \sigma_{d-1}(w) = 0.  \end{align*} This looks like a Riemann-Lebesgue lemma. But I don't know how to tackle it. I intuitively guessed this from the classical Riemann-Lebesgue Lemma which infers that \begin{align*} \lim_{|\xi|\to \infty} \int_{B_1(0)}(1-\cos(|\xi| z\cdot x))u(x)d x = \int_{B_1(0)}u(x)dx\quad \text{for fixed $z\in \Bbb R^d$}.  \end{align*} More generally, if $f$ is $T^d$ -periodic, then $f_\lambda(x)= f(\lambda x)$ weakly converge in $L^p$ to its mean value as $\lambda\to\infty$ that is $$f_\lambda \rightharpoonup \bar f,\quad \quad \bar f=\frac{1}{T^d}\int_{[0,T]^d}f(x) dx.$$ Is there any good reference for this type of limit? Any help is welcome","Let . I want to show that Basically, the question can be reduced into showing that This looks like a Riemann-Lebesgue lemma. But I don't know how to tackle it. I intuitively guessed this from the classical Riemann-Lebesgue Lemma which infers that More generally, if is -periodic, then weakly converge in to its mean value as that is Is there any good reference for this type of limit? Any help is welcome","u\in L^1(\mathbb{S}^{d-1}) \begin{align*}
\lim_{|\xi|\to \infty}
\int_{\mathbb{S}^{d-1}}(1-\cos(\xi\cdot w))u(w)d \sigma_{d-1}(w)
= \int_{\mathbb{S}^{d-1}}u(w)d \sigma_{d-1}(w). 
\end{align*} \begin{align*}
\lim_{|\xi|\to \infty}
\int_{\mathbb{S}^{d-1}}\cos(\xi\cdot w)u(w)d \sigma_{d-1}(w)
= 0. 
\end{align*} \begin{align*}
\lim_{|\xi|\to \infty}
\int_{B_1(0)}(1-\cos(|\xi| z\cdot x))u(x)d x
= \int_{B_1(0)}u(x)dx\quad \text{for fixed z\in \Bbb R^d}. 
\end{align*} f T^d f_\lambda(x)= f(\lambda x) L^p \lambda\to\infty f_\lambda \rightharpoonup \bar f,\quad \quad \bar f=\frac{1}{T^d}\int_{[0,T]^d}f(x) dx.","['real-analysis', 'integration', 'analysis', 'fourier-analysis', 'harmonic-analysis']"
74,An orthonormal basis of $L^{2}(\mathbb{R}^{n})$ which is pointwise in $\ell^{2}(\mathbb{N})$?,An orthonormal basis of  which is pointwise in ?,L^{2}(\mathbb{R}^{n}) \ell^{2}(\mathbb{N}),"Does there exist an orthonormal basis of the Hilbert space $L^{2}(\mathbb{R}^{d})$ , say $(e_{n})_{n=1}^{\infty}$ , such that all elements $e_n\in L^{2}(\mathbb{R}^{d})\cap C^{0}(\mathbb{R}^{d})$ and such that for every $x\in\mathbb{R}^{d}$ , the sequence $(e_{n}(x))_{n=1}^{\infty}\subset \mathbb{C}$ is in $\ell^{2}(\mathbb{N})$ , i.e. such that the sum $$\sum_{n=1}^{\infty}|e_{n}(x)|^{2}$$ is finite? I was thinking about the case $d=1$ , and using the basis of $L^{2}(\mathbb{R})$ constructed from the Hermite polynomials, but I don't get enough decay to make the series converge.","Does there exist an orthonormal basis of the Hilbert space , say , such that all elements and such that for every , the sequence is in , i.e. such that the sum is finite? I was thinking about the case , and using the basis of constructed from the Hermite polynomials, but I don't get enough decay to make the series converge.",L^{2}(\mathbb{R}^{d}) (e_{n})_{n=1}^{\infty} e_n\in L^{2}(\mathbb{R}^{d})\cap C^{0}(\mathbb{R}^{d}) x\in\mathbb{R}^{d} (e_{n}(x))_{n=1}^{\infty}\subset \mathbb{C} \ell^{2}(\mathbb{N}) \sum_{n=1}^{\infty}|e_{n}(x)|^{2} d=1 L^{2}(\mathbb{R}),"['real-analysis', 'integration', 'hilbert-spaces', 'orthogonality']"
75,A generalization of conditional expectation to non-integrable random variables,A generalization of conditional expectation to non-integrable random variables,,"I'm reading about conditional expectations from Achim Klenke's Probability Theory: A Comprehensive Course , which defines conditional expectations for integrable random variables $X$ with respect to a $\sigma$ -algebra $\mathcal F$ as the unique (a.s.) $\mathcal F$ -measurable random variable $Y$ for which $\mathbb E[X\mathbb 1_A] = \mathbb E[Y\mathbb 1_A]$ for all $A \in \mathcal F$ . The following remark is made to generalize this definition to some non-integrable random variables: Let $X : \Omega \to \mathbb R$ be a random variable such that $X^- \in \mathcal L^1(\mathbb P)$ . We can define the conditional expectation as the monotone limit $$ \mathbb E[X\,|\,\mathcal F] = \lim_{n \to \infty} \mathbb E[X_n\,|\,\mathcal F] $$ where $-X^- \leq X_1$ and $X_n \uparrow X$ . Due to the monotonicity of the conditional expectation, it is easy to show that the limit does not depend on the choice of the sequence $(X_n)$ and that it fulfills the conditions of [the definition of conditional convergence]. (Presumably we want $(X_n) \subset \mathcal L^1(\mathbb P)$ to avoid circular definitions.) My question: Why do we need $-X^- \leq X_1$ ? It's not hard to verify these claims. By monotonicity of conditional expectation, we get that $\mathbb E[X_n\,|\,\mathcal F] \uparrow \mathbb E[X\,|\,\mathcal F]$ (this limit may be infinite). So for any $A \in \mathcal F$ , by the Beppo-Levi monotone convergence theorem, since the $\mathbb E[X_n\,|\,\mathcal F]$ are integrable, $$ \mathbb E[\mathbb E[X\,|\,\mathcal F]\mathbb 1_A] = \mathbb E\left[\lim_{n \to \infty} \mathbb E[X_n\,|\,\mathcal F]\mathbb 1_A\right] = \lim_{n \to \infty} \mathbb E\left[\mathbb E[X_n\,|\,\mathcal F]\mathbb 1_A\right] = \lim_{n \to \infty} \mathbb E[X_n\mathbb 1_A] = \mathbb E[X\mathbb 1_A]. $$ If $(\tilde X_n)$ is another sequence with $\tilde X_n \uparrow X$ and $-X^- \leq \tilde X_1$ , letting $Y = \lim \mathbb E[X_n \,|\,\mathcal F]$ and $\tilde Y = \lim\mathbb E[\tilde X_n\,|\,\mathcal F]$ , then both $Y$ and $\tilde Y$ are $\mathcal F$ -measurable (as a limit of $\mathcal F$ -measurable functions), and this calculation shows $\mathbb E[Y\mathbb 1_A] = \mathbb E[\tilde Y \mathbb 1_A]$ for every $A \in \mathcal F$ . It follows that $Y = \tilde Y$ . I can see that we'd want $X^- \in \mathcal L^1(\mathbb P)$ because otherwise we can't have that both $(X_n) \in \mathcal L^1(\mathbb P)$ and $X_n \uparrow X$ . But I don't see why we need $-X^- \leq X_1$ . In fact this seems contradictory if we require $X_n \uparrow X$ . Am I missing something?","I'm reading about conditional expectations from Achim Klenke's Probability Theory: A Comprehensive Course , which defines conditional expectations for integrable random variables with respect to a -algebra as the unique (a.s.) -measurable random variable for which for all . The following remark is made to generalize this definition to some non-integrable random variables: Let be a random variable such that . We can define the conditional expectation as the monotone limit where and . Due to the monotonicity of the conditional expectation, it is easy to show that the limit does not depend on the choice of the sequence and that it fulfills the conditions of [the definition of conditional convergence]. (Presumably we want to avoid circular definitions.) My question: Why do we need ? It's not hard to verify these claims. By monotonicity of conditional expectation, we get that (this limit may be infinite). So for any , by the Beppo-Levi monotone convergence theorem, since the are integrable, If is another sequence with and , letting and , then both and are -measurable (as a limit of -measurable functions), and this calculation shows for every . It follows that . I can see that we'd want because otherwise we can't have that both and . But I don't see why we need . In fact this seems contradictory if we require . Am I missing something?","X \sigma \mathcal F \mathcal F Y \mathbb E[X\mathbb 1_A] = \mathbb E[Y\mathbb 1_A] A \in \mathcal F X : \Omega \to \mathbb R X^- \in \mathcal L^1(\mathbb P) 
\mathbb E[X\,|\,\mathcal F] = \lim_{n \to \infty} \mathbb E[X_n\,|\,\mathcal F]
 -X^- \leq X_1 X_n \uparrow X (X_n) (X_n) \subset \mathcal L^1(\mathbb P) -X^- \leq X_1 \mathbb E[X_n\,|\,\mathcal F] \uparrow \mathbb E[X\,|\,\mathcal F] A \in \mathcal F \mathbb E[X_n\,|\,\mathcal F] 
\mathbb E[\mathbb E[X\,|\,\mathcal F]\mathbb 1_A] = \mathbb E\left[\lim_{n \to \infty} \mathbb E[X_n\,|\,\mathcal F]\mathbb 1_A\right] = \lim_{n \to \infty} \mathbb E\left[\mathbb E[X_n\,|\,\mathcal F]\mathbb 1_A\right] = \lim_{n \to \infty} \mathbb E[X_n\mathbb 1_A] = \mathbb E[X\mathbb 1_A].
 (\tilde X_n) \tilde X_n \uparrow X -X^- \leq \tilde X_1 Y = \lim \mathbb E[X_n \,|\,\mathcal F] \tilde Y = \lim\mathbb E[\tilde X_n\,|\,\mathcal F] Y \tilde Y \mathcal F \mathcal F \mathbb E[Y\mathbb 1_A] = \mathbb E[\tilde Y \mathbb 1_A] A \in \mathcal F Y = \tilde Y X^- \in \mathcal L^1(\mathbb P) (X_n) \in \mathcal L^1(\mathbb P) X_n \uparrow X -X^- \leq X_1 X_n \uparrow X","['integration', 'probability-theory', 'conditional-probability', 'conditional-expectation']"
76,Evaluate this double Integral in polar coordinates.,Evaluate this double Integral in polar coordinates.,,"$$ \iint y^2(a^2-x^2)^{0.5}dxdy $$ over $x^2+y^2\le a^2$ I have evaluated this in $x-y$ plane and got $32a^5/45$ . Please help in evaluating the same in polar coordinates. Ive tried putting $x=r\cos\theta$ and $y=r\sin\theta$ and After considering the Jacobian I am getting this expression $$ \int\limits_0^a\int\limits_0^{2π}r^3\sin^2θ(a^2-r^2cos^2θ)^{0.5}\,drdθ $$ Please help me evaluate this.",over I have evaluated this in plane and got . Please help in evaluating the same in polar coordinates. Ive tried putting and and After considering the Jacobian I am getting this expression Please help me evaluate this.," \iint y^2(a^2-x^2)^{0.5}dxdy  x^2+y^2\le a^2 x-y 32a^5/45 x=r\cos\theta y=r\sin\theta  \int\limits_0^a\int\limits_0^{2π}r^3\sin^2θ(a^2-r^2cos^2θ)^{0.5}\,drdθ ","['integration', 'multivariable-calculus', 'definite-integrals']"
77,"Integrating $\int\ln^e(x)dx$, constant wrong?","Integrating , constant wrong?",\int\ln^e(x)dx,"I am practicing to integrate with the incomplete gamma function. As such, I want to integrate $$\int\ln^e(x)dx$$ I use the following substitutions $$u=\ln(x)\implies \int u^e e^u du$$ $$v=-u\implies \int(-v)^e e^{-v}\cdot -dv$$ Now, we can convert this to a gamma function $$\int(-v)^e e^{-v}\cdot -dv = - \int(-1)^e v^e e^{-v} dv= -(-1)^e\int v^{(1+e)-1} e^{-v} dv = -(-1)^e\cdot -\Gamma(1+e, -\ln(x)) $$ which simplifies to $$(-1)^e\cdot \Gamma(1+e, -\ln(x)) +C$$ This is wrong though, and wolfram alpha gives me an answer of $${\color{red}{(-1)^{-e}}}\cdot \Gamma(1+e, -\ln(x)) +C$$ Something clearly went wrong here (and here , for that matter since I somehow also have a missing negative from the power?) and I'm not exactly sure what went wrong. I conjecture that perhaps splitting $(-v)^e = (-1)^e v^e$ was incorrect since the interior is negative, but I am not sure what to do otherwise with such a term. Can anyone enlighten me as to what my mistake is and how I would properly integrate this function? Thanks Edit : Okay, differentiating the results seem to provide interesting results. Differentiating my own result on wolfram alpha gives $$(-1)^e (-\ln(x))^e$$ which equals the initial function if i combine the powers, while the negative power does not work. I find this odd. I again conjecture that since the inner parts of the power functions are negative, I violated this rule when integrating and violating  the rule again here reverts it. I'm still not sure what to do with the original integral though.","I am practicing to integrate with the incomplete gamma function. As such, I want to integrate I use the following substitutions Now, we can convert this to a gamma function which simplifies to This is wrong though, and wolfram alpha gives me an answer of Something clearly went wrong here (and here , for that matter since I somehow also have a missing negative from the power?) and I'm not exactly sure what went wrong. I conjecture that perhaps splitting was incorrect since the interior is negative, but I am not sure what to do otherwise with such a term. Can anyone enlighten me as to what my mistake is and how I would properly integrate this function? Thanks Edit : Okay, differentiating the results seem to provide interesting results. Differentiating my own result on wolfram alpha gives which equals the initial function if i combine the powers, while the negative power does not work. I find this odd. I again conjecture that since the inner parts of the power functions are negative, I violated this rule when integrating and violating  the rule again here reverts it. I'm still not sure what to do with the original integral though.","\int\ln^e(x)dx u=\ln(x)\implies \int u^e e^u du v=-u\implies \int(-v)^e e^{-v}\cdot -dv \int(-v)^e e^{-v}\cdot -dv = - \int(-1)^e v^e e^{-v} dv= -(-1)^e\int v^{(1+e)-1} e^{-v} dv = -(-1)^e\cdot -\Gamma(1+e, -\ln(x))  (-1)^e\cdot \Gamma(1+e, -\ln(x)) +C {\color{red}{(-1)^{-e}}}\cdot \Gamma(1+e, -\ln(x)) +C (-v)^e = (-1)^e v^e (-1)^e (-\ln(x))^e","['integration', 'indefinite-integrals', 'exponentiation', 'gamma-function']"
78,Show that $\lVert Tf \rVert_{L^2} \leq \sqrt{ab} \lVert f \rVert_{L^2}$,Show that,\lVert Tf \rVert_{L^2} \leq \sqrt{ab} \lVert f \rVert_{L^2},"Suppose $Q(x,y): \Bbb R \times \Bbb R \to [0,\infty)$ is measurable, and $\int_{\Bbb R}Q(x,y) dy \leq a$ for all $x \in \Bbb R$ and $\int_{\Bbb R}Q(x,y) dx \leq b$ for all $y \in \Bbb R$ . For $f(x)$ nonnegative and measurable, define $Tf(x) := \int_{\Bbb R}Q(x,y)f(y) dy$ . Show that $\lVert Tf \rVert_{L^2} \leq \sqrt{ab} \lVert f \rVert_{L^2}$ . I get that $$\lVert Tf \rVert_{L^2}^2 = \int_{\Bbb R}\left(\int_{\Bbb R}Q(x,y)f(y) dy\right)^2 dx \leq  \int_{\Bbb R} \left( \int_{\Bbb R}Q^2(x,y) dy \int_{\Bbb R} f^2(y) dy \right) dx$$ by Hölder's inequality. Not sure what to do next.","Suppose is measurable, and for all and for all . For nonnegative and measurable, define . Show that . I get that by Hölder's inequality. Not sure what to do next.","Q(x,y): \Bbb R \times \Bbb R \to [0,\infty) \int_{\Bbb R}Q(x,y) dy \leq a x \in \Bbb R \int_{\Bbb R}Q(x,y) dx \leq b y \in \Bbb R f(x) Tf(x) := \int_{\Bbb R}Q(x,y)f(y) dy \lVert Tf \rVert_{L^2} \leq \sqrt{ab} \lVert f \rVert_{L^2} \lVert Tf \rVert_{L^2}^2 = \int_{\Bbb R}\left(\int_{\Bbb R}Q(x,y)f(y) dy\right)^2 dx \leq  \int_{\Bbb R} \left( \int_{\Bbb R}Q^2(x,y) dy \int_{\Bbb R} f^2(y) dy \right) dx","['real-analysis', 'integration', 'inequality', 'lp-spaces']"
79,How to evaluate double integrals of a surface over a specific region?,How to evaluate double integrals of a surface over a specific region?,,"I found this exercise while exercising for the exam: Let $T$ $\subset$ $R^2$ be the triangle with these vertices $(0,0), (2,0), (0,1)$ and let $\Omega$ be the surface defined like this: $\Omega$ = { $(x,y,z) \in R^3 : z^2 - x^2 - y^2 = 0, z > 0, (x,y) \in T$ } Evaluate $\iint_{\Omega}x^2 y dS $ I'm having a hard time solving it because it confounds me... I can't seem to ""visualize"" the situation. What's exactly the role of the triangular region, where am I going to have to use that region when solving the integral? Could you help me visualize the problem in some way?","I found this exercise while exercising for the exam: Let be the triangle with these vertices and let be the surface defined like this: = { } Evaluate I'm having a hard time solving it because it confounds me... I can't seem to ""visualize"" the situation. What's exactly the role of the triangular region, where am I going to have to use that region when solving the integral? Could you help me visualize the problem in some way?","T \subset R^2 (0,0), (2,0), (0,1) \Omega \Omega (x,y,z) \in R^3 : z^2 - x^2 - y^2 = 0, z > 0, (x,y) \in T \iint_{\Omega}x^2 y dS ","['integration', 'multivariable-calculus', 'surface-integrals']"
80,On bounding an integral from below.,On bounding an integral from below.,,"I am trying to read Exploring the toolkit of Jean Bourgain , a beautiful article by Terrence Tao, that can be found here . At page 5 Tao considers the integral $$ \int_{|\xi|\le \delta/ t_j}| \hat{1}_B(\xi)  |^2 \hat{\sigma}(t_j\xi) d \xi   \tag{1}  $$ where $0< \delta= \delta(\epsilon) \le 1/2$ is a small quantity depending on $0<\epsilon< 1/2$ to be chosen later, $B \subset [-1,1]^2$ , $0<t_j \le 1$ , $\hat{1}_B$ is the Fourier transform of the indicator function $1_B$ , i.e., $$  \hat{1}_B(\xi) = \int_{\mathbb{R}^d} 1_B(x) e^{2\pi i x \xi} dx , $$ and $\hat{\sigma}(\xi) = \int_{S^1} e^{-2\pi i \omega \xi} d \sigma( \omega) $ is the Fourier transform of the surface measure $d \sigma$ on the unit circle $S^1$ . Tao states that, for $\delta$ small enough the factor $\hat{\sigma}(t_j\xi)$ is close to $1$ and thus it is not difficult to show that the integral in $(1)$ is approximately $\gtrsim|B|$ , thus $$ \int_{|\xi|\le \delta/ t_j}| \hat{1}_B(\xi)  |^2 \hat{\sigma}(t_j\xi) d \xi  \gtrsim |B| \ge \epsilon^2  . $$ How does one rigorously show this?","I am trying to read Exploring the toolkit of Jean Bourgain , a beautiful article by Terrence Tao, that can be found here . At page 5 Tao considers the integral where is a small quantity depending on to be chosen later, , , is the Fourier transform of the indicator function , i.e., and is the Fourier transform of the surface measure on the unit circle . Tao states that, for small enough the factor is close to and thus it is not difficult to show that the integral in is approximately , thus How does one rigorously show this?"," \int_{|\xi|\le \delta/ t_j}| \hat{1}_B(\xi)  |^2 \hat{\sigma}(t_j\xi) d \xi   \tag{1}   0< \delta= \delta(\epsilon) \le 1/2 0<\epsilon< 1/2 B \subset [-1,1]^2 0<t_j \le 1 \hat{1}_B 1_B   \hat{1}_B(\xi) = \int_{\mathbb{R}^d} 1_B(x) e^{2\pi i x \xi} dx ,  \hat{\sigma}(\xi) = \int_{S^1} e^{-2\pi i \omega \xi} d \sigma( \omega)  d \sigma S^1 \delta \hat{\sigma}(t_j\xi) 1 (1) \gtrsim|B|  \int_{|\xi|\le \delta/ t_j}| \hat{1}_B(\xi)  |^2 \hat{\sigma}(t_j\xi) d \xi  \gtrsim |B| \ge \epsilon^2  . ","['real-analysis', 'integration', 'fourier-analysis', 'improper-integrals']"
81,"Why is $\hat f(\xi)/\xi\in L^1(\mathbb R)$ when $f\in L^1$ is odd,$\hat f'(0)$ exists, and $\hat f(\xi)$ always has the same sign as $\xi$?","Why is  when  is odd, exists, and  always has the same sign as ?",\hat f(\xi)/\xi\in L^1(\mathbb R) f\in L^1 \hat f'(0) \hat f(\xi) \xi,"I need to prove: If $f \in L^1(\mathbb{R})$ is an odd function such that its Fourier Transform $\hat{f}$ is differentiable at $\xi = 0$ and $\hat{f} \geq 0$ when $\xi \geq 0$ , then $\hat{f}(\xi)/\xi \in L^1(\mathbb{R})$ . My work so far: I have established (using only $f$ being odd) that we have $$\Gamma = \sup_{\alpha \geq 1} \left|\int_1^\alpha \frac{\hat{f}(\xi)}{\xi} \, d\xi\right| < \infty.$$ Now, $$\left\|\frac{\hat{f}(\xi)}{\xi}\right\| = \int_{-\infty}^{\infty} \left|\frac{\hat{f}(\xi)}{\xi}\right| \, d\xi= 2 \int_0^\infty \frac{\hat{f}(\xi)}{\xi} \, d\xi \\= 2 \left(\int_0^1  \frac{\hat{f}(\xi)}{\xi} \, d\xi + \int_1^\infty  \frac{\hat{f}(\xi)}{\xi} \, d\xi\right) \leq 2\int_0^1  \frac{\hat{f}(\xi)}{\xi} \, d\xi+2\Gamma.$$ I am unsure how to proceed from here. I have not made use of assumption that $\hat{f}'(0)$ exists, but I am not sure how to use it. As a follow-up: seems like a lot of questions on here have talked a lot about functions being odd and considering the Fourier Transform. Is there a particular reason, or is the theory for even functions simplified?","I need to prove: If is an odd function such that its Fourier Transform is differentiable at and when , then . My work so far: I have established (using only being odd) that we have Now, I am unsure how to proceed from here. I have not made use of assumption that exists, but I am not sure how to use it. As a follow-up: seems like a lot of questions on here have talked a lot about functions being odd and considering the Fourier Transform. Is there a particular reason, or is the theory for even functions simplified?","f \in L^1(\mathbb{R}) \hat{f} \xi = 0 \hat{f} \geq 0 \xi \geq 0 \hat{f}(\xi)/\xi \in L^1(\mathbb{R}) f \Gamma = \sup_{\alpha \geq 1} \left|\int_1^\alpha \frac{\hat{f}(\xi)}{\xi} \, d\xi\right| < \infty. \left\|\frac{\hat{f}(\xi)}{\xi}\right\| = \int_{-\infty}^{\infty} \left|\frac{\hat{f}(\xi)}{\xi}\right| \, d\xi= 2 \int_0^\infty \frac{\hat{f}(\xi)}{\xi} \, d\xi \\= 2 \left(\int_0^1  \frac{\hat{f}(\xi)}{\xi} \, d\xi + \int_1^\infty  \frac{\hat{f}(\xi)}{\xi} \, d\xi\right) \leq 2\int_0^1  \frac{\hat{f}(\xi)}{\xi} \, d\xi+2\Gamma. \hat{f}'(0)","['real-analysis', 'integration', 'fourier-analysis', 'fourier-transform', 'even-and-odd-functions']"
82,Is there a numerical method to solve the integral of a function containing a constant?,Is there a numerical method to solve the integral of a function containing a constant?,,"Is there a numerical method to solve the integral of a function containing a constant? Such as: $$\int_0^{\pi} x^2 \cos(tx) e^{a\cos(x)} dx , \qquad t\in\mathbb Z^+, a\in\mathbb R$$ While working on one of the statistical derivations, I encountered integrals as shown in the example, and I tried to solve them analytically, but I did not reach any result even after resorting to modified Bessel function. I do not have a method other than numerical methods, but I do not have enough experience in it.... I look forward to your experience.","Is there a numerical method to solve the integral of a function containing a constant? Such as: While working on one of the statistical derivations, I encountered integrals as shown in the example, and I tried to solve them analytically, but I did not reach any result even after resorting to modified Bessel function. I do not have a method other than numerical methods, but I do not have enough experience in it.... I look forward to your experience.","\int_0^{\pi} x^2 \cos(tx) e^{a\cos(x)} dx , \qquad t\in\mathbb Z^+, a\in\mathbb R","['integration', 'numerical-methods']"
83,Solve: $\int_a^b\frac{1}{x\sqrt{x^2-a^2}}\left(\frac{\cos(x)}{x}+\sin(x)\right)dx$,Solve:,\int_a^b\frac{1}{x\sqrt{x^2-a^2}}\left(\frac{\cos(x)}{x}+\sin(x)\right)dx,"I am trying to solve this integral $$\int_a^b\frac{1}{x\sqrt{x^2-a^2}}\left(\frac{\cos(x)}{x}+\sin(x)\right)dx.$$ I have tried some basic substitution and integration by parts, but beyond that can seem to solve find an analytical solution. I was able to solve it numerically for which an example solution is shown in the picture with the integral on the $y$ axis and $x$ on the $x$ axis. It looks like a Bessel or sinusoidal exponential to me.","I am trying to solve this integral I have tried some basic substitution and integration by parts, but beyond that can seem to solve find an analytical solution. I was able to solve it numerically for which an example solution is shown in the picture with the integral on the axis and on the axis. It looks like a Bessel or sinusoidal exponential to me.",\int_a^b\frac{1}{x\sqrt{x^2-a^2}}\left(\frac{\cos(x)}{x}+\sin(x)\right)dx. y x x,"['integration', 'definite-integrals']"
84,"$f(0,p)$ for $f(x,p) = \int \frac{\sin(2x)}{x} C_i(x+p) dx$",for,"f(0,p) f(x,p) = \int \frac{\sin(2x)}{x} C_i(x+p) dx","How do i find $f(0,p)$ for $$f(x,p) = \int \frac{\sin(2x)}{x} C_i(x+p) dx$$ $C_i(x)$ is Cosine Integral . Obviously, if I could solve the integral, I would have substituted $x$ with $0$ . But I don't know how to solve it. I wonder if there is a general technique for finding the value of this function at a particular point, even if I can't solve it generally for all values of $x$ . Ignore the constant of integration (the usual +C term for indefinite integrals)","How do i find for is Cosine Integral . Obviously, if I could solve the integral, I would have substituted with . But I don't know how to solve it. I wonder if there is a general technique for finding the value of this function at a particular point, even if I can't solve it generally for all values of . Ignore the constant of integration (the usual +C term for indefinite integrals)","f(0,p) f(x,p) = \int \frac{\sin(2x)}{x} C_i(x+p) dx C_i(x) x 0 x",['integration']
85,Problems mainly based on a composite function $f(f(x))={f(x)}^3$,Problems mainly based on a composite function,f(f(x))={f(x)}^3,"For $f(x)$ which is differentiable over all $\mathbb{R}$ , $f(x)$ meets four conditions (a) $f(4) < 1 $ (b) For all $\mathbb{R}$ , $f(f(x))={f(x)}^3$ (c) if $p < q$ , $0\le f(p) \le f(q)$ (d).  if $p < q$ , $f'(p) + \cfrac{3}{4}p \le f'(q) + \cfrac{3}{4}q$ for all $f(x)$ that meets above conditions, $M(x)$ is the function where $f(4)$ become largest number. (maximum) Find the value of $$\int_{-2}^{2} M(x) dx$$ Source: A Korean hs problem I was struggling to understand what (b) means, and I couldn't figure it out from the start. (detailed questions after some comments) I was mainly curious about the condition (b). Simply thought, $f(x)$ is $0$ , $1$ or $x^3$ But it is not likely, because of the condition (a) I think the problem wanted me to think about the domain and range of $f(x)$ But at that point, I wasn't able to move forward. I don't know how to connect that thought with other conditions.","For which is differentiable over all , meets four conditions (a) (b) For all , (c) if , (d).  if , for all that meets above conditions, is the function where become largest number. (maximum) Find the value of Source: A Korean hs problem I was struggling to understand what (b) means, and I couldn't figure it out from the start. (detailed questions after some comments) I was mainly curious about the condition (b). Simply thought, is , or But it is not likely, because of the condition (a) I think the problem wanted me to think about the domain and range of But at that point, I wasn't able to move forward. I don't know how to connect that thought with other conditions.",f(x) \mathbb{R} f(x) f(4) < 1  \mathbb{R} f(f(x))={f(x)}^3 p < q 0\le f(p) \le f(q) p < q f'(p) + \cfrac{3}{4}p \le f'(q) + \cfrac{3}{4}q f(x) M(x) f(4) \int_{-2}^{2} M(x) dx f(x) 0 1 x^3 f(x),"['integration', 'ordinary-differential-equations', 'functional-equations']"
86,Claim seems incorrect in 19.36b of Spivak's Calculus,Claim seems incorrect in 19.36b of Spivak's Calculus,,"In Spivak's Calculus chapter 19, problem 36 b there is the following claim to prove: Given $a_1, \dots, a_n$ and $b_1, \dots, b_n$ , with $\{b_n\}$ being nonincreasing and nonnegative,  and with $m \leq a_1 + a_2 + \dots + a_k \leq M $ for all $k <= n$ . Prove that $b_1 m \leq a_1 b_1 + \dots +a_n b_n \leq b_1 M$ , and in general: $b_k m \leq a_k b_k + \dots +a_n b_n \leq b_k M$ I managed to prove the first claim easily, but I struggled with the second, so I looked up the solution. The author simply applies the first result for $ a_k, \dots, a_n$ and $ b_k, \dots, b_n$ , and concludes that the inequality must hold. Except that from $m \leq a_1 + a_2 + \dots + a_n \leq M $ it does not necessarily follow that $m \leq a_k + \dots + a_n \leq M $ , so in my opinion the reasoning is incorrect. Furthermore, as a counterexample, if we consider $a_n = \frac{(-1)^{n+1}}{n^2}; b_n = 1$ with $m=0.75, M=1$ , it's easy to see, that with n=3 and k=2 the claim doesn't hold: $$ a_2 b_2 + a_3 b_3 = a_2 + a_3 =  -\frac{1}{4} + \frac{1}{9} = -0.13\dot{8} $$ $$ b_2 m = 0.75 \nleq -0.13\dot{8}  $$ Is my reasoning correct? Am I missing something?","In Spivak's Calculus chapter 19, problem 36 b there is the following claim to prove: Given and , with being nonincreasing and nonnegative,  and with for all . Prove that , and in general: I managed to prove the first claim easily, but I struggled with the second, so I looked up the solution. The author simply applies the first result for and , and concludes that the inequality must hold. Except that from it does not necessarily follow that , so in my opinion the reasoning is incorrect. Furthermore, as a counterexample, if we consider with , it's easy to see, that with n=3 and k=2 the claim doesn't hold: Is my reasoning correct? Am I missing something?","a_1, \dots, a_n b_1, \dots, b_n \{b_n\} m \leq a_1 + a_2 + \dots + a_k \leq M  k <= n b_1 m \leq a_1 b_1 + \dots +a_n b_n \leq b_1 M b_k m \leq a_k b_k + \dots +a_n b_n \leq b_k M  a_k, \dots, a_n  b_k, \dots, b_n m \leq a_1 + a_2 + \dots + a_n \leq M  m \leq a_k + \dots + a_n \leq M  a_n = \frac{(-1)^{n+1}}{n^2}; b_n = 1 m=0.75, M=1  a_2 b_2 + a_3 b_3 = a_2 + a_3 =  -\frac{1}{4} + \frac{1}{9} = -0.13\dot{8}   b_2 m = 0.75 \nleq -0.13\dot{8}  ","['calculus', 'integration', 'sequences-and-series']"
87,"Limit of the integral of a function in $[0,x]$ with de l'Hopital",Limit of the integral of a function in  with de l'Hopital,"[0,x]","I want to compute the following limit: $$\lim_{x\to 0}\frac{\int_0^x {e^{t^5+1}-5} dt }{x}$$ I have thought to use the de l'Hopital rule, but in order to be able to apply this result I have to verify: if the limit gives us an indeterminate form of kind $\frac{0}{0}$ or $\frac{\infty}{\infty}$ if the ratio of the derivative of the functions at the numerator and denominator exists. I want to prove $\textbf{1.}$ Surely the limit of the denominator gives me $0$ , so necessarily I want that the numerator goes to $0$ . $\textbf{First way:}$ I have thought that trivially, since when $x\to 0$ I would have $\lim_{x\to 0}\int_0^x {e^{t^5+1}-5} dt \to \int_0^0 {e^{t^5+1}-5} dt $ and for the fact that in this last integral the upper and lower limits of the integral coincide and they are equal to 0, I have that the limit is $0$ (I am using the fact that in general $\int_a^a f(t)dt=0$ ). $\color{red}{\text{First doubt:}}$ $\textbf{I am not conviced of this fact...if my idea is right this  would imply that}$ $\textbf{ in general whatever function of kind  $\int_0^x f(t) dt$ goes to $0$ when $x\to 0$}$ . This could be a conseguence of the fact that whatever function $G(x)=\int_0^x f(t) dt$ is continous and so $\lim_{x\to 0}G(x)=G(0)=0$ ...am I right or I am failing somewhere? Alternatively I have also thought two different ways to prove that the limit of the numerator is $0$ . $\textbf{First alternative way:}$ The function $f(t)=e^{t^5+1}-5$ is continous and differentiable $\forall t\in \mathbb{R}$ so I can apply the mean value integral theorem in whatever $[0,x]$ with $x>0$ and so: $$\exists \xi\in[0,x]: \int_{0}^x e^{t^5+1}-5=f(\xi)\cdot (x-0)=(e^{\xi^5+1}-5)\cdot x$$ So $\lim_{x\to 0}\int_{0}^x (e^{t^5+1}-5)=\lim_{x\to 0}(e^{\xi^5+1}\-5)cdot x=0$ (remembering that when $x\to 0$ also $\xi\to 0$ ) $\textbf{Second alternative way:}$ The function $f(t)=e^{t^5+1}-5$ is continous $\forall t$ and in particular for $t=0$ so $\forall a>0$ I can say: $$\text{in }[0,a] \exists m,M\in\mathbb{R}: m\leq f(t)\leq M$$ This holds from Weierstrass because in $[0,a]$ I am in a neighbourhood of $0$ , and in $0$ the function is continous, and since I want to understand what happens near $0$ (because I consider $x\to 0$ ) I can say: $$0=\lim_{x\to 0}mx=\lim_{x\to 0}\int_0^xmdt\leq\lim_{x\to 0}\int_0^x {e^{t^5+1}-5} dt \leq \lim_{x\to 0}\int_0^xMdt=\lim_{x\to 0}Mx=0$$ $\color{red}{\text{Second doubt:}}$ I am not so convinced of these tw different ways of proving the limit. Do you thinks they are correct? If yes what is in your opinion the best way to use (the first or one of the last alternative)?","I want to compute the following limit: I have thought to use the de l'Hopital rule, but in order to be able to apply this result I have to verify: if the limit gives us an indeterminate form of kind or if the ratio of the derivative of the functions at the numerator and denominator exists. I want to prove Surely the limit of the denominator gives me , so necessarily I want that the numerator goes to . I have thought that trivially, since when I would have and for the fact that in this last integral the upper and lower limits of the integral coincide and they are equal to 0, I have that the limit is (I am using the fact that in general ). . This could be a conseguence of the fact that whatever function is continous and so ...am I right or I am failing somewhere? Alternatively I have also thought two different ways to prove that the limit of the numerator is . The function is continous and differentiable so I can apply the mean value integral theorem in whatever with and so: So (remembering that when also ) The function is continous and in particular for so I can say: This holds from Weierstrass because in I am in a neighbourhood of , and in the function is continous, and since I want to understand what happens near (because I consider ) I can say: I am not so convinced of these tw different ways of proving the limit. Do you thinks they are correct? If yes what is in your opinion the best way to use (the first or one of the last alternative)?","\lim_{x\to 0}\frac{\int_0^x {e^{t^5+1}-5} dt }{x} \frac{0}{0} \frac{\infty}{\infty} \textbf{1.} 0 0 \textbf{First way:} x\to 0 \lim_{x\to 0}\int_0^x {e^{t^5+1}-5} dt \to \int_0^0 {e^{t^5+1}-5} dt  0 \int_a^a f(t)dt=0 \color{red}{\text{First doubt:}} \textbf{I am not conviced of this fact...if my idea is right this
 would imply that} \textbf{ in general whatever function of kind
 \int_0^x f(t) dt goes to 0 when x\to 0} G(x)=\int_0^x f(t) dt \lim_{x\to 0}G(x)=G(0)=0 0 \textbf{First alternative way:} f(t)=e^{t^5+1}-5 \forall t\in \mathbb{R} [0,x] x>0 \exists \xi\in[0,x]: \int_{0}^x e^{t^5+1}-5=f(\xi)\cdot (x-0)=(e^{\xi^5+1}-5)\cdot x \lim_{x\to 0}\int_{0}^x (e^{t^5+1}-5)=\lim_{x\to 0}(e^{\xi^5+1}\-5)cdot x=0 x\to 0 \xi\to 0 \textbf{Second alternative way:} f(t)=e^{t^5+1}-5 \forall t t=0 \forall a>0 \text{in }[0,a] \exists m,M\in\mathbb{R}: m\leq f(t)\leq M [0,a] 0 0 0 x\to 0 0=\lim_{x\to 0}mx=\lim_{x\to 0}\int_0^xmdt\leq\lim_{x\to 0}\int_0^x {e^{t^5+1}-5} dt \leq \lim_{x\to 0}\int_0^xMdt=\lim_{x\to 0}Mx=0 \color{red}{\text{Second doubt:}}","['real-analysis', 'integration', 'limits', 'continuity', 'solution-verification']"
88,Why is this integration correct? Is it a $u$-substitution?,Why is this integration correct? Is it a -substitution?,u,"I need help with equation $(4)$ in the following. I'm interested why it's mathematically correct to integrate both sides with different limits . Are there some extra steps which aren't explicit stated? Here the power of a wave is derived , starting with: $$ dK= \frac{1}{2} \mu v_y^2 \, dx \tag 1 $$ where $dm = \mu \, dx$ . ""Each mass element oif the string oscillates with a velocity:"" $$ v_y=\frac{\partial y(x,t)}{\partial t}= A\omega \cos (kx-\omega t) \tag 2 $$ So $$ dK= \frac{1}{2} A^2 \omega^2 \mu \cos^2(kx-\omega t) \, dx \tag 3 $$ ""This kinetic energy can be integrated over the wavelength to find the energy associated with each wavelength of the wave"", so at $t=0:$ \begin{align} \int_0^{K_\lambda} dK &= \frac{1}{2} A^2 \omega^2 \mu  \int_0^\lambda \cos^2(kx) \, dx \tag 4 \\ K_\lambda &= \frac{1}{4} A^2 \omega^2 \mu  \lambda \tag 5 \end{align} Update: I assume it's a u-substitution which isn't explicit stated. How is it done? I have $$ 	\int_0^{K_\lambda} dK 	= \frac{1}{2} A^2 \omega^2 \mu  \int_0^\lambda \cos^2(kx) \, dx \tag 6 	$$ and because of $dK$ on the left side (I assume?) I want to write the LHS in terms of $K$ . For simplicity I let $B=\frac{1}{2} A^2 \omega^2 \mu$ . Change of variable: \begin{align} K &= kx\\ \frac{1}{k} dK &= dx \end{align} New limits: \begin{align}  x=0: &\quad K=0 \\ x=\lambda: &\quad K=k\lambda \end{align} Now I can write $(6)$ as: \begin{align} \int_0^{K_\lambda} dK = B \int_0^{k\lambda} \frac{1}{k}\cos^2(K) \, dK \tag 7 \end{align} Is this the correct solution? The differential $dK$ appear now on both sides, but the limits are still different... how to proceed?","I need help with equation in the following. I'm interested why it's mathematically correct to integrate both sides with different limits . Are there some extra steps which aren't explicit stated? Here the power of a wave is derived , starting with: where . ""Each mass element oif the string oscillates with a velocity:"" So ""This kinetic energy can be integrated over the wavelength to find the energy associated with each wavelength of the wave"", so at Update: I assume it's a u-substitution which isn't explicit stated. How is it done? I have and because of on the left side (I assume?) I want to write the LHS in terms of . For simplicity I let . Change of variable: New limits: Now I can write as: Is this the correct solution? The differential appear now on both sides, but the limits are still different... how to proceed?","(4) 
dK= \frac{1}{2} \mu v_y^2 \, dx \tag 1
 dm = \mu \, dx 
v_y=\frac{\partial y(x,t)}{\partial t}= A\omega \cos (kx-\omega t) \tag 2
 
dK= \frac{1}{2} A^2 \omega^2 \mu \cos^2(kx-\omega t) \, dx \tag 3
 t=0: \begin{align}
\int_0^{K_\lambda} dK
&= \frac{1}{2} A^2 \omega^2 \mu  \int_0^\lambda \cos^2(kx) \, dx \tag 4
\\
K_\lambda
&= \frac{1}{4} A^2 \omega^2 \mu  \lambda \tag 5
\end{align} 
	\int_0^{K_\lambda} dK
	= \frac{1}{2} A^2 \omega^2 \mu  \int_0^\lambda \cos^2(kx) \, dx \tag 6
	 dK K B=\frac{1}{2} A^2 \omega^2 \mu \begin{align}
K &= kx\\
\frac{1}{k} dK &= dx
\end{align} \begin{align} 
x=0: &\quad K=0 \\
x=\lambda: &\quad K=k\lambda
\end{align} (6) \begin{align}
\int_0^{K_\lambda} dK
= B \int_0^{k\lambda} \frac{1}{k}\cos^2(K) \, dK \tag 7
\end{align} dK","['real-analysis', 'calculus', 'integration', 'physics']"
89,Asymptotics of an integral in the coupon collector's problem,Asymptotics of an integral in the coupon collector's problem,,"I am interested in asymptotics of the integral $$I(h,n)=\int_0^\infty t(u) e^{-un}du$$ as $h\to \infty$ ( $n$ is a fixed positive integer) where $t(u)$ is the functional inverse of the function $$u(t)=-\ln\left(1-e^{-t}\left(1+t+\frac{t^2}{2}+\dots+\frac{t^{h-1}}{(h-1)!}\right)\right). $$ This integral comes up as an expectation in the coupon collector's problem . Based on numerical evidence, it seems that $I(h,n)$ is nearly linear in $h$ . If someone could provide a quick derivation of the asymptotics of $I(h,n)$ as $h\to\infty$ , that would be great. Note that $1-e^{-t}\left(1+t+\frac{t^2}{2}+\dots+\frac{t^{h-1}}{(h-1)!}\right)$ increases from $0$ to $1$ for $t\in(0,\infty)$ , so this function is invertible.","I am interested in asymptotics of the integral as ( is a fixed positive integer) where is the functional inverse of the function This integral comes up as an expectation in the coupon collector's problem . Based on numerical evidence, it seems that is nearly linear in . If someone could provide a quick derivation of the asymptotics of as , that would be great. Note that increases from to for , so this function is invertible.","I(h,n)=\int_0^\infty t(u) e^{-un}du h\to \infty n t(u) u(t)=-\ln\left(1-e^{-t}\left(1+t+\frac{t^2}{2}+\dots+\frac{t^{h-1}}{(h-1)!}\right)\right).  I(h,n) h I(h,n) h\to\infty 1-e^{-t}\left(1+t+\frac{t^2}{2}+\dots+\frac{t^{h-1}}{(h-1)!}\right) 0 1 t\in(0,\infty)","['integration', 'asymptotics']"
90,Weak convergence in Sobolev Space: does this integral converge to $0$?,Weak convergence in Sobolev Space: does this integral converge to ?,0,"Let $\Omega$ be an open bounded domain in $\mathbb{R^N}$ and $A(x)\in L^{\infty}(\Omega)$ . Let $s\geq 1$ and $(u_n)_n$ be a sequence such that $$|u_n|^s u_n\rightharpoonup|u|^s u\quad\mbox{ in } W_0^{1,p}(\Omega).$$ If we suppose $u=0$ , it is true that $$\int_{\Omega} A(x) \nabla(|u_n|^s u_n) dx\to 0?$$ About me the answer is yes, I reasoned in this way. Since $|u_n|^s u_n\rightharpoonup|u|^s u$ in $W_0^{1, p}(\Omega)$ and $u=0$ , thus $|u_n|^s u_n\rightharpoonup 0$ in $L^p(\Omega)$ and $\nabla(|u_n|^s u_n)\rightharpoonup 0$ in $L^p(\Omega)$ . Moreover, since $1\in L^p(\Omega)$ and since $A(x)\in L^{\infty}(\Omega)$ , a constant $c\geq 0$ exists such that $$\int_{\Omega} |A(x)| \nabla(|u_n|^s u_n) dx\leq c \int_{\Omega} \nabla(|u_n|^s u_n) dx\to 0.$$ It is true or am I missing something? Could anyone please help? Thank you in advance!","Let be an open bounded domain in and . Let and be a sequence such that If we suppose , it is true that About me the answer is yes, I reasoned in this way. Since in and , thus in and in . Moreover, since and since , a constant exists such that It is true or am I missing something? Could anyone please help? Thank you in advance!","\Omega \mathbb{R^N} A(x)\in L^{\infty}(\Omega) s\geq 1 (u_n)_n |u_n|^s u_n\rightharpoonup|u|^s u\quad\mbox{ in } W_0^{1,p}(\Omega). u=0 \int_{\Omega} A(x) \nabla(|u_n|^s u_n) dx\to 0? |u_n|^s u_n\rightharpoonup|u|^s u W_0^{1, p}(\Omega) u=0 |u_n|^s u_n\rightharpoonup 0 L^p(\Omega) \nabla(|u_n|^s u_n)\rightharpoonup 0 L^p(\Omega) 1\in L^p(\Omega) A(x)\in L^{\infty}(\Omega) c\geq 0 \int_{\Omega} |A(x)| \nabla(|u_n|^s u_n) dx\leq c \int_{\Omega} \nabla(|u_n|^s u_n) dx\to 0.","['real-analysis', 'integration', 'functional-analysis', 'sobolev-spaces']"
91,Evaluare $I(y)=\int_0^1\frac{1}{y+\cos(x)}dx$. Hence determine $J(y)=\int_0^1\frac{1}{(y+\cos(x))^2}dx$,Evaluare . Hence determine,I(y)=\int_0^1\frac{1}{y+\cos(x)}dx J(y)=\int_0^1\frac{1}{(y+\cos(x))^2}dx,"Consider the following integral: $$I(y)=\int_0^1\frac{1}{y+\cos(x)}dx $$ with Weierstrasse substitution I showed that $$ I(y)=\frac{2}{\sqrt{y^2-1}}\arctan\left(\sqrt{\frac{{y-1}}{y+1}}\right). $$ It is this next part that I am not sure about: Hence detertemine $$J(y)=\int_0^1\frac{1}{(y+\cos(x))^2}.$$ My attempt: Since $I(y)\pm J(y)$ yields no simplication, the most obvious approach would be to rewrite $I(y)$ as $$I(y)=\int_0^1\frac{(y+\cos(x))}{(y+\cos(x))^2}=yJ(y)+\underbrace{\int_0^1\frac{cos(x)}{(y+\cos(x))^2}dx}_{K(y)}$$ Applyling Weierstrasse substitituion for $K(y)$ : $$K(y)=2\int_0^1\frac{(1-x^2)}{((y-1)x^2+(y+1))^2}dx=-2\int_0^1\frac{\frac{1}{y-1}((y-1)x^2+(y+1))-\frac{y+1}{y-1}-1}{((y-1)x^2+(y+1))^2}$$ $$=-2\left(\underbrace{\frac{1}{y-1}\int_0^1\frac{1}{(y-1)x^2+(y+1)}dx}_{\text{elementary integral}\to \arctan()}-\underbrace{\frac{2}{y-1}\int_0^1\frac{1}{((y-1)x^2+(y+1))^2}dx}_{\text{evaluated with }   \tan(u)=\sqrt{\frac{y-1}{y+1}}x}\right)$$ so what follows is quite elmenatary. However it seems to me that $K(y)$ is by no means simpler than $J(y)$ , (i.e. the same approach can be used for $J(y)$ but without having to use the result for $I(y)$ ) so this is clearly not the point of the question?","Consider the following integral: with Weierstrasse substitution I showed that It is this next part that I am not sure about: Hence detertemine My attempt: Since yields no simplication, the most obvious approach would be to rewrite as Applyling Weierstrasse substitituion for : so what follows is quite elmenatary. However it seems to me that is by no means simpler than , (i.e. the same approach can be used for but without having to use the result for ) so this is clearly not the point of the question?","I(y)=\int_0^1\frac{1}{y+\cos(x)}dx   I(y)=\frac{2}{\sqrt{y^2-1}}\arctan\left(\sqrt{\frac{{y-1}}{y+1}}\right).  J(y)=\int_0^1\frac{1}{(y+\cos(x))^2}. I(y)\pm J(y) I(y) I(y)=\int_0^1\frac{(y+\cos(x))}{(y+\cos(x))^2}=yJ(y)+\underbrace{\int_0^1\frac{cos(x)}{(y+\cos(x))^2}dx}_{K(y)} K(y) K(y)=2\int_0^1\frac{(1-x^2)}{((y-1)x^2+(y+1))^2}dx=-2\int_0^1\frac{\frac{1}{y-1}((y-1)x^2+(y+1))-\frac{y+1}{y-1}-1}{((y-1)x^2+(y+1))^2} =-2\left(\underbrace{\frac{1}{y-1}\int_0^1\frac{1}{(y-1)x^2+(y+1)}dx}_{\text{elementary integral}\to \arctan()}-\underbrace{\frac{2}{y-1}\int_0^1\frac{1}{((y-1)x^2+(y+1))^2}dx}_{\text{evaluated with } 
 \tan(u)=\sqrt{\frac{y-1}{y+1}}x}\right) K(y) J(y) J(y) I(y)","['calculus', 'integration', 'definite-integrals', 'substitution', 'trigonometric-integrals']"
92,"Residue theorem for $ I=\int_{-\infty}^{+\infty}\frac{e^{\mathrm{i}\,t\,z}}{(z-z_1)(z-z_2)} \, \mathrm{d}z$",Residue theorem for," I=\int_{-\infty}^{+\infty}\frac{e^{\mathrm{i}\,t\,z}}{(z-z_1)(z-z_2)} \, \mathrm{d}z","If I use the residue theorem to evaluate the integral $$ I(t)=\int_{-\infty}^{+\infty}\frac{e^{\mathrm{i}\,t\,z}}{(z-z_1)(z-z_2)} \, \mathrm{d}z$$ with $t>0$ , $\mathrm{Im}(z_1)>0$ and $\mathrm{Im}(z_2)<0$ , I would have thought to get $$ I(t)=2\,\pi\,\mathrm{i}\,\frac{e^{\,\mathrm{i}\,t\,z_1}}{z_1-z_2}$$ since only the pol in the upper half plane contributes to the integral. If I solve the integral with Mathematica 12.0 it evaluates to $$ I(t)=2\,\pi\,\mathrm{i}\,\frac{e^{\,\mathrm{i}\,t\,z_1}-e^{\,\mathrm{i}\,t\,z_2}}{z_1-z_2}$$ even though I set the correct assumptions on $z_1$ and $z_2$ and allowed for the calculatoin of the Cauchy principal value. Now I am wondering if I misunderstood the residue theorem or Mathematica evaluates the integral incorrectly.","If I use the residue theorem to evaluate the integral with , and , I would have thought to get since only the pol in the upper half plane contributes to the integral. If I solve the integral with Mathematica 12.0 it evaluates to even though I set the correct assumptions on and and allowed for the calculatoin of the Cauchy principal value. Now I am wondering if I misunderstood the residue theorem or Mathematica evaluates the integral incorrectly."," I(t)=\int_{-\infty}^{+\infty}\frac{e^{\mathrm{i}\,t\,z}}{(z-z_1)(z-z_2)} \, \mathrm{d}z t>0 \mathrm{Im}(z_1)>0 \mathrm{Im}(z_2)<0  I(t)=2\,\pi\,\mathrm{i}\,\frac{e^{\,\mathrm{i}\,t\,z_1}}{z_1-z_2}  I(t)=2\,\pi\,\mathrm{i}\,\frac{e^{\,\mathrm{i}\,t\,z_1}-e^{\,\mathrm{i}\,t\,z_2}}{z_1-z_2} z_1 z_2","['integration', 'exponential-function', 'improper-integrals', 'contour-integration', 'residue-calculus']"
93,What is $\lim_{N\to\infty}\frac{-2}{\pi}\sum_{n=1}^N \frac{(-1)^n}{n} \sin(n\frac{N\pi}{N+1})$?,What is ?,\lim_{N\to\infty}\frac{-2}{\pi}\sum_{n=1}^N \frac{(-1)^n}{n} \sin(n\frac{N\pi}{N+1}),"Here is what I have so far: $$\lim_{N\to\infty} f_N \left(\frac{N\pi}{N+1}\right)$$ $$f_N (x) = \frac{-2}{\pi}\sum_{n=1}^N \frac{(-1)^n}{n} \sin(nx)$$ $$\implies \lim_{N\to\infty} f_N \left( \frac{N\pi}{N+1}\right)=\lim_{N\to\infty}\frac{-2}{\pi}\sum_{n=1}^N \frac{(-1)^n}{n} \sin\left(n\frac{N\pi}{N+1}\right)$$ $$=\lim_{N\to\infty}\frac{-2}{\pi}\left(-\sin\left(\frac{N\pi}{N+1}\right)+\frac{1}{2}\sin\left(\frac{2N\pi}{N+1}\right)-\frac{1}{3}\sin\left(\frac{3N\pi}{N+1}\right)+\cdots \pm \frac{1}{N}\sin\left(\frac{N^2 \pi}{N+1}\right) \right)$$ $$=\frac{2}{\pi}\lim_{N\to\infty}\frac{N\pi}{N+1}\left(\frac{\sin( \frac{N\pi}{N+1})}{\frac{N\pi}{N+1}} -\frac{\sin( \frac{2N\pi}{N+1})}{\frac{2N\pi}{N+1}}+\frac{\sin( \frac{3N\pi}{N+1})}{\frac{3N\pi}{N+1}} ... \pm \frac{\sin( \frac{N^2 \pi}{N+1})}{\frac{N^2 \pi}{N+1}}\right)$$ And in the last step I suppose I use the Riemann sum using midpoints to find the corresponding integral and evaluate it however I am a bit confused as to what integral I get. If there is a better way to evaluate this limit, I am open to suggestions. The expected answer is approximately 1.18.","Here is what I have so far: And in the last step I suppose I use the Riemann sum using midpoints to find the corresponding integral and evaluate it however I am a bit confused as to what integral I get. If there is a better way to evaluate this limit, I am open to suggestions. The expected answer is approximately 1.18.",\lim_{N\to\infty} f_N \left(\frac{N\pi}{N+1}\right) f_N (x) = \frac{-2}{\pi}\sum_{n=1}^N \frac{(-1)^n}{n} \sin(nx) \implies \lim_{N\to\infty} f_N \left( \frac{N\pi}{N+1}\right)=\lim_{N\to\infty}\frac{-2}{\pi}\sum_{n=1}^N \frac{(-1)^n}{n} \sin\left(n\frac{N\pi}{N+1}\right) =\lim_{N\to\infty}\frac{-2}{\pi}\left(-\sin\left(\frac{N\pi}{N+1}\right)+\frac{1}{2}\sin\left(\frac{2N\pi}{N+1}\right)-\frac{1}{3}\sin\left(\frac{3N\pi}{N+1}\right)+\cdots \pm \frac{1}{N}\sin\left(\frac{N^2 \pi}{N+1}\right) \right) =\frac{2}{\pi}\lim_{N\to\infty}\frac{N\pi}{N+1}\left(\frac{\sin( \frac{N\pi}{N+1})}{\frac{N\pi}{N+1}} -\frac{\sin( \frac{2N\pi}{N+1})}{\frac{2N\pi}{N+1}}+\frac{\sin( \frac{3N\pi}{N+1})}{\frac{3N\pi}{N+1}} ... \pm \frac{\sin( \frac{N^2 \pi}{N+1})}{\frac{N^2 \pi}{N+1}}\right),"['integration', 'limits', 'trigonometry', 'fourier-series', 'riemann-sum']"
94,"$f\in L^2[0,1]$ iff $f\in L^1[0,1]$ and there is nondecreasing $g$ with $|\int_a^b f(x)dx|^2 \leq (g(b)-g(a))(b-a)$ for $0\leq a\leq b\leq 1$",iff  and there is nondecreasing  with  for,"f\in L^2[0,1] f\in L^1[0,1] g |\int_a^b f(x)dx|^2 \leq (g(b)-g(a))(b-a) 0\leq a\leq b\leq 1","Let $f:[0,1]\to \Bbb C$ be measurable. I am trying to show that $f\in L^2$ iff $f\in L^1$ and there is a nondecreasing function $g:[0,1]\to \Bbb R$ such that $$ \left\lvert \int_a^b f(x)~dx \right\rvert^2 \leq (g(b)-g(a))(b-a)$$ for $0\leq a\leq b\leq 1$ . One implication is easy: we just let $g(x)=\int_0^x |f(t)|^2~dt$ and apply Holder's inequality. But I can't show the other implication. Any hints?",Let be measurable. I am trying to show that iff and there is a nondecreasing function such that for . One implication is easy: we just let and apply Holder's inequality. But I can't show the other implication. Any hints?,"f:[0,1]\to \Bbb C f\in L^2 f\in L^1 g:[0,1]\to \Bbb R  \left\lvert \int_a^b f(x)~dx \right\rvert^2 \leq (g(b)-g(a))(b-a) 0\leq a\leq b\leq 1 g(x)=\int_0^x |f(t)|^2~dt","['real-analysis', 'integration', 'lebesgue-integral', 'lp-spaces']"
95,How to find path for method of steepest descent,How to find path for method of steepest descent,,"We have integral: $$\int_0^1\exp\left(n\left(\frac{itz}{\sqrt{a(1-a)n}}+a\ln(z)+(1-a)\ln(1-z)\right)\right)dz=\int_0^1\exp(nf(z))dz,$$ where $0<a<1$ . We want to approximate this integral when $n\rightarrow\infty$ by method of steepest descent. Why deforming $[0,1]$ to the contour through saddle point has the following expansion: $$z=a+\frac{it\sqrt{a(1-a)}}{\sqrt{n}}+O\left(\frac{1}{n}\right)?$$ I found saddle point $z_0=a$ from $\text{Re}'(f(z))=0$ . I don't know what to do next? I can’t understand how they got it? I hope for your help! Thank you!",We have integral: where . We want to approximate this integral when by method of steepest descent. Why deforming to the contour through saddle point has the following expansion: I found saddle point from . I don't know what to do next? I can’t understand how they got it? I hope for your help! Thank you!,"\int_0^1\exp\left(n\left(\frac{itz}{\sqrt{a(1-a)n}}+a\ln(z)+(1-a)\ln(1-z)\right)\right)dz=\int_0^1\exp(nf(z))dz, 0<a<1 n\rightarrow\infty [0,1] z=a+\frac{it\sqrt{a(1-a)}}{\sqrt{n}}+O\left(\frac{1}{n}\right)? z_0=a \text{Re}'(f(z))=0","['calculus', 'integration', 'asymptotics', 'approximation', 'laplace-method']"
96,A question on the relation of two different forms of the Spectral Theorem for bounded operators,A question on the relation of two different forms of the Spectral Theorem for bounded operators,,"I am going through some spectral theory, and I have found two results under this name. I state this results: (I)  Spectral Theorem I: Let $\mathcal{H}$ be a separable Hilbert space. If $A\in L(\mathcal{H})$ is self adjoint. Then there exists a unique projection valued measure $\mu^A$ on the Borel- $\sigma$ algebra of the spectrum $\sigma(A)$ such that $$\int_{\sigma(A)} \text{Id}_{\sigma(A)} \; d\mu^A =A. $$ (II)  Spectra Theorem II Let $\mathcal{H}$ be a separable Hilbert space. If $A\in L(\mathcal{H})$ is self adjoint. Then there exists a $\sigma-$ finite measure $\mu$ on the spectrum $\sigma(A)$ , a direct integral $$\Gamma(A)=\int_{\sigma(A)}^\oplus H_\lambda\; d\mu (\lambda)  $$ and a unitary map $U:\mathcal{H}\to \Gamma(A)$ such that $$[UAU^{-1}(s)](\lambda)=\lambda s(\lambda) $$ for all sections $s$ in $\Gamma(A)$ . So, maybe a bit of terminology is required. Given a $\sigma-$ finite measure space $(X,\Omega, \mu )$ and a indexed family $\{H_\lambda \}_{\lambda\in X}$ of Hilbert spaces, we can costruct the obvious vector bundle $$\pi: \xi=\bigsqcup_{\lambda\in X} H_\lambda \to X$$ $$\psi\mapsto \lambda \quad \text{if } \psi\in H_\lambda $$ A section $s$ of $\xi$ is defined as a map between $X$ and $\xi$ such that $\pi \circ s=\text{Id}_X$ as it usual, but we further impose a measurability condition. This can only make sense with a measure structure is $\xi$ . This measure structure is given by an indexed family of  sequences $\{ \{e_j^\lambda \}_{j=1}^\infty\}_{\lambda \in X}$ such that for any $\lambda \in X$ we have $\{e^\lambda_j \}_{j=1}^\infty \subseteq H_\lambda$ , $$\langle e_j^\lambda,e_k^\lambda \rangle=0 \text{ for } j\neq k$$ and the norm of every $e_j^\lambda $ is either $1$ or $0$ . We also ask the maps $$\lambda\mapsto \text{dim}(H_\lambda) \quad \text{and} \quad \lambda \mapsto \langle e^\lambda_j,e^\lambda_k \rangle \quad \forall j,k>0 $$ to be measurable. With this, we call a section $s$ measurable if $\lambda\mapsto \langle s(\lambda),e^\lambda_j\rangle $ is a measurable map. Now, the direct integral $$\int_{X}^\oplus H_\lambda\; d\mu (\lambda)   $$ Is the set $\Gamma(\xi)/ \sim $ where $\Gamma(\xi)$ is the set of measurable sections $s$ in $\xi$ for which $$\Vert s \Vert^2=\int_{X} \Vert s(\lambda) \Vert^2 \; d\mu(\lambda)<\infty  $$ and $s_1\sim s_2$ if they agree $\mu-$ almost every where. Now, it seems like we could recover the spectral theorem (I) from (II). Let's try,  suppose (II) and for each $E$ in the borel $\sigma-$ algebra of $\sigma (A)$ , define $V_E\subseteq \Gamma(A)$ as the set of all section $s$ such that $\text{support}(s)\subseteq E$ . Let $P_E $ be the orthogonal projection onto $V_E$ , now we define a projection valued measure $\mu^A$ on $\sigma(A)$ as $$\mu^A(E)=U^{-1}P_E U $$ where $U$ is as in (II). The question is how could I prove that $$\int_{\sigma(A)} \lambda \;d\mu^A(\lambda)=A. $$ Also, does (I) implies (II)? I think it does not, but cannot figure out where does the equivalence fail. Here's my attempt: So, I need to show that for any $\psi\in \mathcal{H}$ we have $$\Bigr\langle \left(\int_{\sigma(A)} \lambda \; d\mu^A (\lambda)\right) \psi, \psi \Bigr\rangle =\langle A\psi, \psi \rangle. $$ Let $\psi=U^{-1}s$ for some $s$ in the direct integral, then $$\langle A\psi,\psi \rangle=\langle AU^{-1}s , U^{-1}s  \rangle=\langle UAU^{-1}s , s \rangle =\int_{\sigma(A)} \langle UAU^{-1}s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda)= \int_{\sigma(A)} \langle \lambda s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda) =   \int_{\sigma(A)} \lambda\langle \ s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda). $$ Hence, it suffices to show that $$ \int_{\sigma(A)} \lambda\langle \ s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda)=\int_{\sigma(A)} \lambda \;d\mu^A_{\psi}(\lambda) $$ where $\mu^A_\psi$ is the real valued measure on $\sigma(A)$ defined by $$\mu^A_\psi(E)=\langle \mu^A(E)\psi , \psi \rangle=\langle U^{-1}P_EU \psi , \psi \rangle= \langle P_E s,s \rangle=\int_{\sigma (A)} \langle P_E s(\lambda),s(\lambda) \rangle \; d\mu(\lambda). $$ Here is where I am stuck. Other notes By support( $s)\subseteq E$ I mean that the $s(\lambda)=0$ for $\mu-$ almost every $\lambda\in E^c$ . Id $_X$ denotes the identity in $X$ and the inner product is assumed to be linear in the first entry. Also, all inner products are missing the label for in which it is defined, it is just to avoid writing the labels too much, figuring out what this label is should not be hard.","I am going through some spectral theory, and I have found two results under this name. I state this results: (I)  Spectral Theorem I: Let be a separable Hilbert space. If is self adjoint. Then there exists a unique projection valued measure on the Borel- algebra of the spectrum such that (II)  Spectra Theorem II Let be a separable Hilbert space. If is self adjoint. Then there exists a finite measure on the spectrum , a direct integral and a unitary map such that for all sections in . So, maybe a bit of terminology is required. Given a finite measure space and a indexed family of Hilbert spaces, we can costruct the obvious vector bundle A section of is defined as a map between and such that as it usual, but we further impose a measurability condition. This can only make sense with a measure structure is . This measure structure is given by an indexed family of  sequences such that for any we have , and the norm of every is either or . We also ask the maps to be measurable. With this, we call a section measurable if is a measurable map. Now, the direct integral Is the set where is the set of measurable sections in for which and if they agree almost every where. Now, it seems like we could recover the spectral theorem (I) from (II). Let's try,  suppose (II) and for each in the borel algebra of , define as the set of all section such that . Let be the orthogonal projection onto , now we define a projection valued measure on as where is as in (II). The question is how could I prove that Also, does (I) implies (II)? I think it does not, but cannot figure out where does the equivalence fail. Here's my attempt: So, I need to show that for any we have Let for some in the direct integral, then Hence, it suffices to show that where is the real valued measure on defined by Here is where I am stuck. Other notes By support( I mean that the for almost every . Id denotes the identity in and the inner product is assumed to be linear in the first entry. Also, all inner products are missing the label for in which it is defined, it is just to avoid writing the labels too much, figuring out what this label is should not be hard.","\mathcal{H} A\in L(\mathcal{H}) \mu^A \sigma \sigma(A) \int_{\sigma(A)} \text{Id}_{\sigma(A)} \; d\mu^A =A.  \mathcal{H} A\in L(\mathcal{H}) \sigma- \mu \sigma(A) \Gamma(A)=\int_{\sigma(A)}^\oplus H_\lambda\; d\mu (\lambda)   U:\mathcal{H}\to \Gamma(A) [UAU^{-1}(s)](\lambda)=\lambda s(\lambda)  s \Gamma(A) \sigma- (X,\Omega, \mu ) \{H_\lambda \}_{\lambda\in X} \pi: \xi=\bigsqcup_{\lambda\in X} H_\lambda \to X \psi\mapsto \lambda \quad \text{if } \psi\in H_\lambda  s \xi X \xi \pi \circ s=\text{Id}_X \xi \{ \{e_j^\lambda \}_{j=1}^\infty\}_{\lambda \in X} \lambda \in X \{e^\lambda_j \}_{j=1}^\infty \subseteq H_\lambda \langle e_j^\lambda,e_k^\lambda \rangle=0 \text{ for } j\neq k e_j^\lambda  1 0 \lambda\mapsto \text{dim}(H_\lambda) \quad \text{and} \quad \lambda \mapsto \langle e^\lambda_j,e^\lambda_k \rangle \quad \forall j,k>0  s \lambda\mapsto \langle s(\lambda),e^\lambda_j\rangle  \int_{X}^\oplus H_\lambda\; d\mu (\lambda)    \Gamma(\xi)/ \sim  \Gamma(\xi) s \xi \Vert s \Vert^2=\int_{X} \Vert s(\lambda) \Vert^2 \; d\mu(\lambda)<\infty   s_1\sim s_2 \mu- E \sigma- \sigma (A) V_E\subseteq \Gamma(A) s \text{support}(s)\subseteq E P_E  V_E \mu^A \sigma(A) \mu^A(E)=U^{-1}P_E U  U \int_{\sigma(A)} \lambda \;d\mu^A(\lambda)=A.  \psi\in \mathcal{H} \Bigr\langle \left(\int_{\sigma(A)} \lambda \; d\mu^A (\lambda)\right) \psi, \psi \Bigr\rangle =\langle A\psi, \psi \rangle.  \psi=U^{-1}s s \langle A\psi,\psi \rangle=\langle AU^{-1}s , U^{-1}s  \rangle=\langle UAU^{-1}s , s \rangle =\int_{\sigma(A)} \langle UAU^{-1}s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda)= \int_{\sigma(A)} \langle \lambda s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda) =   \int_{\sigma(A)} \lambda\langle \ s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda).   \int_{\sigma(A)} \lambda\langle \ s(\lambda) , s(\lambda)\rangle \;d\mu(\lambda)=\int_{\sigma(A)} \lambda \;d\mu^A_{\psi}(\lambda)  \mu^A_\psi \sigma(A) \mu^A_\psi(E)=\langle \mu^A(E)\psi , \psi \rangle=\langle U^{-1}P_EU \psi , \psi \rangle= \langle P_E s,s \rangle=\int_{\sigma (A)} \langle P_E s(\lambda),s(\lambda) \rangle \; d\mu(\lambda).  s)\subseteq E s(\lambda)=0 \mu- \lambda\in E^c _X X","['integration', 'functional-analysis', 'operator-theory', 'hilbert-spaces', 'geometric-measure-theory']"
97,Is$ \int_{0}^{\pi} f^{2}(x) d x$ divergent or convergent?,Is divergent or convergent?, \int_{0}^{\pi} f^{2}(x) d x,let be $f(x) = \sum_{n=1}^{\infty} \frac{\sin n x}{n^{2 / 3}}$ Find $\int_{0}^{\pi} f^{2}(x) d x$ I have understood that $\quad \sum_{n=1}^{\infty} \int_{0}^{\pi} \frac{\sin (n t)}{n^{2 / 3}} d t=\int_{0}^{\pi} \sum_{n=1}^{\infty} \frac{\sin (n t)}{n^{2 / 3}} d t$ $$\int_{0}^{\pi} \frac{\sin (n t)}{n^{2 / 3}} d t = \frac{1-\cos (\pi n)}{n^{5 / 3}} \Rightarrow \int_{0}^{\pi} f(x) d x = \sum_{n=1}^{\infty}\frac{1-\cos (\pi n)}{n^{5 / 3}}$$ But it's all that I can,let be Find I have understood that But it's all that I can,f(x) = \sum_{n=1}^{\infty} \frac{\sin n x}{n^{2 / 3}} \int_{0}^{\pi} f^{2}(x) d x \quad \sum_{n=1}^{\infty} \int_{0}^{\pi} \frac{\sin (n t)}{n^{2 / 3}} d t=\int_{0}^{\pi} \sum_{n=1}^{\infty} \frac{\sin (n t)}{n^{2 / 3}} d t \int_{0}^{\pi} \frac{\sin (n t)}{n^{2 / 3}} d t = \frac{1-\cos (\pi n)}{n^{5 / 3}} \Rightarrow \int_{0}^{\pi} f(x) d x = \sum_{n=1}^{\infty}\frac{1-\cos (\pi n)}{n^{5 / 3}},"['real-analysis', 'integration', 'analysis']"
98,Why is $\int_\Gamma \frac{\log(b-az)}{z} dz=2\pi i\log(b)$?,Why is ?,\int_\Gamma \frac{\log(b-az)}{z} dz=2\pi i\log(b),"Let $a\leq b$ and $\Gamma$ be the unit circle (in the complex plane). I found that $\int_\Gamma \frac{\log(b-az)}{z} dz=2\pi i\log(b)$ . It seems like Cauchy's integral formula has been used here. I want to know why the conditions of Cauchy's integral formula are fulfilled. The conditions are that $\log(b-az)$ is holomorphic on some open set $U \in \mathbb{C}$ that contains the closed unit disc. What can I choose for $U$ ? Maybe $U = \{z \in \mathbb{C} \mid Re(b-az) >0\}$ ? Because then I avoid the branch cut and $\log (b-az)$ is holomorphic on $U$ . However, then if $a=b$ , the closed (!) unit disc is not contained in $U$ . And if I change the "" $>$ "" in the definition of $U$ to a "" $\geq$ "", then $\log(b-az)$ is not any longer defined on all of $U$ . What do I do wrong?","Let and be the unit circle (in the complex plane). I found that . It seems like Cauchy's integral formula has been used here. I want to know why the conditions of Cauchy's integral formula are fulfilled. The conditions are that is holomorphic on some open set that contains the closed unit disc. What can I choose for ? Maybe ? Because then I avoid the branch cut and is holomorphic on . However, then if , the closed (!) unit disc is not contained in . And if I change the "" "" in the definition of to a "" "", then is not any longer defined on all of . What do I do wrong?",a\leq b \Gamma \int_\Gamma \frac{\log(b-az)}{z} dz=2\pi i\log(b) \log(b-az) U \in \mathbb{C} U U = \{z \in \mathbb{C} \mid Re(b-az) >0\} \log (b-az) U a=b U > U \geq \log(b-az) U,"['calculus', 'integration', 'complex-analysis', 'complex-integration', 'cauchy-riemann-equations']"
99,Show that $ (1-\epsilon)^q \lambda(E) \leq \lambda(E_\epsilon) $,Show that, (1-\epsilon)^q \lambda(E) \leq \lambda(E_\epsilon) ,"The question is the following: Suppose $f$ is a real-valued Lebesgue measurable function on a set $E\subset \mathbb{R}$ with finite measure. Given $1 > \varepsilon > 0$ . Let $E_\varepsilon = \{x:|f(x)|\geqslant \varepsilon\}$ . Suppose $$ \frac{1}{\lambda(E)}\int_E |f(x)|\ d\lambda \geqslant  1 \quad \text{and} \quad \frac{1}{\lambda(E)}\int_E |f(x)|^p\ d\lambda \leqslant  1 $$ for some $1<p<\infty$ . Show that $$ (1-\varepsilon)^q \lambda(E) \leqslant \lambda(E_\varepsilon) $$ where $1/p+1/q = 1$ . I tried to compute $$ \int_{E \setminus E_\varepsilon} |f| \ d\lambda  = \int_{{x \in E:|f(x)| \leqslant \varepsilon}} |f| \leqslant \int_{{x \in E:|f(x)| \leq \varepsilon}} \varepsilon \ d\lambda = \epsilon \cdot \lambda(E \setminus E_\varepsilon)\leqslant\varepsilon \cdot(\lambda(E )-\lambda(E_\varepsilon)) $$ Therefore, we have \begin{align*}     \int_{E_\varepsilon} |f| = \int_E |f| - \int_{E \setminus E_\varepsilon}|f| \geqslant \lambda(E) -  \varepsilon \cdot( \lambda(E )-\lambda( E_\varepsilon)) \geqslant (1-\varepsilon) \lambda(E) + \lambda(E_\varepsilon) \end{align*} From Holder's inequality, $$ \int_{E_\varepsilon}|f| \leqslant \left(\int_{E_\varepsilon}|f|^p\right)^{1/p} \cdot \left(\int_{E_\varepsilon}|1|^q\right)^{1/q}  = \left(\int_{E_\varepsilon}|f|^p\right)^{1/p}\cdot(\lambda(E_\varepsilon))^{1/q} $$ then we have $$ \left(\int_{E_\varepsilon}|f|^p\right)^{1/p}\cdot(\lambda(E_\varepsilon))^{1/q}\geqslant (1-\varepsilon) \lambda(E) + \lambda(E_\varepsilon) $$ which does not imply anything. I know that I have to apply the Holder's Inequality some how from the relationship between $p$ and $q$ , but I can't proceed anywhere else. I have no idea how to use the second inequality as it always gives me something from the other direction. Any help and hint are appreciated!! Edit: I have already figured it out, and I was actually very close to the solution. Here attached the rest of my approach. \begin{align*}     (1-\epsilon) \lambda(E) + \lambda(E_\epsilon)& \leq \left(\int_{E_\epsilon}|f|^p\right)^{1/p} \cdot(\lambda(E_\epsilon))^{1/q}\\     &\leq \left(\int_{E}|f|^p\right)^{1/p} \cdot(\lambda(E_\epsilon))^{1/q}\\     &\leq (\lambda(E))^{1/p} \cdot(\lambda(E_\epsilon))^{1/q} \end{align*} and now it suffices to show that the above equation is equivalent to the conclusion $$ (1-\epsilon)^q\lambda(E)\leq \lambda(E_\epsilon) $$ Divide both side by $(\lambda(E))^{1/p}$ and from the fact that $1-1/p = 1/q$ \begin{align*}     (1-\epsilon) [\lambda(E)]^{1/q} + \lambda(E_\epsilon)(\lambda(E))^{-1/p}&\leq (\lambda(E_\epsilon))^{1/q}  \end{align*} Raise both sides to the $q$ -th power, one has \begin{align*}     \lambda(E_\epsilon) &\geq [(1-\epsilon) [\lambda(E)]^{1/q} + \lambda(E_\epsilon)(\lambda(E))^{-1/p}]^q \\     &\geq [(1-\epsilon) [\lambda(E)]^{1/q}]^q \\     &\geq (1-\epsilon)^q \lambda(E) \end{align*}","The question is the following: Suppose is a real-valued Lebesgue measurable function on a set with finite measure. Given . Let . Suppose for some . Show that where . I tried to compute Therefore, we have From Holder's inequality, then we have which does not imply anything. I know that I have to apply the Holder's Inequality some how from the relationship between and , but I can't proceed anywhere else. I have no idea how to use the second inequality as it always gives me something from the other direction. Any help and hint are appreciated!! Edit: I have already figured it out, and I was actually very close to the solution. Here attached the rest of my approach. and now it suffices to show that the above equation is equivalent to the conclusion Divide both side by and from the fact that Raise both sides to the -th power, one has","f E\subset \mathbb{R} 1 > \varepsilon > 0 E_\varepsilon = \{x:|f(x)|\geqslant \varepsilon\} 
\frac{1}{\lambda(E)}\int_E |f(x)|\ d\lambda \geqslant  1 \quad \text{and} \quad \frac{1}{\lambda(E)}\int_E |f(x)|^p\ d\lambda \leqslant  1
 1<p<\infty 
(1-\varepsilon)^q \lambda(E) \leqslant \lambda(E_\varepsilon)
 1/p+1/q = 1 
\int_{E \setminus E_\varepsilon} |f| \ d\lambda  = \int_{{x \in E:|f(x)| \leqslant \varepsilon}} |f| \leqslant \int_{{x \in E:|f(x)| \leq \varepsilon}} \varepsilon \ d\lambda = \epsilon \cdot \lambda(E \setminus E_\varepsilon)\leqslant\varepsilon \cdot(\lambda(E )-\lambda(E_\varepsilon))
 \begin{align*}
    \int_{E_\varepsilon} |f| = \int_E |f| - \int_{E \setminus E_\varepsilon}|f| \geqslant \lambda(E) -  \varepsilon \cdot( \lambda(E )-\lambda( E_\varepsilon)) \geqslant (1-\varepsilon) \lambda(E) + \lambda(E_\varepsilon)
\end{align*} 
\int_{E_\varepsilon}|f| \leqslant \left(\int_{E_\varepsilon}|f|^p\right)^{1/p} \cdot \left(\int_{E_\varepsilon}|1|^q\right)^{1/q}  = \left(\int_{E_\varepsilon}|f|^p\right)^{1/p}\cdot(\lambda(E_\varepsilon))^{1/q}
 
\left(\int_{E_\varepsilon}|f|^p\right)^{1/p}\cdot(\lambda(E_\varepsilon))^{1/q}\geqslant (1-\varepsilon) \lambda(E) + \lambda(E_\varepsilon)
 p q \begin{align*}
    (1-\epsilon) \lambda(E) + \lambda(E_\epsilon)& \leq \left(\int_{E_\epsilon}|f|^p\right)^{1/p} \cdot(\lambda(E_\epsilon))^{1/q}\\
    &\leq \left(\int_{E}|f|^p\right)^{1/p} \cdot(\lambda(E_\epsilon))^{1/q}\\
    &\leq (\lambda(E))^{1/p} \cdot(\lambda(E_\epsilon))^{1/q}
\end{align*} 
(1-\epsilon)^q\lambda(E)\leq \lambda(E_\epsilon)
 (\lambda(E))^{1/p} 1-1/p = 1/q \begin{align*}
    (1-\epsilon) [\lambda(E)]^{1/q} + \lambda(E_\epsilon)(\lambda(E))^{-1/p}&\leq (\lambda(E_\epsilon))^{1/q} 
\end{align*} q \begin{align*}
    \lambda(E_\epsilon) &\geq [(1-\epsilon) [\lambda(E)]^{1/q} + \lambda(E_\epsilon)(\lambda(E))^{-1/p}]^q \\
    &\geq [(1-\epsilon) [\lambda(E)]^{1/q}]^q \\
    &\geq (1-\epsilon)^q \lambda(E)
\end{align*}","['real-analysis', 'integration', 'measure-theory', 'lebesgue-integral', 'lp-spaces']"
