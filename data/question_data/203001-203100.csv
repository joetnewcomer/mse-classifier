,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Understanding a proof of the vanishing of the Weyl tensor for a diagonal Riemannian metric,Understanding a proof of the vanishing of the Weyl tensor for a diagonal Riemannian metric,,"I'm currently working through this paper from Duke Math J., Volume 51, Number 2 (1984), 243-260 (unfortunately couldn't find a publicly visible link); more specifically, the part about the obstructions to the diagonalizability of Riemannian metrics in $n \geq 4$ dimensions, but there are a few parts where I just can't wrap my head around what's happening. On page 258, they start by taking an orthonormal coframe $\{\omega^i = f^i d x^i : i = 1, ..., n\}$ altogether with it's dual frame $\{e_i\}$ . Their goal is to show that the Weyl-tensor $W$ vanishes, so that one can apply the Weyl-Schouten theorem to get that the manifold is already conformally flat. Using some calculations with the connection form $\omega_j^i$ and Cartan's structure equations which I can for the most part follow, they arive at the result that $$ d(\omega^i \wedge \omega^j \wedge \omega_j^i) = \omega^i \wedge \omega^j \wedge \Omega_j^i = 0 \text{ for } i \neq j$$ where $\Omega_j^i$ is the curvature $2$ -form. Now from this, Deturck and Yang make the jump to the sectional curvature $R$ and then on to the Weyl Tensor $W$ . Namely, they argue the following: Thus $\omega^i \wedge \omega^j \wedge \Omega_j^i = 0$ for all $i \neq j$ . This will manifest itself as an integrability condition, as we shal see. Rewriting this in terms of the sectional curvature $R$ , we must have $$R(e_i, e_j, e_k, e_l) = 0 \text{ if $i, j, k, l$ are distinct} $$ where $\{e_i\}$ is the dual frame to $\{\omega^i\}$ . How do they make this jump? How can we come from the equation $\omega^i \wedge \omega^j \wedge \Omega_j^i = 0$ where we have only two distinct components $i, j$ to the equation with four distinct components $i, j, k, l$ for which the curvature $R$ vanishes? What exactly do we do when ""rewriting"" this equation, as they only call it? It might be due to my limited experience with these things, but I fail to see the exact relation between the first equation and the vanishing of the curvature tensor for these four components. Right thereafter, they continue to carry over this equation about the Weyl tensor, namely Since $\{e_i\}$ is an orthonormale frame, none of these components of $R$ enter into the Ricci tensor. We conclude that $$W(e_i, e_j, e_k, e_l) = 0 \text{ if $i, j, k, l$ are distinct}$$ where $W$ is the Weyl tensor. This seems less obscure to me, but I don't understand it entirely either. My first question would be, how do we get from the $\{e_i\}$ being orthonormal to not entering into the Ricci tensor? Is this some property of the Ricci-tensor that I'm missing? And my 2nd question here would be: I know that the Riemannian curvature tensor decomposes into the ""trace""-part (Ricci-Tensor) and the ""traceless""-part (Weyl-Tensor). Is this the argument Deturck and Yang use here to conclude the $W(...) = 0$ -equation? That if the components don't enter into the Ricci-tensor, they can only be in the only other part the curvature tensor consists of, namely the Weyl-tensor, so if one of them is $= 0$ , the other one is too? Am I understanding this argument correctly? (Even if I probably didn't express it too well...) From there on, they continue with some calculations that I can roughly follow to show that $W \equiv 0$ , but I just can't wrap my head around about this passage. I haven't worked that much with Weyl- and Curvature tensors before, so maybe some stuff I have trouble with has a very easy explanation that I'm just missing out on. Any help would be greatly appreciated.","I'm currently working through this paper from Duke Math J., Volume 51, Number 2 (1984), 243-260 (unfortunately couldn't find a publicly visible link); more specifically, the part about the obstructions to the diagonalizability of Riemannian metrics in dimensions, but there are a few parts where I just can't wrap my head around what's happening. On page 258, they start by taking an orthonormal coframe altogether with it's dual frame . Their goal is to show that the Weyl-tensor vanishes, so that one can apply the Weyl-Schouten theorem to get that the manifold is already conformally flat. Using some calculations with the connection form and Cartan's structure equations which I can for the most part follow, they arive at the result that where is the curvature -form. Now from this, Deturck and Yang make the jump to the sectional curvature and then on to the Weyl Tensor . Namely, they argue the following: Thus for all . This will manifest itself as an integrability condition, as we shal see. Rewriting this in terms of the sectional curvature , we must have where is the dual frame to . How do they make this jump? How can we come from the equation where we have only two distinct components to the equation with four distinct components for which the curvature vanishes? What exactly do we do when ""rewriting"" this equation, as they only call it? It might be due to my limited experience with these things, but I fail to see the exact relation between the first equation and the vanishing of the curvature tensor for these four components. Right thereafter, they continue to carry over this equation about the Weyl tensor, namely Since is an orthonormale frame, none of these components of enter into the Ricci tensor. We conclude that where is the Weyl tensor. This seems less obscure to me, but I don't understand it entirely either. My first question would be, how do we get from the being orthonormal to not entering into the Ricci tensor? Is this some property of the Ricci-tensor that I'm missing? And my 2nd question here would be: I know that the Riemannian curvature tensor decomposes into the ""trace""-part (Ricci-Tensor) and the ""traceless""-part (Weyl-Tensor). Is this the argument Deturck and Yang use here to conclude the -equation? That if the components don't enter into the Ricci-tensor, they can only be in the only other part the curvature tensor consists of, namely the Weyl-tensor, so if one of them is , the other one is too? Am I understanding this argument correctly? (Even if I probably didn't express it too well...) From there on, they continue with some calculations that I can roughly follow to show that , but I just can't wrap my head around about this passage. I haven't worked that much with Weyl- and Curvature tensors before, so maybe some stuff I have trouble with has a very easy explanation that I'm just missing out on. Any help would be greatly appreciated.","n \geq 4 \{\omega^i = f^i d x^i : i = 1, ..., n\} \{e_i\} W \omega_j^i  d(\omega^i \wedge \omega^j \wedge \omega_j^i) = \omega^i \wedge \omega^j \wedge \Omega_j^i = 0 \text{ for } i \neq j \Omega_j^i 2 R W \omega^i \wedge \omega^j \wedge \Omega_j^i = 0 i \neq j R R(e_i, e_j, e_k, e_l) = 0 \text{ if i, j, k, l are distinct}  \{e_i\} \{\omega^i\} \omega^i \wedge \omega^j \wedge \Omega_j^i = 0 i, j i, j, k, l R \{e_i\} R W(e_i, e_j, e_k, e_l) = 0 \text{ if i, j, k, l are distinct} W \{e_i\} W(...) = 0 = 0 W \equiv 0","['differential-geometry', 'riemannian-geometry', 'tensors', 'curvature']"
1,Symmetrization and isoperimetric inequality,Symmetrization and isoperimetric inequality,,"Let $\Omega\subseteq\mathbb{R}^n$ be a bounded open set with $C^1$ boundary $\partial\Omega$. The isoperimetric inequality states $$\frac{|\partial\Omega|}{|\Omega|^{\frac{n-1}{n}}}\geq \frac{|\partial B_1|}{|B_1|^{\frac{n-1}{n}}},$$ where $B_1$ is the unit ball centred at $0$. I want to prove a weaker version, say that given a fixed volume $V$ the ball has the lowest perimetre among all the regions $\Omega$ with volume $|\Omega|=V$. (*) My professor told me to focus on an $\Omega$ of the form $$ \Omega=\{(x',x_n)\in\mathbb{R}^{n-1}\times\mathbb{R}:\,x'\in W\subseteq\mathbb{R}^{n-1},\,\varphi_1(x')<x_n<\varphi_2(x')\}, $$ and then to consider $$\Omega_s=\{(x',x_n)\in\mathbb{R}^{n-1}\times\mathbb{R}:\,x'\in W\subseteq\mathbb{R}^{n-1},\,-\frac{\varphi_2(x')-\varphi_1(x')}{2}<x_n<\frac{\varphi_2(x')-\varphi_1(x')}{2}\}.$$ Direct computations show that $|\Omega|=|\Omega_s|$ and $|\partial\Omega|\geq |\partial\Omega_s|$, with equality if and only if $\Omega$ is symmetric with respect to a hyperplane $\{x_n=C\}$. I understand that this provides an intuition for (*). However, I do not see how to extend this idea in order to achieve a formal proof of (*).","Let $\Omega\subseteq\mathbb{R}^n$ be a bounded open set with $C^1$ boundary $\partial\Omega$. The isoperimetric inequality states $$\frac{|\partial\Omega|}{|\Omega|^{\frac{n-1}{n}}}\geq \frac{|\partial B_1|}{|B_1|^{\frac{n-1}{n}}},$$ where $B_1$ is the unit ball centred at $0$. I want to prove a weaker version, say that given a fixed volume $V$ the ball has the lowest perimetre among all the regions $\Omega$ with volume $|\Omega|=V$. (*) My professor told me to focus on an $\Omega$ of the form $$ \Omega=\{(x',x_n)\in\mathbb{R}^{n-1}\times\mathbb{R}:\,x'\in W\subseteq\mathbb{R}^{n-1},\,\varphi_1(x')<x_n<\varphi_2(x')\}, $$ and then to consider $$\Omega_s=\{(x',x_n)\in\mathbb{R}^{n-1}\times\mathbb{R}:\,x'\in W\subseteq\mathbb{R}^{n-1},\,-\frac{\varphi_2(x')-\varphi_1(x')}{2}<x_n<\frac{\varphi_2(x')-\varphi_1(x')}{2}\}.$$ Direct computations show that $|\Omega|=|\Omega_s|$ and $|\partial\Omega|\geq |\partial\Omega_s|$, with equality if and only if $\Omega$ is symmetric with respect to a hyperplane $\{x_n=C\}$. I understand that this provides an intuition for (*). However, I do not see how to extend this idea in order to achieve a formal proof of (*).",,"['differential-geometry', 'proof-writing', 'vector-analysis']"
2,Isometric embedding of Riemannian manifolds into Minkowski space,Isometric embedding of Riemannian manifolds into Minkowski space,,"I was wondering if there are any existence results similar to the Nash embedding theorem where a manifold with a Riemannian metric is isometrically embedded into flat Minkowski space, with metric of signature $(-,+,\ldots,+)$.  Allowing for the target space to be of Lorentzian signature certainly seems to help with negatively curved Riemannian metrics, i.e. the two dimensional hyperbolic plane has no isometric embedding in $\mathbb{R}^3$, however, it is easily embedded into Minkowski space $\mathbb{R}^{2,1}$ as a surface of constant proper time away from the origin.  The question would be given a Riemannian manifold of dimension $n$, what is the minimal dimension of Minkowski space $\mathbb{R}^{d-1,1}$ in which the surface is isometrically embeddable?","I was wondering if there are any existence results similar to the Nash embedding theorem where a manifold with a Riemannian metric is isometrically embedded into flat Minkowski space, with metric of signature $(-,+,\ldots,+)$.  Allowing for the target space to be of Lorentzian signature certainly seems to help with negatively curved Riemannian metrics, i.e. the two dimensional hyperbolic plane has no isometric embedding in $\mathbb{R}^3$, however, it is easily embedded into Minkowski space $\mathbb{R}^{2,1}$ as a surface of constant proper time away from the origin.  The question would be given a Riemannian manifold of dimension $n$, what is the minimal dimension of Minkowski space $\mathbb{R}^{d-1,1}$ in which the surface is isometrically embeddable?",,"['differential-geometry', 'manifolds', 'hyperbolic-geometry', 'isometry']"
3,Zero vector in a vector bundle,Zero vector in a vector bundle,,"I am trying to get familiar with the idea of a vector bundle at an intuitive level, and it doesn't seem to be too abstract an idea: vector spaces get ""attached"" to points on a surface. However, there is a naive, and early question that comes to mind reading the definition on Wikipedia: ... to every point x of the space X we associate (or ""attach"") a vector space V(x) in such a way that these vector spaces fit together to form another space of the same kind as X It is one of the axioms of a vector space that there is an identity element of addition: There exists an element $0 ∈ V,$ called the zero vector , such that $v + 0 = v$ for all v ∈ V which I interpret to mean that vector spaces are centered at the origin of the coordinate system. So in the case of a vector space attached to a point on some surface, is the zero the actual point?","I am trying to get familiar with the idea of a vector bundle at an intuitive level, and it doesn't seem to be too abstract an idea: vector spaces get ""attached"" to points on a surface. However, there is a naive, and early question that comes to mind reading the definition on Wikipedia: ... to every point x of the space X we associate (or ""attach"") a vector space V(x) in such a way that these vector spaces fit together to form another space of the same kind as X It is one of the axioms of a vector space that there is an identity element of addition: There exists an element $0 ∈ V,$ called the zero vector , such that $v + 0 = v$ for all v ∈ V which I interpret to mean that vector spaces are centered at the origin of the coordinate system. So in the case of a vector space attached to a point on some surface, is the zero the actual point?",,"['differential-geometry', 'vector-spaces', 'manifolds', 'differential-topology']"
4,"To Show that $\exp(tX)\exp(tY)= \exp(t(X+Y)) + (1/2)t^2[X, Y] +o(t^3)$",To Show that,"\exp(tX)\exp(tY)= \exp(t(X+Y)) + (1/2)t^2[X, Y] +o(t^3)","Problem 20-9 in Lee's Introduction to Smooth Manifolds (2nd Ed.) asks to prove that for a Lie group $G$, and for $X, Y\in \text{Lie}(G)=\mathfrak g$, there is $\epsilon>0$ and a smooth map $Z:(-\epsilon, \epsilon)\to \mathfrak g$ such that   $$(\exp tX)(\exp tY) = \exp\left(t(X+Y) + \frac{1}{2}t^2[X, Y] + t^3 Z(t)\right)$$ What we want to show is that the first and second term in the Taylor expansion of $\exp^{-1}\left((\exp tX)(\exp tY)\right)$ are $t(X+Y)$ and $\frac{1}{2}t^2[X, Y]$ respectively. Calculating the first term is easy since we just need to differentiate $\exp^{-1}((\exp tX)(\exp tY))$ with respect to $t$ at $t=0$ once, and this gives the desired result. But for the second term we need to take the second derivative at which I am stuck.","Problem 20-9 in Lee's Introduction to Smooth Manifolds (2nd Ed.) asks to prove that for a Lie group $G$, and for $X, Y\in \text{Lie}(G)=\mathfrak g$, there is $\epsilon>0$ and a smooth map $Z:(-\epsilon, \epsilon)\to \mathfrak g$ such that   $$(\exp tX)(\exp tY) = \exp\left(t(X+Y) + \frac{1}{2}t^2[X, Y] + t^3 Z(t)\right)$$ What we want to show is that the first and second term in the Taylor expansion of $\exp^{-1}\left((\exp tX)(\exp tY)\right)$ are $t(X+Y)$ and $\frac{1}{2}t^2[X, Y]$ respectively. Calculating the first term is easy since we just need to differentiate $\exp^{-1}((\exp tX)(\exp tY))$ with respect to $t$ at $t=0$ once, and this gives the desired result. But for the second term we need to take the second derivative at which I am stuck.",,"['differential-geometry', 'differential-topology', 'lie-groups']"
5,Double differential equals zero?,Double differential equals zero?,,"In Elementary Differential Geometry 2nd ed, Barret O'niell, Section 1.6 O'niell states that since p-forms follow the alternation rule, then a repeated differential is necessarily zero, that is $$dx \wedge dx = 0$$ Yet, differentiating position with respect to time, we get $$a = \frac {d^2 p} {dt^2}$$ then integrating back to position $$p = \int_0^t \int_0^t a\,dt\,dt $$ which clearly does not equal zero, yet in my tangled brain looks something like $dt\,dt$. Why is this not zero?","In Elementary Differential Geometry 2nd ed, Barret O'niell, Section 1.6 O'niell states that since p-forms follow the alternation rule, then a repeated differential is necessarily zero, that is $$dx \wedge dx = 0$$ Yet, differentiating position with respect to time, we get $$a = \frac {d^2 p} {dt^2}$$ then integrating back to position $$p = \int_0^t \int_0^t a\,dt\,dt $$ which clearly does not equal zero, yet in my tangled brain looks something like $dt\,dt$. Why is this not zero?",,"['calculus', 'differential-geometry', 'differential-forms', 'exterior-algebra']"
6,"Definition of a section of a vector bundle being in the Sobolev space $H^{k,r}(E)$.",Definition of a section of a vector bundle being in the Sobolev space .,"H^{k,r}(E)","This is taken from Jost's text: We let $E$ be a vector bundle over $M$, $s : M \to E$ be a section of $E$ with compact support. We say that $s$ is contained in the Sobolev space $H^{k,r}(E)$, if for any bundle atlas with the property that on compact sets all coordinates changes and all their derivatives are bounded, and for any bundle chart from such an atlas, $$\varphi : E\vert_U \to U \times \mathbb{R}^n$$ we have that $\varphi \circ s\vert_U$ is contained in $H^{k,r}(U)$. Two questions: Why do we require that the coordinate changes and all their derivatives are bounded? How does that have anything to do with $s$ being in the Sobolev space? By the definition of $\varphi$, wouldn't we have to require that $\varphi \circ s\vert_U \in H^{k,r}(U \times \mathbb{R}^n)$?","This is taken from Jost's text: We let $E$ be a vector bundle over $M$, $s : M \to E$ be a section of $E$ with compact support. We say that $s$ is contained in the Sobolev space $H^{k,r}(E)$, if for any bundle atlas with the property that on compact sets all coordinates changes and all their derivatives are bounded, and for any bundle chart from such an atlas, $$\varphi : E\vert_U \to U \times \mathbb{R}^n$$ we have that $\varphi \circ s\vert_U$ is contained in $H^{k,r}(U)$. Two questions: Why do we require that the coordinate changes and all their derivatives are bounded? How does that have anything to do with $s$ being in the Sobolev space? By the definition of $\varphi$, wouldn't we have to require that $\varphi \circ s\vert_U \in H^{k,r}(U \times \mathbb{R}^n)$?",,['differential-geometry']
7,Tangent space of circle at a point,Tangent space of circle at a point,,"I am trying to compute tangent space of $S^1=\{(x,y)\in \mathbb{R}^2: x^2+y^2=1\}$ at a point say $(1,0)=p$. As $S^1\subseteq \mathbb{R}^2$  we see that $\left\{\frac{\partial}{\partial x}\bigg|_p,\frac{\partial}{\partial y}\bigg|_p\right\}$ are elements of $T_pS^1$. As $S^1$ is one dimensional, we see that $\left\{\frac{\partial}{\partial x}\bigg|_p,\frac{\partial}{\partial y}\bigg|_p\right\}$ is a linearly dependent set when seen as elements of $T_pS^1$ i.e., for some $a,b\in \mathbb{R}$ we have $$a\frac{\partial}{\partial x}\bigg|_p+b\frac{\partial}{\partial y}\bigg|_p=0$$ as functions $C_p^{\infty}(S^1)\rightarrow \mathbb{R}$. For all $f\in C_p^{\infty}(S^1)$ we have $$a\frac{\partial f}{\partial x}\bigg|_p+b\frac{\partial f}{\partial y}\bigg|_p=0.$$ I have no idea how to proceed from here. Any reference which discuss this kind of examples are also welcome.","I am trying to compute tangent space of $S^1=\{(x,y)\in \mathbb{R}^2: x^2+y^2=1\}$ at a point say $(1,0)=p$. As $S^1\subseteq \mathbb{R}^2$  we see that $\left\{\frac{\partial}{\partial x}\bigg|_p,\frac{\partial}{\partial y}\bigg|_p\right\}$ are elements of $T_pS^1$. As $S^1$ is one dimensional, we see that $\left\{\frac{\partial}{\partial x}\bigg|_p,\frac{\partial}{\partial y}\bigg|_p\right\}$ is a linearly dependent set when seen as elements of $T_pS^1$ i.e., for some $a,b\in \mathbb{R}$ we have $$a\frac{\partial}{\partial x}\bigg|_p+b\frac{\partial}{\partial y}\bigg|_p=0$$ as functions $C_p^{\infty}(S^1)\rightarrow \mathbb{R}$. For all $f\in C_p^{\infty}(S^1)$ we have $$a\frac{\partial f}{\partial x}\bigg|_p+b\frac{\partial f}{\partial y}\bigg|_p=0.$$ I have no idea how to proceed from here. Any reference which discuss this kind of examples are also welcome.",,['differential-geometry']
8,Integrate form $\omega=x_jdx_{1}\wedge\cdots\wedge dx_{i-1}\wedge dx_{i+1}\wedge\cdots dx_n$ on $S=\{\textbf{x}\in\mathbb{R^n}:||\textbf{x}||=1\}$,Integrate form  on,\omega=x_jdx_{1}\wedge\cdots\wedge dx_{i-1}\wedge dx_{i+1}\wedge\cdots dx_n S=\{\textbf{x}\in\mathbb{R^n}:||\textbf{x}||=1\},"Integrate form $\omega=x_jdx_{1}\wedge\cdots\wedge dx_{i-1}\wedge dx_{i+1}\wedge\cdots dx_n$ on $S=\{\textbf{x}\in\mathbb{R^n}:||\textbf{x}||=1\}$. $i,j$ are constant. Doing it from definition doesn't seem workable. Any hint would be greatly appreciated. Orientation is external. I do not know Stoke's theorem yet. I know only basic facts connected with differential forms and some thorems about it working up to $\mathbb{R^3}$.","Integrate form $\omega=x_jdx_{1}\wedge\cdots\wedge dx_{i-1}\wedge dx_{i+1}\wedge\cdots dx_n$ on $S=\{\textbf{x}\in\mathbb{R^n}:||\textbf{x}||=1\}$. $i,j$ are constant. Doing it from definition doesn't seem workable. Any hint would be greatly appreciated. Orientation is external. I do not know Stoke's theorem yet. I know only basic facts connected with differential forms and some thorems about it working up to $\mathbb{R^3}$.",,"['integration', 'differential-geometry', 'differential-forms', 'orientation']"
9,Connection on the plane: examples?,Connection on the plane: examples?,,"I am having trouble understanding how to compute the connection on a manifold.  I see the definition $\nabla_ie_j=\Gamma^k_{ij}e_k$, but I am not sure if this equation is supposed to define $\nabla_i$ or $\Gamma$. If it defines $\Gamma$, then how is $\nabla_i$ defined? For instance, in his answer to question 270284 on MathOverflow, a user writes the equations \begin{align*} 	&\nabla_y {\bf e}_x = -{\bf e}_y; \quad \nabla_y {\bf e}_y = {\bf e}_x\\ 	&\nabla_x {\bf e}_x = \nabla_x {\bf e}_y =0 \end{align*}  Once I have these, I can work with them, but I don't understand what exactly they mean. Are the basis vectors ${\bf e}_x$ and ${\bf e}_y$ functions of $x,y$ that are being derivated? How are they related to the usual vectors $\partial_x$ and $\partial_y$? Can someone show me a choice of basis on the plane and its connection and how things are calculated, explicitly?","I am having trouble understanding how to compute the connection on a manifold.  I see the definition $\nabla_ie_j=\Gamma^k_{ij}e_k$, but I am not sure if this equation is supposed to define $\nabla_i$ or $\Gamma$. If it defines $\Gamma$, then how is $\nabla_i$ defined? For instance, in his answer to question 270284 on MathOverflow, a user writes the equations \begin{align*} 	&\nabla_y {\bf e}_x = -{\bf e}_y; \quad \nabla_y {\bf e}_y = {\bf e}_x\\ 	&\nabla_x {\bf e}_x = \nabla_x {\bf e}_y =0 \end{align*}  Once I have these, I can work with them, but I don't understand what exactly they mean. Are the basis vectors ${\bf e}_x$ and ${\bf e}_y$ functions of $x,y$ that are being derivated? How are they related to the usual vectors $\partial_x$ and $\partial_y$? Can someone show me a choice of basis on the plane and its connection and how things are calculated, explicitly?",,['differential-geometry']
10,Nonlinear parallel transport: preserving level sets of an arbitrary function,Nonlinear parallel transport: preserving level sets of an arbitrary function,,"Motivation: Consider a smooth vector bundle $\pi:E\to M$, a fiber metric $g$, and an affine connection $\nabla$ compatible with $g$. Then the parallel transport $\Pi_{\gamma,t_0,t}$ determined by $\nabla$ is an isometry of the fibers of $E$. Consider the smooth function $f:E\to \mathbb{R}$ on a vector bundle defined by $f(v):= g(v,v)$. In particular, parallel transport yields a smooth family of smooth maps $\Pi_{\gamma,t_0,t}:E_{\gamma(t_0)}\to E_{\gamma(t)}$ satisfying $$f \circ \Pi_{\gamma,t_0,t} = f,$$ for any path $\gamma:[t_0,t]\to M$. Question: Suppose that $\pi:E\to M$ is a smooth fiber bundle and $f:E\to \mathbb{R}$ is an arbitrary smooth function. When is it possible to find, for any path $\gamma:[t_0,t]\to M$ a smooth family of smooth maps $\Pi_{\gamma,t_0,t}:E_{\gamma(t_0)}\to E_{\gamma(t)}$ satisfying $$f \circ \Pi_{\gamma,t_0,t} = f?$$ I.e., are there natural conditions that may be imposed on $f$ to ensure that this is possible? Idea: If the level sets of $f$ are all manifolds and there exists a smooth Ehresmann connection on $E$ such that the corresponding horizontal bundle $\mathcal{H}$ is contained in the distribution $\ker df$, then I think the parallel transport determined by this connection would solve the problem. But it isn't clear to me when such an Ehresmann connection exists. Evidently such a (linear) Ehresmann connection exists for the case of $E$ a vector bundle and $f(v) = g(v,v)$ described above.","Motivation: Consider a smooth vector bundle $\pi:E\to M$, a fiber metric $g$, and an affine connection $\nabla$ compatible with $g$. Then the parallel transport $\Pi_{\gamma,t_0,t}$ determined by $\nabla$ is an isometry of the fibers of $E$. Consider the smooth function $f:E\to \mathbb{R}$ on a vector bundle defined by $f(v):= g(v,v)$. In particular, parallel transport yields a smooth family of smooth maps $\Pi_{\gamma,t_0,t}:E_{\gamma(t_0)}\to E_{\gamma(t)}$ satisfying $$f \circ \Pi_{\gamma,t_0,t} = f,$$ for any path $\gamma:[t_0,t]\to M$. Question: Suppose that $\pi:E\to M$ is a smooth fiber bundle and $f:E\to \mathbb{R}$ is an arbitrary smooth function. When is it possible to find, for any path $\gamma:[t_0,t]\to M$ a smooth family of smooth maps $\Pi_{\gamma,t_0,t}:E_{\gamma(t_0)}\to E_{\gamma(t)}$ satisfying $$f \circ \Pi_{\gamma,t_0,t} = f?$$ I.e., are there natural conditions that may be imposed on $f$ to ensure that this is possible? Idea: If the level sets of $f$ are all manifolds and there exists a smooth Ehresmann connection on $E$ such that the corresponding horizontal bundle $\mathcal{H}$ is contained in the distribution $\ker df$, then I think the parallel transport determined by this connection would solve the problem. But it isn't clear to me when such an Ehresmann connection exists. Evidently such a (linear) Ehresmann connection exists for the case of $E$ a vector bundle and $f(v) = g(v,v)$ described above.",,"['differential-geometry', 'reference-request', 'differential-topology']"
11,different definitions for $C^\infty(p)$,different definitions for,C^\infty(p),"I've seen in some books and notes that in order to define the tangent vector $v:C^\infty(p)\to\mathbb R$, the author defines $C^\infty(p)$ as the set of all real valued functions $f:M\to\mathbb R$ such that does there exist an open set $U\subseteq M$ containing $p$ and $f|_U$ is smooth and then defines a tangent vector as a map $v:C^\infty(p)\to\mathbb R$ such that for all $f,g\in C^\infty(p)$ and $a,b\in\mathbb R$, $$v(af+bg)=av(f)+bv(g)\\ v(fg)=f(p)v(g)+v(f)g(p).$$ So why we really need to insert smooth functions which are agree on some smaller open set containing $p$ in an equivalence class and define $C^\infty(p)$ as the set of these equivalence classes? And then define a tangent vector as the map $v:C^\infty(p)\to\mathbb R$ such that for all $[f],[g]\in C^\infty(p)$and $a,b\in\mathbb R$, $$v[af+bg]=av[f]+bv[g]\\ v[fg]=f(p)v[g]+v[f]g(p)?$$ What are differences between first and second $C^\infty(p)$? Is the first definition a standard definition?","I've seen in some books and notes that in order to define the tangent vector $v:C^\infty(p)\to\mathbb R$, the author defines $C^\infty(p)$ as the set of all real valued functions $f:M\to\mathbb R$ such that does there exist an open set $U\subseteq M$ containing $p$ and $f|_U$ is smooth and then defines a tangent vector as a map $v:C^\infty(p)\to\mathbb R$ such that for all $f,g\in C^\infty(p)$ and $a,b\in\mathbb R$, $$v(af+bg)=av(f)+bv(g)\\ v(fg)=f(p)v(g)+v(f)g(p).$$ So why we really need to insert smooth functions which are agree on some smaller open set containing $p$ in an equivalence class and define $C^\infty(p)$ as the set of these equivalence classes? And then define a tangent vector as the map $v:C^\infty(p)\to\mathbb R$ such that for all $[f],[g]\in C^\infty(p)$and $a,b\in\mathbb R$, $$v[af+bg]=av[f]+bv[g]\\ v[fg]=f(p)v[g]+v[f]g(p)?$$ What are differences between first and second $C^\infty(p)$? Is the first definition a standard definition?",,"['differential-geometry', 'differential-topology']"
12,Covariant derivative of tensor densities,Covariant derivative of tensor densities,,"Note: This post is intended to be about Ricci-calculus. My definition of tensor densities in this post makes a scalar density of weight 1 essentially equivalent to a maximal-degree differential form, so answers along the line of modern differential geometry are almost useless to me here. Given an $n$ dimensional real $C^\infty$ manifold $M$, I hereby define a scalar density of weight 1, $\rho$, at $p\in M$ as a rule that assigns to any local chart containing $p$ a real number with the understanding that during coordinate change, this number transforms as $$ \rho'=\det\frac{\partial x}{\partial x'}\ \rho. $$ Let $\nabla_\mu$ be a linear connection that acts on vector fields in a local trivialization as $$ \nabla_\mu X^\nu=\partial_\mu X^\nu+C^\nu_{\mu\sigma}X^\sigma. $$ Linear connections are induced by $\nabla$ on the cotangent bundle and the tensor bundles by the natural conditions that $\nabla$ should commute with contractions and obey the Leibniz rule with respect to tensor products. Since scalar densities of weight 1 at different points, we also need to introduce a connection on the density bundle, given in a local trivialization as $$ \nabla_\mu\rho=\partial_\mu\rho+C_\mu\rho, $$ this $C_\mu$ is a priori independent of $C^\nu_{\mu\rho}$. Now, we can check that during coordinate change, $C_\mu$ transforms as $$ C_\mu'=\frac{\partial x^\mu}{\partial x^{\mu'}}C_\mu-\frac{\partial^2x^\nu}{\partial x^{\mu'}\partial x^{\nu'}}\frac{\partial x^{\nu'}}{\partial x^\nu}, $$ and this is the same as the transformation rule for $-C^\nu_{\mu\nu}$, so one natural way to extend the connection in the tangent bundle to a connection in the density bundle is to define $C_\mu=-C_{\mu\nu}^{\nu}$, however this approach relies a lot on transformation rules, and I don't like it. One other natural condition would be to abuse the relationship between scalar densities and differential forms, as the density $\rho$ corresponds to the differential form $\rho_{\mu_1,...,\mu_n}=\rho\pi_{\mu_1,...,\mu_n}$, where $\pi$ is Levi-Civita's symbol. Then the natural condition is to demand that $\nabla_\nu\rho_{\mu_1...\mu_n}=(\nabla_\nu\rho)\pi_{\mu_1,...,\mu_n}$. I tried to check this, but this quickly became untractable as $$ \nabla_\nu\rho_{\mu_1...\mu_n}=(\partial_\nu\rho)\pi_{\mu_1...\mu_n}-\rho\left\{C^\sigma_{\nu\mu_1}\pi_{\sigma\mu_2...\mu_n}+...+C^\sigma_{\nu\mu_n}\pi_{\mu_1...\mu_{n-1}\sigma}\right\}, $$ and I have no clue how to evaluate the terms in the curly brackets. Question: Would this latter definition of the covariant derivative of a scalar density of weight 1 reduce to the $C_\mu=-C_{\mu\nu}^\nu$ relation implied by the transformation properties? If so, I would be terribly appreciative of any pointers as to how to perform the calculation that shows this. I tried using several identities and meanings related to the Levi-Civita symbol but nothing simplified the curly bracket.","Note: This post is intended to be about Ricci-calculus. My definition of tensor densities in this post makes a scalar density of weight 1 essentially equivalent to a maximal-degree differential form, so answers along the line of modern differential geometry are almost useless to me here. Given an $n$ dimensional real $C^\infty$ manifold $M$, I hereby define a scalar density of weight 1, $\rho$, at $p\in M$ as a rule that assigns to any local chart containing $p$ a real number with the understanding that during coordinate change, this number transforms as $$ \rho'=\det\frac{\partial x}{\partial x'}\ \rho. $$ Let $\nabla_\mu$ be a linear connection that acts on vector fields in a local trivialization as $$ \nabla_\mu X^\nu=\partial_\mu X^\nu+C^\nu_{\mu\sigma}X^\sigma. $$ Linear connections are induced by $\nabla$ on the cotangent bundle and the tensor bundles by the natural conditions that $\nabla$ should commute with contractions and obey the Leibniz rule with respect to tensor products. Since scalar densities of weight 1 at different points, we also need to introduce a connection on the density bundle, given in a local trivialization as $$ \nabla_\mu\rho=\partial_\mu\rho+C_\mu\rho, $$ this $C_\mu$ is a priori independent of $C^\nu_{\mu\rho}$. Now, we can check that during coordinate change, $C_\mu$ transforms as $$ C_\mu'=\frac{\partial x^\mu}{\partial x^{\mu'}}C_\mu-\frac{\partial^2x^\nu}{\partial x^{\mu'}\partial x^{\nu'}}\frac{\partial x^{\nu'}}{\partial x^\nu}, $$ and this is the same as the transformation rule for $-C^\nu_{\mu\nu}$, so one natural way to extend the connection in the tangent bundle to a connection in the density bundle is to define $C_\mu=-C_{\mu\nu}^{\nu}$, however this approach relies a lot on transformation rules, and I don't like it. One other natural condition would be to abuse the relationship between scalar densities and differential forms, as the density $\rho$ corresponds to the differential form $\rho_{\mu_1,...,\mu_n}=\rho\pi_{\mu_1,...,\mu_n}$, where $\pi$ is Levi-Civita's symbol. Then the natural condition is to demand that $\nabla_\nu\rho_{\mu_1...\mu_n}=(\nabla_\nu\rho)\pi_{\mu_1,...,\mu_n}$. I tried to check this, but this quickly became untractable as $$ \nabla_\nu\rho_{\mu_1...\mu_n}=(\partial_\nu\rho)\pi_{\mu_1...\mu_n}-\rho\left\{C^\sigma_{\nu\mu_1}\pi_{\sigma\mu_2...\mu_n}+...+C^\sigma_{\nu\mu_n}\pi_{\mu_1...\mu_{n-1}\sigma}\right\}, $$ and I have no clue how to evaluate the terms in the curly brackets. Question: Would this latter definition of the covariant derivative of a scalar density of weight 1 reduce to the $C_\mu=-C_{\mu\nu}^\nu$ relation implied by the transformation properties? If so, I would be terribly appreciative of any pointers as to how to perform the calculation that shows this. I tried using several identities and meanings related to the Levi-Civita symbol but nothing simplified the curly bracket.",,"['differential-geometry', 'tensors', 'connections']"
13,How Ricci Flow makes room to find Enistein metrics?,How Ricci Flow makes room to find Enistein metrics?,,"I am studding a lecture note entitled ""Topics in Riemanian Geometry"" by Jeff. Viaclovsky. See the below phrase  in lecture 12: ""In order to find Einstein metrics, one would first think of looking at the gradient Ricci flow on the space of Riemannian metrics. This is \begin{equation} {{\partial g}\over {\partial t}}=-2Ric_g, \quad g_0=g(0). \end{equation} I want know the idea behind this flow, and how the flow makes room to obtain an Einstein metric on underlying manifold?","I am studding a lecture note entitled ""Topics in Riemanian Geometry"" by Jeff. Viaclovsky. See the below phrase  in lecture 12: ""In order to find Einstein metrics, one would first think of looking at the gradient Ricci flow on the space of Riemannian metrics. This is \begin{equation} {{\partial g}\over {\partial t}}=-2Ric_g, \quad g_0=g(0). \end{equation} I want know the idea behind this flow, and how the flow makes room to obtain an Einstein metric on underlying manifold?",,['differential-geometry']
14,Recovering the Lie derivative of a covector from Cartan's formula on 1-forms,Recovering the Lie derivative of a covector from Cartan's formula on 1-forms,,"The coordinate expression of the Lie derivative of a covector field, $w$ with respect to a vector field $X$ is given by: $$ \mathcal{L}_{X}w = \left(X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}} + w_{\alpha}\frac{\partial X^{\alpha}}{\partial x^{\mu}}\right)\mathrm{d}x^{\mu} $$ But since a covector is also a 1-form, this should be recoverable using Cartan's formula: $$ \mathcal{L}_{X}w = \left(\mathrm{d}\iota_{X} + \iota_{X}\mathrm{d}\right)w $$ where $\mathrm{d}$ is the external derivative and $\iota_{X}$ is the internal produce with respect to $X$. However, when I expand Cartan's formula, I get: $$\begin{align} \left(\mathrm{d}\iota_{X} + \iota_{X}\mathrm{d}\right)w_{\mu}\mathrm{d}x^{\mu} &= \left(\frac{\partial X^{\alpha}w_{\alpha}}{\partial x^{\mu}} + X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}}\right)\mathrm{d}x^{\mu} \\ &= \left(w_{\alpha}\frac{\partial X^{\alpha}}{\partial x^{\mu}} + X^{\alpha}\frac{\partial w_{\alpha}}{\partial x^{\mu}} + X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}}\right)\mathrm{d}x^{\mu} \\ &= \left(X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}} + w_{\alpha}\frac{\partial X^{\alpha}}{\partial x^{\mu}}\right)\mathrm{d}x^{\mu} + X^{\alpha}\frac{\partial w_{\alpha}}{\partial x^{\mu}}\mathrm{d}x^{\mu}\\ &= \mathcal{L}_{X}w + X^{\alpha}\mathrm{d}w_{\alpha}\\ \end{align}$$ Most likely I've done something wrong (the extra term comes from the product rule on $\frac{\partial X^{\alpha}w_{\alpha}}{\partial x^{\mu}}$, but I'm not sure this the correct way to treat the gradient of $X^{\alpha}w_{\alpha}$), or there's some reason that $X^{\alpha}\mathrm{d}w_{\alpha}$ vanishes. $X^{\alpha}$ and $w_{\alpha}$ are in general not zero, so that implies the components of $w$ are closed, so: $$ \mathrm{d}w_{\alpha} = 0 $$ but I can't think of any way to justify this, since in general they're just functions on a manifold and functions aren't necessarily closed (are they?).","The coordinate expression of the Lie derivative of a covector field, $w$ with respect to a vector field $X$ is given by: $$ \mathcal{L}_{X}w = \left(X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}} + w_{\alpha}\frac{\partial X^{\alpha}}{\partial x^{\mu}}\right)\mathrm{d}x^{\mu} $$ But since a covector is also a 1-form, this should be recoverable using Cartan's formula: $$ \mathcal{L}_{X}w = \left(\mathrm{d}\iota_{X} + \iota_{X}\mathrm{d}\right)w $$ where $\mathrm{d}$ is the external derivative and $\iota_{X}$ is the internal produce with respect to $X$. However, when I expand Cartan's formula, I get: $$\begin{align} \left(\mathrm{d}\iota_{X} + \iota_{X}\mathrm{d}\right)w_{\mu}\mathrm{d}x^{\mu} &= \left(\frac{\partial X^{\alpha}w_{\alpha}}{\partial x^{\mu}} + X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}}\right)\mathrm{d}x^{\mu} \\ &= \left(w_{\alpha}\frac{\partial X^{\alpha}}{\partial x^{\mu}} + X^{\alpha}\frac{\partial w_{\alpha}}{\partial x^{\mu}} + X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}}\right)\mathrm{d}x^{\mu} \\ &= \left(X^{\alpha}\frac{\partial w_{\mu}}{\partial x^{\alpha}} + w_{\alpha}\frac{\partial X^{\alpha}}{\partial x^{\mu}}\right)\mathrm{d}x^{\mu} + X^{\alpha}\frac{\partial w_{\alpha}}{\partial x^{\mu}}\mathrm{d}x^{\mu}\\ &= \mathcal{L}_{X}w + X^{\alpha}\mathrm{d}w_{\alpha}\\ \end{align}$$ Most likely I've done something wrong (the extra term comes from the product rule on $\frac{\partial X^{\alpha}w_{\alpha}}{\partial x^{\mu}}$, but I'm not sure this the correct way to treat the gradient of $X^{\alpha}w_{\alpha}$), or there's some reason that $X^{\alpha}\mathrm{d}w_{\alpha}$ vanishes. $X^{\alpha}$ and $w_{\alpha}$ are in general not zero, so that implies the components of $w$ are closed, so: $$ \mathrm{d}w_{\alpha} = 0 $$ but I can't think of any way to justify this, since in general they're just functions on a manifold and functions aren't necessarily closed (are they?).",,"['differential-geometry', 'exterior-algebra']"
15,"Finding the de Rham Cohomology group of $\mathbb{S}^2\backslash \{a,b,c\}$.",Finding the de Rham Cohomology group of .,"\mathbb{S}^2\backslash \{a,b,c\}","I am trying to understand how to compute the de Rham cohomology group. Could someone show me how I would find the cohomology group of $\mathbb{S}^2\backslash\{n\text{ points of } \mathbb{S}^2 \}$. I know I should find the de Rham cohomology group for $n=1,2,3,4,..$ till I see a pattern. However, I have little experience doing this and can't find a good example I could follow. Could someone show me how to compute these for several n-values?","I am trying to understand how to compute the de Rham cohomology group. Could someone show me how I would find the cohomology group of $\mathbb{S}^2\backslash\{n\text{ points of } \mathbb{S}^2 \}$. I know I should find the de Rham cohomology group for $n=1,2,3,4,..$ till I see a pattern. However, I have little experience doing this and can't find a good example I could follow. Could someone show me how to compute these for several n-values?",,"['differential-geometry', 'homology-cohomology']"
16,Values of $t \in \mathbb{R}$ for which $f^{-1}(t)$ is an embedded submanifold,Values of  for which  is an embedded submanifold,t \in \mathbb{R} f^{-1}(t),"Let $f:\mathbb{R^3} \to \mathbb{R}$ be defined by $f(x,y,z)=(x-1)^2-yz$. For what values of $t \in \mathbb{R}$, is $f^{-1}(t)$ an embedded submanifold of $\mathbb{R^3}$ of dimension $2$? The Jacobian of this function is of the form $[2x-2,-z,-y]$. The jacobian has full rank unless $x=1,y=0$ and $z=0$. Also $f(1,0,0)=0$. Thus I have to look at $f^{-1}(t)$ for $t=0$. Now the hessian matrix at $t=0$ is of the form $$\begin{bmatrix} 2 & 0 & 0\\ 0 & 0 & -1\\ 0 & -1 & 0\\ \end{bmatrix}$$ Let $D_1=2, D_2=\begin{bmatrix} 2 & 0 \\ 0 & 0 \\ \end{bmatrix},D_3=\begin{bmatrix} 2 & 0 & 0\\ 0 & 0 & -1\\ 0 & -1 & 0\\ \end{bmatrix}$. Then $|D_1|=2, |D_2|=0,|D_3| \ne 0$. Hence $(1,0,0)$ is a saddle point. Thus $f^{-1}(t)$ is an embedded submanifold except for when $t=0$. Is this alright? Thanks for the help!!","Let $f:\mathbb{R^3} \to \mathbb{R}$ be defined by $f(x,y,z)=(x-1)^2-yz$. For what values of $t \in \mathbb{R}$, is $f^{-1}(t)$ an embedded submanifold of $\mathbb{R^3}$ of dimension $2$? The Jacobian of this function is of the form $[2x-2,-z,-y]$. The jacobian has full rank unless $x=1,y=0$ and $z=0$. Also $f(1,0,0)=0$. Thus I have to look at $f^{-1}(t)$ for $t=0$. Now the hessian matrix at $t=0$ is of the form $$\begin{bmatrix} 2 & 0 & 0\\ 0 & 0 & -1\\ 0 & -1 & 0\\ \end{bmatrix}$$ Let $D_1=2, D_2=\begin{bmatrix} 2 & 0 \\ 0 & 0 \\ \end{bmatrix},D_3=\begin{bmatrix} 2 & 0 & 0\\ 0 & 0 & -1\\ 0 & -1 & 0\\ \end{bmatrix}$. Then $|D_1|=2, |D_2|=0,|D_3| \ne 0$. Hence $(1,0,0)$ is a saddle point. Thus $f^{-1}(t)$ is an embedded submanifold except for when $t=0$. Is this alright? Thanks for the help!!",,"['differential-geometry', 'proof-verification', 'manifolds', 'differential-topology', 'smooth-manifolds']"
17,Calculate the area of a pixel on a sphere,Calculate the area of a pixel on a sphere,,"Given an photographical image of a sphere, i.e. an circle with radius $r$ quantized into uniform, square pixels, how can one calculate the equivalent area of the sphere covered by each pixel? I'm assuming that the projection is parallel. Example:  Let a sphere of radius $R = 1$ be projected to a circle with a radius of $r = 100\,\mathrm{px}$, where the center of the sphere is the center of the middle pixel $(50, 50)$ in the image. Basically I'm interested in the reverse projection from the pixel space to the sphere. I guess I have to cast rays from the corners of the pixel onto the sphere and from those four points get the area of the sphere in the section that is encased in the four points.","Given an photographical image of a sphere, i.e. an circle with radius $r$ quantized into uniform, square pixels, how can one calculate the equivalent area of the sphere covered by each pixel? I'm assuming that the projection is parallel. Example:  Let a sphere of radius $R = 1$ be projected to a circle with a radius of $r = 100\,\mathrm{px}$, where the center of the sphere is the center of the middle pixel $(50, 50)$ in the image. Basically I'm interested in the reverse projection from the pixel space to the sphere. I guess I have to cast rays from the corners of the pixel onto the sphere and from those four points get the area of the sphere in the section that is encased in the four points.",,"['geometry', 'differential-geometry', 'projective-geometry', 'spheres']"
18,"Gauss Bonnet theorem, degree of surface with genus","Gauss Bonnet theorem, degree of surface with genus",,"I'm reading Frankel's The Geometry of Physics and I have been trying to understand the proof of the Gauss Bonnet theorem but I'm stucked with one part of the proof that is left as an exercise. I have arrived until $$\frac{1}{4\pi}\int\int K dS = deg(n: M^{2} \rightarrow S^{2})$$ with $K$ the curvature and the right part the (Brouwer) degree of the Gauss normal map. What I don't know is how to prove that the degree of the map in case of a surface of genus $g$ ($g$ holes) would be $1 - g$, so: $$\frac{1}{4\pi}\int\int K dS = 1 - g$$ As an extra, could you suggest a reference to read a proof of the Gauss Bonnet for physicists? Thanks.","I'm reading Frankel's The Geometry of Physics and I have been trying to understand the proof of the Gauss Bonnet theorem but I'm stucked with one part of the proof that is left as an exercise. I have arrived until $$\frac{1}{4\pi}\int\int K dS = deg(n: M^{2} \rightarrow S^{2})$$ with $K$ the curvature and the right part the (Brouwer) degree of the Gauss normal map. What I don't know is how to prove that the degree of the map in case of a surface of genus $g$ ($g$ holes) would be $1 - g$, so: $$\frac{1}{4\pi}\int\int K dS = 1 - g$$ As an extra, could you suggest a reference to read a proof of the Gauss Bonnet for physicists? Thanks.",,"['differential-geometry', 'algebraic-topology', 'mathematical-physics']"
19,Cylinder Gaussian Curvature,Cylinder Gaussian Curvature,,"The question is as follows.  Imagine we have two closed geodesics on a surface, where these two geodesics bound a cylinder together and the geodesics are diffeomorphic to circles.  Can the cylinder have $K>0$ everywhere or $K<0$ everywhere?  Here $K$ is Gaussian Curvature. What's confusing me about this question is that a cylinder has Gaussian Curvature of $K=0$ everywhere, so wouldn't the answer to both questions be no?  But then I don't get the point of the question with the geodesics. Thank you in advance","The question is as follows.  Imagine we have two closed geodesics on a surface, where these two geodesics bound a cylinder together and the geodesics are diffeomorphic to circles.  Can the cylinder have $K>0$ everywhere or $K<0$ everywhere?  Here $K$ is Gaussian Curvature. What's confusing me about this question is that a cylinder has Gaussian Curvature of $K=0$ everywhere, so wouldn't the answer to both questions be no?  But then I don't get the point of the question with the geodesics. Thank you in advance",,"['differential-geometry', 'geodesic']"
20,"Given a point in a manifold, what points of a submanifold are closest to it?","Given a point in a manifold, what points of a submanifold are closest to it?",,"Note: I'm still relatively new to studying differential / Riemannian geometry so I'm not sure if my problem is well posed or not. Any reference materials to point me to the right direction would be greatly appreciated! Suppose we have some ambient Riemannian manifold $(M,g)$ and we have some submanifold $S$ of it. I know that up to conditions and definitions, if one specifies two points $p$ and $q$ of $M$, one can find a minimizing geodesic between them. Question : But suppose we are given only one point $p \in M \setminus S$. Can one ask which point $q \in S$ is ""closest"" to $p$? And where ""closest"" is taken to mean the smallest arc length of its geodesics? Can somebody please point me to some references on this question (assuming it is well posed)?","Note: I'm still relatively new to studying differential / Riemannian geometry so I'm not sure if my problem is well posed or not. Any reference materials to point me to the right direction would be greatly appreciated! Suppose we have some ambient Riemannian manifold $(M,g)$ and we have some submanifold $S$ of it. I know that up to conditions and definitions, if one specifies two points $p$ and $q$ of $M$, one can find a minimizing geodesic between them. Question : But suppose we are given only one point $p \in M \setminus S$. Can one ask which point $q \in S$ is ""closest"" to $p$? And where ""closest"" is taken to mean the smallest arc length of its geodesics? Can somebody please point me to some references on this question (assuming it is well posed)?",,"['differential-geometry', 'reference-request', 'riemannian-geometry']"
21,Obtaining higher order terms of the Baker-Campbell-Hausdorff formula as higher order commutators,Obtaining higher order terms of the Baker-Campbell-Hausdorff formula as higher order commutators,,"Let $G$ be a Lie group, then $(X,Y) \mapsto \log(\exp(X)\exp(Y))$ locally defines a group law on a neighbourhood of  $0 \in T_eG$. This local group law is analytic, and the first term is given by $X + Y$ and the second by $\frac{1}{2}[X,Y]$. According to Tits' textbook on Lie groups the Lie bracket may be obtained as the second order derivative of $G \times G \to G, \; (x,y) \mapsto xyx^{-1}y^{-1}$. (This is well-defined, because the first derivative of $(x,y) \mapsto xyx^{-1}y^{-1}$ vanishes.) My question is then: Are there maps $\pi_r: G \times G \to G$ for every $r \in \mathbb{N}$ such that $d^k \pi_r$ vanishes for all $k < r$ (so that we obtain a well defined $r$-linear form $d^r \pi_r: T_eG \times \underbrace{\dots}_{2 r\, \times} \times T_eG \to T_eG$), such that the $r$-th term in the Baker-Campbell-Hausdorff formula is given by $\frac{1}{r!}d^r \pi_r$? Furthermore, can the maps $\pi_r$ be constructed from the multiplication and inverse maps on $G$?","Let $G$ be a Lie group, then $(X,Y) \mapsto \log(\exp(X)\exp(Y))$ locally defines a group law on a neighbourhood of  $0 \in T_eG$. This local group law is analytic, and the first term is given by $X + Y$ and the second by $\frac{1}{2}[X,Y]$. According to Tits' textbook on Lie groups the Lie bracket may be obtained as the second order derivative of $G \times G \to G, \; (x,y) \mapsto xyx^{-1}y^{-1}$. (This is well-defined, because the first derivative of $(x,y) \mapsto xyx^{-1}y^{-1}$ vanishes.) My question is then: Are there maps $\pi_r: G \times G \to G$ for every $r \in \mathbb{N}$ such that $d^k \pi_r$ vanishes for all $k < r$ (so that we obtain a well defined $r$-linear form $d^r \pi_r: T_eG \times \underbrace{\dots}_{2 r\, \times} \times T_eG \to T_eG$), such that the $r$-th term in the Baker-Campbell-Hausdorff formula is given by $\frac{1}{r!}d^r \pi_r$? Furthermore, can the maps $\pi_r$ be constructed from the multiplication and inverse maps on $G$?",,"['differential-geometry', 'manifolds', 'lie-groups', 'lie-algebras', 'analyticity']"
22,Strict inclusion of tori implies strictly inequality on dimensions,Strict inclusion of tori implies strictly inequality on dimensions,,"I'm looking for a formalisation of the following statement (from Bröcker and tom Dieck's book on the representations of compact groups, page 157). Suppose $T$ and $T'$ are tori in the compact Lie group $G$: ""Since tori are compact and connected, if $T\subsetneq T'$, then dim $T < $ dim $T'$."" I can see intuitively why this statement might be true, but how does one prove it?","I'm looking for a formalisation of the following statement (from Bröcker and tom Dieck's book on the representations of compact groups, page 157). Suppose $T$ and $T'$ are tori in the compact Lie group $G$: ""Since tori are compact and connected, if $T\subsetneq T'$, then dim $T < $ dim $T'$."" I can see intuitively why this statement might be true, but how does one prove it?",,"['differential-geometry', 'lie-groups']"
23,Walking on a torus minimum distance,Walking on a torus minimum distance,,"I was imagining a problem, about a torus (in general a well behaved 3D object). Let us pick two arbitrary non-identical points $A$ and $B$ on the surface of the torus. How would I calculate the shortest path connecting both points? I don't know how to start this problem. I think I need to calculate the length of a path in 3D parametrized by $\boldsymbol{c}(t)$ ($\boldsymbol{c}(t=0)=A$,$\boldsymbol{c}(t=1)=B$) and then add the surface of the torus via Lagrange Multipliers. $$L=\int_{t=0}^{t=1}||\boldsymbol{c}(t)||dt+\lambda F,$$ in which $F$ would be the equation describing the surface of the Torus. Would that be an appropriate approach? I think that it would be necessary to pick a different coordinate system (e.g. torus coordinates). I know that the solution is not always unique.","I was imagining a problem, about a torus (in general a well behaved 3D object). Let us pick two arbitrary non-identical points $A$ and $B$ on the surface of the torus. How would I calculate the shortest path connecting both points? I don't know how to start this problem. I think I need to calculate the length of a path in 3D parametrized by $\boldsymbol{c}(t)$ ($\boldsymbol{c}(t=0)=A$,$\boldsymbol{c}(t=1)=B$) and then add the surface of the torus via Lagrange Multipliers. $$L=\int_{t=0}^{t=1}||\boldsymbol{c}(t)||dt+\lambda F,$$ in which $F$ would be the equation describing the surface of the Torus. Would that be an appropriate approach? I think that it would be necessary to pick a different coordinate system (e.g. torus coordinates). I know that the solution is not always unique.",,"['calculus', 'differential-geometry', 'optimization']"
24,"Critical points for a smooth function defined on a manifold - Milnor, Morse theory","Critical points for a smooth function defined on a manifold - Milnor, Morse theory",,"I need some help with a statement from Milnor's Morse theory book! While studying the proof of a theorem I got stuck. That's what we know:  Let $f$ be a differentiable function on a manifold $M$ with no degenerate critical points, and so that for all $a \in \mathbb{R}$,  $M^{a}=\{p\in M: f(p)\leq a\}$ is compact. The author says: "" Let $c_{1}<c_{2}<c_{3}<...$ be the critical values of $f:M \rightarrow \mathbb{R}$. The sequence $\{c_{i}\}$ has no cluster point since each $M^{a}$ is compact. The set $M^{a}$ is vacuous for $a<c_{1}...$"" I proved that the set of critical values of $f$ is countable and that exists a minimum. Then I showed that the mentioned sequence has non cluster point but I did not manage in showing that he set ""$M^{a}$ is vacuous for $a<c_{1}...$"". What I used to show the first two statement are essentially: the fact that non degenerate critical points for a smooth real valued function on a manifold are isolated(consequence of Morse's lemma), the regularity of the function $f$ and the compactness of $M$. I thought of showing the last observation by a ""proof by contradiction"" supposing it exists an $a\in \mathbb{R}$ for which $M^{a}$ is not vacuous and $a<c_{1}$ and then finding a critical point for $f$: $p\in M^{a}$, leading to a contradiction. I did not really get so far in that...Do you have any hints? Suggestions? Thanks","I need some help with a statement from Milnor's Morse theory book! While studying the proof of a theorem I got stuck. That's what we know:  Let $f$ be a differentiable function on a manifold $M$ with no degenerate critical points, and so that for all $a \in \mathbb{R}$,  $M^{a}=\{p\in M: f(p)\leq a\}$ is compact. The author says: "" Let $c_{1}<c_{2}<c_{3}<...$ be the critical values of $f:M \rightarrow \mathbb{R}$. The sequence $\{c_{i}\}$ has no cluster point since each $M^{a}$ is compact. The set $M^{a}$ is vacuous for $a<c_{1}...$"" I proved that the set of critical values of $f$ is countable and that exists a minimum. Then I showed that the mentioned sequence has non cluster point but I did not manage in showing that he set ""$M^{a}$ is vacuous for $a<c_{1}...$"". What I used to show the first two statement are essentially: the fact that non degenerate critical points for a smooth real valued function on a manifold are isolated(consequence of Morse's lemma), the regularity of the function $f$ and the compactness of $M$. I thought of showing the last observation by a ""proof by contradiction"" supposing it exists an $a\in \mathbb{R}$ for which $M^{a}$ is not vacuous and $a<c_{1}$ and then finding a critical point for $f$: $p\in M^{a}$, leading to a contradiction. I did not really get so far in that...Do you have any hints? Suggestions? Thanks",,"['general-topology', 'differential-geometry', 'differential-topology', 'morse-theory']"
25,Local coordinates for rotation manifold SO(3),Local coordinates for rotation manifold SO(3),,"My major is mechanical engineering. Recently, I am working on some subject involving three-dimensional finite rotations. When I read the chapter titled "" Charts on SO(3) "" in Wikipedia and math books about smooth manifolds (e.g., Introduction to smooth manifolds, 2nd edition, by JM Lee). I got trouble to understand the following basic concept: A coordinate chart on $M$ is a pair $(U,\phi)$, where $U$ is an open   set of $M$, and $\phi: U\to \hat U$ is a homeomorphism from $U$ to an   open set $\hat U=\phi (U)\subseteq \mathbb R^{n}$. Does that mean the space $\hat U$ of parameters (local coordinates) should always be an Euclidean space $\mathbb R^{n}$? Taking SO(3) as an example, if we choose the Euler angles as the local coordinates, I can figue out how to establish the map $\phi$, however, as far as I know, the space of parameters (the set of Euler angles in this case) is not an Euclidean space. So, where am I misunderstanding? This question bothers me for a while. Please help me, thank you very much!","My major is mechanical engineering. Recently, I am working on some subject involving three-dimensional finite rotations. When I read the chapter titled "" Charts on SO(3) "" in Wikipedia and math books about smooth manifolds (e.g., Introduction to smooth manifolds, 2nd edition, by JM Lee). I got trouble to understand the following basic concept: A coordinate chart on $M$ is a pair $(U,\phi)$, where $U$ is an open   set of $M$, and $\phi: U\to \hat U$ is a homeomorphism from $U$ to an   open set $\hat U=\phi (U)\subseteq \mathbb R^{n}$. Does that mean the space $\hat U$ of parameters (local coordinates) should always be an Euclidean space $\mathbb R^{n}$? Taking SO(3) as an example, if we choose the Euler angles as the local coordinates, I can figue out how to establish the map $\phi$, however, as far as I know, the space of parameters (the set of Euler angles in this case) is not an Euclidean space. So, where am I misunderstanding? This question bothers me for a while. Please help me, thank you very much!",,"['differential-geometry', 'smooth-manifolds']"
26,Is the hyperboloid model conformal?,Is the hyperboloid model conformal?,,"Consider (one sheet of) a hyperboloid of two sheets embedded in Euclidean $\mathbb{R}^3$. There are at least two natural geometric structures on this surface: The intrinsic geometry inherited from the embedding in $\mathbb{R}^3$. The hyperboloid model of the hyperbolic plane. The hyperboloid sits in a unique cone in $\mathbb{R}^3$ and the geodesics of this model are the intersections of the hyperboloid with Euclidean planes through the apex of the cone. Question: Given two intersecting geodesics in the hyperboloid model, the angle between them can be measured using either of the metrics 1 or 2. Do these two measurements coincide? Bonus Question: What do the ""circles"" of metric 2 look like in terms of metric 1?","Consider (one sheet of) a hyperboloid of two sheets embedded in Euclidean $\mathbb{R}^3$. There are at least two natural geometric structures on this surface: The intrinsic geometry inherited from the embedding in $\mathbb{R}^3$. The hyperboloid model of the hyperbolic plane. The hyperboloid sits in a unique cone in $\mathbb{R}^3$ and the geodesics of this model are the intersections of the hyperboloid with Euclidean planes through the apex of the cone. Question: Given two intersecting geodesics in the hyperboloid model, the angle between them can be measured using either of the metrics 1 or 2. Do these two measurements coincide? Bonus Question: What do the ""circles"" of metric 2 look like in terms of metric 1?",,"['differential-geometry', 'hyperbolic-geometry']"
27,Changing a Differential Form into Spherical Polars,Changing a Differential Form into Spherical Polars,,"I am currently trying to integrate:$$\omega_{a,b,c} = \frac{(x-a)dy\wedge dz+(y-b)dz\wedge dx+(z-c)dx\wedge dy}{[(x-a)^2+(y-b)^2+(z-c)^2]^{3/2}}$$ over the unit sphere centered at $(a,b,c)$, with the standard orientation. I am supposed to show that this integral gives $-4\pi$. I am confused by how the spherical coord system of this differential form would look. I know that the form replacing $(x-a)$ with $x$, same with $y$ and $z$ gives: $$\sin\phi\, d\theta\wedge d\phi$$Am I allowed to use the same parametrization? Or would this give a completely different parametrization? I am looking for a way without using Stokes' Theorem, as this is required for another part of the question. Thank you.","I am currently trying to integrate:$$\omega_{a,b,c} = \frac{(x-a)dy\wedge dz+(y-b)dz\wedge dx+(z-c)dx\wedge dy}{[(x-a)^2+(y-b)^2+(z-c)^2]^{3/2}}$$ over the unit sphere centered at $(a,b,c)$, with the standard orientation. I am supposed to show that this integral gives $-4\pi$. I am confused by how the spherical coord system of this differential form would look. I know that the form replacing $(x-a)$ with $x$, same with $y$ and $z$ gives: $$\sin\phi\, d\theta\wedge d\phi$$Am I allowed to use the same parametrization? Or would this give a completely different parametrization? I am looking for a way without using Stokes' Theorem, as this is required for another part of the question. Thank you.",,"['integration', 'differential-geometry', 'manifolds', 'differential-forms', 'stokes-theorem']"
28,Advanced mathematics in stringed instrument industry,Advanced mathematics in stringed instrument industry,,"This is a soft question. I play classical guitar and I find stringed instrument industry a very fascinating art. I know that, at least for classical guitar, this industry is still developing and exploring new techniques, so it is a very alive research field. I know that it must involve at least some basic mathematics, but I was wondering if anyone has tried to apply deep mathematical tools and concepts in this field, for example from geometric analysis. On the other hand I guess that these techniques could inspire very interesting mathematical questions. What is the state of art of the interaction between maths and stringed instrument industry?","This is a soft question. I play classical guitar and I find stringed instrument industry a very fascinating art. I know that, at least for classical guitar, this industry is still developing and exploring new techniques, so it is a very alive research field. I know that it must involve at least some basic mathematics, but I was wondering if anyone has tried to apply deep mathematical tools and concepts in this field, for example from geometric analysis. On the other hand I guess that these techniques could inspire very interesting mathematical questions. What is the state of art of the interaction between maths and stringed instrument industry?",,"['differential-geometry', 'partial-differential-equations', 'soft-question', 'applications', 'music-theory']"
29,How to find the projection of $x^2+y^2+z^2+2xyz=1$ on $S^2$?,How to find the projection of  on ?,x^2+y^2+z^2+2xyz=1 S^2,"The primary problem is to find the singular points of $g$ when $g$ defines on $S^2$ that $g:S^2 \rightarrow R^3,(x,y,z)\rightarrow(yz-x,zx-y,xy-z)$. $Note:$The singular point in the problem is the point when the rank of $dg_{p}：T_p S^2 \rightarrow T_{g(p)}R^3$ is less than 2. I tried to find the when the 3 determinant of 2-order minor of the Jacobian of $(y\sqrt{1-x^2-y^2}-x,\sqrt{1-x^2-y^2}-y,xy-\sqrt{1-x^2-y^2})$ are all $0$. The equation is hard to solve.So I turned to find the point in $R^3 \setminus (0,0,0)$ whose rank is  less than 3. It is equivalent to find when the determinat of matrix $$  \left[  \begin{matrix}    -1 & z & y \\    z & -1 & x \\    y & x & -1   \end{matrix}   \right]  $$ is $0$. And I get the equation $x^2+y^2+z^2+2xyz=1$ The next,as I think, is to find the projection of $x^2+y^2+z^2+2xyz=1$ on$S^2$ through the map $(x,y,z)\rightarrow(\dfrac{x}{\sqrt{x^2+y^2+z^2}},\dfrac{y}{\sqrt{x^2+y^2+z^2}} ,\dfrac{z}{\sqrt{x^2+y^2+z^2}})$. The intersection of $x^2+y^2+z^2+2xyz=1$ and  $x^2+y^2+z^2=1$ is obvious a solution. $x^2+y^2=1,z=0;y^2+z^2=1,x=0;x^2+z^2=1,y=0$ But I have no idea how to find the other projections.What should I do next?","The primary problem is to find the singular points of $g$ when $g$ defines on $S^2$ that $g:S^2 \rightarrow R^3,(x,y,z)\rightarrow(yz-x,zx-y,xy-z)$. $Note:$The singular point in the problem is the point when the rank of $dg_{p}：T_p S^2 \rightarrow T_{g(p)}R^3$ is less than 2. I tried to find the when the 3 determinant of 2-order minor of the Jacobian of $(y\sqrt{1-x^2-y^2}-x,\sqrt{1-x^2-y^2}-y,xy-\sqrt{1-x^2-y^2})$ are all $0$. The equation is hard to solve.So I turned to find the point in $R^3 \setminus (0,0,0)$ whose rank is  less than 3. It is equivalent to find when the determinat of matrix $$  \left[  \begin{matrix}    -1 & z & y \\    z & -1 & x \\    y & x & -1   \end{matrix}   \right]  $$ is $0$. And I get the equation $x^2+y^2+z^2+2xyz=1$ The next,as I think, is to find the projection of $x^2+y^2+z^2+2xyz=1$ on$S^2$ through the map $(x,y,z)\rightarrow(\dfrac{x}{\sqrt{x^2+y^2+z^2}},\dfrac{y}{\sqrt{x^2+y^2+z^2}} ,\dfrac{z}{\sqrt{x^2+y^2+z^2}})$. The intersection of $x^2+y^2+z^2+2xyz=1$ and  $x^2+y^2+z^2=1$ is obvious a solution. $x^2+y^2=1,z=0;y^2+z^2=1,x=0;x^2+z^2=1,y=0$ But I have no idea how to find the other projections.What should I do next?",,"['differential-geometry', 'manifolds', 'vector-analysis']"
30,Smooth function $f\colon S^n\longrightarrow \mathbb{R}$ with $df_x=df_y=0$,Smooth function  with,f\colon S^n\longrightarrow \mathbb{R} df_x=df_y=0,"How can I prove that for any smooth function $f\colon S^n\longrightarrow \mathbb{R}$ always exist $x,y\in S^n$ such that $df_x=df_y=0$? I have tried it by induction, but I don't know to prove it even with $n=1$.","How can I prove that for any smooth function $f\colon S^n\longrightarrow \mathbb{R}$ always exist $x,y\in S^n$ such that $df_x=df_y=0$? I have tried it by induction, but I don't know to prove it even with $n=1$.",,['differential-geometry']
31,Is this a ruled surface?,Is this a ruled surface?,,"I'd like to know if the contour surfaces of the following $f$ are ruled: $f(x, y, z)$ is a 3-dim scalar field (real-valued function) defined in the 1st octant $x > 0,\, y > 0,\,z > 0$ that exhibits the following scaling property: $$ f(x, y, z) = f\left(~ \frac{z_0}z \, x, \frac{z_0}z \, y,\, z_0 ~\right) \qquad \text{or} \qquad f(x, y, z) = f(\, sx,\, sy,\, s z) \tag*{$s \equiv \frac{z_0}z$} $$ That is, for any point, the value of $f$ can also be found on a reference plane $z = z_0$ by scaling radially $(x, y) \mapsto (sx, sy)$. Of course, any plane $z = z_0 > 0$ can act as the reference plane, and each contour surface $f(x, y, z) = p$ is in fact ""swept out"" by rays originating from the origin and passing through $(x, y, z)$. This reminds me of ruled surface for the following reason: given a contour surface $f(x, y, z) = p$, there is a level curve on the reference plane $g(x, y)=f(x, y, z_0)=p$ which can be parametrized into $g\left(\, x(u),\, y(u) \, \right) \to \beta(u)$ as in $$ f = \alpha(u) + v \beta(u) \qquad \text{with $v = z$}$$ where $(u, v)$ are the parameters, with $\alpha(u) = \{0, 0, 0\}$ being a trivial base curve (directrix) and $\beta(u) = \{ x(u), y(u), z_0 \}$ the director. There is also the alternative parametrization of interpolation/extrapolation of two non-intersecting curves on the contour surface: just take two planar level curves at two different heigh $z = z_1$ and $z = z_2$. However, I'm not sure if the base curve is allowed to be degenerate. In addition, I have trouble constructing a parametrization with rulings orthogonal to the rays. Formally,my question are: Does the scaling property above implies it to be a ruled surface? If it is ruled, is it necessary that there exists a parametrization with two orthogonal rulings? I have very little knowledge about even intro level differential geometry, and I basically would like to know if my field $~f~$ belongs to this type of function (ruled surface) so that I should go ahead and learn the relevant tools and study it that way. p.s. I don't know if this is relevant, but the field $f$ and its 1st derivatives are all continuous, but there are some boundaries of regions where the 2nd derivatives are not continuous with infinite jumps. The boundaries are like $z = y$ and $z = \sqrt{x^2 + y^2}$.","I'd like to know if the contour surfaces of the following $f$ are ruled: $f(x, y, z)$ is a 3-dim scalar field (real-valued function) defined in the 1st octant $x > 0,\, y > 0,\,z > 0$ that exhibits the following scaling property: $$ f(x, y, z) = f\left(~ \frac{z_0}z \, x, \frac{z_0}z \, y,\, z_0 ~\right) \qquad \text{or} \qquad f(x, y, z) = f(\, sx,\, sy,\, s z) \tag*{$s \equiv \frac{z_0}z$} $$ That is, for any point, the value of $f$ can also be found on a reference plane $z = z_0$ by scaling radially $(x, y) \mapsto (sx, sy)$. Of course, any plane $z = z_0 > 0$ can act as the reference plane, and each contour surface $f(x, y, z) = p$ is in fact ""swept out"" by rays originating from the origin and passing through $(x, y, z)$. This reminds me of ruled surface for the following reason: given a contour surface $f(x, y, z) = p$, there is a level curve on the reference plane $g(x, y)=f(x, y, z_0)=p$ which can be parametrized into $g\left(\, x(u),\, y(u) \, \right) \to \beta(u)$ as in $$ f = \alpha(u) + v \beta(u) \qquad \text{with $v = z$}$$ where $(u, v)$ are the parameters, with $\alpha(u) = \{0, 0, 0\}$ being a trivial base curve (directrix) and $\beta(u) = \{ x(u), y(u), z_0 \}$ the director. There is also the alternative parametrization of interpolation/extrapolation of two non-intersecting curves on the contour surface: just take two planar level curves at two different heigh $z = z_1$ and $z = z_2$. However, I'm not sure if the base curve is allowed to be degenerate. In addition, I have trouble constructing a parametrization with rulings orthogonal to the rays. Formally,my question are: Does the scaling property above implies it to be a ruled surface? If it is ruled, is it necessary that there exists a parametrization with two orthogonal rulings? I have very little knowledge about even intro level differential geometry, and I basically would like to know if my field $~f~$ belongs to this type of function (ruled surface) so that I should go ahead and learn the relevant tools and study it that way. p.s. I don't know if this is relevant, but the field $f$ and its 1st derivatives are all continuous, but there are some boundaries of regions where the 2nd derivatives are not continuous with infinite jumps. The boundaries are like $z = y$ and $z = \sqrt{x^2 + y^2}$.",,"['differential-geometry', '3d', 'surfaces', 'parametrization']"
32,"Hypercomplex structure as integrable $Gl(\mathbb{H},n)$-structure.",Hypercomplex structure as integrable -structure.,"Gl(\mathbb{H},n)","Although there is some mess with notation, we say that a manifold $M^{4n}$ has an almost hypercomplex structure if there are three almost complex structures $I,J,K$ satisfing quaternions relations. Now classical definition of hypercomplexity requires all of them to be integrable. Since an almost hypercomplex structure is nothing but $Gl(\mathbb{H},n)$ structure, I would like to know if being hypercomplex is equivalento to be an integrable (in the sence of G-structur) almost hypercomplex? Ofcourse being integrable implies integrability of $I,J,K$ yet I can't see if the seperate integrability of them implies that they can be simultaniously presented in a canonical way in some chart?","Although there is some mess with notation, we say that a manifold $M^{4n}$ has an almost hypercomplex structure if there are three almost complex structures $I,J,K$ satisfing quaternions relations. Now classical definition of hypercomplexity requires all of them to be integrable. Since an almost hypercomplex structure is nothing but $Gl(\mathbb{H},n)$ structure, I would like to know if being hypercomplex is equivalento to be an integrable (in the sence of G-structur) almost hypercomplex? Ofcourse being integrable implies integrability of $I,J,K$ yet I can't see if the seperate integrability of them implies that they can be simultaniously presented in a canonical way in some chart?",,['differential-geometry']
33,How to prove the expanding Ricci soliton is Einstein metric?,How to prove the expanding Ricci soliton is Einstein metric?,,"As picture below ,I want to prove the expanding Ricci soliton is Einstein metric. I can get $R+\Delta f-n\lambda=0$ . Besides ,I want to prove $R+|\nabla f|^2= C$ for some constant $C$ . But fail. I just get $R+|\nabla f|^2-2\lambda f=C'$ . So, how to do it ? Just give a little hint is enough . Thanks. Picture below is from the 176 page of paper . And, the definition of expanding Ricci soliton can be found in here .","As picture below ,I want to prove the expanding Ricci soliton is Einstein metric. I can get . Besides ,I want to prove for some constant . But fail. I just get . So, how to do it ? Just give a little hint is enough . Thanks. Picture below is from the 176 page of paper . And, the definition of expanding Ricci soliton can be found in here .",R+\Delta f-n\lambda=0 R+|\nabla f|^2= C C R+|\nabla f|^2-2\lambda f=C',"['differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'ricci-flow', 'soliton-theory']"
34,Show that $n$-torus is diffeomorphic to the product of $n$ circles? [closed],Show that -torus is diffeomorphic to the product of  circles? [closed],n n,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I'm trying to prove that the $n$-torus $ T^n =\mathbb R^n / \mathbb Z ^n$ is diffeomorphic to the product of $n$ circles $  S^1 $.  Thanks a lot for everyone's help!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I'm trying to prove that the $n$-torus $ T^n =\mathbb R^n / \mathbb Z ^n$ is diffeomorphic to the product of $n$ circles $  S^1 $.  Thanks a lot for everyone's help!",,"['geometry', 'differential-geometry']"
35,Approximation of curvature of arbitrary plane curve,Approximation of curvature of arbitrary plane curve,,"Let $S$ be the area (if finite) of the region bounded by a plane curve and a straight line parallel to the tangent line to the curve at a point on the curve, and at a distance $h$ from it. Express $\lim_{h \rightarrow 0} (S^2/h^3)$ in terms of the curvature of the curve. The first idea occur to me about this problem is that at a given point on the curve we can define an osculating circle , and that the area bounded by the circle and the straight line will tend to $S$ as $h \rightarrow 0$. The latter statement, however, I am not really sure how to prove or even whether it's true. Based on the assumption that such claim is valid, one can calculate the wanted limit by following expressions (see the following figure) and L'Hospital's rule \begin{gather} h = R(1 - \cos(\theta/2)) \\ S \approx \frac{R}{2}(\theta - \sin(\theta)), \end{gather} where $R = 1/\kappa$, $\kappa$ is the curvature of the curve at the point, and $h(\theta) \rightarrow 0$ as  $\theta \rightarrow 0$. For the justification I owed to everyone: Reorient the curve to center the given point at the origin of new coordinate system, such that its tangent vector is point at the $+x$-direction and the normal vector the $+y$-dircection. (See the diagram.) Let the straight line be $y = h$ with $0 \leq h \leq R = 1/\kappa$. Locally we can parametrise the curve by its $x$-coordinate, i.e. $\mathbf{r}(x) = (x, f(x))$, for some interval of $x$ containing the origin, such that $f(x)$ is a smooth function. Note that we have (due to our orientation of curve) $f(0) = 0, f'(0) = 0$ and $ f''(0) = \kappa$. Hence we have the Taylor expansion $f(x) = \frac{1}{2}\kappa x^2 + C x^3 + \dots$, for some constant $C$. For $|x| \leq R$, we have the equation for the circle $g(x) = R - \sqrt{R^2 - x^2}$. Expanded by power series $g(x) = \frac{1}{2R} x^2 + D x^3 + \dots$, where $D$ is some constant. If $y = h$ is close enough to our $x$-axis, by inverse function theorem, we shall find smooth functions $a(h)$ and $b(h)$ such that $f(a(h)) = h = g(b(h))$, and that $a, b \rightarrow 0$ as $h \rightarrow 0$. Now we can approximate the difference between the area $S'$ bounded by g(x) and $y =h $ and $S$: \begin{multline} |S'-S| = 2\left|\int_{0}^{a(h)} g(x) - f(x) dx + \int_{a(h)}^{b(h)} h - f(x) dx\right| \\ \leq 2\left| \int_{0}^a Ex^3 + \dots dx \right| + 2|h||b(h) - a(h)| \\ \leq 2\left[ Fa^4 + O(a^5) \right] + 2|h||b(h)-a(h)|, \end{multline} where $E ,F$ are constants. This will tend to zero if we let $h$ shrink to zero, which completes my argument.","Let $S$ be the area (if finite) of the region bounded by a plane curve and a straight line parallel to the tangent line to the curve at a point on the curve, and at a distance $h$ from it. Express $\lim_{h \rightarrow 0} (S^2/h^3)$ in terms of the curvature of the curve. The first idea occur to me about this problem is that at a given point on the curve we can define an osculating circle , and that the area bounded by the circle and the straight line will tend to $S$ as $h \rightarrow 0$. The latter statement, however, I am not really sure how to prove or even whether it's true. Based on the assumption that such claim is valid, one can calculate the wanted limit by following expressions (see the following figure) and L'Hospital's rule \begin{gather} h = R(1 - \cos(\theta/2)) \\ S \approx \frac{R}{2}(\theta - \sin(\theta)), \end{gather} where $R = 1/\kappa$, $\kappa$ is the curvature of the curve at the point, and $h(\theta) \rightarrow 0$ as  $\theta \rightarrow 0$. For the justification I owed to everyone: Reorient the curve to center the given point at the origin of new coordinate system, such that its tangent vector is point at the $+x$-direction and the normal vector the $+y$-dircection. (See the diagram.) Let the straight line be $y = h$ with $0 \leq h \leq R = 1/\kappa$. Locally we can parametrise the curve by its $x$-coordinate, i.e. $\mathbf{r}(x) = (x, f(x))$, for some interval of $x$ containing the origin, such that $f(x)$ is a smooth function. Note that we have (due to our orientation of curve) $f(0) = 0, f'(0) = 0$ and $ f''(0) = \kappa$. Hence we have the Taylor expansion $f(x) = \frac{1}{2}\kappa x^2 + C x^3 + \dots$, for some constant $C$. For $|x| \leq R$, we have the equation for the circle $g(x) = R - \sqrt{R^2 - x^2}$. Expanded by power series $g(x) = \frac{1}{2R} x^2 + D x^3 + \dots$, where $D$ is some constant. If $y = h$ is close enough to our $x$-axis, by inverse function theorem, we shall find smooth functions $a(h)$ and $b(h)$ such that $f(a(h)) = h = g(b(h))$, and that $a, b \rightarrow 0$ as $h \rightarrow 0$. Now we can approximate the difference between the area $S'$ bounded by g(x) and $y =h $ and $S$: \begin{multline} |S'-S| = 2\left|\int_{0}^{a(h)} g(x) - f(x) dx + \int_{a(h)}^{b(h)} h - f(x) dx\right| \\ \leq 2\left| \int_{0}^a Ex^3 + \dots dx \right| + 2|h||b(h) - a(h)| \\ \leq 2\left[ Fa^4 + O(a^5) \right] + 2|h||b(h)-a(h)|, \end{multline} where $E ,F$ are constants. This will tend to zero if we let $h$ shrink to zero, which completes my argument.",,['differential-geometry']
36,Equations for the image of a 2-sphere by a differentiable map,Equations for the image of a 2-sphere by a differentiable map,,"My professor gave us this exercise. Let $S^2=\{(x_1,x_2,x_3)\in\mathbb{R}^3|(x_1)^2+(x_2)^2+(x_3)^2=1\}$ be the unit sphere in $\mathbb{R}^3$, and let's consider the function $f\colon S^2\to\mathbb{R}^6$ defined by $$ f(x_1,x_2,x_3)=((x_1)^2,(x_2)^2,(x_3)^2,x_2x_3,x_1x_3,x_1x_2). $$ Prove that $f$ is an immersion but is not injective. Besides, write the equations for $f(S^2)\subset\mathbb{R}^6$ and prove that  $f(S^2)$  is an embedded submanifold of $\mathbb{R}^6$. Solution For the first question, it is sufficient to write down the jacobian matrix $J$ of the function f and note that it is not possible for all the determinants of the $3\times3$ submatrices of $J$ to be zero simultaneously (provided that we are considering only the points of the 2-dim sphere), so the differential is everywhere injective on the sphere and we are done. Besides, $f$ is not injective because, for example, $f(x_1,x_2,x_3)=f(-x_1,-x_2,-x_3)$ ($(x_1,x_2,x_3)$ lies on the 2-dim sphere if and only if $(-x_1,-x_2,-x_3)$ does). But I am just stuck with the second question, I don't get what my professor means with ""write the equations for $f(S^2)$""... The only equation I see is satisfied by a point in $f(S^2)$ is $x_1+x_2+x_3=1$. I'm wondering, how many equations there should be for $f(S^2)$? And how can I find them? Only by means of algebric manipulations of the components of $f$, or is there some ""sistematic"" way to find them?","My professor gave us this exercise. Let $S^2=\{(x_1,x_2,x_3)\in\mathbb{R}^3|(x_1)^2+(x_2)^2+(x_3)^2=1\}$ be the unit sphere in $\mathbb{R}^3$, and let's consider the function $f\colon S^2\to\mathbb{R}^6$ defined by $$ f(x_1,x_2,x_3)=((x_1)^2,(x_2)^2,(x_3)^2,x_2x_3,x_1x_3,x_1x_2). $$ Prove that $f$ is an immersion but is not injective. Besides, write the equations for $f(S^2)\subset\mathbb{R}^6$ and prove that  $f(S^2)$  is an embedded submanifold of $\mathbb{R}^6$. Solution For the first question, it is sufficient to write down the jacobian matrix $J$ of the function f and note that it is not possible for all the determinants of the $3\times3$ submatrices of $J$ to be zero simultaneously (provided that we are considering only the points of the 2-dim sphere), so the differential is everywhere injective on the sphere and we are done. Besides, $f$ is not injective because, for example, $f(x_1,x_2,x_3)=f(-x_1,-x_2,-x_3)$ ($(x_1,x_2,x_3)$ lies on the 2-dim sphere if and only if $(-x_1,-x_2,-x_3)$ does). But I am just stuck with the second question, I don't get what my professor means with ""write the equations for $f(S^2)$""... The only equation I see is satisfied by a point in $f(S^2)$ is $x_1+x_2+x_3=1$. I'm wondering, how many equations there should be for $f(S^2)$? And how can I find them? Only by means of algebric manipulations of the components of $f$, or is there some ""sistematic"" way to find them?",,"['differential-geometry', 'manifolds']"
37,Second fundamental form and Weingarten map,Second fundamental form and Weingarten map,,"I know two definitions of the 2nd fundamental form on 2-surfaces in $\mathbb R^3$: 1) For a parametrization $X(u,v)$ of the surface and the normal vector $\nu$, the 2nd fundamental form is given by the matrix $$ \left( \begin{array} & X_{uu} \cdot\nu & X_{uv}\cdot\nu \\ X_{vu} \cdot\nu & X_{vv}\cdot\nu \end{array} \right) $$ where $$X_{uv}=\frac{\partial}{\partial u}\frac{\partial}{\partial v}X$$ 2) $\Pi(x,y)=-\langle Dn_p(x),y\rangle$ where $Dn_p$ is the Weingarten map and $\langle,\rangle$ the scalar product in $\mathbb R^3$. How can I show that the two definitions define the same thing?","I know two definitions of the 2nd fundamental form on 2-surfaces in $\mathbb R^3$: 1) For a parametrization $X(u,v)$ of the surface and the normal vector $\nu$, the 2nd fundamental form is given by the matrix $$ \left( \begin{array} & X_{uu} \cdot\nu & X_{uv}\cdot\nu \\ X_{vu} \cdot\nu & X_{vv}\cdot\nu \end{array} \right) $$ where $$X_{uv}=\frac{\partial}{\partial u}\frac{\partial}{\partial v}X$$ 2) $\Pi(x,y)=-\langle Dn_p(x),y\rangle$ where $Dn_p$ is the Weingarten map and $\langle,\rangle$ the scalar product in $\mathbb R^3$. How can I show that the two definitions define the same thing?",,['differential-geometry']
38,Showing that a curve $\Gamma^*$ is spherical,Showing that a curve  is spherical,\Gamma^*,"I'm having troubles with this differential geometry problem: Let $\Gamma : \overrightarrow{x} = \overrightarrow{x}(s)$ be a curve of $E^3$ with natural parameter $s$ which does not pass through the origin $O$. Now consider the curve $$\Gamma^* : \overrightarrow{x}^*(s) = \frac{\overrightarrow{x}(s)}{f(s)},$$ where $f(s) = \left|\overrightarrow{x}(s)\right|$. I need to show that $\Gamma^*$ is spherical and that $s$ is a natural parameter of $\Gamma^*$ if and only if $f^2 + (f')^2 = 1$. Usually when we want to show that a curve is spherical it is sufficient to show that $$\frac{\rho(s)}{\tau(s)} + (\rho'(s)\tau(s))' = 0$$ where $\rho(s) = \frac 1{\kappa(s)}$ is the radius of curvature and $\tau(s) = \frac 1{\sigma(s)}$ is the radius of torsion. However here I have no way of calculating these scalar quantities. I'm also lost with the second part of the question.","I'm having troubles with this differential geometry problem: Let $\Gamma : \overrightarrow{x} = \overrightarrow{x}(s)$ be a curve of $E^3$ with natural parameter $s$ which does not pass through the origin $O$. Now consider the curve $$\Gamma^* : \overrightarrow{x}^*(s) = \frac{\overrightarrow{x}(s)}{f(s)},$$ where $f(s) = \left|\overrightarrow{x}(s)\right|$. I need to show that $\Gamma^*$ is spherical and that $s$ is a natural parameter of $\Gamma^*$ if and only if $f^2 + (f')^2 = 1$. Usually when we want to show that a curve is spherical it is sufficient to show that $$\frac{\rho(s)}{\tau(s)} + (\rho'(s)\tau(s))' = 0$$ where $\rho(s) = \frac 1{\kappa(s)}$ is the radius of curvature and $\tau(s) = \frac 1{\sigma(s)}$ is the radius of torsion. However here I have no way of calculating these scalar quantities. I'm also lost with the second part of the question.",,[]
39,Basic definition of orientation/preservation question,Basic definition of orientation/preservation question,,"I'm reading through do Carmo's book on Riemannian Geometry and reviewing a bit about orientation. He uses a definition of orientation preserving which I find difficult to verify in practice, but perhaps I'm missing something. He says a manifold is orientable if every change of coordinates function has a positive (determinant) Jacobian, and a choice of such a differentiable structure is a choice of orientation. 1) First, I wanted to verify that if $\varphi: M_1 \to M_2$ is a diffeomorphism, then $M_2$ gets an orientation from $M_1$. My argument was: if $y_\beta^{-1} \circ y_\alpha$ is a change of coordinate map on $M_2$, then $y_\beta^{-1} \circ y_\alpha = (x_\beta \varphi^{-1})^{-1} \circ (x_\alpha \varphi^{-1}) = \varphi (x_\beta^{-1} \circ x_\alpha) \varphi^{-1}$ for suitable coordinate maps $x_\alpha, x_\beta$ on $M_1$. Hence the determinant of the Jacobian for coordinate maps on $M_2$ are positive because the ones on $M_1$ are. Does this work? 2) Now how do I actually compare orientations under a map? For example, I want to do the classic exercise of showing the antipodal map $A: S^n \to S^n$ is orientation preserving iff $n$ is odd. I see that the determinant of the Jacobian of $A$ is $(-1)^{n+1}$ (I think Jacobians behave well under restriction?), but I don't see how to use this to compare the induced orientation on $A(S^n)$ using the above formulation. I would prefer to try to solve this using this level of information, and not bringing anything fancier like differential forms into the picture yet. Thanks.","I'm reading through do Carmo's book on Riemannian Geometry and reviewing a bit about orientation. He uses a definition of orientation preserving which I find difficult to verify in practice, but perhaps I'm missing something. He says a manifold is orientable if every change of coordinates function has a positive (determinant) Jacobian, and a choice of such a differentiable structure is a choice of orientation. 1) First, I wanted to verify that if $\varphi: M_1 \to M_2$ is a diffeomorphism, then $M_2$ gets an orientation from $M_1$. My argument was: if $y_\beta^{-1} \circ y_\alpha$ is a change of coordinate map on $M_2$, then $y_\beta^{-1} \circ y_\alpha = (x_\beta \varphi^{-1})^{-1} \circ (x_\alpha \varphi^{-1}) = \varphi (x_\beta^{-1} \circ x_\alpha) \varphi^{-1}$ for suitable coordinate maps $x_\alpha, x_\beta$ on $M_1$. Hence the determinant of the Jacobian for coordinate maps on $M_2$ are positive because the ones on $M_1$ are. Does this work? 2) Now how do I actually compare orientations under a map? For example, I want to do the classic exercise of showing the antipodal map $A: S^n \to S^n$ is orientation preserving iff $n$ is odd. I see that the determinant of the Jacobian of $A$ is $(-1)^{n+1}$ (I think Jacobians behave well under restriction?), but I don't see how to use this to compare the induced orientation on $A(S^n)$ using the above formulation. I would prefer to try to solve this using this level of information, and not bringing anything fancier like differential forms into the picture yet. Thanks.",,"['differential-geometry', 'differential-topology']"
40,What do we intuitively mean by embedding a manifold in an $n$-dimensional space?,What do we intuitively mean by embedding a manifold in an -dimensional space?,n,"What do we intuitively mean by embedding a manifold in an $n$-dimensional space? Also, why does a circle look so differently when is is embedded in $3$-space than $2$-space?","What do we intuitively mean by embedding a manifold in an $n$-dimensional space? Also, why does a circle look so differently when is is embedded in $3$-space than $2$-space?",,"['general-topology', 'differential-geometry', 'manifolds']"
41,Need help with O'Neill's proof that partial derivative operators form a basis for TpM,Need help with O'Neill's proof that partial derivative operators form a basis for TpM,,"I am trying to understand a proof in B. O'Neill's Semi-Riemanian Geometry . Specifically, I am trying to understand 12. Theorem which in my book is on page 8. The proof is to the theorem that the set $\{\partial_1, \ldots \partial_n \}$ forms a basis in $TpM$. Let $\xi(\mathcal U)$ be a chart defined on an open set $\mathcal U$, and let $\xi(\mathcal U) = \{q \in \mathbb{R}^n : |q| < \epsilon \}$ for some $\epsilon > 0$. Let $g$ be a smooth function. Suppose $0 \leq t \leq 1$. My problem begins right at the start of the proof where he says to define $$g_i(q) := \int_0^1 \frac{\partial g}{\partial u^i}(tq) dt$$ Where did this function come from? What does it even mean? What is the reason for the $tq$ argument and not just $t$? Then he states that using the Fundamental Theorem of Calculus, one can obtain: $$g = g(0) + \sum g_i u^i$$ And the proof goes on from there. I think I understand how to get the second equation using the Fundamental Theorem of Calculus, but I have no idea where that integral came from or what it means and that is where I need help. (I know I can just treat it as a definition, but it drives me crazy if I can't see where it came from and understand it.)","I am trying to understand a proof in B. O'Neill's Semi-Riemanian Geometry . Specifically, I am trying to understand 12. Theorem which in my book is on page 8. The proof is to the theorem that the set $\{\partial_1, \ldots \partial_n \}$ forms a basis in $TpM$. Let $\xi(\mathcal U)$ be a chart defined on an open set $\mathcal U$, and let $\xi(\mathcal U) = \{q \in \mathbb{R}^n : |q| < \epsilon \}$ for some $\epsilon > 0$. Let $g$ be a smooth function. Suppose $0 \leq t \leq 1$. My problem begins right at the start of the proof where he says to define $$g_i(q) := \int_0^1 \frac{\partial g}{\partial u^i}(tq) dt$$ Where did this function come from? What does it even mean? What is the reason for the $tq$ argument and not just $t$? Then he states that using the Fundamental Theorem of Calculus, one can obtain: $$g = g(0) + \sum g_i u^i$$ And the proof goes on from there. I think I understand how to get the second equation using the Fundamental Theorem of Calculus, but I have no idea where that integral came from or what it means and that is where I need help. (I know I can just treat it as a definition, but it drives me crazy if I can't see where it came from and understand it.)",,"['differential-geometry', 'smooth-manifolds']"
42,Ham Sandwich Theorem - intuitive proof,Ham Sandwich Theorem - intuitive proof,,"Ham Sandwich Theorem . Given 3 measurable ""objects"" in $\mathbb{R}^3$, it is possible to divide all of them in half (with respect to their measure, i.e. volume) with a single 2-dimensional plane. Can we turn the following idea into a constructive proof of the Ham sandwich theorem? Let $B^3_1$, $B^3_2$ and $B^3_3$ be balls in $\mathbb{R}^3$. It is clear that we can divide every volume in two with a plane that intersects the centers of those balls. But now we are free to morph upper and lower halves in an ""isovolumetric"" fashion without changing the fact that the plane halves the volume. Also, if there are volume migration between the sides of the plane, then the net change must be zero. If we divide each half ball into a large, but finite, collection of cubes, then it should be clear that we can approximate any shape with equal volume.","Ham Sandwich Theorem . Given 3 measurable ""objects"" in $\mathbb{R}^3$, it is possible to divide all of them in half (with respect to their measure, i.e. volume) with a single 2-dimensional plane. Can we turn the following idea into a constructive proof of the Ham sandwich theorem? Let $B^3_1$, $B^3_2$ and $B^3_3$ be balls in $\mathbb{R}^3$. It is clear that we can divide every volume in two with a plane that intersects the centers of those balls. But now we are free to morph upper and lower halves in an ""isovolumetric"" fashion without changing the fact that the plane halves the volume. Also, if there are volume migration between the sides of the plane, then the net change must be zero. If we divide each half ball into a large, but finite, collection of cubes, then it should be clear that we can approximate any shape with equal volume.",,"['general-topology', 'differential-geometry', 'algebraic-topology', 'soft-question']"
43,Construct smooth mapping $f: B^{n + 1} \to S^n$ with two singularities at which $f$ has degree $+/- 1$.,Construct smooth mapping  with two singularities at which  has degree .,f: B^{n + 1} \to S^n f +/- 1,"I'm currently working through a paper by Pjotr Hajlasz who wants to show that For smooth manifolds $M,N$, if $\pi_{[p]}(N) \neq 0$ and $1 \leq p < n = \dim M$, then the smooth mappings $C^\infty(M,N)$ are not dense in $W^{1,p}(M,N)$. In his proof he asserts that ""It is easy to construct a smooth mapping $f: B^{[p]+1} \to S^{[p]}$ with two singularities such that $f$ restricted to small spheres centered at the singularities have degree +1 and -1 respectively."" How would one go about to construct or at least think about such smooth mapping? I'd appreciate any help!","I'm currently working through a paper by Pjotr Hajlasz who wants to show that For smooth manifolds $M,N$, if $\pi_{[p]}(N) \neq 0$ and $1 \leq p < n = \dim M$, then the smooth mappings $C^\infty(M,N)$ are not dense in $W^{1,p}(M,N)$. In his proof he asserts that ""It is easy to construct a smooth mapping $f: B^{[p]+1} \to S^{[p]}$ with two singularities such that $f$ restricted to small spheres centered at the singularities have degree +1 and -1 respectively."" How would one go about to construct or at least think about such smooth mapping? I'd appreciate any help!",,"['differential-geometry', 'algebraic-topology', 'manifolds', 'differential-topology', 'smooth-manifolds']"
44,About the Fermi charts,About the Fermi charts,,"In the book Topics in Differential geometry , Peter W. Michor defines the Fermi charts for a Riemannian manifold as follows. Let $(M,g)$ be a Riemannian manifold. For simplicity, I assume that $M$ is geodesically complete. Let $c : 0 \in I \subset \mathbb{R} \to M$ a geodesic. Let $\lbrace \dot{c}(0) \rbrace^{\perp}$ denote linear space of tangent vectors in $T_{c(0)}M$ which are orthogonal to $\dot{c}(0)$ (for the metric $g_{c(0)}$). Define the mapping $\Theta : (t,v) \in I \times \lbrace \dot{c}(0) \rbrace^{\perp} \mapsto \mathrm{Exp}_{c(t)}\big( \mathrm{Pt}(c,t)v \big)$, where $\mathrm{Pt}(c,t)v$ denotes the parallel transport of $v$ from $T_{c(0)}M$ to $T_{c(t)}M$ along the curve $c$. The following result is given in the book : The tangent map of $\Theta$ along $I \times \lbrace 0 \rbrace$ is given by : $$ T_{(t,0)}\Theta : (s,Y) \in \mathbb{R} \times \lbrace \dot{c}(0) \rbrace^{\perp} \mapsto s\dot{c}(t) + \mathrm{Pt}(c,t)Y $$ I tried to compute this tangent map myself but I couldn't. I considered a curve $\varphi : ]-\varepsilon,\varepsilon[ \to \mathbb{R} \times \lbrace \dot{c}(0) \rbrace^{\perp}$ such that : $\varphi(0) = (t,0)$ and $\dot{\varphi}(0) = (s,Y)$. But I do not see how to compute the derivative at $u=0$ of $(\Theta \circ \varphi)(u)$ (because $u$ appears in the base point of the Exponential and in the parallel transport). What would be the right way to compute this tangent map ?","In the book Topics in Differential geometry , Peter W. Michor defines the Fermi charts for a Riemannian manifold as follows. Let $(M,g)$ be a Riemannian manifold. For simplicity, I assume that $M$ is geodesically complete. Let $c : 0 \in I \subset \mathbb{R} \to M$ a geodesic. Let $\lbrace \dot{c}(0) \rbrace^{\perp}$ denote linear space of tangent vectors in $T_{c(0)}M$ which are orthogonal to $\dot{c}(0)$ (for the metric $g_{c(0)}$). Define the mapping $\Theta : (t,v) \in I \times \lbrace \dot{c}(0) \rbrace^{\perp} \mapsto \mathrm{Exp}_{c(t)}\big( \mathrm{Pt}(c,t)v \big)$, where $\mathrm{Pt}(c,t)v$ denotes the parallel transport of $v$ from $T_{c(0)}M$ to $T_{c(t)}M$ along the curve $c$. The following result is given in the book : The tangent map of $\Theta$ along $I \times \lbrace 0 \rbrace$ is given by : $$ T_{(t,0)}\Theta : (s,Y) \in \mathbb{R} \times \lbrace \dot{c}(0) \rbrace^{\perp} \mapsto s\dot{c}(t) + \mathrm{Pt}(c,t)Y $$ I tried to compute this tangent map myself but I couldn't. I considered a curve $\varphi : ]-\varepsilon,\varepsilon[ \to \mathbb{R} \times \lbrace \dot{c}(0) \rbrace^{\perp}$ such that : $\varphi(0) = (t,0)$ and $\dot{\varphi}(0) = (s,Y)$. But I do not see how to compute the derivative at $u=0$ of $(\Theta \circ \varphi)(u)$ (because $u$ appears in the base point of the Exponential and in the parallel transport). What would be the right way to compute this tangent map ?",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
45,Bounding Geodesic Curvature,Bounding Geodesic Curvature,,"Let $\Sigma$ be a smooth surface, let $p,q \in \Sigma$ and let $n_{p}$ be the normal at $p$. Suppose that $d(p,q) < c$ for some constant $c$. That is $p$ and $q$ are pretty close to each other on $\Sigma$. Consider the plane $h = \operatorname{span}\{n_{p}, \vec{pq}\}$. The intersection $h \cap \Sigma$ defines a curve $\gamma$ from $p$ to $q$. I want to bound the geodesic curvature of $\gamma$. I have a bound on the principal curvatures in a neighborhood of $p$. This allows me to bound the normal curvature of $\gamma$. I want to bound the geodesic curvature of $\gamma$, so that I can bound the total curvature of $\gamma$. Is there a way to leverage the principal curvatures at $p$, the fact that $\gamma$ lies in a plane defined above, and the fact that $p$ and $q$ are close on $\Sigma$ to bound the geodesic curvature $k_{g}$ of $\gamma$?","Let $\Sigma$ be a smooth surface, let $p,q \in \Sigma$ and let $n_{p}$ be the normal at $p$. Suppose that $d(p,q) < c$ for some constant $c$. That is $p$ and $q$ are pretty close to each other on $\Sigma$. Consider the plane $h = \operatorname{span}\{n_{p}, \vec{pq}\}$. The intersection $h \cap \Sigma$ defines a curve $\gamma$ from $p$ to $q$. I want to bound the geodesic curvature of $\gamma$. I have a bound on the principal curvatures in a neighborhood of $p$. This allows me to bound the normal curvature of $\gamma$. I want to bound the geodesic curvature of $\gamma$, so that I can bound the total curvature of $\gamma$. Is there a way to leverage the principal curvatures at $p$, the fact that $\gamma$ lies in a plane defined above, and the fact that $p$ and $q$ are close on $\Sigma$ to bound the geodesic curvature $k_{g}$ of $\gamma$?",,"['differential-geometry', 'differential-topology']"
46,Killing/Isometry correspondence: Domains of flows generated by vector fields,Killing/Isometry correspondence: Domains of flows generated by vector fields,,"I am wondering about the correspondence between the isometry group $\mathcal{I}$ and the Lie Algebra of Killing vector fields $\mathcal{K}$ on a pseudo-Riemannian manifold $(\mathcal{M}, \mathbf{g})$. Specifically $\mathcal{L}_X \mathbf{g} = 0$ defines $\mathcal{K}$ and gives a necessary condition for $X$ to be in the Lie-Algebra $\mathcal{i}$ of $\mathcal{I}$. But as my understanding goes this is not a sufficient condition i.e not all elements of $\mathcal{K}$ generate flows $\theta_t : \mathcal{M} \rightarrow \mathcal{M}$ with $t > 0$ that are in $\mathcal{I}$. Now I have found obscure references, that only elements of $\mathcal{K}$ that generate global flows are in $\mathcal{i}$. I guess my question boils down to something like: Given a vector field $X$, is it possible that its maximal flow domain contains a finite interval $0 \in [a,b]$ for all $p \in \mathcal{M}$ without the flow being global? My intuition tells me: no, because if this were the case, initial conditions should be ""preserved"" in some sense, forcing e.g $\theta_{2b}$ to be defined as well.","I am wondering about the correspondence between the isometry group $\mathcal{I}$ and the Lie Algebra of Killing vector fields $\mathcal{K}$ on a pseudo-Riemannian manifold $(\mathcal{M}, \mathbf{g})$. Specifically $\mathcal{L}_X \mathbf{g} = 0$ defines $\mathcal{K}$ and gives a necessary condition for $X$ to be in the Lie-Algebra $\mathcal{i}$ of $\mathcal{I}$. But as my understanding goes this is not a sufficient condition i.e not all elements of $\mathcal{K}$ generate flows $\theta_t : \mathcal{M} \rightarrow \mathcal{M}$ with $t > 0$ that are in $\mathcal{I}$. Now I have found obscure references, that only elements of $\mathcal{K}$ that generate global flows are in $\mathcal{i}$. I guess my question boils down to something like: Given a vector field $X$, is it possible that its maximal flow domain contains a finite interval $0 \in [a,b]$ for all $p \in \mathcal{M}$ without the flow being global? My intuition tells me: no, because if this were the case, initial conditions should be ""preserved"" in some sense, forcing e.g $\theta_{2b}$ to be defined as well.",,"['differential-geometry', 'vector-analysis']"
47,Normal sections,Normal sections,,"Let $S$ be a surface and let $p \in S$ with normal $n_{p}$. Let $q \in S$ nearby $p$, say within the injectivity radius of the exponential map at $p$. Consider the plane $\Pi = \operatorname{span}\{n_p, \vec{pq}\}$. The intersection of $\Pi$ with $S$ gives a curve $\gamma$ from $p$ to $q$. Is $\gamma$ a geodesic? Equivalently is $\Pi \cap S$ a normal section?","Let $S$ be a surface and let $p \in S$ with normal $n_{p}$. Let $q \in S$ nearby $p$, say within the injectivity radius of the exponential map at $p$. Consider the plane $\Pi = \operatorname{span}\{n_p, \vec{pq}\}$. The intersection of $\Pi$ with $S$ gives a curve $\gamma$ from $p$ to $q$. Is $\gamma$ a geodesic? Equivalently is $\Pi \cap S$ a normal section?",,"['differential-geometry', 'differential-topology']"
48,A book on Vector Calculus with emphasis on geometrical intuition,A book on Vector Calculus with emphasis on geometrical intuition,,"I am a physicist trying to learn vector calculus in a way that is a mixture of the way mathematicians learn it with the way that physicist learn it in order to be able to learn Differential Geometry the right way afterwards. After asking myself what the geometrical meaning of the chain rule is, I came to the conclusion that I haven't got the right intuition to figure it out on my own. So, I wanted to ask if anybody knows of a book on Vector Calculus that deals with the subject material in such a geometrically intuitive manner. Note: I don't want a book that only explains things qualitatively. I want a book like, say Marsden and Tromba's, but with more emphasis on intuition. Thanks!","I am a physicist trying to learn vector calculus in a way that is a mixture of the way mathematicians learn it with the way that physicist learn it in order to be able to learn Differential Geometry the right way afterwards. After asking myself what the geometrical meaning of the chain rule is, I came to the conclusion that I haven't got the right intuition to figure it out on my own. So, I wanted to ask if anybody knows of a book on Vector Calculus that deals with the subject material in such a geometrically intuitive manner. Note: I don't want a book that only explains things qualitatively. I want a book like, say Marsden and Tromba's, but with more emphasis on intuition. Thanks!",,"['differential-geometry', 'reference-request', 'vector-spaces', 'vectors', 'book-recommendation']"
49,Ring of smooth functions on a manifold and localization with respect to a multiplicative system,Ring of smooth functions on a manifold and localization with respect to a multiplicative system,,"Take $X$ a smooth manifold and $x\in X$. It can be shown that the germ of smooth functions around $x$, $C^\infty(X)_x $ is equal to the algebraic $S^{-1}C^\infty (X)$ where $S$ is the set of smooth function that does not vanish at $x$. But what if we take $S$ to be the set of smooth functions that does not vanish in a closed set $Y$ I tried to show that this led to the set $C^\infty(Y)$ but failed. Can one give me any help on this ?","Take $X$ a smooth manifold and $x\in X$. It can be shown that the germ of smooth functions around $x$, $C^\infty(X)_x $ is equal to the algebraic $S^{-1}C^\infty (X)$ where $S$ is the set of smooth function that does not vanish at $x$. But what if we take $S$ to be the set of smooth functions that does not vanish in a closed set $Y$ I tried to show that this led to the set $C^\infty(Y)$ but failed. Can one give me any help on this ?",,"['differential-geometry', 'ring-theory', 'smooth-manifolds']"
50,Cartan decomposition of SO(2n),Cartan decomposition of SO(2n),,"I am trying to understand the Cartan decomposition theory, on the following example : $G=SO(2n)$, and $K=U(n)$, and I'm interested in the manifold $G/K$ (an hermitian symmetric space). 1) How do we see $U(n)$ as a subgroup of $SO(2n)$ ? 2) Do we have a Cartan decomposition to $G$ ? More precisely do we have for the Lie algebra of $G$ that $\mathfrak{g} = \mathfrak{k} + \mathfrak{p}$, where $\mathfrak{k}$ is the Lie algebra of $K$, and also the +1 eigenspace of an involution $\theta$ on $\mathfrak{g}$, and $\mathfrak{p}$ is the -1 eigenspace of $\theta$ ? 3) If so, what is $\theta$ is that case? And what is $\mathfrak{p}$ explicitly ?","I am trying to understand the Cartan decomposition theory, on the following example : $G=SO(2n)$, and $K=U(n)$, and I'm interested in the manifold $G/K$ (an hermitian symmetric space). 1) How do we see $U(n)$ as a subgroup of $SO(2n)$ ? 2) Do we have a Cartan decomposition to $G$ ? More precisely do we have for the Lie algebra of $G$ that $\mathfrak{g} = \mathfrak{k} + \mathfrak{p}$, where $\mathfrak{k}$ is the Lie algebra of $K$, and also the +1 eigenspace of an involution $\theta$ on $\mathfrak{g}$, and $\mathfrak{p}$ is the -1 eigenspace of $\theta$ ? 3) If so, what is $\theta$ is that case? And what is $\mathfrak{p}$ explicitly ?",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
51,Exterior derivative of complex differential form,Exterior derivative of complex differential form,,"I have this question, from several complex variables: Start with the differential form: $$\omega(z)=\sum_{\nu=1}^{n} \frac{(-1)^{\nu-1}\bar{z}_{\nu}}{|z|^{2n}} d\bar{z}[\nu] \wedge dz, $$ where $dz= dz_1 \wedge ... \wedge dz_n$ and $d\bar{z}[\nu] = dz_1 \wedge ...  dz_{\nu - 1} \wedge dz_{\nu +1} ... \wedge dz_n$. Since $d(\bar{z}_{\nu} d\bar{z}[\nu]) = d\bar{z}_{\nu} \wedge d\bar{z}[\nu] = (-1)^{\nu -1} d\bar{z}$, we have $$d\omega =\sum_{\nu=1}^{n} \frac{\partial}{\partial \bar{z}_{\nu}} \bigg( \frac{\bar{z}_{\nu}}{|z|^{2n}} \bigg) d\bar{z} \wedge dz.$$ It's this line, right at the beginning, which I can't seem to compute. I'm pretty new to differential forms and exterior derivatives, so I can't see exactly how this is arrived at. I dont understand the first computation either ( $d(\bar{z}_{\nu} d\bar{z}[\nu]) = d\bar{z}_{\nu} \wedge d\bar{z}[\nu]$ etc. ). Any help or hints would be great, thanks.","I have this question, from several complex variables: Start with the differential form: $$\omega(z)=\sum_{\nu=1}^{n} \frac{(-1)^{\nu-1}\bar{z}_{\nu}}{|z|^{2n}} d\bar{z}[\nu] \wedge dz, $$ where $dz= dz_1 \wedge ... \wedge dz_n$ and $d\bar{z}[\nu] = dz_1 \wedge ...  dz_{\nu - 1} \wedge dz_{\nu +1} ... \wedge dz_n$. Since $d(\bar{z}_{\nu} d\bar{z}[\nu]) = d\bar{z}_{\nu} \wedge d\bar{z}[\nu] = (-1)^{\nu -1} d\bar{z}$, we have $$d\omega =\sum_{\nu=1}^{n} \frac{\partial}{\partial \bar{z}_{\nu}} \bigg( \frac{\bar{z}_{\nu}}{|z|^{2n}} \bigg) d\bar{z} \wedge dz.$$ It's this line, right at the beginning, which I can't seem to compute. I'm pretty new to differential forms and exterior derivatives, so I can't see exactly how this is arrived at. I dont understand the first computation either ( $d(\bar{z}_{\nu} d\bar{z}[\nu]) = d\bar{z}_{\nu} \wedge d\bar{z}[\nu]$ etc. ). Any help or hints would be great, thanks.",,"['differential-geometry', 'differential-forms', 'exterior-algebra']"
52,Is every hyperbolic isometry the restriction of an orthochronous Lorentz transformation?,Is every hyperbolic isometry the restriction of an orthochronous Lorentz transformation?,,"I know that every isometry of the sphere $\Bbb S^2$ is the restriction of some $A \in {\rm O}(3,\Bbb  R)$: namely, if $A_0:\Bbb S^2\to \Bbb S^2$ is an isometry, then $A_0 = A\big|_{\Bbb S^2}$ where $$Ax = \begin{cases} \|x\| A_0\left(\frac{x}{\|x\|}\right), \text{ if }x \neq 0 \\0 , \text{ if }x=0\end{cases}$$Then I thought of isometries $\Lambda_0:\Bbb H^2 \to \Bbb H^2$, where I see $\Bbb H^2$ inside Lorentz-Minkowski space $\Bbb L^3$. I'd guess that every such $\Lambda_0$ is a restriction of some orthochronous Lorentz transformation $\Lambda: \Bbb L^3 \to \Bbb L^3$, and I add the orthochronous condition so that $\Lambda$ doesn't swap the connected components of the two-sheeted hyperboloid. Trying to define $\Lambda$ from $\Lambda_0$ mimicking the construction for $\Bbb S^2$ doesn't work immediately for lightlike vectors. Every lightlike vector can be approximated by timelike vectors, so I think that this approach is fixable, but I'd like to see that details addressed. Where can I find the proof of that (if the result is actually true)? Thanks.","I know that every isometry of the sphere $\Bbb S^2$ is the restriction of some $A \in {\rm O}(3,\Bbb  R)$: namely, if $A_0:\Bbb S^2\to \Bbb S^2$ is an isometry, then $A_0 = A\big|_{\Bbb S^2}$ where $$Ax = \begin{cases} \|x\| A_0\left(\frac{x}{\|x\|}\right), \text{ if }x \neq 0 \\0 , \text{ if }x=0\end{cases}$$Then I thought of isometries $\Lambda_0:\Bbb H^2 \to \Bbb H^2$, where I see $\Bbb H^2$ inside Lorentz-Minkowski space $\Bbb L^3$. I'd guess that every such $\Lambda_0$ is a restriction of some orthochronous Lorentz transformation $\Lambda: \Bbb L^3 \to \Bbb L^3$, and I add the orthochronous condition so that $\Lambda$ doesn't swap the connected components of the two-sheeted hyperboloid. Trying to define $\Lambda$ from $\Lambda_0$ mimicking the construction for $\Bbb S^2$ doesn't work immediately for lightlike vectors. Every lightlike vector can be approximated by timelike vectors, so I think that this approach is fixable, but I'd like to see that details addressed. Where can I find the proof of that (if the result is actually true)? Thanks.",,"['differential-geometry', 'hyperbolic-geometry', 'semi-riemannian-geometry']"
53,Does every $C^1$ closed differential form differ from some $C^\infty$ closed form by an exact form?,Does every  closed differential form differ from some  closed form by an exact form?,C^1 C^\infty,"Question: On a $C^\infty$ manifold, does every $C^1$ closed differential form differ from some $C^\infty$ closed form by an exact form? Motivation: This result holds for $C^1$ closed 1-forms on a $C^\infty$ manifold $M$ for which the first singular homology is finitely generated (e.g., all compact manifolds). Proof: Let $\omega$ be any $C^1$ closed form on $M$. Let $\sigma_1,\ldots,\sigma_k$ be a $C^\infty$ basis for $H_1(M;\mathbb{R})$ and $[\theta_1],\ldots,[\theta_k] \in H_{dR}^1(M)$ be the dual basis (identifying $H_{dR}^1(M)$ with $Hom(H_1(M;\mathbb{R}),\mathbb{R})$ via the de Rham theorem), where $\theta_1,\ldots,\theta_k$ are $C^\infty$ forms. For $1 \leq i \leq k$, define $c_i := \int_{\sigma_i} \omega$. Then the one-form $\alpha := \omega - c_1 \theta_1 \ldots - c_k \theta_k$ satisfies $\oint_\gamma \alpha = 0$ for any closed loop $\gamma$, since $\gamma$ is a cycle and is thus a finite $\mathbb{R}$-linear combination of the $\sigma_i$ and the integral of $\alpha$ over all $\sigma_i$ is zero. It follows that given any two points $p,q \in M$, the integral of $\alpha$ over a path from $p$ to $q$ is independent of the path. For any points $p$ and $q$, denote this value by $\int_p^q \alpha$. Fix a basepoint $x_0 \in M$ and define $f:M\to \mathbb{R}$ by $f(p):= \int_{x_0}^p \alpha$. It is easy to show that $df = \alpha$. Hence $\omega - c_1 \theta_1 \ldots,c_k \theta_k = \alpha = df$, showing that $\omega = c_1 \theta_1 \ldots + c_k \theta_k + df$, as desired. This completes the proof. Note that the proof works if $\omega$ is only differentiable, and in general $f$ is only as smooth as $\omega$. Observation: The result would follow for $k$-forms on compact manifolds if it were true that ""If the integral of a $C^1$ closed $k$-form $\omega$ over every $k$-cycle was zero, then $\omega$ is exact."" If $\omega$ was a $C^\infty$ closed form, then this property could be shown using the de Rham theorem. However, I haven't yet figured out from the de Rham theorem proof whether it would work with $C^1$ forms rather than $C^\infty$ forms.","Question: On a $C^\infty$ manifold, does every $C^1$ closed differential form differ from some $C^\infty$ closed form by an exact form? Motivation: This result holds for $C^1$ closed 1-forms on a $C^\infty$ manifold $M$ for which the first singular homology is finitely generated (e.g., all compact manifolds). Proof: Let $\omega$ be any $C^1$ closed form on $M$. Let $\sigma_1,\ldots,\sigma_k$ be a $C^\infty$ basis for $H_1(M;\mathbb{R})$ and $[\theta_1],\ldots,[\theta_k] \in H_{dR}^1(M)$ be the dual basis (identifying $H_{dR}^1(M)$ with $Hom(H_1(M;\mathbb{R}),\mathbb{R})$ via the de Rham theorem), where $\theta_1,\ldots,\theta_k$ are $C^\infty$ forms. For $1 \leq i \leq k$, define $c_i := \int_{\sigma_i} \omega$. Then the one-form $\alpha := \omega - c_1 \theta_1 \ldots - c_k \theta_k$ satisfies $\oint_\gamma \alpha = 0$ for any closed loop $\gamma$, since $\gamma$ is a cycle and is thus a finite $\mathbb{R}$-linear combination of the $\sigma_i$ and the integral of $\alpha$ over all $\sigma_i$ is zero. It follows that given any two points $p,q \in M$, the integral of $\alpha$ over a path from $p$ to $q$ is independent of the path. For any points $p$ and $q$, denote this value by $\int_p^q \alpha$. Fix a basepoint $x_0 \in M$ and define $f:M\to \mathbb{R}$ by $f(p):= \int_{x_0}^p \alpha$. It is easy to show that $df = \alpha$. Hence $\omega - c_1 \theta_1 \ldots,c_k \theta_k = \alpha = df$, showing that $\omega = c_1 \theta_1 \ldots + c_k \theta_k + df$, as desired. This completes the proof. Note that the proof works if $\omega$ is only differentiable, and in general $f$ is only as smooth as $\omega$. Observation: The result would follow for $k$-forms on compact manifolds if it were true that ""If the integral of a $C^1$ closed $k$-form $\omega$ over every $k$-cycle was zero, then $\omega$ is exact."" If $\omega$ was a $C^\infty$ closed form, then this property could be shown using the de Rham theorem. However, I haven't yet figured out from the de Rham theorem proof whether it would work with $C^1$ forms rather than $C^\infty$ forms.",,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
54,Show that a k-form can be expressed as wedge product,Show that a k-form can be expressed as wedge product,,"I'm trying to show that given a $1$-form $\omega$ and a $k$-form $\alpha$ such that $\alpha \wedge \omega = 0$ then there exists a $(k-1)$-form $\beta$ such that $\alpha = \omega \wedge \beta$. I'm struggling to show this even in the case of multi-linear algebra and forgetting forms. I've been trying to use the fact that if $v_i$ are a basis for $V$ then $\{v_{i_1}\wedge...\wedge v_{i_k} : 1 \le i_1 < ... < i_k \le n\}$ is a basis for $\bigwedge ^k V$. I thought perhaps we could extend $\omega$ (I'm talking just in the multilinear algebra case here and not thinking about manifolds - I'll worry about that after!) to a basis of $V$ and then $\alpha \wedge \omega = 0$ kills any terms containing $\omega$ in the expansion of $\alpha$ but I'm struggling to make any further progress, Thanks for any help","I'm trying to show that given a $1$-form $\omega$ and a $k$-form $\alpha$ such that $\alpha \wedge \omega = 0$ then there exists a $(k-1)$-form $\beta$ such that $\alpha = \omega \wedge \beta$. I'm struggling to show this even in the case of multi-linear algebra and forgetting forms. I've been trying to use the fact that if $v_i$ are a basis for $V$ then $\{v_{i_1}\wedge...\wedge v_{i_k} : 1 \le i_1 < ... < i_k \le n\}$ is a basis for $\bigwedge ^k V$. I thought perhaps we could extend $\omega$ (I'm talking just in the multilinear algebra case here and not thinking about manifolds - I'll worry about that after!) to a basis of $V$ and then $\alpha \wedge \omega = 0$ kills any terms containing $\omega$ in the expansion of $\alpha$ but I'm struggling to make any further progress, Thanks for any help",,"['differential-geometry', 'differential-forms', 'smooth-manifolds', 'multilinear-algebra']"
55,Oriented atlas on a circle,Oriented atlas on a circle,,"I'm trying to find an oriented atlas on the circle $S^1$, i.e., I want to find an atlas for $S^1$ such that for any two overlapping charts $(U,s)$ and $(V,t)$ of the atlas, the derivative $d s/d t$ is everywhere positive on $U\cap V$. I can define one atlas $\mathfrak U = \{(U_i,\phi_i)\}_{i=1}^4$ for $S^1$ by letting $U_1,U_2$ be the upper and lower semicircles, respectively, and defining $\phi_i(x,y) = x$ for $i = 1,2$, and letting $U_3,U_4$ be the right and left semicircles, respectively, and defining $\phi_i(x,y) = y$ for $i = 3,4$. However, I think this atlas is not oriented, since for example taking the overlapping charts $(U_1,x)$ and $(U_3, y)$ of $\mathfrak U$, we have $y = \sqrt{1 - x^2}$ and $$ \frac{dy}{dx} = -\frac{x}{\sqrt{1-x^2}} \text, $$ which is not positive on $U_1\cap U_3$. How can I modify $\mathfrak U$ to fix this issue? For example, should I redefine $\phi_3(x,y) = -y$, and then keep on checking the other seven derivatives? (I have to check the pairs $dy/dx$ and $dx/dy$ for each quarter-circle.)","I'm trying to find an oriented atlas on the circle $S^1$, i.e., I want to find an atlas for $S^1$ such that for any two overlapping charts $(U,s)$ and $(V,t)$ of the atlas, the derivative $d s/d t$ is everywhere positive on $U\cap V$. I can define one atlas $\mathfrak U = \{(U_i,\phi_i)\}_{i=1}^4$ for $S^1$ by letting $U_1,U_2$ be the upper and lower semicircles, respectively, and defining $\phi_i(x,y) = x$ for $i = 1,2$, and letting $U_3,U_4$ be the right and left semicircles, respectively, and defining $\phi_i(x,y) = y$ for $i = 3,4$. However, I think this atlas is not oriented, since for example taking the overlapping charts $(U_1,x)$ and $(U_3, y)$ of $\mathfrak U$, we have $y = \sqrt{1 - x^2}$ and $$ \frac{dy}{dx} = -\frac{x}{\sqrt{1-x^2}} \text, $$ which is not positive on $U_1\cap U_3$. How can I modify $\mathfrak U$ to fix this issue? For example, should I redefine $\phi_3(x,y) = -y$, and then keep on checking the other seven derivatives? (I have to check the pairs $dy/dx$ and $dx/dy$ for each quarter-circle.)",,"['differential-geometry', 'manifolds', 'circles', 'smooth-manifolds', 'orientation']"
56,Maps between tangent space of product manifold and sum of tangent spaces,Maps between tangent space of product manifold and sum of tangent spaces,,"I am trying to prove that $$T_{(p,q)}(M\times N)\cong T_pM\oplus T_qN$$ We define: $$\Phi:T_{(p,q)}(M\times N)\to T_pM\oplus T_qN:v\mapsto(d_{(p,q)}\pi_M v,d_{(p,q)}\pi_N v)$$ and $$\Psi:T_pM\oplus T_qN\to T_{(p,q)}(M\times N), (v,w)\mapsto d(\iota_M)_p(v) +d(\iota_N)_q(w),$$  where $\iota_M : M\to M\times N$ sends $M$ to $M \times \{q\}$ and where $\iota_N : N\to M\times N$ sends $N$ to $N\times \{q\}$ I have trouble in showing that $\Psi \circ \Phi=\text{Id}$. Let $f$ be a smooth function on $M\times N$. Compute \begin{align*} \Psi \circ \Phi(v)f   &= \Psi (d_{(p,q)}\pi_M v,d_{(p,q)}\pi_N v)f \\ &=  \big(d_{(p,q)}(\iota_M \circ \pi_M) v,d_{(p,q)}(\iota \circ \pi_N) v \big)f \\ &= v(f\circ \iota_M \circ \pi_M )+v(f \circ \iota_N \circ \pi_N) \\ &= v(f\circ \iota_M \circ \pi_M + f \circ \iota_N \circ \pi_N) \end{align*} But I don't know why the last term is equal to $v(f)$. I looked at many solutions to this problem on stackexchange( this one , for example), but they seem to take this part for granted. Thanks in advance!","I am trying to prove that $$T_{(p,q)}(M\times N)\cong T_pM\oplus T_qN$$ We define: $$\Phi:T_{(p,q)}(M\times N)\to T_pM\oplus T_qN:v\mapsto(d_{(p,q)}\pi_M v,d_{(p,q)}\pi_N v)$$ and $$\Psi:T_pM\oplus T_qN\to T_{(p,q)}(M\times N), (v,w)\mapsto d(\iota_M)_p(v) +d(\iota_N)_q(w),$$  where $\iota_M : M\to M\times N$ sends $M$ to $M \times \{q\}$ and where $\iota_N : N\to M\times N$ sends $N$ to $N\times \{q\}$ I have trouble in showing that $\Psi \circ \Phi=\text{Id}$. Let $f$ be a smooth function on $M\times N$. Compute \begin{align*} \Psi \circ \Phi(v)f   &= \Psi (d_{(p,q)}\pi_M v,d_{(p,q)}\pi_N v)f \\ &=  \big(d_{(p,q)}(\iota_M \circ \pi_M) v,d_{(p,q)}(\iota \circ \pi_N) v \big)f \\ &= v(f\circ \iota_M \circ \pi_M )+v(f \circ \iota_N \circ \pi_N) \\ &= v(f\circ \iota_M \circ \pi_M + f \circ \iota_N \circ \pi_N) \end{align*} But I don't know why the last term is equal to $v(f)$. I looked at many solutions to this problem on stackexchange( this one , for example), but they seem to take this part for granted. Thanks in advance!",,"['differential-geometry', 'smooth-manifolds']"
57,Fundamental Group and DeRahm Cohomology from Group of Covering Transformations,Fundamental Group and DeRahm Cohomology from Group of Covering Transformations,,"Old qual problem here, test tomorrow in topology and we barely got to DeRahm Cohomology so I'm not sure how to do this. Let $G$ be the group of transformations of $\mathbb{R}^3$ generated by   \begin{align} A(x,y,z)&=(x+1,y,z)\\ B(x,y,z)&=(x,y+1,z)\\ C(x,y,z)&=(x+y,y,z+1). \end{align} Assume that $M=\mathbb{R}^3/G$ is a   three-manifold. a. Determine $\pi_1(M)$ up to isomorphism by giving a presentation   with generators and relations. ( note the relations will involve only   commutators of generators) b. Determine $H_{DR}^1(M)$ up to isomorphism and give closed one-forms   whose cohomology classes are a basis of $H_{DR}^1(M)$. Here's all I've got: We know that $G$ acts properly discontinuously on $\mathbb{R}^3$ so $\pi_1(M)=G$, but I'm not sure how to write $G$. When we have $G$, we know that $H_{DR}^1(X)=Hom(H_1(X),\mathbb{R})$ where $H_1(X)$ is $\pi_1(X)$ abelianized. I'm also not sure how to find the 1-forms giving a basis. Thank you.","Old qual problem here, test tomorrow in topology and we barely got to DeRahm Cohomology so I'm not sure how to do this. Let $G$ be the group of transformations of $\mathbb{R}^3$ generated by   \begin{align} A(x,y,z)&=(x+1,y,z)\\ B(x,y,z)&=(x,y+1,z)\\ C(x,y,z)&=(x+y,y,z+1). \end{align} Assume that $M=\mathbb{R}^3/G$ is a   three-manifold. a. Determine $\pi_1(M)$ up to isomorphism by giving a presentation   with generators and relations. ( note the relations will involve only   commutators of generators) b. Determine $H_{DR}^1(M)$ up to isomorphism and give closed one-forms   whose cohomology classes are a basis of $H_{DR}^1(M)$. Here's all I've got: We know that $G$ acts properly discontinuously on $\mathbb{R}^3$ so $\pi_1(M)=G$, but I'm not sure how to write $G$. When we have $G$, we know that $H_{DR}^1(X)=Hom(H_1(X),\mathbb{R})$ where $H_1(X)$ is $\pi_1(X)$ abelianized. I'm also not sure how to find the 1-forms giving a basis. Thank you.",,"['general-topology', 'differential-geometry', 'algebraic-topology', 'homology-cohomology']"
58,What is the horizontal space of trivial hermitian line bundle?,What is the horizontal space of trivial hermitian line bundle?,,"Suppose $L=M\times\Bbb C$ is a trivial holomorphic line bundle on a complex manifold $M$, and suppose there is a Hermitian fibre metric $h$ on $L$. Question: What is the horizontal space of $T_{(p,z)}L$ with respect to the canonical connection on $L$. I am a bit mixed up with all the definitions there are. Here the canonical connection is given by a connection 1-form, but we need to translate this into a splitting of the tangent space into horizontal and vertical space. There is clearly an obvious splitting of $T_{(p,z)}L$ and I am wondering if this is just that: We have $T_{(p,z)}L=T_{(p,z)}(M\times\Bbb C)=T_pM\oplus\Bbb C$. Is that the desired splitting?","Suppose $L=M\times\Bbb C$ is a trivial holomorphic line bundle on a complex manifold $M$, and suppose there is a Hermitian fibre metric $h$ on $L$. Question: What is the horizontal space of $T_{(p,z)}L$ with respect to the canonical connection on $L$. I am a bit mixed up with all the definitions there are. Here the canonical connection is given by a connection 1-form, but we need to translate this into a splitting of the tangent space into horizontal and vertical space. There is clearly an obvious splitting of $T_{(p,z)}L$ and I am wondering if this is just that: We have $T_{(p,z)}L=T_{(p,z)}(M\times\Bbb C)=T_pM\oplus\Bbb C$. Is that the desired splitting?",,"['differential-geometry', 'complex-geometry']"
59,Why is $\phi^* g = g$ a PDE for a pseudo-Riemannian metric $g$ on a manifold?,Why is  a PDE for a pseudo-Riemannian metric  on a manifold?,\phi^* g = g g,"Given a (locally trivial) bundle $\pi: E \to M$ a PDE of order $k$ is usually defined to be a submanifold of the jet-bundel $J^k(E)$. Now assume $E = M \times M$ and $\pi$ is the projection on the first factor. Thus $J^k(E) = J^k(M,M)$ and local sections of $\pi$ are nothing else than smooth maps $\phi: U \to M$ defined on an open subset of $U \subset M$. Furthermore assume, we have a given metric $g$ on $M$. Now we are interested in all local diffeomorphisms (that is all diffeomorphisms between open subsets of $M$), that act isometrically. In other words: We are looking for local diffeomorphisms $\phi$ for which $\phi^*g = g$ holds. Now everybody (except me!) seems to be sure, that this relation definies a PDE of order 1. Hence my question is: Why is the set $S= \lbrace j^1_p f \in J^1(M,M), (f^*g -g)(p)=0 \rbrace$ a submanifold of $J^1(M,M)$? This cleary links to my former question: Why is a differential equation a submanifold of a jet bundle? (this one beeing an example of the other one): If $\rho: H \to M$ is the bundle of (2,0)-tensors over $M$, we can define a map $D_f: \Gamma_{loc}(\pi) \to \Gamma_{loc}(\rho)$, which takes a local section $\phi$ of $\pi$ to the section $p \to (\phi^*g -g)(p)$ of $\rho$. It is not hard to see, that there is a bundle morphism $f: E=M\times M \to H$ for which $D_f (\phi)(p)=f(j^1_p \phi) $ holds for everey local section $\phi \in \Gamma_{loc}(\pi)$, namly $f(j^k_p \phi)(X,Y)=g_{\phi(p)}(d\phi_p X, d\phi_p Y)-g_p(X,Y)$. Obviously $S$ ist the preimage of the zero-section in $\rho$ under $f$. But as Anthony Carapetis pointed out in his answer, we need to require something about the rank of the map $f$ for the preimage of a section of $\rho$ to be a submanifold. (Anthony Carapetis asked surjectivity of $Df$ restricted to the vertical bunde, but actually I think constant rank should be enough). Anyhow, I can't figure out, why such a condittion should hold. All of the manifolds and maps in this post are $C^{\infty}$. I'm gratefull for any hint.","Given a (locally trivial) bundle $\pi: E \to M$ a PDE of order $k$ is usually defined to be a submanifold of the jet-bundel $J^k(E)$. Now assume $E = M \times M$ and $\pi$ is the projection on the first factor. Thus $J^k(E) = J^k(M,M)$ and local sections of $\pi$ are nothing else than smooth maps $\phi: U \to M$ defined on an open subset of $U \subset M$. Furthermore assume, we have a given metric $g$ on $M$. Now we are interested in all local diffeomorphisms (that is all diffeomorphisms between open subsets of $M$), that act isometrically. In other words: We are looking for local diffeomorphisms $\phi$ for which $\phi^*g = g$ holds. Now everybody (except me!) seems to be sure, that this relation definies a PDE of order 1. Hence my question is: Why is the set $S= \lbrace j^1_p f \in J^1(M,M), (f^*g -g)(p)=0 \rbrace$ a submanifold of $J^1(M,M)$? This cleary links to my former question: Why is a differential equation a submanifold of a jet bundle? (this one beeing an example of the other one): If $\rho: H \to M$ is the bundle of (2,0)-tensors over $M$, we can define a map $D_f: \Gamma_{loc}(\pi) \to \Gamma_{loc}(\rho)$, which takes a local section $\phi$ of $\pi$ to the section $p \to (\phi^*g -g)(p)$ of $\rho$. It is not hard to see, that there is a bundle morphism $f: E=M\times M \to H$ for which $D_f (\phi)(p)=f(j^1_p \phi) $ holds for everey local section $\phi \in \Gamma_{loc}(\pi)$, namly $f(j^k_p \phi)(X,Y)=g_{\phi(p)}(d\phi_p X, d\phi_p Y)-g_p(X,Y)$. Obviously $S$ ist the preimage of the zero-section in $\rho$ under $f$. But as Anthony Carapetis pointed out in his answer, we need to require something about the rank of the map $f$ for the preimage of a section of $\rho$ to be a submanifold. (Anthony Carapetis asked surjectivity of $Df$ restricted to the vertical bunde, but actually I think constant rank should be enough). Anyhow, I can't figure out, why such a condittion should hold. All of the manifolds and maps in this post are $C^{\infty}$. I'm gratefull for any hint.",,"['differential-geometry', 'partial-differential-equations', 'manifolds']"
60,Finding the envelope of the family $(x-c)^2+y^2=1+c^2$,Finding the envelope of the family,(x-c)^2+y^2=1+c^2,"I have this family of circles: $(x-c)^2+y^2=1+c^2$. I'm to find the envelope of this family. Going by what I know, I write $$F(x,y,c)=(x-c)^2+y^2-1-c^2=x^2-2xc+y^2-1=0.$$ Then, $$\frac{\delta F(x,y,c)}{\delta c}=-2x=0.$$ Ideally, I should get a function in $c$ in the second step, and then substitute that value in the original equation to get the envelope. But here, the $c$ cancels. What should I do now?","I have this family of circles: $(x-c)^2+y^2=1+c^2$. I'm to find the envelope of this family. Going by what I know, I write $$F(x,y,c)=(x-c)^2+y^2-1-c^2=x^2-2xc+y^2-1=0.$$ Then, $$\frac{\delta F(x,y,c)}{\delta c}=-2x=0.$$ Ideally, I should get a function in $c$ in the second step, and then substitute that value in the original equation to get the envelope. But here, the $c$ cancels. What should I do now?",,"['geometry', 'differential-geometry']"
61,$S^1$ acting on $SO(n+1)/SO(n-1)$ by translations,acting on  by translations,S^1 SO(n+1)/SO(n-1),"I'm ready right now in a paper, that $S^1$ acts on $SO(n+1)/SO(n-1)$ by right translations. I thought that a Liegroup $G$ acting by right translations, means that we have a right action $\varphi \colon G \times G \to G, \ (g,h) \mapsto \varphi_g(h)$ with $\varphi_g \circ \varphi_h = \varphi_{hg}$. But we have clearly, that $SO(n+1)/SO(n-1) \neq S^1$. So what do the author mean by ""$S^1$ acts on $SO(n+1)/SO(n-1)$ by right translations""? Edit: Maybe I should mention, that in this paper we get an action of $SO(n+1) \times S^1$, so that $S^1$ has to commute with the action of $SO(n+1)$.","I'm ready right now in a paper, that $S^1$ acts on $SO(n+1)/SO(n-1)$ by right translations. I thought that a Liegroup $G$ acting by right translations, means that we have a right action $\varphi \colon G \times G \to G, \ (g,h) \mapsto \varphi_g(h)$ with $\varphi_g \circ \varphi_h = \varphi_{hg}$. But we have clearly, that $SO(n+1)/SO(n-1) \neq S^1$. So what do the author mean by ""$S^1$ acts on $SO(n+1)/SO(n-1)$ by right translations""? Edit: Maybe I should mention, that in this paper we get an action of $SO(n+1) \times S^1$, so that $S^1$ has to commute with the action of $SO(n+1)$.",,"['differential-geometry', 'lie-groups']"
62,Exercise about Lagrangian submanifolds,Exercise about Lagrangian submanifolds,,"I am trying to solve the following exercise: Let $(M,\omega)$ be a symplectic manifold and $L$ a compact Lagrangian submanifold such that $H^{1}(L)=0$. Let $\{L_{t}\}_{t\in(-1,1)}$ be a smooth family of Lagrangian submanifolds of $(M,\omega)$ with $L_{0}=L$. Does there exist $\epsilon>0$ such that for all $t\in(-\epsilon,\epsilon)$: $L\cap L_{t}\neq\emptyset$? So far, all counterexamples I could find have nontrivial $H^{1}$, like for instance a family of circles in $T^{*}S^{1}\cong S^{1}\times\mathbb{R}$. This makes me believe that the statement is true. Any suggestions how to prove it?","I am trying to solve the following exercise: Let $(M,\omega)$ be a symplectic manifold and $L$ a compact Lagrangian submanifold such that $H^{1}(L)=0$. Let $\{L_{t}\}_{t\in(-1,1)}$ be a smooth family of Lagrangian submanifolds of $(M,\omega)$ with $L_{0}=L$. Does there exist $\epsilon>0$ such that for all $t\in(-\epsilon,\epsilon)$: $L\cap L_{t}\neq\emptyset$? So far, all counterexamples I could find have nontrivial $H^{1}$, like for instance a family of circles in $T^{*}S^{1}\cong S^{1}\times\mathbb{R}$. This makes me believe that the statement is true. Any suggestions how to prove it?",,"['differential-geometry', 'symplectic-geometry']"
63,Confusion about covariant derivative in $\mathbb R^n$,Confusion about covariant derivative in,\mathbb R^n,The Levi-civita connection on $\mathbb R^n$ corresponds to the usual directional derivative. In this sense I expect the following to hold: $$ \left(\nabla_{\partial_i}\partial_j\right)f=\partial_{ij}f. $$ On the other hand: $\nabla_{\partial_i}\partial_j=\Gamma_{ij}^k\partial_k=0$. These results are contradictory (of course) and I'd be happy to get some clarification.,The Levi-civita connection on $\mathbb R^n$ corresponds to the usual directional derivative. In this sense I expect the following to hold: $$ \left(\nabla_{\partial_i}\partial_j\right)f=\partial_{ij}f. $$ On the other hand: $\nabla_{\partial_i}\partial_j=\Gamma_{ij}^k\partial_k=0$. These results are contradictory (of course) and I'd be happy to get some clarification.,,['differential-geometry']
64,Orientability of almost complex manifold,Orientability of almost complex manifold,,"I have troubles trying to prove  almost complex  two-dimensional manifold is orientable. Let I is complex structure on two-dimensional manifold M. Fix a basic $X_1,IX_1$ in each $T_xM$. Easy to see any two such bases diﬀer by a linear transformation with positive determinant. To ﬁx an orientation on M we consider the family of all coordinate systems $x_1,x_2$ of M such that in each coordinate neighborhood, the coordinate basics $\frac{\partial}{\partial x_1},\frac{\partial}{\partial x_2}$ of $T_xM$ at x diﬀer from the chosen basis $X_1,IX_1$ by a linear transformation of positive determinant. I think These coordinate systems determine a complete oriented atlas for M but i don't prove it. Here I am stuck. Could somebody show me how to prove it ?","I have troubles trying to prove  almost complex  two-dimensional manifold is orientable. Let I is complex structure on two-dimensional manifold M. Fix a basic $X_1,IX_1$ in each $T_xM$. Easy to see any two such bases diﬀer by a linear transformation with positive determinant. To ﬁx an orientation on M we consider the family of all coordinate systems $x_1,x_2$ of M such that in each coordinate neighborhood, the coordinate basics $\frac{\partial}{\partial x_1},\frac{\partial}{\partial x_2}$ of $T_xM$ at x diﬀer from the chosen basis $X_1,IX_1$ by a linear transformation of positive determinant. I think These coordinate systems determine a complete oriented atlas for M but i don't prove it. Here I am stuck. Could somebody show me how to prove it ?",,"['differential-geometry', 'riemannian-geometry']"
65,About totally umbilical hypersurfaces,About totally umbilical hypersurfaces,,"Suppose $\tilde{M} \subset M$ is a hypersurface sitting inside a Riemannian manifold $(M,g)$. The second fundamental form of $M$ evaluated on $u,v \in T_pM$ is denoted $II(u,v)$ and defined as the normal component of $\tilde{\nabla}_UV$ for some extensions $U$ and $V$ of $u$ and $v$. Define $l(u,v)$ by the relation $II(u,v) = l(u,v)\nu$ for $\nu$ a fixed unit normal vector field of $M$ around $p$. I recently came across the following exercice : The hypersurface $M$ is said to be totally umbilical if $l = fg$ for $f \in C^{\infty}(M)$ and $g$ the restriction of the metric to $M$. It is asked to show that if $\dim M \geq 2$, then $f$ must be a constant. The book says it is a consequence of the Gauss-Codazzi equation $$\tilde{R}(x,y,u,\nu) = \nabla_xl(y,u) - \nabla_yl(x,u).$$ I tried playing around with this equation, taking traces hoping to find a Bianchi identity, but didn't have any success. Can anyone help me out?","Suppose $\tilde{M} \subset M$ is a hypersurface sitting inside a Riemannian manifold $(M,g)$. The second fundamental form of $M$ evaluated on $u,v \in T_pM$ is denoted $II(u,v)$ and defined as the normal component of $\tilde{\nabla}_UV$ for some extensions $U$ and $V$ of $u$ and $v$. Define $l(u,v)$ by the relation $II(u,v) = l(u,v)\nu$ for $\nu$ a fixed unit normal vector field of $M$ around $p$. I recently came across the following exercice : The hypersurface $M$ is said to be totally umbilical if $l = fg$ for $f \in C^{\infty}(M)$ and $g$ the restriction of the metric to $M$. It is asked to show that if $\dim M \geq 2$, then $f$ must be a constant. The book says it is a consequence of the Gauss-Codazzi equation $$\tilde{R}(x,y,u,\nu) = \nabla_xl(y,u) - \nabla_yl(x,u).$$ I tried playing around with this equation, taking traces hoping to find a Bianchi identity, but didn't have any success. Can anyone help me out?",,"['differential-geometry', 'riemannian-geometry', 'minimal-surfaces']"
66,Covariant Contravariant approach for Tensors,Covariant Contravariant approach for Tensors,,"I'm reading a book on Geometry from the '70s and when speaking about Tensors it defines them starting from the covariant and contravariant commutation rule. I know this definition was quite widespread at least until the '90s. I was used to approach Tensors as multilinear applications, but now I'm wondering: was this definition of the covariant/contravariant transformation rule really bad? Does it have any effective flaw or is it more a question of taste choosing between the two definitions? I have to choose a presentation for tensors in a Differential Geometry environment and in a really selfcontained and simple way, so I'm wondering if the old way with transformation rules is an option or not","I'm reading a book on Geometry from the '70s and when speaking about Tensors it defines them starting from the covariant and contravariant commutation rule. I know this definition was quite widespread at least until the '90s. I was used to approach Tensors as multilinear applications, but now I'm wondering: was this definition of the covariant/contravariant transformation rule really bad? Does it have any effective flaw or is it more a question of taste choosing between the two definitions? I have to choose a presentation for tensors in a Differential Geometry environment and in a really selfcontained and simple way, so I'm wondering if the old way with transformation rules is an option or not",,"['linear-algebra', 'differential-geometry', 'riemannian-geometry', 'tensor-products']"
67,Diffeomorphism from Riemannian metric to Hermitian metric on a complex manifold.,Diffeomorphism from Riemannian metric to Hermitian metric on a complex manifold.,,"It is known that any complex manifold, $M$ admits a Hermitian metric, i.e., a Riemannian metric, $g$, which satisfies  \begin{equation} g_p(J_pX,J_pY)=g_p(X,Y) \end{equation} at each point $p\in M$, where $X,Y\in T_p M$ and $J$ is the complex structure. The proof of this is that given any Riemannian metric $\hat{g}$ on $M$, one can obtain a Hermitian metric $g$ using \begin{equation} g_p(X,Y)\equiv \frac{1}{2}(\hat{g}_p(X,Y)+\hat{g}_p(J_pX,J_pY)). \end{equation} My question is, does there always exist a diffeomorphism (i.e., a local coordinate transformation) that takes us from $\hat{g}$ to $g$?","It is known that any complex manifold, $M$ admits a Hermitian metric, i.e., a Riemannian metric, $g$, which satisfies  \begin{equation} g_p(J_pX,J_pY)=g_p(X,Y) \end{equation} at each point $p\in M$, where $X,Y\in T_p M$ and $J$ is the complex structure. The proof of this is that given any Riemannian metric $\hat{g}$ on $M$, one can obtain a Hermitian metric $g$ using \begin{equation} g_p(X,Y)\equiv \frac{1}{2}(\hat{g}_p(X,Y)+\hat{g}_p(J_pX,J_pY)). \end{equation} My question is, does there always exist a diffeomorphism (i.e., a local coordinate transformation) that takes us from $\hat{g}$ to $g$?",,"['differential-geometry', 'complex-geometry']"
68,"Why is $f(U) \cap V$ the zero set of $y^{n+1}, \dots, y^m$? [duplicate]",Why is  the zero set of ? [duplicate],"f(U) \cap V y^{n+1}, \dots, y^m","This question already has an answer here : Why is the image of a smooth embedding $f: N \to M$ an embedded submanifold? (1 answer) Closed 8 years ago . I'm studying Tu's proof (p. 123) of theorem 11.13, but I just have a question about one detail. He has that $f\colon N\to M$ is an embedding of a manifold of dimension $n$ in a manifold of dimension $m$, and he shows that given $p\in N$, there are local coordinates $(U, x^1, \dots, x^n)$ near $p$ and $(V, y^1, \dots, y^m)$ near $f(p)$ such that $f\colon U\to V$ has the form $$ (x^1, \dots, x^n) \mapsto (x^1, \dots, x^n, 0, \dots, 0). $$ He then says Thus, $f(U)$ is defined in $V$ by the vanishing of the coordinates $y^{n+1}, \dots, y^m$. I understand this statement to mean that $$ f(U) \cap V = \{ q\in V \mid y^{n+1}(q) = \dots = y^m(q) = 0\}. $$ However, I don't understand why this should be the case. Couldn't there be other points of $V$ at which the coordinates $y^{n+1}, \dots, y^m$ vanish?","This question already has an answer here : Why is the image of a smooth embedding $f: N \to M$ an embedded submanifold? (1 answer) Closed 8 years ago . I'm studying Tu's proof (p. 123) of theorem 11.13, but I just have a question about one detail. He has that $f\colon N\to M$ is an embedding of a manifold of dimension $n$ in a manifold of dimension $m$, and he shows that given $p\in N$, there are local coordinates $(U, x^1, \dots, x^n)$ near $p$ and $(V, y^1, \dots, y^m)$ near $f(p)$ such that $f\colon U\to V$ has the form $$ (x^1, \dots, x^n) \mapsto (x^1, \dots, x^n, 0, \dots, 0). $$ He then says Thus, $f(U)$ is defined in $V$ by the vanishing of the coordinates $y^{n+1}, \dots, y^m$. I understand this statement to mean that $$ f(U) \cap V = \{ q\in V \mid y^{n+1}(q) = \dots = y^m(q) = 0\}. $$ However, I don't understand why this should be the case. Couldn't there be other points of $V$ at which the coordinates $y^{n+1}, \dots, y^m$ vanish?",,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
69,Is the converse of this true?,Is the converse of this true?,,"I was reading this reference and I was wondering if someone can provide a proof of the converse, well if it is true of course, I mean if two smooth manifolds are diffeomorphic then they have to be homeomorphic, and if fact does the inverse of a diffeomorphism has to be a diffeomorphism ? Thanks a lot in advance.","I was reading this reference and I was wondering if someone can provide a proof of the converse, well if it is true of course, I mean if two smooth manifolds are diffeomorphic then they have to be homeomorphic, and if fact does the inverse of a diffeomorphism has to be a diffeomorphism ? Thanks a lot in advance.",,['differential-geometry']
70,How to best calculate Christoffel symbols of metric $du^2 +g^2(u) dv^2$?,How to best calculate Christoffel symbols of metric ?,du^2 +g^2(u) dv^2,"Suppose that the first fundamental form is $du^2+g^2(u)dv^2$. Calculate $\Gamma_{11}^1, \Gamma_{11}^2, \Gamma_{12}^1, \Gamma_{12}^2, \Gamma_{22}^1, \Gamma_{22}^2$. In lectures we've been given 6 formulas for the Christoffel symbols, all of this style: $$\Gamma_{11}^1=\frac{GE_u-2FF_u+FE_v}{2(EG-F^2)}$$ but all slightly different. We've also been given 6 equations like this: $$\Gamma_{11}^1 \cdot E + \Gamma_{11}^2 \cdot F=\frac{1}{2}E_u$$ and $$\Gamma_{11}^1 \cdot F + \Gamma_{11}^2 \cdot G=F_u-\frac{1}{2}E_v $$ Again, they're all the same style but all slightly different. What is the best way to calculate the Christoffel symbols? Is it using either of these sets of equations or is there another way? I ask if there is another way because these aren't the easiest of equations to memorise, especially when there are 6 (or 12) of them so another method would be appreciated.","Suppose that the first fundamental form is $du^2+g^2(u)dv^2$. Calculate $\Gamma_{11}^1, \Gamma_{11}^2, \Gamma_{12}^1, \Gamma_{12}^2, \Gamma_{22}^1, \Gamma_{22}^2$. In lectures we've been given 6 formulas for the Christoffel symbols, all of this style: $$\Gamma_{11}^1=\frac{GE_u-2FF_u+FE_v}{2(EG-F^2)}$$ but all slightly different. We've also been given 6 equations like this: $$\Gamma_{11}^1 \cdot E + \Gamma_{11}^2 \cdot F=\frac{1}{2}E_u$$ and $$\Gamma_{11}^1 \cdot F + \Gamma_{11}^2 \cdot G=F_u-\frac{1}{2}E_v $$ Again, they're all the same style but all slightly different. What is the best way to calculate the Christoffel symbols? Is it using either of these sets of equations or is there another way? I ask if there is another way because these aren't the easiest of equations to memorise, especially when there are 6 (or 12) of them so another method would be appreciated.",,['differential-geometry']
71,An example of the first/second fundamental form,An example of the first/second fundamental form,,"I have some trouble understanding the first/second fundamental form, so I guess a worked-out example would really help. Let's say for the graph of a function $g(x,y)$ with respect to the natural chart. What are the matrices for the first fundamental form, the second fundamental form, the differential of the Gauss map, and the Gaussian curvature?","I have some trouble understanding the first/second fundamental form, so I guess a worked-out example would really help. Let's say for the graph of a function $g(x,y)$ with respect to the natural chart. What are the matrices for the first fundamental form, the second fundamental form, the differential of the Gauss map, and the Gaussian curvature?",,['differential-geometry']
72,Kerr spacetime not symmetric?,Kerr spacetime not symmetric?,,"I always see a term $dt \, d \phi$ in the Kerr-spacetime . Now assuming this means $dt \otimes d \phi$ this means that the Kerr spacetime is NOT(!) symmetric which is somehow non-sense. So do physicists mean that $dt \, d\phi = dt \otimes d \phi + d\phi \otimes dt$ or am I missing anything?","I always see a term $dt \, d \phi$ in the Kerr-spacetime . Now assuming this means $dt \otimes d \phi$ this means that the Kerr spacetime is NOT(!) symmetric which is somehow non-sense. So do physicists mean that $dt \, d\phi = dt \otimes d \phi + d\phi \otimes dt$ or am I missing anything?",,"['differential-geometry', 'tensors', 'general-relativity']"
73,"De Rahm cohomology of a sphere, help with proof","De Rahm cohomology of a sphere, help with proof",,"I am working through Guillemin and Pollack's proof that the de Rahm cohomology of the sphere is $H^p(\mathbf{S}^k) = \mathbf{R}$ for $p = 0$ and $p = k$ and $H^p(\mathbf{S}^k) = 0$ otherwise.  Here, $k > 0$ . I am having difficulty understanding one of the maps involved in the proof. The proof is by induction on $k$ .  Assume we are in the inductive step, and we wish to prove the result for $\mathbf{S}^k$ , $k > 1$ .  We use a Mayer-Vietoris type of argument.  Decompose $\mathbf{S}^k$ as $U_1 \cup U_2$ , where $U_1$ is the sphere minus the south pole $S$ and $U_2$ is the sphere minus the north pole $N$ .  I am in the middle of showing the following result: Proposition:  For $p > 1$ , $H^{p-1}(U_1 \cap U_2) \cong H^p(U_1 \cup U_2)$ . The proof goes by constructing explicit maps, each of which is the other's inverse.  I am having trouble understanding why the specific map $H^{p-1}(U_1 \cap U_2) \to H^p(U_1 \cup U_2)$ is induced. Specifically:  Let $Z^p(M)$ denote the closed $p$ -forms on a manifold $M$ , $B^p(M)$ the exact $p$ -forms on the manifold, and $H^p(M) = Z^p(M)/B^p(M)$ the $p^{th}$ cohomology on the manifold. Define a map $G \colon Z^{p-1}(U_1 \cap U_2) \to H^p(U_1 \cup U_2)$ as follows.  Let $\nu$ be a closed $(p-1)$ -form on $U_1 \cap U_2$ .  Note that $\nu$ may blow up at either $N$ or $S$ .  Choose functions $\rho_1, \rho_2 \colon U_1 \cup U_2 \to \mathbf{R}$ such that $\rho_1$ vanishes on a neighborhood of $N$ , $\rho_2$ vanishes on a neighborhood of $S$ , and $\rho_1 + \rho_2 = 1$ .  Define a $(p-1)$ -form $\nu_1$ on $U_1$ by $\nu_1 = \rho_1 \nu$ and define a $(p-1)$ -form $\nu_2$ on $U_2$ by $\nu_2 = -\rho_2 \nu$ .  Define the $p$ -form $\omega$ on $U_1 \cup U_2$ by setting $\omega = d \nu_1$ on $U_1$ and $\omega = d \nu_2$ on $U_2$ .  Then $\omega$ is well-defined since on $U_1 \cap U_2$ , $d \nu_1 - d \nu_2 = d \nu = 0$ .  Clearly, $\omega$ is closed.  Lastly, set $G(\nu)$ to be the class of $\omega$ in $H^p(U_1 \cup U_2)$ .  I was able to prove that $G(\nu)$ is well-defined in the sense that it is independent of the chosen partition of unity. Question:  Why is it the case that $G$ induces a map $H^{p-1}(U_1 \cap U_2) \to H^p(U_1 \cup U_2)$ .  That is, why is it true that if $\nu$ is closed and exact, then $\omega$ is also exact? I realized after working on this for a bit that my method couldn't (shouldn't?) work because it would prove that $\omega$ is exact for any closed $\nu$ .  Specifically, I was only going off the fact that $d \nu = 0$ .  My natural instinct now is to show $\nu_1$ extends to $S$ (or $\nu_2$ extends to $N$ ), but why would $\nu$ being exact mean such an extension exists?  That doesn't seem right to me...  (Just to reiterate, $\omega$ is very close to being exact already; $\omega = d \nu_1$ (or $= d \nu_2$ ) except at just one point at which $\nu_1$ is not, a priori , defined.) Hope someone can help clear this up for me, understanding these maps has been very frustrating! Note: It might be helpful that $U_1$ and $U_2$ are contractible (hence have vanishing cohomology), $U_1 \cap U_2 \cong \mathbf{R} \times \mathbf{S}^{k-1}$ , $H^p(\mathbf{R} \times \mathbf{S}^{k-1}) \cong H^p(\mathbf{S}^{k-1})$ , we are in the induction step, etc... ???","I am working through Guillemin and Pollack's proof that the de Rahm cohomology of the sphere is for and and otherwise.  Here, . I am having difficulty understanding one of the maps involved in the proof. The proof is by induction on .  Assume we are in the inductive step, and we wish to prove the result for , .  We use a Mayer-Vietoris type of argument.  Decompose as , where is the sphere minus the south pole and is the sphere minus the north pole .  I am in the middle of showing the following result: Proposition:  For , . The proof goes by constructing explicit maps, each of which is the other's inverse.  I am having trouble understanding why the specific map is induced. Specifically:  Let denote the closed -forms on a manifold , the exact -forms on the manifold, and the cohomology on the manifold. Define a map as follows.  Let be a closed -form on .  Note that may blow up at either or .  Choose functions such that vanishes on a neighborhood of , vanishes on a neighborhood of , and .  Define a -form on by and define a -form on by .  Define the -form on by setting on and on .  Then is well-defined since on , .  Clearly, is closed.  Lastly, set to be the class of in .  I was able to prove that is well-defined in the sense that it is independent of the chosen partition of unity. Question:  Why is it the case that induces a map .  That is, why is it true that if is closed and exact, then is also exact? I realized after working on this for a bit that my method couldn't (shouldn't?) work because it would prove that is exact for any closed .  Specifically, I was only going off the fact that .  My natural instinct now is to show extends to (or extends to ), but why would being exact mean such an extension exists?  That doesn't seem right to me...  (Just to reiterate, is very close to being exact already; (or ) except at just one point at which is not, a priori , defined.) Hope someone can help clear this up for me, understanding these maps has been very frustrating! Note: It might be helpful that and are contractible (hence have vanishing cohomology), , , we are in the induction step, etc... ???","H^p(\mathbf{S}^k) = \mathbf{R} p = 0 p = k H^p(\mathbf{S}^k) = 0 k > 0 k \mathbf{S}^k k > 1 \mathbf{S}^k U_1 \cup U_2 U_1 S U_2 N p > 1 H^{p-1}(U_1 \cap U_2) \cong H^p(U_1 \cup U_2) H^{p-1}(U_1 \cap U_2) \to H^p(U_1 \cup U_2) Z^p(M) p M B^p(M) p H^p(M) = Z^p(M)/B^p(M) p^{th} G \colon Z^{p-1}(U_1 \cap U_2) \to H^p(U_1 \cup U_2) \nu (p-1) U_1 \cap U_2 \nu N S \rho_1, \rho_2 \colon U_1 \cup U_2 \to \mathbf{R} \rho_1 N \rho_2 S \rho_1 + \rho_2 = 1 (p-1) \nu_1 U_1 \nu_1 = \rho_1 \nu (p-1) \nu_2 U_2 \nu_2 = -\rho_2 \nu p \omega U_1 \cup U_2 \omega = d \nu_1 U_1 \omega = d \nu_2 U_2 \omega U_1 \cap U_2 d \nu_1 - d \nu_2 = d \nu = 0 \omega G(\nu) \omega H^p(U_1 \cup U_2) G(\nu) G H^{p-1}(U_1 \cap U_2) \to H^p(U_1 \cup U_2) \nu \omega \omega \nu d \nu = 0 \nu_1 S \nu_2 N \nu \omega \omega = d \nu_1 = d \nu_2 \nu_1 U_1 U_2 U_1 \cap U_2 \cong \mathbf{R} \times \mathbf{S}^{k-1} H^p(\mathbf{R} \times \mathbf{S}^{k-1}) \cong H^p(\mathbf{S}^{k-1})","['differential-geometry', 'manifolds', 'differential-topology', 'homology-cohomology', 'differential-forms']"
74,"Exist vector field having only finitely many zeros, all lying in open set of compact connected manifold?","Exist vector field having only finitely many zeros, all lying in open set of compact connected manifold?",,"Let $U$ be any open set on the compact connected manifold $X$. Does there exist a vector field having only finitely many zeros, all of which lie in $U$?","Let $U$ be any open set on the compact connected manifold $X$. Does there exist a vector field having only finitely many zeros, all of which lie in $U$?",,"['general-topology', 'differential-geometry']"
75,explanation of differential geometry concept,explanation of differential geometry concept,,"The  derivative of paremeterized curve $r(t)$  gives the attached tangent vector at that point , if $\dot{r}(t)=\vec t$ is further differentiated , $r''(t)=\dot{\vec{t}}=\kappa n$. where n is the normal attached at that point  but in the given illustration the $\dot{\vec{t}}$ is not in the direction of n . please help i am confused and quite naive in this topic. is the principal normal vector $\vec{p}$ different from the normal vector n? reference page 5 https://www.cmu.edu/biolphys/deserno/pdf/diff_geom.pdf","The  derivative of paremeterized curve $r(t)$  gives the attached tangent vector at that point , if $\dot{r}(t)=\vec t$ is further differentiated , $r''(t)=\dot{\vec{t}}=\kappa n$. where n is the normal attached at that point  but in the given illustration the $\dot{\vec{t}}$ is not in the direction of n . please help i am confused and quite naive in this topic. is the principal normal vector $\vec{p}$ different from the normal vector n? reference page 5 https://www.cmu.edu/biolphys/deserno/pdf/diff_geom.pdf",,"['calculus', 'differential-geometry']"
76,Prove that the curvature of a connection on a line bundle is a global two form,Prove that the curvature of a connection on a line bundle is a global two form,,"For a connection $\nabla$ on a line bundle, in a local trivialisation, the connection looks like a one form $\nabla s=ds + sa$ but this is not a proper one form cause it depnds on the choice of local trivialization. Why does the curvature $da$ not depend on the choice of local trivialization?? Why does $da(X,Y)s=\nabla_X\nabla_Y-\nabla_Y\nabla_X-\nabla_{[X,Y]}$?","For a connection $\nabla$ on a line bundle, in a local trivialisation, the connection looks like a one form $\nabla s=ds + sa$ but this is not a proper one form cause it depnds on the choice of local trivialization. Why does the curvature $da$ not depend on the choice of local trivialization?? Why does $da(X,Y)s=\nabla_X\nabla_Y-\nabla_Y\nabla_X-\nabla_{[X,Y]}$?",,"['geometry', 'differential-geometry', 'vector-bundles', 'connections']"
77,Why the vertical lift of a vector bundle takes values on the vertical bundle?,Why the vertical lift of a vector bundle takes values on the vertical bundle?,,"Let $(E,\pi,M)$ be a vector bundle. The vertical bundle of this vector bundle is the subbundle $VE$ of the tangent bundle $TE$ (as a vector bundle $(TE, T\pi, TM)$ over $TM$), such that: $VE = (T\pi)^{-1}(0)$. Then the $\textit{vertical lift}$ is the map $\text{vl}_E: E \times_M E \rightarrow VE$ defined fiberwise as $\text{vl}_E(u_p,v_p) = \frac{d}{dt}|_{t=0}(u_p + tv_p)$. Why this map takes values exactly on $VE$, and not generally on $TE$?","Let $(E,\pi,M)$ be a vector bundle. The vertical bundle of this vector bundle is the subbundle $VE$ of the tangent bundle $TE$ (as a vector bundle $(TE, T\pi, TM)$ over $TM$), such that: $VE = (T\pi)^{-1}(0)$. Then the $\textit{vertical lift}$ is the map $\text{vl}_E: E \times_M E \rightarrow VE$ defined fiberwise as $\text{vl}_E(u_p,v_p) = \frac{d}{dt}|_{t=0}(u_p + tv_p)$. Why this map takes values exactly on $VE$, and not generally on $TE$?",,"['differential-geometry', 'smooth-manifolds', 'vector-bundles']"
78,Smoothness of solutions of the curve shortening flow given bounded curvature,Smoothness of solutions of the curve shortening flow given bounded curvature,,"I've been looking at the Lemma 1.5 of The Heat Equation Shrinks Embedded Plane Curves to Round Points ( here ), where Matthew Grayson proved that If $\kappa(s,t)$ is bounded for $t\in[0,t_0)$. Then for some $\varepsilon>0$, $C(t)$ exists and is smooth for $t\in [0,t_0+\varepsilon)$. In the proof he uses the formula  $${\partial\over\partial t}{\partial\over\partial s}={\partial\over\partial s}{\partial\over\partial t}+\kappa^2{\partial\over\partial s}$$ and also $${\partial\kappa\over\partial t}={\partial^2\kappa\over\partial s^2}+\kappa^3$$ to obtain that $${\partial\over\partial t}\left({\partial\kappa\over\partial s}\right)={\partial\over\partial s^2}\left({\partial\kappa\over\partial s}\right)+4\kappa^2\left({\partial\kappa\over\partial s}\right).$$ He claims that this equation bounds the rate of growth of ${\partial\kappa\over\partial s}$ to exponential. Repeated applications of the first formula yield $${\partial\over\partial t}\left({\partial^n\kappa\over\partial s^n}\right)={\partial\over\partial s^2}\left({\partial^n\kappa\over\partial s^n}\right)+(n+3)\kappa^2\left({\partial^n\kappa\over\partial s^n}\right)\;+\;\text{previously bounded terms},$$ so he gets the same as before for the $n$-th derivative of $\kappa$. With this, using again the first formula, it is proved that the curve converges as $t\to t_0$. And similarly, $C(t_0)$ is smooth. He finally applies the Theorem 1.1 to obtain that $C(t)$ exists and is smooth for some further short time. I'm struggling to understand the key parts of this proof: The boundedness of the derivatives is not that obvious to me from the above formulas. I guess he gets an PDE which solution can be bounded by an exponential, but if so I don't really see how. From the boundedness of the derivatives of $\kappa$ with respect to $s$ for a fixed $t$, $C(t)$ converges as $t\to t_0$. This is because with $\kappa$ and its derivatives bounded, the curves under the flow must exist for $t\in[0,t_0)$. And the same argument for the smoothness... Am I right? As you can see I'm kind of lost here, it would be great if anyone could explain to me a little bit these two ideas. Thanks in advance.","I've been looking at the Lemma 1.5 of The Heat Equation Shrinks Embedded Plane Curves to Round Points ( here ), where Matthew Grayson proved that If $\kappa(s,t)$ is bounded for $t\in[0,t_0)$. Then for some $\varepsilon>0$, $C(t)$ exists and is smooth for $t\in [0,t_0+\varepsilon)$. In the proof he uses the formula  $${\partial\over\partial t}{\partial\over\partial s}={\partial\over\partial s}{\partial\over\partial t}+\kappa^2{\partial\over\partial s}$$ and also $${\partial\kappa\over\partial t}={\partial^2\kappa\over\partial s^2}+\kappa^3$$ to obtain that $${\partial\over\partial t}\left({\partial\kappa\over\partial s}\right)={\partial\over\partial s^2}\left({\partial\kappa\over\partial s}\right)+4\kappa^2\left({\partial\kappa\over\partial s}\right).$$ He claims that this equation bounds the rate of growth of ${\partial\kappa\over\partial s}$ to exponential. Repeated applications of the first formula yield $${\partial\over\partial t}\left({\partial^n\kappa\over\partial s^n}\right)={\partial\over\partial s^2}\left({\partial^n\kappa\over\partial s^n}\right)+(n+3)\kappa^2\left({\partial^n\kappa\over\partial s^n}\right)\;+\;\text{previously bounded terms},$$ so he gets the same as before for the $n$-th derivative of $\kappa$. With this, using again the first formula, it is proved that the curve converges as $t\to t_0$. And similarly, $C(t_0)$ is smooth. He finally applies the Theorem 1.1 to obtain that $C(t)$ exists and is smooth for some further short time. I'm struggling to understand the key parts of this proof: The boundedness of the derivatives is not that obvious to me from the above formulas. I guess he gets an PDE which solution can be bounded by an exponential, but if so I don't really see how. From the boundedness of the derivatives of $\kappa$ with respect to $s$ for a fixed $t$, $C(t)$ converges as $t\to t_0$. This is because with $\kappa$ and its derivatives bounded, the curves under the flow must exist for $t\in[0,t_0)$. And the same argument for the smoothness... Am I right? As you can see I'm kind of lost here, it would be great if anyone could explain to me a little bit these two ideas. Thanks in advance.",,"['differential-geometry', 'partial-differential-equations', 'heat-equation', 'mean-curvature-flows']"
79,Equivalent condition for the normal lines of a curve $\alpha(s)$ to be equidistant from a fixed point,Equivalent condition for the normal lines of a curve  to be equidistant from a fixed point,\alpha(s),"Let $\alpha : I \rightarrow \mathbb{R^2}$ be a curve parametrized by arc length. Show that all normal lines of $\alpha$ are equidistant from a fixed point if and only if there exist numbers $a,b \in \mathbb{R}$ such that $k(s) = \pm \cfrac{1}{\sqrt{as+b}}$ $\forall s \in I$, where $k(s)$ denotes the curvature of $\alpha$ at the point $s$. I'm kinda lost on this one and don't know where to start or how to attack the problem so any hints or ideas would be greatly appreciated.","Let $\alpha : I \rightarrow \mathbb{R^2}$ be a curve parametrized by arc length. Show that all normal lines of $\alpha$ are equidistant from a fixed point if and only if there exist numbers $a,b \in \mathbb{R}$ such that $k(s) = \pm \cfrac{1}{\sqrt{as+b}}$ $\forall s \in I$, where $k(s)$ denotes the curvature of $\alpha$ at the point $s$. I'm kinda lost on this one and don't know where to start or how to attack the problem so any hints or ideas would be greatly appreciated.",,['differential-geometry']
80,Proving that $\mathbb{R}P^n$ is a manifold,Proving that  is a manifold,\mathbb{R}P^n,"Consider $\mathbb{R}P^n$ as the quotient space of $S^n$ with antipodal points identified. Prove that $\mathbb{R}P^n$ is a manifold of dimension $n$. (I'd like to clarify that I've seen the solution to this exersice when we see $\mathbb{R}P^n$ as the quotient of $\mathbb{R}^{n+1}$ with lines identified. I'd like to know if the same answer would solve the problem when it is quotient of $S^n$.) I already proved $\mathbb{R}P^n$ is $T_2$ and second countable. By doing the same thing when $\mathbb{R}P^n$ is quotient of $\mathbb{R}^{n+1}$, I consider the open set: $$V_i=\{x\in S^n:x_i\neq 0\},\quad \quad i=1,...,n+1,$$ and $$F_i:V_i\to\mathbb{R}^n,\quad F_i(x_1,...,x_{n+1})=\dfrac{1}{x_i}(x_1,..,x_{i-1},x_{i+1},...,x_n).$$ And then one should prove that $\phi_i:\pi(V_i)\to\mathbb{R}^n$ given by $\phi_i(\pi(x))=F_i(x)$ is a homeomorphism (where $\pi$ is the projection, which is open). I already proved $\phi _i$ is injective and continuous, but I can't prove that it is surjective. If we take any $(x_1,..,x_n)\in\mathbb{R}^n$, the natural choice would be: $$F_i(x_1,...,x_{i-1},1,x_{i},...,x_n)=(x_1,...,x_n).$$ But $(x_1,...,x_{i-1},1,x_{i},...,x_n)$ need not be in $S^n$. Also, what would be $\phi^{-1}$? (In order to prove the inverse is continous...) Or maybe $\phi_i$ is not surjective and we need another function. Any help? Thank you.","Consider $\mathbb{R}P^n$ as the quotient space of $S^n$ with antipodal points identified. Prove that $\mathbb{R}P^n$ is a manifold of dimension $n$. (I'd like to clarify that I've seen the solution to this exersice when we see $\mathbb{R}P^n$ as the quotient of $\mathbb{R}^{n+1}$ with lines identified. I'd like to know if the same answer would solve the problem when it is quotient of $S^n$.) I already proved $\mathbb{R}P^n$ is $T_2$ and second countable. By doing the same thing when $\mathbb{R}P^n$ is quotient of $\mathbb{R}^{n+1}$, I consider the open set: $$V_i=\{x\in S^n:x_i\neq 0\},\quad \quad i=1,...,n+1,$$ and $$F_i:V_i\to\mathbb{R}^n,\quad F_i(x_1,...,x_{n+1})=\dfrac{1}{x_i}(x_1,..,x_{i-1},x_{i+1},...,x_n).$$ And then one should prove that $\phi_i:\pi(V_i)\to\mathbb{R}^n$ given by $\phi_i(\pi(x))=F_i(x)$ is a homeomorphism (where $\pi$ is the projection, which is open). I already proved $\phi _i$ is injective and continuous, but I can't prove that it is surjective. If we take any $(x_1,..,x_n)\in\mathbb{R}^n$, the natural choice would be: $$F_i(x_1,...,x_{i-1},1,x_{i},...,x_n)=(x_1,...,x_n).$$ But $(x_1,...,x_{i-1},1,x_{i},...,x_n)$ need not be in $S^n$. Also, what would be $\phi^{-1}$? (In order to prove the inverse is continous...) Or maybe $\phi_i$ is not surjective and we need another function. Any help? Thank you.",,"['differential-geometry', 'differential-topology']"
81,A formula for the projection onto the tangent plane $P= I-\vec n \cdot \vec n^T$,A formula for the projection onto the tangent plane,P= I-\vec n \cdot \vec n^T,"Suppose that $N = 3$ and $d = 2$ (so that $\Sigma$ is a surface in $\mathbb R^3$ ), and suppose that $$f: R^3 \to R$$ is $C^\infty$ , and that $\operatorname{grad} f $ does not vanish on $\Sigma =f^{-1}(0)$ . Then the normal vector $$\vec n(X) = \frac{\operatorname{grad} f(X)}{|\operatorname{grad} f(X)|}$$ can be defined everywhere in a neighbourhood of $\Sigma$ , and one can take $$P(X) = I-\vec n(X)\cdot \vec n(X)^T,$$ where $P(X)$ is the orthogonal projection on to the tangent space $T_p \Sigma$ . How to prove this result? I know that the projection of the vector onto the subspace is given by $P=A(A^TA)^{-1}A^T$ .","Suppose that and (so that is a surface in ), and suppose that is , and that does not vanish on . Then the normal vector can be defined everywhere in a neighbourhood of , and one can take where is the orthogonal projection on to the tangent space . How to prove this result? I know that the projection of the vector onto the subspace is given by .","N = 3 d = 2 \Sigma \mathbb R^3 f: R^3 \to R C^\infty \operatorname{grad} f  \Sigma =f^{-1}(0) \vec n(X) = \frac{\operatorname{grad} f(X)}{|\operatorname{grad} f(X)|} \Sigma P(X) = I-\vec n(X)\cdot \vec n(X)^T, P(X) T_p \Sigma P=A(A^TA)^{-1}A^T","['linear-algebra', 'differential-geometry', 'submanifold']"
82,Showing that a function with a second-order zero at $m$ is sent to zero by the whole $T_mM$.,Showing that a function with a second-order zero at  is sent to zero by the whole .,m T_mM,"I was given the following as an exercise. Prove that if $f\in\mathcal{C}^\infty(M)$ where $M$ is a manifold, $f(m)=0$ for some $m\in M$, and the zero is second-order, i.e. in some chart $\phi$ we have $f\circ\phi^{-1}$ with derivatives all zero, then all $v\in T_mM$ send $f$ to 0, i.e. $v(f)=0$ for all $v\in T_mM$. $T_mM$ was defined as the space of all tangent vectors, which were defined as follows. $v:\mathcal{C}^\infty(M)\to\mathbb R$ is a tangent vector at $m\in M$ if: It is linear, i.e. $v(\alpha f+\beta g)=\alpha v(f)+\beta v(g)$ for all $f,g\in\mathcal{C}^\infty(M)$; It satisfies the Leibniz rule, that is $v(fg)=f(m)v(g)+g(m)v(f)$ for all $f,g\in\mathcal{C}^\infty(M)$. In another course, tangent vectors were defined as linear functionals on germs satisfying Leibniz. So the domain of $v$ were not $\mathcal{C}^\infty(M)$, but a quotient of that, identifying all functions coinciding in a neighborhood of $m$. Unfortunately, no mention of germs was made in the definition of this course, so a priori I cannot say that if $f=g$ in a neighborhood of $m$, then $v(f)=v(g)$ for any $v\in T_mM$. My try would have been to use the well-known basis of $T_mM$, the derivative vectors. However: The exercise was given before proving those vectors are a basis, so it should be possible to do it without them; The exercise was used to prove those vectors are a basis, so it must be possible without them. Here is how the statement about derivative vectors was proved. Consider $D$ a derivation at $m$ acting on $\mathcal{C}^\infty(M)$. Then it induces a derivation at $m$ acting on $\mathcal{C}^\infty(U)$, where $U$ is any open set in $M$. That is because I can take $f\in\mathcal{C}^\infty(U)$ and extend it. This extension is done via a bump function $\rho\in\mathcal{C}^\infty(M)$ which is one in a neighborhood of $m$, zero outside $U$, and smooth all over $M$. We define $\hat D(f)$ to be $D(\rho f)$. As long as we choose $\rho$ as said above, the $\hat D$ will not depend on $\rho$, since any two extensions $\rho_1f,\rho_2f$ will coincide in a neighborhood of $m$, precisely where both $\rho_1$ and $\rho_2$ are equal to 1. If two functions coincide in a neighborhood of $m$, their difference has a second-order zero at $m$, hence, by the exercise, $D(\rho_1f-\rho_2f)=0$. If I choose $U$ to be the domain of a local chart $\phi$, I can expand $f\circ\phi^{-1}$ with a sort of Taylor expansion, then deduce a similar expansion for $f$, and finally deduce from that expansion that I can reconstruct any derivation at $m$ acting on $\mathcal{C}^\infty(U)$ via the particular derivations that map a function $f\in\mathcal{C}^\infty(U)$ to one of the derivatives of $f\circ\phi^{-1}$ at $\phi(m)$. But then any derivative acting on $\mathcal{C}^\infty(M)$ induces one on $\mathcal{C}^\infty(U)$, so I have a system of generators for $T_mM$. And oh well those generators are independent and thus a basis. So I cannot (AFAICS) go local in my exercise, because that would require inducing a tangent vector to $U$ from $v\in T_mM$, and that should be done by some extension of $f$ to $M$, and that would require well-posedness of the image of the extension, which, as seen above, was proved with the second-order thing, since clearly any two extensions of $f$ to $M$ coincide in the neighborhood $U$ of $m$. So how can I solve this problem? How can I prove either of the following two? The properties given for tangent vectors imply locality, i.e. that if $f=g$ in a neighborhood of $m$ then $v(f)=v(g)$ for all $v\in T_mM$. The stronger second-order statement at the question start.","I was given the following as an exercise. Prove that if $f\in\mathcal{C}^\infty(M)$ where $M$ is a manifold, $f(m)=0$ for some $m\in M$, and the zero is second-order, i.e. in some chart $\phi$ we have $f\circ\phi^{-1}$ with derivatives all zero, then all $v\in T_mM$ send $f$ to 0, i.e. $v(f)=0$ for all $v\in T_mM$. $T_mM$ was defined as the space of all tangent vectors, which were defined as follows. $v:\mathcal{C}^\infty(M)\to\mathbb R$ is a tangent vector at $m\in M$ if: It is linear, i.e. $v(\alpha f+\beta g)=\alpha v(f)+\beta v(g)$ for all $f,g\in\mathcal{C}^\infty(M)$; It satisfies the Leibniz rule, that is $v(fg)=f(m)v(g)+g(m)v(f)$ for all $f,g\in\mathcal{C}^\infty(M)$. In another course, tangent vectors were defined as linear functionals on germs satisfying Leibniz. So the domain of $v$ were not $\mathcal{C}^\infty(M)$, but a quotient of that, identifying all functions coinciding in a neighborhood of $m$. Unfortunately, no mention of germs was made in the definition of this course, so a priori I cannot say that if $f=g$ in a neighborhood of $m$, then $v(f)=v(g)$ for any $v\in T_mM$. My try would have been to use the well-known basis of $T_mM$, the derivative vectors. However: The exercise was given before proving those vectors are a basis, so it should be possible to do it without them; The exercise was used to prove those vectors are a basis, so it must be possible without them. Here is how the statement about derivative vectors was proved. Consider $D$ a derivation at $m$ acting on $\mathcal{C}^\infty(M)$. Then it induces a derivation at $m$ acting on $\mathcal{C}^\infty(U)$, where $U$ is any open set in $M$. That is because I can take $f\in\mathcal{C}^\infty(U)$ and extend it. This extension is done via a bump function $\rho\in\mathcal{C}^\infty(M)$ which is one in a neighborhood of $m$, zero outside $U$, and smooth all over $M$. We define $\hat D(f)$ to be $D(\rho f)$. As long as we choose $\rho$ as said above, the $\hat D$ will not depend on $\rho$, since any two extensions $\rho_1f,\rho_2f$ will coincide in a neighborhood of $m$, precisely where both $\rho_1$ and $\rho_2$ are equal to 1. If two functions coincide in a neighborhood of $m$, their difference has a second-order zero at $m$, hence, by the exercise, $D(\rho_1f-\rho_2f)=0$. If I choose $U$ to be the domain of a local chart $\phi$, I can expand $f\circ\phi^{-1}$ with a sort of Taylor expansion, then deduce a similar expansion for $f$, and finally deduce from that expansion that I can reconstruct any derivation at $m$ acting on $\mathcal{C}^\infty(U)$ via the particular derivations that map a function $f\in\mathcal{C}^\infty(U)$ to one of the derivatives of $f\circ\phi^{-1}$ at $\phi(m)$. But then any derivative acting on $\mathcal{C}^\infty(M)$ induces one on $\mathcal{C}^\infty(U)$, so I have a system of generators for $T_mM$. And oh well those generators are independent and thus a basis. So I cannot (AFAICS) go local in my exercise, because that would require inducing a tangent vector to $U$ from $v\in T_mM$, and that should be done by some extension of $f$ to $M$, and that would require well-posedness of the image of the extension, which, as seen above, was proved with the second-order thing, since clearly any two extensions of $f$ to $M$ coincide in the neighborhood $U$ of $m$. So how can I solve this problem? How can I prove either of the following two? The properties given for tangent vectors imply locality, i.e. that if $f=g$ in a neighborhood of $m$ then $v(f)=v(g)$ for all $v\in T_mM$. The stronger second-order statement at the question start.",,"['differential-geometry', 'smooth-manifolds']"
83,Proving continuity/smoothness for a special function on a Lie group.,Proving continuity/smoothness for a special function on a Lie group.,,"So I asked this question , yesterday, forgetting the compactness requirement. Jack Lee commented shortly afterwards, noting that, if we take an inner product on the Lie algebra $T_eG$ of a Lie group $G$, extend it to a left-invariant metric on $G$, and define: $$(u,v)_g=\int\limits_G\langle\mathrm{d}_gR_h(u),\mathrm{d}_gR_h(v)\rangle_{gh}d\mu(h),$$ where $\mu$ is the unique left-invariant Haar measure that exists on $G$, the integral might not converge. If $G$ is not compact. So I wondered why compactness ensured convergence, and he said the integrand is continuous, hence integrable on a compact set. Now I can see how continuous would imply bounded. But I'm not too sure I can always guarantee a compact set will have finite measure and hence allow integration of constants. In fact, reading that pdf again, the Haar measure is defined to have this property, and in the construction, the property is evident. But above all, I'm not too sure how to prove continuity. I was thinking I could maybe show the two entries of the metric are smooth vector fields, but then $h\mapsto\mathrm{d}_gR_h(u)$ with $u$ tangent at $g$ is not a vector field because it outputs something not tangent at $h$, but at $gh$. So perhaps I could use the left-invariance of $\langle\cdot,\cdot\rangle$ to get actual vector fields and work on those: $$\langle\mathrm{d}_gR_h(u),\mathrm{d}_gR_h(v)\rangle = \langle(\mathrm{d}_hL_g)^{-1}\mathrm{d}_gR_h(u),(\mathrm{d}_hL_g)^{-1}\mathrm{d}_gR_h(v)\rangle_h.$$ Now the two entries are vector fields, so if I show they are smooth, since I know $\langle\cdot,\cdot\rangle$ is a metric, I conclude the integrand is smooth, hence continuous. But I'm not sure how to do this.","So I asked this question , yesterday, forgetting the compactness requirement. Jack Lee commented shortly afterwards, noting that, if we take an inner product on the Lie algebra $T_eG$ of a Lie group $G$, extend it to a left-invariant metric on $G$, and define: $$(u,v)_g=\int\limits_G\langle\mathrm{d}_gR_h(u),\mathrm{d}_gR_h(v)\rangle_{gh}d\mu(h),$$ where $\mu$ is the unique left-invariant Haar measure that exists on $G$, the integral might not converge. If $G$ is not compact. So I wondered why compactness ensured convergence, and he said the integrand is continuous, hence integrable on a compact set. Now I can see how continuous would imply bounded. But I'm not too sure I can always guarantee a compact set will have finite measure and hence allow integration of constants. In fact, reading that pdf again, the Haar measure is defined to have this property, and in the construction, the property is evident. But above all, I'm not too sure how to prove continuity. I was thinking I could maybe show the two entries of the metric are smooth vector fields, but then $h\mapsto\mathrm{d}_gR_h(u)$ with $u$ tangent at $g$ is not a vector field because it outputs something not tangent at $h$, but at $gh$. So perhaps I could use the left-invariance of $\langle\cdot,\cdot\rangle$ to get actual vector fields and work on those: $$\langle\mathrm{d}_gR_h(u),\mathrm{d}_gR_h(v)\rangle = \langle(\mathrm{d}_hL_g)^{-1}\mathrm{d}_gR_h(u),(\mathrm{d}_hL_g)^{-1}\mathrm{d}_gR_h(v)\rangle_h.$$ Now the two entries are vector fields, so if I show they are smooth, since I know $\langle\cdot,\cdot\rangle$ is a metric, I conclude the integrand is smooth, hence continuous. But I'm not sure how to do this.",,"['differential-geometry', 'lie-groups', 'vector-fields']"
84,Linear Connection on the Hyperbolic Plane,Linear Connection on the Hyperbolic Plane,,"For the upper half-plane $\mathbb{H}^2=\{x+iy\in\mathbb{C}\ \vert\ y>0\}$ equipped with the metric $g = \frac{1}{y^2}(dx^2+dy^2)$, I computed the Christoffel symbols as follows: $$\begin{align}\Gamma^1_{12}&=\Gamma^1_{12}=-\frac{1}{y}\\\Gamma^2_{11}&=\frac{1}{y}\\\Gamma^2_{22}&=-\frac{1}{y}\end{align}$$ Then using the relation between the connection matrix and the Christoffel symbols $\omega^k_j=\Gamma^k_{ij}dx^i$, I computed $$\begin{align} \omega^1_1 &=-\frac{1}{y}dy\\ \omega^1_2 &=-\frac{1}{y}dx\\ \omega^2_1 &=\frac{1}{y}dx\\ \omega^2_2 &=-\frac{1}{y}dy \end{align}$$ I now have two questions: To get the matrix $\omega$ proper, do I now need to contract an index with the metric? How do I actually carry out a computation of $\nabla_X(S)$ for $X\in\Gamma(T\mathbb{H}^2),\ S\in\Gamma(\xi)$? It's clear to me that I should just stick the column vector $S$ to the right of the matrix $\omega$ and multiply in the obvious way, but how do I ""plug in"" the vector field $X$? An example would be really helpful. Thanks!","For the upper half-plane $\mathbb{H}^2=\{x+iy\in\mathbb{C}\ \vert\ y>0\}$ equipped with the metric $g = \frac{1}{y^2}(dx^2+dy^2)$, I computed the Christoffel symbols as follows: $$\begin{align}\Gamma^1_{12}&=\Gamma^1_{12}=-\frac{1}{y}\\\Gamma^2_{11}&=\frac{1}{y}\\\Gamma^2_{22}&=-\frac{1}{y}\end{align}$$ Then using the relation between the connection matrix and the Christoffel symbols $\omega^k_j=\Gamma^k_{ij}dx^i$, I computed $$\begin{align} \omega^1_1 &=-\frac{1}{y}dy\\ \omega^1_2 &=-\frac{1}{y}dx\\ \omega^2_1 &=\frac{1}{y}dx\\ \omega^2_2 &=-\frac{1}{y}dy \end{align}$$ I now have two questions: To get the matrix $\omega$ proper, do I now need to contract an index with the metric? How do I actually carry out a computation of $\nabla_X(S)$ for $X\in\Gamma(T\mathbb{H}^2),\ S\in\Gamma(\xi)$? It's clear to me that I should just stick the column vector $S$ to the right of the matrix $\omega$ and multiply in the obvious way, but how do I ""plug in"" the vector field $X$? An example would be really helpful. Thanks!",,"['differential-geometry', 'riemannian-geometry', 'connections']"
85,"Compute the degree of $\phi:(x_1,x_2,x_3,x_4) \mapsto (x_1,-x_3,-x_2,x_4)$. Does $\phi$ preserve orientation?",Compute the degree of . Does  preserve orientation?,"\phi:(x_1,x_2,x_3,x_4) \mapsto (x_1,-x_3,-x_2,x_4) \phi","Consider the map $\phi:S^3 \rightarrow S^3$ given by $\phi(x_1,x_2,x_3,x_4)=(x_1,-x_3,-x_2,x_4)$. Compute the degree of $\phi$. Does $\phi$ preserve orientation? First I want to point everything that I made: Some introduction: a regular value of a smooth map $\phi:M \rightarrow N$ is a point $a \in N$ such that for each $x \in \phi^{-1}(a)$ the derivative $D\phi_x$ is surjective. If $a$ is a regular value of $\phi$ then $$deg \ \phi=\sum_{x \in \phi^{-1}(a)} sgn \ (det \ D\phi_x)$$ Here in this particular case, $D\phi_x=\begin{bmatrix} 1 & 0 & 0 & 0\\  0 & 0 & -1 & 0\\  0 & -1 & 0 & 0\\  0 & 0 & 0 & 1 \end{bmatrix}$, so every $a \in S^3$ is a regular value of $\phi$. Moreover, $\phi$ is a bijection, so the above sum has only one component and $D\phi_x$ does not depend on $x \in S^3$. Then $deg \ \phi = -1$. For the second part of the question, I take the chart $(U,\varphi)$ of $S^3$, where $U=\{(x_1,x_2,x_3,x_4):x_1>0\}$ and $\varphi:U \rightarrow \mathbb{R}^3$ given by $\varphi(x_1,x_2,x_3,x_4)=(x_2,x_3,x_4)$. So $\omega=-\frac{1}{x_1}dx_2 \wedge dx_3 \wedge dx_4$ is a well defined orientation on $U$. If we can show that $\omega \circ \phi (=\phi^* \omega) = -\omega$, then we can say that $\phi$ does not preserve orientation (I have a feeling that $\phi$ does not preserve orientation, but if the point was to prove that it does preserve orientation, we have to check every chart in an atlas of $S^3$, which is not quick and interesting at all) So $\omega \circ \phi = -\frac{1}{x_1}d(-x_3) \wedge d(-x_2) \wedge dx_4 = +\frac{1}{x_1}dx_2 \wedge dx_3 \wedge dx_4 = -\omega$. Then $\phi$ does not preserve orientation. Is this all correct? Something that I missed? Thanks!","Consider the map $\phi:S^3 \rightarrow S^3$ given by $\phi(x_1,x_2,x_3,x_4)=(x_1,-x_3,-x_2,x_4)$. Compute the degree of $\phi$. Does $\phi$ preserve orientation? First I want to point everything that I made: Some introduction: a regular value of a smooth map $\phi:M \rightarrow N$ is a point $a \in N$ such that for each $x \in \phi^{-1}(a)$ the derivative $D\phi_x$ is surjective. If $a$ is a regular value of $\phi$ then $$deg \ \phi=\sum_{x \in \phi^{-1}(a)} sgn \ (det \ D\phi_x)$$ Here in this particular case, $D\phi_x=\begin{bmatrix} 1 & 0 & 0 & 0\\  0 & 0 & -1 & 0\\  0 & -1 & 0 & 0\\  0 & 0 & 0 & 1 \end{bmatrix}$, so every $a \in S^3$ is a regular value of $\phi$. Moreover, $\phi$ is a bijection, so the above sum has only one component and $D\phi_x$ does not depend on $x \in S^3$. Then $deg \ \phi = -1$. For the second part of the question, I take the chart $(U,\varphi)$ of $S^3$, where $U=\{(x_1,x_2,x_3,x_4):x_1>0\}$ and $\varphi:U \rightarrow \mathbb{R}^3$ given by $\varphi(x_1,x_2,x_3,x_4)=(x_2,x_3,x_4)$. So $\omega=-\frac{1}{x_1}dx_2 \wedge dx_3 \wedge dx_4$ is a well defined orientation on $U$. If we can show that $\omega \circ \phi (=\phi^* \omega) = -\omega$, then we can say that $\phi$ does not preserve orientation (I have a feeling that $\phi$ does not preserve orientation, but if the point was to prove that it does preserve orientation, we have to check every chart in an atlas of $S^3$, which is not quick and interesting at all) So $\omega \circ \phi = -\frac{1}{x_1}d(-x_3) \wedge d(-x_2) \wedge dx_4 = +\frac{1}{x_1}dx_2 \wedge dx_3 \wedge dx_4 = -\omega$. Then $\phi$ does not preserve orientation. Is this all correct? Something that I missed? Thanks!",,"['differential-geometry', 'manifolds', 'differential-forms', 'smooth-manifolds', 'orientation']"
86,Lie group acting transitively => connected component acts locally transitive?,Lie group acting transitively => connected component acts locally transitive?,,"Suppose $G$ is a Lie group acting transitively on a manifold $M$ . Does that already imply that the connected component $G^\circ$ of $G$ acts transitively on the connected components of $M$ ? I have a ""proof"" here but not sure if it is all correct: Let $x \in M$ and define $G_x$ as the isotropy group of $x$ . Since $G$ acts transitively on $M$ we have that $M$ is a homogeneous space and it is diffeomorphic to $G / G_x$ . We have that $\pi_x \colon G \to G/G_x=M$ is an open map and since $G^\circ$ is open in $G$ , $\pi_x(G^°)$ is open in $M$ . But $\pi_x(G^°)$ is the $G^°$ -orbit through $x$ . Using that for each $x \in M$ , we get that $\pi_x(G^°)$ is closed and open and hence $\pi_x(G^°)$ is the union of connected components of $M$ . Futhermore $x \in \pi_x(G^°)$ , so the component containing $x$ is contained in $\pi_x(G^°)$ .","Suppose is a Lie group acting transitively on a manifold . Does that already imply that the connected component of acts transitively on the connected components of ? I have a ""proof"" here but not sure if it is all correct: Let and define as the isotropy group of . Since acts transitively on we have that is a homogeneous space and it is diffeomorphic to . We have that is an open map and since is open in , is open in . But is the -orbit through . Using that for each , we get that is closed and open and hence is the union of connected components of . Futhermore , so the component containing is contained in .",G M G^\circ G M x \in M G_x x G M M G / G_x \pi_x \colon G \to G/G_x=M G^\circ G \pi_x(G^°) M \pi_x(G^°) G^° x x \in M \pi_x(G^°) \pi_x(G^°) M x \in \pi_x(G^°) x \pi_x(G^°),"['differential-geometry', 'lie-groups']"
87,Compact Manifold with Geodesic B0undary,Compact Manifold with Geodesic B0undary,,"Suppose $(M,g)$ is a 2-dimenensional compact Riemannian manifold with boundary $S$. Furthermore, assume that $S$ is totally geodesic. Now consider the conformal change of metric $\widetilde{g}=e^{\phi}g$ for some smooth function $\phi$. In order for $\widetilde{g}$ to satisfy the condition that $S$ is still totally geodesic, then it is necessary that $\partial_N \phi=0$. Is this condition sufficient?","Suppose $(M,g)$ is a 2-dimenensional compact Riemannian manifold with boundary $S$. Furthermore, assume that $S$ is totally geodesic. Now consider the conformal change of metric $\widetilde{g}=e^{\phi}g$ for some smooth function $\phi$. In order for $\widetilde{g}$ to satisfy the condition that $S$ is still totally geodesic, then it is necessary that $\partial_N \phi=0$. Is this condition sufficient?",,['differential-geometry']
88,How to interpret the notation of a formula?,How to interpret the notation of a formula?,,"I was reading a paper where the property of light known as Illuminance , for a specific setup (as in the figure) is given with the following formula: The description below the formula says: The illuminance $E$ on the road surface is given by the formula...  where   $d\Phi$ is the luminous flux (lm), $dA$ is the area of the road   surface (m2), $d\omega$ is the solid angle (sr), $I(\alpha, \beta)$ is   the luminous intensity (cd), $\alpha$ and $\beta$ is the horizontal   and vertical angle (in relation to the headlamp axis), respectively,   $r$ is the distance between the light source and the small area $dA$,   and $\theta$ is the angle between the road surface normal and the   incident direction Now I want to abstract for a moment and look at the formula purely mathematically, ignoring the light terminology. Can someone explain me the presence of $d$ in the formula? What does it represent mathematically? Something related to the derivatives? Why? Can you please provide a ""simple English"" explanation of the formula?","I was reading a paper where the property of light known as Illuminance , for a specific setup (as in the figure) is given with the following formula: The description below the formula says: The illuminance $E$ on the road surface is given by the formula...  where   $d\Phi$ is the luminous flux (lm), $dA$ is the area of the road   surface (m2), $d\omega$ is the solid angle (sr), $I(\alpha, \beta)$ is   the luminous intensity (cd), $\alpha$ and $\beta$ is the horizontal   and vertical angle (in relation to the headlamp axis), respectively,   $r$ is the distance between the light source and the small area $dA$,   and $\theta$ is the angle between the road surface normal and the   incident direction Now I want to abstract for a moment and look at the formula purely mathematically, ignoring the light terminology. Can someone explain me the presence of $d$ in the formula? What does it represent mathematically? Something related to the derivatives? Why? Can you please provide a ""simple English"" explanation of the formula?",,"['differential-geometry', 'self-learning']"
89,Map to exterior power gives rise to smooth embedding of Grassmannian in projective space?,Map to exterior power gives rise to smooth embedding of Grassmannian in projective space?,,"How do I see that the map$$(x_1, \dots, x_n) \mapsto x_1 \wedge \dots \wedge x_n$$from $V_n(\mathbb{R}^m)$ to the exterior power $\wedge^n(\mathbb{R}^m)$ gives rise to a smooth embedding of $G_n(\mathbb{R}^m)$ in the projective space $$G_1(\wedge^n(\mathbb{R}^m)) \cong \mathbb{P}^{\binom{m}{n} - 1}?$$","How do I see that the map$$(x_1, \dots, x_n) \mapsto x_1 \wedge \dots \wedge x_n$$from $V_n(\mathbb{R}^m)$ to the exterior power $\wedge^n(\mathbb{R}^m)$ gives rise to a smooth embedding of $G_n(\mathbb{R}^m)$ in the projective space $$G_1(\wedge^n(\mathbb{R}^m)) \cong \mathbb{P}^{\binom{m}{n} - 1}?$$",,"['linear-algebra', 'general-topology']"
90,Bundle notation used in defining Cartan connection,Bundle notation used in defining Cartan connection,,"I have been trying to understand Cartan connections based on the Wikipedia article , and I am confused about the following paragraph (here $P$ is a principal $H$-bundle with $H$ a Lie group): The pair $(\omega, \theta)$ (a principal connection and a solder form:   $\hspace{2pt}\omega:TP \to \mathfrak h$, $\theta: TP \to R^n$)   defines a 1-form $\eta$ on $P$, with values in the Lie algebra   $\mathfrak g$ of the semidirect product $G$ of $H$ with $R^n$, which   provides an isomorphism of each tangent space $T_p P$ with    $\mathfrak g$. It induces a principal connection $\alpha$ on the associated   principal $G$-bundle $P\times_{H}G$. This is a Cartan connection. (Note: the above is part of the article that serves to motivate Cartan connections; it is not the full, general definition). What does the $H$ subscript in $P\times_{H}G$ in the last line mean? My guess from the context is that $P\times_{H}G$ means to swap out the fibers of $P$ with $G/H$. But if this were correct, then the action of $G$ on the resulting fibers would not be free, and hence $P\times_{H}G$ would not be a principal $G$-bundle, whereas the last line refers to it as such.","I have been trying to understand Cartan connections based on the Wikipedia article , and I am confused about the following paragraph (here $P$ is a principal $H$-bundle with $H$ a Lie group): The pair $(\omega, \theta)$ (a principal connection and a solder form:   $\hspace{2pt}\omega:TP \to \mathfrak h$, $\theta: TP \to R^n$)   defines a 1-form $\eta$ on $P$, with values in the Lie algebra   $\mathfrak g$ of the semidirect product $G$ of $H$ with $R^n$, which   provides an isomorphism of each tangent space $T_p P$ with    $\mathfrak g$. It induces a principal connection $\alpha$ on the associated   principal $G$-bundle $P\times_{H}G$. This is a Cartan connection. (Note: the above is part of the article that serves to motivate Cartan connections; it is not the full, general definition). What does the $H$ subscript in $P\times_{H}G$ in the last line mean? My guess from the context is that $P\times_{H}G$ means to swap out the fibers of $P$ with $G/H$. But if this were correct, then the action of $G$ on the resulting fibers would not be free, and hence $P\times_{H}G$ would not be a principal $G$-bundle, whereas the last line refers to it as such.",,"['differential-geometry', 'cartan-geometry']"
91,Geometric Interpretation for Torsion,Geometric Interpretation for Torsion,,"This is actually two questions about the Wolfram MathWorld article on torsion here. 1: What is a geometric interpretation of torsion? For curvature I understand it as the reciprocal of the radius of the circle around which a point is moving at a given instant. But the description in the link says torsion ""is the rate of change of the curve's osculating plane"". I know what the osculating plane is, but what does it mean by its ""rate of change""? 2: This is a small point, but how do they get from the equation $$\tau = \frac{\left|\dot{x} \,\ddot{x} \, \dddot{x}\right|}{\left|\dot{x} \times \ddot{x}\right|^2}$$ to this? $$\tau = \rho^2 \,\left|\dot{x} \,\ddot{x} \, \dddot{x}\right|$$ (where $|x\,y\,z|$ is the triple product and $\rho$ is the radius of curvature) Is the following correct? $$\rho = \frac{\left| \dot{x} \right|^3}{\left|\dot{x} \times \ddot{x}\right|}$$ It seems like there is a factor of $\left| \dot{x} \right|^6$ unaccounted for.","This is actually two questions about the Wolfram MathWorld article on torsion here. 1: What is a geometric interpretation of torsion? For curvature I understand it as the reciprocal of the radius of the circle around which a point is moving at a given instant. But the description in the link says torsion ""is the rate of change of the curve's osculating plane"". I know what the osculating plane is, but what does it mean by its ""rate of change""? 2: This is a small point, but how do they get from the equation to this? (where is the triple product and is the radius of curvature) Is the following correct? It seems like there is a factor of unaccounted for.","\tau = \frac{\left|\dot{x} \,\ddot{x} \, \dddot{x}\right|}{\left|\dot{x} \times \ddot{x}\right|^2} \tau = \rho^2 \,\left|\dot{x} \,\ddot{x} \, \dddot{x}\right| |x\,y\,z| \rho \rho = \frac{\left| \dot{x} \right|^3}{\left|\dot{x} \times \ddot{x}\right|} \left| \dot{x} \right|^6",['differential-geometry']
92,Chern Classes via Grassmannians,Chern Classes via Grassmannians,,"Let $X$ be some smooth manifold and let $p:E\to X$ be a complex vector bundle of finite rank. Our goal is to classify $E$ up to bundle-isomorphisms. According to Atiyah's K-Theory book, there is a a bijection between the isomorphism classes $Vect_n(X)$ of rank $n$ vector bundles over $X$ and $$[X\to G_n(\mathbb{C}^\infty)]$$ the homotopy classes of maps $f:X\to G_n(\mathbb{C}^\infty)$ (the infinite Grassmannian). Thus, for each $E$ there is a unique homotopy class $[f_E:X\to G_n(\mathbb{C}^\infty)]$ determined by $E$. This in turn induces a map on any contravariant functor $\mathcal{F}$ from the homotopy category to an algebraic category $$ \mathcal{F}([f_E]): \mathcal{F}(G_n(\mathbb{C}^\infty))\to \mathcal{F}(X) $$ Then $\mathcal{F}([f_E]) \neq \mathcal{F}([f_\tilde{E}])$ implies $E \ncong\tilde{E}$, because $E\cong\tilde{E}$ implies $[f_E]=[f_\tilde{E}]$. Question 1: Is there any functor $\mathcal{F}$ such that $\mathcal{F}([f_E]) = \mathcal{F}([f_\tilde{E}])$ implies $E\cong \tilde{E}$? (perhaps for sufficient conditions on $X$?) Question 2: Is it the case that the $k$th Chern class of $E$ is given by $\mathcal{F}([f_E])(c_k)$ where $c_k\in\mathcal{F}(G_n(\mathbb{C}^\infty))$, and $\mathcal{F}$ is either the de Rham or the singular $k$th cohomology functor? If yes, is there a difference between using de Rham cohomology or singular cohomology? Also, how to determine $c_k$ concretely? I realize that $c_k$ is defined as the $k$th Chern class of the classifying bundle (the bundle quotient $(G_n(\mathbb{C}^m)\times \mathbb{C}^m)/F$ where $F$ is the tautological $n$-plane bundle), but is there a way to explain the definition of $c_k$ using this language without reverting to other constructions such as the Euler characteristic or invariant polynomials? Question 3: What could one obtain by using other functors? For instance, the singular homology functor? The $n$th homotopy group functor? Why does one never hear about these? Also, why is it that one only uses the even-degree cohomology functor in this context? Is there a textbook that is very similar to Chern's original 1945 paper, but which uses regular vector bundles instead of sphere bundles?","Let $X$ be some smooth manifold and let $p:E\to X$ be a complex vector bundle of finite rank. Our goal is to classify $E$ up to bundle-isomorphisms. According to Atiyah's K-Theory book, there is a a bijection between the isomorphism classes $Vect_n(X)$ of rank $n$ vector bundles over $X$ and $$[X\to G_n(\mathbb{C}^\infty)]$$ the homotopy classes of maps $f:X\to G_n(\mathbb{C}^\infty)$ (the infinite Grassmannian). Thus, for each $E$ there is a unique homotopy class $[f_E:X\to G_n(\mathbb{C}^\infty)]$ determined by $E$. This in turn induces a map on any contravariant functor $\mathcal{F}$ from the homotopy category to an algebraic category $$ \mathcal{F}([f_E]): \mathcal{F}(G_n(\mathbb{C}^\infty))\to \mathcal{F}(X) $$ Then $\mathcal{F}([f_E]) \neq \mathcal{F}([f_\tilde{E}])$ implies $E \ncong\tilde{E}$, because $E\cong\tilde{E}$ implies $[f_E]=[f_\tilde{E}]$. Question 1: Is there any functor $\mathcal{F}$ such that $\mathcal{F}([f_E]) = \mathcal{F}([f_\tilde{E}])$ implies $E\cong \tilde{E}$? (perhaps for sufficient conditions on $X$?) Question 2: Is it the case that the $k$th Chern class of $E$ is given by $\mathcal{F}([f_E])(c_k)$ where $c_k\in\mathcal{F}(G_n(\mathbb{C}^\infty))$, and $\mathcal{F}$ is either the de Rham or the singular $k$th cohomology functor? If yes, is there a difference between using de Rham cohomology or singular cohomology? Also, how to determine $c_k$ concretely? I realize that $c_k$ is defined as the $k$th Chern class of the classifying bundle (the bundle quotient $(G_n(\mathbb{C}^m)\times \mathbb{C}^m)/F$ where $F$ is the tautological $n$-plane bundle), but is there a way to explain the definition of $c_k$ using this language without reverting to other constructions such as the Euler characteristic or invariant polynomials? Question 3: What could one obtain by using other functors? For instance, the singular homology functor? The $n$th homotopy group functor? Why does one never hear about these? Also, why is it that one only uses the even-degree cohomology functor in this context? Is there a textbook that is very similar to Chern's original 1945 paper, but which uses regular vector bundles instead of sphere bundles?",,"['differential-geometry', 'algebraic-topology', 'vector-bundles', 'characteristic-classes']"
93,Lie derivative of the product of a function and a form,Lie derivative of the product of a function and a form,,"If $V$ is a vector field and $\alpha$ is a linear form, $$ L_V\alpha: X\mapsto V(\alpha(X))-\alpha([V,X]) $$ for every field $X$, is $\mathbb R$-linear, which is trivial since $V$ is a field and $\alpha$ is linear, and $[V,\cdot]$ is also linear. (Is this right?) Also, $L_V:\mathfrak X^*\to\mathfrak X^*$,$ \alpha\mapsto L_V\alpha$ is $\mathbb R$-linear, but I would like to prove that $$ L_V(f\alpha) = V(f)\alpha+ fL_V\alpha, $$ which is like a Leibniz property. Any help?","If $V$ is a vector field and $\alpha$ is a linear form, $$ L_V\alpha: X\mapsto V(\alpha(X))-\alpha([V,X]) $$ for every field $X$, is $\mathbb R$-linear, which is trivial since $V$ is a field and $\alpha$ is linear, and $[V,\cdot]$ is also linear. (Is this right?) Also, $L_V:\mathfrak X^*\to\mathfrak X^*$,$ \alpha\mapsto L_V\alpha$ is $\mathbb R$-linear, but I would like to prove that $$ L_V(f\alpha) = V(f)\alpha+ fL_V\alpha, $$ which is like a Leibniz property. Any help?",,['differential-geometry']
94,Cone with deficit angle $2\pi$,Cone with deficit angle,2\pi,"I've managed to confuse myself with cones and deficit angles. Let's consider a conical defect in 2 dimensions. So the metric is the usual one in polar coordinates, $$ ds^2 = dr^2 + r^2 d\phi^2,$$ except that now $\phi \sim \phi + 2\pi(1-\alpha)$. For $\alpha = 0$, the is just flat space. When $\alpha \neq 0$, there is a singularity in the curvature, and for example the Ricci scalar acquires a delta function:  $$R(x) = 4\pi \alpha \, \delta^{(2)}_{x,x'}, $$ where $x'$ is the location of the conical defect. Now if we use the Gauss-Bonnet theorem (remembering that in 2 dimensions $R=K/2$, where $K$ is the Gaussian curvature), we can relate the deficit angle to the Euler characteristic (neglecting any boundary terms) $$ \chi = \alpha.$$ So my confusion now is: what does it mean to have $\alpha = 1$, which is to say that the deficit angle is $2\pi$? It seems weird that I can remove the whole angle and still have a 2 dimensional space. Since I don't have much intuition for what it means to remove $2\pi$, I looked up what manifolds have $\chi = 1$, I find things like the disk (which has a boundary), and the real projective plane, which is $S^2/\mathbb{Z}_2$ and non-orientable. So what space is a cone with deficit angle $2\pi$? (Bonus question: what space has deficit angle $4\pi$, the Euler formula would suggest a sphere?)","I've managed to confuse myself with cones and deficit angles. Let's consider a conical defect in 2 dimensions. So the metric is the usual one in polar coordinates, $$ ds^2 = dr^2 + r^2 d\phi^2,$$ except that now $\phi \sim \phi + 2\pi(1-\alpha)$. For $\alpha = 0$, the is just flat space. When $\alpha \neq 0$, there is a singularity in the curvature, and for example the Ricci scalar acquires a delta function:  $$R(x) = 4\pi \alpha \, \delta^{(2)}_{x,x'}, $$ where $x'$ is the location of the conical defect. Now if we use the Gauss-Bonnet theorem (remembering that in 2 dimensions $R=K/2$, where $K$ is the Gaussian curvature), we can relate the deficit angle to the Euler characteristic (neglecting any boundary terms) $$ \chi = \alpha.$$ So my confusion now is: what does it mean to have $\alpha = 1$, which is to say that the deficit angle is $2\pi$? It seems weird that I can remove the whole angle and still have a 2 dimensional space. Since I don't have much intuition for what it means to remove $2\pi$, I looked up what manifolds have $\chi = 1$, I find things like the disk (which has a boundary), and the real projective plane, which is $S^2/\mathbb{Z}_2$ and non-orientable. So what space is a cone with deficit angle $2\pi$? (Bonus question: what space has deficit angle $4\pi$, the Euler formula would suggest a sphere?)",,"['differential-geometry', 'differential-topology']"
95,What's the general idea behind (rigorously?) proving that a metric space is a manifold?,What's the general idea behind (rigorously?) proving that a metric space is a manifold?,,"Perhaps this is a broad question, but I opened Spivak's Differential Geometry and on the first page, it defines a manifold as such: A manifold is supposed to be ""locally"" like one of these exemplary metric spaces $\mathbb{R}^n$ . To be precise, a manifold is a metric space $M$ with the following property: If $x\in M$ , then there is some neighborhood $U$ of $x$ and some integer $n\geq0$ such that $U$ is homeomorphic to $\mathbb{R}^n$ . I googled around for a couple minutes but I couldn't find any answer directly addressing how to (or how it's impossible to) prove that some metric space is a manifold. That is, according to the last sentence, proving the neighborhood $U$ of each(?) $x\in M$ is homeomorphic to $\mathbb{R}^n$ for some nonnegative integer $n$ . I'm new to differential geometry and topology, so I apologize if this is a meaningless or too-easy-to-be-asking type of question.","Perhaps this is a broad question, but I opened Spivak's Differential Geometry and on the first page, it defines a manifold as such: A manifold is supposed to be ""locally"" like one of these exemplary metric spaces . To be precise, a manifold is a metric space with the following property: If , then there is some neighborhood of and some integer such that is homeomorphic to . I googled around for a couple minutes but I couldn't find any answer directly addressing how to (or how it's impossible to) prove that some metric space is a manifold. That is, according to the last sentence, proving the neighborhood of each(?) is homeomorphic to for some nonnegative integer . I'm new to differential geometry and topology, so I apologize if this is a meaningless or too-easy-to-be-asking type of question.",\mathbb{R}^n M x\in M U x n\geq0 U \mathbb{R}^n U x\in M \mathbb{R}^n n,"['general-topology', 'differential-geometry', 'metric-spaces']"
96,raising/ lowering indices,raising/ lowering indices,,"Here is my understanding of tensors: There is more than one way to think about tensors. One way is be thinking about tensors as objects with components which obey some transformation laws.  For instance ${T^{abc}}_{def}$ is one component of the type $(3,3)$ tensor $T$.  To raise or lower indices you multiply by the metric tensor, like $g_{ah}g^{ei}{T^{abc}}_{def}={{{{{T_h}^{bc}}_d}^i}_f}$. Another way is to think of a type $(p,q)$ tensor as a multilinear function from the Cartesian product of $p$ copies of the dual space $V^*$ and $q$ copies of the vector space $V$ to the reals: $T: \underbrace{V^* \times \cdots \times V^*}_{\text{p times}} \times \underbrace{V \times \cdots \times V}_{\text{q times}} \to \Bbb R$. The way to recover the components of the tensor from the multilinear function is just by evaluating the tensor at the basis one-forms and vectors.  For instance, if $\{\omega^a\}$ is the standard orthonormal basis of one-forms and $\{v_a\}$ is the standard orthonormal basis of vectors, then $T(\omega^a, \omega^b, v_c, v_d) = {T^{ab}}_{cd}$. My question is: What corresponds to the idea of raising and lowering indices for the multilinear function form of a tensor?","Here is my understanding of tensors: There is more than one way to think about tensors. One way is be thinking about tensors as objects with components which obey some transformation laws.  For instance ${T^{abc}}_{def}$ is one component of the type $(3,3)$ tensor $T$.  To raise or lower indices you multiply by the metric tensor, like $g_{ah}g^{ei}{T^{abc}}_{def}={{{{{T_h}^{bc}}_d}^i}_f}$. Another way is to think of a type $(p,q)$ tensor as a multilinear function from the Cartesian product of $p$ copies of the dual space $V^*$ and $q$ copies of the vector space $V$ to the reals: $T: \underbrace{V^* \times \cdots \times V^*}_{\text{p times}} \times \underbrace{V \times \cdots \times V}_{\text{q times}} \to \Bbb R$. The way to recover the components of the tensor from the multilinear function is just by evaluating the tensor at the basis one-forms and vectors.  For instance, if $\{\omega^a\}$ is the standard orthonormal basis of one-forms and $\{v_a\}$ is the standard orthonormal basis of vectors, then $T(\omega^a, \omega^b, v_c, v_d) = {T^{ab}}_{cd}$. My question is: What corresponds to the idea of raising and lowering indices for the multilinear function form of a tensor?",,"['linear-algebra', 'differential-geometry', 'mathematical-physics', 'tensors', 'multilinear-algebra']"
97,"Why is $|\cos\theta d\omega|$ the projection of the differential solid angle $d\omega$ onto the $(x,y)$-plane?",Why is  the projection of the differential solid angle  onto the -plane?,"|\cos\theta d\omega| d\omega (x,y)","Let $B\subseteq\mathbb R^3$ be the ball with radius $r>0$ around $0$ and $S_{\partial B}$ be the surface measure of the boundary $\partial B$. Given a piece of the surface $A\subseteq\partial B$, its solid angle is defined to be $$\omega=\frac{S_{\partial B}(A)}{r^2}\;.$$ By definition, $$S_{\partial B}(A)=r^2\int_{T^{-1}(A)}\sin\theta\;d\lambda^2(\theta,\phi)\;,$$ where $$T:(0,\pi)\times(0,2\pi)\to\mathbb R^3\;,\;\;\;(\theta,\phi)\mapsto\left(\begin{matrix}r\sin\theta\cos\phi\\ r\sin\theta\sin\phi\\ r\cos\theta\end{matrix}\right)$$ and $\lambda^2$ denotes the $2$-dimensional Lebesgue measure. This leads people to talk about the differential solid angle $$d\omega=\sin\theta\;d\theta\;d\phi\;.$$ We can think about $d\omega$ as being the surface area of an infinitesimal small surface element. However, since this is relatively vague, I don't understand why $\left|\cos\theta d\omega\right|$ is the projection of $d\omega$ onto the $(x,y)$-plane. How can we verify this mathematically? $\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;$","Let $B\subseteq\mathbb R^3$ be the ball with radius $r>0$ around $0$ and $S_{\partial B}$ be the surface measure of the boundary $\partial B$. Given a piece of the surface $A\subseteq\partial B$, its solid angle is defined to be $$\omega=\frac{S_{\partial B}(A)}{r^2}\;.$$ By definition, $$S_{\partial B}(A)=r^2\int_{T^{-1}(A)}\sin\theta\;d\lambda^2(\theta,\phi)\;,$$ where $$T:(0,\pi)\times(0,2\pi)\to\mathbb R^3\;,\;\;\;(\theta,\phi)\mapsto\left(\begin{matrix}r\sin\theta\cos\phi\\ r\sin\theta\sin\phi\\ r\cos\theta\end{matrix}\right)$$ and $\lambda^2$ denotes the $2$-dimensional Lebesgue measure. This leads people to talk about the differential solid angle $$d\omega=\sin\theta\;d\theta\;d\phi\;.$$ We can think about $d\omega$ as being the surface area of an infinitesimal small surface element. However, since this is relatively vague, I don't understand why $\left|\cos\theta d\omega\right|$ is the projection of $d\omega$ onto the $(x,y)$-plane. How can we verify this mathematically? $\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;$",,"['geometry', 'differential-geometry', 'physics', 'mathematical-physics', 'solid-angle']"
98,Show that a developable surface has zero Gaussian curvature.,Show that a developable surface has zero Gaussian curvature.,,"A developable surface is a ruled surface $x(s,t)=\alpha(s)+t\beta(s)$, where $\alpha(s)$ is a unit-speed curve and $|\beta(s)|=1$, such that the tangent planes along each ruling are parallel. Show that the Gaussian curvature of such surface is $K=0$. I am trying to show this using the equations of $\kappa_1$ and $\kappa_2$ which are the eigenvalues of the matrix $L$, which is the Weingarten map matrix. In computing the coefficients of the second fundamental form $L_{ij}:=\langle x_{ij},n \rangle$ with $i,j\in \{s,t\}$, I only find that $L_{tt}=0$, and I don't see how the calculations will simplify.","A developable surface is a ruled surface $x(s,t)=\alpha(s)+t\beta(s)$, where $\alpha(s)$ is a unit-speed curve and $|\beta(s)|=1$, such that the tangent planes along each ruling are parallel. Show that the Gaussian curvature of such surface is $K=0$. I am trying to show this using the equations of $\kappa_1$ and $\kappa_2$ which are the eigenvalues of the matrix $L$, which is the Weingarten map matrix. In computing the coefficients of the second fundamental form $L_{ij}:=\langle x_{ij},n \rangle$ with $i,j\in \{s,t\}$, I only find that $L_{tt}=0$, and I don't see how the calculations will simplify.",,"['differential-geometry', 'curvature']"
99,"Understanding an example for ""minimal surface doesn't imply least area""","Understanding an example for ""minimal surface doesn't imply least area""",,I can't understand two things regarding the following example: 1- Why the minimal surface $S$ will not minimize the area among all surfaces with boundary the two circles if $S_0 < S$? I don't understand this phrase at all and I don't know why the inequality must hold? 2- What is the meaning of the last paragraph and how to show that it holds (a proof)? A clear simple explanation would be much appreciated. PS - Source is the book Elementary Differential Geometry by A. N. Pressley.,I can't understand two things regarding the following example: 1- Why the minimal surface $S$ will not minimize the area among all surfaces with boundary the two circles if $S_0 < S$? I don't understand this phrase at all and I don't know why the inequality must hold? 2- What is the meaning of the last paragraph and how to show that it holds (a proof)? A clear simple explanation would be much appreciated. PS - Source is the book Elementary Differential Geometry by A. N. Pressley.,,['differential-geometry']
