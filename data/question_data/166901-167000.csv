,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Can I, by looking at scores from a game, decide how much luck and how much skill is involved?","Can I, by looking at scores from a game, decide how much luck and how much skill is involved?",,"My wife and I play a lot of rummy against each other, and we keep a record of the score for each game, as well as the accumulated score. Since I have a substantial lead at his point, I claim that I'm a better rummy player than she is, while she argues that it's pure luck. Most people agree that rummy is a game that combines luck and skill, but for many other games it can be hard to decide. Assume we have the following list of scores from a game, but we know nothing about the game. Round   :  1   2   3   4   5   6   7   8   9  10  | Sum  Avg Wins Player A:  -   -   5   2   -   -  17   -   -   -  |  24  2.4   3 Player B: 12   3   -   -   8   4   -   5  17   4  |  53  5.3   7 Is it possible to examine the scores and decide how much luck/skill is involved? It seems reasonable to me that both the total points and number of wins are important, but are there also other factors?","My wife and I play a lot of rummy against each other, and we keep a record of the score for each game, as well as the accumulated score. Since I have a substantial lead at his point, I claim that I'm a better rummy player than she is, while she argues that it's pure luck. Most people agree that rummy is a game that combines luck and skill, but for many other games it can be hard to decide. Assume we have the following list of scores from a game, but we know nothing about the game. Round   :  1   2   3   4   5   6   7   8   9  10  | Sum  Avg Wins Player A:  -   -   5   2   -   -  17   -   -   -  |  24  2.4   3 Player B: 12   3   -   -   8   4   -   5  17   4  |  53  5.3   7 Is it possible to examine the scores and decide how much luck/skill is involved? It seems reasonable to me that both the total points and number of wins are important, but are there also other factors?",,"['statistics', 'hypothesis-testing']"
1,"MLE of uniform distribution on the interval $[\theta − \frac{1}{2}, \theta + \frac{1}{2}]$",MLE of uniform distribution on the interval,"[\theta − \frac{1}{2}, \theta + \frac{1}{2}]","$X_1, X_2, . . . , X_n$ are i.i.d. observations from a uniform distribution on the interval $[\theta − \frac{1}{2}, \theta + \frac{1}{2}]$. Show that any $\theta$ between $X_{max} − \frac{1}{2}$ and $X_{min} + \frac{1}{2}$  maximizes the likelihood, and therefore, can be taken as the MLE. I am confused...because $f(x|\theta) = \frac{1}{(\theta+\frac{1}{2}) -(\theta -\frac{1}{2})} = 1$ for $\theta-\frac{1}{2} \le x \le\theta+\frac{1}{2}$ and 0 otherwise... Isn't the likelihood function $L(x|\theta) = 1$? The how can it be maximized between $X_{max} − \frac{1}{2}$ and $X_{min} + \frac{1}{2}$ ?","$X_1, X_2, . . . , X_n$ are i.i.d. observations from a uniform distribution on the interval $[\theta − \frac{1}{2}, \theta + \frac{1}{2}]$. Show that any $\theta$ between $X_{max} − \frac{1}{2}$ and $X_{min} + \frac{1}{2}$  maximizes the likelihood, and therefore, can be taken as the MLE. I am confused...because $f(x|\theta) = \frac{1}{(\theta+\frac{1}{2}) -(\theta -\frac{1}{2})} = 1$ for $\theta-\frac{1}{2} \le x \le\theta+\frac{1}{2}$ and 0 otherwise... Isn't the likelihood function $L(x|\theta) = 1$? The how can it be maximized between $X_{max} − \frac{1}{2}$ and $X_{min} + \frac{1}{2}$ ?",,"['statistics', 'maximum-likelihood']"
2,Good sources for statistical texts,Good sources for statistical texts,,"I was just hired to a new job and some knowledge of statistics is needed. In my mathematics undergraduate studies (which I finished very recently), I studied quite a bit of probability but not at all statistics. I'm looking to learn about tests and estimators specifically. t tests, z test, p test, kaplan-meier estimator, wilcoxon signed rank test etc Where do I start? What are the most important and widely used tests and where can I learn more?","I was just hired to a new job and some knowledge of statistics is needed. In my mathematics undergraduate studies (which I finished very recently), I studied quite a bit of probability but not at all statistics. I'm looking to learn about tests and estimators specifically. t tests, z test, p test, kaplan-meier estimator, wilcoxon signed rank test etc Where do I start? What are the most important and widely used tests and where can I learn more?",,"['statistics', 'soft-question', 'advice']"
3,Sample joint density conditional on sufficient statistic depends on parameter for uniform distribution,Sample joint density conditional on sufficient statistic depends on parameter for uniform distribution,,"Lex $X_1, X_2 \sim U(0, \theta)$ i.i.d , then obviously the sufficient statistic would be $T = \max\{X_1, X_2\}$, which can be easily proven by factorization theorem. However, I try to compute the density $f(x_1, x_2\mid t)$, which turns out to depend on the parameter $\theta$. This absolutely contradicts the definition of sufficient statistic: $$ f(x_1, x_2, t) = \frac 1 {\theta^2}I\{t\leq \theta, \max\{x_1, x_2\}=t\} $$ $$ f(t) = \frac{2t}{\theta^2}I\{t \leq \theta\} $$ Thus $$ f(x_1, x_2\mid t) = \frac 1 {2t} I\{t\leq \theta\} $$ which depends on $\theta$ through the indicator function $I\{t\leq \theta\}$. What's wrong with my reasoning? Thanks a lot!","Lex $X_1, X_2 \sim U(0, \theta)$ i.i.d , then obviously the sufficient statistic would be $T = \max\{X_1, X_2\}$, which can be easily proven by factorization theorem. However, I try to compute the density $f(x_1, x_2\mid t)$, which turns out to depend on the parameter $\theta$. This absolutely contradicts the definition of sufficient statistic: $$ f(x_1, x_2, t) = \frac 1 {\theta^2}I\{t\leq \theta, \max\{x_1, x_2\}=t\} $$ $$ f(t) = \frac{2t}{\theta^2}I\{t \leq \theta\} $$ Thus $$ f(x_1, x_2\mid t) = \frac 1 {2t} I\{t\leq \theta\} $$ which depends on $\theta$ through the indicator function $I\{t\leq \theta\}$. What's wrong with my reasoning? Thanks a lot!",,['statistics']
4,Derive mode of lognornormal distribution,Derive mode of lognornormal distribution,,"I need to generate some random data from lognormal distribution, where I set the mode and standart deviation of that lognormal distribution. For this purpose I choose to use random numbers generator from lognormal distribution. This generator takes two numbers, that are mean and sd of underlying normal distribution. So far its clear I need to derive mean and sd of normal distribution, which is underlaying for lognormal distribution where I know mode and sd. I know the equations for derivation of mean and sd: NOTATION: n(x) = mean of normal distribution sd(x) = sd of normal distribution n(y) = mean of lognormal distribution sd(y) = sd of lognormal distribution mode(y) = mode of lognormal distribution EQUATIONS: $$  n(x) = 2*ln(n(y)) - (1/2)*ln(sd(y)^2 + n(y)^2) $$ $$ sd(x) = -2*ln(n(y)) + ln(sd(y)^2 + n(y)^2) $$ $$ mode(y) = exp(n(y) - sd(y)^2) $$ Here I stuck because I cant get the equation for $n(y)$ from these equations, that I need to compute $n(x)$. So far I ended: $$ mode(y) = exp(4*ln(n(y))-3/2*ln(n(y)^2 - sd(y)^2)) $$ $$ mode(y)^{2/3}*sd(y)^2 = n(y)^2 * (n(y)^{2/3} - mode(y)^{2/3})  $$ Can anybody help me to complete this derivation? Or there are any other ways to anallytically derive mean of lognormal distribution from mode and sd of lognormal distribution?","I need to generate some random data from lognormal distribution, where I set the mode and standart deviation of that lognormal distribution. For this purpose I choose to use random numbers generator from lognormal distribution. This generator takes two numbers, that are mean and sd of underlying normal distribution. So far its clear I need to derive mean and sd of normal distribution, which is underlaying for lognormal distribution where I know mode and sd. I know the equations for derivation of mean and sd: NOTATION: n(x) = mean of normal distribution sd(x) = sd of normal distribution n(y) = mean of lognormal distribution sd(y) = sd of lognormal distribution mode(y) = mode of lognormal distribution EQUATIONS: $$  n(x) = 2*ln(n(y)) - (1/2)*ln(sd(y)^2 + n(y)^2) $$ $$ sd(x) = -2*ln(n(y)) + ln(sd(y)^2 + n(y)^2) $$ $$ mode(y) = exp(n(y) - sd(y)^2) $$ Here I stuck because I cant get the equation for $n(y)$ from these equations, that I need to compute $n(x)$. So far I ended: $$ mode(y) = exp(4*ln(n(y))-3/2*ln(n(y)^2 - sd(y)^2)) $$ $$ mode(y)^{2/3}*sd(y)^2 = n(y)^2 * (n(y)^{2/3} - mode(y)^{2/3})  $$ Can anybody help me to complete this derivation? Or there are any other ways to anallytically derive mean of lognormal distribution from mode and sd of lognormal distribution?",,"['statistics', 'normal-distribution', 'standard-deviation', 'means']"
5,"Rigorous definition of ""Average""","Rigorous definition of ""Average""",,"We usually tend to say the ""Average"" is whether ""Mean"", ""Median"" or ""Mode"" and in colloquial usage ""Average"" is always equivalent to ""Mean"". But my question is: Is there any precise rigorous definition of ""Average of a statistical population"" in statistics (regardless of our knowledge about mean, median or mode)?","We usually tend to say the ""Average"" is whether ""Mean"", ""Median"" or ""Mode"" and in colloquial usage ""Average"" is always equivalent to ""Mean"". But my question is: Is there any precise rigorous definition of ""Average of a statistical population"" in statistics (regardless of our knowledge about mean, median or mode)?",,"['statistics', 'terminology', 'definition', 'average']"
6,Understanding results of Gram-Schmidt orthogonalization,Understanding results of Gram-Schmidt orthogonalization,,"I just started learning about Gram-Schmidt, and I understand what it does, but I'm having trouble showing why it works. For example, let $P_k$ for $k=1,...,p$ be a projection matrix for a matrix $A_{1:k}$ (so the first $k$ columns). Then let's say we have $u_1 = a_1$, and any $u_k = (I-P_{k-1})a_k$ for each $k$. How do I: 1) Show that the $u_k$ are orthogonal 2) Show that the span of $u_1,...,u_k$ is the same as the span of $a_1,...,a_k$ for each $k=1,...,p$. I feel a bit dumb because I realize that both these results are the the whole point of Gram-Schmidt. #2 I thought should be especially obvious but when I tried to prove it I got no where fast. I was trying to take advantage of the fact that $P$ is symmetric/idempotent, but maybe that's not the approach to take? Can anyone help? I'd really appreciate it.","I just started learning about Gram-Schmidt, and I understand what it does, but I'm having trouble showing why it works. For example, let $P_k$ for $k=1,...,p$ be a projection matrix for a matrix $A_{1:k}$ (so the first $k$ columns). Then let's say we have $u_1 = a_1$, and any $u_k = (I-P_{k-1})a_k$ for each $k$. How do I: 1) Show that the $u_k$ are orthogonal 2) Show that the span of $u_1,...,u_k$ is the same as the span of $a_1,...,a_k$ for each $k=1,...,p$. I feel a bit dumb because I realize that both these results are the the whole point of Gram-Schmidt. #2 I thought should be especially obvious but when I tried to prove it I got no where fast. I was trying to take advantage of the fact that $P$ is symmetric/idempotent, but maybe that's not the approach to take? Can anyone help? I'd really appreciate it.",,"['linear-algebra', 'statistics', 'vector-spaces', 'orthogonality']"
7,Why the covariance matrix of a matrix is the product $XX'$,Why the covariance matrix of a matrix is the product,XX',"Let a matrix of random observations such that   $$\textbf{X}=\begin{bmatrix}x_{11}&x_{12}\\ x_{21}&  x_{22}\end{bmatrix}$$   where $x_{jk}$ is the jth measure of the kth variable.Each column is a random variable. Why the covariance matrix of $\textbf{X}$ is   given by $XX'$? I don't understood this result, because $$\overline{x}_k=\frac{1}{n}\sum_{i=1}^n x_{ik}$$ in this case $\overline{x_1}=\frac{x_{11}+x_{21}}{2}$ and $\overline{x_2}=\frac{x_{12}+x_{22}}{2}$ and the sample covariances are given by $$s_{ik}=\frac{1}{n}\sum_{j=1}^n(x_{ji}-\overline{x_i})(x_{jk}-\overline{x_k})$$ Taking $s_{11}$ as example $$s_{11}=\frac{1}{2}\sum_{j=1}^2 (x_{j1}-\overline{x_1})^2=\frac{1}{2}\Big((x_{11}-(\frac{x_{11}+x_{21}}{2}))^2+(x_{21}-(\frac{x_{11}+x_{21}}{2}   ))^2\Big)$$ $$=\frac{x_{11}^2}{2}-x_{11}x_{21}+\frac{x_{21}^2}{2}$$ If I make $$XX'$$ then $$s_{11}=x_{11}^2+x_{21}^2$$ I made some confusion? Or is there some restriction to this result? EDIT: I get this result from here Correlation matrix from Covariance matrix . Since no one said that is wrong I assumed that will be valid in this case too.","Let a matrix of random observations such that   $$\textbf{X}=\begin{bmatrix}x_{11}&x_{12}\\ x_{21}&  x_{22}\end{bmatrix}$$   where $x_{jk}$ is the jth measure of the kth variable.Each column is a random variable. Why the covariance matrix of $\textbf{X}$ is   given by $XX'$? I don't understood this result, because $$\overline{x}_k=\frac{1}{n}\sum_{i=1}^n x_{ik}$$ in this case $\overline{x_1}=\frac{x_{11}+x_{21}}{2}$ and $\overline{x_2}=\frac{x_{12}+x_{22}}{2}$ and the sample covariances are given by $$s_{ik}=\frac{1}{n}\sum_{j=1}^n(x_{ji}-\overline{x_i})(x_{jk}-\overline{x_k})$$ Taking $s_{11}$ as example $$s_{11}=\frac{1}{2}\sum_{j=1}^2 (x_{j1}-\overline{x_1})^2=\frac{1}{2}\Big((x_{11}-(\frac{x_{11}+x_{21}}{2}))^2+(x_{21}-(\frac{x_{11}+x_{21}}{2}   ))^2\Big)$$ $$=\frac{x_{11}^2}{2}-x_{11}x_{21}+\frac{x_{21}^2}{2}$$ If I make $$XX'$$ then $$s_{11}=x_{11}^2+x_{21}^2$$ I made some confusion? Or is there some restriction to this result? EDIT: I get this result from here Correlation matrix from Covariance matrix . Since no one said that is wrong I assumed that will be valid in this case too.",,"['linear-algebra', 'statistics', 'self-learning', 'covariance']"
8,Is This Continuous Version of the Poisson Distribution Closed Under Addition?,Is This Continuous Version of the Poisson Distribution Closed Under Addition?,,"According its Wikipedia page the CDF of the Poisson distribution is: $$\operatorname{CDF}_0(k) = \frac{\Gamma(\lfloor k+1\rfloor, \lambda)}{\Gamma(\lfloor k+1\rfloor)},$$ with $\Gamma(a, x)$ the incomplete gamma function. This admits an immediate generalization to continuous variables with $k=x\ge0$ by dropping the floor functions in the numerator and denominator, giving (after a shift by $1$): $$\begin{align}\operatorname{CDF}(x) & = \frac{\Gamma(x, \lambda)}{\Gamma( x)},\ \mathrm{and} \\ \operatorname{PDF}(x)& = \frac{\int_\lambda^\infty \ln(t)\, t^{x -1}\operatorname{e}^{-t}  \operatorname{d}t}{\Gamma( x)} - \frac{\Gamma(x, \lambda) }{\Gamma( x)}\psi^0(x),\end{align}$$ with $\psi^0(x)$ the digamma (or polygamma of order $0$) function. Is it possible to show that if $x$ and $y$ are random variables distributed according to $\operatorname{CDF}$ with parameters $\lambda_x$ and $\lambda_y$, respectively, then $x+y$ is distributed according to the same $\operatorname{CDF}$ (presumably with parameter $\lambda_x + \lambda_y$)? If so, how? If not, where does it fail?","According its Wikipedia page the CDF of the Poisson distribution is: $$\operatorname{CDF}_0(k) = \frac{\Gamma(\lfloor k+1\rfloor, \lambda)}{\Gamma(\lfloor k+1\rfloor)},$$ with $\Gamma(a, x)$ the incomplete gamma function. This admits an immediate generalization to continuous variables with $k=x\ge0$ by dropping the floor functions in the numerator and denominator, giving (after a shift by $1$): $$\begin{align}\operatorname{CDF}(x) & = \frac{\Gamma(x, \lambda)}{\Gamma( x)},\ \mathrm{and} \\ \operatorname{PDF}(x)& = \frac{\int_\lambda^\infty \ln(t)\, t^{x -1}\operatorname{e}^{-t}  \operatorname{d}t}{\Gamma( x)} - \frac{\Gamma(x, \lambda) }{\Gamma( x)}\psi^0(x),\end{align}$$ with $\psi^0(x)$ the digamma (or polygamma of order $0$) function. Is it possible to show that if $x$ and $y$ are random variables distributed according to $\operatorname{CDF}$ with parameters $\lambda_x$ and $\lambda_y$, respectively, then $x+y$ is distributed according to the same $\operatorname{CDF}$ (presumably with parameter $\lambda_x + \lambda_y$)? If so, how? If not, where does it fail?",,"['statistics', 'poisson-distribution']"
9,Prerequisites for Stastistics.,Prerequisites for Stastistics.,,"I'm a graduate school student entered this year. Next semester, I would take mathematical statistics. I don't think the book used for this class is rigorous A Course in Mathematical Statistics, Second Edition . But I want to understand Statistics deeply, rigorously. I hear often Measure Theory is useful for deep understanding of Mathematical Statistics. So I have studied Real Analysis. G Folland from chapter 1 measure to chapter 3 Radon-Nikodym Theorem and I will study some more. Could you give me a advice?","I'm a graduate school student entered this year. Next semester, I would take mathematical statistics. I don't think the book used for this class is rigorous A Course in Mathematical Statistics, Second Edition . But I want to understand Statistics deeply, rigorously. I hear often Measure Theory is useful for deep understanding of Mathematical Statistics. So I have studied Real Analysis. G Folland from chapter 1 measure to chapter 3 Radon-Nikodym Theorem and I will study some more. Could you give me a advice?",,"['statistics', 'soft-question', 'book-recommendation']"
10,Derivation of standard error of regression estimate with degrees of freedom,Derivation of standard error of regression estimate with degrees of freedom,,"I am taking a course of Econometrics: I need help to understand as to how do we arrive at the formula for standard error of regression $$\hat{\sigma}^2=\frac{\sum{e_i^2}}{n-k}.$$ I understand the bessel's correction required to remove the bias inherent in sample variance. The proof being available at Bessels Correction Proof of Correctness . I also found Standard deviation of error in simple linear regression How to derive the standard error of linear regression coefficient But I could not find the proof for the above expression (standard error of regression estimate). I tried to open the equation on the lines of Bessels Correction proof. $$e_i=\text{Total SS}- \text{Explained SS}$$ Then I try to expand the Explained sum of squares term, but I got stuck at $$ \sum _{i=1}^n \operatorname {E} \left((\beta\mathbf{ X}-\bar{y} )^2 \right) = \beta^2 E(x^2)-2\beta\bar{xy}+E(\bar{y}^2)$$ I don't know how to proceed. Can anyone please help ? Then I read this : The term ""standard error"" is more often used in the context of a regression model, and you can find it as ""the standard error of regression"". It is the square root of the sum of squared residuals from the regression - divided sometimes by sample size n (and then it is the maximum likelihood estimator of the standard deviation of the error term), or by $n−k$ ( $k$ being the number of regressors), and then it is the ordinary least squares (OLS) estimator of the standard deviation of the error term. on Standard Error vs. Standard Deviation of Sample Mean Can anyone suggest a textbook where I can read about these derivations in more details ?","I am taking a course of Econometrics: I need help to understand as to how do we arrive at the formula for standard error of regression I understand the bessel's correction required to remove the bias inherent in sample variance. The proof being available at Bessels Correction Proof of Correctness . I also found Standard deviation of error in simple linear regression How to derive the standard error of linear regression coefficient But I could not find the proof for the above expression (standard error of regression estimate). I tried to open the equation on the lines of Bessels Correction proof. Then I try to expand the Explained sum of squares term, but I got stuck at I don't know how to proceed. Can anyone please help ? Then I read this : The term ""standard error"" is more often used in the context of a regression model, and you can find it as ""the standard error of regression"". It is the square root of the sum of squared residuals from the regression - divided sometimes by sample size n (and then it is the maximum likelihood estimator of the standard deviation of the error term), or by ( being the number of regressors), and then it is the ordinary least squares (OLS) estimator of the standard deviation of the error term. on Standard Error vs. Standard Deviation of Sample Mean Can anyone suggest a textbook where I can read about these derivations in more details ?",\hat{\sigma}^2=\frac{\sum{e_i^2}}{n-k}. e_i=\text{Total SS}- \text{Explained SS}  \sum _{i=1}^n \operatorname {E} \left((\beta\mathbf{ X}-\bar{y} )^2 \right) = \beta^2 E(x^2)-2\beta\bar{xy}+E(\bar{y}^2) n−k k,"['statistics', 'standard-deviation', 'regression-analysis']"
11,Proving Chi-squared Distribution [duplicate],Proving Chi-squared Distribution [duplicate],,"This question already has answers here : Proof of $\frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}$ (5 answers) Closed 3 years ago . I have some problems solving the following problem: Let $X = (X_1, X_2,\ldots, X_n)$, be random sample , where $X_{i} \sim N(\mu, \sigma^{2})$. Show that: $$U:= \frac{n-1}{\sigma^2} S^2 \sim \chi^2 (n-1); \text{ where } S^2:= \frac{1}{n-1}\sum_{i=1}^n (X_i - \overline{X})^2.$$ Do I need to prove first that the statistic, the sample mean, is sufficient? Or show the independence through Basu's Theorem? Thanks for any help!","This question already has answers here : Proof of $\frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}$ (5 answers) Closed 3 years ago . I have some problems solving the following problem: Let $X = (X_1, X_2,\ldots, X_n)$, be random sample , where $X_{i} \sim N(\mu, \sigma^{2})$. Show that: $$U:= \frac{n-1}{\sigma^2} S^2 \sim \chi^2 (n-1); \text{ where } S^2:= \frac{1}{n-1}\sum_{i=1}^n (X_i - \overline{X})^2.$$ Do I need to prove first that the statistic, the sample mean, is sufficient? Or show the independence through Basu's Theorem? Thanks for any help!",,"['statistics', 'probability-distributions']"
12,Motivation behind Arithmetic Mean,Motivation behind Arithmetic Mean,,"I know that the arithmetic mean $(x_1+x_2+...+x_n)/n$ is the value that minimizes $f(x)=\sum_{k=1}^n (x_k-x)^2$; however, I'm looking for an intuitive relationship between the mean and $g(x)=\sum_{k=1}^n \left\vert{x_k-x}\right\vert$. I'm aware that the mean doesn't necessarily minimize $g$; instead, one of the ${x_k}'s$ does (although maybe not uniquely), but I noticed that, using the triangle inequality, $$h(x)=n\left\vert{x-((x_1+x_2+...+x_n)/n)}\right\vert\le\sum_{k=1}^n\left\vert{x_k-x}\right\vert$$ and the value that minimizes $h$ is the arithmetic mean. That is, the point at which the minimum of this lower bound function of $g$ occurs is the mean. However, I'm unable to think of an intuitive explanation for this. Perhaps it's just a coincidence? Basically, I'm looking for any intuitive connections between the mean and the sum of absolute differences. Any ideas/comments would be greatly appreciated!","I know that the arithmetic mean $(x_1+x_2+...+x_n)/n$ is the value that minimizes $f(x)=\sum_{k=1}^n (x_k-x)^2$; however, I'm looking for an intuitive relationship between the mean and $g(x)=\sum_{k=1}^n \left\vert{x_k-x}\right\vert$. I'm aware that the mean doesn't necessarily minimize $g$; instead, one of the ${x_k}'s$ does (although maybe not uniquely), but I noticed that, using the triangle inequality, $$h(x)=n\left\vert{x-((x_1+x_2+...+x_n)/n)}\right\vert\le\sum_{k=1}^n\left\vert{x_k-x}\right\vert$$ and the value that minimizes $h$ is the arithmetic mean. That is, the point at which the minimum of this lower bound function of $g$ occurs is the mean. However, I'm unable to think of an intuitive explanation for this. Perhaps it's just a coincidence? Basically, I'm looking for any intuitive connections between the mean and the sum of absolute differences. Any ideas/comments would be greatly appreciated!",,"['statistics', 'intuition', 'means', 'motivation']"
13,"How many data points are ""enough"" for linear regression?","How many data points are ""enough"" for linear regression?",,"I have data points $(x_t,y_t)$ generated from $y_t = a + b x_t + \epsilon$ where $\epsilon$ is gaussian error term with zero mean and unknown variance. I want to estimate coefficients $a$ and $b$ but their is some cost associated with generating more data points. So, how many number of data points to get a ""reasonable"" estimate of the coefficients? Can we quantify what is ""reasonable""?","I have data points $(x_t,y_t)$ generated from $y_t = a + b x_t + \epsilon$ where $\epsilon$ is gaussian error term with zero mean and unknown variance. I want to estimate coefficients $a$ and $b$ but their is some cost associated with generating more data points. So, how many number of data points to get a ""reasonable"" estimate of the coefficients? Can we quantify what is ""reasonable""?",,"['statistics', 'regression', 'parameter-estimation', 'regression-analysis']"
14,A Nonhomogenous Poisson Process Question - Harry's Stressful Life,A Nonhomogenous Poisson Process Question - Harry's Stressful Life,,"Due to stress of coping with business, Harry begins to experience migraine headaches of random severities. Headaches are instantaneous and has zero duration. The times when headaches occur follow a Poisson process of rate λ. Headache severities are independent of times of occurrences and are i.i.d. random variables with common exponential distribution given by: $$ \mathbb{P}[H \le x] = 1 − e^{-x}, \quad x > 0 $$ Harry decides to commit himself to the hospital if a headache of severity greater than $c > 0$ occurs in the time period $[0, t]$. Compute the probability that Harry does not commit himself in $[0, t]$. I think that probability of not committing is $\mathbb{P}[H(t)=0]$ $\mathbb{P}[H(t)=0]$ should be equal to $e^{-λt \mathbb{P}[H_s]}$ where $H_s$ is the occurrence probability of a severe headache. But how can I calculate $\mathbb{P}[H_s]$? Should I find $\mathbb{P}[H_s>t] = e^{-tm}$ ??","Due to stress of coping with business, Harry begins to experience migraine headaches of random severities. Headaches are instantaneous and has zero duration. The times when headaches occur follow a Poisson process of rate λ. Headache severities are independent of times of occurrences and are i.i.d. random variables with common exponential distribution given by: $$ \mathbb{P}[H \le x] = 1 − e^{-x}, \quad x > 0 $$ Harry decides to commit himself to the hospital if a headache of severity greater than $c > 0$ occurs in the time period $[0, t]$. Compute the probability that Harry does not commit himself in $[0, t]$. I think that probability of not committing is $\mathbb{P}[H(t)=0]$ $\mathbb{P}[H(t)=0]$ should be equal to $e^{-λt \mathbb{P}[H_s]}$ where $H_s$ is the occurrence probability of a severe headache. But how can I calculate $\mathbb{P}[H_s]$? Should I find $\mathbb{P}[H_s>t] = e^{-tm}$ ??",,"['statistics', 'stochastic-processes', 'poisson-distribution', 'poisson-process', 'exponential-distribution']"
15,What percentage drop is this?,What percentage drop is this?,,"Can someone help a student who is terribly bad at math answer this question? Between 1998 and 2014, in New Mexico, Birth rates for teens 18-19 years of age fell from a rate of 108.8 per 1000 to 69.3 per 1,000 females. What percentage had the teen birth rate dropped? So in my mind all of these answers pop up. The figure 69.3 is 44% lower than 108.8. However, when comparing 108.8/1000 to 69.3/1000 the drop between the two is 13.28%. Then again, simply taking 108.8 and subtracting it by 69.3 would give us 39.5.","Can someone help a student who is terribly bad at math answer this question? Between 1998 and 2014, in New Mexico, Birth rates for teens 18-19 years of age fell from a rate of 108.8 per 1000 to 69.3 per 1,000 females. What percentage had the teen birth rate dropped? So in my mind all of these answers pop up. The figure 69.3 is 44% lower than 108.8. However, when comparing 108.8/1000 to 69.3/1000 the drop between the two is 13.28%. Then again, simply taking 108.8 and subtracting it by 69.3 would give us 39.5.",,"['statistics', 'percentages']"
16,Mean of a portion of a normal distribution?,Mean of a portion of a normal distribution?,,"How do I calculate the mean of a portion of a normal distribution.  In other words, say I have a normal distribution of the heights of adult males.  The mean is 70"" and the standard deviation is 4"".  What is the average height of males above the 95th percentile?  What is the average height of all males below the 95th percentile?  How do I calculate this? Someone asked a similar question here which was never answered clearly: Mean value from part of normal distribution This question has a practical application for my work where I am running a power plant at 10.3 MW mean operating point with a standard deviation of 0.2 MW.  I would like to know the average power when I am above 10 MW.  Or the mean of all points above 10 MW.","How do I calculate the mean of a portion of a normal distribution.  In other words, say I have a normal distribution of the heights of adult males.  The mean is 70"" and the standard deviation is 4"".  What is the average height of males above the 95th percentile?  What is the average height of all males below the 95th percentile?  How do I calculate this? Someone asked a similar question here which was never answered clearly: Mean value from part of normal distribution This question has a practical application for my work where I am running a power plant at 10.3 MW mean operating point with a standard deviation of 0.2 MW.  I would like to know the average power when I am above 10 MW.  Or the mean of all points above 10 MW.",,"['statistics', 'probability-distributions', 'normal-distribution']"
17,definition of a sufficient statistic,definition of a sufficient statistic,,"The ""normal"" definition of a sufficient statistics is via independence of the pdf (conditional on the statistic) of the parameter $\theta$. The Fisher-Neyman theorem gives a nice characterization: The statistic $T$ is sufficient iff $f(x;\theta) = h(x)g(T(x);\theta)$ for two nonnegative functions $h, g$. In the book All of statistics by Larry Wasserman the author defines (I quote): ""Write $\vec{x} \iff \vec{y}$ if $f(\vec{x};\theta) = cf(\vec{y};\theta)$ for some constant $c$ that might depend on $\vec{x}$ and $\vec{y}$ but not on $\theta$. A statistic $T(\vec{x})$ is sufficient if $T(\vec{x})\iff T(\vec{y})$ implies that $\vec{x}\iff \vec{y}$ where $\vec{x} = (x_1, \dots, x_n)$ a data sample. The $T(\vec{x})\iff T(\vec{y})$ seems to be like the Fisher-Neyman thoerem with different data samples. How can one show that Wassermans definition is the same as above (or equivalent to the Fisher-Neyman).","The ""normal"" definition of a sufficient statistics is via independence of the pdf (conditional on the statistic) of the parameter $\theta$. The Fisher-Neyman theorem gives a nice characterization: The statistic $T$ is sufficient iff $f(x;\theta) = h(x)g(T(x);\theta)$ for two nonnegative functions $h, g$. In the book All of statistics by Larry Wasserman the author defines (I quote): ""Write $\vec{x} \iff \vec{y}$ if $f(\vec{x};\theta) = cf(\vec{y};\theta)$ for some constant $c$ that might depend on $\vec{x}$ and $\vec{y}$ but not on $\theta$. A statistic $T(\vec{x})$ is sufficient if $T(\vec{x})\iff T(\vec{y})$ implies that $\vec{x}\iff \vec{y}$ where $\vec{x} = (x_1, \dots, x_n)$ a data sample. The $T(\vec{x})\iff T(\vec{y})$ seems to be like the Fisher-Neyman thoerem with different data samples. How can one show that Wassermans definition is the same as above (or equivalent to the Fisher-Neyman).",,"['statistics', 'definition']"
18,Geometric mean of 2 sets,Geometric mean of 2 sets,,"If $2$ finite sets of positive integers have different cardinality but the same arithmetic mean, does the set with the greater number of elements always have a lower geometric mean?","If $2$ finite sets of positive integers have different cardinality but the same arithmetic mean, does the set with the greater number of elements always have a lower geometric mean?",,['statistics']
19,Quantile Regression - Linear Loss Minimization,Quantile Regression - Linear Loss Minimization,,"I'm currently reading Quantile Regression by Roger Koenker, and for some reason, I'm having a lot of trouble deriving one of his equations (sect. 1.3, p. 5-6). He goes on to demonstrate that $\hat{x}$ minimizing a linear loss corresponds to the $τ$ th quartile of the distribution, when the loss is defined by $$ \rho_\tau(u) = (\tau - 1)\min(0,u) + \tau \max(0,u). $$ To do so, he first writes down the expected loss using the CDF $F$ of the distribution: $$ E[\rho_\tau(X-\hat x)] = (\tau -1)\int_{-\infty}^{\hat x}(x-\hat x)\,dF(x) + \tau \int_{\hat x}^\infty (x-\hat x)\,dF(x), \tag 1 $$ where $X$ is a random variable, which he then differentiates by $\hat x$ to obtain $$ (1-\tau)\int_{-\infty}^{\hat x} dF(x) - τ\int_{\hat x}^\infty dF(x) \tag 2 $$ Now I'm a bit rusty with calculus, and I couldn't find how to go from (1) to (2). I tried to integrate by parts and to apply the fundamental theorem, but I couldn't obtained the result (2).","I'm currently reading Quantile Regression by Roger Koenker, and for some reason, I'm having a lot of trouble deriving one of his equations (sect. 1.3, p. 5-6). He goes on to demonstrate that minimizing a linear loss corresponds to the th quartile of the distribution, when the loss is defined by To do so, he first writes down the expected loss using the CDF of the distribution: where is a random variable, which he then differentiates by to obtain Now I'm a bit rusty with calculus, and I couldn't find how to go from (1) to (2). I tried to integrate by parts and to apply the fundamental theorem, but I couldn't obtained the result (2).","\hat{x} τ 
\rho_\tau(u) = (\tau - 1)\min(0,u) + \tau \max(0,u).
 F 
E[\rho_\tau(X-\hat x)] = (\tau -1)\int_{-\infty}^{\hat x}(x-\hat x)\,dF(x) + \tau \int_{\hat x}^\infty (x-\hat x)\,dF(x), \tag 1
 X \hat x 
(1-\tau)\int_{-\infty}^{\hat x} dF(x) - τ\int_{\hat x}^\infty dF(x) \tag 2
","['calculus', 'statistics', 'regression']"
20,What languages does Zipf's law not hold for?,What languages does Zipf's law not hold for?,,"Despite reading on a book of mine that all languages of all times obeyed Zipf's law, the english Wikipedia article only says most . Is it correct? If so, is a counterexample known?","Despite reading on a book of mine that all languages of all times obeyed Zipf's law, the english Wikipedia article only says most . Is it correct? If so, is a counterexample known?",,"['statistics', 'applications']"
21,Intuition behind Fisher information and expected value,Intuition behind Fisher information and expected value,,"I am learning stats. On page 128 of my book, All of Statistics 1e , it explains that the Fisher information is the variance of the score function. It then goes on to say that when $n = 1$ $$I(\theta) = -E_{\theta}\left(\frac{\partial^2 \log\space f(X;\theta)}{\partial{\theta}^2}\right)$$ where $f(x;\theta)$ is, I think, the pdf with parameters $\theta$. I am trying to get an intuition for what that definition is saying. Why would the variance of the score function be equal to the opposite of the expected value of the partial derivative of the pdf with respect to theta? In googling around I've found some videos for the Cramer-Rao lower bound and that seems related. I'm way over my head mathematically (in part to build up my skills), so it would be great if someone could really break down what is going on.","I am learning stats. On page 128 of my book, All of Statistics 1e , it explains that the Fisher information is the variance of the score function. It then goes on to say that when $n = 1$ $$I(\theta) = -E_{\theta}\left(\frac{\partial^2 \log\space f(X;\theta)}{\partial{\theta}^2}\right)$$ where $f(x;\theta)$ is, I think, the pdf with parameters $\theta$. I am trying to get an intuition for what that definition is saying. Why would the variance of the score function be equal to the opposite of the expected value of the partial derivative of the pdf with respect to theta? In googling around I've found some videos for the Cramer-Rao lower bound and that seems related. I'm way over my head mathematically (in part to build up my skills), so it would be great if someone could really break down what is going on.",,['statistics']
22,Show $\hat{\beta}$ and $s^2$ are independent?,Show  and  are independent?,\hat{\beta} s^2,I have the model: $y=X{\beta}+{\epsilon}$ I know $\hat{\beta}=(X'X)^{-1}X'y$ and that it is an unbiased estimator of ${\beta}$ and that $s^2=\hat{\epsilon}'\hat{\epsilon}/(n-k)$ and is an unbiased estimator of the variance. How do I show that $\hat{\beta}$ and $s^2$ are independent?,I have the model: $y=X{\beta}+{\epsilon}$ I know $\hat{\beta}=(X'X)^{-1}X'y$ and that it is an unbiased estimator of ${\beta}$ and that $s^2=\hat{\epsilon}'\hat{\epsilon}/(n-k)$ and is an unbiased estimator of the variance. How do I show that $\hat{\beta}$ and $s^2$ are independent?,,"['statistics', 'regression']"
23,Linear Regression quadratic terms,Linear Regression quadratic terms,,"I have a hard time understanding the term 'linear regression'. For what I know, linear means polynomial of degree 1. But then, I found that in one of my lectures, the lecturers are saying that this regression is a linear regression: $$Y_i=\alpha_0+\alpha_1 x_i +\alpha_2 x_i^2$$ How is this a linear regression when it has quadratic terms in it? Does it not make it a non-linear regression? However when there is a quadratic curve as the regression, it is called a non-linear regression. Which is right?","I have a hard time understanding the term 'linear regression'. For what I know, linear means polynomial of degree 1. But then, I found that in one of my lectures, the lecturers are saying that this regression is a linear regression: $$Y_i=\alpha_0+\alpha_1 x_i +\alpha_2 x_i^2$$ How is this a linear regression when it has quadratic terms in it? Does it not make it a non-linear regression? However when there is a quadratic curve as the regression, it is called a non-linear regression. Which is right?",,"['statistics', 'terminology', 'regression', 'linear-regression']"
24,Principal component analysis - calculating variance,Principal component analysis - calculating variance,,"Quoting Rahul's answer : It's not hard to show that if the covariance matrix of the original   data points $x_i$ was $\Sigma$, the variance of the new data points is   just $u^{T}\Sigma u$. The covariance between sets $X$ and $Y$ is defined as $\sum_i = \frac{1}{n}(x_i-\bar{x})(y_i-\bar{y})$, where $\bar{x}$ and $\bar{y}$ denote the mean. In some other material I've found it says something else than what I've quoted: Here, the variance is not equal to $u^{T}\Sigma u$. It would be if $A$ in this case were multiplied by $\frac{1}{n}$. They say $A$ would be a covariance matrix if the coefficient was present. But it's not. It looks 'a bit' incompatible with the statement in the quote. The question is - who is wrong here and what is variance equal to? I suppose Rahul is right saying that the variance is equal to $u^{T}\Sigma u$, where $\Sigma$ is the covariance matrix. But the picture below proves a different equality, so what's going on here? Here on page 8, the author derives the equality supporting Rahul's claim (I can't quite understand what's going on there). Which one is correct? Source","Quoting Rahul's answer : It's not hard to show that if the covariance matrix of the original   data points $x_i$ was $\Sigma$, the variance of the new data points is   just $u^{T}\Sigma u$. The covariance between sets $X$ and $Y$ is defined as $\sum_i = \frac{1}{n}(x_i-\bar{x})(y_i-\bar{y})$, where $\bar{x}$ and $\bar{y}$ denote the mean. In some other material I've found it says something else than what I've quoted: Here, the variance is not equal to $u^{T}\Sigma u$. It would be if $A$ in this case were multiplied by $\frac{1}{n}$. They say $A$ would be a covariance matrix if the coefficient was present. But it's not. It looks 'a bit' incompatible with the statement in the quote. The question is - who is wrong here and what is variance equal to? I suppose Rahul is right saying that the variance is equal to $u^{T}\Sigma u$, where $\Sigma$ is the covariance matrix. But the picture below proves a different equality, so what's going on here? Here on page 8, the author derives the equality supporting Rahul's claim (I can't quite understand what's going on there). Which one is correct? Source",,"['linear-algebra', 'statistics']"
25,Bayesian Updating with 1 Signal but 2 Unknowns,Bayesian Updating with 1 Signal but 2 Unknowns,,"Suppose I have an unknown variable $X_i = \alpha_i + \beta_i$ where $\alpha$ is one of 2 different values {${\alpha_1, \alpha_2}$} such that $\alpha = \alpha_1$ with probability $p_1$ and $\beta$ is drawn from a Gaussian distribution: $\beta$~$N(0,\sigma^2)$. Suppose I am given a ""signal"" $Y=X+\epsilon$, where $\epsilon$~$N(0,v^2)$ My goal is to update my beliefs about $\alpha$ and $\beta$ Here's my answer so far: It's to treat the two separately. Suppose I was given $\beta$. Then my ""signal"" for $\alpha$ would be $=Y-\beta$ and my updated probability that $\alpha=\alpha_1$ is: $P(\alpha=\alpha_1|Y,\beta)=\frac{p_1\phi(\frac{Y-\beta-\alpha_1}{v})}{p_1\phi(\frac{Y-\beta-\alpha_1}{v})+(1-p_1)\phi(\frac{Y-\beta-\alpha_2}{v})} \space \space$ (1) where $\phi$ is the standard normal pdf Similarly, the updated distribution of $\beta$ given $\alpha$ is $(\beta|\alpha,Y)$ ~ $N(\mu_1,\sigma^2_1)$ where $\mu_1 = \frac{\sigma^2}{\sigma^2+v^2}*(Y-\alpha)$ and $\sigma^2_1 = \frac{\sigma^2}{\sigma^2+v^2}*v^2\space \space$ (2) I'm not really sure how to proceed next. My goal is to write something like: $P(\alpha=\alpha_1|Y)=\int P(\alpha=\alpha_1|Y,\beta)dH(\beta)$ But, I'm not sure what distribution $H()$ to use. Edit: I suppose I could iterate back and forth between the above methods, but Ideally I am looking for a more closed form solution","Suppose I have an unknown variable $X_i = \alpha_i + \beta_i$ where $\alpha$ is one of 2 different values {${\alpha_1, \alpha_2}$} such that $\alpha = \alpha_1$ with probability $p_1$ and $\beta$ is drawn from a Gaussian distribution: $\beta$~$N(0,\sigma^2)$. Suppose I am given a ""signal"" $Y=X+\epsilon$, where $\epsilon$~$N(0,v^2)$ My goal is to update my beliefs about $\alpha$ and $\beta$ Here's my answer so far: It's to treat the two separately. Suppose I was given $\beta$. Then my ""signal"" for $\alpha$ would be $=Y-\beta$ and my updated probability that $\alpha=\alpha_1$ is: $P(\alpha=\alpha_1|Y,\beta)=\frac{p_1\phi(\frac{Y-\beta-\alpha_1}{v})}{p_1\phi(\frac{Y-\beta-\alpha_1}{v})+(1-p_1)\phi(\frac{Y-\beta-\alpha_2}{v})} \space \space$ (1) where $\phi$ is the standard normal pdf Similarly, the updated distribution of $\beta$ given $\alpha$ is $(\beta|\alpha,Y)$ ~ $N(\mu_1,\sigma^2_1)$ where $\mu_1 = \frac{\sigma^2}{\sigma^2+v^2}*(Y-\alpha)$ and $\sigma^2_1 = \frac{\sigma^2}{\sigma^2+v^2}*v^2\space \space$ (2) I'm not really sure how to proceed next. My goal is to write something like: $P(\alpha=\alpha_1|Y)=\int P(\alpha=\alpha_1|Y,\beta)dH(\beta)$ But, I'm not sure what distribution $H()$ to use. Edit: I suppose I could iterate back and forth between the above methods, but Ideally I am looking for a more closed form solution",,"['statistics', 'probability-distributions', 'normal-distribution', 'bayesian', 'bayes-theorem']"
26,How do I find percentiles of data sets (Even vs odd)?,How do I find percentiles of data sets (Even vs odd)?,,"Given the following data set with an even number of values: $100, 100, 105, 113, 129, 132, 146, 152, 176, 200$ The value representing the 30th percentile, using the formula n(p/100) where n = sample size and p = percentile, is at position 10(0.30) = 3. So the 30th percentile of this data is 105. Given the following data set with an odd number of values: $100, 100, 105, 113, 129, 132, 146, 152, 176, 200, 300$ The value representing the 30th percentile, using the formula n(p/100) where n = sample size and p = percentile, is at position 11(0.30) = 3.3. So now what does one do? I realize that this formula can yield a decimal even if the data set has an even amount of values, say if n = 36, and you want the 10th percentile, 36(.10) = 3.6. In this situation, do you average the 3rd and 4th values? Or is it the 3rd value? or the 4th value? How do you decide? What if the position was 3.2 or 3.7? Does it matter in choosing which value is represents the given percentile? Thanks for any help ahead of time.","Given the following data set with an even number of values: $100, 100, 105, 113, 129, 132, 146, 152, 176, 200$ The value representing the 30th percentile, using the formula n(p/100) where n = sample size and p = percentile, is at position 10(0.30) = 3. So the 30th percentile of this data is 105. Given the following data set with an odd number of values: $100, 100, 105, 113, 129, 132, 146, 152, 176, 200, 300$ The value representing the 30th percentile, using the formula n(p/100) where n = sample size and p = percentile, is at position 11(0.30) = 3.3. So now what does one do? I realize that this formula can yield a decimal even if the data set has an even amount of values, say if n = 36, and you want the 10th percentile, 36(.10) = 3.6. In this situation, do you average the 3rd and 4th values? Or is it the 3rd value? or the 4th value? How do you decide? What if the position was 3.2 or 3.7? Does it matter in choosing which value is represents the given percentile? Thanks for any help ahead of time.",,"['statistics', 'median', 'percentile']"
27,Is there a measure of 'evenness' of dispersion?,Is there a measure of 'evenness' of dispersion?,,"I looked up on the web, but couldn't find anything helpful. I'm basically looking for a way to measure how 'evenly' a value is distributed. As in, an 'evenly' distributed distribution like X : and an 'unevenly' distributed distribution Y of roughly the same mean and standard deviation: But is there any evenness measure m, such that m(X) > m(Y)? If there isn't, what would be the best way to create a measure like that? (Images screenshot from Khan Academy)","I looked up on the web, but couldn't find anything helpful. I'm basically looking for a way to measure how 'evenly' a value is distributed. As in, an 'evenly' distributed distribution like X : and an 'unevenly' distributed distribution Y of roughly the same mean and standard deviation: But is there any evenness measure m, such that m(X) > m(Y)? If there isn't, what would be the best way to create a measure like that? (Images screenshot from Khan Academy)",,"['statistics', 'standard-deviation', 'descriptive-statistics']"
28,Where should I use median instead of average?,Where should I use median instead of average?,,"Is there a general law, or rule of thumb, or rationale, when to use median and when average? Although I know the difference and how they are computed, when I try to translate to simple English I would say in both cases that they both are a value that justly and fairly represents a big group of values of a certain category. Examples: Grades across different subjects for a single student. Grades in one subject across students in one class. Time to close a ticket per worker of a support desk. Jail time given by a judge for a certain crime. Lap time in a 10 laps run for a certain runner. Monthly income per household in a given neighborhood. So what should I use in each case above? And what is the general rule. And as a side question, are there other types of aggregate functions other than median and average that relate to this?","Is there a general law, or rule of thumb, or rationale, when to use median and when average? Although I know the difference and how they are computed, when I try to translate to simple English I would say in both cases that they both are a value that justly and fairly represents a big group of values of a certain category. Examples: Grades across different subjects for a single student. Grades in one subject across students in one class. Time to close a ticket per worker of a support desk. Jail time given by a judge for a certain crime. Lap time in a 10 laps run for a certain runner. Monthly income per household in a given neighborhood. So what should I use in each case above? And what is the general rule. And as a side question, are there other types of aggregate functions other than median and average that relate to this?",,"['statistics', 'average', 'median']"
29,What is a bounded discrete random variable,What is a bounded discrete random variable,,"I'm reading a definition in DeGroot's book that begins with the statement: ""Let X be a bounded discrete random variable whose p.f. is f."" Then he goes on to define the expectation of X. However, I cannot find a definition of what is meant by a ""bounded"" discrete random variable anywhere in the book (after an hour of looking). I do know what a discrete random variable is, but what does the word ""bounded"" mean in this case? Thanks.","I'm reading a definition in DeGroot's book that begins with the statement: ""Let X be a bounded discrete random variable whose p.f. is f."" Then he goes on to define the expectation of X. However, I cannot find a definition of what is meant by a ""bounded"" discrete random variable anywhere in the book (after an hour of looking). I do know what a discrete random variable is, but what does the word ""bounded"" mean in this case? Thanks.",,['statistics']
30,Control limit and population mean,Control limit and population mean,,"A cola-dispensing machine is set to dispense $9.00$ ounces of cola per cup, with a standard deviation of $1.00$ ounces. The manufacturer of the machine would like to set the control limit in such a way that, for samples of $36$, $5$ percent of the sample means will be greater than the upper control limit, and $5$ percent of the sample means will be less than the lower control point. a) At what value should the control limit be set? b) What is the probability that if the population mean shifts to 8.9, this change will not be detected? c) What is the probability that if the population mean shifts to 9.3, this change will not be detected?","A cola-dispensing machine is set to dispense $9.00$ ounces of cola per cup, with a standard deviation of $1.00$ ounces. The manufacturer of the machine would like to set the control limit in such a way that, for samples of $36$, $5$ percent of the sample means will be greater than the upper control limit, and $5$ percent of the sample means will be less than the lower control point. a) At what value should the control limit be set? b) What is the probability that if the population mean shifts to 8.9, this change will not be detected? c) What is the probability that if the population mean shifts to 9.3, this change will not be detected?",,[]
31,"if $X$ and $Y$ are i.i.d., and if $X+Y$ and $X-Y$ are independent, are $X$ and $Y$ normally distributed?","if  and  are i.i.d., and if  and  are independent, are  and  normally distributed?",X Y X+Y X-Y X Y,"Just recently come across Normal Distribution, and the following statement seems to be quite true, but is it? Can someone provide some general proof sketch if so please: For X and Y identically and independently distributed with mean 0 and variance 1. Suppose X+Y and X-Y are independent Does it imply X and Y follow normal distribution?","Just recently come across Normal Distribution, and the following statement seems to be quite true, but is it? Can someone provide some general proof sketch if so please: For X and Y identically and independently distributed with mean 0 and variance 1. Suppose X+Y and X-Y are independent Does it imply X and Y follow normal distribution?",,"['statistics', 'probability-distributions', 'normal-distribution']"
32,What to do with the boundary values of a bin in a histogram?,What to do with the boundary values of a bin in a histogram?,,"Suppose I want to make a simple frequency histogram of the following data: $$\{3, 3, 4, 5, 5, 6, 7, 7, 8, 10, 11\}$$ I'm supposed to use bins of size $5$, starting with zero.  Here's my question: Is there a standard way to handle the boundary values of the bins?  My textbook has the two $5$ values go into the right-hand bin; is this always the case, or do some textbooks put the fives into the left-hand bin? Thanks!","Suppose I want to make a simple frequency histogram of the following data: $$\{3, 3, 4, 5, 5, 6, 7, 7, 8, 10, 11\}$$ I'm supposed to use bins of size $5$, starting with zero.  Here's my question: Is there a standard way to handle the boundary values of the bins?  My textbook has the two $5$ values go into the right-hand bin; is this always the case, or do some textbooks put the fives into the left-hand bin? Thanks!",,['statistics']
33,Expected value given that distribution is positive vs. conditional expectation,Expected value given that distribution is positive vs. conditional expectation,,"Referring to Expected value of normal distribution given that distribution is positive Where is the difference between $E(X$1$_A)$, where $A=[X>0]$, and $E(X∣A)$? Both seem to express the expected value of $X$ given that $X>0$ which is equal to the conditional expectation","Referring to Expected value of normal distribution given that distribution is positive Where is the difference between $E(X$1$_A)$, where $A=[X>0]$, and $E(X∣A)$? Both seem to express the expected value of $X$ given that $X>0$ which is equal to the conditional expectation",,['statistics']
34,Why is the MLE a special case of the minimum contrast estimator?,Why is the MLE a special case of the minimum contrast estimator?,,"In my statistics lecture, we had two definitions, namely Let $X_1,\ldots.X_n$ be iid random variables, each with density $p_{\Theta_0}(x)$. Furthermore, let $\varrho$ be a real function such that $$E_{\Theta_0}[\varrho(x,\Theta)] > E_{\Theta_0}[\varrho(x,\Theta_0)] ~~~~ \forall \Theta\neq\Theta_0. \tag{1}$$   Then, $$\hat{\Theta}=\operatorname{argmin}_{\Theta} \frac{1}{n} \sum_{i=1}^n \varrho(x_i,\Theta)$$ is the Minimum Contrast Estimator (MCE) of $\Theta$. and Let $X_1,\ldots.X_n$ be iid random variables, each with density $p_{\Theta_0}(x)$.   Then, $$\hat{\Theta}=\operatorname{argmax}_{\Theta} \log \prod_{i=1}^n p_\Theta(x_i)$$ is the Maximum Likelihood Estimator (MLE) of $\Theta$. My question. I do understand that setting $\varrho(x,\Theta):=-\log p_\Theta(x)$ will yield the MLE as a special case of the MCE. But why does the so definied function $\varrho$ satisfy condition (1)? My attempt. Writing out condition (1) for this choice of $\varrho$ yields $$\int -\log( p_\Theta(x)) p_{\Theta_0}(x) dx > \int -\log( p_{\Theta_0}(x)) p_{\Theta_0}(x) dx $$ which is equivalent to $$ \int \log\left(\frac{p_{\Theta_0}(x)}{p_\Theta(x)}\right) p_{\Theta_0}(x)dx > 0$$ meaning $$E\left[ \log\left(\frac{p_{\Theta_0}(X)}{p_\Theta(X)}\right)  \right] > 0.$$ I just don't know why this should be the case. Any hint is much appreciated!","In my statistics lecture, we had two definitions, namely Let $X_1,\ldots.X_n$ be iid random variables, each with density $p_{\Theta_0}(x)$. Furthermore, let $\varrho$ be a real function such that $$E_{\Theta_0}[\varrho(x,\Theta)] > E_{\Theta_0}[\varrho(x,\Theta_0)] ~~~~ \forall \Theta\neq\Theta_0. \tag{1}$$   Then, $$\hat{\Theta}=\operatorname{argmin}_{\Theta} \frac{1}{n} \sum_{i=1}^n \varrho(x_i,\Theta)$$ is the Minimum Contrast Estimator (MCE) of $\Theta$. and Let $X_1,\ldots.X_n$ be iid random variables, each with density $p_{\Theta_0}(x)$.   Then, $$\hat{\Theta}=\operatorname{argmax}_{\Theta} \log \prod_{i=1}^n p_\Theta(x_i)$$ is the Maximum Likelihood Estimator (MLE) of $\Theta$. My question. I do understand that setting $\varrho(x,\Theta):=-\log p_\Theta(x)$ will yield the MLE as a special case of the MCE. But why does the so definied function $\varrho$ satisfy condition (1)? My attempt. Writing out condition (1) for this choice of $\varrho$ yields $$\int -\log( p_\Theta(x)) p_{\Theta_0}(x) dx > \int -\log( p_{\Theta_0}(x)) p_{\Theta_0}(x) dx $$ which is equivalent to $$ \int \log\left(\frac{p_{\Theta_0}(x)}{p_\Theta(x)}\right) p_{\Theta_0}(x)dx > 0$$ meaning $$E\left[ \log\left(\frac{p_{\Theta_0}(X)}{p_\Theta(X)}\right)  \right] > 0.$$ I just don't know why this should be the case. Any hint is much appreciated!",,"['statistics', 'estimation', 'parameter-estimation']"
35,I have trouble understanding the proof of the Wold decomposition theorem,I have trouble understanding the proof of the Wold decomposition theorem,,"I'm trying to understand the proof of the Wold decomposition theorem in [1, p.187]. I find a few things about it very irritating. The theorem states: Theorem 5.7.1 (The Wold Decomposition). Let $X_t$ be a stationary process with $$\sigma^2 = E|X_{n+1}-P_{M_n}X_{n+1}|^2 >0,$$ where $$M_n=\overline{span} \lbrace X_t: -\infty<t\leq n \rbrace.$$ Then $X_t$ can be decomposed as $$X_t=\sum_{j=0}^\infty \psi_j Z_{t-j} + V_t$$ where (1) $\psi_0=1, \sum_{j=0}^\infty \psi^2< \infty$ (2) $E[Z_t]=0$, $var(Z_t)=\sigma^2$, $t \in \mathbb{Z}$ and $Z_t$ is uncorrelated (3) $Z_t \in M_t$,  $t \in \mathbb{Z}$ (4) $E(Z_tV_s)=0$,  $t,s \in \mathbb{Z}$ (5) $V_t$ is deterministic Here $P$ denotes the projection. The proof starts by setting $$Z_t:=X_t-P_{M_{t-1}}X_t,$$ $$\psi_t:=\langle X_t, Z_{t-j}\rangle/\sigma^2,$$ $$V_t:=X_t-\sum_{j=0}^\infty \psi_j Z_{t-j}.$$ We have to show that these sequences satisfy (1)-(5). Since $Z_t \in M_t$ and $Z_t \in M_{t-1}^\bot$ by definition, we have that $$Z_t \in M_{t-1}^\bot \subset M_{t-2}^\bot \subset...$$ which shows that $E(Z_sZ_t)=0$ for $s<t$. This establishes the last part of (2). Furthermore, an exercise in the book establishes that $var(Z_t)=\sigma^2$. What I am having trouble with is another part: My question: Why is $E[Z_t]=0$? And why does that not yield that $V=0$? My idea was to use the zero-mean-property of $X_t$. We know that $Z_t \in M_t$, i.e., in the smallest closed subspace that contains all $X_t$, $t<n$. Therefore, $Z_t$ is the limit of a subsequence $\lbrace X_{t_j} \rbrace$ of zero-mean and so $$E[Z_t]=E[\lim_{j \to \infty} X_{t_j}] = \int\lim_{j \to \infty} X_{t_j}dP = \lim_{j \to \infty} E[X_{t_j}]=0.$$ But why can I interchange the limit and the integral in the third inequality? And even worse: If $X_t$ as well as $Z_t$ indeed have zero-mean, why does that not result in $E[V_t]=0$ and therefore -by determinancy- $V_t=0$? Any help is much appreciated! [1] Brockwell, Peter J.: Time series: theory and methods. Second Edition. 2006, Springer.","I'm trying to understand the proof of the Wold decomposition theorem in [1, p.187]. I find a few things about it very irritating. The theorem states: Theorem 5.7.1 (The Wold Decomposition). Let $X_t$ be a stationary process with $$\sigma^2 = E|X_{n+1}-P_{M_n}X_{n+1}|^2 >0,$$ where $$M_n=\overline{span} \lbrace X_t: -\infty<t\leq n \rbrace.$$ Then $X_t$ can be decomposed as $$X_t=\sum_{j=0}^\infty \psi_j Z_{t-j} + V_t$$ where (1) $\psi_0=1, \sum_{j=0}^\infty \psi^2< \infty$ (2) $E[Z_t]=0$, $var(Z_t)=\sigma^2$, $t \in \mathbb{Z}$ and $Z_t$ is uncorrelated (3) $Z_t \in M_t$,  $t \in \mathbb{Z}$ (4) $E(Z_tV_s)=0$,  $t,s \in \mathbb{Z}$ (5) $V_t$ is deterministic Here $P$ denotes the projection. The proof starts by setting $$Z_t:=X_t-P_{M_{t-1}}X_t,$$ $$\psi_t:=\langle X_t, Z_{t-j}\rangle/\sigma^2,$$ $$V_t:=X_t-\sum_{j=0}^\infty \psi_j Z_{t-j}.$$ We have to show that these sequences satisfy (1)-(5). Since $Z_t \in M_t$ and $Z_t \in M_{t-1}^\bot$ by definition, we have that $$Z_t \in M_{t-1}^\bot \subset M_{t-2}^\bot \subset...$$ which shows that $E(Z_sZ_t)=0$ for $s<t$. This establishes the last part of (2). Furthermore, an exercise in the book establishes that $var(Z_t)=\sigma^2$. What I am having trouble with is another part: My question: Why is $E[Z_t]=0$? And why does that not yield that $V=0$? My idea was to use the zero-mean-property of $X_t$. We know that $Z_t \in M_t$, i.e., in the smallest closed subspace that contains all $X_t$, $t<n$. Therefore, $Z_t$ is the limit of a subsequence $\lbrace X_{t_j} \rbrace$ of zero-mean and so $$E[Z_t]=E[\lim_{j \to \infty} X_{t_j}] = \int\lim_{j \to \infty} X_{t_j}dP = \lim_{j \to \infty} E[X_{t_j}]=0.$$ But why can I interchange the limit and the integral in the third inequality? And even worse: If $X_t$ as well as $Z_t$ indeed have zero-mean, why does that not result in $E[V_t]=0$ and therefore -by determinancy- $V_t=0$? Any help is much appreciated! [1] Brockwell, Peter J.: Time series: theory and methods. Second Edition. 2006, Springer.",,"['statistics', 'stochastic-processes', 'time-series']"
36,sum of rounding errors,sum of rounding errors,,"My tax return involves 32 different numbers, each rounded to the nearest dollar and then added together. Assuming that the errors by rounding are uniformly distributed on the interval (-1/2,1/2), estimate the probability that the sum of the rounded amounts differs from the true sum by less than $1. Hint: this is really a question about the sum of the rounding errors. This is a homework problem and I have no idea where to even begin. Any help would be greatly appreciated.","My tax return involves 32 different numbers, each rounded to the nearest dollar and then added together. Assuming that the errors by rounding are uniformly distributed on the interval (-1/2,1/2), estimate the probability that the sum of the rounded amounts differs from the true sum by less than $1. Hint: this is really a question about the sum of the rounding errors. This is a homework problem and I have no idea where to even begin. Any help would be greatly appreciated.",,['statistics']
37,"$95\,\%$ confidence interval for geometric distribution",confidence interval for geometric distribution,"95\,\%","I am analyzing data with a geometric distribution. Using maximum likelihood estimation, I can estimate $p$ to be $\displaystyle \hat p_{MLE} = \frac{N}{\sum_{i=1}^N x_i}$, where $N$ is the number of datapoints and each $x$ is the number of trials necessary for the first success, in each separate experiment. However, it is not clear to me how 'accurate' this value is, and thus I'd like to construct a $95\,\%$ confidence interval. But my searches have been rather unsuccessful, as I can't find any worked out versions of a suitable confidence interval for this particular distribution. I'm pretty sure there has to be something out there, and I would be very thankful if someone could guide me towards it!","I am analyzing data with a geometric distribution. Using maximum likelihood estimation, I can estimate $p$ to be $\displaystyle \hat p_{MLE} = \frac{N}{\sum_{i=1}^N x_i}$, where $N$ is the number of datapoints and each $x$ is the number of trials necessary for the first success, in each separate experiment. However, it is not clear to me how 'accurate' this value is, and thus I'd like to construct a $95\,\%$ confidence interval. But my searches have been rather unsuccessful, as I can't find any worked out versions of a suitable confidence interval for this particular distribution. I'm pretty sure there has to be something out there, and I would be very thankful if someone could guide me towards it!",,['statistics']
38,Method of Moments - What's the logic?,Method of Moments - What's the logic?,,"Method of Moments - What's the logic? We have a random vector $X=(X_1,X_2,...,X_n)$ that generates a sample. The hypothesis is  that our components of the random vector $X_i$ are i.i.d. The method of moments, for point estimation, in statistical inference, suggests a way to find an estimate of a parameter $\theta$. If you need to estimate only one parameter, the procedure seems to force you to equate the first theoretical moment $E(X_i)$ to the corresponding sample moment. Question : If I have only one parameter to estimate, can I equate the second theoretical moment to the second sample moment in order to find $\theta$? Does the fact that I have only one parameter to estimate force me to use just the first moments in my equation? Am I free to use every moment in my equation? Thanks in advance.","Method of Moments - What's the logic? We have a random vector $X=(X_1,X_2,...,X_n)$ that generates a sample. The hypothesis is  that our components of the random vector $X_i$ are i.i.d. The method of moments, for point estimation, in statistical inference, suggests a way to find an estimate of a parameter $\theta$. If you need to estimate only one parameter, the procedure seems to force you to equate the first theoretical moment $E(X_i)$ to the corresponding sample moment. Question : If I have only one parameter to estimate, can I equate the second theoretical moment to the second sample moment in order to find $\theta$? Does the fact that I have only one parameter to estimate force me to use just the first moments in my equation? Am I free to use every moment in my equation? Thanks in advance.",,"['statistics', 'statistical-inference']"
39,What's the difference between arithmetic mean and average?,What's the difference between arithmetic mean and average?,,"I'm trying to intuitively understand an average / arithmetic mean: Here's my attempt: In front of me, I see 1 thermos, two computer mice, two pens, and an iPhone. If I sum those, I get $1+2+2+1=6$ items, $4$ of which are, in functional terms, different. So if I divide $6$ by the number of different items, I get $6/4 = 1.5$ which, I suppose, indicates the amount of repetition. Can you explain it better and/or more concretely?","I'm trying to intuitively understand an average / arithmetic mean: Here's my attempt: In front of me, I see 1 thermos, two computer mice, two pens, and an iPhone. If I sum those, I get $1+2+2+1=6$ items, $4$ of which are, in functional terms, different. So if I divide $6$ by the number of different items, I get $6/4 = 1.5$ which, I suppose, indicates the amount of repetition. Can you explain it better and/or more concretely?",,"['statistics', 'arithmetic']"
40,Best fit line using geometric distance (not vertical distance),Best fit line using geometric distance (not vertical distance),,"There must be a theory of finding the best fit line to a bunch of points in the plane, where ""best fit"" is defined by the geometric distance, not vertical distance.  In other words, we are trying to minimize the sum of the squares of the distances from the points to the line, where the distance is measured along lines that are perpendicular to the best fit.  What is this theory called, and where can I learn about it?","There must be a theory of finding the best fit line to a bunch of points in the plane, where ""best fit"" is defined by the geometric distance, not vertical distance.  In other words, we are trying to minimize the sum of the squares of the distances from the points to the line, where the distance is measured along lines that are perpendicular to the best fit.  What is this theory called, and where can I learn about it?",,"['statistics', 'regression']"
41,Z scoring and normal distribution,Z scoring and normal distribution,,"I tackled a question that asked Given the mean and std dev for rainfall in a city, Mean = 1126mm of rain std Dev. = 355mm of rain What is the probability that a year would have more than 2191mm of rainfall. The way I went about this was Using the Value - Mean/ Std Dev formula I retrieved a Z score from the table in my textbook as 0.0013 as the answer to the calculation was 3.00 . So I interpreted this as, to get a rainfall value of larger than 2191mm there is a 0.13% chance as the Z score is 0.0013 . So my Question is, how would I calculate this for LESS THAN not MORE THAN 2191, do I just calculate like so? 1 - P where P is 0.13%? EDIT: This is confusing for me then, if that is how you calculate it what if you retrieve a negative Z value If I take 685mm for a graph distributed like so And 685 is clearly towards the left side of the 1126mm mean value. If i retrieve a negative Z score of -1.24 using the same formula above to calculate it, do I just use the Z table normally? If so then I get a value of .1075 and to find out the P of less than 685mm would be 1-.1075 but that would mean the probability of it being less than 685mm is 0.8925 It is obvious that it's not 0.8925 . So I assume that for values less than the mean of  the  given data and you're calculating less than you don't have to do 1-P but if you were calculating the probability of MORE THAN 685mm of rain it would be 1-P. Is this correct thinking or am I going mad? Regards","I tackled a question that asked Given the mean and std dev for rainfall in a city, Mean = 1126mm of rain std Dev. = 355mm of rain What is the probability that a year would have more than 2191mm of rainfall. The way I went about this was Using the Value - Mean/ Std Dev formula I retrieved a Z score from the table in my textbook as 0.0013 as the answer to the calculation was 3.00 . So I interpreted this as, to get a rainfall value of larger than 2191mm there is a 0.13% chance as the Z score is 0.0013 . So my Question is, how would I calculate this for LESS THAN not MORE THAN 2191, do I just calculate like so? 1 - P where P is 0.13%? EDIT: This is confusing for me then, if that is how you calculate it what if you retrieve a negative Z value If I take 685mm for a graph distributed like so And 685 is clearly towards the left side of the 1126mm mean value. If i retrieve a negative Z score of -1.24 using the same formula above to calculate it, do I just use the Z table normally? If so then I get a value of .1075 and to find out the P of less than 685mm would be 1-.1075 but that would mean the probability of it being less than 685mm is 0.8925 It is obvious that it's not 0.8925 . So I assume that for values less than the mean of  the  given data and you're calculating less than you don't have to do 1-P but if you were calculating the probability of MORE THAN 685mm of rain it would be 1-P. Is this correct thinking or am I going mad? Regards",,"['statistics', 'normal-distribution']"
42,continuity correction,continuity correction,,I have been told by some PhD's that the correction for continuity used in statistics is wrong and has been know to be wrong for at least the past few decades. Here I mean if we have a discrete random variable $X$ with p.m.f $\;p(x)$ and approximate it by a continuous random variable with p.d.f $\;f(x)$ then $$P(i\leq X \leq j)\approx\int_{i-\frac{1}{2}}^{j+\frac{1}{2}}f(x)dx$$ And this becomes precise in the limit. Can someone explain to me why it is wrong?,I have been told by some PhD's that the correction for continuity used in statistics is wrong and has been know to be wrong for at least the past few decades. Here I mean if we have a discrete random variable $X$ with p.m.f $\;p(x)$ and approximate it by a continuous random variable with p.d.f $\;f(x)$ then $$P(i\leq X \leq j)\approx\int_{i-\frac{1}{2}}^{j+\frac{1}{2}}f(x)dx$$ And this becomes precise in the limit. Can someone explain to me why it is wrong?,,"['real-analysis', 'statistics']"
43,What rating system should I use for a team-based webiste?,What rating system should I use for a team-based webiste?,,"My website has a few thousand users, and they play in teams pitted against each other, i.e. 5v5. I want to implement a system whereby each user has an individual rating that adjusts whether they win/lose, depending on the skill rating of the other players involved. For instance, if a player on your team is really bad and you lose, then you won't lose as many points as if your team was a good one. I was thinking of averaging the ratings of each team, and using the ELO rating system to adjust ratings. But as far as I know the ELO rating is optimized for 1v1 games such as chess, and I'm not sure how mathematically suitable this rating system is for group matches. Excuse me if I sound like a math noob, but thank you in advance for answering this question","My website has a few thousand users, and they play in teams pitted against each other, i.e. 5v5. I want to implement a system whereby each user has an individual rating that adjusts whether they win/lose, depending on the skill rating of the other players involved. For instance, if a player on your team is really bad and you lose, then you won't lose as many points as if your team was a good one. I was thinking of averaging the ratings of each team, and using the ELO rating system to adjust ratings. But as far as I know the ELO rating is optimized for 1v1 games such as chess, and I'm not sure how mathematically suitable this rating system is for group matches. Excuse me if I sound like a math noob, but thank you in advance for answering this question",,['statistics']
44,Stratified Monte Carlo,Stratified Monte Carlo,,"Consider the integral $I=\int_{0}^{1}e^{-x}dx$. Now consider the stratifed Monte Carlo estimate $\hat{I^{s}}$, that has $N_{st}=8$ strata. What is the variance of $\hat{I^{s}}$? What is the percent reduction in variance over the simple Monte Carlo estimate? This follows the problem I asked and solved here: Expected Value and Variance of Monte Carlo Estimate of $\int_{0}^{1}e^{-x}dx$ True value: $\int_{0}^{1}e^{-x}dx=0.6321205588...$ Matlab code for basic Monte Carlo: m=1000; N = 1000; z=zeros(1,m); for j=1:m     U = rand(1,N);     X = exp(-U);     i=mean(X);     z(j)=i; end expectedvalue = mean(z) variance = var(z) Results: integral = 0.6382953,  variance =   3.1346e-05 Stratified Monte Carlo attempt: m=1000; N=1000; z=zeros(1,m); for j=1:m     K = 8;     Ni = N/K;         for i = 1 : K             XS = exp(-((i-1+rand(1,Ni))/K));             XSB(i) = mean(XS);             SS(i) = var(XS);         end,     SST = mean(SS/N);     z(j)=mean(XSB); end expectedvalue=mean(z) variance = var(z) Results: integral =  0.6321,  variance =  5.4545e-07 If anyone who knows Matlab can chime in and help out here, I'd be thankful.","Consider the integral $I=\int_{0}^{1}e^{-x}dx$. Now consider the stratifed Monte Carlo estimate $\hat{I^{s}}$, that has $N_{st}=8$ strata. What is the variance of $\hat{I^{s}}$? What is the percent reduction in variance over the simple Monte Carlo estimate? This follows the problem I asked and solved here: Expected Value and Variance of Monte Carlo Estimate of $\int_{0}^{1}e^{-x}dx$ True value: $\int_{0}^{1}e^{-x}dx=0.6321205588...$ Matlab code for basic Monte Carlo: m=1000; N = 1000; z=zeros(1,m); for j=1:m     U = rand(1,N);     X = exp(-U);     i=mean(X);     z(j)=i; end expectedvalue = mean(z) variance = var(z) Results: integral = 0.6382953,  variance =   3.1346e-05 Stratified Monte Carlo attempt: m=1000; N=1000; z=zeros(1,m); for j=1:m     K = 8;     Ni = N/K;         for i = 1 : K             XS = exp(-((i-1+rand(1,Ni))/K));             XSB(i) = mean(XS);             SS(i) = var(XS);         end,     SST = mean(SS/N);     z(j)=mean(XSB); end expectedvalue=mean(z) variance = var(z) Results: integral =  0.6321,  variance =  5.4545e-07 If anyone who knows Matlab can chime in and help out here, I'd be thankful.",,"['statistics', 'numerical-methods', 'matlab', 'monte-carlo']"
45,Sufficient Statistic for a Parameter,Sufficient Statistic for a Parameter,,"Show that the sum of the observations of a random sample of size $n$ from a gamma distribution that has pdf $f(x,\theta)=(1/\theta)e^{-x/\theta}$, $0<x<\infty$, $0<\theta<\infty$, zero elsewhere, is a sufficient statistic for $\theta$. This is what I did (but it's wrong, I don't know why): $$Y=X_1 + X_2 + \cdots + X_n$$ $$f(y,\theta)= \left(\frac{1}{\theta}\right)e^{-y/(\theta)}$$ $$f(x_1;\theta)f(x_2; \theta)\cdots f(x_n,\theta) = \left(\frac{1}{\theta}\right)^n e^{\frac{-x_1-x_2-\cdots-x_n}{\theta}}$$ So... $$\frac{f(x_1;\theta)f(x_2; \theta)\cdots f(x_n,\theta)}{f(y,\theta)} = \frac{(\frac{1}{\theta})^n e^{\frac{-x_1-x_2-\cdots-x_n}{\theta}}}{(\frac{1}{\theta})e^{-y/\theta}}$$ But that's equal to $(1/\theta)^{n-1}$, which does include $\theta$, so how is it sufficient? I'm sure I did a mistake but I don't know where... Thanks in advance","Show that the sum of the observations of a random sample of size $n$ from a gamma distribution that has pdf $f(x,\theta)=(1/\theta)e^{-x/\theta}$, $0<x<\infty$, $0<\theta<\infty$, zero elsewhere, is a sufficient statistic for $\theta$. This is what I did (but it's wrong, I don't know why): $$Y=X_1 + X_2 + \cdots + X_n$$ $$f(y,\theta)= \left(\frac{1}{\theta}\right)e^{-y/(\theta)}$$ $$f(x_1;\theta)f(x_2; \theta)\cdots f(x_n,\theta) = \left(\frac{1}{\theta}\right)^n e^{\frac{-x_1-x_2-\cdots-x_n}{\theta}}$$ So... $$\frac{f(x_1;\theta)f(x_2; \theta)\cdots f(x_n,\theta)}{f(y,\theta)} = \frac{(\frac{1}{\theta})^n e^{\frac{-x_1-x_2-\cdots-x_n}{\theta}}}{(\frac{1}{\theta})e^{-y/\theta}}$$ But that's equal to $(1/\theta)^{n-1}$, which does include $\theta$, so how is it sufficient? I'm sure I did a mistake but I don't know where... Thanks in advance",,[]
46,Straight line through data by eye - least squares? [closed],Straight line through data by eye - least squares? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. Want to improve this question? Update the question so it's on-topic for Mathematics Stack Exchange. Closed 11 years ago . Improve this question I heard an interesting fact a while ago about how people draw a line through a cloud of points on a scatter plot. Usually, when calculating lines of best fit, we use the minimal the sum of squares of residuals. But if you draw it (to the best of your ability) by eye, you likely won't draw a squared error fit. I believe the exponent is slightly lower than two. This means we try to draw the line close to many points, and don't worry about a few extreme outliers. Does anyone know what sort of error term we use intuitively? I realise the true objective function we minimise subconsciously probably has a more complex form, but this is just to get an indication for the form of the error penalties relative to least squares. I'm writing a chapter for my thesis about regression analysis and I want to mention the effect of using different exponents on the error term. I thought would be nice to throw this bit of information in, too! Thanks. Edit 1: I've just posted this photo for my Facebook friends to do some line of best fit by eye. I have asked them to either send me a picture of the graph with line, or just the extreme y-values of the line. It would be great if we could all have a go! Link: http://www.freeimagehosting.net/ujx9h Sorry for the annoying hosting site. Suggestions for good hoster welcome. Edit 2: (Following discussion in comments.) For simplicity's sake, I am restricting the investigation to error functions of the form of sum of simple exponents of the residual.","Closed. This question is off-topic . It is not currently accepting answers. Want to improve this question? Update the question so it's on-topic for Mathematics Stack Exchange. Closed 11 years ago . Improve this question I heard an interesting fact a while ago about how people draw a line through a cloud of points on a scatter plot. Usually, when calculating lines of best fit, we use the minimal the sum of squares of residuals. But if you draw it (to the best of your ability) by eye, you likely won't draw a squared error fit. I believe the exponent is slightly lower than two. This means we try to draw the line close to many points, and don't worry about a few extreme outliers. Does anyone know what sort of error term we use intuitively? I realise the true objective function we minimise subconsciously probably has a more complex form, but this is just to get an indication for the form of the error penalties relative to least squares. I'm writing a chapter for my thesis about regression analysis and I want to mention the effect of using different exponents on the error term. I thought would be nice to throw this bit of information in, too! Thanks. Edit 1: I've just posted this photo for my Facebook friends to do some line of best fit by eye. I have asked them to either send me a picture of the graph with line, or just the extreme y-values of the line. It would be great if we could all have a go! Link: http://www.freeimagehosting.net/ujx9h Sorry for the annoying hosting site. Suggestions for good hoster welcome. Edit 2: (Following discussion in comments.) For simplicity's sake, I am restricting the investigation to error functions of the form of sum of simple exponents of the residual.",,"['statistics', 'regression', 'mean-square-error']"
47,Distribution of Sum of Absolute Value of Random Variable,Distribution of Sum of Absolute Value of Random Variable,,"I'm wondering if there's a distribution $\Gamma$ such that if we draw $x_i \dots d_n$ iid from $\Gamma$, then $\sum_{i=1}^n |x_i|$ has a nice distribution. I thought maybe the normal distribution, since then the absolute value would be half-normal, but I'm not sure what the distribution of the sum of half-normal variables are.","I'm wondering if there's a distribution $\Gamma$ such that if we draw $x_i \dots d_n$ iid from $\Gamma$, then $\sum_{i=1}^n |x_i|$ has a nice distribution. I thought maybe the normal distribution, since then the absolute value would be half-normal, but I'm not sure what the distribution of the sum of half-normal variables are.",,"['statistics', 'probability-distributions']"
48,Uniform Distribution vs Exponential Distribution + Confidence interval,Uniform Distribution vs Exponential Distribution + Confidence interval,,"Let be a $pdf$, $f(X)$, with exponential distribution and other $pdf$, $f(Y)$, with uniform distribution. I realized, 5000 times, for each one respectively that follow: I used the R to generate a random sample of size $n = 5$, of the random variable  $X$ (and $Y$) with parameter $\gamma = 2,0$ (for $Y$ I used min=0 e max = 4). I calculated the confidence interval 95% for $\mu$ using the data from this sample. For $X$ variable I got a relative frequency closed to 80%, but for $Y$ variable I got  a relative frequency closed to 95%. My question is Why with distribution uniform e small $n$ the confidence intervals have better behave?","Let be a $pdf$, $f(X)$, with exponential distribution and other $pdf$, $f(Y)$, with uniform distribution. I realized, 5000 times, for each one respectively that follow: I used the R to generate a random sample of size $n = 5$, of the random variable  $X$ (and $Y$) with parameter $\gamma = 2,0$ (for $Y$ I used min=0 e max = 4). I calculated the confidence interval 95% for $\mu$ using the data from this sample. For $X$ variable I got a relative frequency closed to 80%, but for $Y$ variable I got  a relative frequency closed to 95%. My question is Why with distribution uniform e small $n$ the confidence intervals have better behave?",,['statistics']
49,Bizarre appearance of Cauchy-like density estimate,Bizarre appearance of Cauchy-like density estimate,,"I have some preliminary findings that are a little strange. I have a couple of related data sets that are small (~150) positive integer samples and that seem rather strange. Because they're small, I don't take their histograms seriously, so I've performed Gaussian kernel density estimation on both of them. (While I haven't been that careful about bandwidth selection, I've at least taken this into account, and doubt it is a significant issue in the present context--but I could be wrong.) The weird thing is this: in both cases, I get a remarkably good-looking fit to a Cauchy distribution (I've done this by hand, no MLE stuff in this instance*, but I've corroborated the fits by looking at normal and log-log plots) which is centered at a positive number (i.e., the KDE basically looks like this ). But as I've said, the samples are (and must be) positive integers, so the support of the distribution is the same. On the other hand, the Cauchy distribution fits very well on the positive region. The only thing that I can imagine producing something like this besides a mistake on my part is that these samples might admit some kind of interpretation of sums of IIDRVs and that leads to the apparent Cauchy-ness due to the generalized CLT . What might cause this? Explanations for mistakes are particularly   welcome. However, please note my doubts about the kernel bandwidth   being an issue. *However, I've tried MLE fits to some other common distributions (e.g., gamma) and these are terrible, especially in comparison.","I have some preliminary findings that are a little strange. I have a couple of related data sets that are small (~150) positive integer samples and that seem rather strange. Because they're small, I don't take their histograms seriously, so I've performed Gaussian kernel density estimation on both of them. (While I haven't been that careful about bandwidth selection, I've at least taken this into account, and doubt it is a significant issue in the present context--but I could be wrong.) The weird thing is this: in both cases, I get a remarkably good-looking fit to a Cauchy distribution (I've done this by hand, no MLE stuff in this instance*, but I've corroborated the fits by looking at normal and log-log plots) which is centered at a positive number (i.e., the KDE basically looks like this ). But as I've said, the samples are (and must be) positive integers, so the support of the distribution is the same. On the other hand, the Cauchy distribution fits very well on the positive region. The only thing that I can imagine producing something like this besides a mistake on my part is that these samples might admit some kind of interpretation of sums of IIDRVs and that leads to the apparent Cauchy-ness due to the generalized CLT . What might cause this? Explanations for mistakes are particularly   welcome. However, please note my doubts about the kernel bandwidth   being an issue. *However, I've tried MLE fits to some other common distributions (e.g., gamma) and these are terrible, especially in comparison.",,"['statistics', 'probability-distributions']"
50,Hypothesis testing,Hypothesis testing,,"Suppose we have a random sample $X_1$, $X_2$ from the Beta($\theta$, $1$) distribution and we want to test $H_{\theta} :\theta \leq 1$ against $H_1:\theta > 1$. The following test issued: “Reject $H_0$ if and only if $3X_1 \leq 4X_2$.” How to show that the power function of the test is given by $$\beta(\theta) = 1-\frac12\left(\frac34\right)^\theta$$ My try : This is not related to question, but I know how to solve if it is only one observation: let's say $X_1$ ~ Beta($\theta$, $1$) and the condition is $X_1 > \frac{1}{2}$ for same $H_0$ and $H_1$. To get the power function we have to solve for : $$\beta(\theta) = P_\theta(X > 1/2) = \int_{1/2}^1 \frac{\Gamma(\theta + 1)}{\Gamma(\theta)\Gamma(1)}x^{\theta-1}(1-x)^{1-1}\mathrm dx$$ I do not know how to go about the original problem I mentioned in the question.","Suppose we have a random sample $X_1$, $X_2$ from the Beta($\theta$, $1$) distribution and we want to test $H_{\theta} :\theta \leq 1$ against $H_1:\theta > 1$. The following test issued: “Reject $H_0$ if and only if $3X_1 \leq 4X_2$.” How to show that the power function of the test is given by $$\beta(\theta) = 1-\frac12\left(\frac34\right)^\theta$$ My try : This is not related to question, but I know how to solve if it is only one observation: let's say $X_1$ ~ Beta($\theta$, $1$) and the condition is $X_1 > \frac{1}{2}$ for same $H_0$ and $H_1$. To get the power function we have to solve for : $$\beta(\theta) = P_\theta(X > 1/2) = \int_{1/2}^1 \frac{\Gamma(\theta + 1)}{\Gamma(\theta)\Gamma(1)}x^{\theta-1}(1-x)^{1-1}\mathrm dx$$ I do not know how to go about the original problem I mentioned in the question.",,['statistics']
51,Why is Krippendorf's alpha behaving this way?,Why is Krippendorf's alpha behaving this way?,,"Let's say we have the following ordinal data with one subject and five observers: Q1 1  1  1  1  1 Krippendorf's alpha turns out to be $1$ , which means we have perfect agreement (as expected). However, if we introduce a little disagreement in answers by changing one value to $2$ : Q1 2  1  1  1  1 We get $\alpha = -0.188$ . What does this negative value mean? Similarly, if we introduce more subjects: Q1; Q2 1; 1 1; 1 1; 2 1; 1 1; 1 $\alpha = -0.0833$ , despite four observers agreeing on their answers ( $80\%$ agreement). Why is this happening and how are these negative values supposed to be interpreted?","Let's say we have the following ordinal data with one subject and five observers: Q1 1  1  1  1  1 Krippendorf's alpha turns out to be , which means we have perfect agreement (as expected). However, if we introduce a little disagreement in answers by changing one value to : Q1 2  1  1  1  1 We get . What does this negative value mean? Similarly, if we introduce more subjects: Q1; Q2 1; 1 1; 1 1; 2 1; 1 1; 1 , despite four observers agreeing on their answers ( agreement). Why is this happening and how are these negative values supposed to be interpreted?",1 2 \alpha = -0.188 \alpha = -0.0833 80\%,"['statistics', 'data-analysis', 'reliability']"
52,Injectivity condition of parametrised statistical manifold,Injectivity condition of parametrised statistical manifold,,"I am currently learning information geometry by following this note .  It starts by defining the set of probability distribution functions $$ S=\{p_\xi=p(x,\xi)\mid \xi=(\xi_1,\ldots, \xi_n)\in O\subset \mathbb{R}^n\}, $$ where $p(x,\xi)$ is a probability distribution function  on space $\Omega$ . It calls $O$ the parameter space, and requires $\xi\mapsto p_\xi$ to be injective, and $O$ is open. However, I find the injectivity condition is very strong for many nonlinear models. For example, let us  consider  the  following softmax models: $$ S=\left\{p_\xi(i)=\frac{e^{\xi_i}}{\sum^n_j e^{\xi_j}}, i=1,\ldots, n\mid \xi=(\xi_1,\ldots, \xi_n)\in \mathbb{R}^n\right\}. $$ Even though $p_\xi(i)=\exp\left(\xi_i-\log(\sum^n_j e^{\xi_j})\right)$ is of the exponential form, the map $\xi\mapsto p_\xi$ is not injective. Indeed, $p_{\xi}=p_{\tilde{\xi}}$ if $\xi=\tilde{\xi}+C\boldsymbol{1}$ for any $C\in \mathbb{R}$ , where $\boldsymbol{1}$ denotes the vector with all entries being $1$ .  Similarly, for many neural networks, the parameterisation is noninjective. However the   optimisation problem $\inf_{p\in S}J(p)$ can still be well-defined, in the sense that there exists a unique minimiser $p^\star\in S$ (associated with many parameterisations). Question . May I know whether this injectivity condition is essential to apply the geometric techniques  to study the set $S$ ? More precisely, can we still equip $S$ with   the well-known Fisher-information metric, and make $S$ a Riemannian manifold? If the injectivity is crucial, does it mean the information geometry is not suitable to study optimisation over softmax models, or more general neural network models? I am not sure whether there is a well-known technique to address this difficulty.","I am currently learning information geometry by following this note .  It starts by defining the set of probability distribution functions where is a probability distribution function  on space . It calls the parameter space, and requires to be injective, and is open. However, I find the injectivity condition is very strong for many nonlinear models. For example, let us  consider  the  following softmax models: Even though is of the exponential form, the map is not injective. Indeed, if for any , where denotes the vector with all entries being .  Similarly, for many neural networks, the parameterisation is noninjective. However the   optimisation problem can still be well-defined, in the sense that there exists a unique minimiser (associated with many parameterisations). Question . May I know whether this injectivity condition is essential to apply the geometric techniques  to study the set ? More precisely, can we still equip with   the well-known Fisher-information metric, and make a Riemannian manifold? If the injectivity is crucial, does it mean the information geometry is not suitable to study optimisation over softmax models, or more general neural network models? I am not sure whether there is a well-known technique to address this difficulty.","
S=\{p_\xi=p(x,\xi)\mid \xi=(\xi_1,\ldots, \xi_n)\in O\subset \mathbb{R}^n\},
 p(x,\xi) \Omega O \xi\mapsto p_\xi O 
S=\left\{p_\xi(i)=\frac{e^{\xi_i}}{\sum^n_j e^{\xi_j}}, i=1,\ldots, n\mid \xi=(\xi_1,\ldots, \xi_n)\in \mathbb{R}^n\right\}.
 p_\xi(i)=\exp\left(\xi_i-\log(\sum^n_j e^{\xi_j})\right) \xi\mapsto p_\xi p_{\xi}=p_{\tilde{\xi}} \xi=\tilde{\xi}+C\boldsymbol{1} C\in \mathbb{R} \boldsymbol{1} 1 \inf_{p\in S}J(p) p^\star\in S S S S","['statistics', 'differential-geometry', 'riemannian-geometry', 'information-geometry']"
53,Why does mutual information use KL divergence?,Why does mutual information use KL divergence?,,"Mutual information between a pair of random variables $X,Y$ having joint distribution $P_{(X,Y)}$ and marginal distributions $P_X,P_Y$ respectively is defined as $$I(X,Y)\equiv D_{\text{KL}}(P_{(X,Y)}\|P_X\otimes P_Y ),$$ where $D_{\text{KL}}$ is the KL divergence. Intuitively, this measures how much ""information"" is revealed about one random variable through observing the other by quantifying how far the joint distribution is from the product of marginals (this distance being zero when $X,Y$ are independent). Why not more flexibly allow for other notions of statistical distance ? i.e. Why not define $$\tilde I(X,Y,d)\equiv d(P_{(X,Y)},P_X\otimes P_Y )$$ for arbitrary distance $d$ ? There are distances that are at least as compelling as KL divergence, such as Jensen-Shannon divergence , which at least symmetrizes KL divergence, or the Wasserstein metric , which is actually a metric and enjoys other attractive properties (as observed in the ML literature ). I understand mutual information as defined has connections with entropy, so perhaps this makes the definition tractable? What merits are there in using the KL divergence vs. other distances?","Mutual information between a pair of random variables having joint distribution and marginal distributions respectively is defined as where is the KL divergence. Intuitively, this measures how much ""information"" is revealed about one random variable through observing the other by quantifying how far the joint distribution is from the product of marginals (this distance being zero when are independent). Why not more flexibly allow for other notions of statistical distance ? i.e. Why not define for arbitrary distance ? There are distances that are at least as compelling as KL divergence, such as Jensen-Shannon divergence , which at least symmetrizes KL divergence, or the Wasserstein metric , which is actually a metric and enjoys other attractive properties (as observed in the ML literature ). I understand mutual information as defined has connections with entropy, so perhaps this makes the definition tractable? What merits are there in using the KL divergence vs. other distances?","X,Y P_{(X,Y)} P_X,P_Y I(X,Y)\equiv D_{\text{KL}}(P_{(X,Y)}\|P_X\otimes P_Y ), D_{\text{KL}} X,Y \tilde I(X,Y,d)\equiv d(P_{(X,Y)},P_X\otimes P_Y ) d","['statistics', 'information-theory', 'entropy']"
54,MLE of number of colors,MLE of number of colors,,"I'm looking at this question and the solution given and I understand it, but I'm unable to see where I'm going wrong. The question states that there are $k$ equally frequent colors and we do not know $k.$ We examine four smarties and notice that they are red, green, red, orange. We wish to find the maximum likelihood estimate $\hat{k}$ . The solution given is that $$\text{lik}(k) = \frac{(k-1)(k-2)}{k^3} $$ since we are looking at the probability that the second and fourth color differs from the first and the third is equal to the first. This can easily seen to be maximized when $\hat{k} = 5$ . My issue is why we are looking at the probability that the second colour and fourth are different from the first. If we instead look at the probability as the probability of seeing R, G, R, O given there are $k$ colours then the likelihood function is just $$\text{lik}(k)=\frac{1}{k^4}$$ since all sequences of colours are equally likely. This is maximized when $k=3$ as there must at least be 3 different colors. I can sort of see that I'm going wrong somewhere as my answer is independent of the sequence we get, but where exactly am I going wrong? And why is the correct interpretation to ignore the actual sequence we get and only look at the differentiation between the colors? EDIT: I'm trying to reimagine a question with $k$ being the maximum positive integer allowed and we see a specific sequence 3, 1, 3, 7. In that case I believe my interpretation would probably be correct. So it must have something to do with the fact that colors aren't ordered, but I'm not able to convince myself exactly what the issue is.","I'm looking at this question and the solution given and I understand it, but I'm unable to see where I'm going wrong. The question states that there are equally frequent colors and we do not know We examine four smarties and notice that they are red, green, red, orange. We wish to find the maximum likelihood estimate . The solution given is that since we are looking at the probability that the second and fourth color differs from the first and the third is equal to the first. This can easily seen to be maximized when . My issue is why we are looking at the probability that the second colour and fourth are different from the first. If we instead look at the probability as the probability of seeing R, G, R, O given there are colours then the likelihood function is just since all sequences of colours are equally likely. This is maximized when as there must at least be 3 different colors. I can sort of see that I'm going wrong somewhere as my answer is independent of the sequence we get, but where exactly am I going wrong? And why is the correct interpretation to ignore the actual sequence we get and only look at the differentiation between the colors? EDIT: I'm trying to reimagine a question with being the maximum positive integer allowed and we see a specific sequence 3, 1, 3, 7. In that case I believe my interpretation would probably be correct. So it must have something to do with the fact that colors aren't ordered, but I'm not able to convince myself exactly what the issue is.",k k. \hat{k} \text{lik}(k) = \frac{(k-1)(k-2)}{k^3}  \hat{k} = 5 k \text{lik}(k)=\frac{1}{k^4} k=3 k,"['statistics', 'maximum-likelihood', 'parameter-estimation']"
55,"An exercise in ""Mathematical Statistics Jun Shao"" about the completeness of a 'modified' exponetial family","An exercise in ""Mathematical Statistics Jun Shao"" about the completeness of a 'modified' exponetial family",,"It is not the first time meeting this problem in StackExchange and I have read the answer to it(the original solution is copied at the bottom, also available in Show a statistic is complete but not suffcient , the idea is checking the completeness by definition). But it seems that he wrongly uses the inverse property of the two-sided Laplace transformation because now the transformation equality does not hold for every real value(not for $0$ ). So what should I do now because Laplace transformation is a direct and powerful tool to solve this kind of problem(like proving completeness in the general exponential family) but it does not work here, Are there any related properties that can fix it? Or other ideas? Let $X_{1}, \ldots, X_{n},(n \geq 2)$ be i.i.d. random variables having the normal distribution $N(\theta, 2)$ when $\theta=0$ and the normal distribution $N(\theta, 1)$ when $\theta \in \mathbb{R}-\{0\}$ . Show that the sample mean $\bar{X}$ is a complete statistic(sorry for missing this one before, this is the main concern of the question) but not a sufficient statistic for $\theta$ . $$ \begin{aligned} \mathrm{E}(g(\bar{X})) &=\int_{\mathbb{R}} g(u) f_{\bar{X}}(u) d u=\int_{\mathbb{R}} g(u) \frac{1}{\sqrt{2 \pi}} \exp \left(\frac{-1}{2} \cdot \frac{(u-\theta)^{2}}{2 / n}\right) d u \\ &=\frac{1}{\sqrt{2 \pi}} \int_{\mathbb{R}} g(u) \exp \left(\frac{-1}{2} \cdot \frac{u^{2}-2 u \theta+\theta^{2}}{2 / n}\right) d u \\ &=\frac{1}{\sqrt{2 \pi}} \cdot \exp \left(\frac{-n \theta^{2}}{4}\right) \int_{\mathbb{R}} \overbrace{\left(g(u) \exp \left(\frac{-n u^{2}}{4}\right)\right)}^{\text {Call this } h(u)} \exp \left(\left(\frac{n \theta}{2}\right) u\right) d u \end{aligned} $$ (The factor that does not depend on $u$ has been pulled out.) $$ =0 \text { only if } \int_{\mathbb{R}} h(u) \exp (\eta u) d u=0 $$ i.e. $\quad(\mathcal{L} h)(\eta)=0$ for every value of $\eta$ , where $\mathcal{L}$ is a two-sided Laplace transform. Recall the inverse property: if $\quad(\mathcal{L} f)(s)=\quad(\mathcal{L} g)(s)$ for every value of $s$ in $\mathbb{R}$ , then $f = g$ almost everywhere. Hence we conclude that $h = 0, a.e$ and therefore $g = 0, a.e$ , which complete the proof of completeness.","It is not the first time meeting this problem in StackExchange and I have read the answer to it(the original solution is copied at the bottom, also available in Show a statistic is complete but not suffcient , the idea is checking the completeness by definition). But it seems that he wrongly uses the inverse property of the two-sided Laplace transformation because now the transformation equality does not hold for every real value(not for ). So what should I do now because Laplace transformation is a direct and powerful tool to solve this kind of problem(like proving completeness in the general exponential family) but it does not work here, Are there any related properties that can fix it? Or other ideas? Let be i.i.d. random variables having the normal distribution when and the normal distribution when . Show that the sample mean is a complete statistic(sorry for missing this one before, this is the main concern of the question) but not a sufficient statistic for . (The factor that does not depend on has been pulled out.) i.e. for every value of , where is a two-sided Laplace transform. Recall the inverse property: if for every value of in , then almost everywhere. Hence we conclude that and therefore , which complete the proof of completeness.","0 X_{1}, \ldots, X_{n},(n \geq 2) N(\theta, 2) \theta=0 N(\theta, 1) \theta \in \mathbb{R}-\{0\} \bar{X} \theta 
\begin{aligned}
\mathrm{E}(g(\bar{X})) &=\int_{\mathbb{R}} g(u) f_{\bar{X}}(u) d u=\int_{\mathbb{R}} g(u) \frac{1}{\sqrt{2 \pi}} \exp \left(\frac{-1}{2} \cdot \frac{(u-\theta)^{2}}{2 / n}\right) d u \\
&=\frac{1}{\sqrt{2 \pi}} \int_{\mathbb{R}} g(u) \exp \left(\frac{-1}{2} \cdot \frac{u^{2}-2 u \theta+\theta^{2}}{2 / n}\right) d u \\
&=\frac{1}{\sqrt{2 \pi}} \cdot \exp \left(\frac{-n \theta^{2}}{4}\right) \int_{\mathbb{R}} \overbrace{\left(g(u) \exp \left(\frac{-n u^{2}}{4}\right)\right)}^{\text {Call this } h(u)} \exp \left(\left(\frac{n \theta}{2}\right) u\right) d u
\end{aligned}
 u 
=0 \text { only if } \int_{\mathbb{R}} h(u) \exp (\eta u) d u=0
 \quad(\mathcal{L} h)(\eta)=0 \eta \mathcal{L} \quad(\mathcal{L} f)(s)=\quad(\mathcal{L} g)(s) s \mathbb{R} f = g h = 0, a.e g = 0, a.e","['statistics', 'normal-distribution', 'inverse-laplace', 'sufficient-statistics']"
56,Is this a mutually exclusive event?,Is this a mutually exclusive event?,,"$\begin{array}{|c|c|c|c|}          \hline          & X = a & X = b & \text{Total}  \\          \hline          Y = c & 20 & 70 & 90 \\          \hline          Y = d & 15 & 45 & 60 \\          \hline          \text{Total} & 35 & 115 & 150 \\          \hline \end{array}$ $P(X = a\hspace{.5 em} OR\hspace{.5 em} Y \ne c)$ Since X can be and Y can be not c at the same time, I'm guessing they are not mutually exclusive so I cannot use the following formula. $P(X = a\hspace{.5 em} OR\hspace{.5 em} Y \ne c) = P(X = a) + P(Y \ne c) = \frac{95}{150}$ I just need to verify this is wrong or right.","Since X can be and Y can be not c at the same time, I'm guessing they are not mutually exclusive so I cannot use the following formula. I just need to verify this is wrong or right.","\begin{array}{|c|c|c|c|}
         \hline
         & X = a & X = b & \text{Total}  \\
         \hline
         Y = c & 20 & 70 & 90 \\
         \hline
         Y = d & 15 & 45 & 60 \\
         \hline
         \text{Total} & 35 & 115 & 150 \\
         \hline
\end{array} P(X = a\hspace{.5 em} OR\hspace{.5 em} Y \ne c) P(X = a\hspace{.5 em} OR\hspace{.5 em} Y \ne c) = P(X = a) + P(Y \ne c) = \frac{95}{150}",['statistics']
57,How to compute the dual of an optimization problem defined on a function space?,How to compute the dual of an optimization problem defined on a function space?,,"I am interested in one result in the first version of the paper titled ""On the Margin Theory of Feedforward Neural Networks"" by Colin Wei, Jason D. Lee, Qiang Liu and Tengyu Ma. In Equation B.1 of the appendix (page 17), the authors introduce the following optimization problem (which relates to the maximum margin of an $\ell_1$ -SVM classifier) : $$\begin{align} \min_{\alpha\in\mathcal L^1(\mathbb S^{d-1})} &||\alpha||_1 = \int_{u\in\mathbb S^{d-1}} |\alpha(u)|du \\ \text{subject to }\, &y_i\langle \alpha,\varphi(x_i)\rangle \ge 1 \end{align} \tag1$$ Here, $\mathbb S^{d-1}$ is the unit sphere in $\mathbb R^d$ , and $\mathcal L^1(\mathbb S^{d-1})$ is the set of real-valued functions defined on $\mathbb S^{d-1}$ with Lebesgue integrable absolute value. For all $i \in [\![ 1;n ]\!]$ , the pair $(x_i,y_i)\in\mathbb R^d \times \{-1,1\} $ represents datapoints and their associated labels, while $\varphi$ is a ""lifting function"" mapping any datapoint $x_i$ to the infinite dimensional space $\mathcal L^\infty(\mathbb S^{d-1}) $ , and thus $\varphi(x_i)\in\mathcal L^\infty(\mathbb S^{d-1})$ . Lastly, $\langle\cdot,\cdot\rangle$ represents the dot product : $\langle f,g\rangle =\int_{u\in\mathbb S^{d-1}} f(u)g(u)du $ . In claim B.3 of the paper (page 17), the authors claim that the dual of equation $(1)$ has the following form : $$  \begin{align} \max_{\lambda\in\mathbb R^n} &\sum_{i=1}^n \lambda_i \\ \text{subject to } &\left\lvert\sum_{i=1}^n \lambda_i y_i \phi(u^Tx_i)\right\rvert\le 1\; \forall u\in\mathbb S^{d-1}\\ &\lambda_i \ge 0 \; \forall i \in [\![ 1;n ]\!] \end{align} \tag2 $$ Where $\phi$ is such that $\forall u \in \mathbb S^{d-1}, \forall x \in \mathbb R^d, \varphi(x)[u] = \phi(u^Tx)$ . The details on how to prove that $(2)$ is the dual of $(1)$ are however not given and I fail to prove it myself, being quite unfamiliar with Lagrangian optimization on function spaces. My question is thus : How to prove that $\mathbf{(2)}$ is the dual of $\mathbf{(1)}$ ? I attempted to do the proof by proceeding like in the more common ""subset of $\mathbb R^d$ "" case, i.e. minimizing the Lagrangian, which according to my calculations has the following expression : $$L(\alpha,\lambda) = ||\alpha||_1 + \sum_{i=1}^n\lambda_i\left(1-y_i\left\langle\alpha,\varphi(x_i)\right\rangle\right) $$ However, I can't get much further than this, as I don't know how to find the minimum of $L(\alpha,\lambda)$ for $\alpha\in\mathcal L^1(\mathbb S^{d-1})$ . Even though the paper suggests to take $L^*(\lambda) = \sum_i \lambda_i $ , I don't know how to prove that it is indeed the solution, and I have no idea where that second constraint with the absolute value in $(2)$ comes from. I'm afraid that my approach is totally wrong. Any help with this problem will be much appreciated.","I am interested in one result in the first version of the paper titled ""On the Margin Theory of Feedforward Neural Networks"" by Colin Wei, Jason D. Lee, Qiang Liu and Tengyu Ma. In Equation B.1 of the appendix (page 17), the authors introduce the following optimization problem (which relates to the maximum margin of an -SVM classifier) : Here, is the unit sphere in , and is the set of real-valued functions defined on with Lebesgue integrable absolute value. For all , the pair represents datapoints and their associated labels, while is a ""lifting function"" mapping any datapoint to the infinite dimensional space , and thus . Lastly, represents the dot product : . In claim B.3 of the paper (page 17), the authors claim that the dual of equation has the following form : Where is such that . The details on how to prove that is the dual of are however not given and I fail to prove it myself, being quite unfamiliar with Lagrangian optimization on function spaces. My question is thus : How to prove that is the dual of ? I attempted to do the proof by proceeding like in the more common ""subset of "" case, i.e. minimizing the Lagrangian, which according to my calculations has the following expression : However, I can't get much further than this, as I don't know how to find the minimum of for . Even though the paper suggests to take , I don't know how to prove that it is indeed the solution, and I have no idea where that second constraint with the absolute value in comes from. I'm afraid that my approach is totally wrong. Any help with this problem will be much appreciated.","\ell_1 \begin{align}
\min_{\alpha\in\mathcal L^1(\mathbb S^{d-1})} &||\alpha||_1 = \int_{u\in\mathbb S^{d-1}} |\alpha(u)|du \\
\text{subject to }\, &y_i\langle \alpha,\varphi(x_i)\rangle \ge 1 \end{align} \tag1 \mathbb S^{d-1} \mathbb R^d \mathcal L^1(\mathbb S^{d-1}) \mathbb S^{d-1} i \in [\![ 1;n ]\!] (x_i,y_i)\in\mathbb R^d \times \{-1,1\}  \varphi x_i \mathcal L^\infty(\mathbb S^{d-1})  \varphi(x_i)\in\mathcal L^\infty(\mathbb S^{d-1}) \langle\cdot,\cdot\rangle \langle f,g\rangle =\int_{u\in\mathbb S^{d-1}} f(u)g(u)du  (1)  
\begin{align}
\max_{\lambda\in\mathbb R^n} &\sum_{i=1}^n \lambda_i \\
\text{subject to } &\left\lvert\sum_{i=1}^n \lambda_i y_i \phi(u^Tx_i)\right\rvert\le 1\; \forall u\in\mathbb S^{d-1}\\
&\lambda_i \ge 0 \; \forall i \in [\![ 1;n ]\!]
\end{align} \tag2
 \phi \forall u \in \mathbb S^{d-1}, \forall x \in \mathbb R^d, \varphi(x)[u] = \phi(u^Tx) (2) (1) \mathbf{(2)} \mathbf{(1)} \mathbb R^d L(\alpha,\lambda) = ||\alpha||_1 + \sum_{i=1}^n\lambda_i\left(1-y_i\left\langle\alpha,\varphi(x_i)\right\rangle\right)  L(\alpha,\lambda) \alpha\in\mathcal L^1(\mathbb S^{d-1}) L^*(\lambda) = \sum_i \lambda_i  (2)","['statistics', 'optimization', 'machine-learning']"
58,On Bayesian credible intervals,On Bayesian credible intervals,,"Question Let $X \mid \mu \sim \mathrm{Poisson} (\mu)$ and $\mu \sim \mathrm{Gamma} (1, 1)$ and suppose that a very large number $x$ is observed. Find, in terms of $x$ , an approximate $95\%$ Bayesian credible interval for $\mu$ . (Hint: $\mathrm{Gamma} (n, 1)$ is the distribution of the sum of $n$ independent $\mathrm{Exponential} (1)$ random variables). My thoughts The comments have pointed out some of my errors previously and following their suggestions, I have re-worked this. I have found that $\mu \mid X \sim \mathrm{Gamma} (X + 1, \frac 1 2)$ using shape and scale parameters and since $x$ is large, the Central Limit Theorem can be applied, but I am unsure if the following is correct - does this mean $\frac 1 2 \mu \mid x \sim \mathcal{N} (x + 1, x + 1)$ approximately and since approximately $95\%$ of all normal data falls within $2$ standard deviations of the mean, then an approximate $95\%$ credible interval for $\mu$ is $[2(x + 1 - 2\sqrt{x + 1}), 2(x + 1 + 2\sqrt{x + 1})]$ ? P.S. We have just covered Bayesian statistics and this is my first ever encounter of a problem asking for a credible interval, so any intuitive explanations will be greatly provided!","Question Let and and suppose that a very large number is observed. Find, in terms of , an approximate Bayesian credible interval for . (Hint: is the distribution of the sum of independent random variables). My thoughts The comments have pointed out some of my errors previously and following their suggestions, I have re-worked this. I have found that using shape and scale parameters and since is large, the Central Limit Theorem can be applied, but I am unsure if the following is correct - does this mean approximately and since approximately of all normal data falls within standard deviations of the mean, then an approximate credible interval for is ? P.S. We have just covered Bayesian statistics and this is my first ever encounter of a problem asking for a credible interval, so any intuitive explanations will be greatly provided!","X \mid \mu \sim \mathrm{Poisson} (\mu) \mu \sim \mathrm{Gamma} (1, 1) x x 95\% \mu \mathrm{Gamma} (n, 1) n \mathrm{Exponential} (1) \mu \mid X \sim \mathrm{Gamma} (X + 1, \frac 1 2) x \frac 1 2 \mu \mid x \sim \mathcal{N} (x + 1, x + 1) 95\% 2 95\% \mu [2(x + 1 - 2\sqrt{x + 1}), 2(x + 1 + 2\sqrt{x + 1})]","['statistics', 'probability-distributions', 'bayesian', 'exponential-distribution', 'gamma-distribution']"
59,"Show that $T(X)=(R,V)=\left( X_{(n)}-X_{(1)},\frac{X_{(n)}+X_{(1)}}{2} \right)$ is a minimal sufficient statistic for $\theta$.",Show that  is a minimal sufficient statistic for .,"T(X)=(R,V)=\left( X_{(n)}-X_{(1)},\frac{X_{(n)}+X_{(1)}}{2} \right) \theta","Let $X_{1}, X_{2}, ..., X_{n}$ be a random sample from $\text{Uniform}(\theta,\theta+1)$ population with $-\infty<\theta<\theta+1< \infty$ show that $T(X)=(X_{(1)},X_{(n)})$ is a minimal sufficient statistic for $\theta$ . Also, show that $T(X)=(R,V)=\left( X_{(n)}-X_{(1)},\frac{X_{(n)}+X_{(1)}}{2} \right)$ is a minimal sufficient statistic. For the first part I did the following $$f(x|\theta,\theta+1)=I_{(\theta,\theta+1)}(x_{(1)},x_{(n)})$$ then $$\frac{f(x|\theta,\theta+1)}{f(y|\theta,\theta+1)}=\frac{I_{(\theta,\theta+1)}(x_{(1)},x_{(n)})}{I_{(\theta,\theta+1)}(y_{(1)},y_{(n)})}$$ This is a constant function in $\theta$ iff $x_{(1)}=y_{(1)}$ and $x_{(n)}=y_{(n)}$ s.t. $T(X)=(X_{(1)},X_{(n)})$ is a minimal sufficient statistic for $\theta$ . However, I am not sure how to proceed to show that $T(X)=(R,V)=\left( X_{(n)}-X_{(1)},\frac{X_{(n)}+X_{(1)}}{2} \right)$ is a minimal sufficient statistic. Can some help me with this?","Let be a random sample from population with show that is a minimal sufficient statistic for . Also, show that is a minimal sufficient statistic. For the first part I did the following then This is a constant function in iff and s.t. is a minimal sufficient statistic for . However, I am not sure how to proceed to show that is a minimal sufficient statistic. Can some help me with this?","X_{1}, X_{2}, ..., X_{n} \text{Uniform}(\theta,\theta+1) -\infty<\theta<\theta+1< \infty T(X)=(X_{(1)},X_{(n)}) \theta T(X)=(R,V)=\left( X_{(n)}-X_{(1)},\frac{X_{(n)}+X_{(1)}}{2} \right) f(x|\theta,\theta+1)=I_{(\theta,\theta+1)}(x_{(1)},x_{(n)}) \frac{f(x|\theta,\theta+1)}{f(y|\theta,\theta+1)}=\frac{I_{(\theta,\theta+1)}(x_{(1)},x_{(n)})}{I_{(\theta,\theta+1)}(y_{(1)},y_{(n)})} \theta x_{(1)}=y_{(1)} x_{(n)}=y_{(n)} T(X)=(X_{(1)},X_{(n)}) \theta T(X)=(R,V)=\left( X_{(n)}-X_{(1)},\frac{X_{(n)}+X_{(1)}}{2} \right)","['statistics', 'statistical-inference', 'uniform-distribution', 'order-statistics']"
60,When can the level of the test be exactly $\alpha ?$ in non randomized test. And how to use CLT to find the critical value.,When can the level of the test be exactly  in non randomized test. And how to use CLT to find the critical value.,\alpha ?,"Let $X_{1}, \ldots, X_{n}$ be a sample from the Bernoulli distribution with parameter $p$ Consider testing $H_{0}: p=p_{0}$ versus $H_{1}: p=p_{1}$ where $p_{0}<p_{1}$ are known numbers. (a) Using the Neyman-Pearson lemma, find the most powerful test (Non-Randomized) among tests with level at most $\alpha$ .   When can the level of the test be exactly $\alpha ?$ (b) Use the CLT to find a critical value such that the level of the test is approximately (asymptotically for large $n$ ) $\alpha$ . To use Neyman Peason lemma I calculate $r$ as : $$r= \frac{f_1}{f_0} = \frac{p_1^{\Sigma x_i}(1-p_1)^{n-\Sigma x_i}}{p_0^{\Sigma x_i}(1-p_0)^{n-\Sigma x_i}}$$ For $p_1>p_0$ we have non randomized test is $\phi(x) =$ Reject $H_0$ for $\Sigma x_i \geq k$ . For given at most level $\alpha$ : $$\alpha \geq E_{p_0} \phi(x) = P_{p_0}\{\Sigma x_i \geq k\} = \Sigma_{r=k+1}^n (n_{C_r}) p_{0}^r (1-p_{0})^{n-r}$$ (a) I don't know how to proceed after this and what to say about When can the level of the test be exactly $\alpha ?$ (b) How to use CLT to find the critical value which satisfies the given condition. Please help me with this problem. Thankyou.","Let be a sample from the Bernoulli distribution with parameter Consider testing versus where are known numbers. (a) Using the Neyman-Pearson lemma, find the most powerful test (Non-Randomized) among tests with level at most .   When can the level of the test be exactly (b) Use the CLT to find a critical value such that the level of the test is approximately (asymptotically for large ) . To use Neyman Peason lemma I calculate as : For we have non randomized test is Reject for . For given at most level : (a) I don't know how to proceed after this and what to say about When can the level of the test be exactly (b) How to use CLT to find the critical value which satisfies the given condition. Please help me with this problem. Thankyou.","X_{1}, \ldots, X_{n} p H_{0}: p=p_{0} H_{1}: p=p_{1} p_{0}<p_{1} \alpha \alpha ? n \alpha r r= \frac{f_1}{f_0} = \frac{p_1^{\Sigma x_i}(1-p_1)^{n-\Sigma x_i}}{p_0^{\Sigma x_i}(1-p_0)^{n-\Sigma x_i}} p_1>p_0 \phi(x) = H_0 \Sigma x_i \geq k \alpha \alpha \geq E_{p_0} \phi(x) = P_{p_0}\{\Sigma x_i \geq k\} = \Sigma_{r=k+1}^n (n_{C_r}) p_{0}^r (1-p_{0})^{n-r} \alpha ?","['statistics', 'statistical-inference', 'hypothesis-testing', 'central-limit-theorem']"
61,How to show the difference of max and min of exponential random variables is exponential?,How to show the difference of max and min of exponential random variables is exponential?,,"Let $X \sim \exp(\lambda_1)$ and $Y \sim \exp(\lambda_2)$ be two exponential random variables. Let $M= \max(X,Y)$ and $L= \min(X, Y)$ . We know that $M -L = |X-Y|$ . How to show $M -L$ is distributed exponentially? My try: $$ P(M-L \leq t) = P( |X-Y| \leq t)=\int_{-\infty}^\infty \int_{x = y- t}^{x= y+t} \lambda_1 e^{-\lambda_1x}\lambda_2e^{-\lambda_2y} \, dx \, dy $$ First I do not know if this is the double integral that leads to the solution. Second, when I try to solve it does not a convergent integral. Can you help me on that?","Let and be two exponential random variables. Let and . We know that . How to show is distributed exponentially? My try: First I do not know if this is the double integral that leads to the solution. Second, when I try to solve it does not a convergent integral. Can you help me on that?","X \sim \exp(\lambda_1) Y \sim \exp(\lambda_2) M= \max(X,Y) L= \min(X, Y) M -L = |X-Y| M -L 
P(M-L \leq t) = P( |X-Y| \leq t)=\int_{-\infty}^\infty \int_{x = y- t}^{x= y+t} \lambda_1 e^{-\lambda_1x}\lambda_2e^{-\lambda_2y} \, dx \, dy
",['statistics']
62,"Let $X_1...X_n \sim \Gamma(\alpha,\beta)$, what unbiased estimator of $\frac{1}{\beta}$ has minimum variance?","Let , what unbiased estimator of  has minimum variance?","X_1...X_n \sim \Gamma(\alpha,\beta) \frac{1}{\beta}","Given that $\alpha$ is known and $\beta$ is an unknown rate parameter, how do I find the unbiased estimator of $\frac{1}{\beta}$ ? Does it involve finding $\hat\theta_{\text{MLE}}$ first? I honestly don't know where to start.","Given that is known and is an unknown rate parameter, how do I find the unbiased estimator of ? Does it involve finding first? I honestly don't know where to start.",\alpha \beta \frac{1}{\beta} \hat\theta_{\text{MLE}},"['statistics', 'parameter-estimation']"
63,How to isolate individual contributions to group against another group?,How to isolate individual contributions to group against another group?,,"Is there a way to compare individual team member contributions when pitted against another team multiple times?  This is in a sport like rowing where you take N number of individuals from a set A and M number of individuals against set B. Is there a way to make estimations on-going with incomplete sets (not all unique combinations of N vs M exist) or with some interdependence where some in N or M are never changed out? In a similar vein to this question How to extract an individual's (normalized) contribution from a group? I am interested if there are some recommended approaches or literature on this subject.  The difference in my question is this limited to two groups with known team vs team data. Just to make it clear, I'm trying to compare relative times between teams and then try to see individual performance.  So for example here is some fake data between Team A and Team B with 9 members to choose 5 from with the teams results for that Event (note the times are the same for members because they are racing in the same boats). TEAM A      Event1     Event2   Event3 N1          55.5       53.3     51.2 N2          ----       53.3     ---- N3          55.5       53.3     ---- N4          55.5       -----    51.2 N5          55.5       ----     51.2 N6          ----       53.3     51.2 N7          ----       53.3     ---- N8          55.5       ----     ---- N9          ----       ----     51.2  Vs TEAM B TEAM B      EVENT1     Event2   Event3 M1          55.0       52.9     53.2 M2          ----       52.9     ---- M3          55.0       52.9     ---- M4          55.0       ----     53.2 M5          55.0       ----     53.2 M6          ----       52.9     53.2 M7          ----       52.9     ---- M8          55.0       ----     ---- M9          ----       ----     53.2 Each event occurs in different conditions so only the same events can be directly compared of Team A vs B.  So for example Team A group at Event1 clocked 55.5 and Team B group won at 55.0. What I've Tried I've computed their relative time difference per event.  Then I've taken each individuals average time difference and compare them.  This works ok, but I don't think this is an accurate comparison and I don't know how to estimate cases where the data is limited or how to know what data still should be gathered.","Is there a way to compare individual team member contributions when pitted against another team multiple times?  This is in a sport like rowing where you take N number of individuals from a set A and M number of individuals against set B. Is there a way to make estimations on-going with incomplete sets (not all unique combinations of N vs M exist) or with some interdependence where some in N or M are never changed out? In a similar vein to this question How to extract an individual's (normalized) contribution from a group? I am interested if there are some recommended approaches or literature on this subject.  The difference in my question is this limited to two groups with known team vs team data. Just to make it clear, I'm trying to compare relative times between teams and then try to see individual performance.  So for example here is some fake data between Team A and Team B with 9 members to choose 5 from with the teams results for that Event (note the times are the same for members because they are racing in the same boats). TEAM A      Event1     Event2   Event3 N1          55.5       53.3     51.2 N2          ----       53.3     ---- N3          55.5       53.3     ---- N4          55.5       -----    51.2 N5          55.5       ----     51.2 N6          ----       53.3     51.2 N7          ----       53.3     ---- N8          55.5       ----     ---- N9          ----       ----     51.2  Vs TEAM B TEAM B      EVENT1     Event2   Event3 M1          55.0       52.9     53.2 M2          ----       52.9     ---- M3          55.0       52.9     ---- M4          55.0       ----     53.2 M5          55.0       ----     53.2 M6          ----       52.9     53.2 M7          ----       52.9     ---- M8          55.0       ----     ---- M9          ----       ----     53.2 Each event occurs in different conditions so only the same events can be directly compared of Team A vs B.  So for example Team A group at Event1 clocked 55.5 and Team B group won at 55.0. What I've Tried I've computed their relative time difference per event.  Then I've taken each individuals average time difference and compare them.  This works ok, but I don't think this is an accurate comparison and I don't know how to estimate cases where the data is limited or how to know what data still should be gathered.",,['statistics']
64,Mean squared error for vectors,Mean squared error for vectors,,"I know that when we compare estimators $\hat{b_1}$ and $\hat{b_2}$ to an unknown parameter $\beta$ , in classical statistics an estimator $\hat{b_1}$ is said to be ""better"" than $\hat{b_2}$ if: $$ MSE(\hat{b_1}) \leq MSE(\hat{b_2}) $$ where MSE is the mean squared error: $$ MSE(\hat{b_1}) = E((\hat{b_1}-\beta)^2 )$$ Now if I had a vector $ \boldsymbol{b} =(b_1,b_2,\ldots b_n)$ of parameters to estimate, how could I compare estimators in terms of the MSE? Because there is no unique ordering relation in vectors. I know some people compare component by component of both estimators, yet I seem to find no bibliography for that. Could you guys help me figure out a bibliography for that?","I know that when we compare estimators and to an unknown parameter , in classical statistics an estimator is said to be ""better"" than if: where MSE is the mean squared error: Now if I had a vector of parameters to estimate, how could I compare estimators in terms of the MSE? Because there is no unique ordering relation in vectors. I know some people compare component by component of both estimators, yet I seem to find no bibliography for that. Could you guys help me figure out a bibliography for that?","\hat{b_1} \hat{b_2} \beta \hat{b_1} \hat{b_2}  MSE(\hat{b_1}) \leq MSE(\hat{b_2})   MSE(\hat{b_1}) = E((\hat{b_1}-\beta)^2 )  \boldsymbol{b} =(b_1,b_2,\ldots b_n)","['statistics', 'estimation', 'parameter-estimation', 'mean-square-error']"
65,Correlation coefficient and regression line : Geometric intuition,Correlation coefficient and regression line : Geometric intuition,,"correlation coefficient $$r = \frac{1}{n}\sum_{i=1}^n\frac{(x_i-\bar x)(y_i-\bar y)}{\sigma_x\cdot\sigma_y}$$ may be thought of as cosine of angle between two $n$-dimensional vectors $$ (x_1- \bar x, x_2- \bar x,\ldots, x_n- \bar x) \text{ and } (y_1- \bar y,y_2- \bar y,\ldots,y_n- \bar y)$$ But what is special about these two vectors? why don't we take take angles between any other two vectors? Yes, I know the intuition behind the algebra,that we  subtract $\bar x\text{ and } \bar y$ so that the mean is zero and the the sign of products gives us the correlation and we divide by $\sigma_x\cdot\sigma_y$ to remove the effects of scaling of the distributions. I want to know the geometric intuition in terms of angle between two vectors. Also I would like to know the geometric intuition behind the relationship slope of regression line $$=r \cdot \frac{\sigma_y}{\sigma_x}$$ I know that when $r = 1,$ the slope of regression line should be  $\frac{\sigma_y}{\sigma_x}$ What I don't understand is how the cosine of angle between two vectors $$ (x_1- \bar x, x_2- \bar x,\ldots,x_n- \bar x) \text{ and } (y_1- \bar y,y_2- \bar y,\ldots,y_n- \bar y)$$ when multiplied to $\frac{\sigma_y}{\sigma_x}$ gives us the slope.","correlation coefficient $$r = \frac{1}{n}\sum_{i=1}^n\frac{(x_i-\bar x)(y_i-\bar y)}{\sigma_x\cdot\sigma_y}$$ may be thought of as cosine of angle between two $n$-dimensional vectors $$ (x_1- \bar x, x_2- \bar x,\ldots, x_n- \bar x) \text{ and } (y_1- \bar y,y_2- \bar y,\ldots,y_n- \bar y)$$ But what is special about these two vectors? why don't we take take angles between any other two vectors? Yes, I know the intuition behind the algebra,that we  subtract $\bar x\text{ and } \bar y$ so that the mean is zero and the the sign of products gives us the correlation and we divide by $\sigma_x\cdot\sigma_y$ to remove the effects of scaling of the distributions. I want to know the geometric intuition in terms of angle between two vectors. Also I would like to know the geometric intuition behind the relationship slope of regression line $$=r \cdot \frac{\sigma_y}{\sigma_x}$$ I know that when $r = 1,$ the slope of regression line should be  $\frac{\sigma_y}{\sigma_x}$ What I don't understand is how the cosine of angle between two vectors $$ (x_1- \bar x, x_2- \bar x,\ldots,x_n- \bar x) \text{ and } (y_1- \bar y,y_2- \bar y,\ldots,y_n- \bar y)$$ when multiplied to $\frac{\sigma_y}{\sigma_x}$ gives us the slope.",,"['statistics', 'regression', 'correlation', 'linear-regression']"
66,Confidence intervals for proportions - why isn't the Bessel correction used in estimating the standard deviation?,Confidence intervals for proportions - why isn't the Bessel correction used in estimating the standard deviation?,,"When calculating confidence intervals for a population with standard deviation σ unknown, σ is estimated using the sample standard deviation S, which uses the Bessel correction to more closely approximate the real σ. But suppose the population X is a Bernoulli variable. X being now a binary variable, $  \sum_{i=1}^n (x_i - \bar x)^2 = n\bar x (1 - \bar x) $ (as we can see in an answer to this question). So the formula of the sample standard deviation would be $ S = \sqrt {\frac {n} {n-1} \bar x (1 - \bar x)}$. But in all resources I've read about confidence intervals for proportions , when the population proportion p is unknown, the standard deviation of the population is estimated by $ \sqrt{\bar p (1-\bar p)} $ . This approximation, however, does not use the Bessel correction. If it were, σ would be approximated by $ \sqrt{\frac {n} {n-1} \bar p (1-\bar p)} $. I understand that $ \bar p (1-\bar p)$ is a consistent estimator for $p(1-p)$, but wouldn't $\frac {n} {n-1} \bar p (1-\bar p)$ be consistend and unbiased, and thus a better estimator?","When calculating confidence intervals for a population with standard deviation σ unknown, σ is estimated using the sample standard deviation S, which uses the Bessel correction to more closely approximate the real σ. But suppose the population X is a Bernoulli variable. X being now a binary variable, $  \sum_{i=1}^n (x_i - \bar x)^2 = n\bar x (1 - \bar x) $ (as we can see in an answer to this question). So the formula of the sample standard deviation would be $ S = \sqrt {\frac {n} {n-1} \bar x (1 - \bar x)}$. But in all resources I've read about confidence intervals for proportions , when the population proportion p is unknown, the standard deviation of the population is estimated by $ \sqrt{\bar p (1-\bar p)} $ . This approximation, however, does not use the Bessel correction. If it were, σ would be approximated by $ \sqrt{\frac {n} {n-1} \bar p (1-\bar p)} $. I understand that $ \bar p (1-\bar p)$ is a consistent estimator for $p(1-p)$, but wouldn't $\frac {n} {n-1} \bar p (1-\bar p)$ be consistend and unbiased, and thus a better estimator?",,"['statistics', 'statistical-inference', 'binomial-distribution', 'standard-deviation', 'confidence-interval']"
67,Maximizing expected value with constrained 2nd moment,Maximizing expected value with constrained 2nd moment,,"$$\begin{array}{ll} \text{maximize} & \displaystyle\int_{0}^{1} x \, f(x) \, \mathrm dx\\ \text{subject to} & \displaystyle\int_{0}^{1} f(x) \, \mathrm dx = 1\\ & \displaystyle\int_{0}^{1} x^2 f(x) \, \mathrm dx = 1\\ & f(x) \geq 0 \quad \forall x \in [0,1]\end{array}$$ A few years ago I studied calculus of variations but for some reason I keep chasing my tail on this problem. If my recollection is even close to the mark we start with $$L=\int_{0}^{1} \left( f(x) \cdot x \right) dx + \lambda_1 \cdot \left( \int_{0}^{1} \left( f(x) \right) dx - 1\right) + \lambda_2 \cdot \left( \int_{0}^{1} \left( f(x) \cdot x^2 \right) dx - 1\right)$$ And then Euler Lagrange drops $f$ completely and gives $$x+\lambda_1 +\lambda_2 x^2=0$$ If the slack constraints are functional $$L=\int_{0}^{1} \left( f(x) \cdot x \right) + \lambda_1(x) \cdot \left(  \left( f(x) \right)  - 1\right) + \lambda_2(x) \cdot \left( \left( f(x) \cdot x^2 \right)  - 1\right) dx$$ gives $$x+\lambda_1(x) +\lambda_2(x) x^2=0$$ But I'm not sure if from here how we enforce the $\lambda$ partials, which if they're just taken directly seem to contradict each other... Conceptually there should be a solution. I'd appreciate some tips on this refresher. Edit: Only solution to constraints is discontinuous. Poorly posed. What about... The version where the expected value of X is to be minimized such that X>0 and the second Central moment (variance) is 1? The PDF of that I think hits the same roadblocks I hit above but is a nontrivial computation. Goal to find the PDF $f(x)$ on $x>0$.","$$\begin{array}{ll} \text{maximize} & \displaystyle\int_{0}^{1} x \, f(x) \, \mathrm dx\\ \text{subject to} & \displaystyle\int_{0}^{1} f(x) \, \mathrm dx = 1\\ & \displaystyle\int_{0}^{1} x^2 f(x) \, \mathrm dx = 1\\ & f(x) \geq 0 \quad \forall x \in [0,1]\end{array}$$ A few years ago I studied calculus of variations but for some reason I keep chasing my tail on this problem. If my recollection is even close to the mark we start with $$L=\int_{0}^{1} \left( f(x) \cdot x \right) dx + \lambda_1 \cdot \left( \int_{0}^{1} \left( f(x) \right) dx - 1\right) + \lambda_2 \cdot \left( \int_{0}^{1} \left( f(x) \cdot x^2 \right) dx - 1\right)$$ And then Euler Lagrange drops $f$ completely and gives $$x+\lambda_1 +\lambda_2 x^2=0$$ If the slack constraints are functional $$L=\int_{0}^{1} \left( f(x) \cdot x \right) + \lambda_1(x) \cdot \left(  \left( f(x) \right)  - 1\right) + \lambda_2(x) \cdot \left( \left( f(x) \cdot x^2 \right)  - 1\right) dx$$ gives $$x+\lambda_1(x) +\lambda_2(x) x^2=0$$ But I'm not sure if from here how we enforce the $\lambda$ partials, which if they're just taken directly seem to contradict each other... Conceptually there should be a solution. I'd appreciate some tips on this refresher. Edit: Only solution to constraints is discontinuous. Poorly posed. What about... The version where the expected value of X is to be minimized such that X>0 and the second Central moment (variance) is 1? The PDF of that I think hits the same roadblocks I hit above but is a nontrivial computation. Goal to find the PDF $f(x)$ on $x>0$.",,"['statistics', 'optimization', 'calculus-of-variations', 'moment-problem']"
68,"What is the correct term for ""growth rate of growth rate""?","What is the correct term for ""growth rate of growth rate""?",,"Let's say a company had these monthly sales: Jan: $10$ Feb: $15$ Mar: $22.5$ The growth rate of sales would be: Jan: - Feb: $50$% Mar: $50$% What is the correct term for the ""growth rate of the growth rate of sales""? e.g.: Jan: - Feb: - Mar: $0$% There are no results found when googling ""growth rate of growth rate"", which leads me to believe I don't know the common term for how to refer to things like this.","Let's say a company had these monthly sales: Jan: $10$ Feb: $15$ Mar: $22.5$ The growth rate of sales would be: Jan: - Feb: $50$% Mar: $50$% What is the correct term for the ""growth rate of the growth rate of sales""? e.g.: Jan: - Feb: - Mar: $0$% There are no results found when googling ""growth rate of growth rate"", which leads me to believe I don't know the common term for how to refer to things like this.",,['statistics']
69,Equality of Expecations Regarding i.i.d Random Variables.,Equality of Expecations Regarding i.i.d Random Variables.,,"If we have $n$ i.i.d random variables $X_1,\ldots,X_n$, and some real-valued function $g: \mathbb{R} \to \mathbb{R}$, is it true that $\mathbb{E}(g(X_1)) = \cdots = \mathbb{E}(g(X_n))$? I think this is true since all the random variables follow the same distribution, when it comes down to it, calculating the expectation for each random variable will follow the same procedure, resulting in the same answer. Can anybody provide a more rigorous justification/proof? Or is this a fine proof? let $i,j \in \{1,\ldots,n\}$ with $i \neq j$. Discrete case: Since $X_1,\ldots,X_n$ are i.i.d, they all have the same associated probability function, so $$\mathbb{E}(g(X_i)) = \sum_{\text{all }x} g(x)\mathbb{P}(X_i = x) = \sum_{\text{all} \ x} g(x)\mathbb{P}(X_j = x) = \mathbb{E}(X_j)$$ Continuous case: Since $X_1,\ldots,X_n$ are i.i.d, they all have the same associated pdf $f$, so $$\mathbb{E}(g(X_i)) = \int_{\text{all } x} g(x) f(x) \, dx = \mathbb{E}(g(X_j))$$ Hence, the result.","If we have $n$ i.i.d random variables $X_1,\ldots,X_n$, and some real-valued function $g: \mathbb{R} \to \mathbb{R}$, is it true that $\mathbb{E}(g(X_1)) = \cdots = \mathbb{E}(g(X_n))$? I think this is true since all the random variables follow the same distribution, when it comes down to it, calculating the expectation for each random variable will follow the same procedure, resulting in the same answer. Can anybody provide a more rigorous justification/proof? Or is this a fine proof? let $i,j \in \{1,\ldots,n\}$ with $i \neq j$. Discrete case: Since $X_1,\ldots,X_n$ are i.i.d, they all have the same associated probability function, so $$\mathbb{E}(g(X_i)) = \sum_{\text{all }x} g(x)\mathbb{P}(X_i = x) = \sum_{\text{all} \ x} g(x)\mathbb{P}(X_j = x) = \mathbb{E}(X_j)$$ Continuous case: Since $X_1,\ldots,X_n$ are i.i.d, they all have the same associated pdf $f$, so $$\mathbb{E}(g(X_i)) = \int_{\text{all } x} g(x) f(x) \, dx = \mathbb{E}(g(X_j))$$ Hence, the result.",,"['statistics', 'probability-distributions']"
70,Bayesian and frequency tail estimation.,Bayesian and frequency tail estimation.,,The tail probability can be estimated by two methods: In Bayesian method: $$P_B(X>a)=\int^{\infty}_{-\infty}\pi(\theta|x)[1-F(a|\theta)]d\theta$$ In Plug-in frequency method: $$P_F(X>a)=1-F(a|\hat{\theta})$$  where $\hat{\theta}$ is the MLE of $\theta$. The numerical results show that it's always $$P_B \geq P_F$$ no matter what the distribution is. Any ideas or any resources related to this topic to explain why is that? Many thanks~,The tail probability can be estimated by two methods: In Bayesian method: $$P_B(X>a)=\int^{\infty}_{-\infty}\pi(\theta|x)[1-F(a|\theta)]d\theta$$ In Plug-in frequency method: $$P_F(X>a)=1-F(a|\hat{\theta})$$  where $\hat{\theta}$ is the MLE of $\theta$. The numerical results show that it's always $$P_B \geq P_F$$ no matter what the distribution is. Any ideas or any resources related to this topic to explain why is that? Many thanks~,,"['statistics', 'statistical-inference', 'bayesian', 'bayes-theorem']"
71,Pencil and paper example of fitting normal distribution to data with MCMC,Pencil and paper example of fitting normal distribution to data with MCMC,,"I've been trying to understand Markov Chain Monte Carlo methods for a while and even though I somewhat get the idea, when it comes to me applying MCMC, I'm not sure what I should do. Many times I've gotten the answer ""use a package"" from professors, but I don't want to use a package, I want to do it myself so I can understand! ;) I've been trying to search internet for good examples but so far I have found none such example which explicitly shows step by step what is happening under the hood. Many examples which I've looked deal with kinda abstract examples which are difficult to fully grasp. In many of the examples what I'm left with is: ""Okay very nice method, now I want to write a MCMC program myself which fits e.g. normal distribution to data"". The problem is, I cannot program abstract concepts, I need a concrete example. Some examples I've found get lost in the details of the domain problem and forget to explain the MCMC method itself. So my question is: Can you provide me with a very simple pencil and paper example? This could be e.g. a problem where you have three data points, say $(4,5), (3,3)$ and $(4,2)$ in the xy-plane and you need to fit this data to normal distribution. Lets also assume that for some reason we need to apply MCMC for this problem (Metropolis-Hastings would be nice). Show me detailed steps of how you do this, taking the derivatives, equating to zero, choosing the proposal distribution, taking a random sample from posterior (if you use Bayesian method) et cetera. Do this like one or two iterations, just to show everybody how the calculations proceed. I think this example would provide valuable info for beginners in MCMC methods. Thank you! "" I hear and I forget. I see and I remember. I do and I understand. "" Confucius","I've been trying to understand Markov Chain Monte Carlo methods for a while and even though I somewhat get the idea, when it comes to me applying MCMC, I'm not sure what I should do. Many times I've gotten the answer ""use a package"" from professors, but I don't want to use a package, I want to do it myself so I can understand! ;) I've been trying to search internet for good examples but so far I have found none such example which explicitly shows step by step what is happening under the hood. Many examples which I've looked deal with kinda abstract examples which are difficult to fully grasp. In many of the examples what I'm left with is: ""Okay very nice method, now I want to write a MCMC program myself which fits e.g. normal distribution to data"". The problem is, I cannot program abstract concepts, I need a concrete example. Some examples I've found get lost in the details of the domain problem and forget to explain the MCMC method itself. So my question is: Can you provide me with a very simple pencil and paper example? This could be e.g. a problem where you have three data points, say and in the xy-plane and you need to fit this data to normal distribution. Lets also assume that for some reason we need to apply MCMC for this problem (Metropolis-Hastings would be nice). Show me detailed steps of how you do this, taking the derivatives, equating to zero, choosing the proposal distribution, taking a random sample from posterior (if you use Bayesian method) et cetera. Do this like one or two iterations, just to show everybody how the calculations proceed. I think this example would provide valuable info for beginners in MCMC methods. Thank you! "" I hear and I forget. I see and I remember. I do and I understand. "" Confucius","(4,5), (3,3) (4,2)","['statistics', 'normal-distribution', 'markov-chains', 'monte-carlo']"
72,Binomial distribution $n \rightarrow \infty$,Binomial distribution,n \rightarrow \infty,"Which is the value of $$ \lim_{n\rightarrow \infty} \sum_{x=0}^{x=n/2} \varepsilon^{2x}(1-\varepsilon)^{n-2x} \frac{n!}{(2x)!(n-(2x))!} $$ i.e the limit of the Binomial distribution summed over all even values of an also even $n$ ($0, 2, 4,\ldots$)? I suppose that it should give $1/2$. Can someone tell me if it is true?","Which is the value of $$ \lim_{n\rightarrow \infty} \sum_{x=0}^{x=n/2} \varepsilon^{2x}(1-\varepsilon)^{n-2x} \frac{n!}{(2x)!(n-(2x))!} $$ i.e the limit of the Binomial distribution summed over all even values of an also even $n$ ($0, 2, 4,\ldots$)? I suppose that it should give $1/2$. Can someone tell me if it is true?",,"['statistics', 'probability-distributions', 'binomial-distribution']"
73,Choosing stratification variable for stratified sampling,Choosing stratification variable for stratified sampling,,"In general, how do you choose which variable to stratify your sample over? More specifically, what should the proportions look like on the variable your stratifying over? For example, I have data that I can stratify based on either age (15-90 years old), race, sex, or marital status. With this data, I am trying to estimate total income for the population. When I stratify over race, I get > stratsizes = table(ipums_data$Race) > prop.table(stratsizes)           1           2           3           4           5  0.863919493 0.109874488 0.006079198 0.016572829 0.003553993 where the numbers 1 through 5 represent different races. When I stratify over marital status, I get > stratsizes = table(ipums_data$Marstat) > prop.table(stratsizes)          1          2          3          4          5  0.58285479 0.02218440 0.06168983 0.07685977 0.25641122 where again, the numbers 1 through 5 represent the different marital statuses. Stratifying through age gives an pretty even proportion through all the ages 15-90, and stratifying with sex gives a 50-50 proportion What variable would be the best to stratify over, and why?","In general, how do you choose which variable to stratify your sample over? More specifically, what should the proportions look like on the variable your stratifying over? For example, I have data that I can stratify based on either age (15-90 years old), race, sex, or marital status. With this data, I am trying to estimate total income for the population. When I stratify over race, I get > stratsizes = table(ipums_data$Race) > prop.table(stratsizes)           1           2           3           4           5  0.863919493 0.109874488 0.006079198 0.016572829 0.003553993 where the numbers 1 through 5 represent different races. When I stratify over marital status, I get > stratsizes = table(ipums_data$Marstat) > prop.table(stratsizes)          1          2          3          4          5  0.58285479 0.02218440 0.06168983 0.07685977 0.25641122 where again, the numbers 1 through 5 represent the different marital statuses. Stratifying through age gives an pretty even proportion through all the ages 15-90, and stratifying with sex gives a 50-50 proportion What variable would be the best to stratify over, and why?",,"['statistics', 'sampling']"
74,Definition of significant figures,Definition of significant figures,,"Normally when we are taught how to add numbers with regards to significant figures, we are told to round the result to the rightmost place of the least precise digit. $3.55 + 4 = 7.55$, for example, would be rounded off to $8$. But for my argument I will be considering the addition of two numbers $9$ and $2$, both of which are significant to the ones digit. Following the usual rule for addition, $9 + 2 = 11$ and now we have two significant figures. However, whenever I think about significant figures I would intuitively think of these two definitions: 1 - Digits to the right of the last significant digit, can be any number   between 0 and 9. 2 - Any digit that has the possibility of being more than one numerical   value, is not a significant digit. Using the first definition, we can put $9$ and $2$ in these forms: $9.A$ $2.B$ where $A$ and $B$ are arbitrary digits ranging from $0$ to $9$. Thus, when we add these two numbers, we would end up with: $$9.A + 2.B$$ $$= 9 + 2 + 0.A + 0.B$$ $$= 11 + 0.A + 0.B$$ Finally when we assign some meaningful values to $A$ and $B$ such as $(A , B) = (0 , 0)$ or $(A , B) = (9 , 9)$, we can observe something very interesting: For $(A , B) = (0 , 0)$: $$11 + 0.0 + 0.0 = 11$$ For $(A , B) = (9 , 9)$: $$11 + 0.9 + 0.9 = 12.8$$ In the set of all possible numbers that can result from adding $9.A$ and $2.B$, both of which are significant to the ones digit, the minimum happens to be $11$ and the maximum happens to be $12.8$ (the set becomes even greater if we add more uncertain digits to the right of $A$ and $B$, and in that case the maximum resulting value starts to approach $13$ as you add more and more 9's to both $9$ and $2$). Lastly, we can see that tens digit is always $1$, and using my second definition of significant digits, we can claim that the tens digit is significant. On the other hand, because ones digit can either be $1$ or $2$, the ones digit is not significant. Thus, using my two definitions of significant figures, we can claim that the addition between $9$ and $2$ results in one significant figure (at the tens place), rather than two significant figures one would get from the usual rule of thumb. So my question is, are my definitions of significant digits correct? If yes, then I can say the general rules of thumb for adding numbers with significant figures is wrong and is being blindly taught and learned in high schools and universities. If not, then can you show me why not and if you have any credible sources.","Normally when we are taught how to add numbers with regards to significant figures, we are told to round the result to the rightmost place of the least precise digit. $3.55 + 4 = 7.55$, for example, would be rounded off to $8$. But for my argument I will be considering the addition of two numbers $9$ and $2$, both of which are significant to the ones digit. Following the usual rule for addition, $9 + 2 = 11$ and now we have two significant figures. However, whenever I think about significant figures I would intuitively think of these two definitions: 1 - Digits to the right of the last significant digit, can be any number   between 0 and 9. 2 - Any digit that has the possibility of being more than one numerical   value, is not a significant digit. Using the first definition, we can put $9$ and $2$ in these forms: $9.A$ $2.B$ where $A$ and $B$ are arbitrary digits ranging from $0$ to $9$. Thus, when we add these two numbers, we would end up with: $$9.A + 2.B$$ $$= 9 + 2 + 0.A + 0.B$$ $$= 11 + 0.A + 0.B$$ Finally when we assign some meaningful values to $A$ and $B$ such as $(A , B) = (0 , 0)$ or $(A , B) = (9 , 9)$, we can observe something very interesting: For $(A , B) = (0 , 0)$: $$11 + 0.0 + 0.0 = 11$$ For $(A , B) = (9 , 9)$: $$11 + 0.9 + 0.9 = 12.8$$ In the set of all possible numbers that can result from adding $9.A$ and $2.B$, both of which are significant to the ones digit, the minimum happens to be $11$ and the maximum happens to be $12.8$ (the set becomes even greater if we add more uncertain digits to the right of $A$ and $B$, and in that case the maximum resulting value starts to approach $13$ as you add more and more 9's to both $9$ and $2$). Lastly, we can see that tens digit is always $1$, and using my second definition of significant digits, we can claim that the tens digit is significant. On the other hand, because ones digit can either be $1$ or $2$, the ones digit is not significant. Thus, using my two definitions of significant figures, we can claim that the addition between $9$ and $2$ results in one significant figure (at the tens place), rather than two significant figures one would get from the usual rule of thumb. So my question is, are my definitions of significant digits correct? If yes, then I can say the general rules of thumb for adding numbers with significant figures is wrong and is being blindly taught and learned in high schools and universities. If not, then can you show me why not and if you have any credible sources.",,"['statistics', 'arithmetic', 'experimental-mathematics']"
75,intuition behind having a unique regression line,intuition behind having a unique regression line,,"I understand this mathematically. we have function of 2 variables represents the sum of square errors. We have to find the $a$ and $b$ that minimize the function. there is only one minimum point. But when I think of it, I can't see why 2 different lines would not bring the value to the same minimum. we have 2 degrees of freedom, so why can't we find a new pair of $(a,b)$ that will have the same value.","I understand this mathematically. we have function of 2 variables represents the sum of square errors. We have to find the $a$ and $b$ that minimize the function. there is only one minimum point. But when I think of it, I can't see why 2 different lines would not bring the value to the same minimum. we have 2 degrees of freedom, so why can't we find a new pair of $(a,b)$ that will have the same value.",,"['statistics', 'regression', 'linear-regression']"
76,Two-sample permutation tests for earthquake magnitudes before and after a damaging quake,Two-sample permutation tests for earthquake magnitudes before and after a damaging quake,,"Background and data. An earthquake of magnitude 5.17 stuck near Yountville, California in the early morning hours of  September  9, 2000, injuring about 25 people and doing about $50 million damage. The magnitudes of 24 smaller earthquakes nearby are given in the vector Mag below. The first 12 occurred within the few hours before the big quake and the last 12 occurred within a few hours after. The issue  is whether the Before and After quakes differ significantly from each other in magnitude. Mag=c(1.00, 1.14, 1.05, 1.79, 1.64, 2.76,  1.42, 1.30, 1.14, 0.96, 1.62, 1.40,        2.06, 1.64, 1.87, 1.41, 1.18, 1.59,  0.95, 1.54, 2.00, 1.16, 0.93, 1.90) The two boxplots below show magnitudes of these two groups of earthquakes. Within the boxes, vertical lines show the sample medians and dots show their sample means. The outlier at 2.76 among those before the main quake might be called a foreshock. The quakes that occurred after the main one include some mild aftershocks. Traditional tests may be inappropriate. We wish to test $H_0: \mu_B = \mu_A$ against $H_a: \mu_B \ne \mu_A.$ Because the general population of California earthquake magnitudes is known to be distinctly right-skewed and our samples are small, one may be reluctant to use a two-sample t test to determine whether the two population means differ. (This test, which assumes normal data, gives the p-value 0.66, indicating no significant difference.) Ordinarily, the substitute would be a Mann-Whitney-Wilcoxon nonparmatric rank sum test, which tests whether population medians are equal. However, tied magnitudes (with values 1.14 and 1.64) would require adjustments in order test whether the population medians are equal (it shows an approximate p-value of 0.42). (And there are other quibbles with the applicability of the MWW test.) By contrast, there are no problematic assumptions for permutation tests. Our purpose here is use appropriate $permutation\: tests$ to see whether the Before and After populations differ, and to compare the results of permutation tests with those for the t and MWW tests.","Background and data. An earthquake of magnitude 5.17 stuck near Yountville, California in the early morning hours of  September  9, 2000, injuring about 25 people and doing about $50 million damage. The magnitudes of 24 smaller earthquakes nearby are given in the vector Mag below. The first 12 occurred within the few hours before the big quake and the last 12 occurred within a few hours after. The issue  is whether the Before and After quakes differ significantly from each other in magnitude. Mag=c(1.00, 1.14, 1.05, 1.79, 1.64, 2.76,  1.42, 1.30, 1.14, 0.96, 1.62, 1.40,        2.06, 1.64, 1.87, 1.41, 1.18, 1.59,  0.95, 1.54, 2.00, 1.16, 0.93, 1.90) The two boxplots below show magnitudes of these two groups of earthquakes. Within the boxes, vertical lines show the sample medians and dots show their sample means. The outlier at 2.76 among those before the main quake might be called a foreshock. The quakes that occurred after the main one include some mild aftershocks. Traditional tests may be inappropriate. We wish to test $H_0: \mu_B = \mu_A$ against $H_a: \mu_B \ne \mu_A.$ Because the general population of California earthquake magnitudes is known to be distinctly right-skewed and our samples are small, one may be reluctant to use a two-sample t test to determine whether the two population means differ. (This test, which assumes normal data, gives the p-value 0.66, indicating no significant difference.) Ordinarily, the substitute would be a Mann-Whitney-Wilcoxon nonparmatric rank sum test, which tests whether population medians are equal. However, tied magnitudes (with values 1.14 and 1.64) would require adjustments in order test whether the population medians are equal (it shows an approximate p-value of 0.42). (And there are other quibbles with the applicability of the MWW test.) By contrast, there are no problematic assumptions for permutation tests. Our purpose here is use appropriate $permutation\: tests$ to see whether the Before and After populations differ, and to compare the results of permutation tests with those for the t and MWW tests.",,"['statistics', 'statistical-inference']"
77,Interpretation of PCA,Interpretation of PCA,,"I am wondering if there is a practical interpretation of a principal component analysis: Consider you have a data matrix $X\in\mathbb{R}^{N\times p}$ and you perform a principal component analysis where you typically receive certain directions $v_1,...,v_q$, $q<p$, in $\mathbb{R}^N$ that explain the most of the variance in the data. Is there an interpretation of these principal components in terms of the original components, i.e. the variables $x_1,...,x_p$ that constitute the model. Think e.g. of $x_i$ being certain ""variables"" of a human body such as weight, blood pressure etc. that should be used to predict expected life time. If one now performs a PCA as described a above, one recognizes that certain linear combinations of the columns of $X$ explain most of the variance. If one wants to reduce the model (i.e. reduce the $p$), which variables do you exclude given the information of the PCA?","I am wondering if there is a practical interpretation of a principal component analysis: Consider you have a data matrix $X\in\mathbb{R}^{N\times p}$ and you perform a principal component analysis where you typically receive certain directions $v_1,...,v_q$, $q<p$, in $\mathbb{R}^N$ that explain the most of the variance in the data. Is there an interpretation of these principal components in terms of the original components, i.e. the variables $x_1,...,x_p$ that constitute the model. Think e.g. of $x_i$ being certain ""variables"" of a human body such as weight, blood pressure etc. that should be used to predict expected life time. If one now performs a PCA as described a above, one recognizes that certain linear combinations of the columns of $X$ explain most of the variance. If one wants to reduce the model (i.e. reduce the $p$), which variables do you exclude given the information of the PCA?",,"['statistics', 'regression', 'regression-analysis', 'principal-component-analysis']"
78,What's the probability of a future polling result falling in a given range?,What's the probability of a future polling result falling in a given range?,,"Question Each day, Gallup polls U.S. Employee Engagement. You can see 7-day rolling averages of the daily numbers here . Assume you have a set of historical daily numbers (ie, [0.354827, 0.352648, 0.34943, …] ). What would be the best technique to estimate the probability of a future number falling in a given range? As an example, I may want to say ""the probability of the number three days from now falling in the range 0.45…1 is ____%."" Initial Attempt My initial attempt counted the # of times this range condition had been met in the last 90 days, but this has a number of flaws. Most notably, the ranges 0…0.01 and 0…0.15 were equally unlikely, but obviously the former should be less likely than the latter. That is, my initial attempt didn't consider that the results tend to hover around 0.30…0.33 . Related Questions I read Continuously sampled event: Estimating the value of a future data point, based on past measurements and their tendency . The question seemed related, but not identical, and the answer was over my head. I started reading about ARIMA models , but I didn't want to get too far into the weeds without knowing if that's the right approach here.","Question Each day, Gallup polls U.S. Employee Engagement. You can see 7-day rolling averages of the daily numbers here . Assume you have a set of historical daily numbers (ie, [0.354827, 0.352648, 0.34943, …] ). What would be the best technique to estimate the probability of a future number falling in a given range? As an example, I may want to say ""the probability of the number three days from now falling in the range 0.45…1 is ____%."" Initial Attempt My initial attempt counted the # of times this range condition had been met in the last 90 days, but this has a number of flaws. Most notably, the ranges 0…0.01 and 0…0.15 were equally unlikely, but obviously the former should be less likely than the latter. That is, my initial attempt didn't consider that the results tend to hover around 0.30…0.33 . Related Questions I read Continuously sampled event: Estimating the value of a future data point, based on past measurements and their tendency . The question seemed related, but not identical, and the answer was over my head. I started reading about ARIMA models , but I didn't want to get too far into the weeds without knowing if that's the right approach here.",,['statistics']
79,Why do polynomial regressions have larger variance at the end?,Why do polynomial regressions have larger variance at the end?,,"In reading the book ""An Introduction to Statistical Learning with Applications in R"", I came across this graph: It shows that the point-wise variance is larger at the ends of the regression curve. Why is that? I thought that the variance may be larger because there seem to be fewer data points near the end, but the variance is calculated on the coefficients so the number of data points used in the estimate has no impact. Then I thought that the variance is larger because the X values are larger, but the graph on the left side shows slight increases in variance on both sides (even when X is small). In general, I have read that polynomials have notorious end behaviours - what causes this? Thanks.","In reading the book ""An Introduction to Statistical Learning with Applications in R"", I came across this graph: It shows that the point-wise variance is larger at the ends of the regression curve. Why is that? I thought that the variance may be larger because there seem to be fewer data points near the end, but the variance is calculated on the coefficients so the number of data points used in the estimate has no impact. Then I thought that the variance is larger because the X values are larger, but the graph on the left side shows slight increases in variance on both sides (even when X is small). In general, I have read that polynomials have notorious end behaviours - what causes this? Thanks.",,"['linear-algebra', 'statistics', 'polynomials', 'regression', 'covariance']"
80,Is tossing a die in 10 consequent days an ergodic process?,Is tossing a die in 10 consequent days an ergodic process?,,"IT maybe an elementary question but I'm totally new to the concept. In Wikipedia , ergodicity is defined as follows: In statistics, the term describes a random process for which the time   average of one sequence of events is the same as the ensemble average. Suppose that we have thrown a die one time in 10 consequent days and gotten these results: $\{5,5,1,5,4,1,2,3,5,5\}$ If we consider $(X_i)_{1\le i\le10}$ the random process for this experiment, in the $i$th day we have 6 possible values for random variable $X_i$ each with probablilty $\frac{1}{6}$ so:  $$ensemble\;average=\frac{1+2+3+4+5+6}{6}=\frac{21}{6}=3.5$$ but for temporal average base on this single realization we have:$$temporal\;average=\frac{36}{10}=3.6$$  so tossing a die for 10 subsequent days is not an ergodic random process. But if $number\;of\;days\to\infty$ then $temporal\;average\to 3.5$ so tossing a die for an infinite subsequent days is an ergodic process. 1-Is my conclusion true? 2-Is my understanding for ensemble average , temporal average and ergodicity right? If yes give me an example of an ergodic and a nonergodic continuous random processes and Compute their ensemble and temporal averages? If no tell me how should I compute ensemble and temporal averages? should I consider all $6^{10}$ possible realizations when computing temporal average?","IT maybe an elementary question but I'm totally new to the concept. In Wikipedia , ergodicity is defined as follows: In statistics, the term describes a random process for which the time   average of one sequence of events is the same as the ensemble average. Suppose that we have thrown a die one time in 10 consequent days and gotten these results: $\{5,5,1,5,4,1,2,3,5,5\}$ If we consider $(X_i)_{1\le i\le10}$ the random process for this experiment, in the $i$th day we have 6 possible values for random variable $X_i$ each with probablilty $\frac{1}{6}$ so:  $$ensemble\;average=\frac{1+2+3+4+5+6}{6}=\frac{21}{6}=3.5$$ but for temporal average base on this single realization we have:$$temporal\;average=\frac{36}{10}=3.6$$  so tossing a die for 10 subsequent days is not an ergodic random process. But if $number\;of\;days\to\infty$ then $temporal\;average\to 3.5$ so tossing a die for an infinite subsequent days is an ergodic process. 1-Is my conclusion true? 2-Is my understanding for ensemble average , temporal average and ergodicity right? If yes give me an example of an ergodic and a nonergodic continuous random processes and Compute their ensemble and temporal averages? If no tell me how should I compute ensemble and temporal averages? should I consider all $6^{10}$ possible realizations when computing temporal average?",,"['statistics', 'stochastic-processes', 'random-variables', 'intuition', 'average']"
81,Same Expected Value but different variances. Is $E[U(X)] \ge E[U(Y)]$?,Same Expected Value but different variances. Is ?,E[U(X)] \ge E[U(Y)],"Let $U: \mathbb R -> \mathbb R$ be a concave function, and let $X$ be a random variable with a normal distribution, expected value $\mu$, and standard deviation $\sigma$. Let $\lambda \gt 1$, and let $Y$ be a random variable with a normal distribution, expected value $\mu$, and standard deviation $\mu \sigma$. (a)Prove that $U(\mu + c) + U(\mu-c) \ge U(\mu + c\sqrt{\lambda}) + U(\mu - c\sqrt{\lambda})$ for all $c \gt 0$ (b) By changing appropriate varible, and using a), prove that $E[U(X)] \ge E[U(Y)]$ I can only know Jensen's inequality which is $U[E(X)] \ge E[U(X)]$. I have no idea how to prove a) and b). Can you please help me? I have forgone statistics for a long time so I greatly appreciate for your help. Thanks.","Let $U: \mathbb R -> \mathbb R$ be a concave function, and let $X$ be a random variable with a normal distribution, expected value $\mu$, and standard deviation $\sigma$. Let $\lambda \gt 1$, and let $Y$ be a random variable with a normal distribution, expected value $\mu$, and standard deviation $\mu \sigma$. (a)Prove that $U(\mu + c) + U(\mu-c) \ge U(\mu + c\sqrt{\lambda}) + U(\mu - c\sqrt{\lambda})$ for all $c \gt 0$ (b) By changing appropriate varible, and using a), prove that $E[U(X)] \ge E[U(Y)]$ I can only know Jensen's inequality which is $U[E(X)] \ge E[U(X)]$. I have no idea how to prove a) and b). Can you please help me? I have forgone statistics for a long time so I greatly appreciate for your help. Thanks.",,"['statistics', 'statistical-inference', 'economics']"
82,Deriving the variance of a binomial distribution,Deriving the variance of a binomial distribution,,"I know that the variance of a binomial distribution is the number of trials multiplied by the variance of each trial, but I'm not seeing the derivation of this. Here's my logic so far: For each trial ($x$), $p$ = probability of success (1), and $1-p$ = probability of failure (0): $$E(x) = 1\cdot p+0\cdot(1-p) = p$$ $$E(x^2) = 1^2\cdot p+0^2\cdot(1-p) = p$$ $$Var(x) = E(x^2)-E(x)^2 = p - p^2 = p(1-p)$$ From here, for any combination of trials ($X$): $$X = x_1 + x_2 + \cdots + x_n$$ $$E(X) = E(x_1) + E(x_2) + \cdots + E(x_n)$$ $$E(X) = np$$ $$E(X^2) = E(x_1^2) + E(x_2^2) + \cdots + E(x_n^2)$$ $$E(X^2) = np$$ By this, the logic indicates the variance would be: $$Var(X) = E(X^2) - E(X)^2 = np - (np)^2 = np(1-np)$$ ...however, this is not correct, since the variance is as follows: $$Var(X) = Var(x_1) + Var(x_2) + \cdots + Var(x_n)$$ $$Var(X) = p(1-p) + p(1-p) + \cdots + p(1-p)$$ $$Var(X) = np(1-p)$$ I'm not seeing in my derivation where I'm missing the mark mathematically, and resulting in the incorrect ""n"" in the parentheses.","I know that the variance of a binomial distribution is the number of trials multiplied by the variance of each trial, but I'm not seeing the derivation of this. Here's my logic so far: For each trial ($x$), $p$ = probability of success (1), and $1-p$ = probability of failure (0): $$E(x) = 1\cdot p+0\cdot(1-p) = p$$ $$E(x^2) = 1^2\cdot p+0^2\cdot(1-p) = p$$ $$Var(x) = E(x^2)-E(x)^2 = p - p^2 = p(1-p)$$ From here, for any combination of trials ($X$): $$X = x_1 + x_2 + \cdots + x_n$$ $$E(X) = E(x_1) + E(x_2) + \cdots + E(x_n)$$ $$E(X) = np$$ $$E(X^2) = E(x_1^2) + E(x_2^2) + \cdots + E(x_n^2)$$ $$E(X^2) = np$$ By this, the logic indicates the variance would be: $$Var(X) = E(X^2) - E(X)^2 = np - (np)^2 = np(1-np)$$ ...however, this is not correct, since the variance is as follows: $$Var(X) = Var(x_1) + Var(x_2) + \cdots + Var(x_n)$$ $$Var(X) = p(1-p) + p(1-p) + \cdots + p(1-p)$$ $$Var(X) = np(1-p)$$ I'm not seeing in my derivation where I'm missing the mark mathematically, and resulting in the incorrect ""n"" in the parentheses.",,"['statistics', 'expectation', 'binomial-theorem']"
83,"The autocovariance function of ARMA(1,1)","The autocovariance function of ARMA(1,1)",,"So I am reading Brockwell and Davis introduction to Time Series analysis on page 89 where he derives the ACVF of an $ARMA(1,1)$ given by: $X_t - \phi X_{t-1}=Z_t+\theta Z_{t-1}$ with ${Z_t}$ is $WN(0,\sigma^2)$ and $\mid \phi \mid < 1$ What is first told is that by causality assumption, the autocovariance at lag $h$ is: $\gamma(h)=\sigma^2\sum_{j=0}^\infty\psi_j \psi_{j+\mid h \mid}$ So this at lag $h = 0$ is becomes: $\gamma (0) = \sigma^2 \sum_{j=0}^\infty \psi_j^2$ How can this then be shown that $\sigma^2 \sum_{j=0}^\infty \psi_j^2 = \sigma^2 \Big[ 1 + \frac{(\theta+\phi)^2}{1-\phi^2} \Big]$ ? And in the same way for $\gamma(1) = \sigma^2 \Big[ \theta + \phi + \frac{(\theta+\phi)^2\phi}{1-\phi^2} \Big]$? I know that there is a definition of the function $\psi (z) = \sum_{j=0}^\infty\psi_j z^j = \frac{\theta(z)}{\phi(z)}$, $\mid z \mid\leq 1$. In what can this be applied here?","So I am reading Brockwell and Davis introduction to Time Series analysis on page 89 where he derives the ACVF of an $ARMA(1,1)$ given by: $X_t - \phi X_{t-1}=Z_t+\theta Z_{t-1}$ with ${Z_t}$ is $WN(0,\sigma^2)$ and $\mid \phi \mid < 1$ What is first told is that by causality assumption, the autocovariance at lag $h$ is: $\gamma(h)=\sigma^2\sum_{j=0}^\infty\psi_j \psi_{j+\mid h \mid}$ So this at lag $h = 0$ is becomes: $\gamma (0) = \sigma^2 \sum_{j=0}^\infty \psi_j^2$ How can this then be shown that $\sigma^2 \sum_{j=0}^\infty \psi_j^2 = \sigma^2 \Big[ 1 + \frac{(\theta+\phi)^2}{1-\phi^2} \Big]$ ? And in the same way for $\gamma(1) = \sigma^2 \Big[ \theta + \phi + \frac{(\theta+\phi)^2\phi}{1-\phi^2} \Big]$? I know that there is a definition of the function $\psi (z) = \sum_{j=0}^\infty\psi_j z^j = \frac{\theta(z)}{\phi(z)}$, $\mid z \mid\leq 1$. In what can this be applied here?",,"['statistics', 'summation', 'power-series', 'covariance', 'time-series']"
84,Moment generating function of Random Sums,Moment generating function of Random Sums,,"I am unsure of a particular step in the supplied solution of this problem. Problem: We are given $X_{i}$, for i = 1,..., n, is a sequence of iid Geometric Random Variables. N ~ Geometric(p), and N is independent of all the $X_{i}$'s $S_{N} = \sum^{N}_{i=1}Xi$. What is the MGF of $S_{N}$? My working: Let $Y = S_{N}$ Know that $M_{X}(t) = \frac{pe^{t}}{1-qe^{t}}$ (from an earlier part of this problem). So the conditional MGF of the random sum is $M_{Y|N}(t|N) = [M_{X}(t)]^{N} = [\frac{pe^{t}}{1-qe^{t}}]^{N}$ Next, MGF of Y, $M_{Y}(t) = E[M_{Y|N}(t|N)] = E[(\frac{pe^{t}}{1-qe^{t}})^{N}]$ I am able to show up till this part, so everything above is fine. The next step is to perform this: $E[(\frac{pe^{t}}{1-qe^{t}})^{N}] = \frac{p.\frac{pe^{t}}{1-qe^{t}}}{1-q.\frac{pe^{t}}{1-qe^{t}}} $ I don't understand  why the expression for the denominator takes that form if we are bringing it up by power of N. Can someone kindly explain the reasoning for it please?","I am unsure of a particular step in the supplied solution of this problem. Problem: We are given $X_{i}$, for i = 1,..., n, is a sequence of iid Geometric Random Variables. N ~ Geometric(p), and N is independent of all the $X_{i}$'s $S_{N} = \sum^{N}_{i=1}Xi$. What is the MGF of $S_{N}$? My working: Let $Y = S_{N}$ Know that $M_{X}(t) = \frac{pe^{t}}{1-qe^{t}}$ (from an earlier part of this problem). So the conditional MGF of the random sum is $M_{Y|N}(t|N) = [M_{X}(t)]^{N} = [\frac{pe^{t}}{1-qe^{t}}]^{N}$ Next, MGF of Y, $M_{Y}(t) = E[M_{Y|N}(t|N)] = E[(\frac{pe^{t}}{1-qe^{t}})^{N}]$ I am able to show up till this part, so everything above is fine. The next step is to perform this: $E[(\frac{pe^{t}}{1-qe^{t}})^{N}] = \frac{p.\frac{pe^{t}}{1-qe^{t}}}{1-q.\frac{pe^{t}}{1-qe^{t}}} $ I don't understand  why the expression for the denominator takes that form if we are bringing it up by power of N. Can someone kindly explain the reasoning for it please?",,"['statistics', 'random-variables', 'moment-generating-functions']"
85,Confusion about Notation for Bayesian Statistics,Confusion about Notation for Bayesian Statistics,,"I'm currently trying to learn Bayesian Statistics but I keep losing time trying to figure out what exactly is meant by notation.  Could someone answer the following for me? Let's say $X \sim N(\mu,\sigma^2)$ (1) I'm trying to calculate a posterior distribution $p(\mu\mid X) \propto p(X\mid\mu)p(\mu)$.  So my understanding is that $p(\mu\mid X)$ is the probability distribution of the parameter $\mu$ given the data $X$.  What then does $p(\mu\mid X,\sigma^2)$ mean exactly?  My guess is that it is the probability distribution of the parameter $\mu$ given the data $X$ and assuming that $\sigma^2$ is fixed.  Is that correct? (2)  Following up from (1), for $p(\mu\mid X,\sigma^2)$, what does the posterior function transform into?  Is it $p(\mu\mid X,\sigma^2) \propto p(X\mid\mu,\sigma^2)p(\mu,\sigma^2)$?   If it is different, how does the likelihood function really change?  My understanding is that the likelihood function is based on the way the data are distributed and not the parameters conditioned on.  Is there a difference. (3)  Similar question regarding the prior.  If we are told that $p(\mu) \propto 1$, is there a difference between $p(\mu)$ and $p(\mu,\sigma^2)$? Any clarification would be greatly appreciated!","I'm currently trying to learn Bayesian Statistics but I keep losing time trying to figure out what exactly is meant by notation.  Could someone answer the following for me? Let's say $X \sim N(\mu,\sigma^2)$ (1) I'm trying to calculate a posterior distribution $p(\mu\mid X) \propto p(X\mid\mu)p(\mu)$.  So my understanding is that $p(\mu\mid X)$ is the probability distribution of the parameter $\mu$ given the data $X$.  What then does $p(\mu\mid X,\sigma^2)$ mean exactly?  My guess is that it is the probability distribution of the parameter $\mu$ given the data $X$ and assuming that $\sigma^2$ is fixed.  Is that correct? (2)  Following up from (1), for $p(\mu\mid X,\sigma^2)$, what does the posterior function transform into?  Is it $p(\mu\mid X,\sigma^2) \propto p(X\mid\mu,\sigma^2)p(\mu,\sigma^2)$?   If it is different, how does the likelihood function really change?  My understanding is that the likelihood function is based on the way the data are distributed and not the parameters conditioned on.  Is there a difference. (3)  Similar question regarding the prior.  If we are told that $p(\mu) \propto 1$, is there a difference between $p(\mu)$ and $p(\mu,\sigma^2)$? Any clarification would be greatly appreciated!",,"['statistics', 'notation', 'bayesian']"
86,Differentiating Integrals,Differentiating Integrals,,"This problem appears as example 2d of Chapter 5 in ""A First Course in Probability - Ross, 8th ed."" Suppose that if you are s minutes early for an appointment, then you incur the cost cs, and if you are s minutes late, then you incur the cost ks. Suppose also that the travel time from where you presently are to the location of your appointment is a continuous random variable having probability density function f . Determine the time at which you should depart if you want to minimize your expected cost. If we let X denote travel time, and you leave t minutes before your appointment, then your cost, $C_t(x)$ is given by: $C_t(x)$ = c(t - X) if X $\le$ t $C_t(x)$ = k(X - t) if X $\ge$ t Therefore, E[$C_t(x)$] = $\int_0^tC_t(x)f(x)dx$ = $\int_0^tc(t - x)f(x)dx$ + $\int_t^{\infty}k(x - t)f(x)dx$ = ct$\int_0^tf(x)dx$ - c$\int_0^txf(x)dx$ + k$\int_t^{\infty}xf(x)dx$ - kt$\int_t^{\infty}f(x)dx$ The value of t that minimizes E[$C_t(x)$] can be obtained by: $\frac{d}{dt}$E[$C_t(x)$] =  ct*f(t) + c*F(t) - ct*f(t) - kt*f(t) + kt*f(t) - k[1 - F(t)] = (k + c)F(t) - k Could someone please explain the steps involved in this differentiation?","This problem appears as example 2d of Chapter 5 in ""A First Course in Probability - Ross, 8th ed."" Suppose that if you are s minutes early for an appointment, then you incur the cost cs, and if you are s minutes late, then you incur the cost ks. Suppose also that the travel time from where you presently are to the location of your appointment is a continuous random variable having probability density function f . Determine the time at which you should depart if you want to minimize your expected cost. If we let X denote travel time, and you leave t minutes before your appointment, then your cost, $C_t(x)$ is given by: $C_t(x)$ = c(t - X) if X $\le$ t $C_t(x)$ = k(X - t) if X $\ge$ t Therefore, E[$C_t(x)$] = $\int_0^tC_t(x)f(x)dx$ = $\int_0^tc(t - x)f(x)dx$ + $\int_t^{\infty}k(x - t)f(x)dx$ = ct$\int_0^tf(x)dx$ - c$\int_0^txf(x)dx$ + k$\int_t^{\infty}xf(x)dx$ - kt$\int_t^{\infty}f(x)dx$ The value of t that minimizes E[$C_t(x)$] can be obtained by: $\frac{d}{dt}$E[$C_t(x)$] =  ct*f(t) + c*F(t) - ct*f(t) - kt*f(t) + kt*f(t) - k[1 - F(t)] = (k + c)F(t) - k Could someone please explain the steps involved in this differentiation?",,"['statistics', 'derivatives']"
87,Variance stabilization for Poisson data,Variance stabilization for Poisson data,,"Intro Let $Z > 0$ be a random variable with the mean and variance defined as $\mathbb{E}\{ Z \}$ and $\operatorname{Var}\{ Z \}$, respectively. The variance stabilization transform (VST) $f(z)$ turns heteroskedastic data $z$ to homoskedastic data $f(z)$ with constant variance, e.g., variance equals 1. Poisson distribution For Poisson distributed data with $\mathbb{E}\{ Z \} = \operatorname{Var}\{ Z \}=\lambda$ this VST, so-called Anscombe transformation, is given by [1,2]: $$f(z) = 2\sqrt{z + 3/8}$$ Based on the first order Taylor expansion we can write (this is called Delta method in the literature) [3]: $$\operatorname{Var}\{f(z)\} \approx  \left( \left.\frac{df}{dz}\right|_{z=\mathbb{E}\{ Z \}} \right)^2 \operatorname{Var}\{Z\} = \frac{\operatorname{Var}\{Z\}}{\mathbb{E}\{ Z \} + 3/8}$$ Problem I performed a Monte Carlo simulations to compare sample variance of the stabilized data $f(z)$ and the variance obtained by the above equation, i.e., $\operatorname{Var}\{f(z)\}$ both numerically as a sample variance and theoretically as follows: $$\operatorname{Var}\{f(z)\} \approx \frac{\lambda}{\lambda + 3/8}$$ Moreover, I went further and derived second order approximation for $Var\{f(z)\}$. There is a mismatch between variance of stabilized data $f(z)$ (green curve) and those obtained theoretically and numerically by means of the $\operatorname{Var}\{f(z)\}$. Can anyone explain me this inconsistency? Anscombe, F. J. (1948), ""The transformation of Poisson, binomial and negative-binomial data"", Biometrika 35 (3–4): 246–254, doi:10.1093/biomet/35.3-4.246, JSTOR 2332343 http://en.wikipedia.org/wiki/Anscombe_transform Kendall's Advanced Theory of Statistics: Volume 1: Distribution Theory by Alan Stuart and Keith Ord (Apr 20, 2009), page. 351, eq. 10.14","Intro Let $Z > 0$ be a random variable with the mean and variance defined as $\mathbb{E}\{ Z \}$ and $\operatorname{Var}\{ Z \}$, respectively. The variance stabilization transform (VST) $f(z)$ turns heteroskedastic data $z$ to homoskedastic data $f(z)$ with constant variance, e.g., variance equals 1. Poisson distribution For Poisson distributed data with $\mathbb{E}\{ Z \} = \operatorname{Var}\{ Z \}=\lambda$ this VST, so-called Anscombe transformation, is given by [1,2]: $$f(z) = 2\sqrt{z + 3/8}$$ Based on the first order Taylor expansion we can write (this is called Delta method in the literature) [3]: $$\operatorname{Var}\{f(z)\} \approx  \left( \left.\frac{df}{dz}\right|_{z=\mathbb{E}\{ Z \}} \right)^2 \operatorname{Var}\{Z\} = \frac{\operatorname{Var}\{Z\}}{\mathbb{E}\{ Z \} + 3/8}$$ Problem I performed a Monte Carlo simulations to compare sample variance of the stabilized data $f(z)$ and the variance obtained by the above equation, i.e., $\operatorname{Var}\{f(z)\}$ both numerically as a sample variance and theoretically as follows: $$\operatorname{Var}\{f(z)\} \approx \frac{\lambda}{\lambda + 3/8}$$ Moreover, I went further and derived second order approximation for $Var\{f(z)\}$. There is a mismatch between variance of stabilized data $f(z)$ (green curve) and those obtained theoretically and numerically by means of the $\operatorname{Var}\{f(z)\}$. Can anyone explain me this inconsistency? Anscombe, F. J. (1948), ""The transformation of Poisson, binomial and negative-binomial data"", Biometrika 35 (3–4): 246–254, doi:10.1093/biomet/35.3-4.246, JSTOR 2332343 http://en.wikipedia.org/wiki/Anscombe_transform Kendall's Advanced Theory of Statistics: Volume 1: Distribution Theory by Alan Stuart and Keith Ord (Apr 20, 2009), page. 351, eq. 10.14",,"['statistics', 'random-variables', 'transformation']"
88,Curse of Dimensionality ... as illustrated by Christopher Bishop,Curse of Dimensionality ... as illustrated by Christopher Bishop,,"I'm reading Christopher Bishop's book ""Neural Networks for Pattern Recognition"". I'm on pg 7 about curse of dimensionality.  Here is the relevant part: For simplicity assume the dimensionality we are working with is 3. Now ""divide the input variables $x_1, \dots x_d$ into M intervals, so that the value of a variable can be specified approximately by saying in which interval it lies. This leads to a division of the whole input space into a large number of [3D] boxes or cells ... Each of the training examples corresponds to a point in one of the cells , and carries an associated value of the output variable $y$. ... [To find $y$ for a given point], by finding which cell the point falls in, and then returning the average value of y for all training points that lie in that cell."" The claim is that if each input variable is divided into $M$ divisions, then the total number of cells is $M^d$. First and foremost, why is this true? Why do we need $M^d$ cells? Secondly, what does it mean to divide an input variable into intervals or divisions. (I assume an input variable is $x_i$ from $x_1, \dots, x_d$ for $1\leq i \leq d$.) I'm interested in making sure that I understand this because this seems (at least to me) a clever way of thinking about the curse of dimensionality.","I'm reading Christopher Bishop's book ""Neural Networks for Pattern Recognition"". I'm on pg 7 about curse of dimensionality.  Here is the relevant part: For simplicity assume the dimensionality we are working with is 3. Now ""divide the input variables $x_1, \dots x_d$ into M intervals, so that the value of a variable can be specified approximately by saying in which interval it lies. This leads to a division of the whole input space into a large number of [3D] boxes or cells ... Each of the training examples corresponds to a point in one of the cells , and carries an associated value of the output variable $y$. ... [To find $y$ for a given point], by finding which cell the point falls in, and then returning the average value of y for all training points that lie in that cell."" The claim is that if each input variable is divided into $M$ divisions, then the total number of cells is $M^d$. First and foremost, why is this true? Why do we need $M^d$ cells? Secondly, what does it mean to divide an input variable into intervals or divisions. (I assume an input variable is $x_i$ from $x_1, \dots, x_d$ for $1\leq i \leq d$.) I'm interested in making sure that I understand this because this seems (at least to me) a clever way of thinking about the curse of dimensionality.",,"['statistics', 'machine-learning']"
89,"Determine whether ARMA(p,q) is stationary and/or invertible?","Determine whether ARMA(p,q) is stationary and/or invertible?",,"Determine whether an ARMA(p,q) process is stationary and invertible   such that $y_t = \sum_{i=1}^{p} \phi_i y_{t-i} + \sum_{i=1}^{p} \theta_{i} \epsilon_{t-i}$ with the restriction that $\theta_{0} = 1$ I'm not familiar with determining this, here's my best shot using the knowledge I have: Set lag operators: $\epsilon_{t-i} = L_1^i \epsilon_{t}$, and $y_{t-i} = L^{i}_{2} y_{t}$ $y_t - y_t \sum_{i=1}^{p} \phi_i L_1^i = y_t(1 - \sum_{i=1}^{p} \phi_i L_1^i) = \epsilon_{t} \sum_{i=1}^{p} \theta_{i} L_2^i$ I am guessing that this is stationary, because the roots of $1 - \sum_{i=1}^{p} \phi_i L_1^i$ can be outside unit circle. What about $\sum_{i=1}^{p} \theta_{i} L_2^i$ ? Does that mean it's invertible? I would guess and say yes, because if $\sum_{i=1}^{p} \theta_i$ is less than zero then the roots should lie outside of the unit circle as well. Is this correct? It would also be nice to have more information about this in general - does anyone know of a resource that goes over determining whether a ARMA/AR/MA process is stationary or invertible?","Determine whether an ARMA(p,q) process is stationary and invertible   such that $y_t = \sum_{i=1}^{p} \phi_i y_{t-i} + \sum_{i=1}^{p} \theta_{i} \epsilon_{t-i}$ with the restriction that $\theta_{0} = 1$ I'm not familiar with determining this, here's my best shot using the knowledge I have: Set lag operators: $\epsilon_{t-i} = L_1^i \epsilon_{t}$, and $y_{t-i} = L^{i}_{2} y_{t}$ $y_t - y_t \sum_{i=1}^{p} \phi_i L_1^i = y_t(1 - \sum_{i=1}^{p} \phi_i L_1^i) = \epsilon_{t} \sum_{i=1}^{p} \theta_{i} L_2^i$ I am guessing that this is stationary, because the roots of $1 - \sum_{i=1}^{p} \phi_i L_1^i$ can be outside unit circle. What about $\sum_{i=1}^{p} \theta_{i} L_2^i$ ? Does that mean it's invertible? I would guess and say yes, because if $\sum_{i=1}^{p} \theta_i$ is less than zero then the roots should lie outside of the unit circle as well. Is this correct? It would also be nice to have more information about this in general - does anyone know of a resource that goes over determining whether a ARMA/AR/MA process is stationary or invertible?",,"['statistics', 'regression', 'stationary-processes']"
90,Joint Moment Generating Function Help,Joint Moment Generating Function Help,,"I've been working on this problem for a while and need some direction. $$ f(x,y) = \left\{ \begin{array}{lr} \frac{1}{\sqrt{2\pi}} e^{-x} e^{-\frac{(y-x)^2}{2}}  &  x \geq 0, -\infty < y < \infty, \\ 0&\mbox{otherwise}\ \end{array} \right. $$ Calculate the joint moment generating function. My textbook hasn't been much help, but I believe the route that I should be taking involves this calculation: $$ M_{X,Y} (t_1, t_2) = E[\exp(t_1X+t_2Y)] $$ $$...$$ $$ = E_X(\exp(t_1X)E[\exp(t_2Y)|X]) $$ After some research I've found that it relates to the ""erf"" function, but this was not discussed in class or in the textbook thus I believe that a different approach is required. Thanks for your help.","I've been working on this problem for a while and need some direction. $$ f(x,y) = \left\{ \begin{array}{lr} \frac{1}{\sqrt{2\pi}} e^{-x} e^{-\frac{(y-x)^2}{2}}  &  x \geq 0, -\infty < y < \infty, \\ 0&\mbox{otherwise}\ \end{array} \right. $$ Calculate the joint moment generating function. My textbook hasn't been much help, but I believe the route that I should be taking involves this calculation: $$ M_{X,Y} (t_1, t_2) = E[\exp(t_1X+t_2Y)] $$ $$...$$ $$ = E_X(\exp(t_1X)E[\exp(t_2Y)|X]) $$ After some research I've found that it relates to the ""erf"" function, but this was not discussed in class or in the textbook thus I believe that a different approach is required. Thanks for your help.",,"['statistics', 'moment-generating-functions']"
91,Correlation Coefficient Distribution Function: An Apparent Discrepancy?,Correlation Coefficient Distribution Function: An Apparent Discrepancy?,,"I'd like to explain an apparent discrepancy between: (1) The sample correlation distribution function between sample vectors for a bivariate, correlated random variable (correlation coefficient = $\rho$) and (2) The sample correlation distribution function for two normally distributed random vectors that each contain a given signal with additive Gaussian noise. In this latter case, the correlation coefficient between these vectors $\rho$. While (1) gives the standard Pearson Correlation Coefficient, (2) is more consistent with time series analysis and match filtering/correlation detection. I'd like to use a distribution function for (2) to identify the detection performance of such a correlation detector. Please read on below. First sample correlation computation: The ""correct"" way to view the correlation distribution function is as follows: Suppose pairs $(x_{1}, s_{1})$, $(x_{2}, s_{2})$, $(x_{3}, s_{3})$, $\cdots$, $(x_{n}, s_{n})$ are a sample of size $n$ drawn from the distribution of the random vector $(S, \, X)^{\prime}$, which has a bivariate normal distribution with mean vector $(\mu_{S}, \, \mu_{X})^{\prime}$ and covariance: \begin{equation}  \Sigma =   \begin{bmatrix}        \sigma_{S}^{2} & \sigma_{S\,X} \\[0.3em]        \sigma_{S\,X} & \sigma_{X}^{2}                  \end{bmatrix}, \end{equation} where the population correlation coefficient is: \begin{equation}  \rho = \cfrac{\sigma_{S\,X}}{\sigma_{X}\, \sigma_{S}} \end{equation} The estimator for $\rho$, call it $\hat{\rho}$, is: \begin{equation} \hat{\rho}_{1}   = \frac{ \boldsymbol{x}^{\text{T}} \boldsymbol{s} } { \left|\left|\, \boldsymbol{x} \,\right|\right| \,\left|\left| \,\boldsymbol{s} \,\right|\right| } \end{equation} where $\boldsymbol{x}$ and $\boldsymbol{s}$ are concatenated $n$-dim vectors formed from from the samples $(x_{k}, s_{k})$ above ($k$ $=$ $1,2,\cdots,n$). Coefficient $\hat{\rho}$ has a Pearson's correlation coefficient distribution function, that I will call $p_{R}\left( r \,; \rho, n, \,\mathcal{H}_{1}\right)$. The expression $\mathcal{H}_{1}$ is borrowed from hypothesis decision theory. It indicates that the true correlation is nonzero, e.g., $\rho$ $\ne$ $0$. Second sample correlation computation: OK: Now take two vectors, $\boldsymbol{x}$ and $\boldsymbol{s}$. This time, assume: $\boldsymbol{x}$ $\sim$ $\mathcal{N}(\boldsymbol{\mu}_{X}, \sigma_{X}^{2}\mathbf{I})$ and: $\boldsymbol{s}$ $\sim$ $\mathcal{N}(\boldsymbol{\mu}_{S}, \sigma_{S}^{2}\mathbf{I})$ Again, compute the sample correlation distribution function: \begin{equation} \hat{\rho}_{2}   = \frac{ \boldsymbol{x}^{\text{T}} \boldsymbol{s} } { \left|\left|\, \boldsymbol{x} \,\right|\right| \,\left|\left| \,\boldsymbol{s} \,\right|\right| } \end{equation} Suppose now that $\rho$ is the same in both cases . Inconsistency: These coefficients DO NOT have the same distribution functions. That is, the distribution function for $\rho_{1}$ and $\rho_{2}$ do not overlap. In fact, the latter is lower variance, and shifted to the right of the first. The following figure illustrates that while  $\rho_{1}$ has the ""expected"" Pearson correlation coefficient distribution (left panel), the second coefficient $\rho_{2}$ behaves as though it has more samples, and a higher correlation coefficient (right panel). A parameter fit for $\rho$ and $n$ using $p_{R}\left( r \,; \rho, n, \,\mathcal{H}_{1}\right)$ illustrates that the distribution for $\rho_{2}$ is parametrized differently (blue curve, right panel). Both $\rho$ and $n$ are larger than expected. My Question : Can we develop the correct distribution function for $\rho_{2}$? Or, can we ""correct"" $\rho$ and $n$ and simply use  $p_{R}\left( r \,; \rho, n, \,\mathcal{H}_{1}\right)$? To generate these figures, Matlab Code follows below: %NOTE! Function corrdist.m is commented out at bottom of code. Save %the function as it's own .m file and comment out to run this code.  %STEP 0:  %PROVIDE PRELIMINARY DEFINITIONS.  clear h; %length of time series/dimension of vector (make N even for convenience) N       = 1e2; %number of samples drawn from population (to make histogram). Choose a very %large sample to make the histogram smooth. Nsim    = 2e4;  %the true correlation coefficient (||n||^2 = sigma^2*(N-1) = 1*(N-1) ): r0  = 1/( 1 + (N-1)./(s'*s));  %now add N(0,1) noise to signal to make Nsim sample-vectors from same %distribution. Call result x.  %signal definition s   = sqrt(2)*randn(N,1); x   = repmat(s,1,Nsim) + randn(N, Nsim);  %STEP 1:  %COMPUTE THE HISTOGRAM FOR THE CORRELATION COEFFICIENT BETWEEN TWO %NORMALLY DISTRIBUTED VECTORS WITH SPECIFIED CORRELATION r0.  %Define a bivariate, normally distributed random variable z. R   = chol([1,r0;r0,1]); mu  = [0,0];  %Compute a correlation coefficient between each random vector %This is not efficient, but it shows the reader (you) what I am doing: c   = []; for k = 1:Nsim,      z       = (repmat(mu,N,1) +  randn(N,2)*R);     c       = cat(1, c, z(:,1)'*z(:,2)/(norm(z(:,1))*norm(z(:,2))));     end;  subplot(1,2,1); [Nb, b]     = hist(c, floor(sqrt(length(cc)))); Nb          = Nb./trapz(b, Nb);  h(1) = bar(b, Nb,'facecolor','k','edgecolor','none'); hold on; r       = linspace(0,1,1e4); h(2)    = plot(r, corrdist(r, r0, N),'-r','linewidth',4); f1      = gcf; a1      = gca;  legend(h,{'Sample Correl. Hist.','Theor. Distr.'},'Location','Best'); legend boxoff; title('Using Correlated Normal Random Variables'); xlabel('Coefficient'); ylabel('Normalized Density');  %STEP 2:  %COMPUTE THE HISTOGRAM FOR THE CORRELATION COEFFICIENT BETWEEN TWO %NORMALLY DISTRIBUTED VECTORS THAT CONSIST OF A GIVEN SIGNAL, PLUS ADDITIVE %GAUSSIAN NOISE.  %normalize data vectors (columns) for correlation coefficient computation.  %Take care not to include norm-computations that are below eps to  %avoid numerical blow-up (divide by zero). n           = sqrt( sum( x.*conj(x),1) ); m           = n(n>eps); x(:,n<eps)  = []; Nsim        = length(m); temp        = repmat(m.^(-1),size(x,1),1);  %normalize x = signal + noise for correlation computation.  x           = x.*temp;  %now compute the sample correlation between the first sample vector and the %following independent and identically distributed column vectors in x. cc      = x(:,1)'*x(:,2:end);  %compute histogram, and normalized histogram. [Nb, b]     = hist(cc, floor(sqrt(length(cc)))); Nb          = Nb./trapz(b, Nb);  %NOTE: The correlation distribution function cc and the histogram do not %agree in this case. subplot(1,2,2); h(3) = bar(b, Nb,'facecolor','k','edgecolor','none'); hold on; r   = linspace(0,1,1e4); h(4) = plot(r, corrdist(r, r0, N),'-r','linewidth',4);  %BUT: The EFFECTIVE distribution function for cc behaves as though it has %many more degrees of freedom, and a different true correlation:  %Find the best fit correlation value and sample number to fit histogram. dof     = fminsearch( @(p) norm( corrdist(b,p(1),p(2)) - Nb), [r0, N]); h(5)    = plot(r, corrdist(r, dof(1), dof(2)),'-b','linewidth',4); f2      = gcf; a2      = gca; ylimRef = ylim; ylim(a1,ylimRef); set(a2,'ytick',[]); set(a1,'xlim',[0.27, 0.92]); set(a2,'xlim',[0.27, 0.92]);  legend(h(3:end),{'Correl. Histogram','Theor. Distr.','Best-Fit Distr.'},'Location','Best'); legend boxoff; title('Using Signal + Noise Vectors'); %Note that the latter,  best-fit correlation distribution fits the  %histogram MUCH better than the correlation distribution function using the %assumed parameters, r0 and N.  mydir   = pwd;  set(gcf,'units','normalized','outerposition',[0,1,1,1]); set(gcf,'Units','points') set(gcf,'PaperUnits','points')  sizeX= get(gcf,'Position'); sizeX= sizeX(3:4); set(gcf,'PaperSize',sizeX)  set(gcf,'PaperPosition',[0,0,sizeX(1),sizeX(2)])  print -dpdf  -r300 CorrelationParadox;  > %CORRDIST.M IS DOWN HERE!  %CORRDIST.M IS DOWN HERE! % % function y = corrdist(r, ro, n)  % %This function computes the probability density function for the % %correlation coefficient of a bivariate random variable. % % % % USAGES % % y = corrdist(r, ro, n) % % % % INPUT % % r:    Vector of possible correlation random variables, i.e. the values at % %       which the pdf is evaluated at. % % ro:   The given (true) correlation coefficient, i.e. the population % %       correlation coefficient. length(ro) > 1 supported. % % n:    The number of samples in the correlated data. Only length(n) = 1 % %       supported. % %  % % OUTPUT % % y:    The probability density function for r, given ro, for n data % %       samples of a bivariate normal distribution. % % % %----------------------------------------------------------------------- % % Latest Edit: 11.June.2012 % % Joshua D Carmichael % % [email protected] % % % % Original Author: Xu Cui, Stanford University (retrieved 11.June.2012) % %----------------------------------------------------------------------- %  % %accept vectorized inputs. % if(length(ro)> 1.5), %     r   = repmat(r(:),1,length(ro)); %     ro  = repmat(ro(:)', length(r),1); % end; %  % if( n < 120 ), %      %     y = (n-2) * gamma(n-1) * ((1-ro.^2).^((n-1)/2)).* (1-r.^2).^((n-4)/2); %     y = y./ (sqrt(2*pi) * gamma(n-1/2) * (1-ro.*r).^(n-3/2)); %     y = y.* (1+ 1/4*(ro.*r+1)/(2*n-1) + 9/16*(ro.*r+1).^2 / (2*n-1)/(2*n+1)); %      % else %      %     y = (n-2) * (1-ro.^2)^((n-1)/2) * (1-r.^2).^((n-4)/2); %     y = y./ (sqrt(2*pi) * (1-ro.*r).^(n-3/2)) * n.^(-1/2); %     y = y.* (1+ 1/4*(ro.*r+1)/(2*n-1) + 9/16*(ro.*r+1).^2 / (2*n-1)/(2*n+1)); %      % end; %  % y(r>1)              = 0; % y(r<-1)             = 0; % y(~isfinite(y))     = 0; %  % return;","I'd like to explain an apparent discrepancy between: (1) The sample correlation distribution function between sample vectors for a bivariate, correlated random variable (correlation coefficient = $\rho$) and (2) The sample correlation distribution function for two normally distributed random vectors that each contain a given signal with additive Gaussian noise. In this latter case, the correlation coefficient between these vectors $\rho$. While (1) gives the standard Pearson Correlation Coefficient, (2) is more consistent with time series analysis and match filtering/correlation detection. I'd like to use a distribution function for (2) to identify the detection performance of such a correlation detector. Please read on below. First sample correlation computation: The ""correct"" way to view the correlation distribution function is as follows: Suppose pairs $(x_{1}, s_{1})$, $(x_{2}, s_{2})$, $(x_{3}, s_{3})$, $\cdots$, $(x_{n}, s_{n})$ are a sample of size $n$ drawn from the distribution of the random vector $(S, \, X)^{\prime}$, which has a bivariate normal distribution with mean vector $(\mu_{S}, \, \mu_{X})^{\prime}$ and covariance: \begin{equation}  \Sigma =   \begin{bmatrix}        \sigma_{S}^{2} & \sigma_{S\,X} \\[0.3em]        \sigma_{S\,X} & \sigma_{X}^{2}                  \end{bmatrix}, \end{equation} where the population correlation coefficient is: \begin{equation}  \rho = \cfrac{\sigma_{S\,X}}{\sigma_{X}\, \sigma_{S}} \end{equation} The estimator for $\rho$, call it $\hat{\rho}$, is: \begin{equation} \hat{\rho}_{1}   = \frac{ \boldsymbol{x}^{\text{T}} \boldsymbol{s} } { \left|\left|\, \boldsymbol{x} \,\right|\right| \,\left|\left| \,\boldsymbol{s} \,\right|\right| } \end{equation} where $\boldsymbol{x}$ and $\boldsymbol{s}$ are concatenated $n$-dim vectors formed from from the samples $(x_{k}, s_{k})$ above ($k$ $=$ $1,2,\cdots,n$). Coefficient $\hat{\rho}$ has a Pearson's correlation coefficient distribution function, that I will call $p_{R}\left( r \,; \rho, n, \,\mathcal{H}_{1}\right)$. The expression $\mathcal{H}_{1}$ is borrowed from hypothesis decision theory. It indicates that the true correlation is nonzero, e.g., $\rho$ $\ne$ $0$. Second sample correlation computation: OK: Now take two vectors, $\boldsymbol{x}$ and $\boldsymbol{s}$. This time, assume: $\boldsymbol{x}$ $\sim$ $\mathcal{N}(\boldsymbol{\mu}_{X}, \sigma_{X}^{2}\mathbf{I})$ and: $\boldsymbol{s}$ $\sim$ $\mathcal{N}(\boldsymbol{\mu}_{S}, \sigma_{S}^{2}\mathbf{I})$ Again, compute the sample correlation distribution function: \begin{equation} \hat{\rho}_{2}   = \frac{ \boldsymbol{x}^{\text{T}} \boldsymbol{s} } { \left|\left|\, \boldsymbol{x} \,\right|\right| \,\left|\left| \,\boldsymbol{s} \,\right|\right| } \end{equation} Suppose now that $\rho$ is the same in both cases . Inconsistency: These coefficients DO NOT have the same distribution functions. That is, the distribution function for $\rho_{1}$ and $\rho_{2}$ do not overlap. In fact, the latter is lower variance, and shifted to the right of the first. The following figure illustrates that while  $\rho_{1}$ has the ""expected"" Pearson correlation coefficient distribution (left panel), the second coefficient $\rho_{2}$ behaves as though it has more samples, and a higher correlation coefficient (right panel). A parameter fit for $\rho$ and $n$ using $p_{R}\left( r \,; \rho, n, \,\mathcal{H}_{1}\right)$ illustrates that the distribution for $\rho_{2}$ is parametrized differently (blue curve, right panel). Both $\rho$ and $n$ are larger than expected. My Question : Can we develop the correct distribution function for $\rho_{2}$? Or, can we ""correct"" $\rho$ and $n$ and simply use  $p_{R}\left( r \,; \rho, n, \,\mathcal{H}_{1}\right)$? To generate these figures, Matlab Code follows below: %NOTE! Function corrdist.m is commented out at bottom of code. Save %the function as it's own .m file and comment out to run this code.  %STEP 0:  %PROVIDE PRELIMINARY DEFINITIONS.  clear h; %length of time series/dimension of vector (make N even for convenience) N       = 1e2; %number of samples drawn from population (to make histogram). Choose a very %large sample to make the histogram smooth. Nsim    = 2e4;  %the true correlation coefficient (||n||^2 = sigma^2*(N-1) = 1*(N-1) ): r0  = 1/( 1 + (N-1)./(s'*s));  %now add N(0,1) noise to signal to make Nsim sample-vectors from same %distribution. Call result x.  %signal definition s   = sqrt(2)*randn(N,1); x   = repmat(s,1,Nsim) + randn(N, Nsim);  %STEP 1:  %COMPUTE THE HISTOGRAM FOR THE CORRELATION COEFFICIENT BETWEEN TWO %NORMALLY DISTRIBUTED VECTORS WITH SPECIFIED CORRELATION r0.  %Define a bivariate, normally distributed random variable z. R   = chol([1,r0;r0,1]); mu  = [0,0];  %Compute a correlation coefficient between each random vector %This is not efficient, but it shows the reader (you) what I am doing: c   = []; for k = 1:Nsim,      z       = (repmat(mu,N,1) +  randn(N,2)*R);     c       = cat(1, c, z(:,1)'*z(:,2)/(norm(z(:,1))*norm(z(:,2))));     end;  subplot(1,2,1); [Nb, b]     = hist(c, floor(sqrt(length(cc)))); Nb          = Nb./trapz(b, Nb);  h(1) = bar(b, Nb,'facecolor','k','edgecolor','none'); hold on; r       = linspace(0,1,1e4); h(2)    = plot(r, corrdist(r, r0, N),'-r','linewidth',4); f1      = gcf; a1      = gca;  legend(h,{'Sample Correl. Hist.','Theor. Distr.'},'Location','Best'); legend boxoff; title('Using Correlated Normal Random Variables'); xlabel('Coefficient'); ylabel('Normalized Density');  %STEP 2:  %COMPUTE THE HISTOGRAM FOR THE CORRELATION COEFFICIENT BETWEEN TWO %NORMALLY DISTRIBUTED VECTORS THAT CONSIST OF A GIVEN SIGNAL, PLUS ADDITIVE %GAUSSIAN NOISE.  %normalize data vectors (columns) for correlation coefficient computation.  %Take care not to include norm-computations that are below eps to  %avoid numerical blow-up (divide by zero). n           = sqrt( sum( x.*conj(x),1) ); m           = n(n>eps); x(:,n<eps)  = []; Nsim        = length(m); temp        = repmat(m.^(-1),size(x,1),1);  %normalize x = signal + noise for correlation computation.  x           = x.*temp;  %now compute the sample correlation between the first sample vector and the %following independent and identically distributed column vectors in x. cc      = x(:,1)'*x(:,2:end);  %compute histogram, and normalized histogram. [Nb, b]     = hist(cc, floor(sqrt(length(cc)))); Nb          = Nb./trapz(b, Nb);  %NOTE: The correlation distribution function cc and the histogram do not %agree in this case. subplot(1,2,2); h(3) = bar(b, Nb,'facecolor','k','edgecolor','none'); hold on; r   = linspace(0,1,1e4); h(4) = plot(r, corrdist(r, r0, N),'-r','linewidth',4);  %BUT: The EFFECTIVE distribution function for cc behaves as though it has %many more degrees of freedom, and a different true correlation:  %Find the best fit correlation value and sample number to fit histogram. dof     = fminsearch( @(p) norm( corrdist(b,p(1),p(2)) - Nb), [r0, N]); h(5)    = plot(r, corrdist(r, dof(1), dof(2)),'-b','linewidth',4); f2      = gcf; a2      = gca; ylimRef = ylim; ylim(a1,ylimRef); set(a2,'ytick',[]); set(a1,'xlim',[0.27, 0.92]); set(a2,'xlim',[0.27, 0.92]);  legend(h(3:end),{'Correl. Histogram','Theor. Distr.','Best-Fit Distr.'},'Location','Best'); legend boxoff; title('Using Signal + Noise Vectors'); %Note that the latter,  best-fit correlation distribution fits the  %histogram MUCH better than the correlation distribution function using the %assumed parameters, r0 and N.  mydir   = pwd;  set(gcf,'units','normalized','outerposition',[0,1,1,1]); set(gcf,'Units','points') set(gcf,'PaperUnits','points')  sizeX= get(gcf,'Position'); sizeX= sizeX(3:4); set(gcf,'PaperSize',sizeX)  set(gcf,'PaperPosition',[0,0,sizeX(1),sizeX(2)])  print -dpdf  -r300 CorrelationParadox;  > %CORRDIST.M IS DOWN HERE!  %CORRDIST.M IS DOWN HERE! % % function y = corrdist(r, ro, n)  % %This function computes the probability density function for the % %correlation coefficient of a bivariate random variable. % % % % USAGES % % y = corrdist(r, ro, n) % % % % INPUT % % r:    Vector of possible correlation random variables, i.e. the values at % %       which the pdf is evaluated at. % % ro:   The given (true) correlation coefficient, i.e. the population % %       correlation coefficient. length(ro) > 1 supported. % % n:    The number of samples in the correlated data. Only length(n) = 1 % %       supported. % %  % % OUTPUT % % y:    The probability density function for r, given ro, for n data % %       samples of a bivariate normal distribution. % % % %----------------------------------------------------------------------- % % Latest Edit: 11.June.2012 % % Joshua D Carmichael % % [email protected] % % % % Original Author: Xu Cui, Stanford University (retrieved 11.June.2012) % %----------------------------------------------------------------------- %  % %accept vectorized inputs. % if(length(ro)> 1.5), %     r   = repmat(r(:),1,length(ro)); %     ro  = repmat(ro(:)', length(r),1); % end; %  % if( n < 120 ), %      %     y = (n-2) * gamma(n-1) * ((1-ro.^2).^((n-1)/2)).* (1-r.^2).^((n-4)/2); %     y = y./ (sqrt(2*pi) * gamma(n-1/2) * (1-ro.*r).^(n-3/2)); %     y = y.* (1+ 1/4*(ro.*r+1)/(2*n-1) + 9/16*(ro.*r+1).^2 / (2*n-1)/(2*n+1)); %      % else %      %     y = (n-2) * (1-ro.^2)^((n-1)/2) * (1-r.^2).^((n-4)/2); %     y = y./ (sqrt(2*pi) * (1-ro.*r).^(n-3/2)) * n.^(-1/2); %     y = y.* (1+ 1/4*(ro.*r+1)/(2*n-1) + 9/16*(ro.*r+1).^2 / (2*n-1)/(2*n+1)); %      % end; %  % y(r>1)              = 0; % y(r<-1)             = 0; % y(~isfinite(y))     = 0; %  % return;",,"['statistics', 'probability-distributions', 'correlation', 'hypothesis-testing']"
92,Conceptual questions dealing with chi-square distributions?,Conceptual questions dealing with chi-square distributions?,,"In my textbook they have this inequality: $$ \chi_{1-\frac{\alpha}{2}}^2 < \frac{(n-1)s^2}{\sigma^2} < \chi_{\frac{\alpha}{2}}^2$$ which later becomes this statement: $$\frac{(n-1)s^2}{\chi_{\frac{\alpha}{2}}^2 } < \sigma^2 < \frac{ (n-1)s^2}{ \chi_{1-\frac{\alpha}{2}}^2}$$ Now I know the whole idea is to find the confidence interval for $\sigma^2$ the variance, but I was wondering if the distribution for the variance is normal. I also don't understand why the chi square is squared. When I look at the picture in the book that shows a right skewed graph with the chi squares labeled (i.e. $\chi_{0.95}^2 = 4.575$ and $\chi_{0.05}^2 = 19.675$), I get the impression that I'm looking at something similar to $z$ scores. What are these chi squares? Do they represent the number of standard deviations away from the mean?","In my textbook they have this inequality: $$ \chi_{1-\frac{\alpha}{2}}^2 < \frac{(n-1)s^2}{\sigma^2} < \chi_{\frac{\alpha}{2}}^2$$ which later becomes this statement: $$\frac{(n-1)s^2}{\chi_{\frac{\alpha}{2}}^2 } < \sigma^2 < \frac{ (n-1)s^2}{ \chi_{1-\frac{\alpha}{2}}^2}$$ Now I know the whole idea is to find the confidence interval for $\sigma^2$ the variance, but I was wondering if the distribution for the variance is normal. I also don't understand why the chi square is squared. When I look at the picture in the book that shows a right skewed graph with the chi squares labeled (i.e. $\chi_{0.95}^2 = 4.575$ and $\chi_{0.05}^2 = 19.675$), I get the impression that I'm looking at something similar to $z$ scores. What are these chi squares? Do they represent the number of standard deviations away from the mean?",,"['statistics', 'probability-distributions']"
93,Why is it called the score of the log likelihood function?,Why is it called the score of the log likelihood function?,,"Since the score of the log likelihood function is just the gradient of the log likelihood function, why give it a special name? Why not just call it the gradient?","Since the score of the log likelihood function is just the gradient of the log likelihood function, why give it a special name? Why not just call it the gradient?",,"['statistics', 'estimation']"
94,Margin of error and $98\%$ confidence interval question for stats people :),Margin of error and  confidence interval question for stats people :),98\%,"The question is (this is homework, for an online class, no teacher so at times confusing)  Carl conducted an experiment to determine if there is a difference in mean body temperature between men and women. He found that the mean body temperature for men in sample was $91.1$ with a population standard deviation of $.52$ and mean body temperature for women in sample was $97.6$ with population standard deviation of $.45$. -Assuming population of body temperatures for men and women were normally distributed, calculate the $98\%$ confidence interval and the margin of error for both. *I have a bit of experience with confidence interval, but only have $90\%, 95\%,$ and $99\%$ and the course gave me a ""confidence interval calculator"" and has only that. Also, I have never before heard of margin of error, when I looked it up I didn't understand it. Could someone please explain to me in a way that I would easily be able to understand? (I asked the same question yesterday, but no one replied. I hope someone can respond today, I wasn't sure I could refresh the old one"" Thank you.","The question is (this is homework, for an online class, no teacher so at times confusing)  Carl conducted an experiment to determine if there is a difference in mean body temperature between men and women. He found that the mean body temperature for men in sample was $91.1$ with a population standard deviation of $.52$ and mean body temperature for women in sample was $97.6$ with population standard deviation of $.45$. -Assuming population of body temperatures for men and women were normally distributed, calculate the $98\%$ confidence interval and the margin of error for both. *I have a bit of experience with confidence interval, but only have $90\%, 95\%,$ and $99\%$ and the course gave me a ""confidence interval calculator"" and has only that. Also, I have never before heard of margin of error, when I looked it up I didn't understand it. Could someone please explain to me in a way that I would easily be able to understand? (I asked the same question yesterday, but no one replied. I hope someone can respond today, I wasn't sure I could refresh the old one"" Thank you.",,['statistics']
95,"Analysis of ""Dungeon Raid""","Analysis of ""Dungeon Raid""",,"The computer game Dungeon Raid is quite complicated, but for our purposes we can consider the following simplified version. The player has a current health $\def\hcur{h}\hcur$ and a maximum health $\def\hmax{h_{max}}\hmax$ with $0\le\hcur\le\hmax$, and a current armor $\def\acur{a}\acur$ and a maximum armor $\def\amax{a_{max}}\amax$ with $0\le\acur\le\amax$. The playing field contains groups of monsters, potions, and shields.  On each turn, the player may attack some monsters, gather some potions, or gather some shields. Killing monsters scores points.  Gathering potions raises $\hcur$, possibly all the way to $\hmax$, but no higher.  Similarly, gathering shields raises $\acur$, but not past $\amax$. After the player's turn, any monsters still alive attack the player, doing $d$ points of damage, where $d$ is independent of the other quantities and is calculated in a way that need not concern us. The damage is divided into a portion that is absorbed by the armor, $d_a = \min(\acur, d)$, and the remaining portion that is applied to the player's health, $d_h = d-d_a = \max(d-\acur, 0)$.  The armor is degraded as follows:  $d_a$ fair coins are flipped, and $\acur$ is reduced by one point for each tail. The player's health $\hcur$ is reduced by $d_h$.  If $\hcur$ is now zero or below, the game is over; if $\hcur$ is positive the player gets another turn. At intervals the game will offer the player a choice of equipment upgrades. One such is a health upgrade, which raises both $\hcur$ and $\hmax$ by 5 points; another is an armor upgrade, which raises both $\acur$ and $\amax$ by 1 point. I would like to analyze whether the health or armor upgrade is likely to be better. To this end, I want to engage in intelligent, directed collection of statistics. For example, it seems important to know the distribution of $d_a$ under typical play.  Similarly, it might be useful to know the expected increase to $\acur$ from gathering shields, which depends on how often $\acur$ is close to $\amax$; when $\acur = \amax - 1$ gathering any number of shields can only raise $\acur$ by 1. I don't know what information to collect, how to decide what to collect, or what to do with the information once I have collected it. My question is: On what parameters might the comparison of the armor and health upgrades depend, and what would I need to know in order to compare them?","The computer game Dungeon Raid is quite complicated, but for our purposes we can consider the following simplified version. The player has a current health $\def\hcur{h}\hcur$ and a maximum health $\def\hmax{h_{max}}\hmax$ with $0\le\hcur\le\hmax$, and a current armor $\def\acur{a}\acur$ and a maximum armor $\def\amax{a_{max}}\amax$ with $0\le\acur\le\amax$. The playing field contains groups of monsters, potions, and shields.  On each turn, the player may attack some monsters, gather some potions, or gather some shields. Killing monsters scores points.  Gathering potions raises $\hcur$, possibly all the way to $\hmax$, but no higher.  Similarly, gathering shields raises $\acur$, but not past $\amax$. After the player's turn, any monsters still alive attack the player, doing $d$ points of damage, where $d$ is independent of the other quantities and is calculated in a way that need not concern us. The damage is divided into a portion that is absorbed by the armor, $d_a = \min(\acur, d)$, and the remaining portion that is applied to the player's health, $d_h = d-d_a = \max(d-\acur, 0)$.  The armor is degraded as follows:  $d_a$ fair coins are flipped, and $\acur$ is reduced by one point for each tail. The player's health $\hcur$ is reduced by $d_h$.  If $\hcur$ is now zero or below, the game is over; if $\hcur$ is positive the player gets another turn. At intervals the game will offer the player a choice of equipment upgrades. One such is a health upgrade, which raises both $\hcur$ and $\hmax$ by 5 points; another is an armor upgrade, which raises both $\acur$ and $\amax$ by 1 point. I would like to analyze whether the health or armor upgrade is likely to be better. To this end, I want to engage in intelligent, directed collection of statistics. For example, it seems important to know the distribution of $d_a$ under typical play.  Similarly, it might be useful to know the expected increase to $\acur$ from gathering shields, which depends on how often $\acur$ is close to $\amax$; when $\acur = \amax - 1$ gathering any number of shields can only raise $\acur$ by 1. I don't know what information to collect, how to decide what to collect, or what to do with the information once I have collected it. My question is: On what parameters might the comparison of the armor and health upgrades depend, and what would I need to know in order to compare them?",,"['statistics', 'recreational-mathematics', 'combinatorial-game-theory']"
96,Why we always put log() before the joint pdf when we use MLE(Maximum likelihood Estimation)?,Why we always put log() before the joint pdf when we use MLE(Maximum likelihood Estimation)?,,"Maybe this question is simple, but I really need some help. When we use the Maximum Likelihood Estimation(MLE) to estimate the parameters, why we always put the log() before the joint density? To use the sum in place of product? But why? The wikipedia said it will be convenient. Why? Thank you.","Maybe this question is simple, but I really need some help. When we use the Maximum Likelihood Estimation(MLE) to estimate the parameters, why we always put the log() before the joint density? To use the sum in place of product? But why? The wikipedia said it will be convenient. Why? Thank you.",,"['statistics', 'parameter-estimation']"
97,"Maximum likelihood estimators, hypergeometric and binomial","Maximum likelihood estimators, hypergeometric and binomial",,"I'm trying to solve a two part problem. The set up is as follows: consider a bag with $\theta$ red marbles and $7-\theta$ blue marbles, with $\theta$ being unknown. Let $x$ denote the number of red marbles found in a sample of 3. If we sample without replacement , what is a maximum likelihood estimator for $\theta$ (the number of red marbles), based on our sample? If we sample with replacement , what is the maximum likelihood estimator for $\theta$. I'd also like to check if these estimators are unbiased, and which has the smaller variance (I'd expected sampling without replacement to be superior). 1.) Sampling without replacement yields a hypergeometric distribution, with the likelihood function $\large L(\theta)=\frac{\binom{\theta}{x}\binom{7-\theta}{3-x}}{\binom{7}{3}}$. I think what I want to do is look at the ratio $\large \hat{L(\theta)}=\frac{L(\theta)}{L(\theta+1)}$, since this should be increasing up to the point $ \hat{L(\theta)}>1$ and decreasing afterwards, and we can take the MLE to be this point of inflection. A bit of algebra shows this point to be $\frac{8x-3}{3}$. When this fraction is an integer, we can see that $ \hat{L(\theta)}=1$, so $\frac{8x-3}{3}+1$ is also an MLE (it is not unique). If it is not an integer, we take the floor and see that the MLE is $[\frac{8x}{3}]$, where the brackets represent the floor function (since $[\frac{8x-3}{3}]<[\frac{8x}{3}]$, we only have one MLE in this case). 2.) The binomial case is more confusing to me, though perhaps I'm just thinking about it incorrectly. I can easily take the maximum likelihood estimate of P (which is, in this case, $\frac{\theta}{7}$), and show that this MLE is simply $\frac{x}{3}$ (this follows from taking the derivative of the log likelihood and setting it to zero). Then solving the equation $\frac{\theta}{7}=\frac{x}{3}$ yields $\theta=\frac{7x}{3}$ (this result is similar to the hypergeometric result, which is reassuring). It is not, however, a whole number and I can't tell if I should take the floor or the ceiling in this case (or perhaps both provide MLEs)? Finally, assuming that my logic is sound up to this point, I'm not sure how to check whether either of these are unbiased, or how to compare the variances (I think this should be relatively easy - I'm just drawing a blank!) Thanks so much for reading - any help is greatly appreciated!","I'm trying to solve a two part problem. The set up is as follows: consider a bag with $\theta$ red marbles and $7-\theta$ blue marbles, with $\theta$ being unknown. Let $x$ denote the number of red marbles found in a sample of 3. If we sample without replacement , what is a maximum likelihood estimator for $\theta$ (the number of red marbles), based on our sample? If we sample with replacement , what is the maximum likelihood estimator for $\theta$. I'd also like to check if these estimators are unbiased, and which has the smaller variance (I'd expected sampling without replacement to be superior). 1.) Sampling without replacement yields a hypergeometric distribution, with the likelihood function $\large L(\theta)=\frac{\binom{\theta}{x}\binom{7-\theta}{3-x}}{\binom{7}{3}}$. I think what I want to do is look at the ratio $\large \hat{L(\theta)}=\frac{L(\theta)}{L(\theta+1)}$, since this should be increasing up to the point $ \hat{L(\theta)}>1$ and decreasing afterwards, and we can take the MLE to be this point of inflection. A bit of algebra shows this point to be $\frac{8x-3}{3}$. When this fraction is an integer, we can see that $ \hat{L(\theta)}=1$, so $\frac{8x-3}{3}+1$ is also an MLE (it is not unique). If it is not an integer, we take the floor and see that the MLE is $[\frac{8x}{3}]$, where the brackets represent the floor function (since $[\frac{8x-3}{3}]<[\frac{8x}{3}]$, we only have one MLE in this case). 2.) The binomial case is more confusing to me, though perhaps I'm just thinking about it incorrectly. I can easily take the maximum likelihood estimate of P (which is, in this case, $\frac{\theta}{7}$), and show that this MLE is simply $\frac{x}{3}$ (this follows from taking the derivative of the log likelihood and setting it to zero). Then solving the equation $\frac{\theta}{7}=\frac{x}{3}$ yields $\theta=\frac{7x}{3}$ (this result is similar to the hypergeometric result, which is reassuring). It is not, however, a whole number and I can't tell if I should take the floor or the ceiling in this case (or perhaps both provide MLEs)? Finally, assuming that my logic is sound up to this point, I'm not sure how to check whether either of these are unbiased, or how to compare the variances (I think this should be relatively easy - I'm just drawing a blank!) Thanks so much for reading - any help is greatly appreciated!",,"['statistics', 'probability-distributions', 'optimization', 'parameter-estimation']"
98,How do mean and standard deviation change after discarding outliers? [closed],How do mean and standard deviation change after discarding outliers? [closed],,"This question is unlikely to help any future visitors; it is only relevant to a small geographic area, a specific moment in time, or an extraordinarily narrow situation that is not generally applicable to the worldwide audience of the internet. For help making this question more broadly applicable, visit the help center . Closed 11 years ago . **Sara measured the time in minutes between cars passing her camp near a desert road over a two hour period The times she measured were 6, 6, 8, 9, 10, 11, 13, 13, 20, 24. She calculated the mean and standard deviation for this set of data. (She decided to reject the two outliers (20 and 24) How do the new mean and standard deviation compare to her original ones? A The mean and standard deviation both decrease. B The mean and standard deviation both increase. C The mean stays the same and the standard deviation decreases. D The mean decreases and the standard deviation increases. My answer is A **","This question is unlikely to help any future visitors; it is only relevant to a small geographic area, a specific moment in time, or an extraordinarily narrow situation that is not generally applicable to the worldwide audience of the internet. For help making this question more broadly applicable, visit the help center . Closed 11 years ago . **Sara measured the time in minutes between cars passing her camp near a desert road over a two hour period The times she measured were 6, 6, 8, 9, 10, 11, 13, 13, 20, 24. She calculated the mean and standard deviation for this set of data. (She decided to reject the two outliers (20 and 24) How do the new mean and standard deviation compare to her original ones? A The mean and standard deviation both decrease. B The mean and standard deviation both increase. C The mean stays the same and the standard deviation decreases. D The mean decreases and the standard deviation increases. My answer is A **",,['statistics']
99,Are there any statistics texts which give both intuition AND justifications for the equations/methods?,Are there any statistics texts which give both intuition AND justifications for the equations/methods?,,"Background:  I took multiple statistics classes in both high school and college, but nothing I learned ever stuck.  The problem is, things like p-tests, the equations for chi-squared/normal distributions, even the standard deviation are always simply presented as fact, without any proof/justification/motivation for why this equation/method is the correct one. Often, this is because the books are written for people looking to simply apply statistics rather than truly understand it.  Usually, not even a calculus-background is assumed, despite the underlying equations being calculus-heavy. Non-calculus example: Why is the standard deviation not defined as the average distance from the mean , when that is the more intuitively obvious definition?  I still don't quite understand the answer to that one... I did find some books that do go deeply into proofs in my college's mathematics library, but even those were heavy on symbols and light on justifications/motiviations (as well as real-world examples) Does anyone know of any statistics books that not only go over the equations/methods, but explain in detail why they are what they are?","Background:  I took multiple statistics classes in both high school and college, but nothing I learned ever stuck.  The problem is, things like p-tests, the equations for chi-squared/normal distributions, even the standard deviation are always simply presented as fact, without any proof/justification/motivation for why this equation/method is the correct one. Often, this is because the books are written for people looking to simply apply statistics rather than truly understand it.  Usually, not even a calculus-background is assumed, despite the underlying equations being calculus-heavy. Non-calculus example: Why is the standard deviation not defined as the average distance from the mean , when that is the more intuitively obvious definition?  I still don't quite understand the answer to that one... I did find some books that do go deeply into proofs in my college's mathematics library, but even those were heavy on symbols and light on justifications/motiviations (as well as real-world examples) Does anyone know of any statistics books that not only go over the equations/methods, but explain in detail why they are what they are?",,"['reference-request', 'statistics']"
