,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"$G \times H \cong G \times K$ , then $ K \cong H$",", then",G \times H \cong G \times K  K \cong H,"I already know that if groups $G,H,K$ are finitely generated abelian groups, following is true. If $G\times K$ is isomorphic to $H\times K$, then $G$ is isomorphic to $H$. I prove this by uniquness of factorization of finitely generated abelian groups. My questions are If group $G$ is finite,$G\times K$ is isomorphic to $H\times K$, then $G$ is isomorphic to $H$? Can you give me a easiest proof and it can be proved by projection function on external direct product? If $G,H,K$ are groups.  If $G\times K$ is isomorphic to $H\times K$, then $G$ is isomorphic to $H$. This statement is false. What is a counterexample? *$\times$ is external direct product","I already know that if groups $G,H,K$ are finitely generated abelian groups, following is true. If $G\times K$ is isomorphic to $H\times K$, then $G$ is isomorphic to $H$. I prove this by uniquness of factorization of finitely generated abelian groups. My questions are If group $G$ is finite,$G\times K$ is isomorphic to $H\times K$, then $G$ is isomorphic to $H$? Can you give me a easiest proof and it can be proved by projection function on external direct product? If $G,H,K$ are groups.  If $G\times K$ is isomorphic to $H\times K$, then $G$ is isomorphic to $H$. This statement is false. What is a counterexample? *$\times$ is external direct product",,"['abstract-algebra', 'group-theory']"
1,Eisenstein Criterion,Eisenstein Criterion,,Why is it that the Eisenstein's Criterion would work when substituting $x$ with $x + 1$ ? Why is it OK to do this for polynomials in $\mathbb{Q}[x]$ ? Thank you,Why is it that the Eisenstein's Criterion would work when substituting with ? Why is it OK to do this for polynomials in ? Thank you,x x + 1 \mathbb{Q}[x],"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
2,The group of rigid motions of the cube is isomorphic to $S_4$.,The group of rigid motions of the cube is isomorphic to .,S_4,"I want to solve the following exercise from Dummit & Foote. My attempt is down below. Is it correct? Thanks! Show that the group of rigid motions of a cube is isomorphic to $S_4$. My attempt: Let us denote the vertices of the cube so that $1,2,3,4,1$ trace a square and $5,6,7,8$ are the vertices opposite to $1,2,3,4$. Let us also denote the pairs of opposite vertices $d_1,d_2,d_3,d_4$, where vertex $i$ is in $d_i$. To each rigid motion of the cube we associate a permutation of the set $A=\{ d_i \}_{i=1}^4$. Denote this association by $\varphi:G \to S_4$, where $G$ is the group of those rigid motions, and we identified $S_A$ with $S_4$. By definition of function composition we can tell that $\varphi$ is a group homomorphism. We prove that $\varphi$ is injective, using the trivial kernel characterisation: Suppose $\varphi(g)=1$ fixes all of the the pairs of opposite edges (that is we have $g(i) \in \{i,i+4 \}$ for all $i$, where the numbers are reduced mod 8). Suppose $g$ sends vertex $1$ to its opposite $5$. Then the vertices $2,4,7$ adjacent to $1$ must be mapped to their opposite vertices as well. This is because out of the two seemingly possible options for their images, only one (the opposite vertex) is adjacent to $g(1)=5$. This completely determines $g$ to be the negation map which is not included in our group. The contradiction shows that we must have $g(1)=1$, and from that we can find similarly that $g$ is the identity mapping. Since $\ker \varphi$ is trivial $\varphi$ is injective. In order to show that it is surjective, observe that $S_4$ is generated by $\{(1 \; 2),(1 \; 2 \; 3 \; 4) \}$ (this is true because products of these two elements allow us to sort the numbers $1,2,3,4$ in any way we like). We now find elements in $G$ with images under $\varphi$ being those generators. Observe that if $s$ is a $90^\circ$ rotation around the axis through the centres of the squares $1,2,3,4$ and $5,6,7,8$, such that $1$ is mapped to $2$, followed by a rotation by $120^\circ$ around the line through $2,6$ (so that $1$ is mapped to $3$), we have $\varphi(s)=(1 \; 2)$ .Observe also that if $t$ is $90^\circ$ rotation around the axis through the centres of the squares $1,2,3,4$ and $5,6,7,8$, such that $1$ is mapped to $2$, we have $\varphi(t)=(1 \; 2 \; 3 \; 4)$. Now if $\sigma \in S_4$ is any permutation, we express in as a product involving $(1 \; 2),(1 \; 2 \; 3 \;4)$, and the corresponding product involving $s,t$ is mapped to $\sigma$ by $\varphi$. This proves $\varphi$ is surjective. We conclude that $\varphi$ is an isomorphism, so $G \cong S_4$.","I want to solve the following exercise from Dummit & Foote. My attempt is down below. Is it correct? Thanks! Show that the group of rigid motions of a cube is isomorphic to $S_4$. My attempt: Let us denote the vertices of the cube so that $1,2,3,4,1$ trace a square and $5,6,7,8$ are the vertices opposite to $1,2,3,4$. Let us also denote the pairs of opposite vertices $d_1,d_2,d_3,d_4$, where vertex $i$ is in $d_i$. To each rigid motion of the cube we associate a permutation of the set $A=\{ d_i \}_{i=1}^4$. Denote this association by $\varphi:G \to S_4$, where $G$ is the group of those rigid motions, and we identified $S_A$ with $S_4$. By definition of function composition we can tell that $\varphi$ is a group homomorphism. We prove that $\varphi$ is injective, using the trivial kernel characterisation: Suppose $\varphi(g)=1$ fixes all of the the pairs of opposite edges (that is we have $g(i) \in \{i,i+4 \}$ for all $i$, where the numbers are reduced mod 8). Suppose $g$ sends vertex $1$ to its opposite $5$. Then the vertices $2,4,7$ adjacent to $1$ must be mapped to their opposite vertices as well. This is because out of the two seemingly possible options for their images, only one (the opposite vertex) is adjacent to $g(1)=5$. This completely determines $g$ to be the negation map which is not included in our group. The contradiction shows that we must have $g(1)=1$, and from that we can find similarly that $g$ is the identity mapping. Since $\ker \varphi$ is trivial $\varphi$ is injective. In order to show that it is surjective, observe that $S_4$ is generated by $\{(1 \; 2),(1 \; 2 \; 3 \; 4) \}$ (this is true because products of these two elements allow us to sort the numbers $1,2,3,4$ in any way we like). We now find elements in $G$ with images under $\varphi$ being those generators. Observe that if $s$ is a $90^\circ$ rotation around the axis through the centres of the squares $1,2,3,4$ and $5,6,7,8$, such that $1$ is mapped to $2$, followed by a rotation by $120^\circ$ around the line through $2,6$ (so that $1$ is mapped to $3$), we have $\varphi(s)=(1 \; 2)$ .Observe also that if $t$ is $90^\circ$ rotation around the axis through the centres of the squares $1,2,3,4$ and $5,6,7,8$, such that $1$ is mapped to $2$, we have $\varphi(t)=(1 \; 2 \; 3 \; 4)$. Now if $\sigma \in S_4$ is any permutation, we express in as a product involving $(1 \; 2),(1 \; 2 \; 3 \;4)$, and the corresponding product involving $s,t$ is mapped to $\sigma$ by $\varphi$. This proves $\varphi$ is surjective. We conclude that $\varphi$ is an isomorphism, so $G \cong S_4$.",,"['abstract-algebra', 'geometry', 'solution-verification']"
3,Intuition for groups,Intuition for groups,,"This is quite a non-standard question, certainly for mathematics, though I believe it is no less important (for me and my peers, i.e. grads). The course I am reading so far introduced us to Groups, rings, fields, etc. in the first year, progressing to characters, reps etc in the latter years. However, even with representation theory I still don't feel like I have a good intuition. How do you gain intuition in such an area. I know there will be a response of doing examples, but this doesn't really help - I've done lots already. Am I doomed.","This is quite a non-standard question, certainly for mathematics, though I believe it is no less important (for me and my peers, i.e. grads). The course I am reading so far introduced us to Groups, rings, fields, etc. in the first year, progressing to characters, reps etc in the latter years. However, even with representation theory I still don't feel like I have a good intuition. How do you gain intuition in such an area. I know there will be a response of doing examples, but this doesn't really help - I've done lots already. Am I doomed.",,['abstract-algebra']
4,Category theory with multisets,Category theory with multisets,,"An alternative to the notion of multiset introduced in Section 2.2 of Aluffi Chapter 0 is obtained by considering sets endowed with equivalence relations; equivalent elements are taken to be multiple instances of elements 'of the same kind'. Define a notion of morphism between such enhanced sets, obtaining a category MSet containing (a 'copy' of) Set as a full subcategory. (There may be more than one reasonable way to do this! This is intentionally an open-ended exercise.) Which objects in MSet determine ordinary multisets as defined in Section 2.2 and how? Spell out what a morphism of multisets would be from this point of view. (There are several natural notions of morphisms of multisets. Try to define morphisms in MSet so that the notion you obtain for ordinary multisets captures your intuitive understanding of these objects.)","An alternative to the notion of multiset introduced in Section 2.2 of Aluffi Chapter 0 is obtained by considering sets endowed with equivalence relations; equivalent elements are taken to be multiple instances of elements 'of the same kind'. Define a notion of morphism between such enhanced sets, obtaining a category MSet containing (a 'copy' of) Set as a full subcategory. (There may be more than one reasonable way to do this! This is intentionally an open-ended exercise.) Which objects in MSet determine ordinary multisets as defined in Section 2.2 and how? Spell out what a morphism of multisets would be from this point of view. (There are several natural notions of morphisms of multisets. Try to define morphisms in MSet so that the notion you obtain for ordinary multisets captures your intuitive understanding of these objects.)",,['abstract-algebra']
5,Lie algebra of normal subgroup is an ideal,Lie algebra of normal subgroup is an ideal,,"I want to prove that if $G$ is a connected Lie group, $H$ is a normal Lie subgroup of $G$, $\mathfrak{g}$ and $\mathfrak{h}$ their respective lie algebras, then $\mathfrak{h}$ is an ideal of $\mathfrak{g}$. I try to proceed as follows: Let $X\in\mathfrak{g}$, $Y\in\mathfrak{h}$, we want to compute $[X,Y]$ and show it is in $\mathfrak{h}$. Let $g:(-\varepsilon,\varepsilon)\rightarrow G$ and $h:(-\varepsilon,\varepsilon)\rightarrow H$ with $g(0) = h(0) = e$ be such that $$\left.\frac{d}{dt}\right|_{t=0}g(t) = X$$ and $$\left.\frac{d}{ds}\right|_{s=0}h(s) = Y$$ Then $$[X,Y]=\left.\frac{d}{dt}\right|_{t=0}Ad_{g(t)}Y = \left.\frac{d}{dt}\right|_{t=0}\left.\frac{d}{ds}\right|_{s=0}g(t)h(s)g(t)^{-1}$$ Since $H$ is normal in $G$, we have that $g(t)h(s)g(t)^{-1}=\tilde{h}(s,t)\in H$ for all $t,s$. This means that differentiating $\tilde{h}$ once at the origin gives us an element of $\mathfrak{h}$, but here we have to differentiate it twice! Am I doing something wrong or there is simply a detail I'm not getting?","I want to prove that if $G$ is a connected Lie group, $H$ is a normal Lie subgroup of $G$, $\mathfrak{g}$ and $\mathfrak{h}$ their respective lie algebras, then $\mathfrak{h}$ is an ideal of $\mathfrak{g}$. I try to proceed as follows: Let $X\in\mathfrak{g}$, $Y\in\mathfrak{h}$, we want to compute $[X,Y]$ and show it is in $\mathfrak{h}$. Let $g:(-\varepsilon,\varepsilon)\rightarrow G$ and $h:(-\varepsilon,\varepsilon)\rightarrow H$ with $g(0) = h(0) = e$ be such that $$\left.\frac{d}{dt}\right|_{t=0}g(t) = X$$ and $$\left.\frac{d}{ds}\right|_{s=0}h(s) = Y$$ Then $$[X,Y]=\left.\frac{d}{dt}\right|_{t=0}Ad_{g(t)}Y = \left.\frac{d}{dt}\right|_{t=0}\left.\frac{d}{ds}\right|_{s=0}g(t)h(s)g(t)^{-1}$$ Since $H$ is normal in $G$, we have that $g(t)h(s)g(t)^{-1}=\tilde{h}(s,t)\in H$ for all $t,s$. This means that differentiating $\tilde{h}$ once at the origin gives us an element of $\mathfrak{h}$, but here we have to differentiate it twice! Am I doing something wrong or there is simply a detail I'm not getting?",,"['abstract-algebra', 'differential-geometry', 'lie-groups', 'lie-algebras']"
6,Extension degree of residue field.,Extension degree of residue field.,,"Let $k$ be a field, and $A$ be a finitely generated $k$-algebra with $\text{dim}(A)\leq 1$. Then for any maximal ideal $\mathfrak{m}$ of $A$, does this inequality $[A/\mathfrak{m}:k]<\infty$ hold? Actually, what I really want to know is following; for a scheme $X$ of finite type over $k$ with $\text{dim}(Z)=1$ for any irreducible component $Z$ of $X$. Let $x\in X$ be a closed point, and $k(x)$ be the residue field at $x$. Then $[k(x):k]<\infty$.","Let $k$ be a field, and $A$ be a finitely generated $k$-algebra with $\text{dim}(A)\leq 1$. Then for any maximal ideal $\mathfrak{m}$ of $A$, does this inequality $[A/\mathfrak{m}:k]<\infty$ hold? Actually, what I really want to know is following; for a scheme $X$ of finite type over $k$ with $\text{dim}(Z)=1$ for any irreducible component $Z$ of $X$. Let $x\in X$ be a closed point, and $k(x)$ be the residue field at $x$. Then $[k(x):k]<\infty$.",,"['abstract-algebra', 'algebraic-geometry', 'field-theory']"
7,"As a $\mathbb{Z}$-module, is $\mathbb{R}\otimes_\mathbb{Z} \mathbb{R}$ isomorphic to $\mathbb{R}$?","As a -module, is  isomorphic to ?",\mathbb{Z} \mathbb{R}\otimes_\mathbb{Z} \mathbb{R} \mathbb{R},Is it true that $\mathbb{R}\otimes_\mathbb{Z} \mathbb{R}$ (the tensor product of $\mathbb{R}$ and $\mathbb{R}$ over $\mathbb{Z}$) is not isomorphic to $\mathbb{R}$ as a $\mathbb{Z}$-module?  Please give proof. It is easy to prove that the tensor product of $\mathbb{Q}$ and $\mathbb{Q}$ over $\mathbb{Z}$ is isomorphic to $\mathbb{Q}$ as $\mathbb{Z}$-modules.,Is it true that $\mathbb{R}\otimes_\mathbb{Z} \mathbb{R}$ (the tensor product of $\mathbb{R}$ and $\mathbb{R}$ over $\mathbb{Z}$) is not isomorphic to $\mathbb{R}$ as a $\mathbb{Z}$-module?  Please give proof. It is easy to prove that the tensor product of $\mathbb{Q}$ and $\mathbb{Q}$ over $\mathbb{Z}$ is isomorphic to $\mathbb{Q}$ as $\mathbb{Z}$-modules.,,"['abstract-algebra', 'tensor-products']"
8,A sufficient condition for a domain to be Dedekind?,A sufficient condition for a domain to be Dedekind?,,"We know that in a Dedekind domain, every nonzero ideal admits a unique factorization into a product of prime ideals. I was wondering if this condition is sufficient for a domain to be Dedekind, i.e., if in a domain $D$ every non-zero ideal admits a unique factorization into a product of prime ideals, then is the domain Dedekind? It seems that ""Noetherianness"" of $D$ follows (via the ascending chain condition) if we can show that every non-zero prime ideal of $D$ is maximal. But, I don't know how to prove the latter assertion. Perhaps, one needs Noetherianness of $D$ to prove that $D$ is a dimension $1$ domain. Any help or hint would be appreciated.","We know that in a Dedekind domain, every nonzero ideal admits a unique factorization into a product of prime ideals. I was wondering if this condition is sufficient for a domain to be Dedekind, i.e., if in a domain $D$ every non-zero ideal admits a unique factorization into a product of prime ideals, then is the domain Dedekind? It seems that ""Noetherianness"" of $D$ follows (via the ascending chain condition) if we can show that every non-zero prime ideal of $D$ is maximal. But, I don't know how to prove the latter assertion. Perhaps, one needs Noetherianness of $D$ to prove that $D$ is a dimension $1$ domain. Any help or hint would be appreciated.",,"['commutative-algebra', 'algebraic-number-theory', 'abstract-algebra']"
9,"$G$ is a group, prove: if $[G: Z(G)]<∞$, then $[G, G]$ is finite.","is a group, prove: if , then  is finite.","G [G: Z(G)]<∞ [G, G]","Let $G$ be a group, $Z(G)$ the center of $G$, and $[G, G]$ the commutator subgroup of $G$.  How do I show that if $[G:Z(G)]<\infty$, then $[G.G]$ is finite? How to prove this? I cannot think of a good approach.","Let $G$ be a group, $Z(G)$ the center of $G$, and $[G, G]$ the commutator subgroup of $G$.  How do I show that if $[G:Z(G)]<\infty$, then $[G.G]$ is finite? How to prove this? I cannot think of a good approach.",,"['abstract-algebra', 'group-theory']"
10,Is there a usual method for finding the minimal polynomial of trigonometric values?,Is there a usual method for finding the minimal polynomial of trigonometric values?,,"I've been thinking a bit about finding the minimal polynomials of side lengths of regular $n$-gons inscribed in the unit circle. For example, I recently wanted to find the minimal polynomial of the side length of an inscribed regular nonagon. Using the law of cosines, I was able to find that the side length is $a=\sqrt{2-2\cos(\frac{2\pi}{9})}$. So $\displaystyle \frac{2-a^2}{2}=\cos \left(\frac{2\pi}{9} \right)$, but since I can't express $\displaystyle\cos \left(\frac{2\pi}{9} \right)$ in terms of rational numbers or their square roots, I'm unsure of how to proceed exactly. Is there a usual method to attack values like this? Possibly for say $\displaystyle \cos \left(\frac{m\pi}{n} \right)$? Thanks.","I've been thinking a bit about finding the minimal polynomials of side lengths of regular $n$-gons inscribed in the unit circle. For example, I recently wanted to find the minimal polynomial of the side length of an inscribed regular nonagon. Using the law of cosines, I was able to find that the side length is $a=\sqrt{2-2\cos(\frac{2\pi}{9})}$. So $\displaystyle \frac{2-a^2}{2}=\cos \left(\frac{2\pi}{9} \right)$, but since I can't express $\displaystyle\cos \left(\frac{2\pi}{9} \right)$ in terms of rational numbers or their square roots, I'm unsure of how to proceed exactly. Is there a usual method to attack values like this? Possibly for say $\displaystyle \cos \left(\frac{m\pi}{n} \right)$? Thanks.",,"['abstract-algebra', 'trigonometry', 'polynomials']"
11,When does a semigroup homomorphism preserve identities on monoids?,When does a semigroup homomorphism preserve identities on monoids?,,"Let $X,Y$ be monoids , with identities $e_X,e_Y$ , respectively. Let $f:X\to Y$ be a semigroup homomorphism . That is, any function which satisfies $$f(xy)=f(x)f(y)\quad\forall x,y \in X\tag{1}$$ I know that $f$ is not necessarily a monoid homomorphism , where the definition of a monoid homomorphism is the same as a semigroup homomorphism, but with the additional requirement that it preserve identities: $$f(e_X)=e_Y\tag{2}$$ This second property is required [see, e.g., the discussion in a number of other math.SE threads, such as this one or this one for examples where $(1)$ holds but $(2)$ does not.] The reason I'm interested: In formal language theory, one deals with the set of all finite strings over some alphabet , which forms a monoid under concatenation, with the empty string being the identity (the ""free monoid""). In this area, it is common to state that the identity-preserving property $(2)$ can be derived from the semigroup homomorphism property $(1)$ (see for example Kozen 1997, Lecture 10 , or Kurz's lecture notes, Lecture 7 ).  I know this must be due to something about the structure of this kind of monoid, since it isn't true in general. My question is: what must be true about monoids $X$ and $Y$ such that all semigroup homomorphisms mapping $X$ to $Y$ preserve the identity (and as such are monoid homomorphisms)?","Let be monoids , with identities , respectively. Let be a semigroup homomorphism . That is, any function which satisfies I know that is not necessarily a monoid homomorphism , where the definition of a monoid homomorphism is the same as a semigroup homomorphism, but with the additional requirement that it preserve identities: This second property is required [see, e.g., the discussion in a number of other math.SE threads, such as this one or this one for examples where holds but does not.] The reason I'm interested: In formal language theory, one deals with the set of all finite strings over some alphabet , which forms a monoid under concatenation, with the empty string being the identity (the ""free monoid""). In this area, it is common to state that the identity-preserving property can be derived from the semigroup homomorphism property (see for example Kozen 1997, Lecture 10 , or Kurz's lecture notes, Lecture 7 ).  I know this must be due to something about the structure of this kind of monoid, since it isn't true in general. My question is: what must be true about monoids and such that all semigroup homomorphisms mapping to preserve the identity (and as such are monoid homomorphisms)?","X,Y e_X,e_Y f:X\to Y f(xy)=f(x)f(y)\quad\forall x,y \in X\tag{1} f f(e_X)=e_Y\tag{2} (1) (2) (2) (1) X Y X Y","['abstract-algebra', 'formal-languages', 'semigroups', 'monoid', 'semigroup-homomorphism']"
12,Let $G$ be a group of order $16$ with an element $g$ of order $4$. Prove that the subgroup of $G$ generated by $g^2$ is normal in $G$.,Let  be a group of order  with an element  of order . Prove that the subgroup of  generated by  is normal in .,G 16 g 4 G g^2 G,"Question: Let $G$ be a group of order $16$ with an element $g$ of order $4$ .  Prove that the subgroup of $G$ generated by $g^2$ is normal in $G$ . Thoughts: I keep getting stuck.  My most recent path is that since $G$ is solvable, then there is a subnormal series... so maybe I can get something to come out there?  But I just feel like a counterexample is throwing a wrench into everything I try.  Any help would be greatly appreciated.","Question: Let be a group of order with an element of order .  Prove that the subgroup of generated by is normal in . Thoughts: I keep getting stuck.  My most recent path is that since is solvable, then there is a subnormal series... so maybe I can get something to come out there?  But I just feel like a counterexample is throwing a wrench into everything I try.  Any help would be greatly appreciated.",G 16 g 4 G g^2 G G,"['abstract-algebra', 'group-theory', 'finite-groups', 'normal-subgroups']"
13,"Help to show that $\bigoplus_{i\in\mathbb{N}}\mathbb{Z}\cong\operatorname{Hom}(\prod_{i\in\mathbb{N}}\mathbb{Z},\mathbb{Z})$.",Help to show that .,"\bigoplus_{i\in\mathbb{N}}\mathbb{Z}\cong\operatorname{Hom}(\prod_{i\in\mathbb{N}}\mathbb{Z},\mathbb{Z})","I am trying to show that $\bigoplus_{i\in\mathbb{N}}\mathbb{Z}\cong\operatorname{Hom}(\prod_{i\in\mathbb{N}}\mathbb{Z},\mathbb{Z})$ , as Abelian groups. I know that there is the map $f:\bigoplus_{i\in\mathbb{N}}\mathbb{Z}\rightarrow\operatorname{Hom}(\prod_{i\in\mathbb{N}}\mathbb{Z},\mathbb{Z})$ that takes an element $a=(a_1,a_2,...)$ to the function $f_a:\prod_{i\in\mathbb{N}}\mathbb{Z}\to\mathbb{Z}$ , where $f_a(x_1,x_2,...)=\sum_{i=1}^\infty a_ix_i$ . By definition, every element of $\bigoplus_{i\in\mathbb{N}}\mathbb{Z}$ has only finitely many non-zero entries. This means that the sum in $f_a$ will be of only finitely many non-zero terms and hence always converge, so $f_a$ is well-defined. I am able to show that each $f_a$ is a group homomorphism for every $a$ in $\bigoplus_{i\in\mathbb{N}}\mathbb{Z}$ , and that $f$ defines an injective group homomorphism, but I can't at all see why $f$ is surjective...","I am trying to show that , as Abelian groups. I know that there is the map that takes an element to the function , where . By definition, every element of has only finitely many non-zero entries. This means that the sum in will be of only finitely many non-zero terms and hence always converge, so is well-defined. I am able to show that each is a group homomorphism for every in , and that defines an injective group homomorphism, but I can't at all see why is surjective...","\bigoplus_{i\in\mathbb{N}}\mathbb{Z}\cong\operatorname{Hom}(\prod_{i\in\mathbb{N}}\mathbb{Z},\mathbb{Z}) f:\bigoplus_{i\in\mathbb{N}}\mathbb{Z}\rightarrow\operatorname{Hom}(\prod_{i\in\mathbb{N}}\mathbb{Z},\mathbb{Z}) a=(a_1,a_2,...) f_a:\prod_{i\in\mathbb{N}}\mathbb{Z}\to\mathbb{Z} f_a(x_1,x_2,...)=\sum_{i=1}^\infty a_ix_i \bigoplus_{i\in\mathbb{N}}\mathbb{Z} f_a f_a f_a a \bigoplus_{i\in\mathbb{N}}\mathbb{Z} f f","['abstract-algebra', 'group-theory', 'ring-theory', 'modules', 'abelian-groups']"
14,If $x \in R$ is non-invertible implies $x^2 \in \{\pm x\}$ and $|R| >9$ odd then $R$ is a field,If  is non-invertible implies  and  odd then  is a field,x \in R x^2 \in \{\pm x\} |R| >9 R,"Let $(R, +, \cdot)$ be a commutative ring with $2n+1$ elements, for some $n\neq 4$ a positive integer. Suppose also that $R$ also satisfies the following condition: If an element $x\in R$ is non-invertible, then $x^2 \in \{\pm x\}$ . Prove that $(R,+,\cdot)$ is a field. Here it's my attempt: Suppose $x\in R$ is a non-invertible element, with $x\neq 0$ . Then also, $2x$ is non-invertible, so we have that $x^2 \in \{\pm x\}$ and $4x^2 \in \{\pm 2x\}$ . It follows that $3x=0$ , so $3$ is non-invertible which means that $9\in \{\pm 3\}$ $\Rightarrow$ $3=0$ . How can i continue? I am trying to prove that the ring should have $9$ elements in this case.","Let be a commutative ring with elements, for some a positive integer. Suppose also that also satisfies the following condition: If an element is non-invertible, then . Prove that is a field. Here it's my attempt: Suppose is a non-invertible element, with . Then also, is non-invertible, so we have that and . It follows that , so is non-invertible which means that . How can i continue? I am trying to prove that the ring should have elements in this case.","(R, +, \cdot) 2n+1 n\neq 4 R x\in R x^2 \in \{\pm x\} (R,+,\cdot) x\in R x\neq 0 2x x^2 \in \{\pm x\} 4x^2 \in \{\pm 2x\} 3x=0 3 9\in \{\pm 3\} \Rightarrow 3=0 9","['abstract-algebra', 'ring-theory', 'finite-rings']"
15,Confused about the splitting of 2 in $\mathbb{Q}(i).$,Confused about the splitting of 2 in,\mathbb{Q}(i).,"How do we split 2 in the cyclotomic ring $S = \mathbb{Z}[\sqrt{-1}]?$ Clearly the field $\mathbb{Q}(i)$ is a degree 2 normal extension. However, $(2)$ in $S$ is equal to $(2) = (1 - i)^2.$ Thus, the ideal cannot split anymore so we can deduce that $(1 - i)$ is in fact a prime ideal. But $S$ is a Dedekind domain and $(1 - i)$ is not a maximal ideal...I say this because $S/(1 - i) \cong \mathbb{Z}.$ Did I mistakenly assume that $\mathbb{Z}[i]/(1 - i) \cong \mathbb{Z}?$","How do we split 2 in the cyclotomic ring Clearly the field is a degree 2 normal extension. However, in is equal to Thus, the ideal cannot split anymore so we can deduce that is in fact a prime ideal. But is a Dedekind domain and is not a maximal ideal...I say this because Did I mistakenly assume that",S = \mathbb{Z}[\sqrt{-1}]? \mathbb{Q}(i) (2) S (2) = (1 - i)^2. (1 - i) S (1 - i) S/(1 - i) \cong \mathbb{Z}. \mathbb{Z}[i]/(1 - i) \cong \mathbb{Z}?,"['abstract-algebra', 'algebraic-number-theory']"
16,Finitely generated nilpotent group where every element is of finite order is finite,Finitely generated nilpotent group where every element is of finite order is finite,,"Let $G = \langle g_1,g_2,\ldots,g_m\rangle$ be a nilpotent group, where each $g_i$ has finite order.  Prove $G$ is finite. I'd like to show this by showing that the lower central series has successive quotients that are finite, i.e., $$|\gamma_n(G) / \gamma_{n+1}(G)| < \infty$$ I'm going to show this by induction.  I'm on the base case $$\gamma_1(G)/\gamma_2(G) = G/[G,G]$$ Any reason why this should be finite?  Any idea how I can argue that $\gamma_{n+1}(G) / \gamma_{n+2}(G)$ should be finite in the inductive step, assuming $\gamma_n(G) / \gamma_{n+1}(G)$ is finite?","Let $G = \langle g_1,g_2,\ldots,g_m\rangle$ be a nilpotent group, where each $g_i$ has finite order.  Prove $G$ is finite. I'd like to show this by showing that the lower central series has successive quotients that are finite, i.e., $$|\gamma_n(G) / \gamma_{n+1}(G)| < \infty$$ I'm going to show this by induction.  I'm on the base case $$\gamma_1(G)/\gamma_2(G) = G/[G,G]$$ Any reason why this should be finite?  Any idea how I can argue that $\gamma_{n+1}(G) / \gamma_{n+2}(G)$ should be finite in the inductive step, assuming $\gamma_n(G) / \gamma_{n+1}(G)$ is finite?",,"['abstract-algebra', 'group-theory', 'finitely-generated']"
17,"Given a ring, when can I find a field that extends it making it a subring?","Given a ring, when can I find a field that extends it making it a subring?",,"My question is the following one. Given a ring $A$, when can I find a field $B$ such that $A$ is a subring of $B$? Of course, if $A$ is not a domain this is imposible because there would be two non-trivial elements in $A$ (so they would be also in $B$) with trivial product. However, there are some examples that this can be made. For instance, if I begin with $\mathbb{Z}$ I can find a field that contains it as subring (for instance $\mathbb{Q}$). Is this possible for any ring which is a domain? If not, is there some sufficient hypothesis to make this hold? Thank you.","My question is the following one. Given a ring $A$, when can I find a field $B$ such that $A$ is a subring of $B$? Of course, if $A$ is not a domain this is imposible because there would be two non-trivial elements in $A$ (so they would be also in $B$) with trivial product. However, there are some examples that this can be made. For instance, if I begin with $\mathbb{Z}$ I can find a field that contains it as subring (for instance $\mathbb{Q}$). Is this possible for any ring which is a domain? If not, is there some sufficient hypothesis to make this hold? Thank you.",,"['abstract-algebra', 'ring-theory', 'field-theory']"
18,When does intersection commute with tensor product,When does intersection commute with tensor product,,"Given two submodules $U,V \subseteq M$ over a (commutative) ring $R$, and a flat $R$-module $A$, I can interpret $U \otimes_R A$ and $V \otimes_R A$ as submodules of $M \otimes_R A$. Is it necessarily true that $$(U \cap V) \otimes_R A \cong (U \otimes_R A) \cap (V \otimes_R A) ?$$ I think it should be true in many cases, with intuition coming from $\mathbb{Z}$-modules and $A = \mathbb{Q}$, but I'm unsure about what happens in general.","Given two submodules $U,V \subseteq M$ over a (commutative) ring $R$, and a flat $R$-module $A$, I can interpret $U \otimes_R A$ and $V \otimes_R A$ as submodules of $M \otimes_R A$. Is it necessarily true that $$(U \cap V) \otimes_R A \cong (U \otimes_R A) \cap (V \otimes_R A) ?$$ I think it should be true in many cases, with intuition coming from $\mathbb{Z}$-modules and $A = \mathbb{Q}$, but I'm unsure about what happens in general.",,"['abstract-algebra', 'commutative-algebra', 'modules', 'tensor-products', 'flatness']"
19,"Burnside group $B(2, 3)$, how to see has $27$ elements and isomorphic to certain group?","Burnside group , how to see has  elements and isomorphic to certain group?","B(2, 3) 27","The Burnside group $B(d, n)$ is defined as the quotient of the free group on $d$ generators by the normal subgroup generated by all $n$th powers. Question. How do I see that $B(2, 3)$ has $27$ elements and is isomorphic to the group of matrices of the form$$\begin{pmatrix} 1 & x & y \\ 0 & 1 & z \\ 0 & 0 & 1 \end{pmatrix}$$for $x,y,z\in\mathbb{F}_3$?","The Burnside group $B(d, n)$ is defined as the quotient of the free group on $d$ generators by the normal subgroup generated by all $n$th powers. Question. How do I see that $B(2, 3)$ has $27$ elements and is isomorphic to the group of matrices of the form$$\begin{pmatrix} 1 & x & y \\ 0 & 1 & z \\ 0 & 0 & 1 \end{pmatrix}$$for $x,y,z\in\mathbb{F}_3$?",,['abstract-algebra']
20,"If every intermediate ring of a field extension is a field, then the extension is algebraic","If every intermediate ring of a field extension is a field, then the extension is algebraic",,"Suppose $E/F$ is an extension of fields. Prove that if every ring $R$ with $F\subseteq R\subseteq E$ is a field, then $E/F$ is an algebraic extension. I can show the converse is true by demonstrating that the inverses of elements of $R$ are also in $R$ , but I have no idea where to start for this one.","Suppose is an extension of fields. Prove that if every ring with is a field, then is an algebraic extension. I can show the converse is true by demonstrating that the inverses of elements of are also in , but I have no idea where to start for this one.",E/F R F\subseteq R\subseteq E E/F R R,['abstract-algebra']
21,Field with four elements,Field with four elements,,"If $F=\{0,1,a,b\}$ is a field (where the four elements are distinct), then: What is the characteristic of $F$ ? Write $b$ in terms of the other elements. What are the multiplication and addition tableau of these operations?","If is a field (where the four elements are distinct), then: What is the characteristic of ? Write in terms of the other elements. What are the multiplication and addition tableau of these operations?","F=\{0,1,a,b\} F b","['abstract-algebra', 'finite-fields']"
22,Is it true that a ring has no zero divisors iff the right and left cancellation laws hold?,Is it true that a ring has no zero divisors iff the right and left cancellation laws hold?,,"This is the definition of zero divisor in Hungerford's Algebra : A zero divisor is an element of $R$ which is BOTH a left and a right zero divisor. It follows a statement: It is easy to verify that a ring $R$ has no zero divisors  if and only if the right and left cancellation laws hold in $R$; that is,  for all $a,b,c\in R$ with $a\neq 0$,  $$ab=ac~~~\text{ or }~~~ba=ca~~~\Rightarrow~~~ b=c.$$ I think it is not true. But I can't find a counterexample.","This is the definition of zero divisor in Hungerford's Algebra : A zero divisor is an element of $R$ which is BOTH a left and a right zero divisor. It follows a statement: It is easy to verify that a ring $R$ has no zero divisors  if and only if the right and left cancellation laws hold in $R$; that is,  for all $a,b,c\in R$ with $a\neq 0$,  $$ab=ac~~~\text{ or }~~~ba=ca~~~\Rightarrow~~~ b=c.$$ I think it is not true. But I can't find a counterexample.",,"['abstract-algebra', 'ring-theory']"
23,"Prove that $G = \langle x,y\ |\ x^2=y^2 \rangle $ is torsion-free.",Prove that  is torsion-free.,"G = \langle x,y\ |\ x^2=y^2 \rangle ","Prove that $G = \langle x,y\ |\ x^2=y^2 \rangle $ is torsion-free. Here $x^2$ is central as $x^2y=yx^2$ similarly $y^2$ is central. Apart from this  I do not know how to proceed. Taking any arbitrary word in $G$ does not help.",Prove that is torsion-free. Here is central as similarly is central. Apart from this  I do not know how to proceed. Taking any arbitrary word in does not help.,"G = \langle x,y\ |\ x^2=y^2 \rangle  x^2 x^2y=yx^2 y^2 G","['abstract-algebra', 'group-theory']"
24,Proving that $SL_2(\mathbb{Z}_5) / \{\pm I\}\simeq A_5$,Proving that,SL_2(\mathbb{Z}_5) / \{\pm I\}\simeq A_5,"I see here that one can prove that $$ SL_2(\mathbb{Z}_5) / \{\pm I\} \simeq A_5 $$ using the First Isomorphism Theorem. My question is how one would do that. I know that I need a surjective homomorphism  $$ T: SL_2(\mathbb{Z}_5) \to A_5 $$ with kernel $\{\pm I\}$. The only homomorphism I have come across with matrix groups is the determinant map, so my question is what homomorphism would work here.","I see here that one can prove that $$ SL_2(\mathbb{Z}_5) / \{\pm I\} \simeq A_5 $$ using the First Isomorphism Theorem. My question is how one would do that. I know that I need a surjective homomorphism  $$ T: SL_2(\mathbb{Z}_5) \to A_5 $$ with kernel $\{\pm I\}$. The only homomorphism I have come across with matrix groups is the determinant map, so my question is what homomorphism would work here.",,"['abstract-algebra', 'matrices', 'finite-fields', 'group-isomorphism']"
25,Is a finitely generated torsion-free module over a UFD necessarily free?,Is a finitely generated torsion-free module over a UFD necessarily free?,,Is a finitely generated torsion-free module over a unique factorization domain necessarily free ?,Is a finitely generated torsion-free module over a unique factorization domain necessarily free ?,,['abstract-algebra']
26,Characterize the commutative rings with trivial group of units,Characterize the commutative rings with trivial group of units,,"This question suggested me the following: Characterize the commutative unitary rings $R$ with trivial group of units, that is, $R^{\times}=\{1\}$. The local case was solved here long time ago and it's very simple. In general, such a ring must have characteristic $2$ and the Jacobson radical $J(R)=(0)$. At present I know two classes of examples: direct products of $\mathbb Z/2\mathbb Z$ and polynomial rings over $\mathbb Z/2\mathbb Z$. (One can also ask for such a characterization in the non-commutative case, but I'm primarily interested in the commutative setting.)","This question suggested me the following: Characterize the commutative unitary rings $R$ with trivial group of units, that is, $R^{\times}=\{1\}$. The local case was solved here long time ago and it's very simple. In general, such a ring must have characteristic $2$ and the Jacobson radical $J(R)=(0)$. At present I know two classes of examples: direct products of $\mathbb Z/2\mathbb Z$ and polynomial rings over $\mathbb Z/2\mathbb Z$. (One can also ask for such a characterization in the non-commutative case, but I'm primarily interested in the commutative setting.)",,"['abstract-algebra', 'commutative-algebra']"
27,Short method to prove the irreducibility of $x^7+21x^5+35x^2+34x-8$ over $\Bbb Q$,Short method to prove the irreducibility of  over,x^7+21x^5+35x^2+34x-8 \Bbb Q,"I am given a task to prove that polynomial $f=x^7+21x^5+35x^2+34x-8$ is irreducible over $\Bbb Q$. In my algebra course we learnt reduction and Eisenstein criterion. Eisenstein doesn't seem to work out here, as well as reduction criterion in $\Bbb F_2$. So I could use reduction criterion with $\Bbb F_3$, but then I would have to prove irreducibility by around 20 polynomial divisions (divide $f$ by all irreducible polynomials of degree less than 4). It isn't that hard, but I wanted to find out whether there is a smarter method to irreducibility in this case? Thank you in advance!","I am given a task to prove that polynomial $f=x^7+21x^5+35x^2+34x-8$ is irreducible over $\Bbb Q$. In my algebra course we learnt reduction and Eisenstein criterion. Eisenstein doesn't seem to work out here, as well as reduction criterion in $\Bbb F_2$. So I could use reduction criterion with $\Bbb F_3$, but then I would have to prove irreducibility by around 20 polynomial divisions (divide $f$ by all irreducible polynomials of degree less than 4). It isn't that hard, but I wanted to find out whether there is a smarter method to irreducibility in this case? Thank you in advance!",,"['abstract-algebra', 'polynomials', 'ring-theory', 'field-theory']"
28,Subgroups containing kernel of group morphism to an abelian group are normal. [closed],Subgroups containing kernel of group morphism to an abelian group are normal. [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $\varphi:G\rightarrow H$ be a group homomorphism from group $G$ to group $H$. Show that, if $H$ is abelian, all subgroups of $G$ that contain $\mathrm{ker} (\varphi)$ are normal in $G$.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $\varphi:G\rightarrow H$ be a group homomorphism from group $G$ to group $H$. Show that, if $H$ is abelian, all subgroups of $G$ that contain $\mathrm{ker} (\varphi)$ are normal in $G$.",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'normal-subgroups', 'group-homomorphism']"
29,Need for inverse in $1-1$ correspondence between left coset and right coset of a group,Need for inverse in  correspondence between left coset and right coset of a group,1-1,"I was trying to solve the problem to show that there is a one-to-one correspondence between the set of left cosets of H in G and the set of right cosets. I attempted to prove it by creating a function mapping aH to Ha as follows: $f(ah) = ha$. I reasoned that is bijective as $h'a = ha$ implies $ah = ah'$, and given $ha$, we know that $f(ah) = ha$. However all of the proofs I found on the internet mapped ah to $ha^{-1}$. Can anyone explain why it is necessary to use the inverse?","I was trying to solve the problem to show that there is a one-to-one correspondence between the set of left cosets of H in G and the set of right cosets. I attempted to prove it by creating a function mapping aH to Ha as follows: $f(ah) = ha$. I reasoned that is bijective as $h'a = ha$ implies $ah = ah'$, and given $ha$, we know that $f(ah) = ha$. However all of the proofs I found on the internet mapped ah to $ha^{-1}$. Can anyone explain why it is necessary to use the inverse?",,"['abstract-algebra', 'group-theory']"
30,Inner automorphism of a subgroup,Inner automorphism of a subgroup,,"Dummit & Foote defines inner automorphism as : Let $G$ be a group and let $g \in G$. Conjugation by $g$ is called an inner automorphism of $G$. Later they say: If $H$ is a normal subgroup of G, conjugation of an element when restricted to H is an automorphism of H, but need not be an inner automorphism of H. I don't understand why this should be true, inner automorphism is itself defined as conjugation by an element. Is the restriction to $H$ placed on the element carrying out the conjugation, or the elements on which are conjugated? Later an examples is given of the Klein 4-group, as the normal subgroup of $A_4$, and conjugation defined by an 3-cycle. So the restriction is not on the element defining the conjugation So why isnt the automorphism of H, an inner automorphism?","Dummit & Foote defines inner automorphism as : Let $G$ be a group and let $g \in G$. Conjugation by $g$ is called an inner automorphism of $G$. Later they say: If $H$ is a normal subgroup of G, conjugation of an element when restricted to H is an automorphism of H, but need not be an inner automorphism of H. I don't understand why this should be true, inner automorphism is itself defined as conjugation by an element. Is the restriction to $H$ placed on the element carrying out the conjugation, or the elements on which are conjugated? Later an examples is given of the Klein 4-group, as the normal subgroup of $A_4$, and conjugation defined by an 3-cycle. So the restriction is not on the element defining the conjugation So why isnt the automorphism of H, an inner automorphism?",,['abstract-algebra']
31,Do properties of algebraic structures sometimes not carry over when their direct products are taken?,Do properties of algebraic structures sometimes not carry over when their direct products are taken?,,"I recently had a homework problem asking to prove that the direct product of rings (or rings with identity) are still rings (with identity), and it seemed really silly to go through all the steps in order to conclude what was extremely trivial. My question is, are there instances when this is not the case? Are there certain properties, or certain algebraic structures whereupon taking their direct products doesn't maintain the original algebraic structure/properties?","I recently had a homework problem asking to prove that the direct product of rings (or rings with identity) are still rings (with identity), and it seemed really silly to go through all the steps in order to conclude what was extremely trivial. My question is, are there instances when this is not the case? Are there certain properties, or certain algebraic structures whereupon taking their direct products doesn't maintain the original algebraic structure/properties?",,"['abstract-algebra', 'ring-theory']"
32,Does the Symmetric difference operator define a group on the powerset of a set?,Does the Symmetric difference operator define a group on the powerset of a set?,,"$G$ is the set of all subsets of a set $A$, under the operation of $\triangle\;$: Symmetric Difference of sets. $A$ has at least two different elements. I need to check if this is a group, and if it does to show if the group is abelian and/or finite. Associativity - easy from Symmetric Difference. Identity element - empty group. Inverse element - each element is inverse to itself. Am I right? abelian? finite?","$G$ is the set of all subsets of a set $A$, under the operation of $\triangle\;$: Symmetric Difference of sets. $A$ has at least two different elements. I need to check if this is a group, and if it does to show if the group is abelian and/or finite. Associativity - easy from Symmetric Difference. Identity element - empty group. Inverse element - each element is inverse to itself. Am I right? abelian? finite?",,"['abstract-algebra', 'group-theory']"
33,Finding all groups with $\text{Aut}(G)=\{1\}$ [duplicate],Finding all groups with  [duplicate],\text{Aut}(G)=\{1\},"This question already has answers here : Closed 11 years ago . Possible Duplicate: $|G|>2$ implies $G$ has non trivial automorphism I am doing this exercise: Find all groups $G$, with $\text{Aut}(G)=\{1\}$. What has been clear to me is the group $G$ should be abelian group. Because we will have $G=Z(G)$ and I see that at least all $\phi_g(x)=g^{-1}xg$ are just identity. Any help is appreciated!","This question already has answers here : Closed 11 years ago . Possible Duplicate: $|G|>2$ implies $G$ has non trivial automorphism I am doing this exercise: Find all groups $G$, with $\text{Aut}(G)=\{1\}$. What has been clear to me is the group $G$ should be abelian group. Because we will have $G=Z(G)$ and I see that at least all $\phi_g(x)=g^{-1}xg$ are just identity. Any help is appreciated!",,"['abstract-algebra', 'group-theory']"
34,The existence of a polynomial of degree $n$ with $m$ real roots when $m\equiv n \pmod 2$.,The existence of a polynomial of degree  with  real roots when .,n m m\equiv n \pmod 2,"I came across the following fact: Let $m$ and $n$ be natural numbers such that $n\geqslant m$ and $m\equiv n \pmod 2$. Then, there exists an irreducible polynomial  $f\in\mathbb{Q}\left[X\right]$ of degree $n$  such that $f$ has exactly $m$ real roots. I guess it is well known for algebraists. Unfortunately, I cannot find the proof of this anywhere and I do not know how to prove it. Could you help me?","I came across the following fact: Let $m$ and $n$ be natural numbers such that $n\geqslant m$ and $m\equiv n \pmod 2$. Then, there exists an irreducible polynomial  $f\in\mathbb{Q}\left[X\right]$ of degree $n$  such that $f$ has exactly $m$ real roots. I guess it is well known for algebraists. Unfortunately, I cannot find the proof of this anywhere and I do not know how to prove it. Could you help me?",,"['abstract-algebra', 'polynomials']"
35,What is the intuition behind the proof of Abel-Ruffini theorem in abstract algebra?,What is the intuition behind the proof of Abel-Ruffini theorem in abstract algebra?,,"Is there a way to explain this proof in Wikipedia without knowing the abstract algebra too much or deep function experience? In addition, I don't how the abstract algebra work even after I look at an introductory abstract algebra book, if you can't take your time to explain the whole thing, may you give some preliminary reference for your explanation? Or may you give hints in a way that is a list of fact would be helpful to the proof and verify it for me please.","Is there a way to explain this proof in Wikipedia without knowing the abstract algebra too much or deep function experience? In addition, I don't how the abstract algebra work even after I look at an introductory abstract algebra book, if you can't take your time to explain the whole thing, may you give some preliminary reference for your explanation? Or may you give hints in a way that is a list of fact would be helpful to the proof and verify it for me please.",,"['abstract-algebra', 'algebra-precalculus', 'reference-request', 'intuition']"
36,Convergent rational series: which ones remain rational?,Convergent rational series: which ones remain rational?,,"Due to closure under addition, it is obvious that a finite sum of rationals is rational. The infinite ones, however (assuming they don't diverge), may remain rational, such as $\sum_{n \in \mathbb{N}} 2^{-n}$, or not, like $\sum_{n \in \mathbb{N}} n^{-2}$. Is there a criterion to find out whether a (convergent) series of rationals is rational or irrational without calculating it? P. S. : insights on the analogous question with infinite products are welcome.","Due to closure under addition, it is obvious that a finite sum of rationals is rational. The infinite ones, however (assuming they don't diverge), may remain rational, such as $\sum_{n \in \mathbb{N}} 2^{-n}$, or not, like $\sum_{n \in \mathbb{N}} n^{-2}$. Is there a criterion to find out whether a (convergent) series of rationals is rational or irrational without calculating it? P. S. : insights on the analogous question with infinite products are welcome.",,"['abstract-algebra', 'algebra-precalculus']"
37,Faithful representations and character tables,Faithful representations and character tables,,"Suppose an n-dimensional irreducible complex representation is not faithful.  Then a non-identity element gets mapped to the identity matrix in $GL_n(\mathbb{C})$ so that the value of its associated character on the conjugacy class of this element is $n$.  Thus, $n$ appears at least twice in the corresponding row of the group's character table. I suspect the converse is true: if the row corresponding to an irreducible $n$-dimensional complex representation contains the dimension of the representation in more than one column, then the representation is not faithful.  I have looked in a few of the standard algebra references and have been unable to find a proof.  Can anyone point me in the right direction?  We proved this for $n=2$, but it seems that it would be difficult and messy to generalize.  I wonder if there is a simpler proof.","Suppose an n-dimensional irreducible complex representation is not faithful.  Then a non-identity element gets mapped to the identity matrix in $GL_n(\mathbb{C})$ so that the value of its associated character on the conjugacy class of this element is $n$.  Thus, $n$ appears at least twice in the corresponding row of the group's character table. I suspect the converse is true: if the row corresponding to an irreducible $n$-dimensional complex representation contains the dimension of the representation in more than one column, then the representation is not faithful.  I have looked in a few of the standard algebra references and have been unable to find a proof.  Can anyone point me in the right direction?  We proved this for $n=2$, but it seems that it would be difficult and messy to generalize.  I wonder if there is a simpler proof.",,['abstract-algebra']
38,Adjoining a function to a ring: what is this called?,Adjoining a function to a ring: what is this called?,,"There's a kind of construction of an extension of a ring, and that I've seen used e.g. here (although that may not be the best example) which is essentially adding a function into the ring, and taking the closure under the function. So for every element $r$ in $R_0$ you would adjoin elements $f(r)$ with no relations to make $R_1$ , and do this again to $R_1$ to make $R_2$ etc. so that $R_\omega$ , the limit of these, is closed under a free unary operation $f$ . I hope I have described this clearly. I would like to know what the terminology here is, and where I can learn more about using this construction and generalisations of it. E.g. with what I currently know, even defining a quotient by a relation, like $f(0)=1$ seems very messy, as you have to be able to describe all the other elements in the ring that have $f(0)$ as part of their construction. So I want to see how this is usually dealt with, and if there's a convenient way of defining variations like that which makes it easy to work with. Worse, proving that any two things aren't equal after taking a massive quotient seems a near-impossible task, but I'm sure there are neat ways of doing it that I'm just not aware of. Edit: @diracdeltafunk provided a nice universal property that makes this easier to work with. I would still like a reference for where to learn more about constructions like this, though.","There's a kind of construction of an extension of a ring, and that I've seen used e.g. here (although that may not be the best example) which is essentially adding a function into the ring, and taking the closure under the function. So for every element in you would adjoin elements with no relations to make , and do this again to to make etc. so that , the limit of these, is closed under a free unary operation . I hope I have described this clearly. I would like to know what the terminology here is, and where I can learn more about using this construction and generalisations of it. E.g. with what I currently know, even defining a quotient by a relation, like seems very messy, as you have to be able to describe all the other elements in the ring that have as part of their construction. So I want to see how this is usually dealt with, and if there's a convenient way of defining variations like that which makes it easy to work with. Worse, proving that any two things aren't equal after taking a massive quotient seems a near-impossible task, but I'm sure there are neat ways of doing it that I'm just not aware of. Edit: @diracdeltafunk provided a nice universal property that makes this easier to work with. I would still like a reference for where to learn more about constructions like this, though.",r R_0 f(r) R_1 R_1 R_2 R_\omega f f(0)=1 f(0),"['abstract-algebra', 'ring-theory', 'reference-request', 'universal-algebra']"
39,What makes the 'special groups' ($\det A = 1$) special?,What makes the 'special groups' () special?,\det A = 1,"This is a rather basic, and open-ended question: in several branches of mathematics and physics, we make an effort to classify linear operators $A$ , especially orthogonal or unitary operators, by whether or not they have unit-determinant $\det A = 1$ , i.e. whether they are special or not. E.g., the special orthogonal group $\operatorname{SO}(N)$ is a subset of the orthogonal group $\operatorname{O}(N)$ and the special unitary group $\operatorname{SU}(N)$ is a subset of the unitary group $\operatorname{U}(N)$ . At the most basic level: Why are we often more (or especially) interested in these special operators? When acting on a vector, which quantities do the special operators leave invariant? What, if any, additional constraints are made on e.g. the spectrum of such special operators?","This is a rather basic, and open-ended question: in several branches of mathematics and physics, we make an effort to classify linear operators , especially orthogonal or unitary operators, by whether or not they have unit-determinant , i.e. whether they are special or not. E.g., the special orthogonal group is a subset of the orthogonal group and the special unitary group is a subset of the unitary group . At the most basic level: Why are we often more (or especially) interested in these special operators? When acting on a vector, which quantities do the special operators leave invariant? What, if any, additional constraints are made on e.g. the spectrum of such special operators?",A \det A = 1 \operatorname{SO}(N) \operatorname{O}(N) \operatorname{SU}(N) \operatorname{U}(N),"['abstract-algebra', 'group-theory', 'lie-groups', 'algebraic-groups']"
40,Why is the Petersen graph no Cayley graph?,Why is the Petersen graph no Cayley graph?,,"On the Wikipedia page of the Petersen graph it is mentioned that it is not a Cayley graph. How it this proved? Honestly I don't even know how to start this. The only criteria I can think of is that all vertices must have the same degree. Also the degree being odd should imply that one generator of the group has order 2. But then how do I proceed? Edit: As already mentioned in the comments, the link did not answer my question.","On the Wikipedia page of the Petersen graph it is mentioned that it is not a Cayley graph. How it this proved? Honestly I don't even know how to start this. The only criteria I can think of is that all vertices must have the same degree. Also the degree being odd should imply that one generator of the group has order 2. But then how do I proceed? Edit: As already mentioned in the comments, the link did not answer my question.",,"['abstract-algebra', 'group-theory', 'graph-theory', 'geometric-group-theory', 'cayley-graphs']"
41,Ring of Invariants of $A_3$,Ring of Invariants of,A_3,"It is well know that the ring of invariants of the permutation group of three elemetns $S_3$ is given by the elementary symmetric polynomials, i.e. $$\mathbb C[x,y,z]^{S_3} = \mathbb C[s_1,s_2,s_3]$$ where $$s_1 = x+y+z$$ $$s_2=xy + yz + zx$$ $$s_3= xyz.$$ Which is the ring of invariants of $A_3$, the alternating subroup of $S_3$, made of even permutations? Of course it contains $s_1, s_2, s_3$. It also contains $$d=(x-y)(y-z)(z-x).$$ They are not algebrically independent because $d^2 \in \mathbb C[s_1,s_2,s_3]$. How can we prove that these $4$ polynomials generate the whole ring of invariants? Which is a basis of algebrically independent generators, if any?","It is well know that the ring of invariants of the permutation group of three elemetns $S_3$ is given by the elementary symmetric polynomials, i.e. $$\mathbb C[x,y,z]^{S_3} = \mathbb C[s_1,s_2,s_3]$$ where $$s_1 = x+y+z$$ $$s_2=xy + yz + zx$$ $$s_3= xyz.$$ Which is the ring of invariants of $A_3$, the alternating subroup of $S_3$, made of even permutations? Of course it contains $s_1, s_2, s_3$. It also contains $$d=(x-y)(y-z)(z-x).$$ They are not algebrically independent because $d^2 \in \mathbb C[s_1,s_2,s_3]$. How can we prove that these $4$ polynomials generate the whole ring of invariants? Which is a basis of algebrically independent generators, if any?",,"['abstract-algebra', 'group-theory', 'ring-theory', 'invariant-theory']"
42,Reference for group cohomology,Reference for group cohomology,,"I would like to know more about group cohomology. I know that there are chapters about group cohomology in some group theory textbooks, for example in Rotman's. However my PhD asvisor told me that he did not really like the way in which it was presented, but could not give my any other reference. I was also wondering if there is some text completely devoted to an introduction to group cohomology...","I would like to know more about group cohomology. I know that there are chapters about group cohomology in some group theory textbooks, for example in Rotman's. However my PhD asvisor told me that he did not really like the way in which it was presented, but could not give my any other reference. I was also wondering if there is some text completely devoted to an introduction to group cohomology...",,"['abstract-algebra', 'group-theory', 'reference-request', 'homology-cohomology', 'group-cohomology']"
43,Galois theory and cryptography,Galois theory and cryptography,,I'm trying to find applications of Galois theory in different areas. Currently the most interesting for me is the cryptography. As I understood the theory of finite fields (a part of Galois theory) has a strong connection with cryptography. My question is the following: Is there an important cryptographic problem that cannot be solved without the Galois theory application?,I'm trying to find applications of Galois theory in different areas. Currently the most interesting for me is the cryptography. As I understood the theory of finite fields (a part of Galois theory) has a strong connection with cryptography. My question is the following: Is there an important cryptographic problem that cannot be solved without the Galois theory application?,,"['abstract-algebra', 'galois-theory', 'finite-fields', 'cryptography']"
44,The intersection of an infinite number of prime ideals in a ring of integers,The intersection of an infinite number of prime ideals in a ring of integers,,"Let $\mathcal{O}$ be the ring of integers of a number field, $\{\mathfrak{p}_i,\,i \in \mathbb{N}\}$ a sequence of two-by-two pairwise distinct prime ideals. Does it follow that$$\bigcap_i \mathfrak{p}_i = \{0\}?$$","Let $\mathcal{O}$ be the ring of integers of a number field, $\{\mathfrak{p}_i,\,i \in \mathbb{N}\}$ a sequence of two-by-two pairwise distinct prime ideals. Does it follow that$$\bigcap_i \mathfrak{p}_i = \{0\}?$$",,['abstract-algebra']
45,Rudin Ex 2.2: Proving countability of algebraic numbers with a hint,Rudin Ex 2.2: Proving countability of algebraic numbers with a hint,,"NOTE: I know that countability of algebraic numbers has been proven on this site before, but I'm concerned about this specific hint they give and I don't know how to prove it using that advice. I am solving an exercise in Rudin to prove that the set of algebraic numbers is countable. In particular, A complex number is said to be algebraic if there are integers $a_0, \dots, a_n$ , not all $0$ , such that $a_0 z^n + a_1 z^{n-1} + \dots + a_n = 0$ . Prove that the set of all algebraic numbers is countable. Hint: For every positive integer $N$ there are only finitely many equations with $n + |a_0| + |a_1| + \dots + |a_n| = N$ I have proven the statement using essentially the method in this post , but I'm curious as to how one can use the hint to prove the statement.","NOTE: I know that countability of algebraic numbers has been proven on this site before, but I'm concerned about this specific hint they give and I don't know how to prove it using that advice. I am solving an exercise in Rudin to prove that the set of algebraic numbers is countable. In particular, A complex number is said to be algebraic if there are integers , not all , such that . Prove that the set of all algebraic numbers is countable. Hint: For every positive integer there are only finitely many equations with I have proven the statement using essentially the method in this post , but I'm curious as to how one can use the hint to prove the statement.","a_0, \dots, a_n 0 a_0 z^n + a_1 z^{n-1} + \dots + a_n = 0 N n + |a_0| + |a_1| + \dots + |a_n| = N","['abstract-algebra', 'elementary-set-theory']"
46,"Show that $\mathbb{A}^n$ on the Zariski Topology is not Hausdorff, but it is $T_1$","Show that  on the Zariski Topology is not Hausdorff, but it is",\mathbb{A}^n T_1,"There was an exercise I could not do. So the property is $T_1$ if for every pair of distinct points, $P, Q \in X$, there is an open subset $U$ containing $P$ but not $Q$ and another open subset $V$ containing $Q$ but not $P$. So I was asked to show if the base field is infinite, then $\mathbb{A}^n$ is $T_1$ but not Hausdorff. I can show that it's not Hausdorff (I believe this is right). So let $k$ be an infinite field, then we have $U$ and $V$ which are two nonempty subsets which are open, thus $U^c$ and $V^c$ finite so by Demorgan's law we have $(U \cap V)^c =U^c \cup V^c$ which is also finite, so this implies that $U\cap V$ is non-empty so it can't be Hausdorff. But I can't seem to really show that it's $T_1$ Any ideas how to approach this? Thank you.","There was an exercise I could not do. So the property is $T_1$ if for every pair of distinct points, $P, Q \in X$, there is an open subset $U$ containing $P$ but not $Q$ and another open subset $V$ containing $Q$ but not $P$. So I was asked to show if the base field is infinite, then $\mathbb{A}^n$ is $T_1$ but not Hausdorff. I can show that it's not Hausdorff (I believe this is right). So let $k$ be an infinite field, then we have $U$ and $V$ which are two nonempty subsets which are open, thus $U^c$ and $V^c$ finite so by Demorgan's law we have $(U \cap V)^c =U^c \cup V^c$ which is also finite, so this implies that $U\cap V$ is non-empty so it can't be Hausdorff. But I can't seem to really show that it's $T_1$ Any ideas how to approach this? Thank you.",,"['abstract-algebra', 'general-topology', 'algebraic-geometry']"
47,How do I find out if a polynomial is irreducible?,How do I find out if a polynomial is irreducible?,,I have this polynomial: $f(x)=x^4+x^3-4x^2-5x-5$ . How can I find out if this polynomial is irreducible over the field $\mathbb{Q}$ of rational numbers? I know about mod $p$ irreducibility test but it fails in this case. In general how do you find out if a polynomial is irreducible or prove that it is reducible?,I have this polynomial: . How can I find out if this polynomial is irreducible over the field of rational numbers? I know about mod irreducibility test but it fails in this case. In general how do you find out if a polynomial is irreducible or prove that it is reducible?,f(x)=x^4+x^3-4x^2-5x-5 \mathbb{Q} p,"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
48,Is abstract algebra (mostly?) restricted to $2$-ary operators?,Is abstract algebra (mostly?) restricted to -ary operators?,2,"This may be due to my own pure ignorance but it's my experience that all abstract algebra I've been introduced to, both in actual courses and in self-studies only exclusively deals with algebraic objects consisting of a set together with one or more binary operators defined on that set, perhaps over some other algebraic structure. Not counting categories here, just ""low-level""-ish stuff. I'm an undergraduate so my knowledge is of course very limited but I can't help to wonder why I never stumble upon algebraic structures with $n$-ary operators? Is there a good reason for this , something along the lines of $n$-ary operators behave ""badly"" when $n>2$ or is it just my ignorance because I'm a beginner in the field?","This may be due to my own pure ignorance but it's my experience that all abstract algebra I've been introduced to, both in actual courses and in self-studies only exclusively deals with algebraic objects consisting of a set together with one or more binary operators defined on that set, perhaps over some other algebraic structure. Not counting categories here, just ""low-level""-ish stuff. I'm an undergraduate so my knowledge is of course very limited but I can't help to wonder why I never stumble upon algebraic structures with $n$-ary operators? Is there a good reason for this , something along the lines of $n$-ary operators behave ""badly"" when $n>2$ or is it just my ignorance because I'm a beginner in the field?",,"['abstract-algebra', 'soft-question']"
49,Definition/existence/uniqueness of a minimal projective resolution,Definition/existence/uniqueness of a minimal projective resolution,,"I'm reading Dave Benson's book ""Representations and Cohomology,"" Volume I, and I'm trying to understand the following discussion on page $32$ in which he introduces the notion of a minimal projective resolution.  Let $\Lambda$ be a ring and $M$ a left $\Lambda$-module.  The book reads: We write $\tilde{\Omega}^n(M)$ for $\ker(\partial_{n-1})$ in a projective resolution of $M$.  Note that by Schanuel's lemma, if $\tilde{\Omega}^n(M)'$ is similarly defined using another projective resolution of $M$ then there are projective modules $P$ and $P'$ with $\tilde{\Omega}^n(M)\oplus P'\cong\tilde{\Omega}^n(M)'\oplus P$.  If $M$ is finitely generated and the Krull-Schmidt theorem holds for finitely generated $\Lambda$-modules then there is a unique minimal resolution of $M$, and we write $\Omega^n(M)$ for $\ker(\partial_{n-1})$ in this particular resolution. For reference, the Krull-Schmidt theorem holds for a module $M$ if it is a finite direct sum of indecomposable modules, unique up to isomorphism and ordering of summands.  I understand the discussion above except for the phrase ""If $M$ is finitely generated and the Krull-Schmidt theorem holds for finitely generated $\Lambda$-modules then there is a unique minimal resolution of $M$.""  Benson does not define what a minimal resolution is, and it is not clear to me why he introduces the notion in the middle of this discussion.  I have many related questions: What is a minimal projective resolution, why does it exist, and why is it unique? Why do we need the Krull-Schmidt theorem to hold for there to exist a (unique) minimal resolution? Is the initial part of this discussion useful in showing there is a unique minimal resolution, or is Benson introducing the notion of a minimal resolution here to give a definition of $\Omega^n(M)$, that is, is the point of this discussion minimal resolutions or $\Omega^n(M)$?","I'm reading Dave Benson's book ""Representations and Cohomology,"" Volume I, and I'm trying to understand the following discussion on page $32$ in which he introduces the notion of a minimal projective resolution.  Let $\Lambda$ be a ring and $M$ a left $\Lambda$-module.  The book reads: We write $\tilde{\Omega}^n(M)$ for $\ker(\partial_{n-1})$ in a projective resolution of $M$.  Note that by Schanuel's lemma, if $\tilde{\Omega}^n(M)'$ is similarly defined using another projective resolution of $M$ then there are projective modules $P$ and $P'$ with $\tilde{\Omega}^n(M)\oplus P'\cong\tilde{\Omega}^n(M)'\oplus P$.  If $M$ is finitely generated and the Krull-Schmidt theorem holds for finitely generated $\Lambda$-modules then there is a unique minimal resolution of $M$, and we write $\Omega^n(M)$ for $\ker(\partial_{n-1})$ in this particular resolution. For reference, the Krull-Schmidt theorem holds for a module $M$ if it is a finite direct sum of indecomposable modules, unique up to isomorphism and ordering of summands.  I understand the discussion above except for the phrase ""If $M$ is finitely generated and the Krull-Schmidt theorem holds for finitely generated $\Lambda$-modules then there is a unique minimal resolution of $M$.""  Benson does not define what a minimal resolution is, and it is not clear to me why he introduces the notion in the middle of this discussion.  I have many related questions: What is a minimal projective resolution, why does it exist, and why is it unique? Why do we need the Krull-Schmidt theorem to hold for there to exist a (unique) minimal resolution? Is the initial part of this discussion useful in showing there is a unique minimal resolution, or is Benson introducing the notion of a minimal resolution here to give a definition of $\Omega^n(M)$, that is, is the point of this discussion minimal resolutions or $\Omega^n(M)$?",,"['abstract-algebra', 'representation-theory', 'modules', 'homological-algebra', 'homology-cohomology']"
50,Group of order $1575$ having a normal Sylow $3$ subgroup is abelian.,Group of order  having a normal Sylow  subgroup is abelian.,1575 3,"Question is to prove that : If a group $G$ with $|G|=1575=3^2\cdot5^2\cdot 7$ has a normal Sylow $3$ subgroup then : Sylow $5$ subgroup is normal Sylow $7$ subgroup is normal In this situation, Prove that $G$ is abelian. All i can do is  : If Sylow $3$ subgroup, Sylow $5$ subgroup, Sylow $7$ subgroup is normal then $G$ is abelian. Notation : $P_3$ for Sylow $3$ subgroup ; $P_5$ for Sylow $5$ subgroup; $P_7$ for Sylow $7$ subgroup We know that  : For $H\leq G$ the quotient group $N_G(H)/C_G(H)$ is isomorphic to a subgroup of $\text{Aut(H)}$ . As $P_3\unlhd G$ we have $N_G(P_3)=G$ As $P_5\unlhd G$ we have $N_G(P_5)=G$ As $P_7\unlhd G$ we have $N_G(P_7)=G$ Thus, we will have The quotient group $G/C_G(P_i)$ is isomorphic to a subgroup of $\text{Aut($P_i$)}$ for $i=3,5,7$ . In case of $P_3$ we have $G/C_G(P_3)\cong M \leq \text{Aut($P_3$)}$ Now, $|P_3|=3^2$ so, $|\text{Aut($P_3$)}|=3(3-1)=6$ As $C_G(P_3)\leq G$ we see that $|C_G(P_3)|$ divides $|G|$ with the condition $|G/C_G(P_3)|$ divides $6$ . As $P_3$ is abelian we have $H\leq C_G(P_3)$ so, $G/C_G(P_3) \leq G/P_3$ i.e., $G/C_G(P_3)\leq G/P_3$ i.e., $|G/C_G(P_3)|$ divides $|G/P_3|=5^2\cdot7$ we already have a condition that $|G/C_G(P_3)|$ divides $6$ . But, $6$ and $5^2.7$ do not have a common factor other than $1$ so, $|G/C_G(P_3)|=1$ i.e., $C_G(P_3)=G$ i.e., $P_3\leq Z(G)$ . In case of $P_5$ we have $G/C_G(P_5)\cong M \leq \text{Aut($P_5$)}$ Now, $|P_5|=5^2$ so, $|\text{Aut($P_5$)}|=5(5-1)=20$ As $C_G(P_5)\leq G$ we see that $|C_G(P_5)|$ divides $|G|$ with the condition $|G/C_G(P_5)|$ divides $20$ . As $P_5$ is abelian we have $H\leq C_G(P_5)$ so, $G/C_G(P_5) \leq G/P_5$ i.e., $G/C_G(P_5)\leq G/H$ i.e., $|G/C_G(P_5)|$ divides $|G/P_5|=3^2\cdot7$ we already have a condition that $|G/C_G(P_5)|$ divides $20$ . But, $20$ and $3^2.7$ do not have a common factor other than $1$ so, $|G/C_G(P_5)|=1$ i.e., $C_G(P_5)=G$ i.e., $P_5\leq Z(G)$ . In case of $P_7$ we have $G/C_G(P_7)\cong M \leq \text{Aut($P_7$)}$ Now, $|P_7|=7$ so, $|\text{Aut($P_3$)}|=(7-1)=6$ As $C_G(P_7)\leq G$ we see that $|C_G(P_7)|$ divides $|G|$ with the condition $|G/C_G(P_7)|$ divides $6$ . As $P_7$ is abelian we have $H\leq C_G(P_7)$ so, $G/C_G(P_7) \leq G/P_7$ i.e., $G/C_G(P_7)\leq G/P_7$ i.e., $|G/C_G(P_7)|$ divides $|G/P_7|=3^2\cdot7$ we already have a condition that $|G/C_G(P_7)|$ divides $6$ . Now there is a hitch.... I can not use same arguments as i have used for $P_3$ and $P_5$ as $3$ does divide $6$ and $3^2.7$ . So, I can not immediately conclude $|G/C_G(P_7)|=1$ i.e., $G=C_G(P_7)$ i.e., $P_7\leq Z(G)$ . Assuming I have Proved $P_i\leq Z(G)$ for $i=3,5,7$ It would not take much time to conclude $G=Z(G)$ As $P_i\cap P_j =\{e\}$ for $i\neq j$ and $i,j\in \{3,5,7\}$ we see that $G=\langle P_3,P_5,P_7\rangle$ But then $P_i\leq Z(G)$ for $i=3,5,7$ i.e., $G =\langle P_3,P_5,P_7\rangle \leq Z(G)$ i.e., $G=Z(G)$ which means $G$ is abelian. So, I am done on more than $40$ percent of the problem leaving possibility of $|G/C_G(P_7)|=3$ and I do not really understand how to make use of $P_3$ being Normal to conclude $P_5$ and $P_7$ are Normal. I am not sure of the procedure but I have something to say  on $P_5$ being normal : As $P_3$ is normal I can consider $G/P_3$ with $|G/P_3|=5^2.7$ So, If i see this group as something named $M$ This subgroup have a Sylow $5$ subgroup and a Sylow $7$ subgroup. But the condition $n_5=1+5k$ dividing $7$ gives only possibility that $n_5=1$ Which means that Sylow $5$ subgroup of $M$ (I wish i could make this as $P_5$ ) is normal. With similar reason $n_7=1+7k$ dividing $5^2$ gives only possibility that $n_7=1$ Which means that Sylow $7$ subgroup of $M$ (I wish I could make this as $P_7$ ) is normal. So I guess I am done up to $60$ percent. I am not so sure how to make use of (believing that I can make use of) Sylow $5$ subgroup, Sylow $7$ subgroup of $M$ being normal to conclude $P_5$ and $P_7$ are normal. I would be thankful if some one can help me to clear two gaps in this : How to get rid of $|G/C_G(P_7)|=3$ . How to make use of Sylow $5$ subgroup, Sylow $7$ subgroup of $M$ being normal to conclude $P_5$ and $P_7$ are normal. Please help me to clear these gaps. Thank you. P.S : Please give ""just hints"". Do not write whole answer at once. This is a ""request"". Thank you :)","Question is to prove that : If a group with has a normal Sylow subgroup then : Sylow subgroup is normal Sylow subgroup is normal In this situation, Prove that is abelian. All i can do is  : If Sylow subgroup, Sylow subgroup, Sylow subgroup is normal then is abelian. Notation : for Sylow subgroup ; for Sylow subgroup; for Sylow subgroup We know that  : For the quotient group is isomorphic to a subgroup of . As we have As we have As we have Thus, we will have The quotient group is isomorphic to a subgroup of for . In case of we have Now, so, As we see that divides with the condition divides . As is abelian we have so, i.e., i.e., divides we already have a condition that divides . But, and do not have a common factor other than so, i.e., i.e., . In case of we have Now, so, As we see that divides with the condition divides . As is abelian we have so, i.e., i.e., divides we already have a condition that divides . But, and do not have a common factor other than so, i.e., i.e., . In case of we have Now, so, As we see that divides with the condition divides . As is abelian we have so, i.e., i.e., divides we already have a condition that divides . Now there is a hitch.... I can not use same arguments as i have used for and as does divide and . So, I can not immediately conclude i.e., i.e., . Assuming I have Proved for It would not take much time to conclude As for and we see that But then for i.e., i.e., which means is abelian. So, I am done on more than percent of the problem leaving possibility of and I do not really understand how to make use of being Normal to conclude and are Normal. I am not sure of the procedure but I have something to say  on being normal : As is normal I can consider with So, If i see this group as something named This subgroup have a Sylow subgroup and a Sylow subgroup. But the condition dividing gives only possibility that Which means that Sylow subgroup of (I wish i could make this as ) is normal. With similar reason dividing gives only possibility that Which means that Sylow subgroup of (I wish I could make this as ) is normal. So I guess I am done up to percent. I am not so sure how to make use of (believing that I can make use of) Sylow subgroup, Sylow subgroup of being normal to conclude and are normal. I would be thankful if some one can help me to clear two gaps in this : How to get rid of . How to make use of Sylow subgroup, Sylow subgroup of being normal to conclude and are normal. Please help me to clear these gaps. Thank you. P.S : Please give ""just hints"". Do not write whole answer at once. This is a ""request"". Thank you :)","G |G|=1575=3^2\cdot5^2\cdot 7 3 5 7 G 3 5 7 G P_3 3 P_5 5 P_7 7 H\leq G N_G(H)/C_G(H) \text{Aut(H)} P_3\unlhd G N_G(P_3)=G P_5\unlhd G N_G(P_5)=G P_7\unlhd G N_G(P_7)=G G/C_G(P_i) \text{Aut(P_i)} i=3,5,7 P_3 G/C_G(P_3)\cong M \leq \text{Aut(P_3)} |P_3|=3^2 |\text{Aut(P_3)}|=3(3-1)=6 C_G(P_3)\leq G |C_G(P_3)| |G| |G/C_G(P_3)| 6 P_3 H\leq C_G(P_3) G/C_G(P_3) \leq G/P_3 G/C_G(P_3)\leq G/P_3 |G/C_G(P_3)| |G/P_3|=5^2\cdot7 |G/C_G(P_3)| 6 6 5^2.7 1 |G/C_G(P_3)|=1 C_G(P_3)=G P_3\leq Z(G) P_5 G/C_G(P_5)\cong M \leq \text{Aut(P_5)} |P_5|=5^2 |\text{Aut(P_5)}|=5(5-1)=20 C_G(P_5)\leq G |C_G(P_5)| |G| |G/C_G(P_5)| 20 P_5 H\leq C_G(P_5) G/C_G(P_5) \leq G/P_5 G/C_G(P_5)\leq G/H |G/C_G(P_5)| |G/P_5|=3^2\cdot7 |G/C_G(P_5)| 20 20 3^2.7 1 |G/C_G(P_5)|=1 C_G(P_5)=G P_5\leq Z(G) P_7 G/C_G(P_7)\cong M \leq \text{Aut(P_7)} |P_7|=7 |\text{Aut(P_3)}|=(7-1)=6 C_G(P_7)\leq G |C_G(P_7)| |G| |G/C_G(P_7)| 6 P_7 H\leq C_G(P_7) G/C_G(P_7) \leq G/P_7 G/C_G(P_7)\leq G/P_7 |G/C_G(P_7)| |G/P_7|=3^2\cdot7 |G/C_G(P_7)| 6 P_3 P_5 3 6 3^2.7 |G/C_G(P_7)|=1 G=C_G(P_7) P_7\leq Z(G) P_i\leq Z(G) i=3,5,7 G=Z(G) P_i\cap P_j =\{e\} i\neq j i,j\in \{3,5,7\} G=\langle P_3,P_5,P_7\rangle P_i\leq Z(G) i=3,5,7 G =\langle P_3,P_5,P_7\rangle \leq Z(G) G=Z(G) G 40 |G/C_G(P_7)|=3 P_3 P_5 P_7 P_5 P_3 G/P_3 |G/P_3|=5^2.7 M 5 7 n_5=1+5k 7 n_5=1 5 M P_5 n_7=1+7k 5^2 n_7=1 7 M P_7 60 5 7 M P_5 P_7 |G/C_G(P_7)|=3 5 7 M P_5 P_7","['abstract-algebra', 'group-theory']"
51,"If $G$ is an infinite group, then the group ring $R(G)$ is not semisimple.","If  is an infinite group, then the group ring  is not semisimple.",G R(G),"Let $R$ be a ring and $G$ an infinite group. Prove that $R(G)$ (group ring) is not semisimple. My idea was to suppose it is semisimple, then $R(G)$ is left artinian and $J(R(G))=0$. I was trying to make a ascending chain of ideals that won't stop, then it is not left noetherian, by Hopkins theorem it is not left artinian, a contradiction. I also tried to make a descending chain that won't stop, so it is not left artinian, but I wasn't successful. So please help me.","Let $R$ be a ring and $G$ an infinite group. Prove that $R(G)$ (group ring) is not semisimple. My idea was to suppose it is semisimple, then $R(G)$ is left artinian and $J(R(G))=0$. I was trying to make a ascending chain of ideals that won't stop, then it is not left noetherian, by Hopkins theorem it is not left artinian, a contradiction. I also tried to make a descending chain that won't stop, so it is not left artinian, but I wasn't successful. So please help me.",,"['abstract-algebra', 'group-theory', 'ring-theory', 'group-rings']"
52,Is $\mathbb{Z}[x]/(x^2+1)$ isomorphic to $\mathbb{Z}[i]$?,Is  isomorphic to ?,\mathbb{Z}[x]/(x^2+1) \mathbb{Z}[i],"Is $\mathbb{Z}[x]/(x^2+1)$  isomorphic to  $\mathbb{Z}[i]$? My attempt is that try to define a mapping $g$ from $\mathbb{Z}[x]$ to $\mathbb{Z}[i]$ by $g(f(x))= f(i)$, for $f(x)\in\mathbb{Z}[x]$. If it is possible then $\ker g$ is $(x^2+1)$? Am I on the right track? Please Help.","Is $\mathbb{Z}[x]/(x^2+1)$  isomorphic to  $\mathbb{Z}[i]$? My attempt is that try to define a mapping $g$ from $\mathbb{Z}[x]$ to $\mathbb{Z}[i]$ by $g(f(x))= f(i)$, for $f(x)\in\mathbb{Z}[x]$. If it is possible then $\ker g$ is $(x^2+1)$? Am I on the right track? Please Help.",,"['abstract-algebra', 'ring-theory']"
53,A non-UFD where we have different lengths of irreducible factorizations?,A non-UFD where we have different lengths of irreducible factorizations?,,"A unique factorization domain (UFD) is defined to be an integral domain where each element other than units and zero has a factorization into irreducibles, and if we have two such factorizations then they are of the same length (the sum of the powers of the irreducible factors) and the irreducibles involved are associated to each other. My knowledge about algebra is extremely limited, but the only non-UFD integral domain I have seen is $\mathbb{Z}[\sqrt{-5}]$, where one shows $9=3\cdot 3=(2+\sqrt{-5})(2-\sqrt{-5})$ gives two different factorizations of $9$ into irreducibles with non-associated factors. However in this case the two factorizations are of the same length. So just curious, can we find integral domains where some elements have factorizations into irreducibles with different lengths? Thanks!","A unique factorization domain (UFD) is defined to be an integral domain where each element other than units and zero has a factorization into irreducibles, and if we have two such factorizations then they are of the same length (the sum of the powers of the irreducible factors) and the irreducibles involved are associated to each other. My knowledge about algebra is extremely limited, but the only non-UFD integral domain I have seen is $\mathbb{Z}[\sqrt{-5}]$, where one shows $9=3\cdot 3=(2+\sqrt{-5})(2-\sqrt{-5})$ gives two different factorizations of $9$ into irreducibles with non-associated factors. However in this case the two factorizations are of the same length. So just curious, can we find integral domains where some elements have factorizations into irreducibles with different lengths? Thanks!",,"['abstract-algebra', 'reference-request', 'ring-theory', 'examples-counterexamples']"
54,Example of non-abelian partially ordered group,Example of non-abelian partially ordered group,,What is a simple example of a non-abelian partially ordered group?,What is a simple example of a non-abelian partially ordered group?,,"['abstract-algebra', 'group-theory', 'examples-counterexamples', 'order-theory', 'lattice-orders']"
55,Isomorphism between tensor product and quotient module.,Isomorphism between tensor product and quotient module.,,"Given a commutative ring $R$ with $1$ , an ideal $I$ and an $R$ -module $A$ , how can I show that the homomorphism $$f: R/I \otimes_R A \to A/IA$$ given by $f((r +I) \otimes a) = ra + IA$ is injective? I can easily see that it's surjective. (We define $IA$ to be the submodule of $A$ generated by elements of the form $ia$ , $i \in I, a \in A$ .)","Given a commutative ring with , an ideal and an -module , how can I show that the homomorphism given by is injective? I can easily see that it's surjective. (We define to be the submodule of generated by elements of the form , .)","R 1 I R A f: R/I \otimes_R A \to A/IA f((r +I) \otimes a) = ra + IA IA A ia i \in I, a \in A","['abstract-algebra', 'modules', 'tensor-products']"
56,"For field extensions $F\subsetneq K \subset F(x)$, $x$ is algebraic over $K$ [closed]","For field extensions ,  is algebraic over  [closed]",F\subsetneq K \subset F(x) x K,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $x$ be an element not algebraic over $F$, and $K \subset F(x)$ a subfield that strictly contains $F$. Why is $x$ algebraic over $K$? Thanks a lot!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $x$ be an element not algebraic over $F$, and $K \subset F(x)$ a subfield that strictly contains $F$. Why is $x$ algebraic over $K$? Thanks a lot!",,"['abstract-algebra', 'field-theory']"
57,Is Gauss's lemma valid for polynomials with coefficients in a GCD domain?,Is Gauss's lemma valid for polynomials with coefficients in a GCD domain?,,"Wikipedia's proof of Gauss's lemma requires this theorem: If $(C \mid S\cdot T) \land \lnot \operatorname{invertible}(C)$, $C$ has a non-invertible divisor in common with at least one of $S$ and $T$. I can prove it for a Bézout domain, but not a GCD domain. Can anybody help me? Original text: If the contents $c = c(ST)$ is not invertible, it has a non-trivial divisor in common with the leading coefficient of at least one of $S$ and $T$ (since it divides their product, which is the leading coefficient of $ST$).","Wikipedia's proof of Gauss's lemma requires this theorem: If $(C \mid S\cdot T) \land \lnot \operatorname{invertible}(C)$, $C$ has a non-invertible divisor in common with at least one of $S$ and $T$. I can prove it for a Bézout domain, but not a GCD domain. Can anybody help me? Original text: If the contents $c = c(ST)$ is not invertible, it has a non-trivial divisor in common with the leading coefficient of at least one of $S$ and $T$ (since it divides their product, which is the leading coefficient of $ST$).",,"['abstract-algebra', 'polynomials', 'ring-theory', 'divisibility', 'gcd-and-lcm']"
58,Finding free subgroup $F_2$ in the free product $\frac{\mathbb{Z}}{5\mathbb{Z}} * \frac{\mathbb{Z}}{6\mathbb{Z}}$,Finding free subgroup  in the free product,F_2 \frac{\mathbb{Z}}{5\mathbb{Z}} * \frac{\mathbb{Z}}{6\mathbb{Z}},"Is there any free group isomorphic to $F_2$ contained in the free product group $\frac{\mathbb{Z}}{5 \mathbb{Z}}* \frac{\mathbb{Z}}{6 \mathbb{Z}}?$ Let $\frac{\mathbb{Z}}{5\mathbb{Z}}= \langle a \mid a^5=1 \rangle$ and $\frac{\mathbb{Z}}{6\mathbb{Z}}= \langle b \mid b^6=1 \rangle$ . Clearly $ab,ba$ these two elements  are of infinite order in the free product. I want to show that the group generated by $\langle ab, ba\rangle$ is a free subgroup of the free product. How to show that?",Is there any free group isomorphic to contained in the free product group Let and . Clearly these two elements  are of infinite order in the free product. I want to show that the group generated by is a free subgroup of the free product. How to show that?,"F_2 \frac{\mathbb{Z}}{5 \mathbb{Z}}* \frac{\mathbb{Z}}{6 \mathbb{Z}}? \frac{\mathbb{Z}}{5\mathbb{Z}}= \langle a \mid a^5=1 \rangle \frac{\mathbb{Z}}{6\mathbb{Z}}= \langle b \mid b^6=1 \rangle ab,ba \langle ab, ba\rangle","['abstract-algebra', 'group-theory', 'free-groups', 'combinatorial-group-theory', 'free-product']"
59,Can you completely determine a finitely presented finite group?,Can you completely determine a finitely presented finite group?,,"Let $G = \langle S \mid R \rangle$ be a finitely presented group. Suppose you know $G$ is finite. Can you completely construct the group multiplication table? I feel like the answer is yes. My first thought is to construct homomorphisms into symmetric groups, but I am not quite sure how to go about it.","Let be a finitely presented group. Suppose you know is finite. Can you completely construct the group multiplication table? I feel like the answer is yes. My first thought is to construct homomorphisms into symmetric groups, but I am not quite sure how to go about it.",G = \langle S \mid R \rangle G,"['abstract-algebra', 'group-theory', 'finite-groups', 'group-presentation', 'combinatorial-group-theory']"
60,Nonexistence of a simple group of order 420,Nonexistence of a simple group of order 420,,"From Dummit & Foote, Abstract Algebra , $\S6.2$ , Exercise 17(a). Prove that there is no simple group of order 420. Suppose not; label such group $G$ . the number of Sylow 7-subgroups of $G$ is 15. Let $G$ act on the set of Sylow 7-subgroups (denoted hereon by ""letters"") by conjugation. There is only one orbit of size 15 (by Sylow 2nd), thus each stabilizer on one letter has size 420/15 = 28. The action induces an injective homomorphism of $G$ into $A_{15}$ . Each stabilizer on a single letter should have an element of order 7 (by Cauchy), permuting the remaining 14 letters. Naturally, this element then generates the unique Sylow 7 within the stabilizer. I now assume that the element of order 7 is a product of 2 disjoint 7-cycles. Is this valid, and why? In particular, am I able to eliminate the possibility of the element being a single 7-cycle? If the above assumption is valid, then I am now able to eliminate the possibility of order 14 and 28 elements, since order 14 implies single 14-cycle (odd) or product of single 7-cycle and some 2-cycles (2nd power is single 7-cycle), likewise for order 28. Now use the fact that the Sylow 7 is normal within the stabilizer: the permutations that sends a 7-cycle to its power by conjugation is either a product of 3 2-cycles (sends to inverse), 2 3-cycles (sends to 2nd/4th power), or a 6-cycle (sends to 3rd/5th power). By similar calculations, permutations that switch between the two 7-cycles are either 7 2-cycles, a 2-cycle and 3 4-cycles, a 2-cycle and 2 6-cycles, a 2-cycle and a 12-cycle, or a 14-cycle. Since the remaining elements are either order 2 and 4, our choices are either 6 2-cycles, 7 2-cycles (odd), or a 2-cycle and 3 4-cycles (third power breaks the pairing of the two 7-cycles). Are my calculations and reasoning correct here? The pair of fixed letters in the 2 7-cycles then determines the whole of the permutation, but noting that the two different fixed letter 2-cycles (per 1 7-cycle) result in a product of a 7-cycle, we conclude that the pairings of fixed letters must be disjoint for two different elements. Then, the number of possible remaining elements is 7 out of a required 21; contradiction. In general, is there a cleaner way to go about this exercise, or proving nonexistence of groups of some highly composite order? I only know the method of embedding the group in an alternating group and trying to derive a contradiction from there (outside the usual repertoire).","From Dummit & Foote, Abstract Algebra , , Exercise 17(a). Prove that there is no simple group of order 420. Suppose not; label such group . the number of Sylow 7-subgroups of is 15. Let act on the set of Sylow 7-subgroups (denoted hereon by ""letters"") by conjugation. There is only one orbit of size 15 (by Sylow 2nd), thus each stabilizer on one letter has size 420/15 = 28. The action induces an injective homomorphism of into . Each stabilizer on a single letter should have an element of order 7 (by Cauchy), permuting the remaining 14 letters. Naturally, this element then generates the unique Sylow 7 within the stabilizer. I now assume that the element of order 7 is a product of 2 disjoint 7-cycles. Is this valid, and why? In particular, am I able to eliminate the possibility of the element being a single 7-cycle? If the above assumption is valid, then I am now able to eliminate the possibility of order 14 and 28 elements, since order 14 implies single 14-cycle (odd) or product of single 7-cycle and some 2-cycles (2nd power is single 7-cycle), likewise for order 28. Now use the fact that the Sylow 7 is normal within the stabilizer: the permutations that sends a 7-cycle to its power by conjugation is either a product of 3 2-cycles (sends to inverse), 2 3-cycles (sends to 2nd/4th power), or a 6-cycle (sends to 3rd/5th power). By similar calculations, permutations that switch between the two 7-cycles are either 7 2-cycles, a 2-cycle and 3 4-cycles, a 2-cycle and 2 6-cycles, a 2-cycle and a 12-cycle, or a 14-cycle. Since the remaining elements are either order 2 and 4, our choices are either 6 2-cycles, 7 2-cycles (odd), or a 2-cycle and 3 4-cycles (third power breaks the pairing of the two 7-cycles). Are my calculations and reasoning correct here? The pair of fixed letters in the 2 7-cycles then determines the whole of the permutation, but noting that the two different fixed letter 2-cycles (per 1 7-cycle) result in a product of a 7-cycle, we conclude that the pairings of fixed letters must be disjoint for two different elements. Then, the number of possible remaining elements is 7 out of a required 21; contradiction. In general, is there a cleaner way to go about this exercise, or proving nonexistence of groups of some highly composite order? I only know the method of embedding the group in an alternating group and trying to derive a contradiction from there (outside the usual repertoire).",\S6.2 G G G G A_{15},"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory', 'simple-groups']"
61,"Is this proof of $H\le G, [G:H] =2 \implies a^2\in H \forall a\in G$ correct?",Is this proof of  correct?,"H\le G, [G:H] =2 \implies a^2\in H \forall a\in G","If $H$ is a subgroup of a group $G$ and the index (number of right cosets) of $H$ is $2$ , then $a^2 \in H$ for all $a\in G$ . My attempt: if $a\in H$ then $a^2\in H$ directly. If $a\notin H$ and $a^2\notin H$ then $a(a^{-1})^{-1}  = a^2 \notin H$ then $G = Ha \cup Ha^{-1}$ (the union being disjoint). But $e\notin Ha$ because $e=a^{-1}a$ and $a^{-1}\notin H$ . Also $e\notin Ha^{-1}$ because $e = aa^{-1}$ and $a\notin H$ . Then we have a contradiction. So $a^2$ must be in $H$ in both cases. I think it's ok but I dont feel the arguments with the identity $e$ are right and don't see how to justify them more rigorously. Thanks in advance","If is a subgroup of a group and the index (number of right cosets) of is , then for all . My attempt: if then directly. If and then then (the union being disjoint). But because and . Also because and . Then we have a contradiction. So must be in in both cases. I think it's ok but I dont feel the arguments with the identity are right and don't see how to justify them more rigorously. Thanks in advance",H G H 2 a^2 \in H a\in G a\in H a^2\in H a\notin H a^2\notin H a(a^{-1})^{-1}  = a^2 \notin H G = Ha \cup Ha^{-1} e\notin Ha e=a^{-1}a a^{-1}\notin H e\notin Ha^{-1} e = aa^{-1} a\notin H a^2 H e,"['abstract-algebra', 'group-theory', 'proof-writing']"
62,Total number of roots of a polynomial of degree $n$ over a ring $R$,Total number of roots of a polynomial of degree  over a ring,n R,"Let $R$ be a commutative ring with unity and $f$ be a polynomial of degree $n$ over $R$. Under what conditions on $R$, does $f$ has at most $n$ roots ? I am asking because in $\mathbb{Z}/12\mathbb{Z}$, the polynomial $x^2-4$ has 4 roots $2,4,8,10$ since $X^2-4=(x-8)(x-4)=(x-10)(x-2)$. The above example shows unique factorization is necessary. So I believe, $R$ should be a UFD as $R[x]$ will also be a UFD then.","Let $R$ be a commutative ring with unity and $f$ be a polynomial of degree $n$ over $R$. Under what conditions on $R$, does $f$ has at most $n$ roots ? I am asking because in $\mathbb{Z}/12\mathbb{Z}$, the polynomial $x^2-4$ has 4 roots $2,4,8,10$ since $X^2-4=(x-8)(x-4)=(x-10)(x-2)$. The above example shows unique factorization is necessary. So I believe, $R$ should be a UFD as $R[x]$ will also be a UFD then.",,"['abstract-algebra', 'polynomials', 'roots']"
63,Key Results of Combinatorial Group Theory.,Key Results of Combinatorial Group Theory.,,"What are the key theorems of combinatorial group theory ? By ""key theorems"", I mean those most commonly used in the literature. For added context, I have copies of ""Presentation of Groups,"" by D. L. Johnson and ""Combinatorial Group Theory: Presentations of Groups in Terms of Generators and Relations, "" by Magnus et al. , and I've just started a Ph.D. in the area. I suppose a good place to start would be Theorem (Nielson-Shreier Theorem): Every subgroup of a free group is itself free. Update: I've got a copy of Lyndon & Schupp's ""Combinatorial Group Theory"" .","What are the key theorems of combinatorial group theory ? By ""key theorems"", I mean those most commonly used in the literature. For added context, I have copies of ""Presentation of Groups,"" by D. L. Johnson and ""Combinatorial Group Theory: Presentations of Groups in Terms of Generators and Relations, "" by Magnus et al. , and I've just started a Ph.D. in the area. I suppose a good place to start would be Theorem (Nielson-Shreier Theorem): Every subgroup of a free group is itself free. Update: I've got a copy of Lyndon & Schupp's ""Combinatorial Group Theory"" .",,"['abstract-algebra', 'group-theory', 'big-list', 'combinatorial-group-theory']"
64,Finitely presented module + flat implies projective,Finitely presented module + flat implies projective,,"Let $M$ be a finitely presented module. Show that $M$ is flat if and only if $M$ is projective. I think I am fine with the part ""projective"" implies flatness but I need help on showing that flatness + finitely presented modules implies projective. Any help on this part will be great.","Let $M$ be a finitely presented module. Show that $M$ is flat if and only if $M$ is projective. I think I am fine with the part ""projective"" implies flatness but I need help on showing that flatness + finitely presented modules implies projective. Any help on this part will be great.",,"['abstract-algebra', 'ring-theory', 'modules', 'projective-module']"
65,Proving that there only finitely many minimal prime ideals of any ideal in Noetherian commutative ring,Proving that there only finitely many minimal prime ideals of any ideal in Noetherian commutative ring,,"Currently, I'm trying to solve a problem from a textbook: Let $R$ be a commutative Noetherian ring with identity, and let $I \subset R$ be a proper ideal of $R$ . Then we know that set of prime ideals of $R$ containing $I$ has minimal elements by inclusion (I decided to call this set $\mathrm{Min}(I)$ in sequel). Prove that $\mathrm{Min}(I)$ is finite. There is also a hint: Define $\mathcal{F}$ as set of all ideals $I$ of $R$ such that $ \vert \mathrm{Min}(I) \vert = \infty$ . Assume that $\mathcal{F} \neq \emptyset$ . Then it must have a maximal element $I$ . Find ideals $J_1,J_2$ such that they all strictly include $I$ , such that $J_1J_2 \subset I$ and deduce a contradiction. So I went along this hint: $I$ can't be a prime, as a prime is the only minimal prime over itself. It means that $\exists a,b \not \in I: ab \in I$ . As $R$ is Noetherian there is a finite list of elements that generates $I = (r_1, \dots, r_n)$ . Then  it's possible to set $J_1 = (r_1, \dots,r_n,a)$ , $J_2 =(r_1, \dots, r_n, b )$ with all required properties. As $I$ is maximal in $\mathcal{F}$ the sets $\mathrm{Min}(J_1)$ and $\mathrm{Min}(J_2)$ must be finite. I am failing to find a desired contradiction and will be grateful for any help.","Currently, I'm trying to solve a problem from a textbook: Let be a commutative Noetherian ring with identity, and let be a proper ideal of . Then we know that set of prime ideals of containing has minimal elements by inclusion (I decided to call this set in sequel). Prove that is finite. There is also a hint: Define as set of all ideals of such that . Assume that . Then it must have a maximal element . Find ideals such that they all strictly include , such that and deduce a contradiction. So I went along this hint: can't be a prime, as a prime is the only minimal prime over itself. It means that . As is Noetherian there is a finite list of elements that generates . Then  it's possible to set , with all required properties. As is maximal in the sets and must be finite. I am failing to find a desired contradiction and will be grateful for any help.","R I \subset R R R I \mathrm{Min}(I) \mathrm{Min}(I) \mathcal{F} I R  \vert \mathrm{Min}(I) \vert = \infty \mathcal{F} \neq \emptyset I J_1,J_2 I J_1J_2 \subset I I \exists a,b \not \in I: ab \in I R I = (r_1, \dots, r_n) J_1 = (r_1, \dots,r_n,a) J_2 =(r_1, \dots, r_n, b ) I \mathcal{F} \mathrm{Min}(J_1) \mathrm{Min}(J_2)","['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals']"
66,Prove there are infinitely many primes in $\mathbb{Z}[i]$,Prove there are infinitely many primes in,\mathbb{Z}[i],"I saw a proof online there are infinitely many primes in $\mathbb{Z}$.  The Euler product let's us factor the harmonic series: $$ \prod  \left( 1 - \frac{1}{p} \right) = \sum \frac{1}{n}$$ I wonder if this extends to $\mathbb{Z}[i]$.  Joan Baez Week 216 of This Week's Finds defines the zeta function of number field as the sum over non-zero ideals basically: $$ \zeta_{\mathbb{Z}[i]}(s) = \sum \frac{1}{(m^2 + n^2)^s} = \prod_{p \in \mathbb{Z}[i]} \left( 1 - \frac{1}{|p|^s} \right) $$ Here $2 = (1+i)(1-i)$ means that $2$ is ramified in $\mathbb{Z}[i]$.  When does this converge? $$ \sum_{m, n \geq 1} \frac{1}{(m^2 + n^2)^s} \approx \frac{\pi}{4}\int \frac{ dr }{r^{2s-1}} < \infty$$ This zeta function converges for $s > 1$ since we are adding more numbers. So for $s = 1$ $$ \zeta_{\mathbb{Z}[i]}(1) = \sum \frac{1}{m^2 + n^2} = \prod_{p \in \mathbb{Z}[i]} \left( 1 - \frac{1}{|p|} \right) = \infty $$ We should also check that $\mathbb{Z}[i]$ has unique factorization, because it has a Euclidean algorithm Did we just prove $\mathbb{Z}[i]$ has infinitely many primes? If that doesn't work, we show that $\zeta(2)$ is irrational.  In fact $\zeta_{\mathbb{Z}}(2) = \frac{\pi^2}{6}$ but what about $\zeta_{\mathbb{Z}[i]}(2) $ ? Different ways to prove there are infinitely many primes? GCD of gaussian integers","I saw a proof online there are infinitely many primes in $\mathbb{Z}$.  The Euler product let's us factor the harmonic series: $$ \prod  \left( 1 - \frac{1}{p} \right) = \sum \frac{1}{n}$$ I wonder if this extends to $\mathbb{Z}[i]$.  Joan Baez Week 216 of This Week's Finds defines the zeta function of number field as the sum over non-zero ideals basically: $$ \zeta_{\mathbb{Z}[i]}(s) = \sum \frac{1}{(m^2 + n^2)^s} = \prod_{p \in \mathbb{Z}[i]} \left( 1 - \frac{1}{|p|^s} \right) $$ Here $2 = (1+i)(1-i)$ means that $2$ is ramified in $\mathbb{Z}[i]$.  When does this converge? $$ \sum_{m, n \geq 1} \frac{1}{(m^2 + n^2)^s} \approx \frac{\pi}{4}\int \frac{ dr }{r^{2s-1}} < \infty$$ This zeta function converges for $s > 1$ since we are adding more numbers. So for $s = 1$ $$ \zeta_{\mathbb{Z}[i]}(1) = \sum \frac{1}{m^2 + n^2} = \prod_{p \in \mathbb{Z}[i]} \left( 1 - \frac{1}{|p|} \right) = \infty $$ We should also check that $\mathbb{Z}[i]$ has unique factorization, because it has a Euclidean algorithm Did we just prove $\mathbb{Z}[i]$ has infinitely many primes? If that doesn't work, we show that $\zeta(2)$ is irrational.  In fact $\zeta_{\mathbb{Z}}(2) = \frac{\pi^2}{6}$ but what about $\zeta_{\mathbb{Z}[i]}(2) $ ? Different ways to prove there are infinitely many primes? GCD of gaussian integers",,"['abstract-algebra', 'commutative-algebra', 'prime-numbers', 'algebraic-number-theory', 'sieve-theory']"
67,"For any rng $R$, can we attach a unity?","For any rng , can we attach a unity?",R,"Let $R$ be an rng. (There may be no unity) Then, does there always exist a ring (with unity) $A$ such that $R$ is a subrng of $A$?","Let $R$ be an rng. (There may be no unity) Then, does there always exist a ring (with unity) $A$ such that $R$ is a subrng of $A$?",,"['abstract-algebra', 'ring-theory', 'rngs']"
68,Implementing trig functions for dual numbers,Implementing trig functions for dual numbers,,"I'm curious, how do common trig functions get implemented for dual numbers? One way would be to use the power series definition, but that seems inefficient","I'm curious, how do common trig functions get implemented for dual numbers? One way would be to use the power series definition, but that seems inefficient",,"['abstract-algebra', 'derivatives', 'numerical-linear-algebra']"
69,Galois group of $x^3 + x^2 - 2x - 1$.,Galois group of .,x^3 + x^2 - 2x - 1,"Suppose $\alpha$ is a root of $x^3 + x^2 - 2x - 1$. Let $E = \mathbb{Q}(\alpha)$. We are given that $\beta = \alpha^2 - 2$ is also a root, and I need to find $Gal(E/\mathbb{Q})$ and show that $E$ is normal over $\mathbb{Q}$. This is what I was thinking: because we have a relation between two roots, then they are both complex or both real. If they are both real, then you have 2 real roots so thus all 3 roots are real. In that case, then the Galois group is $S_3$ or $A_3$..? Or can we say that $\gamma = \beta^2 -2$ is also a root, so then they must all be real? I'm having trouble with figuring our the Galois group when a relation is given like this. Thanks!","Suppose $\alpha$ is a root of $x^3 + x^2 - 2x - 1$. Let $E = \mathbb{Q}(\alpha)$. We are given that $\beta = \alpha^2 - 2$ is also a root, and I need to find $Gal(E/\mathbb{Q})$ and show that $E$ is normal over $\mathbb{Q}$. This is what I was thinking: because we have a relation between two roots, then they are both complex or both real. If they are both real, then you have 2 real roots so thus all 3 roots are real. In that case, then the Galois group is $S_3$ or $A_3$..? Or can we say that $\gamma = \beta^2 -2$ is also a root, so then they must all be real? I'm having trouble with figuring our the Galois group when a relation is given like this. Thanks!",,"['abstract-algebra', 'galois-theory']"
70,"Precise meaning of ""Solution in radicals""","Precise meaning of ""Solution in radicals""",,"I'm wondering precisely what is meant by the phrase ""solution in radicals"".  We know that general quintic (5th degree) polynomials don't have a solution in radicals.  I'm wanting a ""formal"" description of what that phrase means in the symbol-manipulation/computer-algorithms sense.  I've seen lots of imprecise and ambiguous wording in English that glosses over what that means, and all of those definitions seem to be lacking.  Take for example the entry at Britannica : At stake was the existence of a formula that expresses the roots of a quintic equation in terms of the coefficients. This formula, moreover, must involve only the operations of addition, subtraction, multiplication, and division, together with the extraction of roots, since that was all that had been required for the solution of quadratic, cubic, and quartic equations. If such a formula were to exist, the quintic would accordingly be said to be solvable by radicals. Notice the omission of exponentation, which I assume is a typo, but it of course can be recovered by taking reciprocal roots (e.g. $ x^3 = \sqrt[^1/_3]{x} $ ).  Ignoring that issue for the moment, this would seem to allow terms like: $ \pi^a $ $ e^{a \pi i} $ $ \sqrt{2}^{\sqrt{2}} $ $ \sqrt[\pi]{a^{b^c}} $ $ i^a $ ...where $ a,b,... $ (etc.) are coefficients of the original polynomial (i.e. $ ax^5 + bx^4 + cx^3 + dx^2 + ex + f $ ).  This seems pretty typical of the information out there, where there are a lot of potential ambiguities. Wikipedia's entry for Algebraic Solution , is different (more accurate?), stating: An algebraic solution or solution in radicals is a closed form expression, and more specifically a closed-form algebraic expression, that is the solution of an algebraic equation in terms of the coefficients, relying only on addition, subtraction, multiplication, division, raising to integer powers, and the extraction of roots (square roots, cube roots, etc.). ...differences include ""raising to integer powers"", and extraction of roots, but not being exactly clear if the n of nth root can be irrational, imaginary, or a coefficient of the equation.  The mention of ""raising to integer powers"" seems a little odd, since I can effectively raise to rational powers by combining exponentation and root extraction $ a^{^7/_{16}} = \sqrt[16]{a^7} $ Also missing is the mention of a finite number of terms, which is present in a lot of presentations.  I also assume that we're talking about a fixed number of terms, so there would be no number of terms depending on an intermediate calculation, or towers of exponents based on a coefficient.  And there is no mention if the use of transcendental constants are allowed. To that end, I'd like an executable computer algorithm that describes the form of a ""solution in radicals"".  Here's one attempt at a ""solution in radicals"" checker using Mathematica notation: radicalsQ[_Symbol] := True radicalsQ[_?NumericQ] := True radicalsQ[x_ + y_] := radicalsQ[x] && radicalsQ[y] radicalsQ[x_ - y_] := radicalsQ[x] && radicalsQ[y] radicalsQ[x_ * y_] := radicalsQ[x] && radicalsQ[y] radicalsQ[x_ / y_] := radicalsQ[x] && radicalsQ[y] radicalsQ[x_ ^ _Integer] := radicalsQ[x] radicalsQ[root[_Integer,x_]] := radicalsQ[x] radicalsQ[_] := False ...which you can execute on-line here with the mathics.net webpage.  Can anyone point me in the direction of a reference that might verify or contradict the above?  Some day I'd like to learn how to prove Abel's Impossibility Theorem , but I'm not there yet.  But in the mean time, I'm just interested in this small aspect. Here are some tests, showing a few terms that pass and fail the above criteria. trusies = Map[radicalsQ,{123, a, 2*b, (-b + root[2,b^2-4*a*c])/(2*a),                           root[16,a^7],root[16,a]^7, Pi*b,                           root[2,a*E^I]+b^123-c/d}] falsies = Map[radicalsQ,{2^a,root[a,b],a^I}]  allTests = (And @@ trusies) && !(Or @@ falsies)","I'm wondering precisely what is meant by the phrase ""solution in radicals"".  We know that general quintic (5th degree) polynomials don't have a solution in radicals.  I'm wanting a ""formal"" description of what that phrase means in the symbol-manipulation/computer-algorithms sense.  I've seen lots of imprecise and ambiguous wording in English that glosses over what that means, and all of those definitions seem to be lacking.  Take for example the entry at Britannica : At stake was the existence of a formula that expresses the roots of a quintic equation in terms of the coefficients. This formula, moreover, must involve only the operations of addition, subtraction, multiplication, and division, together with the extraction of roots, since that was all that had been required for the solution of quadratic, cubic, and quartic equations. If such a formula were to exist, the quintic would accordingly be said to be solvable by radicals. Notice the omission of exponentation, which I assume is a typo, but it of course can be recovered by taking reciprocal roots (e.g. $ x^3 = \sqrt[^1/_3]{x} $ ).  Ignoring that issue for the moment, this would seem to allow terms like: $ \pi^a $ $ e^{a \pi i} $ $ \sqrt{2}^{\sqrt{2}} $ $ \sqrt[\pi]{a^{b^c}} $ $ i^a $ ...where $ a,b,... $ (etc.) are coefficients of the original polynomial (i.e. $ ax^5 + bx^4 + cx^3 + dx^2 + ex + f $ ).  This seems pretty typical of the information out there, where there are a lot of potential ambiguities. Wikipedia's entry for Algebraic Solution , is different (more accurate?), stating: An algebraic solution or solution in radicals is a closed form expression, and more specifically a closed-form algebraic expression, that is the solution of an algebraic equation in terms of the coefficients, relying only on addition, subtraction, multiplication, division, raising to integer powers, and the extraction of roots (square roots, cube roots, etc.). ...differences include ""raising to integer powers"", and extraction of roots, but not being exactly clear if the n of nth root can be irrational, imaginary, or a coefficient of the equation.  The mention of ""raising to integer powers"" seems a little odd, since I can effectively raise to rational powers by combining exponentation and root extraction $ a^{^7/_{16}} = \sqrt[16]{a^7} $ Also missing is the mention of a finite number of terms, which is present in a lot of presentations.  I also assume that we're talking about a fixed number of terms, so there would be no number of terms depending on an intermediate calculation, or towers of exponents based on a coefficient.  And there is no mention if the use of transcendental constants are allowed. To that end, I'd like an executable computer algorithm that describes the form of a ""solution in radicals"".  Here's one attempt at a ""solution in radicals"" checker using Mathematica notation: radicalsQ[_Symbol] := True radicalsQ[_?NumericQ] := True radicalsQ[x_ + y_] := radicalsQ[x] && radicalsQ[y] radicalsQ[x_ - y_] := radicalsQ[x] && radicalsQ[y] radicalsQ[x_ * y_] := radicalsQ[x] && radicalsQ[y] radicalsQ[x_ / y_] := radicalsQ[x] && radicalsQ[y] radicalsQ[x_ ^ _Integer] := radicalsQ[x] radicalsQ[root[_Integer,x_]] := radicalsQ[x] radicalsQ[_] := False ...which you can execute on-line here with the mathics.net webpage.  Can anyone point me in the direction of a reference that might verify or contradict the above?  Some day I'd like to learn how to prove Abel's Impossibility Theorem , but I'm not there yet.  But in the mean time, I'm just interested in this small aspect. Here are some tests, showing a few terms that pass and fail the above criteria. trusies = Map[radicalsQ,{123, a, 2*b, (-b + root[2,b^2-4*a*c])/(2*a),                           root[16,a^7],root[16,a]^7, Pi*b,                           root[2,a*E^I]+b^123-c/d}] falsies = Map[radicalsQ,{2^a,root[a,b],a^I}]  allTests = (And @@ trusies) && !(Or @@ falsies)",,"['abstract-algebra', 'radicals']"
71,Books on Rings without Identity,Books on Rings without Identity,,"I was just wondering if anybody knows of any good books or articles that study rings (and algebras) without (or not necessarily with) identity. I have gone through Thomas Hungerford's Algebra textbook (and loved it), but every book I have read afterwards on noncommutative algebra (Farb and Dennis' Noncommutative Algebra and T. Y. Lam's A First Course in Noncommutative Rings ) have assumed that all rings are unitary. Could anyone give me a good reference please? Thank you all in advance!","I was just wondering if anybody knows of any good books or articles that study rings (and algebras) without (or not necessarily with) identity. I have gone through Thomas Hungerford's Algebra textbook (and loved it), but every book I have read afterwards on noncommutative algebra (Farb and Dennis' Noncommutative Algebra and T. Y. Lam's A First Course in Noncommutative Rings ) have assumed that all rings are unitary. Could anyone give me a good reference please? Thank you all in advance!",,"['abstract-algebra', 'reference-request', 'ring-theory', 'noncommutative-algebra', 'rngs']"
72,The $i$-th center $Z_{i}(G)$,The -th center,i Z_{i}(G),"Let $H$ be a normal subgroup of a $p$-group $G$, $H$ is of order $p^i$. Prove that $H$ is contained in the $i$-th center $Z_{i}(G)$. Recall that we define $Z_{0}(G)=1$, and for $i>0$, $Z_{i}$ is the subgroup of $G$ corresponding to $Z(G/Z_{i-1})$ by the Correspondence Theorem: $Z_{i}/Z_{i-1}=Z(G/Z_{i-1})$ The sequence of subgroups $Z_{0}\subset Z_{1}\subset Z_{2}\subset\ldots$ is called the upper central series of $G$ I use induction on $i$ and consider $G/Z(G)$. The case $i=0$ is trivial ($H=1$ and $Z_{0}(G)=1$). How should I continue the proof? Thanks for any insight.","Let $H$ be a normal subgroup of a $p$-group $G$, $H$ is of order $p^i$. Prove that $H$ is contained in the $i$-th center $Z_{i}(G)$. Recall that we define $Z_{0}(G)=1$, and for $i>0$, $Z_{i}$ is the subgroup of $G$ corresponding to $Z(G/Z_{i-1})$ by the Correspondence Theorem: $Z_{i}/Z_{i-1}=Z(G/Z_{i-1})$ The sequence of subgroups $Z_{0}\subset Z_{1}\subset Z_{2}\subset\ldots$ is called the upper central series of $G$ I use induction on $i$ and consider $G/Z(G)$. The case $i=0$ is trivial ($H=1$ and $Z_{0}(G)=1$). How should I continue the proof? Thanks for any insight.",,"['abstract-algebra', 'group-theory', 'p-groups']"
73,Showing that an integral domain is a PID if it satisfies two conditions,Showing that an integral domain is a PID if it satisfies two conditions,,"This is just a textbook problem from Dummit and Foote, but the issue is that our class barely touched on PIDs and the preceding material, so I don't really know or understand much. Anyway, Let $R$ be an integral domain.  If $R$ satisfies the following: i. any two nonzero $a,b \in R$ have a gcd in the form of $d=ra+sb, r,s \in R$ ii. If $a_1, a_2,...$ are nonzero in $R$ such that $a_{i+1}$ divides $a_i$ for every $i$ then $\exists N \in \mathbb{Z}$ such that $a_n$ is an unit times $a_N$  $\forall n \ge N$, prove that $R$ is a principal ideal domain. From what I've gathered, the second condition means that $(a_1) \subset (a_2) \subset...$ and $(a_N) = (a_n)$ $\forall n \ge N$.  However, I'm not sure what I should do now. I'm worried that I'm lacking the necessary context here especially since we used Artin pretty much all semester. In short, my question is: how should I proceed with this proof given what I know?","This is just a textbook problem from Dummit and Foote, but the issue is that our class barely touched on PIDs and the preceding material, so I don't really know or understand much. Anyway, Let $R$ be an integral domain.  If $R$ satisfies the following: i. any two nonzero $a,b \in R$ have a gcd in the form of $d=ra+sb, r,s \in R$ ii. If $a_1, a_2,...$ are nonzero in $R$ such that $a_{i+1}$ divides $a_i$ for every $i$ then $\exists N \in \mathbb{Z}$ such that $a_n$ is an unit times $a_N$  $\forall n \ge N$, prove that $R$ is a principal ideal domain. From what I've gathered, the second condition means that $(a_1) \subset (a_2) \subset...$ and $(a_N) = (a_n)$ $\forall n \ge N$.  However, I'm not sure what I should do now. I'm worried that I'm lacking the necessary context here especially since we used Artin pretty much all semester. In short, my question is: how should I proceed with this proof given what I know?",,"['abstract-algebra', 'ring-theory', 'principal-ideal-domains']"
74,"Structures with addition, multiplication and exponentiation.","Structures with addition, multiplication and exponentiation.",,"The set $\mathbb{N}$ can be viewed as a mathematical structure with operations off addition, multiplication and exponentiation. Observe that: It forms an Abelian monoid under both addition and multiplication. Multiplication distributes over addition. $1^x = x^{0} = 1$ $x^{a+b}=x^{a}x^{b}$ $x^{ab} = (x^a)^b$ Furthermore, the set $[0,\infty)$ can also be viewed in this way. Are there other interesting examples of this sort of thing? I am especially looking for examples lacking a natural total order. Remark . A few more examples occur to me. However, they're both naturally ordered. Firstly, for every strong limit cardinal $\kappa$, I think that the set $\{\nu < \kappa\}$ is an example of such a structure. Secondly, if we drop the requirements that addition and multiplication be commutative, and require distributivity only on the left, as in $$x(a+b)=xa+xb,$$ then every non-trivial ordinal that is closed under exponentiation is an example of such a structure.","The set $\mathbb{N}$ can be viewed as a mathematical structure with operations off addition, multiplication and exponentiation. Observe that: It forms an Abelian monoid under both addition and multiplication. Multiplication distributes over addition. $1^x = x^{0} = 1$ $x^{a+b}=x^{a}x^{b}$ $x^{ab} = (x^a)^b$ Furthermore, the set $[0,\infty)$ can also be viewed in this way. Are there other interesting examples of this sort of thing? I am especially looking for examples lacking a natural total order. Remark . A few more examples occur to me. However, they're both naturally ordered. Firstly, for every strong limit cardinal $\kappa$, I think that the set $\{\nu < \kappa\}$ is an example of such a structure. Secondly, if we drop the requirements that addition and multiplication be commutative, and require distributivity only on the left, as in $$x(a+b)=xa+xb,$$ then every non-trivial ordinal that is closed under exponentiation is an example of such a structure.",,"['abstract-algebra', 'examples-counterexamples']"
75,Verifying finite simple groups,Verifying finite simple groups,,"The classification of finite simple groups required thousands of pages in journals. The end result is that a finite group is simple if and only if it is on a list of 26 sporadic groups and several families of groups. Usually in classification theorems proving that the items on the list do what they're supposed to do is far simpler than proving that the list is complete. Is that the case here?  How hard would it be for someone who only knows basic group theory to verify that the groups on the list really are finite simple groups? Update : To break the question up a bit, which parts of the verification would be easiest, hardest, tedious but elementary, etc.? For example, the prime cyclic groups are simple and trivial to verify.","The classification of finite simple groups required thousands of pages in journals. The end result is that a finite group is simple if and only if it is on a list of 26 sporadic groups and several families of groups. Usually in classification theorems proving that the items on the list do what they're supposed to do is far simpler than proving that the list is complete. Is that the case here?  How hard would it be for someone who only knows basic group theory to verify that the groups on the list really are finite simple groups? Update : To break the question up a bit, which parts of the verification would be easiest, hardest, tedious but elementary, etc.? For example, the prime cyclic groups are simple and trivial to verify.",,"['abstract-algebra', 'group-theory', 'simple-groups']"
76,Suppose $H \le G$ and $g^2\in H$ for all $g\in G$. Show $H$ is a normal subgroup of $G$ [duplicate],Suppose  and  for all . Show  is a normal subgroup of  [duplicate],H \le G g^2\in H g\in G H G,"This question already has answers here : Let $H$ be a subgroup of a group $G$ such that $x^2 \in H$ , $\forall x\in G$ . Prove that $H$ is a normal subgroup of $G$ (2 answers) Closed 10 years ago . Let $G$ be a group and $H$ a subgroup of $G$. Suppose $g^2\in H$ for all $g\in G$. Show $H$ is a normal subgroup of $G$. I tried lots of methods, but failed. Any suggestion? Thanks.","This question already has answers here : Let $H$ be a subgroup of a group $G$ such that $x^2 \in H$ , $\forall x\in G$ . Prove that $H$ is a normal subgroup of $G$ (2 answers) Closed 10 years ago . Let $G$ be a group and $H$ a subgroup of $G$. Suppose $g^2\in H$ for all $g\in G$. Show $H$ is a normal subgroup of $G$. I tried lots of methods, but failed. Any suggestion? Thanks.",,"['abstract-algebra', 'group-theory']"
77,What is the orbit of a permutation?,What is the orbit of a permutation?,,"I have the following statement: $\sigma, \tau \in S_n$ are conjugated if and only if their orbits have the same length. I only know orbits in the context of groups acting on a set. Namely, let $X$ be a set and $G$ be a group. Then, $Gx := \{gx |\, g \in G\}$ is called orbit of $x$ in $G$. What in this case is $X$ and what is $G$?","I have the following statement: $\sigma, \tau \in S_n$ are conjugated if and only if their orbits have the same length. I only know orbits in the context of groups acting on a set. Namely, let $X$ be a set and $G$ be a group. Then, $Gx := \{gx |\, g \in G\}$ is called orbit of $x$ in $G$. What in this case is $X$ and what is $G$?",,"['abstract-algebra', 'group-theory', 'group-actions', 'symmetric-groups']"
78,Divisible module which is not injective,Divisible module which is not injective,,"On searching for some example of divisible module but not injective, I come across one in T.Y.Lam, Lectures on Modules and Rings . He considers the $\mathbb{Z}[x]$-module $M=\mathbb{Q}(x)/\mathbb{Z}[x]$, where $\mathbb{Q}(x)$ denotes the quotient fields of $\mathbb{Z}[x]$. It's clear that $M$ is divisible, but how can I go about proving it's not injective? Can someone please give me a little push on this? Thanks a lot, And have a good day,","On searching for some example of divisible module but not injective, I come across one in T.Y.Lam, Lectures on Modules and Rings . He considers the $\mathbb{Z}[x]$-module $M=\mathbb{Q}(x)/\mathbb{Z}[x]$, where $\mathbb{Q}(x)$ denotes the quotient fields of $\mathbb{Z}[x]$. It's clear that $M$ is divisible, but how can I go about proving it's not injective? Can someone please give me a little push on this? Thanks a lot, And have a good day,",,"['abstract-algebra', 'modules', 'injective-module']"
79,Prime ideal and nilpotent elements [closed],Prime ideal and nilpotent elements [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question If $\mathfrak p \subset R$ is a prime ideal, prove that for every nilpotent $r \in R$ it follows that $r \in \mathfrak p$. The only hint that my tutor gave me was to use induction. Can someone explain what he means by this? Thanks for the help!","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question If $\mathfrak p \subset R$ is a prime ideal, prove that for every nilpotent $r \in R$ it follows that $r \in \mathfrak p$. The only hint that my tutor gave me was to use induction. Can someone explain what he means by this? Thanks for the help!",,"['abstract-algebra', 'ring-theory', 'ideals']"
80,Points and maximal ideals in polynomial rings,Points and maximal ideals in polynomial rings,,"Let $k$ be a field, then I want to prove the following statement: for every $P=(b_1,\ldots,b_n)\in K^n$, the ideal $\mathfrak{m}_P=(x_1-b_1,\ldots,x_n-b_n)$ is maximal in the polynomial ring $k[x_1,\ldots,x_n]$. To prove this, I consider the evaluation map $$v_P:k[x_1,\ldots,x_n]\longrightarrow k$$ sending a polynomial $f(x_1,\ldots,x_n)$ to $f(b_1,\ldots,b_n)$. Then $v_P$ is a surjective morphism of rings. So we have that the quotient of $k[x_1,\ldots,x_n]$ by the kernel of $v_P$ is isomorphic to $k$, which is a field, thus is a field itself and $\ker v_P$ is maximal. So we are left to prove that $\mathfrak{m}_P=\ker v_P$. One of the inclusions is obvious, by definition of $\mathfrak{m}_P$. On the other side, I don't know how to prove that $\ker v_P$ is contained in $\mathfrak{m}_P$.","Let $k$ be a field, then I want to prove the following statement: for every $P=(b_1,\ldots,b_n)\in K^n$, the ideal $\mathfrak{m}_P=(x_1-b_1,\ldots,x_n-b_n)$ is maximal in the polynomial ring $k[x_1,\ldots,x_n]$. To prove this, I consider the evaluation map $$v_P:k[x_1,\ldots,x_n]\longrightarrow k$$ sending a polynomial $f(x_1,\ldots,x_n)$ to $f(b_1,\ldots,b_n)$. Then $v_P$ is a surjective morphism of rings. So we have that the quotient of $k[x_1,\ldots,x_n]$ by the kernel of $v_P$ is isomorphic to $k$, which is a field, thus is a field itself and $\ker v_P$ is maximal. So we are left to prove that $\mathfrak{m}_P=\ker v_P$. One of the inclusions is obvious, by definition of $\mathfrak{m}_P$. On the other side, I don't know how to prove that $\ker v_P$ is contained in $\mathfrak{m}_P$.",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'polynomials', 'ideals']"
81,What About The Converse of Lagrange's Theorem?,What About The Converse of Lagrange's Theorem?,,"Given a positive integer $n$, a group $G$ of order $n$, and a divisor $d$ of $n$, in what cases can we be assured of the existence of a subgroup $H$ of $G$ of order $d$? What's the situation in the case of the symmetric group on $m$ letters or for the alternating group? What's the most general statement in each case?","Given a positive integer $n$, a group $G$ of order $n$, and a divisor $d$ of $n$, in what cases can we be assured of the existence of a subgroup $H$ of $G$ of order $d$? What's the situation in the case of the symmetric group on $m$ letters or for the alternating group? What's the most general statement in each case?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
82,A field that is an ordered field in two distinct ways,A field that is an ordered field in two distinct ways,,"Question: Explain the construction below (taken directly from Counter Examples in Analysis): An ordered field is a field $F$ that contains a subset $P$ such that    $P$ is closed with respect to addition and multiplication and exactly one of the following are true:   $$x \in P; x = 0; -x \in P$$ The set $F$ of all numbers of the form $r + s\sqrt{2}$, where $r$ and $s$ are rational and the operations of addition and multiplication are those of the real number system R of which $F$ is a subset, is an ordered field.    Let $P$, defined above, be the set of all members of $F$ that are positive members of R . A second way in which $F$ is an ordered field is provided by the subset $B$ defined:   $$ r+s\sqrt{2} \in B \iff r - s\sqrt{2} \in P.$$ Based on how I've read it these few questions in particular stand out to me. Q1. Isn't the inverse of addition destroyed by selecting only the positive members of $P$? Q2. Can we say that this construction is effectively showing that there exists two automorphisms for the field extension ${\mathbf Q}[\sqrt{2}], {\mathbf Q}\rightarrow {\mathbf R}$? (${\mathbf Q}$ being the rationals) Q3. What are the practical consequences for having these two distinct ways? If there are many, can you sum up their theme? (Read: why is this a counter example except to the rationals and irrationals, or why is this counter example important?) Note: I'm new to fields, if this is an easy/poorly asked question let me know. I'll delete it and ask it again after I've read more, although I would be thankful for a hint in the right direction.","Question: Explain the construction below (taken directly from Counter Examples in Analysis): An ordered field is a field $F$ that contains a subset $P$ such that    $P$ is closed with respect to addition and multiplication and exactly one of the following are true:   $$x \in P; x = 0; -x \in P$$ The set $F$ of all numbers of the form $r + s\sqrt{2}$, where $r$ and $s$ are rational and the operations of addition and multiplication are those of the real number system R of which $F$ is a subset, is an ordered field.    Let $P$, defined above, be the set of all members of $F$ that are positive members of R . A second way in which $F$ is an ordered field is provided by the subset $B$ defined:   $$ r+s\sqrt{2} \in B \iff r - s\sqrt{2} \in P.$$ Based on how I've read it these few questions in particular stand out to me. Q1. Isn't the inverse of addition destroyed by selecting only the positive members of $P$? Q2. Can we say that this construction is effectively showing that there exists two automorphisms for the field extension ${\mathbf Q}[\sqrt{2}], {\mathbf Q}\rightarrow {\mathbf R}$? (${\mathbf Q}$ being the rationals) Q3. What are the practical consequences for having these two distinct ways? If there are many, can you sum up their theme? (Read: why is this a counter example except to the rationals and irrationals, or why is this counter example important?) Note: I'm new to fields, if this is an easy/poorly asked question let me know. I'll delete it and ask it again after I've read more, although I would be thankful for a hint in the right direction.",,"['abstract-algebra', 'group-theory', 'field-theory', 'ordered-fields']"
83,Why are these all the indecomposable projective modules?,Why are these all the indecomposable projective modules?,,"Let $A$ be a finite dimensional associative algebra with unit over a commutative field $k$. Suppose that $M$ is a finitely generated left module. Denote by $I(M)$ the injective hull of $M$ and by $P(M)$ the projective cover of $M$. Suppose that $\{S_i\}_{1\leq i\leq n}$ is the set of all nonisomorphic simple $A$-modules (why is it finite?). Then $\{P(S_i)\}_i$ are all nonisomorphic indecomposable projective modules and $\{I(S_i)\}_i$ all nonisomorphic indecomposable injective modules, why is this true? I'm also wondering why there exist the projective covers? If I call $\mathrm{top}\;M$ the factor module $M/\mathrm{rad}\;M$ where $\mathrm{rad}\;M$ is the radical of $M$, then why $\mathrm{top}\;P(S_i)\cong\;S_i\cong\mathrm{soc}\;I(S_i)$? And why $I(S_i)\cong\mathrm{Hom}(\mathrm{Hom}_A(P(S_i),A),k)$ ? I know that these are a lot of questions, but it makes more sense putting them together in one unique question.","Let $A$ be a finite dimensional associative algebra with unit over a commutative field $k$. Suppose that $M$ is a finitely generated left module. Denote by $I(M)$ the injective hull of $M$ and by $P(M)$ the projective cover of $M$. Suppose that $\{S_i\}_{1\leq i\leq n}$ is the set of all nonisomorphic simple $A$-modules (why is it finite?). Then $\{P(S_i)\}_i$ are all nonisomorphic indecomposable projective modules and $\{I(S_i)\}_i$ all nonisomorphic indecomposable injective modules, why is this true? I'm also wondering why there exist the projective covers? If I call $\mathrm{top}\;M$ the factor module $M/\mathrm{rad}\;M$ where $\mathrm{rad}\;M$ is the radical of $M$, then why $\mathrm{top}\;P(S_i)\cong\;S_i\cong\mathrm{soc}\;I(S_i)$? And why $I(S_i)\cong\mathrm{Hom}(\mathrm{Hom}_A(P(S_i),A),k)$ ? I know that these are a lot of questions, but it makes more sense putting them together in one unique question.",,"['abstract-algebra', 'ring-theory', 'modules', 'noncommutative-algebra']"
84,Subgroups of $S_{4}$ that contain the kernel of a homomorphism $\varphi:S_{4}\to S_{3}$,Subgroups of  that contain the kernel of a homomorphism,S_{4} \varphi:S_{4}\to S_{3},"This is an exercise from Artin's Algebra 2nd Ed. The exercise refers to the following example from the text: The three partitions of the set of four indices    $\{\mathbf{1},\mathbf{2},\mathbf{3},\mathbf{4}\}$ into pairs of subsets of order two are :$$\Pi_{1}\colon\{\mathbf{1},\mathbf{2}\}\cup\{\mathbf{3},\mathbf{4}\},\quad\Pi_{2}\colon\{\mathbf{1},\mathbf{3}\}\cup\{\mathbf{2},\mathbf{4}\},\quad\Pi_{3}\colon\{\mathbf{1},\mathbf{4}\}\cup\{\mathbf{2},\mathbf{3}\}.$$ An element of the symmetric group $S_{4}$ permutes the four indices, and by doing so it also permutes these three partions. This defines a map $\varphi$ from $S_{4}$ to the group of permutations of the set $\{\Pi_{1},\Pi_{2},\Pi_{3}\}$, which is just the symmetric group $S_{3}$. The example goes on to show that $\varphi$ is a homomorphism and that Its kernel can be computed. It is the subgroup of $S_{4}$ consisting of the identity and the three products of disjoint transpositions:   $$K=\left\{1,~(\mathbf{1}~\mathbf{2})(\mathbf{3}~\mathbf{4}),~(\mathbf{1}~\mathbf{3})(\mathbf{2}~\mathbf{4}),~(\mathbf{1}~\mathbf{4})(\mathbf{2}~\mathbf{3})\right\}.$$ The exercise then asks: Determine the six subgroups of $S_{4}$ that contain $K$. I have two difficulties with this exercise. How was $K$ computed? And how can I determine the subgroups of $S_{4}$ that contain $K$ without having to just use brute force to compute all the possible cycle permutations? So far, my naive approach has been to compose elements from $S_{4}$ in an effort to find a composition that gives an element of $K$. While I think this would work eventually, I know there must be an easier way. I should mention that I have always had a difficult time working in $S_{n}$. I'm not familiar with the subgroups of $S_{n}$ and anytime I've had to work with a symmetric group I inevitably have to sit down and write out a table for each permutation and/or the composition of permutations. I haven't tagged this as homework because I'm self studying. (Trying to improve my grasp of permutations and permutation groups.)","This is an exercise from Artin's Algebra 2nd Ed. The exercise refers to the following example from the text: The three partitions of the set of four indices    $\{\mathbf{1},\mathbf{2},\mathbf{3},\mathbf{4}\}$ into pairs of subsets of order two are :$$\Pi_{1}\colon\{\mathbf{1},\mathbf{2}\}\cup\{\mathbf{3},\mathbf{4}\},\quad\Pi_{2}\colon\{\mathbf{1},\mathbf{3}\}\cup\{\mathbf{2},\mathbf{4}\},\quad\Pi_{3}\colon\{\mathbf{1},\mathbf{4}\}\cup\{\mathbf{2},\mathbf{3}\}.$$ An element of the symmetric group $S_{4}$ permutes the four indices, and by doing so it also permutes these three partions. This defines a map $\varphi$ from $S_{4}$ to the group of permutations of the set $\{\Pi_{1},\Pi_{2},\Pi_{3}\}$, which is just the symmetric group $S_{3}$. The example goes on to show that $\varphi$ is a homomorphism and that Its kernel can be computed. It is the subgroup of $S_{4}$ consisting of the identity and the three products of disjoint transpositions:   $$K=\left\{1,~(\mathbf{1}~\mathbf{2})(\mathbf{3}~\mathbf{4}),~(\mathbf{1}~\mathbf{3})(\mathbf{2}~\mathbf{4}),~(\mathbf{1}~\mathbf{4})(\mathbf{2}~\mathbf{3})\right\}.$$ The exercise then asks: Determine the six subgroups of $S_{4}$ that contain $K$. I have two difficulties with this exercise. How was $K$ computed? And how can I determine the subgroups of $S_{4}$ that contain $K$ without having to just use brute force to compute all the possible cycle permutations? So far, my naive approach has been to compose elements from $S_{4}$ in an effort to find a composition that gives an element of $K$. While I think this would work eventually, I know there must be an easier way. I should mention that I have always had a difficult time working in $S_{n}$. I'm not familiar with the subgroups of $S_{n}$ and anytime I've had to work with a symmetric group I inevitably have to sit down and write out a table for each permutation and/or the composition of permutations. I haven't tagged this as homework because I'm self studying. (Trying to improve my grasp of permutations and permutation groups.)",,"['abstract-algebra', 'group-theory']"
85,Embedding of a field extension to another,Embedding of a field extension to another,,Can $\mathbb{Q}(\sqrt {-2})$ be embedded into a cyclic extension of degree 4 over $\mathbb{Q}$?,Can $\mathbb{Q}(\sqrt {-2})$ be embedded into a cyclic extension of degree 4 over $\mathbb{Q}$?,,"['abstract-algebra', 'field-theory', 'galois-theory']"
86,Group Extensions,Group Extensions,,"Let $G$ and $H$ be groups. A group $E$ is called an extension of $G$ by $H$ iff there's a short exact sequence of the type $1\rightarrow G \rightarrow E \rightarrow H \rightarrow 1$ . In that way, $G$ is isomorphic to a normal subgroup of $E$ , and the quotient of $E$ by that subgroup is isomoprhic to $H$ . Next you define that two extensions $E_{1}$ and $E_{2}$ are equivalent when there's a group morphism sucht that certain diagram commutes (the commutative diagram can be found here, Link ). It turns out that with this definition,if two extensions are equivalent the given morphism is an isomorphism. My question is: Suppose you have two extensions that are isomorphic, that is you have $E_{1}$ and $E_{2}$ , which are extensions of $G$ by $H$ , and $E_{1}$ is isomorphic to $E_{2}$ (but you don't know if the diagrams commute). Is $E_{1}$ equivalent to $E_{2}$ ? If not, why is the ""correct"" definition of extension equivalence the one above?","Let and be groups. A group is called an extension of by iff there's a short exact sequence of the type . In that way, is isomorphic to a normal subgroup of , and the quotient of by that subgroup is isomoprhic to . Next you define that two extensions and are equivalent when there's a group morphism sucht that certain diagram commutes (the commutative diagram can be found here, Link ). It turns out that with this definition,if two extensions are equivalent the given morphism is an isomorphism. My question is: Suppose you have two extensions that are isomorphic, that is you have and , which are extensions of by , and is isomorphic to (but you don't know if the diagrams commute). Is equivalent to ? If not, why is the ""correct"" definition of extension equivalence the one above?",G H E G H 1\rightarrow G \rightarrow E \rightarrow H \rightarrow 1 G E E H E_{1} E_{2} E_{1} E_{2} G H E_{1} E_{2} E_{1} E_{2},"['abstract-algebra', 'group-theory']"
87,Maximal submodule in a finitely generated module over a ring,Maximal submodule in a finitely generated module over a ring,,"Let $R$ be a unital ring, $M$ is a finitely generated $R$-module. My question is to prove that there exist a maximal submodule in $M$. However I have no strategy to prove that except using the idea of Zorn lemma. Can any body help me to solve this problem? Also, please give a counter example for the case that if $M$ is not finitely generated. Thank for reading. I beg your pardon for my poor English","Let $R$ be a unital ring, $M$ is a finitely generated $R$-module. My question is to prove that there exist a maximal submodule in $M$. However I have no strategy to prove that except using the idea of Zorn lemma. Can any body help me to solve this problem? Also, please give a counter example for the case that if $M$ is not finitely generated. Thank for reading. I beg your pardon for my poor English",,"['abstract-algebra', 'ring-theory', 'modules']"
88,Non-trivial solutions for cyclotomic polynomials,Non-trivial solutions for cyclotomic polynomials,,"I am seeking algebraic expressions which solve a polynomial equation, in particular an arbitrary cyclotomic polynomial. Let us agree we are not talking about expressions such as $e^{2\pi/7}$. My problem is to distinguish between those expressions I am going to call ""trivial"" and ""non-trivial"". Typically, algebraic expressions with radical signs admit of multiple choices for the value of the radical expression: two for a square root, three for a cube root, etc. I will define a ""non-trivial"" algebraic solution as an expression in radicals such that for any choice of values, the expression is always a solution of the equation. Example: for any quadratic equation, there are two choices for the square root, and both choices give correct solutions. For the fifth cyclotomic polynomial, the solution (which I looked up) is given by the expression: \[ \frac{\sqrt5 - 1}4 + \frac{\sqrt{-5 - \sqrt5}}8 \] This expression takes on four possible values, and each of them is in fact a true solution of the fifth cyclotomic polynomial. It might look like it takes on eight values because there are three choices of the square root, but two of them must be the same choice: you cannot take one value for the square root of five, and then later in the same expression switch to the other value. On the other hand, we have an alternative solution for the same polynomial:  \[ 1^{1/5} \] I define this as a ""trivial"" solution because it takes on five possible values, but only four of them are true solutions of the fifth cyclotomic polynomial. This expression is, of course, a non-trivial solution of the non-irreducible polynomial $x^5 - 1 = 0$, but that's not the polynomial we're talking about. I recently posted a similar question , which I believe was correctly answered by Paul Garret, but I am not at all sure that everyone who participated in the discussion was actually working on the same question. I hope this clarifies the situation. My question, then, was and is: do all the cyclotomic polynomials have ""non-trivial"" solutions? If not, what is the smallest polynomial for which such a solution (a) is not known, or (b) can be shown not to exist? I cannot believe this question is nonsense, and I would be very surprised if it hasn't been answered in the literature. EDIT I am extremely gratifying that you guys had some fun with my question. I have always loved this topic and I think it is the greatest miracle of all math that the six choices of the cubic formula (three cube roots and two square roots) can be made to logically and unambiguously collapse to exactly three values. Because I have only one check mark to award for ""accepted answer"", from many deserving contributors, I award my coveted check-mark to Ben. Thanks again guys.","I am seeking algebraic expressions which solve a polynomial equation, in particular an arbitrary cyclotomic polynomial. Let us agree we are not talking about expressions such as $e^{2\pi/7}$. My problem is to distinguish between those expressions I am going to call ""trivial"" and ""non-trivial"". Typically, algebraic expressions with radical signs admit of multiple choices for the value of the radical expression: two for a square root, three for a cube root, etc. I will define a ""non-trivial"" algebraic solution as an expression in radicals such that for any choice of values, the expression is always a solution of the equation. Example: for any quadratic equation, there are two choices for the square root, and both choices give correct solutions. For the fifth cyclotomic polynomial, the solution (which I looked up) is given by the expression: \[ \frac{\sqrt5 - 1}4 + \frac{\sqrt{-5 - \sqrt5}}8 \] This expression takes on four possible values, and each of them is in fact a true solution of the fifth cyclotomic polynomial. It might look like it takes on eight values because there are three choices of the square root, but two of them must be the same choice: you cannot take one value for the square root of five, and then later in the same expression switch to the other value. On the other hand, we have an alternative solution for the same polynomial:  \[ 1^{1/5} \] I define this as a ""trivial"" solution because it takes on five possible values, but only four of them are true solutions of the fifth cyclotomic polynomial. This expression is, of course, a non-trivial solution of the non-irreducible polynomial $x^5 - 1 = 0$, but that's not the polynomial we're talking about. I recently posted a similar question , which I believe was correctly answered by Paul Garret, but I am not at all sure that everyone who participated in the discussion was actually working on the same question. I hope this clarifies the situation. My question, then, was and is: do all the cyclotomic polynomials have ""non-trivial"" solutions? If not, what is the smallest polynomial for which such a solution (a) is not known, or (b) can be shown not to exist? I cannot believe this question is nonsense, and I would be very surprised if it hasn't been answered in the literature. EDIT I am extremely gratifying that you guys had some fun with my question. I have always loved this topic and I think it is the greatest miracle of all math that the six choices of the cubic formula (three cube roots and two square roots) can be made to logically and unambiguously collapse to exactly three values. Because I have only one check mark to award for ""accepted answer"", from many deserving contributors, I award my coveted check-mark to Ben. Thanks again guys.",,"['abstract-algebra', 'polynomials']"
89,Why is quaternion algebra 4d and not 3d?,Why is quaternion algebra 4d and not 3d?,,"Why is  quaternion algebra 4D and not 3D?  Complex algebra is 2D and what is known as quaternion algebra jumps to 4D. $ i^2 = j^2 = k^2 = ijk = -1 $ Using $1, i, j,$ and $k$ as the base (where complex uses $1$ and $i$ (or $j$ if you are an EE)) which results in a 4-axis space.  Why is there no 3D algebra?","Why is  quaternion algebra 4D and not 3D?  Complex algebra is 2D and what is known as quaternion algebra jumps to 4D. $ i^2 = j^2 = k^2 = ijk = -1 $ Using $1, i, j,$ and $k$ as the base (where complex uses $1$ and $i$ (or $j$ if you are an EE)) which results in a 4-axis space.  Why is there no 3D algebra?",,"['abstract-algebra', 'quaternions']"
90,When do Sylow subgroups have trivial intersection?,When do Sylow subgroups have trivial intersection?,,"When do Sylow subgroups of the same order have trivial intersection? I'm curious because I recently read a proof where it was computed that there are $8$ Sylow 7-subgroups, and hence $8\cdot 6=48$ elements of order 7. This seems to assume that each of the Sylow subgroups has trivial intersection. Why is this the case? Is it true even when the Sylow groups have order a prime power, not necessarily just prime order?","When do Sylow subgroups of the same order have trivial intersection? I'm curious because I recently read a proof where it was computed that there are $8$ Sylow 7-subgroups, and hence $8\cdot 6=48$ elements of order 7. This seems to assume that each of the Sylow subgroups has trivial intersection. Why is this the case? Is it true even when the Sylow groups have order a prime power, not necessarily just prime order?",,['abstract-algebra']
91,What is the difference between addition and product in abstract algebra?,What is the difference between addition and product in abstract algebra?,,"This might seem like a very stupid question and it probably is, but hopefully not as much as one could expect. My question in fact is the following: Does the difference between sum and product lie only in the distinction of their respective neutral elements (i.e. ""0"" for addition and ""1"" for multiplication) and in the ""one-way"" distributive property of multiplication over addition? As a newbie coming to this subject my first instinct while reading up on the basics of abstract algebra (AA from here on) was to take literally the ""abstract"" in AA, which — as I take it — doesn't really have to do with numbers per se , but ""the structures arising from different ways of combining things together"", of which numbers are a very useful and recurring instance, but not the only one. For instance i have learned (from a 3b1b video on youtube) that the set of isomorphic rotations of a polygon is a group, since it is closed under addition, where addition is computed by applying one rotation after the other (also commutativity applies, there exists a ""zero"" element, and for every non-zero element there exists the additive inverse of that element). Here ""addition"" seemed to me to have nothing to do with the familiar algebraic summation of numbers, except for the properties that it holds. Is this the right way of interpreting the subject? That is, am i right in believing that the definition of an operation (a mapping of a set upon itself of the kind $S\times S \longrightarrow S$ ) exactly coincides with its properties and nothing more? (setting aside the fact that we can elaborate different methods of computing the output of these binary operations on different objects)","This might seem like a very stupid question and it probably is, but hopefully not as much as one could expect. My question in fact is the following: Does the difference between sum and product lie only in the distinction of their respective neutral elements (i.e. ""0"" for addition and ""1"" for multiplication) and in the ""one-way"" distributive property of multiplication over addition? As a newbie coming to this subject my first instinct while reading up on the basics of abstract algebra (AA from here on) was to take literally the ""abstract"" in AA, which — as I take it — doesn't really have to do with numbers per se , but ""the structures arising from different ways of combining things together"", of which numbers are a very useful and recurring instance, but not the only one. For instance i have learned (from a 3b1b video on youtube) that the set of isomorphic rotations of a polygon is a group, since it is closed under addition, where addition is computed by applying one rotation after the other (also commutativity applies, there exists a ""zero"" element, and for every non-zero element there exists the additive inverse of that element). Here ""addition"" seemed to me to have nothing to do with the familiar algebraic summation of numbers, except for the properties that it holds. Is this the right way of interpreting the subject? That is, am i right in believing that the definition of an operation (a mapping of a set upon itself of the kind ) exactly coincides with its properties and nothing more? (setting aside the fact that we can elaborate different methods of computing the output of these binary operations on different objects)",S\times S \longrightarrow S,['abstract-algebra']
92,Ring of integer-valued polynomials Int(X) is not isomorphic to Z[X],Ring of integer-valued polynomials Int(X) is not isomorphic to Z[X],,"Write $\operatorname{Int}(\mathbb{Z})$ for the set of polynomials $p$ mapping integers to integers, i.e., $p(\mathbb{Z}) \subseteq \mathbb{Z}$ . I have shown that $\operatorname{Int}(\mathbb{Z})$ is a subring of $\mathbb{Q}[X]$ . I am now asked to prove that $\operatorname{Int}(\mathbb{Z})$ is not isomorphic to $\mathbb{Z}[X]$ . By dabbling around online I found that $\operatorname{Int}(\mathbb{Z})$ is non-Noetherian, whilst $\mathbb{Z}$ as a PID is Noetherian and so $\mathbb{Z}[X]$ is Noetherian, hence the two rings in question cannot be isomorphic. However, I would like to have a more elementary proof. We have $\mathbb{Z}[X] \subsetneq \operatorname{Int}(\mathbb{Z})$ since the latter contains polynomials  such as $\frac{1}{2} X^2 + \frac{1}{2} X$ . I thought I could get a contradiction by considering the 'extra elements', but since both rings are infinite and a ring automorphism needs not be the identity I don't know how to proceed. What are some other properties of ring isomorphisms that I can consider to reach a contradiction?","Write for the set of polynomials mapping integers to integers, i.e., . I have shown that is a subring of . I am now asked to prove that is not isomorphic to . By dabbling around online I found that is non-Noetherian, whilst as a PID is Noetherian and so is Noetherian, hence the two rings in question cannot be isomorphic. However, I would like to have a more elementary proof. We have since the latter contains polynomials  such as . I thought I could get a contradiction by considering the 'extra elements', but since both rings are infinite and a ring automorphism needs not be the identity I don't know how to proceed. What are some other properties of ring isomorphisms that I can consider to reach a contradiction?",\operatorname{Int}(\mathbb{Z}) p p(\mathbb{Z}) \subseteq \mathbb{Z} \operatorname{Int}(\mathbb{Z}) \mathbb{Q}[X] \operatorname{Int}(\mathbb{Z}) \mathbb{Z}[X] \operatorname{Int}(\mathbb{Z}) \mathbb{Z} \mathbb{Z}[X] \mathbb{Z}[X] \subsetneq \operatorname{Int}(\mathbb{Z}) \frac{1}{2} X^2 + \frac{1}{2} X,"['abstract-algebra', 'polynomials', 'ring-isomorphism', 'integer-valued-polynomials']"
93,Avoiding catastrophic cancellation [closed],Avoiding catastrophic cancellation [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 3 years ago . Improve this question Dear computational scientists, I have the following formula that I need to rewrite in order to avoid catastrophic cancellation. $y =\sqrt{\frac{1}{2}(1-\sqrt{1-x^{2})}}$ As x becomes smaller $\sqrt{1-x^{2}}$ approaches 1 so you will get 1 - 1.000000000......1 what will result in a catastrophic cancellation. I tried to rewrite the formula myself in a few different ways, but didn't manage yet to avoid the catastrophic cancellation. The goal is to approximate pi: import numpy as np   tn = 0.5 for i in range(1,100):     tn1 = np.sqrt(0.5*(1-np.sqrt(1-tn**2)))     print(i, 6*2**i*tn1)     tn = tn1 output 1 3.1058285412302498 2 3.132628613281237 3 3.139350203046872 4 3.14103195089053 5 3.1414524722853443 6 3.141557607911622 7 3.141583892148936 8 3.1415904632367617 9 3.1415921060430483 10 3.1415925165881546 11 3.1415926186407894 12 3.1415926453212157 13 3.1415926453212157 14 3.1415926453212157 15 3.1415926453212157 16 3.141593669849427 17 3.1415923038117377 18 3.1416086962248038 19 3.1415868396550413 20 3.1416742650217575 21 3.1416742650217575 22 3.1430727401700396 23 3.1598061649411346 24 3.181980515339464 25 3.3541019662496847 26 4.242640687119286 27 6.0 28 0.0 29 0.0 30 0.0 31 0.0 32 0.0 Question: How should I rewrite the formula to avoid catastrophic cancellation?","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 3 years ago . Improve this question Dear computational scientists, I have the following formula that I need to rewrite in order to avoid catastrophic cancellation. As x becomes smaller approaches 1 so you will get 1 - 1.000000000......1 what will result in a catastrophic cancellation. I tried to rewrite the formula myself in a few different ways, but didn't manage yet to avoid the catastrophic cancellation. The goal is to approximate pi: import numpy as np   tn = 0.5 for i in range(1,100):     tn1 = np.sqrt(0.5*(1-np.sqrt(1-tn**2)))     print(i, 6*2**i*tn1)     tn = tn1 output 1 3.1058285412302498 2 3.132628613281237 3 3.139350203046872 4 3.14103195089053 5 3.1414524722853443 6 3.141557607911622 7 3.141583892148936 8 3.1415904632367617 9 3.1415921060430483 10 3.1415925165881546 11 3.1415926186407894 12 3.1415926453212157 13 3.1415926453212157 14 3.1415926453212157 15 3.1415926453212157 16 3.141593669849427 17 3.1415923038117377 18 3.1416086962248038 19 3.1415868396550413 20 3.1416742650217575 21 3.1416742650217575 22 3.1430727401700396 23 3.1598061649411346 24 3.181980515339464 25 3.3541019662496847 26 4.242640687119286 27 6.0 28 0.0 29 0.0 30 0.0 31 0.0 32 0.0 Question: How should I rewrite the formula to avoid catastrophic cancellation?",y =\sqrt{\frac{1}{2}(1-\sqrt{1-x^{2})}} \sqrt{1-x^{2}},"['abstract-algebra', 'algebra-precalculus', 'computer-science', 'catastrophic-cancellation']"
94,Irreducible representation that is not absolutely semisimple,Irreducible representation that is not absolutely semisimple,,Let $G\to \mathrm{GL}_n(k)$ be an irreducible representation of a group $G$ over a perfect field $k$ . Is it possible that the induced representation $G\to \mathrm{GL}_n(\overline{k})$ is not semisimple? I have some examples in the case of a non-perfect field. Can this happen if $G$ is finite?,Let be an irreducible representation of a group over a perfect field . Is it possible that the induced representation is not semisimple? I have some examples in the case of a non-perfect field. Can this happen if is finite?,G\to \mathrm{GL}_n(k) G k G\to \mathrm{GL}_n(\overline{k}) G,['abstract-algebra']
95,The number of subgroups of index two in $G$,The number of subgroups of index two in,G,"Statement : Let $G$ be a finite group. Then $ I_2(G)=[G:G^2]-1$ . where; $I_2(G)$ is the number of subgroups of index two in $G$ , $[G,G^2]$ represents the index of $G^2$ in $G$ and $G^2= \langle \{x^2: x\in G\} \rangle$ . My work : First I proved that $G^2$ is the subgroup of $G$ generated by squares of elements in $G$ and also $G^2$ is normal in $G$ . I found that $\frac{G}{G^2}$ is abelian. Then, I took for instance, $G=D_n=\langle R,S:$ $R$ is a rotation with $o(R)=n$ and $S$ is  reflection $\rangle $ so that $G^2= \langle R^2 \rangle$ . Which tells that the above statement is true for $D_n$ . My Question: I thought a lot for the proof of this statement but I am not getting any useful tool\concept to prove this. Please provide a proof of this statement.","Statement : Let be a finite group. Then . where; is the number of subgroups of index two in , represents the index of in and . My work : First I proved that is the subgroup of generated by squares of elements in and also is normal in . I found that is abelian. Then, I took for instance, is a rotation with and is  reflection so that . Which tells that the above statement is true for . My Question: I thought a lot for the proof of this statement but I am not getting any useful tool\concept to prove this. Please provide a proof of this statement.","G  I_2(G)=[G:G^2]-1 I_2(G) G [G,G^2] G^2 G G^2= \langle \{x^2: x\in G\} \rangle G^2 G G G^2 G \frac{G}{G^2} G=D_n=\langle R,S: R o(R)=n S \rangle  G^2= \langle R^2 \rangle D_n","['abstract-algebra', 'group-theory']"
96,Is there any subgroup between $A_n$ and $A_{n+1}$,Is there any subgroup between  and,A_n A_{n+1},"Let $A_n$ be the alternating group of $n$ elements. Is there any subgroup $H$ of $A_{n+1}$ such that $A_n \subsetneq H \subsetneq A_{n+1}$ for $n \geq 5$ ? Actually, I'm working on the simplicity of $A_n$ for $n \geq 5$. And I find that it may help to consider this question. Thanks for your help.","Let $A_n$ be the alternating group of $n$ elements. Is there any subgroup $H$ of $A_{n+1}$ such that $A_n \subsetneq H \subsetneq A_{n+1}$ for $n \geq 5$ ? Actually, I'm working on the simplicity of $A_n$ for $n \geq 5$. And I find that it may help to consider this question. Thanks for your help.",,"['abstract-algebra', 'group-theory', 'symmetric-groups']"
97,Does $R[[x]] \cong S[[x]]$ imply $R\cong S$,Does  imply,R[[x]] \cong S[[x]] R\cong S,"Let $R,S$ be commutative unitary rings. Is it true that $$R[[x]] \cong S[[x]] \quad \Rightarrow \quad  R\cong S.$$ Here by $R[[x]], S[[x]]$ I mean the ring of formal power series and the isomorphisms as isomorphisms of rings. In fact, in this question Does $R[x] \cong S[x]$ imply $R \cong S$? the answer for the polynomial ring is negative and I became curious about the formal power series case.","Let $R,S$ be commutative unitary rings. Is it true that $$R[[x]] \cong S[[x]] \quad \Rightarrow \quad  R\cong S.$$ Here by $R[[x]], S[[x]]$ I mean the ring of formal power series and the isomorphisms as isomorphisms of rings. In fact, in this question Does $R[x] \cong S[x]$ imply $R \cong S$? the answer for the polynomial ring is negative and I became curious about the formal power series case.",,"['abstract-algebra', 'commutative-algebra', 'formal-power-series']"
98,$\mathbb{Z}[\sqrt{11}]$ is norm-euclidean,is norm-euclidean,\mathbb{Z}[\sqrt{11}],"I'm trying to show that $\mathbb{Z}[\sqrt{11}]$ is Euclidean with respect to the function $a+b\sqrt{11} \mapsto|N(a+b\sqrt{11})| = | a^2 -11b^2|$ By multiplicativity, it suffices to show that $\forall x \in \mathbb{Q}(\sqrt{11}) \exists n \in \mathbb{Z}(\sqrt{11}):|N(n-x)| < 1$ For the analogous statement for $\mathbb Z [\sqrt6]$, it worked by considering different cases, so I tried to do the same thing here. Here is what I did so far: Let $x+y\sqrt{11} \in \mathbb Q (\sqrt{11})$ Case 1: Suppose there exists a $b \in \mathbb Z$ s.t. $|y-b| < \frac{1}{\sqrt{11}}$, then we can choose such a $b$ and a $a \in \mathbb Z$ s.t. $|x-a| \leq \frac{1}{2}$, then we have $|N(x+y\sqrt{11}-(a+b\sqrt{11}))| < 1$ From now on suppose $\forall b \in \mathbb Z: |y-b| > \frac{1}{\sqrt{11}}$ Case 2: Suppose there exists a $b \in \mathbb Z$ s.t. $|y-b| < \sqrt{\frac{5}{44}}$ Then we have $1 < 11 (y-b)^2 < \frac{5}{4}$, so we can choose $a \in \mathbb Z$ such that $\frac{1}{2} \leq |x-a| \leq 1$, then we have $|N(x+y\sqrt{11}-(a+b\sqrt{11}))| < 1$ From now on suppose $\forall b \in \mathbb Z: |y-b| > \sqrt{\frac{5}{44}}$ Case 3: Suppose there exists a $b \in \mathbb Z$ s.t. $|y-b| < \sqrt{\frac{2}{11}}$ Then we can choose $a \in \mathbb Z $ s.t. $1 \leq |x-a| \leq \frac{3}{2}$, then we have $|N(x+y\sqrt{11}-(a+b\sqrt{11}))| < 1$ From now on, we may suppose that $|y-b| > \sqrt{\frac{2}{11}}$. This is where I'm stuck. I tried choosing $b \in \mathbb Z$ s.t. $\frac{1}{2} \geq |y-b| > \sqrt{\frac{2}{11}}$, but then I run into problems, whether I choose $a \in \mathbb Z$ s.t. $1 \leq |x-a| \leq \frac{3}{2}$ or s.t. $ \frac{3}{2} \leq |x-a| \leq 2$","I'm trying to show that $\mathbb{Z}[\sqrt{11}]$ is Euclidean with respect to the function $a+b\sqrt{11} \mapsto|N(a+b\sqrt{11})| = | a^2 -11b^2|$ By multiplicativity, it suffices to show that $\forall x \in \mathbb{Q}(\sqrt{11}) \exists n \in \mathbb{Z}(\sqrt{11}):|N(n-x)| < 1$ For the analogous statement for $\mathbb Z [\sqrt6]$, it worked by considering different cases, so I tried to do the same thing here. Here is what I did so far: Let $x+y\sqrt{11} \in \mathbb Q (\sqrt{11})$ Case 1: Suppose there exists a $b \in \mathbb Z$ s.t. $|y-b| < \frac{1}{\sqrt{11}}$, then we can choose such a $b$ and a $a \in \mathbb Z$ s.t. $|x-a| \leq \frac{1}{2}$, then we have $|N(x+y\sqrt{11}-(a+b\sqrt{11}))| < 1$ From now on suppose $\forall b \in \mathbb Z: |y-b| > \frac{1}{\sqrt{11}}$ Case 2: Suppose there exists a $b \in \mathbb Z$ s.t. $|y-b| < \sqrt{\frac{5}{44}}$ Then we have $1 < 11 (y-b)^2 < \frac{5}{4}$, so we can choose $a \in \mathbb Z$ such that $\frac{1}{2} \leq |x-a| \leq 1$, then we have $|N(x+y\sqrt{11}-(a+b\sqrt{11}))| < 1$ From now on suppose $\forall b \in \mathbb Z: |y-b| > \sqrt{\frac{5}{44}}$ Case 3: Suppose there exists a $b \in \mathbb Z$ s.t. $|y-b| < \sqrt{\frac{2}{11}}$ Then we can choose $a \in \mathbb Z $ s.t. $1 \leq |x-a| \leq \frac{3}{2}$, then we have $|N(x+y\sqrt{11}-(a+b\sqrt{11}))| < 1$ From now on, we may suppose that $|y-b| > \sqrt{\frac{2}{11}}$. This is where I'm stuck. I tried choosing $b \in \mathbb Z$ s.t. $\frac{1}{2} \geq |y-b| > \sqrt{\frac{2}{11}}$, but then I run into problems, whether I choose $a \in \mathbb Z$ s.t. $1 \leq |x-a| \leq \frac{3}{2}$ or s.t. $ \frac{3}{2} \leq |x-a| \leq 2$",,"['abstract-algebra', 'ring-theory', 'algebraic-number-theory', 'quadratic-forms', 'euclidean-domain']"
99,Presentation of a group question,Presentation of a group question,,"So I know that given a presentation of a group $G$, one can derive from the relations of the group presentation any element in the group $G$ right. However, I do have some confusion. If we take $G=Q_8$ , the famous non-commutative group (Quaternion group), we know that the group presentation of $Q_8$ is as follows $$\large{Q_8 = \big<i,j \space  \big| \space i^4 = 1, j^2 = i^2, j^{-1}ij = i^{-1} \big>}$$ Now it is argued that one can find any element of the group $Q_8$ using the relations given in a group presentation. Now I want to find $k$ because I do know that $k \in Q_8$, and I know that $ij = k$. How can I find $ij$ from these relations. Here is my attempt $i^4=1 \implies i^2i^2 = 1$and since we know that $i^2 =j^2$ so we get that $i^2i^2= 1 \implies i^2j^2 =1$. Now I left multiply by $i^{-1}$ and right multiply by $j^{-1}$ both sides of the equation to end up with $ij = i^{-1}j^{-1}$ and since I know that $i^{-1} = j^{-1}ij$ then I get $ij = j^{-1}ijj^{-1}$ and hence I get $ij = j^{-1}i$. The thing is I never find $k$. Basically my question is the following Given a group presentation ,how come can we find all the elements using the relations in a group presentation even though all the elements may not be listed in the the group presentation. You see there is no $k$ what so ever in the group presentation of $Q_8$. So how come I will be able to find it ?  So should we make life easier, and include all the elements in a group presentation. Even if we did that, there is no clue that $ij = k$ in that group presentation, One must know before hand this relation or else how can he even derive it. Well he can get $ij$ but then he may not be able to know what is $ij$ equals anyway` ` I got this from dummit book page(219) in the section A word on free groups (section 6.3) Thanks for taking the time to read my question :)","So I know that given a presentation of a group $G$, one can derive from the relations of the group presentation any element in the group $G$ right. However, I do have some confusion. If we take $G=Q_8$ , the famous non-commutative group (Quaternion group), we know that the group presentation of $Q_8$ is as follows $$\large{Q_8 = \big<i,j \space  \big| \space i^4 = 1, j^2 = i^2, j^{-1}ij = i^{-1} \big>}$$ Now it is argued that one can find any element of the group $Q_8$ using the relations given in a group presentation. Now I want to find $k$ because I do know that $k \in Q_8$, and I know that $ij = k$. How can I find $ij$ from these relations. Here is my attempt $i^4=1 \implies i^2i^2 = 1$and since we know that $i^2 =j^2$ so we get that $i^2i^2= 1 \implies i^2j^2 =1$. Now I left multiply by $i^{-1}$ and right multiply by $j^{-1}$ both sides of the equation to end up with $ij = i^{-1}j^{-1}$ and since I know that $i^{-1} = j^{-1}ij$ then I get $ij = j^{-1}ijj^{-1}$ and hence I get $ij = j^{-1}i$. The thing is I never find $k$. Basically my question is the following Given a group presentation ,how come can we find all the elements using the relations in a group presentation even though all the elements may not be listed in the the group presentation. You see there is no $k$ what so ever in the group presentation of $Q_8$. So how come I will be able to find it ?  So should we make life easier, and include all the elements in a group presentation. Even if we did that, there is no clue that $ij = k$ in that group presentation, One must know before hand this relation or else how can he even derive it. Well he can get $ij$ but then he may not be able to know what is $ij$ equals anyway` ` I got this from dummit book page(219) in the section A word on free groups (section 6.3) Thanks for taking the time to read my question :)",,"['abstract-algebra', 'group-theory', 'philosophy', 'group-presentation']"
