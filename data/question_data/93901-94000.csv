,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Bound on the derivatives of heat kernel.,Bound on the derivatives of heat kernel.,,"Let the heat kernel $\Phi:\Bbb R^n\times (0,\infty)$ be defined as $$ \Phi(x,y):=\frac 1{(4\pi t)^{n/2}}e^{-\frac{|x|^2}{4t}}. $$ From calculation, I have a feeling the the following should be true: $$ |\nabla^k \Phi(x,t)|\le \frac {C(n,k)}{t^{k/2}} \left( 1+\frac{|x|^2}t \right)^{k/2} \Phi(x,t). $$ At least for even  $k$ this seems to be the case. Is this estimate well-known? Is it even true? I'm trying to prove this but induction seems painful to me (or maybe I'm just bad at calculation). If it is true does anyone have a nice proof of it? A hint is also appreciated.","Let the heat kernel $\Phi:\Bbb R^n\times (0,\infty)$ be defined as $$ \Phi(x,y):=\frac 1{(4\pi t)^{n/2}}e^{-\frac{|x|^2}{4t}}. $$ From calculation, I have a feeling the the following should be true: $$ |\nabla^k \Phi(x,t)|\le \frac {C(n,k)}{t^{k/2}} \left( 1+\frac{|x|^2}t \right)^{k/2} \Phi(x,t). $$ At least for even  $k$ this seems to be the case. Is this estimate well-known? Is it even true? I'm trying to prove this but induction seems painful to me (or maybe I'm just bad at calculation). If it is true does anyone have a nice proof of it? A hint is also appreciated.",,"['real-analysis', 'complex-analysis', 'ordinary-differential-equations', 'partial-differential-equations', 'heat-equation']"
1,"Determine bijective conformal self maps of $\Bbb C \setminus \{0,1\}$",Determine bijective conformal self maps of,"\Bbb C \setminus \{0,1\}","I'm asked how to determine the bijective conformal self maps of $\Bbb C \setminus \{0,1\}$. My attempt is to use the fact that Moebius transformations are uniquely determined by where I send $3$ points (where I'm allowed to pick $\infty$) and are invertible and conformal. Hence by seeing $\{0,1\}$ to $\{0,1\}$ and $\infty$ to $\infty$ I have a family of conformal bijective self maps of $\Bbb C \setminus \{0,1\}$. How to prove that they exhaust all the possible self maps of $\Bbb C \setminus \{0,1\}$?","I'm asked how to determine the bijective conformal self maps of $\Bbb C \setminus \{0,1\}$. My attempt is to use the fact that Moebius transformations are uniquely determined by where I send $3$ points (where I'm allowed to pick $\infty$) and are invertible and conformal. Hence by seeing $\{0,1\}$ to $\{0,1\}$ and $\infty$ to $\infty$ I have a family of conformal bijective self maps of $\Bbb C \setminus \{0,1\}$. How to prove that they exhaust all the possible self maps of $\Bbb C \setminus \{0,1\}$?",,['complex-analysis']
2,definition of meromorphic function : it may have removable singularities,definition of meromorphic function : it may have removable singularities,,"I'd like to know about the definition of meromorphic function. Usually I see the definition of meromorphic function as follows: Let $D\subset\mathbb C$ be a connected open set,  a function $f$ defined on a subset $U$ of $D$ and with value in $\mathbb C$ is meromorphic on $D$ if the following conditions are satisfied: $P(f)=D\setminus U$ is a set of poles $P(f)$ is discrete in $D$ $f$ is holomorphic on $U$. However, in the book "" Complex anlysis for mathematics and engineering"" by John H. Mathews and Russel W. Howeell, $P(f)=D\setminus U$ is a set of poles and removable singularities. I think removable singularities are not real singularities, since we can extend the function to the holomorphic function. Thus, two definitions may be almost same. I'd like to know how other people think about this question. Would you give any comments about this question? Thanks in advance!","I'd like to know about the definition of meromorphic function. Usually I see the definition of meromorphic function as follows: Let $D\subset\mathbb C$ be a connected open set,  a function $f$ defined on a subset $U$ of $D$ and with value in $\mathbb C$ is meromorphic on $D$ if the following conditions are satisfied: $P(f)=D\setminus U$ is a set of poles $P(f)$ is discrete in $D$ $f$ is holomorphic on $U$. However, in the book "" Complex anlysis for mathematics and engineering"" by John H. Mathews and Russel W. Howeell, $P(f)=D\setminus U$ is a set of poles and removable singularities. I think removable singularities are not real singularities, since we can extend the function to the holomorphic function. Thus, two definitions may be almost same. I'd like to know how other people think about this question. Would you give any comments about this question? Thanks in advance!",,"['complex-analysis', 'meromorphic-functions']"
3,Calculate a double integral,Calculate a double integral,,"Why does the following identity hold? $$\int_0^{2\pi}\int_0^{2\pi}\arcsin(k\cdot \cos(\theta-\phi))e^{i(\theta-\phi)} \, d\theta \, d\phi=2\pi\int_0^{2\pi}\arcsin(k\cdot \cos x)e^{ix} \, dx$$ where $k\in[-1,1]$ is a constant. I'm trying to use substitution $x=\theta-\phi$ but it still needs some tricks. Thanks!","Why does the following identity hold? $$\int_0^{2\pi}\int_0^{2\pi}\arcsin(k\cdot \cos(\theta-\phi))e^{i(\theta-\phi)} \, d\theta \, d\phi=2\pi\int_0^{2\pi}\arcsin(k\cdot \cos x)e^{ix} \, dx$$ where $k\in[-1,1]$ is a constant. I'm trying to use substitution $x=\theta-\phi$ but it still needs some tricks. Thanks!",,"['calculus', 'complex-analysis', 'analysis']"
4,Is Apéry's constant a rational multiple of $ \pi ^ 3$?,Is Apéry's constant a rational multiple of ?, \pi ^ 3,"It is well known that the values of the Riemann zeta function for even positive numbers are of the form: $$\zeta(2k) = \rm rational * \pi ^{2k},$$ and more specifically $\zeta (2k)=(-1)^{{k+1}}{\frac  {B_{{2k}}(2\pi )^{{2k}}}{2(2k)!}}\!$ . It is not that far-fetched to consider that $$\zeta(2k + 1) = \rm rational * \pi ^{2k + 1}.$$ Specifically for Apéry's constant (which is $\zeta(3)$ ), did someone prove something like that? The proof should be something like: $\frac{\zeta(3)}{\pi^3}$ is rational / irrational / transcendental. EDIT : Even if the question is still open (which I can see it is from the comments), is there any new development on this matter lately? Just curious.","It is well known that the values of the Riemann zeta function for even positive numbers are of the form: and more specifically . It is not that far-fetched to consider that Specifically for Apéry's constant (which is ), did someone prove something like that? The proof should be something like: is rational / irrational / transcendental. EDIT : Even if the question is still open (which I can see it is from the comments), is there any new development on this matter lately? Just curious.","\zeta(2k) = \rm rational * \pi ^{2k}, \zeta (2k)=(-1)^{{k+1}}{\frac  {B_{{2k}}(2\pi )^{{2k}}}{2(2k)!}}\! \zeta(2k + 1) = \rm rational * \pi ^{2k + 1}. \zeta(3) \frac{\zeta(3)}{\pi^3}","['complex-analysis', 'number-theory', 'riemann-zeta']"
5,"How to show that $\frac{1}{2\pi} \int_{0}^{2\pi}\ln|re^{i\theta} -a|d\theta=\max(\ln r,\ln|a|)$?",How to show that ?,"\frac{1}{2\pi} \int_{0}^{2\pi}\ln|re^{i\theta} -a|d\theta=\max(\ln r,\ln|a|)","In a PDF I am reading they say: $$\frac{1}{2\pi} \int_{0}^{2\pi}\ln|re^{i\theta}-a|d\theta=\max(\ln r,\ln|a|). $$ It is certainly a simple calculation but I can't see why. Is there someone who can explain to me. Thanks.","In a PDF I am reading they say: $$\frac{1}{2\pi} \int_{0}^{2\pi}\ln|re^{i\theta}-a|d\theta=\max(\ln r,\ln|a|). $$ It is certainly a simple calculation but I can't see why. Is there someone who can explain to me. Thanks.",,['complex-analysis']
6,Operational details (Implementation) of Kneser's method of fractional iteration of function $\exp(x)$?,Operational details (Implementation) of Kneser's method of fractional iteration of function ?,\exp(x),"For a long time (a couple of years) I'm following the Q&A's about ""half-iterate of $\exp(x)$"" etc. where there exists a $\mathbb C \to \mathbb C$ due to Schröder's method, but also a $\mathbb R \to \mathbb R$ for fractional heights $h$ due to Hellmuth Kneser. I would like to understand the latter method of Kneser; after reading of several papers (including the original one of Kneser) I still have no real clue how this is done.(See some explanations for instance Tetration-forum thread 1 thread 2 ) One menetekel for me is the so-called ""Riemann-mapping"" for which I find on many places proofs (that it exists) but no idea how to practically implement this for such a case like iteration of the $\exp()$-function (for instance citizendium , and the linked article). Could someone step in and explain that Kneser method in detail? (Note that there seem to be an asymptotic approximation of the Kneser's results using square-roots of the Carleman-matrix for the $\exp()$ )","For a long time (a couple of years) I'm following the Q&A's about ""half-iterate of $\exp(x)$"" etc. where there exists a $\mathbb C \to \mathbb C$ due to Schröder's method, but also a $\mathbb R \to \mathbb R$ for fractional heights $h$ due to Hellmuth Kneser. I would like to understand the latter method of Kneser; after reading of several papers (including the original one of Kneser) I still have no real clue how this is done.(See some explanations for instance Tetration-forum thread 1 thread 2 ) One menetekel for me is the so-called ""Riemann-mapping"" for which I find on many places proofs (that it exists) but no idea how to practically implement this for such a case like iteration of the $\exp()$-function (for instance citizendium , and the linked article). Could someone step in and explain that Kneser method in detail? (Note that there seem to be an asymptotic approximation of the Kneser's results using square-roots of the Carleman-matrix for the $\exp()$ )",,"['complex-analysis', 'riemann-surfaces', 'function-and-relation-composition', 'tetration']"
7,Find the zeros of $h(z)=z^6-5z^4+3z^2-1$ within the unit disc - Verification,Find the zeros of  within the unit disc - Verification,h(z)=z^6-5z^4+3z^2-1,"Let $h(z)=z^6-5z^4+3z^2-1$. Using Rouche's theorem, with $f(z)=-5z^4$ and $g(z)=z^6+3z^2-1$. On the unit disc $\lvert f(z) \rvert =5 > \lvert 1+3-1 \rvert=\lvert g(z)\rvert $ And the number of zeros is 4 for $f(z)$ in the unit disc, so it is also five for $h(z)=f(z)+g(z)$. Is this correct? Thanks. Found an old answer of mine, I chose $g(z)=z^6-1$ and $f(z)=-5z^4+3z^2$, and got the answer $4$ roots again.","Let $h(z)=z^6-5z^4+3z^2-1$. Using Rouche's theorem, with $f(z)=-5z^4$ and $g(z)=z^6+3z^2-1$. On the unit disc $\lvert f(z) \rvert =5 > \lvert 1+3-1 \rvert=\lvert g(z)\rvert $ And the number of zeros is 4 for $f(z)$ in the unit disc, so it is also five for $h(z)=f(z)+g(z)$. Is this correct? Thanks. Found an old answer of mine, I chose $g(z)=z^6-1$ and $f(z)=-5z^4+3z^2$, and got the answer $4$ roots again.",,"['complex-analysis', 'proof-verification']"
8,Holomorphic functions and real functions: continuity of partial derivatives,Holomorphic functions and real functions: continuity of partial derivatives,,"Given $f: A \subset \mathbb{C} \rightarrow \mathbb{C}$ a holomorphic function, I can represent the function as $f=u+iv, \  u,v:A \rightarrow \mathbb{R}$ and so $f$ can be seen as a function from $A' \subset \mathbb{R}^2$ to $\mathbb{R}^2$ under the identification of $\mathbb{C} \ni z=x+iy$ with $(x,y) \in \mathbb{R}^2$ and of $f$ with $F=(u,v)$. Now, the problem arise (for me) in two different direction, the first: A theorem in [Markushevich] [""Theory of functions of a complex variable""] 1 says that if we look at $f$ as $F$ (notation above) then $f$ is holomorphic if and only if $F$ is real differentiable and solve Cauchy-Riemann conditions. Now, this gives us a good method to say when $f$ is holomorphic (at least when we can manage somehow the differentiability of $F$), but (and so the book continues) there is a nice sufficent condition on $F$ which is the continuity of partial derivatives of $u(x,y)$ and $v(x,y)$ (plus C-R equations) to imply holomorphicity of $f$. And that's ok, but this is only a sufficent condition. Wikipedia's page on holomorphic functions seems to do confusion: it says (in ""Properties"" ) If one identifies $\mathbb{C}$ with $\mathbb{R}^2$, then the holomorphic functions coincide with those functions of two real variables with continuous first derivatives which solve the Cauchy–Riemann equations, a set of two partial differential equations. Is it me, or this is wrong? Second question: how the fact that $f$ is holomorphic, and so analytical, relates with $u(x,y)$ and $v(x,y)$? The problem, to me, arises when I try to show that a holomorphic function $f=u+iv$ solve the equation $\frac{\partial^2u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = 0$. i) How can I say that the second (partial) derivatives of $u$ exists? ii) What about the mixed (partial) derivatives of $u$ which are supposed to cancel? How the symmetry requirements on $u$ are satisfied? In summary: which are some good characterisations of holomorphicity in terms of $u,v$? Thank you in advance","Given $f: A \subset \mathbb{C} \rightarrow \mathbb{C}$ a holomorphic function, I can represent the function as $f=u+iv, \  u,v:A \rightarrow \mathbb{R}$ and so $f$ can be seen as a function from $A' \subset \mathbb{R}^2$ to $\mathbb{R}^2$ under the identification of $\mathbb{C} \ni z=x+iy$ with $(x,y) \in \mathbb{R}^2$ and of $f$ with $F=(u,v)$. Now, the problem arise (for me) in two different direction, the first: A theorem in [Markushevich] [""Theory of functions of a complex variable""] 1 says that if we look at $f$ as $F$ (notation above) then $f$ is holomorphic if and only if $F$ is real differentiable and solve Cauchy-Riemann conditions. Now, this gives us a good method to say when $f$ is holomorphic (at least when we can manage somehow the differentiability of $F$), but (and so the book continues) there is a nice sufficent condition on $F$ which is the continuity of partial derivatives of $u(x,y)$ and $v(x,y)$ (plus C-R equations) to imply holomorphicity of $f$. And that's ok, but this is only a sufficent condition. Wikipedia's page on holomorphic functions seems to do confusion: it says (in ""Properties"" ) If one identifies $\mathbb{C}$ with $\mathbb{R}^2$, then the holomorphic functions coincide with those functions of two real variables with continuous first derivatives which solve the Cauchy–Riemann equations, a set of two partial differential equations. Is it me, or this is wrong? Second question: how the fact that $f$ is holomorphic, and so analytical, relates with $u(x,y)$ and $v(x,y)$? The problem, to me, arises when I try to show that a holomorphic function $f=u+iv$ solve the equation $\frac{\partial^2u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = 0$. i) How can I say that the second (partial) derivatives of $u$ exists? ii) What about the mixed (partial) derivatives of $u$ which are supposed to cancel? How the symmetry requirements on $u$ are satisfied? In summary: which are some good characterisations of holomorphicity in terms of $u,v$? Thank you in advance",,"['calculus', 'complex-analysis', 'holomorphic-functions']"
9,Exponential decay of Fourier coefficients correspond to analytic functions,Exponential decay of Fourier coefficients correspond to analytic functions,,"I am looking for a proof of the Payley-Wiener theorem saying that an analytic function on $\mathbb{T}$ (the torus) has exponentially decaying Fourier coefficients. I also found a proof of this fact in this book , but I do not get what they are doing there, i.e. how they apply Cauchy's formula. If somebody could elaborate or prove this from scratch, I would be very grateful.","I am looking for a proof of the Payley-Wiener theorem saying that an analytic function on (the torus) has exponentially decaying Fourier coefficients. I also found a proof of this fact in this book , but I do not get what they are doing there, i.e. how they apply Cauchy's formula. If somebody could elaborate or prove this from scratch, I would be very grateful.",\mathbb{T},"['complex-analysis', 'analysis', 'fourier-analysis', 'fourier-series']"
10,Is a function that maps circles to circles necessarily a Möbius transformation?,Is a function that maps circles to circles necessarily a Möbius transformation?,,"I'm introducing myself to Complex analysis and Möbius transformations and I read that Möbius transformations map circles and lines to circles and lines. Are there any other functions that are not Möbius transformations but they can map circles to circles? If I know that $f(z)$ maps a circle to another circle, can I assume that $f(z)$ is a Möbius transformation?","I'm introducing myself to Complex analysis and Möbius transformations and I read that Möbius transformations map circles and lines to circles and lines. Are there any other functions that are not Möbius transformations but they can map circles to circles? If I know that $f(z)$ maps a circle to another circle, can I assume that $f(z)$ is a Möbius transformation?",,"['complex-analysis', 'circles', 'mobius-transformation']"
11,Equation of a Riemann surface?,Equation of a Riemann surface?,,"Intuitively in complex analysis I know what a Riemann surface is. It is a surface such that at every point on it the value of a function $f(z)$ is single-valued. However, how would I go about finding the equation for such a surface, i.e. if I was to plot one what one I plot?","Intuitively in complex analysis I know what a Riemann surface is. It is a surface such that at every point on it the value of a function $f(z)$ is single-valued. However, how would I go about finding the equation for such a surface, i.e. if I was to plot one what one I plot?",,"['complex-analysis', 'riemann-surfaces']"
12,"Reference request for ""Elementary"" Proofs of Picard's Great Theorem","Reference request for ""Elementary"" Proofs of Picard's Great Theorem",,"This is Picard's Great Theorem; $\textbf{Great Picard Theorem.}$ Suppose an analytic function $f$ has an essential singularity at $z=a$. Then in each neighbourhood of $a$, $f$ assumes each complex number with one possible exception, an infinite number of times. I was wondering if there are any essentially elementary proofs of Picard's Great Theorem that could be taught to a student not well versed in complex analysis. Or a relatively short proof that could be taught to a student who has taken at least one semester of complex analysis. Also how many different proofs of this theorem are there? The proof I have seen, using normal families and Montel's Theorem, is the one in John B Conway's Functions of One Complex Variable. The proof is in Chapter 12 Section 4 and uses quite a number of results that aren't immediately apparent and many of the intermediary results are quite long. If anyone could point me to a book that provides the kind of proof I'm looking for, or explain that such a proof does not exist, I would appreciate it.","This is Picard's Great Theorem; $\textbf{Great Picard Theorem.}$ Suppose an analytic function $f$ has an essential singularity at $z=a$. Then in each neighbourhood of $a$, $f$ assumes each complex number with one possible exception, an infinite number of times. I was wondering if there are any essentially elementary proofs of Picard's Great Theorem that could be taught to a student not well versed in complex analysis. Or a relatively short proof that could be taught to a student who has taken at least one semester of complex analysis. Also how many different proofs of this theorem are there? The proof I have seen, using normal families and Montel's Theorem, is the one in John B Conway's Functions of One Complex Variable. The proof is in Chapter 12 Section 4 and uses quite a number of results that aren't immediately apparent and many of the intermediary results are quite long. If anyone could point me to a book that provides the kind of proof I'm looking for, or explain that such a proof does not exist, I would appreciate it.",,"['complex-analysis', 'reference-request', 'alternative-proof']"
13,"If there is a branch of $\sqrt{z}$ on an open set $U$ with $0 \notin U,$ then there is also a branch of $arg$ $z.$",If there is a branch of  on an open set  with  then there is also a branch of,"\sqrt{z} U 0 \notin U, arg z.","Show that if there is a branch of $\sqrt{z}$ on an open set $U$ with $0 \notin U,$ then there is also a branch of $arg$ $z.$ I am unable to proceed any further in this and any help in this regard would be greatly appreciated.","Show that if there is a branch of $\sqrt{z}$ on an open set $U$ with $0 \notin U,$ then there is also a branch of $arg$ $z.$ I am unable to proceed any further in this and any help in this regard would be greatly appreciated.",,['complex-analysis']
14,Is $\sin^2(z) + \cos^2(z)=1$ still true for $z \in \Bbb{C}$?,Is  still true for ?,\sin^2(z) + \cos^2(z)=1 z \in \Bbb{C},"Is $$\sin^2(z) + \cos^2(z)=1$$ still true for all $z \in \Bbb{C}$? I've tried rewriting it using complex definitions of $\sin$ and $\cos$, and I don't see why it wouldn't, but the text I'm reading asks this question as if it shouldn't hold?","Is $$\sin^2(z) + \cos^2(z)=1$$ still true for all $z \in \Bbb{C}$? I've tried rewriting it using complex definitions of $\sin$ and $\cos$, and I don't see why it wouldn't, but the text I'm reading asks this question as if it shouldn't hold?",,"['complex-analysis', 'trigonometry']"
15,Calculate $\sum_{n=0}^\infty$ $(n+1)(n+2)(\frac{i}{2})^{n-1}$,Calculate,\sum_{n=0}^\infty (n+1)(n+2)(\frac{i}{2})^{n-1},"I want to calculate $\sum_{n=0}^\infty$ $(n+1)(n+2)(\frac{i}{2})^{n-1}$. I tried to separate it into a sum of real numbers ($n=0,2,4,\dots$) and complex numbers that are not real numbers ($n=1,3,5,\dots$) but it didn't work. So I did it another way, using Cauchy's integral theorem: Let $f(z)=(\frac{z}{2})^{n+2}$. Then $4f''(i)$= $(n+1)(n+2)(\frac{i}{2})^{n-1}$, which is a term of the sum I started with. I don't know how to proceed from here. What can I do? How do I solve this?","I want to calculate $\sum_{n=0}^\infty$ $(n+1)(n+2)(\frac{i}{2})^{n-1}$. I tried to separate it into a sum of real numbers ($n=0,2,4,\dots$) and complex numbers that are not real numbers ($n=1,3,5,\dots$) but it didn't work. So I did it another way, using Cauchy's integral theorem: Let $f(z)=(\frac{z}{2})^{n+2}$. Then $4f''(i)$= $(n+1)(n+2)(\frac{i}{2})^{n-1}$, which is a term of the sum I started with. I don't know how to proceed from here. What can I do? How do I solve this?",,['complex-analysis']
16,Advanced complex function theory book recommendation,Advanced complex function theory book recommendation,,"I would like to have some recommendations in order to self study the above topic. I have already studied some complex function theory, covering some of the more 'classical' theorems (the Bloch-Landau theorem, the Little & Big Picard theorems, Riemann mapping theorem) and some introductry to analytic continuation ideas. I would like to further study this, and more specifically: Gamma&Zetta functions, elliptic functions, harmonic functions, and further study of holomorphic and meromorphic functions. Also, What books out there have a proof of Zalcman's lemma?","I would like to have some recommendations in order to self study the above topic. I have already studied some complex function theory, covering some of the more 'classical' theorems (the Bloch-Landau theorem, the Little & Big Picard theorems, Riemann mapping theorem) and some introductry to analytic continuation ideas. I would like to further study this, and more specifically: Gamma&Zetta functions, elliptic functions, harmonic functions, and further study of holomorphic and meromorphic functions. Also, What books out there have a proof of Zalcman's lemma?",,"['complex-analysis', 'reference-request', 'self-learning', 'book-recommendation']"
17,Evaluate the integral $\int_0^{\frac{\pi}{2}} \frac{1}{a + \sin^2 \theta}$ using the residue theorem,Evaluate the integral  using the residue theorem,\int_0^{\frac{\pi}{2}} \frac{1}{a + \sin^2 \theta},Can someone show me how to compute this integral using the residue theorem: $$\int_0^{\frac{\pi}{2}} \frac{1}{a + \sin^2 \theta}d\theta$$,Can someone show me how to compute this integral using the residue theorem: $$\int_0^{\frac{\pi}{2}} \frac{1}{a + \sin^2 \theta}d\theta$$,,"['complex-analysis', 'analysis']"
18,What are irreducibles in the ring $R$ of entire functions?,What are irreducibles in the ring  of entire functions?,R,"Here's how far I have gone: I first find the units in $R$. Let $f$ $ \in $ $R$ be a unit. Then $\exists$ $g$ $\in$ $R$ such that $fg=1$, i.e $f(z)g(z)=1$ $\forall$ $z$ $\in$ $\Bbb C$. Then, $f(z)$ $=$ $\frac 1{g(z)}$ $\forall$ $z \in \Bbb C$. Hence $f(z),g(z) \neq 0$ $\forall$  $z \in \Bbb C$. Now to find the irreducibles, let $f \in R$ be an irreducible. Hence whenever  $f(z)=g(z)h(z)$ for $g,h \in R$, then $g$ or $h$ is a unit. Let $h$ be the unit and $\alpha$ be a zero of $f$. Then $f(\alpha)=g(\alpha)h(\alpha)=0$ $\Rightarrow$ $g(\alpha)=0$. Hence $z-\alpha$ is a factor of $g$. So $g(z)=(z-\alpha)^ng_1(z)$ for some $n \in \Bbb N$, where $g_1$ is unit. Since $f$ is irreducible, hence $n=1$. I'm stuck here. What can be my next step?","Here's how far I have gone: I first find the units in $R$. Let $f$ $ \in $ $R$ be a unit. Then $\exists$ $g$ $\in$ $R$ such that $fg=1$, i.e $f(z)g(z)=1$ $\forall$ $z$ $\in$ $\Bbb C$. Then, $f(z)$ $=$ $\frac 1{g(z)}$ $\forall$ $z \in \Bbb C$. Hence $f(z),g(z) \neq 0$ $\forall$  $z \in \Bbb C$. Now to find the irreducibles, let $f \in R$ be an irreducible. Hence whenever  $f(z)=g(z)h(z)$ for $g,h \in R$, then $g$ or $h$ is a unit. Let $h$ be the unit and $\alpha$ be a zero of $f$. Then $f(\alpha)=g(\alpha)h(\alpha)=0$ $\Rightarrow$ $g(\alpha)=0$. Hence $z-\alpha$ is a factor of $g$. So $g(z)=(z-\alpha)^ng_1(z)$ for some $n \in \Bbb N$, where $g_1$ is unit. Since $f$ is irreducible, hence $n=1$. I'm stuck here. What can be my next step?",,"['complex-analysis', 'ring-theory']"
19,$f$ has a zero of order $m\iff \frac{1}{f}$ has a pole of order m,has a zero of order  has a pole of order m,f m\iff \frac{1}{f},"Question Let $f$ be holomorphic in a domain $D\subset \Bbb{C}$. Then $f$ has a zero of order $m$ in $z_0\in D \iff \frac{1}{f}\in H({D \setminus f^{-1}(0)}) \text{ has a pole of order $m$ in } z_0$. My attempt: I have proved the ""$\implies$"" direction. For the other implication, we suppose that $$\min\left\{v\in \Bbb{N} : \frac{(z-z_0)^v}{f}\text{ is bounded near }z_0\right\}=m$$ We need to find a $g\in H(D)$ with $g(z_0)\neq 0$ such that $f = (z-z_0)^m g$. I haven't been able to do this. Please tell me what I could do.","Question Let $f$ be holomorphic in a domain $D\subset \Bbb{C}$. Then $f$ has a zero of order $m$ in $z_0\in D \iff \frac{1}{f}\in H({D \setminus f^{-1}(0)}) \text{ has a pole of order $m$ in } z_0$. My attempt: I have proved the ""$\implies$"" direction. For the other implication, we suppose that $$\min\left\{v\in \Bbb{N} : \frac{(z-z_0)^v}{f}\text{ is bounded near }z_0\right\}=m$$ We need to find a $g\in H(D)$ with $g(z_0)\neq 0$ such that $f = (z-z_0)^m g$. I haven't been able to do this. Please tell me what I could do.",,['complex-analysis']
20,Prove that the range of the entire function $z^2+\cos(z)$ is all of $\mathbb{C}$.,Prove that the range of the entire function  is all of .,z^2+\cos(z) \mathbb{C},"Prove that the range of the entire function $z^2+\cos(z)$ is all of $\mathbb{C}$. I'm aware this question has been asked already, but the explanations were a little shakey and referenced a google sample preview of a text of whose terminology I wasn't very familiar with, so I would like some more input if possible. Here's my attempt: Let $f(z)=z^2+\cos(z)$. Through the power series of the cosine function $$ f(z)=z^2+1-\frac{z^2}{2!}+\frac{z^4}{4!}-\cdots=1+\frac{z^2}{2!}+\frac{z^4}{4!}-\cdots, $$ so $$ g(z):=\frac{f(z)-1}{z} $$ has a removable singularity at $z=0$ and is effectively an entire odd function. Picard's little theorem asserts that the range of $g$ is all of $\mathbb{C} $: if there exists some $z_0$ such that $g(z)\neq z_0$ for all $z\in\mathbb{C}$, then $-z_0$ is also missed by oddness of $g$, which is a contradiction (since $g(0)=0$ we rule the possibility that $z_0=0$). (I'm not sure about the following step) It follows that $zg(z)$ and so $zg(z)+1=f(z)$ is surjective. Is this method valid? Would I need further justification to show that $z\mapsto z$ and $z\mapsto g(z)$ surjective imply its product -- $z\mapsto zg(z)$ -- is also surjective (if this is even true). Any input is greatly appreciated. Edit: After thinking about this for a moment longer, I realize this logic would also show that the range of any entire even function is all of $\mathbb{C}$, which seems like quite a strong conclusion. This makes feel like there are holes in my logic.","Prove that the range of the entire function $z^2+\cos(z)$ is all of $\mathbb{C}$. I'm aware this question has been asked already, but the explanations were a little shakey and referenced a google sample preview of a text of whose terminology I wasn't very familiar with, so I would like some more input if possible. Here's my attempt: Let $f(z)=z^2+\cos(z)$. Through the power series of the cosine function $$ f(z)=z^2+1-\frac{z^2}{2!}+\frac{z^4}{4!}-\cdots=1+\frac{z^2}{2!}+\frac{z^4}{4!}-\cdots, $$ so $$ g(z):=\frac{f(z)-1}{z} $$ has a removable singularity at $z=0$ and is effectively an entire odd function. Picard's little theorem asserts that the range of $g$ is all of $\mathbb{C} $: if there exists some $z_0$ such that $g(z)\neq z_0$ for all $z\in\mathbb{C}$, then $-z_0$ is also missed by oddness of $g$, which is a contradiction (since $g(0)=0$ we rule the possibility that $z_0=0$). (I'm not sure about the following step) It follows that $zg(z)$ and so $zg(z)+1=f(z)$ is surjective. Is this method valid? Would I need further justification to show that $z\mapsto z$ and $z\mapsto g(z)$ surjective imply its product -- $z\mapsto zg(z)$ -- is also surjective (if this is even true). Any input is greatly appreciated. Edit: After thinking about this for a moment longer, I realize this logic would also show that the range of any entire even function is all of $\mathbb{C}$, which seems like quite a strong conclusion. This makes feel like there are holes in my logic.",,['complex-analysis']
21,Show $f(z)$ can be analytically continued and $F(z+4)=F(z)$ for resulting entire function,Show  can be analytically continued and  for resulting entire function,f(z) F(z+4)=F(z),"I'm working on some past qualifying exam problems in complex analysis and I'm quite stuck on this one: Let $f(z)$ be analytic in $\{z\in\mathbb{C}\,:\,|\text{Re }z|<1\}$ and continuous on the closure of that domain. Suppose that $f(z)$ is real on the lines $\text{Re }z=\pm 1$. Prove that then $f(z)$ can be analytically continued to the whole plane and that the resulting entire function satisfies $F(z+4)=F(z)$ for all $z\in\mathbb{C}$. Here are my thoughts: the problem is clearly (I think) calling for the Schwarz Reflection Principle but I don't quite see how the $F(z+4)=F(z)$ comes out. I assume it will have to do since it can be infinitely reflected left and right throughout the plane, With my understanding of the Schwarz reflection principle, I believe $f$ would extend to $\{z\in\mathbb{C}\,:\,-1<\text{Re }z<3\}$ with $\overline{F(\overline{1-z}+1)}=F(z)$ (since $z\mapsto \overline{1-z}+1$ is the reflection about the line $\text{Re }z=1$ and $z\mapsto\overline{z}$ is the usual reflection about the real axis) TL;DR I understand how it can be analytically continued to an entire function, just not that the resulting entire function satisfies $F(z+4)=F(z)$. Any help is greatly appreciated. Thanks in advance.","I'm working on some past qualifying exam problems in complex analysis and I'm quite stuck on this one: Let $f(z)$ be analytic in $\{z\in\mathbb{C}\,:\,|\text{Re }z|<1\}$ and continuous on the closure of that domain. Suppose that $f(z)$ is real on the lines $\text{Re }z=\pm 1$. Prove that then $f(z)$ can be analytically continued to the whole plane and that the resulting entire function satisfies $F(z+4)=F(z)$ for all $z\in\mathbb{C}$. Here are my thoughts: the problem is clearly (I think) calling for the Schwarz Reflection Principle but I don't quite see how the $F(z+4)=F(z)$ comes out. I assume it will have to do since it can be infinitely reflected left and right throughout the plane, With my understanding of the Schwarz reflection principle, I believe $f$ would extend to $\{z\in\mathbb{C}\,:\,-1<\text{Re }z<3\}$ with $\overline{F(\overline{1-z}+1)}=F(z)$ (since $z\mapsto \overline{1-z}+1$ is the reflection about the line $\text{Re }z=1$ and $z\mapsto\overline{z}$ is the usual reflection about the real axis) TL;DR I understand how it can be analytically continued to an entire function, just not that the resulting entire function satisfies $F(z+4)=F(z)$. Any help is greatly appreciated. Thanks in advance.",,['complex-analysis']
22,"Proof of Cauchy-Schwarz inequality from Terry Tao's notes, meaning of ""cancelling the phase""","Proof of Cauchy-Schwarz inequality from Terry Tao's notes, meaning of ""cancelling the phase""",,"I was reading Tao's proof of the Cauchy-Schwarz inequality by exploiting certain inherent symmetries and making some transformations. He says that first we use the fact that the norm is positive, i.e. $$\|u-v\|^2>0$$ to conclude that $\operatorname{Re} (\langle u,v\rangle) \leq \frac{1}{2}\|u\|^2+\frac{1}{2}\|v\|^2$,  and then he claims that we make a transformation $$v \mapsto ve^{\iota \theta}$$ and the RHS is clearly preserved under the transformation whereas the LHS changes. Now he says that we choose a $\theta$ to make the LHS as high as possible such that it cancels the phase of $\langle u,v\rangle$. The rest of the proof is clear. But I don't get what he means by cancelling the phase. I mean the transformation is such that $\operatorname{Re} (\langle u,v\rangle)e^{\iota \theta} \mapsto |\langle u,v\rangle|$ for the theta which cancels the phase and for this particular theta we are kind of recovering the imaginary part of the complex scalar and then take its length. But how does it work? I don't understand it.","I was reading Tao's proof of the Cauchy-Schwarz inequality by exploiting certain inherent symmetries and making some transformations. He says that first we use the fact that the norm is positive, i.e. $$\|u-v\|^2>0$$ to conclude that $\operatorname{Re} (\langle u,v\rangle) \leq \frac{1}{2}\|u\|^2+\frac{1}{2}\|v\|^2$,  and then he claims that we make a transformation $$v \mapsto ve^{\iota \theta}$$ and the RHS is clearly preserved under the transformation whereas the LHS changes. Now he says that we choose a $\theta$ to make the LHS as high as possible such that it cancels the phase of $\langle u,v\rangle$. The rest of the proof is clear. But I don't get what he means by cancelling the phase. I mean the transformation is such that $\operatorname{Re} (\langle u,v\rangle)e^{\iota \theta} \mapsto |\langle u,v\rangle|$ for the theta which cancels the phase and for this particular theta we are kind of recovering the imaginary part of the complex scalar and then take its length. But how does it work? I don't understand it.",,"['real-analysis', 'complex-analysis', 'inequality']"
23,Prove that $\{n^2f\left(\frac{1}{n}\right)\}$ is bounded.,Prove that  is bounded.,\{n^2f\left(\frac{1}{n}\right)\},"Let , $f$ be entire function such that $|f\left(\frac{1}{n}\right)|\le \frac{1}{n^{3/2}}$  for all $n\in \mathbb N$. Then prove that $\{n^2f\left(\frac{1}{n}\right)\}$ is bounded. From the relation we find that $f(0)=0$. As $f$ is entire so using Taylor's theorem about $z=0$ we get , $$f(z)=\sum_{n=1}^{\infty}a_nz^n.$$ Then from the expression of $n^2f(1/n)$ I could not say that $n^2f(1/n)$ is bounded. How I solve the problem from this or any other way ? Can anyone give any hints ??","Let , $f$ be entire function such that $|f\left(\frac{1}{n}\right)|\le \frac{1}{n^{3/2}}$  for all $n\in \mathbb N$. Then prove that $\{n^2f\left(\frac{1}{n}\right)\}$ is bounded. From the relation we find that $f(0)=0$. As $f$ is entire so using Taylor's theorem about $z=0$ we get , $$f(z)=\sum_{n=1}^{\infty}a_nz^n.$$ Then from the expression of $n^2f(1/n)$ I could not say that $n^2f(1/n)$ is bounded. How I solve the problem from this or any other way ? Can anyone give any hints ??",,"['complex-analysis', 'complex-numbers']"
24,Is there a geometric insight from this exercise?,Is there a geometric insight from this exercise?,,"I am solving some exercises in a book I'm reading and so far all the exercises contained some insight. But then I got to the following exercise: Let $z,a\in \mathbb C$. Show that $$ (1-|z|^2)(1-|a|^2) =|1-z\overline{a}|^2 - |z-a|^2$$ Then deduce from this that if $|a|<1$ then $$ |z|<1 \iff \left| {z-a \over \overline{a}z -1} \right|<1$$ and $$ |z|=1 \iff \left| {z-a \over \overline{a}z -1} \right|=1$$ What is the insight to be had from this exercise? All the other exercises were insightful but this one here seems to be just computational. Note that this is part b) of the exercise. Part a) was: Let $\mathbb H := \{z \in \mathbb C \mid \operatorname{Im}{z}>0 \}$. Show that $z \in \mathbb H$ if and only if $-{1\over z}\in \mathbb H$. I solved part a) and I feel that it should be somehow related to part b) but I don't know how.","I am solving some exercises in a book I'm reading and so far all the exercises contained some insight. But then I got to the following exercise: Let $z,a\in \mathbb C$. Show that $$ (1-|z|^2)(1-|a|^2) =|1-z\overline{a}|^2 - |z-a|^2$$ Then deduce from this that if $|a|<1$ then $$ |z|<1 \iff \left| {z-a \over \overline{a}z -1} \right|<1$$ and $$ |z|=1 \iff \left| {z-a \over \overline{a}z -1} \right|=1$$ What is the insight to be had from this exercise? All the other exercises were insightful but this one here seems to be just computational. Note that this is part b) of the exercise. Part a) was: Let $\mathbb H := \{z \in \mathbb C \mid \operatorname{Im}{z}>0 \}$. Show that $z \in \mathbb H$ if and only if $-{1\over z}\in \mathbb H$. I solved part a) and I feel that it should be somehow related to part b) but I don't know how.",,['complex-analysis']
25,Injective holomorphic function is conformal (i.e. nonzero derivative),Injective holomorphic function is conformal (i.e. nonzero derivative),,"STATEMENT: If $f:U\rightarrow V$ , where $U,V$ are open subsets of $\mathbb{C}$ , is holomorphic and injective, then $f'(z)\neq 0$ for all $z\in U$ . Proof: We argue by contradiction, and suppose that $f'(z_0)=0$ for some $z_0\in U$ . Then $$f(z)-f(z_0)=a(z-z_0)^k+G(z)\;\;\;\;\;\;\;\;\text{for all $z$ near $z_0$}$$ with $a\neq 0, k\geq 2$ and $G$ vanishing to order $k+1$ at $z_0$ . For sufficiently small $w$ we write $$f(z)-f(z_0)-w=G(z)+F(z)\;\;\;\;\;\;\;\;\text{where $F(z)=a(z-z_0)^k-w$}$$ Since $|G(z)|<|F(z)|$ on a small circle centered at $z_0$ , and $F$ has at least two zeros inside that circle, Rouches theorem implies that $f(z)-f(z_0)-w$ has at least two zeros there. Since $f'(z)\neq 0$ for all $z\neq z_0$ but sufficiently close to $z_0$ it follows that the roots of $f(z)-f(z_0)-w$ are distinct, hence $f$ is not injective, a contradiction. QUESTION: This passage is from Stein's Complex Analysis. My question is how does he conclude that the roots of $f(z)-f(z_0)-w$ are distinct by noting $f(z)\neq 0$ if $z\neq z_0$ .","STATEMENT: If , where are open subsets of , is holomorphic and injective, then for all . Proof: We argue by contradiction, and suppose that for some . Then with and vanishing to order at . For sufficiently small we write Since on a small circle centered at , and has at least two zeros inside that circle, Rouches theorem implies that has at least two zeros there. Since for all but sufficiently close to it follows that the roots of are distinct, hence is not injective, a contradiction. QUESTION: This passage is from Stein's Complex Analysis. My question is how does he conclude that the roots of are distinct by noting if .","f:U\rightarrow V U,V \mathbb{C} f'(z)\neq 0 z\in U f'(z_0)=0 z_0\in U f(z)-f(z_0)=a(z-z_0)^k+G(z)\;\;\;\;\;\;\;\;\text{for all z near z_0} a\neq 0, k\geq 2 G k+1 z_0 w f(z)-f(z_0)-w=G(z)+F(z)\;\;\;\;\;\;\;\;\text{where F(z)=a(z-z_0)^k-w} |G(z)|<|F(z)| z_0 F f(z)-f(z_0)-w f'(z)\neq 0 z\neq z_0 z_0 f(z)-f(z_0)-w f f(z)-f(z_0)-w f(z)\neq 0 z\neq z_0",['complex-analysis']
26,Determining the Number of Zeros of a (Holomorphic) Polynomial $f:\mathbb{C}\to\mathbb{C} $ in each Quadrant.,Determining the Number of Zeros of a (Holomorphic) Polynomial  in each Quadrant.,f:\mathbb{C}\to\mathbb{C} ,"Suppose $f(z)=z^4+2z^3+3z^2-z+2$. I would like to be able to determine the number of zeros (without using a CAS) $f$ has in each quadrant. I recently learned about the Argument Principle and Rouche's Theorem. I can use Rouche's Theorem to estimate the number of zeros of $f$ on a given disc restricted to one of the quadrants, but how do I find which disc to use? The other idea I have in mind is to create arbitrary discs in the plane and to apply the argument principle to see how many zeros $f$ has in each disc, but this doesn't seem like an efficient way to go for the same reason as why I wouldn't use Rouche's Theorem. Is there an efficient way to determine how many zeros are in each quadrant? I am looking for a technique general enough to be applied to any polynomial.","Suppose $f(z)=z^4+2z^3+3z^2-z+2$. I would like to be able to determine the number of zeros (without using a CAS) $f$ has in each quadrant. I recently learned about the Argument Principle and Rouche's Theorem. I can use Rouche's Theorem to estimate the number of zeros of $f$ on a given disc restricted to one of the quadrants, but how do I find which disc to use? The other idea I have in mind is to create arbitrary discs in the plane and to apply the argument principle to see how many zeros $f$ has in each disc, but this doesn't seem like an efficient way to go for the same reason as why I wouldn't use Rouche's Theorem. Is there an efficient way to determine how many zeros are in each quadrant? I am looking for a technique general enough to be applied to any polynomial.",,"['complex-analysis', 'polynomials']"
27,Computing Fourier Transform of $\frac{1}{t^2+a^2}$,Computing Fourier Transform of,\frac{1}{t^2+a^2},"I know this should be relatively simple, but I'm not getting the complete answer correct when I check with Wolframalpha. Here is my attempt. Going straight from the definition, with $x,t,a \in \mathbb{R}$ $$\begin{align*} \mathcal{F}\left[\frac{1}{t^2+a^2}\right](x)&=\int_{-\infty}^{\infty}\frac{e^{-itx}}{t^2+a^2}dt\\ &=\int_{-\infty}^{\infty}\frac{e^{-itx}}{(t-ia)(t+ia)}dt \end{align*}$$ Now this is relatively easy with the Residue Theorem (or so I suppose - I think I might miss a step here). Taking the countour $\gamma_R$ to be the half-circle that lies in the upper-half of the complex plane and whose radius is $R$, we can show that the residue of the integrand at the pole at $ia$ (as you can clearly see above, $e^{-itx}$ is entire) multiplied by $2\pi i$ will give us the value of the improper integral above. I have shown my calculations below. It seems that I am missing an absolute value sign in my answer, but I can't see where it comes into play, even when $x<0$. Could you point out my mistake(s)? Calculations Replace all the $t$'s with $z$'s in the integral above. $$\int_{-\infty}^{\infty}\frac{e^{-izx}}{(z-ia)(z+ia)}dz$$ Now we are in the complex domain, and this integral represents integrating the integrand over the real line, going from $-\infty$ to $\infty$. So we consider the semicircle contour $\gamma_R$. If $R \rightarrow \infty$, integrating the part of the contour on the real line will give us our original integral. With that said, we apply the residue theorem. We know that integrating over the entire semicircle can be simplified by the residue theorem, and the only residue that we need to calculate is that at the pole $ia$ (which is inside the contour). $$2 \pi i \textrm{Res} (f; ia) = \left. \frac{e^{-itx}}{t+ia}\right|_{t=ia} = \frac{\pi}{a}e^ax$$ But what I just got only applies to the entire contour $\gamma_R$, not the horizontal line in specific. I now show that it actually does apply to the horizontal line in specific (the real line), as the top part of this semicircle goes to $0$ as $R \rightarrow \infty$. $$ \left| \int_{\textrm{top half}} \frac{e^{-izx}}{z^2+a^2}dz \right| \leq \pi R \left|\frac{1}{a^2-R^2}\right|, \, \rightarrow 0 \,\, \textrm{ as } R \rightarrow \infty $$ So the top-half doesn't matter when $R$ is sufficiently big. This finally leaves us with $$\mathcal{F}\left[\frac{1}{t^2+a^2}\right](x)=\frac{\pi}{a}e^{ax}$$","I know this should be relatively simple, but I'm not getting the complete answer correct when I check with Wolframalpha. Here is my attempt. Going straight from the definition, with $x,t,a \in \mathbb{R}$ $$\begin{align*} \mathcal{F}\left[\frac{1}{t^2+a^2}\right](x)&=\int_{-\infty}^{\infty}\frac{e^{-itx}}{t^2+a^2}dt\\ &=\int_{-\infty}^{\infty}\frac{e^{-itx}}{(t-ia)(t+ia)}dt \end{align*}$$ Now this is relatively easy with the Residue Theorem (or so I suppose - I think I might miss a step here). Taking the countour $\gamma_R$ to be the half-circle that lies in the upper-half of the complex plane and whose radius is $R$, we can show that the residue of the integrand at the pole at $ia$ (as you can clearly see above, $e^{-itx}$ is entire) multiplied by $2\pi i$ will give us the value of the improper integral above. I have shown my calculations below. It seems that I am missing an absolute value sign in my answer, but I can't see where it comes into play, even when $x<0$. Could you point out my mistake(s)? Calculations Replace all the $t$'s with $z$'s in the integral above. $$\int_{-\infty}^{\infty}\frac{e^{-izx}}{(z-ia)(z+ia)}dz$$ Now we are in the complex domain, and this integral represents integrating the integrand over the real line, going from $-\infty$ to $\infty$. So we consider the semicircle contour $\gamma_R$. If $R \rightarrow \infty$, integrating the part of the contour on the real line will give us our original integral. With that said, we apply the residue theorem. We know that integrating over the entire semicircle can be simplified by the residue theorem, and the only residue that we need to calculate is that at the pole $ia$ (which is inside the contour). $$2 \pi i \textrm{Res} (f; ia) = \left. \frac{e^{-itx}}{t+ia}\right|_{t=ia} = \frac{\pi}{a}e^ax$$ But what I just got only applies to the entire contour $\gamma_R$, not the horizontal line in specific. I now show that it actually does apply to the horizontal line in specific (the real line), as the top part of this semicircle goes to $0$ as $R \rightarrow \infty$. $$ \left| \int_{\textrm{top half}} \frac{e^{-izx}}{z^2+a^2}dz \right| \leq \pi R \left|\frac{1}{a^2-R^2}\right|, \, \rightarrow 0 \,\, \textrm{ as } R \rightarrow \infty $$ So the top-half doesn't matter when $R$ is sufficiently big. This finally leaves us with $$\mathcal{F}\left[\frac{1}{t^2+a^2}\right](x)=\frac{\pi}{a}e^{ax}$$",,"['complex-analysis', 'fourier-analysis', 'residue-calculus']"
28,How to calculate value of an analytic function in a closed disk.,How to calculate value of an analytic function in a closed disk.,,"I just have answer of this question which is 6, but I don't know how to arrive at this answer. Please anyone help me solve this. How does one calculate the value of this function?","I just have answer of this question which is 6, but I don't know how to arrive at this answer. Please anyone help me solve this. How does one calculate the value of this function?",,['complex-analysis']
29,Hermitian manifold counterexample,Hermitian manifold counterexample,,"I'm trying to come to come to grips with the notion of a hermitian manifold. Although I know some examples of hermitian manifolds, I am more interested in counterexamples: naturally occurring Riemannian manifolds which are not hermitian. Could anyone check that my (counter)example below is indeed correct? I fear that I am misunderstanding something. Relevant definitions: A linear map $J: V \to V,$ for $V$ a vector space, is said to be an almost complex structure if $J^2 =-Id.$ A Riemannian manifold $M$ is said to be hermitian if the metric $g$ is compatible with an almost complex structure $J$ on the manifold's tangent space. This means that $\langle X, Y \rangle = \langle JX, JY \rangle,$ for all $X,Y \in TM.$ On a complex manifold, there is a natural almost complex structure on $TM$ induced by the holomorphic charts. This is simply the map $\partial_x \mapsto \partial_y$ and $\partial_y \mapsto -\partial_x.$ Main Question: Let us now consider a simple 2D real surface embedded in $\mathbb{R}^3:$ the (upper half) cylinder parametrized by $(x,y) \mapsto (x, y, \sqrt{1-y^2}).$ The induced Riemannian metric can be written in the basis $(\partial_x, \partial_y)$ as \begin{pmatrix}   1 & 0  \\   0 & 1/(1-y^2)   \end{pmatrix} Now, the above parametrization can also be thought of as providing maps from $\mathbb{C}\cap \{|\text{Re}(z)|<1\}$ to the upper half cylinder, with the transition maps simply the identity and hence trivially holomorphic. The induced complex structure, in matrix form, is  \begin{pmatrix}   0 & 1  \\   -1 & 0   \end{pmatrix} We easily compute that $J^*GJ \neq G$ (where $G$ is the matrix of the metric $g$). Hence the Riemannian metric is NOT compatible with the induced almost complex structure. Hence, the cylinder described is not a hermitian manifold. Supplemental note (feel free to ignore): Following the above arguments, I get that a necessary and sufficient condition for a real surface in $\mathbb{R}^3$ which has holomorphic transition functions to be a hermitian manifold is for the metric to be of the form \begin{pmatrix}   a & b  \\   -b & a   \end{pmatrix} Is this right?","I'm trying to come to come to grips with the notion of a hermitian manifold. Although I know some examples of hermitian manifolds, I am more interested in counterexamples: naturally occurring Riemannian manifolds which are not hermitian. Could anyone check that my (counter)example below is indeed correct? I fear that I am misunderstanding something. Relevant definitions: A linear map $J: V \to V,$ for $V$ a vector space, is said to be an almost complex structure if $J^2 =-Id.$ A Riemannian manifold $M$ is said to be hermitian if the metric $g$ is compatible with an almost complex structure $J$ on the manifold's tangent space. This means that $\langle X, Y \rangle = \langle JX, JY \rangle,$ for all $X,Y \in TM.$ On a complex manifold, there is a natural almost complex structure on $TM$ induced by the holomorphic charts. This is simply the map $\partial_x \mapsto \partial_y$ and $\partial_y \mapsto -\partial_x.$ Main Question: Let us now consider a simple 2D real surface embedded in $\mathbb{R}^3:$ the (upper half) cylinder parametrized by $(x,y) \mapsto (x, y, \sqrt{1-y^2}).$ The induced Riemannian metric can be written in the basis $(\partial_x, \partial_y)$ as \begin{pmatrix}   1 & 0  \\   0 & 1/(1-y^2)   \end{pmatrix} Now, the above parametrization can also be thought of as providing maps from $\mathbb{C}\cap \{|\text{Re}(z)|<1\}$ to the upper half cylinder, with the transition maps simply the identity and hence trivially holomorphic. The induced complex structure, in matrix form, is  \begin{pmatrix}   0 & 1  \\   -1 & 0   \end{pmatrix} We easily compute that $J^*GJ \neq G$ (where $G$ is the matrix of the metric $g$). Hence the Riemannian metric is NOT compatible with the induced almost complex structure. Hence, the cylinder described is not a hermitian manifold. Supplemental note (feel free to ignore): Following the above arguments, I get that a necessary and sufficient condition for a real surface in $\mathbb{R}^3$ which has holomorphic transition functions to be a hermitian manifold is for the metric to be of the form \begin{pmatrix}   a & b  \\   -b & a   \end{pmatrix} Is this right?",,"['complex-analysis', 'differential-geometry', 'riemannian-geometry', 'complex-geometry']"
30,Integrating Fresnel Integrals with Cauchy Theorem?,Integrating Fresnel Integrals with Cauchy Theorem?,,"In regards to the above proof, I'm a little confused as to how the last conclusion was made -- How does the fact that $$\int_{-\infty}^{\infty}e^{-x^2}dx = \sqrt{\pi}$$ to conclude that: $$\int_0^{\infty}\cos{x^2} + i\sin{x^2}dx = \int_0^{\infty}e^{ix^2}dx = \frac{\sqrt{2\pi}}{4} + i\frac{\sqrt{2\pi}}{4}?$$","In regards to the above proof, I'm a little confused as to how the last conclusion was made -- How does the fact that $$\int_{-\infty}^{\infty}e^{-x^2}dx = \sqrt{\pi}$$ to conclude that: $$\int_0^{\infty}\cos{x^2} + i\sin{x^2}dx = \int_0^{\infty}e^{ix^2}dx = \frac{\sqrt{2\pi}}{4} + i\frac{\sqrt{2\pi}}{4}?$$",,['complex-analysis']
31,"Conformal map between $\mathbb{C}\setminus((-\infty, -1]\cup[1,\infty))$ and $\{z \in \mathbb{C} \mid 0 < \operatorname{Im}(z) < 7\}$",Conformal map between  and,"\mathbb{C}\setminus((-\infty, -1]\cup[1,\infty)) \{z \in \mathbb{C} \mid 0 < \operatorname{Im}(z) < 7\}","As it says in the title, I am looking for a conformal map from $\mathbb{C}\setminus((-\infty, -1]\cup[1,\infty))$ to $\{z \in \mathbb{C} \mid 0 < \operatorname{Im}(z) < 7\}$ , but with the following restriction on the boundary components: $(-\infty, -1]$ is mapped to $\operatorname{Im}(z) = 7$ and $[1, \infty)$ is mapped to $\operatorname{Im}(z) = 0$ . So far I have been able to map $\mathbb{C}\setminus((-\infty, -1]\cup[1,\infty))$ to $\{w \in \mathbb{C} \mid 0 < \operatorname{Im}(w) < 7\}$ , but I don't know if the boundary components are mapped to their counterparts in the desired way. I used the following sequence of maps (note, the branch of the logarithm is always the one with argument $(0, 2\pi)$ ): $z \mapsto\frac{1}{\sqrt{2}}\sqrt{z - 1}$ maps $\mathbb{C}\setminus((-\infty, -1]\cup[1,\infty))$ to $\mathbb{H}\setminus\{bi \mid b \in [1, \infty)\}$ . $z \mapsto \dfrac{z-i}{z+i}$ maps $\mathbb{H}\setminus\{bi \mid b \in [1, \infty)\}$ to $\mathbb{D}\setminus[0, 1)$ . $z \mapsto \sqrt{z}$ maps $\mathbb{D}\setminus[0, 1)$ to the upper half disc. $z \mapsto z + \frac{1}{z}$ maps the upper half disc to the lower half plane. $z \mapsto \log z$ maps the lower half plane to $\{z \in \mathbb{C} \mid \pi < \operatorname{Im}(z) < 2\pi\}$ . $z \mapsto \frac{7}{\pi}(z - \pi i)$ maps $\{z \in \mathbb{C} \mid \pi < \operatorname{Im}(z) < 2\pi\}$ to $\{z \in \mathbb{C} \mid 0 < \operatorname{Im}(z) < 7\}$ . The after applying the first and second map, $(-\infty, -1]$ is mapped to $[0, 1)$ . What happens to this boundary component under the third map? It seems like it should remain unchanged, but geometrically it seems that it should be mapped to $(-1, 1)$ . Is there an alternative approach to this problem which would make it easier to see what happens to the boundary components? Note, if we could construct a map as desired, except it swapped the boundary components, we could define a new map by (post)composing with the map $z \mapsto 7 - z$ ; this new map would then have all the desired properties.","As it says in the title, I am looking for a conformal map from to , but with the following restriction on the boundary components: is mapped to and is mapped to . So far I have been able to map to , but I don't know if the boundary components are mapped to their counterparts in the desired way. I used the following sequence of maps (note, the branch of the logarithm is always the one with argument ): maps to . maps to . maps to the upper half disc. maps the upper half disc to the lower half plane. maps the lower half plane to . maps to . The after applying the first and second map, is mapped to . What happens to this boundary component under the third map? It seems like it should remain unchanged, but geometrically it seems that it should be mapped to . Is there an alternative approach to this problem which would make it easier to see what happens to the boundary components? Note, if we could construct a map as desired, except it swapped the boundary components, we could define a new map by (post)composing with the map ; this new map would then have all the desired properties.","\mathbb{C}\setminus((-\infty, -1]\cup[1,\infty)) \{z \in \mathbb{C} \mid 0 < \operatorname{Im}(z) < 7\} (-\infty, -1] \operatorname{Im}(z) = 7 [1, \infty) \operatorname{Im}(z) = 0 \mathbb{C}\setminus((-\infty, -1]\cup[1,\infty)) \{w \in \mathbb{C} \mid 0 < \operatorname{Im}(w) < 7\} (0, 2\pi) z \mapsto\frac{1}{\sqrt{2}}\sqrt{z - 1} \mathbb{C}\setminus((-\infty, -1]\cup[1,\infty)) \mathbb{H}\setminus\{bi \mid b \in [1, \infty)\} z \mapsto \dfrac{z-i}{z+i} \mathbb{H}\setminus\{bi \mid b \in [1, \infty)\} \mathbb{D}\setminus[0, 1) z \mapsto \sqrt{z} \mathbb{D}\setminus[0, 1) z \mapsto z + \frac{1}{z} z \mapsto \log z \{z \in \mathbb{C} \mid \pi < \operatorname{Im}(z) < 2\pi\} z \mapsto \frac{7}{\pi}(z - \pi i) \{z \in \mathbb{C} \mid \pi < \operatorname{Im}(z) < 2\pi\} \{z \in \mathbb{C} \mid 0 < \operatorname{Im}(z) < 7\} (-\infty, -1] [0, 1) (-1, 1) z \mapsto 7 - z",['complex-analysis']
32,Evaluation of Sum of $ \sum_{n=1}^{\infty}\frac{\sin (n)}{n}$.,Evaluation of Sum of ., \sum_{n=1}^{\infty}\frac{\sin (n)}{n},If $\displaystyle S = \sum_{n=1}^{\infty}\frac{\sin (n)}{n}.$ Then value of $2S+1 = $ Using Fourier Series Transformation I am Getting $2S+1=\pi$ But I want to solve it Using Euler  Method and Then Use Logarithmic Series. $\bf{My\; Try::}$ Using $\displaystyle \sin (n) = \left(\frac{e^{in}-e^{-in}}{2i}\right)$. So $\displaystyle S = \sum_{n=1}^{n}\frac{\sin (n)}{n} = \frac{1}{2i}\sum_{n=1}^{\infty}\frac{e^{in}}{n}-\frac{1}{2i}\sum_{n=1}^{\infty}\frac{e^{-in}}{n}$ Now Using $\displaystyle \ln(1-x) = -x-\frac{x^2}{2}-\frac{x^3}{3}...............\infty$ So Let $\displaystyle S = -\frac{1}{2i}\ln(1-e^{i})+\frac{1}{2i}\ln(1-e^{-i})$ Now How can I solve after that Help me Thanks,If $\displaystyle S = \sum_{n=1}^{\infty}\frac{\sin (n)}{n}.$ Then value of $2S+1 = $ Using Fourier Series Transformation I am Getting $2S+1=\pi$ But I want to solve it Using Euler  Method and Then Use Logarithmic Series. $\bf{My\; Try::}$ Using $\displaystyle \sin (n) = \left(\frac{e^{in}-e^{-in}}{2i}\right)$. So $\displaystyle S = \sum_{n=1}^{n}\frac{\sin (n)}{n} = \frac{1}{2i}\sum_{n=1}^{\infty}\frac{e^{in}}{n}-\frac{1}{2i}\sum_{n=1}^{\infty}\frac{e^{-in}}{n}$ Now Using $\displaystyle \ln(1-x) = -x-\frac{x^2}{2}-\frac{x^3}{3}...............\infty$ So Let $\displaystyle S = -\frac{1}{2i}\ln(1-e^{i})+\frac{1}{2i}\ln(1-e^{-i})$ Now How can I solve after that Help me Thanks,,['complex-analysis']
33,Completion of Complex Numbers,Completion of Complex Numbers,,"In some way, $\mathbb{C}$ completes $\mathbb{R}$, why is there nothing that completes $\mathbb{C}$? Is it just more so that we don't want anything more than $\mathbb{C}$, or is there a property of $\mathbb{C}$ that makes it complete , in some sense? I know algebraically $\mathbb{C}$ is very nice, but is there nothing else we look for?","In some way, $\mathbb{C}$ completes $\mathbb{R}$, why is there nothing that completes $\mathbb{C}$? Is it just more so that we don't want anything more than $\mathbb{C}$, or is there a property of $\mathbb{C}$ that makes it complete , in some sense? I know algebraically $\mathbb{C}$ is very nice, but is there nothing else we look for?",,[]
34,value of the integral $\int_0^{2\pi} \log|1-ae^{i \theta}| $,value of the integral,\int_0^{2\pi} \log|1-ae^{i \theta}| ,This is a problem from Complex Analysis by Stein and  Shakarchi. We have to find the the value of  $\int_0^{2\pi}  \log|1-ae^{i \theta}| $ when $|a|<1$. So I tried to solve it in this manner. I first made the substitution $e^{i\theta}=z$.   Then the integral becomes $\int_\gamma  \frac{\log|1-az|}{iz} $. Then we observe that $\int_0^{2\pi}  \log|1-ae^{i \theta}| $ is the real part of the integral $\int_0^{2\pi}  \log(1-ae^{i \theta}) $. So we will evaluate $\int_\gamma  \frac{\log(1-az)}{iz} $. But this function has a removable singularity at $z=0$.So the integral of this function is zero since it is holomorphic. So its real part is also zero. Is my reasoning right?If not can someone please point out what is wrong. Thanks,This is a problem from Complex Analysis by Stein and  Shakarchi. We have to find the the value of  $\int_0^{2\pi}  \log|1-ae^{i \theta}| $ when $|a|<1$. So I tried to solve it in this manner. I first made the substitution $e^{i\theta}=z$.   Then the integral becomes $\int_\gamma  \frac{\log|1-az|}{iz} $. Then we observe that $\int_0^{2\pi}  \log|1-ae^{i \theta}| $ is the real part of the integral $\int_0^{2\pi}  \log(1-ae^{i \theta}) $. So we will evaluate $\int_\gamma  \frac{\log(1-az)}{iz} $. But this function has a removable singularity at $z=0$.So the integral of this function is zero since it is holomorphic. So its real part is also zero. Is my reasoning right?If not can someone please point out what is wrong. Thanks,,"['complex-analysis', 'self-learning']"
35,Prove that $e^{\ln{z}}=z$ from the power series,Prove that  from the power series,e^{\ln{z}}=z,For my course in complex analysis we have to prove that the trivial relation $e^{\ln{z}}=z$. We are given the series for $\ln z$: $$f(w)=\sum_{n=0}^\infty (-1)^{n+1}\frac{w^n}{n}$$ $$\ln z = f(z-1)$$ I know that the series for $e^x$ is $$e^{x}=\sum_{n=0}^\infty \frac{x^n}{n!}$$ I tried to solve $$e^{\ln{z}}=\sum_{n=0}^\infty \frac{\left(\sum_{m=0}^\infty (-1)^{m+1}\frac{(z-1)^m}{m}\right)^n}{n!}$$ But just inserting the previous series into this does not yield a very convenient result. I think that if we expand the first power series around $z=0$ we would have already a problem (this makes sense since also $\ln 0$ does not exist. How and with what technique is this problem solved? Edit (clarification): We need to prove the relation given using the power series for $\ln{z}$ as definition.,For my course in complex analysis we have to prove that the trivial relation $e^{\ln{z}}=z$. We are given the series for $\ln z$: $$f(w)=\sum_{n=0}^\infty (-1)^{n+1}\frac{w^n}{n}$$ $$\ln z = f(z-1)$$ I know that the series for $e^x$ is $$e^{x}=\sum_{n=0}^\infty \frac{x^n}{n!}$$ I tried to solve $$e^{\ln{z}}=\sum_{n=0}^\infty \frac{\left(\sum_{m=0}^\infty (-1)^{m+1}\frac{(z-1)^m}{m}\right)^n}{n!}$$ But just inserting the previous series into this does not yield a very convenient result. I think that if we expand the first power series around $z=0$ we would have already a problem (this makes sense since also $\ln 0$ does not exist. How and with what technique is this problem solved? Edit (clarification): We need to prove the relation given using the power series for $\ln{z}$ as definition.,,"['complex-analysis', 'power-series']"
36,Whats the differences between the real-entire functions on $\mathbb R^{2}$ and complex entire functions on $\mathbb C$?,Whats the differences between the real-entire functions on  and complex entire functions on ?,\mathbb R^{2} \mathbb C,"We note, as set of points, $\mathbb R^{2}= \mathbb C.$ A complex valued function $F,$ defined on  an open set  $E$ in the plane $\mathbb R^{2}$, is said to be real-analytic in $E$ if to every point $(s_{0}, t_{0})$ in there corresponds an expansion with complex coefficients $$F(s, t)= \sum_{n,m=0}^{\infty} a_{nm}(s-s_{0})^{m} (t-t_{0})^{n},$$  which converges absolutely for all $(s,t)$ in some neighbourhood of $(s_{0}, t_{0}).$ If $F$ is defined in the whole plane $\mathbb R^{2}$ by a series $$F(s, t)= \sum_{n,m=0}^{\infty} a_{nm}s^{m} t^{n},$$ which converges absolutely for every $(s,t),$ the we call $F$ real-entire . We say $F:\mathbb C \to \mathbb C$ is complex-entire if $F$ is differentiable on whole $\mathbb C.$ My Questions : (1)  What are conceptual differences between real-entire and complex-entire  functions defined on $\mathbb R^{2}= \mathbb C.$ (2) Suppose $f:\mathbb C \to \mathbb C$ is differentiable on whole $\mathbb C$. Is it true that $f:\mathbb R^{2}\to \mathbb C$ is real entire ? (3) Suppose that $f:\mathbb R^{2}\to \mathbb C$ is real entire. Is it true that $f:\mathbb C \to \mathbb C$ is differentiable on $\mathbb C.$ ? Trivial attempt : (a)If we consider, $f:\mathbb C \to \mathbb C$ such that $f(z)=z|z|^{2},$  and put $f=u+iv$, where $u,v:\mathbb R^{2}\to \mathbb R$ and $z=x+iy$; then $u(x,y)= x(x^{2}+y^{2})$ and $v(x,y)= y(x^{2}+y^{2})$; and $f$ satisfies Cauchy- Riemann equations iff $xy=0$; and therefore, $f$ can not be differentiable  on $\mathbb C$ (Please correct me if  I have done some thing wrong); now if we look at $f:\mathbb R^{2}\to \mathbb C$ such that $f(x,y)= (x(x^{2}+ y^{2}), y(x^{2}+y^{2}))$ ; Is $f$  is real-entire ? (I don't know how  to proceed here ) (b) Take, $f:\mathbb R^{2}=\mathbb C \to \mathbb C$ such that $f(z)= |z|z= (x\sqrt{x^{2}+y^{2}}, y\sqrt{x^{2}+y^{2}})$; what can we say about $f$ ? Thanks,","We note, as set of points, $\mathbb R^{2}= \mathbb C.$ A complex valued function $F,$ defined on  an open set  $E$ in the plane $\mathbb R^{2}$, is said to be real-analytic in $E$ if to every point $(s_{0}, t_{0})$ in there corresponds an expansion with complex coefficients $$F(s, t)= \sum_{n,m=0}^{\infty} a_{nm}(s-s_{0})^{m} (t-t_{0})^{n},$$  which converges absolutely for all $(s,t)$ in some neighbourhood of $(s_{0}, t_{0}).$ If $F$ is defined in the whole plane $\mathbb R^{2}$ by a series $$F(s, t)= \sum_{n,m=0}^{\infty} a_{nm}s^{m} t^{n},$$ which converges absolutely for every $(s,t),$ the we call $F$ real-entire . We say $F:\mathbb C \to \mathbb C$ is complex-entire if $F$ is differentiable on whole $\mathbb C.$ My Questions : (1)  What are conceptual differences between real-entire and complex-entire  functions defined on $\mathbb R^{2}= \mathbb C.$ (2) Suppose $f:\mathbb C \to \mathbb C$ is differentiable on whole $\mathbb C$. Is it true that $f:\mathbb R^{2}\to \mathbb C$ is real entire ? (3) Suppose that $f:\mathbb R^{2}\to \mathbb C$ is real entire. Is it true that $f:\mathbb C \to \mathbb C$ is differentiable on $\mathbb C.$ ? Trivial attempt : (a)If we consider, $f:\mathbb C \to \mathbb C$ such that $f(z)=z|z|^{2},$  and put $f=u+iv$, where $u,v:\mathbb R^{2}\to \mathbb R$ and $z=x+iy$; then $u(x,y)= x(x^{2}+y^{2})$ and $v(x,y)= y(x^{2}+y^{2})$; and $f$ satisfies Cauchy- Riemann equations iff $xy=0$; and therefore, $f$ can not be differentiable  on $\mathbb C$ (Please correct me if  I have done some thing wrong); now if we look at $f:\mathbb R^{2}\to \mathbb C$ such that $f(x,y)= (x(x^{2}+ y^{2}), y(x^{2}+y^{2}))$ ; Is $f$  is real-entire ? (I don't know how  to proceed here ) (b) Take, $f:\mathbb R^{2}=\mathbb C \to \mathbb C$ such that $f(z)= |z|z= (x\sqrt{x^{2}+y^{2}}, y\sqrt{x^{2}+y^{2}})$; what can we say about $f$ ? Thanks,",,"['real-analysis', 'complex-analysis', 'analysis']"
37,Show that $ z \sin(z) = 1 $ has only real solutions.,Show that  has only real solutions., z \sin(z) = 1 ,"Here is my question - it is an example sheet question, completely non-examinable: Show that the equation $ z \sin(z) = 1 $ has only real solutions. [ Hint: Find the number of real roots in the interval $[-(n+1/2)\pi, (n+1/2)\pi$ and compare with the number of zeros of $ z \sin(z) - 1 $ in a square box $\{|\Bbb Re(z)|,|\Bbb Im(z)| < (n+1/2)\pi\}$. ] I'd be most grateful if someone were able to give me a suggestion as to how to do this! (I realise that there is a hint, but I can't work out the real roots either! If I divide through by $z$, then I get $ \sin(z) = 1/z $, but we known that $\sin(z)$ has a Taylor series, ie no principal part of the Laurent series. Does this not mean that I am trying to equate $$ \sum_{r=0}^\infty {(-1)^r z^{2r+1} \over (2r+1)!} = {1 \over z} \,?$$ Thanks! :)","Here is my question - it is an example sheet question, completely non-examinable: Show that the equation $ z \sin(z) = 1 $ has only real solutions. [ Hint: Find the number of real roots in the interval $[-(n+1/2)\pi, (n+1/2)\pi$ and compare with the number of zeros of $ z \sin(z) - 1 $ in a square box $\{|\Bbb Re(z)|,|\Bbb Im(z)| < (n+1/2)\pi\}$. ] I'd be most grateful if someone were able to give me a suggestion as to how to do this! (I realise that there is a hint, but I can't work out the real roots either! If I divide through by $z$, then I get $ \sin(z) = 1/z $, but we known that $\sin(z)$ has a Taylor series, ie no principal part of the Laurent series. Does this not mean that I am trying to equate $$ \sum_{r=0}^\infty {(-1)^r z^{2r+1} \over (2r+1)!} = {1 \over z} \,?$$ Thanks! :)",,"['complex-analysis', 'roots']"
38,Corresponding analytic function?,Corresponding analytic function?,,"I have found a general harmonic function of form $a x^3 - 3dx^2 y - 3axy^2 + dy^3$ and it's harmonic conjugate $v = 3ax^2y - 3dxy^2 + ay^3 + dx^3 + K$ where k is constant. I now am asked to find the corresponding analytic function $f(z) $ expressed in terms of $z$, and to check up to an imaginary constant $f(z) = 2u(\frac{1}{2}z, \frac{1}{2i}z) - u(0,0)$. I know that an function $f(z)$ is analytic if its derivative is continuous at $z$, and it should be of form (I imagine) $u(x,y) + iv(x,y)$, but not how to find such a function. If I could have some pointers that would be great. Update: Substituting $f(z) =  u(x,y) + iv(x,y)$ I have managed to find $f(z) = z^3(a + di)$ but I still don't understand the last part?","I have found a general harmonic function of form $a x^3 - 3dx^2 y - 3axy^2 + dy^3$ and it's harmonic conjugate $v = 3ax^2y - 3dxy^2 + ay^3 + dx^3 + K$ where k is constant. I now am asked to find the corresponding analytic function $f(z) $ expressed in terms of $z$, and to check up to an imaginary constant $f(z) = 2u(\frac{1}{2}z, \frac{1}{2i}z) - u(0,0)$. I know that an function $f(z)$ is analytic if its derivative is continuous at $z$, and it should be of form (I imagine) $u(x,y) + iv(x,y)$, but not how to find such a function. If I could have some pointers that would be great. Update: Substituting $f(z) =  u(x,y) + iv(x,y)$ I have managed to find $f(z) = z^3(a + di)$ but I still don't understand the last part?",,"['complex-analysis', 'analyticity']"
39,radius of convergence of half iterate of sinh(z)?,radius of convergence of half iterate of sinh(z)?,,"The half iterate of sinh(z) has a formal power series, centered around z=0.  Does the formal power series for the half iterate converge at the origin? This is equivalent to asking if the half iterate is analytic at the origin.  If it converges, what is the radius of convergence?  Are there any other singularities in the complex plane for the half iterate of the sinh(z)?  The sinh(z) is an entire function, with exponential growth at the real axis, for both positive and negative z.  It has a fixed point of zero, with a fixed point multiplier of 1. $$\sinh(x)=\frac{\exp(x)-\exp(-x)}{2} = x + \frac{x^3}{6} + \frac{x^5}{120}+ \frac{x^7}{7!} + \frac{x^9}{9!} ....$$ One can generate a formal half iterate of the function, such that half(half(x))=sinh(x). $$\text{half}(x) = x + \frac{x^3}{12} + \frac{-x^5}{160}+ \frac{53x^7}{40320} + \frac{-23x^9}{71680} + \frac{92713x^{11}}{1277337600} + ....$$ Such a half iterate would have ""half-exponential"" growth as abs(real(z)) gets bigger, which is why I was curious if it was entire, since I don't know of any entire ""half exponential"" functions.  The coefficients of the half iterate of asinh(z) appear to be mostly decreasing, with the 41st coefficient $\approx  0.0000000047072111$.  Does such a half iterate function converge at the fixed point at the origin, or is the convergence only illusory, with the series actually asymptotic, rather than converging?   Another way of generating the half iterate is $\alpha^{-1}(\alpha(z)+\frac{1}{2})$, where $\alpha(z)$ is the abel function.  Presumably, this generate the same half iterate.  What are the half iterate's singularities in the complex plane?","The half iterate of sinh(z) has a formal power series, centered around z=0.  Does the formal power series for the half iterate converge at the origin? This is equivalent to asking if the half iterate is analytic at the origin.  If it converges, what is the radius of convergence?  Are there any other singularities in the complex plane for the half iterate of the sinh(z)?  The sinh(z) is an entire function, with exponential growth at the real axis, for both positive and negative z.  It has a fixed point of zero, with a fixed point multiplier of 1. $$\sinh(x)=\frac{\exp(x)-\exp(-x)}{2} = x + \frac{x^3}{6} + \frac{x^5}{120}+ \frac{x^7}{7!} + \frac{x^9}{9!} ....$$ One can generate a formal half iterate of the function, such that half(half(x))=sinh(x). $$\text{half}(x) = x + \frac{x^3}{12} + \frac{-x^5}{160}+ \frac{53x^7}{40320} + \frac{-23x^9}{71680} + \frac{92713x^{11}}{1277337600} + ....$$ Such a half iterate would have ""half-exponential"" growth as abs(real(z)) gets bigger, which is why I was curious if it was entire, since I don't know of any entire ""half exponential"" functions.  The coefficients of the half iterate of asinh(z) appear to be mostly decreasing, with the 41st coefficient $\approx  0.0000000047072111$.  Does such a half iterate function converge at the fixed point at the origin, or is the convergence only illusory, with the series actually asymptotic, rather than converging?   Another way of generating the half iterate is $\alpha^{-1}(\alpha(z)+\frac{1}{2})$, where $\alpha(z)$ is the abel function.  Presumably, this generate the same half iterate.  What are the half iterate's singularities in the complex plane?",,"['complex-analysis', 'tetration', 'complex-dynamics']"
40,"Laurent series, radii of convergence.","Laurent series, radii of convergence.",,"I'm working on the following exercise: Prove that a Laurent series   \begin{align*} \sum_{n = -\infty}^\infty a_n(z-z_0)^n = \sum_{n = 0}^\infty a_n(z-z_0)^n + \sum_{n = 1}^\infty a_{-n}(z-z_0)^{-n} \end{align*}   converge for all $z$ such that $r < |z-z_0| < R$, where   \begin{align*} r = \limsup |a_{-n}|^{1/n}, \quad R^{-1} = \limsup |a_n|^{1/n}, \end{align*}   with $0 \le r$, $R \le \infty$. I already tried the ratio test, but I didn't find the limit to be $<1$ and also with comparison test I didn't reach a result. Maybe there is another approach which I don't know. I wanted to prove the convergence for both parts of the series, because if both parts converge, then also the whole Laurent series. Thanks.","I'm working on the following exercise: Prove that a Laurent series   \begin{align*} \sum_{n = -\infty}^\infty a_n(z-z_0)^n = \sum_{n = 0}^\infty a_n(z-z_0)^n + \sum_{n = 1}^\infty a_{-n}(z-z_0)^{-n} \end{align*}   converge for all $z$ such that $r < |z-z_0| < R$, where   \begin{align*} r = \limsup |a_{-n}|^{1/n}, \quad R^{-1} = \limsup |a_n|^{1/n}, \end{align*}   with $0 \le r$, $R \le \infty$. I already tried the ratio test, but I didn't find the limit to be $<1$ and also with comparison test I didn't reach a result. Maybe there is another approach which I don't know. I wanted to prove the convergence for both parts of the series, because if both parts converge, then also the whole Laurent series. Thanks.",,"['complex-analysis', 'convergence-divergence', 'taylor-expansion', 'laurent-series']"
41,I can't understand why Ahlfors' statement is true (isolation of singular points),I can't understand why Ahlfors' statement is true (isolation of singular points),,"In Ahlfors' complex analysis text, page 264, he writes: When $\Omega$ is the whole plane $F(\zeta)$ has isolated singularities at $\zeta = 0$ and $\zeta=\infty $. Reading the previous sections, I assume that $\Omega \subset \mathbb C$ is a region invariant under the translations $z \mapsto z+ \omega,z \mapsto z- \omega$, where $\omega \in \mathbb C$ is some constant. $F(\zeta)=f(z)$ where $\zeta=\exp(2 \pi i z/ \omega)$, and $f$ is some meromorphic function in $\Omega$. Also we denote that image of $\Omega$ under $\zeta(z)$ by $\Omega'$. Here is (what appears to me as) a counterexample to Ahlfors' statement: Construct a function $f(z)$ meromorphic in $\Omega=\mathbb C$ with periods $\omega, i \omega$, with $\omega \in \mathbb R$, whose poles form the lattice $\{m \omega+i n \omega:m,n \in \mathbb Z \}$. The sequence of poles $\{i \omega n\}_1^\infty$ in the $z$-plane corresponds to the sequence of poles $\{e^{-2 \pi n} \}$ in the $\zeta$-plane, which tends to the point $\zeta=0$. This shows that $\zeta=0$ is not an isolated singularity of $F(\zeta)$, (the situation at $\infty$ is identical). Is my reasoning correct, or is Ahlfors right after all? If I'm wrong, please show me why. Thanks!","In Ahlfors' complex analysis text, page 264, he writes: When $\Omega$ is the whole plane $F(\zeta)$ has isolated singularities at $\zeta = 0$ and $\zeta=\infty $. Reading the previous sections, I assume that $\Omega \subset \mathbb C$ is a region invariant under the translations $z \mapsto z+ \omega,z \mapsto z- \omega$, where $\omega \in \mathbb C$ is some constant. $F(\zeta)=f(z)$ where $\zeta=\exp(2 \pi i z/ \omega)$, and $f$ is some meromorphic function in $\Omega$. Also we denote that image of $\Omega$ under $\zeta(z)$ by $\Omega'$. Here is (what appears to me as) a counterexample to Ahlfors' statement: Construct a function $f(z)$ meromorphic in $\Omega=\mathbb C$ with periods $\omega, i \omega$, with $\omega \in \mathbb R$, whose poles form the lattice $\{m \omega+i n \omega:m,n \in \mathbb Z \}$. The sequence of poles $\{i \omega n\}_1^\infty$ in the $z$-plane corresponds to the sequence of poles $\{e^{-2 \pi n} \}$ in the $\zeta$-plane, which tends to the point $\zeta=0$. This shows that $\zeta=0$ is not an isolated singularity of $F(\zeta)$, (the situation at $\infty$ is identical). Is my reasoning correct, or is Ahlfors right after all? If I'm wrong, please show me why. Thanks!",,"['complex-analysis', 'analysis', 'elliptic-functions']"
42,Zero of the derivative of ameromorphic function,Zero of the derivative of ameromorphic function,,"Let $f:\mathbb{C} \rightarrow \hat{\mathbb{C}}$ a meromorphic function with an essential singularity at infinity. Does $f'(z)$ have a zero? No, considering $z\mapsto e^z$. But if I assume that $f$ is surjective, is it true?  and can i say something on the order of vanishing. I am not a specialist of holomorphic function. This question arise in geomerty. More precisely my function satisfies $\frac{f'}{1+\vert f\vert^2}=O(\frac{1}{z})$, where the right-hand side is called the spherical derivative.  Thanks to the work of Letho, The spherical derivative of meromorphic functions in the neighborhood of an isolated singularity , we know that $f$ must be surjective. Added: The full question is: If $f$ has an essential singularity and  satisfies $\frac{f'}{1+\vert f\vert^2}=O(\frac{1}{z})$, does $f'$ vanishes? and can we say something about the order of vanishing.","Let $f:\mathbb{C} \rightarrow \hat{\mathbb{C}}$ a meromorphic function with an essential singularity at infinity. Does $f'(z)$ have a zero? No, considering $z\mapsto e^z$. But if I assume that $f$ is surjective, is it true?  and can i say something on the order of vanishing. I am not a specialist of holomorphic function. This question arise in geomerty. More precisely my function satisfies $\frac{f'}{1+\vert f\vert^2}=O(\frac{1}{z})$, where the right-hand side is called the spherical derivative.  Thanks to the work of Letho, The spherical derivative of meromorphic functions in the neighborhood of an isolated singularity , we know that $f$ must be surjective. Added: The full question is: If $f$ has an essential singularity and  satisfies $\frac{f'}{1+\vert f\vert^2}=O(\frac{1}{z})$, does $f'$ vanishes? and can we say something about the order of vanishing.",,['complex-analysis']
43,Why does this integral vanish? $\int_C \frac{e^{az}}{1+e^z}dz$,Why does this integral vanish?,\int_C \frac{e^{az}}{1+e^z}dz,"I'm looking for an argument that would prove that the integral $$I=\int_C \frac{e^{az}}{1+e^z}dz$$ vanishes for $R \to \infty$, where $C$ is the horizontal line segment from $(1+i)R$ to $(-1+i)R$, and $a \in (0,1)$. Here $R$ goes to infinity 'discretely', so as to avoid the singularies at $(2n+1)\pi i$, the line segment is placed between the subsequent singularities. Parametrizing the contour with $z(t)=iR+t, \ t\in[-R,R]$ and attempting to bound the integral gives me: $$|I| \le \int_{-R}^{R} \frac{e^{at}dt}{|1+e^{t+iR}|}$$ but I don't know what to do with this, using the reverse tringle inequality doesn't help because the denominator becomes $e^t -1$, and the integral goes through zero... Additional information: This problem cropped up when doing the following exercise: ""By choosing a suitable contour, show that  $$\int_\mathbb{R} \frac{e^{ax}}{1+e^x}dx = \frac{\pi}{\sin(a\pi)},$$ where $0<a<1$. I managed to solve this integral now, by choosing the integration contour to be a rectangle with vertices $\pm R, \pm R + 2\pi i$. But originally, I was trying the verteces $\pm R, (\pm 1+i)R$, where the values of $R$ are restricted so the contour doesn't go through a singularity. Letting $R$ to infinity will then have the contour capture all of the residues on the positive imaginary axis, the sum of which (times $2 \pi i$) is precisely $\frac{\pi}{\sin(a\pi)}$, meaning the top part has to tend to zero. Letting $R$ change in discrete steps, $R_n = 2\pi n$ gives a nonzero value of the top integral though, namely $$I_{top} = e^{2\pi i a n} I_n$$ where $$I_n = \int_{-2\pi n}^{2 \pi n} f(x)dx.$$ So, in the limit, things don't actually work out because of the weird oscillatory term. But apparently, taking the limit is not even necessary, as the top integral is always proportional to the bottom one, so their sum is equal to the residues contained inside, which are calculated easily enough.","I'm looking for an argument that would prove that the integral $$I=\int_C \frac{e^{az}}{1+e^z}dz$$ vanishes for $R \to \infty$, where $C$ is the horizontal line segment from $(1+i)R$ to $(-1+i)R$, and $a \in (0,1)$. Here $R$ goes to infinity 'discretely', so as to avoid the singularies at $(2n+1)\pi i$, the line segment is placed between the subsequent singularities. Parametrizing the contour with $z(t)=iR+t, \ t\in[-R,R]$ and attempting to bound the integral gives me: $$|I| \le \int_{-R}^{R} \frac{e^{at}dt}{|1+e^{t+iR}|}$$ but I don't know what to do with this, using the reverse tringle inequality doesn't help because the denominator becomes $e^t -1$, and the integral goes through zero... Additional information: This problem cropped up when doing the following exercise: ""By choosing a suitable contour, show that  $$\int_\mathbb{R} \frac{e^{ax}}{1+e^x}dx = \frac{\pi}{\sin(a\pi)},$$ where $0<a<1$. I managed to solve this integral now, by choosing the integration contour to be a rectangle with vertices $\pm R, \pm R + 2\pi i$. But originally, I was trying the verteces $\pm R, (\pm 1+i)R$, where the values of $R$ are restricted so the contour doesn't go through a singularity. Letting $R$ to infinity will then have the contour capture all of the residues on the positive imaginary axis, the sum of which (times $2 \pi i$) is precisely $\frac{\pi}{\sin(a\pi)}$, meaning the top part has to tend to zero. Letting $R$ change in discrete steps, $R_n = 2\pi n$ gives a nonzero value of the top integral though, namely $$I_{top} = e^{2\pi i a n} I_n$$ where $$I_n = \int_{-2\pi n}^{2 \pi n} f(x)dx.$$ So, in the limit, things don't actually work out because of the weird oscillatory term. But apparently, taking the limit is not even necessary, as the top integral is always proportional to the bottom one, so their sum is equal to the residues contained inside, which are calculated easily enough.",,['complex-analysis']
44,Laurent series of $z^{-3}$ at $z_0 = i$. Is there a way to do this by hand or is the question just evil?,Laurent series of  at . Is there a way to do this by hand or is the question just evil?,z^{-3} z_0 = i,"I have to find the two Laurent series expansions of $\frac{1}{z^3}$ about $i$. The only approach I can think of is to do: $$\frac{1}{z^3} = \frac{1}{(z-i)^3} \left( \frac{z-i}{z} \right) ^3 = \frac{1}{(z-i)^3} \left( 1 - \frac{i}{i+(z-i)} \right) ^3 = \frac{1}{(z-i)^3} \left( 1 - \frac{1}{1-i(z-i)} \right) ^3 $$ This expansion will work in the disk $|z-i|<1:$ $$=\frac{1}{(z-i)^3} \left( 1 - \sum_{n=0}^{\infty}i^n(z-i)^n \right) ^3  =i \left(  \sum_{n=0}^{\infty}i^{n}(z-i)^{n} \right) ^3 .$$ But this is nasty, because I don't know how to cube the series! And I don't think anything nice would come out of it, anyway. The second expansion is in the annulus $|z-i|>1:$ $$\frac{1}{z^3} = ... =  \frac{1}{(z-i)^3} \left( 1 - \frac{1}{z-i}\frac{1}{ \frac{1}{z-i}-i} \right) ^3 = \frac{1}{(z-i)^3} \left( 1 - \frac{1}{z-i}\frac{i}{ 1-\frac{-i}{z-i}} \right) ^3 =$$ $$=  \left( \frac{1}{z-i} - i \sum_{n=0}^{\infty} \frac{(-i)^n}{(z-i)^{n-2}} \right) ^3$$ Same problem, except now it's even worse... How do I deal with this?","I have to find the two Laurent series expansions of $\frac{1}{z^3}$ about $i$. The only approach I can think of is to do: $$\frac{1}{z^3} = \frac{1}{(z-i)^3} \left( \frac{z-i}{z} \right) ^3 = \frac{1}{(z-i)^3} \left( 1 - \frac{i}{i+(z-i)} \right) ^3 = \frac{1}{(z-i)^3} \left( 1 - \frac{1}{1-i(z-i)} \right) ^3 $$ This expansion will work in the disk $|z-i|<1:$ $$=\frac{1}{(z-i)^3} \left( 1 - \sum_{n=0}^{\infty}i^n(z-i)^n \right) ^3  =i \left(  \sum_{n=0}^{\infty}i^{n}(z-i)^{n} \right) ^3 .$$ But this is nasty, because I don't know how to cube the series! And I don't think anything nice would come out of it, anyway. The second expansion is in the annulus $|z-i|>1:$ $$\frac{1}{z^3} = ... =  \frac{1}{(z-i)^3} \left( 1 - \frac{1}{z-i}\frac{1}{ \frac{1}{z-i}-i} \right) ^3 = \frac{1}{(z-i)^3} \left( 1 - \frac{1}{z-i}\frac{i}{ 1-\frac{-i}{z-i}} \right) ^3 =$$ $$=  \left( \frac{1}{z-i} - i \sum_{n=0}^{\infty} \frac{(-i)^n}{(z-i)^{n-2}} \right) ^3$$ Same problem, except now it's even worse... How do I deal with this?",,"['complex-analysis', 'power-series', 'laurent-series']"
45,A question related to uniqueness principle theorem.,A question related to uniqueness principle theorem.,,"We know that the equation $ \sin^2z+ \cos^2z=1$ which holds $\forall z \in\Bbb R$ , also holds $\forall z \in\Bbb C$ . This is obvious under the shadow of following theorem: Uniqueness principle theorem :If $f$ and $g$ are analytic functions on a domain $D$ , and if $f(z)=g(z)$ for $z$ belonging to a set that has a non isolated point, then $f(z)=g(z)$ for all $z\in D$ . Can we extend the domain of function $ |\sin z|^2+|\cos z|^2$ from $\Bbb R$ to $\Bbb C$ ? (i.e Can we say that $|\sin z|^2+|\cos z|^2=1\,\forall z \in\Bbb C$ )? I think this extension of the domain from the real line to the entire complex plane is not possible. Since function on left-hand side i.e. $ |\sin z|^2+|\cos z|^2$ doesn't look analytic. And to use above theorem we need both functions to be analytic. How will we show this? Thanks.","We know that the equation which holds , also holds . This is obvious under the shadow of following theorem: Uniqueness principle theorem :If and are analytic functions on a domain , and if for belonging to a set that has a non isolated point, then for all . Can we extend the domain of function from to ? (i.e Can we say that )? I think this extension of the domain from the real line to the entire complex plane is not possible. Since function on left-hand side i.e. doesn't look analytic. And to use above theorem we need both functions to be analytic. How will we show this? Thanks."," \sin^2z+ \cos^2z=1 \forall z \in\Bbb R \forall z \in\Bbb C f g D f(z)=g(z) z f(z)=g(z) z\in D  |\sin z|^2+|\cos z|^2 \Bbb R \Bbb C |\sin z|^2+|\cos z|^2=1\,\forall z \in\Bbb C  |\sin z|^2+|\cos z|^2","['complex-analysis', 'complex-numbers', 'analyticity']"
46,"Two questions regarding $\mathrm {Li}$ from ""Edwards""","Two questions regarding  from ""Edwards""",\mathrm {Li},"I would appreciate help understanding a relation in Edwards's ""Riemann's Zeta Function."" On page 30 he has: $$\int_{C^{+}} \frac{t^{\beta - 1}}{\log t}dt = \int_{0}^{x^{\beta}}\frac{du}{\log u}= \mathrm {Li} (x^{\beta}) - i\pi$$ He states for $\beta$ positive and real, change variables $u = t^{\beta}$ which implies $\log t = \log u/\beta$ and $dt/t = du/u \beta$. Here $C^{+}$ is a path which is a line segment from $0$ to $1 - \epsilon$ and passes over the singularity at $u = 1$ in a semi-circle in the upper half-plane and continues in a line segment from $1 + \epsilon$ to $1$. I would appreciate help with two aspects: -- Since most of the discussions of the logarithmic integral I have seen take the integral from $2$ rather than from $0$, how do you treat what looks like a $- \mathrm {Li}(0)$ term? -- How do you actually get the $- i \pi$ term. I would guess it's from integrating around the half-circle above $u = 1$ in a clockwise direction. But I have tried parametrization with $u = r e^{i \theta}$. Maybe this is something I should know from complex analysis. Thanks very much.","I would appreciate help understanding a relation in Edwards's ""Riemann's Zeta Function."" On page 30 he has: $$\int_{C^{+}} \frac{t^{\beta - 1}}{\log t}dt = \int_{0}^{x^{\beta}}\frac{du}{\log u}= \mathrm {Li} (x^{\beta}) - i\pi$$ He states for $\beta$ positive and real, change variables $u = t^{\beta}$ which implies $\log t = \log u/\beta$ and $dt/t = du/u \beta$. Here $C^{+}$ is a path which is a line segment from $0$ to $1 - \epsilon$ and passes over the singularity at $u = 1$ in a semi-circle in the upper half-plane and continues in a line segment from $1 + \epsilon$ to $1$. I would appreciate help with two aspects: -- Since most of the discussions of the logarithmic integral I have seen take the integral from $2$ rather than from $0$, how do you treat what looks like a $- \mathrm {Li}(0)$ term? -- How do you actually get the $- i \pi$ term. I would guess it's from integrating around the half-circle above $u = 1$ in a clockwise direction. But I have tried parametrization with $u = r e^{i \theta}$. Maybe this is something I should know from complex analysis. Thanks very much.",,['complex-analysis']
47,"Are $\mathbb{C}\backslash[0,1]$ and $\mathbb{C}\backslash(\cup_{n\in\mathbb{N}_{>0}}\{t \cdot \exp(2 \pi i /n):t\in[0,1/n]\})$ biholomorphic?",Are  and  biholomorphic?,"\mathbb{C}\backslash[0,1] \mathbb{C}\backslash(\cup_{n\in\mathbb{N}_{>0}}\{t \cdot \exp(2 \pi i /n):t\in[0,1/n]\})","Are $\mathbb{C}\backslash[0,1]$ and $\mathbb{C}\backslash \left(\bigcup\limits_{n\in\mathbb{N}_{>0}}\{t \cdot \exp(2 \pi i /n):t\in[0,1/n]\} \right)$ biholomorphic? A friend told me, they are biholomorphic, but he didn't know the map. Could you help me? In my opinion they are not biholomorphic, because the stuff we are deleting at the second is the harmonic series, if I summ the length of the Intervals. Does it work, if we replace $1/n$ above with $1/n^2$?","Are $\mathbb{C}\backslash[0,1]$ and $\mathbb{C}\backslash \left(\bigcup\limits_{n\in\mathbb{N}_{>0}}\{t \cdot \exp(2 \pi i /n):t\in[0,1/n]\} \right)$ biholomorphic? A friend told me, they are biholomorphic, but he didn't know the map. Could you help me? In my opinion they are not biholomorphic, because the stuff we are deleting at the second is the harmonic series, if I summ the length of the Intervals. Does it work, if we replace $1/n$ above with $1/n^2$?",,['complex-analysis']
48,Residues at poles,Residues at poles,,"What is the residue of $$f(x)=\frac{1}{(x^2+1)^a}$$ at $x^2=\pm i$, where $0<a<1$ ? My intuition tells me that there must be a non-zero residue, but my attempts to compute tells me the residue is $0$. How can this be so when $x^2+1=0$ when $x=\pm i$ ?","What is the residue of $$f(x)=\frac{1}{(x^2+1)^a}$$ at $x^2=\pm i$, where $0<a<1$ ? My intuition tells me that there must be a non-zero residue, but my attempts to compute tells me the residue is $0$. How can this be so when $x^2+1=0$ when $x=\pm i$ ?",,"['complex-analysis', 'residue-calculus']"
49,Generalizing a theorem about indentations around simple poles,Generalizing a theorem about indentations around simple poles,,"Assume the function $f(z)$ has a simple pole at $z_{0}$. There is a theorem that states that if $C_{r}$ is an arc of the circle $|z-z_{0}| = r$ of angle $\alpha$, then  $$\lim_{r \to 0} \int_{C_{r}} f(z) \, dz = i \alpha \,  \text{Res}[f,z_{0}].$$ But what if $z_{0}$ is a pole of higher order? Can we say anything definitive about $ \lim_{r \to 0} \int_{C_{r}} f(z) \, dz $?","Assume the function $f(z)$ has a simple pole at $z_{0}$. There is a theorem that states that if $C_{r}$ is an arc of the circle $|z-z_{0}| = r$ of angle $\alpha$, then  $$\lim_{r \to 0} \int_{C_{r}} f(z) \, dz = i \alpha \,  \text{Res}[f,z_{0}].$$ But what if $z_{0}$ is a pole of higher order? Can we say anything definitive about $ \lim_{r \to 0} \int_{C_{r}} f(z) \, dz $?",,"['complex-analysis', 'contour-integration']"
50,The real part of $z^n$,The real part of,z^n,"Prove that $${\displaystyle\lim \limits_{n \to +\infty}{|r^ncos(nθ)|}}=+\infty,$$ where  $n$ is integer, $r>1$, $θ/π$ is irrational. I got this problem from here $1+x+\ldots+x^n$ perfect square , I think it's true for the general situation. PS: The original problem is to prove  $${\displaystyle\lim \limits_{n \to +\infty}{|z^n+\overline{z}^n|}}=+\infty,$$ where $n$ is integer, $z=x+yi,\overline{z}=x-yi,x>y>0,x^2+y^2>1,i=\sqrt{-1}.$ But according to the answer given by @mrf, this is not true when $y/x=tan(π/8)$,so I add the condition that $θ/π$ is irrational. Thanks in advance!","Prove that $${\displaystyle\lim \limits_{n \to +\infty}{|r^ncos(nθ)|}}=+\infty,$$ where  $n$ is integer, $r>1$, $θ/π$ is irrational. I got this problem from here $1+x+\ldots+x^n$ perfect square , I think it's true for the general situation. PS: The original problem is to prove  $${\displaystyle\lim \limits_{n \to +\infty}{|z^n+\overline{z}^n|}}=+\infty,$$ where $n$ is integer, $z=x+yi,\overline{z}=x-yi,x>y>0,x^2+y^2>1,i=\sqrt{-1}.$ But according to the answer given by @mrf, this is not true when $y/x=tan(π/8)$,so I add the condition that $θ/π$ is irrational. Thanks in advance!",,"['complex-analysis', 'diophantine-approximation']"
51,Residue of $p.v.\int_{-\infty}^{\infty}\frac{e^{2x}}{\cosh(\pi x)}dx=\text{sec}1$,Residue of,p.v.\int_{-\infty}^{\infty}\frac{e^{2x}}{\cosh(\pi x)}dx=\text{sec}1,"Show that $$p.v.\int_{-\infty}^{\infty}\frac{e^{2x}}{\cosh(\pi x)}dx=\text{sec}1$$ by integrating $\frac{e^{2z}}{\cosh(\pi z)}$ around   rectangles with vertices at $z=\pm p,p+i,-p+i.$ I asked this similar question, and was recommended this link stackexchange , but the answer provided is confusing. I am not sure how they got those vertices, but with those vertices I got the parameterization: $\begin{cases} \Gamma_1 = t, & -p\leq t\leq p \\\\ \Gamma_2= p+it, &0\leq t \leq 1 \\\\ \Gamma_3 = i-t, & -p\leq t\leq p \\\\ \Gamma_4=i(1-t)-p, & 0\leq t\leq 1. \end{cases}$ Thus I have $\Gamma_p =\Gamma_1 +\Gamma_2+\Gamma_3+\Gamma_4  .$ $f(z)=\frac{e^{2z}}{\cosh(\pi z)} = \frac{2e^{z(2+i\pi)}}{e^{2i\pi z}+1}$, where the denominator has a $\text{pole}=(2n+1)\frac{1}{2}$. And this is as far as I can get.","Show that $$p.v.\int_{-\infty}^{\infty}\frac{e^{2x}}{\cosh(\pi x)}dx=\text{sec}1$$ by integrating $\frac{e^{2z}}{\cosh(\pi z)}$ around   rectangles with vertices at $z=\pm p,p+i,-p+i.$ I asked this similar question, and was recommended this link stackexchange , but the answer provided is confusing. I am not sure how they got those vertices, but with those vertices I got the parameterization: $\begin{cases} \Gamma_1 = t, & -p\leq t\leq p \\\\ \Gamma_2= p+it, &0\leq t \leq 1 \\\\ \Gamma_3 = i-t, & -p\leq t\leq p \\\\ \Gamma_4=i(1-t)-p, & 0\leq t\leq 1. \end{cases}$ Thus I have $\Gamma_p =\Gamma_1 +\Gamma_2+\Gamma_3+\Gamma_4  .$ $f(z)=\frac{e^{2z}}{\cosh(\pi z)} = \frac{2e^{z(2+i\pi)}}{e^{2i\pi z}+1}$, where the denominator has a $\text{pole}=(2n+1)\frac{1}{2}$. And this is as far as I can get.",,"['complex-analysis', 'contour-integration']"
52,Schwarz Reflection Principle -- Mapping across horizontal lines,Schwarz Reflection Principle -- Mapping across horizontal lines,,"I am stuck on the following problem: Suppose an entire function maps two horizontal lines onto two other horizontal lines. Prove that its derivative is periodic. The author supplies a hint: Assume $f = u+iv$ maps the lines $y=y_1$ and $y=y_2$ onto $v=v_1$ and $v=v_2$ with $y_2-y_1 = c$ and $v_2-v_1 = d$. Show then that $f(z+2ci)+f(z)+2di$ for all $z$. I am trying to apply the Schwarz reflection principle to solve this problem. What I've done so far: If we let $\gamma$ be the analytic arc given by the first line, $x+iy_1$. Then, the reflection of $x+iy_2$ over $\gamma$ is $x+i(y_1-c)$, or $$w = \gamma(x+ic) = x+i(y_1+c) = x+iy_2 \\ w^* = \gamma(x-ic) = x+i(y_1-c).$$ Now, what we want is that $f(z+2ci) = f(z)+2di$. Take $z = w^*$, so $z+2ci = w$. Then, we have $f(z+2ci) = f(w) = f(w^*) + 2di$. Then, we need to compute $f(w^*)$ and show that it is equal to the reflection of the image of $w$ under $f$ over $\lambda := f(\gamma) = u+iv_1$. But I'm stuck on where to go from here. Is this even the right approach? I'm taking it for a specific $z$... clearly this can't work for all $z$...","I am stuck on the following problem: Suppose an entire function maps two horizontal lines onto two other horizontal lines. Prove that its derivative is periodic. The author supplies a hint: Assume $f = u+iv$ maps the lines $y=y_1$ and $y=y_2$ onto $v=v_1$ and $v=v_2$ with $y_2-y_1 = c$ and $v_2-v_1 = d$. Show then that $f(z+2ci)+f(z)+2di$ for all $z$. I am trying to apply the Schwarz reflection principle to solve this problem. What I've done so far: If we let $\gamma$ be the analytic arc given by the first line, $x+iy_1$. Then, the reflection of $x+iy_2$ over $\gamma$ is $x+i(y_1-c)$, or $$w = \gamma(x+ic) = x+i(y_1+c) = x+iy_2 \\ w^* = \gamma(x-ic) = x+i(y_1-c).$$ Now, what we want is that $f(z+2ci) = f(z)+2di$. Take $z = w^*$, so $z+2ci = w$. Then, we have $f(z+2ci) = f(w) = f(w^*) + 2di$. Then, we need to compute $f(w^*)$ and show that it is equal to the reflection of the image of $w$ under $f$ over $\lambda := f(\gamma) = u+iv_1$. But I'm stuck on where to go from here. Is this even the right approach? I'm taking it for a specific $z$... clearly this can't work for all $z$...",,['complex-analysis']
53,Prove that $\Gamma (-n+x)=\frac{(-1)^n}{n!}\left [ \frac{1}{x}-\gamma +\sum_{k=1}^{n}k^{-1}+O(x) \right ]$,Prove that,\Gamma (-n+x)=\frac{(-1)^n}{n!}\left [ \frac{1}{x}-\gamma +\sum_{k=1}^{n}k^{-1}+O(x) \right ],Prove that $\Gamma (-n+x)=\frac{(-1)^n}{n!}\left [ \frac{1}{x}-\gamma +\sum_{k=1}^{n}k^{-1}+O(x) \right ]$ I don't know how to do this ? Note that $\gamma $ is the Euler-Mascheroni constant,Prove that $\Gamma (-n+x)=\frac{(-1)^n}{n!}\left [ \frac{1}{x}-\gamma +\sum_{k=1}^{n}k^{-1}+O(x) \right ]$ I don't know how to do this ? Note that $\gamma $ is the Euler-Mascheroni constant,,"['real-analysis', 'complex-analysis', 'special-functions', 'gamma-function']"
54,A qualifying exam problem involving Schwarz lemma,A qualifying exam problem involving Schwarz lemma,,"This is a problem in the book ""Berkeley Problems in Mathematics"", which I think the solution given is wrong, can someone help? The following problem appeared in Spring 1991. Let the function $f$ be analytic in the unit disc, with $|f(z)|\leqslant 1$ and $f(0)=0$ . Assume that there is a number $r$ in $(0,1)$ such that $f(r)=f(-r)=0$ . Prove that $$|f(z)|\leqslant |z|\left| \frac{z^2-r^2}{1-r^2z^2}\right|.$$","This is a problem in the book ""Berkeley Problems in Mathematics"", which I think the solution given is wrong, can someone help? The following problem appeared in Spring 1991. Let the function be analytic in the unit disc, with and . Assume that there is a number in such that . Prove that","f |f(z)|\leqslant 1 f(0)=0 r (0,1) f(r)=f(-r)=0 |f(z)|\leqslant |z|\left| \frac{z^2-r^2}{1-r^2z^2}\right|.","['complex-analysis', 'inequality']"
55,Complex Exponential as a limit,Complex Exponential as a limit,,"I need some help with a homework problem. This is Ahlfors exercise 1 p. 178: Using Taylor's Theorem applied to a branch of $\log (1 + \frac{z}{n})$ prove that $\lim (1 + \frac{z}{n})^n=e^z$ uniformly on all compact sets. What I did: Taking the principal branch we have by Taylor's: $$\log \left(1 + \frac{z}{n}\right) = z -\frac{z^2}{n}+\frac{2z^3}{n^2}- \ldots +f_m(z)z^m$$ Where $f_m(z)$ is a analytic function in the region where the branch is defined, hence: $$1 + \frac{z}{n} = e^{z -\frac{z^2}{n}+\frac{2z^3}{n^2}- \ldots +f_m(z)z^m}$$ $$\Rightarrow \left(1 + \frac{z}{n}\right)^n = e^{n\left(z -\frac{z^2}{n}+\frac{2z^3}{n^2}- \ldots +f_m(z)z^m\right)}$$ then I got stuck, I really apreciate your help. Thanks.","I need some help with a homework problem. This is Ahlfors exercise 1 p. 178: Using Taylor's Theorem applied to a branch of $\log (1 + \frac{z}{n})$ prove that $\lim (1 + \frac{z}{n})^n=e^z$ uniformly on all compact sets. What I did: Taking the principal branch we have by Taylor's: $$\log \left(1 + \frac{z}{n}\right) = z -\frac{z^2}{n}+\frac{2z^3}{n^2}- \ldots +f_m(z)z^m$$ Where $f_m(z)$ is a analytic function in the region where the branch is defined, hence: $$1 + \frac{z}{n} = e^{z -\frac{z^2}{n}+\frac{2z^3}{n^2}- \ldots +f_m(z)z^m}$$ $$\Rightarrow \left(1 + \frac{z}{n}\right)^n = e^{n\left(z -\frac{z^2}{n}+\frac{2z^3}{n^2}- \ldots +f_m(z)z^m\right)}$$ then I got stuck, I really apreciate your help. Thanks.",,['complex-analysis']
56,Why there is no meromorphic function of degree $d=1$ on any compact Riemann surface of positive genus?,Why there is no meromorphic function of degree  on any compact Riemann surface of positive genus?,d=1,"We have the Riemann-Hurwitz formula: $$ 2g_X-2=d(2g_Y-2)+\sum_{x\in X}(e_x-1) $$ It is said that from this we can deduce that there is no meromorphic function of degree $d=1$ on any compact Riemann surface of positive genus. I wonder how? If I let $d=1$, I can get $$ 2(g_X-g_Y)=\sum_{x\in X}(e_x-1) $$ but what's next? Maybe I lack some knowledge about meromorphic function on Riemann surface, anyone can help?","We have the Riemann-Hurwitz formula: $$ 2g_X-2=d(2g_Y-2)+\sum_{x\in X}(e_x-1) $$ It is said that from this we can deduce that there is no meromorphic function of degree $d=1$ on any compact Riemann surface of positive genus. I wonder how? If I let $d=1$, I can get $$ 2(g_X-g_Y)=\sum_{x\in X}(e_x-1) $$ but what's next? Maybe I lack some knowledge about meromorphic function on Riemann surface, anyone can help?",,"['complex-analysis', 'riemann-surfaces']"
57,Is the zero set of a non zero real valued harmonic function discrete?,Is the zero set of a non zero real valued harmonic function discrete?,,"It is a basic fact that the zero set of a non zero holomorphic function defined on a open set $A$ is discrete. By a result in Rudin's textbook on ""Real and Complex Analysis"", we know that any real valued harmonic function $u$ is locally the real part of some holomorphic function, so I ask the following question: Is the zero set $Z(u)$ of a non zero real valued harmonic function $u$ defined on open set $A\subset \mathbb{C}$ discrete? Note that if $u$ vanishes on a nonempty open set $O\subset A$, then write $f=u+iv$ to be the holomorphic function, then Cauchy-Riemman's theorem implies that $v=0$ on $O$, so $f=0$ on $O$, then $f=0$ on $A$.","It is a basic fact that the zero set of a non zero holomorphic function defined on a open set $A$ is discrete. By a result in Rudin's textbook on ""Real and Complex Analysis"", we know that any real valued harmonic function $u$ is locally the real part of some holomorphic function, so I ask the following question: Is the zero set $Z(u)$ of a non zero real valued harmonic function $u$ defined on open set $A\subset \mathbb{C}$ discrete? Note that if $u$ vanishes on a nonempty open set $O\subset A$, then write $f=u+iv$ to be the holomorphic function, then Cauchy-Riemman's theorem implies that $v=0$ on $O$, so $f=0$ on $O$, then $f=0$ on $A$.",,"['complex-analysis', 'analysis', 'harmonic-analysis']"
58,Finding a conformal map of slit disk on to unit disk,Finding a conformal map of slit disk on to unit disk,,"I am trying to find a conformal map of  slit unit disk (slit in negative real axis) i.e $${{z: |z|<1, z\notin (-1,0]}}$$ on to the unit disk that takes $\sqrt2 -1 $ to $0$. This is what I think, I can see $\sqrt{z} $ taking the slit disk to disk ( half disk) in the right half plane, and then rotating counterclockwise gives the disk in the upper half plane and the mapping $(\frac {1-z}{1+z} )^2$ maps to the upper half plane and the map $\frac {z-i}{z+i}$ maps to open unit disk. I tried to compose and get the image of $\sqrt2 -1 $ under this composition. I am getting some frustrating crap. If I knew that this $\sqrt2 -1 $ gets mapped to some $\alpha$ then I would compose the above function (composition function) with the map $(\frac {z-\alpha}{1-\bar\alpha z} )$ to get the image of $\sqrt2 -1 $ as $0$. I also think this map is not unique. So the question is if my work  correct? If not what am I doing wrong? Can someone give me the explicit formula for this. Thanks in advance.","I am trying to find a conformal map of  slit unit disk (slit in negative real axis) i.e $${{z: |z|<1, z\notin (-1,0]}}$$ on to the unit disk that takes $\sqrt2 -1 $ to $0$. This is what I think, I can see $\sqrt{z} $ taking the slit disk to disk ( half disk) in the right half plane, and then rotating counterclockwise gives the disk in the upper half plane and the mapping $(\frac {1-z}{1+z} )^2$ maps to the upper half plane and the map $\frac {z-i}{z+i}$ maps to open unit disk. I tried to compose and get the image of $\sqrt2 -1 $ under this composition. I am getting some frustrating crap. If I knew that this $\sqrt2 -1 $ gets mapped to some $\alpha$ then I would compose the above function (composition function) with the map $(\frac {z-\alpha}{1-\bar\alpha z} )$ to get the image of $\sqrt2 -1 $ as $0$. I also think this map is not unique. So the question is if my work  correct? If not what am I doing wrong? Can someone give me the explicit formula for this. Thanks in advance.",,"['complex-analysis', 'conformal-geometry']"
59,What is the maximum value of $|f(z)|$ on the unit disc $D=\{z \in \mathbb C:|z|\leq 1\}$?,What is the maximum value of  on the unit disc ?,|f(z)| D=\{z \in \mathbb C:|z|\leq 1\},"I am thinking about the following problem: Let $f(z)=2z^2-1.$Then what is  the maximum value of $|f(z)|$ on the unit disc $D=\{z \in \mathbb C:|z|\leq 1\}$ ? I guess i have to use the maximum modulus principle.But  i also notice that $|f(z)|=|2z^2-1|\leq 2|z|^2+1\leq 2+1=3.$  So, is $3$  the maximum value of $|f(z)|?$ Can someone point me in the right direction? Thanks in advance for your time.","I am thinking about the following problem: Let $f(z)=2z^2-1.$Then what is  the maximum value of $|f(z)|$ on the unit disc $D=\{z \in \mathbb C:|z|\leq 1\}$ ? I guess i have to use the maximum modulus principle.But  i also notice that $|f(z)|=|2z^2-1|\leq 2|z|^2+1\leq 2+1=3.$  So, is $3$  the maximum value of $|f(z)|?$ Can someone point me in the right direction? Thanks in advance for your time.",,[]
60,Schwarz Lemma Extension,Schwarz Lemma Extension,,"Let $f: \Omega \rightarrow \Omega$ be holomorphic where $\Omega \subset \mathbb{C}$ is a bounded region containing 0.   If $f(0)=0$ and $f'(0)=1$, does $f(z)=z$? This is true if $\Omega$ is a disk centered at 0 but does it hold if $D$ is only bounded?","Let $f: \Omega \rightarrow \Omega$ be holomorphic where $\Omega \subset \mathbb{C}$ is a bounded region containing 0.   If $f(0)=0$ and $f'(0)=1$, does $f(z)=z$? This is true if $\Omega$ is a disk centered at 0 but does it hold if $D$ is only bounded?",,['complex-analysis']
61,Elliptic functions and (meromorphic) simply periodic functions.,Elliptic functions and (meromorphic) simply periodic functions.,,"Let be $f:\mathbb C\rightarrow\overline {\mathbb C}$ a meromorphic function. The set of periods $\Omega_f$ is a discrete (additive) group and we have one of these possibilities: i) $\Omega_f= \{0\}$ ii) $\Omega_f= \mathbb Z\omega$ iii) $\Omega_f= \mathbb Z\omega_1+\mathbb Z\omega_2$ In the case iii) we say that $f$ is an elliptic function and we now that the foundamental regions are compact subset of $\mathbb C$ (for example foundamental parallelograms). Elliptic fuctions, respect a fixed group of periodicities $\Omega_f=\Lambda$, form a field $E(\Lambda)$ and one can prove that $E(\Lambda)=\mathbb C(\wp,\wp')$. Now I have not found in literature similar results for the case ii) of meromorphic simply periodic functions. In this case foudamental regions are not compact sets and, fixed the group $\Omega_f$, simply periodic functions respect $\Omega_f$ form a field. I ask if this field is in fact $\mathbb C\big(e^\frac{2\pi iz}{\omega}\big)$; moreover what is the relation beethween the meromorphic functions: $$\varepsilon_k=\sum_{n\in\mathbb Z}(z-n)^{-k}$$ and the field of simply periodic funcion, where $\Omega_f=\mathbb Z$?","Let be $f:\mathbb C\rightarrow\overline {\mathbb C}$ a meromorphic function. The set of periods $\Omega_f$ is a discrete (additive) group and we have one of these possibilities: i) $\Omega_f= \{0\}$ ii) $\Omega_f= \mathbb Z\omega$ iii) $\Omega_f= \mathbb Z\omega_1+\mathbb Z\omega_2$ In the case iii) we say that $f$ is an elliptic function and we now that the foundamental regions are compact subset of $\mathbb C$ (for example foundamental parallelograms). Elliptic fuctions, respect a fixed group of periodicities $\Omega_f=\Lambda$, form a field $E(\Lambda)$ and one can prove that $E(\Lambda)=\mathbb C(\wp,\wp')$. Now I have not found in literature similar results for the case ii) of meromorphic simply periodic functions. In this case foudamental regions are not compact sets and, fixed the group $\Omega_f$, simply periodic functions respect $\Omega_f$ form a field. I ask if this field is in fact $\mathbb C\big(e^\frac{2\pi iz}{\omega}\big)$; moreover what is the relation beethween the meromorphic functions: $$\varepsilon_k=\sum_{n\in\mathbb Z}(z-n)^{-k}$$ and the field of simply periodic funcion, where $\Omega_f=\mathbb Z$?",,"['complex-analysis', 'periodic-functions', 'elliptic-functions']"
62,Graphical representation of complex functions,Graphical representation of complex functions,,"Which software (preferably: free/open source) can one use to graphically represent a complex function? I know that real functions can be easily represented with Octave or R; what can you recommend for complex functions? Thanks in advance, Lucian","Which software (preferably: free/open source) can one use to graphically represent a complex function? I know that real functions can be easily represented with Octave or R; what can you recommend for complex functions? Thanks in advance, Lucian",,"['complex-analysis', 'math-software']"
63,Constructing a holomorphic function with some specific points zero/nonzero,Constructing a holomorphic function with some specific points zero/nonzero,,"Given $n \in \mathbb{Z}$, is it possible to construct a holomorphic function $f : \mathbb{C} \rightarrow \mathbb{C}$ such that $f(n) \neq 0$, but for any integer $m \neq n$ we have $f(m)=0$? This is actually a homework problem in algebra which I reduced to this statement (in case it is correct).","Given $n \in \mathbb{Z}$, is it possible to construct a holomorphic function $f : \mathbb{C} \rightarrow \mathbb{C}$ such that $f(n) \neq 0$, but for any integer $m \neq n$ we have $f(m)=0$? This is actually a homework problem in algebra which I reduced to this statement (in case it is correct).",,['complex-analysis']
64,Find and Classify Singularities,Find and Classify Singularities,,"Find and classify the singularities of the following functions in $\mathbb{C}$: $\frac{1}{z(e^{\frac{1}{z}}+1)}$ $\frac{1}{(z^2+1)(z-1)^2}-\frac{1}{4(z-i)}$ OK, so I think the first is the easier (perhaps). There's clearly an essential singularity at the origin caused by the exponential. However, I think there are also singularities where $e^{\frac{1}{z}}=-1$, which occurs when $z=\frac{1}{(2n+1) \pi}$ for $n \in \mathbb{Z}$, though I am not sure how to classify there. Help with that would be very appreciated. For the second, we can split it into $\frac{1}{4(z+i)}-\frac{1}{2(z-1)}+\frac{1}{2(z-1)^2}$, which makes the position of the poles clear; at $-i, 1$. Is it the case that the pole at $-i$ is simple, and the pole at $1$ is a double pole. That seems to be the case. Any help/verification would be very helpful. Thanks in advance.","Find and classify the singularities of the following functions in $\mathbb{C}$: $\frac{1}{z(e^{\frac{1}{z}}+1)}$ $\frac{1}{(z^2+1)(z-1)^2}-\frac{1}{4(z-i)}$ OK, so I think the first is the easier (perhaps). There's clearly an essential singularity at the origin caused by the exponential. However, I think there are also singularities where $e^{\frac{1}{z}}=-1$, which occurs when $z=\frac{1}{(2n+1) \pi}$ for $n \in \mathbb{Z}$, though I am not sure how to classify there. Help with that would be very appreciated. For the second, we can split it into $\frac{1}{4(z+i)}-\frac{1}{2(z-1)}+\frac{1}{2(z-1)^2}$, which makes the position of the poles clear; at $-i, 1$. Is it the case that the pole at $-i$ is simple, and the pole at $1$ is a double pole. That seems to be the case. Any help/verification would be very helpful. Thanks in advance.",,['complex-analysis']
65,Limit conditions of a subharmonic function imply that it is constant,Limit conditions of a subharmonic function imply that it is constant,,"Let $u$ be a subharmonic function on $\mathbb{C}$. Suppose that $$\limsup_{z\to \infty} \frac{u(z)}{\log|z|}=0$$ I'm trying to prove that this implies $u(z)$ is constant. I have a feeling that it may have to do with Hadamard's Three Circles Theorem and/or the maximum principle for sub/superharmonic functions, but I'm not getting anywhere.","Let $u$ be a subharmonic function on $\mathbb{C}$. Suppose that $$\limsup_{z\to \infty} \frac{u(z)}{\log|z|}=0$$ I'm trying to prove that this implies $u(z)$ is constant. I have a feeling that it may have to do with Hadamard's Three Circles Theorem and/or the maximum principle for sub/superharmonic functions, but I'm not getting anywhere.",,['complex-analysis']
66,Domination of complex-value polynomial by highest power.,Domination of complex-value polynomial by highest power.,,"The problem: Let $P(n)$ be a polynomial of degree $n$ . Let $$M(r):= \underset{|z|\le r}{\mbox{sup}} \hspace{2mm} \left|P(z)\right|.$$ I desire to establish that $$r\mapsto \frac{M(r)}{r^n}$$ for $r>0$ is non-increasing as a function of $r$ . At least I believe this to be true and necessary to conclude a long homework assignment :P. 1st attempt at solution I think it is reasonable to assume the polynomial has no constant term, for adding a constant term as far as I understand can only change the $M(r)$ term by a constant. So $P(z)$ can be taken to fix the origin. Then considering, say the holomorphic function, $$\frac{P(rz)}{M(r)}$$ the function should take the disk to the disk, so we can apply Schwartz's Lemma, and get the inequality: $$\left|\frac{P(rz)}{M(r)}\right|\le |z|$$ From here I would hope to pick a nice $z$ in the disk to establish something useful... I'm at a loss. 2nd attempt at solution I did start thinking, establishing an inequality between expressions doesn't quite get me that an expression is non-increasing. What would get me there is taking derivative. I think it's clear $M(r)$ is smooth. So we can differentiate the function in question (with respect to $r$ ) and get that the derivative is: $$\frac{M'(r)r^n - n r^{n-1}M(r)}{r^{2n}}=\frac{M'(r)r - n M(r)}{r^{n+1}}$$ We want that this derivative is $\le 0$ . That is, that $$M'(r) \le \frac{n M(r)}{r}$$ The RHS sort of makes me think of what $M'(r)$ would look like. $P'(z)$ would of course be almost $\frac{n P(z)}{z}$ , except of course for the constant term of $P(z)$ which disappears when differentiating.","The problem: Let be a polynomial of degree . Let I desire to establish that for is non-increasing as a function of . At least I believe this to be true and necessary to conclude a long homework assignment :P. 1st attempt at solution I think it is reasonable to assume the polynomial has no constant term, for adding a constant term as far as I understand can only change the term by a constant. So can be taken to fix the origin. Then considering, say the holomorphic function, the function should take the disk to the disk, so we can apply Schwartz's Lemma, and get the inequality: From here I would hope to pick a nice in the disk to establish something useful... I'm at a loss. 2nd attempt at solution I did start thinking, establishing an inequality between expressions doesn't quite get me that an expression is non-increasing. What would get me there is taking derivative. I think it's clear is smooth. So we can differentiate the function in question (with respect to ) and get that the derivative is: We want that this derivative is . That is, that The RHS sort of makes me think of what would look like. would of course be almost , except of course for the constant term of which disappears when differentiating.",P(n) n M(r):= \underset{|z|\le r}{\mbox{sup}} \hspace{2mm} \left|P(z)\right|. r\mapsto \frac{M(r)}{r^n} r>0 r M(r) P(z) \frac{P(rz)}{M(r)} \left|\frac{P(rz)}{M(r)}\right|\le |z| z M(r) r \frac{M'(r)r^n - n r^{n-1}M(r)}{r^{2n}}=\frac{M'(r)r - n M(r)}{r^{n+1}} \le 0 M'(r) \le \frac{n M(r)}{r} M'(r) P'(z) \frac{n P(z)}{z} P(z),['complex-analysis']
67,Does a branch of a square root determine a branch of a logarithm?,Does a branch of a square root determine a branch of a logarithm?,,"Suppose I have a branch of the logarithm, that is, a continuous function $L(z)$ on some region $\Omega$ such that $e^{L(z)} = z$. We see that this defines a branch for the square root function on $\Omega$, via $\sqrt{z} = \exp(1/2 L(z))$, since $$(\exp(1/2 L(z))^2 = \exp(L(z)) = z$$ I am wondering if a sort of converse of this holds. Suppose on the other hand, we have a branch for the square root, i.e. some continuous function $R(z)$ on $\Omega$ such that $R(z)^2 = z$. Is there some way to get a branch of the logarithm from $R(z)$? If so, does this generalize (i.e. what branches for multi-valued functions will determine a branch of the logarithm)?","Suppose I have a branch of the logarithm, that is, a continuous function $L(z)$ on some region $\Omega$ such that $e^{L(z)} = z$. We see that this defines a branch for the square root function on $\Omega$, via $\sqrt{z} = \exp(1/2 L(z))$, since $$(\exp(1/2 L(z))^2 = \exp(L(z)) = z$$ I am wondering if a sort of converse of this holds. Suppose on the other hand, we have a branch for the square root, i.e. some continuous function $R(z)$ on $\Omega$ such that $R(z)^2 = z$. Is there some way to get a branch of the logarithm from $R(z)$? If so, does this generalize (i.e. what branches for multi-valued functions will determine a branch of the logarithm)?",,['complex-analysis']
68,The Integral of a Harmonic Function,The Integral of a Harmonic Function,,"Show that: $$\frac{1}{2\pi}\int_0^{2\pi}\log|re^{i\theta} - z_0|d\theta = \begin{cases} \log|z_0| & if & |z_0| < r \\  \log|r| & if & |z_0| > r \end{cases}.$$ I know $\log|z|$ is a harmonic function in the slit plane since it is the real part of the analytic function $\log(z)$ on the slit plane.  What I don't understand is that for $|z_0| > r$ this integral is exactly the average of a harmonic function along the boundary of a disk upon which $\log|z|$ is harmonic, thus by the Mean-Value Property it should be equal to $\log|z_0|$, yet it's supposed to be $\log|r|$.  What is going on?","Show that: $$\frac{1}{2\pi}\int_0^{2\pi}\log|re^{i\theta} - z_0|d\theta = \begin{cases} \log|z_0| & if & |z_0| < r \\  \log|r| & if & |z_0| > r \end{cases}.$$ I know $\log|z|$ is a harmonic function in the slit plane since it is the real part of the analytic function $\log(z)$ on the slit plane.  What I don't understand is that for $|z_0| > r$ this integral is exactly the average of a harmonic function along the boundary of a disk upon which $\log|z|$ is harmonic, thus by the Mean-Value Property it should be equal to $\log|z_0|$, yet it's supposed to be $\log|r|$.  What is going on?",,['complex-analysis']
69,A more general case of the Laurent series expansion?,A more general case of the Laurent series expansion?,,"I was recently reading about Laurent series for complex functions. I'm curious about a seemingly similar situation that came up in my reading. Suppose $\Omega$ is a doubly connected region such that $\Omega^c$ (its complement) has two components $E_0$ and $E_1$. So if $f(z)$ is a complex, holomorphic function on $\Omega$, how can it be decomposed as $f=f_0(z)+f_1(z)$ where $f_0(z)$ is holomorphic outside $E_0$, and $f_1(z)$ is holomorphic outside $E_1$? Many thanks.","I was recently reading about Laurent series for complex functions. I'm curious about a seemingly similar situation that came up in my reading. Suppose $\Omega$ is a doubly connected region such that $\Omega^c$ (its complement) has two components $E_0$ and $E_1$. So if $f(z)$ is a complex, holomorphic function on $\Omega$, how can it be decomposed as $f=f_0(z)+f_1(z)$ where $f_0(z)$ is holomorphic outside $E_0$, and $f_1(z)$ is holomorphic outside $E_1$? Many thanks.",,['complex-analysis']
70,Complex Analysis: Liouville's theorem Proof,Complex Analysis: Liouville's theorem Proof,,"I'm being asked to find an alternate proof for the one commonly given for Liouville's Theorem in complex analysis by evaluating the following given an entire function $f$, and two distinct, arbitrary complex numbers $a$ and $b$: $$\lim_{R\to\infty}\oint_{|z|=R} {f(z)\over(z-a)(z-b)} dz $$ What I've done so far is I've tried to apply the cauchy integral formula, since there are two singularities in the integrand, which will fall in the contour for $R$ approaches infinity.  So I got: $$2{\pi}i\biggl({f(a)\over a-b}+{f(b)\over b-a}\biggr)$$ Which equals $$2{\pi}i\biggl({f(a)-f(b)\over a-b}\biggr)$$ and I got stuck here I don't quite see how I can get from this, plus $f(z)$ being bounded and analytic, that can tell me that $f(z)$ is a constant function.  Ugh, the more well known proof is so much simpler -.- Any suggestions/hints?  Am I at least on the right track?","I'm being asked to find an alternate proof for the one commonly given for Liouville's Theorem in complex analysis by evaluating the following given an entire function $f$, and two distinct, arbitrary complex numbers $a$ and $b$: $$\lim_{R\to\infty}\oint_{|z|=R} {f(z)\over(z-a)(z-b)} dz $$ What I've done so far is I've tried to apply the cauchy integral formula, since there are two singularities in the integrand, which will fall in the contour for $R$ approaches infinity.  So I got: $$2{\pi}i\biggl({f(a)\over a-b}+{f(b)\over b-a}\biggr)$$ Which equals $$2{\pi}i\biggl({f(a)-f(b)\over a-b}\biggr)$$ and I got stuck here I don't quite see how I can get from this, plus $f(z)$ being bounded and analytic, that can tell me that $f(z)$ is a constant function.  Ugh, the more well known proof is so much simpler -.- Any suggestions/hints?  Am I at least on the right track?",,"['complex-analysis', 'alternative-proof']"
71,Inequality relating diameter of the image of a holomorphic function on the unit disk to the derivative at 0. [duplicate],Inequality relating diameter of the image of a holomorphic function on the unit disk to the derivative at 0. [duplicate],,"This question already has an answer here : Closed 11 years ago . Possible Duplicate: First derivative bounded by supremum of difference of values in disc Let $f$ be holomorphic in the disk $D_1(0)$ and let $d=\operatorname{diam}(f(D_1(0))$. I want to show that $$2|f'(0)|\leq d$$ I have the following: Let $\gamma$ be the circle of radius $r<1$ traversed counter-clockwise. Let $-\gamma$ be the same circle traversed clockwise. By Cauchy's integral formula for derivatives, we have that $$f'(0)=\frac{1}{2\pi i}\int_\gamma \frac{f(\theta)}{\theta^2}d\theta=-\frac{1}{2\pi i}\int_{-\gamma}\frac{f(\theta)}{\theta^2}d\theta=-\frac{1}{2\pi i}\int_\gamma \frac{f(-\theta)}{\theta^2}d\theta$$ So $$\begin{align} 2f'(0) &=\frac{1}{2\pi i}\int_\gamma \frac{f(\theta)-f(-\theta)}{\theta^2} \; d\theta\\ \end{align}$$ and by the standard estimate $$\begin{align} 2|f'(0)| &=|\frac{1}{2\pi i}\int_\gamma \frac{f(\theta)-f(-\theta)}{\theta^2}d\theta|\\ &\leq \frac{1}{2\pi}\max_{\theta \in \gamma}\{|\frac{f(\theta)-f(-\theta)}{\theta^2}|\}2\pi r\\ &\leq r\max_{\theta \in \gamma}\{|\frac{f(\theta)-f(-\theta)}{\theta^2}|\} \end{align}$$ which is almost what I want, but not quite. We haven't discussed the maximum modulus principle in class, so I can't use that. Any suggestions as to how to finish this up? Thanks.","This question already has an answer here : Closed 11 years ago . Possible Duplicate: First derivative bounded by supremum of difference of values in disc Let $f$ be holomorphic in the disk $D_1(0)$ and let $d=\operatorname{diam}(f(D_1(0))$. I want to show that $$2|f'(0)|\leq d$$ I have the following: Let $\gamma$ be the circle of radius $r<1$ traversed counter-clockwise. Let $-\gamma$ be the same circle traversed clockwise. By Cauchy's integral formula for derivatives, we have that $$f'(0)=\frac{1}{2\pi i}\int_\gamma \frac{f(\theta)}{\theta^2}d\theta=-\frac{1}{2\pi i}\int_{-\gamma}\frac{f(\theta)}{\theta^2}d\theta=-\frac{1}{2\pi i}\int_\gamma \frac{f(-\theta)}{\theta^2}d\theta$$ So $$\begin{align} 2f'(0) &=\frac{1}{2\pi i}\int_\gamma \frac{f(\theta)-f(-\theta)}{\theta^2} \; d\theta\\ \end{align}$$ and by the standard estimate $$\begin{align} 2|f'(0)| &=|\frac{1}{2\pi i}\int_\gamma \frac{f(\theta)-f(-\theta)}{\theta^2}d\theta|\\ &\leq \frac{1}{2\pi}\max_{\theta \in \gamma}\{|\frac{f(\theta)-f(-\theta)}{\theta^2}|\}2\pi r\\ &\leq r\max_{\theta \in \gamma}\{|\frac{f(\theta)-f(-\theta)}{\theta^2}|\} \end{align}$$ which is almost what I want, but not quite. We haven't discussed the maximum modulus principle in class, so I can't use that. Any suggestions as to how to finish this up? Thanks.",,"['complex-analysis', 'inequality']"
72,Showing that $\sec z = \frac1{\cos z} = 1+ \sum\limits_{k=1}^{\infty} \frac{E_{2k}}{(2k)!}z^{2k}$,Showing that,\sec z = \frac1{\cos z} = 1+ \sum\limits_{k=1}^{\infty} \frac{E_{2k}}{(2k)!}z^{2k},"Show that there are complex numbers $E_2,E_4,E_6,\dotsc$ such that $\sec z = \frac{1}{\cos z} = 1+ \sum\limits_{k=1}^{\infty} \frac{E_{2k}}{(2k)!}z^{2k}$ in a neighborhood of $0$ . What is the radius of convergence? Show that: $E_{2n}-{2n\choose 2n-2} E_{2n-2} + {2n\choose 2n-4}E_{2n-4}+ \dotsb -(-1)^{n}{2n \choose 2}E_{2} + (-1)^{n} = 0$ . Compute $E_2, E_4$ and $E_6$ . Can you show me how to solve this problem? I am not able to do any of them.  Thanks. Edit: Ideas have been given for 1,2,4. Thank you.  What about item 3 ?","Show that there are complex numbers such that in a neighborhood of . What is the radius of convergence? Show that: . Compute and . Can you show me how to solve this problem? I am not able to do any of them.  Thanks. Edit: Ideas have been given for 1,2,4. Thank you.  What about item 3 ?","E_2,E_4,E_6,\dotsc \sec z = \frac{1}{\cos z} = 1+ \sum\limits_{k=1}^{\infty} \frac{E_{2k}}{(2k)!}z^{2k} 0 E_{2n}-{2n\choose 2n-2} E_{2n-2} + {2n\choose 2n-4}E_{2n-4}+ \dotsb -(-1)^{n}{2n \choose 2}E_{2} + (-1)^{n} = 0 E_2, E_4 E_6","['complex-analysis', 'trigonometry']"
73,Is the derivative of a modular function a modular function,Is the derivative of a modular function a modular function,,Fix a positive integer $n$. Let $f:\mathbf{H}\longrightarrow \mathbf{C}$ be a modular function with respect to the group $\Gamma(n)$. Is the derivative $$\frac{df}{d\tau}:\mathbf{H}\longrightarrow \mathbf{C}$$ also a modular function with respect to $\Gamma(n)$? I think it's clear that $df/d\tau$ is meromorphic on $\mathbf{H}$ and that it is meromorphic at the cusp. I just don't know why it should be modular with respect to $\Gamma(n)$.,Fix a positive integer $n$. Let $f:\mathbf{H}\longrightarrow \mathbf{C}$ be a modular function with respect to the group $\Gamma(n)$. Is the derivative $$\frac{df}{d\tau}:\mathbf{H}\longrightarrow \mathbf{C}$$ also a modular function with respect to $\Gamma(n)$? I think it's clear that $df/d\tau$ is meromorphic on $\mathbf{H}$ and that it is meromorphic at the cusp. I just don't know why it should be modular with respect to $\Gamma(n)$.,,"['complex-analysis', 'riemann-surfaces', 'modular-forms']"
74,"If $|f(z)|\lt a|q(z)|$ for some $a\gt 0$, then $f=bq$ for some $b\in \mathbb C$ [duplicate]","If  for some , then  for some  [duplicate]",|f(z)|\lt a|q(z)| a\gt 0 f=bq b\in \mathbb C,"This question already has an answer here : Property of Entire Functions (1 answer) Closed 9 years ago . If $q\colon\mathbb{C}\to\mathbb{C}$ is a polynomial, $f\colon\mathbb{C}\to\mathbb{C}$ is analytic on all of $\mathbb{C}$, and if there exists $a\gt 0$ such that  $|f(z)| \lt  a|q(z)|$ for every $z\in \mathbb{C}$, then $f = bq$  for some $b\in \mathbb{C}$. Can an arbitrary analytic function (on all of $\mathbb{C}$) replace $q$?","This question already has an answer here : Property of Entire Functions (1 answer) Closed 9 years ago . If $q\colon\mathbb{C}\to\mathbb{C}$ is a polynomial, $f\colon\mathbb{C}\to\mathbb{C}$ is analytic on all of $\mathbb{C}$, and if there exists $a\gt 0$ such that  $|f(z)| \lt  a|q(z)|$ for every $z\in \mathbb{C}$, then $f = bq$  for some $b\in \mathbb{C}$. Can an arbitrary analytic function (on all of $\mathbb{C}$) replace $q$?",,['complex-analysis']
75,Fixed point iteration for analytic functions on the unit disc,Fixed point iteration for analytic functions on the unit disc,,"Suppose that $f(z)$ is complex analytic on $|z| \leq 1$ and satisfies $|f(z)| < 1$ for $|z|=1$. (a) Prove that the equation $f(z)=z$ has exactly one root (counting multiplicities) in $|z|<1$. (b) Prove that if $|z_0| \leq 1$, then the sequence $z_n$ defined recursively by $z_n= f(z_{n-1}) , n=1,2,...$, converges to the fixed point of $f$. I was able to prove (a) using Rouche's theorem, but (b) stumps me. I know that (b) is true for analytic fuctions such that $f(0)=0$ or $|f'(z)|<1$ on the disc, neither of which are necessarily true in general. The farthest I was able to get was $|f(z)-z^*|<\frac{1}{1-|z*|}|z-z^*|$, where $z^*$ is the fixed point of $f$, but $\frac{1}{1-|z^*|}>1$, so I don't think this helps me. Can someone please point me in the right direction?","Suppose that $f(z)$ is complex analytic on $|z| \leq 1$ and satisfies $|f(z)| < 1$ for $|z|=1$. (a) Prove that the equation $f(z)=z$ has exactly one root (counting multiplicities) in $|z|<1$. (b) Prove that if $|z_0| \leq 1$, then the sequence $z_n$ defined recursively by $z_n= f(z_{n-1}) , n=1,2,...$, converges to the fixed point of $f$. I was able to prove (a) using Rouche's theorem, but (b) stumps me. I know that (b) is true for analytic fuctions such that $f(0)=0$ or $|f'(z)|<1$ on the disc, neither of which are necessarily true in general. The farthest I was able to get was $|f(z)-z^*|<\frac{1}{1-|z*|}|z-z^*|$, where $z^*$ is the fixed point of $f$, but $\frac{1}{1-|z^*|}>1$, so I don't think this helps me. Can someone please point me in the right direction?",,"['complex-analysis', 'numerical-methods']"
76,Why are complex measures not allowed to attain $\infty$ while signed measures are?,Why are complex measures not allowed to attain  while signed measures are?,\infty,"I saw another question similar to this one but I'm not satisfied by answers. Here I changed the question to clearify the point I am interested in. I study Measure Theory for Real & Complex Analysis and I wonder why in the following setting \begin{equation} \mu: \mathcal{M} \rightarrow \mathbb{C} \end{equation} \begin{equation} \mu(E) = \mu_r(E) + i\mu_i(E) \end{equation} where $\mu$ is a complex measure and $\mu_r$ & $\mu_i$ are signed measure some writers (like Folland if I remember correctly) does not let $\mu$ to attain at most one of $\infty$ or $-\infty$ . In the general definition for signed measures we can let signed measures to attain at most one of the plus or negative $\infty$ . For example, is the following setting not meaningful or not sensible? \begin{equation} \mu: \mathcal{M} \rightarrow \mathbb{C}\cup \{\infty\} \end{equation} \begin{equation} \mu(E) = \mu_r(E) + i\mu_i(E) \end{equation} where $\mu_r$ & $\mu_i$ are signed measures that does not attain $-\infty$ , i.e. they are signed measures which attain values in $\mathbb{R} \cup \infty$ , and we defined $\mu(E) = \infty$ whenever $\mu_r = \infty$ or $\mu_i = \infty$ . Here I rely on following artihmetical definitions in a formal way: \begin{equation} a + i\infty = \infty = \infty + ai \end{equation} where $-\infty$ is not considered. EDIT: Typo in the last equation.","I saw another question similar to this one but I'm not satisfied by answers. Here I changed the question to clearify the point I am interested in. I study Measure Theory for Real & Complex Analysis and I wonder why in the following setting where is a complex measure and & are signed measure some writers (like Folland if I remember correctly) does not let to attain at most one of or . In the general definition for signed measures we can let signed measures to attain at most one of the plus or negative . For example, is the following setting not meaningful or not sensible? where & are signed measures that does not attain , i.e. they are signed measures which attain values in , and we defined whenever or . Here I rely on following artihmetical definitions in a formal way: where is not considered. EDIT: Typo in the last equation.",\begin{equation} \mu: \mathcal{M} \rightarrow \mathbb{C} \end{equation} \begin{equation} \mu(E) = \mu_r(E) + i\mu_i(E) \end{equation} \mu \mu_r \mu_i \mu \infty -\infty \infty \begin{equation} \mu: \mathcal{M} \rightarrow \mathbb{C}\cup \{\infty\} \end{equation} \begin{equation} \mu(E) = \mu_r(E) + i\mu_i(E) \end{equation} \mu_r \mu_i -\infty \mathbb{R} \cup \infty \mu(E) = \infty \mu_r = \infty \mu_i = \infty \begin{equation} a + i\infty = \infty = \infty + ai \end{equation} -\infty,"['real-analysis', 'complex-analysis', 'measure-theory', 'complex-integration', 'signed-measures']"
77,How to evaluate $ \displaystyle \int_0^\infty \frac {\sin x}{1+x^3}dx. $?,How to evaluate ?, \displaystyle \int_0^\infty \frac {\sin x}{1+x^3}dx. ,"I was wondering if we can use complex contour integration to evaluate the integral $$ \int_0^\infty \frac {\sin x}{1+x^3}dx. $$ Since the integrand is not even, we cannot extend the integration domain to $\mathbb R$ and use the upper semicircular contour $Re^{it}$ , $0\le t\le \pi$ . We cannot use the keyhole contour either, since the integral of $\frac{e^{iz}}{1+z^3}$ over the lower semicircle $Re^{it}$ , $\pi\le t\le 2\pi$ does not converge to $0$ as $R\to \infty$ . Using Wolframalpha to evaluate the above improper integral, it does not give a closed form answer. Therefore I was wondering if complex integration is not applicable in this case.","I was wondering if we can use complex contour integration to evaluate the integral Since the integrand is not even, we cannot extend the integration domain to and use the upper semicircular contour , . We cannot use the keyhole contour either, since the integral of over the lower semicircle , does not converge to as . Using Wolframalpha to evaluate the above improper integral, it does not give a closed form answer. Therefore I was wondering if complex integration is not applicable in this case.","
\int_0^\infty \frac {\sin x}{1+x^3}dx.
 \mathbb R Re^{it} 0\le t\le \pi \frac{e^{iz}}{1+z^3} Re^{it} \pi\le t\le 2\pi 0 R\to \infty","['calculus', 'complex-analysis', 'improper-integrals', 'complex-integration']"
78,Contour integral of modulus of a sequence of analytic function converges to zero implies the function converges to zero.,Contour integral of modulus of a sequence of analytic function converges to zero implies the function converges to zero.,,"Consider a sequence of function $\{f_n(z)\}_{n \geq 1}$ defined on complex space $z \in \mathbb{C},$ and assume for each $n$ , $f_n$ is analytic in $\{|z|<1 \}$ , and continuous on $\{ |z|\leq 1\},$ and the following property holds \begin{equation} \lim_{n \rightarrow \infty} \frac{1}{2\pi} \int_{0}^{2\pi} |f_n(e^{i\theta})| d \theta =0. \end{equation} I want to show that \begin{equation} \lim_{n \rightarrow \infty} \max_{|z| \leq 1} |f_{n}(z)| =0. \end{equation} My attempt is to use maximum modulus principle for analytic functions. If the statement is wrong, then there exists a subsequence ${f}_{n_k}$ and a positive constant $\epsilon_0$ such that $\max_{|z| \leq 1} |f_{n}(z)|=|f_n(z_n)| \geq \epsilon_0.$ Clearly $z_n \in \{ |z|=1 \}$ . I want to show that $\frac{1}{2\pi} \int_{0}^{2\pi} |f_{n_k}(e^{i\theta})| d \theta$ does not tend to $0$ , but I am stuck here. Can anyone give me some advice? $\textbf{Update}$ ：GEdgar has given a counterexample. Now I would like to prove that, for a given 0<r<1, we have \begin{equation} \lim_{n} \max_{|z| \leq r} \ | f_n(z) |=0. \end{equation}","Consider a sequence of function defined on complex space and assume for each , is analytic in , and continuous on and the following property holds I want to show that My attempt is to use maximum modulus principle for analytic functions. If the statement is wrong, then there exists a subsequence and a positive constant such that Clearly . I want to show that does not tend to , but I am stuck here. Can anyone give me some advice? ：GEdgar has given a counterexample. Now I would like to prove that, for a given 0<r<1, we have","\{f_n(z)\}_{n \geq 1} z \in \mathbb{C}, n f_n \{|z|<1 \} \{ |z|\leq 1\}, \begin{equation}
\lim_{n \rightarrow \infty} \frac{1}{2\pi} \int_{0}^{2\pi} |f_n(e^{i\theta})| d \theta =0.
\end{equation} \begin{equation}
\lim_{n \rightarrow \infty} \max_{|z| \leq 1} |f_{n}(z)| =0.
\end{equation} {f}_{n_k} \epsilon_0 \max_{|z| \leq 1} |f_{n}(z)|=|f_n(z_n)| \geq \epsilon_0. z_n \in \{ |z|=1 \} \frac{1}{2\pi} \int_{0}^{2\pi} |f_{n_k}(e^{i\theta})| d \theta 0 \textbf{Update} \begin{equation}
\lim_{n} \max_{|z| \leq r} \ | f_n(z) |=0.
\end{equation}","['complex-analysis', 'analysis']"
79,"Weierstrass Preparation Theorem, simple exercise","Weierstrass Preparation Theorem, simple exercise",,"I am working with a specific version of the Weierstrass preparation theorem, trying to understand it with an example. I'll cite the theorem before stating the question: Theorem If $f:U\subset \mathbb{C}^{n+1}\rightarrow \mathbb{C}$ is a holomorphic function in the variables $(z,w_1,\dots,w_n)$ such that $f(z,0,\dots,0)$ is not identically zero near $z=0$ , then there exist a holomorphic function $h:B \subset \mathbb{C}^{n+1}\rightarrow \mathbb{C}$ with $h(0,\dots,0)\neq 0$ , a Weierstrass polynomial of the form $$ p(z,w_1,\dots,w_n) = z^d + \alpha_1(w_1,\dots,w_n) z^{d-1} + \dots + \alpha_d(w_1,\dots,w_n) $$ where the coefficients are holomorphic functions in $(w_1,\dots,w_n)$ vanishing at the origin, such that locally near the origin in $\mathbb{C}^{n+1}$ we have $f=h\cdot p$ . The polynomial $p$ is unique. Question : I am trying to get the Weierstrass  polynomial for the following function $f:\mathbb{C}\rightarrow \mathbb{C}$ given by $$ f(z_1,z_2) = z_1^3z_2 + z_1 z_2 + z_1^2z_2² + z_2^2 + z_1 z_2^3 $$ Obviously $f(z_1,0)$ vanishes identically, so the variable that I need to work on is $z_2$ . By differentiating $f=h\cdot p$ with respect to $z_2$ I have been able to show that the degree $d$ is necessarily 2, i.e. $$ p(z_1,z_2) = z_2^2+\alpha(z_1)z_2 + \beta(z_1), $$ for holomorphic coefficients $\alpha,\beta$ vanishing at $z_1=0$ . However, I am stuck since I have too many degrees of freedom : $h,\alpha,\beta$ . How can I construct a method for finding this coefficients?","I am working with a specific version of the Weierstrass preparation theorem, trying to understand it with an example. I'll cite the theorem before stating the question: Theorem If is a holomorphic function in the variables such that is not identically zero near , then there exist a holomorphic function with , a Weierstrass polynomial of the form where the coefficients are holomorphic functions in vanishing at the origin, such that locally near the origin in we have . The polynomial is unique. Question : I am trying to get the Weierstrass  polynomial for the following function given by Obviously vanishes identically, so the variable that I need to work on is . By differentiating with respect to I have been able to show that the degree is necessarily 2, i.e. for holomorphic coefficients vanishing at . However, I am stuck since I have too many degrees of freedom : . How can I construct a method for finding this coefficients?","f:U\subset \mathbb{C}^{n+1}\rightarrow \mathbb{C} (z,w_1,\dots,w_n) f(z,0,\dots,0) z=0 h:B \subset \mathbb{C}^{n+1}\rightarrow \mathbb{C} h(0,\dots,0)\neq 0 
p(z,w_1,\dots,w_n) = z^d + \alpha_1(w_1,\dots,w_n) z^{d-1} + \dots + \alpha_d(w_1,\dots,w_n)
 (w_1,\dots,w_n) \mathbb{C}^{n+1} f=h\cdot p p f:\mathbb{C}\rightarrow \mathbb{C} 
f(z_1,z_2) = z_1^3z_2 + z_1 z_2 + z_1^2z_2² + z_2^2 + z_1 z_2^3
 f(z_1,0) z_2 f=h\cdot p z_2 d 
p(z_1,z_2) = z_2^2+\alpha(z_1)z_2 + \beta(z_1),
 \alpha,\beta z_1=0 h,\alpha,\beta","['complex-analysis', 'complex-numbers', 'several-complex-variables']"
80,Evaluating $\frac{1}{2\pi i}\int^{a+i\infty}_{a-i\infty}\frac{x^s}{s-\beta}ds$ using Feynman integration,Evaluating  using Feynman integration,\frac{1}{2\pi i}\int^{a+i\infty}_{a-i\infty}\frac{x^s}{s-\beta}ds,"I am trying to prove that $$ \frac{1}{2\pi i}\int^{a+i\infty}_{a-i\infty}\frac{x^s}{s-\beta}ds =\begin{cases} x^{\beta}, & x > 1 \\ 0, & 0 < x < 1 \\ \end{cases} $$ for $0<{\rm Re}(\beta)<a$ by using Feynman integration and solving a homogeneous second order differential equation respectively. Here is my attempt: \begin{align*} \frac{1}{2\pi i}\int^{a+i\infty}_{a-i\infty}\frac{x^s}{s}ds& =\frac{x^a}{2\pi}\int^{\infty}_{0}\frac{x^{it}(a-it)+x^{-it}(a+it)}{a^2+t^2}dt\\  & =\frac{x^a}{\pi}\left(\int^{\infty}_{0}\frac{\cos(\ln(x)ta)}{1+t^2}dt+\int^{\infty}_{0}\frac{t\sin(\ln(x)ta)}{1+t^2}dt\right).  \end{align*} \begin{align*} {\rm Re}(\oint_C\frac{x^{iza}}{1+z^2}dz)  & ={\rm Re}\left(\lim_{R \to \infty}\int^{R}_{-R}\frac{x^{iza}}{1+z^2}dz+\int_{\Gamma}\right) \\ & =\frac{\pi}{x^a}.\lim_{R \to \infty} \left| \int_{\Gamma} \right| \\ & \leqslant\lim_{R \to \infty} \frac{2}{R}\int^{\frac{\pi}{2}}_{0}\frac{x^{-2R\theta/\pi}}{1+(Re^{i\theta})^{-2}}d\theta \\ & =0. \end{align*} Therefore $$ \int^{\infty}_{0}\frac{\cos(\ln(x)ta)}{1+t^2}dt = \frac{\pi}{2x^a}. $$ Set $$ I(a):=\int_{R}\frac{\cos(\ln(x)ta)}{1+t^2}dt $$ so $$ I'(a)=\ln(x)(-{\rm sgn}(\ln(x))\pi+\int_{R}\frac{\sin(\ln(x)ta)}{t(1+t^2)}dt) $$ and $$ I''(a)-\ln^2(x)I(a) = 0. $$ Therefore $I(a)=c_1x^a+c_2x^{-a}$ for $$ c_1=\begin{cases} 0, & x > 1 \\ \pi, & 0 < x < 1 \\ \end{cases} \text{ and }  c_2= \begin{cases} \pi, & x > 1 \\ 0, & 0 < x < 1.\end{cases} $$ Assuming my attempt is correct thus far, can I evaluate $$ \int_{R}\frac{t\sin(\ln(x)at)}{1+t^2}dt=-\frac{I'(a)}{\ln(x)}:=D(a)={\rm sgn}(\ln(x))\pi-\int_{R}\frac{\sin(\ln(x)at)}{t(1+t^2)}dt. $$ Then $D'(a)=-\ln(x)I(a)$ , so $$D(a)=c_2x^{-a}-c_1x^{a}.$$ $$ \frac{1}{2\pi i}\int^{a+i\infty}_{a-i\infty}\frac{x^s}{s}ds=\frac{x^{a}}{2\pi}((c_1x^{a}+c_2x^{-a})+c_2x^{-a}-c_1x^{a})=\begin{cases} 1, & x > 1 \\ 0, & 0 < x < 1. \end{cases} $$ (as defined herein) using Feynman integration? It is used extensively in Riemann's paper in finding an analytic representation of the jump function (equivalently, an asymptotic estimate of the prime counting function by applying the Moebius inversion formula [following from the associativity of the Dirichlet convolution] to the analytic representation of the jump function) and in a proof of Perron's formula.  Pardon my illegible uglyography and quotidian rogitation, albeit I consider the transient apanthropinization as a pars pro toto for expunged pedagogical anomalies.","I am trying to prove that for by using Feynman integration and solving a homogeneous second order differential equation respectively. Here is my attempt: Therefore Set so and Therefore for Assuming my attempt is correct thus far, can I evaluate Then , so (as defined herein) using Feynman integration? It is used extensively in Riemann's paper in finding an analytic representation of the jump function (equivalently, an asymptotic estimate of the prime counting function by applying the Moebius inversion formula [following from the associativity of the Dirichlet convolution] to the analytic representation of the jump function) and in a proof of Perron's formula.  Pardon my illegible uglyography and quotidian rogitation, albeit I consider the transient apanthropinization as a pars pro toto for expunged pedagogical anomalies.","
\frac{1}{2\pi i}\int^{a+i\infty}_{a-i\infty}\frac{x^s}{s-\beta}ds
=\begin{cases} x^{\beta}, & x > 1 \\ 0, & 0 < x < 1 \\ \end{cases}
 0<{\rm Re}(\beta)<a \begin{align*}
\frac{1}{2\pi i}\int^{a+i\infty}_{a-i\infty}\frac{x^s}{s}ds& =\frac{x^a}{2\pi}\int^{\infty}_{0}\frac{x^{it}(a-it)+x^{-it}(a+it)}{a^2+t^2}dt\\ 
& =\frac{x^a}{\pi}\left(\int^{\infty}_{0}\frac{\cos(\ln(x)ta)}{1+t^2}dt+\int^{\infty}_{0}\frac{t\sin(\ln(x)ta)}{1+t^2}dt\right). 
\end{align*} \begin{align*}
{\rm Re}(\oint_C\frac{x^{iza}}{1+z^2}dz) 
& ={\rm Re}\left(\lim_{R \to \infty}\int^{R}_{-R}\frac{x^{iza}}{1+z^2}dz+\int_{\Gamma}\right) \\
& =\frac{\pi}{x^a}.\lim_{R \to \infty} \left| \int_{\Gamma} \right| \\
& \leqslant\lim_{R \to \infty} \frac{2}{R}\int^{\frac{\pi}{2}}_{0}\frac{x^{-2R\theta/\pi}}{1+(Re^{i\theta})^{-2}}d\theta \\
& =0.
\end{align*} 
\int^{\infty}_{0}\frac{\cos(\ln(x)ta)}{1+t^2}dt = \frac{\pi}{2x^a}.
 
I(a):=\int_{R}\frac{\cos(\ln(x)ta)}{1+t^2}dt
 
I'(a)=\ln(x)(-{\rm sgn}(\ln(x))\pi+\int_{R}\frac{\sin(\ln(x)ta)}{t(1+t^2)}dt)
 
I''(a)-\ln^2(x)I(a) = 0.
 I(a)=c_1x^a+c_2x^{-a} 
c_1=\begin{cases} 0, & x > 1 \\ \pi, & 0 < x < 1 \\ \end{cases} \text{ and } 
c_2= \begin{cases} \pi, & x > 1 \\ 0, & 0 < x < 1.\end{cases}
 
\int_{R}\frac{t\sin(\ln(x)at)}{1+t^2}dt=-\frac{I'(a)}{\ln(x)}:=D(a)={\rm sgn}(\ln(x))\pi-\int_{R}\frac{\sin(\ln(x)at)}{t(1+t^2)}dt.
 D'(a)=-\ln(x)I(a) D(a)=c_2x^{-a}-c_1x^{a}. 
\frac{1}{2\pi i}\int^{a+i\infty}_{a-i\infty}\frac{x^s}{s}ds=\frac{x^{a}}{2\pi}((c_1x^{a}+c_2x^{-a})+c_2x^{-a}-c_1x^{a})=\begin{cases} 1, & x > 1 \\ 0, & 0 < x < 1. \end{cases}
","['complex-analysis', 'ordinary-differential-equations', 'solution-verification', 'contour-integration', 'leibniz-integral-rule']"
81,Exercise 2. Chapter 5. Stein,Exercise 2. Chapter 5. Stein,,"Suppose $F(z)$ is holomorphic near $z=z_0$ and $F(z_0)=F'(z_0)=0$ , while $F''(z_0)\neq 0$ . Show that there are two curves $\Gamma_1$ and $\Gamma_2$ that pass through $z_0$ , are orthogonal at $z_0$ , and so that $F$ restricted to $\Gamma_1$ is real an has a minimum at $z_0$ , while $F$ restricted to $\Gamma_2$ is also real but has a maximum at $z_0$ . Progress: I know that $F(z)=z^2f(z)$ where $f(z)$ doesn't vanish at $z_0$ . Then in a small disk around $z_0$ the function $f$ doesn't vanish. So I can write $F(z)=g(z)^2$ where $g$ is a bijection in a small disk around $z_0$ . The hint of this exercise suggests to use this function $g$ and its inverse to get the curves $\Gamma_1$ and $\Gamma_2$ , but I don't see how to do it. Any suggestions?","Suppose is holomorphic near and , while . Show that there are two curves and that pass through , are orthogonal at , and so that restricted to is real an has a minimum at , while restricted to is also real but has a maximum at . Progress: I know that where doesn't vanish at . Then in a small disk around the function doesn't vanish. So I can write where is a bijection in a small disk around . The hint of this exercise suggests to use this function and its inverse to get the curves and , but I don't see how to do it. Any suggestions?",F(z) z=z_0 F(z_0)=F'(z_0)=0 F''(z_0)\neq 0 \Gamma_1 \Gamma_2 z_0 z_0 F \Gamma_1 z_0 F \Gamma_2 z_0 F(z)=z^2f(z) f(z) z_0 z_0 f F(z)=g(z)^2 g z_0 g \Gamma_1 \Gamma_2,['complex-analysis']
82,Prove $ \int_0^\infty e^{-x^2} dx = \frac{\sqrt{\pi}}{2}$.,Prove ., \int_0^\infty e^{-x^2} dx = \frac{\sqrt{\pi}}{2},"Prove $ \int_0^\infty e^{-x^2} dx = \frac{\sqrt{\pi}}{2}$ . I know how to do it using calculus. But I want to use Cauchy's integral formula. First, consider $ \oint_C e^{-z^2} dz$ along a contour C consisting of a line along the x-axis from $-R$ to $R$ and the semicircle $\Gamma$ above the x-axis having this line as diameter. By Cauchy's Integral formula $ \oint_C e^{-z^2} dz=0$ which implies $ \int_{-R}^{R} e^{-x^2} dx + \int_{\Gamma} e^{-z^2} dz=0$ . When $R \to \infty$ , $ \int_{-\infty}^{\infty} e^{-x^2} dx + \int_{\Gamma} e^{-z^2} dz=0$ . Now to compute $\int_{\Gamma} e^{-z^2} dz$ , consider $z=Re^{i \theta}$ , $dz=iRe^{i \theta}$ . I am stuck here.","Prove . I know how to do it using calculus. But I want to use Cauchy's integral formula. First, consider along a contour C consisting of a line along the x-axis from to and the semicircle above the x-axis having this line as diameter. By Cauchy's Integral formula which implies . When , . Now to compute , consider , . I am stuck here.", \int_0^\infty e^{-x^2} dx = \frac{\sqrt{\pi}}{2}  \oint_C e^{-z^2} dz -R R \Gamma  \oint_C e^{-z^2} dz=0  \int_{-R}^{R} e^{-x^2} dx + \int_{\Gamma} e^{-z^2} dz=0 R \to \infty  \int_{-\infty}^{\infty} e^{-x^2} dx + \int_{\Gamma} e^{-z^2} dz=0 \int_{\Gamma} e^{-z^2} dz z=Re^{i \theta} dz=iRe^{i \theta},"['complex-analysis', 'contour-integration']"
83,Prove complex numbers $a$ and $b$ are antipodal under stereographic projection $\iff a \overline{b} = -1$,Prove complex numbers  and  are antipodal under stereographic projection,a b \iff a \overline{b} = -1,"I'm trying to prove the following statement: Given $a, b \in \mathbb{C}$ , prove that $a$ and $b$ correspond to antipodal points on the Riemann sphere under stereographic projection if and only if $a \overline{b} = -1$ My attempt I wanted to make a proof where all my implications were reversible to avoid making a proof of each implication separately. As previous knowledge, I know that if a have a point $a \in \mathbb{C}$ , then the stereographic projection $f: \mathbb{C} \to S^2$ is given by $$ f(a) = \left(\frac{a + \overline{a}}{1 + |a|^2},\frac{a - \overline{a}}{i\left(1 + |a|^2\right)},\frac{|a|^2-1}{|a|^2+1}\right) $$ Now, given that $P,Q\in S^2$ are antipodal if and only if $P =-Q$ , I get the following: \begin{align} f(a) = -f(b) &\iff \begin{cases} \frac{a + \overline{a}}{1 + |a|^2} = \frac{-b - \overline{b}}{1 + |b|^2} \\ \frac{a - \overline{a}}{i\left(1 + |a|^2\right)} = \frac{\overline{b}-b}{i\left(1 + |b|^2\right)} \\ \frac{|a|^2-1}{|a|^2+1} = \frac{1-|b|^2}{|b|^2+1} \\ \end{cases}\\ &\iff\begin{cases} a + \overline{a}+a|b|^2 +\overline{a}|b|^2 = -b - \overline{b}-b|a|^2 -\overline{b}|a|^2 \\ a - \overline{a}+a|b|^2 -\overline{a}|b|^2 = -b + \overline{b}-b|a|^2 +\overline{b}|a|^2 \\ |ab|^2+|a|^2-|b|^2-1 =-|ab|^2+|a|^2-|b|^2+1 \\ \end{cases}\\ &\iff\begin{cases} a +a|b|^2 = -b -b|a|^2  \\ \overline{a} +\overline{a}|b|^2 = -\overline{b} -\overline{b}|a|^2  \\ |ab|^2=1 \\ \end{cases}\\ &\iff\begin{cases} a +b +a|b|^2+b|a|^2 =0 \\ |a||b|=1 \\ \end{cases}\\ \end{align} Where here I use brackets to indicate that all those equations are true simultaneously. On this last step is where I ran into trouble because I couldn't find a way to show that both conditions in the last step are equivalent to $b =- \frac{1}{\overline{a}}$ . Is my attempt correct (up to what I have already written)? And if so, does somebody know how I could conclude the proof of equivalence? Any help would be greatly appreciated. Thank you!","I'm trying to prove the following statement: Given , prove that and correspond to antipodal points on the Riemann sphere under stereographic projection if and only if My attempt I wanted to make a proof where all my implications were reversible to avoid making a proof of each implication separately. As previous knowledge, I know that if a have a point , then the stereographic projection is given by Now, given that are antipodal if and only if , I get the following: Where here I use brackets to indicate that all those equations are true simultaneously. On this last step is where I ran into trouble because I couldn't find a way to show that both conditions in the last step are equivalent to . Is my attempt correct (up to what I have already written)? And if so, does somebody know how I could conclude the proof of equivalence? Any help would be greatly appreciated. Thank you!","a, b \in \mathbb{C} a b a \overline{b} = -1 a \in \mathbb{C} f: \mathbb{C} \to S^2 
f(a) = \left(\frac{a + \overline{a}}{1 + |a|^2},\frac{a - \overline{a}}{i\left(1 + |a|^2\right)},\frac{|a|^2-1}{|a|^2+1}\right)
 P,Q\in S^2 P =-Q \begin{align}
f(a) = -f(b) &\iff
\begin{cases}
\frac{a + \overline{a}}{1 + |a|^2} = \frac{-b - \overline{b}}{1 + |b|^2} \\
\frac{a - \overline{a}}{i\left(1 + |a|^2\right)} = \frac{\overline{b}-b}{i\left(1 + |b|^2\right)} \\
\frac{|a|^2-1}{|a|^2+1} = \frac{1-|b|^2}{|b|^2+1} \\
\end{cases}\\
&\iff\begin{cases}
a + \overline{a}+a|b|^2 +\overline{a}|b|^2 = -b - \overline{b}-b|a|^2 -\overline{b}|a|^2 \\
a - \overline{a}+a|b|^2 -\overline{a}|b|^2 = -b + \overline{b}-b|a|^2 +\overline{b}|a|^2 \\
|ab|^2+|a|^2-|b|^2-1 =-|ab|^2+|a|^2-|b|^2+1 \\
\end{cases}\\
&\iff\begin{cases}
a +a|b|^2 = -b -b|a|^2  \\
\overline{a} +\overline{a}|b|^2 = -\overline{b} -\overline{b}|a|^2  \\
|ab|^2=1 \\
\end{cases}\\
&\iff\begin{cases}
a +b +a|b|^2+b|a|^2 =0 \\
|a||b|=1 \\
\end{cases}\\
\end{align} b =- \frac{1}{\overline{a}}","['complex-analysis', 'complex-numbers', 'proof-writing', 'solution-verification', 'analytic-geometry']"
84,Bound for $\sum_{k=0}^{n}(-1)^k{3n\choose k}{n\choose k}$.,Bound for .,\sum_{k=0}^{n}(-1)^k{3n\choose k}{n\choose k},"In the book Complex analysis by Bak J. & Newman J. , chapter 11, talks about Sums Involving Binomial coefficients and find a bound $\frac{16}{9}\sqrt{3}$ for $|(z-1)^2(z+1)|$ in the ""Example 3"" on the unit circle, my way was using lagrange multipliers in this form: We want find $\max{|(z-1)^2(z+1)|}$ ahnd have that $|z-1|^2+|z+1|^2=4$ . Let be $a=|z-1|$ and $b=|z+1|$ and then the exercise is: ""Maximize $f(a,b)=a^2b$ subject to $a^2+b^2=4$ "" then $\nabla f=\lambda\nabla g$ so $\begin{cases}2ab=\lambda(2a)\\a^2=\lambda(2b)\end{cases}$ , i.e., $ab=\lambda a$ if $a(b-\lambda)=0$ therefore i) $a=0$ or $b=\lambda$ , $b^2=4$ then $b=2$ then $|z+1|=2$ or $|z-1|=0$ then $z=1$ and $a^2b=0$ . ii) $b=\lambda$ , $a^2=2b^2$ then $4=a^2+b^2=3b^2$ then $b^2=4/3$ then $b=\frac{2\sqrt{3}}{3}$ then $a^2=\frac{8}{3}$ then $a=\frac{2\sqrt{2}}{\sqrt{3}}$ So $a^2b=\frac{8}{3}\frac{2\sqrt{3}}{3}=\frac{16}{9}\sqrt{3}$ . After i want to use this idea for exercise 17.b with $\sum_{k=0}^{n}(-1)^k{3n\choose k}{n\choose k}$ but, i don´t see what should be $a$ and $b$ . Edit: this exercise says that $|\sum_{k=0}^{n}(-1)^k{3n\choose k}{n\choose k}|\leq4^n$ .","In the book Complex analysis by Bak J. & Newman J. , chapter 11, talks about Sums Involving Binomial coefficients and find a bound for in the ""Example 3"" on the unit circle, my way was using lagrange multipliers in this form: We want find ahnd have that . Let be and and then the exercise is: ""Maximize subject to "" then so , i.e., if therefore i) or , then then or then and . ii) , then then then then then So . After i want to use this idea for exercise 17.b with but, i don´t see what should be and . Edit: this exercise says that .","\frac{16}{9}\sqrt{3} |(z-1)^2(z+1)| \max{|(z-1)^2(z+1)|} |z-1|^2+|z+1|^2=4 a=|z-1| b=|z+1| f(a,b)=a^2b a^2+b^2=4 \nabla f=\lambda\nabla g \begin{cases}2ab=\lambda(2a)\\a^2=\lambda(2b)\end{cases} ab=\lambda a a(b-\lambda)=0 a=0 b=\lambda b^2=4 b=2 |z+1|=2 |z-1|=0 z=1 a^2b=0 b=\lambda a^2=2b^2 4=a^2+b^2=3b^2 b^2=4/3 b=\frac{2\sqrt{3}}{3} a^2=\frac{8}{3} a=\frac{2\sqrt{2}}{\sqrt{3}} a^2b=\frac{8}{3}\frac{2\sqrt{3}}{3}=\frac{16}{9}\sqrt{3} \sum_{k=0}^{n}(-1)^k{3n\choose k}{n\choose k} a b |\sum_{k=0}^{n}(-1)^k{3n\choose k}{n\choose k}|\leq4^n","['complex-analysis', 'optimization', 'summation', 'binomial-coefficients']"
85,Calculating $\lim_n e^{-inz}$,Calculating,\lim_n e^{-inz},"In an exercise I have to prove that $f_n(z)=e^{-inz}$ converges uniformly for $\Re(z)>3$ . So I have to prove that: $$\forall \varepsilon>0, \exists p \in \mathbb{N}:|e^{-inz}-f(z)|<\varepsilon\ \ \ \text{if } n\geq p$$ My question is, how can I find that $f(z)$ ? I've tried calculating the $\lim_n e^{-inz}$ by doing the following: if $z=x+iy$ then: $\lim_n e^{-inz}=\lim_n \frac{1}{e^{inz}}=\lim_n \frac{e^{ny}}{e^{inx}}$ but I could not continue from now on. How can I evaluate this limit?","In an exercise I have to prove that converges uniformly for . So I have to prove that: My question is, how can I find that ? I've tried calculating the by doing the following: if then: but I could not continue from now on. How can I evaluate this limit?","f_n(z)=e^{-inz} \Re(z)>3 \forall \varepsilon>0, \exists p \in \mathbb{N}:|e^{-inz}-f(z)|<\varepsilon\ \ \ \text{if } n\geq p f(z) \lim_n e^{-inz} z=x+iy \lim_n e^{-inz}=\lim_n \frac{1}{e^{inz}}=\lim_n \frac{e^{ny}}{e^{inx}}","['complex-analysis', 'limits']"
86,Compute $\int_0^{+\infty}\frac{\sin x + \cos x}{x^4+1}dx$,Compute,\int_0^{+\infty}\frac{\sin x + \cos x}{x^4+1}dx,"Problem: Compute $$\int_0^{+\infty}\frac{\sin x + \cos x}{x^4+1}dx$$ using the Residue Theorem. My attempt: We know that $$\sin x+ \cos x=\sqrt{2} \sin(x + \frac{\pi}{4})$$ Thus we can reduce to compute: $$\int_0^{+\infty}\frac{e^{ix}}{x^4+1}dx$$ Defining $\alpha_R(t)=t$ for $t \in [0,R]$ , $\beta_R(t)=Re^{it}$ for $t \in [0,\theta]$ and finally $\gamma_R(t)=e^{i\theta}tR$ where $\theta$ is an opportune angle to be chosen I would like to use then Residue Theorem but I cannot say anything about: $$\int_{\gamma_R}f(z)dz$$ where $f(z)=\frac{e^{iz}}{z^4+1}$ .","Problem: Compute using the Residue Theorem. My attempt: We know that Thus we can reduce to compute: Defining for , for and finally where is an opportune angle to be chosen I would like to use then Residue Theorem but I cannot say anything about: where .","\int_0^{+\infty}\frac{\sin x + \cos x}{x^4+1}dx \sin x+ \cos x=\sqrt{2} \sin(x + \frac{\pi}{4}) \int_0^{+\infty}\frac{e^{ix}}{x^4+1}dx \alpha_R(t)=t t \in [0,R] \beta_R(t)=Re^{it} t \in [0,\theta] \gamma_R(t)=e^{i\theta}tR \theta \int_{\gamma_R}f(z)dz f(z)=\frac{e^{iz}}{z^4+1}","['calculus', 'complex-analysis', 'definite-integrals', 'residue-calculus']"
87,Is there any significance to the product $\prod_\limits{n=1}^{\infty} \left(1+\frac{1}{n^x}\right)$?,Is there any significance to the product ?,\prod_\limits{n=1}^{\infty} \left(1+\frac{1}{n^x}\right),"Is there any significance to this product? $$\prod\limits_{n=1}^{\infty} \left(1+\frac{1}{n^x}\right)$$ Basically taking the Riemann zeta function and trying to make it into a convergent product, because if you have a convergent sum then you can take the infinite product of 1+the sum and it will also converge.","Is there any significance to this product? Basically taking the Riemann zeta function and trying to make it into a convergent product, because if you have a convergent sum then you can take the infinite product of 1+the sum and it will also converge.",\prod\limits_{n=1}^{\infty} \left(1+\frac{1}{n^x}\right),"['complex-analysis', 'riemann-zeta', 'infinite-product']"
88,Connected Preimage of Complex Polynomial,Connected Preimage of Complex Polynomial,,"Let $p(z)=z^2+z+i$ . For what $R>0$ is the set $S_R=\{z\in\mathbb{C}:|p(z)|<R\}$ connected in $\mathbb{C}$ ? If $R=\infty$ , then $S_{\infty}=\mathbb{C}$ which is connected. Also, the roots of $p(z)$ are separated by the real line, so if $S_R\cap\mathbb{R}=\emptyset$ , then $S_R$ is not connected in $\mathbb{C}$ . For any $x\in\mathbb{R}$ , Im $(p(x))=i$ , so if $R\leq1$ , then $S_R$ is not connected. I'm not sure about $1<R<\infty$ .","Let . For what is the set connected in ? If , then which is connected. Also, the roots of are separated by the real line, so if , then is not connected in . For any , Im , so if , then is not connected. I'm not sure about .",p(z)=z^2+z+i R>0 S_R=\{z\in\mathbb{C}:|p(z)|<R\} \mathbb{C} R=\infty S_{\infty}=\mathbb{C} p(z) S_R\cap\mathbb{R}=\emptyset S_R \mathbb{C} x\in\mathbb{R} (p(x))=i R\leq1 S_R 1<R<\infty,"['complex-analysis', 'polynomials', 'connectedness']"
89,$\textrm{Re}(f'(z)) > 0$ but $f$ is not injective.,but  is not injective.,\textrm{Re}(f'(z)) > 0 f,"I'm looking for an example of a simply connected open set in $\mathbb{C}$ and a holomorphic function $f \colon \Omega \to \mathbb{C}$ such that $$\textrm{Re}(f'(z)) > 0$$ for all $z \in \Omega$ but $f$ is not injective. One can show that under these conditions, $f$ must be injective if $\Omega$ is convex. I'm not sure how to come up with a counterexample for a nonconvex set though. It seems for many elementary functions such as $z^2, e^z$ that the set where $\textrm{Re}(f'(z)) > 0$ has convex connected components.","I'm looking for an example of a simply connected open set in and a holomorphic function such that for all but is not injective. One can show that under these conditions, must be injective if is convex. I'm not sure how to come up with a counterexample for a nonconvex set though. It seems for many elementary functions such as that the set where has convex connected components.","\mathbb{C} f \colon \Omega \to \mathbb{C} \textrm{Re}(f'(z)) > 0 z \in \Omega f f \Omega z^2, e^z \textrm{Re}(f'(z)) > 0",['complex-analysis']
90,Are winding number and index of a not smooth closed curve the same?,Are winding number and index of a not smooth closed curve the same?,,"Let $\gamma:[0,1] \longrightarrow \mathbf{C} \backslash \{0\}$ be a closed curve (continuous and of bounded variation).  We call $$\operatorname{Ind}_\gamma(0) \overset{\mathrm{def}}{=} \frac{1}{2 \pi i}\int_\gamma \frac{1}{z}\ dz.$$ $\textbf{the index of $\gamma$ around $0$.}$ As for the winding number, we can take a pair of continuous real valued functions $r$ and $\theta$ that satisfies $$r:[0,1] \longrightarrow (0,\infty),$$ $$\theta:[0,1] \longrightarrow \mathbf{R},$$ $$\forall t \in [0,1]\, \left[\, \gamma(t) = r(t) \cdot e^{i \cdot \theta(t)}\, \right],$$ and $$-\pi < \theta(0) \leq \pi.$$ (The proof of this can be found in chapter 7 of A. F. Beardon, Complex Analysis: The Argument Principle in Analysis and Topology, Wiley-Interscience publication 1979). We call $$\operatorname{Wnd}_\gamma(0) \overset{\mathrm{def}}{=}\frac{\theta(1) - \theta(0)}{2\pi}$$ $\textbf{the winding number of $\gamma$ around $0$}$ . It is already known that if $\gamma$ is $C^1$ -curve, then $$\operatorname{Ind}_\gamma(0) = \operatorname{Wnd}_\gamma(0)$$ (see definition of winding number, have doubt in definition. ). My question: When $\gamma$ is not $C^1$ path, $$\operatorname{Ind}_\gamma(0) = \operatorname{Wnd}_\gamma(0)?$$ Thank you for reading.","Let be a closed curve (continuous and of bounded variation).  We call As for the winding number, we can take a pair of continuous real valued functions and that satisfies and (The proof of this can be found in chapter 7 of A. F. Beardon, Complex Analysis: The Argument Principle in Analysis and Topology, Wiley-Interscience publication 1979). We call . It is already known that if is -curve, then (see definition of winding number, have doubt in definition. ). My question: When is not path, Thank you for reading.","\gamma:[0,1] \longrightarrow \mathbf{C} \backslash \{0\} \operatorname{Ind}_\gamma(0) \overset{\mathrm{def}}{=} \frac{1}{2 \pi i}\int_\gamma \frac{1}{z}\ dz. \textbf{the index of \gamma around 0.} r \theta r:[0,1] \longrightarrow (0,\infty), \theta:[0,1] \longrightarrow \mathbf{R}, \forall t \in [0,1]\, \left[\, \gamma(t) = r(t) \cdot e^{i \cdot \theta(t)}\, \right], -\pi < \theta(0) \leq \pi. \operatorname{Wnd}_\gamma(0) \overset{\mathrm{def}}{=}\frac{\theta(1) - \theta(0)}{2\pi} \textbf{the winding number of \gamma around 0} \gamma C^1 \operatorname{Ind}_\gamma(0) = \operatorname{Wnd}_\gamma(0) \gamma C^1 \operatorname{Ind}_\gamma(0) = \operatorname{Wnd}_\gamma(0)?","['complex-analysis', 'plane-curves', 'winding-number']"
91,Is intersection of zero set of any family of holomorphic functions an analytic set?,Is intersection of zero set of any family of holomorphic functions an analytic set?,,"Let $\{f_{\alpha}\}_{\alpha\in \mathcal{I}}$ be a family of holomorphic functions on the unit ball $\mathbb{B}^{n}$ in $\mathbb{C}^{n}$ . Let $$ U:=\{z\in \mathbb{B}^{n}: f_{\alpha}(z)=0,\forall \alpha\in\mathcal{I}\}. $$ Can we always conclude that $U$ is an analytic subset in $\mathbb{B}^{n}$ ? That is, for any $a\in \mathbb{B}^{n}$ , there exist a neighbourhood $B(a,\varepsilon)\subset \mathbb{B}^{n}$ of $a$ , and a finite family of holomorphic functions $g_{1},...,g_{m}$ on $B(a,\varepsilon)$ such that $$ B(a,\varepsilon)\cap U=\{z\in B(a,\varepsilon): g_{1}(z)=...=g_{m}(z)=0\}. $$ I think in general this is not the case. We may need to impose some structure on our family. However, I am not sure at the moment. Thanks so much for any suggestion.","Let be a family of holomorphic functions on the unit ball in . Let Can we always conclude that is an analytic subset in ? That is, for any , there exist a neighbourhood of , and a finite family of holomorphic functions on such that I think in general this is not the case. We may need to impose some structure on our family. However, I am not sure at the moment. Thanks so much for any suggestion.","\{f_{\alpha}\}_{\alpha\in \mathcal{I}} \mathbb{B}^{n} \mathbb{C}^{n} 
U:=\{z\in \mathbb{B}^{n}: f_{\alpha}(z)=0,\forall \alpha\in\mathcal{I}\}.
 U \mathbb{B}^{n} a\in \mathbb{B}^{n} B(a,\varepsilon)\subset \mathbb{B}^{n} a g_{1},...,g_{m} B(a,\varepsilon) 
B(a,\varepsilon)\cap U=\{z\in B(a,\varepsilon): g_{1}(z)=...=g_{m}(z)=0\}.
","['complex-analysis', 'algebraic-geometry', 'several-complex-variables']"
92,Application of Schwarz lemma and Liouville's theorem,Application of Schwarz lemma and Liouville's theorem,,"I recently came across the following problem Let $h : \Bbb C → \Bbb C$ be an analytic function such that $h(0) = 0, h(1/2) = 5$ , and $|h(z)| < 10$ for $|z| < 1$ . Then pick out the correct statement(s): the set $\{z : |h(z)| = 5\}$ is unbounded by the Maximum Principle the set $\{z : |h'(z)| = 5\}$ is a circle of strictly positive radius $h(1) = 10$ regardless of what $h'$ is, $h'' \equiv 0$ . My try Consider $f(z)=\frac{h(z)}{10}$ and $f$ satisfies the hypothesis of Schwarz lemma, so $$\vert f(z) \vert \leq \vert z \vert$$ and so $$\vert h(z) \vert \leq 10 \vert z \vert ^1$$ so by extended Lioville's theorem, $h$ is a polynomial of degree atmost $1$ . So $h$ is either constant or linear. But given hypothesis implies $h$ is not constant and $h$ is exactly $10z$ . That is, $$(\forall z \in \Bbb C): h(z)\equiv 10z$$ So the set in the first bullet is a circle $\vert z \vert =1/2$ ,which is bounded and so it is false The second set is $\varnothing$ and so the second  one is false Third and fourth are true. Since $h$ is linear , its second derivative vanishes! Is my reasoning correct ? Any thoughts? Edit: I agree that my reasoning in wrong as Mr. Kavi Rama Murthy says in the comment. So this $h(z)=10z$ helps to eliminate the first two options. But how to conclude the last two. Any help ?","I recently came across the following problem Let be an analytic function such that , and for . Then pick out the correct statement(s): the set is unbounded by the Maximum Principle the set is a circle of strictly positive radius regardless of what is, . My try Consider and satisfies the hypothesis of Schwarz lemma, so and so so by extended Lioville's theorem, is a polynomial of degree atmost . So is either constant or linear. But given hypothesis implies is not constant and is exactly . That is, So the set in the first bullet is a circle ,which is bounded and so it is false The second set is and so the second  one is false Third and fourth are true. Since is linear , its second derivative vanishes! Is my reasoning correct ? Any thoughts? Edit: I agree that my reasoning in wrong as Mr. Kavi Rama Murthy says in the comment. So this helps to eliminate the first two options. But how to conclude the last two. Any help ?","h : \Bbb C → \Bbb C h(0) = 0, h(1/2) = 5 |h(z)| < 10 |z| < 1 \{z : |h(z)| = 5\} \{z : |h'(z)| = 5\} h(1) = 10 h' h'' \equiv 0 f(z)=\frac{h(z)}{10} f \vert f(z) \vert \leq \vert z \vert \vert h(z) \vert \leq 10 \vert z \vert ^1 h 1 h h h 10z (\forall z \in \Bbb C): h(z)\equiv 10z \vert z \vert =1/2 \varnothing h h(z)=10z",['complex-analysis']
93,limit at infinity of a meromorphic function using residues,limit at infinity of a meromorphic function using residues,,"Let $z_1,\dots,z_n\in\mathbb{C}$ be different points and let $f:\mathbb{C}\setminus\{z_1,\dots,z_n\}\to\mathbb{C}$ be a holomorphic function. Suppose that $\lim\limits_{z\to\infty}f(z)=0$. Prove that $$\lim\limits_{z\to\infty}zf(z)=\sum\limits_{k=1}^n  \operatorname{Res}_{z_k}(f)$$ Clearly, we can look at $\lim\limits_{z\to 0}\frac{1}{z}f(\frac{1}{z})$. I have read something about residue at infinity, but I don't see how to use it.","Let $z_1,\dots,z_n\in\mathbb{C}$ be different points and let $f:\mathbb{C}\setminus\{z_1,\dots,z_n\}\to\mathbb{C}$ be a holomorphic function. Suppose that $\lim\limits_{z\to\infty}f(z)=0$. Prove that $$\lim\limits_{z\to\infty}zf(z)=\sum\limits_{k=1}^n  \operatorname{Res}_{z_k}(f)$$ Clearly, we can look at $\lim\limits_{z\to 0}\frac{1}{z}f(\frac{1}{z})$. I have read something about residue at infinity, but I don't see how to use it.",,"['complex-analysis', 'residue-calculus']"
94,Limit of error function in complex argument,Limit of error function in complex argument,,"How to calculate the limit \begin{align*} \lim_{b\to \infty}\frac{\vert \text{erf}(\sqrt{a+\mathrm{i} b})\vert^{2}}{\sqrt{a^2+b^2}} \end{align*} where \begin{align*} \text{erf}(a+\mathrm{i} b)=\frac{2}{\sqrt{\pi}}\int_{0}^{a+\mathrm{i} b}e^{-t^2}~dt \end{align*} is the error function. The Mathematica shows that as $b$ grows, $\vert \text{erf}(\sqrt{a+\mathrm{i} b})\vert^{2} $ approaches to $1$ and consequently \begin{align*} \frac{\vert \text{erf}(\sqrt{a+\mathrm{i} b})\vert^{2}}{\sqrt{a^2+b^2}} \end{align*} becomes very small. If I try to simplify the error function, then I find an expression in terms of $\cos$ and $\sin$ and that diverge. How to proves that the above limit converges to $0$ (as Mathematica shows).","How to calculate the limit where is the error function. The Mathematica shows that as grows, approaches to and consequently becomes very small. If I try to simplify the error function, then I find an expression in terms of and and that diverge. How to proves that the above limit converges to (as Mathematica shows).","\begin{align*}
\lim_{b\to \infty}\frac{\vert \text{erf}(\sqrt{a+\mathrm{i} b})\vert^{2}}{\sqrt{a^2+b^2}}
\end{align*} \begin{align*}
\text{erf}(a+\mathrm{i} b)=\frac{2}{\sqrt{\pi}}\int_{0}^{a+\mathrm{i} b}e^{-t^2}~dt
\end{align*} b \vert \text{erf}(\sqrt{a+\mathrm{i} b})\vert^{2}  1 \begin{align*}
\frac{\vert \text{erf}(\sqrt{a+\mathrm{i} b})\vert^{2}}{\sqrt{a^2+b^2}}
\end{align*} \cos \sin 0","['complex-analysis', 'limits', 'error-function']"
95,Laurent Series $\sin\left(\frac{z}{z+1}\right)$ [duplicate],Laurent Series  [duplicate],\sin\left(\frac{z}{z+1}\right),"This question already has answers here : Finding The Laurent Series for $\sin(\frac{z}{1+z})$ at $z = -1.$ (2 answers) Closed 3 years ago . I search the Laurent series of $\sin(\frac{z}{z+1})$ in the point $z_0=-1$. What I did is write the taylor expansion $$\sin\Big(\frac{z}{z+1}\Big)=\sum_{n=0}^\infty(-1)^n\frac{\Big(\frac{z}{z+1}\Big)^{2n+1}}{(2n+1)!}$$ But this can't be right, since I didn't take $z_0$ into account. How can I do the Laurent expansion in this case?","This question already has answers here : Finding The Laurent Series for $\sin(\frac{z}{1+z})$ at $z = -1.$ (2 answers) Closed 3 years ago . I search the Laurent series of $\sin(\frac{z}{z+1})$ in the point $z_0=-1$. What I did is write the taylor expansion $$\sin\Big(\frac{z}{z+1}\Big)=\sum_{n=0}^\infty(-1)^n\frac{\Big(\frac{z}{z+1}\Big)^{2n+1}}{(2n+1)!}$$ But this can't be right, since I didn't take $z_0$ into account. How can I do the Laurent expansion in this case?",,"['complex-analysis', 'power-series']"
96,Is $F(z)=\frac{i}{2}\log(z+i)-\frac{i}{2}\log(z-i)$ equal to $\arctan z$?,Is  equal to ?,F(z)=\frac{i}{2}\log(z+i)-\frac{i}{2}\log(z-i) \arctan z,"Show that $F(z)=\frac{i}{2}\log(z+i)-\frac{i}{2}\log(z-i)$ is an antiderivative of $f(z)=\frac{1}{z^2+1}$ for $\operatorname{Re}(z)>0$. Is $F(z)$ equal to $\arctan z$? I basically did $$\frac{d}{dz}F(z)=\frac{i}{2}\frac{1}{z+i}-\frac{i}{2}\frac{1}{z-i}=\frac{1}{z^2+1}=f(z)$$ Thus, $F(z)$ is an antiderivative of $f(z)$. But my question is : Why do we need $\operatorname{Re}(z)>0$ here? Is that a preparation for $\arctan z$ to be defined or something? I think even though $F'(z)=(\arctan z)'=f(z)$, we cannot say $F(z)$ equal to $\arctan z$. Since they are only one member of the antiderivative family of $\frac{1}{z^2+1}$. Is that correct? Thanks~","Show that $F(z)=\frac{i}{2}\log(z+i)-\frac{i}{2}\log(z-i)$ is an antiderivative of $f(z)=\frac{1}{z^2+1}$ for $\operatorname{Re}(z)>0$. Is $F(z)$ equal to $\arctan z$? I basically did $$\frac{d}{dz}F(z)=\frac{i}{2}\frac{1}{z+i}-\frac{i}{2}\frac{1}{z-i}=\frac{1}{z^2+1}=f(z)$$ Thus, $F(z)$ is an antiderivative of $f(z)$. But my question is : Why do we need $\operatorname{Re}(z)>0$ here? Is that a preparation for $\arctan z$ to be defined or something? I think even though $F'(z)=(\arctan z)'=f(z)$, we cannot say $F(z)$ equal to $\arctan z$. Since they are only one member of the antiderivative family of $\frac{1}{z^2+1}$. Is that correct? Thanks~",,"['complex-analysis', 'complex-numbers']"
97,Why aren't complex compact Lie groups trivial?,Why aren't complex compact Lie groups trivial?,,"What's wrong with my understanding of Liouville's theorem? A complex lie group is one where group multiplication and inversion are holomorphic. Supposing $G$ is compact and complex, so is $G \times G$. Then multiplication could be viewed as a holomorphic function on a compact set, so it must be constant valued in $G$ by Liouville's. Then since, in particular, the identity times itself is the identity, so is any element times any other element. But this only makes sense if $G=\{e\}$. I've seen that there is no hesitation in saying that the adjoint representation $\textrm{Ad}: G\to \textrm{Aut}(\mathfrak{g})$ is holomorphic on a compact set and so constant by Liouville in the same context. I assume that the difference must be in that the functions ""multiplication"" and ""inversion"" take values in $G$ instead of some other space, but I don't understand what we lose.","What's wrong with my understanding of Liouville's theorem? A complex lie group is one where group multiplication and inversion are holomorphic. Supposing $G$ is compact and complex, so is $G \times G$. Then multiplication could be viewed as a holomorphic function on a compact set, so it must be constant valued in $G$ by Liouville's. Then since, in particular, the identity times itself is the identity, so is any element times any other element. But this only makes sense if $G=\{e\}$. I've seen that there is no hesitation in saying that the adjoint representation $\textrm{Ad}: G\to \textrm{Aut}(\mathfrak{g})$ is holomorphic on a compact set and so constant by Liouville in the same context. I assume that the difference must be in that the functions ""multiplication"" and ""inversion"" take values in $G$ instead of some other space, but I don't understand what we lose.",,"['complex-analysis', 'lie-groups']"
98,How do I find singularities and residue?,How do I find singularities and residue?,,Given is $f(z)=\sin(\exp(\frac{1}{z}))$. How do I find singularities and residue? I know that singularity for my function is $z_0=0$. But how do I find residue?,Given is $f(z)=\sin(\exp(\frac{1}{z}))$. How do I find singularities and residue? I know that singularity for my function is $z_0=0$. But how do I find residue?,,['complex-analysis']
99,Contour Integral Relating to the Gamma Function,Contour Integral Relating to the Gamma Function,,"Consider $\oint e^{-|a|z}z^{s-1}$, taken around the contour consisting of the line from $\epsilon$ to $R$, the circular arc of radius $R$ where $arg(z)$ goes from $0$ to $arg(a)$, the line defined by $te^{iarg(a)}$, where $t$ goes from $R$ to $\epsilon$, and the circular arc of radius $\epsilon$ required to close the contour. I want to use this integral to show that $\int_{0}^{\infty}e^{-at}t^{s-1}dt=a^{-s}\Gamma(s)$, where $a$ is in general complex and we have $Re(a)>0$ and $Re(s)>0$. Now, the segment on the real axis tends to the integral equired as $\epsilon$ vanishes and $R$ tends to infinity. The segment on the arc of radius $\epsilon$ is bounded by $K|arg(a)|\epsilon ^{Re(s)}$, where $K$ is constant (by application of the ML bound), and so vanishes as $\epsilon$ vanishes. The integral along the straight segment can be easily evaluated as $-|a|^{s-1}\Gamma(s)$ Also, as this contour encloses no singularities, the total integral is $0$ by Cauchy's Theorem. My issue is that I can't seem to show that the integral along the arc of radius $R$ vanishes. Clearly, to give the correctresult this must be the case, but I just can't seem to show it. It's been suggested to me to use an analog of Jordan's Lemma, but still I can't seem to figure it out. I can't seem to express the integrand in the form $e^{i\alpha z}f(z)$, with $\alpha>0$ as required by the Lemma. I'm also a bit worried about the fact that this isn't a full semicircular arc, and we don't know whether $a$ lies in the upper or lower half plane. Any help would be much appreciated, thanks!","Consider $\oint e^{-|a|z}z^{s-1}$, taken around the contour consisting of the line from $\epsilon$ to $R$, the circular arc of radius $R$ where $arg(z)$ goes from $0$ to $arg(a)$, the line defined by $te^{iarg(a)}$, where $t$ goes from $R$ to $\epsilon$, and the circular arc of radius $\epsilon$ required to close the contour. I want to use this integral to show that $\int_{0}^{\infty}e^{-at}t^{s-1}dt=a^{-s}\Gamma(s)$, where $a$ is in general complex and we have $Re(a)>0$ and $Re(s)>0$. Now, the segment on the real axis tends to the integral equired as $\epsilon$ vanishes and $R$ tends to infinity. The segment on the arc of radius $\epsilon$ is bounded by $K|arg(a)|\epsilon ^{Re(s)}$, where $K$ is constant (by application of the ML bound), and so vanishes as $\epsilon$ vanishes. The integral along the straight segment can be easily evaluated as $-|a|^{s-1}\Gamma(s)$ Also, as this contour encloses no singularities, the total integral is $0$ by Cauchy's Theorem. My issue is that I can't seem to show that the integral along the arc of radius $R$ vanishes. Clearly, to give the correctresult this must be the case, but I just can't seem to show it. It's been suggested to me to use an analog of Jordan's Lemma, but still I can't seem to figure it out. I can't seem to express the integrand in the form $e^{i\alpha z}f(z)$, with $\alpha>0$ as required by the Lemma. I'm also a bit worried about the fact that this isn't a full semicircular arc, and we don't know whether $a$ lies in the upper or lower half plane. Any help would be much appreciated, thanks!",,"['complex-analysis', 'contour-integration']"
