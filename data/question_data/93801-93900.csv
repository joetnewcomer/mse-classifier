,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Elementary proof that $\text{Re}\big(\frac{z^{n+1} - n z - z + n}{(z-1)^2}\big) \ge \frac{n}2$?,Elementary proof that ?,\text{Re}\big(\frac{z^{n+1} - n z - z + n}{(z-1)^2}\big) \ge \frac{n}2,"I would like an elementary proof that the real part of $$ f(z) = \frac{z^{n+1} - n z - z + n}{(z-1)^2} $$ is greater than or equal to $n/2$ for any $z \in \mathbb C$ , $|z| \le 1$ , where $n$ is a natural number.  I can prove this for $|z| = 1$ , and then deduce it is true for $|z| \le 1$ using the maximum principle.  But I am looking for a direct proof. Incidentally $$ \text{Re}(f(e^{i\theta})) = \frac n2 + \frac{\sin^2(n \theta/2)}{2\sin^2(\theta/2)} ,$$ which establishes the result if $|z| = 1$ .","I would like an elementary proof that the real part of is greater than or equal to for any , , where is a natural number.  I can prove this for , and then deduce it is true for using the maximum principle.  But I am looking for a direct proof. Incidentally which establishes the result if ."," f(z) = \frac{z^{n+1} - n z - z + n}{(z-1)^2}  n/2 z \in \mathbb C |z| \le 1 n |z| = 1 |z| \le 1  \text{Re}(f(e^{i\theta})) = \frac n2 + \frac{\sin^2(n \theta/2)}{2\sin^2(\theta/2)} , |z| = 1","['complex-analysis', 'inequality']"
1,"If $\sqrt{a}\sqrt{b}=\sqrt{ab}$ only holds for positive real $a$ & $b$, then why can we say $\sqrt{-a}=\sqrt{-1\cdot a}=\sqrt{-1}\sqrt{a}=i\sqrt{a}$?","If  only holds for positive real  & , then why can we say ?",\sqrt{a}\sqrt{b}=\sqrt{ab} a b \sqrt{-a}=\sqrt{-1\cdot a}=\sqrt{-1}\sqrt{a}=i\sqrt{a},I am a little bit bummed that I have this question as I'm sure it has been asked before (I couldn't find the answer) but... If $\sqrt{a}\sqrt{b} = \sqrt{ab}$ is only true for positive reals $a$ and $b$ . Then what allows us to say the following? $$\sqrt{-a} = \sqrt{-1\cdot a} = \sqrt{-1}\sqrt{a} = i\sqrt{a}$$ I don't know what allows the second equal sign. Is this just convention?,I am a little bit bummed that I have this question as I'm sure it has been asked before (I couldn't find the answer) but... If is only true for positive reals and . Then what allows us to say the following? I don't know what allows the second equal sign. Is this just convention?,\sqrt{a}\sqrt{b} = \sqrt{ab} a b \sqrt{-a} = \sqrt{-1\cdot a} = \sqrt{-1}\sqrt{a} = i\sqrt{a},"['complex-analysis', 'algebra-precalculus', 'radicals', 'radical-equations']"
2,Complex proof of the Fundamental Theorem of Algebra,Complex proof of the Fundamental Theorem of Algebra,,"I am self-studying Stein's Complex Analysis text, in which he has as proof for the Fundamental Theorem of Algebra. For some reason, something about it is just not clicking. Here is his proof itself (here $P$ is a non-constant polynomial): If $P$ has no roots, then $1/P(z)$ is a bounded holomorphic function. To see this, we can of course assume $a_n \neq 0$ and write $$\frac{P(z)}{z^n} = a_n + \Bigl(\frac{a_{n-1}}{z} + \cdots + \frac{a_0}{z^n} \Bigr)$$ whenever $z \neq 0$ . Since each term in the parentheses goes to 0 as $|z| \rightarrow \infty$ we conclude that there exists $R > 0$ so that if $c = |a_n|/2$ , then $$|P(z)| \geq c|z|^n, \quad \text{whenever } |z| > R$$ In particular, $P$ is bounded from below when $|z| > R$ . Since $P$ is continuous and has no roots in the disc $|z| \leq R$ , it is bounded from below in that disk as well, thereby proving our claim. By Liouville's theorem we then conclude that $1/P$ is constant. This contradicts our assumption that $P$ is non-constant and proves the corollary. How does he conclude that there exists $R > 0 $ so that if $c = |a_n|/2$ then $|P(z)| \geq c|z|^n$ for $|z| > R$ ? Why is he choosing $c$ as he did? Also, how does he use this to deduce that $P$ is bounded from below?","I am self-studying Stein's Complex Analysis text, in which he has as proof for the Fundamental Theorem of Algebra. For some reason, something about it is just not clicking. Here is his proof itself (here is a non-constant polynomial): If has no roots, then is a bounded holomorphic function. To see this, we can of course assume and write whenever . Since each term in the parentheses goes to 0 as we conclude that there exists so that if , then In particular, is bounded from below when . Since is continuous and has no roots in the disc , it is bounded from below in that disk as well, thereby proving our claim. By Liouville's theorem we then conclude that is constant. This contradicts our assumption that is non-constant and proves the corollary. How does he conclude that there exists so that if then for ? Why is he choosing as he did? Also, how does he use this to deduce that is bounded from below?","P P 1/P(z) a_n \neq 0 \frac{P(z)}{z^n} = a_n + \Bigl(\frac{a_{n-1}}{z} + \cdots + \frac{a_0}{z^n} \Bigr) z \neq 0 |z| \rightarrow \infty R > 0 c = |a_n|/2 |P(z)| \geq c|z|^n, \quad \text{whenever } |z| > R P |z| > R P |z| \leq R 1/P P R > 0  c = |a_n|/2 |P(z)| \geq c|z|^n |z| > R c P","['complex-analysis', 'polynomials', 'proof-explanation']"
3,Find the number of solutions of the equation $e^z = 2z+1$ in the open unit disc $\{z \in \Bbb C : |z| < 1\}$,Find the number of solutions of the equation  in the open unit disc,e^z = 2z+1 \{z \in \Bbb C : |z| < 1\},"Find the number of solutions of the equation $e^z = 2z+1$ in the open unit disc $\{z \in \Bbb C : |z| < 1\}$ . My Attempt: Let $f(z) = e^z-2z-1$ . Let $A \subseteq \{z \in \Bbb C : |z| < 1\}$ be the solution set. For solution,we will put $f(z) = 0$ . Since $f(0) = 0$ so $0 \in A$ . Therefore $A \neq \varnothing$ . Also let $z = x+iy$ then $f(z) = 0$ gives $$e^{x+iy}-2(x+iy)-1 = 0 \implies e^xe^{iy}-(2x+1)-i(2y) =0\\ \implies e^x(\cos y + i\sin y) = (2x+1) + i(2y)$$ On comparing real and imaginary parts on both sides, we get $$e^x\cos y = 2x + 1,\ e^x\sin y = 2y.$$ On dividing, we get $\tan y = \dfrac{2y}{2x+1}$ . I have no general formula. Please help me.","Find the number of solutions of the equation in the open unit disc . My Attempt: Let . Let be the solution set. For solution,we will put . Since so . Therefore . Also let then gives On comparing real and imaginary parts on both sides, we get On dividing, we get . I have no general formula. Please help me.","e^z = 2z+1 \{z \in \Bbb C : |z| < 1\} f(z) = e^z-2z-1 A \subseteq \{z \in \Bbb C : |z| < 1\} f(z) = 0 f(0) = 0 0 \in A A \neq \varnothing z = x+iy f(z) = 0 e^{x+iy}-2(x+iy)-1 = 0 \implies e^xe^{iy}-(2x+1)-i(2y) =0\\
\implies e^x(\cos y + i\sin y) = (2x+1) + i(2y) e^x\cos y = 2x + 1,\ e^x\sin y = 2y. \tan y = \dfrac{2y}{2x+1}","['complex-analysis', 'roots']"
4,Argument Principle - from J.Bak and D.Newman textbook,Argument Principle - from J.Bak and D.Newman textbook,,"The next example is proposed in the mentioned book, in order to light up the origin for the name of the theorem: $$ \frac{1}{2\pi i} \int_{\gamma} \frac{f'(z)}{f(z)} \mathrm{d}z= \frac{\log f(z(1))-\log(f(z(0)))}{2\pi i} $$ where the parametrisation of $\gamma$ is given by $z(t)$ . Here is what confuses me: since the curve is closed, $z(1)=z(0)$ . Doesn't this imply that the numerator is $0$ ?","The next example is proposed in the mentioned book, in order to light up the origin for the name of the theorem: where the parametrisation of is given by . Here is what confuses me: since the curve is closed, . Doesn't this imply that the numerator is ?","
\frac{1}{2\pi i} \int_{\gamma} \frac{f'(z)}{f(z)} \mathrm{d}z= \frac{\log f(z(1))-\log(f(z(0)))}{2\pi i}
 \gamma z(t) z(1)=z(0) 0","['complex-analysis', 'complex-integration']"
5,Why $P(z)\text{sin}(z)+Q(z)\text{cos}(z)$ has only finitely many non-real zeroes?,Why  has only finitely many non-real zeroes?,P(z)\text{sin}(z)+Q(z)\text{cos}(z),"Consider entire functions (defined and holomorphic on the whole complex plane) of the form: $$f(z)=P(z)\text{sin}(z)+Q(z)\text{cos}(z),$$ where $P(z)$ and $Q(z)$ are polynomials with real coefficients. They seem to always have only finitely many zeros that don't lie on real axis. Namely, there is always some real $M>0$ so that if $|z|>M$ and $f(z)=0$ , then $z\in\mathbb{R}$ . How can I prove this? I tried using Cauchy's integral theorem and integral formula, I tried inverting the function or using logarithms, but none worked. Intuitively, I think the point is that in order to split (""split"" because the zeroes would obviously be symmetrical around the real axis) infinitely many zeroes that $\text{sin}$ and $\text{cos}$ have, you (in some way) have to introduce infinitely many saddles (zeros of the derivative), but polynomials can have only finitely many. Does this argument make sense and how could I turn it into a rigorous proof?","Consider entire functions (defined and holomorphic on the whole complex plane) of the form: where and are polynomials with real coefficients. They seem to always have only finitely many zeros that don't lie on real axis. Namely, there is always some real so that if and , then . How can I prove this? I tried using Cauchy's integral theorem and integral formula, I tried inverting the function or using logarithms, but none worked. Intuitively, I think the point is that in order to split (""split"" because the zeroes would obviously be symmetrical around the real axis) infinitely many zeroes that and have, you (in some way) have to introduce infinitely many saddles (zeros of the derivative), but polynomials can have only finitely many. Does this argument make sense and how could I turn it into a rigorous proof?","f(z)=P(z)\text{sin}(z)+Q(z)\text{cos}(z), P(z) Q(z) M>0 |z|>M f(z)=0 z\in\mathbb{R} \text{sin} \text{cos}",['complex-analysis']
6,Different complex structures of a torus.,Different complex structures of a torus.,,"Consider a complex $\mathbb C/\Lambda$ , once we choose a lattice $\Lambda$ , then the torus is uniquely determined. For example, if we choose different lattices: $\Lambda_1=\mathbb Z\oplus i\mathbb Z$ , $\Lambda_2=\mathbb Z\oplus 2i\mathbb Z$ , and let $T_1=\mathbb C/\Lambda_1$ , $T_2=\mathbb C/\Lambda_2$ , then do $T_1$ and $T_2$ have different complex structures? I know they have the same diffeomorphism sturcture, but why they have different complex structures? Does there exist an intuitive explanation why they have different complex structures?","Consider a complex , once we choose a lattice , then the torus is uniquely determined. For example, if we choose different lattices: , , and let , , then do and have different complex structures? I know they have the same diffeomorphism sturcture, but why they have different complex structures? Does there exist an intuitive explanation why they have different complex structures?",\mathbb C/\Lambda \Lambda \Lambda_1=\mathbb Z\oplus i\mathbb Z \Lambda_2=\mathbb Z\oplus 2i\mathbb Z T_1=\mathbb C/\Lambda_1 T_2=\mathbb C/\Lambda_2 T_1 T_2,"['complex-analysis', 'complex-geometry', 'riemann-surfaces']"
7,Complex analysis integral residuum,Complex analysis integral residuum,,"I am asked to evaluate, principal value of $$\int_{-\infty}^\infty\frac{\cos(x)}{a^2-x^2} \, dx=\pi \frac{\sin (a)}{a},a>0$$ If we start from $$\oint\limits_{C}\frac{e^{iz}}{a^2-z^2}dz,a>0$$ the line $C$ is composed of the half circle $\Gamma$ , pole circles at $-a,a, \gamma_1,\gamma_2$ whose circumferences are ( $r,r_1,r_2$ ),  and a portion of the $x$ -axis. If we use the Cauchy remainder theorem, we get $$ \begin{split} \int_0^\pi \frac{e^{ir\cos \theta -r\sin \theta}}                 {a^2-r^2e^{2-\theta}}                 ire^{i\theta} \, d\theta &+ \int_{-r}^{-a-r_2} f(x) \, dx  + J_2 \\ &+ \int_{-a+r_2}^{a-r_1} f(x) \, dx  + J_1  + \int_{a+r_1}^r f(x) \, dx  = 0 \end{split} $$ Since $\left|\int_0^\pi \frac{e^{ir\cos \theta -rsin \theta}}{a^2-r^2 e^{2-\theta}}ire^{i\theta} \, d\theta\right|\leq{\frac{\pi r}{r^2-a^2},(r>a)}$ We get $$\lim_{n \to \infty}\int_0^\pi \frac{e^{ir\cos \theta -r\sin \theta}}{a^2-r^2e^{2-\theta}}ire^{i\theta} \, d\theta=0$$ Evaluating residuum at $J_{1}$ and $J_{2}$ we get $$J_1=\operatorname{Res}f(a)=\lim_{x \to a}(a-x)\frac{e^{ix}}{(a-x)(a+x)} =\frac{e^{ia}}{2a}$$ and $$J_2= \operatorname{Res}f(-a)=\lim_{x \to -a}(a+x)\frac{e^{ix}}{(a-x)(a+x)}=\frac{e^{-ia}}{2a}$$ In my book the author got $J_{1}=\frac{\pi i}{2a}e^{ia}\land J_2=-\frac{\pi i}{2a} e^{-ia}$ Where does the $\pi i$ come from ? also, why - in the second one? Is it because the residuum is at $-a$ ?  Then, adding those two gives us the result, but still, where does $\pi$ come from?","I am asked to evaluate, principal value of If we start from the line is composed of the half circle , pole circles at whose circumferences are ( ),  and a portion of the -axis. If we use the Cauchy remainder theorem, we get Since We get Evaluating residuum at and we get and In my book the author got Where does the come from ? also, why - in the second one? Is it because the residuum is at ?  Then, adding those two gives us the result, but still, where does come from?","\int_{-\infty}^\infty\frac{\cos(x)}{a^2-x^2} \, dx=\pi \frac{\sin (a)}{a},a>0 \oint\limits_{C}\frac{e^{iz}}{a^2-z^2}dz,a>0 C \Gamma -a,a, \gamma_1,\gamma_2 r,r_1,r_2 x 
\begin{split}
\int_0^\pi \frac{e^{ir\cos \theta -r\sin \theta}}
                {a^2-r^2e^{2-\theta}}
                ire^{i\theta} \, d\theta
&+ \int_{-r}^{-a-r_2} f(x) \, dx
 + J_2 \\
&+ \int_{-a+r_2}^{a-r_1} f(x) \, dx
 + J_1
 + \int_{a+r_1}^r f(x) \, dx
 = 0
\end{split}
 \left|\int_0^\pi \frac{e^{ir\cos \theta -rsin \theta}}{a^2-r^2 e^{2-\theta}}ire^{i\theta} \, d\theta\right|\leq{\frac{\pi r}{r^2-a^2},(r>a)} \lim_{n \to \infty}\int_0^\pi \frac{e^{ir\cos \theta -r\sin \theta}}{a^2-r^2e^{2-\theta}}ire^{i\theta} \, d\theta=0 J_{1} J_{2} J_1=\operatorname{Res}f(a)=\lim_{x \to a}(a-x)\frac{e^{ix}}{(a-x)(a+x)} =\frac{e^{ia}}{2a} J_2= \operatorname{Res}f(-a)=\lim_{x \to -a}(a+x)\frac{e^{ix}}{(a-x)(a+x)}=\frac{e^{-ia}}{2a} J_{1}=\frac{\pi i}{2a}e^{ia}\land J_2=-\frac{\pi i}{2a} e^{-ia} \pi i -a \pi","['complex-analysis', 'cauchy-principal-value']"
8,Prove $\lim_{z \to 0} \frac{z}{\overline{z}}$ doesn't exist using $\varepsilon-\delta$.,Prove  doesn't exist using .,\lim_{z \to 0} \frac{z}{\overline{z}} \varepsilon-\delta,"I'm trying to prove that the limit $$ \lim_{z \to 0} \frac{z}{\overline{z}} \quad \qquad z \neq 0 $$ doesn't exist. Up to this point, the only definition of a limit for complex functions I know is as that $\lim_{z \to w} f(z) = L$ if and only if $$ \forall \varepsilon >0, \ \exists \delta >0 \text{ such that if }\lvert z-w \rvert < \delta \implies \lvert f(z)- L\rvert< \varepsilon $$ So I wanted to solve my problem using only this. I know that I could use paths and show that approaching $0$ in different ways gives different limits, but since I don't know how to rigorously justify this I chose to avoid it. My idea was to argue by contradiction. So I would assume that the limit existed and that it was equal to some complex number $L$ , and then I would show that this assumption would lead to problems. My attempt The first thing I notice is that I can simplify the function as follows $$ \lim_{z \to 0} \frac{z}{\overline{z}} = \lim_{z \to 0} \frac{z^2}{|z|^2} = \lim_{z \to 0} \frac{\left(re^{i\theta}\right)^2}{r^2}= \lim_{z \to 0} e^{i(2\theta)} $$ where $\theta = \arg(z)$ is a function of $z$ . Now, since we assume that the limit does exist and that it's equal to $L \in \mathbb{C}$ , we can write $L$ as $$ L = r' e^{i \theta'} $$ where $r'\ge 0$ (i.e. $r' \nless 0$ ) and $\theta'$ are some fixed real numbers. Since we're assuming that the limit exists, if I choose the value $\varepsilon =1 $ I know there exists a $\delta$ such that $\lvert z-0 \rvert < \delta \implies \lvert e^{i(2\theta)}- L\rvert< \varepsilon$ . If I then choose to analyze the complex number $ z =  \frac{\delta}{2} e^{i\left(\frac{\theta' + \pi }{2}\right)}$ I see that $$ \lvert z -0 \rvert = \Biggl\lvert\frac{\delta}{2} e^{i\left(\frac{\theta' + \pi }{2}\right)} -0 \Biggr\rvert =  \Bigl\lvert\frac{\delta}{2} \Bigr\rvert \cdot \Biggl\lvert e^{i\left(\frac{\theta' + \pi }{2}\right)}\Biggl\lvert = \frac{\delta}{2} < \delta $$ which means that for $\theta = \arg\left( \frac{\delta}{2} e^{i\left(\frac{\theta' + \pi }{2}\right)}\right)$ it should be the case that $\lvert e^{i(2\theta)}- L\rvert< \varepsilon$ , but here we see that \begin{align} \Bigl\lvert e^{i(2\theta)} - L\Bigr\rvert &=  \Bigl\lvert  e^{i\left(2\frac{\theta' + \pi }{2}\right)} - r' e^{i\theta}\Bigr\rvert = \Bigl\lvert e^{i\theta'}\left( e^{i\pi}  - r'\right) \Bigl\lvert \\ &= \bigl\lvert e^{i\theta'}\bigl\lvert \cdot \bigl\lvert-\left( 1  + r'\right)\bigl\lvert = 1 + r' \nless 1  = \varepsilon  \end{align} where we get the contradiction we wanted. The idea of my attempt was that I noticed that the function always outputted numbers on the unit circle, which meant that even though I could find a $z$ really close to $0$ , the output couldn't get as close to some limit $L$ as it wanted since it had to be on the unit circle. I'm not sure if my proof used the contradiction correctly, more specifically, I don't know if my final equation implies that my original assumption was wrong or if I can conclude anything from it at all. I'm also unsure if there's a problem with me choosing a specific $z$ which depends on $\delta$ . Could anyone tell me if my attempt is correct? And if it isn't, could someone tell me how I could make a correct proof? Thank you very much!","I'm trying to prove that the limit doesn't exist. Up to this point, the only definition of a limit for complex functions I know is as that if and only if So I wanted to solve my problem using only this. I know that I could use paths and show that approaching in different ways gives different limits, but since I don't know how to rigorously justify this I chose to avoid it. My idea was to argue by contradiction. So I would assume that the limit existed and that it was equal to some complex number , and then I would show that this assumption would lead to problems. My attempt The first thing I notice is that I can simplify the function as follows where is a function of . Now, since we assume that the limit does exist and that it's equal to , we can write as where (i.e. ) and are some fixed real numbers. Since we're assuming that the limit exists, if I choose the value I know there exists a such that . If I then choose to analyze the complex number I see that which means that for it should be the case that , but here we see that where we get the contradiction we wanted. The idea of my attempt was that I noticed that the function always outputted numbers on the unit circle, which meant that even though I could find a really close to , the output couldn't get as close to some limit as it wanted since it had to be on the unit circle. I'm not sure if my proof used the contradiction correctly, more specifically, I don't know if my final equation implies that my original assumption was wrong or if I can conclude anything from it at all. I'm also unsure if there's a problem with me choosing a specific which depends on . Could anyone tell me if my attempt is correct? And if it isn't, could someone tell me how I could make a correct proof? Thank you very much!","
\lim_{z \to 0} \frac{z}{\overline{z}} \quad \qquad z \neq 0
 \lim_{z \to w} f(z) = L 
\forall \varepsilon >0, \ \exists \delta >0 \text{ such that if }\lvert z-w \rvert < \delta \implies \lvert f(z)- L\rvert< \varepsilon
 0 L 
\lim_{z \to 0} \frac{z}{\overline{z}} = \lim_{z \to 0} \frac{z^2}{|z|^2} = \lim_{z \to 0} \frac{\left(re^{i\theta}\right)^2}{r^2}= \lim_{z \to 0} e^{i(2\theta)}
 \theta = \arg(z) z L \in \mathbb{C} L 
L = r' e^{i \theta'}
 r'\ge 0 r' \nless 0 \theta' \varepsilon =1  \delta \lvert z-0 \rvert < \delta \implies \lvert e^{i(2\theta)}- L\rvert< \varepsilon  z =  \frac{\delta}{2} e^{i\left(\frac{\theta' + \pi }{2}\right)} 
\lvert z -0 \rvert = \Biggl\lvert\frac{\delta}{2} e^{i\left(\frac{\theta' + \pi }{2}\right)} -0 \Biggr\rvert =  \Bigl\lvert\frac{\delta}{2} \Bigr\rvert \cdot \Biggl\lvert e^{i\left(\frac{\theta' + \pi }{2}\right)}\Biggl\lvert = \frac{\delta}{2} < \delta
 \theta = \arg\left( \frac{\delta}{2} e^{i\left(\frac{\theta' + \pi }{2}\right)}\right) \lvert e^{i(2\theta)}- L\rvert< \varepsilon \begin{align}
\Bigl\lvert e^{i(2\theta)} - L\Bigr\rvert &=  \Bigl\lvert  e^{i\left(2\frac{\theta' + \pi }{2}\right)} - r' e^{i\theta}\Bigr\rvert = \Bigl\lvert e^{i\theta'}\left( e^{i\pi}  - r'\right) \Bigl\lvert \\
&= \bigl\lvert e^{i\theta'}\bigl\lvert \cdot \bigl\lvert-\left( 1  + r'\right)\bigl\lvert = 1 + r' \nless 1  = \varepsilon 
\end{align} z 0 L z \delta","['complex-analysis', 'limits', 'complex-numbers', 'solution-verification', 'epsilon-delta']"
9,The Hankel Integral Representation for $\Gamma(z)$,The Hankel Integral Representation for,\Gamma(z),"I am trying to understand some details hidden in the proof of the Hankel integral representation for the gamma function: $$\frac{1}{\Gamma(z)} = -\frac{1}{2\pi i} \int_{\mathcal{H}} (-t)^{-z} e^{-t} dt$$ for all $z \in \mathbb{C}$ . Here $\mathcal{H}$ denotes the Hankel contour: $\mathcal{H} = [i + \infty,i] + \mathcal{H}_{sc} + [-i,-i + \infty]$ , where $\mathcal{H}_{sc}$ joins $i$ with $-i$ along a positively oriented semicircle centered at $0$ . A typical approach to the proof, as far as I understand it, goes as follows: Cut the plane along the positive real axis and choose a fixed branch of the multifunction $(-t)^{-z}$ by taking its principal branch for negative real $t$ , and by continuing this branch analytically to the cut plane. Let $\varepsilon\mathcal{H}$ denote $\mathcal{H}$ scaled by $\varepsilon$ , i.e., after applying the transformation $z \mapsto \varepsilon z$ . The integral along $\varepsilon\mathcal{H}$ is then said to be the same as the one along $\mathcal{H}$ by Cauchy's theorem. This is a first step that I find unclear: I understand that the integrand is analytic in $\mathbb{C} \setminus [0,\infty)$ ; however I do not know about any deformation theorem for improper contours. Could someone describe a rigorous argument that is used here? Assume $z < 0$ and take $\varepsilon \to 0$ . The integral can then be decomposed into three integrals, two of which can be manipulated to obtain an integral much alike the usual integral representation of $\Gamma(1-z)$ for $\mathrm{Re}(1-z) > 0$ , while the remaining one can be shown to be negligible when $\varepsilon \to 0$ , thanks to the assumption $z < 0$ . The Hankel representation is then proved for $z < 0$ . Finally, the result is extended to the whole complex plain via analytic continuation. This is a second step that I find unclear , as it can only be performed if one knows that $$I(z) = \int_{\mathcal{H}} (-t)^{-z} e^{-t} dt$$ is an analytic function of $z$ . This property is usually qualified as obvious. Nevertheless, I have no idea about why it is obvious. Could someone explain the rigorous arguments needed to perform the two critical steps mentioned above? I would also be very grateful for pointers to literature that treats the Hankel representation rigorously (the treatements that I have found seem more-or-less sketchy to me). Many thanks in advance.","I am trying to understand some details hidden in the proof of the Hankel integral representation for the gamma function: for all . Here denotes the Hankel contour: , where joins with along a positively oriented semicircle centered at . A typical approach to the proof, as far as I understand it, goes as follows: Cut the plane along the positive real axis and choose a fixed branch of the multifunction by taking its principal branch for negative real , and by continuing this branch analytically to the cut plane. Let denote scaled by , i.e., after applying the transformation . The integral along is then said to be the same as the one along by Cauchy's theorem. This is a first step that I find unclear: I understand that the integrand is analytic in ; however I do not know about any deformation theorem for improper contours. Could someone describe a rigorous argument that is used here? Assume and take . The integral can then be decomposed into three integrals, two of which can be manipulated to obtain an integral much alike the usual integral representation of for , while the remaining one can be shown to be negligible when , thanks to the assumption . The Hankel representation is then proved for . Finally, the result is extended to the whole complex plain via analytic continuation. This is a second step that I find unclear , as it can only be performed if one knows that is an analytic function of . This property is usually qualified as obvious. Nevertheless, I have no idea about why it is obvious. Could someone explain the rigorous arguments needed to perform the two critical steps mentioned above? I would also be very grateful for pointers to literature that treats the Hankel representation rigorously (the treatements that I have found seem more-or-less sketchy to me). Many thanks in advance.","\frac{1}{\Gamma(z)} = -\frac{1}{2\pi i} \int_{\mathcal{H}} (-t)^{-z} e^{-t} dt z \in \mathbb{C} \mathcal{H} \mathcal{H} = [i + \infty,i] + \mathcal{H}_{sc} + [-i,-i + \infty] \mathcal{H}_{sc} i -i 0 (-t)^{-z} t \varepsilon\mathcal{H} \mathcal{H} \varepsilon z \mapsto \varepsilon z \varepsilon\mathcal{H} \mathcal{H} \mathbb{C} \setminus [0,\infty) z < 0 \varepsilon \to 0 \Gamma(1-z) \mathrm{Re}(1-z) > 0 \varepsilon \to 0 z < 0 z < 0 I(z) = \int_{\mathcal{H}} (-t)^{-z} e^{-t} dt z","['complex-analysis', 'improper-integrals', 'special-functions', 'contour-integration', 'gamma-function']"
10,Find all analytic functions $f(z)$ on the open unit disk that satisfy $|f(z)|\leq2^{-\frac{1}{|z|}}$,Find all analytic functions  on the open unit disk that satisfy,f(z) |f(z)|\leq2^{-\frac{1}{|z|}},"I am required to find all analytic functions $f(z)$ defined on the open unit disk $D=\{z\in\mathbb{C}\mid |z|<1\}$ that satisfy the following inequality: $$\forall z\in D\setminus\{0\}:|f(z)|\leq2^{-\frac{1}{|z|}}$$ I found that the constant function $f(z)\equiv0$ is an option. I suspect this is the only option. I noticed that $f(z)$ is bounded on $D$ according to the inequality; However this is actually not an additional information since I already know that $f(z)$ is bounded on $\bar{D}$ , as it is analytic (thus continuous). Something about the inequality seems odd to me. I feel that there's nothing special about the function on the RHS and this is merely a specific way to state something more general about $f(z)$ . I may be wrong. Usually I solve this kind of problems using Liouville's Theorem , however $f(z)$ is not entire here so this is not an option. Thank you!","I am required to find all analytic functions defined on the open unit disk that satisfy the following inequality: I found that the constant function is an option. I suspect this is the only option. I noticed that is bounded on according to the inequality; However this is actually not an additional information since I already know that is bounded on , as it is analytic (thus continuous). Something about the inequality seems odd to me. I feel that there's nothing special about the function on the RHS and this is merely a specific way to state something more general about . I may be wrong. Usually I solve this kind of problems using Liouville's Theorem , however is not entire here so this is not an option. Thank you!",f(z) D=\{z\in\mathbb{C}\mid |z|<1\} \forall z\in D\setminus\{0\}:|f(z)|\leq2^{-\frac{1}{|z|}} f(z)\equiv0 f(z) D f(z) \bar{D} f(z) f(z),['complex-analysis']
11,A complex top form determine complex structure [closed],A complex top form determine complex structure [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Let $M$ is a $2n$ -dimensional real manifold and $\Omega\in \Lambda^{n}(T^{*}M\otimes \mathbb{C})$ be a complex top form. How does one determine a complex structure on the tangent space $TM$ ?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Let is a -dimensional real manifold and be a complex top form. How does one determine a complex structure on the tangent space ?",M 2n \Omega\in \Lambda^{n}(T^{*}M\otimes \mathbb{C}) TM,"['complex-analysis', 'differential-geometry', 'complex-geometry']"
12,Do all coefficients in a Laurent series need to be real?,Do all coefficients in a Laurent series need to be real?,,"Suppose we are given $ f(x)$ holomorphic in $ \Bbb C \setminus\{0\}$ that has Laurent series around $0$ and $ f(x)\in \Bbb R $ for all $ x \in \Bbb R $ , $x\ne0$ . Does it imply that all coefficients in the Laurent series need to be real? How can I prove it? Any hints would be appreciated.","Suppose we are given holomorphic in that has Laurent series around and for all , . Does it imply that all coefficients in the Laurent series need to be real? How can I prove it? Any hints would be appreciated.", f(x)  \Bbb C \setminus\{0\} 0  f(x)\in \Bbb R   x \in \Bbb R  x\ne0,"['complex-analysis', 'laurent-series', 'holomorphic-functions']"
13,anomaly in elementary complex analysis,anomaly in elementary complex analysis,,"To Do Given that $\;\displaystyle w_1 \;=\; \left(2 + \sqrt{\sqrt{2}}\sqrt{2 + \sqrt{2}}\right) - i\left(1 + \sqrt{\sqrt{2}}\sqrt{2 - \sqrt{2}}\right)$ . 1. Derive the two square roots of $w_1$ . 2. Illustrate the general method of deriving the square roots of such a messy complex number as $w_1.$ Context In ""An Introduction to Complex Function Theory"", 1991, by Bruce Palka, problem 4.14.(iii), p26 specifies : find all roots of $\;z^4 + (-4+2i)z^2 - 1 = 0.$ Preliminary to this problem, it is established that : (a) Arg( $z$ ) is the unique angle $\;\alpha \in (-\pi,\pi]\;$ such that $\;z = |z|\left[\cos(\alpha) + i\sin(\alpha)\right].$ (b) Taking $\;\beta = (\alpha/2), \;\sqrt{z} \;=\;  \pm \sqrt{|z|}\left[\cos(\beta) + i\sin(\beta)\right].$ (c) $\displaystyle \cos(\beta) \;=\; \sqrt{\frac{1 + \cos(\alpha)}{2}}, \;\;\sin(\beta) \;=\; \sqrt{\frac{1 - \cos(\alpha)}{2}}.$ (d) $\;az^2 + bz + c = 0\;$ will have roots $\displaystyle\;\frac{1}{2a}\left(-b \pm \sqrt{b^2 - 4ac}\right).$ My Attack Of Problem (iii) My first approach was : 1. let $\;w = z^2,\;$ 2. interpret problem (iii) as a quadratic equation in $w$ . 3. use the preliminary concepts to derive the two solutions $w_1$ and $w_2.$ 4. take the two square roots of both $w_1$ and $w_2,\;$ to derive the 4  roots $\;z_1, z_2, z_3, z_4.$ One of the roots to problem (iii) interpreted as a quadratic equation, $w_1,$ is as identified in the To Do section at the start of this query. However, after identifying $w_1$ and assigning $\;\alpha \;=\; \text{Arg}(w_1), \;$ I was unable to compute $\;\cos(\alpha)\;$ or $\;\sin(\alpha).\;$ Since Palka's preliminary concepts didn't seem to help here, I  temporarily abandoned this approach. My second approach, which succeeded, and was probably the intended approach , was : 1. factor $\;z^4 + (-4+2i)z^2 - 1 \;=\; (z^2 + 2z + i) \times (z^2 - 2z + i).$ 2. solve each of the two resulting quadratic equations. Solving both of these quadratic equations, I generated four roots,  one of which was $\displaystyle z_2 \;=\;  \left(-1 - \frac{1}{2}\sqrt{\sqrt{2}}\sqrt{2 + \sqrt{2}}\right) \;+\; i \, \left(\frac{1}{2}\sqrt{\sqrt{2}}\sqrt{2 - \sqrt{2}}\right).$ After manually verifying that $z_2$ did satisfy problem (iii), I noticed that $\;(z_2)^2 = w_1,\;$ which provided a separate verification of $z_2.$ However, I feel that I should not have had to abandon the first approach.  I think that there should be a way of $\underline{\text{deriving}}$ that $z_2$ is one of the square roots of $w_1.$ My tangential approach My 2nd approach in the My Attack Of Problem (iii) section of this query may be re-interpreted as a tangential algorithm for identifying the square roots of $w_1.$ This means that given any messy complex  expression $w$ , one might identify the square roots of $w$ as follows: Identify (for example) a fourth degree equation of the form $\;[E]\;\;az^4 + bz^2 + c = 0.\;$ Interpret this as a quadratic equation in $z^2,$ one of whose roots is $w.$ As in my 2nd approach in the My Attack Of Problem (iii) section, $\;E,\;$ must be readily factorable into two 2nd degree polynomials. Further, each of the two polynomials must be readily solvable. This means that for each polynomial, its resultant expression $\;\sqrt{b^2 - 4ac},\;$ must be readily computable. This means that the sine and cosine of the corresponding principal Argument must be readily computable. Note:  Since there is flexibility in choosing any equation $\;E,\;$ one of whose roots is $w,$ there needs to be guidelines for designing $\;E,\;$ so that is readily factorable into two 2nd degree polynomials, each of whom is readily solvable. My Related Questions I am way out of my depth here, and request responses from professional mathematicians. Ignoring my tangential approach, is there a standard method of computing the square roots of such a messy complex number as $w_1.$ Is my tangential approach viable?  Is it a standard method?  Are there guidelines for designing the corresponding helper equation $\;E$ ?","To Do Given that . 1. Derive the two square roots of . 2. Illustrate the general method of deriving the square roots of such a messy complex number as Context In ""An Introduction to Complex Function Theory"", 1991, by Bruce Palka, problem 4.14.(iii), p26 specifies : find all roots of Preliminary to this problem, it is established that : (a) Arg( ) is the unique angle such that (b) Taking (c) (d) will have roots My Attack Of Problem (iii) My first approach was : 1. let 2. interpret problem (iii) as a quadratic equation in . 3. use the preliminary concepts to derive the two solutions and 4. take the two square roots of both and to derive the 4  roots One of the roots to problem (iii) interpreted as a quadratic equation, is as identified in the To Do section at the start of this query. However, after identifying and assigning I was unable to compute or Since Palka's preliminary concepts didn't seem to help here, I  temporarily abandoned this approach. My second approach, which succeeded, and was probably the intended approach , was : 1. factor 2. solve each of the two resulting quadratic equations. Solving both of these quadratic equations, I generated four roots,  one of which was After manually verifying that did satisfy problem (iii), I noticed that which provided a separate verification of However, I feel that I should not have had to abandon the first approach.  I think that there should be a way of that is one of the square roots of My tangential approach My 2nd approach in the My Attack Of Problem (iii) section of this query may be re-interpreted as a tangential algorithm for identifying the square roots of This means that given any messy complex  expression , one might identify the square roots of as follows: Identify (for example) a fourth degree equation of the form Interpret this as a quadratic equation in one of whose roots is As in my 2nd approach in the My Attack Of Problem (iii) section, must be readily factorable into two 2nd degree polynomials. Further, each of the two polynomials must be readily solvable. This means that for each polynomial, its resultant expression must be readily computable. This means that the sine and cosine of the corresponding principal Argument must be readily computable. Note:  Since there is flexibility in choosing any equation one of whose roots is there needs to be guidelines for designing so that is readily factorable into two 2nd degree polynomials, each of whom is readily solvable. My Related Questions I am way out of my depth here, and request responses from professional mathematicians. Ignoring my tangential approach, is there a standard method of computing the square roots of such a messy complex number as Is my tangential approach viable?  Is it a standard method?  Are there guidelines for designing the corresponding helper equation ?","\;\displaystyle w_1 \;=\;
\left(2 + \sqrt{\sqrt{2}}\sqrt{2 + \sqrt{2}}\right)
- i\left(1 + \sqrt{\sqrt{2}}\sqrt{2 - \sqrt{2}}\right) w_1 w_1. \;z^4 + (-4+2i)z^2 - 1 = 0. z \;\alpha \in (-\pi,\pi]\; \;z = |z|\left[\cos(\alpha) + i\sin(\alpha)\right]. \;\beta = (\alpha/2), \;\sqrt{z} \;=\; 
\pm \sqrt{|z|}\left[\cos(\beta) + i\sin(\beta)\right]. \displaystyle \cos(\beta) \;=\; \sqrt{\frac{1 + \cos(\alpha)}{2}},
\;\;\sin(\beta) \;=\; \sqrt{\frac{1 - \cos(\alpha)}{2}}. \;az^2 + bz + c = 0\; \displaystyle\;\frac{1}{2a}\left(-b \pm \sqrt{b^2 - 4ac}\right). \;w = z^2,\; w w_1 w_2. w_1 w_2,\; \;z_1, z_2, z_3, z_4. w_1, w_1 \;\alpha \;=\; \text{Arg}(w_1), \; \;\cos(\alpha)\; \;\sin(\alpha).\; \;z^4 + (-4+2i)z^2 - 1 \;=\; (z^2 + 2z + i) \times (z^2 - 2z + i). \displaystyle z_2 \;=\; 
\left(-1 - \frac{1}{2}\sqrt{\sqrt{2}}\sqrt{2 + \sqrt{2}}\right)
\;+\; i \, \left(\frac{1}{2}\sqrt{\sqrt{2}}\sqrt{2 - \sqrt{2}}\right). z_2 \;(z_2)^2 = w_1,\; z_2. \underline{\text{deriving}} z_2 w_1. w_1. w w \;[E]\;\;az^4 + bz^2 + c = 0.\; z^2, w. \;E,\; \;\sqrt{b^2 - 4ac},\; \;E,\; w, \;E,\; w_1. \;E",['complex-analysis']
14,Real power series absolutely converges. Does complex series converge too?,Real power series absolutely converges. Does complex series converge too?,,"Consider a function $f: (0,1) \to \mathbb R$ defined as the following power series: $$ f(x) = \sum_{k=0}^\infty a_k (1-x)^k. $$ This series has $a_k > 0$ and is assumed to converge point-wise for all $x \in (0,1)$. My question is: If $x$ in the above expression is replaced by a complex variable $z$, can it be assured that $\sum_{k=0}^\infty a_k (1-z)^k$ converges for all $z$ with $|z-1|<1$? Here is my attempt at a proof , but I'm not sure it is correct. The series for $x \in (0,1)$ is absolutely convergent in $(0,1)$ by the assumptions. That is, $\sum_{k=0}^\infty a_k (1-x)^k = \sum_{k=0}^\infty a_k |1-x|^k$ is finite for all such $x$. Replacing $x$ by any complex $z$ such that $|1-z| = |1-x|$, the resulting $\sum_{k=0}^\infty a_k |1-z|^k$ converges to the same value. This implies that the complex series $\sum_{k=0}^\infty a_k (1-z)^k$ (absolutely) converges. Since this holds for any $x \in (0,1)$, the complex series converges for any $z$ in the disk $|z-1|<1$. Are all my steps correct ? If so, is there any shorter proof ? If not, is there a counterexample ?","Consider a function $f: (0,1) \to \mathbb R$ defined as the following power series: $$ f(x) = \sum_{k=0}^\infty a_k (1-x)^k. $$ This series has $a_k > 0$ and is assumed to converge point-wise for all $x \in (0,1)$. My question is: If $x$ in the above expression is replaced by a complex variable $z$, can it be assured that $\sum_{k=0}^\infty a_k (1-z)^k$ converges for all $z$ with $|z-1|<1$? Here is my attempt at a proof , but I'm not sure it is correct. The series for $x \in (0,1)$ is absolutely convergent in $(0,1)$ by the assumptions. That is, $\sum_{k=0}^\infty a_k (1-x)^k = \sum_{k=0}^\infty a_k |1-x|^k$ is finite for all such $x$. Replacing $x$ by any complex $z$ such that $|1-z| = |1-x|$, the resulting $\sum_{k=0}^\infty a_k |1-z|^k$ converges to the same value. This implies that the complex series $\sum_{k=0}^\infty a_k (1-z)^k$ (absolutely) converges. Since this holds for any $x \in (0,1)$, the complex series converges for any $z$ in the disk $|z-1|<1$. Are all my steps correct ? If so, is there any shorter proof ? If not, is there a counterexample ?",,"['calculus', 'real-analysis', 'complex-analysis', 'convergence-divergence', 'power-series']"
15,Good Books on Complex Multiplication (on Elliptic Curves),Good Books on Complex Multiplication (on Elliptic Curves),,"I don't know anything yet about Complex Multiplication (on elliptic Curves). Do you know good introductory books on the Matter? I'm especially looking for a proof that the following terms are algebraic integers whenever $\tau$ is a quadratic irrationality: $$\frac{E_4(\tau)}{\eta^8(\tau)},\quad\frac{E_6(\tau)}{\eta^{12}(\tau)}\quad\text{and}\quad\sqrt{D}\cdot\frac{E_2(\tau)-\frac{3}{\pi\Im(\tau)}}{\eta^4(\tau)}$$ Here $\eta$ denotes the Dedekind $\eta$-Function, $E_k$ are the Eisenstein series of weight $k$, and $D=B^2-4AC$ where $A\tau^2+B\tau+C=0$ Edit: As @Mathmo123 commented (Thank you!!!), the first expression is a root of the polynomial $P(X)=X^3-1728J(\tau)$ and the second is a root of $Q(X)=X^2-1728+1728J(\tau)$, where $1728J(\tau)\in\mathbb Z$. Thus it only remains to prove that the third expression is an algebraic integer. Edit: I verified numerically that the sixth power of the third expression is integral for all Discriminants with class number $1$, but I don't see how I can prove it. Unfortunately, I couldn't find anything in the books mentioned by @gandalf61 or by @Mathmo123 ... -> but this is another topic, moved to another question here .","I don't know anything yet about Complex Multiplication (on elliptic Curves). Do you know good introductory books on the Matter? I'm especially looking for a proof that the following terms are algebraic integers whenever $\tau$ is a quadratic irrationality: $$\frac{E_4(\tau)}{\eta^8(\tau)},\quad\frac{E_6(\tau)}{\eta^{12}(\tau)}\quad\text{and}\quad\sqrt{D}\cdot\frac{E_2(\tau)-\frac{3}{\pi\Im(\tau)}}{\eta^4(\tau)}$$ Here $\eta$ denotes the Dedekind $\eta$-Function, $E_k$ are the Eisenstein series of weight $k$, and $D=B^2-4AC$ where $A\tau^2+B\tau+C=0$ Edit: As @Mathmo123 commented (Thank you!!!), the first expression is a root of the polynomial $P(X)=X^3-1728J(\tau)$ and the second is a root of $Q(X)=X^2-1728+1728J(\tau)$, where $1728J(\tau)\in\mathbb Z$. Thus it only remains to prove that the third expression is an algebraic integer. Edit: I verified numerically that the sixth power of the third expression is integral for all Discriminants with class number $1$, but I don't see how I can prove it. Unfortunately, I couldn't find anything in the books mentioned by @gandalf61 or by @Mathmo123 ... -> but this is another topic, moved to another question here .",,"['complex-analysis', 'algebraic-number-theory', 'analytic-number-theory', 'elliptic-curves', 'modular-forms']"
16,Construction a harmonic function,Construction a harmonic function,,"Suppose $f:\mathbb{R}\to\mathbb{R}$ is a smooth, positive, bounded function on $\mathbb{R}$. Construct a real-valued continuous function $u$ on $\overline{\mathbb{H}}$ which are harmonic on $\mathbb{H}$, such that $u|_{\mathbb{R}} = f$ and $u(i) = 0$, where $\mathbb{H}$ is $\{z : Im(z) > 0\}$ } I don't know how to construct, and I also feel confused: Suppose $u$ exists, then we consider the function $u\circ h$, where $h=\frac{i(w+1)}{1-w}$. So $u\circ h$ is defined on $D$ with positive value on $\partial D$, and $u\circ h(0)=u(i)=0$, then by mean value property, we deduce a contradiction.","Suppose $f:\mathbb{R}\to\mathbb{R}$ is a smooth, positive, bounded function on $\mathbb{R}$. Construct a real-valued continuous function $u$ on $\overline{\mathbb{H}}$ which are harmonic on $\mathbb{H}$, such that $u|_{\mathbb{R}} = f$ and $u(i) = 0$, where $\mathbb{H}$ is $\{z : Im(z) > 0\}$ } I don't know how to construct, and I also feel confused: Suppose $u$ exists, then we consider the function $u\circ h$, where $h=\frac{i(w+1)}{1-w}$. So $u\circ h$ is defined on $D$ with positive value on $\partial D$, and $u\circ h(0)=u(i)=0$, then by mean value property, we deduce a contradiction.",,"['complex-analysis', 'harmonic-analysis', 'harmonic-functions']"
17,We can always find a projective line $L\subset\mathbb{CP^2}$ intersecting degree $d$ projective curve at $d$ distinct points,We can always find a projective line  intersecting degree  projective curve at  distinct points,L\subset\mathbb{CP^2} d d,"Let $X$ be a smooth projective plane curve$\{ [Z_0, Z_1, Z_2]\in \mathbb{CP^2}\ \vert \ p(Z_0, Z_1, Z_2) = 0 \}$ defined by non-singular homogeneous polynomial $p$ of degree $d$. Then there exists a projective line $L\subset\mathbb{CP^2}$ intersecting $X$ at $d$ distinct points. Is there a way to prove the above statement using only elementary knowledge of Riemann surfaces? I do not know much of algebraic geometry.","Let $X$ be a smooth projective plane curve$\{ [Z_0, Z_1, Z_2]\in \mathbb{CP^2}\ \vert \ p(Z_0, Z_1, Z_2) = 0 \}$ defined by non-singular homogeneous polynomial $p$ of degree $d$. Then there exists a projective line $L\subset\mathbb{CP^2}$ intersecting $X$ at $d$ distinct points. Is there a way to prove the above statement using only elementary knowledge of Riemann surfaces? I do not know much of algebraic geometry.",,"['complex-analysis', 'algebraic-geometry', 'complex-geometry', 'riemann-surfaces']"
18,What is an intuitive explanation of a complex slope of a real line?,What is an intuitive explanation of a complex slope of a real line?,,"On thinking about what real slopes and imaginary slopes are I have become a bit confused. We have one coordinate $x$-$y$-$z$ system that we use to specify position. I suppose the coordinates in this system will have only real values. But then again in the argand plane the $x$ axis is real and $y$ axis is imaginary. What is a complex slope of a real line? How do we find it?My book has this sentence: ""If $A(z_1)$ and $B(z_2)$ are two points in the argand plane then the complex slope of line $AB$ is $\frac{z_1-z_2}{\bar z_1-\bar z_2}$."" Where did they get this from? I'm not very sure whether this formula is correct either.  I do not have extensive knowledge of complex numbers, I have just studied the basics.","On thinking about what real slopes and imaginary slopes are I have become a bit confused. We have one coordinate $x$-$y$-$z$ system that we use to specify position. I suppose the coordinates in this system will have only real values. But then again in the argand plane the $x$ axis is real and $y$ axis is imaginary. What is a complex slope of a real line? How do we find it?My book has this sentence: ""If $A(z_1)$ and $B(z_2)$ are two points in the argand plane then the complex slope of line $AB$ is $\frac{z_1-z_2}{\bar z_1-\bar z_2}$."" Where did they get this from? I'm not very sure whether this formula is correct either.  I do not have extensive knowledge of complex numbers, I have just studied the basics.",,"['complex-analysis', 'complex-numbers', 'coordinate-systems', 'polar-coordinates']"
19,Show that $\lim_{z\to z_0}|f(z)|=\infty$ if and only if $z_0$ is a pole,Show that  if and only if  is a pole,\lim_{z\to z_0}|f(z)|=\infty z_0,"Im stuck with this exercise Let $f$ holomorphic on $U\setminus\{z_0\}$ where $U$ is open. Show that $\lim_{z\to z_0}|f(z)|=\infty$ if and only if $z_0$ is a pole. One direction is easy to show, Im stuck trying to show that $$\lim_{z\to z_0}|f(z)|=\infty\implies z_0\text{ is a pole}$$ In particular Im having a hard time to figure how to show that if $\lim_{z\to z_0}|f(z)|=\infty$ then $z_0$ cannot be an essential singularity. My work so far: if $\lim_{z\to z_0}|f(z)|=\infty$ then $f$ have a non-removable singularity at $z_0$ . If $z_0$ would be an essential singularity then I know that (this is my definition of essential singularity) the principal part of the Laurent expansion of $f$ around $z_0$ have infinitely many non-zero coefficients, that is $$\lim_{z\to z_0}|f(z)|=\lim_{z\to z_0}\left|\sum_{k=1}^\infty c_{-k}(z-z_0)^{-k}\right|\tag1$$ where there are infinitely many $c_{-k}\neq 0$ . Then to show that the limit of $(1)$ doesnt exists is enough to show that there is some $\theta\in[0,2\pi)$ such that $$\lim_{r\to\infty}\left|\sum_{k=1}^\infty c_{-k}e^{ik\theta}r^k\right|<\infty\tag2$$ That is: if there is some linear path $z\to z_0$ such that $\lim_{z\to z_0}|f(z)|<\infty$ we are done. However Im not sure if this approach is useful or not. In any case I get stuck here, I dont have a clue about how to show that $z_0$ cannot be an essential singularity if $\lim_{z\to z_0}|f(z)|=\infty$ . Some help will be appreciated, thank you. EDIT: I think I see a path for a solution. We can write $\omega_k(\alpha_k)^k$ for $\omega_k\in\mathrm S^1$ and $\alpha_k\in(0,\infty)$ such that $\lim \alpha_k=\infty$ instead of $c_{-k}e^{ik\theta}r^k$ (because $\lim c_{-k}= 0$ ) what give us great freedom to choose suitable sequences $(\omega_k)$ and $(\alpha_k)$ to try to prove $(2)$ . Indeed, if Im not wrong, choosing $\omega_k=(-1)^k$ we are done.","Im stuck with this exercise Let holomorphic on where is open. Show that if and only if is a pole. One direction is easy to show, Im stuck trying to show that In particular Im having a hard time to figure how to show that if then cannot be an essential singularity. My work so far: if then have a non-removable singularity at . If would be an essential singularity then I know that (this is my definition of essential singularity) the principal part of the Laurent expansion of around have infinitely many non-zero coefficients, that is where there are infinitely many . Then to show that the limit of doesnt exists is enough to show that there is some such that That is: if there is some linear path such that we are done. However Im not sure if this approach is useful or not. In any case I get stuck here, I dont have a clue about how to show that cannot be an essential singularity if . Some help will be appreciated, thank you. EDIT: I think I see a path for a solution. We can write for and such that instead of (because ) what give us great freedom to choose suitable sequences and to try to prove . Indeed, if Im not wrong, choosing we are done.","f U\setminus\{z_0\} U \lim_{z\to z_0}|f(z)|=\infty z_0 \lim_{z\to z_0}|f(z)|=\infty\implies z_0\text{ is a pole} \lim_{z\to z_0}|f(z)|=\infty z_0 \lim_{z\to z_0}|f(z)|=\infty f z_0 z_0 f z_0 \lim_{z\to z_0}|f(z)|=\lim_{z\to z_0}\left|\sum_{k=1}^\infty c_{-k}(z-z_0)^{-k}\right|\tag1 c_{-k}\neq 0 (1) \theta\in[0,2\pi) \lim_{r\to\infty}\left|\sum_{k=1}^\infty c_{-k}e^{ik\theta}r^k\right|<\infty\tag2 z\to z_0 \lim_{z\to z_0}|f(z)|<\infty z_0 \lim_{z\to z_0}|f(z)|=\infty \omega_k(\alpha_k)^k \omega_k\in\mathrm S^1 \alpha_k\in(0,\infty) \lim \alpha_k=\infty c_{-k}e^{ik\theta}r^k \lim c_{-k}= 0 (\omega_k) (\alpha_k) (2) \omega_k=(-1)^k","['complex-analysis', 'holomorphic-functions', 'singularity']"
20,Analytic function $f$ such that $(f(z))^n= f(z^n)$,Analytic function  such that,f (f(z))^n= f(z^n),"Let $f(z) = \sum_{k\geq 0}a_kz^k$ be an analytic function, where $a_k\in\mathbb{C}$ for $k\geq 0$. I am trying to get some conditions for $a_k$ that give us the general form of $f$ such that $(f(z))^n= f(z^n)$. What I tried is to use the Multinomial Theorem , but I get stuck while trying to compute the coefficients of $(f(z))^n$. I would like to obtain the general solution, but in fact I need only two cases: if either $a_0 = f(0) = 0$ or $a_1 = f'(0) = 0$. Thank you!","Let $f(z) = \sum_{k\geq 0}a_kz^k$ be an analytic function, where $a_k\in\mathbb{C}$ for $k\geq 0$. I am trying to get some conditions for $a_k$ that give us the general form of $f$ such that $(f(z))^n= f(z^n)$. What I tried is to use the Multinomial Theorem , but I get stuck while trying to compute the coefficients of $(f(z))^n$. I would like to obtain the general solution, but in fact I need only two cases: if either $a_0 = f(0) = 0$ or $a_1 = f'(0) = 0$. Thank you!",,"['complex-analysis', 'functional-equations', 'analytic-functions', 'multinomial-coefficients']"
21,Why are complex numbers treated as coordinates?,Why are complex numbers treated as coordinates?,,"When I see examples of complex numbers on the complex plane (imaginary $y$-axis, real $x$-axis), we have some number $z = a + bi$ and almost every diagram, tutorial, says this maps to the point $a$ units over on the real line and then $b$ units up/down on the imaginary line which is labeled $..., -2i, -1i, 0, 1i, 2i, ...$. Why is this so? It's treated like some obvious statement. But I don't see why it should be the case. It's like $z = a + bi$ is really being treated as a coordinate pair $(a, b)$.","When I see examples of complex numbers on the complex plane (imaginary $y$-axis, real $x$-axis), we have some number $z = a + bi$ and almost every diagram, tutorial, says this maps to the point $a$ units over on the real line and then $b$ units up/down on the imaginary line which is labeled $..., -2i, -1i, 0, 1i, 2i, ...$. Why is this so? It's treated like some obvious statement. But I don't see why it should be the case. It's like $z = a + bi$ is really being treated as a coordinate pair $(a, b)$.",,"['complex-analysis', 'complex-numbers', 'definition', 'coordinate-systems']"
22,Why is $e^{a\pi i}\neq (-1)^a$?,Why is ?,e^{a\pi i}\neq (-1)^a,Why are the following statements incorrect? I have trouble understanding my mistake. $$e^{a\cdot \pi i} = e^{\pi i^a} = (-1)^a $$ $$e^{a\cdot 2\pi i} = e^{2\pi i^a} = (1)^a =1 $$ Any clues would be appreciated!,Why are the following statements incorrect? I have trouble understanding my mistake. $$e^{a\cdot \pi i} = e^{\pi i^a} = (-1)^a $$ $$e^{a\cdot 2\pi i} = e^{2\pi i^a} = (1)^a =1 $$ Any clues would be appreciated!,,"['complex-analysis', 'complex-numbers', 'exponential-function']"
23,Show that $\int_0^\infty \frac{\ln x}{(x^2+1)(x^2-1)}dx=\frac{\pi^2}{8}$,Show that,\int_0^\infty \frac{\ln x}{(x^2+1)(x^2-1)}dx=\frac{\pi^2}{8},"How do I show that: $\int_0^\infty \frac{\ln x}{(x^2+1)(x^2-1)}dx=\frac{\pi^2}{8}$ using contours and residues My attempt: I know that the singular points are $i,-i,-1,1,0$ consider $f(z)= \frac{\ln z}{(z^2+1)(z^2-1)}$ and the branch $|z|>0$, $0<\theta<2\pi$ $u: z=r, \rho\le r \le R$ (u is the upper edge) $-l: z=r, \rho\le r \le R$ (lower edge) $\int_ufdz-\int_{-l}fdz=\int_\rho^R \frac{\ln r + i0}{(z^2+1)(z^2-1)}-\int_\rho^R \frac{\ln r + i2\pi}{(z^2+1)(z^2-1)}$ How do I continue from here?","How do I show that: $\int_0^\infty \frac{\ln x}{(x^2+1)(x^2-1)}dx=\frac{\pi^2}{8}$ using contours and residues My attempt: I know that the singular points are $i,-i,-1,1,0$ consider $f(z)= \frac{\ln z}{(z^2+1)(z^2-1)}$ and the branch $|z|>0$, $0<\theta<2\pi$ $u: z=r, \rho\le r \le R$ (u is the upper edge) $-l: z=r, \rho\le r \le R$ (lower edge) $\int_ufdz-\int_{-l}fdz=\int_\rho^R \frac{\ln r + i0}{(z^2+1)(z^2-1)}-\int_\rho^R \frac{\ln r + i2\pi}{(z^2+1)(z^2-1)}$ How do I continue from here?",,['complex-analysis']
24,Determine $\sin(2 - 2i)$ and write the answer in the form $a + ib$.,Determine  and write the answer in the form .,\sin(2 - 2i) a + ib,"Determine $\sin(2 - 2i)$ and write the answer in the form $a + ib$. I managed to get it into the form $\dfrac{e^{2i + 2} - e^{-2 -2i}}{2i}$. The solution has the following calculations: $\sin(2 - 2i) = \dfrac{e^{i(2 - 2i)} - e^{-i(2 - 2i)}}{2i}$ $ = \dfrac{(e^2 - e^{-2})\cos(2) + i(e^2 + e^{-2})\sin(2)}{2i}$ $= \dfrac{(e^2 + e^{-2})\sin(2)}{2} - i\dfrac{(e^2 - e^{-2})\cos(2)}{2}$ I am struggling to get from my solution into the form of the provided solution. I can see that the algebraic property $e^{x + iy} = e^xe^{iy} = e^x(\cos(y) + i\sin(y))$ was used, but I still do not understand how to get from my solution to the provided solution. I would appreciate it if people could please take the time to post a solution that shows the steps that lead from my intermediate solution to the provided solution.","Determine $\sin(2 - 2i)$ and write the answer in the form $a + ib$. I managed to get it into the form $\dfrac{e^{2i + 2} - e^{-2 -2i}}{2i}$. The solution has the following calculations: $\sin(2 - 2i) = \dfrac{e^{i(2 - 2i)} - e^{-i(2 - 2i)}}{2i}$ $ = \dfrac{(e^2 - e^{-2})\cos(2) + i(e^2 + e^{-2})\sin(2)}{2i}$ $= \dfrac{(e^2 + e^{-2})\sin(2)}{2} - i\dfrac{(e^2 - e^{-2})\cos(2)}{2}$ I am struggling to get from my solution into the form of the provided solution. I can see that the algebraic property $e^{x + iy} = e^xe^{iy} = e^x(\cos(y) + i\sin(y))$ was used, but I still do not understand how to get from my solution to the provided solution. I would appreciate it if people could please take the time to post a solution that shows the steps that lead from my intermediate solution to the provided solution.",,['complex-analysis']
25,Is this product of Gamma functions bounded?,Is this product of Gamma functions bounded?,,"Consider the following term: $$q(z,x):=\bigg\vert\frac{\Gamma(\sqrt{z} + 1 + ix)\Gamma(\sqrt{z} + 1 - ix)}{\Gamma(\sqrt{z} + 1)\Gamma(\sqrt{z} + 1)}\bigg\vert\cdot e^{\pi x}. $$ I would like to know whether the function $q$ is bounded for all values $x\in\mathbb{R}$ and $z=a+ib$ with $a>0$ fixed and $b\in\mathbb{R}$. That is, I want to know if the following statement is correct: $$\exists\, c,a>0\,\forall x,b\in\mathbb{R}: \vert q(z,x) \vert \leq c,\, \text{where }z=a+ib.$$ Unfortunately, I could not find any reference for such an estimate and it indeed seems to be a tough problem. How could one analyze that function? In case the above statement is not true: What would be the best estimate one can hope for? I would very appreciate any help.","Consider the following term: $$q(z,x):=\bigg\vert\frac{\Gamma(\sqrt{z} + 1 + ix)\Gamma(\sqrt{z} + 1 - ix)}{\Gamma(\sqrt{z} + 1)\Gamma(\sqrt{z} + 1)}\bigg\vert\cdot e^{\pi x}. $$ I would like to know whether the function $q$ is bounded for all values $x\in\mathbb{R}$ and $z=a+ib$ with $a>0$ fixed and $b\in\mathbb{R}$. That is, I want to know if the following statement is correct: $$\exists\, c,a>0\,\forall x,b\in\mathbb{R}: \vert q(z,x) \vert \leq c,\, \text{where }z=a+ib.$$ Unfortunately, I could not find any reference for such an estimate and it indeed seems to be a tough problem. How could one analyze that function? In case the above statement is not true: What would be the best estimate one can hope for? I would very appreciate any help.",,"['complex-analysis', 'analysis', 'asymptotics', 'special-functions', 'gamma-function']"
26,"Why does the integral for the average value of a complex function on a circle normalize by $2\pi$, rather than $2\pi R$?","Why does the integral for the average value of a complex function on a circle normalize by , rather than ?",2\pi 2\pi R,"In Gamelin's Complex Analysis , the expression for the average value of a complex function on a circle is introduced before Cauchy's integral theorem. It says that the average value of $h(z)$ on the circle $|z-z_0|=R$ is given by $$ A(r) = \frac{1}{2 \pi}        \int_0^{2 \pi} h\left(z_0 + re^{i \theta}\right) d \theta. $$ I'm puzzled as to why we are normalizing by $2\pi$ instead of $2\pi R$.","In Gamelin's Complex Analysis , the expression for the average value of a complex function on a circle is introduced before Cauchy's integral theorem. It says that the average value of $h(z)$ on the circle $|z-z_0|=R$ is given by $$ A(r) = \frac{1}{2 \pi}        \int_0^{2 \pi} h\left(z_0 + re^{i \theta}\right) d \theta. $$ I'm puzzled as to why we are normalizing by $2\pi$ instead of $2\pi R$.",,['complex-analysis']
27,Holomorphic Function is Injective in a Neighborhood where it has Nonzero Derivative,Holomorphic Function is Injective in a Neighborhood where it has Nonzero Derivative,,"Suppose $f : \Omega \to \mathbb{C}$ is a holomorphic function on some open set $\Omega.$ If $f'(z)\neq 0$ for some $z\in \Omega,$ does there necessarily exist a neighborhood $U$ of $z$ where $f$ is injective?","Suppose $f : \Omega \to \mathbb{C}$ is a holomorphic function on some open set $\Omega.$ If $f'(z)\neq 0$ for some $z\in \Omega,$ does there necessarily exist a neighborhood $U$ of $z$ where $f$ is injective?",,['complex-analysis']
28,Proof that the Riemann Zeta Function is holomorphic on $Re(z)>1$,Proof that the Riemann Zeta Function is holomorphic on,Re(z)>1,"Ultimately I am trying to prove that that the Riemann Zeta function is holomorphic on $Re(z)>1$. So far I have manipulated the series in the following way: $\sum_{n=1}^\infty \frac{1}{n^z}$ = $\sum_{n=1}^\infty e^{-zlogn}$ = $\sum_{n=1}^\infty \frac{1}{n^x}cos(ylogn) - i\sum_{n=1}^\infty\frac{1}{n^x}sin(ylogn)$ From this point I have considered using the fact that a function, $f$ say, of a complex variable defined by a power series $\sum_{n=0}^\infty a_n(z-a)^n$ with radius of convergence $R$ is holomorphic on an open disc $D(a,R)$. However, I really don't know how to go about this as I do not know what radius to choose as $Re(z)>1$ is obviously not a disc. Furthermore, I had no luck trying to find $R$ using the ratio test. Do I need to continue manipulating the series into a more manageable form? Or am I approaching this problem in the wrong way? Any help on what to try next would be great!","Ultimately I am trying to prove that that the Riemann Zeta function is holomorphic on $Re(z)>1$. So far I have manipulated the series in the following way: $\sum_{n=1}^\infty \frac{1}{n^z}$ = $\sum_{n=1}^\infty e^{-zlogn}$ = $\sum_{n=1}^\infty \frac{1}{n^x}cos(ylogn) - i\sum_{n=1}^\infty\frac{1}{n^x}sin(ylogn)$ From this point I have considered using the fact that a function, $f$ say, of a complex variable defined by a power series $\sum_{n=0}^\infty a_n(z-a)^n$ with radius of convergence $R$ is holomorphic on an open disc $D(a,R)$. However, I really don't know how to go about this as I do not know what radius to choose as $Re(z)>1$ is obviously not a disc. Furthermore, I had no luck trying to find $R$ using the ratio test. Do I need to continue manipulating the series into a more manageable form? Or am I approaching this problem in the wrong way? Any help on what to try next would be great!",,"['complex-analysis', 'riemann-zeta']"
29,non-constant entire function $f$ such that $f(n+\dfrac{1}{n})=0\forall n\in \Bbb N$?,non-constant entire function  such that ?,f f(n+\dfrac{1}{n})=0\forall n\in \Bbb N,Does there exist a non-constant entire function $f : \mathbb{C}\to\mathbb{C}$ such that $f(n+\dfrac{1}{n})=0$ for all $n\in \Bbb N$? Let $f$ be a  non-constant entire function  such that $f(n+\dfrac{1}{n})=0\forall n\in \Bbb N$. Then $f(2)=0;f(3+\frac{1}{3})=0$  and so on.But the problem is the set of zeros of $f$ does not have a limit point. How can I conclude whether such  a function exists or not?Please help,Does there exist a non-constant entire function $f : \mathbb{C}\to\mathbb{C}$ such that $f(n+\dfrac{1}{n})=0$ for all $n\in \Bbb N$? Let $f$ be a  non-constant entire function  such that $f(n+\dfrac{1}{n})=0\forall n\in \Bbb N$. Then $f(2)=0;f(3+\frac{1}{3})=0$  and so on.But the problem is the set of zeros of $f$ does not have a limit point. How can I conclude whether such  a function exists or not?Please help,,"['complex-analysis', 'entire-functions']"
30,Complex power series exercise,Complex power series exercise,,"I'm stuck in a the following point of an exercise. Consider the following series $$\sum_{n = 1}^\infty \left(1 + \frac{i}{n}\right)^{n^3} z^n,$$ it says that the convergence radius is $\frac{1}{\sqrt{e}}$. How can I prove that?","I'm stuck in a the following point of an exercise. Consider the following series $$\sum_{n = 1}^\infty \left(1 + \frac{i}{n}\right)^{n^3} z^n,$$ it says that the convergence radius is $\frac{1}{\sqrt{e}}$. How can I prove that?",,"['complex-analysis', 'convergence-divergence', 'power-series']"
31,Show that $\int_{\partial P}z\frac {f'(z)} {f(z)} dz $ is on the lattice $\Lambda$,Show that  is on the lattice,\int_{\partial P}z\frac {f'(z)} {f(z)} dz  \Lambda,"Problem: Let $f(z)$ be a meromorphic function on the complex torus $\mathbb C/\Lambda$ that as a function on $\mathbb C$ has no zeros and no poles on $\partial P$, the boundary of the fundamental parallelogram $P$. Show that \begin{equation}                 \frac{1}{2 \pi i}\int_{\partial P}z\frac {f'(z)} {f(z)} dz \in \Lambda \, . \end{equation} Thoughts: By the Residue Theorem  \begin{equation} \frac{1}{2 \pi i}\int_{\partial P}z\frac {f'(z)} {f(z)} dz = \sum_{z_0 \in \text{ Int }P} v_{z_0}(f)z_0. \end{equation}  I don't know why the latter is on the lattice. Thanks!","Problem: Let $f(z)$ be a meromorphic function on the complex torus $\mathbb C/\Lambda$ that as a function on $\mathbb C$ has no zeros and no poles on $\partial P$, the boundary of the fundamental parallelogram $P$. Show that \begin{equation}                 \frac{1}{2 \pi i}\int_{\partial P}z\frac {f'(z)} {f(z)} dz \in \Lambda \, . \end{equation} Thoughts: By the Residue Theorem  \begin{equation} \frac{1}{2 \pi i}\int_{\partial P}z\frac {f'(z)} {f(z)} dz = \sum_{z_0 \in \text{ Int }P} v_{z_0}(f)z_0. \end{equation}  I don't know why the latter is on the lattice. Thanks!",,"['complex-analysis', 'differential-geometry', 'riemann-surfaces']"
32,"$|f|\leq |g|$ on $\mathbb{C}$, then $f=cg$. [duplicate]","on , then . [duplicate]",|f|\leq |g| \mathbb{C} f=cg,"This question already has an answer here : Property of Entire Functions (1 answer) Closed 9 months ago . Let $f$ and $ g$ be entire functions with $|f(z)|\leq |g(z)|$ for all $z\in \mathbb{C}$. Is it true that $f=cg$ for some $c\in \mathbb{C}$? My attempt: If $g=0$, we are done. Suppose then that $g$ is not identically zero. Let $h=f/g$. Fix an arbitrary $z_0$. If $g(z_0)\neq 0$, then $g$ is nonzero on a neighborhood of $ z_0$ and $h$ is holomorphic at $z_0$. If $g(z_0)=0$, then $g$ is nonzero on a neighborhood of $z_0$ except at $z_0$ (by analytic continuation). Then $h$ is holomorphic on that neighborhood of $z_0 $ except at $z_0$. As $| h|\leq 1$, $h$ has an avoidable singularity at $z_0$, therefore it can be assumed to be holomorphic at $z_0$. Thus, $h$ is entire and by Liouville constant.","This question already has an answer here : Property of Entire Functions (1 answer) Closed 9 months ago . Let $f$ and $ g$ be entire functions with $|f(z)|\leq |g(z)|$ for all $z\in \mathbb{C}$. Is it true that $f=cg$ for some $c\in \mathbb{C}$? My attempt: If $g=0$, we are done. Suppose then that $g$ is not identically zero. Let $h=f/g$. Fix an arbitrary $z_0$. If $g(z_0)\neq 0$, then $g$ is nonzero on a neighborhood of $ z_0$ and $h$ is holomorphic at $z_0$. If $g(z_0)=0$, then $g$ is nonzero on a neighborhood of $z_0$ except at $z_0$ (by analytic continuation). Then $h$ is holomorphic on that neighborhood of $z_0 $ except at $z_0$. As $| h|\leq 1$, $h$ has an avoidable singularity at $z_0$, therefore it can be assumed to be holomorphic at $z_0$. Thus, $h$ is entire and by Liouville constant.",,['complex-analysis']
33,Decomposition of Harmonic function into sum of holomorphic and anti-holomorphic function,Decomposition of Harmonic function into sum of holomorphic and anti-holomorphic function,,"How do you prove that a harmonic planar mapping $f(x,y) = u(x,y) + i v(x,y)$ for real $u,v$ can be written as $f(x,y) = \phi(x,y) + \overline{\psi}(x,y)$ where $\phi$ is a holomorphic function, and $\overline{\psi}$ is an anti-holomorphic function (conjugate of a holomorphic function)?","How do you prove that a harmonic planar mapping $f(x,y) = u(x,y) + i v(x,y)$ for real $u,v$ can be written as $f(x,y) = \phi(x,y) + \overline{\psi}(x,y)$ where $\phi$ is a holomorphic function, and $\overline{\psi}$ is an anti-holomorphic function (conjugate of a holomorphic function)?",,"['complex-analysis', 'harmonic-functions', 'holomorphic-functions']"
34,"How to evaluate $\frac{1}{2\pi}\int_0^{2\pi}\log\left\lvert re^{it}-\zeta\right\rvert\,dt$?",How to evaluate ?,"\frac{1}{2\pi}\int_0^{2\pi}\log\left\lvert re^{it}-\zeta\right\rvert\,dt","Prove that if $\zeta \in \mathbb{C}$ and $r>0$ then    $$ \frac{1}{2\pi}\int_0^{2\pi}\log\left\lvert re^{it}-\zeta\right\rvert\,dt = \log \left\lvert\zeta\right\rvert\, $$ if $\,r\leq \left\lvert\zeta\right\rvert$, and it is $\,\log r\,$ if $\,r> \left\lvert\zeta\right\rvert$. My Try: First I consider the case where $\zeta=0$. Then we have only the case where $r>\left\lvert\zeta\right\rvert$. Then the result is obvious. Now suppose $\zeta\neq 0$. Then $\left\lvert\zeta\right\rvert>0$. Suppose $0<r'<\left\lvert\zeta\right\rvert$.  Let $u\left(z\right)=\log\left\lvert z\right\rvert$ for $z\in \mathbb{C}$. Then $u\left(-\zeta\right)>-\infty$. So $u\left(z\right)$ is harmonic near $-\zeta$. So there is $\rho>0$ $(\rho$ depends on $-\zeta)$ such that $u\left(-\zeta\right)=\log\left\lvert\zeta\right\rvert=\frac{1}{2\pi}\int_0^{2\pi}\log\left\lvert re^{it}-\zeta\right\rvert \, dt\,$ for all $0\leq r<\rho$. Now if $r'<\rho$ then we are done. But what if $r'>\rho$? That is the place where I stuck. Can somebody please help me to solve it? Moreover, I don't know how to handle the case where $r'=\left\lvert\zeta\right\rvert$ for the original problem.","Prove that if $\zeta \in \mathbb{C}$ and $r>0$ then    $$ \frac{1}{2\pi}\int_0^{2\pi}\log\left\lvert re^{it}-\zeta\right\rvert\,dt = \log \left\lvert\zeta\right\rvert\, $$ if $\,r\leq \left\lvert\zeta\right\rvert$, and it is $\,\log r\,$ if $\,r> \left\lvert\zeta\right\rvert$. My Try: First I consider the case where $\zeta=0$. Then we have only the case where $r>\left\lvert\zeta\right\rvert$. Then the result is obvious. Now suppose $\zeta\neq 0$. Then $\left\lvert\zeta\right\rvert>0$. Suppose $0<r'<\left\lvert\zeta\right\rvert$.  Let $u\left(z\right)=\log\left\lvert z\right\rvert$ for $z\in \mathbb{C}$. Then $u\left(-\zeta\right)>-\infty$. So $u\left(z\right)$ is harmonic near $-\zeta$. So there is $\rho>0$ $(\rho$ depends on $-\zeta)$ such that $u\left(-\zeta\right)=\log\left\lvert\zeta\right\rvert=\frac{1}{2\pi}\int_0^{2\pi}\log\left\lvert re^{it}-\zeta\right\rvert \, dt\,$ for all $0\leq r<\rho$. Now if $r'<\rho$ then we are done. But what if $r'>\rho$? That is the place where I stuck. Can somebody please help me to solve it? Moreover, I don't know how to handle the case where $r'=\left\lvert\zeta\right\rvert$ for the original problem.",,['complex-analysis']
35,What is the line bundle on $\mathbb{P}^1_\mathbb{C}$ whose transition function is $e^z$,What is the line bundle on  whose transition function is,\mathbb{P}^1_\mathbb{C} e^z,"Let $U_0,U_\infty$ be the two affine patches of $\mathbb{P}^1_\mathbb{C}$, neighborhoods of ""0"" and ""$\infty$"" respectively. Let $L$ be the line bundle on $\mathbb{P}^1_\mathbb{C}$ constructed by gluing the trivial bundles over $U_0$ and $U_\infty$ via the function $e^z$, which is a nowhere vanishing holomorphic function on $U_0\cap U_\infty$. I've never taken complex geometry (my background is in algebraic geometry, and $e^z$ isn't an algebraic function), so my question is - does $L$ exist in the algebraic world? Which one is it? (for which $n\in\mathbb{Z}$ is $L\cong\mathcal{O}(n)$?). If it isn't any of them, what is the ""right statement"" to say that it doesn't exist? For example, is $e^z$ somehow not in $\mathcal{O}_{\mathbb{P}^1}(U_0\cap U_\infty)$?","Let $U_0,U_\infty$ be the two affine patches of $\mathbb{P}^1_\mathbb{C}$, neighborhoods of ""0"" and ""$\infty$"" respectively. Let $L$ be the line bundle on $\mathbb{P}^1_\mathbb{C}$ constructed by gluing the trivial bundles over $U_0$ and $U_\infty$ via the function $e^z$, which is a nowhere vanishing holomorphic function on $U_0\cap U_\infty$. I've never taken complex geometry (my background is in algebraic geometry, and $e^z$ isn't an algebraic function), so my question is - does $L$ exist in the algebraic world? Which one is it? (for which $n\in\mathbb{Z}$ is $L\cong\mathcal{O}(n)$?). If it isn't any of them, what is the ""right statement"" to say that it doesn't exist? For example, is $e^z$ somehow not in $\mathcal{O}_{\mathbb{P}^1}(U_0\cap U_\infty)$?",,"['complex-analysis', 'algebraic-geometry']"
36,Extract imaginary part of $\text{Li}_3\left(\frac{2}{3}-i \frac{2\sqrt{2}}{3}\right)$ in closed form,Extract imaginary part of  in closed form,\text{Li}_3\left(\frac{2}{3}-i \frac{2\sqrt{2}}{3}\right),"We know that polylogarithms of complex argument sometimes have simple real and imaginary parts, e.g. $\mathrm{Re}[\text{Li}_2(i)]=-\frac{\pi^2}{48}$ Is there a closed form (free of polylogs and imaginary numbers) for the  imaginary part of $\text{Li}_3\left(\frac{2}{3}-i \frac{2\sqrt{2}}{3}\right)$","We know that polylogarithms of complex argument sometimes have simple real and imaginary parts, e.g. $\mathrm{Re}[\text{Li}_2(i)]=-\frac{\pi^2}{48}$ Is there a closed form (free of polylogs and imaginary numbers) for the  imaginary part of $\text{Li}_3\left(\frac{2}{3}-i \frac{2\sqrt{2}}{3}\right)$",,"['calculus', 'complex-analysis', 'special-functions', 'closed-form', 'polylogarithm']"
37,Prove that zeros of f are poles of 1/f,Prove that zeros of f are poles of 1/f,,"Let $f$ be analytic at $z=z_0$ and have a zero of $n$th order at $z=z_0$. Then $1/f(z)$ has a pole of $n$th order at $z=z_0$. I want to prove this, and for this I expand $f(z)$ as a power series, \begin{align*} f(z) = \sum_{k=0}^\infty c_k (z-z_0)^k \end{align*} Since we know that $(z-z_0)$ is zero at $z=z_0$ all the way up to order $n$, i.e. $(z-z_0)^k = 0$ all the way up to $k=n$ (since it can be rewritten as $(z-z_0$ and by the definition of a zero $a_0=0$ such that $f(z_0) = 0$, it follows that \begin{align*} \frac{1}{f(z)} = \frac{1}{\sum_{k=0}^\infty c_k (z-z_0)^k}, \end{align*} such that $1/f \rightarrow \infty$ about the same point. Is this proof complete enough or am I missing something?","Let $f$ be analytic at $z=z_0$ and have a zero of $n$th order at $z=z_0$. Then $1/f(z)$ has a pole of $n$th order at $z=z_0$. I want to prove this, and for this I expand $f(z)$ as a power series, \begin{align*} f(z) = \sum_{k=0}^\infty c_k (z-z_0)^k \end{align*} Since we know that $(z-z_0)$ is zero at $z=z_0$ all the way up to order $n$, i.e. $(z-z_0)^k = 0$ all the way up to $k=n$ (since it can be rewritten as $(z-z_0$ and by the definition of a zero $a_0=0$ such that $f(z_0) = 0$, it follows that \begin{align*} \frac{1}{f(z)} = \frac{1}{\sum_{k=0}^\infty c_k (z-z_0)^k}, \end{align*} such that $1/f \rightarrow \infty$ about the same point. Is this proof complete enough or am I missing something?",,['complex-analysis']
38,Differentiable but not Holomorphic?,Differentiable but not Holomorphic?,,Can I get a few examples of complex functions being complex differentiable at a point but not holomorphic in their domain?,Can I get a few examples of complex functions being complex differentiable at a point but not holomorphic in their domain?,,['complex-analysis']
39,Proof of Sufficiency of Cauchy-Riemann equations,Proof of Sufficiency of Cauchy-Riemann equations,,"I understand that the Cauchy-Riemann equations $$\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y}$$ and $$\frac{\partial u}{\partial y}=-\frac{\partial v}{\partial x}$$ are necessary for a complex function to be complex-differentiable, but I would like to see a proof that they are also sufficient for this to be true. I am assuming that these partial derivatives exist and are continuous everywhere that they are satisfied.","I understand that the Cauchy-Riemann equations $$\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y}$$ and $$\frac{\partial u}{\partial y}=-\frac{\partial v}{\partial x}$$ are necessary for a complex function to be complex-differentiable, but I would like to see a proof that they are also sufficient for this to be true. I am assuming that these partial derivatives exist and are continuous everywhere that they are satisfied.",,"['calculus', 'complex-analysis']"
40,Proving that $\int_{-\pi}^{\pi} \ln |1 - e^{i\theta}| d\theta = 0$,Proving that,\int_{-\pi}^{\pi} \ln |1 - e^{i\theta}| d\theta = 0,"I found this on some comprehensive exam. Prove that $\int_{-\pi}^{\pi} \ln |1 - e^{i\theta}| d\theta  = 0$. I was wondering would standard approach work? By that I just mean splitting the integerl up into  $\int_{-\pi}^{0} + \int_{0}^{\pi}$, and then use $$\ln(1 - e^{i\theta}) = -\sum\frac{e^{i\theta n}}{n}.$$ I found that the first integral yields $-\frac{2}{i n^2}$ and the second yields the negative of that, which yields $0$. But I feel like this is a real-analysis approach. Can someone give me some insight?","I found this on some comprehensive exam. Prove that $\int_{-\pi}^{\pi} \ln |1 - e^{i\theta}| d\theta  = 0$. I was wondering would standard approach work? By that I just mean splitting the integerl up into  $\int_{-\pi}^{0} + \int_{0}^{\pi}$, and then use $$\ln(1 - e^{i\theta}) = -\sum\frac{e^{i\theta n}}{n}.$$ I found that the first integral yields $-\frac{2}{i n^2}$ and the second yields the negative of that, which yields $0$. But I feel like this is a real-analysis approach. Can someone give me some insight?",,"['complex-analysis', 'improper-integrals']"
41,Why is $z$ holomorphic but $\bar z$ not holomorphic,Why is  holomorphic but  not holomorphic,z \bar z,Can anyone show me how I can prove something as simple as $f(z) =  z$ is holomorphic but $\bar z$ is not?,Can anyone show me how I can prove something as simple as $f(z) =  z$ is holomorphic but $\bar z$ is not?,,['complex-analysis']
42,Proof for de Moivre's Formula,Proof for de Moivre's Formula,,"I have a book that has a brief history of the complex numbers and it covers de Moivre's formula: $(\cos(x) + i\sin(x))^n = \cos(nx) + i\sin(nx)$. I am very curious as to how this result was originally found, or derived, BEFORE Euler's formula was around. Also, what was the original proof of this?","I have a book that has a brief history of the complex numbers and it covers de Moivre's formula: $(\cos(x) + i\sin(x))^n = \cos(nx) + i\sin(nx)$. I am very curious as to how this result was originally found, or derived, BEFORE Euler's formula was around. Also, what was the original proof of this?",,"['complex-analysis', 'math-history']"
43,Automorphisms of the upper half plane,Automorphisms of the upper half plane,,"STATEMENT: Suppose $(x_1,x_2,x_3)$ and $(y_1,y_2,y_3)$ are two pairs of three distinct points on the real axis with$$x_1<x_2<x_3 \;\;\;\;\text{and} \;\;\;\;\;y_1<y_2<y_3$$ Prove that there exists (a unique) automorphism $\Phi$ of $\mathbb{H}$ so that $\Phi(x_j)=y_j$, $j=1,2,3$. QUESTION: I  am uncertain about how to proceed with this problem. I know that the group of automorphisms of the upper half plane is transitive, but I don't see how this will help me. Any hints would be appreciated.","STATEMENT: Suppose $(x_1,x_2,x_3)$ and $(y_1,y_2,y_3)$ are two pairs of three distinct points on the real axis with$$x_1<x_2<x_3 \;\;\;\;\text{and} \;\;\;\;\;y_1<y_2<y_3$$ Prove that there exists (a unique) automorphism $\Phi$ of $\mathbb{H}$ so that $\Phi(x_j)=y_j$, $j=1,2,3$. QUESTION: I  am uncertain about how to proceed with this problem. I know that the group of automorphisms of the upper half plane is transitive, but I don't see how this will help me. Any hints would be appreciated.",,"['complex-analysis', 'analysis', 'conformal-geometry']"
44,Conformally mapping the unit disk to the upper-half plane,Conformally mapping the unit disk to the upper-half plane,,"Within $\mathbb{C} \cup \{ \infty \}$, consider the unit-disk $\mathbb{D} = \{ z : |z|\leq 1 \}$ with three points labelled as $a$, $b$, $c$ on its boundary. I want to map $\mathbb{D}$ conformally and bijectively to the upper-half plane $\mathbb{H} =  \{ z : Im(z) \geq 0\}$ with the added constraint that $a$, $b$ and $c$ should be mapped to $0$, $1$ and $\infty$ respectively. Is this possible? With the moebius map $f(z) = \frac{i (1+ z)}{1-z}$ we can map $\mathbb{D}$ to $\mathbb{H}$. But I am not sure, how to enforce the mapping of the points $a$, $b$ and $c$   to $0$, $1$ and $\infty$ respectively. Do we compose this $f$ with another moebius map?","Within $\mathbb{C} \cup \{ \infty \}$, consider the unit-disk $\mathbb{D} = \{ z : |z|\leq 1 \}$ with three points labelled as $a$, $b$, $c$ on its boundary. I want to map $\mathbb{D}$ conformally and bijectively to the upper-half plane $\mathbb{H} =  \{ z : Im(z) \geq 0\}$ with the added constraint that $a$, $b$ and $c$ should be mapped to $0$, $1$ and $\infty$ respectively. Is this possible? With the moebius map $f(z) = \frac{i (1+ z)}{1-z}$ we can map $\mathbb{D}$ to $\mathbb{H}$. But I am not sure, how to enforce the mapping of the points $a$, $b$ and $c$   to $0$, $1$ and $\infty$ respectively. Do we compose this $f$ with another moebius map?",,"['complex-analysis', 'conformal-geometry']"
45,"Given four complex numbers $z_1, z_2, z_3$ and $z_4,$ show that they lie on a circle.",Given four complex numbers  and  show that they lie on a circle.,"z_1, z_2, z_3 z_4,","Given four complex numbers $z_1, z_2, z_3$, and $z_4,$ show that they lie on a circle if  $$\arg\left(\frac{z_4-z_1}{z_4-z_2}\right)=\arg\left(\frac{z_3-z_1}{z_3-z_2}\right).$$  How can I interpret this equality? And how can I show this statement? I need some help. Thanks.","Given four complex numbers $z_1, z_2, z_3$, and $z_4,$ show that they lie on a circle if  $$\arg\left(\frac{z_4-z_1}{z_4-z_2}\right)=\arg\left(\frac{z_3-z_1}{z_3-z_2}\right).$$  How can I interpret this equality? And how can I show this statement? I need some help. Thanks.",,['complex-analysis']
46,A question regarding Frobenius method in ODE,A question regarding Frobenius method in ODE,,"Suppose $b(x),c(x)$ are real functions analytic at $0$. Let $b(x)=\sum_{i=0}^\infty b_ix^i, c(x)=\sum_{i=0}^\infty c_ix^i$ on $(-R,R)$. Suppose $r$ is a double root of  $r(r-1)+b_0r+c_0=0$. It is well known that the differential equation $$x^2y''+xb(x)y'+c(x)y=0$$ has a solution of the form $$y_1=x^r(1+\sum_{i=1}^\infty a_ix^i),$$ where the series $\sum_{i=1}^\infty a_ix^i$ has radius of convergence $\ge R$ (e.g., see Tyn Myint-U, Ordinary Differential Equations). Another solution is of the form $$y_1\ln x + x^r(\sum_{i=1}^\infty A_ix^i).$$ Most books (including Tyn's) mention without proof that $\sum_{i=1}^\infty A_ix^i$ also has radius of convergence at least $R$. Let $I(s)=s(s-1)+b_0s+c_0$. Then $A_i, i\ge 1$ satisfy the following recursive relation $$I(r+i)A_i=-\sum_{k=0}^{i-1}A_k[(r+k)b_{i-k}+c_{i-k}]-2ia_i-\sum_{k=1}^{i}b_ka_{i-k}$$ where $A_0=0$. (Note that $2r=1-b_0$). Proving that the power series $\sum_{k=1}A_kx^k$ has radius of convergence at least $R$ directly seems to be hopeless. I tried comparison test as in Coddington's book Introduction to Ordinary Differential Equations , but with no success. Does anyone have a proof, or a reference where a proof is given?","Suppose $b(x),c(x)$ are real functions analytic at $0$. Let $b(x)=\sum_{i=0}^\infty b_ix^i, c(x)=\sum_{i=0}^\infty c_ix^i$ on $(-R,R)$. Suppose $r$ is a double root of  $r(r-1)+b_0r+c_0=0$. It is well known that the differential equation $$x^2y''+xb(x)y'+c(x)y=0$$ has a solution of the form $$y_1=x^r(1+\sum_{i=1}^\infty a_ix^i),$$ where the series $\sum_{i=1}^\infty a_ix^i$ has radius of convergence $\ge R$ (e.g., see Tyn Myint-U, Ordinary Differential Equations). Another solution is of the form $$y_1\ln x + x^r(\sum_{i=1}^\infty A_ix^i).$$ Most books (including Tyn's) mention without proof that $\sum_{i=1}^\infty A_ix^i$ also has radius of convergence at least $R$. Let $I(s)=s(s-1)+b_0s+c_0$. Then $A_i, i\ge 1$ satisfy the following recursive relation $$I(r+i)A_i=-\sum_{k=0}^{i-1}A_k[(r+k)b_{i-k}+c_{i-k}]-2ia_i-\sum_{k=1}^{i}b_ka_{i-k}$$ where $A_0=0$. (Note that $2r=1-b_0$). Proving that the power series $\sum_{k=1}A_kx^k$ has radius of convergence at least $R$ directly seems to be hopeless. I tried comparison test as in Coddington's book Introduction to Ordinary Differential Equations , but with no success. Does anyone have a proof, or a reference where a proof is given?",,"['real-analysis', 'complex-analysis', 'ordinary-differential-equations', 'reference-request']"
47,sequence and series (complex analysis),sequence and series (complex analysis),,"Let $N_0\in \mathbb{N}.$ If a sequence of complex numbers $\{F_N\}_{N \in \mathbb{N}}$ has the following properties: $$\lim_{N \rightarrow \infty} |F_N|^{1/N}=0$$ and for all $N \geq N_0$, $$|F_N|\leq \sum_{k=N+1}^{\infty} |F_k|,\quad \quad \quad  $$ then there exists $N_1\in \mathbb{N}$ such that $F_N=0$ for all $N \geq N_1.$ I found this argument on a paper but I cannot prove it. Could you please help me or give me an idea? Thank you. Masik","Let $N_0\in \mathbb{N}.$ If a sequence of complex numbers $\{F_N\}_{N \in \mathbb{N}}$ has the following properties: $$\lim_{N \rightarrow \infty} |F_N|^{1/N}=0$$ and for all $N \geq N_0$, $$|F_N|\leq \sum_{k=N+1}^{\infty} |F_k|,\quad \quad \quad  $$ then there exists $N_1\in \mathbb{N}$ such that $F_N=0$ for all $N \geq N_1.$ I found this argument on a paper but I cannot prove it. Could you please help me or give me an idea? Thank you. Masik",,['complex-analysis']
48,Proving taylor coefficients of $\tan {\pi z \over 2}$ follow $\lim \limits_{n\to\infty} a_{2n+1}={4\over\pi}$.,Proving taylor coefficients of  follow .,\tan {\pi z \over 2} \lim \limits_{n\to\infty} a_{2n+1}={4\over\pi},"I've stumbled upon the following question while studying for a test in complex analysis: Given the following Taylor series: $\tan {\pi z \over 2} = \sum \limits _{n=0}^{\infty} a_{2n+1} z ^ {2n+1}$ Prove that: $\lim \limits_{n\to\infty} a_{2n+1}={4\over\pi}$. I've tried using Cauchy's integral formula for the $n^{th}$ derivative of $\tan {\pi z \over 2}$, but didn't get much progress. If it helps, this is the third part of the question. The two others are: Find all the singularity points of $\tan {\pi z \over 2}$, classify them and find the residues. (There are singularities at $\{1 + 2k; k \in \Bbb Z\}$, all are simple poles with  residue $-{2\over\pi}$) What is the radius of convergence of the Taylor series: $\tan {\pi z \over 2} = \sum \limits _{n=0}^{\infty} a_{2n+1} z ^ {2n+1}$? (It's 1 because $\tan {\pi z \over 2}$ has singularities in -1, 1) I'm struggling with this question for several hours, so any help would be appreciated.","I've stumbled upon the following question while studying for a test in complex analysis: Given the following Taylor series: $\tan {\pi z \over 2} = \sum \limits _{n=0}^{\infty} a_{2n+1} z ^ {2n+1}$ Prove that: $\lim \limits_{n\to\infty} a_{2n+1}={4\over\pi}$. I've tried using Cauchy's integral formula for the $n^{th}$ derivative of $\tan {\pi z \over 2}$, but didn't get much progress. If it helps, this is the third part of the question. The two others are: Find all the singularity points of $\tan {\pi z \over 2}$, classify them and find the residues. (There are singularities at $\{1 + 2k; k \in \Bbb Z\}$, all are simple poles with  residue $-{2\over\pi}$) What is the radius of convergence of the Taylor series: $\tan {\pi z \over 2} = \sum \limits _{n=0}^{\infty} a_{2n+1} z ^ {2n+1}$? (It's 1 because $\tan {\pi z \over 2}$ has singularities in -1, 1) I'm struggling with this question for several hours, so any help would be appreciated.",,['complex-analysis']
49,Calculating $\zeta(0)$ by the residue of $\zeta(1)$,Calculating  by the residue of,\zeta(0) \zeta(1),"$$\begin {aligned}\pi^{-s/2}\Gamma(s/2)\zeta(s)=&\pi^{-(1-s)/2}\Gamma((1-s)/2)\zeta(1-s) \\ \zeta(0) =&\frac{\pi^{-1/2}\Gamma(1/2)\zeta(1)}{\pi^{0}\Gamma(0)}=\frac{\zeta(1)}{\Gamma(0)}\end {aligned}$$ so that $\zeta(0)$ is the ratio of the residues of $\zeta(s)$ at $s=1$ end $\Gamma(s)$ at $s=0$. The latter is just $1$ since $$\lim_{s\rightarrow 0} s\Gamma(s) = \Gamma(1)=1.$$ To calculate the residue of $\zeta(s)$ at $s=1$, I simply used the expression, proved in Stein & Shakarchi Complex Analysis p. 171 $$\pi^{-s/2}\Gamma(s/2)\zeta(s) = \frac 1{s-1} -\frac1s +\frac12\int_1^\infty(u^{(-s/2)-1/2}+u^{s/2-1})[\theta(u)-1]du$$ I argued that since the integral on the RHS is holomorphic at $s=1$, the residue of the LHS at $s=1$ must be $1$ (the coefficient of the first fraction). Since $\pi^{-1/2}\Gamma(1/2)$ cancel each other, it should be the case that $\operatorname {res}_{s=1} \zeta(s)=1$, but then my argument says that $\zeta(0) = 1$. Where did I miss the $-\frac12$?","$$\begin {aligned}\pi^{-s/2}\Gamma(s/2)\zeta(s)=&\pi^{-(1-s)/2}\Gamma((1-s)/2)\zeta(1-s) \\ \zeta(0) =&\frac{\pi^{-1/2}\Gamma(1/2)\zeta(1)}{\pi^{0}\Gamma(0)}=\frac{\zeta(1)}{\Gamma(0)}\end {aligned}$$ so that $\zeta(0)$ is the ratio of the residues of $\zeta(s)$ at $s=1$ end $\Gamma(s)$ at $s=0$. The latter is just $1$ since $$\lim_{s\rightarrow 0} s\Gamma(s) = \Gamma(1)=1.$$ To calculate the residue of $\zeta(s)$ at $s=1$, I simply used the expression, proved in Stein & Shakarchi Complex Analysis p. 171 $$\pi^{-s/2}\Gamma(s/2)\zeta(s) = \frac 1{s-1} -\frac1s +\frac12\int_1^\infty(u^{(-s/2)-1/2}+u^{s/2-1})[\theta(u)-1]du$$ I argued that since the integral on the RHS is holomorphic at $s=1$, the residue of the LHS at $s=1$ must be $1$ (the coefficient of the first fraction). Since $\pi^{-1/2}\Gamma(1/2)$ cancel each other, it should be the case that $\operatorname {res}_{s=1} \zeta(s)=1$, but then my argument says that $\zeta(0) = 1$. Where did I miss the $-\frac12$?",,"['complex-analysis', 'riemann-zeta']"
50,A holomorphic function is conformal,A holomorphic function is conformal,,"I am trying to show that if a function $f = u+iv$ is holomorphic with $\partial_z f(z)$ always non zero, then $f$ is a conformal mapping, i.e. it preserves angles between smooth curves. If $f$ is holomorphic, by Cauchy-Riemann $$ \begin{vmatrix} u_x & u_y\\ v_x & v_y \end{vmatrix} = \begin{vmatrix} u_x & -v_x\\ v_x & u_x \end{vmatrix} = u_x^2 + v_x^2 = |\partial_z f|^2 \neq 0, $$ so changing variables $r, \theta$ s.t. $$ r = |\partial _z f(z)|, \cos \theta = \dfrac{u_x}{|\partial_z f|}, \sin \theta = \dfrac{v_x}{|\partial_z f|}$$ the jacobian matrix of $f$ becomes $$\begin{pmatrix} u_x & u_y\\ v_x & v_y \end{pmatrix} = r \begin{pmatrix} \cos \theta & - \sin \theta\\ \sin \theta & \cos \theta \end{pmatrix}.$$ Now the Jacobian indeed preserves angles since it is a composition of a rotation with a dilation. But why $f$ should also preserve angles??","I am trying to show that if a function $f = u+iv$ is holomorphic with $\partial_z f(z)$ always non zero, then $f$ is a conformal mapping, i.e. it preserves angles between smooth curves. If $f$ is holomorphic, by Cauchy-Riemann $$ \begin{vmatrix} u_x & u_y\\ v_x & v_y \end{vmatrix} = \begin{vmatrix} u_x & -v_x\\ v_x & u_x \end{vmatrix} = u_x^2 + v_x^2 = |\partial_z f|^2 \neq 0, $$ so changing variables $r, \theta$ s.t. $$ r = |\partial _z f(z)|, \cos \theta = \dfrac{u_x}{|\partial_z f|}, \sin \theta = \dfrac{v_x}{|\partial_z f|}$$ the jacobian matrix of $f$ becomes $$\begin{pmatrix} u_x & u_y\\ v_x & v_y \end{pmatrix} = r \begin{pmatrix} \cos \theta & - \sin \theta\\ \sin \theta & \cos \theta \end{pmatrix}.$$ Now the Jacobian indeed preserves angles since it is a composition of a rotation with a dilation. But why $f$ should also preserve angles??",,"['complex-analysis', 'multivariable-calculus', 'conformal-geometry']"
51,Does De Moivre's Theorem hold for all real n?,Does De Moivre's Theorem hold for all real n?,,"I have seen the proof by induction for all integers, and I have also seen in a textbook that we can use Euler's formula to prove it true for all rational n, but nowhere in the book does it say its true for irrational n. I have also looked over the internet and there seems to be some problem with non-integer values for n (as I understand, a problem of uniqueness, but I'm not sure). I would appreciate it if someone could just clarify this for me. Thanks in advance!","I have seen the proof by induction for all integers, and I have also seen in a textbook that we can use Euler's formula to prove it true for all rational n, but nowhere in the book does it say its true for irrational n. I have also looked over the internet and there seems to be some problem with non-integer values for n (as I understand, a problem of uniqueness, but I'm not sure). I would appreciate it if someone could just clarify this for me. Thanks in advance!",,"['complex-analysis', 'complex-numbers', 'self-learning']"
52,Elementary bound on the Riemann zeta function,Elementary bound on the Riemann zeta function,,"I am currently preparing for a course in analytic number theory and I wanted to  get a heads start. In my preparation, I came across the following problem: Show that for $|y|\geq 2$, $|\zeta(1+iy)| \leq C\log|y|$ for some constant $C.$ I am very weak when it comes to determining bounds such as this, and honestly don't know where to start. This is all very new to me. Any help is appreciated.","I am currently preparing for a course in analytic number theory and I wanted to  get a heads start. In my preparation, I came across the following problem: Show that for $|y|\geq 2$, $|\zeta(1+iy)| \leq C\log|y|$ for some constant $C.$ I am very weak when it comes to determining bounds such as this, and honestly don't know where to start. This is all very new to me. Any help is appreciated.",,"['complex-analysis', 'number-theory', 'analytic-number-theory', 'riemann-zeta']"
53,"Cauchy-Goursat theorem, proof without using vector calculus.","Cauchy-Goursat theorem, proof without using vector calculus.",,"On the wikipedia page for the Cauchy-Goursat theorem it says: If one assumes that the partial derivatives of a holomorphic function are continuous, the Cauchy integral theorem can be proved as a direct consequence of Green's theorem and the fact that the real and imaginary parts of $f=u+iv$ must satisfy the Cauchy–Riemann equations in the region bounded by $\gamma$, and moreover in the open neighborhood U of this region. Cauchy provided this proof, but it was later proved by Goursat without requiring techniques from vector calculus, or the continuity of partial derivatives. But there is no reference given, and I couldn't find it on the internet. Where could I find Goursat's proof? Is it very complicated?","On the wikipedia page for the Cauchy-Goursat theorem it says: If one assumes that the partial derivatives of a holomorphic function are continuous, the Cauchy integral theorem can be proved as a direct consequence of Green's theorem and the fact that the real and imaginary parts of $f=u+iv$ must satisfy the Cauchy–Riemann equations in the region bounded by $\gamma$, and moreover in the open neighborhood U of this region. Cauchy provided this proof, but it was later proved by Goursat without requiring techniques from vector calculus, or the continuity of partial derivatives. But there is no reference given, and I couldn't find it on the internet. Where could I find Goursat's proof? Is it very complicated?",,"['complex-analysis', 'reference-request']"
54,holomorphic functions uniformly convergent on any compact subset of an open set implies uniformly convergent on the whole open set.,holomorphic functions uniformly convergent on any compact subset of an open set implies uniformly convergent on the whole open set.,,"In Stein's complex analysis, there is one theorem 5.3 of Chapter 2 which says that if holomorphic functions  $f_n$ converges uniformly to $f$ on any compact subset of an open set $\Omega$, then so does $f'_n$. In his proof, he said ""without loss of generality we can assume $f_n$ converges uniformly to $f$ on all of $\Omega$"". So I think what he meant was that from the conditions of the theorem, we can get $f_n$ converges uniformly to $f$ on all of $\Omega$. However, I don't know how to prove this assumption. Any help would be welcome.","In Stein's complex analysis, there is one theorem 5.3 of Chapter 2 which says that if holomorphic functions  $f_n$ converges uniformly to $f$ on any compact subset of an open set $\Omega$, then so does $f'_n$. In his proof, he said ""without loss of generality we can assume $f_n$ converges uniformly to $f$ on all of $\Omega$"". So I think what he meant was that from the conditions of the theorem, we can get $f_n$ converges uniformly to $f$ on all of $\Omega$. However, I don't know how to prove this assumption. Any help would be welcome.",,['complex-analysis']
55,Entire function - exponent?,Entire function - exponent?,,Suppose that $f(z)$ is an entire function and $ |f(z)| \le e^x \ (z = x + iy) $ throughout the complex plane. What can be said about $ f(z) $?,Suppose that $f(z)$ is an entire function and $ |f(z)| \le e^x \ (z = x + iy) $ throughout the complex plane. What can be said about $ f(z) $?,,[]
56,Expand $(4+i)(5+3i)$ and show $\pi/4=\arctan{1/4}+\arctan{3/5}$,Expand  and show,(4+i)(5+3i) \pi/4=\arctan{1/4}+\arctan{3/5},I can't remember ever having done this before so if someone could help me out that would be great. The question is expand $(4+i)(5+3i)$ and hence show that $\pi/4=\arctan{1/4}+\arctan{3/5}$. Expansion: $$(4+i)(5+3i)=20+17i-3=17(1+i)=17\sqrt{2}e^{i\frac{\pi}{4}}.$$ But I don't see how this shows me anything about $\arctan$. Any pointers would be appreciated. :),I can't remember ever having done this before so if someone could help me out that would be great. The question is expand $(4+i)(5+3i)$ and hence show that $\pi/4=\arctan{1/4}+\arctan{3/5}$. Expansion: $$(4+i)(5+3i)=20+17i-3=17(1+i)=17\sqrt{2}e^{i\frac{\pi}{4}}.$$ But I don't see how this shows me anything about $\arctan$. Any pointers would be appreciated. :),,"['complex-analysis', 'complex-numbers']"
57,Proving that a function has a removable singularity at infinity,Proving that a function has a removable singularity at infinity,,"I'm having trouble with the following exercise from Ahlfors' text (not homework) ""If $f(z)$ is analytic in a neighborhood of $\infty$ and if $z^{-1} \Re f(z) \to0$ as $z \to \infty$, show that $\lim_{z \to \infty} f(z)$ exists. (In other words, the isolated singularity at $\infty$ is removable) Hint : Show first, by use of Cauchy's integral formula, that $f = f_1 +f_2$ where $f_1(z) \to 0$ for $z \to \infty$ and $f_2(z)$ is analytic in the whole plane. My attempt: $f$ is analytic in the exterior of some disk $\{|z|\geq R_0 \}$. For large enough $|z|$ the circle $C_1(z)$ around $z$ with radius one lies in the domain of analyticity, and we can apply Cauchy's integral formula:  $$f(z)=\frac{1}{2\pi i}\oint_{C_1(z)}\frac{f(\zeta)}{\zeta-z} \mathrm{d} \zeta=\frac{1}{2 \pi i} \oint_{C_1(z)}\frac{\Re f(\zeta)}{\zeta-z} \mathrm{d} \zeta+\frac{1}{2\pi} \oint_{C_1(z)}\frac{\Im f(\zeta)}{\zeta-z} \mathrm{d} \zeta. $$ I want to say that the last expression is exactly the decomposition $f_1+f_2$. Indeed, using Cauchy's estimate (and the fact about the real part) one can show that the first integral tends to zero for large $|z|$, but I can't understand how to define the other one for all $z \in \mathbb C$. In fact, even if I have such a decomposition, I don't think that it will suffice: For instance $f(z)=f_1(z)+f_2(z)$ with $f_1(z)=0,f_2(z)=\exp(z)$ has an essential singularity at $\infty$. Thank you for any directions.","I'm having trouble with the following exercise from Ahlfors' text (not homework) ""If $f(z)$ is analytic in a neighborhood of $\infty$ and if $z^{-1} \Re f(z) \to0$ as $z \to \infty$, show that $\lim_{z \to \infty} f(z)$ exists. (In other words, the isolated singularity at $\infty$ is removable) Hint : Show first, by use of Cauchy's integral formula, that $f = f_1 +f_2$ where $f_1(z) \to 0$ for $z \to \infty$ and $f_2(z)$ is analytic in the whole plane. My attempt: $f$ is analytic in the exterior of some disk $\{|z|\geq R_0 \}$. For large enough $|z|$ the circle $C_1(z)$ around $z$ with radius one lies in the domain of analyticity, and we can apply Cauchy's integral formula:  $$f(z)=\frac{1}{2\pi i}\oint_{C_1(z)}\frac{f(\zeta)}{\zeta-z} \mathrm{d} \zeta=\frac{1}{2 \pi i} \oint_{C_1(z)}\frac{\Re f(\zeta)}{\zeta-z} \mathrm{d} \zeta+\frac{1}{2\pi} \oint_{C_1(z)}\frac{\Im f(\zeta)}{\zeta-z} \mathrm{d} \zeta. $$ I want to say that the last expression is exactly the decomposition $f_1+f_2$. Indeed, using Cauchy's estimate (and the fact about the real part) one can show that the first integral tends to zero for large $|z|$, but I can't understand how to define the other one for all $z \in \mathbb C$. In fact, even if I have such a decomposition, I don't think that it will suffice: For instance $f(z)=f_1(z)+f_2(z)$ with $f_1(z)=0,f_2(z)=\exp(z)$ has an essential singularity at $\infty$. Thank you for any directions.",,"['complex-analysis', 'analysis', 'analyticity', 'singularity-theory']"
58,Primes and the Unit circle.,Primes and the Unit circle.,,"Consider the ""prime spiral"" $f(z) = \sqrt{z}\exp(2\pi i \sqrt{z})$, for integer $z$. It has been shown that the intersections of $f$ with some quadratic curves contain a significantly disproportionate number of primes. Let $P = \{\exp(2\pi i \sqrt{p}) \;:\ p \;prime \}$, the set of unitized prime spiral coordinates. 1) Is $P$ equal to the circle group or is it a proper subset? (note that $P$ is countable) 2) What is the complement of $P$ in the circle group? 3) Is the complement a group? 4) Is the circle group equal to the closure of $P$?","Consider the ""prime spiral"" $f(z) = \sqrt{z}\exp(2\pi i \sqrt{z})$, for integer $z$. It has been shown that the intersections of $f$ with some quadratic curves contain a significantly disproportionate number of primes. Let $P = \{\exp(2\pi i \sqrt{p}) \;:\ p \;prime \}$, the set of unitized prime spiral coordinates. 1) Is $P$ equal to the circle group or is it a proper subset? (note that $P$ is countable) 2) What is the complement of $P$ in the circle group? 3) Is the complement a group? 4) Is the circle group equal to the closure of $P$?",,"['real-analysis', 'group-theory', 'complex-analysis', 'prime-numbers']"
59,Finding the number of solutions of a complex valued function $f(z) = z^n$,Finding the number of solutions of a complex valued function,f(z) = z^n,"This past semester I took a graduate course in complex analysis which I completed moderately well in spite of my expectations (that is I honestly think I deserved a lower grade than I received). I had one assigned question which caused me to join MSE on the subject of Rouché's theorem. This problem comes from Chapter 5 section three of Conway's Functions of a single Complex Variable, the section is on the Argument Principle and Rouché's theorem. The problem is number 2 of this chapter and proceeds as such: ""Suppose $f$ is analytic on $\bar B(0 ; 1) $ and satisfies $\left| f(z) \right|<1 $ for $ |z|=1$. Find the number of solutions (counting multiplicities) of the equation $f(z) = z^n$ where $n$ is an integer larger than or equal to $1$."" Now my question isn't about solving this problem but more of a hint at where to start. As I understood Rouché's theorem, I am required to compare two functions, say $f$ and $g$, so I can compare the number of poles and zeroes. Every example I could find on MSE however included an equation with more than one term and seemed (at least to me) easier than the one I was given. I unfortunately do not have any work of my own to provide as I was definitely stumped. Any discussion of this will help, or references to MSE questions I might have missed would be greatly appreciated","This past semester I took a graduate course in complex analysis which I completed moderately well in spite of my expectations (that is I honestly think I deserved a lower grade than I received). I had one assigned question which caused me to join MSE on the subject of Rouché's theorem. This problem comes from Chapter 5 section three of Conway's Functions of a single Complex Variable, the section is on the Argument Principle and Rouché's theorem. The problem is number 2 of this chapter and proceeds as such: ""Suppose $f$ is analytic on $\bar B(0 ; 1) $ and satisfies $\left| f(z) \right|<1 $ for $ |z|=1$. Find the number of solutions (counting multiplicities) of the equation $f(z) = z^n$ where $n$ is an integer larger than or equal to $1$."" Now my question isn't about solving this problem but more of a hint at where to start. As I understood Rouché's theorem, I am required to compare two functions, say $f$ and $g$, so I can compare the number of poles and zeroes. Every example I could find on MSE however included an equation with more than one term and seemed (at least to me) easier than the one I was given. I unfortunately do not have any work of my own to provide as I was definitely stumped. Any discussion of this will help, or references to MSE questions I might have missed would be greatly appreciated",,['complex-analysis']
60,Analytic functions of a real variable which do not extend to an open complex neighborhood,Analytic functions of a real variable which do not extend to an open complex neighborhood,,"Do such functions exist? If not, is it appropriate to think of real analytic functions as ""slices"" of holomorphic functions?","Do such functions exist? If not, is it appropriate to think of real analytic functions as ""slices"" of holomorphic functions?",,"['real-analysis', 'complex-analysis', 'power-series', 'taylor-expansion', 'analyticity']"
61,How do I find the Laurent series for $\frac{1}{z^2 - 4}$ at $z = 2$?,How do I find the Laurent series for  at ?,\frac{1}{z^2 - 4} z = 2,"How do I find the Laurent series for $\frac{1}{z^2 - 4}$ at $z = 2$? Can anyone help me out with this? I used partial fraction decomposition and got the $\frac{1}{4}$ part of it, just don't understand the rest. I think I may be treating to much like an infinite series","How do I find the Laurent series for $\frac{1}{z^2 - 4}$ at $z = 2$? Can anyone help me out with this? I used partial fraction decomposition and got the $\frac{1}{4}$ part of it, just don't understand the rest. I think I may be treating to much like an infinite series",,"['complex-analysis', 'laurent-series']"
62,Two trivial questions about zeta function,Two trivial questions about zeta function,,"I have two questions concerning the Riemann zeta function which are rather trivial so if anyone can give me the answers that would be nice, here is what I`m interested in: 1) In the equality $\zeta(s)=\sum_{n=1}^{\infty} \dfrac {1}{n^s}$ is the term $\dfrac {1}{n^s}$ by the definition equal to $e^{-s\log n}$, where $e$ is the natural logarithm base and $\log$ is the natural logarithm? 2) Because it is the case that it holds that $\zeta (s)={\dfrac {1}{1-2^{1-s}}}\sum_{n=1}^{\infty}\dfrac {(-1)^{n-1}}{n^s}$ is finding the zero of $\zeta (s)$ in the range $0<\Re(s)<1$ equivalent to finding the zero of $\eta (s)=\sum_{n=1}^{\infty}\dfrac {(-1)^{n-1}}{n^s}$ in the same range?","I have two questions concerning the Riemann zeta function which are rather trivial so if anyone can give me the answers that would be nice, here is what I`m interested in: 1) In the equality $\zeta(s)=\sum_{n=1}^{\infty} \dfrac {1}{n^s}$ is the term $\dfrac {1}{n^s}$ by the definition equal to $e^{-s\log n}$, where $e$ is the natural logarithm base and $\log$ is the natural logarithm? 2) Because it is the case that it holds that $\zeta (s)={\dfrac {1}{1-2^{1-s}}}\sum_{n=1}^{\infty}\dfrac {(-1)^{n-1}}{n^s}$ is finding the zero of $\zeta (s)$ in the range $0<\Re(s)<1$ equivalent to finding the zero of $\eta (s)=\sum_{n=1}^{\infty}\dfrac {(-1)^{n-1}}{n^s}$ in the same range?",,['complex-analysis']
63,Why can infinite product only be zero if one of the factors is zero?,Why can infinite product only be zero if one of the factors is zero?,,"I was reading about the Riemann zeta function in the region $Re(Z) > 1$, where it can be represented by the Euler product formula. And the book mentioned that there can be no zeros in this region, since each factor  $1/(1 - 1/p^s)$ is never zero. Can someone explain why the product can't converge to zero? For example,  consider the infinite product $1/2 \cdot 1/3 \cdot 1/4 \cdots$.  This seems to converge to zero, but each factor is not zero. Thanks!","I was reading about the Riemann zeta function in the region $Re(Z) > 1$, where it can be represented by the Euler product formula. And the book mentioned that there can be no zeros in this region, since each factor  $1/(1 - 1/p^s)$ is never zero. Can someone explain why the product can't converge to zero? For example,  consider the infinite product $1/2 \cdot 1/3 \cdot 1/4 \cdots$.  This seems to converge to zero, but each factor is not zero. Thanks!",,"['complex-analysis', 'infinite-product']"
64,Does there exist an analytic function on $\mathbb{C}$ such that $f(1/2n)=f(1/2n+1)=1/2n$?,Does there exist an analytic function on  such that ?,\mathbb{C} f(1/2n)=f(1/2n+1)=1/2n,"Does there exist an analytic function on $\mathbb{C}$ such that $f(1/2n)=f(1/2n+1)=1/2n$? Well, I considered a new function $g(z)=f(z)-z$. The zeroes of $g$ has limit point $0$ in $\mathbb{C}$ so $g(z)\equiv 0\Rightarrow f(z)=z$ but I checked that both the condition is not satisfied by $f$ i.e $f(1/2n+1)=1/2n\Rightarrow 1=0 \Leftrightarrow$ so such a non constant analytic function does not exists. Am I right? Please help!","Does there exist an analytic function on $\mathbb{C}$ such that $f(1/2n)=f(1/2n+1)=1/2n$? Well, I considered a new function $g(z)=f(z)-z$. The zeroes of $g$ has limit point $0$ in $\mathbb{C}$ so $g(z)\equiv 0\Rightarrow f(z)=z$ but I checked that both the condition is not satisfied by $f$ i.e $f(1/2n+1)=1/2n\Rightarrow 1=0 \Leftrightarrow$ so such a non constant analytic function does not exists. Am I right? Please help!",,['complex-analysis']
65,$f$ be an analytic function defined on $\mathbb{D}=\{z\in\mathbb{C}:|z|<1\}$,be an analytic function defined on,f \mathbb{D}=\{z\in\mathbb{C}:|z|<1\},"I came across the following problem that says: Let $f$ be an analytic function defined on $\mathbb{D}=\{z\in\mathbb{C}:|z|<1\}$ such that the range of $f$ is contained in the set $\mathbb{C}\setminus (-\infty,0]$ . Then $f$ is necessarily a constant function. there exists an analytic function $g$ on $\mathbb{D}$ such that $g(x)$ is a square root of $f(z)$ for each $z\in\mathbb{D}$ . there exists an analytic function $g$ on $\mathbb{D}$ such that $\operatorname{Re}g(z)\geq 0$ and $g(z)$ is a square root of $f(z)$ for each $z\in\mathbb{D}$ . there exists an analytic function $g$ on $\mathbb{D}$ such that $\operatorname{Re}g(z)\leq 0$ and $g(z)$ is a square root of $f(z)$ for each $z\in\mathbb{D}$ . I have to determine which options are correct. Can someone help in the right direction? Thanks in advance for your time.",I came across the following problem that says: Let be an analytic function defined on such that the range of is contained in the set . Then is necessarily a constant function. there exists an analytic function on such that is a square root of for each . there exists an analytic function on such that and is a square root of for each . there exists an analytic function on such that and is a square root of for each . I have to determine which options are correct. Can someone help in the right direction? Thanks in advance for your time.,"f \mathbb{D}=\{z\in\mathbb{C}:|z|<1\} f \mathbb{C}\setminus (-\infty,0] f g \mathbb{D} g(x) f(z) z\in\mathbb{D} g \mathbb{D} \operatorname{Re}g(z)\geq 0 g(z) f(z) z\in\mathbb{D} g \mathbb{D} \operatorname{Re}g(z)\leq 0 g(z) f(z) z\in\mathbb{D}",['complex-analysis']
66,Complex Analysis using Geometric Argument,Complex Analysis using Geometric Argument,,"I need to prove $|z-1| \le ||z|-1|+|z||\arg z|$ using a purely geometric argument. I know that $|z-1|$ is the distance from z to (1,0).  $|z|-1$ is the distance from $z$ to the edge of the unit circle when $z$ is outside of the unit circle. (Similarly, $1-|z|$ is the distance from $z$ to the edge of the unit circle when $z$ is inside of the unit circle.) I am, however, having a bit of difficulty interpreting what $|z||\arg z|$ is geometrically. I know that the two vectors $|z-1|$ and $|z|-1$ (or $1-|z|$) seem to form 2 sides of a triangle. I think that $|z||\arg z|$ must somehow be related to that last side of the triangle. Is $|z||\arg z|$ related to an arc? If so, how is that related to the triangle listed above? Thanks for all your help in advance!","I need to prove $|z-1| \le ||z|-1|+|z||\arg z|$ using a purely geometric argument. I know that $|z-1|$ is the distance from z to (1,0).  $|z|-1$ is the distance from $z$ to the edge of the unit circle when $z$ is outside of the unit circle. (Similarly, $1-|z|$ is the distance from $z$ to the edge of the unit circle when $z$ is inside of the unit circle.) I am, however, having a bit of difficulty interpreting what $|z||\arg z|$ is geometrically. I know that the two vectors $|z-1|$ and $|z|-1$ (or $1-|z|$) seem to form 2 sides of a triangle. I think that $|z||\arg z|$ must somehow be related to that last side of the triangle. Is $|z||\arg z|$ related to an arc? If so, how is that related to the triangle listed above? Thanks for all your help in advance!",,"['geometry', 'complex-analysis']"
67,Fibonacci( Binet's Formula Derivation)-Revised with work shown,Fibonacci( Binet's Formula Derivation)-Revised with work shown,,"Okay so here is the revised question with my current work. Links to previous post(s)(Just for Gerry): Fibonacci Numbers - Complex Analysis Here's my attempt on the problem set thus far: (Note that $\bullet$ represents a completed problem (in my opinion) while $\circ$ represents a semi-completed problem.) ~Problem set can be found on page 106: http://www.math.binghamton.edu/sabalka/teaching/09Spring375/Chapter10.pdf (2) To derive a generating function for $f_n$, note that the fibonacci series is defined by the sequence of numbers $(0,1,f_1+f_0,f_2+f_1,...f_n+f_n-1)$. If we break this up into three separate generating functions and sum them to obtain the generating function $F(z)$ it will look something like: $$(0,1,0,0,0...) \rightarrow\,z)$$ $$+(0,f_0,f_1,f_2,...)\to\,zF(z)$$ for a $F(z) = f_0+f_1z+f_2z^2+...+f_nz^n$  $$+ (0,0,,f_0,f_1,f_2,...)\to z^2F(z)$$ for the same $F(z)$ This all equals $$(0,1+f_0,f_1+f_0,f_2+f_1,f_3+f_2,...)\to z+zF(z)+z^2F(z)$$ Therefore $F(z)=z+zF(z)+z^2F(z)$, solving for $F(z)$ we obtain $$F(z) = \frac {z}{1-z-z^2} \bullet$$ P.S. I don't understand why it says $\frac{1}{1-z-z^2}$ instead of  $\frac{z}{1-z-z^2}$ in the original problem set. Is it because they're excluding the $f_0$ and $f_1$ terms? ~ I felt that it would make more sense to do (2) before (1) so here's (1) *First note that by the quadratic formula, the two roots of the denominator are $\varphi,\bar \varphi$ where $\varphi= \frac {1+\sqrt5}{2}$. So $F(z)$ has a positive radius of convergence by the ratio test which gives $r=\lim_{n\to\infty}\frac{f_n+1}{f_n}= \bar \varphi \bullet$ ~ (3) Now to show that $Res (\frac{1}{z^n+1(1-z-z^2)})$ at $z=0$ = $f_n$ I know that you must use the formula: $Res(f,c) = \frac{1}{n-1!}\lim_{z\to c}\frac{d^n-1}{dz^n-1} ((z-c)^nF(z)$ for a pole of order n. I need a little help here. I'm also confused as to where they get the $z^n+1$ from. Why does it appear there?      $\circ$ Edit I realized that since $$1=Res_{z=0}z^{-1}$$ then  z^n+1 would be the extracting term: $$f_n=Res_{z=0}\frac{1}{z^{n+1}} \sum_{n>1}{f_nz^n}$$ Is this correct? Edit According to Brian M. Scott, the proper work for this problem (3) is $$\begin{align*} \operatorname{Res}_{z=0}\left(\frac1{z^{n+1}(1-z-z^2)}\right)&=\frac1{n!}\lim_{z\to 0}\frac{d^n}{dz^n}\left(z^{n+1}\frac1{z^{n+1}(1-z-z^2)}\right)\\ &=\frac1{n!}\lim_{z\to 0}\frac{d^n}{dz^n}\big(F(z)\big)\\ &=\frac1{n!}\lim_{z\to 0}\frac{d^n}{dz^n}\sum_{k\ge 0}f_kz^k\\ &=\frac1{n!}\lim_{z\to 0}\sum_{k\ge 0}f_k\frac{d^n}{dz^n}z^k\\ &=\frac1{n!}\lim_{z\to 0}\sum_{k\ge n}f_k \Big( \prod_{i=0}^{n-1} (k-i) \Big)z^{k-n}\\ &=\frac1{n!}\lim_{z\to 0}\left(f_nn!+\sum_{k>n}f_k \Big( \prod_{i=0}^{n-1} (k-i) \Big) z^{k-n}\right)\\ &=f_n+\frac1{n!}\lim_{z\to 0}z\sum_{k\ge n+1}f_k \Big( \prod_{i=0}^{n-1} (k-i) \Big) z^{k-(n+1)}\\ &=f_n\; \bullet \end{align*}$$ I follow this work until the third to last step where I don't understand how he obtained the $f_nn!$ term. Any Explanations? (4)  Using the residue theorem $$\int_{\gamma} f(z) dz = 2 \pi i \sum_{\rho} \text{Res}(f(z)),z=\rho)$$ Now quite obviously applying this: $$\int_{\gamma} \frac{dz}{z^{n+1}(1-z-z^2)} = 2 \pi i [f_n + R\varphi + R_{\bar \varphi}]$$ Okay, so obviously we must parametrize over a circle of radius R. This parametrization is $\gamma(t) = Re^{it}$ because a circle is just a simple curve. Performing a change of variables, we obtain  $$\int_0^{2 \pi} \frac{i R e^{it} dt}{R^{n+1}e^{it(n+1)}(1-(Re^{it})-(Re^{it})^2)}$$ The only reason that I personally thought of why this integral $\to 0$ is because the one can trivially see that the denominator would be $>>$ than the numerator because you have $\infty$ raised to a power. I'm also confused as to why it's even necessary to show that this integral disappears as the Radius of the circle approaches $\infty$. Could someone care to explain? Finally, for the exact calculations of $(R\varphi, R_{\bar \varphi})$ First note that $(1-z-z^2)=(\varphi + z)(\bar \varphi-z) $$R_\varphi = \text{Res}(\frac{1}{z^{n+1}(1-z-z^2)},z=\varphi) = \lim_{z \to \varphi}\frac{z-\varphi}{z^{n+1}(1-z-z^2)} = \lim_{z \to -\varphi}\frac{z-\varphi}{z^{n+1}(\varphi + z)(\bar \varphi-z)} =\frac{1}{\varphi^{n+1}(1-\bar \varphi)}$$     Alternatively,   $$R_\bar \varphi = \text{Res}(\frac{1}{z^{n+1}(1-z-z^2)},z=\bar \varphi) = \lim_{z \to \bar \varphi}\frac{z-\bar \varphi}{z^{n+1}(1-z-z^2)} = \lim_{z \to \bar \varphi}\frac{z-\bar \varphi}{z^{n+1}(\varphi + z)(\bar \varphi-z)} =\frac{1}{\bar \varphi^{n+1}(1- \varphi)} \circ$ (5) Requires the completion of (4) This is all of my current work that I have thus far. I honestly do not know where to go from my last step in (4). I still need to arrive at a final identity for $f_n$. So I need to know how to continue this work. Any hints, etc? Thanks!~ Edit I now understand that $$f_n=Res (F(z)) at z=0= \Big(Res(F(z) at z=0 + Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) - \Big(Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) = {2\pi i}\int F(z)dz - - \Big(Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) = - \Big(Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) $$ because the integral $$2\pi i\int F(z)dz \to 0$$ as $R \to \infty$ Is this correct?","Okay so here is the revised question with my current work. Links to previous post(s)(Just for Gerry): Fibonacci Numbers - Complex Analysis Here's my attempt on the problem set thus far: (Note that $\bullet$ represents a completed problem (in my opinion) while $\circ$ represents a semi-completed problem.) ~Problem set can be found on page 106: http://www.math.binghamton.edu/sabalka/teaching/09Spring375/Chapter10.pdf (2) To derive a generating function for $f_n$, note that the fibonacci series is defined by the sequence of numbers $(0,1,f_1+f_0,f_2+f_1,...f_n+f_n-1)$. If we break this up into three separate generating functions and sum them to obtain the generating function $F(z)$ it will look something like: $$(0,1,0,0,0...) \rightarrow\,z)$$ $$+(0,f_0,f_1,f_2,...)\to\,zF(z)$$ for a $F(z) = f_0+f_1z+f_2z^2+...+f_nz^n$  $$+ (0,0,,f_0,f_1,f_2,...)\to z^2F(z)$$ for the same $F(z)$ This all equals $$(0,1+f_0,f_1+f_0,f_2+f_1,f_3+f_2,...)\to z+zF(z)+z^2F(z)$$ Therefore $F(z)=z+zF(z)+z^2F(z)$, solving for $F(z)$ we obtain $$F(z) = \frac {z}{1-z-z^2} \bullet$$ P.S. I don't understand why it says $\frac{1}{1-z-z^2}$ instead of  $\frac{z}{1-z-z^2}$ in the original problem set. Is it because they're excluding the $f_0$ and $f_1$ terms? ~ I felt that it would make more sense to do (2) before (1) so here's (1) *First note that by the quadratic formula, the two roots of the denominator are $\varphi,\bar \varphi$ where $\varphi= \frac {1+\sqrt5}{2}$. So $F(z)$ has a positive radius of convergence by the ratio test which gives $r=\lim_{n\to\infty}\frac{f_n+1}{f_n}= \bar \varphi \bullet$ ~ (3) Now to show that $Res (\frac{1}{z^n+1(1-z-z^2)})$ at $z=0$ = $f_n$ I know that you must use the formula: $Res(f,c) = \frac{1}{n-1!}\lim_{z\to c}\frac{d^n-1}{dz^n-1} ((z-c)^nF(z)$ for a pole of order n. I need a little help here. I'm also confused as to where they get the $z^n+1$ from. Why does it appear there?      $\circ$ Edit I realized that since $$1=Res_{z=0}z^{-1}$$ then  z^n+1 would be the extracting term: $$f_n=Res_{z=0}\frac{1}{z^{n+1}} \sum_{n>1}{f_nz^n}$$ Is this correct? Edit According to Brian M. Scott, the proper work for this problem (3) is $$\begin{align*} \operatorname{Res}_{z=0}\left(\frac1{z^{n+1}(1-z-z^2)}\right)&=\frac1{n!}\lim_{z\to 0}\frac{d^n}{dz^n}\left(z^{n+1}\frac1{z^{n+1}(1-z-z^2)}\right)\\ &=\frac1{n!}\lim_{z\to 0}\frac{d^n}{dz^n}\big(F(z)\big)\\ &=\frac1{n!}\lim_{z\to 0}\frac{d^n}{dz^n}\sum_{k\ge 0}f_kz^k\\ &=\frac1{n!}\lim_{z\to 0}\sum_{k\ge 0}f_k\frac{d^n}{dz^n}z^k\\ &=\frac1{n!}\lim_{z\to 0}\sum_{k\ge n}f_k \Big( \prod_{i=0}^{n-1} (k-i) \Big)z^{k-n}\\ &=\frac1{n!}\lim_{z\to 0}\left(f_nn!+\sum_{k>n}f_k \Big( \prod_{i=0}^{n-1} (k-i) \Big) z^{k-n}\right)\\ &=f_n+\frac1{n!}\lim_{z\to 0}z\sum_{k\ge n+1}f_k \Big( \prod_{i=0}^{n-1} (k-i) \Big) z^{k-(n+1)}\\ &=f_n\; \bullet \end{align*}$$ I follow this work until the third to last step where I don't understand how he obtained the $f_nn!$ term. Any Explanations? (4)  Using the residue theorem $$\int_{\gamma} f(z) dz = 2 \pi i \sum_{\rho} \text{Res}(f(z)),z=\rho)$$ Now quite obviously applying this: $$\int_{\gamma} \frac{dz}{z^{n+1}(1-z-z^2)} = 2 \pi i [f_n + R\varphi + R_{\bar \varphi}]$$ Okay, so obviously we must parametrize over a circle of radius R. This parametrization is $\gamma(t) = Re^{it}$ because a circle is just a simple curve. Performing a change of variables, we obtain  $$\int_0^{2 \pi} \frac{i R e^{it} dt}{R^{n+1}e^{it(n+1)}(1-(Re^{it})-(Re^{it})^2)}$$ The only reason that I personally thought of why this integral $\to 0$ is because the one can trivially see that the denominator would be $>>$ than the numerator because you have $\infty$ raised to a power. I'm also confused as to why it's even necessary to show that this integral disappears as the Radius of the circle approaches $\infty$. Could someone care to explain? Finally, for the exact calculations of $(R\varphi, R_{\bar \varphi})$ First note that $(1-z-z^2)=(\varphi + z)(\bar \varphi-z) $$R_\varphi = \text{Res}(\frac{1}{z^{n+1}(1-z-z^2)},z=\varphi) = \lim_{z \to \varphi}\frac{z-\varphi}{z^{n+1}(1-z-z^2)} = \lim_{z \to -\varphi}\frac{z-\varphi}{z^{n+1}(\varphi + z)(\bar \varphi-z)} =\frac{1}{\varphi^{n+1}(1-\bar \varphi)}$$     Alternatively,   $$R_\bar \varphi = \text{Res}(\frac{1}{z^{n+1}(1-z-z^2)},z=\bar \varphi) = \lim_{z \to \bar \varphi}\frac{z-\bar \varphi}{z^{n+1}(1-z-z^2)} = \lim_{z \to \bar \varphi}\frac{z-\bar \varphi}{z^{n+1}(\varphi + z)(\bar \varphi-z)} =\frac{1}{\bar \varphi^{n+1}(1- \varphi)} \circ$ (5) Requires the completion of (4) This is all of my current work that I have thus far. I honestly do not know where to go from my last step in (4). I still need to arrive at a final identity for $f_n$. So I need to know how to continue this work. Any hints, etc? Thanks!~ Edit I now understand that $$f_n=Res (F(z)) at z=0= \Big(Res(F(z) at z=0 + Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) - \Big(Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) = {2\pi i}\int F(z)dz - - \Big(Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) = - \Big(Res(F(z) at z= \varphi + Res(F(z) at z=\bar \varphi\Big) $$ because the integral $$2\pi i\int F(z)dz \to 0$$ as $R \to \infty$ Is this correct?",,"['complex-analysis', 'fibonacci-numbers', 'residue-calculus']"
68,Evaluating real integral using residue calculus: why different results?,Evaluating real integral using residue calculus: why different results?,,"I have to evaluate the real integral $$ I = \int_0^{\infty} \frac{\log^2 x}{x^2+1}. $$ using residue calculus. Its value is $\frac{\pi^3}{8}$, as you can verify (for example) introducing the function $$   \frac{(\log z-i(\pi/2))^2}{z^2+1}. $$ and considering the branch cut for the logarithm function on the negative semiaxis of the immaginary numbers and an upper half-circle indented at 0 as integration contour. I tried a different method , but unfortunately I obtained a different result and I don't know why. I consider the branching axis of the logarithm function as the positive real semiaxis. I tried as integration contour this closed curve. I used the complex function $$ f(z)=\frac{\log^3z}{z^2+1} $$ obtaining  $$ \int_r^{R} \frac{\log^3 x}{x^2+1}\;dx + \int_\Gamma \frac{\log^3 z}{z^2+1}\;dz - \int_r^{R} \frac{(\log x+2\pi i)^3}{x^2+1}\;dx - \int_\gamma \frac{\log^3 z}{z^2+1}\;dz. $$ It is easy to see that integrals over circular paths $\gamma$ and $\Gamma$ tend to zero when $R\to \infty,r\to 0$. So we have to evaluate $$ \int_r^{R} \frac{\log^3 x}{x^2+1}\;dx - \int_r^{R} \frac{(\log x+2\pi i)^3}{x^2+1}\;dx, $$ which immaginary part is ( EDIT : changed $8\pi i$ to $8\pi^3 i$ ) $$ -6\pi i \int_r^{R} \frac{\log^2 x}{x^2+1}\;dx + 8\pi^3 i \int_r^{R} \frac{1}{x^2+1}\;dx, $$ that has to be equal to the immaginary part of $$ 2\pi i\;\left( \mathrm{Res} \left[f,i \right] + \mathrm{Res}\left[f,-i \right]\right) = -i \frac{\pi^4}{4}. $$  So, doing the rest of the work, finally I found that the result is $\frac{17\pi^3}{24}$, that is clearly different from $\frac{\pi^3}{8}$... but where is the flaw in my argument? Please help","I have to evaluate the real integral $$ I = \int_0^{\infty} \frac{\log^2 x}{x^2+1}. $$ using residue calculus. Its value is $\frac{\pi^3}{8}$, as you can verify (for example) introducing the function $$   \frac{(\log z-i(\pi/2))^2}{z^2+1}. $$ and considering the branch cut for the logarithm function on the negative semiaxis of the immaginary numbers and an upper half-circle indented at 0 as integration contour. I tried a different method , but unfortunately I obtained a different result and I don't know why. I consider the branching axis of the logarithm function as the positive real semiaxis. I tried as integration contour this closed curve. I used the complex function $$ f(z)=\frac{\log^3z}{z^2+1} $$ obtaining  $$ \int_r^{R} \frac{\log^3 x}{x^2+1}\;dx + \int_\Gamma \frac{\log^3 z}{z^2+1}\;dz - \int_r^{R} \frac{(\log x+2\pi i)^3}{x^2+1}\;dx - \int_\gamma \frac{\log^3 z}{z^2+1}\;dz. $$ It is easy to see that integrals over circular paths $\gamma$ and $\Gamma$ tend to zero when $R\to \infty,r\to 0$. So we have to evaluate $$ \int_r^{R} \frac{\log^3 x}{x^2+1}\;dx - \int_r^{R} \frac{(\log x+2\pi i)^3}{x^2+1}\;dx, $$ which immaginary part is ( EDIT : changed $8\pi i$ to $8\pi^3 i$ ) $$ -6\pi i \int_r^{R} \frac{\log^2 x}{x^2+1}\;dx + 8\pi^3 i \int_r^{R} \frac{1}{x^2+1}\;dx, $$ that has to be equal to the immaginary part of $$ 2\pi i\;\left( \mathrm{Res} \left[f,i \right] + \mathrm{Res}\left[f,-i \right]\right) = -i \frac{\pi^4}{4}. $$  So, doing the rest of the work, finally I found that the result is $\frac{17\pi^3}{24}$, that is clearly different from $\frac{\pi^3}{8}$... but where is the flaw in my argument? Please help",,"['complex-analysis', 'residue-calculus', 'complex-integration']"
69,Are limit superior and limit inferior defined for $z_n$ being a complex sequence?,Are limit superior and limit inferior defined for  being a complex sequence?,z_n,All the definitions of limit superior and limit inferior I have seen (even in the books about complex analysis) define them for a real sequence only. What could stop us from defining it as follow for a complex sequence? $$\limsup\limits_{n\to\infty} z_n := \lim_{n\to\infty}\Big(\sup\{|z_k|:k \geq n\}\Big)$$ $$\liminf\limits_{n\to\infty} z_n := \lim_{n\to\infty}\Big(\inf\{|z_k|:k \geq n\}\Big)$$,All the definitions of limit superior and limit inferior I have seen (even in the books about complex analysis) define them for a real sequence only. What could stop us from defining it as follow for a complex sequence? $$\limsup\limits_{n\to\infty} z_n := \lim_{n\to\infty}\Big(\sup\{|z_k|:k \geq n\}\Big)$$ $$\liminf\limits_{n\to\infty} z_n := \lim_{n\to\infty}\Big(\inf\{|z_k|:k \geq n\}\Big)$$,,"['complex-analysis', 'limsup-and-liminf']"
70,Prove that the only root of the equation $z-\sin(z)$ in the unit disk is zero.,Prove that the only root of the equation  in the unit disk is zero.,z-\sin(z),"Prove that the only root of the equation $z-\sin(z)$  in the unit disk is $z=0$. My first thought is Rouche's Theorem, but I don't know any bounds on $|\sin(z)|$. Suggestions?","Prove that the only root of the equation $z-\sin(z)$  in the unit disk is $z=0$. My first thought is Rouche's Theorem, but I don't know any bounds on $|\sin(z)|$. Suggestions?",,['complex-analysis']
71,How does one prove Riemann's explicit formula?,How does one prove Riemann's explicit formula?,,"Q: Is there a reference for a detailed proof of Riemann's explicit formula ? I am reading the TeXified version of Riemann's manuscript, but sometimes I can't follow (I think the author has kept typos from the orignal paper ). Here are some points I have trouble with (but there are others) : How does he calculate $$\int_{a+i\mathbb{R}} \frac{d}{ds} \left( \frac{1}{s} \log(1-s/\beta)\right) x^s ds$$ on page 4 ? What do I need to know about $Li(x)$ to see how the terms $Li(x^{1/2+i\alpha})$ appear ?","Q: Is there a reference for a detailed proof of Riemann's explicit formula ? I am reading the TeXified version of Riemann's manuscript, but sometimes I can't follow (I think the author has kept typos from the orignal paper ). Here are some points I have trouble with (but there are others) : How does he calculate $$\int_{a+i\mathbb{R}} \frac{d}{ds} \left( \frac{1}{s} \log(1-s/\beta)\right) x^s ds$$ on page 4 ? What do I need to know about $Li(x)$ to see how the terms $Li(x^{1/2+i\alpha})$ appear ?",,"['number-theory', 'complex-analysis']"
72,Residue of $f(z) = \frac{z}{1-\cos(z)}$ at $z=0$,Residue of  at,f(z) = \frac{z}{1-\cos(z)} z=0,"I've been self-studying some complex variables and just started on residues. I'm looking at a problem where I've been asked to calculate the residue of: $$f(z) = \frac{z}{1-\cos(z)}$$ at $z=0$. I'm not really sure how to find the Laurent series of this function, and I can't really apply Cauchy's integral formula either. So I would appreciate if anyone can get me started.","I've been self-studying some complex variables and just started on residues. I'm looking at a problem where I've been asked to calculate the residue of: $$f(z) = \frac{z}{1-\cos(z)}$$ at $z=0$. I'm not really sure how to find the Laurent series of this function, and I can't really apply Cauchy's integral formula either. So I would appreciate if anyone can get me started.",,['complex-analysis']
73,Problem on analytic function.,Problem on analytic function.,,Let $f(z)$ be analytic function on $D = \{z\in C : |z-1|<1\}$ such that $f(1) = 1$. If $f(z) = f(z^2)$ for all $z\in D$. Then which of the following statement is not correct. 1-$f(z) = [f(z)]^2$ for all $z\in D$ 2- $f(z/2)$ = $\frac{1}{2}[f(z)]$ for all $z\in D$ 3- $f(z) = [f(z)]^3$ for all $z\in D$ 4- $f'(1) = 0$ I am fully stucked on this problem.  I need help. Thanks,Let $f(z)$ be analytic function on $D = \{z\in C : |z-1|<1\}$ such that $f(1) = 1$. If $f(z) = f(z^2)$ for all $z\in D$. Then which of the following statement is not correct. 1-$f(z) = [f(z)]^2$ for all $z\in D$ 2- $f(z/2)$ = $\frac{1}{2}[f(z)]$ for all $z\in D$ 3- $f(z) = [f(z)]^3$ for all $z\in D$ 4- $f'(1) = 0$ I am fully stucked on this problem.  I need help. Thanks,,['complex-analysis']
74,Showing $\sum_{n=-\infty}^\infty \frac{1}{(z+n)^2}=\frac{\pi^2}{\sin^2(\pi z)}$,Showing,\sum_{n=-\infty}^\infty \frac{1}{(z+n)^2}=\frac{\pi^2}{\sin^2(\pi z)},"I'm doing a homework problem, and so far I've proved $$\sum_{n=-\infty}^\infty \frac{1}{(z+n)^k}=\frac{(-2\pi i)^k}{(k-1)!}\sum_{m=1}^\infty m^{k-1}e^{2\pi imz}$$ for $k$ an integer $\geq 2$ and $\text{Im}(z)>0$. The next part of the problem asks me to put $k=2$ and show  $$\sum_{n=-\infty}^\infty \frac{1}{(z+n)^2}=\frac{\pi^2}{\sin^2(\pi z)}$$ for $\text{Im}(z)>0$, but after nearly an hour of bashing I still see it-- I've tried product expansions of sine, using Euler's formula (which equates to showing $\frac{e^{2\pi ir}+e^{-2\pi ir}-2}{16}=-4\pi^2 \sum_{m=1}^\infty me^{2\pi imz}$). Could anybody point out a way to get the above equality from the one I derived? Apologies in advance if I'm just ditzy and it's really obvious. Also, the next question asks if the above formula is true if $z$ is any complex number that is not an integer, but I'm not really sure I understand what it's asking. Why wouldn't it be true?","I'm doing a homework problem, and so far I've proved $$\sum_{n=-\infty}^\infty \frac{1}{(z+n)^k}=\frac{(-2\pi i)^k}{(k-1)!}\sum_{m=1}^\infty m^{k-1}e^{2\pi imz}$$ for $k$ an integer $\geq 2$ and $\text{Im}(z)>0$. The next part of the problem asks me to put $k=2$ and show  $$\sum_{n=-\infty}^\infty \frac{1}{(z+n)^2}=\frac{\pi^2}{\sin^2(\pi z)}$$ for $\text{Im}(z)>0$, but after nearly an hour of bashing I still see it-- I've tried product expansions of sine, using Euler's formula (which equates to showing $\frac{e^{2\pi ir}+e^{-2\pi ir}-2}{16}=-4\pi^2 \sum_{m=1}^\infty me^{2\pi imz}$). Could anybody point out a way to get the above equality from the one I derived? Apologies in advance if I'm just ditzy and it's really obvious. Also, the next question asks if the above formula is true if $z$ is any complex number that is not an integer, but I'm not really sure I understand what it's asking. Why wouldn't it be true?",,"['complex-analysis', 'fourier-analysis']"
75,"why not define $H^{p,q}_{\partial}(M)$?",why not define ?,"H^{p,q}_{\partial}(M)","Let $M$ be a complex manifold, $A^{p,q}(M)$ be $C^{\infty}$ $(p,q)$ form. Dolbeault cohomology $H^{p,q}_{\bar{\partial}}(M)$ is defined as the cohomology with boundary map $\bar{\partial}$, but why not define $H^{p,q}_{\partial}(M)$, with boundary map $\partial$?","Let $M$ be a complex manifold, $A^{p,q}(M)$ be $C^{\infty}$ $(p,q)$ form. Dolbeault cohomology $H^{p,q}_{\bar{\partial}}(M)$ is defined as the cohomology with boundary map $\bar{\partial}$, but why not define $H^{p,q}_{\partial}(M)$, with boundary map $\partial$?",,"['complex-analysis', 'differential-geometry']"
76,On the Cayley (conformal) transform,On the Cayley (conformal) transform,,"Prove that the function $$ \begin{align} \phi (z) = i \dfrac{1 - z}{1 + z} \end{align} $$ maps the set $D = \{z \in \mathbb{C}: |z| < 1 \} $ one-to-one onto the set $U = \{ z \in \mathbb{C} : Im(z) > 0 \}$ . (This is exercise 1.9 in ""Function Theory..."" by Green & Krantz, and is also a claim on the Wikipedia page , though they have a function $W:U \to D $ ...) For injective, I suppose that $$\begin{align} \phi (z)  &= \phi (w) \\ \\ i \dfrac{1 - z}{1 + z}&= i \dfrac{1 - w}{1 + w} \end{align}$$ ... and after a few manipulations, end up with $z = w$ . For surjective, I am stuck. Q: How to I prove ""onto""? Do I work with $z, w$ in $(x + i \cdot y)$ form? Also, how/where do I use that $|z| < 1$ (in $D$ ) or that $Im (\phi (z)) >0$ ?","Prove that the function maps the set one-to-one onto the set . (This is exercise 1.9 in ""Function Theory..."" by Green & Krantz, and is also a claim on the Wikipedia page , though they have a function ...) For injective, I suppose that ... and after a few manipulations, end up with . For surjective, I am stuck. Q: How to I prove ""onto""? Do I work with in form? Also, how/where do I use that (in ) or that ?"," \begin{align} \phi (z) = i \dfrac{1 - z}{1 + z} \end{align}  D = \{z \in \mathbb{C}: |z| < 1 \}  U = \{ z \in \mathbb{C} : Im(z) > 0 \} W:U \to D  \begin{align} \phi (z)  &= \phi (w) \\ \\ i \dfrac{1 - z}{1 + z}&= i \dfrac{1 - w}{1 + w} \end{align} z = w z, w (x + i \cdot y) |z| < 1 D Im (\phi (z)) >0",['complex-analysis']
77,Polynomials that are orthogonal over curves in the complex plane,Polynomials that are orthogonal over curves in the complex plane,,"Various important sets of polynomials (Legendre, Chebyshev, etc.) are orthogonal over some real interval with some weighting.  Are there known families of polynomials that are orthogonal over other curves in the complex plane? For instance, I would like a basis for the polynomials of degree n that is orthogonal over, say, the circle $$-1 + \exp(it)$$ for  $0\le t< 2\pi$.","Various important sets of polynomials (Legendre, Chebyshev, etc.) are orthogonal over some real interval with some weighting.  Are there known families of polynomials that are orthogonal over other curves in the complex plane? For instance, I would like a basis for the polynomials of degree n that is orthogonal over, say, the circle $$-1 + \exp(it)$$ for  $0\le t< 2\pi$.",,"['complex-analysis', 'polynomials']"
78,Finding a primitive explicitly,Finding a primitive explicitly,,"Let $A=\{z\in\mathbb{C}~:~|z|>4\}$.  Let $f(z)=\frac{z}{(z-1)(z-2)(z-3)}$ and $g(z)=\frac{z^2}{(z-1)(z-2)(z-3)}$. I have been asked whether or not $f$ and $g$ have global primitives in $A$ and if so to find them. After decomposing into partial fractions I have: $f(z)=\frac{1}{2}\bigg(\frac{1}{z-1}\bigg)-2\bigg(\frac{1}{z-2}\bigg)+\frac{3}{2}\bigg(\frac{1}{z-3}\bigg)$ and $g(z)=\frac{1}{2}\bigg(\frac{1}{z-1}\bigg)+-4\bigg(\frac{1}{z-2}\bigg)+\frac{9}{2}\bigg(\frac{1}{z-3}\bigg)$. Now my understanding of the complex logarithm is not great, but from what I understand, in any simply connected open subset of $\mathbb{C}-{a}$ there is a branch of $\log(z-a)$ serving as a primitive for $\frac{1}{z-a}$.  However our region $A$ is not simply connected.  How can we work around this? Thanks for any advice and/or deeper insights into understanding primitives involving logs/mulitivalued functions. $\bf{UPDATE:}$  Thanks to zyx's answer, I have made the following realization.  To show the existence of a primitive for a given function in the domain $A$, I just need to show that the integral around every closed loop in $A$ evaluates to 0.  For loops which wind around the complement of $A$, this only happens when the coefficients of the $\frac{1}{z-a}$ terms sum to 0, as hinted below. However I still do not really understand why we can say the primitive $\frac{1}{2}\log(z-1)-2\log(z-2)+\frac{3}{2}\log(z-3)$ is well defined in $A$.","Let $A=\{z\in\mathbb{C}~:~|z|>4\}$.  Let $f(z)=\frac{z}{(z-1)(z-2)(z-3)}$ and $g(z)=\frac{z^2}{(z-1)(z-2)(z-3)}$. I have been asked whether or not $f$ and $g$ have global primitives in $A$ and if so to find them. After decomposing into partial fractions I have: $f(z)=\frac{1}{2}\bigg(\frac{1}{z-1}\bigg)-2\bigg(\frac{1}{z-2}\bigg)+\frac{3}{2}\bigg(\frac{1}{z-3}\bigg)$ and $g(z)=\frac{1}{2}\bigg(\frac{1}{z-1}\bigg)+-4\bigg(\frac{1}{z-2}\bigg)+\frac{9}{2}\bigg(\frac{1}{z-3}\bigg)$. Now my understanding of the complex logarithm is not great, but from what I understand, in any simply connected open subset of $\mathbb{C}-{a}$ there is a branch of $\log(z-a)$ serving as a primitive for $\frac{1}{z-a}$.  However our region $A$ is not simply connected.  How can we work around this? Thanks for any advice and/or deeper insights into understanding primitives involving logs/mulitivalued functions. $\bf{UPDATE:}$  Thanks to zyx's answer, I have made the following realization.  To show the existence of a primitive for a given function in the domain $A$, I just need to show that the integral around every closed loop in $A$ evaluates to 0.  For loops which wind around the complement of $A$, this only happens when the coefficients of the $\frac{1}{z-a}$ terms sum to 0, as hinted below. However I still do not really understand why we can say the primitive $\frac{1}{2}\log(z-1)-2\log(z-2)+\frac{3}{2}\log(z-3)$ is well defined in $A$.",,['complex-analysis']
79,analytic functions from square to unit disk,analytic functions from square to unit disk,,"Let $f$ be an analytic function from $\{z; -1 < \Re(z) < 1, -1 < \Im(z) < 1\}$ to $\{z; |z| < 1\}$. If $f(0)=0$ and $f$ is one-one and onto, should $f(i\ z)=i\ f(z)$ for each $z$? I tried to show that $f(i\ z)-i\ f(z)$ is a constant, but it seems that I could not use  Liouville Theorem. Thank you very much.","Let $f$ be an analytic function from $\{z; -1 < \Re(z) < 1, -1 < \Im(z) < 1\}$ to $\{z; |z| < 1\}$. If $f(0)=0$ and $f$ is one-one and onto, should $f(i\ z)=i\ f(z)$ for each $z$? I tried to show that $f(i\ z)-i\ f(z)$ is a constant, but it seems that I could not use  Liouville Theorem. Thank you very much.",,[]
80,Why only one singularity is involved? $\int_{0}^{2\pi} \frac{1}{13+5\sin(\theta)}~d\theta$,Why only one singularity is involved?,\int_{0}^{2\pi} \frac{1}{13+5\sin(\theta)}~d\theta,"I solved the integral $$\int_{0}^{2\pi} \frac{1}{13+5\sin(\theta)}~d\theta$$ with the residue theorem and Cauchy’s Integral Formula. The following is the solution, but I am unsure why in the end we consider only one of the residues which is a singularity point in the unit circle. Making the substitution $z=e^{i\theta}$ , $d\theta=\frac{dz}{iz}$ , with $z$ being the unit circle in the complex plane: $$ \int_{0}^{2\pi}\frac{1}{13+5\sin(\theta)}d\theta = 2\oint_{C}\frac{1}{5z^2+26iz-5}dz = \frac{2}{5}\oint_{C}\frac{1}{(z+\frac{i}{5})(z+5i)}dz$$ Therefore, the singular points are $-i/5$ and $-5i$ . Now this is where I’m confused. Since we made the substitution on the unit circle, the only relevant singularity point is $-i/5$ , and thus we ignore the other residue when using Cauchy’s Integral Formula. $$ \frac{2}{5}\oint_{C}\frac{1}{(z+\frac{i}{5})(z+5i)}=\frac{2}{5}\cdot2\pi i\cdot \operatorname{Res}\left(z=-\frac{i}{5}\right)=\frac{\pi}{6}$$ My question is, since we arbitrarily used the unit circle for our substitution, isn’t it just as valid to use a substitution for a circle with a larger radius? Could the larger radius lead to all singular points of $f(z)$ being inside this larger circle, resulting in two residues? Or will the substitution with the inclusion of radius $R$ at the beginning lead to the same outcome?","I solved the integral with the residue theorem and Cauchy’s Integral Formula. The following is the solution, but I am unsure why in the end we consider only one of the residues which is a singularity point in the unit circle. Making the substitution , , with being the unit circle in the complex plane: Therefore, the singular points are and . Now this is where I’m confused. Since we made the substitution on the unit circle, the only relevant singularity point is , and thus we ignore the other residue when using Cauchy’s Integral Formula. My question is, since we arbitrarily used the unit circle for our substitution, isn’t it just as valid to use a substitution for a circle with a larger radius? Could the larger radius lead to all singular points of being inside this larger circle, resulting in two residues? Or will the substitution with the inclusion of radius at the beginning lead to the same outcome?",\int_{0}^{2\pi} \frac{1}{13+5\sin(\theta)}~d\theta z=e^{i\theta} d\theta=\frac{dz}{iz} z  \int_{0}^{2\pi}\frac{1}{13+5\sin(\theta)}d\theta = 2\oint_{C}\frac{1}{5z^2+26iz-5}dz = \frac{2}{5}\oint_{C}\frac{1}{(z+\frac{i}{5})(z+5i)}dz -i/5 -5i -i/5  \frac{2}{5}\oint_{C}\frac{1}{(z+\frac{i}{5})(z+5i)}=\frac{2}{5}\cdot2\pi i\cdot \operatorname{Res}\left(z=-\frac{i}{5}\right)=\frac{\pi}{6} f(z) R,"['complex-analysis', 'contour-integration', 'complex-integration', 'residue-calculus', 'cauchy-integral-formula']"
81,Real part of $ \quad 1- \frac{2}{\pi} \arctan(r^{\rho}e^{i\rho\theta}).$,Real part of, \quad 1- \frac{2}{\pi} \arctan(r^{\rho}e^{i\rho\theta}).,"To solve the Dirichlet problem  using mellin transform, i needed to find the real part of $ \quad 1- \displaystyle\frac{2}{\pi} \arctan(r^{\rho}e^{i\rho\theta}).$ I already know the result will be \begin{cases} \quad 1- \displaystyle \frac{1}{\pi}\arctan(\frac{2r^{\rho}\cos(\rho \theta)}{1-r^{2\rho}}) & \text{ si } r\in [0, 1]\\ \quad \\ \quad  \displaystyle \frac{1}{\pi}\arctan(\frac{2r^{\rho}\cos(\rho \theta)}{r^{2\rho}-1}) & \text{ si } r\in ]1,+\infty[.\\ \end{cases} I find it in ""Dautray R., Lions J.L.,  Mathematical analysis and numerical calculation for science and technology."" I want to know how they found it ?","To solve the Dirichlet problem  using mellin transform, i needed to find the real part of I already know the result will be I find it in ""Dautray R., Lions J.L.,  Mathematical analysis and numerical calculation for science and technology."" I want to know how they found it ?"," \quad 1- \displaystyle\frac{2}{\pi} \arctan(r^{\rho}e^{i\rho\theta}). \begin{cases}
\quad 1- \displaystyle \frac{1}{\pi}\arctan(\frac{2r^{\rho}\cos(\rho \theta)}{1-r^{2\rho}}) & \text{ si } r\in [0, 1]\\ \quad \\
\quad  \displaystyle \frac{1}{\pi}\arctan(\frac{2r^{\rho}\cos(\rho \theta)}{r^{2\rho}-1}) & \text{ si } r\in ]1,+\infty[.\\
\end{cases}","['real-analysis', 'calculus', 'complex-analysis', 'complex-numbers']"
82,"Given $u(x,y) = e^x (x \cos y - y \sin y)$ for analytic $f(z) = u + iv$, find $v(x,y)$","Given  for analytic , find","u(x,y) = e^x (x \cos y - y \sin y) f(z) = u + iv v(x,y)","Given $u(x,y) = e^x (x \cos y - y \sin y)$ for analytic $f(z) = u + iv$ , find $v(x,y)$ . I know that there is an answer to this question in For an analytic function $f(z)=u+iv$, if $u=e^x(x \cos y-y \sin x)$ find $v$. . But it seems to me that approach used there is specific to the problem (the choice of the integration path). Is it? If not, could you exlain how the integration path is chosen? If it is, could you exlain what the general approach is to solve such problems? I know, I should check if $u$ is harmonic, then I should find the harmonic conjugate of $u$ but I don't know what path to choose (usually I'd take the line connecting $(0,0)$ and $(x,y)$ . In this case it results in rather complicated integrals so I think there has to be a better path to integrate over. A clarification would be very helpful. Thanks in advance.","Given for analytic , find . I know that there is an answer to this question in For an analytic function $f(z)=u+iv$, if $u=e^x(x \cos y-y \sin x)$ find $v$. . But it seems to me that approach used there is specific to the problem (the choice of the integration path). Is it? If not, could you exlain how the integration path is chosen? If it is, could you exlain what the general approach is to solve such problems? I know, I should check if is harmonic, then I should find the harmonic conjugate of but I don't know what path to choose (usually I'd take the line connecting and . In this case it results in rather complicated integrals so I think there has to be a better path to integrate over. A clarification would be very helpful. Thanks in advance.","u(x,y) = e^x (x \cos y - y \sin y) f(z) = u + iv v(x,y) u u (0,0) (x,y)","['complex-analysis', 'harmonic-functions', 'analytic-functions']"
83,Extending an automorphism of the upper-half plane to the whole Riemann sphere,Extending an automorphism of the upper-half plane to the whole Riemann sphere,,"We know the automorphism group of the upper-half plane $\mathbb{H} \subset \mathbb{C}$ is given by $\Big\{ \frac{az+b}{cz+d} \quad \big|\quad a,b,c,d \in \mathbb{R} \quad \text{and } ad-bc>0 \Big\}$ . This is usually proved in textbooks by mapping this set to $\text{Aut}(\mathbb{D})$ and then using our explicit knowledge of $\text{Aut}(\mathbb{D})$ . I was trying to prove this result using the fact that $\text{Aut}(\mathbb{C}_{\infty})=\Big\{ \frac{az+b}{cz+d} \quad \big| \quad a,b,c,d \in \mathbb{C} \quad \text{and } ad-bc \neq 0 \Big \}$ , where $\mathbb{C}_{\infty}$ is the Riemann sphere. The idea is: It is clear that $\Big\{ \frac{az+b}{cz+d} \quad \big| \quad a,b,c,d \in \mathbb{R} \quad \text{and } ad-bc>0 \Big\}$ are in $\text{Aut}(\mathbb{H})$ . For the other way, let $\varphi \in \text{Aut}({\mathbb{H}})$ .  Suppose we can extend $\varphi$ to an automorphism of $\mathbb{C}_{\infty}$ and call this extension $\Phi$ . Now, \begin{equation} \Phi(z)=\frac{az+b}{cz+d} \quad a,b,c,d \in \mathbb{C} \quad \text{and } ad-bc \neq 0  \end{equation} As $\Phi \big| _{\mathbb{H}}=\varphi \in \text{Aut}(\mathbb{H})$ , we must have $\Phi(\mathbb{R}) \subseteq \mathbb{R}$ . So $a,b,c \text{ and }d$ are in fact real. Now \begin{equation} \text{Im}(\Phi(z))= \text{Im}\left(\frac{az+b}{cz+d}\right)=\text{Im}\left(\frac{(az+b)(c\bar{z}+d)}{|cz+d|^2}\right)=\text{Im}\left(\frac{adz+bc\bar{z}}{|cz+d|^2}\right)=\frac{(ad-bc)y}{|cz+d|^2} \end{equation} where $y=\text{Im}(z)$ . We need $\text{Im}(\Phi(z))>0$ whenever $\text{Im}(z)>0$ . Hence, $ad-bc>0$ . But it is not at all clear to me how to extend $\varphi$ to an automorphism of $\mathbb{C}_{\infty}$ . I know it can be continuously extended to $\mathbb{R}$ and then to the whole of $\mathbb{C}$ by a reflection but this is not enough. Any help would be appreciated.","We know the automorphism group of the upper-half plane is given by . This is usually proved in textbooks by mapping this set to and then using our explicit knowledge of . I was trying to prove this result using the fact that , where is the Riemann sphere. The idea is: It is clear that are in . For the other way, let .  Suppose we can extend to an automorphism of and call this extension . Now, As , we must have . So are in fact real. Now where . We need whenever . Hence, . But it is not at all clear to me how to extend to an automorphism of . I know it can be continuously extended to and then to the whole of by a reflection but this is not enough. Any help would be appreciated.","\mathbb{H} \subset \mathbb{C} \Big\{ \frac{az+b}{cz+d} \quad \big|\quad a,b,c,d \in \mathbb{R} \quad \text{and } ad-bc>0 \Big\} \text{Aut}(\mathbb{D}) \text{Aut}(\mathbb{D}) \text{Aut}(\mathbb{C}_{\infty})=\Big\{ \frac{az+b}{cz+d} \quad \big| \quad a,b,c,d \in \mathbb{C} \quad \text{and } ad-bc \neq 0 \Big \} \mathbb{C}_{\infty} \Big\{ \frac{az+b}{cz+d} \quad \big| \quad a,b,c,d \in \mathbb{R} \quad \text{and } ad-bc>0 \Big\} \text{Aut}(\mathbb{H}) \varphi \in \text{Aut}({\mathbb{H}}) \varphi \mathbb{C}_{\infty} \Phi \begin{equation}
\Phi(z)=\frac{az+b}{cz+d} \quad a,b,c,d \in \mathbb{C} \quad \text{and } ad-bc \neq 0 
\end{equation} \Phi \big| _{\mathbb{H}}=\varphi \in \text{Aut}(\mathbb{H}) \Phi(\mathbb{R}) \subseteq \mathbb{R} a,b,c \text{ and }d \begin{equation}
\text{Im}(\Phi(z))= \text{Im}\left(\frac{az+b}{cz+d}\right)=\text{Im}\left(\frac{(az+b)(c\bar{z}+d)}{|cz+d|^2}\right)=\text{Im}\left(\frac{adz+bc\bar{z}}{|cz+d|^2}\right)=\frac{(ad-bc)y}{|cz+d|^2}
\end{equation} y=\text{Im}(z) \text{Im}(\Phi(z))>0 \text{Im}(z)>0 ad-bc>0 \varphi \mathbb{C}_{\infty} \mathbb{R} \mathbb{C}","['complex-analysis', 'riemann-surfaces', 'mobius-transformation']"
84,"Under what conditions, or how can be done that, one says that something divergent can have a value?","Under what conditions, or how can be done that, one says that something divergent can have a value?",,"Excuse my question, I just don't get it. In this proof , is mentioned: Now if you write formally the derivative of the Dirichlet-series for zeta then you have $$ \zeta'(s) = {\ln(1) \over 1^s}+{\ln(1/2) \over 2^s}  +{\ln(1/3) \over 3^s} + \ldots $$ This is for some s convergent and from there can be analytically continued to $s=0$ as well from where the the formal expression reduces to $$ \zeta'(0) = -(\ln(1) +\ln(2) +\ln(3)  + \ldots )$$ which is then formally identical to $ - \lim_{n \to \infty} \ln(n!)$ . That is, one ultimately gets $ - \lim_{n \to \infty} \ln(n!)$ In that same proof, mentions that $\zeta'(0)=-\ln\sqrt{2\pi}$ Ultimately, one would get to "" $\infty!=\sqrt{2\pi}$ "" Why the two values "" $\infty$ "" and $\sqrt{2\pi}$ were assigned to be equal? Thanks in advance.","Excuse my question, I just don't get it. In this proof , is mentioned: Now if you write formally the derivative of the Dirichlet-series for zeta then you have This is for some s convergent and from there can be analytically continued to as well from where the the formal expression reduces to which is then formally identical to . That is, one ultimately gets In that same proof, mentions that Ultimately, one would get to "" "" Why the two values "" "" and were assigned to be equal? Thanks in advance.", \zeta'(s) = {\ln(1) \over 1^s}+{\ln(1/2) \over 2^s}  +{\ln(1/3) \over 3^s} + \ldots  s=0  \zeta'(0) = -(\ln(1) +\ln(2) +\ln(3)  + \ldots )  - \lim_{n \to \infty} \ln(n!)  - \lim_{n \to \infty} \ln(n!) \zeta'(0)=-\ln\sqrt{2\pi} \infty!=\sqrt{2\pi} \infty \sqrt{2\pi},"['complex-analysis', 'proof-explanation', 'analytic-number-theory', 'riemann-zeta', 'analytic-continuation']"
85,On a Geometric Proof (Ahlfors) that the Cross ratio is real if and only if four points lie on a circle or straight line,On a Geometric Proof (Ahlfors) that the Cross ratio is real if and only if four points lie on a circle or straight line,,"The cross-ratio $(z_1,z_2,z_3,z_4)$ is real if and only if the four points lie on a circle or on a straight line. I know this question has been asked numerous times on MSE, but I have a specific question with respect to how Ahlfors proves this on page 79 of his book.  He says, ""This is evident by elementary geometry, for we obtain $$\text{arg}(z_1,z_2,z_3,z_4)=\text{arg}\frac{z_1-z_3}{z_1-z_4}-\text{arg}\frac{z_2-z_3}{z_2-z_4}$$ and if the points lie on a circle this difference of angles is either $0$ or $\pm\pi$ "" Could someone elaborate a bit on this for me?  I see that he's splitting up the cross-ratio using arguments, and I know that straight lines and circles are the same in $\mathbb{R}\cup\infty$ , but I am not seeing how the geometry proves both directions of the statement.  I would appreciate it very much!  Thank you.","The cross-ratio is real if and only if the four points lie on a circle or on a straight line. I know this question has been asked numerous times on MSE, but I have a specific question with respect to how Ahlfors proves this on page 79 of his book.  He says, ""This is evident by elementary geometry, for we obtain and if the points lie on a circle this difference of angles is either or "" Could someone elaborate a bit on this for me?  I see that he's splitting up the cross-ratio using arguments, and I know that straight lines and circles are the same in , but I am not seeing how the geometry proves both directions of the statement.  I would appreciate it very much!  Thank you.","(z_1,z_2,z_3,z_4) \text{arg}(z_1,z_2,z_3,z_4)=\text{arg}\frac{z_1-z_3}{z_1-z_4}-\text{arg}\frac{z_2-z_3}{z_2-z_4} 0 \pm\pi \mathbb{R}\cup\infty","['complex-analysis', 'geometry', 'cross-ratio']"
86,"For $\sum_{n \geq 0}a_n z^n=f(z)=e^z /\cos{\frac{\pi}{2}z}$, what is $a_{100}$ with error $0.0001$ at most?","For , what is  with error  at most?",\sum_{n \geq 0}a_n z^n=f(z)=e^z /\cos{\frac{\pi}{2}z} a_{100} 0.0001,"For $\displaystyle\sum\limits_{n \geq 0}a_n  z^n$ the Maclaurin series of $f(z)=\frac{e^z}{\cos{\frac{\pi}{2}z}}$ , what is an approximation of $a_{100}$ with error $0.0001$ at most? This is a past qualifying exam question, so no computer. I am looking for a solution that could be given in a timed exam setting, by a student with one semester of graduate Complex Analysis, familiar with first half of Stein's book, with Churchill's book, and somewhat with first half of Ahlfor's book. I write $c(z)\,=\,\cos{\frac{\pi}{2}z}\,=\,\displaystyle\sum\limits_{\;n\geq0\\\text{(even)}}c_n  z^n,$ and also $\theta=\frac{2}{\pi}<1.$ We have $c_n\,=\,\frac{(-1)^{n/2}}{n!\theta^n}.$ $$f(z)\,=\,\frac{1\,+\,z\,+\,\frac{z^2}{2!}\,+\,\frac{z^3}{3!}\,+\,\frac{z^4}{4!}\,+\,\cdots}{1\;\quad-\quad\frac{z^2}{2!\theta^2}\quad+\quad\frac{z^4}{4!\theta^4}\,-+\,\cdots}\qquad\qquad(z\in\mathbb{D}).$$ Using the usual method, I found $a_0,a_1,a_2,a_3,a_4$ by hand, so we have $\,f(z)\,=\,$ $$\displaystyle\sum\limits_{n \geq 0}a_n  z^n\,=\,1+z+\left(\frac{1}{2}+\frac{1}{2\theta^2}\right)z^2+\left(\frac{1}{6}+\frac{1}{2\theta^2}\right)z^3+\left(\frac{1}{24}+\frac{1}{4\theta^2}+\frac{5}{24\theta^4}\right)z^4+\cdots.$$ I tried to discern a pattern by keeping the expressions more abstract, i.e. keeping the $a_n$ and $c_n$ . Doing so we can write e.g., $$a_2\,=\,\frac{1}{2!}\,-\,c_2\,=\,\frac{1}{2!}\,-\,\displaystyle\sum\limits^{2}_{\,\ell\,=\,2\\\text{(even)}}c_\ell  a_{n-\ell},$$ $$a_7\,=\,\frac{1}{7!}\,-\,(c_2 a_5+c_4 a_3+c_6)\,=\,\frac{1}{7!}\,-\,\displaystyle\sum\limits^{7}_{\,\ell\,=\,2\\\text{(even)}}c_\ell  a_{n-\ell},$$ $$a_{100}\,=\,\frac{1}{100!}\,-\,(c_2 a_{98}+c_4 a_{96}+\cdots+c_{98}a_2+c_{100}).$$ I am not sure what to do next. I did consider Cauchy's Integral Inequalities, but could not see how to get a useful estimate from them. If $0<r<1,$ $$a_{100} = \frac{f^{(100)}(0)}{100!\,} = \frac{1}{2\pi i } \oint_{|z| = r} \frac{e^z}{c(z)\,z^{101}} dz,$$ $$|a_{100}| \leq \frac{1}{r^{100}}\max_{|z| = r}\left|\frac{e^z}{\cos(\frac{\pi}{2}z)} \right|,$$ but for either $r$ very near zero, or very near one, or say for $r=$ one-half, the estimate seems to not be useful.","For the Maclaurin series of , what is an approximation of with error at most? This is a past qualifying exam question, so no computer. I am looking for a solution that could be given in a timed exam setting, by a student with one semester of graduate Complex Analysis, familiar with first half of Stein's book, with Churchill's book, and somewhat with first half of Ahlfor's book. I write and also We have Using the usual method, I found by hand, so we have I tried to discern a pattern by keeping the expressions more abstract, i.e. keeping the and . Doing so we can write e.g., I am not sure what to do next. I did consider Cauchy's Integral Inequalities, but could not see how to get a useful estimate from them. If but for either very near zero, or very near one, or say for one-half, the estimate seems to not be useful.","\displaystyle\sum\limits_{n \geq 0}a_n  z^n f(z)=\frac{e^z}{\cos{\frac{\pi}{2}z}} a_{100} 0.0001 c(z)\,=\,\cos{\frac{\pi}{2}z}\,=\,\displaystyle\sum\limits_{\;n\geq0\\\text{(even)}}c_n  z^n, \theta=\frac{2}{\pi}<1. c_n\,=\,\frac{(-1)^{n/2}}{n!\theta^n}. f(z)\,=\,\frac{1\,+\,z\,+\,\frac{z^2}{2!}\,+\,\frac{z^3}{3!}\,+\,\frac{z^4}{4!}\,+\,\cdots}{1\;\quad-\quad\frac{z^2}{2!\theta^2}\quad+\quad\frac{z^4}{4!\theta^4}\,-+\,\cdots}\qquad\qquad(z\in\mathbb{D}). a_0,a_1,a_2,a_3,a_4 \,f(z)\,=\, \displaystyle\sum\limits_{n \geq 0}a_n  z^n\,=\,1+z+\left(\frac{1}{2}+\frac{1}{2\theta^2}\right)z^2+\left(\frac{1}{6}+\frac{1}{2\theta^2}\right)z^3+\left(\frac{1}{24}+\frac{1}{4\theta^2}+\frac{5}{24\theta^4}\right)z^4+\cdots. a_n c_n a_2\,=\,\frac{1}{2!}\,-\,c_2\,=\,\frac{1}{2!}\,-\,\displaystyle\sum\limits^{2}_{\,\ell\,=\,2\\\text{(even)}}c_\ell  a_{n-\ell}, a_7\,=\,\frac{1}{7!}\,-\,(c_2 a_5+c_4 a_3+c_6)\,=\,\frac{1}{7!}\,-\,\displaystyle\sum\limits^{7}_{\,\ell\,=\,2\\\text{(even)}}c_\ell  a_{n-\ell}, a_{100}\,=\,\frac{1}{100!}\,-\,(c_2 a_{98}+c_4 a_{96}+\cdots+c_{98}a_2+c_{100}). 0<r<1, a_{100} = \frac{f^{(100)}(0)}{100!\,} = \frac{1}{2\pi i } \oint_{|z| = r} \frac{e^z}{c(z)\,z^{101}} dz, |a_{100}| \leq \frac{1}{r^{100}}\max_{|z| = r}\left|\frac{e^z}{\cos(\frac{\pi}{2}z)} \right|, r r=","['complex-analysis', 'taylor-expansion', 'approximation']"
87,Infinity norm inequality,Infinity norm inequality,,"Let $a_1, a_2, \dots, a_n$ given with $a_i = \pm 1$ . Let $f(x) = \sum_{k=1}^n a_k e^{ikx}$ . I need to prove that $\lVert f \rVert_\infty \geq \sqrt{n}$ where $\lVert f \rVert_\infty$ is defined as the maximum value of $|f|$ in the interval $[0,2\pi]$ . Attempt: I tried experimenting with all $a_i$ being $1$ or $-1$ but I couldn't generalize it. Any hint would be appreciated. No need for the full solution.",Let given with . Let . I need to prove that where is defined as the maximum value of in the interval . Attempt: I tried experimenting with all being or but I couldn't generalize it. Any hint would be appreciated. No need for the full solution.,"a_1, a_2, \dots, a_n a_i = \pm 1 f(x) = \sum_{k=1}^n a_k e^{ikx} \lVert f \rVert_\infty \geq \sqrt{n} \lVert f \rVert_\infty |f| [0,2\pi] a_i 1 -1","['real-analysis', 'complex-analysis', 'fourier-analysis', 'fourier-series']"
88,Find a power series that is convergent on the closed unit disk but diverges elsewhere.,Find a power series that is convergent on the closed unit disk but diverges elsewhere.,,"Question: Does there exist a power series centered at $z=0$ , $f(z)=\sum_{n=0}^\infty a_n z^n$ such that the domain of $f$ is exactly the unit disk $D^2\subset \mathbb{C}$ ? In other words, I'm looking for a power series whose radius of convergence $\rho=1$ such that the series also converges on the unit circle. Motivation: I'm thinking about a problem: ""does there exist a Laurent series that converges only on the unit circle but nowhere else?"" I realize that this problem reduces to the above question.","Question: Does there exist a power series centered at , such that the domain of is exactly the unit disk ? In other words, I'm looking for a power series whose radius of convergence such that the series also converges on the unit circle. Motivation: I'm thinking about a problem: ""does there exist a Laurent series that converges only on the unit circle but nowhere else?"" I realize that this problem reduces to the above question.",z=0 f(z)=\sum_{n=0}^\infty a_n z^n f D^2\subset \mathbb{C} \rho=1,"['complex-analysis', 'power-series', 'laurent-series']"
89,"Is the function, $f(z)=iz\bar{z}$ analytic?","Is the function,  analytic?",f(z)=iz\bar{z},"Question: Is the function, $f(z)=iz\bar{z}$ analytic? My approach: We know that for any $z\in\mathbb{C}$ , $z\bar{z}=|z|^2.$ Thus $f(z)=i|z|^2, \forall z.$ Now let $z=x+iy\implies f(z)=f(x+iy)=i(x^2+y^2).$ Thus we have $u(x,y)=0$ and $v(x,y)=x^2+y^2$ , $\forall x,y\in\mathbb{R}$ . Now observe that both $u$ and $v$ are continuous functions in $x$ and $y$ , $\forall x,y\in\mathbb{R}.$ Now $$\frac{\partial{u}}{\partial{x}}=0, \frac{\partial{u}}{\partial{y}}=0,\frac{\partial{v}}{\partial{x}}=2x,\frac{\partial{v}}{\partial{y}}=2y, \forall x,y\in\mathbb{R}.$$ Thus the functions $\frac{\partial{u}}{\partial{x}},\frac{\partial{u}}{\partial{y}},\frac{\partial{v}}{\partial{x}},\frac{\partial{v}}{\partial{y}}$ are continuous $\forall x,y\in\mathbb{R}.$ Now we move forward to analyze if the Cauchy-Riemann conditions are satisfied or not. Observe that since $$\frac{\partial{u}}{\partial{x}}=0 \text{ and } \frac{\partial{v}}{\partial{y}}=2y, \text{ therefore } \frac{\partial{u}}{\partial{x}}=\frac{\partial{v}}{\partial{y}}\iff 2y=0\iff y=0.$$ Again since, $$\frac{\partial{u}}{\partial{y}}=0 \text{ and } -\frac{\partial{v}}{\partial{x}}=-2x, \text{ therefore } \frac{\partial{u}}{\partial{y}}=-\frac{\partial{v}}{\partial{x}}\iff -2x=0\iff x=0.$$ Thus the Cauchy-Riemann conditions are satisfied only at the point $(x,y)=(0,0)$ , i.e., at the point $z=0$ . Thus we can conclude that $f$ is analytic only at the point $z=0$ . I have read in the book ""Advanced Engineering Mathematics"" by Erwin Kreyszig that: A function $f(z)$ is said to be analytic at a point $z=z_0$ in a domain $D$ if $f(z)$ is analytic in a neighborhood of $z_0$ . But, here we see that $f(z)$ is analytic only at the point $z=0$ , and not in any $\delta$ neighborhood of $z=0$ . So, can we still conclude that $f(z)$ is analytic at the point $z=0$ ? And, obviously $f(z)$ is not a analytic function, since it is not differentiable at every point in some domain.","Question: Is the function, analytic? My approach: We know that for any , Thus Now let Thus we have and , . Now observe that both and are continuous functions in and , Now Thus the functions are continuous Now we move forward to analyze if the Cauchy-Riemann conditions are satisfied or not. Observe that since Again since, Thus the Cauchy-Riemann conditions are satisfied only at the point , i.e., at the point . Thus we can conclude that is analytic only at the point . I have read in the book ""Advanced Engineering Mathematics"" by Erwin Kreyszig that: A function is said to be analytic at a point in a domain if is analytic in a neighborhood of . But, here we see that is analytic only at the point , and not in any neighborhood of . So, can we still conclude that is analytic at the point ? And, obviously is not a analytic function, since it is not differentiable at every point in some domain.","f(z)=iz\bar{z} z\in\mathbb{C} z\bar{z}=|z|^2. f(z)=i|z|^2, \forall z. z=x+iy\implies f(z)=f(x+iy)=i(x^2+y^2). u(x,y)=0 v(x,y)=x^2+y^2 \forall x,y\in\mathbb{R} u v x y \forall x,y\in\mathbb{R}. \frac{\partial{u}}{\partial{x}}=0, \frac{\partial{u}}{\partial{y}}=0,\frac{\partial{v}}{\partial{x}}=2x,\frac{\partial{v}}{\partial{y}}=2y, \forall x,y\in\mathbb{R}. \frac{\partial{u}}{\partial{x}},\frac{\partial{u}}{\partial{y}},\frac{\partial{v}}{\partial{x}},\frac{\partial{v}}{\partial{y}} \forall x,y\in\mathbb{R}. \frac{\partial{u}}{\partial{x}}=0 \text{ and } \frac{\partial{v}}{\partial{y}}=2y, \text{ therefore } \frac{\partial{u}}{\partial{x}}=\frac{\partial{v}}{\partial{y}}\iff 2y=0\iff y=0. \frac{\partial{u}}{\partial{y}}=0 \text{ and } -\frac{\partial{v}}{\partial{x}}=-2x, \text{ therefore } \frac{\partial{u}}{\partial{y}}=-\frac{\partial{v}}{\partial{x}}\iff -2x=0\iff x=0. (x,y)=(0,0) z=0 f z=0 f(z) z=z_0 D f(z) z_0 f(z) z=0 \delta z=0 f(z) z=0 f(z)",['complex-analysis']
90,Zeros of the Jacobi Theta function,Zeros of the Jacobi Theta function,,"How do you obtain all the zeros in $z$ of the Jacobi Theta function $$\vartheta(z) = \sum_{n} e^{\pi i n^2 \tau + 2\pi i n z} \, ?$$ Probably the easiest way is to just read them of the Jacobi-Triple product, but I'm pretty sure they can also be derived from the series representation. The zeros are $$z=a\tau + b + \frac{\tau + 1}{2} \, ,$$ where $a,b \in {\mathbb Z}$ , of which I lack to find the term $a\tau$ . Since $\vartheta(z+1)=\vartheta(z)$ , it is periodic with perdiod $1$ in $z$ . So any zero $z_0$ will lead to a zero $b+z_0$ for any integer $b$ . It can be seen that $z_0=\frac{\tau+1}{2}$ is a zero since $$\vartheta(z_0) = \sum_{n} e^{\pi i n^2 \tau + \pi i n (\tau+1) } \stackrel{n\rightarrow -n-1}{=} \sum_{n} e^{\pi i n^2 \tau + 2\pi i n \tau + \pi i\tau - \pi i (n+1)(\tau+1)} \\ = -\sum_{n} e^{\pi i n^2 \tau + \pi i n \tau - \pi i n} = -\sum_{n} e^{\pi i n^2 \tau + \pi i n (\tau + 1)} = - \vartheta(z_0) \, .$$ $\vartheta(z)$ has a period of $2$ in $\tau$ , but that doesn't help to obtain the term $a\tau$ . Any idea?","How do you obtain all the zeros in of the Jacobi Theta function Probably the easiest way is to just read them of the Jacobi-Triple product, but I'm pretty sure they can also be derived from the series representation. The zeros are where , of which I lack to find the term . Since , it is periodic with perdiod in . So any zero will lead to a zero for any integer . It can be seen that is a zero since has a period of in , but that doesn't help to obtain the term . Any idea?","z \vartheta(z) = \sum_{n} e^{\pi i n^2 \tau + 2\pi i n z} \, ? z=a\tau + b + \frac{\tau + 1}{2} \, , a,b \in {\mathbb Z} a\tau \vartheta(z+1)=\vartheta(z) 1 z z_0 b+z_0 b z_0=\frac{\tau+1}{2} \vartheta(z_0) = \sum_{n} e^{\pi i n^2 \tau + \pi i n (\tau+1) } \stackrel{n\rightarrow -n-1}{=} \sum_{n} e^{\pi i n^2 \tau + 2\pi i n \tau + \pi i\tau - \pi i (n+1)(\tau+1)} \\
= -\sum_{n} e^{\pi i n^2 \tau + \pi i n \tau - \pi i n} = -\sum_{n} e^{\pi i n^2 \tau + \pi i n (\tau + 1)} = - \vartheta(z_0) \, . \vartheta(z) 2 \tau a\tau","['complex-analysis', 'analytic-number-theory', 'theta-functions']"
91,All Roots to be on unit circle,All Roots to be on unit circle,,"Suppose $p(z)=1+a(z+z^2+\cdots+z^{n-1})+z^n, a\in{\bf R}, n\geq 2.$ Then  the necessary and sufficient conditions for $p(z)$ to have all its roots on the unit circle are $-2/(n-1)\le a\le2n/(n-1)$ for odd $n$ and $-2/(n-1)\le a\le2$ for even $n$ .",Suppose Then  the necessary and sufficient conditions for to have all its roots on the unit circle are for odd and for even .,"p(z)=1+a(z+z^2+\cdots+z^{n-1})+z^n, a\in{\bf R}, n\geq 2. p(z) -2/(n-1)\le a\le2n/(n-1) n -2/(n-1)\le a\le2 n",['complex-analysis']
92,Finding infinitesimal Mobius transformations,Finding infinitesimal Mobius transformations,,"I'm working to understand a bit more about Mobius transformations. I understand that the Mobius group is isomorphic to $SL(2,\mathbb{C})$ , which has as its Lie algebra $\mathfrak{sl}(2,\mathbb{C})$ . However, Mobius transformations are complex functions, whereas the elements of $\mathfrak{sl}(2,\mathbb{C})$ are matrices with trace 0. Can I bring back the connection to functions on the extended complex plane? In particular, I wanted to know whether elements of the algebra could correspond to infinitesimal conformal transformations. In physics, we often think of infinitesimal rotations and translations on a space. I wanted to think of infinitesimal Mobius transformations in the same way.","I'm working to understand a bit more about Mobius transformations. I understand that the Mobius group is isomorphic to , which has as its Lie algebra . However, Mobius transformations are complex functions, whereas the elements of are matrices with trace 0. Can I bring back the connection to functions on the extended complex plane? In particular, I wanted to know whether elements of the algebra could correspond to infinitesimal conformal transformations. In physics, we often think of infinitesimal rotations and translations on a space. I wanted to think of infinitesimal Mobius transformations in the same way.","SL(2,\mathbb{C}) \mathfrak{sl}(2,\mathbb{C}) \mathfrak{sl}(2,\mathbb{C})","['complex-analysis', 'lie-algebras', 'mobius-transformation']"
93,Branch points of $f(z)= \frac{\sqrt{z} \log(z)}{(1+z)^2}$,Branch points of,f(z)= \frac{\sqrt{z} \log(z)}{(1+z)^2},How does one go about finding the branch points/holomorphic branches of a multi-function composed of several other multi-functions? Here is an example of what I mean: Let $f(z)= [\frac{\sqrt{z} \log(z)}{(1+z)^2}]$ be a multifunction. Identify the branch points and find a holomorphic branch. I have no idea how to approach this if $\sqrt{z}$ and $\log(z)$ are considered multi-functions themselves. Can someone help me out here? Thanks!,How does one go about finding the branch points/holomorphic branches of a multi-function composed of several other multi-functions? Here is an example of what I mean: Let be a multifunction. Identify the branch points and find a holomorphic branch. I have no idea how to approach this if and are considered multi-functions themselves. Can someone help me out here? Thanks!,f(z)= [\frac{\sqrt{z} \log(z)}{(1+z)^2}] \sqrt{z} \log(z),"['complex-analysis', 'complex-numbers']"
94,Partial derivative of the real part of a function,Partial derivative of the real part of a function,,"I'm trying to understand the mathematical reasoning behind the example provided in this question. If we have $$z = Ae^{i(\omega _{o}t+\phi )}$$ and define $$x = Re (z),$$ then why is it that $$\frac{\partial x}{\partial t} = Re  \frac{\partial z}{\partial t},$$ instead of $$\frac{\partial x}{\partial t} =  \frac{\partial [Re(z)]}{\partial t}$$ In other words, why is it that the partial derivative of the real part of a function is equal to the real part of the partial derivative of the function, rather than being equal to the partial derivative of the real part of the function? I'm just trying to understand the mathematical reasoning behind this, rather than why it is nonsensical from a physical standpoint.","I'm trying to understand the mathematical reasoning behind the example provided in this question. If we have and define then why is it that instead of In other words, why is it that the partial derivative of the real part of a function is equal to the real part of the partial derivative of the function, rather than being equal to the partial derivative of the real part of the function? I'm just trying to understand the mathematical reasoning behind this, rather than why it is nonsensical from a physical standpoint.","z = Ae^{i(\omega _{o}t+\phi )} x = Re (z), \frac{\partial x}{\partial t} = Re  \frac{\partial z}{\partial t}, \frac{\partial x}{\partial t} =  \frac{\partial [Re(z)]}{\partial t}","['real-analysis', 'complex-analysis', 'complex-numbers', 'partial-derivative']"
95,"The use of limit in Titchmarsh's book ""The theory of the Riemann zeta-function"" in Theorem $3.13$","The use of limit in Titchmarsh's book ""The theory of the Riemann zeta-function"" in Theorem",3.13,"In Titchmarsh's book ""The theory of the Riemann Zeta-function"" his Lemma $3.12$ is one of the main tools. Lemma $3.12$ is a version of Perron formula. Lemma $3.12$ starts by observing that, with $c>0$ and with $n<x$ , $$ \frac{1}{2\pi i}\int\limits_{c-iT}^{c+iT}\left(\frac{x}{n}\right)^w \frac{\mathrm dw}{w}=1+ O\left( \frac{(x/n)^c}{T\log (x/n)} \right) $$ This stems from the fact that $c>0$ , and so if one completes the integration contour to the left by encircling the point $w=0$ completely in the complex $w$ plane by a rectangle whose right-most side is the original integration line $(c-iT,c+iT)$ , the residue is simply $1$ . This is the reason for the requirement $c>0$ . The requirement $n<x$ comes from letting the left-most side of the integration rectangle be at $\Re(w)=-\infty$ and so $(x/n)^w\to 0$ if and only if $n<x$ as $\Re(w)\to -\infty$ . And so, in Theorem $3.13$ the starting point is the application of Lemma $3.12$ , $$ \sum\limits_{n<x} \frac{\mu(n)}{n^s}=\frac{1}{2\pi i}\int\limits_{c-iT}^{c+iT} \frac{x^w \mathrm dw}{w\zeta(s+w)}+ O\left( \frac{x^c}{cT} \right)+ O\left( \frac{\log x}{T} \right) $$ On the LHS the condition $n<x$ is the condition from Lemma $3.12$ , and $c$ is still required to obey $c>0$ . Now Titchmarsh enlarges the contour of integration and encloses the $w=0$ completely, as earlier. Do notice that $c>0$ should still hold, since $c$ is nothing else but $\Re(w)$ on the right-most side the integration contour. No matter how the original line $(c-iT,c+iT)$ is deformed, the deformed closed integration contour must enclose the point $w=0$ , and hence $c>0$ on the RHS part of the contour that intersects the real axis in $w$ plane. With $c>0$ the pole at $w=0$ produces the residue $1/\zeta(s)$ and the result is now $$\sum\limits_{n<x} \frac{\mu(n)}{n^s}=\frac{1}{\zeta(s)}+O$$ The $O$ term tends to $0$ in the end, after Titchmarsh adjusts $T$ and $x$ appropriately. And so then Titchmarsh requires $$c=\frac{1}{\log x}$$ Additionally, he then lets $x\to\infty$ . But in this limit, $c\to 0$ . And this makes the original starting equation useless, since the pole of the integrand at $w=0$ is no longer enclosed in the integration countour, but lies on the integration contour instead, if one interprets the limit as $\lim\limits_{x\to\infty}x=\infty$ . On the other hand, if one interprets the limit $\lim\limits_{x\to\infty}x$ in the way that $x$ grows large but never hits the point at infinity, then $c$ never reaches $0$ , and this would do. But aren't there problems with this interpretation of a limit in standard mathematics? Maybe Titchmarsh uses the Sokhotski–Plemelj theorem , but then the result misses the summand $\frac{1}{2\zeta(s)}$ ... Or maybe I'm missing some detail completely here... So my question is: What exactly enables Titchmarsh to take the limit $x\to\infty$ ?","In Titchmarsh's book ""The theory of the Riemann Zeta-function"" his Lemma is one of the main tools. Lemma is a version of Perron formula. Lemma starts by observing that, with and with , This stems from the fact that , and so if one completes the integration contour to the left by encircling the point completely in the complex plane by a rectangle whose right-most side is the original integration line , the residue is simply . This is the reason for the requirement . The requirement comes from letting the left-most side of the integration rectangle be at and so if and only if as . And so, in Theorem the starting point is the application of Lemma , On the LHS the condition is the condition from Lemma , and is still required to obey . Now Titchmarsh enlarges the contour of integration and encloses the completely, as earlier. Do notice that should still hold, since is nothing else but on the right-most side the integration contour. No matter how the original line is deformed, the deformed closed integration contour must enclose the point , and hence on the RHS part of the contour that intersects the real axis in plane. With the pole at produces the residue and the result is now The term tends to in the end, after Titchmarsh adjusts and appropriately. And so then Titchmarsh requires Additionally, he then lets . But in this limit, . And this makes the original starting equation useless, since the pole of the integrand at is no longer enclosed in the integration countour, but lies on the integration contour instead, if one interprets the limit as . On the other hand, if one interprets the limit in the way that grows large but never hits the point at infinity, then never reaches , and this would do. But aren't there problems with this interpretation of a limit in standard mathematics? Maybe Titchmarsh uses the Sokhotski–Plemelj theorem , but then the result misses the summand ... Or maybe I'm missing some detail completely here... So my question is: What exactly enables Titchmarsh to take the limit ?","3.12 3.12 3.12 c>0 n<x 
\frac{1}{2\pi i}\int\limits_{c-iT}^{c+iT}\left(\frac{x}{n}\right)^w \frac{\mathrm dw}{w}=1+
O\left( \frac{(x/n)^c}{T\log (x/n)} \right)
 c>0 w=0 w (c-iT,c+iT) 1 c>0 n<x \Re(w)=-\infty (x/n)^w\to 0 n<x \Re(w)\to -\infty 3.13 3.12 
\sum\limits_{n<x} \frac{\mu(n)}{n^s}=\frac{1}{2\pi i}\int\limits_{c-iT}^{c+iT}
\frac{x^w \mathrm dw}{w\zeta(s+w)}+
O\left( \frac{x^c}{cT} \right)+
O\left( \frac{\log x}{T} \right)
 n<x 3.12 c c>0 w=0 c>0 c \Re(w) (c-iT,c+iT) w=0 c>0 w c>0 w=0 1/\zeta(s) \sum\limits_{n<x} \frac{\mu(n)}{n^s}=\frac{1}{\zeta(s)}+O O 0 T x c=\frac{1}{\log x} x\to\infty c\to 0 w=0 \lim\limits_{x\to\infty}x=\infty \lim\limits_{x\to\infty}x x c 0 \frac{1}{2\zeta(s)} x\to\infty","['complex-analysis', 'riemann-zeta']"
96,Behavior of $\sum_{n=1}^\infty \frac{1}{n} z^{n!}$ on the unit circle [duplicate],Behavior of  on the unit circle [duplicate],\sum_{n=1}^\infty \frac{1}{n} z^{n!},"This question already has answers here : Series with radius of convergence 1 that diverges on roots of unity, converges elsewhere on the circle. (2 answers) Closed 5 years ago . I'm trying to understand the behavior of $\sum_{n=1}^\infty \frac{1}{n} z^{n!}$ on the unit circle. Since for each $m$ th root of unity $\zeta_m$ $$\sum_{n=1}^\infty \frac{1}{n} \zeta_m^{n!} = C + \sum_{n=m}^\infty \frac{1}{n} = \infty$$ holds for some $C \in \mathbb{C}$ , the series diverges for all $e^{\varphi \pi i}$ with $\varphi \in \mathbb{Q}$ . But what happens for $\varphi \in \mathbb{R} \setminus \mathbb{Q}$ ? Does the series diverge everywhere, or are there points where it is convergent?","This question already has answers here : Series with radius of convergence 1 that diverges on roots of unity, converges elsewhere on the circle. (2 answers) Closed 5 years ago . I'm trying to understand the behavior of on the unit circle. Since for each th root of unity holds for some , the series diverges for all with . But what happens for ? Does the series diverge everywhere, or are there points where it is convergent?",\sum_{n=1}^\infty \frac{1}{n} z^{n!} m \zeta_m \sum_{n=1}^\infty \frac{1}{n} \zeta_m^{n!} = C + \sum_{n=m}^\infty \frac{1}{n} = \infty C \in \mathbb{C} e^{\varphi \pi i} \varphi \in \mathbb{Q} \varphi \in \mathbb{R} \setminus \mathbb{Q},"['calculus', 'complex-analysis']"
97,Complex Analysis - Application of Liouville theorem [closed],Complex Analysis - Application of Liouville theorem [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question If $f:\mathbb{C}\to\mathbb{C}$ is an entire function and it holds that: ""For every $z\in \mathbb{C}$, either $|f'(z)|\leq1$ or $|f''(z)|\leq 1$."" Then there exist $a,b,c \in \mathbb{C}$ such that $2|a|\leq 1$ and $f(z)=az^2+bz+c$ .","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question If $f:\mathbb{C}\to\mathbb{C}$ is an entire function and it holds that: ""For every $z\in \mathbb{C}$, either $|f'(z)|\leq1$ or $|f''(z)|\leq 1$."" Then there exist $a,b,c \in \mathbb{C}$ such that $2|a|\leq 1$ and $f(z)=az^2+bz+c$ .",,['complex-analysis']
98,Confusion between function and multivalued function.,Confusion between function and multivalued function.,,"""What is a function?"" can be  answered as ""Single-valued relations are called functions"" . But how can ""What are the multi-valued function?"" be answered? Will someone clarify my doubt why multi-valued functions are not violating the classical definition of function? EDIT This is what Wikipedia says on multivalued functions: In mathematics, a multivalued function from a domain X to a codomain Y is a heterogeneous relation. However, in some contexts such as the complex plane (X = Y = ℂ), authors prefer to mimic function theory as they extend concepts of the ordinary (single-valued) functions. In this context, an ordinary function is often called a single-valued function to avoid confusion. The term multivalued function originated in complex analysis, from analytic continuation. It often occurs that one knows the value of a complex analytic function $f(z)$ in some neighbourhood of a point $ z=a$ . This is the case for functions defined by the implicit function theorem or by a Taylor series around $ z=a$ . In such a situation, one may extend the domain of the single-valued function $f(z)$ along curves in the complex plane starting at $a$ . In doing so, one finds that the value of the extended function at a point $z=b$ depends on the chosen curve from $ a$ to $ b$ ; since none of the new values is more natural than the others, all of them are incorporated into a multivalued function. For example, let $f(z)=\sqrt {z}$ , be the usual square root function on positive real numbers. One may extend its domain to a neighbourhood of $z=1$ in the complex plane, and then further along curves starting at $z=1$ , so that the values along a given curve vary continuously from $\sqrt {1}=1$ . Extending to negative real numbers, one gets two opposite values of the square root such as $\sqrt {-1}=\pm i$ , depending on whether the domain has been extended through the upper or the lower half of the complex plane. This phenomenon is very frequent, occurring for $n$ th roots, logarithms and inverse trigonometric functions. To define a single-valued function from a complex multivalued function, one may distinguish one of the multiple values as the principal value, producing a single-valued function on the whole plane which is discontinuous along certain boundary curves. Alternatively, dealing with the multivalued function allows having something that is everywhere continuous, at the cost of possible value changes when one follows a closed path (monodromy). These problems are resolved in the theory of Riemann surfaces: to consider a multivalued function ${\displaystyle f(z)}$ as an ordinary function without discarding any values, one multiplies the domain into a many-layered covering space, a manifold which is the Riemann surface associated to $f(z)$ .","""What is a function?"" can be  answered as ""Single-valued relations are called functions"" . But how can ""What are the multi-valued function?"" be answered? Will someone clarify my doubt why multi-valued functions are not violating the classical definition of function? EDIT This is what Wikipedia says on multivalued functions: In mathematics, a multivalued function from a domain X to a codomain Y is a heterogeneous relation. However, in some contexts such as the complex plane (X = Y = ℂ), authors prefer to mimic function theory as they extend concepts of the ordinary (single-valued) functions. In this context, an ordinary function is often called a single-valued function to avoid confusion. The term multivalued function originated in complex analysis, from analytic continuation. It often occurs that one knows the value of a complex analytic function in some neighbourhood of a point . This is the case for functions defined by the implicit function theorem or by a Taylor series around . In such a situation, one may extend the domain of the single-valued function along curves in the complex plane starting at . In doing so, one finds that the value of the extended function at a point depends on the chosen curve from to ; since none of the new values is more natural than the others, all of them are incorporated into a multivalued function. For example, let , be the usual square root function on positive real numbers. One may extend its domain to a neighbourhood of in the complex plane, and then further along curves starting at , so that the values along a given curve vary continuously from . Extending to negative real numbers, one gets two opposite values of the square root such as , depending on whether the domain has been extended through the upper or the lower half of the complex plane. This phenomenon is very frequent, occurring for th roots, logarithms and inverse trigonometric functions. To define a single-valued function from a complex multivalued function, one may distinguish one of the multiple values as the principal value, producing a single-valued function on the whole plane which is discontinuous along certain boundary curves. Alternatively, dealing with the multivalued function allows having something that is everywhere continuous, at the cost of possible value changes when one follows a closed path (monodromy). These problems are resolved in the theory of Riemann surfaces: to consider a multivalued function as an ordinary function without discarding any values, one multiplies the domain into a many-layered covering space, a manifold which is the Riemann surface associated to .",f(z)  z=a  z=a f(z) a z=b  a  b f(z)=\sqrt {z} z=1 z=1 \sqrt {1}=1 \sqrt {-1}=\pm i n {\displaystyle f(z)} f(z),"['calculus', 'complex-analysis', 'functions', 'definition', 'multivalued-functions']"
99,Use of a Laplace Transform to solve Abel's Integral Equation,Use of a Laplace Transform to solve Abel's Integral Equation,,"I am following an exercise where I have to solve Abel's integral equation: $$f(t)=\int_{0}^{t} \frac {\phi(\tau)}{(t-\tau)^{\alpha}} d\tau$$ I have taken the first step and shown that: $$\bar{\phi }(s) = \frac{1}{\Gamma(1-\alpha)}s^{1-\alpha}\bar{f}(s)$$ However, I now have to assume a function $\psi$ such that $\phi=d\psi/dt$ and $\psi(0)=0$.  Using my above result I have find the Laplace transform of $\psi(t)$ and then show that $\phi(t)=\frac{\sin \pi \alpha}{\pi}\frac{d}{dt}\int^t_0\frac{f(\tau)}{(t-\tau)^{1-\alpha}}d\tau$ Could anyone provide some pointers on how I would do this?  I am guessing that the sine term will appear due to the identity $1/\Gamma(z)\Gamma(1-z)=\frac{\sin \pi z}{\pi}$ but not sure how exactly to carry it all out.","I am following an exercise where I have to solve Abel's integral equation: $$f(t)=\int_{0}^{t} \frac {\phi(\tau)}{(t-\tau)^{\alpha}} d\tau$$ I have taken the first step and shown that: $$\bar{\phi }(s) = \frac{1}{\Gamma(1-\alpha)}s^{1-\alpha}\bar{f}(s)$$ However, I now have to assume a function $\psi$ such that $\phi=d\psi/dt$ and $\psi(0)=0$.  Using my above result I have find the Laplace transform of $\psi(t)$ and then show that $\phi(t)=\frac{\sin \pi \alpha}{\pi}\frac{d}{dt}\int^t_0\frac{f(\tau)}{(t-\tau)^{1-\alpha}}d\tau$ Could anyone provide some pointers on how I would do this?  I am guessing that the sine term will appear due to the identity $1/\Gamma(z)\Gamma(1-z)=\frac{\sin \pi z}{\pi}$ but not sure how exactly to carry it all out.",,"['complex-analysis', 'laplace-transform', 'integral-equations']"
