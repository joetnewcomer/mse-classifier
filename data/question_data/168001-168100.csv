,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Fitting normal distribution to the data,Fitting normal distribution to the data,,I have been given a set of data points. How can I find the best fit of the form $$\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{\sigma^2}}?$$ Even better if Sage can do it. And how can I approximate how good the fit is?,I have been given a set of data points. How can I find the best fit of the form $$\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{\sigma^2}}?$$ Even better if Sage can do it. And how can I approximate how good the fit is?,,"['statistics', 'normal-distribution', 'sagemath']"
1,1 sample space with 2 probability example?,1 sample space with 2 probability example?,,"I am a freshman here with the following question, sorry for my gramar I don't know the exact matematical probability terms in english. So, if I have a sample space, can I define in this space 2 probability? I know that, the probability function fit 3 condition. $P(a) \ge 0$ $P(\Omega) = 1$ $P\left(\bigcup_{j\in J}A_j\right) =\sum_{j\in J}P(A_j)$ The following probabilities function fit the conditions: probability as geometrie, probability as counting, probability as algebra.  Example: probability as counting P(event) = of successful outcomes / of total outcomes So can I define a 2 function on the same sample space? If not why, how to prove it? If anyone can give me examples, I would be very grateful. I want to understand this with 100% percent. Thank you very much.","I am a freshman here with the following question, sorry for my gramar I don't know the exact matematical probability terms in english. So, if I have a sample space, can I define in this space 2 probability? I know that, the probability function fit 3 condition. $P(a) \ge 0$ $P(\Omega) = 1$ $P\left(\bigcup_{j\in J}A_j\right) =\sum_{j\in J}P(A_j)$ The following probabilities function fit the conditions: probability as geometrie, probability as counting, probability as algebra.  Example: probability as counting P(event) = of successful outcomes / of total outcomes So can I define a 2 function on the same sample space? If not why, how to prove it? If anyone can give me examples, I would be very grateful. I want to understand this with 100% percent. Thank you very much.",,"['probability', 'statistics', 'functions']"
2,Mathematics of change money,Mathematics of change money,,Do you know any results or articles about change money? Something like the statistics of different value notes in a cash box. Or answers to questions which distribution of notes values is best for starting a day in a shop. I mean obviously you need more small value notes than large ones. After one day of selling you probably have more large notes as they don't go away easily.,Do you know any results or articles about change money? Something like the statistics of different value notes in a cash box. Or answers to questions which distribution of notes values is best for starting a day in a shop. I mean obviously you need more small value notes than large ones. After one day of selling you probably have more large notes as they don't go away easily.,,['statistics']
3,Exponentiating cubic functions (and so on),Exponentiating cubic functions (and so on),,"The exponential distribution follows from exponentiating a linear function, while the normal distribution follows from exponentiating a quadratic function. Do the distributions that follow from exponentiating functions of 3rd or higher degree have names or uses?","The exponential distribution follows from exponentiating a linear function, while the normal distribution follows from exponentiating a quadratic function. Do the distributions that follow from exponentiating functions of 3rd or higher degree have names or uses?",,"['statistics', 'probability-distributions']"
4,Average Maximum Of Random Subset?,Average Maximum Of Random Subset?,,"Suppose I have a set of $n$ real numbers, $\{x_1, x_2, \dots, x_n\}$. I choose a uniformly random subset of size $m \le n$. What is the expected maximum of the subset in terms of $n$, $m$ and $x_i$?","Suppose I have a set of $n$ real numbers, $\{x_1, x_2, \dots, x_n\}$. I choose a uniformly random subset of size $m \le n$. What is the expected maximum of the subset in terms of $n$, $m$ and $x_i$?",,"['combinatorics', 'statistics']"
5,Examples of Student's T-distribution in real world empirical data?,Examples of Student's T-distribution in real world empirical data?,,"I have recently stumbled onto some empirical (forecasting error) data that should be normally distributed. However, the normal distribution fits relatively poorly due to the abundance of data points in the tails. On the other hand, the t-distribution (df=2) fits virtually perfectly. I need to know how to explain it if I wish to use it for modelling purposes. Is there a logic to this, or am I ""over-fitting"" the data? I would really like to know why this is happening and where this can occur in other real-world samples. Note: I'm sorry I cannot share the exact nature of the data, but I can say it has over 15,000 data points.","I have recently stumbled onto some empirical (forecasting error) data that should be normally distributed. However, the normal distribution fits relatively poorly due to the abundance of data points in the tails. On the other hand, the t-distribution (df=2) fits virtually perfectly. I need to know how to explain it if I wish to use it for modelling purposes. Is there a logic to this, or am I ""over-fitting"" the data? I would really like to know why this is happening and where this can occur in other real-world samples. Note: I'm sorry I cannot share the exact nature of the data, but I can say it has over 15,000 data points.",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
6,Ranking System and Separated Populations,Ranking System and Separated Populations,,"I'm trying to modify the ELO ranking system formulas to adapt them to eSport (electronic sports, but more specifically Starcraft II). (The reason I'm using ELO, is the straight forward concept and the pretty easy maths it is using. I might change though if I find a solution that can't be implemented in ELO.) One of the big problems I have is the following : How do you rank two separate populations that encounter each other very rarely (basically players from different geographical regions), in the same raking ? Little explanation. Imagine that you have one player from England and one player from South-Korea, both have say ""2700"" rating. Now the problem is that you can't say that they have the same ""skill"" since they play in two different environments populated with different players that have a different level of skill. (In this particular use of the system (Starcraft II), about 10% of the games correspond to ""cross-population"" games. And in those 10%, I would say that the players are generally the same and correspond to roughly 20% of the total number of players in the population they are part of.) I looked at quite a lot of other ranking systems like Chessmetrics and Glicko I-II, but none of them seem to solve the problem. Most likely because they were designed for a more ""global"" game (Chess) and thus don't have this issue with ""separated populations"". The only potential solution I could think of was to inflate the ""K"" factor in the ELO formula for those particular ""cross-population"" games. This would increase the ""weight"" of this particular case. But honestly, I don't really like this solution ... Thank you a lot in advance ! --Awake","I'm trying to modify the ELO ranking system formulas to adapt them to eSport (electronic sports, but more specifically Starcraft II). (The reason I'm using ELO, is the straight forward concept and the pretty easy maths it is using. I might change though if I find a solution that can't be implemented in ELO.) One of the big problems I have is the following : How do you rank two separate populations that encounter each other very rarely (basically players from different geographical regions), in the same raking ? Little explanation. Imagine that you have one player from England and one player from South-Korea, both have say ""2700"" rating. Now the problem is that you can't say that they have the same ""skill"" since they play in two different environments populated with different players that have a different level of skill. (In this particular use of the system (Starcraft II), about 10% of the games correspond to ""cross-population"" games. And in those 10%, I would say that the players are generally the same and correspond to roughly 20% of the total number of players in the population they are part of.) I looked at quite a lot of other ranking systems like Chessmetrics and Glicko I-II, but none of them seem to solve the problem. Most likely because they were designed for a more ""global"" game (Chess) and thus don't have this issue with ""separated populations"". The only potential solution I could think of was to inflate the ""K"" factor in the ELO formula for those particular ""cross-population"" games. This would increase the ""weight"" of this particular case. But honestly, I don't really like this solution ... Thank you a lot in advance ! --Awake",,"['statistics', 'algorithms']"
7,How can you have a density function that depends on a parameter?,How can you have a density function that depends on a parameter?,,"Let $X_1,...,X_n$ be a random sample from a distribution with mass/density function $f_X$ that depends on a (possible vector) parameter $\theta$. Then $f_{X_1}(x_1) = f_X(x_1;\theta)$ so that $f_{X_1,...,X_k}(x_1,...,x_k) = \prod_{i=1}^kf_X(x_i;\theta).$ Could someone please explain what the significance of $\theta$ is in the above definition. I've never seen this before. Is it the mass/density function that depends on the parameter or is it the random sample that depends on the parameter.","Let $X_1,...,X_n$ be a random sample from a distribution with mass/density function $f_X$ that depends on a (possible vector) parameter $\theta$. Then $f_{X_1}(x_1) = f_X(x_1;\theta)$ so that $f_{X_1,...,X_k}(x_1,...,x_k) = \prod_{i=1}^kf_X(x_i;\theta).$ Could someone please explain what the significance of $\theta$ is in the above definition. I've never seen this before. Is it the mass/density function that depends on the parameter or is it the random sample that depends on the parameter.",,"['statistics', 'probability-distributions']"
8,Probability involving unique group combinations,Probability involving unique group combinations,,"If I have $30$ objects and $5$ buckets that each hold $6$ objects, how many times could I put the objects into the buckets without an object being in the bucket with an object it has previously been grouped with?  So, for each round you would empty all of the objects from the buckets and place them into buckets again (they could be in the same bucket multiple times, just not see another object multiple times). Edit :  A better example would be $120$ objects in $20$ buckets that hold $6$ objects.  No object can ever be in a bucket with another object that it has seen previously.","If I have $30$ objects and $5$ buckets that each hold $6$ objects, how many times could I put the objects into the buckets without an object being in the bucket with an object it has previously been grouped with?  So, for each round you would empty all of the objects from the buckets and place them into buckets again (they could be in the same bucket multiple times, just not see another object multiple times). Edit :  A better example would be $120$ objects in $20$ buckets that hold $6$ objects.  No object can ever be in a bucket with another object that it has seen previously.",,"['probability', 'combinatorics', 'statistics']"
9,involving exponential distributions,involving exponential distributions,,"The question states: Let X = time between calls to a service center, It is known that X follows an exponential distribution with a mean of 15 minutes, part 1. What is the probability that x is greater than 20 minutes. So far this is the only one I think I've been able to work out. Since we know that the average is 15 i.e. $ \mu$ = 15, then $\lambda$ = $\frac{1}{15}$, which means that the probability of X > 20 is: P(X>20) = $e^{-\lambda x}$ = $e^{-1}$ or .3678 (36.78%) the other questions are as follows: part 2: if there are no service calls during the last 10 minutes what is the probability that there will be no service call during the next 30 minutes? part 3: find the 90th percentile of X part 4: what is the median time between calls to the service center. can anyone help me solve these problems?","The question states: Let X = time between calls to a service center, It is known that X follows an exponential distribution with a mean of 15 minutes, part 1. What is the probability that x is greater than 20 minutes. So far this is the only one I think I've been able to work out. Since we know that the average is 15 i.e. $ \mu$ = 15, then $\lambda$ = $\frac{1}{15}$, which means that the probability of X > 20 is: P(X>20) = $e^{-\lambda x}$ = $e^{-1}$ or .3678 (36.78%) the other questions are as follows: part 2: if there are no service calls during the last 10 minutes what is the probability that there will be no service call during the next 30 minutes? part 3: find the 90th percentile of X part 4: what is the median time between calls to the service center. can anyone help me solve these problems?",,['statistics']
10,Ranking probability problem,Ranking probability problem,,"$A, B, C$ are independently sampled from an uniform distribution in $[0, 1]$. We know $P(A > B) = 0.7, P(B > C) = 0.6$, what is $P(A > C)$? Is this a well defined problem? Does it have a sensible answer? EDIT: Suppose we have two careless observers. An observer observes $A > B$ and there are 70% probability that she is right. Another observer observes $B > C$ and there are 60% probability that she is right. So what is the probability of $A > C$ in the underlying event?","$A, B, C$ are independently sampled from an uniform distribution in $[0, 1]$. We know $P(A > B) = 0.7, P(B > C) = 0.6$, what is $P(A > C)$? Is this a well defined problem? Does it have a sensible answer? EDIT: Suppose we have two careless observers. An observer observes $A > B$ and there are 70% probability that she is right. Another observer observes $B > C$ and there are 60% probability that she is right. So what is the probability of $A > C$ in the underlying event?",,"['probability', 'statistics']"
11,Calculating kWh from multiple watt readings,Calculating kWh from multiple watt readings,,"I have a file which contains watt readings for various times throughout the day. A reading is stored roughly every 6 seconds. 206,2012/04/24 00:00:05 400,2012/04/24 00:00:21 300,2012/04/24 00:00:23 90,2012/04/24 00:00:29 I have two methods of working out a total kilowatt-hour figure from the above readings. Method 1:- I take an average of the watt reading, so 206+400+300+90 = 790 / 4 = 197.5 Then i work out the total range of the file, so 29 - 5 = 24 seconds. Then i work out the kWh by converting the avg. watts to kW 197.5 / 1000 = 0.1975 Convert the seconds to hours, 24/3600 = 0.006666666 Then 0.1975 * 0.00666666666666667 = 0.00131666 kwh. The other method i have is to work out the kwH per line and keep a running total:- I do this by working out how long the first reading lasted by subtracting the second readings time value from the first. We assume the last line lasted 6 seconds as we havent got a reading after it to distinguish its length. 206,2012/04/24 00:00:05    lasted 16 seconds             so 206 for 16 seconds = ? kwh 400,2012/04/24 00:00:21    lasted 2 seconds              so 400 for 2 seconds = ? kwh 300,2012/04/24 00:00:23    lasted 6 seconds              and so on.... 90,2012/04/24 00:00:29     assume last record lasted 6 seconds I then work out the kwh per line and keep a running total of the kwh reading. Question is, which is more accurate, and would there be a massive difference in the accuracy of the two methods.","I have a file which contains watt readings for various times throughout the day. A reading is stored roughly every 6 seconds. 206,2012/04/24 00:00:05 400,2012/04/24 00:00:21 300,2012/04/24 00:00:23 90,2012/04/24 00:00:29 I have two methods of working out a total kilowatt-hour figure from the above readings. Method 1:- I take an average of the watt reading, so 206+400+300+90 = 790 / 4 = 197.5 Then i work out the total range of the file, so 29 - 5 = 24 seconds. Then i work out the kWh by converting the avg. watts to kW 197.5 / 1000 = 0.1975 Convert the seconds to hours, 24/3600 = 0.006666666 Then 0.1975 * 0.00666666666666667 = 0.00131666 kwh. The other method i have is to work out the kwH per line and keep a running total:- I do this by working out how long the first reading lasted by subtracting the second readings time value from the first. We assume the last line lasted 6 seconds as we havent got a reading after it to distinguish its length. 206,2012/04/24 00:00:05    lasted 16 seconds             so 206 for 16 seconds = ? kwh 400,2012/04/24 00:00:21    lasted 2 seconds              so 400 for 2 seconds = ? kwh 300,2012/04/24 00:00:23    lasted 6 seconds              and so on.... 90,2012/04/24 00:00:29     assume last record lasted 6 seconds I then work out the kwh per line and keep a running total of the kwh reading. Question is, which is more accurate, and would there be a massive difference in the accuracy of the two methods.",,"['statistics', 'average']"
12,Is there an unbiased random walk on a colored plane for any number of colors?,Is there an unbiased random walk on a colored plane for any number of colors?,,"So I was trying to motivate the fundamental postulate of statistical mechanics (i.e. all microstates are assumed to be equally probable $-$ even if we can't practically measure them, but only their macroscopic properties) using simple examples. I came up with the simple analog of a dice, where the six sides $1-6$ are the random microstates and a yes/no-answer machine can only compute some rough ""macroscopic"" property of the result. When I tried to incorporate a metaphor for the dynamics, which changes one microstate to another, a mathematical problem emerged: The idea is to create a two-dimensional plane, (source: gstatic.com ) $\ \ \ $ (example of a random plane) with $n$ (e.g. six) differently colored fields and the following property: If you stand on one field of some color and you take a random step to a neightboring field you can end up on any of the other colors. So the problem is to find a colored plane, finite or not, such that every other color can be reached from every colored field. The number of colors $n$ is fixed, but the number of fields on the plane is $n$ or more (i.e. repitition of equally colored fields is allowed). Up to four colors, I figured that a solution would just be projections of a tetrahedron. For these solution you need only exactly $n$ fields and if you want them to they are even finite or ""compact"" as board: But from there on it gets tricky. For which $n$ is it possible to solve the problem described above and why ? If there are some ways around it, how can the constructions be formalized? Sadly, I guess there are some topological restrictions above $n=4$ . This leads to a more difficult secondary follow up question. Let's say I come up with a plane, which doesn't fulfill the criteria of equal propability for each color, like for example in where there are some red fields, which don't connect to blue ones. Then if I start somewhere and take $100$ random steps, I will collect fewer blue than yellow steps. Is there a canonical way to classify the dependency of the descriptive statistics of the random walk on the structure and coloring of the plane? This gets difficult very fast, but I can imagine inductive investigations on geometries with high symmetry. I also have a little second question for the dice metaphor, which has no definitive answer and is too trivial for a seperate post: To define a ""macroscopic property"" of a dice roll, what are some good/interesting ways to distinguish two out of the six numbers $\{1,2,3,4,5,6\}$ ? The best thing I could come up with is ""these numbers are divisible by 3"", but that's kind of lame.","So I was trying to motivate the fundamental postulate of statistical mechanics (i.e. all microstates are assumed to be equally probable even if we can't practically measure them, but only their macroscopic properties) using simple examples. I came up with the simple analog of a dice, where the six sides are the random microstates and a yes/no-answer machine can only compute some rough ""macroscopic"" property of the result. When I tried to incorporate a metaphor for the dynamics, which changes one microstate to another, a mathematical problem emerged: The idea is to create a two-dimensional plane, (source: gstatic.com ) (example of a random plane) with (e.g. six) differently colored fields and the following property: If you stand on one field of some color and you take a random step to a neightboring field you can end up on any of the other colors. So the problem is to find a colored plane, finite or not, such that every other color can be reached from every colored field. The number of colors is fixed, but the number of fields on the plane is or more (i.e. repitition of equally colored fields is allowed). Up to four colors, I figured that a solution would just be projections of a tetrahedron. For these solution you need only exactly fields and if you want them to they are even finite or ""compact"" as board: But from there on it gets tricky. For which is it possible to solve the problem described above and why ? If there are some ways around it, how can the constructions be formalized? Sadly, I guess there are some topological restrictions above . This leads to a more difficult secondary follow up question. Let's say I come up with a plane, which doesn't fulfill the criteria of equal propability for each color, like for example in where there are some red fields, which don't connect to blue ones. Then if I start somewhere and take random steps, I will collect fewer blue than yellow steps. Is there a canonical way to classify the dependency of the descriptive statistics of the random walk on the structure and coloring of the plane? This gets difficult very fast, but I can imagine inductive investigations on geometries with high symmetry. I also have a little second question for the dice metaphor, which has no definitive answer and is too trivial for a seperate post: To define a ""macroscopic property"" of a dice roll, what are some good/interesting ways to distinguish two out of the six numbers ? The best thing I could come up with is ""these numbers are divisible by 3"", but that's kind of lame.","- 1-6 \ \ \  n n n n n n=4 100 \{1,2,3,4,5,6\}","['general-topology', 'statistics', 'graph-theory', 'random-walk', 'coloring']"
13,Find the Bayes estimate of $θ$,Find the Bayes estimate of,θ,"Can someone help me solve this out, please? Thanks a lot. Find the Bayes estimate of $\theta$ based on a single observation of $5$ from a distribution that is uniform on the interval 0 to $\theta$. Use square-error loss and a prior distribution of $\theta$ which has p.d.f. $p(\theta) = \theta \cdot \mathrm{e}^{-\theta}$ where  $0<\theta <\infty$.","Can someone help me solve this out, please? Thanks a lot. Find the Bayes estimate of $\theta$ based on a single observation of $5$ from a distribution that is uniform on the interval 0 to $\theta$. Use square-error loss and a prior distribution of $\theta$ which has p.d.f. $p(\theta) = \theta \cdot \mathrm{e}^{-\theta}$ where  $0<\theta <\infty$.",,['statistics']
14,"Multiplying two averages, what to do with the deviations?","Multiplying two averages, what to do with the deviations?",,"If I multiply the averages of two sets of data, then what can I conclude with the deviation of that data? That is, for a given average X1 and X2, both are different sets of data but related, I calculated a derived average X3 = X1 * X2. Both X1 and X2 also has their own standard deviation values, D1 and D2. How can I calculate the standard deviation value D3? My concrete sample problem to illustrate the use-case I have sample performance measurements of a computer operation, measured in miliseconds / invocation (the first data set) and invocations / day (the second data set). Both of these has a mean and a standard deviation value. I would like to get another measure that is in miliseconds / day . So I multiplied the first data with the second : X1 * X2 = X3 miliseconds / invocation * invocations / day = miliseconds / day The question is, how do I get the standard deviation value of X3 ? Thanks in advance.","If I multiply the averages of two sets of data, then what can I conclude with the deviation of that data? That is, for a given average X1 and X2, both are different sets of data but related, I calculated a derived average X3 = X1 * X2. Both X1 and X2 also has their own standard deviation values, D1 and D2. How can I calculate the standard deviation value D3? My concrete sample problem to illustrate the use-case I have sample performance measurements of a computer operation, measured in miliseconds / invocation (the first data set) and invocations / day (the second data set). Both of these has a mean and a standard deviation value. I would like to get another measure that is in miliseconds / day . So I multiplied the first data with the second : X1 * X2 = X3 miliseconds / invocation * invocations / day = miliseconds / day The question is, how do I get the standard deviation value of X3 ? Thanks in advance.",,"['statistics', 'standard-deviation']"
15,ELO ranking system: what's a good start rank?,ELO ranking system: what's a good start rank?,,"I'm looking to implement an ELO ranking system. I've read the wikipedia articles and I'm confused about the start rank for players who enter the system at a later point. The common solution is to use a provisional ranking system but I'm curious if anyone can point me to specific numeric details: what K value do new players get? how long does a player stay in provisional mode? how does K value change as rank changes? I'm sure there are many variations, I'd just like to know actual numbers for a system that someone has implemented successfully. Thanks for your time.","I'm looking to implement an ELO ranking system. I've read the wikipedia articles and I'm confused about the start rank for players who enter the system at a later point. The common solution is to use a provisional ranking system but I'm curious if anyone can point me to specific numeric details: what K value do new players get? how long does a player stay in provisional mode? how does K value change as rank changes? I'm sure there are many variations, I'd just like to know actual numbers for a system that someone has implemented successfully. Thanks for your time.",,['statistics']
16,Showing a distribution is not complete for a parameter $\theta$,Showing a distribution is not complete for a parameter,\theta,"I am trying to show that a normal distribution with parameters $\mu = 0$ and variance $\theta$ is not complete. I am looking for a function $u(x)$ that is not equal to 0 such that $\mathbb E(u(x)) = 0$. I have done some research on this problem and I have found that $\bar{X}$ and $S$ (sample standard deviation) are independent and can help yield me a function that will give me $\mathbb E(u(x)) = 0$. I know that $\bar{X}$ is normally distributed with mean 0 and variance $\theta/n$. I know that $S^2$ has a chi-squared distribution. I was trying to take an expectation $\mathbb E(\bar{X} S^2)$ to yield a value of 0, but I am not sure how exactly to do that. Also, would this approach be correct in showing that it is not complete for $\theta$? EDIT: An iid sample is taken and theta > 0.","I am trying to show that a normal distribution with parameters $\mu = 0$ and variance $\theta$ is not complete. I am looking for a function $u(x)$ that is not equal to 0 such that $\mathbb E(u(x)) = 0$. I have done some research on this problem and I have found that $\bar{X}$ and $S$ (sample standard deviation) are independent and can help yield me a function that will give me $\mathbb E(u(x)) = 0$. I know that $\bar{X}$ is normally distributed with mean 0 and variance $\theta/n$. I know that $S^2$ has a chi-squared distribution. I was trying to take an expectation $\mathbb E(\bar{X} S^2)$ to yield a value of 0, but I am not sure how exactly to do that. Also, would this approach be correct in showing that it is not complete for $\theta$? EDIT: An iid sample is taken and theta > 0.",,"['probability', 'statistics']"
17,"What probability distribution function(s) describe asymmetrical ""increasing resistance""?","What probability distribution function(s) describe asymmetrical ""increasing resistance""?",,"I don't have the proper vocabulary, so I'll just try to present two situations that I think capture my question: if you were to chart ""vertical leaping ability among high school students,"" I would think you'd get a distribution where there'd be a lot of variance in the below-median ability but less variance at the high-end because advantages between elite and quite-fit athletes are only a matter of a few inches. Another example might be ""speeds of everyone riding a bike right now"" where the above-median side is limited by wind resistance. Is this sort of situation described by its own probability distribution function or does one have to preprocess the data so that the varying / resistance aspect is removed? (That is, transform ""vertical leap"" or ""bike speed"" into calories or somesuch; but what if the underlying driver(s) are unknown?)","I don't have the proper vocabulary, so I'll just try to present two situations that I think capture my question: if you were to chart ""vertical leaping ability among high school students,"" I would think you'd get a distribution where there'd be a lot of variance in the below-median ability but less variance at the high-end because advantages between elite and quite-fit athletes are only a matter of a few inches. Another example might be ""speeds of everyone riding a bike right now"" where the above-median side is limited by wind resistance. Is this sort of situation described by its own probability distribution function or does one have to preprocess the data so that the varying / resistance aspect is removed? (That is, transform ""vertical leap"" or ""bike speed"" into calories or somesuch; but what if the underlying driver(s) are unknown?)",,"['statistics', 'probability-distributions']"
18,Course Grade - Statistics Question,Course Grade - Statistics Question,,"I'm confused about finding the standard deviation of various weighted objects in a problem. For example, consider an academic setting, with four assessments as follows: (30pts weight) Quiz 1 - Avg: 75% Std: +/- 35% Quiz 2 - Avg: 39.6% Std: +/- 25.4% Quiz 3 - Avg: 69.4% Std: +/- 22.4%  (20pts weight)  Midterm - Avg: 63.62% +/- 13.09%  (50pts total) Overall - Avg: 62% +/- 10.89% Could one then calculate the std's for the course average, by treating the std's like the avg, and just weight them? That's how I got the std above for the overall grade.","I'm confused about finding the standard deviation of various weighted objects in a problem. For example, consider an academic setting, with four assessments as follows: (30pts weight) Quiz 1 - Avg: 75% Std: +/- 35% Quiz 2 - Avg: 39.6% Std: +/- 25.4% Quiz 3 - Avg: 69.4% Std: +/- 22.4%  (20pts weight)  Midterm - Avg: 63.62% +/- 13.09%  (50pts total) Overall - Avg: 62% +/- 10.89% Could one then calculate the std's for the course average, by treating the std's like the avg, and just weight them? That's how I got the std above for the overall grade.",,"['statistics', 'average', 'standard-deviation']"
19,A subtle modification to the $t$ distribution,A subtle modification to the  distribution,t,"Let $X$ and $Y\,$ be independent normal random variables with zero mean. What are the differences between the distributions of $$A\triangleq \frac{X+Y}{X-Y} \quad\text{ and }\quad B\triangleq \frac{X+Y}{|X-Y\,|}\quad?$$","Let $X$ and $Y\,$ be independent normal random variables with zero mean. What are the differences between the distributions of $$A\triangleq \frac{X+Y}{X-Y} \quad\text{ and }\quad B\triangleq \frac{X+Y}{|X-Y\,|}\quad?$$",,"['statistics', 'probability-distributions']"
20,Confidence interval of a random variable for an ordinary linear regression,Confidence interval of a random variable for an ordinary linear regression,,"I have a small problem. With my limited stats background I am not sure I am getting this one right. After fitting an ordinary linear regression model I get $$\hat{\underline{Y}}=X\hat{\underline{\beta}}$$ Now the problem is to calculate confidence interval of not observed $Y_{\alpha}$. Is this incredible stupid to just calculate confidence interval for each $\beta_j$, say $\hat{\beta_j}\pm\epsilon_j$ and then look at $a:=\sum{\epsilon_j} x_{ij}+\hat{\sigma} z$, (z=1.96 usually) where $\sigma^2$ is the variance of an error term of a model $$\underline{Y}=X\underline{\beta}+\underline{\epsilon}, \underline{\epsilon} \sim N_n(0,\sigma^2I_n)$$ Now It seems intuitive to claim that $(\sum{\hat{\beta_j} x_{ij}}\pm a)$ is the confidence interval for $Y_{\alpha}$.","I have a small problem. With my limited stats background I am not sure I am getting this one right. After fitting an ordinary linear regression model I get $$\hat{\underline{Y}}=X\hat{\underline{\beta}}$$ Now the problem is to calculate confidence interval of not observed $Y_{\alpha}$. Is this incredible stupid to just calculate confidence interval for each $\beta_j$, say $\hat{\beta_j}\pm\epsilon_j$ and then look at $a:=\sum{\epsilon_j} x_{ij}+\hat{\sigma} z$, (z=1.96 usually) where $\sigma^2$ is the variance of an error term of a model $$\underline{Y}=X\underline{\beta}+\underline{\epsilon}, \underline{\epsilon} \sim N_n(0,\sigma^2I_n)$$ Now It seems intuitive to claim that $(\sum{\hat{\beta_j} x_{ij}}\pm a)$ is the confidence interval for $Y_{\alpha}$.",,"['statistics', 'probability-distributions', 'regression']"
21,Ridge Regression: $\hat{\beta} \rightarrow \beta$,Ridge Regression:,\hat{\beta} \rightarrow \beta,"I'm trying to find the probability limit of $$\hat{\beta} = \left( \sum x_i x'_i + \lambda I_k \right)^{-1} \left( \sum x_i y_i \right) $$ as $n \to \infty$, and $\lambda$ is some positive constant. I've gotten as far as as substituting $y_i = \beta x + e_i$.  (Which I know isn't very far).  I'm not really sure how to progress.  If anyone could provide some help that be greatly appreciated. Thanks","I'm trying to find the probability limit of $$\hat{\beta} = \left( \sum x_i x'_i + \lambda I_k \right)^{-1} \left( \sum x_i y_i \right) $$ as $n \to \infty$, and $\lambda$ is some positive constant. I've gotten as far as as substituting $y_i = \beta x + e_i$.  (Which I know isn't very far).  I'm not really sure how to progress.  If anyone could provide some help that be greatly appreciated. Thanks",,"['statistics', 'regression']"
22,General question about statistical concept,General question about statistical concept,,"In parametric statistics, the goal is to estimate the parameter of a population assuming that we know the form of the density of the  population. What happens if we do not know the form of the density of the population? In all practical problems, we do not know the form of the population density. Can someone give me an example of a problem where we know the form of the density of the population and a problem where we do not know the form of the density of the population?","In parametric statistics, the goal is to estimate the parameter of a population assuming that we know the form of the density of the  population. What happens if we do not know the form of the density of the population? In all practical problems, we do not know the form of the population density. Can someone give me an example of a problem where we know the form of the density of the population and a problem where we do not know the form of the density of the population?",,['statistics']
23,Unbiased estimator questions,Unbiased estimator questions,,"If $X_1,X_2,\ldots,X_n$ are i.i.d. $\mathrm{B}(1,p)$, find the best unbiased estimator of $p^n$. Attempt: Use indicator functions to show every observation has mean equal to 1 so this is the same as the summation of the xi's = n. So this is a sufficient statistic and best unbiased estimator. Let $X_1,X_2,\ldots,X_n$ be i.i.d. $\mathcal{N}(\mu,1)$. If $\bar{x}$ attains the lower bound as an unbiased estimator of $\mu$, find the Fisher Information in $(X_1,X_2,\ldots,X_n)$. Fisher information = 1/CR-lower bound. If $X_1,X_2,\ldots,X_n$ are i.i.d. Uniform on $(\theta-\frac{1}{4},\theta + \frac{1}{4})$, find the sufficient statistic for theta and find an unbiased estimator of $\theta$ based on $\bar{x}$ and determine if you can improve it. So x_bar is a sufficent statistic and E[Unbiased Estimator|Sufficent Statistic] is the best unbiased estimator.","If $X_1,X_2,\ldots,X_n$ are i.i.d. $\mathrm{B}(1,p)$, find the best unbiased estimator of $p^n$. Attempt: Use indicator functions to show every observation has mean equal to 1 so this is the same as the summation of the xi's = n. So this is a sufficient statistic and best unbiased estimator. Let $X_1,X_2,\ldots,X_n$ be i.i.d. $\mathcal{N}(\mu,1)$. If $\bar{x}$ attains the lower bound as an unbiased estimator of $\mu$, find the Fisher Information in $(X_1,X_2,\ldots,X_n)$. Fisher information = 1/CR-lower bound. If $X_1,X_2,\ldots,X_n$ are i.i.d. Uniform on $(\theta-\frac{1}{4},\theta + \frac{1}{4})$, find the sufficient statistic for theta and find an unbiased estimator of $\theta$ based on $\bar{x}$ and determine if you can improve it. So x_bar is a sufficent statistic and E[Unbiased Estimator|Sufficent Statistic] is the best unbiased estimator.",,"['statistics', 'random-variables', 'estimation', 'parameter-estimation']"
24,Boxcar Recursive Method for Finding Standard Deviation,Boxcar Recursive Method for Finding Standard Deviation,,"I'm trying to develop a real time algorithm for finding level areas of an electrical signal. To do so I need to find the variance for a particular rolling time interval. From John Cook's blog and the Art of Computer Programming the algorithm for quickly determining variance is: M k = M k-1 + (x k - M k-1 )/k S k = S k-1 + (x k - M k-1 ) * (x k - M k ) Where the kth estimate of the variance is: $ s^2 = S_k / (k-1) $ This works great, but I need to keep a 'rolling' variance of 100 samples. With each step I would add one new sample and take the 100th sample off the list. If I know the value of x k-100 is there a quick algorithm for 'erasing' it from the variance result?","I'm trying to develop a real time algorithm for finding level areas of an electrical signal. To do so I need to find the variance for a particular rolling time interval. From John Cook's blog and the Art of Computer Programming the algorithm for quickly determining variance is: M k = M k-1 + (x k - M k-1 )/k S k = S k-1 + (x k - M k-1 ) * (x k - M k ) Where the kth estimate of the variance is: $ s^2 = S_k / (k-1) $ This works great, but I need to keep a 'rolling' variance of 100 samples. With each step I would add one new sample and take the 100th sample off the list. If I know the value of x k-100 is there a quick algorithm for 'erasing' it from the variance result?",,"['statistics', 'algorithms', 'recurrence-relations']"
25,basic probability question - effect of repetition on odds,basic probability question - effect of repetition on odds,,"If I have a 5% chance of catching a cold by hugging someone with a cold, what are the odds that I will catch a cold if I hug someone 150 times?  Sorry, basic question.","If I have a 5% chance of catching a cold by hugging someone with a cold, what are the odds that I will catch a cold if I hug someone 150 times?  Sorry, basic question.",,"['probability', 'statistics']"
26,What is the standard deviation of multiple correlated random variables subtracted from another random variable?,What is the standard deviation of multiple correlated random variables subtracted from another random variable?,,Wiki states that standard deviation of $X-Y$ is: $$\sigma_{x-y} = \sqrt { \sigma_x^2 + \sigma_y^2 - 2\rho\sigma_x\sigma_y }$$ I have a number (say 3) correlated random variables to be subtracted from another correlated random variable. All random variables have identical correlation $\rho$. Can I subtract each one in turn like this: $$\sigma_{x-1} = \sqrt { \sigma_x^2 + \sigma_1^2 - 2\rho\sigma_x\sigma_1 }$$ $$\sigma_{x-2} = \sqrt { \sigma_{x-1}^2 + \sigma_2^2 - 2\rho\sigma_{x-1}\sigma_2 }$$ $$\sigma_{x-3} = \sqrt { \sigma_{x-2}^2 + \sigma_3^2 - 2\rho\sigma_{x-2}\sigma_3 }$$ The application is determining carrier-to-interference ratio of multiple co-channel interferers in an environment where it can be assumed that each interferer has identical correlated variation.,Wiki states that standard deviation of $X-Y$ is: $$\sigma_{x-y} = \sqrt { \sigma_x^2 + \sigma_y^2 - 2\rho\sigma_x\sigma_y }$$ I have a number (say 3) correlated random variables to be subtracted from another correlated random variable. All random variables have identical correlation $\rho$. Can I subtract each one in turn like this: $$\sigma_{x-1} = \sqrt { \sigma_x^2 + \sigma_1^2 - 2\rho\sigma_x\sigma_1 }$$ $$\sigma_{x-2} = \sqrt { \sigma_{x-1}^2 + \sigma_2^2 - 2\rho\sigma_{x-1}\sigma_2 }$$ $$\sigma_{x-3} = \sqrt { \sigma_{x-2}^2 + \sigma_3^2 - 2\rho\sigma_{x-2}\sigma_3 }$$ The application is determining carrier-to-interference ratio of multiple co-channel interferers in an environment where it can be assumed that each interferer has identical correlated variation.,,"['statistics', 'correlation']"
27,Statistics with overlapping periods,Statistics with overlapping periods,,"I've been having a lot of discussions about finance recently in which people will point to some results using overlapping time periods and claim a high degree of statistical significance.  For example, they might say only one 20 year period since 1900 (1900-1920, 1901-1921, etc) has experienced X.  They will say they have 91 data points.  I say they have about 5.5 independent data points and that using overlapping periods overstates the statistical significance of the results. 1) Am I missing something? 2) Is there any respected source I can point to on the subject, such as a widely used textbook?","I've been having a lot of discussions about finance recently in which people will point to some results using overlapping time periods and claim a high degree of statistical significance.  For example, they might say only one 20 year period since 1900 (1900-1920, 1901-1921, etc) has experienced X.  They will say they have 91 data points.  I say they have about 5.5 independent data points and that using overlapping periods overstates the statistical significance of the results. 1) Am I missing something? 2) Is there any respected source I can point to on the subject, such as a widely used textbook?",,"['statistics', 'finance', 'economics']"
28,The inverse variance is proportional to the sample size?,The inverse variance is proportional to the sample size?,,"Interested in meta-analysis I found the lecture notes http://www.uazuay.edu.ec/cibse/lecture_notes.pdf I understand that it makes sense in a meta-analysis to assign different weights to different studies. Personally I find it natural to weigh by the sample sizes of the particular studies. However, in the fixed effect model the inverse of the variances is used. As an explanation on page 17 I read the sentence  ""The inverse variance is roughly proportional to sample size, but has finer distinctions,( and serves to minimize the variance of the combined effect.)"" I do not understand that and have problems with the first claim. Suppose $X_1,..,X_n$ are random variables iid. Then  $\bar{X}=\frac{1}{n} \sum_n X_i$ has variance $\frac{Var(X)}{n}$. This is clear. So one could say that on the level of random variables the inverse variance of the arithmetic mean is proportional to the sample size. However, on the level of samples, we always compute the sample means and the sample variances, and the sample variance is an estimator for the variance of an individual measurement and not the variance of the (sample) arithmetic mean. Can somebody clear up my confusion","Interested in meta-analysis I found the lecture notes http://www.uazuay.edu.ec/cibse/lecture_notes.pdf I understand that it makes sense in a meta-analysis to assign different weights to different studies. Personally I find it natural to weigh by the sample sizes of the particular studies. However, in the fixed effect model the inverse of the variances is used. As an explanation on page 17 I read the sentence  ""The inverse variance is roughly proportional to sample size, but has finer distinctions,( and serves to minimize the variance of the combined effect.)"" I do not understand that and have problems with the first claim. Suppose $X_1,..,X_n$ are random variables iid. Then  $\bar{X}=\frac{1}{n} \sum_n X_i$ has variance $\frac{Var(X)}{n}$. This is clear. So one could say that on the level of random variables the inverse variance of the arithmetic mean is proportional to the sample size. However, on the level of samples, we always compute the sample means and the sample variances, and the sample variance is an estimator for the variance of an individual measurement and not the variance of the (sample) arithmetic mean. Can somebody clear up my confusion",,['statistics']
29,Scoring system for two-party game,Scoring system for two-party game,,"Suppose we have a game that operates with '$a~$' players for one party, and '$b~$' players on the opposing party. Each party has a long-run average win percentage for this game, with $A\%$ and $B\%~$(such that $(A + B) = 100~$) respectively for the first and second party. After $(a+b)$ players are willing to participate in the game, each will be assigned to a party (with equal chance of joining either party) Firstly, I was wondering if the expected long-run average win percentage for a random player joining this game, before his alignment has been assigned, can be calculated using the formula $\frac{aA + bB}{a + b}\% ~$, and if there are any improvements that can be made to this description. More particularly, this game is one of a system of games. The system aims to discourage players exclusively selecting games with a high $\frac{aA + bB}{a + b}\% ~$ percentage, or in other words, games in which a random player joining can more easily win ( before his alignment has been assigned) Furthermore, suppose the first party wins the game, and one were to allocate points to the party based on some scoring system. The maximum number of points allowed to be allocated to a specific party is 100 points. Would the following formula allocate the points in a fair manner, under the assumption that loss rate of party $\propto$ points deserved ? $\displaystyle \frac{(100 - A) + (100 - \frac{aA + bB}{a + b})}{2}~$ noting that $(100 -A) = B$ How could this model possibly be improved? Please comment if this description is too vague or unclear, and I apologize if this question is not suitable for this website. Note: In the formula, I'm averaging functions of two values (long-run average win percentage before and after alignment has been dictated) to determine the points deserved. As an example, suppose a game has 9 players for the first party, and 1 player for the second. The long-run average win probabilities are 60% and 40% respectively for each party. By the first formula, the average win probability for a random player joining this game is $\frac{60\times9 + 40}{9 +1}\%=58\%$ The scoring system punishes joining games with a high win probability, hence, half the score will be determined by $(100 - 58) = 42~$,  as loss rate $\propto$ points deserved. The scoring system also rewards games won by a party with a high win probability less , hence if the first party wins, the second half of the score is determined by $(100 - 60) = 40~$, as loss rate of party $\propto$ points deserved. Therefore, the final score is the average, $\frac{40 + 42}{2} = 41~$.This is modeled by the above formulas. Comment: Specifically, the variation in long-run average win percentages for the parties arises naturally as a result of specific methods, unique to each party , that can be exploited to win the game,  and thus, this may unintentionally favor a specific party (as reflected in win probabilities, if $A\ne B$)","Suppose we have a game that operates with '$a~$' players for one party, and '$b~$' players on the opposing party. Each party has a long-run average win percentage for this game, with $A\%$ and $B\%~$(such that $(A + B) = 100~$) respectively for the first and second party. After $(a+b)$ players are willing to participate in the game, each will be assigned to a party (with equal chance of joining either party) Firstly, I was wondering if the expected long-run average win percentage for a random player joining this game, before his alignment has been assigned, can be calculated using the formula $\frac{aA + bB}{a + b}\% ~$, and if there are any improvements that can be made to this description. More particularly, this game is one of a system of games. The system aims to discourage players exclusively selecting games with a high $\frac{aA + bB}{a + b}\% ~$ percentage, or in other words, games in which a random player joining can more easily win ( before his alignment has been assigned) Furthermore, suppose the first party wins the game, and one were to allocate points to the party based on some scoring system. The maximum number of points allowed to be allocated to a specific party is 100 points. Would the following formula allocate the points in a fair manner, under the assumption that loss rate of party $\propto$ points deserved ? $\displaystyle \frac{(100 - A) + (100 - \frac{aA + bB}{a + b})}{2}~$ noting that $(100 -A) = B$ How could this model possibly be improved? Please comment if this description is too vague or unclear, and I apologize if this question is not suitable for this website. Note: In the formula, I'm averaging functions of two values (long-run average win percentage before and after alignment has been dictated) to determine the points deserved. As an example, suppose a game has 9 players for the first party, and 1 player for the second. The long-run average win probabilities are 60% and 40% respectively for each party. By the first formula, the average win probability for a random player joining this game is $\frac{60\times9 + 40}{9 +1}\%=58\%$ The scoring system punishes joining games with a high win probability, hence, half the score will be determined by $(100 - 58) = 42~$,  as loss rate $\propto$ points deserved. The scoring system also rewards games won by a party with a high win probability less , hence if the first party wins, the second half of the score is determined by $(100 - 60) = 40~$, as loss rate of party $\propto$ points deserved. Therefore, the final score is the average, $\frac{40 + 42}{2} = 41~$.This is modeled by the above formulas. Comment: Specifically, the variation in long-run average win percentages for the parties arises naturally as a result of specific methods, unique to each party , that can be exploited to win the game,  and thus, this may unintentionally favor a specific party (as reflected in win probabilities, if $A\ne B$)",,"['probability', 'statistics']"
30,Calculate relative contribution to percent change,Calculate relative contribution to percent change,,"Let me use a simple example to illustrate my problem. First, assume we are calculating rate $r$ at time $t$ such that $r_t=\frac{x_t}{y_t}$ . Furthermore, each measure has two component parts: $x = x_A +x_B$ and $y = y_A + y_B$ . We can thus calculate percent change $c$ for the rate between $t_2>t_1$ as $c=\frac{r_2-r_1}{r_1}$ . Next, I want to allocate $c$ to measure the relative contribution of each component $A$ and $B$ . When the changes are in the same direction between $t_1$ and $t_2$ this is easy (e.g. $x_{A_1} > x_{A_2}$ and $x_{B_1} > x_{B_2}$ and $y_{A_1} > y_{A_2}$ and $y_{B_1} > y_{B_2}$ ). You calculate the change for each component, divide that by the absolute change and apply that ""share"" to the total percent change. That allows me to make a statement, e.g. when the rate changed from $10\%$ to $15\%$ , $75\%$ of the $50\%$ change was due to component $A$ and $25\%$ to component $B$ . Here's my question: how can I calculate the relative contribution of these components when the differences are in opposite directions? For example, component $A$ decreased for $x$ and $y$ (and more for $y$ , relatively) and component $B$ increased for $x$ and $y$ (and more for $y$ , relatively). I'm sure this is simple but no amount of searching has made me the wiser. If you could point me in the right direction -- or ask questions to better illuminate my subject matter -- I would greatly appreciate your help. Thanks! PS: I found a few resources, linked below but I'm still not sure of the exact math required.... http://www.bea.gov/papers/pdf/Moulton0603.pdf http://www.esri.cao.go.jp/en/sna/sokuhou/kako/2007/qe074/kiyoe.pdf","Let me use a simple example to illustrate my problem. First, assume we are calculating rate at time such that . Furthermore, each measure has two component parts: and . We can thus calculate percent change for the rate between as . Next, I want to allocate to measure the relative contribution of each component and . When the changes are in the same direction between and this is easy (e.g. and and and ). You calculate the change for each component, divide that by the absolute change and apply that ""share"" to the total percent change. That allows me to make a statement, e.g. when the rate changed from to , of the change was due to component and to component . Here's my question: how can I calculate the relative contribution of these components when the differences are in opposite directions? For example, component decreased for and (and more for , relatively) and component increased for and (and more for , relatively). I'm sure this is simple but no amount of searching has made me the wiser. If you could point me in the right direction -- or ask questions to better illuminate my subject matter -- I would greatly appreciate your help. Thanks! PS: I found a few resources, linked below but I'm still not sure of the exact math required.... http://www.bea.gov/papers/pdf/Moulton0603.pdf http://www.esri.cao.go.jp/en/sna/sokuhou/kako/2007/qe074/kiyoe.pdf",r t r_t=\frac{x_t}{y_t} x = x_A +x_B y = y_A + y_B c t_2>t_1 c=\frac{r_2-r_1}{r_1} c A B t_1 t_2 x_{A_1} > x_{A_2} x_{B_1} > x_{B_2} y_{A_1} > y_{A_2} y_{B_1} > y_{B_2} 10\% 15\% 75\% 50\% A 25\% B A x y y B x y y,"['probability', 'statistics', 'soft-question']"
31,leading and lagging moving average indicator,leading and lagging moving average indicator,,"What are leading short and lagging long moving average indicators and how do we calculate them? e.g. for the following data set, and let window size be 2 . Can you show me what the running leading and lagging moving averages are? 4 5 2 10 3 8 9 Reference: http://www.mathworks.com/help/toolbox/finance/movavg.html Thanks!","What are leading short and lagging long moving average indicators and how do we calculate them? e.g. for the following data set, and let window size be 2 . Can you show me what the running leading and lagging moving averages are? 4 5 2 10 3 8 9 Reference: http://www.mathworks.com/help/toolbox/finance/movavg.html Thanks!",,"['statistics', 'average']"
32,Help needed on method to use for anomaly detection in Computer Science,Help needed on method to use for anomaly detection in Computer Science,,"I think people here could guide me in solving a problem related to anomaly detection. The term anomaly here refers to some undesired event occurring in the system like a virus infection. I could get to know about it from more than one source. For example extracting value from two different data structure and if the value is different it is certain that virus infection is there. In order to remove the false positive cases, information is gathered from different data structures or mechanisms. In that certain information are less trusted and certain information are more trusted. I am looking for a mathematical method, that could easily handle this type of situations. Whether fuzzy/Genetic Algorithm/Neural Net fits here ? Found in some places they using one normality based approach(using z score) . Please help.","I think people here could guide me in solving a problem related to anomaly detection. The term anomaly here refers to some undesired event occurring in the system like a virus infection. I could get to know about it from more than one source. For example extracting value from two different data structure and if the value is different it is certain that virus infection is there. In order to remove the false positive cases, information is gathered from different data structures or mechanisms. In that certain information are less trusted and certain information are more trusted. I am looking for a mathematical method, that could easily handle this type of situations. Whether fuzzy/Genetic Algorithm/Neural Net fits here ? Found in some places they using one normality based approach(using z score) . Please help.",,"['statistics', 'computer-science', 'fuzzy-logic', 'machine-learning']"
33,Statistics Question of the Day,Statistics Question of the Day,,"Motivation: I am a graduate student in the Department of Statistics at Kansas State University. Everyday I create a ""question of the day"" for myself, and it has been going well for the past year. These are often little distribution puzzles (sum of iid r.v. from Chi-Square is also Chi-Square, etc). Today, I came up with a question that seems simple (and perhaps is); however, I am quite stumped. The question is as follows: Question: Let $\{X_n\} \stackrel{iid}{\sim}$ Exp( $\theta$ ), where $\theta > 0$ . What is the distribution of $\{X_{(i)} - X_{(i-1)}\}$ , $i = 2, \dots, n$ ? (Note: $X_{(i)}$ denotes the i-th order statistic) Thought Process: I began by looking at the pdf for order statistics, both marginally and jointly; however, this did not lead anywhere because I am interested in the difference between two order statistics, and not the joint pdf of two order statistics. My other thought was to examine the mgf of each, but I cannot find an explicit method for determining the mgf of an order statistic.","Motivation: I am a graduate student in the Department of Statistics at Kansas State University. Everyday I create a ""question of the day"" for myself, and it has been going well for the past year. These are often little distribution puzzles (sum of iid r.v. from Chi-Square is also Chi-Square, etc). Today, I came up with a question that seems simple (and perhaps is); however, I am quite stumped. The question is as follows: Question: Let Exp( ), where . What is the distribution of , ? (Note: denotes the i-th order statistic) Thought Process: I began by looking at the pdf for order statistics, both marginally and jointly; however, this did not lead anywhere because I am interested in the difference between two order statistics, and not the joint pdf of two order statistics. My other thought was to examine the mgf of each, but I cannot find an explicit method for determining the mgf of an order statistic.","\{X_n\} \stackrel{iid}{\sim} \theta \theta > 0 \{X_{(i)} - X_{(i-1)}\} i = 2, \dots, n X_{(i)}","['statistics', 'probability-distributions', 'exponential-distribution', 'order-statistics']"
34,Magical relationship between Exponential distribution and Poisson process,Magical relationship between Exponential distribution and Poisson process,,"Consider i.i.d. random variables $X_1,X_2,\ldots,X_n$ satisfying exponential distribution $\operatorname{Exp}(1)$ . Let $Y=X_1+X_2+\ldots+X_n$ . We know that the p.d.f. of $Y$ is the Gamma distribution $$ f_Y(t)=\frac{t^{n-1}}{(n-1)!}e^{-t}, (t\geq 0). $$ What surprised me is that this is exactly the p.m.f. of a Poisson distribution with parameter $t$ . Define a Poisson process with rate $1$ , $N_t$ , then $\frac{t^{n-1}}{(n-1)!}e^{-t}$ equals $P(N_t=n-1)$ . Since we can define Poisson process with i.i.d. exponentials, we actually can write $$ P\left(\sum_{i=1}^{n-1}X_i\leq t, \sum_{i=1}^n X_i>t\right)= P(N_t=n-1)=\frac{t^{n-1}}{(n-1)!}e^{-t}. $$ I believe there must exist a intuitive explanation of this relationship. But I couldn’t find it.","Consider i.i.d. random variables satisfying exponential distribution . Let . We know that the p.d.f. of is the Gamma distribution What surprised me is that this is exactly the p.m.f. of a Poisson distribution with parameter . Define a Poisson process with rate , , then equals . Since we can define Poisson process with i.i.d. exponentials, we actually can write I believe there must exist a intuitive explanation of this relationship. But I couldn’t find it.","X_1,X_2,\ldots,X_n \operatorname{Exp}(1) Y=X_1+X_2+\ldots+X_n Y 
f_Y(t)=\frac{t^{n-1}}{(n-1)!}e^{-t}, (t\geq 0).
 t 1 N_t \frac{t^{n-1}}{(n-1)!}e^{-t} P(N_t=n-1) 
P\left(\sum_{i=1}^{n-1}X_i\leq t, \sum_{i=1}^n X_i>t\right)= P(N_t=n-1)=\frac{t^{n-1}}{(n-1)!}e^{-t}.
","['probability', 'statistics', 'stochastic-processes', 'equivalence-relations', 'gamma-distribution']"
35,"Find $a_n,b_n$ so that $b_n(X_n-a_n)$ converges to a non-degenerate limit",Find  so that  converges to a non-degenerate limit,"a_n,b_n b_n(X_n-a_n)","I have the following problem: Let $X_n$ be the maximum of a random sample $Y_1,...,Y_n$ from the density $f(x)=2(1-x), x\in [0,1]$ . Find constants $a_n,b_n$ so that $b_n(X_n-a_n)$ converges in distribution to a non-degenerate limit. I did the following: Calculate $F(x)=x(2-x), x\in [0,1]$ and find distribution of $X_n$ : $$ F_{X_n}(x) = \mathbb{P}[max{Y_i} \leq x] = \mathbb{P}[Y_1 \leq x,...,Y_n \leq x] = \mathbb{P}[Y_1 \leq x]^n = x^n(2-x)^n$$ So $$ \mathbb{P}[b_n(X_n-a_n) \leq x] = \mathbb{P}[X_n \leq \dfrac{x}{b_n}+a_n] = F_{X_n}(\dfrac{x}{b_n}+a_n)=(\dfrac{x}{b_n}+a_n)^n (2-\dfrac{x}{b_n}-a_n)^n$$ My intuition here is to use that $(1+\dfrac{x}{n})^n \rightarrow e^x$ and choose $a_n=1 , b_n=n$ In that case $$ \mathbb{P}[b_n(X_n-a_n) \leq x] \rightarrow e^xe^{-x}=1$$ However if I understand correctly a ""non-degenerate"" limit means that it should not be a constant. Can someone please correct me? What should $a_n,b_n$ be?","I have the following problem: Let be the maximum of a random sample from the density . Find constants so that converges in distribution to a non-degenerate limit. I did the following: Calculate and find distribution of : So My intuition here is to use that and choose In that case However if I understand correctly a ""non-degenerate"" limit means that it should not be a constant. Can someone please correct me? What should be?","X_n Y_1,...,Y_n f(x)=2(1-x), x\in [0,1] a_n,b_n b_n(X_n-a_n) F(x)=x(2-x), x\in [0,1] X_n  F_{X_n}(x) = \mathbb{P}[max{Y_i} \leq x] = \mathbb{P}[Y_1 \leq x,...,Y_n \leq x] = \mathbb{P}[Y_1 \leq x]^n = x^n(2-x)^n  \mathbb{P}[b_n(X_n-a_n) \leq x] = \mathbb{P}[X_n \leq \dfrac{x}{b_n}+a_n] = F_{X_n}(\dfrac{x}{b_n}+a_n)=(\dfrac{x}{b_n}+a_n)^n (2-\dfrac{x}{b_n}-a_n)^n (1+\dfrac{x}{n})^n \rightarrow e^x a_n=1 , b_n=n  \mathbb{P}[b_n(X_n-a_n) \leq x] \rightarrow e^xe^{-x}=1 a_n,b_n","['probability', 'statistics', 'probability-distributions', 'weak-convergence', 'extreme-value-theorem']"
36,Bernoulli Bootstrapping and the Beta Distribution,Bernoulli Bootstrapping and the Beta Distribution,,"My understanding of the bootstrap is that it gives us a method to understand the distribution of an estimator applied to a dataset. I've read statements of the form ""bootstrapping relies on the closeness of the empirical CDF for a sample of size $n$ to the true CDF"". But I wanted to understand the implication of using the bootstrap in a simple case. Suppose I have a dataset of $N$ Bernoulli trials, with $n$ successes. I want to have an understanding of my uncertainty in $p$ , the probability of success. My understanding is that the bayesian approach to this would give us a pdf for $p$ of $$ P(p|N, n) = \frac{p^{n+ \alpha -1} (1-p)^{N-n+\beta-1}}{B(n+ \alpha, N-n+\beta)} $$ Where $\alpha$ and $\beta$ define the prior. Naively, I guessed that maybe using the bootstrap on this type of data might give the same answer as a Haldane prior, of $\alpha=0, \ \beta=0$ , since if $n=N$ , both this and the bootstrap would require that $p=1$ . But when I wrote down what the bootstrap would predict for probabilities of $k$ successes, I get $$ P(p=k/N) = {N \choose k} (n/N)^{k} (1 - n/N)^{N-k} $$ This seems to take a totally different form than the Bayesian answer. How should I understand both of these approaches? Am I totally misunderstanding the interpretation of bootstrapping in this case? Is there some Bayesian prior secretly implied by the use of the bootstrap in this example?","My understanding of the bootstrap is that it gives us a method to understand the distribution of an estimator applied to a dataset. I've read statements of the form ""bootstrapping relies on the closeness of the empirical CDF for a sample of size to the true CDF"". But I wanted to understand the implication of using the bootstrap in a simple case. Suppose I have a dataset of Bernoulli trials, with successes. I want to have an understanding of my uncertainty in , the probability of success. My understanding is that the bayesian approach to this would give us a pdf for of Where and define the prior. Naively, I guessed that maybe using the bootstrap on this type of data might give the same answer as a Haldane prior, of , since if , both this and the bootstrap would require that . But when I wrote down what the bootstrap would predict for probabilities of successes, I get This seems to take a totally different form than the Bayesian answer. How should I understand both of these approaches? Am I totally misunderstanding the interpretation of bootstrapping in this case? Is there some Bayesian prior secretly implied by the use of the bootstrap in this example?","n N n p p 
P(p|N, n) = \frac{p^{n+ \alpha -1} (1-p)^{N-n+\beta-1}}{B(n+ \alpha, N-n+\beta)}
 \alpha \beta \alpha=0, \ \beta=0 n=N p=1 k 
P(p=k/N) = {N \choose k} (n/N)^{k} (1 - n/N)^{N-k}
","['probability', 'statistics', 'bayesian', 'bernoulli-distribution', 'bootstrap-sampling']"
37,Principal components of Vandermonde matrix,Principal components of Vandermonde matrix,,"Recall that the Vandermonde matrix of a collection $\{x_0,\ldots,x_m\}$ of points is $$ V = \begin{pmatrix} 1 & x_0 & x_0^2 & \cdots & x_0^n \\ 1 & x_1 & x_1^2 & \cdots & x_1^n \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 1 & x_m & x_m^2 & \cdots & x_m^n \end{pmatrix} $$ Take your points to be uniformly spread out over the interval $[-1, 1]$ , with step sizes $2/m$ . Now use SVD to extract the first $r$ principal components of $V$ . Numerical analysis suggests that the principal components stabilize as $m$ and $n$ tend to $\infty$ . Below I plot the case $r = 5$ , $m = 20\,000$ , $n = 1000$ to illustrate. Is there a name for these functions?","Recall that the Vandermonde matrix of a collection of points is Take your points to be uniformly spread out over the interval , with step sizes . Now use SVD to extract the first principal components of . Numerical analysis suggests that the principal components stabilize as and tend to . Below I plot the case , , to illustrate. Is there a name for these functions?","\{x_0,\ldots,x_m\}  V = \begin{pmatrix} 1 & x_0 & x_0^2 & \cdots & x_0^n \\
1 & x_1 & x_1^2 & \cdots & x_1^n \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_m & x_m^2 & \cdots & x_m^n \end{pmatrix}  [-1, 1] 2/m r V m n \infty r = 5 m = 20\,000 n = 1000","['calculus', 'linear-algebra', 'statistics', 'numerical-methods']"
38,Probability that a restaurant is better than another,Probability that a restaurant is better than another,,"Consider two restaurants $A$ and $B$ that both have a set of online reviews $S_A$ and $S_B$ , and each review can have an integer score from 1 to 5. What is the probability that a new review for $B$ , $r_B$ , will have a higher score than a new review for $A$ , $r_A$ ? I tried to solve this problem by considering the distribution of reviews for each restaurant, that is $$P(r_B > r_A) = \sum_{i=1}^{5}P(r_A = i)P(r_B > i)$$ Where $P(r_A = i)$ would be the fraction of $S_A$ that is equal to $i$ and $P(r_B > i)$ the fraction of $S_B$ that is bigger than $i$ . However, I've noticed that this is only useful if the number of reviews for both $A$ and $B$ is sufficiently big. That's because if $A$ had 1000 reviews and an average score of 4.8 and $B$ had 1 review with a score of 5, then $B$ , by the above equation, would be considered the best option, even though it has only 1 review. That means there is some uncertainty associated to the distribution of reviews. In this sense, how does one take this uncertainty into account?","Consider two restaurants and that both have a set of online reviews and , and each review can have an integer score from 1 to 5. What is the probability that a new review for , , will have a higher score than a new review for , ? I tried to solve this problem by considering the distribution of reviews for each restaurant, that is Where would be the fraction of that is equal to and the fraction of that is bigger than . However, I've noticed that this is only useful if the number of reviews for both and is sufficiently big. That's because if had 1000 reviews and an average score of 4.8 and had 1 review with a score of 5, then , by the above equation, would be considered the best option, even though it has only 1 review. That means there is some uncertainty associated to the distribution of reviews. In this sense, how does one take this uncertainty into account?",A B S_A S_B B r_B A r_A P(r_B > r_A) = \sum_{i=1}^{5}P(r_A = i)P(r_B > i) P(r_A = i) S_A i P(r_B > i) S_B i A B A B B,"['probability', 'statistics', 'probability-distributions', 'statistical-inference']"
39,Does $\hat{\theta} - \theta \overset{p}{\rightarrow} 0$ imply $\sqrt{n}(\hat{\theta} -\theta) \overset{p}{\rightarrow} 0$? Or vice versa?,Does  imply ? Or vice versa?,\hat{\theta} - \theta \overset{p}{\rightarrow} 0 \sqrt{n}(\hat{\theta} -\theta) \overset{p}{\rightarrow} 0,"Suppose I have a sample of $n$ observations, and $\hat{\theta}$ is an estimator for the parameter $\theta$ (which is a constant). From the following two convergence in probability statements: $\hat{\theta} - \theta \overset{p}{\rightarrow} 0$ $\sqrt{n}(\hat{\theta} -\theta) \overset{p}{\rightarrow} 0$ Does (1) imply (2)? The other way around? Or (1) $\Leftrightarrow$ (2)?","Suppose I have a sample of observations, and is an estimator for the parameter (which is a constant). From the following two convergence in probability statements: Does (1) imply (2)? The other way around? Or (1) (2)?",n \hat{\theta} \theta \hat{\theta} - \theta \overset{p}{\rightarrow} 0 \sqrt{n}(\hat{\theta} -\theta) \overset{p}{\rightarrow} 0 \Leftrightarrow,"['probability', 'statistics']"
40,"Derive the uniformly most powerful test of size $\alpha=0.05$ for $H_0: \mu\le \lambda$, v.s. $H_1: \mu>\lambda$","Derive the uniformly most powerful test of size  for , v.s.",\alpha=0.05 H_0: \mu\le \lambda H_1: \mu>\lambda,"Let $X$ and $Y$ be independent uniform random variables on $[\lambda, \lambda+1]$ and $[\mu, \mu+1] $ respectively. The problem of testing $H_0: \mu\le \lambda$ , v.s. $H_1: \mu>\lambda$ is invariant under location change $g(X, Y)=(X+c, Y+c)$ , $c \in R$ . Derive the uniformly most powerful test of size $\alpha=0.05$ . My idea is to use the Neyman-Pearson Lemma. The likelihood ratio test is based on the ratio of the likelihoods under the two hypotheses: $$ \Lambda=\frac{L_0(x, y)}{ L_1(x, y)}=\frac{I[\lambda<x<\lambda +1]I[\mu <y <\mu+1]}{?} $$ I am confused about the ratio. And how to proceed the next step? It seems that we need to find $$ \Lambda>k $$","Let and be independent uniform random variables on and respectively. The problem of testing , v.s. is invariant under location change , . Derive the uniformly most powerful test of size . My idea is to use the Neyman-Pearson Lemma. The likelihood ratio test is based on the ratio of the likelihoods under the two hypotheses: I am confused about the ratio. And how to proceed the next step? It seems that we need to find","X Y [\lambda, \lambda+1] [\mu, \mu+1]  H_0: \mu\le \lambda H_1: \mu>\lambda g(X, Y)=(X+c, Y+c) c \in R \alpha=0.05 
\Lambda=\frac{L_0(x, y)}{ L_1(x, y)}=\frac{I[\lambda<x<\lambda +1]I[\mu <y <\mu+1]}{?}
 
\Lambda>k
","['probability', 'statistics', 'probability-distributions', 'hypothesis-testing']"
41,How long before someone is ahead by 10 in a game of flipping a coin?,How long before someone is ahead by 10 in a game of flipping a coin?,,"If me and a friend are playing a game and start with 10 marbles each. We flip a coin each round and each time it's a head he gives me a marble and each time it's tails I give him one. How many coin flips do we have to do on average before someone has all the marbles? I tried to do the average by 10 * (1/2) ^10 + (11C1) * (1/2)^11 .... up to infinity by multiplying the probability of each time getting 10 more heads than my opponent gets tails. This doesn't make sense to me though: the answer seemed way off, and also the game wouldn't actually be able to end on 11 flips because it is an odd number. It also doesn't seem to consider the fact the game could end on an earlier round. Any help with this question is much appreciated.","If me and a friend are playing a game and start with 10 marbles each. We flip a coin each round and each time it's a head he gives me a marble and each time it's tails I give him one. How many coin flips do we have to do on average before someone has all the marbles? I tried to do the average by 10 * (1/2) ^10 + (11C1) * (1/2)^11 .... up to infinity by multiplying the probability of each time getting 10 more heads than my opponent gets tails. This doesn't make sense to me though: the answer seemed way off, and also the game wouldn't actually be able to end on 11 flips because it is an odd number. It also doesn't seem to consider the fact the game could end on an earlier round. Any help with this question is much appreciated.",,"['probability', 'sequences-and-series', 'statistics', 'factorial', 'word-problem']"
42,Smallest value of $d$ such that $\frac{\left(\sum_{i=1}^d i^{-p}\right)^2}{\sum_{i=1}^d i^{-2p}}\ge \frac{1}{2}\frac{\zeta(p)^2}{\zeta(2p)}$,Smallest value of  such that,d \frac{\left(\sum_{i=1}^d i^{-p}\right)^2}{\sum_{i=1}^d i^{-2p}}\ge \frac{1}{2}\frac{\zeta(p)^2}{\zeta(2p)},"I'm looking for $d^*$ , the smallest value of $d$ such that the following holds: $$\frac{\left(\sum_{i=1}^d i^{-p}\right)^2}{\sum_{i=1}^d i^{-2p}}\ge \frac{1}{2}\frac{\zeta(p)^2}{\zeta(2p)}$$ with $\zeta$ referring to Riemann Zeta function . Empirically this seems to scale as the function below, why? $$d^*\approx c_1 \exp\left(\frac{c_2}{p-1}\right)$$ Notebook Edit Mathematica user found a way to express $c_1$ and $c_2$ in terms of Euler gamma constant and $\sqrt{2}$ Motivation: $\frac{\zeta(p)^2}{\zeta(2p)}$ gives ""effective rank"" of infinite-dimensional linear regression problem with eigenvalues $1^{-p},2^{-p},\ldots$ (ie, how many observations are needed for prediction). This question gives $d$ such that finite-dimensional truncation after $d$ terms has similar effective rank.","I'm looking for , the smallest value of such that the following holds: with referring to Riemann Zeta function . Empirically this seems to scale as the function below, why? Notebook Edit Mathematica user found a way to express and in terms of Euler gamma constant and Motivation: gives ""effective rank"" of infinite-dimensional linear regression problem with eigenvalues (ie, how many observations are needed for prediction). This question gives such that finite-dimensional truncation after terms has similar effective rank.","d^* d \frac{\left(\sum_{i=1}^d i^{-p}\right)^2}{\sum_{i=1}^d i^{-2p}}\ge \frac{1}{2}\frac{\zeta(p)^2}{\zeta(2p)} \zeta d^*\approx c_1 \exp\left(\frac{c_2}{p-1}\right) c_1 c_2 \sqrt{2} \frac{\zeta(p)^2}{\zeta(2p)} 1^{-p},2^{-p},\ldots d d","['real-analysis', 'sequences-and-series', 'statistics', 'riemann-zeta']"
43,Determining the marginal distribution for a markov chain,Determining the marginal distribution for a markov chain,,"Let ${X_n : n = 0, 1, 2, . . .}$ denote a Markov chain with the states $S = {1, 2, 3}$ and transition matrix P given by $$ \begin{bmatrix} 0 & 0.5 & 0.5 \\ 0.1 & 0 & 0.9 \\ 0.8 & 0.2 & 0 \end{bmatrix} $$ Determine whether the Markov chain has a marginal distribution. Determine the it and explain how you found it. Also determine whether the boundary distribution is unique. So i know that an irreducible and aperiodic markov chain has a unique solution, which also is the limiting distribution. In this case, the stationary distribution is a limiting distribution. To find the stationary distribution i need to solve the following: \begin{align*}     \pi_1 &= \frac{1}{2}\pi_2 + \frac{1}{2}\pi_3   \\     \pi_2 &= \frac{1}{10}\pi_1 + \frac{9}{10}\pi_3 \\     \pi_3 &= \frac{8}{10}\pi_1 + \frac{2}{10}\pi_2 \\     1 &= \pi_1 + \pi_2 + \pi_3 \end{align*} I have solved it and got that $\pi_1 = \frac{1}{3}$ , $\pi_2 = \frac{1}{3}$ and $\pi_3 = \frac{1}{3}$ Now that i have found my stationary distribution, which is also the limiting distribution what do i do with it? Is my limiting distribution the marginal distribution? I know that the desired marginal distribution that i need to find is $(0.35, 0.25, 0.4)$ but i can't manage to get this.","Let denote a Markov chain with the states and transition matrix P given by Determine whether the Markov chain has a marginal distribution. Determine the it and explain how you found it. Also determine whether the boundary distribution is unique. So i know that an irreducible and aperiodic markov chain has a unique solution, which also is the limiting distribution. In this case, the stationary distribution is a limiting distribution. To find the stationary distribution i need to solve the following: I have solved it and got that , and Now that i have found my stationary distribution, which is also the limiting distribution what do i do with it? Is my limiting distribution the marginal distribution? I know that the desired marginal distribution that i need to find is but i can't manage to get this.","{X_n : n = 0, 1, 2, . . .} S = {1, 2, 3} 
\begin{bmatrix}
0 & 0.5 & 0.5 \\
0.1 & 0 & 0.9 \\
0.8 & 0.2 & 0
\end{bmatrix}
 \begin{align*}
    \pi_1 &= \frac{1}{2}\pi_2 + \frac{1}{2}\pi_3   \\
    \pi_2 &= \frac{1}{10}\pi_1 + \frac{9}{10}\pi_3 \\
    \pi_3 &= \frac{8}{10}\pi_1 + \frac{2}{10}\pi_2 \\
    1 &= \pi_1 + \pi_2 + \pi_3
\end{align*} \pi_1 = \frac{1}{3} \pi_2 = \frac{1}{3} \pi_3 = \frac{1}{3} (0.35, 0.25, 0.4)","['probability', 'statistics', 'probability-distributions', 'markov-chains', 'marginal-distribution']"
44,the nature of conditional probability,the nature of conditional probability,,"I'm reading Jeffrey's ""Subjective Probability"" and was intrigued by the following passage: ""The quotient rule is often called the definition of conditional probability. It is not. If it were, we could never be in the position we are often in, of making a conditional judgment--say, about how a coin that may or may not be tossed will land--without attributing some particular positive value to the condition that $pr$ (head|tossed) = 1/2 even though $\frac{pr(\text{head} \ \land \ \text{tossed})}{pr(\text{tossed})} = \frac{\textit{undefined}}{\textit{undefined}}$ . [...] The quotient rule merely restates the product rule; and the product rule is no definition but an essential principle relating two distinct sorts of probability."" (Jeffrey 2004, p.14) The product rule is this: $pr(H \ \land D) = pr(H|D) pr(D)$ The quotient rule is this: $pr(H|D) = \frac{pr(H \ \land \ D)}{pr(D)}$ , provided $pr(D) > 0$ . $pr(H|D)$ of course means the conditional probability of $H$ given $D$ . Further useful information is that Jeffrey uses a Dutch book argument to motivate the product rule (as he also does in motivating the special disjunction axiom). So, what is he saying: Is the product rule a further axiom of the probability calculus? If not, how is it a theorem? I got confused multiple times in people defining conditional probability out of the blue, not seeing how its definition is implicit in the axioms. In short, what does Jeffrey mean when he says that the product rule is an ""essential principle""? How exactly does it relate to the axioms?","I'm reading Jeffrey's ""Subjective Probability"" and was intrigued by the following passage: ""The quotient rule is often called the definition of conditional probability. It is not. If it were, we could never be in the position we are often in, of making a conditional judgment--say, about how a coin that may or may not be tossed will land--without attributing some particular positive value to the condition that (head|tossed) = 1/2 even though . [...] The quotient rule merely restates the product rule; and the product rule is no definition but an essential principle relating two distinct sorts of probability."" (Jeffrey 2004, p.14) The product rule is this: The quotient rule is this: , provided . of course means the conditional probability of given . Further useful information is that Jeffrey uses a Dutch book argument to motivate the product rule (as he also does in motivating the special disjunction axiom). So, what is he saying: Is the product rule a further axiom of the probability calculus? If not, how is it a theorem? I got confused multiple times in people defining conditional probability out of the blue, not seeing how its definition is implicit in the axioms. In short, what does Jeffrey mean when he says that the product rule is an ""essential principle""? How exactly does it relate to the axioms?",pr \frac{pr(\text{head} \ \land \ \text{tossed})}{pr(\text{tossed})} = \frac{\textit{undefined}}{\textit{undefined}} pr(H \ \land D) = pr(H|D) pr(D) pr(H|D) = \frac{pr(H \ \land \ D)}{pr(D)} pr(D) > 0 pr(H|D) H D,"['probability', 'statistics', 'conditional-probability', 'bayesian']"
45,Distribution of a sum of first and last order statistics,Distribution of a sum of first and last order statistics,,"I can't find anywhere on the internet a solution to the following exercise: Let $X = (X_1, \dots, X_n)$ be a sequence of i.i.d random variables from exponential distribution. Find the distribution of statistic $T = \frac{1}{2}(X_{(1)} + X_{(n)})$ where $X_{(1)}, X_{(n)}$ are first and last order statistics. Preparation : $$f_{X_i}(x_i) = \lambda e^{-\lambda x_i}\mathbb{1}_{(0,\infty)}(x_i)$$ $$F_{X_i}(x_i) = 1-e^{-\lambda x_i}$$ I know the general formula for the density function of vector $X_{(r)},X_{(s)}$ which is $$f_{X_{(r)},X_{(s)}}(u,v) = \frac{n!}{(r-1)!(s-r-1)!(n-s)!}F(u)^{r-1}f(u)(F(v)-F(u))^{s-r-1}f(v)(1-F(v))^{n-s}$$ So by using this formula for $X_{(1)}, X_{(n)}$ I have: $$f_{X_{(1)}, X_{(n)}}(x,y) = (n-1)n\lambda^2e^{-\lambda(x+y)}(e^{-\lambda x}-e^{-\lambda y})^{n-2}\mathbb{1}_{(0,\infty)}(x)\mathbb{1}_{(0,\infty)}(y)\mathbb{1}(x \leq y)$$ First approach : Here is the area of integration $$F_T(t) = P(T \leq t) = P(\frac{1}{2}X_{(1)} + \frac{1}{2}X_{(n)} \leq t) = P(X_{(n)} \leq -X_{(1)}+2t) = \iint_A f_{X_{(1)}, X_{(n)}}(x,y) \,dx\,dy = \\ =\int_{0}^{t}\int_{x}^{-x+2t} (n-1)n\lambda^2e^{-\lambda(x+y)}(e^{-\lambda x}-e^{-\lambda y})^{n-2} \,dy\,dx = \\ =(n-1)n\lambda^2\int_{0}^{t} e^{-\lambda x}\int_{x}^{-x+2t}e^{-\lambda y}(e^{-\lambda x}-e^{-\lambda y})^{n-2} \,dy\,dx$$ I don't know how to calculate this integral. Second approach : Here is the area of integration $$F_T(t) = P(T \leq t) = P(\frac{1}{2}X_{(1)} + \frac{1}{2}X_{(n)} \leq t) = \iint_B f_{X_{(1)}, X_{(n)}}(x,y) \,dx\,dy = \dots$$ Now using substitution: $u = x, v= \frac{1}{2}(x+y)$ so $x = u, y = 2v-u, |J| = \begin{bmatrix} 1 & 0\\ -1 & 2 \end{bmatrix} = 2$ $$\dots = \int_{-\infty}^{\infty}\int_{-\infty}^{t} 2f_{X_{(1)}, X_{(n)}}(u,v-u) \,dv\,du = \int_{-\infty}^{t}\int_{-\infty}^{\infty} 2f_{X_{(1)}, X_{(n)}}(u,v-u) \,du\,dv$$ So that means: $$f_T(v) = \int_{-\infty}^{\infty} 2f_{X_{(1)}, X_{(n)}}(u,v-u) \,du = \\ =\int_{-\infty}^{\infty} 2(n-1)n\lambda^2e^{-\lambda(u+2v-u)}(e^{-\lambda u}-e^{-\lambda (2v-u)})^{n-2}\mathbb{1}_{(0,\infty)}(u)\mathbb{1}_{(0,\infty)}(2v-u)\mathbb{1}(u \leq 2v-u)\,du =\\ = 2(n-1)n\lambda^2 e^{-2\lambda v} \int_{0}^{\infty}(e^{-\lambda u}-e^{-\lambda (2v-u)})^{n-2}\,du $$ Again similar integral. Third approach: Chat GPT gave me the following solution :) $X_{(1)}=\min(X_1,\dots,X_n), X_{(n)}=\max(X_1,\ldots,X_n)$ - I agree with this so far. $$F_T(t) = P(T \leq t) = P(\frac{1}{2}X_{(1)} + \frac{1}{2}X_{(n)} \leq t) = P(X_{(1)} \leq -X_{(n)}+2t) = \\ =1 - P(X_{(1)} > 2t - X_{(n)}) = \\ =1 - P(X_1>2t-X_n, X_2>2t-X_n, \dots, X_{n-1}>2t-X_n, X_n>2t-X_n)=\\ = 1 - \prod_{i=1}^{n}P(X_i>2t-X_n) = 1-[1-F_{X_i}(2t-X_n)]^n= 1-[1-\int_{2t}^{\infty} \lambda e^{\lambda(2t-x)}\,dx]^n = \\ = 1- [e^{-\lambda t}]^n = 1-e^{-n \lambda t}$$ $$f_T(t) = \frac{d}{dt}(1-F_T(t)) = \frac{d}{dt}(e^{-n\lambda t}) = n\lambda e^{-n \lambda t}$$ I do not understand why from $X_{(1)}>2t-X_{(n)}$ we go suddenly to $X_1>2t-X_n, \dots, X_n>2t-X_n$ Summary: My questions are: If my first and second approach is correct, how to solve integrals at the end? Is chat gpt correct? If none of this approaches are correct then I would be grateful for solution.","I can't find anywhere on the internet a solution to the following exercise: Let be a sequence of i.i.d random variables from exponential distribution. Find the distribution of statistic where are first and last order statistics. Preparation : I know the general formula for the density function of vector which is So by using this formula for I have: First approach : Here is the area of integration I don't know how to calculate this integral. Second approach : Here is the area of integration Now using substitution: so So that means: Again similar integral. Third approach: Chat GPT gave me the following solution :) - I agree with this so far. I do not understand why from we go suddenly to Summary: My questions are: If my first and second approach is correct, how to solve integrals at the end? Is chat gpt correct? If none of this approaches are correct then I would be grateful for solution.","X = (X_1, \dots, X_n) T = \frac{1}{2}(X_{(1)} + X_{(n)}) X_{(1)}, X_{(n)} f_{X_i}(x_i) = \lambda e^{-\lambda x_i}\mathbb{1}_{(0,\infty)}(x_i) F_{X_i}(x_i) = 1-e^{-\lambda x_i} X_{(r)},X_{(s)} f_{X_{(r)},X_{(s)}}(u,v) = \frac{n!}{(r-1)!(s-r-1)!(n-s)!}F(u)^{r-1}f(u)(F(v)-F(u))^{s-r-1}f(v)(1-F(v))^{n-s} X_{(1)}, X_{(n)} f_{X_{(1)}, X_{(n)}}(x,y) = (n-1)n\lambda^2e^{-\lambda(x+y)}(e^{-\lambda x}-e^{-\lambda y})^{n-2}\mathbb{1}_{(0,\infty)}(x)\mathbb{1}_{(0,\infty)}(y)\mathbb{1}(x \leq y) F_T(t) = P(T \leq t) = P(\frac{1}{2}X_{(1)} + \frac{1}{2}X_{(n)} \leq t) = P(X_{(n)} \leq -X_{(1)}+2t) = \iint_A f_{X_{(1)}, X_{(n)}}(x,y) \,dx\,dy = \\
=\int_{0}^{t}\int_{x}^{-x+2t} (n-1)n\lambda^2e^{-\lambda(x+y)}(e^{-\lambda x}-e^{-\lambda y})^{n-2} \,dy\,dx = \\
=(n-1)n\lambda^2\int_{0}^{t} e^{-\lambda x}\int_{x}^{-x+2t}e^{-\lambda y}(e^{-\lambda x}-e^{-\lambda y})^{n-2} \,dy\,dx F_T(t) = P(T \leq t) = P(\frac{1}{2}X_{(1)} + \frac{1}{2}X_{(n)} \leq t) = \iint_B f_{X_{(1)}, X_{(n)}}(x,y) \,dx\,dy = \dots u = x, v= \frac{1}{2}(x+y) x = u, y = 2v-u, |J| = \begin{bmatrix} 1 & 0\\ -1 & 2 \end{bmatrix} = 2 \dots = \int_{-\infty}^{\infty}\int_{-\infty}^{t} 2f_{X_{(1)}, X_{(n)}}(u,v-u) \,dv\,du = \int_{-\infty}^{t}\int_{-\infty}^{\infty} 2f_{X_{(1)}, X_{(n)}}(u,v-u) \,du\,dv f_T(v) = \int_{-\infty}^{\infty} 2f_{X_{(1)}, X_{(n)}}(u,v-u) \,du = \\
=\int_{-\infty}^{\infty} 2(n-1)n\lambda^2e^{-\lambda(u+2v-u)}(e^{-\lambda u}-e^{-\lambda (2v-u)})^{n-2}\mathbb{1}_{(0,\infty)}(u)\mathbb{1}_{(0,\infty)}(2v-u)\mathbb{1}(u \leq 2v-u)\,du =\\
= 2(n-1)n\lambda^2 e^{-2\lambda v} \int_{0}^{\infty}(e^{-\lambda u}-e^{-\lambda (2v-u)})^{n-2}\,du  X_{(1)}=\min(X_1,\dots,X_n), X_{(n)}=\max(X_1,\ldots,X_n) F_T(t) = P(T \leq t) = P(\frac{1}{2}X_{(1)} + \frac{1}{2}X_{(n)} \leq t) = P(X_{(1)} \leq -X_{(n)}+2t) = \\
=1 - P(X_{(1)} > 2t - X_{(n)}) = \\
=1 - P(X_1>2t-X_n, X_2>2t-X_n, \dots, X_{n-1}>2t-X_n, X_n>2t-X_n)=\\
= 1 - \prod_{i=1}^{n}P(X_i>2t-X_n) = 1-[1-F_{X_i}(2t-X_n)]^n= 1-[1-\int_{2t}^{\infty} \lambda e^{\lambda(2t-x)}\,dx]^n = \\
= 1- [e^{-\lambda t}]^n = 1-e^{-n \lambda t} f_T(t) = \frac{d}{dt}(1-F_T(t)) = \frac{d}{dt}(e^{-n\lambda t}) = n\lambda e^{-n \lambda t} X_{(1)}>2t-X_{(n)} X_1>2t-X_n, \dots, X_n>2t-X_n","['probability', 'integration', 'statistics', 'probability-distributions', 'order-statistics']"
46,Why doesn't the sample variance become the population variance when the sample has the whole population,Why doesn't the sample variance become the population variance when the sample has the whole population,,"We know that for a sample of size $n$ the sample variance is $\displaystyle S^{2} = \frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\overline{X})^{2}$ Suppose I used the whole population of size $N$ as my sample then in this case the variance I compute is $\displaystyle S^{2} = \frac{1}{N-1}\sum_{i=1}^{N}(X_{i}-\mu)^{2}$ where $\mu=\frac{\sum_{i=1}^{N}X_i}{N}$ However, the population variance is $\displaystyle \sigma^{2} = \frac{1}{N}\sum_{i=1}^{N}(X_{i}-\mu)^{2}$ where $\mu=\frac{\sum_{i=1}^{N}X_i}{N}$ and this is counterintuitive. One would think that by using the unbiased estimator of the sample variance, convergence when the whole population is considered is guaranteed as the variance of an estimator approaches $0$ as $N \rightarrow \infty$","We know that for a sample of size the sample variance is Suppose I used the whole population of size as my sample then in this case the variance I compute is where However, the population variance is where and this is counterintuitive. One would think that by using the unbiased estimator of the sample variance, convergence when the whole population is considered is guaranteed as the variance of an estimator approaches as",n \displaystyle S^{2} = \frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\overline{X})^{2} N \displaystyle S^{2} = \frac{1}{N-1}\sum_{i=1}^{N}(X_{i}-\mu)^{2} \mu=\frac{\sum_{i=1}^{N}X_i}{N} \displaystyle \sigma^{2} = \frac{1}{N}\sum_{i=1}^{N}(X_{i}-\mu)^{2} \mu=\frac{\sum_{i=1}^{N}X_i}{N} 0 N \rightarrow \infty,"['statistics', 'variance']"
47,"Calculate $\mathbb{E}[N(X)]$, where $N(·)$ is the cdf of the standard normal distribution, and $X$ is a standard normal random variable.","Calculate , where  is the cdf of the standard normal distribution, and  is a standard normal random variable.",\mathbb{E}[N(X)] N(·) X,"I'm stuck with this problem: Calculate $\mathbb{E}[N(X)]$ , where N(·) is the cdf of the standard normal distribution, and X is a standard normal random variable. Here's where I'm stuck: We know that: $$\mathbb{E}[g(X)]=\int_{-\infty }^{\infty}g(x)f_{X}(x)dx$$ And we are given that: $$ g(x) = N(x) = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{x}e^{-\frac{u^2}{2}}du $$ $$ f_{X}(x)=\frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}} $$ So, the solution should be to develop this: $$\begin{split} \mathbb{E}[N(X)] &= \int_{-\infty }^{\infty} \left( \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{x}e^{-\frac{u^2}{2}}du \right) \left( \frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}} \right) dx\\ &= \frac{1}{2 \pi} \int_{-\infty }^{\infty} \left( \int_{-\infty}^{x}e^{-\frac{u^2}{2}}du \right) e^{-\frac{x^2}{2}} dx\\ &= \frac{1}{2 \pi} \int_{-\infty }^{\infty} \int_{-\infty}^{x} e^{-\frac{u^2+x^2}{2}}dudx \end{split}$$ My questions are: Can we combine the exponents moving the term with x inside, the last step above? If yes, this looks like a good opportunity to change variables to polar. If that's the case, how to change the limits of the integrals from $x$ and $u$ to $r$ and $\theta$ ? Any help would be extremely appreciated! Thanks!","I'm stuck with this problem: Calculate , where N(·) is the cdf of the standard normal distribution, and X is a standard normal random variable. Here's where I'm stuck: We know that: And we are given that: So, the solution should be to develop this: My questions are: Can we combine the exponents moving the term with x inside, the last step above? If yes, this looks like a good opportunity to change variables to polar. If that's the case, how to change the limits of the integrals from and to and ? Any help would be extremely appreciated! Thanks!","\mathbb{E}[N(X)] \mathbb{E}[g(X)]=\int_{-\infty }^{\infty}g(x)f_{X}(x)dx  g(x) = N(x) = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{x}e^{-\frac{u^2}{2}}du   f_{X}(x)=\frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}}  \begin{split}
\mathbb{E}[N(X)] &= \int_{-\infty }^{\infty} \left( \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{x}e^{-\frac{u^2}{2}}du \right) \left( \frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}} \right) dx\\
&= \frac{1}{2 \pi} \int_{-\infty }^{\infty} \left( \int_{-\infty}^{x}e^{-\frac{u^2}{2}}du \right) e^{-\frac{x^2}{2}} dx\\
&= \frac{1}{2 \pi} \int_{-\infty }^{\infty} \int_{-\infty}^{x} e^{-\frac{u^2+x^2}{2}}dudx
\end{split} x u r \theta","['probability', 'statistics']"
48,"Can we show that for every $\delta>0$, there exist constants $\alpha>0, \beta>0$ so that the following inequality holds with high probability?","Can we show that for every , there exist constants  so that the following inequality holds with high probability?","\delta>0 \alpha>0, \beta>0","Consider two $n-$ dimensional random vectors $u$ and $v$ uniformly distributed on the sphere. Define $X_n :=u\cdot v$ . Note that as $n\to \infty$ , $\sqrt{n}X_n \to N(0,1)$ as $n\to \infty$ . Fix $\epsilon>0$ (very small). Can we show that for every $\delta>0$ , there exist constants $\alpha>0, \beta>0$ so that $$ \lim_{n\to \infty}P\left(\frac{X_n^{-2}-1}{\epsilon^{-2}-1}<\alpha n^\beta\right)\ge 1-\delta. $$ Or can we revise this upper bound for $\frac{X_n^{-2}-1}{\epsilon^{-2}-1}$ depending on $n$ . Since we know that the order $X_n=O_p(n^{-1/2})$ , then the order of $\frac{X_n^{-2}-1}{\epsilon^{-2}-1}$ is about $O_p(n)$ . But I am stuck on how get the strict upper bound. (Maybe this question would be helpful: Can we find $C>1$ so that $ P(|X|\le \frac{\epsilon}{C})\ge 1-\delta $? ) Let $Y\sim N(0,1)$ (hence we can write $X_n=n^{-1/2}Y$ . Note that $$\begin{align*} \lim_{n\to \infty}P\left(\frac{X_n^{-2}-1}{\epsilon^{-2}-1}<\alpha n^\beta\right)&=P\left(n\frac{Y^{-2}-1}{\epsilon^{-2}-1}<\alpha n^\beta\right)\\&=P\left(nY^{-2}<\alpha(\epsilon^{-2}-1)n^{\beta}+1\right)\\&=P\left(Y^2>\frac{n}{\alpha(\epsilon^{-2}-1)n^{\beta}+1}\right)\end{align*} $$ I am not sure if we can apply the concentration result of the Gaussian variable to find proper $\alpha, \beta>0$ so that this probability larger than $1-\delta$ .","Consider two dimensional random vectors and uniformly distributed on the sphere. Define . Note that as , as . Fix (very small). Can we show that for every , there exist constants so that Or can we revise this upper bound for depending on . Since we know that the order , then the order of is about . But I am stuck on how get the strict upper bound. (Maybe this question would be helpful: Can we find $C>1$ so that $ P(|X|\le \frac{\epsilon}{C})\ge 1-\delta $? ) Let (hence we can write . Note that I am not sure if we can apply the concentration result of the Gaussian variable to find proper so that this probability larger than .","n- u v X_n :=u\cdot v n\to \infty \sqrt{n}X_n \to N(0,1) n\to \infty \epsilon>0 \delta>0 \alpha>0, \beta>0 
\lim_{n\to \infty}P\left(\frac{X_n^{-2}-1}{\epsilon^{-2}-1}<\alpha n^\beta\right)\ge 1-\delta.
 \frac{X_n^{-2}-1}{\epsilon^{-2}-1} n X_n=O_p(n^{-1/2}) \frac{X_n^{-2}-1}{\epsilon^{-2}-1} O_p(n) Y\sim N(0,1) X_n=n^{-1/2}Y \begin{align*}
\lim_{n\to \infty}P\left(\frac{X_n^{-2}-1}{\epsilon^{-2}-1}<\alpha n^\beta\right)&=P\left(n\frac{Y^{-2}-1}{\epsilon^{-2}-1}<\alpha n^\beta\right)\\&=P\left(nY^{-2}<\alpha(\epsilon^{-2}-1)n^{\beta}+1\right)\\&=P\left(Y^2>\frac{n}{\alpha(\epsilon^{-2}-1)n^{\beta}+1}\right)\end{align*}
 \alpha, \beta>0 1-\delta","['real-analysis', 'probability', 'statistics', 'inequality']"
49,Find the average value of the average value of the image of a random finite set.,Find the average value of the average value of the image of a random finite set.,,"Context: This is part of an absurd thought experiment in which an immortal, telekinetic rat tries to push a blinking button from a variable distance while piloting a spacecraft blindfolded at relativistic speeds. I need to calculate what the rat most likely believes is the probability that the button is lit. This is my attempt to do that. Fix $\omega\in\Bbb R$ , and let $L:\Bbb R\to\Bbb R$ be given by $$L(t)=\lfloor\sin(\omega t)+1\rfloor$$ $\color{lightgray}{\text{[This is the signal controlling the light]}}$ For each $n\in\Bbb N$ , let $[\Bbb R]^n=\{S\subseteq\Bbb R:|S|=n\}$ . Let $[\Bbb R]^{<\Bbb N}=\bigcup_{n\in\Bbb N}[\Bbb R]^n$ , and define $A:[\Bbb R]^{<\Bbb N}\to\Bbb R$ according to $$\begin{align} A(T)&=\frac1{|T|}\sum_{t\in T}\lfloor\sin(\omega t)+1\rfloor\\ &=\frac1{|T|}\sum_{t\in T}L(t) \end{align}$$ That is, $A(T)$ is the average value of the image of $T$ under $L$ . $\color{lightgray}{\text{[Each finite subset of $\Bbb R$ corresponds to a possible set of times (as measured from the button)}\\ {\text{when information about the state of the button reaches the rat. Due to time dilation and}\\ \text{unpredictable movement (a result of the blindfold), we can assume nothing about the likelihood}\\ \text{of a given set.]}}}$ Questions: How is the average value of $A$ defined? What is the average value of $A$ ? It seems extremely obvious that the answer should be $1/2$ . Realistically, a large enough uniform random sampling of a sufficiently large interval $[a,b]$ will almost always land you with a value of $1/2$ ; but I don't know how to show that the average average is actually $1/2$ , and that the apparent tendency towards this value isn't a miraculous coincidence. Intuitively, I'd think that we'd want to take some kind limit-integral like $$\overline A=\lim_{R\to[\Bbb R]^{<\Bbb N}}\mu(R)^{-1}\int_R A(T)\ dT$$ Given $|[\Bbb R]^{<\Bbb N}|=|\Bbb R|$ (obviously true), there must be some bijection $C:\Bbb R\to[\Bbb R]^{<\Bbb N}$ . Assuming that we can define $C$ in a nice way, we could reasonably assert $$\lim_{R\to[\Bbb R]^{<\Bbb N}}\mu(R)^{-1}\int_R A(T)\ dT=\lim_{a\to-\infty}\lim_{b\to\infty}\frac1{b-a}\int_a^b A(C(t))\ dt$$ but 1) this requires $A\circ C:\Bbb R\to\Bbb R$ to be continuous, which I'm not sure is even possible (and I don't know how to prove it either way), 2) there may not be a nice way to define $C$ even if such a continuous function does exist.","Context: This is part of an absurd thought experiment in which an immortal, telekinetic rat tries to push a blinking button from a variable distance while piloting a spacecraft blindfolded at relativistic speeds. I need to calculate what the rat most likely believes is the probability that the button is lit. This is my attempt to do that. Fix , and let be given by For each , let . Let , and define according to That is, is the average value of the image of under . Questions: How is the average value of defined? What is the average value of ? It seems extremely obvious that the answer should be . Realistically, a large enough uniform random sampling of a sufficiently large interval will almost always land you with a value of ; but I don't know how to show that the average average is actually , and that the apparent tendency towards this value isn't a miraculous coincidence. Intuitively, I'd think that we'd want to take some kind limit-integral like Given (obviously true), there must be some bijection . Assuming that we can define in a nice way, we could reasonably assert but 1) this requires to be continuous, which I'm not sure is even possible (and I don't know how to prove it either way), 2) there may not be a nice way to define even if such a continuous function does exist.","\omega\in\Bbb R L:\Bbb R\to\Bbb R L(t)=\lfloor\sin(\omega t)+1\rfloor \color{lightgray}{\text{[This is the signal controlling the light]}} n\in\Bbb N [\Bbb R]^n=\{S\subseteq\Bbb R:|S|=n\} [\Bbb R]^{<\Bbb N}=\bigcup_{n\in\Bbb N}[\Bbb R]^n A:[\Bbb R]^{<\Bbb N}\to\Bbb R \begin{align}
A(T)&=\frac1{|T|}\sum_{t\in T}\lfloor\sin(\omega t)+1\rfloor\\
&=\frac1{|T|}\sum_{t\in T}L(t)
\end{align} A(T) T L \color{lightgray}{\text{[Each finite subset of \Bbb R corresponds to a possible set of times (as measured from the button)}\\
{\text{when information about the state of the button reaches the rat. Due to time dilation and}\\
\text{unpredictable movement (a result of the blindfold), we can assume nothing about the likelihood}\\
\text{of a given set.]}}} A A 1/2 [a,b] 1/2 1/2 \overline A=\lim_{R\to[\Bbb R]^{<\Bbb N}}\mu(R)^{-1}\int_R A(T)\ dT |[\Bbb R]^{<\Bbb N}|=|\Bbb R| C:\Bbb R\to[\Bbb R]^{<\Bbb N} C \lim_{R\to[\Bbb R]^{<\Bbb N}}\mu(R)^{-1}\int_R A(T)\ dT=\lim_{a\to-\infty}\lim_{b\to\infty}\frac1{b-a}\int_a^b A(C(t))\ dt A\circ C:\Bbb R\to\Bbb R C","['real-analysis', 'statistics', 'average']"
50,Fisher information of poisson distributed random variable,Fisher information of poisson distributed random variable,,"Let's consider a printer queue. We know that the expected number of printer jobs almost obeys a Poisson distribution, so $P_{\vartheta}(X=k)=e^{-\vartheta}\frac{\vartheta^k}{k!}$ , where $\vartheta\in]0,\infty[$ . We estimate the expected number of printer jobs $\vartheta$ by $\frac{1}{n}\sum\limits_{i=1}^nX_i$ . Compute the Fisher information $I(\vartheta):=\mathbb{E}_{\vartheta}\left(\left(\frac{d\ln(P_{\vartheta}(X))}{d\vartheta}\right)^2\right)$ . We know that if $(X_1,\dots,X_n)$ are independent random variables with a distribution like $P_X(\vartheta)=f(X_1,\vartheta)\dots f(X_n,\vartheta)$ , then $$\mathbb{E}_{\vartheta}\left(\left(\frac{d\ln(P_{\vartheta}(X))}{d\vartheta}\right)^2\right)=n\cdot \mathbb{E}_{\vartheta}\left(\left(\frac{d\ln(P_{\vartheta}(X_i))}{d\vartheta}\right)^2\right).$$ If we consider the $n$ -many independent observations $X:=(X_1,\dots,X_n)$ , where each $X_i$ is the number of printer jobs in a certain period of time, the probability is given by \begin{align*}  &P_{\vartheta}(\{X=(x_1,\dots,x_n)\})=P_{\vartheta}(\{X_1=x_1\})\cdots P_{\vartheta}(\{X_n=x_n\})\\  &=\frac{e^{-\vartheta}\vartheta^{x_1}}{(x_1!)}\dots \frac{e^{-\vartheta}\vartheta^{x_n}}{(x_n!)}=\frac{e^{-n\vartheta}\vartheta^{\sum\limits_{i=1}^nx_i}}{\prod\limits_{i=1}^n(x_i!)}.  \end{align*} Applying the above statement yields after some manipulations $I(\vartheta)=\frac{n}{\vartheta}$ . However, the sample solution says: \begin{align*} &I(\vartheta)=\sum\limits_{x=0}^{\infty}\frac{\left(\frac{d\ln(P_{\vartheta}(X))}{d\vartheta}\right)^2}{P_{\vartheta}(X)}=\sum\limits_{x=0}^{\infty}\frac{1}{x!}e^{\vartheta}\vartheta^{-x}\left(-e^{-\vartheta}\vartheta^x+e^{-\vartheta}x\vartheta^{x-1}\right)\\ &= \sum\limits_{x=0}^{\infty}\frac{\vartheta^x}{x!}e^{-\vartheta}\left(\frac{x}{\vartheta}-1\right)^2=\mathbb{V}(X)\frac{1}{\vartheta}^2=\frac{1}{\vartheta}. \end{align*} This makes no sense to me? Why $x\to\infty$ and why is there only one random variable instead of a vector which represents $n$ -many obersavtions?","Let's consider a printer queue. We know that the expected number of printer jobs almost obeys a Poisson distribution, so , where . We estimate the expected number of printer jobs by . Compute the Fisher information . We know that if are independent random variables with a distribution like , then If we consider the -many independent observations , where each is the number of printer jobs in a certain period of time, the probability is given by Applying the above statement yields after some manipulations . However, the sample solution says: This makes no sense to me? Why and why is there only one random variable instead of a vector which represents -many obersavtions?","P_{\vartheta}(X=k)=e^{-\vartheta}\frac{\vartheta^k}{k!} \vartheta\in]0,\infty[ \vartheta \frac{1}{n}\sum\limits_{i=1}^nX_i I(\vartheta):=\mathbb{E}_{\vartheta}\left(\left(\frac{d\ln(P_{\vartheta}(X))}{d\vartheta}\right)^2\right) (X_1,\dots,X_n) P_X(\vartheta)=f(X_1,\vartheta)\dots f(X_n,\vartheta) \mathbb{E}_{\vartheta}\left(\left(\frac{d\ln(P_{\vartheta}(X))}{d\vartheta}\right)^2\right)=n\cdot \mathbb{E}_{\vartheta}\left(\left(\frac{d\ln(P_{\vartheta}(X_i))}{d\vartheta}\right)^2\right). n X:=(X_1,\dots,X_n) X_i \begin{align*} 
&P_{\vartheta}(\{X=(x_1,\dots,x_n)\})=P_{\vartheta}(\{X_1=x_1\})\cdots P_{\vartheta}(\{X_n=x_n\})\\ 
&=\frac{e^{-\vartheta}\vartheta^{x_1}}{(x_1!)}\dots \frac{e^{-\vartheta}\vartheta^{x_n}}{(x_n!)}=\frac{e^{-n\vartheta}\vartheta^{\sum\limits_{i=1}^nx_i}}{\prod\limits_{i=1}^n(x_i!)}. 
\end{align*} I(\vartheta)=\frac{n}{\vartheta} \begin{align*}
&I(\vartheta)=\sum\limits_{x=0}^{\infty}\frac{\left(\frac{d\ln(P_{\vartheta}(X))}{d\vartheta}\right)^2}{P_{\vartheta}(X)}=\sum\limits_{x=0}^{\infty}\frac{1}{x!}e^{\vartheta}\vartheta^{-x}\left(-e^{-\vartheta}\vartheta^x+e^{-\vartheta}x\vartheta^{x-1}\right)\\
&= \sum\limits_{x=0}^{\infty}\frac{\vartheta^x}{x!}e^{-\vartheta}\left(\frac{x}{\vartheta}-1\right)^2=\mathbb{V}(X)\frac{1}{\vartheta}^2=\frac{1}{\vartheta}.
\end{align*} x\to\infty n","['statistics', 'random-variables', 'proof-explanation', 'expected-value', 'fisher-information']"
51,Maximum likelihood estimator for non-standard distribution,Maximum likelihood estimator for non-standard distribution,,"This is a question from an old exam-paper: ""Suppose that we have data $y = (y_1, . . . , y_n)$ . Each data-point $y_i$ is assumed to be generated by a distribution with the following probability density function: $$p(y_i|\theta)=\frac{\theta^2}{y_i^3}e^{-\frac{\theta}{y_i}},y_i\ge0 $$ The unknown parameter is $\theta$ , with $\theta>0$ . Write down the likelihood for $\theta|y$ . Find an expression for the maximum likelihood estimate $\hat{\theta}$ ."" My approach is as follows: $$L(\theta;y) = \prod_{i=1}^n \frac{\theta^2}{y_i^3}e^{-\frac{\theta}{y_i}},y_i\ge0  $$ Now, $$\prod_{i=1}^n \theta^2=\theta^{2n}$$ $$\prod_{i=1}^n \frac{1}{y_i^3}=\frac{1}{(\prod y_i)^3} $$ and $$\prod_{i=1}^n e^{-\frac{\theta}{y_i}}=e^{-\theta \sum\frac{1}{y_i}} $$ So overall, $$L(\theta;y)=\theta^{2n} \frac{1}{(\prod y_i)^3} e^{-\theta \sum\frac{1}{y_i}}$$ The log-likelihood is $$\ell(\theta;y)=2n\ln(\theta) + \ln\left(\frac{1}{(\prod y_i)^3}\right) -\theta \sum\frac{1}{y_i}$$ Where all the products and sums happen over $i=1,2,3,\dots,n$ . Differentiating with respect to $\theta$ : $$ \frac{d\ell}{d\theta}=\frac{2n}{\theta}-\sum\frac{1}{y_i}=0$$ This implies that $$\hat{\theta}=\frac{2n}{\sum\frac{1}{y_i}} $$ Is the likelihood and the MLE correct?","This is a question from an old exam-paper: ""Suppose that we have data . Each data-point is assumed to be generated by a distribution with the following probability density function: The unknown parameter is , with . Write down the likelihood for . Find an expression for the maximum likelihood estimate ."" My approach is as follows: Now, and So overall, The log-likelihood is Where all the products and sums happen over . Differentiating with respect to : This implies that Is the likelihood and the MLE correct?","y = (y_1, . . . , y_n) y_i p(y_i|\theta)=\frac{\theta^2}{y_i^3}e^{-\frac{\theta}{y_i}},y_i\ge0  \theta \theta>0 \theta|y \hat{\theta} L(\theta;y) = \prod_{i=1}^n \frac{\theta^2}{y_i^3}e^{-\frac{\theta}{y_i}},y_i\ge0   \prod_{i=1}^n \theta^2=\theta^{2n} \prod_{i=1}^n \frac{1}{y_i^3}=\frac{1}{(\prod y_i)^3}  \prod_{i=1}^n e^{-\frac{\theta}{y_i}}=e^{-\theta \sum\frac{1}{y_i}}  L(\theta;y)=\theta^{2n} \frac{1}{(\prod y_i)^3} e^{-\theta \sum\frac{1}{y_i}} \ell(\theta;y)=2n\ln(\theta) + \ln\left(\frac{1}{(\prod y_i)^3}\right) -\theta \sum\frac{1}{y_i} i=1,2,3,\dots,n \theta  \frac{d\ell}{d\theta}=\frac{2n}{\theta}-\sum\frac{1}{y_i}=0 \hat{\theta}=\frac{2n}{\sum\frac{1}{y_i}} ","['statistics', 'solution-verification', 'bayesian', 'maximum-likelihood']"
52,Does type of moving average for an irregular time series exist already?,Does type of moving average for an irregular time series exist already?,,"Context I have an irregular time series where data points occur at irregular intervals of time. As a way to observe the behavior of this data over time, I want to use some type of moving average . The traditional suggestions for moving averages such as simple, weighted, or exponential, are not useful due to the irregular frequency of data points. Date Value 2022-12-04 10 2022-12-03 10 2022-12-02 10 2022-12-01 10 2020-01-01 1 This is an example of what could happen if I blindly applied a simple moving average. Suppose this example data represents a sequence of 5 data points that could occur within my data. $$ SMA_5 = \frac{10+10+10+10+1}{5} $$ $$ SMA_5 = 8.2 $$ The simple moving average is dragged down by that last observation of 1, even though the observation occurred two years ago and is of little relevance now. What I want is a moving average that would somehow take into consideration how long it has been from time of evaluation to time of observation. A weighted or exponential moving average, therefore, is not useful since it would assign less weight to the last value for the sake of it being the 5th, and not because it was a long time ago. My Approach The solution that I've come up with involves the following steps. I apologize in advance, as I am sure the process is unorthodox. Computing $DaysAgo$ , a new column containing the number of days that has passed since the time of evaluation $$ DaysAgo = CutoffDate - ObservedDate $$ Taking an arbitrary cutoff date of 2022-12-05, my sample data now looks like this. Date Value Days Ago 2022-12-04 10 1 2022-12-03 10 2 2022-12-02 10 3 2022-12-01 10 4 2020-01-01 1 1069 Computing $Weight$ , a new column containing a computed weight for each value $$ Weight = \frac{1}{\alpha*DaysAgo}+\frac{\alpha-1}{\alpha} $$ $$ \alpha \geq 1 $$ The idea behind this formula is to let the weight of each observation model the rational function $y = \frac{1}{x}$ , so as to achieve decay over time reflected in the weight. $\alpha$ is there to have a parameter that lets us adjust the strength of the decay over time. The sample data now looks like this. Date Value Days Ago Weight 2022-12-04 10 1 1.0000 2022-12-03 10 2 0.5000 2022-12-02 10 3 0.3333 2022-12-01 10 4 0.2500 2020-01-01 1 1069 0.0009 Computing $WeightAdj$ , a new column containing the adjusted values of $Weight$ $$ WeightAdj = \frac{Weight}{\sum Weight} $$ $$ WeightAdj = \frac{Weight}{1.0000+0.5000+0.3333+0.2500+0.0009} $$ The sample data now looks like this. Date Value Days Ago Weight WeightAdj 2022-12-04 10 1 1.0000 0.4798 2022-12-03 10 2 0.5000 0.2399 2022-12-02 10 3 0.3333 0.1599 2022-12-01 10 4 0.2500 0.1199 2020-01-01 1 1069 0.0009 0.0004 The weight adjustment allows for the following. $$ \sum WeightAdj = 1 $$ Compute $ValueAdj$ , a new column containing the adjusted values of $Value$ $$ ValueAdj = Value * WeightAdj $$ The sample data now looks like this. Date Value Days Ago Weight WeightAdj ValueAdj 2022-12-04 10 1 1.0000 0.4798 4.7978 2022-12-03 10 2 0.5000 0.2399 2.3989 2022-12-02 10 3 0.3333 0.1599 1.5993 2022-12-01 10 4 0.2500 0.1199 1.1995 2020-01-01 1 1069 0.0009 0.0004 0.0004 Finally, we compute the value of my custom moving average $$ MA_5 = \sum ValueAdj $$ $$ MA_5 = 9.9960 $$ $$ \alpha = 1 $$ In which, we can see that the old observation barely affects the outcome. If I wanted the time decay to be weaker, however, all I have to do is adjust $\alpha$ . $$ MA_5 = 8.7284 $$ $$ \alpha = 2 $$ $$ MA_5 = 8.2795 $$ $$ \alpha = 10 $$ This seems to me like a novel solution to my problem. It lets me analyze my data over time if I'm willing to compute this moving average many times while shifting the cutoff date by, say, a day each time. Not to mention, this moving average doesn't freak out if you have many points that occurred at the exact same time, or a singular point that occurred a very long time ago. My Questions Does this type of moving average exist already? Does this type of moving average remind you of another one that is more efficient? Are there any cases where this moving average behaves unexpectedly? As I got to coding this solution in Python, I figured it would be a good idea to ask about it here first. I welcome any criticisms or anyone who's got a more elegant solution. Your thoughts are much appreciated, thanks.","Context I have an irregular time series where data points occur at irregular intervals of time. As a way to observe the behavior of this data over time, I want to use some type of moving average . The traditional suggestions for moving averages such as simple, weighted, or exponential, are not useful due to the irregular frequency of data points. Date Value 2022-12-04 10 2022-12-03 10 2022-12-02 10 2022-12-01 10 2020-01-01 1 This is an example of what could happen if I blindly applied a simple moving average. Suppose this example data represents a sequence of 5 data points that could occur within my data. The simple moving average is dragged down by that last observation of 1, even though the observation occurred two years ago and is of little relevance now. What I want is a moving average that would somehow take into consideration how long it has been from time of evaluation to time of observation. A weighted or exponential moving average, therefore, is not useful since it would assign less weight to the last value for the sake of it being the 5th, and not because it was a long time ago. My Approach The solution that I've come up with involves the following steps. I apologize in advance, as I am sure the process is unorthodox. Computing , a new column containing the number of days that has passed since the time of evaluation Taking an arbitrary cutoff date of 2022-12-05, my sample data now looks like this. Date Value Days Ago 2022-12-04 10 1 2022-12-03 10 2 2022-12-02 10 3 2022-12-01 10 4 2020-01-01 1 1069 Computing , a new column containing a computed weight for each value The idea behind this formula is to let the weight of each observation model the rational function , so as to achieve decay over time reflected in the weight. is there to have a parameter that lets us adjust the strength of the decay over time. The sample data now looks like this. Date Value Days Ago Weight 2022-12-04 10 1 1.0000 2022-12-03 10 2 0.5000 2022-12-02 10 3 0.3333 2022-12-01 10 4 0.2500 2020-01-01 1 1069 0.0009 Computing , a new column containing the adjusted values of The sample data now looks like this. Date Value Days Ago Weight WeightAdj 2022-12-04 10 1 1.0000 0.4798 2022-12-03 10 2 0.5000 0.2399 2022-12-02 10 3 0.3333 0.1599 2022-12-01 10 4 0.2500 0.1199 2020-01-01 1 1069 0.0009 0.0004 The weight adjustment allows for the following. Compute , a new column containing the adjusted values of The sample data now looks like this. Date Value Days Ago Weight WeightAdj ValueAdj 2022-12-04 10 1 1.0000 0.4798 4.7978 2022-12-03 10 2 0.5000 0.2399 2.3989 2022-12-02 10 3 0.3333 0.1599 1.5993 2022-12-01 10 4 0.2500 0.1199 1.1995 2020-01-01 1 1069 0.0009 0.0004 0.0004 Finally, we compute the value of my custom moving average In which, we can see that the old observation barely affects the outcome. If I wanted the time decay to be weaker, however, all I have to do is adjust . This seems to me like a novel solution to my problem. It lets me analyze my data over time if I'm willing to compute this moving average many times while shifting the cutoff date by, say, a day each time. Not to mention, this moving average doesn't freak out if you have many points that occurred at the exact same time, or a singular point that occurred a very long time ago. My Questions Does this type of moving average exist already? Does this type of moving average remind you of another one that is more efficient? Are there any cases where this moving average behaves unexpectedly? As I got to coding this solution in Python, I figured it would be a good idea to ask about it here first. I welcome any criticisms or anyone who's got a more elegant solution. Your thoughts are much appreciated, thanks.","
SMA_5 = \frac{10+10+10+10+1}{5}
 
SMA_5 = 8.2
 DaysAgo 
DaysAgo = CutoffDate - ObservedDate
 Weight 
Weight = \frac{1}{\alpha*DaysAgo}+\frac{\alpha-1}{\alpha}
 
\alpha \geq 1
 y = \frac{1}{x} \alpha WeightAdj Weight 
WeightAdj = \frac{Weight}{\sum Weight}
 
WeightAdj = \frac{Weight}{1.0000+0.5000+0.3333+0.2500+0.0009}
 
\sum WeightAdj = 1
 ValueAdj Value 
ValueAdj = Value * WeightAdj
 
MA_5 = \sum ValueAdj
 
MA_5 = 9.9960
 
\alpha = 1
 \alpha 
MA_5 = 8.7284
 
\alpha = 2
 
MA_5 = 8.2795
 
\alpha = 10
","['statistics', 'time-series']"
53,Confidence Intervals of Markov Chains?,Confidence Intervals of Markov Chains?,,"I understand that a Discrete Time Markov Chain ( https://en.wikipedia.org/wiki/Markov_chain ) is closely related to a Multinomial Distribution ( https://en.wikipedia.org/wiki/Multinomial_distribution ). As I understand: A Multinomial Probability Distribution is a Discrete Probability Distribution Function which is characterized by a ""k"" number of possible events and a ""k"" number of probabilities corresponding to each of these possible events. As an example, the probability corresponding to the outcome of a dice roll can be characterized as a Multinomial Probability Distribution Function. On the other hand: A Discrete Time Markov Chain has a set of discrete states (e.g. ""k"" number of states) - e.g. State ""S1"", State ""S2"", State ""S3"" A Discrete Time Markov Chain has a corresponding set of probabilities which describe the probabilities of transitioning to one of these ""k"" states conditional on the the Markov Chain being in any other of these ""k"" states - these are referred to as ""Transition Probabilities"" Suppose we consider a Discrete Time Markov Chain with k=3 states - this means that there will be 3 x 3 = 9 transition probabilities : p11, p12, p13, p21, p22, p23, p31, p32, p33. Together, these 9 transition probabilities can be placed into a ""Transition Matrix"" (3x3) . As such, (p11, p12, p13) are in the first row of this transition matrix, (p21, p22, p23) are in the second row of this transition matrix, and (p31, p32, p33) are in the third row of this transition matrix. Now, consider just one row of this transition matrix. These three probabilities describe the ""fate"" of the Markov Chain provided they are currently situated in State ""S1"". As such, at this point we can consider the 3 transition probabilities as parameters of a Multinomial Probability Distribution. Now, this leads me to my question. The Wikipedia page on the Multinomial Distribution shows the properties of a Random Variable ""X"" following a Multinomial Distribution - for example, if a Random Variable ""X"" follows a Multinomial Distribution, we can find out the Mean and the Variance of ""X"" However, given some data (e.g. the Markov Chain was observed over 10 days to be in S1, S1, S2, S1, S2, S3, S1, S1, S1, S2) it is not immediately clear as to how we can estimate the transition probabilities and the variance of these transition probabilities. In other words, how can I estimate the mean and variance for the parameters of a Multinomial Distribution - NOT just the mean and variance for a Random Variable that follows a Multinomial Distribution? After doing some reading online, I came across the following link (e.g. https://www.stat.cmu.edu/~cshalizi/462/lectures/06/markov-mle.pdf , Maximum Likelihood Estimator of parameters of multinomial distribution ) which shows how Maximum Likelihood Estimation can be used to derive formula that can estimate the transition probabilities (i.e. parameters of a Multinomial Distribution) of a Markov Chain. Essentially, this is done by differentiating the log-likelihood function of the Multinomial Distribution with respect to each one of the parameters (i.e. dependent on the number of states), setting them to 0, and then solving the resulting system of equations. Doing this will provide the (""obvious"") estimates for these transition probabilities, e.g. P11 = (Number of Times Markov Chain was in State 1 and Transitioned to State 1) / (Number of Times Markov Chain was in State 1 and Transitioned to State 1 + Number of Times Markov Chain was in State 1 and Transitioned to State 2 + Number of Times Markov Chain was in State 1 and Transitioned to State 3) But I am still confused as to how the variance estimates for the transition probabilities can be calculated. Currently, several ideas come to mind: We can use ""bootstrap sampling"" ( https://en.wikipedia.org/wiki/Bootstrapping_(statistics) ) to randomly sample consecutive sequences of historical states (so that the chronological order of the state sequences are not interrupted) and calculate the transition probabilities based on this random sample. If we repeat this random sampling many times, we will now get a range of transition probabilities (e.g. p11_1st_sample, p11_2nd_sample...p11_nth_sample ...... p31_1st_sample...p33_nth_sample). For each transition probability, if we rank these random samples from smallest to largest and then take the 5th and 95th percentile, we construct a ""crude"" range of possible values that each transition probability could assume and their relative deviance from the mean value. The second way could be through the ""Delta Method"" ( https://en.wikipedia.org/wiki/Delta_method ), in which a formulation for the variance is first constructed, a 2nd Order Taylor Expansion is then approximated -  and finally we evaluate the variance of this 2nd Order Taylor Expansion using the Laws of Expectation. But this looks very complicated and I don't know how to do this? I remember hearing there is an inverse relationship between the Fisher Information of a Probability Distribution and the Variance for the Parameters Belonging to this Probability Distribution - supposedly doing some algebraic manipulations might lead to a formula for the variance of these parameters ... but I am not sure about this, and this seems is even more complicated! Finally, some classic methods involving Method of Moments and Var(x) = E(x^2) - (E(x))^2 might also be possible? I am interested in seeing a theoretical formulation for the variance of Transition Probabilities in a Discrete Time Markov Chain (or equivalently, the parameters of a Multinomial Distribution). I have spent a lot of time searching for a reference that clearly explains this - but I have not been able to find something. Can someone please help me in deriving these variance estimates alongside with providing an explanation as to how you approached and solved this problem? Thanks! Note: Throughout this whole question, I have assumed that the mean estimate for the parameters of a Multinomial Distribution are equal to the mean estimate for the Transition Probabilities of a Discrete Time Markov Chain ... and that the variance estimates for the parameters of a Multinomial Distribution are equal to the variance estimates for the Transitional Probabilities of a Discrete Time Markov Chain. In general, is this even true?","I understand that a Discrete Time Markov Chain ( https://en.wikipedia.org/wiki/Markov_chain ) is closely related to a Multinomial Distribution ( https://en.wikipedia.org/wiki/Multinomial_distribution ). As I understand: A Multinomial Probability Distribution is a Discrete Probability Distribution Function which is characterized by a ""k"" number of possible events and a ""k"" number of probabilities corresponding to each of these possible events. As an example, the probability corresponding to the outcome of a dice roll can be characterized as a Multinomial Probability Distribution Function. On the other hand: A Discrete Time Markov Chain has a set of discrete states (e.g. ""k"" number of states) - e.g. State ""S1"", State ""S2"", State ""S3"" A Discrete Time Markov Chain has a corresponding set of probabilities which describe the probabilities of transitioning to one of these ""k"" states conditional on the the Markov Chain being in any other of these ""k"" states - these are referred to as ""Transition Probabilities"" Suppose we consider a Discrete Time Markov Chain with k=3 states - this means that there will be 3 x 3 = 9 transition probabilities : p11, p12, p13, p21, p22, p23, p31, p32, p33. Together, these 9 transition probabilities can be placed into a ""Transition Matrix"" (3x3) . As such, (p11, p12, p13) are in the first row of this transition matrix, (p21, p22, p23) are in the second row of this transition matrix, and (p31, p32, p33) are in the third row of this transition matrix. Now, consider just one row of this transition matrix. These three probabilities describe the ""fate"" of the Markov Chain provided they are currently situated in State ""S1"". As such, at this point we can consider the 3 transition probabilities as parameters of a Multinomial Probability Distribution. Now, this leads me to my question. The Wikipedia page on the Multinomial Distribution shows the properties of a Random Variable ""X"" following a Multinomial Distribution - for example, if a Random Variable ""X"" follows a Multinomial Distribution, we can find out the Mean and the Variance of ""X"" However, given some data (e.g. the Markov Chain was observed over 10 days to be in S1, S1, S2, S1, S2, S3, S1, S1, S1, S2) it is not immediately clear as to how we can estimate the transition probabilities and the variance of these transition probabilities. In other words, how can I estimate the mean and variance for the parameters of a Multinomial Distribution - NOT just the mean and variance for a Random Variable that follows a Multinomial Distribution? After doing some reading online, I came across the following link (e.g. https://www.stat.cmu.edu/~cshalizi/462/lectures/06/markov-mle.pdf , Maximum Likelihood Estimator of parameters of multinomial distribution ) which shows how Maximum Likelihood Estimation can be used to derive formula that can estimate the transition probabilities (i.e. parameters of a Multinomial Distribution) of a Markov Chain. Essentially, this is done by differentiating the log-likelihood function of the Multinomial Distribution with respect to each one of the parameters (i.e. dependent on the number of states), setting them to 0, and then solving the resulting system of equations. Doing this will provide the (""obvious"") estimates for these transition probabilities, e.g. P11 = (Number of Times Markov Chain was in State 1 and Transitioned to State 1) / (Number of Times Markov Chain was in State 1 and Transitioned to State 1 + Number of Times Markov Chain was in State 1 and Transitioned to State 2 + Number of Times Markov Chain was in State 1 and Transitioned to State 3) But I am still confused as to how the variance estimates for the transition probabilities can be calculated. Currently, several ideas come to mind: We can use ""bootstrap sampling"" ( https://en.wikipedia.org/wiki/Bootstrapping_(statistics) ) to randomly sample consecutive sequences of historical states (so that the chronological order of the state sequences are not interrupted) and calculate the transition probabilities based on this random sample. If we repeat this random sampling many times, we will now get a range of transition probabilities (e.g. p11_1st_sample, p11_2nd_sample...p11_nth_sample ...... p31_1st_sample...p33_nth_sample). For each transition probability, if we rank these random samples from smallest to largest and then take the 5th and 95th percentile, we construct a ""crude"" range of possible values that each transition probability could assume and their relative deviance from the mean value. The second way could be through the ""Delta Method"" ( https://en.wikipedia.org/wiki/Delta_method ), in which a formulation for the variance is first constructed, a 2nd Order Taylor Expansion is then approximated -  and finally we evaluate the variance of this 2nd Order Taylor Expansion using the Laws of Expectation. But this looks very complicated and I don't know how to do this? I remember hearing there is an inverse relationship between the Fisher Information of a Probability Distribution and the Variance for the Parameters Belonging to this Probability Distribution - supposedly doing some algebraic manipulations might lead to a formula for the variance of these parameters ... but I am not sure about this, and this seems is even more complicated! Finally, some classic methods involving Method of Moments and Var(x) = E(x^2) - (E(x))^2 might also be possible? I am interested in seeing a theoretical formulation for the variance of Transition Probabilities in a Discrete Time Markov Chain (or equivalently, the parameters of a Multinomial Distribution). I have spent a lot of time searching for a reference that clearly explains this - but I have not been able to find something. Can someone please help me in deriving these variance estimates alongside with providing an explanation as to how you approached and solved this problem? Thanks! Note: Throughout this whole question, I have assumed that the mean estimate for the parameters of a Multinomial Distribution are equal to the mean estimate for the Transition Probabilities of a Discrete Time Markov Chain ... and that the variance estimates for the parameters of a Multinomial Distribution are equal to the variance estimates for the Transitional Probabilities of a Discrete Time Markov Chain. In general, is this even true?",,"['probability', 'statistics', 'markov-chains', 'confidence-interval']"
54,"If $Y$ is a sub-Gaussian random variable, must $Y-E(Y\mid X)$ be also sub-Gaussian?","If  is a sub-Gaussian random variable, must  be also sub-Gaussian?",Y Y-E(Y\mid X),"Question. If $Y$ is a sub-Gaussian random variable, must the regression residual $\varepsilon=Y-E(Y\mid X)$ be also sub-Gaussian? In terms of the variance, it is well known that $\mathrm{var}(\varepsilon)\leq \mathrm{var}(Y)$ . However, I can't find out a way to prove (or disprove) the sub-Gaussianity of $\varepsilon$ when $Y$ is sub-Gaussian.","Question. If is a sub-Gaussian random variable, must the regression residual be also sub-Gaussian? In terms of the variance, it is well known that . However, I can't find out a way to prove (or disprove) the sub-Gaussianity of when is sub-Gaussian.",Y \varepsilon=Y-E(Y\mid X) \mathrm{var}(\varepsilon)\leq \mathrm{var}(Y) \varepsilon Y,"['probability', 'statistics']"
55,Gibbs sampler for a posterior distribution of hierarchical model,Gibbs sampler for a posterior distribution of hierarchical model,,"I'm trying to get a posterior distribution of hierarchical model by using a Gibbs sampler. I haven't dealt with hierarchical models so far and I'm not really familiar with the Gibbs sampler so I'm a bit confused. (1) $y_{i}|\theta_{i},\mu \stackrel{ind}\sim N(\theta_{i},\sigma^{2})$ for i =1,2,...,n ( $\sigma^{2}$ is known) (2) $\theta_{i}|\mu \stackrel{iid}\sim N(\mu,\tau^{2})$ for i =1,2,...,n (3) $\pi(\mu,\tau^{2})\propto \Large\frac{\tau^{2}}{\sigma^{2}+\tau^{2}}$ First Question The thing I want to know is $P(\theta_{i}|y_{i})$ so I'm thinking of getting $(\theta_{(1)},\mu_{(1)},\tau^{2}_{(1)})$ , $(\theta_{(2)},\mu_{(2)},\tau^{2}_{(2)})$ , $(\theta_{(3)},\mu_{(3)},\tau^{2}_{(3)})$ ..... by using a gibbs sampler and then just pulling out only $\theta_{1},\theta_{2},\theta_{3},...$ Then does distribution of $\theta_{i}$ is P $(\theta_{i}|y_{i})$ that I'd like to know? If that's the case... I actually calculated each of full conditional distributions to use a Gibbs sampler and I'm having trouble getting this one because of the leftmost term. $P(\tau^{2}|\theta_{1},..,\theta_{n},y_{1},..,y_{n},\mu) \large\propto(\tau^{2})^{-\frac{n}{2}}exp[-\frac{\sum(\theta_{i}-\mu)^2}{2r^2}]\large\frac{\tau^{2}}{\sigma^{2}+\tau^{2}}$ I guess I could use Inverse Gamma distribution if I could just get rid of the leftmost term $\large\frac{\tau^{2}}{\sigma^{2}+\tau^{2}}$ and change a little bit. $P(\tau^{2}|\theta_{1},..,\theta_{n},y_{1},..,y_{n},\mu) \large\propto(\tau^{2})^{-\frac{n-2}{2}-1}exp[-\frac{\sum(\theta_{i}-\mu)^2}{2r^2}] \sim IG(\frac{n-2}{2},\frac{\sum(\theta_{i}-\mu)^2}{2})$ Second Question Since we are calculating in proportional, can I consider that term as just 1? ( $\Large\frac{\tau^{2}}{\sigma^{2}+\tau^{2}} \propto 1$ ) so I could use Inverse Gamma distribution. Can anyone help me with this? Anything is welcome. I'm kinda eager to know this:) Thank you.","I'm trying to get a posterior distribution of hierarchical model by using a Gibbs sampler. I haven't dealt with hierarchical models so far and I'm not really familiar with the Gibbs sampler so I'm a bit confused. (1) for i =1,2,...,n ( is known) (2) for i =1,2,...,n (3) First Question The thing I want to know is so I'm thinking of getting , , ..... by using a gibbs sampler and then just pulling out only Then does distribution of is P that I'd like to know? If that's the case... I actually calculated each of full conditional distributions to use a Gibbs sampler and I'm having trouble getting this one because of the leftmost term. I guess I could use Inverse Gamma distribution if I could just get rid of the leftmost term and change a little bit. Second Question Since we are calculating in proportional, can I consider that term as just 1? ( ) so I could use Inverse Gamma distribution. Can anyone help me with this? Anything is welcome. I'm kinda eager to know this:) Thank you.","y_{i}|\theta_{i},\mu \stackrel{ind}\sim N(\theta_{i},\sigma^{2}) \sigma^{2} \theta_{i}|\mu \stackrel{iid}\sim N(\mu,\tau^{2}) \pi(\mu,\tau^{2})\propto \Large\frac{\tau^{2}}{\sigma^{2}+\tau^{2}} P(\theta_{i}|y_{i}) (\theta_{(1)},\mu_{(1)},\tau^{2}_{(1)}) (\theta_{(2)},\mu_{(2)},\tau^{2}_{(2)}) (\theta_{(3)},\mu_{(3)},\tau^{2}_{(3)}) \theta_{1},\theta_{2},\theta_{3},... \theta_{i} (\theta_{i}|y_{i}) P(\tau^{2}|\theta_{1},..,\theta_{n},y_{1},..,y_{n},\mu) \large\propto(\tau^{2})^{-\frac{n}{2}}exp[-\frac{\sum(\theta_{i}-\mu)^2}{2r^2}]\large\frac{\tau^{2}}{\sigma^{2}+\tau^{2}} \large\frac{\tau^{2}}{\sigma^{2}+\tau^{2}} P(\tau^{2}|\theta_{1},..,\theta_{n},y_{1},..,y_{n},\mu) \large\propto(\tau^{2})^{-\frac{n-2}{2}-1}exp[-\frac{\sum(\theta_{i}-\mu)^2}{2r^2}] \sim IG(\frac{n-2}{2},\frac{\sum(\theta_{i}-\mu)^2}{2}) \Large\frac{\tau^{2}}{\sigma^{2}+\tau^{2}} \propto 1","['probability', 'statistics', 'probability-distributions', 'bayesian']"
56,Find the probability that at least one digit will occupy its proper place.,Find the probability that at least one digit will occupy its proper place.,,"Suppose that the three digits $1$ , $2$ and $3$ are written down in random order. What is the probability that at least one digit will occupy its proper place? Answer: $\frac{2}{3}$ My attempt: In my first take I used the definition of probability with finite sample space and equally likely outcomes, which achieve: $3\times 2 \times 1 = 6$ possibilities to arrange the three digits. And the set with all these arrangements would be: $S=\{(1,2,3);(1,3,2);(2,1,3);(2,3,1);(3,2,1);(3,1,2)\}$ And the asked probability is: $P=\frac{4}{6}=\frac{2}{3}$ Trying to solve in a more general way which would be more efficient if the number of digits were much larger, I got this: $P(\text{getting 1 digit at the right place})= \binom{3}{1}\times(\frac13)\times(\frac23)^2=\frac{4}{9}$ $P(\text{getting 2 digits at the right place})=\binom{3}{2}\times(\frac13)^2\times(\frac23)=\frac{2}{9}$ $P(\text{getting all digits at the right place})=\binom{3}{3}\times(\frac{1} {3})^3=\frac{1}{27}$ And the probability of getting at least one digit at the right place would be the sum of all three. $P=\frac{4}{9} + \frac{2}{9} +\frac{1}{27}=\frac{19}{27}$ I know this problem could be solved like this: https://math.stackexchange.com/q/2882673 . I just want to know why I didn't get the same result in the second attempt and if I could make some adjustment to achieve the wanted result.","Suppose that the three digits , and are written down in random order. What is the probability that at least one digit will occupy its proper place? Answer: My attempt: In my first take I used the definition of probability with finite sample space and equally likely outcomes, which achieve: possibilities to arrange the three digits. And the set with all these arrangements would be: And the asked probability is: Trying to solve in a more general way which would be more efficient if the number of digits were much larger, I got this: And the probability of getting at least one digit at the right place would be the sum of all three. I know this problem could be solved like this: https://math.stackexchange.com/q/2882673 . I just want to know why I didn't get the same result in the second attempt and if I could make some adjustment to achieve the wanted result.","1 2 3 \frac{2}{3} 3\times 2 \times 1 = 6 S=\{(1,2,3);(1,3,2);(2,1,3);(2,3,1);(3,2,1);(3,1,2)\} P=\frac{4}{6}=\frac{2}{3} P(\text{getting 1 digit at the right place})= \binom{3}{1}\times(\frac13)\times(\frac23)^2=\frac{4}{9} P(\text{getting 2 digits at the right place})=\binom{3}{2}\times(\frac13)^2\times(\frac23)=\frac{2}{9} P(\text{getting all digits at the right place})=\binom{3}{3}\times(\frac{1} {3})^3=\frac{1}{27} P=\frac{4}{9} + \frac{2}{9} +\frac{1}{27}=\frac{19}{27}","['probability', 'statistics']"
57,Find the probability that the smallest/largest number is 5.,Find the probability that the smallest/largest number is 5.,,"Ten persons in a room are wearing badges marked $1$ through $10$ . Three persons are chosen at random, and asked to leave the room simultaneously. Their badge number is noted. (a) What is the probability that the smallest badge number is $5$ ? (b) what is the probability that the largest badge number is $5$ ? Answer: (a) $\frac{1}{12}$ , (b) $\frac{1}{20}$ . My attempt: (a) We have five numbers greater than $5$ from a total of ten, so the probability wanted is: $P=\frac{5\times4\times3}{10\times9\times8}=\frac{1}{12}$ (b) Using the same logic we have: $P=\frac{4\times3\times2}{10\times9\times8}=\frac{1}{30}$ I know it's a combination problem, I've calculated this way cause I find more intuitive, I just don't get why it worked for one item but not the other. What was my mistake?","Ten persons in a room are wearing badges marked through . Three persons are chosen at random, and asked to leave the room simultaneously. Their badge number is noted. (a) What is the probability that the smallest badge number is ? (b) what is the probability that the largest badge number is ? Answer: (a) , (b) . My attempt: (a) We have five numbers greater than from a total of ten, so the probability wanted is: (b) Using the same logic we have: I know it's a combination problem, I've calculated this way cause I find more intuitive, I just don't get why it worked for one item but not the other. What was my mistake?",1 10 5 5 \frac{1}{12} \frac{1}{20} 5 P=\frac{5\times4\times3}{10\times9\times8}=\frac{1}{12} P=\frac{4\times3\times2}{10\times9\times8}=\frac{1}{30},"['probability', 'combinatorics', 'statistics']"
58,How to prove Cauchy Distribution doesn't belong to Exponential Family?,How to prove Cauchy Distribution doesn't belong to Exponential Family?,,"My idea is that the Expectation of Cauchy Distribution is infinite, and I find the following lemma If $X$ were from the exponential family, it would have finite expectation. The question is solved if I can prove the lemma, but I have no idea how to prove it. I could get that if $f_X(x;θ)$ can be written as $$f_X(x;\eta)=h(x)\exp\left(\sum_{i=1}^s\eta_iT_i(x)−A(\eta)\right)$$ then $E[T_i(X)]=\frac{\partial A(\eta)}{\partial η_i}$ is finite But I don't know how to apply this to show that the expectation $E[X]$ is finite.","My idea is that the Expectation of Cauchy Distribution is infinite, and I find the following lemma If were from the exponential family, it would have finite expectation. The question is solved if I can prove the lemma, but I have no idea how to prove it. I could get that if can be written as then is finite But I don't know how to apply this to show that the expectation is finite.",X f_X(x;θ) f_X(x;\eta)=h(x)\exp\left(\sum_{i=1}^s\eta_iT_i(x)−A(\eta)\right) E[T_i(X)]=\frac{\partial A(\eta)}{\partial η_i} E[X],"['probability', 'statistics', 'expected-value', 'exponential-family']"
59,method of moments poisson distribution not unique,method of moments poisson distribution not unique,,"We know that MOM estimate may not be unique. The most common example is Poisson distribution. From my lecture notes, it said if we only consider $m_1 = \mu_1'$ , then we have $\hat{\lambda} = \bar{X}$ . While if we consider $m_1 = \mu_1'$ and $m_2 = \mu_2'$ together, then $m_2 = \lambda + m_1^2 =\lambda + \bar{X}^2$ , which implies $\hat{\lambda} = m_2 - m_1^2$ . My question is why I cannot write $m_2 = \lambda + \lambda^2 $ , so this will be a new estimate.","We know that MOM estimate may not be unique. The most common example is Poisson distribution. From my lecture notes, it said if we only consider , then we have . While if we consider and together, then , which implies . My question is why I cannot write , so this will be a new estimate.",m_1 = \mu_1' \hat{\lambda} = \bar{X} m_1 = \mu_1' m_2 = \mu_2' m_2 = \lambda + m_1^2 =\lambda + \bar{X}^2 \hat{\lambda} = m_2 - m_1^2 m_2 = \lambda + \lambda^2 ,['statistics']
60,"If $X$ is log-normal, find $\mathbb{E}(\min(X-4,1))$.","If  is log-normal, find .","X \mathbb{E}(\min(X-4,1))","For a random variable $X$ , we have $\mathbb{E}(X)=4$ and that $\ln X$ follows normal distribution with variance $3$ . I need to find $\mathbb{E}(\min(X-4,1))$ and express it with $\Phi$ , the cumulative distribution function of the standard normal distribution. My attempt: $$ \begin{align} \mathbb{E}(\min(X-4,1)) &=\int^\infty_{-\infty} \min(x-4,1)f_X(x)dx\\ &=\int^5_{-\infty}(x-4)f_X(x)dx+\int^\infty_5f_X(x)dx\\ \end{align} $$ Here's where I'm stuck and i don't know what to do to express it with $\Phi$ , the CDF of the standard normal distribution. Any suggestions please?","For a random variable , we have and that follows normal distribution with variance . I need to find and express it with , the cumulative distribution function of the standard normal distribution. My attempt: Here's where I'm stuck and i don't know what to do to express it with , the CDF of the standard normal distribution. Any suggestions please?","X \mathbb{E}(X)=4 \ln X 3 \mathbb{E}(\min(X-4,1)) \Phi 
\begin{align}
\mathbb{E}(\min(X-4,1))
&=\int^\infty_{-\infty} \min(x-4,1)f_X(x)dx\\
&=\int^5_{-\infty}(x-4)f_X(x)dx+\int^\infty_5f_X(x)dx\\
\end{align}
 \Phi","['statistics', 'normal-distribution', 'expected-value']"
61,Intuitive Understanding of the Fisher Information?,Intuitive Understanding of the Fisher Information?,,"Within Statistics and Probability, the Fisher Information ( https://en.wikipedia.org/wiki/Fisher_information ) is generally said to describe the ""amount of information that an observed random variable (i.e. a random data point) carries about some hidden parameter"". For example: If we assume a Uniform Probability Distribution with parameters (a,b) - any random point carries as much information as any other random point about the parameters (a,b). But in a Normal Probability Distribution with parameters (mu, sigma), points from the ""tail"" areas of the distribution are said to carry more information about the parameters (mu, sigma) compared to points closer to the ""peak areas"" (I am not exactly sure why this is). Looking at the mathematical formula for the Fisher Information - it appears to be the ""expected value of the square of the second derivative of the log likelihood function (for some probability distribution). This leads me to my question: Why does the ""expected value of the square of the second derivative of the log likelihood function (for some probability distribution)"" tell us about the ""information that an observed random variable carries about some hidden parameter""? I can understand both of these arguments in isolation - I can accept that for some probability distributions, some random points are ""more informative"" about the probability distribution compared to other random points. And the mathematical formula used to calculate the Fisher Information seems (complex but) straightforward. But how does the ""expected value of the square of the second derivative of the log likelihood function (for some probability distribution)"" relate to amount of information carried by some random point? Just by looking at the mathematical formula of the Fisher Information in isolation, how am I supposed to recognize that this is a formula that is describing the informativeness of a random point? It still seems a bit ""arbitrary"" to me, even though I am sure its not. Thanks!","Within Statistics and Probability, the Fisher Information ( https://en.wikipedia.org/wiki/Fisher_information ) is generally said to describe the ""amount of information that an observed random variable (i.e. a random data point) carries about some hidden parameter"". For example: If we assume a Uniform Probability Distribution with parameters (a,b) - any random point carries as much information as any other random point about the parameters (a,b). But in a Normal Probability Distribution with parameters (mu, sigma), points from the ""tail"" areas of the distribution are said to carry more information about the parameters (mu, sigma) compared to points closer to the ""peak areas"" (I am not exactly sure why this is). Looking at the mathematical formula for the Fisher Information - it appears to be the ""expected value of the square of the second derivative of the log likelihood function (for some probability distribution). This leads me to my question: Why does the ""expected value of the square of the second derivative of the log likelihood function (for some probability distribution)"" tell us about the ""information that an observed random variable carries about some hidden parameter""? I can understand both of these arguments in isolation - I can accept that for some probability distributions, some random points are ""more informative"" about the probability distribution compared to other random points. And the mathematical formula used to calculate the Fisher Information seems (complex but) straightforward. But how does the ""expected value of the square of the second derivative of the log likelihood function (for some probability distribution)"" relate to amount of information carried by some random point? Just by looking at the mathematical formula of the Fisher Information in isolation, how am I supposed to recognize that this is a formula that is describing the informativeness of a random point? It still seems a bit ""arbitrary"" to me, even though I am sure its not. Thanks!",,"['probability', 'statistics', 'normal-distribution']"
62,Estimating variance of population with variance of sample mean,Estimating variance of population with variance of sample mean,,"Suppose a population has a given random variable $X$ with unknown mean $\mu$ and unknown variance $\sigma^2$ . Sampling theory tells us that for a sample of size $n$ , $E(\bar{X}) = \mu$ and $V(\bar{X})=\frac{\sigma^2}{n}$ . It is well known that $E(\bar{X})$ is an unbiased estimator of $\mu$ . To estimate the parameter $\sigma^2$ , how bad of an estimator is $n V(\bar{X})$ ?","Suppose a population has a given random variable with unknown mean and unknown variance . Sampling theory tells us that for a sample of size , and . It is well known that is an unbiased estimator of . To estimate the parameter , how bad of an estimator is ?",X \mu \sigma^2 n E(\bar{X}) = \mu V(\bar{X})=\frac{\sigma^2}{n} E(\bar{X}) \mu \sigma^2 n V(\bar{X}),"['statistics', 'estimation', 'sampling']"
63,"Let $Y$ be $b(300,p)$. If the observed value of $Y$ is $y=75$, find the approximate $90\%$ confidence interval for $p$.","Let  be . If the observed value of  is , find the approximate  confidence interval for .","Y b(300,p) Y y=75 90\% p","I tried solving this problem by what I've learned about confidence intervals for proportions, but something goes wrong at some point because I'm not matching the textbook answer. For this problem, since $Y$ is not normally distributed, let's consider the following general pivot random variable: $$ Z = \frac{\overline{X}-\mu}{\frac{\sqrt{S^2/n}}{n}} $$ where $\overline{X}$ is the sample mean (mle of $\mu$ ), $\mu$ is the mean (the parameter we wish to estimate), $S^2$ is the sample variance and $n$ is the sample size. By the central limit theorem and by the independence of the samples $Y_1, \ldots, Y_n$ , $Z$ approximately follows a standard normal distribution, i.e. $N(0,1)$ . A $(1-\alpha)100\%$ confidence interval for $\mu$ is one such that $$ \text{Pr}\left(\overline{X} - z_{\alpha/2}{\frac{\sqrt{S^2/n}}{n}} < \mu < \overline{X} + z_{\alpha/2} \frac{\sqrt{S^2/n}}{n}\right) = 1-\alpha $$ where $0 < \alpha < 1$ . In our case, \begin{align} \alpha &= 0.10 \\ z_{\alpha/2} &= 1.645 \\ n &= 300 \\ \overline{X} &= \widehat{p} = 75/300 = 1/4 \\ \\ S^2 &= \sigma^2 = 300\widehat{p}(1-\widehat{p}) \end{align} With these values in mind, our confidence interval for $p$ is: \begin{align} \left(1/4 - 1.645\frac{\sqrt{300(1/4)(1-1/4)/300}}{300}, 1/4 + 1.645\frac{\sqrt{300(1/4)(1-1/4)/300}}{300}\right) &=  (0.2476, 0.2524) \end{align} My textbook has the following confidence interval: $$ (0.2089,0.2911) $$ What did I do wrong?","I tried solving this problem by what I've learned about confidence intervals for proportions, but something goes wrong at some point because I'm not matching the textbook answer. For this problem, since is not normally distributed, let's consider the following general pivot random variable: where is the sample mean (mle of ), is the mean (the parameter we wish to estimate), is the sample variance and is the sample size. By the central limit theorem and by the independence of the samples , approximately follows a standard normal distribution, i.e. . A confidence interval for is one such that where . In our case, With these values in mind, our confidence interval for is: My textbook has the following confidence interval: What did I do wrong?","Y 
Z = \frac{\overline{X}-\mu}{\frac{\sqrt{S^2/n}}{n}}
 \overline{X} \mu \mu S^2 n Y_1, \ldots, Y_n Z N(0,1) (1-\alpha)100\% \mu 
\text{Pr}\left(\overline{X} - z_{\alpha/2}{\frac{\sqrt{S^2/n}}{n}} < \mu < \overline{X} + z_{\alpha/2} \frac{\sqrt{S^2/n}}{n}\right) = 1-\alpha
 0 < \alpha < 1 \begin{align}
\alpha &= 0.10 \\
z_{\alpha/2} &= 1.645 \\
n &= 300 \\
\overline{X} &= \widehat{p} = 75/300 = 1/4 \\
\\
S^2 &= \sigma^2 = 300\widehat{p}(1-\widehat{p})
\end{align} p \begin{align}
\left(1/4 - 1.645\frac{\sqrt{300(1/4)(1-1/4)/300}}{300}, 1/4 + 1.645\frac{\sqrt{300(1/4)(1-1/4)/300}}{300}\right) &= 
(0.2476, 0.2524)
\end{align} 
(0.2089,0.2911)
","['probability', 'statistics', 'confidence-interval']"
64,Calculating win probability in a specific game of chance,Calculating win probability in a specific game of chance,,"Consider a ""game"" (scare quotes because there's no strategy involved, just pure luck) with the following rules: Each of two players begins with some number of pieces (not necessarily the same number for both players), each labeled with a digit between 1 and 6. On each player's turn, they roll two dice. For each die, if a player holds a piece labeled with that die's number, that piece is eliminated. The winner is the first player to eliminate all their pieces. My question is how to determine which player is more likely to win given the number and distribution of their pieces. Two points are obvious: Having fewer pieces than your opponent makes you more likely to win; Having pieces that are more evenly distributed than your opponent makes you more likely to win. To illustrate the second point, if one player has [1,2,3,4,5,6] and the other has [1,1,1,1,1,1], the first will benefit from any die roll while the second will only benefit from a 1. How do these two factors interact? I did some coding and found that in practice, [1,2,3,4,5,6] seems to beat [1,1,1] more often than not, but lose to [1,1] or [1,1,2]; [1,2,2,3,3,3,4,4,4,4] and [6,6,6,6,6] are about evenly matched; etc. But is there some general formula which, given how many pieces each player has and how many distinct digits they represent, can tell you who has the higher win probability?","Consider a ""game"" (scare quotes because there's no strategy involved, just pure luck) with the following rules: Each of two players begins with some number of pieces (not necessarily the same number for both players), each labeled with a digit between 1 and 6. On each player's turn, they roll two dice. For each die, if a player holds a piece labeled with that die's number, that piece is eliminated. The winner is the first player to eliminate all their pieces. My question is how to determine which player is more likely to win given the number and distribution of their pieces. Two points are obvious: Having fewer pieces than your opponent makes you more likely to win; Having pieces that are more evenly distributed than your opponent makes you more likely to win. To illustrate the second point, if one player has [1,2,3,4,5,6] and the other has [1,1,1,1,1,1], the first will benefit from any die roll while the second will only benefit from a 1. How do these two factors interact? I did some coding and found that in practice, [1,2,3,4,5,6] seems to beat [1,1,1] more often than not, but lose to [1,1] or [1,1,2]; [1,2,2,3,3,3,4,4,4,4] and [6,6,6,6,6] are about evenly matched; etc. But is there some general formula which, given how many pieces each player has and how many distinct digits they represent, can tell you who has the higher win probability?",,"['probability', 'statistics']"
65,Using Jensen's inequality on $\mathbb{E}[1/x]$ when x can be both positive and negative,Using Jensen's inequality on  when x can be both positive and negative,\mathbb{E}[1/x],We know the function $f(x)=\frac{1}{x}$ is convex when $x$ is positive and concave when $x$ is negative. I want to show if $\mathbb{E}[\frac{1}{x}]$ is bigger than or smaller than $\frac{1}{\mathbb{E}[x]}$ using Jensen's inequality but what happens if $x$ is on the range for example $-1<x<1$ so that it is concave on some portion and convex on some portion? How do I know the direction of the inequality? Does the range of the function matter? For example when there are more positives than negatives $-1<x<2$ versus when there are more negative than positive $-2<x<1$ ? Thank you so much!,We know the function is convex when is positive and concave when is negative. I want to show if is bigger than or smaller than using Jensen's inequality but what happens if is on the range for example so that it is concave on some portion and convex on some portion? How do I know the direction of the inequality? Does the range of the function matter? For example when there are more positives than negatives versus when there are more negative than positive ? Thank you so much!,f(x)=\frac{1}{x} x x \mathbb{E}[\frac{1}{x}] \frac{1}{\mathbb{E}[x]} x -1<x<1 -1<x<2 -2<x<1,"['probability', 'statistics', 'probability-distributions', 'jensen-inequality']"
66,What is the best way to measure similarity between two histograms,What is the best way to measure similarity between two histograms,,"What is the best way to measure the similarity between two histograms? For example, in the following pictures, how can I tell if the distributions are similar enough? I now have 2 lists of values, and I've normalized them to fall between 0 and 1. I've tried multiple statistical tests including Pearson, Spearman, and Kolmogorov-Smirnov and it looks like Spearman is the best test to use. However, the Spearman is not consistent all the time, it sometimes gives me a high ""s"" value but the shapes of the distribution are not similar enough. In theory, a higher (positive) ""s"" means the values are strongly correlated. Am I even on the right track using correlation to measure similarities? Are there any other tests that can be used to do this? corr0.89_1 = [10.7441, 8.9568, 11.0018, 9.29803, 8.92043, 8.78492, 13.5503, 6.74334, 6.14392, 5.75271, 28.851, 26.8173, 6.52642, 6.56071, 5.7169, 7.3095, 6.36379, 5.74984, 7.10243, 5.87364, 11.2827, 2.94984, 2.84836, 22.8551, 24.8372, 10.6571, 9.7891, 11.3021, 5.89328, 10.1372, 24.0525, 3.49401, 2.16394, 11.2825, 11.6859, 7.9918, 13.2742, 11.1194, 2.49575, 16.733, 27.918, 3.27145, 14.3346, 20.4979, 13.0808, 13.6282, 14.1474, 25.0414, 8.06032, 280.803, 22.0135, 18.2725, 12.9601, 7.64593] corr0.89_2 = [9.14167, 6.30561, 7.7479, 8.05475, 7.14188, 7.62774, 9.18454, 1.48037, 1.5912, 2.07612, 21.302, 22.7082, 2.67858, 2.25732, 1.74804, 2.04191, 2.03539, 1.78882, 2.57568, 1.6512, 8.62473, 2.99236, 3.13484, 13.014, 16.2016, 9.17172, 7.97379, 9.12539, 4.8298, 8.42477, 16.0582, 2.68252, 1.92429, 5.6744, 4.70516, 5.20169, 11.0945, 9.10398, 2.68375, 13.6299, 17.3429, 3.19181, 9.41762, 12.2805, 9.92005, 11.5985, 11.7269, 17.4832, 6.66996, 60.8647, 13.9616, 14.9909, 10.4712, 6.13891] corr1.0_1 = [0.00905783, 0, 0.0075662, 0, 0.00583336, 0, 0.0101741, 0.00617847, 0.00474902, 0, 0.0243326, 0.0300779, 0.0062144, 0.00581433, 0, 0.00712057, 0.00703617, 0, 0, 0, 0.0101258, 0.00844863, 0.014988, 0.0248553, 0, 0.00680134, 0.00762619, 0.00701553, 0.0106525, 0.00425654, 0.0160354, 0, 0, 0, 0, 0, 0.0110151, 0.00874536, 0, 0.0182528, 0.0291939, 0, 0.0426431, 0.0141304, 0.0139076, 0.0182638, 0.0177141, 0.021119, 0, 12.3977, 0.0121492, 0.016053, 0.0148212, 0.00767271] corr1.0_2 = [0.128504, 0.119172, 0.0403692, 0.148327, 0.132162, 0.0366454, 0.139191, 0.0464803, 0.0235099, 0.0333772, 0.0427275, 0.0510047, 0.0278845, 0.0202271, 0.0918039, 0.129276, 0.0266636, 0.0399166, 0.693549, 0.131911, 0.134276, 0, 0, 0.248764, 0.17239, 0.0450586, 0.0932654, 0.0671463, 0.239433, 0.102551, 0.378029, 0.031807, 0.0181028, 0.107356, 0.145449, 0.0735069, 0.788291, 0.496569, 0.0209139, 0.0983066, 0.0530917, 0.0755444, 0.25198, 0.550969, 0.172254, 0.104131, 0.113987, 0.548016, 0.302768, 126.145, 0.886364, 0.107977, 0.4037, 1.23249]","What is the best way to measure the similarity between two histograms? For example, in the following pictures, how can I tell if the distributions are similar enough? I now have 2 lists of values, and I've normalized them to fall between 0 and 1. I've tried multiple statistical tests including Pearson, Spearman, and Kolmogorov-Smirnov and it looks like Spearman is the best test to use. However, the Spearman is not consistent all the time, it sometimes gives me a high ""s"" value but the shapes of the distribution are not similar enough. In theory, a higher (positive) ""s"" means the values are strongly correlated. Am I even on the right track using correlation to measure similarities? Are there any other tests that can be used to do this? corr0.89_1 = [10.7441, 8.9568, 11.0018, 9.29803, 8.92043, 8.78492, 13.5503, 6.74334, 6.14392, 5.75271, 28.851, 26.8173, 6.52642, 6.56071, 5.7169, 7.3095, 6.36379, 5.74984, 7.10243, 5.87364, 11.2827, 2.94984, 2.84836, 22.8551, 24.8372, 10.6571, 9.7891, 11.3021, 5.89328, 10.1372, 24.0525, 3.49401, 2.16394, 11.2825, 11.6859, 7.9918, 13.2742, 11.1194, 2.49575, 16.733, 27.918, 3.27145, 14.3346, 20.4979, 13.0808, 13.6282, 14.1474, 25.0414, 8.06032, 280.803, 22.0135, 18.2725, 12.9601, 7.64593] corr0.89_2 = [9.14167, 6.30561, 7.7479, 8.05475, 7.14188, 7.62774, 9.18454, 1.48037, 1.5912, 2.07612, 21.302, 22.7082, 2.67858, 2.25732, 1.74804, 2.04191, 2.03539, 1.78882, 2.57568, 1.6512, 8.62473, 2.99236, 3.13484, 13.014, 16.2016, 9.17172, 7.97379, 9.12539, 4.8298, 8.42477, 16.0582, 2.68252, 1.92429, 5.6744, 4.70516, 5.20169, 11.0945, 9.10398, 2.68375, 13.6299, 17.3429, 3.19181, 9.41762, 12.2805, 9.92005, 11.5985, 11.7269, 17.4832, 6.66996, 60.8647, 13.9616, 14.9909, 10.4712, 6.13891] corr1.0_1 = [0.00905783, 0, 0.0075662, 0, 0.00583336, 0, 0.0101741, 0.00617847, 0.00474902, 0, 0.0243326, 0.0300779, 0.0062144, 0.00581433, 0, 0.00712057, 0.00703617, 0, 0, 0, 0.0101258, 0.00844863, 0.014988, 0.0248553, 0, 0.00680134, 0.00762619, 0.00701553, 0.0106525, 0.00425654, 0.0160354, 0, 0, 0, 0, 0, 0.0110151, 0.00874536, 0, 0.0182528, 0.0291939, 0, 0.0426431, 0.0141304, 0.0139076, 0.0182638, 0.0177141, 0.021119, 0, 12.3977, 0.0121492, 0.016053, 0.0148212, 0.00767271] corr1.0_2 = [0.128504, 0.119172, 0.0403692, 0.148327, 0.132162, 0.0366454, 0.139191, 0.0464803, 0.0235099, 0.0333772, 0.0427275, 0.0510047, 0.0278845, 0.0202271, 0.0918039, 0.129276, 0.0266636, 0.0399166, 0.693549, 0.131911, 0.134276, 0, 0, 0.248764, 0.17239, 0.0450586, 0.0932654, 0.0671463, 0.239433, 0.102551, 0.378029, 0.031807, 0.0181028, 0.107356, 0.145449, 0.0735069, 0.788291, 0.496569, 0.0209139, 0.0983066, 0.0530917, 0.0755444, 0.25198, 0.550969, 0.172254, 0.104131, 0.113987, 0.548016, 0.302768, 126.145, 0.886364, 0.107977, 0.4037, 1.23249]",,"['statistics', 'correlation']"
67,Integral involving beta function (continuous version of binomial distribution),Integral involving beta function (continuous version of binomial distribution),,"I'm hoping someone can help me out with a problem that's consumed me for a while. I'm working with a continuous version of the binomial distribution defined for real $n > 0$ and continuous $0 < \mu < 1$ : $$ P(x) = n \mu^{nx} (1 - \mu)^{n - nx} \frac{\Gamma(n + 1)}{\Gamma(nx + 1) \Gamma(n - nx + 1)} $$ (The $n$ adjusts for rescaling: the binomial distribution takes in $k$ , but we take in $nx$ with $x \in [0, 1]$ .) My goal is to find a way of computing $\int_0^1 P(x)\,dx$ or $$ \int_0^1 n \mu^{nx} (1 - \mu)^{n - nx} \frac{\Gamma(n + 1)}{\Gamma(nx + 1) \Gamma(n - nx + 1)} \, dx $$ What I've tried: It's possible to convert this to the beta function and rewrite in terms of a trigonometric integral found here to get $$\int_{x=0}^1 \int_{\theta=0}^{\pi/2} \mu^{nx} (1 - \mu)^{n - nx} \frac{2^{n+1}}{\pi} \cos^n \theta \cos ((2nx - n)\theta)\,d\theta\,dx$$ Then, Mathematica eliminates $x$ and produces $$ \int_{0}^{\pi/2} \frac{2^n \cos^n \theta \left[\theta (\mu^n + (1 - \mu)^n) \sin (n\theta) + ((1 - \mu)^n - \mu^n) \tanh^{-1}(1 - 2\mu) \cos n \theta \right]}{\pi \left(\theta^2 + \left[ \tanh^{-1} (1 - 2u) \right]^2\right)} \, d\theta $$ which is a pretty interesting integral that's vaguely Bessel-esque (if you graph this for $(n, \mu) = (100, 0.5)$ it's surprising that the answer is almost exactly 1), but not something I've managed to make any progress on. It seems natural to try and transform the integral so $x, \mu$ are over a different interval than $[0, 1]$ , but nothing I've tried there has worked. This integral isn't exactly like the incomplete beta function (this is almost exactly the PDF of $\text{Beta}(\alpha = nx + 1, \beta = n(1 - x) + 1)$ applied to $\mu$ , instead of switching $\mu$ and $x$ which is what the incomplete beta function can help with.) Any ideas? I'm beat.","I'm hoping someone can help me out with a problem that's consumed me for a while. I'm working with a continuous version of the binomial distribution defined for real and continuous : (The adjusts for rescaling: the binomial distribution takes in , but we take in with .) My goal is to find a way of computing or What I've tried: It's possible to convert this to the beta function and rewrite in terms of a trigonometric integral found here to get Then, Mathematica eliminates and produces which is a pretty interesting integral that's vaguely Bessel-esque (if you graph this for it's surprising that the answer is almost exactly 1), but not something I've managed to make any progress on. It seems natural to try and transform the integral so are over a different interval than , but nothing I've tried there has worked. This integral isn't exactly like the incomplete beta function (this is almost exactly the PDF of applied to , instead of switching and which is what the incomplete beta function can help with.) Any ideas? I'm beat.","n > 0 0 < \mu < 1 
P(x) = n \mu^{nx} (1 - \mu)^{n - nx} \frac{\Gamma(n + 1)}{\Gamma(nx + 1) \Gamma(n - nx + 1)}
 n k nx x \in [0, 1] \int_0^1 P(x)\,dx 
\int_0^1 n \mu^{nx} (1 - \mu)^{n - nx} \frac{\Gamma(n + 1)}{\Gamma(nx + 1) \Gamma(n - nx + 1)} \, dx
 \int_{x=0}^1 \int_{\theta=0}^{\pi/2} \mu^{nx} (1 - \mu)^{n - nx} \frac{2^{n+1}}{\pi} \cos^n \theta \cos ((2nx - n)\theta)\,d\theta\,dx x 
\int_{0}^{\pi/2} \frac{2^n \cos^n \theta \left[\theta (\mu^n + (1 - \mu)^n) \sin (n\theta) + ((1 - \mu)^n - \mu^n) \tanh^{-1}(1 - 2\mu) \cos n \theta \right]}{\pi \left(\theta^2 + \left[ \tanh^{-1} (1 - 2u) \right]^2\right)} \, d\theta
 (n, \mu) = (100, 0.5) x, \mu [0, 1] \text{Beta}(\alpha = nx + 1, \beta = n(1 - x) + 1) \mu \mu x","['integration', 'statistics', 'definite-integrals', 'gamma-function', 'beta-function']"
68,Why do we have a conservation of probability during the transformation?,Why do we have a conservation of probability during the transformation?,,"I don't know what it is called in the literature but whenever we have a transformation of random variables (x -> y) with the probability distributions of $g(y)\  \&\ f(x)$ , we write saying that probability is equal , the following: $$ f(x)dx = g(y)dy$$ Now, y and x are related through a function, let's take it to be $J(x) = y$ . The next step is generally using the delta function for identifying the new probabilities $P(y)$ through $$ P(y) = \int dx\ \delta( y-J(x) ) f(x)  $$ Hence my two-part question: How, starting from this, I can derive the first equation logically. The general derivation treats derivatives as fractions which I don't consider to be correct. In some of the books, it is given directly. So, how does it make sense intuitively, too? Comment Since it is pointed out, the complete expression for P(y) would be $$ g(y)dy = P(y) = \int dx\ \delta( y-J(x) ) f(x)  $$","I don't know what it is called in the literature but whenever we have a transformation of random variables (x -> y) with the probability distributions of , we write saying that probability is equal , the following: Now, y and x are related through a function, let's take it to be . The next step is generally using the delta function for identifying the new probabilities through Hence my two-part question: How, starting from this, I can derive the first equation logically. The general derivation treats derivatives as fractions which I don't consider to be correct. In some of the books, it is given directly. So, how does it make sense intuitively, too? Comment Since it is pointed out, the complete expression for P(y) would be","g(y)\ 
\&\ f(x)  f(x)dx = g(y)dy J(x) = y P(y)  P(y) = \int dx\ \delta( y-J(x) ) f(x)    g(y)dy = P(y) = \int dx\ \delta( y-J(x) ) f(x)  ","['probability', 'statistics', 'probability-distributions']"
69,Find $r$ when $r>15$,Find  when,r r>15,"A light-bulb flickers after every so often in minutes, and the time taken between each flicker is recorded. In total 5 observations are counted, and the time between each has been recorded as the following: $$x_1=2.5, x_2=5.4, x_3 = 6.4, x_4 = 2.1$$ However, the 5th observation is only recorded when the time between flickers is greater than 15 minutes, so we have $x_5 > 15$ . Calculate the sample mean. Here's what I have tried: $$\frac{1}{n}\sum_{i=1}^5x_i = \frac{2.5+5.3+6.4+2.1+r}{5}=3.26+\frac{r}{5}$$ Where $r$ represents $x_5 > 15$ . However, how do I find a value for $r$ if possible? The original question asks for this distribution to find the MLE of $X \sim \exp(\lambda;x)$ . Give the MLE of $\exp(\lambda;x)$ is $\bar{x}$ , I thought the interpretation I gave would be the answer. Please let me know if an alternative approach was required!","A light-bulb flickers after every so often in minutes, and the time taken between each flicker is recorded. In total 5 observations are counted, and the time between each has been recorded as the following: However, the 5th observation is only recorded when the time between flickers is greater than 15 minutes, so we have . Calculate the sample mean. Here's what I have tried: Where represents . However, how do I find a value for if possible? The original question asks for this distribution to find the MLE of . Give the MLE of is , I thought the interpretation I gave would be the answer. Please let me know if an alternative approach was required!","x_1=2.5, x_2=5.4, x_3 = 6.4, x_4 = 2.1 x_5 > 15 \frac{1}{n}\sum_{i=1}^5x_i = \frac{2.5+5.3+6.4+2.1+r}{5}=3.26+\frac{r}{5} r x_5 > 15 r X \sim \exp(\lambda;x) \exp(\lambda;x) \bar{x}","['statistics', 'maximum-likelihood']"
70,"Assume $X_1,...,X_n$, are i.i.d, $E(X^k)=\mu_k, k=3,4$ Then sample variance satisfies $\sqrt{n}(\hat\sigma^2-\sigma^2)\to_D N(0,\alpha^2)$","Assume , are i.i.d,  Then sample variance satisfies","X_1,...,X_n E(X^k)=\mu_k, k=3,4 \sqrt{n}(\hat\sigma^2-\sigma^2)\to_D N(0,\alpha^2)","Assume $X_1,...,X_n$ , are i.i.d, $E(X_i)=\mu, Var(X_i) = \sigma^2, E(X^k)=\mu_k, k=3,4$ Then sample variance satisfies $\sqrt{n}(\hat\sigma^2-\sigma^2)\to_D N(0,\alpha^2)$ , find $\alpha$ the question doesnt say but I assume it means sample variance $\frac{1}{n}\sum_{i=1}^n (X_i-\bar X)^2$ , not divided by $n-1$ . So Central Limit Theorem gives me that $\sqrt{n}(\frac{1}{n}\sum_{i=1}^n X_i - \mu)\to_D N(0,\Sigma)$ And so from here I want to use delta method, to find some function $f$ , to take $f(\bar X)-f(\mu)=\hat\sigma^2-\sigma^2$ and then use the delta method to compute $\alpha$ I expanded $\hat\sigma^2=\frac{1}{n}\sum_{i=1}^n (X_i^2 - 2X_i \bar X +\bar X^2)=\frac{1}{n}\sum_{i=1}^n X_i^2 - \bar X^2$ I know that $\sigma^2=E(X^2)-\mu^2$ From here I'm not sure what to do, I also don't see where the condition that $E(X^k)=\mu_k, k=3,4$ would be needed.","Assume , are i.i.d, Then sample variance satisfies , find the question doesnt say but I assume it means sample variance , not divided by . So Central Limit Theorem gives me that And so from here I want to use delta method, to find some function , to take and then use the delta method to compute I expanded I know that From here I'm not sure what to do, I also don't see where the condition that would be needed.","X_1,...,X_n E(X_i)=\mu, Var(X_i) = \sigma^2, E(X^k)=\mu_k, k=3,4 \sqrt{n}(\hat\sigma^2-\sigma^2)\to_D N(0,\alpha^2) \alpha \frac{1}{n}\sum_{i=1}^n (X_i-\bar X)^2 n-1 \sqrt{n}(\frac{1}{n}\sum_{i=1}^n X_i - \mu)\to_D N(0,\Sigma) f f(\bar X)-f(\mu)=\hat\sigma^2-\sigma^2 \alpha \hat\sigma^2=\frac{1}{n}\sum_{i=1}^n (X_i^2 - 2X_i \bar X +\bar X^2)=\frac{1}{n}\sum_{i=1}^n X_i^2 - \bar X^2 \sigma^2=E(X^2)-\mu^2 E(X^k)=\mu_k, k=3,4","['probability', 'statistics', 'central-limit-theorem']"
71,Ratio of Poisson Distributions (Possible mistake on exams by instructor),Ratio of Poisson Distributions (Possible mistake on exams by instructor),,"I found the following on a practice final of one of my students and it does not seem to add up. Let $X_1, X_2, \dots, X_n$ be a random sample from a Poisson distribution $f(k\vert \theta) = \frac{e^{-\theta}\theta^k}{k!}$ where $k \in \mathbb{N}$ . Show that $S(X)= \frac{X_1}{\sum_{i=1}^n X_i}$ is an ancillary statistic (i.e. its distribution does not depend on $\theta$ ). I think what they have in mind is that the above expression is scale invariant which it is. The issue is however twofold: $S$ is not well defined when $X_1 = X_2 = \dots = X_n = 0$ which happens with non-zero probability. The scale invariant property of the expression is not sufficient. One also needs to show that the $X_i$ 's follow what is known as the scale model, namely there are Random Variables $W_i$ which do NOT depend on $\theta$ and a constant $c$ such that: $X_i = cW_i$ . To my knowledge this is not the case for Poisson. Is this a case of a simple oversight or am I missing something obvious? (Note: This is a standard graduate course in statistics where students are expected to identify various kinds of statistics (sufficient, complete, ancillary etc) and apply these ideas to relevant theorems such as Basu's theorem.)","I found the following on a practice final of one of my students and it does not seem to add up. Let be a random sample from a Poisson distribution where . Show that is an ancillary statistic (i.e. its distribution does not depend on ). I think what they have in mind is that the above expression is scale invariant which it is. The issue is however twofold: is not well defined when which happens with non-zero probability. The scale invariant property of the expression is not sufficient. One also needs to show that the 's follow what is known as the scale model, namely there are Random Variables which do NOT depend on and a constant such that: . To my knowledge this is not the case for Poisson. Is this a case of a simple oversight or am I missing something obvious? (Note: This is a standard graduate course in statistics where students are expected to identify various kinds of statistics (sufficient, complete, ancillary etc) and apply these ideas to relevant theorems such as Basu's theorem.)","X_1, X_2, \dots, X_n f(k\vert \theta) = \frac{e^{-\theta}\theta^k}{k!} k \in \mathbb{N} S(X)= \frac{X_1}{\sum_{i=1}^n X_i} \theta S X_1 = X_2 = \dots = X_n = 0 X_i W_i \theta c X_i = cW_i","['statistics', 'poisson-distribution']"
72,Creating a probability density function for a particular dataset [closed],Creating a probability density function for a particular dataset [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I want to create a probability density function for a particular dataset. First of all, I calculate the mean and the variance of my dataset. So, I use the mean and the variance to create a probability density function, for example, Gaussian distribution. Is my thinking correct?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I want to create a probability density function for a particular dataset. First of all, I calculate the mean and the variance of my dataset. So, I use the mean and the variance to create a probability density function, for example, Gaussian distribution. Is my thinking correct?",,"['probability', 'statistics', 'probability-distributions', 'data-analysis']"
73,How to determine power of a test of the difference of two binomial proportions?,How to determine power of a test of the difference of two binomial proportions?,,"Consider a sample of 800 adults with wrist fracture where 400 are provided an operative treatment and 400 are provided physiotherapy only. Outcome of interest is whether the wrist is fully healed after 6 months. What power will a hypothesis test possess to detect a 10% improvement in the operative cohort, assuming 50% of the physiotherapy cohort are fully healed at 6 months? My attempt (assuming $\alpha = 0.05$ ): A 10% improvement would mean the proportion difference (test statistic) between the two therapies: $$\theta = p_2 - p_1 = \frac{240}{400} - \frac{200}{400} = 0.1$$ Thus, we have two sample distributions for $\theta$ . One is the null hypothesis where there is no difference between the therapies and the mean, $\bar{\theta_1}$ , is $0$ . The other distribution is where $\bar{\theta_2}$ , is $0.1$ . Here is an illustration: This is the point where I got stuck. Usually, in these types of questions I'm told that we are sampling from a normally distributed population with a known standard deviation so I can use Z statistic ( $1.64$ ) to determine the rejection threshold for the null hypothesis and go from there. However, here we are reliant on sampling two distributions (physio + operative) that I assume to be binomially distributed. Thus, the variance of the black and red curves (null vs alternate hypothesis) would be the sum of the variances from the two underlying distributions: $$Var(\theta) = \frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}$$ How do I proceed from here? Can we assume the sample distributions are normally distributed? If so, I can use the Z statistic with the null distribution: $$1.96 = \frac{\theta - 0}{\sqrt{2\frac{p_1(1-p_1)}{n_1}}}$$ Edit: This question was inspired by the example in this video starting at 50:47 . I don't understand the reasoning behind his steps and I tried to break it down using the approach I was more familiar with.","Consider a sample of 800 adults with wrist fracture where 400 are provided an operative treatment and 400 are provided physiotherapy only. Outcome of interest is whether the wrist is fully healed after 6 months. What power will a hypothesis test possess to detect a 10% improvement in the operative cohort, assuming 50% of the physiotherapy cohort are fully healed at 6 months? My attempt (assuming ): A 10% improvement would mean the proportion difference (test statistic) between the two therapies: Thus, we have two sample distributions for . One is the null hypothesis where there is no difference between the therapies and the mean, , is . The other distribution is where , is . Here is an illustration: This is the point where I got stuck. Usually, in these types of questions I'm told that we are sampling from a normally distributed population with a known standard deviation so I can use Z statistic ( ) to determine the rejection threshold for the null hypothesis and go from there. However, here we are reliant on sampling two distributions (physio + operative) that I assume to be binomially distributed. Thus, the variance of the black and red curves (null vs alternate hypothesis) would be the sum of the variances from the two underlying distributions: How do I proceed from here? Can we assume the sample distributions are normally distributed? If so, I can use the Z statistic with the null distribution: Edit: This question was inspired by the example in this video starting at 50:47 . I don't understand the reasoning behind his steps and I tried to break it down using the approach I was more familiar with.",\alpha = 0.05 \theta = p_2 - p_1 = \frac{240}{400} - \frac{200}{400} = 0.1 \theta \bar{\theta_1} 0 \bar{\theta_2} 0.1 1.64 Var(\theta) = \frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2} 1.96 = \frac{\theta - 0}{\sqrt{2\frac{p_1(1-p_1)}{n_1}}},"['probability', 'statistics', 'probability-distributions', 'hypothesis-testing']"
74,Possible range of correlation between two random variables,Possible range of correlation between two random variables,,"I was given this question in a job interview and I wasn't sure how to answer it. Suppose you have two random variables, $X,Y$ . Let us say that $X=1$ with probability $50\%$ and $0$ otherwise, $Y=1$ with probability of $30\%$ and $0$ otherwise. The first question was what is the range of probabilities for the event $X=1 ,Y=1$ ? The answer to that would be from $0\%$ to $30\%$ , so this is not the focus of my question The second question, which I was unsure of, is the following - what is the range of the correlation between both variables? The standard formula for correlation seemed quite unhelpful, especially since the question wasn't phrased like that with 0 and 1 (it was framed in the sense that $X$ or $Y$ occurred or did not occur)","I was given this question in a job interview and I wasn't sure how to answer it. Suppose you have two random variables, . Let us say that with probability and otherwise, with probability of and otherwise. The first question was what is the range of probabilities for the event ? The answer to that would be from to , so this is not the focus of my question The second question, which I was unsure of, is the following - what is the range of the correlation between both variables? The standard formula for correlation seemed quite unhelpful, especially since the question wasn't phrased like that with 0 and 1 (it was framed in the sense that or occurred or did not occur)","X,Y X=1 50\% 0 Y=1 30\% 0 X=1 ,Y=1 0\% 30\% X Y","['probability', 'statistics']"
75,Measurement Errors in Gaussian Process,Measurement Errors in Gaussian Process,,"If we consider a Gaussian process for one-dimensional variable $$ S(X) \sim GP(\mu,\sigma^2K), $$ where $K$ is the exponential kernel ( $K(x,y) = e^{-\frac{||x-y||_2}{\phi}}$ ), I am wondering how can we find a new process $R(x)$ that $$  R(x) = \frac{1}{2\theta}\int_{x-\theta}^{x+\theta}S(z)dz $$ and figure out its mean, variance, and kernel function?","If we consider a Gaussian process for one-dimensional variable where is the exponential kernel ( ), I am wondering how can we find a new process that and figure out its mean, variance, and kernel function?","
S(X) \sim GP(\mu,\sigma^2K),
 K K(x,y) = e^{-\frac{||x-y||_2}{\phi}} R(x)  
R(x) = \frac{1}{2\theta}\int_{x-\theta}^{x+\theta}S(z)dz
","['probability', 'statistics', 'stochastic-processes']"
76,"Verifying a simple method to use $U(0,1)$ random generators with the CLT to sample from $N(0, 1)$",Verifying a simple method to use  random generators with the CLT to sample from,"U(0,1) N(0, 1)","I am trying to understand an approach that was discussed in my pattern recognition class today of using uniform random variables, which can be sampled using some random generator, to obtain samples that are approximately $N(0,1)$ . Unfortunately there were no notes given so I wish to reproduce what my professor said from my understanding. Knowing that for random variables $X \sim U(0, 1)$ we have $\mu_{X} = 0.5, \sigma_{X}^2 = \frac{1}{12}$ , then consider a random variable $$Y = (\sum_{i=0}^{12} X_i) - 6 $$ $Y$ has $u_{Y}= 0, \sigma_{Y}^2 = 1$ . Now I wish to use the Central Limit Theorem (CLT), where according to the Lindeberg-Levy version of the CLT, if $\{X_1, \ldots, X_n \}$ is a sequence of i.i.d random variables with $\mathbb{E}[X_i] = \mu$ , and $Var[X_i] = \sigma^2 \leq \infty$ , then as $n$ approaches infinite, the random variables $\sqrt{n}(\bar{X} - \mu) $ converges to $N(0, \sigma^2)$ . Then as far as I understand it, by taking $n$ samples of $Y$ , we would have, for sufficiently large $n$ , that $\sqrt{n} * \bar{Y} \sim N(0, 1)$ . Is this algorithm correct? I also see in the wikipedia entry here (the computational methods section) that they do something similar: ""Generate $12$ uniform $U(0,1)$ deviates, add them all up, and subtract $6$ – the resulting random variable will have approximately standard normal distribution"", but they do not further average these values and multiply by $\sqrt{n}$ , so how does the CLT apply here? I'm trying to think why it would be inefficient as well?, but these seem to be pretty simple computations, in python ... import random import math import numpy as np  def get_y_bar(num_samples=50):     y_bar = 0     for i in range(num_samples):         y_bar += sample_y()     y_bar /= num_samples     y_bar *= math.sqrt(num_samples)     return y_bar  def sample_y():     y = 0     for i in range(12):         y += random.random()     y -= 6     return y  def sample_normal(N=100000):     sample_list = []     for i in range(N):         sample_list.append(get_y_bar())     sample_list = np.array(sample_list)     sample_mean = np.mean(sample_list)     sample_std = np.std(sample_list)     print(f""The sample mean is {sample_mean}, and the sample std is {sample_std}"")  sample_normal() With output: The sample mean is $-0.0015446492547001867$ , and the sample std is $0.9989513839711084$ , which is pretty close, about $2$ digits of precision off from the theoretical idea.","I am trying to understand an approach that was discussed in my pattern recognition class today of using uniform random variables, which can be sampled using some random generator, to obtain samples that are approximately . Unfortunately there were no notes given so I wish to reproduce what my professor said from my understanding. Knowing that for random variables we have , then consider a random variable has . Now I wish to use the Central Limit Theorem (CLT), where according to the Lindeberg-Levy version of the CLT, if is a sequence of i.i.d random variables with , and , then as approaches infinite, the random variables converges to . Then as far as I understand it, by taking samples of , we would have, for sufficiently large , that . Is this algorithm correct? I also see in the wikipedia entry here (the computational methods section) that they do something similar: ""Generate uniform deviates, add them all up, and subtract – the resulting random variable will have approximately standard normal distribution"", but they do not further average these values and multiply by , so how does the CLT apply here? I'm trying to think why it would be inefficient as well?, but these seem to be pretty simple computations, in python ... import random import math import numpy as np  def get_y_bar(num_samples=50):     y_bar = 0     for i in range(num_samples):         y_bar += sample_y()     y_bar /= num_samples     y_bar *= math.sqrt(num_samples)     return y_bar  def sample_y():     y = 0     for i in range(12):         y += random.random()     y -= 6     return y  def sample_normal(N=100000):     sample_list = []     for i in range(N):         sample_list.append(get_y_bar())     sample_list = np.array(sample_list)     sample_mean = np.mean(sample_list)     sample_std = np.std(sample_list)     print(f""The sample mean is {sample_mean}, and the sample std is {sample_std}"")  sample_normal() With output: The sample mean is , and the sample std is , which is pretty close, about digits of precision off from the theoretical idea.","N(0,1) X \sim U(0, 1) \mu_{X} = 0.5, \sigma_{X}^2 = \frac{1}{12} Y = (\sum_{i=0}^{12} X_i) - 6  Y u_{Y}= 0, \sigma_{Y}^2 = 1 \{X_1, \ldots, X_n \} \mathbb{E}[X_i] = \mu Var[X_i] = \sigma^2 \leq \infty n \sqrt{n}(\bar{X} - \mu)  N(0, \sigma^2) n Y n \sqrt{n} * \bar{Y} \sim N(0, 1) 12 U(0,1) 6 \sqrt{n} -0.0015446492547001867 0.9989513839711084 2",['statistics']
77,Why do we approximate sample stdev using sample stdev / sqrt(n) when population stdev is unknown? [closed],Why do we approximate sample stdev using sample stdev / sqrt(n) when population stdev is unknown? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question In this stackoverflow stdev estimation question , we are discussing about when to use z-distribution and t-distribution. Now, I'm getting confused here why are we taking the indirect & apparently longer path for finding sample z-score? For a given set of sample and population, $sample \ z_{score}= \frac{x - \mu_{sample}}{\sigma_{sample}}$ . Now, we go around to estimate $\sigma_{sample} = \frac{\sigma_{population}}{\sqrt{n}} \ \ \ \ \ \ \  ... [1]\ $ where $n$ = sample size. Now, my question is following: If we want $\sigma_{sample}$ , why not simply find it using formula: $$\sigma = \frac{\sum_{i=1}^{n}(x_{i}-\mu)^2}{N-1}$$ Also, this will be having a different answer from our estimation [1]'s $\sqrt{n}$ factor. Please help me if I'm missing something major over here.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question In this stackoverflow stdev estimation question , we are discussing about when to use z-distribution and t-distribution. Now, I'm getting confused here why are we taking the indirect & apparently longer path for finding sample z-score? For a given set of sample and population, . Now, we go around to estimate where = sample size. Now, my question is following: If we want , why not simply find it using formula: Also, this will be having a different answer from our estimation [1]'s factor. Please help me if I'm missing something major over here.",sample \ z_{score}= \frac{x - \mu_{sample}}{\sigma_{sample}} \sigma_{sample} = \frac{\sigma_{population}}{\sqrt{n}} \ \ \ \ \ \ \  ... [1]\  n \sigma_{sample} \sigma = \frac{\sum_{i=1}^{n}(x_{i}-\mu)^2}{N-1} \sqrt{n},"['probability', 'statistics', 'standard-deviation']"
78,$ \frac{(1+o_p(1) )A_n}{(1+o(1) )E[A_n]}=\frac{A_n}{E[A_n]}+ o_p(\frac{A_n}{E[A_n]}) ??$,, \frac{(1+o_p(1) )A_n}{(1+o(1) )E[A_n]}=\frac{A_n}{E[A_n]}+ o_p(\frac{A_n}{E[A_n]}) ??,"I was reading a paper and in it, they stated for a random sequence $ A_n=\Theta(1)$ , $$ \frac{(1+o_p(1) )A_n}{(1+o(1) )E[A_n]}=\frac{A_n}{E[A_n]}+ o_p(\frac{A_n}{E[A_n]}) ??$$ without any proof. Although seemingly intuitive, I couldnt come up with a proof, and this actually is a crucial step, so I wanted to make sure. Also, if possible, can you tell me if there is a easy way to estimate the precise order of $ o_p(\frac{A_n}{E[A_n]}) $ ,other than actually calculating $ \frac{(1+o_p(1) )A_n}{(1+o(1) )E[A_n]}-\frac{A_n}{E[A_n]}$ ,which is quite tedious in this case. Thanks beforehand.","I was reading a paper and in it, they stated for a random sequence , without any proof. Although seemingly intuitive, I couldnt come up with a proof, and this actually is a crucial step, so I wanted to make sure. Also, if possible, can you tell me if there is a easy way to estimate the precise order of ,other than actually calculating ,which is quite tedious in this case. Thanks beforehand.", A_n=\Theta(1)  \frac{(1+o_p(1) )A_n}{(1+o(1) )E[A_n]}=\frac{A_n}{E[A_n]}+ o_p(\frac{A_n}{E[A_n]}) ??  o_p(\frac{A_n}{E[A_n]})   \frac{(1+o_p(1) )A_n}{(1+o(1) )E[A_n]}-\frac{A_n}{E[A_n]},"['probability', 'statistics', 'notation', 'probability-limit-theorems']"
79,Integral-sum conversion in the proof that the $\chi^2$ statistic tends to the $\chi^2$ distribution,Integral-sum conversion in the proof that the  statistic tends to the  distribution,\chi^2 \chi^2,"I cite the derivation on Wikipedia, here . The focus of that section of the article is to show that the $\chi_p^2$ statistic is asymptotically equivalent to the $\chi^2$ distribution. Let $n$ be the number of observations, $m$ the number of cells and $p_i$ the probability of an observation (according to the null hypothesis of the supposed underlying distribution) falling in the $i$ th cell, $1\le i\le m$ . Let $\{k_i\}$ denote the configuration where $k_i$ occurences are observed in the $i$ th cell. Let $\chi^2_p(\{k_i\},\{p_i\})$ denote the test statistic, and let $\chi^2_p(\{p_i\})$ denote its distribution. For any arbitrary real $T$ , assuming that observations are multinomially distributed by the supposed underlying distribution: $$P(\chi^2_p(\{p_i\})\gt T)=\sum_{\{k_i\}:\chi^2_p(\{k_i\},\{p_i\})\gt T}\frac{n!}{k_1!\cdots k_m!}\prod_{i=1}^mp_i^{k_i}$$ As $n\to\infty$ , one may use Stirling's approximation for the factorial: $$P(\chi^2_p(\{p_i\})\gt T)\sim\sqrt{\frac{2\pi n}{\prod_{i=1}^m2\pi k_i}}\sum_{\{k_i\}:\chi^2_p(\{k_i\},\{p_i\})\gt T}\prod_{i=1}^m\left(\frac{n p_i}{k_i}\right)^{k_i}$$ With the substitution $x_i=\frac{k_i-np_i}{\sqrt{n}},\,1\le i\le m-1$ and noting that $k_m=np_m-\sqrt{n}\sum_{i=1}^{m-1}x_i$ , one finds: $$\begin{align}P(\chi^2_p(\{p_i\})\gt T)&\sim\sqrt{\frac{2\pi n}{\prod_{i=1}^m2\pi k_i}}\sum_{\{x_i\}:\chi^2_p(\{x_i\sqrt{n}+np_i\},\{p_i\})\gt T}\\&\left\{\left(1-\frac{\sum_{i=1}^{m-1}x_i}{p_m\sqrt{n}}\right)^{-(np_m-\sqrt{n}\sum_{i=1}^mx_i)}\prod_{i=1}^{m-1}\left(1+\frac{x_i}{p_i\sqrt{n}}\right)^{-(np_i+x_i\sqrt{n})}\right\}\end{align}$$ Ugly as this is so far, I have no problems. However, as $n\to\infty$ , Wikipedia pass from the above sum to an $(m-1)$ dimensional integral over the $x_i$ , with everything unchanged save for an extra (mystifying) factor of: $$\prod_{i=1}^{m-1}\left(\sqrt{n}\,\mathrm{d}x_i\right)$$ $$\begin{align}P(\chi^2_p(\{p_i\})\gt T)\sim\sqrt{\frac{2\pi n}{\prod_{i=1}^m2\pi k_i}}\color{red}{\int_{\chi^2_p(\{x_i\sqrt{n}+np_i\},\{p_i\})\gt T}}\hspace{100pt}\\\left\{\left(1-\frac{\sum_{i=1}^{m-1}x_i}{p_m\sqrt{n}}\right)^{-(np_m-\sqrt{n}\sum_{i=1}^mx_i)}\prod_{i=1}^{m-1}\left(1+\frac{x_i}{p_i\sqrt{n}}\right)^{-(np_i+x_i\sqrt{n})}\right\}\color{red}{\left\{\prod_{i=1}^{m-1}\sqrt{n}\,\mathrm{d}x_i\right\}}\end{align}$$ This step I don't understand. That extra factor suggests that $\mathrm{d}x_i\sim\frac{1}{\sqrt{n}}$ , but how can this be formalised? Or is it that, under the null hypothesis, $k_i-np_i\approx0$ as $n\to\infty$ ? In passing from a sum over discrete variables to a continuous integral, work must be done and the article's authors have not provided it. If anyone could help me see how the above sum transforms to an $m-1$ dimensional Riemann sum, with limiting difference $\sqrt{n}\mathrm{d}x_i$ , that would be greatly appreciated. I understand that we can change our perspective and view the $x_i$ as a free ranging variable. I guess I just don't get the meaning of the symbol $\mathrm{d}x_i$ in this context.","I cite the derivation on Wikipedia, here . The focus of that section of the article is to show that the statistic is asymptotically equivalent to the distribution. Let be the number of observations, the number of cells and the probability of an observation (according to the null hypothesis of the supposed underlying distribution) falling in the th cell, . Let denote the configuration where occurences are observed in the th cell. Let denote the test statistic, and let denote its distribution. For any arbitrary real , assuming that observations are multinomially distributed by the supposed underlying distribution: As , one may use Stirling's approximation for the factorial: With the substitution and noting that , one finds: Ugly as this is so far, I have no problems. However, as , Wikipedia pass from the above sum to an dimensional integral over the , with everything unchanged save for an extra (mystifying) factor of: This step I don't understand. That extra factor suggests that , but how can this be formalised? Or is it that, under the null hypothesis, as ? In passing from a sum over discrete variables to a continuous integral, work must be done and the article's authors have not provided it. If anyone could help me see how the above sum transforms to an dimensional Riemann sum, with limiting difference , that would be greatly appreciated. I understand that we can change our perspective and view the as a free ranging variable. I guess I just don't get the meaning of the symbol in this context.","\chi_p^2 \chi^2 n m p_i i 1\le i\le m \{k_i\} k_i i \chi^2_p(\{k_i\},\{p_i\}) \chi^2_p(\{p_i\}) T P(\chi^2_p(\{p_i\})\gt T)=\sum_{\{k_i\}:\chi^2_p(\{k_i\},\{p_i\})\gt T}\frac{n!}{k_1!\cdots k_m!}\prod_{i=1}^mp_i^{k_i} n\to\infty P(\chi^2_p(\{p_i\})\gt T)\sim\sqrt{\frac{2\pi n}{\prod_{i=1}^m2\pi k_i}}\sum_{\{k_i\}:\chi^2_p(\{k_i\},\{p_i\})\gt T}\prod_{i=1}^m\left(\frac{n p_i}{k_i}\right)^{k_i} x_i=\frac{k_i-np_i}{\sqrt{n}},\,1\le i\le m-1 k_m=np_m-\sqrt{n}\sum_{i=1}^{m-1}x_i \begin{align}P(\chi^2_p(\{p_i\})\gt T)&\sim\sqrt{\frac{2\pi n}{\prod_{i=1}^m2\pi k_i}}\sum_{\{x_i\}:\chi^2_p(\{x_i\sqrt{n}+np_i\},\{p_i\})\gt T}\\&\left\{\left(1-\frac{\sum_{i=1}^{m-1}x_i}{p_m\sqrt{n}}\right)^{-(np_m-\sqrt{n}\sum_{i=1}^mx_i)}\prod_{i=1}^{m-1}\left(1+\frac{x_i}{p_i\sqrt{n}}\right)^{-(np_i+x_i\sqrt{n})}\right\}\end{align} n\to\infty (m-1) x_i \prod_{i=1}^{m-1}\left(\sqrt{n}\,\mathrm{d}x_i\right) \begin{align}P(\chi^2_p(\{p_i\})\gt T)\sim\sqrt{\frac{2\pi n}{\prod_{i=1}^m2\pi k_i}}\color{red}{\int_{\chi^2_p(\{x_i\sqrt{n}+np_i\},\{p_i\})\gt T}}\hspace{100pt}\\\left\{\left(1-\frac{\sum_{i=1}^{m-1}x_i}{p_m\sqrt{n}}\right)^{-(np_m-\sqrt{n}\sum_{i=1}^mx_i)}\prod_{i=1}^{m-1}\left(1+\frac{x_i}{p_i\sqrt{n}}\right)^{-(np_i+x_i\sqrt{n})}\right\}\color{red}{\left\{\prod_{i=1}^{m-1}\sqrt{n}\,\mathrm{d}x_i\right\}}\end{align} \mathrm{d}x_i\sim\frac{1}{\sqrt{n}} k_i-np_i\approx0 n\to\infty m-1 \sqrt{n}\mathrm{d}x_i x_i \mathrm{d}x_i","['integration', 'statistics', 'solution-verification', 'riemann-sum', 'chi-squared']"
80,How do you check if a die is fair using the posterior probability density function?,How do you check if a die is fair using the posterior probability density function?,,"I want to understand how to check if one die is fair using the posterior probability density function, similarly to how a coin is checked in this manner here . To do this, I am assuming that the die has a multinomial distribution, giving the probability density function as: $$P=\frac{n!}{(n_1!)(n_2!)\cdots(n_x!)}p_1^{n_1}p_2^{n_2}\cdots p_x^{n_x}$$ where $n$ is the number of events, $n_x$ is the number of outcomes of event $x$ and $p_x$ is the probability of event $x$ happening. For the sake of the example, let's assume that we have a 3-sided die with letters $A$ , $B$ and $C$ respectively on each face and we want to check whether it is fair. Let's say that we have thrown the die 9 times and the outcomes were the following: Face   Count A      2 B      4 C      3 Now, following this Wikipedia article we would need to create something along the lines of: $$f(a\mid A=2,B=4,C=3)=\frac{9!}{(2!)(4!)(3!)}a^2b^4c^3$$ where $a$ , $b$ and $c$ are the probabilities of the faces $A$ , $B$ and $C$ showing up respectively. When there are only two cases, this can be solved since the parameters $b$ and $c$ would be represented by $(1-a)$ . However, in this case I am stuck and do not know how to proceed.","I want to understand how to check if one die is fair using the posterior probability density function, similarly to how a coin is checked in this manner here . To do this, I am assuming that the die has a multinomial distribution, giving the probability density function as: where is the number of events, is the number of outcomes of event and is the probability of event happening. For the sake of the example, let's assume that we have a 3-sided die with letters , and respectively on each face and we want to check whether it is fair. Let's say that we have thrown the die 9 times and the outcomes were the following: Face   Count A      2 B      4 C      3 Now, following this Wikipedia article we would need to create something along the lines of: where , and are the probabilities of the faces , and showing up respectively. When there are only two cases, this can be solved since the parameters and would be represented by . However, in this case I am stuck and do not know how to proceed.","P=\frac{n!}{(n_1!)(n_2!)\cdots(n_x!)}p_1^{n_1}p_2^{n_2}\cdots p_x^{n_x} n n_x x p_x x A B C f(a\mid A=2,B=4,C=3)=\frac{9!}{(2!)(4!)(3!)}a^2b^4c^3 a b c A B C b c (1-a)","['probability', 'statistics', 'statistical-inference', 'bayesian']"
81,Probability - Am I understanding the problem correctly (Part II)?,Probability - Am I understanding the problem correctly (Part II)?,,"The problem It is given that a certain type of battery has a mean shelf life of $30$ months with a standard deviation of $3$ months. For a randomly selected battery let 𝑋 denote the lifetime of the battery. Assuming a normal distribution: $$X\sim\mathcal{N}(30,9).$$ The question asks to estimate how long $90\%$ of batteries are expected to last. The solution(?) The probability that a randomly selected battery has a lifetime of $\approx2.18$ years can be evaluated as $$p=\mathbb P(X>2.18)=\mathbb P(Z>-1.28)=0.9$$ where $Z$ is a standard normal random variable. I'm uncertain as to why (or why not) $2.18$ years is the estimate of how long $90\%$ of batteries are expected to last. Please advise. Thanks.",The problem It is given that a certain type of battery has a mean shelf life of months with a standard deviation of months. For a randomly selected battery let 𝑋 denote the lifetime of the battery. Assuming a normal distribution: The question asks to estimate how long of batteries are expected to last. The solution(?) The probability that a randomly selected battery has a lifetime of years can be evaluated as where is a standard normal random variable. I'm uncertain as to why (or why not) years is the estimate of how long of batteries are expected to last. Please advise. Thanks.,"30 3 X\sim\mathcal{N}(30,9). 90\% \approx2.18 p=\mathbb P(X>2.18)=\mathbb P(Z>-1.28)=0.9 Z 2.18 90\%","['probability', 'statistics', 'normal-distribution']"
82,"""Magic"" numbers are those divided by all partial digit sums: prove that there is no infinite set of ""magic"" powers among the natural powers of $\ell$","""Magic"" numbers are those divided by all partial digit sums: prove that there is no infinite set of ""magic"" powers among the natural powers of",\ell,"For a natural number $n$ , let $P_n$ the set of sums of each subset of digits in decimal notation of $n$ . A number is magic if for each $s \in P_n$ , we have $s \ | \ n$ . Let's consider a number $\ell$ , not divisible by $10$ . Then, only a finite number of natural powers of $\ell$ are magic. My approach : Proof by contradiction principle - logic formalism principle : $$(\neg q \to \neg p) \leftrightarrow (p \to q)$$ In an infinite set $I$ of natural powers, we have, by combinatorics principles (I think Wan der Waerden?), there is an arbitrary long arithmetic progression in the exponents. So, therefore, considering an ""almost infinite"" progression (enough long), I'm thinking to find here a contradiction, as arithmetic progressions at the exponents do mean geometric progressions, therefore constant ratios. I've read also some papers ( statistical approach ), that are trying to find the lower bound for number of specific digits (i. e. number of $1$ s) in powers. And, therefore, try to find divisors that are mandatory in $P_{a^k}$ , where $k$ is large enoungh, and here we got a contradiction, as the only divisors of $a_k$ are the powers of divisors of $a$ . However, statistical approach is not a rigurous mathematical proof, at least for my purpose, so, those assumptions could be no more than conjectures about the problem. Please give me a hint! Any help would be appreciated. Update: As @Vepir mentioned, ""magic"" numbers are super Nieven numbers.","For a natural number , let the set of sums of each subset of digits in decimal notation of . A number is magic if for each , we have . Let's consider a number , not divisible by . Then, only a finite number of natural powers of are magic. My approach : Proof by contradiction principle - logic formalism principle : In an infinite set of natural powers, we have, by combinatorics principles (I think Wan der Waerden?), there is an arbitrary long arithmetic progression in the exponents. So, therefore, considering an ""almost infinite"" progression (enough long), I'm thinking to find here a contradiction, as arithmetic progressions at the exponents do mean geometric progressions, therefore constant ratios. I've read also some papers ( statistical approach ), that are trying to find the lower bound for number of specific digits (i. e. number of s) in powers. And, therefore, try to find divisors that are mandatory in , where is large enoungh, and here we got a contradiction, as the only divisors of are the powers of divisors of . However, statistical approach is not a rigurous mathematical proof, at least for my purpose, so, those assumptions could be no more than conjectures about the problem. Please give me a hint! Any help would be appreciated. Update: As @Vepir mentioned, ""magic"" numbers are super Nieven numbers.",n P_n n s \in P_n s \ | \ n \ell 10 \ell (\neg q \to \neg p) \leftrightarrow (p \to q) I 1 P_{a^k} k a_k a,"['number-theory', 'elementary-number-theory', 'statistics', 'arithmetic-progressions', 'geometric-progressions']"
83,What kind of calculations cause the sum of survey percentages to be greater than 100%?,What kind of calculations cause the sum of survey percentages to be greater than 100%?,,"I was looking at this Facts and Figures page for Mount San Antonio College and saw this note for the Age breakdown of the school: * note: Numbers do not add up to 100 because some students selected ""unknown"" or chose not to respond. This is the data: Age 24.55% 19 or less 34.77% 20 to 24 13.88% 25 to 29 6.04% 30 to 34 3.65% 35 to 39 5.78% 40 to 49 12.30% 50+ The sum of these percentages is 100.97%. I tried to scale them back down by dividing through by 1.0097 but I don't think this ""undoes"" the voodoo the original researches did. My question is, what were they doing to the data that would cause these percentages to be inflated? I could guess but I can't rationalize it and I definitely can't test it because I don't have the data. It wouldn't be hard to experiment with a fake survey (i.e. the same question, but fewer respondents with 1 non-response), but what makes an adjustment the ""correct"" adjustment? How would we know? EDIT: Ok, what it looks like this is a situation where the survey results were ""weighted"" to account for non-responses. I found a really nasty PDF writeup called Designing Surveys to Account for Endogenous Non-Response . I can't understand (can't apply) this at all. I dropped out of grad school and this writeup seems to assume I know a lot about Stats or complicated use-cases that I don't. Can somebody explain in this context? Is a model this complex even relevant? Are survey weights non-reversible without the original data (different, less-important question)? EDIT2: HOLY-POOP, THEY'RE TALKING ABOUT THIS ON NPR RIGHT NOW! (not the nitty-gritty calculations though, just the social cost)","I was looking at this Facts and Figures page for Mount San Antonio College and saw this note for the Age breakdown of the school: * note: Numbers do not add up to 100 because some students selected ""unknown"" or chose not to respond. This is the data: Age 24.55% 19 or less 34.77% 20 to 24 13.88% 25 to 29 6.04% 30 to 34 3.65% 35 to 39 5.78% 40 to 49 12.30% 50+ The sum of these percentages is 100.97%. I tried to scale them back down by dividing through by 1.0097 but I don't think this ""undoes"" the voodoo the original researches did. My question is, what were they doing to the data that would cause these percentages to be inflated? I could guess but I can't rationalize it and I definitely can't test it because I don't have the data. It wouldn't be hard to experiment with a fake survey (i.e. the same question, but fewer respondents with 1 non-response), but what makes an adjustment the ""correct"" adjustment? How would we know? EDIT: Ok, what it looks like this is a situation where the survey results were ""weighted"" to account for non-responses. I found a really nasty PDF writeup called Designing Surveys to Account for Endogenous Non-Response . I can't understand (can't apply) this at all. I dropped out of grad school and this writeup seems to assume I know a lot about Stats or complicated use-cases that I don't. Can somebody explain in this context? Is a model this complex even relevant? Are survey weights non-reversible without the original data (different, less-important question)? EDIT2: HOLY-POOP, THEY'RE TALKING ABOUT THIS ON NPR RIGHT NOW! (not the nitty-gritty calculations though, just the social cost)",,['statistics']
84,Probability that sum of digits of random numbers matches.,Probability that sum of digits of random numbers matches.,,"Given two random 9-digit numbers (with the standard assumptions), what is the probability that the sum of their digits match? I saw this , and it seemed extremely relevant. Also, how does the answer change if we work in different number systems, or allow for ""digits"" which range from 35 to 54 (e.g., 38 is allowed to be a digit)? Edit for context : My motivation is strictly intellectual curiosity. My first attempt to solve this problem didn't get very far; I thought the answer might be solved by simple counting and elementary probability. The fact that we are working with sums, and not just the digits themselves though, seemed to complicate things for me. I linked a thread because the general topic of my question (about the sums of digits of random numbers) is directly addressed in that thread (but my exact question is not), showing that I did research and am trying to in good faith spur discussion. I think my question is interesting enough to warrant a thread despite me being clueless (for the most part) as to how to proceed.","Given two random 9-digit numbers (with the standard assumptions), what is the probability that the sum of their digits match? I saw this , and it seemed extremely relevant. Also, how does the answer change if we work in different number systems, or allow for ""digits"" which range from 35 to 54 (e.g., 38 is allowed to be a digit)? Edit for context : My motivation is strictly intellectual curiosity. My first attempt to solve this problem didn't get very far; I thought the answer might be solved by simple counting and elementary probability. The fact that we are working with sums, and not just the digits themselves though, seemed to complicate things for me. I linked a thread because the general topic of my question (about the sums of digits of random numbers) is directly addressed in that thread (but my exact question is not), showing that I did research and am trying to in good faith spur discussion. I think my question is interesting enough to warrant a thread despite me being clueless (for the most part) as to how to proceed.",,"['probability', 'statistics', 'discrete-mathematics']"
85,Why do waiting times in a queue tend to follow a gamma distribution?,Why do waiting times in a queue tend to follow a gamma distribution?,,"I’m trying to get an intuition for gamma distributions, and why they are the model of choice for waiting times. In addition, I’d love to hear about any other distributions that are useful for modeling wait times for the same reason. I’d say I’ve got a pretty solid understanding of why everyday random variables tend to follow a normal distribution. If you drop balls into a line of tubes from above, Galton board style, you’ll tend to see them arrange into a normal distribution. Add pegs to provide something for the balls to bounce off of, allowing small deviations in initial position to translate into larger deviations in which tube the balls end up in, and the standard deviation increases. This makes intuitive sense, and establishes very good intuitions around what types of random variables will tend to be normally distributed, and why. Is there a way to explain the gamma distribution’s connection to wait times, an empirical argument, example, or combination of the two that makes it clear why wait times will tend to look like a gamma distribution? Further, are there other distributions that will tend to model wait times well for reasons that can be understood from a similar explanation? Image courtesy of Seeking Wisdom .","I’m trying to get an intuition for gamma distributions, and why they are the model of choice for waiting times. In addition, I’d love to hear about any other distributions that are useful for modeling wait times for the same reason. I’d say I’ve got a pretty solid understanding of why everyday random variables tend to follow a normal distribution. If you drop balls into a line of tubes from above, Galton board style, you’ll tend to see them arrange into a normal distribution. Add pegs to provide something for the balls to bounce off of, allowing small deviations in initial position to translate into larger deviations in which tube the balls end up in, and the standard deviation increases. This makes intuitive sense, and establishes very good intuitions around what types of random variables will tend to be normally distributed, and why. Is there a way to explain the gamma distribution’s connection to wait times, an empirical argument, example, or combination of the two that makes it clear why wait times will tend to look like a gamma distribution? Further, are there other distributions that will tend to model wait times well for reasons that can be understood from a similar explanation? Image courtesy of Seeking Wisdom .",,"['statistics', 'probability-distributions', 'intuition', 'queueing-theory', 'gamma-distribution']"
86,Quick Question: using expectation as a scalar,Quick Question: using expectation as a scalar,,"I'd like to ask a question about possible rules of expectation when we can and can't use them ""as if"" they were scalars. Given Random Variables: $X_i \underset{iid}{\sim} z$ forming a random sample of z where z is some distribution and two given functions f and g. lets define $\mathbb{E}_{g}[f(X)]=\int_{-\infty}^{\infty} f(X)g(X)~dx$ as the weighted expectation of f wrt to g. From my understanding this is a number... it has a value and is not a ""random variable"" (even though i know constants are technically random variables with constant value)... so if we were to calculate for example: $$Var[h(X)] = \sum\limits_{1}^{n}Var_{g}[\mathbb{E}_{g}[f(X_i)]w(X_i)]$$ In this instance, would it be correct to consider the expectation as if it's acting as a scalar (since it's value is constant for each defined observation) and so we could rewrite this as $$\sum\limits_{1}^{n}\mathbb{E}_{g}[f(X_i)]Var_{g}[w(X_i)]$$ where the $Var_g$ is defined analogously to $\mathbb{E}_{g}$ Thanks.","I'd like to ask a question about possible rules of expectation when we can and can't use them ""as if"" they were scalars. Given Random Variables: forming a random sample of z where z is some distribution and two given functions f and g. lets define as the weighted expectation of f wrt to g. From my understanding this is a number... it has a value and is not a ""random variable"" (even though i know constants are technically random variables with constant value)... so if we were to calculate for example: In this instance, would it be correct to consider the expectation as if it's acting as a scalar (since it's value is constant for each defined observation) and so we could rewrite this as where the is defined analogously to Thanks.",X_i \underset{iid}{\sim} z \mathbb{E}_{g}[f(X)]=\int_{-\infty}^{\infty} f(X)g(X)~dx Var[h(X)] = \sum\limits_{1}^{n}Var_{g}[\mathbb{E}_{g}[f(X_i)]w(X_i)] \sum\limits_{1}^{n}\mathbb{E}_{g}[f(X_i)]Var_{g}[w(X_i)] Var_g \mathbb{E}_{g},"['probability', 'statistics', 'monte-carlo']"
87,How to do statistic test if I know only one changed parameter?,How to do statistic test if I know only one changed parameter?,,I have next condition of some study. We have 15 dogs that passed some test before specific therapy and after one week of therapy its passed it again and 13 pets had positive dynamic and participants with positive effect be the random variable Y. $Y_{obs}$ is 13 First I need establish $H_0$ and alternative hypotheses. My $H_0$ that nothing changed and alternative that therapy has positive effect to the participants. Can I establish $H_a$ that mean generally changed or in this case only that the therapy has positive effect? Next I should describe distribution. My guess that it is binomial with equal probability. The therapy has positive effect or don't have. Then I should give answer does therapy has effect or not with significant level 1%. And here if it binomial distribution I use mean = np and std $=\sqrt{npq}$ Thank you friends!,I have next condition of some study. We have 15 dogs that passed some test before specific therapy and after one week of therapy its passed it again and 13 pets had positive dynamic and participants with positive effect be the random variable Y. is 13 First I need establish and alternative hypotheses. My that nothing changed and alternative that therapy has positive effect to the participants. Can I establish that mean generally changed or in this case only that the therapy has positive effect? Next I should describe distribution. My guess that it is binomial with equal probability. The therapy has positive effect or don't have. Then I should give answer does therapy has effect or not with significant level 1%. And here if it binomial distribution I use mean = np and std Thank you friends!,Y_{obs} H_0 H_0 H_a =\sqrt{npq},"['probability', 'statistics']"
88,Basic matrix algebra in SVD,Basic matrix algebra in SVD,,"For my math course I'm reading about SVD in Principal Component Analysis (Abdi et al., 2010), I get stuck in (I think) a simple matrix algebra. In the text, equation (1) define SVD as: $X = PΔQ^T$ (Eq.1) and factor scores $F$ is defined as: $F = PΔ$ (Eq. 2) The matrix $Q$ gives the coefficients of the linear combinations used to compute the factors scores. This matrix can also be interpreted as a projection matrix because multiplying X by $Q$ gives the values of the projections of the observations on the principal components. This can be shown by combining Eqs. 1 and 2 as: $F = PΔ = PΔQ^TQ = XQ$ I need help to see how to combining Eq1 and 2 I get $F=XQ$ . Thanks!","For my math course I'm reading about SVD in Principal Component Analysis (Abdi et al., 2010), I get stuck in (I think) a simple matrix algebra. In the text, equation (1) define SVD as: (Eq.1) and factor scores is defined as: (Eq. 2) The matrix gives the coefficients of the linear combinations used to compute the factors scores. This matrix can also be interpreted as a projection matrix because multiplying X by gives the values of the projections of the observations on the principal components. This can be shown by combining Eqs. 1 and 2 as: I need help to see how to combining Eq1 and 2 I get . Thanks!",X = PΔQ^T F F = PΔ Q Q F = PΔ = PΔQ^TQ = XQ F=XQ,"['matrices', 'statistics', 'svd']"
89,Using Chernoff's inequality,Using Chernoff's inequality,,"Let $X$ denote the number of pairs of $HH$ in a sequence of 1000 coin tosses where we also consider the pair of the last and the first coin toss (cyclic). I'm asked to use Chernoff's inequality (the one which is only applicable for bernoulli variables) so I can't do that directly since $X$ is not distributed binomially. The tip is to split $X$ into pairs of tosses $i$ and $i+1$ where one time $i$ is even and the other time $i$ is odd. Clearly, those two expirements are distributed binomially, but how can I use this fact to use Chernoff's inequality to estimate something of the form $P(X\geq (1 + \delta)E[X])$ whereby I know that $X = X_{i \text{ is even}} + X_{i \text{ is odd}}$ so $E[X] = E[X_{i \text{ is even}}] + E[X_{i \text{ is odd}}]$ .","Let denote the number of pairs of in a sequence of 1000 coin tosses where we also consider the pair of the last and the first coin toss (cyclic). I'm asked to use Chernoff's inequality (the one which is only applicable for bernoulli variables) so I can't do that directly since is not distributed binomially. The tip is to split into pairs of tosses and where one time is even and the other time is odd. Clearly, those two expirements are distributed binomially, but how can I use this fact to use Chernoff's inequality to estimate something of the form whereby I know that so .",X HH X X i i+1 i i P(X\geq (1 + \delta)E[X]) X = X_{i \text{ is even}} + X_{i \text{ is odd}} E[X] = E[X_{i \text{ is even}}] + E[X_{i \text{ is odd}}],"['probability', 'statistics', 'expected-value', 'binomial-distribution']"
90,Number of patients in ICUs,Number of patients in ICUs,,During the past 50 days we observed the number of Covid patients in the city's hospitals and the records show a mean $μ = 710$ and $σ = 151$ . Calculate the probability to have more than 950 patients in ICUs. We want to find $P(X>950)$ . We calculate $Z = \frac{950-710}{\sqrt 151} = 19.53$ but I don't think it is correct. Any help? Thank you.,During the past 50 days we observed the number of Covid patients in the city's hospitals and the records show a mean and . Calculate the probability to have more than 950 patients in ICUs. We want to find . We calculate but I don't think it is correct. Any help? Thank you.,μ = 710 σ = 151 P(X>950) Z = \frac{950-710}{\sqrt 151} = 19.53,"['probability', 'statistics']"
91,Find value of the test statistic given set of values and alpha,Find value of the test statistic given set of values and alpha,,"""Based on population figures and other general information on the Canadian population, suppose it has been estimated that, on average, a family of four in Canada spends about $1,135 annually on dental expenditures. Suppose further that a regional dental association wants to test to determine if this figure is accurate for their area of the country. To test this, 22 families of four are randomly selected from the population in that area of the country and a log is kept of the family’s dental expenditures for one year. The resulting data are given below. Assuming that dental expenditures are normally distributed in the population, use the data and an alpha of 0.05 to test the dental association’s hypothesis."" 1,008   812 1,117   1,323   1,308   1,415 831 1,021   1,287   851 930 740 699 872 913 944 987 954 1,695   995 1,003   994 Attempt: Did https://i.sstatic.net/0Vw9p.jpg Then use (xbar-u)/(o/rootn) n=22 o=245.6477 xbar=1135 u=60342.79 (1135-60342.79)/(245.6477/root22) =-1130.52 Fail to reject null The numerical answer is wrong so what mistake did I make? Whats the correct equation to solve for test equation.","""Based on population figures and other general information on the Canadian population, suppose it has been estimated that, on average, a family of four in Canada spends about $1,135 annually on dental expenditures. Suppose further that a regional dental association wants to test to determine if this figure is accurate for their area of the country. To test this, 22 families of four are randomly selected from the population in that area of the country and a log is kept of the family’s dental expenditures for one year. The resulting data are given below. Assuming that dental expenditures are normally distributed in the population, use the data and an alpha of 0.05 to test the dental association’s hypothesis."" 1,008   812 1,117   1,323   1,308   1,415 831 1,021   1,287   851 930 740 699 872 913 944 987 954 1,695   995 1,003   994 Attempt: Did https://i.sstatic.net/0Vw9p.jpg Then use (xbar-u)/(o/rootn) n=22 o=245.6477 xbar=1135 u=60342.79 (1135-60342.79)/(245.6477/root22) =-1130.52 Fail to reject null The numerical answer is wrong so what mistake did I make? Whats the correct equation to solve for test equation.",,"['statistics', 'hypothesis-testing']"
92,"Show $\frac{(n-1)S^2}{\theta}$ is pivotal quantity of random sample $Y_1,...,Y_n$ from $N(\theta,\theta)$ then derive confidence interval",Show  is pivotal quantity of random sample  from  then derive confidence interval,"\frac{(n-1)S^2}{\theta} Y_1,...,Y_n N(\theta,\theta)","Show $\frac{(n-1)S^2}{\theta}$ is pivotal quantity of random sample $Y_1,...,Y_n$ from $N(\theta,\theta)$ then derive confidence interval $(1-\alpha)100%$ confidence interval for $\theta$ So I can show that $\frac{(n-1)S^2}{\theta}\sim \chi^2_{n-1}$ since $S^2=\sum_{k=1}^n \frac{(Y_i-\bar{Y})}{n-1}$ But I'm not sure how to find the confidence interval? I believe it is supposed to look like $P(\chi^2_{n-1}\leq \frac{(n-1)S^2}{\theta}\leq \chi^2_{n-1})=1-\alpha$ And then solving for $\theta$ in the middle. But I know $\chi^2_{n-1}$ is wrong, I don't understand what the bounds are supposed to be.","Show is pivotal quantity of random sample from then derive confidence interval confidence interval for So I can show that since But I'm not sure how to find the confidence interval? I believe it is supposed to look like And then solving for in the middle. But I know is wrong, I don't understand what the bounds are supposed to be.","\frac{(n-1)S^2}{\theta} Y_1,...,Y_n N(\theta,\theta) (1-\alpha)100% \theta \frac{(n-1)S^2}{\theta}\sim \chi^2_{n-1} S^2=\sum_{k=1}^n \frac{(Y_i-\bar{Y})}{n-1} P(\chi^2_{n-1}\leq \frac{(n-1)S^2}{\theta}\leq \chi^2_{n-1})=1-\alpha \theta \chi^2_{n-1}",['statistics']
93,"Book recommendation for formal, proof-based, theoretical books on time series and panel data","Book recommendation for formal, proof-based, theoretical books on time series and panel data",,"I'd like to ask you if there are any formal, proof-based and mainly theoretical books on time series and panel data. When searching for books on time series and panel data I got really good recommendations but all the books were more leaning towards the applied aspect. Either the books focused more on the computer science aspect (how to plot time series, how to execute Dickey-Fuller test, how to run regressions on panel data) accompanied with intuition but there are no proofs. Sometimes basic stuff is proven (like AR(1) is stationary if and only if the coefficient next to the laggued variable is between -1 and 1). But, I've already seen a similar question asked here and the only recommended book that meets my needs is this one : Time Series Theory and Methods by Peter J. Brockwell, Richard A. Davis. The one that suggested this book said, I quote, ""This used to be (still is?) the main reference for Time Series back in the day for those theoretically inclined."" And so I'd like to know if there are any other books of the sort that are more recent or, even if they're old but were heavily used back in the days. Thank you in advance.","I'd like to ask you if there are any formal, proof-based and mainly theoretical books on time series and panel data. When searching for books on time series and panel data I got really good recommendations but all the books were more leaning towards the applied aspect. Either the books focused more on the computer science aspect (how to plot time series, how to execute Dickey-Fuller test, how to run regressions on panel data) accompanied with intuition but there are no proofs. Sometimes basic stuff is proven (like AR(1) is stationary if and only if the coefficient next to the laggued variable is between -1 and 1). But, I've already seen a similar question asked here and the only recommended book that meets my needs is this one : Time Series Theory and Methods by Peter J. Brockwell, Richard A. Davis. The one that suggested this book said, I quote, ""This used to be (still is?) the main reference for Time Series back in the day for those theoretically inclined."" And so I'd like to know if there are any other books of the sort that are more recent or, even if they're old but were heavily used back in the days. Thank you in advance.",,"['probability', 'statistics', 'book-recommendation', 'time-series']"
94,What does the null hypothesis $H_0:\beta_2=0$ mean?,What does the null hypothesis  mean?,H_0:\beta_2=0,For the model $$Y=\beta_1+\beta_2X_2+\beta_3X_3+\epsilon$$ what does the null hypothesis $H_0:\beta_2=0$ mean? I think that then $X_2$ would not affect the expected value of $Y$ since the coefficient os then $0$ . But is that correct?,For the model what does the null hypothesis mean? I think that then would not affect the expected value of since the coefficient os then . But is that correct?,Y=\beta_1+\beta_2X_2+\beta_3X_3+\epsilon H_0:\beta_2=0 X_2 Y 0,"['statistics', 'hypothesis-testing']"
95,Deriving $-nE\left[\frac{\partial ^2\ln\left(f\left(X\right)\right)}{\partial \theta ^2}\right]$,Deriving,-nE\left[\frac{\partial ^2\ln\left(f\left(X\right)\right)}{\partial \theta ^2}\right],"The information about θ in a random sample of size n is also given by $$-nE\left[\frac{\partial ^2\ln\left(f_\theta\left(X\right)\right)}{\partial \theta ^2}\right]$$ where $f_\theta(x)$ is the value of the population density at x, provided that the extremes of the region for which $f_\theta(x)$ is not equal to 0 do not depend on θ. The derivation of this formula takes the following steps: Differentiating the expressions on both sides of $$\int f_\theta\left(x\right)dx=1$$ with respect to $\theta$ , show that $$\int \frac{\partial \ln\left(f_\theta\left(x\right)\right)}{\partial \theta }\left(f_\theta\left(x\right)\right)dx=0$$ by interchanging the order of integration and differentiation. Differentiating again with respect to θ, show that $$E\left[\left(\frac{\partial \ln\left(f_\theta\left(X\right)\right)}{\partial \theta }\right)^2\right]=-E\left[\frac{\partial ^2\ln\left(f_\theta\left(X\right)\right)}{\partial \theta ^2}\right]$$ I'm a little confused about what the question is asking. I am not sure how the $\ln$ comes in, in the first part and then how I relate that to the second part of the question?","The information about θ in a random sample of size n is also given by where is the value of the population density at x, provided that the extremes of the region for which is not equal to 0 do not depend on θ. The derivation of this formula takes the following steps: Differentiating the expressions on both sides of with respect to , show that by interchanging the order of integration and differentiation. Differentiating again with respect to θ, show that I'm a little confused about what the question is asking. I am not sure how the comes in, in the first part and then how I relate that to the second part of the question?",-nE\left[\frac{\partial ^2\ln\left(f_\theta\left(X\right)\right)}{\partial \theta ^2}\right] f_\theta(x) f_\theta(x) \int f_\theta\left(x\right)dx=1 \theta \int \frac{\partial \ln\left(f_\theta\left(x\right)\right)}{\partial \theta }\left(f_\theta\left(x\right)\right)dx=0 E\left[\left(\frac{\partial \ln\left(f_\theta\left(X\right)\right)}{\partial \theta }\right)^2\right]=-E\left[\frac{\partial ^2\ln\left(f_\theta\left(X\right)\right)}{\partial \theta ^2}\right] \ln,"['probability', 'statistics']"
96,Scale parameter definition,Scale parameter definition,,"I have seen two definitions of scale parameter of a distribution: Let $X$ be random variable and $\{{P_{\theta, X }: \theta \in \Theta \subset \mathbb{R}\}}$ be a parametric family of distribution of $X$ indexed by $\theta$ $$1)~~ \theta \text{   is a scale parameter iff} \rightarrow \text{ the distribution of } cX \text{ is in } \{{P_{\theta, X }: \theta \in \Theta \subset \mathbb{R}\}} \text{ for every positive constant c}$$ For example Let $X$ ~ $LogNormal(\theta, 1)~, \theta \in (-\infty, \infty)$ then $cX$ ~ $LogNormal(\theta^*,1)$ where $\theta^* = \theta + ln(c) \in (-\infty, \infty)$ . With this definition $\theta$ is a scale parameter. For the second definition it is required that $\theta$ is positive: $$2) ~ \theta > 0 \text{ is a scale parameter } iff \rightarrow \text{ the distribution of } X/\theta \text{ is independent of } \theta$$ If $X$ ~ $LogNormal(\theta, 1)~, \theta \in (0, \infty)$ (We restrict the parameter space) then $X/\theta $ ~ $LogNormal(\theta + ln(1/\theta), 1)$ . With this definition $\theta$ is not a scale parameter. I was wondering which of these two is the correct definition of a scale parameter? Or it depends on the book and the author?",I have seen two definitions of scale parameter of a distribution: Let be random variable and be a parametric family of distribution of indexed by For example Let ~ then ~ where . With this definition is a scale parameter. For the second definition it is required that is positive: If ~ (We restrict the parameter space) then ~ . With this definition is not a scale parameter. I was wondering which of these two is the correct definition of a scale parameter? Or it depends on the book and the author?,"X \{{P_{\theta, X }: \theta \in \Theta \subset \mathbb{R}\}} X \theta 1)~~ \theta \text{   is a scale parameter iff} \rightarrow \text{ the distribution of } cX \text{ is in } \{{P_{\theta, X }: \theta \in \Theta \subset \mathbb{R}\}} \text{ for every positive constant c} X LogNormal(\theta, 1)~, \theta \in (-\infty, \infty) cX LogNormal(\theta^*,1) \theta^* = \theta + ln(c) \in (-\infty, \infty) \theta \theta 2) ~ \theta > 0 \text{ is a scale parameter } iff \rightarrow \text{ the distribution of } X/\theta \text{ is independent of } \theta X LogNormal(\theta, 1)~, \theta \in (0, \infty) X/\theta  LogNormal(\theta + ln(1/\theta), 1) \theta","['probability', 'statistics', 'probability-distributions', 'parametric', 'parametrization']"
97,Finding the $p$-value from Bernoulli hypothesis test,Finding the -value from Bernoulli hypothesis test,p,"So I'm told that $X_i \sim Bern(p)$ , $Y = \sum_{i=1}^N X_i$ and $H_0: p \geq 0.5$ vs $H_1: p < 0.5$ with $\alpha = 0.05$ . I have to find the $p$ -value at $n=30$ and $y=5$ . I'm not sure if this correct, but I figured the $p$ -value was simply: $$P(Y \leq 5) = \sum_{i=1}^5 \binom{30}{y}(0.5)^y (0.5)^{30-y}$$ which works out to be $0.00016$ . If this is correct, then why have I been given $\alpha$ ?","So I'm told that , and vs with . I have to find the -value at and . I'm not sure if this correct, but I figured the -value was simply: which works out to be . If this is correct, then why have I been given ?",X_i \sim Bern(p) Y = \sum_{i=1}^N X_i H_0: p \geq 0.5 H_1: p < 0.5 \alpha = 0.05 p n=30 y=5 p P(Y \leq 5) = \sum_{i=1}^5 \binom{30}{y}(0.5)^y (0.5)^{30-y} 0.00016 \alpha,"['statistics', 'hypothesis-testing', 'p-value']"
98,"Convergence in probability and asymptotic distribution of MLE for Uniform $(-\theta, \theta)$",Convergence in probability and asymptotic distribution of MLE for Uniform,"(-\theta, \theta)","Problem. I am having difficulties with asymptotic results of the maximum likelihood estimator (MLE) of the parameter $\theta$ for the Uniform $(-\theta, \theta)$ distribution, given an IID sample $X_1, X_2,..., X_n$ .  Namely showing explicitly that: $$\widehat{\theta}_n \overset{p}{\rightarrow} \theta$$ and finding the limiting distribution $$n(\theta - \widehat{\theta}_n)$$ Where $\widehat{\theta}_n$ denotes the maximum-likelihood estimator. I am aware that if certain regularity conditions are satisfied, the MLE is a consistent estimator of a parameter of a distribution; so this question concerns showing it for a particular form of the Uniform distribution. I would have liked this question to be more concise, but it is not so because the issue lies in the fact that I am making reasoning errors which I am unable to discern. My attempt. Convergence in probability I first computed the likelihood function $L(\theta)$ , and found that the MLE of $\theta$ can be expressed as $\widehat{\theta}_n = \max \{ -X_{(1)}, X_{(n)} \}$ , where $X_{(1)}$ and $X_{(n)}$ are the 1st and nth order statistics. Now in order to show consistency, I began by considering the following, with a view to showing that it converges to 0 as $n \rightarrow \infty$ : $$P(|\widehat{\theta}_n - \theta | \geq \epsilon) = \underbrace{P(\widehat{\theta}_n \geq \theta + \epsilon)}_{=0} + P(\widehat{\theta}_n \leq \theta - \epsilon) = P(\widehat{\theta}_n \leq \theta - \epsilon)$$ I then proceeded by evaluating the RHS and this is where things start to become uncertain for me: $$\begin{align} P(\widehat{\theta}_n \leq \theta - \epsilon) &= P(\max \{ -X_{(1)}, X_{(n)} \} \leq \theta - \epsilon) \\ &= P \left( \left\{ -X_{(1)} \leq \theta - \epsilon \right \} \cap \left \{ X_{(n)} \leq \theta - \epsilon \right \} \right) \\ &= P(-X_{(1)} \leq \theta - \epsilon) P(X_{(n)} \leq \theta - \epsilon) \end{align}$$ In going from the 1st to the 2nd equality, I reasoned that in order for the maximum of $-X_{(1)}$ and $X_{(n)}$ to be less than $\theta - \epsilon$ , both $-X_{(1)}$ and $X_{(n)}$ must be less that $\theta - \epsilon$ . However, as it is a maximum of order statistics, the nesting is confusing me, and I'm starting to experience doubt as to whether this is a valid justification. In going from the 2nd to the 3rd equality, I am fairly certain that is appropriate as the $X_i$ are independent, and hence their order statistics are independent. I computed the CDF of the Uniform $(-\theta, \theta)$ to get: $$F_{X_i}(x_i) =  \begin{cases} 0 \quad &x_i \leq -\theta \\ \frac{x_i + \theta}{2\theta} \quad &-\theta \leq x_i \leq \theta \\ 1 \quad &x_i \geq \theta \\ \end{cases}$$ Evaluating the probability on the nth order statistic: $$P(X_{(n)} \leq \theta - \epsilon) = P \left(\bigcap^n_{i=1} X_i \leq \theta - \epsilon \right) = \prod^n_{i=1} P (X_i \leq \theta - \epsilon) = \left(1 - \frac{\epsilon}{2 \theta} \right)^n$$ Evaluating the probability on the 1st order statistic: $$P(-X_{(1)} \leq \theta - \epsilon) = P(X_{(1)} \geq - \theta + \epsilon) = 1 - P \left(X_{(1)} \leq -\theta + \epsilon \right) = 1 - P \left( \bigcap^n_{i=1} X_i \leq - \theta + \epsilon \right) = \left( 1 - \frac{\epsilon}{2\theta} \right)^n $$ Setting aside my reservation about how the above two calculations are combined , the above two individual probability calculations seem to accord with my intuitions, in that they are the same due to symmetry arguments. Which yields: $$P(|\widehat{\theta}_n - \theta | \geq \epsilon) = \left( 1 - \frac{\epsilon}{2\theta} \right)^{2n} = \left(\frac{2 \theta - \epsilon}{2\theta} \right)^{2n}$$ Which converges to 0 as $n \rightarrow \infty$ for all $\epsilon > 0$ . Convergence in distribution From a previous example in my notes, I know that for IID $X_1, ... ,X_n \sim \text{Uniform}(0,1)$ , the limiting distribution of the nth order statistic is an $\text{Exponential}(1)$ distribution; that is: $$X_{(n)} \overset{d}{\rightarrow} \text{Exponential}(1)$$ On this basis, I guessed that the solution would have a similar flavour. Invoking the arguments I made previously, I found that: $$\begin{align} P(n(\theta - \widehat{\theta}_n) \leq t)  &= 1 - P \left(\widehat{\theta}_n \leq \theta - \frac{t}{n} \right) \\ &= 1 - P\left( \left\{-X_{(1)} \leq \theta - \frac{t}{n} \right \} \cap \left \{ X_{(n)} \leq \theta -\frac{t}{n} \right \} \right)  \\ &= 1 - \left( 1 - \frac{t}{2n \theta} \right)^{2n} \\ \end{align}$$ Now I am left with something that looks very similar to an exponential CDF, and as a guess I suspect it might be an $\text{Exponential}(1 / \theta)$ ; and that the appearance of the factor of 2 is erroneous (due to an issue in the previous arguments which I am unable to discern). Another attempt. After reading through some previous posts on here, I decided to try reformulating the MLE estimator to something equivalent, that is by setting $\widehat{\theta}_n = \max\{|X_i|\} \space \forall \space i = 1, ... , n$ . I found that this skirts around the issue of not being sure about point 1. Focusing on the convergence in distribution argument (as the convergence in probability argument is a stepping stone) I found that: $$\begin{align} P(n(\theta - \widehat{\theta}_n) \leq t) = 1 - P \left(\widehat{\theta}_n \leq \theta - \frac{t}{n} \right) &= 1 - P \left( \max \{ |X_i | \} \leq \theta - \frac{t}{n} \space \forall \space i = 1, ... , n \right) \\ &= 1 - P \left( \bigcap^n_{i=1} |X_i| \leq \theta - \frac{t}{n} \right) \\ &= 1 - \prod^n_{i=1} \left( P(X_i \leq \theta - \frac{t}{n}) + P(-X_i \leq \theta - \frac{t}{n} ) \right) \\ &= 1 - \prod^n_{i=1} \left( P(X_i \leq \theta - \frac{t}{n}) + P(X_i \geq -\theta + \frac{t}{n}) \right) \\ &= 1 - \prod^n_{i=1} F_{X_i}\left( \theta - \frac{t}{n} \right) \left[1 - F_{X_i}\left(-\theta + \frac{t}{n} \right) \right] \\ &= 1 - \prod^n_{i=1} \left( \frac{2 \theta - t/n}{2 \theta} + 1 - \frac{t/n}{2 \theta} \right) \\ &= 1 - \left( 2 - \frac{t}{2n \theta} \right)^n \end{align}$$ So I know that as I am not getting the same results, there are errors of reasoning being made. However, I am having trouble discerning where these lie. I would appreciate if members of this community were to assist me.","Problem. I am having difficulties with asymptotic results of the maximum likelihood estimator (MLE) of the parameter for the Uniform distribution, given an IID sample .  Namely showing explicitly that: and finding the limiting distribution Where denotes the maximum-likelihood estimator. I am aware that if certain regularity conditions are satisfied, the MLE is a consistent estimator of a parameter of a distribution; so this question concerns showing it for a particular form of the Uniform distribution. I would have liked this question to be more concise, but it is not so because the issue lies in the fact that I am making reasoning errors which I am unable to discern. My attempt. Convergence in probability I first computed the likelihood function , and found that the MLE of can be expressed as , where and are the 1st and nth order statistics. Now in order to show consistency, I began by considering the following, with a view to showing that it converges to 0 as : I then proceeded by evaluating the RHS and this is where things start to become uncertain for me: In going from the 1st to the 2nd equality, I reasoned that in order for the maximum of and to be less than , both and must be less that . However, as it is a maximum of order statistics, the nesting is confusing me, and I'm starting to experience doubt as to whether this is a valid justification. In going from the 2nd to the 3rd equality, I am fairly certain that is appropriate as the are independent, and hence their order statistics are independent. I computed the CDF of the Uniform to get: Evaluating the probability on the nth order statistic: Evaluating the probability on the 1st order statistic: Setting aside my reservation about how the above two calculations are combined , the above two individual probability calculations seem to accord with my intuitions, in that they are the same due to symmetry arguments. Which yields: Which converges to 0 as for all . Convergence in distribution From a previous example in my notes, I know that for IID , the limiting distribution of the nth order statistic is an distribution; that is: On this basis, I guessed that the solution would have a similar flavour. Invoking the arguments I made previously, I found that: Now I am left with something that looks very similar to an exponential CDF, and as a guess I suspect it might be an ; and that the appearance of the factor of 2 is erroneous (due to an issue in the previous arguments which I am unable to discern). Another attempt. After reading through some previous posts on here, I decided to try reformulating the MLE estimator to something equivalent, that is by setting . I found that this skirts around the issue of not being sure about point 1. Focusing on the convergence in distribution argument (as the convergence in probability argument is a stepping stone) I found that: So I know that as I am not getting the same results, there are errors of reasoning being made. However, I am having trouble discerning where these lie. I would appreciate if members of this community were to assist me.","\theta (-\theta, \theta) X_1, X_2,..., X_n \widehat{\theta}_n \overset{p}{\rightarrow} \theta n(\theta - \widehat{\theta}_n) \widehat{\theta}_n L(\theta) \theta \widehat{\theta}_n = \max \{ -X_{(1)}, X_{(n)} \} X_{(1)} X_{(n)} n \rightarrow \infty P(|\widehat{\theta}_n - \theta | \geq \epsilon) = \underbrace{P(\widehat{\theta}_n \geq \theta + \epsilon)}_{=0} + P(\widehat{\theta}_n \leq \theta - \epsilon) = P(\widehat{\theta}_n \leq \theta - \epsilon) \begin{align}
P(\widehat{\theta}_n \leq \theta - \epsilon) &= P(\max \{ -X_{(1)}, X_{(n)} \} \leq \theta - \epsilon) \\
&= P \left( \left\{ -X_{(1)} \leq \theta - \epsilon \right \} \cap \left \{ X_{(n)} \leq \theta - \epsilon \right \} \right) \\
&= P(-X_{(1)} \leq \theta - \epsilon) P(X_{(n)} \leq \theta - \epsilon)
\end{align} -X_{(1)} X_{(n)} \theta - \epsilon -X_{(1)} X_{(n)} \theta - \epsilon X_i (-\theta, \theta) F_{X_i}(x_i) = 
\begin{cases}
0 \quad &x_i \leq -\theta \\
\frac{x_i + \theta}{2\theta} \quad &-\theta \leq x_i \leq \theta \\
1 \quad &x_i \geq \theta \\
\end{cases} P(X_{(n)} \leq \theta - \epsilon) = P \left(\bigcap^n_{i=1} X_i \leq \theta - \epsilon \right) = \prod^n_{i=1} P (X_i \leq \theta - \epsilon) = \left(1 - \frac{\epsilon}{2 \theta} \right)^n P(-X_{(1)} \leq \theta - \epsilon) = P(X_{(1)} \geq - \theta + \epsilon) = 1 - P \left(X_{(1)} \leq -\theta + \epsilon \right) = 1 - P \left( \bigcap^n_{i=1} X_i \leq - \theta + \epsilon \right) = \left( 1 - \frac{\epsilon}{2\theta} \right)^n  P(|\widehat{\theta}_n - \theta | \geq \epsilon) = \left( 1 - \frac{\epsilon}{2\theta} \right)^{2n} = \left(\frac{2 \theta - \epsilon}{2\theta} \right)^{2n} n \rightarrow \infty \epsilon > 0 X_1, ... ,X_n \sim \text{Uniform}(0,1) \text{Exponential}(1) X_{(n)} \overset{d}{\rightarrow} \text{Exponential}(1) \begin{align}
P(n(\theta - \widehat{\theta}_n) \leq t)  &= 1 - P \left(\widehat{\theta}_n \leq \theta - \frac{t}{n} \right) \\
&= 1 - P\left( \left\{-X_{(1)} \leq \theta - \frac{t}{n} \right \} \cap \left \{ X_{(n)} \leq \theta -\frac{t}{n} \right \} \right)  \\
&= 1 - \left( 1 - \frac{t}{2n \theta} \right)^{2n} \\
\end{align} \text{Exponential}(1 / \theta) \widehat{\theta}_n = \max\{|X_i|\} \space \forall \space i = 1, ... , n \begin{align}
P(n(\theta - \widehat{\theta}_n) \leq t) = 1 - P \left(\widehat{\theta}_n \leq \theta - \frac{t}{n} \right) &= 1 - P \left( \max \{ |X_i | \} \leq \theta - \frac{t}{n} \space \forall \space i = 1, ... , n \right) \\
&= 1 - P \left( \bigcap^n_{i=1} |X_i| \leq \theta - \frac{t}{n} \right) \\
&= 1 - \prod^n_{i=1} \left( P(X_i \leq \theta - \frac{t}{n}) + P(-X_i \leq \theta - \frac{t}{n} ) \right) \\
&= 1 - \prod^n_{i=1} \left( P(X_i \leq \theta - \frac{t}{n}) + P(X_i \geq -\theta + \frac{t}{n}) \right) \\
&= 1 - \prod^n_{i=1} F_{X_i}\left( \theta - \frac{t}{n} \right) \left[1 - F_{X_i}\left(-\theta + \frac{t}{n} \right) \right] \\
&= 1 - \prod^n_{i=1} \left( \frac{2 \theta - t/n}{2 \theta} + 1 - \frac{t/n}{2 \theta} \right) \\
&= 1 - \left( 2 - \frac{t}{2n \theta} \right)^n
\end{align}","['statistics', 'statistical-inference', 'maximum-likelihood', 'parameter-estimation', 'probability-limit-theorems']"
99,Calculating average number of tries for an event whose probability increases with the number of unsuccesful tries,Calculating average number of tries for an event whose probability increases with the number of unsuccesful tries,,"I have a question that I didn't even know how to word on google. I have a system where an event has a 2% chance of happening each roll for the first 50 rolls, and, starting from the 51st, its probability increases by 2% each unsuccessful try, so in the 51st try it has a 4% chance, in the 52nd a 6% chance and so on until the 99th in which it has 100% chance, however the chance resets to 2% if the event is rolled. I have calculated the chance of rolling the event at least once within x number of pulls, for example for 52 pulls it is $1-( (.98^{50})(.96)(.94) )=.6714$ ,please do correct me if I am wrong. However I also wanted to know on average how many attempts it would take for the event to occur: I tried reasoning that for an event with a 2% chance it would take on average 50 tries, but that would mean that the increase in probability from the 51st have no weight on this average, and that seemed weird. In addition, in some instances even if you roll the event there is a p chance that the roll still fails; p is determined before starting the 1st roll and doesn't change throughout the attempts. As you can probably imagine I'm not experienced at all in the field (or mathematics in general for the matter) so if it is possible to explain reasonings and calculations in a simple manner I would appreciate. Thank you in advance.","I have a question that I didn't even know how to word on google. I have a system where an event has a 2% chance of happening each roll for the first 50 rolls, and, starting from the 51st, its probability increases by 2% each unsuccessful try, so in the 51st try it has a 4% chance, in the 52nd a 6% chance and so on until the 99th in which it has 100% chance, however the chance resets to 2% if the event is rolled. I have calculated the chance of rolling the event at least once within x number of pulls, for example for 52 pulls it is ,please do correct me if I am wrong. However I also wanted to know on average how many attempts it would take for the event to occur: I tried reasoning that for an event with a 2% chance it would take on average 50 tries, but that would mean that the increase in probability from the 51st have no weight on this average, and that seemed weird. In addition, in some instances even if you roll the event there is a p chance that the roll still fails; p is determined before starting the 1st roll and doesn't change throughout the attempts. As you can probably imagine I'm not experienced at all in the field (or mathematics in general for the matter) so if it is possible to explain reasonings and calculations in a simple manner I would appreciate. Thank you in advance.",1-( (.98^{50})(.96)(.94) )=.6714,"['probability', 'statistics', 'expected-value']"
