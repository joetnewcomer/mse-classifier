,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,If $f'(z)$ exists does this mean that $f'(\bar{z})$ exists?,If  exists does this mean that  exists?,f'(z) f'(\bar{z}),"Suppose we know that a complex function $f$ is differentiable in some region, $D$. Then how can we show that $f'(\bar{z})$ also exists? I tried using the definition of the derivative: $$f'(\bar{z}) = \lim _{h \rightarrow 0} \frac{f(\bar{z}+h)-f(\bar{z})}{h}$$ and then relating this to the limit for $f'(z)$ but I haven't gotten very far with that. How should I proceed?","Suppose we know that a complex function $f$ is differentiable in some region, $D$. Then how can we show that $f'(\bar{z})$ also exists? I tried using the definition of the derivative: $$f'(\bar{z}) = \lim _{h \rightarrow 0} \frac{f(\bar{z}+h)-f(\bar{z})}{h}$$ and then relating this to the limit for $f'(z)$ but I haven't gotten very far with that. How should I proceed?",,['complex-analysis']
1,What's about $\int_0^\infty x^{-z}Li_{z+2}(e^{-xz})dx$ as $-\zeta(3)z^2\Gamma(-z)$?,What's about  as ?,\int_0^\infty x^{-z}Li_{z+2}(e^{-xz})dx -\zeta(3)z^2\Gamma(-z),"Because $$-\int_0^\infty \frac{e^{-zt}}{t^z}dt=z^2\Gamma(-z),$$  holds for $0<\Re z<1$ then using the change of variable $t=nx$ one has that $$-\frac{1}{n^{z-1}}\int_0^\infty \frac{e^{-znx}dx}{x^z}=z^2\Gamma(-z),$$ and multiplying by $\frac{1}{n^3}$ for integers $n\geq 1$ and taking the sum, one has if there were not mistakes $$\zeta(3)=-\frac{-1}{z^2\Gamma(-z)}\int_0^\infty\frac{1}{x^z}\left(\sum_{n=1}^\infty\frac{e^{-znx}}{n^{z+2}}\right)dx.$$  Then I tried know if it was right. First one knows, using Wolfram Alpha, that the second factor in previous integrand is $Li_{z+2}(e^{-xz})$. Question. Were rights my calculations? Can you integrating $$\int_0^\infty x^{-z}Li_{z+2}(e^{-xz})dx$$ show that it is equal to $$-\zeta(3)z^2\Gamma(-z)?$$ Thanks in advance. I am not able to prove (previous directly as I am asking) with Wolfram Alpha online calculator , with this my code and with standard computation time: int x^(-z) PolyLog(z+2,e^(-xz)) dx from x=0 to infinite .","Because $$-\int_0^\infty \frac{e^{-zt}}{t^z}dt=z^2\Gamma(-z),$$  holds for $0<\Re z<1$ then using the change of variable $t=nx$ one has that $$-\frac{1}{n^{z-1}}\int_0^\infty \frac{e^{-znx}dx}{x^z}=z^2\Gamma(-z),$$ and multiplying by $\frac{1}{n^3}$ for integers $n\geq 1$ and taking the sum, one has if there were not mistakes $$\zeta(3)=-\frac{-1}{z^2\Gamma(-z)}\int_0^\infty\frac{1}{x^z}\left(\sum_{n=1}^\infty\frac{e^{-znx}}{n^{z+2}}\right)dx.$$  Then I tried know if it was right. First one knows, using Wolfram Alpha, that the second factor in previous integrand is $Li_{z+2}(e^{-xz})$. Question. Were rights my calculations? Can you integrating $$\int_0^\infty x^{-z}Li_{z+2}(e^{-xz})dx$$ show that it is equal to $$-\zeta(3)z^2\Gamma(-z)?$$ Thanks in advance. I am not able to prove (previous directly as I am asking) with Wolfram Alpha online calculator , with this my code and with standard computation time: int x^(-z) PolyLog(z+2,e^(-xz)) dx from x=0 to infinite .",,"['integration', 'complex-analysis']"
2,show that $g(f(z))$ has an essential singularity at $z=z_0$?,show that  has an essential singularity at ?,g(f(z)) z=z_0,"Question : Let $f(z)$ be analytic in an open set $G\subset \mathbb{C}$ except for a pole at $z_0\in G$. $g(z)$ be an entire function that is not a polynomial. how to show that $g(f(z))$ has an essential singularity at $z=z_0$? My work: I tried to prove by contradiction from that if it is a pole, then $\forall \delta>0 \exists R>0$ such that $\{w:|w|>R\}\subset f(\{z\in\mathbb{C}:|z-z_0|<\delta\})$. If it is a removable singularity, then $\lim_{z\to z_0}g(f(z))=c$ for some $c\in\mathbb{C}$. If it is a pole, then it is a removable singularity of $\frac{1}{g(z)}$, then I cannot find the contradiction come from? Could anyone kindly help? Thanks!","Question : Let $f(z)$ be analytic in an open set $G\subset \mathbb{C}$ except for a pole at $z_0\in G$. $g(z)$ be an entire function that is not a polynomial. how to show that $g(f(z))$ has an essential singularity at $z=z_0$? My work: I tried to prove by contradiction from that if it is a pole, then $\forall \delta>0 \exists R>0$ such that $\{w:|w|>R\}\subset f(\{z\in\mathbb{C}:|z-z_0|<\delta\})$. If it is a removable singularity, then $\lim_{z\to z_0}g(f(z))=c$ for some $c\in\mathbb{C}$. If it is a pole, then it is a removable singularity of $\frac{1}{g(z)}$, then I cannot find the contradiction come from? Could anyone kindly help? Thanks!",,"['complex-analysis', 'analysis']"
3,Analytic continuation of $\sum z^{2n}$,Analytic continuation of,\sum z^{2n},"If I'm not misusing the root test, the convergence radius of $\sum z^{2n}$ is $\lim \sup \sqrt[2n]{1}=1$ (is this correct?). Now, is there a closed-form expression of $f(z)=\sum z^{2n}$ so that it be analytically continuated beyond this radius of convergence? Any hint would be appreciated.","If I'm not misusing the root test, the convergence radius of $\sum z^{2n}$ is $\lim \sup \sqrt[2n]{1}=1$ (is this correct?). Now, is there a closed-form expression of $f(z)=\sum z^{2n}$ so that it be analytically continuated beyond this radius of convergence? Any hint would be appreciated.",,"['complex-analysis', 'power-series', 'analytic-continuation']"
4,Intermediate step in proving Cauchy's Integral Formula,Intermediate step in proving Cauchy's Integral Formula,,"I'm trying to understand the proof of the Cauchy's Integral Formula from the J. Conway, Complex Integration book. He states that However, I don't know how to solve what he left as exercise 1, at the beginning of the proof. Can anyone give me a hint? Thanks","I'm trying to understand the proof of the Cauchy's Integral Formula from the J. Conway, Complex Integration book. He states that However, I don't know how to solve what he left as exercise 1, at the beginning of the proof. Can anyone give me a hint? Thanks",,['complex-analysis']
5,On real part of the complex number $(1+i)z^2$,On real part of the complex number,(1+i)z^2,"Find the set of points belonging to the coordinate plane $xy$, for which the real part of the complex number $(1+i)z^2$ is positive. My solution:- Lets start with letting $z=r\cdot e^{i\theta}$. Then the expression $(1+i)z^2$ becomes $$\large\sqrt2\cdot|z|^2\cdot e^{{i}\left(2\theta+\dfrac{\pi}{4}\right)}$$ Now, as $\sqrt2\cdot|z|^2\gt0$, so $\Re{((1+i)z^2)}\gt 0 \implies\cos{\left(2\theta+\dfrac{\pi}{4}\right)}\gt 0$. So, we get  $$-\dfrac{\pi}{2}\lt\left(2\theta+\dfrac{\pi}{4}\right)\lt\dfrac{\pi}{2} \implies-\dfrac{3\pi}{4}\lt2\theta\lt\dfrac{\pi}{4} \implies-\dfrac{3\pi}{8}\lt\theta\lt\dfrac{\pi}{8}$$ Now, lets find the equation of the lines which would help us show these inequalities in the coordinate plane. The inequality can be represented by  $$\begin{equation} y\lt \tan{\dfrac{\pi}{8}}x\implies y\lt(\sqrt2-1)x \tag{1} \end{equation}$$ $$\begin{equation} y\gt \tan{(-\dfrac{3\pi}{8})}x \implies y\gt-(\sqrt2+1)x \tag{2} \end{equation}$$ So, the inequality can be represented in the coordinate plane as in the following portion of the graph with the cross-hatched part. My deal with the question:- The book I am solving gives the answer as the (cross-hatched part + un-hatched part) , so what am I missing in my solution. And, as always more elegant solutions are welcome.","Find the set of points belonging to the coordinate plane $xy$, for which the real part of the complex number $(1+i)z^2$ is positive. My solution:- Lets start with letting $z=r\cdot e^{i\theta}$. Then the expression $(1+i)z^2$ becomes $$\large\sqrt2\cdot|z|^2\cdot e^{{i}\left(2\theta+\dfrac{\pi}{4}\right)}$$ Now, as $\sqrt2\cdot|z|^2\gt0$, so $\Re{((1+i)z^2)}\gt 0 \implies\cos{\left(2\theta+\dfrac{\pi}{4}\right)}\gt 0$. So, we get  $$-\dfrac{\pi}{2}\lt\left(2\theta+\dfrac{\pi}{4}\right)\lt\dfrac{\pi}{2} \implies-\dfrac{3\pi}{4}\lt2\theta\lt\dfrac{\pi}{4} \implies-\dfrac{3\pi}{8}\lt\theta\lt\dfrac{\pi}{8}$$ Now, lets find the equation of the lines which would help us show these inequalities in the coordinate plane. The inequality can be represented by  $$\begin{equation} y\lt \tan{\dfrac{\pi}{8}}x\implies y\lt(\sqrt2-1)x \tag{1} \end{equation}$$ $$\begin{equation} y\gt \tan{(-\dfrac{3\pi}{8})}x \implies y\gt-(\sqrt2+1)x \tag{2} \end{equation}$$ So, the inequality can be represented in the coordinate plane as in the following portion of the graph with the cross-hatched part. My deal with the question:- The book I am solving gives the answer as the (cross-hatched part + un-hatched part) , so what am I missing in my solution. And, as always more elegant solutions are welcome.",,"['complex-analysis', 'inequality', 'complex-numbers']"
6,Topology for Hardy spaces,Topology for Hardy spaces,,"Let $\Omega\subset \mathbb{C}$ be an open set (of the complex plane) and let $\mathcal{H}(\Omega)$ be the algebra of analytic functions on $\Omega$ endowed with the topology of compact convergence (uniform convergence on all compacts of $\Omega$). It is known that, due to the Cauchy formula, this space is complete (and therefore Fréchet; I can elaborate more this point on request). Can one provide an example of a pointwise convergent sequence $(f_n)_{n\geq 0}$ of analytic functions (i.e. in $\mathcal{H}(\Omega)$) such that the (pointwise) limit is not continuous ? And/or is there a theorem giving properties of such (pointwise) limits ? Added after answer Can one provide an explicit example of a pointwise convergent sequence $(f_n)_{n\geq 0}$ of analytic functions (i.e. in $\mathcal{H}(\Omega)$) such that the (pointwise) limit is continuous but not holomorphic ?","Let $\Omega\subset \mathbb{C}$ be an open set (of the complex plane) and let $\mathcal{H}(\Omega)$ be the algebra of analytic functions on $\Omega$ endowed with the topology of compact convergence (uniform convergence on all compacts of $\Omega$). It is known that, due to the Cauchy formula, this space is complete (and therefore Fréchet; I can elaborate more this point on request). Can one provide an example of a pointwise convergent sequence $(f_n)_{n\geq 0}$ of analytic functions (i.e. in $\mathcal{H}(\Omega)$) such that the (pointwise) limit is not continuous ? And/or is there a theorem giving properties of such (pointwise) limits ? Added after answer Can one provide an explicit example of a pointwise convergent sequence $(f_n)_{n\geq 0}$ of analytic functions (i.e. in $\mathcal{H}(\Omega)$) such that the (pointwise) limit is continuous but not holomorphic ?",,"['complex-analysis', 'functional-analysis']"
7,Ratio of holomorphic forms on a Riemann surface,Ratio of holomorphic forms on a Riemann surface,,"Let $R$ be a Riemann surface of genus $g>1$ and $\omega$, $\sigma$ two holomorphic 1-forms on $R$. This means that locally we can write $\omega=fdz$ and $\sigma=gdz$ with $f$ and $g$ holomorphic. Now suppose that the forms $\omega$ and $\sigma$ have just one zero of multiplicity $2g-2$ in the same point. From $\omega$ and $\sigma$ we get a well defined function $\theta:R\rightarrow \mathbb{C}$ which locally is defined as $\frac f g$. My question is: is $\theta$ a holomorphic function? I think yes, because $f$ and $g$ have a zero of the same multiplicity in the same point, so $\theta$ should have no poles.. but then this means that $\theta$ should be a constant function.. So this implies that every two holomorphic 1-forms on $R$ with one zero of multiplicity $2g-2$ in the same point differ by a constant? This doesn't seem right because this would mean that the complex vector space of holomorphic forms with one zero of multiplicity $2g-2$ in a fixed point should have dimension 1 which is impossible.. Where am I wrong?","Let $R$ be a Riemann surface of genus $g>1$ and $\omega$, $\sigma$ two holomorphic 1-forms on $R$. This means that locally we can write $\omega=fdz$ and $\sigma=gdz$ with $f$ and $g$ holomorphic. Now suppose that the forms $\omega$ and $\sigma$ have just one zero of multiplicity $2g-2$ in the same point. From $\omega$ and $\sigma$ we get a well defined function $\theta:R\rightarrow \mathbb{C}$ which locally is defined as $\frac f g$. My question is: is $\theta$ a holomorphic function? I think yes, because $f$ and $g$ have a zero of the same multiplicity in the same point, so $\theta$ should have no poles.. but then this means that $\theta$ should be a constant function.. So this implies that every two holomorphic 1-forms on $R$ with one zero of multiplicity $2g-2$ in the same point differ by a constant? This doesn't seem right because this would mean that the complex vector space of holomorphic forms with one zero of multiplicity $2g-2$ in a fixed point should have dimension 1 which is impossible.. Where am I wrong?",,"['complex-analysis', 'differential-geometry', 'algebraic-topology', 'complex-geometry', 'riemann-surfaces']"
8,How to rigorously deduce the Laurent series of $\log\frac{z-p}{z-q}$?,How to rigorously deduce the Laurent series of ?,\log\frac{z-p}{z-q},"Of course, the logarithm here is defined on the ring region $|z|>R\ge\max\{|p|,|q|\}$ as  $$\log\frac{z-p}{z-q}=\int_{z_0}^z \left(\frac1{w-p}-\frac1{w-q}\right)\mathrm d w. $$ Here the integral is along an arbitrary curve connecting $z_0$, a fixed point, to $z$ in the ring region. It's noteworthy that this logarithm is actually well defined, although not appearing so at first glance. All I know is $\log(1+z)=z-\frac12z^2+\frac13z^3+\cdots$ when $|z|<1$ and $\log$ is chosen to be the principal branch. With this idea I can work out a naive argument: for our fractional logarithm, first rewrite the expression as $\log\frac{1-p/z}{1-q/z}$ by dividing both the numerator and denominator simultaneously (I don't know how to justify this from the integral definition , though); then it all reduces to $\log(1-p/z)-\log(1-q/z)$, with the two logarithm both chosen as suitable branches, to which the canonical power expansion applies. I believe I'm almost on the right track, but can't get over that confusion. Could you help me? Thanks!","Of course, the logarithm here is defined on the ring region $|z|>R\ge\max\{|p|,|q|\}$ as  $$\log\frac{z-p}{z-q}=\int_{z_0}^z \left(\frac1{w-p}-\frac1{w-q}\right)\mathrm d w. $$ Here the integral is along an arbitrary curve connecting $z_0$, a fixed point, to $z$ in the ring region. It's noteworthy that this logarithm is actually well defined, although not appearing so at first glance. All I know is $\log(1+z)=z-\frac12z^2+\frac13z^3+\cdots$ when $|z|<1$ and $\log$ is chosen to be the principal branch. With this idea I can work out a naive argument: for our fractional logarithm, first rewrite the expression as $\log\frac{1-p/z}{1-q/z}$ by dividing both the numerator and denominator simultaneously (I don't know how to justify this from the integral definition , though); then it all reduces to $\log(1-p/z)-\log(1-q/z)$, with the two logarithm both chosen as suitable branches, to which the canonical power expansion applies. I believe I'm almost on the right track, but can't get over that confusion. Could you help me? Thanks!",,"['complex-analysis', 'logarithms', 'laurent-series']"
9,"Help, why these are two different results of integral of $\sqrt{z}$ on unit circle depending the choice of Branch cut","Help, why these are two different results of integral of  on unit circle depending the choice of Branch cut",\sqrt{z},"everyone, I want test the effect of different choice of branch cut for contour, So I find a simple function, i.e. $\sqrt{z}$ with $z=re^{i\theta}$ on 1st Branch as $$I=\oint_{UnitCircle}{\sqrt{z}dz}$$ I always find two contours to calculate and contrast. The 1st one contour is shown as By using the Cauchy Theorem, I have $\oint_{\Gamma}{\sqrt{z}dz}=\int_{C_1}+\int_{C_2}+\int_{C_3}+\int_{C}$, The $\int_{C}$ is what I want when the radius $\delta$ of small circle turn to $0$ . And I have three results for other three contours which are given as $$\int_{C_{1}}{\sqrt{z}dz}=\int_{C_{1}}{\sqrt{r}e^{i\frac{0}{2}}d(re^{i0})}=\int_{C_{1}}{\sqrt{r}dr}=\int_{0}^{1}{\sqrt{r}dr}=\frac{2}{3}$$ $$\int_{C_{2}}{\sqrt{z}dz}=\int_{C_{2}}{\sqrt{r}e^{i\frac{2\pi}{2}}d(re^{i 2\pi)}}=-\int_{C_{2}}{\sqrt{r}dr}=-\int_{1}^{0}{\sqrt{r}dr}=\frac{2}{3}$$ For $C_{3}$, I use the $\epsilon-\Delta$ formula as: given positive real number $\epsilon$, have a positive real number $\Delta<\epsilon^{\frac{2}{3}}$, when $\left|z-0\right|=\left|z\right|=\delta$, $\left|zf(z)-0\right|=\left|r^{\frac{3}{2}}e^{\frac{i3\theta}{2}}\right|=r^{\frac{3}{2}}<\Delta^{\frac{3}{2}}<\epsilon$, so I have $$lim_{\delta\rightarrow 0}{\int_{C_{3}}\sqrt{z}dz}=i0(2\pi-0)=0$$. So, I directly get $$I=-\frac{4}{3}$$. Then, I re-calculate $I$ using 2nd contour as shown as , and I get a different result . I also start with the Cauchy Theorem as $\oint_{\Gamma}{\sqrt{z}dz}=\int_{C_1}+\int_{C_2}+\int_{C_3}+\int_{C}$, The $\int_{C}$ is what I want when the radius $\delta$ of small circle turn to $0$ . And I have three results for other three contours which are given as $$\int_{C_{1}}{\sqrt{z}dz}=\int_{C_{1}}{\sqrt{r}e^{i\frac{\pi}{2}}d(re^{i\pi})}=\int_{C_{1}}{-i\sqrt{r}dr}=-i\int_{1}^{0}{\sqrt{r}dr}=i\int_{0}^{1}{\sqrt{r}dr}=i\frac{2}{3}$$ $$\int_{C_{2}}{\sqrt{z}dz}=\int_{C_{2}}{\sqrt{r}e^{i\frac{-\pi}{2}}d(re^{-i\pi})}=\int_{C_{2}}{-i\sqrt{r}d(-r)}=i\int_{C_{2}}{\sqrt{r}dr}=i\int_{0}^{1}{\sqrt{r}dr}=i\frac{2}{3}$$ And I also have $\epsilon-\Delta$ formula:given positive real number $\epsilon$, have a positive real number $\Delta<\epsilon^{\frac{2}{3}}$, when $\left|z-0\right|=\left|z\right|=\delta$, $\left|zf(z)-0\right|=\left|r^{\frac{3}{2}}e^{\frac{i3\theta}{2}}\right|=r^{\frac{3}{2}}<\Delta^{\frac{3}{2}}<\epsilon$, which gives $$lim_{\delta\rightarrow 0}{\int_{C_{3}}\sqrt{z}dz}=i0(\pi+\pi)=0$$. So, I get $$I=-i\frac{4}{3}$$ which is not same as the result given in 1st contour, Is it correct? I know that the complex contour integral depends the kink and path at same time, But the result I wanted is calculate on a ""Closed"" circle in a roughly view. On the other hand, the circle in these two contours actually start/end at different point, i.e. $(0, 2\pi]$ and $(-\pi, \pi]$. May be it is the key point. Can anyone help me fix it? Thanks!!Please!!","everyone, I want test the effect of different choice of branch cut for contour, So I find a simple function, i.e. $\sqrt{z}$ with $z=re^{i\theta}$ on 1st Branch as $$I=\oint_{UnitCircle}{\sqrt{z}dz}$$ I always find two contours to calculate and contrast. The 1st one contour is shown as By using the Cauchy Theorem, I have $\oint_{\Gamma}{\sqrt{z}dz}=\int_{C_1}+\int_{C_2}+\int_{C_3}+\int_{C}$, The $\int_{C}$ is what I want when the radius $\delta$ of small circle turn to $0$ . And I have three results for other three contours which are given as $$\int_{C_{1}}{\sqrt{z}dz}=\int_{C_{1}}{\sqrt{r}e^{i\frac{0}{2}}d(re^{i0})}=\int_{C_{1}}{\sqrt{r}dr}=\int_{0}^{1}{\sqrt{r}dr}=\frac{2}{3}$$ $$\int_{C_{2}}{\sqrt{z}dz}=\int_{C_{2}}{\sqrt{r}e^{i\frac{2\pi}{2}}d(re^{i 2\pi)}}=-\int_{C_{2}}{\sqrt{r}dr}=-\int_{1}^{0}{\sqrt{r}dr}=\frac{2}{3}$$ For $C_{3}$, I use the $\epsilon-\Delta$ formula as: given positive real number $\epsilon$, have a positive real number $\Delta<\epsilon^{\frac{2}{3}}$, when $\left|z-0\right|=\left|z\right|=\delta$, $\left|zf(z)-0\right|=\left|r^{\frac{3}{2}}e^{\frac{i3\theta}{2}}\right|=r^{\frac{3}{2}}<\Delta^{\frac{3}{2}}<\epsilon$, so I have $$lim_{\delta\rightarrow 0}{\int_{C_{3}}\sqrt{z}dz}=i0(2\pi-0)=0$$. So, I directly get $$I=-\frac{4}{3}$$. Then, I re-calculate $I$ using 2nd contour as shown as , and I get a different result . I also start with the Cauchy Theorem as $\oint_{\Gamma}{\sqrt{z}dz}=\int_{C_1}+\int_{C_2}+\int_{C_3}+\int_{C}$, The $\int_{C}$ is what I want when the radius $\delta$ of small circle turn to $0$ . And I have three results for other three contours which are given as $$\int_{C_{1}}{\sqrt{z}dz}=\int_{C_{1}}{\sqrt{r}e^{i\frac{\pi}{2}}d(re^{i\pi})}=\int_{C_{1}}{-i\sqrt{r}dr}=-i\int_{1}^{0}{\sqrt{r}dr}=i\int_{0}^{1}{\sqrt{r}dr}=i\frac{2}{3}$$ $$\int_{C_{2}}{\sqrt{z}dz}=\int_{C_{2}}{\sqrt{r}e^{i\frac{-\pi}{2}}d(re^{-i\pi})}=\int_{C_{2}}{-i\sqrt{r}d(-r)}=i\int_{C_{2}}{\sqrt{r}dr}=i\int_{0}^{1}{\sqrt{r}dr}=i\frac{2}{3}$$ And I also have $\epsilon-\Delta$ formula:given positive real number $\epsilon$, have a positive real number $\Delta<\epsilon^{\frac{2}{3}}$, when $\left|z-0\right|=\left|z\right|=\delta$, $\left|zf(z)-0\right|=\left|r^{\frac{3}{2}}e^{\frac{i3\theta}{2}}\right|=r^{\frac{3}{2}}<\Delta^{\frac{3}{2}}<\epsilon$, which gives $$lim_{\delta\rightarrow 0}{\int_{C_{3}}\sqrt{z}dz}=i0(\pi+\pi)=0$$. So, I get $$I=-i\frac{4}{3}$$ which is not same as the result given in 1st contour, Is it correct? I know that the complex contour integral depends the kink and path at same time, But the result I wanted is calculate on a ""Closed"" circle in a roughly view. On the other hand, the circle in these two contours actually start/end at different point, i.e. $(0, 2\pi]$ and $(-\pi, \pi]$. May be it is the key point. Can anyone help me fix it? Thanks!!Please!!",,"['real-analysis', 'complex-analysis', 'analysis', 'contour-integration']"
10,Laurent series of $\frac{e^z}{z^2+1}$,Laurent series of,\frac{e^z}{z^2+1},I cant  figure out the laurent series of the following function. Let $f(z)= \frac{e^z}{z^2+1} $ and $|z|\gt 1$ $$\frac{1}{z^2+1}=\sum_{n=0}^{\infty}(-1)^nz^{-2n-2}$$ and $$e^z = \sum_{n=0}^{\infty}\frac{z^{n}}{n!}$$ $$e^z*\frac{1}{z^2+1} =\sum_{n=0}^{\infty}\sum_{k=0}^{n}(-1)^nz^{-2n-2}*\frac{z^{n-k}}{(n-k)!}$$ How can I go from here ?,I cant  figure out the laurent series of the following function. Let $f(z)= \frac{e^z}{z^2+1} $ and $|z|\gt 1$ $$\frac{1}{z^2+1}=\sum_{n=0}^{\infty}(-1)^nz^{-2n-2}$$ and $$e^z = \sum_{n=0}^{\infty}\frac{z^{n}}{n!}$$ $$e^z*\frac{1}{z^2+1} =\sum_{n=0}^{\infty}\sum_{k=0}^{n}(-1)^nz^{-2n-2}*\frac{z^{n-k}}{(n-k)!}$$ How can I go from here ?,,"['sequences-and-series', 'complex-analysis', 'power-series', 'laurent-series', 'cauchy-product']"
11,Confusion concerning the Sokhotski–Plemelj theorem: two different values for the same real integral,Confusion concerning the Sokhotski–Plemelj theorem: two different values for the same real integral,,"A very well-known formula in complex analysis is $ \lim_{\epsilon\to0^+}\int_{-\infty}^\infty\frac{f(x)}{x-x_0\pm i\epsilon}dx = P\int_{-\infty}^\infty \frac{f(x)}{x-x_0}dx \mp i\pi f(x_0), $ known as Sokhotski–Plemelj theorem . I am really puzzled by the meaning of the integral on the left hand side. I understand that this integral comes from an integral over an infinite arc of radius $R$ on the upper-half plane (where the integral goes to zero for $R\to\infty$) plus the real line (after taking the limit $\epsilon\to 0$). Assuming the integrand goes to zero faster than $x^{-1}$ and considering the residue theorem, we get the result: $ \lim_{\epsilon\to0^+}\int_{-\infty}^\infty\frac{f(x)}{x-x_0\pm i\epsilon}dx=2\pi i \text{Res}[f;x_0]. $ Now, if we take the minus sign for $i\epsilon$ and send $\epsilon$ to 0 (without calculating the integral) the above equation yields $2\pi if(x_0)$, while the plus sign yields 0. What is the problem here? Is this related to the fact I can't commute the limit with the integral sign in this case, i.e. $ \lim_{\epsilon\to0^+}\int_{-\infty}^\infty\frac{f(x)}{x-x_0\pm i\epsilon}dx\neq\int_{-\infty}^\infty\frac{f(x)}{x-x_0}dx? $","A very well-known formula in complex analysis is $ \lim_{\epsilon\to0^+}\int_{-\infty}^\infty\frac{f(x)}{x-x_0\pm i\epsilon}dx = P\int_{-\infty}^\infty \frac{f(x)}{x-x_0}dx \mp i\pi f(x_0), $ known as Sokhotski–Plemelj theorem . I am really puzzled by the meaning of the integral on the left hand side. I understand that this integral comes from an integral over an infinite arc of radius $R$ on the upper-half plane (where the integral goes to zero for $R\to\infty$) plus the real line (after taking the limit $\epsilon\to 0$). Assuming the integrand goes to zero faster than $x^{-1}$ and considering the residue theorem, we get the result: $ \lim_{\epsilon\to0^+}\int_{-\infty}^\infty\frac{f(x)}{x-x_0\pm i\epsilon}dx=2\pi i \text{Res}[f;x_0]. $ Now, if we take the minus sign for $i\epsilon$ and send $\epsilon$ to 0 (without calculating the integral) the above equation yields $2\pi if(x_0)$, while the plus sign yields 0. What is the problem here? Is this related to the fact I can't commute the limit with the integral sign in this case, i.e. $ \lim_{\epsilon\to0^+}\int_{-\infty}^\infty\frac{f(x)}{x-x_0\pm i\epsilon}dx\neq\int_{-\infty}^\infty\frac{f(x)}{x-x_0}dx? $",,['complex-analysis']
12,Analytic continuation of power series on the unit whose terms tends to 0,Analytic continuation of power series on the unit whose terms tends to 0,,"This problem is from complex analysis. Set $$f(z)=\sum_{n=0}^{\infty}a_nz^n$$ with convergence radius of 1, and $$\lim_{n \to \infty}a_n=0$$ Prove that if $z_0 \in \partial B(0,1)$ is not a singular point of f(z), then $$\sum_{n=0}^{\infty}a_n z_0^n$$ converges. It's easy to see that if $$\lim_{n \to \infty}na_n=0$$, we can quickly solve it because of Tauber's theorem. But now the condition $$\lim_{n \to \infty}a_n=0$$ seems too weak, is it really sufficient enough for the problem?","This problem is from complex analysis. Set $$f(z)=\sum_{n=0}^{\infty}a_nz^n$$ with convergence radius of 1, and $$\lim_{n \to \infty}a_n=0$$ Prove that if $z_0 \in \partial B(0,1)$ is not a singular point of f(z), then $$\sum_{n=0}^{\infty}a_n z_0^n$$ converges. It's easy to see that if $$\lim_{n \to \infty}na_n=0$$, we can quickly solve it because of Tauber's theorem. But now the condition $$\lim_{n \to \infty}a_n=0$$ seems too weak, is it really sufficient enough for the problem?",,"['complex-analysis', 'analytic-continuation', 'singularity']"
13,Laurent series expansion of $\frac{z^2-1}{z^2+1}$,Laurent series expansion of,\frac{z^2-1}{z^2+1},"Given $f(z) =\frac{z^2-1}{z^2+1}$, I need to find it's Laurent series   expansion at open disk $\sqrt{2} < |z-1| < +\infty$ So at first  I've found that, at $z=\pm i$ function is not defined.Yet I do not quite understand key steps here, so please correct me if I'm mistaken. $$f(z) = 1 - \frac{2}{z^2+1}$$ I need to simplify this expression so I can use known expansion formulas $$L(z) = \frac{2}{z^2+1} = i [\frac{1}{z+i} -  \frac{1}{z-i}] = i [\frac{1}{(z-1)+i+1} -  \frac{1}{(z-1)-(i-1)}]$$ Here I have that $ |\frac{i+1}{z-1}| = |\frac{i-1}{z-1}| < 1$ So I can use known geometric series formula $$L(z) = \frac{i}{z-1} [\frac{1}{\frac{i+1}{z-1}+1} - \frac{1}{1-\frac{i-1}{z-1}}] = \sum_{n=0}^{\infty} \frac{i (-1)^n (i+1)^n}{(z-1)^{n+1}} -  \sum_{n=0}^{\infty} \frac{i (i-1)^n}{(z-1)^{n+1}} = \sum_{n=0}^{\infty} \frac{i [(-1)^n (i+1)^n - (i-1)^n]}{(z-1)^{n+1}}$$ I hope I've not done any mistake till now. My major problem is, that final answer is unreachable, which is $1 + \sum_{n=1}^{\infty}(-1)^n \frac{2^{\frac{n+2}{2}} \sin(\frac{\pi n}{4})}{(z-1)^{n+1}}$. Any hints are much appreciated, thank you","Given $f(z) =\frac{z^2-1}{z^2+1}$, I need to find it's Laurent series   expansion at open disk $\sqrt{2} < |z-1| < +\infty$ So at first  I've found that, at $z=\pm i$ function is not defined.Yet I do not quite understand key steps here, so please correct me if I'm mistaken. $$f(z) = 1 - \frac{2}{z^2+1}$$ I need to simplify this expression so I can use known expansion formulas $$L(z) = \frac{2}{z^2+1} = i [\frac{1}{z+i} -  \frac{1}{z-i}] = i [\frac{1}{(z-1)+i+1} -  \frac{1}{(z-1)-(i-1)}]$$ Here I have that $ |\frac{i+1}{z-1}| = |\frac{i-1}{z-1}| < 1$ So I can use known geometric series formula $$L(z) = \frac{i}{z-1} [\frac{1}{\frac{i+1}{z-1}+1} - \frac{1}{1-\frac{i-1}{z-1}}] = \sum_{n=0}^{\infty} \frac{i (-1)^n (i+1)^n}{(z-1)^{n+1}} -  \sum_{n=0}^{\infty} \frac{i (i-1)^n}{(z-1)^{n+1}} = \sum_{n=0}^{\infty} \frac{i [(-1)^n (i+1)^n - (i-1)^n]}{(z-1)^{n+1}}$$ I hope I've not done any mistake till now. My major problem is, that final answer is unreachable, which is $1 + \sum_{n=1}^{\infty}(-1)^n \frac{2^{\frac{n+2}{2}} \sin(\frac{\pi n}{4})}{(z-1)^{n+1}}$. Any hints are much appreciated, thank you",,"['complex-analysis', 'laurent-series']"
14,Integral of $p(x)\operatorname{csch}(x)$,Integral of,p(x)\operatorname{csch}(x),"I'd like to calculate the following integral $$\int_{-\infty}^{+\infty}\frac{x^4 \left(\frac 1 {a^2+x^2} +\frac 1 {b^2+x^2}\right)}{\sinh^2(x\pi /c)} \, dx$$ where $a$, $b$ and $c$ are positive constants. Any suggestions? I probably have to use contour integrals, but I'm not sure of which would be the most convenient contour, nor if there's an easy way (I know that the solution has something like the Trigamma function on it). Thanks a lot! You've been so helpful with my previous questions!","I'd like to calculate the following integral $$\int_{-\infty}^{+\infty}\frac{x^4 \left(\frac 1 {a^2+x^2} +\frac 1 {b^2+x^2}\right)}{\sinh^2(x\pi /c)} \, dx$$ where $a$, $b$ and $c$ are positive constants. Any suggestions? I probably have to use contour integrals, but I'm not sure of which would be the most convenient contour, nor if there's an easy way (I know that the solution has something like the Trigamma function on it). Thanks a lot! You've been so helpful with my previous questions!",,"['integration', 'complex-analysis', 'improper-integrals', 'contour-integration']"
15,Residue of trace of resolvent,Residue of trace of resolvent,,"I am looking for a way of computing the following integral. Let $A$ be some self-adjoint complex matrix. Let $f(z) = \text{tr} \left( z I - A \right)^{-1} $. Let $\gamma$ be a simple positively-oriented closed curve that goes around some $m$ poles of $f$. The integral is: $$ J = \oint_{\gamma} f(z) dz $$ I want to show that $J= 2 \pi i m$ somehow by pure complex analysis means without resorting to the spectral theorem, diagonalization or even eigenvalue problem. It is not true in general for the residues of a rational function.","I am looking for a way of computing the following integral. Let $A$ be some self-adjoint complex matrix. Let $f(z) = \text{tr} \left( z I - A \right)^{-1} $. Let $\gamma$ be a simple positively-oriented closed curve that goes around some $m$ poles of $f$. The integral is: $$ J = \oint_{\gamma} f(z) dz $$ I want to show that $J= 2 \pi i m$ somehow by pure complex analysis means without resorting to the spectral theorem, diagonalization or even eigenvalue problem. It is not true in general for the residues of a rational function.",,"['linear-algebra', 'complex-analysis']"
16,Solution to Cauchy-Riemann Differential Equation of Compact Support,Solution to Cauchy-Riemann Differential Equation of Compact Support,,"I'm working through Forster's $\textit{Lectures on Riemann Surfaces}$ and am struggling with the following problem: Suppose $g \in \mathcal{E}(\mathbb{C})$ is of compact support. Prove there is a solution $f \in \mathcal{E}(\mathbb{C})$ of the equation $\partial f/\partial \bar{z} = g$ having compact support iff $$\int \int_{\mathbb{C}} z^n g(z)dz   \wedge d\bar{z} = 0$$ for all $n \in \mathbb{N}$. Here, $\mathcal{E}(\mathbb{C})$ denotes the $\mathbb{C}$-algebra of functions differentiable with respect to the coordinate $x$ and $y$ (where $z=x+iy$). We already have a solution, namely $f(\zeta) = \int \int_{\mathbb{C}} \frac{g(z)}{z-\zeta} dz \wedge d\bar{z}$, but it is not necessarily of compact support. I really don't have a good approach to the problem; maybe just a hint would be nice, not a full solution.","I'm working through Forster's $\textit{Lectures on Riemann Surfaces}$ and am struggling with the following problem: Suppose $g \in \mathcal{E}(\mathbb{C})$ is of compact support. Prove there is a solution $f \in \mathcal{E}(\mathbb{C})$ of the equation $\partial f/\partial \bar{z} = g$ having compact support iff $$\int \int_{\mathbb{C}} z^n g(z)dz   \wedge d\bar{z} = 0$$ for all $n \in \mathbb{N}$. Here, $\mathcal{E}(\mathbb{C})$ denotes the $\mathbb{C}$-algebra of functions differentiable with respect to the coordinate $x$ and $y$ (where $z=x+iy$). We already have a solution, namely $f(\zeta) = \int \int_{\mathbb{C}} \frac{g(z)}{z-\zeta} dz \wedge d\bar{z}$, but it is not necessarily of compact support. I really don't have a good approach to the problem; maybe just a hint would be nice, not a full solution.",,"['complex-analysis', 'ordinary-differential-equations', 'differential-forms', 'riemann-surfaces']"
17,A counterexample of Riemann mapping theorem in high dimension,A counterexample of Riemann mapping theorem in high dimension,,"There is an exercise (1.1.16) in Huybrechts: the polidisc $B_{(1,1)}(0)\subset\mathbb C^2$ and the unit disc $D$ in $\mathbb C^2$ can not be biholomorphic. The hint is to compare the automorphisms of these two sets. The unitary matrices is a subgroup of the group of biholomorphic maps of $D$ which leaves the origin fixed. Clearly, the group of unitary matrices of $\dim 2$ is not abelian and the group of biholomorphic maps of $B_{(1,1)}(0)$ is transitive. If we can show the group of biholomorphic maps of $B_{(1,1)}(0)$ which leave invariant the origin is abelian, then this will complete the proof. If we set $f_1(z_1,z_2)=(z_2,z_1)$ and $f_2(z_1,z_2)=(e^{i\pi/3}z_1,e^{i2\pi/3}z_2)$, then these are clearly in biholomorphic maps of $B_{(1,1)}(0)$. However, $f_1\circ f_2\neq f_2\circ f_1$. Please tell me where is the problem. Any hint is helpful. Thx.","There is an exercise (1.1.16) in Huybrechts: the polidisc $B_{(1,1)}(0)\subset\mathbb C^2$ and the unit disc $D$ in $\mathbb C^2$ can not be biholomorphic. The hint is to compare the automorphisms of these two sets. The unitary matrices is a subgroup of the group of biholomorphic maps of $D$ which leaves the origin fixed. Clearly, the group of unitary matrices of $\dim 2$ is not abelian and the group of biholomorphic maps of $B_{(1,1)}(0)$ is transitive. If we can show the group of biholomorphic maps of $B_{(1,1)}(0)$ which leave invariant the origin is abelian, then this will complete the proof. If we set $f_1(z_1,z_2)=(z_2,z_1)$ and $f_2(z_1,z_2)=(e^{i\pi/3}z_1,e^{i2\pi/3}z_2)$, then these are clearly in biholomorphic maps of $B_{(1,1)}(0)$. However, $f_1\circ f_2\neq f_2\circ f_1$. Please tell me where is the problem. Any hint is helpful. Thx.",,"['complex-analysis', 'complex-geometry', 'several-complex-variables']"
18,How to integrate |z| dz?,How to integrate |z| dz?,,"As the title says, how do we integrate $|z|dz$ on a straight line on the complex plane? Suppose that I've already known the parametrization. If it were on reals, we would break the integral down to multiple parts where z changes sign, but how do I do that on the complex plane? Is it just simply the formula for absolute value (square root of the sum of the squares of real and imaginary parts)?","As the title says, how do we integrate $|z|dz$ on a straight line on the complex plane? Suppose that I've already known the parametrization. If it were on reals, we would break the integral down to multiple parts where z changes sign, but how do I do that on the complex plane? Is it just simply the formula for absolute value (square root of the sum of the squares of real and imaginary parts)?",,"['integration', 'complex-analysis', 'complex-integration']"
19,"Are holomorphic maps that ""almost"" preserve norm ""almost"" rotations?","Are holomorphic maps that ""almost"" preserve norm ""almost"" rotations?",,"Let's say I have a sequence of injective holomorphic maps $f_n \colon \mathbb{D} \to \mathbb{D}$ such that $f_n(0) = 0$. The main thing is that $f$ ""almost preserves norms"" in the sense that for all nonzero $z$, $$ r_n |\,z\,| < |\,f(z)\,| < |\,z\,| $$ where $r_n \nearrow 1$. Does it follow that the $f_n$ approximate rotations? More precisely, let's assume that $f_n'(0) > 0$ for every $n$ (in fact by Schwarz lemma-esque reasoning we can get that $f_n'(0) \to 1$). Is it true that $f_n \to \text{Id}$ pointwise/uniformly on compacts? This was inspired by an exercise in Stein and Shakarchi's complex analysis book. Edited to add: My motivation in asking this question comes from the Riemann mapping theorem. I'm interested in the relationship between the magnitude of the derivative of a mapping $f \colon K \to D$ at the origin and the size of the largest disk it contains. Indeed such a $K$ must contain a disc about the origin, and if you assume that $|\,f(z)\,| > |\,z\,|$ for all $z \neq 0$ you get that $f$ increases the size of $K$, and also that $|\,f'(0)\,| > 1$. If you keep expanding $K$ by chaining these maps, the ""tail expansions"" from large domains to $\mathbb{D}$ should look somewhat like rotations, I think. And if they look like rotations the only way for their derivative at the origin to be positive is for them to be almost trivial rotations.","Let's say I have a sequence of injective holomorphic maps $f_n \colon \mathbb{D} \to \mathbb{D}$ such that $f_n(0) = 0$. The main thing is that $f$ ""almost preserves norms"" in the sense that for all nonzero $z$, $$ r_n |\,z\,| < |\,f(z)\,| < |\,z\,| $$ where $r_n \nearrow 1$. Does it follow that the $f_n$ approximate rotations? More precisely, let's assume that $f_n'(0) > 0$ for every $n$ (in fact by Schwarz lemma-esque reasoning we can get that $f_n'(0) \to 1$). Is it true that $f_n \to \text{Id}$ pointwise/uniformly on compacts? This was inspired by an exercise in Stein and Shakarchi's complex analysis book. Edited to add: My motivation in asking this question comes from the Riemann mapping theorem. I'm interested in the relationship between the magnitude of the derivative of a mapping $f \colon K \to D$ at the origin and the size of the largest disk it contains. Indeed such a $K$ must contain a disc about the origin, and if you assume that $|\,f(z)\,| > |\,z\,|$ for all $z \neq 0$ you get that $f$ increases the size of $K$, and also that $|\,f'(0)\,| > 1$. If you keep expanding $K$ by chaining these maps, the ""tail expansions"" from large domains to $\mathbb{D}$ should look somewhat like rotations, I think. And if they look like rotations the only way for their derivative at the origin to be positive is for them to be almost trivial rotations.",,"['complex-analysis', 'conformal-geometry']"
20,Find the value of,Find the value of,,"$\int_{c}\dfrac {1}{\left( z-\alpha \right) ^{3}}dz$ Where C is some closed anti clockwise contour which does not pass through alpha. I was thinking to use Cauchys integral formula, but didnt know if it was applicable due to the cubic term on the bottom. I've got a few questions: -How would we calculate this  -What would happen if the contour did go trough alpha ? -Why does the contour need to be anticlockwise ? Thanks Tom","$\int_{c}\dfrac {1}{\left( z-\alpha \right) ^{3}}dz$ Where C is some closed anti clockwise contour which does not pass through alpha. I was thinking to use Cauchys integral formula, but didnt know if it was applicable due to the cubic term on the bottom. I've got a few questions: -How would we calculate this  -What would happen if the contour did go trough alpha ? -Why does the contour need to be anticlockwise ? Thanks Tom",,['complex-analysis']
21,"Is it true that $log(i) = \frac\pi2i$ ? If so, are both of these legitimate proofs? They seem too beautiful not to be...","Is it true that  ? If so, are both of these legitimate proofs? They seem too beautiful not to be...",log(i) = \frac\pi2i,"Sorry if this is a naive question. I have not yet taken any upper level math courses involving complex numbers. However, in preparation for those courses, together with utilizing the knowledge that mathematicians such as Euler would just play around with infinite series, led me to this result. This seems too beautiful not to be true. If it is true, could someone explain the general framework from which this is derived? Statement: $$log(i) = \frac\pi2i$$ Proof One: By Euler's Identity $e^{ix} = cos{x} + isin{x}$ So that $$e^{\frac\pi2i} = cos\frac\pi2 + isin\frac\pi2 = i$$ But $$e^{log(i)} = i$$ Thus $$e^{log(i)} = e^{\frac\pi2i}$$ So that $$log(i) = \frac\pi2i$$ Proof Two: Using Power Series $$log(i) = log(\frac{2i}2) = log\left(\frac{(1+i)(1+i)}{(1+i)(1-i)}\right) = log\left(\frac{1+i}{1-i}\right) = log(1+i) - log(1-i)$$ But $$ log(1+i) = i - \frac{i^2}2 + \frac{i^3}3 - \frac{i^4}4 + ...$$ And $$-log(1-i) = i + \frac{i^2}2 + \frac{i^3}3 + \frac{i^4}4 + ...$$ Thus $$log(1+i) - log(1-i) = 2\{i + \frac{i^3}3 + \frac{i^5}5 + \frac{i^7}7 + ...\} = 2i\{1 - \frac13 + \frac15 - \frac17 + ...\} = 2i\frac\pi4 = \frac\pi2i$$ Therefore $$log(i) = \frac\pi2i$$ Added June 4, 2016: I found a delightful identity for logarithms of complex quantites in general as opposed to the case $a+bi = i$. Since the proof is essentially a generalization of my proof that $log(i) = \frac{\pi}{2}i$ as well as being aesthetically pleasing I thought it was worth posting. Statement: $$log\left(a+bi\right) = \frac{1}{2}log\left(a^{2}+b^{2}\right) + itan^{-1}\frac{b}{a}$$ Proof: $$log\left(a+bi\right) = log\left({\sqrt{a^{2}+b^{2}}}{\frac{a+bi} {\sqrt{a^{2}+b^{2}}}}\right) = \frac{1}{2}log\left(a^{2}+b^{2}\right) + log\left({\frac{a+bi}{\sqrt{a^{2}+b^{2}}}}\right)$$ Now, $$log\left({\frac{a+bi}{\sqrt{a^{2}+b^{2}}}}\right) = log\left({\frac{1+i\frac{b}{a}}{\sqrt{1+\frac{b^{2}}{a^2}}}}\right) = log\left({1+i\frac{b}{a}}\right) - \frac{1}{2}log\left(1+\frac{b^{2}}{a^2}\right)$$ But, $$log\left(1+i\frac{b}{a}\right) = \left(i\frac{b}{a}\right)-\frac{1}{2}{\left(i\frac{b}{a}\right)}^{2} + \frac{1}{3}{\left(i\frac{b}{a}\right)}^{3} - \frac{1}{4}{\left(i\frac{b}{a}\right)}^{4} +... =  i\left( \left(\frac{b}{a}\right)-\frac{1}{3}{\left(\frac{b}{a}\right)}^{3} + \frac{1}{5}{\left(\frac{b}{a}\right)}^{5} - \frac{1}{7}{\left(\frac{b}{a}\right)}^{7} +... \right) + \\ \frac{1}{2}\left(\frac{b}{a}\right)-\frac{1}{4}{\left(\frac{b}{a}\right)}^{4} + \frac{1}{6}{\left(\frac{b}{a}\right)}^{6} - \frac{1}{8}{\left(\frac{b}{a}\right)}^{8} +...$$ And,$$ \frac{1}{2}log\left(1+\frac{b^2}{a^2}\right) = \frac{1}{2}\left(\left({\frac{b^{2}}{a^{2}}}\right) - \frac{1}{2}\left({\frac{b^{2}}{a^{2}}}\right)^{2} + \frac{1}{3}\left({\frac{b^{2}}{a^{2}}}\right)^{3} - \frac{1}{4}\left({\frac{b^{2}}{a^{2}}}\right)^{4} +...\right) = \\ \frac{1}{2}\left(\frac{b}{a}\right)^{2}-\frac{1}{4}{\left(\frac{b}{a}\right)}^{4} + \frac{1}{6}{\left(\frac{b}{a}\right)}^{6} - \frac{1}{8}{\left(\frac{b}{a}\right)}^{8} +...$$ So that, $$log\left({1+i\frac{b}{a}}\right) - \frac{1}{2}log\left(1+\frac{b^{2}}{a^2}\right) = i\left( \left(\frac{b}{a}\right)-\frac{1}{3}{\left(\frac{b}{a}\right)}^{3} + \frac{1}{5}{\left(\frac{b}{a}\right)}^{5} - \frac{1}{7}{\left(\frac{b}{a}\right)}^{7} +... \right) = itan^{-1}{\frac{b}{a}}$$ Therefore, $$log(a+bi) = \frac{1}{2}log(a^{2}+b^{2}) + itan^{-1}\frac{b}{a}$$  Example: Let a=0 and b=1 and we have  $$log(i) = itan^{-1}\infty = \frac{\pi}{2}i + 2\pi mi$$","Sorry if this is a naive question. I have not yet taken any upper level math courses involving complex numbers. However, in preparation for those courses, together with utilizing the knowledge that mathematicians such as Euler would just play around with infinite series, led me to this result. This seems too beautiful not to be true. If it is true, could someone explain the general framework from which this is derived? Statement: $$log(i) = \frac\pi2i$$ Proof One: By Euler's Identity $e^{ix} = cos{x} + isin{x}$ So that $$e^{\frac\pi2i} = cos\frac\pi2 + isin\frac\pi2 = i$$ But $$e^{log(i)} = i$$ Thus $$e^{log(i)} = e^{\frac\pi2i}$$ So that $$log(i) = \frac\pi2i$$ Proof Two: Using Power Series $$log(i) = log(\frac{2i}2) = log\left(\frac{(1+i)(1+i)}{(1+i)(1-i)}\right) = log\left(\frac{1+i}{1-i}\right) = log(1+i) - log(1-i)$$ But $$ log(1+i) = i - \frac{i^2}2 + \frac{i^3}3 - \frac{i^4}4 + ...$$ And $$-log(1-i) = i + \frac{i^2}2 + \frac{i^3}3 + \frac{i^4}4 + ...$$ Thus $$log(1+i) - log(1-i) = 2\{i + \frac{i^3}3 + \frac{i^5}5 + \frac{i^7}7 + ...\} = 2i\{1 - \frac13 + \frac15 - \frac17 + ...\} = 2i\frac\pi4 = \frac\pi2i$$ Therefore $$log(i) = \frac\pi2i$$ Added June 4, 2016: I found a delightful identity for logarithms of complex quantites in general as opposed to the case $a+bi = i$. Since the proof is essentially a generalization of my proof that $log(i) = \frac{\pi}{2}i$ as well as being aesthetically pleasing I thought it was worth posting. Statement: $$log\left(a+bi\right) = \frac{1}{2}log\left(a^{2}+b^{2}\right) + itan^{-1}\frac{b}{a}$$ Proof: $$log\left(a+bi\right) = log\left({\sqrt{a^{2}+b^{2}}}{\frac{a+bi} {\sqrt{a^{2}+b^{2}}}}\right) = \frac{1}{2}log\left(a^{2}+b^{2}\right) + log\left({\frac{a+bi}{\sqrt{a^{2}+b^{2}}}}\right)$$ Now, $$log\left({\frac{a+bi}{\sqrt{a^{2}+b^{2}}}}\right) = log\left({\frac{1+i\frac{b}{a}}{\sqrt{1+\frac{b^{2}}{a^2}}}}\right) = log\left({1+i\frac{b}{a}}\right) - \frac{1}{2}log\left(1+\frac{b^{2}}{a^2}\right)$$ But, $$log\left(1+i\frac{b}{a}\right) = \left(i\frac{b}{a}\right)-\frac{1}{2}{\left(i\frac{b}{a}\right)}^{2} + \frac{1}{3}{\left(i\frac{b}{a}\right)}^{3} - \frac{1}{4}{\left(i\frac{b}{a}\right)}^{4} +... =  i\left( \left(\frac{b}{a}\right)-\frac{1}{3}{\left(\frac{b}{a}\right)}^{3} + \frac{1}{5}{\left(\frac{b}{a}\right)}^{5} - \frac{1}{7}{\left(\frac{b}{a}\right)}^{7} +... \right) + \\ \frac{1}{2}\left(\frac{b}{a}\right)-\frac{1}{4}{\left(\frac{b}{a}\right)}^{4} + \frac{1}{6}{\left(\frac{b}{a}\right)}^{6} - \frac{1}{8}{\left(\frac{b}{a}\right)}^{8} +...$$ And,$$ \frac{1}{2}log\left(1+\frac{b^2}{a^2}\right) = \frac{1}{2}\left(\left({\frac{b^{2}}{a^{2}}}\right) - \frac{1}{2}\left({\frac{b^{2}}{a^{2}}}\right)^{2} + \frac{1}{3}\left({\frac{b^{2}}{a^{2}}}\right)^{3} - \frac{1}{4}\left({\frac{b^{2}}{a^{2}}}\right)^{4} +...\right) = \\ \frac{1}{2}\left(\frac{b}{a}\right)^{2}-\frac{1}{4}{\left(\frac{b}{a}\right)}^{4} + \frac{1}{6}{\left(\frac{b}{a}\right)}^{6} - \frac{1}{8}{\left(\frac{b}{a}\right)}^{8} +...$$ So that, $$log\left({1+i\frac{b}{a}}\right) - \frac{1}{2}log\left(1+\frac{b^{2}}{a^2}\right) = i\left( \left(\frac{b}{a}\right)-\frac{1}{3}{\left(\frac{b}{a}\right)}^{3} + \frac{1}{5}{\left(\frac{b}{a}\right)}^{5} - \frac{1}{7}{\left(\frac{b}{a}\right)}^{7} +... \right) = itan^{-1}{\frac{b}{a}}$$ Therefore, $$log(a+bi) = \frac{1}{2}log(a^{2}+b^{2}) + itan^{-1}\frac{b}{a}$$  Example: Let a=0 and b=1 and we have  $$log(i) = itan^{-1}\infty = \frac{\pi}{2}i + 2\pi mi$$",,"['calculus', 'sequences-and-series', 'complex-analysis', 'complex-numbers', 'power-series']"
22,Stein and Shakarchi potential typo?,Stein and Shakarchi potential typo?,,"I'm working through Chapter 6 in Complex Analysis by Stein and Shakarchi, and problem 3 is as follows: If $Q(x)=\lbrace x\rbrace-1/2$, then we can write the expression in the previous problem as $$\zeta(s)=\frac{s}{s-1}-\frac{1}{2}-s\int_1^\infty\frac{Q(x)}{x^{s+1}}\mathrm{d}x$$ The expression in the previous problem is $$\zeta(s)=\frac{s}{s-1}-s\int_1^\infty\frac{\lbrace x\rbrace}{x^{s+1}}\mathrm{d}x$$ which I've already shown to be true.  Also, the notation $\lbrace x\rbrace$ denotes the ffractional part of $x$. My issue is in the $-1/2$ term in the first equation.  Shouldn't it have a factor of $s$ in it?  I just want to make sure that there is a typo before I assume so, as I'd rather not have future work rendered useless by a wrong assumption.","I'm working through Chapter 6 in Complex Analysis by Stein and Shakarchi, and problem 3 is as follows: If $Q(x)=\lbrace x\rbrace-1/2$, then we can write the expression in the previous problem as $$\zeta(s)=\frac{s}{s-1}-\frac{1}{2}-s\int_1^\infty\frac{Q(x)}{x^{s+1}}\mathrm{d}x$$ The expression in the previous problem is $$\zeta(s)=\frac{s}{s-1}-s\int_1^\infty\frac{\lbrace x\rbrace}{x^{s+1}}\mathrm{d}x$$ which I've already shown to be true.  Also, the notation $\lbrace x\rbrace$ denotes the ffractional part of $x$. My issue is in the $-1/2$ term in the first equation.  Shouldn't it have a factor of $s$ in it?  I just want to make sure that there is a typo before I assume so, as I'd rather not have future work rendered useless by a wrong assumption.",,['complex-analysis']
23,The closure of $\{ z:|f(z)|<c\}$ is the set $\{z:|f(z)|\leq c\}$.,The closure of  is the set .,\{ z:|f(z)|<c\} \{z:|f(z)|\leq c\},"Exercise: Let $f$ be entire and non-constant. For any positive real number $c>0$ show that the closure of $\{ z:|f(z)|<c\}$ is the set $\{z:|f(z)|\leq c\}$. Solution: Let $\varepsilon>0$ and define $A:=\{ z:|f(z)|<c\}$. Then, because $f$ is continuous (via entire) and non-constant, there exists $z\in A$ such that $$B(c;\varepsilon)\cap A \neq \varnothing .$$ That is to say that $c$ is a limit point of $A$. Since $A^-$ must contain all of its limit points, we have that $\{z:|f(z)|\leq c\}$. Is my solution correct? I have another way of doing it using a sequence $z_n\to z$, but I would prefer to use the above if it correct. The reason I am feeling unsure about my solution is because I am not sure how we know (geometrically) that $|f(z)|$ goes all the way up to the boundary (i.e. $c$). Is it safe to say that $|f(z)$ gets infinitely close to $c$ but does not touch because $f$ is entire & non-constant? FYI I am new at these concepts so please be a detailed as possible. Thank you in advance! Note: I am using the notation $A^-$ to indicate the closure of $A$. This is the notation used in my text (Complex, Conway) and I suspect it is used as to not be confused with the complex conjugate.","Exercise: Let $f$ be entire and non-constant. For any positive real number $c>0$ show that the closure of $\{ z:|f(z)|<c\}$ is the set $\{z:|f(z)|\leq c\}$. Solution: Let $\varepsilon>0$ and define $A:=\{ z:|f(z)|<c\}$. Then, because $f$ is continuous (via entire) and non-constant, there exists $z\in A$ such that $$B(c;\varepsilon)\cap A \neq \varnothing .$$ That is to say that $c$ is a limit point of $A$. Since $A^-$ must contain all of its limit points, we have that $\{z:|f(z)|\leq c\}$. Is my solution correct? I have another way of doing it using a sequence $z_n\to z$, but I would prefer to use the above if it correct. The reason I am feeling unsure about my solution is because I am not sure how we know (geometrically) that $|f(z)|$ goes all the way up to the boundary (i.e. $c$). Is it safe to say that $|f(z)$ gets infinitely close to $c$ but does not touch because $f$ is entire & non-constant? FYI I am new at these concepts so please be a detailed as possible. Thank you in advance! Note: I am using the notation $A^-$ to indicate the closure of $A$. This is the notation used in my text (Complex, Conway) and I suspect it is used as to not be confused with the complex conjugate.",,"['general-topology', 'complex-analysis', 'entire-functions']"
24,$\lim_{y\rightarrow 0^{+}}(f(x+iy)-f(x-iy))$,,\lim_{y\rightarrow 0^{+}}(f(x+iy)-f(x-iy)),"I was trying to solve this exercize. Let $\varphi:[0,1]\rightarrow\mathbb{C}$ be a continuous function and  $$f(z)=\int_{0}^1 \dfrac{\varphi(t)}{t-z} dt, z\in\mathbb{C}\setminus[0,1].$$ I was able to prove that $f$ is holomorphic and $$f^{(k)}(z)=k!\int_{0}^1 \dfrac{\varphi(t)}{(t-z)^{k+1}} dt$$ I want to find $$\lim_{y\rightarrow 0^{+}}(f(x+iy)-f(x-iy)),$$ for $x\in[0,1]$. I guess that the limit should be an expression of $\varphi(x)$, but apart from that I have no idea even how to start. Any ideas?","I was trying to solve this exercize. Let $\varphi:[0,1]\rightarrow\mathbb{C}$ be a continuous function and  $$f(z)=\int_{0}^1 \dfrac{\varphi(t)}{t-z} dt, z\in\mathbb{C}\setminus[0,1].$$ I was able to prove that $f$ is holomorphic and $$f^{(k)}(z)=k!\int_{0}^1 \dfrac{\varphi(t)}{(t-z)^{k+1}} dt$$ I want to find $$\lim_{y\rightarrow 0^{+}}(f(x+iy)-f(x-iy)),$$ for $x\in[0,1]$. I guess that the limit should be an expression of $\varphi(x)$, but apart from that I have no idea even how to start. Any ideas?",,['complex-analysis']
25,Formula for analytic function using Schwartz's Lemma,Formula for analytic function using Schwartz's Lemma,,"I've been working on the following problem from Conway's complex variables book: Suppose $f$ is analytic in some region containing $\overline{B(0,1)}$ and $|f(z)|=1$ where $|z|=1$. Find a formula for $f$. (Hint: First consider the case where $f$ has no zeros in $B(0,1$). First, we know that if $f$ has no zeros in $B(0,1)$, it is a constant (this was an earlier problem in the book). In general, I believe $f$ has the form $$f=c\prod_{i=1}^m\phi_{a_i}(z)^{m_i}$$ where $\phi_a(z)=\frac{z-a}{1-\overline{a}z}$ and $|c|=1$. Here's an incomplete justification as to why: First, if $f$ has one zero of order $1$ at, say $a$, it is one-to-one in a neighborhood of $a$ so $f$ has the form $f=c\phi_a$ where $|c|=1$ (I realized there's a problem here, because to apply the theorem which tells us that, we need $f$ to be one-to-one on all of $B(0,1)$, not just a neighborhood of $a$. Second, if $f$ has a zero of order $m$ at $a$, then write $f(z)=(z-a)^{m-1}h(z)$ where $h$ has a root of order $1$ at $a$. Define $g(z)=(1-\overline{a}z)^{m-1}$, which has a root of order $1$ at $a$, to write $$f(z)=\frac{(z-a)^{m-1}}{(1-\overline{a}z)^{m-1}}g(z)$$ and apply the above to obtain $f(z)=c\phi_a(z)^m$. Now for any $f$, it has finitely many zeros in $B(0,1)$ and so I want to just take the product of the above, but I'm not sure how to justify that, either. Thank you.","I've been working on the following problem from Conway's complex variables book: Suppose $f$ is analytic in some region containing $\overline{B(0,1)}$ and $|f(z)|=1$ where $|z|=1$. Find a formula for $f$. (Hint: First consider the case where $f$ has no zeros in $B(0,1$). First, we know that if $f$ has no zeros in $B(0,1)$, it is a constant (this was an earlier problem in the book). In general, I believe $f$ has the form $$f=c\prod_{i=1}^m\phi_{a_i}(z)^{m_i}$$ where $\phi_a(z)=\frac{z-a}{1-\overline{a}z}$ and $|c|=1$. Here's an incomplete justification as to why: First, if $f$ has one zero of order $1$ at, say $a$, it is one-to-one in a neighborhood of $a$ so $f$ has the form $f=c\phi_a$ where $|c|=1$ (I realized there's a problem here, because to apply the theorem which tells us that, we need $f$ to be one-to-one on all of $B(0,1)$, not just a neighborhood of $a$. Second, if $f$ has a zero of order $m$ at $a$, then write $f(z)=(z-a)^{m-1}h(z)$ where $h$ has a root of order $1$ at $a$. Define $g(z)=(1-\overline{a}z)^{m-1}$, which has a root of order $1$ at $a$, to write $$f(z)=\frac{(z-a)^{m-1}}{(1-\overline{a}z)^{m-1}}g(z)$$ and apply the above to obtain $f(z)=c\phi_a(z)^m$. Now for any $f$, it has finitely many zeros in $B(0,1)$ and so I want to just take the product of the above, but I'm not sure how to justify that, either. Thank you.",,"['complex-analysis', 'analysis']"
26,How to deduce the poles and residues just by looking?,How to deduce the poles and residues just by looking?,,"Let $$f(z)=\frac{5z-2}{z(z-1)}$$ Then $f$ has simple poles at $0,1$ with $\text{Res}(f,0)=2$ and $\text{Res}(f,1)=3$. How can one tell this? The way I did it was to say $z(z-1)=z^2-z$ which vanishes at $0,1$ yet its derivative $2z-1$ does not vanish at either $0,1$ and also $5z-2$ doesn't vanish at $0,1$ so $f(z)$ has simple poles at $0,1$ and then $\text{Res}(f,0)=\lim_{z \rightarrow 0} \frac{5z-2}{z-1}=2$ and similarly for the other residue. Is there a better/quicker way?","Let $$f(z)=\frac{5z-2}{z(z-1)}$$ Then $f$ has simple poles at $0,1$ with $\text{Res}(f,0)=2$ and $\text{Res}(f,1)=3$. How can one tell this? The way I did it was to say $z(z-1)=z^2-z$ which vanishes at $0,1$ yet its derivative $2z-1$ does not vanish at either $0,1$ and also $5z-2$ doesn't vanish at $0,1$ so $f(z)$ has simple poles at $0,1$ and then $\text{Res}(f,0)=\lim_{z \rightarrow 0} \frac{5z-2}{z-1}=2$ and similarly for the other residue. Is there a better/quicker way?",,['complex-analysis']
27,How is the principal branch of logarithm defined?,How is the principal branch of logarithm defined?,,"In my textbook, it is defined as: $$\operatorname{Log} z = \ln |z| + i \operatorname{Arg} z$$ Where $\operatorname{Arg}$ is the principal branch of $\arg$, that's, the function which outputs the unique argument of $z$ in the interval $(-\pi, \pi]$. However, I am reading from Ahlfors' Complex Analysis, and on page $71$, it is written: ""...define the principal branch of logarithm by the condition $| \operatorname{Im log} z | < \pi$"". Which one is the correct definition? They are essentially different definitions because one includes the possibility that $\operatorname{Im log} z = \pi$.","In my textbook, it is defined as: $$\operatorname{Log} z = \ln |z| + i \operatorname{Arg} z$$ Where $\operatorname{Arg}$ is the principal branch of $\arg$, that's, the function which outputs the unique argument of $z$ in the interval $(-\pi, \pi]$. However, I am reading from Ahlfors' Complex Analysis, and on page $71$, it is written: ""...define the principal branch of logarithm by the condition $| \operatorname{Im log} z | < \pi$"". Which one is the correct definition? They are essentially different definitions because one includes the possibility that $\operatorname{Im log} z = \pi$.",,['complex-analysis']
28,How to expand $f(z)$ as a Laurent Series,How to expand  as a Laurent Series,f(z),"Given $$\frac{z}{(z-1)(z+2i)}$$ expand $f(z)$ in the following regions: $|z|<1$, $1<|z|<2$, $|z|>2$ I'm preparing for an exam and Laurent Series are a weakness of mine. I would love advice regarding interpretation, understanding, and solution of the problem.","Given $$\frac{z}{(z-1)(z+2i)}$$ expand $f(z)$ in the following regions: $|z|<1$, $1<|z|<2$, $|z|>2$ I'm preparing for an exam and Laurent Series are a weakness of mine. I would love advice regarding interpretation, understanding, and solution of the problem.",,"['sequences-and-series', 'complex-analysis', 'laurent-series']"
29,A problem to show a certain sum is invariant in some Euclidean geometric configurations.,A problem to show a certain sum is invariant in some Euclidean geometric configurations.,,"$\textbf{Problem.}$ Suppose circles of radius $r$ and radius $s$ are externally tangent at the point $1/2$ and internally tangent to the unit circle. There are infinitely many such configurations, one of which is illustrated in the diagram below. Prove that $\displaystyle\frac{1}{r}+\frac{1}{s}=\frac{16}{3}$ for every such configuration. The above problem appeared in a complex analysis exam in some graduate school. I tried number of things, but nothing worked yet and I have little clue about what I should do to solve this problem. One of the thing I tried is just setting the given configuration into the following equations by setting the centers of the circles as $p,q$ to obtain $|p-\frac{1}{2}|=r,|q-\frac{1}{2}|=s,|p|+r=|q|+s=1,r+s=|p-q|$ and to try some random computations but it didn't work. I also tried to use some Mobius transform but it didn't work. Please let me know how to solve this or if this problem is related to some known stuff.","$\textbf{Problem.}$ Suppose circles of radius $r$ and radius $s$ are externally tangent at the point $1/2$ and internally tangent to the unit circle. There are infinitely many such configurations, one of which is illustrated in the diagram below. Prove that $\displaystyle\frac{1}{r}+\frac{1}{s}=\frac{16}{3}$ for every such configuration. The above problem appeared in a complex analysis exam in some graduate school. I tried number of things, but nothing worked yet and I have little clue about what I should do to solve this problem. One of the thing I tried is just setting the given configuration into the following equations by setting the centers of the circles as $p,q$ to obtain $|p-\frac{1}{2}|=r,|q-\frac{1}{2}|=s,|p|+r=|q|+s=1,r+s=|p-q|$ and to try some random computations but it didn't work. I also tried to use some Mobius transform but it didn't work. Please let me know how to solve this or if this problem is related to some known stuff.",,"['complex-analysis', 'euclidean-geometry']"
30,A basis for the algebra $\mathbb{C}\{z^{\alpha}(1-z)^{\beta}\}$?,A basis for the algebra ?,\mathbb{C}\{z^{\alpha}(1-z)^{\beta}\},"Let us consider the domain  $$ \Omega=\mathbb{C}\setminus (]-\infty, 0]\,\cup\,[1,+\infty[) $$  (the doubly cleft plane). On it, we have the functions, $z^{\alpha}(1-z)^{\beta}$ for $\alpha,\beta\in \mathbb{C}$. We want to find a basis of the $\mathbb{C}$ - linear span of these fonctions (which form a monoid) denoted here $\mathcal{A}$.  $$ \mathcal{A}=span_\mathbb{C}\{z^{\alpha}(1-z)^{\beta}\}_{\alpha,\beta\in \mathbb{C}} $$ Beginning with $\alpha,\beta\in \mathbb{R}$ and using the four relations $\frac{z}{1-z}=\frac{1}{1-z}-1$ (first quadrant) $\frac{1-z}{z}=\frac{1}{z}-1$ (second quadrant) $1=(1-z)+z$ (third quadrant) $z=1-(1-z)$ (fourth quadrant) one can prove that the set $\{z^{\alpha}(1-z)^{\beta}\}_{(\alpha,\beta)\in D}$ where $D$ is the domain  $$ D=\{(\alpha,\beta)\in \mathbb{R}^2\,|\,  0\leq \alpha<1\}=[0,1[\times \mathbb{R} $$ is (linearly) generating $\mathcal{A}$. On the basis of examples, I smell that it is a basis of it but cannot prove that they are linearly independent. Q1) Does anybody have a hint for proving that $\{z^{\alpha}(1-z)^{\beta}\}_{(\alpha,\beta)\in D}$ are $\mathbb{R}$-linearly independent ? $\mathbb{C}$-linearly independent ? Q2) Stronger question : find a similar ""fundamental domain"" for $\alpha,\beta\in \mathbb{C}$.","Let us consider the domain  $$ \Omega=\mathbb{C}\setminus (]-\infty, 0]\,\cup\,[1,+\infty[) $$  (the doubly cleft plane). On it, we have the functions, $z^{\alpha}(1-z)^{\beta}$ for $\alpha,\beta\in \mathbb{C}$. We want to find a basis of the $\mathbb{C}$ - linear span of these fonctions (which form a monoid) denoted here $\mathcal{A}$.  $$ \mathcal{A}=span_\mathbb{C}\{z^{\alpha}(1-z)^{\beta}\}_{\alpha,\beta\in \mathbb{C}} $$ Beginning with $\alpha,\beta\in \mathbb{R}$ and using the four relations $\frac{z}{1-z}=\frac{1}{1-z}-1$ (first quadrant) $\frac{1-z}{z}=\frac{1}{z}-1$ (second quadrant) $1=(1-z)+z$ (third quadrant) $z=1-(1-z)$ (fourth quadrant) one can prove that the set $\{z^{\alpha}(1-z)^{\beta}\}_{(\alpha,\beta)\in D}$ where $D$ is the domain  $$ D=\{(\alpha,\beta)\in \mathbb{R}^2\,|\,  0\leq \alpha<1\}=[0,1[\times \mathbb{R} $$ is (linearly) generating $\mathcal{A}$. On the basis of examples, I smell that it is a basis of it but cannot prove that they are linearly independent. Q1) Does anybody have a hint for proving that $\{z^{\alpha}(1-z)^{\beta}\}_{(\alpha,\beta)\in D}$ are $\mathbb{R}$-linearly independent ? $\mathbb{C}$-linearly independent ? Q2) Stronger question : find a similar ""fundamental domain"" for $\alpha,\beta\in \mathbb{C}$.",,"['linear-algebra', 'complex-analysis', 'functional-analysis', 'exponential-function']"
31,"$E$ be a domain, define $E^*=\{z \in C: \overline{z}\in E\}$ $f: E \to C$ is analytic, then $f^*(z)=\overline{f(\overline{z})}$ analytic on $E*$. [duplicate]","be a domain, define   is analytic, then  analytic on . [duplicate]",E E^*=\{z \in C: \overline{z}\in E\} f: E \to C f^*(z)=\overline{f(\overline{z})} E*,"This question already has answers here : How do I rigorously show $f(z)$ is analytic if and only if $\overline{f(\bar{z})}$ is? (5 answers) Closed 4 years ago . We know that since $f$ is analytic on $E$ we have $$u_x=v_y \quad u_y=-v_x$$ We have $f^*(z)=u(x,-y)-iv(x,-y)$ Essentially we are going from $$E^* \stackrel{\overline{z}}{\rightarrow} E \stackrel{f}{\rightarrow} \mathbb{C} \stackrel{\overline{z}}{\rightarrow} \mathbb{C}$$ and $f$ is analytic on $E$. While $z \mapsto \overline{z}$ is not analytic we are doing that mapping twice so it may not disturb analyticity? I know I need to consider the Cauchy-Riemann equations on $f^*$ but I'm not sure how to get there. Thanks for the help!","This question already has answers here : How do I rigorously show $f(z)$ is analytic if and only if $\overline{f(\bar{z})}$ is? (5 answers) Closed 4 years ago . We know that since $f$ is analytic on $E$ we have $$u_x=v_y \quad u_y=-v_x$$ We have $f^*(z)=u(x,-y)-iv(x,-y)$ Essentially we are going from $$E^* \stackrel{\overline{z}}{\rightarrow} E \stackrel{f}{\rightarrow} \mathbb{C} \stackrel{\overline{z}}{\rightarrow} \mathbb{C}$$ and $f$ is analytic on $E$. While $z \mapsto \overline{z}$ is not analytic we are doing that mapping twice so it may not disturb analyticity? I know I need to consider the Cauchy-Riemann equations on $f^*$ but I'm not sure how to get there. Thanks for the help!",,['complex-analysis']
32,Integrate $\int_{-\infty}^\infty\frac{e^{-ik\sqrt{x^2+a^2}}}{\sqrt{x^2+a^2}}dx$,Integrate,\int_{-\infty}^\infty\frac{e^{-ik\sqrt{x^2+a^2}}}{\sqrt{x^2+a^2}}dx,"I'm trying to evaluate the integral below for my research related to sound radiation. Assume $a$ is a positive constant. $$\int_{-\infty}^\infty\frac{e^{-ik\sqrt{x^2+a^2}}}{\sqrt{x^2+a^2}}dx$$ First, I tried to separate the functon real and imaginary part. $$\int_{-\infty}^\infty\frac{\cos({k\sqrt{x^2+a^2})}}{\sqrt{x^2+a^2}}dx-i\int_{-\infty}^\infty\frac{\sin({k\sqrt{x^2+a^2})}}{\sqrt{x^2+a^2}}dx$$ And I tried to contour integral using branch cut similar to the link . However I can't handle branch cuts on the imaginary line well.(Is the answer of the link only way to handle it?) How to handle that branch cuts simple as the case of real line. And.... How to evaluate the whole integral?? Thanks for several answers. I've thought the problem too hard.. However, I made a mistake to my question. I need to consider the case when $a=0$. I guess... $$\int_{-\infty}^\infty\frac{e^{-ik\sqrt{x^2}}}{\sqrt{x^2}}dx=2\int_{0}^\infty\frac{e^{-ik\sqrt{x^2}}}{\sqrt{x^2}}dx=2\int_{0}^\infty\frac{e^{-ikx}}{x}dx$$ Is it valid?","I'm trying to evaluate the integral below for my research related to sound radiation. Assume $a$ is a positive constant. $$\int_{-\infty}^\infty\frac{e^{-ik\sqrt{x^2+a^2}}}{\sqrt{x^2+a^2}}dx$$ First, I tried to separate the functon real and imaginary part. $$\int_{-\infty}^\infty\frac{\cos({k\sqrt{x^2+a^2})}}{\sqrt{x^2+a^2}}dx-i\int_{-\infty}^\infty\frac{\sin({k\sqrt{x^2+a^2})}}{\sqrt{x^2+a^2}}dx$$ And I tried to contour integral using branch cut similar to the link . However I can't handle branch cuts on the imaginary line well.(Is the answer of the link only way to handle it?) How to handle that branch cuts simple as the case of real line. And.... How to evaluate the whole integral?? Thanks for several answers. I've thought the problem too hard.. However, I made a mistake to my question. I need to consider the case when $a=0$. I guess... $$\int_{-\infty}^\infty\frac{e^{-ik\sqrt{x^2}}}{\sqrt{x^2}}dx=2\int_{0}^\infty\frac{e^{-ik\sqrt{x^2}}}{\sqrt{x^2}}dx=2\int_{0}^\infty\frac{e^{-ikx}}{x}dx$$ Is it valid?",,"['complex-analysis', 'contour-integration', 'bessel-functions', 'branch-cuts']"
33,"If $f,g$ real analytic and $\lim_{t \to t_0} f(t)/g(t)$ exists then $f/g$ is analytic",If  real analytic and  exists then  is analytic,"f,g \lim_{t \to t_0} f(t)/g(t) f/g","If $f,g$ are real analytic at $t_0$ and $\lim_{t \to t_0} f(t)/g(t)$ exists then is it true that $f/g$ with the limiting value filled in at $t= t_0$ is real analytic at $t_0$? I know the complex version is true, so that if $\lim_{z \to z_0} f(z)/g(z)$ exists, then $f/g$ can be analytically continued to the point $t_0$, but I wonder if the same holds for just real analytic. I'm thinking yes, just take the power series and view them as complex functions, but I'm not entirely sure.","If $f,g$ are real analytic at $t_0$ and $\lim_{t \to t_0} f(t)/g(t)$ exists then is it true that $f/g$ with the limiting value filled in at $t= t_0$ is real analytic at $t_0$? I know the complex version is true, so that if $\lim_{z \to z_0} f(z)/g(z)$ exists, then $f/g$ can be analytically continued to the point $t_0$, but I wonder if the same holds for just real analytic. I'm thinking yes, just take the power series and view them as complex functions, but I'm not entirely sure.",,"['real-analysis', 'complex-analysis', 'power-series', 'analyticity']"
34,"If $\operatorname{Re}z^n > 0$ for all $n$, then $z$ is real","If  for all , then  is real",\operatorname{Re}z^n > 0 n z,"I'd like a hint, if you can, for this exercise. I tried many ways  but finally I could not solve it. Here it is : Let $z$ any complex number for which $\operatorname{Re}(z^n)>0$ for every natural number $n$. Prove that $z$ is a real positive number.","I'd like a hint, if you can, for this exercise. I tried many ways  but finally I could not solve it. Here it is : Let $z$ any complex number for which $\operatorname{Re}(z^n)>0$ for every natural number $n$. Prove that $z$ is a real positive number.",,"['complex-analysis', 'complex-numbers']"
35,Expressing $(-8)^{\frac13}$ in polar form,Expressing  in polar form,(-8)^{\frac13},"I want to express $(-8)^{\frac{1}{3}}$ in polar and cartesian coordinates. What I did was to solve the equation $-8 = r^3e^{3i\theta}= r^3(\cos(3\theta)+i\sin(3\theta))$ which implies that I must solve the equations $$ r^3\cos(3\theta) = -8 $$ and the equation $$ r^3\sin(3\theta)= 0 $$ The latter gives me $\theta = 0, \frac{\pi}{3}, \frac{2\pi}{3},\dotsc$ and so using $\theta = 0$, using the equation $r^3\cos(3\theta) = -8$, I get $r = -2$ and in this case the polar and cartesian form is $-2$, then using $\theta = \frac{\pi}{3}.$ I get $r =2$ and so the polar form is $2e^{\frac{\pi}{3}}$ and the cartesian form is $1+i \sqrt{3}$ and finally using $\theta = \frac{2\pi}{3}$ I get $r=-2$ and in polar form the answer is $-2e^{\frac{2\pi}{3}}$ and in cartesian coordinates the answer is $-1 + i \sqrt{3}$. However, the answers in my book are different mostly by signs, like the first answer is $2$ instead of $-2$. Can anyone explain why I am getting this sign errors?","I want to express $(-8)^{\frac{1}{3}}$ in polar and cartesian coordinates. What I did was to solve the equation $-8 = r^3e^{3i\theta}= r^3(\cos(3\theta)+i\sin(3\theta))$ which implies that I must solve the equations $$ r^3\cos(3\theta) = -8 $$ and the equation $$ r^3\sin(3\theta)= 0 $$ The latter gives me $\theta = 0, \frac{\pi}{3}, \frac{2\pi}{3},\dotsc$ and so using $\theta = 0$, using the equation $r^3\cos(3\theta) = -8$, I get $r = -2$ and in this case the polar and cartesian form is $-2$, then using $\theta = \frac{\pi}{3}.$ I get $r =2$ and so the polar form is $2e^{\frac{\pi}{3}}$ and the cartesian form is $1+i \sqrt{3}$ and finally using $\theta = \frac{2\pi}{3}$ I get $r=-2$ and in polar form the answer is $-2e^{\frac{2\pi}{3}}$ and in cartesian coordinates the answer is $-1 + i \sqrt{3}$. However, the answers in my book are different mostly by signs, like the first answer is $2$ instead of $-2$. Can anyone explain why I am getting this sign errors?",,"['complex-analysis', 'polar-coordinates']"
36,Improper integral using residue theorem to show: $\int\limits_{-\infty}^\infty \frac{\cos t}{(t^2+1)^2}dt=\frac{\pi}{e}$,Improper integral using residue theorem to show:,\int\limits_{-\infty}^\infty \frac{\cos t}{(t^2+1)^2}dt=\frac{\pi}{e},"I am meant to use the residue theorem to show that $\int\limits_{-\infty}^\infty \frac{\cos t}{(t^2+1)^2}dt=\frac{\pi}{e}$. So far I have deduced that I should take a contour over $\alpha$ the path from $-r$ to $r$ along with the semi-circle connecting $-r$ to $r$. Then I should take the limit as $r$ goes to infinity, show that the integral along the semicircle portion vanishes, and thus, by the residue theorem and the fact that the integrand has a simple pole at $i$, the improper integral is equal to $2\pi i$ times the residue of the integrand at $i$. Can someone tell me if I am approaching this correctly and possibly explain some of the details because I am having trouble.","I am meant to use the residue theorem to show that $\int\limits_{-\infty}^\infty \frac{\cos t}{(t^2+1)^2}dt=\frac{\pi}{e}$. So far I have deduced that I should take a contour over $\alpha$ the path from $-r$ to $r$ along with the semi-circle connecting $-r$ to $r$. Then I should take the limit as $r$ goes to infinity, show that the integral along the semicircle portion vanishes, and thus, by the residue theorem and the fact that the integrand has a simple pole at $i$, the improper integral is equal to $2\pi i$ times the residue of the integrand at $i$. Can someone tell me if I am approaching this correctly and possibly explain some of the details because I am having trouble.",,"['calculus', 'complex-analysis', 'improper-integrals', 'residue-calculus']"
37,Question about non trivial zeros of Riemann zeta function,Question about non trivial zeros of Riemann zeta function,,Riemann zeta function is $$\zeta(s)=\sum\frac{1}{n^s}$$ I read at wiki that the first nontrivial zero is located at $14.134725\ldots$ As far as I understand it means $$\zeta(s)=\sum\frac{1}{n^{0.5+i14.134725\ldots}}$$ Does it means $$\sum\frac{1}{n^{0.5+i14.134725\ldots}}$$ converges to $0$ for $n=1$ to infinity?,Riemann zeta function is $$\zeta(s)=\sum\frac{1}{n^s}$$ I read at wiki that the first nontrivial zero is located at $14.134725\ldots$ As far as I understand it means $$\zeta(s)=\sum\frac{1}{n^{0.5+i14.134725\ldots}}$$ Does it means $$\sum\frac{1}{n^{0.5+i14.134725\ldots}}$$ converges to $0$ for $n=1$ to infinity?,,['complex-analysis']
38,Solve $z^4+2z^3+3z^2+2z+1 =0$,Solve,z^4+2z^3+3z^2+2z+1 =0,Solve $z^4+2z^3+3z^2+2z+1 =0$ with $z$: a complex variable. Attempt at solving the problem : We divide the polynom by $z^2$ and we get: $z^2+2z+3+\dfrac{2}{z}+  \dfrac{1}{z^2}=0  $  $         $ We set $w=z+  \dfrac{1}{z}$ We now have $w^2+2w+5=0$ $\bigtriangleup = -16$ Let's find $\omega$ such that $\omega^2=-16$ We have $\omega=4i$ Therefore we have the 2 roots: $w_    {1}=-1-2i$ and $ w_    {2}=-1+2i  $ The issue is: I don't know how to find z,Solve $z^4+2z^3+3z^2+2z+1 =0$ with $z$: a complex variable. Attempt at solving the problem : We divide the polynom by $z^2$ and we get: $z^2+2z+3+\dfrac{2}{z}+  \dfrac{1}{z^2}=0  $  $         $ We set $w=z+  \dfrac{1}{z}$ We now have $w^2+2w+5=0$ $\bigtriangleup = -16$ Let's find $\omega$ such that $\omega^2=-16$ We have $\omega=4i$ Therefore we have the 2 roots: $w_    {1}=-1-2i$ and $ w_    {2}=-1+2i  $ The issue is: I don't know how to find z,,"['complex-analysis', 'complex-numbers']"
39,An elementary introduction to Puiseux series?,An elementary introduction to Puiseux series?,,"While studying Analytic combinatorics of Flajolet and Sedgewick (to be more specific, the coefficient asymptotics of algebraic functions), I have come across the concept of Newton-Puiseux expansions. Flajolet and Sedgewick explain these series only in a sketchy way, so I have been looking for some other sources in order to gain better understanding. However, most explanations I have found rely on quite sophisticated mathematics, such as modern algebraic geometry or Riemann surfaces. I do not doubt this is the most elegant way to approach the topic. But on the other hand, none of these have been known in the era of Newton. For this reason, I guess there should be some more elementary approach to the topic. This would be preferable for me, as my mathematical background is quite modest. So my question is: can you recommend me a reference for a more-or-less elementary introduction to Newton-Puiseux series? Thanks a lot.","While studying Analytic combinatorics of Flajolet and Sedgewick (to be more specific, the coefficient asymptotics of algebraic functions), I have come across the concept of Newton-Puiseux expansions. Flajolet and Sedgewick explain these series only in a sketchy way, so I have been looking for some other sources in order to gain better understanding. However, most explanations I have found rely on quite sophisticated mathematics, such as modern algebraic geometry or Riemann surfaces. I do not doubt this is the most elegant way to approach the topic. But on the other hand, none of these have been known in the era of Newton. For this reason, I guess there should be some more elementary approach to the topic. This would be preferable for me, as my mathematical background is quite modest. So my question is: can you recommend me a reference for a more-or-less elementary introduction to Newton-Puiseux series? Thanks a lot.",,"['complex-analysis', 'reference-request', 'power-series']"
40,Suppose f is analytic in some region containing $\bar{B}(0;1)$ and $ |f(z)| = 1$ where $|z| = 1$. Find a formula for $f$.,Suppose f is analytic in some region containing  and  where . Find a formula for .,\bar{B}(0;1)  |f(z)| = 1 |z| = 1 f,"The following is a problem from Conway chapter 6 section 2: Suppose f is analytic in some region containing $\bar{B}(0;1)$ and $ |f(z)| = 1$ where $|z| = 1$. Find a formula for $f$. (Hint: First consider the case where f has no zeros in B(0;1).) I have figured that $f$ is analytic over $B(0;1)$, so by Maximum Modulus principle it attains its maximum on the boundary of $B(0;1)$, and so again by the maximum modulus principle $f$ must be constant in $B(0;1)$. So $f(z)=c$ where $|c|=1$ for all $z\in$ $\bar{B}(0;1)$. Any hints how to continue from here? Also I'm not entirely sure the argument I gave so far is totally correct.","The following is a problem from Conway chapter 6 section 2: Suppose f is analytic in some region containing $\bar{B}(0;1)$ and $ |f(z)| = 1$ where $|z| = 1$. Find a formula for $f$. (Hint: First consider the case where f has no zeros in B(0;1).) I have figured that $f$ is analytic over $B(0;1)$, so by Maximum Modulus principle it attains its maximum on the boundary of $B(0;1)$, and so again by the maximum modulus principle $f$ must be constant in $B(0;1)$. So $f(z)=c$ where $|c|=1$ for all $z\in$ $\bar{B}(0;1)$. Any hints how to continue from here? Also I'm not entirely sure the argument I gave so far is totally correct.",,['complex-analysis']
41,Runge Approximation Theorem in Hormanders text,Runge Approximation Theorem in Hormanders text,,"NOTE : This excerpt comes form Hormander's text, An Introduction to COmplex Analysis of Several Variables . STATEMENT: (Runge approximation theorem)Let $\Omega$ be an open set in $\mathbb{C}$ and $K$ a compact subset of $\Omega$. The following conditions on $\Omega$ and $K$ are equivalent: (a) Every function which is analytic in a neighborhood of $K$ can be approximated uniformly on $K$ by functions in $A(\Omega)$. (b)The open set $\Omega\backslash K=\Omega \cap K^c$ has no components which is relatively compact in $\Omega$. (c)For every $z\in\Omega\backslash K$ there is a function $f\in A(\Omega)$ such that $$|f(z)|>\sup_k |f|$$ Proof :To prove that $(b)\rightarrow (a)$ it suffices to show that every measure which is orthogonal to $A(\Omega)$ is also orthogonal to every function which is analytic in a neighborhood of $K$, for the theorem is then a consequence of the Hahn-Banach theorem. Set $$\varphi(\zeta)=\int(z-\zeta)^{-1}d\mu(z),\;\;\;\;\; z\in K^c$$ By theorem 1.2.2, $\varphi$ is analytic in $K^c$, and when $\zeta\in \Omega^c$ we have $$\varphi^{(k)}(\zeta)=k!\int(z-\zeta)^{-k-1}d\mu(z)=0\;\;\;\;\;\;\text{for every}\;k$$ QUESTION : So I have two questions regarding Hormander's proof. The first one is how does the problem reduce to just using Hahn-Banach theorem. Secondly, why does $\varphi^{(k)}$ vanish for all $k$ when $\zeta\in\Omega^c$.","NOTE : This excerpt comes form Hormander's text, An Introduction to COmplex Analysis of Several Variables . STATEMENT: (Runge approximation theorem)Let $\Omega$ be an open set in $\mathbb{C}$ and $K$ a compact subset of $\Omega$. The following conditions on $\Omega$ and $K$ are equivalent: (a) Every function which is analytic in a neighborhood of $K$ can be approximated uniformly on $K$ by functions in $A(\Omega)$. (b)The open set $\Omega\backslash K=\Omega \cap K^c$ has no components which is relatively compact in $\Omega$. (c)For every $z\in\Omega\backslash K$ there is a function $f\in A(\Omega)$ such that $$|f(z)|>\sup_k |f|$$ Proof :To prove that $(b)\rightarrow (a)$ it suffices to show that every measure which is orthogonal to $A(\Omega)$ is also orthogonal to every function which is analytic in a neighborhood of $K$, for the theorem is then a consequence of the Hahn-Banach theorem. Set $$\varphi(\zeta)=\int(z-\zeta)^{-1}d\mu(z),\;\;\;\;\; z\in K^c$$ By theorem 1.2.2, $\varphi$ is analytic in $K^c$, and when $\zeta\in \Omega^c$ we have $$\varphi^{(k)}(\zeta)=k!\int(z-\zeta)^{-k-1}d\mu(z)=0\;\;\;\;\;\;\text{for every}\;k$$ QUESTION : So I have two questions regarding Hormander's proof. The first one is how does the problem reduce to just using Hahn-Banach theorem. Secondly, why does $\varphi^{(k)}$ vanish for all $k$ when $\zeta\in\Omega^c$.",,"['complex-analysis', 'analysis']"
42,Solving the Sturm-Liouville problem using Green's function and Spectral Theorem.,Solving the Sturm-Liouville problem using Green's function and Spectral Theorem.,,"I am reading a paper that deals with the solution of the Sturm-Liouville problem: $u''(t) + \rho (t) u + \lambda ^{-1}u= -f $ $ u(0)=u(1)=0$ For $\rho(t) \leq 0 $. First it is solved the problem: $u''(t) + \rho (t) u= -f $ $u(0)=u(1)=0 \hspace{1cm}$ (1) Picking two arbitrary linearly independent solutions $u_1,u_2, u_1(0)=0$ $u_2(1)=0$ and using Variation of constants method to obtain a particular solution $u_p$. Then, by imposing to the general solution $u=u_p +a u_1 +b u_2$ the boundary conditions of the original (1) problem, it is found the solution that the solution to (1) is written in integral form as $ \int_{0}^{1} k(t,s)f(s)ds$. So it is defined the operator $K$: $$K:L^2([0,1]) \hspace{1cm} \longrightarrow \hspace{1cm} L^2([0,1])$$   $$ \hspace{4cm} f \hspace{1cm} \longrightarrow \hspace{1cm} u(t)= \int_{0}^{1} k(t,s)f(s)ds$$ Where u is the solution to the ODE $u'' + \rho u=f$  (With the boundary conditions $u(0)=u(1)=0$) and $k(t,s)$ is Green's Function: $$k(t,s):=\left\{\begin{matrix} - \frac{u_2(t)u_1(s)}{W(0)}& s \leq t \\    -\frac{u_2(s)u_1(t)}{W(0)}& t\leq s \end{matrix}\right. $$ I understand the last part of the paper which uses spectral theorem for compact self-adjoint operators to solve the initial problem. But I have a few  questions: It is shown that the operator $K$ is injective, so that for a given $f \in  L^2([0,1])$ there is a unique solution $u \in  L^2([0,1])$. Is this necessary? Couldn't it be shown using the fact that two different $\hat{u_1}, \hat{u_2}$ lineally independent solutions yield the same Green's function as $u_1, u_2$? Also, it is shown that if  $f \in  C([0,1])$ then  $u \in  C^2([0,1])$. This is done by derivating u in its integral form two times. Again, Is this necessary? As u verifies $u'' + \rho u=f$ then $u''$ is also continuous so that $u \in  C^2([0,1])$ as long as f is continuous. Am I missing something?","I am reading a paper that deals with the solution of the Sturm-Liouville problem: $u''(t) + \rho (t) u + \lambda ^{-1}u= -f $ $ u(0)=u(1)=0$ For $\rho(t) \leq 0 $. First it is solved the problem: $u''(t) + \rho (t) u= -f $ $u(0)=u(1)=0 \hspace{1cm}$ (1) Picking two arbitrary linearly independent solutions $u_1,u_2, u_1(0)=0$ $u_2(1)=0$ and using Variation of constants method to obtain a particular solution $u_p$. Then, by imposing to the general solution $u=u_p +a u_1 +b u_2$ the boundary conditions of the original (1) problem, it is found the solution that the solution to (1) is written in integral form as $ \int_{0}^{1} k(t,s)f(s)ds$. So it is defined the operator $K$: $$K:L^2([0,1]) \hspace{1cm} \longrightarrow \hspace{1cm} L^2([0,1])$$   $$ \hspace{4cm} f \hspace{1cm} \longrightarrow \hspace{1cm} u(t)= \int_{0}^{1} k(t,s)f(s)ds$$ Where u is the solution to the ODE $u'' + \rho u=f$  (With the boundary conditions $u(0)=u(1)=0$) and $k(t,s)$ is Green's Function: $$k(t,s):=\left\{\begin{matrix} - \frac{u_2(t)u_1(s)}{W(0)}& s \leq t \\    -\frac{u_2(s)u_1(t)}{W(0)}& t\leq s \end{matrix}\right. $$ I understand the last part of the paper which uses spectral theorem for compact self-adjoint operators to solve the initial problem. But I have a few  questions: It is shown that the operator $K$ is injective, so that for a given $f \in  L^2([0,1])$ there is a unique solution $u \in  L^2([0,1])$. Is this necessary? Couldn't it be shown using the fact that two different $\hat{u_1}, \hat{u_2}$ lineally independent solutions yield the same Green's function as $u_1, u_2$? Also, it is shown that if  $f \in  C([0,1])$ then  $u \in  C^2([0,1])$. This is done by derivating u in its integral form two times. Again, Is this necessary? As u verifies $u'' + \rho u=f$ then $u''$ is also continuous so that $u \in  C^2([0,1])$ as long as f is continuous. Am I missing something?",,"['complex-analysis', 'analysis', 'functional-analysis', 'differential-operators', 'sturm-liouville']"
43,On the proof of Riemann extension theorem in Huybrechts,On the proof of Riemann extension theorem in Huybrechts,,"In the proof of the generalized Riemann extension theorem in Daniel Huybrechts's Complex Geometry , which is: Proposition 1.1.7 (Riemann extension theorem) Let $f$ be a holomorphic function on an open set $U\subset \mathbb{C}^n$. If $g:U\backslash Z(f)\to\mathbb{C}$ is holomorphic and locally bounded near $Z(f)$ , then $g$ can uniquely be extended to a holomorphic function $\widetilde{g}:U\to\mathbb{C}.$ Where $Z(f)$ is defined to be $\{ z|f(z)=0 \}$. Before starting the rigor proof, the author had assumed that: ...We can restrict to the case that the restriction $f_0$ of $f$ to this line (which means the set $ U\cap\{ (z_1,0,\dots,0) |z_1\in \mathbb{C} \} $) vanishes only in the origin. ... Where $f_w$ is defined by $f_w(z_1)=f(z_1,w)$. I guess this restriction could be made under a inversible linear transformation of $\mathbb{C}^n$ to itself. But is the transformation alway exists? Could anyone give me some details about that? Why there is no loss of generality about this?","In the proof of the generalized Riemann extension theorem in Daniel Huybrechts's Complex Geometry , which is: Proposition 1.1.7 (Riemann extension theorem) Let $f$ be a holomorphic function on an open set $U\subset \mathbb{C}^n$. If $g:U\backslash Z(f)\to\mathbb{C}$ is holomorphic and locally bounded near $Z(f)$ , then $g$ can uniquely be extended to a holomorphic function $\widetilde{g}:U\to\mathbb{C}.$ Where $Z(f)$ is defined to be $\{ z|f(z)=0 \}$. Before starting the rigor proof, the author had assumed that: ...We can restrict to the case that the restriction $f_0$ of $f$ to this line (which means the set $ U\cap\{ (z_1,0,\dots,0) |z_1\in \mathbb{C} \} $) vanishes only in the origin. ... Where $f_w$ is defined by $f_w(z_1)=f(z_1,w)$. I guess this restriction could be made under a inversible linear transformation of $\mathbb{C}^n$ to itself. But is the transformation alway exists? Could anyone give me some details about that? Why there is no loss of generality about this?",,"['complex-analysis', 'complex-geometry', 'several-complex-variables']"
44,"If a Möbius transformation preserves the real line, its coefficients can be chosen to be real","If a Möbius transformation preserves the real line, its coefficients can be chosen to be real",,"If $T$ is a Möbius transformation with $ Tz = \frac{az+b}{cz+d} $ and $ T(\mathbb{R}_{\infty}) = \mathbb{R}_{\infty} $, show that we can choose $a,b,c,d$ to be real numbers. This is an exercise from Conway. Now, $ T(\infty) = {a \over c} \in \mathbb{R}, T(0) = { b \over d} \in \mathbb{R} $ so $ a$ and $b$ are real multiple of $c$ and $d$, but how does this implies we can choose them all real?","If $T$ is a Möbius transformation with $ Tz = \frac{az+b}{cz+d} $ and $ T(\mathbb{R}_{\infty}) = \mathbb{R}_{\infty} $, show that we can choose $a,b,c,d$ to be real numbers. This is an exercise from Conway. Now, $ T(\infty) = {a \over c} \in \mathbb{R}, T(0) = { b \over d} \in \mathbb{R} $ so $ a$ and $b$ are real multiple of $c$ and $d$, but how does this implies we can choose them all real?",,"['complex-analysis', 'mobius-transformation']"
45,Integrating secans over the imaginary axis using the residue theorem,Integrating secans over the imaginary axis using the residue theorem,,"I am trying to integrate $\sec(z)$ over the whole imaginary axis using the residue theorem. i.e., I want to calculate the integral $$\int_{\Gamma} \frac{dz}{\cos{z}}$$ where $\Gamma$ is the (open) contour that moves along the straight line $x=0$ from $y=-\infty$ to $y=\infty$.  $1/\cos(z)$ has infintely many simple poles at either side of the contour. The residues at these poles are $$\text{Res}_{z=-\frac{\pi}{2}+ 2n\pi}\left(\frac{1}{\cos(x)}\right)=1$$ and $$\text{Res}_{z=\frac{\pi}{2}+ 2n\pi}\left(\frac{1}{\cos(x)}\right)=1$$ for $n\in \mathbb{Z}$. My question doesn't really concern the calculation, I just want to find the appropriate contour(s). My initial idea was to use two contours so that the infinite poles on either side of $x=0$ would somehow cancel out, but I haven't gotten very far.","I am trying to integrate $\sec(z)$ over the whole imaginary axis using the residue theorem. i.e., I want to calculate the integral $$\int_{\Gamma} \frac{dz}{\cos{z}}$$ where $\Gamma$ is the (open) contour that moves along the straight line $x=0$ from $y=-\infty$ to $y=\infty$.  $1/\cos(z)$ has infintely many simple poles at either side of the contour. The residues at these poles are $$\text{Res}_{z=-\frac{\pi}{2}+ 2n\pi}\left(\frac{1}{\cos(x)}\right)=1$$ and $$\text{Res}_{z=\frac{\pi}{2}+ 2n\pi}\left(\frac{1}{\cos(x)}\right)=1$$ for $n\in \mathbb{Z}$. My question doesn't really concern the calculation, I just want to find the appropriate contour(s). My initial idea was to use two contours so that the infinite poles on either side of $x=0$ would somehow cancel out, but I haven't gotten very far.",,"['complex-analysis', 'contour-integration', 'residue-calculus']"
46,"Limit of a difference of integrals that both look almost identical,","Limit of a difference of integrals that both look almost identical,",,"Let $\gamma (t) = t+i(e^t-1)$ for $-1\le t \le 1$. find $$\lim_{\epsilon \to 0^+} \left[\int_{\gamma} \frac{\sin(z)}{(z-i\epsilon)^2} dz - \int_{\gamma} \frac{\sin(z)}{(z+i\epsilon)^2} dz\right]$$ I have tried using directly the parametrization given and integrating from -1 to 1 against $dt$.  Also, instead of sin(z), I used $e^{iz}$, and planned to take the imaginary part of the result.  No luck... I then integrated by parts -- also not insightful. Now I'm wondering whether dominated convergence theorem can be applied. Any ideas are welcome. Thanks,","Let $\gamma (t) = t+i(e^t-1)$ for $-1\le t \le 1$. find $$\lim_{\epsilon \to 0^+} \left[\int_{\gamma} \frac{\sin(z)}{(z-i\epsilon)^2} dz - \int_{\gamma} \frac{\sin(z)}{(z+i\epsilon)^2} dz\right]$$ I have tried using directly the parametrization given and integrating from -1 to 1 against $dt$.  Also, instead of sin(z), I used $e^{iz}$, and planned to take the imaginary part of the result.  No luck... I then integrated by parts -- also not insightful. Now I'm wondering whether dominated convergence theorem can be applied. Any ideas are welcome. Thanks,",,"['integration', 'complex-analysis', 'limits', 'residue-calculus', 'singularity-theory']"
47,Why do I need absolute convergence to prove $\cos z=\frac{e^{iz}+e^{-iz}}{2}$?,Why do I need absolute convergence to prove ?,\cos z=\frac{e^{iz}+e^{-iz}}{2},"I'm reading Conway's Complex Analysis book and on page 38 he said we can manipulate the power series because they are absolute convergent: Let's see: Conway defines $$\cos z=1-z^2/2+z^4/24-\ldots$$ So, we know $$e^{iz}=1+iz-\frac{z^2}{2}-\frac{z^3i}{6}+\frac{z^4}{24}+\frac{z^5i}{120}\ldots$$ $$e^{-iz}=1-iz-\frac{z^2}{2}+\frac{z^3i}{6}+\frac{z^4}{24}-\frac{z^5i}{120}+\ldots$$ Now, lets call $e^{iz}=\lim_{n\to \infty}s_n=\lim_{n\to \infty}(a_1+a_2+\ldots+a_n)$ and $e^{-iz}=\lim_{n\to \infty}s_n'=\lim_{n\to \infty}(b_1+b_2+\ldots+b_n)$. Then, we have $$\cos z=\lim_{n\to \infty}(1/2(a_1+b_1)+1/2(a_2+b_2)+\ldots1/2(a_n+b_n))=\lim_{n\to \infty}(((1/2)a_1+(1/2)a_2+\ldots+(1/2)a_n))+((1/2)b_1+(1/2)b_2+\ldots+(1/2)b_n)))=1/2\lim_{n\to \infty}(a_1+a_2+\ldots+a_n)+1/2\lim_{n\to \infty}(b_1+b_2+\ldots+b_n)=(1/2)e^{iz}+(1/2)e^{-iz}=\frac{e^{iz}+e^{-iz}}{2}$$ I think I didn't use the fact the series $e^{iz}$ and $e^{-iz}$ are absolute convergent. Where am I wrong? what am I missing? EDIT Note that I'm using commutativity only in the finite case: $$\lim\sum_{k=1}^n(a_k+b_k)=\lim((\sum_{k=1}^n a_k)+(\sum_{k=1}^n b_k))=\lim(s_n+s_n')=\lim s_n+\lim s_n'$$. I need help Thanks!","I'm reading Conway's Complex Analysis book and on page 38 he said we can manipulate the power series because they are absolute convergent: Let's see: Conway defines $$\cos z=1-z^2/2+z^4/24-\ldots$$ So, we know $$e^{iz}=1+iz-\frac{z^2}{2}-\frac{z^3i}{6}+\frac{z^4}{24}+\frac{z^5i}{120}\ldots$$ $$e^{-iz}=1-iz-\frac{z^2}{2}+\frac{z^3i}{6}+\frac{z^4}{24}-\frac{z^5i}{120}+\ldots$$ Now, lets call $e^{iz}=\lim_{n\to \infty}s_n=\lim_{n\to \infty}(a_1+a_2+\ldots+a_n)$ and $e^{-iz}=\lim_{n\to \infty}s_n'=\lim_{n\to \infty}(b_1+b_2+\ldots+b_n)$. Then, we have $$\cos z=\lim_{n\to \infty}(1/2(a_1+b_1)+1/2(a_2+b_2)+\ldots1/2(a_n+b_n))=\lim_{n\to \infty}(((1/2)a_1+(1/2)a_2+\ldots+(1/2)a_n))+((1/2)b_1+(1/2)b_2+\ldots+(1/2)b_n)))=1/2\lim_{n\to \infty}(a_1+a_2+\ldots+a_n)+1/2\lim_{n\to \infty}(b_1+b_2+\ldots+b_n)=(1/2)e^{iz}+(1/2)e^{-iz}=\frac{e^{iz}+e^{-iz}}{2}$$ I think I didn't use the fact the series $e^{iz}$ and $e^{-iz}$ are absolute convergent. Where am I wrong? what am I missing? EDIT Note that I'm using commutativity only in the finite case: $$\lim\sum_{k=1}^n(a_k+b_k)=\lim((\sum_{k=1}^n a_k)+(\sum_{k=1}^n b_k))=\lim(s_n+s_n')=\lim s_n+\lim s_n'$$. I need help Thanks!",,"['real-analysis', 'complex-analysis']"
48,Laurent expansion of $\operatorname{sech}(z)$ centred at $\pi i/2$,Laurent expansion of  centred at,\operatorname{sech}(z) \pi i/2,I have found that the roots of the $\cosh(z)=0$ occur at $\frac{(2k+1)\pi i}{2}$ where $k \in \mathbb{N}\cup{0}$. But I want to find the order the poles of $\operatorname{sech}(z)$ so I'm trying to find the order of the zero for just $\pi i/2$ and after that also the residue at  $\pi i/2$. Thanks,I have found that the roots of the $\cosh(z)=0$ occur at $\frac{(2k+1)\pi i}{2}$ where $k \in \mathbb{N}\cup{0}$. But I want to find the order the poles of $\operatorname{sech}(z)$ so I'm trying to find the order of the zero for just $\pi i/2$ and after that also the residue at  $\pi i/2$. Thanks,,"['complex-analysis', 'contour-integration', 'residue-calculus', 'laurent-series']"
49,Geometrical interpretation of a diagram in Complex Analysis,Geometrical interpretation of a diagram in Complex Analysis,,"I am currently self-studying complex analysis in preparation for my course that will commence next year and I am stuck with this question as shown below: In the complex plane, draw a picture of $$S=\{z \in \mathbb{C} : \vert z-1 \vert + \vert z+1 \vert = 2\}.$$ I was told that by squaring both sides, the curve is equivalent to $$\vert z^{2} \vert + \vert z^{2} -1 \vert = 1$$ but I cannot work out as such. Can anyone show me how the squaring of both sides resulted into the equation?","I am currently self-studying complex analysis in preparation for my course that will commence next year and I am stuck with this question as shown below: In the complex plane, draw a picture of $$S=\{z \in \mathbb{C} : \vert z-1 \vert + \vert z+1 \vert = 2\}.$$ I was told that by squaring both sides, the curve is equivalent to $$\vert z^{2} \vert + \vert z^{2} -1 \vert = 1$$ but I cannot work out as such. Can anyone show me how the squaring of both sides resulted into the equation?",,['complex-analysis']
50,contour integration problem.. [closed],contour integration problem.. [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question how can we find $$\int_C e^{2z} 9^{z-2} dz,$$  where $C$ is the the contour from $z = 0$ to $z = 1 − i$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question how can we find $$\int_C e^{2z} 9^{z-2} dz,$$  where $C$ is the the contour from $z = 0$ to $z = 1 − i$",,"['complex-analysis', 'contour-integration']"
51,How to construct such a harmonic function on the upper half plane of $\mathbb{C}$ satisfying the following condition?,How to construct such a harmonic function on the upper half plane of  satisfying the following condition?,\mathbb{C},"(1)Let u be a bounded harmonic function on the upper half plane of $\mathbb{C}$. Show that $\forall y$ we have $u(x+iy)=\frac{1}{\pi}\int_{-\infty}^{\infty}\frac{y\cdot u(t)}{(t-x)^2+y^2}dt$ for $x,y\in \mathbb{R}$. (2)find a harmonic function on the upper half plane with lim$_{(y\to 0^+)}u(x+iy)=0,\ \text{if}\ x<0$ and lim$_{(y\to 0^+)}u(x+iy)=1,\ \text{if}\ x>0$ I have worked out the first part but I have no idea to construct such a function.","(1)Let u be a bounded harmonic function on the upper half plane of $\mathbb{C}$. Show that $\forall y$ we have $u(x+iy)=\frac{1}{\pi}\int_{-\infty}^{\infty}\frac{y\cdot u(t)}{(t-x)^2+y^2}dt$ for $x,y\in \mathbb{R}$. (2)find a harmonic function on the upper half plane with lim$_{(y\to 0^+)}u(x+iy)=0,\ \text{if}\ x<0$ and lim$_{(y\to 0^+)}u(x+iy)=1,\ \text{if}\ x>0$ I have worked out the first part but I have no idea to construct such a function.",,"['complex-analysis', 'harmonic-functions']"
52,calculating $(1-i\sqrt{3})^{1+i}$,calculating,(1-i\sqrt{3})^{1+i},How can I calculate this complex number : $ (1-i\sqrt{3})^{1+i} $ please correct or leave comment if my answer below is wrong (or put your own answer)...,How can I calculate this complex number : $ (1-i\sqrt{3})^{1+i} $ please correct or leave comment if my answer below is wrong (or put your own answer)...,,"['complex-analysis', 'complex-numbers']"
53,Let $f$ be analytic function defined on the open unit disc in $\mathbb{C}$. Then which are of the following true?,Let  be analytic function defined on the open unit disc in . Then which are of the following true?,f \mathbb{C},"Let $f$ be analytic function defined on the open unit disc in $\mathbb{C}$ . Then $f$ is constant if $1.~~f\left(\frac{1}{n}\right)=0$ for all $n\geq1.$ $ 2. ~~f(z)=0$ for all $|z|=1/2$ $ 3. ~~f\left(\frac{1}{n^2}\right)=0$ for all $n\geq1.$ $ 4. ~~f(z)=0$ for all $z\in (-1,1)$ I used Identity theorem and conclude that $1$ , $3$ and $4$ are true. But I am confused with $2$ . Please help me with some hints or ideas.","Let be analytic function defined on the open unit disc in . Then is constant if for all for all for all for all I used Identity theorem and conclude that , and are true. But I am confused with . Please help me with some hints or ideas.","f \mathbb{C} f 1.~~f\left(\frac{1}{n}\right)=0 n\geq1.  2. ~~f(z)=0 |z|=1/2  3. ~~f\left(\frac{1}{n^2}\right)=0 n\geq1.  4. ~~f(z)=0 z\in (-1,1) 1 3 4 2",['complex-analysis']
54,Supremum of holomorphic function on the unit disk,Supremum of holomorphic function on the unit disk,,"Let $f\colon B \to \mathbb{C}$ be holomorphic where $B$ is the unit disk in the complex plane centered at the origin.   For $0<r<1$, let $M_r=\sup\{|f(z)|:|z|=r\}$. Show that $|f(0)|≤M_r$ $ \forall r \in (0,1)$. Now suppose further that $|f(0)|≥|f(z)| \forall z\in B$. Show that $|f(z)|$ is constant on $B$, For the first bit I use Cauchy's integral formula and got: $$\left| \frac{1}{2\pi i} \int_{|z|=r}^{} \frac{f(z)}{z} \right| = \left|f(0)\right|\leq \frac{1}{2\pi} \int_{|z|=r}^{} \left|\frac{f(z)}{z} \right| $$  Now I'm not sure how to implement the $M_r$ Need help with the second part...","Let $f\colon B \to \mathbb{C}$ be holomorphic where $B$ is the unit disk in the complex plane centered at the origin.   For $0<r<1$, let $M_r=\sup\{|f(z)|:|z|=r\}$. Show that $|f(0)|≤M_r$ $ \forall r \in (0,1)$. Now suppose further that $|f(0)|≥|f(z)| \forall z\in B$. Show that $|f(z)|$ is constant on $B$, For the first bit I use Cauchy's integral formula and got: $$\left| \frac{1}{2\pi i} \int_{|z|=r}^{} \frac{f(z)}{z} \right| = \left|f(0)\right|\leq \frac{1}{2\pi} \int_{|z|=r}^{} \left|\frac{f(z)}{z} \right| $$  Now I'm not sure how to implement the $M_r$ Need help with the second part...",,['complex-analysis']
55,Given $f(z)$ entire function and $\left| f(z) \right| \le 1 + \left| z \right|^3$ for all $z \in \mathbb{C}$ show that $f$ is a polynomial,Given  entire function and  for all  show that  is a polynomial,f(z) \left| f(z) \right| \le 1 + \left| z \right|^3 z \in \mathbb{C} f,"I'm learning about complex analysis and need some help with this problem : Given $f(z)$ entire function and $\left| f(z) \right| \le 1 + \left| z \right|^3$ for all $z \in \mathbb{C}$ show that $f$ is a polynomial. What is the degree of the polynomial? Here's my attempt so far : By Cauchy's Integral Formula for Derivatives we have: $$f^{(n)}(z) = \frac{n!}{2 \pi i} \int_{C} \frac{f(\zeta)}{(\zeta - z)^{n+1}} \, d\zeta $$ Let $C_R = \{z \in \mathbb{C} : \left| z \right| = R \}$. For $\left| z \right| < R$ we have: $$\left| f^{(n)}(z) \right| = \frac{n!}{2 \pi} \left| \int_{\left| \zeta \right| = R} \frac{f(\zeta)}{(\zeta - z)^{n+1}} \, d\zeta \right| = \frac{n!}{2 \pi} \left| \int_{0}^{2 \pi}\frac{\left|f(\zeta_t) \right|}{\left|\zeta_t - z\right|^{n+1}} \, \left| \zeta'_t \right| d\zeta \right| \le$$ $$\le \frac{n!}{2 \pi} \int_{0}^{2 \pi}\frac{1 + \left| \zeta(t) \right|^3}{(\left|\zeta(t) \right| - \left| z \right|)^{n+1}} \, \left| \zeta'(t) \right| dt = \frac{n!}{2\pi} \frac{1+R^3}{(R - \left| z \right|)^{n+1}} 2\pi R =$$ $$= n! \frac{1+R^3}{(R - \left| z \right|)^{n+1}} R$$ We want $\left| f^{(n)}(z) \right| \rightarrow 0$ when $R \rightarrow \infty$. This is where I'm stuck. Is my work correct so far and how do I continue from here to find the degree of the polynomial?","I'm learning about complex analysis and need some help with this problem : Given $f(z)$ entire function and $\left| f(z) \right| \le 1 + \left| z \right|^3$ for all $z \in \mathbb{C}$ show that $f$ is a polynomial. What is the degree of the polynomial? Here's my attempt so far : By Cauchy's Integral Formula for Derivatives we have: $$f^{(n)}(z) = \frac{n!}{2 \pi i} \int_{C} \frac{f(\zeta)}{(\zeta - z)^{n+1}} \, d\zeta $$ Let $C_R = \{z \in \mathbb{C} : \left| z \right| = R \}$. For $\left| z \right| < R$ we have: $$\left| f^{(n)}(z) \right| = \frac{n!}{2 \pi} \left| \int_{\left| \zeta \right| = R} \frac{f(\zeta)}{(\zeta - z)^{n+1}} \, d\zeta \right| = \frac{n!}{2 \pi} \left| \int_{0}^{2 \pi}\frac{\left|f(\zeta_t) \right|}{\left|\zeta_t - z\right|^{n+1}} \, \left| \zeta'_t \right| d\zeta \right| \le$$ $$\le \frac{n!}{2 \pi} \int_{0}^{2 \pi}\frac{1 + \left| \zeta(t) \right|^3}{(\left|\zeta(t) \right| - \left| z \right|)^{n+1}} \, \left| \zeta'(t) \right| dt = \frac{n!}{2\pi} \frac{1+R^3}{(R - \left| z \right|)^{n+1}} 2\pi R =$$ $$= n! \frac{1+R^3}{(R - \left| z \right|)^{n+1}} R$$ We want $\left| f^{(n)}(z) \right| \rightarrow 0$ when $R \rightarrow \infty$. This is where I'm stuck. Is my work correct so far and how do I continue from here to find the degree of the polynomial?",,"['complex-analysis', 'complex-integration', 'cauchy-integral-formula']"
56,Hardy-Littlewood theorem about the Poisson integral for $p=1$,Hardy-Littlewood theorem about the Poisson integral for,p=1,"(Hardy-Littlewood Theorem) : Let ‎$ u(r,‎\theta)‎$‎ be the Poisson integral of ‎$ ‎\varphi ‎\in L‎^{p}‎‎$‎, ‎$ 1<P ‎\leqslant‎ ‎\infty‎$‎ , and let $ U(‎\theta)=\sup‎_{r<1}‎|u(r,‎\theta)|‎ $‎. Then $ ‎U ‎\in L‎^{p}‎‎$, and there is a constant $A‎_{p}‎ $ depending only on $p$ such that  ‎‎$ ‎\Vert ‎U‎\Vert‎_{P}‎‎‎ ‎\leqslant A‎_{p}‎   ‎\Vert ‎\varphi ‎\Vert‎_{P}‎‎‎‎‎$‎. The proof of theorem is easy. But my question is why for $p=1$ Theorem is False. I try to use the modified Poisson kernel $ u(r,‎\theta)= ‎\dfrac{R^2-r^2}{R^2-2R r   \cos‎\theta+r^2}‎‎$ for $R>1$. I use max and min $ u(r,‎\theta)‎$ but I can't solve the problem.","(Hardy-Littlewood Theorem) : Let ‎$ u(r,‎\theta)‎$‎ be the Poisson integral of ‎$ ‎\varphi ‎\in L‎^{p}‎‎$‎, ‎$ 1<P ‎\leqslant‎ ‎\infty‎$‎ , and let $ U(‎\theta)=\sup‎_{r<1}‎|u(r,‎\theta)|‎ $‎. Then $ ‎U ‎\in L‎^{p}‎‎$, and there is a constant $A‎_{p}‎ $ depending only on $p$ such that  ‎‎$ ‎\Vert ‎U‎\Vert‎_{P}‎‎‎ ‎\leqslant A‎_{p}‎   ‎\Vert ‎\varphi ‎\Vert‎_{P}‎‎‎‎‎$‎. The proof of theorem is easy. But my question is why for $p=1$ Theorem is False. I try to use the modified Poisson kernel $ u(r,‎\theta)= ‎\dfrac{R^2-r^2}{R^2-2R r   \cos‎\theta+r^2}‎‎$ for $R>1$. I use max and min $ u(r,‎\theta)‎$ but I can't solve the problem.",,"['complex-analysis', 'harmonic-analysis', 'harmonic-functions', 'hardy-spaces']"
57,"A Conformal map sends the upper semi-circle to the positive real line and $[-1,1]$ to the other half of the real line.",A Conformal map sends the upper semi-circle to the positive real line and  to the other half of the real line.,"[-1,1]","Is there a conformal mapping that sends the upper semi-circle to the positive (or negative) real line, and the real interval $[-1,1]$ to the other half of the real line? I am considering the upper semi-circle $\{|z|=1, 0<arg(z)<\pi\}$, with the line $[-1,1]$ that closes the loop. I want to map the arc to a half line, and the interval to the other half line. Is this possible? I have tried for a bit, with no success so far. The end goal is to find a harmonic function on this upper semi-disk, but I think the conformal mapping needs to be executed first... I used the Joukowski transform, since part of the problem statement specifically asks to compute its image, but this transform takes the arc to an interval $[-2,2]$, which is not at all helpful. Thanks.","Is there a conformal mapping that sends the upper semi-circle to the positive (or negative) real line, and the real interval $[-1,1]$ to the other half of the real line? I am considering the upper semi-circle $\{|z|=1, 0<arg(z)<\pi\}$, with the line $[-1,1]$ that closes the loop. I want to map the arc to a half line, and the interval to the other half line. Is this possible? I have tried for a bit, with no success so far. The end goal is to find a harmonic function on this upper semi-disk, but I think the conformal mapping needs to be executed first... I used the Joukowski transform, since part of the problem statement specifically asks to compute its image, but this transform takes the arc to an interval $[-2,2]$, which is not at all helpful. Thanks.",,"['complex-analysis', 'harmonic-functions', 'conformal-geometry', 'mobius-transformation']"
58,Limiting behaviour of a real Möbius sequence,Limiting behaviour of a real Möbius sequence,,"Consider the fractional linear transformation of the real variable $t$, transformation $$f(t)=\frac{at+b}{ct+d}$$ where $a,b,c,d\in\mathbb{R}$. Define $t_{n+1}=f(t_n)$ where $t_0\in\mathbb{R}$. There are plenty of references indicating how this sequence behaves when $f$ has either two distinct fixed points $\alpha,\beta\in\mathbb{R}$ and when $f$ has one fixed point $\alpha\in\mathbb{R}$. However, I couldn't find anything that indicates the behaviour (however nasty) when $f$ has no fixed point. Is there any reference that indicates how this is analysis might proceed? I'm actually thinking of $f$ as an automorphism of the circle (or equivalently the real projective line). I was wondering if there is a result such as $\{t_n\}$ is dense in the circle (except for certain combinations of $a,b,c,d$ that give cyclic behaviour).","Consider the fractional linear transformation of the real variable $t$, transformation $$f(t)=\frac{at+b}{ct+d}$$ where $a,b,c,d\in\mathbb{R}$. Define $t_{n+1}=f(t_n)$ where $t_0\in\mathbb{R}$. There are plenty of references indicating how this sequence behaves when $f$ has either two distinct fixed points $\alpha,\beta\in\mathbb{R}$ and when $f$ has one fixed point $\alpha\in\mathbb{R}$. However, I couldn't find anything that indicates the behaviour (however nasty) when $f$ has no fixed point. Is there any reference that indicates how this is analysis might proceed? I'm actually thinking of $f$ as an automorphism of the circle (or equivalently the real projective line). I was wondering if there is a result such as $\{t_n\}$ is dense in the circle (except for certain combinations of $a,b,c,d$ that give cyclic behaviour).",,"['calculus', 'sequences-and-series', 'complex-analysis', 'analysis', 'dynamical-systems']"
59,Inverse function of a conformal mapping,Inverse function of a conformal mapping,,"I'm trying to prove that, if $f$ is a conformal mapping at $z_0$ , then it has an inverse $g$ that is conformal at $w_0=f(z_0)$ . I proved the existence of $g$ using the Inverse Function Theorem. Since $f$ is conformal at $z_0$ , then $f$ is analytic in $z_0$ and so $u,v\in C^1(D)$ . Tha Jacobian is $\begin{equation*} J =\begin{vmatrix} u_x & u_y\\ v_x & v_y\\ \end{vmatrix} =u_xv_y-u_yv_x \end{equation*}$ and using the Cauchy-Riemann equations, we have that \begin{equation*} J=(u_x)^2+(v_x)^2=|f'(z)|^2 \end{equation*} Since $f'(z_0)\neq 0$ , $J\neq 0$ . So, by the Inverse Function Theorem, $f$ has an inverse $g$ . How can I prove that $g$ is analytic in $w_0$ ? That's the only thing that is missing, since I also proved that \begin{equation*} g'(w_0)=\frac{1}{f'(z_0)} \end{equation*} and since $f'(z_0)\neq 0$ , then $g'(w_0)\neq 0$ . This, coupled with the fact that $g$ is analytic in $w_0$ , implies that $g$ is conformal at $w_0$ .","I'm trying to prove that, if is a conformal mapping at , then it has an inverse that is conformal at . I proved the existence of using the Inverse Function Theorem. Since is conformal at , then is analytic in and so . Tha Jacobian is and using the Cauchy-Riemann equations, we have that Since , . So, by the Inverse Function Theorem, has an inverse . How can I prove that is analytic in ? That's the only thing that is missing, since I also proved that and since , then . This, coupled with the fact that is analytic in , implies that is conformal at .","f z_0 g w_0=f(z_0) g f z_0 f z_0 u,v\in C^1(D) \begin{equation*}
J =\begin{vmatrix}
u_x & u_y\\
v_x & v_y\\
\end{vmatrix}
=u_xv_y-u_yv_x
\end{equation*} \begin{equation*}
J=(u_x)^2+(v_x)^2=|f'(z)|^2
\end{equation*} f'(z_0)\neq 0 J\neq 0 f g g w_0 \begin{equation*}
g'(w_0)=\frac{1}{f'(z_0)}
\end{equation*} f'(z_0)\neq 0 g'(w_0)\neq 0 g w_0 g w_0","['complex-analysis', 'conformal-geometry']"
60,Holomorphic section is determined by arbitrarily small neighborhood?,Holomorphic section is determined by arbitrarily small neighborhood?,,"Let $X$ be a connected complex manifold and $E\to X$ a holomorphic vector bundle. Suppose that $s:X\to E$ is a holomorphic section such that $s(x)=0$ for all $x$ in a non-empty open set $U\subset X$. Does this imply that $s$ is identically zero on $X$? By analogy with the fact that a holomorphic function $f:\Bbb C\to\Bbb C$ is determined by its values on any non-empty open set, I am convinced that the answer is yes. But I have some trouble proving this for complex manifolds. If $X$ is compact I am able to prove it by using a finite cover of holomorphic coordinates and using the result for holomorphic functions, but that argument doesn't generalize to non-compact.","Let $X$ be a connected complex manifold and $E\to X$ a holomorphic vector bundle. Suppose that $s:X\to E$ is a holomorphic section such that $s(x)=0$ for all $x$ in a non-empty open set $U\subset X$. Does this imply that $s$ is identically zero on $X$? By analogy with the fact that a holomorphic function $f:\Bbb C\to\Bbb C$ is determined by its values on any non-empty open set, I am convinced that the answer is yes. But I have some trouble proving this for complex manifolds. If $X$ is compact I am able to prove it by using a finite cover of holomorphic coordinates and using the result for holomorphic functions, but that argument doesn't generalize to non-compact.",,"['complex-analysis', 'differential-geometry', 'complex-geometry']"
61,Determine the complex contour integral $\oint \limits_{C} \frac{2}{z^3+z}dz$ without using Residue Theorems,Determine the complex contour integral  without using Residue Theorems,\oint \limits_{C} \frac{2}{z^3+z}dz,"Without residue theory, determine $$\oint \limits_{C} \frac{2}{z^3+z}dz$$ if $C: \big|~z~-~\frac{i}{2}~\big|=1$ is positively oriented. We first find that our integrand has three distinct singular points $z=\{-i,~0,~i\}$ Now if we draw a sketch of $C$ , we see that only two of these singular points are within $C$ . We can thus rewrite our integral as $$\oint \limits_{C} \frac{2}{z^3+z}dz = 2 \oint \limits_C \bigg(\frac{1}{z}\cdot \frac{1}{(z+i)(z-i)}\bigg)dz$$ Now we may define two closed, piecewise smooth curves $C_1, C_2$ around each singular point in $C$ as follows We then have that \begin{align}\oint \limits_{C} \frac{2}{z^3+z}dz &= 2 \oint \limits_C \bigg(\frac{1}{z}\cdot \frac{1}{(z+i)(z-i)}\bigg)dz \\ &= 2 \bigg[ \underbrace{\oint \limits_{C_1} \bigg(\frac{1}{z}\cdot \frac{1}{(z+i)(z-i)}\bigg)dz}_{\displaystyle I_1} + \underbrace{\oint \limits_{C_2} \bigg(\frac{1}{z}\cdot \frac{1}{(z+i)(z-i)}\bigg)dz}_{\displaystyle I_2} \bigg] \end{align} Now let $f(z) = \frac{1}{z(z+i)}$ then, from Cauchy Integral Formula, we know that \begin{align}I_1 &=\oint \limits_{C_1} \frac{f(z)}{(z-i)}dz \\ &= 2\pi i ~f(i) \\ &=-\pi i\end{align} Now let $g(z) = \frac{1}{(z+i)(z-i)}$ , then from Cauchy Integral Formula, we know that \begin{align}I_2 &= \oint \limits_{C_2} \frac{g(z)}{z}dz \\ &= 2\pi i ~ g(0) \\ &= 2\pi i\end{align} So finally we have that \begin{align}\oint \limits_C \frac{2}{z^3 + z}dz = 2\big( -\pi i + 2\pi i\big) = 2 \pi i\end{align} Does this seem correct?","Without residue theory, determine if is positively oriented. We first find that our integrand has three distinct singular points Now if we draw a sketch of , we see that only two of these singular points are within . We can thus rewrite our integral as Now we may define two closed, piecewise smooth curves around each singular point in as follows We then have that Now let then, from Cauchy Integral Formula, we know that Now let , then from Cauchy Integral Formula, we know that So finally we have that Does this seem correct?","\oint \limits_{C} \frac{2}{z^3+z}dz C: \big|~z~-~\frac{i}{2}~\big|=1 z=\{-i,~0,~i\} C C \oint \limits_{C} \frac{2}{z^3+z}dz = 2 \oint \limits_C \bigg(\frac{1}{z}\cdot \frac{1}{(z+i)(z-i)}\bigg)dz C_1, C_2 C \begin{align}\oint \limits_{C} \frac{2}{z^3+z}dz &= 2 \oint \limits_C \bigg(\frac{1}{z}\cdot \frac{1}{(z+i)(z-i)}\bigg)dz \\ &= 2 \bigg[ \underbrace{\oint \limits_{C_1} \bigg(\frac{1}{z}\cdot \frac{1}{(z+i)(z-i)}\bigg)dz}_{\displaystyle I_1} + \underbrace{\oint \limits_{C_2} \bigg(\frac{1}{z}\cdot \frac{1}{(z+i)(z-i)}\bigg)dz}_{\displaystyle I_2} \bigg] \end{align} f(z) = \frac{1}{z(z+i)} \begin{align}I_1 &=\oint \limits_{C_1} \frac{f(z)}{(z-i)}dz \\ &= 2\pi i ~f(i) \\ &=-\pi i\end{align} g(z) = \frac{1}{(z+i)(z-i)} \begin{align}I_2 &= \oint \limits_{C_2} \frac{g(z)}{z}dz \\ &= 2\pi i ~ g(0) \\ &= 2\pi i\end{align} \begin{align}\oint \limits_C \frac{2}{z^3 + z}dz = 2\big( -\pi i + 2\pi i\big) = 2 \pi i\end{align}","['complex-analysis', 'contour-integration', 'cauchy-integral-formula']"
62,Not every holomorphic function $f$ can be written as $f(z)=e^{g(z)}$,Not every holomorphic function  can be written as,f f(z)=e^{g(z)},"Problem: Show that not every holomorphic function $f:\Bbb C-\{0\}\to\Bbb C-\{0\}$ can be written as   $$f(z)=e^{g(z)}$$   for some holomorphic function $g:\Bbb C-\{0\}\to\Bbb C$. I tried to arrive at a contradiction by supposing $$e^{g(z)}=\frac{1}{z}$$ for some $g$. We would have $\int_\gamma e^{g(z)}dz=2\pi i$ over the unit circle, so it would be sufficient to show that $e^{g(z)}$ extends to a holomorphic function on $\Bbb C$, but I am not sure if we can do this.","Problem: Show that not every holomorphic function $f:\Bbb C-\{0\}\to\Bbb C-\{0\}$ can be written as   $$f(z)=e^{g(z)}$$   for some holomorphic function $g:\Bbb C-\{0\}\to\Bbb C$. I tried to arrive at a contradiction by supposing $$e^{g(z)}=\frac{1}{z}$$ for some $g$. We would have $\int_\gamma e^{g(z)}dz=2\pi i$ over the unit circle, so it would be sufficient to show that $e^{g(z)}$ extends to a holomorphic function on $\Bbb C$, but I am not sure if we can do this.",,['complex-analysis']
63,"Show that if there exist two complex numbers $a,b$ such that $f(a)=a$ and $f(b)=b$ then $f(z)=z$ for all $z\in B(0,1)$.",Show that if there exist two complex numbers  such that  and  then  for all .,"a,b f(a)=a f(b)=b f(z)=z z\in B(0,1)","Let $f:B(0,1) \to B(0,1)$ holomorphic. Show that if there exist two complex numbers $a,b$ such that $f(a)=a$ and $f(b)=b$ then $f(z)=z$ for all $z\in B(0,1)$. There is a suggestion in the excercise that says, consider the function $g(z)=\frac{h(z)-a}{1-\overline{a}h(z)}$ with $h(z)=f \left(\frac{z+a}{1+\overline{a}z} \right)$ and use Schwarz Lemma. Ok, so I've been thinking about this excercise for a while, I wasn't able to solve it. Im not seeing how can I use the suggestion. By replacing, I easily got that $g(0)=0$ but Im not being able to prove that $|g(z)|<1$ and also Im not being able to continue even assuming that is true. Any hint in how to use the suggestion?","Let $f:B(0,1) \to B(0,1)$ holomorphic. Show that if there exist two complex numbers $a,b$ such that $f(a)=a$ and $f(b)=b$ then $f(z)=z$ for all $z\in B(0,1)$. There is a suggestion in the excercise that says, consider the function $g(z)=\frac{h(z)-a}{1-\overline{a}h(z)}$ with $h(z)=f \left(\frac{z+a}{1+\overline{a}z} \right)$ and use Schwarz Lemma. Ok, so I've been thinking about this excercise for a while, I wasn't able to solve it. Im not seeing how can I use the suggestion. By replacing, I easily got that $g(0)=0$ but Im not being able to prove that $|g(z)|<1$ and also Im not being able to continue even assuming that is true. Any hint in how to use the suggestion?",,['complex-analysis']
64,Finite open covers of a complex $C^{(1)}$ curve.,Finite open covers of a complex  curve.,C^{(1)},"Consider a complex curve $\gamma \subset \mathbb{C}$, parametrized by $\alpha: [a,b]\to \mathbb{C}$, with $\alpha \in C^{(1)}$. Further, consider an finite open cover $\Phi$ of $\gamma=\alpha([a,b])$. Such cover exists by compactness and continuity. I want to show that we can find a $\textbf{finite}$ partition $a=t_0<t_1<\dots<t_n=b$ such that, for each $k\in\{1,\dots,n\}$, there exists $V\in \Phi$ with $\alpha \left ( [t_{k-1},t_k]\right ) \subset V$. Intuitively, this seems obvious, but I can't seem to come up with a rigorous proof (or a counterexample). My best effort is as follows: Since $\Phi$ is a cover of $\gamma$, $\alpha(a)$ belongs to some member of $\Phi$, call it $V_1$. If $\gamma \subset V_1$, then we are done. Suppose then that: $$\{ t\in [a,b] : \alpha(t)\not \in V_1 \}\neq \emptyset$$ Since $\alpha$ is continuous and $V$ is open, the LHS is closed  (and bounded), hence compact, and thus contains a minimum element, say $t_1$, with $a<t_1$. Again, since $\Phi$ is a cover of $\gamma$, $\alpha(t_1)$ belongs to some member of $\Phi$ (different from $V_1$), say $V_2$. We repeat the argument to find $t_2 = \min\{ t\in [t_1,b] : \alpha(t)\not \in V_2 \}$, with $t_2 > t_1$. At each step, if the sets so far considered are already a cover for $\gamma$, we are done (alternatively, to avoid this we could suppose that $\Phi$ a minimal cover, which exists by finiteness). We can obviously continue this way to find $t_1<t_2<t_3,\dots$, but does the process end in a finite number of steps, where the final $t_n$ found is $b$? My objection to the past construction is that the relative lengths of the intervals $[t_{k-1},t_k]$ could become arbitrarily small, and hence we might never ""reach"" the endpoint $b$, ala Zeno's paradox. I imagine that I'm missing something related to the compactness of the sets which are involved. Further, the fact that the curve is of class $C^{(1)}$ has not been used yet, merely the continuity of the curve, so its natural to ask whether this also holds for a curve which is simply continuous, or whether I need this additional hypothesis to complete the curve. If anyone could either help me finish with my method, or provide me with an alternative argument for the existence of the desired partition, I would be extremely grateful. Also, would anything changed if we restricted the members of $\Phi$ to be open disks? Note : I realize the title is rather vague, but I couldn't come up with something more specific (and short), so I'm open for suggestions.","Consider a complex curve $\gamma \subset \mathbb{C}$, parametrized by $\alpha: [a,b]\to \mathbb{C}$, with $\alpha \in C^{(1)}$. Further, consider an finite open cover $\Phi$ of $\gamma=\alpha([a,b])$. Such cover exists by compactness and continuity. I want to show that we can find a $\textbf{finite}$ partition $a=t_0<t_1<\dots<t_n=b$ such that, for each $k\in\{1,\dots,n\}$, there exists $V\in \Phi$ with $\alpha \left ( [t_{k-1},t_k]\right ) \subset V$. Intuitively, this seems obvious, but I can't seem to come up with a rigorous proof (or a counterexample). My best effort is as follows: Since $\Phi$ is a cover of $\gamma$, $\alpha(a)$ belongs to some member of $\Phi$, call it $V_1$. If $\gamma \subset V_1$, then we are done. Suppose then that: $$\{ t\in [a,b] : \alpha(t)\not \in V_1 \}\neq \emptyset$$ Since $\alpha$ is continuous and $V$ is open, the LHS is closed  (and bounded), hence compact, and thus contains a minimum element, say $t_1$, with $a<t_1$. Again, since $\Phi$ is a cover of $\gamma$, $\alpha(t_1)$ belongs to some member of $\Phi$ (different from $V_1$), say $V_2$. We repeat the argument to find $t_2 = \min\{ t\in [t_1,b] : \alpha(t)\not \in V_2 \}$, with $t_2 > t_1$. At each step, if the sets so far considered are already a cover for $\gamma$, we are done (alternatively, to avoid this we could suppose that $\Phi$ a minimal cover, which exists by finiteness). We can obviously continue this way to find $t_1<t_2<t_3,\dots$, but does the process end in a finite number of steps, where the final $t_n$ found is $b$? My objection to the past construction is that the relative lengths of the intervals $[t_{k-1},t_k]$ could become arbitrarily small, and hence we might never ""reach"" the endpoint $b$, ala Zeno's paradox. I imagine that I'm missing something related to the compactness of the sets which are involved. Further, the fact that the curve is of class $C^{(1)}$ has not been used yet, merely the continuity of the curve, so its natural to ask whether this also holds for a curve which is simply continuous, or whether I need this additional hypothesis to complete the curve. If anyone could either help me finish with my method, or provide me with an alternative argument for the existence of the desired partition, I would be extremely grateful. Also, would anything changed if we restricted the members of $\Phi$ to be open disks? Note : I realize the title is rather vague, but I couldn't come up with something more specific (and short), so I'm open for suggestions.",,"['complex-analysis', 'plane-curves']"
65,an exercise involving open mapping theorem,an exercise involving open mapping theorem,,"I am stuck with an exercise in complex analysis that reads as follows... Suppose $f:U\longrightarrow\mathbb{C}$ is a holomorphic function from a connected open set $U$ such that for every $z\in U$ there are integers $m,n$ possibly depending on $z$ such that $f(z)^m=\overline{f(z)}^n$. Show that $f$ is constant. I think I should use the open mapping theorem to define a logarithm or a $m$th root of $f$ locally, but since $m,n$ are a priori dependent on $z$ I don't see where to go from there... any help would be appreciated. Thanks!","I am stuck with an exercise in complex analysis that reads as follows... Suppose $f:U\longrightarrow\mathbb{C}$ is a holomorphic function from a connected open set $U$ such that for every $z\in U$ there are integers $m,n$ possibly depending on $z$ such that $f(z)^m=\overline{f(z)}^n$. Show that $f$ is constant. I think I should use the open mapping theorem to define a logarithm or a $m$th root of $f$ locally, but since $m,n$ are a priori dependent on $z$ I don't see where to go from there... any help would be appreciated. Thanks!",,['complex-analysis']
66,What is the limit of $x^{e^{x}}$ if $x$ tends to $-\infty$?,What is the limit of  if  tends to ?,x^{e^{x}} x -\infty,"I was looking at the function $f(x)=x^{e^{x}}$ and was curious as to why its domain is defined for $x\geq0$, when it looks like there are no problems with negative values of $x$. Also, when plugging in negative values for $x$, I noticed that it looks like $f(x)$ is approaching $-1$, but when doing the actual limit, this is the result: $$\lim_{x\to-\infty} f(x) = 1$$ Could someone give me an explanation as to why these are the results? I feel really lost. I want to say that it has to do with trying to take $\ln({f(x)})$, but I am not really sure if that has anything to do with it. Any help/insight is greatly appreciated. Thanks.","I was looking at the function $f(x)=x^{e^{x}}$ and was curious as to why its domain is defined for $x\geq0$, when it looks like there are no problems with negative values of $x$. Also, when plugging in negative values for $x$, I noticed that it looks like $f(x)$ is approaching $-1$, but when doing the actual limit, this is the result: $$\lim_{x\to-\infty} f(x) = 1$$ Could someone give me an explanation as to why these are the results? I feel really lost. I want to say that it has to do with trying to take $\ln({f(x)})$, but I am not really sure if that has anything to do with it. Any help/insight is greatly appreciated. Thanks.",,['complex-analysis']
67,Ratio of Hypergeometric Functions [closed],Ratio of Hypergeometric Functions [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Show that if $a$ is a negative integer while $b$ and $c$ are not integers, then the ratio $$\dfrac{F(a,b;a+b-c+1;1-z)}{F(a,b;c;z)}$$ is independent of $z$ and find its value. Thanks in advance! EDIT: From gammatesters answer, we may conclude: $$\dfrac{F\left( a,b;c;z \right)}{F(a,b;a+b-c+1;1-z)} = \frac{\Gamma(c)\Gamma(c-a-b)}{\Gamma(c-a) \Gamma(c-b)} = \dfrac{(c-a)_a}{(c-b)_a},$$ using the definition of the Pochhammer symbol $(a)_n=\dfrac{\Gamma(a+n)}{\Gamma(n)}$.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Show that if $a$ is a negative integer while $b$ and $c$ are not integers, then the ratio $$\dfrac{F(a,b;a+b-c+1;1-z)}{F(a,b;c;z)}$$ is independent of $z$ and find its value. Thanks in advance! EDIT: From gammatesters answer, we may conclude: $$\dfrac{F\left( a,b;c;z \right)}{F(a,b;a+b-c+1;1-z)} = \frac{\Gamma(c)\Gamma(c-a-b)}{\Gamma(c-a) \Gamma(c-b)} = \dfrac{(c-a)_a}{(c-b)_a},$$ using the definition of the Pochhammer symbol $(a)_n=\dfrac{\Gamma(a+n)}{\Gamma(n)}$.",,"['complex-analysis', 'hypergeometric-function']"
68,How to find Radius of Convergence in general?,How to find Radius of Convergence in general?,,"I am now learning complex analysis and my very first obstacle is that I cannot find a systematic way to tackle the problem of finding radius of convergence. In particular, I am not familiar with $\lim \sup$. The only thing I use is the Cauchy-Hadamard formula: Consider $\sum c_n z^n$. The radius of convergence of this series, R,   is given by $$ R = \left( \lim \sup_{n \to \infty} | c_n |  ^{\frac{1}{n}} \right)^{-1} .$$ The following are some questions I have encountered. I mention them so as to show my logic to solve these problems. I hope that you can give me some instructions. For example, I want to find the radius of convergence of $\sum z^{n!}$. I checked in MSE, and found the solution using ratio test. Then I came across the problem of finding R of $\sum (n+2^n)z^n$. And now I am stuck when using Cauchy Hadamard formula. Then I come up with this solution: Note that $$\sum (n+2^n)z^n = \sum nz^n + \sum (2z)^n.$$ The first sum   will converge for $|z|<1$ and the second sum would converge for   $|2z|<1$, i.e. $|z|<0.5$. Hence, $R= 0.5$.   Is there any problem? I also have the following problem: Suppose $\sum c_n z^n$ has a radius of convergence R. Find the radius   of convergence of $\sum n^p c_n z^n$. Again, I make use of the Cauchy Hadamard formula $\lim \sup_{n \to \infty} | n^pc_n | ^{\frac{1}{n}}$. But I don't know what can be done for that. I appreciate that you can give me some ideas on the questions. But more importantly, it would be of my best interest that you can introduce more on finding radius of convergence.","I am now learning complex analysis and my very first obstacle is that I cannot find a systematic way to tackle the problem of finding radius of convergence. In particular, I am not familiar with $\lim \sup$. The only thing I use is the Cauchy-Hadamard formula: Consider $\sum c_n z^n$. The radius of convergence of this series, R,   is given by $$ R = \left( \lim \sup_{n \to \infty} | c_n |  ^{\frac{1}{n}} \right)^{-1} .$$ The following are some questions I have encountered. I mention them so as to show my logic to solve these problems. I hope that you can give me some instructions. For example, I want to find the radius of convergence of $\sum z^{n!}$. I checked in MSE, and found the solution using ratio test. Then I came across the problem of finding R of $\sum (n+2^n)z^n$. And now I am stuck when using Cauchy Hadamard formula. Then I come up with this solution: Note that $$\sum (n+2^n)z^n = \sum nz^n + \sum (2z)^n.$$ The first sum   will converge for $|z|<1$ and the second sum would converge for   $|2z|<1$, i.e. $|z|<0.5$. Hence, $R= 0.5$.   Is there any problem? I also have the following problem: Suppose $\sum c_n z^n$ has a radius of convergence R. Find the radius   of convergence of $\sum n^p c_n z^n$. Again, I make use of the Cauchy Hadamard formula $\lim \sup_{n \to \infty} | n^pc_n | ^{\frac{1}{n}}$. But I don't know what can be done for that. I appreciate that you can give me some ideas on the questions. But more importantly, it would be of my best interest that you can introduce more on finding radius of convergence.",,['complex-analysis']
69,Radius Of Convergence Confusion [duplicate],Radius Of Convergence Confusion [duplicate],,"This question already has answers here : Finding the convergence interval of $\sum_{n=0}^\infty\frac{n!x^n}{n^n}$. (2 answers) Closed 4 years ago . Given the series $\sum^{\infty}_{n=1} \frac{n!z^n}{n^n}$ find the radius of convergence. Well, I know that if the following Lemma holds: Lemma Given the series $\sum^{\infty}_{n=1} c_nz^n$ where $c_n,z \in \mathbb C$. If $\beta := lim\frac{|c_n|}{|c_{n+1}|}$ exists, then it is also agrees with the radius of convergence $\rho := \frac{1}{limsup|c_n|^{1/n}}$. That is, $\beta = \rho$ Attempt at the Solution First I apply the lemma above: $\frac{\frac{n!}{n^n}}{\frac{(n+1)!}{n^{n+1}}} = \frac{n}{n+1} = 1 -\frac{1}{n+1} \rightarrow 1$ If I now consider $\limsup(\frac{n!}{n^n})^{1/n} = \limsup\frac{(n!)^{1/n}}{n} \rightarrow +\infty$ Since $\limsup(n!)^{1/n} \rightarrow +\infty$ faster than $\limsup n \rightarrow +\infty$ On the authority of the textbook I'm reading, the radius of convergence should be $e$ I'm not quite sure how one comes to that conclusion. If anyone could point me into the right direction that would be great. Thanks.","This question already has answers here : Finding the convergence interval of $\sum_{n=0}^\infty\frac{n!x^n}{n^n}$. (2 answers) Closed 4 years ago . Given the series $\sum^{\infty}_{n=1} \frac{n!z^n}{n^n}$ find the radius of convergence. Well, I know that if the following Lemma holds: Lemma Given the series $\sum^{\infty}_{n=1} c_nz^n$ where $c_n,z \in \mathbb C$. If $\beta := lim\frac{|c_n|}{|c_{n+1}|}$ exists, then it is also agrees with the radius of convergence $\rho := \frac{1}{limsup|c_n|^{1/n}}$. That is, $\beta = \rho$ Attempt at the Solution First I apply the lemma above: $\frac{\frac{n!}{n^n}}{\frac{(n+1)!}{n^{n+1}}} = \frac{n}{n+1} = 1 -\frac{1}{n+1} \rightarrow 1$ If I now consider $\limsup(\frac{n!}{n^n})^{1/n} = \limsup\frac{(n!)^{1/n}}{n} \rightarrow +\infty$ Since $\limsup(n!)^{1/n} \rightarrow +\infty$ faster than $\limsup n \rightarrow +\infty$ On the authority of the textbook I'm reading, the radius of convergence should be $e$ I'm not quite sure how one comes to that conclusion. If anyone could point me into the right direction that would be great. Thanks.",,"['sequences-and-series', 'complex-analysis', 'convergence-divergence', 'power-series']"
70,Let $f(z)\ = \frac {z^5} {|z|^4}$ if $z\ \neq 0$ and $f(0) = 0$,Let  if  and,f(z)\ = \frac {z^5} {|z|^4} z\ \neq 0 f(0) = 0,"Question : Conclude that the partials of u , v exist and that the Cauchy-Riemann equations hold but that $f'(0)$ does not exist. Does this conclusion contradict the Cauchy-Riemann Theorem? Could some one explain how I can prove this? I was sick and missed an entire week of class, but is this related to the Inverse Function Theorem? For the CR equations, the previous question told me to assume that $ u = Re(f)$ and $v = Im(f)$.","Question : Conclude that the partials of u , v exist and that the Cauchy-Riemann equations hold but that $f'(0)$ does not exist. Does this conclusion contradict the Cauchy-Riemann Theorem? Could some one explain how I can prove this? I was sick and missed an entire week of class, but is this related to the Inverse Function Theorem? For the CR equations, the previous question told me to assume that $ u = Re(f)$ and $v = Im(f)$.",,['complex-analysis']
71,How do I solve this complex integration problem?.,How do I solve this complex integration problem?.,,"I want to find the value of  $$I=\int_{|z|=r}\frac{|dz|}{|z-z_0|^4},$$ where $|z_0|\neq r>0$.","I want to find the value of  $$I=\int_{|z|=r}\frac{|dz|}{|z-z_0|^4},$$ where $|z_0|\neq r>0$.",,"['complex-analysis', 'contour-integration']"
72,Direct evaluation of Multivariate Complex Gaussian Integral without using analytic continuation,Direct evaluation of Multivariate Complex Gaussian Integral without using analytic continuation,,"Consider the integral $$ \int_{\mathbb{R}^n}dx\,e^{-\frac12 x^TAx}=\frac{(2\pi)^{n/2}}{\sqrt{\det A}} $$ where $A=A^T$ is a symmetric $n\times n$ complex matrix with positive definite real part. Question: can we explicitly calculate this integral (for complex $A$ ) without using analytic continuation? Motivation: the standard proof of the above result starts off with a real $A$ and uses Cholesky decomposition to decouple the integral into $n$ one-dimensional Gaussian. (Diagonalizing $A$ with an orthogonal matrix with Jacobian $J=1$ essentially does the same.) Then one argues that, as long as the real part of $A$ remains positive definite, both sides are holomorphic and by analytic continuation the integral must have the value of the right hand side even for complex $A$ , (see a good discussion on this here ). My question is motivated by the observation that for $n=1$ everything is scalar, $\det A=A$ , and one can prove the above result for $\Re A>0$ using Cauchy theorem and contour integration with complex Jacobian $J=\sqrt{A}$ , $\arg\sqrt{A}\in(-\pi/4,\pi/4)$ . There is no need for analytic continuation (unless of course you want to go to $\Re A<0$ ), see the proof here . So I wonder if there exists a direct proof for $n>1$ using some variant of Cauchy theorem in $\mathbb{C}^n$ ? Or some other way of integration with substitution using complex Jacobians, without having to rely on analytic continuation?","Consider the integral where is a symmetric complex matrix with positive definite real part. Question: can we explicitly calculate this integral (for complex ) without using analytic continuation? Motivation: the standard proof of the above result starts off with a real and uses Cholesky decomposition to decouple the integral into one-dimensional Gaussian. (Diagonalizing with an orthogonal matrix with Jacobian essentially does the same.) Then one argues that, as long as the real part of remains positive definite, both sides are holomorphic and by analytic continuation the integral must have the value of the right hand side even for complex , (see a good discussion on this here ). My question is motivated by the observation that for everything is scalar, , and one can prove the above result for using Cauchy theorem and contour integration with complex Jacobian , . There is no need for analytic continuation (unless of course you want to go to ), see the proof here . So I wonder if there exists a direct proof for using some variant of Cauchy theorem in ? Or some other way of integration with substitution using complex Jacobians, without having to rely on analytic continuation?","
\int_{\mathbb{R}^n}dx\,e^{-\frac12 x^TAx}=\frac{(2\pi)^{n/2}}{\sqrt{\det A}}
 A=A^T n\times n A A n A J=1 A A n=1 \det A=A \Re A>0 J=\sqrt{A} \arg\sqrt{A}\in(-\pi/4,\pi/4) \Re A<0 n>1 \mathbb{C}^n","['calculus', 'complex-analysis', 'contour-integration', 'gaussian-integral']"
73,Inequality $|f(x)|' \le c|f'(x)| $?,Inequality ?,|f(x)|' \le c|f'(x)| ,"Let $f:\mathbb{R} \ni x\mapsto f(x) \in \mathbb{C}$. I want to know that the following is true: $$\left| \frac{d|f(x)|}{dx}\right| \le \frac{|f_r f_r'| +|f_i f_i'|}{|f|} \le \frac{(|f_r| + |f_i|)(|f_r'| + |f_i'|)}{|f|} \le c \frac{|f| |f'|}{|f|}\le c|f'(x)|$$ with some positive constant $c$, where $f(x) = f_r(x) + if_i(x) $.","Let $f:\mathbb{R} \ni x\mapsto f(x) \in \mathbb{C}$. I want to know that the following is true: $$\left| \frac{d|f(x)|}{dx}\right| \le \frac{|f_r f_r'| +|f_i f_i'|}{|f|} \le \frac{(|f_r| + |f_i|)(|f_r'| + |f_i'|)}{|f|} \le c \frac{|f| |f'|}{|f|}\le c|f'(x)|$$ with some positive constant $c$, where $f(x) = f_r(x) + if_i(x) $.",,"['calculus', 'complex-analysis', 'derivatives']"
74,Is holomorphic function on the Riemann sphere entire?,Is holomorphic function on the Riemann sphere entire?,,"What does holomorphic function on the Riemann sphere mean? Is that just $f\in H(\mathbb{C}\cup \{\infty\})$, so $f:\mathbb{C\cup \{\infty\}}\to \mathbb{C}$. And is $f$ entire? Since $f$ is holomorhpic over the whole complex plane. I am attempting to prove the following: All holomorphic functions on the Riemann shpere are constant The way to do this is by Liouville's theorem, which said every bounded entire function is constant. So I just need to show that entire function on Riemann sphere is bounded.","What does holomorphic function on the Riemann sphere mean? Is that just $f\in H(\mathbb{C}\cup \{\infty\})$, so $f:\mathbb{C\cup \{\infty\}}\to \mathbb{C}$. And is $f$ entire? Since $f$ is holomorhpic over the whole complex plane. I am attempting to prove the following: All holomorphic functions on the Riemann shpere are constant The way to do this is by Liouville's theorem, which said every bounded entire function is constant. So I just need to show that entire function on Riemann sphere is bounded.",,['complex-analysis']
75,Finding the (12k+2)th derivative,Finding the (12k+2)th derivative,,"Find:   $$\frac{d^{12k+2}}{dt^{12k+2}}\left[e^{t\sqrt{3}/2}\cos(t/2)\right], k \in \mathbb{N}$$ The answer should not be dependent on the value of $k$, which I gathered to mean that $k$ is not in the final solution, but I am not entirely sure on that. I have managed to reduce it to: $$Re(((((sqrt(3)+1)/2)^(6k+1))*e^(i*pi/6))*e^(t(sqrt(3)+i)/2))$$ However, I cannot seem to go further whilst also eliminating $k$ from the answer. How can I solve this question?","Find:   $$\frac{d^{12k+2}}{dt^{12k+2}}\left[e^{t\sqrt{3}/2}\cos(t/2)\right], k \in \mathbb{N}$$ The answer should not be dependent on the value of $k$, which I gathered to mean that $k$ is not in the final solution, but I am not entirely sure on that. I have managed to reduce it to: $$Re(((((sqrt(3)+1)/2)^(6k+1))*e^(i*pi/6))*e^(t(sqrt(3)+i)/2))$$ However, I cannot seem to go further whilst also eliminating $k$ from the answer. How can I solve this question?",,"['complex-analysis', 'trigonometry', 'derivatives']"
76,Primitive of $dz/z$ is a branch of log,Primitive of  is a branch of log,dz/z,"Let $D$ a connected open set of $\mathbb{C}$. A continuous function $f:D\to \mathbb{C}$ is a branch of log if $e^{f(t)}=t$ on $D$. In my book (Cartan) it is written that if $F$ is a primitive of the 1-form $dz/z$ on $D$ then $F$ is a branch of log on $D$. It is easy to show that if $f$ is a branch of log on $D$, then $f'(t)=1/t$. So I'd like to prove the converse statement. Any suggestions?","Let $D$ a connected open set of $\mathbb{C}$. A continuous function $f:D\to \mathbb{C}$ is a branch of log if $e^{f(t)}=t$ on $D$. In my book (Cartan) it is written that if $F$ is a primitive of the 1-form $dz/z$ on $D$ then $F$ is a branch of log on $D$. It is easy to show that if $f$ is a branch of log on $D$, then $f'(t)=1/t$. So I'd like to prove the converse statement. Any suggestions?",,"['complex-analysis', 'logarithms']"
77,If $\sum c_{n} (z-a)^n$ has a radius of convergence $R$ show $\sum c_{n} n(z-a)^{n-1}$ does as well,If  has a radius of convergence  show  does as well,\sum c_{n} (z-a)^n R \sum c_{n} n(z-a)^{n-1},"If the series, $$\sum_{n=0}^{\infty} c_{n} (z-a)^{n}$$ has a radius of convergence, $R$ . Show, $$\sum_{n=0}^{\infty} c_{n} n(z-a)^{n-1} $$ has the same radius of convergence. My proof: The power series $$\sum_{n=0}^{\infty} c_{n} (z-a)^{n}$$ having a radius of convergence $R$ means that, $$\lim_{n \to \infty}|\frac{c_n}{c_{n+1}}|=R$$ Let $k_n=nc_n$ , by definition $$\sum_{n=0}^{\infty} k_{n} (z-a)^{n-1} $$ is also a power series so the same theorem should apply. $$\lim_{n \to \infty} |\frac{nc_{n}}{(n+1)c_{n+1}}|=R \lim_{n \to \infty} |1-\frac{1}{n}|=R$$ Q.E.D Is my proof correct? Does anyone else have another proof method?","If the series, has a radius of convergence, . Show, has the same radius of convergence. My proof: The power series having a radius of convergence means that, Let , by definition is also a power series so the same theorem should apply. Q.E.D Is my proof correct? Does anyone else have another proof method?",\sum_{n=0}^{\infty} c_{n} (z-a)^{n} R \sum_{n=0}^{\infty} c_{n} n(z-a)^{n-1}  \sum_{n=0}^{\infty} c_{n} (z-a)^{n} R \lim_{n \to \infty}|\frac{c_n}{c_{n+1}}|=R k_n=nc_n \sum_{n=0}^{\infty} k_{n} (z-a)^{n-1}  \lim_{n \to \infty} |\frac{nc_{n}}{(n+1)c_{n+1}}|=R \lim_{n \to \infty} |1-\frac{1}{n}|=R,"['sequences-and-series', 'complex-analysis', 'limits', 'proof-verification']"
78,Prove that $z_0$ is a removable singularity,Prove that  is a removable singularity,z_0,"Let $z_0$ be an isolated singularity of a holomorphic function $f$. Suppose that there are $A, \epsilon > 0$ such that for all $z$ sufficiently close to $z_0$ we have $$|f(z)| \leq \frac{A}{|z - z_0|^{1 - \epsilon}}\ .$$ Prove that $z_0$ is a removable singularity. Can someone please show me how to do this problem? Thank you.","Let $z_0$ be an isolated singularity of a holomorphic function $f$. Suppose that there are $A, \epsilon > 0$ such that for all $z$ sufficiently close to $z_0$ we have $$|f(z)| \leq \frac{A}{|z - z_0|^{1 - \epsilon}}\ .$$ Prove that $z_0$ is a removable singularity. Can someone please show me how to do this problem? Thank you.",,"['complex-analysis', 'analysis']"
79,Largest domain where the function $e^z/(\sin z+\cos z)$ is analytic,Largest domain where the function  is analytic,e^z/(\sin z+\cos z),"I have a function $f(z) = \frac{\exp{z}}{\sin z+\cos z}$ and I need to show the region where $f(z)$ is analytic. My work so far :- As the function is the sum and product of holomorphic functions, I conclude that it is holomorphic wherever it is defined. So it defined as long as $\sin z +\cos z \neq 0$. Using identities, $\sin(z)+\cos(z) = (\sin x+\cos x)\cosh{y} + i(\cos x-\sin x)\sinh y $ Now $\sin x + \cos x = 0$ for $x=(4n+1)\frac{\pi}{4}$ and $\cos x - \sin x = 0$ for $x=(4n-1)\frac{\pi}{4}$ For case 1, $\sinh y = 0$ which occurs at $y = 0$ For case 2, no such value of y. Hence solution is the $\mathbb{C} - (x=(4n+1)\frac{\pi}{4} , y= 0)$. Is this correct?","I have a function $f(z) = \frac{\exp{z}}{\sin z+\cos z}$ and I need to show the region where $f(z)$ is analytic. My work so far :- As the function is the sum and product of holomorphic functions, I conclude that it is holomorphic wherever it is defined. So it defined as long as $\sin z +\cos z \neq 0$. Using identities, $\sin(z)+\cos(z) = (\sin x+\cos x)\cosh{y} + i(\cos x-\sin x)\sinh y $ Now $\sin x + \cos x = 0$ for $x=(4n+1)\frac{\pi}{4}$ and $\cos x - \sin x = 0$ for $x=(4n-1)\frac{\pi}{4}$ For case 1, $\sinh y = 0$ which occurs at $y = 0$ For case 2, no such value of y. Hence solution is the $\mathbb{C} - (x=(4n+1)\frac{\pi}{4} , y= 0)$. Is this correct?",,"['complex-analysis', 'exponential-function', 'solution-verification']"
80,Complex line integrals in increasing directions,Complex line integrals in increasing directions,,The problem I am stuck on is :Evaluate $\displaystyle\int\frac{dz}{z^2+4}$ along the line $x+y=1$ in the direction of increasing x ..... Nothing I have learned in my independent study of this subject seems to help me here.......,The problem I am stuck on is :Evaluate $\displaystyle\int\frac{dz}{z^2+4}$ along the line $x+y=1$ in the direction of increasing x ..... Nothing I have learned in my independent study of this subject seems to help me here.......,,['complex-analysis']
81,Complex integration by Cauchy's residue theorem,Complex integration by Cauchy's residue theorem,,"Evaluate the following integral by Cauchy's Residue Theorem $$\int_C\frac{2z^2-z+1}{(2z-1)(z+1)^2}\,dz$$ where , $C:r=2\cos \theta$ , $0\le \theta \le \pi.$ I have problem about the contour $C$ . Here, $r^2=4\cos^2 \theta=\frac{4x^2}{x^2+y^2}$ , as $\tan \theta =y/x$ . Then , $x^2+y^2=\frac{4x^2}{x^2+y^2}\implies x^2+y^2=\pm 2x\implies (x\pm 1)^2+y^2=1$ . Thus we get two semicircles , which we take for the integration and why?","Evaluate the following integral by Cauchy's Residue Theorem where , , I have problem about the contour . Here, , as . Then , . Thus we get two semicircles , which we take for the integration and why?","\int_C\frac{2z^2-z+1}{(2z-1)(z+1)^2}\,dz C:r=2\cos \theta 0\le \theta \le \pi. C r^2=4\cos^2 \theta=\frac{4x^2}{x^2+y^2} \tan \theta =y/x x^2+y^2=\frac{4x^2}{x^2+y^2}\implies x^2+y^2=\pm 2x\implies (x\pm 1)^2+y^2=1",['complex-analysis']
82,Riemann mapping under which uncountably many boundary points correspond to a single point,Riemann mapping under which uncountably many boundary points correspond to a single point,,"I am interested in the following question, which is 10.4 from this list : Give an example of a domain conformally equivalent to the disc where   uncountably many points on the unit circle correspond to a single   point on the boundary. I take this to mean something like, ""Find a point $p$ on the boundary of the domain and uncountably many points $e^{i\theta_\alpha}$ such that $f(z)$ tends to each $e^{i\theta_\alpha}$ depending on how $z$ approaches $p$."" I was thinking of doing something like the following. Fix a finite number of angles $\theta_i$. Consider the unit disk, and excise line segments of length $1$ with center at the origin and angle $\theta_i$. Then excise a slit from origin to the boundary of the disk to make the region simply connected. It seems like the origin would then correspond to finitely many different points on the boundary of the disk (depending on which part of the middle ""star"" the sequence of points approaches the origin in the original region). However, cutting out uncountably many line segments no longer leaves an open set, so I don't think this method will work. Is there another way?","I am interested in the following question, which is 10.4 from this list : Give an example of a domain conformally equivalent to the disc where   uncountably many points on the unit circle correspond to a single   point on the boundary. I take this to mean something like, ""Find a point $p$ on the boundary of the domain and uncountably many points $e^{i\theta_\alpha}$ such that $f(z)$ tends to each $e^{i\theta_\alpha}$ depending on how $z$ approaches $p$."" I was thinking of doing something like the following. Fix a finite number of angles $\theta_i$. Consider the unit disk, and excise line segments of length $1$ with center at the origin and angle $\theta_i$. Then excise a slit from origin to the boundary of the disk to make the region simply connected. It seems like the origin would then correspond to finitely many different points on the boundary of the disk (depending on which part of the middle ""star"" the sequence of points approaches the origin in the original region). However, cutting out uncountably many line segments no longer leaves an open set, so I don't think this method will work. Is there another way?",,"['complex-analysis', 'conformal-geometry']"
83,Is there a simpler way to compute the residue of a function at a pole of order 3?,Is there a simpler way to compute the residue of a function at a pole of order 3?,,"The function $$\frac {1}{z^2(e^{i2\pi z}-1)}$$ has a triple pole at z = 0.  To compute the residue of f at z = 0, I can compute the Laurent expansion of f about z = 0, and then read off the coefficient of the 1/z term.  But the fraction requires polynomial long division and I generally make a lot of mistakes during this somewhat heavy computation (by hand).  Is there a better way to compute the residue at 0? Thanks,","The function $$\frac {1}{z^2(e^{i2\pi z}-1)}$$ has a triple pole at z = 0.  To compute the residue of f at z = 0, I can compute the Laurent expansion of f about z = 0, and then read off the coefficient of the 1/z term.  But the fraction requires polynomial long division and I generally make a lot of mistakes during this somewhat heavy computation (by hand).  Is there a better way to compute the residue at 0? Thanks,",,"['complex-analysis', 'residue-calculus', 'laurent-series']"
84,finding such function,finding such function,,"Is there a function $f(z)$ satisfying: (1) $f$ is analytic in some region containing $|z|\leq 1$ (2) The only zero of $f$ in $|z|\leq 1$ occurs at $1/2+i/2$ and it has order 3. (3) $|f(z)|=1$ in $|z|=1$ (4) $f'(0)=3/4$ If such $f$ exists, is it unique? Any idea/hints? I know this has to do with Schwarz lemma.","Is there a function $f(z)$ satisfying: (1) $f$ is analytic in some region containing $|z|\leq 1$ (2) The only zero of $f$ in $|z|\leq 1$ occurs at $1/2+i/2$ and it has order 3. (3) $|f(z)|=1$ in $|z|=1$ (4) $f'(0)=3/4$ If such $f$ exists, is it unique? Any idea/hints? I know this has to do with Schwarz lemma.",,['complex-analysis']
85,Image of a complex region,Image of a complex region,,"Let $A$ be the complex region that satisfies: $1\leq|z|\leq2 \wedge 0\leq\operatorname{Arg}z\leq\frac{1}{3}\pi$. Draw $A$ in the complex plane and describe the image of $A$ under $z\mapsto z^2$. I was able to draw $A$, it's a disk centered at the origin bounded by the circle with radius 1 and radius 2, with the condition that it's between the line's with angle $0$ and $\frac{1}{3}\pi$. I don't know the answer to the second question. Could someone give some help?","Let $A$ be the complex region that satisfies: $1\leq|z|\leq2 \wedge 0\leq\operatorname{Arg}z\leq\frac{1}{3}\pi$. Draw $A$ in the complex plane and describe the image of $A$ under $z\mapsto z^2$. I was able to draw $A$, it's a disk centered at the origin bounded by the circle with radius 1 and radius 2, with the condition that it's between the line's with angle $0$ and $\frac{1}{3}\pi$. I don't know the answer to the second question. Could someone give some help?",,['complex-analysis']
86,Holomorphicity and modularity of Jacobi forms,Holomorphicity and modularity of Jacobi forms,,"I am reading this paper Suerconformal algebras and mock theta functions by T. Eguchi and K. Hikami. In section 3.2, the authors define a function $$J(z;w;\tau) = \frac{(\theta_{11}(z;\tau))^2}{(\eta(\tau))^3} (\mu(z;t) - \mu(w;\tau))$$ where $\theta_{11}$ is one of the Jacobi theta functions, $$\theta_{11}(z;\tau) = i q^{1/8} y^{1/2} \prod\limits_{n=1}^{\infty} (1-q^n) (1-yq^n) (1-y^{-1}q^{n-1})$$ $\eta(\tau)$ is the Dedekind eta function $$\eta(\tau) = q^{1/24}\prod\limits_{n=1}^{\infty} (1-q^n)$$ and $\mu (z;\tau)$ is the following sum. $$\mu(z;\tau) = \frac{iy^{1/2}}{\theta_{11}(z;\tau)}\sum\limits_{n=1}^{\infty} (-1)^n \frac{q^{\frac{n(n+1)}{2}}y^n}{1-y q^n}$$ where $q = e^{2\pi i \tau}$ and $y = e^{2\pi i z}$ throughout, with $z \in \mathbb{C}$ and $\tau \in \mathbb{H}$. It is argued below equation (3.22) that since the function $J(z;w;\tau)$ is holomorphic in all its variables, then fixing the value of $w$ to $\frac{1}{2}$, $\frac{1+\tau}{2}$ and $\frac{\tau}{2}$ gives us following identifications of J-function with ratios of theta functions based on the transformation properties of these functions: $$J(z;\frac{1}{2};\tau) = \left(\frac{\theta_{10}(z;\tau)}{\theta_{10}(0;\tau)}\right)^2$$  $$J(z;\frac{1+\tau}{2};\tau) = \left(\frac{\theta_{00}(z;\tau)}{\theta_{00}(0;\tau)}\right)^2$$  $$J(z;\frac{\tau}{2};\tau) = \left(\frac{\theta_{01}(z;\tau)}{\theta_{01}(0;\tau)}\right)^2$$ My question is: Why is it so that holomorphicity and transformation properties of J-function at particular values of $w$ fixes the function completely? In other words, how can the authors be sure that, say $J(z;\frac{1+\tau}{2};\tau)$ is exactly equal to $\left(\frac{\theta_{00}(z;\tau)}{\theta_{00}(0;\tau)}\right)^2$ based on the knowledge of the two functions' transformation properties? Can there not be two different holomorphic functions that transform in the same way? For completeness, I present here the transformation properties of one of the examples above: $J(z;\frac{1+\tau}{2};\tau)$ and $\left(\frac{\theta_{00}(z;\tau)}{\theta_{00}(0;\tau)}\right)^2$. $$J(z+1;\frac{1+\tau}{2};\tau) = J(z;\frac{1+\tau}{2};\tau+1) = J(z;\frac{1+\tau}{2};\tau)$$ $$J(z+\tau;\frac{1+\tau}{2};\tau) = q^{-1} y^{-2} J(z;\frac{1+\tau}{2};\tau)$$ $$J(\frac{z}{\tau};\frac{1+\tau}{2};\frac{-1}{\tau}) = e^{-2\pi i z^2 /\tau} J(z;\frac{1+\tau}{2};\tau)$$ and $\left(\frac{\theta_{00}(z;\tau)}{\theta_{00}(0;\tau)}\right)^2$ also has the same transformation properties.","I am reading this paper Suerconformal algebras and mock theta functions by T. Eguchi and K. Hikami. In section 3.2, the authors define a function $$J(z;w;\tau) = \frac{(\theta_{11}(z;\tau))^2}{(\eta(\tau))^3} (\mu(z;t) - \mu(w;\tau))$$ where $\theta_{11}$ is one of the Jacobi theta functions, $$\theta_{11}(z;\tau) = i q^{1/8} y^{1/2} \prod\limits_{n=1}^{\infty} (1-q^n) (1-yq^n) (1-y^{-1}q^{n-1})$$ $\eta(\tau)$ is the Dedekind eta function $$\eta(\tau) = q^{1/24}\prod\limits_{n=1}^{\infty} (1-q^n)$$ and $\mu (z;\tau)$ is the following sum. $$\mu(z;\tau) = \frac{iy^{1/2}}{\theta_{11}(z;\tau)}\sum\limits_{n=1}^{\infty} (-1)^n \frac{q^{\frac{n(n+1)}{2}}y^n}{1-y q^n}$$ where $q = e^{2\pi i \tau}$ and $y = e^{2\pi i z}$ throughout, with $z \in \mathbb{C}$ and $\tau \in \mathbb{H}$. It is argued below equation (3.22) that since the function $J(z;w;\tau)$ is holomorphic in all its variables, then fixing the value of $w$ to $\frac{1}{2}$, $\frac{1+\tau}{2}$ and $\frac{\tau}{2}$ gives us following identifications of J-function with ratios of theta functions based on the transformation properties of these functions: $$J(z;\frac{1}{2};\tau) = \left(\frac{\theta_{10}(z;\tau)}{\theta_{10}(0;\tau)}\right)^2$$  $$J(z;\frac{1+\tau}{2};\tau) = \left(\frac{\theta_{00}(z;\tau)}{\theta_{00}(0;\tau)}\right)^2$$  $$J(z;\frac{\tau}{2};\tau) = \left(\frac{\theta_{01}(z;\tau)}{\theta_{01}(0;\tau)}\right)^2$$ My question is: Why is it so that holomorphicity and transformation properties of J-function at particular values of $w$ fixes the function completely? In other words, how can the authors be sure that, say $J(z;\frac{1+\tau}{2};\tau)$ is exactly equal to $\left(\frac{\theta_{00}(z;\tau)}{\theta_{00}(0;\tau)}\right)^2$ based on the knowledge of the two functions' transformation properties? Can there not be two different holomorphic functions that transform in the same way? For completeness, I present here the transformation properties of one of the examples above: $J(z;\frac{1+\tau}{2};\tau)$ and $\left(\frac{\theta_{00}(z;\tau)}{\theta_{00}(0;\tau)}\right)^2$. $$J(z+1;\frac{1+\tau}{2};\tau) = J(z;\frac{1+\tau}{2};\tau+1) = J(z;\frac{1+\tau}{2};\tau)$$ $$J(z+\tau;\frac{1+\tau}{2};\tau) = q^{-1} y^{-2} J(z;\frac{1+\tau}{2};\tau)$$ $$J(\frac{z}{\tau};\frac{1+\tau}{2};\frac{-1}{\tau}) = e^{-2\pi i z^2 /\tau} J(z;\frac{1+\tau}{2};\tau)$$ and $\left(\frac{\theta_{00}(z;\tau)}{\theta_{00}(0;\tau)}\right)^2$ also has the same transformation properties.",,"['complex-analysis', 'number-theory', 'modular-forms', 'automorphic-forms', 'theta-functions']"
87,Maximum is attained on the boundary,Maximum is attained on the boundary,,"Let $f_1, ... , f_n$ be holomorphic on a bounded domain $\Omega$, continuous on $\overline{\Omega}$.  Let $g = |f_1| + \cdots + |f_n|$.  The problem I couldn't get is to show that the maximum of $g$ is attained on the boundary of $\Omega$.  This should be some obvious application of the fact that the maximum of each $f_i$ occurs on the boundary, but I'm just not seeing it.","Let $f_1, ... , f_n$ be holomorphic on a bounded domain $\Omega$, continuous on $\overline{\Omega}$.  Let $g = |f_1| + \cdots + |f_n|$.  The problem I couldn't get is to show that the maximum of $g$ is attained on the boundary of $\Omega$.  This should be some obvious application of the fact that the maximum of each $f_i$ occurs on the boundary, but I'm just not seeing it.",,['complex-analysis']
88,Showing $f$ is constant using (?) the mean value theorem,Showing  is constant using (?) the mean value theorem,f,"So I'm working through a packet of old problems and I was wondering if any one could lend me a hand with this one. Let $D$ be an open domain in $\mathbb{C},$ containing the unit disc. Let $f: D\rightarrow\mathbb{C}$ be analytic. If  $$|f(0)|^2=\frac{1}{2\pi}\int_0^{2\pi} |f(e^{i\theta})|^2d\theta,$$ show that $f$ is constant. So my thought is to somehow use the MVP since the methods of Liouville and Max/Min Modulus Principle don't look promising. I just don't see how to connect the above and $$f(0)=\frac{1}{2\pi}\int_0^{2\pi} f(re^{i\theta}) d\theta,$$ where $0<r<1.$ Any suggestions would be appreciated. Thanks.","So I'm working through a packet of old problems and I was wondering if any one could lend me a hand with this one. Let $D$ be an open domain in $\mathbb{C},$ containing the unit disc. Let $f: D\rightarrow\mathbb{C}$ be analytic. If  $$|f(0)|^2=\frac{1}{2\pi}\int_0^{2\pi} |f(e^{i\theta})|^2d\theta,$$ show that $f$ is constant. So my thought is to somehow use the MVP since the methods of Liouville and Max/Min Modulus Principle don't look promising. I just don't see how to connect the above and $$f(0)=\frac{1}{2\pi}\int_0^{2\pi} f(re^{i\theta}) d\theta,$$ where $0<r<1.$ Any suggestions would be appreciated. Thanks.",,"['complex-analysis', 'maximum-principle']"
89,Finding an analytic function satisfying given two conditions.,Finding an analytic function satisfying given two conditions.,,"Does there exists an analytic function $f:D\to D$ such that $f(1/2)=1/2$ and $f'(1/2)=-1$ ? If exists then find such a function. where , $D=\{z\in \mathbb C:|z|<1\}.$ I found that such a function exists, as $$|f'(z)|\le \frac{1-|f(z)|^2}{1-|z|^2}$$ holds good. But I am unable to find such a function..Please help to construct such a function. Are there any particular rule to find such a function or it can be done only by trial ?","Does there exists an analytic function $f:D\to D$ such that $f(1/2)=1/2$ and $f'(1/2)=-1$ ? If exists then find such a function. where , $D=\{z\in \mathbb C:|z|<1\}.$ I found that such a function exists, as $$|f'(z)|\le \frac{1-|f(z)|^2}{1-|z|^2}$$ holds good. But I am unable to find such a function..Please help to construct such a function. Are there any particular rule to find such a function or it can be done only by trial ?",,"['complex-analysis', 'complex-numbers']"
90,Can the following trick be expanded upon?,Can the following trick be expanded upon?,,"Main Question What is the expansion of $d^{1+\epsilon}?$ Background I noticed the following trick (sometimes more laborious) to directly differentiate $ f(x) $ twice without differentiating it even once. To show what I mean let $ f(x)=x^2 $ By Taylor expansion for any $f(x)$ : Equation 1 $$ f(x+ \epsilon ) = f(x) + \epsilon f'(x) + \frac{\epsilon^2 f''(x)}{2!} + ...  $$ Equation 2 $$ f(x+ \epsilon ) = (x+ \epsilon )^2 = ... + \epsilon^2 $$ Comparing the $ \epsilon^2 $ term in equation $1 $and $2 $ we get: $$ \frac{f''(x)}{2!} = 1$$ Hence, $$ f''(x) = 2 $$ Question Can similar reasoning be applied for $ d^{1+\epsilon} g(x) $ where $g(x)$ is a dummy function to reveal the entire space of $ (d^n g(x)) $ on $g(x)$ ?","Main Question What is the expansion of $d^{1+\epsilon}?$ Background I noticed the following trick (sometimes more laborious) to directly differentiate $ f(x) $ twice without differentiating it even once. To show what I mean let $ f(x)=x^2 $ By Taylor expansion for any $f(x)$ : Equation 1 $$ f(x+ \epsilon ) = f(x) + \epsilon f'(x) + \frac{\epsilon^2 f''(x)}{2!} + ...  $$ Equation 2 $$ f(x+ \epsilon ) = (x+ \epsilon )^2 = ... + \epsilon^2 $$ Comparing the $ \epsilon^2 $ term in equation $1 $and $2 $ we get: $$ \frac{f''(x)}{2!} = 1$$ Hence, $$ f''(x) = 2 $$ Question Can similar reasoning be applied for $ d^{1+\epsilon} g(x) $ where $g(x)$ is a dummy function to reveal the entire space of $ (d^n g(x)) $ on $g(x)$ ?",,"['complex-analysis', 'derivatives', 'taylor-expansion', 'fractional-calculus']"
91,Why is this map a Möbius transformation?,Why is this map a Möbius transformation?,,"Question : Let $D_2=\bar D(2,1)$ and $D_{-2}=\bar D(-2,1)$ be the closed disks of radius $1$ centered at $z=2$ and $z=-2$ in the complex plane, respectively. Set $X= \mathbb C-\{D_2 \cup D_{-2} \}$, and suppose $$f:X \rightarrow X,$$ is analytic, 1-1, and satisfies $f(X)=X.$ Show that $f$ is a Möbius transformation. Attempt(s) : (1) I was thinking this could be done by contradiction. Here is a vague sketch of what I had in mind. Assume it's not a Möbius transformation. Viewing $f$ as a map on the Riemann sphere/extended complex plane minus these two disks, either $\infty\rightarrow \infty$ or some point on the boundary of one of the two disks is mapped to $\infty$. (If both ""large complex numbers"" and points near the boundary headed to $\infty$ we would not have injectivity. If neither, then we wouldn't have surjectivity.) If all points on the boundary of the disks do not go to $\infty$, then we can extend $f$ into the disks... (I get lost here) then somehow need to show that this maps $D_{-2}$ to $D_2$ and $D_2$ into $D_{-2}$, or fixes them both. What I would like to end up with is some automorphism of the Riemann sphere which must be a Möbius transformation. (2) Use symmetry and the Schwarz reflection principle somehow, but I don't know that the real line is mapped into real line.","Question : Let $D_2=\bar D(2,1)$ and $D_{-2}=\bar D(-2,1)$ be the closed disks of radius $1$ centered at $z=2$ and $z=-2$ in the complex plane, respectively. Set $X= \mathbb C-\{D_2 \cup D_{-2} \}$, and suppose $$f:X \rightarrow X,$$ is analytic, 1-1, and satisfies $f(X)=X.$ Show that $f$ is a Möbius transformation. Attempt(s) : (1) I was thinking this could be done by contradiction. Here is a vague sketch of what I had in mind. Assume it's not a Möbius transformation. Viewing $f$ as a map on the Riemann sphere/extended complex plane minus these two disks, either $\infty\rightarrow \infty$ or some point on the boundary of one of the two disks is mapped to $\infty$. (If both ""large complex numbers"" and points near the boundary headed to $\infty$ we would not have injectivity. If neither, then we wouldn't have surjectivity.) If all points on the boundary of the disks do not go to $\infty$, then we can extend $f$ into the disks... (I get lost here) then somehow need to show that this maps $D_{-2}$ to $D_2$ and $D_2$ into $D_{-2}$, or fixes them both. What I would like to end up with is some automorphism of the Riemann sphere which must be a Möbius transformation. (2) Use symmetry and the Schwarz reflection principle somehow, but I don't know that the real line is mapped into real line.",,"['complex-analysis', 'analyticity', 'mobius-transformation']"
92,Computation of a certain integral,Computation of a certain integral,,"Assume that $\alpha>0, t \in R$. Compute the integral $\int_0^1(-1)^xx^{-\alpha-it}dx.$","Assume that $\alpha>0, t \in R$. Compute the integral $\int_0^1(-1)^xx^{-\alpha-it}dx.$",,['complex-analysis']
93,Let $f$ be an entire function that is not a polynomial. Denote $M(r)=\max_{|z|=r}|f(z)|$. Show that $\lim_{r\to\infty}\frac{M(r/2)}{M(r)}=0$.,Let  be an entire function that is not a polynomial. Denote . Show that .,f M(r)=\max_{|z|=r}|f(z)| \lim_{r\to\infty}\frac{M(r/2)}{M(r)}=0,"Let $f$ be an entire function that is not a polynomial. Denote   $$ M(r)=\max_{|z|=r}|f(z)|. $$ Show that   $$ \lim_{r\to\infty}\frac{M(r/2)}{M(r)}=0. $$ I believe I have a proof for this, but I'm concerned because I don't think I'm using the assumption that $f$ is not a polynomial. My proof is the following: First, notice that \begin{align*} \log\left(\frac{M(r/2)}{M(r)}\right)&=\log M(r/2)-\log M(r)\\ &=-\frac{r}{2}\frac{d}{dr}\left(\log M(r)\right)\big|_{r=r_0} \end{align*} for some $r/2\leq r_0<r$ by the mean value theorem. Let $\log r=x$. By Hadamard's three-circles theorem, $\log M(r)$ is a convex function of $\log r$, i.e., $x$. Hence $\frac{d}{dx}\left(\log M(r)\right)>0$ for sufficiently large $x$. The chain rule shows $$ \frac{d}{dx}\left(\log M(r)\right)=e^x\cdot\frac{d}{dr}\left(\log M(r)\right). $$ Since $\frac{d}{dx}(\log M(r)),e^x>0$ for large $x$, $\frac{d}{dr}(\log M(r))>0$ for large $x$ as well. This shows that $$ \lim_{r\to\infty}\log\left(\frac{M(r/2)}{M(r)}\right)=-\infty $$ and so $\lim_{r\to\infty}\frac{M(r/2)}{M(r)}=0$. Could someone please enlighten me on where my proof goes wrong or where I may subtlety use the assumption? Alternative proofs are welcome. Thank you in advance for your time.","Let $f$ be an entire function that is not a polynomial. Denote   $$ M(r)=\max_{|z|=r}|f(z)|. $$ Show that   $$ \lim_{r\to\infty}\frac{M(r/2)}{M(r)}=0. $$ I believe I have a proof for this, but I'm concerned because I don't think I'm using the assumption that $f$ is not a polynomial. My proof is the following: First, notice that \begin{align*} \log\left(\frac{M(r/2)}{M(r)}\right)&=\log M(r/2)-\log M(r)\\ &=-\frac{r}{2}\frac{d}{dr}\left(\log M(r)\right)\big|_{r=r_0} \end{align*} for some $r/2\leq r_0<r$ by the mean value theorem. Let $\log r=x$. By Hadamard's three-circles theorem, $\log M(r)$ is a convex function of $\log r$, i.e., $x$. Hence $\frac{d}{dx}\left(\log M(r)\right)>0$ for sufficiently large $x$. The chain rule shows $$ \frac{d}{dx}\left(\log M(r)\right)=e^x\cdot\frac{d}{dr}\left(\log M(r)\right). $$ Since $\frac{d}{dx}(\log M(r)),e^x>0$ for large $x$, $\frac{d}{dr}(\log M(r))>0$ for large $x$ as well. This shows that $$ \lim_{r\to\infty}\log\left(\frac{M(r/2)}{M(r)}\right)=-\infty $$ and so $\lim_{r\to\infty}\frac{M(r/2)}{M(r)}=0$. Could someone please enlighten me on where my proof goes wrong or where I may subtlety use the assumption? Alternative proofs are welcome. Thank you in advance for your time.",,['complex-analysis']
94,Use Rouche's theorem to show that $e^z$ never vanishes on the unit disk,Use Rouche's theorem to show that  never vanishes on the unit disk,e^z,"Use Rouche's theorem to show that $e^z$ cannot vanish on the unit disk. Generally, in applications of Rouche's theorem, if I was trying to prove $f$ had a certain number of zeros in the unit disk, I would find holomorphic functions $g$ and $h$ such that $g + h = f$, show that $|g| > |h|$ on the unit circle, and then conclude that $f$ had the same number of 0's as $g$. However, I 'm not sure what functions $g$ and $h$ I would use, in this case... I know that $e^z = e^x \cos y + ie^x \sin y$, but I can't show that either one of those terms is bounded by the other on the unit circle. Am I missing something, or should I be applying Rouche's theorem in a different way?","Use Rouche's theorem to show that $e^z$ cannot vanish on the unit disk. Generally, in applications of Rouche's theorem, if I was trying to prove $f$ had a certain number of zeros in the unit disk, I would find holomorphic functions $g$ and $h$ such that $g + h = f$, show that $|g| > |h|$ on the unit circle, and then conclude that $f$ had the same number of 0's as $g$. However, I 'm not sure what functions $g$ and $h$ I would use, in this case... I know that $e^z = e^x \cos y + ie^x \sin y$, but I can't show that either one of those terms is bounded by the other on the unit circle. Am I missing something, or should I be applying Rouche's theorem in a different way?",,['complex-analysis']
95,Singular points and residues,Singular points and residues,,"In each case write the principal part of the function at its isolated   singular point and determine whether that point is a pole, a removable   singular point, or an essential singular point. i)$f(z)=ze^\frac{1}{z}$   ii)$f(z)=\frac{z^2}{1+z}$   iii)$f(z)=\frac{\sin z}{z}$ iv)$f(z)=\frac{\cos z}{z}$   v)$f(z)=\frac{1}{(2-z)^3}$ What I did i)$$f(z)=ze^\frac{1}{z}=z\sum_{n=0}^\infty\frac{1}{n!z^n}=\sum_{n=0}^\infty\frac{1}{n!z^{n-1}}$$ $$=z+1+\frac{1}{2!z}+\frac{1}{3!z^2}+\frac{1}{4!z^3}+...\frac{1}{m!z^{m-1}}+\sum_{n=m}^\infty \frac{1}{n!z^{n-1}}$$ then $z_0=0$ is an essential singular point. ii)$$lim_{z\rightarrow -1}(z+1)\frac{z^2}{z+1}=lim_{z\rightarrow -1}z^2=1$$ then $z_0=-1$ is a simple pole and $Res(f;z_0)=1$ iii)$$lim_{z\rightarrow 0}(z-0)\frac{\sin z}{z}=lim_{z\rightarrow 0}\sin z=0$$ then $z_0=0$ is a removable singular point and $Res(f;z_0)=0$ iv)$$lim_{z\rightarrow 0}(z-0)\frac{\cos z}{z}=lim_{z\rightarrow 0}\cos z=1$$ then $z_0=0$ is a simple pole and $Res(f;z_0)=1$ v)$$lim_{z\rightarrow 2}(z-2)^2\frac{1}{(z-2)^2}=1$$ then $z_0=2$ is a pole of order 2 some wrong?","In each case write the principal part of the function at its isolated   singular point and determine whether that point is a pole, a removable   singular point, or an essential singular point. i)$f(z)=ze^\frac{1}{z}$   ii)$f(z)=\frac{z^2}{1+z}$   iii)$f(z)=\frac{\sin z}{z}$ iv)$f(z)=\frac{\cos z}{z}$   v)$f(z)=\frac{1}{(2-z)^3}$ What I did i)$$f(z)=ze^\frac{1}{z}=z\sum_{n=0}^\infty\frac{1}{n!z^n}=\sum_{n=0}^\infty\frac{1}{n!z^{n-1}}$$ $$=z+1+\frac{1}{2!z}+\frac{1}{3!z^2}+\frac{1}{4!z^3}+...\frac{1}{m!z^{m-1}}+\sum_{n=m}^\infty \frac{1}{n!z^{n-1}}$$ then $z_0=0$ is an essential singular point. ii)$$lim_{z\rightarrow -1}(z+1)\frac{z^2}{z+1}=lim_{z\rightarrow -1}z^2=1$$ then $z_0=-1$ is a simple pole and $Res(f;z_0)=1$ iii)$$lim_{z\rightarrow 0}(z-0)\frac{\sin z}{z}=lim_{z\rightarrow 0}\sin z=0$$ then $z_0=0$ is a removable singular point and $Res(f;z_0)=0$ iv)$$lim_{z\rightarrow 0}(z-0)\frac{\cos z}{z}=lim_{z\rightarrow 0}\cos z=1$$ then $z_0=0$ is a simple pole and $Res(f;z_0)=1$ v)$$lim_{z\rightarrow 2}(z-2)^2\frac{1}{(z-2)^2}=1$$ then $z_0=2$ is a pole of order 2 some wrong?",,"['complex-analysis', 'complex-numbers', 'residue-calculus']"
96,Is it so easy to show a locally bounded function with holomorphic cross sections is holomorphic?,Is it so easy to show a locally bounded function with holomorphic cross sections is holomorphic?,,"Let $f: U \rightarrow \mathbb{C}$ where $U$ is open in $\mathbb{C}^n$ and suppose every coordinate cross section of $f$ is holomorphic (I hope that's not too colloquial). I've heard it's a somewhat deep theorem that this is enough to imply f is continuous, and therefore holomorphic as a function of n variables.  However when one uses Cauchy's formula (in one variable) to get a power series expansion of $f$ in a neighborhood of a point, one seems only to use that $f$ is locally bounded (so one can bound the values of f on the distinguished boundary of a polydisc). Is that correct? I.e. does {locally bounded} + {holomorphic cross sections} so easily imply holomorphic or have I made a mistake?","Let $f: U \rightarrow \mathbb{C}$ where $U$ is open in $\mathbb{C}^n$ and suppose every coordinate cross section of $f$ is holomorphic (I hope that's not too colloquial). I've heard it's a somewhat deep theorem that this is enough to imply f is continuous, and therefore holomorphic as a function of n variables.  However when one uses Cauchy's formula (in one variable) to get a power series expansion of $f$ in a neighborhood of a point, one seems only to use that $f$ is locally bounded (so one can bound the values of f on the distinguished boundary of a polydisc). Is that correct? I.e. does {locally bounded} + {holomorphic cross sections} so easily imply holomorphic or have I made a mistake?",,"['complex-analysis', 'analysis', 'several-complex-variables']"
97,"Complex analysis, find the residue","Complex analysis, find the residue",,"Find the residue of $f(z)=\frac{1}{z^2\sin z}$ at $z_0=0$ What I tried Let $g(z)=1$ and $h(z)=z^2\sin z$, both are analytics but they have zeros of different orders then $f(z)$ don't have removable singularity point at $z_0$ Then I tried to use the fact that if $lim_{z\rightarrow z_0}(z-z_0)^kf(z)$ exists, then $f(z)$ have pole of order $k$ at $z_0$, but I'm stuck on this, because if for example I take $k=2$ $$lim_{z\rightarrow z_0}(z-0)^2\frac{1}{z^2\sin z}=lim_{z\rightarrow z_0}\frac{1}{\sin z}=\infty$$ Maybe I need to do some transformation in the function, but I can not see such a transformation.","Find the residue of $f(z)=\frac{1}{z^2\sin z}$ at $z_0=0$ What I tried Let $g(z)=1$ and $h(z)=z^2\sin z$, both are analytics but they have zeros of different orders then $f(z)$ don't have removable singularity point at $z_0$ Then I tried to use the fact that if $lim_{z\rightarrow z_0}(z-z_0)^kf(z)$ exists, then $f(z)$ have pole of order $k$ at $z_0$, but I'm stuck on this, because if for example I take $k=2$ $$lim_{z\rightarrow z_0}(z-0)^2\frac{1}{z^2\sin z}=lim_{z\rightarrow z_0}\frac{1}{\sin z}=\infty$$ Maybe I need to do some transformation in the function, but I can not see such a transformation.",,"['complex-analysis', 'complex-numbers', 'residue-calculus']"
98,existence of holomorphic functions,existence of holomorphic functions,,Let $D$ = { $z \epsilon \Bbb C :|z|<1$ } .   Then there exists a holomorphic function $f:D\to \overline D$ with $f(0)=0$ with the property a) $f'(0)={1\over 2}$ b) $|f(1/3)|={1\over 4}$ c) $f(1/3)={1\over 2}$ d) $|f'(0)|=\sec(\pi/6)$ when $f(z)={1\over 2}z$ then $a)$ is true when $f(z)={1\over 4}$ then $b)$ is true To solve the problem do we've to take such examples?Or is there any other way?,Let = { } .   Then there exists a holomorphic function with with the property a) b) c) d) when then is true when then is true To solve the problem do we've to take such examples?Or is there any other way?,D z \epsilon \Bbb C :|z|<1 f:D\to \overline D f(0)=0 f'(0)={1\over 2} |f(1/3)|={1\over 4} f(1/3)={1\over 2} |f'(0)|=\sec(\pi/6) f(z)={1\over 2}z a) f(z)={1\over 4} b),['complex-analysis']
99,"Prove without Liouville's theorem: $f$ is entire, $\forall z \in \mathbb C: |f(z)| \leq |z|$, then $f=a \cdot z$, $a \in \mathbb C, |a| \leq 1$","Prove without Liouville's theorem:  is entire, , then ,","f \forall z \in \mathbb C: |f(z)| \leq |z| f=a \cdot z a \in \mathbb C, |a| \leq 1","Prove without Liouville's theorem: $f$ is entire, $\forall z \in \mathbb C: |f(z)| \leq |z|$, then $f=a \cdot z$, $a \in \mathbb C, |a| \leq 1$ What I tried so far: $f$ is entire, so $f(z)= \Sigma _{n=0}^\infty a_nz^n$, and then $|\Sigma _{n=0}^\infty a_nz^n| \leq |z| \Rightarrow |\frac {\Sigma _{n=0}^\infty a_nz^n}{z}| \leq 1 \Rightarrow |\Sigma _{n=0}^\infty a_nz^{n-1}| \leq 1$ How can I continue from here? Thank you in advance for your assistance!","Prove without Liouville's theorem: $f$ is entire, $\forall z \in \mathbb C: |f(z)| \leq |z|$, then $f=a \cdot z$, $a \in \mathbb C, |a| \leq 1$ What I tried so far: $f$ is entire, so $f(z)= \Sigma _{n=0}^\infty a_nz^n$, and then $|\Sigma _{n=0}^\infty a_nz^n| \leq |z| \Rightarrow |\frac {\Sigma _{n=0}^\infty a_nz^n}{z}| \leq 1 \Rightarrow |\Sigma _{n=0}^\infty a_nz^{n-1}| \leq 1$ How can I continue from here? Thank you in advance for your assistance!",,['complex-analysis']
