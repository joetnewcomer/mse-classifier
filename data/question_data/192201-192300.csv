,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Prove $g(x)=\frac{f(x)-f(a)}{x-a}$ is increasing,Prove  is increasing,g(x)=\frac{f(x)-f(a)}{x-a},"Let $f:\mathbb{R}\rightarrow \mathbb{R}$ be a differentiable function such that $f'$ is increasing. Setting $a\in\mathbb{R}$, prove: the function $g(x)=\frac{f(x)-f(a)}{x-a}$ is also an increasing function on $(a,\infty)$ and $(-\infty,a)$ My thoughts: By MVT: $\exists c\in(a,x_0) \ s.t. f'(c)=\frac{f(x_0)-f(a)}{x-a}, \ \exists d\in(x_0,x_1) \ s.t. \ f'(d)=\frac{f(x_1)-f(x_0)}{x_1-x_0}$ $d>c \Rightarrow f'(d)\geq f'(c)$ Now I got stuck since I couldn't show $\frac{f(x_1)-f(a)}{x_1-a} \geq \frac{f(x_1)-f(x_0)}{x_1-x_0}$. Any help appreciated.","Let $f:\mathbb{R}\rightarrow \mathbb{R}$ be a differentiable function such that $f'$ is increasing. Setting $a\in\mathbb{R}$, prove: the function $g(x)=\frac{f(x)-f(a)}{x-a}$ is also an increasing function on $(a,\infty)$ and $(-\infty,a)$ My thoughts: By MVT: $\exists c\in(a,x_0) \ s.t. f'(c)=\frac{f(x_0)-f(a)}{x-a}, \ \exists d\in(x_0,x_1) \ s.t. \ f'(d)=\frac{f(x_1)-f(x_0)}{x_1-x_0}$ $d>c \Rightarrow f'(d)\geq f'(c)$ Now I got stuck since I couldn't show $\frac{f(x_1)-f(a)}{x_1-a} \geq \frac{f(x_1)-f(x_0)}{x_1-x_0}$. Any help appreciated.",,"['calculus', 'derivatives']"
1,Prove $f^\ {''}(c)=0$,Prove,f^\ {''}(c)=0,"Let $f:\mathbb{R} \rightarrow\mathbb{R}$ be twice differentiable and bounded, and suppose $f$ gets minimum at $x_0$. Prove there exists $c\in\mathbb{R}$ such that $f^\ {''}(c)=0$. $f$ is bounded $\Rightarrow \exists M>0 \ s.t \ |f(x)|\leq M, \forall x\in\mathbb{R}$ So by MVT I got that the derivative is positive for all $x>x_0$ and negative for all $x<x_0$, and from that I concluded that $f(x)\rightarrow M$ when $x\rightarrow\pm\infty$. Not sure how to continue from here. Any help appreciated.","Let $f:\mathbb{R} \rightarrow\mathbb{R}$ be twice differentiable and bounded, and suppose $f$ gets minimum at $x_0$. Prove there exists $c\in\mathbb{R}$ such that $f^\ {''}(c)=0$. $f$ is bounded $\Rightarrow \exists M>0 \ s.t \ |f(x)|\leq M, \forall x\in\mathbb{R}$ So by MVT I got that the derivative is positive for all $x>x_0$ and negative for all $x<x_0$, and from that I concluded that $f(x)\rightarrow M$ when $x\rightarrow\pm\infty$. Not sure how to continue from here. Any help appreciated.",,"['calculus', 'derivatives']"
2,I've found the fractional-ordered derivative operator,I've found the fractional-ordered derivative operator,,"I've been thinking about it since yesterday and have noticed this pattern: We have, the first order derivative of a function $f(x)$ is: $$f'(x)=\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h} .......(1)$$ The second order derivative of the same function is: $$f''(x)=\lim_{h\rightarrow 0}\frac{f'(x+h)-f'(x)}{h}$$ By putting $x=x+h$ in (1), we can have $f'(x+h)$. So,$$f''(x)=\lim_{h\rightarrow 0}\frac{\lim_{h\rightarrow 0}\frac{f(x+h+h)-f(x+h)}{h}-\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}}{h}$$ Or , $$f''(x)=\lim_{h\rightarrow 0}\frac{f(x+2h)-2f(x+h)+f(x)}{h^2}.....(2)$$ You can check by L'Hospital's rule that this limit evaluates to $f''(x)$. Now, the third order derivative of the same function is: $$f'''(x)=\lim_{h\rightarrow 0}\frac{f''(x+h)-f''(x)}{h}$$ By putting $x=x+h$ in (2), we can get $f''(x+h)$. So, $$f'''(x)=\lim_{h\rightarrow 0}\frac{\lim_{h\rightarrow 0}\frac{f(x+3h)-2f(x+2h)+f(x+h)}{h^2}-\lim_{h\rightarrow 0}\frac{f(x+2h)-2f(x+h)+f(x)}{h^2}}{h}$$ which gives $$f'''(x)=\lim_{h\rightarrow 0} \frac{f(x+3h)-3f(x+2h)+3f(x+h)-f(x)}{h^3}......(3)$$ Again, by repeating the same process, we can get that: $$f''''(x)=\lim_{h\rightarrow 0}\frac{f(x+4h)-4f(x+3h)+6f(x+2h)-4f(x+h)+f(x)}{h^4}....(4)$$ So, we observe that the coefficient of $f(x+(n-r)h)$ in the expression of $f^{n}(x)$ ($n^{th}$ derivative of $f(x)$) is actually $(-1)^{r}\cdot {^n}C_r$, same as the coefficient of $x^{n-r}$ in the expansion of $(x-1)^n$. It can be proved that: $$f^n(x)=\lim_{h\rightarrow 0}\frac{\sum_{r=0}^n(-1)^{r}\cdot ^{n}C_r\cdot f(x+(n-r)h)}{h^n}$$ where $f^n(x)$ is the $n^{th}$ order derivative of the function $f(x)$. Now, to generalize this to fractional order derivatives, we just have to generalize the coefficients, which must be similar to the generalization of the expansion of $(x-1)^n$ to fractional exponents. I'm not very good with binomial theorem, but I guess that it should be: $$f^n(x)=\lim_{h\rightarrow 0}\frac{f(x+nh)-n\cdot f(x+(n-1)h)+\frac{n(n-1)}{2!}\cdot f(x+(n-2)h)-....}{h^n}$$ , where $n$ can be fractional. Have I done anything wrong? UPDATE: A lot of people are saying that my method to get the expressions of $f''(x)$, $f'''(x)$, $f''''(x)$, etc are wrong. I've checked by L'Hospital's rule that the results are correct. Could you please write an answer about getting to these results by using a correct method? UPDATE: On second thoughts, the $n^{th}$ derivative of a function can also proved to be equal to: $$\lim_{h\rightarrow 0^+}\frac{\sum_{r=0}^{n}(-1)^r\cdot \binom{n}{r}\cdot f(x-(n-r)h)}{(-h)^n}$$ If we try to expand this to fractions, it can turn out to be imaginary because of the fractional power of $-1$ in the denominator.","I've been thinking about it since yesterday and have noticed this pattern: We have, the first order derivative of a function $f(x)$ is: $$f'(x)=\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h} .......(1)$$ The second order derivative of the same function is: $$f''(x)=\lim_{h\rightarrow 0}\frac{f'(x+h)-f'(x)}{h}$$ By putting $x=x+h$ in (1), we can have $f'(x+h)$. So,$$f''(x)=\lim_{h\rightarrow 0}\frac{\lim_{h\rightarrow 0}\frac{f(x+h+h)-f(x+h)}{h}-\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}}{h}$$ Or , $$f''(x)=\lim_{h\rightarrow 0}\frac{f(x+2h)-2f(x+h)+f(x)}{h^2}.....(2)$$ You can check by L'Hospital's rule that this limit evaluates to $f''(x)$. Now, the third order derivative of the same function is: $$f'''(x)=\lim_{h\rightarrow 0}\frac{f''(x+h)-f''(x)}{h}$$ By putting $x=x+h$ in (2), we can get $f''(x+h)$. So, $$f'''(x)=\lim_{h\rightarrow 0}\frac{\lim_{h\rightarrow 0}\frac{f(x+3h)-2f(x+2h)+f(x+h)}{h^2}-\lim_{h\rightarrow 0}\frac{f(x+2h)-2f(x+h)+f(x)}{h^2}}{h}$$ which gives $$f'''(x)=\lim_{h\rightarrow 0} \frac{f(x+3h)-3f(x+2h)+3f(x+h)-f(x)}{h^3}......(3)$$ Again, by repeating the same process, we can get that: $$f''''(x)=\lim_{h\rightarrow 0}\frac{f(x+4h)-4f(x+3h)+6f(x+2h)-4f(x+h)+f(x)}{h^4}....(4)$$ So, we observe that the coefficient of $f(x+(n-r)h)$ in the expression of $f^{n}(x)$ ($n^{th}$ derivative of $f(x)$) is actually $(-1)^{r}\cdot {^n}C_r$, same as the coefficient of $x^{n-r}$ in the expansion of $(x-1)^n$. It can be proved that: $$f^n(x)=\lim_{h\rightarrow 0}\frac{\sum_{r=0}^n(-1)^{r}\cdot ^{n}C_r\cdot f(x+(n-r)h)}{h^n}$$ where $f^n(x)$ is the $n^{th}$ order derivative of the function $f(x)$. Now, to generalize this to fractional order derivatives, we just have to generalize the coefficients, which must be similar to the generalization of the expansion of $(x-1)^n$ to fractional exponents. I'm not very good with binomial theorem, but I guess that it should be: $$f^n(x)=\lim_{h\rightarrow 0}\frac{f(x+nh)-n\cdot f(x+(n-1)h)+\frac{n(n-1)}{2!}\cdot f(x+(n-2)h)-....}{h^n}$$ , where $n$ can be fractional. Have I done anything wrong? UPDATE: A lot of people are saying that my method to get the expressions of $f''(x)$, $f'''(x)$, $f''''(x)$, etc are wrong. I've checked by L'Hospital's rule that the results are correct. Could you please write an answer about getting to these results by using a correct method? UPDATE: On second thoughts, the $n^{th}$ derivative of a function can also proved to be equal to: $$\lim_{h\rightarrow 0^+}\frac{\sum_{r=0}^{n}(-1)^r\cdot \binom{n}{r}\cdot f(x-(n-r)h)}{(-h)^n}$$ If we try to expand this to fractions, it can turn out to be imaginary because of the fractional power of $-1$ in the denominator.",,"['calculus', 'derivatives']"
3,"Finding a $w\in\Bbb{R}^2$ fulfilling $dX|_pw=(x,y,0)^T$, $X$ a parameterization for $S^2$ and $p$ the north pole","Finding a  fulfilling ,  a parameterization for  and  the north pole","w\in\Bbb{R}^2 dX|_pw=(x,y,0)^T X S^2 p","Let $S^2$ be the unit sphere in $\Bbb{R}^3$. It is a regular surface. Let $\phi:S^2\rightarrow S^2$ be the reflection function, $p=(0,0,1)$ the north pole on the sphere, and $v=(x,y,0)^T$ a vector in the tangent plane $T_p S^2$ (which is the $XY$ plane). I need to show that $d\phi |_p (v)=-v$. For that, I use the definition: $d\phi|_p (v)=d(\phi \circ X)|_{X^{-1}(p)}(w)$ when $w\in\Bbb{R}^2$ is a vector fulfilling $dX|_p(w)=v$ (there exists one, from the definition on a tangent plane) and $X:U\subset\mathbb{R}^2\rightarrow S^2$ a parameterization of $S^2$. My problem was in finding $w$. If I take $X(\theta,\phi)=(\cos\phi\sin\theta,\sin\phi\sin\theta,\cos\theta)$, then $X^{-1}(p)=(\theta=0,\phi)$.  $\phi$ is general, because it can be anything, right? Now, I want to find a $w$ such that $dX|_{(\theta=0,\phi)}w=(x,y,0)^T$. But $$dX|_{(\theta=0,\phi)}=\begin{pmatrix}         \cos\phi & 0 \\         \sin\phi & 0  \\         0 & 0  \\         \end{pmatrix}$$ So $dX|_{(\theta=0,\phi)}\begin{pmatrix}         w_1 \\         w_2  \\         \end{pmatrix}=\begin{pmatrix}          w_1 \cos\phi\\         w_1  \sin\phi\\ 0\\         \end{pmatrix}$ which can't be equal to $\begin{pmatrix}          x\\         y\\ 0\\         \end{pmatrix}$ with general $x,y\in\Bbb{R}$ unless we add $\phi$ as a variable, which is wierd because it shouldn't influence the answer. Note: if I ignore the fact I can't find $w$ and treat it as just a vector fulfilling $dX|_{(\theta=0,\phi)}w=(x,y,0)^T$, I can prove the statement easily. However, it really bothered me that I couldn't find $w$, even though it is not crucial for this very question.","Let $S^2$ be the unit sphere in $\Bbb{R}^3$. It is a regular surface. Let $\phi:S^2\rightarrow S^2$ be the reflection function, $p=(0,0,1)$ the north pole on the sphere, and $v=(x,y,0)^T$ a vector in the tangent plane $T_p S^2$ (which is the $XY$ plane). I need to show that $d\phi |_p (v)=-v$. For that, I use the definition: $d\phi|_p (v)=d(\phi \circ X)|_{X^{-1}(p)}(w)$ when $w\in\Bbb{R}^2$ is a vector fulfilling $dX|_p(w)=v$ (there exists one, from the definition on a tangent plane) and $X:U\subset\mathbb{R}^2\rightarrow S^2$ a parameterization of $S^2$. My problem was in finding $w$. If I take $X(\theta,\phi)=(\cos\phi\sin\theta,\sin\phi\sin\theta,\cos\theta)$, then $X^{-1}(p)=(\theta=0,\phi)$.  $\phi$ is general, because it can be anything, right? Now, I want to find a $w$ such that $dX|_{(\theta=0,\phi)}w=(x,y,0)^T$. But $$dX|_{(\theta=0,\phi)}=\begin{pmatrix}         \cos\phi & 0 \\         \sin\phi & 0  \\         0 & 0  \\         \end{pmatrix}$$ So $dX|_{(\theta=0,\phi)}\begin{pmatrix}         w_1 \\         w_2  \\         \end{pmatrix}=\begin{pmatrix}          w_1 \cos\phi\\         w_1  \sin\phi\\ 0\\         \end{pmatrix}$ which can't be equal to $\begin{pmatrix}          x\\         y\\ 0\\         \end{pmatrix}$ with general $x,y\in\Bbb{R}$ unless we add $\phi$ as a variable, which is wierd because it shouldn't influence the answer. Note: if I ignore the fact I can't find $w$ and treat it as just a vector fulfilling $dX|_{(\theta=0,\phi)}w=(x,y,0)^T$, I can prove the statement easily. However, it really bothered me that I couldn't find $w$, even though it is not crucial for this very question.",,"['derivatives', 'differential-geometry']"
4,Approximation of $e^x$,Approximation of,e^x,"I was working on the approximation of $y=$ $e^x$ at $x=x_2$ in terms of its known value at a neighbour point $x=x_1$. Approximation by derivatives gives us this:  $y_2$ =$e^{x_2}=e^{x_1}+(x_2-x_1)e^{x_1}$=$y_1+(x_2-x_1)y_1$ I was trying to get something even more accurate and I've come up with this: $lny_2$= $x_1(\frac{lnx_2}{lnx_1})^{lnx_1}$  where $lnx$ is the natural logarithm. I've checked that this one is more accurate. It's less accurate than the derivative formula for $x_1=1,2,3$ but for higher $x_1>3$, it gives a better approximation. 1. Is my formula some special case of some already discovered approximation rule or have I come up with something new? 2. Is it useless? I've derived approximations of other functions also but the one for $e^x$ was the least messy. Update: I just checked that it's more accurate even when $x_1=3$. By taking $x_1=3$, I tried approximating $e^{3.5}$. The actual value is 33.1. The derivative approximation gave 30.11 and my formula gave 31.98. For somewhat large $x$, it is far better than the derivative. Try approximating $e^{12}$ by taking $x_1=10$ by derivative and by my method. Update:Oh, I just figured out that my formula is equivalent to saying $x_2$=$x_1(\frac{lnx_2}{lnx_1})^{lnx_1}$  , where $x_1$ and $x_2$ are any two neighbouring numbers. So, I think it's useless then. But still is it a new relation between two neighbouring numbers and their logarithms?.","I was working on the approximation of $y=$ $e^x$ at $x=x_2$ in terms of its known value at a neighbour point $x=x_1$. Approximation by derivatives gives us this:  $y_2$ =$e^{x_2}=e^{x_1}+(x_2-x_1)e^{x_1}$=$y_1+(x_2-x_1)y_1$ I was trying to get something even more accurate and I've come up with this: $lny_2$= $x_1(\frac{lnx_2}{lnx_1})^{lnx_1}$  where $lnx$ is the natural logarithm. I've checked that this one is more accurate. It's less accurate than the derivative formula for $x_1=1,2,3$ but for higher $x_1>3$, it gives a better approximation. 1. Is my formula some special case of some already discovered approximation rule or have I come up with something new? 2. Is it useless? I've derived approximations of other functions also but the one for $e^x$ was the least messy. Update: I just checked that it's more accurate even when $x_1=3$. By taking $x_1=3$, I tried approximating $e^{3.5}$. The actual value is 33.1. The derivative approximation gave 30.11 and my formula gave 31.98. For somewhat large $x$, it is far better than the derivative. Try approximating $e^{12}$ by taking $x_1=10$ by derivative and by my method. Update:Oh, I just figured out that my formula is equivalent to saying $x_2$=$x_1(\frac{lnx_2}{lnx_1})^{lnx_1}$  , where $x_1$ and $x_2$ are any two neighbouring numbers. So, I think it's useless then. But still is it a new relation between two neighbouring numbers and their logarithms?.",,['derivatives']
5,n th derivative of complex exponential,n th derivative of complex exponential,,How to find $n $ th derivative of complex exponential \begin{align*} \frac{d^{n}}{dx^{n}}e^{ix^2/(2a)} \end{align*}  One method is series soultion. I want a formula which works faster in my programme. Please help me.,How to find $n $ th derivative of complex exponential \begin{align*} \frac{d^{n}}{dx^{n}}e^{ix^2/(2a)} \end{align*}  One method is series soultion. I want a formula which works faster in my programme. Please help me.,,"['derivatives', 'exponential-function']"
6,Is a function strictly increasing if its derivative is positive at all point but critical points?,Is a function strictly increasing if its derivative is positive at all point but critical points?,,"$f: (a,b) \to \Bbb{R}$ is differentiable and $f'(x)>0$ at all points but at $c$ where $f'(c) = 0$. I need to prove that $f$ is strictly increasing. I thought to split the intervals to $(a,c)$ and $(c,b)$ and use the continuity of $f$ at $c$, but I'm not sure how to explain that. More generally, I understand that this is true for a finite number of critical points, how do I explain that too? Help please","$f: (a,b) \to \Bbb{R}$ is differentiable and $f'(x)>0$ at all points but at $c$ where $f'(c) = 0$. I need to prove that $f$ is strictly increasing. I thought to split the intervals to $(a,c)$ and $(c,b)$ and use the continuity of $f$ at $c$, but I'm not sure how to explain that. More generally, I understand that this is true for a finite number of critical points, how do I explain that too? Help please",,['derivatives']
7,Evaluate $f^{2016}(0)$ for the function $f(x)=x^2 \ln(x+1)$,Evaluate  for the function,f^{2016}(0) f(x)=x^2 \ln(x+1),"Question: Evaluate $f^{2016}(0)$ for the function $f(x)=x^2 \ln(x+1)$ Background: I know we can use taylor/mclaurin/power series to solve this but these were not teached to me by my teacher and not part of the syllabus so we are required to find the $nth$ derivative and make a suitable observation and hence evaluate the function. One thing I wasn't sure about was to make a new post or edit my old post asking the part of the question . So if someone could clarify that for me , it would be great for the future. My attempt (for $n\geq 3$ I have used partial fractions decomposition but I have not showed the working): $$f^{(0)}(x)=x^2 \ln(x+1)$$ $$f^{(1)}(x)= 2x\ln(x+1) + \frac{x^2}{x+1} $$ $$f^{(2)}(x)=2\ln(x+1) + \frac{4x}{x+1} - \frac{x^2}{(x+1)^2}$$ $$f^{(3)}(x)=\frac{2}{(x+1)}+\frac{2}{(x+1)^2}+\frac{2}{(x+1)^3}$$ $$f^{(4)}(x)=-\frac{2}{(x+1)^2}-\frac{6}{(x+1)^3}-\frac{8}{(x+1)^4} $$ $$f^{(5)}(x)=\frac{4}{(x+1)^3}+\frac{12}{(x+1)^4}+\frac{24}{(x+1)^5}$$ From here I can see that for $n\geq3$ we have: $$ f^{(n)}(x)=(-1)^{n-1} \left[ \frac{2(n-3)!}{(x+1)^{n-2}} + \frac{2(n-2)!}{(x+1)^{n-1}} + \frac{(n-1)!}{(x+1)^n} \right]$$ (it doesn't work for $n <3$ since we can't have a negative factorial) Now evaluating this at zero for the $2016$th derivative: $$ f^{(2016)}(0)=(-1)^{2015} \left[ 2(2013)!+2(2014)!+2015! \right]$$ $$ \Longrightarrow f^{(2016)}(0)=(-1) \left[ 2(2013)!+2(2014)!+2015! \right]$$ Would this be correct?","Question: Evaluate $f^{2016}(0)$ for the function $f(x)=x^2 \ln(x+1)$ Background: I know we can use taylor/mclaurin/power series to solve this but these were not teached to me by my teacher and not part of the syllabus so we are required to find the $nth$ derivative and make a suitable observation and hence evaluate the function. One thing I wasn't sure about was to make a new post or edit my old post asking the part of the question . So if someone could clarify that for me , it would be great for the future. My attempt (for $n\geq 3$ I have used partial fractions decomposition but I have not showed the working): $$f^{(0)}(x)=x^2 \ln(x+1)$$ $$f^{(1)}(x)= 2x\ln(x+1) + \frac{x^2}{x+1} $$ $$f^{(2)}(x)=2\ln(x+1) + \frac{4x}{x+1} - \frac{x^2}{(x+1)^2}$$ $$f^{(3)}(x)=\frac{2}{(x+1)}+\frac{2}{(x+1)^2}+\frac{2}{(x+1)^3}$$ $$f^{(4)}(x)=-\frac{2}{(x+1)^2}-\frac{6}{(x+1)^3}-\frac{8}{(x+1)^4} $$ $$f^{(5)}(x)=\frac{4}{(x+1)^3}+\frac{12}{(x+1)^4}+\frac{24}{(x+1)^5}$$ From here I can see that for $n\geq3$ we have: $$ f^{(n)}(x)=(-1)^{n-1} \left[ \frac{2(n-3)!}{(x+1)^{n-2}} + \frac{2(n-2)!}{(x+1)^{n-1}} + \frac{(n-1)!}{(x+1)^n} \right]$$ (it doesn't work for $n <3$ since we can't have a negative factorial) Now evaluating this at zero for the $2016$th derivative: $$ f^{(2016)}(0)=(-1)^{2015} \left[ 2(2013)!+2(2014)!+2015! \right]$$ $$ \Longrightarrow f^{(2016)}(0)=(-1) \left[ 2(2013)!+2(2014)!+2015! \right]$$ Would this be correct?",,"['derivatives', 'factorial']"
8,Calculus: Sketching a Graph that satisfies the following conditions (I),Calculus: Sketching a Graph that satisfies the following conditions (I),,"I have to sketch a graph that satisfies the conditions: A. $f(2)=f(4)=0$ B. $f'(x)\lt0$ if $x\lt3$ C. $f'(3)$ does not exist D. $f'(x) \gt 0$ if $x \gt 3$ E. $f''(x) \lt 0$,$x\ne 3$ I am a bit stuck on how to tell if the second derivative is always negative from a graph?  I know that there is a sharp turn at $x=3$, and there is also a minimum there but the second derivative part trips me up.","I have to sketch a graph that satisfies the conditions: A. $f(2)=f(4)=0$ B. $f'(x)\lt0$ if $x\lt3$ C. $f'(3)$ does not exist D. $f'(x) \gt 0$ if $x \gt 3$ E. $f''(x) \lt 0$,$x\ne 3$ I am a bit stuck on how to tell if the second derivative is always negative from a graph?  I know that there is a sharp turn at $x=3$, and there is also a minimum there but the second derivative part trips me up.",,"['calculus', 'derivatives']"
9,"Total differentiability of $f(\left\lVert (x,y) \right\rVert)$ with $f: [0,+ \infty) \to \mathbb{R}$",Total differentiability of  with,"f(\left\lVert (x,y) \right\rVert) f: [0,+ \infty) \to \mathbb{R}","I have trouble answering the following question: ""Let $f: [0,+ \infty) \to \mathbb{R}$ be a function and consider the function $g: \mathbb{R}^2 \to \mathbb{R}: (x,y) \mapsto f(\left\lVert (x,y) \right\rVert)$. Give a necessary and sufficient condition on $f$ such that $g$ is totally differentiable."" I have tried to solve this and thought a good condition could be that $f$ is differentiable (I don't know if it is correct, though). For the sufficiency of this condition, I have the following. Since $\mathbb{R}^2 \to \mathbb{R}: (x,y) \mapsto \left\lVert (x,y) \right\rVert$ is totally differentiable on $\mathbb{R}^2 \backslash \left\{(0,0)\right\}$, the chain rule gives us that $g$ is totally differentiable on $\mathbb{R}^2 \backslash \left\{(0,0)\right\}$. But then I don't know why $g$ would also be totally differentiable in $(0,0)$... For the necessity of the condition, I don't know why total differentiability of $g$ would imply differentiability of $f$... Thanks in advance for any help.","I have trouble answering the following question: ""Let $f: [0,+ \infty) \to \mathbb{R}$ be a function and consider the function $g: \mathbb{R}^2 \to \mathbb{R}: (x,y) \mapsto f(\left\lVert (x,y) \right\rVert)$. Give a necessary and sufficient condition on $f$ such that $g$ is totally differentiable."" I have tried to solve this and thought a good condition could be that $f$ is differentiable (I don't know if it is correct, though). For the sufficiency of this condition, I have the following. Since $\mathbb{R}^2 \to \mathbb{R}: (x,y) \mapsto \left\lVert (x,y) \right\rVert$ is totally differentiable on $\mathbb{R}^2 \backslash \left\{(0,0)\right\}$, the chain rule gives us that $g$ is totally differentiable on $\mathbb{R}^2 \backslash \left\{(0,0)\right\}$. But then I don't know why $g$ would also be totally differentiable in $(0,0)$... For the necessity of the condition, I don't know why total differentiability of $g$ would imply differentiability of $f$... Thanks in advance for any help.",,"['real-analysis', 'derivatives']"
10,Discrepancy in differentiating: $y=\tan^{-1}\left(\frac{\sqrt{1+\sin{x}}+\sqrt{1-\sin{x}}}{\sqrt{1+\sin{x}}-\sqrt{1-\sin{x}}}\right)$,Discrepancy in differentiating:,y=\tan^{-1}\left(\frac{\sqrt{1+\sin{x}}+\sqrt{1-\sin{x}}}{\sqrt{1+\sin{x}}-\sqrt{1-\sin{x}}}\right),"$$y=\tan^{-1}\left(\frac{\sqrt{1+\sin{x}}+\sqrt{1-\sin{x}}}{\sqrt{1+\sin{x}}-\sqrt{1-\sin{x}}}\right)$$ $$\sqrt{1+\sin{x}}=\sin{\frac{x}{2}}+\cos{\frac{x}{2}}$$ $$\sqrt{1-\sin{x}}=\sin{\frac{x}{2}}-\cos{\frac{x}{2}}$$ $$y=\tan^{-1}\left(\tan{\frac{x}{2}}\right)$$Differentiating, we get: $$\frac{dy}{dx}=\frac{1}{2}$$ But taking: $$\sqrt{1-\sin{x}}=\cos{\frac{x}{2}}-\sin{\frac{x}{2}}$$ $$y=\tan^{-1}\left(\cot{\frac{x}{2}}\right)$$ Differentiating, we get: $$\frac{dy}{dx}=\frac{-1}{2}$$ I figured that I needed to use absolute value for the simplification of $\sqrt{1-\sin{x}}$, i.e. $\sqrt{1-\sin{x}}=\left|\sin{\frac{x}{2}}-\cos{\frac{x}{2}}\right|$. Subsequently, I put the below functions into Wolfram Alpha's input box to differentiate: $$y_1=\tan^{-1}\left(\frac{\sqrt{1+\sin{x}}+\sqrt{1-\sin{x}}}{\sqrt{1+\sin{x}}-\sqrt{1-\sin{x}}}\right)$$ And $$y_2=\tan^{-1}\left(\frac{\left|\sin{\frac{x}{2}}+\cos{\frac{x}{2}}\right|+\left|\sin{\frac{x}{2}}-\cos{\frac{x}{2}}\right|}{\left|\sin{\frac{x}{2}}+\cos{\frac{x}{2}}\right|-\left|\sin{\frac{x}{2}}-\cos{\frac{x}{2}}\right|}\right)$$ The answers should ideally match, but they dont. $\frac{dy_1}{dx}=\frac{-1}{2}\neq\frac{dy_2}{dx}$ Why don't they?","$$y=\tan^{-1}\left(\frac{\sqrt{1+\sin{x}}+\sqrt{1-\sin{x}}}{\sqrt{1+\sin{x}}-\sqrt{1-\sin{x}}}\right)$$ $$\sqrt{1+\sin{x}}=\sin{\frac{x}{2}}+\cos{\frac{x}{2}}$$ $$\sqrt{1-\sin{x}}=\sin{\frac{x}{2}}-\cos{\frac{x}{2}}$$ $$y=\tan^{-1}\left(\tan{\frac{x}{2}}\right)$$Differentiating, we get: $$\frac{dy}{dx}=\frac{1}{2}$$ But taking: $$\sqrt{1-\sin{x}}=\cos{\frac{x}{2}}-\sin{\frac{x}{2}}$$ $$y=\tan^{-1}\left(\cot{\frac{x}{2}}\right)$$ Differentiating, we get: $$\frac{dy}{dx}=\frac{-1}{2}$$ I figured that I needed to use absolute value for the simplification of $\sqrt{1-\sin{x}}$, i.e. $\sqrt{1-\sin{x}}=\left|\sin{\frac{x}{2}}-\cos{\frac{x}{2}}\right|$. Subsequently, I put the below functions into Wolfram Alpha's input box to differentiate: $$y_1=\tan^{-1}\left(\frac{\sqrt{1+\sin{x}}+\sqrt{1-\sin{x}}}{\sqrt{1+\sin{x}}-\sqrt{1-\sin{x}}}\right)$$ And $$y_2=\tan^{-1}\left(\frac{\left|\sin{\frac{x}{2}}+\cos{\frac{x}{2}}\right|+\left|\sin{\frac{x}{2}}-\cos{\frac{x}{2}}\right|}{\left|\sin{\frac{x}{2}}+\cos{\frac{x}{2}}\right|-\left|\sin{\frac{x}{2}}-\cos{\frac{x}{2}}\right|}\right)$$ The answers should ideally match, but they dont. $\frac{dy_1}{dx}=\frac{-1}{2}\neq\frac{dy_2}{dx}$ Why don't they?",,"['calculus', 'trigonometry', 'derivatives', 'proof-verification', 'absolute-value']"
11,quant interview question from 1996 at Banc One in Columbus Ohio,quant interview question from 1996 at Banc One in Columbus Ohio,,"During a quant interview with Banc One in 1996 post-physics doctorate, I choked on this interview question: What is the derivative $\frac{dy}{dx}$ of $y=x^{x^{x^{.^{.^{.}}}}}$","During a quant interview with Banc One in 1996 post-physics doctorate, I choked on this interview question: What is the derivative $\frac{dy}{dx}$ of $y=x^{x^{x^{.^{.^{.}}}}}$",,['derivatives']
12,Proof of differentiability of $f(x)$ [duplicate],Proof of differentiability of  [duplicate],f(x),"This question already has answers here : Show that $f$ is differentiable on $(−1, 1)$. (3 answers) Closed 3 years ago . Let $f$ be a function defined on the interval $(-1,1)$ such that for all $x,y\in(-1,1)$, $f(x+y)=\frac{f(x)+f(y)}{1-f(x)f(y)}$. Suppose that $f$ is differentiable at $x=0$. Show that $f$ is differentiable on $(-1,1)$. For me I can see that $\tan(x)$ is obviously a case of $f$, but I cannot find a general proof for this $f$. Could any kind soul help?","This question already has answers here : Show that $f$ is differentiable on $(−1, 1)$. (3 answers) Closed 3 years ago . Let $f$ be a function defined on the interval $(-1,1)$ such that for all $x,y\in(-1,1)$, $f(x+y)=\frac{f(x)+f(y)}{1-f(x)f(y)}$. Suppose that $f$ is differentiable at $x=0$. Show that $f$ is differentiable on $(-1,1)$. For me I can see that $\tan(x)$ is obviously a case of $f$, but I cannot find a general proof for this $f$. Could any kind soul help?",,"['calculus', 'derivatives']"
13,"Are the different ways of rigorizing the notion of ""differential"" mutually exclusive?","Are the different ways of rigorizing the notion of ""differential"" mutually exclusive?",,"Let $C=\{(x,y):f(x,y)=0\}$ be the level set of a continuously differentiable function $f(x,y)$ of two variables. Using implicit differentiation, we get: $$\frac{dy}{dx} = - \frac{\displaystyle\frac{\partial f}{\partial x}}{\displaystyle\frac{\partial f}{\partial y}}$$ Thus, with a wink and a nudge, we define the differential of $f$ to be $$df = \frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial y}dy. $$ I am aware of at least two different ways to make this notion rigorous: 1. Using multilinear algebra, interpret $dx$ and $dy$ as differential forms. 2. Using non-standard analysis, interpret $dx$ and $dy$ as infinitesimals (in the hypperreals). Questions: Are these two interpretations mutually exclusive? Is there a third way to think of them that unifies both? As far as I am aware, differential forms and infinitesimals are very different objects, so it seems like these two ways of understanding the concept of differential are intractable when considered together. The motivation for the notion of differential as stated above comes from p. 174, section 3.6.2., of Algebraic Geometry: A Problem Solving Approach .","Let $C=\{(x,y):f(x,y)=0\}$ be the level set of a continuously differentiable function $f(x,y)$ of two variables. Using implicit differentiation, we get: $$\frac{dy}{dx} = - \frac{\displaystyle\frac{\partial f}{\partial x}}{\displaystyle\frac{\partial f}{\partial y}}$$ Thus, with a wink and a nudge, we define the differential of $f$ to be $$df = \frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial y}dy. $$ I am aware of at least two different ways to make this notion rigorous: 1. Using multilinear algebra, interpret $dx$ and $dy$ as differential forms. 2. Using non-standard analysis, interpret $dx$ and $dy$ as infinitesimals (in the hypperreals). Questions: Are these two interpretations mutually exclusive? Is there a third way to think of them that unifies both? As far as I am aware, differential forms and infinitesimals are very different objects, so it seems like these two ways of understanding the concept of differential are intractable when considered together. The motivation for the notion of differential as stated above comes from p. 174, section 3.6.2., of Algebraic Geometry: A Problem Solving Approach .",,"['derivatives', 'soft-question', 'differential-forms', 'differential', 'nonstandard-analysis']"
14,How to use the derivative (which has x and y in the answer) to approximate values of the function,How to use the derivative (which has x and y in the answer) to approximate values of the function,,"For ethical reasons, I won't ask the exact assignment question: For a function such as $4x^3 + 2y^3 -yx^2 = 49$. How could I use the derivative to estimate the values on the curve near a certain point? I am asked to create a table of values close to a point given to me. Since I have created the function above, I cannot give one as there is likely no pretty answer. So, if the solution requires this, how would I utilize it? The derivative of this function is similar in nature to the one in my assignment, that being it has values of x and y. The derivative for this particular function is $$ f'(x)=\frac{2x(6x-y)}{x^2 -6y^2} $$ I believe the solution lies in the using something similar to f(x) ≈ f(a) + f'(a)(x − a), but I do not know how to implement this. For my assignment in particular it asks me, after telling me to find values on the curve near x=1, y=2, to include the 0.96, 0.98, 1, 1.02, and 1.04 in my table of values. I can only assume this means the x values and find the subsequent y? I am not sure how to do this with the derivative considering if I put in a value of x, there are two unknowns: the value of y and the derivative itself. Sorry I have waffled a bit, and I apologise if my wording makes things confusing. It is a manifestation of my own confusion. Edit: The next part of the question involves finding x values such that the tangent to the curve is horizontal, or vertical. How would I go about this? My initial response. for horizontal, is to make the derivative =0, but I have two variables? How could I find a vertical tangent?","For ethical reasons, I won't ask the exact assignment question: For a function such as $4x^3 + 2y^3 -yx^2 = 49$. How could I use the derivative to estimate the values on the curve near a certain point? I am asked to create a table of values close to a point given to me. Since I have created the function above, I cannot give one as there is likely no pretty answer. So, if the solution requires this, how would I utilize it? The derivative of this function is similar in nature to the one in my assignment, that being it has values of x and y. The derivative for this particular function is $$ f'(x)=\frac{2x(6x-y)}{x^2 -6y^2} $$ I believe the solution lies in the using something similar to f(x) ≈ f(a) + f'(a)(x − a), but I do not know how to implement this. For my assignment in particular it asks me, after telling me to find values on the curve near x=1, y=2, to include the 0.96, 0.98, 1, 1.02, and 1.04 in my table of values. I can only assume this means the x values and find the subsequent y? I am not sure how to do this with the derivative considering if I put in a value of x, there are two unknowns: the value of y and the derivative itself. Sorry I have waffled a bit, and I apologise if my wording makes things confusing. It is a manifestation of my own confusion. Edit: The next part of the question involves finding x values such that the tangent to the curve is horizontal, or vertical. How would I go about this? My initial response. for horizontal, is to make the derivative =0, but I have two variables? How could I find a vertical tangent?",,"['calculus', 'derivatives', 'approximation']"
15,"The level curves of a function with $|\nabla u(x,y)|=f(u(x,y))$ and $\Delta u=1$ are lines or circles (locally)",The level curves of a function with  and  are lines or circles (locally),"|\nabla u(x,y)|=f(u(x,y)) \Delta u=1","Consider $u:\Omega\subset \mathbb R^2\to \mathbb R$ be a $C^2$   function. Knowing that $\nabla u\neq 0$ everywhere on $\Omega$,   $\Delta u\equiv 1$ and $|\nabla u(x,y)|=f(u(x,y))$ for some $f$ $C^1$, prove   that, locally, the level curves of $u$ are lines or circles. My attempt was to prove that these curves have locally constant curvature. I calculated the curvature, following the Frenet formulas, as the module of the derivative of the normal vector. So, given a local arc length parametrization of a level curve (it exists by the implicit function theorem) we can say that $$k(t)=\Big|\frac{d}{dt}\frac{\nabla u(x(t),y(t))}{f(u(x(t),y(t)))}\Big|$$ since the gradient is normal to the level curve. Developing the formulas, one actually makes use of the hypotesis $\Delta u=1$ in order to simplify the expression, but I didn't obtain that $k$ is constant. Is my attempt successful? Are there any better ways? Thank you in advance.","Consider $u:\Omega\subset \mathbb R^2\to \mathbb R$ be a $C^2$   function. Knowing that $\nabla u\neq 0$ everywhere on $\Omega$,   $\Delta u\equiv 1$ and $|\nabla u(x,y)|=f(u(x,y))$ for some $f$ $C^1$, prove   that, locally, the level curves of $u$ are lines or circles. My attempt was to prove that these curves have locally constant curvature. I calculated the curvature, following the Frenet formulas, as the module of the derivative of the normal vector. So, given a local arc length parametrization of a level curve (it exists by the implicit function theorem) we can say that $$k(t)=\Big|\frac{d}{dt}\frac{\nabla u(x(t),y(t))}{f(u(x(t),y(t)))}\Big|$$ since the gradient is normal to the level curve. Developing the formulas, one actually makes use of the hypotesis $\Delta u=1$ in order to simplify the expression, but I didn't obtain that $k$ is constant. Is my attempt successful? Are there any better ways? Thank you in advance.",,"['real-analysis', 'derivatives', 'curvature']"
16,Prove that a given function is locally Lipschitz and therefore differentiable a.e.,Prove that a given function is locally Lipschitz and therefore differentiable a.e.,,"Consider $u:S^1\times (0,T)\to \mathbb R$ a $C^1$ function, and define   $$v(t)=\max_{p\in S^1} u(p,t)$$   Prove that $v$ is locally Lipschitz and deduce that $$\frac {dv}{dt}(t_0)=\frac{\partial u}{\partial t}(p_0,t_0)$$ where $p_0$ is any maximum point for $u(\cdot, t_0)$. For point one my idea was to prove that at least one maximum point at height $t$ (viewing the domain as a vertical cylinder) has a neighbourhood which contains a differentiable curve made of maximum points for $u$. Therefore, in that neighbourhood (i.e. for $t$ near to $t_0$) one could use that $u$ is $C^1$. But is that true? And is this really the best way? For point two, I know that locally Lipschitz implies absolutely continuous which implies a.e. differentiable. But how could I deduce the (however intuitive) formula for the derivative? Furthermore, I'm quite sure that the result absolutely continuous $\Longrightarrow$ differentiable a.e. is more advanced than the level at which the problem was given. Isn't there a simpler way for this special case? Thank you in advance.","Consider $u:S^1\times (0,T)\to \mathbb R$ a $C^1$ function, and define   $$v(t)=\max_{p\in S^1} u(p,t)$$   Prove that $v$ is locally Lipschitz and deduce that $$\frac {dv}{dt}(t_0)=\frac{\partial u}{\partial t}(p_0,t_0)$$ where $p_0$ is any maximum point for $u(\cdot, t_0)$. For point one my idea was to prove that at least one maximum point at height $t$ (viewing the domain as a vertical cylinder) has a neighbourhood which contains a differentiable curve made of maximum points for $u$. Therefore, in that neighbourhood (i.e. for $t$ near to $t_0$) one could use that $u$ is $C^1$. But is that true? And is this really the best way? For point two, I know that locally Lipschitz implies absolutely continuous which implies a.e. differentiable. But how could I deduce the (however intuitive) formula for the derivative? Furthermore, I'm quite sure that the result absolutely continuous $\Longrightarrow$ differentiable a.e. is more advanced than the level at which the problem was given. Isn't there a simpler way for this special case? Thank you in advance.",,"['real-analysis', 'derivatives', 'lipschitz-functions']"
17,What is $\frac{dx}{d}?$,What is,\frac{dx}{d}?,"The operator $\frac{d}{dx}$ is common in calculus to denote a derivative. However, this also begs the question, what is the operator $\frac{dx}{d}$? Is this operator used commonly? If so, what is it called/what does it do? I have played aroud with it before, and found a natural way to define it seems to be that $$\frac{dx}{d}\frac{1}{f(x)} := \frac{dx}{df} = \frac{1}{(\frac{df}{dx})}$$ I found also in my own playing around that this could define an odd thing when applying the operator twice: $$\frac{dx}{d}(\frac{dx}{df}) = \frac{dx}{d\frac{df}{dx}} = \frac{1}{\frac{d\frac{df}{dx}}{dx}} = \frac{1}{\frac{d^2f}{dx^2}}$$ Which would seem to imply a nice notation definition: $$\frac{dx}{d}(\frac{dx}{df}) := \frac{dx^2}{d^2f}$$ All this is purely my own speculation/invention, of course. I've never heard of any operation like this, and can't find it on the internet, because I don't have a name for it and can't find the notation anywhere. Is this operation already well-defined?","The operator $\frac{d}{dx}$ is common in calculus to denote a derivative. However, this also begs the question, what is the operator $\frac{dx}{d}$? Is this operator used commonly? If so, what is it called/what does it do? I have played aroud with it before, and found a natural way to define it seems to be that $$\frac{dx}{d}\frac{1}{f(x)} := \frac{dx}{df} = \frac{1}{(\frac{df}{dx})}$$ I found also in my own playing around that this could define an odd thing when applying the operator twice: $$\frac{dx}{d}(\frac{dx}{df}) = \frac{dx}{d\frac{df}{dx}} = \frac{1}{\frac{d\frac{df}{dx}}{dx}} = \frac{1}{\frac{d^2f}{dx^2}}$$ Which would seem to imply a nice notation definition: $$\frac{dx}{d}(\frac{dx}{df}) := \frac{dx^2}{d^2f}$$ All this is purely my own speculation/invention, of course. I've never heard of any operation like this, and can't find it on the internet, because I don't have a name for it and can't find the notation anywhere. Is this operation already well-defined?",,"['calculus', 'derivatives']"
18,Symbol of differential operator and change of coordinates,Symbol of differential operator and change of coordinates,,"$\DeclareMathOperator{I changed index to upper one}{but edit has to take al least 6 elements}$ Some time ago I posted the question about the change of coordinates in differential operator. Here is the relevant discussion Symbol of differential operator transforms like a cotangent vector The answer which was given to this question explains why we can invariantly define the principial symbol of differential operator. However I would like to understand straightforward what happens with the principial symbol when we introduce new coordinates. Let me recall some formulas for transformation laws for tensors: if $(x^i)$ are old coordinates and $(y^i)$ are new coordinates then we have following formulas for canonical basis in tangent and cotangent spaces (everything takes place over manifold $M$): $$\frac{\partial}{\partial y^i}=\sum_{k=1}^n \frac{\partial x^k}{\partial y^i} \frac{\partial}{\partial x^k}, \qquad \frac{\partial}{\partial x^i}=\sum_{k=1}^n \frac{\partial y^k}{\partial x^i} \frac{\partial}{\partial y^k},$$ $$dy^i=\sum_{k=1}^n\frac{\partial y^i}{\partial x^k} dx^k, \qquad dx^i=\sum_{k=1}^n\frac{\partial x^i}{\partial y^k} dy^k $$ If we have vector field $X=\sum_{k=1}^nX^k \frac{\partial}{\partial x^k}=\sum_{k=1}^n Y^k \frac{\partial}{\partial y^k}$ and differential one-form $\omega=\sum_{k=1}^n \alpha_k dx^k=\sum_{k=1}^n\beta_k dy^k$ expressed in these two system of coordinates then we have formulas: $$Y^i=\sum_{k=1}^n\frac{\partial y^i}{\partial x^k}X^k, \qquad X^i=\sum_{k=1}^n\frac{\partial x^i}{\partial y^k}Y^k,$$ $$\beta_i=\sum_{k=1}^n\frac{\partial x^k}{\partial y^i}\alpha_k, \qquad \alpha_i=\sum_{k=1}^n\frac{\partial y^k}{\partial x^i}\beta_k.$$ For general tensors of type $(r,s)$ if we have in two differenet coordinate systems $$t=\sum_{i_1,...,i_r,j_1,...,j_s}t^{i_1,...,i_r}_{j_1,...,j_s}\frac{\partial}{\partial x^{i_1}} \otimes ... \otimes \frac{\partial}{\partial x^{i_r}}\otimes dx^{j_1} \otimes ... \otimes dx^{j_s}=\sum_{i_1,...,i_r,j_1,...,j_s}u^{i_1,...,i_r}_{j_1,...,j_s}\frac{\partial}{\partial y^{i_1}} \otimes ... \otimes \frac{\partial}{\partial y^{i_r}}\otimes dy^{j_1} \otimes ... \otimes dy^{j_s}$$ then we have  $$\frac{\partial}{\partial y^{i_1}} \otimes ... \otimes \frac{\partial}{\partial y^{i_r}}\otimes dy^{j_1} \otimes ... \otimes dy^{j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial x^{k_1}}{\partial y^{i_1}} ... \frac{\partial x^{k_r}}{\partial y^{i_r}}\frac{\partial y^{j_1}}{\partial x^{l_1}} ... \frac{\partial y^{j_s}}{\partial x^{l_s}}  \frac{\partial}{\partial x^{k_1}} \otimes ... \otimes \frac{\partial}{\partial x^{k_r}}\otimes dx^{l_1} \otimes ... \otimes dx^{l_s},$$ $$\frac{\partial}{\partial x^{i_1}} \otimes ... \otimes \frac{\partial}{\partial x^{i_r}}\otimes dx^{j_1} \otimes ... \otimes dx^{j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial y^{k_1}}{\partial x^{i_1}} ... \frac{\partial y^{k_r}}{\partial x^{i_r}}\frac{\partial x^{j_1}}{\partial y^{l_1}} ... \frac{\partial x^{j_s}}{\partial y^{l_s}}  \frac{\partial}{\partial y^{k_1}} \otimes ... \otimes \frac{\partial}{\partial y^{k_r}}\otimes dy^{l_1} \otimes ... \otimes dy^{l_s}$$and also $$u^{i_1,...,i_r}_{j_1,...,j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial y^{i_1}}{\partial x^{k_1}} ... \frac{\partial y^{i_r}}{\partial x^{k_r}} \frac{\partial x^{l_1}}{\partial y^{j_1}} ... \frac{\partial x^{l_s}}{\partial y^{j_s}}t^{k_1,...,k_r}_{l_1,...,l_s},$$ $$t^{i_1,...,i_r}_{j_1,...,j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial x^{i_1}}{\partial y^{k_1}} ... \frac{\partial x^{i_r}}{\partial y^{k_r}} \frac{\partial y^{l_1}}{\partial x^{j_1}} ... \frac{\partial y^{l_s}}{\partial x^{j_s}}u^{k_1,...,k_r}_{l_1,...,l_s}.$$ However general differential operator contains higher order differentials for which I haven't seen the appriopriate formulas. For general differential order $m$ operator of the form $D=\sum_{|\alpha| \leq m}a_{\alpha}(x)\frac{\partial^{|\alpha|}}{\partial x_1^{\alpha_1} ... \partial x_n^{\alpha_n}}$ (where $\alpha=(\alpha_1,...,\alpha_n)$ a multiindex and $a_{\alpha}(x)$ are matrices) the principial synmbol is defined as the expression $a(x,\xi)=\sum_{|\alpha|=m}a_{\alpha}(x)\xi_1^{\alpha_1} ... \xi_n^{\alpha_n}$ where $\xi=(\xi_1,...,\xi_n)$ is a vector: what we do, we replace each $\frac{\partial}{\partial x_k}$ by $\xi_k$. So far we have some formal expression $a$ which takes a point $x$ of a manifold and vector $\xi \in \mathbb{R}^n$ and produces some matrix. And here are my questions: What transformation law the function $a$ must obey in order to correctly define a mapping from the cotangent bundle $T^*M$? Or maybe we look for some transformation laws for the variables $\xi_k$? How to show that such transformation law holds? I repeat once again: I already understood how to define symbol globally as a map from cotangent space and that this definition gives exactly the local expression described above-however I would like to understand the reason for such definition which at the moment is pulled out of hat.Concerning the second question I would like to understand whether there are some general formulas for transformation laws for an arbitrary differential operators: as far as I remeber, when I once saw the computations for spherical Laplacian, it was not clear whether such method will work in general arbitrary example.","$\DeclareMathOperator{I changed index to upper one}{but edit has to take al least 6 elements}$ Some time ago I posted the question about the change of coordinates in differential operator. Here is the relevant discussion Symbol of differential operator transforms like a cotangent vector The answer which was given to this question explains why we can invariantly define the principial symbol of differential operator. However I would like to understand straightforward what happens with the principial symbol when we introduce new coordinates. Let me recall some formulas for transformation laws for tensors: if $(x^i)$ are old coordinates and $(y^i)$ are new coordinates then we have following formulas for canonical basis in tangent and cotangent spaces (everything takes place over manifold $M$): $$\frac{\partial}{\partial y^i}=\sum_{k=1}^n \frac{\partial x^k}{\partial y^i} \frac{\partial}{\partial x^k}, \qquad \frac{\partial}{\partial x^i}=\sum_{k=1}^n \frac{\partial y^k}{\partial x^i} \frac{\partial}{\partial y^k},$$ $$dy^i=\sum_{k=1}^n\frac{\partial y^i}{\partial x^k} dx^k, \qquad dx^i=\sum_{k=1}^n\frac{\partial x^i}{\partial y^k} dy^k $$ If we have vector field $X=\sum_{k=1}^nX^k \frac{\partial}{\partial x^k}=\sum_{k=1}^n Y^k \frac{\partial}{\partial y^k}$ and differential one-form $\omega=\sum_{k=1}^n \alpha_k dx^k=\sum_{k=1}^n\beta_k dy^k$ expressed in these two system of coordinates then we have formulas: $$Y^i=\sum_{k=1}^n\frac{\partial y^i}{\partial x^k}X^k, \qquad X^i=\sum_{k=1}^n\frac{\partial x^i}{\partial y^k}Y^k,$$ $$\beta_i=\sum_{k=1}^n\frac{\partial x^k}{\partial y^i}\alpha_k, \qquad \alpha_i=\sum_{k=1}^n\frac{\partial y^k}{\partial x^i}\beta_k.$$ For general tensors of type $(r,s)$ if we have in two differenet coordinate systems $$t=\sum_{i_1,...,i_r,j_1,...,j_s}t^{i_1,...,i_r}_{j_1,...,j_s}\frac{\partial}{\partial x^{i_1}} \otimes ... \otimes \frac{\partial}{\partial x^{i_r}}\otimes dx^{j_1} \otimes ... \otimes dx^{j_s}=\sum_{i_1,...,i_r,j_1,...,j_s}u^{i_1,...,i_r}_{j_1,...,j_s}\frac{\partial}{\partial y^{i_1}} \otimes ... \otimes \frac{\partial}{\partial y^{i_r}}\otimes dy^{j_1} \otimes ... \otimes dy^{j_s}$$ then we have  $$\frac{\partial}{\partial y^{i_1}} \otimes ... \otimes \frac{\partial}{\partial y^{i_r}}\otimes dy^{j_1} \otimes ... \otimes dy^{j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial x^{k_1}}{\partial y^{i_1}} ... \frac{\partial x^{k_r}}{\partial y^{i_r}}\frac{\partial y^{j_1}}{\partial x^{l_1}} ... \frac{\partial y^{j_s}}{\partial x^{l_s}}  \frac{\partial}{\partial x^{k_1}} \otimes ... \otimes \frac{\partial}{\partial x^{k_r}}\otimes dx^{l_1} \otimes ... \otimes dx^{l_s},$$ $$\frac{\partial}{\partial x^{i_1}} \otimes ... \otimes \frac{\partial}{\partial x^{i_r}}\otimes dx^{j_1} \otimes ... \otimes dx^{j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial y^{k_1}}{\partial x^{i_1}} ... \frac{\partial y^{k_r}}{\partial x^{i_r}}\frac{\partial x^{j_1}}{\partial y^{l_1}} ... \frac{\partial x^{j_s}}{\partial y^{l_s}}  \frac{\partial}{\partial y^{k_1}} \otimes ... \otimes \frac{\partial}{\partial y^{k_r}}\otimes dy^{l_1} \otimes ... \otimes dy^{l_s}$$and also $$u^{i_1,...,i_r}_{j_1,...,j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial y^{i_1}}{\partial x^{k_1}} ... \frac{\partial y^{i_r}}{\partial x^{k_r}} \frac{\partial x^{l_1}}{\partial y^{j_1}} ... \frac{\partial x^{l_s}}{\partial y^{j_s}}t^{k_1,...,k_r}_{l_1,...,l_s},$$ $$t^{i_1,...,i_r}_{j_1,...,j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial x^{i_1}}{\partial y^{k_1}} ... \frac{\partial x^{i_r}}{\partial y^{k_r}} \frac{\partial y^{l_1}}{\partial x^{j_1}} ... \frac{\partial y^{l_s}}{\partial x^{j_s}}u^{k_1,...,k_r}_{l_1,...,l_s}.$$ However general differential operator contains higher order differentials for which I haven't seen the appriopriate formulas. For general differential order $m$ operator of the form $D=\sum_{|\alpha| \leq m}a_{\alpha}(x)\frac{\partial^{|\alpha|}}{\partial x_1^{\alpha_1} ... \partial x_n^{\alpha_n}}$ (where $\alpha=(\alpha_1,...,\alpha_n)$ a multiindex and $a_{\alpha}(x)$ are matrices) the principial synmbol is defined as the expression $a(x,\xi)=\sum_{|\alpha|=m}a_{\alpha}(x)\xi_1^{\alpha_1} ... \xi_n^{\alpha_n}$ where $\xi=(\xi_1,...,\xi_n)$ is a vector: what we do, we replace each $\frac{\partial}{\partial x_k}$ by $\xi_k$. So far we have some formal expression $a$ which takes a point $x$ of a manifold and vector $\xi \in \mathbb{R}^n$ and produces some matrix. And here are my questions: What transformation law the function $a$ must obey in order to correctly define a mapping from the cotangent bundle $T^*M$? Or maybe we look for some transformation laws for the variables $\xi_k$? How to show that such transformation law holds? I repeat once again: I already understood how to define symbol globally as a map from cotangent space and that this definition gives exactly the local expression described above-however I would like to understand the reason for such definition which at the moment is pulled out of hat.Concerning the second question I would like to understand whether there are some general formulas for transformation laws for an arbitrary differential operators: as far as I remeber, when I once saw the computations for spherical Laplacian, it was not clear whether such method will work in general arbitrary example.",,"['real-analysis', 'differential-geometry', 'derivatives', 'tensors', 'change-of-basis']"
19,Derivative of $X_u A X B X_u^T$ w.r.t. $X_u$,Derivative of  w.r.t.,X_u A X B X_u^T X_u,"How to solve this $\frac{d X_u A X B X_u^T}{d X_u}$, where $X, A, B \in \mathbb{R}^{n \times n}$ and $X_u$ is the $u$-th row in $X$?","How to solve this $\frac{d X_u A X B X_u^T}{d X_u}$, where $X, A, B \in \mathbb{R}^{n \times n}$ and $X_u$ is the $u$-th row in $X$?",,"['linear-algebra', 'matrices', 'derivatives', 'matrix-calculus']"
20,function is not differentiable on $\mathbb R\setminus\{0\}$,function is not differentiable on,\mathbb R\setminus\{0\},"I need to prove that the given function $f$ is not differentiable on $\mathbb R \setminus\{0\}$. $$ f(x) =  \begin{cases} x^2, \ x \in \mathbb{Q}\\ 0,  \ x \in \mathbb{R}-\mathbb{Q} \end{cases} $$ Can anyone tell me for $c\in\mathbb R \setminus \{0\}$ my work is correct or not and also if you have any different way to this question comment them please thanks Suppose $c\in\mathbb R \setminus \{0\}$ be arbitrary CASE 1  $c\in\mathbb R \setminus \mathbb Q$. Let $\varepsilon = c^2>0$ Let $δ>0$ be arbitrary Suppose $|x-c|<δ$ If $c > 0$ choose $x'\in(c,c+\delta) \cap \mathbb R \setminus\mathbb Q$. If $c < 0$ choose $x'\in(c-\delta,c) \cap \mathbb R \setminus\mathbb Q$. Since $|f(x')-f(c)|=|x'^2-0^2 |=|x'^2-0^2 |>c^2=ε$. $f$ is not continuous at $0$ hence $f$ is not differentiable at $\mathbb R \setminus\mathbb Q$.","I need to prove that the given function $f$ is not differentiable on $\mathbb R \setminus\{0\}$. $$ f(x) =  \begin{cases} x^2, \ x \in \mathbb{Q}\\ 0,  \ x \in \mathbb{R}-\mathbb{Q} \end{cases} $$ Can anyone tell me for $c\in\mathbb R \setminus \{0\}$ my work is correct or not and also if you have any different way to this question comment them please thanks Suppose $c\in\mathbb R \setminus \{0\}$ be arbitrary CASE 1  $c\in\mathbb R \setminus \mathbb Q$. Let $\varepsilon = c^2>0$ Let $δ>0$ be arbitrary Suppose $|x-c|<δ$ If $c > 0$ choose $x'\in(c,c+\delta) \cap \mathbb R \setminus\mathbb Q$. If $c < 0$ choose $x'\in(c-\delta,c) \cap \mathbb R \setminus\mathbb Q$. Since $|f(x')-f(c)|=|x'^2-0^2 |=|x'^2-0^2 |>c^2=ε$. $f$ is not continuous at $0$ hence $f$ is not differentiable at $\mathbb R \setminus\mathbb Q$.",,"['calculus', 'real-analysis', 'derivatives']"
21,Is $f(a+b\epsilon)=f(a)+b\epsilon f'(a)$ true for non-analytic smooth functions of dual argument,Is  true for non-analytic smooth functions of dual argument,f(a+b\epsilon)=f(a)+b\epsilon f'(a),"Does $f(a+b\epsilon)=f(a)+b\epsilon f'(a)$  remain true for non-analytic smooth functions of dual number argument? Where $ \epsilon^2=0$, $\epsilon \neq 0$ and $a,b \in \mathbb R$.  I found proofs based only on Taylor series. That means it is okay to use the formula for argument values where function is analytic (in real numbers). But what about other cases? 1. Does a proof of $f(a+b\epsilon)=f(a)+b\epsilon f'(a)$ for non-analytic smooth functions exist? 2. What about dual values $b\epsilon g(a)$ that correspond to argument $a$ where function is non-analytic?","Does $f(a+b\epsilon)=f(a)+b\epsilon f'(a)$  remain true for non-analytic smooth functions of dual number argument? Where $ \epsilon^2=0$, $\epsilon \neq 0$ and $a,b \in \mathbb R$.  I found proofs based only on Taylor series. That means it is okay to use the formula for argument values where function is analytic (in real numbers). But what about other cases? 1. Does a proof of $f(a+b\epsilon)=f(a)+b\epsilon f'(a)$ for non-analytic smooth functions exist? 2. What about dual values $b\epsilon g(a)$ that correspond to argument $a$ where function is non-analytic?",,"['real-analysis', 'derivatives', 'analyticity', 'hypercomplex-numbers']"
22,Does the Upper and Lower Derivative Definition Imply the Standard Derivative Definition?,Does the Upper and Lower Derivative Definition Imply the Standard Derivative Definition?,,"The upper and lower derivatives of a function f on the interior of a set $E$ are defined as follows: for $x\in E\strut^\mathrm{o}$, $$\overline Df(x)= \lim _{h\rightarrow0}\left[\sup_{0<|t|\leq h} \frac{f(x+t)-f(x)}{t} \right];$$ $$\underline Df(x)=\lim _{h\rightarrow0}\left[\inf_{0<|t|\leq h} \frac{f(x+t)-f(x)}{t} \right].$$ The function $f$ is differentiable in $x$ $\iff$ $\overline Df(x)=\underline Df(x)$. My question is that, does the definition above of differentiability imply the 'standard' definition of differentiability? That is, if $\overline Df(x)=\underline Df(x)$, does it imply that $$\lim_{h\rightarrow0}\frac{f(x+h)-f(x)}{h}?$$","The upper and lower derivatives of a function f on the interior of a set $E$ are defined as follows: for $x\in E\strut^\mathrm{o}$, $$\overline Df(x)= \lim _{h\rightarrow0}\left[\sup_{0<|t|\leq h} \frac{f(x+t)-f(x)}{t} \right];$$ $$\underline Df(x)=\lim _{h\rightarrow0}\left[\inf_{0<|t|\leq h} \frac{f(x+t)-f(x)}{t} \right].$$ The function $f$ is differentiable in $x$ $\iff$ $\overline Df(x)=\underline Df(x)$. My question is that, does the definition above of differentiability imply the 'standard' definition of differentiability? That is, if $\overline Df(x)=\underline Df(x)$, does it imply that $$\lim_{h\rightarrow0}\frac{f(x+h)-f(x)}{h}?$$",,"['real-analysis', 'derivatives']"
23,"If $f'(a)=f''(a)=0$ but $a$ is not an inflection point, then must $a$ be a maximum or minimum?","If  but  is not an inflection point, then must  be a maximum or minimum?",f'(a)=f''(a)=0 a a,"Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be twice-differentiable and $a\in\mathbb{R}$. If $f'(a)=f''(a)=0$ but $a$ is not an inflection point, then must $a$ be a maximum point or a minimum point?","Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be twice-differentiable and $a\in\mathbb{R}$. If $f'(a)=f''(a)=0$ but $a$ is not an inflection point, then must $a$ be a maximum point or a minimum point?",,['calculus']
24,Do irrational derivative orders exist?,Do irrational derivative orders exist?,,"There are many notations for a derivative of $y$ with respect to $x$. Two, most popular are $y'(x)$ or just $y'$ and $\frac{dy}{dx}$. For higher order derivatives, the more consistent notation is $\frac{d^ny}{dx^n}$. Now, we know it is possible to have fractional derivative orders (there was even one question about it here on math.stackexchange). What about irrational derivative orders? For example, does this expression exist?: $$\frac{d^{\sqrt{2}}}{dx^{\sqrt{2}}}\Bigg(2x^3+5x\Bigg)$$","There are many notations for a derivative of $y$ with respect to $x$. Two, most popular are $y'(x)$ or just $y'$ and $\frac{dy}{dx}$. For higher order derivatives, the more consistent notation is $\frac{d^ny}{dx^n}$. Now, we know it is possible to have fractional derivative orders (there was even one question about it here on math.stackexchange). What about irrational derivative orders? For example, does this expression exist?: $$\frac{d^{\sqrt{2}}}{dx^{\sqrt{2}}}\Bigg(2x^3+5x\Bigg)$$",,"['calculus', 'derivatives']"
25,If $f(x) = -2\sin(x)$ then $f′(x)$ equals what?,If  then  equals what?,f(x) = -2\sin(x) f′(x),If $f(x) = -2\sin(x)$ then $f′(x)$ equals what? A: $2\cos x$ If $f(x) = (15)^x$ then $f′(x)$ = ? A: $(15)^x \ln (15)^x$ Are my solutions correct?,If $f(x) = -2\sin(x)$ then $f′(x)$ equals what? A: $2\cos x$ If $f(x) = (15)^x$ then $f′(x)$ = ? A: $(15)^x \ln (15)^x$ Are my solutions correct?,,"['calculus', 'derivatives']"
26,zeros of two functions are alternate,zeros of two functions are alternate,,"Let $a,b,c,d$ be real numbers. Show that the zeros of the functions $f(x)=a\cos x+b\sin x$ and $g(x)=c\cos x+d\sin x$ are distinct and alternate whenever $ad-bc\neq 0$. Suppose $x_0\in \mathbb{R}$ such that $f(x_0)=g(x_0)=0$ we have  $$\begin{bmatrix}a &b\\c&d\end{bmatrix}\begin{bmatrix}\cos x_0\\ \sin x_0\end{bmatrix}=\begin{bmatrix}0\\ 0\end{bmatrix}$$ As $\begin{bmatrix}a &b\\c&d\end{bmatrix}$ is with nonzero determinat $ad-bc$ we see that $\cos x_0=\sin x_0=0$ which is not possible as $\sin x$ and $\cos x$ can not be zero simultaneously. Now, to show that zeros of $f(x)$ and $g(x)$ occur alternatively. Suppose $x_0,x_1$ be zeros of $f(x)$ we then have by mean value theorem an element $z_0\in(x_0,x_1)$ such that $f'(z_0)=0$.. I thought of using something like this as derivative of $f$ and the function $g$ are closely related. But  it did not work.. Existence of $z_0\in(x_0,x_1)$ with $f'(z_0)=0$ is valid even then $f(x_0)\neq 0\neq f(x_1)$. So, I thought I am neglecting some crucial information by deducing this weak result.. Consider giving me some hints to solve this. EDIT : I mean $f(x)$ and $g(x)$ have alternate zeros if between two zeros of $f(x)$ there is a zero of $g(x)$ and between two zeros of $g(x)$ there is a zero of $f(x)$.","Let $a,b,c,d$ be real numbers. Show that the zeros of the functions $f(x)=a\cos x+b\sin x$ and $g(x)=c\cos x+d\sin x$ are distinct and alternate whenever $ad-bc\neq 0$. Suppose $x_0\in \mathbb{R}$ such that $f(x_0)=g(x_0)=0$ we have  $$\begin{bmatrix}a &b\\c&d\end{bmatrix}\begin{bmatrix}\cos x_0\\ \sin x_0\end{bmatrix}=\begin{bmatrix}0\\ 0\end{bmatrix}$$ As $\begin{bmatrix}a &b\\c&d\end{bmatrix}$ is with nonzero determinat $ad-bc$ we see that $\cos x_0=\sin x_0=0$ which is not possible as $\sin x$ and $\cos x$ can not be zero simultaneously. Now, to show that zeros of $f(x)$ and $g(x)$ occur alternatively. Suppose $x_0,x_1$ be zeros of $f(x)$ we then have by mean value theorem an element $z_0\in(x_0,x_1)$ such that $f'(z_0)=0$.. I thought of using something like this as derivative of $f$ and the function $g$ are closely related. But  it did not work.. Existence of $z_0\in(x_0,x_1)$ with $f'(z_0)=0$ is valid even then $f(x_0)\neq 0\neq f(x_1)$. So, I thought I am neglecting some crucial information by deducing this weak result.. Consider giving me some hints to solve this. EDIT : I mean $f(x)$ and $g(x)$ have alternate zeros if between two zeros of $f(x)$ there is a zero of $g(x)$ and between two zeros of $g(x)$ there is a zero of $f(x)$.",,['real-analysis']
27,Derivative of Elementwise Function (working on a vector),Derivative of Elementwise Function (working on a vector),,"I have seen an example (it is in terms of neural network back propagation) that I don’t understand. Given: $\mathbf{a} = \mathbf{x}\mathbf{W}_{1}+\mathbf{b}_{1}$ (where $\mathbf{x}$ is dimension ( $1\times5$ ), $\mathbf{W}_1$ is ( $5\times3$ )) and $\mathbf{b}_1$ is ( $1\times3$ )) $\textbf{h}=\sigma(\textbf{a})$ is the sigmoid function: $\frac{1}{1+\exp(-a_{i})}$ which acts on the $n$ -dimensional vector $a$ element-wise, meaning $\sigma(\mathbf{a}) =[\sigma(a_{1}),\sigma(a_{2}),\ldots,\sigma(a_{n})]$ $\theta = \mathbf{h}\mathbf{W}_{2}+\mathbf{b}_2$ (where $\mathbf{h}$ is dimension ( $1\times3$ ), $\mathbf{W}_2$ is ( $3\times5$ ) and $\mathbf{b}_2$ is ( $1\times5$ )) $\hat{\mathbf{y}}= \operatorname{softmax}(\theta)$ (where $\hat{\mathbf{y}}$ is dimension ( $1\times5$ )) ( definition ) $L=\operatorname{xent}(y, \hat{y})$ ( definition ) The derivative of interest is $\frac{\partial L}{\partial x}$ or by the chain rule: $$\frac{\partial L}{\partial{x}} =\frac{\partial L}{\partial \hat{y}}\frac{\partial \hat{y}}{\partial{\theta}}\frac{\partial{\theta}}{\partial {h}}\frac{\partial{h}}{\partial{a}}\frac{\partial{a}}{\partial{x}}$$ The result they show makes perfect sense to me (almost) $((\hat{\mathbf{y}}-\mathbf{y}) \mathbf{W}_{2}^{T})\circ\sigma'(a)\mathbf{W}_{1}$ My Questions: Since $(\hat{\mathbf{y}}-\mathbf{y})$ is dimension ( $1\times5$ ) they transpose $\mathbf{W}_{2}$ to conform to vector matrix multiplication. Is this OK? Can you just transpose a matrix when you want? Why the elementwise multiplication by the derivative of $\sigma(a)$ The rationale is that since $\sigma$ is an elementwise operator, this is proper. I don’t understand why you would not apply sigma to each element of $\mathbf{a}$ and then matrix-multiply this result against the vector on the left?","I have seen an example (it is in terms of neural network back propagation) that I don’t understand. Given: (where is dimension ( ), is ( )) and is ( )) is the sigmoid function: which acts on the -dimensional vector element-wise, meaning (where is dimension ( ), is ( ) and is ( )) (where is dimension ( )) ( definition ) ( definition ) The derivative of interest is or by the chain rule: The result they show makes perfect sense to me (almost) My Questions: Since is dimension ( ) they transpose to conform to vector matrix multiplication. Is this OK? Can you just transpose a matrix when you want? Why the elementwise multiplication by the derivative of The rationale is that since is an elementwise operator, this is proper. I don’t understand why you would not apply sigma to each element of and then matrix-multiply this result against the vector on the left?","\mathbf{a} = \mathbf{x}\mathbf{W}_{1}+\mathbf{b}_{1} \mathbf{x} 1\times5 \mathbf{W}_1 5\times3 \mathbf{b}_1 1\times3 \textbf{h}=\sigma(\textbf{a}) \frac{1}{1+\exp(-a_{i})} n a \sigma(\mathbf{a}) =[\sigma(a_{1}),\sigma(a_{2}),\ldots,\sigma(a_{n})] \theta = \mathbf{h}\mathbf{W}_{2}+\mathbf{b}_2 \mathbf{h} 1\times3 \mathbf{W}_2 3\times5 \mathbf{b}_2 1\times5 \hat{\mathbf{y}}= \operatorname{softmax}(\theta) \hat{\mathbf{y}} 1\times5 L=\operatorname{xent}(y, \hat{y}) \frac{\partial L}{\partial x} \frac{\partial L}{\partial{x}} =\frac{\partial L}{\partial \hat{y}}\frac{\partial \hat{y}}{\partial{\theta}}\frac{\partial{\theta}}{\partial {h}}\frac{\partial{h}}{\partial{a}}\frac{\partial{a}}{\partial{x}} ((\hat{\mathbf{y}}-\mathbf{y}) \mathbf{W}_{2}^{T})\circ\sigma'(a)\mathbf{W}_{1} (\hat{\mathbf{y}}-\mathbf{y}) 1\times5 \mathbf{W}_{2} \sigma(a) \sigma \mathbf{a}","['calculus', 'linear-algebra', 'derivatives', 'vector-spaces']"
28,What does the derivative of a function at a point describe? [duplicate],What does the derivative of a function at a point describe? [duplicate],,"This question already has answers here : What does it mean to differentiate in calculus? (4 answers) Closed 8 years ago . I understand that the derivative of a function $f$ at a point $x=x_{0}$ is defined as the limit $$f'(x_{0})=\lim_{\Delta x\rightarrow 0}\frac{f(x_{0}+\Delta x)-f(x_{0})}{\Delta x}$$ where $\Delta x$ is a small change in the argument $x$ as we ""move"" from $x=x_{0}$ to a neighbouring point $x=x_{0}+\Delta x$.  What confuses me is how to interpret its meaning correctly, that is, what does the derivative $f'(x_{0})$ actually describe? On Wikipedia it says that "" the derivative of a function quantifies the rate at which the value of the function changes as we change the input "" (or words to that effect). However, the function has a particular constant value, $f(x_{0})$ at a given point $x=x_{0}$ so how can one meaningfully discuss the rate at which the value of the function is changing at that point? Would it be correct to interpret the derivative of a function at a point as describing how ""quickly"" it's value changes as we move from that point to (infinitesimally close) neighbouring points? (As such in the example above, in moving from the point $x_{0}$ to $x_{0}+\Delta x$ the value of the function $f$ changes by an amount $f'(x_{0})\Delta x$ for infinitesimally small change $\Delta x$). Is it then simply that the value of the derivative at that point equals the slope of the tangent line to the the function (curve) at that point? (In general then, the derivative of a function is itself a function whose value at each point equals the slope of the tangent line to the curve at that point).","This question already has answers here : What does it mean to differentiate in calculus? (4 answers) Closed 8 years ago . I understand that the derivative of a function $f$ at a point $x=x_{0}$ is defined as the limit $$f'(x_{0})=\lim_{\Delta x\rightarrow 0}\frac{f(x_{0}+\Delta x)-f(x_{0})}{\Delta x}$$ where $\Delta x$ is a small change in the argument $x$ as we ""move"" from $x=x_{0}$ to a neighbouring point $x=x_{0}+\Delta x$.  What confuses me is how to interpret its meaning correctly, that is, what does the derivative $f'(x_{0})$ actually describe? On Wikipedia it says that "" the derivative of a function quantifies the rate at which the value of the function changes as we change the input "" (or words to that effect). However, the function has a particular constant value, $f(x_{0})$ at a given point $x=x_{0}$ so how can one meaningfully discuss the rate at which the value of the function is changing at that point? Would it be correct to interpret the derivative of a function at a point as describing how ""quickly"" it's value changes as we move from that point to (infinitesimally close) neighbouring points? (As such in the example above, in moving from the point $x_{0}$ to $x_{0}+\Delta x$ the value of the function $f$ changes by an amount $f'(x_{0})\Delta x$ for infinitesimally small change $\Delta x$). Is it then simply that the value of the derivative at that point equals the slope of the tangent line to the the function (curve) at that point? (In general then, the derivative of a function is itself a function whose value at each point equals the slope of the tangent line to the curve at that point).",,"['calculus', 'derivatives', 'intuition']"
29,18th derivative of $\arctan(x^2)$ at point $x=0$,18th derivative of  at point,\arctan(x^2) x=0,$$\frac{\mathrm d^{18}}{\mathrm dx^{18}} \arctan(x^2)$$ Without using Taylor. I relay don't have any idea how to use General Leibniz rule or any other idea how to get result.,$$\frac{\mathrm d^{18}}{\mathrm dx^{18}} \arctan(x^2)$$ Without using Taylor. I relay don't have any idea how to use General Leibniz rule or any other idea how to get result.,,"['calculus', 'real-analysis', 'derivatives']"
30,Derivative of Frobenius norm of matrix logarithm with respect to scalar,Derivative of Frobenius norm of matrix logarithm with respect to scalar,,"I am stuck on finding $t$ such that: $$ \frac{\partial}{\partial t} \left\| \log_m \left( M \Lambda^t M^T \right) \right\|_F = 0$$ where $M$ is $n \times n$ positive definite matrix (not symmetric, not unitary), $\Lambda$ is $n\times n$ diagonal matrix and positive definite, and $t \in (0,1)$ . Found the following link that deals with something similar since $\|A\|_F^2=Tr(AA^T)$ Derivative of matrix involving trace and log . Also this other may help Derivative of a trace w.r.t matrix within log of matrix sums . Any help is really appreciated.","I am stuck on finding such that: where is positive definite matrix (not symmetric, not unitary), is diagonal matrix and positive definite, and . Found the following link that deals with something similar since Derivative of matrix involving trace and log . Also this other may help Derivative of a trace w.r.t matrix within log of matrix sums . Any help is really appreciated.","t  \frac{\partial}{\partial t} \left\| \log_m \left( M \Lambda^t M^T \right) \right\|_F = 0 M n \times n \Lambda n\times n t \in (0,1) \|A\|_F^2=Tr(AA^T)","['calculus', 'matrices', 'derivatives', 'normed-spaces', 'matrix-calculus']"
31,How is this integral equal to this natural logarithm?,How is this integral equal to this natural logarithm?,,"I am trying to understand following problem: $$\int {\sin x \over \cos x}dx = -\int {d \cos x \over \cos x} = - \ln \lvert \cos x\rvert + k $$ I don't really get the final step, are they equal because $ d \cos x = -\sin x$ and the double $-$ makes for a $+$? Resulting in the following: $$\int \tan x = - \ln \lvert \cos x\rvert + k$$ I am not sure of this, because I don't know whether you can simply take the regular suffix of $dx$ and multiply it to the nominator. Or is the $d$ simply standing there because $\sin x$ was transformed into $-\cos x$? Any advice would be greatly appreciated, thanks!","I am trying to understand following problem: $$\int {\sin x \over \cos x}dx = -\int {d \cos x \over \cos x} = - \ln \lvert \cos x\rvert + k $$ I don't really get the final step, are they equal because $ d \cos x = -\sin x$ and the double $-$ makes for a $+$? Resulting in the following: $$\int \tan x = - \ln \lvert \cos x\rvert + k$$ I am not sure of this, because I don't know whether you can simply take the regular suffix of $dx$ and multiply it to the nominator. Or is the $d$ simply standing there because $\sin x$ was transformed into $-\cos x$? Any advice would be greatly appreciated, thanks!",,"['integration', 'derivatives']"
32,Is finding the second derivative of $\sqrt[3]{\vert x\vert}$ the best method to determine if it is convex?,Is finding the second derivative of  the best method to determine if it is convex?,\sqrt[3]{\vert x\vert},"I have an exercise where I have to tell on which intervals a function is concave or convex. I usually do it using second derivative, but I would like to know if there is a simpler way of doing so, because this  gets a little messy for me when considering $ \sqrt[3]{\vert x\vert } $.","I have an exercise where I have to tell on which intervals a function is concave or convex. I usually do it using second derivative, but I would like to know if there is a simpler way of doing so, because this  gets a little messy for me when considering $ \sqrt[3]{\vert x\vert } $.",,"['calculus', 'derivatives', 'convex-analysis', 'absolute-value']"
33,"Fréchét derivative, its inverse and existense of a solution to $X^2 = B$ in an open subset of $M_2 (\mathbb{R})$","Fréchét derivative, its inverse and existense of a solution to  in an open subset of",X^2 = B M_2 (\mathbb{R}),"Let $A = \operatorname{diag}(\lambda_1, \lambda_2) $ and let $f:M_2 (\mathbb{R}) \to M_2 (\mathbb{R}), f(X)= X^2$. We consider an arbitrary matrix norm. If we look at the Fréchét derivative at $A$ of $f$ then we have $f'(A) H=AH + HA$. The first question asks to show that $f'(A)$ is invertible iff $ \lambda_i \neq 0 $ and $ \lambda_1 + \lambda_2 \neq 0$ which is not hard to show. [edited] I need to show that the equation $X^2 =B$ has a solution for $B$ in some neighbourhood of $B_0= \operatorname{diag}(4,1)$. My idea is to consider $g(X)= f(X) -B +X$ and show that a fixed point of $g$ exists, using the Banach fixed point theorem. However (if this is the right idea) I fail to see how to show that $g$ is $q<1$ Lipschitz at a complete subset of $M_2(\mathbb{R}).$","Let $A = \operatorname{diag}(\lambda_1, \lambda_2) $ and let $f:M_2 (\mathbb{R}) \to M_2 (\mathbb{R}), f(X)= X^2$. We consider an arbitrary matrix norm. If we look at the Fréchét derivative at $A$ of $f$ then we have $f'(A) H=AH + HA$. The first question asks to show that $f'(A)$ is invertible iff $ \lambda_i \neq 0 $ and $ \lambda_1 + \lambda_2 \neq 0$ which is not hard to show. [edited] I need to show that the equation $X^2 =B$ has a solution for $B$ in some neighbourhood of $B_0= \operatorname{diag}(4,1)$. My idea is to consider $g(X)= f(X) -B +X$ and show that a fixed point of $g$ exists, using the Banach fixed point theorem. However (if this is the right idea) I fail to see how to show that $g$ is $q<1$ Lipschitz at a complete subset of $M_2(\mathbb{R}).$",,"['real-analysis', 'linear-algebra', 'derivatives', 'frechet-derivative']"
34,Functions whose second derivative is of the same sign,Functions whose second derivative is of the same sign,,"$$\frac{\mathrm{d^{2}} }{\mathrm{d} x^{2}}\psi=\frac{2m}{\hbar^{2}}\left [ V\left ( x \right ) -E\right ]\psi$$ I must show that $E>V\left(x\right)$ for all $x$ for every normalisable solution to the time-independent Schrödinger equation. Let's suppose $\psi$ is a function of $x$, and if $\psi(x)>0$ then $\psi''(x)>0$. Similarly, if $\psi(x)<0$ then $\psi''(x)<0$. A positive derivative indicates an increasing rate of change (convex up and local minima exists) and a negative derivative indicates a decreasing rate of change(concave down and local maxima exists) but why isn't the function able to start and end at $x=0$?","$$\frac{\mathrm{d^{2}} }{\mathrm{d} x^{2}}\psi=\frac{2m}{\hbar^{2}}\left [ V\left ( x \right ) -E\right ]\psi$$ I must show that $E>V\left(x\right)$ for all $x$ for every normalisable solution to the time-independent Schrödinger equation. Let's suppose $\psi$ is a function of $x$, and if $\psi(x)>0$ then $\psi''(x)>0$. Similarly, if $\psi(x)<0$ then $\psi''(x)<0$. A positive derivative indicates an increasing rate of change (convex up and local minima exists) and a negative derivative indicates a decreasing rate of change(concave down and local maxima exists) but why isn't the function able to start and end at $x=0$?",,"['real-analysis', 'derivatives']"
35,How to calculate the local minimum of a hyperbola without using derivatives?,How to calculate the local minimum of a hyperbola without using derivatives?,,"I've got the following rational function, which is a hyperbola. $f(x) = \frac{2\cdot\pi (x+ 4)^2}{x}$$\quad$ on WolframAlpha There is a minimum in the first quadrant and a maximum in the third quadrant. I want to find the minimum in the first quadrant, so I define that $x>0$. Now I want to find this minimum without using the derivation of the function $f(x)$. My idea was to remove somehow the part I don't want to look at (with $x>0$), so the function is not rational anymore. Then I would use the vertex of a parabola notation $\left(-\frac{b}{2a},c-\frac{b^2}{4a}\right)$. (What's the correct name for this in English?) $\frac{2\cdot\pi (x+ 4)^2}{x} \Rightarrow 2\cdot\pi (x+ 4)^2 \Rightarrow 2\pi x^2 + 16\pi x + 32\pi$ This leads to $-\frac{16\pi}{4\pi}$, which leads to $x=-4$. Now where I'm struggling is to get the minimum, because this seems to be the maximum?","I've got the following rational function, which is a hyperbola. $f(x) = \frac{2\cdot\pi (x+ 4)^2}{x}$$\quad$ on WolframAlpha There is a minimum in the first quadrant and a maximum in the third quadrant. I want to find the minimum in the first quadrant, so I define that $x>0$. Now I want to find this minimum without using the derivation of the function $f(x)$. My idea was to remove somehow the part I don't want to look at (with $x>0$), so the function is not rational anymore. Then I would use the vertex of a parabola notation $\left(-\frac{b}{2a},c-\frac{b^2}{4a}\right)$. (What's the correct name for this in English?) $\frac{2\cdot\pi (x+ 4)^2}{x} \Rightarrow 2\cdot\pi (x+ 4)^2 \Rightarrow 2\pi x^2 + 16\pi x + 32\pi$ This leads to $-\frac{16\pi}{4\pi}$, which leads to $x=-4$. Now where I'm struggling is to get the minimum, because this seems to be the maximum?",,"['derivatives', 'rational-functions']"
36,"is there a relation between the fact that the derivative of x^2 is 2x and that the difference between 1,4,9,16, ... is 3, 5, 7, 9, ...?","is there a relation between the fact that the derivative of x^2 is 2x and that the difference between 1,4,9,16, ... is 3, 5, 7, 9, ...?",,"Is there a relation between the fact that the derivative of x^2 is 2x and that the difference between 1,4,9,16, ... is 3, 5, 7, 9, ...? And why is the difference always 2? I think there is a relationship, but I can't get how and why...","Is there a relation between the fact that the derivative of x^2 is 2x and that the difference between 1,4,9,16, ... is 3, 5, 7, 9, ...? And why is the difference always 2? I think there is a relationship, but I can't get how and why...",,"['calculus', 'derivatives']"
37,Derivation of a function over $\frac{1}{\sinh(t)}\frac{d }{dt}$,Derivation of a function over,\frac{1}{\sinh(t)}\frac{d }{dt},"I can not calculate the next derivative, someone has an idea $$\left( \frac{1}{\sinh(t)}\frac{d }{dt} \right)^n \left( e^{z t} \right)$$ Where $n\in \mathbb N$, $t>0$ and $z\in \mathbb C$. Thanks in advance","I can not calculate the next derivative, someone has an idea $$\left( \frac{1}{\sinh(t)}\frac{d }{dt} \right)^n \left( e^{z t} \right)$$ Where $n\in \mathbb N$, $t>0$ and $z\in \mathbb C$. Thanks in advance",,"['calculus', 'real-analysis', 'derivatives', 'special-functions']"
38,"Given that $f''(x)=f(x^2)$, what is $f''(x^3)$","Given that , what is",f''(x)=f(x^2) f''(x^3),I'm pretty sure you can't do $f''(x^3)=f((x^3)^2)$. To Clarify I DO NOT mean $(f(x^3))''$ but $f''(x^3)$,I'm pretty sure you can't do $f''(x^3)=f((x^3)^2)$. To Clarify I DO NOT mean $(f(x^3))''$ but $f''(x^3)$,,['derivatives']
39,How would I take this derivative?,How would I take this derivative?,,"I am not really sure how I would take the following derivative: $\frac{\partial}{\partial r}\left( F(r) \right) = \frac{\partial}{\partial r}\left( \int_{0}^{2 \pi} f(r,\theta) d\theta \right)$ Would it maybe just be: $\frac{d}{dr}\left( F(r) \right)  = \left( \int_{0}^{2 \pi} \frac{\partial f(r,\theta)}{\partial r} d\theta \right)$ Is this right?","I am not really sure how I would take the following derivative: $\frac{\partial}{\partial r}\left( F(r) \right) = \frac{\partial}{\partial r}\left( \int_{0}^{2 \pi} f(r,\theta) d\theta \right)$ Would it maybe just be: $\frac{d}{dr}\left( F(r) \right)  = \left( \int_{0}^{2 \pi} \frac{\partial f(r,\theta)}{\partial r} d\theta \right)$ Is this right?",,"['calculus', 'integration', 'derivatives']"
40,Cusps and Points of Inflection,Cusps and Points of Inflection,,Can cusps be considered points of inflection? I'm getting conflicting information but my thought process is that cusps cannot be points of inflection? Can points of inflection exist when there is a vertical tangent to the graph? Assume there is change in concavity and the function is continuous.,Can cusps be considered points of inflection? I'm getting conflicting information but my thought process is that cusps cannot be points of inflection? Can points of inflection exist when there is a vertical tangent to the graph? Assume there is change in concavity and the function is continuous.,,"['calculus', 'derivatives', 'graphing-functions', 'curves']"
41,Differentiate $[x^{5\coth(6x)}]'$,Differentiate,[x^{5\coth(6x)}]',can you help me to differentiate this function? $$[x^{5\coth(6x)}]'$$ My steps: $$[x^{5\coth(6x)}*\ln(x)]*[5(1-\coth^2(6x))]*[6]$$ I dont know what formula i should use $$[x^n]'$$ or $$[a^x]'$$ thanks for advice.,can you help me to differentiate this function? $$[x^{5\coth(6x)}]'$$ My steps: $$[x^{5\coth(6x)}*\ln(x)]*[5(1-\coth^2(6x))]*[6]$$ I dont know what formula i should use $$[x^n]'$$ or $$[a^x]'$$ thanks for advice.,,"['derivatives', 'hyperbolic-functions']"
42,Calculating a simpler derivative for $\frac{1+\cot x}{2- \sec x}$,Calculating a simpler derivative for,\frac{1+\cot x}{2- \sec x},"So I'm fairly new to derivative exercises, and I am often concerned about the fact that many of my answers are larger than the original function. For example: $$\frac{1+\cot x}{2- \sec x}$$ Becomes $$\frac{-\csc^2x \cdot(2-\sec x) + \sec x \cdot \tan x \cdot (1 + \cot x)}{(2-\sec x)^2}$$ I am assuming that this is technically the right answer, but it is surprisingly long and would probably make things very messy if I try to calculate the second derivative. So my question is, is there a way to simplify this derivate in case I need to calculate yet another derivative? I'm afraid they just keep getting larger.","So I'm fairly new to derivative exercises, and I am often concerned about the fact that many of my answers are larger than the original function. For example: $$\frac{1+\cot x}{2- \sec x}$$ Becomes $$\frac{-\csc^2x \cdot(2-\sec x) + \sec x \cdot \tan x \cdot (1 + \cot x)}{(2-\sec x)^2}$$ I am assuming that this is technically the right answer, but it is surprisingly long and would probably make things very messy if I try to calculate the second derivative. So my question is, is there a way to simplify this derivate in case I need to calculate yet another derivative? I'm afraid they just keep getting larger.",,"['calculus', 'derivatives']"
43,All functions such that $f'(x) = f(x+1)-f(x) = \frac{f(x+2)-f(x)}{2}$ for all $x \in \mathbb{R}$,All functions such that  for all,f'(x) = f(x+1)-f(x) = \frac{f(x+2)-f(x)}{2} x \in \mathbb{R},"I would like to find all (differentiable) functions $\mathbb{R} \to \mathbb{R}$ satisfying $$f'(x) = f(x+1)-f(x) = \frac{f(x+2)-f(x)}{2}$$ for all $x \in \mathbb{R}$. I claim that the only functions are $f(x) = ax+b$ with $a,b \in \mathbb{R}$. My proof goes as the following: Since $f'(x) = f(x+1)-f(x)$ and $f$ is differentiable, $f'$ is differentiable and we have $f''(x) = f'(x+1)-f'(x)$. By assumptions we get $2f'(x)+f(x) = f(x+2)$ and thus $$f'(x+1) = f(x+1+1)-f(x+1) = f(x+2)-f(x+1) = 2f'(x)+f(x)-f(x+1) = 2f'(x)-f'(x) = f'(x)$$ Therefore $f'(x+1)=f'(x)$ for all $x \in \mathbb{R}$, and $f''(x) = 0$ for all $x \in \mathbb{R}$. This proves that $f(x) = ax+b$. Is this proof correct? If not, what is wrong with it and what other functions satisfy these conditions?","I would like to find all (differentiable) functions $\mathbb{R} \to \mathbb{R}$ satisfying $$f'(x) = f(x+1)-f(x) = \frac{f(x+2)-f(x)}{2}$$ for all $x \in \mathbb{R}$. I claim that the only functions are $f(x) = ax+b$ with $a,b \in \mathbb{R}$. My proof goes as the following: Since $f'(x) = f(x+1)-f(x)$ and $f$ is differentiable, $f'$ is differentiable and we have $f''(x) = f'(x+1)-f'(x)$. By assumptions we get $2f'(x)+f(x) = f(x+2)$ and thus $$f'(x+1) = f(x+1+1)-f(x+1) = f(x+2)-f(x+1) = 2f'(x)+f(x)-f(x+1) = 2f'(x)-f'(x) = f'(x)$$ Therefore $f'(x+1)=f'(x)$ for all $x \in \mathbb{R}$, and $f''(x) = 0$ for all $x \in \mathbb{R}$. This proves that $f(x) = ax+b$. Is this proof correct? If not, what is wrong with it and what other functions satisfy these conditions?",,"['real-analysis', 'derivatives', 'proof-verification']"
44,Find the critical numbers of $f(x) = 7x^3 + |x|$. Determine critical numbers at which the tangent line is horizontal,Find the critical numbers of . Determine critical numbers at which the tangent line is horizontal,f(x) = 7x^3 + |x|,"Find the critical numbers of $f(x) = 7x^3 + |x|$. Determine critical numbers at which the tangent line is horizontal Here is what I have so far: I know that $|x|$ can be rewritten as $\sqrt{x^2}$ Differentiating $f(x) = 7x^3 + |x| $ where $f^\prime(x) = 21x^2 + \frac{x}{|x|} $ I have know that a critical number is when $f^\prime(x) = 0$ or undefined. The first critical number would be 0 since it would be undefined. The second critical number would be $\frac{-1}{\sqrt{21}}$. This is also supported when I had graphed the derivative so the tangent line should be horizontal at those two critical numbers. Unfortunately, I'm not even sure if I found all of the critical numbers. Sorry for the format.","Find the critical numbers of $f(x) = 7x^3 + |x|$. Determine critical numbers at which the tangent line is horizontal Here is what I have so far: I know that $|x|$ can be rewritten as $\sqrt{x^2}$ Differentiating $f(x) = 7x^3 + |x| $ where $f^\prime(x) = 21x^2 + \frac{x}{|x|} $ I have know that a critical number is when $f^\prime(x) = 0$ or undefined. The first critical number would be 0 since it would be undefined. The second critical number would be $\frac{-1}{\sqrt{21}}$. This is also supported when I had graphed the derivative so the tangent line should be horizontal at those two critical numbers. Unfortunately, I'm not even sure if I found all of the critical numbers. Sorry for the format.",,"['calculus', 'derivatives']"
45,L'Hospitals Rule on infinite intervals,L'Hospitals Rule on infinite intervals,,"It seems like every proof I see of L'Hospital's rule is on a finite interval, for example my Real Analysis defines L'Hospital's rule as follows: If $f$ and $g$ are differentiable functions defined on an interval $(a,b)$, both of which tend to $0$ at $b$, and if the ratio of their derivatives $\frac{f'(x)}{g'(x)}$ tends to a finite limit $L$ at $b$ then $\frac{f(x)}{g(x)}$ also tends to $L$ at $b$. It is assumed that $g(x), g'(x) \neq 0$ How would I go about proving the result on the interval $[a,\infty]$? What about if $L = \infty$?","It seems like every proof I see of L'Hospital's rule is on a finite interval, for example my Real Analysis defines L'Hospital's rule as follows: If $f$ and $g$ are differentiable functions defined on an interval $(a,b)$, both of which tend to $0$ at $b$, and if the ratio of their derivatives $\frac{f'(x)}{g'(x)}$ tends to a finite limit $L$ at $b$ then $\frac{f(x)}{g(x)}$ also tends to $L$ at $b$. It is assumed that $g(x), g'(x) \neq 0$ How would I go about proving the result on the interval $[a,\infty]$? What about if $L = \infty$?",,"['real-analysis', 'derivatives']"
46,"Show that $f(x,y)$ is differentiable at $(0,0)$",Show that  is differentiable at,"f(x,y) (0,0)","Show that $f(x,y)$ defined by: $$f(x,y) = \begin{cases}\dfrac{x^2y^2}{\sqrt{x^2+y^2}}&\text{ if }(x,y)\not =(0,0)\\0 &\text{ if }(x,y)=(0,0)\end{cases}$$ is differentiable at $(x,y) = (0,0)$ I tried to solve this problem by applying the theorem that if partial derivatives are continuous then the function is differentiable. Therefore, I calculated partial derivated but not I am stuck in showing they are indeed continuous. Help me!","Show that $f(x,y)$ defined by: $$f(x,y) = \begin{cases}\dfrac{x^2y^2}{\sqrt{x^2+y^2}}&\text{ if }(x,y)\not =(0,0)\\0 &\text{ if }(x,y)=(0,0)\end{cases}$$ is differentiable at $(x,y) = (0,0)$ I tried to solve this problem by applying the theorem that if partial derivatives are continuous then the function is differentiable. Therefore, I calculated partial derivated but not I am stuck in showing they are indeed continuous. Help me!",,"['derivatives', 'partial-derivative']"
47,"Is this derivative thing I found a defined mathematical concept? If so, what is it called?","Is this derivative thing I found a defined mathematical concept? If so, what is it called?",,"I'm sure you're aware that $\frac{d^n}{dx^n}\frac{1}{x}=\frac{(-1)^nn!}{x^{n+1}}$ Well, what if $n=\frac{1}{2}$? $$\frac{d^\frac{1}{2}}{dx^\frac{1}{2}}\frac{1}{x}=\frac{(-1)^\frac{1}{2}(\frac{1}{2})!}{x^(\frac{1}{2}+1)}$$ $$\frac{d^\frac{1}{2}}{dx^\frac{1}{2}}\frac{1}{x}=\frac{\sqrt{-1}(\frac{1}{2})!}{x^\frac{3}{2}}$$ So would it be correct to say that: $$\frac{d^\frac{1}{2}}{dx^\frac{1}{2}}\frac{1}{x}=\frac{i\sqrt{\pi}}{x^\frac{3}{2}}$$ Or am I just an idiot? Please tell me. :)","I'm sure you're aware that $\frac{d^n}{dx^n}\frac{1}{x}=\frac{(-1)^nn!}{x^{n+1}}$ Well, what if $n=\frac{1}{2}$? $$\frac{d^\frac{1}{2}}{dx^\frac{1}{2}}\frac{1}{x}=\frac{(-1)^\frac{1}{2}(\frac{1}{2})!}{x^(\frac{1}{2}+1)}$$ $$\frac{d^\frac{1}{2}}{dx^\frac{1}{2}}\frac{1}{x}=\frac{\sqrt{-1}(\frac{1}{2})!}{x^\frac{3}{2}}$$ So would it be correct to say that: $$\frac{d^\frac{1}{2}}{dx^\frac{1}{2}}\frac{1}{x}=\frac{i\sqrt{\pi}}{x^\frac{3}{2}}$$ Or am I just an idiot? Please tell me. :)",,"['calculus', 'derivatives', 'complex-numbers', 'fractional-calculus']"
48,Determine the values of a and b that makes the function differentiable everywhere,Determine the values of a and b that makes the function differentiable everywhere,,"Given $$f(x)=ax^3\cos(1/x)+bx+b$$ for $$x<0$$ and $$f(x)=\sqrt{a+bx}$$ for $$x\ge0$$ Where $$a,b$$ are positive constants. Determine the values of a and b, if any, that make f differentiable everywhere. Proposed solution: (1) $$f'(x)=3ax^2\cos(\frac{1}{x})+ax\sin(\frac{1}{x})+b$$ and (2) $$f'(x)=\frac{1}{2}(a+bx)^{-\frac{1}{2}}b$$ From (2), $$f(0)=a^{\frac{1}{2}}, f'(0)=\frac{1}{2}(a^{-\frac{1}{2}})b$$ and From (1), $$\lim_{x \rightarrow 0-}f(x)=b$$ (Using Squeeze theorem) Since differentiability implies continuity, (3) $$\lim_{x \rightarrow 0-}f(x)=\lim_{x \rightarrow 0}f(x)=b=f(0)=a^{\frac{1}{2}}$$ For f(x) to be differentiable at 0, using (3), $$\frac{1}{2}=3ax^2\cos(\frac{1}{x})+ax\sin(\frac{1}{x})+a^{\frac{1}{2}}$$ which is unsolvable. So a,b does not exist. Am I right? Thanks.","Given $$f(x)=ax^3\cos(1/x)+bx+b$$ for $$x<0$$ and $$f(x)=\sqrt{a+bx}$$ for $$x\ge0$$ Where $$a,b$$ are positive constants. Determine the values of a and b, if any, that make f differentiable everywhere. Proposed solution: (1) $$f'(x)=3ax^2\cos(\frac{1}{x})+ax\sin(\frac{1}{x})+b$$ and (2) $$f'(x)=\frac{1}{2}(a+bx)^{-\frac{1}{2}}b$$ From (2), $$f(0)=a^{\frac{1}{2}}, f'(0)=\frac{1}{2}(a^{-\frac{1}{2}})b$$ and From (1), $$\lim_{x \rightarrow 0-}f(x)=b$$ (Using Squeeze theorem) Since differentiability implies continuity, (3) $$\lim_{x \rightarrow 0-}f(x)=\lim_{x \rightarrow 0}f(x)=b=f(0)=a^{\frac{1}{2}}$$ For f(x) to be differentiable at 0, using (3), $$\frac{1}{2}=3ax^2\cos(\frac{1}{x})+ax\sin(\frac{1}{x})+a^{\frac{1}{2}}$$ which is unsolvable. So a,b does not exist. Am I right? Thanks.",,"['calculus', 'derivatives', 'continuity']"
49,Proof that applying the difference operator to a $d$-degree polynomial $d$ times yields $d!a_d$,Proof that applying the difference operator to a -degree polynomial  times yields,d d d!a_d,"Let $L$ be the lag operator and $\triangledown:=(1-L)$ be the difference operator , that is, given a polynomial $p(t)$, we have  $$L(p(t))=p(t-1)\qquad \triangledown(p(t))=p(t) - p(t-1)$$ I am interested in proving that   $$ \triangledown^d \sum_{i=0}^{d}a_it^i = a_dd! $$ It can be shown that $c<d \implies \triangledown^dt^c=0$. Hence, the above polynomial should (?) be equivalent to $$ \triangledown^da_dt^d  $$ which, together with the linearity of the difference operator, suggests that the problem is equivalent to prove that $$ a_d(\triangledown^dt^d) = (a_d)d!  $$  that is $$ \triangledown^dt^d = d!  $$  or, equivalently $$ \triangledown^dt^d = (1-L)^dt^d=\sum_{k=0}^{d}(-1)^{d-k}\binom{d}{k}L^k(t)^d = d! \iff $$  $$ \triangledown^dt^d = (1-L)^dt^d=\sum_{k=0}^{d}(-1)^{d-k}\binom{d}{k}(t-k)^d = d! $$  but from this point I am stuck. I would like to tag the entry with a Lag-operator tag but do not have sufficient reputation yet. Any help would be much appreciated.","Let $L$ be the lag operator and $\triangledown:=(1-L)$ be the difference operator , that is, given a polynomial $p(t)$, we have  $$L(p(t))=p(t-1)\qquad \triangledown(p(t))=p(t) - p(t-1)$$ I am interested in proving that   $$ \triangledown^d \sum_{i=0}^{d}a_it^i = a_dd! $$ It can be shown that $c<d \implies \triangledown^dt^c=0$. Hence, the above polynomial should (?) be equivalent to $$ \triangledown^da_dt^d  $$ which, together with the linearity of the difference operator, suggests that the problem is equivalent to prove that $$ a_d(\triangledown^dt^d) = (a_d)d!  $$  that is $$ \triangledown^dt^d = d!  $$  or, equivalently $$ \triangledown^dt^d = (1-L)^dt^d=\sum_{k=0}^{d}(-1)^{d-k}\binom{d}{k}L^k(t)^d = d! \iff $$  $$ \triangledown^dt^d = (1-L)^dt^d=\sum_{k=0}^{d}(-1)^{d-k}\binom{d}{k}(t-k)^d = d! $$  but from this point I am stuck. I would like to tag the entry with a Lag-operator tag but do not have sufficient reputation yet. Any help would be much appreciated.",,"['derivatives', 'polynomials']"
50,Integral of $2^{2^{2^x}}$?,Integral of ?,2^{2^{2^x}},"$$\int2^{2^{2^x}}~\mathrm{d}x$$ Derivative is $\ln^3(2)2^{2^x+x+2^{2^x}}$. So no substitution technique can be used. So please guide, I am confused. Is this elliptic?","$$\int2^{2^{2^x}}~\mathrm{d}x$$ Derivative is $\ln^3(2)2^{2^x+x+2^{2^x}}$. So no substitution technique can be used. So please guide, I am confused. Is this elliptic?",,"['integration', 'derivatives', 'indefinite-integrals']"
51,How do I prove that the $f(x)$ is positive for all real $x$?,How do I prove that the  is positive for all real ?,f(x) x,"$$ \frac {f(x+y) - f(x)}{2}= \frac{f(y)-a}{2} +xy $$  for all real $x$ and $y$. If $f(x)$ is differentiable and $f'(0)$ exists for all real permisible values of $a$ and is equal to $\sqrt{5a-1-a^2}$. Prove that $f(x)$ is positive for all real $x$. I differentiated the equation keeping $x$ constant and then put $y=0$ and then integrated and got $f(x)$ as $$f(x)= x^2 +x\sqrt{5a-1-a^2}+c$$ by putting $x=y=0$ in  $$ \frac {f(x+y) - f(x)}{2}= \frac{f(y)-a}{2} +xy $$  I got $f(0) =a$ so I finally got the function as  $$f(x)= x^2 +x\sqrt{5a-1-a^2}+a.$$ Now how should I proceed, will $b^2 -4ac <0 $ help?","$$ \frac {f(x+y) - f(x)}{2}= \frac{f(y)-a}{2} +xy $$  for all real $x$ and $y$. If $f(x)$ is differentiable and $f'(0)$ exists for all real permisible values of $a$ and is equal to $\sqrt{5a-1-a^2}$. Prove that $f(x)$ is positive for all real $x$. I differentiated the equation keeping $x$ constant and then put $y=0$ and then integrated and got $f(x)$ as $$f(x)= x^2 +x\sqrt{5a-1-a^2}+c$$ by putting $x=y=0$ in  $$ \frac {f(x+y) - f(x)}{2}= \frac{f(y)-a}{2} +xy $$  I got $f(0) =a$ so I finally got the function as  $$f(x)= x^2 +x\sqrt{5a-1-a^2}+a.$$ Now how should I proceed, will $b^2 -4ac <0 $ help?",,"['calculus', 'derivatives', 'partial-derivative', 'quadratics']"
52,How to find unkown height of triangle without hyptenuse,How to find unkown height of triangle without hyptenuse,,"I been trying to solve this question and have tried to solve it for many days, but do not know how, any help would be much oblidged. A cable company owns the roads marked with the dotted lines in the figure, and it costs the cable company 25 dollars per foot to run the line on poles along the county roads. The area bounded by the house and roads is a privately owned field, ant the cable company must pay for an easement to run lines underground in the field. It is also more costly for the company to run the line underground than to run them on the poles. The total cost to run lines underground across the field is $52 per foot. Whilst to run the cable via pole 46% less than to run it underground. Image: https://i.sstatic.net/2A5ib.jpg The cable company has the choice of running the lines line along the road or cutting across the field. I. Advise the company on the costings to the company to run lines both along the road to H and directly across the field. II. What would the critical distance that the piped must be laid which will contribute to a minimum costings to the company. For part I, I had used pythagor's theorem to find the distance of PH and multiply it by the respective costs of the material. However for II, I am a bit stumped. The critical distance is defined as the distance from p to the second point on the line, let us call it G. So critical distance is equal to PG, however, I do not know how to find it since the value of that hypotenuse is not given, and the height is ewual to (100-x). Plugging in this value in the theorem gives an unimaginably large expression without any real roots. Any help would be much oblidged.","I been trying to solve this question and have tried to solve it for many days, but do not know how, any help would be much oblidged. A cable company owns the roads marked with the dotted lines in the figure, and it costs the cable company 25 dollars per foot to run the line on poles along the county roads. The area bounded by the house and roads is a privately owned field, ant the cable company must pay for an easement to run lines underground in the field. It is also more costly for the company to run the line underground than to run them on the poles. The total cost to run lines underground across the field is $52 per foot. Whilst to run the cable via pole 46% less than to run it underground. Image: https://i.sstatic.net/2A5ib.jpg The cable company has the choice of running the lines line along the road or cutting across the field. I. Advise the company on the costings to the company to run lines both along the road to H and directly across the field. II. What would the critical distance that the piped must be laid which will contribute to a minimum costings to the company. For part I, I had used pythagor's theorem to find the distance of PH and multiply it by the respective costs of the material. However for II, I am a bit stumped. The critical distance is defined as the distance from p to the second point on the line, let us call it G. So critical distance is equal to PG, however, I do not know how to find it since the value of that hypotenuse is not given, and the height is ewual to (100-x). Plugging in this value in the theorem gives an unimaginably large expression without any real roots. Any help would be much oblidged.",,"['calculus', 'algebra-precalculus', 'trigonometry', 'derivatives', 'economics']"
53,Enlighten me... the science behind differentiation [duplicate],Enlighten me... the science behind differentiation [duplicate],,"This question already has answers here : Where is the flaw in this ""proof"" that 1=2? (Derivative of repeated addition) (11 answers) Closed 8 years ago . This a tricky math question I encountered. I know a little bit about the answer. But I want somebody who is very good at math to help me find the real reason behind this. OK Lets start $1^2 = 1$ $2^2 = 2+2$ $3^2 = 3+3+3$ ........................... ................................ $x^2 = x+x+x+x+.....(x times)$ Differentiating with respect to $x$ We get $2x = 1+1+1+1...... (x times)$ which is equal to $2x = 1*x$ $2x = x$ Which is incorrect. Where did I go wrong?? :O :O","This question already has answers here : Where is the flaw in this ""proof"" that 1=2? (Derivative of repeated addition) (11 answers) Closed 8 years ago . This a tricky math question I encountered. I know a little bit about the answer. But I want somebody who is very good at math to help me find the real reason behind this. OK Lets start $1^2 = 1$ $2^2 = 2+2$ $3^2 = 3+3+3$ ........................... ................................ $x^2 = x+x+x+x+.....(x times)$ Differentiating with respect to $x$ We get $2x = 1+1+1+1...... (x times)$ which is equal to $2x = 1*x$ $2x = x$ Which is incorrect. Where did I go wrong?? :O :O",,"['derivatives', 'implicit-differentiation']"
54,Finding first and second derivative of an function with an absolute value,Finding first and second derivative of an function with an absolute value,,"Given the equation $f(x)= |x^2-9|$ where $-4\le x\le 5$, I must find the extremes, as well as the concavities. This I know how to do. The issue is I'm unfamiliar on how to find the first and second derivative of the given function. Thanks in advance.","Given the equation $f(x)= |x^2-9|$ where $-4\le x\le 5$, I must find the extremes, as well as the concavities. This I know how to do. The issue is I'm unfamiliar on how to find the first and second derivative of the given function. Thanks in advance.",,"['calculus', 'derivatives', 'graphing-functions', 'absolute-value']"
55,Stochastic calculus - Ito confusion,Stochastic calculus - Ito confusion,,"We have $W(t) = f(t)X(t)$. My textbook says that $dW = fdX + X\dfrac{df}{dt} dt$. I don't get how they arrived at this conclusion. I get the first part, because $\dfrac{dW}{dX}dX = fdX$. But for the second part, I have no clue how they arrived there. $(\dfrac{dW}{dt} + \dfrac{1}{2} \dfrac{d^2W}{dX^2})dt \stackrel{?}{=} X\dfrac{df}{dt} dt$ If so, could someone please explain why?","We have $W(t) = f(t)X(t)$. My textbook says that $dW = fdX + X\dfrac{df}{dt} dt$. I don't get how they arrived at this conclusion. I get the first part, because $\dfrac{dW}{dX}dX = fdX$. But for the second part, I have no clue how they arrived there. $(\dfrac{dW}{dt} + \dfrac{1}{2} \dfrac{d^2W}{dX^2})dt \stackrel{?}{=} X\dfrac{df}{dt} dt$ If so, could someone please explain why?",,"['derivatives', 'stochastic-calculus']"
56,"Logarithmic Differentiation equation, Help!","Logarithmic Differentiation equation, Help!",,"So, I have to differentiate this via $\log$. I am still learning, so please be patient, I will try to explain everything I did. Please tell me if it is correct. $$y=\frac{(x+3)^4(2x^2+5x)^3}{\sqrt{4x-3}}$$ $$\ln(y) = \ln\left((x+3)^4(2x^2+5x)^3)\right) - \ln\left(\sqrt{4x-3}\right)$$ $$\ln(y) = 4\ln(x+3) 3\ln(2x^2+5x) - \frac{1}{2} \ln(4x-3)$$ aaaaaaaaand don't know what to do next, any help in the process or next step?","So, I have to differentiate this via $\log$. I am still learning, so please be patient, I will try to explain everything I did. Please tell me if it is correct. $$y=\frac{(x+3)^4(2x^2+5x)^3}{\sqrt{4x-3}}$$ $$\ln(y) = \ln\left((x+3)^4(2x^2+5x)^3)\right) - \ln\left(\sqrt{4x-3}\right)$$ $$\ln(y) = 4\ln(x+3) 3\ln(2x^2+5x) - \frac{1}{2} \ln(4x-3)$$ aaaaaaaaand don't know what to do next, any help in the process or next step?",,"['calculus', 'derivatives', 'logarithms', 'implicit-differentiation']"
57,Find derivative of integrate square function [closed],Find derivative of integrate square function [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I am finding a solution of that function. Could you have me to resolve it $$F=\left( \int {(ax+b-c)}^2 dx \right) +\lambda_1(a-m)^2+\lambda_2(b-n)^2$$ where $c,m,n ,\lambda_1,\lambda_2$ are constant How to find $$ \frac{\partial F}{\partial a}=?$$ $$ \frac{\partial F}{\partial b}=?$$ $$ \frac{\partial F}{\partial x}=?$$ Update: Sorry, I just one more require How to find $a,b,x$ if I set $$ \frac{\partial F}{\partial a}=0$$ $$ \frac{\partial F}{\partial b}=0$$ $$ \frac{\partial F}{\partial x}=0$$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I am finding a solution of that function. Could you have me to resolve it $$F=\left( \int {(ax+b-c)}^2 dx \right) +\lambda_1(a-m)^2+\lambda_2(b-n)^2$$ where $c,m,n ,\lambda_1,\lambda_2$ are constant How to find $$ \frac{\partial F}{\partial a}=?$$ $$ \frac{\partial F}{\partial b}=?$$ $$ \frac{\partial F}{\partial x}=?$$ Update: Sorry, I just one more require How to find $a,b,x$ if I set $$ \frac{\partial F}{\partial a}=0$$ $$ \frac{\partial F}{\partial b}=0$$ $$ \frac{\partial F}{\partial x}=0$$",,"['calculus', 'integration', 'derivatives', 'partial-derivative']"
58,Diffeomorphism from disk to plane,Diffeomorphism from disk to plane,,"I want to show that the disk $D = \{(x,y) \in \mathbb R^2 : x^2+y^2 < 1\}$, the open square $K = (-1, 1)^2$ and the whole plane $\mathbb R^2$ are all diffeomorphic to each other. Therefore I want to consider two functions, namely $$f \colon D \to \mathbb R^2, \quad f(x,y) = \left(\frac{x^2+y^2}{1-x^2-y^2} \cdot x, \frac{x^2+y^2}{1-x^2-y^2} \cdot y \right)$$ and $$g \colon K \to \mathbb R^2 = \left(\tan \frac{\pi x}{2}, \tan \frac{\pi y}{2}\right).$$ After calculating partial derivatives I know that both are differentiable (just like their inverses), but how to prove that they are even $C^\infty$ (e.g. infinitely often differentiable)?","I want to show that the disk $D = \{(x,y) \in \mathbb R^2 : x^2+y^2 < 1\}$, the open square $K = (-1, 1)^2$ and the whole plane $\mathbb R^2$ are all diffeomorphic to each other. Therefore I want to consider two functions, namely $$f \colon D \to \mathbb R^2, \quad f(x,y) = \left(\frac{x^2+y^2}{1-x^2-y^2} \cdot x, \frac{x^2+y^2}{1-x^2-y^2} \cdot y \right)$$ and $$g \colon K \to \mathbb R^2 = \left(\tan \frac{\pi x}{2}, \tan \frac{\pi y}{2}\right).$$ After calculating partial derivatives I know that both are differentiable (just like their inverses), but how to prove that they are even $C^\infty$ (e.g. infinitely often differentiable)?",,['real-analysis']
59,Why do we define curves on manifolds via the objects $\phi\circ\gamma$?,Why do we define curves on manifolds via the objects ?,\phi\circ\gamma,"Consider the following definition: ($M$ denotes a manifold structure, $U$ are subsets of the manifold and $\phi$ the transition functions) Def :   A smooth curve in $M$ is a map $\gamma: I \rightarrow M,$ where $I \subset \mathbb{R}$ is an open interval, such that for any chart $(U,\phi)$, the map $\phi \circ \gamma : I \rightarrow \mathbb{R}^n$ is smooth. My first question is, why do we define a smooth curve in this way? In particular, why is the map $\phi \circ \gamma$ a good object to consider? The only thing that comes to mind is that now we have a function defined from $\mathbb{R} \rightarrow \mathbb{R}^n$ so differentiation is well defined and thus one may introduce the concept of a tangent vector (as below). Now let $f: M \rightarrow \mathbb{R}$ be a smooth function on $M$ and $\gamma: I \rightarrow M$, smooth curve as before. Then $f \circ \gamma : I \rightarrow \mathbb{R}$ is smooth. Hence we take a derivative to find the rate of change of $f$ along the curve $\gamma$: $$\frac{d}{dt}f(\gamma(t)) = [(f \circ \phi^{-1}) \circ (\phi \circ \gamma)]'(t) = \sum_{i=1}^n \left(\frac{\partial (f \circ \phi^{-1})}{\partial x^i}\right)_{\phi(\gamma(t))} \frac{d}{dt} x^i(\gamma(t))$$ My next question is to simply understand how this equation comes about. I can see it is some application of the chain rule but I am struggling with the precise details of the equation, mostly in how the final equality comes about and the subscript on the  $\partial (f \circ \phi^{-1})/\partial x^i$  term.  Many thanks!","Consider the following definition: ($M$ denotes a manifold structure, $U$ are subsets of the manifold and $\phi$ the transition functions) Def :   A smooth curve in $M$ is a map $\gamma: I \rightarrow M,$ where $I \subset \mathbb{R}$ is an open interval, such that for any chart $(U,\phi)$, the map $\phi \circ \gamma : I \rightarrow \mathbb{R}^n$ is smooth. My first question is, why do we define a smooth curve in this way? In particular, why is the map $\phi \circ \gamma$ a good object to consider? The only thing that comes to mind is that now we have a function defined from $\mathbb{R} \rightarrow \mathbb{R}^n$ so differentiation is well defined and thus one may introduce the concept of a tangent vector (as below). Now let $f: M \rightarrow \mathbb{R}$ be a smooth function on $M$ and $\gamma: I \rightarrow M$, smooth curve as before. Then $f \circ \gamma : I \rightarrow \mathbb{R}$ is smooth. Hence we take a derivative to find the rate of change of $f$ along the curve $\gamma$: $$\frac{d}{dt}f(\gamma(t)) = [(f \circ \phi^{-1}) \circ (\phi \circ \gamma)]'(t) = \sum_{i=1}^n \left(\frac{\partial (f \circ \phi^{-1})}{\partial x^i}\right)_{\phi(\gamma(t))} \frac{d}{dt} x^i(\gamma(t))$$ My next question is to simply understand how this equation comes about. I can see it is some application of the chain rule but I am struggling with the precise details of the equation, mostly in how the final equality comes about and the subscript on the  $\partial (f \circ \phi^{-1})/\partial x^i$  term.  Many thanks!",,"['linear-algebra', 'differential-geometry', 'derivatives', 'manifolds', 'curves']"
60,Related Rates Question With Cylinder?,Related Rates Question With Cylinder?,,"On a test we needed to solve the following question: A right circular cylinder with a constant volume is decreasing in   height at a rate of 0.2 in/sec. At the moment that the height is 4   inches and the radius is 3 inches, what is the rate at which the   radius is decreasing? After the test I still don't know the actual answer, however I am quite curious about what the answer should have been. What I tried was the following. Givens: $V=(\pi)r^2(h)$ $V=(\pi)(3)^2(4)$ $V=36 \pi$ $r=3$ $h=4$ $dh/dt=-0.2$ in /sec $dr/dt=?$ Work: $V=(\pi)r^2(h)$ $36\pi=(\pi)r^2(dh/dt)+h(2\pi(r)(dr/dt))$ $36\pi=(\pi)(3)^2(-0.2)+4(2\pi(3)(dr/dt))$ $36\pi=9(\pi)(-0.2)+24(\pi)(4dr/dt)$ $36\pi=-1.8(\pi)+24(\pi)(4dr/dt)$ $37.8\pi=24(\pi)(4dr/dt)$ $37.8\pi/24(\pi)=(24(\pi)(4dr/dt))/24(\pi)$ $1.6 \pi=4(dr/dt)$ $dr/dr=0.4\pi$ in/sec Could you tell me what I did was correct or did I make any mistakes? All help is greatly appreciated.","On a test we needed to solve the following question: A right circular cylinder with a constant volume is decreasing in   height at a rate of 0.2 in/sec. At the moment that the height is 4   inches and the radius is 3 inches, what is the rate at which the   radius is decreasing? After the test I still don't know the actual answer, however I am quite curious about what the answer should have been. What I tried was the following. Givens: $V=(\pi)r^2(h)$ $V=(\pi)(3)^2(4)$ $V=36 \pi$ $r=3$ $h=4$ $dh/dt=-0.2$ in /sec $dr/dt=?$ Work: $V=(\pi)r^2(h)$ $36\pi=(\pi)r^2(dh/dt)+h(2\pi(r)(dr/dt))$ $36\pi=(\pi)(3)^2(-0.2)+4(2\pi(3)(dr/dt))$ $36\pi=9(\pi)(-0.2)+24(\pi)(4dr/dt)$ $36\pi=-1.8(\pi)+24(\pi)(4dr/dt)$ $37.8\pi=24(\pi)(4dr/dt)$ $37.8\pi/24(\pi)=(24(\pi)(4dr/dt))/24(\pi)$ $1.6 \pi=4(dr/dt)$ $dr/dr=0.4\pi$ in/sec Could you tell me what I did was correct or did I make any mistakes? All help is greatly appreciated.",,"['calculus', 'derivatives']"
61,When does differentiability of $g\circ f$ and $f$ resp. $g$ imply differentiablity of $g$ resp. $f$?,When does differentiability of  and  resp.  imply differentiablity of  resp. ?,g\circ f f g g f,"To me the following seems intuitively true: If $f$ is differentiable at $x$ with surjective derivative then $g$ is differentiable at $f(x)$ iff $g\circ f$ is differentiable at $x$. On the other hand, if $g$ is differentiable at $f(x)$ with injective derivative then $f$ is differentiable at $x$ iff $g\circ f$ is differentiable at $x$. I assume $f,g$ to be mappings between Banach spaces but I guess this should not make a huge difference.","To me the following seems intuitively true: If $f$ is differentiable at $x$ with surjective derivative then $g$ is differentiable at $f(x)$ iff $g\circ f$ is differentiable at $x$. On the other hand, if $g$ is differentiable at $f(x)$ with injective derivative then $f$ is differentiable at $x$ iff $g\circ f$ is differentiable at $x$. I assume $f,g$ to be mappings between Banach spaces but I guess this should not make a huge difference.",,"['calculus', 'derivatives', 'banach-spaces', 'function-and-relation-composition']"
62,An example of a function for which the equality $M_1 = 2 \sqrt{M_0M_2}$ holds.,An example of a function for which the equality  holds.,M_1 = 2 \sqrt{M_0M_2},"Let $f$ be twice differentiable on $(a,\infty),a\in \Bbb R$ and let  $$M_k = \sup \{|f^k(x)|\mid x \in (a, \infty) \} < \infty, k=0,1,2.$$ $a)$ Prove that $M_1 \leq 2 \sqrt{M_0M_2}$. $b)$ Give an example of a function for which the equality $M_1 = 2 \sqrt{M_0M_2}$ holds. I have done the first part. But help needed for the example in the second part!!","Let $f$ be twice differentiable on $(a,\infty),a\in \Bbb R$ and let  $$M_k = \sup \{|f^k(x)|\mid x \in (a, \infty) \} < \infty, k=0,1,2.$$ $a)$ Prove that $M_1 \leq 2 \sqrt{M_0M_2}$. $b)$ Give an example of a function for which the equality $M_1 = 2 \sqrt{M_0M_2}$ holds. I have done the first part. But help needed for the example in the second part!!",,"['calculus', 'real-analysis', 'derivatives']"
63,Differentiating under the summation,Differentiating under the summation,,"I saw on the Wikipedia page for differentiation under the integral that it could also be applied to summations. Here is the link: http://en.wikipedia.org/wiki/Differentiation_under_the_integral_sign#Applications_to_series It says exactly that ""Differentiating under the integral can also be applied to differentiating under summation, interpreting summation as counting measure. An example of an application is the fact that power series are differentiable in their radius of convergence."" Does this mean that I can use differentiation under the summation to evaluate a series? If so, can someone give an example for me to see?","I saw on the Wikipedia page for differentiation under the integral that it could also be applied to summations. Here is the link: http://en.wikipedia.org/wiki/Differentiation_under_the_integral_sign#Applications_to_series It says exactly that ""Differentiating under the integral can also be applied to differentiating under summation, interpreting summation as counting measure. An example of an application is the fact that power series are differentiable in their radius of convergence."" Does this mean that I can use differentiation under the summation to evaluate a series? If so, can someone give an example for me to see?",,['calculus']
64,"Curvature of plane curve, formula disagrees with Mathematica?","Curvature of plane curve, formula disagrees with Mathematica?",,I have the following equation $$y=\pi\ln(2x)$$ And when I ask Mathematica/WolframAlpha for the curvature I get $$K=\frac{\pi x}{(x^2+\pi^2)^{3/2}}$$ However the formula for curvature of a plane curve is: $$K = \frac{|y''|}{(1+y'^2)^{3/2}}$$ Which when using $$y'=\frac{\pi}{x}$$ $$y''=-\frac{\pi}{x^2}$$ Which are both taken from WolframAlpha\Mathematica we find $$K = \frac{\pi}{(1+ \frac{\pi^2}{x^2})^{3/2}x^2}$$ I've tested for equivalence between the two functions in Mathematica and they aren't the same. Can someone please explain how the Mathematica answer for curviture is reached or verify that my calculated curvature is correct?,I have the following equation $$y=\pi\ln(2x)$$ And when I ask Mathematica/WolframAlpha for the curvature I get $$K=\frac{\pi x}{(x^2+\pi^2)^{3/2}}$$ However the formula for curvature of a plane curve is: $$K = \frac{|y''|}{(1+y'^2)^{3/2}}$$ Which when using $$y'=\frac{\pi}{x}$$ $$y''=-\frac{\pi}{x^2}$$ Which are both taken from WolframAlpha\Mathematica we find $$K = \frac{\pi}{(1+ \frac{\pi^2}{x^2})^{3/2}x^2}$$ I've tested for equivalence between the two functions in Mathematica and they aren't the same. Can someone please explain how the Mathematica answer for curviture is reached or verify that my calculated curvature is correct?,,"['derivatives', 'curvature', 'wolfram-alpha']"
65,Partial differentiation of a integral,Partial differentiation of a integral,,"If I have: $$f(x,y)=\int_{x}^{y}e^{-t^2}dt$$ To calculate that, I change the t to y and x to get: $$e^{-y^2}(e^{-y^2})'-e^{-x^2}(e^{-x^2})$$ With the differentials being in respect to x and y for each partial derivative?","If I have: $$f(x,y)=\int_{x}^{y}e^{-t^2}dt$$ To calculate that, I change the t to y and x to get: $$e^{-y^2}(e^{-y^2})'-e^{-x^2}(e^{-x^2})$$ With the differentials being in respect to x and y for each partial derivative?",,"['calculus', 'integration', 'derivatives', 'partial-derivative']"
66,Real roots of $p(x)=x^n+ax+b$,Real roots of,p(x)=x^n+ax+b,What can we say about the real roots of $p(x)$? My Work: If $n$ is odd I found that $p$ has at most $3$ real roots if $a<0$ and $p$ has at most $1$ real root if $a\geq 0$. How can I classify the roots of $p$ like this when $n$ is even? I got that when $n$ is even $p'(x)=nx^{n-1}+a$. Since $n-1$ is odd $p'(x)$ has exactly one real root. Then $p$ has either $1$ root or $2$ roots or no roots. But how can I classify it exactly? I am stuck. Can anyone please help me?,What can we say about the real roots of $p(x)$? My Work: If $n$ is odd I found that $p$ has at most $3$ real roots if $a<0$ and $p$ has at most $1$ real root if $a\geq 0$. How can I classify the roots of $p$ like this when $n$ is even? I got that when $n$ is even $p'(x)=nx^{n-1}+a$. Since $n-1$ is odd $p'(x)$ has exactly one real root. Then $p$ has either $1$ root or $2$ roots or no roots. But how can I classify it exactly? I am stuck. Can anyone please help me?,,"['real-analysis', 'derivatives', 'polynomials']"
67,$dy$ by $dx$ or $dy$ divided by $dx$,by  or  divided by,dy dx dy dx,"I was always taught do not say ""$dy$ divided by $dx$"", instead ""$dy$ by $dx$"" because it's not really dividing. I then studied differentiation from first principles, where one takes two points on a curve: eg. $(x, y)$ and $(x+\delta x, y+\delta y)$ $$\therefore \text{ gradient} = \frac{(y+\delta y)- y}{(x+\delta x) - x}$$ I'll skip the continuation but one gets the derivative of the equation through some algebra. If you simply expand the brackets instantly you simplify it to $\frac{\delta y}{\delta x}$ which is a division. Firstly, why is the sign different - is it just because it is easier to right $d$ than $\delta$? Secondly, why can one not say $dy$ divided by $dx$? Thanks","I was always taught do not say ""$dy$ divided by $dx$"", instead ""$dy$ by $dx$"" because it's not really dividing. I then studied differentiation from first principles, where one takes two points on a curve: eg. $(x, y)$ and $(x+\delta x, y+\delta y)$ $$\therefore \text{ gradient} = \frac{(y+\delta y)- y}{(x+\delta x) - x}$$ I'll skip the continuation but one gets the derivative of the equation through some algebra. If you simply expand the brackets instantly you simplify it to $\frac{\delta y}{\delta x}$ which is a division. Firstly, why is the sign different - is it just because it is easier to right $d$ than $\delta$? Secondly, why can one not say $dy$ divided by $dx$? Thanks",,"['calculus', 'derivatives']"
68,Differentiability/continuity of piecewise defined functions,Differentiability/continuity of piecewise defined functions,,"Let $$f(x)=\begin{cases}x^2\sin(\frac{1}{x}), &x\not= 0,\\ 0, &x = 0.\end{cases}$$ Since I can differentiate both parts of this, technically, $f$ is differentiable for all $x$. However I have written down in my notes that $f'(x)$ is not even continuous at $0$ and thus not differentiable. However, I am confused about this because isn't my original function not continuous?","Let $$f(x)=\begin{cases}x^2\sin(\frac{1}{x}), &x\not= 0,\\ 0, &x = 0.\end{cases}$$ Since I can differentiate both parts of this, technically, $f$ is differentiable for all $x$. However I have written down in my notes that $f'(x)$ is not even continuous at $0$ and thus not differentiable. However, I am confused about this because isn't my original function not continuous?",,"['calculus', 'derivatives', 'continuity']"
69,Explain why $|x^2-x|$ is not differentiable at $x=1$,Explain why  is not differentiable at,|x^2-x| x=1,Explain why $|x^2-x|$ is not differentiable at $x=1$..... lets go.... we need to show that $\lim_{a\to0}$ of $\frac{f(1+a)-f(1)}{a}$ doesn't exist...which is to say $\lim_{a\to0}$ of $\frac{(|(1+a)^2 - (1+a)|- |1^2-1|)}{a}$ doesn't exist which is like $\lim_{a\to0}$ of $\frac{(|(a)^2 + a|)}{a}$ so we take off absolute value (Is this allowed?) and get  $\lim_{a\to0}$ of $\frac{((a)^2 + a)}{a}$ which is $1$ Not quite what expected...How do we do this?,Explain why $|x^2-x|$ is not differentiable at $x=1$..... lets go.... we need to show that $\lim_{a\to0}$ of $\frac{f(1+a)-f(1)}{a}$ doesn't exist...which is to say $\lim_{a\to0}$ of $\frac{(|(1+a)^2 - (1+a)|- |1^2-1|)}{a}$ doesn't exist which is like $\lim_{a\to0}$ of $\frac{(|(a)^2 + a|)}{a}$ so we take off absolute value (Is this allowed?) and get  $\lim_{a\to0}$ of $\frac{((a)^2 + a)}{a}$ which is $1$ Not quite what expected...How do we do this?,,"['calculus', 'derivatives']"
70,Whats the derivative of $\sqrt{4+|x|}$ using first principle,Whats the derivative of  using first principle,\sqrt{4+|x|},Here is my attempt: $$f(x)=\sqrt{4+|x|}$$ $$f`(x) = \lim_{h\to0} \frac{\sqrt{4+|x-h|}-\sqrt{4+|x|}}{h}$$ multiplying by the conjugate: $$\lim_{h\to0} \frac{4+|x-h|-4-|x|}{h[\sqrt{4+|x-h|}+\sqrt{4+|x|}]}$$ $$\lim_{h\to0} \frac{|x-h|-|x|}{h[\sqrt{4+|x-h|}+\sqrt{4+|x|}]}$$ What is the next step? how can I deal with absloute value of |x|?,Here is my attempt: $$f(x)=\sqrt{4+|x|}$$ $$f`(x) = \lim_{h\to0} \frac{\sqrt{4+|x-h|}-\sqrt{4+|x|}}{h}$$ multiplying by the conjugate: $$\lim_{h\to0} \frac{4+|x-h|-4-|x|}{h[\sqrt{4+|x-h|}+\sqrt{4+|x|}]}$$ $$\lim_{h\to0} \frac{|x-h|-|x|}{h[\sqrt{4+|x-h|}+\sqrt{4+|x|}]}$$ What is the next step? how can I deal with absloute value of |x|?,,"['calculus', 'derivatives']"
71,Directly proving continuous differentiability,Directly proving continuous differentiability,,"Let us say that we want to prove that a function $f: I \to \mathbb{R}$ defined on an open interval $I$ is continuously differentiable on $I$. One way to do this is to establish that $f'(x)$ exists at each point in the interval $I$, by examining the limit of $h^{-1}(f(x+h)-f(x))$ as $h \to 0$ for each fixed $x \in I$, and then showing that the now well-defined function $f': I \to \mathbb{R}$ is continuous by examining $f'(x+h) - f'(x)$ as $h \to 0$ for each $x \in I$. Is there a way to combine these two steps, directly showing continuous differentiability?","Let us say that we want to prove that a function $f: I \to \mathbb{R}$ defined on an open interval $I$ is continuously differentiable on $I$. One way to do this is to establish that $f'(x)$ exists at each point in the interval $I$, by examining the limit of $h^{-1}(f(x+h)-f(x))$ as $h \to 0$ for each fixed $x \in I$, and then showing that the now well-defined function $f': I \to \mathbb{R}$ is continuous by examining $f'(x+h) - f'(x)$ as $h \to 0$ for each $x \in I$. Is there a way to combine these two steps, directly showing continuous differentiability?",,"['real-analysis', 'derivatives', 'continuity']"
72,Finding all tangent lines that pass through a specific point (not the origin),Finding all tangent lines that pass through a specific point (not the origin),,"I was given the function $y = x^3-x$ and told to find all tangent lines that pass through $(-2,2)$. Not sure what steps to take past finding the derivative.","I was given the function $y = x^3-x$ and told to find all tangent lines that pass through $(-2,2)$. Not sure what steps to take past finding the derivative.",,"['calculus', 'derivatives']"
73,Derivative of ellipse,Derivative of ellipse,,Find $y'=\frac{dy}{dx}$ when: $$2x^2-xy+y^2=1$$ How do I solve this? Do I start with this?: $$y=\frac{2x^2+y^2-1}{x}$$ $$y'=\left(\frac{2x^2+y^2-1}{x}\right)'$$,Find $y'=\frac{dy}{dx}$ when: $$2x^2-xy+y^2=1$$ How do I solve this? Do I start with this?: $$y=\frac{2x^2+y^2-1}{x}$$ $$y'=\left(\frac{2x^2+y^2-1}{x}\right)'$$,,['derivatives']
74,Integral Question- Help would be appreciated! $\int_{1}^{x^2} t^2 \cos(\pi t)$,Integral Question- Help would be appreciated!,\int_{1}^{x^2} t^2 \cos(\pi t),"Just started talking about integration in calculus class. I'm thrown off by this problem: Let $$f(x) = \int_{1}^{x^2} t^2 \cos(\pi t)$$ Evaluate $F'(x)$ and $F'(\sqrt{3})$. By the way, we just started integration so the only technique I know is u-sub. What throws me off is there being two variables (why is $x^2$ in the upper boundary?)","Just started talking about integration in calculus class. I'm thrown off by this problem: Let $$f(x) = \int_{1}^{x^2} t^2 \cos(\pi t)$$ Evaluate $F'(x)$ and $F'(\sqrt{3})$. By the way, we just started integration so the only technique I know is u-sub. What throws me off is there being two variables (why is $x^2$ in the upper boundary?)",,"['calculus', 'integration', 'derivatives']"
75,Prove that $\frac{d^n}{dx^n} (\sin^4 x + \cos^4 x) = 4^{n-1}\cos (4x + \frac{n\pi}{2})$,Prove that,\frac{d^n}{dx^n} (\sin^4 x + \cos^4 x) = 4^{n-1}\cos (4x + \frac{n\pi}{2}),"Question Prove that $\frac{d^n}{dx^n} (\sin^4 x + \cos^4 x) = 4^{n-1}\cos (4x + \frac{n\pi}{2})$ My attempt First calculate $\frac{d}{dx} (\sin^4 x + \cos^4 x)$, that is,  $$\frac{d}{dx} (\sin^4 x + \cos^4 x) =4\sin^3 x \cos x - 4\cos^3 x \sin x $$ $$= 4\sin x \cos x(\sin^2 x - \cos^2 x)$$ $$\tag {n=1} = -2\sin 2x \cos 2x = - \sin 4x$$ Now, using the value of $n=1$, I calculate the derivatives for a few more values of $n$: $$\tag {n=2} -4\cos 4x$$ $$\tag {n=3} 4^2\sin 4x$$ $$\tag {n=4} 4^3\cos 4x$$ $$\tag {n=2} -4^4\sin 4x$$ From this I observe the consistency of the $4^{n-1}$ factor. Now I will expand $\cos (4x + \frac{n\pi}{2})$, which results in $$\cos 4x \cos \frac{n\pi}{2} - \sin 4x \sin \frac{n\pi}{2}$$ From what I know of of $\sin$ and $\cos$ functions, this fits the pattern I observe in calculating the derivatives of $\sin^4 x + \cos^4 x$ My concerns I feel uncomfortable putting so much weight on observing a pattern, instead I feel I should be able to put it down in terms of mathematics . One more thing, I don't feel comfortable with From what I know of of $\sin$ and $\cos$ functions, this fits the pattern I observe in calculating the derivatives of $\sin^4 x + \cos^4 x$. , there must be a better way to relate $$\frac{d^{n-1}}{dx^{n-1}} (-\sin 4x) $$ with $$\cos (4x + \frac{n\pi}{2})$$ I would appreciate any hints, suggestions, and alternative approaches. Keep in mind that this should be approached with the tools of elementary introductory derivatives and trigonometry.","Question Prove that $\frac{d^n}{dx^n} (\sin^4 x + \cos^4 x) = 4^{n-1}\cos (4x + \frac{n\pi}{2})$ My attempt First calculate $\frac{d}{dx} (\sin^4 x + \cos^4 x)$, that is,  $$\frac{d}{dx} (\sin^4 x + \cos^4 x) =4\sin^3 x \cos x - 4\cos^3 x \sin x $$ $$= 4\sin x \cos x(\sin^2 x - \cos^2 x)$$ $$\tag {n=1} = -2\sin 2x \cos 2x = - \sin 4x$$ Now, using the value of $n=1$, I calculate the derivatives for a few more values of $n$: $$\tag {n=2} -4\cos 4x$$ $$\tag {n=3} 4^2\sin 4x$$ $$\tag {n=4} 4^3\cos 4x$$ $$\tag {n=2} -4^4\sin 4x$$ From this I observe the consistency of the $4^{n-1}$ factor. Now I will expand $\cos (4x + \frac{n\pi}{2})$, which results in $$\cos 4x \cos \frac{n\pi}{2} - \sin 4x \sin \frac{n\pi}{2}$$ From what I know of of $\sin$ and $\cos$ functions, this fits the pattern I observe in calculating the derivatives of $\sin^4 x + \cos^4 x$ My concerns I feel uncomfortable putting so much weight on observing a pattern, instead I feel I should be able to put it down in terms of mathematics . One more thing, I don't feel comfortable with From what I know of of $\sin$ and $\cos$ functions, this fits the pattern I observe in calculating the derivatives of $\sin^4 x + \cos^4 x$. , there must be a better way to relate $$\frac{d^{n-1}}{dx^{n-1}} (-\sin 4x) $$ with $$\cos (4x + \frac{n\pi}{2})$$ I would appreciate any hints, suggestions, and alternative approaches. Keep in mind that this should be approached with the tools of elementary introductory derivatives and trigonometry.",,"['calculus', 'trigonometry', 'derivatives']"
76,How do I Implicitly Differentiate this equation?,How do I Implicitly Differentiate this equation?,,"My equation is $y=x^{y^2}$ I did the $\ln$ of both sides, then I tried implicit differentiation. I got $$y'= \frac{x^{y^2} y^2}{x}.$$","My equation is $y=x^{y^2}$ I did the $\ln$ of both sides, then I tried implicit differentiation. I got $$y'= \frac{x^{y^2} y^2}{x}.$$",,"['derivatives', 'implicit-differentiation']"
77,Simplifying the derivative of $f(x)= \frac{e^x - e^{-x}}{e^x+e^{-x}}$,Simplifying the derivative of,f(x)= \frac{e^x - e^{-x}}{e^x+e^{-x}},I was having some trouble on simplifying the derivative because I didn't know if it's correct. The original function is $$f(x)= \frac{e^x - e^{-x}}{e^x+e^{-x}}$$ What would the simplified derivative be with no negative exponents? So far I got $$f'(x)= \frac{(e^x+e^{-x})^2 - (e^x-e^{-x})^2}{(e^x+e^{-x})^2}$$ is this correct?,I was having some trouble on simplifying the derivative because I didn't know if it's correct. The original function is $$f(x)= \frac{e^x - e^{-x}}{e^x+e^{-x}}$$ What would the simplified derivative be with no negative exponents? So far I got $$f'(x)= \frac{(e^x+e^{-x})^2 - (e^x-e^{-x})^2}{(e^x+e^{-x})^2}$$ is this correct?,,"['calculus', 'derivatives', 'exponential-function']"
78,Equations of the tangents to the curve $f(x) = 2x^2 + 3$,Equations of the tangents to the curve,f(x) = 2x^2 + 3,"Find the equations of the tangents to the curve $f(x) = 2x^2 + 3$ that pass through the point $(2,3)$. Include a sketch as part of your solution. First, I found the derivative of $f(x)$ which is $4x$, but I'm not sure what to do next. Thank you.","Find the equations of the tangents to the curve $f(x) = 2x^2 + 3$ that pass through the point $(2,3)$. Include a sketch as part of your solution. First, I found the derivative of $f(x)$ which is $4x$, but I'm not sure what to do next. Thank you.",,['derivatives']
79,Failing to reproduce specific Functional derivative,Failing to reproduce specific Functional derivative,,"I'm failing to reproduce an (indirect) result in a paper, namely $${δF[g]\overδg(x,y,z)}={r^4\over\ell^5} $$ where $F[g]=\iiint \frac{2dxdydz}{\ell g(x,y,z)}    $ and $g(x,y,z)=-{\ell^2 \over r^2} $. Note that $\ell$ and $r$ do not depend on $x$, $y$ or $z$. I'm not terribly familiar with functional derivatives, but it seems to me that this is a simple example, since no derivatives of $g$ appear in $F$, and hence, when $F$ is of the form $F[ρ]=\int f(ρ(\mathbf x)) d\mathbf x $, the following should hold [e.g. from wiki] : $${δF[f]\overδρ(\mathbf x)}=\frac {\partial f}{\partial ρ}$$ In this particular case, this gives $$\begin{align} {δF[g]\overδg(x,y,z)} &= \frac\partial{\partial g}\left(\frac {2}{\ell g(x,y,z)}\right)\\ &=- \frac {2} {\ell g^2(x,y,z)}\\ &=-2\frac {r^4} {\ell^5} \end{align}$$ This isn't what the authors find. The weird thing about this derivation is that the function derived with respect to, $g$, doesn't depend on its arguments but on $r$, and so does the functional. It is as if I'm looking for a generalized relation for when $F$ of the form $F[ρ]=\int f(ρ(\mathbf x, r)) d\mathbf x $ rather than of the form $F[ρ]=\int f(ρ(\mathbf x)) d\mathbf x $,  $${δF[f]\overδρ(\mathbf x, r)}=?$$ What am I doing wrong, and more generally, does this dependence on $r$ even make a difference? This is the paper I'm referring to, page 11, eq. (46) and line below. The calculation is the $AdS_4$ case, with $F \to S_{ct}=-\frac 2\ell\int dtdx_idx_i \sqrt{-γ}, g \to γ^{tt}=-\frac {\ell^2}{r^2}$ and  $\sqrt {-γ}=-(γ^{tt})^{-1}$. They claim $8πGT_{tt}=0=-2\frac {r^2}{\ell^3}+\frac 2{\sqrt{-γ}} \frac {δS_{ct}}{δγ^{tt}}$ from which I get the 'indirect' statement (at top): $\frac {δS_{ct}}{δγ^{tt}} =\frac {r^4}{ \ell^5}$","I'm failing to reproduce an (indirect) result in a paper, namely $${δF[g]\overδg(x,y,z)}={r^4\over\ell^5} $$ where $F[g]=\iiint \frac{2dxdydz}{\ell g(x,y,z)}    $ and $g(x,y,z)=-{\ell^2 \over r^2} $. Note that $\ell$ and $r$ do not depend on $x$, $y$ or $z$. I'm not terribly familiar with functional derivatives, but it seems to me that this is a simple example, since no derivatives of $g$ appear in $F$, and hence, when $F$ is of the form $F[ρ]=\int f(ρ(\mathbf x)) d\mathbf x $, the following should hold [e.g. from wiki] : $${δF[f]\overδρ(\mathbf x)}=\frac {\partial f}{\partial ρ}$$ In this particular case, this gives $$\begin{align} {δF[g]\overδg(x,y,z)} &= \frac\partial{\partial g}\left(\frac {2}{\ell g(x,y,z)}\right)\\ &=- \frac {2} {\ell g^2(x,y,z)}\\ &=-2\frac {r^4} {\ell^5} \end{align}$$ This isn't what the authors find. The weird thing about this derivation is that the function derived with respect to, $g$, doesn't depend on its arguments but on $r$, and so does the functional. It is as if I'm looking for a generalized relation for when $F$ of the form $F[ρ]=\int f(ρ(\mathbf x, r)) d\mathbf x $ rather than of the form $F[ρ]=\int f(ρ(\mathbf x)) d\mathbf x $,  $${δF[f]\overδρ(\mathbf x, r)}=?$$ What am I doing wrong, and more generally, does this dependence on $r$ even make a difference? This is the paper I'm referring to, page 11, eq. (46) and line below. The calculation is the $AdS_4$ case, with $F \to S_{ct}=-\frac 2\ell\int dtdx_idx_i \sqrt{-γ}, g \to γ^{tt}=-\frac {\ell^2}{r^2}$ and  $\sqrt {-γ}=-(γ^{tt})^{-1}$. They claim $8πGT_{tt}=0=-2\frac {r^2}{\ell^3}+\frac 2{\sqrt{-γ}} \frac {δS_{ct}}{δγ^{tt}}$ from which I get the 'indirect' statement (at top): $\frac {δS_{ct}}{δγ^{tt}} =\frac {r^4}{ \ell^5}$",,"['functional-analysis', 'derivatives', 'functional-equations']"
80,True or false? A relative maximum or minimum must occur at a critical point.,True or false? A relative maximum or minimum must occur at a critical point.,,"I'm taking calculus one and I have to determine if this statement is true or false. A relative maximum or minimum must occur at a critical point. I believe it is false. The answer key says it is true so I am curious if I am right (low probability) or if I can get this clarified (the answer key has always been right when I thought it was wrong). For example for y = $\frac{1}{x}$ there is a critical point at x=0 (because the derivative at this point does not exist) even though there is no relative maximum or minimum (or is there?). I think if the statement was ""A relative maximum or minimum must occur at a critical point when the derivative at that point exists."" Please help. Thanks.","I'm taking calculus one and I have to determine if this statement is true or false. A relative maximum or minimum must occur at a critical point. I believe it is false. The answer key says it is true so I am curious if I am right (low probability) or if I can get this clarified (the answer key has always been right when I thought it was wrong). For example for y = $\frac{1}{x}$ there is a critical point at x=0 (because the derivative at this point does not exist) even though there is no relative maximum or minimum (or is there?). I think if the statement was ""A relative maximum or minimum must occur at a critical point when the derivative at that point exists."" Please help. Thanks.",,"['calculus', 'derivatives']"
81,"Existence of solution in $x,y \in (a,b)$ of $(\frac { a+b}2)^{x+y}=a^xb^y$",Existence of solution in  of,"x,y \in (a,b) (\frac { a+b}2)^{x+y}=a^xb^y","Let $a<b$ be positive real numbers , then is it true that there exist $x,y \in (a,b)$ such that $ \bigg(\dfrac { a+b}2\bigg)^{x+y}=a^xb^y$ ?","Let $a<b$ be positive real numbers , then is it true that there exist $x,y \in (a,b)$ such that $ \bigg(\dfrac { a+b}2\bigg)^{x+y}=a^xb^y$ ?",,"['real-analysis', 'derivatives', 'exponentiation']"
82,Summation of infinite series,Summation of infinite series,,If we know the series sum  given below converges to a value $C$(constant)  $$\sum_{n=0}^{\infty}a_n =C \tag 2$$ Can we generate following in terms of C. values of $a_n$ will tend to zero as n goes to infinity and sum too converges to C.. $\sum_{n=0}^{\infty}na_n $ $\sum_{n=0}^{\infty} \frac{a_n}{n!}$,If we know the series sum  given below converges to a value $C$(constant)  $$\sum_{n=0}^{\infty}a_n =C \tag 2$$ Can we generate following in terms of C. values of $a_n$ will tend to zero as n goes to infinity and sum too converges to C.. $\sum_{n=0}^{\infty}na_n $ $\sum_{n=0}^{\infty} \frac{a_n}{n!}$,,"['sequences-and-series', 'derivatives', 'summation', 'recurrence-relations', 'power-series']"
83,Show that the graph of $y=x^3\sin(\pi/x)$ extends to a smooth arc,Show that the graph of  extends to a smooth arc,y=x^3\sin(\pi/x),"Here's the problem: Let $y(x)$ be a real-valued function defined on the interval $x\in [0,1]$ by means of the equation   $$y(x)= \left\{ \begin{array}{lr}        x^3\sin(\frac{\pi}{x}) \;\;\;\mathbb{for}  & x \in (0,1]        \\0 \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\mathbb{for} & x=0        \end{array}    \right.$$ (a) Show that $z=x+iy(x)$ represent an arc $C$ that intersects the real axis at points $z=\frac{1}{n}$ $\forall n \in \mathbb{Z^+}$, and $z=0$ (b) Verify that the arc $C$ in part (a) is, in fact, a smooth arc. Okay so I figured out part (a). Now, I think I figured out part (b), but am not sure if my logic was valid. Here's the work: Attempted work for (b) In order for an arc to be smooth , $z'$ must be continuous on $[a,b]$ and non-zero on $(a,b)$. Since $z=x+iy(x)$, differentiating our result on $(0,1]$ will give us    $$z'=1+i(3x^2\sin(\frac{\pi}{x})-\pi x\cos(\frac{\pi}{x}))$$    Clearly, $x'$ is continuous on $[0,1]$ and non-zero on $(0,1)$ since any value we plug in will just give us $1$. $y'(x)$ is clearly defined for all values NOT $0$, so it is certainly continuous on $(0,1]$. Further, because of the relation between cosine and sine, it follows that $y'$ is non-zero on $(0,1)$ since sine and cosine will never be $0$ at the same time. We wish to show that $y'$ is continuous at $0$. Suppose that $y' \to 0$ when $x \to 0$. Then given $\epsilon >0$, we wish to show $\exists \delta >0$ s.t $\forall x \in (0,1]$ and    $$|x-0|<\delta \implies |3x^2\sin(\frac{\pi}{x})-\pi x\cos(\frac{\pi}{x})-0|<\epsilon$$   Observe that since $|sin(x)| \leq 1$, $|cos(x)| \leq 1$, we can extend this to $|sin(\frac{\pi}{x})|,|cos(\frac{\pi}{x})|$. Thus, observe that   $$|3x^2\sin(\frac{\pi}{x})-\pi x\cos(\frac{\pi}{x})| \leq |3x^2\sin(\frac{\pi}{x})|+|-\pi x\cos(\frac{\pi}{x})-0| \leq |3x^2|+\pi|x|$$   Since $x>0$, it follows that   $$|3x^2|+\pi|x| = 3x^2+\pi x < 3x^2 + 4x = 3x(x+\frac{4}{3})<\epsilon$$   $$\impliedby 3x < \frac{\epsilon}{x+\frac{4}{3}}$$   And since $x \leq 1$,   $$\frac{\epsilon}{x+\frac{4}{3}} \leq \frac{\epsilon}{1+\frac{4}{3}} = \frac{3\epsilon}{7}$$   so   $$3x<\frac{3\epsilon}{7} \impliedby x=|x-0|< \frac{\epsilon}{7} = \delta$$   Thus, given $\epsilon >0$, $\exists \delta=\frac{\epsilon}{7}$ s.t $\forall x\in (0,1]$ and   $$|x-0|<\frac{\epsilon}{7} \implies |3x^2\sin(\frac{\pi}{x})-\pi x\cos(\frac{\pi}{x})-0|<\epsilon$$   It is clear that $y'(x)$ is continuous at $0$. So $y'(x)$ is continuous on $[0,1]$ $\implies$ our arc is smooth. So my question: was what I did valid in the proof? Or did I pull some strings that shouldn't have been pulled?","Here's the problem: Let $y(x)$ be a real-valued function defined on the interval $x\in [0,1]$ by means of the equation   $$y(x)= \left\{ \begin{array}{lr}        x^3\sin(\frac{\pi}{x}) \;\;\;\mathbb{for}  & x \in (0,1]        \\0 \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\mathbb{for} & x=0        \end{array}    \right.$$ (a) Show that $z=x+iy(x)$ represent an arc $C$ that intersects the real axis at points $z=\frac{1}{n}$ $\forall n \in \mathbb{Z^+}$, and $z=0$ (b) Verify that the arc $C$ in part (a) is, in fact, a smooth arc. Okay so I figured out part (a). Now, I think I figured out part (b), but am not sure if my logic was valid. Here's the work: Attempted work for (b) In order for an arc to be smooth , $z'$ must be continuous on $[a,b]$ and non-zero on $(a,b)$. Since $z=x+iy(x)$, differentiating our result on $(0,1]$ will give us    $$z'=1+i(3x^2\sin(\frac{\pi}{x})-\pi x\cos(\frac{\pi}{x}))$$    Clearly, $x'$ is continuous on $[0,1]$ and non-zero on $(0,1)$ since any value we plug in will just give us $1$. $y'(x)$ is clearly defined for all values NOT $0$, so it is certainly continuous on $(0,1]$. Further, because of the relation between cosine and sine, it follows that $y'$ is non-zero on $(0,1)$ since sine and cosine will never be $0$ at the same time. We wish to show that $y'$ is continuous at $0$. Suppose that $y' \to 0$ when $x \to 0$. Then given $\epsilon >0$, we wish to show $\exists \delta >0$ s.t $\forall x \in (0,1]$ and    $$|x-0|<\delta \implies |3x^2\sin(\frac{\pi}{x})-\pi x\cos(\frac{\pi}{x})-0|<\epsilon$$   Observe that since $|sin(x)| \leq 1$, $|cos(x)| \leq 1$, we can extend this to $|sin(\frac{\pi}{x})|,|cos(\frac{\pi}{x})|$. Thus, observe that   $$|3x^2\sin(\frac{\pi}{x})-\pi x\cos(\frac{\pi}{x})| \leq |3x^2\sin(\frac{\pi}{x})|+|-\pi x\cos(\frac{\pi}{x})-0| \leq |3x^2|+\pi|x|$$   Since $x>0$, it follows that   $$|3x^2|+\pi|x| = 3x^2+\pi x < 3x^2 + 4x = 3x(x+\frac{4}{3})<\epsilon$$   $$\impliedby 3x < \frac{\epsilon}{x+\frac{4}{3}}$$   And since $x \leq 1$,   $$\frac{\epsilon}{x+\frac{4}{3}} \leq \frac{\epsilon}{1+\frac{4}{3}} = \frac{3\epsilon}{7}$$   so   $$3x<\frac{3\epsilon}{7} \impliedby x=|x-0|< \frac{\epsilon}{7} = \delta$$   Thus, given $\epsilon >0$, $\exists \delta=\frac{\epsilon}{7}$ s.t $\forall x\in (0,1]$ and   $$|x-0|<\frac{\epsilon}{7} \implies |3x^2\sin(\frac{\pi}{x})-\pi x\cos(\frac{\pi}{x})-0|<\epsilon$$   It is clear that $y'(x)$ is continuous at $0$. So $y'(x)$ is continuous on $[0,1]$ $\implies$ our arc is smooth. So my question: was what I did valid in the proof? Or did I pull some strings that shouldn't have been pulled?",,"['real-analysis', 'derivatives', 'continuity']"
84,What's the Differential of this Map $f:S^3\rightarrow \mathbb{R}$,What's the Differential of this Map,f:S^3\rightarrow \mathbb{R},"$f:S^3 \rightarrow \mathbb{R}$ is defined as $f(x,y,z,w)=x+zw$, where $S^3= \{(x,y,z,w) | x^2 +y^2 +z^2 +w^2 =1\}$ I tried using a stereographic chart but that got ugly. The function is so simple I was hoping there would be a better way to compute it. Thanks.","$f:S^3 \rightarrow \mathbb{R}$ is defined as $f(x,y,z,w)=x+zw$, where $S^3= \{(x,y,z,w) | x^2 +y^2 +z^2 +w^2 =1\}$ I tried using a stereographic chart but that got ugly. The function is so simple I was hoping there would be a better way to compute it. Thanks.",,"['differential-geometry', 'derivatives', 'manifolds', 'differential-topology', 'smooth-manifolds']"
85,Differentiability of the sum of the series $\sum_k \sin(kx)/k^2$,Differentiability of the sum of the series,\sum_k \sin(kx)/k^2,"How to show the following: If $ f(x) = \displaystyle\sum_{k=1}^{\infty} \dfrac {\sin(kx)}{k^2} $, then show that $f(x)$ is differentiable on $(0,1)$ I guess it should be related to uniform convergence of partial sums, but how to proceed?","How to show the following: If $ f(x) = \displaystyle\sum_{k=1}^{\infty} \dfrac {\sin(kx)}{k^2} $, then show that $f(x)$ is differentiable on $(0,1)$ I guess it should be related to uniform convergence of partial sums, but how to proceed?",,"['calculus', 'real-analysis', 'sequences-and-series', 'derivatives', 'trigonometric-series']"
86,Measuring sums of complex alternating series,Measuring sums of complex alternating series,,"Suppose we have functions $$f(x) = \sqrt{x}, \space g(f) = \frac{df}{dx}+\frac{d^2f}{dx^2}+\frac{d^3f}{dx^3}\space ...$$ Applying function f(x) to g(f) we get: $$g(f(x))=\frac{1}{2}x^{-\frac{1}{2}} - \frac{1}{4}x^{-\frac{3}{2}} + \frac{3}{8}x^{-\frac{5}{2}} - \frac{15}{16}x^{-\frac{7}{2}}$$ Is it possible to tell if it's converging? If it is, what is it converging to?","Suppose we have functions $$f(x) = \sqrt{x}, \space g(f) = \frac{df}{dx}+\frac{d^2f}{dx^2}+\frac{d^3f}{dx^3}\space ...$$ Applying function f(x) to g(f) we get: $$g(f(x))=\frac{1}{2}x^{-\frac{1}{2}} - \frac{1}{4}x^{-\frac{3}{2}} + \frac{3}{8}x^{-\frac{5}{2}} - \frac{15}{16}x^{-\frac{7}{2}}$$ Is it possible to tell if it's converging? If it is, what is it converging to?",,"['sequences-and-series', 'derivatives', 'summation']"
87,Show that $f(x) = x\sin(1/x)$ is Differentiable everywhere where $x\ne0$.,Show that  is Differentiable everywhere where .,f(x) = x\sin(1/x) x\ne0,"I have to show that  $f(x)= x\sin(1/x)$ is continuous everywhere differentiable everywhere where $x\ne 0$. I can show the continuous property, and how it is not differentiable when $x=0$, but how would I go to prove that it is differentiable for all $x$, such that $x\ne 0$. Trying to put it into the definition of the derivative and simplifying does not work (I could not get a proper answer.) Any hints on how to proceed would be greatly appreciated.","I have to show that  $f(x)= x\sin(1/x)$ is continuous everywhere differentiable everywhere where $x\ne 0$. I can show the continuous property, and how it is not differentiable when $x=0$, but how would I go to prove that it is differentiable for all $x$, such that $x\ne 0$. Trying to put it into the definition of the derivative and simplifying does not work (I could not get a proper answer.) Any hints on how to proceed would be greatly appreciated.",,"['calculus', 'derivatives']"
88,"Show there are $b, c \in \mathbb{R}$ such that $f(x)= {a\over 2}x^2 + bx + c$",Show there are  such that,"b, c \in \mathbb{R} f(x)= {a\over 2}x^2 + bx + c","Given $f:I\rightarrow \mathbb{R}$ and $f''(x) = a.\forall x\in I$.   Show there are $b, c \in \mathbb{R}$ such that $f(x)= {a\over 2}x^2  + bx + c$. If we define $g(x) = ax + b$, then $g'(x) = f''(x) = a$. Therefore, $f'(x)$ and $g(x)$ are equal (maybe differ by a constant). Hence, $f'(x)$ has to have the form: $f'(x) = ax + b$ I've been told to use Lagrange's Mean Value Thm but I'm not sure why the above alone isn't sufficient. P.S I wrote ""Therefore, $f'(x)$ and $g(x)$ are equal (maybe differ by a constant)"". How should I write it in a more professional/mathematical way?","Given $f:I\rightarrow \mathbb{R}$ and $f''(x) = a.\forall x\in I$.   Show there are $b, c \in \mathbb{R}$ such that $f(x)= {a\over 2}x^2  + bx + c$. If we define $g(x) = ax + b$, then $g'(x) = f''(x) = a$. Therefore, $f'(x)$ and $g(x)$ are equal (maybe differ by a constant). Hence, $f'(x)$ has to have the form: $f'(x) = ax + b$ I've been told to use Lagrange's Mean Value Thm but I'm not sure why the above alone isn't sufficient. P.S I wrote ""Therefore, $f'(x)$ and $g(x)$ are equal (maybe differ by a constant)"". How should I write it in a more professional/mathematical way?",,"['calculus', 'real-analysis', 'derivatives']"
89,How do I differentiate to what they have given?,How do I differentiate to what they have given?,,"Given that  $y = \dfrac{x^3 - 5x}{\sqrt{x}}$, show that $\dfrac{dy}{dx}$= $\dfrac{5(x^2 - 1)}{2 \sqrt{x}}$ (Posted from ``answer'' below: I get as far as  $\dfrac{dy}{dx}= \dfrac {5}{2}x^\frac {3}{2}  - \dfrac {5}{2}x^\frac{-1}{2}$  but struggling with the first fraction.) I am just getting to grips with the formatting so hope that is clear!  Many thanks","Given that  $y = \dfrac{x^3 - 5x}{\sqrt{x}}$, show that $\dfrac{dy}{dx}$= $\dfrac{5(x^2 - 1)}{2 \sqrt{x}}$ (Posted from ``answer'' below: I get as far as  $\dfrac{dy}{dx}= \dfrac {5}{2}x^\frac {3}{2}  - \dfrac {5}{2}x^\frac{-1}{2}$  but struggling with the first fraction.) I am just getting to grips with the formatting so hope that is clear!  Many thanks",,"['calculus', 'derivatives']"
90,Mean value theorem for the second derivative: $f(a+h)-2f(a)+f(a-h) = h^2f''(\xi)$,Mean value theorem for the second derivative:,f(a+h)-2f(a)+f(a-h) = h^2f''(\xi),"State, without proof, the Mean Value Theorem for a function $$g:[z-\alpha,z+\alpha]\to\mathbb{R}$$ where $z$ is a real number and $\alpha$ is positive. Suppose $f:\mathbb{R}\to\mathbb{R}$ is twice differentiable and $a\in\mathbb{R}$. Prove that for all $h\gt0$ there exists $\xi\in(a-h,a+h)$ with $$f(a+h)-2f(a)+f(a-h)=h^2f''(\xi).$$ Hint: consider the function $\varphi$ given by $$\varphi(t)=f(a+t)-2f(a)+f(a-t)-\left(\dfrac th\right)^2\big(f(a+h)-2f(a)+f(a-h)\big)$$ Attempt; First Part Here I just have to stat the definition of Mean Value Theorem; If $g$ is continuous on $[z-a,z+a]$ and differentiable on $(z-a,z+a)$ the there exists $\xi \in (z-a,z+a)$ such that $$g'(\xi)=\dfrac{g(z+a)-g(z-a)}{(z+a) - (z-a)}= \dfrac{g(z+a)-g(z-a)}{2 a}$$ Second Part Now I am having trouble relating the Mean Value theorem to the equation provided in the hint; $$\rho = f(a +t)-2f(a)+f(a-t)-(\dfrac{t}{h})^2(f(a+h)-2f(a)+f(a-t))$$ So from here how should I proceed? should I differentiate $\rho (t)$? Any hints would be great,","State, without proof, the Mean Value Theorem for a function $$g:[z-\alpha,z+\alpha]\to\mathbb{R}$$ where $z$ is a real number and $\alpha$ is positive. Suppose $f:\mathbb{R}\to\mathbb{R}$ is twice differentiable and $a\in\mathbb{R}$. Prove that for all $h\gt0$ there exists $\xi\in(a-h,a+h)$ with $$f(a+h)-2f(a)+f(a-h)=h^2f''(\xi).$$ Hint: consider the function $\varphi$ given by $$\varphi(t)=f(a+t)-2f(a)+f(a-t)-\left(\dfrac th\right)^2\big(f(a+h)-2f(a)+f(a-h)\big)$$ Attempt; First Part Here I just have to stat the definition of Mean Value Theorem; If $g$ is continuous on $[z-a,z+a]$ and differentiable on $(z-a,z+a)$ the there exists $\xi \in (z-a,z+a)$ such that $$g'(\xi)=\dfrac{g(z+a)-g(z-a)}{(z+a) - (z-a)}= \dfrac{g(z+a)-g(z-a)}{2 a}$$ Second Part Now I am having trouble relating the Mean Value theorem to the equation provided in the hint; $$\rho = f(a +t)-2f(a)+f(a-t)-(\dfrac{t}{h})^2(f(a+h)-2f(a)+f(a-t))$$ So from here how should I proceed? should I differentiate $\rho (t)$? Any hints would be great,",,"['calculus', 'derivatives']"
91,Derivative of $l_2$ norm w.r.t matrix,Derivative of  norm w.r.t matrix,l_2,"I have a matrix $A$ which is of size $m \times n$, a vector $B$ which of size $n \times 1$ and a vector $c$ which of size $m \times 1$. I'd like to take the derivative of the following function w.r.t to $A$: $f(A) = \lVert A \times B - c\rVert_2^2$ Notice that this is a $l_2$ norm not a matrix norm, since $A \times B$ is $m \times 1$. I am using this in an optimization problem where I need to find the optimal $A$.","I have a matrix $A$ which is of size $m \times n$, a vector $B$ which of size $n \times 1$ and a vector $c$ which of size $m \times 1$. I'd like to take the derivative of the following function w.r.t to $A$: $f(A) = \lVert A \times B - c\rVert_2^2$ Notice that this is a $l_2$ norm not a matrix norm, since $A \times B$ is $m \times 1$. I am using this in an optimization problem where I need to find the optimal $A$.",,"['matrices', 'derivatives', 'normed-spaces']"
92,Question about differential operators,Question about differential operators,,Say $N = ab$. How can I express $\frac{d}{dN}$ in terms of $\frac{d}{da}$ and $\frac{d}{db}$?,Say $N = ab$. How can I express $\frac{d}{dN}$ in terms of $\frac{d}{da}$ and $\frac{d}{db}$?,,"['calculus', 'derivatives', 'differential-operators']"
93,A Question about Hessian of log function (general form),A Question about Hessian of log function (general form),,Sincerely hope to ask how to obtain the RHS? Should I consider ln(10) among the process of d(log(x))/dx? Thanks!,Sincerely hope to ask how to obtain the RHS? Should I consider ln(10) among the process of d(log(x))/dx? Thanks!,,['derivatives']
94,"Strictly monotone real function: stationary point, non-differentiable point","Strictly monotone real function: stationary point, non-differentiable point",,"If we have a real function $f$ that is strictly increasing (or strictly decreasing), what can we say about measure and cardinality of stationary points/points with no derivative. In particular: -Is the set of stationary point countable? Measure zero? -Is the set of point where derivative does not exist countable? Measure zero? -If it have derivative everywhere (but not necessary continuous derivative) what can we say about its set of stationary point? What I have so far: -Derivative does not exist due to discontinuity is accounted for, only countable of them. -Inverse always exist and is also monotone, and stationary point of $f$ corresponde to point with no derivative of $f^{-1}$, so if we solve the 2nd one we might be done with first one, or perhaps the other way round, depend on what the answer is. -I am thinking of tweaking Cantor's staircase to make it strictly increasing, while still have stationary point almost everywhere. But cannot figure out how. The main problem is that I do not know anything about the derivative of a function even if I know those of functions that converge uniformly to it. Thank you for your help.","If we have a real function $f$ that is strictly increasing (or strictly decreasing), what can we say about measure and cardinality of stationary points/points with no derivative. In particular: -Is the set of stationary point countable? Measure zero? -Is the set of point where derivative does not exist countable? Measure zero? -If it have derivative everywhere (but not necessary continuous derivative) what can we say about its set of stationary point? What I have so far: -Derivative does not exist due to discontinuity is accounted for, only countable of them. -Inverse always exist and is also monotone, and stationary point of $f$ corresponde to point with no derivative of $f^{-1}$, so if we solve the 2nd one we might be done with first one, or perhaps the other way round, depend on what the answer is. -I am thinking of tweaking Cantor's staircase to make it strictly increasing, while still have stationary point almost everywhere. But cannot figure out how. The main problem is that I do not know anything about the derivative of a function even if I know those of functions that converge uniformly to it. Thank you for your help.",,"['real-analysis', 'derivatives']"
95,Derivative of exponential functions,Derivative of exponential functions,,"Can anyone present an intuitive reason for why the derivatives of exponential functions, lets say, as apposed to polynomials, grow more rapidly than the functions themselves? i.e. $$ y = e^{x^2}\\ \frac{\mathrm{d}y}{\mathrm{d}x} = 2 x e^{x^2} $$ I would appreciate an answer that does not simply go out and show algebraic manipulations (of limits etc.) which lead to the desired result. I am much more interested in a, at least partially, verbal explanation. Thank you! :)","Can anyone present an intuitive reason for why the derivatives of exponential functions, lets say, as apposed to polynomials, grow more rapidly than the functions themselves? i.e. $$ y = e^{x^2}\\ \frac{\mathrm{d}y}{\mathrm{d}x} = 2 x e^{x^2} $$ I would appreciate an answer that does not simply go out and show algebraic manipulations (of limits etc.) which lead to the desired result. I am much more interested in a, at least partially, verbal explanation. Thank you! :)",,"['derivatives', 'intuition', 'exponential-function']"
96,How can I solve this definite integral ?,How can I solve this definite integral ?,,How can I solve this? I need help with the steps,How can I solve this? I need help with the steps,,"['calculus', 'integration', 'derivatives', 'definite-integrals']"
97,Derivative on Hilbert space,Derivative on Hilbert space,,"Please, on a Hilbert space what is the  derivative of  $\displaystyle\frac{x}{||x||}$ ? I know that it's equal to $\displaystyle \frac{1}{||x||}-\frac{\langle x,\cdot\rangle}{||x||^3} x$ but can I write it as $\displaystyle\frac{1}{||x||}-\frac{\langle x,x\rangle}{||x||^3}$? thank you","Please, on a Hilbert space what is the  derivative of  $\displaystyle\frac{x}{||x||}$ ? I know that it's equal to $\displaystyle \frac{1}{||x||}-\frac{\langle x,\cdot\rangle}{||x||^3} x$ but can I write it as $\displaystyle\frac{1}{||x||}-\frac{\langle x,x\rangle}{||x||^3}$? thank you",,"['derivatives', 'hilbert-spaces']"
98,How to make a piecewise function differentiable?,How to make a piecewise function differentiable?,,"I have the following question: Suppose $$f(x) = \left\{\begin{array}{cc}x^2 & \text{if }x\leq 2 \\ mx+b& \text{if }x>2\end{array}\right.$$ If $f$ is differentiable everywhere, then what are the values of $m$ and $b$? How exactly would I be able to get the values to be differentiable? I know that the point at 2 has to exist and that it has to be continuous and connect to the other function to work. How exactly do I get the exact values for ""m"" and ""b"" though?","I have the following question: Suppose $$f(x) = \left\{\begin{array}{cc}x^2 & \text{if }x\leq 2 \\ mx+b& \text{if }x>2\end{array}\right.$$ If $f$ is differentiable everywhere, then what are the values of $m$ and $b$? How exactly would I be able to get the values to be differentiable? I know that the point at 2 has to exist and that it has to be continuous and connect to the other function to work. How exactly do I get the exact values for ""m"" and ""b"" though?",,['derivatives']
99,"Find an equation for the tangent line to the curve $y=8/\sqrt{4+3x}$ at the point $(4,2)$",Find an equation for the tangent line to the curve  at the point,"y=8/\sqrt{4+3x} (4,2)",I think the derivative is $-12/(3x+4)^{3/2}$ yet I'm not getting what I'm looking for.  I also think the equation is $3x+16y=44$. Can you help?,I think the derivative is $-12/(3x+4)^{3/2}$ yet I'm not getting what I'm looking for.  I also think the equation is $3x+16y=44$. Can you help?,,"['calculus', 'derivatives']"
