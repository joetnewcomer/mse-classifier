,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Considering the function $g(x) = 2 + e^x$.,Considering the function .,g(x) = 2 + e^x,"Considering the function $g(x) = 2 + e^x$ . a) Find $g’(x)$ . So, this is simply derivative of the function. This would be $g’(x) = e^x$ , right? b) Explain how this shows that $g(x)$ is an increasing function for all values of $x$ . In this case, don’t we set the derivative to $0$ and find what the $x$ equals? Then, we put the $x$ values on a sign chart to find out if it is increasing or decreasing? c) Find the equation of the tangent line to $g(x)$ at $x=1$ . For this part, we plug $x$ into our derivative to get the slope, right? Then we plug $x=1$ into the original function, $g(x)$ to get our $y$ value. Then find our $b$ value by plugging our y, x, and slope values.","Considering the function . a) Find . So, this is simply derivative of the function. This would be , right? b) Explain how this shows that is an increasing function for all values of . In this case, don’t we set the derivative to and find what the equals? Then, we put the values on a sign chart to find out if it is increasing or decreasing? c) Find the equation of the tangent line to at . For this part, we plug into our derivative to get the slope, right? Then we plug into the original function, to get our value. Then find our value by plugging our y, x, and slope values.",g(x) = 2 + e^x g’(x) g’(x) = e^x g(x) x 0 x x g(x) x=1 x x=1 g(x) y b,['functions']
1,Functional equation $f(x+y) = f(x)e^y+ f(y)e^x + 2xye^x e^y$,Functional equation,f(x+y) = f(x)e^y+ f(y)e^x + 2xye^x e^y,"If $f(x)$ be a differentiable function which satisfies the functional equation $f(x+y) = f(x)e^y+ f(y)e^x + 2xye^x e^y~~ \forall ~x,y \in \mathbb R,$ and $f'(0)= 0$ then the number of solutions of $f(x)= 0$ is? Attempt: I have obtained $f(0)=0$ by putting $x=y=0$ . But I am really struggling after that. I have tried by putting $y=-x$ but that isn't helping. Even after differentiating wrt x then putting $y =-x$ doesn't help. What is the trick/method to solve this question? Answer is: 1",If be a differentiable function which satisfies the functional equation and then the number of solutions of is? Attempt: I have obtained by putting . But I am really struggling after that. I have tried by putting but that isn't helping. Even after differentiating wrt x then putting doesn't help. What is the trick/method to solve this question? Answer is: 1,"f(x) f(x+y) = f(x)e^y+ f(y)e^x + 2xye^x e^y~~ \forall ~x,y \in \mathbb R, f'(0)= 0 f(x)= 0 f(0)=0 x=y=0 y=-x y =-x","['calculus', 'functions', 'derivatives']"
2,"How to construct a bijection from $[0,1]$ to $[0,1] \times [0,1]$? [duplicate]",How to construct a bijection from  to ? [duplicate],"[0,1] [0,1] \times [0,1]","This question already has answers here : Examples of bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$ (2 answers) Closed 5 years ago . I'm trying to find a bijective map $f$ such that $$ f : [0,1] \mapsto [0,1] \times [0,1] $$ I've succeeded in constructing one in the 1D case : $[0,1] \mapsto [0,1]$, but I don't know how to approach in 2D case as the above. Is there anyone to help me out?","This question already has answers here : Examples of bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$ (2 answers) Closed 5 years ago . I'm trying to find a bijective map $f$ such that $$ f : [0,1] \mapsto [0,1] \times [0,1] $$ I've succeeded in constructing one in the 1D case : $[0,1] \mapsto [0,1]$, but I don't know how to approach in 2D case as the above. Is there anyone to help me out?",,"['real-analysis', 'functions']"
3,Example of a function which is nearly a linear transformation,Example of a function which is nearly a linear transformation,,"Let $V$ and $W$ be vector spaces over the field $\mathbb{F}.$ Let $f$ be a function from $V$ to $W.$ Now $f$ will be called a linear transformation if \begin{align} &\tag1 f(\alpha + \beta) = f(\alpha) + f(\beta)\,\, \forall \alpha,\beta \in V \\ &f(c\alpha) = cf(\alpha)\,\, \forall c\in \mathbb{F}\tag2 \end{align} I am interested in finding examples of functions where : (a) the first condition $(1)$ fails and second condition $(2)$ holds (b) the second condition $(2)$ fails and first condition $(1)$ holds I have two examples for the (b) part: Consider $f : M_{n\times n}(\mathbb{C}) \rightarrow M_{n\times n}(\mathbb{C}) $ with the mapping $A \to A^*$ where $A^*$ is the conjugate transpose of $A.$ Consider $f : \mathbb{C} \rightarrow \mathbb{C}$ wih the mapping $z \to \overline{z}.$ So far I haven't been able to find an example for (a).Please help me wind this up. Also if you find more examples for (b), please list them too.","Let $V$ and $W$ be vector spaces over the field $\mathbb{F}.$ Let $f$ be a function from $V$ to $W.$ Now $f$ will be called a linear transformation if \begin{align} &\tag1 f(\alpha + \beta) = f(\alpha) + f(\beta)\,\, \forall \alpha,\beta \in V \\ &f(c\alpha) = cf(\alpha)\,\, \forall c\in \mathbb{F}\tag2 \end{align} I am interested in finding examples of functions where : (a) the first condition $(1)$ fails and second condition $(2)$ holds (b) the second condition $(2)$ fails and first condition $(1)$ holds I have two examples for the (b) part: Consider $f : M_{n\times n}(\mathbb{C}) \rightarrow M_{n\times n}(\mathbb{C}) $ with the mapping $A \to A^*$ where $A^*$ is the conjugate transpose of $A.$ Consider $f : \mathbb{C} \rightarrow \mathbb{C}$ wih the mapping $z \to \overline{z}.$ So far I haven't been able to find an example for (a).Please help me wind this up. Also if you find more examples for (b), please list them too.",,"['linear-algebra', 'functions']"
4,Solve for $x$: $x^{x-1} - (x-1)^x = 1$,Solve for :,x x^{x-1} - (x-1)^x = 1,"If $x$ is a real number, then solve for $x$ wherever the below equation is defined: $$x^{x-1} - (x-1)^x = 1$$ I viewed the answer to the question: $x^{x-1} = (x-1)^x $; but those methods won't work here because of the $1$ on RHS. Also by using a graph plotter, I found that the only solutions for $x \geq 1$ are $x = 1,2$ or $3$. How to prove this, and how to find the solutions for $x < 1$?","If $x$ is a real number, then solve for $x$ wherever the below equation is defined: $$x^{x-1} - (x-1)^x = 1$$ I viewed the answer to the question: $x^{x-1} = (x-1)^x $; but those methods won't work here because of the $1$ on RHS. Also by using a graph plotter, I found that the only solutions for $x \geq 1$ are $x = 1,2$ or $3$. How to prove this, and how to find the solutions for $x < 1$?",,"['calculus', 'functions']"
5,"Proving That $f: \mathbb{Z} \to \mathbb{Z}$, where $f(x) = x + 10$, Is Surjective","Proving That , where , Is Surjective",f: \mathbb{Z} \to \mathbb{Z} f(x) = x + 10,"I am trying to prove that $f: \mathbb{Z} \to \mathbb{Z}$, where $f(x) = x + 10$, is surjective. I have included my reasoning and would appreciate it if people could check whether it is correct. My Proof Let $b \in \mathbb{Z}$. We want to show that, for any $b \in \mathbb{Z}$, there exists some $x \in \mathbb{Z}$ such that $b = f(x) = x + 10$. $\therefore x = b - 10$ We constructed an integer $x$. $\therefore f(x) = f(b - 10)$ $= (b - 10) + 10$ (By the hypothesis.) $= b$ $= x + 10 \ \ \ Q.E.D. \ \ \ $ We have now demonstrated that $b = f(x) = x + 10$. I would greatly appreciate it if people could please take the time to review my proof and the reasoning I have included in it.","I am trying to prove that $f: \mathbb{Z} \to \mathbb{Z}$, where $f(x) = x + 10$, is surjective. I have included my reasoning and would appreciate it if people could check whether it is correct. My Proof Let $b \in \mathbb{Z}$. We want to show that, for any $b \in \mathbb{Z}$, there exists some $x \in \mathbb{Z}$ such that $b = f(x) = x + 10$. $\therefore x = b - 10$ We constructed an integer $x$. $\therefore f(x) = f(b - 10)$ $= (b - 10) + 10$ (By the hypothesis.) $= b$ $= x + 10 \ \ \ Q.E.D. \ \ \ $ We have now demonstrated that $b = f(x) = x + 10$. I would greatly appreciate it if people could please take the time to review my proof and the reasoning I have included in it.",,"['functions', 'proof-verification']"
6,Level Sets of Symmetric Functions,Level Sets of Symmetric Functions,,"If $f(x,y)$ is symmetric (i.e., $f(x,y)=f(y,x)$) and $C^1$ such that its first derivatives $f_x$ and $f_y$ are always strictly positive, is it necessarily the case that there is a $C^1$ function $g(z)$ with strictly positive derivative such that $g(x)+g(y)$ has the same level curves as $f(x,y)$? It seems to me that this ought to be true, but I am unable to prove it or to find a counterexample.  Some sort of smoothness assumption seems to be necessary, as the examples $f(x,y) = \max(x,y)$ and $f(x,y) = x+y+\max(x,y)$ show.","If $f(x,y)$ is symmetric (i.e., $f(x,y)=f(y,x)$) and $C^1$ such that its first derivatives $f_x$ and $f_y$ are always strictly positive, is it necessarily the case that there is a $C^1$ function $g(z)$ with strictly positive derivative such that $g(x)+g(y)$ has the same level curves as $f(x,y)$? It seems to me that this ought to be true, but I am unable to prove it or to find a counterexample.  Some sort of smoothness assumption seems to be necessary, as the examples $f(x,y) = \max(x,y)$ and $f(x,y) = x+y+\max(x,y)$ show.",,"['real-analysis', 'linear-algebra', 'functions', 'plane-geometry']"
7,Given the function $f(x)=\frac {1}{\sqrt[3] {1-x^3}}$ find $\underbrace {f(f(\cdots f(19)\cdots))}_{95}$,Given the function  find,f(x)=\frac {1}{\sqrt[3] {1-x^3}} \underbrace {f(f(\cdots f(19)\cdots))}_{95},Given the function $$f(x)=\frac {1}{\sqrt[3] {1-x^3}}$$ find $$\underbrace {f(f(\cdots f(19)\cdots))}_{95}$$ My try: Define $$f^n(x)=\underbrace {f(f(\cdots f(x)\cdots))}_{n}$$ We see that  $$f(x)=\frac {1}{\sqrt[3] {1-x^3}}$$ $$f^2(x)=\frac {\sqrt[3] {1-x^3}}{-x}$$ $$f^3(x)=x$$ And again $$f^4(x)=\frac {1}{\sqrt[3] {1-x^3}}$$ Hence $$f^{3k+2}(x)=\frac {\sqrt[3] {1-x^3}}{-x}$$ Substituting $k=31$ and $x=19$ I can find $$\underbrace {f(f(\cdots f(19)\cdots))}_{95}$$ So am I going on the right path.,Given the function $$f(x)=\frac {1}{\sqrt[3] {1-x^3}}$$ find $$\underbrace {f(f(\cdots f(19)\cdots))}_{95}$$ My try: Define $$f^n(x)=\underbrace {f(f(\cdots f(x)\cdots))}_{n}$$ We see that  $$f(x)=\frac {1}{\sqrt[3] {1-x^3}}$$ $$f^2(x)=\frac {\sqrt[3] {1-x^3}}{-x}$$ $$f^3(x)=x$$ And again $$f^4(x)=\frac {1}{\sqrt[3] {1-x^3}}$$ Hence $$f^{3k+2}(x)=\frac {\sqrt[3] {1-x^3}}{-x}$$ Substituting $k=31$ and $x=19$ I can find $$\underbrace {f(f(\cdots f(19)\cdots))}_{95}$$ So am I going on the right path.,,"['functions', 'contest-math', 'recursion']"
8,Proof for $f(x)=e^x+x$ strictly increasing,Proof for  strictly increasing,f(x)=e^x+x,"I am asked: Let $f:\mathbb{R} \to \mathbb{R}$ be given by $f(x)=e^x+x$. Prove that $f$ is strictly increasing. That is to say, prove that for any $a,b\in \mathbb{R} $       $$(a<b)\implies (e^{a}+a<e^{b}+b)$$ Here's my attempt: For any $a,b\in \mathbb{R}$, assume that $a<b$, i.e. $b=a+c$ for some $c\in \mathbb{R}^+$. Then, $e^a+a<e^b+b\implies e^a+a<e^{a+c}+(a+c)\implies e^a+a<e^a*e^c+a+c\implies e^a<e^a*e^c+c\implies 1<e^c+\frac{c}{e^a}\implies 0<e^c+\frac{c}{e^a}-1$. Since $c\in \mathbb{R}^+,e^c>1$. Therefore, $0<e^c+c$ is true for $c\in \mathbb{R}^+$. Thus, the original implication is true, so the function $f$ is strictly increasing. $\blacksquare$ Did I miss anything? Thanks!","I am asked: Let $f:\mathbb{R} \to \mathbb{R}$ be given by $f(x)=e^x+x$. Prove that $f$ is strictly increasing. That is to say, prove that for any $a,b\in \mathbb{R} $       $$(a<b)\implies (e^{a}+a<e^{b}+b)$$ Here's my attempt: For any $a,b\in \mathbb{R}$, assume that $a<b$, i.e. $b=a+c$ for some $c\in \mathbb{R}^+$. Then, $e^a+a<e^b+b\implies e^a+a<e^{a+c}+(a+c)\implies e^a+a<e^a*e^c+a+c\implies e^a<e^a*e^c+c\implies 1<e^c+\frac{c}{e^a}\implies 0<e^c+\frac{c}{e^a}-1$. Since $c\in \mathbb{R}^+,e^c>1$. Therefore, $0<e^c+c$ is true for $c\in \mathbb{R}^+$. Thus, the original implication is true, so the function $f$ is strictly increasing. $\blacksquare$ Did I miss anything? Thanks!",,"['functions', 'proof-verification']"
9,How do I show that $F(h) = h \circ h$ is surjective?,How do I show that  is surjective?,F(h) = h \circ h,"We are looking at a function $F:\mathbb{N}^\mathbb{N}\to \mathbb{N}^\mathbb{N}$ $$F(h)=h\circ h$$ I want to show that $F$ is not surjective. I have a solution, but I'm not quite sure if this is a proof or I just missed something. Let's take the function $h(x)=x$ and feed it to $F$. We will get $F(h(x))=h(h(x))$. The function $h(h(x))$ is always equal to $x$. So I say that $F$ is not surjective, because if I feed $h(x)$ in, some values like for instance $t(x)=x^2$ will not be hit in the codomain, so $F$ is not surjective. I am really unsure whether this proves the statement. I feel like it's too easy. If it's wrong, I'd really appreciate some tipps!","We are looking at a function $F:\mathbb{N}^\mathbb{N}\to \mathbb{N}^\mathbb{N}$ $$F(h)=h\circ h$$ I want to show that $F$ is not surjective. I have a solution, but I'm not quite sure if this is a proof or I just missed something. Let's take the function $h(x)=x$ and feed it to $F$. We will get $F(h(x))=h(h(x))$. The function $h(h(x))$ is always equal to $x$. So I say that $F$ is not surjective, because if I feed $h(x)$ in, some values like for instance $t(x)=x^2$ will not be hit in the codomain, so $F$ is not surjective. I am really unsure whether this proves the statement. I feel like it's too easy. If it's wrong, I'd really appreciate some tipps!",,"['functions', 'proof-verification']"
10,Difference of the Closest Multiples of Two Real Numbers,Difference of the Closest Multiples of Two Real Numbers,,"I am trying to find an algorithm / function for a computer program that I am working on. It looks like the following: $$F(f_1,f_2) = \Delta $$ where $\Delta$ is to be the smallest possible difference among a constrained set of integer multiples of $f_1$ and integer multiples of $f_2$. To put it another way, $$\Delta = \left\lvert n_1f_1 - n_2f_2\right\rvert\,\,s.t.\,\,\forall a_1,a_2 \in \{z_1,z_1+1,...,z_2\}, \left\lvert n_1f_1-n_2f_2 \right\rvert \le \left\lvert a_1f_1-a_2f_2 \right\rvert \; where\; z_1,z_2 \in \mathbb Z_{\gt 0}$$ Since I only need this for a very specific application, if it helps, we can also assume a few things about $f_1,\,f_2,\,z_1,$ and $z_2$: $f_1$ and $f_2$ are musical notes from a 12 note, equally tempered scale. This means that $f_1 = (\sqrt[12]{2})^{c_1}f_0$ and $f_2 = (\sqrt[12]{2})^{c_2}f_0$ for some integers $c_1$, $c_2$ and some fundamental frequency $f_0$. Typically $f_0$ is $440hz$. This cannot be assumed here, but we can assume that $f_0$ is some known constant. We can also assume that $z_1=1$ and $z_2=6$ Obviously, this problem could be solved very easily with a brute force computer program, as illustrated in the pseudo code below: function(f1,f2){       var delta = f1 - f2       var temp = 0       for(i=1;i<7;i++) {          for(k=1;k<7;k++){             temp = abs(i*f1 - k*f2)             if(temp < delta){                delta = temp             }          }       }        return delta    } But, there has to be a more elegant solution, right? Can someone help me out here?","I am trying to find an algorithm / function for a computer program that I am working on. It looks like the following: $$F(f_1,f_2) = \Delta $$ where $\Delta$ is to be the smallest possible difference among a constrained set of integer multiples of $f_1$ and integer multiples of $f_2$. To put it another way, $$\Delta = \left\lvert n_1f_1 - n_2f_2\right\rvert\,\,s.t.\,\,\forall a_1,a_2 \in \{z_1,z_1+1,...,z_2\}, \left\lvert n_1f_1-n_2f_2 \right\rvert \le \left\lvert a_1f_1-a_2f_2 \right\rvert \; where\; z_1,z_2 \in \mathbb Z_{\gt 0}$$ Since I only need this for a very specific application, if it helps, we can also assume a few things about $f_1,\,f_2,\,z_1,$ and $z_2$: $f_1$ and $f_2$ are musical notes from a 12 note, equally tempered scale. This means that $f_1 = (\sqrt[12]{2})^{c_1}f_0$ and $f_2 = (\sqrt[12]{2})^{c_2}f_0$ for some integers $c_1$, $c_2$ and some fundamental frequency $f_0$. Typically $f_0$ is $440hz$. This cannot be assumed here, but we can assume that $f_0$ is some known constant. We can also assume that $z_1=1$ and $z_2=6$ Obviously, this problem could be solved very easily with a brute force computer program, as illustrated in the pseudo code below: function(f1,f2){       var delta = f1 - f2       var temp = 0       for(i=1;i<7;i++) {          for(k=1;k<7;k++){             temp = abs(i*f1 - k*f2)             if(temp < delta){                delta = temp             }          }       }        return delta    } But, there has to be a more elegant solution, right? Can someone help me out here?",,"['functions', 'algorithms', 'computer-science', 'special-functions', 'factoring']"
11,"$\operatorname{Ext}^1(M,R/m)=0$ iff $M$ is projective",iff  is projective,"\operatorname{Ext}^1(M,R/m)=0 M","In this answer it is suggested that over a commutative local ring, a module $M$ is projective iff $\operatorname{Ext}^1_R(M,R/m)=0$. A similar result holds for flatness and Tor. In the case of Tor, I can find a proof in Robert Ash's Commutative Algebra , which involves specific isomorphisms with tensor. But I cannot prove the case of Ext. Can anyone show me the proof? Thank you. FYI, the ""proof"" in the next answer in that link is quite vague to me, so it would be ok if you guys can clear things out here.","In this answer it is suggested that over a commutative local ring, a module $M$ is projective iff $\operatorname{Ext}^1_R(M,R/m)=0$. A similar result holds for flatness and Tor. In the case of Tor, I can find a proof in Robert Ash's Commutative Algebra , which involves specific isomorphisms with tensor. But I cannot prove the case of Ext. Can anyone show me the proof? Thank you. FYI, the ""proof"" in the next answer in that link is quite vague to me, so it would be ok if you guys can clear things out here.",,"['functions', 'homological-algebra', 'projective-module', 'derived-functors']"
12,"Find $f:(1,\infty) \to \mathbb{R}$",Find,"f:(1,\infty) \to \mathbb{R}","Find $f:(1,\infty) \to \mathbb{R}$, where   \begin{align*} &f(x) \leq \frac{x-2}{\ln 2}, \: \forall x>1 \\ &f(x^3+1) \leq 3f(x+1), \: \forall x>0 \\ &f(x)+f\left(\frac{x}{x-1} \right) \geq 0, \: \forall x>1 \end{align*} All I got, which is also obvious, is the fact that $f(2)=0$. I tried to at least guess the function, without success. Also, substituting $x \to \frac{x}{x-1}$ in the last inequality makes it unchanged, thus this doesn't help either... My last thought was that the $3$ in the second inequality getting out of the function must somehow be related to $\log$s. As a side note, I found this as a real analysis/calculus problem .","Find $f:(1,\infty) \to \mathbb{R}$, where   \begin{align*} &f(x) \leq \frac{x-2}{\ln 2}, \: \forall x>1 \\ &f(x^3+1) \leq 3f(x+1), \: \forall x>0 \\ &f(x)+f\left(\frac{x}{x-1} \right) \geq 0, \: \forall x>1 \end{align*} All I got, which is also obvious, is the fact that $f(2)=0$. I tried to at least guess the function, without success. Also, substituting $x \to \frac{x}{x-1}$ in the last inequality makes it unchanged, thus this doesn't help either... My last thought was that the $3$ in the second inequality getting out of the function must somehow be related to $\log$s. As a side note, I found this as a real analysis/calculus problem .",,"['calculus', 'real-analysis', 'functions']"
13,Variable versus Function,Variable versus Function,,"When we write $y=f(x)$ what do we mean? Would we call $y$ a function of $x$ as well? $y=f(x)$ would represent geometrically a curve in the xy-plane, but other than that I don't understand why we would write something like that.","When we write $y=f(x)$ what do we mean? Would we call $y$ a function of $x$ as well? $y=f(x)$ would represent geometrically a curve in the xy-plane, but other than that I don't understand why we would write something like that.",,"['functions', 'notation']"
14,The $n$-th derivative has $n$ zeros. Can such a function be unbounded?,The -th derivative has  zeros. Can such a function be unbounded?,n n,"Question : Given a $C^\infty$-function $f:\Bbb R\to\Bbb R$ for which the $n$-th derivative has exactly $n$ zeros (counted with multiplicity) for all $n\in \Bbb N_0$. Can such a function be unbounded ? The motivation comes from another question of mine. I conjectured that functions with such zero-patterns look ""bell-shaped"". Examples might be $$\exp(-x^2)\quad\text{and}\quad \frac1{1+x^2}.$$ To construct an unbounded example, I had the following idea: take an intuitively bell-shaped function (like one of the above) which vanishes at infinity. Now, replace the converging tails with something that does diverge to $-\infty$ instead. The divergence must be sufficiently slow so that the zero pattern is preserved. I was not successful so far. For another idea, take once more a function with the desired zero-pattern. Then, add an unbounded function but pay attention to not destroy the zero pattern. This too turned out to be very tricky.","Question : Given a $C^\infty$-function $f:\Bbb R\to\Bbb R$ for which the $n$-th derivative has exactly $n$ zeros (counted with multiplicity) for all $n\in \Bbb N_0$. Can such a function be unbounded ? The motivation comes from another question of mine. I conjectured that functions with such zero-patterns look ""bell-shaped"". Examples might be $$\exp(-x^2)\quad\text{and}\quad \frac1{1+x^2}.$$ To construct an unbounded example, I had the following idea: take an intuitively bell-shaped function (like one of the above) which vanishes at infinity. Now, replace the converging tails with something that does diverge to $-\infty$ instead. The divergence must be sufficiently slow so that the zero pattern is preserved. I was not successful so far. For another idea, take once more a function with the desired zero-pattern. Then, add an unbounded function but pay attention to not destroy the zero pattern. This too turned out to be very tricky.",,"['functions', 'derivatives', 'examples-counterexamples']"
15,Is this function unimodal?,Is this function unimodal?,,"Consider the real function: $$f\left(\xi\right)=\frac{1-\xi}{\xi+c\mathrm{e}^{k/\xi}\left(a+\xi-a\xi\right)},\quad0\le\xi\le1$$ where $a,c,k$ are positive parameters. For all combinations of parameters I have tried, this function is always unimodal (I plotted it). I have not been able to prove this because the derivative is quite messy. Is there a simpler way? On the other hand, by considering expansions near $\xi \approx 0$ and $\xi \approx 1$, I was able to show that this function is increasing near $\xi \approx 0$, and decreasing near $\xi \approx 1$.","Consider the real function: $$f\left(\xi\right)=\frac{1-\xi}{\xi+c\mathrm{e}^{k/\xi}\left(a+\xi-a\xi\right)},\quad0\le\xi\le1$$ where $a,c,k$ are positive parameters. For all combinations of parameters I have tried, this function is always unimodal (I plotted it). I have not been able to prove this because the derivative is quite messy. Is there a simpler way? On the other hand, by considering expansions near $\xi \approx 0$ and $\xi \approx 1$, I was able to show that this function is increasing near $\xi \approx 0$, and decreasing near $\xi \approx 1$.",,"['real-analysis', 'functions']"
16,Minimum of $f_n(x)= \sum\limits_{i=0}^{n} (-1)^{i} |x+i|$,Minimum of,f_n(x)= \sum\limits_{i=0}^{n} (-1)^{i} |x+i|,"How does one systematically find the minimum of $$f(x)= \sum_{i=0}^{n} (-1)^{i} |x+i|$$ where $x \in \mathbf{R}$? Experimentation on Wolfram Alpha shows a specific pattern, but I'm thinking about using bounding arguments. If $f(x)= \sum_{i=0}^{n} |x+i|$, then repeated uses of the triangle inequality works, but I can't seem to use the triangle inequality to bound $\sum_{i=0}^{n}(-1)^{i} |x+i|$.","How does one systematically find the minimum of $$f(x)= \sum_{i=0}^{n} (-1)^{i} |x+i|$$ where $x \in \mathbf{R}$? Experimentation on Wolfram Alpha shows a specific pattern, but I'm thinking about using bounding arguments. If $f(x)= \sum_{i=0}^{n} |x+i|$, then repeated uses of the triangle inequality works, but I can't seem to use the triangle inequality to bound $\sum_{i=0}^{n}(-1)^{i} |x+i|$.",,"['functions', 'absolute-value', 'maxima-minima']"
17,prove that $f \in C^{\infty}(\mathbb{R})$ with $f^{(k)}(0) = 0$ and $|f^{(k)}(x)| \leq k!$ is $f(x)=0$,prove that  with  and  is,f \in C^{\infty}(\mathbb{R}) f^{(k)}(0) = 0 |f^{(k)}(x)| \leq k! f(x)=0,"I'm supposed to prove that $f \in C^{\infty}(\mathbb{R})$ with $f^{(k)}(0) = 0$ and $|f^{(k)}(x)| \leq k!$ for every $k \in \mathbb{N}$ and $x \in \mathbb{R}$ satisfies $f(x)=0$ My first thought was to use the Taylor series, but I was not given an analytic function, so maybe the series doesn't converge. But I can still calculate $f(x) = f(0) + f'(0)x + ...+ \frac{f^{(k)}(0)}{k!}x^k + r_{k}(x) \Rightarrow f(x) = r_k(x)$ Then, I have $r_{k}(x) = \frac{1}{(k+1)!}f^{(k+1)}(\theta x)x^{(k+1)}$, for some $\theta \in (0,1)$ As $|f^k(x)| \leq k!$, so $|r_k(x)| = |\frac{1}{(k+1)!}f^{(k+1)}(\theta x)x^{(k+1)}| \leq |\frac{(k+1)!}{(k+1)!}x^{(k+1)}| = |x^{k+1}|$ Then I don't know what to do. Any help will be appreciated.","I'm supposed to prove that $f \in C^{\infty}(\mathbb{R})$ with $f^{(k)}(0) = 0$ and $|f^{(k)}(x)| \leq k!$ for every $k \in \mathbb{N}$ and $x \in \mathbb{R}$ satisfies $f(x)=0$ My first thought was to use the Taylor series, but I was not given an analytic function, so maybe the series doesn't converge. But I can still calculate $f(x) = f(0) + f'(0)x + ...+ \frac{f^{(k)}(0)}{k!}x^k + r_{k}(x) \Rightarrow f(x) = r_k(x)$ Then, I have $r_{k}(x) = \frac{1}{(k+1)!}f^{(k+1)}(\theta x)x^{(k+1)}$, for some $\theta \in (0,1)$ As $|f^k(x)| \leq k!$, so $|r_k(x)| = |\frac{1}{(k+1)!}f^{(k+1)}(\theta x)x^{(k+1)}| \leq |\frac{(k+1)!}{(k+1)!}x^{(k+1)}| = |x^{k+1}|$ Then I don't know what to do. Any help will be appreciated.",,"['real-analysis', 'functions', 'taylor-expansion']"
18,Functional equations $f\left(\frac{x+y}{2}\right)=\frac{f(x)+f(y)}{2}$ and $f(x)=\frac{f\left(\frac{2}{3}x\right)+f\left(\frac{4}{3}x\right)}{2}$.,Functional equations  and .,f\left(\frac{x+y}{2}\right)=\frac{f(x)+f(y)}{2} f(x)=\frac{f\left(\frac{2}{3}x\right)+f\left(\frac{4}{3}x\right)}{2},"Suppose $f$ is continuous and $f\left(\frac{x+y}{2}\right)=\frac{f(x)+f(y)}{2}$. Can we claim that $f(x)=kx$? What if $f$ only satisfy $f(x)=\frac{f\left(\frac{2}{3}x\right)+f\left(\frac{4}{3}x\right)}{2}$? This functional equation was called Jensen's equation on wiki, but there is no further discussion about it","Suppose $f$ is continuous and $f\left(\frac{x+y}{2}\right)=\frac{f(x)+f(y)}{2}$. Can we claim that $f(x)=kx$? What if $f$ only satisfy $f(x)=\frac{f\left(\frac{2}{3}x\right)+f\left(\frac{4}{3}x\right)}{2}$? This functional equation was called Jensen's equation on wiki, but there is no further discussion about it",,"['real-analysis', 'functions', 'functional-equations']"
19,"The number of linear functions from $\left\{0, 1\right\}^{n}$ to $\left\{0, 1\right\}$",The number of linear functions from  to,"\left\{0, 1\right\}^{n} \left\{0, 1\right\}","I know it is a duplicate of this question. But still, i am posting this because I am completely stuck.I think i have not understand the question itself. I am posting my attempt.Please guide me to move further. Question For $x, y\in \left\{0, 1\right\}^{n}$, let $x ⊕ y$ be the element of $\left\{0, 1\right\}^{n}$ obtained by the component-wise exclusive-or of $x$ and $y$. A Boolean function $F:\left\{0, 1\right\}^{n}\rightarrow\left\{0, 1\right\}$ is said to be linear if $F(x ⊕ y)= F(x) ⊕ F(y)$, for all $x$ and $y$. The number of linear functions from $\left\{0, 1\right\}^{n}$ to $\left\{0, 1\right\}$ is. Attempt let the value of $n$=4 Now we have the size of domain as $2^{4}$ which are $\left\{0000,0001,0010,0011,0100\,\,\cdot\cdot\cdot\cdot 1111\right\}$ Total number of binary function possible $F:\left\{0, 1\right\}^{n}\rightarrow\left\{0, 1\right\}$ =$2^{2^{4}}=2^{16}$ We have to find actually the size of domain. Now among $16$ possible combination of $\left \{0, 1\right\}^{4}$, Let $x=0010$  and $y=1010$ Now $$x ⊕ y=1000$$ Now$F(x ⊕ y)$=$F(0010)$=$F(x)⊕ F(y)$=???? Completely stuck !!,no clue what to do !Even the accepted answer is not clear to me ! Please help me out using this example!","I know it is a duplicate of this question. But still, i am posting this because I am completely stuck.I think i have not understand the question itself. I am posting my attempt.Please guide me to move further. Question For $x, y\in \left\{0, 1\right\}^{n}$, let $x ⊕ y$ be the element of $\left\{0, 1\right\}^{n}$ obtained by the component-wise exclusive-or of $x$ and $y$. A Boolean function $F:\left\{0, 1\right\}^{n}\rightarrow\left\{0, 1\right\}$ is said to be linear if $F(x ⊕ y)= F(x) ⊕ F(y)$, for all $x$ and $y$. The number of linear functions from $\left\{0, 1\right\}^{n}$ to $\left\{0, 1\right\}$ is. Attempt let the value of $n$=4 Now we have the size of domain as $2^{4}$ which are $\left\{0000,0001,0010,0011,0100\,\,\cdot\cdot\cdot\cdot 1111\right\}$ Total number of binary function possible $F:\left\{0, 1\right\}^{n}\rightarrow\left\{0, 1\right\}$ =$2^{2^{4}}=2^{16}$ We have to find actually the size of domain. Now among $16$ possible combination of $\left \{0, 1\right\}^{4}$, Let $x=0010$  and $y=1010$ Now $$x ⊕ y=1000$$ Now$F(x ⊕ y)$=$F(0010)$=$F(x)⊕ F(y)$=???? Completely stuck !!,no clue what to do !Even the accepted answer is not clear to me ! Please help me out using this example!",,['functions']
20,Proof about Involutory Functions,Proof about Involutory Functions,,"I would like to prove (or disprove) that involutory functions (functions that are their own inverses) have no real functional square root/half iterate, but I'm not sure where to start with this. This assumption seems ""correct"", but that isn't really enough. So far all of these functions that I've come across have some functional square root involving complex numbers. For example, if $𝑓(𝑥)=-x$, then the functional square root is $𝑔(𝑥)=ix$. Another example is that if $𝑓(𝑥)=\frac{1}{x}$, then $𝑔(𝑥)=x^i$. One last example is that if $𝑓(𝑥)=1-x$, then $𝑔(𝑥)=ix+\frac{1}{2}-\frac{1}{2}i$. Can anybody help me out by giving me some idea how I can begin this proof, or give a counterexample?","I would like to prove (or disprove) that involutory functions (functions that are their own inverses) have no real functional square root/half iterate, but I'm not sure where to start with this. This assumption seems ""correct"", but that isn't really enough. So far all of these functions that I've come across have some functional square root involving complex numbers. For example, if $𝑓(𝑥)=-x$, then the functional square root is $𝑔(𝑥)=ix$. Another example is that if $𝑓(𝑥)=\frac{1}{x}$, then $𝑔(𝑥)=x^i$. One last example is that if $𝑓(𝑥)=1-x$, then $𝑔(𝑥)=ix+\frac{1}{2}-\frac{1}{2}i$. Can anybody help me out by giving me some idea how I can begin this proof, or give a counterexample?",,"['functions', 'function-and-relation-composition', 'inverse-function']"
21,"Is there a single real-valued function, continuous $f:[100,\infty]\to\mathbb R$ such that $f(f(x)) = \log x$ for every $x$ in its domain?","Is there a single real-valued function, continuous  such that  for every  in its domain?","f:[100,\infty]\to\mathbb R f(f(x)) = \log x x","Consider the function $L_i(x)=\log^{(i)} x$ whose value is determined by taking the log of $x$ --  $i$ times. For example $L_2(x) = \log\log x$. Now, I want to extend this notion to non-integer $i$'s, and specifically $f(x)\triangleq L_{0.5}(x)$. In order to do so, I thought we can define $f(x)$ by the equation  $$f(f(x)) = \log x$$ Is there a single real-valued continuous function $f$ such that on its domain it satisfies $f(f(x))=\log x$? Without the continuity requirement, the implicit assumption that $f(f(x))=\log x$ doesn't seem to be enough for the function to be unique. If it is indeed not, can anyone suggest a better way of generalizing $\{L_i\}_{i\in\mathbb N}$ to non-integer $i$'s? Is there a name for this function?","Consider the function $L_i(x)=\log^{(i)} x$ whose value is determined by taking the log of $x$ --  $i$ times. For example $L_2(x) = \log\log x$. Now, I want to extend this notion to non-integer $i$'s, and specifically $f(x)\triangleq L_{0.5}(x)$. In order to do so, I thought we can define $f(x)$ by the equation  $$f(f(x)) = \log x$$ Is there a single real-valued continuous function $f$ such that on its domain it satisfies $f(f(x))=\log x$? Without the continuity requirement, the implicit assumption that $f(f(x))=\log x$ doesn't seem to be enough for the function to be unique. If it is indeed not, can anyone suggest a better way of generalizing $\{L_i\}_{i\in\mathbb N}$ to non-integer $i$'s? Is there a name for this function?",,"['functions', 'implicit-function']"
22,Using Functions to Reach Every Positive Integer,Using Functions to Reach Every Positive Integer,,"Consider the functions $f(x)=2x+1$ and $g(x)=3x+1$, as well as their inverses f'(x) and g'(x). Starting with the number 1, is it possible to reach every positive integer through some finite sequence of these $4$ functions? For example, we could have the following sequence: $$1\,\,\overbrace {\longrightarrow}^{f(x)}  \,\, 3\,\,\overbrace {\longrightarrow}^{f(x)}  \,\,7\,\,\overbrace {\longrightarrow}^{g'(x)} \,\,2\,\,\overbrace {\longrightarrow}^{f(x)} \, \,5$$ Edit: I've tried a few things like taking base 6 and simply bashing a lot, and it seems like that it is possible, though I have no idea how to rigorously prove that.","Consider the functions $f(x)=2x+1$ and $g(x)=3x+1$, as well as their inverses f'(x) and g'(x). Starting with the number 1, is it possible to reach every positive integer through some finite sequence of these $4$ functions? For example, we could have the following sequence: $$1\,\,\overbrace {\longrightarrow}^{f(x)}  \,\, 3\,\,\overbrace {\longrightarrow}^{f(x)}  \,\,7\,\,\overbrace {\longrightarrow}^{g'(x)} \,\,2\,\,\overbrace {\longrightarrow}^{f(x)} \, \,5$$ Edit: I've tried a few things like taking base 6 and simply bashing a lot, and it seems like that it is possible, though I have no idea how to rigorously prove that.",,['elementary-number-theory']
23,Bijection from the set of odd natural numbers to integers [closed],Bijection from the set of odd natural numbers to integers [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How to construct  a bijection $f: A\to \Bbb{Z}$ where $A$ is the set of odd natural numbers?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How to construct  a bijection $f: A\to \Bbb{Z}$ where $A$ is the set of odd natural numbers?",,"['real-analysis', 'functions']"
24,Why do convex and concave function have their own name like that not the opposite?,Why do convex and concave function have their own name like that not the opposite?,,"Here is the definition for each kind of function https://i.sstatic.net/dMWb1.jpg And here is the definition for the words ""concave and convex"" in dictionary, with convex means curving out and concave means curving in. https://i.sstatic.net/99SkU.jpg In my logic, the convex function should be called concave func, and concave the opposite, because from the graph, I see a rumble strip bar, going up a little bit and down, like a concave function, but I think the rumble strip bar is described as ""convex"", here it's a little difficult for you to see my logic about it, but I don't understand why we call those function like that, not the opposite. Sorry because i'm not in an English speaker country. Thanks for your explaination!","Here is the definition for each kind of function https://i.sstatic.net/dMWb1.jpg And here is the definition for the words ""concave and convex"" in dictionary, with convex means curving out and concave means curving in. https://i.sstatic.net/99SkU.jpg In my logic, the convex function should be called concave func, and concave the opposite, because from the graph, I see a rumble strip bar, going up a little bit and down, like a concave function, but I think the rumble strip bar is described as ""convex"", here it's a little difficult for you to see my logic about it, but I don't understand why we call those function like that, not the opposite. Sorry because i'm not in an English speaker country. Thanks for your explaination!",,"['functions', 'convex-geometry']"
25,Construct more simple functions by restricting the domain,Construct more simple functions by restricting the domain,,"I need a function that has the same values as $f(x)=\sin\left(\frac{x}{2}\right)\cdot\sin\left(x^2\right)$ between $x=0$ and the following root of $f(x)$ at $x > 0$. At any other point, the function may differ from f (the reason I need this function is that I need to get the area under $f$ between the roots, but the integral is too complicated, and the area's value can not be directly approximated because my original f has more parameters, see ""edit""). Here is the plot of f. The function f itself fulfills the wanted property (but its integral is really ugly). So I was hoping that there was a function that has the same values in the range between the first two roots ($x=0$ and the smallest one with $x>0$), but may have a much more simple formula (and integral). The following image shows a red-colored function with (maybe) such a property: The function is defined by having the same values between the first two roots and is - aside from that - point symmetric in every root. It looks much less complex, so I'd hope the formula to be much more simple for this function. How can I construct a formula for the red-colored function? Also, is there maybe an even more simple function than the red one? Edit: As an additional info: The function of which I really need to get the area is $f(x,a)=\sin\left(\frac{x}{2}\right)\cdot\sin\left(3^{(4a-2)} x^2\right)$ where $0 \le a \le 1$. In my computer program, the parameter $a$ changes very, very often. I'd like to have an integral, since if $a$ changes, there should be done as few re-computations as possible.","I need a function that has the same values as $f(x)=\sin\left(\frac{x}{2}\right)\cdot\sin\left(x^2\right)$ between $x=0$ and the following root of $f(x)$ at $x > 0$. At any other point, the function may differ from f (the reason I need this function is that I need to get the area under $f$ between the roots, but the integral is too complicated, and the area's value can not be directly approximated because my original f has more parameters, see ""edit""). Here is the plot of f. The function f itself fulfills the wanted property (but its integral is really ugly). So I was hoping that there was a function that has the same values in the range between the first two roots ($x=0$ and the smallest one with $x>0$), but may have a much more simple formula (and integral). The following image shows a red-colored function with (maybe) such a property: The function is defined by having the same values between the first two roots and is - aside from that - point symmetric in every root. It looks much less complex, so I'd hope the formula to be much more simple for this function. How can I construct a formula for the red-colored function? Also, is there maybe an even more simple function than the red one? Edit: As an additional info: The function of which I really need to get the area is $f(x,a)=\sin\left(\frac{x}{2}\right)\cdot\sin\left(3^{(4a-2)} x^2\right)$ where $0 \le a \le 1$. In my computer program, the parameter $a$ changes very, very often. I'd like to have an integral, since if $a$ changes, there should be done as few re-computations as possible.",,"['functions', 'trigonometry', 'definite-integrals']"
26,How can I prove or disprove that there exists a function such that...,How can I prove or disprove that there exists a function such that...,,"Suppose we have a function $f$ of $bx-ay$ where $a$ and $b$ are two real constants, if we have for example $e^{bx-ay}$  then obviously it is a function of $bx-ay$. Can we find a function $f$ such that: $f(bx-ay) = ax-by$? in other words what operations we should operate on $bx-ay$ to get $ax-by$? how can I proceed?","Suppose we have a function $f$ of $bx-ay$ where $a$ and $b$ are two real constants, if we have for example $e^{bx-ay}$  then obviously it is a function of $bx-ay$. Can we find a function $f$ such that: $f(bx-ay) = ax-by$? in other words what operations we should operate on $bx-ay$ to get $ax-by$? how can I proceed?",,['functions']
27,An always increasing function,An always increasing function,,"Suppose I wanted a function $f(x)$ such that the following properties are had. $f(x)$ maps $\mathbb{R}\to\mathbb{R}$. $f(a)>f(b)$ if $a>b$. The function may or may not be continuous, but it doesn't have singularities. Is there a special name for this type of function and does it have any special properties?  (properties for all functions that meet the requirements.)","Suppose I wanted a function $f(x)$ such that the following properties are had. $f(x)$ maps $\mathbb{R}\to\mathbb{R}$. $f(a)>f(b)$ if $a>b$. The function may or may not be continuous, but it doesn't have singularities. Is there a special name for this type of function and does it have any special properties?  (properties for all functions that meet the requirements.)",,"['functions', 'special-functions']"
28,"Are the ""weights"" inside a neural network actually ""terms"" for a polynomial?","Are the ""weights"" inside a neural network actually ""terms"" for a polynomial?",,"This just hit me today. I am not too experienced with math or neural networks, but I am trying to find out about them in my own way so I can some day understand them well. So I was thinking about how neural networks are connected to more familiar things that I know. This is just speculation, but I would like to know if I am on the right track at all. Currently I think that neural networks are in fact ""function adapters"" (if that is the correct term in english) so that when they are learning, they are trying to adapt some invisible function so that the inputs match the wanted outputs. If I wanted to do something like this by hand, I would of course adjust the terms of some function that I am adapting. Like if I had a simple polynomial: 5x + 1 I would adjust the x until the function outputs what I want with the given input. I think the x in this example might actually represent a weight in a neural network. It would make a lot of sense if this was the case! And then there is the ""back propagation"", which I have not studied that much at all, but I think it has to do with correcting the other weights when adjusting one, because if the weights are the unknowns of a polynomial and I adjust some unknown in a polynomial - all the previous calculations would be off to account for this name input, because the old inputs use the same network / polynomial as the new input that the network / polynomial was just adjusted for. So this ""back propagation"" takes this into account and tries to minimize the error for the old inputs? Am I on the right track here? Simply put: Are weights = unknowns in a polynomial Is ""back propagation"" = Making sure that the polynomial gives same outputs for the old inputs, after the polynomial has been adjusted to work with a new input Thanks!","This just hit me today. I am not too experienced with math or neural networks, but I am trying to find out about them in my own way so I can some day understand them well. So I was thinking about how neural networks are connected to more familiar things that I know. This is just speculation, but I would like to know if I am on the right track at all. Currently I think that neural networks are in fact ""function adapters"" (if that is the correct term in english) so that when they are learning, they are trying to adapt some invisible function so that the inputs match the wanted outputs. If I wanted to do something like this by hand, I would of course adjust the terms of some function that I am adapting. Like if I had a simple polynomial: 5x + 1 I would adjust the x until the function outputs what I want with the given input. I think the x in this example might actually represent a weight in a neural network. It would make a lot of sense if this was the case! And then there is the ""back propagation"", which I have not studied that much at all, but I think it has to do with correcting the other weights when adjusting one, because if the weights are the unknowns of a polynomial and I adjust some unknown in a polynomial - all the previous calculations would be off to account for this name input, because the old inputs use the same network / polynomial as the new input that the network / polynomial was just adjusted for. So this ""back propagation"" takes this into account and tries to minimize the error for the old inputs? Am I on the right track here? Simply put: Are weights = unknowns in a polynomial Is ""back propagation"" = Making sure that the polynomial gives same outputs for the old inputs, after the polynomial has been adjusted to work with a new input Thanks!",,"['functions', 'polynomials', 'error-propagation', 'neural-networks']"
29,Multiplicative even and odd functions?,Multiplicative even and odd functions?,,"An even function satisfies $$ f_e(x) = f_e(-x) $$ and a odd function $$ f_o(x) = -f_o(-x) $$ Every function can be split into an even and an odd part $$ f(x) = f_e(x) + f_o(x) = \frac{1}{2}(f(x)+f(-x)) + \frac{1}{2}(f(x)-f(-x)) $$ Now even and odd functions are basically related to the operation of addition and the inverse of addition. I wonder if it would make sense to define even and odd functions related to multiplication and the inverse of multiplication. So I imagine a multiplicative even function would satisfy $$ f_{me}(x)=f_{me}\left(\frac{1}{x}\right) $$ and a multiplicative odd function $$ f_{mo}(x)=\frac{1}{f_{mo}\left(\frac{1}{x}\right)} $$ Are these functional equations the correct generalizations of even and off functions to the operation of multiplication? If so, what functions can fulfill these equations? Is it possible to split each function into a multiplicative even and odd part?","An even function satisfies $$ f_e(x) = f_e(-x) $$ and a odd function $$ f_o(x) = -f_o(-x) $$ Every function can be split into an even and an odd part $$ f(x) = f_e(x) + f_o(x) = \frac{1}{2}(f(x)+f(-x)) + \frac{1}{2}(f(x)-f(-x)) $$ Now even and odd functions are basically related to the operation of addition and the inverse of addition. I wonder if it would make sense to define even and odd functions related to multiplication and the inverse of multiplication. So I imagine a multiplicative even function would satisfy $$ f_{me}(x)=f_{me}\left(\frac{1}{x}\right) $$ and a multiplicative odd function $$ f_{mo}(x)=\frac{1}{f_{mo}\left(\frac{1}{x}\right)} $$ Are these functional equations the correct generalizations of even and off functions to the operation of multiplication? If so, what functions can fulfill these equations? Is it possible to split each function into a multiplicative even and odd part?",,"['functions', 'functional-equations']"
30,"Is there a difference between $f(x,y)$ $f(x;y)$ and $f(x\mid y)$?",Is there a difference between   and ?,"f(x,y) f(x;y) f(x\mid y)","While reading I have come across all three of these notations seemingly at random, and as far as I can tell they are all positional arguments to a function, but I can't tell if they mean different things, do they?","While reading I have come across all three of these notations seemingly at random, and as far as I can tell they are all positional arguments to a function, but I can't tell if they mean different things, do they?",,"['functions', 'notation']"
31,Prove that $ f(a+b) \ge f(a)+f(b)$.,Prove that ., f(a+b) \ge f(a)+f(b),"Let $f$ be a function such that $f^{\prime \prime} (x) \ge 0$ , $f(0)=0$, for each $x \ge 0$. Prove that if $a,b \ge 0$ , then: $$ f(a+b) \ge f(a)+f(b)$$ It's really hard for me to get an intuition for questions like this, can someone give me a hint and explain in what way did he think to get such intuition?","Let $f$ be a function such that $f^{\prime \prime} (x) \ge 0$ , $f(0)=0$, for each $x \ge 0$. Prove that if $a,b \ge 0$ , then: $$ f(a+b) \ge f(a)+f(b)$$ It's really hard for me to get an intuition for questions like this, can someone give me a hint and explain in what way did he think to get such intuition?",,"['calculus', 'functions']"
32,"Finding $f\in C( \mathbb R)$ such that for some integer $n>1$, $f^n(x)=x,\,\forall x \in \mathbb R$","Finding  such that for some integer ,","f\in C( \mathbb R) n>1 f^n(x)=x,\,\forall x \in \mathbb R","Let $f:\mathbb R \to \mathbb R$ be a continuous function such that for some integer $n>1$, $f^n(x)=x,\,\forall x \in \mathbb R$; then is it true that either $f(x)=x,\,\forall x \in \mathbb R$ or $f(x)=-x,\,\forall x \in \mathbb R$?","Let $f:\mathbb R \to \mathbb R$ be a continuous function such that for some integer $n>1$, $f^n(x)=x,\,\forall x \in \mathbb R$; then is it true that either $f(x)=x,\,\forall x \in \mathbb R$ or $f(x)=-x,\,\forall x \in \mathbb R$?",,['real-analysis']
33,Proving $x^2$ is surjective,Proving  is surjective,x^2,"Prove that $f:[0,\infty)\to[0,\infty): x\mapsto x^2$ is surjective. I'm guessing this is quite elementary, but the catch is: I don't want to use the continuity theorems (intermediate value thm., min-max thm., and extreme value thm.)or limits at all for that matter. Also, I defined the square root of a number as an inverse (thus implicitly assuming its existence i.e. the surjectivity of the function defined above). Is there any other way to do this?","Prove that $f:[0,\infty)\to[0,\infty): x\mapsto x^2$ is surjective. I'm guessing this is quite elementary, but the catch is: I don't want to use the continuity theorems (intermediate value thm., min-max thm., and extreme value thm.)or limits at all for that matter. Also, I defined the square root of a number as an inverse (thus implicitly assuming its existence i.e. the surjectivity of the function defined above). Is there any other way to do this?",,"['real-analysis', 'functions']"
34,How can one show that $f(0)=0$ for $f$ satisfying certain conditions?,How can one show that  for  satisfying certain conditions?,f(0)=0 f,"Given the functional equation  $$f(x+(1+x)f(y))=y+(1+y)f(x)$$ Such that $f:(-1,\infty) \to (-1,\infty)$ and the function $g(x):=\frac{f(x)}{x}$ is strictly increasing in $I=(-1,0)\cup(0,+\infty),$ how can one show that for every $t \in I$ we have  $f(t)\neq t$? Plugging $x=y=0,$ that makes $f(f(0))=f(0).$ Does that mean that $f(0)=0$? Making $x=y,$ $f(x+(1+x)f(x))=x+(1+x)f(x)$ so we make $x+(1+x)f(x)=t$ that makes $f(t)=t$ but we can't make $t=0$ because $t$ is not in $I$? So do I have to use the fact that $\frac{f(x)}{x}$ is increasing? Then after all this work we have to deduce that $f(0)=0$ and $f(x)=\frac{-x}{x+1}$ for $x \in (-1,\infty).$","Given the functional equation  $$f(x+(1+x)f(y))=y+(1+y)f(x)$$ Such that $f:(-1,\infty) \to (-1,\infty)$ and the function $g(x):=\frac{f(x)}{x}$ is strictly increasing in $I=(-1,0)\cup(0,+\infty),$ how can one show that for every $t \in I$ we have  $f(t)\neq t$? Plugging $x=y=0,$ that makes $f(f(0))=f(0).$ Does that mean that $f(0)=0$? Making $x=y,$ $f(x+(1+x)f(x))=x+(1+x)f(x)$ so we make $x+(1+x)f(x)=t$ that makes $f(t)=t$ but we can't make $t=0$ because $t$ is not in $I$? So do I have to use the fact that $\frac{f(x)}{x}$ is increasing? Then after all this work we have to deduce that $f(0)=0$ and $f(x)=\frac{-x}{x+1}$ for $x \in (-1,\infty).$",,"['functions', 'functional-equations']"
35,Function / Map notation?,Function / Map notation?,,"Please forgive my ignorance, if I've phrased my question improperly. I'm not sure what the appropriate terminology is; that's the basis of my question. So, I'm not sure if I'm even remotely close in my description of this notation: I'm wondering what is the proper name for the following notation. Is it function notation? Or part of set notation? None of the mathematics courses I've taken at my college (College Algebra through Calculus II) has used this notation, but I've begun to encounter it in some of the calculus & analysis textbooks I've looked at, and I see it used here and elsewhere on the web. The other part of my question is, where can I learn more about the following notation (and similar/related notation)? It seems like notation like this should be covered in some course, but I haven't encountered on yet which did cover it: $$f : \mathbb{R} \to \mathbb{R} \quad \text{ or } \quad f : \mathbb{Z} \to \mathbb{R}$$ I understand this is a form of function notation, but I wasn't sure what to call it, and thus what would make a good google query. When I googled ""function notation,"" of course, the results I got back were about the familiar $y=f(x)$ notation.","Please forgive my ignorance, if I've phrased my question improperly. I'm not sure what the appropriate terminology is; that's the basis of my question. So, I'm not sure if I'm even remotely close in my description of this notation: I'm wondering what is the proper name for the following notation. Is it function notation? Or part of set notation? None of the mathematics courses I've taken at my college (College Algebra through Calculus II) has used this notation, but I've begun to encounter it in some of the calculus & analysis textbooks I've looked at, and I see it used here and elsewhere on the web. The other part of my question is, where can I learn more about the following notation (and similar/related notation)? It seems like notation like this should be covered in some course, but I haven't encountered on yet which did cover it: $$f : \mathbb{R} \to \mathbb{R} \quad \text{ or } \quad f : \mathbb{Z} \to \mathbb{R}$$ I understand this is a form of function notation, but I wasn't sure what to call it, and thus what would make a good google query. When I googled ""function notation,"" of course, the results I got back were about the familiar $y=f(x)$ notation.",,"['functions', 'notation']"
36,Functions satisfying the functional equation $ \big( 1 - f ( x ) f ( y ) \big) f ( x + y ) = f ( x ) + f ( y ) $,Functions satisfying the functional equation, \big( 1 - f ( x ) f ( y ) \big) f ( x + y ) = f ( x ) + f ( y ) ,"How can I prove that there is no real function defined on $ \mathbb R $ , continuous at $ 0 $ and not always vanishing satisfying the functional equation $$ \big( 1 - f ( x ) f ( y ) \big) f ( x + y ) = f ( x ) + f ( y ) \text ? \tag E $$","How can I prove that there is no real function defined on , continuous at and not always vanishing satisfying the functional equation", \mathbb R   0   \big( 1 - f ( x ) f ( y ) \big) f ( x + y ) = f ( x ) + f ( y ) \text ? \tag E ,"['functions', 'continuity', 'functional-equations']"
37,How to simplify this composition function $g(x)=\underset{n\text{ times}}{\underbrace{f \circ f \circ f \circ f\circ f \circ \cdots\circ f}}(x)$?,How to simplify this composition function ?,g(x)=\underset{n\text{ times}}{\underbrace{f \circ f \circ f \circ f\circ f \circ \cdots\circ f}}(x),Let $f(x)=\dfrac{\sin x}{(1+\sin^n(x))^{1/n}}$ and $g(x)=\underset{n\text{ times}}{\underbrace{f \circ f \circ f \circ f\circ f \circ \cdots\circ f}}(x)$. Where $\circ$ represents function composition. Show that $g(x)=\dfrac{\sin x}{(1+n\sin^n(x))^{1/n}}$. I cant spot any pattern in the composition function. Each time it's becoming more complicated. Am I missing something?,Let $f(x)=\dfrac{\sin x}{(1+\sin^n(x))^{1/n}}$ and $g(x)=\underset{n\text{ times}}{\underbrace{f \circ f \circ f \circ f\circ f \circ \cdots\circ f}}(x)$. Where $\circ$ represents function composition. Show that $g(x)=\dfrac{\sin x}{(1+n\sin^n(x))^{1/n}}$. I cant spot any pattern in the composition function. Each time it's becoming more complicated. Am I missing something?,,['calculus']
38,"""Proportional to"" - but nonlinear.","""Proportional to"" - but nonlinear.",,"If $A$ is proportional to $B$, then it means that $A$ varies with $B$ linearly (we're just not specifying the linear constant). Is there a similar notion for the case that $A$ increases as $B$ increases, but in the case that this relationship isn't necessarily linear? I'm looking for something like ""$A$ is ______ to $B$"".","If $A$ is proportional to $B$, then it means that $A$ varies with $B$ linearly (we're just not specifying the linear constant). Is there a similar notion for the case that $A$ increases as $B$ increases, but in the case that this relationship isn't necessarily linear? I'm looking for something like ""$A$ is ______ to $B$"".",,"['functions', 'terminology']"
39,How possible for function to be $A \subset f^{-1} \left( f(A) \right) \forall f$?,How possible for function to be ?,A \subset f^{-1} \left( f(A) \right) \forall f,"While trying to understand concept of measurable function I read on wiki more about function inverse and found interesting fact about them. For every function $f$, subset $A$ of the domain and subset $B$ of the   codomain we have $A \subset f^{−1}(f(A))$ and $f(f^{−1}(B))\subset B$. If $f$ is injective we have $A = f^{−1}(f(A))$ and if ''f'' is   surjective we have $f(f^{−1}(B)) = B$. I have made a sketch, and have some questions: 1) do we need to have mapping from all elements of A to other set? (Otherwise I get $f^{−1}(f(A)) \subset A$, see picture 2) 2) can inverse of surjective function have 2 elements at the domain? 3)$A \subset f^{−1}(f(A))$ does not work in general as you see! Maybe I do some restricted operations? It only works if I have 2 elements: 1 from set and 1 out of the set mapping to the same element in codomain.","While trying to understand concept of measurable function I read on wiki more about function inverse and found interesting fact about them. For every function $f$, subset $A$ of the domain and subset $B$ of the   codomain we have $A \subset f^{−1}(f(A))$ and $f(f^{−1}(B))\subset B$. If $f$ is injective we have $A = f^{−1}(f(A))$ and if ''f'' is   surjective we have $f(f^{−1}(B)) = B$. I have made a sketch, and have some questions: 1) do we need to have mapping from all elements of A to other set? (Otherwise I get $f^{−1}(f(A)) \subset A$, see picture 2) 2) can inverse of surjective function have 2 elements at the domain? 3)$A \subset f^{−1}(f(A))$ does not work in general as you see! Maybe I do some restricted operations? It only works if I have 2 elements: 1 from set and 1 out of the set mapping to the same element in codomain.",,['functions']
40,"Prove: If $f:A\to B, C\subseteq A, D\subseteq B$, then $f(C) \subseteq D \iff C \subseteq f^{-1}(D)$","Prove: If , then","f:A\to B, C\subseteq A, D\subseteq B f(C) \subseteq D \iff C \subseteq f^{-1}(D)","Prove: If $f:A\to B, C\subseteq A, D\subseteq B$, then $f(C) \subseteq D \iff C \subseteq f^{-1}(D)$ My attempt: Suppose $f(C) \subseteq D$. If $x\in C$, then $f(x)\in f(C)$ and certainly $f(x) \in D$ since $f(C)\subseteq D$. But whenever $f(x)\in D$, we have that $x\in f^{-1}(D)$. So $C\subseteq f^{-1}(D)$. Conversely, suppose $C\subseteq f^{-1}(D)$. Given that $C \subseteq f^{-1}(D)$, if $x\in f^{-1}(D)$, then certainly $f(x)\in d$. Hence $C\subseteq f^{-1}(D)$. Is there any flaw with my proof? Also, when is the equality part of this proof satisfied and why?","Prove: If $f:A\to B, C\subseteq A, D\subseteq B$, then $f(C) \subseteq D \iff C \subseteq f^{-1}(D)$ My attempt: Suppose $f(C) \subseteq D$. If $x\in C$, then $f(x)\in f(C)$ and certainly $f(x) \in D$ since $f(C)\subseteq D$. But whenever $f(x)\in D$, we have that $x\in f^{-1}(D)$. So $C\subseteq f^{-1}(D)$. Conversely, suppose $C\subseteq f^{-1}(D)$. Given that $C \subseteq f^{-1}(D)$, if $x\in f^{-1}(D)$, then certainly $f(x)\in d$. Hence $C\subseteq f^{-1}(D)$. Is there any flaw with my proof? Also, when is the equality part of this proof satisfied and why?",,['functions']
41,"Relation between continuity of $f$, $g$ and $f\circ g$","Relation between continuity of ,  and",f g f\circ g,"Let $f$, $g$  be  functions  from  $[0,1]$ to  $[0,1]$  with  $f$  strictly  increasing . Then $A.$ If  $f$  is  continuous  then  so  is  $f\circ g.$ $B.$ If $f$ and  $f\circ g$  are  continuous then  so  is  $g.$ $C.$ If  $g$  and $f\circ g$ are  continuous then  so  is  $f.$ Now  for  $A$ ,  I  can take  $g(x)=x$ and  $f$  any  discontinuous  function  thus  this  is  not  the  case. If $g$  is  the  Dirichlet function  and  $f$  is  the  $0$  function or  $f(x)=1$ for  all $x\in [0,1]$  then  $B$  could  be cancelled  but  $f$  needed  to  be  strictly  increasing here  so  this  was  nonsense . So  I  am  not  sure  about  the  last  two options. Any  help  is  appreciated . Thanks.","Let $f$, $g$  be  functions  from  $[0,1]$ to  $[0,1]$  with  $f$  strictly  increasing . Then $A.$ If  $f$  is  continuous  then  so  is  $f\circ g.$ $B.$ If $f$ and  $f\circ g$  are  continuous then  so  is  $g.$ $C.$ If  $g$  and $f\circ g$ are  continuous then  so  is  $f.$ Now  for  $A$ ,  I  can take  $g(x)=x$ and  $f$  any  discontinuous  function  thus  this  is  not  the  case. If $g$  is  the  Dirichlet function  and  $f$  is  the  $0$  function or  $f(x)=1$ for  all $x\in [0,1]$  then  $B$  could  be cancelled  but  $f$  needed  to  be  strictly  increasing here  so  this  was  nonsense . So  I  am  not  sure  about  the  last  two options. Any  help  is  appreciated . Thanks.",,"['real-analysis', 'functions', 'continuity', 'function-and-relation-composition']"
42,injective and surjective,injective and surjective,,"How to prove that a composite function $f\circ g$ is bijective$?$ because i have two questions. if $f$ is injective and $g$ is surjective, can $g\circ f$ be both injective and surjective? because the question assumes both sets to be the same criteria ( $f$ injective, $g$ surjective) , so one question is whether $g\circ f$ is injective and the other is if $g\circ f$ is surjective. i proved that if $f$ is injective then, $x=y$, $f(x)=f(y)$, then $g(f(x)) = g (f(y))$ so $g\circ f$ is injective. but is it true that if $f$ is injective and $g$ is surjective, then $g\circ f$ can also be surjective. its making me confused.","How to prove that a composite function $f\circ g$ is bijective$?$ because i have two questions. if $f$ is injective and $g$ is surjective, can $g\circ f$ be both injective and surjective? because the question assumes both sets to be the same criteria ( $f$ injective, $g$ surjective) , so one question is whether $g\circ f$ is injective and the other is if $g\circ f$ is surjective. i proved that if $f$ is injective then, $x=y$, $f(x)=f(y)$, then $g(f(x)) = g (f(y))$ so $g\circ f$ is injective. but is it true that if $f$ is injective and $g$ is surjective, then $g\circ f$ can also be surjective. its making me confused.",,['functions']
43,"Convolution can smooth an input function, is there an operation which bunches it up?","Convolution can smooth an input function, is there an operation which bunches it up?",,"An easy to remember description of what the convolution of two functions is, is to say that one is a weight function and the result is a weighted average of the other function. The canonical example would be a lowpass filter, which smoothes the input function by means of the filter (weight) function. A highpass filter, on the other hand does roughly the opposite by removing the smoothness. What I am looking for: is there an operation where a function is ""bunched up"" by another one, where ""bunching up"" should roughly mean: keep the value of the integral, reduce the support, or at least reduce function values which are already small, while increasing the larger ones, keep the symmetry between the two input functions (despite the fact that we call one the filter or weight). My hunch is that I could Fourier transform the input, shift all frequencies towards zero somehow making use of the second function and then reverse transform and normalize, but then the two input functions are not used symmetrically. And I don't want to invent this. I would think that this concept exists already. EDIT: If I understand the first answer correctly, @josh suggests that if a convolution kernel $\phi$ had a convolutional inverse $\phi^{-1}$, we could reverse a smoothing. Smoothing an $f$ by $f\ast\phi = g$ could then be reverted to $f\ast\phi\ast\phi^{-1} = g\ast\phi^{-1} = f$. As mentioned in that answer, the ""convolutional inverse"" does not seem to exist always as a well behaved function. So I would like to invite more answers, not bound to convolution at all, maybe even non-linear operations.","An easy to remember description of what the convolution of two functions is, is to say that one is a weight function and the result is a weighted average of the other function. The canonical example would be a lowpass filter, which smoothes the input function by means of the filter (weight) function. A highpass filter, on the other hand does roughly the opposite by removing the smoothness. What I am looking for: is there an operation where a function is ""bunched up"" by another one, where ""bunching up"" should roughly mean: keep the value of the integral, reduce the support, or at least reduce function values which are already small, while increasing the larger ones, keep the symmetry between the two input functions (despite the fact that we call one the filter or weight). My hunch is that I could Fourier transform the input, shift all frequencies towards zero somehow making use of the second function and then reverse transform and normalize, but then the two input functions are not used symmetrically. And I don't want to invent this. I would think that this concept exists already. EDIT: If I understand the first answer correctly, @josh suggests that if a convolution kernel $\phi$ had a convolutional inverse $\phi^{-1}$, we could reverse a smoothing. Smoothing an $f$ by $f\ast\phi = g$ could then be reverted to $f\ast\phi\ast\phi^{-1} = g\ast\phi^{-1} = f$. As mentioned in that answer, the ""convolutional inverse"" does not seem to exist always as a well behaved function. So I would like to invite more answers, not bound to convolution at all, maybe even non-linear operations.",,"['functions', 'convolution', 'binary-operations']"
44,Let $\ f_1:A \rightarrow B$ and $\ f_2:A \rightarrow B$. Prove or disprove $f_1 \cap f_2$ iff $f_1=f_2$.,Let  and . Prove or disprove  iff .,\ f_1:A \rightarrow B \ f_2:A \rightarrow B f_1 \cap f_2 f_1=f_2,"Here is the question I am working on (screenshot): So, I haven't worked with function proofs very much (especially in the context of iff statements and with intersections). I am looking to see if I am on the right track for how to approach this proof, and to look for feedback in the holes of my proof knowledge. Strategy: I will prove this statement (not disprove). Forward: Prove directly. Let $(x,y) \in f_1 \cap f_2$. This is equivalent to saying that $x \in f_1$ and $x \in f_2$, given by the intersection. From here, I am uncertain where to go and how to show this indicates $A=B$. Converse: I was thinking that I should proceed by contrapositive. To do the contrapositive, my statement would be ""If $A \neq B$, then $f_1 \cup f_2$ is not a function"". I am much more stuck with the converse direction, so a push in the right direction would be helpful. Additional question: Can you prove either side of a biconditional statement by contradiction?","Here is the question I am working on (screenshot): So, I haven't worked with function proofs very much (especially in the context of iff statements and with intersections). I am looking to see if I am on the right track for how to approach this proof, and to look for feedback in the holes of my proof knowledge. Strategy: I will prove this statement (not disprove). Forward: Prove directly. Let $(x,y) \in f_1 \cap f_2$. This is equivalent to saying that $x \in f_1$ and $x \in f_2$, given by the intersection. From here, I am uncertain where to go and how to show this indicates $A=B$. Converse: I was thinking that I should proceed by contrapositive. To do the contrapositive, my statement would be ""If $A \neq B$, then $f_1 \cup f_2$ is not a function"". I am much more stuck with the converse direction, so a push in the right direction would be helpful. Additional question: Can you prove either side of a biconditional statement by contradiction?",,"['functions', 'proof-writing']"
45,Prove that $f(X\cap f^{-1}(Y))=f(X)\cap Y$,Prove that,f(X\cap f^{-1}(Y))=f(X)\cap Y,"Let $\ f\colon A\to B$ and let $X\subset A$, $Y\subset B$, prove that   $$f(X\cap f^{-1}(Y))=f(X)\cap Y$$ The ""$\subset$""$-$inclusion is easy: if $y\in f(X\cap f^{-1}(Y))$, exists a $x\in X\cap f^{-1}(Y)$ such that $f(x)=y$. Thus, $x\in X$ and $x\in f^{-1}(Y)$, and hence $f(x)\in f(X)$ and $f(x)\in Y$. This leads to $f(x)=y\in f(X)\cap Y$. I'm having problems with the other inclusion. If I proceed the same way I get: if $y\in f(X)\cap Y$, then $y\in f(X)$ and $y\in Y$. Thus, exists a $x\in X$ such that $f(x)=y$, and exists a $x'\in f^{-1}(Y)$ such that $f(x')=y$. If $x=x'$, it's clear the result, but don't know whether $x=x'$. I don't know what to do. I'll thank any help.","Let $\ f\colon A\to B$ and let $X\subset A$, $Y\subset B$, prove that   $$f(X\cap f^{-1}(Y))=f(X)\cap Y$$ The ""$\subset$""$-$inclusion is easy: if $y\in f(X\cap f^{-1}(Y))$, exists a $x\in X\cap f^{-1}(Y)$ such that $f(x)=y$. Thus, $x\in X$ and $x\in f^{-1}(Y)$, and hence $f(x)\in f(X)$ and $f(x)\in Y$. This leads to $f(x)=y\in f(X)\cap Y$. I'm having problems with the other inclusion. If I proceed the same way I get: if $y\in f(X)\cap Y$, then $y\in f(X)$ and $y\in Y$. Thus, exists a $x\in X$ such that $f(x)=y$, and exists a $x'\in f^{-1}(Y)$ such that $f(x')=y$. If $x=x'$, it's clear the result, but don't know whether $x=x'$. I don't know what to do. I'll thank any help.",,"['functions', 'elementary-set-theory']"
46,How to determine the generating function?,How to determine the generating function?,,"So I have $$\overset{*}{F} = \overset{*}{F}_{n-1} + \overset{*}{F}_{n-2} + g(n)$$ where $\overset{*}{F}$ is NOT a Fibonacci number for $n \geq 2$. $g(n)$ is any function $g: \mathbb{N} \to \mathbb{R}$. And $\overset{*}{F}_0 = g(0)$ and $\overset{*}{F}_1 = g(1)$. I think that $\overset{*}{F}_n$ would be a sequence of $g(n)$s. Actually, I have found that $$\overset{*}{F}_n = f_{n-1}\cdot g(0) + f_n\cdot g(1) + f_{n-1}\cdot g(2) + f_{n-2}\cdot g(3) + \dots + f_1\cdot g(n)$$ Here $f_n$ is the n-th Fibonacci number. So to clarify, let n = 5, then: $$\overset{*}{F}_5 = f_4\cdot g(0) + f_5\cdot g(1) + f_4\cdot g(2) + f_3\cdot g(3) + f_2\cdot g(4) + f_1\cdot g(5)$$ $$\overset{*}{F}_5 = 3\cdot g(0) + 5\cdot g(1) + 3\cdot g(2) + 2\cdot g(3) + 1\cdot g(4) + 1\cdot g(5)$$ My question is how to find the generating function of $\overset{*}{F}_n$ if $$G(x) = \sum^{\infty}_{n=0}g(n)\cdot x^n$$ applies? I have difficulties representing the generating function of the Fibonacci numbers reversed. Even though that I know that the regular g.f. $F(x) = \frac{1}{1-x-x^2}$ Maybe I should somehow transform this: $$\overset{*}{F}_n = f_{n-1}\cdot g(0)x^0 + f_n\cdot g(1)x^1 + f_{n-1}\cdot g(2)x^2 + f_{n-2}\cdot g(3)x^3 + \dots + f_1\cdot g(n)x^n$$ and use $G(x)$ to get the generating function for all $\overset{*}{F}_n$?","So I have $$\overset{*}{F} = \overset{*}{F}_{n-1} + \overset{*}{F}_{n-2} + g(n)$$ where $\overset{*}{F}$ is NOT a Fibonacci number for $n \geq 2$. $g(n)$ is any function $g: \mathbb{N} \to \mathbb{R}$. And $\overset{*}{F}_0 = g(0)$ and $\overset{*}{F}_1 = g(1)$. I think that $\overset{*}{F}_n$ would be a sequence of $g(n)$s. Actually, I have found that $$\overset{*}{F}_n = f_{n-1}\cdot g(0) + f_n\cdot g(1) + f_{n-1}\cdot g(2) + f_{n-2}\cdot g(3) + \dots + f_1\cdot g(n)$$ Here $f_n$ is the n-th Fibonacci number. So to clarify, let n = 5, then: $$\overset{*}{F}_5 = f_4\cdot g(0) + f_5\cdot g(1) + f_4\cdot g(2) + f_3\cdot g(3) + f_2\cdot g(4) + f_1\cdot g(5)$$ $$\overset{*}{F}_5 = 3\cdot g(0) + 5\cdot g(1) + 3\cdot g(2) + 2\cdot g(3) + 1\cdot g(4) + 1\cdot g(5)$$ My question is how to find the generating function of $\overset{*}{F}_n$ if $$G(x) = \sum^{\infty}_{n=0}g(n)\cdot x^n$$ applies? I have difficulties representing the generating function of the Fibonacci numbers reversed. Even though that I know that the regular g.f. $F(x) = \frac{1}{1-x-x^2}$ Maybe I should somehow transform this: $$\overset{*}{F}_n = f_{n-1}\cdot g(0)x^0 + f_n\cdot g(1)x^1 + f_{n-1}\cdot g(2)x^2 + f_{n-2}\cdot g(3)x^3 + \dots + f_1\cdot g(n)x^n$$ and use $G(x)$ to get the generating function for all $\overset{*}{F}_n$?",,"['sequences-and-series', 'functions', 'recurrence-relations', 'generating-functions', 'fibonacci-numbers']"
47,How many Fibonacci Numbers are in the sequence,How many Fibonacci Numbers are in the sequence,,"I have $I_n = \{2^n + 1, 2^n + 2, 2^n + 3, \dots , 2^{n+1}\}$ and I am trying to prove using induction how many Fibonacci numbers are there. First, the length of $I_n$ is $|I_n| = 2^n$ then for $F_0 = 1$ and for $F_1 = 1$ but how can I transform the Binet`s formula for my induction hypothesis and and what exactly to derive it from. The Binet formula in general: $$F_n = \frac{\phi^n -(- \phi)^n}{\sqrt{5}}$$ where $\phi = \frac{1 + \sqrt{5}}{2}$ Question How to prove with Induction over n the number of Fibonacci numbers in $I_n$?","I have $I_n = \{2^n + 1, 2^n + 2, 2^n + 3, \dots , 2^{n+1}\}$ and I am trying to prove using induction how many Fibonacci numbers are there. First, the length of $I_n$ is $|I_n| = 2^n$ then for $F_0 = 1$ and for $F_1 = 1$ but how can I transform the Binet`s formula for my induction hypothesis and and what exactly to derive it from. The Binet formula in general: $$F_n = \frac{\phi^n -(- \phi)^n}{\sqrt{5}}$$ where $\phi = \frac{1 + \sqrt{5}}{2}$ Question How to prove with Induction over n the number of Fibonacci numbers in $I_n$?",,"['sequences-and-series', 'functions', 'induction', 'fibonacci-numbers']"
48,Curious formula for minimum?,Curious formula for minimum?,,"A few years ago I derived the following formula which I just came across in my notes: $$\min(x,y)=\log\left(\frac{e^x+e^y}{1+e^{|x-y|}}\right)=y+\log\left(\frac{1+e^{x-y}}{1+e^{|x-y|}}\right).$$ Has anyone seen this before, and if so is there a reference? There is also a version for $\max$, $$\max(x,y)=\log \left(\frac{e^x+e^y}{1+e^{-\left| x-y\right| }}\right).$$ At the time (rightly or wrongly!) I thought maybe it might shed light on ""$\min$"" and ""$\max$"" analogies for complex numbers, but apart from producing a new complex number (different to $x$ and $y$) it didn't yield much. Still I'd not seen this before so thought it might be of interest... Works perfectly for the reals. UPDATE Apparently this is related to the Softmax function.","A few years ago I derived the following formula which I just came across in my notes: $$\min(x,y)=\log\left(\frac{e^x+e^y}{1+e^{|x-y|}}\right)=y+\log\left(\frac{1+e^{x-y}}{1+e^{|x-y|}}\right).$$ Has anyone seen this before, and if so is there a reference? There is also a version for $\max$, $$\max(x,y)=\log \left(\frac{e^x+e^y}{1+e^{-\left| x-y\right| }}\right).$$ At the time (rightly or wrongly!) I thought maybe it might shed light on ""$\min$"" and ""$\max$"" analogies for complex numbers, but apart from producing a new complex number (different to $x$ and $y$) it didn't yield much. Still I'd not seen this before so thought it might be of interest... Works perfectly for the reals. UPDATE Apparently this is related to the Softmax function.",,['functions']
49,"Is this is the right way to do these one-to-one functions, finding their inverse, if not, how to do it?","Is this is the right way to do these one-to-one functions, finding their inverse, if not, how to do it?",,"Question 1)    $f(x) = 1-x$ My answer (1):   $f(x) = 1-x$, $y = 1 - x$, $y + 1 = x$, $x = y + 1$,  $f$ of inverse $f(y) = y + 1$ Question 2) :  $f(x) = \dfrac{2x}{x-1}$ My answer 2) :  $f(x) = \frac{2x}{x-1} = y$, $\frac{2x}{x-1}$,  $y+1=2x$, $\frac{y+1}{2} = x$, $x= \frac{y+1}{2}$, $f$ of inverse $f(y) = \frac{y+1}{2}$ Question 3):  $f(x) = \sqrt{5} - x$ My answer 3) : $f(x) = \sqrt{5} - x = y = \sqrt{5} - x = y + 5 = x = x = y + 5$, f of inverse $f(y) = y + 5$ Question 4):  $f(x) = x^3$ My answer 4): $f(x) = x^3$,  $y=x^3$, $y^3 = x$, $x=y^3$, f of inverse $f(y)  = y^3$","Question 1)    $f(x) = 1-x$ My answer (1):   $f(x) = 1-x$, $y = 1 - x$, $y + 1 = x$, $x = y + 1$,  $f$ of inverse $f(y) = y + 1$ Question 2) :  $f(x) = \dfrac{2x}{x-1}$ My answer 2) :  $f(x) = \frac{2x}{x-1} = y$, $\frac{2x}{x-1}$,  $y+1=2x$, $\frac{y+1}{2} = x$, $x= \frac{y+1}{2}$, $f$ of inverse $f(y) = \frac{y+1}{2}$ Question 3):  $f(x) = \sqrt{5} - x$ My answer 3) : $f(x) = \sqrt{5} - x = y = \sqrt{5} - x = y + 5 = x = x = y + 5$, f of inverse $f(y) = y + 5$ Question 4):  $f(x) = x^3$ My answer 4): $f(x) = x^3$,  $y=x^3$, $y^3 = x$, $x=y^3$, f of inverse $f(y)  = y^3$",,['functions']
50,Determine whether F is injective and surjective,Determine whether F is injective and surjective,,"Let $f:\mathbb{R} \to \mathbb{R}$ be a function. Determine whether or not f is injective and surjective where $f(x)=|x|$ So if i'm right, it is not injective and it is not surjective. For a proof, i'll do a counter example: injective counter example: let $x=-1$ and $x=1,$ you will get $y=1$ meaning two x is mapped to one in the codomain. surjective counter example: there is no $x$ which lets you obtain $y=-1$ anyone can verify?","Let $f:\mathbb{R} \to \mathbb{R}$ be a function. Determine whether or not f is injective and surjective where $f(x)=|x|$ So if i'm right, it is not injective and it is not surjective. For a proof, i'll do a counter example: injective counter example: let $x=-1$ and $x=1,$ you will get $y=1$ meaning two x is mapped to one in the codomain. surjective counter example: there is no $x$ which lets you obtain $y=-1$ anyone can verify?",,['functions']
51,How to prove if something is a function?,How to prove if something is a function?,,"I know two conditions to prove if something is a function: If $f: A \to B$ then the domain of the function should be A. If ($z,x$) , ($z,y$) $\in f$ then $x = y$. Now for example I have two functions: $f:Z \to Z$ $g: Z \to Z$ And I have to show that the following are also functions: $h: Z \to Z$ defined as $h(x) = f(g(x))$. $h: Z \to Z$ defined as $h(x) = f(x) + g(x)$. $h: Z \to Z$ defined as $h(x) = f(x) \times g(x)$. Now in all these cases to I would have to show that the $Dom(h) = Z$. Now I show this by showing $Dom(h) \subset Z$ and then showing $Z \subset Dom(h)$. Hence through this I am able to show $Dom(h) = Z$. Now to show this for the three functions: 1 (a). $Dom(h) \subset Z$: $Dom(h) = Dom(f(g(x))) = Dom (g(x)) = Z$ . (As this is an equality can I use this statement instead showing both sides as subsets of each other?) 1 (b). $Z \subset Dom(h)$: (I don't understand how I would show this side.) 2 (a), (b). $Dom(h) = Dom(f(x) + g(x)$ = $Dom(f(x) + Dom(g(x)) = Z + Z = Z$ 3 (a), (b). $Dom(h) = Dom(f(x) + g(x)$ = $Dom(f(x) * Dom(g(x)) = Z$ (Can I do this instead of showing them subsets for each side. Plus here is it correct to say $Dom(f(x)*g(x)) = Z.$ What if the domains of the two functions were different? Now for each function I have to show that each element in the domain only maps to one element in the co-domain. (How would I show this?) Is this method correct: Let $(z,x), (z,y) \in h$. Then $(z,x), (z,y) \in f(g(x))$ hence $\exists a,b : (z,a), (z,b) \in g$ AND $(a,x), (b,y) \in f$. So as $g$ is a function $a = b$, and then as $f$ is a function $x=y$ hence $h$ is a function. Let $(z,x), (z,y) \in h$. Then $(z,x), (z,y) \in f(x) + g(x)$ hence $\exists a,b,c,d : (z,a), (z,b) \in g$ AND $(z,c), (z,d) \in f$. ($x=a+c$, $y=b+d$). So as $g$ is a function $a = b$, and then as $f$ is a function $c=d$ hence $x=y$ so $h$ is a function. Let $(z,x), (z,y) \in h$. Then $(z,x), (z,y) \in f(x) \times g(x)$ hence $\exists a,b,c,d : (z,a), (z,b) \in g$ AND $(z,c), (z,d) \in f$. ($x=a*c$, $y=b*d$). So as $g$ is a function $a = b$, and then as $f$ is a function $c=d$ hence $x=y$ so $h$ is a function.","I know two conditions to prove if something is a function: If $f: A \to B$ then the domain of the function should be A. If ($z,x$) , ($z,y$) $\in f$ then $x = y$. Now for example I have two functions: $f:Z \to Z$ $g: Z \to Z$ And I have to show that the following are also functions: $h: Z \to Z$ defined as $h(x) = f(g(x))$. $h: Z \to Z$ defined as $h(x) = f(x) + g(x)$. $h: Z \to Z$ defined as $h(x) = f(x) \times g(x)$. Now in all these cases to I would have to show that the $Dom(h) = Z$. Now I show this by showing $Dom(h) \subset Z$ and then showing $Z \subset Dom(h)$. Hence through this I am able to show $Dom(h) = Z$. Now to show this for the three functions: 1 (a). $Dom(h) \subset Z$: $Dom(h) = Dom(f(g(x))) = Dom (g(x)) = Z$ . (As this is an equality can I use this statement instead showing both sides as subsets of each other?) 1 (b). $Z \subset Dom(h)$: (I don't understand how I would show this side.) 2 (a), (b). $Dom(h) = Dom(f(x) + g(x)$ = $Dom(f(x) + Dom(g(x)) = Z + Z = Z$ 3 (a), (b). $Dom(h) = Dom(f(x) + g(x)$ = $Dom(f(x) * Dom(g(x)) = Z$ (Can I do this instead of showing them subsets for each side. Plus here is it correct to say $Dom(f(x)*g(x)) = Z.$ What if the domains of the two functions were different? Now for each function I have to show that each element in the domain only maps to one element in the co-domain. (How would I show this?) Is this method correct: Let $(z,x), (z,y) \in h$. Then $(z,x), (z,y) \in f(g(x))$ hence $\exists a,b : (z,a), (z,b) \in g$ AND $(a,x), (b,y) \in f$. So as $g$ is a function $a = b$, and then as $f$ is a function $x=y$ hence $h$ is a function. Let $(z,x), (z,y) \in h$. Then $(z,x), (z,y) \in f(x) + g(x)$ hence $\exists a,b,c,d : (z,a), (z,b) \in g$ AND $(z,c), (z,d) \in f$. ($x=a+c$, $y=b+d$). So as $g$ is a function $a = b$, and then as $f$ is a function $c=d$ hence $x=y$ so $h$ is a function. Let $(z,x), (z,y) \in h$. Then $(z,x), (z,y) \in f(x) \times g(x)$ hence $\exists a,b,c,d : (z,a), (z,b) \in g$ AND $(z,c), (z,d) \in f$. ($x=a*c$, $y=b*d$). So as $g$ is a function $a = b$, and then as $f$ is a function $c=d$ hence $x=y$ so $h$ is a function.",,"['functions', 'solution-verification']"
52,Is it of any value to express a function as the sum of an even and an odd function?,Is it of any value to express a function as the sum of an even and an odd function?,,"So I learned about this formula $$ f(x) = \frac{f(x)+f(-x)}{2}+\frac{f(x)-f(-x)}{2} $$ and I'm wondering, is it of any value to express a function in this form?","So I learned about this formula $$ f(x) = \frac{f(x)+f(-x)}{2}+\frac{f(x)-f(-x)}{2} $$ and I'm wondering, is it of any value to express a function in this form?",,['functions']
53,Help prove $f:X \rightarrow Y$ is an injection $\Leftrightarrow$ $f:X\rightarrow Y$ is a surjection when $|X|=|Y|$,Help prove  is an injection   is a surjection when,f:X \rightarrow Y \Leftrightarrow f:X\rightarrow Y |X|=|Y|,"I need to prove: Given non-empty finite sets $X$ and $Y$ with $|X| = |Y|,$ a function $X\rightarrow Y$ is an injection if and only if it is a surjection. The hint given is to use the pigeonhole principle and proof by contradiction. Here's what I've tried: From the given assumptions, I know that: $|X|=|Y|=n$ for some $n\in \mathbb{Z}^+$ There exist bijections $g:\mathbb{N}_n \rightarrow X$ and $h:\mathbb{N}_n \rightarrow Y$ So I need to prove: $f:X \rightarrow Y$ is an injection $\Leftrightarrow$ $f:X\rightarrow Y$ is a surjection So, to prove the case $\Rightarrow$: Suppose for contradiction, $f:X\rightarrow Y \text{ is injective but not surjective} \tag{1}$ Furthermore, $f:X\rightarrow Y$ is an injection $\Rightarrow |X|\le |Y|$, by the pigeonhole principle. This is where I am stuck. I think I need to conclude that $|X|>|Y|$ from $(1)$ so that I can get the contradiction: $|X|\le |Y| \text{ and } |X|>|Y|$ To prove the case $\Leftarrow$: Suppose for contradiction: $f:X\rightarrow Y \text{ is surjective but not injective }\tag{ 2}$ Furthermore, $\begin{align} f:X \rightarrow Y \text{ is a surjection } & \Rightarrow & \exists g:Y\rightarrow X \text{ an injection (previous exercise) }\\ & \Rightarrow & |Y| \le |X|, \text{ pigeonhole principle } \end{align}$ I'm also stuck here. Similar to 3, I think I need to conclude $|Y|>|X|$ from $(2)$ to get a contradiction. Can I please get some help to complete steps 3 and 4?","I need to prove: Given non-empty finite sets $X$ and $Y$ with $|X| = |Y|,$ a function $X\rightarrow Y$ is an injection if and only if it is a surjection. The hint given is to use the pigeonhole principle and proof by contradiction. Here's what I've tried: From the given assumptions, I know that: $|X|=|Y|=n$ for some $n\in \mathbb{Z}^+$ There exist bijections $g:\mathbb{N}_n \rightarrow X$ and $h:\mathbb{N}_n \rightarrow Y$ So I need to prove: $f:X \rightarrow Y$ is an injection $\Leftrightarrow$ $f:X\rightarrow Y$ is a surjection So, to prove the case $\Rightarrow$: Suppose for contradiction, $f:X\rightarrow Y \text{ is injective but not surjective} \tag{1}$ Furthermore, $f:X\rightarrow Y$ is an injection $\Rightarrow |X|\le |Y|$, by the pigeonhole principle. This is where I am stuck. I think I need to conclude that $|X|>|Y|$ from $(1)$ so that I can get the contradiction: $|X|\le |Y| \text{ and } |X|>|Y|$ To prove the case $\Leftarrow$: Suppose for contradiction: $f:X\rightarrow Y \text{ is surjective but not injective }\tag{ 2}$ Furthermore, $\begin{align} f:X \rightarrow Y \text{ is a surjection } & \Rightarrow & \exists g:Y\rightarrow X \text{ an injection (previous exercise) }\\ & \Rightarrow & |Y| \le |X|, \text{ pigeonhole principle } \end{align}$ I'm also stuck here. Similar to 3, I think I need to conclude $|Y|>|X|$ from $(2)$ to get a contradiction. Can I please get some help to complete steps 3 and 4?",,"['functions', 'proof-writing', 'pigeonhole-principle']"
54,Concerning Rules of Exponents & Absolute Value,Concerning Rules of Exponents & Absolute Value,,"I understand that one of the accepted definitions of the absolute value function is $\left| x \right| = \sqrt{x^2}$. However, I do not understand why if I substitute $-5$ in for $x$ that I can't do the following using rules of exponents: $\left|-5\right| = \sqrt{(-5)^2} = \left[(-5)^2\right]^\frac 12 = (-5)^\frac 22 = (-5)^\frac 11 = -5$. Clearly we know that the end result isn't right, but I can't find any logical problems with my reasoning. Can someone shed some light onto the situation for me? Thanks!","I understand that one of the accepted definitions of the absolute value function is $\left| x \right| = \sqrt{x^2}$. However, I do not understand why if I substitute $-5$ in for $x$ that I can't do the following using rules of exponents: $\left|-5\right| = \sqrt{(-5)^2} = \left[(-5)^2\right]^\frac 12 = (-5)^\frac 22 = (-5)^\frac 11 = -5$. Clearly we know that the end result isn't right, but I can't find any logical problems with my reasoning. Can someone shed some light onto the situation for me? Thanks!",,"['functions', 'exponentiation', 'absolute-value']"
55,Increasing marginal product implies increasing returns to scale?,Increasing marginal product implies increasing returns to scale?,,"Setup Let $f(x,y)$ be twice differentiable in both $x$ and $y$ . Assume $\partial f/\partial x>0,\partial f/\partial y>0$ for $x,y>0$ . $f$ is said to have increasing marginal product of input $x$ if its second derivative with respect to $x$ is positive, i.e. $\partial^2 f/\partial x^2>0$ for $x,y>0$ . $f$ is said to have increasing returns to scale if, $\alpha f(x,y)<f(\alpha x,\alpha y)$ for $\alpha>1$ and $x,y>0$ . Question Does it follow that whenever $f$ has increasing marginal product of input $x$ , it also has increasing returns to scale?","Setup Let be twice differentiable in both and . Assume for . is said to have increasing marginal product of input if its second derivative with respect to is positive, i.e. for . is said to have increasing returns to scale if, for and . Question Does it follow that whenever has increasing marginal product of input , it also has increasing returns to scale?","f(x,y) x y \partial f/\partial x>0,\partial f/\partial y>0 x,y>0 f x x \partial^2 f/\partial x^2>0 x,y>0 f \alpha f(x,y)<f(\alpha x,\alpha y) \alpha>1 x,y>0 f x","['functions', 'inequality', 'economics']"
56,Difference of concave functions,Difference of concave functions,,"Suppose that there are two concave functions $f_1(x)$ and $f_2(x)$ defined on $x\geq0$. In addition, the functions are  positive, smooth, bounded ($|f_2|\leq b_2,|f_1|\leq b_1$ such that $b_2 = b_1<\infty$), monotone increasing and $f_1\geq f_2$ where $f_1(0)=f_2(0)=0$. I'm trying to be as much specific as I can because my question is a bit vague: Is there something general that can be said about the  difference $f_1-f_2$ without the further knowledge of the behavior of their derivatives? Namely, is there something to say about the number of local extrema or stationary points the difference can have? To elaborate: clearly, $f'_1(0)>f'_2(0)$ but for $x>0$ the derivative of $f_2$ can become greater than that of $f_1$ at least once. In that case there is  one stationary point. Can there be more? What changes if $b_2< b_1<\infty$ or if both functions are unbounded? Feel free to point me to books, web sites or lecture notes where the answers are. This is not a homework. EDIT: Loosely speaking, can a difference of two functions satisfying the assumptions above have many ($>1$) humps and dips? If yes provide an example or argument. What would the two functions have to satisfy for their difference to have just one stationary point (that is one function approaches the other, crosses it and departs)?","Suppose that there are two concave functions $f_1(x)$ and $f_2(x)$ defined on $x\geq0$. In addition, the functions are  positive, smooth, bounded ($|f_2|\leq b_2,|f_1|\leq b_1$ such that $b_2 = b_1<\infty$), monotone increasing and $f_1\geq f_2$ where $f_1(0)=f_2(0)=0$. I'm trying to be as much specific as I can because my question is a bit vague: Is there something general that can be said about the  difference $f_1-f_2$ without the further knowledge of the behavior of their derivatives? Namely, is there something to say about the number of local extrema or stationary points the difference can have? To elaborate: clearly, $f'_1(0)>f'_2(0)$ but for $x>0$ the derivative of $f_2$ can become greater than that of $f_1$ at least once. In that case there is  one stationary point. Can there be more? What changes if $b_2< b_1<\infty$ or if both functions are unbounded? Feel free to point me to books, web sites or lecture notes where the answers are. This is not a homework. EDIT: Loosely speaking, can a difference of two functions satisfying the assumptions above have many ($>1$) humps and dips? If yes provide an example or argument. What would the two functions have to satisfy for their difference to have just one stationary point (that is one function approaches the other, crosses it and departs)?",,"['functions', 'convex-analysis']"
57,Determine linear map $T$ such that $T(f)(x)\geq 0$.,Determine linear map  such that .,T T(f)(x)\geq 0,"Determine the linear mappings $T$ of $(C^2([0,1],\mathbb R)$ in $C^0([0,1],\mathbb R)$   such that for every $f \in C^2([0,1],\mathbb R)$ and all $x \in(0.1)$ if $f$ has a local minimum at $x$, then $T(f)(x)\geq 0$. My attempt : If $f$ is $\mathcal {C}^2$ and admits a local minimum at $x$, we can probably show that $f$ is convex in the vicinity of $x$ as $x$ is within the segment $[0,1]$. $$ T(f)(x) = f''(x) $$ It is linear and it satisfies the hypotheses. Nevertheless, I have not managed to prove this rigorously. Any help will be very appreciated. Thank you in advance.","Determine the linear mappings $T$ of $(C^2([0,1],\mathbb R)$ in $C^0([0,1],\mathbb R)$   such that for every $f \in C^2([0,1],\mathbb R)$ and all $x \in(0.1)$ if $f$ has a local minimum at $x$, then $T(f)(x)\geq 0$. My attempt : If $f$ is $\mathcal {C}^2$ and admits a local minimum at $x$, we can probably show that $f$ is convex in the vicinity of $x$ as $x$ is within the segment $[0,1]$. $$ T(f)(x) = f''(x) $$ It is linear and it satisfies the hypotheses. Nevertheless, I have not managed to prove this rigorously. Any help will be very appreciated. Thank you in advance.",,['calculus']
58,Example of functions that grow faster than the exponential functions and/or factorial functions?,Example of functions that grow faster than the exponential functions and/or factorial functions?,,What is example of functions that grow faster than the exponential functions and/or factorial functions?,What is example of functions that grow faster than the exponential functions and/or factorial functions?,,['functions']
59,Proving whether functions are one-to-one and onto.,Proving whether functions are one-to-one and onto.,,"I'm doing some practice problems and am having trouble answering these problems: Prove or disprove each statement. (a) If $f : A \rightarrow A$ is one-to-one, then $f$ is onto. (b) If $A$ is finite and $f : A \rightarrow A$ is one-to-one, then f is onto. (c) If $f : A \rightarrow A$ is $f$ is onto, then $f$ is one-to-one. (d) If $A$ is finite and $f : A \rightarrow A$ is $f$ is onto, then $f$ is one-to-one I know that for a function to be one-to-one there can't be two distinct elements in the domain that map to the same element in the codomain. Also that a function is onto if every element in the codomain has a pre-image in the domain (or in other words every element in the codomain must be mapped to an element in the domain). Pictorially what I mean is this: So for my problem:  In part a) I believe that just because a function is one-to-one it does not necessarily have to be onto as can be seen from the diagram. But then I feel like you can use the same logic to disprove all of them, which I'm not sure it correct. (maybe the finite ones are true?) Any help with these problems would be appreciated.","I'm doing some practice problems and am having trouble answering these problems: Prove or disprove each statement. (a) If $f : A \rightarrow A$ is one-to-one, then $f$ is onto. (b) If $A$ is finite and $f : A \rightarrow A$ is one-to-one, then f is onto. (c) If $f : A \rightarrow A$ is $f$ is onto, then $f$ is one-to-one. (d) If $A$ is finite and $f : A \rightarrow A$ is $f$ is onto, then $f$ is one-to-one I know that for a function to be one-to-one there can't be two distinct elements in the domain that map to the same element in the codomain. Also that a function is onto if every element in the codomain has a pre-image in the domain (or in other words every element in the codomain must be mapped to an element in the domain). Pictorially what I mean is this: So for my problem:  In part a) I believe that just because a function is one-to-one it does not necessarily have to be onto as can be seen from the diagram. But then I feel like you can use the same logic to disprove all of them, which I'm not sure it correct. (maybe the finite ones are true?) Any help with these problems would be appreciated.",,"['functions', 'discrete-mathematics']"
60,How to approach proving $f^{-1}(B\setminus C)=A\setminus f^{-1}(C)$?,How to approach proving ?,f^{-1}(B\setminus C)=A\setminus f^{-1}(C),"Let $A,B,C$ be sets such that $C\subseteq B$. Let $f: A \to B$ be a function.  Prove that $f^{-1} (B\setminus C)=A\setminus f^{-1} (C).$ I really need help with this proof problem. I'm not sure where to begin or what strategy to consider using.","Let $A,B,C$ be sets such that $C\subseteq B$. Let $f: A \to B$ be a function.  Prove that $f^{-1} (B\setminus C)=A\setminus f^{-1} (C).$ I really need help with this proof problem. I'm not sure where to begin or what strategy to consider using.",,"['functions', 'elementary-set-theory']"
61,An inequality in $L^p$-spaces,An inequality in -spaces,L^p,"Let $\{f_k\}_{k=1}^{\infty}$ be a sequence in $L^p(\Omega,\Sigma,\mu)$ for $1\leq p<\infty$. Suppose $0<c=\inf_k \lVert f_k\rVert_p\leq \sup_k \lVert f_k\rVert_p=C<\infty$ and $f_if_j=0$ for $i\neq j$. Let $(a_k)_{k=1}^{\infty}$ be a sequence of real numbers such that $\sum_k \lvert a_k\rvert^p<\infty$. Then by the completeness of $L^p$, $f=\sum_{k=1}^\infty a_k f_k$ is a function in $L^p(\Omega,\Sigma,\mu)$. Moreover, $$ \lVert f\rVert _p\leq C(\sum_{k=1}^\infty \lvert a_k\rvert ^p)^{1/p}. $$ And when $p=2$, I can obtain $$ \lVert f\rVert_2\geq c(\sum_{k=1}^\infty \lvert a_k\rvert^2)^{1/2}. $$ In general, how to prove  $$ \lVert f\rVert _p\geq c(\sum_{k=1}^\infty \lvert a_k\rvert^p)^{1/p} $$ ??? I have no way to prove it.","Let $\{f_k\}_{k=1}^{\infty}$ be a sequence in $L^p(\Omega,\Sigma,\mu)$ for $1\leq p<\infty$. Suppose $0<c=\inf_k \lVert f_k\rVert_p\leq \sup_k \lVert f_k\rVert_p=C<\infty$ and $f_if_j=0$ for $i\neq j$. Let $(a_k)_{k=1}^{\infty}$ be a sequence of real numbers such that $\sum_k \lvert a_k\rvert^p<\infty$. Then by the completeness of $L^p$, $f=\sum_{k=1}^\infty a_k f_k$ is a function in $L^p(\Omega,\Sigma,\mu)$. Moreover, $$ \lVert f\rVert _p\leq C(\sum_{k=1}^\infty \lvert a_k\rvert ^p)^{1/p}. $$ And when $p=2$, I can obtain $$ \lVert f\rVert_2\geq c(\sum_{k=1}^\infty \lvert a_k\rvert^2)^{1/2}. $$ In general, how to prove  $$ \lVert f\rVert _p\geq c(\sum_{k=1}^\infty \lvert a_k\rvert^p)^{1/p} $$ ??? I have no way to prove it.",,"['real-analysis', 'functions', 'integral-inequality']"
62,"Given an inductive function, how to calculate?","Given an inductive function, how to calculate?",,"Currently having slight difficulty figuring out how to solve this. Given is; $$\begin{align}f(0) &= -3\\ f(1)&= 2 \\ f(n) &= f( n - 2 ) + 2  f( n - 1)\end{align}$$ Now, I need to calculate $f(5)$. I'm not sure how to handle a function like this. Fill the N's and dissasemble?","Currently having slight difficulty figuring out how to solve this. Given is; $$\begin{align}f(0) &= -3\\ f(1)&= 2 \\ f(n) &= f( n - 2 ) + 2  f( n - 1)\end{align}$$ Now, I need to calculate $f(5)$. I'm not sure how to handle a function like this. Fill the N's and dissasemble?",,['functions']
63,Logic: existence of a certain type of a bijective function on an infinite set,Logic: existence of a certain type of a bijective function on an infinite set,,"Let $X$ be an  infinite set. Prove that there is a bijective function $f: X \rightarrow X$ with the property that for every $x \in X$ and all $n > 0$: $f^n(x) \neq x$. I've tried to proved this by considering a bijective function $g: \mathbb{Z} \times X \rightarrow X$ in a certain way (by the composition of a function $f: \mathbb{Z} \times X \rightarrow \mathbb{Z} \times X$), but that's all i've got at the moment.","Let $X$ be an  infinite set. Prove that there is a bijective function $f: X \rightarrow X$ with the property that for every $x \in X$ and all $n > 0$: $f^n(x) \neq x$. I've tried to proved this by considering a bijective function $g: \mathbb{Z} \times X \rightarrow X$ in a certain way (by the composition of a function $f: \mathbb{Z} \times X \rightarrow \mathbb{Z} \times X$), but that's all i've got at the moment.",,"['elementary-set-theory', 'functions', 'logic']"
64,Prove that $T: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ is a bijection,Prove that  is a bijection,T: \mathbb{R}^2 \rightarrow \mathbb{R}^2,"I have to prove that the following is a bijection: $ T: \mathbb{R}^2 \rightarrow \mathbb{R}^2 $ , with $T(x,y)=  \left( \begin{array}{c}    5x + \sin(y)\\   5y + \arctan(x) \end{array} \right)$ Now, to prove it is surjective I composed it with $x = \tan(z)$ obtaining: $ T^1\colon \left]-\pi /2, \pi /2 \right[\times \mathbb{R} \rightarrow \mathbb{R}^2 $ , with $T^1(z,y)=  \left( \begin{array}{c}    5\tan(z) + \sin(y)\\   5y + z \end{array} \right) $ Then, if we consider a generic $(z_0,y_0)$ we have $5y+z=y_0 \Rightarrow z = y_0 - 5y$ and $5 \tan(y_0 - 5y) + \sin(y)=g(y)$ . Considering the limits for $g(y)$ at the inf and sup of its domain are $+ \infty$ and $-\infty$ and the continuity of $g(y)$ we prove the existence of $Y$ such that $g(Y) = z_0$ and then $Z = y_0 - 5Y$ and we've found a couple $(Y,Z)$ such that $T^1(Y,Z)=(z_0,y_0)$ . As for the injectivity I've noticed that, using the fact that sin and arctan are limited functions, we get $T(x,y)=T(x',y') \Rightarrow |x-x'|< \frac{2}{5}$ and $|y-y'|< \frac{2 \pi}{5}$ but I can't do any better. My questions are: 1) Is there an easier or better proof of surjectivity? (given that mine is correct...if not please point out where I did wrong) 2) Can somebody give me hints to prove the injectivity? Thank you very much in advance!","I have to prove that the following is a bijection: , with Now, to prove it is surjective I composed it with obtaining: , with Then, if we consider a generic we have and . Considering the limits for at the inf and sup of its domain are and and the continuity of we prove the existence of such that and then and we've found a couple such that . As for the injectivity I've noticed that, using the fact that sin and arctan are limited functions, we get and but I can't do any better. My questions are: 1) Is there an easier or better proof of surjectivity? (given that mine is correct...if not please point out where I did wrong) 2) Can somebody give me hints to prove the injectivity? Thank you very much in advance!"," T: \mathbb{R}^2 \rightarrow \mathbb{R}^2  T(x,y)=  \left(
\begin{array}{c} 
  5x + \sin(y)\\
  5y + \arctan(x)
\end{array}
\right) x = \tan(z)  T^1\colon \left]-\pi /2, \pi /2 \right[\times \mathbb{R} \rightarrow \mathbb{R}^2  T^1(z,y)=  \left(
\begin{array}{c} 
  5\tan(z) + \sin(y)\\
  5y + z
\end{array}
\right)
 (z_0,y_0) 5y+z=y_0 \Rightarrow z = y_0 - 5y 5 \tan(y_0 - 5y) + \sin(y)=g(y) g(y) + \infty -\infty g(y) Y g(Y) = z_0 Z = y_0 - 5Y (Y,Z) T^1(Y,Z)=(z_0,y_0) T(x,y)=T(x',y') \Rightarrow |x-x'|< \frac{2}{5} |y-y'|< \frac{2 \pi}{5}",['functions']
65,Function to penalise extreme values,Function to penalise extreme values,,"I am carrying out analysis on a corpus of data and I am currently investigating the frequency of words appearing in that corpus. What I am looking for is a function which penalises large and small values so that, instead of a graph of decreasing values as words become more infrequent, I will be left with an approximation of a bell shaped curve. Any help would be greatly appreciated. Patrick","I am carrying out analysis on a corpus of data and I am currently investigating the frequency of words appearing in that corpus. What I am looking for is a function which penalises large and small values so that, instead of a graph of decreasing values as words become more infrequent, I will be left with an approximation of a bell shaped curve. Any help would be greatly appreciated. Patrick",,['functions']
66,"Is there a name for this ""opposite of a projection"" function?","Is there a name for this ""opposite of a projection"" function?",,"I was wondering if there is a name of a function like $$(x_1, x_2,..., x_n) \mapsto (x_1, x_2, ..., x_n, 0, 0, ..., 0)\,.$$ I know when we do it the other way around it's called the projection. And when there is no $0$'s it's called the identity map. Is there a special name for this one?","I was wondering if there is a name of a function like $$(x_1, x_2,..., x_n) \mapsto (x_1, x_2, ..., x_n, 0, 0, ..., 0)\,.$$ I know when we do it the other way around it's called the projection. And when there is no $0$'s it's called the identity map. Is there a special name for this one?",,"['calculus', 'real-analysis', 'functions']"
67,Every injective function is an inclusion (up to a unique bijection),Every injective function is an inclusion (up to a unique bijection),,"Let $X$ be a set and let $A$ be a subet of $X$. Let $i:A\longrightarrow X$ be the usual inclusion of $A$ in $X$. Then $i$ is an example of an injective function. I want to show that every injective function is of this kind. More precisely: for every set $Y$ and every injective function $f:X\longrightarrow Y$, there exist a subset $B$ of $Y$ and a bijection $g:X\longrightarrow B$ such that $f$ factors through $B$, i.e. $f=j\circ g$, where $j$ is the inclusion of $B$ in $Y$. Moreover, $g$ is unique with respect to this property. I can take $B:=f(X)$ and $g:=f$ (so that $g$ is the same of $f$ as a rule, but with different codomain) and it is easely checked that everything works. Moreover $g$ is unique, since $j\circ g=f=j\circ g'$ implies $g=g'$ by injectivity of $j$. There is something that does not convince at all, in the unicity part. I mean, $g$ is unique if I fix $B=f(X)$, but what about the unicity of $B$? Is there a $B'$, different from $B$, and a $g'$ from $X$ to $B'$ bijective, such that $j'\circ g'=f$ holds?","Let $X$ be a set and let $A$ be a subet of $X$. Let $i:A\longrightarrow X$ be the usual inclusion of $A$ in $X$. Then $i$ is an example of an injective function. I want to show that every injective function is of this kind. More precisely: for every set $Y$ and every injective function $f:X\longrightarrow Y$, there exist a subset $B$ of $Y$ and a bijection $g:X\longrightarrow B$ such that $f$ factors through $B$, i.e. $f=j\circ g$, where $j$ is the inclusion of $B$ in $Y$. Moreover, $g$ is unique with respect to this property. I can take $B:=f(X)$ and $g:=f$ (so that $g$ is the same of $f$ as a rule, but with different codomain) and it is easely checked that everything works. Moreover $g$ is unique, since $j\circ g=f=j\circ g'$ implies $g=g'$ by injectivity of $j$. There is something that does not convince at all, in the unicity part. I mean, $g$ is unique if I fix $B=f(X)$, but what about the unicity of $B$? Is there a $B'$, different from $B$, and a $g'$ from $X$ to $B'$ bijective, such that $j'\circ g'=f$ holds?",,"['functions', 'abstract-algebra']"
68,Power Series representation of $\frac{1+x}{(1-x)^2}$,Power Series representation of,\frac{1+x}{(1-x)^2},"Can anyone work out how to do this problem, because I'm getting an answer that close to the answer in the back of the book, but mine is off by a + 1. What I do is, I first find a representation for $1/1-x$ ( which is the integral of $1/(1-x)^2$ ) and then derive to get back to the representation for $1/(1-x)^2$. From here I think you should be able to multiply by $1+x$ and eventually get the answer. Any flaws in my logic?","Can anyone work out how to do this problem, because I'm getting an answer that close to the answer in the back of the book, but mine is off by a + 1. What I do is, I first find a representation for $1/1-x$ ( which is the integral of $1/(1-x)^2$ ) and then derive to get back to the representation for $1/(1-x)^2$. From here I think you should be able to multiply by $1+x$ and eventually get the answer. Any flaws in my logic?",,"['sequences-and-series', 'functions']"
69,"Showing that a function $G : [0,1) \times [0,1) \rightarrow [0,1)$ is not a surjection",Showing that a function  is not a surjection,"G : [0,1) \times [0,1) \rightarrow [0,1)","While proving $|\Bbb C|=|\Bbb R|$ in Just and Weese's Set Theory book, they construct a function $G : [0,1) \times [0,1) \rightarrow [0,1)$ where $\langle x,y\rangle \in [0,1) \times [0,1)$ such that $x = +.x_0x_1x_2...$ and $y=+.y_0y_1y_2...$ and $G(x,y) = +.x_0y_0x_1y_1x_2y_2...$ It is clear to me why this function is one-to-one, however he makes the comment that it does not map $[0,1) \times [0,1)$ onto $[0,1)$. But since each digit of $z\in G$ is free to be any number 0 through 9 without restriction, I am led to the conclusion that G is onto. My guess at a solution would be to create some function that alters $z$ in such a way that it cannot be written as $+.x_0y_0x_1y_1x_2y_2...$  however I cannot find such a function.","While proving $|\Bbb C|=|\Bbb R|$ in Just and Weese's Set Theory book, they construct a function $G : [0,1) \times [0,1) \rightarrow [0,1)$ where $\langle x,y\rangle \in [0,1) \times [0,1)$ such that $x = +.x_0x_1x_2...$ and $y=+.y_0y_1y_2...$ and $G(x,y) = +.x_0y_0x_1y_1x_2y_2...$ It is clear to me why this function is one-to-one, however he makes the comment that it does not map $[0,1) \times [0,1)$ onto $[0,1)$. But since each digit of $z\in G$ is free to be any number 0 through 9 without restriction, I am led to the conclusion that G is onto. My guess at a solution would be to create some function that alters $z$ in such a way that it cannot be written as $+.x_0y_0x_1y_1x_2y_2...$  however I cannot find such a function.",,"['elementary-set-theory', 'functions']"
70,Generalizing monotonicity to 2D,Generalizing monotonicity to 2D,,"Monotone functions of a single variable are well defined, they just keep increasing when the variable increases (or decreases). I wonder if this concept has a standard generalization to two dimensions. Obviously, if any function is observed by following an arbitrary path in the XY plane, it can go increasing or decreasing or both. On the other hand, simple functions like affine (a X + b Y + c) or a paraboloid in the first quadrant (f=X^2+Y2, X, Y > 0) are intuitively 2D monotonic. Is there a way to formalize 2D monotonicity ? Are there monotone surfaces ?","Monotone functions of a single variable are well defined, they just keep increasing when the variable increases (or decreases). I wonder if this concept has a standard generalization to two dimensions. Obviously, if any function is observed by following an arbitrary path in the XY plane, it can go increasing or decreasing or both. On the other hand, simple functions like affine (a X + b Y + c) or a paraboloid in the first quadrant (f=X^2+Y2, X, Y > 0) are intuitively 2D monotonic. Is there a way to formalize 2D monotonicity ? Are there monotone surfaces ?",,[]
71,Is my logic correct?,Is my logic correct?,,"The question says there is a function $f(x)$ which maps $R$ to $R$, and $f''(x)>0$ for all x. This means $f'(x)$ is always increasing. And it is given that $$g(x)=2f\left(\frac{x^2}{2}\right)+f\left(6-x^2\right)$$ We need to check the monotonicity of $g(x)$. I first calculate $$g'(x)=2x\left(f'\left(\frac{x^2}{2}\right)-f'\left(6-x^2\right)\right)=2x(Q)$$ Since both $Q$ and $x$ vary, we need to keep both in mind. Also, if $$f'(x_1)>f'(x_2)$$ $$x_1>x_2$$ Now comes the step I doubt. I suppose $$Q=f'\left(\frac{x^2}{2}\right)-f'\left(6-x^2\right)=\left(\frac{x^2}{2}-\left(6-x^2\right)\right)R$$ where $R$ is a positive quantity. Then I check where $\left(\frac{x^2}{2}-\left(6-x^2\right)\right)$ and $x$ are positive and negative, and arrive at an answer, which my book says is correct. My logic behind $Q$ and $R$ is that it is $(x_1-x_2)$ that matters which, if negative, makes $Q$ negative. Is this correct? Does any other ""not-going-over-the-head"" way apply?","The question says there is a function $f(x)$ which maps $R$ to $R$, and $f''(x)>0$ for all x. This means $f'(x)$ is always increasing. And it is given that $$g(x)=2f\left(\frac{x^2}{2}\right)+f\left(6-x^2\right)$$ We need to check the monotonicity of $g(x)$. I first calculate $$g'(x)=2x\left(f'\left(\frac{x^2}{2}\right)-f'\left(6-x^2\right)\right)=2x(Q)$$ Since both $Q$ and $x$ vary, we need to keep both in mind. Also, if $$f'(x_1)>f'(x_2)$$ $$x_1>x_2$$ Now comes the step I doubt. I suppose $$Q=f'\left(\frac{x^2}{2}\right)-f'\left(6-x^2\right)=\left(\frac{x^2}{2}-\left(6-x^2\right)\right)R$$ where $R$ is a positive quantity. Then I check where $\left(\frac{x^2}{2}-\left(6-x^2\right)\right)$ and $x$ are positive and negative, and arrive at an answer, which my book says is correct. My logic behind $Q$ and $R$ is that it is $(x_1-x_2)$ that matters which, if negative, makes $Q$ negative. Is this correct? Does any other ""not-going-over-the-head"" way apply?",,"['calculus', 'functions']"
72,Using Logical Operators in One Line,Using Logical Operators in One Line,,I am looking for a function that has this meaning: f(x)= if x>10 x+1 else x-1 or f(x)=x>10 : x+1 ? x-1 Similar to the ternary operator in computer programming. What syntax should I use to express this as a mathematical function?,I am looking for a function that has this meaning: f(x)= if x>10 x+1 else x-1 or f(x)=x>10 : x+1 ? x-1 Similar to the ternary operator in computer programming. What syntax should I use to express this as a mathematical function?,,"['functions', 'logic']"
73,"If $F$ and $G$ are one to one, then $G \circ F$ is one to one and  $(G \circ F)^\neg = F^\neg \circ G^\neg$","If  and  are one to one, then  is one to one and",F G G \circ F (G \circ F)^\neg = F^\neg \circ G^\neg,"THEOREM: if $F$ and $G$ are one to one then $G \circ F$ is also one to one and  $(G \circ F)^\neg$ = $F^\neg \circ G^\neg$ PROOF: if $F: A\rightarrow B$, $G: B \rightarrow C$ and $$\forall a, a' \in A \ \   F(a)=F(a') \Rightarrow a=a'$$ then F is one to one and if $$\forall b, b' \in B \ \   G(b)=G(b') \Rightarrow b=b'$$ then G is one to one by the definition of one to one. If $(G \circ F)(a)=(G \circ F)(a') \Rightarrow G(F(a))= G(F(a'))$ then $F(a)= F(a')$ since $G$ is one to one. If $F(a)=F(a')$  then $a=a'$ since $F$ is one to one Because $G \circ F$ is one to one it is also invertible so $(G \circ F)^\neg$ exist now  if we compute  $$\begin{align}((G\circ F)\circ (F^\neg\circ G^\neg))(a)&=\\ ((G\circ (F\circ F^\neg)\circ G^\neg))(a)&=\\ ((G\circ G^\neg))(a)&=a\end{align} $$ So, $(F^\neg\circ G^\neg)$ is the inverse of  $G \circ F$ therefore  $(G \circ F)^\neg=(F^\neg\circ G^\neg)$ QED I feel like the first part is ok but the 2nd part is all messed up ... what did I do wrong?","THEOREM: if $F$ and $G$ are one to one then $G \circ F$ is also one to one and  $(G \circ F)^\neg$ = $F^\neg \circ G^\neg$ PROOF: if $F: A\rightarrow B$, $G: B \rightarrow C$ and $$\forall a, a' \in A \ \   F(a)=F(a') \Rightarrow a=a'$$ then F is one to one and if $$\forall b, b' \in B \ \   G(b)=G(b') \Rightarrow b=b'$$ then G is one to one by the definition of one to one. If $(G \circ F)(a)=(G \circ F)(a') \Rightarrow G(F(a))= G(F(a'))$ then $F(a)= F(a')$ since $G$ is one to one. If $F(a)=F(a')$  then $a=a'$ since $F$ is one to one Because $G \circ F$ is one to one it is also invertible so $(G \circ F)^\neg$ exist now  if we compute  $$\begin{align}((G\circ F)\circ (F^\neg\circ G^\neg))(a)&=\\ ((G\circ (F\circ F^\neg)\circ G^\neg))(a)&=\\ ((G\circ G^\neg))(a)&=a\end{align} $$ So, $(F^\neg\circ G^\neg)$ is the inverse of  $G \circ F$ therefore  $(G \circ F)^\neg=(F^\neg\circ G^\neg)$ QED I feel like the first part is ok but the 2nd part is all messed up ... what did I do wrong?",,['functions']
74,"If $\operatorname{ran} F \subseteq \operatorname{dom} G$, then $\operatorname{dom}(G \circ F) = \operatorname{dom} F$.","If , then .",\operatorname{ran} F \subseteq \operatorname{dom} G \operatorname{dom}(G \circ F) = \operatorname{dom} F,THEOREM : If $ \text{ran } F  \subseteq \text{dom } G $    then $\text{dom }(G \circ F)= \text{dom }F$ PROOF : if $ F\subseteq  A \times B$ and  $ G\subseteq  B\times C$ then by definition $$\text{dom }F=A \\\text{ ran }F=B$$ $$\text{dom }G=B\\\text{ran }G=C$$ Now  $(G \circ F)\subseteq A \times C$  by definition so   $\text{dom}(G \circ F)= A =\text{dom}F$ $ QED $,THEOREM : If $ \text{ran } F  \subseteq \text{dom } G $    then $\text{dom }(G \circ F)= \text{dom }F$ PROOF : if $ F\subseteq  A \times B$ and  $ G\subseteq  B\times C$ then by definition $$\text{dom }F=A \\\text{ ran }F=B$$ $$\text{dom }G=B\\\text{ran }G=C$$ Now  $(G \circ F)\subseteq A \times C$  by definition so   $\text{dom}(G \circ F)= A =\text{dom}F$ $ QED $,,['functions']
75,Help solving this question on even and odd functions,Help solving this question on even and odd functions,,"a) Suppose that $E(x)$ is an even function and that $O(x)$ is an odd function. Suppose furthermore that $E(x) + O(x) = 0$. Show that for all $x$, $E(x) = 0$ and $O(x) = 0$. b) Use part a) to show that if $A\sin(ax)+B\cos(bx) = 0$ for all $x$, where $A,B,a,b$ are fixed real numbers, then $B = 0$ and one of either $A$ or $a$ is also equal to $0$.","a) Suppose that $E(x)$ is an even function and that $O(x)$ is an odd function. Suppose furthermore that $E(x) + O(x) = 0$. Show that for all $x$, $E(x) = 0$ and $O(x) = 0$. b) Use part a) to show that if $A\sin(ax)+B\cos(bx) = 0$ for all $x$, where $A,B,a,b$ are fixed real numbers, then $B = 0$ and one of either $A$ or $a$ is also equal to $0$.",,"['calculus', 'functions']"
76,Need a formula for a quadratic spline,Need a formula for a quadratic spline,,"I'm trying to reproduce some results from a paper and I need an explicit formula for a specific quadratic spline to do so. The problem is, I've only got a plot of it. The quadratic spline is from figure 2 (a) of Stephane Mallats paper ""Singularity Detection and Processing with Wavelets"" in IEEE Transactions on Information Theory, Vol. 38, No. 2.  March 1992. Link to journal . Link to PDF . The spline has a positive lobe lobe from $[-1,0]$ and a negative lobe from $[0,1].$  It appears to go to zero from $[-2,-1]$ and from $[1,2].$  It also acheives a peak values of about $0.66$ or $-0.66$ in either lobe as measured in imageJ.  This spline is bound to be a wavelet so it's necessarily $0$ on the average and is compactly supported from $[-2,2]$ (possibly a smaller interval if it goes to zero where I think it does.)","I'm trying to reproduce some results from a paper and I need an explicit formula for a specific quadratic spline to do so. The problem is, I've only got a plot of it. The quadratic spline is from figure 2 (a) of Stephane Mallats paper ""Singularity Detection and Processing with Wavelets"" in IEEE Transactions on Information Theory, Vol. 38, No. 2.  March 1992. Link to journal . Link to PDF . The spline has a positive lobe lobe from $[-1,0]$ and a negative lobe from $[0,1].$  It appears to go to zero from $[-2,-1]$ and from $[1,2].$  It also acheives a peak values of about $0.66$ or $-0.66$ in either lobe as measured in imageJ.  This spline is bound to be a wavelet so it's necessarily $0$ on the average and is compactly supported from $[-2,2]$ (possibly a smaller interval if it goes to zero where I think it does.)",,"['functions', 'signal-processing', 'interpolation', 'wavelets']"
77,Why does no one use the notation $f(x)^2$?,Why does no one use the notation ?,f(x)^2,"It seems to me that ""$f(x)^2$"" couldn't mean anything other than ""$[f(x)]^2$"", so there shouldn't be any ambiguity involved, but people always tend to put an extra pair of brackets around the ""$f(x)$"" everywhere I see it squared. Is there a reason for this?","It seems to me that ""$f(x)^2$"" couldn't mean anything other than ""$[f(x)]^2$"", so there shouldn't be any ambiguity involved, but people always tend to put an extra pair of brackets around the ""$f(x)$"" everywhere I see it squared. Is there a reason for this?",,"['functions', 'notation']"
78,Bound for the Legendre function of the second kind of degree $1/2$,Bound for the Legendre function of the second kind of degree,1/2,"Let $Q_{1/2}(u)$ be the Legendre function of the second kind of degree $1/2$. One can show that $Q_{1/2}(u) = O(u^{-3/2})$ as $u\to \infty$; see Equation 21 in Section 3.9.2 of Higher transcendental functions , the Bateman Manuscripta Project Volume 1 . I'm looking for a more precise statement. Namely, I would like to know if one can prove an upper bound for $Q_{1/2}(u)$ of the form $c u^{-3/2}$, where $c$ is an explicit real number. Where can I find this, or how can I derive this?","Let $Q_{1/2}(u)$ be the Legendre function of the second kind of degree $1/2$. One can show that $Q_{1/2}(u) = O(u^{-3/2})$ as $u\to \infty$; see Equation 21 in Section 3.9.2 of Higher transcendental functions , the Bateman Manuscripta Project Volume 1 . I'm looking for a more precise statement. Namely, I would like to know if one can prove an upper bound for $Q_{1/2}(u)$ of the form $c u^{-3/2}$, where $c$ is an explicit real number. Where can I find this, or how can I derive this?",,"['functions', 'inequality', 'special-functions', 'estimation']"
79,What is the Jacobian?,What is the Jacobian?,,"What is the Jacobian of the function $f(u+iv)={u+iv-a\over u+iv-b}$? I think the Jacobian should be something of the form  $\left(\begin{matrix}   {\partial f_1\over\partial u} & {\partial f_1\over\partial v}  \\   {\partial f_2\over\partial u} & {\partial f_2\over\partial v}  \end{matrix}\right)$ but I don't know what $f_1,f_2$ are in this case. Thank you.","What is the Jacobian of the function $f(u+iv)={u+iv-a\over u+iv-b}$? I think the Jacobian should be something of the form  $\left(\begin{matrix}   {\partial f_1\over\partial u} & {\partial f_1\over\partial v}  \\   {\partial f_2\over\partial u} & {\partial f_2\over\partial v}  \end{matrix}\right)$ but I don't know what $f_1,f_2$ are in this case. Thank you.",,"['linear-algebra', 'functions', 'complex-numbers']"
80,Nested radicals,Nested radicals,,Let $S$ be the set of functions $f:\mathbb{R}\to \mathbb{R}$ such that $\sqrt{f(1)+\sqrt{f(2)+\sqrt{f(3)+\dots}}}$ converges. A function $q(x)$ dominates $p(x)$ if there exist an m such that $q(x)\gt p(x)$ for all $x\gt m$. Take all functions $f(x)$ from $S$ and put $O(f(x))$ in $S2$. Which function $g(x)$ in $S2$ dominates all others? Are there asymptotic lower and upper bounds on $g(x)$?,Let $S$ be the set of functions $f:\mathbb{R}\to \mathbb{R}$ such that $\sqrt{f(1)+\sqrt{f(2)+\sqrt{f(3)+\dots}}}$ converges. A function $q(x)$ dominates $p(x)$ if there exist an m such that $q(x)\gt p(x)$ for all $x\gt m$. Take all functions $f(x)$ from $S$ and put $O(f(x))$ in $S2$. Which function $g(x)$ in $S2$ dominates all others? Are there asymptotic lower and upper bounds on $g(x)$?,,"['sequences-and-series', 'functions', 'convergence-divergence', 'nested-radicals']"
81,fully customizable periodic function?,fully customizable periodic function?,,"I am looking for a bell-shaped periodic function f(x) with parameters a and b,  with following characteristics: ( not sure if such function already exists or one can formulate one ) : oscillating between zero and a constant non-negative number A. Width of bell can be modified through parameter b. customizable period of  c. Preferably easy to calculate its integral Obviously such function should look like a spike with lower b numbers and conversely turn into square-like with larger b. I tried playing with Gaussian and normal distribution, it satisfies the first two requirements but fails to drop to zero at periodicals of x = c. something like the picture below any suggestions highly appreciated !","I am looking for a bell-shaped periodic function f(x) with parameters a and b,  with following characteristics: ( not sure if such function already exists or one can formulate one ) : oscillating between zero and a constant non-negative number A. Width of bell can be modified through parameter b. customizable period of  c. Preferably easy to calculate its integral Obviously such function should look like a spike with lower b numbers and conversely turn into square-like with larger b. I tried playing with Gaussian and normal distribution, it satisfies the first two requirements but fails to drop to zero at periodicals of x = c. something like the picture below any suggestions highly appreciated !",,"['functions', 'exponential-function', 'normal-distribution', 'periodic-functions']"
82,"Prove that there can't exist a bijection $f: A\rightarrow I_{n}$, if $A\subset I_{n}, \ I_{n}=\{ 1,2,...,n \}$","Prove that there can't exist a bijection , if","f: A\rightarrow I_{n} A\subset I_{n}, \ I_{n}=\{ 1,2,...,n \}","Prove that there can't exist a bijection $f: A\rightarrow I_{n}$ , if $A\subset I_{n}, \ I_{n}=\{ 1,2,...,n \}$ For me this is a quite simple concept to understand, but my class book stated a longer explanation than I think was necessary, so I want to know if what I thought is valid. It follows: Take a bijection $f: I_{n} \rightarrow I_{n}$ , if we remove any element $x$ from the domain, such that $f(x)=y$ , it would be impossible to still have a bijection by the pigeonhole principle, as we would have a $n$ elements set choosing $n-1$ elements from the domain. The same is applied if we remove $k<n$ elements, as $n$ elements set cannot choose $n-k$ elements without at least one element from $I_{n}$ be choosing at least twice an element from the domain, making $f$ not a well defined function.","Prove that there can't exist a bijection , if For me this is a quite simple concept to understand, but my class book stated a longer explanation than I think was necessary, so I want to know if what I thought is valid. It follows: Take a bijection , if we remove any element from the domain, such that , it would be impossible to still have a bijection by the pigeonhole principle, as we would have a elements set choosing elements from the domain. The same is applied if we remove elements, as elements set cannot choose elements without at least one element from be choosing at least twice an element from the domain, making not a well defined function.","f: A\rightarrow I_{n} A\subset I_{n}, \ I_{n}=\{ 1,2,...,n \} f: I_{n} \rightarrow I_{n} x f(x)=y n n-1 k<n n n-k I_{n} f","['real-analysis', 'functions', 'solution-verification']"
83,non-decreasing surjective map from reals to rationals [closed],non-decreasing surjective map from reals to rationals [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question I have a feeling that no such map exists, i.e., there is no non-decreasing surjective function from $\mathbb{R}$ to $\mathbb{Q}$ . But I am just unable to write an argument. Any hint or sketch of proof will be helpful.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question I have a feeling that no such map exists, i.e., there is no non-decreasing surjective function from to . But I am just unable to write an argument. Any hint or sketch of proof will be helpful.",\mathbb{R} \mathbb{Q},"['real-analysis', 'functions']"
84,Homogeneous of degree one functions that are a monotonic transformation of an additively separable function,Homogeneous of degree one functions that are a monotonic transformation of an additively separable function,,"Let $n>1$ , and let $f:\mathbb{R}^n_{\ge 0}\rightarrow\mathbb{R}_{\ge 0}$ be continuously differentiable, concave, and homogeneous of degree one. Here, homogeneity of degree one means that for all $s\in\mathbb{R}_{\ge 0}$ , and $x\in\mathbb{R}^n_{\ge 0}$ , $f(sx)=sf(x)$ . And suppose that there exist continuously differentiable monotonic increasing functions $g:\mathbb{R}\rightarrow\mathbb{R}_{\ge 0}$ and $h_1,\dots,h_n:\mathbb{R}_{\ge 0}\rightarrow\mathbb{R}$ such that for all $x\in\mathbb{R}^n_{\ge 0}$ : $$f(x)=g(h_1(x_1)+\cdots+h_n(x_n)).$$ Must it be the case that there exists $a_1,\dots,a_n\in\mathbb{R}$ and $\rho,b_1,\dots,b_n\in\mathbb{R}_{\ge 0}$ such that for all $i\in\{1,\dots,n\}$ , $h_i(x)=a_i+b_i \frac{x^{1-\rho}-1}{1-\rho}$ ? (Where, when $\rho=1$ , we understand this as stating $h_i(x)=a_i+b_i\log(x)$ .) Note that by Euler's homogeneous function theorem: $$g(h_1(x_1)+\cdots+h_n(x_n))=(h_1'(x_1)x_1+\cdots+h_n'(x_n)x_n)g'(h_1(x_1)+\cdots+h_n(x_n)).$$ Does this (differential equation) help?","Let , and let be continuously differentiable, concave, and homogeneous of degree one. Here, homogeneity of degree one means that for all , and , . And suppose that there exist continuously differentiable monotonic increasing functions and such that for all : Must it be the case that there exists and such that for all , ? (Where, when , we understand this as stating .) Note that by Euler's homogeneous function theorem: Does this (differential equation) help?","n>1 f:\mathbb{R}^n_{\ge 0}\rightarrow\mathbb{R}_{\ge 0} s\in\mathbb{R}_{\ge 0} x\in\mathbb{R}^n_{\ge 0} f(sx)=sf(x) g:\mathbb{R}\rightarrow\mathbb{R}_{\ge 0} h_1,\dots,h_n:\mathbb{R}_{\ge 0}\rightarrow\mathbb{R} x\in\mathbb{R}^n_{\ge 0} f(x)=g(h_1(x_1)+\cdots+h_n(x_n)). a_1,\dots,a_n\in\mathbb{R} \rho,b_1,\dots,b_n\in\mathbb{R}_{\ge 0} i\in\{1,\dots,n\} h_i(x)=a_i+b_i \frac{x^{1-\rho}-1}{1-\rho} \rho=1 h_i(x)=a_i+b_i\log(x) g(h_1(x_1)+\cdots+h_n(x_n))=(h_1'(x_1)x_1+\cdots+h_n'(x_n)x_n)g'(h_1(x_1)+\cdots+h_n(x_n)).","['functions', 'partial-differential-equations', 'convex-analysis', 'economics', 'homothety']"
85,The maximum number of intersections for a type of exponential function,The maximum number of intersections for a type of exponential function,,"Given two real valued functions $f(x)$ and $g(x)$ which both satisfy the conditions that they are sums of exactly $k$ positive terms each, each term of the form $b_i^x$ where $b_i \in \mathbb{N}$ $(i\in \{1,...,k\})$ , can we come up with the maximum number $m$ of points in which $f(x)$ and $g(x)$ intersect (in general)? Consider $x\in R$ , $x\geq 0$ or even $x\in \mathbb{N}_{0}$ if it makes the question simpler. Examples: $f(x)=2^x+42^x, g(x)=3^x+4^x$ or $f(x)=30^x+20^x+10^x, g(x)=1^x+2^x+3^x$ . In both examples $f$ and $g$ at least intersect at $x=0$ since $f$ and $g$ both have $k$ terms. My guess was, at first, that it's exactly one point (being $x=0$ ), but I am not so sure anymore and now consider the answers $m=2$ or some $m(k)\in O(k)$ . Is it important to know that the terms are convex to solve this problem? Edit 2: Since this is very interesting problem to me and I think it fits, can one also find out for what $c$ there cannot be any new intersection for all $x>c$ ? Edit: After trying to come up with examples on wolfram alpha that have more than 1 intersection I quickly found multiple examples, but I decided to stop after a while without being able to come up with an example where there are 3 or more intersections.","Given two real valued functions and which both satisfy the conditions that they are sums of exactly positive terms each, each term of the form where , can we come up with the maximum number of points in which and intersect (in general)? Consider , or even if it makes the question simpler. Examples: or . In both examples and at least intersect at since and both have terms. My guess was, at first, that it's exactly one point (being ), but I am not so sure anymore and now consider the answers or some . Is it important to know that the terms are convex to solve this problem? Edit 2: Since this is very interesting problem to me and I think it fits, can one also find out for what there cannot be any new intersection for all ? Edit: After trying to come up with examples on wolfram alpha that have more than 1 intersection I quickly found multiple examples, but I decided to stop after a while without being able to come up with an example where there are 3 or more intersections.","f(x) g(x) k b_i^x b_i \in \mathbb{N} (i\in \{1,...,k\}) m f(x) g(x) x\in R x\geq 0 x\in \mathbb{N}_{0} f(x)=2^x+42^x, g(x)=3^x+4^x f(x)=30^x+20^x+10^x, g(x)=1^x+2^x+3^x f g x=0 f g k x=0 m=2 m(k)\in O(k) c x>c",['functions']
86,What is what in a mathematical function notation,What is what in a mathematical function notation,,"I've started learning math from zero. As we know a function consists of three integral parts: input, relationship and output. When we write something like $f(x) = x + 1$ , we can clearly see and understand what is what in this notation: f is a name of function, x is its argument and so on. Misunderstandings begin when other letters are used instead of the letter f or when it's combined with other letters, like: $y(x) = x^2$ $y = f(x)$ So here I cannot understand and identify the positions of those three parts of a function. And now the questions: Is the letter f or any other letter that comes before the brackets a variable or just a function name? For example, when we write $y = f(x)$ is this "" $f$ "" a variable into which the result of the function is substituted (i.e. its output), and then assigned to the variable $y$ ? If not, what about $y(x) = x^2$ ? Is y here just the function name too? In short, by what rule can I quickly determine in a function what is an input, an output, and a relationship? Because at first glance, it seems to me that there is no single way to represent a function as a formula For example, in each programming language there is a single template by which a function is defined - you must specify in a certain sequence the return type, parameters, and then a processing algorithm","I've started learning math from zero. As we know a function consists of three integral parts: input, relationship and output. When we write something like , we can clearly see and understand what is what in this notation: f is a name of function, x is its argument and so on. Misunderstandings begin when other letters are used instead of the letter f or when it's combined with other letters, like: So here I cannot understand and identify the positions of those three parts of a function. And now the questions: Is the letter f or any other letter that comes before the brackets a variable or just a function name? For example, when we write is this "" "" a variable into which the result of the function is substituted (i.e. its output), and then assigned to the variable ? If not, what about ? Is y here just the function name too? In short, by what rule can I quickly determine in a function what is an input, an output, and a relationship? Because at first glance, it seems to me that there is no single way to represent a function as a formula For example, in each programming language there is a single template by which a function is defined - you must specify in a certain sequence the return type, parameters, and then a processing algorithm",f(x) = x + 1 y(x) = x^2 y = f(x) y = f(x) f y y(x) = x^2,"['functions', 'notation']"
87,"How to write proof for there is no injective function from $[0, 1]$ to $\mathbb{N}$?",How to write proof for there is no injective function from  to ?,"[0, 1] \mathbb{N}","I am given the following problem: Let $f$ be a function from $[0, 1]$ to $\mathbb{N}$ . Prove there exists $x, y\in [0, 1]$ such that $x\neq y$ and $f(x) = f(y)$ . Clearly, this is true because $|[0, 1]| = |\mathbb{R}| > |\mathbb{N}|$ , and there cannot be an injective function from an uncountable set to a countable set. But... how should I write my solution? They are asking for a proof and I do not know how to formally prove the statement above. Thank you!","I am given the following problem: Let be a function from to . Prove there exists such that and . Clearly, this is true because , and there cannot be an injective function from an uncountable set to a countable set. But... how should I write my solution? They are asking for a proof and I do not know how to formally prove the statement above. Thank you!","f [0, 1] \mathbb{N} x, y\in [0, 1] x\neq y f(x) = f(y) |[0, 1]| = |\mathbb{R}| > |\mathbb{N}|","['functions', 'elementary-set-theory', 'cardinals']"
88,Domain of composite function $\left( f \circ g \right)\left( x \right).$,Domain of composite function,\left( f \circ g \right)\left( x \right).,"Question: Given that $f\left( x \right) = \sqrt{x - 3}$ and $g\left( x \right) = x + 1$ , find the domain of $\left( f \circ g \right)\left( x \right)$ . My attempt: $\left( f \circ g \right)\left( x \right) = \sqrt{x - 2}$ , hence the domain of $\left( f \circ g \right)\left( x \right)$ is $\{x\mid x \geq 2\}$ . However, I also aware that a composite function can only exist over a domain where both component functions exist. This implies that the domain of $\left( f \circ g \right)\left( x \right)$ is $\{x\mid x \geq 3\}$ . Could someone please explain the second solution to me because it is perplexing.","Question: Given that and , find the domain of . My attempt: , hence the domain of is . However, I also aware that a composite function can only exist over a domain where both component functions exist. This implies that the domain of is . Could someone please explain the second solution to me because it is perplexing.",f\left( x \right) = \sqrt{x - 3} g\left( x \right) = x + 1 \left( f \circ g \right)\left( x \right) \left( f \circ g \right)\left( x \right) = \sqrt{x - 2} \left( f \circ g \right)\left( x \right) \{x\mid x \geq 2\} \left( f \circ g \right)\left( x \right) \{x\mid x \geq 3\},"['functions', 'elementary-functions']"
89,"Finding all the surjective functions $ f: \mathbb{R} \to \mathbb{R}$ which satisfy $f(x+f(x)+xy)=2f(x)+xf(y) \ \forall x, y \in \mathbb{R}$",Finding all the surjective functions  which satisfy," f: \mathbb{R} \to \mathbb{R} f(x+f(x)+xy)=2f(x)+xf(y) \ \forall x, y \in \mathbb{R}","Find the function(s) $ f: \mathbb{R} \to \mathbb{R}$ which satisfies these two conditions: $f(x+f(x)+xy)=2f(x)+xf(y) \ \forall x, y \in \mathbb{R}$ function $f$ is surjective ( $\forall z \in \mathbb R, \ \exists x \in \mathbb R, \ f(x)=z$ ). My attempt: \begin{align} &\text{let }P(x, y): \ f(x+f(x)+xy)=2f(x)+xf(y) \\ &P(0, y): \ f(f(0))=2f(0). \\ &P(x, 0): \ f(x+f(x))=2f(x)+xf(0). \\ \ \\ &\text{let } f(a)=f(b). \ \\ &P(a, -1): f(f(a))=2f(a)+af(-1). \\ &P(b, -1): f(f(b))=2f(b)+bf(-1). \\ & \Rightarrow a=b \text{ if } f(-1) \neq 0. \\ \ \\ &\text{Edit: }\\ & \text{if } f(-1)=0: \\ &P(x, -1): \ f(f(x))=2f(x). \\ & \text{Since the function } f \text{ is surjective, } f(x)=2x \text{ for } \forall x \in \mathbb{R}. \\ & x=-1; \ f(-1)=-2, \text{ which is contradiction.} \\ \ \\ &\therefore f(a)=f(b) \Rightarrow a=b. \end{align} Well, I expect this function to be $f(x)=x. $ Can you show the full process of finding the function(s)?","Find the function(s) which satisfies these two conditions: function is surjective ( ). My attempt: Well, I expect this function to be Can you show the full process of finding the function(s)?"," f: \mathbb{R} \to \mathbb{R} f(x+f(x)+xy)=2f(x)+xf(y) \ \forall x, y \in \mathbb{R} f \forall z \in \mathbb R, \ \exists x \in \mathbb R, \ f(x)=z \begin{align}
&\text{let }P(x, y): \ f(x+f(x)+xy)=2f(x)+xf(y) \\
&P(0, y): \ f(f(0))=2f(0). \\
&P(x, 0): \ f(x+f(x))=2f(x)+xf(0). \\
\ \\
&\text{let } f(a)=f(b). \ \\
&P(a, -1): f(f(a))=2f(a)+af(-1). \\
&P(b, -1): f(f(b))=2f(b)+bf(-1). \\
& \Rightarrow a=b \text{ if } f(-1) \neq 0. \\
\ \\
&\text{Edit: }\\
& \text{if } f(-1)=0: \\
&P(x, -1): \ f(f(x))=2f(x). \\
& \text{Since the function } f \text{ is surjective, } f(x)=2x \text{ for } \forall x \in \mathbb{R}. \\
& x=-1; \ f(-1)=-2, \text{ which is contradiction.} \\
\ \\
&\therefore f(a)=f(b) \Rightarrow a=b.
\end{align} f(x)=x. ","['functions', 'functional-equations']"
90,Continuous function satisfying $f\left( {2{x^2} - 1} \right) = \left( {{x^3} + x} \right)f\left( x \right)$,Continuous function satisfying,f\left( {2{x^2} - 1} \right) = \left( {{x^3} + x} \right)f\left( x \right),"If $f\colon\left[ { - 1,1} \right] \to \mathbb R$ be continuous function satisfying $f\left( {2{x^2} - 1} \right) = \left( {{x^3} + x} \right)f\left( x \right)$ , then $\mathop {\lim }\limits_{x \to 0} \frac{{f\left( {\cos x} \right)}}{{\sin x}}$ is _______. My solution is as follow $x = \cos \left( {\frac{\theta }{2}} \right)$ $f\left( {2{{\cos }^2}\left( {\frac{\theta }{2}} \right) - 1} \right) = \left( {{{\cos }^3}\left( {\frac{\theta }{2}} \right) + \cos \left( {\frac{\theta }{2}} \right)} \right)f\left( {\cos \left( {\frac{\theta }{2}} \right)} \right)$ $\frac{{f\left( {\cos \theta } \right)}}{{\sin \theta }} = \frac{{\left( {{{\cos }^3}\left( {\frac{\theta }{2}} \right) + \cos \left( {\frac{\theta }{2}} \right)} \right)}}{{2\sin \left( {\frac{\theta }{2}} \right)\cos \left( {\frac{\theta }{2}} \right)}}f\left( {\cos \left( {\frac{\theta }{2}} \right)} \right)$ $\frac{{f\left( {\cos \theta } \right)}}{{\sin \theta }} = \frac{{\left( {{{\cos }^2}\left( {\frac{\theta }{2}} \right) + 1} \right)}}{{2\sin \left( {\frac{\theta }{2}} \right)}}f\left( {\cos \left( {\frac{\theta }{2}} \right)} \right)$ How do I proceed from here","If be continuous function satisfying , then is _______. My solution is as follow How do I proceed from here","f\colon\left[ { - 1,1} \right] \to \mathbb R f\left( {2{x^2} - 1} \right) = \left( {{x^3} + x} \right)f\left( x \right) \mathop {\lim }\limits_{x \to 0} \frac{{f\left( {\cos x} \right)}}{{\sin x}} x = \cos \left( {\frac{\theta }{2}} \right) f\left( {2{{\cos }^2}\left( {\frac{\theta }{2}} \right) - 1} \right) = \left( {{{\cos }^3}\left( {\frac{\theta }{2}} \right) + \cos \left( {\frac{\theta }{2}} \right)} \right)f\left( {\cos \left( {\frac{\theta }{2}} \right)} \right) \frac{{f\left( {\cos \theta } \right)}}{{\sin \theta }} = \frac{{\left( {{{\cos }^3}\left( {\frac{\theta }{2}} \right) + \cos \left( {\frac{\theta }{2}} \right)} \right)}}{{2\sin \left( {\frac{\theta }{2}} \right)\cos \left( {\frac{\theta }{2}} \right)}}f\left( {\cos \left( {\frac{\theta }{2}} \right)} \right) \frac{{f\left( {\cos \theta } \right)}}{{\sin \theta }} = \frac{{\left( {{{\cos }^2}\left( {\frac{\theta }{2}} \right) + 1} \right)}}{{2\sin \left( {\frac{\theta }{2}} \right)}}f\left( {\cos \left( {\frac{\theta }{2}} \right)} \right)",['functions']
91,"""Determine all functions $\Bbb{Z}\to\Bbb{Z}$ such that $f(2a)+2f(b)=f(f(a+b))$""","""Determine all functions  such that """,\Bbb{Z}\to\Bbb{Z} f(2a)+2f(b)=f(f(a+b)),"I came across this problem: Let $\Bbb{Z}$ be the set of integers. Determine all functions $f$ : $\Bbb{Z}\to\Bbb{Z}$ , such that for all integers $a$ , $b \in \Bbb{Z}$ $f(2a)+2f(b)=f(f(a+b))$ . The unsatisfying solution that was presented was to substitute $a=0$ and $a=1$ , and notice that $f$ is an arithmetic progression, and find both coefficients. A satisfying solution, in my view, should go along these lines: What special property of $\Bbb{Z}\to\Bbb{Z}$ functions allows us to resolve equations involving such functions, and their convolutions? For that I come for your help.","I came across this problem: Let be the set of integers. Determine all functions : , such that for all integers , . The unsatisfying solution that was presented was to substitute and , and notice that is an arithmetic progression, and find both coefficients. A satisfying solution, in my view, should go along these lines: What special property of functions allows us to resolve equations involving such functions, and their convolutions? For that I come for your help.",\Bbb{Z} f \Bbb{Z}\to\Bbb{Z} a b \in \Bbb{Z} f(2a)+2f(b)=f(f(a+b)) a=0 a=1 f \Bbb{Z}\to\Bbb{Z},"['functions', 'integers']"
92,Do you pick a delta or do you pick an epsilon beginner confusion,Do you pick a delta or do you pick an epsilon beginner confusion,,"Let $f : \mathbb R \to\mathbb R$ be a continuous function such that $\lim_{x\to0} f(x) = 2.$ Prove that there exists a $δ > 0$ such that, on the interval $(−δ, δ)$ , the function f is bounded. Hello I am a beginner in college mathematics, here is my attempt. I know that for every $ε>0$ , there exist a $δ>0$ such that $|x-a| < δ$ implies that $|f(x) - L| < ε$ $|x| < δ$ = $- δ < x < δ$ $|f(x) - 2| < ε$ Then use the 2nd triangle inequality?? (Sorry I am just trying to create something) $|f(x)| - |2| < ε$ = $|f(x)| < ε$ +  |2| = $-ε- 2<f(x) < ε$ + 2 So here what do I do ? Do I pick a ε? So let $ε = 1$ and now the function f is bounded? Do I pick the delta or epsilon first? Thanks -Alice","Let be a continuous function such that Prove that there exists a such that, on the interval , the function f is bounded. Hello I am a beginner in college mathematics, here is my attempt. I know that for every , there exist a such that implies that = Then use the 2nd triangle inequality?? (Sorry I am just trying to create something) = +  |2| = + 2 So here what do I do ? Do I pick a ε? So let and now the function f is bounded? Do I pick the delta or epsilon first? Thanks -Alice","f : \mathbb R \to\mathbb R \lim_{x\to0} f(x) = 2. δ > 0 (−δ, δ) ε>0 δ>0 |x-a| < δ |f(x) - L| < ε |x| < δ - δ < x < δ |f(x) - 2| < ε |f(x)| - |2| < ε |f(x)| < ε -ε- 2<f(x) < ε ε = 1","['functions', 'solution-verification']"
93,Bijection $\mathbb N \to \mathbb Z$ using floor function. Define bijection $\mathbb Z \to \mathbb Q$,Bijection  using floor function. Define bijection,\mathbb N \to \mathbb Z \mathbb Z \to \mathbb Q,"After defining the bijection $$  F: \mathbb{N}\to \mathbb{Z}$$ using floor function, and by defining bijections: $$\mathbb{N} \to \mathbb{N} \setminus \{ 0 \}\\ \mathbb{Q} \to \mathbb{Q} \setminus \{ 0 \}  $$ define bijection: $$\mathbb{Z} \to \mathbb{Q} \setminus \{ 0 \}$$ . After a few attempts I got first one $F: \Bbb N \to \Bbb Z$ , $F(x) = (-1)^x \lfloor(x/2)\rfloor$ but I'm stuck with other ones. I'm new into that course at university - if I made some mistakes - I'm sorry.","After defining the bijection using floor function, and by defining bijections: define bijection: . After a few attempts I got first one , but I'm stuck with other ones. I'm new into that course at university - if I made some mistakes - I'm sorry."," 
F: \mathbb{N}\to \mathbb{Z} \mathbb{N} \to \mathbb{N} \setminus \{ 0 \}\\
\mathbb{Q} \to \mathbb{Q} \setminus \{ 0 \} 
 \mathbb{Z} \to \mathbb{Q} \setminus \{ 0 \} F: \Bbb N \to \Bbb Z F(x) = (-1)^x \lfloor(x/2)\rfloor","['functions', 'elementary-set-theory']"
94,Asymptotic formula for roots of a polynomial-like function,Asymptotic formula for roots of a polynomial-like function,,"Let $\sigma \in (0, 1)$ and $n \geq1$ be given. How can one rigorously show that the positive root $x_0 \in (0, n)$ of \begin{equation} f(x) = (n^2-x^2-\sigma n^2 x)-(n^2-x^2+\sigma n^2x)e^{-4x} \end{equation} is of the form \begin{equation} x_0 = x^*-\varepsilon_n \end{equation} for some $\varepsilon_n$ such that $\varepsilon_n \rightarrow 0$ as $n\to+\infty$ , and where $$x^* := \frac12(n\sqrt{n^2\sigma^2+4}-n^2\sigma)$$ is the positive root of $f_1(x) = (n^2-x^2-\sigma n^2x)$ ? This question is related and complementary to Roots of polynomial/exponential function .","Let and be given. How can one rigorously show that the positive root of is of the form for some such that as , and where is the positive root of ? This question is related and complementary to Roots of polynomial/exponential function .","\sigma \in (0, 1) n \geq1 x_0 \in (0, n) \begin{equation}
f(x) = (n^2-x^2-\sigma n^2 x)-(n^2-x^2+\sigma n^2x)e^{-4x}
\end{equation} \begin{equation}
x_0 = x^*-\varepsilon_n
\end{equation} \varepsilon_n \varepsilon_n \rightarrow 0 n\to+\infty x^* := \frac12(n\sqrt{n^2\sigma^2+4}-n^2\sigma) f_1(x) = (n^2-x^2-\sigma n^2x)","['real-analysis', 'calculus', 'functions', 'polynomials']"
95,Can information-theory quantify deviations from bijectivity?,Can information-theory quantify deviations from bijectivity?,,"There are basic ways to qualitatively classify deviations from bijectivity of a function $f: x \to y$ , e.g. non-injective, non-surjective, non-existence of an inverse: more generally non-monomorphic, non-epimorphic. Are there two ""natural"" quantitative measures of  deviation from injectivity and surjectivity? Is there one natural quantitative measure of ""total deviation"" from bijectivity (combining both injective/surjectivity violation)? And from isomorphic? Brain storm: Relative entropy of $\{f^{-1}(y) \}$ , i.e. the preimages of $f$ , seems one relevant to measuring relative injectivity? Relative measure or cardinality $|Im(f)/Cod(f)|$ seems one way to measure surjectivity? These both invoke additional concepts, e.g. probability or measure. I am sure mathematicians will have clearer and better ways that I can't think of. Any ideas or references will be most welcome. The above mostly relates to functions between sets. How does one ask and answer the corresponding questions for structure-preserving functions, i.e. functorial functions, such as monotone, equivariant, homomorphic, continuous? (Apologies if this latter is asking too much in one question!). Thanks!","There are basic ways to qualitatively classify deviations from bijectivity of a function , e.g. non-injective, non-surjective, non-existence of an inverse: more generally non-monomorphic, non-epimorphic. Are there two ""natural"" quantitative measures of  deviation from injectivity and surjectivity? Is there one natural quantitative measure of ""total deviation"" from bijectivity (combining both injective/surjectivity violation)? And from isomorphic? Brain storm: Relative entropy of , i.e. the preimages of , seems one relevant to measuring relative injectivity? Relative measure or cardinality seems one way to measure surjectivity? These both invoke additional concepts, e.g. probability or measure. I am sure mathematicians will have clearer and better ways that I can't think of. Any ideas or references will be most welcome. The above mostly relates to functions between sets. How does one ask and answer the corresponding questions for structure-preserving functions, i.e. functorial functions, such as monotone, equivariant, homomorphic, continuous? (Apologies if this latter is asking too much in one question!). Thanks!",f: x \to y \{f^{-1}(y) \} f |Im(f)/Cod(f)|,"['functions', 'elementary-set-theory', 'information-theory', 'entropy']"
96,How to prove that these functions do not intersect?,How to prove that these functions do not intersect?,,"I want to prove that these two functions $f(x)$ and $g(x)$ do not intersect for $x>1$ : $$f(x)=\cosh \left(\frac{2 \sqrt{2} \pi  x \left(x^2-1\right) \cosh (\pi  x)}{\sqrt{x^4+6 x^2+\left(x^2-1\right)^2 \cosh (2 \pi  x)+1}}\right)$$ $$g(x)=\frac{4 x^2+\left(x^2-1\right)^2 \cosh (2 \pi  x)}{\left(x^2+1\right)^2}$$ Both functions are greater than one and strictly increasing. Subtraction and taking derivative do not work, the problem becomes more complicated. Does anyone have an idea to prove it by assuming false assumption? Or to prove that $f(x)-g(x)$ has no real root? Any hints or suggestions are really appreciated.","I want to prove that these two functions and do not intersect for : Both functions are greater than one and strictly increasing. Subtraction and taking derivative do not work, the problem becomes more complicated. Does anyone have an idea to prove it by assuming false assumption? Or to prove that has no real root? Any hints or suggestions are really appreciated.",f(x) g(x) x>1 f(x)=\cosh \left(\frac{2 \sqrt{2} \pi  x \left(x^2-1\right) \cosh (\pi  x)}{\sqrt{x^4+6 x^2+\left(x^2-1\right)^2 \cosh (2 \pi  x)+1}}\right) g(x)=\frac{4 x^2+\left(x^2-1\right)^2 \cosh (2 \pi  x)}{\left(x^2+1\right)^2} f(x)-g(x),"['functions', 'roots']"
97,"Are there ""simple"" functions whose asymptotic behaviour is impossible to know?","Are there ""simple"" functions whose asymptotic behaviour is impossible to know?",,"My question is Does exist a simple function $f \colon A \subseteq \mathbb R \to \mathbb R$ such that it is impossible to know $\lim_{x \to \infty} f(x)$ ? Of course there are a lot of function whose behaviour is not known; but what happens if we use only elementary functions (the rigourous definition of elementary function involves differential algebra, so let's just imagine a elementary function as a composition of exponentials, logarithms, rational functions and trigonometric functions)?. More clearly the problem is: Is it possible to create some function (or sequence) ""easy to define"" for which is not possible to evaluate his asymptotic behaviour? Edit : with ""not possible to evaluate"" I mean that the problem to evaluate $$\lim_{x \to +\infty} f(x)$$ is not decidible.","My question is Does exist a simple function such that it is impossible to know ? Of course there are a lot of function whose behaviour is not known; but what happens if we use only elementary functions (the rigourous definition of elementary function involves differential algebra, so let's just imagine a elementary function as a composition of exponentials, logarithms, rational functions and trigonometric functions)?. More clearly the problem is: Is it possible to create some function (or sequence) ""easy to define"" for which is not possible to evaluate his asymptotic behaviour? Edit : with ""not possible to evaluate"" I mean that the problem to evaluate is not decidible.",f \colon A \subseteq \mathbb R \to \mathbb R \lim_{x \to \infty} f(x) \lim_{x \to +\infty} f(x),"['real-analysis', 'functions', 'decidability']"
98,Find the general solution to $\csc \theta + \sec \theta = 1$,Find the general solution to,\csc \theta + \sec \theta = 1,"Find the general solution to $$\csc\theta + \sec\theta =1$$ This is how I solved. We have, \begin{align} \csc\theta + \sec\theta &=1\\ \frac1{\sin\theta} + \frac1{\cos\theta}& =1\\ \frac{\sin\theta+\cos\theta}{\sin\theta\cos\theta} &=1\\ (\sin\theta + \cos\theta)^2 &= (\sin\theta\cos\theta)^2 \\ 1 + 2\sin\theta\cos\theta &= \frac{4\sin^2\theta\cos^2\theta}4\\ 1 + \sin2\theta &= \frac{(2\sin\theta\cos\theta)^2 }4\\ 4 + 4\sin2\theta &= \sin^2 2\theta\\ \sin^2 2\theta - 4\sin2\theta - 4 &= 0\\ \sin2\theta &= 2 - 2\sqrt2\end{align} Now here I am stuck. Can someone please help me proceed further?","Find the general solution to This is how I solved. We have, Now here I am stuck. Can someone please help me proceed further?","\csc\theta + \sec\theta =1 \begin{align}
\csc\theta + \sec\theta &=1\\
\frac1{\sin\theta} + \frac1{\cos\theta}& =1\\
\frac{\sin\theta+\cos\theta}{\sin\theta\cos\theta} &=1\\
(\sin\theta + \cos\theta)^2 &= (\sin\theta\cos\theta)^2 \\
1 + 2\sin\theta\cos\theta &= \frac{4\sin^2\theta\cos^2\theta}4\\
1 + \sin2\theta &= \frac{(2\sin\theta\cos\theta)^2 }4\\
4 + 4\sin2\theta &= \sin^2 2\theta\\
\sin^2 2\theta - 4\sin2\theta - 4 &= 0\\
\sin2\theta &= 2 - 2\sqrt2\end{align}",['functions']
99,What does it mean for a function $f: \mathbb R^n \to\mathbb R^m$ to be continuously differentiable?,What does it mean for a function  to be continuously differentiable?,f: \mathbb R^n \to\mathbb R^m,"The inverse function theorem in higher dimensions states that $f: \mathbb R^n \to \mathbb R^m$ has to be continuously differentiable, but I don't understand what that's supposed to mean.","The inverse function theorem in higher dimensions states that has to be continuously differentiable, but I don't understand what that's supposed to mean.",f: \mathbb R^n \to \mathbb R^m,"['real-analysis', 'functions']"
