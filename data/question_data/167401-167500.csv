,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Can a finite data set have all its values within $n$ standard deviations from the mean?,Can a finite data set have all its values within  standard deviations from the mean?,n,"Aside from the trivial $(x,x,x,x,...)$ data set, is it possible to have all the elements of a data set within some $n$ standard deviations from the mean? What is the minimum possible value for $n$ such that there exists a set with this property? I'm also wondering if $n$ has any significance on the interpretation of the data itself. Are these distributions special in some way (other than simply ""the numbers are all close together"")? Sorry if the answer is trivial, and thank you in advance! EDIT: I just realized that in a finite data set, of course there exists some $n$ so that every data point is within $n$ standard deviations from the mean (because there are only finitely many Z-scores...) The main question is the actual lower bound for this value of $n$ and its interpretation.","Aside from the trivial $(x,x,x,x,...)$ data set, is it possible to have all the elements of a data set within some $n$ standard deviations from the mean? What is the minimum possible value for $n$ such that there exists a set with this property? I'm also wondering if $n$ has any significance on the interpretation of the data itself. Are these distributions special in some way (other than simply ""the numbers are all close together"")? Sorry if the answer is trivial, and thank you in advance! EDIT: I just realized that in a finite data set, of course there exists some $n$ so that every data point is within $n$ standard deviations from the mean (because there are only finitely many Z-scores...) The main question is the actual lower bound for this value of $n$ and its interpretation.",,['statistics']
1,Re-writing exponent of Multivariate Gaussian,Re-writing exponent of Multivariate Gaussian,,"In Bishop's Pattern Recognition and Machine Learning (ISBN-13: 978-0387-31073-2), Bishop writes on page 86: This is an example of a rather common operation associated with Gaussian   distributions, sometimes called ‘completing the square’, in which we are given a   quadratic form defining the exponent terms in a Gaussian distribution, and we need   to determine the corresponding mean and covariance. Such problems can be solved   straightforwardly by noting that the exponent in a general Gaussian distribution   $N(x|\mu,\Sigma)$ can be written:   $$ -\dfrac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu) = -\dfrac{1}{2}x^T \Sigma^{-1} x + x^T \Sigma^{-1} \mu + \text{const}$$ Where $\mu$ is the mean of a multivariate Gaussian and $\Sigma$ is the covariance matrix. How was the above equation derived?  Is there a name for this technique (Looking up completing the square doesn't yield anything)?","In Bishop's Pattern Recognition and Machine Learning (ISBN-13: 978-0387-31073-2), Bishop writes on page 86: This is an example of a rather common operation associated with Gaussian   distributions, sometimes called ‘completing the square’, in which we are given a   quadratic form defining the exponent terms in a Gaussian distribution, and we need   to determine the corresponding mean and covariance. Such problems can be solved   straightforwardly by noting that the exponent in a general Gaussian distribution   $N(x|\mu,\Sigma)$ can be written:   $$ -\dfrac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu) = -\dfrac{1}{2}x^T \Sigma^{-1} x + x^T \Sigma^{-1} \mu + \text{const}$$ Where $\mu$ is the mean of a multivariate Gaussian and $\Sigma$ is the covariance matrix. How was the above equation derived?  Is there a name for this technique (Looking up completing the square doesn't yield anything)?",,"['linear-algebra', 'probability', 'statistics', 'probability-distributions']"
2,Reasoning for confidence interval,Reasoning for confidence interval,,"Suppose  $$X_1,\dots,X_{20} \sim f_X(x;\beta)$$ where $$f_X(x;\beta) = \frac{1}{\beta} e^{-\frac{x}{\beta}},\quad x>0;\beta>0$$ It can shown that (""details omitted"") $$P(0.52 \bar{X} \leq \beta \leq 1.67 \bar{X}) = 0.99, \quad \forall\beta>0 \tag{1}$$ Thus the 99% confidence interval for  $\beta$ is $$(0.52 \bar{X} , 1.67 \bar{X})$$ My question is how $(1)$ come about? My attempt to reason By definition, $$P(\text{confidence interval for } \beta) = 0.99$$ There exists test statistics $A = A(X_1,\dots,X_{20})$ and $B = B(X_1,\dots,X_{20})$  such that $$P(A \leq \beta \leq B) = 0.99$$ I have found that the MLE of $\beta$ is $\hat \beta = \bar{X}$. This can be involved into the confidence interval as functions of $X_i's$. That is, there exists $a_1,a_2 \in \mathbb{R}$ such that $$P(a_1 \bar{X} \leq \beta  \leq \bar{X} a_2) = 0.99$$ Since $\hat \beta = \bar{X}$, $$P(a_1 \leq \frac{\beta}{\hat \beta} \leq a_2) = 0.99$$ Now we assign $a_1 = x_{0.001}$ and $a_2 = x_{0.99}$ because finding the probability of such bounds yields $0.99$, $$P(x_{0.001} \leq \frac{\beta}{\hat \beta} \leq x_{0.99}) = 0.99$$ Now we compute the CDF of $\dfrac{\beta}{\hat \beta}$ by finding the CDF of $\hat \beta$ then applying the transform, $ Y = \frac{1}{X}$. Here is what I""ve established, is this the right direction? I'm skeptical because the functions $A$ and $B$ are not general enough..","Suppose  $$X_1,\dots,X_{20} \sim f_X(x;\beta)$$ where $$f_X(x;\beta) = \frac{1}{\beta} e^{-\frac{x}{\beta}},\quad x>0;\beta>0$$ It can shown that (""details omitted"") $$P(0.52 \bar{X} \leq \beta \leq 1.67 \bar{X}) = 0.99, \quad \forall\beta>0 \tag{1}$$ Thus the 99% confidence interval for  $\beta$ is $$(0.52 \bar{X} , 1.67 \bar{X})$$ My question is how $(1)$ come about? My attempt to reason By definition, $$P(\text{confidence interval for } \beta) = 0.99$$ There exists test statistics $A = A(X_1,\dots,X_{20})$ and $B = B(X_1,\dots,X_{20})$  such that $$P(A \leq \beta \leq B) = 0.99$$ I have found that the MLE of $\beta$ is $\hat \beta = \bar{X}$. This can be involved into the confidence interval as functions of $X_i's$. That is, there exists $a_1,a_2 \in \mathbb{R}$ such that $$P(a_1 \bar{X} \leq \beta  \leq \bar{X} a_2) = 0.99$$ Since $\hat \beta = \bar{X}$, $$P(a_1 \leq \frac{\beta}{\hat \beta} \leq a_2) = 0.99$$ Now we assign $a_1 = x_{0.001}$ and $a_2 = x_{0.99}$ because finding the probability of such bounds yields $0.99$, $$P(x_{0.001} \leq \frac{\beta}{\hat \beta} \leq x_{0.99}) = 0.99$$ Now we compute the CDF of $\dfrac{\beta}{\hat \beta}$ by finding the CDF of $\hat \beta$ then applying the transform, $ Y = \frac{1}{X}$. Here is what I""ve established, is this the right direction? I'm skeptical because the functions $A$ and $B$ are not general enough..",,"['statistics', 'statistical-inference']"
3,"Reference request, statistical inference","Reference request, statistical inference",,"Good morning, I'm looking for a good reference for study on statistical inference, the main topics that will study are Tests of Hypotheses Interval estimation I recommend taking a look at Mood Casella These books are good?","Good morning, I'm looking for a good reference for study on statistical inference, the main topics that will study are Tests of Hypotheses Interval estimation I recommend taking a look at Mood Casella These books are good?",,"['statistics', 'reference-request', 'statistical-inference', 'estimation', 'hypothesis-testing']"
4,Are there any limits on Standard Deviation of a data set with given $n$ and mean?,Are there any limits on Standard Deviation of a data set with given  and mean?,n,"Say a class of 200 students is graded out of 100 marks. The mean of the dataset is 50. Can we put a maximum limit on Standard Deviation for the set ? I thought of putting a number of people onto 100 and the rest to zero and came up with $\frac{(100a + 0*(200-a))}{(200)} = 50$, which gives a = 100, so if a 100 people got 100 and a 100 got zero the average would still be 50. Now Standard Deviation = $\sqrt{\frac{\sum{(x_i - 50)}^2}{N}}$ which would equal $\sqrt{ \frac{100*50*50 + 100 *50 *50}{200}}$ = $50$ Is this the max value of standard deviation of this data set ? How do I prove it ? EDIT I now tried it out for different mean values and see that all values are less than 50. Thus max value should be 50. But how do I prove it ?","Say a class of 200 students is graded out of 100 marks. The mean of the dataset is 50. Can we put a maximum limit on Standard Deviation for the set ? I thought of putting a number of people onto 100 and the rest to zero and came up with $\frac{(100a + 0*(200-a))}{(200)} = 50$, which gives a = 100, so if a 100 people got 100 and a 100 got zero the average would still be 50. Now Standard Deviation = $\sqrt{\frac{\sum{(x_i - 50)}^2}{N}}$ which would equal $\sqrt{ \frac{100*50*50 + 100 *50 *50}{200}}$ = $50$ Is this the max value of standard deviation of this data set ? How do I prove it ? EDIT I now tried it out for different mean values and see that all values are less than 50. Thus max value should be 50. But how do I prove it ?",,['statistics']
5,"For X,Y random variables, with pdfs that are symmetric around 0, does $V(X)\geq V(Y) \Rightarrow E(|X|)\geq E(|Y|)$?","For X,Y random variables, with pdfs that are symmetric around 0, does ?",V(X)\geq V(Y) \Rightarrow E(|X|)\geq E(|Y|),"I need to show the following thing. Consider two continuous random variables $X,Y$ which take values in $[-1,1]$ and are have pdf's that are symmetric around zero. How can I show that $V(X)\geq V(Y) \Rightarrow E(|X|)\geq E(|Y|)$ ? I have tried a number of examples where this holds, but I straggle finding a general answer. As an example one can try $f_1(x)=\frac{1}{2}$ (uniform) and $f_2(x)=\frac{3}{2}x^2$ that satisfy the above conditions and the result holds.","I need to show the following thing. Consider two continuous random variables $X,Y$ which take values in $[-1,1]$ and are have pdf's that are symmetric around zero. How can I show that $V(X)\geq V(Y) \Rightarrow E(|X|)\geq E(|Y|)$ ? I have tried a number of examples where this holds, but I straggle finding a general answer. As an example one can try $f_1(x)=\frac{1}{2}$ (uniform) and $f_2(x)=\frac{3}{2}x^2$ that satisfy the above conditions and the result holds.",,"['statistics', 'probability-distributions', 'expectation', 'absolute-value']"
6,"A starting lineup consists of 2 forwards, 2 guards and 1 center. How many different starting lineups..","A starting lineup consists of 2 forwards, 2 guards and 1 center. How many different starting lineups..",,"A certain school has $4$ forwards, $4$ guards, $3$ centers and $1$ person who can play as either a forward or a guard. How many different starting lineups can be made? I came up with 2 answers to this problem. However I don't know which one is right and I can't tell the difference between the two: Solution 1: There are two possibilities, X is a forward, in which there is $\binom{5}{2}\binom{4}{2}\binom{3}{1} = 180$ ways of making this starting lineup. X could be a guard as well, which results in the same number, $180$ ways of making the starting lineup. Add together to get $360$ different ways of making this starting lineup. Solution 2: There are three possibilities which encompass all possible starting lineups: x is not picked, x is picked as a forward, and x is picked as a guard. When x is not picked, there is $\binom{4}{2}\binom{4}{2}\binom{3}{1} = 108$ different lineups without x in it. when x is picked as a forward, you only need to pick one more forward, so there is $\binom{4}{1}\binom{4}{2}\binom{3}{1} = 72$ different lineups with x as forward. the same number will result when you pick x as a guard: $72$. adding $108+72+72$ results in $252$ different lineups. So the problem is that I can't see the fault in logic in either of my solutions. Which one is the right one? edit: centers","A certain school has $4$ forwards, $4$ guards, $3$ centers and $1$ person who can play as either a forward or a guard. How many different starting lineups can be made? I came up with 2 answers to this problem. However I don't know which one is right and I can't tell the difference between the two: Solution 1: There are two possibilities, X is a forward, in which there is $\binom{5}{2}\binom{4}{2}\binom{3}{1} = 180$ ways of making this starting lineup. X could be a guard as well, which results in the same number, $180$ ways of making the starting lineup. Add together to get $360$ different ways of making this starting lineup. Solution 2: There are three possibilities which encompass all possible starting lineups: x is not picked, x is picked as a forward, and x is picked as a guard. When x is not picked, there is $\binom{4}{2}\binom{4}{2}\binom{3}{1} = 108$ different lineups without x in it. when x is picked as a forward, you only need to pick one more forward, so there is $\binom{4}{1}\binom{4}{2}\binom{3}{1} = 72$ different lineups with x as forward. the same number will result when you pick x as a guard: $72$. adding $108+72+72$ results in $252$ different lineups. So the problem is that I can't see the fault in logic in either of my solutions. Which one is the right one? edit: centers",,"['combinatorics', 'statistics']"
7,Bayesian posterior variance,Bayesian posterior variance,,"Let $Var[\omega]$ be the variance of a population parameter $\omega$ prior to the collection of a random sample $\mathcal{X}=\left\lbrace X_1,X_2,\dots,X_n\right\rbrace$ from the population.  Prove or disprove the claim that the posterior variance is, on average, less than or equal to the prior variance. This is a homework problem for introduction to Bayesian statistics.  I want to say that the claim is false, because I could pick any prior distribution that I want, and if I picked a distribution with a super tiny variance, it is likely that the posterior variance would actually be larger. I just think the wording of the problem is a bit vague.  Any insights would be appreciated.","Let $Var[\omega]$ be the variance of a population parameter $\omega$ prior to the collection of a random sample $\mathcal{X}=\left\lbrace X_1,X_2,\dots,X_n\right\rbrace$ from the population.  Prove or disprove the claim that the posterior variance is, on average, less than or equal to the prior variance. This is a homework problem for introduction to Bayesian statistics.  I want to say that the claim is false, because I could pick any prior distribution that I want, and if I picked a distribution with a super tiny variance, it is likely that the posterior variance would actually be larger. I just think the wording of the problem is a bit vague.  Any insights would be appreciated.",,"['probability', 'statistics', 'bayesian']"
8,Let X be a discrete random variable,Let X be a discrete random variable,,"Let X be a discrete random variable. If $E[X]=-3$, then $E[(3+5X)^2]=$ I understand that to find the expected value the formula would be $E[aX+b] = aE[X]+b$  so it would be 3+5(-3). My problem is that I do not know what to do with the square. Where would I put it in the formula. I tried squaring my answer, but it was wrong. What is the formula in an expected value that is squared?","Let X be a discrete random variable. If $E[X]=-3$, then $E[(3+5X)^2]=$ I understand that to find the expected value the formula would be $E[aX+b] = aE[X]+b$  so it would be 3+5(-3). My problem is that I do not know what to do with the square. Where would I put it in the formula. I tried squaring my answer, but it was wrong. What is the formula in an expected value that is squared?",,"['probability', 'statistics']"
9,Maximum likelihood with Bernoulli trials: what to do if there are no successes?,Maximum likelihood with Bernoulli trials: what to do if there are no successes?,,"I'm analyzing the security of a secret sharing scheme.  One attempt I'm analyzing is ""blind luck"".  I return a random share and hope that noone notices. The probability $p$ of someone not noticing will be quite small, around $10^{-14}$ [it's meant to be secure, after all].  I have a theoretical lower bound on $p$, but no decent upper bound. I'm trying to demonstrate that $p$ must be small experimentally.  So I simulated $10^9$ attempts: all of them failed.  This means the maximum likelihood estimate for $p$ is $0$, which is not useful. Q :  Given that each Bernoulli trial resulted in failure, and it's impractical for me to run enough trials to obtain successes, how can I proceed to find some meaningful conclusions about $p$? E.g., perhaps we can say something like we can be 99% sure that $p$ is at most [blah] .","I'm analyzing the security of a secret sharing scheme.  One attempt I'm analyzing is ""blind luck"".  I return a random share and hope that noone notices. The probability $p$ of someone not noticing will be quite small, around $10^{-14}$ [it's meant to be secure, after all].  I have a theoretical lower bound on $p$, but no decent upper bound. I'm trying to demonstrate that $p$ must be small experimentally.  So I simulated $10^9$ attempts: all of them failed.  This means the maximum likelihood estimate for $p$ is $0$, which is not useful. Q :  Given that each Bernoulli trial resulted in failure, and it's impractical for me to run enough trials to obtain successes, how can I proceed to find some meaningful conclusions about $p$? E.g., perhaps we can say something like we can be 99% sure that $p$ is at most [blah] .",,"['probability', 'statistics', 'experimental-mathematics']"
10,Determine the Cumulative Distributive Distribution(CDF) of a truncated value?,Determine the Cumulative Distributive Distribution(CDF) of a truncated value?,,It is the last part(part h) that I am having problems with. I know you use integration and then split it into 2 parts. But how exactly do you do it ? A detailed answer would be very helpful ! Please help !,It is the last part(part h) that I am having problems with. I know you use integration and then split it into 2 parts. But how exactly do you do it ? A detailed answer would be very helpful ! Please help !,,['probability']
11,The p.d.f as a derivative of the c.d.f.,The p.d.f as a derivative of the c.d.f.,,"The cumulative distribution function is defined as: $$F(x)=P(X\le x)=\int_{-\infty}^x f(t)\,dt,$$ where $f(t)$ is the probability density function. By the fundamental theorem of calculus: $$f(x)=F'(x)$$ I am having some difficulty with this topic. For example, suppose that I define: $$F(x)=\begin{cases} 0,\quad x<0\\ x,\quad 0\le x<\frac12\\ \frac12x+\frac12,\quad \frac12\le x\le 1\\ 1,\quad x>2 \end{cases}$$ Now, the graph appears to satisfy all of the requirements of a c.d.f. $F$ is nondecreasing, right continuous, $\lim_{x\to-\infty}F(x)=0$, and $\lim_{x\to\infty}F(x)=1$. However, if I differentiate to try and obtain the p.d.f, I get: $$f(x)=F'(x)=\begin{cases} 0,\quad x<0\\ 1,\quad 0<x<\frac12\\ \frac12,\quad \frac12<x<1\\ 0,\quad x>1 \end{cases}$$ Note that the derivative does not exist at $x=0$, 1/2, and 1. Now, the difficulty is this: $$\int_{-\infty}^{\infty}f(x)\,dx=\frac34$$ It does not equal one as it should. So clearly I am making some sort of mistake and some sort of misunderstanding. Either I have not created a proper c.d.f, or I am not handling the ""jump"" in continuity of $F$. I'm stuck. Any thoughts?","The cumulative distribution function is defined as: $$F(x)=P(X\le x)=\int_{-\infty}^x f(t)\,dt,$$ where $f(t)$ is the probability density function. By the fundamental theorem of calculus: $$f(x)=F'(x)$$ I am having some difficulty with this topic. For example, suppose that I define: $$F(x)=\begin{cases} 0,\quad x<0\\ x,\quad 0\le x<\frac12\\ \frac12x+\frac12,\quad \frac12\le x\le 1\\ 1,\quad x>2 \end{cases}$$ Now, the graph appears to satisfy all of the requirements of a c.d.f. $F$ is nondecreasing, right continuous, $\lim_{x\to-\infty}F(x)=0$, and $\lim_{x\to\infty}F(x)=1$. However, if I differentiate to try and obtain the p.d.f, I get: $$f(x)=F'(x)=\begin{cases} 0,\quad x<0\\ 1,\quad 0<x<\frac12\\ \frac12,\quad \frac12<x<1\\ 0,\quad x>1 \end{cases}$$ Note that the derivative does not exist at $x=0$, 1/2, and 1. Now, the difficulty is this: $$\int_{-\infty}^{\infty}f(x)\,dx=\frac34$$ It does not equal one as it should. So clearly I am making some sort of mistake and some sort of misunderstanding. Either I have not created a proper c.d.f, or I am not handling the ""jump"" in continuity of $F$. I'm stuck. Any thoughts?",,['statistics']
12,A house is guarded by two alarms,A house is guarded by two alarms,,"I am trying to wrap my head around the following problem A house is guarded by two alarms. If Alarm 1 fires, p(theft) = 80% If Alarm 2 fires, p(theft) = 70% If both alarms fire at the same time, what is the probability of a theft? Assuming both alarms are independent Assuming there is some dependence between the alarms It seems simple, but I just can't seem to get it for some reason. Your help is greatly appreciated.","I am trying to wrap my head around the following problem A house is guarded by two alarms. If Alarm 1 fires, p(theft) = 80% If Alarm 2 fires, p(theft) = 70% If both alarms fire at the same time, what is the probability of a theft? Assuming both alarms are independent Assuming there is some dependence between the alarms It seems simple, but I just can't seem to get it for some reason. Your help is greatly appreciated.",,"['probability', 'statistics', 'bayesian']"
13,What is the best book to learn statistics?,What is the best book to learn statistics?,,"Right now I'm taking a 3 part course on probability and statistics using Schverish & Degroot Probability and Statistics and it is just not helpful. For the first part, which was on Probability, I used a First Course in Probability by Sheldon Ross which was extremely helpful unfortunately it doesn't have much statistics. So is there a similar textbook that is focused on statistics?","Right now I'm taking a 3 part course on probability and statistics using Schverish & Degroot Probability and Statistics and it is just not helpful. For the first part, which was on Probability, I used a First Course in Probability by Sheldon Ross which was extremely helpful unfortunately it doesn't have much statistics. So is there a similar textbook that is focused on statistics?",,"['probability', 'statistics', 'reference-request']"
14,Find the probability that you have three of a kind after you pick 5 cards from a regular 52-card deck.,Find the probability that you have three of a kind after you pick 5 cards from a regular 52-card deck.,,"How would I go about finding this? I was thinking that, since this is a permutation, you would  have 52!/(52-5!)? But how would that account for 3 of a kind?","How would I go about finding this? I was thinking that, since this is a permutation, you would  have 52!/(52-5!)? But how would that account for 3 of a kind?",,"['probability', 'statistics']"
15,Joint PDF of all n Order Statistics,Joint PDF of all n Order Statistics,,"If $X_1,\ldots,X_n$ is a random sample from a continuous distribution with pdf $f_{\theta}(x)$, why is the joint PDF of the order statistics $X_{(1)},\ldots,X_{(n)}$ the following: $$\large f_{X_{(1)},\ldots,X_{(n)}}(x_1,\ldots,x_n)=n!\prod_{i=1}^nf_{\theta}(x_i)$$ I'm not sure where the $n!$ is coming from. Is the joint PDF of all $n$ order statistics not just a ""re-ordering"" of the random variables $X_1,\ldots,X_n$? And the joint distribution of $X_1,\ldots,X_n$ is just $\large\prod\limits_{i=1}^n f_{\theta}(x_i)$.","If $X_1,\ldots,X_n$ is a random sample from a continuous distribution with pdf $f_{\theta}(x)$, why is the joint PDF of the order statistics $X_{(1)},\ldots,X_{(n)}$ the following: $$\large f_{X_{(1)},\ldots,X_{(n)}}(x_1,\ldots,x_n)=n!\prod_{i=1}^nf_{\theta}(x_i)$$ I'm not sure where the $n!$ is coming from. Is the joint PDF of all $n$ order statistics not just a ""re-ordering"" of the random variables $X_1,\ldots,X_n$? And the joint distribution of $X_1,\ldots,X_n$ is just $\large\prod\limits_{i=1}^n f_{\theta}(x_i)$.",,"['statistics', 'probability-distributions', 'order-statistics']"
16,Median vs. Mean,Median vs. Mean,,"Problem: Consider the following model: $y_i = \mu + \epsilon_i$, $i = 1,...,n$ Let the mean $\mu$ be estimated by minimizing the criterion $\sum|\mu - y_i|$ over $\mu$. Show that $m = $median($y_1,y_2,...,y_n$) is optimal for this criterion. Distinguish the case $n$ is odd and $n$ is even. My idea to approach the problem: $1)$ Rewrite the criterion such that no absolute signs are needed (with indicator function for example). $2)$ Determine the first order condition to recognize the median. $3)$ Order data to distinguish $n$ odd or $n$ even However, I dont't know how to to the steps of my apporach in a mathematical/statistical way. Could anyone please help me?","Problem: Consider the following model: $y_i = \mu + \epsilon_i$, $i = 1,...,n$ Let the mean $\mu$ be estimated by minimizing the criterion $\sum|\mu - y_i|$ over $\mu$. Show that $m = $median($y_1,y_2,...,y_n$) is optimal for this criterion. Distinguish the case $n$ is odd and $n$ is even. My idea to approach the problem: $1)$ Rewrite the criterion such that no absolute signs are needed (with indicator function for example). $2)$ Determine the first order condition to recognize the median. $3)$ Order data to distinguish $n$ odd or $n$ even However, I dont't know how to to the steps of my apporach in a mathematical/statistical way. Could anyone please help me?",,"['probability', 'statistics', 'median']"
17,Is my understanding of the Central Limit Theorem correct?,Is my understanding of the Central Limit Theorem correct?,,"Have I got this correct - Say we have a population. We take a random sample of size $n$ from this population. I.e. we form a sample $S$ based on random variables $X_1, X_2, ..., X_n$ taken from this population. So the sample $S$ is a set consisting of of these random variables, and hence the mean of the sample $\overline X$ will be a function of these random variables. The distribution of $\overline X$ will be approximately normal. And if we keep taking samples infinitely, and standardizing $\overline X$ by taking $$h(x) = \frac{\overline X - \mu}{\frac{\sigma}{\sqrt{n}}}$$ the limiting distribution of $h(x)$ will be $N(0, 1)$. Is my understanding correct here?","Have I got this correct - Say we have a population. We take a random sample of size $n$ from this population. I.e. we form a sample $S$ based on random variables $X_1, X_2, ..., X_n$ taken from this population. So the sample $S$ is a set consisting of of these random variables, and hence the mean of the sample $\overline X$ will be a function of these random variables. The distribution of $\overline X$ will be approximately normal. And if we keep taking samples infinitely, and standardizing $\overline X$ by taking $$h(x) = \frac{\overline X - \mu}{\frac{\sigma}{\sqrt{n}}}$$ the limiting distribution of $h(x)$ will be $N(0, 1)$. Is my understanding correct here?",,"['probability', 'statistics', 'normal-distribution', 'central-limit-theorem']"
18,Is there a convenient formula for variance of discrete random variable in terms of CDF,Is there a convenient formula for variance of discrete random variable in terms of CDF,,"For a discrete random variable X, $\Omega_X\subseteq \{0,1,2,\ldots\}$, we can write $$\mathrm{E}[X] = \sum_{x=0}^\infty (1-F(x)) $$ where $F(x)$ is the cumulative distribution function of $X$. This formula is proving convenient to me on the current problem I'm working on where  the cumulative probability of being in a ""sink"" state naturally comes out of formulating the problem in terms of a transition matrix. However, I was wondering whether there is an analogous formula for variance in terms of the CDF, or whether if I want the variance I'm going to have to change tack? I'm thinking there isn't such a formula, because variance is defined as $E[(X-\mu)^2]$ and although $(X-\mu)^2$ is positive, it isn't an integer and so a similar approach won't work.","For a discrete random variable X, $\Omega_X\subseteq \{0,1,2,\ldots\}$, we can write $$\mathrm{E}[X] = \sum_{x=0}^\infty (1-F(x)) $$ where $F(x)$ is the cumulative distribution function of $X$. This formula is proving convenient to me on the current problem I'm working on where  the cumulative probability of being in a ""sink"" state naturally comes out of formulating the problem in terms of a transition matrix. However, I was wondering whether there is an analogous formula for variance in terms of the CDF, or whether if I want the variance I'm going to have to change tack? I'm thinking there isn't such a formula, because variance is defined as $E[(X-\mu)^2]$ and although $(X-\mu)^2$ is positive, it isn't an integer and so a similar approach won't work.",,['statistics']
19,"X follows an exponential distribution, calculate Expected value of sqrt(X).","X follows an exponential distribution, calculate Expected value of sqrt(X).",,"Problem: Let X follow an exponential distribution with expected value of 1. Define Y=sqrt(X). Calculate E(Y). This is my first course in probability theory (5 weeks ≈ about 5*40 hours of workload) so the tools we have learned are not that many. Tip: if X follows N(0,1) then E(X^2)=1. Attempt: Correct answer it sqrt(Pi/2)","Problem: Let X follow an exponential distribution with expected value of 1. Define Y=sqrt(X). Calculate E(Y). This is my first course in probability theory (5 weeks ≈ about 5*40 hours of workload) so the tools we have learned are not that many. Tip: if X follows N(0,1) then E(X^2)=1. Attempt: Correct answer it sqrt(Pi/2)",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
20,Derivative of double summation and dot notation?,Derivative of double summation and dot notation?,,"I am trying to differentiate the following summation: $$ L(\mu, \tau_1, \ldots, \tau_i)= \sum_{i=1}^v \sum_{t=1}^{r_i} (y_{it}-\mu - \tau_i)^2 $$ $$\frac{dL}{d\mu} = y_{\cdot\cdot}-n\mu - \sum_{i=1}^v r_i \tau_i$$ $$\frac{dL}{d\tau_i} = y_{i\cdot}-r_i \mu - r_i \tau_i$$ I tried taking the derivative in terms of $\mu$ and $\tau $ but the dot notation/summations confuse me in terms of expanding the equation of the derivative. For instance, I don't understand how you get $y_{\cdot\cdot}$, $n$, and $\sum r_i$ (within the terms) when taking the derivative in terms of $\mu$. Or when taking the derivative in terms of $\tau$, I don't get why you get $y_{i\cdot}$ and $r_i$. I brushed up on taking derivatives of summations and I still don't understand. I'd appreciate it if someone can help me understand, thank you.","I am trying to differentiate the following summation: $$ L(\mu, \tau_1, \ldots, \tau_i)= \sum_{i=1}^v \sum_{t=1}^{r_i} (y_{it}-\mu - \tau_i)^2 $$ $$\frac{dL}{d\mu} = y_{\cdot\cdot}-n\mu - \sum_{i=1}^v r_i \tau_i$$ $$\frac{dL}{d\tau_i} = y_{i\cdot}-r_i \mu - r_i \tau_i$$ I tried taking the derivative in terms of $\mu$ and $\tau $ but the dot notation/summations confuse me in terms of expanding the equation of the derivative. For instance, I don't understand how you get $y_{\cdot\cdot}$, $n$, and $\sum r_i$ (within the terms) when taking the derivative in terms of $\mu$. Or when taking the derivative in terms of $\tau$, I don't get why you get $y_{i\cdot}$ and $r_i$. I brushed up on taking derivatives of summations and I still don't understand. I'd appreciate it if someone can help me understand, thank you.",,"['statistics', 'derivatives', 'summation', 'partial-derivative']"
21,What is the probability of selecting an item of a list of items that have not been selected before?,What is the probability of selecting an item of a list of items that have not been selected before?,,"Story behind my question From time to time, I like to play DotA. It is a competitive computer game, where you pick 1 out of more than 100 heroes and play against each other. For simplicity, let's stick to 3 heroes. For to learn how to play with every single hero, I like to pick one randomly at the start of every game. Playing with my friends, I was criticized for playing with heroes that I do not know. The question So I asked myself: What is the probability of getting a hero that I have not played before after $x$ games (and, as a consequence, encounter higher difficulty)? Small example Before the first game ($x=0$), the probability is $100$%. Then it gets difficult. Consider the following list of three heroes: $H = \{A, B, C\}$. Playing two games, these outcomes might occur: $E = \{$$AA$, $AB$, $BA$, $BB$, $AC$, $CA$, $CC$, $BC$, $CB$ $\}$ In the following cases the probability of a new hero in the third game is $1/3$ $AB, BA, CB, BC, AC, CA$ In the following cases the probability of a new hero in the third game is $2/3$ $AA, BB, CC$ For example, after $AA$ the heroes $B$ and $C$ will still be new. In contrast, after seeing $BC$ only $A$ would be new. My approach The probability of getting a new hero depends on the number of rounds played and the number of heroes available. There are 3 heroes in the easy example, in reality more than 100. Every hero has the same chance of being picked each game. So it could be the same for $x$ games in a row. I think of it as a kind of binomial distribution. But it's not about ""Prob. that a coin is head 5 out of 6 times"". It's about the probability that anyone of those who have never been selected in games before is now selected . How could one solve it?","Story behind my question From time to time, I like to play DotA. It is a competitive computer game, where you pick 1 out of more than 100 heroes and play against each other. For simplicity, let's stick to 3 heroes. For to learn how to play with every single hero, I like to pick one randomly at the start of every game. Playing with my friends, I was criticized for playing with heroes that I do not know. The question So I asked myself: What is the probability of getting a hero that I have not played before after $x$ games (and, as a consequence, encounter higher difficulty)? Small example Before the first game ($x=0$), the probability is $100$%. Then it gets difficult. Consider the following list of three heroes: $H = \{A, B, C\}$. Playing two games, these outcomes might occur: $E = \{$$AA$, $AB$, $BA$, $BB$, $AC$, $CA$, $CC$, $BC$, $CB$ $\}$ In the following cases the probability of a new hero in the third game is $1/3$ $AB, BA, CB, BC, AC, CA$ In the following cases the probability of a new hero in the third game is $2/3$ $AA, BB, CC$ For example, after $AA$ the heroes $B$ and $C$ will still be new. In contrast, after seeing $BC$ only $A$ would be new. My approach The probability of getting a new hero depends on the number of rounds played and the number of heroes available. There are 3 heroes in the easy example, in reality more than 100. Every hero has the same chance of being picked each game. So it could be the same for $x$ games in a row. I think of it as a kind of binomial distribution. But it's not about ""Prob. that a coin is head 5 out of 6 times"". It's about the probability that anyone of those who have never been selected in games before is now selected . How could one solve it?",,"['calculus', 'probability', 'statistics']"
22,Convert nonlinear regression equation to a linear regression equation,Convert nonlinear regression equation to a linear regression equation,,"The question is: Show how the nonlinear regression equation $y=aX^B$ can be converted to a linear regression equation solvable by the method of least squares. I found how to take $Y=Ae^{bX}u$ to a linear equation $y=a+bX+v$ , where $y=\ln(Y)$ , $a=\ln(A)$ and $v=\ln(u)$ . However, I feel like there is a key difference between that example and my equation. The base of the exponential equation is $e$ in their example and $X$ in mine. The base being $e$ in their example is what allows then to simplify $\ln(e^{bX})=bX$ , right? So I'm not sure what to do with my equation. I'm assuming the answer is not as simple as $y=a+B \ln(X)$ . Because this is still not linear. Any help explaining this would be greatly appreciated!","The question is: Show how the nonlinear regression equation can be converted to a linear regression equation solvable by the method of least squares. I found how to take to a linear equation , where , and . However, I feel like there is a key difference between that example and my equation. The base of the exponential equation is in their example and in mine. The base being in their example is what allows then to simplify , right? So I'm not sure what to do with my equation. I'm assuming the answer is not as simple as . Because this is still not linear. Any help explaining this would be greatly appreciated!",y=aX^B Y=Ae^{bX}u y=a+bX+v y=\ln(Y) a=\ln(A) v=\ln(u) e X e \ln(e^{bX})=bX y=a+B \ln(X),"['statistics', 'regression']"
23,MLE of fourth moment of normal distribution,MLE of fourth moment of normal distribution,,"Take $X\sim N(0,\theta)$, and let $\phi = E(X^4)$, the fourth moment. What is its MLE, $\hat{\phi}$, and what is the asymptotic distribution of $\sqrt{n}(\hat{\phi} - \phi) $ as $n\to \infty$? Any help with this question would be appreciated, as I really can't think of where to start!! Many thanks. I have integrated the expression for $E(X^4)$ by parts three times to get $\phi = 6\theta^3$, which gives $\hat{\phi} = 6\hat{\theta}^3$ as the function is continuous (is this correct?). However, I am not sure what the MLE of $\theta$ should be, and what that makes the asymptotic distribution $\sqrt{n}(\hat{\phi} - \phi) $.","Take $X\sim N(0,\theta)$, and let $\phi = E(X^4)$, the fourth moment. What is its MLE, $\hat{\phi}$, and what is the asymptotic distribution of $\sqrt{n}(\hat{\phi} - \phi) $ as $n\to \infty$? Any help with this question would be appreciated, as I really can't think of where to start!! Many thanks. I have integrated the expression for $E(X^4)$ by parts three times to get $\phi = 6\theta^3$, which gives $\hat{\phi} = 6\hat{\theta}^3$ as the function is continuous (is this correct?). However, I am not sure what the MLE of $\theta$ should be, and what that makes the asymptotic distribution $\sqrt{n}(\hat{\phi} - \phi) $.",,"['probability', 'statistics', 'normal-distribution']"
24,"Markov chains for beginners, how to think about them?","Markov chains for beginners, how to think about them?",,"So this is what my book states: Random variables $X,Y, and Z$ are said to form a Markov chain in that order denoted $X\rightarrow Y \rightarrow Z$ if and only if: $p(x,y,z)=p(x)p(y|x)p(z|y) $ That's great and all but that doesn't give any intuition as to what a Markov chain is or what it implies. Can someone please give me more intuition as to how I should think about Markov chains? Thanks a lot!!","So this is what my book states: Random variables $X,Y, and Z$ are said to form a Markov chain in that order denoted $X\rightarrow Y \rightarrow Z$ if and only if: $p(x,y,z)=p(x)p(y|x)p(z|y) $ That's great and all but that doesn't give any intuition as to what a Markov chain is or what it implies. Can someone please give me more intuition as to how I should think about Markov chains? Thanks a lot!!",,"['probability', 'statistics', 'information-theory']"
25,"Random process, stochastic process explained intuitively?","Random process, stochastic process explained intuitively?",,"So I've read the definitions online and this is what I understood. $X(t)$ is a random process for $t>0$ and we can think of it as being a random variable at any given time $t=t_0$. For example, $X(t_0)$ is a random variable while $X(t)$ is a random process. So a definition of a random process COULD be: \begin{align*} Let \space X(t) =   \begin{cases}    1  & \mbox{w.p. } 1/t\\    4 & \mbox{w.p. } 1-1/t \\ \end{cases} \end{align*} Is this correct? Please give me more intuition as to what a random process is Thank you so much!","So I've read the definitions online and this is what I understood. $X(t)$ is a random process for $t>0$ and we can think of it as being a random variable at any given time $t=t_0$. For example, $X(t_0)$ is a random variable while $X(t)$ is a random process. So a definition of a random process COULD be: \begin{align*} Let \space X(t) =   \begin{cases}    1  & \mbox{w.p. } 1/t\\    4 & \mbox{w.p. } 1-1/t \\ \end{cases} \end{align*} Is this correct? Please give me more intuition as to what a random process is Thank you so much!",,"['probability', 'statistics', 'information-theory']"
26,"Is $X^2-Y^2/ \sqrt{X^2+Y^2}$ normal where $X,Y\sim N(0,1)$ [duplicate]",Is  normal where  [duplicate],"X^2-Y^2/ \sqrt{X^2+Y^2} X,Y\sim N(0,1)","This question already has answers here : Given that $X,Y$ are independent $N(0,1)$ , show that $\frac{XY}{\sqrt{X^2+Y^2}},\frac{X^2-Y^2}{2\sqrt{X^2+Y^2}}$ are independent $N(0,\frac{1}{4})$ (3 answers) Closed 4 years ago . Can I say that  $(X^2-Y^2)/ \sqrt{X^2+Y^2}$ is normal since $X,Y\sim N(0,1)$ and $X,Y$ are normal and independent? I am trying to do those problem using polar coordinates with $X=r \cos \theta$ and $Y=r \sin \theta$, but I got stuck when I was trying to simplify $(X^2-Y^2)/ \sqrt{X^2+Y^2}$. Can anybody please help me? Thanks!","This question already has answers here : Given that $X,Y$ are independent $N(0,1)$ , show that $\frac{XY}{\sqrt{X^2+Y^2}},\frac{X^2-Y^2}{2\sqrt{X^2+Y^2}}$ are independent $N(0,\frac{1}{4})$ (3 answers) Closed 4 years ago . Can I say that  $(X^2-Y^2)/ \sqrt{X^2+Y^2}$ is normal since $X,Y\sim N(0,1)$ and $X,Y$ are normal and independent? I am trying to do those problem using polar coordinates with $X=r \cos \theta$ and $Y=r \sin \theta$, but I got stuck when I was trying to simplify $(X^2-Y^2)/ \sqrt{X^2+Y^2}$. Can anybody please help me? Thanks!",,['probability']
27,Linear fit to wrapped / periodic data,Linear fit to wrapped / periodic data,,"Assume I have a number $N$ of noisy (phase) data $\varphi_i$, i.e., $\varphi_i \in [0,2\pi)$. I know that between $\varphi_{i-1}$ and $\varphi_i$ there is a constant phase shift $\Delta \varphi$ (neglecting the noise). If I want to determine $\Delta \varphi$ from the noisy data, I could do a linear fit: $$ \varphi_i = \varphi_0 + i \Delta\varphi $$ The only problem is the ""wrapping"" of $\varphi_i$ at $2\pi$. Actually I would have to find a least squares solution to something like: $$ \varphi_i = (\varphi_0 + i \Delta\varphi \mod 2\pi) $$ It would be possible to do an ""unwrapping"" of the data before by shifting $\varphi_i$ by $2n_i\pi$ such that $|\varphi_{i-1}-\varphi_i|$ gets minimal and applying a linear fit afterwards (see the first equation). However, I wonder whether there is a way to do it ""directly"" without the unwrapping, which might potentially affect the result (especially in case of a more complex phase shift model, which is what I am actually heading to...).","Assume I have a number $N$ of noisy (phase) data $\varphi_i$, i.e., $\varphi_i \in [0,2\pi)$. I know that between $\varphi_{i-1}$ and $\varphi_i$ there is a constant phase shift $\Delta \varphi$ (neglecting the noise). If I want to determine $\Delta \varphi$ from the noisy data, I could do a linear fit: $$ \varphi_i = \varphi_0 + i \Delta\varphi $$ The only problem is the ""wrapping"" of $\varphi_i$ at $2\pi$. Actually I would have to find a least squares solution to something like: $$ \varphi_i = (\varphi_0 + i \Delta\varphi \mod 2\pi) $$ It would be possible to do an ""unwrapping"" of the data before by shifting $\varphi_i$ by $2n_i\pi$ such that $|\varphi_{i-1}-\varphi_i|$ gets minimal and applying a linear fit afterwards (see the first equation). However, I wonder whether there is a way to do it ""directly"" without the unwrapping, which might potentially affect the result (especially in case of a more complex phase shift model, which is what I am actually heading to...).",,"['statistics', 'periodic-functions']"
28,Examples of logistic regression and multinomial logistic regression,Examples of logistic regression and multinomial logistic regression,,"I've been studying to understand the concept of logistic regression and I think I understand the idea more or less, but there are still some gaps to fill. What I'm looking for is an example of logistic regression and multinomial logistic regression to take the point home. Could someone perhaps give me a very simple examples to show me the fundamental steps one needs to take when doing logistic regression? For example could someone show me what would I have to do If my data set consisted of the following: $$\textbf{x}_1 = x_{11}, x_{12}, ..., x_{1n}$$ $$\textbf{x}_2 = x_{21}, x_{22}, ..., x_{2n}$$ $$\vdots$$ $$\textbf{x}_m = x_{m1}, x_{m2}, ..., x_{mn}$$ So $\textbf{x}_i$ is the $i$th variable and the observations from that variable I have denoted as $x_{ij}$, $1 \leq j \leq n$. I have $m$ variables and $n$ observations on each of them. Let's say the data described different kind of physiological features from $n$ different persons and I would like to use logistic regression to get the probability that person $A_k$, $1 \leq k \leq n$ gets an heart attack. In this example there are only two possible events: ""heart attack"" and ""no heart attack"". Could someone give me a pencil and paper like example what I would need to do to estimate the parameters using maximum likelihood etc. just to make it absolutely clear to me. It would be very nice if I could get examples in the case of two possible events and in the general cases where the number of possible events is $\geq 3$, because I'm using logistic regression in a project work where I have more than three possible events. Hope my question is clear. The examples don't have to be long or anything. Just a very simple, short, showing all the steps,(e.g. calculating parameter estimates etc.). I have been watching some examples from the web, but in many sources the actual calculations I would like to see are just replaced by the words: ""And computer gives us the parameters"" :(. I want to see what is going on :) Thank you for any help :) P.S. You don't have to present a numeric example (you can if you want ;)). It is enough just to show all the necessary steps so that I'll be able to program the steps in Matlab if I wanted to :) Both logistic and multinomial logistic regression :) UPDATE: If anyone is interested I found a very good site explaining logistic regression covering the details, etc. The site can be found here: http://www.real-statistics.com/logistic-regression/basic-concepts-logistic-regression/","I've been studying to understand the concept of logistic regression and I think I understand the idea more or less, but there are still some gaps to fill. What I'm looking for is an example of logistic regression and multinomial logistic regression to take the point home. Could someone perhaps give me a very simple examples to show me the fundamental steps one needs to take when doing logistic regression? For example could someone show me what would I have to do If my data set consisted of the following: $$\textbf{x}_1 = x_{11}, x_{12}, ..., x_{1n}$$ $$\textbf{x}_2 = x_{21}, x_{22}, ..., x_{2n}$$ $$\vdots$$ $$\textbf{x}_m = x_{m1}, x_{m2}, ..., x_{mn}$$ So $\textbf{x}_i$ is the $i$th variable and the observations from that variable I have denoted as $x_{ij}$, $1 \leq j \leq n$. I have $m$ variables and $n$ observations on each of them. Let's say the data described different kind of physiological features from $n$ different persons and I would like to use logistic regression to get the probability that person $A_k$, $1 \leq k \leq n$ gets an heart attack. In this example there are only two possible events: ""heart attack"" and ""no heart attack"". Could someone give me a pencil and paper like example what I would need to do to estimate the parameters using maximum likelihood etc. just to make it absolutely clear to me. It would be very nice if I could get examples in the case of two possible events and in the general cases where the number of possible events is $\geq 3$, because I'm using logistic regression in a project work where I have more than three possible events. Hope my question is clear. The examples don't have to be long or anything. Just a very simple, short, showing all the steps,(e.g. calculating parameter estimates etc.). I have been watching some examples from the web, but in many sources the actual calculations I would like to see are just replaced by the words: ""And computer gives us the parameters"" :(. I want to see what is going on :) Thank you for any help :) P.S. You don't have to present a numeric example (you can if you want ;)). It is enough just to show all the necessary steps so that I'll be able to program the steps in Matlab if I wanted to :) Both logistic and multinomial logistic regression :) UPDATE: If anyone is interested I found a very good site explaining logistic regression covering the details, etc. The site can be found here: http://www.real-statistics.com/logistic-regression/basic-concepts-logistic-regression/",,"['calculus', 'probability', 'statistics', 'regression']"
29,Maximum Likelihood Principle; Local vs. Global Maxima,Maximum Likelihood Principle; Local vs. Global Maxima,,"In the statement for estimating parameters through the Maximum Likelihood Principle (MLE), there is no mention of whether to choose a local maximum or a global maximum. (In my very limited reading so far) From the examples given in various textbooks/lecture notes, it seems that we should choose the global maximum of the likelihood function for inference. Is this correct? The reason I am asking is because I am dealing with some data whose likelihood seems to have several maxima. The parameter space is three dimensional, so I have no intuition about the situation. In this case how do I estimate the parameters properly - do I just look for the maximum in a small part of the parameter space? (The bounds could be established through guesses based on the data, for example.)","In the statement for estimating parameters through the Maximum Likelihood Principle (MLE), there is no mention of whether to choose a local maximum or a global maximum. (In my very limited reading so far) From the examples given in various textbooks/lecture notes, it seems that we should choose the global maximum of the likelihood function for inference. Is this correct? The reason I am asking is because I am dealing with some data whose likelihood seems to have several maxima. The parameter space is three dimensional, so I have no intuition about the situation. In this case how do I estimate the parameters properly - do I just look for the maximum in a small part of the parameter space? (The bounds could be established through guesses based on the data, for example.)",,"['statistics', 'statistical-inference']"
30,$\chi^2$ tests giving apparently conflicting results; and debate on validity of classical statistics,tests giving apparently conflicting results; and debate on validity of classical statistics,\chi^2,"I've come across some very bright people who say that ""classical statistics"" is ""plain wrong"", as is also said about cosmology based on string theory. I think they prefer the ""Bayesian"" statistics that classical statistics replaced, or at least, most of them do. I'm looking for a way in to understanding what they are talking about! Can people please help with the following question, on which I think reflection may be useful in this connection. A random sample of 59 people yielded the following results: Eye-colour                 1(Blue)   2(Brown)                 ------------------ Sex 1 (Male)       19       10     2 (Female)      9       21 Carry out Pearson’s $\chi^2$-squared test at the 5% level of the null   hypothesis that sex and eye-colour are independent. Now do the same   for the null hypothesis that each of the cell probabilities is $\frac{1}{4}$. In the first case, I get $T=7.46 > \chi_1^2(0.05) = 3.84$. So reject the NH. In the second case, I get $T=7.64 < \chi_3^2(0.05) = 7.81$. So accept the NH. Comment on your results. We appear to be getting an absurdity; that we should reject the hypothesis that the variables are independent, but accept the hypothesis that each of the probabilities is $\frac{1}{4}$, which implies independence. Assistance would be welcome!","I've come across some very bright people who say that ""classical statistics"" is ""plain wrong"", as is also said about cosmology based on string theory. I think they prefer the ""Bayesian"" statistics that classical statistics replaced, or at least, most of them do. I'm looking for a way in to understanding what they are talking about! Can people please help with the following question, on which I think reflection may be useful in this connection. A random sample of 59 people yielded the following results: Eye-colour                 1(Blue)   2(Brown)                 ------------------ Sex 1 (Male)       19       10     2 (Female)      9       21 Carry out Pearson’s $\chi^2$-squared test at the 5% level of the null   hypothesis that sex and eye-colour are independent. Now do the same   for the null hypothesis that each of the cell probabilities is $\frac{1}{4}$. In the first case, I get $T=7.46 > \chi_1^2(0.05) = 3.84$. So reject the NH. In the second case, I get $T=7.64 < \chi_3^2(0.05) = 7.81$. So accept the NH. Comment on your results. We appear to be getting an absurdity; that we should reject the hypothesis that the variables are independent, but accept the hypothesis that each of the probabilities is $\frac{1}{4}$, which implies independence. Assistance would be welcome!",,['statistics']
31,Interesting gun versus car fatality question,Interesting gun versus car fatality question,,"I think I'm overthinking this problem, but it doesn't seem intuitive: if 184 million people drive daily resulting in 33,000 fatalities yearly, and there are 1.5 million gun owners who use their guns yearly, resulting in 776 unintentional fatalities yearly, what would be the equivalent fatality rate if adjusted for daily gun use?","I think I'm overthinking this problem, but it doesn't seem intuitive: if 184 million people drive daily resulting in 33,000 fatalities yearly, and there are 1.5 million gun owners who use their guns yearly, resulting in 776 unintentional fatalities yearly, what would be the equivalent fatality rate if adjusted for daily gun use?",,"['probability', 'statistics']"
32,Number of Strings with two specific letters,Number of Strings with two specific letters,,How many ways can you construct a string four letters (from 26 alphabet characters) that have both the letters j and k in them?,How many ways can you construct a string four letters (from 26 alphabet characters) that have both the letters j and k in them?,,"['combinatorics', 'statistics', 'permutations']"
33,Statistical Freedom,Statistical Freedom,,"What is the English counterpart of the French term ""statistique libre""? The following excerpt, translated by me from an excellent 70's French textbook in mathematical statistics ([BAR]), defines the term ""a free statistic"" (""statistique libre""). As i am unfamiliar with either the term or its definition, and as i did not find a definition thereof in the French Wikipedia, i was wondering whether this concept has a standard English name, or whether it has not withstood the test of time and its use is essentially confined to this textbook. Let $\left(\Omega,\mathcal{A},\mathbf{P}\right)$ be a statistical space. An event $A$ is said to be free if $P(A)$ is the same value for all $P\in\mathbf{P}$ . A sub- $\sigma$ -algebra $\mathcal{B}\subseteq\mathcal{A}$ is said to be free if each of its events is. The statistic $T$ , taking values in $\left(\Gamma,\mathcal{B}\right)$ is said to be free if $T^{-1}\left(\mathcal{B}\right)$ is, i.e. if $T$ 's distribution is the same for all $P\in\mathbf{P}$ . -- Ch. II, Sec. 4, Definition 1 I should add that, as far as the author of the textbook is concerned, this is a very important concept: It features in the title of a chapter right next to ""sufficiency"" (chapter II: ""Sufficiency and Freedom""), and the author goes on to write that the two notions of sufficiency and freedom are distinctive features of statistics that separate it from probability. (In the introduction to chapter II). References [BAR] Barra, Jean-René. Notion fondamentales de statistique mathématique. Dunod, 1971.","What is the English counterpart of the French term ""statistique libre""? The following excerpt, translated by me from an excellent 70's French textbook in mathematical statistics ([BAR]), defines the term ""a free statistic"" (""statistique libre""). As i am unfamiliar with either the term or its definition, and as i did not find a definition thereof in the French Wikipedia, i was wondering whether this concept has a standard English name, or whether it has not withstood the test of time and its use is essentially confined to this textbook. Let be a statistical space. An event is said to be free if is the same value for all . A sub- -algebra is said to be free if each of its events is. The statistic , taking values in is said to be free if is, i.e. if 's distribution is the same for all . -- Ch. II, Sec. 4, Definition 1 I should add that, as far as the author of the textbook is concerned, this is a very important concept: It features in the title of a chapter right next to ""sufficiency"" (chapter II: ""Sufficiency and Freedom""), and the author goes on to write that the two notions of sufficiency and freedom are distinctive features of statistics that separate it from probability. (In the introduction to chapter II). References [BAR] Barra, Jean-René. Notion fondamentales de statistique mathématique. Dunod, 1971.","\left(\Omega,\mathcal{A},\mathbf{P}\right) A P(A) P\in\mathbf{P} \sigma \mathcal{B}\subseteq\mathcal{A} T \left(\Gamma,\mathcal{B}\right) T^{-1}\left(\mathcal{B}\right) T P\in\mathbf{P}","['statistics', 'terminology']"
34,Can Bhattacharyya distance be greater than one?,Can Bhattacharyya distance be greater than one?,,"I have two vectors, say $P$ and $Q$. I want to find the statistical overlap between two given that $P$ is my reference which I have modeled after Normal distribution and I have parameters for it. $Q$ is the distribution whose overlap with $P$ I want to find. For this problem, I took two vectors ($P$ with 8000 elements and $Q$ with 60 elements). $P$ will always remain fixed whereas $Q$ will keep on changing. Now, I find Bhattacharyya distance between two to find its statistical overlap. The formula I have used to find distance is given here . Also the previous link suggests that Bhattacharyya distance is always between 0 and 1. I am getting it to be 4.0978. Am I doing something wrong? I am sure my implementation of formula is correct. Also, is this the best method to solve the problem I have described? P.S. To include specific numbers so that anybody will be able to replicate my results and tell me what is wrong. Notations are according to the formula described here : $\sigma_p = 0.0524$ $\sigma_q = 0.0623$ $\mu_p = 0.9244$ $\mu_q = 0.5952$","I have two vectors, say $P$ and $Q$. I want to find the statistical overlap between two given that $P$ is my reference which I have modeled after Normal distribution and I have parameters for it. $Q$ is the distribution whose overlap with $P$ I want to find. For this problem, I took two vectors ($P$ with 8000 elements and $Q$ with 60 elements). $P$ will always remain fixed whereas $Q$ will keep on changing. Now, I find Bhattacharyya distance between two to find its statistical overlap. The formula I have used to find distance is given here . Also the previous link suggests that Bhattacharyya distance is always between 0 and 1. I am getting it to be 4.0978. Am I doing something wrong? I am sure my implementation of formula is correct. Also, is this the best method to solve the problem I have described? P.S. To include specific numbers so that anybody will be able to replicate my results and tell me what is wrong. Notations are according to the formula described here : $\sigma_p = 0.0524$ $\sigma_q = 0.0623$ $\mu_p = 0.9244$ $\mu_q = 0.5952$",,"['statistics', 'probability-distributions', 'normal-distribution']"
35,Generating a random number from a given distribution,Generating a random number from a given distribution,,"I have a problem (a part of a Monte Carlo simulation) where I'm given the energy of an incoming particle, $\varepsilon$ and want to split this energy in two parts, randomly generating the fraction that goes into each part according to a given function $P(\varepsilon_s) \propto %\frac{1}{\bar E \arctan\left(\frac{\varepsilon}{\bar E}\right)}  \frac{1}{1+\left(\frac{\varepsilon_s}{\bar E}\right)^2}$ $\bar E$ is a known shape parameter. Now, the incoming particle can have energies ranging from 0 to a known maximum, $\varepsilon \in \left[0,\varepsilon_{\text{max}}\right]$, but I do not know the energy until the collision event, when I want to split it up, and therefore I can't figure out how to normalize the distribution function properly. I have a pseudo-random number generator at my disposal which generates uniformly distributed numbers on $[0,1)$. How do I generate random numbers that properly describe how the two collisional products share the available energy? I've tried reading up on methods for this in available books, but they're all a little to theoretical for me to be able to apply them to my scenario. It's been way too long since I took a proper statistics course, and now it seems I need it :) Update : As requested, a more thorough description of $P$ (which will get into detail about the physics of this experiment...) follows here: The physics of this problem is ionization - I have an incoming electron with kinetic energy $\varepsilon$, that collides with a molecule and ionizes it. After the collision event, I have two electrons with energies $\varepsilon_p$ (primary) and $\varepsilon_s$ (secondary), with $\varepsilon_p+\varepsilon_s=\varepsilon-\varepsilon_i$, the latter being the (known) ionization energy. Now, I don't really care which electron is which after the collision, so determining the two energies is simply a problem of dividing $\varepsilon-\varepsilon_i$ into two parts. To do this, I am using the differential cross section of the collision, as suggested by Y. Tzeng and E. E. Kunhardt 1 , which is given by them as $q(\varepsilon, \varepsilon_s) = \frac{C(\varepsilon)}{\bar E \arctan\left((\varepsilon-\varepsilon_i)/\bar E\right)}\cdot \frac{1}{1+\left({\varepsilon_s/\bar E}\right)^2}$ $C(\varepsilon)$ in this epxression is the total collision cross section, which is also known. I'm not 100% sure on this, but if I've understood the physics correctly then normalizing this function over the available energies should give me a probability density. As it turn out, this funciton is normalized so that $\int_0^{\varepsilon-\varepsilon_i} q(\varepsilon, \varepsilon_s)d\varepsilon_s = C(\varepsilon)$ so normalizing w.r.t. the entire interval is just a matter of removing the factor $C(\varepsilon)$. However, if I insert $\varepsilon=\varepsilon_{\text{max}}$, that gives me a probability distribution which allows for energies higher than the available energy, and if I don't then I don't know how to generate random numbers from the distribution correctly. 1 I don't think I'm at liberty to relay the entire paper here, unfortunately...","I have a problem (a part of a Monte Carlo simulation) where I'm given the energy of an incoming particle, $\varepsilon$ and want to split this energy in two parts, randomly generating the fraction that goes into each part according to a given function $P(\varepsilon_s) \propto %\frac{1}{\bar E \arctan\left(\frac{\varepsilon}{\bar E}\right)}  \frac{1}{1+\left(\frac{\varepsilon_s}{\bar E}\right)^2}$ $\bar E$ is a known shape parameter. Now, the incoming particle can have energies ranging from 0 to a known maximum, $\varepsilon \in \left[0,\varepsilon_{\text{max}}\right]$, but I do not know the energy until the collision event, when I want to split it up, and therefore I can't figure out how to normalize the distribution function properly. I have a pseudo-random number generator at my disposal which generates uniformly distributed numbers on $[0,1)$. How do I generate random numbers that properly describe how the two collisional products share the available energy? I've tried reading up on methods for this in available books, but they're all a little to theoretical for me to be able to apply them to my scenario. It's been way too long since I took a proper statistics course, and now it seems I need it :) Update : As requested, a more thorough description of $P$ (which will get into detail about the physics of this experiment...) follows here: The physics of this problem is ionization - I have an incoming electron with kinetic energy $\varepsilon$, that collides with a molecule and ionizes it. After the collision event, I have two electrons with energies $\varepsilon_p$ (primary) and $\varepsilon_s$ (secondary), with $\varepsilon_p+\varepsilon_s=\varepsilon-\varepsilon_i$, the latter being the (known) ionization energy. Now, I don't really care which electron is which after the collision, so determining the two energies is simply a problem of dividing $\varepsilon-\varepsilon_i$ into two parts. To do this, I am using the differential cross section of the collision, as suggested by Y. Tzeng and E. E. Kunhardt 1 , which is given by them as $q(\varepsilon, \varepsilon_s) = \frac{C(\varepsilon)}{\bar E \arctan\left((\varepsilon-\varepsilon_i)/\bar E\right)}\cdot \frac{1}{1+\left({\varepsilon_s/\bar E}\right)^2}$ $C(\varepsilon)$ in this epxression is the total collision cross section, which is also known. I'm not 100% sure on this, but if I've understood the physics correctly then normalizing this function over the available energies should give me a probability density. As it turn out, this funciton is normalized so that $\int_0^{\varepsilon-\varepsilon_i} q(\varepsilon, \varepsilon_s)d\varepsilon_s = C(\varepsilon)$ so normalizing w.r.t. the entire interval is just a matter of removing the factor $C(\varepsilon)$. However, if I insert $\varepsilon=\varepsilon_{\text{max}}$, that gives me a probability distribution which allows for energies higher than the available energy, and if I don't then I don't know how to generate random numbers from the distribution correctly. 1 I don't think I'm at liberty to relay the entire paper here, unfortunately...",,"['statistics', 'probability-distributions', 'random']"
36,Cumulative Distribution of X/Y,Cumulative Distribution of X/Y,,"Let X, Y be independent exponential variables with rates $\alpha$, and $\beta$.  Find the c.d.f. of X/Y. So far, I let Z = X/Y. I can then show $f_Z(z) = \int_{-\infty}^{+\infty} |x|f_{X,Y}(x,xz)  \,dx$ (unless my logic is incorrect). Then because X,Y are independent, = $\int_{-\infty}^{+\infty} |x|f_{X}(x)f_Y(xz)  \,dx$. Would I just then insert the c.d.f for the exponential distribution of X, Y? Thanks","Let X, Y be independent exponential variables with rates $\alpha$, and $\beta$.  Find the c.d.f. of X/Y. So far, I let Z = X/Y. I can then show $f_Z(z) = \int_{-\infty}^{+\infty} |x|f_{X,Y}(x,xz)  \,dx$ (unless my logic is incorrect). Then because X,Y are independent, = $\int_{-\infty}^{+\infty} |x|f_{X}(x)f_Y(xz)  \,dx$. Would I just then insert the c.d.f for the exponential distribution of X, Y? Thanks",,"['probability', 'statistics', 'probability-distributions']"
37,What is the probability for a monkey writing Shakespeare? [duplicate],What is the probability for a monkey writing Shakespeare? [duplicate],,"This question already has answers here : Given an infinite number of monkeys and an infinite amount of time, would one of them write Hamlet? (13 answers) Closed 11 years ago . The article clearly describes the idea but does not the state the probability. What is the probability? Can this problem be extended to audio, graphics and video for instance what is the probability that a random outcome is a certain song, a certain photo or a certain movie?","This question already has answers here : Given an infinite number of monkeys and an infinite amount of time, would one of them write Hamlet? (13 answers) Closed 11 years ago . The article clearly describes the idea but does not the state the probability. What is the probability? Can this problem be extended to audio, graphics and video for instance what is the probability that a random outcome is a certain song, a certain photo or a certain movie?",,"['probability', 'statistics']"
38,What is the probability that two samples represent the same normal distribution?,What is the probability that two samples represent the same normal distribution?,,"Yes, it's a basic question.  But, I have searched about 25 web pages for this and found only things that were irrelevant or incomprehensible.  So I have indeed tried. My question is: I have two samples.  I know their sizes, means, and standard devs.  I just need a simple formula or procedure for determining the probability that they represent the same normal distribution.  I know it's out there.  In the distant past, I've used it myself.  But can't remember it now.  Can anyone point me to it?  Thanks.","Yes, it's a basic question.  But, I have searched about 25 web pages for this and found only things that were irrelevant or incomprehensible.  So I have indeed tried. My question is: I have two samples.  I know their sizes, means, and standard devs.  I just need a simple formula or procedure for determining the probability that they represent the same normal distribution.  I know it's out there.  In the distant past, I've used it myself.  But can't remember it now.  Can anyone point me to it?  Thanks.",,"['statistics', 'probability-distributions', 'normal-distribution']"
39,Combinatorics and Probability Problem,Combinatorics and Probability Problem,,"The problem I am working on is: An ATM personal identification number (PIN) consists of four digits, each a 0, 1, 2, . . . 8, or 9, in succession. a.How many different possible PINs are there if there are no restrictions on the choice of digits? b.According to a representative at the author’s local branch of Chase Bank, there are in fact restrictions on the choice of digits. The following choices are prohibited: (i) all four digits identical (ii) sequences of consecutive ascending or descending digits, such as 6543 (iii) any sequence start-ing with 19 (birth years are too easy to guess). So if one of the PINs in (a) is randomly selected, what is the prob-ability that it will be a legitimate PIN (that is, not be one of the prohibited sequences)? c. Someone has stolen an ATM card and knows that the first and last digits of the PIN are 8 and 1, respectively. He has three tries before the card is retained by the ATM (but does not realize that). So he randomly selects the $2nd$ and $3^{rd}$ digits for the first try, then randomly selects a different pair of digits for the second try, and yet another randomly selected pair of digits for the third try (the individual knows about the restrictions described in (b) so selects only from the legitimate possibilities). What is the probability that the individual gains access to the account? d.Recalculate the probability in (c) if the first and last digits are 1 and 1, respectively. --------------------------------------------- For part a): The total number of pins without restrictions is $10,000$ For part b): The number of pins in either ascending or descending order is $10 \cdot 1 \cdot 1 \cdot 1$, because once the first digit is known, then the three other spots containing digits are already spoken for. The number of pins where each slot contains the same digit is $10 \cdot 1 \cdot 1 \cdot 1$, because once the first digit is known there is only one option left to the rest of the slots. The number of pins that have their first and second slot occupied by 1 and 9, respectively, is $1 \cdot 1 \cdot 10 \cdot 10 \cdot$. So, if R is the set that contains these restricted pins, then $|R| = 130$; and if N is the set that contains the non-restricted ones, meaning R and N are complementary sets, then $|N| = 10,000 - 130$. Hence, the probability is then $P(N) = 9780/10000 = 0.9870.$ However, the answer is $0.9876$. What did I do wrong? For part c): The sample space, containing all of the outcomes of the experiment that will take place, is $|N|=9870$. When it says that the thief won't use the same pair of digits in each try, does that not allow him trying the pin 8 5 2 1 in one try and the pin 8 2 5 1 in another try?","The problem I am working on is: An ATM personal identification number (PIN) consists of four digits, each a 0, 1, 2, . . . 8, or 9, in succession. a.How many different possible PINs are there if there are no restrictions on the choice of digits? b.According to a representative at the author’s local branch of Chase Bank, there are in fact restrictions on the choice of digits. The following choices are prohibited: (i) all four digits identical (ii) sequences of consecutive ascending or descending digits, such as 6543 (iii) any sequence start-ing with 19 (birth years are too easy to guess). So if one of the PINs in (a) is randomly selected, what is the prob-ability that it will be a legitimate PIN (that is, not be one of the prohibited sequences)? c. Someone has stolen an ATM card and knows that the first and last digits of the PIN are 8 and 1, respectively. He has three tries before the card is retained by the ATM (but does not realize that). So he randomly selects the $2nd$ and $3^{rd}$ digits for the first try, then randomly selects a different pair of digits for the second try, and yet another randomly selected pair of digits for the third try (the individual knows about the restrictions described in (b) so selects only from the legitimate possibilities). What is the probability that the individual gains access to the account? d.Recalculate the probability in (c) if the first and last digits are 1 and 1, respectively. --------------------------------------------- For part a): The total number of pins without restrictions is $10,000$ For part b): The number of pins in either ascending or descending order is $10 \cdot 1 \cdot 1 \cdot 1$, because once the first digit is known, then the three other spots containing digits are already spoken for. The number of pins where each slot contains the same digit is $10 \cdot 1 \cdot 1 \cdot 1$, because once the first digit is known there is only one option left to the rest of the slots. The number of pins that have their first and second slot occupied by 1 and 9, respectively, is $1 \cdot 1 \cdot 10 \cdot 10 \cdot$. So, if R is the set that contains these restricted pins, then $|R| = 130$; and if N is the set that contains the non-restricted ones, meaning R and N are complementary sets, then $|N| = 10,000 - 130$. Hence, the probability is then $P(N) = 9780/10000 = 0.9870.$ However, the answer is $0.9876$. What did I do wrong? For part c): The sample space, containing all of the outcomes of the experiment that will take place, is $|N|=9870$. When it says that the thief won't use the same pair of digits in each try, does that not allow him trying the pin 8 5 2 1 in one try and the pin 8 2 5 1 in another try?",,"['probability', 'combinatorics', 'statistics', 'permutations']"
40,A question about Poisson and Binomial distributions,A question about Poisson and Binomial distributions,,"I'm struggling with understanding why the following statement is true: Let $X$ be a Random Variable with Poisson distribution.  Let $Z$ be a Random Variable independent from $X$, whose distribution is $P(Z=0.9)=0.2=1-P(Z=0.6)$.  Let $Y$ be a Random Variable such that $Y |( X=x , Z=z)\sim \text{Binom}(x,z)$. Then given $Z=0.9, Y\sim \text{Poisson}$. I'm told that it is a consequence of some general fact about split Poisson variables but I couldn't make much of that fact, or wasn't able to see why it's true by myself. I don't really know how to go about this so any help would be greatly appreciated. Thanks!","I'm struggling with understanding why the following statement is true: Let $X$ be a Random Variable with Poisson distribution.  Let $Z$ be a Random Variable independent from $X$, whose distribution is $P(Z=0.9)=0.2=1-P(Z=0.6)$.  Let $Y$ be a Random Variable such that $Y |( X=x , Z=z)\sim \text{Binom}(x,z)$. Then given $Z=0.9, Y\sim \text{Poisson}$. I'm told that it is a consequence of some general fact about split Poisson variables but I couldn't make much of that fact, or wasn't able to see why it's true by myself. I don't really know how to go about this so any help would be greatly appreciated. Thanks!",,"['probability', 'statistics', 'probability-distributions']"
41,Showing that Poisson sums to 1,Showing that Poisson sums to 1,,"The PDF of a Poisson distribution is $P(X=k)=\frac{\lambda^k}{k!}e^\lambda$. As a PDF, it should sum to one; i.e. $\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}e^\lambda=1$. I'm having trouble proving this though. From the Taylor series for $e$, I can see that $\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}<\sum_{k=0}^{\infty}\frac{1}{k!}=e$ so it must be less than $e^{\lambda+1}$, but that's the tightest bound I've been able to get. Any help?","The PDF of a Poisson distribution is $P(X=k)=\frac{\lambda^k}{k!}e^\lambda$. As a PDF, it should sum to one; i.e. $\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}e^\lambda=1$. I'm having trouble proving this though. From the Taylor series for $e$, I can see that $\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}<\sum_{k=0}^{\infty}\frac{1}{k!}=e$ so it must be less than $e^{\lambda+1}$, but that's the tightest bound I've been able to get. Any help?",,"['sequences-and-series', 'statistics']"
42,"What is a good algorithm to randomly determine the move order of a set of players given their ""speed"" values?","What is a good algorithm to randomly determine the move order of a set of players given their ""speed"" values?",,"The context of this is that I am creating a turn-based RPG engine, and each of a set of players has a ""speed"", which determines the probability of moving earlier in a turn depending on how high it is. The higher the speed, the earlier in the turn the player is expected to move. I would like to devise an algorithm to determine a random probabilistic turn order based off of these speed values. The algorithm should have the following properties: It is commutative. That is, no matter which player is used as the base for calculations, the algorithm will return the same probability of each turn order occurring. It is consistent. The probabilities always add up to 1. It handles equality well. When all the players have the same speed, they should have an equal probability of moving first, second, etc. When two players have equal speed, but dominate over the rest, they will have an equal probability between themselves and everybody else will have a lesser amount. It is scalable. The same formula should work no matter how many players (even the degenerate case of one) there are. It is smooth. That is, it does not suddenly snap from one case to another. If we make the fastest player always move first, the probability of a player moving first snaps from 0 to 1 on the basis of a single point difference, which is bad. It preserves priority. That is, if the faster player does not move first, it should have a high probability of moving second, and if it doesn't, then it should have an even higher probability of moving third, etc. And a few properties that are less important: It is adjustable. Depending on how steep the user wants the increase in probability to be, there should be a parameter in the algorithm to account for it, without requiring a complete redesign of the algorithm. It handles edge cases well. If we let $s$ be a variable representing the speed of one of the players and $p(s)$ represent the probability that that player moves first, then $\displaystyle \lim_{s \rightarrow \infty} p(s) = 1$.","The context of this is that I am creating a turn-based RPG engine, and each of a set of players has a ""speed"", which determines the probability of moving earlier in a turn depending on how high it is. The higher the speed, the earlier in the turn the player is expected to move. I would like to devise an algorithm to determine a random probabilistic turn order based off of these speed values. The algorithm should have the following properties: It is commutative. That is, no matter which player is used as the base for calculations, the algorithm will return the same probability of each turn order occurring. It is consistent. The probabilities always add up to 1. It handles equality well. When all the players have the same speed, they should have an equal probability of moving first, second, etc. When two players have equal speed, but dominate over the rest, they will have an equal probability between themselves and everybody else will have a lesser amount. It is scalable. The same formula should work no matter how many players (even the degenerate case of one) there are. It is smooth. That is, it does not suddenly snap from one case to another. If we make the fastest player always move first, the probability of a player moving first snaps from 0 to 1 on the basis of a single point difference, which is bad. It preserves priority. That is, if the faster player does not move first, it should have a high probability of moving second, and if it doesn't, then it should have an even higher probability of moving third, etc. And a few properties that are less important: It is adjustable. Depending on how steep the user wants the increase in probability to be, there should be a parameter in the algorithm to account for it, without requiring a complete redesign of the algorithm. It handles edge cases well. If we let $s$ be a variable representing the speed of one of the players and $p(s)$ represent the probability that that player moves first, then $\displaystyle \lim_{s \rightarrow \infty} p(s) = 1$.",,"['probability', 'statistics']"
43,Probability that the sum of all values of 5 pairs of dice will be between 30 and 40,Probability that the sum of all values of 5 pairs of dice will be between 30 and 40,,"I'm trying to solve a question that asks: If 5 pairs of fair dice are rolled, approximate the probability that the sum    of the values obtained is between 30 and 40 inclusive. My approach so far, was to create a random variable called $T$ whose range is from $10$ to $60$ and look for  $$P\{|T-35| \le 5\} $$ I don't know what to do next. Can I proceed like this is a normal distribution or is five too small a sample to qualify for the Central Limit Theorem?","I'm trying to solve a question that asks: If 5 pairs of fair dice are rolled, approximate the probability that the sum    of the values obtained is between 30 and 40 inclusive. My approach so far, was to create a random variable called $T$ whose range is from $10$ to $60$ and look for  $$P\{|T-35| \le 5\} $$ I don't know what to do next. Can I proceed like this is a normal distribution or is five too small a sample to qualify for the Central Limit Theorem?",,"['statistics', 'normal-distribution', 'dice']"
44,Casio fx 991ms Factorial,Casio fx 991ms Factorial,,"I apologize if this is the wrong forum for this, but I can't find the answer through google. I'm wondering how to find factorials on my casio f-991MS calculator. Any help is much appreciated.","I apologize if this is the wrong forum for this, but I can't find the answer through google. I'm wondering how to find factorials on my casio f-991MS calculator. Any help is much appreciated.",,"['statistics', 'factorial']"
45,"Given that $X$ is normal, find the probability that $(X-10)^2 <12$","Given that  is normal, find the probability that",X (X-10)^2 <12,Suppose that $X$ is a random variable that has a normal distribution with mean = 5 and standard deviation = 10. Evaluate the following probabilities: $\mathrm{Prob}((X-10)^2 < 12)$,Suppose that $X$ is a random variable that has a normal distribution with mean = 5 and standard deviation = 10. Evaluate the following probabilities: $\mathrm{Prob}((X-10)^2 < 12)$,,"['probability', 'statistics', 'normal-distribution']"
46,non-intuitive results in random sampling,non-intuitive results in random sampling,,"I play a card game (Magic The Gathering) that involves creating a deck of cards that can loosely be split into two categories: land and spells. You are permitted to play only one land per turn, and the land are used to cast your spells. Due to the one-per-turn limitation, it is advantageous to have access to exactly X land on turn X (otherwise your hand  is wasted on land you can't play.) For purposes of my current experiment, I consider myself to be in a good position if on turn X, I have access to (that is, have either drawn or played) either X, X+1, or X+2 land. Having access to X-1 land means I'm not playing spells of cost X on turn X, while my opponent is, so I'm probably at a disadvantage. Having X+3 or more land on turn X means I don't have a good choice of spells to play. I desire the happy medium, with the potential buffer of 2 extras. You start the game with 7 cards, and draw an additional card every turn. There are other effects that can cause you to draw more, discard more, play additional lands, or play more powerful lands, but these are edge cases that are not included in this experiment. In order to gather data, I wrote a small java application that enables me to simulate drawing cards from my deck. The experiment consists of a 40 card deck with either 16 or 17 land. (A good rule of thumb is 40% land.) For simulation purposes, I do monte-carlo of 1 million hand draws. Here are the results for having 16 land. This table reads ""On turn 4, I have access to 5 land 21.9% of the time."" The ""good"" column is the sum of X, X+1, and X+2 for any given turn. 16 Land   Turn                      Lands     1      2      3      4      5      6      7      8 0        1.9%   0.9%   0.5%   0.2%   0.1%   0.0%   0.0%   0.0% 1       11.5%   7.2%   4.3%   2.5%   1.4%   0.7%   0.4%   0.2% 2       27.4%  21.0%  15.2%  10.5%   6.7%   4.2%   2.5%   1.4% 3       31.9%  31.0%  27.6%  22.9%  17.8%  13.1%   9.2%   6.0% 4       19.7%  25.2%  28.3%  28.9%  27.3%  24.0%  19.8%  15.4% 5        6.4%  11.5%  17.0%  21.9%  25.4%  27.1%  26.7%  24.6% 6        1.0%   2.9%   5.9%  10.0%  14.7%  19.3%  23.0%  25.4% 7        0.1%   0.4%   1.2%   2.7%   5.3%   8.7%  12.8%  17.0% 8                      0.1%   0.4%   1.1%   2.4%   4.6%   7.4% 9                                    0.1%   0.4%   1.0%   2.1% 10                                                 0.1%   0.4%  Good:   71%    77%    73%    61%    45.4%  30.4%  18.4%   9.9% In the same manner, here is the result for 17 land. Lands   1      2      3      4      5      6      7      8 0      1.3%   0.6%   0.3%   0.1%   0.1%   0.4%   0.0%   0.0% 1      9.2%   5.4%   3.0%   1.6%   0.8%   2.8%   0.2%   0.1% 2     24.6%  17.8%  12.2%   7.9%   4.8%   9.9%   1.5%   0.8% 3     32.3%  29.8%  25.1%  19.7%  14.4%  20.8%   6.4%   4.0% 4     22.5%  27.4%  29.4%  28.3%  25.2%  27.2%  16.2%  11.7% 5      8.4%  14.3%  20.0%  24.5%  27.1%  22.4%  25.3%  21.8% 6      1.5%   4.1%   8.0%  12.9%  18.0%  11.7%  25.2%  26.2% 7      0.1%   0.6%   1.8%   4.1%   7.5%   3.9%  16.3%  20.6% 8                    0.2%   0.7%   1.9%   0.8%   6.8%  10.6% 9                           0.1%   0.3%   0.1%   1.8%   3.5% 10                                               0.3%   0.7% 11                                                      0.1% Good: 66.1%  75.0%  74.5%  65.7%  52.6%  16.4%  24.9%  14.8% Okay, now that's a lot of data. I've included it for your review. Here's what I don't get - let's take a look at the ""good"" results for 16 versus 17, paying very close attention to turn 6 for 17 land. Turn 1  Turn 2  Turn 3  Turn 4  Turn 5  Turn 6  Turn 7  Turn 8 16 Land  70.8%   77.2%   72.9%   60.8%   45.4%   30.4%   18.4%    9.9% 17 Land  66.1%   75.0%   74.5%   65.7%   52.6%   16.4%   24.9%   14.8% It would appear that on turn 7, my liklihood of having 7,8, or 9 land is higher (substantially) than having 6,7, or 8 land on turn 6. How is that value so low on turn 6? I've summed up all the columns, and they of course add up to 100% (barring a couple rounding errors). I've re-ran the simulation multiple times and it consistently comes up with the same value. Here are the questions that I feel will help me solve this mystery: What could possibly cause the ""good curve"" for 17-land to dip so much on turn 6? How could it be more likely that a 16 land deck could have a higher chance of having the same amount of land access than a 17 land deck after the same number of draws? Are there formulas that allow me to calculate the ""land-likelihood"" that might shed insight into this anomaly?","I play a card game (Magic The Gathering) that involves creating a deck of cards that can loosely be split into two categories: land and spells. You are permitted to play only one land per turn, and the land are used to cast your spells. Due to the one-per-turn limitation, it is advantageous to have access to exactly X land on turn X (otherwise your hand  is wasted on land you can't play.) For purposes of my current experiment, I consider myself to be in a good position if on turn X, I have access to (that is, have either drawn or played) either X, X+1, or X+2 land. Having access to X-1 land means I'm not playing spells of cost X on turn X, while my opponent is, so I'm probably at a disadvantage. Having X+3 or more land on turn X means I don't have a good choice of spells to play. I desire the happy medium, with the potential buffer of 2 extras. You start the game with 7 cards, and draw an additional card every turn. There are other effects that can cause you to draw more, discard more, play additional lands, or play more powerful lands, but these are edge cases that are not included in this experiment. In order to gather data, I wrote a small java application that enables me to simulate drawing cards from my deck. The experiment consists of a 40 card deck with either 16 or 17 land. (A good rule of thumb is 40% land.) For simulation purposes, I do monte-carlo of 1 million hand draws. Here are the results for having 16 land. This table reads ""On turn 4, I have access to 5 land 21.9% of the time."" The ""good"" column is the sum of X, X+1, and X+2 for any given turn. 16 Land   Turn                      Lands     1      2      3      4      5      6      7      8 0        1.9%   0.9%   0.5%   0.2%   0.1%   0.0%   0.0%   0.0% 1       11.5%   7.2%   4.3%   2.5%   1.4%   0.7%   0.4%   0.2% 2       27.4%  21.0%  15.2%  10.5%   6.7%   4.2%   2.5%   1.4% 3       31.9%  31.0%  27.6%  22.9%  17.8%  13.1%   9.2%   6.0% 4       19.7%  25.2%  28.3%  28.9%  27.3%  24.0%  19.8%  15.4% 5        6.4%  11.5%  17.0%  21.9%  25.4%  27.1%  26.7%  24.6% 6        1.0%   2.9%   5.9%  10.0%  14.7%  19.3%  23.0%  25.4% 7        0.1%   0.4%   1.2%   2.7%   5.3%   8.7%  12.8%  17.0% 8                      0.1%   0.4%   1.1%   2.4%   4.6%   7.4% 9                                    0.1%   0.4%   1.0%   2.1% 10                                                 0.1%   0.4%  Good:   71%    77%    73%    61%    45.4%  30.4%  18.4%   9.9% In the same manner, here is the result for 17 land. Lands   1      2      3      4      5      6      7      8 0      1.3%   0.6%   0.3%   0.1%   0.1%   0.4%   0.0%   0.0% 1      9.2%   5.4%   3.0%   1.6%   0.8%   2.8%   0.2%   0.1% 2     24.6%  17.8%  12.2%   7.9%   4.8%   9.9%   1.5%   0.8% 3     32.3%  29.8%  25.1%  19.7%  14.4%  20.8%   6.4%   4.0% 4     22.5%  27.4%  29.4%  28.3%  25.2%  27.2%  16.2%  11.7% 5      8.4%  14.3%  20.0%  24.5%  27.1%  22.4%  25.3%  21.8% 6      1.5%   4.1%   8.0%  12.9%  18.0%  11.7%  25.2%  26.2% 7      0.1%   0.6%   1.8%   4.1%   7.5%   3.9%  16.3%  20.6% 8                    0.2%   0.7%   1.9%   0.8%   6.8%  10.6% 9                           0.1%   0.3%   0.1%   1.8%   3.5% 10                                               0.3%   0.7% 11                                                      0.1% Good: 66.1%  75.0%  74.5%  65.7%  52.6%  16.4%  24.9%  14.8% Okay, now that's a lot of data. I've included it for your review. Here's what I don't get - let's take a look at the ""good"" results for 16 versus 17, paying very close attention to turn 6 for 17 land. Turn 1  Turn 2  Turn 3  Turn 4  Turn 5  Turn 6  Turn 7  Turn 8 16 Land  70.8%   77.2%   72.9%   60.8%   45.4%   30.4%   18.4%    9.9% 17 Land  66.1%   75.0%   74.5%   65.7%   52.6%   16.4%   24.9%   14.8% It would appear that on turn 7, my liklihood of having 7,8, or 9 land is higher (substantially) than having 6,7, or 8 land on turn 6. How is that value so low on turn 6? I've summed up all the columns, and they of course add up to 100% (barring a couple rounding errors). I've re-ran the simulation multiple times and it consistently comes up with the same value. Here are the questions that I feel will help me solve this mystery: What could possibly cause the ""good curve"" for 17-land to dip so much on turn 6? How could it be more likely that a 16 land deck could have a higher chance of having the same amount of land access than a 17 land deck after the same number of draws? Are there formulas that allow me to calculate the ""land-likelihood"" that might shed insight into this anomaly?",,"['statistics', 'monte-carlo', 'card-games']"
47,Log likehood functions - Expected value,Log likehood functions - Expected value,,"Let $X_1,X_2,\ldots,X_n$ be a random sample from a Bernoulli($θ$) distribution with probility function $$P(X=x)= (θ^x)(1-θ)^{1-x},\qquad x=0,1;\ 0 < θ < 1.$$ $dl/dθ = [n \overline{x}/θ] \cdot (n-n\overline{x})/(1-θ)$ <-- Is it this that's wrong? :/ Got help with this too (Perhaps you can tell stats isn't my best subject) Show that $E[(dl(θ)/dθ)] = 0$ Apologies, exam in a couple of days in a mad scattered panic! When I first did this I integrated by accident, then I diffentiated and got a very strange answer and wasn't sure how to bring it to zero.","Let $X_1,X_2,\ldots,X_n$ be a random sample from a Bernoulli($θ$) distribution with probility function $$P(X=x)= (θ^x)(1-θ)^{1-x},\qquad x=0,1;\ 0 < θ < 1.$$ $dl/dθ = [n \overline{x}/θ] \cdot (n-n\overline{x})/(1-θ)$ <-- Is it this that's wrong? :/ Got help with this too (Perhaps you can tell stats isn't my best subject) Show that $E[(dl(θ)/dθ)] = 0$ Apologies, exam in a couple of days in a mad scattered panic! When I first did this I integrated by accident, then I diffentiated and got a very strange answer and wasn't sure how to bring it to zero.",,['statistics']
48,Differentiating the posterior distribution function,Differentiating the posterior distribution function,,"I am learning about Bayesian statistics and I'm currently doing loss functions. Let $f(\theta | \mathbf{x} ) $ be a posterior pdf . Let $F(\theta | \mathbf{x} ) $ be the associated distribution function. I want to differentiate $F(a - D| \mathbf{x} )$ with respect to $D$. In this case $D$ is the ""decision"" which is to be optimised and $a$ is constant. I am having a problem here: $$\frac{d}{d D}F(a - D| \mathbf{x} ) = \frac{d}{d D} \left( \int_{-\infty}^{a - D} f(\theta|\mathbf{x}) d \theta \right)$$ $$=f(a - D | \mathbf{x})$$ Is this correct ? I think it might be wrong. Should it be $=-f(a - D | \mathbf{x})$ because I have to apply the chain rule somewhere ?? Or is something else wrong ? I know there are some issues about integration under differentiation but my teacher said I don't need to worry about that now, and just use this: $$\frac{d}{dy} \int_{-\infty}^y f(t) dt=f(y)$$ I'm doing self-study (with a bit of teacher guidance in his own time so I don't like to ask him too much) but I feel a bit out of depth now and school breaks up for the holidays next week !","I am learning about Bayesian statistics and I'm currently doing loss functions. Let $f(\theta | \mathbf{x} ) $ be a posterior pdf . Let $F(\theta | \mathbf{x} ) $ be the associated distribution function. I want to differentiate $F(a - D| \mathbf{x} )$ with respect to $D$. In this case $D$ is the ""decision"" which is to be optimised and $a$ is constant. I am having a problem here: $$\frac{d}{d D}F(a - D| \mathbf{x} ) = \frac{d}{d D} \left( \int_{-\infty}^{a - D} f(\theta|\mathbf{x}) d \theta \right)$$ $$=f(a - D | \mathbf{x})$$ Is this correct ? I think it might be wrong. Should it be $=-f(a - D | \mathbf{x})$ because I have to apply the chain rule somewhere ?? Or is something else wrong ? I know there are some issues about integration under differentiation but my teacher said I don't need to worry about that now, and just use this: $$\frac{d}{dy} \int_{-\infty}^y f(t) dt=f(y)$$ I'm doing self-study (with a bit of teacher guidance in his own time so I don't like to ask him too much) but I feel a bit out of depth now and school breaks up for the holidays next week !",,"['statistics', 'derivatives', 'bayesian']"
49,approximation hypergeometric distribution with binomial,approximation hypergeometric distribution with binomial,,"Let $X$ be $\rm{Hypergeometric}(2n,\ell,n)$ and $E(X)=\frac{1}{2} \ell=:\mu$.  Is it possible and how to approximate the $q$-th central moment $E(X-\mu)^q$ of the hypergeometric distribution by the moments of binomial distribution? Thank you.","Let $X$ be $\rm{Hypergeometric}(2n,\ell,n)$ and $E(X)=\frac{1}{2} \ell=:\mu$.  Is it possible and how to approximate the $q$-th central moment $E(X-\mu)^q$ of the hypergeometric distribution by the moments of binomial distribution? Thank you.",,"['probability', 'statistics', 'probability-distributions', 'approximation']"
50,Compute the probability that $ | \bar{X} - \mu | > S$,Compute the probability that, | \bar{X} - \mu | > S,"Given $X_1, \ldots, X_n$ from $\mathcal{N} (\mu, \sigma^2)$. I have to compute the probability: $$P\left(|\bar{X} - \mu| > S\right)$$ where $\bar{X}$ is the sample mean and $S^2$ is the sample variance. I tried to expand: $$P\left(\bar{X}^2 + \mu^2 - \bar{X}\mu > \frac{1}{n}\sum {X_i}^2 + \frac{1}{n}\sum\bar{X} - 2\left(\frac{1}{n}\sum X_i\right) \bar{X} \right) $$ $$P\left( \mu^2 - \bar{X}\mu > \frac{1}{n}\sum {X_i}^2  - 2\bar{X}^2 \right) $$ but it does not seems to be helpful. Can someone help me?","Given $X_1, \ldots, X_n$ from $\mathcal{N} (\mu, \sigma^2)$. I have to compute the probability: $$P\left(|\bar{X} - \mu| > S\right)$$ where $\bar{X}$ is the sample mean and $S^2$ is the sample variance. I tried to expand: $$P\left(\bar{X}^2 + \mu^2 - \bar{X}\mu > \frac{1}{n}\sum {X_i}^2 + \frac{1}{n}\sum\bar{X} - 2\left(\frac{1}{n}\sum X_i\right) \bar{X} \right) $$ $$P\left( \mu^2 - \bar{X}\mu > \frac{1}{n}\sum {X_i}^2  - 2\bar{X}^2 \right) $$ but it does not seems to be helpful. Can someone help me?",,['statistics']
51,How to find the number of unique sets of 7 letters?,How to find the number of unique sets of 7 letters?,,"The order of the letters does not matter, so: ABALNKM is the same as ALMKNBA bonus points How would I determine the number of sets where any letter can only be repeated a maximum of 4 times?","The order of the letters does not matter, so: ABALNKM is the same as ALMKNBA bonus points How would I determine the number of sets where any letter can only be repeated a maximum of 4 times?",,"['combinatorics', 'statistics']"
52,Overlapping Events,Overlapping Events,,I have an event that will start exactly X times within a single 24 hour period. Each event lasts Y milliseconds. The start time of an individual event is uniform randomly distributed throughout the 24 hour period.  The start time of each event is independent of the others. What is the probability that at any point during the 24 hour period Z (or more) events are currently occurring and overlapping each other?,I have an event that will start exactly X times within a single 24 hour period. Each event lasts Y milliseconds. The start time of an individual event is uniform randomly distributed throughout the 24 hour period.  The start time of each event is independent of the others. What is the probability that at any point during the 24 hour period Z (or more) events are currently occurring and overlapping each other?,,"['probability', 'statistics']"
53,How close are these events?,How close are these events?,,"I'm a computer programmer and we're running into a weird error on our website. We have a large number users who do a certain task.  Between the entire set of users, this task happens about once every 20 seconds, but of course each user is unique. We're seeing a strange problem about once every four hours that may be caused by users doing the task at the exact same time as another. I tried to find this answer on my own, and got as far as the Poisson distribution, but I haven't dealt with statistics beyond basic Poker strategy since my stats class in college 15 years ago.  So, my question: Given a large number of independent events that happen every 20 seconds, what is the exact level of unusual closeness that I would expect to see every four hours?","I'm a computer programmer and we're running into a weird error on our website. We have a large number users who do a certain task.  Between the entire set of users, this task happens about once every 20 seconds, but of course each user is unique. We're seeing a strange problem about once every four hours that may be caused by users doing the task at the exact same time as another. I tried to find this answer on my own, and got as far as the Poisson distribution, but I haven't dealt with statistics beyond basic Poker strategy since my stats class in college 15 years ago.  So, my question: Given a large number of independent events that happen every 20 seconds, what is the exact level of unusual closeness that I would expect to see every four hours?",,['statistics']
54,Chance of selecting a duplicate?,Chance of selecting a duplicate?,,"When you select things at random repeatedly (with replacement or whatever) out of a field of N possible things, how do you calculate the probability that something has been chosen X times after Y choices were made? For example, if there are 64 DotA 2 heroes and I choose a random one 9 times, what's the chance that I get Skeleton King 5 of those times?","When you select things at random repeatedly (with replacement or whatever) out of a field of N possible things, how do you calculate the probability that something has been chosen X times after Y choices were made? For example, if there are 64 DotA 2 heroes and I choose a random one 9 times, what's the chance that I get Skeleton King 5 of those times?",,"['probability', 'statistics']"
55,Is hypothesis testing at $\alpha=0$ possible?,Is hypothesis testing at  possible?,\alpha=0,"A while back I've asked a question on the relationship of the total variation distance between probability measures to hypothesis testing and got a very nice answer.  I understand that that answer gives a trade-off relationship between the probability of type I error (false positive) $\alpha$ and a type II error (miss) $\beta$, similar to what Neyman-Pearson lemma provides. Within the Neyman-Pearson framework, one can set $\alpha$ arbitrarily close to 0 at the expense of the power of the statistical test $1-\beta$, however, as far as I understand, one can not set $\alpha=0$. I am wondering if there are non-trivial hypothesis tests out there allow one to set $\alpha=0$.  I haven't encountered one in my reading.  My intuition tells me that there aren't because 1) a hypothesis test must be a threshold-based test; and 2) as long as the probability distributions associated with the hypotheses are different, any non-trivial threshold test (i.e. a test that doesn't always accept the null hypothesis) has some finite chance of falsely rejecting the null hypothesis. However, I thought I'd ask the experts here whether my intuition, and the reasoning behind this intuition, is correct.  Perhaps there are statistical hypothesis tests not based on thresholds out there...","A while back I've asked a question on the relationship of the total variation distance between probability measures to hypothesis testing and got a very nice answer.  I understand that that answer gives a trade-off relationship between the probability of type I error (false positive) $\alpha$ and a type II error (miss) $\beta$, similar to what Neyman-Pearson lemma provides. Within the Neyman-Pearson framework, one can set $\alpha$ arbitrarily close to 0 at the expense of the power of the statistical test $1-\beta$, however, as far as I understand, one can not set $\alpha=0$. I am wondering if there are non-trivial hypothesis tests out there allow one to set $\alpha=0$.  I haven't encountered one in my reading.  My intuition tells me that there aren't because 1) a hypothesis test must be a threshold-based test; and 2) as long as the probability distributions associated with the hypotheses are different, any non-trivial threshold test (i.e. a test that doesn't always accept the null hypothesis) has some finite chance of falsely rejecting the null hypothesis. However, I thought I'd ask the experts here whether my intuition, and the reasoning behind this intuition, is correct.  Perhaps there are statistical hypothesis tests not based on thresholds out there...",,"['statistics', 'statistical-inference', 'hypothesis-testing']"
56,"Expected value and Variance of $Y=\frac{1}{a} X-b$ where $X \sim N(\mu, \sigma^2)$",Expected value and Variance of  where,"Y=\frac{1}{a} X-b X \sim N(\mu, \sigma^2)","I absolutely know I am not doing this right. :[ Could I get some input or point back in the right direction? My work done so far is shown below. Let $X$ be a normal random variable with parameters $N(\mu, \sigma^2)$. Please find the Expected value and Variance of random variable $Y=\frac{1}{a} X-b$, where $a$ and $b$ are constant values. My work. $$ \begin{align*} E(Y) &= aE(x)-b = \sum_x \Big(\frac{1}{a} x - b \Big) p_x(x) = \frac{1}{a} \sum_x x p_x(x) - b  \\ &=  \frac{1}{a} \sum_x x p_x(x) - b \sum_x p_x(x) = a E(x) - b \cdot 1. \end{align*} $$ If $a = 0$, then $E(x-b) = E(x)$ and if $b = 0$, then $E(ax)= \frac{1}{a}E(x)$. $$ \begin{align*} \mu &= E(X) = \int_{-\infty}^{\infty} x f(x) dx = \int_{0}^{1} x \Big(\frac{1}{a} X - b \Big) dx = \frac{1}{a} \int_0^1 X^2 - xb ~dx  \\ & = \frac{1}{a} \Big( \frac{x^3}{3} - \frac{bx^2}{2} \Big) \text{ from } 1 \text{ to } 0  \\ & = \frac{1}{a} \Big( \frac{1}{3} - \frac{b}{2} \Big) . \end{align*} $$ $$ \text{RV } Y = (X - E(x)^2). $$ $$ \sigma^2 = \operatorname{Var}(x) = E[(x) - E[x])^2] $$ $$ \operatorname{Var} \Big( \frac{1}{a} X - b \Big) = a^2 \operatorname{Var}(x). $$ $$ \int_{\Box}^{\Box}\Big( \frac{1}{a} X - b \Big) - \Big( \frac{1}{a} X - b \Big)^2 \ldots $$","I absolutely know I am not doing this right. :[ Could I get some input or point back in the right direction? My work done so far is shown below. Let $X$ be a normal random variable with parameters $N(\mu, \sigma^2)$. Please find the Expected value and Variance of random variable $Y=\frac{1}{a} X-b$, where $a$ and $b$ are constant values. My work. $$ \begin{align*} E(Y) &= aE(x)-b = \sum_x \Big(\frac{1}{a} x - b \Big) p_x(x) = \frac{1}{a} \sum_x x p_x(x) - b  \\ &=  \frac{1}{a} \sum_x x p_x(x) - b \sum_x p_x(x) = a E(x) - b \cdot 1. \end{align*} $$ If $a = 0$, then $E(x-b) = E(x)$ and if $b = 0$, then $E(ax)= \frac{1}{a}E(x)$. $$ \begin{align*} \mu &= E(X) = \int_{-\infty}^{\infty} x f(x) dx = \int_{0}^{1} x \Big(\frac{1}{a} X - b \Big) dx = \frac{1}{a} \int_0^1 X^2 - xb ~dx  \\ & = \frac{1}{a} \Big( \frac{x^3}{3} - \frac{bx^2}{2} \Big) \text{ from } 1 \text{ to } 0  \\ & = \frac{1}{a} \Big( \frac{1}{3} - \frac{b}{2} \Big) . \end{align*} $$ $$ \text{RV } Y = (X - E(x)^2). $$ $$ \sigma^2 = \operatorname{Var}(x) = E[(x) - E[x])^2] $$ $$ \operatorname{Var} \Big( \frac{1}{a} X - b \Big) = a^2 \operatorname{Var}(x). $$ $$ \int_{\Box}^{\Box}\Big( \frac{1}{a} X - b \Big) - \Big( \frac{1}{a} X - b \Big)^2 \ldots $$",,"['probability', 'statistics']"
57,Cochran's Theorem - Lemma involving symmetric idempotent matrices,Cochran's Theorem - Lemma involving symmetric idempotent matrices,,"I am writing notes for a reading class and I've decided to add a proof of Cochran's theorem in order to show that a statistic is $\chi^2$. I am struggling for the proof of a particular lemma but the rest is just peachy. Lemma: Let $A$ be a real real symmetric idempotent matrix of order $n$ with rank $r$. Suppose $A=A_1+\cdots+A_k$ with rank $A_i = r_i$ and $A_i$ symmetric. Additionally, $r_1+\cdots+r_k=r$. Then each $A_i$ is idempotent. I've been really struggling with this. It seems fairly obvious that $A_i$ gives an orthogonal decomposition of $A$. I've tried a lot of methods, looking at $A$'s and $A_i'$s spectral decomposition so I can show that the eigenvalues of $A_i$ must be $1$. Tried showing that $A_iA_j =0$ for $i$ not equal to $j$.","I am writing notes for a reading class and I've decided to add a proof of Cochran's theorem in order to show that a statistic is $\chi^2$. I am struggling for the proof of a particular lemma but the rest is just peachy. Lemma: Let $A$ be a real real symmetric idempotent matrix of order $n$ with rank $r$. Suppose $A=A_1+\cdots+A_k$ with rank $A_i = r_i$ and $A_i$ symmetric. Additionally, $r_1+\cdots+r_k=r$. Then each $A_i$ is idempotent. I've been really struggling with this. It seems fairly obvious that $A_i$ gives an orthogonal decomposition of $A$. I've tried a lot of methods, looking at $A$'s and $A_i'$s spectral decomposition so I can show that the eigenvalues of $A_i$ must be $1$. Tried showing that $A_iA_j =0$ for $i$ not equal to $j$.",,"['linear-algebra', 'statistics', 'probability-distributions']"
58,biased Maximum Likelihood estimation,biased Maximum Likelihood estimation,,"Given $N$ points ($x_k$, k from $1$ to $N$) generated from a normal distribution (1-dimensional case) with known mean $\mu$, the Maximum Likelihood estimation of the variance is $\frac{1}{N}\sum_{k=1}^{\infty} (x_k-\mu)^2$. How is it justified that this estimation is biased for finite N? thanks, Nikos","Given $N$ points ($x_k$, k from $1$ to $N$) generated from a normal distribution (1-dimensional case) with known mean $\mu$, the Maximum Likelihood estimation of the variance is $\frac{1}{N}\sum_{k=1}^{\infty} (x_k-\mu)^2$. How is it justified that this estimation is biased for finite N? thanks, Nikos",,"['probability', 'statistics', 'parameter-estimation']"
59,How to prove something is a sufficient statistic?,How to prove something is a sufficient statistic?,,"If you have $n$ random variables that are iid with density $\frac{1}{p}e^{-x/p}$, how do you show that the sum of the $x_i$'s is a sufficient statistic? Attempt: Take likelihood function and express in terms of $g(p)h(x)$ and use factorization theorem to show that it is a sufficient statistic. So likelihood = $\frac{1}{p^n} \exp(\sum \frac{-x_i}{p}) = \frac{1}{p^n} \exp(\frac{1}{p}  \sum (-x_i))$.","If you have $n$ random variables that are iid with density $\frac{1}{p}e^{-x/p}$, how do you show that the sum of the $x_i$'s is a sufficient statistic? Attempt: Take likelihood function and express in terms of $g(p)h(x)$ and use factorization theorem to show that it is a sufficient statistic. So likelihood = $\frac{1}{p^n} \exp(\sum \frac{-x_i}{p}) = \frac{1}{p^n} \exp(\frac{1}{p}  \sum (-x_i))$.",,['statistics']
60,What is the correct way to plot histogram?,What is the correct way to plot histogram?,,"When we plot the frequency histogram, the frequency is equal to the area of the bar or the height of the bar? Is $\text{height} = \frac{\text{frequency}}{\text{size of the class}}$ ? If so, then how to label the vertical axis? For example, based on the following data, Class   Frequency [0,9)      10 [10,19)    20 [20,39)    40 Then what is the label for vertical axis? Is it ""frequency"" or ""frequency density""? The height of first class is 10 or 1.0? For the 3rd class, is it 20, 2.0, or 40? Possible solution (or answer) Based on the information I studied from several links, when the width of the class is different, one needs to use ""Frequency density"" for the vertical axis. Then, $\text{frequency} = \text{height} \times \text{width of the class}$ If the class are in the same width, then one can use ""Frequency"" for the vertical axis, then all the heights of the bars are point to the value directly.","When we plot the frequency histogram, the frequency is equal to the area of the bar or the height of the bar? Is $\text{height} = \frac{\text{frequency}}{\text{size of the class}}$ ? If so, then how to label the vertical axis? For example, based on the following data, Class   Frequency [0,9)      10 [10,19)    20 [20,39)    40 Then what is the label for vertical axis? Is it ""frequency"" or ""frequency density""? The height of first class is 10 or 1.0? For the 3rd class, is it 20, 2.0, or 40? Possible solution (or answer) Based on the information I studied from several links, when the width of the class is different, one needs to use ""Frequency density"" for the vertical axis. Then, $\text{frequency} = \text{height} \times \text{width of the class}$ If the class are in the same width, then one can use ""Frequency"" for the vertical axis, then all the heights of the bars are point to the value directly.",,"['statistics', 'graphing-functions']"
61,Stupid graph or stupid me?,Stupid graph or stupid me?,,"Reading the Microsoft TechNet article "" Test results: Extra-large scenario (FAST Search Server 2010 for SharePoint) "", I came across this graph. Now, am I stupid (and if so, could someone please enlighten me), or is this graph just stupid? To me, it seems like it's created with MS Paint instead of reflecting real values - I can not make sense of the graph as it seems like any given value on the horizontal axis (Queries per second) can result in multiple values on the vertical axis (Latency). EDIT: Thanks to all who contributed, the curves (not graphs) make more sense to me now. My conclusion to the original question is somewhere in the middle. I admit some stupidity on my own behalf, but still think the graphical representation of the data is quite stupid, as it fails to clearly communicate what it should.","Reading the Microsoft TechNet article "" Test results: Extra-large scenario (FAST Search Server 2010 for SharePoint) "", I came across this graph. Now, am I stupid (and if so, could someone please enlighten me), or is this graph just stupid? To me, it seems like it's created with MS Paint instead of reflecting real values - I can not make sense of the graph as it seems like any given value on the horizontal axis (Queries per second) can result in multiple values on the vertical axis (Latency). EDIT: Thanks to all who contributed, the curves (not graphs) make more sense to me now. My conclusion to the original question is somewhere in the middle. I admit some stupidity on my own behalf, but still think the graphical representation of the data is quite stupid, as it fails to clearly communicate what it should.",,"['statistics', 'graphing-functions']"
62,How can I calculate the standard deviation knowing an event probability and a number of trials?,How can I calculate the standard deviation knowing an event probability and a number of trials?,,"I'm writing a test for a probabilistic data structure that I've implemented. Since its probabilistic, its performance is different every time, and in particular, the performance varies much more widely (as a percentage) when the number of items is small. I want the test to fail if the performance is so bad that it's unlikely to have been that bad by chance. Basically, I want a significance test. In the test, I check the structure n times. Each check may fail with probability p. If the total number of failures is more than twice the standard deviation greater than the mean (n*p), I want to fail the test. Now, I know n and I can calculate p. How can I use n and p to get the standard deviation? I know it can be easily estimated by simulation, but there are about a hundred combinations of n and p, so I would prefer a way to just calculate it. Unfortunately, I haven't found an answer, or if I have it was too complex for this layman to notice.","I'm writing a test for a probabilistic data structure that I've implemented. Since its probabilistic, its performance is different every time, and in particular, the performance varies much more widely (as a percentage) when the number of items is small. I want the test to fail if the performance is so bad that it's unlikely to have been that bad by chance. Basically, I want a significance test. In the test, I check the structure n times. Each check may fail with probability p. If the total number of failures is more than twice the standard deviation greater than the mean (n*p), I want to fail the test. Now, I know n and I can calculate p. How can I use n and p to get the standard deviation? I know it can be easily estimated by simulation, but there are about a hundred combinations of n and p, so I would prefer a way to just calculate it. Unfortunately, I haven't found an answer, or if I have it was too complex for this layman to notice.",,"['probability', 'statistics', 'standard-deviation']"
63,"Ordinal, nominal data type. what type of data is True/false matrix? (Level of measurement)","Ordinal, nominal data type. what type of data is True/false matrix? (Level of measurement)",,"cat1    cat2    cat3    cat4 topic1  1        1         1    1 topic2  1        0         1    1 topic3  1        0         1    1 topic4  1        0         1    0 This data table means: When a topic belongs to category, the data entry will be 1.  If the topic doesn't belong to certain category, then the data entry will be 0. What kind of level measurement is this? Ordinal scale, nominal scale, ratio scale, or  interval scale? Thank You","cat1    cat2    cat3    cat4 topic1  1        1         1    1 topic2  1        0         1    1 topic3  1        0         1    1 topic4  1        0         1    0 This data table means: When a topic belongs to category, the data entry will be 1.  If the topic doesn't belong to certain category, then the data entry will be 0. What kind of level measurement is this? Ordinal scale, nominal scale, ratio scale, or  interval scale? Thank You",,['statistics']
64,Gaussian approximation of Poisson distribution,Gaussian approximation of Poisson distribution,,"I am using a Gaussian distribution to generate a Poisson variable with parameter $\lambda$. According to Wikipedia , when $\lambda > 1000$ this approximation is pretty good. However, using MATLAB I noticed that even when $\lambda = 400$ Gaussian and Poisson distributions seem to be almost identical. What do you think would be the minimum value of $\lambda$ to guarantee that the two distributions are close enough?","I am using a Gaussian distribution to generate a Poisson variable with parameter $\lambda$. According to Wikipedia , when $\lambda > 1000$ this approximation is pretty good. However, using MATLAB I noticed that even when $\lambda = 400$ Gaussian and Poisson distributions seem to be almost identical. What do you think would be the minimum value of $\lambda$ to guarantee that the two distributions are close enough?",,"['statistics', 'probability-distributions', 'normal-distribution']"
65,Computing the population given a set of replication rates,Computing the population given a set of replication rates,,"So I'm looking to calculate the probability that a bacterial population dies out with the following conditions: Initial population is 1 At each iteration the bacteria can die, do nothing, divide into 2 or divide into three.  So each bacteria can change into either 0, 1, 2, 3 bacteria. Each event has a 25% likelihood. So I know from simulation that the likelihood of the population dying out is ~36.3%. However, I'm looking for a method to calculate this analytically. Some MATLAB code for the simulation: ntries = 100000; mnum = 10000; res = ones(ntries, 1);   for i = 1:ntries     while res(i) > 0 && res(i) < mnum         res(i) = sum(randi(4,res(i), 1)-1);     end end mean(res==0) Thanks, Will","So I'm looking to calculate the probability that a bacterial population dies out with the following conditions: Initial population is 1 At each iteration the bacteria can die, do nothing, divide into 2 or divide into three.  So each bacteria can change into either 0, 1, 2, 3 bacteria. Each event has a 25% likelihood. So I know from simulation that the likelihood of the population dying out is ~36.3%. However, I'm looking for a method to calculate this analytically. Some MATLAB code for the simulation: ntries = 100000; mnum = 10000; res = ones(ntries, 1);   for i = 1:ntries     while res(i) > 0 && res(i) < mnum         res(i) = sum(randi(4,res(i), 1)-1);     end end mean(res==0) Thanks, Will",,"['probability', 'statistics']"
66,how can we generate random numbers using skew normal distribution in multivariate case,how can we generate random numbers using skew normal distribution in multivariate case,,how can we generate random numbers using skew normal distribution in multivariate case,how can we generate random numbers using skew normal distribution in multivariate case,,['probability']
67,Properties of sigmoid functions,Properties of sigmoid functions,,"I'm considering a parametrized sigmoid function such as the following logistic: $$f(x)=\frac{e^{a+bx}}{1+e^{a+bx}}$$ And I'm interested only in the interval $\displaystyle x >= 0$ and $\displaystyle x < x_{max}$ (with a given $x_{max}$). Two tiny questions regarding its properties: 1) Is the sum of sigmoid functions always a sigmoid function itself ? 2) Is the log function (i.e. $\displaystyle f(x) = log_{a}(bx^{c})$ or similar) a particular case of a sigmoid function ? In other words, can I pick parameters for the logistic function above so that it behaves like a log function in the given interval? Thanks.","I'm considering a parametrized sigmoid function such as the following logistic: $$f(x)=\frac{e^{a+bx}}{1+e^{a+bx}}$$ And I'm interested only in the interval $\displaystyle x >= 0$ and $\displaystyle x < x_{max}$ (with a given $x_{max}$). Two tiny questions regarding its properties: 1) Is the sum of sigmoid functions always a sigmoid function itself ? 2) Is the log function (i.e. $\displaystyle f(x) = log_{a}(bx^{c})$ or similar) a particular case of a sigmoid function ? In other words, can I pick parameters for the logistic function above so that it behaves like a log function in the given interval? Thanks.",,['statistics']
68,$T$ Pokemon trainers catch a Pokemon every day. How many days does it take until two trainers own Pokemons of the same species?,Pokemon trainers catch a Pokemon every day. How many days does it take until two trainers own Pokemons of the same species?,T,$T$ Pokemon trainers catch $1$ out of $P$ different species of Pokemons every day. Every species has the same chance to be caught. One species can be caught by one trainer multiple times. In mean how many days $D$ does it take until at least $2$ trainers own at least one common species? I'm looking for a approximative formula which can be computed for large $P$ and $T$ with $T\ll P$ where a simulation can't be done anymore. $ \pm 10 \%$ is good enough. Proof is not required. Experiments I did some experiment with $P=1025$ Pokemon (current count) and different trainer $T$ count to calculate the mean day $D$ required (results need to be round up). Furthermore the median days and the total number of caught Pokemon among all trainer and the median times the trainer count. T trainer Mean days $D$ needed Median day $D$ needed Total caught Pokemon Median $D$ times $T$ 2 28.8126 27 57.6251 54 3 16.8072 16 50.4215 48 4 12.0491 11 48.1963 44 5 9.44665 9 47.2332 45 6 7.77382 7 46.6429 42 7 6.63424 6 46.4397 42 8 5.83851 6 46.7081 48 9 5.18945 5 46.705 45 10 4.69666 4 46.9666 40 11 4.29345 4 47.2279 44 12 3.95724 4 47.4869 48 13 3.68294 3 47.8782 39 14 3.44168 3 48.1835 42 15 3.24476 3 48.6714 45 16 3.07407 3 49.1851 48 For $T = 2$ trainers we can approximate the mean days $E(D)$ needed with $$E(D) \approx \frac{\sqrt{P\cdot \pi}}{2}$$ Can we generalize this formula for $T>2$ ? Bonus question 1: If we have a look at the total caught Pokemon we see it has a local minimum. The $T$ needed for this local minimum would also be interesting to know. Bonus question 2: How would the mean days $E(D)$ change if one of those 2 trainer need to be a specific one? E.g the first Is there a well studied problem related to this? Birthday paradox has some similarities.,Pokemon trainers catch out of different species of Pokemons every day. Every species has the same chance to be caught. One species can be caught by one trainer multiple times. In mean how many days does it take until at least trainers own at least one common species? I'm looking for a approximative formula which can be computed for large and with where a simulation can't be done anymore. is good enough. Proof is not required. Experiments I did some experiment with Pokemon (current count) and different trainer count to calculate the mean day required (results need to be round up). Furthermore the median days and the total number of caught Pokemon among all trainer and the median times the trainer count. T trainer Mean days needed Median day needed Total caught Pokemon Median times 2 28.8126 27 57.6251 54 3 16.8072 16 50.4215 48 4 12.0491 11 48.1963 44 5 9.44665 9 47.2332 45 6 7.77382 7 46.6429 42 7 6.63424 6 46.4397 42 8 5.83851 6 46.7081 48 9 5.18945 5 46.705 45 10 4.69666 4 46.9666 40 11 4.29345 4 47.2279 44 12 3.95724 4 47.4869 48 13 3.68294 3 47.8782 39 14 3.44168 3 48.1835 42 15 3.24476 3 48.6714 45 16 3.07407 3 49.1851 48 For trainers we can approximate the mean days needed with Can we generalize this formula for ? Bonus question 1: If we have a look at the total caught Pokemon we see it has a local minimum. The needed for this local minimum would also be interesting to know. Bonus question 2: How would the mean days change if one of those 2 trainer need to be a specific one? E.g the first Is there a well studied problem related to this? Birthday paradox has some similarities.,T 1 P D 2 P T T\ll P  \pm 10 \% P=1025 T D D D D T T = 2 E(D) E(D) \approx \frac{\sqrt{P\cdot \pi}}{2} T>2 T E(D),"['probability', 'statistics', 'expected-value', 'coupon-collector', 'birthday']"
69,A sequence of coin flips of random length has n heads. What is the expected value of the sequence's length?,A sequence of coin flips of random length has n heads. What is the expected value of the sequence's length?,,"More rigorously, let's say you are generating sequences of coin flips with a maximum length l, with equal probability of any length from 1 to l. You generate a sequence with n heads. What is the expected value of the sequence's length as l goes to infinity? I tried this for n=1, where I obtained the probability density function P(x) = x*2^(-x) and an expected value of 3. For general value of n, I obtained P(x) = x*C(x,n)*2^(-x). Not sure if the sum converges for these, or what the value is. SOLVED E(0) = 1/2 + 1/4 + 1/8... = 1 E(n)+1 = E(n)/2+E(n+1)/2 => E(n+1) = E(n) + 2 Therefore: E(n) = 2n+1","More rigorously, let's say you are generating sequences of coin flips with a maximum length l, with equal probability of any length from 1 to l. You generate a sequence with n heads. What is the expected value of the sequence's length as l goes to infinity? I tried this for n=1, where I obtained the probability density function P(x) = x*2^(-x) and an expected value of 3. For general value of n, I obtained P(x) = x*C(x,n)*2^(-x). Not sure if the sum converges for these, or what the value is. SOLVED E(0) = 1/2 + 1/4 + 1/8... = 1 E(n)+1 = E(n)/2+E(n+1)/2 => E(n+1) = E(n) + 2 Therefore: E(n) = 2n+1",,"['probability', 'statistics', 'probability-distributions']"
70,Probability that mean is larger than median,Probability that mean is larger than median,,"Let $X_1,\ldots,X_n$ be i.i.d random variables taking values in $\mathbb{R}$ . Suppose that $n$ is odd and the $X_i$ follow a continuous distribution. I am interested in the probability that the mean of these random variables is larger than their median, i.e. $$ \mathbb{P}\left[ \frac{1}{n}\sum_{i=1}^nX_i>X_{\left(\frac{n+1}{2}\right)} \right] $$ My guess is that in general, there is no nice formula for this probability. But I wonder: Are there (easy or known) special cases, where there is a (nice) formula?","Let be i.i.d random variables taking values in . Suppose that is odd and the follow a continuous distribution. I am interested in the probability that the mean of these random variables is larger than their median, i.e. My guess is that in general, there is no nice formula for this probability. But I wonder: Are there (easy or known) special cases, where there is a (nice) formula?","X_1,\ldots,X_n \mathbb{R} n X_i 
\mathbb{P}\left[
\frac{1}{n}\sum_{i=1}^nX_i>X_{\left(\frac{n+1}{2}\right)}
\right]
","['probability', 'combinatorics', 'statistics', 'order-statistics']"
71,Best strategy to maximize outcome in Binomial Distribution.,Best strategy to maximize outcome in Binomial Distribution.,,"The question is the following: Given a multiple choice test with 12 ""yes"" or ""no"" questions, for which you need 8 correct answers to pass. You answer randomly, but know that 6 out of the twelve questions have answer ""yes"" (although you don't know which ones), what is the best strategy to maximize the likelyhood of passing? My approach feels unnecessarily complicated and might be wrong, I feel like I am missing something obvious. Results: I get $22.7\%$ chance of passing for $j = 10$ . I get $27.27\%$ for $j=8$ . I get $\approx 12\%$ for $j=7$ . I get $\approx 28.35 \%$ for $j=6$ My take went as follows: I want to find how many ""yes"" you should put at random in the test, in order to maximize the odds of getting $8$ answers correct. Here is my approach: The upper Line is the answer of the candidate ( $1$ for yes, $0$ for no) and the lower Line is the solution to the test: $$ \omega =  \begin{pmatrix} \omega_1 & \omega_2 & \cdots & \omega_6 & \omega_7 & \cdots &\omega_{12} \\ T_1 & T_2 & \cdots & T_6 & T_7 & \cdots & T_{12} \end{pmatrix}$$ Where $\omega_i$ is answer of a candidate to the $i$ -th question and $T_i$ the Solution to said question. If $\omega_i = T_i$ , then the answer is correct. Given a test, we can rearrange the order of the questions such that $\omega$ is equivalent to some $$[\omega] =  \begin{pmatrix} \omega_{\pi(1)} & \omega_{\pi(2)} & \cdots & \omega_{\pi(3)} & \omega_{\pi(7)} & \cdots &\omega_{\pi(12)} \\ 1 & 1 & \cdots & 1 & 0 & \cdots & 0 \end{pmatrix}$$ Where $\pi$ is some permutation of the columns. Now, let $1 \leq j \leq 12$ be the number of ""yes"" answers, we have $\binom{12}{j}$ possible ways to answer the test. For $j=12$ , we always get $6$ correct answers, but never $8$ . For $j=11$ , we can get a maximum of $7$ correct answers. For $j=10$ , things get more interesting and my attempt is too long to write down, but I reason as follows: All elements are equivalent to one of the following possible scenarios: \begin{align*}          r_1 &= \begin{pmatrix} 1 & 1 &  \cdots & 1 & 0 & 0 & 1 & \cdots & 1 & 1 \\                                 1 & 1 & \cdots  & 1 & 0 & 0 & 0 & \cdots  & 0 & 0 \end{pmatrix}        & r_2& = \begin{pmatrix} 0 & 1 & 1 & \cdots & 1 & 0 & 1 & \cdots & 1 \\                                 1 & 1 & 1 & \cdots & 1 & 0 & 0 & \cdots & 0 \end{pmatrix} \\           r_3 &= \begin{pmatrix} 0 & 0 & 1 & \cdots & 1 & 1 & \cdots & 1 \\                                  1 & 1 & 1 & \cdots & 1 & 0 & \cdots & 0 \end{pmatrix} & &       \end{align*} And by counting the number of possible permutations of each distinguishalbe column of each representant, we get the number of possibilities tied to each number of correct answer. Only $[r_1]$ can get us to pass and we get a $22.7\%$ chance of passing for $j = 10$ . I use a similar process for the rest. Here is my concrete computation in the case $j=6$ , where $S(r_i)$ is the number of correct answers associated to a certain respresentant and the numbers below for example $\begin{pmatrix} 1 \\ 0 \end{pmatrix}$ correspond to the number of columns of this form that any element equivalent to $r_i$ has:","The question is the following: Given a multiple choice test with 12 ""yes"" or ""no"" questions, for which you need 8 correct answers to pass. You answer randomly, but know that 6 out of the twelve questions have answer ""yes"" (although you don't know which ones), what is the best strategy to maximize the likelyhood of passing? My approach feels unnecessarily complicated and might be wrong, I feel like I am missing something obvious. Results: I get chance of passing for . I get for . I get for . I get for My take went as follows: I want to find how many ""yes"" you should put at random in the test, in order to maximize the odds of getting answers correct. Here is my approach: The upper Line is the answer of the candidate ( for yes, for no) and the lower Line is the solution to the test: Where is answer of a candidate to the -th question and the Solution to said question. If , then the answer is correct. Given a test, we can rearrange the order of the questions such that is equivalent to some Where is some permutation of the columns. Now, let be the number of ""yes"" answers, we have possible ways to answer the test. For , we always get correct answers, but never . For , we can get a maximum of correct answers. For , things get more interesting and my attempt is too long to write down, but I reason as follows: All elements are equivalent to one of the following possible scenarios: And by counting the number of possible permutations of each distinguishalbe column of each representant, we get the number of possibilities tied to each number of correct answer. Only can get us to pass and we get a chance of passing for . I use a similar process for the rest. Here is my concrete computation in the case , where is the number of correct answers associated to a certain respresentant and the numbers below for example correspond to the number of columns of this form that any element equivalent to has:","22.7\% j = 10 27.27\% j=8 \approx 12\% j=7 \approx 28.35 \% j=6 8 1 0  \omega =  \begin{pmatrix} \omega_1 & \omega_2 & \cdots & \omega_6 & \omega_7 & \cdots &\omega_{12} \\ T_1 & T_2 & \cdots & T_6 & T_7 & \cdots & T_{12} \end{pmatrix} \omega_i i T_i \omega_i = T_i \omega [\omega] =  \begin{pmatrix} \omega_{\pi(1)} & \omega_{\pi(2)} & \cdots & \omega_{\pi(3)} & \omega_{\pi(7)} & \cdots &\omega_{\pi(12)} \\ 1 & 1 & \cdots & 1 & 0 & \cdots & 0 \end{pmatrix} \pi 1 \leq j \leq 12 \binom{12}{j} j=12 6 8 j=11 7 j=10 \begin{align*}
         r_1 &= \begin{pmatrix} 1 & 1 &  \cdots & 1 & 0 & 0 & 1 & \cdots & 1 & 1 \\
                                1 & 1 & \cdots  & 1 & 0 & 0 & 0 & \cdots  & 0 & 0 \end{pmatrix}
       & r_2& = \begin{pmatrix} 0 & 1 & 1 & \cdots & 1 & 0 & 1 & \cdots & 1 \\
                                1 & 1 & 1 & \cdots & 1 & 0 & 0 & \cdots & 0 \end{pmatrix} \\
          r_3 &= \begin{pmatrix} 0 & 0 & 1 & \cdots & 1 & 1 & \cdots & 1 \\
                                 1 & 1 & 1 & \cdots & 1 & 0 & \cdots & 0 \end{pmatrix} & & 
     \end{align*} [r_1] 22.7\% j = 10 j=6 S(r_i) \begin{pmatrix} 1 \\ 0 \end{pmatrix} r_i","['probability', 'statistics']"
72,Conditional Poisson Distribution is Binomial,Conditional Poisson Distribution is Binomial,,"I need to show that if Xi ∼ Poisson(λi), i = 1, 2, . . . , k are independent then the conditional distribution of X1 given X1 + X2 + . . .Xk is Binomial and determines the parameters of this Binomial distribution. I tried: $$ P(X1 = x| X1+...+Xk = y)$$ $$=\frac{P(X1 = x)P(X1+...+Xk = y|X1= x)}{P(X1 +...+Xk = y)}$$ $$=\frac{P(X1=x, X1+...+Xk = y)}{P(X1+...+Xk = y)}$$ $$=\frac{P(X1 = x)P(X2+...+Xk = y-x)}{\sum_{m=0}^yP(X1=m)P(X2+...+Xk = y-m) }$$ $$=\frac{λ1^xexp(-λ1)/x! *\frac{(λ2 + ...+λk)^{y-x}exp(-[λ2+...+λk])}{(y-x)!} }{\sum_{m=0}^y\frac{λ1^mexp(-λ1)}{m!} * \frac{(λ2 + ...+λk)^{y-m}exp(-[λ2+...+λk])}{(y-m)!} }$$ Then I am completely stuck. Am I on the right track? How do I get the $\frac{n!}{k!(n-k)!}$ for the $nCk$ in the Binomial distribution? Any help is greatly appreciated. -- Edit: I have managed to get to the following: $$=\frac{\frac{λ1^xexp(-λ1)}{x!} *\frac{(λ2 + ...+λk)^{y-x}exp(-[λ2+...+λk])}{(y-x)!} }   { \frac{(λ1 + ...+λk)^{y}exp(-[λ1+...+λk])} { y!}}$$ $$= \frac{y!}{x!{y-x}!}*\frac{λ1^x (λ2+...+λk)^{y-x}}{(λ1+...+λk)^y}$$ where I think I got the $nCk$ but not the $p^k(1-p)^{n-k}$ bit. How can I simplify this step further? Sorry if this is really straightforward. What is $λ1+...+λk$ ? Can they sum up to 1?","I need to show that if Xi ∼ Poisson(λi), i = 1, 2, . . . , k are independent then the conditional distribution of X1 given X1 + X2 + . . .Xk is Binomial and determines the parameters of this Binomial distribution. I tried: Then I am completely stuck. Am I on the right track? How do I get the for the in the Binomial distribution? Any help is greatly appreciated. -- Edit: I have managed to get to the following: where I think I got the but not the bit. How can I simplify this step further? Sorry if this is really straightforward. What is ? Can they sum up to 1?"," P(X1 = x| X1+...+Xk = y) =\frac{P(X1 = x)P(X1+...+Xk = y|X1= x)}{P(X1 +...+Xk = y)} =\frac{P(X1=x, X1+...+Xk = y)}{P(X1+...+Xk = y)} =\frac{P(X1 = x)P(X2+...+Xk = y-x)}{\sum_{m=0}^yP(X1=m)P(X2+...+Xk = y-m) } =\frac{λ1^xexp(-λ1)/x! *\frac{(λ2 + ...+λk)^{y-x}exp(-[λ2+...+λk])}{(y-x)!} }{\sum_{m=0}^y\frac{λ1^mexp(-λ1)}{m!} * \frac{(λ2 + ...+λk)^{y-m}exp(-[λ2+...+λk])}{(y-m)!} } \frac{n!}{k!(n-k)!} nCk =\frac{\frac{λ1^xexp(-λ1)}{x!} *\frac{(λ2 + ...+λk)^{y-x}exp(-[λ2+...+λk])}{(y-x)!} }   { \frac{(λ1 + ...+λk)^{y}exp(-[λ1+...+λk])} { y!}} = \frac{y!}{x!{y-x}!}*\frac{λ1^x (λ2+...+λk)^{y-x}}{(λ1+...+λk)^y} nCk p^k(1-p)^{n-k} λ1+...+λk","['statistics', 'probability-distributions', 'poisson-distribution', 'binomial-distribution']"
73,Existence of density of product of random variable and random vector,Existence of density of product of random variable and random vector,,"Let $X$ be a random vector in $\mathbb R^d$ and $Y$ be a binary random variable on the same probability space, and with values in $\{\pm 1\}$ . Suppose that for every $y \in \{\pm 1\}$ : conditioned on the event $Y=y$ , (the distribution of) $X$ has density. Question. Is it true that the random vector $Z:=YZ$ has density ? Rough guess For any $y \in \{\pm 1\}$ , let $\pi_y := \mathbb P(Y=y)$ and let $f_y:\mathbb R^d \to \mathbb R_+$ be the density of $X$ conditioned on the event $Y=y$ . For any measurable $A \subseteq \mathbb R^d$ , one has $$ \begin{split} \mathbb P(Z \in A) &= \sum_y \pi_y\mathbb P(yX \in A \mid Y = y) = \sum_y \pi_y\mathbb P( X \in yA \mid Y = y)\\ & = \sum_y\pi_y\int_{y A}f_y(b)\mathrm{d}b = \sum_y \pi_y \int_{A}f_y(ya)\mathrm{d}a, \end{split} $$ where we have used the change of variable $b=ya$ , which has Jacobian determinant $1$ . Thus, it would seem that $Z$ has density given  by the explicit formula $f(a) := \sum_y \pi_y f_y(ya)$ .","Let be a random vector in and be a binary random variable on the same probability space, and with values in . Suppose that for every : conditioned on the event , (the distribution of) has density. Question. Is it true that the random vector has density ? Rough guess For any , let and let be the density of conditioned on the event . For any measurable , one has where we have used the change of variable , which has Jacobian determinant . Thus, it would seem that has density given  by the explicit formula .","X \mathbb R^d Y \{\pm 1\} y \in \{\pm 1\} Y=y X Z:=YZ y \in \{\pm 1\} \pi_y := \mathbb P(Y=y) f_y:\mathbb R^d \to \mathbb R_+ X Y=y A \subseteq \mathbb R^d 
\begin{split}
\mathbb P(Z \in A) &= \sum_y \pi_y\mathbb P(yX \in A \mid Y = y) = \sum_y \pi_y\mathbb P( X \in yA \mid Y = y)\\
& = \sum_y\pi_y\int_{y A}f_y(b)\mathrm{d}b = \sum_y \pi_y \int_{A}f_y(ya)\mathrm{d}a,
\end{split}
 b=ya 1 Z f(a) := \sum_y \pi_y f_y(ya)","['probability', 'statistics', 'probability-distributions', 'conditional-probability']"
74,Variance of standardized linear regression coefficient,Variance of standardized linear regression coefficient,,"Suppose we have standardized inputs (mean $0$ , variance $1$ ). So that $y=x_1\beta_1+x_2\beta_2+\varepsilon$ , (we have no $\beta_0$ due to standardization). With $\varepsilon \sim N(0,\sigma^{2})$ . Also note that we only have 2 variables. We wish to show that $Var(\beta_1)=\frac{\sigma^{2}}{1-r_{12}^{2}}$ , where $r_{12}$ is the sample correlation between $x_1,x_2$ . So I have arrived at $Var(\hat{\beta})=Var((X^{T}X)^{-1}X^{T}Y)=Var((X^{T}X)^{-1}X^{T}(X\beta+\varepsilon))=Var((X^{T}X)^{-1}X^{T}\sigma^2I) = \sigma^2(X^TX)^{-1}$ And I'm not exactly sure where to continue, any help would be appreciated.","Suppose we have standardized inputs (mean , variance ). So that , (we have no due to standardization). With . Also note that we only have 2 variables. We wish to show that , where is the sample correlation between . So I have arrived at And I'm not exactly sure where to continue, any help would be appreciated.","0 1 y=x_1\beta_1+x_2\beta_2+\varepsilon \beta_0 \varepsilon \sim N(0,\sigma^{2}) Var(\beta_1)=\frac{\sigma^{2}}{1-r_{12}^{2}} r_{12} x_1,x_2 Var(\hat{\beta})=Var((X^{T}X)^{-1}X^{T}Y)=Var((X^{T}X)^{-1}X^{T}(X\beta+\varepsilon))=Var((X^{T}X)^{-1}X^{T}\sigma^2I) = \sigma^2(X^TX)^{-1}","['statistics', 'variance', 'linear-regression']"
75,How does rerolling one of two dice affect the expected value?,How does rerolling one of two dice affect the expected value?,,"This problem came to my head this morning and now I've just been curious since. Say you have two fair dice and you roll both of them after you must reroll the lowest die, if the dice are equal one gets chosen at random to be rerolled. What would be the expected outcome of this? Example: I roll two dice and get $ \left\{2,3\right\} $ because $ 2 \lt 3 $ I reroll the first die and then I get $ \left\{4,3\right\} $ . The expected value of two die rolls is $ 7 $ because you add all the outcomes then divide by $ 12 $ . However in this case there the data is negatively skewed therefore we have to times the outcomes by their chance of appearing. In this case the chances for each number are: Roll Outcome Chance $ 2 $ $ 1/216 $ $ 3 $ $ 4/216 $ $ 4 $ $ 9/216 $ $ 5 $ $ 16/216 $ $ 6 $ $ 25/216 $ $ 7 $ $ 36/216 $ $ 8 $ $ 35/216 $ $ 9 $ $ 32/216 $ $ 10 $ $ 27/216 $ $ 11 $ $ 20/216 $ $ 12 $ $ 11/216 $ The $ x $ in $ 216 $ comes from $ 6 $ cubed as we are effectively rolling three six-sided dice. Multiplying the rows together and then adding them we get $ 7.9\overline{2} $ as the expected value. Is this number correct? If not, how can I get the value? If so, is there a more mathematical way to prove this?","This problem came to my head this morning and now I've just been curious since. Say you have two fair dice and you roll both of them after you must reroll the lowest die, if the dice are equal one gets chosen at random to be rerolled. What would be the expected outcome of this? Example: I roll two dice and get because I reroll the first die and then I get . The expected value of two die rolls is because you add all the outcomes then divide by . However in this case there the data is negatively skewed therefore we have to times the outcomes by their chance of appearing. In this case the chances for each number are: Roll Outcome Chance The in comes from cubed as we are effectively rolling three six-sided dice. Multiplying the rows together and then adding them we get as the expected value. Is this number correct? If not, how can I get the value? If so, is there a more mathematical way to prove this?"," \left\{2,3\right\}   2 \lt 3   \left\{4,3\right\}   7   12   2   1/216   3   4/216   4   9/216   5   16/216   6   25/216   7   36/216   8   35/216   9   32/216   10   27/216   11   20/216   12   11/216   x   216   6   7.9\overline{2} ","['probability', 'statistics', 'dice']"
76,How to use Metropolis-Hastings algorithm for discrete case,How to use Metropolis-Hastings algorithm for discrete case,,"I came across this question that is quite confusing for me. So far, I've dealt or seen many examples of MH and Gibbs sampling for continuous case and haven't really thought about them for discrete case. Q : Estimate the marginal distribution of X with a Gibbs sampler. $X|n,y\sim Bim(n,y)\\y\sim Beta(2,4)\,\,\, , \,\,n\sim Poi(16)$ (y and n are independent) I derived joint posterior distribution and each full conditional distribution for each parameter.(I'm not sure about them. There might be some mistakes) (0) $P(X,n,y)\propto P(X|n,y)P(n)P(y)\propto \Large\binom{n}{x}\large y^x(1-y)^{n-x}*y(1-y)^3*\Large\frac{16^n}{n! }$ (1) $X|n,y\sim Bim(n,y)$ (2) $y|X,n\propto \large y^{x+2-1}(1-y)^{n-x+4-1}\sim Beta(x+2, n-x+4)$ (3) $n|X,y\propto \Large\binom{n}{x}\large(1-y)^{n-x}\Large\frac{16^n}{n!} \sim ?$ I don't think I can tell which distributions (3) is. Since I can't think of any distributions, I'm gonna use Metropolis-Hastings algorithm. Then I need proposal distribution which has at least the same support of n.(Since 'n' comes from Poisson distribution, it can take 0,1,2,...) So my question is... (1)What kind of proposal distribution should I use? (Binomial? Poisson? or some discrete distributions?) (2)Does discrete case have the same MH-algorithm steps with continuous case? I mean calculating the ratio, comparing with 1 and deciding whether to accept or not. Any help would be really appreciated:)","I came across this question that is quite confusing for me. So far, I've dealt or seen many examples of MH and Gibbs sampling for continuous case and haven't really thought about them for discrete case. Q : Estimate the marginal distribution of X with a Gibbs sampler. (y and n are independent) I derived joint posterior distribution and each full conditional distribution for each parameter.(I'm not sure about them. There might be some mistakes) (0) (1) (2) (3) I don't think I can tell which distributions (3) is. Since I can't think of any distributions, I'm gonna use Metropolis-Hastings algorithm. Then I need proposal distribution which has at least the same support of n.(Since 'n' comes from Poisson distribution, it can take 0,1,2,...) So my question is... (1)What kind of proposal distribution should I use? (Binomial? Poisson? or some discrete distributions?) (2)Does discrete case have the same MH-algorithm steps with continuous case? I mean calculating the ratio, comparing with 1 and deciding whether to accept or not. Any help would be really appreciated:)","X|n,y\sim Bim(n,y)\\y\sim Beta(2,4)\,\,\, , \,\,n\sim Poi(16) P(X,n,y)\propto P(X|n,y)P(n)P(y)\propto \Large\binom{n}{x}\large y^x(1-y)^{n-x}*y(1-y)^3*\Large\frac{16^n}{n! } X|n,y\sim Bim(n,y) y|X,n\propto \large y^{x+2-1}(1-y)^{n-x+4-1}\sim Beta(x+2, n-x+4) n|X,y\propto \Large\binom{n}{x}\large(1-y)^{n-x}\Large\frac{16^n}{n!} \sim ?","['probability', 'statistics', 'conditional-probability', 'bayesian']"
77,Probability normally random variable X is between two values,Probability normally random variable X is between two values,,"Find δ such that $P(2 −δ < X < 2 + δ) = 0.95$ when $\mu = 2$ and $\sigma^2 = 4$ I believe the approach to this question is to normalize the bounds of X. Doing so I get P(−δ/2 < Z < δ/2). Since the middle 95% of the area is covered, that means the lower bound is at the 2.5th percentile. I am not sure how to translate that to a value of δ however. Is this the right approach?","Find δ such that when and I believe the approach to this question is to normalize the bounds of X. Doing so I get P(−δ/2 < Z < δ/2). Since the middle 95% of the area is covered, that means the lower bound is at the 2.5th percentile. I am not sure how to translate that to a value of δ however. Is this the right approach?",P(2 −δ < X < 2 + δ) = 0.95 \mu = 2 \sigma^2 = 4,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
78,Relationship between Fisher Test and Student Test,Relationship between Fisher Test and Student Test,,"When performing linear regression with one explanatory variable (predictor), one can compute Fisher's test with value $F$ , and derive Student's test $T=\sqrt{F}$ . When there is more than one explanatory variable (predictor), the relationship $T=\sqrt{F}$ no longer holds. Is there a relationship between $F$ and the different student tests $T_i$ (one for each variable)? Perhaps a system of equations? Note : I am referring to F test in Excel's linear regression report:","When performing linear regression with one explanatory variable (predictor), one can compute Fisher's test with value , and derive Student's test . When there is more than one explanatory variable (predictor), the relationship no longer holds. Is there a relationship between and the different student tests (one for each variable)? Perhaps a system of equations? Note : I am referring to F test in Excel's linear regression report:",F T=\sqrt{F} T=\sqrt{F} F T_i,"['probability', 'statistics', 'hypothesis-testing']"
79,"Why is $\textbf{E}[X + Y \mid X,Y] = X + Y$?",Why is ?,"\textbf{E}[X + Y \mid X,Y] = X + Y","Intuitively, it seems obvious, but I am struggling to prove it for the case where $X_1,...,X_n$ are continuous random variables. I am aware that $E[c(X)|X]=c(X)$ . So how would one show that $E[c(X_i)|X_1,...,X_n]=c(X_i)$ and that $E[c(X_i)+a(X_j)|X_1,...,X_n]=c(X_i)+a(X_j)$ for $i,j=1,...,n$ ? The reason I am asking is that, given a linear regression model $y = \beta_0 + \beta_1 x_1 + \beta_2 x_i + u$ where $y,x_1, x_2, u$ are random variables, it is often said that $E[y|x_1,x_2]=\beta_0+\beta_1 x_1 + \beta_2 x_2 + E[u|x_1,x_2]$","Intuitively, it seems obvious, but I am struggling to prove it for the case where are continuous random variables. I am aware that . So how would one show that and that for ? The reason I am asking is that, given a linear regression model where are random variables, it is often said that","X_1,...,X_n E[c(X)|X]=c(X) E[c(X_i)|X_1,...,X_n]=c(X_i) E[c(X_i)+a(X_j)|X_1,...,X_n]=c(X_i)+a(X_j) i,j=1,...,n y = \beta_0 + \beta_1 x_1 + \beta_2 x_i + u y,x_1, x_2, u E[y|x_1,x_2]=\beta_0+\beta_1 x_1 + \beta_2 x_2 + E[u|x_1,x_2]","['statistics', 'conditional-expectation']"
80,What is probability that 10th toss of a weighted coin is a head given that the first 9 tosses were heads?,What is probability that 10th toss of a weighted coin is a head given that the first 9 tosses were heads?,,"Question : We are given a coin which lands on head with probability p such that $ P(p \le x) = x^5$ . Given that the first 9 tosses of the coin lands on head, what is the probability that the 10th toss is a head? I have been practicing several probability problems, but having read this one I have no idea how to start. I am wondering if there is a way to determine a range on the value of p, but I do not have any idea how to use the information on the  previous tosses. I would appreciate someone giving me some hints/some resources I can use to learn about how to solve these types of question.","Question : We are given a coin which lands on head with probability p such that . Given that the first 9 tosses of the coin lands on head, what is the probability that the 10th toss is a head? I have been practicing several probability problems, but having read this one I have no idea how to start. I am wondering if there is a way to determine a range on the value of p, but I do not have any idea how to use the information on the  previous tosses. I would appreciate someone giving me some hints/some resources I can use to learn about how to solve these types of question.", P(p \le x) = x^5,"['probability', 'statistics', 'conditional-probability']"
81,what is a distribution of $X$ given $X-Y>0$,what is a distribution of  given,X X-Y>0,"given two normally distributed variables $X\sim\mathcal N(\mu_X,\sigma_X)$ and $Y\sim\mathcal N(\mu_Y,\sigma_Y)$ that are independent $\rho_{XY} =0$ , what is a distribution of $X$ given $X>Y$ . I have run several simulations in Matlab and $X|X>Y$ looks suspiciously normally distributed, but what are its mean and standard deviation? Thank you for your help. EDIT: I agree with comments below. Although it looks suspiciously normally distributed, it definitely isn't.","given two normally distributed variables and that are independent , what is a distribution of given . I have run several simulations in Matlab and looks suspiciously normally distributed, but what are its mean and standard deviation? Thank you for your help. EDIT: I agree with comments below. Although it looks suspiciously normally distributed, it definitely isn't.","X\sim\mathcal N(\mu_X,\sigma_X) Y\sim\mathcal N(\mu_Y,\sigma_Y) \rho_{XY} =0 X X>Y X|X>Y","['probability', 'statistics', 'probability-distributions', 'normal-distribution', 'conditional-probability']"
82,Related to order statistics?,Related to order statistics?,,"say there are $N$ independent and identically distributed random channels i.e., $Z_i \in \{ Z_1, Z_2,..., Z_i\}$ with PDFs $f_{Z_i}(z)$ ordered in ascending order. Then using order statistics the PDF of $Z_1 = \text{min}_i(Z_i)$ is given by $f_{Z_1}(z) = N (1-F_{Z_i}(z))^{N-1}f_{Z_i}(z)$ ---(1) My query is will equation (1) will be valid if the random variables are not independent and not identically distributed. Any help in this regard will be highly appreciated.","say there are independent and identically distributed random channels i.e., with PDFs ordered in ascending order. Then using order statistics the PDF of is given by ---(1) My query is will equation (1) will be valid if the random variables are not independent and not identically distributed. Any help in this regard will be highly appreciated.","N Z_i \in \{ Z_1, Z_2,..., Z_i\} f_{Z_i}(z) Z_1 = \text{min}_i(Z_i) f_{Z_1}(z) = N (1-F_{Z_i}(z))^{N-1}f_{Z_i}(z)","['statistics', 'probability-distributions', 'density-function', 'cumulative-distribution-functions']"
83,Average vs. Median in a sample vs. the full population,Average vs. Median in a sample vs. the full population,,"Let's say I take a random sample from a full population of which I know average and median. Can I estimate the average and median for the sample from the average and median of the full population (without an explicit calculation)? I am assuming the median should be close, while the averages do not need to be close at all, depending on the distribution. In other words, if I select an hypothetical random element, the value for that element should be probabilistically closer to the median of the population rather than the average.","Let's say I take a random sample from a full population of which I know average and median. Can I estimate the average and median for the sample from the average and median of the full population (without an explicit calculation)? I am assuming the median should be close, while the averages do not need to be close at all, depending on the distribution. In other words, if I select an hypothetical random element, the value for that element should be probabilistically closer to the median of the population rather than the average.",,"['statistics', 'average', 'median']"
84,Fisher-Neyman Factorisation Theorem and sufficient statistic misunderstanding,Fisher-Neyman Factorisation Theorem and sufficient statistic misunderstanding,,"Fisher Neyman Factorisation Theorem states that for a statistical model for $X$ with PDF / PMF $f_{\theta}$ , then $T(X)$ is a sufficient statistic for $\theta$ if and only if there exists nonnegative functions $g_{\theta}$ and $h(x)$ such that for all $x,\theta$ we have that $f_{\theta}(x)=g_{\theta}(T(x))(h(x))$ . Computationally, this makes sense to me. However, recently I have started to have some doubts about when and where I can apply this theorem. For example, if I have the PDF for a uniform distribution $f_{\theta}(x)=\frac{1}{\theta}$ , doesn't this allow me to make any sufficient statistic that I like by rewriting the PDF as $$f_{\theta}(x)=\Big(\frac{X^2+X^4}{\theta}\Big)\Big(\frac{1}{X^2+X^4}\Big)$$ which would make our sufficient statistic $T(X)=X^2+X^4$ . Or if we replace this particular choice of $T(X)$ for something else, doesn't this allow us to construct almost any choice of $T(X)$ as a valid sufficient statistic? Is this correct, or am I doing something wrong here by arbitrarily adding in functions of $X$ that cancel out in order to create sufficient statistics?","Fisher Neyman Factorisation Theorem states that for a statistical model for with PDF / PMF , then is a sufficient statistic for if and only if there exists nonnegative functions and such that for all we have that . Computationally, this makes sense to me. However, recently I have started to have some doubts about when and where I can apply this theorem. For example, if I have the PDF for a uniform distribution , doesn't this allow me to make any sufficient statistic that I like by rewriting the PDF as which would make our sufficient statistic . Or if we replace this particular choice of for something else, doesn't this allow us to construct almost any choice of as a valid sufficient statistic? Is this correct, or am I doing something wrong here by arbitrarily adding in functions of that cancel out in order to create sufficient statistics?","X f_{\theta} T(X) \theta g_{\theta} h(x) x,\theta f_{\theta}(x)=g_{\theta}(T(x))(h(x)) f_{\theta}(x)=\frac{1}{\theta} f_{\theta}(x)=\Big(\frac{X^2+X^4}{\theta}\Big)\Big(\frac{1}{X^2+X^4}\Big) T(X)=X^2+X^4 T(X) T(X) X","['probability', 'statistics', 'statistical-inference', 'uniform-distribution', 'sufficient-statistics']"
85,"Derive density of $Z=XY$, $X\sim U(0,1)$ and $Y\sim\mathcal N(0,1)$.","Derive density of ,  and .","Z=XY X\sim U(0,1) Y\sim\mathcal N(0,1)","I have been stumped for a few days on this. I have two random variables $X\sim U(0,1)$ and $Y\sim\mathcal N(0,1)$ , which are independent. How can I get the density of $Z = XY$ ? I put $Z = XY, W = Y$ i.e. $X=Z/W, Y=W$ and achieved the Jacobian as $J={1\over|W|}$ , but I've got $f_{Z,W}(z,w)={1\over\sqrt{2\pi}|w|}{\exp(-w^2/2)}$ and I don't know how to integrate this w.r.t $w$ and get the (marginal) density of $Z$ . Could you please help me with this problem? I tried partial integration too but it doesn't work.","I have been stumped for a few days on this. I have two random variables and , which are independent. How can I get the density of ? I put i.e. and achieved the Jacobian as , but I've got and I don't know how to integrate this w.r.t and get the (marginal) density of . Could you please help me with this problem? I tried partial integration too but it doesn't work.","X\sim U(0,1) Y\sim\mathcal N(0,1) Z = XY Z = XY, W = Y X=Z/W, Y=W J={1\over|W|} f_{Z,W}(z,w)={1\over\sqrt{2\pi}|w|}{\exp(-w^2/2)} w Z","['probability', 'statistics', 'probability-distributions', 'density-function', 'change-of-variable']"
86,Pearson Correlation as a measure for non-linear dependence.,Pearson Correlation as a measure for non-linear dependence.,,"It is known that $\rho$ , the pearson correlation, is a measure for the linear dependence of two random variables say $X$ , $Y$ . But can't you say just transform $X$ and $Y$ such that we have, $$ \rho_{X,Y}(f(X),g(Y))$$ where $f$ , $g$ are non-linear functions such that it measures other kinds of dependce (take for example $f(s)=g(s)=s^2$ for quadratic dependence).","It is known that , the pearson correlation, is a measure for the linear dependence of two random variables say , . But can't you say just transform and such that we have, where , are non-linear functions such that it measures other kinds of dependce (take for example for quadratic dependence).","\rho X Y X Y  \rho_{X,Y}(f(X),g(Y)) f g f(s)=g(s)=s^2","['probability', 'statistics', 'statistical-inference', 'correlation']"
87,MLE for uniform distribution with two parameters,MLE for uniform distribution with two parameters,,"A finite number of random variables $X_1 ... X_n$ have a uniform distribution $[a, b]$ with $b>a$ , such that it has the following density: $$f_X(x) = \frac{1}{b-a}, a\le x \le b$$ find the MLE. Here's what I have tried: $L(b,a;x) = \prod_{i=1}^nf(x_i;b, a) = \prod_{i=1}^n\frac{1}{b-a} = \left(\frac{1}{b-a}\right)^n \\   \mathbf{L}(b,a;x) = \log L(b,a;x) = -n\log(b-a)$ Taking the first and second derivative in respect to b, and then with respect to a. $\frac{\partial\mathbf{L}(b,a;x)}{\partial b} = -\frac{n}{(b-a)} \\  \frac{\partial\mathbf{L}(b,a;x)}{\partial a} = \frac{n}{(b-a)} \\ \frac{\partial^2\mathbf{L}(b,a;x)}{\partial b^2} = \frac{2n}{(b-a)^2} \\ \frac{\partial^2\mathbf{L}(b,a;x)}{\partial a^2} = -\frac{2n}{(b-a)^2} \\ \frac{\partial^2\mathbf{L}(b,a;x)}{\partial ba} = -\frac{2n}{(b-a)^2}$ When I set the first two derivatves to zero to find the turning points, and these are when $b=a$ . To find the local maximum, I plug these into the hessian matrix: $$H :=\begin{pmatrix} \frac{\partial^2\mathbf{L}(b,a;x)}{\partial b^2}&\frac{\partial^2\mathbf{L}(b,a;x)}{\partial ba} \\ \frac{\partial^2\mathbf{L}(b,a;x)}{\partial ba}&\frac{\partial^2\mathbf{L}(b,a;x)}{\partial a^2} \end{pmatrix} \implies \begin{pmatrix} \frac{2n}{(b-a)^2}&-\frac{2n}{(b-a)^2} \\ -\frac{2n}{(b-a)^2}&-\frac{2n}{(b-a)^2} \end{pmatrix} \\  \\ = -\left(\frac{2n}{(b-a)^2}\right)\left(\frac{2n}{(b-a)^2}\right) -\left(\frac{2n}{(b-a)^2}\right)\left(\frac{2n}{(b-a)^2}\right) =  -\frac{8n^2}{(b-a)^4}$$ Given that $\frac{\partial^2\mathbf{L}(b,a;x)}{\partial b^2}>0$ and $Det(H) < 0$ , then our turning point is not a local maximum as the reverse inequality should happen for this to be the case. However, this cannot be true. The actual question assumes three random variables such that $x_1 = 1.5, x_2 = 4.6, x_3 = 7.2$ , and I'm supposed to plug these into the MLE. However, if there is no MLE then I cannot do this. So I have gone wrong somewhere.","A finite number of random variables have a uniform distribution with , such that it has the following density: find the MLE. Here's what I have tried: Taking the first and second derivative in respect to b, and then with respect to a. When I set the first two derivatves to zero to find the turning points, and these are when . To find the local maximum, I plug these into the hessian matrix: Given that and , then our turning point is not a local maximum as the reverse inequality should happen for this to be the case. However, this cannot be true. The actual question assumes three random variables such that , and I'm supposed to plug these into the MLE. However, if there is no MLE then I cannot do this. So I have gone wrong somewhere.","X_1 ... X_n [a, b] b>a f_X(x) = \frac{1}{b-a}, a\le x \le b L(b,a;x) = \prod_{i=1}^nf(x_i;b, a) = \prod_{i=1}^n\frac{1}{b-a} = \left(\frac{1}{b-a}\right)^n \\  
\mathbf{L}(b,a;x) = \log L(b,a;x) = -n\log(b-a) \frac{\partial\mathbf{L}(b,a;x)}{\partial b} = -\frac{n}{(b-a)} \\ 
\frac{\partial\mathbf{L}(b,a;x)}{\partial a} = \frac{n}{(b-a)} \\
\frac{\partial^2\mathbf{L}(b,a;x)}{\partial b^2} = \frac{2n}{(b-a)^2} \\
\frac{\partial^2\mathbf{L}(b,a;x)}{\partial a^2} = -\frac{2n}{(b-a)^2} \\
\frac{\partial^2\mathbf{L}(b,a;x)}{\partial ba} = -\frac{2n}{(b-a)^2} b=a H :=\begin{pmatrix} \frac{\partial^2\mathbf{L}(b,a;x)}{\partial b^2}&\frac{\partial^2\mathbf{L}(b,a;x)}{\partial ba} \\ \frac{\partial^2\mathbf{L}(b,a;x)}{\partial ba}&\frac{\partial^2\mathbf{L}(b,a;x)}{\partial a^2} \end{pmatrix} \implies \begin{pmatrix} \frac{2n}{(b-a)^2}&-\frac{2n}{(b-a)^2} \\ -\frac{2n}{(b-a)^2}&-\frac{2n}{(b-a)^2} \end{pmatrix} \\ 
\\
= -\left(\frac{2n}{(b-a)^2}\right)\left(\frac{2n}{(b-a)^2}\right) -\left(\frac{2n}{(b-a)^2}\right)\left(\frac{2n}{(b-a)^2}\right) =  -\frac{8n^2}{(b-a)^4} \frac{\partial^2\mathbf{L}(b,a;x)}{\partial b^2}>0 Det(H) < 0 x_1 = 1.5, x_2 = 4.6, x_3 = 7.2","['statistics', 'maximum-likelihood']"
88,Calculating the following MLE,Calculating the following MLE,,"Q. A biased die favours the number 2. It's rolled 4 times and 2 comes up twice. It's rolled again 4 times and 2 comes up once. Calculate the Likelihood and find the MLE. My working out: $L(\theta;x) = \binom{8}{3}\theta^3(1-\theta)^5$ , then taking the first derivative to find the local maximum $\binom{8}{3}\theta^2(1-\theta)^4(3(1-\theta) - 5\theta)=0 \implies \theta = \frac{3}{8}$ we take the second derivative to check the turning points. $\frac{\partial L(\theta;x)}{\partial \theta}=2\binom{8}{3}\theta(1-\theta)^3(32\theta^2-25\theta+3)$ plugging in for $\theta = \frac{3}{8}$ we finally get $2 \cdot 56 \cdot 3/8 \cdot (2/8)^3(32 \cdot (3/8)^3-25\cdot 3/8 + 3) = -2.06$ therefore, $\theta = \frac{3}{8}$ is a global maximum. Have i derived the MLE correctly?","Q. A biased die favours the number 2. It's rolled 4 times and 2 comes up twice. It's rolled again 4 times and 2 comes up once. Calculate the Likelihood and find the MLE. My working out: , then taking the first derivative to find the local maximum we take the second derivative to check the turning points. plugging in for we finally get therefore, is a global maximum. Have i derived the MLE correctly?",L(\theta;x) = \binom{8}{3}\theta^3(1-\theta)^5 \binom{8}{3}\theta^2(1-\theta)^4(3(1-\theta) - 5\theta)=0 \implies \theta = \frac{3}{8} \frac{\partial L(\theta;x)}{\partial \theta}=2\binom{8}{3}\theta(1-\theta)^3(32\theta^2-25\theta+3) \theta = \frac{3}{8} 2 \cdot 56 \cdot 3/8 \cdot (2/8)^3(32 \cdot (3/8)^3-25\cdot 3/8 + 3) = -2.06 \theta = \frac{3}{8},"['statistics', 'maximum-likelihood']"
89,Sampling from a high-dimensional multivariate Gaussian distribution when low-rank approximation for the inverse of the covariance matrix is available,Sampling from a high-dimensional multivariate Gaussian distribution when low-rank approximation for the inverse of the covariance matrix is available,,"I want to get random samples from a high-dimensional (say, $10^4$ or more) multivariate Gaussian distribution. Assume a case of zero mean for simplicity, the probability density is given as $$P({\bf x})=\frac{1}{\sqrt{(2\pi)^n|{\bf \Sigma}|}} \exp(-\frac{1}{2}{\bf x}^T {\bf \Sigma}^{-1} {\bf x})~~~~~~~~~(1)$$ where ${\bf \Sigma}$ is a $n\times n$ covariance matrix. I here have a low-rank approximation for inverse of the covariance matrix ${\bf Q}={\bf \Sigma}^{-1}$ (i.e., precision matrix, NOT the covariance matrix ${\bf \Sigma}$ itself), $${\bf Q} \simeq {\bf P}^T {\bf P}$$ where ${\bf P}$ is a $n\times r$ matrix where $r < n$ . (Such an approximation can be obtained based on truncated singular value decomposition, for instance) When $r \ll n$ , what is the most efficient way to get the random samples from the Gaussian distribution? At first, I was thinking that simple Markov chain Monte-Carlo methods like the Metropolis-Hastings  (MH) algorithm are directly applicable because $P({\bf x})$ is unimodal and we can relatively easily evaluate $P({\bf x})$ for a given ${\bf x}$ because of fast calculation of ${\bf P}^T {\bf P}$ . However, articles like the one below introduces more complicated sampling algorithms for high-dimensional Gaussian distributions instead of such simple ones. I also want to know why they never tell that application of methods like simple MH algorithm is effective? (Note that the article do not discuss low-rank approximation) Vono, M., Dobigeon, N., & Chainais, P. (2022). High-dimensional Gaussian sampling: a review and a unifying approach based on a stochastic proximal point algorithm. SIAM Review, 64(1), 3-56.","I want to get random samples from a high-dimensional (say, or more) multivariate Gaussian distribution. Assume a case of zero mean for simplicity, the probability density is given as where is a covariance matrix. I here have a low-rank approximation for inverse of the covariance matrix (i.e., precision matrix, NOT the covariance matrix itself), where is a matrix where . (Such an approximation can be obtained based on truncated singular value decomposition, for instance) When , what is the most efficient way to get the random samples from the Gaussian distribution? At first, I was thinking that simple Markov chain Monte-Carlo methods like the Metropolis-Hastings  (MH) algorithm are directly applicable because is unimodal and we can relatively easily evaluate for a given because of fast calculation of . However, articles like the one below introduces more complicated sampling algorithms for high-dimensional Gaussian distributions instead of such simple ones. I also want to know why they never tell that application of methods like simple MH algorithm is effective? (Note that the article do not discuss low-rank approximation) Vono, M., Dobigeon, N., & Chainais, P. (2022). High-dimensional Gaussian sampling: a review and a unifying approach based on a stochastic proximal point algorithm. SIAM Review, 64(1), 3-56.",10^4 P({\bf x})=\frac{1}{\sqrt{(2\pi)^n|{\bf \Sigma}|}} \exp(-\frac{1}{2}{\bf x}^T {\bf \Sigma}^{-1} {\bf x})~~~~~~~~~(1) {\bf \Sigma} n\times n {\bf Q}={\bf \Sigma}^{-1} {\bf \Sigma} {\bf Q} \simeq {\bf P}^T {\bf P} {\bf P} n\times r r < n r \ll n P({\bf x}) P({\bf x}) {\bf x} {\bf P}^T {\bf P},"['linear-algebra', 'statistics', 'statistical-inference', 'sampling']"
90,Method of moments estimator for lognormal distribution,Method of moments estimator for lognormal distribution,,"Let $X_1,\cdots X_n$ be identically and independently distributed lognormally. I want to find the method of moments estimators for $\mu,\sigma^2$ . We know that $E[X] = e^{\mu+\frac{\sigma^2}{2}}$ , $E[X^2] = e^{2\mu + 2\sigma^2}$ . Then we have $\mu + \frac{\sigma^2}{2} = \log\left( \frac{\sum X_i}{n} \right)$ . Hence, $\mu = \log(\sum X_i) - \log(n) - \frac{\sigma^2}{2}$ . Further, $e^{2\mu + 2\sigma^2} = \frac{\sum X_i^2}{n}$ which gives $2\mu + 2\sigma^2 = \log \left( \frac{\sum X_i}{n} \right)$ , and after some algebraic manipulation we have $\mu = \log \left( \frac{\log(\sum X_i^2)}{2} \right) - \frac{\log(n)}{2} - \sigma^2$ . Equating these gives $\sigma^2_{MM} = \log(\sum{X_i^2}) - 2\log(\sum X_i) + \log(n)$ , and in the exact same way $\mu_{MM} = -\frac{\log(\sum X_i^2)}{2} + 2\log(\sum X_i) - \frac{3}{2}\log (n)$ . However the wikipedia page gives $\mu_{MM} = \log \left( \frac{E(X)^2}{\sqrt{\text{Var}(X) + E(X)^2}} \right), \sigma^2_{MM} = \log \left( \frac{\text{Var}(X)}{E(X)^2} + 1 \right)$ . Have I done it wrong and if so where is the mistake? Thanks:)","Let be identically and independently distributed lognormally. I want to find the method of moments estimators for . We know that , . Then we have . Hence, . Further, which gives , and after some algebraic manipulation we have . Equating these gives , and in the exact same way . However the wikipedia page gives . Have I done it wrong and if so where is the mistake? Thanks:)","X_1,\cdots X_n \mu,\sigma^2 E[X] = e^{\mu+\frac{\sigma^2}{2}} E[X^2] = e^{2\mu + 2\sigma^2} \mu + \frac{\sigma^2}{2} = \log\left( \frac{\sum X_i}{n} \right) \mu = \log(\sum X_i) - \log(n) - \frac{\sigma^2}{2} e^{2\mu + 2\sigma^2} = \frac{\sum X_i^2}{n} 2\mu + 2\sigma^2 = \log \left( \frac{\sum X_i}{n} \right) \mu = \log \left( \frac{\log(\sum X_i^2)}{2} \right) - \frac{\log(n)}{2} - \sigma^2 \sigma^2_{MM} = \log(\sum{X_i^2}) - 2\log(\sum X_i) + \log(n) \mu_{MM} = -\frac{\log(\sum X_i^2)}{2} + 2\log(\sum X_i) - \frac{3}{2}\log (n) \mu_{MM} = \log \left( \frac{E(X)^2}{\sqrt{\text{Var}(X) + E(X)^2}} \right), \sigma^2_{MM} = \log \left( \frac{\text{Var}(X)}{E(X)^2} + 1 \right)","['probability', 'statistics', 'solution-verification', 'parameter-estimation']"
91,Lipschitz inequality with Rademacher variable,Lipschitz inequality with Rademacher variable,,"Suppose $(\epsilon_i)_{i = 1}^n$ are IID Rademacher variables. And we have another series of rv.s $(X_i)_{i = 1}^n$ independent with $(\epsilon_i)_{i = 1}^n$ with a Lipschitz function $|f(x, z_1) - f(x, z_2)| < L(x) |z_1 - z_2|$ . What I want to do is to bound the expectation: $$     \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i \big( f(X_i, z_1) - f(X_i, z_2) \big) \bigg|. $$ First, I simply use the fact $ \big( f(X_i, z_1) - f(X_i, z_2) \big) \leq L(X_i) |z_1 - z_2|$ to give the upper bound $|z_1 - z_2| \cdot \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i L(X_i)\bigg|$ . But later I found that this may not be held since $\epsilon_i$ can be either positive or negative. So I wonder if there exist some constant $C$ such that $$     \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i \big( f(X_i, z_1) - f(X_i, z_2) \big) \bigg| \leq C \cdot |z_1 - z_2| \cdot \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i L(X_i)\bigg| $$","Suppose are IID Rademacher variables. And we have another series of rv.s independent with with a Lipschitz function . What I want to do is to bound the expectation: First, I simply use the fact to give the upper bound . But later I found that this may not be held since can be either positive or negative. So I wonder if there exist some constant such that","(\epsilon_i)_{i = 1}^n (X_i)_{i = 1}^n (\epsilon_i)_{i = 1}^n |f(x, z_1) - f(x, z_2)| < L(x) |z_1 - z_2| 
    \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i \big( f(X_i, z_1) - f(X_i, z_2) \big) \bigg|.
  \big( f(X_i, z_1) - f(X_i, z_2) \big) \leq L(X_i) |z_1 - z_2| |z_1 - z_2| \cdot \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i L(X_i)\bigg| \epsilon_i C 
    \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i \big( f(X_i, z_1) - f(X_i, z_2) \big) \bigg| \leq C \cdot |z_1 - z_2| \cdot \mathrm{E} \bigg| \sum_{i = 1}^n \epsilon_i L(X_i)\bigg|
","['probability', 'statistics', 'inequality', 'probability-distributions']"
92,Normal distribution of the mean of a uniform distribution,Normal distribution of the mean of a uniform distribution,,"I have $\bar{X}$ which is the mean of the numbers from the uniform distribution of $[0, 1]$ with $n = 100$ . I know that $\mu = \frac{1}{2}$ and $\sigma^2 = \frac{1}{1200}$ , thus, $\sigma \approx 0.028 $ , I need to find the probability of $\bar{X}$ having a value between $[0.47, 0.53]$ . Calculating the normal distribution, I find $1 - 2(0.3508) = 0.2984$ , however the book says the answer is $0.7016$ . It is easy to see that $1 - 0.2984 = 0.7016$ , and it makes me sure that I'm in the right path. I just don't know why I should subtract the value I found in the distribution from $1$ , and it makes me think the book forgot one step before finishing the exercise. Could someone clarify this for me?","I have which is the mean of the numbers from the uniform distribution of with . I know that and , thus, , I need to find the probability of having a value between . Calculating the normal distribution, I find , however the book says the answer is . It is easy to see that , and it makes me sure that I'm in the right path. I just don't know why I should subtract the value I found in the distribution from , and it makes me think the book forgot one step before finishing the exercise. Could someone clarify this for me?","\bar{X} [0, 1] n = 100 \mu = \frac{1}{2} \sigma^2 = \frac{1}{1200} \sigma \approx 0.028  \bar{X} [0.47, 0.53] 1 - 2(0.3508) = 0.2984 0.7016 1 - 0.2984 = 0.7016 1","['statistics', 'normal-distribution']"
93,"Given IID normal random variables $X_1, \ldots, X_n$, show that $(X_1 - \bar{X})/S$ is ancillary.","Given IID normal random variables , show that  is ancillary.","X_1, \ldots, X_n (X_1 - \bar{X})/S","This has been bugging me for the past day, and I just can't seem to figure it out. Suppose $X_i \sim N(\mu, \sigma^2)$ for $i=1, \ldots, n$ are IID, where $\mu \in \mathbb{R}$ and $\sigma^2>0$ are unknown. I want to show that $Z = \frac{X_1 - \bar{X}}{S}$ is an ancillary statistic (its distribution is independent of $\mu$ and $\sigma$ ). Basically, I need to calculate the distribution of $Z$ . I know that the formula for the density of $Z$ is given by (Shao, Mathematical Statistics , pg. 165 eq (3.1)): $$  f(z) = \frac{\sqrt{n}\Gamma(\frac{n-1}{2})}{\sqrt{\pi}(n-1)\Gamma(\frac{n-2}{2})} \bigg[ 1 - \frac{nz^2}{(n-1)^2}\bigg]^{(n/2) - 2} I_{(0, (n-1)/\sqrt{n})}(|z|) $$ but I have no idea how to derive this result. Presumably you use some transformation, but I just can't seem to find the right one. I don't need a full solution, mostly just some help getting started. Thanks! Oh, and $\bar{X}$ and $S^2$ are the sample mean and sample variance, respectively.","This has been bugging me for the past day, and I just can't seem to figure it out. Suppose for are IID, where and are unknown. I want to show that is an ancillary statistic (its distribution is independent of and ). Basically, I need to calculate the distribution of . I know that the formula for the density of is given by (Shao, Mathematical Statistics , pg. 165 eq (3.1)): but I have no idea how to derive this result. Presumably you use some transformation, but I just can't seem to find the right one. I don't need a full solution, mostly just some help getting started. Thanks! Oh, and and are the sample mean and sample variance, respectively.","X_i \sim N(\mu, \sigma^2) i=1, \ldots, n \mu \in \mathbb{R} \sigma^2>0 Z = \frac{X_1 - \bar{X}}{S} \mu \sigma Z Z 
 f(z) = \frac{\sqrt{n}\Gamma(\frac{n-1}{2})}{\sqrt{\pi}(n-1)\Gamma(\frac{n-2}{2})} \bigg[ 1 - \frac{nz^2}{(n-1)^2}\bigg]^{(n/2) - 2} I_{(0, (n-1)/\sqrt{n})}(|z|)
 \bar{X} S^2","['statistics', 'probability-distributions', 'normal-distribution']"
94,Statistics - What is the random error of a measurement with one reading?,Statistics - What is the random error of a measurement with one reading?,,"To calculate the random error in a set of measurements this is what I would do. Get the standard deviation of the measurements: $$ \sigma=\sqrt{\frac{1}{N-1}\Sigma_{i=1}^N(x_i-\bar{x})^2} $$ Where $N$ is the number of repeats, $x_i$ is the value of each sample, $\bar{x}$ is the mean, and $\sigma$ is the standard deviation. The standard error of the mean: $$ s_\bar{x}=\frac{\sigma}{\sqrt{N}} $$ Obtain the random error using a t distribution: $$ \varepsilon_{rnd}=±t_{N-1}*s_\bar{x} $$ The problem is, if I have a measurement with a single reading of a given value, this method for random error calculation is clearly no longer applicable. Therefore, how would you go about calculating the random error in a for a sample set where N=1? Is that even possible? Thanks for your time!","To calculate the random error in a set of measurements this is what I would do. Get the standard deviation of the measurements: Where is the number of repeats, is the value of each sample, is the mean, and is the standard deviation. The standard error of the mean: Obtain the random error using a t distribution: The problem is, if I have a measurement with a single reading of a given value, this method for random error calculation is clearly no longer applicable. Therefore, how would you go about calculating the random error in a for a sample set where N=1? Is that even possible? Thanks for your time!", \sigma=\sqrt{\frac{1}{N-1}\Sigma_{i=1}^N(x_i-\bar{x})^2}  N x_i \bar{x} \sigma  s_\bar{x}=\frac{\sigma}{\sqrt{N}}   \varepsilon_{rnd}=±t_{N-1}*s_\bar{x} ,"['statistics', 'standard-deviation', 'standard-error']"
95,Expected Value and Variance of Random Variable Divided by Another Random Variable,Expected Value and Variance of Random Variable Divided by Another Random Variable,,"Let $N$ be a random variable taking values $1,2,...,n$ , with known probabilities $p_1,p_2,...,p_n$ , where $\sum_i p_i = 1$ . Furthermore let $X \sim binomial(N,\theta)$ . Consider now the estimator $\frac{X}{N}$ and show that $E(\frac{X}{N}) = \theta$ , and $Var(\frac{X}{N}) = \theta(1-\theta)E(\frac{1}{N})$ So far Im struggling to find the expected value. I know that $E(\frac{X}{N}) = E(X) \cdot E(\frac{1}{N}) = n \theta E(\frac{1}{N}).$ The formula for $E(\frac{1}{N})$ is $E(\frac{1}{N}) = \sum_i \frac{1}{i} p_i$ but not sure how to determine this sum. Also not sure what formula to apply to calculate the variance. Would appreciate any help.","Let be a random variable taking values , with known probabilities , where . Furthermore let . Consider now the estimator and show that , and So far Im struggling to find the expected value. I know that The formula for is but not sure how to determine this sum. Also not sure what formula to apply to calculate the variance. Would appreciate any help.","N 1,2,...,n p_1,p_2,...,p_n \sum_i p_i = 1 X \sim binomial(N,\theta) \frac{X}{N} E(\frac{X}{N}) = \theta Var(\frac{X}{N}) = \theta(1-\theta)E(\frac{1}{N}) E(\frac{X}{N}) = E(X) \cdot E(\frac{1}{N}) = n \theta E(\frac{1}{N}). E(\frac{1}{N}) E(\frac{1}{N}) = \sum_i \frac{1}{i} p_i","['statistics', 'random-variables', 'expected-value', 'variance']"
96,Maximum likelihood estimation intuition for continuous distributions,Maximum likelihood estimation intuition for continuous distributions,,"I was just revisiting the fundamentals and rationale of maximum likelihood estimation when I realised I can't rationalise the continuous case as opposed to the discrete case. For a discrete random variable, say $X$ , with PMF $p_X(x\mid\theta)$ , suppose we have an i.i.d sample $(X_1, X_2, \ldots, X_n)$ from this distribution. Then, the joint PMF will be given by: $$p_{X_1,\ldots,X_n}(x_1,\ldots,x_n\mid\theta) = \prod_{i=1}^n p_X(x_i\mid\theta).$$ We can use the joint PMF here to calculate probabilities of specific vectors, like the probability that $(X_1, \ldots, X_n)$ actually took on observed values $(x_1, \ldots, x_n)$ . However, this depends on the fixed $\theta$ . The MLE methodology suggests that we look for a value of $\theta$ that maximises the probability that $(X_1, \ldots, X_n) = (x_1, \ldots, x_n)$ . This is why we have $$ L(\theta \mid x_1,\ldots,x_n) = \prod_{i=1}^n p_X(x_i\mid\theta),$$ which outputs the probability of the observed values occurring, depending on the value of $\theta$ we select. This function makes sense to maximise as it directly corresponds to probability values (though $L$ is not a PMF/PDF itself). My confusion arises when we have $X$ continuous, with PDF $f_X(x\mid\theta)$ . We have the joint PDF $$ f_{X_1,\ldots,X_n}(x_1,\ldots,x_n\mid\theta)=\prod_{i=1}^n f_X(x_i\mid\theta). $$ Now differently, this function evaluated on the observed data $(x_1,\ldots,x_n)$ does NOT correspond to the probability of the sample occurring under the distribution $f$ . Of course, the probability that the vector $ (X_1, \ldots, X_n) $ is equal to the particular sample is $0$ since the distribution is now continuous. So why is the next step to maximise the joint density's value evaluated on the data instead? Is this because the volume under the joint PDF around the observed point $(x_1,\ldots,x_n)$ would increase? I'm trying to conceptualise the trivial case where $n=1$ and MLE suggests I simply select a $\theta$ to maximise $f_{X_1}$ at the observed point. But I can't figure out why that would maximise the probability of observing $x_1$ itself. This question might be a little trivial, but I'm struggling to find any answers on this specific concept. Any help is appreciated! Thank you :)","I was just revisiting the fundamentals and rationale of maximum likelihood estimation when I realised I can't rationalise the continuous case as opposed to the discrete case. For a discrete random variable, say , with PMF , suppose we have an i.i.d sample from this distribution. Then, the joint PMF will be given by: We can use the joint PMF here to calculate probabilities of specific vectors, like the probability that actually took on observed values . However, this depends on the fixed . The MLE methodology suggests that we look for a value of that maximises the probability that . This is why we have which outputs the probability of the observed values occurring, depending on the value of we select. This function makes sense to maximise as it directly corresponds to probability values (though is not a PMF/PDF itself). My confusion arises when we have continuous, with PDF . We have the joint PDF Now differently, this function evaluated on the observed data does NOT correspond to the probability of the sample occurring under the distribution . Of course, the probability that the vector is equal to the particular sample is since the distribution is now continuous. So why is the next step to maximise the joint density's value evaluated on the data instead? Is this because the volume under the joint PDF around the observed point would increase? I'm trying to conceptualise the trivial case where and MLE suggests I simply select a to maximise at the observed point. But I can't figure out why that would maximise the probability of observing itself. This question might be a little trivial, but I'm struggling to find any answers on this specific concept. Any help is appreciated! Thank you :)","X p_X(x\mid\theta) (X_1, X_2, \ldots, X_n) p_{X_1,\ldots,X_n}(x_1,\ldots,x_n\mid\theta) = \prod_{i=1}^n p_X(x_i\mid\theta). (X_1, \ldots, X_n) (x_1, \ldots, x_n) \theta \theta (X_1, \ldots, X_n) = (x_1, \ldots, x_n)  L(\theta \mid x_1,\ldots,x_n) = \prod_{i=1}^n p_X(x_i\mid\theta), \theta L X f_X(x\mid\theta)  f_{X_1,\ldots,X_n}(x_1,\ldots,x_n\mid\theta)=\prod_{i=1}^n f_X(x_i\mid\theta).  (x_1,\ldots,x_n) f  (X_1, \ldots, X_n)  0 (x_1,\ldots,x_n) n=1 \theta f_{X_1} x_1","['probability', 'statistics', 'intuition', 'estimation', 'maximum-likelihood']"
97,A modified median,A modified median,,"Assume we have real numbers $x_1 < x_2 < \dots < x_n$ . Consider the following function which returns the average distance of a point $t$ from $x_1,\dots,x_n.$ $$ D_1(t) = \frac{1}{n}\sum_{i=1}^n|x_i - t|. $$ It is well known that $D_1(t)$ is minimized at a median of $x_1,\dots,x_n$ . I am interested in the centrality parameter that is obtained when the mean is replaced by the median above (you may assume $n$ is odd and $n \geq 3$ if it helps). So, my question is this : Is there a simple expression for $$ \arg\min D_2(t) $$ where $$ D_2(t) = \operatorname{median}\{|x_1-t|,\dots,|x_n-t|\}? $$ I have done some numerical experiments. I think that there is always a minimum at a point of the form $\frac{x_i + x_j}{2}$ where $i \leq j$ and $\frac{x_i+x_j}{2}\leq x_{i+1}.$ This problem is combinatorial because one has to keep track of how the order of $|x_i - t|$ 's change as $t$ changes. Update: User Joe has conjectured that if $n=2k+1$ is odd then the minimum occurs that $t = \frac{x_m + x_{m+k}}{2}$ where $m = \arg\min (x_{m+k} - x_m)$ . The plot of the objective function for $1, 2, 3, 10, 11, 12, 20$ shows that a median may not be the minimizer. The conjecture is valid here (k=3), a minimum occurs at $\frac{x_1+x_4}{2}$ and $x_4-x_1=9$ . Another example where the conjecture is valid. Here $k=4$ and the minimum occurs at $\frac{x_1+x_5}{2}=3.$","Assume we have real numbers . Consider the following function which returns the average distance of a point from It is well known that is minimized at a median of . I am interested in the centrality parameter that is obtained when the mean is replaced by the median above (you may assume is odd and if it helps). So, my question is this : Is there a simple expression for where I have done some numerical experiments. I think that there is always a minimum at a point of the form where and This problem is combinatorial because one has to keep track of how the order of 's change as changes. Update: User Joe has conjectured that if is odd then the minimum occurs that where . The plot of the objective function for shows that a median may not be the minimizer. The conjecture is valid here (k=3), a minimum occurs at and . Another example where the conjecture is valid. Here and the minimum occurs at","x_1 < x_2 < \dots < x_n t x_1,\dots,x_n. 
D_1(t) = \frac{1}{n}\sum_{i=1}^n|x_i - t|.
 D_1(t) x_1,\dots,x_n n n \geq 3  \arg\min D_2(t)  
D_2(t) = \operatorname{median}\{|x_1-t|,\dots,|x_n-t|\}?
 \frac{x_i + x_j}{2} i \leq j \frac{x_i+x_j}{2}\leq x_{i+1}. |x_i - t| t n=2k+1 t = \frac{x_m + x_{m+k}}{2} m = \arg\min (x_{m+k} - x_m) 1, 2, 3, 10, 11, 12, 20 \frac{x_1+x_4}{2} x_4-x_1=9 k=4 \frac{x_1+x_5}{2}=3.","['combinatorics', 'statistics', 'optimization']"
98,How to Derive this Formula for Expected n-Way Collisions?,How to Derive this Formula for Expected n-Way Collisions?,,"I learned from the first answer to https://crypto.stackexchange.com/questions/24660/the-effect-of-truncated-hash-on-entropy (by formidable contributor fgrieu) that when $N$ uniform random selections are made from a finite set of $N$ elements, the probability that any particular element will be selected exactly $j$ times $\displaystyle\approx\frac 1{e\;j!}$ , so the expected number of elements selected $j$ times $\displaystyle\approx\frac N{e\;j!}$ . The approximation is very rough for small $N$ and seems to converge gradually.  For sufficiently large $N$ (certainly by $10^9$ ) it works very well. Contributor fgrieu even included the results of computational experiments for $N = 2^{35}$ , confirming that this formula is very accurate for small $j$ , and ""breaks down"" only when $j$ is near its maximum. The author wrote that ""we can establish"" this expression ""by counting of the possibilities."" I've been trying to derive the formula myself, and searched for a derivation online, so far without success. I think I grasp the presence of fundamental constant $e$ ; for example, a classic gambler's problem asks ""if the probability of winning a play is $\frac 1 n$ , what is the probability of making $n$ plays without winning?""  The probability of losing each play is $1 - \frac 1 n$ , so the probability of losing $n$ in a row is $\left( 1 - \frac 1 n \right)^n$ , and $$\lim\limits_{n \to \infty} \left( 1 - \frac 1 n \right)^n = \frac 1 e$$ giving the asymptotic proportion of zero-win outcomes. This also exactly accords with fgrieu's formula for the case $j=0$ . I've made no progress, however, justifying the formula's divisor $j!$ .  I thought about $j!$ as the number of distinct orderings of selections of a given element in the sequence of $N$ selections, but didn't see that leading anywhere.  I enumerated every possible selection sequence for some tiny cases with very small $N$ , looking for patterns in those sequences resulting in $j$ -way collisions, without seeing the light.  [Exhaustive enumeration is a desperate exercise of size $N^N$ ; its appeal was that under the premise of uniform random selection every sequence is equally probable, so counting sequences with particular outcomes is a direct measure of probability.] I've pondered the implicit recurrence that for $j > 0$ , the probability a particular element will be selected exactly $j$ times equals $\frac 1 j $ times the probability it will be selected $j-1$ times ... but I have yet to find an explanation of why this must be so. My intuition is that the derivation is simple, and I'm missing something that's right in front of me.  My thanks to any and all who will help me see it.","I learned from the first answer to https://crypto.stackexchange.com/questions/24660/the-effect-of-truncated-hash-on-entropy (by formidable contributor fgrieu) that when uniform random selections are made from a finite set of elements, the probability that any particular element will be selected exactly times , so the expected number of elements selected times . The approximation is very rough for small and seems to converge gradually.  For sufficiently large (certainly by ) it works very well. Contributor fgrieu even included the results of computational experiments for , confirming that this formula is very accurate for small , and ""breaks down"" only when is near its maximum. The author wrote that ""we can establish"" this expression ""by counting of the possibilities."" I've been trying to derive the formula myself, and searched for a derivation online, so far without success. I think I grasp the presence of fundamental constant ; for example, a classic gambler's problem asks ""if the probability of winning a play is , what is the probability of making plays without winning?""  The probability of losing each play is , so the probability of losing in a row is , and giving the asymptotic proportion of zero-win outcomes. This also exactly accords with fgrieu's formula for the case . I've made no progress, however, justifying the formula's divisor .  I thought about as the number of distinct orderings of selections of a given element in the sequence of selections, but didn't see that leading anywhere.  I enumerated every possible selection sequence for some tiny cases with very small , looking for patterns in those sequences resulting in -way collisions, without seeing the light.  [Exhaustive enumeration is a desperate exercise of size ; its appeal was that under the premise of uniform random selection every sequence is equally probable, so counting sequences with particular outcomes is a direct measure of probability.] I've pondered the implicit recurrence that for , the probability a particular element will be selected exactly times equals times the probability it will be selected times ... but I have yet to find an explanation of why this must be so. My intuition is that the derivation is simple, and I'm missing something that's right in front of me.  My thanks to any and all who will help me see it.",N N j \displaystyle\approx\frac 1{e\;j!} j \displaystyle\approx\frac N{e\;j!} N N 10^9 N = 2^{35} j j e \frac 1 n n 1 - \frac 1 n n \left( 1 - \frac 1 n \right)^n \lim\limits_{n \to \infty} \left( 1 - \frac 1 n \right)^n = \frac 1 e j=0 j! j! N N j N^N j > 0 j \frac 1 j  j-1,"['probability', 'combinatorics', 'statistics']"
99,What is the most general distribution for which E[1/x] = 1/E[x]?,What is the most general distribution for which E[1/x] = 1/E[x]?,,"What is the most general distribution for which the expected value of the multiplicative inverse equals the multiplicative inverse of the expected value? Motivation: I'm into modelling dynamics on graphs and I found a problem which is easily solvable in cases where the degree distribution of the vertices is a distribution where $E[1/k] = 1/E[k]$ . ( $k_i$ is the degree of the $i$ th vertex) From this solution I may gain an insight into how to unify multiple models. So particularly I'm looking for a distribution which consists of non-negative, finite integers . But I'm also interested in continuous solutions. Distributions where $E[1/k^n]=1/E[k^n]$ may also help unifying the models. What I do know so far , that $k_i=1$ is a particular solution. In the continuous case every function where $f(x)=f(1/x)$ and $E[x]=1$ is a solution. I know what momentum generating functions are and they seem like a good direction to try in, but I failed so far. What is the most general form of this distribution? Does it have a name? It sounds like something trivial, like a ""famous"" distribution, but I can't find it.","What is the most general distribution for which the expected value of the multiplicative inverse equals the multiplicative inverse of the expected value? Motivation: I'm into modelling dynamics on graphs and I found a problem which is easily solvable in cases where the degree distribution of the vertices is a distribution where . ( is the degree of the th vertex) From this solution I may gain an insight into how to unify multiple models. So particularly I'm looking for a distribution which consists of non-negative, finite integers . But I'm also interested in continuous solutions. Distributions where may also help unifying the models. What I do know so far , that is a particular solution. In the continuous case every function where and is a solution. I know what momentum generating functions are and they seem like a good direction to try in, but I failed so far. What is the most general form of this distribution? Does it have a name? It sounds like something trivial, like a ""famous"" distribution, but I can't find it.",E[1/k] = 1/E[k] k_i i E[1/k^n]=1/E[k^n] k_i=1 f(x)=f(1/x) E[x]=1,"['statistics', 'discrete-mathematics']"
