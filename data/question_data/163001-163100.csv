,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"What is an example of a covering of the set of irrational numbers in the interval $[0,1]$, with a total length of $1$?","What is an example of a covering of the set of irrational numbers in the interval , with a total length of ?","[0,1] 1","Let $E$ be the set of rationals in the interval $A=[0,1]$ , and let $F$ be the set of irrationals in $A$ . Then, $m^*(E)=0$ since $E$ is countable, and so, by the definition of Lebesgue measurable sets, $m^*(F)=1$ , since $m^*(A)=1$ . That is, $m^*(A)=m^*(A \cap E)+m^*(A \cap E^C)  \implies 1=m^*(E)+m^*(F)$ . However, I find the result $m^*(F)=1$ rather surprising. What is an example of a covering of open sets of $F$ with total length $1$ ?  The obvious answer would be $\{(0,1)\}$ , but how do I show that there does not exist a covering with a smaller length, e.g. of length $0$ ? In other words, I'm looking for an alternative derivation of the result $m^*(F)=1$ .  One that is done more directly from the definition of $m^*$ , i.e. involving a covering of open sets of the set $F$ .","Let be the set of rationals in the interval , and let be the set of irrationals in . Then, since is countable, and so, by the definition of Lebesgue measurable sets, , since . That is, . However, I find the result rather surprising. What is an example of a covering of open sets of with total length ?  The obvious answer would be , but how do I show that there does not exist a covering with a smaller length, e.g. of length ? In other words, I'm looking for an alternative derivation of the result .  One that is done more directly from the definition of , i.e. involving a covering of open sets of the set .","E A=[0,1] F A m^*(E)=0 E m^*(F)=1 m^*(A)=1 m^*(A)=m^*(A \cap E)+m^*(A \cap E^C)  \implies 1=m^*(E)+m^*(F) m^*(F)=1 F 1 \{(0,1)\} 0 m^*(F)=1 m^* F","['measure-theory', 'lebesgue-measure', 'irrational-numbers', 'measurable-sets']"
1,Borel $\sigma$-algebra of a Borel subset,Borel -algebra of a Borel subset,\sigma,"Let $(X, \tau)$ be a topological space. Then $\sigma(\tau)$ is the Borel $\sigma$ -algebra on $(X, \tau)$ . For any subset $Y \subseteq X$ the subspace topology on $Y$ is $\tau|Y = \{ G \cap Y \mid G \in \tau \}$ and the trace $\sigma$ -algebra on $Y$ is $\sigma(\tau)|Y = \{ B \cap Y \mid B \in \sigma(\tau) \}$ . It holds $\sigma(\tau|Y) = \sigma(\tau)|Y$ . If $Y \in \sigma(\tau)$ then $\sigma(\tau)|Y \subseteq \sigma(\tau)$ , hence $\sigma(\tau|Y) \subseteq \sigma(\tau)$ . Consider $X = \mathbb{R}^2$ , $\tau_e$ the Euclidean topology and $\tau_S$ the Sorgenfrey plane topology (generated by semi-open rectangles $[a, b) \times [c, d)$ ). Then $\tau_e \subsetneq \tau_S$ (open rectangles $(a,b) \times (c,d)$ can be written as a union of semi-open rectangles) but $\sigma(\tau_e) = \sigma(\tau_S)$ (since $[a, b) \times [c, d) \in \sigma(\tau_e)$ ). Consider the antidiagonal $Y := \{ (x, -x) \mid x \in \mathbb{R} \}$ . Then $Y$ is a $\tau_e$ -closed subset of $X$ , hence a $\tau_S$ -closed subset. For any $x \in \mathbb{R}$ it holds $\{ (x, -x) \} = ([x, x+1) \times [-x,-x+1)) \cap Y \in \tau_S|Y$ , i.e. every point in $Y$ is $\tau_S|Y$ -open in $Y$ . Therefore, $\tau_S|Y = \mathcal{P}(Y)$ is the discrete topology, hence $\sigma(\tau_S|Y) = \mathcal{P}(Y)$ . Now, since $Y$ is $\tau_S$ -closed in $X$ , we have $Y \in \sigma(\tau_S)$ and therefore $\sigma(\tau_S|Y) \subseteq \sigma(\tau_S) = \sigma(\tau_e)$ , hence $\mathcal{P}(Y) \subseteq \sigma(\tau_e)$ . But this is a contradiction (e.g. by comparing the cardinalities: $|Y| = \frak{c}$ , hence $|\mathcal{P}(Y)| = 2^{\frak{c}}$ while $|\sigma(\tau_e)| = \frak{c}$ because $\sigma(\tau_e)$ is generated by countably many sets (the open rectangles with rational endpoints); see also here ). What am I missing?","Let be a topological space. Then is the Borel -algebra on . For any subset the subspace topology on is and the trace -algebra on is . It holds . If then , hence . Consider , the Euclidean topology and the Sorgenfrey plane topology (generated by semi-open rectangles ). Then (open rectangles can be written as a union of semi-open rectangles) but (since ). Consider the antidiagonal . Then is a -closed subset of , hence a -closed subset. For any it holds , i.e. every point in is -open in . Therefore, is the discrete topology, hence . Now, since is -closed in , we have and therefore , hence . But this is a contradiction (e.g. by comparing the cardinalities: , hence while because is generated by countably many sets (the open rectangles with rational endpoints); see also here ). What am I missing?","(X, \tau) \sigma(\tau) \sigma (X, \tau) Y \subseteq X Y \tau|Y = \{ G \cap Y \mid G \in \tau \} \sigma Y \sigma(\tau)|Y = \{ B \cap Y \mid B \in \sigma(\tau) \} \sigma(\tau|Y) = \sigma(\tau)|Y Y \in \sigma(\tau) \sigma(\tau)|Y \subseteq \sigma(\tau) \sigma(\tau|Y) \subseteq \sigma(\tau) X = \mathbb{R}^2 \tau_e \tau_S [a, b) \times [c, d) \tau_e \subsetneq \tau_S (a,b) \times (c,d) \sigma(\tau_e) = \sigma(\tau_S) [a, b) \times [c, d) \in \sigma(\tau_e) Y := \{ (x, -x) \mid x \in \mathbb{R} \} Y \tau_e X \tau_S x \in \mathbb{R} \{ (x, -x) \} = ([x, x+1) \times [-x,-x+1)) \cap Y \in \tau_S|Y Y \tau_S|Y Y \tau_S|Y = \mathcal{P}(Y) \sigma(\tau_S|Y) = \mathcal{P}(Y) Y \tau_S X Y \in \sigma(\tau_S) \sigma(\tau_S|Y) \subseteq \sigma(\tau_S) = \sigma(\tau_e) \mathcal{P}(Y) \subseteq \sigma(\tau_e) |Y| = \frak{c} |\mathcal{P}(Y)| = 2^{\frak{c}} |\sigma(\tau_e)| = \frak{c} \sigma(\tau_e)",['measure-theory']
2,Is such a function measurable in the product measure space?,Is such a function measurable in the product measure space?,,"Let $(\Omega_T,\mathcal{A},\nu)$ be a product measure space. Given a vector function $f:\Omega_T\rightarrow \mathbb{R}^{m\times n}$ , we say that $f\in L^2(\Omega_T,\mathbb{R}^{m\times n})$ if $f$ is measurable with respect to $\nu$ and $$\int_{\Omega_T}\|f(t,\omega)\|^2d\nu<\infty.$$ Now $g(t,x(t,\omega))$ is a Caratheodory function (namely, for each fixd $x(t,\omega)\in\mathbb{R}^{mn}$ , $ g(\cdot,x)$ is measurable, and for every $t\in[0,T]$ , $ g(t,\cdot)$ is continuous) and $x(t,\omega)\in L^2(\Omega_T,\mathbb{R}^{m\times n})$ . Is this function $g(t,x(t,\omega))$ measurable with respect to $\nu$ ?In addition, the function g also satisfies the following conditions $$\exists h(t,\omega)\in L^2 :\|g(t,x(t,\omega)\|\leq h(t,\omega)+\|x(t,\omega)\|.$$ I want to prove that $g(t,x(t,\omega))$ is an $L^2-$ function, then I should first prove that it is measurable，but I don't know how to verify that it is measurable。","Let be a product measure space. Given a vector function , we say that if is measurable with respect to and Now is a Caratheodory function (namely, for each fixd , is measurable, and for every , is continuous) and . Is this function measurable with respect to ?In addition, the function g also satisfies the following conditions I want to prove that is an function, then I should first prove that it is measurable，but I don't know how to verify that it is measurable。","(\Omega_T,\mathcal{A},\nu) f:\Omega_T\rightarrow \mathbb{R}^{m\times n} f\in L^2(\Omega_T,\mathbb{R}^{m\times n}) f \nu \int_{\Omega_T}\|f(t,\omega)\|^2d\nu<\infty. g(t,x(t,\omega)) x(t,\omega)\in\mathbb{R}^{mn}  g(\cdot,x) t\in[0,T]  g(t,\cdot) x(t,\omega)\in L^2(\Omega_T,\mathbb{R}^{m\times n}) g(t,x(t,\omega)) \nu \exists h(t,\omega)\in L^2 :\|g(t,x(t,\omega)\|\leq h(t,\omega)+\|x(t,\omega)\|. g(t,x(t,\omega)) L^2-","['real-analysis', 'measure-theory']"
3,Does convolution of Borel measures have the cancellation property?,Does convolution of Borel measures have the cancellation property?,,"The convolution of two Borel measures $\mu$ and $\nu$ is given by $$(\mu * \nu)(E) = \int_{-\infty}^\infty \nu(E - x) \; \mu(d x).$$ I have been trying to figure out whether the following cancellation law holds for convolutions: $$\text{if } \nu \neq 0 \text{ and } \mu_1 * \nu = \mu_2 * \nu, \text{ then also } \mu_1 = \mu_2$$ Here I use $\mu = \nu$ to mean that $\mu(E) = \nu(E)$ for all Borel measurable $E$ . Intuitively, I feel that the cancellation property should hold, but I have seen examples of the cancellation property failing for very similar kinds of convolution, so I am unsure. Does the cancellation property above hold for convolution of measures? And if not, can we recover it by restricting for example to probability measures and/or continuous measures?","The convolution of two Borel measures and is given by I have been trying to figure out whether the following cancellation law holds for convolutions: Here I use to mean that for all Borel measurable . Intuitively, I feel that the cancellation property should hold, but I have seen examples of the cancellation property failing for very similar kinds of convolution, so I am unsure. Does the cancellation property above hold for convolution of measures? And if not, can we recover it by restricting for example to probability measures and/or continuous measures?","\mu \nu (\mu * \nu)(E) = \int_{-\infty}^\infty \nu(E - x) \; \mu(d x). \text{if } \nu \neq 0 \text{ and } \mu_1 * \nu = \mu_2 * \nu, \text{ then also } \mu_1 = \mu_2 \mu = \nu \mu(E) = \nu(E) E","['measure-theory', 'convolution']"
4,"If $\mu \ll \lambda$ and $\lambda \ll \mu$, then $L^p(\mu)$ and $L^p(\lambda)$ are isometric.","If  and , then  and  are isometric.",\mu \ll \lambda \lambda \ll \mu L^p(\mu) L^p(\lambda),"Let $\mu$ and $\lambda$ be two positive $\sigma$ -finite measures such that $\mu \ll \lambda$ and $\lambda \ll \mu$ , then $L^p(\mu)$ and $L^p(\lambda)$ are isometric. My attempt: Since $\mu \ll \lambda$ , by Radon-Nikodym theorem, exists $g \in L^1(\lambda)$ such that $d\mu = g d\lambda$ , i.e. $\int \chi_E d\mu = \int g \chi_E d\lambda$ for every measurable $E$ . Then, $$ \int f d\mu = \int gf d\lambda \quad (I) $$ holds for every simple measurable function. Then, $(I)$ holds for functions in $L^\infty$ (since simple functions are dense in $L^\infty$ ) and then $(I)$ holds for every $f \in L^p(\mu)$ , since $L^\infty$ is dense in $L^p$ . Using the same argument, since $\lambda \ll \mu$ , exists $h \in L^1(\mu)$ such that $$ \int f d\lambda = \int hf d\mu \quad(II) $$ holds for every $f \in L^p(\lambda)$ . I don't know how to proceed. Help?","Let and be two positive -finite measures such that and , then and are isometric. My attempt: Since , by Radon-Nikodym theorem, exists such that , i.e. for every measurable . Then, holds for every simple measurable function. Then, holds for functions in (since simple functions are dense in ) and then holds for every , since is dense in . Using the same argument, since , exists such that holds for every . I don't know how to proceed. Help?",\mu \lambda \sigma \mu \ll \lambda \lambda \ll \mu L^p(\mu) L^p(\lambda) \mu \ll \lambda g \in L^1(\lambda) d\mu = g d\lambda \int \chi_E d\mu = \int g \chi_E d\lambda E  \int f d\mu = \int gf d\lambda \quad (I)  (I) L^\infty L^\infty (I) f \in L^p(\mu) L^\infty L^p \lambda \ll \mu h \in L^1(\mu)  \int f d\lambda = \int hf d\mu \quad(II)  f \in L^p(\lambda),"['real-analysis', 'integration', 'measure-theory', 'radon-nikodym']"
5,Volume of compact rectangle in $\mathbb{R}^d$,Volume of compact rectangle in,\mathbb{R}^d,"Very often I find difficult to prove what it seems obvious. This is the problem: Let $R\subseteq \mathbb{R}^d$ a compact rectangle and $R_1,\ldots,R_n$ open rectangles such that $R\subseteq R_1\cup\ldots\cup R_n$ . Then show that $v(R) \le v(R_1)+\ldots + v(R_n)$ Now my guess is, since $\cup R_i$ is open then we can write it like a union of nonoverlapping cubes and then we take volumes. Thanks in advance for your help.","Very often I find difficult to prove what it seems obvious. This is the problem: Let a compact rectangle and open rectangles such that . Then show that Now my guess is, since is open then we can write it like a union of nonoverlapping cubes and then we take volumes. Thanks in advance for your help.","R\subseteq \mathbb{R}^d R_1,\ldots,R_n R\subseteq R_1\cup\ldots\cup R_n v(R) \le v(R_1)+\ldots + v(R_n) \cup R_i","['real-analysis', 'measure-theory', 'lebesgue-measure']"
6,$\quad A\subset\mathbb{R}$ is measurable and $m(A)>0$. then $m\left(\mathbb{R}-\bigcup_{q\in\mathbb{Q}}q\cdot A\right)=0$. [duplicate],is measurable and . then . [duplicate],\quad A\subset\mathbb{R} m(A)>0 m\left(\mathbb{R}-\bigcup_{q\in\mathbb{Q}}q\cdot A\right)=0,"This question already has answers here : Minkowski sum of a positive Lebesgue measure set and $\mathbb{Q}$. (2 answers) Closed 5 years ago . $\quad A\subset\mathbb{R}$ is measurable and $m(A)>0$ . then $m\left(\mathbb{R}-\bigcup_{q\in\mathbb{Q}}q\cdot A\right)=0$ . How to prove it ? $ q \cdot A $ is a dilation or contraction of each element in $ A$ for example if $ A=(1 ,3],  2A= 2(1 ,3] = (2,6].$ The proof  is trivial if $ A $ is an interval or countable union of intervals but not so for arbitrary sets. This question is not a duplicate of link because taking logarithm $ log_{10} (qA) =log_{10}A+log_{10}q$ , $ log_{10} q $ is not always a rational number","This question already has answers here : Minkowski sum of a positive Lebesgue measure set and $\mathbb{Q}$. (2 answers) Closed 5 years ago . is measurable and . then . How to prove it ? is a dilation or contraction of each element in for example if The proof  is trivial if is an interval or countable union of intervals but not so for arbitrary sets. This question is not a duplicate of link because taking logarithm , is not always a rational number","\quad A\subset\mathbb{R} m(A)>0 m\left(\mathbb{R}-\bigcup_{q\in\mathbb{Q}}q\cdot A\right)=0  q \cdot A   A  A=(1 ,3],  2A= 2(1 ,3] = (2,6].  A   log_{10} (qA) =log_{10}A+log_{10}q  log_{10} q ","['real-analysis', 'measure-theory']"
7,Radon Nikodym derivative and density,Radon Nikodym derivative and density,,"Let $(X, M, \mu)$ be a measure space and $F:M \to \mathbb{R}$ be an absolutely continuous countably additive function(i.e., $F(\cup_n^\infty E_n) = \sum_n^\infty F(E_n)$ for disjoint $E_n \in M$ ). There is a Radon-Nikodym derivative $f$ and $F(E)=\int_E f d\mu$ . Does the following hold? $$f(x)=\lim_{\mu(E)\to 0, x\in E \in M} \frac{F(E)}{\mu(E)} (a.e.)$$ What I tried: It is enough to prove for the case $F\geq0$ . Let $\mathcal{F}$ be the set $\{ f\geq0| \forall E\in M. \int_Ef\mu\leq F(E)\}$ and $\alpha = \sup_{f \in \mathcal{F}}\int_Xf d\mu$ . If I select functions $f_n \in \mathcal{F}$ such that $\alpha = \lim_{n \to \infty} \int_X f_nd\mu$ , $\sup_{n\geq 1}f_n$ is a Radon-Nikodym derivative of $F$ . Hense I want to find $f_n$ in the form $f_n(x)=\frac{F(E_x)}{\mu(E_x)}$ for some $E_x \in M$ satisfying $x\in E_x$ , $\mu(E_x) < \frac{1}{n}$ and $f_n \in \mathcal{F}$ . Next, I want to prove $\alpha = \lim_{n \to \infty} \int_X f_nd\mu$ and $\sup_{n\geq 1} f_n = \lim_{\mu(E)\to 0} \frac{F(E)}{\mu(E)}(a.e.)$ . However, I do not know how to construct such measurable $f_n$ . Let $f$ be a Radon-Nikodym derivative of $F$ and $S$ be the set $\{x \in X | f(x) \neq \lim_{\mu(E)\to 0} \frac{F(E)}{\mu(E)}\}$ . $S=S_0 \cup \cup_{n \in \mathbb{N}}S_n$ , where $S_0$ is the set of $x$ where $\lim_{\mu(E)\to 0, x \in E} \frac{F(E)}{\mu(E)}$ does not converge and $S_n$ are the sets which the limit converges and $\left|\lim_{\mu(E)\to 0, x \in E} \frac{F(E)}{\mu(E)}- f(x)\right|> \frac{1}{n}$ . I want to prove $\mu(S_0)=0$ . Then, if $\mu(S)\neq 0$ , there is $S_n$ such that $\mu(S_n)\neq 0$ and I want to derive a contradiction using $S_n$ . However, I cannot prove them.","Let be a measure space and be an absolutely continuous countably additive function(i.e., for disjoint ). There is a Radon-Nikodym derivative and . Does the following hold? What I tried: It is enough to prove for the case . Let be the set and . If I select functions such that , is a Radon-Nikodym derivative of . Hense I want to find in the form for some satisfying , and . Next, I want to prove and . However, I do not know how to construct such measurable . Let be a Radon-Nikodym derivative of and be the set . , where is the set of where does not converge and are the sets which the limit converges and . I want to prove . Then, if , there is such that and I want to derive a contradiction using . However, I cannot prove them.","(X, M, \mu) F:M \to \mathbb{R} F(\cup_n^\infty E_n) = \sum_n^\infty F(E_n) E_n \in M f F(E)=\int_E f d\mu f(x)=\lim_{\mu(E)\to 0, x\in E \in M} \frac{F(E)}{\mu(E)} (a.e.) F\geq0 \mathcal{F} \{ f\geq0| \forall E\in M. \int_Ef\mu\leq F(E)\} \alpha = \sup_{f \in \mathcal{F}}\int_Xf d\mu f_n \in \mathcal{F} \alpha = \lim_{n \to \infty} \int_X f_nd\mu \sup_{n\geq 1}f_n F f_n f_n(x)=\frac{F(E_x)}{\mu(E_x)} E_x \in M x\in E_x \mu(E_x) < \frac{1}{n} f_n \in \mathcal{F} \alpha = \lim_{n \to \infty} \int_X f_nd\mu \sup_{n\geq 1} f_n = \lim_{\mu(E)\to 0} \frac{F(E)}{\mu(E)}(a.e.) f_n f F S \{x \in X | f(x) \neq \lim_{\mu(E)\to 0} \frac{F(E)}{\mu(E)}\} S=S_0 \cup \cup_{n \in \mathbb{N}}S_n S_0 x \lim_{\mu(E)\to 0, x \in E} \frac{F(E)}{\mu(E)} S_n \left|\lim_{\mu(E)\to 0, x \in E} \frac{F(E)}{\mu(E)}- f(x)\right|> \frac{1}{n} \mu(S_0)=0 \mu(S)\neq 0 S_n \mu(S_n)\neq 0 S_n",['measure-theory']
8,Reference of the ergodic theorem in continuous time,Reference of the ergodic theorem in continuous time,,"Let $(\Omega,\mathcal A,\operatorname P)$ be a probability space and $\tau_t:\Omega\to\Omega$ for $t\ge0$ such that $\tau_0=\operatorname{id}_\Omega$ $\tau_{s+t}=\tau_s\tau_t$ for all $s,t\ge0$ $\tau:\Omega\times[0,\infty)\to\Omega$ is $\left(\mathcal A\otimes\mathcal B\left([0,\infty)\right),\mathcal A\right)$ -measurable $\operatorname P\circ\:\tau_t^{-1}=\operatorname P$ for all $t\ge0$ Now, let $$\mathcal I:=\left\{A\in\mathcal A:\tau_t^{-1}(A)=A\text{ for all }t\ge0\right\}.$$ I'm searching for a reference (with proof) of the ergodic theorem of the following form: If $p\in[1,\infty)$ and $F\in\mathcal L^1(\operatorname P)$ , then $$\frac1t\int_0^tF\circ\tau_t\:{\rm d}t\xrightarrow{t\to\infty}\operatorname E\left[F\mid\mathcal I\right]\tag1$$ almost surely and in $L^p(\operatorname P)$ . I was only able to find either the discrete-time analogue or the special where $\tau$ is the time-shift on the canonical probability space of a stochastic process.","Let be a probability space and for such that for all is -measurable for all Now, let I'm searching for a reference (with proof) of the ergodic theorem of the following form: If and , then almost surely and in . I was only able to find either the discrete-time analogue or the special where is the time-shift on the canonical probability space of a stochastic process.","(\Omega,\mathcal A,\operatorname P) \tau_t:\Omega\to\Omega t\ge0 \tau_0=\operatorname{id}_\Omega \tau_{s+t}=\tau_s\tau_t s,t\ge0 \tau:\Omega\times[0,\infty)\to\Omega \left(\mathcal A\otimes\mathcal B\left([0,\infty)\right),\mathcal A\right) \operatorname P\circ\:\tau_t^{-1}=\operatorname P t\ge0 \mathcal I:=\left\{A\in\mathcal A:\tau_t^{-1}(A)=A\text{ for all }t\ge0\right\}. p\in[1,\infty) F\in\mathcal L^1(\operatorname P) \frac1t\int_0^tF\circ\tau_t\:{\rm d}t\xrightarrow{t\to\infty}\operatorname E\left[F\mid\mathcal I\right]\tag1 L^p(\operatorname P) \tau","['measure-theory', 'reference-request', 'stochastic-processes', 'dynamical-systems', 'ergodic-theory']"
9,When does a subset of a Polish space meet all the orbits?,When does a subset of a Polish space meet all the orbits?,,"While I was studying Borel actions of Polish groups on Polish spaces (I assume of measure $1$ ), I have tried to understand if a measure $1$ (hence dense) subset of this Polish space meets all the orbits; more precisely, the question naturally arose because I want to solve the following problem: Assume $X$ , $Y$ be standard Borel spaces (Polish space equipped with the $\sigma$ -algebra generated by open sets), that $\mu$ be an (possibly ergodic) invariant Borel probability measure on $X$ and that $f\colon A\subseteq X\to Y$ be a Borel function. If $G$ is a Polish locally compact group (I'm particularly interested in the case $G=SL_m(\mathbb{Z})$ ) acting (as a Borel map) on $X$ and $A$ has measure $1$ in $X$ (hence $\mu(G.A)=1$ by invariance), I would like to define a Borel function $f'$ on the whole space $X$ by means of a Borel function $c\colon X\to A$ (so that $f'=f\circ c$ is a Borel function from $X$ into $Y$ ) s.t. $c(x)$ belongs to the same equivalence class of $x$ . Here is my attempt: $\mu(A)=1$ implies that $A$ is dense in $X$ (because otherwise the existence of a non-empty open set disjoint from it leads to a contraddiction). Now, if $A$ meets every $G$ -orbit (I don't know  how to prove this), I guess I can define $c\colon X\to A$ by letting $c(x)=$ one element in $\mathrm{Orb}(x)\cap A$ . But I'm not sure this works also because in this way I need the Axiom of Choice to guarantee the existence of such a function (am I right?) Any hint? Thank you in advance for your help.","While I was studying Borel actions of Polish groups on Polish spaces (I assume of measure ), I have tried to understand if a measure (hence dense) subset of this Polish space meets all the orbits; more precisely, the question naturally arose because I want to solve the following problem: Assume , be standard Borel spaces (Polish space equipped with the -algebra generated by open sets), that be an (possibly ergodic) invariant Borel probability measure on and that be a Borel function. If is a Polish locally compact group (I'm particularly interested in the case ) acting (as a Borel map) on and has measure in (hence by invariance), I would like to define a Borel function on the whole space by means of a Borel function (so that is a Borel function from into ) s.t. belongs to the same equivalence class of . Here is my attempt: implies that is dense in (because otherwise the existence of a non-empty open set disjoint from it leads to a contraddiction). Now, if meets every -orbit (I don't know  how to prove this), I guess I can define by letting one element in . But I'm not sure this works also because in this way I need the Axiom of Choice to guarantee the existence of such a function (am I right?) Any hint? Thank you in advance for your help.",1 1 X Y \sigma \mu X f\colon A\subseteq X\to Y G G=SL_m(\mathbb{Z}) X A 1 X \mu(G.A)=1 f' X c\colon X\to A f'=f\circ c X Y c(x) x \mu(A)=1 A X A G c\colon X\to A c(x)= \mathrm{Orb}(x)\cap A,"['measure-theory', 'group-actions', 'descriptive-set-theory', 'measurable-functions', 'polish-spaces']"
10,Characterisation of point-mass distributions,Characterisation of point-mass distributions,,"Let X be non-empty and consider $a : X → [0,+\infty]$ . We define $\mu : 2^X → [0,\infty] $ by $$\mu(E)=\sum_{x\in E} a(x)$$ for every $E\subset X$ .   The measure ( proposition easy to prove ) on $(X,2^X)$ defined above is called the point-mass distribution on X induced by the function a . I am trying to solve the following exercise Let $X\neq\emptyset$ . Prove that every measure $\mu$ on $(X,2^X)$ is a point-mass distribution. So we want to define a function $a$ on X such that $$\mu(E)=\sum_{x\in E} a(x)$$ for every $E\subset X$ . If the set X is at most countable this obvious. We just have to take $a(x)=\mu(\{x\})$ , for every $x\in E$ and use the countable additivity of the measure to gain the result, since $E=\cup_{x\in E}\{x\}$ . But we can't use the same argument in the general case. Which is my question. Also, in order to solve the exercise, I tried to find the point-mass distribution for a specific measure on a general non-empty set X. So I considered the measure $\mu(E)=0$ , if $E$ is countable or else is $+\infty$ . Which confused me more.","Let X be non-empty and consider . We define by for every .   The measure ( proposition easy to prove ) on defined above is called the point-mass distribution on X induced by the function a . I am trying to solve the following exercise Let . Prove that every measure on is a point-mass distribution. So we want to define a function on X such that for every . If the set X is at most countable this obvious. We just have to take , for every and use the countable additivity of the measure to gain the result, since . But we can't use the same argument in the general case. Which is my question. Also, in order to solve the exercise, I tried to find the point-mass distribution for a specific measure on a general non-empty set X. So I considered the measure , if is countable or else is . Which confused me more.","a : X → [0,+\infty] \mu : 2^X → [0,\infty]  \mu(E)=\sum_{x\in E} a(x) E\subset X (X,2^X) X\neq\emptyset \mu (X,2^X) a \mu(E)=\sum_{x\in E} a(x) E\subset X a(x)=\mu(\{x\}) x\in E E=\cup_{x\in E}\{x\} \mu(E)=0 E +\infty",['measure-theory']
11,Understanding a remark for the Hausdorff measure in Wolff's lecture notes,Understanding a remark for the Hausdorff measure in Wolff's lecture notes,,"In the chapter of Hausdorff measures in Wolff's notes on harmonic analysis, I'm trying to understand a piece of remark. Fix $\alpha>0$ , and let $E\subset\mathbb{R}^n$ . For $\epsilon>0$ , one defines $$ H_\alpha^\epsilon(E)=\inf \sum_{j=1}^\infty r_j^\alpha, $$ where the infimum is taken over all countable coverings of $E$ by discs $D(x_j,r_j)$ with $r_j<\epsilon$ . It is clear that $H_\alpha^\epsilon(E)$ increases 1 as $\epsilon$ decreases, and we define $$ H_\alpha(E)=\lim_{\epsilon\to 0} H_\alpha^\epsilon(E). $$ 1. Note: I believe this should be understood as ""not decrease"" since if $H_\alpha^1(E)=0$ , then $H_\alpha(E)=0$ . Remark . It is clear that $H_\alpha(E)=0$ for all $E$ if $\alpha>n$ , since one can then cover $\mathbb{R}^n$ by discs $D(x_j,r_j)$ with $\sum_jr_j^\alpha$ arbitrarily small. I don't understand the remark. Could anyone elaborate it? By applying the inequality $$ \sum_j r_j^\alpha \le \delta^{\alpha-n}\sum_jr_j^n,\quad r_j<\delta, $$ one can show that if $H_n(E)<\infty$ , then $H_\alpha(E)=0$ for $\alpha>n$ . But the remark says something stronger.","In the chapter of Hausdorff measures in Wolff's notes on harmonic analysis, I'm trying to understand a piece of remark. Fix , and let . For , one defines where the infimum is taken over all countable coverings of by discs with . It is clear that increases 1 as decreases, and we define 1. Note: I believe this should be understood as ""not decrease"" since if , then . Remark . It is clear that for all if , since one can then cover by discs with arbitrarily small. I don't understand the remark. Could anyone elaborate it? By applying the inequality one can show that if , then for . But the remark says something stronger.","\alpha>0 E\subset\mathbb{R}^n \epsilon>0 
H_\alpha^\epsilon(E)=\inf \sum_{j=1}^\infty r_j^\alpha,
 E D(x_j,r_j) r_j<\epsilon H_\alpha^\epsilon(E) \epsilon 
H_\alpha(E)=\lim_{\epsilon\to 0} H_\alpha^\epsilon(E).
 H_\alpha^1(E)=0 H_\alpha(E)=0 H_\alpha(E)=0 E \alpha>n \mathbb{R}^n D(x_j,r_j) \sum_jr_j^\alpha 
\sum_j r_j^\alpha \le \delta^{\alpha-n}\sum_jr_j^n,\quad r_j<\delta,
 H_n(E)<\infty H_\alpha(E)=0 \alpha>n","['real-analysis', 'measure-theory']"
12,Regularity of measure in Lemma 7.2.6 of Bogachev,Regularity of measure in Lemma 7.2.6 of Bogachev,,"In the book ""Measure Theory"" of Bogachev, vol. 2, Lemma 7.2.6 states the following. Let $\mu$ be a $\tau$ -additive, regular Borel measure on a topological space $X$ , and let $\{f_\alpha\}$ be an increasing net of lower-semicontinuous non-negative functions such that $f:= \lim_\alpha f_\alpha$ is bounded. Then $$ \lim_\alpha \int_X f_\alpha \, d\mu \quad = \quad \int_X f \, d\mu . $$ In the proof it is quite clear where the $\tau$ -additivity comes into play. However, I cannot see why we need $\mu$ to be regular . Bogachev defines this property in the following way (paraphrasing its Definition 7.1.5): A measure $\mu$ on a topological space $X$ is called regular if for every measurable set $A\subseteq X$ and for every $\varepsilon > 0$ there exists a closed set $C_\varepsilon \subseteq A$ such that $\mu(A) - \mu(C_\varepsilon) < \varepsilon$ . Is regularity of $\mu$ in Lemma 7.2.6 then really necessary?","In the book ""Measure Theory"" of Bogachev, vol. 2, Lemma 7.2.6 states the following. Let be a -additive, regular Borel measure on a topological space , and let be an increasing net of lower-semicontinuous non-negative functions such that is bounded. Then In the proof it is quite clear where the -additivity comes into play. However, I cannot see why we need to be regular . Bogachev defines this property in the following way (paraphrasing its Definition 7.1.5): A measure on a topological space is called regular if for every measurable set and for every there exists a closed set such that . Is regularity of in Lemma 7.2.6 then really necessary?","\mu \tau X \{f_\alpha\} f:= \lim_\alpha f_\alpha 
\lim_\alpha \int_X f_\alpha \, d\mu \quad = \quad \int_X f \, d\mu .
 \tau \mu \mu X A\subseteq X \varepsilon > 0 C_\varepsilon \subseteq A \mu(A) - \mu(C_\varepsilon) < \varepsilon \mu","['measure-theory', 'lebesgue-integral', 'borel-measures']"
13,weak* convergence of convolution between mollifiers and Radon measure,weak* convergence of convolution between mollifiers and Radon measure,,"I've got a question concerning mollifiers. If $\Omega \subset \mathbb{R}^N$ is open and $\mu = (\mu_1,..., \mu_m)$ is a Radon measure in $\Omega$ . Let $(\rho_{\epsilon})_{\epsilon > 0}$ be a family of mollifiers. Why does $\mu_{\epsilon} := \mu * \rho_{\epsilon} \mathcal{L}^N$ locally weakly* converge in $\Omega$ to $\mu$ as $\epsilon$ goes to zero? I tried it using Fubini, but couldn't really see how it works out? Whereas a sequence of Radon measures $(\mu_h)_{h \in \mathbb{N}}$ is called weak* convergent if there exists a Radon measure $\mu$ such that for all $u \in C_0(\Omega)$ \begin{equation}  \lim\limits_{n \rightarrow \infty}{\int_{\Omega}} u d\mu_h = \int_{\Omega} u d\mu \end{equation} holds. The convolution of a measure $\mu$ and a continiuos function $f$ is defined as \begin{equation} \mu * f (x) := \int_{\Omega} f(x-y) d\mu(y) \end{equation} Thanks in advance!","I've got a question concerning mollifiers. If is open and is a Radon measure in . Let be a family of mollifiers. Why does locally weakly* converge in to as goes to zero? I tried it using Fubini, but couldn't really see how it works out? Whereas a sequence of Radon measures is called weak* convergent if there exists a Radon measure such that for all holds. The convolution of a measure and a continiuos function is defined as Thanks in advance!","\Omega \subset \mathbb{R}^N \mu = (\mu_1,..., \mu_m) \Omega (\rho_{\epsilon})_{\epsilon > 0} \mu_{\epsilon} := \mu * \rho_{\epsilon} \mathcal{L}^N \Omega \mu \epsilon (\mu_h)_{h \in \mathbb{N}} \mu u \in C_0(\Omega) \begin{equation}
 \lim\limits_{n \rightarrow \infty}{\int_{\Omega}} u d\mu_h = \int_{\Omega} u d\mu
\end{equation} \mu f \begin{equation}
\mu * f (x) := \int_{\Omega} f(x-y) d\mu(y)
\end{equation}","['real-analysis', 'measure-theory', 'convolution', 'weak-convergence', 'geometric-measure-theory']"
14,"Prove that if $E \subset \mathbb{R}^n $ has finite perimeter, then almost every vertical slice has finite perimeter too.","Prove that if  has finite perimeter, then almost every vertical slice has finite perimeter too.",E \subset \mathbb{R}^n ,"Before explaining my problem, I recall the definitions: Let $E \subset \mathbb{R}^n$ be a Lebesgue measurable set. We say that $E$ is a set of locally finite perimeter if for every compact set $K \subset \mathbb{R}^n$ it holds that \begin{equation*} \label{eq:deflocfiniteperimeter} M_K := \sup \left\{ \int_{E} div\, T(x) \,dx : T \in C^1_c( \mathbb{R}^n; \mathbb{R}^n), spt \,T \subset K, \| T \| \leq 1 \right\} < \infty. \end{equation*} Moreover, if $$ \sup\left\{M_K:K \subset  \mathbb{R}^n, K\text{compact}\right\}< \infty,$$ then we say that $E$ is a set of finite perimeter. Now suppose that $E$ is a set of finite perimeter. I have to prove that for $\mathcal{L}^{n-1}$ -a.e. $z \in \mathbb{R}^{n-1}$ the vertical slice $E_z \subset \mathbb{R}$ is a set of finite perimeter; where, by definition, $E_z := \{ t \in \mathbb{R} : (z,t ) \in E\}$ . I can only prove that for a.e. $z \in \mathbb{R}^{n-1}$ the vertical slice is a set of LOCALLY finite perimeter. Here I descrive my attempt: Let $\rho$ is a regulatizing kernel and consider the sequence $ u_{h} : = \chi_E * \rho_{1/h}$ : I already know (from a previous result) that $$ \limsup_{h \to \infty} \int_K |\nabla u_h(x)| dx \leq P(E;K)$$ for all compact sets $K \subset \mathbb{R}^{n}$ . Now fix a compact $J \subset \mathbb{R}$ . I have proved that if $T \in C^1_c(\mathbb{R})$ satisfies $\|T\| \leq 1$ and $J \supset spt T$ , then for a.e. $z \in \mathbb{R}^{n-1}$ it holds $$ \left| \int_{E_z} T'(t) \, dt \right| \leq \liminf_{h \to \infty} \int_{J} |\nabla u_h (z,t)| \, dt .$$ Taking the sup among the functions $T \in C^1_c(\mathbb{R})$ with $\|T\| \leq 1$ and $J \supset spt T$ and integrating on a compact set $H \subset \mathbb{R}^{n-1}$ , we get $$ \int_H \sup \left\{ \left| \int_{E_z} T' \right| : T \in C^1_c(\mathbb{R}), \, \|T\| \leq 1 , \, J \supset spt T \right\}  \leq \liminf_{h \to \infty} \int_{H \times J} |\nabla u_h| \leq P(E; H \times J ) \leq P(E) < \infty. $$ If the integral of a function is finite then the function is a.e. finite. Hence for a.e. $z$ we have $$ M_{J} := \sup \left\{ \left| \int_{E_z} T' \right| : T \in C^1_c(\mathbb{R}), \, \|T\| \leq 1 , \, J \supset spt T \right\} < \infty.$$ This proves that the set has locally finite perimeter but I can't find a uniform bound for $M_{J}$ . Any help would be really appreciated!","Before explaining my problem, I recall the definitions: Let be a Lebesgue measurable set. We say that is a set of locally finite perimeter if for every compact set it holds that Moreover, if then we say that is a set of finite perimeter. Now suppose that is a set of finite perimeter. I have to prove that for -a.e. the vertical slice is a set of finite perimeter; where, by definition, . I can only prove that for a.e. the vertical slice is a set of LOCALLY finite perimeter. Here I descrive my attempt: Let is a regulatizing kernel and consider the sequence : I already know (from a previous result) that for all compact sets . Now fix a compact . I have proved that if satisfies and , then for a.e. it holds Taking the sup among the functions with and and integrating on a compact set , we get If the integral of a function is finite then the function is a.e. finite. Hence for a.e. we have This proves that the set has locally finite perimeter but I can't find a uniform bound for . Any help would be really appreciated!","E \subset \mathbb{R}^n E K \subset \mathbb{R}^n \begin{equation*} \label{eq:deflocfiniteperimeter}
M_K := \sup \left\{ \int_{E} div\, T(x) \,dx : T \in C^1_c( \mathbb{R}^n; \mathbb{R}^n), spt \,T \subset K, \| T \| \leq 1 \right\} < \infty.
\end{equation*} 
\sup\left\{M_K:K \subset  \mathbb{R}^n, K\text{compact}\right\}< \infty, E E \mathcal{L}^{n-1} z \in \mathbb{R}^{n-1} E_z \subset \mathbb{R} E_z := \{ t \in \mathbb{R} : (z,t ) \in E\} z \in \mathbb{R}^{n-1} \rho  u_{h} : = \chi_E * \rho_{1/h}  \limsup_{h \to \infty} \int_K |\nabla u_h(x)| dx \leq P(E;K) K \subset \mathbb{R}^{n} J \subset \mathbb{R} T \in C^1_c(\mathbb{R}) \|T\| \leq 1 J \supset spt T z \in \mathbb{R}^{n-1}  \left| \int_{E_z} T'(t) \, dt \right| \leq \liminf_{h \to \infty} \int_{J} |\nabla u_h (z,t)| \, dt . T \in C^1_c(\mathbb{R}) \|T\| \leq 1 J \supset spt T H \subset \mathbb{R}^{n-1}  \int_H \sup \left\{ \left| \int_{E_z} T' \right| : T \in C^1_c(\mathbb{R}), \, \|T\| \leq 1 , \, J \supset spt T \right\}  \leq \liminf_{h \to \infty} \int_{H \times J} |\nabla u_h| \leq P(E; H \times J ) \leq P(E) < \infty.  z  M_{J} := \sup \left\{ \left| \int_{E_z} T' \right| : T \in C^1_c(\mathbb{R}), \, \|T\| \leq 1 , \, J \supset spt T \right\} < \infty. M_{J}","['real-analysis', 'integration', 'measure-theory', 'geometric-measure-theory']"
15,"Let $f: \Omega \to [0, \infty]$ be measurable. Let $\mu$ be $\sigma$-finite. Then $\{t\mid \mu\{f = t\} \neq 0 \}$ is countable.",Let  be measurable. Let  be -finite. Then  is countable.,"f: \Omega \to [0, \infty] \mu \sigma \{t\mid \mu\{f = t\} \neq 0 \}","Let $f: \Omega \to [0, \infty]$ be measurable. Let $\mu$ be $\sigma$ -finite. Then $\{t\mid \mu\{f = t\} \neq 0 \}$ is countable. My attempt: I managed to show the result if $\mu(\Omega) < \infty$ . If $\mu(\Omega) =\infty$ , I guess I'll have to use $\sigma$ -finiteness to lift the previous case. I took a sequence $(C_n)_n$ with $\mu(C_n) < \infty$ such that $C_n \uparrow \Omega$ . I then defined $\mu_n(A) := \mu(A \cap C_n)$ . Then $\mu_n$ is a $\sigma$ -finite measure and $\{t \mid \mu_n\{f = t\} \neq 0\}$ is at most countable. Observe now that $\mu = \lim_n \mu_n$ . From here, I'm stuck. Any ideas? (Note, the hypothesis that $\mu$ is $\sigma$ -finite might be irrelevant)","Let be measurable. Let be -finite. Then is countable. My attempt: I managed to show the result if . If , I guess I'll have to use -finiteness to lift the previous case. I took a sequence with such that . I then defined . Then is a -finite measure and is at most countable. Observe now that . From here, I'm stuck. Any ideas? (Note, the hypothesis that is -finite might be irrelevant)","f: \Omega \to [0, \infty] \mu \sigma \{t\mid \mu\{f = t\} \neq 0 \} \mu(\Omega) < \infty \mu(\Omega) =\infty \sigma (C_n)_n \mu(C_n) < \infty C_n \uparrow \Omega \mu_n(A) := \mu(A \cap C_n) \mu_n \sigma \{t \mid \mu_n\{f = t\} \neq 0\} \mu = \lim_n \mu_n \mu \sigma",['measure-theory']
16,Is the Norm of the $L^{2}$ Function Equal to the Given Limit?,Is the Norm of the  Function Equal to the Given Limit?,L^{2},"Let $g$ be an $L^{2}$ function on $[0,2]$ , with respect to the Lebesgue measure $m$ . Is it true that $$||g||_{1}=\lim_{p\to 1}\left(\int |g|^{p}~dm\right)^{1/p}?$$ I'm really not sure how to tackle this problem. I'm. assuming that the integral is taken over $[0,2]$ , but it wasn't explicitly given in the statement. I know that $\left(\int_{0}^{2}|g(x)|^{2}~dx\right)^{1/2}<\infty$ since $g\in L^{1}([0,2])$ , so my intuition is that the questioned equality does hold. However, I'm not sure if this is correct, and if it is, I'm not sure how to prove it. Any help is appreciated.","Let be an function on , with respect to the Lebesgue measure . Is it true that I'm really not sure how to tackle this problem. I'm. assuming that the integral is taken over , but it wasn't explicitly given in the statement. I know that since , so my intuition is that the questioned equality does hold. However, I'm not sure if this is correct, and if it is, I'm not sure how to prove it. Any help is appreciated.","g L^{2} [0,2] m ||g||_{1}=\lim_{p\to 1}\left(\int |g|^{p}~dm\right)^{1/p}? [0,2] \left(\int_{0}^{2}|g(x)|^{2}~dx\right)^{1/2}<\infty g\in L^{1}([0,2])","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'lp-spaces']"
17,Is $f$ integrable?,Is  integrable?,f,"Exercise 11.21 in Real Analysis for... by Richard Bass says:  Suppose $f: \mathbb{R}^n : \rightarrow \mathbb{R}$ is measurable, $c>0$ , and $p<n$ ? If $|f(x)| \leq c|x|^{-p} \chi_{B(0,1)}(x)$ a.e, prove that $f$ is integrable. First of all, am I right to assume that $|x|$ means $||x||$ ? In what follows, I will choose $||\cdot|| = || \cdot ||_1$ To get some intuition, I tried the case where $n=2$ and $p=1$ . We have that: $\int_{\mathbb{R^2}} |f(x)| \, dm(x) \leq c\int_{B(0,1)} ||x||_1 dm(x) = c\int_{-1}^{1} [ \int_{-1}^{1} \frac{1}{|x_1| + |x_2|}dm(x_1)]\, dm(x_2)$ and $\int_{-1}^{1} \frac{1}{|x_1| + |x_2|}dm(x_1) \leq \int_{-1}^{1} \frac{1}{|x_1|}dm(x_1)=2 \int_{0}^{1} \frac{1}{x_1} dm(x_1)$ But $\int_{0}^{1} \frac{1}{x_1} dm(x_1)$ is not finite. So, even in the easiest case I am kind of stuck. Can someone help me out ?","Exercise 11.21 in Real Analysis for... by Richard Bass says:  Suppose is measurable, , and ? If a.e, prove that is integrable. First of all, am I right to assume that means ? In what follows, I will choose To get some intuition, I tried the case where and . We have that: and But is not finite. So, even in the easiest case I am kind of stuck. Can someone help me out ?","f: \mathbb{R}^n : \rightarrow \mathbb{R} c>0 p<n |f(x)| \leq c|x|^{-p} \chi_{B(0,1)}(x) f |x| ||x|| ||\cdot|| = || \cdot ||_1 n=2 p=1 \int_{\mathbb{R^2}} |f(x)| \, dm(x) \leq c\int_{B(0,1)} ||x||_1 dm(x) = c\int_{-1}^{1} [ \int_{-1}^{1} \frac{1}{|x_1| + |x_2|}dm(x_1)]\, dm(x_2) \int_{-1}^{1} \frac{1}{|x_1| + |x_2|}dm(x_1) \leq \int_{-1}^{1} \frac{1}{|x_1|}dm(x_1)=2 \int_{0}^{1} \frac{1}{x_1} dm(x_1) \int_{0}^{1} \frac{1}{x_1} dm(x_1)","['real-analysis', 'integration', 'measure-theory', 'notation']"
18,"$T_{f}(a,x)$ is absolutely continuous in $[a,b]$ whenever $f$ is absolutely continuous $[a,b]$. (Proof verification)",is absolutely continuous in  whenever  is absolutely continuous . (Proof verification),"T_{f}(a,x) [a,b] f [a,b]","Let $$T_{f}(a,x) = \sup \sum_{j=1}^{n}|f(t_{j}) - f(t_{j-1})|$$ be the total variation of $f$ on $[a,x]$ . I want show that: $T_{f}(a,x)$ is absolutely continuous in $[a,b]$ whenever $f$ is absolutely continuous $[a,b]$ . My attempt. We need to show that for each $\epsilon > 0$ , there is a $\delta>0$ such that: $$\sum_{1}^{m}|T_{f}(a,b_{k}) - T_{f}(a,a_{k})| < \epsilon$$ whenever $$\sum_{1}^{m}|b_{k} - a_{k}|<\delta.$$ Note that $$\sum_{1}^{m}|T_{f}(a,b_{k}) - T_{f}(a,a_{k})| = \sum_{1}^{m}T_{f}(a,b_{k}) - T_{f}(a,a_{k}) = \sum_{1}^{m}T_{f}(a_{k},b_{k}).$$ Choose $\delta$ that satisfies the absolutely continuity of $f$ on $[a,b]$ and $\displaystyle \tilde{\epsilon} < \min\left\{\frac{\epsilon}{m+1},\frac{\epsilon}{2}\right\}$ . So, $$\sum_{1}^{n}|t_{j}-t_{j-1}|<\delta$$ implies $$\sum_{1}^{n}|f(t_{j}) - f(t_{j-1})|<\tilde{\epsilon}.$$ for any partition of $[a_{k},b_{k}]$ . Therefore, $$T_{f}(a_{k},b_{k}) = \sup \sum_{1}^{n}|f(t_{j}) - f(t_{j-1})|<\frac{\epsilon}{m}.$$ Thus, $$\sum_{1}^{m}T_{f}(a_{k},b_{k}) <\epsilon.$$ That makes sense?","Let be the total variation of on . I want show that: is absolutely continuous in whenever is absolutely continuous . My attempt. We need to show that for each , there is a such that: whenever Note that Choose that satisfies the absolutely continuity of on and . So, implies for any partition of . Therefore, Thus, That makes sense?","T_{f}(a,x) = \sup \sum_{j=1}^{n}|f(t_{j}) - f(t_{j-1})| f [a,x] T_{f}(a,x) [a,b] f [a,b] \epsilon > 0 \delta>0 \sum_{1}^{m}|T_{f}(a,b_{k}) - T_{f}(a,a_{k})| < \epsilon \sum_{1}^{m}|b_{k} - a_{k}|<\delta. \sum_{1}^{m}|T_{f}(a,b_{k}) - T_{f}(a,a_{k})| = \sum_{1}^{m}T_{f}(a,b_{k}) - T_{f}(a,a_{k}) = \sum_{1}^{m}T_{f}(a_{k},b_{k}). \delta f [a,b] \displaystyle \tilde{\epsilon} < \min\left\{\frac{\epsilon}{m+1},\frac{\epsilon}{2}\right\} \sum_{1}^{n}|t_{j}-t_{j-1}|<\delta \sum_{1}^{n}|f(t_{j}) - f(t_{j-1})|<\tilde{\epsilon}. [a_{k},b_{k}] T_{f}(a_{k},b_{k}) = \sup \sum_{1}^{n}|f(t_{j}) - f(t_{j-1})|<\frac{\epsilon}{m}. \sum_{1}^{m}T_{f}(a_{k},b_{k}) <\epsilon.","['real-analysis', 'measure-theory', 'absolute-continuity']"
19,What does mod 0 mean in the context of ergodic theory?,What does mod 0 mean in the context of ergodic theory?,,"I have come across the following definition: A measure-preserving transformation (or flow) $T$ is ergodic if any essentially $T$ -invariant measurable set has either measure 0 or full measure. Equivalently, $T$ is ergodic if any essentially $T$ -invariant measurable function is constant $\mod 0$ . What does $\mod 0$ mean in this context. Does it mean except a set of measure $0$ ? i.e. the function is constant a.e. ?","I have come across the following definition: A measure-preserving transformation (or flow) is ergodic if any essentially -invariant measurable set has either measure 0 or full measure. Equivalently, is ergodic if any essentially -invariant measurable function is constant . What does mean in this context. Does it mean except a set of measure ? i.e. the function is constant a.e. ?",T T T T \mod 0 \mod 0 0,"['measure-theory', 'dynamical-systems', 'ergodic-theory']"
20,Uniqueness of measure on $\mu^*$ measurable sets,Uniqueness of measure on  measurable sets,\mu^*,"Folland proves the following theorem: Let $\mathcal{A} \subset \mathcal{P}(X)$ be an algebra, $\mu_0$ a premeasure on $\mathcal{A}$, and $\mathcal{M}$ be the sigma algbera generated by $\mathcal{A}$. There exists a measure on $\mu$ on $\mathcal{M}$ whose restriction to $\mathcal{A}$ is $\mu_0$ - namely, $\mu = \mu^*|_{\mathcal{M}}$ where $\mu^*$ is the outer measure. If $\nu$ is another measure on $\mathcal{M}$ that extends $\mu_0$, then $\nu(E) \leq \mu(E)$ for all $E \in \mathcal{M}$, with equality when $\mu(E) < \infty$ I have a question about the second part of the statement, showing the equivalence of $\mu$ and $\nu$. When I did this myself, I used the following arguement: Let $E \subset X$ and $A_j \in \mathcal{A}$, then: $$\nu(E) \leq \sum \nu(A_j) = \sum \mu_0(A_j) = \sum \mu(A_j) =  \mu(\bigcup A_j) \, \,\forall j \implies \nu(E) \leq \mu(E)$$ $$\mu(E) \leq \sum \mu(A_j) = \sum \mu_0(A_j) = \sum \nu(A_j) =  \nu(\bigcup A_j) \, \,\forall j \implies \mu(E) \leq \nu(E)$$ Folland does this a different way, is this correct though?","Folland proves the following theorem: Let $\mathcal{A} \subset \mathcal{P}(X)$ be an algebra, $\mu_0$ a premeasure on $\mathcal{A}$, and $\mathcal{M}$ be the sigma algbera generated by $\mathcal{A}$. There exists a measure on $\mu$ on $\mathcal{M}$ whose restriction to $\mathcal{A}$ is $\mu_0$ - namely, $\mu = \mu^*|_{\mathcal{M}}$ where $\mu^*$ is the outer measure. If $\nu$ is another measure on $\mathcal{M}$ that extends $\mu_0$, then $\nu(E) \leq \mu(E)$ for all $E \in \mathcal{M}$, with equality when $\mu(E) < \infty$ I have a question about the second part of the statement, showing the equivalence of $\mu$ and $\nu$. When I did this myself, I used the following arguement: Let $E \subset X$ and $A_j \in \mathcal{A}$, then: $$\nu(E) \leq \sum \nu(A_j) = \sum \mu_0(A_j) = \sum \mu(A_j) =  \mu(\bigcup A_j) \, \,\forall j \implies \nu(E) \leq \mu(E)$$ $$\mu(E) \leq \sum \mu(A_j) = \sum \mu_0(A_j) = \sum \nu(A_j) =  \nu(\bigcup A_j) \, \,\forall j \implies \mu(E) \leq \nu(E)$$ Folland does this a different way, is this correct though?",,"['real-analysis', 'measure-theory', 'proof-verification']"
21,Proving the Leibniz integral rule in measure theory,Proving the Leibniz integral rule in measure theory,,"The task at hand is to prove that for a function $f\colon X\times (0,1)\rightarrow \mathbb C$ there holds  $$ \frac d {dt}\int_X f(x,t)\,\mathrm d\mu(x)=\int_X \frac{\partial f}{\partial t}(x,t)\,\mathrm d\mu(x) $$ at certain conditions, for $X$ a space with measure $\mu$. Namely, the conditions are that: $f(\cdot, t)\colon X\rightarrow \mathbb C$ is integrable $\forall t\in (0,1)$, $\frac{\partial f}{\partial t}(x,t)$ exists for almost all $(x,t)\in X\times (0,1)$, $\exists g\in L^1\colon \forall t\in(0,1)\colon\left\lvert\frac{\partial f}{\partial t}(x,t)\right\rvert \leq g(x)$. Let $F(t)=\int_Xf(x,t)\, d\mu(x)$. Fix $t\in(0,1)$; by the definition of derivative, we have  \begin{align} F'(t)&=\lim_{n\rightarrow \infty} n\left(F\left( t+\frac 1 n\right)-F(t)\right)\\ &=\lim_{n\rightarrow\infty}n\left(\int_X f\left(x,t+\frac 1 n\right)\, \mathrm d\mu(x)-\int_X f(x,t)\,\mathrm d\mu(x)\right)\\ &\stackrel{lin.}=\lim_{n\rightarrow \infty}\int_X n\left(f\left(x,t+\frac 1 n\right)-f(x,t)\right)\,\mathrm d\mu(x), \end{align} and now let $f_n(x,t):=n\left(f(x,t+\frac 1 n)-f(x,t)\right)$. It's worth noting that $t+\frac 1 n$ may fall out of $(0,1)$, but we can ignore that by defining the expressions above only for large enough $n$ because the limit in $n$ is independent of the first finitely many terms. By assumption, we have that $\frac{\partial f}{\partial t}=\lim_{n\rightarrow \infty} f_n$ exists almost everywhere and therefore so does $\frac{\partial f}{\partial t}(\cdot,t)$. In order to be able to exchange the limit with the integral, we utilize the dominated convergence theorem. However, the condition to use it is $\lvert f_n (\cdot, t)\rvert\leq g_0$ for some integrable function $g_0$ for all $t\in(0,1)$. The assumed function $g$ above is such that $\lvert\lim_n f_n(\cdot,t)\rvert\leq g$, but $(f_n(\cdot,t))$ isn't necessarily increasing in $n$ (for $X=\mathbb R$ we can have a function that is convex in $x$), thus taking $g_0\equiv g$ isn't appropriate. I've thought of taking $g_0(x)=\sup\{\lvert f_n(x,t)\rvert\;;\;t\in(0,1), n\in \mathbb N\}$, but have no idea how to prove $g_0\in L^1$ then. After finding the function $g_0$ in question, the rest is straightforward. Additionally, I would like to know if the last condition above can be deduced from continuity of the function $\frac{\partial f}{\partial t}$ in case of $X=\mathbb R$ with Lebesgue measure.","The task at hand is to prove that for a function $f\colon X\times (0,1)\rightarrow \mathbb C$ there holds  $$ \frac d {dt}\int_X f(x,t)\,\mathrm d\mu(x)=\int_X \frac{\partial f}{\partial t}(x,t)\,\mathrm d\mu(x) $$ at certain conditions, for $X$ a space with measure $\mu$. Namely, the conditions are that: $f(\cdot, t)\colon X\rightarrow \mathbb C$ is integrable $\forall t\in (0,1)$, $\frac{\partial f}{\partial t}(x,t)$ exists for almost all $(x,t)\in X\times (0,1)$, $\exists g\in L^1\colon \forall t\in(0,1)\colon\left\lvert\frac{\partial f}{\partial t}(x,t)\right\rvert \leq g(x)$. Let $F(t)=\int_Xf(x,t)\, d\mu(x)$. Fix $t\in(0,1)$; by the definition of derivative, we have  \begin{align} F'(t)&=\lim_{n\rightarrow \infty} n\left(F\left( t+\frac 1 n\right)-F(t)\right)\\ &=\lim_{n\rightarrow\infty}n\left(\int_X f\left(x,t+\frac 1 n\right)\, \mathrm d\mu(x)-\int_X f(x,t)\,\mathrm d\mu(x)\right)\\ &\stackrel{lin.}=\lim_{n\rightarrow \infty}\int_X n\left(f\left(x,t+\frac 1 n\right)-f(x,t)\right)\,\mathrm d\mu(x), \end{align} and now let $f_n(x,t):=n\left(f(x,t+\frac 1 n)-f(x,t)\right)$. It's worth noting that $t+\frac 1 n$ may fall out of $(0,1)$, but we can ignore that by defining the expressions above only for large enough $n$ because the limit in $n$ is independent of the first finitely many terms. By assumption, we have that $\frac{\partial f}{\partial t}=\lim_{n\rightarrow \infty} f_n$ exists almost everywhere and therefore so does $\frac{\partial f}{\partial t}(\cdot,t)$. In order to be able to exchange the limit with the integral, we utilize the dominated convergence theorem. However, the condition to use it is $\lvert f_n (\cdot, t)\rvert\leq g_0$ for some integrable function $g_0$ for all $t\in(0,1)$. The assumed function $g$ above is such that $\lvert\lim_n f_n(\cdot,t)\rvert\leq g$, but $(f_n(\cdot,t))$ isn't necessarily increasing in $n$ (for $X=\mathbb R$ we can have a function that is convex in $x$), thus taking $g_0\equiv g$ isn't appropriate. I've thought of taking $g_0(x)=\sup\{\lvert f_n(x,t)\rvert\;;\;t\in(0,1), n\in \mathbb N\}$, but have no idea how to prove $g_0\in L^1$ then. After finding the function $g_0$ in question, the rest is straightforward. Additionally, I would like to know if the last condition above can be deduced from continuity of the function $\frac{\partial f}{\partial t}$ in case of $X=\mathbb R$ with Lebesgue measure.",,['measure-theory']
22,"How is the ""surface measure"" on a manifold defined?","How is the ""surface measure"" on a manifold defined?",,"Let $k,n\in\mathbb N$ with $k\le n$ $M$ be a $k$-dimensional $C^1$-submanifold of $\mathbb R^n$ $\Omega\subseteq\mathbb R^k$ be open, $\phi:\Omega\to M$ be a global chart of $M$ and $$g_\phi(x):=\det\left(\left({\rm D}\phi(x)\right)^\ast {\rm D}\phi(x)\right)\;\;\;\text{for }x\in U$$ Now, let $\lambda^k$ denote the Lebesgue measure on $\mathcal B(\mathbb R^k)$,  $\sqrt{g_\phi}{\rm d}\left.\lambda^k\right|_U$ denote the measure with density $\sqrt{g_\phi}$ with respect to $\left.\lambda^k\right|_U$ and $$S_M:=\phi_\ast\left(\sqrt{g_\phi}{\rm d}\left.\lambda^k\right|_U\right)$$ the pushforward measure of $\sqrt{g_\phi}{\rm d}\left.\lambda^k\right|_U$ with respect to $\phi$. $S_M$ is a measure on $\mathcal B(M)$ and we're able to verify that $S_M(A)$ is the surface area of $A\in\mathcal B(M)$. I'm searching for a generalization of the concept described above for more general $M$. In particular, the $M$ I've got in mind is the finite union of triangles in $\mathbb R^3$. Two different triangles can be assumed to intersect only along one common side or at one common vertex and two different sides can intersect only at one common vertex. I've searched the internet for a couple of hours, but couldn't find anything (Actually, I wasn't even able to find the construction of $S_M$ above anywhere). So, is there any good textbook on that topic?","Let $k,n\in\mathbb N$ with $k\le n$ $M$ be a $k$-dimensional $C^1$-submanifold of $\mathbb R^n$ $\Omega\subseteq\mathbb R^k$ be open, $\phi:\Omega\to M$ be a global chart of $M$ and $$g_\phi(x):=\det\left(\left({\rm D}\phi(x)\right)^\ast {\rm D}\phi(x)\right)\;\;\;\text{for }x\in U$$ Now, let $\lambda^k$ denote the Lebesgue measure on $\mathcal B(\mathbb R^k)$,  $\sqrt{g_\phi}{\rm d}\left.\lambda^k\right|_U$ denote the measure with density $\sqrt{g_\phi}$ with respect to $\left.\lambda^k\right|_U$ and $$S_M:=\phi_\ast\left(\sqrt{g_\phi}{\rm d}\left.\lambda^k\right|_U\right)$$ the pushforward measure of $\sqrt{g_\phi}{\rm d}\left.\lambda^k\right|_U$ with respect to $\phi$. $S_M$ is a measure on $\mathcal B(M)$ and we're able to verify that $S_M(A)$ is the surface area of $A\in\mathcal B(M)$. I'm searching for a generalization of the concept described above for more general $M$. In particular, the $M$ I've got in mind is the finite union of triangles in $\mathbb R^3$. Two different triangles can be assumed to intersect only along one common side or at one common vertex and two different sides can intersect only at one common vertex. I've searched the internet for a couple of hours, but couldn't find anything (Actually, I wasn't even able to find the construction of $S_M$ above anywhere). So, is there any good textbook on that topic?",,"['real-analysis', 'measure-theory', 'manifolds', 'manifolds-with-boundary', 'submanifold']"
23,Set with no full or empty intervals [duplicate],Set with no full or empty intervals [duplicate],,"This question already has an answer here : Construct a Borel set on R such that it intersect every open interval with non-zero non-""full"" measure (1 answer) Closed 5 years ago . Let $m(\cdot)$ denote Lebesgue measure. Does there exist an $S\subset [0,1]$ such that for all $a<b$ we would have $0<m([a,b]\cap S)<b-a$? I believe that the answer is yes, and I have a rough construction in mind. On the first step, allocate $1/4$ ""mass"" to either side of $1/2$ (this gives $S_1$).  Then recursively allocate $1/8$ mass to either side of $1/4$ and of $3/4$ (to get $S_2$).  Continue this process. At depth $d$ of the recursion, we have that for $a,b$ with binary expansions with at most $d$ digits, $m([a,b]\cap S_d)=(b-a)/2$.  Then in the limit, any interval can be written as the countable disjoint union of intervals with finite binary expansion, so (I think) $m([a,b]\cap S_d)=(b-a)/2$ holds for all $0<a<b<1$. I can describe the construction a bit more formally: For every $n$, consider the set of points with $n$ digits in its binary expansion.  There are $2^{n-1}$ such points since every digit is free, except for the last one which must be 1.  Place an interval of length $2^{-n}$ centered at each of those points.  Let $S_n$ be the union of those intervals. This would give us $S_1=[1/4,3/4],S_2=[1/8,3/8]\cup [5/8,7/8],\cdots$","This question already has an answer here : Construct a Borel set on R such that it intersect every open interval with non-zero non-""full"" measure (1 answer) Closed 5 years ago . Let $m(\cdot)$ denote Lebesgue measure. Does there exist an $S\subset [0,1]$ such that for all $a<b$ we would have $0<m([a,b]\cap S)<b-a$? I believe that the answer is yes, and I have a rough construction in mind. On the first step, allocate $1/4$ ""mass"" to either side of $1/2$ (this gives $S_1$).  Then recursively allocate $1/8$ mass to either side of $1/4$ and of $3/4$ (to get $S_2$).  Continue this process. At depth $d$ of the recursion, we have that for $a,b$ with binary expansions with at most $d$ digits, $m([a,b]\cap S_d)=(b-a)/2$.  Then in the limit, any interval can be written as the countable disjoint union of intervals with finite binary expansion, so (I think) $m([a,b]\cap S_d)=(b-a)/2$ holds for all $0<a<b<1$. I can describe the construction a bit more formally: For every $n$, consider the set of points with $n$ digits in its binary expansion.  There are $2^{n-1}$ such points since every digit is free, except for the last one which must be 1.  Place an interval of length $2^{-n}$ centered at each of those points.  Let $S_n$ be the union of those intervals. This would give us $S_1=[1/4,3/4],S_2=[1/8,3/8]\cup [5/8,7/8],\cdots$",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
24,Measurability of piecewise defined function on a product space,Measurability of piecewise defined function on a product space,,"Let $(\Omega,\mathcal A)$ and $(X,\mathcal X)$ be measurable spaces $g_n:\Omega\times X\to\mathbb R$ be $\mathcal A\otimes\mathcal X$-measurable for $n\in\mathbb N$ Assume that for all $x\in X$, there is a $N_x\in\mathcal A$ such that $(g_n(\omega,x))_{n\in\mathbb N}$ is convergent for all $\omega\in\Omega\setminus N_x$. Now, let $$g(\omega,x):=\begin{cases}\displaystyle\lim_{n\to\infty}g_n(\omega,x)&&\text{, if }\omega\in\Omega\setminus N_x\\0&&\text{, otherwise}\end{cases}$$ for $(\omega,x)\in\Omega\times X$. How can we conclude that $g$ is $\mathcal A\otimes\mathcal X$-measurable? My problem with this task is the dependence of $N_x$ on $x$. How do we need to argue?","Let $(\Omega,\mathcal A)$ and $(X,\mathcal X)$ be measurable spaces $g_n:\Omega\times X\to\mathbb R$ be $\mathcal A\otimes\mathcal X$-measurable for $n\in\mathbb N$ Assume that for all $x\in X$, there is a $N_x\in\mathcal A$ such that $(g_n(\omega,x))_{n\in\mathbb N}$ is convergent for all $\omega\in\Omega\setminus N_x$. Now, let $$g(\omega,x):=\begin{cases}\displaystyle\lim_{n\to\infty}g_n(\omega,x)&&\text{, if }\omega\in\Omega\setminus N_x\\0&&\text{, otherwise}\end{cases}$$ for $(\omega,x)\in\Omega\times X$. How can we conclude that $g$ is $\mathcal A\otimes\mathcal X$-measurable? My problem with this task is the dependence of $N_x$ on $x$. How do we need to argue?",,"['real-analysis', 'measure-theory', 'product-space']"
25,Reverse type $1-1$ inequality,Reverse type  inequality,1-1,"If $\mu \in \mathcal{M}(\mathbb{T})$ is nontrivial and singular with respect to lebesgue measure, then  $$|\{\theta \in \mathbb{T} : M\mu(\theta) >\lambda\}| \ge \frac C\lambda \|\mu\|$$ where $| \cdot | $ denotes Lebesgue measure, $|\lambda| > \|\mu\|$, which is the total variation norm, and $C$ is an absolute constant. That is the problem statement. I'm looking for advice on how to establish a weak 1-1 inequality going the other way. The standard tools (Besicovitch, Vitali) don't seem readily applicable. The maximal function $M\mu(x) = \displaystyle\sup_{I \supset x} \frac{\mu(I)}{|I|}$ where the sup is taken over all intervals $I$ containing $x$.","If $\mu \in \mathcal{M}(\mathbb{T})$ is nontrivial and singular with respect to lebesgue measure, then  $$|\{\theta \in \mathbb{T} : M\mu(\theta) >\lambda\}| \ge \frac C\lambda \|\mu\|$$ where $| \cdot | $ denotes Lebesgue measure, $|\lambda| > \|\mu\|$, which is the total variation norm, and $C$ is an absolute constant. That is the problem statement. I'm looking for advice on how to establish a weak 1-1 inequality going the other way. The standard tools (Besicovitch, Vitali) don't seem readily applicable. The maximal function $M\mu(x) = \displaystyle\sup_{I \supset x} \frac{\mu(I)}{|I|}$ where the sup is taken over all intervals $I$ containing $x$.",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'harmonic-analysis', 'singular-measures']"
26,"Prove that $\frac{g(x)}{\ln(1+x)}$ is integrable over $[0,1].$",Prove that  is integrable over,"\frac{g(x)}{\ln(1+x)} [0,1].","Question : Let $f$ be a measurable function on $[0,1]$ such that    $$g(x) = |f(x)| \ln(1+x)$$   is Lebsegue integrable over $[0,1].$   Prove that $f$ is Lebesgue integrable over $[0,1]$ So the question is asking us to show that  $$\int_0^1 |f(x)|\, dx = \int_0^1 \frac{|g(x)|}{\ln(1+x)}dx$$ is finite. However, I think that the question is not correct.  Clearly $g(x) = 1$ is Lebesgue integrable over $[0,1],$ as  $$\int_0^1 |g(x)| \, dx = 1,$$  but $$\int_0^1 \frac{1}{\ln(1+x)}dx,$$ based on Wolfram Alpha , is not finite. So $f$ is not Lebesgue integrable over $[0,1].$ Is my reasoning correct?","Question : Let $f$ be a measurable function on $[0,1]$ such that    $$g(x) = |f(x)| \ln(1+x)$$   is Lebsegue integrable over $[0,1].$   Prove that $f$ is Lebesgue integrable over $[0,1]$ So the question is asking us to show that  $$\int_0^1 |f(x)|\, dx = \int_0^1 \frac{|g(x)|}{\ln(1+x)}dx$$ is finite. However, I think that the question is not correct.  Clearly $g(x) = 1$ is Lebesgue integrable over $[0,1],$ as  $$\int_0^1 |g(x)| \, dx = 1,$$  but $$\int_0^1 \frac{1}{\ln(1+x)}dx,$$ based on Wolfram Alpha , is not finite. So $f$ is not Lebesgue integrable over $[0,1].$ Is my reasoning correct?",,"['integration', 'measure-theory', 'lebesgue-integral']"
27,Tricky Lebesgue problem,Tricky Lebesgue problem,,"There is this one Lebesgue problem I have trouble solving, and it goes: Problem: For every positive integer $n$, let $f_n:[0,1] \rightarrow \mathbb{R}$ be measurable. Let $f:[0,1] \rightarrow \mathbb{R}$ be a function such that for every $\epsilon > 0$, we have: $$\lim \limits_{n \to \infty} m^*(\{x\in[0,1]: |f_n(x)-f(x)|>\epsilon\})=0$$ Prove that $f$ is measurable. So far I have some sketch of the solution but I am not sure if it is correct but it goes like this: My attempt: First we consider some smaller problem where we define some $a_1, a_2, a_3, ...  \in (0, \infty)$ and $a_1+a_2+a_3+... <\infty$ and $E_1, E_2, E_3,... $ are subsets of $\mathbb{R} $ such that $m^* (E_k)<a_k$, then we have $$m^*(\bigcap_{K=1}^\infty \bigcup_{n=K}^\infty E_n) = 0 $$ This part is easy to show. the next part is using this small result to apply to my question, and we have: First we let $a_K = \frac{1}{2^K}$, then $\sum_{K=1}^\infty a_K=1<\infty.$ Now according to the definition of the limit we have $\epsilon = \frac{1}{2^K}>0$ there exists some $n_K$ such that $m^*(\{x\in[0,1]: |f_{n_K}(x)-f(x)|>\frac{1}{2^K}\})<\frac{1}{2^K}$. Let us define then that $$E_K = \{x\in[0,1]: |f_{n_K}(x)-f(x)|>\frac{1}{2^K}\}$$ Now if we let $S = \bigcap_{K=1}^\infty \bigcup_{n=K}^\infty E_n$, then we know that $m^*(S)=0$ hence $S$ is measurable. For $x\in [0,1]\setminus S = \bigcup_{K=1}^\infty \bigcap_{j=K}^\infty([0,1]\setminus E_j)$ and this implies that there exists $K\in \mathbb{N},  \forall j\ge K$, and $x \notin E_j$. So there exists some $K\in \mathbb{N}, \forall j\ge K,$ $$|f_{n_j}(x)-f(x)|\le\frac{1}{2^K}$$ which further implies that: $$\lim \limits_{j \to \infty} f_{n_j}(x)=f(x)$$ Since $m(S)=0$, we have $\lim \limits_{j \to \infty} f_{n_j}(x)=f(x)$ almost everywhere on $[0,1]$. Since $f_{n_j}$ are measurable hence $f$ is measurable. Is this correct? Im not entirely sure if this is correct, can anyone give me some feedbacks to my attempt. If this approach is wrong, can anyone gimme an outline of the method to do this problem?","There is this one Lebesgue problem I have trouble solving, and it goes: Problem: For every positive integer $n$, let $f_n:[0,1] \rightarrow \mathbb{R}$ be measurable. Let $f:[0,1] \rightarrow \mathbb{R}$ be a function such that for every $\epsilon > 0$, we have: $$\lim \limits_{n \to \infty} m^*(\{x\in[0,1]: |f_n(x)-f(x)|>\epsilon\})=0$$ Prove that $f$ is measurable. So far I have some sketch of the solution but I am not sure if it is correct but it goes like this: My attempt: First we consider some smaller problem where we define some $a_1, a_2, a_3, ...  \in (0, \infty)$ and $a_1+a_2+a_3+... <\infty$ and $E_1, E_2, E_3,... $ are subsets of $\mathbb{R} $ such that $m^* (E_k)<a_k$, then we have $$m^*(\bigcap_{K=1}^\infty \bigcup_{n=K}^\infty E_n) = 0 $$ This part is easy to show. the next part is using this small result to apply to my question, and we have: First we let $a_K = \frac{1}{2^K}$, then $\sum_{K=1}^\infty a_K=1<\infty.$ Now according to the definition of the limit we have $\epsilon = \frac{1}{2^K}>0$ there exists some $n_K$ such that $m^*(\{x\in[0,1]: |f_{n_K}(x)-f(x)|>\frac{1}{2^K}\})<\frac{1}{2^K}$. Let us define then that $$E_K = \{x\in[0,1]: |f_{n_K}(x)-f(x)|>\frac{1}{2^K}\}$$ Now if we let $S = \bigcap_{K=1}^\infty \bigcup_{n=K}^\infty E_n$, then we know that $m^*(S)=0$ hence $S$ is measurable. For $x\in [0,1]\setminus S = \bigcup_{K=1}^\infty \bigcap_{j=K}^\infty([0,1]\setminus E_j)$ and this implies that there exists $K\in \mathbb{N},  \forall j\ge K$, and $x \notin E_j$. So there exists some $K\in \mathbb{N}, \forall j\ge K,$ $$|f_{n_j}(x)-f(x)|\le\frac{1}{2^K}$$ which further implies that: $$\lim \limits_{j \to \infty} f_{n_j}(x)=f(x)$$ Since $m(S)=0$, we have $\lim \limits_{j \to \infty} f_{n_j}(x)=f(x)$ almost everywhere on $[0,1]$. Since $f_{n_j}$ are measurable hence $f$ is measurable. Is this correct? Im not entirely sure if this is correct, can anyone give me some feedbacks to my attempt. If this approach is wrong, can anyone gimme an outline of the method to do this problem?",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
28,Proof of measurability of the sum of extended-real measurable functions,Proof of measurability of the sum of extended-real measurable functions,,"I was reading Rudin's Real and Complex Analysis (3rd ed.), and on page 19 he says: (The key point here is about arithmetic in $[0, \infty]$ .) Observe that the following useful proposition holds: (with arithmetic in $[0, \infty]$ ) If $0\le a_1 \le a_2 \le \cdots$ , $0\le b_1 \le b_2 \le \cdots$ , $a_n \to a$ and $b_n \to b$ , then $a_nb_n\to ab$ . If we combine this with Theorems $1.17$ and $1.14$ , we see that sums and products of measurable functions into $[0, \infty]$ are measurable. Theorem 1.14 If $f_n:X\to [-\infty, \infty]$ is measurable, and $g=\sup_n f_n$ , then g is measurable. Theorem 1.17 Let $f:X\to [0, \infty]$ be measurable.  There exist simple measurable funcctions $s_n$ on $X$ s.t. $0\le s_1\le s_2\le \cdots\le f$ , and $\forall x\in X: s_n(x)\to f(x)$ as $n\to \infty.$ I am not very sure what he meant.  I list my attempted proof below, and would appreciate it if someone can confirm if it's valid, or point out if I miss his point. Suppose $f, g:X\to[0, \infty]$ are two measurable functions.  I want to show that $f+g$ is also measurable.  I'd proceed as follows: First, I state an easily proved proposition similar to the one given above: If $0\le a_1 \le a_2 \le \cdots$ , $0\le b_1 \le b_2 \le \cdots$ , $a_n \to a$ and $b_n \to b$ , then $a_n+b_n\to a+b$ .  (Even if $a$ or $b$ takes value of $\infty$ .) Since $f, g$ are measurable, by Theorem 1.17, there must exist simple measurable functions $f_n, g_n$ on $X$ s.t. $0\le f_1 \le f_2 \le \cdots\le f$ , and $\forall x\in X:f_n(x)\to f(x).$ Similarly, $0\le g_1 \le g_2 \le \cdots\le g$ , and $\forall x\in X: g_n(x)\to g(x).$ (In Rudin's book, simple functions are real functions, not extended-real.) Hence $\forall x\in X:f_n(x)+g_n(x)\to f(x)+g(x)$ by the proposition above.  (Note that $f_n+g_n$ is real, while $f+g$ is extended-real valued.) But $f_n, g_n$ are simple measurable functions, so their sum $f_n+g_n$ must be simple and measurable.  Moreover, $\{f_n+g_n\}$ is a sequence of increasing functions, so $$\lim_{n\to \infty} (f_n+g_n)=\sup_n(f_n+g_n).$$ Since the supremum of a sequence of real measurable functions must be measurable (Theorem 1.14), we conclude that $f+g$ is measurable (even though it's extended-real).","I was reading Rudin's Real and Complex Analysis (3rd ed.), and on page 19 he says: (The key point here is about arithmetic in .) Observe that the following useful proposition holds: (with arithmetic in ) If , , and , then . If we combine this with Theorems and , we see that sums and products of measurable functions into are measurable. Theorem 1.14 If is measurable, and , then g is measurable. Theorem 1.17 Let be measurable.  There exist simple measurable funcctions on s.t. , and as I am not very sure what he meant.  I list my attempted proof below, and would appreciate it if someone can confirm if it's valid, or point out if I miss his point. Suppose are two measurable functions.  I want to show that is also measurable.  I'd proceed as follows: First, I state an easily proved proposition similar to the one given above: If , , and , then .  (Even if or takes value of .) Since are measurable, by Theorem 1.17, there must exist simple measurable functions on s.t. , and Similarly, , and (In Rudin's book, simple functions are real functions, not extended-real.) Hence by the proposition above.  (Note that is real, while is extended-real valued.) But are simple measurable functions, so their sum must be simple and measurable.  Moreover, is a sequence of increasing functions, so Since the supremum of a sequence of real measurable functions must be measurable (Theorem 1.14), we conclude that is measurable (even though it's extended-real).","[0, \infty] [0, \infty] 0\le a_1 \le a_2 \le \cdots 0\le b_1 \le b_2 \le \cdots a_n \to a b_n \to b a_nb_n\to ab 1.17 1.14 [0, \infty] f_n:X\to [-\infty, \infty] g=\sup_n f_n f:X\to [0, \infty] s_n X 0\le s_1\le s_2\le \cdots\le f \forall x\in X: s_n(x)\to f(x) n\to \infty. f, g:X\to[0, \infty] f+g 0\le a_1 \le a_2 \le \cdots 0\le b_1 \le b_2 \le \cdots a_n \to a b_n \to b a_n+b_n\to a+b a b \infty f, g f_n, g_n X 0\le f_1 \le f_2 \le \cdots\le f \forall x\in X:f_n(x)\to f(x). 0\le g_1 \le g_2 \le \cdots\le g \forall x\in X: g_n(x)\to g(x). \forall x\in X:f_n(x)+g_n(x)\to f(x)+g(x) f_n+g_n f+g f_n, g_n f_n+g_n \{f_n+g_n\} \lim_{n\to \infty} (f_n+g_n)=\sup_n(f_n+g_n). f+g","['real-analysis', 'measure-theory']"
29,"If $E$ is measurable, then there is an interval $I$ such that $m(E \cap I) > \frac{9}{10} m(I)$ or $m(E^c \cap I) > \frac{9}{10} m (I)$.","If  is measurable, then there is an interval  such that  or .",E I m(E \cap I) > \frac{9}{10} m(I) m(E^c \cap I) > \frac{9}{10} m (I),"Here is my answer at the moment: Suppose not! Then for all $I$, $m(E \cap I) \leq \frac{9}{10} \chi(I)$ and $m(E^c \cap I) \leq \frac{9}{10} \chi(I)$. Suppose $E$ has finite measure and let $E \subset \bigcup^{\infty}_{n=1} I_n$. Then $$m(E) = m \left(E \cap \bigcup^{\infty}_{n=1} I_n \right) = m\left(\bigcup^{\infty}_{n=1} E \cap I_n \right) \leq m(E \cap I_n) \leq \frac{9}{10} \sum^{\infty} _{n =1} m (I_n)$$ Thus for all covers of $E$, $m(E) \leq \frac{9}{10} \sum^{\infty} _{n =1} m(I_n)$. But, by definition  $$m(E) = \inf \{m(I_n) : E \subset \bigcup^{\infty}_{n=1} I_n\}$$ Hence  $$m(E) \leq \frac{9}{10} m(E) \implies m(E) = 0$$ Now for $E$ with any measure,  $$m(E \cap(-n,n) \cap I_n) \leq m(E \cap I) \leq \frac{9}{n}m(I_n)$$ Hence $m(E \cap (-n,n)) = 0$ for all $n$ where  $$m(E) = m \left(\bigcup^{\infty}_{n=1} (E \cap(-n,n)) \right) \leq \sum^{\infty}_{n=1} m(E \cap (-n,n)) = 0$$ Note the same proof works for $m(E^c) = 0$. I am not certain that this argument works, or is complete. Is there any more to add, or change to make this proof complete? Thanks in advance!","Here is my answer at the moment: Suppose not! Then for all $I$, $m(E \cap I) \leq \frac{9}{10} \chi(I)$ and $m(E^c \cap I) \leq \frac{9}{10} \chi(I)$. Suppose $E$ has finite measure and let $E \subset \bigcup^{\infty}_{n=1} I_n$. Then $$m(E) = m \left(E \cap \bigcup^{\infty}_{n=1} I_n \right) = m\left(\bigcup^{\infty}_{n=1} E \cap I_n \right) \leq m(E \cap I_n) \leq \frac{9}{10} \sum^{\infty} _{n =1} m (I_n)$$ Thus for all covers of $E$, $m(E) \leq \frac{9}{10} \sum^{\infty} _{n =1} m(I_n)$. But, by definition  $$m(E) = \inf \{m(I_n) : E \subset \bigcup^{\infty}_{n=1} I_n\}$$ Hence  $$m(E) \leq \frac{9}{10} m(E) \implies m(E) = 0$$ Now for $E$ with any measure,  $$m(E \cap(-n,n) \cap I_n) \leq m(E \cap I) \leq \frac{9}{n}m(I_n)$$ Hence $m(E \cap (-n,n)) = 0$ for all $n$ where  $$m(E) = m \left(\bigcup^{\infty}_{n=1} (E \cap(-n,n)) \right) \leq \sum^{\infty}_{n=1} m(E \cap (-n,n)) = 0$$ Note the same proof works for $m(E^c) = 0$. I am not certain that this argument works, or is complete. Is there any more to add, or change to make this proof complete? Thanks in advance!",,"['real-analysis', 'measure-theory']"
30,Integral on a completion of measure space,Integral on a completion of measure space,,"Let $(X,{\cal M}, \mu)$ be a measure space with completion $(X,\bar{{\cal M}},\bar{\mu})$. If $f \in {\cal L}^1(X,{\cal M},\mu)$, show that $f \in {\cal L^1}(X,\bar{\cal M},\bar{\mu})$ and $\int fd\mu = \int f d\bar{ \mu}$ My attempt: firstly to show that $f$ is $\bar {\cal M}$ measurable, let $E \in {\cal B}_{\mathbb{C}}$, then $f^{-1}(E) \in \cal{M}$, by the definition of completion, $\bar{\cal M} := \{F \cup G: F \in {\cal M}, G \subseteq N, N \in {\cal M}, \mu(N) = 0\}$, if we set $G = \emptyset $, then we can have $f^{-1}(E) \in \bar {\cal M}$, hence $f$ is $\bar {\cal M}$ measurable. Furthermore, $f \in {\cal L}^1(X, \bar{\cal M},\bar{\mu})$ will directly follow from $\int f d\mu = \int f d \bar{\mu}$, but how to show this? I appreciate your help!","Let $(X,{\cal M}, \mu)$ be a measure space with completion $(X,\bar{{\cal M}},\bar{\mu})$. If $f \in {\cal L}^1(X,{\cal M},\mu)$, show that $f \in {\cal L^1}(X,\bar{\cal M},\bar{\mu})$ and $\int fd\mu = \int f d\bar{ \mu}$ My attempt: firstly to show that $f$ is $\bar {\cal M}$ measurable, let $E \in {\cal B}_{\mathbb{C}}$, then $f^{-1}(E) \in \cal{M}$, by the definition of completion, $\bar{\cal M} := \{F \cup G: F \in {\cal M}, G \subseteq N, N \in {\cal M}, \mu(N) = 0\}$, if we set $G = \emptyset $, then we can have $f^{-1}(E) \in \bar {\cal M}$, hence $f$ is $\bar {\cal M}$ measurable. Furthermore, $f \in {\cal L}^1(X, \bar{\cal M},\bar{\mu})$ will directly follow from $\int f d\mu = \int f d \bar{\mu}$, but how to show this? I appreciate your help!",,['real-analysis']
31,"Claim $\limsup_{k\rightarrow \infty}f_k\leq f$ in ""Measure theory and fine properties of functions""","Claim  in ""Measure theory and fine properties of functions""",\limsup_{k\rightarrow \infty}f_k\leq f,"In the book ""Measure theory and fine properties of functions"", the author is proving that $D_{\mu}\nu$ is measurable when $\mu$ and $\nu$ are Radon measures. He claims that $\limsup_{y\rightarrow x}\mu(B(y, r))\leq \mu(B(x, r))$ where I guess $B(x, r)$ is closed ball. He takes $f_k=\chi_{B(y_k, x)}$, where $y_k\rightarrow x$ and $f=\chi_{B(x,r)}$. Then he just says $$\limsup_{k\rightarrow \infty}f_k\leq f.$$ I don't understand this step, would someone kindly explain me this. Also, if the ball $B(x, r)$ is open, then why $$\liminf_{k\rightarrow\infty}f_k\geq f$$ holds? Thank you in advance.","In the book ""Measure theory and fine properties of functions"", the author is proving that $D_{\mu}\nu$ is measurable when $\mu$ and $\nu$ are Radon measures. He claims that $\limsup_{y\rightarrow x}\mu(B(y, r))\leq \mu(B(x, r))$ where I guess $B(x, r)$ is closed ball. He takes $f_k=\chi_{B(y_k, x)}$, where $y_k\rightarrow x$ and $f=\chi_{B(x,r)}$. Then he just says $$\limsup_{k\rightarrow \infty}f_k\leq f.$$ I don't understand this step, would someone kindly explain me this. Also, if the ball $B(x, r)$ is open, then why $$\liminf_{k\rightarrow\infty}f_k\geq f$$ holds? Thank you in advance.",,"['measure-theory', 'limsup-and-liminf']"
32,Why do we have $\lim_nE(\inf_{k\geq n}X_k)\leq\liminf_nE(X_n)$?,Why do we have ?,\lim_nE(\inf_{k\geq n}X_k)\leq\liminf_nE(X_n),Why do we have $\lim_nE(\inf_{k\geq n}X_k)\leq\liminf_nE(X_n)$? My try is that $\lim_nE(\inf_{k\geq n}X_k)= \liminf_nE(\inf_{k\geq n}X_k) \leq \liminf_nE(X_k) $. Am I correct? This is part of the proof for Fatou's lemma... Any help would be appreciated.,Why do we have $\lim_nE(\inf_{k\geq n}X_k)\leq\liminf_nE(X_n)$? My try is that $\lim_nE(\inf_{k\geq n}X_k)= \liminf_nE(\inf_{k\geq n}X_k) \leq \liminf_nE(X_k) $. Am I correct? This is part of the proof for Fatou's lemma... Any help would be appreciated.,,['measure-theory']
33,Pointwise convergence of a sequence of polynomials,Pointwise convergence of a sequence of polynomials,,"Consider the identity function $f(x) = x$ and let $\{h_n;n \in \mathbb{N}\}$ be a sequence of polynomials, which are defined on $[0,a]$ with some fixed $a<1$, and are of the form $h_n(x) = \sum_{i=1}^n c_{i,n} x^i$ where $c_{i,n}$ is the $i$th coefficient in the $n$th polynomial $h_n$. Further assume that: (1) $0 \leq h_n(x) \leq x$ and $h_n(0) = 0$ for every $n$; (2) each $h_n$ is monotonically increasing; (3) $\lim_{n \to \infty} h_n(x) = x$ uniformly for all $x \in [0,a]$. From (1) we know that $c_{1,n} = h_n'(0) \leq x'|_{x=0} = 1$ for every $n$. My question is: from conditions (1), (2) and (3), is it necessarily true that $\lim_{n \to \infty} c_{1,n} = 1$? If I impose the extra condition $\sup_{n \in \mathbb{N}} \{\sum_{i=2}^n |c_{i,n}|\} < M$ for some absolute constant $M > 0$, then the claim holds. But this is a too stringent condition. But I am not sure if the claim is unconditionally true. If not, what could be a minimal set of conditions that I need to impose? Thanks very much.","Consider the identity function $f(x) = x$ and let $\{h_n;n \in \mathbb{N}\}$ be a sequence of polynomials, which are defined on $[0,a]$ with some fixed $a<1$, and are of the form $h_n(x) = \sum_{i=1}^n c_{i,n} x^i$ where $c_{i,n}$ is the $i$th coefficient in the $n$th polynomial $h_n$. Further assume that: (1) $0 \leq h_n(x) \leq x$ and $h_n(0) = 0$ for every $n$; (2) each $h_n$ is monotonically increasing; (3) $\lim_{n \to \infty} h_n(x) = x$ uniformly for all $x \in [0,a]$. From (1) we know that $c_{1,n} = h_n'(0) \leq x'|_{x=0} = 1$ for every $n$. My question is: from conditions (1), (2) and (3), is it necessarily true that $\lim_{n \to \infty} c_{1,n} = 1$? If I impose the extra condition $\sup_{n \in \mathbb{N}} \{\sum_{i=2}^n |c_{i,n}|\} < M$ for some absolute constant $M > 0$, then the claim holds. But this is a too stringent condition. But I am not sure if the claim is unconditionally true. If not, what could be a minimal set of conditions that I need to impose? Thanks very much.",,"['calculus', 'real-analysis', 'measure-theory', 'polynomials', 'convergence-divergence']"
34,Proving a basic property of integration without using Monotone Convergence Theorem,Proving a basic property of integration without using Monotone Convergence Theorem,,"I'm trying to prove the exercise 4.F of Bartle's book: The Elements of Integration and Lebesgue Measure. 4.F Employ Exercise 4.E to establish that if $f,g\in M^{+}(X,\mathcal{F})$ then $f+g\in M^{+}(X,\mathcal{F})$ and $$\int(f+g)d\mu=\int fd\mu+\int gd\mu.$$ Exercise 4.E: Let $f,g\in M^{+},$ let $\omega\in M^{+}$ be a simple function such that $\omega\leq f+g$ and let $\phi_{n}(x)=\sup\{(m/n)\omega(x): 0\leq  m\leq n, (m/n)\omega(x)\leq f(x)\}.$ Also let $\psi_{n}(x)=\sup\{(1-\frac{1}{n})\omega(x)-\phi_{n}(x),0\}.$ Show that $$(1-\frac{1}{n})\omega\leq\psi_{n}+\phi_{n},\quad\phi_{n}\leq f,\psi_{n}\leq g.$$ I've proved exercise 4.E but I have problems proving 4.F My attempt:because of the problem 4.E we can assure that $\sup\int\omega d\mu=\int f d\mu.$ In fact, we have the existence of $\int f d\mu$ and $\int g d\mu.$ I think the proof is divided in two parts: proving the inequialities to get the desired equality. I don't get how utilize the previous result to finish this exercise. Any kind of help is thanked in advanced.","I'm trying to prove the exercise 4.F of Bartle's book: The Elements of Integration and Lebesgue Measure. 4.F Employ Exercise 4.E to establish that if $f,g\in M^{+}(X,\mathcal{F})$ then $f+g\in M^{+}(X,\mathcal{F})$ and $$\int(f+g)d\mu=\int fd\mu+\int gd\mu.$$ Exercise 4.E: Let $f,g\in M^{+},$ let $\omega\in M^{+}$ be a simple function such that $\omega\leq f+g$ and let $\phi_{n}(x)=\sup\{(m/n)\omega(x): 0\leq  m\leq n, (m/n)\omega(x)\leq f(x)\}.$ Also let $\psi_{n}(x)=\sup\{(1-\frac{1}{n})\omega(x)-\phi_{n}(x),0\}.$ Show that $$(1-\frac{1}{n})\omega\leq\psi_{n}+\phi_{n},\quad\phi_{n}\leq f,\psi_{n}\leq g.$$ I've proved exercise 4.E but I have problems proving 4.F My attempt:because of the problem 4.E we can assure that $\sup\int\omega d\mu=\int f d\mu.$ In fact, we have the existence of $\int f d\mu$ and $\int g d\mu.$ I think the proof is divided in two parts: proving the inequialities to get the desired equality. I don't get how utilize the previous result to finish this exercise. Any kind of help is thanked in advanced.",,"['real-analysis', 'measure-theory']"
35,Is the set of points for which $\lim f_n$ exists still measurable?,Is the set of points for which  exists still measurable?,\lim f_n,"Suppose $(X,\mathscr A)$ is a measurable space, $Y$ is Polish and $f_n:X\to Y$ is a sequence of measurable functions. Then  the set $L\subseteq X$ for which $\lim f_n$ exists is measurable. The proof relies on the fact that $L$ is just the set of $x\in X$ for which $(f_n(x))_n$ is Cauchy in $Y$. Of course, this only works because $Y$ is complete. Moreover, it is clear that separability is necessary, to ensure that $\mathscr B(Y\times Y)=\mathscr B(Y)\times \mathscr B(Y).$ Now I am wondering what happens if we remove the condition of completeness of $Y?$ Obviously the forementioned proof won't work. In fact, I think that completeness is necessary, and am looking for a counterexample. i.e.; a sequence of measurable $f_n$ such that $L=\left \{ x:\lim f_n(x)\  \text {exists} \right \}$ is not measurable.","Suppose $(X,\mathscr A)$ is a measurable space, $Y$ is Polish and $f_n:X\to Y$ is a sequence of measurable functions. Then  the set $L\subseteq X$ for which $\lim f_n$ exists is measurable. The proof relies on the fact that $L$ is just the set of $x\in X$ for which $(f_n(x))_n$ is Cauchy in $Y$. Of course, this only works because $Y$ is complete. Moreover, it is clear that separability is necessary, to ensure that $\mathscr B(Y\times Y)=\mathscr B(Y)\times \mathscr B(Y).$ Now I am wondering what happens if we remove the condition of completeness of $Y?$ Obviously the forementioned proof won't work. In fact, I think that completeness is necessary, and am looking for a counterexample. i.e.; a sequence of measurable $f_n$ such that $L=\left \{ x:\lim f_n(x)\  \text {exists} \right \}$ is not measurable.",,"['real-analysis', 'measure-theory']"
36,Differentiation of functions defined by Borel measures.,Differentiation of functions defined by Borel measures.,,"My question has to do with a detail in the proof of the following: Let $\mu$ be a finite Borel measure on $\mathbb R$, and let $F : \mathbb R\to \mathbb R$  be defined by $F(x) =\mu ((−∞,x]).$ If $\mu$ is differentiable at $a$, then $F$ is differentiable at $a$, and $F'(a) = (D\mu)(a)$ where $$D\mu(a)=\limsup_{\epsilon \downarrow 0}\left \{ \frac{\mu (I))}{\lambda (I)}: a\in I; |I|<\epsilon\right \}.$$ The proof goes as follows: if $x<a$ then $\frac{F(x)-F(a)}{x-a}=\frac{\mu ([a,x])}{\lambda ([a,x])}$  whereas  $\frac{F(x)-F(a)}{x-a}=\frac{\mu ((a,x])}{\lambda ((a,x])}$ if $x>a.$ In the first case, we have $$D\mu(a)=\limsup_{\epsilon \downarrow 0^-}\left \{ \frac{\mu ([a,x])}{\lambda ([a,x])}: a\in I; |I|<\epsilon\right \}=\lim_{x\to a^{-}}\frac{F(x)-F(a)}{x-a}.$$ In the second case, we want to assert that $$D\mu(a)=\limsup_{\epsilon \downarrow 0^+}\left \{ \frac{\mu ([a,x])}{\lambda ([a,x])}: a\in I; |I|<\epsilon\right \}=\lim_{x\to a^{+}}\frac{F(x)-F(a)}{x-a}$$ and then the result is immediate. But this is not quite right because the intervals above (when $x>a$) are $\it{half-open}.$ Now it is pretty obvious that these intervals can be approximated to any desired degree of accuracy by considering intervals of the form $[a+1/n,x]$ so I am looking for a rigorous way to work this into the definition of $D\mu.$ Maybe along these lines: If $D\mu(a)=d$ then for all $r >0,$ there is an $\epsilon>0$ such that $\ \left |  \frac{\mu([a,x])}{\lambda([a,x])}-d \right |<r$ whenever $x-a<\epsilon.$ Then for each integer $n$  such that $a+1/n<x$ we have  $x-(a+1/n)=x-1/n-a<\epsilon$ and  then, $\left |\frac{\mu([a+1/n,x])}{\lambda([a+1/n,x])}  -d\right |<r.$ Since this is true for all integers $n$ such that $a+1/n<x$, the result follows. On the other hand, since $\mu$ is differentiable at $a$ we must have $\mu (\left \{ a \right \})=0, $ so perhaps it is as easy as noting that $[a,x]=(a,x]\cup \left \{ a \right \}.$","My question has to do with a detail in the proof of the following: Let $\mu$ be a finite Borel measure on $\mathbb R$, and let $F : \mathbb R\to \mathbb R$  be defined by $F(x) =\mu ((−∞,x]).$ If $\mu$ is differentiable at $a$, then $F$ is differentiable at $a$, and $F'(a) = (D\mu)(a)$ where $$D\mu(a)=\limsup_{\epsilon \downarrow 0}\left \{ \frac{\mu (I))}{\lambda (I)}: a\in I; |I|<\epsilon\right \}.$$ The proof goes as follows: if $x<a$ then $\frac{F(x)-F(a)}{x-a}=\frac{\mu ([a,x])}{\lambda ([a,x])}$  whereas  $\frac{F(x)-F(a)}{x-a}=\frac{\mu ((a,x])}{\lambda ((a,x])}$ if $x>a.$ In the first case, we have $$D\mu(a)=\limsup_{\epsilon \downarrow 0^-}\left \{ \frac{\mu ([a,x])}{\lambda ([a,x])}: a\in I; |I|<\epsilon\right \}=\lim_{x\to a^{-}}\frac{F(x)-F(a)}{x-a}.$$ In the second case, we want to assert that $$D\mu(a)=\limsup_{\epsilon \downarrow 0^+}\left \{ \frac{\mu ([a,x])}{\lambda ([a,x])}: a\in I; |I|<\epsilon\right \}=\lim_{x\to a^{+}}\frac{F(x)-F(a)}{x-a}$$ and then the result is immediate. But this is not quite right because the intervals above (when $x>a$) are $\it{half-open}.$ Now it is pretty obvious that these intervals can be approximated to any desired degree of accuracy by considering intervals of the form $[a+1/n,x]$ so I am looking for a rigorous way to work this into the definition of $D\mu.$ Maybe along these lines: If $D\mu(a)=d$ then for all $r >0,$ there is an $\epsilon>0$ such that $\ \left |  \frac{\mu([a,x])}{\lambda([a,x])}-d \right |<r$ whenever $x-a<\epsilon.$ Then for each integer $n$  such that $a+1/n<x$ we have  $x-(a+1/n)=x-1/n-a<\epsilon$ and  then, $\left |\frac{\mu([a+1/n,x])}{\lambda([a+1/n,x])}  -d\right |<r.$ Since this is true for all integers $n$ such that $a+1/n<x$, the result follows. On the other hand, since $\mu$ is differentiable at $a$ we must have $\mu (\left \{ a \right \})=0, $ so perhaps it is as easy as noting that $[a,x]=(a,x]\cup \left \{ a \right \}.$",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
37,"Is $C_c^{\infty}(\mathbb{R}^n)$ dense in $L^p(M,d\sigma)$, $1\leq p<\infty$, where $M$ is an $n-1$ regular surface in $\mathbb{R}^n$?","Is  dense in , , where  is an  regular surface in ?","C_c^{\infty}(\mathbb{R}^n) L^p(M,d\sigma) 1\leq p<\infty M n-1 \mathbb{R}^n","I know that, given an open set $\Omega\subseteq\mathbb{R}^n$, $C_c^{\infty}(\Omega)$ (smooth functions with compact support) is dense in $L^p(\Omega)$, $1\leq p<\infty$. Let $M$ be a smooth $n-1$ regular surface in $\mathbb{R}^n$, and let $d\sigma$ be the surface measure. Is it true that $C_c^{\infty}(\mathbb{R}^n)$ is dense in $L^p(M,d\sigma)$, $1\leq p<\infty$? That is, if $\int_M |f|^p\,d\sigma<\infty$, can we find $\{f_m\}\subseteq C_c^{\infty}(\mathbb{R}^n)$ such that $\lim_m \int_M|f-f_m|^p\,d\sigma=0$? If not, which spaces would be dense in $L^p(M,d\sigma)$?","I know that, given an open set $\Omega\subseteq\mathbb{R}^n$, $C_c^{\infty}(\Omega)$ (smooth functions with compact support) is dense in $L^p(\Omega)$, $1\leq p<\infty$. Let $M$ be a smooth $n-1$ regular surface in $\mathbb{R}^n$, and let $d\sigma$ be the surface measure. Is it true that $C_c^{\infty}(\mathbb{R}^n)$ is dense in $L^p(M,d\sigma)$, $1\leq p<\infty$? That is, if $\int_M |f|^p\,d\sigma<\infty$, can we find $\{f_m\}\subseteq C_c^{\infty}(\mathbb{R}^n)$ such that $\lim_m \int_M|f-f_m|^p\,d\sigma=0$? If not, which spaces would be dense in $L^p(M,d\sigma)$?",,"['measure-theory', 'differential-geometry', 'surface-integrals']"
38,Upward continuous multiplication?,Upward continuous multiplication?,,"While reading the preface of Terence Tao's An Introduction to Measure Theory , I came across the following statement: We note also that once one adopts the convention $+\infty\cdot0 = 0\cdot+\infty= 0$ , then multiplication becomes upward continuous (in the sense that whenever $x_n \in [0, +\infty]$ increases to $x \in [0, +\infty]$ , and $y_n \in [0, +\infty]$ increases to $y \in [0, +\infty]$ , then $x_ny_n$ increases to $xy$ ) but not downward continuous ( e.g. $1/n \to 0$ , but $1/n \cdot +\infty \not\to 0\cdot+\infty$ ). Can anyone give me some intuition as to what this means? What would be an example of an upward continuous function?","While reading the preface of Terence Tao's An Introduction to Measure Theory , I came across the following statement: We note also that once one adopts the convention , then multiplication becomes upward continuous (in the sense that whenever increases to , and increases to , then increases to ) but not downward continuous ( e.g. , but ). Can anyone give me some intuition as to what this means? What would be an example of an upward continuous function?","+\infty\cdot0 =
0\cdot+\infty= 0 x_n \in [0, +\infty] x \in [0, +\infty] y_n \in [0, +\infty] y \in [0, +\infty] x_ny_n xy 1/n \to 0 1/n \cdot +\infty \not\to 0\cdot+\infty","['real-analysis', 'measure-theory']"
39,Showing the Monotone Convergence Theorem for measurable sets,Showing the Monotone Convergence Theorem for measurable sets,,"I'm reading Real Analysis by Yeh and I'm looking at the following (the rest of the proof for part a on the next page essentially just uses telescoping series) Before reading Yeh's proof I had what I feel is a simpler way to prove part a.  My question is whether it still works or if Yeh's way is necessary (for instance, he split the $\mu(E_n)< \infty \; \forall n$ and the $\mu(E_n)= \infty$ for some n cases).  In my notes I like to be brief so if a shorter way works I'd like to write that out instead :) My idea: pick a sequence $(F_n:n \in \mathbb{N})$ in $\frak{A}$ where $F_1=E_1$, $F_n=E_n \setminus ( \cup_{k=1}^{n-1} E_k)$.  Then a previous lemma shows  $$\cup_{k=1}^n E_k = \cup_{k=1}^n F_k \text{ for } n=1,2,\ldots, \infty$$ Then by the countable additivity of $\mu$: \begin{split} \mu( \cup_{k=1}^\infty E_k) & = \mu( \cup_{k=1}^\infty F_k)= \sum_{k=1}^\infty \mu( F_k)\\ &= \lim_{n \to \infty} \sum_{k=1}^\infty \mu( F_k)= \lim_{n \to \infty} \mu( \cup_{k=1}^n F_k)\\ &= \lim_{n \to \infty} \mu( \cup_{k=1}^n E_k)= \lim_{n \to \infty} \mu( E_n) \end{split} Thanks in advance for any help!","I'm reading Real Analysis by Yeh and I'm looking at the following (the rest of the proof for part a on the next page essentially just uses telescoping series) Before reading Yeh's proof I had what I feel is a simpler way to prove part a.  My question is whether it still works or if Yeh's way is necessary (for instance, he split the $\mu(E_n)< \infty \; \forall n$ and the $\mu(E_n)= \infty$ for some n cases).  In my notes I like to be brief so if a shorter way works I'd like to write that out instead :) My idea: pick a sequence $(F_n:n \in \mathbb{N})$ in $\frak{A}$ where $F_1=E_1$, $F_n=E_n \setminus ( \cup_{k=1}^{n-1} E_k)$.  Then a previous lemma shows  $$\cup_{k=1}^n E_k = \cup_{k=1}^n F_k \text{ for } n=1,2,\ldots, \infty$$ Then by the countable additivity of $\mu$: \begin{split} \mu( \cup_{k=1}^\infty E_k) & = \mu( \cup_{k=1}^\infty F_k)= \sum_{k=1}^\infty \mu( F_k)\\ &= \lim_{n \to \infty} \sum_{k=1}^\infty \mu( F_k)= \lim_{n \to \infty} \mu( \cup_{k=1}^n F_k)\\ &= \lim_{n \to \infty} \mu( \cup_{k=1}^n E_k)= \lim_{n \to \infty} \mu( E_n) \end{split} Thanks in advance for any help!",,"['real-analysis', 'measure-theory', 'elementary-set-theory', 'convergence-divergence']"
40,Is there a function satisfying the following condition?,Is there a function satisfying the following condition?,,"I have a question about measure theory. Let $(X,\mathcal{F},\mu)$ be a measure space. Let $f$ be a $\mu$-integrable nonnegative function on $X$. I'm looking for a function $\varphi$ satisfying the following: $\varphi: \mathbb{R} \to \mathbb{R}$, nondecreasing, $\lim_{x \to \infty} \varphi(x)/x=\infty$, $\int_{X} \varphi \circ f\,d\mu<\infty$. My attempt \begin{align*} \int_{X} \varphi \circ f\,d\mu&=\int_{0}^{\infty} \varphi(x)\, \nu(dx)=\int_{0}^{\infty} \nu(\{\varphi>t\})\,dt, \end{align*} where $\nu(A)=\mu(f^{-1}(A))$, $A \in \mathcal{B}(\mathbb{R})$. From the Markov inequality,  \begin{align*} \nu(\{\varphi>t\}) \le \frac{1}{t} \int_{0}^{\infty}\varphi \,d \nu. \end{align*} However, $\int_{1}^{\infty} 1/t\,dt=\infty$. Is there sharper upperbound of $\nu(\{\varphi>t\})$ under a suitable condition on $\varphi$? What $\varphi$ should satify? If you know, please let me know.","I have a question about measure theory. Let $(X,\mathcal{F},\mu)$ be a measure space. Let $f$ be a $\mu$-integrable nonnegative function on $X$. I'm looking for a function $\varphi$ satisfying the following: $\varphi: \mathbb{R} \to \mathbb{R}$, nondecreasing, $\lim_{x \to \infty} \varphi(x)/x=\infty$, $\int_{X} \varphi \circ f\,d\mu<\infty$. My attempt \begin{align*} \int_{X} \varphi \circ f\,d\mu&=\int_{0}^{\infty} \varphi(x)\, \nu(dx)=\int_{0}^{\infty} \nu(\{\varphi>t\})\,dt, \end{align*} where $\nu(A)=\mu(f^{-1}(A))$, $A \in \mathcal{B}(\mathbb{R})$. From the Markov inequality,  \begin{align*} \nu(\{\varphi>t\}) \le \frac{1}{t} \int_{0}^{\infty}\varphi \,d \nu. \end{align*} However, $\int_{1}^{\infty} 1/t\,dt=\infty$. Is there sharper upperbound of $\nu(\{\varphi>t\})$ under a suitable condition on $\varphi$? What $\varphi$ should satify? If you know, please let me know.",,"['real-analysis', 'measure-theory']"
41,function with finite measure support in $L^p(\mathbb{R})$,function with finite measure support in,L^p(\mathbb{R}),"Let $p > q$ be fixed numbers in $[1,\infty]$. Give a proof or a counterexample to each of the statements below. (a) If $f \in L^p(\mathbb{R})$ has finite measure support, then $f \in L^q(\mathbb{R})$. (b) If $f \in L^q(\mathbb{R})$ has finite measure support, then $f \in L^p(\mathbb{R})$. (c) If $f \in L^p(\mathbb{R})$ is bounded, then $f \in L^q(\mathbb{R}$). (d) If $f \in L^q(\mathbb{R})$ is bounded, then $f \in L^p(\mathbb{R})$. For (a) I think it is true, since $f \in L^p(\mathbb{R})$ then $|f|^p$ is finite almost everywhere so is f. So let $$K_o=\lbrace x \in \mathbb{R} \; ; \; f(x)=0\rbrace \qquad K=\lbrace x \in \mathbb{R} \; ; \; f(x)\neq 0 \; \& \; \infty \rbrace \qquad K_{\infty}=\lbrace x \in \mathbb{R} \; ; \; f(x)=\infty\rbrace$$ Then $\mu(K_{\infty})=0$ $$\int|f|^q =\int_{K_0}|f|^q+\int_K |f|^q +\int_{K_{\infty}} |f|^q=\int_K |f|^q=M^q \mu(K)<\infty$$ For (b) my guess is false but I could not find any counterexample. Also no idea about (c) and (d)","Let $p > q$ be fixed numbers in $[1,\infty]$. Give a proof or a counterexample to each of the statements below. (a) If $f \in L^p(\mathbb{R})$ has finite measure support, then $f \in L^q(\mathbb{R})$. (b) If $f \in L^q(\mathbb{R})$ has finite measure support, then $f \in L^p(\mathbb{R})$. (c) If $f \in L^p(\mathbb{R})$ is bounded, then $f \in L^q(\mathbb{R}$). (d) If $f \in L^q(\mathbb{R})$ is bounded, then $f \in L^p(\mathbb{R})$. For (a) I think it is true, since $f \in L^p(\mathbb{R})$ then $|f|^p$ is finite almost everywhere so is f. So let $$K_o=\lbrace x \in \mathbb{R} \; ; \; f(x)=0\rbrace \qquad K=\lbrace x \in \mathbb{R} \; ; \; f(x)\neq 0 \; \& \; \infty \rbrace \qquad K_{\infty}=\lbrace x \in \mathbb{R} \; ; \; f(x)=\infty\rbrace$$ Then $\mu(K_{\infty})=0$ $$\int|f|^q =\int_{K_0}|f|^q+\int_K |f|^q +\int_{K_{\infty}} |f|^q=\int_K |f|^q=M^q \mu(K)<\infty$$ For (b) my guess is false but I could not find any counterexample. Also no idea about (c) and (d)",,"['measure-theory', 'lp-spaces']"
42,Translation of a finite set and lebesgue measure,Translation of a finite set and lebesgue measure,,Let $A \subset \mathbb{R}$ a finite set and $E \subset \mathbb{R} $ a lebesgue measurable set and $m(E)>0$.Prove that $\exists x\in \mathbb{R}$ and $\exists s>0$ such that $x+sA \subset E$. I tried to use fubini's theorem and the steinhauss theorem without success. Can someone help me with this?,Let $A \subset \mathbb{R}$ a finite set and $E \subset \mathbb{R} $ a lebesgue measurable set and $m(E)>0$.Prove that $\exists x\in \mathbb{R}$ and $\exists s>0$ such that $x+sA \subset E$. I tried to use fubini's theorem and the steinhauss theorem without success. Can someone help me with this?,,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
43,Criteria of finite Lebesgue measurability2,Criteria of finite Lebesgue measurability2,,"The problem: Let $E$ be a Lebesgue measurable subset of $\mathbb{R}^d$ with finite measure . To show that $\forall \epsilon>0$ , $\exists$ a compact set $V$ such that $m(E \setminus V) \leq \epsilon$ . My approach: $E$ is Lebesgue measurable . Fix $\epsilon > 0$ . Now we can employ the inner approximation by closed set criterion for Lebesgue measurability to assert that $\exists$ a closed set $F$ , contained in $E$ , such that $m(E \setminus F) \leq \frac{\epsilon}{3}$ . Now if $E$ is bounded, so is $F$ and we are done. So let us assume that $E$ is unbounded, so that $F$ is not necessarily bounded. By monotonicity , $m(F) \leq m(E) < \infty$ . Let us decompose $\mathbb{R}^d$ into countable number of almost disjoint closed bounded boxes. More formally, $\mathbb{R}^d=\bigcup_{n=1}^{\infty}B_n$ , where $B_n$$'$ s are almost disjoint closed boxes. Now let $G$ be the set of all these closed boxes which are completely contained inside $F$ . Formally written, $$G=\bigcup\Big\{B_{n_j} : B_{n_j} = B_n ~\mbox{for some}~ n \in \mathbb{N} ~\mbox{and}~ B_{n_j} \subset F\Big\}$$ Clearly $G \subset F$ . Since $G$ is countable union of almost disjoint closed boxes, $m(G)=\sum_{j=1}^{\infty}|B_{n_j}|$ . Again by monotonicity , $m(G) \leq m(F) < \infty$ . Hence the sum $\sum_{j=1}^{\infty}|B_{n_j}|$ converges. Now we can choose $N \in \mathbb{N}$ , which depends on the pre-fixed $\epsilon$ , such that the partial sum $\sum_{j=1}^N|B_{n_j}| \geq \sum_{j=1}^{\infty}|B_{n_j}|-\frac{\epsilon}{3}$ . Define $S_N=\bigcup_{n_j=1}^N B_{n_j}$ . Clearly, $S_N \subset G$ . $S_N$ is closed and bounded (being finite union of closed, bounded boxes) and hence compact , by the Heine-Borel theorem . Thus it is a possible candidate for the required compact set contained in $E$ . Now, by additivity of Lebesgue measure, $m(G)=m(S_N)+m(G \setminus S_N)$ . Then $m(G \setminus S_N)=m(G)-m(S_N)=\sum_{j=1}^{\infty}|B_{n_j}| - \sum_{j=1}^N|B_{n_j}| \leq \frac{\epsilon}{3}$ . Finally we need to control the quantity $m(E \setminus S_N)$ . Note that $$E \setminus S_N = (E \setminus F) ~\bigcup~ (F \setminus G) ~\bigcup~ (G \setminus S_N)$$ Each of the sets in the right-hand side of the above equation is Lebesgue measurable (each being intersection of two Lebesgue measurable sets). Using additivity , we have $$m(E \setminus S_N)=m(E \setminus F)+m(F \setminus G)+m(G \setminus S_N)$$ We have already shown that $m(E \setminus F) \leq \frac{\epsilon}{3}$ and $m(G \setminus S_N) \leq \frac{\epsilon}{3}$ . All that is left is to control the quantity $m(F \setminus G)$ . It is intuitively very clear that we should be able to keep this quantity as small as possible, whenever $E$ is Lebesgue measurable , making the decomposition of $\mathbb{R}^d$ increasingly finer . What I need is a rigourous argument to defend this point. Any help would be greatly appreciated. EDIT: I think that I found a logic. Suppose $m(F \setminus G) > \frac{\epsilon}{3}$ . Since $F \setminus G$ is Lebesgue measurable , we can use the inner approximation by closed criterion for Lebesgue measurability to assert that $\exists$ a closed set $H$ , contained in $F \setminus G$ such that $m((F \setminus G) \setminus H) \leq \frac{\epsilon}{3}$ . Then we can include $H$ to $G$ and replace $G$ with $G^*=G \cup H$ in the above argument and continue. Please check if this reasoning is good enough.","The problem: Let be a Lebesgue measurable subset of with finite measure . To show that , a compact set such that . My approach: is Lebesgue measurable . Fix . Now we can employ the inner approximation by closed set criterion for Lebesgue measurability to assert that a closed set , contained in , such that . Now if is bounded, so is and we are done. So let us assume that is unbounded, so that is not necessarily bounded. By monotonicity , . Let us decompose into countable number of almost disjoint closed bounded boxes. More formally, , where s are almost disjoint closed boxes. Now let be the set of all these closed boxes which are completely contained inside . Formally written, Clearly . Since is countable union of almost disjoint closed boxes, . Again by monotonicity , . Hence the sum converges. Now we can choose , which depends on the pre-fixed , such that the partial sum . Define . Clearly, . is closed and bounded (being finite union of closed, bounded boxes) and hence compact , by the Heine-Borel theorem . Thus it is a possible candidate for the required compact set contained in . Now, by additivity of Lebesgue measure, . Then . Finally we need to control the quantity . Note that Each of the sets in the right-hand side of the above equation is Lebesgue measurable (each being intersection of two Lebesgue measurable sets). Using additivity , we have We have already shown that and . All that is left is to control the quantity . It is intuitively very clear that we should be able to keep this quantity as small as possible, whenever is Lebesgue measurable , making the decomposition of increasingly finer . What I need is a rigourous argument to defend this point. Any help would be greatly appreciated. EDIT: I think that I found a logic. Suppose . Since is Lebesgue measurable , we can use the inner approximation by closed criterion for Lebesgue measurability to assert that a closed set , contained in such that . Then we can include to and replace with in the above argument and continue. Please check if this reasoning is good enough.",E \mathbb{R}^d \forall \epsilon>0 \exists V m(E \setminus V) \leq \epsilon E \epsilon > 0 \exists F E m(E \setminus F) \leq \frac{\epsilon}{3} E F E F m(F) \leq m(E) < \infty \mathbb{R}^d \mathbb{R}^d=\bigcup_{n=1}^{\infty}B_n B_n' G F G=\bigcup\Big\{B_{n_j} : B_{n_j} = B_n ~\mbox{for some}~ n \in \mathbb{N} ~\mbox{and}~ B_{n_j} \subset F\Big\} G \subset F G m(G)=\sum_{j=1}^{\infty}|B_{n_j}| m(G) \leq m(F) < \infty \sum_{j=1}^{\infty}|B_{n_j}| N \in \mathbb{N} \epsilon \sum_{j=1}^N|B_{n_j}| \geq \sum_{j=1}^{\infty}|B_{n_j}|-\frac{\epsilon}{3} S_N=\bigcup_{n_j=1}^N B_{n_j} S_N \subset G S_N E m(G)=m(S_N)+m(G \setminus S_N) m(G \setminus S_N)=m(G)-m(S_N)=\sum_{j=1}^{\infty}|B_{n_j}| - \sum_{j=1}^N|B_{n_j}| \leq \frac{\epsilon}{3} m(E \setminus S_N) E \setminus S_N = (E \setminus F) ~\bigcup~ (F \setminus G) ~\bigcup~ (G \setminus S_N) m(E \setminus S_N)=m(E \setminus F)+m(F \setminus G)+m(G \setminus S_N) m(E \setminus F) \leq \frac{\epsilon}{3} m(G \setminus S_N) \leq \frac{\epsilon}{3} m(F \setminus G) E \mathbb{R}^d m(F \setminus G) > \frac{\epsilon}{3} F \setminus G \exists H F \setminus G m((F \setminus G) \setminus H) \leq \frac{\epsilon}{3} H G G G^*=G \cup H,['real-analysis']
44,Is it true the derivative of the length of a Lipschitz path equals its speed? (when they exist),Is it true the derivative of the length of a Lipschitz path equals its speed? (when they exist),,"$\newcommand{\ga}{\gamma}$ $\newcommand{\e}{\epsilon}$ I have the following situation: $(X,d)$ is a metric space. $\gamma:[0,1] \to X$ is a Lipschitz path . The speed of $\gamma$ is defined as $$ \nu_{\ga}(s):=\lim_{\e \to 0} \frac{d\left( \ga(s),\ga(s+\e) \right)}{|\e|}, $$ if the limit exists. Define $g(t)=L(\ga|_{[0,t]})$, and assume $g'(t_0),\nu_{\ga}(t_0)$ exist for a specific $t_0 \in [0,1]$. Is it true that $g'(t_0)=\nu_{\ga}(t_0)$? Note: It is a known theorem, that for any Lipschitz path $\ga$, the speed $\nu_{\ga}(t)$ exists for almost all $t$, and $L(\ga)=\int \nu_{\ga}(t) dt$ (See ""A course in metric geometry"" by Burago,Burago and Ivanov, theorem 2.7.6). In fact, the proof actually shows that for almost all $t$, $g'(t),\nu_{\ga}(t)$ exist and are equal. I am asking about their equality at a single point (assuming existence). Partial Results: $$g'(t)=\frac{d}{dt}L(\ga|_{[0,t]})=\lim_{\Delta t \to 0+} \frac{L(\ga|_{[0,t+\Delta t]})-L(\ga|_{[0,t]})}{\Delta t}=\lim_{\Delta t \to 0+} \frac{L(\ga|_{[t,t+\Delta t]})}{\Delta t} $$ $$ \ge  \lim_{\Delta t \to 0+} \frac{d\left( \ga(t),\ga(t+\Delta t) \right)}{\Delta t} = \nu_{\ga}(t)$$ So, we established $g'(t) \ge \nu_{\ga}(t) $. The question about the other direction still remains. In the special case, where $X$ is a length space, and $\gamma$ is a geodesic (i.e locally a shortest path), we have that $d\left( \ga(t),\ga(t+\Delta t) \right)=L(\ga|_{[t,t+\Delta t]})$ (for small enough $\Delta t$), so the equality obviously holds. Perhaps it will be easier to prove this for length spaces, but without the assumption that $\ga$ is a geodesic, I do not see how it helps.","$\newcommand{\ga}{\gamma}$ $\newcommand{\e}{\epsilon}$ I have the following situation: $(X,d)$ is a metric space. $\gamma:[0,1] \to X$ is a Lipschitz path . The speed of $\gamma$ is defined as $$ \nu_{\ga}(s):=\lim_{\e \to 0} \frac{d\left( \ga(s),\ga(s+\e) \right)}{|\e|}, $$ if the limit exists. Define $g(t)=L(\ga|_{[0,t]})$, and assume $g'(t_0),\nu_{\ga}(t_0)$ exist for a specific $t_0 \in [0,1]$. Is it true that $g'(t_0)=\nu_{\ga}(t_0)$? Note: It is a known theorem, that for any Lipschitz path $\ga$, the speed $\nu_{\ga}(t)$ exists for almost all $t$, and $L(\ga)=\int \nu_{\ga}(t) dt$ (See ""A course in metric geometry"" by Burago,Burago and Ivanov, theorem 2.7.6). In fact, the proof actually shows that for almost all $t$, $g'(t),\nu_{\ga}(t)$ exist and are equal. I am asking about their equality at a single point (assuming existence). Partial Results: $$g'(t)=\frac{d}{dt}L(\ga|_{[0,t]})=\lim_{\Delta t \to 0+} \frac{L(\ga|_{[0,t+\Delta t]})-L(\ga|_{[0,t]})}{\Delta t}=\lim_{\Delta t \to 0+} \frac{L(\ga|_{[t,t+\Delta t]})}{\Delta t} $$ $$ \ge  \lim_{\Delta t \to 0+} \frac{d\left( \ga(t),\ga(t+\Delta t) \right)}{\Delta t} = \nu_{\ga}(t)$$ So, we established $g'(t) \ge \nu_{\ga}(t) $. The question about the other direction still remains. In the special case, where $X$ is a length space, and $\gamma$ is a geodesic (i.e locally a shortest path), we have that $d\left( \ga(t),\ga(t+\Delta t) \right)=L(\ga|_{[t,t+\Delta t]})$ (for small enough $\Delta t$), so the equality obviously holds. Perhaps it will be easier to prove this for length spaces, but without the assumption that $\ga$ is a geodesic, I do not see how it helps.",,"['real-analysis', 'measure-theory', 'metric-spaces', 'curves', 'lipschitz-functions']"
45,Equivalence of Lebesgue measurability condition,Equivalence of Lebesgue measurability condition,,"I'm having trouble proving the following proposition, which is ""left to the reader"". Let $f:[a,b]\to \mathbb{R}$ be a bounded function. Let us define $$s(f) := \left\{\int \phi : \phi \text{ is simple, } \phi \leq f\right\}$$ $$S(f) := \left\{\int \phi : \phi \text{ is simple, } \phi \geq f\right\}$$ and $$\underline\int f := \sup s(f)$$ $$\overline\int f := \inf S(f).$$   Show that $f$ is Lebesgue measurable iff $\underline\int f = \overline\int f$. Supposing that $f$ is Lebesgue measurable, I thought of approximating $f$ using two sequences of simple functions converging ""from above"" and ""from below"" to $f$, and evaluate the error in the approximation, but I couldn't develop this idea any further.","I'm having trouble proving the following proposition, which is ""left to the reader"". Let $f:[a,b]\to \mathbb{R}$ be a bounded function. Let us define $$s(f) := \left\{\int \phi : \phi \text{ is simple, } \phi \leq f\right\}$$ $$S(f) := \left\{\int \phi : \phi \text{ is simple, } \phi \geq f\right\}$$ and $$\underline\int f := \sup s(f)$$ $$\overline\int f := \inf S(f).$$   Show that $f$ is Lebesgue measurable iff $\underline\int f = \overline\int f$. Supposing that $f$ is Lebesgue measurable, I thought of approximating $f$ using two sequences of simple functions converging ""from above"" and ""from below"" to $f$, and evaluate the error in the approximation, but I couldn't develop this idea any further.",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
46,using measure theory in a proof of invariance of domain,using measure theory in a proof of invariance of domain,,"https://terrytao.wordpress.com/2011/06/13 Terence Tao, in the blog cited above, derives invariance of domain from the fixed point theorem without reliance on algebraic-topology. He does, however, appeal to measure theory for a result that I am unable to replicate. If I understand him he asserts: If $P$ is a polynomial in $ \mathbb{R}^n$ then there exists an $y\in \mathbb{R}^n$ and a $\delta > 0$ such that $P(x+\epsilon y)\neq 0$ for $x\in S^{n-1}$ and $0 < \epsilon < \delta$. He says this follows from the fact that $S^{n-1}$ and $P(S^{n-1})$ both have measure $0$ in $\mathbb{R}^n$. Do I interpret him correctly? His assertions sound plausible but I need a hint or two to make a convincing argument of my own. Is it true that an infinitesimal displacement is sufficient to make 2 sets of measure 0 disjoint?","https://terrytao.wordpress.com/2011/06/13 Terence Tao, in the blog cited above, derives invariance of domain from the fixed point theorem without reliance on algebraic-topology. He does, however, appeal to measure theory for a result that I am unable to replicate. If I understand him he asserts: If $P$ is a polynomial in $ \mathbb{R}^n$ then there exists an $y\in \mathbb{R}^n$ and a $\delta > 0$ such that $P(x+\epsilon y)\neq 0$ for $x\in S^{n-1}$ and $0 < \epsilon < \delta$. He says this follows from the fact that $S^{n-1}$ and $P(S^{n-1})$ both have measure $0$ in $\mathbb{R}^n$. Do I interpret him correctly? His assertions sound plausible but I need a hint or two to make a convincing argument of my own. Is it true that an infinitesimal displacement is sufficient to make 2 sets of measure 0 disjoint?",,['measure-theory']
47,"How to show $\int_{E} x \, d\mu \geq \mu(E)^2 / 2$",How to show,"\int_{E} x \, d\mu \geq \mu(E)^2 / 2","Let $E \subseteq [0,1]$ , $\mu$ the Lebesgue measure. I would like to show that $\int_{E} x \, d\mu \geq \frac{1}{2} \mu(E)^2$ . Lemma: $$ \int_{0}^{\mu(E)} x \, d\mu \leq \int_{E} x \, d\mu $$ This lemma seems pretty reasonable, in fact, I would expect it to hold for any monotone function $f : [0, 1] \to \mathbb{R}$ : $$ \int_{0}^{\mu(E)} f \, d\mu \leq \int_{E} f \, d\mu $$ But I'm not sure how to prove it rigorously. If the lemma holds, the result follow as $\int_{0}^{\mu(E)} x \, d\mu = \frac{1}{2} \mu(E)^2$ . Idea of a proof: \begin{align*} \int_{0}^{1} 1_{E} f \, d\mu &= \left[ f(x) \int_{0}^{x} 1_{E} \, d\mu \right]_{0}^{1} - \int_{0}^{1} \left( \int_{0}^{x} 1_{E} \, d\mu \right) f'(x) \, d\mu(x) \\ &= f(1) \mu(E) - \int_{0}^{1} \left( \int_{0}^{x} 1_{E} \, d\mu \right) f'(x) \, d\mu(x) \\ &\geq f(1) \mu(E) - \int_{0}^{1} \left( \int_{0}^{x} 1_{[0, \mu(E)]} \, d\mu \right) f'(x) \, d\mu(x)  \\ &= \int_{0}^{1} 1_{[0, \mu(E)]} f \, d\mu \end{align*} Again, I'm not sure if integration by parts is valid in this context, and I'm pretty sure that $f$ needn't be differentiable for the lemma to hold.","Let , the Lebesgue measure. I would like to show that . Lemma: This lemma seems pretty reasonable, in fact, I would expect it to hold for any monotone function : But I'm not sure how to prove it rigorously. If the lemma holds, the result follow as . Idea of a proof: Again, I'm not sure if integration by parts is valid in this context, and I'm pretty sure that needn't be differentiable for the lemma to hold.","E \subseteq [0,1] \mu \int_{E} x \, d\mu \geq \frac{1}{2} \mu(E)^2  \int_{0}^{\mu(E)} x \, d\mu \leq \int_{E} x \, d\mu  f : [0, 1] \to \mathbb{R}  \int_{0}^{\mu(E)} f \, d\mu \leq \int_{E} f \, d\mu  \int_{0}^{\mu(E)} x \, d\mu = \frac{1}{2} \mu(E)^2 \begin{align*}
\int_{0}^{1} 1_{E} f \, d\mu
&= \left[ f(x) \int_{0}^{x} 1_{E} \, d\mu \right]_{0}^{1}
- \int_{0}^{1} \left( \int_{0}^{x} 1_{E} \, d\mu \right) f'(x) \, d\mu(x) \\
&= f(1) \mu(E) - \int_{0}^{1} \left( \int_{0}^{x} 1_{E} \, d\mu \right) f'(x) \, d\mu(x) \\
&\geq f(1) \mu(E) - \int_{0}^{1} \left( \int_{0}^{x} 1_{[0, \mu(E)]} \, d\mu \right) f'(x) \, d\mu(x)  \\
&= \int_{0}^{1} 1_{[0, \mu(E)]} f \, d\mu
\end{align*} f","['real-analysis', 'measure-theory']"
48,measure preserving map does not increase distance,measure preserving map does not increase distance,,"I read a sentence saying ""any measurable subset of $\mathbb{R}$ can be mapped to an interval by a measure-preserving transformation which does not increase distances"" Here the measure is Lebesgue measure and the distance is the standard distance. Is there any reference for this? Thanks!","I read a sentence saying ""any measurable subset of $\mathbb{R}$ can be mapped to an interval by a measure-preserving transformation which does not increase distances"" Here the measure is Lebesgue measure and the distance is the standard distance. Is there any reference for this? Thanks!",,"['measure-theory', 'reference-request']"
49,Conclusion about measurable functions from knowledge about continuous functions,Conclusion about measurable functions from knowledge about continuous functions,,"Let $\mu$ and $\nu$ be two finite Borel measures on $\mathbb{R}$. We know that if $$\int f d\mu = \int f d\nu $$ for all continuous functions $f$ then $\mu=\nu$ and so the equation above holds for all measurable functions. Now let $\mu$ be as above and let $\{\nu_n\}_n$ be a sequence of measures on $\mathbb{R}$ such that $$ \int f d\mu = \lim_{n\to\infty}\int f d\nu_n$$ again, for all continuous functions $f$ (the existence of the limit is part of the input). What is now necessary in order to conclude that the above equation holds for all measurable $f$ as well? I suppose some notion of convergence of measures and some usage of a dominated convergence theorem for the measure instead of the integrand, but I'm not sure.. Let $g$ be measurable and let $f_n$ be a sequence of continuous functions converging to $g$ from below. Then we have  \begin{align} \int g d\mu &= \int \lim_{n\to\infty}f_n d\mu \\ &\stackrel{1}{=} \lim_{n\to\infty} \int f_n d\mu \\ &\stackrel{2}{=}   \lim_{n\to\infty} \lim_{m\to\infty}\int f_n d\nu_{m} \\ &\stackrel{3}{=}\lim_{m\to\infty} \lim_{n\to\infty}\int f_n d\nu_{m} \\ &\stackrel{4}{=}\lim_{m\to\infty} \int \lim_{n\to\infty} f_n d\nu_{m} \\ &= \lim_{m\to\infty} \int g d\nu_{m} \end{align} Where in $1$ and $4$ we used the dominated convergence theorem, in $2$ we used the hypothesis and $3$ remains to be justified.","Let $\mu$ and $\nu$ be two finite Borel measures on $\mathbb{R}$. We know that if $$\int f d\mu = \int f d\nu $$ for all continuous functions $f$ then $\mu=\nu$ and so the equation above holds for all measurable functions. Now let $\mu$ be as above and let $\{\nu_n\}_n$ be a sequence of measures on $\mathbb{R}$ such that $$ \int f d\mu = \lim_{n\to\infty}\int f d\nu_n$$ again, for all continuous functions $f$ (the existence of the limit is part of the input). What is now necessary in order to conclude that the above equation holds for all measurable $f$ as well? I suppose some notion of convergence of measures and some usage of a dominated convergence theorem for the measure instead of the integrand, but I'm not sure.. Let $g$ be measurable and let $f_n$ be a sequence of continuous functions converging to $g$ from below. Then we have  \begin{align} \int g d\mu &= \int \lim_{n\to\infty}f_n d\mu \\ &\stackrel{1}{=} \lim_{n\to\infty} \int f_n d\mu \\ &\stackrel{2}{=}   \lim_{n\to\infty} \lim_{m\to\infty}\int f_n d\nu_{m} \\ &\stackrel{3}{=}\lim_{m\to\infty} \lim_{n\to\infty}\int f_n d\nu_{m} \\ &\stackrel{4}{=}\lim_{m\to\infty} \int \lim_{n\to\infty} f_n d\nu_{m} \\ &= \lim_{m\to\infty} \int g d\nu_{m} \end{align} Where in $1$ and $4$ we used the dominated convergence theorem, in $2$ we used the hypothesis and $3$ remains to be justified.",,"['real-analysis', 'integration', 'measure-theory', 'lebesgue-measure']"
50,Conditions on a complex measure to be real,Conditions on a complex measure to be real,,"Let $(X,\mathcal{S}, \mu)$ be a measure space with $X$ a locally compact Hausdorff space, $\mathcal{S}$ the Borel subsets of $X$ and $\mu$ a complex measure. Suppose that  $$ \int_X f \ d\mu \in \mathbb{R} $$ for all  $f\in C( X,\mathbb{R} )$ i.e. the continous functions from $X$ to $\mathbb{R}$. I want to know if this implies that $\mu$ is a real measure? Of  course with $f\equiv1$ we have that $\mu(X) \in \mathbb{R}$, but does this necessarily implies that $\mu(E)\in \mathbb{R}$ for all $E \in \mathcal{S}?$ I am incline to think that $\mu$ must be a regular measure for this to happen.","Let $(X,\mathcal{S}, \mu)$ be a measure space with $X$ a locally compact Hausdorff space, $\mathcal{S}$ the Borel subsets of $X$ and $\mu$ a complex measure. Suppose that  $$ \int_X f \ d\mu \in \mathbb{R} $$ for all  $f\in C( X,\mathbb{R} )$ i.e. the continous functions from $X$ to $\mathbb{R}$. I want to know if this implies that $\mu$ is a real measure? Of  course with $f\equiv1$ we have that $\mu(X) \in \mathbb{R}$, but does this necessarily implies that $\mu(E)\in \mathbb{R}$ for all $E \in \mathcal{S}?$ I am incline to think that $\mu$ must be a regular measure for this to happen.",,"['real-analysis', 'integration', 'measure-theory', 'complex-integration']"
51,$\mu * \nu$ a finite Borel measure in $\mathbb{R}$?,a finite Borel measure in ?,\mu * \nu \mathbb{R},"Let $\mu$ and $\nu$ be two finite Borel measures on $\mathbb{R}$. For any Borel set $A \subset \mathbb{R}$, define$$\mu * \nu(A) = \mu \times \nu(\{(x, y) \in \mathbb{R}^2 : x + y \in A\}).$$Is $\mu * \nu$ necessarily a finite Borel measure in $\mathbb{R}$? Thoughts. I know that the set $\{(x, y) \in \mathbb{R}^2 : x + y \in A\}$ is Borel when $A$ is Borel.","Let $\mu$ and $\nu$ be two finite Borel measures on $\mathbb{R}$. For any Borel set $A \subset \mathbb{R}$, define$$\mu * \nu(A) = \mu \times \nu(\{(x, y) \in \mathbb{R}^2 : x + y \in A\}).$$Is $\mu * \nu$ necessarily a finite Borel measure in $\mathbb{R}$? Thoughts. I know that the set $\{(x, y) \in \mathbb{R}^2 : x + y \in A\}$ is Borel when $A$ is Borel.",,['real-analysis']
52,Lebesgue integral - no dominating integrable function of $(f_n)$,Lebesgue integral - no dominating integrable function of,(f_n),"Let $\lambda$ be the Lebesgue-measure on $\Omega =[0,1]$. Given a sequence of non-negative measurable functions $$f_n:\Omega\to\Bbb R: x \mapsto ne^{-nx},$$ how can I show that $f_n$ converges $\lambda$-almost  everywhere to a measurable function $f$, but $$\int f d\lambda \neq \lim_{n\to\infty} \int f_nd\lambda $$ The theorem of dominated convergence seems to fail here.. Any hints for the proof? Edit: Ok what I have done so far: $(f_n)$ converges almost everywhere to $f(x)=0$. Obviously $f_n(0)=n$ for all $n \in \Bbb N_{\gt 0}$. Hence, $$\int f d\lambda =0 \neq 1 = \lim_{n\to\infty} \int f_nd\lambda$$ Now, how can I show that there is no integrable function that dominates $(f_n)$ without utilizing the theorem of dominated convergence?","Let $\lambda$ be the Lebesgue-measure on $\Omega =[0,1]$. Given a sequence of non-negative measurable functions $$f_n:\Omega\to\Bbb R: x \mapsto ne^{-nx},$$ how can I show that $f_n$ converges $\lambda$-almost  everywhere to a measurable function $f$, but $$\int f d\lambda \neq \lim_{n\to\infty} \int f_nd\lambda $$ The theorem of dominated convergence seems to fail here.. Any hints for the proof? Edit: Ok what I have done so far: $(f_n)$ converges almost everywhere to $f(x)=0$. Obviously $f_n(0)=n$ for all $n \in \Bbb N_{\gt 0}$. Hence, $$\int f d\lambda =0 \neq 1 = \lim_{n\to\infty} \int f_nd\lambda$$ Now, how can I show that there is no integrable function that dominates $(f_n)$ without utilizing the theorem of dominated convergence?",,"['real-analysis', 'integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
53,Does integration wrt to a differential form always come from a measure?,Does integration wrt to a differential form always come from a measure?,,"More precisely, is there an $n$-manifold $M$ with an $n$-form $\omega$ such that there is no measure $\nu$ on $M$ satisfying $$\int f \omega = \int f d\mu $$ for all compactly supported smooth functions $f$? EDIT: More generally, assuming the answer to the above is yes, what if we have a $k$-form  $\omega$ ($k\leqslant n$)? Then for every oriented $k$-submanifold $S$ we have the functional $$f\mapsto \int _S f \omega,$$ so for every such $S$ there is a measure such that this is integration wrt it. But is there a single measure for all such $S$? I guess you'd have to say something about the orientation here...","More precisely, is there an $n$-manifold $M$ with an $n$-form $\omega$ such that there is no measure $\nu$ on $M$ satisfying $$\int f \omega = \int f d\mu $$ for all compactly supported smooth functions $f$? EDIT: More generally, assuming the answer to the above is yes, what if we have a $k$-form  $\omega$ ($k\leqslant n$)? Then for every oriented $k$-submanifold $S$ we have the functional $$f\mapsto \int _S f \omega,$$ so for every such $S$ there is a measure such that this is integration wrt it. But is there a single measure for all such $S$? I guess you'd have to say something about the orientation here...",,"['integration', 'measure-theory', 'differential-forms']"
54,Checking measurability on open sets,Checking measurability on open sets,,"This is exercise 5 of section 53 in Halmos' Measure theory. Let $X$ be a locally compact Hausdorff space and $\mu^{*}$ an outer measure on the hereditary class of $\sigma$-bounded sets. Suppose $\mu^{*}(C)=\inf_{C \subset U, U \: \text{open}} \mu^{*}(U)<+\infty$ for every compact $C$. Let $E$ be a $\sigma$-bounded set such that  \begin{equation*} \mu^{*}(U)=\mu^{*}(U\cap E) + \mu^{*}(U\cap E^{c}) \end{equation*} for every open $U$. Is it true that $E$ is $\mu^{*}$-measurable ? My guess is no, but I can't find a counter example.","This is exercise 5 of section 53 in Halmos' Measure theory. Let $X$ be a locally compact Hausdorff space and $\mu^{*}$ an outer measure on the hereditary class of $\sigma$-bounded sets. Suppose $\mu^{*}(C)=\inf_{C \subset U, U \: \text{open}} \mu^{*}(U)<+\infty$ for every compact $C$. Let $E$ be a $\sigma$-bounded set such that  \begin{equation*} \mu^{*}(U)=\mu^{*}(U\cap E) + \mu^{*}(U\cap E^{c}) \end{equation*} for every open $U$. Is it true that $E$ is $\mu^{*}$-measurable ? My guess is no, but I can't find a counter example.",,"['measure-theory', 'outer-measure']"
55,Quotient of measurable functions is measurable,Quotient of measurable functions is measurable,,"I need to show that if $f,g : X \to \mathbb{R}$ are measurables with respect to  the $\sigma$ -algebra $S$ of $X$ , and $g(x) \neq 0,  \forall x \in X$ , then $f/g: X \to \mathbb{R}$ is measurable. So far what i got is: I need to show that { $x \in X: (f/g)(x) \leq c$ } $\in S$ . First Proof: { $x \in X: (f/g)(x) < c$ } $\in S$ Without loss of generality I can write this set as $$\{x \in X: f(x) < c \cdot g(x)\} \implies \exists q \in \mathbb{Q}: \{x \in X: f(x) < q < c \cdot g(x)\} \implies \bigcup_q [ \{x \in X: f(x) < q\} \cap \{x \in X: q < c \cdot g(x)\} ]  $$ Here's where i'm stuck. I know that $\{x \in X: f(x) < q \} \in S$ but, how do i prove that $\{x \in X: q < c \cdot g(x)\} \in S$ ? I'm thinking the rest of the proof isn't that complicated, but if someone has more ideas, better!","I need to show that if are measurables with respect to  the -algebra of , and , then is measurable. So far what i got is: I need to show that { } . First Proof: { } Without loss of generality I can write this set as Here's where i'm stuck. I know that but, how do i prove that ? I'm thinking the rest of the proof isn't that complicated, but if someone has more ideas, better!","f,g : X \to \mathbb{R} \sigma S X g(x) \neq 0,  \forall x \in X f/g: X \to \mathbb{R} x \in X: (f/g)(x) \leq c \in S x \in X: (f/g)(x) < c \in S \{x \in X: f(x) < c \cdot g(x)\}
\implies
\exists q \in \mathbb{Q}: \{x \in X: f(x) < q < c \cdot g(x)\}
\implies \bigcup_q [ \{x \in X: f(x) < q\} \cap \{x \in X: q < c \cdot g(x)\} ] 
 \{x \in X: f(x) < q \} \in S \{x \in X: q < c \cdot g(x)\} \in S","['real-analysis', 'measure-theory']"
56,Generalized measures,Generalized measures,,"This question is kind of broad. I welcome any answer, but I'll be more than happy to look it up myself in some book, if you could mention some title. Here's the setting: there's a Lie group $G$ acting via endomorphisms on an algebra $A$ with the action $\rho$, and there's its Lie algebra $\mathfrak g$ acting via derivations with the action $\gamma$. We require the two actions to be compatible by the equation \begin{equation} \frac{d}{dt}|_{t=0}(\rho(\exp(t\xi))(a))=(\gamma(\xi)(a))\ \forall a\in A,\xi\in\mathfrak g \end{equation} The problem is: how to define this derivative in general? The book I'm studying on (""Supersymmetry and equivariant de Rham Theory"", by Guillemin and Sternberg) claims this is possible if $A$ is equipped with ""some kind of topology"" or if any $a\in A$ is $G-$finite (i.e. the orbits of the $G-$action are all finite). I don't see how one should do this: I can accept, in principle, that giving a topology one can define limits, but I don't see clearly how the argumentation goes. As for $G-$finiteness, I understand that the fact that $\rho(g)(a)$ can only be a finite number of elements forces the limit we want to define to converge somewhere - but again: does it? And this is only an idea, I can't formalize anything. The second point is analogous. Pick the Lie group to be compact, consider an Haar measure $\mu$. We want to make sense of the assignment \begin{equation} A\ni a\mapsto \int_G\rho(g)(a)d\mu(g)\in A \end{equation} hence we need to be able to define the integral. The claim of the author is again that this is possible in the cases mentioned above - but they still don't mention how, and I keep not seeing it. Any idea?","This question is kind of broad. I welcome any answer, but I'll be more than happy to look it up myself in some book, if you could mention some title. Here's the setting: there's a Lie group $G$ acting via endomorphisms on an algebra $A$ with the action $\rho$, and there's its Lie algebra $\mathfrak g$ acting via derivations with the action $\gamma$. We require the two actions to be compatible by the equation \begin{equation} \frac{d}{dt}|_{t=0}(\rho(\exp(t\xi))(a))=(\gamma(\xi)(a))\ \forall a\in A,\xi\in\mathfrak g \end{equation} The problem is: how to define this derivative in general? The book I'm studying on (""Supersymmetry and equivariant de Rham Theory"", by Guillemin and Sternberg) claims this is possible if $A$ is equipped with ""some kind of topology"" or if any $a\in A$ is $G-$finite (i.e. the orbits of the $G-$action are all finite). I don't see how one should do this: I can accept, in principle, that giving a topology one can define limits, but I don't see clearly how the argumentation goes. As for $G-$finiteness, I understand that the fact that $\rho(g)(a)$ can only be a finite number of elements forces the limit we want to define to converge somewhere - but again: does it? And this is only an idea, I can't formalize anything. The second point is analogous. Pick the Lie group to be compact, consider an Haar measure $\mu$. We want to make sense of the assignment \begin{equation} A\ni a\mapsto \int_G\rho(g)(a)d\mu(g)\in A \end{equation} hence we need to be able to define the integral. The claim of the author is again that this is possible in the cases mentioned above - but they still don't mention how, and I keep not seeing it. Any idea?",,"['measure-theory', 'reference-request']"
57,Lebesgue measure of Cantor type set,Lebesgue measure of Cantor type set,,"I'm learning about Measure Theory and need some help with this problem: Let $0 < \alpha < 1$. We construct a set $C_\alpha$ (Cantor type) as follows: In the first step we remove from the interval $[0, 1]$ a ""middle"" open interval of length $(1 - \alpha)3^{-1}$. In the nth step we remove $2^{n-1}$ open intervals of length $(1 - \alpha)3^{-n}$. Find the Lebesgue measure of $C_\alpha$. My work and thoughts: If we remove the set $C_\alpha$ from the close interval $[0, 1]$ we are left with the union of pairwise disjoint intervals. In more traditionally formulaic notation, we can write: $$[0, 1] \setminus C_\alpha = E_1 \cup E_2 \cup E_3 \cup \ldots$$ Therefore, taking the Lebesgue measure on both side of the preivous equality we get: $$\mu \left([0, 1] \setminus C_\alpha \right) = \mu \left( \bigcup_{n=1}^{+\infty} E_n \right) = \sum_{n = 1}^{+\infty} \mu(E_n).$$ I need to find a way to express $\mu(E_n)$ and calculate the above series. If I can do so then the result is immediate since: $$\mu(C_\alpha) = \mu([0, 1]) - \mu([0, 1]\setminus C_\alpha)$$ where $\mu([0, 1]) = 1$.","I'm learning about Measure Theory and need some help with this problem: Let $0 < \alpha < 1$. We construct a set $C_\alpha$ (Cantor type) as follows: In the first step we remove from the interval $[0, 1]$ a ""middle"" open interval of length $(1 - \alpha)3^{-1}$. In the nth step we remove $2^{n-1}$ open intervals of length $(1 - \alpha)3^{-n}$. Find the Lebesgue measure of $C_\alpha$. My work and thoughts: If we remove the set $C_\alpha$ from the close interval $[0, 1]$ we are left with the union of pairwise disjoint intervals. In more traditionally formulaic notation, we can write: $$[0, 1] \setminus C_\alpha = E_1 \cup E_2 \cup E_3 \cup \ldots$$ Therefore, taking the Lebesgue measure on both side of the preivous equality we get: $$\mu \left([0, 1] \setminus C_\alpha \right) = \mu \left( \bigcup_{n=1}^{+\infty} E_n \right) = \sum_{n = 1}^{+\infty} \mu(E_n).$$ I need to find a way to express $\mu(E_n)$ and calculate the above series. If I can do so then the result is immediate since: $$\mu(C_\alpha) = \mu([0, 1]) - \mu([0, 1]\setminus C_\alpha)$$ where $\mu([0, 1]) = 1$.",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'cantor-set']"
58,Integration over finite partition of integration domain,Integration over finite partition of integration domain,,"I think the title does not reflect my problem very well. Feel free to leave a comment with a more appropriate title. Let $f \in L^1([0,1])$. How do I prove there exists a partition of $[0,1]$ into intervals $I_1 \dot\cup \dots \dot\cup I_N$ such that  $$\int_{I_i} |f| \mathrm{d}\lambda = \frac{1}{N} \int_{[0,1]} |f| \mathrm{d}\lambda$$ for all $i \in \{1,\dots,N\}$? Some thoughts : I want to show there exists $b \in [0,1]$ such that for the first interval $[0,b] \subseteq [0,1]$ $$\int_{[0,b]} |f| \mathrm{d}\lambda = \frac{1}{N} \int_{[0,1]} |f| \mathrm{d}\lambda \tag{$\ast$}.$$ Let $h_n := \frac{1}{2^n}$, $b_0 = 1$ and for $n > 0$ set $b_n = b_{n-1} - h_n$ if $$\int_{[0,b_{n-1}]} |f| \mathrm{d}\lambda > \frac{1}{N} \int_{[0,1]} |f| \mathrm{d}\lambda$$ and $b_n = b_{n-1} + h_n$ otherwise. Since $|b_i - b_j| \leq \sum_{k=i}^j \frac{1}{2^k}$ supposing $j \geq i$, the sequence $(b_n)$ is Cauchy and converges to some $b$. I still need to show ($\ast$): Consider the subsequences $(b_{n_k})$ and $(b_{n_k'})$ with $$  \int_{[0,b_{n_k}]} |f| \mathrm{d}\lambda  >  \frac{1}{N} \int_{[0,1]}|f|\mathrm{d}\lambda  \quad\text{and}\quad  \int_{[0,b_{n_k'}]} |f| \mathrm{d}\lambda \leq \frac{1}{N} \int_{[0,1]}|f|\mathrm{d}\lambda \tag{$\ast\ast$} $$ for all $k \in \mathbb{N}$. From the above, I know that the sequence of characteristic functions $\chi_{[0,b_n]}$ converges to $\chi_{[0,b]}$ since for each $\varepsilon > 0$ I find $m \in \mathbb{N}$ such that for all $n \geq m$ $$ \int_{[0,1]} |\chi_{[0,b]} - \chi_{[0,b_n]}| \mathrm{d}\lambda  = |b_n - b| < \varepsilon. $$ The same holds for the subsequences of characteristic functions generated by the subsequences $(b_{n_k})$ and $(b_{n_k'})$. Dominated convergence applied to ($\ast\ast$) should give the claim. Have I made any mistakes?","I think the title does not reflect my problem very well. Feel free to leave a comment with a more appropriate title. Let $f \in L^1([0,1])$. How do I prove there exists a partition of $[0,1]$ into intervals $I_1 \dot\cup \dots \dot\cup I_N$ such that  $$\int_{I_i} |f| \mathrm{d}\lambda = \frac{1}{N} \int_{[0,1]} |f| \mathrm{d}\lambda$$ for all $i \in \{1,\dots,N\}$? Some thoughts : I want to show there exists $b \in [0,1]$ such that for the first interval $[0,b] \subseteq [0,1]$ $$\int_{[0,b]} |f| \mathrm{d}\lambda = \frac{1}{N} \int_{[0,1]} |f| \mathrm{d}\lambda \tag{$\ast$}.$$ Let $h_n := \frac{1}{2^n}$, $b_0 = 1$ and for $n > 0$ set $b_n = b_{n-1} - h_n$ if $$\int_{[0,b_{n-1}]} |f| \mathrm{d}\lambda > \frac{1}{N} \int_{[0,1]} |f| \mathrm{d}\lambda$$ and $b_n = b_{n-1} + h_n$ otherwise. Since $|b_i - b_j| \leq \sum_{k=i}^j \frac{1}{2^k}$ supposing $j \geq i$, the sequence $(b_n)$ is Cauchy and converges to some $b$. I still need to show ($\ast$): Consider the subsequences $(b_{n_k})$ and $(b_{n_k'})$ with $$  \int_{[0,b_{n_k}]} |f| \mathrm{d}\lambda  >  \frac{1}{N} \int_{[0,1]}|f|\mathrm{d}\lambda  \quad\text{and}\quad  \int_{[0,b_{n_k'}]} |f| \mathrm{d}\lambda \leq \frac{1}{N} \int_{[0,1]}|f|\mathrm{d}\lambda \tag{$\ast\ast$} $$ for all $k \in \mathbb{N}$. From the above, I know that the sequence of characteristic functions $\chi_{[0,b_n]}$ converges to $\chi_{[0,b]}$ since for each $\varepsilon > 0$ I find $m \in \mathbb{N}$ such that for all $n \geq m$ $$ \int_{[0,1]} |\chi_{[0,b]} - \chi_{[0,b_n]}| \mathrm{d}\lambda  = |b_n - b| < \varepsilon. $$ The same holds for the subsequences of characteristic functions generated by the subsequences $(b_{n_k})$ and $(b_{n_k'})$. Dominated convergence applied to ($\ast\ast$) should give the claim. Have I made any mistakes?",,"['measure-theory', 'proof-verification', 'lebesgue-integral']"
59,Inclusion of $L^p$ and weak $L^p$ spaces,Inclusion of  and weak  spaces,L^p L^p,"Let $0<p_0<p_1<\infty$, $0<\theta<1$, and $1/p_\theta=(1-\theta)/p_0+\theta/p_1$. Show that $$L^{p_\theta,\infty}(X)\subset L^{p_0}(X)+L^{p_1}(X).$$ Suppose that  $f\in L^{p_\theta,\infty}(X)$, we need to show that $f$ can be written as $f=f_0+f_1$ with $f_0\in L^{p_0}(X)$ and $f_1\in L^{p_1}(X)$. Without loss of generality, we can assume that $\|f\|_{L^{p_\theta,\infty}}=1$, then we have $$\sup_{t>0}t\lambda_f(t)^{1/p_\theta}\leq 1,$$ where $\lambda_f(t):=\mu(\{x\in X:|f(x)|\geq t\}$ is the distribution function of $f$. I'm stuck here, I don't know how to determine $f_0$ and $f_1$?","Let $0<p_0<p_1<\infty$, $0<\theta<1$, and $1/p_\theta=(1-\theta)/p_0+\theta/p_1$. Show that $$L^{p_\theta,\infty}(X)\subset L^{p_0}(X)+L^{p_1}(X).$$ Suppose that  $f\in L^{p_\theta,\infty}(X)$, we need to show that $f$ can be written as $f=f_0+f_1$ with $f_0\in L^{p_0}(X)$ and $f_1\in L^{p_1}(X)$. Without loss of generality, we can assume that $\|f\|_{L^{p_\theta,\infty}}=1$, then we have $$\sup_{t>0}t\lambda_f(t)^{1/p_\theta}\leq 1,$$ where $\lambda_f(t):=\mu(\{x\in X:|f(x)|\geq t\}$ is the distribution function of $f$. I'm stuck here, I don't know how to determine $f_0$ and $f_1$?",,"['real-analysis', 'measure-theory', 'weak-lp-spaces']"
60,Regularity of $\nu $ for $g \in L^1 (\mu) $ and $d\nu = g d\mu $,Regularity of  for  and,\nu  g \in L^1 (\mu)  d\nu = g d\mu ,"Suppose $\mu $ is a positive regular measure on Baire $ \sigma$-algebra of  a locally compact Hausdorff space $ S $ , $ 0\leq g \in L^1 (\mu) $, and $$\lambda (E)= \int_E  g d\mu $$ then $\lambda$ is also a positive measure.  Can we say that $\lambda $ is a regular measure?","Suppose $\mu $ is a positive regular measure on Baire $ \sigma$-algebra of  a locally compact Hausdorff space $ S $ , $ 0\leq g \in L^1 (\mu) $, and $$\lambda (E)= \int_E  g d\mu $$ then $\lambda$ is also a positive measure.  Can we say that $\lambda $ is a regular measure?",,"['real-analysis', 'measure-theory']"
61,"locally compact metric space, regular borel measure","locally compact metric space, regular borel measure",,"Lets say you have a locally comapct metric space. And you have a complex Borel measure on that space. And the space is given by $\Omega=\bigcup\limits_{n=1}^\infty A_n$, where each $A_n$ is compact. Then I am supposed to show that this is a regular measure. That is if $\nu$ is the measure and $|\nu|$ is the total variation. Then for any Borel set E, and any $\epsilon> 0$, there is a compact set K and an open set O, such that $K \subset E\subset O$, and $|\nu|(O\backslash K)<\epsilon.$ I dont really know how to show this. We know that $|\nu|$ must be a finite measure.  First I thought that by using the continuity of measures we can choose a set $\cup_{n=1}^NA_n=A$ , such that $|\nu|(E\backslash A)<\epsilon/4$. But one problem is that even if A is compact $A\cap E$ may not be. I guess I must use the local compactness in some way. Any hints?","Lets say you have a locally comapct metric space. And you have a complex Borel measure on that space. And the space is given by $\Omega=\bigcup\limits_{n=1}^\infty A_n$, where each $A_n$ is compact. Then I am supposed to show that this is a regular measure. That is if $\nu$ is the measure and $|\nu|$ is the total variation. Then for any Borel set E, and any $\epsilon> 0$, there is a compact set K and an open set O, such that $K \subset E\subset O$, and $|\nu|(O\backslash K)<\epsilon.$ I dont really know how to show this. We know that $|\nu|$ must be a finite measure.  First I thought that by using the continuity of measures we can choose a set $\cup_{n=1}^NA_n=A$ , such that $|\nu|(E\backslash A)<\epsilon/4$. But one problem is that even if A is compact $A\cap E$ may not be. I guess I must use the local compactness in some way. Any hints?",,"['real-analysis', 'measure-theory']"
62,Convergence of measurable functions and the completion of a measure,Convergence of measurable functions and the completion of a measure,,"I am currently studying from Folland's Real Analysis: Modern Techniques and Their Applications . I know the following: If $\mu$ is a complete measure, and $\{ f_{n} \}$ is a sequence of measurable functions such that $f_{n} \to f$ a.e., then $f$ is also measurable. If $(X, \mathcal{M} , \mu)$ is a measure space and $(X ,\bar{\mathcal{M}}, \bar{\mu})$ is its completion, and if $f$ is a $\bar{\mathcal{M}}$-measurable function on $X$, then there is an $\mathcal{M}$-measurable function $g$ such that $f=g$ $\bar{\mu}$- almost everywhere. Now, at the beginning of Folland's proof of the dominated convergence theorem, he argues (very briefly) that if $f_{n} \to f$ a.e., and $\{ f_{n} \}$ is a sequence in $L^{1}$, then ""$f$ is measurable (perhaps after redefinition on a null set)"", which he says follows from (1) and (2) above. What does he mean by this? And wouldn't we then be able to apply this logic to any old measurable sequence $\{ h_{n} \}$ such that $h_{n} \to h$ a.e., and claim that ""$h$ is measurable (perhaps after redefinition on a null set)"" regardless of whether the measure we use is complete? Any help is appreciated.","I am currently studying from Folland's Real Analysis: Modern Techniques and Their Applications . I know the following: If $\mu$ is a complete measure, and $\{ f_{n} \}$ is a sequence of measurable functions such that $f_{n} \to f$ a.e., then $f$ is also measurable. If $(X, \mathcal{M} , \mu)$ is a measure space and $(X ,\bar{\mathcal{M}}, \bar{\mu})$ is its completion, and if $f$ is a $\bar{\mathcal{M}}$-measurable function on $X$, then there is an $\mathcal{M}$-measurable function $g$ such that $f=g$ $\bar{\mu}$- almost everywhere. Now, at the beginning of Folland's proof of the dominated convergence theorem, he argues (very briefly) that if $f_{n} \to f$ a.e., and $\{ f_{n} \}$ is a sequence in $L^{1}$, then ""$f$ is measurable (perhaps after redefinition on a null set)"", which he says follows from (1) and (2) above. What does he mean by this? And wouldn't we then be able to apply this logic to any old measurable sequence $\{ h_{n} \}$ such that $h_{n} \to h$ a.e., and claim that ""$h$ is measurable (perhaps after redefinition on a null set)"" regardless of whether the measure we use is complete? Any help is appreciated.",,"['real-analysis', 'measure-theory']"
63,Folland exercise 1.32,Folland exercise 1.32,,"Here is a problems after the measure theory section. Suppose { $\alpha_j$ } $\subset (0,1)$ . a. $\prod $ (1- $\alpha_j$ ) > 0 iff $\sum \alpha_j < \infty $ . (Compare $\sum log(1- \alpha_j) to \sum \alpha_j$ .) b. Given $\beta \in (0,1)$ , exhibit a sequence ${\alpha_j}$ such that $\prod(1-\alpha_j) = \beta$ . The problem is interesting. The infinite product gives the measure of the generalized Cantor set. Any idea about how to prove it?","Here is a problems after the measure theory section. Suppose { } . a. (1- ) > 0 iff . (Compare .) b. Given , exhibit a sequence such that . The problem is interesting. The infinite product gives the measure of the generalized Cantor set. Any idea about how to prove it?","\alpha_j \subset (0,1) \prod  \alpha_j \sum \alpha_j < \infty  \sum log(1- \alpha_j) to \sum \alpha_j \beta \in (0,1) {\alpha_j} \prod(1-\alpha_j) = \beta","['measure-theory', 'cantor-set']"
64,For what $p$ is $\frac{1}{(x(1+\ln(x)^2))^p}$ Lebesgue integrable?,For what  is  Lebesgue integrable?,p \frac{1}{(x(1+\ln(x)^2))^p},"I'm trying to use the fact that given $f:[a,\infty)\to\mathbb{R}$ Riemann integrable for every closed interval $[c,d]\subset [a,\infty)$, then $f$ is Lebesgue integrable if, and only if, $\int_a^\infty|f(x)| \, dx$ exists. In particular, $f(x)=\frac{1}{x(1+\ln(x)^2)}$ is $p$-Lebesgue integrable if $\int_0^\infty\frac{1}{x^p(1+\ln(x)^2)^p} \, dx<\infty $. Here using the fact that $f>0$. But I can't solve this Riemann integral.","I'm trying to use the fact that given $f:[a,\infty)\to\mathbb{R}$ Riemann integrable for every closed interval $[c,d]\subset [a,\infty)$, then $f$ is Lebesgue integrable if, and only if, $\int_a^\infty|f(x)| \, dx$ exists. In particular, $f(x)=\frac{1}{x(1+\ln(x)^2)}$ is $p$-Lebesgue integrable if $\int_0^\infty\frac{1}{x^p(1+\ln(x)^2)^p} \, dx<\infty $. Here using the fact that $f>0$. But I can't solve this Riemann integral.",,"['integration', 'measure-theory', 'improper-integrals', 'lebesgue-integral', 'lp-spaces']"
65,"$\pi-\lambda$ Theorem to show measure giving interval lengths equivalent to Lebesgue on [0,1]","Theorem to show measure giving interval lengths equivalent to Lebesgue on [0,1]",\pi-\lambda,"so I have been working on this problem and I want to make sure I am understanding the conclusion fully. So I have the following scenario: Not part of the actual question, but relevant. Consider the measure space $([0,1],\mathcal{M},m),$ where   $\mathcal{M}$ is the set of Lebesgue measurable sets contained in   $[0,1],$ and $m$ is the Lebesgue measure. Let $f$ be some function s.t. $$\int_a^b f dm =b-a,$$ and define $$\int_A 1d\mu=\mu(A):=\int_A f dm.$$ Thus we have for any $[a,b]\subseteq[0,1]$ $$\mu([a,b])=b-a.$$ I want to show $f=1$ [m] a.e., and I think good way to go about this would be to show $m=\mu.$ Now if we consider the set $L,$ which is where the Lebesgue measure and $\mu$ agree we have that $I,$ the set of intervals is contained in the former, i.e. $I\subseteq L.$ Now I is clearly a $\pi$ system and $L$ is a $\lambda$ system, which means by Dynkin's Theorem $\sigma(I)=\mathcal{B}\subseteq L,$ where $\mathcal{B}$ is the Borel sets on $[0,1].$ Now this would give me that $\mu=m,$ but only on the Borel sets, and hence I can't say that $m=\mu$ on $\mathcal{M}.$ Is this correct or am I missing something? I also see that $f$ is the Radon-Nikodym derivative, which means it is unique and we know $f=1$ works (on intervals). I don't think this gives me the result fully though. Thanks for any help.","so I have been working on this problem and I want to make sure I am understanding the conclusion fully. So I have the following scenario: Not part of the actual question, but relevant. Consider the measure space $([0,1],\mathcal{M},m),$ where   $\mathcal{M}$ is the set of Lebesgue measurable sets contained in   $[0,1],$ and $m$ is the Lebesgue measure. Let $f$ be some function s.t. $$\int_a^b f dm =b-a,$$ and define $$\int_A 1d\mu=\mu(A):=\int_A f dm.$$ Thus we have for any $[a,b]\subseteq[0,1]$ $$\mu([a,b])=b-a.$$ I want to show $f=1$ [m] a.e., and I think good way to go about this would be to show $m=\mu.$ Now if we consider the set $L,$ which is where the Lebesgue measure and $\mu$ agree we have that $I,$ the set of intervals is contained in the former, i.e. $I\subseteq L.$ Now I is clearly a $\pi$ system and $L$ is a $\lambda$ system, which means by Dynkin's Theorem $\sigma(I)=\mathcal{B}\subseteq L,$ where $\mathcal{B}$ is the Borel sets on $[0,1].$ Now this would give me that $\mu=m,$ but only on the Borel sets, and hence I can't say that $m=\mu$ on $\mathcal{M}.$ Is this correct or am I missing something? I also see that $f$ is the Radon-Nikodym derivative, which means it is unique and we know $f=1$ works (on intervals). I don't think this gives me the result fully though. Thanks for any help.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
66,The Cantor set and ternary expansions,The Cantor set and ternary expansions,,"I'm trying to prove that the Cantor set $\mathcal{C}$ contains all numbers $x \in [0,1]$ with ternary expansion $x = \sum_{k=1}^\infty \frac{a_k}{3^k}$, such that $a_k=0$ or $a_k=2$. I'm going by induction, proving that $x$ belongs to every $\mathcal{C}_k$, where $\mathcal{C} = \bigcap_{k=1}^\infty \mathcal{C}_k$, and $\mathcal{C}_k$ is the usual $k$-th set in the construction of the Cantor set (i.e., a disjoint union of $2^k$ closed intervals, each of length $\frac{1}{3^k}$, etc.). Here's my work so far: The base case, $k=1$, was easy: If $a_1=0$, then the geometric sum yields $x \leq \frac{1}{3}$; similarly, if $a_1=2$, then $x \geq \frac{2}{3}$. For the inductive step, I assume $x \in \mathcal{C}_k$, and try to prove $x \in \mathcal{C}_{k+1}$. First, I assume there is an interval $[a,b]$ of length $\frac{1}{3^k}$ containing $x$, where $[a,b]$ is one of the $2^k$ intervals that make up $\mathcal{C}_k$. I can write $[a,b]$ as $$ [a,b] = \left[a, a + \frac{1}{3^{k+1}} \right] \cup \left( a + \frac{1}{3^{k+1}},  b - \frac{1}{3^{k+1}} \right) \cup \left[ b- \frac{1}{3^{k+1}}, b \right], $$ and of course I'd like to show, for instance, that $x$ is in the leftmost of these intervals if $a_{k+1} = 0$. The geometric sum gives me the bound $x \leq \sum_{j=1}^k \frac{a_j}{3^j} + \frac{1}{3^{k+1}}$, but I want $x \leq a + \frac{1}{3^{k+1}}$. I've tried and failed to get past here. I feel like I'm missing something silly, but can anybody help me reach finish off the argument? Thanks!","I'm trying to prove that the Cantor set $\mathcal{C}$ contains all numbers $x \in [0,1]$ with ternary expansion $x = \sum_{k=1}^\infty \frac{a_k}{3^k}$, such that $a_k=0$ or $a_k=2$. I'm going by induction, proving that $x$ belongs to every $\mathcal{C}_k$, where $\mathcal{C} = \bigcap_{k=1}^\infty \mathcal{C}_k$, and $\mathcal{C}_k$ is the usual $k$-th set in the construction of the Cantor set (i.e., a disjoint union of $2^k$ closed intervals, each of length $\frac{1}{3^k}$, etc.). Here's my work so far: The base case, $k=1$, was easy: If $a_1=0$, then the geometric sum yields $x \leq \frac{1}{3}$; similarly, if $a_1=2$, then $x \geq \frac{2}{3}$. For the inductive step, I assume $x \in \mathcal{C}_k$, and try to prove $x \in \mathcal{C}_{k+1}$. First, I assume there is an interval $[a,b]$ of length $\frac{1}{3^k}$ containing $x$, where $[a,b]$ is one of the $2^k$ intervals that make up $\mathcal{C}_k$. I can write $[a,b]$ as $$ [a,b] = \left[a, a + \frac{1}{3^{k+1}} \right] \cup \left( a + \frac{1}{3^{k+1}},  b - \frac{1}{3^{k+1}} \right) \cup \left[ b- \frac{1}{3^{k+1}}, b \right], $$ and of course I'd like to show, for instance, that $x$ is in the leftmost of these intervals if $a_{k+1} = 0$. The geometric sum gives me the bound $x \leq \sum_{j=1}^k \frac{a_j}{3^j} + \frac{1}{3^{k+1}}$, but I want $x \leq a + \frac{1}{3^{k+1}}$. I've tried and failed to get past here. I feel like I'm missing something silly, but can anybody help me reach finish off the argument? Thanks!",,"['measure-theory', 'elementary-set-theory', 'cantor-set']"
67,"Prove that $M(t)^2 - t$ is a martingale, $M(t)$ is a symmetric random walk","Prove that  is a martingale,  is a symmetric random walk",M(t)^2 - t M(t),"Prove that $M(t)^2 - t$ is a martingale, $M(t)$ is a symmetric random walk. My question here mainly has to do with the $F_{t}$ measurability of $M(t)^2 - t$, where $F_{t} = \sigma (X_1 , X_2, ... , X_t)$. If a function $M(t)$ is a measurable wrt $F_{t} = \sigma (X_1 , X_2, ... , X_t)$, is it always true that its square is also $F_{t}$- measurable?","Prove that $M(t)^2 - t$ is a martingale, $M(t)$ is a symmetric random walk. My question here mainly has to do with the $F_{t}$ measurability of $M(t)^2 - t$, where $F_{t} = \sigma (X_1 , X_2, ... , X_t)$. If a function $M(t)$ is a measurable wrt $F_{t} = \sigma (X_1 , X_2, ... , X_t)$, is it always true that its square is also $F_{t}$- measurable?",,"['measure-theory', 'stochastic-processes', 'stochastic-calculus', 'stochastic-analysis']"
68,Convergence of the integral of a product of functions.,Convergence of the integral of a product of functions.,,"Let $\phi:\mathbb{R^n}\to\mathbb{R}$ be a Lebesgue-measurable function, with the property that for every $n$-dimensional cube $Q$ in $\mathbb{R^n}$, we have $$ \left|\int_{Q}\phi(x)dx \right|\leq\frac{M m(Q)}{1+m(Q)} $$ for a constant $M$, where $m$ denotes the Lebesgue measure. Prove that if $f \in L^{1}(\mathbb{R}^n)$,  $$ \lim_{k\to \infty}\int_{\mathbb{R^n}}\phi(kx)f(x)dx = 0  $$ From the first inequality, if you assume that $\int_{\mathbb{R^n}}=\lim_{m(Q)\to \infty}\int_{Q}$ (is this even true?), you can do: $$ \left|\int_{\mathbb{R}^n}\phi(x)dx\right|=\lim_{m(Q)\to \infty}\left|\int_{Q}\phi(x)dx\right|\leq \lim_{m(Q)\to \infty}\frac{M m(Q)}{1+m(Q)}=M $$ Maybe one can use this and apply Hölder's inequality on that product, with some sort of variable change, but I couldn't make it work. Does anyone have any suggestions?","Let $\phi:\mathbb{R^n}\to\mathbb{R}$ be a Lebesgue-measurable function, with the property that for every $n$-dimensional cube $Q$ in $\mathbb{R^n}$, we have $$ \left|\int_{Q}\phi(x)dx \right|\leq\frac{M m(Q)}{1+m(Q)} $$ for a constant $M$, where $m$ denotes the Lebesgue measure. Prove that if $f \in L^{1}(\mathbb{R}^n)$,  $$ \lim_{k\to \infty}\int_{\mathbb{R^n}}\phi(kx)f(x)dx = 0  $$ From the first inequality, if you assume that $\int_{\mathbb{R^n}}=\lim_{m(Q)\to \infty}\int_{Q}$ (is this even true?), you can do: $$ \left|\int_{\mathbb{R}^n}\phi(x)dx\right|=\lim_{m(Q)\to \infty}\left|\int_{Q}\phi(x)dx\right|\leq \lim_{m(Q)\to \infty}\frac{M m(Q)}{1+m(Q)}=M $$ Maybe one can use this and apply Hölder's inequality on that product, with some sort of variable change, but I couldn't make it work. Does anyone have any suggestions?",,"['real-analysis', 'measure-theory', 'harmonic-analysis']"
69,Showing a simple function is continuous on a restricted domain,Showing a simple function is continuous on a restricted domain,,"Motivation: I am studying for an exam over Chapters $1-3$ of Real Analysis by Royden and Fitzpatrick, 4th edition. I am stuck on understanding some of Proposition $11$, which I have reproduced below: Proposition 11: Let $f$ be a simple function defined on a set $E$ of finite measure. Then for each $\varepsilon>0$, there is a continuous function $g$ on $\mathbb{R}$ and a closed set $F$ contained in $E$ for which $f=g$ on $F$ and $m(E-F)<\varepsilon.$ Proof: Let $a_1,a_2,\ldots, a_n$ be the finite number of distinct values taken by $f$, and let them be taken on the sets $E_1, E_2, \ldots, E_n,$ respectively. The collection $\{E_k\}_{k=1}^{n}$ is disjoint since the $a_k$'s are distinct. According to Theorem $11$ of Chapter $2$, we may choose closed sets $F_1, F_2, \ldots, F_n$ such that for each index $k, 1\leq k \leq n,$ $F_k \subseteq E_k$ and $m(E_k-F_k)<\varepsilon/n.$ Define $g$ on $F$ to take the value $a_k$ on $F_k$ for $1 \leq k \leq n.$ Since the collection $\{F_k\}_{k=1}^{n}$ is disjoint, $g$ is properly defined. Moreover, $g$ is continuous on $F$ since for a point $x \in F_i,$   there is an open interval containing $x$ which is disjoint from the closed set $\cup_{k \neq i} F_k$ and  hence on the intersection of this interval with $F$ the function $g$   is constant. But $g$ can be extended from a continuous function on the closed set $F$ to a continuous function on all of $\mathbb{R}.$ The continuous function $g$ on $\mathbb{R}$ has the required approximation properties. Question: Please explain rigorously why the ""grey"" area is true?","Motivation: I am studying for an exam over Chapters $1-3$ of Real Analysis by Royden and Fitzpatrick, 4th edition. I am stuck on understanding some of Proposition $11$, which I have reproduced below: Proposition 11: Let $f$ be a simple function defined on a set $E$ of finite measure. Then for each $\varepsilon>0$, there is a continuous function $g$ on $\mathbb{R}$ and a closed set $F$ contained in $E$ for which $f=g$ on $F$ and $m(E-F)<\varepsilon.$ Proof: Let $a_1,a_2,\ldots, a_n$ be the finite number of distinct values taken by $f$, and let them be taken on the sets $E_1, E_2, \ldots, E_n,$ respectively. The collection $\{E_k\}_{k=1}^{n}$ is disjoint since the $a_k$'s are distinct. According to Theorem $11$ of Chapter $2$, we may choose closed sets $F_1, F_2, \ldots, F_n$ such that for each index $k, 1\leq k \leq n,$ $F_k \subseteq E_k$ and $m(E_k-F_k)<\varepsilon/n.$ Define $g$ on $F$ to take the value $a_k$ on $F_k$ for $1 \leq k \leq n.$ Since the collection $\{F_k\}_{k=1}^{n}$ is disjoint, $g$ is properly defined. Moreover, $g$ is continuous on $F$ since for a point $x \in F_i,$   there is an open interval containing $x$ which is disjoint from the closed set $\cup_{k \neq i} F_k$ and  hence on the intersection of this interval with $F$ the function $g$   is constant. But $g$ can be extended from a continuous function on the closed set $F$ to a continuous function on all of $\mathbb{R}.$ The continuous function $g$ on $\mathbb{R}$ has the required approximation properties. Question: Please explain rigorously why the ""grey"" area is true?",,"['real-analysis', 'measure-theory', 'proof-verification']"
70,"how prove that $\lim_{n\to{}\infty} {\sum_{(i, j)\in{K_n}}^\infty{a_{ij}}}=\sum_{i=1}^\infty\sum_{j=1}^\infty{a_ {ij}}$",how prove that,"\lim_{n\to{}\infty} {\sum_{(i, j)\in{K_n}}^\infty{a_{ij}}}=\sum_{i=1}^\infty\sum_{j=1}^\infty{a_ {ij}}","Let $a_{ij}\geq 0$ $(i,j)\in \mathbb{N}^2$ then $$\sum_{j=1}^\infty\sum_{i=1}^\infty{a_{ij}}=\sum_{i=1}^\infty\sum_{j=1}^\infty{a_{ij}}$$ Moreover, given $ K_1 \subseteq K_2 \subseteq \ldots \subseteq \mathbb{N}^2$  such that $\bigcup_{n\in{\mathbb{N}}}^{}{K_n}=\mathbb{N}^2$ then $\displaystyle \lim_{n\to{}\infty} {\sum_{(i, j)\in{K_n}}^\infty{a_{ij}}}=\sum_{i=1}^\infty\sum_{j=1}^\infty{a_ {ij}}$. I thought of applying the monotone convergence theorem, but not if this will help solve this problem.? Any ideas thanks","Let $a_{ij}\geq 0$ $(i,j)\in \mathbb{N}^2$ then $$\sum_{j=1}^\infty\sum_{i=1}^\infty{a_{ij}}=\sum_{i=1}^\infty\sum_{j=1}^\infty{a_{ij}}$$ Moreover, given $ K_1 \subseteq K_2 \subseteq \ldots \subseteq \mathbb{N}^2$  such that $\bigcup_{n\in{\mathbb{N}}}^{}{K_n}=\mathbb{N}^2$ then $\displaystyle \lim_{n\to{}\infty} {\sum_{(i, j)\in{K_n}}^\infty{a_{ij}}}=\sum_{i=1}^\infty\sum_{j=1}^\infty{a_ {ij}}$. I thought of applying the monotone convergence theorem, but not if this will help solve this problem.? Any ideas thanks",,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
71,"What is the size of $\{(x_1,\ldots,x_n)\in\mathbb{R}^n:x_1+\cdots+x_n<a\text{, and }x_i>0\}$? [duplicate]",What is the size of ? [duplicate],"\{(x_1,\ldots,x_n)\in\mathbb{R}^n:x_1+\cdots+x_n<a\text{, and }x_i>0\}","This question already has answers here : Volume of $T_n=\{x_i\ge0:x_1+\cdots+x_n\le1\}$ (4 answers) Closed 8 years ago . Is there an easy way to compute the size (Lebesgue measure) of the set $$S_n(a):=\{(x_1,\ldots,x_n)\in\mathbb{R}^n:x_1+\cdots+x_n<a\text{, and }x_i>0\}.$$ Using integration I computed that $$m(S_n(a))=\frac{a^n}{n!}.$$ But the computation is tedious, and I was wondering if there are more concise/direct ways of proving it. Computation: $$ \begin{align} m(S_n(a)) &= \int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-1}}dx_n\cdots dx_1 \\ &= \int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-2}}(a-x_1-\cdots-x_{n-1})dx_{n-1}\cdots dx_1 \\ &= \int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-3}}\frac{-1}{2}(a-x_1-\cdots-x_{n-1})^2\big|_0^{a-x_1-\cdots-x_{n-2}}dx_{n-2}\cdots dx_1\\ &=\int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-3}}\frac{1}{2}(a-x_1-\cdots-x_{n-2})^2dx_{n-2}\cdots dx_1\\ \end{align} $$ and so on...","This question already has answers here : Volume of $T_n=\{x_i\ge0:x_1+\cdots+x_n\le1\}$ (4 answers) Closed 8 years ago . Is there an easy way to compute the size (Lebesgue measure) of the set $$S_n(a):=\{(x_1,\ldots,x_n)\in\mathbb{R}^n:x_1+\cdots+x_n<a\text{, and }x_i>0\}.$$ Using integration I computed that $$m(S_n(a))=\frac{a^n}{n!}.$$ But the computation is tedious, and I was wondering if there are more concise/direct ways of proving it. Computation: $$ \begin{align} m(S_n(a)) &= \int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-1}}dx_n\cdots dx_1 \\ &= \int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-2}}(a-x_1-\cdots-x_{n-1})dx_{n-1}\cdots dx_1 \\ &= \int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-3}}\frac{-1}{2}(a-x_1-\cdots-x_{n-1})^2\big|_0^{a-x_1-\cdots-x_{n-2}}dx_{n-2}\cdots dx_1\\ &=\int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-3}}\frac{1}{2}(a-x_1-\cdots-x_{n-2})^2dx_{n-2}\cdots dx_1\\ \end{align} $$ and so on...",,"['calculus', 'real-analysis', 'measure-theory', 'volume', 'simplex']"
72,Prove that measure of $A$ is $1$,Prove that measure of  is,A 1,"Let $A\subset (0,1)$ be a Lebesgue measurable set and $\lambda>0$. Suppose that if $0\le a<b\le 1$ then $\mu(A\cap (a,b))\ge \lambda(b-a)$. Prove that $\mu(A)=1$. It is clear that $\lambda \le 1$ and to show $\mu(A)=1$ is equivalent to show that $\mu(A^c)=0$.","Let $A\subset (0,1)$ be a Lebesgue measurable set and $\lambda>0$. Suppose that if $0\le a<b\le 1$ then $\mu(A\cap (a,b))\ge \lambda(b-a)$. Prove that $\mu(A)=1$. It is clear that $\lambda \le 1$ and to show $\mu(A)=1$ is equivalent to show that $\mu(A^c)=0$.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
73,Correspondence between countably generated sigma algebras and partitions,Correspondence between countably generated sigma algebras and partitions,,"Let X be a standard Borel space and $\mathcal C, \mathcal D$ be countably generated sub sigma algebras of the Borel sigma algebra of X. Suppose that for each $x \in X$ we have $[x]_{\mathcal C} \subset [x]_{\mathcal D}$ where $[x]_{\mathcal C}$ means the intersection of all elements in $\mathcal C$ containing $x$. Does it follow that $\mathcal D \subset \mathcal C$? Even for finite $\mathcal D$, I don't know how to proceed. But once the finite $\mathcal D$ case is done, the infinite case follows easily. Special cases where this implication is known include: the case where $\mathcal D$ is the Borel sigma algebra of X the case where $\mathcal C, \mathcal D$ are both finite A related question where ignoring null sets is allowed is: Two possible senses of a random variable being a function of another random variable","Let X be a standard Borel space and $\mathcal C, \mathcal D$ be countably generated sub sigma algebras of the Borel sigma algebra of X. Suppose that for each $x \in X$ we have $[x]_{\mathcal C} \subset [x]_{\mathcal D}$ where $[x]_{\mathcal C}$ means the intersection of all elements in $\mathcal C$ containing $x$. Does it follow that $\mathcal D \subset \mathcal C$? Even for finite $\mathcal D$, I don't know how to proceed. But once the finite $\mathcal D$ case is done, the infinite case follows easily. Special cases where this implication is known include: the case where $\mathcal D$ is the Borel sigma algebra of X the case where $\mathcal C, \mathcal D$ are both finite A related question where ignoring null sets is allowed is: Two possible senses of a random variable being a function of another random variable",,"['measure-theory', 'descriptive-set-theory']"
74,Exercise on Rudin about $R^2$ measurable,Exercise on Rudin about  measurable,R^2,"I'm thinking about exercise 9 on Rudin's Real and Complex Analysis chapter 8: $E$ is dense in $\mathbb{R}^1$ and $f$ is a real function on $\mathbb{R}^2$ such that: (a) $f_x$ is Lebesgue measurable for each $x\in E$; (b) $f^y$ is continuous for almost all $y\in \mathbb{R}^1$. Prove that $f$ is $\mathbb{R}^2$ Lebesgue measurable. My idea is to construct a sequence $\{f_n\}_n$ to approach $f$ just like the exercise above, but fail. Who can give some hints for this problem? Any suggestion is appreciated. Thank all of you!","I'm thinking about exercise 9 on Rudin's Real and Complex Analysis chapter 8: $E$ is dense in $\mathbb{R}^1$ and $f$ is a real function on $\mathbb{R}^2$ such that: (a) $f_x$ is Lebesgue measurable for each $x\in E$; (b) $f^y$ is continuous for almost all $y\in \mathbb{R}^1$. Prove that $f$ is $\mathbb{R}^2$ Lebesgue measurable. My idea is to construct a sequence $\{f_n\}_n$ to approach $f$ just like the exercise above, but fail. Who can give some hints for this problem? Any suggestion is appreciated. Thank all of you!",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
75,Limit of integral over set measurable,Limit of integral over set measurable,,"If $A\subset[0,2\pi]$ is measurable, prove that $$\lim_{n\to\infty}\int_A \cos (nx)\ dx=\lim_{n\to\infty}\int_A \sin(nx) \ dx=0$$ Please, any suggestions are welcome.","If $A\subset[0,2\pi]$ is measurable, prove that $$\lim_{n\to\infty}\int_A \cos (nx)\ dx=\lim_{n\to\infty}\int_A \sin(nx) \ dx=0$$ Please, any suggestions are welcome.",,"['measure-theory', 'lebesgue-integral']"
76,Properties of Lebesgue Integration,Properties of Lebesgue Integration,,"I am completely stuck with the following problem on Lebesgue Integration: Let $f:\mathbb{R}^d \to [0, +\infty]$ be measurable. Show that if $\int_{\mathbb{R}^d} f(x)dx < \infty$, then $f$ is finite almost everywhere. Give a counterexample to show that the converse statement is false. Show that $\int_{\mathbb{R}^d} f(x)dx=0$ if and only if $f$ is zero almost everywhere. All I know is the definition of a measurable function: An unsigned function $f:\mathbb{R}^d \to [0, +\infty]$ is unsigned Lebesgue measurable , or measurable for short, if it is the point-wise limit of unsigned simple functions, i.e., if there exists a sequence $f_1,f_2,f_3, \ldots : \mathbb{R}^d \to [0, +\infty]$ of unsigned simple functions such that $f_n(x) \to f(x)$ for every $x \in \mathbb{R}^d$. How would I be able to use this to my advantage in order to solve the problem at hand? Thank you in advance for helping me with these questions.","I am completely stuck with the following problem on Lebesgue Integration: Let $f:\mathbb{R}^d \to [0, +\infty]$ be measurable. Show that if $\int_{\mathbb{R}^d} f(x)dx < \infty$, then $f$ is finite almost everywhere. Give a counterexample to show that the converse statement is false. Show that $\int_{\mathbb{R}^d} f(x)dx=0$ if and only if $f$ is zero almost everywhere. All I know is the definition of a measurable function: An unsigned function $f:\mathbb{R}^d \to [0, +\infty]$ is unsigned Lebesgue measurable , or measurable for short, if it is the point-wise limit of unsigned simple functions, i.e., if there exists a sequence $f_1,f_2,f_3, \ldots : \mathbb{R}^d \to [0, +\infty]$ of unsigned simple functions such that $f_n(x) \to f(x)$ for every $x \in \mathbb{R}^d$. How would I be able to use this to my advantage in order to solve the problem at hand? Thank you in advance for helping me with these questions.",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
77,Measure Theory Inequality,Measure Theory Inequality,,"I was having trouble showing the following inequality: Prove that if $A \subset I = [0,1]$ has measure $u(A) < 1$ and $\epsilon > 0$, then there is an interval $[a,b] \subset I$ such that $u(A \cap [a,b]) < \epsilon(b-a)$. (Where $u$ denotes Lebesgue Measure) I was thinking of showing that the set $I \setminus A$ contains an interval $[a,b]$ but you cannot necessarily show this because $I/A$ can be a set such as the irrationals. Otherwise I'm not sure where to begin. Thanks for the help!","I was having trouble showing the following inequality: Prove that if $A \subset I = [0,1]$ has measure $u(A) < 1$ and $\epsilon > 0$, then there is an interval $[a,b] \subset I$ such that $u(A \cap [a,b]) < \epsilon(b-a)$. (Where $u$ denotes Lebesgue Measure) I was thinking of showing that the set $I \setminus A$ contains an interval $[a,b]$ but you cannot necessarily show this because $I/A$ can be a set such as the irrationals. Otherwise I'm not sure where to begin. Thanks for the help!",,"['real-analysis', 'measure-theory']"
78,Almost all subgroups of a Lie group are free,Almost all subgroups of a Lie group are free,,"I am currently reading this paper by Epstein. I need help with understanding the proof. Specifically, I have the following two questions. Let $w\colon G\to H$ be an analytic mapping between connected Lie groups $G$ and $H$. How do we prove that the preimage of a point is either the whole of $G$ or has Haar measure zero in $G$? The paper says one should take $G$ to be an open subset of $\mathbb{R}^m$ and use induction on $m$ and Fubini's theorem, but this doesn't really convince me (I cannot fill the details). The whole paper seems to assume that $G$ is analytic manifold, whereas the usual assumption is that Lie group is smooth manifold. Does this mean that the result of the paper hold only for real-analytic Lie groups, or this assumption is not actually a restriction and in some way we also have the claim for the classical real Lie groups? Edit: Actually, regarding (1), I don't see why the usual $t\in\mathbb{R}\mapsto e^{-1/t^2}1_{t>0}\in\mathbb{R}$ is not a counterexample.","I am currently reading this paper by Epstein. I need help with understanding the proof. Specifically, I have the following two questions. Let $w\colon G\to H$ be an analytic mapping between connected Lie groups $G$ and $H$. How do we prove that the preimage of a point is either the whole of $G$ or has Haar measure zero in $G$? The paper says one should take $G$ to be an open subset of $\mathbb{R}^m$ and use induction on $m$ and Fubini's theorem, but this doesn't really convince me (I cannot fill the details). The whole paper seems to assume that $G$ is analytic manifold, whereas the usual assumption is that Lie group is smooth manifold. Does this mean that the result of the paper hold only for real-analytic Lie groups, or this assumption is not actually a restriction and in some way we also have the claim for the classical real Lie groups? Edit: Actually, regarding (1), I don't see why the usual $t\in\mathbb{R}\mapsto e^{-1/t^2}1_{t>0}\in\mathbb{R}$ is not a counterexample.",,"['measure-theory', 'manifolds', 'lie-groups']"
79,Measures $\mu$ such that $\mu(a+A)\leq c\ \mu(A)$,Measures  such that,\mu \mu(a+A)\leq c\ \mu(A),"Let $\mu$ be a positive measure on $\mathbb{R}$ such that $\mu[a,b]<+\infty$, for all $a,b\in\mathbb{R}$ and $\mu(\mathbb{R})=+\infty$. The set $a+A$ denotes the translation set of $A$ by a, i.e. $a+A=\{a+x, \text{with }x\in A \}$. Consider the following hypotheses on the measure $\mu$: (H0) For all $a\in \mathbb{R}$ and $A$ measurable set $$\mu(a+A)=\mu(A).$$ (H1) $\exists c>0$ such that for all $a\in \mathbb{R}$ and $A$ measurable set $$\mu(a+A)\leq c\ \mu(A).$$ Consider also the weaker hypothesis: (H2) For all $a\in \mathbb{R}$, $\exists c_a>0$ such that for all $A$ measurable set $$\mu(a+A)\leq c_a\ \mu(A).$$ We know that if $\mu$ satisfies (H0) , then $\mu$ is nothing but the Lebesgue measure multiplied by a constant. What can we say about (H1) and (H2) ?","Let $\mu$ be a positive measure on $\mathbb{R}$ such that $\mu[a,b]<+\infty$, for all $a,b\in\mathbb{R}$ and $\mu(\mathbb{R})=+\infty$. The set $a+A$ denotes the translation set of $A$ by a, i.e. $a+A=\{a+x, \text{with }x\in A \}$. Consider the following hypotheses on the measure $\mu$: (H0) For all $a\in \mathbb{R}$ and $A$ measurable set $$\mu(a+A)=\mu(A).$$ (H1) $\exists c>0$ such that for all $a\in \mathbb{R}$ and $A$ measurable set $$\mu(a+A)\leq c\ \mu(A).$$ Consider also the weaker hypothesis: (H2) For all $a\in \mathbb{R}$, $\exists c_a>0$ such that for all $A$ measurable set $$\mu(a+A)\leq c_a\ \mu(A).$$ We know that if $\mu$ satisfies (H0) , then $\mu$ is nothing but the Lebesgue measure multiplied by a constant. What can we say about (H1) and (H2) ?",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
80,Question of the Outer measure of a set,Question of the Outer measure of a set,,I was given the following problem and I need to check if I approached and solved it correctly If $A \subseteq R $ $m^{*}(A) = \inf \{ m^*(U) \mid  U  \text{ is open and } A \subseteq U \}$ It is obvious that $m^*(A) \leq   \inf \{  m^*(U) \mid U  \text{ is open and } A \subseteq U \}$ and for the reverse inequality I considered any collection of bounded open intervals  {$I_k$} such that $ A \subseteq \bigcup_{k=0}^\infty I_k  $ and since $\bigcup_{k=0}^\infty I_k  $ is itself an open set I took as $\sum_{k=0}^\infty l(I_k) $ $\ge$ $m^*(\bigcup_{k=0}^\infty I_k ) \ge   \inf \{ m^*(U) \mid  U  \text{ is open and } A \subseteq U \}$ and the result followed is it correct? and if not please suggest a way to do it Thanks,I was given the following problem and I need to check if I approached and solved it correctly If $A \subseteq R $ $m^{*}(A) = \inf \{ m^*(U) \mid  U  \text{ is open and } A \subseteq U \}$ It is obvious that $m^*(A) \leq   \inf \{  m^*(U) \mid U  \text{ is open and } A \subseteq U \}$ and for the reverse inequality I considered any collection of bounded open intervals  {$I_k$} such that $ A \subseteq \bigcup_{k=0}^\infty I_k  $ and since $\bigcup_{k=0}^\infty I_k  $ is itself an open set I took as $\sum_{k=0}^\infty l(I_k) $ $\ge$ $m^*(\bigcup_{k=0}^\infty I_k ) \ge   \inf \{ m^*(U) \mid  U  \text{ is open and } A \subseteq U \}$ and the result followed is it correct? and if not please suggest a way to do it Thanks,,"['real-analysis', 'measure-theory']"
81,Outer measure question.,Outer measure question.,,"Ok, so let $A \subset [0,1/2]$ and $B \subset (1/2,1]$ then how would I prove that the outer measure of $(A \cup B)$ is the same as outer measure of A + outer measure of B.","Ok, so let $A \subset [0,1/2]$ and $B \subset (1/2,1]$ then how would I prove that the outer measure of $(A \cup B)$ is the same as outer measure of A + outer measure of B.",,"['real-analysis', 'measure-theory']"
82,Variant of dominated convergence theorem,Variant of dominated convergence theorem,,"There are several variants of dominated convergence theorem. The standard one requires $f_n \to f$ a.e. and $|f_n|\leq g$ a.e. where $g$ is integrable. It can be weakened to only convergent in measure, if we impose $\sigma$-finiteness to the measure, c.f. Generalisation of Dominated Convergence Theorem . However, we know if $g$ is integrable, $N(g) = \{g\neq 0\}$ has a $\sigma$- finite measure. Does it imply that converging in measure is alway sufficient, if given a dominating integrable function $g$. If all statements made above are correct, I want to ask the following question, why most of textbooks only introduce the one with strong assumptions rather than the more general one?","There are several variants of dominated convergence theorem. The standard one requires $f_n \to f$ a.e. and $|f_n|\leq g$ a.e. where $g$ is integrable. It can be weakened to only convergent in measure, if we impose $\sigma$-finiteness to the measure, c.f. Generalisation of Dominated Convergence Theorem . However, we know if $g$ is integrable, $N(g) = \{g\neq 0\}$ has a $\sigma$- finite measure. Does it imply that converging in measure is alway sufficient, if given a dominating integrable function $g$. If all statements made above are correct, I want to ask the following question, why most of textbooks only introduce the one with strong assumptions rather than the more general one?",,"['integration', 'measure-theory', 'convergence-divergence']"
83,Borel cantelli lemma application.,Borel cantelli lemma application.,,"For each fixed $C>0$ write  $$A_{c}=\{x\in [0,1]:\mid x-\frac{p}{q}\mid >\frac{c}{q^3} \text{for every relatively prime pair} (p,q)\in \mathbb{N}\}$$ Prove that each $A_{c}$ is measurable and there exists $c>0$ such that $\lambda(A_{c})=\frac{1}{2}$, whre $\lambda$ is Lebesgue measure. For the $A_{c}$ is measurable we can use Borel cantelli lemma. I need help how to construct second assertion.","For each fixed $C>0$ write  $$A_{c}=\{x\in [0,1]:\mid x-\frac{p}{q}\mid >\frac{c}{q^3} \text{for every relatively prime pair} (p,q)\in \mathbb{N}\}$$ Prove that each $A_{c}$ is measurable and there exists $c>0$ such that $\lambda(A_{c})=\frac{1}{2}$, whre $\lambda$ is Lebesgue measure. For the $A_{c}$ is measurable we can use Borel cantelli lemma. I need help how to construct second assertion.",,"['real-analysis', 'measure-theory']"
84,Finding limit of sequence to converge to the $L^1$ norm of $f$.,Finding limit of sequence to converge to the  norm of .,L^1 f,"If $f \in L^1(m)$ ($m$ is Lebesgue measure on $\mathbb R$), I'd like to show that $$\sum_{-n^2}^{n^2} \left|\int_{j/n}^{(j+1)/n} f \,dm\,\right| \xrightarrow{n \rightarrow \infty} \int_\Bbb R |\,f\,| \,dm$$. Intuitively I see why this is true. As $m$ gets larger we're covering both a wider and finer evaluation of the integral of $f$. I suppose we can somehow compare $f$ to a simple $\phi$ in $L^1$: $\int |\phi - f| < \epsilon$. We also have that for sufficiently large $m\in \mathbb N$, $$\sum_{-m^2}^{m^2} \left| \int_{-j/n}^{(j+1)/n} f \,dm\,\right| \leq \int_\Bbb R |f| \,dm$$. Therefore $$ \int_\Bbb R |f| \,dm - \sum_{-n^2}^{n^2} |\int_{j/n}^{(j+1)/n} f \,dm| = \int_{(-\infty,-n]\cup [n,\infty)} |f| \,dm + \int_{-n}^n |f| - \sum_{-n^2}^{n^2} |\int_{j/n}^{(j+1)/n} f | < $$ $$< \varepsilon + \sum_{-n^2}^{n^2} \int_{j/n}^{(j+1)/n} |f| - |\int_{j/m}^{(j+1)/m} f |$$. I am not sure where to go from here.","If $f \in L^1(m)$ ($m$ is Lebesgue measure on $\mathbb R$), I'd like to show that $$\sum_{-n^2}^{n^2} \left|\int_{j/n}^{(j+1)/n} f \,dm\,\right| \xrightarrow{n \rightarrow \infty} \int_\Bbb R |\,f\,| \,dm$$. Intuitively I see why this is true. As $m$ gets larger we're covering both a wider and finer evaluation of the integral of $f$. I suppose we can somehow compare $f$ to a simple $\phi$ in $L^1$: $\int |\phi - f| < \epsilon$. We also have that for sufficiently large $m\in \mathbb N$, $$\sum_{-m^2}^{m^2} \left| \int_{-j/n}^{(j+1)/n} f \,dm\,\right| \leq \int_\Bbb R |f| \,dm$$. Therefore $$ \int_\Bbb R |f| \,dm - \sum_{-n^2}^{n^2} |\int_{j/n}^{(j+1)/n} f \,dm| = \int_{(-\infty,-n]\cup [n,\infty)} |f| \,dm + \int_{-n}^n |f| - \sum_{-n^2}^{n^2} |\int_{j/n}^{(j+1)/n} f | < $$ $$< \varepsilon + \sum_{-n^2}^{n^2} \int_{j/n}^{(j+1)/n} |f| - |\int_{j/m}^{(j+1)/m} f |$$. I am not sure where to go from here.",,['real-analysis']
85,"Show, there exists exactly one operator with $\int_A P_T(f)\, d\lambda=\int_{T^{-1}(A)}f\, d\lambda$","Show, there exists exactly one operator with","\int_A P_T(f)\, d\lambda=\int_{T^{-1}(A)}f\, d\lambda","Let $T\colon\mathbb{R}\to\mathbb{R}$ be a non-singular function, i.e. a measurable function with the property that     $$ \forall A\in\mathcal{B}: \lambda(A)=0 \implies \lambda(T^{-1}(A))=0. $$     Show: There exists exactly one linear operator  $P_T\colon L_{\lambda}^1\to L_{\lambda}^1$ so that for all $f\in L_{\lambda}^1$ and all $A\in \mathcal{B}$ it is     $$ \int_A P_T(f)\, d\lambda=\int_{T^{-1}(A)}f\, d\lambda. $$ Hello, I would really prefer to present you my own recent ideas but I do not have own ideas. To be honest, I am rather helpless. Can you pls give me help? Greetings. math12 New Edit : The only thing I already know is that $A\mapsto\int_{T^{-1}(A)}f\, d\lambda$ is a signed measure. Now one can apply Radon-Nikodým or something like that?","Let $T\colon\mathbb{R}\to\mathbb{R}$ be a non-singular function, i.e. a measurable function with the property that     $$ \forall A\in\mathcal{B}: \lambda(A)=0 \implies \lambda(T^{-1}(A))=0. $$     Show: There exists exactly one linear operator  $P_T\colon L_{\lambda}^1\to L_{\lambda}^1$ so that for all $f\in L_{\lambda}^1$ and all $A\in \mathcal{B}$ it is     $$ \int_A P_T(f)\, d\lambda=\int_{T^{-1}(A)}f\, d\lambda. $$ Hello, I would really prefer to present you my own recent ideas but I do not have own ideas. To be honest, I am rather helpless. Can you pls give me help? Greetings. math12 New Edit : The only thing I already know is that $A\mapsto\int_{T^{-1}(A)}f\, d\lambda$ is a signed measure. Now one can apply Radon-Nikodým or something like that?",,[]
86,Let $f\in L^1(\mathbb{R})$. Find $\lim_{n\rightarrow\infty} \int_\mathbb{R}\vert f(x+n)-f(x)\vert dx$.,Let . Find .,f\in L^1(\mathbb{R}) \lim_{n\rightarrow\infty} \int_\mathbb{R}\vert f(x+n)-f(x)\vert dx,"Let $f\in L^1(\mathbb{R})$. Find $\lim_{n\rightarrow\infty} \int_\mathbb{R}\vert f(x+n)-f(x)\vert dx$. I think the limit is $2\Vert f\Vert_{L^1}$, as this result holds for simple functions. If we first consider $f$ is a simple function, after some large $n$, support of $f(x+n)$ and $f(x)$ are going to be disjoint which will give the result I guess. But I could not generalize my idea by density, because I could  get only one side inequality by density, Maybe my guess is wrong, Thanks in advance for any help/hint suggestions.","Let $f\in L^1(\mathbb{R})$. Find $\lim_{n\rightarrow\infty} \int_\mathbb{R}\vert f(x+n)-f(x)\vert dx$. I think the limit is $2\Vert f\Vert_{L^1}$, as this result holds for simple functions. If we first consider $f$ is a simple function, after some large $n$, support of $f(x+n)$ and $f(x)$ are going to be disjoint which will give the result I guess. But I could not generalize my idea by density, because I could  get only one side inequality by density, Maybe my guess is wrong, Thanks in advance for any help/hint suggestions.",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
87,Equivalence of $\int_a^b|f|=0$,Equivalence of,\int_a^b|f|=0,"Suppose $f\geq 0$, is Riemann integrable on $[a,b]$, then $\int_a^bf=0$ iff $D=\{x\in[a,b]\mid f(x)>0\}$ has Lebesgue measure zero. A set $A\subseteq\mathbb{R}$ has Lebesgue measure zero iff $\forall\epsilon>0\exists$a countable family of open intervals $\{I_n\}_{n\in\omega}(A\subseteq\bigcup_{n\in\omega}I_n\wedge\sum_{n=0}^\infty|I_n|<\epsilon)$. So far my thoughts are, ($\rightarrow$) $L(P,f)=0$ for all partition $P$. Let $\epsilon>0$, then $\exists P_0(U(P_0,f)<\epsilon)$. But how can I construct a family of open intervals using that partition $P_0$? I found some similar questions here and here , but they are not in the form I stated. I am just starting to learn measure theory. Can anyone prove it using definitions only? Thanks!","Suppose $f\geq 0$, is Riemann integrable on $[a,b]$, then $\int_a^bf=0$ iff $D=\{x\in[a,b]\mid f(x)>0\}$ has Lebesgue measure zero. A set $A\subseteq\mathbb{R}$ has Lebesgue measure zero iff $\forall\epsilon>0\exists$a countable family of open intervals $\{I_n\}_{n\in\omega}(A\subseteq\bigcup_{n\in\omega}I_n\wedge\sum_{n=0}^\infty|I_n|<\epsilon)$. So far my thoughts are, ($\rightarrow$) $L(P,f)=0$ for all partition $P$. Let $\epsilon>0$, then $\exists P_0(U(P_0,f)<\epsilon)$. But how can I construct a family of open intervals using that partition $P_0$? I found some similar questions here and here , but they are not in the form I stated. I am just starting to learn measure theory. Can anyone prove it using definitions only? Thanks!",,['measure-theory']
88,Measure extension via inner measure,Measure extension via inner measure,,"Is it possible to use ""inner measure"" in the proof of the Caratheodory extension theorem ? I'm trying to understand why we prefer outer one instead, although definitions of outer and inner measures are dual. N. B.: I mean $\mu_*(A) = \sup \{\sum \mu(E_i) | E_i\mbox{ disjoint}, E_i \subset A\}$ is the ""inner measure,"" generated by some pre-measure $\mu$, defined on some ring $\mathcal R$. It's not in general use. So let me explain the problem: We can proof superadditivity of $\mu_*$ defined above. Then we consider $\mathcal M (\mathcal R) = \{A \;|\; \forall E  \in \mathcal R \;\;\mu_*(E\cup A) + \mu_*(E\setminus A) = \mu_*(E)\}.$ Now it's not hard to show that $\mathcal M(\mathcal R)$ closed under finite union and completion. But I can't prove that $\mathcal M(\mathcal R)$ closed under countable union. Maybe it's not true in general? What is the difference in such symmetrical concepts of inner in outer measure?","Is it possible to use ""inner measure"" in the proof of the Caratheodory extension theorem ? I'm trying to understand why we prefer outer one instead, although definitions of outer and inner measures are dual. N. B.: I mean $\mu_*(A) = \sup \{\sum \mu(E_i) | E_i\mbox{ disjoint}, E_i \subset A\}$ is the ""inner measure,"" generated by some pre-measure $\mu$, defined on some ring $\mathcal R$. It's not in general use. So let me explain the problem: We can proof superadditivity of $\mu_*$ defined above. Then we consider $\mathcal M (\mathcal R) = \{A \;|\; \forall E  \in \mathcal R \;\;\mu_*(E\cup A) + \mu_*(E\setminus A) = \mu_*(E)\}.$ Now it's not hard to show that $\mathcal M(\mathcal R)$ closed under finite union and completion. But I can't prove that $\mathcal M(\mathcal R)$ closed under countable union. Maybe it's not true in general? What is the difference in such symmetrical concepts of inner in outer measure?",,['measure-theory']
89,Prove that $\mu_{\star}(A) = \frac{\sup A - \inf A}{2}$ is outer measure.,Prove that  is outer measure.,\mu_{\star}(A) = \frac{\sup A - \inf A}{2},"Let $X = \mathbb{N}$ and $\mu_{\star}: \mathcal{P}(\mathbb{N}) \rightarrow [0,\infty]$ such that $$\mu_{\star}(A) = \frac{\sup A - \inf A}{2}$$where $\sup \emptyset = \inf \emptyset = 0$. Prove that $\mu_{\star}$ is outer measure. The first condition is obviously, because we have $\mu_{\star}(\emptyset) = 0$.  So let $$A \subseteq \bigcup_{n=1}^{\infty} A_n$$we would like show that $$\mu_{\star}(A) \le \sum_{n=1}^{\infty} \mu_{\star}(A_n)$$ Hence from definition of $\mu_{\star}(A)$ we have to show: $$\frac{\sup A - \inf A}{2} \le \sum_{n=1}^{\infty} \frac{\sup A_n - \inf A_n}{2}$$ So $$ \sup A - \inf A \le \sum_{n=1}^{\infty} \sup A_n - \sum_{n=1}^{\infty} \inf A_n \quad (\dagger)$$ But as you can see in this topic: Inequality with infimum and supremum for $A \subseteq \bigcup_{n=1}^{\infty}A_n$ inequality $( \dagger)$ is not true. So this exercise is wrong? I am really confused, because it is next mistake today... I will grateful for your help.","Let $X = \mathbb{N}$ and $\mu_{\star}: \mathcal{P}(\mathbb{N}) \rightarrow [0,\infty]$ such that $$\mu_{\star}(A) = \frac{\sup A - \inf A}{2}$$where $\sup \emptyset = \inf \emptyset = 0$. Prove that $\mu_{\star}$ is outer measure. The first condition is obviously, because we have $\mu_{\star}(\emptyset) = 0$.  So let $$A \subseteq \bigcup_{n=1}^{\infty} A_n$$we would like show that $$\mu_{\star}(A) \le \sum_{n=1}^{\infty} \mu_{\star}(A_n)$$ Hence from definition of $\mu_{\star}(A)$ we have to show: $$\frac{\sup A - \inf A}{2} \le \sum_{n=1}^{\infty} \frac{\sup A_n - \inf A_n}{2}$$ So $$ \sup A - \inf A \le \sum_{n=1}^{\infty} \sup A_n - \sum_{n=1}^{\infty} \inf A_n \quad (\dagger)$$ But as you can see in this topic: Inequality with infimum and supremum for $A \subseteq \bigcup_{n=1}^{\infty}A_n$ inequality $( \dagger)$ is not true. So this exercise is wrong? I am really confused, because it is next mistake today... I will grateful for your help.",,['measure-theory']
90,"Why is the shift the optimal plan between $[0,1)$ and $[1,2)$ (with distance-squared cost function)?",Why is the shift the optimal plan between  and  (with distance-squared cost function)?,"[0,1) [1,2)","Example 1.3 of Optimal and Better Transport Plans reads Consider the task to transport points on the real line (equipped with the Lebesgue measure) from the interval [0, 1) to [1, 2) where the cost of moving one point to another is the squared distance between these points ($X = [0, 1)$, $Y = [1, 2)$, $c(x, y) = (x − y)^2$, $\mu = \nu = \lambda$). The simplest way to achieve this transport is to shift every point by 1. This results in transport costs of 1 and one easily checks that all other transport plans are more expensive. Why are all other transport plans more expensive? I.e., given a transport plan $P$ (which is a measure on $[0,1) \times [1,2)$ such that $P \circ \pi_{1}^{-1} = \mu$ and $P \circ \pi_{2}^{-1} = \nu$, where $\pi_i$ is the projection onto the $i$-th coordinate) why is it true that $$ \int_{[0,1) \times [1,2)} (x-y)^2 \, dP \geq 1 ? $$ What I tried initially. By writing $(x-y)^2 = x^2 -2xy + y^2$ and using the fact that integrating a function of $x$ with respect to $P$ is the same as integrating with respect to $\mu$ (and similarly for $y$ and $\nu$) gives $$ \begin{align*} \int_{[0,1) \times [1,2)} (x-y)^2 \,dP &= \int_{0}^{1}x^{2} \,dx - 2\int_{[0,1) \times [1,2)} xy \,dP + \int_{1}^{2} y^{2}\, dy \\ &= 8/3 - 2\int_{[0,1) \times [1,2)} xy \,dP, \end{align*} $$ so it suffices to show that $\int_{[0,1) \times [1,2)} xy \,dP \leq 5/6$. I don't see how to show this. Addendum. I'm not sure if what I tried above was leading to a solution, but I think I have the answer, based on @Niels Diepeveen's hint. As noted in my comment to Niels' answer, it suffices to show that the 'diagonal' transport plan $P_{o}$ on $[0,1)\times [0,1)$ is optimal for the cost function $c(x,y+1) = (x-y-1)^{2}$ ('diagonal' here means that $P_{o}$ is supported by $\{(x,y):x=y\}$. As noted by Niels, it is clear that $P_{o}$ is optimal for the cost function $c(x,y)=(x-y)^{2}$. But $c(x,y+1) = c(x,y) -2(x-y)+ 1$, so if $P$ is any transport plan, $$ \begin{align*} \int_{[0,1)^{2}} c(x,y+1)\, dP &= \int_{[0,1)^{2}} (c(x,y) - 2(x-y) + 1) \, dP \\ &= \int_{[0,1)^{2}} c(x,y) \, dP - 2\int_{[0,1)^{2}} x \, dP + 2\int_{[0,1)^{2}} y \, dP + 1  \\ &= \int_{[0,1)^{2}} c(x,y) \, dP - 2\int^{1}_{0} x \, d\lambda + 2\int^{1}_{0} y \, d\lambda + 1  \\ &= \int_{[0,1)^{2}} c(x,y) \, dP +1 \\ &\geq \int_{[0,1)^{2}} c(x,y) \, dP_{o} +1 \\ &= \int_{[0,1)^{2}} c(x,y+1)\, dP_{o}, \qquad \text{(By the computation just done.)} \end{align*} $$ where we've used the fact that integrating a function of just one variable with respect to a transport measure (plan) is the same as integrating that same function with respect to the marginal measure.","Example 1.3 of Optimal and Better Transport Plans reads Consider the task to transport points on the real line (equipped with the Lebesgue measure) from the interval [0, 1) to [1, 2) where the cost of moving one point to another is the squared distance between these points ($X = [0, 1)$, $Y = [1, 2)$, $c(x, y) = (x − y)^2$, $\mu = \nu = \lambda$). The simplest way to achieve this transport is to shift every point by 1. This results in transport costs of 1 and one easily checks that all other transport plans are more expensive. Why are all other transport plans more expensive? I.e., given a transport plan $P$ (which is a measure on $[0,1) \times [1,2)$ such that $P \circ \pi_{1}^{-1} = \mu$ and $P \circ \pi_{2}^{-1} = \nu$, where $\pi_i$ is the projection onto the $i$-th coordinate) why is it true that $$ \int_{[0,1) \times [1,2)} (x-y)^2 \, dP \geq 1 ? $$ What I tried initially. By writing $(x-y)^2 = x^2 -2xy + y^2$ and using the fact that integrating a function of $x$ with respect to $P$ is the same as integrating with respect to $\mu$ (and similarly for $y$ and $\nu$) gives $$ \begin{align*} \int_{[0,1) \times [1,2)} (x-y)^2 \,dP &= \int_{0}^{1}x^{2} \,dx - 2\int_{[0,1) \times [1,2)} xy \,dP + \int_{1}^{2} y^{2}\, dy \\ &= 8/3 - 2\int_{[0,1) \times [1,2)} xy \,dP, \end{align*} $$ so it suffices to show that $\int_{[0,1) \times [1,2)} xy \,dP \leq 5/6$. I don't see how to show this. Addendum. I'm not sure if what I tried above was leading to a solution, but I think I have the answer, based on @Niels Diepeveen's hint. As noted in my comment to Niels' answer, it suffices to show that the 'diagonal' transport plan $P_{o}$ on $[0,1)\times [0,1)$ is optimal for the cost function $c(x,y+1) = (x-y-1)^{2}$ ('diagonal' here means that $P_{o}$ is supported by $\{(x,y):x=y\}$. As noted by Niels, it is clear that $P_{o}$ is optimal for the cost function $c(x,y)=(x-y)^{2}$. But $c(x,y+1) = c(x,y) -2(x-y)+ 1$, so if $P$ is any transport plan, $$ \begin{align*} \int_{[0,1)^{2}} c(x,y+1)\, dP &= \int_{[0,1)^{2}} (c(x,y) - 2(x-y) + 1) \, dP \\ &= \int_{[0,1)^{2}} c(x,y) \, dP - 2\int_{[0,1)^{2}} x \, dP + 2\int_{[0,1)^{2}} y \, dP + 1  \\ &= \int_{[0,1)^{2}} c(x,y) \, dP - 2\int^{1}_{0} x \, d\lambda + 2\int^{1}_{0} y \, d\lambda + 1  \\ &= \int_{[0,1)^{2}} c(x,y) \, dP +1 \\ &\geq \int_{[0,1)^{2}} c(x,y) \, dP_{o} +1 \\ &= \int_{[0,1)^{2}} c(x,y+1)\, dP_{o}, \qquad \text{(By the computation just done.)} \end{align*} $$ where we've used the fact that integrating a function of just one variable with respect to a transport measure (plan) is the same as integrating that same function with respect to the marginal measure.",,"['measure-theory', 'optimal-transport']"
91,Application of Minkowski inequality for integrals,Application of Minkowski inequality for integrals,,"I have a question regarding Minkowski inequality for integrals: Suppose $f:(0,\infty)\rightarrow\mathbb{R}$ is a function in $L^p$ with respect to Lebesgue measure on $(0,\infty),\ p\in(1,\infty)$. Define $F(y)=\int_{(0,1)}f(xy)d\lambda(x),\ y>0$. Show that $F\in L^p$ with respect to the Lebesgue measure on $(0,\infty)$ and $||F||_p={p\over{p-1}}||f||_p$. I am advised to use Minkowski inequality for integrals: $||F||_p=[\int_{(0,\infty)}|\int_{(0,1)}f(xy)d\lambda(x)|^{p}d\lambda(y)]^{1\over p}\leq\int_{(0,1)}[\int_{(0,\infty)}|f(xy)|^{p}d\lambda(y)]^{1\over p}d\lambda(x)$. However, I am stucked after reaching this step. Kindly advise to proceed on the working. Thank you very much.","I have a question regarding Minkowski inequality for integrals: Suppose $f:(0,\infty)\rightarrow\mathbb{R}$ is a function in $L^p$ with respect to Lebesgue measure on $(0,\infty),\ p\in(1,\infty)$. Define $F(y)=\int_{(0,1)}f(xy)d\lambda(x),\ y>0$. Show that $F\in L^p$ with respect to the Lebesgue measure on $(0,\infty)$ and $||F||_p={p\over{p-1}}||f||_p$. I am advised to use Minkowski inequality for integrals: $||F||_p=[\int_{(0,\infty)}|\int_{(0,1)}f(xy)d\lambda(x)|^{p}d\lambda(y)]^{1\over p}\leq\int_{(0,1)}[\int_{(0,\infty)}|f(xy)|^{p}d\lambda(y)]^{1\over p}d\lambda(x)$. However, I am stucked after reaching this step. Kindly advise to proceed on the working. Thank you very much.",,['measure-theory']
92,Is the outer measure of $A\cup B$ equal to the sum of their outer measures if $A\cap B=\varnothing$?,Is the outer measure of  equal to the sum of their outer measures if ?,A\cup B A\cap B=\varnothing,"I understand that Lebesgue outer measure on $\mathbb R$ is not countably additive. But if there are two disjoint sets, does the outer measure of their union equal the sum of their outer measure? Can someone give me a counterexample?","I understand that Lebesgue outer measure on $\mathbb R$ is not countably additive. But if there are two disjoint sets, does the outer measure of their union equal the sum of their outer measure? Can someone give me a counterexample?",,"['real-analysis', 'measure-theory']"
93,Show that $\mu$ is the Lebesgue-Stieltjes measure corresponding to $\alpha$,Show that  is the Lebesgue-Stieltjes measure corresponding to,\mu \alpha,"I am preparing the quiz for the Lebesgue measure courses, and I am stuck with the problem of the book ""Real analysis for graduate students"" The problem is following. Let $\mu$ be a measure on the Borel-$\sigma$ algebra of $\mathbb{R}$ such that $\mu(K) < \infty$ Whenever $K$ is compact, define $\alpha (x) = \mu((0,x])$ if $x \geq 0$ and $\alpha(x) = -\mu((x,0])$ if $x < 0$. Show that $\mu$ is the Lebesgue-Stieltjes measure corresponding to $\alpha$ The only hint I got so far is that I have to use Caratheodory Extention Thorem. Could anybody help to solve that? Thanks in advance.","I am preparing the quiz for the Lebesgue measure courses, and I am stuck with the problem of the book ""Real analysis for graduate students"" The problem is following. Let $\mu$ be a measure on the Borel-$\sigma$ algebra of $\mathbb{R}$ such that $\mu(K) < \infty$ Whenever $K$ is compact, define $\alpha (x) = \mu((0,x])$ if $x \geq 0$ and $\alpha(x) = -\mu((x,0])$ if $x < 0$. Show that $\mu$ is the Lebesgue-Stieltjes measure corresponding to $\alpha$ The only hint I got so far is that I have to use Caratheodory Extention Thorem. Could anybody help to solve that? Thanks in advance.",,"['measure-theory', 'lebesgue-integral']"
94,Almost everywhere limit of Borel measurable scalar functions is Borel measurable in a complete measure space,Almost everywhere limit of Borel measurable scalar functions is Borel measurable in a complete measure space,,"I am trying to solve the following exercise from Royden: Let $(\Omega, \Sigma, \mu)$ be a complete measure space and $f_{n}:\Omega\to\mathbb{R}$ be measurable for each $n\geq 1$.  If $f_{n}\to f$ almost everywhere on $\Omega$, then $f$ is measurable. What I was thinking might work is if I could somehow construct an increasing sequence of measurable functions $g_{n}:\Omega\to\mathbb{R}$ which also converge to $f$ almost everywhere.  That is, $g_{n}(\lambda)\geq g_{n-1}(\lambda)$ for all $\lambda\in\Omega,n\geq 1$. Then I could use the fact that $\{\lambda\in\Omega : f(\lambda) \geq \alpha\}$ is ""almost equal"" to $\bigcup_{n=1}^{\infty}\{\lambda\in\Omega : f_{n}(\lambda) \geq \alpha\}$, and pull some magic with completeness to get that $\{\lambda\in\Omega : f(\lambda) \geq \alpha\}\in\Sigma$. Is there a way to construct such $g_{n}$?","I am trying to solve the following exercise from Royden: Let $(\Omega, \Sigma, \mu)$ be a complete measure space and $f_{n}:\Omega\to\mathbb{R}$ be measurable for each $n\geq 1$.  If $f_{n}\to f$ almost everywhere on $\Omega$, then $f$ is measurable. What I was thinking might work is if I could somehow construct an increasing sequence of measurable functions $g_{n}:\Omega\to\mathbb{R}$ which also converge to $f$ almost everywhere.  That is, $g_{n}(\lambda)\geq g_{n-1}(\lambda)$ for all $\lambda\in\Omega,n\geq 1$. Then I could use the fact that $\{\lambda\in\Omega : f(\lambda) \geq \alpha\}$ is ""almost equal"" to $\bigcup_{n=1}^{\infty}\{\lambda\in\Omega : f_{n}(\lambda) \geq \alpha\}$, and pull some magic with completeness to get that $\{\lambda\in\Omega : f(\lambda) \geq \alpha\}\in\Sigma$. Is there a way to construct such $g_{n}$?",,['measure-theory']
95,Show that the upper envelope of a bounded function is upper semi continuous directly,Show that the upper envelope of a bounded function is upper semi continuous directly,,"Definition 1: A real valued function $f$ is said to be upper semicontinuous at a point $p$ if: $$f(p) \geq \limsup_{x \rightarrow p} f(x) $$ Definition 2: Let $f$ be a bounded real valued function on $[a,b]$ . Define the upper envelope $h$ of $f$ as: $$ h(y) = \inf_{\delta >0} \sup_{|x-y|<\delta} f(x)$$ The question: If $f$ is a real valued bounded function on $[a,b]$ , show that the upper envelope of $f$ is upper semicontinuous. Background: This is a sample qualifying exam question. In the past, this question is sometimes asked with a part a which says that a function is upper semicontinuous iff the sets $\{x: f(x) < \lambda\}$ are open for each $\lambda \in \mathbb{R}$ . This characterization is not too difficult to prove. Also, the desired result is not too difficult to deduce from this characterization. For example, see: Upper semi-continuity and lower semi-continuity of particular functions However, this approach is unsatisfactory. In particular, this problem has shown up sans part a before on the qualifying exam. I'm looking for a proof that takes a bounded real valued function $f$ , and from Definition 2 deduces Definition 1 directly. Every attempt I make, I get lost in chasing infs and sups through inequalities. Any help would be much appreciated.","Definition 1: A real valued function is said to be upper semicontinuous at a point if: Definition 2: Let be a bounded real valued function on . Define the upper envelope of as: The question: If is a real valued bounded function on , show that the upper envelope of is upper semicontinuous. Background: This is a sample qualifying exam question. In the past, this question is sometimes asked with a part a which says that a function is upper semicontinuous iff the sets are open for each . This characterization is not too difficult to prove. Also, the desired result is not too difficult to deduce from this characterization. For example, see: Upper semi-continuity and lower semi-continuity of particular functions However, this approach is unsatisfactory. In particular, this problem has shown up sans part a before on the qualifying exam. I'm looking for a proof that takes a bounded real valued function , and from Definition 2 deduces Definition 1 directly. Every attempt I make, I get lost in chasing infs and sups through inequalities. Any help would be much appreciated.","f p f(p) \geq \limsup_{x \rightarrow p} f(x)  f [a,b] h f  h(y) = \inf_{\delta >0} \sup_{|x-y|<\delta} f(x) f [a,b] f \{x: f(x) < \lambda\} \lambda \in \mathbb{R} f","['real-analysis', 'measure-theory', 'continuity']"
96,Integration with respect to complex measure,Integration with respect to complex measure,,"In page 129 of Rudin's real and complex analysis, it assumes that $\mu$ is a complex Borel measure and defines integration by $\int f d\mu = \int fh\ d|\mu|$, where $d\mu = h\ d|\mu|$ and $|h|=1$. Then it claims that $\int \chi_E d\mu = \mu(E)$ is a special case, but I'm having trouble to see why $\int_E h d|\mu|$ is equal to $\mu(E)$. I tried to prove it using the definitions, but it didn't seem to work. I'm not sure what I'm missing...","In page 129 of Rudin's real and complex analysis, it assumes that $\mu$ is a complex Borel measure and defines integration by $\int f d\mu = \int fh\ d|\mu|$, where $d\mu = h\ d|\mu|$ and $|h|=1$. Then it claims that $\int \chi_E d\mu = \mu(E)$ is a special case, but I'm having trouble to see why $\int_E h d|\mu|$ is equal to $\mu(E)$. I tried to prove it using the definitions, but it didn't seem to work. I'm not sure what I'm missing...",,"['measure-theory', 'lebesgue-integral']"
97,Why is the Borel-$\sigma$-field in $n$ dimensions the $\sigma$-field generated by the products of half open intervals?,Why is the Borel--field in  dimensions the -field generated by the products of half open intervals?,\sigma n \sigma,"My professor defines $\mathcal{B}^2 \equiv \sigma\{A \times E : A,E \in \mathcal{B} \}$ where $\mathcal{B}$ is the Borel sets on the real line. He then says an equivalent definition is that $\mathcal{B}^2 \equiv \sigma\{(a_1, b_2] \times (a_2, b_2] : a_1 \leq b_1, a_2 \leq b_2\}$ . I am not seeing how these two are equivalent. I understand that the Borel sets on the real line are defined as $\sigma\{(a, b] : a \leq b\}$ .",My professor defines where is the Borel sets on the real line. He then says an equivalent definition is that . I am not seeing how these two are equivalent. I understand that the Borel sets on the real line are defined as .,"\mathcal{B}^2 \equiv \sigma\{A \times E : A,E \in \mathcal{B} \} \mathcal{B} \mathcal{B}^2 \equiv \sigma\{(a_1, b_2] \times (a_2, b_2] : a_1 \leq b_1, a_2 \leq b_2\} \sigma\{(a, b] : a \leq b\}",['measure-theory']
98,Tricky detail in the proof of Haar's theorem,Tricky detail in the proof of Haar's theorem,,"I'm trying to dig in the details of the proof of Haar's theorem, and at some point I need to use Fubini's theorem, which requires that if we want to change the order of integration over the product space $X  \times Y$, the spaces $X$ and $Y$ must be complete measure spaces. (In my case, they are topological measure spaces and my measure is also defined over the completion of their $\sigma$-algebras, but in order to have a topological measure space, I restrict the measure to the Borel $\sigma$-algebra). However, I am working with a continuous function (the one I am integrating). I am wondering if the following holds : given a continuous function $h : X \times X \to \mathbb C$ where $(X, \mathcal T)$ is a topological space, $(X, \Sigma, \mu)$ is a complete measure space and $\sigma(\mathcal T) \subseteq \Sigma$ (the Borel sets are measurable), is it possible to show that $h$ is measurable with respect to $\overline{\sigma}(T) \times \overline{\sigma}(\mathcal T)$? (Here $\overline{\sigma}$ denotes the completion of the $\sigma$-algebra generated by $\mathcal T$.) This will imply I can use Fubini. Note that my measure $\mu$ comes from Haar's theorem, so if it helps, it is non-zero and inner/outer regular. Perhaps the following could be easier to prove : if $f : (X, \mathcal T_X) \to (Y, \mathcal T_Y)$ is a continuous function, is $f$ measurable with respect to $\overline{\sigma}(\mathcal T_X)$ and $\overline{\sigma}(\mathcal T_Y)$? I guess it's false if you put the zero measure on $Y$ because then the completion is just the trivial $\sigma$-algebra, but in my case I am working with $\mathbb C$ and the Lebesgue measure, so perhaps I can find my way around it. All the proofs I've read seem to hide this tricky detail that the assumptions of Fubini must be satisfied...","I'm trying to dig in the details of the proof of Haar's theorem, and at some point I need to use Fubini's theorem, which requires that if we want to change the order of integration over the product space $X  \times Y$, the spaces $X$ and $Y$ must be complete measure spaces. (In my case, they are topological measure spaces and my measure is also defined over the completion of their $\sigma$-algebras, but in order to have a topological measure space, I restrict the measure to the Borel $\sigma$-algebra). However, I am working with a continuous function (the one I am integrating). I am wondering if the following holds : given a continuous function $h : X \times X \to \mathbb C$ where $(X, \mathcal T)$ is a topological space, $(X, \Sigma, \mu)$ is a complete measure space and $\sigma(\mathcal T) \subseteq \Sigma$ (the Borel sets are measurable), is it possible to show that $h$ is measurable with respect to $\overline{\sigma}(T) \times \overline{\sigma}(\mathcal T)$? (Here $\overline{\sigma}$ denotes the completion of the $\sigma$-algebra generated by $\mathcal T$.) This will imply I can use Fubini. Note that my measure $\mu$ comes from Haar's theorem, so if it helps, it is non-zero and inner/outer regular. Perhaps the following could be easier to prove : if $f : (X, \mathcal T_X) \to (Y, \mathcal T_Y)$ is a continuous function, is $f$ measurable with respect to $\overline{\sigma}(\mathcal T_X)$ and $\overline{\sigma}(\mathcal T_Y)$? I guess it's false if you put the zero measure on $Y$ because then the completion is just the trivial $\sigma$-algebra, but in my case I am working with $\mathbb C$ and the Lebesgue measure, so perhaps I can find my way around it. All the proofs I've read seem to hide this tricky detail that the assumptions of Fubini must be satisfied...",,"['measure-theory', 'topological-groups']"
99,"Prove that $λ^∗(A×B)\geq λ^∗(A)λ^∗(B)$ for every pair of sets, $A \subseteq \mathbb{R}^n$ and $B \subseteq \mathbb{R}^m$","Prove that  for every pair of sets,  and",λ^∗(A×B)\geq λ^∗(A)λ^∗(B) A \subseteq \mathbb{R}^n B \subseteq \mathbb{R}^m,"Prove that  $ \lambda^*(A\times B)\geq \lambda^*(A) \lambda^*(B)$ for every pair of sets, $A \subseteq\mathbb{R}^n$ and $B \subseteq\mathbb{R}^m$, where $\lambda^*$ denotes the Lebesgue Outer Measure and $\lambda$ the Lebesgue Measure. Given $\epsilon>0$, there is an open set $G$ such that $A\times B \subseteq G$  and  $ \lambda^*(A\times B) \geq \lambda(G) - \epsilon$. Then, naming $G_n$ the first $n$ coordinates of $G$, and $G_m$ the last $m$ coordinates of $G$,  $A \subseteq G_n$ and $B \subseteq{G_m}$,   $G_n$ and $G_m$ are open sets. Thus, $ \lambda(G_n)\geq \lambda^*(A)$ and $ \lambda(G_m) \geq \lambda^*(B)$. I want to conclude that  $\lambda(G) \geq \lambda (G_n\times G_m)$, but I don't see how. Ps: I have already proved: $\lambda(G_n\times G_m) =\lambda (G_n) \lambda (G_m)$.","Prove that  $ \lambda^*(A\times B)\geq \lambda^*(A) \lambda^*(B)$ for every pair of sets, $A \subseteq\mathbb{R}^n$ and $B \subseteq\mathbb{R}^m$, where $\lambda^*$ denotes the Lebesgue Outer Measure and $\lambda$ the Lebesgue Measure. Given $\epsilon>0$, there is an open set $G$ such that $A\times B \subseteq G$  and  $ \lambda^*(A\times B) \geq \lambda(G) - \epsilon$. Then, naming $G_n$ the first $n$ coordinates of $G$, and $G_m$ the last $m$ coordinates of $G$,  $A \subseteq G_n$ and $B \subseteq{G_m}$,   $G_n$ and $G_m$ are open sets. Thus, $ \lambda(G_n)\geq \lambda^*(A)$ and $ \lambda(G_m) \geq \lambda^*(B)$. I want to conclude that  $\lambda(G) \geq \lambda (G_n\times G_m)$, but I don't see how. Ps: I have already proved: $\lambda(G_n\times G_m) =\lambda (G_n) \lambda (G_m)$.",,"['real-analysis', 'measure-theory', 'inequality']"
