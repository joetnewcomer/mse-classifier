,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Does the empirical CDF converge in $L^1$ and $L^2$?,Does the empirical CDF converge in  and ?,L^1 L^2,"I am somewhat confused with the empirical distribution function: Assume we have $X_1, X_2, ...$ iid real-valued random variables with true distribution $F_0$. Then by the Theorem of Glivenko-Cantelli, $$| \hat F_n - F_0 |_\infty \longrightarrow 0$$ Does this also imply that $\hat F_n$ converges to the true CDF in $L^1$ and $L^2$ norm, i.e, $$ \int | \hat F_n(x) - F_0(x) | \, dx \longrightarrow 0$$ and $$ \left[\int (\hat F_n(x) - F_0(x))^2 \, dx\right]^\frac{1}{2}  \longrightarrow 0?$$ If not, what else doe we have to assume on $F_0$? After reading on embeddings of $L^p$ spaces ( http://en.wikipedia.org/wiki/Lp_space#Embeddings ), I guess this does not follow from some general results, but is there maybe something special to the empirical CDF that guarantees this?","I am somewhat confused with the empirical distribution function: Assume we have $X_1, X_2, ...$ iid real-valued random variables with true distribution $F_0$. Then by the Theorem of Glivenko-Cantelli, $$| \hat F_n - F_0 |_\infty \longrightarrow 0$$ Does this also imply that $\hat F_n$ converges to the true CDF in $L^1$ and $L^2$ norm, i.e, $$ \int | \hat F_n(x) - F_0(x) | \, dx \longrightarrow 0$$ and $$ \left[\int (\hat F_n(x) - F_0(x))^2 \, dx\right]^\frac{1}{2}  \longrightarrow 0?$$ If not, what else doe we have to assume on $F_0$? After reading on embeddings of $L^p$ spaces ( http://en.wikipedia.org/wiki/Lp_space#Embeddings ), I guess this does not follow from some general results, but is there maybe something special to the empirical CDF that guarantees this?",,['statistics']
1,when can I say there is a relationship between events?,when can I say there is a relationship between events?,,"I am by no means a math expert, but I am analyzing very large weather data data for a computer science course .I am taking away all the weather related issues out of the analyzing and just looking strictly at it in the eyes of statistics. Lets say there are 2 events, 1 occurs 250 times in the year, and the other event occurs 50 times in a year. The second event occurs every single day the first event occurred. Can I say that there is a relationship between the two events? I am not sure if it is safe to say there is a good chance there is a relationship between the data because this could just be a coincidence. For example if the event A occurred 25 times a year and event B occurred 15 times again event B occurring every time event A occurred I would be more confident to say there is a relationship between the two events because there is less of a chance it is a coincidence due the the number of times event A occurred. To rephrase, lets say event A occurred 365 times in the year and event B occurred 10 times in the year, event B would occur every single time event A occurred, but this is just because event A occurred every day so there is no relationship. Is there some sort of standard to say that when two events have a statistically high probability of having a relationship of some sort? Hope this makes sense.","I am by no means a math expert, but I am analyzing very large weather data data for a computer science course .I am taking away all the weather related issues out of the analyzing and just looking strictly at it in the eyes of statistics. Lets say there are 2 events, 1 occurs 250 times in the year, and the other event occurs 50 times in a year. The second event occurs every single day the first event occurred. Can I say that there is a relationship between the two events? I am not sure if it is safe to say there is a good chance there is a relationship between the data because this could just be a coincidence. For example if the event A occurred 25 times a year and event B occurred 15 times again event B occurring every time event A occurred I would be more confident to say there is a relationship between the two events because there is less of a chance it is a coincidence due the the number of times event A occurred. To rephrase, lets say event A occurred 365 times in the year and event B occurred 10 times in the year, event B would occur every single time event A occurred, but this is just because event A occurred every day so there is no relationship. Is there some sort of standard to say that when two events have a statistically high probability of having a relationship of some sort? Hope this makes sense.",,['statistics']
2,What distribution would describe this?,What distribution would describe this?,,"I start with 100 eggs, 10 of them being broken. I randomly select eggs without replacement until they are all split into baskets of 10 eggs each. Here's what I know: Best case scenario all 10 bad eggs go into 1 basket, giving me 9 good baskets out of 10. Worst case is each basket carries 1 bad egg giving me 0 good baskets. Probability of any one basket being good, p, is 0.90^10=0.349. Mean number of good baskets would be 10*0.349=3.49? However this calculation assumes replacements, or at least requires large number of baskets/eggs to be a good approximation. Every good basket created decreases the probability that the next basket(s) will be good. For large numbers of eggs, say 50,000, is the non-replacement a big issue? Which distribution would allow me to calculate a confidence interval for the mean number of good baskets? Given that there are a large number of eggs (thousands), with known defect rate (around 1%) and fixed number of eggs per basket.","I start with 100 eggs, 10 of them being broken. I randomly select eggs without replacement until they are all split into baskets of 10 eggs each. Here's what I know: Best case scenario all 10 bad eggs go into 1 basket, giving me 9 good baskets out of 10. Worst case is each basket carries 1 bad egg giving me 0 good baskets. Probability of any one basket being good, p, is 0.90^10=0.349. Mean number of good baskets would be 10*0.349=3.49? However this calculation assumes replacements, or at least requires large number of baskets/eggs to be a good approximation. Every good basket created decreases the probability that the next basket(s) will be good. For large numbers of eggs, say 50,000, is the non-replacement a big issue? Which distribution would allow me to calculate a confidence interval for the mean number of good baskets? Given that there are a large number of eggs (thousands), with known defect rate (around 1%) and fixed number of eggs per basket.",,['statistics']
3,Accuracy of distance and bearing between GPS locations,Accuracy of distance and bearing between GPS locations,,"I'm writing on an Android app that tracks the distance and bearing between two GPS location (each from a different device). Finding the mean distance and angle between the devices is quite easy, and seems to work well.  But since my locations are rather close, and I really need the results to be as reliable as possible, I'm also trying calculating the uncertainty of the calculations, and here I need some help. I'm using the accuracy parameter I get from android as my error estimation for the GPS readings (Android docs say this parameter gives a circular radius that the location has a 68% certainty to be within, so I assume the result is normally distributed, and that this parameter is the SD). I know how to officially calculate the propagated uncertainty (using partial derivatives) if I ignore the covariance (which I have no idea if I could even theoretically find) - But this gives me a tremendous uncertainty, since both GPS readings have a very large uncertainty. The thing is, all I'm looking for is the relative distance (or angle) between these location, and I don't care where they really are compared to earth. And since I know that at lest some of this uncertainty is the same for both devices (for instance, Ionospheric effects), I could safely ignore them and get much more precise results. Even better, if part of the uncertainty comes from random errors, I could filter most of it out even before comparing the locations (Although I suspect that that the location Android provides is already filtered). The thing is, I don't know what part of the uncertainty is random and what part is constant, and I obviously have to deal with them separately... So, to sum up my problem - given two sets of GPS reading, plus their 'accuracy' , how can I tell apart the uncertainty that is the same for both sets, from the part the varies between them? I'm sure there is a good mathematical way to do this, I just can't think of one...","I'm writing on an Android app that tracks the distance and bearing between two GPS location (each from a different device). Finding the mean distance and angle between the devices is quite easy, and seems to work well.  But since my locations are rather close, and I really need the results to be as reliable as possible, I'm also trying calculating the uncertainty of the calculations, and here I need some help. I'm using the accuracy parameter I get from android as my error estimation for the GPS readings (Android docs say this parameter gives a circular radius that the location has a 68% certainty to be within, so I assume the result is normally distributed, and that this parameter is the SD). I know how to officially calculate the propagated uncertainty (using partial derivatives) if I ignore the covariance (which I have no idea if I could even theoretically find) - But this gives me a tremendous uncertainty, since both GPS readings have a very large uncertainty. The thing is, all I'm looking for is the relative distance (or angle) between these location, and I don't care where they really are compared to earth. And since I know that at lest some of this uncertainty is the same for both devices (for instance, Ionospheric effects), I could safely ignore them and get much more precise results. Even better, if part of the uncertainty comes from random errors, I could filter most of it out even before comparing the locations (Although I suspect that that the location Android provides is already filtered). The thing is, I don't know what part of the uncertainty is random and what part is constant, and I obviously have to deal with them separately... So, to sum up my problem - given two sets of GPS reading, plus their 'accuracy' , how can I tell apart the uncertainty that is the same for both sets, from the part the varies between them? I'm sure there is a good mathematical way to do this, I just can't think of one...",,"['statistics', 'error-propagation']"
4,Can we ever have $E(\arg\!\min(f)) = \arg\!\min(E(f))$?,Can we ever have ?,E(\arg\!\min(f)) = \arg\!\min(E(f)),"Consider a parametric real-valued function $f_{\boldsymbol{\alpha}}: \mathbb D^N \to\mathbb R$ whose parameters $\boldsymbol\alpha$ vary according to some distribution $\psi$ , and $\mathbb D$ is either $\mathbb{R}$ or $\mathbb{Z}$ (i.e. reals or integers). Can we ever have that $\mathbb{E}_\psi \left(\underset{\mathbf{x}}{\arg\!\min}\; f_{\boldsymbol{\alpha}}(\mathbf{x})\right) = \underset{\mathbf{x}}{\arg\!\min} \; \mathbb E_\psi\left(f_{\boldsymbol{\alpha}}(\mathbf x)\right)$ for some choice of $\psi$ and/or $f$ ? I am particularly interested in convex programming problems, that is, when $f$ is convex and only defined within a convex region, and specifically in LP problems , when $f$ is also a linear function, but an answer for any $f$ would suffice. A stronger version of this question is when would we have LHS $=$ RHS in the Eq. above, but any examples of when LHS = RHS for a linear programming problem would already be very helpful.","Consider a parametric real-valued function whose parameters vary according to some distribution , and is either or (i.e. reals or integers). Can we ever have that for some choice of and/or ? I am particularly interested in convex programming problems, that is, when is convex and only defined within a convex region, and specifically in LP problems , when is also a linear function, but an answer for any would suffice. A stronger version of this question is when would we have LHS RHS in the Eq. above, but any examples of when LHS = RHS for a linear programming problem would already be very helpful.",f_{\boldsymbol{\alpha}}: \mathbb D^N \to\mathbb R \boldsymbol\alpha \psi \mathbb D \mathbb{R} \mathbb{Z} \mathbb{E}_\psi \left(\underset{\mathbf{x}}{\arg\!\min}\; f_{\boldsymbol{\alpha}}(\mathbf{x})\right) = \underset{\mathbf{x}}{\arg\!\min} \; \mathbb E_\psi\left(f_{\boldsymbol{\alpha}}(\mathbf x)\right) \psi f f f f =,"['statistics', 'functions', 'optimization', 'convex-optimization', 'linear-programming']"
5,Trying to show convergence (in probability) of integrals using Taylor expansion,Trying to show convergence (in probability) of integrals using Taylor expansion,,"I've been working for a long time now on how to prove a proposition given in a paper about the asymptotic normality of POT-quantile estimators. Hope somebody can help me out. Proposition (i) Let $X_1,\ldots,X_n$ be iid RV and $X_{1:n}\le\ldots \le X_{n:n}$ the corresponding order statistics. (ii) Let $k=k_n$ and $p=p_n$ be sequences in $\mathbb{R}_{\ge 0}$ with $k=k_n \xrightarrow[n \to \infty]{} \infty$, $\frac{k}{n}=\frac{k_n}{n}\xrightarrow[n \to \infty]{} 0$ and $\frac{k}{np}=\frac{k_n}{np_n} \xrightarrow[n \to \infty]{} \infty$ so that $\frac{\log\left( \frac{k}{np} \right) }{\sqrt{k}} \xrightarrow[n \to \infty]{} 0.$ (iii) Let $\widehat{\gamma_k}=\widehat{\gamma_{k_n}}(X_{n-k+1:n},\ldots,X_{n:n})$ be an estimator for some $\gamma \in \mathbb{R}$. ($\widehat{\gamma_k}$ is an estimator depending on the $k$ upper order statistics.) Assume that $G_k:=\sqrt{k}(\widehat{\gamma_k}-\gamma)\xrightarrow[n \to \infty]{d} G \sim N(\mu,\sigma^2)$. Then $$ (\ast) \quad \frac{\int_1^{\frac{k}{np}}s^{\widehat{\gamma_k}-1} \log s\, ds}{\int_1^{\frac{k}{np}}s^{\gamma-1} \log s\, ds} \xrightarrow[n \to \infty]{P} 1. $$ $\underline{\text{Hint given in the paper}}$: ""The proof is direct. It follows from Taylor expansions and the fact that $\widehat{\gamma_k}=\gamma+ \frac{G_k}{\sqrt{k}}$."" My ideas so far: Define $f(s)=s^{\frac{G_k}{\sqrt{k}}}$ Taylor expansion in $1$: $f(s)=1+f'(\xi_s)(s-1)=1+\frac{G_k}{\sqrt{k}} \xi_s^{\frac{G_k}{\sqrt{k}}-1}(s-1)$ for some $\xi_s \in (1,s).$  Then $$(\ast) = \frac{\int_1^{\frac{k}{np}}s^{\gamma-1} s^{\frac{G_k}{\sqrt{k}}} \log s\, ds}{\int_1^{\frac{k}{np}}s^{\gamma-1} \log s\, ds} = \frac{\int_1^{\frac{k}{np}}s^{\gamma-1} (1+\frac{G_k}{\sqrt{k}} \xi_s^{\frac{G_k}{\sqrt{k}}-1}(s-1)) \log s\, ds}{\int_1^{\frac{k}{np}}s^{\gamma-1} \log s\, ds}$$ $$=1+ \frac{\int_1^{\frac{k}{np}} s^{\gamma-1} \frac{G_k}{\sqrt{k}} \xi_s^{\frac{G_k}{\sqrt{k}}-1}(s-1) \log s\, ds}{\int_1^{\frac{k}{np}}s^{\gamma-1} \log s\, ds}=:1+(\ast \ast)$$ Need to show: $(\ast \ast) \xrightarrow[n \to \infty]{P} 0.$ It is $$(\ast \ast)\le G_k \frac{log\left( \frac{k}{np} \right) }{\sqrt{k}} \frac{\int_1^{\frac{k}{np}}s^{\gamma-1} \xi_s^{\frac{G_k}{\sqrt{k}}-1}(s-1) \, ds}{\int_1^{\frac{k}{np}}s^{\gamma-1} \log s\, ds}$$ and from the Slutsky theorem I know that $G_k \frac{\log\left( \frac{k}{np} \right) }{\sqrt{k}}\xrightarrow[n \to \infty ]{d}0. $ I haven't been able to work out what happens to the rest term, though. I know that $\frac{G_k}{\sqrt{k}}=\widehat{\gamma_k}-\gamma \xrightarrow[n\to \infty]{p} 0$ but not how fast in comparison to the interval $(1,s)$ that $\xi_k$ lies in (the upper limit of interval tends to $\infty$ with $n$ because $\frac{k}{np}$ does). Does anybody have an idea on how to solve this? The hint says ""Taylor expansion s "", so maybe I need one more to make it work? Thanks in advance!","I've been working for a long time now on how to prove a proposition given in a paper about the asymptotic normality of POT-quantile estimators. Hope somebody can help me out. Proposition (i) Let $X_1,\ldots,X_n$ be iid RV and $X_{1:n}\le\ldots \le X_{n:n}$ the corresponding order statistics. (ii) Let $k=k_n$ and $p=p_n$ be sequences in $\mathbb{R}_{\ge 0}$ with $k=k_n \xrightarrow[n \to \infty]{} \infty$, $\frac{k}{n}=\frac{k_n}{n}\xrightarrow[n \to \infty]{} 0$ and $\frac{k}{np}=\frac{k_n}{np_n} \xrightarrow[n \to \infty]{} \infty$ so that $\frac{\log\left( \frac{k}{np} \right) }{\sqrt{k}} \xrightarrow[n \to \infty]{} 0.$ (iii) Let $\widehat{\gamma_k}=\widehat{\gamma_{k_n}}(X_{n-k+1:n},\ldots,X_{n:n})$ be an estimator for some $\gamma \in \mathbb{R}$. ($\widehat{\gamma_k}$ is an estimator depending on the $k$ upper order statistics.) Assume that $G_k:=\sqrt{k}(\widehat{\gamma_k}-\gamma)\xrightarrow[n \to \infty]{d} G \sim N(\mu,\sigma^2)$. Then $$ (\ast) \quad \frac{\int_1^{\frac{k}{np}}s^{\widehat{\gamma_k}-1} \log s\, ds}{\int_1^{\frac{k}{np}}s^{\gamma-1} \log s\, ds} \xrightarrow[n \to \infty]{P} 1. $$ $\underline{\text{Hint given in the paper}}$: ""The proof is direct. It follows from Taylor expansions and the fact that $\widehat{\gamma_k}=\gamma+ \frac{G_k}{\sqrt{k}}$."" My ideas so far: Define $f(s)=s^{\frac{G_k}{\sqrt{k}}}$ Taylor expansion in $1$: $f(s)=1+f'(\xi_s)(s-1)=1+\frac{G_k}{\sqrt{k}} \xi_s^{\frac{G_k}{\sqrt{k}}-1}(s-1)$ for some $\xi_s \in (1,s).$  Then $$(\ast) = \frac{\int_1^{\frac{k}{np}}s^{\gamma-1} s^{\frac{G_k}{\sqrt{k}}} \log s\, ds}{\int_1^{\frac{k}{np}}s^{\gamma-1} \log s\, ds} = \frac{\int_1^{\frac{k}{np}}s^{\gamma-1} (1+\frac{G_k}{\sqrt{k}} \xi_s^{\frac{G_k}{\sqrt{k}}-1}(s-1)) \log s\, ds}{\int_1^{\frac{k}{np}}s^{\gamma-1} \log s\, ds}$$ $$=1+ \frac{\int_1^{\frac{k}{np}} s^{\gamma-1} \frac{G_k}{\sqrt{k}} \xi_s^{\frac{G_k}{\sqrt{k}}-1}(s-1) \log s\, ds}{\int_1^{\frac{k}{np}}s^{\gamma-1} \log s\, ds}=:1+(\ast \ast)$$ Need to show: $(\ast \ast) \xrightarrow[n \to \infty]{P} 0.$ It is $$(\ast \ast)\le G_k \frac{log\left( \frac{k}{np} \right) }{\sqrt{k}} \frac{\int_1^{\frac{k}{np}}s^{\gamma-1} \xi_s^{\frac{G_k}{\sqrt{k}}-1}(s-1) \, ds}{\int_1^{\frac{k}{np}}s^{\gamma-1} \log s\, ds}$$ and from the Slutsky theorem I know that $G_k \frac{\log\left( \frac{k}{np} \right) }{\sqrt{k}}\xrightarrow[n \to \infty ]{d}0. $ I haven't been able to work out what happens to the rest term, though. I know that $\frac{G_k}{\sqrt{k}}=\widehat{\gamma_k}-\gamma \xrightarrow[n\to \infty]{p} 0$ but not how fast in comparison to the interval $(1,s)$ that $\xi_k$ lies in (the upper limit of interval tends to $\infty$ with $n$ because $\frac{k}{np}$ does). Does anybody have an idea on how to solve this? The hint says ""Taylor expansion s "", so maybe I need one more to make it work? Thanks in advance!",,"['statistics', 'convergence-divergence', 'stochastic-processes', 'taylor-expansion', 'parameter-estimation']"
6,How does 2D kriging interpolation work?,How does 2D kriging interpolation work?,,"I have a grid of points Example x         80     82.5     85    87.5    90   y 5        0.5      1.6     1.7    1.7    2.3     2.5      1.6      1.7     1.8    2.1    2.7     0        2.4      2.3     2.6    3.0    3.8 and I want to be able to find any point for example point (81,4) What would I need to do to find this point using 2D kriging ? Could someone show me the mathematical steps to reach my value. Here is an Example of the Calculus behind 1d kriging http://www.climateneeds.umd.edu/pdf/EfficientKrigingforReal-Time.pdf","I have a grid of points Example x         80     82.5     85    87.5    90   y 5        0.5      1.6     1.7    1.7    2.3     2.5      1.6      1.7     1.8    2.1    2.7     0        2.4      2.3     2.6    3.0    3.8 and I want to be able to find any point for example point (81,4) What would I need to do to find this point using 2D kriging ? Could someone show me the mathematical steps to reach my value. Here is an Example of the Calculus behind 1d kriging http://www.climateneeds.umd.edu/pdf/EfficientKrigingforReal-Time.pdf",,"['statistics', 'interpolation', 'data-analysis', 'covariance']"
7,Necessary sample size for difference between means,Necessary sample size for difference between means,,"Not looking for a solution, just wonder what formula to use (and why?): Given population A and population B, where: standard deviation(A) = standard deviation(B) = $100$ If I select equal sample size N from A and B, how big does the sample size need to be to estimate the difference in population mean to within $10$ with 99% confidence? My attempt: If both of the population standard deviations are known, then the formula for a confidence interval for the difference between two population means (averages) is $\bar{x_1} - \bar{x_2} \pm z\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$ Where $\bar{x_1} - \bar{x_2}$ is the difference in the sample means. We know the sample sizes are the same: $n_1 = n_2 = N$ And the z value for 99% confidence level is 2.58, so: $\bar{x_1} - \bar{x_2} \pm 2.58\sqrt{\frac{100^2 +100^2}{N}}$ Is $\pm 2.58\sqrt{\frac{100^2 +100^2}{N}}$ the margin of error? Then solving: $10 = \pm 2.58\sqrt{\frac{100^2 +100^2}{N}}$ yields $N = 1331.28$. Am I on the right track here?","Not looking for a solution, just wonder what formula to use (and why?): Given population A and population B, where: standard deviation(A) = standard deviation(B) = $100$ If I select equal sample size N from A and B, how big does the sample size need to be to estimate the difference in population mean to within $10$ with 99% confidence? My attempt: If both of the population standard deviations are known, then the formula for a confidence interval for the difference between two population means (averages) is $\bar{x_1} - \bar{x_2} \pm z\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$ Where $\bar{x_1} - \bar{x_2}$ is the difference in the sample means. We know the sample sizes are the same: $n_1 = n_2 = N$ And the z value for 99% confidence level is 2.58, so: $\bar{x_1} - \bar{x_2} \pm 2.58\sqrt{\frac{100^2 +100^2}{N}}$ Is $\pm 2.58\sqrt{\frac{100^2 +100^2}{N}}$ the margin of error? Then solving: $10 = \pm 2.58\sqrt{\frac{100^2 +100^2}{N}}$ yields $N = 1331.28$. Am I on the right track here?",,['statistics']
8,Two independent Poisson processes.,Two independent Poisson processes.,,"I am trying to prove the result that exactly $k$ occurrences of a Poisson process before the first occurrence of another independent Poisson process is a geometric random variable. \begin{align} & P(k\text{ events of type }\lambda_1 \text{before first event of type } \lambda_2) P(\text{the next event is of type }\lambda_2) \\[6pt] = {} &\left( \int_0^\infty e^{-\lambda_1t}\frac{(\lambda_1t)^k}{k!}e^{-\lambda_2t}dt\right) (\frac{\lambda_2}{\lambda_1+\lambda_2}) \\[6pt] = {} & \frac{\lambda_1^{k}\lambda_2}{k!(\lambda_1+\lambda_2)} \int_0^\infty t^ke^{-(\lambda_1+\lambda_2)t} \, dt \\[6pt] = {} & \frac{\lambda_1^{k}\lambda_2}{k!(\lambda_1+\lambda_2)} . \frac{\Gamma(k+1)}{(\lambda_1+\lambda_2)^{k+1}} \\[6pt] = {} & \frac{\lambda_1^{k}\lambda_2}{(\lambda_1+\lambda_2)^{k+2}} \end{align} I cannot figure out why I am having an extra $(\lambda_1+\lambda_2)$ term in the denominator. Can someone please point out where I am going wrong? Thanks!","I am trying to prove the result that exactly $k$ occurrences of a Poisson process before the first occurrence of another independent Poisson process is a geometric random variable. \begin{align} & P(k\text{ events of type }\lambda_1 \text{before first event of type } \lambda_2) P(\text{the next event is of type }\lambda_2) \\[6pt] = {} &\left( \int_0^\infty e^{-\lambda_1t}\frac{(\lambda_1t)^k}{k!}e^{-\lambda_2t}dt\right) (\frac{\lambda_2}{\lambda_1+\lambda_2}) \\[6pt] = {} & \frac{\lambda_1^{k}\lambda_2}{k!(\lambda_1+\lambda_2)} \int_0^\infty t^ke^{-(\lambda_1+\lambda_2)t} \, dt \\[6pt] = {} & \frac{\lambda_1^{k}\lambda_2}{k!(\lambda_1+\lambda_2)} . \frac{\Gamma(k+1)}{(\lambda_1+\lambda_2)^{k+1}} \\[6pt] = {} & \frac{\lambda_1^{k}\lambda_2}{(\lambda_1+\lambda_2)^{k+2}} \end{align} I cannot figure out why I am having an extra $(\lambda_1+\lambda_2)$ term in the denominator. Can someone please point out where I am going wrong? Thanks!",,"['statistics', 'probability-distributions', 'stochastic-processes', 'poisson-distribution']"
9,Exponential distribution: Calculate $E(Y^a)$,Exponential distribution: Calculate,E(Y^a),"For a Gamma distribution where $Y\sim \mathrm{Gamma}(\alpha, \beta)$ we have $$f(y)=\frac{y^{\alpha -1}e^{-y/\beta}}{\beta^{\alpha} \Gamma(\alpha)}$$ The question is, given that random variable $Y \sim \textrm{Expo}(\beta)$, derive a closed-form expression for $E[Y^a].$ An exponential distribution with parameter $\beta$ is simply a Gamma distribution with $\alpha = 1$. The answer is $\beta^a\Gamma(a+1)$. But how may I reach this answer? Thank you very much. The solution is as follows. Update: Thanks Robin. I think I forgot about the following fact. The problem should be solved now. Thank you very much!","For a Gamma distribution where $Y\sim \mathrm{Gamma}(\alpha, \beta)$ we have $$f(y)=\frac{y^{\alpha -1}e^{-y/\beta}}{\beta^{\alpha} \Gamma(\alpha)}$$ The question is, given that random variable $Y \sim \textrm{Expo}(\beta)$, derive a closed-form expression for $E[Y^a].$ An exponential distribution with parameter $\beta$ is simply a Gamma distribution with $\alpha = 1$. The answer is $\beta^a\Gamma(a+1)$. But how may I reach this answer? Thank you very much. The solution is as follows. Update: Thanks Robin. I think I forgot about the following fact. The problem should be solved now. Thank you very much!",,['statistics']
10,Uni-variate Moving Average Theta coefficients,Uni-variate Moving Average Theta coefficients,,"Consider the Uni-variate Moving Average Models (MA models) MA(1)  $$x_t = \mu + w_t +\theta_1w_{t-1}$$ or the second order moving average MA(2)  $$x_t = \mu + w_t +\theta_1w_{t-1}+\theta_2w_{t-2}$$ or the The qth order moving average model, denoted by MA(q) is $$ x_t = \mu + w_t +\theta_1w_{t-1}+\theta_2w_{t-2}+\dots + \theta_qw_{t-q} $$ Am trying to understand how the coefficient $$\theta_1,\theta_2,...\theta_q$$ are calculated? Can someone help me on this how to calculate the theta coefficient for an Uni variate  MA process? Sometimes I see examples like this xt = 10 + wt + .7wt-1, where Theta = 0.7 for an MA(1) process, am not sure how was this calculated? Thanks,Kamal.","Consider the Uni-variate Moving Average Models (MA models) MA(1)  $$x_t = \mu + w_t +\theta_1w_{t-1}$$ or the second order moving average MA(2)  $$x_t = \mu + w_t +\theta_1w_{t-1}+\theta_2w_{t-2}$$ or the The qth order moving average model, denoted by MA(q) is $$ x_t = \mu + w_t +\theta_1w_{t-1}+\theta_2w_{t-2}+\dots + \theta_qw_{t-q} $$ Am trying to understand how the coefficient $$\theta_1,\theta_2,...\theta_q$$ are calculated? Can someone help me on this how to calculate the theta coefficient for an Uni variate  MA process? Sometimes I see examples like this xt = 10 + wt + .7wt-1, where Theta = 0.7 for an MA(1) process, am not sure how was this calculated? Thanks,Kamal.",,"['linear-algebra', 'statistics', 'regression', 'time-series']"
11,How do you calculate randomness?,How do you calculate randomness?,,"Suppose I receive a list of 1 million coinflips, and I want to know how likely it is that the list was randomly generated. My first thought would be to count the number of heads and tails, which should be evenly distributed (around 500.000). But suppose the distribution looks normal, its still possible the list contains patterns or repititions. For example, the first half of the list may be the heads, and the last half the tails. In real random data, that would be highly unlikely. So how do you calculate the 'randomness' of this list?","Suppose I receive a list of 1 million coinflips, and I want to know how likely it is that the list was randomly generated. My first thought would be to count the number of heads and tails, which should be evenly distributed (around 500.000). But suppose the distribution looks normal, its still possible the list contains patterns or repititions. For example, the first half of the list may be the heads, and the last half the tails. In real random data, that would be highly unlikely. So how do you calculate the 'randomness' of this list?",,"['statistics', 'random']"
12,Independent set of points in a square.,Independent set of points in a square.,,"Suppose I select points uniformly at random in $[0,1]^{2}$ and two points share an edge if their euclidean distance is less than $r$. Suppose I have $n$ points $v_{1},v_{2},...,v_{n}$ selected in this way, how could I compute the probability that they are all independent given that $1<m<n$ of them are? One way would be to cover the $m$ points with circles of radius $r$ and calculate the probability that the remaining $n-m$ points form an independent set in a region outside that covered by the circles, but you would need to know how much area is covered in the first place which seems difficult to calculate.","Suppose I select points uniformly at random in $[0,1]^{2}$ and two points share an edge if their euclidean distance is less than $r$. Suppose I have $n$ points $v_{1},v_{2},...,v_{n}$ selected in this way, how could I compute the probability that they are all independent given that $1<m<n$ of them are? One way would be to cover the $m$ points with circles of radius $r$ and calculate the probability that the remaining $n-m$ points form an independent set in a region outside that covered by the circles, but you would need to know how much area is covered in the first place which seems difficult to calculate.",,"['probability', 'combinatorics', 'geometry', 'statistics']"
13,Probability of random assignment to form pairs,Probability of random assignment to form pairs,,"So the question goes: I have 100 individuals and 100 different buses, and I randomly assigned each individual to sit on a bus (each bus has equal probability of being selected). How many buses are expected to be empty at the end of assignment? What type of question is this? Does it have a particular name? Also - how does it differ from calculating how many pairs of people will be sitting on the same bus? E.g. 2 people on a bus = 1 pair, 3 people on a bus is 3 pairs.","So the question goes: I have 100 individuals and 100 different buses, and I randomly assigned each individual to sit on a bus (each bus has equal probability of being selected). How many buses are expected to be empty at the end of assignment? What type of question is this? Does it have a particular name? Also - how does it differ from calculating how many pairs of people will be sitting on the same bus? E.g. 2 people on a bus = 1 pair, 3 people on a bus is 3 pairs.",,"['probability', 'statistics', 'random-variables', 'random']"
14,Summation of series $\sum_{k=0}^\infty 2^k/\binom{2k+1}{k}$,Summation of series,\sum_{k=0}^\infty 2^k/\binom{2k+1}{k},"How to find the sum of this series?  $$\sum_{k=0}^{\infty}\cfrac{{2}^{k}}{\binom{2k+1}{k}}$$ It seems very easy. But I still can not work it out, can anyone help?","How to find the sum of this series?  $$\sum_{k=0}^{\infty}\cfrac{{2}^{k}}{\binom{2k+1}{k}}$$ It seems very easy. But I still can not work it out, can anyone help?",,"['sequences-and-series', 'summation', 'combinations']"
15,Board Game Score Calculation Suggestions?,Board Game Score Calculation Suggestions?,,"My coworkers and I play board games at lunch.  We've taken it so seriously that I've written an application to calculate a ""player score"" based on how you place in each game played. Here's how it currently works: (Positions - Placement) / (Positions - 1) = Score where Placement is 1st == 1, 2nd == 2, 3rd == 3, etc... and Positions is how many people were playing the game. 4 Man Game Scoring Example  Position  Calculation  Score 1st       (4-1)/(4-1)  1.000 2nd       (4-2)/(4-1)  0.667 3rd       (4-3)/(4-1)  0.333 4th       (4-4)/(4-1)  0.000 Now that that's all figured out, you take your average for all the games played and away you go. While there may be other issues, the primary concern is that we've had to put a ""Minimum Games"" requirement when going for the season trophy because if you win a single game, you stand with a solid 1.000 score and if you lose your only game, you sit with 0.000. We've considered various ways of creating ""bonuses"" for playing numerous games but nailing that magic number is a hard thing to do.  Doing a traditional ELO doesn't appear to be sufficient because it's not 1v1. If there's anyone with a suggestion as to how to do it better, I'm all ears.  And my apologies if this is the wrong forum.  The board & card games one didn't feel totally right. Thanks in advance - Hugh","My coworkers and I play board games at lunch.  We've taken it so seriously that I've written an application to calculate a ""player score"" based on how you place in each game played. Here's how it currently works: (Positions - Placement) / (Positions - 1) = Score where Placement is 1st == 1, 2nd == 2, 3rd == 3, etc... and Positions is how many people were playing the game. 4 Man Game Scoring Example  Position  Calculation  Score 1st       (4-1)/(4-1)  1.000 2nd       (4-2)/(4-1)  0.667 3rd       (4-3)/(4-1)  0.333 4th       (4-4)/(4-1)  0.000 Now that that's all figured out, you take your average for all the games played and away you go. While there may be other issues, the primary concern is that we've had to put a ""Minimum Games"" requirement when going for the season trophy because if you win a single game, you stand with a solid 1.000 score and if you lose your only game, you sit with 0.000. We've considered various ways of creating ""bonuses"" for playing numerous games but nailing that magic number is a hard thing to do.  Doing a traditional ELO doesn't appear to be sufficient because it's not 1v1. If there's anyone with a suggestion as to how to do it better, I'm all ears.  And my apologies if this is the wrong forum.  The board & card games one didn't feel totally right. Thanks in advance - Hugh",,"['statistics', 'scoring-algorithm']"
16,Definition of Time Series,Definition of Time Series,,"Having not done any stats for a few years, I seek clarification regarding the definition of time series given in my textbook. I apologize for the length, but I would be glad to just resolve my main concern (so feel free to ignore my secondary concern). Background: To begin with, a stochastic process is a family of time-indexed random variables $X(\omega, t)$, where $w$ belongs to a sample space and $t$ belongs to an index set. For a given observation $\omega$, $X_{\omega}(t)$ is a function of $t$, which is called a realization of the stochastic process. Definition: A time series is a realization from a certain stochastic process. Main Concern: Does the definition imply that a time series is a single function (the realization of a stochastic process, corresponding to some fixed outcome $\omega$), or is a time series an assignment of time-dependent functions to each element $\omega$ in the sample space $\Omega$? In other words, we define a realization of a stochastic process relative to some fixed element $\omega \in \Omega$. But then is a time series the collection of realizations for each $\omega \in \Omega$, or just a realization for a single outcome? Secondary Concern: Regarding stationary time series, my textbook writes that the exact values of the mean, variance, autocorrelation, and partial autocorrelation parameters ""can be calculated if the ensemble of all possible realizations is known. Otherwise, they can be estimated if multiple independent realizations are available."" The ensemble was defined as the collection of all possible realizations in a stochastic process. In light of the authors comments above, this makes me question whether the ensemble refers to the collection of realizations corresponding to each $\omega \in \Omega$ or if, rather, the ensemble consists of all possible realizations for each $\omega \in \Omega$. The way it is defined makes me suspect the latter, but then I don't see how this information would relevant towards determining the above parameters.","Having not done any stats for a few years, I seek clarification regarding the definition of time series given in my textbook. I apologize for the length, but I would be glad to just resolve my main concern (so feel free to ignore my secondary concern). Background: To begin with, a stochastic process is a family of time-indexed random variables $X(\omega, t)$, where $w$ belongs to a sample space and $t$ belongs to an index set. For a given observation $\omega$, $X_{\omega}(t)$ is a function of $t$, which is called a realization of the stochastic process. Definition: A time series is a realization from a certain stochastic process. Main Concern: Does the definition imply that a time series is a single function (the realization of a stochastic process, corresponding to some fixed outcome $\omega$), or is a time series an assignment of time-dependent functions to each element $\omega$ in the sample space $\Omega$? In other words, we define a realization of a stochastic process relative to some fixed element $\omega \in \Omega$. But then is a time series the collection of realizations for each $\omega \in \Omega$, or just a realization for a single outcome? Secondary Concern: Regarding stationary time series, my textbook writes that the exact values of the mean, variance, autocorrelation, and partial autocorrelation parameters ""can be calculated if the ensemble of all possible realizations is known. Otherwise, they can be estimated if multiple independent realizations are available."" The ensemble was defined as the collection of all possible realizations in a stochastic process. In light of the authors comments above, this makes me question whether the ensemble refers to the collection of realizations corresponding to each $\omega \in \Omega$ or if, rather, the ensemble consists of all possible realizations for each $\omega \in \Omega$. The way it is defined makes me suspect the latter, but then I don't see how this information would relevant towards determining the above parameters.",,"['statistics', 'stochastic-processes', 'time-series']"
17,Expectation and convolution question.,Expectation and convolution question.,,"I am learning in an image processing course, and the professor did the following: As part of a derivation, has this: What I do not understand, is how he was able to remove $r(i,j)$ to the 'outside'. I understand that it can be removed to the outside of the expectation since it is deterministic. What I do not understand is how he is able to remove it from the convolution. TLDR: How did we go from $\mathbb{E}\Big[ \big[y(i,j) \star r(i,j) \big] y^*(i,j) \Big]$, to this: $r(i,j) \star \mathbb{E}\Big[ y(i,j) \ y^*(i,j) \Big]$ ? Thanks.","I am learning in an image processing course, and the professor did the following: As part of a derivation, has this: What I do not understand, is how he was able to remove $r(i,j)$ to the 'outside'. I understand that it can be removed to the outside of the expectation since it is deterministic. What I do not understand is how he is able to remove it from the convolution. TLDR: How did we go from $\mathbb{E}\Big[ \big[y(i,j) \star r(i,j) \big] y^*(i,j) \Big]$, to this: $r(i,j) \star \mathbb{E}\Big[ y(i,j) \ y^*(i,j) \Big]$ ? Thanks.",,"['statistics', 'expectation', 'convolution', 'signal-processing', 'correlation']"
18,Looking to assign percentage contribution among 4 variables in a simple equation,Looking to assign percentage contribution among 4 variables in a simple equation,,"I have a seemingly simple problem, that is giving me some trouble in solving. I have a 4 variable equation and want to determine the contribution of each variable in moving the dependent variable from time $t_0$ to time $t_1$. The equation looks like: $y = a\cdot\frac{b}{c}\cdot d$ I need to assign a percentage of each variable (totaling to 100%) responsible for the change in $Y$. $$ \begin{align} t_0 &: -0.4\cdot\frac{205,000}{640}\cdot 0.6 = -76\\ t_1 &: 3.94\cdot\frac{916,000}{320}\cdot 1.85 = 20,864 \end{align} $$ There is a total delta of $20,940$, and I need to assign a percentage of ""responsibility"" for this delta among the four variables changing. My approach was to ""take away"" each of the variable changes individually, then add up the resulting deltas and simply take each delta from each individual X and divide by the sum of the deltas to determine percentage. As I worked it out, I get $a = 36\%, b = 16\%, c = 22\%,  d = 25\%$ It's a very simple sensitivity analysis, but I really don't have theoretical backup. Is there a better way that I am missing?","I have a seemingly simple problem, that is giving me some trouble in solving. I have a 4 variable equation and want to determine the contribution of each variable in moving the dependent variable from time $t_0$ to time $t_1$. The equation looks like: $y = a\cdot\frac{b}{c}\cdot d$ I need to assign a percentage of each variable (totaling to 100%) responsible for the change in $Y$. $$ \begin{align} t_0 &: -0.4\cdot\frac{205,000}{640}\cdot 0.6 = -76\\ t_1 &: 3.94\cdot\frac{916,000}{320}\cdot 1.85 = 20,864 \end{align} $$ There is a total delta of $20,940$, and I need to assign a percentage of ""responsibility"" for this delta among the four variables changing. My approach was to ""take away"" each of the variable changes individually, then add up the resulting deltas and simply take each delta from each individual X and divide by the sum of the deltas to determine percentage. As I worked it out, I get $a = 36\%, b = 16\%, c = 22\%,  d = 25\%$ It's a very simple sensitivity analysis, but I really don't have theoretical backup. Is there a better way that I am missing?",,"['statistics', 'applications']"
19,Normal Approximation to Binomial Distribution using Moment Generating Functions,Normal Approximation to Binomial Distribution using Moment Generating Functions,,"We're told not to use the central limit theorem to show that the normal approximation is suitable for a binomial distribution when n tends to infinity. I've managed to show the answer, but it involves some messy infinite series. Eg: $$M_Z(T) = M_{\frac{X-\mu}{\sigma}} = e^{-\frac{t\mu}{\sigma}}[1 + \theta(e^{\frac{t}{\sigma}} - 1]^n$$ $$ \mu =  n\theta \ and \ \sigma = \sqrt{n\theta(1-\theta)}$$ Then without putting it all here, I take logarithms, use the infinite series of $ e^{\frac{t}{\sigma}}$ and then the infinite series of $ln(1+x)$, collect some terms and show that a lot tend to zero as n tends to infinity, leaving us with the Normal MGF. It's quite ugly, and I'm wondering if there is a clearer method (but still using MGFs)?","We're told not to use the central limit theorem to show that the normal approximation is suitable for a binomial distribution when n tends to infinity. I've managed to show the answer, but it involves some messy infinite series. Eg: $$M_Z(T) = M_{\frac{X-\mu}{\sigma}} = e^{-\frac{t\mu}{\sigma}}[1 + \theta(e^{\frac{t}{\sigma}} - 1]^n$$ $$ \mu =  n\theta \ and \ \sigma = \sqrt{n\theta(1-\theta)}$$ Then without putting it all here, I take logarithms, use the infinite series of $ e^{\frac{t}{\sigma}}$ and then the infinite series of $ln(1+x)$, collect some terms and show that a lot tend to zero as n tends to infinity, leaving us with the Normal MGF. It's quite ugly, and I'm wondering if there is a clearer method (but still using MGFs)?",,"['statistics', 'moment-generating-functions']"
20,"Linear regression, reversing it back then.","Linear regression, reversing it back then.",,"Need's formatting, editing will take some time.","Need's formatting, editing will take some time.",,"['statistics', 'logic']"
21,Find spikes in data,Find spikes in data,,"I have some datasets and I need to find spikes in them. Imagine the data looks like trading data. If the spike is big enough, I need to log it, otherwise, proceed in the analysis. I tried with a moving average approach, but cannot detect all of them. Is there a better way? Also, I would like to know if there is a robust approach to calculating the baseline, so I can filter it out.","I have some datasets and I need to find spikes in them. Imagine the data looks like trading data. If the spike is big enough, I need to log it, otherwise, proceed in the analysis. I tried with a moving average approach, but cannot detect all of them. Is there a better way? Also, I would like to know if there is a robust approach to calculating the baseline, so I can filter it out.",,"['statistics', 'average', 'data-analysis']"
22,Is this method to find mean already discovered?,Is this method to find mean already discovered?,,"I am a 10th class student and in our syllabus, we have three methods for finding mean of grouped data: Direct method. Assumed mean method. Step deviation method. Out of these, the Step deviation method is the simplest but still requires a lot of calculations. In the step-deviation method, you have to first find class mark ($x_i$), subtract some number ($a$) from all of them to get $d_i$ and then divide them all by some number ($h$) to get $u_i$, and then use a formula to get mean. After doing some of the excercises, I noticed that in most of the questions, the values of ui were ...,-2,-1,0,1,2,... etc., so I made this method. Suppose this is the data: $$\begin{array}{c|cc} i & \text{CI} & f_i \\\hline 1 & 1-3 & 1\\ 2 & 3-5 & 2\\ 3 & 5-7 & 2\\ 4 & 7-9 & 1\\ \end{array}$$ Let $m=$ the class number with the largest $f_i$. (It doesn't matter which number you choose but it will be easy in this way). $\qquad\therefore \qquad m=3$. Set $k_i = m-i$. $$\begin{array}{c|cc|c} i & \text{CI} & f_i & k_i \\\hline 1 & 1-3 & 1 & 2\\ 2 & 3-5 & 2 & 1\\ 3 & 5-7 & 2 & 0\\ 4 & 7-9 & 1 & -1\\ \end{array}$$ Let Mean of $kf = \bar k$, that is, $\bar k = \frac{\displaystyle \Sigma f_ik_i}{\displaystyle  \Sigma f_i }$ $$\begin{array}{c|cc|c|c} i & \text{CI} & f_i & k_i&f_ik_i \\\hline 1 & 1-3 & 1 & 2 & 2\\ 2 & 3-5 & 2 & 1 & 2\\ 3 & 5-7 & 2 & 0 & 0\\ 4 & 7-9 & 1 & -1&-1\\\hline &&\Sigma f_i = 6&&\Sigma f_ik_i=3 \end{array}$$$$\therefore\qquad\bar k=\frac12$$ Use this formula which I discovered: $$\bar x = -h\bar k+l+hm-\frac h2$$ (where $h$ is class size and $l$ is lower limit of the first class) $$\therefore\qquad\bar x = -2\times\frac12+1+2\times 3-\frac22=5$$ Which is the correct answer. Now the question is Has this method been dicovered earlier? What do we call it? If it has been dicovered earlier, then why do they still teach us so complicated methods in school? (As we all know, math is ungooglable.)","I am a 10th class student and in our syllabus, we have three methods for finding mean of grouped data: Direct method. Assumed mean method. Step deviation method. Out of these, the Step deviation method is the simplest but still requires a lot of calculations. In the step-deviation method, you have to first find class mark ($x_i$), subtract some number ($a$) from all of them to get $d_i$ and then divide them all by some number ($h$) to get $u_i$, and then use a formula to get mean. After doing some of the excercises, I noticed that in most of the questions, the values of ui were ...,-2,-1,0,1,2,... etc., so I made this method. Suppose this is the data: $$\begin{array}{c|cc} i & \text{CI} & f_i \\\hline 1 & 1-3 & 1\\ 2 & 3-5 & 2\\ 3 & 5-7 & 2\\ 4 & 7-9 & 1\\ \end{array}$$ Let $m=$ the class number with the largest $f_i$. (It doesn't matter which number you choose but it will be easy in this way). $\qquad\therefore \qquad m=3$. Set $k_i = m-i$. $$\begin{array}{c|cc|c} i & \text{CI} & f_i & k_i \\\hline 1 & 1-3 & 1 & 2\\ 2 & 3-5 & 2 & 1\\ 3 & 5-7 & 2 & 0\\ 4 & 7-9 & 1 & -1\\ \end{array}$$ Let Mean of $kf = \bar k$, that is, $\bar k = \frac{\displaystyle \Sigma f_ik_i}{\displaystyle  \Sigma f_i }$ $$\begin{array}{c|cc|c|c} i & \text{CI} & f_i & k_i&f_ik_i \\\hline 1 & 1-3 & 1 & 2 & 2\\ 2 & 3-5 & 2 & 1 & 2\\ 3 & 5-7 & 2 & 0 & 0\\ 4 & 7-9 & 1 & -1&-1\\\hline &&\Sigma f_i = 6&&\Sigma f_ik_i=3 \end{array}$$$$\therefore\qquad\bar k=\frac12$$ Use this formula which I discovered: $$\bar x = -h\bar k+l+hm-\frac h2$$ (where $h$ is class size and $l$ is lower limit of the first class) $$\therefore\qquad\bar x = -2\times\frac12+1+2\times 3-\frac22=5$$ Which is the correct answer. Now the question is Has this method been dicovered earlier? What do we call it? If it has been dicovered earlier, then why do they still teach us so complicated methods in school? (As we all know, math is ungooglable.)",,['statistics']
23,Combining confidence intervals for sums of generic random variables,Combining confidence intervals for sums of generic random variables,,"So my fiancee is a civil servant and asked me for help with the following problem. She has been given a collection of upper and lower bounds on expenditure for a collection of projects like: Project A: 2 million- 70 million Project B: 55 million to 60 million and so on... She wants to provide a suitable interval for probable total expenditure. Now the obvious technique is to just add up the upper bounds and add up the lower bounds, but a lot of the ranges are huge and there's over 300 projects- so this gives something like: 65 million-700 million This is obviously rubbish in the sense that both of the extremes are incredibly unlikely, and the upper bound differs from the lower by a factor of 10. Her colleagues have variously suggested narrowing the bounds in cases where they are less likely (which strikes me as very bad for birthday paradox type reasons), and to do something my fiancee remembers as being called 'Optimisation Bias', which google has never heard of. After some thought, it struck me that modelling these as gaussians, you can translate pretty easily from confidence interval to standard deviation and then back after some playing, that is: If $r_i:=\max(X_i)-\min(X_i)$ And we pretend $r_i=Z_i\sigma_i$ then $R:=\sqrt{\Sigma r_i^2}=\sqrt{\Sigma Z_i^2 \sigma_i^2} \geq \min_i Z_i \sigma$ (where $\sigma$ is the s.d. of the sum) So you get a confidence interval with at least the confidence level of at least that of the 'least confident variable', which you can put either side of your expected value to get a much reduced interval. But when you don't assume normality, you need to start playing with Chebychev-type inequalities to translate between confidence and s.d., and the sheer variety of these makes my head hurt, and after some mucking around with the tamer ones trying to get a theoretical bound on the confidence level of the resulting interval, I've decided it's time to ask the internet. So my questions: First, this seems like a common problem, is there a current consensus on best practice here, possibly using a totally different approach? ('Optimisation Bias' perhaps?!?!?) Second, and this is just out of interest for me really, if one prats about with inequalities for long enough, does a sensible bound for confidence emerge for the 'square-sum-square-root interval' I've concocted if the distribution is generic? What about if we say bounded-positive? Unimodal?","So my fiancee is a civil servant and asked me for help with the following problem. She has been given a collection of upper and lower bounds on expenditure for a collection of projects like: Project A: 2 million- 70 million Project B: 55 million to 60 million and so on... She wants to provide a suitable interval for probable total expenditure. Now the obvious technique is to just add up the upper bounds and add up the lower bounds, but a lot of the ranges are huge and there's over 300 projects- so this gives something like: 65 million-700 million This is obviously rubbish in the sense that both of the extremes are incredibly unlikely, and the upper bound differs from the lower by a factor of 10. Her colleagues have variously suggested narrowing the bounds in cases where they are less likely (which strikes me as very bad for birthday paradox type reasons), and to do something my fiancee remembers as being called 'Optimisation Bias', which google has never heard of. After some thought, it struck me that modelling these as gaussians, you can translate pretty easily from confidence interval to standard deviation and then back after some playing, that is: If And we pretend then (where is the s.d. of the sum) So you get a confidence interval with at least the confidence level of at least that of the 'least confident variable', which you can put either side of your expected value to get a much reduced interval. But when you don't assume normality, you need to start playing with Chebychev-type inequalities to translate between confidence and s.d., and the sheer variety of these makes my head hurt, and after some mucking around with the tamer ones trying to get a theoretical bound on the confidence level of the resulting interval, I've decided it's time to ask the internet. So my questions: First, this seems like a common problem, is there a current consensus on best practice here, possibly using a totally different approach? ('Optimisation Bias' perhaps?!?!?) Second, and this is just out of interest for me really, if one prats about with inequalities for long enough, does a sensible bound for confidence emerge for the 'square-sum-square-root interval' I've concocted if the distribution is generic? What about if we say bounded-positive? Unimodal?",r_i:=\max(X_i)-\min(X_i) r_i=Z_i\sigma_i R:=\sqrt{\Sigma r_i^2}=\sqrt{\Sigma Z_i^2 \sigma_i^2} \geq \min_i Z_i \sigma \sigma,"['statistics', 'probability-distributions']"
24,Expected value versus mean value,Expected value versus mean value,,What is the difference between the expected value and mean value of a discrete random variable or discrete uniform distribution?,What is the difference between the expected value and mean value of a discrete random variable or discrete uniform distribution?,,['statistics']
25,Is the maximum-likelihood estimation notation formally correct?,Is the maximum-likelihood estimation notation formally correct?,,"I just saw from the Wikipedia's entry on Maximum likelihood, http://en.wikipedia.org/wiki/Maximum_likelihood , the formula $\mathcal{L}(\theta\,|\,x_1,\ldots,x_n) = f(x_1,x_2,\ldots,x_n\;|\;\theta) = \prod_{i=1}^n f(x_i|\theta).$ Could someone explain if this is formally correct? I mean, I haven't seen the definition of vertical bar in the function parameters and I feel that the mapping $f$ suddenly changes from $\mathbb{R}^n\to \mathbb{R}$ (or maybe $\mathbb{R}^{n+1}\to \mathbb{R}$) to $\mathbb{R}\to\mathbb{R}$ or $\mathbb{R}^2\to\mathbb{R}$.","I just saw from the Wikipedia's entry on Maximum likelihood, http://en.wikipedia.org/wiki/Maximum_likelihood , the formula $\mathcal{L}(\theta\,|\,x_1,\ldots,x_n) = f(x_1,x_2,\ldots,x_n\;|\;\theta) = \prod_{i=1}^n f(x_i|\theta).$ Could someone explain if this is formally correct? I mean, I haven't seen the definition of vertical bar in the function parameters and I feel that the mapping $f$ suddenly changes from $\mathbb{R}^n\to \mathbb{R}$ (or maybe $\mathbb{R}^{n+1}\to \mathbb{R}$) to $\mathbb{R}\to\mathbb{R}$ or $\mathbb{R}^2\to\mathbb{R}$.",,"['statistics', 'notation']"
26,Sum of Random Distributions/ Unusual Results,Sum of Random Distributions/ Unusual Results,,"$$X \sim N(\mu_1,\sigma_1^2)$$ $$Y \sim N(\mu_2,\sigma_2^2)$$ then  $$X+Y \sim N(0,\sigma_1^2+\sigma_2^2)$$ One way, I tested this to be true is in excel, I used the norm.inv(rand(),0,1) and created an array of 1000 rows/data points. X            Y 1   -0.57306826      0.516810296 2   -0.209113627     0.191298912 3   -1.399749083    -1.195672984 4   1.317783869     0.003841951 5   1.800761285     0.866364269 6   1.259689933     -0.985409706 7   -0.501198314    1.799725917 8   0.209555354     -0.258582777 9   -0.744123211    0.738373998 10  0.595194985     -0.653501771 Then I summed $X$ and $Y$ and then took the average of the two columns and I indeed got a mean of 0, ($\mu_{x+y}=0$)  and a standard deviation ($\sigma_{x+y}=2$). So I said, perfect!! But then an idea occurred to me. What if started from an initial standard normal value, and then summed another and added it to the former as such, in other words, reiteravily adding normal values. $X_t=X_{t-1}+X_{t-2}$ , where each $X \sim N(0,1)$ In excel format, 1   0 2   =NORM.INV(RAND(),0,1)+A1 3   =NORM.INV(RAND(),0,1)+A2 4   =NORM.INV(RAND(),0,1)+A3 5   =NORM.INV(RAND(),0,1)+A4 6   =NORM.INV(RAND(),0,1)+A5 7   =NORM.INV(RAND(),0,1)+A6 8   =NORM.INV(RAND(),0,1)+A7 9   =NORM.INV(RAND(),0,1)+A8 10  =NORM.INV(RAND(),0,1)+A9 Using this approach, when I averaged the entire column of 1000 data points, my mean wasn't zero and my variance also wasn't $1000$ as I had expected. What gives? The variance never equaled 1000 throughout all the simulations of random numbers. Theoretically, my $E(\sum_1^nX_t)=0$ and the Variance $Var(\sum_1^nX_t)=n\cdot1$","$$X \sim N(\mu_1,\sigma_1^2)$$ $$Y \sim N(\mu_2,\sigma_2^2)$$ then  $$X+Y \sim N(0,\sigma_1^2+\sigma_2^2)$$ One way, I tested this to be true is in excel, I used the norm.inv(rand(),0,1) and created an array of 1000 rows/data points. X            Y 1   -0.57306826      0.516810296 2   -0.209113627     0.191298912 3   -1.399749083    -1.195672984 4   1.317783869     0.003841951 5   1.800761285     0.866364269 6   1.259689933     -0.985409706 7   -0.501198314    1.799725917 8   0.209555354     -0.258582777 9   -0.744123211    0.738373998 10  0.595194985     -0.653501771 Then I summed $X$ and $Y$ and then took the average of the two columns and I indeed got a mean of 0, ($\mu_{x+y}=0$)  and a standard deviation ($\sigma_{x+y}=2$). So I said, perfect!! But then an idea occurred to me. What if started from an initial standard normal value, and then summed another and added it to the former as such, in other words, reiteravily adding normal values. $X_t=X_{t-1}+X_{t-2}$ , where each $X \sim N(0,1)$ In excel format, 1   0 2   =NORM.INV(RAND(),0,1)+A1 3   =NORM.INV(RAND(),0,1)+A2 4   =NORM.INV(RAND(),0,1)+A3 5   =NORM.INV(RAND(),0,1)+A4 6   =NORM.INV(RAND(),0,1)+A5 7   =NORM.INV(RAND(),0,1)+A6 8   =NORM.INV(RAND(),0,1)+A7 9   =NORM.INV(RAND(),0,1)+A8 10  =NORM.INV(RAND(),0,1)+A9 Using this approach, when I averaged the entire column of 1000 data points, my mean wasn't zero and my variance also wasn't $1000$ as I had expected. What gives? The variance never equaled 1000 throughout all the simulations of random numbers. Theoretically, my $E(\sum_1^nX_t)=0$ and the Variance $Var(\sum_1^nX_t)=n\cdot1$",,"['probability', 'statistics']"
27,"Repeated sampling with replacement, increasing probability","Repeated sampling with replacement, increasing probability",,"I would appreciate help with the following problem, since I can't quite figure out the effect an increasing number of trials has on probability: Suppose a bin has white marbles and black marbles. Say the probability of choosing a black marble is $P(B) = \beta$. Each experiment consists of taking 5 marbles from this bin. Certainly, the probability that we get no black marbles from one experiment is $(1-\beta)^5$. Question: If we repeat this experiment of 5 marbles at a time, with replacement, $N$ times then what is the probability that at least one of our $N$ experiments consists of no black marbles (i.e. at least one of our selections is exactly 5 white marbles)? Also, how does this probability grow with $N$? References, e.g. books or online notes, addressing this theme would also be appreciated!","I would appreciate help with the following problem, since I can't quite figure out the effect an increasing number of trials has on probability: Suppose a bin has white marbles and black marbles. Say the probability of choosing a black marble is $P(B) = \beta$. Each experiment consists of taking 5 marbles from this bin. Certainly, the probability that we get no black marbles from one experiment is $(1-\beta)^5$. Question: If we repeat this experiment of 5 marbles at a time, with replacement, $N$ times then what is the probability that at least one of our $N$ experiments consists of no black marbles (i.e. at least one of our selections is exactly 5 white marbles)? Also, how does this probability grow with $N$? References, e.g. books or online notes, addressing this theme would also be appreciated!",,"['probability', 'statistics']"
28,Best closed convex surface fitting N points in 3D,Best closed convex surface fitting N points in 3D,,"First. It's easier to understand the problem by describing the application where it arises from. We have a convex body $B$ in $\mathbb{R}^{3}$ and measure points on its surface. The measurements are noisy. We need to reconstruct the body from these measurements. It's dangerous to do this just by considering $Hull(x_{1}, \ldots, x_{N})$, because not all points are vertexes of $Hull(x_{1}, \ldots, x_{N})$. Now we state it as a mathematical problem. Suppose that N points $x_{1}, \ldots, x_{N}$ in $\mathbb{R}^{3}$ are given (and they are so that $O = (0, 0, 0)$ is the interior point of $Hull(O, x_{1}, \ldots, x_{N})$). Let's consider the set $\mathfrak{M}$ of all closed convex surfaces $M$ that have the following property: $O = \{0, 0, 0\} \in Int \overline{M}$, where $\overline{M}$ is a convex body whose bondary is $M$, i. e. $\partial \overline{M} = M$ It's needed to find such $M \in \mathfrak{M}$ that minimizes the sum of distances from $x_{i}$ to $M$ for all $x_{1}, \ldots, x_{N}$. $$ I(M) = \sum \limits_{i = 1}^{N} \rho(x_{i}, M) \to inf \;\;\; s.t. M \in \mathfrak{M} $$ It's obvious that it is enough to consider not whole $\mathfrak{M}$, but only polyhedrons, because if $M^{*} = argmin \; I(M)$ then one can construct a polyhedron $P^{*}$ such that $I(M^{*}) = I(P^{*})$ just by finding such $y_{i} \in M^{*}$ so that $\rho(x_{i}, M^{*}) = \rho(x_{i}, y_{i})$ and then $P^{*} = Hull(y_{1}, \ldots, y_{N})$. Does anybody know any method to find such best surface or polyhedron? NOTE: It is not a convex hull. Here is the contrary instance: If you consider the convex hull, then it's possible to find better surface by dropping 3 exterior points and considering the convex hull of the rest points. It will have better value of the inital functional.","First. It's easier to understand the problem by describing the application where it arises from. We have a convex body $B$ in $\mathbb{R}^{3}$ and measure points on its surface. The measurements are noisy. We need to reconstruct the body from these measurements. It's dangerous to do this just by considering $Hull(x_{1}, \ldots, x_{N})$, because not all points are vertexes of $Hull(x_{1}, \ldots, x_{N})$. Now we state it as a mathematical problem. Suppose that N points $x_{1}, \ldots, x_{N}$ in $\mathbb{R}^{3}$ are given (and they are so that $O = (0, 0, 0)$ is the interior point of $Hull(O, x_{1}, \ldots, x_{N})$). Let's consider the set $\mathfrak{M}$ of all closed convex surfaces $M$ that have the following property: $O = \{0, 0, 0\} \in Int \overline{M}$, where $\overline{M}$ is a convex body whose bondary is $M$, i. e. $\partial \overline{M} = M$ It's needed to find such $M \in \mathfrak{M}$ that minimizes the sum of distances from $x_{i}$ to $M$ for all $x_{1}, \ldots, x_{N}$. $$ I(M) = \sum \limits_{i = 1}^{N} \rho(x_{i}, M) \to inf \;\;\; s.t. M \in \mathfrak{M} $$ It's obvious that it is enough to consider not whole $\mathfrak{M}$, but only polyhedrons, because if $M^{*} = argmin \; I(M)$ then one can construct a polyhedron $P^{*}$ such that $I(M^{*}) = I(P^{*})$ just by finding such $y_{i} \in M^{*}$ so that $\rho(x_{i}, M^{*}) = \rho(x_{i}, y_{i})$ and then $P^{*} = Hull(y_{1}, \ldots, y_{N})$. Does anybody know any method to find such best surface or polyhedron? NOTE: It is not a convex hull. Here is the contrary instance: If you consider the convex hull, then it's possible to find better surface by dropping 3 exterior points and considering the convex hull of the rest points. It will have better value of the inital functional.",,"['statistics', 'differential-geometry', '3d', 'computational-geometry']"
29,Queuing Theory with Poisson Distribution,Queuing Theory with Poisson Distribution,,"Suppose customers arrive in a one-server queue according to a Poisson distribution with rate lambda=1 (in hours). Suppose that the service times equal 1/4 hour, 1/2 hour, or one hour each with probability 1/3. (a) Assume that the queue is empty and a customer arrives. What is the expected amount of time until that customer leaves? (b) Assume that the queue is empty and a customer arrives. What is the expected amount of time until the queue is empty again? (c) At a large time t what is the probability that there are no customers in the queue? I'm trying to do couple of practice problems involving queuing before my exam and I am really confused, I would really appreciate it if someone can show me how to do this problem. Thanks","Suppose customers arrive in a one-server queue according to a Poisson distribution with rate lambda=1 (in hours). Suppose that the service times equal 1/4 hour, 1/2 hour, or one hour each with probability 1/3. (a) Assume that the queue is empty and a customer arrives. What is the expected amount of time until that customer leaves? (b) Assume that the queue is empty and a customer arrives. What is the expected amount of time until the queue is empty again? (c) At a large time t what is the probability that there are no customers in the queue? I'm trying to do couple of practice problems involving queuing before my exam and I am really confused, I would really appreciate it if someone can show me how to do this problem. Thanks",,"['probability', 'statistics', 'statistical-inference', 'queueing-theory']"
30,Generating a uniform distribution in the volume of a box,Generating a uniform distribution in the volume of a box,,"Suppose I have a three dimensional box, of volume $V$, and with lengths $x, y$, and $z$.  I then change the box volume by $\Delta V$, such that $(V + \Delta V) = (x + \Delta x)(y + \Delta y)(z + \Delta z)$. I would like to generate a uniform distribution of box volumes on some interval, such that $\Delta V \in \left[-\epsilon, \epsilon \right]$. How should I select $\Delta x, \Delta y$, and $\Delta z$, such that they each follow the same distribution, but generate this uniform distribution in volume?","Suppose I have a three dimensional box, of volume $V$, and with lengths $x, y$, and $z$.  I then change the box volume by $\Delta V$, such that $(V + \Delta V) = (x + \Delta x)(y + \Delta y)(z + \Delta z)$. I would like to generate a uniform distribution of box volumes on some interval, such that $\Delta V \in \left[-\epsilon, \epsilon \right]$. How should I select $\Delta x, \Delta y$, and $\Delta z$, such that they each follow the same distribution, but generate this uniform distribution in volume?",,"['statistics', 'probability-distributions']"
31,Expected minimum of a finite random walk.,Expected minimum of a finite random walk.,,"So I couldn't find any resource for how to calculate the expected minimum of a random walk. Since it is such the minimum of the random variables are actually not independent as they are cumulative sums of random variables. Formally: We are given some finite parameters $M,N \in \mathbb{N}$ Let $X_i \sim U(-M,M)$ for $i \in \{1,2,\dots,N\}$. In both cases of a continuous or discrete uniform I would be quite happy to find a solution, so you can assume whatever you prefer. Let $Y_i=\sum_{j=1}^i X_j$ for $i \in \{1,2,\dots,N\}$ $E[\min(Y_i)]=?$ The only solution so far I found is simulation, but I was wondering for any approach for a analytical solution.","So I couldn't find any resource for how to calculate the expected minimum of a random walk. Since it is such the minimum of the random variables are actually not independent as they are cumulative sums of random variables. Formally: We are given some finite parameters $M,N \in \mathbb{N}$ Let $X_i \sim U(-M,M)$ for $i \in \{1,2,\dots,N\}$. In both cases of a continuous or discrete uniform I would be quite happy to find a solution, so you can assume whatever you prefer. Let $Y_i=\sum_{j=1}^i X_j$ for $i \in \{1,2,\dots,N\}$ $E[\min(Y_i)]=?$ The only solution so far I found is simulation, but I was wondering for any approach for a analytical solution.",,"['statistics', 'random-walk', 'expectation']"
32,"Extracting a ball from an urn, introducing it into the second. Expected value=?","Extracting a ball from an urn, introducing it into the second. Expected value=?",,"We have two urns, the first with 6 white balls and 7 black balls and the second with 10 white balls and 5 black balls. We extract a ball from the first urn and introduce it into the second one, then we extract from the second urn 5 balls, without reintroducing them back after each extraction. If X is the nr. of white balls of the 5 extracted from the second urn, what is the expected value of X? My line of thought was that I could find the probability of extracting a white ball from the first urn, then somehow adding it to the nr of white balls in the second urn, however i am at a loss of what to do next.","We have two urns, the first with 6 white balls and 7 black balls and the second with 10 white balls and 5 black balls. We extract a ball from the first urn and introduce it into the second one, then we extract from the second urn 5 balls, without reintroducing them back after each extraction. If X is the nr. of white balls of the 5 extracted from the second urn, what is the expected value of X? My line of thought was that I could find the probability of extracting a white ball from the first urn, then somehow adding it to the nr of white balls in the second urn, however i am at a loss of what to do next.",,"['probability', 'statistics', 'discrete-mathematics']"
33,Deriving statistical distributions from games,Deriving statistical distributions from games,,"The normal distribution can be derived from basic principles and calculus The Normal Distribution: A derivation from basic principles .  Are there other distributions that can be derived like this from naturally occurring processes like those found in simple games? Like any sort of familiar games specifically such as backgammon, billiards, cards, checkers, or chess to name a few.","The normal distribution can be derived from basic principles and calculus The Normal Distribution: A derivation from basic principles .  Are there other distributions that can be derived like this from naturally occurring processes like those found in simple games? Like any sort of familiar games specifically such as backgammon, billiards, cards, checkers, or chess to name a few.",,"['calculus', 'statistics', 'probability-distributions', 'stochastic-processes', 'game-theory']"
34,How to find Influence function?,How to find Influence function?,,"Derive $IF(x;T,F)$ when    $$\displaystyle T(F)=\int_{F^{-1}(\alpha)}^{F^{-1}(1-\alpha)}x ~dF(x)$$   Here $IF$ stands for Influence function. Trial: Here $$\begin{align}IF(x;T,F) &=\lim_{t\to 0}\frac{T((1-t)F+t\Delta_x)-T(F)}t \\ &=\lim_{t\to 0}\frac{g(t)-g(0)}t=\frac{d}{dt}g(t)|_{t=0} \end{align}$$ Then I try to simplify $T(F)$ as $$\int_{F^{-1}(\alpha)}^{F^{-1}(1-\alpha)}x ~dF(x) \\ =\int_{\alpha}^{1-\alpha}F^{-1}(y) ~dy$$  Then I am stuck. Please help.","Derive $IF(x;T,F)$ when    $$\displaystyle T(F)=\int_{F^{-1}(\alpha)}^{F^{-1}(1-\alpha)}x ~dF(x)$$   Here $IF$ stands for Influence function. Trial: Here $$\begin{align}IF(x;T,F) &=\lim_{t\to 0}\frac{T((1-t)F+t\Delta_x)-T(F)}t \\ &=\lim_{t\to 0}\frac{g(t)-g(0)}t=\frac{d}{dt}g(t)|_{t=0} \end{align}$$ Then I try to simplify $T(F)$ as $$\int_{F^{-1}(\alpha)}^{F^{-1}(1-\alpha)}x ~dF(x) \\ =\int_{\alpha}^{1-\alpha}F^{-1}(y) ~dy$$  Then I am stuck. Please help.",,"['statistics', 'robust-statistics']"
35,"How is the ""cooking"" done in surveys","How is the ""cooking"" done in surveys",,"In my country there's an official center undertaking surveys of voting intention every 4 months. However, they provide only ""direct"" voting intention, and the statistics obtained are usually pretty far away from the final results in the election day (people voting right wing parties usually pretend they don't or just say they don't know what they are going to vote yet). So, if you want a good estimator of the real voting intention you have to correct the data collected (in my country it is called ""cooking"" the survey, but I don't know how is it called outside), using in some way the information given by the deviations in previous elections. Do you know any paper or reference that studies this cooking corrections with some mathematical rigor? Or can explain how this corrections are developed?","In my country there's an official center undertaking surveys of voting intention every 4 months. However, they provide only ""direct"" voting intention, and the statistics obtained are usually pretty far away from the final results in the election day (people voting right wing parties usually pretend they don't or just say they don't know what they are going to vote yet). So, if you want a good estimator of the real voting intention you have to correct the data collected (in my country it is called ""cooking"" the survey, but I don't know how is it called outside), using in some way the information given by the deviations in previous elections. Do you know any paper or reference that studies this cooking corrections with some mathematical rigor? Or can explain how this corrections are developed?",,"['statistics', 'statistical-inference', 'parameter-estimation']"
36,Quantile density function: student's t vs normal,Quantile density function: student's t vs normal,,"I'm trying to show that $\frac{\exp\Big(\frac{\Phi^{-1}(x)^2}{2}\Big)}{\Big(1+\frac{\Psi^{-1}(x)^2}{\delta}\Big)^{(\delta-1)/2}}$ goes to infinity as $x$ goes to one, where $\Phi^{-1}$ denotes the inverse CDF of the standard normal, and $\Psi^{-1}$ denotes the inverse CDF of the standard Student's t with $\delta$ degrees of freedom. If it helps, I've noticed that $\frac{\exp\Big(\frac{\Phi^{-1}(x)^2}{2}\Big)}{\Big(1+\frac{\Psi^{-1}(x)^2}{\delta}\Big)^{(\delta-1)/2}}$ always seems to exceed one, but that $\frac{\exp\Big(\frac{\Phi^{-1}(x)^2}{2}\Big)}{\Big(1+\frac{\Psi^{-1}(x)^2}{\delta}\Big)^{(\delta+1)/2}}$ always seems to fall short of one, where $\exp\Big(\frac{\Phi^{-1}(x)^2}{2}\Big)$ is the quantile density function of the standard normal and $\Big(1+\frac{\Psi^{-1}(x)^2}{\delta}\Big)^{(\delta+1)/2}$ is the quantile density function of the Student's t with $\delta$ degrees of freedom. Thanks, Rob","I'm trying to show that $\frac{\exp\Big(\frac{\Phi^{-1}(x)^2}{2}\Big)}{\Big(1+\frac{\Psi^{-1}(x)^2}{\delta}\Big)^{(\delta-1)/2}}$ goes to infinity as $x$ goes to one, where $\Phi^{-1}$ denotes the inverse CDF of the standard normal, and $\Psi^{-1}$ denotes the inverse CDF of the standard Student's t with $\delta$ degrees of freedom. If it helps, I've noticed that $\frac{\exp\Big(\frac{\Phi^{-1}(x)^2}{2}\Big)}{\Big(1+\frac{\Psi^{-1}(x)^2}{\delta}\Big)^{(\delta-1)/2}}$ always seems to exceed one, but that $\frac{\exp\Big(\frac{\Phi^{-1}(x)^2}{2}\Big)}{\Big(1+\frac{\Psi^{-1}(x)^2}{\delta}\Big)^{(\delta+1)/2}}$ always seems to fall short of one, where $\exp\Big(\frac{\Phi^{-1}(x)^2}{2}\Big)$ is the quantile density function of the standard normal and $\Big(1+\frac{\Psi^{-1}(x)^2}{\delta}\Big)^{(\delta+1)/2}$ is the quantile density function of the Student's t with $\delta$ degrees of freedom. Thanks, Rob",,['statistics']
37,The sum of Gaussian functions,The sum of Gaussian functions,,"Suppose there is a normal distribution and the Gaussian function is $F(x)=\exp(-c\|x-b\|^2)$ where $c$ is a constant and $x,b\in \mathbb{R}^N$, b means the mean value. $F(x)=\exp(-c\|x-b\|^2)=F(x)=\exp(-c(x^Tx-2x^Tb+b^Tb))=\exp(-c(x^Tx))\times\exp(2cx^Tb)\times\exp(-c(b^Tb))$ 1) $F(x_1)+F(x_2)+F(x_3)=\exp(-c(b^Tb)) \times(  \exp(-c(x_1^Tx_1))\times\exp(2cx_1^Tb)+\exp(-c(x_2^Tx_2))\times\exp(2cx_2^Tb)+\exp(-c(x_3^Tx_3))\times\exp(2cx_3^Tb)   )$ Is there any way I can write as $F(x_1)+F(x_2)+F(x_3)=G(b)\times H(x_1,x_2,x_3)$. 2) How about $\sum\limits_{x\in \Omega}F(x)$?","Suppose there is a normal distribution and the Gaussian function is $F(x)=\exp(-c\|x-b\|^2)$ where $c$ is a constant and $x,b\in \mathbb{R}^N$, b means the mean value. $F(x)=\exp(-c\|x-b\|^2)=F(x)=\exp(-c(x^Tx-2x^Tb+b^Tb))=\exp(-c(x^Tx))\times\exp(2cx^Tb)\times\exp(-c(b^Tb))$ 1) $F(x_1)+F(x_2)+F(x_3)=\exp(-c(b^Tb)) \times(  \exp(-c(x_1^Tx_1))\times\exp(2cx_1^Tb)+\exp(-c(x_2^Tx_2))\times\exp(2cx_2^Tb)+\exp(-c(x_3^Tx_3))\times\exp(2cx_3^Tb)   )$ Is there any way I can write as $F(x_1)+F(x_2)+F(x_3)=G(b)\times H(x_1,x_2,x_3)$. 2) How about $\sum\limits_{x\in \Omega}F(x)$?",,['statistics']
38,Distribution of $(XY)^Z$,Distribution of,(XY)^Z,"Can you please help me with this. Let $X,Y,Z$ are independent random variables uniformly distributed over $[0,1]$. Show that $(XY)^Z$ is also uniformly distributed over $[0,1]$ I try to show that $-Z(\ln X+\ln Y)$ has an exponential distribution, but i am not sure. Thanks in advance.","Can you please help me with this. Let $X,Y,Z$ are independent random variables uniformly distributed over $[0,1]$. Show that $(XY)^Z$ is also uniformly distributed over $[0,1]$ I try to show that $-Z(\ln X+\ln Y)$ has an exponential distribution, but i am not sure. Thanks in advance.",,['statistics']
39,Is the Support Vector Classifier in some sense optimal?,Is the Support Vector Classifier in some sense optimal?,,"My question is, is the original hard-margin support vector classifier optimal in some sense? If you have an answer that refers to the soft-margin SVC instead, I'd also be interested. I know that the SVC has advantages:  it does not depend on specific distributional assumptions  it deals gracefully and without special tricks with the $p > n$ situation  it produces a solution which is sparse w.r.t. the training data  it integrates naturally with the ""kernel trick"". I know that the SVC performs well in many practical problems. I know that it is possible to derive diverse upper bounds on the generalization error of the SVC. I know that the SVC is based on an optimization process: finding the separating hyperplane with the largest margin.  but I'm unclear about the statistical motivation of the margin maximization approach itself. Of course it makes intuitive sense: First make sure that all training data points are correctly classified (separating hyperplane), then choose the hyperplane that least invites any ambiguity as to how the training data should be classified. But is this more than a plausible heuristic? Is there e.g. a theorem that shows that maximizing the margin leads to the smallest generalization error under some set of assumptions? Hastie et al. write in The Elements of Statistical Learning : Not only does this provide a unique solution to the separating   hyperplane problem, but by maximizing the margin between the two   classes on the training data, this leads to better classification   performance on test data.  The intuition is that a large margin on the training data will lead to   good separation on the test data. This suggests the ""plausible heuristic"" interpretation. They further write: Vapniks structural risk minimization (SRM) approach fits a nested   sequence of models of increasing VC dimensions $h_1 < h_2 < \cdots$ ,   and then chooses the model with the smallest value of the upper bound.    An example in which the structural risk minimization program can be   successfully carried out is the support vector classifier  This sounds like that what makes the SVC special is that it can be analyzed by the SRM approach  but not necessarily that it is SRM-optimal, because alternatives cannot be analyzed. Can anyone shed light on this?","My question is, is the original hard-margin support vector classifier optimal in some sense? If you have an answer that refers to the soft-margin SVC instead, I'd also be interested. I know that the SVC has advantages:  it does not depend on specific distributional assumptions  it deals gracefully and without special tricks with the $p > n$ situation  it produces a solution which is sparse w.r.t. the training data  it integrates naturally with the ""kernel trick"". I know that the SVC performs well in many practical problems. I know that it is possible to derive diverse upper bounds on the generalization error of the SVC. I know that the SVC is based on an optimization process: finding the separating hyperplane with the largest margin.  but I'm unclear about the statistical motivation of the margin maximization approach itself. Of course it makes intuitive sense: First make sure that all training data points are correctly classified (separating hyperplane), then choose the hyperplane that least invites any ambiguity as to how the training data should be classified. But is this more than a plausible heuristic? Is there e.g. a theorem that shows that maximizing the margin leads to the smallest generalization error under some set of assumptions? Hastie et al. write in The Elements of Statistical Learning : Not only does this provide a unique solution to the separating   hyperplane problem, but by maximizing the margin between the two   classes on the training data, this leads to better classification   performance on test data.  The intuition is that a large margin on the training data will lead to   good separation on the test data. This suggests the ""plausible heuristic"" interpretation. They further write: Vapniks structural risk minimization (SRM) approach fits a nested   sequence of models of increasing VC dimensions $h_1 < h_2 < \cdots$ ,   and then chooses the model with the smallest value of the upper bound.    An example in which the structural risk minimization program can be   successfully carried out is the support vector classifier  This sounds like that what makes the SVC special is that it can be analyzed by the SRM approach  but not necessarily that it is SRM-optimal, because alternatives cannot be analyzed. Can anyone shed light on this?",,"['statistics', 'optimization', 'machine-learning']"
40,Find minimal sufficient statistics and ML estimator,Find minimal sufficient statistics and ML estimator,,"Let $X_1, X_2, \ldots, X_n$ be i.i.d. uniform $(a-b, a+b)$, where $b>0$ and let $\theta = (a,b)$. Find a minimal sufficient statistics $t$ for $\theta$. Find the ML estimator $\hat{\theta}$ of $\theta$. So, what I have done is for minimal sufficient statistics $t$ for $\theta$,  by Fisher Neyman theorem, showed that $T(X_i) = (\min(X_i), \max(X_i))$.  Is this correct? And for the ML estimator,  I just can understand the distribution would be $p = 1/2b$.  Then can I just take a log function and calculate ML?","Let $X_1, X_2, \ldots, X_n$ be i.i.d. uniform $(a-b, a+b)$, where $b>0$ and let $\theta = (a,b)$. Find a minimal sufficient statistics $t$ for $\theta$. Find the ML estimator $\hat{\theta}$ of $\theta$. So, what I have done is for minimal sufficient statistics $t$ for $\theta$,  by Fisher Neyman theorem, showed that $T(X_i) = (\min(X_i), \max(X_i))$.  Is this correct? And for the ML estimator,  I just can understand the distribution would be $p = 1/2b$.  Then can I just take a log function and calculate ML?",,['statistics']
41,Finding an unbiased estimator for function of Poisson,Finding an unbiased estimator for function of Poisson,,"Let $X_1,...,X_n \sim Poi(\lambda)$ then unbiased estimator for $\lambda$ is obviously $\bar{X}$. What about $\tau(\lambda)=\sqrt{\lambda}$? Also how would one derive UMVUE for this lambda?","Let $X_1,...,X_n \sim Poi(\lambda)$ then unbiased estimator for $\lambda$ is obviously $\bar{X}$. What about $\tau(\lambda)=\sqrt{\lambda}$? Also how would one derive UMVUE for this lambda?",,"['statistics', 'self-learning', 'estimation']"
42,Relation between standard deviation and mean in random processes,Relation between standard deviation and mean in random processes,,"In a Poisson distribution the square of the standard deviation $\sigma$ is equal to mean $\mu$ ($\sigma^2=\mu$) and in a binomial distribution $\sigma ^2=\mu\,(1-p)$ (with $p$ the probability of success). I wonder what relations exist between the mean and the standard deviation in other random processes. Does the standard deviation always increase with the mean? Are they always related or may be independent? Particular cases are also welcome.","In a Poisson distribution the square of the standard deviation $\sigma$ is equal to mean $\mu$ ($\sigma^2=\mu$) and in a binomial distribution $\sigma ^2=\mu\,(1-p)$ (with $p$ the probability of success). I wonder what relations exist between the mean and the standard deviation in other random processes. Does the standard deviation always increase with the mean? Are they always related or may be independent? Particular cases are also welcome.",,"['probability', 'statistics', 'stochastic-processes', 'random-variables', 'standard-deviation']"
43,How many items to acquire to get a full collection? (random chance involved),How many items to acquire to get a full collection? (random chance involved),,"The problem: My daughter wants to have a collection of certain Kinder Surprise toys. There're 10 different toys in this series. Assuming the chances of getting each toy are equal, how many Kinder Surprises should I buy to get her a full collection? What I did was 1/1+1/0.9+1/0.8+1/0.7+1/0.6+1/0.5+1/0.4+1/0.3+1/0.2+1/0.1 and it gave me the answer of 29.28968 Question 1: is it correct? Is there a better way to do it? Question 2: I want to know how dispersed the hypothetical data of buying Kinder Surprises until you get all 10 would be . If it is applicable in this situation, standard deviation would answer my question. If I knew the standard deviation, I would know that ~95% of values lie within 2 standard deviations, so I could decide on how many Kinder Surprises to buy to get a full collection for sure. Edit: if you have an answer which you can explain both mathematically and as an R idiom [software], including the latter would be very helpful.","The problem: My daughter wants to have a collection of certain Kinder Surprise toys. There're 10 different toys in this series. Assuming the chances of getting each toy are equal, how many Kinder Surprises should I buy to get her a full collection? What I did was 1/1+1/0.9+1/0.8+1/0.7+1/0.6+1/0.5+1/0.4+1/0.3+1/0.2+1/0.1 and it gave me the answer of 29.28968 Question 1: is it correct? Is there a better way to do it? Question 2: I want to know how dispersed the hypothetical data of buying Kinder Surprises until you get all 10 would be . If it is applicable in this situation, standard deviation would answer my question. If I knew the standard deviation, I would know that ~95% of values lie within 2 standard deviations, so I could decide on how many Kinder Surprises to buy to get a full collection for sure. Edit: if you have an answer which you can explain both mathematically and as an R idiom [software], including the latter would be very helpful.",,['statistics']
44,Successive outcome probability problem,Successive outcome probability problem,,"Here is another question from the book of V. Rohatgi and A. Saleh. I would like to ask help again. Here it goes: A biased coin with probability $p$, $0 < p < 1$, of success (heads) is tossed until for the first time, the same result occurs three times in succession (that is, three heads or three tails in succession). Find the probability that the game will end at the seventh throw. So here is what I have so far. I considered two cases: (1) _ _ _ THHH ; and (2) _ _ _ HTTT. So for the first case, the only ways that the 3 blanks can be filled up are through the outcomes $$\text{HHT, HTH, THH, TTH, and THT}$$ So what I did is that I took the individual probabilities of each sequence, e.g. $$\text{P{HHT}}=p^2(1-p)$$ and so on. So I add all these 5 probabilities and multiplied the sum with having THHH as the last 4 outcomes, i.e. $$\text{P{THHH}}=p^3(1-p)$$ I did the same thing for the second case. Afterwards, I added probabilities for both cases; thus, giving me the result $$(1-p)p^3[1-p(1-p)^2-(1-p)^3-p^3]+p(1-p)^3[1-p^2(1-p)-p^3-(1-p)^3]$$ I would like to ask if I am doing it correctly or not, or whether there is a shorter solution. I read some texts that considered the problem as a renewal process; however, I have trouble understanding it, especially all I have found so far concern with ""expected number of tosses"". The answer, by the way, as given in the text is $$p^2(1-p)^2[3-7p(1-p)]$$ Can anyone verify and explain why please? Thanks","Here is another question from the book of V. Rohatgi and A. Saleh. I would like to ask help again. Here it goes: A biased coin with probability $p$, $0 < p < 1$, of success (heads) is tossed until for the first time, the same result occurs three times in succession (that is, three heads or three tails in succession). Find the probability that the game will end at the seventh throw. So here is what I have so far. I considered two cases: (1) _ _ _ THHH ; and (2) _ _ _ HTTT. So for the first case, the only ways that the 3 blanks can be filled up are through the outcomes $$\text{HHT, HTH, THH, TTH, and THT}$$ So what I did is that I took the individual probabilities of each sequence, e.g. $$\text{P{HHT}}=p^2(1-p)$$ and so on. So I add all these 5 probabilities and multiplied the sum with having THHH as the last 4 outcomes, i.e. $$\text{P{THHH}}=p^3(1-p)$$ I did the same thing for the second case. Afterwards, I added probabilities for both cases; thus, giving me the result $$(1-p)p^3[1-p(1-p)^2-(1-p)^3-p^3]+p(1-p)^3[1-p^2(1-p)-p^3-(1-p)^3]$$ I would like to ask if I am doing it correctly or not, or whether there is a shorter solution. I read some texts that considered the problem as a renewal process; however, I have trouble understanding it, especially all I have found so far concern with ""expected number of tosses"". The answer, by the way, as given in the text is $$p^2(1-p)^2[3-7p(1-p)]$$ Can anyone verify and explain why please? Thanks",,"['probability', 'statistics']"
45,"What does the ""$\top\,$"" in ""$\,y = [x,u,v,y]^{\top}\,$"" mean?","What does the """" in """" mean?","\top\, \,y = [x,u,v,y]^{\top}\,","There is a diffrential equation which takes the form: $$\frac{dy}{dt} = f(y,t) $$ $$y = [x,u,v,y]^{\top}$$ What does the superscript of $\top$ in this case mean?",There is a diffrential equation which takes the form: What does the superscript of in this case mean?,"\frac{dy}{dt} = f(y,t)  y = [x,u,v,y]^{\top} \top","['ordinary-differential-equations', 'functions', 'notation']"
46,Calculating linguistic diversity of a text with respect to size,Calculating linguistic diversity of a text with respect to size,,"I'm doing linguistics work and I'm trying to make a measure of linguistic diversity in a text.  A simple calculation seems to be linguistic uniformity (diversity) = number of words / unique words But this must ""privilege"" shorter texts like poetry for diversity, since the author is less likely to repeat themselves in so short a space.  For example, Blake's poetry gets a score of 5, whereas the KJV bible scores 79 and this has a lot to do with the size of the bible compared to Blake's poetry.  If we analysed more of the Blakes's corpus, his score would definitely go higher. How can I normalize the calculation, taking into account the inevitable repetition that comes with longer texts, and the fact that shorter texts are so small that we just haven't seen an appreciable part of an author's lexicon?  I know that there's a name for this, I just can't remember what it is.  I've looked at the wiki article on diversity index but it hasnt helped me. Apologise if my question seems stupid. I'm a linguist, not a mathematician. Tagged as homework even though it's not because I'm unsure what category to put it under otherwise.","I'm doing linguistics work and I'm trying to make a measure of linguistic diversity in a text.  A simple calculation seems to be linguistic uniformity (diversity) = number of words / unique words But this must ""privilege"" shorter texts like poetry for diversity, since the author is less likely to repeat themselves in so short a space.  For example, Blake's poetry gets a score of 5, whereas the KJV bible scores 79 and this has a lot to do with the size of the bible compared to Blake's poetry.  If we analysed more of the Blakes's corpus, his score would definitely go higher. How can I normalize the calculation, taking into account the inevitable repetition that comes with longer texts, and the fact that shorter texts are so small that we just haven't seen an appreciable part of an author's lexicon?  I know that there's a name for this, I just can't remember what it is.  I've looked at the wiki article on diversity index but it hasnt helped me. Apologise if my question seems stupid. I'm a linguist, not a mathematician. Tagged as homework even though it's not because I'm unsure what category to put it under otherwise.",,['statistics']
47,How do I state that a data set has a 'denser' standard deviation?,How do I state that a data set has a 'denser' standard deviation?,,"Suppose I have two algorithms that produce numerical data. The first algorithm produces { 2452, 695, 318, ... } with a mean of 1155 and a standard deviation of 1138. The second algorithm produces { 35036, 29720, 31744, ...} with a mean of 32170 and a standard deviation of 2683. I would like to formally describe the two results in terms of how 'dense' the output is about the mean. The first algorithm produces a lower standard deviation of 1138, but intuitively, this value is close to the mean of 1155, so my gut is that the distribution is very wide. On the other hand, the second algorithm produces a larger standard deviation of 2683, but this value is small compared to the mean of 32170. What is the correct formal description of this 'denseness' of standard deviation around the mean? What can I formally say when comparing algorithm 1 and 2?","Suppose I have two algorithms that produce numerical data. The first algorithm produces { 2452, 695, 318, ... } with a mean of 1155 and a standard deviation of 1138. The second algorithm produces { 35036, 29720, 31744, ...} with a mean of 32170 and a standard deviation of 2683. I would like to formally describe the two results in terms of how 'dense' the output is about the mean. The first algorithm produces a lower standard deviation of 1138, but intuitively, this value is close to the mean of 1155, so my gut is that the distribution is very wide. On the other hand, the second algorithm produces a larger standard deviation of 2683, but this value is small compared to the mean of 32170. What is the correct formal description of this 'denseness' of standard deviation around the mean? What can I formally say when comparing algorithm 1 and 2?",,"['probability', 'statistics', 'descriptive-statistics']"
48,Understanding degrees of freedom,Understanding degrees of freedom,,"Please provide guidance for the following question. Which of the following is/are correct? $1.$ A free particle in $\mathbb R^3$ can have infinite degrees of freedom. $2.$ The number of degree of freedom of $N$ particles is greater than $3N$ . $3.$ A system of $N$ particles with $k$ constants has $3N+k$ degrees of freedom. $4.$ A system consisting of three point masses connected by three rigid massless rods has six degrees of freedom. I think $1$ st is wrong, because a particle can have max $3$ degrees of freedom, I would assume in x,y and z direction. Are all of these $3$ degrees translational? Or, one is tranlational, one rotation and one vibration? Regarding $2$ nd, I know that max degrees of freedom of N particles is $3N$ , why it is so, I've no idea. Regarding $3$ rd, I am not getting what is meant by $k$ constants. Regarding $4$ th, I checked diatomic example. It has $3$ translational degrees (I assume of co-ordinates), $2$ rotational (I assume clockwise and anti-clockwise), and $1$ vibrational (I assume we have to assume that they are tied by a thread). Similarly, For $3$ particles, I would say, $3$ translational, $2$ rotational and $3$ vibrational (becasue $3$ threads). I wish somebody could help me see clearly so that I be able to solve this question. Thanks in advance!","Please provide guidance for the following question. Which of the following is/are correct? A free particle in can have infinite degrees of freedom. The number of degree of freedom of particles is greater than . A system of particles with constants has degrees of freedom. A system consisting of three point masses connected by three rigid massless rods has six degrees of freedom. I think st is wrong, because a particle can have max degrees of freedom, I would assume in x,y and z direction. Are all of these degrees translational? Or, one is tranlational, one rotation and one vibration? Regarding nd, I know that max degrees of freedom of N particles is , why it is so, I've no idea. Regarding rd, I am not getting what is meant by constants. Regarding th, I checked diatomic example. It has translational degrees (I assume of co-ordinates), rotational (I assume clockwise and anti-clockwise), and vibrational (I assume we have to assume that they are tied by a thread). Similarly, For particles, I would say, translational, rotational and vibrational (becasue threads). I wish somebody could help me see clearly so that I be able to solve this question. Thanks in advance!",1. \mathbb R^3 2. N 3N 3. N k 3N+k 4. 1 3 3 2 3N 3 k 4 3 2 1 3 3 2 3 3,['statistics']
49,SLLN of Markov chains .,SLLN of Markov chains .,,"Let $X_1$, $X_2$,... be a finite state, irreducible and aperiodic Markov chain with initial state $X_0=i$. It is known that  \begin{equation} \mathrm{P}\Big\{\lim_{n\rightarrow\infty} \frac{1}{n}\sum_{t=1}^n I\{X_t=j\}=\pi(j) \Big\} = 1, \end{equation} where $I(\cdot)$ is the indicator function and $\pi(j)$ is the stationary distribution of state $j$. Question: Is the above also true if the state of the Markov chain is observed at arbitrary time instances (for example recording only every second state transition of the chain $X_1, X_3, X_5,...$)? To put more formally, I'd like to know if the following is also true : \begin{equation} \mathrm{P}\Big\{\lim_{n\rightarrow\infty} \frac{1}{n}\sum_{k=1}^n I\{X_{\tau(k)}=j\}=\pi(j) \Big\} = 1, \end{equation} where $\{\tau(k)\}$ is any infinite strictly increasing sequence of natural numbers.","Let $X_1$, $X_2$,... be a finite state, irreducible and aperiodic Markov chain with initial state $X_0=i$. It is known that  \begin{equation} \mathrm{P}\Big\{\lim_{n\rightarrow\infty} \frac{1}{n}\sum_{t=1}^n I\{X_t=j\}=\pi(j) \Big\} = 1, \end{equation} where $I(\cdot)$ is the indicator function and $\pi(j)$ is the stationary distribution of state $j$. Question: Is the above also true if the state of the Markov chain is observed at arbitrary time instances (for example recording only every second state transition of the chain $X_1, X_3, X_5,...$)? To put more formally, I'd like to know if the following is also true : \begin{equation} \mathrm{P}\Big\{\lim_{n\rightarrow\infty} \frac{1}{n}\sum_{k=1}^n I\{X_{\tau(k)}=j\}=\pi(j) \Big\} = 1, \end{equation} where $\{\tau(k)\}$ is any infinite strictly increasing sequence of natural numbers.",,"['probability', 'statistics', 'markov-chains', 'law-of-large-numbers']"
50,Integral of a max function over a hypersphere; expected max z score,Integral of a max function over a hypersphere; expected max z score,,"Is there a closed-form expression for the integral of max($x_1,..., x_n$) over the ($n-2$)-dimensional hypersphere, {$x \in \mathbf{R}^n$:  $\sum_{i=1}^n x_i = 0$,  $\sum_{i=1}^n x_i^2 = 1$}? I come across this integral in trying to find the expected value of the maximum z score from independent normals.","Is there a closed-form expression for the integral of max($x_1,..., x_n$) over the ($n-2$)-dimensional hypersphere, {$x \in \mathbf{R}^n$:  $\sum_{i=1}^n x_i = 0$,  $\sum_{i=1}^n x_i^2 = 1$}? I come across this integral in trying to find the expected value of the maximum z score from independent normals.",,"['probability', 'statistics', 'integration', 'manifolds']"
51,Rewrite constrained optimization objective,Rewrite constrained optimization objective,,"I wanted to ask, under which conditions can one rewrite the optimization objective $\min_x f(x)\;\;\;s.t.\;\;\;g(x) \leq s$ as $\min_x g(x)\;\;\;s.t.\;\;\;f(x) \leq t$ I have particular interest in the case where $f(x) = \|x\|_1$ and $g(x) = \|y - Ax\|_2$ (i.e. for the Lasso!), but would like to know the details for the general case. References to appropriate books would be equally useful. Thank you!","I wanted to ask, under which conditions can one rewrite the optimization objective $\min_x f(x)\;\;\;s.t.\;\;\;g(x) \leq s$ as $\min_x g(x)\;\;\;s.t.\;\;\;f(x) \leq t$ I have particular interest in the case where $f(x) = \|x\|_1$ and $g(x) = \|y - Ax\|_2$ (i.e. for the Lasso!), but would like to know the details for the general case. References to appropriate books would be equally useful. Thank you!",,"['statistics', 'optimization', 'linear-programming', 'convex-optimization', 'numerical-optimization']"
52,"Double Summation: Need help to handle $ i \neq j $ : $ \sum_{i=0 \to 7,\ j=1 \to 8,\ i\neq j} (8i + j) $",Double Summation: Need help to handle  :," i \neq j   \sum_{i=0 \to 7,\ j=1 \to 8,\ i\neq j} (8i + j) ","[Q1]. Can I ? ( write the same summation as ) : $$ \sum_{i=0, i \neq j}^7 \sum_{j=1}^8 (8i + j)   \tag{1}$$ I tried to solve the following Summation as follows: Let i = m-1 then, $ \sum_{i=0,\ i \neq j}^7 $ becomes  $\sum_{m=1,\ j\neq m-1}^8 $ Now applying change of base equation (1) i.e. $ \sum_{i=0, i \neq j}^7 \sum_{j=1}^8 (8i + j)    $ becomes  $$ \sum_{m=1,\ j\neq m-1}^8 \sum_{j=1}^8 \Big(8(m-1) + j \Big) $$ [Q2]. Can we do the next step? By what rule? $$\text{Above}= \sum_{m=1,\ j=1, \ j\neq m-1}^8 (8m - 8 +j)  \\ = (\sum_{m=1,\ j=1, \ j\neq m-1}^8 8m )- (\sum_{m=1,\ j=1, \ j\neq m-1}^8 8) + (\sum_{m=1,\ j=1, \ j\neq m-1}^8 j) \\     = 8\ \Big(\sum_{m=1}^8 m \Big)-  8 \ \Big(\sum_1^8 1 \Big) + \Big(\sum_{j=1}^8 j\Big)  \\ = 8 \Big( 8. \frac{8+1}{2} \Big)  -  8(8)+ \Big( 8. \frac{8+1}{2} \Big)    \\ =260 $$ [Q3]. Don't we need to handle $ i \neq j $ ? If so, then in which situation does $ i \neq j $ matter and how ? Please explain what iff. $ i ==j $ then ? Please clear my concept by answering all my 3 questions above(Q1,Q2 and Q3).","[Q1]. Can I ? ( write the same summation as ) : $$ \sum_{i=0, i \neq j}^7 \sum_{j=1}^8 (8i + j)   \tag{1}$$ I tried to solve the following Summation as follows: Let i = m-1 then, $ \sum_{i=0,\ i \neq j}^7 $ becomes  $\sum_{m=1,\ j\neq m-1}^8 $ Now applying change of base equation (1) i.e. $ \sum_{i=0, i \neq j}^7 \sum_{j=1}^8 (8i + j)    $ becomes  $$ \sum_{m=1,\ j\neq m-1}^8 \sum_{j=1}^8 \Big(8(m-1) + j \Big) $$ [Q2]. Can we do the next step? By what rule? $$\text{Above}= \sum_{m=1,\ j=1, \ j\neq m-1}^8 (8m - 8 +j)  \\ = (\sum_{m=1,\ j=1, \ j\neq m-1}^8 8m )- (\sum_{m=1,\ j=1, \ j\neq m-1}^8 8) + (\sum_{m=1,\ j=1, \ j\neq m-1}^8 j) \\     = 8\ \Big(\sum_{m=1}^8 m \Big)-  8 \ \Big(\sum_1^8 1 \Big) + \Big(\sum_{j=1}^8 j\Big)  \\ = 8 \Big( 8. \frac{8+1}{2} \Big)  -  8(8)+ \Big( 8. \frac{8+1}{2} \Big)    \\ =260 $$ [Q3]. Don't we need to handle $ i \neq j $ ? If so, then in which situation does $ i \neq j $ matter and how ? Please explain what iff. $ i ==j $ then ? Please clear my concept by answering all my 3 questions above(Q1,Q2 and Q3).",,"['sequences-and-series', 'statistics', 'summation']"
53,Proving $\text{Var}{(\hat{y}_h)} = \sigma^2 \left(\frac{1}{n} + \frac{(x_h-\bar{x})^2}{S_{xx}}\right)$,Proving,\text{Var}{(\hat{y}_h)} = \sigma^2 \left(\frac{1}{n} + \frac{(x_h-\bar{x})^2}{S_{xx}}\right),"I have asked in another question how $\text{Var}{(\hat{y}_h)} = \sigma^2 \left(\frac{1}{n} + \frac{(x_h-\bar{x})^2}{S_{xx}}\right)$.  Note that $\hat{y}_h$ = $b_0 + b_1X_h$ which is a regression line estimate at some given $X_h$. This question concerns why the term $Cov(b_0,b_1)$ alone yields the RHS.  Substituting $b_0 = Y - b_1X$ we get that $Cov(Y,b_1) - XCov(b_1,b_1)$ = $Cov(\frac{\sum{Y_i}}{n},\sum k_iY_i) - XVar{(b_1)}$. Here X and Y without subscript are arithmetic means. We can then rearrange to obtain $\sum \frac{k_i Var(Y_i)}{n} - \frac{X\sigma^2}{S_{xx}}$ which quickly yields the desired result.  My question is, why does this work?  This single term does not seem like it should alone yield the RHS.  Have I made an error in algebra?","I have asked in another question how $\text{Var}{(\hat{y}_h)} = \sigma^2 \left(\frac{1}{n} + \frac{(x_h-\bar{x})^2}{S_{xx}}\right)$.  Note that $\hat{y}_h$ = $b_0 + b_1X_h$ which is a regression line estimate at some given $X_h$. This question concerns why the term $Cov(b_0,b_1)$ alone yields the RHS.  Substituting $b_0 = Y - b_1X$ we get that $Cov(Y,b_1) - XCov(b_1,b_1)$ = $Cov(\frac{\sum{Y_i}}{n},\sum k_iY_i) - XVar{(b_1)}$. Here X and Y without subscript are arithmetic means. We can then rearrange to obtain $\sum \frac{k_i Var(Y_i)}{n} - \frac{X\sigma^2}{S_{xx}}$ which quickly yields the desired result.  My question is, why does this work?  This single term does not seem like it should alone yield the RHS.  Have I made an error in algebra?",,"['statistics', 'regression']"
54,Distribution of a group of people and a subset of them,Distribution of a group of people and a subset of them,,"Given $n$ people, each has probability $v$ of having a virus. Of those with the virus, they are hospitalized with probability $p$ . Independently of having the virus, any of the $n$ people may be hospitalized for a different reason with probability $a$ . Let $X$ be a random variable that denotes the number of the $n$ people who are hospitalized, and $Y$ be a random variable that denotes the number of people in the hospital that have the virus. Find the distributions of X and Y. I think this situation reflects a certain distribution. I was thinking Bernoulli, but I can't seem to think of a way to represent both of the random variables. Can anyone help with this please?","Given people, each has probability of having a virus. Of those with the virus, they are hospitalized with probability . Independently of having the virus, any of the people may be hospitalized for a different reason with probability . Let be a random variable that denotes the number of the people who are hospitalized, and be a random variable that denotes the number of people in the hospital that have the virus. Find the distributions of X and Y. I think this situation reflects a certain distribution. I was thinking Bernoulli, but I can't seem to think of a way to represent both of the random variables. Can anyone help with this please?",n v p n a X n Y,"['probability', 'statistics']"
55,Simple question about histogram,Simple question about histogram,,"Wikipedia article about histograms says following: A histogram is a representation of tabulated frequencies, shown as   adjacent rectangles, erected over discrete intervals (bins), with an area equal to the frequency of the observations in the interval. The height of a rectangle is also equal to the frequency density of the   interval, i.e., the frequency divided by the width of the interval. and yet, its own example about ""heights of Black Cherry trees"" has heights equal to frequency of observations. So when is the height frequency density and when is it frequency observations?","Wikipedia article about histograms says following: A histogram is a representation of tabulated frequencies, shown as   adjacent rectangles, erected over discrete intervals (bins), with an area equal to the frequency of the observations in the interval. The height of a rectangle is also equal to the frequency density of the   interval, i.e., the frequency divided by the width of the interval. and yet, its own example about ""heights of Black Cherry trees"" has heights equal to frequency of observations. So when is the height frequency density and when is it frequency observations?",,['statistics']
56,Comparing two or more sets of sequences,Comparing two or more sets of sequences,,"I have observed nurses during 400 episodes of care and recorded the sequence of surfaces contacts in each. I categorised the surfaces into 5 groups 1:5 and calculated the probability density functions of touching any one of 1:5 (PDF). PDF=[ 0.255202629   0.186199343 0.104052574 0.201533406 0.253012048] I then predicted some 1000 sequences using: for i=1:1000 % 1000 different nurses     seq(i,1:end)=randsample(1:5,max(observed_seq_length),'true',PDF); end eg. seq =     1     5     2     3     4     2     5     5     2     5  stairs(1:max(observed_seq_length),seq) hold all I'd like to compare my empirical sequences with my predicted one. What would you suggest to be the best strategy or property to look at? Regards,","I have observed nurses during 400 episodes of care and recorded the sequence of surfaces contacts in each. I categorised the surfaces into 5 groups 1:5 and calculated the probability density functions of touching any one of 1:5 (PDF). PDF=[ 0.255202629   0.186199343 0.104052574 0.201533406 0.253012048] I then predicted some 1000 sequences using: for i=1:1000 % 1000 different nurses     seq(i,1:end)=randsample(1:5,max(observed_seq_length),'true',PDF); end eg. seq =     1     5     2     3     4     2     5     5     2     5  stairs(1:max(observed_seq_length),seq) hold all I'd like to compare my empirical sequences with my predicted one. What would you suggest to be the best strategy or property to look at? Regards,",,"['algebra-precalculus', 'statistics']"
57,Exponential Families and Riemannian Symmetric Spaces,Exponential Families and Riemannian Symmetric Spaces,,Suppose the $f_{X}(x|\theta)$ is a probability density function from an exponential family. Is it true that the Riemannian manifold which has the Fisher information as it's Riemannian metric is a homogeneous space? Better yet is it a Riemannian symmetric space?,Suppose the $f_{X}(x|\theta)$ is a probability density function from an exponential family. Is it true that the Riemannian manifold which has the Fisher information as it's Riemannian metric is a homogeneous space? Better yet is it a Riemannian symmetric space?,,"['linear-algebra', 'statistics', 'manifolds']"
58,Probability that a normal distribution is greater than two others,Probability that a normal distribution is greater than two others,,"Given 3 independent variables with normal distributions, how can I calculate the probability that one of them will be greater than the other two simultaneously? So, how to calculate $P ((A>B) \bigcap (A>C))$ with $A=N(\mu_A,\sigma_A)$ $B=N(\mu_B,\sigma_B)$ $C=N(\mu_C,\sigma_C)$ I know how to calculate $P(A>B)$, since $P(A>B) = P(A-B>0)$, where $A-B$ has a normal distribution with $\mu = \mu_A - \mu_B$ and $\sigma^2= (\sigma_A)^2 + (\sigma_A)^2$ I'm also aware of the formula for conditional probability $P ((A>B) \bigcap (A>C)) = P (A>B) P(A>C|A>B)$ But I'm lost as to how to calculate $P(A>C|A>B)$ (or any other way to solve this).","Given 3 independent variables with normal distributions, how can I calculate the probability that one of them will be greater than the other two simultaneously? So, how to calculate $P ((A>B) \bigcap (A>C))$ with $A=N(\mu_A,\sigma_A)$ $B=N(\mu_B,\sigma_B)$ $C=N(\mu_C,\sigma_C)$ I know how to calculate $P(A>B)$, since $P(A>B) = P(A-B>0)$, where $A-B$ has a normal distribution with $\mu = \mu_A - \mu_B$ and $\sigma^2= (\sigma_A)^2 + (\sigma_A)^2$ I'm also aware of the formula for conditional probability $P ((A>B) \bigcap (A>C)) = P (A>B) P(A>C|A>B)$ But I'm lost as to how to calculate $P(A>C|A>B)$ (or any other way to solve this).",,"['probability', 'statistics', 'probability-distributions']"
59,Standardized Normal Distribution Problem,Standardized Normal Distribution Problem,,"Mopeds (small motorcycles with an engine capacity below $50~cm^3$ ) are very popular in Europe because of their mobility, ease of operation, and low cost. The article Procedure to Verify the Maximum Speed of Automatic Transmission Mopeds in Periodic Motor Vehicle Inspections (J. of Automobile Engr.,2008: 16151623) described a rolling bench test for determining maximum vehicle speed.A normal distribution with mean value 46.8 km/h and standard deviation 1.75 km/h is postulated. Consider randomly selecting a single such moped. a.What is the probability that maximum speed is at most 50 km/h? b.What is the probability that maximum speed is at least 48 km/h? c. What is the probability that maximum speed differs from the mean value by at most 1.5 standard deviations? I am working on part c), at the moment. How I calculated it was in terms of the adjusted mean and deviation: $P( \mu - \sigma \le Z \le \mu + \sigma) = P(-\sigma \le Z \le \sigma) = P(-1.5 \le Z \le 1.5) = \phi(1.5) - \phi(-1.5)$ This doesn't lead to the correct answer. What have I done wrong?","Mopeds (small motorcycles with an engine capacity below ) are very popular in Europe because of their mobility, ease of operation, and low cost. The article Procedure to Verify the Maximum Speed of Automatic Transmission Mopeds in Periodic Motor Vehicle Inspections (J. of Automobile Engr.,2008: 16151623) described a rolling bench test for determining maximum vehicle speed.A normal distribution with mean value 46.8 km/h and standard deviation 1.75 km/h is postulated. Consider randomly selecting a single such moped. a.What is the probability that maximum speed is at most 50 km/h? b.What is the probability that maximum speed is at least 48 km/h? c. What is the probability that maximum speed differs from the mean value by at most 1.5 standard deviations? I am working on part c), at the moment. How I calculated it was in terms of the adjusted mean and deviation: This doesn't lead to the correct answer. What have I done wrong?",50~cm^3 P( \mu - \sigma \le Z \le \mu + \sigma) = P(-\sigma \le Z \le \sigma) = P(-1.5 \le Z \le 1.5) = \phi(1.5) - \phi(-1.5),"['probability', 'statistics', 'normal-distribution']"
60,Does this count as a Monte Carlo simulation?,Does this count as a Monte Carlo simulation?,,"Let's say I have a group of robots that walk on a 11x11 grid of tiles in four directions, N, S, E, W, and each robot has different probability distribution functions that assign different probabilities to each of the four outcomes per move. If I want to know how many moves it will take on average for each robot to exit the grid and also how often on average it will exit on a particular side (N S E W), and so I run a simulation for 1000s of iterations for each robot to determine mean averages, does this count as a Monte Carlo simulation?","Let's say I have a group of robots that walk on a 11x11 grid of tiles in four directions, N, S, E, W, and each robot has different probability distribution functions that assign different probabilities to each of the four outcomes per move. If I want to know how many moves it will take on average for each robot to exit the grid and also how often on average it will exit on a particular side (N S E W), and so I run a simulation for 1000s of iterations for each robot to determine mean averages, does this count as a Monte Carlo simulation?",,"['probability', 'statistics', 'monte-carlo']"
61,On the empirical mean and variance of a Poisson i.i.d. sample,On the empirical mean and variance of a Poisson i.i.d. sample,,"Let $X_1, X_2, \ldots, X_n$ be a random sample from a Poisson($\lambda$) distribution. Let ($\bar{X}$) be their sample mean and $s^2$ their sample variance. Show that $\frac{\sqrt{n}[\bar{X}-\lambda]}{\sqrt{\bar{X}}}$ and $\frac{\sqrt{n}[\bar{X}-\lambda]}{s}$ both have a standard normal limiting distribution. Find the limiting distribution of $\sqrt{n}[\bar{X}-\lambda]^2$ Find the limiting distribution of $\sqrt{n}[\bar{X}^2-\lambda^2]$ 1) For $\frac{\sqrt{n}[\bar{X}-\lambda]}{S}$, we know that $\frac{\sqrt{n}[\bar{X}-\lambda]}{S}$ = $(\frac{\sqrt{n}[\bar{X}-\lambda]}{\sigma})(\frac{\sigma}{S})$. Since  $\frac{\sqrt{n}[\bar{X}-\lambda]}{\sigma}$ appraches N(0,1) in distribution by CLT, and since $(\frac{\sigma}{S})$ appraches 1 in probability, the whole thing approaches N(0,1). For $\frac{\sqrt{n}[\bar{X}-\lambda]}{\sqrt{\bar{X}}}$, we get the same result...since the mean is equal to the variance in a poisson distribution. 2) I'm a little confused about this one... 3) From a theorem in my textbook, I know that if $\sqrt{n}(X_n - \theta) \rightarrow N(0,\sigma^2)$ and if there is a differentiable function g(x) at theta where the derivative at theta is not zero...then $\sqrt{n}(g(X_n)-g(\theta)) \rightarrow N(0,\sigma^2(g'(\theta))^2)$. So I just need to use this theorem, right? And in this case $g(x)=x^2$. Do you think my answer for 1), and 3) are correct? Also, can you give me a hint for 2)? Thanks in advance","Let $X_1, X_2, \ldots, X_n$ be a random sample from a Poisson($\lambda$) distribution. Let ($\bar{X}$) be their sample mean and $s^2$ their sample variance. Show that $\frac{\sqrt{n}[\bar{X}-\lambda]}{\sqrt{\bar{X}}}$ and $\frac{\sqrt{n}[\bar{X}-\lambda]}{s}$ both have a standard normal limiting distribution. Find the limiting distribution of $\sqrt{n}[\bar{X}-\lambda]^2$ Find the limiting distribution of $\sqrt{n}[\bar{X}^2-\lambda^2]$ 1) For $\frac{\sqrt{n}[\bar{X}-\lambda]}{S}$, we know that $\frac{\sqrt{n}[\bar{X}-\lambda]}{S}$ = $(\frac{\sqrt{n}[\bar{X}-\lambda]}{\sigma})(\frac{\sigma}{S})$. Since  $\frac{\sqrt{n}[\bar{X}-\lambda]}{\sigma}$ appraches N(0,1) in distribution by CLT, and since $(\frac{\sigma}{S})$ appraches 1 in probability, the whole thing approaches N(0,1). For $\frac{\sqrt{n}[\bar{X}-\lambda]}{\sqrt{\bar{X}}}$, we get the same result...since the mean is equal to the variance in a poisson distribution. 2) I'm a little confused about this one... 3) From a theorem in my textbook, I know that if $\sqrt{n}(X_n - \theta) \rightarrow N(0,\sigma^2)$ and if there is a differentiable function g(x) at theta where the derivative at theta is not zero...then $\sqrt{n}(g(X_n)-g(\theta)) \rightarrow N(0,\sigma^2(g'(\theta))^2)$. So I just need to use this theorem, right? And in this case $g(x)=x^2$. Do you think my answer for 1), and 3) are correct? Also, can you give me a hint for 2)? Thanks in advance",,['probability']
62,Calculating Total Field Goals Using Poisson,Calculating Total Field Goals Using Poisson,,"With the Super Bowl around the corner, I've been attempting to price various prop bets. My question is, can I use the Poisson distribution to calculate the odds of the total number of field goals being over/under a certain amount? So far, my approach has been to generate a table of the odds of each possible combination of field goals such as 3-0, and then sum up the probabilities of each of the events that would result in being over/under for the bet. Does this work? I feel like I might be overlooking some correlation between the number of field goals one team kicks and the number of field goals the other team kicks. I just used the average number of field goals kicked for the last 16 games or so to do all my calculations.","With the Super Bowl around the corner, I've been attempting to price various prop bets. My question is, can I use the Poisson distribution to calculate the odds of the total number of field goals being over/under a certain amount? So far, my approach has been to generate a table of the odds of each possible combination of field goals such as 3-0, and then sum up the probabilities of each of the events that would result in being over/under for the bet. Does this work? I feel like I might be overlooking some correlation between the number of field goals one team kicks and the number of field goals the other team kicks. I just used the average number of field goals kicked for the last 16 games or so to do all my calculations.",,['probability']
63,"CDF of $\max(x_1,x_2)+\max(x_3,x_4)$ where all $x_i$s are iid from $U[a,b]$",CDF of  where all s are iid from,"\max(x_1,x_2)+\max(x_3,x_4) x_i U[a,b]","I am looking for the cumulative density function of the sum of two variables, which are themselves the result of a rank order process. Thus, if $x_1, x_2, x_3$ and $x_4$ are all independent draws from a uniform distribution with support $[a,b]$, what is the CDF for $\max(x_1,x_2)+\max(x_3,x_4)$? Thanks.","I am looking for the cumulative density function of the sum of two variables, which are themselves the result of a rank order process. Thus, if $x_1, x_2, x_3$ and $x_4$ are all independent draws from a uniform distribution with support $[a,b]$, what is the CDF for $\max(x_1,x_2)+\max(x_3,x_4)$? Thanks.",,['statistics']
64,Regressing $Y$ back on the residuals,Regressing  back on the residuals,Y,"Suppose I have the linear regression model $ \hat{y_i} = a + b x_i $ for $a,b$ obtained via OLS. How does one regress $y$ back on the residuals $\hat{e}_i = y_i - \hat{y}_i$? If we write $ \hat{\hat{y_i}} = c + d \hat{e}_i$ and attempt to use the regression coefficient formulas, I'm unsure how to write $c$ and $d$ in terms of $a,b$.","Suppose I have the linear regression model $ \hat{y_i} = a + b x_i $ for $a,b$ obtained via OLS. How does one regress $y$ back on the residuals $\hat{e}_i = y_i - \hat{y}_i$? If we write $ \hat{\hat{y_i}} = c + d \hat{e}_i$ and attempt to use the regression coefficient formulas, I'm unsure how to write $c$ and $d$ in terms of $a,b$.",,"['statistics', 'regression']"
65,Expected number of cumulative distinct values when sampling with replacement from a changing population over time,Expected number of cumulative distinct values when sampling with replacement from a changing population over time,,"I'm trying to estimate the cumulative number of distinct values when sampling with replacement from a changing population of integers over time. Concretely (and forgive my awful notation here), I'm assuming that there is some initial population ($m_0 = \{0,1,2,...n_0\}$) which experiences a constant rate $d$ at which members are removed from the pool and a constant rate   $a$ at which members are added. Which members are removed is random, s.t. the size of a set at some time period can be written as:$$|m_t| = |m_{t-1}| * (1 + a - d)$$ I know that for some set time period the estimated number of distinct values I see when drawing $s$ samples from a population of size $p$ is one of the solutions to the Birthday Problem, i.e.: $$p*(1-(1-1/p)^s)$$ At this point, however, I'm a little stuck. I'm tempted to try to go the route of estimating the expected number of set members not seen in a cumulative time period, and I've also been encouraged to try to solve a more incremental version of the above problem as a stepping-stone (e.g. to try and solve the case where after each sample is taken the underlying population increases by one) At this point I've spent a good couple of hours trying to find any leads on this and haven't  had much success, so any and all pointers, help, etc. would be appreciated. Thanks!","I'm trying to estimate the cumulative number of distinct values when sampling with replacement from a changing population of integers over time. Concretely (and forgive my awful notation here), I'm assuming that there is some initial population ($m_0 = \{0,1,2,...n_0\}$) which experiences a constant rate $d$ at which members are removed from the pool and a constant rate   $a$ at which members are added. Which members are removed is random, s.t. the size of a set at some time period can be written as:$$|m_t| = |m_{t-1}| * (1 + a - d)$$ I know that for some set time period the estimated number of distinct values I see when drawing $s$ samples from a population of size $p$ is one of the solutions to the Birthday Problem, i.e.: $$p*(1-(1-1/p)^s)$$ At this point, however, I'm a little stuck. I'm tempted to try to go the route of estimating the expected number of set members not seen in a cumulative time period, and I've also been encouraged to try to solve a more incremental version of the above problem as a stepping-stone (e.g. to try and solve the case where after each sample is taken the underlying population increases by one) At this point I've spent a good couple of hours trying to find any leads on this and haven't  had much success, so any and all pointers, help, etc. would be appreciated. Thanks!",,"['combinatorics', 'statistics']"
66,Estimate population size based on first repeat,Estimate population size based on first repeat,,"https://mathoverflow.net/questions/14964/estimate-population-size-based-on-repeated-observation asks the following question. I take the bus to work every day. Every bus has a serial number, but   unlike in the German Tank Problem, I don't know if they are numbered   uniformly $1...n$. Suppose the first $k$ buses are all different, but on day $k+1$ I take   one I've been on before. What is the best estimate for the total   number of buses? The provided answer gives a maximum likelihood estimator as well as an unbiased estimator of $k(k+1)/2$ If you know the number of buses can't be larger than some given value $N \geq k+1$, how does that change the maximum likelihood estimator and the unbiased estimator ?","https://mathoverflow.net/questions/14964/estimate-population-size-based-on-repeated-observation asks the following question. I take the bus to work every day. Every bus has a serial number, but   unlike in the German Tank Problem, I don't know if they are numbered   uniformly $1...n$. Suppose the first $k$ buses are all different, but on day $k+1$ I take   one I've been on before. What is the best estimate for the total   number of buses? The provided answer gives a maximum likelihood estimator as well as an unbiased estimator of $k(k+1)/2$ If you know the number of buses can't be larger than some given value $N \geq k+1$, how does that change the maximum likelihood estimator and the unbiased estimator ?",,"['probability', 'statistics']"
67,What is the distribution of the sum of absolute differences?,What is the distribution of the sum of absolute differences?,,"Suppose there is a $2\times2$ matrix $O$ of observed values: $$O = \begin{bmatrix}o_{11}&o_{12}\\o_{21}&o_{22}\end{bmatrix}$$ and two matrices $E_1$ and $E_2$ of expected values: $$E_1 = \begin{bmatrix}e'_{11}&e'_{12}\\e'_{21}&e'_{22}\end{bmatrix}\text{ and } E_2 = \begin{bmatrix}e''_{11}&e''_{12}\\e''_{21}&e''_{22}\end{bmatrix}.$$ The total misallocation supposing $O$ is distributed according to $E_1$ is $$L_1=\frac{1}{2}\left(\left|o_{11} - e'_{11}\right| + \left|o_{12} - e'_{12}\right| + \left|o_{21} - e'_{21}\right| + \left|o_{22} - e'_{22}\right|\right)$$ and the total misallocation supposing O is distributed according to $E_2$ is $$L_2=\frac{1}{2}\left(\left|o_{11} - e''_{11}\right| + \left|o_{12} - e''_{12}\right| + \left|o_{21} - e''_{21}\right| + \left|o_{22} - e''_{22}\right|\right).$$ My question is, how can I measure how much better $E_1$ or $E_2$ is at representing $O$. Initially, I thought I could use a Chi-Squared or F distribution type test, but I don't know the distributions of $L_1$ and $L_2$. Any help would be appreciated.","Suppose there is a $2\times2$ matrix $O$ of observed values: $$O = \begin{bmatrix}o_{11}&o_{12}\\o_{21}&o_{22}\end{bmatrix}$$ and two matrices $E_1$ and $E_2$ of expected values: $$E_1 = \begin{bmatrix}e'_{11}&e'_{12}\\e'_{21}&e'_{22}\end{bmatrix}\text{ and } E_2 = \begin{bmatrix}e''_{11}&e''_{12}\\e''_{21}&e''_{22}\end{bmatrix}.$$ The total misallocation supposing $O$ is distributed according to $E_1$ is $$L_1=\frac{1}{2}\left(\left|o_{11} - e'_{11}\right| + \left|o_{12} - e'_{12}\right| + \left|o_{21} - e'_{21}\right| + \left|o_{22} - e'_{22}\right|\right)$$ and the total misallocation supposing O is distributed according to $E_2$ is $$L_2=\frac{1}{2}\left(\left|o_{11} - e''_{11}\right| + \left|o_{12} - e''_{12}\right| + \left|o_{21} - e''_{21}\right| + \left|o_{22} - e''_{22}\right|\right).$$ My question is, how can I measure how much better $E_1$ or $E_2$ is at representing $O$. Initially, I thought I could use a Chi-Squared or F distribution type test, but I don't know the distributions of $L_1$ and $L_2$. Any help would be appreciated.",,['statistics']
68,Multinomial Distribution to Binomial Distribution and Joint Probability Function,Multinomial Distribution to Binomial Distribution and Joint Probability Function,,"I'm having trouble with a few multinomial questions. I know that for a multinomial distribution we have: $$p_1+p_2+\dots+p_k=1$$ $$X_1+X_2+\dots+X_k=n$$ For $(X_1,\dots,X_{10}) $ Mult$(n,p_1, ,p_{10})$ I need show that: $X_1$ ~ $Bi(n,p_1)$ $f_{X_1, X_2}(x_1,x_2)=	\frac{n!}{x_1!x_2!(n-x_1-x_2)!}p_1^{x_1}p_2^{x_2}(1p_1p_2 )^{nx1x2}I(nx_1x_2)$","I'm having trouble with a few multinomial questions. I know that for a multinomial distribution we have: $$p_1+p_2+\dots+p_k=1$$ $$X_1+X_2+\dots+X_k=n$$ For $(X_1,\dots,X_{10}) $ Mult$(n,p_1, ,p_{10})$ I need show that: $X_1$ ~ $Bi(n,p_1)$ $f_{X_1, X_2}(x_1,x_2)=	\frac{n!}{x_1!x_2!(n-x_1-x_2)!}p_1^{x_1}p_2^{x_2}(1p_1p_2 )^{nx1x2}I(nx_1x_2)$",,"['probability', 'statistics']"
69,Questions on Bayesian analysis of an opinion poll (an example in a book),Questions on Bayesian analysis of an opinion poll (an example in a book),,"I'm sorry in advance for rather long questions. This is an example in ""Bayesian logical data analysis for physical sciences"" by P. C. Gregory and I have some questions about the example. In a poll of 800 decided voters, 440 voters supported the political party A. Let's denote the poll result as $D$. The quantity of interest is the probability that the party A will achieve a majority of at least 51% in the upcoming election, assuming the poll will be representative of the population at the time of the election. The book regards the problem as a model selection problem. $M_1$ : The party A will achieve a majority with a parameter $H$ that has uniform prior in the range $0.51 \le H \le 1$. $M_2$ : The party A will not achieve a majority with a parameter $H$ that has uniform prior in the range $0 \le H < 0.51$. If we have no prior reason to prefer $M_1$ over $M_2$, we can write the odds ratio $$\begin{aligned} O_{12}&=p(M_1|D,I)/p(M_2|D,I)\\ &=p(D|M_1,I)/p(D|M_2,I)\\ &=\frac{\int_{0.51}^1 p(H|M_1,I)p(D|H,M_1,I) dH }{\int_{0}^{0.51} p(H|M_2,I)p(D|H,M_2,I) dH}\\ &=\frac{\int_{0.51}^1 (1/0.49)p(D|H,M_1,I) dH }{\int_{0}^{0.51} (1/0.51)p(D|H,M_2,I) dH}\\ &=87.68 \end{aligned}$$ Here are my questions. The book don't give explicit expressions for $p(D|H,M_1,I)$ and $p(D|H,M_2,I)$. If I use binomial distribution $$p(D|H,M_1,I)=p(D|H,M_2,I)=\frac{800! H^{440}(1-H)^{800-440}}{440!(800-440)!}$$ I get $87.03$ as a result. It is not same to the value $87.68$ of the Book. What probability distribution should I use for the likelihoods? I have another question. Why do I have to introduce the models $M_1$ and $M_2$? Is $$ O_{12}=\frac{\int_{0.51}^1 p(H|D,I) dH}{\int_{0}^{0.51} p(H|D,I) dH} $$ not an appropriate aproach for the problem? It does not have the factor $(1/0.49)/(1/0.51)$ introduced with the models $M_1$ and $M_2$.","I'm sorry in advance for rather long questions. This is an example in ""Bayesian logical data analysis for physical sciences"" by P. C. Gregory and I have some questions about the example. In a poll of 800 decided voters, 440 voters supported the political party A. Let's denote the poll result as $D$. The quantity of interest is the probability that the party A will achieve a majority of at least 51% in the upcoming election, assuming the poll will be representative of the population at the time of the election. The book regards the problem as a model selection problem. $M_1$ : The party A will achieve a majority with a parameter $H$ that has uniform prior in the range $0.51 \le H \le 1$. $M_2$ : The party A will not achieve a majority with a parameter $H$ that has uniform prior in the range $0 \le H < 0.51$. If we have no prior reason to prefer $M_1$ over $M_2$, we can write the odds ratio $$\begin{aligned} O_{12}&=p(M_1|D,I)/p(M_2|D,I)\\ &=p(D|M_1,I)/p(D|M_2,I)\\ &=\frac{\int_{0.51}^1 p(H|M_1,I)p(D|H,M_1,I) dH }{\int_{0}^{0.51} p(H|M_2,I)p(D|H,M_2,I) dH}\\ &=\frac{\int_{0.51}^1 (1/0.49)p(D|H,M_1,I) dH }{\int_{0}^{0.51} (1/0.51)p(D|H,M_2,I) dH}\\ &=87.68 \end{aligned}$$ Here are my questions. The book don't give explicit expressions for $p(D|H,M_1,I)$ and $p(D|H,M_2,I)$. If I use binomial distribution $$p(D|H,M_1,I)=p(D|H,M_2,I)=\frac{800! H^{440}(1-H)^{800-440}}{440!(800-440)!}$$ I get $87.03$ as a result. It is not same to the value $87.68$ of the Book. What probability distribution should I use for the likelihoods? I have another question. Why do I have to introduce the models $M_1$ and $M_2$? Is $$ O_{12}=\frac{\int_{0.51}^1 p(H|D,I) dH}{\int_{0}^{0.51} p(H|D,I) dH} $$ not an appropriate aproach for the problem? It does not have the factor $(1/0.49)/(1/0.51)$ introduced with the models $M_1$ and $M_2$.",,"['probability', 'statistics', 'bayesian']"
70,Estimating a sample mean using sub-sample means,Estimating a sample mean using sub-sample means,,"we collect a lot of data on a daily basis via an API, and part of this data includes fields that represent sample means. Specifically, we get provided with a sample mean and the sample size, lets call them avg_pos and impressions . If you can't tell yet, the domain is advertising, avg_pos tells us the average position our ad showed in over the period of a day, and impressions tells us how many impressions we got (the size of the sample used for avg_pos ). Now, suppose I want to get the average position for a 30 day period  we only have available to us 30 avg_pos values and 30 impressions values. The sum of impressions is the amount of impressions over the entire period. Question: intuitively I think one way to estimate the 30 day average position would be to do something like: $$ total\_impressions = \sum impressions \\ \sum avg\_pos * \frac{impressions}{total\_impressions} $$ Can someone explain the implications of this approach, and when it is likely to be accurate and when it is not? I assume its accuracy will depend on how normally distributed all the position values are that make up the avg_pos sample means.","we collect a lot of data on a daily basis via an API, and part of this data includes fields that represent sample means. Specifically, we get provided with a sample mean and the sample size, lets call them avg_pos and impressions . If you can't tell yet, the domain is advertising, avg_pos tells us the average position our ad showed in over the period of a day, and impressions tells us how many impressions we got (the size of the sample used for avg_pos ). Now, suppose I want to get the average position for a 30 day period  we only have available to us 30 avg_pos values and 30 impressions values. The sum of impressions is the amount of impressions over the entire period. Question: intuitively I think one way to estimate the 30 day average position would be to do something like: $$ total\_impressions = \sum impressions \\ \sum avg\_pos * \frac{impressions}{total\_impressions} $$ Can someone explain the implications of this approach, and when it is likely to be accurate and when it is not? I assume its accuracy will depend on how normally distributed all the position values are that make up the avg_pos sample means.",,"['statistics', 'average', 'estimation']"
71,How can I calculate how many iterations of a benchmark test to do?,How can I calculate how many iterations of a benchmark test to do?,,"I have a test which benchmarks the performance of my 3D rendering software, in frames per second. I run the test for each revision of my rendering software to check that I'm improving performance. For any given revision, each test run gives a slightly different result, so I actually run the test a number of times and track the mean and variance for each revision. Each test run takes a reasonable duration of time, so I would like to find the minimum number of iterations that will give me confidence in the mean value that I measure. Any suggestions on how to frame this problem statistically would be much appreciated.","I have a test which benchmarks the performance of my 3D rendering software, in frames per second. I run the test for each revision of my rendering software to check that I'm improving performance. For any given revision, each test run gives a slightly different result, so I actually run the test a number of times and track the mean and variance for each revision. Each test run takes a reasonable duration of time, so I would like to find the minimum number of iterations that will give me confidence in the mean value that I measure. Any suggestions on how to frame this problem statistically would be much appreciated.",,['statistics']
72,Which statistics are sufficient?,Which statistics are sufficient?,,"Can anyone help explain why the following statistics are either Sufficient or not Sufficient? Mode, Mean, Median, Standard Deviation, Skewness, Kurtosis, Range, IQR","Can anyone help explain why the following statistics are either Sufficient or not Sufficient? Mode, Mean, Median, Standard Deviation, Skewness, Kurtosis, Range, IQR",,['statistics']
73,Expectation of max of independent (unknown distribution) random variables.,Expectation of max of independent (unknown distribution) random variables.,,"Let's say we have 50 independent random variables $X_i$ with the same distribution. Let's also say that $E(X_i) = \mu$ and $Var(X_i) = \sigma^2 > 0$ are known values. Is it possible to determine a (non trivial) lower bound for $E(\max X_i)$? I've found some questions here concerning uniform distributions, but I was wondering if we could say something about this question when distribution of $X_i$s is unknown (other than ($E(\max X_i)\geq \mu)$).","Let's say we have 50 independent random variables $X_i$ with the same distribution. Let's also say that $E(X_i) = \mu$ and $Var(X_i) = \sigma^2 > 0$ are known values. Is it possible to determine a (non trivial) lower bound for $E(\max X_i)$? I've found some questions here concerning uniform distributions, but I was wondering if we could say something about this question when distribution of $X_i$s is unknown (other than ($E(\max X_i)\geq \mu)$).",,"['probability', 'statistics', 'random-variables']"
74,Hypergeometric distribution with a random number of draws?,Hypergeometric distribution with a random number of draws?,,"I was wondering if any classical distributions can be arrived at via a hypergeometric r.v. where the number of draws from the urn is also a random variable? Ideally I would like the sample space for the number of draws to be over [0,$\infty$], so a gamma distribution is my first thought. Through some research I have found out and understood the proof for why a poisson r.v. with gamma distributed mean is a negative binomial r.v. So at worst I think I could use the poisson to approximate the hypergeometric, and thus the negative binomial result should work to approximate the hypergeometric with a gamma random number of draws (unless I am thinking about this completely wrong). However an analytic result would be preferable to an approximation.","I was wondering if any classical distributions can be arrived at via a hypergeometric r.v. where the number of draws from the urn is also a random variable? Ideally I would like the sample space for the number of draws to be over [0,$\infty$], so a gamma distribution is my first thought. Through some research I have found out and understood the proof for why a poisson r.v. with gamma distributed mean is a negative binomial r.v. So at worst I think I could use the poisson to approximate the hypergeometric, and thus the negative binomial result should work to approximate the hypergeometric with a gamma random number of draws (unless I am thinking about this completely wrong). However an analytic result would be preferable to an approximation.",,"['probability', 'statistics', 'probability-distributions']"
75,Exact percentile of random variables sum,Exact percentile of random variables sum,,"For a list of empirical random variables $x_1, \ldots, x_n$ where each is given by approx. $7000$ sample values, is there a fast way to calculate a $y$% percentile of $\sum_{i=1}^n x_i$? I have asked this qustion on stackoverflow.com as without employing any math the problem is of exponential complexity (basically unsolvable for $n > 4$), to no avail. No specific information about the distributions of $x_1,\ldots,x_n$ is given. They are neither normal, nor symetric. Nor do they have comparable means and ranges. $n$ is expected to be somewhere in the $2,\ldots, 720$ range, hence Central Limit Theorem can be applied only for a subset of required n values. Any hint is much appreciated. Daniel","For a list of empirical random variables $x_1, \ldots, x_n$ where each is given by approx. $7000$ sample values, is there a fast way to calculate a $y$% percentile of $\sum_{i=1}^n x_i$? I have asked this qustion on stackoverflow.com as without employing any math the problem is of exponential complexity (basically unsolvable for $n > 4$), to no avail. No specific information about the distributions of $x_1,\ldots,x_n$ is given. They are neither normal, nor symetric. Nor do they have comparable means and ranges. $n$ is expected to be somewhere in the $2,\ldots, 720$ range, hence Central Limit Theorem can be applied only for a subset of required n values. Any hint is much appreciated. Daniel",,"['probability', 'statistics']"
76,Parameter optimization in probabilistic models,Parameter optimization in probabilistic models,,"Task: Suppose we model a variable $y = Wx + \mu$ as a linear transformation of $x$ plus some Gaussian noise $\mu\sim\mathcal N(0,\sigma I)$. Our aim is to minimize the estimation error of $x$ given $y$ in terms of $W$, i.e. we want to minimize the entropy $H(x|y,W)$ as a function of $W$. Suppose that, during learning, we know $x$ for every observed state $y$: what is the optimal supervised update of the model parameters $W$? The problem is: I can't wrap my head around the question how I come - in a rigorous way - from the estimation problem that I want to solve to the parameter updates that depend on the variable I want to estimate. It's probably a standard procedure but the problem is hard to nail down to Google-friendly buzzwords. Thanks in advance!! blue2script","Task: Suppose we model a variable $y = Wx + \mu$ as a linear transformation of $x$ plus some Gaussian noise $\mu\sim\mathcal N(0,\sigma I)$. Our aim is to minimize the estimation error of $x$ given $y$ in terms of $W$, i.e. we want to minimize the entropy $H(x|y,W)$ as a function of $W$. Suppose that, during learning, we know $x$ for every observed state $y$: what is the optimal supervised update of the model parameters $W$? The problem is: I can't wrap my head around the question how I come - in a rigorous way - from the estimation problem that I want to solve to the parameter updates that depend on the variable I want to estimate. It's probably a standard procedure but the problem is hard to nail down to Google-friendly buzzwords. Thanks in advance!! blue2script",,"['statistics', 'normal-distribution', 'parameter-estimation', 'entropy']"
77,"rate of convergence of mean ,variance & skewness estimators","rate of convergence of mean ,variance & skewness estimators",,"We are asked a question which of mean,variance or skewness converges faster. At first I thought it was straight forward answer: mean->variance->skewness. But I am not sure anymore because I read somewhere standard error of the mean estimator is only slightly smaller. std_error_of_mean=sigma/sqrt(n) std_error_of_varaince=sqrt(2) * (sigma^2)/sqrt(n) So it is only sqrt(2) times better ? I am not a statician, so can some one please explain what the general pattern is for standard error of higher order moments. Also are there equations for the rate of convergence of moments, so that I could compare with observation. Thank you","We are asked a question which of mean,variance or skewness converges faster. At first I thought it was straight forward answer: mean->variance->skewness. But I am not sure anymore because I read somewhere standard error of the mean estimator is only slightly smaller. std_error_of_mean=sigma/sqrt(n) std_error_of_varaince=sqrt(2) * (sigma^2)/sqrt(n) So it is only sqrt(2) times better ? I am not a statician, so can some one please explain what the general pattern is for standard error of higher order moments. Also are there equations for the rate of convergence of moments, so that I could compare with observation. Thank you",,"['probability', 'statistics', 'stochastic-processes', 'standard-deviation']"
78,"Determine whether a statistic is sufficient, given the probability density","Determine whether a statistic is sufficient, given the probability density",,"Let $X_1, X_2, \dots, X_n$ be a sample of i.i.d. random variables, with density $$f_\theta=\frac{2}{3\theta}\left(1-\frac{x}{3\theta}\right) $$ for $0 < x < 3\theta$. And $f_\theta=0$ if $ x < 0$ or $ x>3\theta$ Let $\hat{\theta}=\overline{X}$ be an estimate for $\theta$ 1.) Determine whether $\theta$ is unbiased ? 2.) Determine whether $\theta$ is consistent ? 3.) Determine whether $\theta$ is sufficient ? 4.) Why doesn't the Cramer-Rao lower bound apply to unbiased estimates of $\theta$ for this distribution? I tried: 1.) $\theta$ is unbiased because the integral of $$\int_0^{3\theta}{x}\left(\frac{2}{3\theta}\left(1-\frac{x}{3\theta}\right)\right) \, dx = \theta = E[\hat{\theta}]$$Hence the statistic is unbiased. 2.) Yes, because $$\operatorname{VAR}[\hat{\theta}]=\operatorname{VAR}\left[\overline{X}\right]=\frac{\sigma^2}{n}. \lim_{n\to \infty}\left(\frac{\sigma^2}{n}\right)=0$$Hence $\theta$ is consistent. 3.)According to the factorization theorem I have to find a function $g(\hat{\theta},\theta)$ and $h(x_1,x_2,\dots ,x_n)$ so that $gh=f(x_1,x_2,...,x_n; \theta)$ I guess I have to calculate $\prod_{i=1}^{n}{f_\theta} $ and derive some function g. But I don't know how to start. Thank you for your help in advance!","Let $X_1, X_2, \dots, X_n$ be a sample of i.i.d. random variables, with density $$f_\theta=\frac{2}{3\theta}\left(1-\frac{x}{3\theta}\right) $$ for $0 < x < 3\theta$. And $f_\theta=0$ if $ x < 0$ or $ x>3\theta$ Let $\hat{\theta}=\overline{X}$ be an estimate for $\theta$ 1.) Determine whether $\theta$ is unbiased ? 2.) Determine whether $\theta$ is consistent ? 3.) Determine whether $\theta$ is sufficient ? 4.) Why doesn't the Cramer-Rao lower bound apply to unbiased estimates of $\theta$ for this distribution? I tried: 1.) $\theta$ is unbiased because the integral of $$\int_0^{3\theta}{x}\left(\frac{2}{3\theta}\left(1-\frac{x}{3\theta}\right)\right) \, dx = \theta = E[\hat{\theta}]$$Hence the statistic is unbiased. 2.) Yes, because $$\operatorname{VAR}[\hat{\theta}]=\operatorname{VAR}\left[\overline{X}\right]=\frac{\sigma^2}{n}. \lim_{n\to \infty}\left(\frac{\sigma^2}{n}\right)=0$$Hence $\theta$ is consistent. 3.)According to the factorization theorem I have to find a function $g(\hat{\theta},\theta)$ and $h(x_1,x_2,\dots ,x_n)$ so that $gh=f(x_1,x_2,...,x_n; \theta)$ I guess I have to calculate $\prod_{i=1}^{n}{f_\theta} $ and derive some function g. But I don't know how to start. Thank you for your help in advance!",,"['statistics', 'parameter-estimation', 'estimation']"
79,Symmetrizing a sequence of vectors,Symmetrizing a sequence of vectors,,"Given a finite set of real numbers $X_1, \ldots, X_n$, we can compute the first $n$ power sums of these numbers. From the power sums, the set $\{X_1, \ldots, X_n\}$ can be recovered. Essentially we lose the order by symmetrizing. What about when $X_1, \ldots, X_n$ are vectors in $\mathbb R^m$? As many pointed out, my initial statement was not clear so I'll explain what I have in mind. I am hoping these functions $f_k(Y_1, \ldots, Y_k) = \sum_{1\le i_1, \ldots, i_k\le n}\prod_{j=1}^k \langle X_{i_j}, Y_j \rangle$ will be sufficient to represent the set $\{X_1, \ldots, X_n\}$. To ""store"" $f_k$, I can pick standard basis vectors for $Y_i$ and compute the result, but then there are $m^k$ possibilities. Symmetry should be able to reduce this number, probably by $O(m!)$. (I'm guessing again.) Anyway, I still don't know if $f_1, \ldots, f_n$ will be sufficient to recover the set $\{X_1, \ldots, X_n\}$. I heard about multi-symmetric polynomials too, but I'm not sure about the set of generators to use. Does there exist an isometry-invariant set of generators? (Are my $f_k$ isometry-invariant?)","Given a finite set of real numbers $X_1, \ldots, X_n$, we can compute the first $n$ power sums of these numbers. From the power sums, the set $\{X_1, \ldots, X_n\}$ can be recovered. Essentially we lose the order by symmetrizing. What about when $X_1, \ldots, X_n$ are vectors in $\mathbb R^m$? As many pointed out, my initial statement was not clear so I'll explain what I have in mind. I am hoping these functions $f_k(Y_1, \ldots, Y_k) = \sum_{1\le i_1, \ldots, i_k\le n}\prod_{j=1}^k \langle X_{i_j}, Y_j \rangle$ will be sufficient to represent the set $\{X_1, \ldots, X_n\}$. To ""store"" $f_k$, I can pick standard basis vectors for $Y_i$ and compute the result, but then there are $m^k$ possibilities. Symmetry should be able to reduce this number, probably by $O(m!)$. (I'm guessing again.) Anyway, I still don't know if $f_1, \ldots, f_n$ will be sufficient to recover the set $\{X_1, \ldots, X_n\}$. I heard about multi-symmetric polynomials too, but I'm not sure about the set of generators to use. Does there exist an isometry-invariant set of generators? (Are my $f_k$ isometry-invariant?)",,"['probability', 'statistics', 'vector-spaces', 'symmetric-polynomials', 'symmetric-functions']"
80,elementary t-test question,elementary t-test question,,"Q: A tire manufacturer wishes to compare the tread wear of tires made of a new material with that of conventional material. 10 Cars are driven 40,000 miles as the sample set. the following data is obtained: (To avoid some confusion and messy tables I've done some of these computations myself) $\mu_{conventional}$ =4.11 $\mu_{new}$ = 4.814 $s$ = .6699 (To clarify this is the sample standard deviation of the  ""new"" material dataset) The question then is to test at $\alpha$=0.05 that the true mean of the new material exceeds that of the old material. This is a one-sided t-test. (Right?) So I've set it up the following way: $H_0 : \mu = 4.11$ $H_1 : \mu$ > 4.814 $ t = \frac{\bar{x}-\mu_0}{s/\sqrt{n}} = \frac{4.814-4.11}{.6699/\sqrt{10}}$ = 3.3233 Now to look for a .05 confidence using the t-test I obtained the value 1.833 from the t-distribution table. Since the value from our test statistic is 3.3233 > 1.833, I'd reject the Null hypothesis. Can anyone check my work to verify this?","Q: A tire manufacturer wishes to compare the tread wear of tires made of a new material with that of conventional material. 10 Cars are driven 40,000 miles as the sample set. the following data is obtained: (To avoid some confusion and messy tables I've done some of these computations myself) $\mu_{conventional}$ =4.11 $\mu_{new}$ = 4.814 $s$ = .6699 (To clarify this is the sample standard deviation of the  ""new"" material dataset) The question then is to test at $\alpha$=0.05 that the true mean of the new material exceeds that of the old material. This is a one-sided t-test. (Right?) So I've set it up the following way: $H_0 : \mu = 4.11$ $H_1 : \mu$ > 4.814 $ t = \frac{\bar{x}-\mu_0}{s/\sqrt{n}} = \frac{4.814-4.11}{.6699/\sqrt{10}}$ = 3.3233 Now to look for a .05 confidence using the t-test I obtained the value 1.833 from the t-distribution table. Since the value from our test statistic is 3.3233 > 1.833, I'd reject the Null hypothesis. Can anyone check my work to verify this?",,['statistics']
81,Variance of function-valued random variables,Variance of function-valued random variables,,"I am struggling with abstract definitions of basic statistical concepts. For a random variable $X$ which we assume to live in a real Hilbert (or even Banach) space $\mathcal{H}$, its expectation is defined as an element $\mathbb{E}[X] \in \mathcal{H}$ such that $$ \mathbb{E}[y^*(X)] = y^*(\mathbb{E}[X])$$ for all $y^{*} \in \mathcal{H}^{*}$, the dual space of $\mathcal{H}$. This is fine and to simplify, let's assume that $\mathbb{E}[X] = 0$. How can I then define the variance of $X$? Is it correct to say that it's then equal to $\text{Var}(X) = \mathbb{E}[(y^{*}(X))^2]$. Won't it depend on the choice of $y^{*}$? I am pretty confused here. Please let me know if the statements aren't clear (or true). EDIT : any textbook references on this kind of theory will be kindly appreciated!","I am struggling with abstract definitions of basic statistical concepts. For a random variable $X$ which we assume to live in a real Hilbert (or even Banach) space $\mathcal{H}$, its expectation is defined as an element $\mathbb{E}[X] \in \mathcal{H}$ such that $$ \mathbb{E}[y^*(X)] = y^*(\mathbb{E}[X])$$ for all $y^{*} \in \mathcal{H}^{*}$, the dual space of $\mathcal{H}$. This is fine and to simplify, let's assume that $\mathbb{E}[X] = 0$. How can I then define the variance of $X$? Is it correct to say that it's then equal to $\text{Var}(X) = \mathbb{E}[(y^{*}(X))^2]$. Won't it depend on the choice of $y^{*}$? I am pretty confused here. Please let me know if the statements aren't clear (or true). EDIT : any textbook references on this kind of theory will be kindly appreciated!",,['statistics']
82,Birth-death process invariant distribution,Birth-death process invariant distribution,,"Let $X_n$ be a birth-death process, with birth rates $\lambda_n$ and death rates $\mu_n$ (with $\mu_o=0$ and $\lambda_{-1}=0$). How do you show that the invariant distribution $\pi_i$ is: $\pi_0=\Big[ 1+ \sum_{k=0}^\infty \frac{\lambda_k\lambda_{k-1}\dots\lambda_0}{\mu_{k+1}\mu_k\dots \mu_1}\Big]^{-1}$ and $\pi_{n+1}=\frac{\lambda_n}{\mu_{n+1}}\pi_n$? I used the definition of invariant distribution, and arrived at the formula $\pi_i=\frac{\pi_{i-1}\lambda_{i-1}+\pi_{i+1}\mu_{i+1}}{\lambda_i+\mu_i}$, but I have no idea how to use this to prove what I'm being asked to prove.","Let $X_n$ be a birth-death process, with birth rates $\lambda_n$ and death rates $\mu_n$ (with $\mu_o=0$ and $\lambda_{-1}=0$). How do you show that the invariant distribution $\pi_i$ is: $\pi_0=\Big[ 1+ \sum_{k=0}^\infty \frac{\lambda_k\lambda_{k-1}\dots\lambda_0}{\mu_{k+1}\mu_k\dots \mu_1}\Big]^{-1}$ and $\pi_{n+1}=\frac{\lambda_n}{\mu_{n+1}}\pi_n$? I used the definition of invariant distribution, and arrived at the formula $\pi_i=\frac{\pi_{i-1}\lambda_{i-1}+\pi_{i+1}\mu_{i+1}}{\lambda_i+\mu_i}$, but I have no idea how to use this to prove what I'm being asked to prove.",,"['statistics', 'stochastic-processes']"
83,What are problems an $M$ - estimator is trying to solve?,What are problems an  - estimator is trying to solve?,M,Anyone here have any experience with $M$ - estimators and do you think you can give a brief explanation that the problem an $M$ - estimator is trying to solve ?  Thanks.,Anyone here have any experience with $M$ - estimators and do you think you can give a brief explanation that the problem an $M$ - estimator is trying to solve ?  Thanks.,,"['statistics', 'robust-statistics']"
84,MDS and low distortion embeddings,MDS and low distortion embeddings,,"While googling about low distortion embeddings, I feel that there are two separate communities working on the subject of low distortion embedding, without much communication with each other. In particular, I see a math community, refering to Johnson Lindenstrauss Lemma, Bourgain's theorem and its various refinements, some constructive methods for such low distortion embeddings with Frechet type embeddings, the work from Matousek or Indyk etc. A typical paper would be: Advances in Metric Embedding Theory A typical lecture : James Lee's lecture or Indyk's lecture On the other hand, I see a stat/CS community, working on Multi Dimensional Scaling (MDS) or IsoMaps, with method such as SMACOF, SparseMap, MetricMap, Landmark MDS etc. achieving similar results to embedd into $l_2$. A typical paper would be : Multidimensional Scaling Using Majorization: SMACOF in R or FastMap, MetricMap, and Landmark MDS are all Nystrom Algorithms A simple short lecture: UToronto's lecture The techniques are very different (Frchet embedding vs optimization techniques or spectral methods).. and hence I wonder whether these problems are actually different ? The overlap in techniques, analysis and references is almost null whereas the goal looks the same to me. Thanks!","While googling about low distortion embeddings, I feel that there are two separate communities working on the subject of low distortion embedding, without much communication with each other. In particular, I see a math community, refering to Johnson Lindenstrauss Lemma, Bourgain's theorem and its various refinements, some constructive methods for such low distortion embeddings with Frechet type embeddings, the work from Matousek or Indyk etc. A typical paper would be: Advances in Metric Embedding Theory A typical lecture : James Lee's lecture or Indyk's lecture On the other hand, I see a stat/CS community, working on Multi Dimensional Scaling (MDS) or IsoMaps, with method such as SMACOF, SparseMap, MetricMap, Landmark MDS etc. achieving similar results to embedd into $l_2$. A typical paper would be : Multidimensional Scaling Using Majorization: SMACOF in R or FastMap, MetricMap, and Landmark MDS are all Nystrom Algorithms A simple short lecture: UToronto's lecture The techniques are very different (Frchet embedding vs optimization techniques or spectral methods).. and hence I wonder whether these problems are actually different ? The overlap in techniques, analysis and references is almost null whereas the goal looks the same to me. Thanks!",,"['geometry', 'statistics', 'algorithms']"
85,Algorithm to predict next 3D points,Algorithm to predict next 3D points,,"For example, having this data: year x/y/z 2007 10/20/70 2008 20/10/70 2009 30/10/60 2010 40/10/50 2011 40/15/45 We want to predict what will be the x/y/z in 2012. We can observe that x is constantly increasing, y rather constant, z decreasing, so we can predict, for example: 2012 50/10/40 How to predict that x/y/z values? x/y/z refers to number of positive/neutral/negative sentiments in given year. We always get 100 sentiments of news for a year. In our example, in year 2007 there were 10 positive, 20 neutral and 70 negative sentiments. So, x/y/z are in range <0; 100> and x + y + z = 100. x/y/z seems to be independent. Number of consecutive years from which we are gathering data is in range <2; 10>. In example it was 5. Algorithm is going to be implemented in Python.","For example, having this data: year x/y/z 2007 10/20/70 2008 20/10/70 2009 30/10/60 2010 40/10/50 2011 40/15/45 We want to predict what will be the x/y/z in 2012. We can observe that x is constantly increasing, y rather constant, z decreasing, so we can predict, for example: 2012 50/10/40 How to predict that x/y/z values? x/y/z refers to number of positive/neutral/negative sentiments in given year. We always get 100 sentiments of news for a year. In our example, in year 2007 there were 10 positive, 20 neutral and 70 negative sentiments. So, x/y/z are in range <0; 100> and x + y + z = 100. x/y/z seems to be independent. Number of consecutive years from which we are gathering data is in range <2; 10>. In example it was 5. Algorithm is going to be implemented in Python.",,"['statistics', 'algorithms', 'approximation', 'pattern-recognition']"
86,Bayesian Estimation with Two Parameters,Bayesian Estimation with Two Parameters,,"Warning After hours of trying, it has been proven (thanks, @leonbloy) that my attempt at a solution contained lots of mistakes. Maybe the correct answer is that there is no solution, but I don't know! Homework question Let $X_1, ..., X_n$ be a random sample from a distribution with pdf: $$f_X(x | \lambda, \theta) = \lambda \, e^{-\lambda(x - \theta)} \, \mathbf{1}_{\{x \geq \theta \}}$$ The (independent) prior distributions of $\lambda$ and $\theta$ are: $$ \begin{cases} p(\lambda) = \frac{1}{\lambda^2} \, \mathbf{1}_{\{\lambda > 1\}} \\ p(\theta) = \frac{1}{\pi(1+\theta^2)} \, \mathbf{1}_{\{\theta \in \mathbf{R}\}} \end{cases} $$ The goal is to find Bayesian estimates under quadratic loss of $\lambda$ and $\theta$. First approach What we want is to find $\mathbf{E}[p(\lambda | \mathbf{x})]$ and $\mathbf{E}[p(\theta | \mathbf{x})]$. The posterior distribution is: $$ p(\lambda, \theta \, | \, \mathbf{x}) \propto p(\theta,\lambda) f(\mathbf{x} \, | \, \lambda, \theta) $$ And then the marginal posterior distributions are: $$ \begin{cases} p(\lambda | \mathbf{x}) =\int_{-\infty}^{x_{(1)}} p(\lambda, \theta \, | \, \mathbf{x}) \, d\theta \\ p(\theta | \mathbf{x}) = \int_1^\infty p(\lambda, \theta \, | \, \mathbf{x}) \, d\lambda \end{cases} $$ Trying to answer the question If I'm not wrong: $$ p(\lambda, \theta \, | \, \mathbf{x}) \propto  \underbrace{\frac{1}{\pi\lambda^2(1+\theta)^2}}_{p(\lambda,\theta)} \, \underbrace{\lambda^n e^{-\lambda(S-n\theta)}}_{ f(\mathbf{x} \, | \, \lambda, \theta)} \qquad \left(S = \sum_{i=1}^n x_i\right) $$ I think that the normalizing constant is: $$ c_n = \frac{1}{\pi} \int_{-\infty}^{x_{(1)}}  \frac{1}{1+\theta^2} \int_{1}^\infty  \lambda^{n-2} e^{-\lambda(S-n\theta)} \, d\lambda \, d\theta = \frac{1}{\pi} \int_{-\infty}^{x_{(1)}}\frac{\Gamma(n-1,S-n\theta)}{(S-n\theta)^{n-1}(1+\theta^2)}  \, d\theta $$ In this case $\Gamma(n-1,s-n\theta)$ is the Incomplete Gamma Function. Changing the order of integration doesn't help: $$ c_n = \int_{1}^\infty \lambda^{n-2} e^{-\lambda S} \int_{-\infty}^{x_{(1)}} \frac{e^{n\theta\lambda}}{\pi(1+\theta^2)}   \, d\theta \, d\lambda $$ Of course, I am also unable to find the (approximate) marginal posterior distributions. Thanks in advance for your help!","Warning After hours of trying, it has been proven (thanks, @leonbloy) that my attempt at a solution contained lots of mistakes. Maybe the correct answer is that there is no solution, but I don't know! Homework question Let $X_1, ..., X_n$ be a random sample from a distribution with pdf: $$f_X(x | \lambda, \theta) = \lambda \, e^{-\lambda(x - \theta)} \, \mathbf{1}_{\{x \geq \theta \}}$$ The (independent) prior distributions of $\lambda$ and $\theta$ are: $$ \begin{cases} p(\lambda) = \frac{1}{\lambda^2} \, \mathbf{1}_{\{\lambda > 1\}} \\ p(\theta) = \frac{1}{\pi(1+\theta^2)} \, \mathbf{1}_{\{\theta \in \mathbf{R}\}} \end{cases} $$ The goal is to find Bayesian estimates under quadratic loss of $\lambda$ and $\theta$. First approach What we want is to find $\mathbf{E}[p(\lambda | \mathbf{x})]$ and $\mathbf{E}[p(\theta | \mathbf{x})]$. The posterior distribution is: $$ p(\lambda, \theta \, | \, \mathbf{x}) \propto p(\theta,\lambda) f(\mathbf{x} \, | \, \lambda, \theta) $$ And then the marginal posterior distributions are: $$ \begin{cases} p(\lambda | \mathbf{x}) =\int_{-\infty}^{x_{(1)}} p(\lambda, \theta \, | \, \mathbf{x}) \, d\theta \\ p(\theta | \mathbf{x}) = \int_1^\infty p(\lambda, \theta \, | \, \mathbf{x}) \, d\lambda \end{cases} $$ Trying to answer the question If I'm not wrong: $$ p(\lambda, \theta \, | \, \mathbf{x}) \propto  \underbrace{\frac{1}{\pi\lambda^2(1+\theta)^2}}_{p(\lambda,\theta)} \, \underbrace{\lambda^n e^{-\lambda(S-n\theta)}}_{ f(\mathbf{x} \, | \, \lambda, \theta)} \qquad \left(S = \sum_{i=1}^n x_i\right) $$ I think that the normalizing constant is: $$ c_n = \frac{1}{\pi} \int_{-\infty}^{x_{(1)}}  \frac{1}{1+\theta^2} \int_{1}^\infty  \lambda^{n-2} e^{-\lambda(S-n\theta)} \, d\lambda \, d\theta = \frac{1}{\pi} \int_{-\infty}^{x_{(1)}}\frac{\Gamma(n-1,S-n\theta)}{(S-n\theta)^{n-1}(1+\theta^2)}  \, d\theta $$ In this case $\Gamma(n-1,s-n\theta)$ is the Incomplete Gamma Function. Changing the order of integration doesn't help: $$ c_n = \int_{1}^\infty \lambda^{n-2} e^{-\lambda S} \int_{-\infty}^{x_{(1)}} \frac{e^{n\theta\lambda}}{\pi(1+\theta^2)}   \, d\theta \, d\lambda $$ Of course, I am also unable to find the (approximate) marginal posterior distributions. Thanks in advance for your help!",,['statistics']
87,Independence of Events,Independence of Events,,"I'd appreciate some help with this problem: There are 2 plants that make keyboards. Keyboard faults are classified in 3 categories: letter, number, and other. If a keyboard is chosen at random, are the events ""faulty letter"" and ""plant 2"" independent? Plant    Letter    Number    Other 1        15        45        40 2        75        30        45 I know that to prove independence, I need to show $P(A|B) = P(A)$; or $P(B|A) = P(B)$; or $P(A \cap B) = P(A)P(B)$. But my question is, how can I do this if I'm only given $P(A)$ and $P(B)$? The intersection of those, divided by either $A$ or $B$ (as needed), will always give me the other probability, so this isn't useful. In case it matters, this IS a textbook problem, but only for my benefit, not class.","I'd appreciate some help with this problem: There are 2 plants that make keyboards. Keyboard faults are classified in 3 categories: letter, number, and other. If a keyboard is chosen at random, are the events ""faulty letter"" and ""plant 2"" independent? Plant    Letter    Number    Other 1        15        45        40 2        75        30        45 I know that to prove independence, I need to show $P(A|B) = P(A)$; or $P(B|A) = P(B)$; or $P(A \cap B) = P(A)P(B)$. But my question is, how can I do this if I'm only given $P(A)$ and $P(B)$? The intersection of those, divided by either $A$ or $B$ (as needed), will always give me the other probability, so this isn't useful. In case it matters, this IS a textbook problem, but only for my benefit, not class.",,"['probability', 'statistics']"
88,Sufficient conditions for convergence of functions of random variables,Sufficient conditions for convergence of functions of random variables,,"I hope this question is not too general, but I am not completely sure yet how to phrase it. So we all know that when we have two sequences of random variables $X_n$ and $Y_n$ for $n \ge 1$, that converge to $X$ and $Y$ (using some measure, almost surely, or with probability, in distribution, etc.) then we have all kind of nice properties such as $X_n + Y_n \rightarrow X + Y$ and $X_n Y_n \rightarrow X Y$ so on (with some regularity conditions). My question is: what if we have a general operator on $X$ and $Y$? Are there some mild/not mild conditions on an operator $g(X_n,Y_n)$ that returns a random variable $Z_n$ such that $g(X_n,Y_n) \rightarrow g(X,Y)$? I think the continuous mapping theorem would state that if $g$ is continuous, then we have that this holds. Are there milder conditions?","I hope this question is not too general, but I am not completely sure yet how to phrase it. So we all know that when we have two sequences of random variables $X_n$ and $Y_n$ for $n \ge 1$, that converge to $X$ and $Y$ (using some measure, almost surely, or with probability, in distribution, etc.) then we have all kind of nice properties such as $X_n + Y_n \rightarrow X + Y$ and $X_n Y_n \rightarrow X Y$ so on (with some regularity conditions). My question is: what if we have a general operator on $X$ and $Y$? Are there some mild/not mild conditions on an operator $g(X_n,Y_n)$ that returns a random variable $Z_n$ such that $g(X_n,Y_n) \rightarrow g(X,Y)$? I think the continuous mapping theorem would state that if $g$ is continuous, then we have that this holds. Are there milder conditions?",,"['probability', 'statistics']"
89,The relation between Bregman divergence and KL divergence,The relation between Bregman divergence and KL divergence,,"I see that Bregman divergence is defined as $d_\phi(x,y)=\phi(x)-\phi(y)-<x-y,\nabla\phi(y)>$ , where $x,y\in R^d$ and $\phi$ is a strictly convex function. KL divergence is an instance of Bregman divergence. If $p$ is a discrete probability distribution ( $\sum_{i=1}^d p_i=1$ ), if we use negative entropy $\phi(p)=\sum_{i=1}^d p_i \log p_i$ in Bregmen divergence, then we can get KL divergence. How about the KL divergence between two continuous distributions? Can we get KL divergence between two continuous distributions from Bregman divergence (may be varied)?","I see that Bregman divergence is defined as , where and is a strictly convex function. KL divergence is an instance of Bregman divergence. If is a discrete probability distribution ( ), if we use negative entropy in Bregmen divergence, then we can get KL divergence. How about the KL divergence between two continuous distributions? Can we get KL divergence between two continuous distributions from Bregman divergence (may be varied)?","d_\phi(x,y)=\phi(x)-\phi(y)-<x-y,\nabla\phi(y)> x,y\in R^d \phi p \sum_{i=1}^d p_i=1 \phi(p)=\sum_{i=1}^d p_i \log p_i","['probability', 'statistics', 'machine-learning']"
90,Are A and B conditionally independent,Are A and B conditionally independent,,"Are A and B conditionally independent given the class label? I calculated that $$P(A=1) = \frac{1}{2}$$ $$P(B=1) = \frac{2}{5}$$ $$P(A=1,B=1)=\frac{1}{5}$$ My answer is yes. I do it by anding $(A\text{ and }B)$ which shows that when $A = 1$ and $B = 1$ it doesn't imply Class will be +. How can I actually prove this without this pseudo prove I have come up with?","Are A and B conditionally independent given the class label? I calculated that $$P(A=1) = \frac{1}{2}$$ $$P(B=1) = \frac{2}{5}$$ $$P(A=1,B=1)=\frac{1}{5}$$ My answer is yes. I do it by anding $(A\text{ and }B)$ which shows that when $A = 1$ and $B = 1$ it doesn't imply Class will be +. How can I actually prove this without this pseudo prove I have come up with?",,"['probability', 'statistics', 'data-mining']"
91,"normal test to student test, logic behind it","normal test to student test, logic behind it",,"Let's say we have : $$ X_i  \sim \ N( \mu, \sigma^2 ) $$ iid I'm constructing this test function, in order to test two hypothesis on $\mu$ : $$ \mathbb { 1} {\{ \sum^n X_i < q_a \} } $$ where $q_a$ is the $a$ -quantile of $$ P_{ \mu_0 } ( \sum^n X_i < q_a  ) $$ If I know $\sigma$ , this test is just fine. Because then I can rewrite the test function as : $$ \mathbb { 1} \{ \frac{  \sum X_i - n \mu_0 }{ \sigma \sqrt{n} } < \phi^{-1} (a) \}  $$ But if I don't know $\sigma$ , how can I handle things ? I have been told to replace it by $S$ , such that : $$ S^2 = \frac 1 {n-1} \sum^n (X_i - \overline X)^2 $$ But how do you conclude that the test is now : $$ \mathbb { 1} \{ \frac{  \sum X_i - n \mu_0 }{ S \sqrt{n} } < t_{n-1, a} \}  $$ where $t_{n-1, a} $ is the $a$ -quantile of the student law with n-1 degrees of freedom?","Let's say we have : iid I'm constructing this test function, in order to test two hypothesis on : where is the -quantile of If I know , this test is just fine. Because then I can rewrite the test function as : But if I don't know , how can I handle things ? I have been told to replace it by , such that : But how do you conclude that the test is now : where is the -quantile of the student law with n-1 degrees of freedom?"," X_i  \sim \ N( \mu, \sigma^2 )  \mu  \mathbb { 1} {\{ \sum^n X_i < q_a \} }  q_a a  P_{ \mu_0 } ( \sum^n X_i < q_a  )  \sigma  \mathbb { 1} \{ \frac{  \sum X_i - n \mu_0 }{ \sigma \sqrt{n} } < \phi^{-1} (a) \}   \sigma S  S^2 = \frac 1 {n-1} \sum^n (X_i - \overline X)^2   \mathbb { 1} \{ \frac{  \sum X_i - n \mu_0 }{ S \sqrt{n} } < t_{n-1, a} \}   t_{n-1, a}  a","['statistics', 'normal-distribution', 'statistical-inference']"
92,Not complete but minimal sufficient statistic,Not complete but minimal sufficient statistic,,"Let $X =(X_1,\ldots, X_n), ~ X_i \mathrm{iid} \sim \mathcal N ( \theta, \theta^2), ~ \theta \in \Theta = \mathbb R \setminus \{0\}, ~ T(X)=(\sum_{i=1}^n X_i, \sum_{i=1}^n X_i^2)$. I figured out that $T(X)$ is sufficient. To show that it's not complete I checked the function $g$ with $g(u,v) = 2u^2 - (n+1)v$ and noticed that $E_{\theta}[g(T(X))] = 0 ~ \forall \theta \in \Theta$ - but why is $P_{\theta}(g(T(X)) = 0) < 1$? And how to show that $T(X)$ is minimal sufficient? I know that one can choose a subfamiliy $\mathcal P_0 \subset \mathcal P = \{f_{\theta} \mid \theta \in \Theta \}$ where $P$ is a family of densities with the same support and that's enough to show that $T$ is minimal sufficient for the subfamiliy. And if we have such a subfamily, $T^{*}(X) = \left(\frac{f_{\theta_1}(x)}{f_{\theta_0}(x)}, \ldots, \frac{f_{\theta_k}(x)}{f_{\theta_0}(x)}\right)$ is minimal sufficient (for $\Theta = \{\theta_0, \ldots, \theta_k\}$). But how to apply on the present case?","Let $X =(X_1,\ldots, X_n), ~ X_i \mathrm{iid} \sim \mathcal N ( \theta, \theta^2), ~ \theta \in \Theta = \mathbb R \setminus \{0\}, ~ T(X)=(\sum_{i=1}^n X_i, \sum_{i=1}^n X_i^2)$. I figured out that $T(X)$ is sufficient. To show that it's not complete I checked the function $g$ with $g(u,v) = 2u^2 - (n+1)v$ and noticed that $E_{\theta}[g(T(X))] = 0 ~ \forall \theta \in \Theta$ - but why is $P_{\theta}(g(T(X)) = 0) < 1$? And how to show that $T(X)$ is minimal sufficient? I know that one can choose a subfamiliy $\mathcal P_0 \subset \mathcal P = \{f_{\theta} \mid \theta \in \Theta \}$ where $P$ is a family of densities with the same support and that's enough to show that $T$ is minimal sufficient for the subfamiliy. And if we have such a subfamily, $T^{*}(X) = \left(\frac{f_{\theta_1}(x)}{f_{\theta_0}(x)}, \ldots, \frac{f_{\theta_k}(x)}{f_{\theta_0}(x)}\right)$ is minimal sufficient (for $\Theta = \{\theta_0, \ldots, \theta_k\}$). But how to apply on the present case?",,['statistics']
93,Forecasting Lottery,Forecasting Lottery,,"I do understand that all lottery has a negative mathematical expectation but I am wondering, if we have a set of historical data of the winning numbers, is it possible to increase the winning chance? I also do understand that each round is a independent event but according to this theory where you roll a dice $n$ times, you each side should get $n/6$ times as $n \to \infty$. So my questions is, does such a function exist to increase the winning chances of a lottery?","I do understand that all lottery has a negative mathematical expectation but I am wondering, if we have a set of historical data of the winning numbers, is it possible to increase the winning chance? I also do understand that each round is a independent event but according to this theory where you roll a dice $n$ times, you each side should get $n/6$ times as $n \to \infty$. So my questions is, does such a function exist to increase the winning chances of a lottery?",,"['probability', 'statistics']"
94,"Is this true: $\mathrm{Cov}(X,Y) = \sqrt{\mathrm{Var(X)}}\sqrt{\mathrm{Var}(Y)}$?",Is this true: ?,"\mathrm{Cov}(X,Y) = \sqrt{\mathrm{Var(X)}}\sqrt{\mathrm{Var}(Y)}","I just want to confirm whether this is correct or not: The covariance of $X$ and $Y$ is equal to the standard deviation of $X$ times the standard deviation of $Y$. or, in mathematical notation, $$ \mathrm{Cov}(X,Y) = \sqrt{\mathrm{Var(X)}}\sqrt{\mathrm{Var}(Y)} $$","I just want to confirm whether this is correct or not: The covariance of $X$ and $Y$ is equal to the standard deviation of $X$ times the standard deviation of $Y$. or, in mathematical notation, $$ \mathrm{Cov}(X,Y) = \sqrt{\mathrm{Var(X)}}\sqrt{\mathrm{Var}(Y)} $$",,"['statistics', 'standard-deviation']"
95,Solve for $\beta$. (Series),Solve for . (Series),\beta,I am proving the least squares estimates of the regression coefficients and I've come across these 2 equations. $$\sum_{i=1}^{n}y_i=\alpha n+\beta \sum_{i=1}^{n}x_i$$ $$\sum_{i=1}^{n}y_ix_i=\alpha \sum_{i=1}^{n}x_i+\beta \sum_{i=1}^{n}x_i^2$$ I am supposed to solve what is $\beta$. The answer given is $$\beta=\frac{n(\sum_{i=1}^{n}x_iy_i)-(\sum_{i=1}^{n}x_i)(\sum_{i=1}^{n}y_i)}{n(\sum_{i=1}^{n}x_i^2)-(\sum_{i=1}^{n}x_i)^2}$$ I've tried many times to work it out by substitution method. But failed.  It's tedious. Hope someone can help me out. Thanks in advance.,I am proving the least squares estimates of the regression coefficients and I've come across these 2 equations. $$\sum_{i=1}^{n}y_i=\alpha n+\beta \sum_{i=1}^{n}x_i$$ $$\sum_{i=1}^{n}y_ix_i=\alpha \sum_{i=1}^{n}x_i+\beta \sum_{i=1}^{n}x_i^2$$ I am supposed to solve what is $\beta$. The answer given is $$\beta=\frac{n(\sum_{i=1}^{n}x_iy_i)-(\sum_{i=1}^{n}x_i)(\sum_{i=1}^{n}y_i)}{n(\sum_{i=1}^{n}x_i^2)-(\sum_{i=1}^{n}x_i)^2}$$ I've tried many times to work it out by substitution method. But failed.  It's tedious. Hope someone can help me out. Thanks in advance.,,"['sequences-and-series', 'algebra-precalculus', 'statistics', 'linear-regression']"
96,Probability to pick at least one pair of socks,Probability to pick at least one pair of socks,,"There are 10 pairs of socks. What is the probability that in 4 socks chosen at random there is at least one pair. My try: Let $A$ be an event of choosing exactly one pair of socks among 4 socks and $B$ be an event of choosing exactly two pairs, $$P(A)=\frac{\binom{10}{1}\left(1-\frac{\binom{9}{1}}{\binom{18}{2}}\right)}{\binom{20}{4}}$$ and $$P(B)=\frac{\binom{10}{2}}{\binom{20}{4}}$$ So the total probability is $P(A)+P(B)$. But i know that some mistake is there in my solution... can any one help?","There are 10 pairs of socks. What is the probability that in 4 socks chosen at random there is at least one pair. My try: Let $A$ be an event of choosing exactly one pair of socks among 4 socks and $B$ be an event of choosing exactly two pairs, $$P(A)=\frac{\binom{10}{1}\left(1-\frac{\binom{9}{1}}{\binom{18}{2}}\right)}{\binom{20}{4}}$$ and $$P(B)=\frac{\binom{10}{2}}{\binom{20}{4}}$$ So the total probability is $P(A)+P(B)$. But i know that some mistake is there in my solution... can any one help?",,"['probability', 'combinatorics', 'statistics']"
97,How to find the probability of getting queens using combination or premutations?,How to find the probability of getting queens using combination or premutations?,,"Two cards are drawn at random from a standard deck of 52 cards, without replacement. What is the probability that both cards are drawn are queens? Its a permutation cause the order matter, I mean its a pack of cards and cards have order so its going to be different if you choose anything else right? I'm just guessing not sure. So the $$ P(Queens) = ? / 52P2 $$ Whats going to be the numerator? I mean i said the denominator was 52P2 because its the total number of outcomes and you pick 2 out of it?","Two cards are drawn at random from a standard deck of 52 cards, without replacement. What is the probability that both cards are drawn are queens? Its a permutation cause the order matter, I mean its a pack of cards and cards have order so its going to be different if you choose anything else right? I'm just guessing not sure. So the $$ P(Queens) = ? / 52P2 $$ Whats going to be the numerator? I mean i said the denominator was 52P2 because its the total number of outcomes and you pick 2 out of it?",,"['probability', 'statistics']"
98,Is it true that $\mathbb E[{\frac{X}{Y}]}={\frac{\mathbb E[X]}{\mathbb E[Y]}}$?,Is it true that ?,\mathbb E[{\frac{X}{Y}]}={\frac{\mathbb E[X]}{\mathbb E[Y]}},"If $X$ and $Y$ are both random variables, does it hold $$\mathbb E\left[\frac{X}{Y}\right]={\frac{\mathbb E[X]}{\mathbb E[Y]}}$$ ??","If $X$ and $Y$ are both random variables, does it hold $$\mathbb E\left[\frac{X}{Y}\right]={\frac{\mathbb E[X]}{\mathbb E[Y]}}$$ ??",,"['probability', 'statistics', 'statistical-inference', 'sampling']"
99,Finding the optimum supply quantity when there is uncertainty in forecast,Finding the optimum supply quantity when there is uncertainty in forecast,,"This is actually a quiz that will be needed in a real life food stall! I need to decide how much stock to supply for my pumpkin soup stall. I sell each soup for $5$ dollars a cup, and let's say my ingredients cost is $1$ dollar. Therefore an outcome of under-forecasting is $4$ dollars per unit, while an outcome of over-forecasting is 1 dollar per unit. My forecast isn't so simple, however. I'm guessing that the most probable number of sales is $150$ units, but I'm very unsure, so there's a normal distribution behind this prediction with a standard deviation of $30$ units.  This is harder than I expected. Intuitively I would prepare ingredients for $180$ units, at which point I'd guess that the likely opportunity costs that would come with understocking would roughly meet the likely costs of overstocking. But given this is such a common dilemma, I thought that someone must be able to find a precise solution, and would then hopefully be able to explain it in layman's terms.","This is actually a quiz that will be needed in a real life food stall! I need to decide how much stock to supply for my pumpkin soup stall. I sell each soup for $5$ dollars a cup, and let's say my ingredients cost is $1$ dollar. Therefore an outcome of under-forecasting is $4$ dollars per unit, while an outcome of over-forecasting is 1 dollar per unit. My forecast isn't so simple, however. I'm guessing that the most probable number of sales is $150$ units, but I'm very unsure, so there's a normal distribution behind this prediction with a standard deviation of $30$ units.  This is harder than I expected. Intuitively I would prepare ingredients for $180$ units, at which point I'd guess that the likely opportunity costs that would come with understocking would roughly meet the likely costs of overstocking. But given this is such a common dilemma, I thought that someone must be able to find a precise solution, and would then hopefully be able to explain it in layman's terms.",,"['statistics', 'optimization']"
