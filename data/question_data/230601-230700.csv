,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Showing A Relation Is Reflexive, Symmetric, and Transitive.","Showing A Relation Is Reflexive, Symmetric, and Transitive.",,"The question is, ""Show that the relation R = ‚àÖ on the empty set S = ‚àÖ is reflexive, symmetric, and transitive."" I was told by my teacher that you could simply say it can't be shown that each property isn't true; and that would show that the relation had those three properties. To me, this answer isn't very satisfying. Could someone, perhaps, elaborate on this idea more? Thank you!","The question is, ""Show that the relation R = ‚àÖ on the empty set S = ‚àÖ is reflexive, symmetric, and transitive."" I was told by my teacher that you could simply say it can't be shown that each property isn't true; and that would show that the relation had those three properties. To me, this answer isn't very satisfying. Could someone, perhaps, elaborate on this idea more? Thank you!",,"['elementary-set-theory', 'relations']"
1,An exercise on set theory,An exercise on set theory,,"The type of exercise I'm about to speak of seems quite basic however I didn't have any exposure to it until recently so please provide me with some pointers on how to work it out. Show that if the sets A, B and C satisfy the following relations simultaneously: $A\cup B = C\\     (A\cup C) \cap B = C\\     (A \cap C) \cup B = A$ then they are the same.","The type of exercise I'm about to speak of seems quite basic however I didn't have any exposure to it until recently so please provide me with some pointers on how to work it out. Show that if the sets A, B and C satisfy the following relations simultaneously: $A\cup B = C\\     (A\cup C) \cap B = C\\     (A \cap C) \cup B = A$ then they are the same.",,['elementary-set-theory']
2,Why can disjoint subsets be picked out in these sets?,Why can disjoint subsets be picked out in these sets?,,"Still another exercise on Reinhard Diestel Graph Theory, GTM 173, edition 3 (on page 51) Let $A$ be a finite set with subsets $A_1, \cdots, A_n$, and let $d_1, \cdots, d_n \in \mathbb N$. Show that there are disjoint subsets $D_k \subseteq  A_k$, with $|D_k| =d_k$ for all $k \leq n$, if and only if $|\cup_{i\in I}A_i| \geq \sum_{i \in I} d_i$ for all $I \subseteq \{ 1,\cdots,n\}$. This ""if and only if"" statement is clear in one direction since for the properly chosen $D_k$, $|\cup_{i\in I}A_i| \geq |\cup_{i\in I}D_i| = \sum_{i \in I} d_i$. But the proof of the other direction seems more complicated to me. I tried to prove it by induction, but failed. Since I am a beginner of graph theory, I just take it as an exercise of set theory, and cannot think it in the way of graphs. Maybe graph theoretic methods are favorable. Longing for your advice. Thanks very much.","Still another exercise on Reinhard Diestel Graph Theory, GTM 173, edition 3 (on page 51) Let $A$ be a finite set with subsets $A_1, \cdots, A_n$, and let $d_1, \cdots, d_n \in \mathbb N$. Show that there are disjoint subsets $D_k \subseteq  A_k$, with $|D_k| =d_k$ for all $k \leq n$, if and only if $|\cup_{i\in I}A_i| \geq \sum_{i \in I} d_i$ for all $I \subseteq \{ 1,\cdots,n\}$. This ""if and only if"" statement is clear in one direction since for the properly chosen $D_k$, $|\cup_{i\in I}A_i| \geq |\cup_{i\in I}D_i| = \sum_{i \in I} d_i$. But the proof of the other direction seems more complicated to me. I tried to prove it by induction, but failed. Since I am a beginner of graph theory, I just take it as an exercise of set theory, and cannot think it in the way of graphs. Maybe graph theoretic methods are favorable. Longing for your advice. Thanks very much.",,"['graph-theory', 'elementary-set-theory']"
3,How to show a subset is part of another set?,How to show a subset is part of another set?,,"I'm not sure how to ""show"" these two answers. The small group created from the intersection $A\cap B\cap C$ is a subset of $A\cap B$ since abc is a smaller ""portion"" of the overall sets. The difference of $(A-B)-C$ is the same as $A-C$ since part of $A$ was removed with the $B$ already. Let $A, B$, and $C$ be sets. Show that 1) $(A \cap B \cap C) \subseteq (A \cap B)$ 2) $(A ‚àí B) ‚àí C \subseteq A ‚àí C$","I'm not sure how to ""show"" these two answers. The small group created from the intersection $A\cap B\cap C$ is a subset of $A\cap B$ since abc is a smaller ""portion"" of the overall sets. The difference of $(A-B)-C$ is the same as $A-C$ since part of $A$ was removed with the $B$ already. Let $A, B$, and $C$ be sets. Show that 1) $(A \cap B \cap C) \subseteq (A \cap B)$ 2) $(A ‚àí B) ‚àí C \subseteq A ‚àí C$",,['elementary-set-theory']
4,Removing redundant sets from an intersection,Removing redundant sets from an intersection,,"Let $I$ be a non-empty set and $(A_i)_{i\in I}$ a family of sets. Is it true that there exists a subset $J\subset I$ such that $\bigcap_{j\in J}A_j=\bigcap_{i\in I}A_i$ and, for any $j_0\in J$, $\bigcap_{j\in J-\{j_0\}}A_j\neq\bigcap_{j\in J}A_j$? If $I=\mathbb{N}$, the answer is yes (if I am not mistaken): $J$ can be constructed by starting with $\mathbb{N}$ and, at the $n$-th step, removing $n$ if that does not affect the intersection. What if $I$ is uncountable? I guess the answer is still ""yes"" and tried to prove it by generalizing the above approach using transfinite induction, but I failed. The answer ""yes"" or ""no"" and a sketch of a proof (resp. a counterexample) would be nice.","Let $I$ be a non-empty set and $(A_i)_{i\in I}$ a family of sets. Is it true that there exists a subset $J\subset I$ such that $\bigcap_{j\in J}A_j=\bigcap_{i\in I}A_i$ and, for any $j_0\in J$, $\bigcap_{j\in J-\{j_0\}}A_j\neq\bigcap_{j\in J}A_j$? If $I=\mathbb{N}$, the answer is yes (if I am not mistaken): $J$ can be constructed by starting with $\mathbb{N}$ and, at the $n$-th step, removing $n$ if that does not affect the intersection. What if $I$ is uncountable? I guess the answer is still ""yes"" and tried to prove it by generalizing the above approach using transfinite induction, but I failed. The answer ""yes"" or ""no"" and a sketch of a proof (resp. a counterexample) would be nice.",,['elementary-set-theory']
5,Another proof of $A \triangle (B \triangle C)=(A \triangle B) \triangle C$,Another proof of,A \triangle (B \triangle C)=(A \triangle B) \triangle C,I can prove associativity of symmetric difference of sets using it's definition $A \triangle B = (A \backslash B)\cup(B \backslash A)$. But in the text I read author gives a hint to derive it somehow from associativity of addition in $\mathbb{Z}_2$. I can't see any clear analogy. Update: clear analogy is given in the comment section below.,I can prove associativity of symmetric difference of sets using it's definition $A \triangle B = (A \backslash B)\cup(B \backslash A)$. But in the text I read author gives a hint to derive it somehow from associativity of addition in $\mathbb{Z}_2$. I can't see any clear analogy. Update: clear analogy is given in the comment section below.,,['elementary-set-theory']
6,If a line segment is divided into 2 parts then one of the parts is equinumerous to the original segment.,If a line segment is divided into 2 parts then one of the parts is equinumerous to the original segment.,,"Assume we have a set $X$ which is a (closed) line segment. Prove that if we split $X$ into 2 parts $X_1$ and $X_2$ then at least one of those sets would have the same cardinality as $X$. My attempt: 1) Let's assume that $X_1$ contains some line segment itself, let's call it $Y$. 2) We know that there is a bijection between $X$ and $Y$ and therefore $|X| = |Y|$. 3) And since $X_1$ is embedded in $X$ we can use Cantor-Bernstein theorem to conclude that $|X_1| = |X|$. Now, I am not sure how to prove the second case: when $X_1$ (or $X_2$) does not contain a line segment. Is there a way to use Cantor-Bernstein there?","Assume we have a set $X$ which is a (closed) line segment. Prove that if we split $X$ into 2 parts $X_1$ and $X_2$ then at least one of those sets would have the same cardinality as $X$. My attempt: 1) Let's assume that $X_1$ contains some line segment itself, let's call it $Y$. 2) We know that there is a bijection between $X$ and $Y$ and therefore $|X| = |Y|$. 3) And since $X_1$ is embedded in $X$ we can use Cantor-Bernstein theorem to conclude that $|X_1| = |X|$. Now, I am not sure how to prove the second case: when $X_1$ (or $X_2$) does not contain a line segment. Is there a way to use Cantor-Bernstein there?",,"['elementary-set-theory', 'cardinals']"
7,Heuristics suggesting a unit interval is uncountable,Heuristics suggesting a unit interval is uncountable,,"This is maybe a soft question, I am not sure yet. Anyway, I am delivering a 8 (+ 4 supervisions) hour course on 'basic set theory' for undergraduates : set notation, bijections, functions, count-ability, Schroeder-Bernstein theorem [basically extremely naive set theory]. Now, there are loads of ways to show $ \mathbb R$ is uncountable (or equivalenetly some interval of  $ \mathbb R$ is uncountable) - perfect sets, diagnol argument, real numbers of (0,1) in binary, Schoreder-Bernstein with the power set of $ \mathbb N$ , ... HOWEVER! I - course mates included - found it mind blowing getting a theorem proving the rationals and irrationals were not equinumerous [barely 8 days into our first term at University]. I want to provide some heuristics supporting the claim - I read somewhere about throwing a 10 sided die and letting the faces produce some real in (0,1); for instance throw 1: 9 throw 2: 0 throw 3: 5 ... Yields the number 0.905 ... This at least supports the claim that we should expect to get more irrational numbers after throwing the die in an intuitive way - but infinity isn't intuitive! A similar argument might go: Between 0 and 1 there is 1/2 , between 0 and 1/2 there is a 1/4, ... - surely we can find more rational numbers than natural numbers? EEEErrr uh oh! No we cannot. Do you have some plausible heuristic to back up uncountability arguments for irrationals?","This is maybe a soft question, I am not sure yet. Anyway, I am delivering a 8 (+ 4 supervisions) hour course on 'basic set theory' for undergraduates : set notation, bijections, functions, count-ability, Schroeder-Bernstein theorem [basically extremely naive set theory]. Now, there are loads of ways to show $ \mathbb R$ is uncountable (or equivalenetly some interval of  $ \mathbb R$ is uncountable) - perfect sets, diagnol argument, real numbers of (0,1) in binary, Schoreder-Bernstein with the power set of $ \mathbb N$ , ... HOWEVER! I - course mates included - found it mind blowing getting a theorem proving the rationals and irrationals were not equinumerous [barely 8 days into our first term at University]. I want to provide some heuristics supporting the claim - I read somewhere about throwing a 10 sided die and letting the faces produce some real in (0,1); for instance throw 1: 9 throw 2: 0 throw 3: 5 ... Yields the number 0.905 ... This at least supports the claim that we should expect to get more irrational numbers after throwing the die in an intuitive way - but infinity isn't intuitive! A similar argument might go: Between 0 and 1 there is 1/2 , between 0 and 1/2 there is a 1/4, ... - surely we can find more rational numbers than natural numbers? EEEErrr uh oh! No we cannot. Do you have some plausible heuristic to back up uncountability arguments for irrationals?",,"['soft-question', 'elementary-set-theory']"
8,Cardinalities of $\mathbb{R^{2}}$ and $\mathbb{C}$ and isomorphisms,Cardinalities of  and  and isomorphisms,\mathbb{R^{2}} \mathbb{C},"Using the tools of linear-algebra it seems like  $\mathbb{R^{2}}$ or $\mathbb{R}$ $\times$ $\mathbb{R}$ is isomorphic to $\mathbb{C}$, since both of the spaces are of dimension 2. Does this mean that the these sets are equinumerous? $\mathbb{R}$ is a subspace of $\mathbb{C}$, but I am wondering how could one prove that they are equinumerous without using isomorphisms (assuming they imply equinumerosity); would this require cardinal arithmetic? Thanks.","Using the tools of linear-algebra it seems like  $\mathbb{R^{2}}$ or $\mathbb{R}$ $\times$ $\mathbb{R}$ is isomorphic to $\mathbb{C}$, since both of the spaces are of dimension 2. Does this mean that the these sets are equinumerous? $\mathbb{R}$ is a subspace of $\mathbb{C}$, but I am wondering how could one prove that they are equinumerous without using isomorphisms (assuming they imply equinumerosity); would this require cardinal arithmetic? Thanks.",,"['linear-algebra', 'elementary-set-theory']"
9,Clarifying Notation (Sets & Functions),Clarifying Notation (Sets & Functions),,"The basic problem is that I want to be extremely clear about the sets that mathematical manipulations and operations are taking place in, I am hoping for someone who really understands this to read what I've written closely and point out what is getting me all mixed up, though of course reading &/or responding isn't mandatory (lol) - but it is a long post even though it's dealing with just one idea. The set-theoretic definition of a function is f = (X,Y,F) where F is a subset of ordered pairs of the Cartesian product of X & Y, (i.e. F ‚äÜ (X x Y) a relation). This is Bourbaki's way of defining a function and he (they) call F the graph. But isn't a function itself a relation and therefore musn't we write (X,Y,f) as the set in which the function acts? To expand this out: (X,Y,f) = (X,Y,(X,Y,F)). I've come across notation that specifies (X,Y,f) as ((X,Y),f). Here, page 35 of this .pdf file So ((X,Y),f) = ((X,Y),((X,Y),F)) would seem to make sense. Bourbaki calls f a set & F it's graph but the notation in the .pdf file says that f would be defined in the way I've explained above, i.e. that F is a subset of XxY. The thing is that since a function f is itself a relation shouldn't it be a relation in a set, i.e. ((X,Y),f)? Assuming that the above is the way to think about these things, how would I think of both F & f? In f = (X,Y,F), F ‚äÜ (X x Y) so (x,y) ‚àà F or xFy, where obviously (x‚ààX) & (y‚ààY). How about f? I think f ‚äÜ (X x Y) so (x,y) ‚àà f or xfy. I don't understand how this makes sense because for the set f = (X,Y,F) Bourbaki writes f : X ‚Üí Y so for (X,Y,f) I'd have to set g = (X,Y,f) and write g : X ‚Üí Y. This is a weird conclusion but it seems to suggest itself. The problem of being extremely clear about what sets you are using is particularly interesting when doing linear algebra. The use of set-theoretic notation in linear algebra both clarifies things for me and brings up similar questions, for a vector space V I could write ((V,+),(F,+',¬∞),‚Ä¢) with the clarification that: in (V,+) we have + : V √ó V ‚Üí V, in (F,+',¬∞) we have (+' : F √ó F ‚Üí F) & ( ¬∞ : F √ó F ‚Üí F). In ‚Ä¢ we have (‚Ä¢ : F √ó V ‚Üí V) or perhaps [‚Ä¢ : (V,+) √ó (F,+',¬∞) ‚Üí (V,+)]? This notation clearly illustrates why the two operations, vector addition and scalar multiplication are used on a vector space and the axioms for each clearly jump out, i.e. (V,+) is abelian, (F,+',¬∞) is a field and ‚Ä¢ isn't the clearest to me but I think it's similar to the way that + & ¬∞ are related in a field, i.e. ""multiplication distributes over addition"". Relating all of this to the concerns I had above in a clear manner, in the set (F,+',¬∞) it would make sense that +' is a set of the form (F,+'') where +'' is a subset of the cartesian product of F x F. Similarly with ¬∞, and in the set (V,+) you'd have something similar, also in ‚Ä¢ you'd have a crazy set ((V,+), (F,+',¬∞), ‚Ä¢') or including even more brackets (((V,+), (F,+',¬∞)), ‚Ä¢') with ‚Ä¢' being a subset of the cartesian product of (V,+) & (F,+',¬∞). There is another problem when you want to give a vector space a norm, would I write ((V,+),(F,+',¬∞),‚Ä¢,‚äó) where ‚äó : V x V ‚Üí F ? Would ‚äó itself suggest the subset ((V,+), (F,+',¬∞), ‚äó') in the manner explained above? I don't think so because ‚äó' would be the set of ordered pairs (x,a) with x ‚àà V and a ‚àà F but since V x V ‚Üí F you've got the map (x,x') ‚Ü¶ a, it's quite confusing tbh and need help with this. All this seems crazy but it also makes a lot of sense, I want to be very rigorous about what I'm doing and all of the above seems to suggest itself but it could be a lot of nonsense caused by simple confusion of a particular issue in the post , I'm thinking that (X,Y,F) implying (X,Y,f) is the culprit but again this idea clarifies things. If you read to this point thanks so much, hopefully you recognise the issue.","The basic problem is that I want to be extremely clear about the sets that mathematical manipulations and operations are taking place in, I am hoping for someone who really understands this to read what I've written closely and point out what is getting me all mixed up, though of course reading &/or responding isn't mandatory (lol) - but it is a long post even though it's dealing with just one idea. The set-theoretic definition of a function is f = (X,Y,F) where F is a subset of ordered pairs of the Cartesian product of X & Y, (i.e. F ‚äÜ (X x Y) a relation). This is Bourbaki's way of defining a function and he (they) call F the graph. But isn't a function itself a relation and therefore musn't we write (X,Y,f) as the set in which the function acts? To expand this out: (X,Y,f) = (X,Y,(X,Y,F)). I've come across notation that specifies (X,Y,f) as ((X,Y),f). Here, page 35 of this .pdf file So ((X,Y),f) = ((X,Y),((X,Y),F)) would seem to make sense. Bourbaki calls f a set & F it's graph but the notation in the .pdf file says that f would be defined in the way I've explained above, i.e. that F is a subset of XxY. The thing is that since a function f is itself a relation shouldn't it be a relation in a set, i.e. ((X,Y),f)? Assuming that the above is the way to think about these things, how would I think of both F & f? In f = (X,Y,F), F ‚äÜ (X x Y) so (x,y) ‚àà F or xFy, where obviously (x‚ààX) & (y‚ààY). How about f? I think f ‚äÜ (X x Y) so (x,y) ‚àà f or xfy. I don't understand how this makes sense because for the set f = (X,Y,F) Bourbaki writes f : X ‚Üí Y so for (X,Y,f) I'd have to set g = (X,Y,f) and write g : X ‚Üí Y. This is a weird conclusion but it seems to suggest itself. The problem of being extremely clear about what sets you are using is particularly interesting when doing linear algebra. The use of set-theoretic notation in linear algebra both clarifies things for me and brings up similar questions, for a vector space V I could write ((V,+),(F,+',¬∞),‚Ä¢) with the clarification that: in (V,+) we have + : V √ó V ‚Üí V, in (F,+',¬∞) we have (+' : F √ó F ‚Üí F) & ( ¬∞ : F √ó F ‚Üí F). In ‚Ä¢ we have (‚Ä¢ : F √ó V ‚Üí V) or perhaps [‚Ä¢ : (V,+) √ó (F,+',¬∞) ‚Üí (V,+)]? This notation clearly illustrates why the two operations, vector addition and scalar multiplication are used on a vector space and the axioms for each clearly jump out, i.e. (V,+) is abelian, (F,+',¬∞) is a field and ‚Ä¢ isn't the clearest to me but I think it's similar to the way that + & ¬∞ are related in a field, i.e. ""multiplication distributes over addition"". Relating all of this to the concerns I had above in a clear manner, in the set (F,+',¬∞) it would make sense that +' is a set of the form (F,+'') where +'' is a subset of the cartesian product of F x F. Similarly with ¬∞, and in the set (V,+) you'd have something similar, also in ‚Ä¢ you'd have a crazy set ((V,+), (F,+',¬∞), ‚Ä¢') or including even more brackets (((V,+), (F,+',¬∞)), ‚Ä¢') with ‚Ä¢' being a subset of the cartesian product of (V,+) & (F,+',¬∞). There is another problem when you want to give a vector space a norm, would I write ((V,+),(F,+',¬∞),‚Ä¢,‚äó) where ‚äó : V x V ‚Üí F ? Would ‚äó itself suggest the subset ((V,+), (F,+',¬∞), ‚äó') in the manner explained above? I don't think so because ‚äó' would be the set of ordered pairs (x,a) with x ‚àà V and a ‚àà F but since V x V ‚Üí F you've got the map (x,x') ‚Ü¶ a, it's quite confusing tbh and need help with this. All this seems crazy but it also makes a lot of sense, I want to be very rigorous about what I'm doing and all of the above seems to suggest itself but it could be a lot of nonsense caused by simple confusion of a particular issue in the post , I'm thinking that (X,Y,F) implying (X,Y,f) is the culprit but again this idea clarifies things. If you read to this point thanks so much, hopefully you recognise the issue.",,[]
10,What is the order of the set of distinct (up to similarity) nxn matrices over R?,What is the order of the set of distinct (up to similarity) nxn matrices over R?,,"What is the order of the set of distinct (up to similarity) nxn matrices over $\mathbb{R}$ with determinant equal to some non-zero scalar... say 6? (eg. countable, uncountable etc.) The set of matrices over $\mathbb{R}$ is uncountable. So is the order of the set consisting of classes of matrices with the same determinant. In each of those classes we have further subsets, the equivalence classes formed by grouping similar matrices. Each equivalence class of similar matrices represents one linear transformation expressed in terms of all possible bases of $\mathbb{R}^n$, so the size of each equivalence class is also uncountable. What I'm not certian about is the size of the set of ""different"" transformations that have the same determinant. Is it uncountable too? What can I put it in a correspondence with to show this? Apologies if this is poorly worded-- let me know if there is a better way to ask this question.","What is the order of the set of distinct (up to similarity) nxn matrices over $\mathbb{R}$ with determinant equal to some non-zero scalar... say 6? (eg. countable, uncountable etc.) The set of matrices over $\mathbb{R}$ is uncountable. So is the order of the set consisting of classes of matrices with the same determinant. In each of those classes we have further subsets, the equivalence classes formed by grouping similar matrices. Each equivalence class of similar matrices represents one linear transformation expressed in terms of all possible bases of $\mathbb{R}^n$, so the size of each equivalence class is also uncountable. What I'm not certian about is the size of the set of ""different"" transformations that have the same determinant. Is it uncountable too? What can I put it in a correspondence with to show this? Apologies if this is poorly worded-- let me know if there is a better way to ask this question.",,"['linear-algebra', 'elementary-set-theory', 'cardinals']"
11,"Is the ordered pair definition $(ùë•,ùë¶):=\{ùë•,\{ùë•,ùë¶\}\}$ a good definition?",Is the ordered pair definition  a good definition?,"(ùë•,ùë¶):=\{ùë•,\{ùë•,ùë¶\}\}","In answer to this post There is no one fixed way to define an ordered pair in terms of sets. It is also common to define an ordered pair as $(ùë•,ùë¶):=\{ùë•,\{ùë•,ùë¶\}\}$ . One can prove that $\{x_1, \{x_1,y_1\}\} = \{x_2, \{x_2,y_2\}\} \iff x_1 = x_2 \text{ and }y_1=y_2 \label{1}\tag{$*$}.$ I've tried the proof, and the process is questionable: take simplest case when $$ x=y,\, u=v,\, \langle x,y\rangle=\langle u,v\rangle \iff \{ùë•,\{ùë•\}\}=\{u,\{u\}\},$$ to which $x=u,\{ùë•\}=\{u\}$ is a solution. As we can immediately see,  also $x=\{u\},u=\{ùë•\}$ can be a solution as long as there exist a set such that $x=\{\{x\}\}$ , i.e. if $x$ is a set containing a set containing itself. Now searching the internet for an example of a set containing itself, I've found this Quora Q&A , where it states that in ZFC set theory there isn't a set containing itself (so I think it also means a set containing a set containing itself wouldn't exist). On the other hand, other non-ZFC set theories allows a set containing itself to exist (so I assume a set containing a set containing itself would also exist under such theory), so under this theory we cannot prove \eqref{1}. On the contrary to Kuratowski's definition $\langle x,y\rangle=\{\{x\},\{x,y\}\}$ , Wiener's definition $$ \langle x,y\rangle=\{\{\{x\},\emptyset\},\{\{y\}\} $$ is a good one because it don't rely on such a particular axiom of set theory. It works in set theories other than ZFC, even works in naive set theory.","In answer to this post There is no one fixed way to define an ordered pair in terms of sets. It is also common to define an ordered pair as . One can prove that I've tried the proof, and the process is questionable: take simplest case when to which is a solution. As we can immediately see,  also can be a solution as long as there exist a set such that , i.e. if is a set containing a set containing itself. Now searching the internet for an example of a set containing itself, I've found this Quora Q&A , where it states that in ZFC set theory there isn't a set containing itself (so I think it also means a set containing a set containing itself wouldn't exist). On the other hand, other non-ZFC set theories allows a set containing itself to exist (so I assume a set containing a set containing itself would also exist under such theory), so under this theory we cannot prove \eqref{1}. On the contrary to Kuratowski's definition , Wiener's definition is a good one because it don't rely on such a particular axiom of set theory. It works in set theories other than ZFC, even works in naive set theory.","(ùë•,ùë¶):=\{ùë•,\{ùë•,ùë¶\}\} \{x_1, \{x_1,y_1\}\} = \{x_2, \{x_2,y_2\}\} \iff x_1 = x_2 \text{ and }y_1=y_2 \label{1}\tag{*}. 
x=y,\, u=v,\, \langle x,y\rangle=\langle u,v\rangle \iff \{ùë•,\{ùë•\}\}=\{u,\{u\}\}, x=u,\{ùë•\}=\{u\} x=\{u\},u=\{ùë•\} x=\{\{x\}\} x \langle x,y\rangle=\{\{x\},\{x,y\}\} 
\langle x,y\rangle=\{\{\{x\},\emptyset\},\{\{y\}\}
","['elementary-set-theory', 'set-theory']"
12,"If sets $X$ and $Y$ have at least two elements each, then $X \cup Y \preceq X \times Y$","If sets  and  have at least two elements each, then",X Y X \cup Y \preceq X \times Y,"This is a problem from Derek Goldrei's Classic Set Theory, a book that I am currently working through. This is in a chapter titled 'Cardinals (without the Axiom of Choice)' in case that context is necessary. If sets $X$ and $Y$ have at least two elements each, then $X \cup Y \preceq X \times Y$ I've been struggling to come up with an injection to prove this. I understand what it's saying is analogous to saying that $x + y \leq xy$ when $x$ and $y$ are both greater than or equal to $2$ , and I thought by writing that proof out I would get some insight into proving the original statement, but that did not happen. I have written out a few finite examples and of course the injections are immediately spotted, but I haven't been able to form a general function. Going straight from $X \cup Y$ to $X \times Y$ doesn't seem feasible because there will be multiple ordered pairs for any given element in $X \cup Y$ . So I believe there will be some intermediate set(s) that I need to map $X \cup Y$ to in order to eventually map to $X \times Y$ such that all of the intermediate mappings are injections. I'm not necessarily looking for a full solution, more so a nudge in the right direction. Thanks.","This is a problem from Derek Goldrei's Classic Set Theory, a book that I am currently working through. This is in a chapter titled 'Cardinals (without the Axiom of Choice)' in case that context is necessary. If sets and have at least two elements each, then I've been struggling to come up with an injection to prove this. I understand what it's saying is analogous to saying that when and are both greater than or equal to , and I thought by writing that proof out I would get some insight into proving the original statement, but that did not happen. I have written out a few finite examples and of course the injections are immediately spotted, but I haven't been able to form a general function. Going straight from to doesn't seem feasible because there will be multiple ordered pairs for any given element in . So I believe there will be some intermediate set(s) that I need to map to in order to eventually map to such that all of the intermediate mappings are injections. I'm not necessarily looking for a full solution, more so a nudge in the right direction. Thanks.",X Y X \cup Y \preceq X \times Y x + y \leq xy x y 2 X \cup Y X \times Y X \cup Y X \cup Y X \times Y,"['elementary-set-theory', 'intuition']"
13,How to create infinitely many disjoint sets from infinitely many sets,How to create infinitely many disjoint sets from infinitely many sets,,"Suppose we have a countably infinite set $X$ and we have (countably) infinitely many subsets $A_1,A_2,\cdots\subseteq X$ which are non-empty and distinct (i.e. for any $i\neq j$ either $A_i\setminus A_j$ or $A_j\setminus A_i$ is non-empty). Is it possible (in ZF) to disjoint these sets i.e. come up with sets $B_1,B_2,\cdots\subseteq X$ that are non-empty and pairwise disjoint. Edit: it is not necessarily the case that $X$ is in bijection with $\omega$ in our model of ZF, we know that $X$ is countably infinite from outside our model.","Suppose we have a countably infinite set and we have (countably) infinitely many subsets which are non-empty and distinct (i.e. for any either or is non-empty). Is it possible (in ZF) to disjoint these sets i.e. come up with sets that are non-empty and pairwise disjoint. Edit: it is not necessarily the case that is in bijection with in our model of ZF, we know that is countably infinite from outside our model.","X A_1,A_2,\cdots\subseteq X i\neq j A_i\setminus A_j A_j\setminus A_i B_1,B_2,\cdots\subseteq X X \omega X","['elementary-set-theory', 'set-theory', 'model-theory']"
14,Can (a certain interpretation of) the Ross-Littlewood paradox be formalized in set theory?,Can (a certain interpretation of) the Ross-Littlewood paradox be formalized in set theory?,,"In the Ross-Littlewood paradox , there is a supertask that goes as follows: At step 1, you add 10 balls to a jar labeled 1 through 10 and remove ball #1. At step 2, you add 10 balls to a jar labeled 11 through 20 and remove ball #2. At step 3, you add 10 balls to a jar labeled 21 through 30 and remove ball #3. This process goes on inductively, with each step taking half the time of the previous step (so that all this takes place in finite time). The question is, how many balls are left in the jar after the supertask is done? Based on the literature, it seems there are two sensible conclusions: either you can say the scenario is not physically sensible and thus there is no answer, or you can say there are precisely zero balls left. Now, my question is not about the paradox , so please leave the debate about it aside. Under some suitable interpretation , we can try to think about the process of adding and removing balls in terms of set theory with the final result being zero balls left. When I try to think about this, I am thinking of defining the sets $$ S_{1} = (\varnothing\cup\{1, \ldots, 10\})\setminus\{1\}, \qquad S_{2} = (S_{1}\cup\{11, \ldots, 20\})\setminus\{2\}, \qquad S_{3} = (S_{2}\cup\{21, \ldots, 30\})\setminus\{3\}, \qquad \ldots. $$ In general, $$ S_{n+1} = (S_{n}\cup\{10n+1, \ldots, 10(n+1)\})\setminus\{n+1\}. $$ We can either think of this as an infinite sequence of sets $S_{1}, S_{2}, \ldots$ or as an infinite sequence of operations (union, setminus, union, setminus, etc.) done to sets. Either way, it seems like there ought to be some sort of ""set limit"" which would be the empty set $\{\}$ . Is there any way in which this can be formalized? I am aware there are cases where no ""set limit"" could be assigned. For example, if we define $T_{1} = \{5\}$ , $T_{2} = \varnothing$ , $T_{3} = \{5\}$ , $T_{4} = \varnothing, \ldots$ , then I think there likely can't be any ""set limit"" assigned. However, I don't think this spoils the original question, because there are plenty of sums in real analysis that don't have any result such as $\sum_{n\ge 0} (-1)^{n}$ . The fact that the result of this sum is undefined doesn't mean other sums can't have a well-defined result. Indeed, we can formalize infinite sums by limits (under the epsilon-delta definition of limits) perfectly well and we can even tell which series converge and which don't. Is there anything analogous to this for sets?","In the Ross-Littlewood paradox , there is a supertask that goes as follows: At step 1, you add 10 balls to a jar labeled 1 through 10 and remove ball #1. At step 2, you add 10 balls to a jar labeled 11 through 20 and remove ball #2. At step 3, you add 10 balls to a jar labeled 21 through 30 and remove ball #3. This process goes on inductively, with each step taking half the time of the previous step (so that all this takes place in finite time). The question is, how many balls are left in the jar after the supertask is done? Based on the literature, it seems there are two sensible conclusions: either you can say the scenario is not physically sensible and thus there is no answer, or you can say there are precisely zero balls left. Now, my question is not about the paradox , so please leave the debate about it aside. Under some suitable interpretation , we can try to think about the process of adding and removing balls in terms of set theory with the final result being zero balls left. When I try to think about this, I am thinking of defining the sets In general, We can either think of this as an infinite sequence of sets or as an infinite sequence of operations (union, setminus, union, setminus, etc.) done to sets. Either way, it seems like there ought to be some sort of ""set limit"" which would be the empty set . Is there any way in which this can be formalized? I am aware there are cases where no ""set limit"" could be assigned. For example, if we define , , , , then I think there likely can't be any ""set limit"" assigned. However, I don't think this spoils the original question, because there are plenty of sums in real analysis that don't have any result such as . The fact that the result of this sum is undefined doesn't mean other sums can't have a well-defined result. Indeed, we can formalize infinite sums by limits (under the epsilon-delta definition of limits) perfectly well and we can even tell which series converge and which don't. Is there anything analogous to this for sets?"," S_{1} = (\varnothing\cup\{1, \ldots, 10\})\setminus\{1\}, \qquad S_{2} = (S_{1}\cup\{11, \ldots, 20\})\setminus\{2\}, \qquad S_{3} = (S_{2}\cup\{21, \ldots, 30\})\setminus\{3\}, \qquad \ldots.   S_{n+1} = (S_{n}\cup\{10n+1, \ldots, 10(n+1)\})\setminus\{n+1\}.  S_{1}, S_{2}, \ldots \{\} T_{1} = \{5\} T_{2} = \varnothing T_{3} = \{5\} T_{4} = \varnothing, \ldots \sum_{n\ge 0} (-1)^{n}","['sequences-and-series', 'elementary-set-theory', 'recreational-mathematics', 'paradoxes']"
15,Does every preorder induce a partial order?,Does every preorder induce a partial order?,,"A (non-strict) preorder is defined as a reflexive and transitive homogenous relation; a (non-strict) partial order is defined as a reflexive, antisymmetric, and transitive homogenous relation. Clearly, every partial order is a preorder but not every preorder needs to be a partial order (cf. [1]). However, it seems to me that every preorder induces a partial order via the following construction: Every preorder induces a strict preorder (an irreflexive, transitive relation). [2] Every strict preorder is a strict partial order (an irreflexive, transitive, antisymmetric relation). [3] Every strict partial order induces a (non-strict) partial order. [4] Is that correct or where did I go wrong? I appreciate any help you can provide. Sources: [1] StackExchange: Preorders vs partial orders - Clarification [2] Wikipedia: Strict preorder induced by a preorder [3] Wikipedia on preorders: ""A binary relation is a strict preorder if and only if it is a strict partial order."" [4] Wikipedia on partial orders: ""Conversely, a strict partial order $<$ on $P$ may be converted to a non-strict partial order"".","A (non-strict) preorder is defined as a reflexive and transitive homogenous relation; a (non-strict) partial order is defined as a reflexive, antisymmetric, and transitive homogenous relation. Clearly, every partial order is a preorder but not every preorder needs to be a partial order (cf. [1]). However, it seems to me that every preorder induces a partial order via the following construction: Every preorder induces a strict preorder (an irreflexive, transitive relation). [2] Every strict preorder is a strict partial order (an irreflexive, transitive, antisymmetric relation). [3] Every strict partial order induces a (non-strict) partial order. [4] Is that correct or where did I go wrong? I appreciate any help you can provide. Sources: [1] StackExchange: Preorders vs partial orders - Clarification [2] Wikipedia: Strict preorder induced by a preorder [3] Wikipedia on preorders: ""A binary relation is a strict preorder if and only if it is a strict partial order."" [4] Wikipedia on partial orders: ""Conversely, a strict partial order on may be converted to a non-strict partial order"".",< P,"['elementary-set-theory', 'order-theory']"
16,Why is $g(A) \cap g(B) \subseteq g(A \cap B)$ not true?,Why is  not true?,g(A) \cap g(B) \subseteq g(A \cap B),"The following is from Understanding Analysis, Stephen Abbott. Show that, for an arbitrary function $g : \mathbb{R} ‚Üí \mathbb{R}$ , it is always true that $$g(A \cap B) \subseteq g(A) \cap g(B)$$ for all sets $A, B > \subseteq R$ . Question: I want to understand this better by also understanding why the opposite statement is not true: $$g(A) \cap g(B) \subseteq g(A \cap B)$$ My flawed attempt at answering the original question is as follows: let's say $y \in g(A \cap B)$ if $x \in A \cap B$ then both of the following statements must be true: (1) $x \in A$ and (2) $x \in B$ using only the first statement: if $x \in A$ then $y \in g(A)$ using only the second statement: if $x \in B$ then $y \in g(B)$ but since both statements have to be true, we can say $y \in g(A) \cap g(B)$ that is, $g(A \cap B) \subseteq g(A) \cap g(B)$ The reason I believe this is flawed , is because it doesn't allow me to say why the opposite $g(A) \cap g(B) \subseteq g(A \cap B)$ is not true. Exploration I can think of examples to show why the opposite is not true, for example: $g(x) = x^2$ and $A=[-2,-1], B=[1,2]$ has $A \cap B = \emptyset$ , but $g(A) = g(B) = [1,4]$ One of the ideas I am trying to explore is which step of the above proof would not work for the opposite: I can ""split the domain"" , a statement about $A \cap B$ into two statements, one about $A$ and one about $B$ . But I can't ""merge the co-domains"" , statements about $g(A)$ and $g(B)$ into a single statement about $A \cap B$ And the reason for this is because the co-domains might not be 1-to-1 unique (injective function?). I would appreciate identifying the flaw in the attempted proof, which will I hope shed light on why the opposite statement is not true.","The following is from Understanding Analysis, Stephen Abbott. Show that, for an arbitrary function , it is always true that for all sets . Question: I want to understand this better by also understanding why the opposite statement is not true: My flawed attempt at answering the original question is as follows: let's say if then both of the following statements must be true: (1) and (2) using only the first statement: if then using only the second statement: if then but since both statements have to be true, we can say that is, The reason I believe this is flawed , is because it doesn't allow me to say why the opposite is not true. Exploration I can think of examples to show why the opposite is not true, for example: and has , but One of the ideas I am trying to explore is which step of the above proof would not work for the opposite: I can ""split the domain"" , a statement about into two statements, one about and one about . But I can't ""merge the co-domains"" , statements about and into a single statement about And the reason for this is because the co-domains might not be 1-to-1 unique (injective function?). I would appreciate identifying the flaw in the attempted proof, which will I hope shed light on why the opposite statement is not true.","g : \mathbb{R} ‚Üí \mathbb{R} g(A \cap B) \subseteq g(A) \cap g(B) A, B
> \subseteq R g(A) \cap g(B) \subseteq g(A \cap B) y \in g(A \cap B) x \in A \cap B x \in A x \in B x \in A y \in g(A) x \in B y \in g(B) y \in g(A) \cap g(B) g(A \cap B) \subseteq g(A) \cap g(B) g(A) \cap g(B) \subseteq g(A \cap B) g(x) = x^2 A=[-2,-1], B=[1,2] A \cap B = \emptyset g(A) = g(B) = [1,4] A \cap B A B g(A) g(B) A \cap B",['elementary-set-theory']
17,Why does $ x \in (A \cap B)^c \implies x \in A^c \cup B^c $?,Why does ?, x \in (A \cap B)^c \implies x \in A^c \cup B^c ,"The following is true: $$ \boxed{ x \in (A \cap B)^c \implies x \in A^c \cup B^c }$$ Notation - here $S^c$ is the complement of the set $S$ . Question: Why is this true? I know it is true by constructing a Venn diagram to show that it is. However I would like to see a step-by-step argument based on the fundamental definitions of sets and the union/intersection/complement operators. This question also asks the same question but the comments and answers fail to provide a solution to the specific question of why . Further research: Understanding Analysis, Second Edition, by the well respected Stephen Abbott, has an exercise and an official solution by the author. To quote the step I am not understanding: If $x \in (A \cap B)^c$ then $x \notin (A \cap B)$ . But this implies $x \notin A$ or $x \notin B$ . Why does this imply $x \notin A$ or $x \notin B$ ? This is not obvious to me. Again, to clarify, I can draw Venn diagrams to confirm the truth but I would like to see logical steps based on fundamental definitions or axions if possible. Attempting to think about this in plain English with a real-world example to see if it helps .. doesn't seem to help: If it is not summer and hot, then it is not summer or not hot.","The following is true: Notation - here is the complement of the set . Question: Why is this true? I know it is true by constructing a Venn diagram to show that it is. However I would like to see a step-by-step argument based on the fundamental definitions of sets and the union/intersection/complement operators. This question also asks the same question but the comments and answers fail to provide a solution to the specific question of why . Further research: Understanding Analysis, Second Edition, by the well respected Stephen Abbott, has an exercise and an official solution by the author. To quote the step I am not understanding: If then . But this implies or . Why does this imply or ? This is not obvious to me. Again, to clarify, I can draw Venn diagrams to confirm the truth but I would like to see logical steps based on fundamental definitions or axions if possible. Attempting to think about this in plain English with a real-world example to see if it helps .. doesn't seem to help: If it is not summer and hot, then it is not summer or not hot.", \boxed{ x \in (A \cap B)^c \implies x \in A^c \cup B^c } S^c S x \in (A \cap B)^c x \notin (A \cap B) x \notin A x \notin B x \notin A x \notin B,['elementary-set-theory']
18,Any partition of an at most countable set has a set of representatives.,Any partition of an at most countable set has a set of representatives.,,"I'm trying to understand the demonstration of the following proposition Any partition of an at most countable set has a set of representatives Proof: Let $\mathcal{P}$ be a partition of $A$ . Then there exists an equivalence relation $\sim$ on $A$ induced by $\mathcal{P}$ . Since $A$ is at most countable, the set of equivalence classes, $A / \sim=\left\{[a]_{\sim}: a \in A\right\}$ , is at most countable. Hence, $$ A / \sim=\left\langle\left[a_1\right]_{\sim},\left[a_2\right]_{\sim}, \ldots\right\rangle, $$ and so there is a set of representatives: $\left\{a_1, a_2, \ldots\right\}$ . I do not understand why this result has come about: $$ A / \sim=\left\langle\left[a_1\right]_{\sim},\left[a_2\right]_{\sim}, \ldots\right\rangle, $$ How to get to it?","I'm trying to understand the demonstration of the following proposition Any partition of an at most countable set has a set of representatives Proof: Let be a partition of . Then there exists an equivalence relation on induced by . Since is at most countable, the set of equivalence classes, , is at most countable. Hence, and so there is a set of representatives: . I do not understand why this result has come about: How to get to it?","\mathcal{P} A \sim A \mathcal{P} A A / \sim=\left\{[a]_{\sim}: a \in A\right\} 
A / \sim=\left\langle\left[a_1\right]_{\sim},\left[a_2\right]_{\sim}, \ldots\right\rangle,
 \left\{a_1, a_2, \ldots\right\} 
A / \sim=\left\langle\left[a_1\right]_{\sim},\left[a_2\right]_{\sim}, \ldots\right\rangle,
","['elementary-set-theory', 'set-theory', 'cardinals']"
19,what is the Cardinality of subsets of Z of size 3,what is the Cardinality of subsets of Z of size 3,,"I need to find out the cardinality of the subsets of Z of size 3, |N| = ◊ê0 |R| = ◊ê, thats how we defined it in class. My idea is to build a ZxZ matrix, we can see that the subsets of size 2 are all under the main diagonal. now we can build a path and for each step we name the current element we standing on the number of the step, we get a 1:1 and onto function from N --> ZxZ and we can conclude that the cardinality of the subsets of Z of size 2 is ◊ê0, now we take all those ZxZ pairs we walked on and place them on another matrix Z x (ZxZ), and now we can make a new path, but the problem I encounter is that there are many many repetitions and elements such as (-1,-1,0) that cant be a subset. can i ignore them and say : we number only valid and not seen already subsets? or is this approach not logical in the first place? Thanks in advance for the help","I need to find out the cardinality of the subsets of Z of size 3, |N| = ◊ê0 |R| = ◊ê, thats how we defined it in class. My idea is to build a ZxZ matrix, we can see that the subsets of size 2 are all under the main diagonal. now we can build a path and for each step we name the current element we standing on the number of the step, we get a 1:1 and onto function from N --> ZxZ and we can conclude that the cardinality of the subsets of Z of size 2 is ◊ê0, now we take all those ZxZ pairs we walked on and place them on another matrix Z x (ZxZ), and now we can make a new path, but the problem I encounter is that there are many many repetitions and elements such as (-1,-1,0) that cant be a subset. can i ignore them and say : we number only valid and not seen already subsets? or is this approach not logical in the first place? Thanks in advance for the help",,"['combinatorics', 'elementary-set-theory', 'cardinals']"
20,"Prove or disprove. $\bigcup_{i\in I} \bigcap_{j\in J} C_{i,j} = \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j}.$ [duplicate]",Prove or disprove.  [duplicate],"\bigcup_{i\in I} \bigcap_{j\in J} C_{i,j} = \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j}.","This question already has answers here : Counterexample, union of intersections, intersection of unions (2 answers) Closed last year . Let $\{ C_{i,j} : i\in I \text{ and } j\in J \}$ be a family of sets. Assume the set $I$ (of indices $i$ ) is arbitrary, non-empty, and non-enumerable. Similarly, assume the set $J$ (of indices $j$ ) is arbitrary, non-empty, and non-enumerable. Prove or disprove the equality $$\bigcup_{i\in I} \bigcap_{j\in J} C_{i,j} = \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j}.$$ Check my proof of this equality. Any errors? To prove that the equality is true, we need to show two inclusions. First, we will show that $$\bigcup_{i\in I} \bigcap_{j\in J} C_{i,j} \subseteq \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j}.$$ Suppose $x$ belongs to $\bigcup_{i\in I} \bigcap_{j\in J} C_{i,j}$ . This means that there exists an index $i_0$ in $I$ such that $x \in \bigcap_{j\in J} C_{i_0,j}$ . For all $j \in J$ , we have $x \in C_{i_0,j}$ , therefore $x \in \bigcup_{i\in I} C_{i,j}$ for all $j \in J$ . This implies that $x$ belongs to $\bigcap_{j\in J} \bigcup_{i\in I} C_{i,j}$ , as desired. Now, let's show that $$\bigcap_{j\in J} \bigcup_{i\in I} C_{i,j} \subseteq \bigcup_{i\in I} \bigcap_{j\in J} C_{i,j}.$$ Suppose $x$ belongs to $\bigcap_{j\in J} \bigcup_{i\in I} C_{i,j}$ . This means that for all $j \in J$ , we have $x \in \bigcup_{i\in I} C_{i,j}$ . Therefore, for each $j \in J$ , there exists an index $i_j$ in $I$ such that $x \in C_{i_j,j}$ . If for each index $j$ we choose a unique index $i_j$ , we can define a function $\varphi: J\to I$ by setting $\varphi(j)=i_{j}$ . Then, for all $j \in J$ , we have $x \in C_{i_j,j}$ , which implies that $x$ belongs to $\bigcap_{j\in J} C_{i_j,j}$ . Therefore, $x$ belongs to $\bigcup_{i\in \varphi(J)} \bigcap_{j\in J} C_{i,j}$ . On the other hand, since $\varphi(J)\subset I$ , we have $$\bigcup_{i\in \varphi(J)} \bigcap_{j\in J} C_{i,j} \subseteq \bigcup_{i\in I} \bigcap_{j\in J} C_{i,j}$$ With this, we conclude that $$\bigcup_{i\in I} \bigcap_{j\in J} C_{i,j} = \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j}$$ is true.","This question already has answers here : Counterexample, union of intersections, intersection of unions (2 answers) Closed last year . Let be a family of sets. Assume the set (of indices ) is arbitrary, non-empty, and non-enumerable. Similarly, assume the set (of indices ) is arbitrary, non-empty, and non-enumerable. Prove or disprove the equality Check my proof of this equality. Any errors? To prove that the equality is true, we need to show two inclusions. First, we will show that Suppose belongs to . This means that there exists an index in such that . For all , we have , therefore for all . This implies that belongs to , as desired. Now, let's show that Suppose belongs to . This means that for all , we have . Therefore, for each , there exists an index in such that . If for each index we choose a unique index , we can define a function by setting . Then, for all , we have , which implies that belongs to . Therefore, belongs to . On the other hand, since , we have With this, we conclude that is true.","\{ C_{i,j} : i\in I \text{ and } j\in J \} I i J j \bigcup_{i\in I} \bigcap_{j\in J} C_{i,j} = \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j}. \bigcup_{i\in I} \bigcap_{j\in J} C_{i,j} \subseteq \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j}. x \bigcup_{i\in I} \bigcap_{j\in J} C_{i,j} i_0 I x \in \bigcap_{j\in J} C_{i_0,j} j \in J x \in C_{i_0,j} x \in \bigcup_{i\in I} C_{i,j} j \in J x \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j} \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j} \subseteq \bigcup_{i\in I} \bigcap_{j\in J} C_{i,j}. x \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j} j \in J x \in \bigcup_{i\in I} C_{i,j} j \in J i_j I x \in C_{i_j,j} j i_j \varphi: J\to I \varphi(j)=i_{j} j \in J x \in C_{i_j,j} x \bigcap_{j\in J} C_{i_j,j} x \bigcup_{i\in \varphi(J)} \bigcap_{j\in J} C_{i,j} \varphi(J)\subset I \bigcup_{i\in \varphi(J)} \bigcap_{j\in J} C_{i,j} \subseteq \bigcup_{i\in I} \bigcap_{j\in J} C_{i,j} \bigcup_{i\in I} \bigcap_{j\in J} C_{i,j} = \bigcap_{j\in J} \bigcup_{i\in I} C_{i,j}","['elementary-set-theory', 'solution-verification']"
21,Formally defining and understanding the summation over a finite set,Formally defining and understanding the summation over a finite set,,"Let $S$ be a finite, nonempty set. Then there exists a positive integer $n$ and a bijective map $\phi: [n]\rightarrow S$ , where $[n]:=[1, n]\cap \mathbb{Z}$ . Let $(Y, +)$ be an abelian group, and $f: S\rightarrow Y$ . It seems that the summation over a set is defined to be $$ \sum_{x\in S} f(x):=\sum_{i=1}^n ¬†f(\phi(i)),$$ even though Wikipedia gives it as an identity (as if it would be a consequence of some more elementary properties; see the fourth identity in the Wikipedia page). It turns out that this is well-defined as the value does not depend on the choice of the bijection $\phi$ . So we have a rigorous definition for the sum. However, it is also important to have an intuitive understanding of it. We want $\Sigma_{x\in S} f(x)$ to mean that $f$ is evaluated at every element of $S$ precisely once, and those evaluations are added together; no other terms are added. What would be the easiest way to verify that the formal definition corresponds to intuition? Summations over a set are done all the time even without a thought, but I had never encountered the formal definition before. The definition seems to be somewhat complicated in the sense that it involves bijections, but we are dealing with something which you would expect to be very elementary.","Let be a finite, nonempty set. Then there exists a positive integer and a bijective map , where . Let be an abelian group, and . It seems that the summation over a set is defined to be even though Wikipedia gives it as an identity (as if it would be a consequence of some more elementary properties; see the fourth identity in the Wikipedia page). It turns out that this is well-defined as the value does not depend on the choice of the bijection . So we have a rigorous definition for the sum. However, it is also important to have an intuitive understanding of it. We want to mean that is evaluated at every element of precisely once, and those evaluations are added together; no other terms are added. What would be the easiest way to verify that the formal definition corresponds to intuition? Summations over a set are done all the time even without a thought, but I had never encountered the formal definition before. The definition seems to be somewhat complicated in the sense that it involves bijections, but we are dealing with something which you would expect to be very elementary.","S n \phi: [n]\rightarrow S [n]:=[1, n]\cap \mathbb{Z} (Y, +) f: S\rightarrow Y  \sum_{x\in S} f(x):=\sum_{i=1}^n ¬†f(\phi(i)), \phi \Sigma_{x\in S} f(x) f S","['elementary-set-theory', 'summation', 'definition', 'intuition']"
22,Prove the commutation of smallest sigma-algebra and inverse,Prove the commutation of smallest sigma-algebra and inverse,,"Let $f:Œ© \toŒ©'$ , and let $G$ be a class of subsets of $Œ©'$ . Show that $\sigma(f^{-1}(G))=f^{-1}(\sigma(G))$ . It is not hard to verfify that $f^{-1}(\sigma(G))$ is a $\sigma$ -algebra, and also $G\subset\sigma(G)$ , so $f^{-1}(G)\subset f^{-1}(\sigma(G))$ so we have $\sigma(f^{-1}(G))\subset f^{-1}(\sigma(G))$ , but how to prove the other direction?","Let , and let be a class of subsets of . Show that . It is not hard to verfify that is a -algebra, and also , so so we have , but how to prove the other direction?",f:Œ© \toŒ©' G Œ©' \sigma(f^{-1}(G))=f^{-1}(\sigma(G)) f^{-1}(\sigma(G)) \sigma G\subset\sigma(G) f^{-1}(G)\subset f^{-1}(\sigma(G)) \sigma(f^{-1}(G))\subset f^{-1}(\sigma(G)),"['real-analysis', 'elementary-set-theory']"
23,Is $\mathcal P(A \cap B) \subseteq \mathcal P(A) \cap \mathcal P(B)$ for all sets A and B?,Is  for all sets A and B?,\mathcal P(A \cap B) \subseteq \mathcal P(A) \cap \mathcal P(B),"My question is: Is $\mathcal P(A \cap B) \subseteq \mathcal P(A) \cap \mathcal P(B)$ for all sets A and B? I'm pretty lost on this but I have tried to solve it and I need some help. Let's say $A=\{1, 2, 3\}$ and $B=\{2, 3, 4\}$ Then $\mathcal P(A \cap B) = \mathcal P(\{2, 3\})=\{ \{\emptyset\}, \{2, 3\}, \{2\}, \{3\} \}$ And $\mathcal P(A) \cap \mathcal P(B)=\mathcal P(\{ \{\emptyset\}, \{1, 2, 3\}, \{1, 2\}, \{2, 3\}, \{1, 3\}, \{1\}, \{2\}, \{3\} \})\cap\mathcal P(\{ \{\emptyset\}, \{2, 3, 4\}, \{2, 3\}, \{2, 4\}, \{3, 4\}, \{2\}, \{3\}, \{4\} \})=\{ \{\emptyset\},\{2, 3\}, \{2\}, \{3\} \}$ Does this mean that the original statement is true? If so, how can we prove that it's true? Thanks in advance.","My question is: Is for all sets A and B? I'm pretty lost on this but I have tried to solve it and I need some help. Let's say and Then And Does this mean that the original statement is true? If so, how can we prove that it's true? Thanks in advance.","\mathcal P(A \cap B) \subseteq \mathcal P(A) \cap \mathcal P(B) A=\{1, 2, 3\} B=\{2, 3, 4\} \mathcal P(A \cap B) = \mathcal P(\{2, 3\})=\{ \{\emptyset\}, \{2, 3\}, \{2\}, \{3\} \} \mathcal P(A) \cap \mathcal P(B)=\mathcal P(\{ \{\emptyset\}, \{1, 2, 3\}, \{1, 2\}, \{2, 3\}, \{1, 3\}, \{1\}, \{2\}, \{3\} \})\cap\mathcal P(\{ \{\emptyset\}, \{2, 3, 4\}, \{2, 3\}, \{2, 4\}, \{3, 4\}, \{2\}, \{3\}, \{4\} \})=\{ \{\emptyset\},\{2, 3\}, \{2\}, \{3\} \}",['elementary-set-theory']
24,Real-world set theory/combinatorics problem,Real-world set theory/combinatorics problem,,"I have a real-world problem, and, unfortunately, being an engineer, I feel compelled to solve it. I went to Walmart the other day and attempted to purchase eleven over-the-counter (OTC) health-related products totaling $104.07. At checkout, $$61.54  of the total was approved for payment by my insurance OTC benefit card, while $42.53 of the total was not approved (which I paid for in cash.) The receipt does NOT indicate which items were approved and which were not. The problem I'm trying to solve is: Which items were approved and which were not? The eleven items and their costs are as follows: Gauze pads       2.34 Alcohol          3.48 Antibiotic cream 4.12 Lidocaine cream  4.94 Bandages         4.97 Hydrocortisone   7.12 Peptobismol      8.56 Toothpaste      10.59 Melatonin       13.76 Ibuprofan 19.71 Loratadine 24.48 In summary: There are eleven elements in total divided into two sets. Set ""A"" contains ""n"" elements totaling $61.54. Set ""B"" contains ""11-n"" elements totaling $42.53. What are the ""n"" elements contained in set ""A""? I don't have a clue as to how to go about solving this. I do realize, however, that there may be more than one solution to this problem. Edit: Taxes have been removed from the totals.","I have a real-world problem, and, unfortunately, being an engineer, I feel compelled to solve it. I went to Walmart the other day and attempted to purchase eleven over-the-counter (OTC) health-related products totaling $104.07. At checkout, $$61.54  of the total was approved for payment by my insurance OTC benefit card, while $42.53 of the total was not approved (which I paid for in cash.) The receipt does NOT indicate which items were approved and which were not. The problem I'm trying to solve is: Which items were approved and which were not? The eleven items and their costs are as follows: Gauze pads       2.34 Alcohol          3.48 Antibiotic cream 4.12 Lidocaine cream  4.94 Bandages         4.97 Hydrocortisone   7.12 Peptobismol      8.56 Toothpaste      10.59 Melatonin       13.76 Ibuprofan 19.71 Loratadine 24.48 In summary: There are eleven elements in total divided into two sets. Set ""A"" contains ""n"" elements totaling $61.54. Set ""B"" contains ""11-n"" elements totaling $42.53. What are the ""n"" elements contained in set ""A""? I don't have a clue as to how to go about solving this. I do realize, however, that there may be more than one solution to this problem. Edit: Taxes have been removed from the totals.",,"['combinatorics', 'elementary-set-theory']"
25,Intersection of decreasing sequence of sets,Intersection of decreasing sequence of sets,,"In an exam, my teacher wrote this problem , I proved it in a similar way to the answer in that post , but he pointed out to me that a step in the proof is wrong. What my teacher says Let $A_1 \supset A_2 \supset A_3 \supset \dots$ sequence of decreasing sets We can construct the following sequence of disjoint sets $B_1 = A_1 - A_2$ $B_2 = A_2 - A_3$ $B_3 = A_3 - A_4$ $\dots$ let $A = \cap_{k \in \mathbb{N}} A_k$ , then $A$ and $\cup_{k = N}^{\infty} B_k$ do not form a partition of $A_N$ , are not disjoint, in fact $A$ is contained in the union $\cup_{k = N}^{\infty} B_k$ . But I think he is wrong, and I have this proof to prove that step. My proof $A_1 - \cap_{k \in \mathbb{N}} A_k  = A_1 \cap (\cap_{k \in \mathbb{N}} A_k)^c = A_1 \cap (\cup_{k \in \mathbb{N}} A_k^c)$ The intersection is distributed over the union, then $A_1 \cap (\cup_{k \in \mathbb{N}} A_k^c) = \cup_{k \in \mathbb{N}} (A_1 \cap A_k^c) = $ $= \emptyset \cup (A_1 - A_2) \cup (A_1 - A_3) \cup (A_1 - A_4) \cup ... = $ since the sequence is decreasing, finally $= \emptyset \cup (A_1 - A_2) \cup (A_1 - A_3) \cup (A_1 - A_4) \cup ... = $ $= \emptyset \cup (A_1 - A_2) \cup (A_2 - A_3) \cup (A_3 - A_4) \cup ... =$ $= \cup_{k \in \mathbb{N}} B_k$ This is $A_1 - \cap_{k \in \mathbb{N}} A_k  = \cup_{k \in \mathbb{N}} B_k$ . The case $A_N - \cap_{k \in \mathbb{N}} A_k  = \cup_{k = N}^{\infty} B_k$ is analogous. Is my proof correct?","In an exam, my teacher wrote this problem , I proved it in a similar way to the answer in that post , but he pointed out to me that a step in the proof is wrong. What my teacher says Let sequence of decreasing sets We can construct the following sequence of disjoint sets let , then and do not form a partition of , are not disjoint, in fact is contained in the union . But I think he is wrong, and I have this proof to prove that step. My proof The intersection is distributed over the union, then since the sequence is decreasing, finally This is . The case is analogous. Is my proof correct?",A_1 \supset A_2 \supset A_3 \supset \dots B_1 = A_1 - A_2 B_2 = A_2 - A_3 B_3 = A_3 - A_4 \dots A = \cap_{k \in \mathbb{N}} A_k A \cup_{k = N}^{\infty} B_k A_N A \cup_{k = N}^{\infty} B_k A_1 - \cap_{k \in \mathbb{N}} A_k  = A_1 \cap (\cap_{k \in \mathbb{N}} A_k)^c = A_1 \cap (\cup_{k \in \mathbb{N}} A_k^c) A_1 \cap (\cup_{k \in \mathbb{N}} A_k^c) = \cup_{k \in \mathbb{N}} (A_1 \cap A_k^c) =  = \emptyset \cup (A_1 - A_2) \cup (A_1 - A_3) \cup (A_1 - A_4) \cup ... =  = \emptyset \cup (A_1 - A_2) \cup (A_1 - A_3) \cup (A_1 - A_4) \cup ... =  = \emptyset \cup (A_1 - A_2) \cup (A_2 - A_3) \cup (A_3 - A_4) \cup ... = = \cup_{k \in \mathbb{N}} B_k A_1 - \cap_{k \in \mathbb{N}} A_k  = \cup_{k \in \mathbb{N}} B_k A_N - \cap_{k \in \mathbb{N}} A_k  = \cup_{k = N}^{\infty} B_k,['elementary-set-theory']
26,How can we conclude about the probability of two events?,How can we conclude about the probability of two events?,,"Suppose there are two events $E_1$ and $E_2$ such that if both $E_1$ and $E_2$ holds then another event $E_3$ that will occur. How do I derive that $P(E_{1} \cap E_{2}) \leq P(E_{3})$ ? If $E_{1} \implies E_{2}$ is also true, how can we derive $P(E_{1}) \leq P(E_{2})$ ? Could anybody explain it with proper proof and example?","Suppose there are two events and such that if both and holds then another event that will occur. How do I derive that ? If is also true, how can we derive ? Could anybody explain it with proper proof and example?",E_1 E_2 E_1 E_2 E_3 P(E_{1} \cap E_{2}) \leq P(E_{3}) E_{1} \implies E_{2} P(E_{1}) \leq P(E_{2}),"['probability', 'elementary-set-theory']"
27,Is set equality a primitive notion or a relation whose definition is given by the axiom of extensionality?,Is set equality a primitive notion or a relation whose definition is given by the axiom of extensionality?,,"I saw some sources claiming that the equality of sets is a primitive notion (i.e. according to Wikipedia, a concept which is not defined in terms of previously defined concepts). However, the axiom of extensionality gives that two sets are said to be equal iff $\forall x(x \in A \iff x \in B)$ . Isn't set equality then a concept which can be defined in terms of the the primitive notion of set equality together with the concepts from first order logic? (i.e. isn't set equality not a primitive notion?)","I saw some sources claiming that the equality of sets is a primitive notion (i.e. according to Wikipedia, a concept which is not defined in terms of previously defined concepts). However, the axiom of extensionality gives that two sets are said to be equal iff . Isn't set equality then a concept which can be defined in terms of the the primitive notion of set equality together with the concepts from first order logic? (i.e. isn't set equality not a primitive notion?)",\forall x(x \in A \iff x \in B),"['elementary-set-theory', 'set-theory']"
28,Is the union of the intersection the same as the intersection of the union?,Is the union of the intersection the same as the intersection of the union?,,"If $A_{nm}$ is a subset of $A$ for $n = 1,2, \dots$ and $m = 1,2, \dots$ is it necessarily true that $$\displaystyle\bigcup_{n=1}^\infty \Big[ \displaystyle\bigcap_{m=1}^\infty A_{nm} \Big] = \displaystyle\bigcap_{m=1}^\infty \Big[ \displaystyle\bigcup_{n=1}^\infty A_{nm} \Big] \, \, ? $$ I claim that this is the case. So I attempt to prove it by showing double inclusion which implies equality. Proof . Let $x \in \displaystyle\bigcup_{n=1}^\infty \Big[ \displaystyle\bigcap_{m=1}^\infty A_{nm} \Big]$ . By definition of union, there exists $\displaystyle\bigcap_{m=1}^\infty A_{n_0 m}$ so that $x \in \displaystyle\bigcap_{m=1}^\infty A_{n_0 m}$ . By definition of intersection, we have $$\forall \, m \in \mathbb{N}, x \in A_{n_0 m}$$ Now notice that  for any $m \in \mathbb{N}$ , we also have $x \in A_{n_0 m} \subset \displaystyle\bigcup_{n=1}^\infty A_{nm}$ . Now from here, I want to somehow get an intersection on the outside of that union to show inclusion the first direction, but I'm not sure how to do so. Maybe union and intersection aren't interchangeable. Maybe there's a counterexample to this claim. Any advice?","If is a subset of for and is it necessarily true that I claim that this is the case. So I attempt to prove it by showing double inclusion which implies equality. Proof . Let . By definition of union, there exists so that . By definition of intersection, we have Now notice that  for any , we also have . Now from here, I want to somehow get an intersection on the outside of that union to show inclusion the first direction, but I'm not sure how to do so. Maybe union and intersection aren't interchangeable. Maybe there's a counterexample to this claim. Any advice?","A_{nm} A n = 1,2, \dots m = 1,2, \dots \displaystyle\bigcup_{n=1}^\infty \Big[ \displaystyle\bigcap_{m=1}^\infty A_{nm} \Big] = \displaystyle\bigcap_{m=1}^\infty \Big[ \displaystyle\bigcup_{n=1}^\infty A_{nm} \Big] \, \, ?  x \in \displaystyle\bigcup_{n=1}^\infty \Big[ \displaystyle\bigcap_{m=1}^\infty A_{nm} \Big] \displaystyle\bigcap_{m=1}^\infty A_{n_0 m} x \in \displaystyle\bigcap_{m=1}^\infty A_{n_0 m} \forall \, m \in \mathbb{N}, x \in A_{n_0 m} m \in \mathbb{N} x \in A_{n_0 m} \subset \displaystyle\bigcup_{n=1}^\infty A_{nm}",['elementary-set-theory']
29,"Is (Baby) Rudin being lazy in Theorem 2.38? (I.e., assuming something holds for all sets in an infinite intersection is sufficient)","Is (Baby) Rudin being lazy in Theorem 2.38? (I.e., assuming something holds for all sets in an infinite intersection is sufficient)",,"The theorem in question is: If $\{I_n\}$ is a sequence of intervals on $\mathbb{R}^1$ such that $I_n\supset I_{n+1}$ , then $\cap_{n=1}^\infty I_n\neq\emptyset.$ Rudin says to let $I_n=[a_n,b_n]$ , and since $\{a_n\}$ is bounded above by $b_1$ , it has a sup, which we can call $x$ . $a_m \leq x\leq b_m$ , so $x\in I_m$ for all $m=1,2,3,...$ , so $x\in\cap_{n=1}^\infty I_n\Rightarrow\cap_{n=1}^\infty I_n\neq\emptyset.$ This strikes me as a bit odd: Rudin says something about every set in an infinite intersection and doesn't really worry about the potential qualitative difference between each object in the intersection and the intersection itself--e.g., each interval has a nonzero length, but the intersection may not. I suppose it doesn't matter here because membership doesn't seem to change qualitatively in the same way length does. Nevertheless, it does seem a bit 'sloppy' in a way to make the final deduction Rudin does. Or should it be clear on a case by case basis when this 'jump' is valid to make? It seems to me less 'sloppy' to show that $\cap_{n=1}^\infty I_n \supset [\alpha,\beta],$ where $\alpha=\sup\{a_n\}$ and $\beta=\inf\{b_n\}$ . And then show $\alpha\leq\beta$ . Since $\alpha\leq\beta$ , $[\alpha,\beta]\neq\emptyset$ , $\cap_{n=1}^\infty I_n\neq\emptyset.$ But perhaps the same 'jump' I accuse Rudin of making is still here, just better hidden from me...","The theorem in question is: If is a sequence of intervals on such that , then Rudin says to let , and since is bounded above by , it has a sup, which we can call . , so for all , so This strikes me as a bit odd: Rudin says something about every set in an infinite intersection and doesn't really worry about the potential qualitative difference between each object in the intersection and the intersection itself--e.g., each interval has a nonzero length, but the intersection may not. I suppose it doesn't matter here because membership doesn't seem to change qualitatively in the same way length does. Nevertheless, it does seem a bit 'sloppy' in a way to make the final deduction Rudin does. Or should it be clear on a case by case basis when this 'jump' is valid to make? It seems to me less 'sloppy' to show that where and . And then show . Since , , But perhaps the same 'jump' I accuse Rudin of making is still here, just better hidden from me...","\{I_n\} \mathbb{R}^1 I_n\supset I_{n+1} \cap_{n=1}^\infty I_n\neq\emptyset. I_n=[a_n,b_n] \{a_n\} b_1 x a_m \leq x\leq b_m x\in I_m m=1,2,3,... x\in\cap_{n=1}^\infty I_n\Rightarrow\cap_{n=1}^\infty I_n\neq\emptyset. \cap_{n=1}^\infty I_n \supset [\alpha,\beta], \alpha=\sup\{a_n\} \beta=\inf\{b_n\} \alpha\leq\beta \alpha\leq\beta [\alpha,\beta]\neq\emptyset \cap_{n=1}^\infty I_n\neq\emptyset.","['real-analysis', 'general-topology', 'elementary-set-theory']"
30,Inequality for a sorted set,Inequality for a sorted set,,"Given $X = \{x_1, x_2, \cdots, x_n\}, n \geq2$ such that $x_1 \lt x_2 \lt \cdots \lt x_n$ , could you prove: $ \frac{1}{n^2}\sum_{1 \leq i \lt j \leq n}(x_i - x_j)^2 \leq \frac{(x_1 - x_n)^2}{4} $ I can easily prove for $n=2, 3, 4, 5$ , but I'm failed to do it for an arbitrary $n$ .","Given such that , could you prove: I can easily prove for , but I'm failed to do it for an arbitrary .","X = \{x_1, x_2, \cdots, x_n\}, n \geq2 x_1 \lt x_2 \lt \cdots \lt x_n 
\frac{1}{n^2}\sum_{1 \leq i \lt j \leq n}(x_i - x_j)^2 \leq \frac{(x_1 - x_n)^2}{4}
 n=2, 3, 4, 5 n","['inequality', 'elementary-set-theory', 'variance']"
31,Simple proof about prime filters.,Simple proof about prime filters.,,"Exercise. Let $F$ be an true filter in a set $X$ . Show that $F$ is an ultrafilter ( $\Leftrightarrow$ prime) iff a subset of $X$ intersects every set of $F$ then this same subset is in $F$ . UPDATE. My attempt. $(\Rightarrow)$ Suppose $F$ is an ultrafilter. Then, we have that $A,B \in F \Rightarrow A \cap B \in F$ and $A \in F, A \subseteq B \Rightarrow B \in F$ by definition of a filter. Let $S \subset X$ s.t. $S \cap A \neq \emptyset$ , $\forall A \in F$ . This guarantees that there is another filter $F'$ s.t. $F \subseteq F'$ and $S \in F'$ , but $F$ is maximal and thus $F=F'$ , meaning $S \in F$ , proving what's wanted. $(\Leftarrow)$ Suppose now that the second condition is verified for every subset $S$ of $X$ . By the same reasoning as before, we can guarantee that there exists a filter $F'$ s.t. $F \subseteq F'$ and $S \in F'$ . If we show that $F=F'$ we have that $F$ is maximal, and that's what we want. Let's assume that $F \neq F'$ , i.e., that there is a set $Z$ such that $Z \in F'$ and $Z \notin F$ . Then we have: $(X\backslash Z)\cup Z = X \in F$ ( $F$ is a filter). But this is equivalent to saying that $X\backslash Z \in F \vee Z \in F$ but $Z \notin F$ and thus $X \backslash Z \in F \Rightarrow X\backslash Z \in F'\Rightarrow Z \notin F'$ which is a contradiction. Thus $F=F'$ e so $F$ is maximal. Is this formulation right? I have some issues understanding this basic concepts about filters and some of my proofs go wrong because of it. Thanks for all the help in advance.","Exercise. Let be an true filter in a set . Show that is an ultrafilter ( prime) iff a subset of intersects every set of then this same subset is in . UPDATE. My attempt. Suppose is an ultrafilter. Then, we have that and by definition of a filter. Let s.t. , . This guarantees that there is another filter s.t. and , but is maximal and thus , meaning , proving what's wanted. Suppose now that the second condition is verified for every subset of . By the same reasoning as before, we can guarantee that there exists a filter s.t. and . If we show that we have that is maximal, and that's what we want. Let's assume that , i.e., that there is a set such that and . Then we have: ( is a filter). But this is equivalent to saying that but and thus which is a contradiction. Thus e so is maximal. Is this formulation right? I have some issues understanding this basic concepts about filters and some of my proofs go wrong because of it. Thanks for all the help in advance.","F X F \Leftrightarrow X F F (\Rightarrow) F A,B \in F \Rightarrow A \cap B \in F A \in F, A \subseteq B \Rightarrow B \in F S \subset X S \cap A \neq \emptyset \forall A \in F F' F \subseteq F' S \in F' F F=F' S \in F (\Leftarrow) S X F' F \subseteq F' S \in F' F=F' F F \neq F' Z Z \in F' Z \notin F (X\backslash Z)\cup Z = X \in F F X\backslash Z \in F \vee Z \in F Z \notin F X \backslash Z \in F \Rightarrow X\backslash Z \in F'\Rightarrow Z \notin F' F=F' F","['elementary-set-theory', 'filters']"
32,Existence of a set with property that all subsets are members,Existence of a set with property that all subsets are members,,"Within Zermelo Fraenkel Set theory (Edit: Without the axiom of regularity ), Does there exist a nonempty set $X$ with the property that if $Y \subseteq X$ , then $Y \in X$ ? My guess is no, but currently unable to prove it. Would the set $S = \{ x \in X : x \not\subseteq X \}$ derive a contradiction ? Or is this provable without the axiom of regularity?","Within Zermelo Fraenkel Set theory (Edit: Without the axiom of regularity ), Does there exist a nonempty set with the property that if , then ? My guess is no, but currently unable to prove it. Would the set derive a contradiction ? Or is this provable without the axiom of regularity?",X Y \subseteq X Y \in X S = \{ x \in X : x \not\subseteq X \},['elementary-set-theory']
33,"Finding $\bigcap\limits_{n=1}^{\infty} \left(- \frac{1}{n}, \frac{n}{2n+1}\right)$ [duplicate]",Finding  [duplicate],"\bigcap\limits_{n=1}^{\infty} \left(- \frac{1}{n}, \frac{n}{2n+1}\right)","This question already has answers here : Finding and proving $\bigcap\limits_{n=1}^{\infty} \left(- \frac{1}{n}, \frac{n}{2n+1}\right)$ (2 answers) Closed 2 years ago . Upon defining $A_n = \left(- \frac{1}{n}, \frac{n}{2n+1}\right)$ , I am trying to find and prove $\bigcap\limits_{n=1}^{\infty} A_n$ . Since $- \frac{1}{n}, \frac{n}{2n+1}$ converge to $0$ as sequences, I am fairly sure that the answer is $0$ (though I don't have any other intuition other than thinking of them sequences). Here is my attempt at proving it. I claim that $\bigcap\limits_{n-1}^{\infty} A_n = \{0\}$ . For any $n \in \mathbb{N}$ , we have $- \frac{1}{n} < 0 < \frac{n}{2n+1}$ , so $0 \in A_n$ for all $n$ , hence $0 \in \bigcap\limits_{n=1}^{\infty} A_n$ . Furthermore, given $x < 0$ , we can find a sufficiently large $N$ such that $- \frac{1}{N} > x$ . so $x \not \in A_n$ and hence $x \not \in \bigcap\limits_{n=1}^{\infty} A_n$ . Furthermore, given $x > 0$ , we can find an $N \in \mathbb{N}$ for which $N > x$ . Then, since $N \geq 1$ , $2N + 1 \geq 1$ , so $x(2N + 1) \geq x > N$ , so $x > \frac{N}{2N+1}$ , so $x \not \in A_N$ , and hence $x \not \in \bigcap\limits_{n=1}^{\infty} A_n$ . Therefore, if $x \neq 0$ , $x \not \in \bigcap\limits_{n=1}^{\infty}$ , so $\bigcap\limits_{n=1}^{\infty} A_n = \{0\}$ . How does this look? Is there a better way to either intuitively come up with this or to prove this? I'm not particularly comfortable with how I proved that $x > 0$ was not in the intersection.","This question already has answers here : Finding and proving $\bigcap\limits_{n=1}^{\infty} \left(- \frac{1}{n}, \frac{n}{2n+1}\right)$ (2 answers) Closed 2 years ago . Upon defining , I am trying to find and prove . Since converge to as sequences, I am fairly sure that the answer is (though I don't have any other intuition other than thinking of them sequences). Here is my attempt at proving it. I claim that . For any , we have , so for all , hence . Furthermore, given , we can find a sufficiently large such that . so and hence . Furthermore, given , we can find an for which . Then, since , , so , so , so , and hence . Therefore, if , , so . How does this look? Is there a better way to either intuitively come up with this or to prove this? I'm not particularly comfortable with how I proved that was not in the intersection.","A_n = \left(- \frac{1}{n}, \frac{n}{2n+1}\right) \bigcap\limits_{n=1}^{\infty} A_n - \frac{1}{n}, \frac{n}{2n+1} 0 0 \bigcap\limits_{n-1}^{\infty} A_n = \{0\} n \in \mathbb{N} - \frac{1}{n} < 0 < \frac{n}{2n+1} 0 \in A_n n 0 \in \bigcap\limits_{n=1}^{\infty} A_n x < 0 N - \frac{1}{N} > x x \not \in A_n x \not \in \bigcap\limits_{n=1}^{\infty} A_n x > 0 N \in \mathbb{N} N > x N \geq 1 2N + 1 \geq 1 x(2N + 1) \geq x > N x > \frac{N}{2N+1} x \not \in A_N x \not \in \bigcap\limits_{n=1}^{\infty} A_n x \neq 0 x \not \in \bigcap\limits_{n=1}^{\infty} \bigcap\limits_{n=1}^{\infty} A_n = \{0\} x > 0","['elementary-set-theory', 'solution-verification']"
34,Logic of proofs involving variables and ‚Äúfor all‚Äù statements,Logic of proofs involving variables and ‚Äúfor all‚Äù statements,,"It is taught that in order to prove ""for all"" statements such as $$P(G): \mathrm{For \ all \ groups} \ G \ \mathrm{it \ holds \ that} \ \{(g,g+g) \in G \times G \ | \ g \in G\} \ \mathrm{is \ a \ set}$$ one assumes that $G$ is a group and then proves the statement $P(G)$ . I wonder about the logic behind this and ""what is logically allowed"", which is never explained in introductory courses. Q $1$ : What does ""Let $G$ be a group"" even mean? A $1$ : As far as I can tell, it means that one assumes that all properties of the object of interest, in this case a group, are true and one calls the object of interest $G$ . Explicitly this would mean that it is true that $G$ is a set equipped with an addition/multiplication (whatever definition you are using) satisfying the group laws. Note that as far as I can tell one does not know which elements are contained in $G$ , only that $G$ is a set satisfying some extra properties. Q $2$ : Why is the above a set? Since I use the naive set definition, meaning that any unordered collection of objects are sets, it is true that the collection of all $(g,g+g)$ is a set, which is exactly $\{(g,2g) \in G \times G \ | \ g \in G\}$ . Q $3$ : Why does this prove the statement? Or more generally, why does this method suffice to prove a for all statement in general? I think there would be two ways to view this: $(1)$ One proved the statement is correct using nothing but the properties of a group which any group obviously satisfies. Thus the proof is ""a path"" one could follow for any explicit group to show that the statement is indeed true. $(2)$ Assume there exists a group which does not satisfy a statement proven this way. Then one could go through the process of the proof with this object and comes to a contradiction.","It is taught that in order to prove ""for all"" statements such as one assumes that is a group and then proves the statement . I wonder about the logic behind this and ""what is logically allowed"", which is never explained in introductory courses. Q : What does ""Let be a group"" even mean? A : As far as I can tell, it means that one assumes that all properties of the object of interest, in this case a group, are true and one calls the object of interest . Explicitly this would mean that it is true that is a set equipped with an addition/multiplication (whatever definition you are using) satisfying the group laws. Note that as far as I can tell one does not know which elements are contained in , only that is a set satisfying some extra properties. Q : Why is the above a set? Since I use the naive set definition, meaning that any unordered collection of objects are sets, it is true that the collection of all is a set, which is exactly . Q : Why does this prove the statement? Or more generally, why does this method suffice to prove a for all statement in general? I think there would be two ways to view this: One proved the statement is correct using nothing but the properties of a group which any group obviously satisfies. Thus the proof is ""a path"" one could follow for any explicit group to show that the statement is indeed true. Assume there exists a group which does not satisfy a statement proven this way. Then one could go through the process of the proof with this object and comes to a contradiction.","P(G): \mathrm{For \ all \ groups} \ G \ \mathrm{it \ holds \ that} \ \{(g,g+g) \in G \times G \ | \ g \in G\} \ \mathrm{is \ a \ set} G P(G) 1 G 1 G G G G 2 (g,g+g) \{(g,2g) \in G \times G \ | \ g \in G\} 3 (1) (2)","['abstract-algebra', 'elementary-set-theory', 'logic', 'proof-writing']"
35,A question on Cantor's proof of countability of algebraic numbers.,A question on Cantor's proof of countability of algebraic numbers.,,"So the exercise 2.2 in Baby Rudin led me to Cantor's original proof of the countability of algebraic numbers. See here for a translation in English of Cantor's paper. The question I have is regarding the computation of the height function as defined by Cantor, for the equation: $$\begin{equation}a_0\omega^n+a_1\omega^{n-1}+\dots+a_n=0\tag{1}\end{equation}$$ where all coefficients are integers. Here is the relevant bit from Cantor: If we go back to equation (1), which an algebraic number $\omega$ satisfies and which, according to our restrictions, is completely determined, we can call the sum of the absolute values of the coefficients and the number $n-1$ (where $n$ is the degree of $\omega$ ) the height of the number $\omega$ and denote it with $N$ ; using the now common notation, we therefore have $$N=n-1+|a_0|+|a_1|+\dots+|a_n|.\tag{3}$$ According to this, the height $N$ is for each real algebraic number a specified positive integer; conversely for each positive integer value of $N$ there are only a finite number of algebraic real numbers with height $N$ ; let the number of these be $\varphi(N)$ ; for example, $\varphi(1)=1$ ; $\varphi(2)=2$ ; $\varphi(3)=4.$ Question: But when I try to compute $\varphi(N)$ , it doesn't match with Cantor's results! For example, consider $\varphi(2)$ - there are two possible cases, one for degree $n=1$ and other for degree $n=2$ . For $n=1$ we have from (3), $$2=1-1+|a_0|+|a_1|\implies 2=|a_0|+|a_1|\implies|a_0|=|a_1|=1\quad\text{or}\quad |a_0|=2$$ which corresponds respectively to the equations $\omega\pm 1=0$ and $2\omega = 0$ . Thus for $n=1$ alone we get $3$ such $\omega$ . Where is my mistake in computing $\varphi$ ?","So the exercise 2.2 in Baby Rudin led me to Cantor's original proof of the countability of algebraic numbers. See here for a translation in English of Cantor's paper. The question I have is regarding the computation of the height function as defined by Cantor, for the equation: where all coefficients are integers. Here is the relevant bit from Cantor: If we go back to equation (1), which an algebraic number satisfies and which, according to our restrictions, is completely determined, we can call the sum of the absolute values of the coefficients and the number (where is the degree of ) the height of the number and denote it with ; using the now common notation, we therefore have According to this, the height is for each real algebraic number a specified positive integer; conversely for each positive integer value of there are only a finite number of algebraic real numbers with height ; let the number of these be ; for example, ; ; Question: But when I try to compute , it doesn't match with Cantor's results! For example, consider - there are two possible cases, one for degree and other for degree . For we have from (3), which corresponds respectively to the equations and . Thus for alone we get such . Where is my mistake in computing ?",\begin{equation}a_0\omega^n+a_1\omega^{n-1}+\dots+a_n=0\tag{1}\end{equation} \omega n-1 n \omega \omega N N=n-1+|a_0|+|a_1|+\dots+|a_n|.\tag{3} N N N \varphi(N) \varphi(1)=1 \varphi(2)=2 \varphi(3)=4. \varphi(N) \varphi(2) n=1 n=2 n=1 2=1-1+|a_0|+|a_1|\implies 2=|a_0|+|a_1|\implies|a_0|=|a_1|=1\quad\text{or}\quad |a_0|=2 \omega\pm 1=0 2\omega = 0 n=1 3 \omega \varphi,"['real-analysis', 'elementary-set-theory']"
36,Proving $\operatorname{card} \mathbb{R} = \operatorname{card} 2^{\mathbb{N}}$ *without* using Cantor-Schr√∂der-Bernstein theorem?,Proving  *without* using Cantor-Schr√∂der-Bernstein theorem?,\operatorname{card} \mathbb{R} = \operatorname{card} 2^{\mathbb{N}},"On math.stackexchange.com and elsewhere proofs of the equality $\operatorname{card} \mathbb{R} = \operatorname{card} 2^{\mathbb{N}}$ , or equivalently the equality $\operatorname{card} \mathbb{R} = \operatorname{card} \mathcal{P}(\mathbb{N})$ , abound that use the Cantor-Bernstein theorem. What is a proof that does not use that theorem? P.S. All the proofs that I previously knew, including those appearing in two undergraduate texts I authored, use CB and prove CB there, too.","On math.stackexchange.com and elsewhere proofs of the equality , or equivalently the equality , abound that use the Cantor-Bernstein theorem. What is a proof that does not use that theorem? P.S. All the proofs that I previously knew, including those appearing in two undergraduate texts I authored, use CB and prove CB there, too.",\operatorname{card} \mathbb{R} = \operatorname{card} 2^{\mathbb{N}} \operatorname{card} \mathbb{R} = \operatorname{card} \mathcal{P}(\mathbb{N}),"['elementary-set-theory', 'cardinals']"
37,When does downward closure commute with supremum?,When does downward closure commute with supremum?,,"Let $A$ be a suplattices, and suppose we have a family $\{a_i\}_{i\in I}\subseteq A.$ Is $\bigcup_{i\in I}(\operatorname{\downarrow}a_i) = \operatorname{\downarrow} \sup_{i\in I}(a_i)$ in general? Here $\downarrow a$ means the principal downward closed sets (order ideal) generated by $a.$ I believe this assertion is wrong in general, and my counter example is $I=\{1, 2\}$ and $A=\{0\lt a_1\lt 1, 0\lt a_2\lt a\lt 1\}.$ Then $\operatorname{\downarrow} a_1\cup\operatorname{\downarrow} a_2=\{0, a_1, a_2\}$ while $\operatorname{\downarrow}(a_1\lor a_2)=A.$ Am I correct? Are there any obvious conditions on $A$ or $\{a_i\}_{i\in I}$ that would guaranteed the property in the above question? I am looking for a condition like $A$ being distributive. This sounds like a very vague question. But, hopefully more experienced people can tell me something useful.","Let be a suplattices, and suppose we have a family Is in general? Here means the principal downward closed sets (order ideal) generated by I believe this assertion is wrong in general, and my counter example is and Then while Am I correct? Are there any obvious conditions on or that would guaranteed the property in the above question? I am looking for a condition like being distributive. This sounds like a very vague question. But, hopefully more experienced people can tell me something useful.","A \{a_i\}_{i\in I}\subseteq A. \bigcup_{i\in I}(\operatorname{\downarrow}a_i) = \operatorname{\downarrow} \sup_{i\in I}(a_i) \downarrow a a. I=\{1, 2\} A=\{0\lt a_1\lt 1, 0\lt a_2\lt a\lt 1\}. \operatorname{\downarrow} a_1\cup\operatorname{\downarrow} a_2=\{0, a_1, a_2\} \operatorname{\downarrow}(a_1\lor a_2)=A. A \{a_i\}_{i\in I} A","['elementary-set-theory', 'order-theory', 'supremum-and-infimum', 'lattice-orders']"
38,"Find a relation on $\{1, 2, 3\}$ [duplicate]",Find a relation on  [duplicate],"\{1, 2, 3\}","This question already has answers here : Examples and Counterexamples of Relations which Satisfy Certain Properties (2 answers) Closed 3 years ago . For each of the eight subsets of {reflexive, symmetric, transitive}, find a relation on $\{1, 2, 3\}$ that has the properties in that subset, but not the properties that are not in the subset. What I have done This is the same question asked here . I have found the same possible subsets. But for each of them instead of establishing the relationship via ordered pairs, I have defined them with an operation. The possible subsets of {reflexive, symmetric, transitive} are $T_0=\{\varnothing \}, T_1=\{\text{Reflexive}\}, T_2=\{\text{Symmetric}\}, T_3=\{\text{Transitive}\}, T_4=\{\text{Reflexive, Symmetric}\},  T_5=\{\text{Reflexive, Transitive}\}, T_6=\{\text{Symmetric, Transitive}\}, T_7=\{\text{Reflexive, Symmetric, Transitive}\}$ . For $T_{0}$ , define the relation $\rho$ on $\{1, 2, 3\}$ via $a\rho b$ iff $a-b=1$ . For $T_{1}$ ? For $T_{2}$ , define the relation $\rho$ on $\{1, 2, 3\}$ via $a\rho b$ iff $ab$ is even. For $T_{3}$ , define the relation $\rho$ on $\{1, 2, 3\}$ via $a\rho b$ iff $a<b$ . For $T_{4}$ , define the relation $\rho$ on $\{1, 2, 3\}$ via $a\rho b$ iff $|a-b|\leq 1$ . For $T_{5}$ , define the relation $\rho$ on $\{1, 2, 3\}$ via $a\rho b$ iff $a\leq b$ . For $T_{6}$ ? For $T_{7}$ , define the relation $\rho$ on $\{1, 2, 3\}$ via $a\rho b$ iff $a= b$ . For $T_1$ and for $T_6$ it is easy to find the relation via ordered pairs, but defining the relation by means of an operation has not been possible for me, could you please help me? If I completed the list using ordered pairs, I think it would be inelegant.","This question already has answers here : Examples and Counterexamples of Relations which Satisfy Certain Properties (2 answers) Closed 3 years ago . For each of the eight subsets of {reflexive, symmetric, transitive}, find a relation on that has the properties in that subset, but not the properties that are not in the subset. What I have done This is the same question asked here . I have found the same possible subsets. But for each of them instead of establishing the relationship via ordered pairs, I have defined them with an operation. The possible subsets of {reflexive, symmetric, transitive} are . For , define the relation on via iff . For ? For , define the relation on via iff is even. For , define the relation on via iff . For , define the relation on via iff . For , define the relation on via iff . For ? For , define the relation on via iff . For and for it is easy to find the relation via ordered pairs, but defining the relation by means of an operation has not been possible for me, could you please help me? If I completed the list using ordered pairs, I think it would be inelegant.","\{1, 2, 3\} T_0=\{\varnothing \}, T_1=\{\text{Reflexive}\}, T_2=\{\text{Symmetric}\}, T_3=\{\text{Transitive}\}, T_4=\{\text{Reflexive, Symmetric}\},  T_5=\{\text{Reflexive, Transitive}\}, T_6=\{\text{Symmetric, Transitive}\}, T_7=\{\text{Reflexive, Symmetric, Transitive}\} T_{0} \rho \{1, 2, 3\} a\rho b a-b=1 T_{1} T_{2} \rho \{1, 2, 3\} a\rho b ab T_{3} \rho \{1, 2, 3\} a\rho b a<b T_{4} \rho \{1, 2, 3\} a\rho b |a-b|\leq 1 T_{5} \rho \{1, 2, 3\} a\rho b a\leq b T_{6} T_{7} \rho \{1, 2, 3\} a\rho b a= b T_1 T_6","['elementary-set-theory', 'examples-counterexamples', 'relations']"
39,Complicated comparing sets,Complicated comparing sets,,"Consider the open interval $(0, 1)$ and the closed interval $[0, 1]$ . We claim that $[0, 1] ‚âà (0, 1)$ . We deduced the equipotence $[0, 1] ‚âà (0, 1)$ by invoking the Schr¬®oder‚ÄìBernstein theorem, but we didn‚Äôt actually construct a bijection $[0, 1] ‚Üí (0, 1).$ (a) Verify that the function $h$ given by the following scheme is such a bijection: $$0\overset{h}{\longmapsto}\frac12\qquad\qquad\qquad\qquad\qquad\qquad\quad\,{}\\\frac1n\longmapsto\frac1{n+2}\qquad\text{for each integer }n\ge 1\\x\longmapsto x\qquad\qquad\qquad\qquad\quad\;\text{otherwise}$$ (b) The function $h$ in part (a) acts on $[0, 1]$ in a way that resembles the strategy of the hotel manager in the text below. How? Now imagine that there is a hotel with infinitely many rooms along an unending corridor: a first room, a second room, and so on. Imagine further that there is a person occupying each room; so we can reasonably say that there are exactly as many guests as there are rooms. You arrive at the hotel seeking a room, and the manager tells you, ‚ÄúAt the moment the rooms are all occupied, but we always have room for one more.‚Äù Whereupon she speaks into an intercom connected to all the rooms, saying, ‚ÄúAt the sound of the bell, each guest should step out into the corridor and move into the next room in line.‚Äù This clears out the first room, and you have a place to stay. Notice that although you thought you had enlarged the collection of guests by your presence, there are still as many hotel rooms as there are guests. My work is below: We are given function $h$ $$h(x)=\begin{cases}\cfrac1{n+2} & \text{for }x=\cfrac1n,n\ge 1\\\cfrac12 & \text{for }x=0\\x & \text{otherwise}\end{cases}$$ We know that a function from $A$ (the domain) to $B$ (the range) is both one-to-one and onto when no element of $B$ is the image of more than one element of $A,$ and all elements in $B$ are used. Functions that are both one-to-one and onto are referred to as bijective. Here we can say that $h(x)$ is an identity function as $x,$ in the form of $\frac1n$ and $x\ne0.$ We know that an identity function is bijective. For $x\ne\frac1n$ and $x\ne 0,$ $h(x)$ is bijective. Let us consider $x_1=\frac{1}{n_1},x_2=\frac{1}{n_2}$ and assume that $h(x_1)=h(x_2),$ so $h\left(\frac{1}{n_1}\right)=h\left(\frac{1}{n_2}\right).$ Then, $$\frac{1}{n_1+2}=\frac{1}{n_2+2}\iff n_1+2=n_2+2$$ Therefore, $n_1=n_2,$ thus $x_1=x_2$ which proves that $h(x)$ is one-to-one. For $n\ge 1,$ $\frac{1}{n+2}\ne\frac{1}{2}$ Thus, only $x=0$ maps to $\frac12.$ Let us check identity function for the numbers $y=\frac1n,n>2.$ If we have $y=\frac1n,$ then there exists an element $x$ such that $\frac1n=h\left(\frac{1}{n-2}\right),$ $x=\frac1{n-2}$ Therefore, $h(x)$ is onto, so we conclude that $h(x)$ is bijective. This question is driving me nuts. Please give me some advice on how to answer it concisely. Thank you so much!","Consider the open interval and the closed interval . We claim that . We deduced the equipotence by invoking the Schr¬®oder‚ÄìBernstein theorem, but we didn‚Äôt actually construct a bijection (a) Verify that the function given by the following scheme is such a bijection: (b) The function in part (a) acts on in a way that resembles the strategy of the hotel manager in the text below. How? Now imagine that there is a hotel with infinitely many rooms along an unending corridor: a first room, a second room, and so on. Imagine further that there is a person occupying each room; so we can reasonably say that there are exactly as many guests as there are rooms. You arrive at the hotel seeking a room, and the manager tells you, ‚ÄúAt the moment the rooms are all occupied, but we always have room for one more.‚Äù Whereupon she speaks into an intercom connected to all the rooms, saying, ‚ÄúAt the sound of the bell, each guest should step out into the corridor and move into the next room in line.‚Äù This clears out the first room, and you have a place to stay. Notice that although you thought you had enlarged the collection of guests by your presence, there are still as many hotel rooms as there are guests. My work is below: We are given function We know that a function from (the domain) to (the range) is both one-to-one and onto when no element of is the image of more than one element of and all elements in are used. Functions that are both one-to-one and onto are referred to as bijective. Here we can say that is an identity function as in the form of and We know that an identity function is bijective. For and is bijective. Let us consider and assume that so Then, Therefore, thus which proves that is one-to-one. For Thus, only maps to Let us check identity function for the numbers If we have then there exists an element such that Therefore, is onto, so we conclude that is bijective. This question is driving me nuts. Please give me some advice on how to answer it concisely. Thank you so much!","(0, 1) [0, 1] [0, 1] ‚âà (0, 1) [0, 1] ‚âà (0, 1) [0, 1] ‚Üí (0, 1). h 0\overset{h}{\longmapsto}\frac12\qquad\qquad\qquad\qquad\qquad\qquad\quad\,{}\\\frac1n\longmapsto\frac1{n+2}\qquad\text{for each integer }n\ge 1\\x\longmapsto x\qquad\qquad\qquad\qquad\quad\;\text{otherwise} h [0, 1] h h(x)=\begin{cases}\cfrac1{n+2} & \text{for }x=\cfrac1n,n\ge 1\\\cfrac12 & \text{for }x=0\\x & \text{otherwise}\end{cases} A B B A, B h(x) x, \frac1n x\ne0. x\ne\frac1n x\ne 0, h(x) x_1=\frac{1}{n_1},x_2=\frac{1}{n_2} h(x_1)=h(x_2), h\left(\frac{1}{n_1}\right)=h\left(\frac{1}{n_2}\right). \frac{1}{n_1+2}=\frac{1}{n_2+2}\iff n_1+2=n_2+2 n_1=n_2, x_1=x_2 h(x) n\ge 1, \frac{1}{n+2}\ne\frac{1}{2} x=0 \frac12. y=\frac1n,n>2. y=\frac1n, x \frac1n=h\left(\frac{1}{n-2}\right), x=\frac1{n-2} h(x) h(x)","['elementary-set-theory', 'solution-verification']"
40,Are there any interesting non standard models of $Q$?,Are there any interesting non standard models of ?,Q,"I've encountered a few of the models of Robinson arithmetic here a quick list: $\mathbb{N}\cup {\infty}$ (used to show Robinson arithmetic has a non standard model) $\mathbb{N}\cup \{a,b\}$ where the operations are defined so $a$ and $b$ do not commute. $\mathbb{Z}[x]^+$ which is the set of all integer polynomials with positive leading coefficient. (In this model you can show Robinson Arithmetic cannot prove all elements are odd or even.) All these models seem to be used only to show how weak Robinson Arithmetic is or rather what things it's unable to prove. Besides the natural numbers are there some models that have some importance beyond being used as a counter example? I am aware that any model of $Q$ must contain an isomorphic copy of the natural numbers. But for weak theories like the group axioms there are plenty of important ""models"" for example the symmetric group is studied for other reasons besides proving that the group axioms can't prove commutativity.","I've encountered a few of the models of Robinson arithmetic here a quick list: (used to show Robinson arithmetic has a non standard model) where the operations are defined so and do not commute. which is the set of all integer polynomials with positive leading coefficient. (In this model you can show Robinson Arithmetic cannot prove all elements are odd or even.) All these models seem to be used only to show how weak Robinson Arithmetic is or rather what things it's unable to prove. Besides the natural numbers are there some models that have some importance beyond being used as a counter example? I am aware that any model of must contain an isomorphic copy of the natural numbers. But for weak theories like the group axioms there are plenty of important ""models"" for example the symmetric group is studied for other reasons besides proving that the group axioms can't prove commutativity.","\mathbb{N}\cup {\infty} \mathbb{N}\cup \{a,b\} a b \mathbb{Z}[x]^+ Q","['elementary-set-theory', 'first-order-logic', 'model-theory']"
41,Step missing in the proof of $\mathbb{R}$ being uncountable.,Step missing in the proof of  being uncountable.,\mathbb{R},"Today I saw the proof of the uncountability of $\mathbb{R}$ , where given  a list of all elements of $\mathbb{R}$ , we produce an element not in the list by requiring that its $n$ -th digit is different from the $n$ -th digit of the $n$ -th element of the list. Since it has different decimal expansion from every element in the list, it can't be on the list. I think this last statement is actually wrong since in $\mathbb{R}$ one number can have more than one decimal expansion. So even if the decimal expansion of the newly generated element differs from those of the elements on the list, this doesn't mean that the element is not in the list. Am I right? and if so, how can the argument be fixed?","Today I saw the proof of the uncountability of , where given  a list of all elements of , we produce an element not in the list by requiring that its -th digit is different from the -th digit of the -th element of the list. Since it has different decimal expansion from every element in the list, it can't be on the list. I think this last statement is actually wrong since in one number can have more than one decimal expansion. So even if the decimal expansion of the newly generated element differs from those of the elements on the list, this doesn't mean that the element is not in the list. Am I right? and if so, how can the argument be fixed?",\mathbb{R} \mathbb{R} n n n \mathbb{R},"['elementary-set-theory', 'proof-explanation', 'real-numbers']"
42,Intersection of sets is indeed a set,Intersection of sets is indeed a set,,"My question is pretty straight forward - how do I use ZF axioms to prove that if $\{A\}_{i\in\Bbb{N}}$ is a family of sets, then $\bigcap_{i}A_i$ is a set? I feel like I should be using the axiom of union and the axiom of separation, but I'm not quite sure how.","My question is pretty straight forward - how do I use ZF axioms to prove that if is a family of sets, then is a set? I feel like I should be using the axiom of union and the axiom of separation, but I'm not quite sure how.",\{A\}_{i\in\Bbb{N}} \bigcap_{i}A_i,"['elementary-set-theory', 'axioms']"
43,Set theory difficult question on proving that set $\mathbf {H}$ always exists,Set theory difficult question on proving that set  always exists,\mathbf {H},"I have been puzzling over this question for literally hours: Let H be a 1011-element subset of the set {0, 1, 2, ..., 2021}. Prove that it has two (not necessarily distinct) elements a and b such that a+b is a power of 2. After watching a heap of Youtube videos about set theory, I have finally come up with this: $$\mathbf {H} \subset \mathbb {N} | \mathbf {H} _ z = m, m \in \mathbb {N}, 0 \leq m \leq 2021, |\mathbf {H}| = 1011 \\ \mathbf {J} = \{(a, b) | a + b = 2 ^ {n} | n \in \mathbb {N}\} \\ (\mathbf {H} _ x, \mathbf {H} _ y) \in \mathbf {J} | x \in \mathbb {N}, y \in \mathbb {N}, x \neq y$$ However, since I am very inexperienced, I can't solve this... I would really appreciate a solution and an explanation on how you have got to that answer :)","I have been puzzling over this question for literally hours: Let H be a 1011-element subset of the set {0, 1, 2, ..., 2021}. Prove that it has two (not necessarily distinct) elements a and b such that a+b is a power of 2. After watching a heap of Youtube videos about set theory, I have finally come up with this: However, since I am very inexperienced, I can't solve this... I would really appreciate a solution and an explanation on how you have got to that answer :)","\mathbf {H} \subset \mathbb {N} | \mathbf {H} _ z = m, m \in \mathbb {N}, 0 \leq m \leq 2021, |\mathbf {H}| = 1011 \\
\mathbf {J} = \{(a, b) | a + b = 2 ^ {n} | n \in \mathbb {N}\} \\
(\mathbf {H} _ x, \mathbf {H} _ y) \in \mathbf {J} | x \in \mathbb {N}, y \in \mathbb {N}, x \neq y",['elementary-set-theory']
44,Set notation with subscript and superscript,Set notation with subscript and superscript,,"In the ""The Hundred-Page Machine Learning Book"", the author uses the following notation to describe the set of all labeled feature vectors. $$\{(x_i,y_i)\}_{i=1}^N$$ What I understand: $\{\ldots\}$ denotes a set $x_i$ and $y_i$ are the feature vector and its label $i$ starts at $1$ and runs up to $N$ What I do not understand: Is this a common set notation? I did not find anything like this","In the ""The Hundred-Page Machine Learning Book"", the author uses the following notation to describe the set of all labeled feature vectors. What I understand: denotes a set and are the feature vector and its label starts at and runs up to What I do not understand: Is this a common set notation? I did not find anything like this","\{(x_i,y_i)\}_{i=1}^N \{\ldots\} x_i y_i i 1 N","['elementary-set-theory', 'notation']"
45,"Infinitely many $ n \in \mathbb{N} $ such that $ n^2+1 $ has two divisors $ a,b $ such that $a-b=n $",Infinitely many  such that  has two divisors  such that," n \in \mathbb{N}   n^2+1   a,b  a-b=n ","Prove that there is infinitely many $ n \in \mathbb{N} $ such that $ n^2+1 $ has two divisors $ a,b $ such that $a-b=n $ . It is obvious that if $ p\mid n^2+1 $ then $\gcd(p,n)=1$ . I tried to use the Chinese remainder theorem, but I got nothing. Please help me.","Prove that there is infinitely many such that has two divisors such that . It is obvious that if then . I tried to use the Chinese remainder theorem, but I got nothing. Please help me."," n \in \mathbb{N}   n^2+1   a,b  a-b=n   p\mid n^2+1  \gcd(p,n)=1","['number-theory', 'elementary-set-theory', 'modular-arithmetic', 'contest-math']"
46,Mobile families of sets and pure subsets,Mobile families of sets and pure subsets,,"Exercise This is Bourbaki Theory of Sets Chapter 3 Section 4 Exercise 11, English version: Let $A$ be a set and let $\mathcal{R}$ be a subset of the set $\mathcal{F}(A)$ of finite subsets of $A$ . $\mathcal{R}$ is said to be mobile if it satisfies the following condition: (MO) If $X$ , $Y$ are two distinct elements of $\mathcal{R}$ and if $z\in X\cap Y$ , then there exists $Z\subseteq X\cap Y$ belonging to $\mathcal{R}$ such that $z\notin Z$ . A subset $P$ of $A$ is then said to be pure if it contains no set belonging to $\mathcal{R}$ . a) Show that every pure subset of $A$ is contained in a maximal pure subset of $A$ . b) Let $M$ ba a maximal pure subset of $A$ . Show that for each $x\in X\setminus M$ there exists a unique finite subset $E_{M}(x)$ of $M$ such that $E_{M}(x)\cup\{x\}\in\mathcal{R}$ . Moreover, if $y\in E_M(x)$ , the set $(M\cup\{x\})\setminus\{y\}$ is a maximal pure subset of $A$ . c) Let $M$ , $N$ be two maximal pure subsets of $A$ , such that $N\setminus M$ is finite. Show that $|M|=|N|$ . d) Let $M$ , $N$ be two maximal pure subsets of $A$ , and put $N'=N\setminus M$ , $M'=M\setminus N$ . Show that: $$M'\subseteq\bigcup_{x\in N'}E_M(x).$$ Deduce that $|M|=|N|$ . Question I was able to do all this exercise, but, in the French version, the exercise assumes only a weaker condition: (MO') If $X$ , $Y$ are two distinct elements of $\mathcal{R}$ and if $z\in X\cap Y$ , then there exists $Z\subseteq X\cup Y$ belonging to $\mathcal{R}$ such that $z\notin Z$ instead of (MO), and was able to do items (a) to (c), but I do not know how to do item (d). Attempt There is my solution to items (a) to (c) assuming only (MO') and item (d) assuming (MO). a) Straightforward application of Zorn's lemma. In fact, if $\mathcal{A}$ is the set of all pure subsets of $A$ containing a given pure subset $P$ , then for every totally ordered subset $\mathcal{C}$ of $\mathcal{A}$ , if $\bigcup\mathcal{C}$ is not pure, then it contains an $R\in\mathcal{R}$ , but $R$ is finite, say, $R=\{a_1,\dots,a_n\}$ , so for $i=1,\dots,n$ there is a $Q_i\in\mathcal{C}$ such that $a_i\in Q_i$ , then there is a $Q\in\mathcal{C}$ such that $Q_1,\dots,Q_n\subseteq Q$ , so $R\subseteq Q$ , contradicting the purity of $Q$ ; therefore $\bigcup\mathcal{C}\in\mathcal{P}$ . b) Because of maximality of $M$ , there is an $E\in\mathcal{F}(M)$ such that $E\cup\{x\}\in\mathcal{R}$ . If $F\in\mathcal{F}(M)$ , $F\neq E$ and $F\cup\{x\}\in\mathcal{R}$ , then $E\cup\{x\}\neq F\cup\{x\}$ and $x\in\left(E\cup\{x\}\right)\cap\left(F\cup\{x\}\right)$ , so by (MO') the set $\left(\left(E\cup\{x\}\right)\cup\left(F\cup\{x\}\right)\right)\setminus\{x\}$ is not pure, but: $$\left(\left(E\cup\{x\}\right)\cup\left(F\cup\{x\}\right)\right)\setminus\{x\}\subseteq E\cup F\subseteq M,$$ so $M$ will not be pure, a contradiction. Let $y\in E$ . If $R\subseteq(M\cup\{x\})\setminus\{y\}$ and $R\in\mathcal{R}$ , then $R\subseteq M\cup\{x\}$ , so, by purity of $M$ , $R=G\cup\{x\}$ for some $G\in\mathcal{F}(M)$ , and by (a) we have $G=E$ , but $y\notin G$ and $y\in E$ , a contradiction. Therefore $(M\cup\{x\})\setminus\{y\}$ is pure. Let $z\in A\setminus((M\cup\{x\})\setminus\{y\})$ , then $z=y\text{ or }(z\notin M\text{ and }z\neq x)$ . For the case $z=y$ , we have $((M\cup\{x\})\setminus\{y\})\cup\{y\}=M\cup\{x\}$ , that is not pure. For the case $z\neq y$ , then $z\notin M$ and $z\neq x$ , so there is a $H\in\mathcal{F}(M)$ such that $H\cup\{z\}\in\mathcal{R}$ , so: If $y\notin H\cup\{z\}$ , then: $$H\cup\{z\}\subseteq (M\cup\{z\})\setminus\{y\}\subseteq((M\cup\{x\})\setminus\{y\})\cup\{z\}.$$ If $y\in S$ , then $y\in(E\cup\{x\})\cap(H\cup\{z\})$ , so $((E\cup\{x\})\cup(H\cup\{z\}))\setminus\{y\}$ is not pure, and: $$((E\cup\{x\})\cup(H\cup\{z\}))\setminus\{y\}\subseteq((M\cup\{x\})\setminus\{y\})\cup\{z\}.$$ Therefore $((M\cup\{x\})\setminus\{y\})\cup\{z\}$ is not pure. So $(M\cup\{x\})\setminus\{y\}$ is maximal. c) Induction on $|N\setminus M|$ . If $|N\setminus M|=0$ , then $N\subseteq M$ , so by maximality of $N$ we have $N=M$ , so $|M|=|N|$ . If $|N\setminus M|>0$ , then there is a $m\in M\setminus N$ and there is an $n\in E_N(m)$ , so by item (b) the set $N'=(N\cup\{m\})\setminus\{n\}$ is pure maximal and $|N'\setminus M|<|N\setminus M|$ , so by induction hypothesis we have $|M|=|N'|$ , but $|N'|=|N|$ , so $|M|=|N|$ . d) If we assume (MO), then for $m\in M'$ we have $E_N(m)\cup\{m\}\in\mathcal{R}$ , so $E_N(m)\cup\{m\}\nsubseteq M$ , but $m\in M$ , so $E_N(m)\nsubseteq M$ , so there is an $x\in E_N(m)$ such that $x\notin M$ , so $x\in N'$ , and $E_M(x)\cup\{x\}\in\mathcal{R}$ , therefore: $$x\in(E_M(x)\cup\{x\})\cap(E_N(m)\cup\{m\}),$$ so we have two cases: If $E_M(x)\cup\{x\}=E_N(m)\cup\{m\}$ , then $x\in N'$ and $m\in E_M(x)$ . If $E_M(x)\cup\{x\}\neq E_N(m)\cup\{m\},$ then by (MO) the set $((E_M(x)\cup\{x\})\cap(E_N(m)\cup\{m\}))\setminus\{x\}$ is not pure, but it is contained in $M$ , a contradiction. Finally, by virtue of (c), we are reduced to the case where $M'$ and $N'$ are infinite, so: $$|M'|\leq|\bigcup_{x\in N'}E_M(x)|\leq\sum_{x\in N'}|E_M(x)|\leq\sum_{x\in N'}\aleph_0=|N'|\aleph_0=|N'|,$$ and analogously $|N'|\leq |M'|$ , so $|M'|=|N'|$ , and we conclude that $|M|=|N|$ .","Exercise This is Bourbaki Theory of Sets Chapter 3 Section 4 Exercise 11, English version: Let be a set and let be a subset of the set of finite subsets of . is said to be mobile if it satisfies the following condition: (MO) If , are two distinct elements of and if , then there exists belonging to such that . A subset of is then said to be pure if it contains no set belonging to . a) Show that every pure subset of is contained in a maximal pure subset of . b) Let ba a maximal pure subset of . Show that for each there exists a unique finite subset of such that . Moreover, if , the set is a maximal pure subset of . c) Let , be two maximal pure subsets of , such that is finite. Show that . d) Let , be two maximal pure subsets of , and put , . Show that: Deduce that . Question I was able to do all this exercise, but, in the French version, the exercise assumes only a weaker condition: (MO') If , are two distinct elements of and if , then there exists belonging to such that instead of (MO), and was able to do items (a) to (c), but I do not know how to do item (d). Attempt There is my solution to items (a) to (c) assuming only (MO') and item (d) assuming (MO). a) Straightforward application of Zorn's lemma. In fact, if is the set of all pure subsets of containing a given pure subset , then for every totally ordered subset of , if is not pure, then it contains an , but is finite, say, , so for there is a such that , then there is a such that , so , contradicting the purity of ; therefore . b) Because of maximality of , there is an such that . If , and , then and , so by (MO') the set is not pure, but: so will not be pure, a contradiction. Let . If and , then , so, by purity of , for some , and by (a) we have , but and , a contradiction. Therefore is pure. Let , then . For the case , we have , that is not pure. For the case , then and , so there is a such that , so: If , then: If , then , so is not pure, and: Therefore is not pure. So is maximal. c) Induction on . If , then , so by maximality of we have , so . If , then there is a and there is an , so by item (b) the set is pure maximal and , so by induction hypothesis we have , but , so . d) If we assume (MO), then for we have , so , but , so , so there is an such that , so , and , therefore: so we have two cases: If , then and . If then by (MO) the set is not pure, but it is contained in , a contradiction. Finally, by virtue of (c), we are reduced to the case where and are infinite, so: and analogously , so , and we conclude that .","A \mathcal{R} \mathcal{F}(A) A \mathcal{R} X Y \mathcal{R} z\in X\cap Y Z\subseteq X\cap Y \mathcal{R} z\notin Z P A \mathcal{R} A A M A x\in X\setminus M E_{M}(x) M E_{M}(x)\cup\{x\}\in\mathcal{R} y\in E_M(x) (M\cup\{x\})\setminus\{y\} A M N A N\setminus M |M|=|N| M N A N'=N\setminus M M'=M\setminus N M'\subseteq\bigcup_{x\in N'}E_M(x). |M|=|N| X Y \mathcal{R} z\in X\cap Y Z\subseteq X\cup Y \mathcal{R} z\notin Z \mathcal{A} A P \mathcal{C} \mathcal{A} \bigcup\mathcal{C} R\in\mathcal{R} R R=\{a_1,\dots,a_n\} i=1,\dots,n Q_i\in\mathcal{C} a_i\in Q_i Q\in\mathcal{C} Q_1,\dots,Q_n\subseteq Q R\subseteq Q Q \bigcup\mathcal{C}\in\mathcal{P} M E\in\mathcal{F}(M) E\cup\{x\}\in\mathcal{R} F\in\mathcal{F}(M) F\neq E F\cup\{x\}\in\mathcal{R} E\cup\{x\}\neq F\cup\{x\} x\in\left(E\cup\{x\}\right)\cap\left(F\cup\{x\}\right) \left(\left(E\cup\{x\}\right)\cup\left(F\cup\{x\}\right)\right)\setminus\{x\} \left(\left(E\cup\{x\}\right)\cup\left(F\cup\{x\}\right)\right)\setminus\{x\}\subseteq E\cup F\subseteq M, M y\in E R\subseteq(M\cup\{x\})\setminus\{y\} R\in\mathcal{R} R\subseteq M\cup\{x\} M R=G\cup\{x\} G\in\mathcal{F}(M) G=E y\notin G y\in E (M\cup\{x\})\setminus\{y\} z\in A\setminus((M\cup\{x\})\setminus\{y\}) z=y\text{ or }(z\notin M\text{ and }z\neq x) z=y ((M\cup\{x\})\setminus\{y\})\cup\{y\}=M\cup\{x\} z\neq y z\notin M z\neq x H\in\mathcal{F}(M) H\cup\{z\}\in\mathcal{R} y\notin H\cup\{z\} H\cup\{z\}\subseteq (M\cup\{z\})\setminus\{y\}\subseteq((M\cup\{x\})\setminus\{y\})\cup\{z\}. y\in S y\in(E\cup\{x\})\cap(H\cup\{z\}) ((E\cup\{x\})\cup(H\cup\{z\}))\setminus\{y\} ((E\cup\{x\})\cup(H\cup\{z\}))\setminus\{y\}\subseteq((M\cup\{x\})\setminus\{y\})\cup\{z\}. ((M\cup\{x\})\setminus\{y\})\cup\{z\} (M\cup\{x\})\setminus\{y\} |N\setminus M| |N\setminus M|=0 N\subseteq M N N=M |M|=|N| |N\setminus M|>0 m\in M\setminus N n\in E_N(m) N'=(N\cup\{m\})\setminus\{n\} |N'\setminus M|<|N\setminus M| |M|=|N'| |N'|=|N| |M|=|N| m\in M' E_N(m)\cup\{m\}\in\mathcal{R} E_N(m)\cup\{m\}\nsubseteq M m\in M E_N(m)\nsubseteq M x\in E_N(m) x\notin M x\in N' E_M(x)\cup\{x\}\in\mathcal{R} x\in(E_M(x)\cup\{x\})\cap(E_N(m)\cup\{m\}), E_M(x)\cup\{x\}=E_N(m)\cup\{m\} x\in N' m\in E_M(x) E_M(x)\cup\{x\}\neq E_N(m)\cup\{m\}, ((E_M(x)\cup\{x\})\cap(E_N(m)\cup\{m\}))\setminus\{x\} M M' N' |M'|\leq|\bigcup_{x\in N'}E_M(x)|\leq\sum_{x\in N'}|E_M(x)|\leq\sum_{x\in N'}\aleph_0=|N'|\aleph_0=|N'|, |N'|\leq |M'| |M'|=|N'| |M|=|N|","['combinatorics', 'elementary-set-theory']"
47,"Prove that a transitive relation can be ""shortcutted""","Prove that a transitive relation can be ""shortcutted""",,"I want to prove the following theorem and already spent a lot of time on doing this, but almost unsuccessfully: Let $R$ be a transitive relation over the set $A$ . Prove that in the graphical representation of the relation (that is, the graph $(A, R)$ ), that $(u, v) \in R$ if $v$ is reachable from $u$ . So, reachability here I think means that there is a path from $u$ to $v$ . What I tried so far: I tried to prove that "" $v$ is reachable from $u$ $\implies uRv$ "" using contradiction that $u \not R v$ . I thought that if there is a path, then we can find some $x$ , where $uRx$ , but $x \not R v$ , otherwise it would mean that $uRv$ . And this led me to the conclusion that it must be at least one more point between $x$ and $v$ and so on ad infinitum. Another attempt was hiring contrapositive with further contradiction (if $u \not R v \implies v$ is not reachable from $u$ . Then for the sake of contradiction assuming that there is a path between $u$ and $v$ ). But this also led me to the same result as the first one. Since the first and the second attempts led me to an ""endless"" path between $u$ and $v$ I thought that induction can be a solution here. First of all, let's assume that any set, constructed of the elements of the path $uRx_1, x_1Rx_2, ..., x_nRv$ have the greatest element in respect to $R$ .  (I will prove it if my proof of the original theorem is correct). So let $P(n)$ is true when ""if there is $n$ -length path between $u$ and $v$ , then $uRv$ "" is true. I'm not sure but it seems that $P(0)$ is true, because there is always a zero-path between any elements. Let's consider any $n+1$ -length path and remove the greatest element $x_{n+1}$ from it. The resulting path has length $n$ , so that we sure know that $uRx_n$ . Now put the $x_{n+1}$ back and since we know that $x_{n + 1}$ is the greatest it means that $x_{n} R x_{n+1}$ . Then by transitivity we have that $uRx_{n+1}$ . UPDATE: First of all, let's assume that any set, constructed of the elements of the path $uRx_1, x_1Rx_2, ..., x_nRv$ have the greatest element in respect to $R$ Now I think that this lemma above is another way to prove the theorem. So if I proved it, I could prove that the greatest element is $v$ and then we would have $uRv$ . I'm sorry for a lot of text, but I'd like you to look at all my attempts and, probably, suggest how I can improve all of them to prove the theorem (if this is possible). So does my induction hypothesis seem good or is there a better one for this theorem? Is it correct to say that $P(0)$ is true? And could you please provide any hints how this theorem can be proved without induction (like I tried in my first and second attempts) if this is possible? I'd be also grateful if you can criticize my conclusions and assumptions.","I want to prove the following theorem and already spent a lot of time on doing this, but almost unsuccessfully: Let be a transitive relation over the set . Prove that in the graphical representation of the relation (that is, the graph ), that if is reachable from . So, reachability here I think means that there is a path from to . What I tried so far: I tried to prove that "" is reachable from "" using contradiction that . I thought that if there is a path, then we can find some , where , but , otherwise it would mean that . And this led me to the conclusion that it must be at least one more point between and and so on ad infinitum. Another attempt was hiring contrapositive with further contradiction (if is not reachable from . Then for the sake of contradiction assuming that there is a path between and ). But this also led me to the same result as the first one. Since the first and the second attempts led me to an ""endless"" path between and I thought that induction can be a solution here. First of all, let's assume that any set, constructed of the elements of the path have the greatest element in respect to .  (I will prove it if my proof of the original theorem is correct). So let is true when ""if there is -length path between and , then "" is true. I'm not sure but it seems that is true, because there is always a zero-path between any elements. Let's consider any -length path and remove the greatest element from it. The resulting path has length , so that we sure know that . Now put the back and since we know that is the greatest it means that . Then by transitivity we have that . UPDATE: First of all, let's assume that any set, constructed of the elements of the path have the greatest element in respect to Now I think that this lemma above is another way to prove the theorem. So if I proved it, I could prove that the greatest element is and then we would have . I'm sorry for a lot of text, but I'd like you to look at all my attempts and, probably, suggest how I can improve all of them to prove the theorem (if this is possible). So does my induction hypothesis seem good or is there a better one for this theorem? Is it correct to say that is true? And could you please provide any hints how this theorem can be proved without induction (like I tried in my first and second attempts) if this is possible? I'd be also grateful if you can criticize my conclusions and assumptions.","R A (A, R) (u, v) \in R v u u v v u \implies uRv u \not R v x uRx x \not R v uRv x v u \not R v \implies v u u v u v uRx_1, x_1Rx_2, ..., x_nRv R P(n) n u v uRv P(0) n+1 x_{n+1} n uRx_n x_{n+1} x_{n + 1} x_{n} R x_{n+1} uRx_{n+1} uRx_1, x_1Rx_2, ..., x_nRv R v uRv P(0)","['elementary-set-theory', 'proof-writing', 'induction', 'solution-verification', 'relations']"
48,About the definition of the indexed set of a family,About the definition of the indexed set of a family,,"I'm a computer science student currently studying universal algebra by reading the book Foundations of Algebraic Specification and Formal Software Development by Donald Sannella and Andrzej Tarlecki. I'm having a hard time trying to understand the subtleties of indexed families. As far as I know, families are just maps between two sets: $I$ , the index set; and $A$ , the indexed set. That means that $|A|_{i_0}$ , which is the element of $A$ indexed by $i_0$ could be basically anything, like a number, a set, a collection, etc. And that the particular case where $I$ is $\mathbb{N}$ it is called a sequence. However, the definition of the product of an indexed family is: $ \prod_{i\in I} A_i=\{f:I\to \bigcup_{i\in I} A_i: (\forall i_0\in I)(f(i_0)\in A_{i_0})\}$ Considering the definition of a family, then the product could be also defined as the set of all families $ (a_i)_{i \mathop \in I}$ with $|a|_{i_0} \in |A|_{i_0}$ for each $i_0 \in I$ But then, it is implied that the indexed set ( $A$ ) must be a collection (a set of sets), because otherwise, $|A|_{i_0}$ could be an element like a number thus the union of $|A|_i$ would make no sense, since it only works for sets. So why does the definition of a family (at least the ones I've read on several math textbooks) does not require the indexed set to be a collection rather than just a set? Also, would this mean that the elements of a sequence must be sets (containing just one or more elements)? I'm use to thinking about elements of a sequence, specially when studying convergence, as just real numbers. And finally, I will give an example of what I understand so that you could tell me what I'm missing: I will define a family of countries indexed by their currency name. So: $I$ , the index set would be $I = \{pound, dollar,euro\} $ $A$ , the indexed set would be $A = \{\{Spain, Italy, France\},\{UK\},\{US, Canada\}\}$ Then, the family would be a mapping defined as: $(A_i)_{i \in I}= \{pound \rightarrow \{UK\},dollar \rightarrow \{US, Canada\}, euro \rightarrow \{Spain, Italy, France\} \} $ Finally, the product of the family $\prod_{i\in I} A_i$ will consist on a set of mappings (families) where each one of them has $I$ as index set, and maps each index to a set containing just one of the elements of the corresponding subset of $A$ . So in that way, each of these families will map the indexes to one of the six combinations possibles by picking one element from each subset of $A$ . Then the product of the family will be a set of exactly 6 families, somewhat similar to the Cartesian product of the subsets of $A$ .","I'm a computer science student currently studying universal algebra by reading the book Foundations of Algebraic Specification and Formal Software Development by Donald Sannella and Andrzej Tarlecki. I'm having a hard time trying to understand the subtleties of indexed families. As far as I know, families are just maps between two sets: , the index set; and , the indexed set. That means that , which is the element of indexed by could be basically anything, like a number, a set, a collection, etc. And that the particular case where is it is called a sequence. However, the definition of the product of an indexed family is: Considering the definition of a family, then the product could be also defined as the set of all families with for each But then, it is implied that the indexed set ( ) must be a collection (a set of sets), because otherwise, could be an element like a number thus the union of would make no sense, since it only works for sets. So why does the definition of a family (at least the ones I've read on several math textbooks) does not require the indexed set to be a collection rather than just a set? Also, would this mean that the elements of a sequence must be sets (containing just one or more elements)? I'm use to thinking about elements of a sequence, specially when studying convergence, as just real numbers. And finally, I will give an example of what I understand so that you could tell me what I'm missing: I will define a family of countries indexed by their currency name. So: , the index set would be , the indexed set would be Then, the family would be a mapping defined as: Finally, the product of the family will consist on a set of mappings (families) where each one of them has as index set, and maps each index to a set containing just one of the elements of the corresponding subset of . So in that way, each of these families will map the indexes to one of the six combinations possibles by picking one element from each subset of . Then the product of the family will be a set of exactly 6 families, somewhat similar to the Cartesian product of the subsets of .","I A |A|_{i_0} A i_0 I \mathbb{N}  \prod_{i\in I} A_i=\{f:I\to \bigcup_{i\in I} A_i: (\forall i_0\in I)(f(i_0)\in A_{i_0})\}  (a_i)_{i \mathop \in I} |a|_{i_0} \in |A|_{i_0} i_0 \in I A |A|_{i_0} |A|_i I I = \{pound, dollar,euro\}  A A = \{\{Spain, Italy, France\},\{UK\},\{US, Canada\}\} (A_i)_{i \in I}= \{pound \rightarrow \{UK\},dollar \rightarrow \{US, Canada\}, euro \rightarrow \{Spain, Italy, France\} \}  \prod_{i\in I} A_i I A A A","['elementary-set-theory', 'definition', 'universal-algebra']"
49,If $A\cap B^\complement=\emptyset$ then $A\cap B=A$,If  then,A\cap B^\complement=\emptyset A\cap B=A,I need help with this excercise. If $A\cap B^\complement=\emptyset$ then $A\cap B=A$ I try $$A\cap B^\complement =\emptyset$$ $$(A\cap B^\complement)\cap B =\emptyset \cap B$$ $$A\cap (B^\complement\cap B )= B$$ $$A=B$$ Is this reasoning correct?,I need help with this excercise. If then I try Is this reasoning correct?,A\cap B^\complement=\emptyset A\cap B=A A\cap B^\complement =\emptyset (A\cap B^\complement)\cap B =\emptyset \cap B A\cap (B^\complement\cap B )= B A=B,"['elementary-set-theory', 'solution-verification']"
50,"Describing the set $\{n\in \Bbb N\lvert (n>1)\wedge (\forall x,y\in \Bbb N)[(xy=n)\implies (x=1\lor y=1)]\}$",Describing the set,"\{n\in \Bbb N\lvert (n>1)\wedge (\forall x,y\in \Bbb N)[(xy=n)\implies (x=1\lor y=1)]\}","This set appears in an exercise of the course Introduction to Mathematical Thinking , by Dr.Keith Devlin $A$ = $\{n\in \Bbb N\lvert (n>1)\wedge (\forall x,y\in \Bbb N)[(xy=n)\implies (x=1\lor y=1)]\}$ Although this is the very first question of the exercise on a refresher to Set Theory, I cannot process the logical syntax as it is. I'll break down my approach to understanding this set: The domain of discourse is the set of natural numbers(the convention followed in the course is to exclude $0$ from $\Bbb N$ ). The set $A$ , first and foremost, requires $n$ to be greater than $1$ . Next, $A$ requires $n$ to satisfy the implication $(xy=n)\implies (x=1\lor y=1)$ for every $x, y$ chosen from $\Bbb N$ (this is precisely where I feel I might be wrong). Clearly, in the event of both $x,y$ being greater than 1 the entire implication will be falsified. Thus, there does not exist any $n\in \Bbb N$ satisfying the conditions required by $A$ , which means $A$ is an empty set. I'd like to know which part of my reasoning is incorrect(if any at all). I believe such case-by-case splitting may not be necessary for trivial examples like this one (at least for math students and professionals), but I'm a layman and would hence appreciate such an approach.","This set appears in an exercise of the course Introduction to Mathematical Thinking , by Dr.Keith Devlin = Although this is the very first question of the exercise on a refresher to Set Theory, I cannot process the logical syntax as it is. I'll break down my approach to understanding this set: The domain of discourse is the set of natural numbers(the convention followed in the course is to exclude from ). The set , first and foremost, requires to be greater than . Next, requires to satisfy the implication for every chosen from (this is precisely where I feel I might be wrong). Clearly, in the event of both being greater than 1 the entire implication will be falsified. Thus, there does not exist any satisfying the conditions required by , which means is an empty set. I'd like to know which part of my reasoning is incorrect(if any at all). I believe such case-by-case splitting may not be necessary for trivial examples like this one (at least for math students and professionals), but I'm a layman and would hence appreciate such an approach.","A \{n\in \Bbb N\lvert (n>1)\wedge (\forall x,y\in \Bbb N)[(xy=n)\implies (x=1\lor y=1)]\} 0 \Bbb N A n 1 A n (xy=n)\implies (x=1\lor y=1) x, y \Bbb N x,y n\in \Bbb N A A","['elementary-set-theory', 'solution-verification', 'predicate-logic']"
51,Is the set $T$ of all sequences of rational numbers which converge to the number $3$ countable or uncountable? [duplicate],Is the set  of all sequences of rational numbers which converge to the number  countable or uncountable? [duplicate],T 3,This question already has answers here : How many sequences of rational numbers converging to 1 are there? (7 answers) Cardinality of set of sequences from $\mathbb{Q}$ that converge to $0$ (4 answers) Closed 4 years ago . I have been trying to solve the following problem: How many rational sequences exist for $\lim_{n\to 3}$ My intuition: I believe the set $T$ is countable. It can be shown (in more ways than one) that $\mathbb{Q}$ is a countable set. The set $T$ is a subset of $\mathbb{Q}$ and must therefore be countable. Is my intuition correct?,This question already has answers here : How many sequences of rational numbers converging to 1 are there? (7 answers) Cardinality of set of sequences from $\mathbb{Q}$ that converge to $0$ (4 answers) Closed 4 years ago . I have been trying to solve the following problem: How many rational sequences exist for My intuition: I believe the set is countable. It can be shown (in more ways than one) that is a countable set. The set is a subset of and must therefore be countable. Is my intuition correct?,\lim_{n\to 3} T \mathbb{Q} T \mathbb{Q},"['real-analysis', 'elementary-set-theory', 'proof-writing']"
52,"Ranks of $\mathbb{Z},\mathbb{Q}$ and $\mathbb{R}$",Ranks of  and,"\mathbb{Z},\mathbb{Q} \mathbb{R}","We have the following definitions of the rank of a set in the von Neumann hierarchy: $$\mathrm{rank}(x)=\sup\{(\mathrm{rank}\,y)^+:y\in x\}.$$ I now want to find the ranks of $\mathbb{Z},\mathbb{Q}$ and $\mathbb{R}$ . $\mathbb{Z}$ can be realised as a subset of $2\times \omega$ , each element having finite rank (regardless of implementation details like pairing method). Hence I get that the rank of $\mathbb{Z}$ is $\omega$ as well. Similarly, $\mathbb{Q}$ can be thought of as a subset of $\mathbb{Z}\times \mathbb{Z}$ , and again, regardless of implementation details, each element in this set has finite rank, hence I get that the rank of $\mathbb{Q}$ is $\omega$ . We construct $\mathbb{R}$ as subsets of $\mathbb{Q}$ (e.g. the lower part of Dedekind cuts), the relevant subsets having rank $\omega+1$ . Hence the rank of $\mathbb{R}$ as defined like this is $\omega+2$ . My questions are: Some other answers seemed to suggest that the ranks of $\mathbb{Z}$ and $\mathbb{Q}$ depend on implementation details - however, with the argument above, I find this hard to see. So are the ranks both $\omega$ in most cases, or have I missed something? Is it true that, defined like this, the rank of $\mathbb{R}$ is $\omega+2$ ? Other relevant links: The real numbers and the Von Neumann Universe Rank of $\mathbb Z$ and $\mathbb Q$","We have the following definitions of the rank of a set in the von Neumann hierarchy: I now want to find the ranks of and . can be realised as a subset of , each element having finite rank (regardless of implementation details like pairing method). Hence I get that the rank of is as well. Similarly, can be thought of as a subset of , and again, regardless of implementation details, each element in this set has finite rank, hence I get that the rank of is . We construct as subsets of (e.g. the lower part of Dedekind cuts), the relevant subsets having rank . Hence the rank of as defined like this is . My questions are: Some other answers seemed to suggest that the ranks of and depend on implementation details - however, with the argument above, I find this hard to see. So are the ranks both in most cases, or have I missed something? Is it true that, defined like this, the rank of is ? Other relevant links: The real numbers and the Von Neumann Universe Rank of $\mathbb Z$ and $\mathbb Q$","\mathrm{rank}(x)=\sup\{(\mathrm{rank}\,y)^+:y\in x\}. \mathbb{Z},\mathbb{Q} \mathbb{R} \mathbb{Z} 2\times \omega \mathbb{Z} \omega \mathbb{Q} \mathbb{Z}\times \mathbb{Z} \mathbb{Q} \omega \mathbb{R} \mathbb{Q} \omega+1 \mathbb{R} \omega+2 \mathbb{Z} \mathbb{Q} \omega \mathbb{R} \omega+2",['elementary-set-theory']
53,Cardinality of a tuple,Cardinality of a tuple,,"Studying Linear Algebra, I learned how the dimension of a vector space $E$ is just the number of elements in any base of the vector space $E$ . $$ \mathscr{B}=(e_1, e_2, ..., e_n) \quad \text{base of E} \implies \mathrm{dim}(E)=n $$ If I wanted to further formalize this idea, it would come natural to me to express the notion of ""number of elements in a tuple"" as a cardinality. My textbook introduces basis of vector spaces as tuples after all. Could I write something like $ \mathrm{card}(\mathscr{B})=n=\mathrm{dim}(E) $ or not? I know that the notion of cardinality is made for sets. Is there anything similar for indicating the ""length of a tuple""?","Studying Linear Algebra, I learned how the dimension of a vector space is just the number of elements in any base of the vector space . If I wanted to further formalize this idea, it would come natural to me to express the notion of ""number of elements in a tuple"" as a cardinality. My textbook introduces basis of vector spaces as tuples after all. Could I write something like or not? I know that the notion of cardinality is made for sets. Is there anything similar for indicating the ""length of a tuple""?","E E  \mathscr{B}=(e_1, e_2, ..., e_n) \quad \text{base of E} \implies \mathrm{dim}(E)=n   \mathrm{card}(\mathscr{B})=n=\mathrm{dim}(E) ","['elementary-set-theory', 'terminology']"
54,how do you prove that $A\times (B\setminus C) = (A\times B) \setminus (A\times C)$?,how do you prove that ?,A\times (B\setminus C) = (A\times B) \setminus (A\times C),"This is what I have come up with so far, but I am rather lost at lines 3-4... $$\begin{align} (a,b)\in A\times (B\setminus C)\iff& a\in A \land b\in (B\setminus C)\\ \iff& a\in A \land (b\in B \land \lnot(b\in C))\\ \iff& (a\in A \land b\in B) \land (a\in A \land b\notin C)\\ \iff& (a\in A \land b\in B)\setminus (a\in A \land b\in C)\\ \iff& (a,b)\in (A\times B)\setminus ((a,b)\in A\times C)\\ \iff& (a,b)\in (A\times B)\setminus (A\times C) \end{align}$$","This is what I have come up with so far, but I am rather lost at lines 3-4...","\begin{align}
(a,b)\in A\times (B\setminus C)\iff& a\in A \land b\in (B\setminus C)\\
\iff& a\in A \land (b\in B \land \lnot(b\in C))\\
\iff& (a\in A \land b\in B) \land (a\in A \land b\notin C)\\
\iff& (a\in A \land b\in B)\setminus (a\in A \land b\in C)\\
\iff& (a,b)\in (A\times B)\setminus ((a,b)\in A\times C)\\
\iff& (a,b)\in (A\times B)\setminus (A\times C)
\end{align}","['elementary-set-theory', 'logic']"
55,Principle of Induction and Well-Ordering Principle,Principle of Induction and Well-Ordering Principle,,"My Analysis lecturer defined $\mathbb{N}$ as the smallest set such that $0 \in \mathbb{N}$ and if $n \in \mathbb{N}$ then $n+1 \in \mathbb{N}$ . He then proceeded to ""prove"" the Principle of Mathematical Induction as follows: Let $P(n)$ be a family of propositions indexed on $\mathbb{N}$ . Suppose that $P(0)$ is true and that for any $n \geq 0$ , if $P(n)$ is true then $P(n+1)$ is true. Let $S$ be the set of natural numbers such that $P(n)$ is true. Then $S$ is a subset of $N$ . Since $P(0)$ is true, $0 \in S$ , and if $n \in S$ then $P(n)$ is true, so $P(n+1)$ is true, or equivalently $n+1 \in S$ . Thus $S$ has the properties $0 \in S$ and if $n \in S$ then $n+1 \in S$ ; as $N$ is the smallest set with these properties, $N$ is a subset of $S$ , but since we already know $S$ is a subset of $N$ it follows that $S=N$ , i.e. $P(n)$ is true for all natural numbers. My question is whether this proof is actually valid. I can't see any obvious flaw in the logic, but at the same time, I always thought that either the Principle of Mathematical Induction or (equivalently) the Well-Ordering Principle had to be taken as an axiom and couldn't be proved itself.","My Analysis lecturer defined as the smallest set such that and if then . He then proceeded to ""prove"" the Principle of Mathematical Induction as follows: Let be a family of propositions indexed on . Suppose that is true and that for any , if is true then is true. Let be the set of natural numbers such that is true. Then is a subset of . Since is true, , and if then is true, so is true, or equivalently . Thus has the properties and if then ; as is the smallest set with these properties, is a subset of , but since we already know is a subset of it follows that , i.e. is true for all natural numbers. My question is whether this proof is actually valid. I can't see any obvious flaw in the logic, but at the same time, I always thought that either the Principle of Mathematical Induction or (equivalently) the Well-Ordering Principle had to be taken as an axiom and couldn't be proved itself.",\mathbb{N} 0 \in \mathbb{N} n \in \mathbb{N} n+1 \in \mathbb{N} P(n) \mathbb{N} P(0) n \geq 0 P(n) P(n+1) S P(n) S N P(0) 0 \in S n \in S P(n) P(n+1) n+1 \in S S 0 \in S n \in S n+1 \in S N N S S N S=N P(n),"['elementary-set-theory', 'induction']"
56,Does a bijection $f:\textbf{Z}\rightarrow \textbf{Q}$ exist? [duplicate],Does a bijection  exist? [duplicate],f:\textbf{Z}\rightarrow \textbf{Q},"This question already has answers here : Produce an explicit bijection between rationals and naturals (9 answers) Closed 4 years ago . In this case, as is usual, $\textbf{Z}$ represents the set of integers and $\textbf{Q}$ represents the set of rational numbers. I'm meant to figure out if the bijection $f:\textbf{Z}\rightarrow\textbf{Q}$ exists and, while I know that this entails proving that it is both injective and surjective, I'm stuck with how to proceed. I've been struggling with proving bijectivity for sets in general and what I'm looking for is a framework with which to work when it comes to these sorts of problems, as my attempts to research similar problems online haven't helped. EDIT: While I do see other problems asking similar questions, the answers I read failed to show steps that proved both injectivity and surjectivity, which is how I would like to solve the question, if possible.","This question already has answers here : Produce an explicit bijection between rationals and naturals (9 answers) Closed 4 years ago . In this case, as is usual, represents the set of integers and represents the set of rational numbers. I'm meant to figure out if the bijection exists and, while I know that this entails proving that it is both injective and surjective, I'm stuck with how to proceed. I've been struggling with proving bijectivity for sets in general and what I'm looking for is a framework with which to work when it comes to these sorts of problems, as my attempts to research similar problems online haven't helped. EDIT: While I do see other problems asking similar questions, the answers I read failed to show steps that proved both injectivity and surjectivity, which is how I would like to solve the question, if possible.",\textbf{Z} \textbf{Q} f:\textbf{Z}\rightarrow\textbf{Q},['elementary-set-theory']
57,Is an Uncountable Set and a Continuous Set the Same Thing?,Is an Uncountable Set and a Continuous Set the Same Thing?,,"An Uncountable set is a set that has no existence of bijection with $Z$ . Is it the same as a continuous set ? Suppose $[0,1]$ is both uncountable and continuous. If both are different, please provide an example to clarify it. Background : I got this doubt because of the following statement from Introduction To Probability by Dimitri P. Bertsekas Probabilistic models with continuous sample spaces differ from their   discrete counterparts in that the probabilities of the single-element   events may not be sufficient to characterize the probability law","An Uncountable set is a set that has no existence of bijection with . Is it the same as a continuous set ? Suppose is both uncountable and continuous. If both are different, please provide an example to clarify it. Background : I got this doubt because of the following statement from Introduction To Probability by Dimitri P. Bertsekas Probabilistic models with continuous sample spaces differ from their   discrete counterparts in that the probabilities of the single-element   events may not be sufficient to characterize the probability law","Z [0,1]","['elementary-set-theory', 'definition']"
58,Can one characterize the set of all $A\subseteq\mathbb{R}$ satisfying $2\cdot A\cdot A\subseteq A$ and $A\cdot(\mathbb{R}\backslash A)\subseteq A$?,Can one characterize the set of all  satisfying  and ?,A\subseteq\mathbb{R} 2\cdot A\cdot A\subseteq A A\cdot(\mathbb{R}\backslash A)\subseteq A,"This question is a spin-off of this question . When trying to solve that question, we came up with the idea of construction functions using sets $A\subseteq \mathbb{R}$ having the properties that $2xy\in A$ for all $x,y \in A$ and $xy\in A$ for all $x\in A$ and $y\in\mathbb{R}\backslash A$ . How would one characterize the set of such sets $A$ ? I would literally have no idea where to start, although the problem can be formulated so easily. I know that the sets $A=\varnothing$ , $A=\{0\}$ , and $A=\mathbb{R}$ qualify, but are these the only ones? Any ideas/suggestions? Thanks!","This question is a spin-off of this question . When trying to solve that question, we came up with the idea of construction functions using sets having the properties that for all and for all and . How would one characterize the set of such sets ? I would literally have no idea where to start, although the problem can be formulated so easily. I know that the sets , , and qualify, but are these the only ones? Any ideas/suggestions? Thanks!","A\subseteq \mathbb{R} 2xy\in A x,y \in A xy\in A x\in A y\in\mathbb{R}\backslash A A A=\varnothing A=\{0\} A=\mathbb{R}","['real-analysis', 'elementary-set-theory']"
59,Confusion in Intersection of Images of sets.,Confusion in Intersection of Images of sets.,,"I am somehow unable to understand the following relation. if $f:X\rightarrow Y$ and $S,T\subseteq X$ then $$f(S\cap T)\subseteq f(S)\cap f(T)$$ The main problem is I always end up in showing the equality rather than the subset-ness. Example $f:X=\{x_1,x_2,x_3\}\rightarrow Y=\{y_1,y_2,y_3\}$ where $f$ is defined by $f(x_1)=f(x_2)=y_1$ , $f(x_3)=y_3$ and $S=\{x_1\},T=\{x_2,x_3\}$ Then clearly $f(S)\cap f(T)\subseteq f(S\cap T)$ does not hold,thus the equality is not possible. But My question is where I am making mistake in following proof : $$y\in f(S) \cap f(T)$$ $$\implies y\in f(S) \land y\in f(T)$$ $$\implies \exists x\in S \land \exists x\in T$$ such that $y=f(x)$ $$\implies x\in S\cap T$$ $$\implies f(x)=y\in f(S\cap T)$$ Hence $$f(S)\cap f(T)\subseteq f(S\cap T)$$ Can you please correct me,?","I am somehow unable to understand the following relation. if and then The main problem is I always end up in showing the equality rather than the subset-ness. Example where is defined by , and Then clearly does not hold,thus the equality is not possible. But My question is where I am making mistake in following proof : such that Hence Can you please correct me,?","f:X\rightarrow Y S,T\subseteq X f(S\cap T)\subseteq f(S)\cap f(T) f:X=\{x_1,x_2,x_3\}\rightarrow Y=\{y_1,y_2,y_3\} f f(x_1)=f(x_2)=y_1 f(x_3)=y_3 S=\{x_1\},T=\{x_2,x_3\} f(S)\cap f(T)\subseteq f(S\cap T) y\in f(S) \cap f(T) \implies y\in f(S) \land y\in f(T) \implies \exists x\in S \land \exists x\in T y=f(x) \implies x\in S\cap T \implies f(x)=y\in f(S\cap T) f(S)\cap f(T)\subseteq f(S\cap T)",['elementary-set-theory']
60,What's a 'simply put' difference between Sx and S(x)?,What's a 'simply put' difference between Sx and S(x)?,,The professor wouldn't really put it bluntly enough. This is a rookie question but I don't know what to search for (suggestions appreciated). What's the difference between: $C_n = \{X \in C:|X| = n\}$ vs $C(n) = \{X \in C:|X| = n\}$ Do they vary in terms of usage in other formulas or is it really just a syntactic sugar?,The professor wouldn't really put it bluntly enough. This is a rookie question but I don't know what to search for (suggestions appreciated). What's the difference between: vs Do they vary in terms of usage in other formulas or is it really just a syntactic sugar?,C_n = \{X \in C:|X| = n\} C(n) = \{X \in C:|X| = n\},['elementary-set-theory']
61,Prove that if $n \in \omega$ then $n \notin n$,Prove that if  then,n \in \omega n \notin n,"Prove that if $n \in \omega$ then $n \notin n$ . I'm trying to do it by induction. Consider $S=\{n \in \omega : n \notin n\}$ $0 \in S$ : $\emptyset \notin\emptyset $ $i\in S \Rightarrow s(i) \in S$ : $i \notin i \Rightarrow \{i\} \notin \{i\}$ (if $\{i\} \in \{i\} \text{ then } i=\{i\}, \text{ therefore } i \in i$ ). I want show now that $\{i\} \notin\{i\} \Rightarrow s(i)=\{i\} \cup i \notin s(i)=\{i\} \cup i$ . Suppose by absurdity that $\{i\} \cup i \in\{i\} \cup i$ then: or $\{i\} \cup i \in \{i\} \Rightarrow \{i\}\cup i = i \text{ then } i \in i$ , contradition. or $\{i\} \cup i \in i$ . I do not know to get in a contradition. I do not have the axim of regularity.","Prove that if then . I'm trying to do it by induction. Consider : : (if ). I want show now that . Suppose by absurdity that then: or , contradition. or . I do not know to get in a contradition. I do not have the axim of regularity.","n \in \omega n \notin n S=\{n \in \omega : n \notin n\} 0 \in S \emptyset \notin\emptyset  i\in S \Rightarrow s(i) \in S i \notin i \Rightarrow \{i\} \notin \{i\} \{i\} \in \{i\} \text{ then } i=\{i\}, \text{ therefore } i \in i \{i\} \notin\{i\} \Rightarrow s(i)=\{i\} \cup i \notin s(i)=\{i\} \cup i \{i\} \cup i \in\{i\} \cup i \{i\} \cup i \in \{i\} \Rightarrow \{i\}\cup i = i \text{ then } i \in i \{i\} \cup i \in i","['elementary-set-theory', 'induction']"
62,"Understanding empty set, set with empty set and set with set of empty set.","Understanding empty set, set with empty set and set with set of empty set.",,"I am having trouble understanding the difference between these sets. $\emptyset,\{\emptyset\},\{\{\emptyset\}\},...$ I think they're supposed to be different to eachother, but I read that the empty set is a subset of every set including itself . So every set in $\emptyset$ is in $\{\emptyset\}$ and every set in $\{\emptyset\}$ is in $\emptyset$ . So they're subsets of each other and therefore the same set. So $\emptyset,\{\emptyset\},\{\{\emptyset\}\},...$ are all the same. Is this right?","I am having trouble understanding the difference between these sets. I think they're supposed to be different to eachother, but I read that the empty set is a subset of every set including itself . So every set in is in and every set in is in . So they're subsets of each other and therefore the same set. So are all the same. Is this right?","\emptyset,\{\emptyset\},\{\{\emptyset\}\},... \emptyset \{\emptyset\} \{\emptyset\} \emptyset \emptyset,\{\emptyset\},\{\{\emptyset\}\},...",['elementary-set-theory']
63,What does it mean for a set to be contained in another?,What does it mean for a set to be contained in another?,,"If $A$ & $B$ are two sets, what does ' $A$ is contained in $B$ ' mean ? Does it mean that $A$ is a subset of $B$ or $A$ is a proper subset of $B$ ?","If & are two sets, what does ' is contained in ' mean ? Does it mean that is a subset of or is a proper subset of ?",A B A B A B A B,"['elementary-set-theory', 'definition']"
64,When is a collection of sets closed under union?,When is a collection of sets closed under union?,,"I started studying Probability, and I'm not sure if I understand what is the meaning of ""closed under union"". A collection (say $F$ ) of subsets of a set (say $\Omega$ ) is said to be a $\sigma$ -algebra if: $\Omega \in F$ $F$ is closed under complement $F$ is closed under union Now, consider the following example: Given $\Omega = \{1, 2, 3, 4, 5\}$ , is $F = \{\emptyset, \{1, 2\}, \{3, 4, 5\}, \{5\}, \{1, 2, 3, 4\}, \{1, 2, 3, 4, 5\}\}$ closed under union? I'm asking because I know that $\bigcup_{i = 1}^{6} X_i \in F$ ; however it does not happen for any two elements, for example: $\{1,2\} \cup \{5\} \not\in F$ .","I started studying Probability, and I'm not sure if I understand what is the meaning of ""closed under union"". A collection (say ) of subsets of a set (say ) is said to be a -algebra if: is closed under complement is closed under union Now, consider the following example: Given , is closed under union? I'm asking because I know that ; however it does not happen for any two elements, for example: .","F \Omega \sigma \Omega \in F F F \Omega = \{1, 2, 3, 4, 5\} F = \{\emptyset, \{1, 2\}, \{3, 4, 5\}, \{5\}, \{1, 2, 3, 4\}, \{1, 2, 3, 4, 5\}\} \bigcup_{i = 1}^{6} X_i \in F \{1,2\} \cup \{5\} \not\in F","['probability', 'elementary-set-theory']"
65,A set that's provably nonempty but with nothing provably in it,A set that's provably nonempty but with nothing provably in it,,"Working in a consistent theory (say, ZFC), is there a set/class that is provably nonempty, but nothing is provably in it? Formally, ( $T\vdash \exists x:x\in A)\land (\forall x,T\nvdash x\in A)$","Working in a consistent theory (say, ZFC), is there a set/class that is provably nonempty, but nothing is provably in it? Formally, (","T\vdash \exists x:x\in A)\land (\forall x,T\nvdash x\in A)","['elementary-set-theory', 'logic']"
66,Set-Builder notation for flattening a nested set,Set-Builder notation for flattening a nested set,,"Assume we have a set of sets $\textbf{P}=\{ \textbf{P}_j \}_{j=1}^{n}$ where $\textbf{P}_j=\{P_j^i \}_{i=1}^{m_j}$ for every $\textbf{P}_j \in \textbf{P}$ . Now, we want to build a set of $P_j^i$ for every $(i,j) \in j \times m_j$ for every $j\in n$ from $\textbf{P}$ . In plain words, we are flattening an unaligned nested set, or an unaligned matrix. Here is expression [1]: $$\{p\in\textbf{P}_j|\textbf{P}_j \in \textbf{P} \} $$ where the condition is actually on the member's domain. And another expression [2]: $$\bigcup_{j=1}^n \{ p|p \in \textbf{P}_j \}, where\ \textbf{P}_j \in \textbf{P}$$ Which expression makes more sense and why? Are there any other expressions for this case?","Assume we have a set of sets where for every . Now, we want to build a set of for every for every from . In plain words, we are flattening an unaligned nested set, or an unaligned matrix. Here is expression [1]: where the condition is actually on the member's domain. And another expression [2]: Which expression makes more sense and why? Are there any other expressions for this case?","\textbf{P}=\{ \textbf{P}_j \}_{j=1}^{n} \textbf{P}_j=\{P_j^i \}_{i=1}^{m_j} \textbf{P}_j \in \textbf{P} P_j^i (i,j) \in j \times m_j j\in n \textbf{P} \{p\in\textbf{P}_j|\textbf{P}_j \in \textbf{P} \}  \bigcup_{j=1}^n \{ p|p \in \textbf{P}_j \}, where\ \textbf{P}_j \in \textbf{P}",['elementary-set-theory']
67,Set of sets such that any three of them has nonempty intersection. Show all of them have nonempty intersection.,Set of sets such that any three of them has nonempty intersection. Show all of them have nonempty intersection.,,"Given $2^{n-1}$ subsets of a set with $n$ elements with the property that any three have nonempty intersection, prove that the intersection of all the sets is nonempty. My attempt: Let $|X|=n$ and $S \subset \mathcal{P}(X)$ be the above mentioned set. If the intersection of all the sets in $S$ is nonempty and contains W.L.O.G $a \in X$ , then the set of all subsets of $X$ containing $a$ satisfy the requirement.","Given subsets of a set with elements with the property that any three have nonempty intersection, prove that the intersection of all the sets is nonempty. My attempt: Let and be the above mentioned set. If the intersection of all the sets in is nonempty and contains W.L.O.G , then the set of all subsets of containing satisfy the requirement.",2^{n-1} n |X|=n S \subset \mathcal{P}(X) S a \in X X a,"['combinatorics', 'elementary-set-theory', 'contest-math', 'problem-solving']"
68,Cardinality of a set defined on the Cartesian product of a power set.,Cardinality of a set defined on the Cartesian product of a power set.,,"$2^A$ is the power set of some finite set A. Let $R:= \{(B, C) \in 2^A \times 2^A | B \subseteq C\}$ . Show that $\lvert R\rvert = 3^{\lvert A\rvert}$ . It is the $B \subseteq C$ part in the definition of $R$ that I cannot understand nor its implications. $2^A \times 2^A$ would just be the Cartesian product. However, with the condition $B \subseteq C$ not all elements of the product would be included. I cannot visualize/articulate which would be, though.","is the power set of some finite set A. Let . Show that . It is the part in the definition of that I cannot understand nor its implications. would just be the Cartesian product. However, with the condition not all elements of the product would be included. I cannot visualize/articulate which would be, though.","2^A R:= \{(B, C) \in 2^A \times 2^A | B \subseteq C\} \lvert R\rvert = 3^{\lvert A\rvert} B \subseteq C R 2^A \times 2^A B \subseteq C",['combinatorics']
69,"Finding a bijection from $\{1,2,...,nm\}$ to $X \times Y$",Finding a bijection from  to,"\{1,2,...,nm\} X \times Y","I'm trying to prove that for two finite sets $X,Y$ , where $|X|=n$ , $|Y|=m$ , $|X||Y|=|X \times Y|$ . I know that there exists bijections $f:\{1,2,...,n\} \rightarrow X$ and $g:\{1,2,...,m\} \rightarrow Y$ and I'm trying to find a bijection $h:\{1,2,...,nm\} \rightarrow X \times Y$ . I know that this is equivalent to showing there exists a bijection $k: X \times Y \rightarrow \{1,2,...,nm\}$ . One such bijection that seemingly works is $k(x_i,y_j) = (i-1)m + j$ , where $1 \leq i \leq n$ and $1 \leq j \leq m$ . I've tried to prove the injectivity and surjectivity of this function but to no avail: Injecivity: Suppose $k(x_a,y_b) = k(x_c,y_d)$ for $x_a, x_c \in X$ and $y_b, y_d \in Y$ . This gives $(a-1)m + b = (c-1)m + d$ but I've not been able to show that $a = c, b = d$ from here. Surjectivity: Suppose $z \in \{1,2,...,nm\}$ then $\exists i,j$ s.t. $ z = (i-1)m + j$ for some $i,j$ satisfying $1 \leq i \leq n$ and $1 \leq j \leq m$ . Now, since $X, Y$ can be written as $X = \{x_1,x_2,...,x_n\}$ , $Y = \{y_1,y_2,...,y_m\}$ and $X \times Y  = \{(x,y) | x \in X \wedge y \in Y\}$ then we can say $\exists(x_i, y_j) \in X \times Y$ and by the definition of $k$ we have $k((x_i, y_j)) = (i-1)m + j$ . But I'm not sure if this all watertight since I've assumed that $z$ can be written in the desired form.","I'm trying to prove that for two finite sets , where , , . I know that there exists bijections and and I'm trying to find a bijection . I know that this is equivalent to showing there exists a bijection . One such bijection that seemingly works is , where and . I've tried to prove the injectivity and surjectivity of this function but to no avail: Injecivity: Suppose for and . This gives but I've not been able to show that from here. Surjectivity: Suppose then s.t. for some satisfying and . Now, since can be written as , and then we can say and by the definition of we have . But I'm not sure if this all watertight since I've assumed that can be written in the desired form.","X,Y |X|=n |Y|=m |X||Y|=|X \times Y| f:\{1,2,...,n\} \rightarrow X g:\{1,2,...,m\} \rightarrow Y h:\{1,2,...,nm\} \rightarrow X \times Y k: X \times Y \rightarrow \{1,2,...,nm\} k(x_i,y_j) = (i-1)m + j 1 \leq i \leq n 1 \leq j \leq m k(x_a,y_b) = k(x_c,y_d) x_a, x_c \in X y_b, y_d \in Y (a-1)m + b = (c-1)m + d a = c, b = d z \in \{1,2,...,nm\} \exists i,j  z = (i-1)m + j i,j 1 \leq i \leq n 1 \leq j \leq m X, Y X = \{x_1,x_2,...,x_n\} Y = \{y_1,y_2,...,y_m\} X \times Y  = \{(x,y) | x \in X \wedge y \in Y\} \exists(x_i, y_j) \in X \times Y k k((x_i, y_j)) = (i-1)m + j z",['elementary-set-theory']
70,"Show that no two of the three sets ‚åÄ, {‚åÄ}, and {{‚åÄ}} are equal to each other.","Show that no two of the three sets ‚åÄ, {‚åÄ}, and {{‚åÄ}} are equal to each other.",,"I'm doing this course on logic and we have an exam from set theory coming up,  ""Show that no two of the three sets ‚åÄ, {‚åÄ}, and {{‚åÄ}} are equal to each other."" is one of the problems in the workbook we were assigned and I can't for the life of me even begin to solve this. I have the general knowledge surrounding empty sets and operations, but I don't know how I would go about writing a solution to this problem.","I'm doing this course on logic and we have an exam from set theory coming up,  ""Show that no two of the three sets ‚åÄ, {‚åÄ}, and {{‚åÄ}} are equal to each other."" is one of the problems in the workbook we were assigned and I can't for the life of me even begin to solve this. I have the general knowledge surrounding empty sets and operations, but I don't know how I would go about writing a solution to this problem.",,"['elementary-set-theory', 'logic']"
71,Under what conditions does $\mathcal{P}(\cup A) = A$ hold,Under what conditions does  hold,\mathcal{P}(\cup A) = A,"I'm studying ZF axiomatic set theory and I've encountered this question: Under what conditions does $\mathcal{P}(\cup A) = A$ holds? I easily proved that $A \subseteq\mathcal{P}(\cup A)$ and now I'm wondering whether the other inclusion holds. I first noted that it holds for $A = \{\varnothing\}$ and does not hold for $A = \varnothing$. But the first one is the only case? I tried to suppose that $A\neq \varnothing$ and that $A$ has an element other than $\phi$. Taking an such element, say $a = \{a_i\}$ in $A$, we have that every $a_i$ is in $\cup A$ so that any subset $\{a_{k_i}\}$ of $a$ must a subset of $\cup A$, that is, $\mathcal{P}(a)\subseteq \cup A$. I think I must arrive at a contradiction from here but I don't know what to conclude from this. Any help will be appreciated. (Obs.: I don't know for sure which of the two tags of set theory I must choose, once this question is not so elementary in the sense of common set theory used in math. I entered both but feel free to change if you know what is the correct one).","I'm studying ZF axiomatic set theory and I've encountered this question: Under what conditions does $\mathcal{P}(\cup A) = A$ holds? I easily proved that $A \subseteq\mathcal{P}(\cup A)$ and now I'm wondering whether the other inclusion holds. I first noted that it holds for $A = \{\varnothing\}$ and does not hold for $A = \varnothing$. But the first one is the only case? I tried to suppose that $A\neq \varnothing$ and that $A$ has an element other than $\phi$. Taking an such element, say $a = \{a_i\}$ in $A$, we have that every $a_i$ is in $\cup A$ so that any subset $\{a_{k_i}\}$ of $a$ must a subset of $\cup A$, that is, $\mathcal{P}(a)\subseteq \cup A$. I think I must arrive at a contradiction from here but I don't know what to conclude from this. Any help will be appreciated. (Obs.: I don't know for sure which of the two tags of set theory I must choose, once this question is not so elementary in the sense of common set theory used in math. I entered both but feel free to change if you know what is the correct one).",,['elementary-set-theory']
72,Is ( (A‚äÜB) & (B‚äÜA) ) ‚Üí A = B a theorem?,Is ( (A‚äÜB) & (B‚äÜA) ) ‚Üí A = B a theorem?,,"(It's probably important to state that I'm not a trained mathematician. Apologies if this question is too naive.) The formula in question is $((A \subseteq B)  \And (B \subseteq A))\rightarrow(A=B))$. This formula is a plausible formalisation of a purported proof by Thomas Hobbes, in his /Leviathan/, of the ""co-extensiveness"" of natural law and civil law. It seems intuitively valid and I haven't been able to find any counterexamples. But I'd like to know with certainty that it's true, if it's true. Two questions follow from this: 1) /is/ it a theorem? if it is, what is its proof, if this proof is straightforward? 2) what kind of course-material would I have to master in order to produce such a proof myself? Is that course-material available on the internet? (With regard to question two: of course I'm only asking about the /most advanced necessary/ material; I assume none of you can know exactly how backward I am from the evidence of this short post.)","(It's probably important to state that I'm not a trained mathematician. Apologies if this question is too naive.) The formula in question is $((A \subseteq B)  \And (B \subseteq A))\rightarrow(A=B))$. This formula is a plausible formalisation of a purported proof by Thomas Hobbes, in his /Leviathan/, of the ""co-extensiveness"" of natural law and civil law. It seems intuitively valid and I haven't been able to find any counterexamples. But I'd like to know with certainty that it's true, if it's true. Two questions follow from this: 1) /is/ it a theorem? if it is, what is its proof, if this proof is straightforward? 2) what kind of course-material would I have to master in order to produce such a proof myself? Is that course-material available on the internet? (With regard to question two: of course I'm only asking about the /most advanced necessary/ material; I assume none of you can know exactly how backward I am from the evidence of this short post.)",,['elementary-set-theory']
73,Cardinality of the set of primes that are not Fibonacci primes,Cardinality of the set of primes that are not Fibonacci primes,,"Consider the set of prime numbers that are not Fibonacci numbers, $ \mathbb{P}_{\neq \mathcal{F}} = \mathbb{P} \setminus \mathcal{F} $. The first few numbers in this set are $\mathbb{P}_{\neq \mathcal{F}} = \{7, 11, 17, 19, 23, 29, ...\}$ Can it be shown that $|\mathbb{P}_{\neq \mathcal{F}}| = \aleph_{0}$? In other words, can it be shown that there are an infinite number of prime numbers that are not Fibonacci numbers? A comment: note that if the cardinality of $\mathbb{P}_{\neq \mathcal{F}}$ was finite, then the number of Fibonacci primes would necessarily be infinite (which is an open question). However, $|\mathbb{P}_{\neq \mathcal{F}}| = \aleph_{0}$ does not indicate anything about the number of Fibonacci primes.","Consider the set of prime numbers that are not Fibonacci numbers, $ \mathbb{P}_{\neq \mathcal{F}} = \mathbb{P} \setminus \mathcal{F} $. The first few numbers in this set are $\mathbb{P}_{\neq \mathcal{F}} = \{7, 11, 17, 19, 23, 29, ...\}$ Can it be shown that $|\mathbb{P}_{\neq \mathcal{F}}| = \aleph_{0}$? In other words, can it be shown that there are an infinite number of prime numbers that are not Fibonacci numbers? A comment: note that if the cardinality of $\mathbb{P}_{\neq \mathcal{F}}$ was finite, then the number of Fibonacci primes would necessarily be infinite (which is an open question). However, $|\mathbb{P}_{\neq \mathcal{F}}| = \aleph_{0}$ does not indicate anything about the number of Fibonacci primes.",,"['number-theory', 'elementary-set-theory', 'prime-numbers', 'fibonacci-numbers']"
74,The law of excluded middle in mathematics,The law of excluded middle in mathematics,,"I want to make sure that I'm understanding this correctly. Let ZFC denote the Zermelo-Frankel theory of sets with the axiom of choice. Let H denote the continuum hypothesis. Let A be a formula of ZFC. Then (A or not A) is a theorem of ZFC. In particular, (H or not H) is a theorem of ZFC. However, neither H nor (not H) is a theorem of ZFC. That is, H is undecidable. Is any of this incorrect?","I want to make sure that I'm understanding this correctly. Let ZFC denote the Zermelo-Frankel theory of sets with the axiom of choice. Let H denote the continuum hypothesis. Let A be a formula of ZFC. Then (A or not A) is a theorem of ZFC. In particular, (H or not H) is a theorem of ZFC. However, neither H nor (not H) is a theorem of ZFC. That is, H is undecidable. Is any of this incorrect?",,"['elementary-set-theory', 'logic']"
75,Short mathematical notation for a sequence without the last element,Short mathematical notation for a sequence without the last element,,"I have a sequence (with unique elements): $a = (1,4,9)$. Is there a short notation for the same set, but without the last element: $b = (1,4)$? I came up with one solution, which simple removes the last item by index: $$b =a \setminus \{ a_{|a|-1}\}$$  or by taking all except the last: $$b = (a_0,...,a_{|a|-2})$$ However i am hoping to find something shorter, like $a_{-1}$ or something in that direction. Is there a standard way of doing this?","I have a sequence (with unique elements): $a = (1,4,9)$. Is there a short notation for the same set, but without the last element: $b = (1,4)$? I came up with one solution, which simple removes the last item by index: $$b =a \setminus \{ a_{|a|-1}\}$$  or by taking all except the last: $$b = (a_0,...,a_{|a|-2})$$ However i am hoping to find something shorter, like $a_{-1}$ or something in that direction. Is there a standard way of doing this?",,"['sequences-and-series', 'elementary-set-theory', 'notation']"
76,Question about the proof of the distributive property for sets,Question about the proof of the distributive property for sets,,"I have been learning set theory from scratch again and I have a question about the distributive property for sets. It seems the only proof I found of it actually USES the very same distributive property while proving it. This seems circular to me, could someone explain why it is allowed? This is what I am trying to prove. $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$ I got this proof from a quora answer. Let $x \in A \cup (B \cap C)$. If $x \in A \cup (B \cap C)$ then $x$ is either in $A$ or in ($B \cap C$). $x \in A$ or $x \in (B \cap C)$ $x \in A$ or ($x \in B$ and $x \in C$) HERE!!! How does one get from the statement above to the one below without actually using the distributive property itself? ($x \in A$ or $x \in B$) and ($x \in A$ or $x \in C$) $x \in (A \cup B)$ and $x \in (A \cup C)$ $x \in (A ‚à™ B) \cap (A ‚à™ C)$ $x \in A \cup (B \cap C) \implies x \in (A \cup B) \cap (A \cup C)$. Thanks a lot!!","I have been learning set theory from scratch again and I have a question about the distributive property for sets. It seems the only proof I found of it actually USES the very same distributive property while proving it. This seems circular to me, could someone explain why it is allowed? This is what I am trying to prove. $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$ I got this proof from a quora answer. Let $x \in A \cup (B \cap C)$. If $x \in A \cup (B \cap C)$ then $x$ is either in $A$ or in ($B \cap C$). $x \in A$ or $x \in (B \cap C)$ $x \in A$ or ($x \in B$ and $x \in C$) HERE!!! How does one get from the statement above to the one below without actually using the distributive property itself? ($x \in A$ or $x \in B$) and ($x \in A$ or $x \in C$) $x \in (A \cup B)$ and $x \in (A \cup C)$ $x \in (A ‚à™ B) \cap (A ‚à™ C)$ $x \in A \cup (B \cap C) \implies x \in (A \cup B) \cap (A \cup C)$. Thanks a lot!!",,"['elementary-set-theory', 'proof-verification', 'logic']"
77,How does Axiom of Dependent Choice imply this weaker variant?,How does Axiom of Dependent Choice imply this weaker variant?,,"Here is the excerpt from the textbook A Course in Mathematical Analysis by Prof D. J. H. Garling. So I have the Theorem 1 : Given a set $A\neq\varnothing$, a mapping $\varphi:A\to P(A )\setminus \{\varnothing\}$, and $\bar{a}\in A$. Then there exists a sequence  $$(a_{n})_{n\in \mathbb{N}}$$  such that $a_{0}=\bar{a}$ and $a_{n+1}\in \varphi(a_{n})$ for all $n\in \mathbb{N}$ Axiom of Choice : Given a collection $A$ of nonempty sets, there exists a function  $$c: A \to \bigcup_{A_{i} \in A}A_{i}$$  such that $c(A_{i})\in A_{i}$ for all $A_{i} \in A$. Axiom of Dependent Choice : Given a nonempty set $A$ and a binary relation $\mathcal{R}$ on $A$ such that for all $a\in A$, there exists $b\in A$ such that $a\mathcal{R}b$. There exists a sequence  $$(a_{n})_{n\in \mathbb{N}}$$  such that $a_{n}\mathcal{R}a_{n+1}$ for all $n \in \mathbb{N}$. The author states that The axiom of dependent choice states that this [Theorem 1] is always possible . But I can only infer Theorem 1 from Axiom of Choice , not from Axiom of Dependent Choice . Below is how I did it. Using Axiom of Choice for the collection $P(A)\setminus \{\varnothing\}$ of nonempty sets, then there exists a choice function $$\varphi':P(A)\setminus \{\varnothing\} \to A$$ such that $\varphi'(X)\in X$ for all $X\in P(A)\setminus \{\varnothing\}$. Let $\bar{\varphi}=\varphi'\circ \varphi:A\to A\implies\bar{\varphi}(a)=\varphi'(\varphi(a))\in \varphi(\bar{a})$ for all $a\in A$ To sum up, we have $\bar{\varphi}:A\to A$ and $\bar{a}\in A$. Applying Recursion Theorem, we get a sequence $$(a_{n})_{n\in \mathbb{N}}$$ such that $a_{0}=\bar{a}$ and $a_{n+1}=\bar{\varphi}(a_{n})\in\varphi(a_{n})$ for all $n\in \mathbb{N}$.  So this $(a_{n})_{n\in \mathbb{N}}$ is the required sequence. I would like you to check my above proof and check whether it is possible for Axiom of Dependent Choice to imply Theorem 1 . Many thanks for your help!","Here is the excerpt from the textbook A Course in Mathematical Analysis by Prof D. J. H. Garling. So I have the Theorem 1 : Given a set $A\neq\varnothing$, a mapping $\varphi:A\to P(A )\setminus \{\varnothing\}$, and $\bar{a}\in A$. Then there exists a sequence  $$(a_{n})_{n\in \mathbb{N}}$$  such that $a_{0}=\bar{a}$ and $a_{n+1}\in \varphi(a_{n})$ for all $n\in \mathbb{N}$ Axiom of Choice : Given a collection $A$ of nonempty sets, there exists a function  $$c: A \to \bigcup_{A_{i} \in A}A_{i}$$  such that $c(A_{i})\in A_{i}$ for all $A_{i} \in A$. Axiom of Dependent Choice : Given a nonempty set $A$ and a binary relation $\mathcal{R}$ on $A$ such that for all $a\in A$, there exists $b\in A$ such that $a\mathcal{R}b$. There exists a sequence  $$(a_{n})_{n\in \mathbb{N}}$$  such that $a_{n}\mathcal{R}a_{n+1}$ for all $n \in \mathbb{N}$. The author states that The axiom of dependent choice states that this [Theorem 1] is always possible . But I can only infer Theorem 1 from Axiom of Choice , not from Axiom of Dependent Choice . Below is how I did it. Using Axiom of Choice for the collection $P(A)\setminus \{\varnothing\}$ of nonempty sets, then there exists a choice function $$\varphi':P(A)\setminus \{\varnothing\} \to A$$ such that $\varphi'(X)\in X$ for all $X\in P(A)\setminus \{\varnothing\}$. Let $\bar{\varphi}=\varphi'\circ \varphi:A\to A\implies\bar{\varphi}(a)=\varphi'(\varphi(a))\in \varphi(\bar{a})$ for all $a\in A$ To sum up, we have $\bar{\varphi}:A\to A$ and $\bar{a}\in A$. Applying Recursion Theorem, we get a sequence $$(a_{n})_{n\in \mathbb{N}}$$ such that $a_{0}=\bar{a}$ and $a_{n+1}=\bar{\varphi}(a_{n})\in\varphi(a_{n})$ for all $n\in \mathbb{N}$.  So this $(a_{n})_{n\in \mathbb{N}}$ is the required sequence. I would like you to check my above proof and check whether it is possible for Axiom of Dependent Choice to imply Theorem 1 . Many thanks for your help!",,"['elementary-set-theory', 'axiom-of-choice']"
78,Does an ordinal number $\beta$ such that $\alpha<\beta$ and $\beta<\alpha +1$ exist for some another ordinal number $\alpha$?,Does an ordinal number  such that  and  exist for some another ordinal number ?,\beta \alpha<\beta \beta<\alpha +1 \alpha,"My question is simple: is there a pair of ordinals $\alpha,\beta$ such that $\alpha<\beta$ and $\beta<\alpha+1$? I'm quite sure the answer is no, but I'm a bit afraid of limit ordinals. For me that result follows the fact that given $\alpha$ an ordinal number, $\alpha +1$ is the least element of the set $$\{\beta:\alpha<\beta \} .$$ However, I haven't found a nice explanation for what a limit ordinal is. I only know what Wiki says: limit ordinal is an ordinal $\omega$ such that there isn't any other ordinal $\alpha$ satisfying $\alpha+1=\omega$. Hence I'm not totally sure. Because larg ordinals may be very strangers. What do you think? Thanks. What do you think?","My question is simple: is there a pair of ordinals $\alpha,\beta$ such that $\alpha<\beta$ and $\beta<\alpha+1$? I'm quite sure the answer is no, but I'm a bit afraid of limit ordinals. For me that result follows the fact that given $\alpha$ an ordinal number, $\alpha +1$ is the least element of the set $$\{\beta:\alpha<\beta \} .$$ However, I haven't found a nice explanation for what a limit ordinal is. I only know what Wiki says: limit ordinal is an ordinal $\omega$ such that there isn't any other ordinal $\alpha$ satisfying $\alpha+1=\omega$. Hence I'm not totally sure. Because larg ordinals may be very strangers. What do you think? Thanks. What do you think?",,"['elementary-set-theory', 'ordinals']"
79,Set Theory question about equalities of sets,Set Theory question about equalities of sets,,"Consider the following sets: $A=\{3,4\},$     $B=\{4,3\}\bigcup \emptyset, C=\{4,3\}\bigcup\{\emptyset\}$ Which pairs of sets are equal? My attempt: We obviously have $C=\{4,3,\emptyset\}$ We also have(?) $B=\{4,3\}$ as by the Null set Axiom, the empty set is the unique set having no elements. Now by the extensionality axiom, $A$ and $B$ are equal since they have the same elements. However, they are not equal to $C$ as they don't contain the empty set as an element. Is that true? I'm still unsure about the bit where I look at the empty set as an element of $C$ since technically, no element of $C$ is not an element of $A$ or vice versa, hence we can use ZF1 again to conclude that they are equal?? Thanks in advance","Consider the following sets: $A=\{3,4\},$     $B=\{4,3\}\bigcup \emptyset, C=\{4,3\}\bigcup\{\emptyset\}$ Which pairs of sets are equal? My attempt: We obviously have $C=\{4,3,\emptyset\}$ We also have(?) $B=\{4,3\}$ as by the Null set Axiom, the empty set is the unique set having no elements. Now by the extensionality axiom, $A$ and $B$ are equal since they have the same elements. However, they are not equal to $C$ as they don't contain the empty set as an element. Is that true? I'm still unsure about the bit where I look at the empty set as an element of $C$ since technically, no element of $C$ is not an element of $A$ or vice versa, hence we can use ZF1 again to conclude that they are equal?? Thanks in advance",,['elementary-set-theory']
80,Is it possible to prove this version of recursion theorem from the simpler one?,Is it possible to prove this version of recursion theorem from the simpler one?,,"The simpler version: Let $A$ be a set, $a\in A$, and $f \colon A\to A$ a mapping. Then there exists a unique mapping $g \colon \Bbb N\to A$ such that 1. $g(0)=a$ 2. $g(n+1)=f(g(n))$ The version I want to prove: Let $A$ be a set, $a\in A$, and $f\colon A\times\Bbb N \to A$ a mapping. Then there exists a unique mapping $g \colon \Bbb N\to A$ such that 1. $g(0)=a$ 2. $g(n+1)=f(g(n),n)$ I would like to ask whether it is possible to apply the first version to prove the second one. Many thanks for your help!","The simpler version: Let $A$ be a set, $a\in A$, and $f \colon A\to A$ a mapping. Then there exists a unique mapping $g \colon \Bbb N\to A$ such that 1. $g(0)=a$ 2. $g(n+1)=f(g(n))$ The version I want to prove: Let $A$ be a set, $a\in A$, and $f\colon A\times\Bbb N \to A$ a mapping. Then there exists a unique mapping $g \colon \Bbb N\to A$ such that 1. $g(0)=a$ 2. $g(n+1)=f(g(n),n)$ I would like to ask whether it is possible to apply the first version to prove the second one. Many thanks for your help!",,"['elementary-set-theory', 'recurrence-relations', 'recursion']"
81,Set-theoretical definition of function evaluation,Set-theoretical definition of function evaluation,,"I am familiar with the set-theoretical definition of functions. A function $f : A \rightarrow B$ from a set $A$ to a set $B$ is a subset $f \subseteq A \times B$ of the Cartesian product $A \times B$ such that the following conditions hold: $\forall a \in A : \exists b \in B : (a,b) \in f$ $\forall a \in A : \forall b, b' \in B : (a,b), (a,b') \in f \rightarrow b=b'$ Is there a purely set-theoretical definition of the function evaluation $f(a)$ for every $a \in A$? I get as far as defining  $f(a) = \{ b \in B : (a,b) \in f \}$ but that defines rather the set of values of a multi-valued function.","I am familiar with the set-theoretical definition of functions. A function $f : A \rightarrow B$ from a set $A$ to a set $B$ is a subset $f \subseteq A \times B$ of the Cartesian product $A \times B$ such that the following conditions hold: $\forall a \in A : \exists b \in B : (a,b) \in f$ $\forall a \in A : \forall b, b' \in B : (a,b), (a,b') \in f \rightarrow b=b'$ Is there a purely set-theoretical definition of the function evaluation $f(a)$ for every $a \in A$? I get as far as defining  $f(a) = \{ b \in B : (a,b) \in f \}$ but that defines rather the set of values of a multi-valued function.",,['elementary-set-theory']
82,"What is ""the least equivalence relation $E \subset Y \times Y$ which contains all pairs $\langle fx, gx \rangle$ for $x \in X$""?","What is ""the least equivalence relation  which contains all pairs  for ""?","E \subset Y \times Y \langle fx, gx \rangle x \in X","From Mac Lane's Category Theory: The coequalizer of two functions $f,g: X \rightarrow Y$ is the projection $p: Y \rightarrow Y/E$ on the quotient set of $Y$ by the least equivalence relation $E \subset Y \times Y$ which contains all pairs $\langle fx, gx \rangle$ for $x \in X.$ I'm having trouble understanding what $$\text{""the least equivalence relation $E \subset Y \times Y$ which contains all pairs $\langle fx, gx \rangle$ for $x \in X$""}$$ means. If $X$ is a set and $E$ is an equivalence relation on $X$, then $X/E= \{ [x] : x \in X\}$ where $[x]=\{x' \in X: x' E \space x\}$. How does the above quotation translate into an equivalence class definition?","From Mac Lane's Category Theory: The coequalizer of two functions $f,g: X \rightarrow Y$ is the projection $p: Y \rightarrow Y/E$ on the quotient set of $Y$ by the least equivalence relation $E \subset Y \times Y$ which contains all pairs $\langle fx, gx \rangle$ for $x \in X.$ I'm having trouble understanding what $$\text{""the least equivalence relation $E \subset Y \times Y$ which contains all pairs $\langle fx, gx \rangle$ for $x \in X$""}$$ means. If $X$ is a set and $E$ is an equivalence relation on $X$, then $X/E= \{ [x] : x \in X\}$ where $[x]=\{x' \in X: x' E \space x\}$. How does the above quotation translate into an equivalence class definition?",,"['elementary-set-theory', 'category-theory', 'definition']"
83,Does $f^{-1}(B^\circ)\subset (f^{-1}(B))^\circ$ imply continuity?,Does  imply continuity?,f^{-1}(B^\circ)\subset (f^{-1}(B))^\circ,"Let $(X,\tau),(Y,\eta)$ be topological spaces and  $f:X\to Y$ a function. Prove that  $f$ is continuous if and only if $f^{-1}(B^\circ)\subset (f^{-1}(B))^\circ,\forall B\subset Y$ $\implies$ Let $B\subset Y.$ As $f$ is continuous, $f^{-1}(B^\circ)=(f^{-1}(B^\circ))^\circ\subset (f^{-1}(B))^\circ$ $\Longleftarrow$ What can I do to prove this side? Is the implication $\implies$ correct?","Let $(X,\tau),(Y,\eta)$ be topological spaces and  $f:X\to Y$ a function. Prove that  $f$ is continuous if and only if $f^{-1}(B^\circ)\subset (f^{-1}(B))^\circ,\forall B\subset Y$ $\implies$ Let $B\subset Y.$ As $f$ is continuous, $f^{-1}(B^\circ)=(f^{-1}(B^\circ))^\circ\subset (f^{-1}(B))^\circ$ $\Longleftarrow$ What can I do to prove this side? Is the implication $\implies$ correct?",,['general-topology']
84,Set theory identity,Set theory identity,,Prove that $(A\triangle B)\triangle (A\cap B) = A\cup B$ . I tried and mostly went in circles. The idea is to use that  $(A\triangle B)=(A\setminus B)\cup (B\setminus A)$ and also  $A\setminus B = \bar A\cap B$ where $\bar A$ is absolute complement of A together with the De Morgan's laws . These are the few lines: $(A\triangle B)\triangle (A\cap B)$ = $[(\bar A\cap B)\cup(\bar B\cap A)]\triangle(A\cap B)$ = ... I would post my solution so far but I suck at LaTeX so it would take me too long.,Prove that $(A\triangle B)\triangle (A\cap B) = A\cup B$ . I tried and mostly went in circles. The idea is to use that  $(A\triangle B)=(A\setminus B)\cup (B\setminus A)$ and also  $A\setminus B = \bar A\cap B$ where $\bar A$ is absolute complement of A together with the De Morgan's laws . These are the few lines: $(A\triangle B)\triangle (A\cap B)$ = $[(\bar A\cap B)\cup(\bar B\cap A)]\triangle(A\cap B)$ = ... I would post my solution so far but I suck at LaTeX so it would take me too long.,,['elementary-set-theory']
85,Union on the empty set and the set containing the empty set,Union on the empty set and the set containing the empty set,,"I'm trying to get a clearer sense of some of the consequences the axiom of unions has on the empty set. I understand that $\emptyset = \{\} \not= \{\emptyset\}$. But assuming the following identities are correct, I don't understand why $\bigcup\emptyset = \bigcup \{\} = \bigcup \{\emptyset\}$. It's likely that I'm floundering on some minutiae of set theory, but it's making me uncomfortable, and I'd like to know what I'm missing.","I'm trying to get a clearer sense of some of the consequences the axiom of unions has on the empty set. I understand that $\emptyset = \{\} \not= \{\emptyset\}$. But assuming the following identities are correct, I don't understand why $\bigcup\emptyset = \bigcup \{\} = \bigcup \{\emptyset\}$. It's likely that I'm floundering on some minutiae of set theory, but it's making me uncomfortable, and I'd like to know what I'm missing.",,['elementary-set-theory']
86,Do All Subsets of $\Bbb N$ Have Predicates?,Do All Subsets of  Have Predicates?,\Bbb N,"I have a question: Is it true that for any subset $S$ of $\mathbb N$, there is a predicate $œÜ(x)$ in this language $S$ such that $S$ = $\{n\in \mathbb N | œÜ(n)\}$? Here's my thought process so far. If everything that's $\in$ $\mathbb N$ has some predicate, the number of predicates of the language (POL) must be equal to the number of sets of $\mathbb N$. So, |POL| = | $P(\mathbb N) |$. Now, POL $\subseteq$ WFF But the |WFFs| = |$\mathbb N$| And |$\mathbb N$| $\ne$ $P(\mathbb N) |$. Does it thereby follow that |POL| $\ne$ |$P (\mathbb N)|$? Any advice, tips, tricks or suggestions about how to answer this question would be greatly appreciated.","I have a question: Is it true that for any subset $S$ of $\mathbb N$, there is a predicate $œÜ(x)$ in this language $S$ such that $S$ = $\{n\in \mathbb N | œÜ(n)\}$? Here's my thought process so far. If everything that's $\in$ $\mathbb N$ has some predicate, the number of predicates of the language (POL) must be equal to the number of sets of $\mathbb N$. So, |POL| = | $P(\mathbb N) |$. Now, POL $\subseteq$ WFF But the |WFFs| = |$\mathbb N$| And |$\mathbb N$| $\ne$ $P(\mathbb N) |$. Does it thereby follow that |POL| $\ne$ |$P (\mathbb N)|$? Any advice, tips, tricks or suggestions about how to answer this question would be greatly appreciated.",,['elementary-set-theory']
87,"R is symmetric and transitive relation, if and only if $R = R^{-1}\circ R$","R is symmetric and transitive relation, if and only if",R = R^{-1}\circ R,"How do I prove that the following: Let $R$ be a (binary) relation on a set. Prove that $R$ is symmetric and transitive relation, if and only if $R = R^{-1}\circ R$ . Here, $R^{-1} \circ R$ is defined as the relation $\{(u,v) | \exists x, uR^{-1}x \land xRv\}$ , where $xRu$ means $\left(x,u\right) \in R$ . I only have a problem with assuming the 2nd, and deriving the first, any tips on the proof technique?","How do I prove that the following: Let be a (binary) relation on a set. Prove that is symmetric and transitive relation, if and only if . Here, is defined as the relation , where means . I only have a problem with assuming the 2nd, and deriving the first, any tips on the proof technique?","R R R = R^{-1}\circ R R^{-1} \circ R \{(u,v) | \exists x, uR^{-1}x \land xRv\} xRu \left(x,u\right) \in R","['elementary-set-theory', 'relations', 'equivalence-relations', 'function-and-relation-composition']"
88,"Prove that for any family of sets $\mathcal F$, $‚à™!\mathcal F = ‚à™\mathcal F$ iff $\mathcal F$ is pairwise disjoint.","Prove that for any family of sets ,  iff  is pairwise disjoint.",\mathcal F ‚à™!\mathcal F = ‚à™\mathcal F \mathcal F,"This is Velleman's exercise 3.6.5.b: Prove that for any family of sets $\mathcal F$, $‚à™!\mathcal F = ‚à™\mathcal F$ iff $\mathcal F$ is pairwise disjoint. First let's do some translations: $\bullet$ $‚à™!\mathcal F = \{x | ‚àÉ!A(A ‚àà \mathcal F ‚àß x ‚àà A)\}$. $\bullet$ $‚àÉ!A$ means that ""there exists a unique $A$ such that..."" thus ""$x ‚àà ‚à™!\mathcal F$"" which we will use later is equivalent to $‚àÉA(A ‚àà \mathcal F ‚àß x ‚àà A) ‚àß  ‚àÄB((A ‚àà \mathcal F ‚àß x ‚àà A) \Rightarrow B = A)$. $\bullet$ A family of sets $\mathcal F$ is said to be pairwise disjoint if $‚àÄA ‚àà \mathcal F‚àÄB ‚àà \mathcal F(A \neq B ‚Üí A ‚à© B =‚àÖ)$. And now here's my proof of it: Proof. ($\rightarrow$) Suppose $‚à™!\mathcal F = ‚à™\mathcal F$ i.e. $x ‚àà ‚à™!\mathcal F \iff x ‚àà ‚à™\mathcal F$ i.e. $x ‚àà ‚à™!\mathcal F \Rightarrow x ‚àà ‚à™\mathcal F$ and $x ‚àà ‚à™!\mathcal F \Leftarrow x ‚àà ‚à™\mathcal F$. Let $A$ and $B$ be arbitrary elements of $\mathcal F$. Now we prove the contrapositive and suppose $A ‚à© B \neq ‚àÖ$ which means $‚àÉx(x ‚àà A ‚àß x ‚àà B)$. We can now choose some $x_0$ such that $x_0 ‚àà A$ and $x_0 ‚àà B$. Since $A$ was an arbitrary element of $\mathcal F$ then from $x ‚àà ‚à™\mathcal F$, we have $x ‚àà ‚à™!\mathcal F$. Since $B$ was an arbitrary element of $\mathcal F$ and $x_0 ‚àà B$, then from $x ‚àà ‚à™!\mathcal F$: particularly from $‚àÄB((A ‚àà \mathcal F ‚àß x ‚àà A) \Rightarrow B = A)$, we get $B = A$. Since $A$ and $B$ were arbitary then $\mathcal F$ is pairwise disjoint. Therefore if $‚à™!\mathcal F = ‚à™\mathcal F$ then $\mathcal F$ is pairwise disjoint. Here are my questions: Is my proof of the forward direction valid? What about the backward direction? Isn't the statement $‚à™!\mathcal F = ‚à™\mathcal F$ kind of self-explanatory (i.e. each side kind of prove the other side)? In other words I cannot see a way to use $‚àÄA ‚àà \mathcal F‚àÄB ‚àà \mathcal F(A \neq B ‚Üí A ‚à© B =‚àÖ)$ to prove those conditional-existential statements (they seem to sufficiently rely on each other for their existence)! Thanks.","This is Velleman's exercise 3.6.5.b: Prove that for any family of sets $\mathcal F$, $‚à™!\mathcal F = ‚à™\mathcal F$ iff $\mathcal F$ is pairwise disjoint. First let's do some translations: $\bullet$ $‚à™!\mathcal F = \{x | ‚àÉ!A(A ‚àà \mathcal F ‚àß x ‚àà A)\}$. $\bullet$ $‚àÉ!A$ means that ""there exists a unique $A$ such that..."" thus ""$x ‚àà ‚à™!\mathcal F$"" which we will use later is equivalent to $‚àÉA(A ‚àà \mathcal F ‚àß x ‚àà A) ‚àß  ‚àÄB((A ‚àà \mathcal F ‚àß x ‚àà A) \Rightarrow B = A)$. $\bullet$ A family of sets $\mathcal F$ is said to be pairwise disjoint if $‚àÄA ‚àà \mathcal F‚àÄB ‚àà \mathcal F(A \neq B ‚Üí A ‚à© B =‚àÖ)$. And now here's my proof of it: Proof. ($\rightarrow$) Suppose $‚à™!\mathcal F = ‚à™\mathcal F$ i.e. $x ‚àà ‚à™!\mathcal F \iff x ‚àà ‚à™\mathcal F$ i.e. $x ‚àà ‚à™!\mathcal F \Rightarrow x ‚àà ‚à™\mathcal F$ and $x ‚àà ‚à™!\mathcal F \Leftarrow x ‚àà ‚à™\mathcal F$. Let $A$ and $B$ be arbitrary elements of $\mathcal F$. Now we prove the contrapositive and suppose $A ‚à© B \neq ‚àÖ$ which means $‚àÉx(x ‚àà A ‚àß x ‚àà B)$. We can now choose some $x_0$ such that $x_0 ‚àà A$ and $x_0 ‚àà B$. Since $A$ was an arbitrary element of $\mathcal F$ then from $x ‚àà ‚à™\mathcal F$, we have $x ‚àà ‚à™!\mathcal F$. Since $B$ was an arbitrary element of $\mathcal F$ and $x_0 ‚àà B$, then from $x ‚àà ‚à™!\mathcal F$: particularly from $‚àÄB((A ‚àà \mathcal F ‚àß x ‚àà A) \Rightarrow B = A)$, we get $B = A$. Since $A$ and $B$ were arbitary then $\mathcal F$ is pairwise disjoint. Therefore if $‚à™!\mathcal F = ‚à™\mathcal F$ then $\mathcal F$ is pairwise disjoint. Here are my questions: Is my proof of the forward direction valid? What about the backward direction? Isn't the statement $‚à™!\mathcal F = ‚à™\mathcal F$ kind of self-explanatory (i.e. each side kind of prove the other side)? In other words I cannot see a way to use $‚àÄA ‚àà \mathcal F‚àÄB ‚àà \mathcal F(A \neq B ‚Üí A ‚à© B =‚àÖ)$ to prove those conditional-existential statements (they seem to sufficiently rely on each other for their existence)! Thanks.",,"['elementary-set-theory', 'logic', 'proof-verification', 'proof-writing']"
89,Prove that if $A \bigtriangleup B\subseteq A$ then $B \subseteq A.$,Prove that if  then,A \bigtriangleup B\subseteq A B \subseteq A.,"This is Velleman's exercise 3.5.5 ( And NO! not a duplicate of Prove that if $A \mathop \triangle B \subseteq A$ then $B\subseteq A$ ! My question is different ): Prove that if $A \bigtriangleup B\subseteq A$ then $B \subseteq A.$ Since in the definition of a symmetric difference we have disjunction, shouldn't we prove this statement by cases? So here's my proof of it: Proof. Let $x$ be an arbitrary element of $B$ . Now suppose $x \not\in A$ . From $x \in B$ and $x \not\in A$ , we get $x \in (B\setminus A)$ . We now consider two cases. Case 1. $x \in (A\setminus B)$ . Then by $A \bigtriangleup B \subseteq A$ , we have $x \in A$ which is a contradiction. Case 2. $x \not\in (A\setminus B)$ . Since $x \in (B\setminus A)$ and $A \bigtriangleup B \subseteq A$ , $x \in A$ which is also a contradiction. Since by both cases we reached a contradiction then $x \in A$ and since $x$ was arbitrary, $B \subseteq A$ . In other words, in proof by cases (when we have disjunction in the given/hypotheses/premises) when we also use a contradiction, do we need to reach a contradiction for all the cases or just one will be enough? Thanks in advance.","This is Velleman's exercise 3.5.5 ( And NO! not a duplicate of Prove that if $A \mathop \triangle B \subseteq A$ then $B\subseteq A$ ! My question is different ): Prove that if then Since in the definition of a symmetric difference we have disjunction, shouldn't we prove this statement by cases? So here's my proof of it: Proof. Let be an arbitrary element of . Now suppose . From and , we get . We now consider two cases. Case 1. . Then by , we have which is a contradiction. Case 2. . Since and , which is also a contradiction. Since by both cases we reached a contradiction then and since was arbitrary, . In other words, in proof by cases (when we have disjunction in the given/hypotheses/premises) when we also use a contradiction, do we need to reach a contradiction for all the cases or just one will be enough? Thanks in advance.",A \bigtriangleup B\subseteq A B \subseteq A. x B x \not\in A x \in B x \not\in A x \in (B\setminus A) x \in (A\setminus B) A \bigtriangleup B \subseteq A x \in A x \not\in (A\setminus B) x \in (B\setminus A) A \bigtriangleup B \subseteq A x \in A x \in A x B \subseteq A,"['elementary-set-theory', 'logic', 'proof-verification']"
90,Where did I go wrong? Analyze the logical form of $\{n^2+n+1 | n \in \mathbb{N}\} \subseteq \{2n+1 | n \in \mathbb{N}\}$,Where did I go wrong? Analyze the logical form of,\{n^2+n+1 | n \in \mathbb{N}\} \subseteq \{2n+1 | n \in \mathbb{N}\},"This question is taken from Velleman's $\textit{How to Prove it}$. It is in the exercises section of 2.3, Question 1c: $\{n^2+n+1 | n \in \mathbb{N}\} \subseteq \{2n+1 | n \in \mathbb{N}\}$ My work is as follows, The statement is equivalent to $\forall x(x \in \{n^2+n+1 | n \in \mathbb{N}\} \to x \in \{2n+1 | n \in \mathbb{N}\})$ (definition of a subset) $x \in \{n^2+n+1 | n \in \mathbb{N}\} \equiv \exists n \in \mathbb{N}(x=n^2+n+1)$ and $x \in \{2n+1 | n \in \mathbb{N}\} \equiv \exists n \in \mathbb{N}(x = 2n+1)$ so the final expression ends up as, $\forall x (\exists n \in \mathbb{N}(x=n^2+n+1) \to \exists n \in \mathbb{N}(x=2n+1))$ The solution provided is $\forall n \in \mathbb{N} \: \exists m \in \mathbb{N}(n^2+n+1=2m+1)$ which makes perfect sense to me looking at it in retrospect. I guess the overarching concern that I have is the methodology involved in solving the question - my approach was to break the statement down into smaller parts and then to rewrite after interpreting each individual segment (not an unreasonable strategy IMO, that seems to be what Velleman has been advocating up to this point). Was that approach incorrectly applied in this situation? Or did I make a technical error that I am just not aware of? Thanks in advance for any help/insight that can be given!","This question is taken from Velleman's $\textit{How to Prove it}$. It is in the exercises section of 2.3, Question 1c: $\{n^2+n+1 | n \in \mathbb{N}\} \subseteq \{2n+1 | n \in \mathbb{N}\}$ My work is as follows, The statement is equivalent to $\forall x(x \in \{n^2+n+1 | n \in \mathbb{N}\} \to x \in \{2n+1 | n \in \mathbb{N}\})$ (definition of a subset) $x \in \{n^2+n+1 | n \in \mathbb{N}\} \equiv \exists n \in \mathbb{N}(x=n^2+n+1)$ and $x \in \{2n+1 | n \in \mathbb{N}\} \equiv \exists n \in \mathbb{N}(x = 2n+1)$ so the final expression ends up as, $\forall x (\exists n \in \mathbb{N}(x=n^2+n+1) \to \exists n \in \mathbb{N}(x=2n+1))$ The solution provided is $\forall n \in \mathbb{N} \: \exists m \in \mathbb{N}(n^2+n+1=2m+1)$ which makes perfect sense to me looking at it in retrospect. I guess the overarching concern that I have is the methodology involved in solving the question - my approach was to break the statement down into smaller parts and then to rewrite after interpreting each individual segment (not an unreasonable strategy IMO, that seems to be what Velleman has been advocating up to this point). Was that approach incorrectly applied in this situation? Or did I make a technical error that I am just not aware of? Thanks in advance for any help/insight that can be given!",,['elementary-set-theory']
91,"Does every function $X^n \to Y$ for $X, Y$ finite extend to a linear transformation between finite vector spaces?",Does every function  for  finite extend to a linear transformation between finite vector spaces?,"X^n \to Y X, Y","Suppose we have any arbitrary function $f : X^n \to Y$, where $X, Y$ are finite sets and $n > 0$. Then is there necessarily a finite vector space $V$ containing $X$ and a finite vector space $W$ containing $Y$ so that $f$ is the restriction of a linear transformation $\phi : V^n \to W$? The $n=1$ case is pretty easy : just let $V$ be the free $K$-vector space on $X$, where $K$ is any finite field, and let $W$ be any $K$-vector space containing $Y$; since $X$ is now a basis of $V$, then $f : X^n \to Y$ automatically extends linearly to a (unique) linear transformation $V^n \to W$. Does the same kind of result hold for $n > 1$? If $X$ and $Y$ do not embed in vector spaces so that $f$ extends to a linear transformation, then can we relax the requirements and instead just require that $X$ and $Y$ embed in finite abelian groups so that $f$ extends to a group homomorphism? It seems that the naive attempt of letting $V$ again be a free vector space over $X$, and then extending $f$ to a map $V^n \to W$, where $W$ just contains $Y$, does not work, since $V^n$ is of dimension $n\left|X\right|$, while $\left|X^n\right| = \left|X\right|^n$ instead; and if we instead say that $V^n$ itself should be a free vector space over $X^n$, then this would require that $\dim V = \frac{1}{n}\left|X\right|^n$, so in particular we have an unnatural requirement that $n | \left|X\right|^n.$","Suppose we have any arbitrary function $f : X^n \to Y$, where $X, Y$ are finite sets and $n > 0$. Then is there necessarily a finite vector space $V$ containing $X$ and a finite vector space $W$ containing $Y$ so that $f$ is the restriction of a linear transformation $\phi : V^n \to W$? The $n=1$ case is pretty easy : just let $V$ be the free $K$-vector space on $X$, where $K$ is any finite field, and let $W$ be any $K$-vector space containing $Y$; since $X$ is now a basis of $V$, then $f : X^n \to Y$ automatically extends linearly to a (unique) linear transformation $V^n \to W$. Does the same kind of result hold for $n > 1$? If $X$ and $Y$ do not embed in vector spaces so that $f$ extends to a linear transformation, then can we relax the requirements and instead just require that $X$ and $Y$ embed in finite abelian groups so that $f$ extends to a group homomorphism? It seems that the naive attempt of letting $V$ again be a free vector space over $X$, and then extending $f$ to a map $V^n \to W$, where $W$ just contains $Y$, does not work, since $V^n$ is of dimension $n\left|X\right|$, while $\left|X^n\right| = \left|X\right|^n$ instead; and if we instead say that $V^n$ itself should be a free vector space over $X^n$, then this would require that $\dim V = \frac{1}{n}\left|X\right|^n$, so in particular we have an unnatural requirement that $n | \left|X\right|^n.$",,"['abstract-algebra', 'elementary-set-theory']"
92,Axiom of Dependent Choice and the von Neumann Universe,Axiom of Dependent Choice and the von Neumann Universe,,"Reading Roitman's revised edition of her 'Introduction to Modern Set Theory', I got  a bit confused about her proof of the claim that under regularity $V$, the universe of sets is equal to $\bigcup_{\alpha \in ON} V_\alpha$, the von Neumann universe, especially about the role of choice principles in that proof. Here's her proof. Let a set $x$ be big, if $x \not \in \bigcup_{\alpha \in ON} V_\alpha$. Every big $x$ has some big element. Otherwise we would have $x \subseteq \bigcup_{\alpha \in ON} V_\alpha$, which is impossible. So, if there's some big $x$, $x$ is the beginning of some infinite descending $\in$-chain, contradicting regularity. Here's my question: Doesn't inferring the existence of some infinite descending $\in$-chain require the axiom of Dependent Choice (DC)? For under DC from every big $x$ containg some big $y$ we can conclude that there's some countably infinite sequence of big sets $f$ with $f(0) = x$ and $f(n +1) \in f(n)$. Is there a way of avoiding choice principles in Roitman's proof?","Reading Roitman's revised edition of her 'Introduction to Modern Set Theory', I got  a bit confused about her proof of the claim that under regularity $V$, the universe of sets is equal to $\bigcup_{\alpha \in ON} V_\alpha$, the von Neumann universe, especially about the role of choice principles in that proof. Here's her proof. Let a set $x$ be big, if $x \not \in \bigcup_{\alpha \in ON} V_\alpha$. Every big $x$ has some big element. Otherwise we would have $x \subseteq \bigcup_{\alpha \in ON} V_\alpha$, which is impossible. So, if there's some big $x$, $x$ is the beginning of some infinite descending $\in$-chain, contradicting regularity. Here's my question: Doesn't inferring the existence of some infinite descending $\in$-chain require the axiom of Dependent Choice (DC)? For under DC from every big $x$ containg some big $y$ we can conclude that there's some countably infinite sequence of big sets $f$ with $f(0) = x$ and $f(n +1) \in f(n)$. Is there a way of avoiding choice principles in Roitman's proof?",,"['elementary-set-theory', 'logic']"
93,"Prove that if $A$ is any infinite set, the set of all finite subsets of $A$ has the same cardinality as $A$","Prove that if  is any infinite set, the set of all finite subsets of  has the same cardinality as",A A A,"I have considered as following: Consider any infinite set $A$ with cardinality $m$ for some infinite cardinal $m$, for each natural number $n$, denote the set of subsets of $A$ with exactly $n$ elements as $A_n$. Denote the set of finite subsets of $A$ by $F$, thus $F=\lbrace \emptyset \rbrace \cup A_1\cup A_2 \cup...=\lbrace \emptyset\rbrace \oplus A_1\oplus A_2\oplus...$. There is the missing argument to conclude that for each $n\in \Bbb N$, $A_n\approx A$ Hence $\#F=\#(\lbrace \emptyset\rbrace \oplus A_1\oplus A_2\oplus...)=1+m+m+... =m+m+...=(1+1+1+...)m=\aleph_0\cdot m=m$ Is that correct? I fell I am stuck on proving that each $A_n$ has the same cardinality as $A$. It seems to be related to the product set but I can only find an injection from each $A_n$ to $A^n$. So could someone please help? Thanks so much!","I have considered as following: Consider any infinite set $A$ with cardinality $m$ for some infinite cardinal $m$, for each natural number $n$, denote the set of subsets of $A$ with exactly $n$ elements as $A_n$. Denote the set of finite subsets of $A$ by $F$, thus $F=\lbrace \emptyset \rbrace \cup A_1\cup A_2 \cup...=\lbrace \emptyset\rbrace \oplus A_1\oplus A_2\oplus...$. There is the missing argument to conclude that for each $n\in \Bbb N$, $A_n\approx A$ Hence $\#F=\#(\lbrace \emptyset\rbrace \oplus A_1\oplus A_2\oplus...)=1+m+m+... =m+m+...=(1+1+1+...)m=\aleph_0\cdot m=m$ Is that correct? I fell I am stuck on proving that each $A_n$ has the same cardinality as $A$. It seems to be related to the product set but I can only find an injection from each $A_n$ to $A^n$. So could someone please help? Thanks so much!",,"['elementary-set-theory', 'cardinals']"
94,What does a transitive set exactly imply?,What does a transitive set exactly imply?,,"In set theory, what does it mean for a set to be transitive, and what does it have to do with transitivity of a relation?","In set theory, what does it mean for a set to be transitive, and what does it have to do with transitivity of a relation?",,['elementary-set-theory']
95,Prove that there are infinitely many natural numbers that are not powers of any prime.,Prove that there are infinitely many natural numbers that are not powers of any prime.,,"I am wondering whether there is a way to prove that the set consisting of all natural numbers that are not powers of any prime is infinite . For example, 6 is such a natural number. Just to make this clear, what I mean is that any numbers that are powers of 2,3,5,7... (prime numbers) are not in the defined set. So 2,4,8 ; 3,9,27 are not in the set. For a set to be infinite, I mean the following: I am trying to this by proving that this set is equivalent to $ \Bbb N$ but it is really hard to find an explicit bijection. Another way to do this is that I can prove the set consisting of all natural numbers that are powers of a primes is countably infinite . But it seems that the complement of a countably infinite set in $ \Bbb N$ may not be countably infinite? Can someone please give me a hand? Thanks.","I am wondering whether there is a way to prove that the set consisting of all natural numbers that are not powers of any prime is infinite . For example, 6 is such a natural number. Just to make this clear, what I mean is that any numbers that are powers of 2,3,5,7... (prime numbers) are not in the defined set. So 2,4,8 ; 3,9,27 are not in the set. For a set to be infinite, I mean the following: I am trying to this by proving that this set is equivalent to $ \Bbb N$ but it is really hard to find an explicit bijection. Another way to do this is that I can prove the set consisting of all natural numbers that are powers of a primes is countably infinite . But it seems that the complement of a countably infinite set in $ \Bbb N$ may not be countably infinite? Can someone please give me a hand? Thanks.",,"['number-theory', 'elementary-number-theory', 'elementary-set-theory']"
96,Comparing Infinite Sets,Comparing Infinite Sets,,"Hello Stack Exchange Community, I just read a book on Cantor and how he proved that the real numbers were a larger infinity than the natural numbers. He uses bijection and claims that if you were to write out all of the natural numbers you would be able to biject every single one with a real number, but after this bijection there would still be more real numbers. However, could you also use the same logic and biject all the real numbers with natural numbers and when you have a new real number, just add 1 to your previous real number? Also, since we can list all the fractions by listing 1 over every natural number, then 2 and 3 and on to infinity, couldn't we just write the ""first"" real number by just writing inifitely many zeroes, then a 1, then repeat but write 2, then 3, and all the natural numbers? This may just be a conceptual thing but I don't understand Cantor's logic and the different types of infinities.","Hello Stack Exchange Community, I just read a book on Cantor and how he proved that the real numbers were a larger infinity than the natural numbers. He uses bijection and claims that if you were to write out all of the natural numbers you would be able to biject every single one with a real number, but after this bijection there would still be more real numbers. However, could you also use the same logic and biject all the real numbers with natural numbers and when you have a new real number, just add 1 to your previous real number? Also, since we can list all the fractions by listing 1 over every natural number, then 2 and 3 and on to infinity, couldn't we just write the ""first"" real number by just writing inifitely many zeroes, then a 1, then repeat but write 2, then 3, and all the natural numbers? This may just be a conceptual thing but I don't understand Cantor's logic and the different types of infinities.",,['elementary-set-theory']
97,Are natural numbers a field with alternate addition and multiplication,Are natural numbers a field with alternate addition and multiplication,,"I've just started P.Halmos' book ""Finite Vector Spaces"", and at the first chapter, after defining the axioms of a field, there is an exercide that asks: if we consider the non negative integers, can we redefine addition and multiplication so that they form a field? Can't we, since $\mathbb{N}$ is countable just like $\mathbb{Q}$ that is a field, use some sort of coding to represent the field $\mathbb{Q}$ with it's operations with the natural numbers?","I've just started P.Halmos' book ""Finite Vector Spaces"", and at the first chapter, after defining the axioms of a field, there is an exercide that asks: if we consider the non negative integers, can we redefine addition and multiplication so that they form a field? Can't we, since $\mathbb{N}$ is countable just like $\mathbb{Q}$ that is a field, use some sort of coding to represent the field $\mathbb{Q}$ with it's operations with the natural numbers?",,"['elementary-set-theory', 'vector-spaces', 'field-theory']"
98,Is the $Cl(A \times B)=Cl(A) \times Cl(B)$.,Is the .,Cl(A \times B)=Cl(A) \times Cl(B),"Here is my the part of my proof that I have questions about namely; the first containment. $ \subset) $ $$ (x,y)\in Cl(A \times B) $$ Therefore every closed set in the product topology looks like $$ (x,y) \in \bigcap_\alpha( U_\alpha \times V_\alpha)|\text{$U_\alpha$  closed in $A$ and $V_\alpha$ closed in B } $$ So now is the part I am unsure about is the rest $$ x\in\bigcap_\alpha U_\alpha \quad \quad y\in \bigcap_\alpha V_\alpha $$ Thus $$ x\in Cl(A) \quad y\in Cl(B) $$ Therefore $$ (x,y)\in Cl(A)\times Cl(B). $$","Here is my the part of my proof that I have questions about namely; the first containment. $ \subset) $ $$ (x,y)\in Cl(A \times B) $$ Therefore every closed set in the product topology looks like $$ (x,y) \in \bigcap_\alpha( U_\alpha \times V_\alpha)|\text{$U_\alpha$  closed in $A$ and $V_\alpha$ closed in B } $$ So now is the part I am unsure about is the rest $$ x\in\bigcap_\alpha U_\alpha \quad \quad y\in \bigcap_\alpha V_\alpha $$ Thus $$ x\in Cl(A) \quad y\in Cl(B) $$ Therefore $$ (x,y)\in Cl(A)\times Cl(B). $$",,"['general-topology', 'elementary-set-theory']"
99,The topology of sets,The topology of sets,,"Normally limits come from topologies. However the set-theoretic limit is defined without reference to a specific topology. Therefore I wonder: What is the topology of sets that corresponds to this limit? Using this answer to another question of me, I figured out that the set of all subsets with at most $n$ elements of a given set is closed, and that the set of all finite subsets of an infinite set is not closed, but that by itself doesn't really give me an idea what the topology looks like. What I'd like is a general rule when some set is open or closed under this topology.","Normally limits come from topologies. However the set-theoretic limit is defined without reference to a specific topology. Therefore I wonder: What is the topology of sets that corresponds to this limit? Using this answer to another question of me, I figured out that the set of all subsets with at most $n$ elements of a given set is closed, and that the set of all finite subsets of an infinite set is not closed, but that by itself doesn't really give me an idea what the topology looks like. What I'd like is a general rule when some set is open or closed under this topology.",,"['general-topology', 'elementary-set-theory']"
