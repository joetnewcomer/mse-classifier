,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,The fundamental vector fields of a principal bundle are vertical.,The fundamental vector fields of a principal bundle are vertical.,,"Let $p:P\to M$ be a principal $G$-bundle. To each $A$ in the Lie algebra of $G$ corresponds a fundamental vector field $A^*$ on $M$ defined by $$A^*_u=\frac{d}{dt}|_{t=0} u(exp(tA))$$ How can we see that $A_u^*$ is a vertical vector? Idea: We need to verify that $p_*(A_u^*)=0$. None of the manipulations that I apply to the left hand side help. Supposedly, the statement is obvious from the fact that the action of $G$ takes each fiber to itself.","Let $p:P\to M$ be a principal $G$-bundle. To each $A$ in the Lie algebra of $G$ corresponds a fundamental vector field $A^*$ on $M$ defined by $$A^*_u=\frac{d}{dt}|_{t=0} u(exp(tA))$$ How can we see that $A_u^*$ is a vertical vector? Idea: We need to verify that $p_*(A_u^*)=0$. None of the manipulations that I apply to the left hand side help. Supposedly, the statement is obvious from the fact that the action of $G$ takes each fiber to itself.",,"['differential-geometry', 'differential-topology', 'lie-groups', 'lie-algebras', 'principal-bundles']"
1,question from do carmo diff. geometry,question from do carmo diff. geometry,,"I am studying differential geometry myself from Do carmo and i didn't understand the question : show that if a surface is tangent to a plane along a curve , then the points of this curve are either parabolic or planar . At the question i didn't understand the sentence ' surface is tangent to a plane along a curve '  Please firstly help  me about it and later maybe hints for solution","I am studying differential geometry myself from Do carmo and i didn't understand the question : show that if a surface is tangent to a plane along a curve , then the points of this curve are either parabolic or planar . At the question i didn't understand the sentence ' surface is tangent to a plane along a curve '  Please firstly help  me about it and later maybe hints for solution",,['differential-geometry']
2,Codifferential and corresponding homology theory,Codifferential and corresponding homology theory,,"This is the kind of a natural question which can come to mind after completing the standard course in differential geometry and homology theory: lety us start with a smooth manifold $M$. One can construct the differential $d$ on differential forms which satisfies $d^2=0$. With the help of this differnetial one can consider de Rham (cochain) complex and one naturally arrives to the de Rham cohomology. However, it is also possible to consider the codifferential $\delta$ defined as $\pm \star d \star$ where $\star$ is the Hodge star operator. However, as far as I understood, the Hodge star depends on the choice of metric (Riemannian) structure on $M$. This codifferential satisfies $\delta^2=0$ so also gives rise to some (chain) complex and therefore to some homology theory. Question : what is the connection of homology corresponding to this codifferential with (for instance) singular homology? In patricular, is it true that this homology does not depend from the choice of metric structure?","This is the kind of a natural question which can come to mind after completing the standard course in differential geometry and homology theory: lety us start with a smooth manifold $M$. One can construct the differential $d$ on differential forms which satisfies $d^2=0$. With the help of this differnetial one can consider de Rham (cochain) complex and one naturally arrives to the de Rham cohomology. However, it is also possible to consider the codifferential $\delta$ defined as $\pm \star d \star$ where $\star$ is the Hodge star operator. However, as far as I understood, the Hodge star depends on the choice of metric (Riemannian) structure on $M$. This codifferential satisfies $\delta^2=0$ so also gives rise to some (chain) complex and therefore to some homology theory. Question : what is the connection of homology corresponding to this codifferential with (for instance) singular homology? In patricular, is it true that this homology does not depend from the choice of metric structure?",,"['differential-geometry', 'manifolds', 'homology-cohomology']"
3,Smooth curves on manifolds,Smooth curves on manifolds,,"Assume that there is a parametrized smooth curve $c$ on the manifold $M$, mapping from $[a,b]$ to $M$. Also assume that there is a tangent vector on $M$ in the form $(p,v)$. Tu's text states that it is assumed that the curve $c$ is starting at $p$ if $c(0)=p$. Is there a way to show that $c(0)=p$ in any way? Any help would be appreciated! Thanks in advance!","Assume that there is a parametrized smooth curve $c$ on the manifold $M$, mapping from $[a,b]$ to $M$. Also assume that there is a tangent vector on $M$ in the form $(p,v)$. Tu's text states that it is assumed that the curve $c$ is starting at $p$ if $c(0)=p$. Is there a way to show that $c(0)=p$ in any way? Any help would be appreciated! Thanks in advance!",,['differential-geometry']
4,Finding Gauss curvature of surface,Finding Gauss curvature of surface,,"Consider the surface $S=F(\mathbb{R}^2)$ where $F:\mathbb{R}^2 \to \mathbb{R}^3$ is defined by $$(r, \varphi) \mapsto ( r \cos \varphi, r \sin \varphi, \varphi).$$ I would like to find the Gauss curvature of $S$ . We defined the Gauss curvature of $S$ at the point $p$ as $\det(W_p)$ where $W_p: T_p S \to T_p S$ is the Weingarten-map defined by $W_p: X\mapsto - d_p N(X)$. Here $N: S \to \mathbb{R}^3$ assigns to each $p\in S$ a vector $N(p)$ that is orthogonal on the tangential space $T_p S$. Working with this definition seems terribly complicated. How do I find the map $N$ ? Is there a nicer way of doing this?","Consider the surface $S=F(\mathbb{R}^2)$ where $F:\mathbb{R}^2 \to \mathbb{R}^3$ is defined by $$(r, \varphi) \mapsto ( r \cos \varphi, r \sin \varphi, \varphi).$$ I would like to find the Gauss curvature of $S$ . We defined the Gauss curvature of $S$ at the point $p$ as $\det(W_p)$ where $W_p: T_p S \to T_p S$ is the Weingarten-map defined by $W_p: X\mapsto - d_p N(X)$. Here $N: S \to \mathbb{R}^3$ assigns to each $p\in S$ a vector $N(p)$ that is orthogonal on the tangential space $T_p S$. Working with this definition seems terribly complicated. How do I find the map $N$ ? Is there a nicer way of doing this?",,"['general-topology', 'differential-geometry', 'differential-topology']"
5,Minkowski metric on a surface,Minkowski metric on a surface,,Do closed surfaces admit a metric with lorentzian signature? Any reference?,Do closed surfaces admit a metric with lorentzian signature? Any reference?,,"['differential-geometry', 'mathematical-physics', 'surfaces']"
6,Signature of a finite covering space,Signature of a finite covering space,,"Suppose $\tilde{M}\rightarrow M$ is a finite (k-fold) covering of the smooth, oriented, compact 4-manifold $M$. Is there a relation between the signatures ( http://en.wikipedia.org/wiki/Signature_(topology) ) of $M$ and $\tilde{M}$? I have a line of reasoning involving the Hirzebruch signature theorem that suggests $\sigma(\tilde{M})=k\cdot\sigma(M)$. If this is true, I would love to see independent lines of reasoning that support it.","Suppose $\tilde{M}\rightarrow M$ is a finite (k-fold) covering of the smooth, oriented, compact 4-manifold $M$. Is there a relation between the signatures ( http://en.wikipedia.org/wiki/Signature_(topology) ) of $M$ and $\tilde{M}$? I have a line of reasoning involving the Hirzebruch signature theorem that suggests $\sigma(\tilde{M})=k\cdot\sigma(M)$. If this is true, I would love to see independent lines of reasoning that support it.",,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
7,Gluing oriented manifold along boundaries,Gluing oriented manifold along boundaries,,"Let $M_1$ and $M_2$ be oriented manifolds with boundaries. Suppose they have homeomorphic boundaries. I want to glue $M_1$ and $M_2$ along the boundaries via some homeomorphism. To ensure that the resulting space is again an oriented manifold, I think I need to take an orientation reversing homeomorphism between boundaries. So let $f:\partial M_1 \to \partial M_2$ be a homeomorphism. My question is that:should $f$ be an orientation preserving with respect to the induced orientation on the boundaries? Or can we choose any orientations on the boundaries so that $f$ is orientation reversing with respect to the choice of the orientations of the boundaries? Thank you.","Let $M_1$ and $M_2$ be oriented manifolds with boundaries. Suppose they have homeomorphic boundaries. I want to glue $M_1$ and $M_2$ along the boundaries via some homeomorphism. To ensure that the resulting space is again an oriented manifold, I think I need to take an orientation reversing homeomorphism between boundaries. So let $f:\partial M_1 \to \partial M_2$ be a homeomorphism. My question is that:should $f$ be an orientation preserving with respect to the induced orientation on the boundaries? Or can we choose any orientations on the boundaries so that $f$ is orientation reversing with respect to the choice of the orientations of the boundaries? Thank you.",,"['general-topology', 'differential-geometry']"
8,How does $v\Phi^1=\cdots=v\Phi^k=0$ imply $v\in\ker d\Phi_p$?,How does  imply ?,v\Phi^1=\cdots=v\Phi^k=0 v\in\ker d\Phi_p,"I'm confused about an immediate corollary in John Lee's Smooth Manifolds . Proposition 5.38 says Suppose $M$ is a smooth manifold and $S\subset M$ is an embedded submanifold. If $\Phi\colon U\to N$ is any local defining map for $S$, then $T_pS=\ker d\Phi_p\colon T_pM\to T_{\Phi(p)}N$ for each $p\in S\cap U$. It says an immediate corollary is that if $S\subseteq M$ is a level set of a smooth submersion $\Phi=(\Phi^1,\dots,\Phi^k)\colon M\to\mathbb{R}^k$, then $v\in T_pM$ is tangent to $S$ iff $v\Phi^1=\cdots=v\Phi^k=0$. Why does $v\Phi^1=\cdots=v\Phi^k=0$ imply $v\in T_pS$? By the proposition, how does  $v\Phi^1=\cdots=v\Phi^k=0$ imply $v\in\ker d\Phi_p$? I don't see how to relate this to the individual components though to use $v\Phi^1=\cdots=v\Phi^k=0$.","I'm confused about an immediate corollary in John Lee's Smooth Manifolds . Proposition 5.38 says Suppose $M$ is a smooth manifold and $S\subset M$ is an embedded submanifold. If $\Phi\colon U\to N$ is any local defining map for $S$, then $T_pS=\ker d\Phi_p\colon T_pM\to T_{\Phi(p)}N$ for each $p\in S\cap U$. It says an immediate corollary is that if $S\subseteq M$ is a level set of a smooth submersion $\Phi=(\Phi^1,\dots,\Phi^k)\colon M\to\mathbb{R}^k$, then $v\in T_pM$ is tangent to $S$ iff $v\Phi^1=\cdots=v\Phi^k=0$. Why does $v\Phi^1=\cdots=v\Phi^k=0$ imply $v\in T_pS$? By the proposition, how does  $v\Phi^1=\cdots=v\Phi^k=0$ imply $v\in\ker d\Phi_p$? I don't see how to relate this to the individual components though to use $v\Phi^1=\cdots=v\Phi^k=0$.",,"['differential-geometry', 'differential-topology']"
9,is knot type invariant under diffeomorphism?,is knot type invariant under diffeomorphism?,,"Is it possible to have a diffeomorphism of $R^3$ which changes the knot type, for instance the image of a trivial knot is a trefoil knot?","Is it possible to have a diffeomorphism of $R^3$ which changes the knot type, for instance the image of a trivial knot is a trefoil knot?",,"['differential-geometry', 'knot-theory']"
10,curve of constant curvature on unit sphere is planar curve?,curve of constant curvature on unit sphere is planar curve?,,"I've studied differential geometry and get this question. I'd like to verify following statement. curve of constant curvature on unit sphere is planar curve I've struggled with Frenet-Serret frame, differentiating, differentiating, differentiating, ..... BUT I didn't get something yet.. Could you give me some hint, please? $$ $$ Ah!! FIRST OF ALL, I'd like to know whether the statement is true or false. Thanks in advance.","I've studied differential geometry and get this question. I'd like to verify following statement. curve of constant curvature on unit sphere is planar curve I've struggled with Frenet-Serret frame, differentiating, differentiating, differentiating, ..... BUT I didn't get something yet.. Could you give me some hint, please? $$ $$ Ah!! FIRST OF ALL, I'd like to know whether the statement is true or false. Thanks in advance.",,"['differential-geometry', 'frenet-frame']"
11,"Are vector bundles just modules over $C^{\infty}(M)$, or are ""locality"" conditions required?","Are vector bundles just modules over , or are ""locality"" conditions required?",C^{\infty}(M),"In this question the asker defines 1-forms on a (real, smooth) manifold $M$ to be $C^{\infty}(M)$-module homomorphism[s] from $Vec(M)$ to $C^{\infty}(M).\:\:\:\:(*)$ I'm wondering if this is correct. I've previously seen 1-forms defined as being homomorphisms from $TM$ to $\mathbb{R}\times M$ as vector-bundles-over-$M$. It's easy to see that a 1-form in this sense defines a 1-form in the first sense, but I can't see why the converse is true. It seems like an extra condition ought to be added to $(*)$ saying that given a supposed 1-form $\eta$ taking a vector $X$ to a scalar $f$, the value of $f$ at $x\in M$ should depend only on the value of $X$ at $x$. Or something like that. Are all $C^{\infty}(M)$-modules given by spaces of sections of vector bundles? Are all $C^{\infty}(M)$-homomorphisms between the spaces of sections of bundles given by corresponding maps between the bundles themselves?","In this question the asker defines 1-forms on a (real, smooth) manifold $M$ to be $C^{\infty}(M)$-module homomorphism[s] from $Vec(M)$ to $C^{\infty}(M).\:\:\:\:(*)$ I'm wondering if this is correct. I've previously seen 1-forms defined as being homomorphisms from $TM$ to $\mathbb{R}\times M$ as vector-bundles-over-$M$. It's easy to see that a 1-form in this sense defines a 1-form in the first sense, but I can't see why the converse is true. It seems like an extra condition ought to be added to $(*)$ saying that given a supposed 1-form $\eta$ taking a vector $X$ to a scalar $f$, the value of $f$ at $x\in M$ should depend only on the value of $X$ at $x$. Or something like that. Are all $C^{\infty}(M)$-modules given by spaces of sections of vector bundles? Are all $C^{\infty}(M)$-homomorphisms between the spaces of sections of bundles given by corresponding maps between the bundles themselves?",,"['differential-geometry', 'vector-bundles']"
12,Why $S^1\times S^{2m-1}$ carries a complex structure.,Why  carries a complex structure.,S^1\times S^{2m-1},"Let $S^n$ denotes $n$-sphere, then why $S^1\times S^{2m-1}$ carries a complex structure.","Let $S^n$ denotes $n$-sphere, then why $S^1\times S^{2m-1}$ carries a complex structure.",,"['differential-geometry', 'complex-geometry', 'kahler-manifolds']"
13,Path to Differential Geometry,Path to Differential Geometry,,"What do I need to learn to start on the rigorous study of differential geometry?  I'm about to start my 3rd undergrad year at school, and have taken Cal 1-3, Linear Algebra, Elementary Number Theory, and ODEs. If I want to take the most direct path to studying differential geometry, what should I start learning now?  Should I start on Real Analysis or Topology?  Should I just pick up Spivak's Intro to Differential Geometry ?  My multivariable calculus class did not cover differential forms, so should I read his Calculus on Manifolds or Munkres' Analysis on Manifolds first? I'm pretty sure that I want to study differential geometry in grad school and I'd like to start on it before then (ideally, I'd like to be able to publish something -- not necessarily extremely deep -- in diff geo before applying to grad schools). So what path should I take to self-study it? NOTE: My school has 1 undergrad course in Differential Geometry available in the Spring, so I'll probably do that next year, but I'd rather start now and go well beyond whatever I'm going to learn in that class.","What do I need to learn to start on the rigorous study of differential geometry?  I'm about to start my 3rd undergrad year at school, and have taken Cal 1-3, Linear Algebra, Elementary Number Theory, and ODEs. If I want to take the most direct path to studying differential geometry, what should I start learning now?  Should I start on Real Analysis or Topology?  Should I just pick up Spivak's Intro to Differential Geometry ?  My multivariable calculus class did not cover differential forms, so should I read his Calculus on Manifolds or Munkres' Analysis on Manifolds first? I'm pretty sure that I want to study differential geometry in grad school and I'd like to start on it before then (ideally, I'd like to be able to publish something -- not necessarily extremely deep -- in diff geo before applying to grad schools). So what path should I take to self-study it? NOTE: My school has 1 undergrad course in Differential Geometry available in the Spring, so I'll probably do that next year, but I'd rather start now and go well beyond whatever I'm going to learn in that class.",,"['differential-geometry', 'soft-question', 'advice']"
14,Construct tensors from differential forms?,Construct tensors from differential forms?,,"Let $(M,g)$ be a Riemannian manifold, differential forms are defined using tensors, could we define a tensor using a differential form? For example, if $\omega$ is a two-form on $M$ which is expressed locally as $$F(p)=F_{ij}(p)e^i\wedge e^j,$$ where $e_i$ is an o.n. basis for $T_pM$ and $F_{ji}=-F_{ij}$, is $T=(F_{ij}-F_{ji})e^i\otimes e^j$ a well-defined two-tensor on $M$? Added: is $F(p)=\sigma_{ij}F_{ij}(p)e^i\wedge e^j$ well-defined? where $\sigma_{ij}=1$ or $-1$. Edited according to Hurkyl's answer.","Let $(M,g)$ be a Riemannian manifold, differential forms are defined using tensors, could we define a tensor using a differential form? For example, if $\omega$ is a two-form on $M$ which is expressed locally as $$F(p)=F_{ij}(p)e^i\wedge e^j,$$ where $e_i$ is an o.n. basis for $T_pM$ and $F_{ji}=-F_{ij}$, is $T=(F_{ij}-F_{ji})e^i\otimes e^j$ a well-defined two-tensor on $M$? Added: is $F(p)=\sigma_{ij}F_{ij}(p)e^i\wedge e^j$ well-defined? where $\sigma_{ij}=1$ or $-1$. Edited according to Hurkyl's answer.",,"['differential-geometry', 'differential-forms', 'tensors']"
15,What is the pushforward of a function (not a vector),What is the pushforward of a function (not a vector),,"If we have two manifolds $M$, $N$ with the map $f:M \to N$, then this induces a map between their tangent spaces $f_*:T_pM \to T_{f(p)} N$. By duality, another map exists $f^* : T^*_{f(p)}N \to T^*_pM$. This gives rise to the following relation: \begin{equation} f^* \omega(V) = \omega(f_* V)  \tag{1} \end{equation} for $V \in T_pM$ and $\omega \in T^*_{f(p)}N$. Now what happens when $\omega$ is a smooth function on $N$, i.e. $\omega \in C^\infty(N)$? Then I think we have $f^* : C^\infty(N) \to C^\infty(M)$. If so, what does $f_*$ maps such that it is consistent with equation $(1)$?","If we have two manifolds $M$, $N$ with the map $f:M \to N$, then this induces a map between their tangent spaces $f_*:T_pM \to T_{f(p)} N$. By duality, another map exists $f^* : T^*_{f(p)}N \to T^*_pM$. This gives rise to the following relation: \begin{equation} f^* \omega(V) = \omega(f_* V)  \tag{1} \end{equation} for $V \in T_pM$ and $\omega \in T^*_{f(p)}N$. Now what happens when $\omega$ is a smooth function on $N$, i.e. $\omega \in C^\infty(N)$? Then I think we have $f^* : C^\infty(N) \to C^\infty(M)$. If so, what does $f_*$ maps such that it is consistent with equation $(1)$?",,"['differential-geometry', 'vector-spaces', 'differential-topology']"
16,Integrating a 0-form,Integrating a 0-form,,"The Stokes theorem states: $$\int_\mathcal M d\omega =\int_{\partial \mathcal M} \omega $$ If we have that $\mathcal M$ is a one dimensional manifold with two extreme points, like a closed interval of $\mathbb R$, and $d\omega$  is a one-form, how could the integral in the second term be done? Does that make sense? Because $\partial\mathcal M$ is just two isolated points. We are integrating a function to a single point? The only thing that makes some sense would be the value of the function at those points, and only because it coincides in a specific problem with what I should get by integrating $d\omega$ to the curve, but I don't see that clear at all. I know this is actually what gives: $$\int_a^b df=\left. f\right|_a^b$$ but I can't prove it.","The Stokes theorem states: $$\int_\mathcal M d\omega =\int_{\partial \mathcal M} \omega $$ If we have that $\mathcal M$ is a one dimensional manifold with two extreme points, like a closed interval of $\mathbb R$, and $d\omega$  is a one-form, how could the integral in the second term be done? Does that make sense? Because $\partial\mathcal M$ is just two isolated points. We are integrating a function to a single point? The only thing that makes some sense would be the value of the function at those points, and only because it coincides in a specific problem with what I should get by integrating $d\omega$ to the curve, but I don't see that clear at all. I know this is actually what gives: $$\int_a^b df=\left. f\right|_a^b$$ but I can't prove it.",,['differential-geometry']
17,diffeomorphism preserve a volume form,diffeomorphism preserve a volume form,,"Let $\omega_1$, $\omega_2$ two volume form on a compact manifold $M$, we know that there exists a never-vanishing function $f$, s.t.   $\omega_1=f\omega_2$. If $h$ is a diffeomorphism $M \to M$ preserves $\omega_1$, does it preserve $\omega_2$?","Let $\omega_1$, $\omega_2$ two volume form on a compact manifold $M$, we know that there exists a never-vanishing function $f$, s.t.   $\omega_1=f\omega_2$. If $h$ is a diffeomorphism $M \to M$ preserves $\omega_1$, does it preserve $\omega_2$?",,"['differential-geometry', 'differential-forms']"
18,"How to show the symplectic group is a submanifold of $GL(n,\mathbb{H})$?",How to show the symplectic group is a submanifold of ?,"GL(n,\mathbb{H})","I am trying to show that the symplectic group $Sp(n) =\{A\in GL(n,\mathbb{H})\mid \overline{A}^TA=I\}$ is a regular submanifold of $GL(n,\mathbb{H})$ but I am stuck. Any help would be appreciated.","I am trying to show that the symplectic group $Sp(n) =\{A\in GL(n,\mathbb{H})\mid \overline{A}^TA=I\}$ is a regular submanifold of $GL(n,\mathbb{H})$ but I am stuck. Any help would be appreciated.",,['differential-geometry']
19,Surjectivity of an integration map,Surjectivity of an integration map,,"N.B. : Thanks to studiosus answer I realised I should ask for more conditions or otherwise the answer is straightforwardly wrong. I rechecked my problem and added new assumptions that I boldface. Given $\tau>0$ we have a finite number of smooth maps $$\gamma_i:[0,\tau]\longrightarrow\mathbb{R}^n,\ i=1,\ldots,s.$$ Let $V$ the real vector space spanned by $\gamma_1,\ldots,\gamma_s$. To every $\gamma\in V$ we associate $n$ smooth non-negative functions $$f_\gamma^1,\ldots,f_\gamma^n:[0,\tau]\longrightarrow\mathbb{R}$$ such that $f_\gamma^j(0)=f_\gamma^j(\tau)=0$ . I would like to prove that $$ \begin{array}{ccc} V & \longrightarrow &\mathbb{R}^n\\ \gamma & \longmapsto & \left(\int_0^\tau f^1_\gamma(t)dt\cdots\int_0^\tau f^n_\gamma(t)dt\right) \end{array} $$ is surjective assuming the following hypothesis: 1) There exists $t_0\in(0,\tau)$ such that $(f_{\gamma_1}^1(t_0)\cdots f_{\gamma_1}^n(t_0)),\ldots,(f_{\gamma_s}^1(t_0)\cdots f_{\gamma_s}^n(t_0))$ span $\mathbb{R}^n$. 2) The mappings  $$ \begin{array}{ccc} V & \longrightarrow & C^\infty([0,\tau],\mathbb{R})\\  \gamma &\longmapsto & f_\gamma^j \end{array} $$ are linear for $j=1,\ldots,n$. N.B.: The question actually comes from a differential geometry problem (hence the tag) but I tried to get rid of all the unnecessary stuff and keep the essential information. Hopefully that will suffice to get your hints.","N.B. : Thanks to studiosus answer I realised I should ask for more conditions or otherwise the answer is straightforwardly wrong. I rechecked my problem and added new assumptions that I boldface. Given $\tau>0$ we have a finite number of smooth maps $$\gamma_i:[0,\tau]\longrightarrow\mathbb{R}^n,\ i=1,\ldots,s.$$ Let $V$ the real vector space spanned by $\gamma_1,\ldots,\gamma_s$. To every $\gamma\in V$ we associate $n$ smooth non-negative functions $$f_\gamma^1,\ldots,f_\gamma^n:[0,\tau]\longrightarrow\mathbb{R}$$ such that $f_\gamma^j(0)=f_\gamma^j(\tau)=0$ . I would like to prove that $$ \begin{array}{ccc} V & \longrightarrow &\mathbb{R}^n\\ \gamma & \longmapsto & \left(\int_0^\tau f^1_\gamma(t)dt\cdots\int_0^\tau f^n_\gamma(t)dt\right) \end{array} $$ is surjective assuming the following hypothesis: 1) There exists $t_0\in(0,\tau)$ such that $(f_{\gamma_1}^1(t_0)\cdots f_{\gamma_1}^n(t_0)),\ldots,(f_{\gamma_s}^1(t_0)\cdots f_{\gamma_s}^n(t_0))$ span $\mathbb{R}^n$. 2) The mappings  $$ \begin{array}{ccc} V & \longrightarrow & C^\infty([0,\tau],\mathbb{R})\\  \gamma &\longmapsto & f_\gamma^j \end{array} $$ are linear for $j=1,\ldots,n$. N.B.: The question actually comes from a differential geometry problem (hence the tag) but I tried to get rid of all the unnecessary stuff and keep the essential information. Hopefully that will suffice to get your hints.",,"['real-analysis', 'linear-algebra', 'integration', 'differential-geometry']"
20,Unitary group and unit circle,Unitary group and unit circle,,"Let $U(n)$ denote the group of complex unitary matrices, let $S^1$ be the unit circle in the complex plane. Then the map $$f:U(n)\to S^1,\quad f(A)=det(A)$$ is a group homomorphism and a submersion. It is straight forward to show that $f$ is a group homomorphism. For the second part, we have the derivative of $f$ as follows: $$df_A(X)=det(A)tr(A^{-1}X)$$ I wonder how can we show that $df_A:T_AU(n)\to T_{f(A)}S^1$ is surjective. Please help","Let $U(n)$ denote the group of complex unitary matrices, let $S^1$ be the unit circle in the complex plane. Then the map $$f:U(n)\to S^1,\quad f(A)=det(A)$$ is a group homomorphism and a submersion. It is straight forward to show that $f$ is a group homomorphism. For the second part, we have the derivative of $f$ as follows: $$df_A(X)=det(A)tr(A^{-1}X)$$ I wonder how can we show that $df_A:T_AU(n)\to T_{f(A)}S^1$ is surjective. Please help",,"['differential-geometry', 'manifolds', 'lie-groups']"
21,Finding the metric of a surface embedded in $\mathbb{R}^3$,Finding the metric of a surface embedded in,\mathbb{R}^3,"I have a problem about finding the metric of a surface defined by $x=\rho\cos\varphi,\ y=\rho\sin\varphi,\ z=\rho^2$, embedded into $\mathbb{R}^3$, where $ds^2=dx^2+dy^2+dz^2$. I have literally no idea how to do this. Worse perhaps, is I find the expression $ds^2=dx^2+dy^2+dz^2$ hopelessly meaningless, because I can't understand any precise meaning of $ds, dx$ etc. I understand it's supposed to capture the nature of the pythagorean theorem as used to calculate distances in 3D and generalise it, but what exactly $dx$ is precisely escapes me. ""A small distance"" or ""A small change"" don't do it for me; it's apparently being used to define distances so calling it a small distance is clearly circular, and what exactly makes a small change? How do you calculate with such quantities? How do you know how the expression for $ds^2$ is going to change when you change coordinates? (These are questions I feel I really shouldn't have to ask, but my lecturer is very sporadic, unclear, and provides very few resources, and feel quite stuck.) I am looking for an explanation or some resources to enlighten me as to what I should understand by these quantities/expressions, and some hopefully some help with how I would go about finding the metric of the paraboloid above. I would also appreciate a recommendation of a good text for a first course on differential geometry of curves and surfaces to self-study from. Thanks in advance.","I have a problem about finding the metric of a surface defined by $x=\rho\cos\varphi,\ y=\rho\sin\varphi,\ z=\rho^2$, embedded into $\mathbb{R}^3$, where $ds^2=dx^2+dy^2+dz^2$. I have literally no idea how to do this. Worse perhaps, is I find the expression $ds^2=dx^2+dy^2+dz^2$ hopelessly meaningless, because I can't understand any precise meaning of $ds, dx$ etc. I understand it's supposed to capture the nature of the pythagorean theorem as used to calculate distances in 3D and generalise it, but what exactly $dx$ is precisely escapes me. ""A small distance"" or ""A small change"" don't do it for me; it's apparently being used to define distances so calling it a small distance is clearly circular, and what exactly makes a small change? How do you calculate with such quantities? How do you know how the expression for $ds^2$ is going to change when you change coordinates? (These are questions I feel I really shouldn't have to ask, but my lecturer is very sporadic, unclear, and provides very few resources, and feel quite stuck.) I am looking for an explanation or some resources to enlighten me as to what I should understand by these quantities/expressions, and some hopefully some help with how I would go about finding the metric of the paraboloid above. I would also appreciate a recommendation of a good text for a first course on differential geometry of curves and surfaces to self-study from. Thanks in advance.",,['differential-geometry']
22,How can I parametrize Viviani's Curve?,How can I parametrize Viviani's Curve?,,"How can I parametrize Viviani's Curve ? $\textbf{Viviani’s curve}$ is the intersection of the unit sphere with center $(\frac{-1}{2},0,0)$ and the cylinder with center $(0,0,0)$ and radius $1/2$ Paramatrization of the cylinder is $(\frac{1}{2}cos(t),\frac{1}{2}sin(t),?)$ and the unit sphere $(cos(\theta)cos(\phi)-\frac{1}{2},cos(\theta)sin(\phi),sin(\theta))$ I think, i have to use some trigonometric equations but i see only 1 in this case.","How can I parametrize Viviani's Curve ? is the intersection of the unit sphere with center and the cylinder with center and radius Paramatrization of the cylinder is and the unit sphere I think, i have to use some trigonometric equations but i see only 1 in this case.","\textbf{Viviani’s curve} (\frac{-1}{2},0,0) (0,0,0) 1/2 (\frac{1}{2}cos(t),\frac{1}{2}sin(t),?) (cos(\theta)cos(\phi)-\frac{1}{2},cos(\theta)sin(\phi),sin(\theta))","['differential-geometry', 'curves']"
23,Show that $N$ is contained a plane.,Show that  is contained a plane.,N,"Let $\alpha$ be a planar curve in $\mathbb R^3$, contained in plane $P$. Show that its normal  vector $N$ at every point is in the plane P also. The only thing I know is that the torsion is 0, but I don't how to relate it to N. Please give me some idea.","Let $\alpha$ be a planar curve in $\mathbb R^3$, contained in plane $P$. Show that its normal  vector $N$ at every point is in the plane P also. The only thing I know is that the torsion is 0, but I don't how to relate it to N. Please give me some idea.",,['differential-geometry']
24,Are critical points fixed?,Are critical points fixed?,,"Let $M$ be a smooth manifold (compact, connected, without boundary and oriented if you wish) with a smooth action of $S^1$. Let $f:M\rightarrow\mathbb{R}$ be an invariant function $f$. I know how to prove that a fixed point of the action is a critical point of $f$. What I don't know is if the converse is true: I can prove that if a point is critical, then all the points in its orbit are critical as well, but that's all. So the questions are: 1) Are the critical points of $f$ necessarily fixed? 2) If the answer to 1) is ""yes"": any hint on the proof? 3) If the answer to 1) is ""no"": any counterexample? Is there any extra condition that makes the answer of 1) to be ""yes""?","Let $M$ be a smooth manifold (compact, connected, without boundary and oriented if you wish) with a smooth action of $S^1$. Let $f:M\rightarrow\mathbb{R}$ be an invariant function $f$. I know how to prove that a fixed point of the action is a critical point of $f$. What I don't know is if the converse is true: I can prove that if a point is critical, then all the points in its orbit are critical as well, but that's all. So the questions are: 1) Are the critical points of $f$ necessarily fixed? 2) If the answer to 1) is ""yes"": any hint on the proof? 3) If the answer to 1) is ""no"": any counterexample? Is there any extra condition that makes the answer of 1) to be ""yes""?",,['differential-geometry']
25,Length-Diameter Inequality for Convex Curves using Fourier Analysis,Length-Diameter Inequality for Convex Curves using Fourier Analysis,,"I'm trying to prove an isoperimetric inequality, but I have absolutely no idea how to go about it. let $\Gamma$ be a closed plane curve parametrized by $\gamma(t) = (x(t), y(t))$ on $[-\pi, \pi]$. Let $l$ denote the length of the curve and $d = \sup_{t_1, t_2 \in [-\pi, \pi]} |\gamma(t_1) - \gamma(t_2)|$. If $\Gamma$ is convex then $l\leq \pi d$.","I'm trying to prove an isoperimetric inequality, but I have absolutely no idea how to go about it. let $\Gamma$ be a closed plane curve parametrized by $\gamma(t) = (x(t), y(t))$ on $[-\pi, \pi]$. Let $l$ denote the length of the curve and $d = \sup_{t_1, t_2 \in [-\pi, \pi]} |\gamma(t_1) - \gamma(t_2)|$. If $\Gamma$ is convex then $l\leq \pi d$.",,"['differential-geometry', 'fourier-analysis', 'convex-analysis']"
26,manifold diffeomorphic (?) to SO(3),manifold diffeomorphic (?) to SO(3),,"Consider the set of all pairs $(\boldsymbol{n},\boldsymbol{v})$ of vectors in $\mathbb{R}^3$ such that $\boldsymbol{n}$ is a vector on the unit sphere centered at the origin and $\boldsymbol{v}$ is a unit vector tangent to the sphere at the point $\boldsymbol{n}.$ i. Introduce a structure of smooth manifold on this set. ii. Prove that this manifold is diffeomorphic to the group $SO(3).$ To my understanding, this manifold is $S^2 \times S^1,$ which gives a parametrization of $SO(3),$ but it is far from being a diffeomorphism, i.e. the exercise is false: do you agree?","Consider the set of all pairs $(\boldsymbol{n},\boldsymbol{v})$ of vectors in $\mathbb{R}^3$ such that $\boldsymbol{n}$ is a vector on the unit sphere centered at the origin and $\boldsymbol{v}$ is a unit vector tangent to the sphere at the point $\boldsymbol{n}.$ i. Introduce a structure of smooth manifold on this set. ii. Prove that this manifold is diffeomorphic to the group $SO(3).$ To my understanding, this manifold is $S^2 \times S^1,$ which gives a parametrization of $SO(3),$ but it is far from being a diffeomorphism, i.e. the exercise is false: do you agree?",,"['differential-geometry', 'rotations']"
27,Curvature of a non-compact complete surface,Curvature of a non-compact complete surface,,"Assume $\Sigma$ is a non compact, complete surface. Assume the integral $$\int_{\Sigma}K$$ is convergent, where K is the Gauss curvature of $\Sigma$. Is it always true that $$\frac{1}{2\pi}\int_{\Sigma}K$$ is an integer?","Assume $\Sigma$ is a non compact, complete surface. Assume the integral $$\int_{\Sigma}K$$ is convergent, where K is the Gauss curvature of $\Sigma$. Is it always true that $$\frac{1}{2\pi}\int_{\Sigma}K$$ is an integer?",,"['differential-geometry', 'curvature']"
28,Extending a smooth map,Extending a smooth map,,"When can I extend a smooth map $f:\mathbb{R^2}-\lbrace 0 \rbrace \to S^1$ to a smooth map $\tilde{f}:\mathbb{R^2} \to S^1$.  For instance, consider $g(x,y)=(x,y)/\sqrt{x^2+y^2}$?  Am I able to extend that to a smooth map $g$?  My end goal is having the smooth map from $\mathbb{R^2}$ to $S^1$.  It can be any map, this is just how I am trying to do it. Thanks!","When can I extend a smooth map $f:\mathbb{R^2}-\lbrace 0 \rbrace \to S^1$ to a smooth map $\tilde{f}:\mathbb{R^2} \to S^1$.  For instance, consider $g(x,y)=(x,y)/\sqrt{x^2+y^2}$?  Am I able to extend that to a smooth map $g$?  My end goal is having the smooth map from $\mathbb{R^2}$ to $S^1$.  It can be any map, this is just how I am trying to do it. Thanks!",,"['differential-geometry', 'manifolds', 'differential-topology']"
29,geometrically finite hyperbolic surface of infinite volume,geometrically finite hyperbolic surface of infinite volume,,"I am starting to read some papers involving analysis on hyperbolic manifolds. In these the notion of a ""geometrically finite hyperbolic surface of infinite volume"" is mentioned frequently and I am struggeling to locate a precise definition for it (presumably because it is a relatively basic concept that one should know about). If someone could add some definition to the above words (or refer to an appropriate source where I could read up on this) that would be very helpful, many thanks !","I am starting to read some papers involving analysis on hyperbolic manifolds. In these the notion of a ""geometrically finite hyperbolic surface of infinite volume"" is mentioned frequently and I am struggeling to locate a precise definition for it (presumably because it is a relatively basic concept that one should know about). If someone could add some definition to the above words (or refer to an appropriate source where I could read up on this) that would be very helpful, many thanks !",,"['differential-geometry', 'manifolds', 'definition', 'hyperbolic-geometry']"
30,orbits are open in Manifold ? group action on manifold.,orbits are open in Manifold ? group action on manifold.,,"I need to show: for a differentiable manifold $M$, and $Aut(M)$ acts on $M$, orbit of a point $a\in M$ is open in $M$, please help.","I need to show: for a differentiable manifold $M$, and $Aut(M)$ acts on $M$, orbit of a point $a\in M$ is open in $M$, please help.",,"['differential-geometry', 'manifolds', 'differential-topology']"
31,SO(5)-invariant metrics on the 4-sphere,SO(5)-invariant metrics on the 4-sphere,,Are there any examples of Riemannian metrics on $S^{4} \subset \mathbb{R}^{5}$ that are not  SO(5)-invariant? Or are all  metrics on the 4-sphere SO(5)-invariant? Hope my question is not too trivial :). Dmitri,Are there any examples of Riemannian metrics on $S^{4} \subset \mathbb{R}^{5}$ that are not  SO(5)-invariant? Or are all  metrics on the 4-sphere SO(5)-invariant? Hope my question is not too trivial :). Dmitri,,"['differential-geometry', 'lie-groups', 'riemannian-geometry']"
32,Surface of a 2-sphere expressed as union of two closed disks,Surface of a 2-sphere expressed as union of two closed disks,,"I'm reading a First Course in Differential Geometry by Chuan-Chih Hsiung and on page 8 he says ""A closed disk that is homeomorphic to $I^2$ [i.e. $I\times I$, where $I = [a, b]$] is connected. The surface $S^2$ of a 2-sphere can be expressed as the union of two closed disks with nonempty intersection."" I'm not sure what he means by the second sentence. Am I supposed to imagine two disks being deformed into the two halves of the sphere (so the disks touch each other at their circumferences)? I don't understand what it means to express the spherical surface as a union of two disks.","I'm reading a First Course in Differential Geometry by Chuan-Chih Hsiung and on page 8 he says ""A closed disk that is homeomorphic to $I^2$ [i.e. $I\times I$, where $I = [a, b]$] is connected. The surface $S^2$ of a 2-sphere can be expressed as the union of two closed disks with nonempty intersection."" I'm not sure what he means by the second sentence. Am I supposed to imagine two disks being deformed into the two halves of the sphere (so the disks touch each other at their circumferences)? I don't understand what it means to express the spherical surface as a union of two disks.",,"['general-topology', 'differential-geometry']"
33,Any fiber bundle is in fact principal fiber bundle.,Any fiber bundle is in fact principal fiber bundle.,,I wonder whether or not ${\bf R}$ is a topological group. In fact ${\bf R}$ is a group with addition structure. So is it topological group ? In fact any ${\bf R}^n$ is a topological group. Note that any element in ${\bf R}^n$ is    mapped into diagonal matrics in $GL_n({\bf R})$ From this we conclude that any fiber bundle with ${\bf R}^n$-fiber is a principal fiber bundle. This implies that definition of any fiber bundle is equal to that of   the principal fiber bundle. Am I right  ?,I wonder whether or not ${\bf R}$ is a topological group. In fact ${\bf R}$ is a group with addition structure. So is it topological group ? In fact any ${\bf R}^n$ is a topological group. Note that any element in ${\bf R}^n$ is    mapped into diagonal matrics in $GL_n({\bf R})$ From this we conclude that any fiber bundle with ${\bf R}^n$-fiber is a principal fiber bundle. This implies that definition of any fiber bundle is equal to that of   the principal fiber bundle. Am I right  ?,,['differential-geometry']
34,Does diffeology provide moduli for classical constructions?,Does diffeology provide moduli for classical constructions?,,"Do classical constructions on differentiable manifolds like affine connections, Riemannian metrics, or (almost) complex structures have moduli spaces in category of diffeological spaces?","Do classical constructions on differentiable manifolds like affine connections, Riemannian metrics, or (almost) complex structures have moduli spaces in category of diffeological spaces?",,['differential-geometry']
35,The Riemannian metric on manifold with boundary,The Riemannian metric on manifold with boundary,,"$(M,g)$ is a Riemannian manifold with non-empty boundary and $DM$ is the double of $M$, is there a Riemannian metric $G$ on $DM$ such that $g=i^*G$? ($i$ is the inclusion from $M$ to $DM$)","$(M,g)$ is a Riemannian manifold with non-empty boundary and $DM$ is the double of $M$, is there a Riemannian metric $G$ on $DM$ such that $g=i^*G$? ($i$ is the inclusion from $M$ to $DM$)",,"['differential-geometry', 'riemannian-geometry']"
36,How can I prove that a curve with constant nonzero curvature and torsion is a helix? [duplicate],How can I prove that a curve with constant nonzero curvature and torsion is a helix? [duplicate],,"This question already has answers here : Curves with constant curvature and constant torsion (3 answers) Closed 8 years ago . I've gotten as far as $\mathbf{n''}+(\kappa^2+\tau^2)\mathbf{n} = 0$, which suggests or at least permits trigonometric expressions for every component of $\mathbf{n}$ -- not something that seems to lead to a standard expression for a helix. Am I just supposed to prove that a helix has constant nonzero curvature and torsion and invoke the fundamental theorem of curves? ETA: I was able to get further than the point I described, but the equation for the curve I came up with was... $$\big(c_1\cos{\sqrt{\kappa^2+\tau^2}t}+c_2\sin{\sqrt{\kappa^2+\tau^2}t+c_3t+c_4},c_5\cos{\sqrt{\kappa^2+\tau^2}t}+c_6\sin{\sqrt{\kappa^2+\tau^2}t+c_7t+c_8},c_9\cos{\sqrt{\kappa^2+\tau^2}t}+c_{10}\sin{\sqrt{\kappa^2+\tau^2}t+c_{11}t+c_{12}}\big)$$ ...and I have no idea how to prove that that's a helix, plus I suspect it isn't even right.","This question already has answers here : Curves with constant curvature and constant torsion (3 answers) Closed 8 years ago . I've gotten as far as $\mathbf{n''}+(\kappa^2+\tau^2)\mathbf{n} = 0$, which suggests or at least permits trigonometric expressions for every component of $\mathbf{n}$ -- not something that seems to lead to a standard expression for a helix. Am I just supposed to prove that a helix has constant nonzero curvature and torsion and invoke the fundamental theorem of curves? ETA: I was able to get further than the point I described, but the equation for the curve I came up with was... $$\big(c_1\cos{\sqrt{\kappa^2+\tau^2}t}+c_2\sin{\sqrt{\kappa^2+\tau^2}t+c_3t+c_4},c_5\cos{\sqrt{\kappa^2+\tau^2}t}+c_6\sin{\sqrt{\kappa^2+\tau^2}t+c_7t+c_8},c_9\cos{\sqrt{\kappa^2+\tau^2}t}+c_{10}\sin{\sqrt{\kappa^2+\tau^2}t+c_{11}t+c_{12}}\big)$$ ...and I have no idea how to prove that that's a helix, plus I suspect it isn't even right.",,['differential-geometry']
37,Definition of vector bundle,Definition of vector bundle,,"Everywhere i see definition of vector bundle  as  triple $(E, p, B)$, $B$ and $E$ are manifold   and local trivialization condition holds.  For example see the definition here. . Local trivialization gives manifold structure on $E$, then why initial assumption on $E$ that $E$ is manifold is necessary.","Everywhere i see definition of vector bundle  as  triple $(E, p, B)$, $B$ and $E$ are manifold   and local trivialization condition holds.  For example see the definition here. . Local trivialization gives manifold structure on $E$, then why initial assumption on $E$ that $E$ is manifold is necessary.",,"['algebraic-geometry', 'differential-geometry', 'complex-geometry']"
38,Sard's Theorem For Constant functions,Sard's Theorem For Constant functions,,"It states: Let $g:A \to R^n$ be continuously differentiable, where $A \subset R^n$ is open, and let $B=${${x \in A: \det g'(x)=0}$}.  Thne $g(B)$ has measure $0$. Okay....  obviously this theorem is right... but why don't constant functions violate this?  After all, the  derivative of a constant function is $0$ EVERYWHERE.... so that can't possibly be measure zero!","It states: Let $g:A \to R^n$ be continuously differentiable, where $A \subset R^n$ is open, and let $B=${${x \in A: \det g'(x)=0}$}.  Thne $g(B)$ has measure $0$. Okay....  obviously this theorem is right... but why don't constant functions violate this?  After all, the  derivative of a constant function is $0$ EVERYWHERE.... so that can't possibly be measure zero!",,['differential-geometry']
39,Question about integral curve on a manifold,Question about integral curve on a manifold,,"In Warner's book on page 36 a curve $\gamma:(a,b)\rightarrow M$ is  defined to be an integral curve iff $$d\gamma(\frac{d}{dr}|_t)=X(\gamma(t))$$ Could anyone explain to me the left side in detail and break it into coordinates? Here $X$ is a vector field on $M$. A curve $\sigma$ is an integral in $M$ if $\dot{\sigma(t)}=X(\sigma(t)) \forall t \in \text{domain of $\sigma$ }$.","In Warner's book on page 36 a curve $\gamma:(a,b)\rightarrow M$ is  defined to be an integral curve iff $$d\gamma(\frac{d}{dr}|_t)=X(\gamma(t))$$ Could anyone explain to me the left side in detail and break it into coordinates? Here $X$ is a vector field on $M$. A curve $\sigma$ is an integral in $M$ if $\dot{\sigma(t)}=X(\sigma(t)) \forall t \in \text{domain of $\sigma$ }$.",,['differential-geometry']
40,Second Bianchi identity,Second Bianchi identity,,"This is q. 7 of ch. 4 from Do Carmo's book on Riemannian Geometry . Prove that: $$ \nabla R(X,Y,Z,W,T) + \nabla R(X,Y,W,T,Z) + \nabla R(X,Y,T,Z,W)=0.$$ Let $\{e_i\}$ a geodesic frame  on $p$ , it is enough to prove that the identity for : $$ \nabla R(e_i,e_j,e_k,e_l,e_h) + \nabla R(e_i,e_j,e_l,e_h,e_k) + \nabla R(e_i,e_j,e_h,e_k,e_l)=0.$$ The author says that the left side expression is : $$ R(e_l,e_h,\nabla_{e_k} e_i,e_j) + R(e_h,e_k,\nabla_{e_l} e_i,e_j) +  R(e_k,e_l,\nabla_{e_h} e_i,e_j).$$ I'd like to know why this is indeed the case.(you can check that: $$\nabla R(e_i,e_j,e_k,e_l,e_h)=\langle \nabla_{e_h} \nabla_{e_l} \nabla_{e_k}e_i - \nabla_{e_h} \nabla_{e_k} \nabla_{e_l}e_i +\nabla_{e_h} \nabla_{[e_k,e_l]}e_i , e_j \rangle).$$","This is q. 7 of ch. 4 from Do Carmo's book on Riemannian Geometry . Prove that: $$ \nabla R(X,Y,Z,W,T) + \nabla R(X,Y,W,T,Z) + \nabla R(X,Y,T,Z,W)=0.$$ Let $\{e_i\}$ a geodesic frame  on $p$ , it is enough to prove that the identity for : $$ \nabla R(e_i,e_j,e_k,e_l,e_h) + \nabla R(e_i,e_j,e_l,e_h,e_k) + \nabla R(e_i,e_j,e_h,e_k,e_l)=0.$$ The author says that the left side expression is : $$ R(e_l,e_h,\nabla_{e_k} e_i,e_j) + R(e_h,e_k,\nabla_{e_l} e_i,e_j) +  R(e_k,e_l,\nabla_{e_h} e_i,e_j).$$ I'd like to know why this is indeed the case.(you can check that: $$\nabla R(e_i,e_j,e_k,e_l,e_h)=\langle \nabla_{e_h} \nabla_{e_l} \nabla_{e_k}e_i - \nabla_{e_h} \nabla_{e_k} \nabla_{e_l}e_i +\nabla_{e_h} \nabla_{[e_k,e_l]}e_i , e_j \rangle).$$",,"['differential-geometry', 'riemannian-geometry']"
41,Lie bracket and covariant derivatives,Lie bracket and covariant derivatives,,"I came across the following equality $[\text{grad} f, X] = \nabla_{\text{grad} f} X + \nabla_X \text{grad} f$ Is this true, and how can I prove this (without coordinates)?","I came across the following equality $[\text{grad} f, X] = \nabla_{\text{grad} f} X + \nabla_X \text{grad} f$ Is this true, and how can I prove this (without coordinates)?",,['differential-geometry']
42,Embedding a manifold in the disk,Embedding a manifold in the disk,,"I don't understand a sentence made by Hirsch in his Differential Topology at page 175: If $k > n+1$ and $M^n = \partial W^{n+1}$, then an embedding $M^n \hookrightarrow S^{n+k}$ extends to a neat embedding $W^{n+1} \hookrightarrow D^{n+k+1}$. ($D^{n+k+1}$ is the disk of dimension $n+k+1$, $S^{n+k}$ is the boundary of $D^{n+k+1}$, i.e. the sphere of dimension $n+k$,  $W$ is a compact manifold of dimension $n+1$ and $M$ is the boundary of $W$.) Could someone explain to me why this sentence is true? Thanks to all!","I don't understand a sentence made by Hirsch in his Differential Topology at page 175: If $k > n+1$ and $M^n = \partial W^{n+1}$, then an embedding $M^n \hookrightarrow S^{n+k}$ extends to a neat embedding $W^{n+1} \hookrightarrow D^{n+k+1}$. ($D^{n+k+1}$ is the disk of dimension $n+k+1$, $S^{n+k}$ is the boundary of $D^{n+k+1}$, i.e. the sphere of dimension $n+k$,  $W$ is a compact manifold of dimension $n+1$ and $M$ is the boundary of $W$.) Could someone explain to me why this sentence is true? Thanks to all!",,"['general-topology', 'algebraic-topology', 'differential-geometry', 'differential-topology', 'cobordism']"
43,Tractrix tangent segment (from Baby Do-Carmo),Tractrix tangent segment (from Baby Do-Carmo),,"I need some help with question 4 in section 1.3 in Baby Do-Carmo textbook in DG. The question asks: Let $\alpha(t):(0,\pi)\rightarrow R^2 $ be given by: $$ \alpha(t)= (\cos(t), \cos(t) +\log(\tan(t/2)) $$ its image is called the tractrix. Question b, asks to prove that the length of the segment of the tangent of the tractrix between the point of tangency and the y axis is constantly 1. Now the angle between $\alpha$ and the y axis is t. So basically if I were to use the sine theorem from trig, where $$\frac{S}{\sin(t)} = \frac{|\alpha(t)|}{\sin(\pi-(t+\angle \alpha(t) \alpha '(t)))}$$ Where S is the required line segment I am looking for. Now I am only left with calculating the angle between $\alpha(t)$ and $\alpha '(t)$, is this about right, or I am way off here? It's hell of a calculation if I am right (and it's really rare when I am). Thanks.","I need some help with question 4 in section 1.3 in Baby Do-Carmo textbook in DG. The question asks: Let $\alpha(t):(0,\pi)\rightarrow R^2 $ be given by: $$ \alpha(t)= (\cos(t), \cos(t) +\log(\tan(t/2)) $$ its image is called the tractrix. Question b, asks to prove that the length of the segment of the tangent of the tractrix between the point of tangency and the y axis is constantly 1. Now the angle between $\alpha$ and the y axis is t. So basically if I were to use the sine theorem from trig, where $$\frac{S}{\sin(t)} = \frac{|\alpha(t)|}{\sin(\pi-(t+\angle \alpha(t) \alpha '(t)))}$$ Where S is the required line segment I am looking for. Now I am only left with calculating the angle between $\alpha(t)$ and $\alpha '(t)$, is this about right, or I am way off here? It's hell of a calculation if I am right (and it's really rare when I am). Thanks.",,"['differential-geometry', 'plane-curves']"
44,"Is an Exterior Product the ""Opposite"" of an Inner Product","Is an Exterior Product the ""Opposite"" of an Inner Product",,"One is represented by a dot product, the other by a cross product. The ""inner product collapses two co-ordinate vectors into a scalar, the exterior product seems to expand them in a multilinear (manifold)? The inner product seldom has ""cancellation,"" the exterior product has a lot of cancellation (between the same differential forms). Are they just two opposite sides of the same coin? If not, why do they seem to be so ""parallel""?","One is represented by a dot product, the other by a cross product. The ""inner product collapses two co-ordinate vectors into a scalar, the exterior product seems to expand them in a multilinear (manifold)? The inner product seldom has ""cancellation,"" the exterior product has a lot of cancellation (between the same differential forms). Are they just two opposite sides of the same coin? If not, why do they seem to be so ""parallel""?",,['differential-geometry']
45,"Examples of compact, nonorientable n-manifolds","Examples of compact, nonorientable n-manifolds",,"Among the best-known examples of nonorientable, compact manifolds are projective spaces. However for these one has the fact that $\mathbb RP^n$ is orientable iff $n$ is odd, so that only ""half"" of them are nonorientable. This statement relies on the fact that the antipodal map $\alpha$ on $S^n$ is orientation-preserving iff $n$ is odd, and $\mathbb RP^n = S^n/\{id_{S^n}, \alpha\}$ is a quotient manifold. Now, since $S^n$ is precisely the orientation covering of $\mathbb R P^n$, and $\alpha$ is the nontrivial covering transformation on $S^n$, I wondered, whether one could generalise this to arbitrary compact, connected manifolds $M^n$ of dimension $n$. I.e. whether it is true that if $n$ is odd, the nontrivial covering transformation cannot be orientation reversing, which would mean that every such $M$ has to be orientable. I guess this cannot be true so generally, so I went looking for some counterexamples, but neither I myself nor google seems to find any. Would anyone here be able to help me out with an example, maybe? Thanks in advance, Sam","Among the best-known examples of nonorientable, compact manifolds are projective spaces. However for these one has the fact that $\mathbb RP^n$ is orientable iff $n$ is odd, so that only ""half"" of them are nonorientable. This statement relies on the fact that the antipodal map $\alpha$ on $S^n$ is orientation-preserving iff $n$ is odd, and $\mathbb RP^n = S^n/\{id_{S^n}, \alpha\}$ is a quotient manifold. Now, since $S^n$ is precisely the orientation covering of $\mathbb R P^n$, and $\alpha$ is the nontrivial covering transformation on $S^n$, I wondered, whether one could generalise this to arbitrary compact, connected manifolds $M^n$ of dimension $n$. I.e. whether it is true that if $n$ is odd, the nontrivial covering transformation cannot be orientation reversing, which would mean that every such $M$ has to be orientable. I guess this cannot be true so generally, so I went looking for some counterexamples, but neither I myself nor google seems to find any. Would anyone here be able to help me out with an example, maybe? Thanks in advance, Sam",,"['differential-geometry', 'differential-topology']"
46,Compact manifold/Morse theory,Compact manifold/Morse theory,,"I have a question concerning the proof of theorem 3.5 in Milnor's Morse Theory. This theorem states that if $f$ is a differentiable function on a Manifold M with no critical points, and if each $M^a = \{x\in M | f(x)\leq a \} $ is compact then $M$ has the homotopy type of a CW-complex with one cell of dimension $\lambda$ for each critical point of index $\lambda$ Basically the proof shows via induction and appealing to previous theorems that $M^a$ has the homotopy type of a CW complex satisfying the conclusion above. But then Milnor says ""If $M$ is compact this completes the proof"". I don't understand how this just follows directly? Is there some theorem involving Compact manifolds or CW complexes that I am missing?  Does $M^a$ have to be homotopic to $M$ for some $a$ if $M$ is compact?","I have a question concerning the proof of theorem 3.5 in Milnor's Morse Theory. This theorem states that if $f$ is a differentiable function on a Manifold M with no critical points, and if each $M^a = \{x\in M | f(x)\leq a \} $ is compact then $M$ has the homotopy type of a CW-complex with one cell of dimension $\lambda$ for each critical point of index $\lambda$ Basically the proof shows via induction and appealing to previous theorems that $M^a$ has the homotopy type of a CW complex satisfying the conclusion above. But then Milnor says ""If $M$ is compact this completes the proof"". I don't understand how this just follows directly? Is there some theorem involving Compact manifolds or CW complexes that I am missing?  Does $M^a$ have to be homotopic to $M$ for some $a$ if $M$ is compact?",,['differential-geometry']
47,The notion of orientation in vector spaces,The notion of orientation in vector spaces,,"Do Carmo's Curves and Surfaces book states that ""two ordered bases $e = \{e_i\}$ and $f = \{f_i\}$ , $i = 1,\ldots,n$ , of an $n$ -dimensional vector space $V$ have the same orientation if the matrix of change of basis has positive determinant."" This same concept of ""orientation"" is the subject of another question on stack, but I am concerned with a purer intuitive understanding. What is the idea behind assigning this notion of same orientation to this particular circumstance with positive determinant? What properties of a matrix with positive determinant motivate this definition?","Do Carmo's Curves and Surfaces book states that ""two ordered bases and , , of an -dimensional vector space have the same orientation if the matrix of change of basis has positive determinant."" This same concept of ""orientation"" is the subject of another question on stack, but I am concerned with a purer intuitive understanding. What is the idea behind assigning this notion of same orientation to this particular circumstance with positive determinant? What properties of a matrix with positive determinant motivate this definition?","e = \{e_i\} f = \{f_i\} i = 1,\ldots,n n V","['linear-algebra', 'differential-geometry', 'intuition', 'curves']"
48,"Why is $[X,Y]_{\mathfrak g} = -[X,Y]$?",Why is ?,"[X,Y]_{\mathfrak g} = -[X,Y]","Let $G$ be a Lie group that is a closed subgroup of the isometry group of a manifold $M$ . Identify each $X$ in the Lie algebra $\mathfrak g$ of $G$ with the vector field on $M$ that is generated by the one-parameter group of diffeomorphisms $\phi_t(y) = \exp(tX)y$ . Then Arthur Besse’s book “Einstein Manifolds” warns on p.182 that $$[X,Y]_{\mathfrak g} = -[X,Y],$$ where $[\cdot,\cdot]$ is the bracket of vector fields on $M$ and $[\cdot,\cdot]_{\mathfrak g}$ is the bracket on $\mathfrak g$ . Attempt: By the definition of the commutator on $M$ , $[X,Y]f$ , where $f$ is a function on $M$ , is $(XY - YX)f$ . The first term, $XY(f)(p)$ , equals $$\left.\frac{d}{dt}\right\vert_{t=0}(\exp tX)^*\left.\frac{d}{ds}\right\vert_{s=0}(\exp sY)^* f(p) = \left.\frac{d}{dt}\right\vert_{t=0}\left.\frac{d}{ds}\right\vert_{s=0}(\exp tX)^*(\exp sY)^*f(p) = \left.\frac{d}{dt}\right\vert_{t=0}\left.\frac{d}{ds}\right\vert_{s=0}(\exp tX)^*f((\exp sY)(p)) = \left.\frac{d}{dt}\right\vert_{t=0}\left.\frac{d}{ds}\right\vert_{s=0}f\big((\exp sY)((\exp tX)(p))\big) = \left.\frac{d}{dt}\right\vert_{t=0}\left.\frac{d}{ds}\right\vert_{s=0} f\left(\exp \left(sY + tX +\frac{st}{2}[Y,X]_{\mathfrak g} + \dots\right)p\right),$$ by the BCH formula. So far it looks promising that the result of these two derivatives combined with the $-YXf$ term should yield $[X,Y]f = [Y,X]_\mathfrak g f$ . Unfortunately, I’m unsure how to apply the chain rule correctly when taking these two derivatives. In my attempt, I got $XY(f)(p) = f’’(p)XpYp +f’(p)\left(\frac 12 [Y,X]_\mathfrak g + YXp\right).$ Note: Besse gives two references for this warning, but unfortunately, I couldn’t find them. The first is N.R. Wallach’s “Compact homogeneous Riemannian manifolds with strictly positive curvature” and the second is Kobayashi and Nomizu’s “Foundations of differentiable Geometry Vol. II” p.469 (this reference doesn’t even have this many pages).","Let be a Lie group that is a closed subgroup of the isometry group of a manifold . Identify each in the Lie algebra of with the vector field on that is generated by the one-parameter group of diffeomorphisms . Then Arthur Besse’s book “Einstein Manifolds” warns on p.182 that where is the bracket of vector fields on and is the bracket on . Attempt: By the definition of the commutator on , , where is a function on , is . The first term, , equals by the BCH formula. So far it looks promising that the result of these two derivatives combined with the term should yield . Unfortunately, I’m unsure how to apply the chain rule correctly when taking these two derivatives. In my attempt, I got Note: Besse gives two references for this warning, but unfortunately, I couldn’t find them. The first is N.R. Wallach’s “Compact homogeneous Riemannian manifolds with strictly positive curvature” and the second is Kobayashi and Nomizu’s “Foundations of differentiable Geometry Vol. II” p.469 (this reference doesn’t even have this many pages).","G M X \mathfrak g G M \phi_t(y) = \exp(tX)y [X,Y]_{\mathfrak g} = -[X,Y], [\cdot,\cdot] M [\cdot,\cdot]_{\mathfrak g} \mathfrak g M [X,Y]f f M (XY - YX)f XY(f)(p) \left.\frac{d}{dt}\right\vert_{t=0}(\exp tX)^*\left.\frac{d}{ds}\right\vert_{s=0}(\exp sY)^* f(p) = \left.\frac{d}{dt}\right\vert_{t=0}\left.\frac{d}{ds}\right\vert_{s=0}(\exp tX)^*(\exp sY)^*f(p) = \left.\frac{d}{dt}\right\vert_{t=0}\left.\frac{d}{ds}\right\vert_{s=0}(\exp tX)^*f((\exp sY)(p)) = \left.\frac{d}{dt}\right\vert_{t=0}\left.\frac{d}{ds}\right\vert_{s=0}f\big((\exp sY)((\exp tX)(p))\big) = \left.\frac{d}{dt}\right\vert_{t=0}\left.\frac{d}{ds}\right\vert_{s=0} f\left(\exp \left(sY + tX +\frac{st}{2}[Y,X]_{\mathfrak g} + \dots\right)p\right), -YXf [X,Y]f = [Y,X]_\mathfrak g f XY(f)(p) = f’’(p)XpYp +f’(p)\left(\frac 12 [Y,X]_\mathfrak g + YXp\right).","['differential-geometry', 'lie-algebras']"
49,Exterior derivative for non-alternating forms,Exterior derivative for non-alternating forms,,"Given a manifold $M$ , a differential $k$ -form $\omega$ assigns to each point $p$ $\epsilon$ $M$ a $k$ -covector $\omega_p$ $\epsilon$ $\bigwedge^k \left(T_p^*M\right)$ , where $\bigwedge^k \left(T_p^*M\right)$ is the space of alternating $k$ -tensors on the tangent space $T_pM$ . If $\omega = \sum f_i dx^i$ denotes a 1-form of $M$ , then the exterior derivative $d:\bigwedge^k \left(T_p^*M\right) \rightarrow \bigwedge^{k+1} \left(T_p^*M\right)$ acts on $\omega$ to give a 2-form: $dw = \sum \frac{\partial f_i}{\partial x^j} dx^j \wedge dx^i$ . I wonder if there is an analogous construction of ""symmetric"" $k$ -forms. By a symmetric $k$ -form I mean a map $\sigma$ that assigns to each point $p$ $\epsilon$ $M$ a $k$ -covector $\sigma_p$ that is a symmetric $k$ -tensor of the tangent space $T_pM$ . If $\sigma = \sum g_i dx^i$ , maybe the exterior derivative of this symmetric 1-form could be $d\sigma = \frac{\partial g_i}{\partial x^j} dx^j \vee dx^i$ , where $dx^j \vee dx^i$ could be analogous to the wedge product with the property $dx^j \vee dx^i = dx^i \vee dx^j$ . Do you have any idea if such a construction exists? Also, could there be an analogous to the de Rham complex?","Given a manifold , a differential -form assigns to each point a -covector , where is the space of alternating -tensors on the tangent space . If denotes a 1-form of , then the exterior derivative acts on to give a 2-form: . I wonder if there is an analogous construction of ""symmetric"" -forms. By a symmetric -form I mean a map that assigns to each point a -covector that is a symmetric -tensor of the tangent space . If , maybe the exterior derivative of this symmetric 1-form could be , where could be analogous to the wedge product with the property . Do you have any idea if such a construction exists? Also, could there be an analogous to the de Rham complex?",M k \omega p \epsilon M k \omega_p \epsilon \bigwedge^k \left(T_p^*M\right) \bigwedge^k \left(T_p^*M\right) k T_pM \omega = \sum f_i dx^i M d:\bigwedge^k \left(T_p^*M\right) \rightarrow \bigwedge^{k+1} \left(T_p^*M\right) \omega dw = \sum \frac{\partial f_i}{\partial x^j} dx^j \wedge dx^i k k \sigma p \epsilon M k \sigma_p k T_pM \sigma = \sum g_i dx^i d\sigma = \frac{\partial g_i}{\partial x^j} dx^j \vee dx^i dx^j \vee dx^i dx^j \vee dx^i = dx^i \vee dx^j,"['differential-geometry', 'algebraic-topology', 'manifolds']"
50,Covariant derivative/connection of a local frame $\nabla \bar e = \nabla(e)g + edg$,Covariant derivative/connection of a local frame,\nabla \bar e = \nabla(e)g + edg,"Suppose $e$ and $\bar e$ are two frames for a vector bundle $E \to M$ over $U \subset M$ such that $\bar e = eg$ for some $g: U \to \text{GL}(r,\Bbb R)$ . Then $$\nabla \bar e = \nabla(e)g + edg.$$ I'm trying to understand this which is seemingly just the Leibniz rule, but I have some trouble with the definitions. A frame $e = (e_1,\dots,e_r)$ is an $r$ -tuple of sections $e_i : U \to E$ such that $e(p)=(e_1(p),\dots,e_r(p))$ forms a basis for $E_{p}$ . There are some slight ambiguities here, first off is $e$ a map $e : U \to E$ also? I mean it has to be since otherwise $\nabla e$ would not make sense.  Second, could someone help me understand how the above equation is the Leibniz rule? In general for a connection $\nabla$ on a vector bundle the Leibniz rule gives $$\nabla (fs)=df \otimes s + f\nabla s$$ where $s$ is a section $M \to E$ , but $f :M \to \Bbb R$ is a smooth function not a map with codomain $\text{GL}(r,\Bbb R)$ so what gives?","Suppose and are two frames for a vector bundle over such that for some . Then I'm trying to understand this which is seemingly just the Leibniz rule, but I have some trouble with the definitions. A frame is an -tuple of sections such that forms a basis for . There are some slight ambiguities here, first off is a map also? I mean it has to be since otherwise would not make sense.  Second, could someone help me understand how the above equation is the Leibniz rule? In general for a connection on a vector bundle the Leibniz rule gives where is a section , but is a smooth function not a map with codomain so what gives?","e \bar e E \to M U \subset M \bar e = eg g: U \to \text{GL}(r,\Bbb R) \nabla \bar e = \nabla(e)g + edg. e = (e_1,\dots,e_r) r e_i : U \to E e(p)=(e_1(p),\dots,e_r(p)) E_{p} e e : U \to E \nabla e \nabla \nabla (fs)=df \otimes s + f\nabla s s M \to E f :M \to \Bbb R \text{GL}(r,\Bbb R)",['differential-geometry']
51,When Is it possible to define a ''Integral surface''?,When Is it possible to define a ''Integral surface''?,,"An integral curve $c(t)$ of a vector field $V$ on a manifold $M$ is defined as the solution of $\frac{dc(t)}{t}=V(c(t))$ , here we require that $t\in \mathbb{R}$ . Is it possible to define an integral surface $s$ of two vector fields $V_1,V_2$ ,  i.e.  a map $\mathbb{R}^2 \supset \Delta \longrightarrow M$ , $t=(t_1,t_2)\mapsto s(t_1,t_2)$ , such that $\frac{\partial s}{\partial t_1}=V_1(s)$ and $\frac{\partial s}{\partial t_2}=V_2(s)$ ? I tried to define $s(t_1,t_2)$ by firstly fixing $t_2$ ,  we go from the initial point $p=s(0,0)$ through the integral curve of $V_1$ for time $t_1$ , the $s(t_1,0)$ is defined as the point where we are now, then fix $t_1$ and go through the integral curve of $V_2$ for time $t_2$ and define $s(t_1,t_2)$ as the point where we are now. But I know this is wrong since if we instead go through integral curve of $V_2$ first, we will get another point if the Lie bracket $[V_1,V_2]\neq 0$ . So when is this system of PDE ( $\frac{\partial s}{\partial t_1}=V_1(s)$ , $\frac{\partial s}{\partial t_2}=V_2(s)$ ) solvable, is it solvable only if $[V_1,V_2]=0$ ? I don't much knowledge in PDE theory so I apologize if this question is too naive.","An integral curve of a vector field on a manifold is defined as the solution of , here we require that . Is it possible to define an integral surface of two vector fields ,  i.e.  a map , , such that and ? I tried to define by firstly fixing ,  we go from the initial point through the integral curve of for time , the is defined as the point where we are now, then fix and go through the integral curve of for time and define as the point where we are now. But I know this is wrong since if we instead go through integral curve of first, we will get another point if the Lie bracket . So when is this system of PDE ( , ) solvable, is it solvable only if ? I don't much knowledge in PDE theory so I apologize if this question is too naive.","c(t) V M \frac{dc(t)}{t}=V(c(t)) t\in \mathbb{R} s V_1,V_2 \mathbb{R}^2 \supset \Delta \longrightarrow M t=(t_1,t_2)\mapsto s(t_1,t_2) \frac{\partial s}{\partial t_1}=V_1(s) \frac{\partial s}{\partial t_2}=V_2(s) s(t_1,t_2) t_2 p=s(0,0) V_1 t_1 s(t_1,0) t_1 V_2 t_2 s(t_1,t_2) V_2 [V_1,V_2]\neq 0 \frac{\partial s}{\partial t_1}=V_1(s) \frac{\partial s}{\partial t_2}=V_2(s) [V_1,V_2]=0","['differential-geometry', 'partial-differential-equations']"
52,When wedge power of a vector nulls,When wedge power of a vector nulls,,"Let $l$ be even and $v \in \bigwedge^\ell \mathbb{C}^{\ell n}$ . What conditions on vector $v$ imply $v^{\wedge n} \neq 0$ ? Note, that for $\ell = 2$ the criteria is that $v$ must be non-degenerate (skew-symmetric bilinear form). Is there any reference of idea how one can approach at least the implication ""condition on $v$ $\implies$ $v^{\wedge n}$ not nulls""?","Let be even and . What conditions on vector imply ? Note, that for the criteria is that must be non-degenerate (skew-symmetric bilinear form). Is there any reference of idea how one can approach at least the implication ""condition on not nulls""?",l v \in \bigwedge^\ell \mathbb{C}^{\ell n} v v^{\wedge n} \neq 0 \ell = 2 v v \implies v^{\wedge n},"['linear-algebra', 'differential-geometry', 'complex-geometry', 'differential-forms', 'exterior-algebra']"
53,Criterion for deducing connectedness of level set of a smooth map,Criterion for deducing connectedness of level set of a smooth map,,"Suppose that $U\subset \mathbb R^n$ is open and suppose that $f: U\to \mathbb R$ is smooth. Define $M_c= f^{-1}(c)$ . The question is: is $M_c$ connected? Here is an example where $M_c$ is connected for a particular $c$ but not connected for some other values of $c$ : $n=2, f(x,y)= x^2-y^2$ . In this case, $M_0=$ pair of straight lines passing through the origin and therefore $M_0$ is connected. But $M_1=\{(x,y): x^2-y^2=1\}$ is not connected. It suggests that there should be some restriction on $c$ but I’m not sure how to generalise this. Any suggestions on this are welcome. Thanks for your time.","Suppose that is open and suppose that is smooth. Define . The question is: is connected? Here is an example where is connected for a particular but not connected for some other values of : . In this case, pair of straight lines passing through the origin and therefore is connected. But is not connected. It suggests that there should be some restriction on but I’m not sure how to generalise this. Any suggestions on this are welcome. Thanks for your time.","U\subset \mathbb R^n f: U\to \mathbb R M_c= f^{-1}(c) M_c M_c c c n=2, f(x,y)= x^2-y^2 M_0= M_0 M_1=\{(x,y): x^2-y^2=1\} c","['general-topology', 'differential-geometry']"
54,Affine connection on non smooth vector fields,Affine connection on non smooth vector fields,,"The usual definition of an affine connection $\nabla_X Y$ requires $X,Y$ to be smooth vector fields on the ambiant differential manifold $M$ , i.e. $C^\infty$ . However at any point $p\in M$ , $(\nabla_X Y)_p$ means the differential of $Y$ at $p$ in the direction $X_p$ . So it seems enough that $Y$ is just differentiable, and we don't need any hypothesis on $X$ , not even continuity. Likewise, geodesics are required to be smooth curves, but their definition $\nabla_{\dot{\gamma}}\dot{\gamma}=0$ suggests that they are only $C^2$ (their acceleration is zero). And regarding the parallel transport of a tangent vector $u\in T_p M$ along a curve $\gamma$ , it seems that $\gamma$ just has to be piecewise differentiable : compose the parallel transports on each segment where $\gamma$ is differentiable. The speed $\dot{\gamma}$ does not need to exist at the junction points. Are there generalized definitions of connections for these non smooth cases ?","The usual definition of an affine connection requires to be smooth vector fields on the ambiant differential manifold , i.e. . However at any point , means the differential of at in the direction . So it seems enough that is just differentiable, and we don't need any hypothesis on , not even continuity. Likewise, geodesics are required to be smooth curves, but their definition suggests that they are only (their acceleration is zero). And regarding the parallel transport of a tangent vector along a curve , it seems that just has to be piecewise differentiable : compose the parallel transports on each segment where is differentiable. The speed does not need to exist at the junction points. Are there generalized definitions of connections for these non smooth cases ?","\nabla_X Y X,Y M C^\infty p\in M (\nabla_X Y)_p Y p X_p Y X \nabla_{\dot{\gamma}}\dot{\gamma}=0 C^2 u\in T_p M \gamma \gamma \gamma \dot{\gamma}","['differential-geometry', 'vector-fields', 'connections']"
55,Index Notation - An Inconsistency with a deeper meaning?,Index Notation - An Inconsistency with a deeper meaning?,,"Background Suppose we have a linear transformation $T : V \to W$ where $V$ and $W$ are finite dimensional vector spaces with bases $(e_i)$ and $(f_i)$ respectively. Using index notation, it is tempting to define the components of $T$ with respect to the bases $(e_i)$ and $(f_i)$ as $$ T(e_i) = {T_i}^j f_j $$ If we carry out the application of $T$ to $v = v^i e_i$ , we obtain $$ T(v) = T(v^i e_i) = v^i T(e_i) = v^i {T_i}^j f_j $$ So far so good. All the indices are matching up nicely. But consider the composition with $S : W \to U$ where $U$ has basis $(g_i)$ . We have $$ (S \circ T)(v) = S(v^i {T_i}^j f_j) = v^i {T_i}^j S(f_j) = v^i {T_i}^j {S_j}^k g_k $$ from which we conclude $$ {(S \circ T)_i}^k = {T_i}^j {S_j}^k $$ Oh no! It looks like passing to components is a contravariant functor. Not a disaster, but certainly unexpected. This is ""unexpected"" because this is not the usual way to define the components of a linear transformation with respect to a basis. Usually, one defines $$ T(e_i) = {T^j}_i f_j $$ Defined in this usual way, passing to components is a covariant functor, but we had to write down the somewhat ugly and less obvious expression ${T^j}_i f_j$ . I call this ugly because the $i$ is between the two $j$ 's with this convention. We can make this look a little less ugly if we agree to write basis elements to the left, i.e. $T(e_i) = f_j {T^j}_i$ . That looks a bit better, but it certainly isn't the usual convention (I've seen it in one textbook: ""The Geometry of Physics"" by Frankel). This convention also runs into problems when we want to think of vectors as differential operators, since $e_i v^i f$ looks like it should mean $e_i (v^i f)$ , but it actually means $v^i (e_i f)$ . It seems like no matter what we do, we have to deal with some ugliness in how we define passing to components with index notation. Question Is there significance to the fact that the most ""obvious"" (I suppose a matter of opinion) way to write down the indices for a linear transformation makes passing to components a contravariant functor? Or maybe more to the point: is there significance to the fact that no matter what we do we have to deal with some ugliness / non-obviousness in how we pass to index notation, especially when we want to start thinking of vectors as differential operators? I've run into this sort of thing before and concluded that the problem comes about because we apply functions to the left and not the right (this is, for example, why we have to read commutative diagrams ""backward"" when writing down the identities they imply). But it seems like there's a deeper problem here. Apologies if this is an extremely pedantic question, but it's something that's been nagging me for some time now. Hopefully the question is clear enough.","Background Suppose we have a linear transformation where and are finite dimensional vector spaces with bases and respectively. Using index notation, it is tempting to define the components of with respect to the bases and as If we carry out the application of to , we obtain So far so good. All the indices are matching up nicely. But consider the composition with where has basis . We have from which we conclude Oh no! It looks like passing to components is a contravariant functor. Not a disaster, but certainly unexpected. This is ""unexpected"" because this is not the usual way to define the components of a linear transformation with respect to a basis. Usually, one defines Defined in this usual way, passing to components is a covariant functor, but we had to write down the somewhat ugly and less obvious expression . I call this ugly because the is between the two 's with this convention. We can make this look a little less ugly if we agree to write basis elements to the left, i.e. . That looks a bit better, but it certainly isn't the usual convention (I've seen it in one textbook: ""The Geometry of Physics"" by Frankel). This convention also runs into problems when we want to think of vectors as differential operators, since looks like it should mean , but it actually means . It seems like no matter what we do, we have to deal with some ugliness in how we define passing to components with index notation. Question Is there significance to the fact that the most ""obvious"" (I suppose a matter of opinion) way to write down the indices for a linear transformation makes passing to components a contravariant functor? Or maybe more to the point: is there significance to the fact that no matter what we do we have to deal with some ugliness / non-obviousness in how we pass to index notation, especially when we want to start thinking of vectors as differential operators? I've run into this sort of thing before and concluded that the problem comes about because we apply functions to the left and not the right (this is, for example, why we have to read commutative diagrams ""backward"" when writing down the identities they imply). But it seems like there's a deeper problem here. Apologies if this is an extremely pedantic question, but it's something that's been nagging me for some time now. Hopefully the question is clear enough.","T : V \to W V W (e_i) (f_i) T (e_i) (f_i) 
T(e_i) = {T_i}^j f_j
 T v = v^i e_i 
T(v) = T(v^i e_i) = v^i T(e_i) = v^i {T_i}^j f_j
 S : W \to U U (g_i) 
(S \circ T)(v) = S(v^i {T_i}^j f_j) = v^i {T_i}^j S(f_j) = v^i {T_i}^j {S_j}^k g_k
 
{(S \circ T)_i}^k = {T_i}^j {S_j}^k
 
T(e_i) = {T^j}_i f_j
 {T^j}_i f_j i j T(e_i) = f_j {T^j}_i e_i v^i f e_i (v^i f) v^i (e_i f)","['linear-algebra', 'differential-geometry', 'vector-spaces', 'index-notation']"
56,Is their any relation between stiefel-whitney class and obstruction to lift SO(3) to SU(2)?,Is their any relation between stiefel-whitney class and obstruction to lift SO(3) to SU(2)?,,"I found a paper by kirby and taylor https://www.maths.ed.ac.uk/~v1ranick/papers/kirbytaylorpin.pdf . It is said that the obstruction to lift O(n) bundle to $pin(n)_-$ bundle is some stiefel-whitney class. So, is there any similar conclusion for lift SO(n) to spin(n).","I found a paper by kirby and taylor https://www.maths.ed.ac.uk/~v1ranick/papers/kirbytaylorpin.pdf . It is said that the obstruction to lift O(n) bundle to bundle is some stiefel-whitney class. So, is there any similar conclusion for lift SO(n) to spin(n).",pin(n)_-,"['differential-geometry', 'algebraic-topology']"
57,Basis for the cotangent space $T^\ast_p M$ and the maps $dx^i$,Basis for the cotangent space  and the maps,T^\ast_p M dx^i,"Let $M$ be a manifold and $p \in M$ , then we have the tangent space $T_pM$ that has a basis $\left\{ \left(\frac{\partial}{\partial x^i}\right)_p \right \}$ . The cotangent space $T^\ast_p M$ has then a basis $\{ (dx^i)_p \}$ . I'm trying to figure out why the cotangent space has the proposed base. If $V$ is a finite dimensional vector space with base $\{e_1, \dots e_n \}$ , then $V^\ast$ has a basis $\{f^1, \dots f^n \}$ , where $f^i : V \to \Bbb R$ and $f^i(e_j) = \delta_i^j$ . In the cotangent space case $\{ (dx^i)_p \}$ would be a basis if $$(dx^i)_p\left(\frac{\partial}{\partial x^j}\right)_p = \delta_i^j.$$ Now $(dx^i)_p : T^\ast_p M \to \Bbb R$ is just any linear map so how can I know anything about $(dx^i)_p\left(\frac{\partial}{\partial x^j}\right)_p$ without defining what $(dx^i)_p$ does first? I'm told that $dx^i$ is ""just a notation"", but it should apparently be defined to be something in order for this to work out?","Let be a manifold and , then we have the tangent space that has a basis . The cotangent space has then a basis . I'm trying to figure out why the cotangent space has the proposed base. If is a finite dimensional vector space with base , then has a basis , where and . In the cotangent space case would be a basis if Now is just any linear map so how can I know anything about without defining what does first? I'm told that is ""just a notation"", but it should apparently be defined to be something in order for this to work out?","M p \in M T_pM \left\{ \left(\frac{\partial}{\partial x^i}\right)_p \right \} T^\ast_p M \{ (dx^i)_p \} V \{e_1, \dots e_n \} V^\ast \{f^1, \dots f^n \} f^i : V \to \Bbb R f^i(e_j) = \delta_i^j \{ (dx^i)_p \} (dx^i)_p\left(\frac{\partial}{\partial x^j}\right)_p = \delta_i^j. (dx^i)_p : T^\ast_p M \to \Bbb R (dx^i)_p\left(\frac{\partial}{\partial x^j}\right)_p (dx^i)_p dx^i",['differential-geometry']
58,No Nash-Kuiper theorem for $\mathcal C^2$ isometries,No Nash-Kuiper theorem for  isometries,\mathcal C^2,"Reading about the Nash-Kuiper theorem, I found the following statement in Y. Eliashberg and N. Mishachev's book Introduction to the $h$ -Principle : Is there a regular homotopy $f_t:S^2\rightarrow\mathbb R^3$ which begins with the inclusion $f_0$ of the unit sphere and ends with an isometric immersion $f_1$ into the ball of radius $\frac{1}{2}$ ? Here the word 'isometric' means preserving length of all curves . The answer is, of course, negative if $f_1$ is required to be $\mathcal C^2$ -smooth. Indeed, in this case the Gaussian curvature of the metric on $S^2$ should be at least $\geq 4$ somewhere. I am puzzled about the last affirmation. More precisely, suppose we have a regular surface immersed inside a ball of radius $1/2$ . Why should its Gaussian curvature be at least 4 at some point? This is intuitively clear, but I am not familiar with results about isometric immersions, so I don't know how one should stablish such a conclusion.","Reading about the Nash-Kuiper theorem, I found the following statement in Y. Eliashberg and N. Mishachev's book Introduction to the -Principle : Is there a regular homotopy which begins with the inclusion of the unit sphere and ends with an isometric immersion into the ball of radius ? Here the word 'isometric' means preserving length of all curves . The answer is, of course, negative if is required to be -smooth. Indeed, in this case the Gaussian curvature of the metric on should be at least somewhere. I am puzzled about the last affirmation. More precisely, suppose we have a regular surface immersed inside a ball of radius . Why should its Gaussian curvature be at least 4 at some point? This is intuitively clear, but I am not familiar with results about isometric immersions, so I don't know how one should stablish such a conclusion.",h f_t:S^2\rightarrow\mathbb R^3 f_0 f_1 \frac{1}{2} f_1 \mathcal C^2 S^2 \geq 4 1/2,"['differential-geometry', 'riemannian-geometry', 'surfaces', 'riemann-surfaces', 'curvature']"
59,Levi-Civita connection acting on tensor density,Levi-Civita connection acting on tensor density,,"Consider an arbitrary $d$ -dimensional (pseudo)-Riemannian manifold $(\mathcal{M},g)$ with Levi-Civita connection and some covariant $2$ -tensor density $T$ . More precisely, we consider $T$ to be given by $$T=T^{\prime}\otimes\mathrm{vol}_{g}\in\Gamma^{\infty}(T^{\ast}\mathcal{M}^{\otimes 2}\otimes{\bigwedge}^{d}T^{\ast}\mathcal{M})\cong\Gamma^{\infty}(T^{\ast}\mathcal{M}^{\otimes 2})\otimes_{C^{\infty}(\mathcal{M})}\Omega^{d}(\mathcal{M}),$$ where $\mathrm{vol}_{g}$ denotes the volume $d$ -form of $(\mathcal{M},g)$ and $\Omega^{d}(\mathcal{M})$ denotes the space of top-degree differential forms on $\mathcal{M}$ . In other words, we consider a density $T$ with tensor part $T^{\prime}$ and density part $\mathrm{vol}_{g}$ . Now, I try to figure out what $\nabla_{X}T$ is for some vector field $X$ . Using the Leibniz rule, this can be written as $$\nabla_{X}T=(\nabla_{X}T^{\prime})\otimes\mathrm{vol}_{g}+T^{\prime}\otimes\nabla_{X}\mathrm{vol}_{g}.$$ Maybe its trivial, but is there are general way to compute $\nabla_{X}\mathrm{vol}_{g}$ ? By definition of the Levi-Civita connection, $\nabla g=0$ . Does this imply $\nabla_{X}\mathrm{vol}_{g}=0$ ? I am not sure, since there is the square root of $g$ appearing ing $\mathrm{vol}_{g}$ ...","Consider an arbitrary -dimensional (pseudo)-Riemannian manifold with Levi-Civita connection and some covariant -tensor density . More precisely, we consider to be given by where denotes the volume -form of and denotes the space of top-degree differential forms on . In other words, we consider a density with tensor part and density part . Now, I try to figure out what is for some vector field . Using the Leibniz rule, this can be written as Maybe its trivial, but is there are general way to compute ? By definition of the Levi-Civita connection, . Does this imply ? I am not sure, since there is the square root of appearing ing ...","d (\mathcal{M},g) 2 T T T=T^{\prime}\otimes\mathrm{vol}_{g}\in\Gamma^{\infty}(T^{\ast}\mathcal{M}^{\otimes 2}\otimes{\bigwedge}^{d}T^{\ast}\mathcal{M})\cong\Gamma^{\infty}(T^{\ast}\mathcal{M}^{\otimes 2})\otimes_{C^{\infty}(\mathcal{M})}\Omega^{d}(\mathcal{M}), \mathrm{vol}_{g} d (\mathcal{M},g) \Omega^{d}(\mathcal{M}) \mathcal{M} T T^{\prime} \mathrm{vol}_{g} \nabla_{X}T X \nabla_{X}T=(\nabla_{X}T^{\prime})\otimes\mathrm{vol}_{g}+T^{\prime}\otimes\nabla_{X}\mathrm{vol}_{g}. \nabla_{X}\mathrm{vol}_{g} \nabla g=0 \nabla_{X}\mathrm{vol}_{g}=0 g \mathrm{vol}_{g}","['differential-geometry', 'riemannian-geometry', 'tensors', 'differential-forms', 'connections']"
60,Express the Induced Curvature Forms on the Pullback Bundle through the connection forms,Express the Induced Curvature Forms on the Pullback Bundle through the connection forms,,"This question came up while reading Differential Geometry by Loring W.Tu. Suppose $\pi: E \to M$ is a $\mathcal{C}^{\infty}$ vector bundle. And $f:N \to M$ a $\mathcal{C}^{\infty}$ map of manifolds. Let $\nabla$ be a connection on $E$ with connection matrix $\omega_e$ relative to a local frame $e$ for $E$ . Then there is a unique connection $\nabla'$ on the pullback bundle $f^{*}E \to N$ whose connection matrix relative to the frame $f^{*}e$ is $f^{*}(\omega_e)$ . That makes sense so far. The author then writes: The induced curvature form on $f^{*}E$ is therefore $f^{*} \Omega_e = f^{*} \omega_e + \frac{1}{2} [f^{*} \omega_e, f^{*} \omega_e]$ . Now I don't understand why the induced curvature forms are $f^{*} \Omega_e$ or why this formula holds.",This question came up while reading Differential Geometry by Loring W.Tu. Suppose is a vector bundle. And a map of manifolds. Let be a connection on with connection matrix relative to a local frame for . Then there is a unique connection on the pullback bundle whose connection matrix relative to the frame is . That makes sense so far. The author then writes: The induced curvature form on is therefore . Now I don't understand why the induced curvature forms are or why this formula holds.,"\pi: E \to M \mathcal{C}^{\infty} f:N \to M \mathcal{C}^{\infty} \nabla E \omega_e e E \nabla' f^{*}E \to N f^{*}e f^{*}(\omega_e) f^{*}E f^{*} \Omega_e = f^{*} \omega_e + \frac{1}{2} [f^{*} \omega_e, f^{*} \omega_e] f^{*} \Omega_e","['differential-geometry', 'riemannian-geometry', 'curvature', 'connections', 'pullback']"
61,How to use chain rule in this equation?,How to use chain rule in this equation?,,"Source: Prof. Meinrenken's notes on Differential Geometry, page No 72: Theorem $4.1$ . let $(U,\varphi)$ be  a  coordinate  chart  around $p$ .A linear map $v :C^{\infty}(M) \to \mathbb{R}$ is in $T_pM$ if and  only  if it  has  the  form $$v(f)=\sum_{i=1}^{m} a^i\frac{\partial(f \circ \varphi^{-1})}{\partial u^i}|_{u=\varphi(p)}$$ for some $a=(a^1,.....,a^m)\in \mathbb{R}^m$ Proof : Given a linear  map v of this form.Let $\bar{\gamma}: \mathbb{R} \to \varphi(U)$ be  a curve  with $\bar\gamma(t)=\varphi(p) +ta $ for $|t|$ suffiently  small .Let $\gamma = \varphi^{-1} \circ \bar\gamma$ .Then $$\frac{d}{dt}|_{t=0} f(\gamma(t))=\frac{d}{dt}|_{t=0}(f\circ \varphi^{-1})(\varphi(p) +ta)=\sum_{i=1}^{m} a^i\frac{\partial(f \circ \varphi^{-1})}{\partial u^i}|_{u=\varphi(p)} $$ by chain rule My confusion :How to use   chain rule  in this equation why $$\frac{d}{dt}|_{t=0}(f\circ \varphi^{-1})(\varphi(p) +ta)=\sum_{i=1}^{m} a^i\frac{\partial(f \circ \varphi^{-1})}{\partial u^i}|_{u=\varphi(p)} ?$$ I know  that chain rule mean $$\frac{\partial (f \circ F)}{\partial x^i} =\sum_{j=1}^m\frac{\partial f}{\partial y^j}\frac{\partial F^j}{\partial x^i}.$$ where $f:V\to\Bbb R$ on an open set $V\subseteq\Bbb R^m$ , with its partial derivative with respect to the $j$ -th coordinate denoted $\frac{\partial f}{\partial y^j}$ . and $F:U\to V$ on an open set $U\subseteq\Bbb R^n$ , with its $j$ -th component function's partial derivative with respect to the $i$ -th coordinate denoted $\frac{\partial F^j}{\partial x^i}$ . My attempt: $$\frac{d}{dt}|_{t=0}(f\circ \varphi^{-1})(\varphi(p) +ta)=\frac{d}{dt}|_{t=0}((f\circ \varphi^{-1})(\varphi(p))  + (f\circ \varphi^{-1})ta)=\frac{d}{dt}|_{t=0}((f(p))  + (f\circ \varphi^{-1})ta) $$ After  that Im not able to proceed further","Source: Prof. Meinrenken's notes on Differential Geometry, page No 72: Theorem . let be  a  coordinate  chart  around .A linear map is in if and  only  if it  has  the  form for some Proof : Given a linear  map v of this form.Let be  a curve  with for suffiently  small .Let .Then by chain rule My confusion :How to use   chain rule  in this equation why I know  that chain rule mean where on an open set , with its partial derivative with respect to the -th coordinate denoted . and on an open set , with its -th component function's partial derivative with respect to the -th coordinate denoted . My attempt: After  that Im not able to proceed further","4.1 (U,\varphi) p v :C^{\infty}(M) \to \mathbb{R} T_pM v(f)=\sum_{i=1}^{m} a^i\frac{\partial(f \circ \varphi^{-1})}{\partial u^i}|_{u=\varphi(p)} a=(a^1,.....,a^m)\in \mathbb{R}^m \bar{\gamma}: \mathbb{R} \to \varphi(U) \bar\gamma(t)=\varphi(p) +ta  |t| \gamma = \varphi^{-1} \circ \bar\gamma \frac{d}{dt}|_{t=0} f(\gamma(t))=\frac{d}{dt}|_{t=0}(f\circ \varphi^{-1})(\varphi(p) +ta)=\sum_{i=1}^{m} a^i\frac{\partial(f \circ \varphi^{-1})}{\partial u^i}|_{u=\varphi(p)}  \frac{d}{dt}|_{t=0}(f\circ \varphi^{-1})(\varphi(p) +ta)=\sum_{i=1}^{m} a^i\frac{\partial(f \circ \varphi^{-1})}{\partial u^i}|_{u=\varphi(p)} ? \frac{\partial (f \circ F)}{\partial x^i} =\sum_{j=1}^m\frac{\partial f}{\partial y^j}\frac{\partial F^j}{\partial x^i}. f:V\to\Bbb R V\subseteq\Bbb R^m j \frac{\partial f}{\partial y^j} F:U\to V U\subseteq\Bbb R^n j i \frac{\partial F^j}{\partial x^i} \frac{d}{dt}|_{t=0}(f\circ \varphi^{-1})(\varphi(p) +ta)=\frac{d}{dt}|_{t=0}((f\circ \varphi^{-1})(\varphi(p))  + (f\circ \varphi^{-1})ta)=\frac{d}{dt}|_{t=0}((f(p))  + (f\circ \varphi^{-1})ta) ",['differential-geometry']
62,"For Riemannian manifolds, what does it mean to express a vector using the dual basis?","For Riemannian manifolds, what does it mean to express a vector using the dual basis?",,"I've read most of Lee's Smooth Manifolds and also his Intro to Riemannian Manifolds . In Lee's books, for a manifold $M$ , he defines a tangent vector $v \in T_p M$ as a derivation at a point $p$ , i.e., a linear map that maps real-valued functions $f \in C^\infty (M)$ to a real number: $v: C^\infty (M) \rightarrow \mathbb R$ . And I'm not sure if it's necessarily has to be of this form, but he seems to identify them earlier by the fact that a tangent vector $v$ yields a map $D_v|_p: C^\infty (M) \rightarrow \mathbb R$ , the directional  derivative of a function $f$ . He also defines tangent covectors as linear functionals on the tangent space at a point $p$ , i.e., if the tangent space is a vector space $V$ , then the covector space $V^*$ is the set of linear maps $\omega: V \rightarrow \mathbb R$ , and the basis $E_j$ and dual basis $\epsilon_i$ of the vector/covector spaces are orthogonal in the usual way: $\langle  \epsilon_i , E_j \rangle = \epsilon_i (E_j) = \delta^i_j$ . That all makes sense to me, but I'm conceptually confused by other things I saw. E.g., in An Elementary Introduction to Information Geometry (p5) by Frank Nielsen, the author says: and: I read this to mean that a given vector $v$ can be expressed using either its primal basis ( $e_i$ ) or its dual basis ( $e^i$ ), in Einstein notation: $$v = v^i e_i = v_i e^i$$ What I don't understand is how $v$ can be expressed with either basis, given that the basis of the primal space are vectors, while the basis of the dual space are covectors! the way I read it in the Lee books were that vectors and covectors are different entities, which do different things. My best guess is that it somehow involves using the isomorphism the metric provides between a basis and its dual, e.g., $e^i = g^{ij} e_j$ , but I don't see how that gets around the fact that $v$ still must be a vector in the end. How can a vector be expressed using both the primal or dual bases? edit: and with regards to the last picture, I'm even more confused: my understanding (and what he says) is that the metric $g$ is a mapping $V \times V \rightarrow \mathbb R$ , and that defines an isomorphism that basically allows us to translate between vectors and covectors, i.e., $g: V \times V \rightarrow \mathbb R \Rightarrow g: V \rightarrow (V \rightarrow \mathbb R) \Rightarrow g: V \rightarrow V^\ast$ . And that's what he appears to be doing in eq's 7 and 8, but it's translating between $e_i$ and $e^{\ast j}$ , which seem to be both vectors...","I've read most of Lee's Smooth Manifolds and also his Intro to Riemannian Manifolds . In Lee's books, for a manifold , he defines a tangent vector as a derivation at a point , i.e., a linear map that maps real-valued functions to a real number: . And I'm not sure if it's necessarily has to be of this form, but he seems to identify them earlier by the fact that a tangent vector yields a map , the directional  derivative of a function . He also defines tangent covectors as linear functionals on the tangent space at a point , i.e., if the tangent space is a vector space , then the covector space is the set of linear maps , and the basis and dual basis of the vector/covector spaces are orthogonal in the usual way: . That all makes sense to me, but I'm conceptually confused by other things I saw. E.g., in An Elementary Introduction to Information Geometry (p5) by Frank Nielsen, the author says: and: I read this to mean that a given vector can be expressed using either its primal basis ( ) or its dual basis ( ), in Einstein notation: What I don't understand is how can be expressed with either basis, given that the basis of the primal space are vectors, while the basis of the dual space are covectors! the way I read it in the Lee books were that vectors and covectors are different entities, which do different things. My best guess is that it somehow involves using the isomorphism the metric provides between a basis and its dual, e.g., , but I don't see how that gets around the fact that still must be a vector in the end. How can a vector be expressed using both the primal or dual bases? edit: and with regards to the last picture, I'm even more confused: my understanding (and what he says) is that the metric is a mapping , and that defines an isomorphism that basically allows us to translate between vectors and covectors, i.e., . And that's what he appears to be doing in eq's 7 and 8, but it's translating between and , which seem to be both vectors...","M v \in T_p M p f \in C^\infty (M) v: C^\infty (M) \rightarrow \mathbb R v D_v|_p: C^\infty (M) \rightarrow \mathbb R f p V V^* \omega: V \rightarrow \mathbb R E_j \epsilon_i \langle  \epsilon_i , E_j \rangle = \epsilon_i (E_j) = \delta^i_j v e_i e^i v = v^i e_i = v_i e^i v e^i = g^{ij} e_j v g V \times V \rightarrow \mathbb R g: V \times V \rightarrow \mathbb R \Rightarrow g: V \rightarrow (V \rightarrow \mathbb R) \Rightarrow g: V \rightarrow V^\ast e_i e^{\ast j}","['differential-geometry', 'riemannian-geometry', 'dual-spaces']"
63,Orthonormal basis given by the integral of a vector field along a curve orthogonal to the tangent,Orthonormal basis given by the integral of a vector field along a curve orthogonal to the tangent,,"A friend and I are trying to understand the construction on section 3.2 of this paper by Bernatzki and Ye. Suppose $\gamma$ is a smooth simple closed curve in $\mathbb{R}^3$ . Then this paper claims there exist vector fields $v_i: \gamma \to \mathbb{R}^3$ , $i = 1,2,3$ , such that $v_i \perp \dot{\gamma}$ everywhere, and the three vectors $V_i = \int_{\gamma} v_i(s) ds$ , $s$ being the arc-length parameter, form an orthonormal basis. Furthermore, we can make the support of the $v_i$ arbitrarily small. Why is this true? We know that each $v_i$ can be written as a linear combination $f_iN + g_i B$ , with $(T,N,B)$ being the Frenet frame, $f_i$ and $g_i$ being functions, but the integrals $\int f_iN + g_i B$ don't seem to have particularly nice forms, even after applying the Frenet-Serret equations and integration by parts. I think almost any choice of $v_i$ should yield $V_i$ forming a basis of $\mathbb{R}^3$ , but there seems to be difficulty in proving this rigorously.","A friend and I are trying to understand the construction on section 3.2 of this paper by Bernatzki and Ye. Suppose is a smooth simple closed curve in . Then this paper claims there exist vector fields , , such that everywhere, and the three vectors , being the arc-length parameter, form an orthonormal basis. Furthermore, we can make the support of the arbitrarily small. Why is this true? We know that each can be written as a linear combination , with being the Frenet frame, and being functions, but the integrals don't seem to have particularly nice forms, even after applying the Frenet-Serret equations and integration by parts. I think almost any choice of should yield forming a basis of , but there seems to be difficulty in proving this rigorously.","\gamma \mathbb{R}^3 v_i: \gamma \to \mathbb{R}^3 i = 1,2,3 v_i \perp \dot{\gamma} V_i = \int_{\gamma} v_i(s) ds s v_i v_i f_iN + g_i B (T,N,B) f_i g_i \int f_iN + g_i B v_i V_i \mathbb{R}^3","['differential-geometry', 'differential-topology', 'vector-analysis', 'curves', 'vector-bundles']"
64,In the proof of Lemma 6.18 associated to the Hopf-Rinow theorem.,In the proof of Lemma 6.18 associated to the Hopf-Rinow theorem.,,"I'm reading the John M.Lee, Introduction to Riemannian manifolds, second edition, p.167, Lemma 6.18 and I stuck at some statement : My question is, Question 1. Why can we write a unit-speed minimizing geodesic from $p$ to $q_i$ (whose existence is gauranteed by the lemma) as form of $\operatorname{exp}_p(tv_i)$ for some unit vector $v_i$ ? Question 2. How can we prove the "" $q_i=\operatorname{exp}_p(d_iv_i)$ ""? I feel that I somewhat didn't understand about the exponential map. Can anyone helps?","I'm reading the John M.Lee, Introduction to Riemannian manifolds, second edition, p.167, Lemma 6.18 and I stuck at some statement : My question is, Question 1. Why can we write a unit-speed minimizing geodesic from to (whose existence is gauranteed by the lemma) as form of for some unit vector ? Question 2. How can we prove the "" ""? I feel that I somewhat didn't understand about the exponential map. Can anyone helps?",p q_i \operatorname{exp}_p(tv_i) v_i q_i=\operatorname{exp}_p(d_iv_i),"['differential-geometry', 'proof-explanation', 'riemannian-geometry']"
65,Tensor fields defining $G$-structure are parallel,Tensor fields defining -structure are parallel,G,"Suppose $G \leq GL_n(\mathbb{R})$ is the stabilizer of some tensors $T^0_1, ..., T^0_k$ , let $P$ be a $G$ -structure on a manifold, i.e. a principal $G$ subbundle of the frame bundle of $M$ and let $T_1, ..., T_k$ be tensor fields that are pointwise the image of $T^0_1, ..., T^0_k$ through the frames of $P$ , as in this question. Is it true that the tensor fields $T_1, ..., T_k$ are parallel with respect to any given connection on $P$ ? If you want add the hypothesis of the connection on $P$ being torsion-free (meaning the induced connection on the tangent bundle is) but I believe this is not needed. Alternatively, is it true that if the holonomy of a Riemannian manifold is contained in $G$ then the tensors defining (in the sense of the linked question) the $G$ structure are parallel? By looking at Berger's classification it looks true. I guess that one way to go would be to argue that the parallel transport of a generic tensor on $M$ is characterized by the principal bundle this way: take a tensor at a point, pull it back through a frame at that point getting a tensor on $\mathbb{R}^n$ , transport the frame to the point you want and finally push forward the tensor through the new frame. However I am not at all familiar with parallel transport on induced vector bundles to argue that this is true.","Suppose is the stabilizer of some tensors , let be a -structure on a manifold, i.e. a principal subbundle of the frame bundle of and let be tensor fields that are pointwise the image of through the frames of , as in this question. Is it true that the tensor fields are parallel with respect to any given connection on ? If you want add the hypothesis of the connection on being torsion-free (meaning the induced connection on the tangent bundle is) but I believe this is not needed. Alternatively, is it true that if the holonomy of a Riemannian manifold is contained in then the tensors defining (in the sense of the linked question) the structure are parallel? By looking at Berger's classification it looks true. I guess that one way to go would be to argue that the parallel transport of a generic tensor on is characterized by the principal bundle this way: take a tensor at a point, pull it back through a frame at that point getting a tensor on , transport the frame to the point you want and finally push forward the tensor through the new frame. However I am not at all familiar with parallel transport on induced vector bundles to argue that this is true.","G \leq GL_n(\mathbb{R}) T^0_1, ..., T^0_k P G G M T_1, ..., T_k T^0_1, ..., T^0_k P T_1, ..., T_k P P G G M \mathbb{R}^n","['differential-geometry', 'tensors', 'connections', 'principal-bundles', 'holonomy']"
66,Inconsistency in the definition of the connection coefficients,Inconsistency in the definition of the connection coefficients,,"I am new to general relativity and I am currently facing an apparent inconsistency in the definition of the connection coefficients. Some references I've been consulting (e.g. the lecture notes by S. Carroll or those by D. Tong) define them as follows: $$ \nabla_{\partial_i}\partial_j=\Gamma^k_{ij}\partial_k $$ where $\{\partial_i\}$ are the chart-induced basis vector fields. Some other references, however (e.g. these beautiful lectures by prof. Schuller) define them with the lower indices swapped: $$ \nabla_{\partial_i}\partial_j=\Gamma^k_{ji}\partial_k $$ I know that for a torsion-free connection the coefficients are symmetric in the lower indices, so it doesn't really matter which definition one chooses to adopt. Still, this disagreement is bothering me, since I would like to know how the coefficients are supposed to be defined in the general case of a non-torsion-free connection. Is this discrepancy due to a mere convention/choice of notation? And if not, which definition is to be assumed as the correct one?","I am new to general relativity and I am currently facing an apparent inconsistency in the definition of the connection coefficients. Some references I've been consulting (e.g. the lecture notes by S. Carroll or those by D. Tong) define them as follows: where are the chart-induced basis vector fields. Some other references, however (e.g. these beautiful lectures by prof. Schuller) define them with the lower indices swapped: I know that for a torsion-free connection the coefficients are symmetric in the lower indices, so it doesn't really matter which definition one chooses to adopt. Still, this disagreement is bothering me, since I would like to know how the coefficients are supposed to be defined in the general case of a non-torsion-free connection. Is this discrepancy due to a mere convention/choice of notation? And if not, which definition is to be assumed as the correct one?","
\nabla_{\partial_i}\partial_j=\Gamma^k_{ij}\partial_k
 \{\partial_i\} 
\nabla_{\partial_i}\partial_j=\Gamma^k_{ji}\partial_k
","['differential-geometry', 'connections', 'general-relativity']"
67,Question regarding reduction of structure group,Question regarding reduction of structure group,,Let $\pi:P \to M$ be a principal $G$ -bundle. Given a subgroup $H$ of $G$ one can consider the fibre bundle $P_H :=P\times_{G}G/H$ whose fibres are the coset space $G/H$ . We define a reduction of structure group to be a section of $P_H \to M$ which is also the same as a $G$ -equivariant map from $P \to G/H$ . Here are my questions : I would expect $P_H$ to be a principal $H$ -bundle from the name. But the fibres are $G/H$ . Am I understanding wrong? Another interpretation of $G$ -bundles are by specifying transition functions from $U\cap V \to G$ satisfying cocycle conditions. I would expect reduction to $H$ should somehow mean the transition functions land in $H$ instead of the full $G$ . How can I formulate this? All spaces above are smooth manifolds and groups are Lie groups.,Let be a principal -bundle. Given a subgroup of one can consider the fibre bundle whose fibres are the coset space . We define a reduction of structure group to be a section of which is also the same as a -equivariant map from . Here are my questions : I would expect to be a principal -bundle from the name. But the fibres are . Am I understanding wrong? Another interpretation of -bundles are by specifying transition functions from satisfying cocycle conditions. I would expect reduction to should somehow mean the transition functions land in instead of the full . How can I formulate this? All spaces above are smooth manifolds and groups are Lie groups.,\pi:P \to M G H G P_H :=P\times_{G}G/H G/H P_H \to M G P \to G/H P_H H G/H G U\cap V \to G H H G,"['differential-geometry', 'smooth-manifolds', 'principal-bundles']"
68,How do we go from a covariant derivative on a principal bundle to a covariant derivative on an associated bundle,How do we go from a covariant derivative on a principal bundle to a covariant derivative on an associated bundle,,"Let $M$ be a smooth manifold and $\pi:P\to M$ a principal $G$ bundle over $M$ . Suppose that $P$ is equipped with a connection one form $\omega$ . We can define an exterior covariant derivative on $P$ via $D\eta = d\eta \circ \operatorname{hor}$ , where $\operatorname{hor}$ is the horizontal part of any vector in $TP$ . For $G$ -equivariant functions $\phi :P\to F$ (that is $\phi(p\cdot g) =\rho(g^{-1})\phi(p)$ , where $\rho:G\to F$ is a representation of $G$ ), and indeed for $G$ -equivariant forms as well (but we don't need them), the exterior covariant derivative takes the simple form $$D\phi = d \phi + \rho_{*e}(\omega)\wedge \phi,$$ where the wedge product can be defined in a natural way. These $G$ -equivariant functions are in one-to-one correspondence with local sections of the associated bundle $Q :=P \times _G F$ over an open set $U$ of $M$ , and they contain the same information. The question is then, how does one go from the exterior covariant derivative on $G$ -equivariant functions to the covariant derivative of local sections of the associated bundle $Q$ ? One could naturally take the covariant derivative to simply be the local section $\sigma$ associated to $D\phi(X)$ , where $X \in TP$ , but this is not a covariant derivative on $Q$ , since $X$ is not in $TM$ . I have also seen the covariant derivative defined by pulling back $D\phi$ by a local section $s$ of $P$ over an open set $U$ , but this approach doesn't make much sense to me. This approach would make more sense if the correspondence mentioned above was between global sections and $G$ -equivariant functions, in which case we just take the local representation of the section (i.e. $s^*(D\phi)$ ). If anyone could clarify, it would be very helpful.","Let be a smooth manifold and a principal bundle over . Suppose that is equipped with a connection one form . We can define an exterior covariant derivative on via , where is the horizontal part of any vector in . For -equivariant functions (that is , where is a representation of ), and indeed for -equivariant forms as well (but we don't need them), the exterior covariant derivative takes the simple form where the wedge product can be defined in a natural way. These -equivariant functions are in one-to-one correspondence with local sections of the associated bundle over an open set of , and they contain the same information. The question is then, how does one go from the exterior covariant derivative on -equivariant functions to the covariant derivative of local sections of the associated bundle ? One could naturally take the covariant derivative to simply be the local section associated to , where , but this is not a covariant derivative on , since is not in . I have also seen the covariant derivative defined by pulling back by a local section of over an open set , but this approach doesn't make much sense to me. This approach would make more sense if the correspondence mentioned above was between global sections and -equivariant functions, in which case we just take the local representation of the section (i.e. ). If anyone could clarify, it would be very helpful.","M \pi:P\to M G M P \omega P D\eta = d\eta \circ \operatorname{hor} \operatorname{hor} TP G \phi :P\to F \phi(p\cdot g) =\rho(g^{-1})\phi(p) \rho:G\to F G G D\phi = d \phi + \rho_{*e}(\omega)\wedge \phi, G Q :=P \times _G F U M G Q \sigma D\phi(X) X \in TP Q X TM D\phi s P U G s^*(D\phi)","['differential-geometry', 'connections', 'principal-bundles']"
69,Does the condition $(\nabla_XJ)Y=(\nabla_YJ)X$ imply $\nabla J=0$?,Does the condition  imply ?,(\nabla_XJ)Y=(\nabla_YJ)X \nabla J=0,"Let $(M,g,J)$ be an Almost Hermitian manifold and $\nabla $ the Levi-Civita connection. If $$(\nabla_XJ)Y=(\nabla_YJ)X$$ for any $X,Y\in \Gamma(TM)$ , can we get $\nabla J=0$ , i.e., $(M,g,J)$ is Kahlerian? The condition says that $\nabla J$ is symmetric, and I don't think it follows from the symmetry of $\nabla J$ that $\nabla J=0$ . However, I can't an example to illustrate it.","Let be an Almost Hermitian manifold and the Levi-Civita connection. If for any , can we get , i.e., is Kahlerian? The condition says that is symmetric, and I don't think it follows from the symmetry of that . However, I can't an example to illustrate it.","(M,g,J) \nabla  (\nabla_XJ)Y=(\nabla_YJ)X X,Y\in \Gamma(TM) \nabla J=0 (M,g,J) \nabla J \nabla J \nabla J=0","['differential-geometry', 'complex-geometry', 'kahler-manifolds', 'almost-complex']"
70,Derivative of distance along a smooth curve,Derivative of distance along a smooth curve,,"I am struggling to solve the following problem from 'Introduction to Riemannian Manifolds' by John M. Lee $(M,g)$ be a connected Riemannian manifold. $\gamma:(-\epsilon,\epsilon)\to M$ be a smooth curve then $$\lim_{t\to0}\frac{d_g(\gamma(0),\gamma(t))}{t}=|\dot\gamma(0)|_g$$ I was able to show that $$\lim_{t\to0}\frac{d_g(\gamma(0),\gamma(t))}{t}\le \lim_{t\to0+}\frac{l(\gamma|_{[0,t]})}{t}=\lim_{t\to0-}\frac{l(\gamma|_{[t,0]})}{t}=|\dot\gamma(0)|_g$$ Here $l(\cdot)$ denotes length of the curve. Then I tried to contradict assuming $$\lim_{t\to0}\frac{d_g(\gamma(0),\gamma(t))}{t}>|\dot\gamma(0)|_g$$ but failed to complete the argument. Am I doing anything wrong? Please help. Some hints would be highly appreciated.",I am struggling to solve the following problem from 'Introduction to Riemannian Manifolds' by John M. Lee be a connected Riemannian manifold. be a smooth curve then I was able to show that Here denotes length of the curve. Then I tried to contradict assuming but failed to complete the argument. Am I doing anything wrong? Please help. Some hints would be highly appreciated.,"(M,g) \gamma:(-\epsilon,\epsilon)\to M \lim_{t\to0}\frac{d_g(\gamma(0),\gamma(t))}{t}=|\dot\gamma(0)|_g \lim_{t\to0}\frac{d_g(\gamma(0),\gamma(t))}{t}\le \lim_{t\to0+}\frac{l(\gamma|_{[0,t]})}{t}=\lim_{t\to0-}\frac{l(\gamma|_{[t,0]})}{t}=|\dot\gamma(0)|_g l(\cdot) \lim_{t\to0}\frac{d_g(\gamma(0),\gamma(t))}{t}>|\dot\gamma(0)|_g","['differential-geometry', 'riemannian-geometry', 'arc-length', 'metric-geometry']"
71,Condition on local flows that imply completeness of vector field,Condition on local flows that imply completeness of vector field,,"Given any smooth vector field $X$ on a manifold $M$ we can cover $M$ by open sets $\{U_\alpha\}_{\alpha\in A}$ such that for each $\alpha$ there is an $\epsilon_\alpha>0$ such that if $p \in U_\alpha$ the local flow for $X$ at $p$ , say $\phi^\alpha_t$ is defined for $t\in (-\epsilon_\alpha,\epsilon_\alpha)$ . The $\phi^\alpha_t$ being local diffeomeorphisms we get a local family of local diffeomorphisms out of this i.e. $\{U_\alpha, \phi^\alpha_t,\epsilon_\alpha\}_{\alpha\in A}$ Now there is a result that if $\inf_{\alpha\in A}\epsilon_\alpha>0$ then the local family can be extended to a global one-parameter family of diffeomorphisms as follows: Say $\inf_{\alpha\in A}\epsilon_\alpha=\epsilon$ . Then define $\phi_t(p)=\phi^\alpha_t(p)$ where $p\in U_\alpha$ and $|t|<\epsilon$ else if $n$ is such that $|\frac{t}{n}|<\epsilon$ then $\phi_t(p)=\underbrace{\phi^\alpha_{\frac{t}{n}}\circ\phi^\alpha_{\frac{t}{n}}\circ...\phi^\alpha_{\frac{t}{n}}}_{n\ \ \text{times}}(p)$ The well-defined ness of the above definition etc needs to be checked here. Now my problem here is that I don't see what problem arises when $\inf_{\alpha\in A}\epsilon_\alpha=0$ .Given $p$ in a particular $U_\alpha$ the $n$ that we took above has to be adjusted so that $|\frac{t}{n}|<\epsilon_\alpha$ so we'd have to work with a variable $n$ in this case. But I don't see what harm this variable n causes to the well-definedness etc of $\phi$ (which has lead me to suspect that I have missed something vital that led to well-definedness in the result mentioned). Please help see the necessity of $\inf_{\alpha\in A}\epsilon_\alpha>0$ in the result above.","Given any smooth vector field on a manifold we can cover by open sets such that for each there is an such that if the local flow for at , say is defined for . The being local diffeomeorphisms we get a local family of local diffeomorphisms out of this i.e. Now there is a result that if then the local family can be extended to a global one-parameter family of diffeomorphisms as follows: Say . Then define where and else if is such that then The well-defined ness of the above definition etc needs to be checked here. Now my problem here is that I don't see what problem arises when .Given in a particular the that we took above has to be adjusted so that so we'd have to work with a variable in this case. But I don't see what harm this variable n causes to the well-definedness etc of (which has lead me to suspect that I have missed something vital that led to well-definedness in the result mentioned). Please help see the necessity of in the result above.","X M M \{U_\alpha\}_{\alpha\in A} \alpha \epsilon_\alpha>0 p \in U_\alpha X p \phi^\alpha_t t\in (-\epsilon_\alpha,\epsilon_\alpha) \phi^\alpha_t \{U_\alpha, \phi^\alpha_t,\epsilon_\alpha\}_{\alpha\in A} \inf_{\alpha\in A}\epsilon_\alpha>0 \inf_{\alpha\in A}\epsilon_\alpha=\epsilon \phi_t(p)=\phi^\alpha_t(p) p\in U_\alpha |t|<\epsilon n |\frac{t}{n}|<\epsilon \phi_t(p)=\underbrace{\phi^\alpha_{\frac{t}{n}}\circ\phi^\alpha_{\frac{t}{n}}\circ...\phi^\alpha_{\frac{t}{n}}}_{n\ \ \text{times}}(p) \inf_{\alpha\in A}\epsilon_\alpha=0 p U_\alpha n |\frac{t}{n}|<\epsilon_\alpha n \phi \inf_{\alpha\in A}\epsilon_\alpha>0","['differential-geometry', 'vector-fields', 'diffeomorphism']"
72,"Let $X, Y$ be vector fields on a manifold $M$. Show, that $XY$ is not a vector field","Let  be vector fields on a manifold . Show, that  is not a vector field","X, Y M XY","Let $X, Y$ be vector fields on a manifold $M$ . Show, that $XY$ is not a vector field My attempt My idea would be to directly show, that $$XY (fg) \neq (XY f)g + f(XY g) \quad \lor \quad XY (\alpha f + \beta g) \neq \alpha XY f + \beta XY g$$ I am not sure at writing out $XY (fg)$ $$XY (fg) = X ( Y (fg)) = X ((Yf)g + f(Yg)) = X((Yf)g) + X(f(Yg)) = $$ $$ = (X (Y f))g + (Yf)Xg + (Xf)(Yg) + f (X(Yg)) = (XYf)g + (Yf)Xg + (Xf)Yg + f(XYg)$$ So we get an additional $(Yf)Xg + (Xf)Yg$ , thus $XY (fg) \neq (XY f)g + f(XY g)$ Which is enough to show that $XY$ is not a vector field. Are my calculations alright? I'm not sure especially because at the end, I simply ignore the brackets i.e. $(X(Yf))g$ becomes $(XYf)g$ so it can fit into our first assumption. I don't know if we can do that","Let be vector fields on a manifold . Show, that is not a vector field My attempt My idea would be to directly show, that I am not sure at writing out So we get an additional , thus Which is enough to show that is not a vector field. Are my calculations alright? I'm not sure especially because at the end, I simply ignore the brackets i.e. becomes so it can fit into our first assumption. I don't know if we can do that","X, Y M XY XY (fg) \neq (XY f)g + f(XY g) \quad \lor \quad XY (\alpha f + \beta g) \neq \alpha XY f + \beta XY g XY (fg) XY (fg) = X ( Y (fg)) = X ((Yf)g + f(Yg)) = X((Yf)g) + X(f(Yg)) =   = (X (Y f))g + (Yf)Xg + (Xf)(Yg) + f (X(Yg)) = (XYf)g + (Yf)Xg + (Xf)Yg + f(XYg) (Yf)Xg + (Xf)Yg XY (fg) \neq (XY f)g + f(XY g) XY (X(Yf))g (XYf)g","['differential-geometry', 'manifolds', 'vector-fields']"
73,Why is the space of differential forms $\bigoplus_{p=0}^n \Lambda_x^p$?,Why is the space of differential forms ?,\bigoplus_{p=0}^n \Lambda_x^p,"In Wald's book ""General Relativity"", the space $\Lambda_x$ of differential forms at a point $x$ is worked out in the following manner: Let $M$ be an $n$ -dimensional manifold. The vector space of all $p$ -forms at a point $x \in M$ is given by $\Lambda_x^p$ . The vector space $\Lambda_x$ of all differential forms (not limited to a specified degree $p$ ) is given by the direct sum: $$ \Lambda_x =\bigoplus_{p=0}^n \Lambda_x^p $$ However, from my understanding, the direct sum $A \oplus B$ of two spaces $A$ and $B$ consists of all ordered pairs $(a,b)$ where $a \in A$ and $b \in B$ , with the additional structure: $$(a_1, b_1) + (a_2, b_2) = (a_1 + a_2, b_1 + b_2)$$ Wouldn't this mean that an element from $\omega \in \Lambda_x$ would take the form: $$ \omega = (\omega_1, \omega_2, \dots , \omega_n) $$ where $\omega_1$ is a 1-form, $\omega_2$ a 2-form, and so on? This to me doesn't seem to be the space of all differential forms at $x$ , unless all $\omega_i$ are 0 except one for each $\omega$ . In fact, it seems to be a much larger space, since it can contain multiple differential forms of different degrees. My first guess was that a $p$ -form and a $q$ -form would be combined via the map $ \bigwedge: \Lambda^p_x \times \Lambda^q_x \mapsto \Lambda^{p+q}_x $ , but then we are no longer limited to the degree $n$ . Why is this written as a direct sum rather than, for example, a union? $$ \Lambda_x = \bigcup_{p=0}^n \Lambda_x^p $$","In Wald's book ""General Relativity"", the space of differential forms at a point is worked out in the following manner: Let be an -dimensional manifold. The vector space of all -forms at a point is given by . The vector space of all differential forms (not limited to a specified degree ) is given by the direct sum: However, from my understanding, the direct sum of two spaces and consists of all ordered pairs where and , with the additional structure: Wouldn't this mean that an element from would take the form: where is a 1-form, a 2-form, and so on? This to me doesn't seem to be the space of all differential forms at , unless all are 0 except one for each . In fact, it seems to be a much larger space, since it can contain multiple differential forms of different degrees. My first guess was that a -form and a -form would be combined via the map , but then we are no longer limited to the degree . Why is this written as a direct sum rather than, for example, a union?","\Lambda_x x M n p x \in M \Lambda_x^p \Lambda_x p 
\Lambda_x =\bigoplus_{p=0}^n \Lambda_x^p
 A \oplus B A B (a,b) a \in A b \in B (a_1, b_1) + (a_2, b_2) = (a_1 + a_2, b_1 + b_2) \omega \in \Lambda_x 
\omega = (\omega_1, \omega_2, \dots , \omega_n)
 \omega_1 \omega_2 x \omega_i \omega p q  \bigwedge: \Lambda^p_x \times \Lambda^q_x \mapsto \Lambda^{p+q}_x  n 
\Lambda_x = \bigcup_{p=0}^n \Lambda_x^p
","['differential-geometry', 'differential-forms', 'direct-sum']"
74,"A question about $SL(2,\mathbb{R})$",A question about,"SL(2,\mathbb{R})","My professor gave me an exercise where I had to show that the special linear group $SL(2,\mathbb{R})$ is a lie subgroup of $GL(2,\mathbb{R})$ . I was able to do this part. However, I was then asked to do the following: All real $2\times 2$ matrices $\begin{pmatrix} a & b \\ c & d\end{pmatrix}$ can be identified with $(a,b,c,d) \in \mathbb{R}^4$ . In this way, $SL(2,\mathbb{R})$ can be thought of as a subset of $\mathbb{R}^4$ . In this correspondence, find all matrices in $SL(2,\mathbb{R})$ that are closest to the origin. I really don't have any idea how to approach this problem. The only things I have ever seen like this are Lagrange multipliers, but those don't seem to apply here. For reference, though this exercise is not in the text, our course is using Introduction to Smooth Manifolds by Lee.","My professor gave me an exercise where I had to show that the special linear group is a lie subgroup of . I was able to do this part. However, I was then asked to do the following: All real matrices can be identified with . In this way, can be thought of as a subset of . In this correspondence, find all matrices in that are closest to the origin. I really don't have any idea how to approach this problem. The only things I have ever seen like this are Lagrange multipliers, but those don't seem to apply here. For reference, though this exercise is not in the text, our course is using Introduction to Smooth Manifolds by Lee.","SL(2,\mathbb{R}) GL(2,\mathbb{R}) 2\times 2 \begin{pmatrix} a & b \\ c & d\end{pmatrix} (a,b,c,d) \in \mathbb{R}^4 SL(2,\mathbb{R}) \mathbb{R}^4 SL(2,\mathbb{R})","['differential-geometry', 'optimization', 'manifolds', 'lie-groups']"
75,Sectional curvature of a compact Lie Group,Sectional curvature of a compact Lie Group,,"I've been trying to proof this: In a compact lie group with bi-invariant metric $g$ , the sectional curvature holds the next equality. $K(\sigma)=\frac{1}{4}\|[X,Y]\|^2$ When I tried, I needed to use that $g([[X,Y],X],Y)=g([X,Y],[X,Y])$ but I couldn't prove it. Thank you","I've been trying to proof this: In a compact lie group with bi-invariant metric , the sectional curvature holds the next equality. When I tried, I needed to use that but I couldn't prove it. Thank you","g K(\sigma)=\frac{1}{4}\|[X,Y]\|^2 g([[X,Y],X],Y)=g([X,Y],[X,Y])","['differential-geometry', 'riemannian-geometry', 'lie-groups']"
76,How do metrics work on the total space of a vector bundle?,How do metrics work on the total space of a vector bundle?,,"Suppose $\pi: E \rightarrow M$ is a vector bundle over a manifold $M$ . Suppose that $$k: E \times_M E \rightarrow \mathbb{R}$$ is a bundle metric on $E$ and that $$g: TM \times_M TM \rightarrow \mathbb{R}$$ is a Riemannian metric on $M$ . Then if I have a connection $\nabla: \Gamma(TM) \times \Gamma(E) \rightarrow \Gamma(E)$ on $E$ , I can write a splitting: $$TE = HE \oplus VE \cong TM \oplus E$$ My question is, can I use these structures to define a Riemannian metric on the total space $E$ ? Also, are any of these three things unnecessary? Here is my guess about how to construct the metric on the total space $E$ : $$G: TE \times_E TE \rightarrow \mathbb{R}$$ via $$G_e(u,w) = k_p(u_v,w_v) + g_p(u_h , w_h)$$ where $u_v$ is the vertical projection of $u$ and $u_h$ is the horizontal projection of $u$ (so like $d\pi(u)$ ) and $p = \pi(e)$","Suppose is a vector bundle over a manifold . Suppose that is a bundle metric on and that is a Riemannian metric on . Then if I have a connection on , I can write a splitting: My question is, can I use these structures to define a Riemannian metric on the total space ? Also, are any of these three things unnecessary? Here is my guess about how to construct the metric on the total space : via where is the vertical projection of and is the horizontal projection of (so like ) and","\pi: E \rightarrow M M k: E \times_M E \rightarrow \mathbb{R} E g: TM \times_M TM \rightarrow \mathbb{R} M \nabla: \Gamma(TM) \times \Gamma(E) \rightarrow \Gamma(E) E TE = HE \oplus VE \cong TM \oplus E E E G: TE \times_E TE \rightarrow \mathbb{R} G_e(u,w) = k_p(u_v,w_v) + g_p(u_h , w_h) u_v u u_h u d\pi(u) p = \pi(e)","['differential-geometry', 'vector-bundles']"
77,At the centroid does the gradient becomes zero?,At the centroid does the gradient becomes zero?,,"Suppose we have a smooth differentiable planar curve given as $F(x,y)=0$ . Suppose that the centroid of the curve $F=0$ is $F(x_0,y_0)$ . My question is:- $$\nabla F(x_0,y_0)=0$$ That is, does the gradient of $F$ becomes zero at $(x_0,y_0)$ ? Now some examples supporting this statement are circles and ellipses . I would be grateful if anyone proves the statement or gives a counter example . Also I welcome anyone who would like to generalise this statement in any direction. Thanks!","Suppose we have a smooth differentiable planar curve given as . Suppose that the centroid of the curve is . My question is:- That is, does the gradient of becomes zero at ? Now some examples supporting this statement are circles and ellipses . I would be grateful if anyone proves the statement or gives a counter example . Also I welcome anyone who would like to generalise this statement in any direction. Thanks!","F(x,y)=0 F=0 F(x_0,y_0) \nabla F(x_0,y_0)=0 F (x_0,y_0)","['differential-geometry', 'euclidean-geometry', 'analytic-geometry']"
78,"Is the Lie algebra generated by $e_1, e_2$ spanned by $e_1, e_2, [e_1, e_2]$?",Is the Lie algebra generated by  spanned by ?,"e_1, e_2 e_1, e_2, [e_1, e_2]","The Lie algebra generated by $e_1, e_2$ is spanned by the iterated Lie brackets of $e_1$ and $e_2$ ( $e_1, e_2, [e_1, e_2], [e_1, [e_1, e_2]], [e_2, [e_1, e_2]], \ldots$ ). Is it also spanned by just $e_1, e_2$ and $[e_1, e_2]$ ? The reason I ask is that in this Wikipedia article the parabolic Hörmander condition is stated just with $n+1$ iterations of the Lie bracket when considering $n+1$ vector fields and in other sources it is stated with an arbitrary number of iterations of the Lie bracket. I would like to show that a particular SDE $dx = A_0(x)dt + A_1(x) dB_t$ does not satisfy the parabolic Hörmander condition and I was wondering if it would be enough to show that $A_1(x_0)$ and $[A_0, A_1](x_0)$ do not span the tangent space at a particular point $x_0$ like the Wikipedia article suggests.",The Lie algebra generated by is spanned by the iterated Lie brackets of and ( ). Is it also spanned by just and ? The reason I ask is that in this Wikipedia article the parabolic Hörmander condition is stated just with iterations of the Lie bracket when considering vector fields and in other sources it is stated with an arbitrary number of iterations of the Lie bracket. I would like to show that a particular SDE does not satisfy the parabolic Hörmander condition and I was wondering if it would be enough to show that and do not span the tangent space at a particular point like the Wikipedia article suggests.,"e_1, e_2 e_1 e_2 e_1, e_2, [e_1, e_2], [e_1, [e_1, e_2]], [e_2, [e_1, e_2]], \ldots e_1, e_2 [e_1, e_2] n+1 n+1 dx = A_0(x)dt + A_1(x) dB_t A_1(x_0) [A_0, A_1](x_0) x_0","['differential-geometry', 'lie-algebras', 'stochastic-differential-equations']"
79,How are manifolds embedded into an euclidean space? [closed],How are manifolds embedded into an euclidean space? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 2 years ago . Improve this question I am really new to differential geometry and topology and I am trying to understand how it is possible to embed a minfold into an euclidean space. In particular, I am looking at projective spaces, but as I have already said I am really new, so I don't know if it is really realated. So, my question is really short and it is: How are manifolds embedded into an euclidean space? If possible, I would like to have a more intuitive explanation of how this happens.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 2 years ago . Improve this question I am really new to differential geometry and topology and I am trying to understand how it is possible to embed a minfold into an euclidean space. In particular, I am looking at projective spaces, but as I have already said I am really new, so I don't know if it is really realated. So, my question is really short and it is: How are manifolds embedded into an euclidean space? If possible, I would like to have a more intuitive explanation of how this happens.",,"['general-topology', 'differential-geometry', 'algebraic-topology']"
80,Normal bundles of $S^1$ in a Klein bottle,Normal bundles of  in a Klein bottle,S^1,"Consider the Klein bottle $K$ obtained from a square by gluing the corresponding edges in the blow figure. Then we get two obvious embedding of $S^1$ to Klein bottle $i_a: S^1\to K$ and $i_b:S^1\to K$ , that is, embedded into the circle $a$ and the circle $b$ respectively. I want to identify the normal bundles with respect to those two embedding. My guess: the first normal bundle is trivial bundle over $S^1$ and the second one is the unbounded Möbius band on $S^1$ . But I have trouble in showing this explicitly. My attempt starts with writing a smooth atlas of the Klein bottle and I hope this can help me do calculation. However, by definition, the normal bundle $N_{K/S^1}$ is the quotient bundle $((i_a)^*TK)/TS^1$ , that is, $$0\to TS^1 \to ((i_a)^*TK)/TS^1 \to N_{K/S^1} \to 0$$ However, I don’t know how to write the first map in local chart so that I can calculate the bundle explicitly. Any reference, hints, and answers are welcome!","Consider the Klein bottle obtained from a square by gluing the corresponding edges in the blow figure. Then we get two obvious embedding of to Klein bottle and , that is, embedded into the circle and the circle respectively. I want to identify the normal bundles with respect to those two embedding. My guess: the first normal bundle is trivial bundle over and the second one is the unbounded Möbius band on . But I have trouble in showing this explicitly. My attempt starts with writing a smooth atlas of the Klein bottle and I hope this can help me do calculation. However, by definition, the normal bundle is the quotient bundle , that is, However, I don’t know how to write the first map in local chart so that I can calculate the bundle explicitly. Any reference, hints, and answers are welcome!",K S^1 i_a: S^1\to K i_b:S^1\to K a b S^1 S^1 N_{K/S^1} ((i_a)^*TK)/TS^1 0\to TS^1 \to ((i_a)^*TK)/TS^1 \to N_{K/S^1} \to 0,"['general-topology', 'differential-geometry', 'differential-topology', 'geometric-topology']"
81,Cheeger constant of a ball in $\mathbb{R}^3$,Cheeger constant of a ball in,\mathbb{R}^3,"I'm trying to find a reference about or related to the Cheeger constant of a ball in $\mathbb{R}^3$ . The definition of Cheeger constant $h(\Omega)$ is as follows: given a domain $\Omega\subset\mathbb{R}^d$ , $$h(\Omega) = \inf \{\frac{|\partial D|}{|D|}, D\subset \Omega\}$$ where we use Lebesgue measures respectively of dimension $d-1$ for $\partial D$ and dimension $d$ for $D$ . And $D$ is varying among the smooth subdomains of $\Omega$ . Is there any reference on how to compute this for balls of some size $r>0$ ( $\{|x|\le r\}$ ) in $\mathbb{R}^3$ . This is related to a problem of first non-linear eigenvalue of $\textbf{1-Laplacian}$ on balls in $\mathbb{R}^3$ that I'm working on. Any suggestion will be appreciated!","I'm trying to find a reference about or related to the Cheeger constant of a ball in . The definition of Cheeger constant is as follows: given a domain , where we use Lebesgue measures respectively of dimension for and dimension for . And is varying among the smooth subdomains of . Is there any reference on how to compute this for balls of some size ( ) in . This is related to a problem of first non-linear eigenvalue of on balls in that I'm working on. Any suggestion will be appreciated!","\mathbb{R}^3 h(\Omega) \Omega\subset\mathbb{R}^d h(\Omega) = \inf \{\frac{|\partial D|}{|D|}, D\subset \Omega\} d-1 \partial D d D D \Omega r>0 \{|x|\le r\} \mathbb{R}^3 \textbf{1-Laplacian} \mathbb{R}^3","['differential-geometry', 'laplacian']"
82,"Pullback, 2-form invariant","Pullback, 2-form invariant",,"Let $\mathbb H^2 = \{(x, y) \in \mathbb{R}^2 : y> 0\}$ and consider the $2$ -form in $\mathbb H^2$ defined by $$\varphi = \dfrac{dx \wedge dy}{y^2}.$$ Show that $\varphi$ is invariant $(T^*(\varphi)= \varphi)$ under the transformation $T$ from $\mathbb H^2$ to $\mathbb H^2$ given by $$T(z) = \dfrac{az + b}{cz + d}$$ where $z \in \mathbb H^2 \subset \mathbb{C}$ and $a, b, c, d \in \mathbb{R}$ with $ad - bc \neq 0$ . My attempt was to try to express $T(x, y)$ and calculate $dx $ and $ dy $ to make $ dx \wedge dy $ , and calculate the pullback. I couldn't, the expression for $T$ was strange.","Let and consider the -form in defined by Show that is invariant under the transformation from to given by where and with . My attempt was to try to express and calculate and to make , and calculate the pullback. I couldn't, the expression for was strange.","\mathbb H^2 = \{(x, y) \in \mathbb{R}^2 : y> 0\} 2 \mathbb H^2 \varphi = \dfrac{dx \wedge dy}{y^2}. \varphi (T^*(\varphi)= \varphi) T \mathbb H^2 \mathbb H^2 T(z) = \dfrac{az + b}{cz + d} z \in \mathbb H^2 \subset \mathbb{C} a, b, c, d \in \mathbb{R} ad - bc \neq 0 T(x, y) dx   dy   dx \wedge dy  T",['differential-geometry']
83,Yamabe Positive iff Admits Metric of Positive Scalar Curvature,Yamabe Positive iff Admits Metric of Positive Scalar Curvature,,"I'm trying to prove that the Yamabe invariant of a compact manifold, that is the sigma constant, is positive iff $M$ admits a metric of positive scalar curvature. I will use $$Y_{[g]} = \underset{g \in [g]}{\inf} \mathcal{E}(g)$$ to be the Yamabe constant with $$\mathcal{E}(g) = {\frac{{\int_{M}S_g \Omega}}{\left({\int_{M} \Omega}\right)^{{\frac{n-2}{n}}}}}$$ One direction is straightforward. That is, assume $\sigma(M) > 0$ , then there exists some conformal class [g] such that $Y_{[g]} > 0$ . Then by the Yamabe problem there exists a metric $\tilde{g} \in [g]$ such that $(M,\tilde{g})$ has constant positive scalar curvature. I'm struggling with the other direction. Suppose $M$ admits a metric of positive scalar curvature $g_0$ , say. We want to show that $$\sigma(M) = \underset{[g]\in \mathcal{C}_M }{\sup} Y_{[g]} > 0$$ with $\mathcal{C}_{M}$ being the set of conformal classes on $M$ . So we just need to show there exists a conformal class giving a positive Yamabe constant. Given the information we have I would imagine that this supremum is achieved by $Y_{[g_0]}$ . But I'm having trouble showing that this is positive. What's stopping there being some other metric, say $\tilde{g_0} \in [g_0]$ such that $\mathcal{E}(\tilde{g_0}) \leq 0$ thus giving a non-positive value for $Y_{[g_0]}$ ?","I'm trying to prove that the Yamabe invariant of a compact manifold, that is the sigma constant, is positive iff admits a metric of positive scalar curvature. I will use to be the Yamabe constant with One direction is straightforward. That is, assume , then there exists some conformal class [g] such that . Then by the Yamabe problem there exists a metric such that has constant positive scalar curvature. I'm struggling with the other direction. Suppose admits a metric of positive scalar curvature , say. We want to show that with being the set of conformal classes on . So we just need to show there exists a conformal class giving a positive Yamabe constant. Given the information we have I would imagine that this supremum is achieved by . But I'm having trouble showing that this is positive. What's stopping there being some other metric, say such that thus giving a non-positive value for ?","M Y_{[g]} = \underset{g \in [g]}{\inf} \mathcal{E}(g) \mathcal{E}(g) = {\frac{{\int_{M}S_g \Omega}}{\left({\int_{M} \Omega}\right)^{{\frac{n-2}{n}}}}} \sigma(M) > 0 Y_{[g]} > 0 \tilde{g} \in [g] (M,\tilde{g}) M g_0 \sigma(M) = \underset{[g]\in \mathcal{C}_M }{\sup} Y_{[g]} > 0 \mathcal{C}_{M} M Y_{[g_0]} \tilde{g_0} \in [g_0] \mathcal{E}(\tilde{g_0}) \leq 0 Y_{[g_0]}","['differential-geometry', 'riemannian-geometry', 'curvature']"
84,Are $SO(3)$ and $SU(2)$ abstractly isomorphic?,Are  and  abstractly isomorphic?,SO(3) SU(2),"The groups $SO(3)$ and $SU(2)$ are usually ""the"" classic example of nonisomorphic Lie groups whose corresponding Lie algebras are isomorphic. While I understand the isomorphism of their algebras, it was not obvious at all to me that we must have $SU(2) \not\cong SO(3)$ , I think one can conclude that by looking at the topological structure, for example the fact that their fundamental groups are nonisomorphic should suffice (I think ). What if we forget about the topology and consider them just as abstract groups? I've been trying to find some obstruction but all the facts I know about them, for example $SO(3) \cong SU(2)/Z(SU(2))$ , don't seem to be enough! Am I missing something obvious?","The groups and are usually ""the"" classic example of nonisomorphic Lie groups whose corresponding Lie algebras are isomorphic. While I understand the isomorphism of their algebras, it was not obvious at all to me that we must have , I think one can conclude that by looking at the topological structure, for example the fact that their fundamental groups are nonisomorphic should suffice (I think ). What if we forget about the topology and consider them just as abstract groups? I've been trying to find some obstruction but all the facts I know about them, for example , don't seem to be enough! Am I missing something obvious?",SO(3) SU(2) SU(2) \not\cong SO(3) SO(3) \cong SU(2)/Z(SU(2)),"['general-topology', 'group-theory', 'differential-geometry', 'algebraic-topology', 'lie-groups']"
85,The differential of the exponential map on a Riemannian manifold,The differential of the exponential map on a Riemannian manifold,,"Let $M$ be a Riemannian manifold and $exp_{x}: T_{x}M \to M$ the usual exponential map. It is an important fact that $D_{0}exp_{x}(v) = v$ for any $v \in T_{0}(T_{x}M)$ . The proof goes like this: $D_{0} exp_{x}(v) = \frac{d}{dt} exp_{x}(tv)|_{t = 0} =  \gamma(t)'|_{t = 0} = v$ , where $\gamma(t)$ is the geodesic starting at $v$ . I am struggling to understand this proof because I find it hard to interpret $\frac{d}{dt} exp_{x}(tv)|_{t = 0}$ . Is it supposed to be understood as $\lim_{t \to 0} \frac{exp_{x}(tv) - exp_{x}(0)}{t}?$ This difference expression does not make sense since we cannot take difference on a manifold without extra structure. I guess my problem is most of the texts I encountered tend to treat calculations like this like they are in the Euclidean space rather than on a manifold. I suppose it should be correct to do so, but is it trivially true without any justification? The way I would prove this is to take $f \in C^{\infty}(M)$ , and try to figure out what is the action of $D_{0}exp_{x}(v)$ on $f$ , but none of the reference I find take this approach.","Let be a Riemannian manifold and the usual exponential map. It is an important fact that for any . The proof goes like this: , where is the geodesic starting at . I am struggling to understand this proof because I find it hard to interpret . Is it supposed to be understood as This difference expression does not make sense since we cannot take difference on a manifold without extra structure. I guess my problem is most of the texts I encountered tend to treat calculations like this like they are in the Euclidean space rather than on a manifold. I suppose it should be correct to do so, but is it trivially true without any justification? The way I would prove this is to take , and try to figure out what is the action of on , but none of the reference I find take this approach.",M exp_{x}: T_{x}M \to M D_{0}exp_{x}(v) = v v \in T_{0}(T_{x}M) D_{0} exp_{x}(v) = \frac{d}{dt} exp_{x}(tv)|_{t = 0} =  \gamma(t)'|_{t = 0} = v \gamma(t) v \frac{d}{dt} exp_{x}(tv)|_{t = 0} \lim_{t \to 0} \frac{exp_{x}(tv) - exp_{x}(0)}{t}? f \in C^{\infty}(M) D_{0}exp_{x}(v) f,"['differential-geometry', 'riemannian-geometry']"
86,Darboux theorem for the symplectisation of a contact manifold,Darboux theorem for the symplectisation of a contact manifold,,"I'm wondering if there is some ""nice"" version of Darboux's theorem that can be applied in the case of a symplectisation of a contact manifold $(X,\alpha)$ with the canonical symplectic form. i.e. $(\Bbb R \times X, d(e^t\alpha))$ , where $t$ is the $\Bbb R$ -parameter. More specifically, I'd like to know if we can assume that the first 2 coordinates in a Darboux neighbourhood are given by the Reeb vector field and the canonical Liouville vector field $\partial_t$ . I tried looking around but wasn't really able to find anything","I'm wondering if there is some ""nice"" version of Darboux's theorem that can be applied in the case of a symplectisation of a contact manifold with the canonical symplectic form. i.e. , where is the -parameter. More specifically, I'd like to know if we can assume that the first 2 coordinates in a Darboux neighbourhood are given by the Reeb vector field and the canonical Liouville vector field . I tried looking around but wasn't really able to find anything","(X,\alpha) (\Bbb R \times X, d(e^t\alpha)) t \Bbb R \partial_t","['differential-geometry', 'symplectic-geometry', 'contact-topology']"
87,Do people agree on what dx is in Riemann integration?,Do people agree on what dx is in Riemann integration?,,"I've been rather curious about what the official rigorous understanding of the dx term in a Riemann integral is. Of course, we could use the formal definition of a Riemann integral but I have seen on Wikipedia other proposed ways of defining the differential of some function (we'll call x), dx. The classic high school teacher approach is to say it's a ""very small change in x"", or rather a small change in a linear approximation of x. However, as someone who studies differential geometry, I am wondering how this can be interpreted as the exterior derivative of a function x, in which dx is a 1-form. Do we then reinterpret $\int{f(x)}\,dx$ as being the integral of a 1-form? And how then can we consider a 1-form to be a ""small change in x""?","I've been rather curious about what the official rigorous understanding of the dx term in a Riemann integral is. Of course, we could use the formal definition of a Riemann integral but I have seen on Wikipedia other proposed ways of defining the differential of some function (we'll call x), dx. The classic high school teacher approach is to say it's a ""very small change in x"", or rather a small change in a linear approximation of x. However, as someone who studies differential geometry, I am wondering how this can be interpreted as the exterior derivative of a function x, in which dx is a 1-form. Do we then reinterpret as being the integral of a 1-form? And how then can we consider a 1-form to be a ""small change in x""?","\int{f(x)}\,dx","['integration', 'differential-geometry', 'riemann-integration', 'differential']"
88,Extensions of diffeomorphisms from $R^3$ to $S^3$.,Extensions of diffeomorphisms from  to .,R^3 S^3,"Is there a convenient theorem about which diffeomorphisms $f: \mathbb R^3\rightarrow\mathbb  R^3$ can be extended to diffeomorphisms $\overline{f}: S^3\rightarrow S^3$ ? That is, given a diffeomorphism $f:\mathbb R^3\rightarrow\mathbb R^3$ , when does there exist an inclusion $i:\mathbb R^3\rightarrow S^3$ inducing a homeomorphism between $R^3$ and $i(\mathbb R^3)$ such that the map $\overline{f}: S^3\rightarrow S^3$ which fixes the point at infinity and is equal to $i\circ f\circ i^{-1}(x)$ for every other $x\in S^3$ is a diffeomorphism?","Is there a convenient theorem about which diffeomorphisms can be extended to diffeomorphisms ? That is, given a diffeomorphism , when does there exist an inclusion inducing a homeomorphism between and such that the map which fixes the point at infinity and is equal to for every other is a diffeomorphism?",f: \mathbb R^3\rightarrow\mathbb  R^3 \overline{f}: S^3\rightarrow S^3 f:\mathbb R^3\rightarrow\mathbb R^3 i:\mathbb R^3\rightarrow S^3 R^3 i(\mathbb R^3) \overline{f}: S^3\rightarrow S^3 i\circ f\circ i^{-1}(x) x\in S^3,['differential-geometry']
89,Show that $|α(t)|$ is a nonzero constant if and only if $α(t)$ is orthogonal to $α'(t)$ for all $t ∈ I$ .,Show that  is a nonzero constant if and only if  is orthogonal to  for all  .,|α(t)| α(t) α'(t) t ∈ I,"Let $\alpha: I → \mathbb{R^3}$ be a parametrized curve, with $α'(t) \neq 0$ for all $t \in I$ . Show that $|α(t)|$ is a nonzero constant if and only if $α(t)$ is orthogonal to $α'(t)$ for all $t ∈ I$ . my attempt: For the second implication: Suppose that $ \alpha (t) \cdot \alpha'(t) = 0 $ . I should show that $ | \alpha (t) | = C \neq 0 $ , for all $ t \in I $ , where $ C $ is a constant. Now $( | \alpha (t) |^2)' = 2 \alpha (t) \alpha'(t) = 0 $ . This implies that $ | \alpha (t)| = C$ for some constant $C$ . However I could not show that that $ C \neq 0 $ . I need suggestions for the other implication please.","Let be a parametrized curve, with for all . Show that is a nonzero constant if and only if is orthogonal to for all . my attempt: For the second implication: Suppose that . I should show that , for all , where is a constant. Now . This implies that for some constant . However I could not show that that . I need suggestions for the other implication please.",\alpha: I → \mathbb{R^3} α'(t) \neq 0 t \in I |α(t)| α(t) α'(t) t ∈ I  \alpha (t) \cdot \alpha'(t) = 0   | \alpha (t) | = C \neq 0   t \in I   C  ( | \alpha (t) |^2)' = 2 \alpha (t) \alpha'(t) = 0   | \alpha (t)| = C C  C \neq 0 ,['differential-geometry']
90,Inherited Riemannian metric on a submanifold,Inherited Riemannian metric on a submanifold,,"I am a beginner in differential geometry and I am reading chapter 1 of Differential Geometry of Loring Tu. For a smooth manifold $M$ , a Riemannian metric on $M$ is an assignment that assigns $p\in M$ to an inner product on $T_pM$ , such that for any smooth vector fields $X,Y$ on $M$ , the map $p\mapsto \langle X_p,Y_p \rangle$ is a smooth function on $M$ . Let $(M,\langle,\rangle_M)$ be a Riemannian manifold and $N$ be a submanifold. Then for each $p\in N$ , $T_pN$ is  a subspace of $T_pM$ , so we can naturally define a Riemannian metric on $N$ by letting $\langle v,w\rangle_N=\langle v,w\rangle_M$ for $v,w\in T_pN, p\in N$ . But how can we show that this Riemannian metric on $N$ satisfy the smoothness condition? I.e., for any smooth vector fields $X,Y$ on $N$ , how can we show the map $p\mapsto \langle X_p,Y_p \rangle$ is a smooth function on $N$ ?","I am a beginner in differential geometry and I am reading chapter 1 of Differential Geometry of Loring Tu. For a smooth manifold , a Riemannian metric on is an assignment that assigns to an inner product on , such that for any smooth vector fields on , the map is a smooth function on . Let be a Riemannian manifold and be a submanifold. Then for each , is  a subspace of , so we can naturally define a Riemannian metric on by letting for . But how can we show that this Riemannian metric on satisfy the smoothness condition? I.e., for any smooth vector fields on , how can we show the map is a smooth function on ?","M M p\in M T_pM X,Y M p\mapsto \langle X_p,Y_p \rangle M (M,\langle,\rangle_M) N p\in N T_pN T_pM N \langle v,w\rangle_N=\langle v,w\rangle_M v,w\in T_pN, p\in N N X,Y N p\mapsto \langle X_p,Y_p \rangle N","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
91,How does topology work when taking charts on a Psuedo-Riemannian manifold?,How does topology work when taking charts on a Psuedo-Riemannian manifold?,,"I'll first explain why I think taking charts is sane when working with Riemannian manifolds, and then show what I believe breaks down in the Pseudo-Riemannian case with a particular choice of a Pseudo Riemannian manifold (Minkowski space). I'd like to understand where I am going wrong. A Riemannian manifold is a differentiable manifold $M$ equipped with a positive definite inner product $d: T_p M \times T_p M \rightarrow \mathbb R$ . Let us concentrate attention on some chart $(U \subseteq M, \phi : U \rightarrow \mathbb R^n)$ . Here $\phi$ is a homeomorphism, hence we can ""push forward"" $d$ along $\phi$ to get some inner product structure on $\mathbb R^n$ : $d^\star: \mathbb R^n \times \mathbb R^n \rightarrow \mathbb R$ . Now since this $d^\star$ is an inner product structure, it induces a metric, which induces a topology on $\mathbb R^n$ . However (and this is the saving grace), due to equivalene of norm in a finite dimensional vector space , the topology induced by $d^\star$ will match the 'usual topology' on $\mathbb R^n$ . So the differential calculus that we do (which depends on having limits) cannot see the difference between $d^\star$ and the regular topology, and thus we can just do 'calculus on $\mathbb R^n$ ' and it transfers. Now let us look at the contrast in the Pseudo-Riemannian case. Let us assume we have Minkowski space, which is $\mathbb M \equiv (\mathbb R^4, d')$ where the manifold structure on $M \equiv \mathbb R^4$ is the 'stupid chart': we have a single chart $\phi: M \rightarrow \mathbb R^4; \phi(x) = x$ . Now, we take the bilinear form to be $d': T_p \mathbb M \times T_p \mathbb M \rightarrow \mathbb R$ as given by $d'(\mathbf p, \mathbf q) \equiv - p_0 q_0 + p_1 q_1 + p_2 q_2 + p_3 q_3$ . This is no longer positive definite! Nor is it an inner product, and this cannot even induce a norm . However, intuitively, the way $d'$ sees space is very different from the way the usual topology sees space. For example, the distance between the points $\mathbf p =(t, x, 0, 0)$ and $ \mathbf q = (x, t, 0, 0)$ is $0$ according to $d'$ but $\sqrt{2xt}$ according to the Euclidian distance. So, how is it legal for us to do things like take limits inside minkowski space? We seem to have two choices: Claim that we treat $d'$ as simply some bilinear form, while still obeying the topology of $\mathbb R^4$ . This seems really weird to me, because now the structure of the topology is no longer 'intrinsic' to the manifold + bilinear form. It is rather induced by the chart into $\mathbb R^n$ I am going wrong somewhere in my explanation above, and I'd love to know where.","I'll first explain why I think taking charts is sane when working with Riemannian manifolds, and then show what I believe breaks down in the Pseudo-Riemannian case with a particular choice of a Pseudo Riemannian manifold (Minkowski space). I'd like to understand where I am going wrong. A Riemannian manifold is a differentiable manifold equipped with a positive definite inner product . Let us concentrate attention on some chart . Here is a homeomorphism, hence we can ""push forward"" along to get some inner product structure on : . Now since this is an inner product structure, it induces a metric, which induces a topology on . However (and this is the saving grace), due to equivalene of norm in a finite dimensional vector space , the topology induced by will match the 'usual topology' on . So the differential calculus that we do (which depends on having limits) cannot see the difference between and the regular topology, and thus we can just do 'calculus on ' and it transfers. Now let us look at the contrast in the Pseudo-Riemannian case. Let us assume we have Minkowski space, which is where the manifold structure on is the 'stupid chart': we have a single chart . Now, we take the bilinear form to be as given by . This is no longer positive definite! Nor is it an inner product, and this cannot even induce a norm . However, intuitively, the way sees space is very different from the way the usual topology sees space. For example, the distance between the points and is according to but according to the Euclidian distance. So, how is it legal for us to do things like take limits inside minkowski space? We seem to have two choices: Claim that we treat as simply some bilinear form, while still obeying the topology of . This seems really weird to me, because now the structure of the topology is no longer 'intrinsic' to the manifold + bilinear form. It is rather induced by the chart into I am going wrong somewhere in my explanation above, and I'd love to know where.","M d: T_p M \times T_p M \rightarrow \mathbb R (U \subseteq M, \phi : U \rightarrow \mathbb R^n) \phi d \phi \mathbb R^n d^\star: \mathbb R^n \times \mathbb R^n \rightarrow \mathbb R d^\star \mathbb R^n d^\star \mathbb R^n d^\star \mathbb R^n \mathbb M \equiv (\mathbb R^4, d') M \equiv \mathbb R^4 \phi: M \rightarrow \mathbb R^4; \phi(x) = x d': T_p \mathbb M \times T_p \mathbb M \rightarrow \mathbb R d'(\mathbf p, \mathbf q) \equiv - p_0 q_0 + p_1 q_1 + p_2 q_2 + p_3 q_3 d' \mathbf p =(t, x, 0, 0)  \mathbf q = (x, t, 0, 0) 0 d' \sqrt{2xt} d' \mathbb R^4 \mathbb R^n","['differential-geometry', 'riemannian-geometry', 'general-relativity', 'semi-riemannian-geometry', 'special-relativity']"
92,Determining that a certain diffeomorphism of $\Bbb R^n-\{0\}$ is orientation preserving or not,Determining that a certain diffeomorphism of  is orientation preserving or not,\Bbb R^n-\{0\},"Consider the diffeomorphism $f:\Bbb R^n-\{0\} \to \Bbb R^n-\{0\}$ (whose inverse is itself) given by $x\mapsto x/|x|^2$ . How can we determine that $f$ is orientation preserving? For $n=1$ it is clearly orientation reversing, and also for $n=2$ , but it seems not easy to compute its Jacobian determinant for large $n$ , so I think there should be another method. Can I get a hint?","Consider the diffeomorphism (whose inverse is itself) given by . How can we determine that is orientation preserving? For it is clearly orientation reversing, and also for , but it seems not easy to compute its Jacobian determinant for large , so I think there should be another method. Can I get a hint?",f:\Bbb R^n-\{0\} \to \Bbb R^n-\{0\} x\mapsto x/|x|^2 f n=1 n=2 n,"['differential-geometry', 'smooth-manifolds', 'orientation', 'smooth-functions']"
93,What is a distribution,What is a distribution,,"I am studying the basics of geometrical control theory, and I am struggling with some concepts. At the moment I am studyng the concept of distribution . So far I have understood that a distribution is a law that associates to each point $x$ a subspace of the teangent space of $x$ : $$\Delta : x \rightarrow \Delta (x)\subset T_x\mathbb{R}^{n}$$ but I cannot grasp the concept. For example, if I consider a distribution: $$\Delta (x)=\begin{pmatrix} x_1 & 1\\  x_1x_3 &x_1 \\  0 &0  \end{pmatrix}$$ if I consider the definition, it should associate to each point a subspace, but what does it mean? Maybe each column of the distribution if a vector, and so a collection of vectors defines a subspace? This that I just said is just a reasoning I did, so I am not sure. Moreover, I have studied that a distribution is given by a set of independet vectors: $$\Delta (x)=\operatorname{span}[f_1(x),....,f_n(x)]$$ which I think is has to be true, otherwise they won't define a space. But I am also confused by the fact that each vectors is associated to a point, so if I take each vector by itself, I have a space with more vectors associated to points. After this, the notes of my professor start describing costant rank distributions and integrable distributions, which are hard to understand for me at this point, considering that I have not clear the concept of distribution. Can somebody please help me?","I am studying the basics of geometrical control theory, and I am struggling with some concepts. At the moment I am studyng the concept of distribution . So far I have understood that a distribution is a law that associates to each point a subspace of the teangent space of : but I cannot grasp the concept. For example, if I consider a distribution: if I consider the definition, it should associate to each point a subspace, but what does it mean? Maybe each column of the distribution if a vector, and so a collection of vectors defines a subspace? This that I just said is just a reasoning I did, so I am not sure. Moreover, I have studied that a distribution is given by a set of independet vectors: which I think is has to be true, otherwise they won't define a space. But I am also confused by the fact that each vectors is associated to a point, so if I take each vector by itself, I have a space with more vectors associated to points. After this, the notes of my professor start describing costant rank distributions and integrable distributions, which are hard to understand for me at this point, considering that I have not clear the concept of distribution. Can somebody please help me?","x x \Delta : x \rightarrow \Delta (x)\subset T_x\mathbb{R}^{n} \Delta (x)=\begin{pmatrix}
x_1 & 1\\ 
x_1x_3 &x_1 \\ 
0 &0 
\end{pmatrix} \Delta (x)=\operatorname{span}[f_1(x),....,f_n(x)]","['differential-geometry', 'dynamical-systems', 'control-theory']"
94,Reference Requiest: Representation Theory of Diffeomorphism Groups,Reference Requiest: Representation Theory of Diffeomorphism Groups,,"This wonderful and insightful Wikipedia page contains a lot of interesting facts about representations of diffeomorphism groups.  However, there are no references. In general, I'm curious if $Diff_k^p(\mathbb{R}^d)$ denotes the orientation-preserving $C^k$ -diffeomorphism group of $\mathbb{R}^d$ which stabilizes $0$ .  They claim that $Diff^{\infty}_x(\mathbb{R}^d)/Diff^{1}_x(\mathbb{R}^d)$ can be identified with $GL(\mathbb{R}^d)$ .  Where can I find this fact?  More interestingly, what can we say about $$ Diff^{\infty}_x(\mathbb{R}^d)/Diff^{k}_x(\mathbb{R}^d), $$ for $k\geq 2$ (besides it being finite-dimensional) and where can I find a nice book about these wonderful things?","This wonderful and insightful Wikipedia page contains a lot of interesting facts about representations of diffeomorphism groups.  However, there are no references. In general, I'm curious if denotes the orientation-preserving -diffeomorphism group of which stabilizes .  They claim that can be identified with .  Where can I find this fact?  More interestingly, what can we say about for (besides it being finite-dimensional) and where can I find a nice book about these wonderful things?","Diff_k^p(\mathbb{R}^d) C^k \mathbb{R}^d 0 Diff^{\infty}_x(\mathbb{R}^d)/Diff^{1}_x(\mathbb{R}^d) GL(\mathbb{R}^d) 
Diff^{\infty}_x(\mathbb{R}^d)/Diff^{k}_x(\mathbb{R}^d),
 k\geq 2","['differential-geometry', 'reference-request', 'lie-groups', 'topological-groups', 'diffeomorphism']"
95,"Left invariant metric on $SL(n,\mathbb{R}$)",Left invariant metric on ),"SL(n,\mathbb{R}","I'm vaguely familiar with the concept of invariant Riemannian metrics on Lie groups. I am mainly interested in $SL(n,\mathbb{R})$ but I guess the following is more general. To the best of my knowledge, for any Lie group $G$ there can always be chosen a left-invariant (or right) Riemannian metric (but usually not bi-invariant). Moreover, this Riemannian metric induces a left-invariant (""standard"", non Riemannian) metric $d_G$ on $G$ . My questions are: Are my statements above correct? I don't know any canonical reference for these, so I would appreciate any. Is the (non Riemannian) left invariant metric $d_G$ on $G$ unique in some sense (maybe up to equivalence or something)? $SL(n,\mathbb{R})$ is naturally embedded in $\mathbb{R}^{n^2}$ , on which all metrics are equivalent. How is the (non Riemannian) metric $d_{SL(n,\mathbb{R})}$ on $SL(n,\mathbb{R})$ relates to the metrics on $\mathbb{R}^{n^2}$ ? Is there any relation at all? Are there any interesting inequalities? Even the $n=2$ case is a starting point. I vaguely remember some identities somewhat looking like $\|M\|^2\approx \cosh d(M,I)$","I'm vaguely familiar with the concept of invariant Riemannian metrics on Lie groups. I am mainly interested in but I guess the following is more general. To the best of my knowledge, for any Lie group there can always be chosen a left-invariant (or right) Riemannian metric (but usually not bi-invariant). Moreover, this Riemannian metric induces a left-invariant (""standard"", non Riemannian) metric on . My questions are: Are my statements above correct? I don't know any canonical reference for these, so I would appreciate any. Is the (non Riemannian) left invariant metric on unique in some sense (maybe up to equivalence or something)? is naturally embedded in , on which all metrics are equivalent. How is the (non Riemannian) metric on relates to the metrics on ? Is there any relation at all? Are there any interesting inequalities? Even the case is a starting point. I vaguely remember some identities somewhat looking like","SL(n,\mathbb{R}) G d_G G d_G G SL(n,\mathbb{R}) \mathbb{R}^{n^2} d_{SL(n,\mathbb{R})} SL(n,\mathbb{R}) \mathbb{R}^{n^2} n=2 \|M\|^2\approx \cosh d(M,I)","['differential-geometry', 'reference-request', 'metric-spaces', 'lie-groups', 'riemannian-geometry']"
96,Are exotic $\mathbb{R}^4$ flat?,Are exotic  flat?,\mathbb{R}^4,$\mathbb{R}^4$ can be given two different differential structures which are not diffeomorphic. The standard $\mathbb{R}^4$ with its common differential structure can be given a metric in which its Riemann tensor is zero everywhere. Do exotic differential structures also admit a metric with Riemann tensor vanishing everywhere?,can be given two different differential structures which are not diffeomorphic. The standard with its common differential structure can be given a metric in which its Riemann tensor is zero everywhere. Do exotic differential structures also admit a metric with Riemann tensor vanishing everywhere?,\mathbb{R}^4 \mathbb{R}^4,"['differential-geometry', 'differential-topology']"
97,Proof of geodesic has constant speed,Proof of geodesic has constant speed,,"So I'm working with differential geometry. So my book claim that ""any geodesic has constant speed"" . And the proof is left as an exercise and I found the exercise in the book. Exercise: ""Prove that any geodesic has constant speed and so a very simple unit-speed reparametrization."" I know the definition of geodesic, but I don't know how to work it out. Thanks in advance Edit: The definition, ""Let $\gamma$ be a curve on a surface $\textbf{S}$ . Then the curve is called a $\textit{geodesic}$ if $\ddot{\gamma}$ is zero or orthogonal to the tangent plane of the surface at the point $\gamma$ .""","So I'm working with differential geometry. So my book claim that ""any geodesic has constant speed"" . And the proof is left as an exercise and I found the exercise in the book. Exercise: ""Prove that any geodesic has constant speed and so a very simple unit-speed reparametrization."" I know the definition of geodesic, but I don't know how to work it out. Thanks in advance Edit: The definition, ""Let be a curve on a surface . Then the curve is called a if is zero or orthogonal to the tangent plane of the surface at the point .""",\gamma \textbf{S} \textit{geodesic} \ddot{\gamma} \gamma,"['differential-geometry', 'curves', 'geodesic']"
98,Exercise 5.20 from John Lee's ISM. Every open subset of a immersed submanifold $S$ in the subspace topology is also open in the submanifold topology,Exercise 5.20 from John Lee's ISM. Every open subset of a immersed submanifold  in the subspace topology is also open in the submanifold topology,S,"This is Exercise 5.20 from John Lee's ISM. The text says this is simply an observation but I'm having trouble proving this fact. Suppose $M$ is a smooth manifold and $S \subset M$ is an immersed submanifold. Show that every subset of $S$ that is open in the subspace topology is also open in its given submanifold topology; and the converse is true if and only if $S$ is embedded. $S\subset M$ immersed submanifold means that $S$ is endowed with a topology (call it the submanifold topology) and a smooth structure in which the inclusion map $S \hookrightarrow M$ is a smooth immersion. Since the subspace topology is the coarsest topology in which the inclusion map is continuous, and smooth maps are continuous the first fact follows. However, I am not sure how to show that the submanifold topology is contained in the subspace topology only if $S$ is embedded.","This is Exercise 5.20 from John Lee's ISM. The text says this is simply an observation but I'm having trouble proving this fact. Suppose is a smooth manifold and is an immersed submanifold. Show that every subset of that is open in the subspace topology is also open in its given submanifold topology; and the converse is true if and only if is embedded. immersed submanifold means that is endowed with a topology (call it the submanifold topology) and a smooth structure in which the inclusion map is a smooth immersion. Since the subspace topology is the coarsest topology in which the inclusion map is continuous, and smooth maps are continuous the first fact follows. However, I am not sure how to show that the submanifold topology is contained in the subspace topology only if is embedded.",M S \subset M S S S\subset M S S \hookrightarrow M S,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
99,$\mathbb{S}^1$-action over $T^2$ is symplectic but not Hamiltonian,-action over  is symplectic but not Hamiltonian,\mathbb{S}^1 T^2,"I've read the following assertion in Ana Cannas' Lectures in Symplectic Manifolds : ""On the $2$ -torus $(T^2,d\theta_1\wedge d\theta_2)$ , the vector fields $X_1=\frac{\partial}{\partial\theta_1}$ and $X_2=\frac{\partial}{\partial\theta_2}$ are symplectic but not Hamiltonian."" Here's my attempt to prove it. I'm used to writing $T^2=\mathbb{R}^2/\mathbb{Z}^2$ , so I'll use $x,y$ for the coordinates and the symplectic form will be $dx\wedge dy$ . Clearly the flows for $X_1,X_2$ are $\phi_t^1(x,y)=(x+t,y)$ and $\phi_t^2(x,y)=(x,y+t)$ respectively, so $(\phi_t^1)^*(dx\wedge dy)=d(x+t)\wedge dy=dx\wedge dy$ and $(\phi_t^2)^*(dx\wedge dy)=dx\wedge dy$ . This means that both $X_1,X_2$ are symplectic. On the other hand, $i_{X_1}(dx\wedge dy)=dy$ and $i_{X_2}(dx\wedge dy)=dx$ , so it looks like both are also Hamiltonian. I guess what I'm doing wrong is that $dx,dy$ are perfectly ok in $\mathbb{R}^2$ but not in $T^2$ because of the quotient by $\mathbb{Z}^2$ . But in that case, is the first argument with the pullbacks also wrong?","I've read the following assertion in Ana Cannas' Lectures in Symplectic Manifolds : ""On the -torus , the vector fields and are symplectic but not Hamiltonian."" Here's my attempt to prove it. I'm used to writing , so I'll use for the coordinates and the symplectic form will be . Clearly the flows for are and respectively, so and . This means that both are symplectic. On the other hand, and , so it looks like both are also Hamiltonian. I guess what I'm doing wrong is that are perfectly ok in but not in because of the quotient by . But in that case, is the first argument with the pullbacks also wrong?","2 (T^2,d\theta_1\wedge d\theta_2) X_1=\frac{\partial}{\partial\theta_1} X_2=\frac{\partial}{\partial\theta_2} T^2=\mathbb{R}^2/\mathbb{Z}^2 x,y dx\wedge dy X_1,X_2 \phi_t^1(x,y)=(x+t,y) \phi_t^2(x,y)=(x,y+t) (\phi_t^1)^*(dx\wedge dy)=d(x+t)\wedge dy=dx\wedge dy (\phi_t^2)^*(dx\wedge dy)=dx\wedge dy X_1,X_2 i_{X_1}(dx\wedge dy)=dy i_{X_2}(dx\wedge dy)=dx dx,dy \mathbb{R}^2 T^2 \mathbb{Z}^2","['differential-geometry', 'group-actions', 'symplectic-geometry']"
