,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Show that $\lim\limits_{n \to \infty} \frac{(n!)^{1/n}}{n}= \frac{1}{e}$ [duplicate],Show that  [duplicate],\lim\limits_{n \to \infty} \frac{(n!)^{1/n}}{n}= \frac{1}{e},"This question already has answers here : Finding the limit of $\frac {n}{\sqrt[n]{n!}}$ (11 answers) Closed 9 years ago . Show that $$\lim_{n \to \infty} \left\{\frac{(n!)^{1/n}}{n}\right\} = \frac{1}{e}$$ What I did is to let $U_n = \dfrac{(n!)^{\frac{1}{n}}}{n}$ and  $U_{n+1} = \dfrac{(n+1)!^{\frac{1}{n+1}}}{n+1}$. Then $$\frac{ U_{n+1} }{U_n } = \frac{\frac{(n+1)!^{\frac{1}{n+1}}}{n+1}}{\frac{(n!)^{\frac{1}{n}}}{n}}$$ Next I just got stuck. Am I on the right track, or am I wrong doing this type of sequence?","This question already has answers here : Finding the limit of $\frac {n}{\sqrt[n]{n!}}$ (11 answers) Closed 9 years ago . Show that $$\lim_{n \to \infty} \left\{\frac{(n!)^{1/n}}{n}\right\} = \frac{1}{e}$$ What I did is to let $U_n = \dfrac{(n!)^{\frac{1}{n}}}{n}$ and  $U_{n+1} = \dfrac{(n+1)!^{\frac{1}{n+1}}}{n+1}$. Then $$\frac{ U_{n+1} }{U_n } = \frac{\frac{(n+1)!^{\frac{1}{n+1}}}{n+1}}{\frac{(n!)^{\frac{1}{n}}}{n}}$$ Next I just got stuck. Am I on the right track, or am I wrong doing this type of sequence?",,"['real-analysis', 'sequences-and-series', 'limits', 'factorial', 'radicals']"
1,Limit of $\lim\limits_{n\to\infty} (1 + \frac{x_n}{n})^n$,Limit of,\lim\limits_{n\to\infty} (1 + \frac{x_n}{n})^n,"Many websites and calculus books give this well known result \begin{equation} \lim\limits_{n\to\infty} \left(1 + \frac{x}{n}\right)^n = e^x \end{equation} However, a textbook I was reading casually mentioned that if $x_n \rightarrow x$ then  \begin{equation} \lim\limits_{n\to\infty} \left(1 + \frac{x_n}{n}\right)^n = e^x \end{equation} Why is this true? It seems very intuitive but I feel some explanation is missing. Thank you!","Many websites and calculus books give this well known result \begin{equation} \lim\limits_{n\to\infty} \left(1 + \frac{x}{n}\right)^n = e^x \end{equation} However, a textbook I was reading casually mentioned that if $x_n \rightarrow x$ then  \begin{equation} \lim\limits_{n\to\infty} \left(1 + \frac{x_n}{n}\right)^n = e^x \end{equation} Why is this true? It seems very intuitive but I feel some explanation is missing. Thank you!",,"['calculus', 'real-analysis', 'sequences-and-series', 'limits']"
2,Show that: $\lim\limits_{r\to\infty}\int\limits_{0}^{\pi/2}e^{-r\sin \theta}\text d\theta=0$,Show that:,\lim\limits_{r\to\infty}\int\limits_{0}^{\pi/2}e^{-r\sin \theta}\text d\theta=0,"I would like to show $\lim\limits_{r\to\infty}\int_{0}^{\pi/2}e^{-r\sin \theta}\text d\theta=0$ . Now, of course, the integrand does not converge uniformly to $0$ on $\theta\in [0, \pi/2]$ , since it has value $1$ at $\theta =0$ for all $r\in \mathbb{R}$ . If $F(r) = \int_{0}^{\pi/2}e^{-r\sin \theta}\text d\theta$ , we can find the $j$ th derivative $F^{(j)}(r) = (-1)^j\int_{0}^{\pi/2}\sin^{j}(\theta)e^{-r\sin\theta}\text d\theta$ , but I don't see how this is helping. The function is strictly decreasing on $[0,\pi/2]$ , since $\partial_{\theta}(e^{-r\sin\theta})=-r\cos\theta e^{-r\sin \theta}$ , which is strictly negative on $(0,\pi/2)$ . Any ideas?","I would like to show . Now, of course, the integrand does not converge uniformly to on , since it has value at for all . If , we can find the th derivative , but I don't see how this is helping. The function is strictly decreasing on , since , which is strictly negative on . Any ideas?","\lim\limits_{r\to\infty}\int_{0}^{\pi/2}e^{-r\sin \theta}\text d\theta=0 0 \theta\in [0, \pi/2] 1 \theta =0 r\in \mathbb{R} F(r) = \int_{0}^{\pi/2}e^{-r\sin \theta}\text d\theta j F^{(j)}(r) = (-1)^j\int_{0}^{\pi/2}\sin^{j}(\theta)e^{-r\sin\theta}\text d\theta [0,\pi/2] \partial_{\theta}(e^{-r\sin\theta})=-r\cos\theta e^{-r\sin \theta} (0,\pi/2)","['calculus', 'real-analysis', 'integration', 'complex-analysis', 'limits']"
3,What are the real-world applications of real analysis?,What are the real-world applications of real analysis?,,"I've read the wikipedia article on mathematical analysis and this , but I can't exactly find an answer. Is real analysis just some pure math, or does it really have something to with physical applications? Feel free to send me any references that might answer my question, thanks!","I've read the wikipedia article on mathematical analysis and this , but I can't exactly find an answer. Is real analysis just some pure math, or does it really have something to with physical applications? Feel free to send me any references that might answer my question, thanks!",,"['real-analysis', 'reference-request', 'soft-question', 'applications']"
4,What is the point of nuking this mosquito in Real Analysis by Shakarchi and Stein?,What is the point of nuking this mosquito in Real Analysis by Shakarchi and Stein?,,"I have tried to read volume 3 of Shakarchi and Stein more than a few times now and I keep getting stuck in chapter one in the same place . After going through a bunch of basic concepts from analysis we finally come to a lemma, which says that if a given rectangle is the almost disjoint union of other rectangles, then the area of the given rectangle is equal to the sum of the area of the inner rectangles.  Ok duh. So at this point I assume we are going to have a rigorous proof which is going to explain why drawing lines of area 0 in a rectangle doesn't decrease the area of the rectangle.  Unfortunately the first sentence of the proof is ""we consider the grid formed by extending the sides of all rectangles indefinitely."" Is that supposed to be rigorous? I can think of three different ways to extend the sides of all the inner rectangles indefinitely, and I still can't figure out which one they mean because the picture is pretty strange, and so now I figure I am wrong about why the authors feel the need to prove such an obvious statement. The next sentence is ""This construction yields finitely many rectangles...and a partition of the integers between 1 and M"".  I'm sorry, but is this a joke, or is this just a weak part of the book that I should skip over? By the end of the proof I am left very confused as to what the point of this section is.  Can someone please explain what I am missing here? Thanks!","I have tried to read volume 3 of Shakarchi and Stein more than a few times now and I keep getting stuck in chapter one in the same place . After going through a bunch of basic concepts from analysis we finally come to a lemma, which says that if a given rectangle is the almost disjoint union of other rectangles, then the area of the given rectangle is equal to the sum of the area of the inner rectangles.  Ok duh. So at this point I assume we are going to have a rigorous proof which is going to explain why drawing lines of area 0 in a rectangle doesn't decrease the area of the rectangle.  Unfortunately the first sentence of the proof is ""we consider the grid formed by extending the sides of all rectangles indefinitely."" Is that supposed to be rigorous? I can think of three different ways to extend the sides of all the inner rectangles indefinitely, and I still can't figure out which one they mean because the picture is pretty strange, and so now I figure I am wrong about why the authors feel the need to prove such an obvious statement. The next sentence is ""This construction yields finitely many rectangles...and a partition of the integers between 1 and M"".  I'm sorry, but is this a joke, or is this just a weak part of the book that I should skip over? By the end of the proof I am left very confused as to what the point of this section is.  Can someone please explain what I am missing here? Thanks!",,['real-analysis']
5,"Conjecture: $\,\lim\limits_{n\to\infty}\int_0^1 (1+|\sin{nx}|)^{-2}\mathrm dx=\frac{4}{3\pi}$",Conjecture:,"\,\lim\limits_{n\to\infty}\int_0^1 (1+|\sin{nx}|)^{-2}\mathrm dx=\frac{4}{3\pi}","I was playing with integrals, and came up with $$L=\lim_{n\to\infty}\int_0^1 \frac{1}{(1+|\sin (nx)|)^2}dx.$$ Conjecture: $L=\dfrac{4}{3\pi}$ Is my conjecture true? Remarks on numerical investigation: Desmos and Wolfram don't do a good job with numerical investigation of this limit, but we can consider the series $f(n)=\dfrac{1}{n}\sum\limits_{k=1}^n \dfrac{1}{(1+|\sin{k}|)^2}$ . $f(10^3)\approx0.999568\left(\frac{4}{3\pi}\right)$ $f(10^6)\approx0.999999635\left(\frac{4}{3\pi}\right)$ $f(10^9)\approx0.999999999807\left(\frac{4}{3\pi}\right)$ This suggests that $\lim\limits_{n\to\infty}f(n)=\frac{4}{3\pi}$ . Using Riemann sums, we have $\lim\limits_{n\to\infty}f(n)=L$ . My attempt: I tried to use $\,\sin nx = \dfrac{1}{2i}(e^{nxi}-e^{-nxi})\,$ in $\;\displaystyle\int_0^1 \dfrac{1}{(1+|\sin (nx)|)^2}\,\mathrm dx\;,\;\;$ to no avail. I also tried to use complex numbers in the series $f(n)$ , as in answers to a question about $\sum_{n=1}^{\infty} \frac{\cos (n)}{n}$ , to no avail.","I was playing with integrals, and came up with Conjecture: Is my conjecture true? Remarks on numerical investigation: Desmos and Wolfram don't do a good job with numerical investigation of this limit, but we can consider the series . This suggests that . Using Riemann sums, we have . My attempt: I tried to use in to no avail. I also tried to use complex numbers in the series , as in answers to a question about , to no avail.","L=\lim_{n\to\infty}\int_0^1 \frac{1}{(1+|\sin (nx)|)^2}dx. L=\dfrac{4}{3\pi} f(n)=\dfrac{1}{n}\sum\limits_{k=1}^n \dfrac{1}{(1+|\sin{k}|)^2} f(10^3)\approx0.999568\left(\frac{4}{3\pi}\right) f(10^6)\approx0.999999635\left(\frac{4}{3\pi}\right) f(10^9)\approx0.999999999807\left(\frac{4}{3\pi}\right) \lim\limits_{n\to\infty}f(n)=\frac{4}{3\pi} \lim\limits_{n\to\infty}f(n)=L \,\sin nx = \dfrac{1}{2i}(e^{nxi}-e^{-nxi})\, \;\displaystyle\int_0^1 \dfrac{1}{(1+|\sin (nx)|)^2}\,\mathrm dx\;,\;\; f(n) \sum_{n=1}^{\infty} \frac{\cos (n)}{n}","['real-analysis', 'sequences-and-series', 'limits', 'definite-integrals', 'conjectures']"
6,Find $f^{(n)}(1)$ on $f(x)=(1+\sqrt{x})^{2n+2}$,Find  on,f^{(n)}(1) f(x)=(1+\sqrt{x})^{2n+2},Find $f^{(n)}(1)$ on $f(x)=(1+\sqrt{x})^{2n+2}$ . Here is a solution by someone: \begin{align*} f(x)&=(1+\sqrt{x})^{2n+2}=\sum_{k=0}^{2n+2}\binom{2n+2}{k}x^{\frac{k}{2}}\\ &=\sum_{k=0}^{2n+2}\binom{2n+2}{k}\sum_{j=0}^{\infty}\binom{\frac{k}{2}}{j}(x-1)^j\\ &=\sum_{j=0}^{\infty}\sum_{k=0}^{2n+2}\binom{2n+2}{k}\binom{\frac{k}{2}}{j}(x-1)^j. \end{align*} Hence \begin{align*} f^{(n)}(1)&=n!\sum_{k=0}^{2n+2}\binom{2n+2}{k}\binom{\frac{k}{2}}{n}=n!\cdot4(n+1)^2. \end{align*} Is it correct? How to compute $$n!\sum_{k=0}^{2n+2}\binom{2n+2}{k}\binom{\frac{k}{2}}{n}=n!\cdot4(n+1)^2?$$,Find on . Here is a solution by someone: Hence Is it correct? How to compute,f^{(n)}(1) f(x)=(1+\sqrt{x})^{2n+2} \begin{align*} f(x)&=(1+\sqrt{x})^{2n+2}=\sum_{k=0}^{2n+2}\binom{2n+2}{k}x^{\frac{k}{2}}\\ &=\sum_{k=0}^{2n+2}\binom{2n+2}{k}\sum_{j=0}^{\infty}\binom{\frac{k}{2}}{j}(x-1)^j\\ &=\sum_{j=0}^{\infty}\sum_{k=0}^{2n+2}\binom{2n+2}{k}\binom{\frac{k}{2}}{j}(x-1)^j. \end{align*} \begin{align*} f^{(n)}(1)&=n!\sum_{k=0}^{2n+2}\binom{2n+2}{k}\binom{\frac{k}{2}}{n}=n!\cdot4(n+1)^2. \end{align*} n!\sum_{k=0}^{2n+2}\binom{2n+2}{k}\binom{\frac{k}{2}}{n}=n!\cdot4(n+1)^2?,"['real-analysis', 'calculus', 'derivatives', 'solution-verification']"
7,Limit exists with definition but not with polar coordinates,Limit exists with definition but not with polar coordinates,,"I would like to know why if I try to prove with the delta epsilon definition that the limit as $(x,y)$ tends to $(0,0)$ is $0$ of this function: $$\frac{x^2 +y}{\sqrt{x^2+y^2}}$$ I get a positive result: for $\delta = \varepsilon -1$ , I get that $|f(x,y)-0|$ is less than $\varepsilon$ . But if you evaluate the limit with polar coordinates, you get that the limit depends on the path, and thus it doesn't exist.","I would like to know why if I try to prove with the delta epsilon definition that the limit as tends to is of this function: I get a positive result: for , I get that is less than . But if you evaluate the limit with polar coordinates, you get that the limit depends on the path, and thus it doesn't exist.","(x,y) (0,0) 0 \frac{x^2 +y}{\sqrt{x^2+y^2}} \delta = \varepsilon -1 |f(x,y)-0| \varepsilon","['real-analysis', 'limits', 'multivariable-calculus', 'polar-coordinates', 'epsilon-delta']"
8,Do there exist inner product spaces for families of real valued functions other than weighted integrals?,Do there exist inner product spaces for families of real valued functions other than weighted integrals?,,"In transform theory we join linear algebra with analysis by defining scalar products for real valued functions with weighted integrals of products, for example: $$\langle f,g\rangle_w = \int_{-\infty}^{\infty} w(t)f(t)g(t)dt$$ And in multiple dimensions as multivariate integrals: $$\langle f,g\rangle_w = \int\cdots\int_{-\infty}^{\infty} w(t_1,\cdots,t_k)f(t_1,\cdots,t_k)g(t_1,\cdots,t_k)dt_1 \cdots dt_k$$ To my question, does there exist other ways to define inner products for families of real valued functions?","In transform theory we join linear algebra with analysis by defining scalar products for real valued functions with weighted integrals of products, for example: And in multiple dimensions as multivariate integrals: To my question, does there exist other ways to define inner products for families of real valued functions?","\langle f,g\rangle_w = \int_{-\infty}^{\infty} w(t)f(t)g(t)dt \langle f,g\rangle_w = \int\cdots\int_{-\infty}^{\infty} w(t_1,\cdots,t_k)f(t_1,\cdots,t_k)g(t_1,\cdots,t_k)dt_1 \cdots dt_k","['real-analysis', 'linear-algebra', 'reference-request', 'soft-question', 'inner-products']"
9,prove $\ln(1+x^2)\arctan x=-2\sum_{n=1}^\infty \frac{(-1)^n H_{2n}}{2n+1}x^{2n+1}$,prove,\ln(1+x^2)\arctan x=-2\sum_{n=1}^\infty \frac{(-1)^n H_{2n}}{2n+1}x^{2n+1},I was able to prove the above identity using 1) Cauchy Product of Power series and 2) integration but the point of posting it here is to use it as a reference in our solutions. other approaches would be appreciated.,I was able to prove the above identity using 1) Cauchy Product of Power series and 2) integration but the point of posting it here is to use it as a reference in our solutions. other approaches would be appreciated.,,"['real-analysis', 'calculus', 'generating-functions', 'closed-form', 'harmonic-numbers']"
10,Calculate $\sum_{n=0}^\infty \frac1{(4n^2 - 1)^2}$,Calculate,\sum_{n=0}^\infty \frac1{(4n^2 - 1)^2},"How do I find the value of the following infinite series? $$\sum_{n=0}^\infty \frac{1}{(4n^2-1)^2} $$ My attempt at a solution: $$\sum_{n=0}^\infty \frac{1}{(4n^2-1)^2} = \sum_{n=0}^\infty \frac{1}{((2n-1)(2n+1))^2} = \sum_{n=0}^\infty \left(\frac{1}{2}\left(\frac{1}{(2n-1)}-\frac{1}{(2n+1)}\right)\right)^2  = \frac{1}{4}\sum_{n=0}^\infty \left(\frac{1}{2n-1}-\frac{1}{2n+1}\right)^2 $$ I then tried to compute the partial sums of this series, but with no luck. Does anyone else know how to do it?","How do I find the value of the following infinite series? My attempt at a solution: I then tried to compute the partial sums of this series, but with no luck. Does anyone else know how to do it?",\sum_{n=0}^\infty \frac{1}{(4n^2-1)^2}  \sum_{n=0}^\infty \frac{1}{(4n^2-1)^2} = \sum_{n=0}^\infty \frac{1}{((2n-1)(2n+1))^2} = \sum_{n=0}^\infty \left(\frac{1}{2}\left(\frac{1}{(2n-1)}-\frac{1}{(2n+1)}\right)\right)^2  = \frac{1}{4}\sum_{n=0}^\infty \left(\frac{1}{2n-1}-\frac{1}{2n+1}\right)^2 ,"['real-analysis', 'sequences-and-series']"
11,Prove that inequality $1+\frac{1}{2\sqrt{2}}+...+\frac{1}{n\sqrt{n}}<2\sqrt{2}$,Prove that inequality,1+\frac{1}{2\sqrt{2}}+...+\frac{1}{n\sqrt{n}}<2\sqrt{2},Let $n$ is a natural number. Prove that inequality $$1+\frac{1}{2\sqrt{2}}+\frac{1}{3\sqrt{3}}+...+\frac{1}{n\sqrt{n}}<2\sqrt{2}$$ My try: $$\frac{1}{n\sqrt{n}}=\frac{\sqrt{n}}{n^2}<\frac{\sqrt{n}}{n\left(n-1\right)}=\sqrt{n}\left(\frac{1}{n}-\frac{1}{n-1}\right)=\left(\frac{1}{\sqrt{n}}-\frac{1}{\sqrt{n-1}}\right)\left(\frac{\sqrt{n}+\sqrt{n-1}}{\sqrt{n-1}}\right)<\frac{1}{\sqrt{n}}-\frac{1}{\sqrt{n-1}}$$ Please check my solution for me and give me some idea.,Let $n$ is a natural number. Prove that inequality $$1+\frac{1}{2\sqrt{2}}+\frac{1}{3\sqrt{3}}+...+\frac{1}{n\sqrt{n}}<2\sqrt{2}$$ My try: $$\frac{1}{n\sqrt{n}}=\frac{\sqrt{n}}{n^2}<\frac{\sqrt{n}}{n\left(n-1\right)}=\sqrt{n}\left(\frac{1}{n}-\frac{1}{n-1}\right)=\left(\frac{1}{\sqrt{n}}-\frac{1}{\sqrt{n-1}}\right)\left(\frac{\sqrt{n}+\sqrt{n-1}}{\sqrt{n-1}}\right)<\frac{1}{\sqrt{n}}-\frac{1}{\sqrt{n-1}}$$ Please check my solution for me and give me some idea.,,"['real-analysis', 'inequality', 'radicals', 'harmonic-functions', 'telescopic-series']"
12,Showing a function has exactly one zero with IVT and Rolle's Theorem,Showing a function has exactly one zero with IVT and Rolle's Theorem,,"This is an exercise that appears on differential calculus exams at my university. I'm typing up a thorough response to this exercise here to share with my class, and maybe it'll help other students too. Let $f$ be the function given by $$f(x) = 3x -2\sin(x)+7\,.$$ Use the Intermediate Value Theorem to show that $f$ has at least one zero, and then use the Mean Value Theorem to show $f$ has exactly one zero. See the sidebar under the Linked header for similar questions. ​ ​ ​ ​ ​ ​ ​","This is an exercise that appears on differential calculus exams at my university. I'm typing up a thorough response to this exercise here to share with my class, and maybe it'll help other students too. Let be the function given by Use the Intermediate Value Theorem to show that has at least one zero, and then use the Mean Value Theorem to show has exactly one zero. See the sidebar under the Linked header for similar questions. ​ ​ ​ ​ ​ ​ ​","f f(x) = 3x -2\sin(x)+7\,. f f","['calculus', 'real-analysis', 'roots', 'rolles-theorem']"
13,Why is the upper Riemann integral the infimum of all upper sums?,Why is the upper Riemann integral the infimum of all upper sums?,,"I was reading the theory of Riemann integration when I cam across the following , If $f$ is bounded on $[a,b]$ , and $P = \{x_0,x_1,x_2.......x_n\}$ is a partition of $[a,b]$ , let $$M_j = \sup_{x_{j-1}\leq x\leq x_j}f(x)$$ The upper sum of f over P is $$S(P) = \sum_{j=1}^{n} M_j(x_j-x_{j-1})$$ and the upper integral of $f$ over $[a,b]$ , denoted by $$\int_{a}^{b^-} f(x)dx$$ is the infimum of all upper sums. The theorem similarly goes on to state the result for lower sums. My doubt is : I do not understand how is $$\int_{a}^{b^-} f(x)dx$$ the infimum of all upper sums. I understand that if we refine the partition P, then the upper sum would decrease, so it may be a lower limit for all the upper sums computed on the refinements of P (but still being the lower limit does not prove that it is the infimum) and what about those partitions for which P itself is the refinement of?  How do I know that it will be a lower limit for those, let alone a infimum?","I was reading the theory of Riemann integration when I cam across the following , If is bounded on , and is a partition of , let The upper sum of f over P is and the upper integral of over , denoted by is the infimum of all upper sums. The theorem similarly goes on to state the result for lower sums. My doubt is : I do not understand how is the infimum of all upper sums. I understand that if we refine the partition P, then the upper sum would decrease, so it may be a lower limit for all the upper sums computed on the refinements of P (but still being the lower limit does not prove that it is the infimum) and what about those partitions for which P itself is the refinement of?  How do I know that it will be a lower limit for those, let alone a infimum?","f [a,b] P = \{x_0,x_1,x_2.......x_n\} [a,b] M_j = \sup_{x_{j-1}\leq x\leq x_j}f(x) S(P) = \sum_{j=1}^{n} M_j(x_j-x_{j-1}) f [a,b] \int_{a}^{b^-} f(x)dx \int_{a}^{b^-} f(x)dx","['real-analysis', 'riemann-integration']"
14,Are continuous functions with compact support bounded?,Are continuous functions with compact support bounded?,,While studying measure theory I came across the following fact: $\mathcal{K}(X) \subset C_b(X)$ (meaning the continuous functions with compact support are a subset of the bounded continuous functions). This seems somehow odd to me; I've tried to prove it but did not succeed. Could someone help me out here? Thanks!,While studying measure theory I came across the following fact: $\mathcal{K}(X) \subset C_b(X)$ (meaning the continuous functions with compact support are a subset of the bounded continuous functions). This seems somehow odd to me; I've tried to prove it but did not succeed. Could someone help me out here? Thanks!,,"['real-analysis', 'general-topology', 'functional-analysis', 'measure-theory']"
15,"If $f$ is uniformly continuous on $(a, b)$, then $f$ is bounded on $(a, b)$.","If  is uniformly continuous on , then  is bounded on .","f (a, b) f (a, b)","So I know that since $f$ is uniformly continuous on $(a,b)$, then for every  $\varepsilon > 0$, there exists $\delta > 0$ such that for all $x$ and $y$ in $(a,b)$,  if $\,\lvert x - y\rvert < \delta$, then $\,\lvert\,f(x) - f(y)\rvert < \varepsilon$. I also know that I need to show that there are some numbers $M$, $N$, so that  $M ≤ f(x) ≤ N$, for all $x$ and $y$ in $(a,b)$. It makes logical sense to me because it means that for every x and y that you pick, the function values can only jump by epsilon, so there would be no way for the function suddenly approach infinity at the endpoints. However, I don't know really how to make a rigorous argument. I was thinking that maybe I could do something by contradiction, like saying that $f(y)>N$, but $f(x)<N$, and then somehow showing that this jump is now greater than  $\varepsilon$, but I'm not sure that would really work since we only have an arbitrary function with arbitrary bounds.","So I know that since $f$ is uniformly continuous on $(a,b)$, then for every  $\varepsilon > 0$, there exists $\delta > 0$ such that for all $x$ and $y$ in $(a,b)$,  if $\,\lvert x - y\rvert < \delta$, then $\,\lvert\,f(x) - f(y)\rvert < \varepsilon$. I also know that I need to show that there are some numbers $M$, $N$, so that  $M ≤ f(x) ≤ N$, for all $x$ and $y$ in $(a,b)$. It makes logical sense to me because it means that for every x and y that you pick, the function values can only jump by epsilon, so there would be no way for the function suddenly approach infinity at the endpoints. However, I don't know really how to make a rigorous argument. I was thinking that maybe I could do something by contradiction, like saying that $f(y)>N$, but $f(x)<N$, and then somehow showing that this jump is now greater than  $\varepsilon$, but I'm not sure that would really work since we only have an arbitrary function with arbitrary bounds.",,"['real-analysis', 'continuity', 'metric-spaces', 'epsilon-delta', 'uniform-continuity']"
16,Example of a smooth 'step'-function that is constant below 0 and constant above 1,Example of a smooth 'step'-function that is constant below 0 and constant above 1,,"I need an infinitely smooth non-decreasing function $\ f(x)$, that $$f(x)=0\quad\forall x\leq 0,$$ $$f(x)=1\quad\forall x\geq 1,$$ and all its derivatives in $x=0$ and $x=1$ are $0$. I found that I can't present any such function, what makes me confused. I know many examples of smooth finite hat-function, such as $e^{1/{(x-1)x}}$, but I still can't make it useful to create that step.","I need an infinitely smooth non-decreasing function $\ f(x)$, that $$f(x)=0\quad\forall x\leq 0,$$ $$f(x)=1\quad\forall x\geq 1,$$ and all its derivatives in $x=0$ and $x=1$ are $0$. I found that I can't present any such function, what makes me confused. I know many examples of smooth finite hat-function, such as $e^{1/{(x-1)x}}$, but I still can't make it useful to create that step.",,"['real-analysis', 'functions', 'examples-counterexamples', 'distribution-theory', 'smooth-functions']"
17,Use $\epsilon-\delta$ definition of limit to prove that $\displaystyle \lim_{x \to 0} x \lfloor \frac{1}{x} \rfloor = 1$. [duplicate],Use  definition of limit to prove that . [duplicate],\epsilon-\delta \displaystyle \lim_{x \to 0} x \lfloor \frac{1}{x} \rfloor = 1,"This question already has answers here : How to find limit of function: $\lim_{x\to 0}\left(x{{\left\lfloor{ \frac{1}{x}} \right\rfloor}}\right)$ [duplicate] (3 answers) Closed 2 years ago . I was trying to write some nice problems for applying $\epsilon-\delta$ definition to give it to my friend but then I realized that I couldn't solve some of them either. This is one of them: Use $\epsilon-\delta$ definition of limit to prove that $$ \lim_{x \to 0} x \lfloor \frac{1}{x} \rfloor = 1$$ It's easy to show that this is true by using the squeeze(sandwich) theorem, but I'm looking for an $\epsilon-\delta$ proof. Also, a similar problem could be: $$ \lim_{n \to \infty} \frac{[nx]}{n}=x$$ Again it's obvious that this is true by using the squeeze theorem, but I'm looking for an elementary proof that uses nothing but just the definition of the limit of a sequence.","This question already has answers here : How to find limit of function: $\lim_{x\to 0}\left(x{{\left\lfloor{ \frac{1}{x}} \right\rfloor}}\right)$ [duplicate] (3 answers) Closed 2 years ago . I was trying to write some nice problems for applying $\epsilon-\delta$ definition to give it to my friend but then I realized that I couldn't solve some of them either. This is one of them: Use $\epsilon-\delta$ definition of limit to prove that $$ \lim_{x \to 0} x \lfloor \frac{1}{x} \rfloor = 1$$ It's easy to show that this is true by using the squeeze(sandwich) theorem, but I'm looking for an $\epsilon-\delta$ proof. Also, a similar problem could be: $$ \lim_{n \to \infty} \frac{[nx]}{n}=x$$ Again it's obvious that this is true by using the squeeze theorem, but I'm looking for an elementary proof that uses nothing but just the definition of the limit of a sequence.",,"['calculus', 'real-analysis']"
18,Proof $\mathbb{R}^n$ is a complete metric space.,Proof  is a complete metric space.,\mathbb{R}^n,"$\mathbb{R}^n$ is a complete metric space. Consider a Cauchy sequence $\{\mathbf{x}_k\}$ in $\mathbb{R}^n$ , we want to show it converges to a point $\mathbf{x} \in \mathbb{R}^n$ . That is to say, if $|\mathbf{x - x_k}| \to 0$ as $k \to \infty$ . Hence, we let $\epsilon \to 0$ , and we get $\mathbf{|x_k - x_j|} < \epsilon$ by Cauchy sequence, and let $\mathbf{x = x_j}$ we showed the desired result. Definition $\mathbb{R}^n$ is a complete metric space . Every Cauchy sequence in $\mathbb{R}^n$ converges to a point of $\mathbb{R}^n$ . Definition Cauchy sequence . Given $\epsilon > 0$ , there is an integer $K$ such that $\mathbf{|x_k - x_j|} < \epsilon$ for all $k,j \geq K$ . I am not fond of my proof, because I am not certain if I can approach $\epsilon$ to be zero, nor if I can equate $\mathbf{x}$ to be $\mathbf{x_j}$ since $\mathbf{x_j}$ is changing while $\epsilon$ changes. Edit Especially, I am baffled that why we need to do it in coordinates? I think they can be subtracted directly, as the definition of Cauchy sequence I added a short while ago?","is a complete metric space. Consider a Cauchy sequence in , we want to show it converges to a point . That is to say, if as . Hence, we let , and we get by Cauchy sequence, and let we showed the desired result. Definition is a complete metric space . Every Cauchy sequence in converges to a point of . Definition Cauchy sequence . Given , there is an integer such that for all . I am not fond of my proof, because I am not certain if I can approach to be zero, nor if I can equate to be since is changing while changes. Edit Especially, I am baffled that why we need to do it in coordinates? I think they can be subtracted directly, as the definition of Cauchy sequence I added a short while ago?","\mathbb{R}^n \{\mathbf{x}_k\} \mathbb{R}^n \mathbf{x} \in \mathbb{R}^n |\mathbf{x - x_k}| \to 0 k \to \infty \epsilon \to 0 \mathbf{|x_k - x_j|} < \epsilon \mathbf{x = x_j} \mathbb{R}^n \mathbb{R}^n \mathbb{R}^n \epsilon > 0 K \mathbf{|x_k - x_j|} < \epsilon k,j \geq K \epsilon \mathbf{x} \mathbf{x_j} \mathbf{x_j} \epsilon","['real-analysis', 'proof-verification']"
19,If $f$ is differentiable at $x = x_0$ then $f$ is continuous at $x = x_0$.,If  is differentiable at  then  is continuous at .,f x = x_0 f x = x_0,"Claim: if $f$ is differentiable at $x = x_0$ then $f$ is continuous at $x = x_0$. Please, see if I made some mistake in the proof below. I mention some theorems in the proof: The condition to $f(x)$ be continuous at $x=x_0$ is $\lim\limits_{x\to x_0} f(x)=f(x_0)$. (1) If $f(x)$ is differentiable at $x-x_0$, then $f'(x)=\lim\limits_{x\to x_0} \dfrac{f(x)-f(x_0)}{x-x_0}$ exists and the function is defined at $x=x_0$. (2) Therefore, by the Limit Linearity Theorem, $\lim\limits_{x\to x_0} f(x)$ exists and we'll show it is equals $f(x_0)$. (3) We'll do this by the Precise Limit Definion: given $ \epsilon>0, \exists\delta|0<|x-x_0|<\delta$, then $0<|f(x)-f(x_0)|<\epsilon$. As this limit exists by (2), we can make $f(x)$ as close to  $f(x_0)$ as one wishes, therefore $\lim\limits_{x\to x_0} f(x)=f(x_0)$, what satisfies the condition for $f(x)$ be differentiable at  $x=x_0$. The end.","Claim: if $f$ is differentiable at $x = x_0$ then $f$ is continuous at $x = x_0$. Please, see if I made some mistake in the proof below. I mention some theorems in the proof: The condition to $f(x)$ be continuous at $x=x_0$ is $\lim\limits_{x\to x_0} f(x)=f(x_0)$. (1) If $f(x)$ is differentiable at $x-x_0$, then $f'(x)=\lim\limits_{x\to x_0} \dfrac{f(x)-f(x_0)}{x-x_0}$ exists and the function is defined at $x=x_0$. (2) Therefore, by the Limit Linearity Theorem, $\lim\limits_{x\to x_0} f(x)$ exists and we'll show it is equals $f(x_0)$. (3) We'll do this by the Precise Limit Definion: given $ \epsilon>0, \exists\delta|0<|x-x_0|<\delta$, then $0<|f(x)-f(x_0)|<\epsilon$. As this limit exists by (2), we can make $f(x)$ as close to  $f(x_0)$ as one wishes, therefore $\lim\limits_{x\to x_0} f(x)=f(x_0)$, what satisfies the condition for $f(x)$ be differentiable at  $x=x_0$. The end.",,"['real-analysis', 'limits', 'derivatives', 'definition']"
20,Looking for a bijective nowhere-continuous function ${\mathbb R}\rightarrow{\mathbb R}$,Looking for a bijective nowhere-continuous function,{\mathbb R}\rightarrow{\mathbb R},"Does there exist a bijective function $f:{\mathbb R}\rightarrow{\mathbb R}$ that is nowhere-continuous, assuming that both domain and range have the ""standard topology""? 1 1 By this I mean the one generated by the open intervals $(a, b) \subset {\mathrm R}$.  BTW, if this topology has a name more readily recognized than the standard topology ( on ${\mathbb R}$), please toss me a comment! EDIT: the original version of this question allowed for the possibility that $f$ be only injective, but shortly after I posted the following injective function came to mind: let $n:{\mathbb Q}\rightarrow {\mathbb N}$ be an ordering of the rationals, and define $$f(x)=\begin{cases} n(x) & x\in\mathbb Q\\ x& x\notin\mathbb Q\end{cases}$$ It is clear that this $f$ is injective, and it seems to me that the proof of the nowhere-continuity of the Dirichlet function applies to this case as well. EDIT2: OK, I was next going to try modifying the candidate above to make the function bijective, but Asaf Karagila got there first, with a much neater solution than what I was heading for...","Does there exist a bijective function $f:{\mathbb R}\rightarrow{\mathbb R}$ that is nowhere-continuous, assuming that both domain and range have the ""standard topology""? 1 1 By this I mean the one generated by the open intervals $(a, b) \subset {\mathrm R}$.  BTW, if this topology has a name more readily recognized than the standard topology ( on ${\mathbb R}$), please toss me a comment! EDIT: the original version of this question allowed for the possibility that $f$ be only injective, but shortly after I posted the following injective function came to mind: let $n:{\mathbb Q}\rightarrow {\mathbb N}$ be an ordering of the rationals, and define $$f(x)=\begin{cases} n(x) & x\in\mathbb Q\\ x& x\notin\mathbb Q\end{cases}$$ It is clear that this $f$ is injective, and it seems to me that the proof of the nowhere-continuity of the Dirichlet function applies to this case as well. EDIT2: OK, I was next going to try modifying the candidate above to make the function bijective, but Asaf Karagila got there first, with a much neater solution than what I was heading for...",,"['real-analysis', 'general-topology', 'examples-counterexamples']"
21,"Find the limit $\lim \limits_{n \to \infty}  \int_0^1 f(nx) \,dx $",Find the limit,"\lim \limits_{n \to \infty}  \int_0^1 f(nx) \,dx ","Please try to help me with a question that I'm trying to solve. $f(x)$ is continuous in the range of $[0, \infty)$ and $\lim \limits_{x \to \infty}x^2 f(x) = 1$ . Calculate $$\lim_{n \to \infty}  \int_0^1 f(nx) \,dx .$$",Please try to help me with a question that I'm trying to solve. is continuous in the range of and . Calculate,"f(x) [0, \infty) \lim \limits_{x \to \infty}x^2 f(x) = 1 \lim_{n \to \infty}  \int_0^1 f(nx) \,dx .","['calculus', 'real-analysis', 'limits', 'definite-integrals']"
22,Lebesgue integral uniform convergence,Lebesgue integral uniform convergence,,"Let $f_n, f \colon [a,b] \to \mathbb{R}.$ Show that, if $f_n \to f$ uniformly, then the Lebesgue integrals are equal, i.e. $\int f = \lim \int f_n$ . This is clearly true for continuous functions, but how do I handle the case of non-continuous functions?","Let Show that, if uniformly, then the Lebesgue integrals are equal, i.e. . This is clearly true for continuous functions, but how do I handle the case of non-continuous functions?","f_n, f \colon [a,b] \to \mathbb{R}. f_n \to f \int f = \lim \int f_n","['real-analysis', 'integration']"
23,Question regarding Weierstrass M-test,Question regarding Weierstrass M-test,,"The Weierstrass M-test tells that given a function sequence $(u_{n}(x))$ where $x \in I$, if there exists a convergent series $\sum a_{n}$ such that $|u_{n}(x)|\leq a_{n}$ for all $n$ and $x\in I$, then $\sum u_{n}(x)$ converges uniformly in $I$. What about the opposite of it? If $\sum u_{n}(x)$ converges uniformly in $I$, then there exists a convergent series $\sum g_{n}$ such that $|u_{n}(x)|\leq g_{n}$ for all $n$ and $x \in I$. Since the theorem isn't in the form of 'if and only if', I'm trying to think of an example to counter the above: My attempt was to define a function sequence such as this: Then taking $u_{1}(x)=f_{1}(x),\ u_{n}(x)=f_{n}(x)-f_{n-1}(x)$. It can be shown that $f_{n}(x)$ converges uniformly in $[1, \infty)$, therefore $u_{n}(x)$ does as well. But $|u_{n}(1)|=|f_{n}(1)|$ which is the constant sequence: $1, 1, 1, ...$. If we assume by contradiction that there exists such a sequence $1\leq g_{n}$ that $\sum g_{n}$ converges then by the comparison test $\sum 1$ converges which is obviously not true. First, I'd like to know if the above is true. It took me quite a while to come up with something and I'm not even sure it's true. Also, It's very difficult for me to visualize these complicated functions (like the one above) where both $x$ and $n$ play a role. Is there an easier way to deal with these questions?","The Weierstrass M-test tells that given a function sequence $(u_{n}(x))$ where $x \in I$, if there exists a convergent series $\sum a_{n}$ such that $|u_{n}(x)|\leq a_{n}$ for all $n$ and $x\in I$, then $\sum u_{n}(x)$ converges uniformly in $I$. What about the opposite of it? If $\sum u_{n}(x)$ converges uniformly in $I$, then there exists a convergent series $\sum g_{n}$ such that $|u_{n}(x)|\leq g_{n}$ for all $n$ and $x \in I$. Since the theorem isn't in the form of 'if and only if', I'm trying to think of an example to counter the above: My attempt was to define a function sequence such as this: Then taking $u_{1}(x)=f_{1}(x),\ u_{n}(x)=f_{n}(x)-f_{n-1}(x)$. It can be shown that $f_{n}(x)$ converges uniformly in $[1, \infty)$, therefore $u_{n}(x)$ does as well. But $|u_{n}(1)|=|f_{n}(1)|$ which is the constant sequence: $1, 1, 1, ...$. If we assume by contradiction that there exists such a sequence $1\leq g_{n}$ that $\sum g_{n}$ converges then by the comparison test $\sum 1$ converges which is obviously not true. First, I'd like to know if the above is true. It took me quite a while to come up with something and I'm not even sure it's true. Also, It's very difficult for me to visualize these complicated functions (like the one above) where both $x$ and $n$ play a role. Is there an easier way to deal with these questions?",,"['real-analysis', 'sequences-and-series']"
24,Summation of $\sum\limits_{n=1}^{\infty} \frac{x(x+1) \cdots (x+n-1)}{y(y+1) \cdots (y+n-1)}$,Summation of,\sum\limits_{n=1}^{\infty} \frac{x(x+1) \cdots (x+n-1)}{y(y+1) \cdots (y+n-1)},"For $x>0$ and $y>x+1$, how do we prove that $$\sum\limits_{n=1}^{\infty} \frac{x(x+1) \cdots (x+n-1)}{y(y+1) \cdots (y+n-1)} = \frac{x}{y-x-1}$$","For $x>0$ and $y>x+1$, how do we prove that $$\sum\limits_{n=1}^{\infty} \frac{x(x+1) \cdots (x+n-1)}{y(y+1) \cdots (y+n-1)} = \frac{x}{y-x-1}$$",,['real-analysis']
25,How can tempered distributions be identified with functions?,How can tempered distributions be identified with functions?,,"In Stein's Harmonic Analysis: Real-Variable Methods, Orthogonality and Oscillatory Integrals , he defines tempered distribution ( $\mathscr S'$ ) as continuous linear functionals from the Schwartz class. Here, the continuity is given with respect to the family of seminorms \begin{equation*}\|\Phi\|_{\alpha,\beta}=\sup_{x\in\mathbb R^N}|x^\alpha\partial^\beta_x\Phi(x)|.\end{equation*} Then, without any further clarification, he proceeds to discuss convolutions between a tempered distribution and functions in the Schwartz family. This is where I get puzzled. If the tempered distributions are functionals, what is this convolution supposed to mean? It seems as if he (and every other source, for that matter) was assuming these functionals can be clearly identified with some functions. My question is: how do you make this identification? I was thinking, as Schwartz functions are in $L^2$ , maybe the identification is the one given by Riesz representation theorem. However, I think this is not possible as the topology we are considering in the Schwartz class is different from that of $L^2$ . Moreover, while discussing $H^p$ spaces, he claims that, for $p>1$ , $L^p$ is the same as $H^p$ . Here, he is using again this identification that I don't quite get and, if my hypothesis was correct that the identification is made through Riesz representation theorem, this should mean $H^2=L^2=\mathscr S'$ . This seems a bit strange to me. Another thing that's worrying me as well is the fact that he is discussing, without a prior definition, bounded distributions. Of course, if these were elements of $L^2$ 's dual, they would be automatically bounded, so this is another hint that my original assumption about the identification is wrong. I think this is a very basic question, but I don't find any source in which this is specifically discussed and clarify. How can we talk about an object as both a tempered distribution (an element of $\mathscr S'$ ) and a function defined on $\mathbb R^N$ ?","In Stein's Harmonic Analysis: Real-Variable Methods, Orthogonality and Oscillatory Integrals , he defines tempered distribution ( ) as continuous linear functionals from the Schwartz class. Here, the continuity is given with respect to the family of seminorms Then, without any further clarification, he proceeds to discuss convolutions between a tempered distribution and functions in the Schwartz family. This is where I get puzzled. If the tempered distributions are functionals, what is this convolution supposed to mean? It seems as if he (and every other source, for that matter) was assuming these functionals can be clearly identified with some functions. My question is: how do you make this identification? I was thinking, as Schwartz functions are in , maybe the identification is the one given by Riesz representation theorem. However, I think this is not possible as the topology we are considering in the Schwartz class is different from that of . Moreover, while discussing spaces, he claims that, for , is the same as . Here, he is using again this identification that I don't quite get and, if my hypothesis was correct that the identification is made through Riesz representation theorem, this should mean . This seems a bit strange to me. Another thing that's worrying me as well is the fact that he is discussing, without a prior definition, bounded distributions. Of course, if these were elements of 's dual, they would be automatically bounded, so this is another hint that my original assumption about the identification is wrong. I think this is a very basic question, but I don't find any source in which this is specifically discussed and clarify. How can we talk about an object as both a tempered distribution (an element of ) and a function defined on ?","\mathscr S' \begin{equation*}\|\Phi\|_{\alpha,\beta}=\sup_{x\in\mathbb R^N}|x^\alpha\partial^\beta_x\Phi(x)|.\end{equation*} L^2 L^2 H^p p>1 L^p H^p H^2=L^2=\mathscr S' L^2 \mathscr S' \mathbb R^N","['real-analysis', 'functional-analysis', 'distribution-theory', 'dual-spaces', 'schwartz-space']"
26,Holomorphic and analytic functions.,Holomorphic and analytic functions.,,"I read this today (source: Wikipedia): The fact that all holomorphic functions are complex analytic   functions, and vice versa, is a major theorem in complex analysis. Is there a similar result in real analysis?","I read this today (source: Wikipedia): The fact that all holomorphic functions are complex analytic   functions, and vice versa, is a major theorem in complex analysis. Is there a similar result in real analysis?",,"['real-analysis', 'complex-analysis']"
27,How do I prove a sequence is Cauchy,How do I prove a sequence is Cauchy,,"I was hoping someone could explain to me how to prove a sequence is Cauchy. I've been given two definitions of a Cauchy sequence: $\forall \epsilon > 0, \exists N \in \mathbb{N}$ such that $n,m> N$ $\Rightarrow |a_n - a_m| ≤ \epsilon$ and equivalently $\forall \epsilon > 0, \exists N \in \mathbb{N}$ such that $n> N$ $\Rightarrow |a_{n+p} - a_n| ≤ \epsilon$,  $\forall p \in \mathbb{N}$ I understand that proving a sequence is Cauchy also proves it is convergent and the usefulness of this property, however, it was never explicitly explained how to prove a sequence is Cauchy using either of these two definitions. I'd appreciate it if someone could explain me how to prove a sequence is Cauchy perhaps $a_n = \sqrt{n+1} - \sqrt{n}$ ? or another example just for me to grasp the concept.","I was hoping someone could explain to me how to prove a sequence is Cauchy. I've been given two definitions of a Cauchy sequence: $\forall \epsilon > 0, \exists N \in \mathbb{N}$ such that $n,m> N$ $\Rightarrow |a_n - a_m| ≤ \epsilon$ and equivalently $\forall \epsilon > 0, \exists N \in \mathbb{N}$ such that $n> N$ $\Rightarrow |a_{n+p} - a_n| ≤ \epsilon$,  $\forall p \in \mathbb{N}$ I understand that proving a sequence is Cauchy also proves it is convergent and the usefulness of this property, however, it was never explicitly explained how to prove a sequence is Cauchy using either of these two definitions. I'd appreciate it if someone could explain me how to prove a sequence is Cauchy perhaps $a_n = \sqrt{n+1} - \sqrt{n}$ ? or another example just for me to grasp the concept.",,['real-analysis']
28,Using the same limit for a second derivative,Using the same limit for a second derivative,,"I've been trying to answer the same question answered here: Second derivative ""formula derivation"" And I'm stuck in a step that is not addressed both in the answer and in the comments of the question over there. In the original question he uses the fact that $$f''(x) = \lim_{h\to0} \frac{f'(x+h) - f'(x)}{h}$$   $$f''(x) = \lim_{h\to0} \frac{  \frac{ f(x+2h) - f(x+h)}{h} - \frac{ f(x+h) - f(x)}{h}  }{h}$$ Which I basically see as taking the derivatives with the same limit 3 times.  Shouldn't it be as follow? $$f''(x) = \lim_{h\to0} \frac{  \lim_{h_1\to0}\frac{ f(x+h+h_1) - f(x+h)}{h_1} - \lim_{h_2\to0}\frac{ f(x+h_2) - f(x)}{h_2}  }{h}$$ How do you justify moving to the equation given in the original answer?","I've been trying to answer the same question answered here: Second derivative ""formula derivation"" And I'm stuck in a step that is not addressed both in the answer and in the comments of the question over there. In the original question he uses the fact that $$f''(x) = \lim_{h\to0} \frac{f'(x+h) - f'(x)}{h}$$   $$f''(x) = \lim_{h\to0} \frac{  \frac{ f(x+2h) - f(x+h)}{h} - \frac{ f(x+h) - f(x)}{h}  }{h}$$ Which I basically see as taking the derivatives with the same limit 3 times.  Shouldn't it be as follow? $$f''(x) = \lim_{h\to0} \frac{  \lim_{h_1\to0}\frac{ f(x+h+h_1) - f(x+h)}{h_1} - \lim_{h_2\to0}\frac{ f(x+h_2) - f(x)}{h_2}  }{h}$$ How do you justify moving to the equation given in the original answer?",,"['real-analysis', 'derivatives']"
29,"Suppose $a_n>0$ and $\sum_{n=1}^{\infty}{a_n}$ diverges. Determine convergence of $\sum_{n=1}^{\infty}{\frac{a_n}{s_n^2}}$, where $s_n=\sum^n a_n$.","Suppose  and  diverges. Determine convergence of , where .",a_n>0 \sum_{n=1}^{\infty}{a_n} \sum_{n=1}^{\infty}{\frac{a_n}{s_n^2}} s_n=\sum^n a_n,"Suppose $a_n>0$ and $\sum_{n=1}^{\infty}{a_n}$ diverges. Determine whether $\sum_{n=1}^{\infty}{\frac{a_n}{s_n^2}}$ converges, where $s_n=a_1+a_2+ \cdots + a_n$. My attempt: By testing a few examples, the series $\sum_{n=1}^{\infty}{\frac{a_n}{s_n^2}}$ converges. We proceed to prove it. Note that $$\frac{a_n}{s_n^2} \leq \frac{a_n}{n^2(a_1a_2\cdots a_n)}$$ Now if I manage to prove that $a_1a_2\cdots a_n \geq 1$, then the inequality above becomes $$\frac{a_n}{s_n^2} \leq \frac{1}{n^2}$$. My guess is that it should have something to do with the divergent series $\sum_{n=1}^{\infty}{a_n}$. Then by the Comparison test, we are done. However, I have difficulty to prove the claim. Can anyone give some hint? UPDATE: So I made some mistake in my working. Here is my another 'promising' claim: $$a_n \leq (\frac{a_1+...+a_n}{n})^2$$ It seems to work for any series satisfying the question. But I am unable o prove it.","Suppose $a_n>0$ and $\sum_{n=1}^{\infty}{a_n}$ diverges. Determine whether $\sum_{n=1}^{\infty}{\frac{a_n}{s_n^2}}$ converges, where $s_n=a_1+a_2+ \cdots + a_n$. My attempt: By testing a few examples, the series $\sum_{n=1}^{\infty}{\frac{a_n}{s_n^2}}$ converges. We proceed to prove it. Note that $$\frac{a_n}{s_n^2} \leq \frac{a_n}{n^2(a_1a_2\cdots a_n)}$$ Now if I manage to prove that $a_1a_2\cdots a_n \geq 1$, then the inequality above becomes $$\frac{a_n}{s_n^2} \leq \frac{1}{n^2}$$. My guess is that it should have something to do with the divergent series $\sum_{n=1}^{\infty}{a_n}$. Then by the Comparison test, we are done. However, I have difficulty to prove the claim. Can anyone give some hint? UPDATE: So I made some mistake in my working. Here is my another 'promising' claim: $$a_n \leq (\frac{a_1+...+a_n}{n})^2$$ It seems to work for any series satisfying the question. But I am unable o prove it.",,"['real-analysis', 'sequences-and-series', 'contest-math']"
30,"Is a single point in euclidean space open, closed, neither or both?","Is a single point in euclidean space open, closed, neither or both?",,"In a euclidean space $\mathbb{R}^k$, is the set consisting of a single point open, closed, neither, or both? I would say that a set $E$ consisting of a single point $p$ doesn't have any limit points, so $E$ contains all of its limit points and is therefore closed. But it might be open, too, since a ball of radius zero around $p$ is a subset of $E$. When using balls to define interior points, do balls have to have radius greater than zero?","In a euclidean space $\mathbb{R}^k$, is the set consisting of a single point open, closed, neither, or both? I would say that a set $E$ consisting of a single point $p$ doesn't have any limit points, so $E$ contains all of its limit points and is therefore closed. But it might be open, too, since a ball of radius zero around $p$ is a subset of $E$. When using balls to define interior points, do balls have to have radius greater than zero?",,['real-analysis']
31,coordinate free proof that $\text{div}(\nabla f \times \nabla g) = 0$,coordinate free proof that,\text{div}(\nabla f \times \nabla g) = 0,"Let $V$ be a Euclidean $3$-dimensional space. Does there exist a coordinate-free proof that for any two $C^1$-functions $f, g: \mathbb{R}^3 \to \mathbb{R}$ we have $$\text{div}(\nabla f \times \nabla g) = 0?$$","Let $V$ be a Euclidean $3$-dimensional space. Does there exist a coordinate-free proof that for any two $C^1$-functions $f, g: \mathbb{R}^3 \to \mathbb{R}$ we have $$\text{div}(\nabla f \times \nabla g) = 0?$$",,"['real-analysis', 'multivariable-calculus']"
32,"If $|f(x)-f(y)|\geq \frac12|x-y|$, must $f$ be bijective? [duplicate]","If , must  be bijective? [duplicate]",|f(x)-f(y)|\geq \frac12|x-y| f,"This question already has an answer here : $|f(x)-f(y)|\geq k|x-y|$.Then $f$ is bijective and its inverse is continuous. (1 answer) Closed 9 years ago . Let $f:\mathbb R\rightarrow \mathbb R$ be a continuous function such that $$|f(x)-f(y)|\geq \frac12|x-y|$$ for all$x,y\in \mathbb R$. Then is $f$ one-one and onto? Let $f(x)=f(y)$ i.e. $0=|f(x)-f(y)|\geq (1/2)|x-y|$ i.e $x=y$ Hence $f$ is injective. But I am unable to conclude whether $f$ is onto.Any help","This question already has an answer here : $|f(x)-f(y)|\geq k|x-y|$.Then $f$ is bijective and its inverse is continuous. (1 answer) Closed 9 years ago . Let $f:\mathbb R\rightarrow \mathbb R$ be a continuous function such that $$|f(x)-f(y)|\geq \frac12|x-y|$$ for all$x,y\in \mathbb R$. Then is $f$ one-one and onto? Let $f(x)=f(y)$ i.e. $0=|f(x)-f(y)|\geq (1/2)|x-y|$ i.e $x=y$ Hence $f$ is injective. But I am unable to conclude whether $f$ is onto.Any help",,"['real-analysis', 'continuity']"
33,Nullhomotopic map extended,Nullhomotopic map extended,,"I have troubles understanding this proof: Let $h:S^1 \rightarrow X$ be a continuous map, then we have that if $h$ is nullhomotopic, $h$ can be extended to a continuous map $k:B^2 \rightarrow X.$ Proof: Since $h$ is nullhomotopic, there exists a homotopy $H: S^1 \times I  \rightarrow X$ between $h$ and a constant map.(This is clear). Now we define a map $\pi:S^1 \times I \rightarrow B^2$ by $\pi(x,t)= (1-t)x$. Then $\pi$ is continuous, onto and closed. Now, I am not sure why we know that this map is closed.  Alright so far. Now we notice that this is a quotient map with $\pi(S^1 ,1)=0 \in B^2$ and otherwise this map is injective. It is concluded from this that we can extend $h$ to a map $k$, but it is not sad: HOW?! Does anybody know why this is possible now?","I have troubles understanding this proof: Let $h:S^1 \rightarrow X$ be a continuous map, then we have that if $h$ is nullhomotopic, $h$ can be extended to a continuous map $k:B^2 \rightarrow X.$ Proof: Since $h$ is nullhomotopic, there exists a homotopy $H: S^1 \times I  \rightarrow X$ between $h$ and a constant map.(This is clear). Now we define a map $\pi:S^1 \times I \rightarrow B^2$ by $\pi(x,t)= (1-t)x$. Then $\pi$ is continuous, onto and closed. Now, I am not sure why we know that this map is closed.  Alright so far. Now we notice that this is a quotient map with $\pi(S^1 ,1)=0 \in B^2$ and otherwise this map is injective. It is concluded from this that we can extend $h$ to a map $k$, but it is not sad: HOW?! Does anybody know why this is possible now?",,"['real-analysis', 'general-topology', 'analysis', 'algebraic-topology']"
34,"Convergence of the series $\sum a_n$ implies the convergence of $\sum \frac{\sqrt a_n}{n}$, if $a_n>0$ [duplicate]","Convergence of the series  implies the convergence of , if  [duplicate]",\sum a_n \sum \frac{\sqrt a_n}{n} a_n>0,"This question already has answers here : If the series $\sum_0^\infty a_n$ converges, then so does $\sum_1^\infty \frac{\sqrt{a_n}}{n} $ [duplicate] (2 answers) Closed 11 years ago . I need help to solve following problem from Rudin's Mathematical analysis book: Convergence of the series $\sum a_n$  implies the convergence of $\sum \dfrac{\sqrt {a_n}}{n}$, if $a_n>0$ I tried to construct a suitable convergence sequence $b_n$ such that $\sum b_n$ converges and $a_n \leq b_n$ but, I am not able to find such sequence $b_n$ . Thanks for the help and sugestions.","This question already has answers here : If the series $\sum_0^\infty a_n$ converges, then so does $\sum_1^\infty \frac{\sqrt{a_n}}{n} $ [duplicate] (2 answers) Closed 11 years ago . I need help to solve following problem from Rudin's Mathematical analysis book: Convergence of the series $\sum a_n$  implies the convergence of $\sum \dfrac{\sqrt {a_n}}{n}$, if $a_n>0$ I tried to construct a suitable convergence sequence $b_n$ such that $\sum b_n$ converges and $a_n \leq b_n$ but, I am not able to find such sequence $b_n$ . Thanks for the help and sugestions.",,"['real-analysis', 'sequences-and-series']"
35,Study continuity of this function,Study continuity of this function,,"Hello im studying calculus at the university and I dont know how to solve the following exercise: Study the continuity of the next function: $$f(x,y) = \begin{cases} \frac{x^2-xy}{x+y}&\text{for } x+y\ne0\\ 0 &\text{for }(x,y) =(0,0). \end{cases}$$ I've tried to resolve it with iterated limits and directional limits, but im sure if its correct.","Hello im studying calculus at the university and I dont know how to solve the following exercise: Study the continuity of the next function: $$f(x,y) = \begin{cases} \frac{x^2-xy}{x+y}&\text{for } x+y\ne0\\ 0 &\text{for }(x,y) =(0,0). \end{cases}$$ I've tried to resolve it with iterated limits and directional limits, but im sure if its correct.",,"['calculus', 'real-analysis', 'limits', 'functions', 'continuity']"
36,Evaluate $\lim_{n\to\infty}\sum_{k=1}^{n}\frac{k}{n^2+k^2}$ [duplicate],Evaluate  [duplicate],\lim_{n\to\infty}\sum_{k=1}^{n}\frac{k}{n^2+k^2},"This question already has answers here : How do you calculate this limit $\lim_{n\to\infty}\sum_{k=1}^{n} \frac{k}{n^2+k^2}$? (3 answers) Closed 4 years ago . Considering the sum as a Riemann sum, evaluate $$\lim_{n\to\infty}\sum_{k=1}^{n}\frac{k}{n^2+k^2} .$$","This question already has answers here : How do you calculate this limit $\lim_{n\to\infty}\sum_{k=1}^{n} \frac{k}{n^2+k^2}$? (3 answers) Closed 4 years ago . Considering the sum as a Riemann sum, evaluate $$\lim_{n\to\infty}\sum_{k=1}^{n}\frac{k}{n^2+k^2} .$$",,"['calculus', 'real-analysis', 'integration', 'summation']"
37,Does a recursive definition of a variable make sense at all?,Does a recursive definition of a variable make sense at all?,,"Let $A:=\sum_{n=0}^\infty 2^n$ . I was given the following equation: $$A=\sum_{n=0}^\infty 2^n=\sum_{n=1}^\infty2^{n-1}=\sum_{n=1}^\infty(2^n\cdot\frac{1}{2})=\frac{1}{2}\sum_{n=1}^\infty2^n=\frac{1}{2}(-1+\sum_{n=0}^\infty2^n)=\frac{1}{2}(-1+A)$$ My task is to explain that why this can't be true and to find the mistake in the equation. I think that I found the mistake but I am not  quite sure if I found it correctly so maybe someone can look over it. First, this obviously has to be wrong, because if I solve $A=\frac{1}{2}(-1+A)$ for $A$ I get $A=-1$ . But this can't be true, because $\lim_{n\to\infty}(\sum_{k=1}^n2^k)=+\infty$ . I now tried to check every step and the single steps (except the last) seem to be correct. With the last step I thought that it might be a problem that we have replaced the sum with $A$ again, because then we get a recursive definition of $A$ . And from my point of view it makes no sense to do this because then we can never assign a value to $A$ . So my thought wass that a recursive definition of a variable is completly senseless. On the other hand I thought that this might be a notation problem my teacher wants to draw my attention to. In our class we are using the symbol $\sum_{n=0}^\infty a_n$ once for the series and once for the limit $\lim_{n\to\infty}\sum_{k=1}^n a_k$ . Maybe we can't replace the $\sum_{n=0}^\infty 2^n$ with $A$ because $A$ is the series and $\sum_{n=0}^\infty 2^n$ is the limit and not the series. So now I am not quite sure why exactly the equation given is wrong, so maybe someone here can explain better. This question here is quite similiar, but from my point of view It wouldn't have helped me to solve my problem, because there is not stated that $A\notin\mathbb{R}$ holds and this was the essential point where I started to understand my problem.","Let . I was given the following equation: My task is to explain that why this can't be true and to find the mistake in the equation. I think that I found the mistake but I am not  quite sure if I found it correctly so maybe someone can look over it. First, this obviously has to be wrong, because if I solve for I get . But this can't be true, because . I now tried to check every step and the single steps (except the last) seem to be correct. With the last step I thought that it might be a problem that we have replaced the sum with again, because then we get a recursive definition of . And from my point of view it makes no sense to do this because then we can never assign a value to . So my thought wass that a recursive definition of a variable is completly senseless. On the other hand I thought that this might be a notation problem my teacher wants to draw my attention to. In our class we are using the symbol once for the series and once for the limit . Maybe we can't replace the with because is the series and is the limit and not the series. So now I am not quite sure why exactly the equation given is wrong, so maybe someone here can explain better. This question here is quite similiar, but from my point of view It wouldn't have helped me to solve my problem, because there is not stated that holds and this was the essential point where I started to understand my problem.",A:=\sum_{n=0}^\infty 2^n A=\sum_{n=0}^\infty 2^n=\sum_{n=1}^\infty2^{n-1}=\sum_{n=1}^\infty(2^n\cdot\frac{1}{2})=\frac{1}{2}\sum_{n=1}^\infty2^n=\frac{1}{2}(-1+\sum_{n=0}^\infty2^n)=\frac{1}{2}(-1+A) A=\frac{1}{2}(-1+A) A A=-1 \lim_{n\to\infty}(\sum_{k=1}^n2^k)=+\infty A A A \sum_{n=0}^\infty a_n \lim_{n\to\infty}\sum_{k=1}^n a_k \sum_{n=0}^\infty 2^n A A \sum_{n=0}^\infty 2^n A\notin\mathbb{R},"['real-analysis', 'sequences-and-series', 'limits', 'infinity', 'divergent-series']"
38,Should one learn the proofs of theorems which have highly complicated proofs?,Should one learn the proofs of theorems which have highly complicated proofs?,,"Lately, I have been reading a really dense real analysis textbook and I came across different theorems which have exceedingly long proofs (for instance, the dominated/bounded convergence theorem or many other theorems that involve interchanging the order of integration/differentiation). I wonder if it is worth learning such proofs, because, for instance, I have known the DCT for a while and I have used it extensively to compute different limits, but I can't see why it would be useful to know how to prove it. I would like to add that I am mostly self-learnt at this level, because I have just finished high school. As a result, I don't know if, for instance, in a college level real analysis course the lecturer would prove such a result. I chose the DCT as an example because I have found it quite useful in different problems, but there are many other theorems which fit into this category.","Lately, I have been reading a really dense real analysis textbook and I came across different theorems which have exceedingly long proofs (for instance, the dominated/bounded convergence theorem or many other theorems that involve interchanging the order of integration/differentiation). I wonder if it is worth learning such proofs, because, for instance, I have known the DCT for a while and I have used it extensively to compute different limits, but I can't see why it would be useful to know how to prove it. I would like to add that I am mostly self-learnt at this level, because I have just finished high school. As a result, I don't know if, for instance, in a college level real analysis course the lecturer would prove such a result. I chose the DCT as an example because I have found it quite useful in different problems, but there are many other theorems which fit into this category.",,"['real-analysis', 'soft-question', 'self-learning', 'education']"
39,How to prove that there is no differentiable function with given partial derivatives,How to prove that there is no differentiable function with given partial derivatives,,"Let $U=\{(x,y)\in\mathbb{R}^2:(x,y)\neq(0,0)\}$. Show that there is no differentiable function $f:U\rightarrow\mathbb{R}$ satisfying   $$\frac{\partial f}{\partial x}=\frac{y}{x^2+y^2}, \frac{\partial f}{\partial y}=-\frac{x}{x^2+y^2}.$$ My initial thought was to show that these partials are not continuous at some point $(x,y)\neq(0,0)$, but since it is possible to have a differentiable function that is not $C^1$, this is not enough. Any suggestions are greatly appreciated.","Let $U=\{(x,y)\in\mathbb{R}^2:(x,y)\neq(0,0)\}$. Show that there is no differentiable function $f:U\rightarrow\mathbb{R}$ satisfying   $$\frac{\partial f}{\partial x}=\frac{y}{x^2+y^2}, \frac{\partial f}{\partial y}=-\frac{x}{x^2+y^2}.$$ My initial thought was to show that these partials are not continuous at some point $(x,y)\neq(0,0)$, but since it is possible to have a differentiable function that is not $C^1$, this is not enough. Any suggestions are greatly appreciated.",,"['real-analysis', 'multivariable-calculus', 'derivatives']"
40,Find the number of natural solutions of $5^x+7^x+11^x=6^x+8^x+9^x$,Find the number of natural solutions of,5^x+7^x+11^x=6^x+8^x+9^x,"Find the number of natural solutions of $5^x+7^x+11^x=6^x+8^x+9^x$ It's easy to see that $x=0$ and $x=1$ are solutions but are these the only one? How do I demonstrate that? I've tried to write them either: $$5^x+7^x+11^x=2^x*3^x+2^{3x}+3^{2x}$$ or $$5^x+7^x+11^x=(5+1)^x+(7+1)^x+(11-2)^x$$ and tried to think of some AM-GM mean inequality or to divide everything by $11^x$, but those don't seem like the way to go. Any hints?","Find the number of natural solutions of $5^x+7^x+11^x=6^x+8^x+9^x$ It's easy to see that $x=0$ and $x=1$ are solutions but are these the only one? How do I demonstrate that? I've tried to write them either: $$5^x+7^x+11^x=2^x*3^x+2^{3x}+3^{2x}$$ or $$5^x+7^x+11^x=(5+1)^x+(7+1)^x+(11-2)^x$$ and tried to think of some AM-GM mean inequality or to divide everything by $11^x$, but those don't seem like the way to go. Any hints?",,"['calculus', 'real-analysis', 'functions', 'exponential-function', 'karamata-inequality']"
41,Convergence of $1+\frac13-\frac12+\frac15+\frac17-\frac14+\frac19+\frac1{11}-\frac16+\ldots$,Convergence of,1+\frac13-\frac12+\frac15+\frac17-\frac14+\frac19+\frac1{11}-\frac16+\ldots,"I was reading Rudin PMA, example 3.53 on P76. There he points out that rearrangement may not give same limit of a series. Then he says that it is left as exercise to show that above mentioned series converges. I thought clubbing three terms, but did not seem 'legal'. How to show that series $1+\dfrac13-\dfrac12+\dfrac15+\dfrac17-\dfrac14+\dfrac19+\dfrac1{11}-\dfrac16+\ldots$ converges? I tried root test: Let this series be $\sum_{n=1}^{\infty}a_n$, then $\limsup\limits_{n\to\infty}\sqrt[n]{|a_n|}=1$, since basically, this series is rearrangement of $\sum \frac {(-1)^n}n$. So root test is inconclusive.","I was reading Rudin PMA, example 3.53 on P76. There he points out that rearrangement may not give same limit of a series. Then he says that it is left as exercise to show that above mentioned series converges. I thought clubbing three terms, but did not seem 'legal'. How to show that series $1+\dfrac13-\dfrac12+\dfrac15+\dfrac17-\dfrac14+\dfrac19+\dfrac1{11}-\dfrac16+\ldots$ converges? I tried root test: Let this series be $\sum_{n=1}^{\infty}a_n$, then $\limsup\limits_{n\to\infty}\sqrt[n]{|a_n|}=1$, since basically, this series is rearrangement of $\sum \frac {(-1)^n}n$. So root test is inconclusive.",,"['real-analysis', 'sequences-and-series']"
42,A function is uniformly differentiable if its derivative is uniformly continuous?,A function is uniformly differentiable if its derivative is uniformly continuous?,,"Suppose $I$ is an open interval and $f:I\rightarrow\mathbb{R}$ is a differential function. We can say $f$ is uniformly diferentiable if for every $\epsilon> 0$ there exists $\delta> 0$ such that $x,y\in I$ and $0\lt|x-y|<\delta  \Rightarrow  \Big| \frac{f(x)-f(y)}{x-y}-f'(x) \Big|\lt\epsilon$ I would like to prove that, if and only if $f'$ is uniformly continuous, then $f$ is uniformly differentiable.","Suppose is an open interval and is a differential function. We can say is uniformly diferentiable if for every there exists such that and I would like to prove that, if and only if is uniformly continuous, then is uniformly differentiable.","I f:I\rightarrow\mathbb{R} f \epsilon> 0 \delta> 0 x,y\in I 0\lt|x-y|<\delta  \Rightarrow  \Big| \frac{f(x)-f(y)}{x-y}-f'(x) \Big|\lt\epsilon f' f","['real-analysis', 'functions', 'derivatives', 'uniform-continuity']"
43,To find maximum possible value of this integral,To find maximum possible value of this integral,,"If $\int_{0}^{1} f dx=3$  and  $\int_{0}^{1} xf dx  =2$, then find the maximum value of $$\int_{0}^{1} f^2 dx.$$ What methods would apply to find this maximum value? I am not approaching the methods...","If $\int_{0}^{1} f dx=3$  and  $\int_{0}^{1} xf dx  =2$, then find the maximum value of $$\int_{0}^{1} f^2 dx.$$ What methods would apply to find this maximum value? I am not approaching the methods...",,['real-analysis']
44,"If $\int_0^\infty x f(x) \ dx < \infty$, is $\int_0^\infty \int_0^\infty f(x+y) \ dx \ dy< \infty$?","If , is ?",\int_0^\infty x f(x) \ dx < \infty \int_0^\infty \int_0^\infty f(x+y) \ dx \ dy< \infty,"Question: Let $f : [0, \infty) \to [0,\infty)$ be a measurable function which, more than being integrable, satisfies $\int_0^\infty x f(x) < \infty$. Does it follow that  $\int_0^\infty \int_0^\infty  f(x+y) \ dx \ dy< \infty$? Remark: The conclusion does not hold if you only assume $\int_0^\infty f(x) \ dx <\infty$. For example, the sequence $a_n = \frac{1}{n} - \frac{1}{n+1}$ is such that $\sum_{n=1}^\infty a_n < \infty$, but $\sum_{n=1}^\infty \sum_{m=1}^\infty a_{n+m} = \infty$.  It's not difficult to adapt this example to the present setting. Remark: Things also fall apart if the integral $\int_0^\infty \int_0^\infty  f(x+y) \ dx \ dy$ isn't taken over the first quadrant only. If $f : \mathbb{R} \to [0,\infty)$ is measurable and not zero almost everywhere, then assuming $\int_0^\infty x f(x) \ dx < \infty$ doesn't change the fact that the integral of $f(x+y)$ over every, e.g., horizontal line will be the same positive number so that $\int_{-\infty}^\infty \int_{-\infty}^\infty f(x+y) \ dx \ dy = \infty$. Added: In retrospect, a nice geometric way to see that the two integrals should be equal is to note that $(x,y) \mapsto f(x+y)$ is constant along lines of slope $-1$, the value of $f$ on $x+y = a$  being $f(a)$.  Meanwhile, the length of the intersection of $x+y = a$ with the 1st quadrant grows linearly with $a$.","Question: Let $f : [0, \infty) \to [0,\infty)$ be a measurable function which, more than being integrable, satisfies $\int_0^\infty x f(x) < \infty$. Does it follow that  $\int_0^\infty \int_0^\infty  f(x+y) \ dx \ dy< \infty$? Remark: The conclusion does not hold if you only assume $\int_0^\infty f(x) \ dx <\infty$. For example, the sequence $a_n = \frac{1}{n} - \frac{1}{n+1}$ is such that $\sum_{n=1}^\infty a_n < \infty$, but $\sum_{n=1}^\infty \sum_{m=1}^\infty a_{n+m} = \infty$.  It's not difficult to adapt this example to the present setting. Remark: Things also fall apart if the integral $\int_0^\infty \int_0^\infty  f(x+y) \ dx \ dy$ isn't taken over the first quadrant only. If $f : \mathbb{R} \to [0,\infty)$ is measurable and not zero almost everywhere, then assuming $\int_0^\infty x f(x) \ dx < \infty$ doesn't change the fact that the integral of $f(x+y)$ over every, e.g., horizontal line will be the same positive number so that $\int_{-\infty}^\infty \int_{-\infty}^\infty f(x+y) \ dx \ dy = \infty$. Added: In retrospect, a nice geometric way to see that the two integrals should be equal is to note that $(x,y) \mapsto f(x+y)$ is constant along lines of slope $-1$, the value of $f$ on $x+y = a$  being $f(a)$.  Meanwhile, the length of the intersection of $x+y = a$ with the 1st quadrant grows linearly with $a$.",,"['real-analysis', 'integration']"
45,computing the limit of $\frac{1}{n} \sum_{k=1}^{n}{\frac{1}{k}}$ [duplicate],computing the limit of  [duplicate],\frac{1}{n} \sum_{k=1}^{n}{\frac{1}{k}},This question already has answers here : How to show that $\lim \frac{1}{n} \sum_{i=1}^n \frac{1}{i}=0 $? [duplicate] (8 answers) Closed 6 years ago . Prove that the following limit is 0 $\lim\limits_{n\to\infty} \frac{1}{n} \sum_{k=1}^{n}{\frac{1}{k}}$ Please I don't know how to do it :S. The harmonic series diverges thus it requires some special trick,This question already has answers here : How to show that $\lim \frac{1}{n} \sum_{i=1}^n \frac{1}{i}=0 $? [duplicate] (8 answers) Closed 6 years ago . Prove that the following limit is 0 $\lim\limits_{n\to\infty} \frac{1}{n} \sum_{k=1}^{n}{\frac{1}{k}}$ Please I don't know how to do it :S. The harmonic series diverges thus it requires some special trick,,"['calculus', 'real-analysis', 'limits', 'harmonic-numbers']"
46,Proving that $X$ is a Banach space iff convergence of $\sum\|x_n\|$ implies convergence of $\sum x_n$,Proving that  is a Banach space iff convergence of  implies convergence of,X \sum\|x_n\| \sum x_n,"The following is an Exercise of Conway's Functional Analysis . Prove that $X$ is a $\,Banach$ space iff whenever $\{x_n\}$ is a sequence in $X$, such that $\sum \| x_n \| < \infty$, then $\sum x_n$ converges. I easily can show that if $X$ is a Banach space then $\sum x_n$ converges. My problem is showing that $X$ is a Banach space. For this I suppose that $\{s_n\}$ is a Cauchy sequence in $X$, then I want to make a series. For this I do not have any idea. Please help me.","The following is an Exercise of Conway's Functional Analysis . Prove that $X$ is a $\,Banach$ space iff whenever $\{x_n\}$ is a sequence in $X$, such that $\sum \| x_n \| < \infty$, then $\sum x_n$ converges. I easily can show that if $X$ is a Banach space then $\sum x_n$ converges. My problem is showing that $X$ is a Banach space. For this I suppose that $\{s_n\}$ is a Cauchy sequence in $X$, then I want to make a series. For this I do not have any idea. Please help me.",,"['real-analysis', 'sequences-and-series', 'functional-analysis', 'banach-spaces', 'normed-spaces']"
47,Is the Cartesian product of two open sets open?,Is the Cartesian product of two open sets open?,,"Just a quick question: If you have two sets $A,B \subset \mathbb{R}$ that are open, that is, for every $p \in A$, there exists an $\varepsilon > 0$ such that $B(p;\varepsilon) \subset A$, is the Cartesian Product of these sets also open? I am trying to think of a proof, but I am stuck rather quickly. So far I have this: Proof: Let $A$, $B \subset \mathbb{R}$ be open sets. Let $C = A \times B$. Since $A$ is open, there exists an $\varepsilon > 0$ such that for all $p \in A$, $B(p;\varepsilon ) \subset A$. Since $B$ is open, there exists an $\varepsilon ' > 0$ such that for all $q \in B$, $B(q;\varepsilon ') \subset B$. In other words, we can make a ball around a point in the $x$ or $y$ direction, but can we also make a ball in both at the same time? Some guidance would be lovely. Thanks in advance!","Just a quick question: If you have two sets $A,B \subset \mathbb{R}$ that are open, that is, for every $p \in A$, there exists an $\varepsilon > 0$ such that $B(p;\varepsilon) \subset A$, is the Cartesian Product of these sets also open? I am trying to think of a proof, but I am stuck rather quickly. So far I have this: Proof: Let $A$, $B \subset \mathbb{R}$ be open sets. Let $C = A \times B$. Since $A$ is open, there exists an $\varepsilon > 0$ such that for all $p \in A$, $B(p;\varepsilon ) \subset A$. Since $B$ is open, there exists an $\varepsilon ' > 0$ such that for all $q \in B$, $B(q;\varepsilon ') \subset B$. In other words, we can make a ball around a point in the $x$ or $y$ direction, but can we also make a ball in both at the same time? Some guidance would be lovely. Thanks in advance!",,"['real-analysis', 'general-topology', 'metric-spaces', 'product-space']"
48,Sum of a Hyper-geometric series. (NBHM 2011),Sum of a Hyper-geometric series. (NBHM 2011),,"How to find the sum of the following series $$\frac{1}{5} - \frac{1\cdot 4}{5\cdot 10} + \frac{1\cdot 4\cdot 7}{5\cdot 10\cdot 15} - \dots\,.?$$ I have no idea. I have written the general term and tested its convergence by Gauss' test for convergence, but they are neither the question nor the answer.","How to find the sum of the following series I have no idea. I have written the general term and tested its convergence by Gauss' test for convergence, but they are neither the question nor the answer.","\frac{1}{5} - \frac{1\cdot 4}{5\cdot 10} + \frac{1\cdot 4\cdot 7}{5\cdot 10\cdot 15} - \dots\,.?","['real-analysis', 'sequences-and-series', 'algebra-precalculus']"
49,"Show a convergent series $\sum a_n$, but $\sum a_n^p$ is not convergent","Show a convergent series , but  is not convergent",\sum a_n \sum a_n^p,"$p>1$ is a integer, Show  a  convergent series $\sum\limits_{n=1}^\infty a_n$, $a_n\in\Bbb R$, such that the series $$\sum_{n=1}^\infty a_n^p$$ is divergent p.s. If $p>1$ is not an integer and $a_n\lt0$, it will be difficult to define $a_n^p$(complex analysis?), so we only consider $p\in\Bbb Z$","$p>1$ is a integer, Show  a  convergent series $\sum\limits_{n=1}^\infty a_n$, $a_n\in\Bbb R$, such that the series $$\sum_{n=1}^\infty a_n^p$$ is divergent p.s. If $p>1$ is not an integer and $a_n\lt0$, it will be difficult to define $a_n^p$(complex analysis?), so we only consider $p\in\Bbb Z$",,"['calculus', 'real-analysis', 'sequences-and-series', 'examples-counterexamples']"
50,Compute $\int_0^1\int_0^1...\int_0^1\lfloor{x_1+x_2+...+x_n}\rfloor dx_1dx_2...dx_n$,Compute,\int_0^1\int_0^1...\int_0^1\lfloor{x_1+x_2+...+x_n}\rfloor dx_1dx_2...dx_n,"Compute $\int_0^1\int_0^1...\int_0^1\lfloor{x_1+x_2+...+x_n}\rfloor dx_1dx_2...dx_n$ where the integrand consists of the floor (or greatest integer less than or equal) function. The case $n=1,2,3$ all can be solved geometrically. Actually the case $n=3$ is pretty fun where you get to dissect the unit cube. I guess the cases $n\ge4$ don't have useful geometric interpretations... so how to approach them (well, you still get to divide the sum into different cases: sum between 0 and 1, between 1 and 2, ..., between $n-1$ and $n$, and multiply the floor of the sum with the measure of the corresponding region) ?","Compute $\int_0^1\int_0^1...\int_0^1\lfloor{x_1+x_2+...+x_n}\rfloor dx_1dx_2...dx_n$ where the integrand consists of the floor (or greatest integer less than or equal) function. The case $n=1,2,3$ all can be solved geometrically. Actually the case $n=3$ is pretty fun where you get to dissect the unit cube. I guess the cases $n\ge4$ don't have useful geometric interpretations... so how to approach them (well, you still get to divide the sum into different cases: sum between 0 and 1, between 1 and 2, ..., between $n-1$ and $n$, and multiply the floor of the sum with the measure of the corresponding region) ?",,"['real-analysis', 'integration', 'multivariable-calculus', 'contest-math']"
51,Does There exist a continuous bijection $\mathbb{Q}\to \mathbb{Q}\times \mathbb{Q}$?,Does There exist a continuous bijection ?,\mathbb{Q}\to \mathbb{Q}\times \mathbb{Q},Does there exist a continuous bijection $\mathbb{Q}\to \mathbb{Q}\times \mathbb{Q}$? I am not able to find out how to proceed.,Does there exist a continuous bijection $\mathbb{Q}\to \mathbb{Q}\times \mathbb{Q}$? I am not able to find out how to proceed.,,"['real-analysis', 'general-topology', 'examples-counterexamples']"
52,"What does $C[0,1]$ mean?",What does  mean?,"C[0,1]","In the context of real analysis, I have found this question: For each $$f \in C[0,1] $$ there is a series of even polynomials , which converge uniformly on $[0,1]$ to f. What is $C[0,1]$ ? Is it the space of functions which are continuous for $0\le x \le 1 $ ?","In the context of real analysis, I have found this question: For each $$f \in C[0,1] $$ there is a series of even polynomials , which converge uniformly on $[0,1]$ to f. What is $C[0,1]$ ? Is it the space of functions which are continuous for $0\le x \le 1 $ ?",,"['real-analysis', 'analysis', 'multivariable-calculus', 'notation']"
53,"$f=\infty$ on a set of measure 0, then $\int_E f = 0$","on a set of measure 0, then",f=\infty \int_E f = 0,"Let $E$ be a set of measure zero and define $f = \infty$ on $E$. Show that $\int_E f = 0$. This is out of Royden 4E, p 84. I know how to prove this if $f=0$ on $E$.  But I'm curious, as stated, won't this result in a situation in which $\infty \cdot 0$.","Let $E$ be a set of measure zero and define $f = \infty$ on $E$. Show that $\int_E f = 0$. This is out of Royden 4E, p 84. I know how to prove this if $f=0$ on $E$.  But I'm curious, as stated, won't this result in a situation in which $\infty \cdot 0$.",,['real-analysis']
54,"In $C[0,1]$ prove that the subset of Lipschitz functions is dense",In  prove that the subset of Lipschitz functions is dense,"C[0,1]","In $C[0,1]$ prove that the subset of Lipschitz functions is dense. I can't prove it.","In $C[0,1]$ prove that the subset of Lipschitz functions is dense. I can't prove it.",,['real-analysis']
55,"Let $a_{n}$ be a sequence such that $(a_{n})^{2}=ca_{n-1}$ where ($c>0,a_{1}>0$).Prove that $a_n$ converges to $c$.",Let  be a sequence such that  where ().Prove that  converges to .,"a_{n} (a_{n})^{2}=ca_{n-1} c>0,a_{1}>0 a_n c","Let $a_{n}$ be a sequence such that $(a_{n})^{2}=ca_{n-1}$ where ($c>0,a_{1}>0$).Prove that the sequence converges to $c$. My first problem was to find some terms of the sequence to verify that point and show that converges and converges to that point using some convergence criterion. Could someone help me through this problem?","Let $a_{n}$ be a sequence such that $(a_{n})^{2}=ca_{n-1}$ where ($c>0,a_{1}>0$).Prove that the sequence converges to $c$. My first problem was to find some terms of the sequence to verify that point and show that converges and converges to that point using some convergence criterion. Could someone help me through this problem?",,"['real-analysis', 'sequences-and-series']"
56,"Finding simple, step, and continuous functions to satisfy Lebesgue integral conditions","Finding simple, step, and continuous functions to satisfy Lebesgue integral conditions",,"The problem: Suppose $E \in \mathfrak{M}$ and that $f$ is (Lebesgue) integrable over $E$. For any $\epsilon > 0$ show that there exist simple, step, and continuous functions $\varphi, \psi, g$ (respectively) such that: $\displaystyle\int_E |f - \varphi|\,dm < \epsilon$ $\displaystyle\int_E|f - \psi|\,dm < \epsilon$ $\displaystyle\int_E|f - g|\,dm <\epsilon$ Now, we have shown in the notes that for $f: [a, b] \to [-\infty, +\infty]$ measurable (and $f \neq \pm \infty$ almost everywhere) we can find simple, step, and continuous functions such that : $$m(\left \{x \in [a, b] : |f(x) - (\text{the function})| \geq \epsilon \right \}) < \epsilon $$ So I'm certain that these two are related! We also have that $\displaystyle\int_E |f|\,dm < \infty$ by assumption on $f$. But how are these connected?","The problem: Suppose $E \in \mathfrak{M}$ and that $f$ is (Lebesgue) integrable over $E$. For any $\epsilon > 0$ show that there exist simple, step, and continuous functions $\varphi, \psi, g$ (respectively) such that: $\displaystyle\int_E |f - \varphi|\,dm < \epsilon$ $\displaystyle\int_E|f - \psi|\,dm < \epsilon$ $\displaystyle\int_E|f - g|\,dm <\epsilon$ Now, we have shown in the notes that for $f: [a, b] \to [-\infty, +\infty]$ measurable (and $f \neq \pm \infty$ almost everywhere) we can find simple, step, and continuous functions such that : $$m(\left \{x \in [a, b] : |f(x) - (\text{the function})| \geq \epsilon \right \}) < \epsilon $$ So I'm certain that these two are related! We also have that $\displaystyle\int_E |f|\,dm < \infty$ by assumption on $f$. But how are these connected?",,"['real-analysis', 'measure-theory']"
57,Prove that $ \frac{1}{1}-\frac{1}{4}+\frac{1}{7}-\frac{1}{10}+\ldots= \frac{1}{3} \left( {\frac{\pi}{\sqrt{3}}+ \log 2} \right)$,Prove that, \frac{1}{1}-\frac{1}{4}+\frac{1}{7}-\frac{1}{10}+\ldots= \frac{1}{3} \left( {\frac{\pi}{\sqrt{3}}+ \log 2} \right),"How do I show that $$ \frac{1}{1}-\frac{1}{4}+\frac{1}{7}-\frac{1}{10}+\ldots= \frac{1}{3} \left( {\frac{\pi}{\sqrt{3}}+ \log 2} \right)?$$ This problem belongs to Riemann Theory of Definite Integral, and not to any series summation. I recommend an answer which is to the topic i.e., Riemann Theory of D.I.. Thanks!","How do I show that $$ \frac{1}{1}-\frac{1}{4}+\frac{1}{7}-\frac{1}{10}+\ldots= \frac{1}{3} \left( {\frac{\pi}{\sqrt{3}}+ \log 2} \right)?$$ This problem belongs to Riemann Theory of Definite Integral, and not to any series summation. I recommend an answer which is to the topic i.e., Riemann Theory of D.I.. Thanks!",,"['calculus', 'real-analysis']"
58,What are the conditions for existence of the Fourier series expansion of a function $f\colon\mathbb{R}\to\mathbb{R}$,What are the conditions for existence of the Fourier series expansion of a function,f\colon\mathbb{R}\to\mathbb{R},What are the conditions for existence of the Fourier series expansion of a function $f\colon\mathbb{R}\to\mathbb{R}$?,What are the conditions for existence of the Fourier series expansion of a function $f\colon\mathbb{R}\to\mathbb{R}$?,,"['real-analysis', 'fourier-series']"
59,"prove that $\int_0^\infty \frac{\sin^2 x-x\sin x}{x^3} \, dx= \frac{1}{2} - \ln 2$",prove that,"\int_0^\infty \frac{\sin^2 x-x\sin x}{x^3} \, dx= \frac{1}{2} - \ln 2","Prove that $$ \int_{0}^{\infty} \frac{\sin^2 x-x\sin x}{x^3} \, dx = \frac{1}{2} - \ln 2 .$$ Integration by parts gives \begin{align*} &\lim_{R\to \infty} \int_{0}^{R} \frac{\sin^2 x-x\sin x}{x^3} \, dx \\ &= \lim_{R\to \infty} \biggl( \int_{0}^{R} \frac{\sin^2x}{x^3} \, dx - \int_{0}^{R} \frac{\sin x}{x^2} \, dx \biggr)\\ &= \lim_{R\to\infty} \biggl( \frac{\sin^2 x}{-2x^2}\Biggr\rvert_{0}^{R} - \int_{0}^{R} \frac{\sin (2x)}{-2x^2} \, dx - \biggl(-\frac{\sin x}{x} \Biggr\rvert_{0}^{R} + \int_{0}^{R} \frac{\cos x}{x} \,dx \biggr) \biggr) \\ &= \lim_{R\to \infty} \biggl(\frac{1}{2} + \int_{0}^{2R} \frac{\sin u}{u^2/2} \, \Bigl(\frac{1}2 \, du\Bigr) - \biggl( 1 + \int_{0}^{R} \frac{\cos x}{x} \, dx \biggr)\biggr) \\ &\hspace{22em}\text{(using the substitution $u\mapsto 2x$)}\\ &= -\frac{1}{2} + \lim_{R\to \infty} \biggl(\int_{0}^{2R} \frac{\sin u}{u^2} \, du - \int_{0}^{R} \frac{\cos x}{x} \,dx \biggr)\\ &= \frac{1}{2} + \lim_{R\to\infty} \biggl(\int_{R}^{2R} \frac{\cos x}{x} \, dx \biggr) \end{align*} Thus it suffices to show that $\lim_{R\to\infty} \int_{R}^{2R} \frac{\cos x}{x} \, dx = \ln 2$ . The Taylor series expansion of $\cos x$ is given by $\cos x = \sum_{i=0}^{\infty} \frac{(-1)^i x^{2i}}{(2i)!}$ . (If the step below (the one involving the interchanging of an infinite sum and integral) is valid, why exactly is it valid? For instance, does it use uniform convergence?) The limit equals $$ \lim_{R\to\infty} \int_{R}^{2R} \biggl( \frac{1}{x} + \sum_{i=1}^{\infty} \frac{(-1)^i x^{2i-1}}{(2i)!} \biggr) \, dx = \ln 2 + \lim_{R\to\infty} \sum_{i=1}^{\infty} \biggl[\frac{(-1)^ix^{2i}}{(2i)(2i)!}\biggr]_{R}^{2R} . $$ But I don't know how to show $\lim_{R\to\infty} \lim_{R\to\infty} \sum_{i=1}^{\infty} \Bigl[\frac{(-1)^ix^{2i}}{(2i)(2i)!}\Bigr]_{R}^{2R} = -2 \ln 2$ .","Prove that Integration by parts gives Thus it suffices to show that . The Taylor series expansion of is given by . (If the step below (the one involving the interchanging of an infinite sum and integral) is valid, why exactly is it valid? For instance, does it use uniform convergence?) The limit equals But I don't know how to show ."," \int_{0}^{\infty} \frac{\sin^2 x-x\sin x}{x^3} \, dx = \frac{1}{2} - \ln 2 . \begin{align*}
&\lim_{R\to \infty} \int_{0}^{R} \frac{\sin^2 x-x\sin x}{x^3} \, dx \\
&= \lim_{R\to \infty} \biggl( \int_{0}^{R} \frac{\sin^2x}{x^3} \, dx - \int_{0}^{R} \frac{\sin x}{x^2} \, dx \biggr)\\
&= \lim_{R\to\infty} \biggl( \frac{\sin^2 x}{-2x^2}\Biggr\rvert_{0}^{R} - \int_{0}^{R} \frac{\sin (2x)}{-2x^2} \, dx - \biggl(-\frac{\sin x}{x} \Biggr\rvert_{0}^{R} + \int_{0}^{R} \frac{\cos x}{x} \,dx \biggr) \biggr) \\
&= \lim_{R\to \infty} \biggl(\frac{1}{2} + \int_{0}^{2R} \frac{\sin u}{u^2/2} \, \Bigl(\frac{1}2 \, du\Bigr) - \biggl( 1 + \int_{0}^{R} \frac{\cos x}{x} \, dx \biggr)\biggr) \\
&\hspace{22em}\text{(using the substitution u\mapsto 2x)}\\
&= -\frac{1}{2} + \lim_{R\to \infty} \biggl(\int_{0}^{2R} \frac{\sin u}{u^2} \, du - \int_{0}^{R} \frac{\cos x}{x} \,dx \biggr)\\
&= \frac{1}{2} + \lim_{R\to\infty} \biggl(\int_{R}^{2R} \frac{\cos x}{x} \, dx \biggr)
\end{align*} \lim_{R\to\infty} \int_{R}^{2R} \frac{\cos x}{x} \, dx = \ln 2 \cos x \cos x = \sum_{i=0}^{\infty} \frac{(-1)^i x^{2i}}{(2i)!} 
\lim_{R\to\infty} \int_{R}^{2R} \biggl( \frac{1}{x} + \sum_{i=1}^{\infty} \frac{(-1)^i x^{2i-1}}{(2i)!} \biggr) \, dx
= \ln 2 + \lim_{R\to\infty} \sum_{i=1}^{\infty} \biggl[\frac{(-1)^ix^{2i}}{(2i)(2i)!}\biggr]_{R}^{2R} .  \lim_{R\to\infty} \lim_{R\to\infty} \sum_{i=1}^{\infty} \Bigl[\frac{(-1)^ix^{2i}}{(2i)(2i)!}\Bigr]_{R}^{2R} = -2 \ln 2","['real-analysis', 'calculus', 'integration', 'improper-integrals']"
60,What is an open set in a topological space?,What is an open set in a topological space?,,"I recently started learning topology to help me understand limits and continuity better for calculus, and I am struggling with some of the definitions. What I am getting confused with is why is every set in a topology considered to be open and when talking about sets in the topology we always say the set is open. My intuitive notion of openness from  previous knowledge of mathematics is an interval that does not contain its endpoints, so there is an infinite sequence at the end points, e.g., $(0,1)$ is an open interval. However, in topology, for example, the singleton $\{1\}$ is considered an open set—how is this so? Why are sets in a topology always open? And what is the definition of an open set in a topological space? Thanks in advance.","I recently started learning topology to help me understand limits and continuity better for calculus, and I am struggling with some of the definitions. What I am getting confused with is why is every set in a topology considered to be open and when talking about sets in the topology we always say the set is open. My intuitive notion of openness from  previous knowledge of mathematics is an interval that does not contain its endpoints, so there is an infinite sequence at the end points, e.g., is an open interval. However, in topology, for example, the singleton is considered an open set—how is this so? Why are sets in a topology always open? And what is the definition of an open set in a topological space? Thanks in advance.","(0,1) \{1\}","['real-analysis', 'general-topology']"
61,$ \lim\limits_{n \to \infty} \frac1n\sqrt[n]{n\cdot(n+1)\cdots(2n)}$,, \lim\limits_{n \to \infty} \frac1n\sqrt[n]{n\cdot(n+1)\cdots(2n)},It tried to solve this limit $$    \lim_{n \to \infty} \frac{\sqrt[n]{n\cdot(n+1)\cdots(2n)}}{n}$$ $   \frac{\sqrt[n]{n\cdot(n+1)\cdots(2n)}}{n} = \sqrt[n]{\frac {2n!n}{n!}} \frac{1}{n} \sim \sqrt[n]{\frac {   \sqrt {2 \pi  2 n} (\frac {2n}{e})^ {2n}n }{\sqrt {2 \pi   n} (\frac {n}{e})^ {n} }} \frac{1}{n} =  \sqrt[n]{\frac {   \sqrt {2 } (\frac {2n}{e})^ {n}(\frac {2n}{e})^ {n}n }{ (\frac {n}{e})^ {n} }} \frac{1}{n} = 2^{\frac{1}{2n}} \frac{4}{e}n^{\frac{1}{n}} \rightarrow \frac{4}{e}$ Is it right?,It tried to solve this limit Is it right?,"    \lim_{n \to \infty} \frac{\sqrt[n]{n\cdot(n+1)\cdots(2n)}}{n}    \frac{\sqrt[n]{n\cdot(n+1)\cdots(2n)}}{n} = \sqrt[n]{\frac {2n!n}{n!}} \frac{1}{n} \sim \sqrt[n]{\frac { 
 \sqrt {2 \pi  2 n} (\frac {2n}{e})^ {2n}n }{\sqrt {2 \pi   n} (\frac {n}{e})^ {n} }} \frac{1}{n} = 
\sqrt[n]{\frac { 
 \sqrt {2 } (\frac {2n}{e})^ {n}(\frac {2n}{e})^ {n}n }{ (\frac {n}{e})^ {n} }} \frac{1}{n} = 2^{\frac{1}{2n}} \frac{4}{e}n^{\frac{1}{n}} \rightarrow \frac{4}{e}",['real-analysis']
62,Lindelöf and second countable spaces,Lindelöf and second countable spaces,,"Can anyone give me some examples and non examples of Lindelöf or second countable space and spaces that is Lindelöf but not second countable?   And I understand the definition but find it is hard to visualize and imagine. I have tried google it but it turns out I only found some silly examples like finite set or empty set. In general, how can one construct a topological space that is Lindelöf or second countable? Someone in stack exchange said the real line with discrete topology is Lindelöf, but I do not think so. We can simply construct an open cover defined by the collection of all the singleton set. And this open cover is well defined since singleton set is open in discrete topology. Hence, by definition it is not Lindelöf. Last question, is (0,1) in the real line equipped with usual topology Lindelöf? I think it is Lindelöf but I could not give any formal proof. (0,1) fails to be a compact set since we can construct an open cover defined by (1/n,1-1/n) but this open cover does not work so well for arguing for Lindelöf property since quotient number is dense in (0,1). So intuitively I think it is Lindelöf. I wrote a pretty long question. My mothertongue is not English. Hopefully, you guys can understand me.","Can anyone give me some examples and non examples of Lindelöf or second countable space and spaces that is Lindelöf but not second countable?   And I understand the definition but find it is hard to visualize and imagine. I have tried google it but it turns out I only found some silly examples like finite set or empty set. In general, how can one construct a topological space that is Lindelöf or second countable? Someone in stack exchange said the real line with discrete topology is Lindelöf, but I do not think so. We can simply construct an open cover defined by the collection of all the singleton set. And this open cover is well defined since singleton set is open in discrete topology. Hence, by definition it is not Lindelöf. Last question, is (0,1) in the real line equipped with usual topology Lindelöf? I think it is Lindelöf but I could not give any formal proof. (0,1) fails to be a compact set since we can construct an open cover defined by (1/n,1-1/n) but this open cover does not work so well for arguing for Lindelöf property since quotient number is dense in (0,1). So intuitively I think it is Lindelöf. I wrote a pretty long question. My mothertongue is not English. Hopefully, you guys can understand me.",,"['real-analysis', 'general-topology', 'second-countable', 'lindelof-spaces']"
63,Is it possible to prove that all Cauchy sequences of real numbers converge without using the Bolzano-Weierstrass theorem?,Is it possible to prove that all Cauchy sequences of real numbers converge without using the Bolzano-Weierstrass theorem?,,"Question: Prove that a sequence of real numbers is convergent if and only if it is a Cauchy sequence. I'm currently learning real analysis through an inquiry based course, and I'm trying to prove the above statement in the backwards direction. I've already proved that every Cauchy sequence is bounded (using similar logic to this proof), so now I'm trying to see how I can use that information in my proof. Most proofs that I have seen across the internet use the ""Bolzano-Weierstrass theorem,"" which is something that is not in the text (and it seems like a pretty involved proof), so I'm trying to see if there's another way to complete this proof. We are allowed to assume that a monotone sequence is convergent iff it is bounded, but the text doesn't say much about monotone sequences, so I'm not sure  if that information is helpful or not. Thanks for any help you can give me in understanding this concept. I'm happy to elaborate where I can.","Question: Prove that a sequence of real numbers is convergent if and only if it is a Cauchy sequence. I'm currently learning real analysis through an inquiry based course, and I'm trying to prove the above statement in the backwards direction. I've already proved that every Cauchy sequence is bounded (using similar logic to this proof), so now I'm trying to see how I can use that information in my proof. Most proofs that I have seen across the internet use the ""Bolzano-Weierstrass theorem,"" which is something that is not in the text (and it seems like a pretty involved proof), so I'm trying to see if there's another way to complete this proof. We are allowed to assume that a monotone sequence is convergent iff it is bounded, but the text doesn't say much about monotone sequences, so I'm not sure  if that information is helpful or not. Thanks for any help you can give me in understanding this concept. I'm happy to elaborate where I can.",,"['real-analysis', 'sequences-and-series', 'cauchy-sequences']"
64,"If a sequence grows too fast, then its harmonic sum cannot be rational","If a sequence grows too fast, then its harmonic sum cannot be rational",,"Let $A = \{a_i\}_{i = 1}^{\infty}$ be a sequence of positive integers. If the terms in $A$ grow 'too fast', can we determine that  $$S_A = \sum_{i = 1}^{\infty} \frac{1}{a_i}$$ is irrational ? More formally, is there a criteria that says if $a_i = \Omega(f(i)),$ then $S$ is irrational ? If not, for every sequence $A$ such that $S_A$ converges to a rational number, can we find a sequence of positive integers $B = \{b_i\}_{i = 1}^{\infty}$ such that  $$\lim_{n \rightarrow \infty} \frac{a_n}{b_n} = 0 \ $$ and $S_B$ also converges to a rational number ? This question was inspired by the following fact: $\sum_{k = 1}^{\infty} \frac{1}{(k!)^2}$ and $\sum_{k = 1}^{\infty} \frac{1}{2^{k^2}}$ are both irrational.","Let $A = \{a_i\}_{i = 1}^{\infty}$ be a sequence of positive integers. If the terms in $A$ grow 'too fast', can we determine that  $$S_A = \sum_{i = 1}^{\infty} \frac{1}{a_i}$$ is irrational ? More formally, is there a criteria that says if $a_i = \Omega(f(i)),$ then $S$ is irrational ? If not, for every sequence $A$ such that $S_A$ converges to a rational number, can we find a sequence of positive integers $B = \{b_i\}_{i = 1}^{\infty}$ such that  $$\lim_{n \rightarrow \infty} \frac{a_n}{b_n} = 0 \ $$ and $S_B$ also converges to a rational number ? This question was inspired by the following fact: $\sum_{k = 1}^{\infty} \frac{1}{(k!)^2}$ and $\sum_{k = 1}^{\infty} \frac{1}{2^{k^2}}$ are both irrational.",,"['real-analysis', 'sequences-and-series', 'irrational-numbers', 'rational-numbers']"
65,Continuous functions and uncountable intersections with the x-axis,Continuous functions and uncountable intersections with the x-axis,,"Let $f : \mathbb{R} \to \mathbb{R}$ such that the set $X = \{x \in \mathbb{R} : f(x) = 0\}$ does not contain any interval (i.e. there is no interval $I \subset X$) Of course the set $X$ can be uncountable (see Cantor Set ). If we add that $f$ is continuous, is it true that X is countable? I have been thinking about this for a while, and couldn't find any counterexamples - my intuition says the answer is yes. I tried to start a proof but really couldn't move forward. My attempt (by contradiction): assume $X$ is uncountable. Then there exists $[a, b] \subset \mathbb{R}$ such that $X \cap [a, b]$ is uncountable. Now, let $g$ be the restriction of $f$ to $[a, b]$. Then $g$ is uniformly continuous. I don't know what to do next, though... Any hints appreciated.","Let $f : \mathbb{R} \to \mathbb{R}$ such that the set $X = \{x \in \mathbb{R} : f(x) = 0\}$ does not contain any interval (i.e. there is no interval $I \subset X$) Of course the set $X$ can be uncountable (see Cantor Set ). If we add that $f$ is continuous, is it true that X is countable? I have been thinking about this for a while, and couldn't find any counterexamples - my intuition says the answer is yes. I tried to start a proof but really couldn't move forward. My attempt (by contradiction): assume $X$ is uncountable. Then there exists $[a, b] \subset \mathbb{R}$ such that $X \cap [a, b]$ is uncountable. Now, let $g$ be the restriction of $f$ to $[a, b]$. Then $g$ is uniformly continuous. I don't know what to do next, though... Any hints appreciated.",,"['real-analysis', 'examples-counterexamples', 'cantor-set']"
66,"Find $\int\limits_{0}^{2\pi} \frac{1}{5-3\cos(x)} \,\,dx$",Find,"\int\limits_{0}^{2\pi} \frac{1}{5-3\cos(x)} \,\,dx","I have to find $$\int_0^{2\pi} \frac{1}{5-3\cos(x)} \,\,dx$$ I tried to do it by substitution $t = \tan(\frac{x}{2})$ Then we have that $$\cos(x) = \frac{1-t^2}{1+t^2} \quad dx = \frac{2\,dt}{1+t^2}$$ but then also limits of integration are changing so we have $$\int\limits_{t(0)}^{t(2\pi)} \frac{1}{5 - \frac{1-t^2}{1+t^2}} \cdot \frac{2dt}{1+t^2} = \int\limits_0^0 \frac{1}{5 - \frac{1-t^2}{1+t^2}} \cdot \frac{2\,dt}{1+t^2} = 0$$ I figured out that it is not correct because $\tan(\frac{\pi}{2})$ is not defined and $t(\pi) = \tan(\frac{\pi}{2})$ and $\pi \in [0, 2\pi]$. How can I ""repair"" that and do it right?","I have to find $$\int_0^{2\pi} \frac{1}{5-3\cos(x)} \,\,dx$$ I tried to do it by substitution $t = \tan(\frac{x}{2})$ Then we have that $$\cos(x) = \frac{1-t^2}{1+t^2} \quad dx = \frac{2\,dt}{1+t^2}$$ but then also limits of integration are changing so we have $$\int\limits_{t(0)}^{t(2\pi)} \frac{1}{5 - \frac{1-t^2}{1+t^2}} \cdot \frac{2dt}{1+t^2} = \int\limits_0^0 \frac{1}{5 - \frac{1-t^2}{1+t^2}} \cdot \frac{2\,dt}{1+t^2} = 0$$ I figured out that it is not correct because $\tan(\frac{\pi}{2})$ is not defined and $t(\pi) = \tan(\frac{\pi}{2})$ and $\pi \in [0, 2\pi]$. How can I ""repair"" that and do it right?",,"['calculus', 'real-analysis', 'integration', 'definite-integrals']"
67,concepts which is present in metric space but not in topological space,concepts which is present in metric space but not in topological space,,"I want to know some concepts which is present in metric space but not in topological space. The one that first comes to mind is uniform continuity, equicontinuity i.e. concepts defined with some kind of distance.","I want to know some concepts which is present in metric space but not in topological space. The one that first comes to mind is uniform continuity, equicontinuity i.e. concepts defined with some kind of distance.",,"['real-analysis', 'general-topology', 'metric-spaces']"
68,Product of bounded and convergent to $0$ sequence is a convergent to $0$ sequence,Product of bounded and convergent to  sequence is a convergent to  sequence,0 0,Let $a_n$ be a null sequence and let $b_n$ be a bounded sequence. Prove that $a_n \cdot b_n$ is a null sequence. I tried using the product rule of sequences but cannot because $b_n$ is not necessarily convergent and may not have a limit. How do I go about answering this?,Let $a_n$ be a null sequence and let $b_n$ be a bounded sequence. Prove that $a_n \cdot b_n$ is a null sequence. I tried using the product rule of sequences but cannot because $b_n$ is not necessarily convergent and may not have a limit. How do I go about answering this?,,"['real-analysis', 'sequences-and-series']"
69,Does there exist a continuously differentiable function with the following properties?,Does there exist a continuously differentiable function with the following properties?,,"Does there exist a continuously differentiable function $f: [1,5] \rightarrow \mathbb{R}$, such that $f(1) \lt 0, f(5) \gt 3$ and $f'(x) \leq e^{-f(x)}$? Now do I just integrate it to get $f(x) = -e^{-f(x)}$? This is only true at $f(x) = 0$ though, what the!!","Does there exist a continuously differentiable function $f: [1,5] \rightarrow \mathbb{R}$, such that $f(1) \lt 0, f(5) \gt 3$ and $f'(x) \leq e^{-f(x)}$? Now do I just integrate it to get $f(x) = -e^{-f(x)}$? This is only true at $f(x) = 0$ though, what the!!",,"['calculus', 'real-analysis', 'derivatives', 'continuity']"
70,Is it possible that all subseries converge to irrationals?,Is it possible that all subseries converge to irrationals?,,"Does there exists a positive decreasing sequence $\{a_i\}$ with $\sum_{i\in\mathbb{N}} a_i$ convergent, such that $\forall I\subset\mathbb{N},\sum_{i\in I}a_i$ is an irrational number? Such an example would give rise to a closed perfect set containing no rationals . I can only do it for infinite $I$ (for example let $a_i=10^{-p_i}$, where $p_i$ is the $i$th prime.), but the set of infinite sums is not closed.","Does there exists a positive decreasing sequence $\{a_i\}$ with $\sum_{i\in\mathbb{N}} a_i$ convergent, such that $\forall I\subset\mathbb{N},\sum_{i\in I}a_i$ is an irrational number? Such an example would give rise to a closed perfect set containing no rationals . I can only do it for infinite $I$ (for example let $a_i=10^{-p_i}$, where $p_i$ is the $i$th prime.), but the set of infinite sums is not closed.",,['real-analysis']
71,Show that $f$ is uniformly continuous if limit exists,Show that  is uniformly continuous if limit exists,f,"Let $f(x)$ be continuous on $(0,1]$. Show that $f$ is uniformly continuous IFF $\displaystyle \lim_{x\to0^+} f(x)$ exists. Thoughts: Backward Proof: Let another function $\overline f(x)$ be continuous on $[0,1]$ which is equal to $f(x)$ plus the limit point. Thus the limit exists and it is uniformly continuous. So, as $f(x)$. Forward Proof: I Don't really have any idea...?? Please help guys","Let $f(x)$ be continuous on $(0,1]$. Show that $f$ is uniformly continuous IFF $\displaystyle \lim_{x\to0^+} f(x)$ exists. Thoughts: Backward Proof: Let another function $\overline f(x)$ be continuous on $[0,1]$ which is equal to $f(x)$ plus the limit point. Thus the limit exists and it is uniformly continuous. So, as $f(x)$. Forward Proof: I Don't really have any idea...?? Please help guys",,"['real-analysis', 'general-topology', 'continuity']"
72,Prove that if $S$ is a finite set then $S$ has no limit points.,Prove that if  is a finite set then  has no limit points.,S S,"Prove that if $S$ is a finite set then $S$  has no limit points. Can someone tell me if my approach is correct: Proof : Suppose $S$ is a finite set, then we can write $S = \{a_1, a_2, \ldots, a_n\}$ with $a_i \neq a_j$ if $i \neq j$. Suppose to the contrary that $S$ has a limit point $x_0$. Then by definition given any $\varepsilon > 0$ there exists $x \in S$ with $x \neq x_0$ such that $\vert x - x_0 \vert < \varepsilon$. Choose $\varepsilon$ to be the smallest distance between any two $a_i, a_j \in S$ with $i \neq j$. We can immediately see that there is no $x \in S$ such that $\vert x - x_0 \vert < \varepsilon$ holds, a contradiction. Thus we can conclude that $S$ has no limit points.","Prove that if $S$ is a finite set then $S$  has no limit points. Can someone tell me if my approach is correct: Proof : Suppose $S$ is a finite set, then we can write $S = \{a_1, a_2, \ldots, a_n\}$ with $a_i \neq a_j$ if $i \neq j$. Suppose to the contrary that $S$ has a limit point $x_0$. Then by definition given any $\varepsilon > 0$ there exists $x \in S$ with $x \neq x_0$ such that $\vert x - x_0 \vert < \varepsilon$. Choose $\varepsilon$ to be the smallest distance between any two $a_i, a_j \in S$ with $i \neq j$. We can immediately see that there is no $x \in S$ such that $\vert x - x_0 \vert < \varepsilon$ holds, a contradiction. Thus we can conclude that $S$ has no limit points.",,['real-analysis']
73,Rolle's Theorem,Rolle's Theorem,,"Let $f$ be a continuous function on $[a,b]$ and differentiable on $(a,b)$, where $a<b$. Suppose $f(a)=f(b)$. Prove that there exists number $c_{1},c_{2},...,c_{2012}$ $\in$ $(a,b)$ satisfying $c_{1} < c_{2} <...< c_{2012}$ and $f'(c_{1})+f'(c_{2})+...+f'(c_{2012})=0$. I believe it has something to do with Rolle's Theorem, judging by the hypotheses. However, I can't seem to find a way to tackle this problem. Any help is appreciated, thanks!","Let $f$ be a continuous function on $[a,b]$ and differentiable on $(a,b)$, where $a<b$. Suppose $f(a)=f(b)$. Prove that there exists number $c_{1},c_{2},...,c_{2012}$ $\in$ $(a,b)$ satisfying $c_{1} < c_{2} <...< c_{2012}$ and $f'(c_{1})+f'(c_{2})+...+f'(c_{2012})=0$. I believe it has something to do with Rolle's Theorem, judging by the hypotheses. However, I can't seem to find a way to tackle this problem. Any help is appreciated, thanks!",,['real-analysis']
74,"convergent series, sequences?","convergent series, sequences?",,"I want to construct a sequence of rational numbers whose sum converges to an irrational number and whose sum of absolute values converges to 1. I can find/construct plenty of examples that has one or the other property, but I am having trouble find/construct one that has both these properties. Any hints(not solutions)?","I want to construct a sequence of rational numbers whose sum converges to an irrational number and whose sum of absolute values converges to 1. I can find/construct plenty of examples that has one or the other property, but I am having trouble find/construct one that has both these properties. Any hints(not solutions)?",,"['real-analysis', 'analysis']"
75,Countability of irrationals,Countability of irrationals,,"Since the reals are uncountable, rationals countable and rationals + irrationals = reals, it follows that the irrational numbers are uncountable. I think I've found a ""disproof"" of this fact, and I can't see the error. Since $Q$ is countable, list $q_1, q_2, \dots$ such that $q_i < q_{i+1}$. I want to show that between $q_i$ and $q_{i+1}$ there is exactly one irrational number; this will give us a bijection and prove the irrationals countable. Since the irrationals are dense, it follows that there is at least one irrational number in $\left(q_i,q_{i+1}\right)$. Suppose there was more than one in this range, e.g. $x$ and $y$. Since $(x,y)$ is an open subset of $R$ and the rationals are dense, there must be some rational $q_c$ in this interval. But that means $q_i<q_c<q_{i+1}$, which contradicts our ordering. So there must be exactly one irrational in this range. QED. Where is the problem? The only thing I can think of is that the rationals can be put into a sequence, but cannot be put into an increasing sequence, which seems odd.","Since the reals are uncountable, rationals countable and rationals + irrationals = reals, it follows that the irrational numbers are uncountable. I think I've found a ""disproof"" of this fact, and I can't see the error. Since $Q$ is countable, list $q_1, q_2, \dots$ such that $q_i < q_{i+1}$. I want to show that between $q_i$ and $q_{i+1}$ there is exactly one irrational number; this will give us a bijection and prove the irrationals countable. Since the irrationals are dense, it follows that there is at least one irrational number in $\left(q_i,q_{i+1}\right)$. Suppose there was more than one in this range, e.g. $x$ and $y$. Since $(x,y)$ is an open subset of $R$ and the rationals are dense, there must be some rational $q_c$ in this interval. But that means $q_i<q_c<q_{i+1}$, which contradicts our ordering. So there must be exactly one irrational in this range. QED. Where is the problem? The only thing I can think of is that the rationals can be put into a sequence, but cannot be put into an increasing sequence, which seems odd.",,"['real-analysis', 'analysis', 'elementary-set-theory']"
76,How equal are a series and its sum?,How equal are a series and its sum?,,"This is a question about the logic of mathematical language concerning infinite series. It's normal to say $\sum\limits_{n=0}^\infty 2^{-n}=2$.  This type of equation is often given in the form of a notational introduction within the definition of ""converge(nt)"".  But it's also normal to assert things about $\sum\limits_{n=0}^\infty 2^{-n}$ and deny the corresponding statements about $2$: $\sum\limits_{n=0}^\infty 2^{-n}$ converges, but $2$  does not ""converge"". $\sum\limits_{n=0}^\infty 2^{-n}$ is an infinite series, but $2$ is not. On the surface, this looks like a violation of the basic substitutability of equals for equals. I see two possible explanations: First, the problem result from talking about $\sum\limits_{n=0}^\infty 2^{-n}$ but implicitly referring to its form.  For example, in ""6/3 is a fraction but 2 is not"", the idea ""is a fraction"" refers not to the value of 6/3 but to its form.  This seems plausible and attractive, especially for saying ""is an infinite series"", but it seems to be a stretch for ""converges"".  For example, to say that a nested sum $\sum\limits_{n=0}^\infty \ \sum\limits_{m=0}^\infty \ldots$ ""converges"" (treating it as a sum on $n$), we require that the inner sums be evaluated.  This does not feel like a description of form alone. Second, the problem might occur because the equality of $ \sum\limits_{n=0}^\infty 2^{-n}=2$ is not in fact sincere equality:  It means something other than logical identity.  This interpretation is strongly favored by the fact that it appears in a definition!  (Presumably we would not be entitled to redefine logical identity.)  Thus there is no reason to expect substitutability, and there is no problem.  But this seems disingenuous:  In many contexts, we freely substitute series and their sums.  We also use this ""$=$"" symbol symmetrically and transitively, mixing it without comment with normal equality. Have I correctly understood normal usage?  Is either of these interpretations the ""correct"" one?  Is there a ""logician's solution""?","This is a question about the logic of mathematical language concerning infinite series. It's normal to say $\sum\limits_{n=0}^\infty 2^{-n}=2$.  This type of equation is often given in the form of a notational introduction within the definition of ""converge(nt)"".  But it's also normal to assert things about $\sum\limits_{n=0}^\infty 2^{-n}$ and deny the corresponding statements about $2$: $\sum\limits_{n=0}^\infty 2^{-n}$ converges, but $2$  does not ""converge"". $\sum\limits_{n=0}^\infty 2^{-n}$ is an infinite series, but $2$ is not. On the surface, this looks like a violation of the basic substitutability of equals for equals. I see two possible explanations: First, the problem result from talking about $\sum\limits_{n=0}^\infty 2^{-n}$ but implicitly referring to its form.  For example, in ""6/3 is a fraction but 2 is not"", the idea ""is a fraction"" refers not to the value of 6/3 but to its form.  This seems plausible and attractive, especially for saying ""is an infinite series"", but it seems to be a stretch for ""converges"".  For example, to say that a nested sum $\sum\limits_{n=0}^\infty \ \sum\limits_{m=0}^\infty \ldots$ ""converges"" (treating it as a sum on $n$), we require that the inner sums be evaluated.  This does not feel like a description of form alone. Second, the problem might occur because the equality of $ \sum\limits_{n=0}^\infty 2^{-n}=2$ is not in fact sincere equality:  It means something other than logical identity.  This interpretation is strongly favored by the fact that it appears in a definition!  (Presumably we would not be entitled to redefine logical identity.)  Thus there is no reason to expect substitutability, and there is no problem.  But this seems disingenuous:  In many contexts, we freely substitute series and their sums.  We also use this ""$=$"" symbol symmetrically and transitively, mixing it without comment with normal equality. Have I correctly understood normal usage?  Is either of these interpretations the ""correct"" one?  Is there a ""logician's solution""?",,"['real-analysis', 'sequences-and-series', 'logic']"
77,"Points of discontinuity of a bijective function $f:\mathbb{R} \to [0,\infty)$",Points of discontinuity of a bijective function,"f:\mathbb{R} \to [0,\infty)","We know that the points of discontinuity of a monotone function on an interval $[a,b]$ are countable. Using this can we prov that: Any bijection $f: \mathbb{R} \to [0,\infty)$ has infinitely many points of discontinuity. If yes, how or otherwise how to prove the above result?","We know that the points of discontinuity of a monotone function on an interval $[a,b]$ are countable. Using this can we prov that: Any bijection $f: \mathbb{R} \to [0,\infty)$ has infinitely many points of discontinuity. If yes, how or otherwise how to prove the above result?",,['real-analysis']
78,"Asymptotics of $\int^{\pi/2}_0 xf(x)(\cos x)^n\,dx$",Asymptotics of,"\int^{\pi/2}_0 xf(x)(\cos x)^n\,dx","The following is an old Analysis qualifying problem I am tried to solve but I have not been able to solve rigorously. Suppose $f$ is continuous in $[0,\pi/2]$ . A simple application of dominated convergence shows that $$I_n=\int^{\pi/2}_0 x f(x) (\cos x)^n\, dx \rightarrow0\quad\text{as}\quad n\rightarrow\infty$$ The problem asks to show that $$I_n\sim \frac{1}{n}f(0)+o(1/n)$$ This integral seems to have similarities with integrals where the Laplace method can be use. The function $\cos$ has maximum at $x=0$ in $[0,1]$ , so it is not surprise that the values of $x\in[0,\pi/2]$ that contribute to $I_n$ are those near $0$ . On the other hand, $\sin x\sim x$ as $x\rightarrow0$ . This suggest that $$I_n\sim \int^{\pi/2}_0f(0)\sin x(\cos x)^n\,dx=\frac{1}{n+1}f(0)$$ I can't find a way to put things into a  rigorous argument. Any help is appreciated. Thank you!","The following is an old Analysis qualifying problem I am tried to solve but I have not been able to solve rigorously. Suppose is continuous in . A simple application of dominated convergence shows that The problem asks to show that This integral seems to have similarities with integrals where the Laplace method can be use. The function has maximum at in , so it is not surprise that the values of that contribute to are those near . On the other hand, as . This suggest that I can't find a way to put things into a  rigorous argument. Any help is appreciated. Thank you!","f [0,\pi/2] I_n=\int^{\pi/2}_0 x f(x) (\cos x)^n\, dx \rightarrow0\quad\text{as}\quad n\rightarrow\infty I_n\sim \frac{1}{n}f(0)+o(1/n) \cos x=0 [0,1] x\in[0,\pi/2] I_n 0 \sin x\sim x x\rightarrow0 I_n\sim \int^{\pi/2}_0f(0)\sin x(\cos x)^n\,dx=\frac{1}{n+1}f(0)","['real-analysis', 'integration', 'asymptotics']"
79,How to show that $f(x)\equiv x$ for an injective and continuous $ f $ satisfying $f\big(2x-f(x)\big)\equiv x$?,How to show that  for an injective and continuous  satisfying ?,f(x)\equiv x  f  f\big(2x-f(x)\big)\equiv x,"Let $f:\mathbb R\to \mathbb R$ be a bijective function with a fixed point $a$ . i.e. $f(a)=a$ . Suppose $f$ satisfies the following relation $$f\big(2x-f(x)\big)=x \text,\qquad \forall x\in \mathbb R \text.$$ Then how can I show that $f(x)\equiv x$ ? Additional question: what about if $f$ is injective and continuous ? I saw a bit long solution of this before somewhere (I don't know where). I am looking for a beautiful solution. Edit: I think one can work on the following way for solution: Suppose there exist a $b$ such that $f(b)\ne b$ . Then the set $$K:=\{b,f(b),f\circ f(b), \dots \}$$ is a infinite set of distinct points. I have no Idea how to use this!",Let be a bijective function with a fixed point . i.e. . Suppose satisfies the following relation Then how can I show that ? Additional question: what about if is injective and continuous ? I saw a bit long solution of this before somewhere (I don't know where). I am looking for a beautiful solution. Edit: I think one can work on the following way for solution: Suppose there exist a such that . Then the set is a infinite set of distinct points. I have no Idea how to use this!,"f:\mathbb R\to \mathbb R a f(a)=a f f\big(2x-f(x)\big)=x \text,\qquad \forall x\in \mathbb R \text. f(x)\equiv x f b f(b)\ne b K:=\{b,f(b),f\circ f(b), \dots \}","['real-analysis', 'functional-equations']"
80,An exercise from Apostol's book,An exercise from Apostol's book,,"I am trying to solve following problem from Apostol's Mathematical Analysis. The problem could be very trivial, but I am not getting clue for it. Let $\{a_n\}$ be a sequence of real numbers in $[-2,2]$ such that $$|a_{n+2}-a_{n+1}|\le \frac{1}{8} |a_{n+1}^2-a_n^2| \,\,\,\, \mbox{ for all } n\ge 1.$$ Prove that $\{a_n\}$ is convergent. Q. Any hint for solving this? (I was not getting the restrictions of interval and the factor $\frac{1}{8}$ ). My try: since $a_i\in [-2,2]$ so $a_i^2\in [0,4]$ . Thus, $|a_{n+1}^2-a_n^2|\le 4$ and so $|a_{n+2}-a_{n+1}|\le \frac{1}{2}$ . After this, I couldn't proceed. Any HINT is sufficient.","I am trying to solve following problem from Apostol's Mathematical Analysis. The problem could be very trivial, but I am not getting clue for it. Let be a sequence of real numbers in such that Prove that is convergent. Q. Any hint for solving this? (I was not getting the restrictions of interval and the factor ). My try: since so . Thus, and so . After this, I couldn't proceed. Any HINT is sufficient.","\{a_n\} [-2,2] |a_{n+2}-a_{n+1}|\le \frac{1}{8} |a_{n+1}^2-a_n^2| \,\,\,\, \mbox{ for all } n\ge 1. \{a_n\} \frac{1}{8} a_i\in [-2,2] a_i^2\in [0,4] |a_{n+1}^2-a_n^2|\le 4 |a_{n+2}-a_{n+1}|\le \frac{1}{2}","['real-analysis', 'calculus']"
81,"Show that any compact metric space $X$ can be isometrically embedded into $C([0,1])$, the space of continuous functions over $[0,1]$","Show that any compact metric space  can be isometrically embedded into , the space of continuous functions over","X C([0,1]) [0,1]","Show that any compact metric space $X$ can be isometrically embedded into $C([0,1])$ , the space of continuous functions over $[0,1]$ with sup-norm $(||f||_\infty = sup_x(|f(x)|)$ I have no idea yet how to approach this, any help would be appreciated.","Show that any compact metric space can be isometrically embedded into , the space of continuous functions over with sup-norm I have no idea yet how to approach this, any help would be appreciated.","X C([0,1]) [0,1] (||f||_\infty = sup_x(|f(x)|)","['real-analysis', 'general-topology', 'functional-analysis', 'metric-spaces']"
82,Proving that the derivative always diverges faster than the original function,Proving that the derivative always diverges faster than the original function,,"Let $f$ be a differentiable real function. What is the simplest/neatest way of proving that $\lim_{x \to a} f(x) = \infty$ implies that $ \lim_{x\to a} \frac{f'(x)}{f(x)} = \infty$? It seems like such a simple statement that perhaps there is even a proof that avoids equations altogether? (Note that $a$ is a finite number.) Here is the one I came up with so far, which works by proving that integrating $\frac{f'(x)}{f(x)}$ in the vicinity of $x = a$ blows up. Indeed, $\int \frac{f'(x)}{f(x)} \mathrm d x = \int \frac{\mathrm d}{\mathrm d x} \left( \ln f(x) \right) \mathrm dx = \ln f(x) + c$, and then we can use the fact that $\lim_{x \to a} f(x) = \infty$ implies that $\lim_{x \to a} \ln f(x) = \infty$. EDIT: the above statement is not true! The catch is that $f'/f$ might not have a well-defined limit. The best one can show is that $f'/f$ is unbounded in any neighbourhood of $a$. (See RRL's answer for the proof, and Euler's answer for a counter-example to the  original statement.)","Let $f$ be a differentiable real function. What is the simplest/neatest way of proving that $\lim_{x \to a} f(x) = \infty$ implies that $ \lim_{x\to a} \frac{f'(x)}{f(x)} = \infty$? It seems like such a simple statement that perhaps there is even a proof that avoids equations altogether? (Note that $a$ is a finite number.) Here is the one I came up with so far, which works by proving that integrating $\frac{f'(x)}{f(x)}$ in the vicinity of $x = a$ blows up. Indeed, $\int \frac{f'(x)}{f(x)} \mathrm d x = \int \frac{\mathrm d}{\mathrm d x} \left( \ln f(x) \right) \mathrm dx = \ln f(x) + c$, and then we can use the fact that $\lim_{x \to a} f(x) = \infty$ implies that $\lim_{x \to a} \ln f(x) = \infty$. EDIT: the above statement is not true! The catch is that $f'/f$ might not have a well-defined limit. The best one can show is that $f'/f$ is unbounded in any neighbourhood of $a$. (See RRL's answer for the proof, and Euler's answer for a counter-example to the  original statement.)",,"['real-analysis', 'integration', 'derivatives', 'singularity']"
83,Collect 'unusual' examples of real-valued functions,Collect 'unusual' examples of real-valued functions,,"I am trying to collect research papers, articles and books which contain 'weird' or 'unusual' examples of real-valued function. An example of research paper is A Counterexample and an Exact Versoin of Fatou's Lemma in Infinite Dimension An example of article is Some counterexamples on the behaviour of real-valued functions and their derivatives Examples of books are Surprises and Counterexamples in Real Function Theory Analysis in examples and counterexamples. An introduction to the theory of real functions Counterexamples in Analysis Question: Can someone provide me more articles and books which are similar to the above? My aim is to learn as many function construction techniques as possible.","I am trying to collect research papers, articles and books which contain 'weird' or 'unusual' examples of real-valued function. An example of research paper is A Counterexample and an Exact Versoin of Fatou's Lemma in Infinite Dimension An example of article is Some counterexamples on the behaviour of real-valued functions and their derivatives Examples of books are Surprises and Counterexamples in Real Function Theory Analysis in examples and counterexamples. An introduction to the theory of real functions Counterexamples in Analysis Question: Can someone provide me more articles and books which are similar to the above? My aim is to learn as many function construction techniques as possible.",,"['real-analysis', 'functions', 'reference-request', 'soft-question', 'examples-counterexamples']"
84,$\|f\|_p\to \|f\|_\infty$ under general assumptions,under general assumptions,\|f\|_p\to \|f\|_\infty,"I am trying to show that for nonnegative $f$ on $\mathbb{R}$ if $||f||_1<\infty$ , we have $$ \lim_{p\uparrow \infty}\|f\|_p=\|f\|_\infty $$ I have tried to fiddle around with $$ \left(\int_\mathbb{R}|f|^p|f|^{1-p} \right)^{1/p}<\infty $$ but haven't found a nice way to get an estimate on $\int_E|f|^p$ from this. Honestly I am pretty uncomfortable with non finite measure spaces. Any hints would be awesome! Any references for problems similar to this would also be awesome. edit: this is not a duplicate of the linked question as 1) my measure space is not finite, 2) my function is in $L^1$ and not necessarily in $L^\infty$","I am trying to show that for nonnegative on if , we have I have tried to fiddle around with but haven't found a nice way to get an estimate on from this. Honestly I am pretty uncomfortable with non finite measure spaces. Any hints would be awesome! Any references for problems similar to this would also be awesome. edit: this is not a duplicate of the linked question as 1) my measure space is not finite, 2) my function is in and not necessarily in","f \mathbb{R} ||f||_1<\infty 
\lim_{p\uparrow \infty}\|f\|_p=\|f\|_\infty
 
\left(\int_\mathbb{R}|f|^p|f|^{1-p} \right)^{1/p}<\infty
 \int_E|f|^p L^1 L^\infty","['real-analysis', 'functional-analysis', 'measure-theory', 'lp-spaces']"
85,Convergence test for series with definite integral summand,Convergence test for series with definite integral summand,,"I was asked by a friend this problem: Show whether the series $$\sum_{n = 1}^{\infty} \int_{0}^{1 / \sqrt{n}} \frac{\mathrm{e}^{x} - 1}{1 + x} \mathop{}\!\mathrm{d} x$$ converges. Now the integral does not have a closed form, and the summand evidently vanishes as $n \to \infty$. I've tried to apply all convergence tests that I could find, but none seem to work in this case. Many of them (d'Alembert, Dirichlet, etc.) try to evaluate $\displaystyle \frac{a_{n + 1}}{a_{n}}$ and then do something about it, but in this case, when the summand is a definite integral, this fraction doesn't seem to simply things much... Nor does it seem to simply things to evaluate the square root $\sqrt{\lvert a_{n}\rvert}$ or the integral $\displaystyle \int_{1}^{\infty} a_{n} \mathop{}\!\mathrm{d} n$. The Cauchy condensation test evaluates $2^{n} a_{2^{n}}$, which also doesn't seem to lead anywhere... I think the reason the aforementioned tests don't seem to work (based on my trial anyway...maybe they do and I'm just not seeing it) is that the summand is an integral. Hence I was wondering if there is a convergence test which works for series with definite integral summand? Edit : As Jack pointed out below, there is no need for a test specifically for series with integral summand. (It's techniques and tricks combined with available tests)","I was asked by a friend this problem: Show whether the series $$\sum_{n = 1}^{\infty} \int_{0}^{1 / \sqrt{n}} \frac{\mathrm{e}^{x} - 1}{1 + x} \mathop{}\!\mathrm{d} x$$ converges. Now the integral does not have a closed form, and the summand evidently vanishes as $n \to \infty$. I've tried to apply all convergence tests that I could find, but none seem to work in this case. Many of them (d'Alembert, Dirichlet, etc.) try to evaluate $\displaystyle \frac{a_{n + 1}}{a_{n}}$ and then do something about it, but in this case, when the summand is a definite integral, this fraction doesn't seem to simply things much... Nor does it seem to simply things to evaluate the square root $\sqrt{\lvert a_{n}\rvert}$ or the integral $\displaystyle \int_{1}^{\infty} a_{n} \mathop{}\!\mathrm{d} n$. The Cauchy condensation test evaluates $2^{n} a_{2^{n}}$, which also doesn't seem to lead anywhere... I think the reason the aforementioned tests don't seem to work (based on my trial anyway...maybe they do and I'm just not seeing it) is that the summand is an integral. Hence I was wondering if there is a convergence test which works for series with definite integral summand? Edit : As Jack pointed out below, there is no need for a test specifically for series with integral summand. (It's techniques and tricks combined with available tests)",,"['real-analysis', 'sequences-and-series']"
86,Solve $\sum_{k=0}^{\infty}\frac{1}{1-16k^2}$,Solve,\sum_{k=0}^{\infty}\frac{1}{1-16k^2},"I could use some help on calculating this infinite sum: $\sum_{k=0}^{\infty}\frac{1}{1-16k^2}$. Included was that I had to start with a Fourier series for the function $f:\Re \to \Re: x \mapsto \sin(x)$ for $x\in[0, \frac{\pi}{2}[$, so let's start with that. Let  \begin{eqnarray*} g(x) = \frac{a_0}{2} + \sum_{k=1}^{\infty}a_k\cos(4kx) + \sum_{k=1}^{\infty}b_k\sin(4kx). \end{eqnarray*}  This is the Fourier series for $f$. With $a_k = \frac{4}{\pi}\int_{0}^{\frac{\pi}{2}}\sin(x)\cos(4kx)dx$ and $b_k = \frac{4}{\pi}\int_{0}^{\frac{\pi}{2}}\sin(x)\sin(4kx)dx$. Solving this leads to (or at least I found that): $a_k = \frac{4}{(1-16k^2)\pi}$, $b_k = \frac{16k}{(1-16k^2)\pi}$ for $k\geq1$ and $a_0 = \frac{4}{\pi}$. Bringing this to $g(x)$ gives: \begin{eqnarray*} g(x) = \frac{2}{\pi} + \sum_{k=1}^{\infty}\frac{4}{(1-16k^2)\pi}\cos(4kx) + \sum_{k=1}^{\infty}\frac{16k}{(1-16k^2)\pi}\sin(4kx).  \end{eqnarray*} Since $f(x) \approx g(x)$, we can say that $f(0) = g(0)$. We get  \begin{eqnarray*} \sin(0) = \frac{2}{\pi} + \sum_{k=1}^{\infty}\frac{4}{(1-16k^2)\pi}\cos(0) + \sum_{k=1}^{\infty}\frac{16k}{(1-16k^2)\pi}\sin(0), \end{eqnarray*} this becomes  \begin{eqnarray*} 0 = \frac{2}{\pi} + \sum_{k=1}^{\infty}\frac{4}{(1-16k^2)\pi}. \end{eqnarray*} We get  \begin{eqnarray*} \frac{-2}{\pi} = \frac{4}{\pi}\sum_{k=1}^{\infty}\frac{1}{1-16k^2} \end{eqnarray*} so  \begin{eqnarray*} \sum_{k=1}^{\infty}\frac{1}{1-16k^2} = \frac{-1}{2}. \end{eqnarray*} We need the sum from k = 0. The term $\frac{1}{1-16k^2}$ for k = 0 gives 1, so we add 1 to both sides. This leads to my solution  \begin{eqnarray*} \sum_{k=0}^{\infty}\frac{1}{1-16k^2} = \frac{1}{2}. \end{eqnarray*} However, when approaching this sum numerically and using Wolfram, I find that the sum should be $\frac{4+\pi}{8}$. Could some help and point out where I went wrong with my approach? Thanks in advance","I could use some help on calculating this infinite sum: $\sum_{k=0}^{\infty}\frac{1}{1-16k^2}$. Included was that I had to start with a Fourier series for the function $f:\Re \to \Re: x \mapsto \sin(x)$ for $x\in[0, \frac{\pi}{2}[$, so let's start with that. Let  \begin{eqnarray*} g(x) = \frac{a_0}{2} + \sum_{k=1}^{\infty}a_k\cos(4kx) + \sum_{k=1}^{\infty}b_k\sin(4kx). \end{eqnarray*}  This is the Fourier series for $f$. With $a_k = \frac{4}{\pi}\int_{0}^{\frac{\pi}{2}}\sin(x)\cos(4kx)dx$ and $b_k = \frac{4}{\pi}\int_{0}^{\frac{\pi}{2}}\sin(x)\sin(4kx)dx$. Solving this leads to (or at least I found that): $a_k = \frac{4}{(1-16k^2)\pi}$, $b_k = \frac{16k}{(1-16k^2)\pi}$ for $k\geq1$ and $a_0 = \frac{4}{\pi}$. Bringing this to $g(x)$ gives: \begin{eqnarray*} g(x) = \frac{2}{\pi} + \sum_{k=1}^{\infty}\frac{4}{(1-16k^2)\pi}\cos(4kx) + \sum_{k=1}^{\infty}\frac{16k}{(1-16k^2)\pi}\sin(4kx).  \end{eqnarray*} Since $f(x) \approx g(x)$, we can say that $f(0) = g(0)$. We get  \begin{eqnarray*} \sin(0) = \frac{2}{\pi} + \sum_{k=1}^{\infty}\frac{4}{(1-16k^2)\pi}\cos(0) + \sum_{k=1}^{\infty}\frac{16k}{(1-16k^2)\pi}\sin(0), \end{eqnarray*} this becomes  \begin{eqnarray*} 0 = \frac{2}{\pi} + \sum_{k=1}^{\infty}\frac{4}{(1-16k^2)\pi}. \end{eqnarray*} We get  \begin{eqnarray*} \frac{-2}{\pi} = \frac{4}{\pi}\sum_{k=1}^{\infty}\frac{1}{1-16k^2} \end{eqnarray*} so  \begin{eqnarray*} \sum_{k=1}^{\infty}\frac{1}{1-16k^2} = \frac{-1}{2}. \end{eqnarray*} We need the sum from k = 0. The term $\frac{1}{1-16k^2}$ for k = 0 gives 1, so we add 1 to both sides. This leads to my solution  \begin{eqnarray*} \sum_{k=0}^{\infty}\frac{1}{1-16k^2} = \frac{1}{2}. \end{eqnarray*} However, when approaching this sum numerically and using Wolfram, I find that the sum should be $\frac{4+\pi}{8}$. Could some help and point out where I went wrong with my approach? Thanks in advance",,"['real-analysis', 'sequences-and-series', 'fourier-series']"
87,"Given subsequences converge, prove that the sequence converges.","Given subsequences converge, prove that the sequence converges.",,"I have looked through previous posts but have been struggling with this problem. The sequence is {$a_n$} and its subsequences {$a_{2k}$}, {$a_{2k+1}$}, {$a_{3k}$} converge. I have to prove that {$a_n$} converges. I know that a sequence converges if all of its subsequences converge. I'm suspecting that I have to prove that every subsequence belongs into these 3 subsequences. Thank you for your time and help.","I have looked through previous posts but have been struggling with this problem. The sequence is {$a_n$} and its subsequences {$a_{2k}$}, {$a_{2k+1}$}, {$a_{3k}$} converge. I have to prove that {$a_n$} converges. I know that a sequence converges if all of its subsequences converge. I'm suspecting that I have to prove that every subsequence belongs into these 3 subsequences. Thank you for your time and help.",,['real-analysis']
88,How to Find $ \lim\limits_{x\to 0} \left(\frac {\tan x }{x} \right)^{\frac{1}{x^2}}$.,How to Find ., \lim\limits_{x\to 0} \left(\frac {\tan x }{x} \right)^{\frac{1}{x^2}},"Can someone help me with this limit? I'm working on it for hours and cant figure it out. $$ \lim_{x\to 0} \left(\frac {\tan x }{x} \right)^{\frac{1}{x^2}}$$ I started transforming to the form $ \lim_{x\to 0} e^{  {\frac{\ln \left(\frac {\tan x}{x} \right)}{x^2}}  }$ and applied the l'Hopital rule (since indeterminated $\frac00$), getting: $$ \lim_{x\to 0} \left( \frac{2x-\sin 2x }{2x^2\sin 2x} \right)$$ From here, I try continue with various forms of trigonometric substitutions, appling the l'Hopital rule again and again, but no luck for me. Can someone help me?","Can someone help me with this limit? I'm working on it for hours and cant figure it out. $$ \lim_{x\to 0} \left(\frac {\tan x }{x} \right)^{\frac{1}{x^2}}$$ I started transforming to the form $ \lim_{x\to 0} e^{  {\frac{\ln \left(\frac {\tan x}{x} \right)}{x^2}}  }$ and applied the l'Hopital rule (since indeterminated $\frac00$), getting: $$ \lim_{x\to 0} \left( \frac{2x-\sin 2x }{2x^2\sin 2x} \right)$$ From here, I try continue with various forms of trigonometric substitutions, appling the l'Hopital rule again and again, but no luck for me. Can someone help me?",,"['real-analysis', 'limits', 'trigonometry', 'exponential-function', 'limits-without-lhopital']"
89,Does $|f'(x)|<1$ imply $f$ has a fixed point?,Does  imply  has a fixed point?,|f'(x)|<1 f,"$f :\mathbb R \rightarrow \mathbb R$ is differentiable on $\mathbb R $ and $|f'(x)| \lt 1$, does $f$ have a fixed point? I think it does but I can't finish the proof. Let's define $g(x) = f(x) - x$, we want to prove that this function is equal to $0$ at some point. $g'(x) = f'(x) - 1 \in (-2,0)$, so $g$ is strictly decreasing. What now?","$f :\mathbb R \rightarrow \mathbb R$ is differentiable on $\mathbb R $ and $|f'(x)| \lt 1$, does $f$ have a fixed point? I think it does but I can't finish the proof. Let's define $g(x) = f(x) - x$, we want to prove that this function is equal to $0$ at some point. $g'(x) = f'(x) - 1 \in (-2,0)$, so $g$ is strictly decreasing. What now?",,['real-analysis']
90,Why does $\sum_{n=0}^{\infty} \cos^n(n)$ converges?,Why does  converges?,\sum_{n=0}^{\infty} \cos^n(n),"Consider the series $$\sum_{n=0}^{\infty}\cos^n(n)$$ I think that the root test is inconclusive, because $$\limsup_n \sqrt[n]{|\cos^n(n)|}=\limsup_n|\cos(n)|\leq 1$$ once we can approximate $\pi$ by rational numbers, there will always be some $i$ and $j\in\mathbb{N}$ such that $|j\pi-i|<\varepsilon$, for every $\varepsilon>0$ that we choose. And in this case $|\cos(i)-1|<\delta$. Nevertheless, it seems that it converges . I can't think of any other convergent series to compare with it. My question is: how can I prove that this series converges? Edit : Actually, this series diverges, as you can see in tmyklebu's answer. I made a fortran program  and here are some values of the sequence of the partial sums: n     S_n 10    1.5898364866640549 100   7.8365722183614510 1000  24.825953005207236 10000 79.232008037801393","Consider the series $$\sum_{n=0}^{\infty}\cos^n(n)$$ I think that the root test is inconclusive, because $$\limsup_n \sqrt[n]{|\cos^n(n)|}=\limsup_n|\cos(n)|\leq 1$$ once we can approximate $\pi$ by rational numbers, there will always be some $i$ and $j\in\mathbb{N}$ such that $|j\pi-i|<\varepsilon$, for every $\varepsilon>0$ that we choose. And in this case $|\cos(i)-1|<\delta$. Nevertheless, it seems that it converges . I can't think of any other convergent series to compare with it. My question is: how can I prove that this series converges? Edit : Actually, this series diverges, as you can see in tmyklebu's answer. I made a fortran program  and here are some values of the sequence of the partial sums: n     S_n 10    1.5898364866640549 100   7.8365722183614510 1000  24.825953005207236 10000 79.232008037801393",,"['real-analysis', 'sequences-and-series', 'trigonometric-series']"
91,Can anyone explain this equation (about $\frac\pi2$ ),Can anyone explain this equation (about  ),\frac\pi2,"$${\frac{\pi}{2} = \lim_{l \to \infty} \prod_{j = 1}^{l + 1} \frac{(2j)(2j)}{(2j - 1)(2j+1)}}$$ Hi all. My first impression of this equation is naive curiosity why ""limit"" is required. Can I just drop the limit sign and replace $l+1$ by $\infty$? Or If ""limit"" can not be omitted, why would we multiply all the terms upto $l+1$? Does it change anything if I replace $l+1$ by $l$?","$${\frac{\pi}{2} = \lim_{l \to \infty} \prod_{j = 1}^{l + 1} \frac{(2j)(2j)}{(2j - 1)(2j+1)}}$$ Hi all. My first impression of this equation is naive curiosity why ""limit"" is required. Can I just drop the limit sign and replace $l+1$ by $\infty$? Or If ""limit"" can not be omitted, why would we multiply all the terms upto $l+1$? Does it change anything if I replace $l+1$ by $l$?",,"['real-analysis', 'analysis']"
92,Calculating in closed form $\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{m^4(m^2+n^2)}$,Calculating in closed form,\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{m^4(m^2+n^2)},How would you tackle this series by real analysis? $$\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{m^4(m^2+n^2)}$$,How would you tackle this series by real analysis? $$\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{m^4(m^2+n^2)}$$,,"['calculus', 'real-analysis', 'sequences-and-series']"
93,Lie group. How is manifold defined?,Lie group. How is manifold defined?,,"If I have the Lie group $SL(2,\mathbb{R})$. Then how is the manifold structure on this algebraic group defined, could anybody explain this to me? I mean this is the group of matrices that determinant one, but where comes the manifold structure from?","If I have the Lie group $SL(2,\mathbb{R})$. Then how is the manifold structure on this algebraic group defined, could anybody explain this to me? I mean this is the group of matrices that determinant one, but where comes the manifold structure from?",,"['real-analysis', 'differential-geometry', 'algebraic-topology', 'differential-topology', 'lie-groups']"
94,"Cauchy sequences - can we control the rate at which elements ""get closer""?","Cauchy sequences - can we control the rate at which elements ""get closer""?",,"In Simon & Reed's book Methods of Modern Mathematical Physics, it is proven in chapter 1 (Theorem 1.12) that $L^1$ is complete (Riesz-Fisher theorem). The proof starts off as follows: Let $f_n$ be a Cauchy sequence of functions in $L^1$. It is enough to show that some subsequence converges (this has been shown earlier) so we pass to a subsequence (labeled in the same way) with $\left|\left|f_n-f_{n+1}\right|\right|_1\leq 2^{-n}$ . This arouses my suspicion (although surely I will turn out to be wrong): Can we pick a subsequence such that $\left|\left|f_n-f_{n+1}\right|\right|_1\leq 2^{-n}$? This seems strange to me because it seems to say something about the rate of at which elements ""get closer"" under this norm (I should probably specify that $\left|\left| f\right|\right|_1=\int \left| f \right| dx$), rather than just saying that they do get arbitrarily close at some point. In particular, it seems to say that each progressive element is ""twice as close"". The definition of a Cauchy sequence says that for each $\epsilon>0$ we can choose and $N$ such that $n,m>N$ implies $\left|\left| f_n-f_m\right|\right|_1=d(f_n,f_m)\leq\epsilon$, where $d(\cdot,\cdot)$ is the metric induced by the norm. This, to me, does not seem equivalent to saying that for any strictly positive $\epsilon(n)$ there is a subsequence such that $d(f_n,f_{n+1})\leq \epsilon(n)$. Am I mistaken?","In Simon & Reed's book Methods of Modern Mathematical Physics, it is proven in chapter 1 (Theorem 1.12) that $L^1$ is complete (Riesz-Fisher theorem). The proof starts off as follows: Let $f_n$ be a Cauchy sequence of functions in $L^1$. It is enough to show that some subsequence converges (this has been shown earlier) so we pass to a subsequence (labeled in the same way) with $\left|\left|f_n-f_{n+1}\right|\right|_1\leq 2^{-n}$ . This arouses my suspicion (although surely I will turn out to be wrong): Can we pick a subsequence such that $\left|\left|f_n-f_{n+1}\right|\right|_1\leq 2^{-n}$? This seems strange to me because it seems to say something about the rate of at which elements ""get closer"" under this norm (I should probably specify that $\left|\left| f\right|\right|_1=\int \left| f \right| dx$), rather than just saying that they do get arbitrarily close at some point. In particular, it seems to say that each progressive element is ""twice as close"". The definition of a Cauchy sequence says that for each $\epsilon>0$ we can choose and $N$ such that $n,m>N$ implies $\left|\left| f_n-f_m\right|\right|_1=d(f_n,f_m)\leq\epsilon$, where $d(\cdot,\cdot)$ is the metric induced by the norm. This, to me, does not seem equivalent to saying that for any strictly positive $\epsilon(n)$ there is a subsequence such that $d(f_n,f_{n+1})\leq \epsilon(n)$. Am I mistaken?",,"['real-analysis', 'normed-spaces', 'cauchy-sequences']"
95,Another Epsilon-N Limit Proof Question,Another Epsilon-N Limit Proof Question,,"How to prove the limit of the following sequence using epsilon-N argument. $$a_n=\frac{3n^2+2n+1}{2n^2+n}$$ I took the limit to be $\frac{3}{2}$ and proceeded with the argument, $$\left|\frac{3n^2+2n+1}{2n^2+n}-\frac{3}{2}\right|<\epsilon$$ $$\frac{n+2}{4n^2+2n}<\epsilon$$ How do I complete the argument from this point?","How to prove the limit of the following sequence using epsilon-N argument. $$a_n=\frac{3n^2+2n+1}{2n^2+n}$$ I took the limit to be $\frac{3}{2}$ and proceeded with the argument, $$\left|\frac{3n^2+2n+1}{2n^2+n}-\frac{3}{2}\right|<\epsilon$$ $$\frac{n+2}{4n^2+2n}<\epsilon$$ How do I complete the argument from this point?",,"['calculus', 'real-analysis', 'sequences-and-series', 'limits', 'epsilon-delta']"
96,How to prove that the sum of two log-convex functions is log-convex?,How to prove that the sum of two log-convex functions is log-convex?,,"Let $(a,b)$ be an open interval. Let $f,g : (a,b) \to \mathbb{R}$ be positive log-convex functions. How to prove that $f+g$ is log-convex? I am reading a proof using quadratic forms, but I'm not really familiar with quadratic forms, so I don't get the proof. Please help.","Let be an open interval. Let be positive log-convex functions. How to prove that is log-convex? I am reading a proof using quadratic forms, but I'm not really familiar with quadratic forms, so I don't get the proof. Please help.","(a,b) f,g : (a,b) \to \mathbb{R} f+g","['real-analysis', 'convex-analysis']"
97,Can $\le$ be used insted of < in the definition of continuity?,Can  be used insted of < in the definition of continuity?,\le,"A common definition of a continuous map $T:M_1\to M_2$ is that for every $x\in M_1$ and every $\varepsilon>0$ there exists a $\delta >0$ such that for all $y$ in $M_1$ $$d_1(x,y)<\delta \implies d_2(T(x),T(y))<\varepsilon,$$ i.e. we use a strict inequality. Now in a proof it reads that $T$ is continuous if for every $x\in M_1$ and every $\varepsilon>0$ there is a $\delta>0$ such that $$\|Tx-Ty\|\le\varepsilon\ \mbox{for all $y$ in $M_1$ satisfying } \|x-y\|\le \delta.$$ Here the norm is given by the metric. Is it correct to use $\le$ instead of the strict inequality <, and can one somehow prove the equality of these definitions? Or is this obviously the same condition? Thanks in advance!","A common definition of a continuous map is that for every and every there exists a such that for all in i.e. we use a strict inequality. Now in a proof it reads that is continuous if for every and every there is a such that Here the norm is given by the metric. Is it correct to use instead of the strict inequality <, and can one somehow prove the equality of these definitions? Or is this obviously the same condition? Thanks in advance!","T:M_1\to M_2 x\in M_1 \varepsilon>0 \delta >0 y M_1 d_1(x,y)<\delta \implies d_2(T(x),T(y))<\varepsilon, T x\in M_1 \varepsilon>0 \delta>0 \|Tx-Ty\|\le\varepsilon\ \mbox{for all y in M_1 satisfying } \|x-y\|\le \delta. \le","['real-analysis', 'general-topology', 'functional-analysis', 'metric-spaces', 'continuity']"
98,Can We Represent Every Real Number Using Only Finite Memory?,Can We Represent Every Real Number Using Only Finite Memory?,,"This question arises from a comment I recently read in another question. My question is whether we can represent every real number using only finite memory. I will clarify what I mean by represent using only finite memory by use of examples: $5$ can be represented in finite memory simply by itself as a one-character string. Similarly for $1.234583$, which can also be represented by a string of finite length. $\pi$ can also be adequately represented in finite memory: it is the ratio of any circle's circumference to its diameter. $e$ we can represent as $\displaystyle\lim_{n \rightarrow \infty} \left(1+\frac1n\right)^n$ $0.818181\ldots$ can be represented as $0.\overline{81}$ or $\frac{9}{11}$. $0.010011000111\ldots$ can be represented as the sum of some sequence $a_n$ as $n\rightarrow \infty$. For all the examples above, an adequate representation of the given real is possible using only finite memory, because we can describe/define exactly the given real using a string of finite length. So do any reals that cannot be described/represented in finite memory exist? For which their only closed-form expression requires a string of infinite length? (Infinitely many digits?) Relevant Reading Material Includes: Is it possible to represent every huge number in abbreviated form? Every Number is Describable?","This question arises from a comment I recently read in another question. My question is whether we can represent every real number using only finite memory. I will clarify what I mean by represent using only finite memory by use of examples: $5$ can be represented in finite memory simply by itself as a one-character string. Similarly for $1.234583$, which can also be represented by a string of finite length. $\pi$ can also be adequately represented in finite memory: it is the ratio of any circle's circumference to its diameter. $e$ we can represent as $\displaystyle\lim_{n \rightarrow \infty} \left(1+\frac1n\right)^n$ $0.818181\ldots$ can be represented as $0.\overline{81}$ or $\frac{9}{11}$. $0.010011000111\ldots$ can be represented as the sum of some sequence $a_n$ as $n\rightarrow \infty$. For all the examples above, an adequate representation of the given real is possible using only finite memory, because we can describe/define exactly the given real using a string of finite length. So do any reals that cannot be described/represented in finite memory exist? For which their only closed-form expression requires a string of infinite length? (Infinitely many digits?) Relevant Reading Material Includes: Is it possible to represent every huge number in abbreviated form? Every Number is Describable?",,"['real-analysis', 'number-theory', 'formal-languages']"
99,$f(x)=\sin x^3$ for $x\in \mathbb{R}$ is not uniformly continuous,for  is not uniformly continuous,f(x)=\sin x^3 x\in \mathbb{R},"Question is to prove that : $f(x)=\sin x^3$ for $x\in \mathbb{R}$ is not uniformly continuous. What would my first observation in checking uniform continuity is to check if its derivative is bounded. In this case its derivative $f'(x)=3x^2\sin x^3$ which is unbounded. So, I can not rely on this. I tried with definition : $|f(x)-f(y)|=|\sin x^3-\sin y^3|=|2\cos (\frac{x^3+y^3}{2})\sin (\frac{x^3-y^3}{2})|\leq 2 |\sin (\frac{x^3-y^3}{2})|$ I see that $\sin x \leq  x$.. This may not imply $|\sin x|\leq |x|$ but  i am assuming it... So, $|f(x)-f(y)|\leq 2 |\sin (\frac{x^3-y^3}{2})|\leq 2\frac{|x^3-y^3|}{2}=|x^3-y^3|=|x-y||x^2+xy+y^2|$. Though $|x-y|$ is small i should make $|f(x)-f(y)|$ considerably large. I now have $|f(x)-f(y)|\leq 2 |x-y||x^2+xy+y^2|$ I some how can sense that I can make $|x^2+xy+y^2|$ large enough though $|x-y|$ is small but not so sure how to make this in $\epsilon-\delta$ case. Please help me to solve this. Thank you. EDIT : I know that uniform continuous functions takes cauchy sequence to cauchy sequence and tried to use it in this case. But, I could not find correct cauchy sequence that would help me to go through this. I would be thankful if some one can help me in this way too.","Question is to prove that : $f(x)=\sin x^3$ for $x\in \mathbb{R}$ is not uniformly continuous. What would my first observation in checking uniform continuity is to check if its derivative is bounded. In this case its derivative $f'(x)=3x^2\sin x^3$ which is unbounded. So, I can not rely on this. I tried with definition : $|f(x)-f(y)|=|\sin x^3-\sin y^3|=|2\cos (\frac{x^3+y^3}{2})\sin (\frac{x^3-y^3}{2})|\leq 2 |\sin (\frac{x^3-y^3}{2})|$ I see that $\sin x \leq  x$.. This may not imply $|\sin x|\leq |x|$ but  i am assuming it... So, $|f(x)-f(y)|\leq 2 |\sin (\frac{x^3-y^3}{2})|\leq 2\frac{|x^3-y^3|}{2}=|x^3-y^3|=|x-y||x^2+xy+y^2|$. Though $|x-y|$ is small i should make $|f(x)-f(y)|$ considerably large. I now have $|f(x)-f(y)|\leq 2 |x-y||x^2+xy+y^2|$ I some how can sense that I can make $|x^2+xy+y^2|$ large enough though $|x-y|$ is small but not so sure how to make this in $\epsilon-\delta$ case. Please help me to solve this. Thank you. EDIT : I know that uniform continuous functions takes cauchy sequence to cauchy sequence and tried to use it in this case. But, I could not find correct cauchy sequence that would help me to go through this. I would be thankful if some one can help me in this way too.",,['real-analysis']
