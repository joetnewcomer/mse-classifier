,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,All the roots of $\lambda x+\cot(x)=0$ are real. Looking for an alternative proof,All the roots of  are real. Looking for an alternative proof,\lambda x+\cot(x)=0,"I am looking for an alternative (possibly simpler) proof of the following fact, that has some relevance in finding the eigenfunctions for the laplacian operator . For any $\lambda\in\mathbb{R}^+$, $\lambda\geq 1$, all the solutions of    $$  \cot(x) + \lambda x = 0$$   belong to $\mathbb{R}$. My proof goes as follows: we just have to prove that all the roots of $f(x)=\cot(x)+\lambda x$ are real. If we assume the opposite, then $f'(x)=\lambda-\frac{1}{\sin^2(x)}$ must have some complex root by the Gauss-Lucas theorem . That is the same as stating that for some $z\in\mathbb{C}\setminus\mathbb{R}$ we have $\sin(z)=\pm\frac{1}{\sqrt{\lambda}}$, or, by setting $z=\sigma+it$, $$ e^{i\sigma-t}-e^{-i\sigma+t} = \pm\frac{2i}{\sqrt{\lambda}}. $$ However, if we set $w=e^{iz}$, the equation $w-\frac{1}{w}=\frac{2i}{\sqrt{\lambda}}$ is solved only by  $$ w = \frac{i\pm\sqrt{\lambda-1}}{\sqrt{\lambda}} $$ that is a number on the unit circle. That leads to $z\in\mathbb{R}$, i.e. $t=0$. Extra question. What can we say about the distribution of the roots if $\lambda\in\mathbb{R}$ but $\lambda < 1$?","I am looking for an alternative (possibly simpler) proof of the following fact, that has some relevance in finding the eigenfunctions for the laplacian operator . For any $\lambda\in\mathbb{R}^+$, $\lambda\geq 1$, all the solutions of    $$  \cot(x) + \lambda x = 0$$   belong to $\mathbb{R}$. My proof goes as follows: we just have to prove that all the roots of $f(x)=\cot(x)+\lambda x$ are real. If we assume the opposite, then $f'(x)=\lambda-\frac{1}{\sin^2(x)}$ must have some complex root by the Gauss-Lucas theorem . That is the same as stating that for some $z\in\mathbb{C}\setminus\mathbb{R}$ we have $\sin(z)=\pm\frac{1}{\sqrt{\lambda}}$, or, by setting $z=\sigma+it$, $$ e^{i\sigma-t}-e^{-i\sigma+t} = \pm\frac{2i}{\sqrt{\lambda}}. $$ However, if we set $w=e^{iz}$, the equation $w-\frac{1}{w}=\frac{2i}{\sqrt{\lambda}}$ is solved only by  $$ w = \frac{i\pm\sqrt{\lambda-1}}{\sqrt{\lambda}} $$ that is a number on the unit circle. That leads to $z\in\mathbb{R}$, i.e. $t=0$. Extra question. What can we say about the distribution of the roots if $\lambda\in\mathbb{R}$ but $\lambda < 1$?",,['complex-analysis']
1,Understanding what is the order of a meromorphic function,Understanding what is the order of a meromorphic function,,"I am reading a book on Complex Curves by Miranda. The book defined meromorphic function: A function on an open set W of a Riemann surface X is said to be meromorphic at $p \in W$ if there exists a chart $\phi: U \rightarrow V$ where $p \in U$ such that $f \circ \phi^{-1}$ is either holomorphic or has removable singularity at $\phi(p)$ or a pole at $\phi(p)$. Then we defined the order of a meromorphic function f at p to be the minimal power of the Laurent series ie $ord_p(f)=\min\{n: c_n\}$ for the $\sum c_n(z-z_0)^n$. So it was noted that this is independent of the chart. I am confused on what this order is. For example if we work with the Riemann Sphere and we have a $ord_p(f)=3$ what does this mean for f? I guess from what I have read, the $ord_p(f)$ is the order of the pole if it negative value. Is this what I should understand from the order function?","I am reading a book on Complex Curves by Miranda. The book defined meromorphic function: A function on an open set W of a Riemann surface X is said to be meromorphic at $p \in W$ if there exists a chart $\phi: U \rightarrow V$ where $p \in U$ such that $f \circ \phi^{-1}$ is either holomorphic or has removable singularity at $\phi(p)$ or a pole at $\phi(p)$. Then we defined the order of a meromorphic function f at p to be the minimal power of the Laurent series ie $ord_p(f)=\min\{n: c_n\}$ for the $\sum c_n(z-z_0)^n$. So it was noted that this is independent of the chart. I am confused on what this order is. For example if we work with the Riemann Sphere and we have a $ord_p(f)=3$ what does this mean for f? I guess from what I have read, the $ord_p(f)$ is the order of the pole if it negative value. Is this what I should understand from the order function?",,"['abstract-algebra', 'complex-analysis', 'algebraic-geometry']"
2,"Evaluate the following complex integral $\frac{1}{2\pi i}\int_{|z|=1}\frac{\overline{f(z)}}{z-a}\,dz$",Evaluate the following complex integral,"\frac{1}{2\pi i}\int_{|z|=1}\frac{\overline{f(z)}}{z-a}\,dz","Let , $f$ be analytic for $|z|<2$. Show that $$\frac{1}{2\pi i}\int_{|z|=1}\frac{\overline{f(z)}}{z-a}\,dz=\begin{cases}\overline{f(0)} &\text{ if } |a|<1\\\overline{f(0)}-\overline{f(1/a)}&\text{ if }|a|>1\end{cases}$$ By putting $z=e^{i\theta}$ , $\displaystyle\int_{|z|=1}\frac{\overline{f(z)}}{z-a}\,dz=\int_0^{2\pi}\frac{\overline{f(e^{i\theta})}}{e^{i\theta}-a}ie^{i\theta}\,d\theta=i\int_0^{2\pi}\frac{\overline{f\left(\overline{e^{-i\theta}}\right)}}{1-ae^{-i\theta}}\,d\theta$. Now putting , $e^{-i\theta}=t$ , it becomes $\displaystyle =-\int_{|t|=1}\frac{\overline{f(\bar t)}}{1-at}\,dt$. As $f(t)$ is analytic so $\overline{f(\bar t)}$ is also analytic. Now we can apply the residue theorem and finally I got the desire integral $=-\overline{f(0)}$ when $|a|<1$. My problem is about the sign . I got an extra negative sign. Please verify my proof & detect where I made mistake ...","Let , $f$ be analytic for $|z|<2$. Show that $$\frac{1}{2\pi i}\int_{|z|=1}\frac{\overline{f(z)}}{z-a}\,dz=\begin{cases}\overline{f(0)} &\text{ if } |a|<1\\\overline{f(0)}-\overline{f(1/a)}&\text{ if }|a|>1\end{cases}$$ By putting $z=e^{i\theta}$ , $\displaystyle\int_{|z|=1}\frac{\overline{f(z)}}{z-a}\,dz=\int_0^{2\pi}\frac{\overline{f(e^{i\theta})}}{e^{i\theta}-a}ie^{i\theta}\,d\theta=i\int_0^{2\pi}\frac{\overline{f\left(\overline{e^{-i\theta}}\right)}}{1-ae^{-i\theta}}\,d\theta$. Now putting , $e^{-i\theta}=t$ , it becomes $\displaystyle =-\int_{|t|=1}\frac{\overline{f(\bar t)}}{1-at}\,dt$. As $f(t)$ is analytic so $\overline{f(\bar t)}$ is also analytic. Now we can apply the residue theorem and finally I got the desire integral $=-\overline{f(0)}$ when $|a|<1$. My problem is about the sign . I got an extra negative sign. Please verify my proof & detect where I made mistake ...",,['complex-analysis']
3,Is a holomorphic function on $\mathbb{C}$ that's $L^2$ integrable necessarily bounded?,Is a holomorphic function on  that's  integrable necessarily bounded?,\mathbb{C} L^2,"I'm working on a homework problem and if I can prove this claim then I am finished.  Intuitively the answer should be yes, but I can't think about how I would attempt to rigorously prove this.  I have an entire function $f:\mathbb{C}\rightarrow\mathbb{C}$ and I know that $|f|^2$ is integrable over $\mathbb{C}$.  I want to say this implies that $f$ is bounded and hence the $0$ function by Liouville's theorem. The idea is that if $f$ isn't bounded, then its modulus has to approach infinity as $|z|\rightarrow\infty$ for some particular direction.  But this ""direction"" should be on a set that doesn't have measure $0$ and hence the integral of $|f|^2$ wouldn't be finite, which would contradict my claim.","I'm working on a homework problem and if I can prove this claim then I am finished.  Intuitively the answer should be yes, but I can't think about how I would attempt to rigorously prove this.  I have an entire function $f:\mathbb{C}\rightarrow\mathbb{C}$ and I know that $|f|^2$ is integrable over $\mathbb{C}$.  I want to say this implies that $f$ is bounded and hence the $0$ function by Liouville's theorem. The idea is that if $f$ isn't bounded, then its modulus has to approach infinity as $|z|\rightarrow\infty$ for some particular direction.  But this ""direction"" should be on a set that doesn't have measure $0$ and hence the integral of $|f|^2$ wouldn't be finite, which would contradict my claim.",,['complex-analysis']
4,Proving a modified version of Jordan's lemma?,Proving a modified version of Jordan's lemma?,,I want to prove the version of Jordan's lemma which say's that: Around a contour as shown below: The integral: $$\int_{\Gamma} e^{az}f(z)dz$$ will go to $0$ if $$|f(z)|\le \frac{M}{R^\alpha}$$ for some positive $M$ and $\alpha$. Does anyone know how this can be proved?,I want to prove the version of Jordan's lemma which say's that: Around a contour as shown below: The integral: $$\int_{\Gamma} e^{az}f(z)dz$$ will go to $0$ if $$|f(z)|\le \frac{M}{R^\alpha}$$ for some positive $M$ and $\alpha$. Does anyone know how this can be proved?,,"['complex-analysis', 'contour-integration']"
5,Sketch the set of points satysfing an inequality $|z+1|+|z-1|\leq2$,Sketch the set of points satysfing an inequality,|z+1|+|z-1|\leq2,"The inequality is  $$|z-1|+|z+1|\leq2$$ I used a triangle inequality to show that  Since triangle inequality states: $$|z+w|\leq|z|+|w|$$ Then $$|z-1+z+1|\leq|z-1|+|z+1|\leq2$$ So $$|2z|\leq2$$ From this point I expanded out $$\sqrt{(2x)^2+(2y)^2}\leq2$$ Or $$4x^2+4y^2\leq4$$ So I end up with a disk centred at origin, radius 1. However my ""answer"" at the back of the page says ""one point"" (it doesnt give step by step solution)Thanks for the help","The inequality is  $$|z-1|+|z+1|\leq2$$ I used a triangle inequality to show that  Since triangle inequality states: $$|z+w|\leq|z|+|w|$$ Then $$|z-1+z+1|\leq|z-1|+|z+1|\leq2$$ So $$|2z|\leq2$$ From this point I expanded out $$\sqrt{(2x)^2+(2y)^2}\leq2$$ Or $$4x^2+4y^2\leq4$$ So I end up with a disk centred at origin, radius 1. However my ""answer"" at the back of the page says ""one point"" (it doesnt give step by step solution)Thanks for the help",,"['complex-analysis', 'inequality']"
6,zeros of $p(z)=z^4+2$,zeros of,p(z)=z^4+2,"I want to find all zeros of $p(z)=z^4+2$ and I'm not sure if I've done everything correctly. Can you correct this if something is wrong? $$x^4+2=0 \iff x^4=-2=2\cdot(-1)$$ $$\Rightarrow x_k= \sqrt[4]{2}e^{\frac{i(2k+1)\pi}{4}}$$with $k\in \{0,1,2,3\}$ are the zeros of $p$. Is it correct? Additional question: If I want to determine all zeros of $z^n+a$ with $a\in\mathbb{R}$ and $n\in\mathbb{N}$, are the zeros $$x_k= \sqrt[n]{a}e^{\frac{i(2k+1)\pi}{n}}$$for $k=0,..,.n-1$ in general?","I want to find all zeros of $p(z)=z^4+2$ and I'm not sure if I've done everything correctly. Can you correct this if something is wrong? $$x^4+2=0 \iff x^4=-2=2\cdot(-1)$$ $$\Rightarrow x_k= \sqrt[4]{2}e^{\frac{i(2k+1)\pi}{4}}$$with $k\in \{0,1,2,3\}$ are the zeros of $p$. Is it correct? Additional question: If I want to determine all zeros of $z^n+a$ with $a\in\mathbb{R}$ and $n\in\mathbb{N}$, are the zeros $$x_k= \sqrt[n]{a}e^{\frac{i(2k+1)\pi}{n}}$$for $k=0,..,.n-1$ in general?",,"['complex-analysis', 'polynomials']"
7,Show that $f(z)$ can be extended to all of $\mathbb{C}$ as an entire function.,Show that  can be extended to all of  as an entire function.,f(z) \mathbb{C},"Let $f(z)$ be analytic in the unit disc $D$. Suppose there is a constant $M$ such that $$\left|f^{(n)}(0)\right| \leq M^n$$ for all n sufficiently large. Show that $f(z)$ can be extended to all of $\mathbb{C}$ as an entire function. My idea is to construct a function $g(z)$ whose restriction to $D$ is $f(z)$, and prove that its Taylor series has infinite radius of convergence, which means it is an entire function. But I do not know how to do that. Do you have any idea? Any help would be highly appreciated! Thank you in advance!","Let $f(z)$ be analytic in the unit disc $D$. Suppose there is a constant $M$ such that $$\left|f^{(n)}(0)\right| \leq M^n$$ for all n sufficiently large. Show that $f(z)$ can be extended to all of $\mathbb{C}$ as an entire function. My idea is to construct a function $g(z)$ whose restriction to $D$ is $f(z)$, and prove that its Taylor series has infinite radius of convergence, which means it is an entire function. But I do not know how to do that. Do you have any idea? Any help would be highly appreciated! Thank you in advance!",,['complex-analysis']
8,Computing the integral $\int_{-\infty}^{\infty}\frac{z^4}{1+z^8}dz$,Computing the integral,\int_{-\infty}^{\infty}\frac{z^4}{1+z^8}dz,I need help to compute the following integral: $$\int_{-\infty}^{\infty}\frac{z^4}{1+z^8}dz$$ I need to use Cauchy's residue theorem. I can write that $z^8+1=z^8-i^2=(z^4-i)(z^4+i)$. How do I proceed? Please give a methodological answer so that I can solve other questions too. Thanks,I need help to compute the following integral: $$\int_{-\infty}^{\infty}\frac{z^4}{1+z^8}dz$$ I need to use Cauchy's residue theorem. I can write that $z^8+1=z^8-i^2=(z^4-i)(z^4+i)$. How do I proceed? Please give a methodological answer so that I can solve other questions too. Thanks,,"['integration', 'complex-analysis', 'definite-integrals', 'complex-integration']"
9,Evaluating $\int_0^2 x(8-x^3)^{\frac{1}{3}}\ dx$,Evaluating,\int_0^2 x(8-x^3)^{\frac{1}{3}}\ dx,"What substitution would you use to get from $$\int\limits_0^2 x(8-x^3)^{\frac{1}{3}}\ dx$$ to $$\int\limits_0^1 (1-t)^{a-1}t^{-a}\ dt, \ a\in(0,1)\ ?$$ I know how to evaluate the second integral and I thought that if I substitute $t={x^3\over8}$ I would reduce this to the form above, but what I get is $$\frac{8}{3}\int\limits_0^1 (1-y)^{\frac{1}{3}}y^{-\frac{1}{3}}\ dy$$","What substitution would you use to get from $$\int\limits_0^2 x(8-x^3)^{\frac{1}{3}}\ dx$$ to $$\int\limits_0^1 (1-t)^{a-1}t^{-a}\ dt, \ a\in(0,1)\ ?$$ I know how to evaluate the second integral and I thought that if I substitute $t={x^3\over8}$ I would reduce this to the form above, but what I get is $$\frac{8}{3}\int\limits_0^1 (1-y)^{\frac{1}{3}}y^{-\frac{1}{3}}\ dy$$",,"['integration', 'complex-analysis', 'definite-integrals', 'substitution']"
10,Evaluating $\int_{0}^{\infty}\frac{\sin(ax)}{\sinh(x)}dx$ with a rectangular contour,Evaluating  with a rectangular contour,\int_{0}^{\infty}\frac{\sin(ax)}{\sinh(x)}dx,"I need to try to evaluate $\int_{0}^{\infty}\frac{\sin(ax)}{\sinh(x)}dx$ and it seems like this is supposed to be done using some sort of rectangular contour based on looking at other questions. My main issue is that I am unsure how this kind of contour works in general. For example: How high or low should I have the rectangle contour? Should the contour be centered on the real axis or should it actually be shifted up or down or does it depend? When you make bumps on the contour about the singularities, do you make the bumps as to include the singularities inside of the domain or should they be outside of the domain? I ask the last question based on this question "" tough integral involving $\sin(x^2)$ and $\sinh^2 (x)$ "" here in which robjohn had his contour surround the singularity at $i$ yet did not surround the singularity at $-i$, so I was wondering if this choice matters and why not include or exclude both singularities using the contour. For this, though, I believe I need to use the singularities at $0$ and $i\pi$, but I suppose I could have the rectangle between any two consecutive singularities on the imaginary axis, correct? Either way, any insight on this would be appreciated. Edit: There is no information given on a. I assume it is an arbitrary complex parameter.","I need to try to evaluate $\int_{0}^{\infty}\frac{\sin(ax)}{\sinh(x)}dx$ and it seems like this is supposed to be done using some sort of rectangular contour based on looking at other questions. My main issue is that I am unsure how this kind of contour works in general. For example: How high or low should I have the rectangle contour? Should the contour be centered on the real axis or should it actually be shifted up or down or does it depend? When you make bumps on the contour about the singularities, do you make the bumps as to include the singularities inside of the domain or should they be outside of the domain? I ask the last question based on this question "" tough integral involving $\sin(x^2)$ and $\sinh^2 (x)$ "" here in which robjohn had his contour surround the singularity at $i$ yet did not surround the singularity at $-i$, so I was wondering if this choice matters and why not include or exclude both singularities using the contour. For this, though, I believe I need to use the singularities at $0$ and $i\pi$, but I suppose I could have the rectangle between any two consecutive singularities on the imaginary axis, correct? Either way, any insight on this would be appreciated. Edit: There is no information given on a. I assume it is an arbitrary complex parameter.",,"['integration', 'complex-analysis', 'improper-integrals', 'contour-integration', 'residue-calculus']"
11,Asymptotic expansion of Legendre polynomial,Asymptotic expansion of Legendre polynomial,,"I am trying to determine the asymptotic expansion of the Legendre function as described in a Bender and Orszag text, but have been unable to - some solutions are online, but they approach it in different forms and I'd like to solve it using the below integral definition of the Legendre polynomial. Specifically, defining: $$P_n(x)=\frac{1}{\pi}\int_0^\infty(x+cos(\theta)\sqrt{x^2-1})^n d\theta $$ Show that for large n: $$P_n(x) \sim \frac{1}{\sqrt{2\pi n}}\frac{(x+(x^2-1)^{1/2})^{n+1/2}}{(x^2-1)^{1/4}}$$ Any help is appreciated!","I am trying to determine the asymptotic expansion of the Legendre function as described in a Bender and Orszag text, but have been unable to - some solutions are online, but they approach it in different forms and I'd like to solve it using the below integral definition of the Legendre polynomial. Specifically, defining: $$P_n(x)=\frac{1}{\pi}\int_0^\infty(x+cos(\theta)\sqrt{x^2-1})^n d\theta $$ Show that for large n: $$P_n(x) \sim \frac{1}{\sqrt{2\pi n}}\frac{(x+(x^2-1)^{1/2})^{n+1/2}}{(x^2-1)^{1/4}}$$ Any help is appreciated!",,"['complex-analysis', 'legendre-polynomials']"
12,Residues of poles,Residues of poles,,"Find $Res_{f}\left ( z_{0} \right )$, where, $f\left ( z \right )=\frac{1}{z^{4}+4}$, for $z_{0}=1+i$ The definition for  $$Res_{f}\left ( 1+i \right ) =\lim_{z \to z_{0}} \left\{\left ( z-\left ( 1+i \right ) \right ) \cdot \frac{1}{z^{4}+4} \right\}$$ and the roots for $$z^{4}+4$$ are $\sqrt{+2i}$, $\sqrt{-2i}$, $- \sqrt{+2i}$, $- \sqrt{-2i}$ I'm a bit stuck here. Could someone give me a push?","Find $Res_{f}\left ( z_{0} \right )$, where, $f\left ( z \right )=\frac{1}{z^{4}+4}$, for $z_{0}=1+i$ The definition for  $$Res_{f}\left ( 1+i \right ) =\lim_{z \to z_{0}} \left\{\left ( z-\left ( 1+i \right ) \right ) \cdot \frac{1}{z^{4}+4} \right\}$$ and the roots for $$z^{4}+4$$ are $\sqrt{+2i}$, $\sqrt{-2i}$, $- \sqrt{+2i}$, $- \sqrt{-2i}$ I'm a bit stuck here. Could someone give me a push?",,"['complex-analysis', 'residue-calculus']"
13,2-dimensional delta function (complex plane),2-dimensional delta function (complex plane),,"I have a task to show that $$\partial_{\bar{z}} \frac{1}{z - \zeta} = \pi \delta^{(2)}(z - \zeta) $$ But I thought, that delta-function is determined by $\int f(\zeta) \delta(z-\zeta) d\zeta = f(z)$, so in such point of view function $\frac{1}{z-\zeta}$ should be a delta function. Where am I wrong?  And how to proof this relation, because function $\frac{1}{z-\zeta}$ is holomorphic, so its $\partial_{\bar{z}}$ equals zero.","I have a task to show that $$\partial_{\bar{z}} \frac{1}{z - \zeta} = \pi \delta^{(2)}(z - \zeta) $$ But I thought, that delta-function is determined by $\int f(\zeta) \delta(z-\zeta) d\zeta = f(z)$, so in such point of view function $\frac{1}{z-\zeta}$ should be a delta function. Where am I wrong?  And how to proof this relation, because function $\frac{1}{z-\zeta}$ is holomorphic, so its $\partial_{\bar{z}}$ equals zero.",,"['complex-analysis', 'distribution-theory', 'dirac-delta']"
14,To show there exists a unique function $u \in C^{1}(\mathbb{C^n})$ that satisfies $(\bar{\partial u})=f$,To show there exists a unique function  that satisfies,u \in C^{1}(\mathbb{C^n}) (\bar{\partial u})=f,"Assume $n \gt 1$. Let $f$ be a $(0,1)$ form in $\mathbb{C^n}$, with $C^1$-coefficients and compact support $K$, such that $\bar{\partial} f=0$. Let $\Omega_{0}$ be the unbounded component of $\mathbb{C^n}-K$. I need to show there exists a unique function $u \in C^{1}(\mathbb{C^n})$ that satisfies $(\bar{\partial u})=f$ as well as $u(z)=0$ for every $z \in \Omega_{0}$ Let $f=\sum f_j(z) d\bar{z_j} $. Let's define for $z \in \mathbb{C^n}$ $$u(z)=\frac{1}{2\pi i}\int_{\mathbb{C}}f_{1}(\lambda,z_2,..,z_n) \frac{d\lambda \wedge d\bar{\lambda}}{\lambda-z_1}$$ $$=\frac{1}{2\pi i}\int_{\mathbb{C}}f_{1}(\lambda+z_1,z_2,..,z_n) \frac{d\lambda \wedge d\bar{\lambda}}{\lambda}$$ I am trying to evoke the following proposition here: Let $\Omega \subset \mathbb{C}$ be a bounded open set. Suppose $f \in C^{1 }(\Omega)$, $f$ is bounded and $$u(z)=\frac{1}{2\pi i} \int_{\Omega} \frac{f(\lambda)}{\lambda-z} d\lambda \wedge d\bar{\lambda}, (z \in \Omega).$$ Then $u \in C^{1}(\Omega)$ and $\bar{D}u=f$. From the above mentioned Proposition, $\bar{D_1}u=f_1$. I also think that $u \in C^1(\mathbb{C})$ follows from here but I am not sure about it. Now since we have $(\bar{\partial f})=0$, for $2 \le j \le n$, $\bar{D_j}f_1=\bar{D_1}f_j$, so that $$(\bar{D_j})u(z)=\frac{1}{2\pi i}\int_{\mathbb{C}}(\bar{D_j}f_{1})(\lambda,z_2,..,z_n) \frac{d\lambda \wedge d\bar{\lambda}}{\lambda-z_1}$$(why can I take the differential inside: because the function is bounded ??) $$=(\bar{D_j})u(z)=\frac{1}{2\pi i}\int_{\mathbb{C}}(\bar{D_1}f_{j})(\lambda,z_2,..,z_n) \frac{d\lambda \wedge d\bar{\lambda}}{\lambda-z_1}$$ It should follow from here that the last statement is equal to $f_j(z)$. I am thinking of this proposition (but not able to find out why) $$\text{Let $\Omega$ be a bounded region in $\mathbb{C}$, with smooth oriented boundary $\partial\Omega$. If $u \in C^1(\bar{\Omega})$, then we have $u(a)=\dfrac{1}{2\pi i}\int_{\partial \Omega}\dfrac{u(\lambda)d\lambda}{\lambda-a}-\dfrac{1}{2\pi i}\int_{\Omega}\dfrac{\bar{D}u(\lambda)d\bar{\lambda}\wedge d\lambda}{\lambda-a} $}$$ Suppose $\bar{D_j}u=f_j$ for $1 \le j \le n$, then we are done with the first part. This also shows that $u$ is holomorphic in $\Omega_0$(as the derivatives vanish there). I have no idea how to show that $u(z)=0$ in $\Omega_0$( take $|z_1|$ large in the first equation??) Also why this theorem fails when $n=1$?? Thanks for the help","Assume $n \gt 1$. Let $f$ be a $(0,1)$ form in $\mathbb{C^n}$, with $C^1$-coefficients and compact support $K$, such that $\bar{\partial} f=0$. Let $\Omega_{0}$ be the unbounded component of $\mathbb{C^n}-K$. I need to show there exists a unique function $u \in C^{1}(\mathbb{C^n})$ that satisfies $(\bar{\partial u})=f$ as well as $u(z)=0$ for every $z \in \Omega_{0}$ Let $f=\sum f_j(z) d\bar{z_j} $. Let's define for $z \in \mathbb{C^n}$ $$u(z)=\frac{1}{2\pi i}\int_{\mathbb{C}}f_{1}(\lambda,z_2,..,z_n) \frac{d\lambda \wedge d\bar{\lambda}}{\lambda-z_1}$$ $$=\frac{1}{2\pi i}\int_{\mathbb{C}}f_{1}(\lambda+z_1,z_2,..,z_n) \frac{d\lambda \wedge d\bar{\lambda}}{\lambda}$$ I am trying to evoke the following proposition here: Let $\Omega \subset \mathbb{C}$ be a bounded open set. Suppose $f \in C^{1 }(\Omega)$, $f$ is bounded and $$u(z)=\frac{1}{2\pi i} \int_{\Omega} \frac{f(\lambda)}{\lambda-z} d\lambda \wedge d\bar{\lambda}, (z \in \Omega).$$ Then $u \in C^{1}(\Omega)$ and $\bar{D}u=f$. From the above mentioned Proposition, $\bar{D_1}u=f_1$. I also think that $u \in C^1(\mathbb{C})$ follows from here but I am not sure about it. Now since we have $(\bar{\partial f})=0$, for $2 \le j \le n$, $\bar{D_j}f_1=\bar{D_1}f_j$, so that $$(\bar{D_j})u(z)=\frac{1}{2\pi i}\int_{\mathbb{C}}(\bar{D_j}f_{1})(\lambda,z_2,..,z_n) \frac{d\lambda \wedge d\bar{\lambda}}{\lambda-z_1}$$(why can I take the differential inside: because the function is bounded ??) $$=(\bar{D_j})u(z)=\frac{1}{2\pi i}\int_{\mathbb{C}}(\bar{D_1}f_{j})(\lambda,z_2,..,z_n) \frac{d\lambda \wedge d\bar{\lambda}}{\lambda-z_1}$$ It should follow from here that the last statement is equal to $f_j(z)$. I am thinking of this proposition (but not able to find out why) $$\text{Let $\Omega$ be a bounded region in $\mathbb{C}$, with smooth oriented boundary $\partial\Omega$. If $u \in C^1(\bar{\Omega})$, then we have $u(a)=\dfrac{1}{2\pi i}\int_{\partial \Omega}\dfrac{u(\lambda)d\lambda}{\lambda-a}-\dfrac{1}{2\pi i}\int_{\Omega}\dfrac{\bar{D}u(\lambda)d\bar{\lambda}\wedge d\lambda}{\lambda-a} $}$$ Suppose $\bar{D_j}u=f_j$ for $1 \le j \le n$, then we are done with the first part. This also shows that $u$ is holomorphic in $\Omega_0$(as the derivatives vanish there). I have no idea how to show that $u(z)=0$ in $\Omega_0$( take $|z_1|$ large in the first equation??) Also why this theorem fails when $n=1$?? Thanks for the help",,"['complex-analysis', 'several-complex-variables']"
15,Limit of complex sequence.,Limit of complex sequence.,,"I have the following limit: If $z_{n+1}=\dfrac{1}{2}\left(z_n+\dfrac{1}{z_n}\right)$ for $n \in \mathbb{N}\cup \{0\}$ and $-\dfrac{\pi}{2}<arg(z_0)<\dfrac{\pi}{2},$  then $$\lim_{n \rightarrow \infty} z_n=1.$$ I have tried to look for a recurent formula, but every time it gets worst and worst. I have also tried to put $z_0=|z_0|e^{i \theta}$ for $-\dfrac{\pi}{2}<\theta<\dfrac{\pi}{2},$ but I'm really stuck. Any hint would be appreciated.","I have the following limit: If $z_{n+1}=\dfrac{1}{2}\left(z_n+\dfrac{1}{z_n}\right)$ for $n \in \mathbb{N}\cup \{0\}$ and $-\dfrac{\pi}{2}<arg(z_0)<\dfrac{\pi}{2},$  then $$\lim_{n \rightarrow \infty} z_n=1.$$ I have tried to look for a recurent formula, but every time it gets worst and worst. I have also tried to put $z_0=|z_0|e^{i \theta}$ for $-\dfrac{\pi}{2}<\theta<\dfrac{\pi}{2},$ but I'm really stuck. Any hint would be appreciated.",,"['complex-analysis', 'limits', 'recurrence-relations']"
16,Geometric Interpretation of $|z_1-z_2|\ge ||z_1|-|z_2||$,Geometric Interpretation of,|z_1-z_2|\ge ||z_1|-|z_2||,"I have to give a geometric argument that, given two complex numbers $z_1, z_2$, the following inequality holds $$|z_1-z_2|\ge ||z_1|-|z_2||$$ I know every complex number has a nonnegative modulus, and this becomes a problem if $|z_1|\lt |z_2|$, and it contradicts the fact that $|z|\ge 0$ for all $z \in \mathbb{C}$.  Intuitively I understand what is happening, but I'm having trouble formulating a geometric argument.  I would imagine that, looking at a Argand diagram, the Triangle Inequality would be $$|z_1|+|-z_2|\ge |z_1-z_2|$$ which makes sense.  But I'm not sure where to go from here.","I have to give a geometric argument that, given two complex numbers $z_1, z_2$, the following inequality holds $$|z_1-z_2|\ge ||z_1|-|z_2||$$ I know every complex number has a nonnegative modulus, and this becomes a problem if $|z_1|\lt |z_2|$, and it contradicts the fact that $|z|\ge 0$ for all $z \in \mathbb{C}$.  Intuitively I understand what is happening, but I'm having trouble formulating a geometric argument.  I would imagine that, looking at a Argand diagram, the Triangle Inequality would be $$|z_1|+|-z_2|\ge |z_1-z_2|$$ which makes sense.  But I'm not sure where to go from here.",,"['complex-analysis', 'complex-numbers']"
17,Holomorphic function with reals to reals,Holomorphic function with reals to reals,,"Suppose that $f$ is an entire function and that there is a bounded sequence of real numbers $a_1, a_2, ... $ such that $f(a_n)$ is real for all $n$. Show that $f(x)$ is real for all real $x$. Thoughts so far: Since $a_n$ is a bounded sequence of real numbers, we now that the set ${a_n}$ has an accumulation point. Now, since we're given that the function is entire, my first thought was to apply Liouville's Theorem somehow, but I can't get it to work out. A hint would be much appreciated. Context: I'm studying for a qual, so just a hint at this point would be most helpful.","Suppose that $f$ is an entire function and that there is a bounded sequence of real numbers $a_1, a_2, ... $ such that $f(a_n)$ is real for all $n$. Show that $f(x)$ is real for all real $x$. Thoughts so far: Since $a_n$ is a bounded sequence of real numbers, we now that the set ${a_n}$ has an accumulation point. Now, since we're given that the function is entire, my first thought was to apply Liouville's Theorem somehow, but I can't get it to work out. A hint would be much appreciated. Context: I'm studying for a qual, so just a hint at this point would be most helpful.",,['complex-analysis']
18,Evaluate the integral $\int_0^\infty x^{t-1}e^{-\beta x}dx$,Evaluate the integral,\int_0^\infty x^{t-1}e^{-\beta x}dx,"I want to evaluate the following integral $$\int_0^\infty x^{t-1}e^{-\beta x}dx$$ where $\beta$ is a complex number. Now, if $\beta$ was real, we could just set $y = \beta x$ and we will reduce to the Gamma function. Since $\beta$ is complex, though, when I set $y = \beta x$, I am integrating over the line with $\arg \beta$ on the complex plane, so I can't reduce directly to the Gamma function, can I? I have found after some calculations that $$\int_0^\infty x^{t-1}e^{-\beta x}dx = \Gamma(t)\beta^{-t}$$ which is exactly what one would find if it didn't bother with the previous observation. So my questions are:  Is my observation on the complex line correct? and 2) What is the best way to prove the result? My work Write $\beta = a + ib$. Consider the integral as a function of $t,a,b$ to get $$I(t,a,b) = \int_0^\infty x^{t-1}e^{-a x}e^{-ibx}dx$$. Notice that $$\frac{\partial I}{\partial a}(t,a,b) = -I(t+1,a,b)$$ and $$\frac{\partial I}{\partial b}(t,a,b) = -iI(t+1,a,b)$$ Now since $\displaystyle I(t+1) = \frac t{a+ib}I(t)$, the previous two equations become $$\frac{\partial I}{\partial a} = -\frac t{a+ib}I$$ and $$\frac{\partial I}{\partial b} = -\frac{it}{a+ib}I$$ which put together yield $I(t,a,b) = C(t) (a+ib)^{-t}$. Also, since $\displaystyle I(t,1,0) = C(t) = \int_0^\infty x^{t-1}e^{-x}dx= \Gamma(t)$, we get $$I(t,a,b) = \Gamma(t) (a+ib)^{-t} = \Gamma(t)\beta^{-t}$$ which seems like too much work!","I want to evaluate the following integral $$\int_0^\infty x^{t-1}e^{-\beta x}dx$$ where $\beta$ is a complex number. Now, if $\beta$ was real, we could just set $y = \beta x$ and we will reduce to the Gamma function. Since $\beta$ is complex, though, when I set $y = \beta x$, I am integrating over the line with $\arg \beta$ on the complex plane, so I can't reduce directly to the Gamma function, can I? I have found after some calculations that $$\int_0^\infty x^{t-1}e^{-\beta x}dx = \Gamma(t)\beta^{-t}$$ which is exactly what one would find if it didn't bother with the previous observation. So my questions are:  Is my observation on the complex line correct? and 2) What is the best way to prove the result? My work Write $\beta = a + ib$. Consider the integral as a function of $t,a,b$ to get $$I(t,a,b) = \int_0^\infty x^{t-1}e^{-a x}e^{-ibx}dx$$. Notice that $$\frac{\partial I}{\partial a}(t,a,b) = -I(t+1,a,b)$$ and $$\frac{\partial I}{\partial b}(t,a,b) = -iI(t+1,a,b)$$ Now since $\displaystyle I(t+1) = \frac t{a+ib}I(t)$, the previous two equations become $$\frac{\partial I}{\partial a} = -\frac t{a+ib}I$$ and $$\frac{\partial I}{\partial b} = -\frac{it}{a+ib}I$$ which put together yield $I(t,a,b) = C(t) (a+ib)^{-t}$. Also, since $\displaystyle I(t,1,0) = C(t) = \int_0^\infty x^{t-1}e^{-x}dx= \Gamma(t)$, we get $$I(t,a,b) = \Gamma(t) (a+ib)^{-t} = \Gamma(t)\beta^{-t}$$ which seems like too much work!",,"['calculus', 'complex-analysis', 'improper-integrals', 'gamma-function', 'analytic-continuation']"
19,Schwarz Reflection Principle on a unit disk,Schwarz Reflection Principle on a unit disk,,"Suppose $f$ is a analytic function defined on $\bar{D}(0;1)$ and has real value on the boundary. I'm trying to show $f$ can be extended to entire plane by $$g(z) = \begin{cases}f(z) &, \lvert z\rvert \leqslant 1\\ \frac{1}{\overline{f(\overline{z}^{-1})}},  &, \lvert z\rvert > 1\end{cases} $$ I tried to use $\gamma(z)=e^{iz}$, which sends real axis to unit circle, for Schwarz Reflection Principle. But I did not get the result. May I get a help?","Suppose $f$ is a analytic function defined on $\bar{D}(0;1)$ and has real value on the boundary. I'm trying to show $f$ can be extended to entire plane by $$g(z) = \begin{cases}f(z) &, \lvert z\rvert \leqslant 1\\ \frac{1}{\overline{f(\overline{z}^{-1})}},  &, \lvert z\rvert > 1\end{cases} $$ I tried to use $\gamma(z)=e^{iz}$, which sends real axis to unit circle, for Schwarz Reflection Principle. But I did not get the result. May I get a help?",,['complex-analysis']
20,Prove that $f$ is a polynomial,Prove that  is a polynomial,f,"If $f(z)$ is an entire function and $|f(z)|\ge1$ for all $z$ with $|z|\ge \pi$ then show that $f$ is a polynomial. I tried to apply Lioville's theorem on $f$. For $|z|\le \pi$ , $|f(z)|\le k$ for positive constant. But it does not help. I've also tried with Taylor's series expansion as , $$f(z)=\sum_{n=0}^{\infty}a_nz^n$$where, $$a_n=\frac{1}{2\pi i}\int_{|z|=R}\frac{f(z)}{z^n}\, \mathrm{d}z$$ Then I wanted to find that $a_n=0$ for $n>p$ for some $p$ , but I failed to do so.","If $f(z)$ is an entire function and $|f(z)|\ge1$ for all $z$ with $|z|\ge \pi$ then show that $f$ is a polynomial. I tried to apply Lioville's theorem on $f$. For $|z|\le \pi$ , $|f(z)|\le k$ for positive constant. But it does not help. I've also tried with Taylor's series expansion as , $$f(z)=\sum_{n=0}^{\infty}a_nz^n$$where, $$a_n=\frac{1}{2\pi i}\int_{|z|=R}\frac{f(z)}{z^n}\, \mathrm{d}z$$ Then I wanted to find that $a_n=0$ for $n>p$ for some $p$ , but I failed to do so.",,['complex-analysis']
21,Evaluating a complex integral using residue theorem,Evaluating a complex integral using residue theorem,,Evaluate the integral $$\int_{|z+1|=2} \frac{z^2}{4-z^2}dz$$ Solution : So $|z+1|=2$ is the circle of radius 2 centered at -1. Now inside this circle $\frac{z^2}{4-z^2}$ is analytic except for a simple pole at $z=-2$. We can write $f(z)=\frac{\phi (z)}{z+2}$ and $\phi (z)=\frac{z^2}{z-2}$. Therefore residue at -2 is -1. So the integral is $-2 \pi i$. But the answer on the book is $2 \pi i$ is there an error in my calculation? Help please!,Evaluate the integral $$\int_{|z+1|=2} \frac{z^2}{4-z^2}dz$$ Solution : So $|z+1|=2$ is the circle of radius 2 centered at -1. Now inside this circle $\frac{z^2}{4-z^2}$ is analytic except for a simple pole at $z=-2$. We can write $f(z)=\frac{\phi (z)}{z+2}$ and $\phi (z)=\frac{z^2}{z-2}$. Therefore residue at -2 is -1. So the integral is $-2 \pi i$. But the answer on the book is $2 \pi i$ is there an error in my calculation? Help please!,,"['complex-analysis', 'complex-numbers']"
22,"How do I prove that for any two points in $\mathbb{C}$, there exists a $C^1$-curve adjoining them?","How do I prove that for any two points in , there exists a -curve adjoining them?",\mathbb{C} C^1,"Let $G$ be an open-connected subset of $\mathbb{C}$. Let $a,b$ be two distinct points in $G$. How do I prove that there exists a $C^1$-curve $\alpha:[0,1]\rightarrow G$ such that $\alpha(0)=a$ and $\alpha(1)=b$? Here's how I tried: I have proven that there exists a polygonal path joining $a,b$ just like below. Then, this curve is $C^1$-curve except for the ""edges"" of the curve. Now let's focus on an edge. Since the image is lying in an open set $G$, we can have an open neighborhood $N$ of an edge. And if we transform the curve in $N$ to a dotted line, then it would be a $C^1$ cirve around an edge. However, I have a trouble with formalizing this idea. How do I formally show that a curve-image around an edge can be transformed into a dotted line?","Let $G$ be an open-connected subset of $\mathbb{C}$. Let $a,b$ be two distinct points in $G$. How do I prove that there exists a $C^1$-curve $\alpha:[0,1]\rightarrow G$ such that $\alpha(0)=a$ and $\alpha(1)=b$? Here's how I tried: I have proven that there exists a polygonal path joining $a,b$ just like below. Then, this curve is $C^1$-curve except for the ""edges"" of the curve. Now let's focus on an edge. Since the image is lying in an open set $G$, we can have an open neighborhood $N$ of an edge. And if we transform the curve in $N$ to a dotted line, then it would be a $C^1$ cirve around an edge. However, I have a trouble with formalizing this idea. How do I formally show that a curve-image around an edge can be transformed into a dotted line?",,['complex-analysis']
23,Help with proof that that affine plane curves in $\mathbb{C}^2$ are not compact,Help with proof that that affine plane curves in  are not compact,\mathbb{C}^2,"This is a problem from Kirwan's Complex Algebraic Curves that I'm stuck on. She gives a hint suggesting that for $C = \{(x,y)\in\mathbb{C}^2: P(x,y) = 0\}$, show that at all but finitely many points $a\in\mathbb{C}$ there is a $b$ such that that $P(a,b) = 0$. I know appealing to the Heine-Borel theorem finishes the argument if I can show the hint. It's also pretty obvious that if $g(y) = P(a,y)$ is non-constant, then we can factorize $g$ by the Fundamental Theorem of Algebra and let $b$ be one of the roots to conclude. I don't understand why we can do this at all but finitely many $a$ though. It seems like having $g(y) = k_a$ where $k_a\in\mathbb{C}$ for infinitely many $a\in \mathbb{C}$ should give some kind of contradiction. It would be easy if it were the same constant $k_a$ every time, since we could factorize $g(y) - k_a$ as a polynomial of $a$ to show that the number of $a$'s where this occurs is bounded by the polynomial degree. But $k_a$ should vary with $a$, right? Do I need to appeal to some kind of complex-analytic argument? I might just be missing something obvious. Any help explaining this would be appreciated!","This is a problem from Kirwan's Complex Algebraic Curves that I'm stuck on. She gives a hint suggesting that for $C = \{(x,y)\in\mathbb{C}^2: P(x,y) = 0\}$, show that at all but finitely many points $a\in\mathbb{C}$ there is a $b$ such that that $P(a,b) = 0$. I know appealing to the Heine-Borel theorem finishes the argument if I can show the hint. It's also pretty obvious that if $g(y) = P(a,y)$ is non-constant, then we can factorize $g$ by the Fundamental Theorem of Algebra and let $b$ be one of the roots to conclude. I don't understand why we can do this at all but finitely many $a$ though. It seems like having $g(y) = k_a$ where $k_a\in\mathbb{C}$ for infinitely many $a\in \mathbb{C}$ should give some kind of contradiction. It would be easy if it were the same constant $k_a$ every time, since we could factorize $g(y) - k_a$ as a polynomial of $a$ to show that the number of $a$'s where this occurs is bounded by the polynomial degree. But $k_a$ should vary with $a$, right? Do I need to appeal to some kind of complex-analytic argument? I might just be missing something obvious. Any help explaining this would be appreciated!",,"['abstract-algebra', 'complex-analysis', 'algebraic-curves']"
24,$\int_{\gamma}f(z)\log\left(\frac{z+1}{z-1}\right)dz = 2\pi i\int_{x=-1}^{x=1}f(x)dx$ on an ellipse,on an ellipse,\int_{\gamma}f(z)\log\left(\frac{z+1}{z-1}\right)dz = 2\pi i\int_{x=-1}^{x=1}f(x)dx,"I am a self-studier and this is a problem from a course I've been doing. I would appreciate help showing: $$\int_{\gamma}f(z)\log\left(\frac{z+1}{z-1}\right)dz = 2\pi i\int_{x=-1}^{x=1}f(x)dx$$ where $\gamma$ is an ellipse with foci at $-1$ and $1$ and $f$ is analytic inside and on it. Initially it asks to show $\left(\frac{z+1}{z-1}\right)\in [-\infty,0]$ iff $z\in[-1,1]$. This seems OK in that substituting $-1$ and $1$, and then testing $+1/2$ and $-1/2$ show it is $\leq 0$. Any help would be appreciated. Thanks.","I am a self-studier and this is a problem from a course I've been doing. I would appreciate help showing: $$\int_{\gamma}f(z)\log\left(\frac{z+1}{z-1}\right)dz = 2\pi i\int_{x=-1}^{x=1}f(x)dx$$ where $\gamma$ is an ellipse with foci at $-1$ and $1$ and $f$ is analytic inside and on it. Initially it asks to show $\left(\frac{z+1}{z-1}\right)\in [-\infty,0]$ iff $z\in[-1,1]$. This seems OK in that substituting $-1$ and $1$, and then testing $+1/2$ and $-1/2$ show it is $\leq 0$. Any help would be appreciated. Thanks.",,['complex-analysis']
25,Evaluating a definite integral using Bessel functions,Evaluating a definite integral using Bessel functions,,"I've been examining an integral I remember encountering in complex analysis: $$ I = \int_0^\pi e^{\cos\theta} \cos\left(n\theta - \sin\theta\right) d\theta $$ where $n$ is a nonnegative integer. It's not too hard to show that $I = \frac{\pi}{n!}$ by changing $\cos\left(n\theta - \sin\theta\right)$ into $\operatorname{Re}\left[e^{i(n\theta - \sin\theta)}\right]$ and making the substitution $z = e^{i\theta}$ to turn the integral into a contour integral on the complex unit circle. However, I came across the following representation of the Bessel functions of the first kind on Wikipedia: $$ J_n(x) = \frac{1}{\pi} \int_0^\pi \cos\left(n\theta - x\sin\theta\right) d\theta $$ Given the similarity between this formula when $x = 1$ and the initial integral, I'm sure there's some way to evaluate the integral using properties of the Bessel functions. But so far I'm stuck as to figuring it out. I tried expanding $e^{\cos\theta}$ as a series but that got ugly pretty quickly. Any suggestions?","I've been examining an integral I remember encountering in complex analysis: $$ I = \int_0^\pi e^{\cos\theta} \cos\left(n\theta - \sin\theta\right) d\theta $$ where $n$ is a nonnegative integer. It's not too hard to show that $I = \frac{\pi}{n!}$ by changing $\cos\left(n\theta - \sin\theta\right)$ into $\operatorname{Re}\left[e^{i(n\theta - \sin\theta)}\right]$ and making the substitution $z = e^{i\theta}$ to turn the integral into a contour integral on the complex unit circle. However, I came across the following representation of the Bessel functions of the first kind on Wikipedia: $$ J_n(x) = \frac{1}{\pi} \int_0^\pi \cos\left(n\theta - x\sin\theta\right) d\theta $$ Given the similarity between this formula when $x = 1$ and the initial integral, I'm sure there's some way to evaluate the integral using properties of the Bessel functions. But so far I'm stuck as to figuring it out. I tried expanding $e^{\cos\theta}$ as a series but that got ugly pretty quickly. Any suggestions?",,"['complex-analysis', 'definite-integrals', 'bessel-functions']"
26,Does a weaker form of the mean value property already imply harmonicity for continuous functions?,Does a weaker form of the mean value property already imply harmonicity for continuous functions?,,"If $u:\mathbb{C}\to \mathbb{R}$ is continuous and satisfies $u(z)=\frac{1}{2\pi}\int_0 ^{2\pi}u(z+\frac{e^{i\theta}}{n})d\theta$ for all $n\in \mathbb{N}$ and $z\in \mathbb{C}$, is $u$ harmonic? What I know: If for each $P\in \mathbb{C}$ there exists $r_P$ such that for $0<r<r_P$, $u(P)=\frac{1}{2\pi}\int_0 ^{2\pi } u(P+re^{i\theta})d\theta$ then $u$ is harmonic, but in the proof I need the fact that the equation holds for all $0<r<r_P$. I tried showing that $u$ is a limit of holomorphic functions satisfying the integral equation for $0<r<r_P$, and I considered looking for a counterexample but I don't know where to start.","If $u:\mathbb{C}\to \mathbb{R}$ is continuous and satisfies $u(z)=\frac{1}{2\pi}\int_0 ^{2\pi}u(z+\frac{e^{i\theta}}{n})d\theta$ for all $n\in \mathbb{N}$ and $z\in \mathbb{C}$, is $u$ harmonic? What I know: If for each $P\in \mathbb{C}$ there exists $r_P$ such that for $0<r<r_P$, $u(P)=\frac{1}{2\pi}\int_0 ^{2\pi } u(P+re^{i\theta})d\theta$ then $u$ is harmonic, but in the proof I need the fact that the equation holds for all $0<r<r_P$. I tried showing that $u$ is a limit of holomorphic functions satisfying the integral equation for $0<r<r_P$, and I considered looking for a counterexample but I don't know where to start.",,"['complex-analysis', 'harmonic-functions']"
27,Zeroes of sin(x),Zeroes of sin(x),,"Consider the function f = $\sin(x)$ defined as $$ \sin(x) = \frac{e^{ix}- e^{-ix}}{2i} $$ How to prove that the only zeroes of this function lie on the line $i = 0$ in the complex plane and furthermore that those zeroes are of the form $\pi k$ for $k \in \Bbb{Z}$. To begin the first step I note that we really just interested in the zeroes of $$  e^{ix}- e^{-ix} $$ Furthemore consider a zero x such that $i \ne 0 $ we can declare $x = a + bi$ and therefore $$ e^{ai - b} - e^{b - ai} = 0 $$ From here it follows that  $$ ai - b = b - ai$$ We note that that the only circumstance this can happen is if $b = ai$ and since b,a are real number it then MUST be the case that $b = 0$ resulting in a contradiction. For the second phase I note that $$ e^{ix}  = e^{-ix} $$ Obviously we desire $e^{ix} = \pm 1 $. Given by definition that $e^{i\pi} = -1$ and that integer powers of $-1$ are also in the set $1,-1$ it then follows that each integer times pi is a zero. But how do I know that integer multiples of $pi$ are the ONLY values for which $e^{ix} = \pm 1$ ?","Consider the function f = $\sin(x)$ defined as $$ \sin(x) = \frac{e^{ix}- e^{-ix}}{2i} $$ How to prove that the only zeroes of this function lie on the line $i = 0$ in the complex plane and furthermore that those zeroes are of the form $\pi k$ for $k \in \Bbb{Z}$. To begin the first step I note that we really just interested in the zeroes of $$  e^{ix}- e^{-ix} $$ Furthemore consider a zero x such that $i \ne 0 $ we can declare $x = a + bi$ and therefore $$ e^{ai - b} - e^{b - ai} = 0 $$ From here it follows that  $$ ai - b = b - ai$$ We note that that the only circumstance this can happen is if $b = ai$ and since b,a are real number it then MUST be the case that $b = 0$ resulting in a contradiction. For the second phase I note that $$ e^{ix}  = e^{-ix} $$ Obviously we desire $e^{ix} = \pm 1 $. Given by definition that $e^{i\pi} = -1$ and that integer powers of $-1$ are also in the set $1,-1$ it then follows that each integer times pi is a zero. But how do I know that integer multiples of $pi$ are the ONLY values for which $e^{ix} = \pm 1$ ?",,"['complex-analysis', 'trigonometry', 'complex-numbers', 'exponential-function', 'roots']"
28,Modular forms: What is $\mathbb{H} / SL_2(\mathbb{Z})$?,Modular forms: What is ?,\mathbb{H} / SL_2(\mathbb{Z}),"I am beginning to understand the very basics of modular forms, in that I understand the concept of a weakly modular function, I have seen the examples of $G_k(z)$ and $E_k(z)$ as weakly modular functions, and modular forms resp. I have also seen the importance of $D:=\{z\in \mathbb{H} : -\frac 12 \leq \Re(z) \leq \frac 12 , |z|\geq 1 \}$, where $\mathbb{H}$ is the upper half plane, and the proof that $\gamma \in\Gamma$ sends $z\in\mathbb{H}$ to $\gamma z \in D$, and also that the points on the boundary of $D$ are the unique points where $\gamma z=z$, so that there are three points at which the stablilizer subgroup of $SL_2(\mathbb{Z})$ is not the identity matrix. My question is regarding the theorem that seems to follow on from these observations. We are given a function, $f$, that is meromorphic at $p$, and we define $v_p(f)$ to be  $k$, where $f(z)=(z-p)^k+\sum_{n=k+1}^\infty a_n(z-p)^n$. We also define $e_p$ to be $\frac{\#Stab(p)\subset SL_2(\mathbb{Z})}{2}$, which can take values of $1,2$ or $3$. Finally, if $f$ is weakly modular of weight $k$, define $v_{\infty}(f):=k$ s.t. $f=a_kq^k+\sum_{n=k+1}^\infty a_nq^n, a_k\neq 0$ The theorem states: $$v_{\infty}(f)+\sum_{p\:\in \:\mathbb{H}\:/\:SL_2(\mathbb{Z})}  \frac{v_p(f)}{e_p}=\frac{k}{12}$$ My main problem is that I don't understand the definition of $\mathbb{H}/SL_2(\mathbb{Z})$. Is it the set given by the action of $SL_2(\mathbb{Z})$ on $\mathbb{H}$? Is it merely all the points at which $f$ is meromorphic? I ask because it is used repeatedly later on and although I have a sense of what it is I don't quite get it.","I am beginning to understand the very basics of modular forms, in that I understand the concept of a weakly modular function, I have seen the examples of $G_k(z)$ and $E_k(z)$ as weakly modular functions, and modular forms resp. I have also seen the importance of $D:=\{z\in \mathbb{H} : -\frac 12 \leq \Re(z) \leq \frac 12 , |z|\geq 1 \}$, where $\mathbb{H}$ is the upper half plane, and the proof that $\gamma \in\Gamma$ sends $z\in\mathbb{H}$ to $\gamma z \in D$, and also that the points on the boundary of $D$ are the unique points where $\gamma z=z$, so that there are three points at which the stablilizer subgroup of $SL_2(\mathbb{Z})$ is not the identity matrix. My question is regarding the theorem that seems to follow on from these observations. We are given a function, $f$, that is meromorphic at $p$, and we define $v_p(f)$ to be  $k$, where $f(z)=(z-p)^k+\sum_{n=k+1}^\infty a_n(z-p)^n$. We also define $e_p$ to be $\frac{\#Stab(p)\subset SL_2(\mathbb{Z})}{2}$, which can take values of $1,2$ or $3$. Finally, if $f$ is weakly modular of weight $k$, define $v_{\infty}(f):=k$ s.t. $f=a_kq^k+\sum_{n=k+1}^\infty a_nq^n, a_k\neq 0$ The theorem states: $$v_{\infty}(f)+\sum_{p\:\in \:\mathbb{H}\:/\:SL_2(\mathbb{Z})}  \frac{v_p(f)}{e_p}=\frac{k}{12}$$ My main problem is that I don't understand the definition of $\mathbb{H}/SL_2(\mathbb{Z})$. Is it the set given by the action of $SL_2(\mathbb{Z})$ on $\mathbb{H}$? Is it merely all the points at which $f$ is meromorphic? I ask because it is used repeatedly later on and although I have a sense of what it is I don't quite get it.",,"['complex-analysis', 'number-theory', 'modular-forms']"
29,Prove that the map $f(z)=\frac{1}{z}$ sends any line onto either a line or a circle.,Prove that the map  sends any line onto either a line or a circle.,f(z)=\frac{1}{z},"Show the cases in which the image is a line and the case in which the image is a circle. I understand that representing the equation of line, ($ax+by+c=0$  $a,b,c\in\Bbb R$  $a,b\neq0$ at the same time), as $pz+\overline {pz} +2c=0$ where $p$  is a suitable nonzero complex number, should help me achieve my end goal in this proof. However, I'm not sure how to use this fact to do so as well as how to justify why I should think of the line in this way.","Show the cases in which the image is a line and the case in which the image is a circle. I understand that representing the equation of line, ($ax+by+c=0$  $a,b,c\in\Bbb R$  $a,b\neq0$ at the same time), as $pz+\overline {pz} +2c=0$ where $p$  is a suitable nonzero complex number, should help me achieve my end goal in this proof. However, I'm not sure how to use this fact to do so as well as how to justify why I should think of the line in this way.",,"['complex-analysis', 'transformation']"
30,Let $∑_{n=0}^∞c_n z^n $ be a representation for the function $\frac{1}{1-z-z^2 }$. Find the coefficient $c_n$,Let  be a representation for the function . Find the coefficient,∑_{n=0}^∞c_n z^n  \frac{1}{1-z-z^2 } c_n,"Let $∑_{n=0}^∞c_n z^n $ be a power series representation for the function $\frac{1}{1-z-z^2 }$. Find the coefficient $c_n$ and radius of convergence of the series. Clearly this is a power series with center $z_0=0$, and $f(z)=\frac{1}{1-z-z^2 }$ is analytic, because it's represented by a power series. I also know that $$c_n =\frac{1}{n!} f^{(n)}(0)$$ but this doesn't get me anywhere, I also try the special case of Taylor series, but nothing look like this. I wonder if any one would give  me a hint please.","Let $∑_{n=0}^∞c_n z^n $ be a power series representation for the function $\frac{1}{1-z-z^2 }$. Find the coefficient $c_n$ and radius of convergence of the series. Clearly this is a power series with center $z_0=0$, and $f(z)=\frac{1}{1-z-z^2 }$ is analytic, because it's represented by a power series. I also know that $$c_n =\frac{1}{n!} f^{(n)}(0)$$ but this doesn't get me anywhere, I also try the special case of Taylor series, but nothing look like this. I wonder if any one would give  me a hint please.",,['complex-analysis']
31,Properties of holomorphic functions (demonstration),Properties of holomorphic functions (demonstration),,"I don't know how to do this demonstration: ""If f is an holomorphic function, and M $\in \mathbb{R}^+$, such that for $z \in \mathbb{C}$, $|f(z)| \leq M(1+ |z|^n)$, then f is a $n$ or less degree polynomial"" Thanks for your attention!","I don't know how to do this demonstration: ""If f is an holomorphic function, and M $\in \mathbb{R}^+$, such that for $z \in \mathbb{C}$, $|f(z)| \leq M(1+ |z|^n)$, then f is a $n$ or less degree polynomial"" Thanks for your attention!",,"['complex-analysis', 'analyticity']"
32,The Set of Functions satisfying $\int_{D}\vert f(z)\vert (1-\vert z\vert)^2dA(z)\le 1$ is a Normal Family,The Set of Functions satisfying  is a Normal Family,\int_{D}\vert f(z)\vert (1-\vert z\vert)^2dA(z)\le 1,"Let $\mathcal{F}$ be a family of holomorphic functions on the unit disc so that for any $f\in \mathcal{F}$ one has $$\int_{D}\vert f(z)\vert (1-\vert z\vert)^2dA(z)\le 1$$   Prove $\mathcal{F}$ is a normal family. I have also seen a similar problem where the integral was $\int_{D}\vert f \vert^2dA(z)$. I am looking for a solution that can can used in both of these examples. The only technique that comes to mind is the following: Montel's Theorem: If $U\subset \mathbb{C}$ is an open set and $\mathcal{F}$ is a family of holomorphic functions on $U$ that is bounded on compact sets, then there is a sequence ${f_n}\subset \mathcal{F}$ that converges normally in $U$. Attempt: For each $n$ let $g_n(z)=\int_{D}\vert f_n(z)\vert (1-\vert z \vert )^2dA(z)$. Then $g_n$ is bounded by $1$ on any compact subset of $D$. So by Montel's Theorem and continuity of the integral, $g_n$ converges normally to some $\int_{D}\vert g(z)\vert (1-\vert z \vert)^2dA(z)$. Hence $f_n$ converges normally to $g$. Am I on the right track? For the example $\int_{D}\vert f \vert^2 dA(z)$, I am not sure if this method suffices since the hint is to use Cauchy inequalities to show that $\vert f \vert ^2$ does not exceed the mean value of $\vert f\vert ^2$ on a small disc centered at $z$.","Let $\mathcal{F}$ be a family of holomorphic functions on the unit disc so that for any $f\in \mathcal{F}$ one has $$\int_{D}\vert f(z)\vert (1-\vert z\vert)^2dA(z)\le 1$$   Prove $\mathcal{F}$ is a normal family. I have also seen a similar problem where the integral was $\int_{D}\vert f \vert^2dA(z)$. I am looking for a solution that can can used in both of these examples. The only technique that comes to mind is the following: Montel's Theorem: If $U\subset \mathbb{C}$ is an open set and $\mathcal{F}$ is a family of holomorphic functions on $U$ that is bounded on compact sets, then there is a sequence ${f_n}\subset \mathcal{F}$ that converges normally in $U$. Attempt: For each $n$ let $g_n(z)=\int_{D}\vert f_n(z)\vert (1-\vert z \vert )^2dA(z)$. Then $g_n$ is bounded by $1$ on any compact subset of $D$. So by Montel's Theorem and continuity of the integral, $g_n$ converges normally to some $\int_{D}\vert g(z)\vert (1-\vert z \vert)^2dA(z)$. Hence $f_n$ converges normally to $g$. Am I on the right track? For the example $\int_{D}\vert f \vert^2 dA(z)$, I am not sure if this method suffices since the hint is to use Cauchy inequalities to show that $\vert f \vert ^2$ does not exceed the mean value of $\vert f\vert ^2$ on a small disc centered at $z$.",,"['complex-analysis', 'uniform-convergence', 'normal-families']"
33,conformal map of unit disk slit,conformal map of unit disk slit,,"Map the unit disk slit along $(-1,-r ]$, $r \in (0, 1)$, onto the unit disk. Can anyone explain how to do the conformal map thoroughly since I have difficulty understanding it. Thanks","Map the unit disk slit along $(-1,-r ]$, $r \in (0, 1)$, onto the unit disk. Can anyone explain how to do the conformal map thoroughly since I have difficulty understanding it. Thanks",,"['complex-analysis', 'conformal-geometry']"
34,Residue theorem:When a singularity on the circle (not inside the circle),Residue theorem:When a singularity on the circle (not inside the circle),,"This is the integration I am trying to solve $$\int_{0}^{\pi} \sin^{2}(\theta)\sec^{3}(\theta)d\theta$$ putting $$z=e^{i\theta}$$ $$\int_{\gamma} \frac{-2{(z^{2}-1)}^2}{i(z-i)^{3}(z+i)^{3}}d\theta$$ when applying the residue theorem over a circle of radius 1, singularities are on the circle instead of inside the circle.How can we evaluate a integration like this Thanks","This is the integration I am trying to solve $$\int_{0}^{\pi} \sin^{2}(\theta)\sec^{3}(\theta)d\theta$$ putting $$z=e^{i\theta}$$ $$\int_{\gamma} \frac{-2{(z^{2}-1)}^2}{i(z-i)^{3}(z+i)^{3}}d\theta$$ when applying the residue theorem over a circle of radius 1, singularities are on the circle instead of inside the circle.How can we evaluate a integration like this Thanks",,"['integration', 'complex-analysis', 'contour-integration', 'residue-calculus', 'cauchy-principal-value']"
35,"Is the function complex differentiable at (0,0)?","Is the function complex differentiable at (0,0)?",,"(in Complex) $$  g(z) = \begin{cases} \frac{z^5}{|z|^4} & \text{if $z \neq 0$} \\ 0, & \text{if $z = 0$ } \end{cases} $$ For the function above, is it differentiable at $z=0$? I am trying to use following theorem to solve it: Let $f(z)=u(x,y)+iv(x,y)$ be defined in some open set G containing the point $z_0$. If the first partial derivates of u and v exist in G, are continuous at $z_0$ and satisfy the C-R equations at $z_0$, then f is differentiable at $z_0$. I would say, since $g(z)=0$ if $z=0$ that C-R holds at $0$ and that first partial derivates exist in $C$, but I am not sure about the partial derivates being continuous at $0$ (how do I see that)?","(in Complex) $$  g(z) = \begin{cases} \frac{z^5}{|z|^4} & \text{if $z \neq 0$} \\ 0, & \text{if $z = 0$ } \end{cases} $$ For the function above, is it differentiable at $z=0$? I am trying to use following theorem to solve it: Let $f(z)=u(x,y)+iv(x,y)$ be defined in some open set G containing the point $z_0$. If the first partial derivates of u and v exist in G, are continuous at $z_0$ and satisfy the C-R equations at $z_0$, then f is differentiable at $z_0$. I would say, since $g(z)=0$ if $z=0$ that C-R holds at $0$ and that first partial derivates exist in $C$, but I am not sure about the partial derivates being continuous at $0$ (how do I see that)?",,"['complex-analysis', 'derivatives']"
36,Infinite sum of analytic function still analytic,Infinite sum of analytic function still analytic,,"Consider $$ f_n(x)  = n e^{-n^6(x-n)^2} : \mathbb R \rightarrow \mathbb R$$ and the series $$ f(x) = \sum_{n=1}^{\infty} f_n(x). $$ Is $f$ analytic on $\mathbb R$? A function is analytic if for every compact set $K$ we can find $C$ s.t. the $k$-th derivative can be bounded as $$|f^{(k)}(x) | \leq C^{k+1} k! \quad \forall x \in K.$$ From the form of $f_n$, we know that $f^{(k)}$ will be a series of a polynomial of degree $k$ times $f_n$. However I find it hard to actually estimate $|f^{(k)}(x) |$ as required... Another try: since $f_n$ is analytic we can write $f_n(x) = \sum_k a_{k,n} x^k $ so  $$ f(x) = \sum_n \sum_k a_{k,n} x^k.$$ Now if we switch the sums we get $$ f(x) = \sum_k \left( \sum_n a_{k,n} \right) x^k. $$ But can we switch the sum, and it is true that $\forall k, \sum_n a_{k,n} < \infty$? Any suggestion or faster way to prove that $f$ is analytic?","Consider $$ f_n(x)  = n e^{-n^6(x-n)^2} : \mathbb R \rightarrow \mathbb R$$ and the series $$ f(x) = \sum_{n=1}^{\infty} f_n(x). $$ Is $f$ analytic on $\mathbb R$? A function is analytic if for every compact set $K$ we can find $C$ s.t. the $k$-th derivative can be bounded as $$|f^{(k)}(x) | \leq C^{k+1} k! \quad \forall x \in K.$$ From the form of $f_n$, we know that $f^{(k)}$ will be a series of a polynomial of degree $k$ times $f_n$. However I find it hard to actually estimate $|f^{(k)}(x) |$ as required... Another try: since $f_n$ is analytic we can write $f_n(x) = \sum_k a_{k,n} x^k $ so  $$ f(x) = \sum_n \sum_k a_{k,n} x^k.$$ Now if we switch the sums we get $$ f(x) = \sum_k \left( \sum_n a_{k,n} \right) x^k. $$ But can we switch the sum, and it is true that $\forall k, \sum_n a_{k,n} < \infty$? Any suggestion or faster way to prove that $f$ is analytic?",,"['real-analysis', 'complex-analysis', 'power-series']"
37,Prove that there is no entire function such that for every $w$ in the complex plane $f^{-1}(w)$ consists of exactly 2 points.,Prove that there is no entire function such that for every  in the complex plane  consists of exactly 2 points.,w f^{-1}(w),"So I came across the following problem. Prove that there is no entire function such that for every $w$ in the complex plane $f^{-1}(w)$ consists of exactly 2 points. So here is what I was thinking. Let $f^{-1}(w)=\{z_1, z_2\}$. Now consider $f: \mathbb{C} \setminus \{z_1, z_2\}  \rightarrow \mathbb{C} \setminus \{w\}$, the restriction. Now consider the open mapping property of holomorphic functions. Given any point $x\in \mathbb{C} \setminus \{w\}$ we can pick two sufficiently small open balls around the preimage points so that they map to an open neighborhoods around $x$. . Take their intersection, and take an open ball around $x$. Now, I would like to say taking the preimage of this open neighborhood gives me two disjoint open subsets homeomorphic to a ball, and so I would have a 2 sheeted covering. Coverings induce injections on fundamental groups, but the fundamental group of the twice punctured plane is $\mathbb{Z}\ast \mathbb{Z}$ which is non-abelian, while that of the once punctured plane is just $\mathbb{Z}$ yielding a contradiction. So, does this seem correct? And is there a more clever way of doing this without resorting to covering space ideas? Thanks for any help!","So I came across the following problem. Prove that there is no entire function such that for every $w$ in the complex plane $f^{-1}(w)$ consists of exactly 2 points. So here is what I was thinking. Let $f^{-1}(w)=\{z_1, z_2\}$. Now consider $f: \mathbb{C} \setminus \{z_1, z_2\}  \rightarrow \mathbb{C} \setminus \{w\}$, the restriction. Now consider the open mapping property of holomorphic functions. Given any point $x\in \mathbb{C} \setminus \{w\}$ we can pick two sufficiently small open balls around the preimage points so that they map to an open neighborhoods around $x$. . Take their intersection, and take an open ball around $x$. Now, I would like to say taking the preimage of this open neighborhood gives me two disjoint open subsets homeomorphic to a ball, and so I would have a 2 sheeted covering. Coverings induce injections on fundamental groups, but the fundamental group of the twice punctured plane is $\mathbb{Z}\ast \mathbb{Z}$ which is non-abelian, while that of the once punctured plane is just $\mathbb{Z}$ yielding a contradiction. So, does this seem correct? And is there a more clever way of doing this without resorting to covering space ideas? Thanks for any help!",,"['complex-analysis', 'algebraic-topology', 'complex-numbers']"
38,Integrate using residue theorem,Integrate using residue theorem,,This was a question on my complex analysis take home final. Since the semester is over and grades have been posted I believe I can post it now. Let $a > 0$ and $b > 0$. Verify that $$\int_{-\infty}^{\infty} \frac{dx}{e^{a x}+e^{-b x}} = \frac{\pi}{(a+b) \sin{\left (\frac{a \pi}{a+b} \right )}} $$ (Using Residue Theorem) I believe we have to choose a rectangular contour which contains exactly one of the singularities.,This was a question on my complex analysis take home final. Since the semester is over and grades have been posted I believe I can post it now. Let $a > 0$ and $b > 0$. Verify that $$\int_{-\infty}^{\infty} \frac{dx}{e^{a x}+e^{-b x}} = \frac{\pi}{(a+b) \sin{\left (\frac{a \pi}{a+b} \right )}} $$ (Using Residue Theorem) I believe we have to choose a rectangular contour which contains exactly one of the singularities.,,"['complex-analysis', 'contour-integration', 'residue-calculus']"
39,"Simple proof that there is no isomorphism between any two of $ Aut(\hat{C}) $(Riemann Sphere),$ Aut(H^+) $(upper half plane) and $ Aut(C) $","Simple proof that there is no isomorphism between any two of (Riemann Sphere),(upper half plane) and", Aut(\hat{C})   Aut(H^+)   Aut(C) ,"Referring the groups of automorphisms (holomorphic bijections) of the respective domains. This is a homework problem. Is a basic course, so sophisticated answers may not be of help (it has a simple solution according to my teacher).  Also, it looks like an Algebra problem, but I’ve been assured that there is a solution within complex analysis, so if anyone can give a non algebraic proof, it will be appreciated. I tried constructing a conformal mapping (between two of the domains) using a supposed isomorphism, also calculate the unit roots (of second degree, and some of higher degree) in each of the groups, and a couple ideas more, but with no luck.  Thanks in advance for your help (and sorry about my poor English). Edit:The question was edited to avoid sophisticated algebraic answers.  Please, just use the very basic of algebra in your solution. Is a complex analysis exercise! (of course, if you just want to share a sohpisticated answer that can help other users, welcome.)","Referring the groups of automorphisms (holomorphic bijections) of the respective domains. This is a homework problem. Is a basic course, so sophisticated answers may not be of help (it has a simple solution according to my teacher).  Also, it looks like an Algebra problem, but I’ve been assured that there is a solution within complex analysis, so if anyone can give a non algebraic proof, it will be appreciated. I tried constructing a conformal mapping (between two of the domains) using a supposed isomorphism, also calculate the unit roots (of second degree, and some of higher degree) in each of the groups, and a couple ideas more, but with no luck.  Thanks in advance for your help (and sorry about my poor English). Edit:The question was edited to avoid sophisticated algebraic answers.  Please, just use the very basic of algebra in your solution. Is a complex analysis exercise! (of course, if you just want to share a sohpisticated answer that can help other users, welcome.)",,['complex-analysis']
40,Why is the derivative of a polar function $dy/dx$ and not $dr/d\theta$?,Why is the derivative of a polar function  and not ?,dy/dx dr/d\theta,"I don't understand. If $r = 2\cos(\theta)$ then why is the derivative: $dy/dx$? I have a ""hypothesis,"" By the polar equation are you really describing a curve in the cartesian plane? So is that why?","I don't understand. If $r = 2\cos(\theta)$ then why is the derivative: $dy/dx$? I have a ""hypothesis,"" By the polar equation are you really describing a curve in the cartesian plane? So is that why?",,"['calculus', 'algebra-precalculus', 'complex-analysis', 'derivatives']"
41,"show that if $f$ is non constant and entire , $e^f$ is transcendental","show that if  is non constant and entire ,  is transcendental",f e^f,"Entire function that is not a polynomial is called an entire transcendental function. I know that $\infty$ is an essential singularity of $f$ iff $f$ entire transcendental function. Hence, I only need to show that $e^f$ has an essential singularity at $\infty$. Any hints?","Entire function that is not a polynomial is called an entire transcendental function. I know that $\infty$ is an essential singularity of $f$ iff $f$ entire transcendental function. Hence, I only need to show that $e^f$ has an essential singularity at $\infty$. Any hints?",,['complex-analysis']
42,Find all solutions of $e^z = e$ with $z \in \mathbb{C}$,Find all solutions of  with,e^z = e z \in \mathbb{C},"How do we go about doing this? $e^z = e \implies e^{x+iy} = e \implies x+iy =1$ Obviously $(1,0)$ works, but what else?","How do we go about doing this? $e^z = e \implies e^{x+iy} = e \implies x+iy =1$ Obviously $(1,0)$ works, but what else?",,['complex-analysis']
43,Show that $\int_{|z|=1} \frac{e^z}{z^k} dz = \frac{2\pi i}{(k-1)!}$,Show that,\int_{|z|=1} \frac{e^z}{z^k} dz = \frac{2\pi i}{(k-1)!},"I'm supposed to show that $$\int_{|z|=1} \frac{e^z}{z^k} dz = \frac{2\pi i}{(k-1)!}$$ where $|z|=1$ is traversed counterclockwise and $k>0$. We can parametrize this path as $\gamma(t)=e^{it}$ for $t\in [0,2\pi]$. Now I already know that if $n\neq -1$, we have $\int_{\gamma} z^n dz = 0$ by Cauchy's Integral Theorem (and $= 2\pi i$ if $n=-1$). I also know that $e^z$ converges uniformly on any closed ball $\overline{D_r(0)}$. Lastly, I'm told that $$ \frac{e^z}{z^k} = z^{-k} + z^{1-k}+\frac{z^{2-k}}{2!} + \cdots$$ converges uniformly on any annulus $\{z\in\mathbb{C} \mid r\leq|z|\leq R\}$, where $0<r<R$. I'm supposed to use all of these elements to calculate the integral, but I'm having a hard time putting all the pieces together.","I'm supposed to show that $$\int_{|z|=1} \frac{e^z}{z^k} dz = \frac{2\pi i}{(k-1)!}$$ where $|z|=1$ is traversed counterclockwise and $k>0$. We can parametrize this path as $\gamma(t)=e^{it}$ for $t\in [0,2\pi]$. Now I already know that if $n\neq -1$, we have $\int_{\gamma} z^n dz = 0$ by Cauchy's Integral Theorem (and $= 2\pi i$ if $n=-1$). I also know that $e^z$ converges uniformly on any closed ball $\overline{D_r(0)}$. Lastly, I'm told that $$ \frac{e^z}{z^k} = z^{-k} + z^{1-k}+\frac{z^{2-k}}{2!} + \cdots$$ converges uniformly on any annulus $\{z\in\mathbb{C} \mid r\leq|z|\leq R\}$, where $0<r<R$. I'm supposed to use all of these elements to calculate the integral, but I'm having a hard time putting all the pieces together.",,"['complex-analysis', 'uniform-convergence', 'complex-integration']"
44,"Half-Fourier transform, relation to Delta function","Half-Fourier transform, relation to Delta function",,"so the Fourier transform of the Kronecker Delta function is (up to sign conventions / normalisation) $$\int_{-\infty}^\infty dt\; e^{i t \omega} = \delta(\omega).$$ Can one say anything about the half-Fourier transform $$\int_0^\infty dt\; e^{i t \omega}$$ and its relation to the Kronecker Delta function? Specifically, I have come across the relation $$\int_0^\infty dt\; \textrm{Re}[e^{i t \omega}]  \;\;\Big(=\int_0^\infty dt \cos( t \omega)\Big) \;\;= \delta (\omega),$$ but cannot seem to prove this. Any ideas?","so the Fourier transform of the Kronecker Delta function is (up to sign conventions / normalisation) $$\int_{-\infty}^\infty dt\; e^{i t \omega} = \delta(\omega).$$ Can one say anything about the half-Fourier transform $$\int_0^\infty dt\; e^{i t \omega}$$ and its relation to the Kronecker Delta function? Specifically, I have come across the relation $$\int_0^\infty dt\; \textrm{Re}[e^{i t \omega}]  \;\;\Big(=\int_0^\infty dt \cos( t \omega)\Big) \;\;= \delta (\omega),$$ but cannot seem to prove this. Any ideas?",,"['integration', 'complex-analysis', 'fourier-analysis', 'complex-integration', 'dirac-delta']"
45,Curvature in complex analysis,Curvature in complex analysis,,"Apparently, the curvature of the image contour of the unit circle $|z| = 1$ under the conformal mapping $w = f(z)$ is $$\frac{1}{|zf'(z)|} \text{Re}\bigg(1 + \frac{zf''(z)}{f'(z)}\bigg).$$ How does one show this? How do we even define curvature in complex analysis? I could not find a single book that explains what curvature is in complex analysis.","Apparently, the curvature of the image contour of the unit circle $|z| = 1$ under the conformal mapping $w = f(z)$ is $$\frac{1}{|zf'(z)|} \text{Re}\bigg(1 + \frac{zf''(z)}{f'(z)}\bigg).$$ How does one show this? How do we even define curvature in complex analysis? I could not find a single book that explains what curvature is in complex analysis.",,"['complex-analysis', 'complex-numbers', 'curvature']"
46,Chebyshev Polynomial Recurrence relation,Chebyshev Polynomial Recurrence relation,,"the problem states: ""Show that $\cos(n\theta)$ is a polynomial in $\cos(\theta).$"" Now, using De Moivre's and Binomial theorems i get that  $$\cos(n\theta) = \sum_{k = 0, evens}^{n}\binom{n}{k}\cos^{n-k}(\theta)(\pm(1-\cos^{2}(\theta))^{k/2})$$ Note that the $\pm$ here does not mean both, but it rather means ""we don't care which one,"" and so it is obvious that the RHS is a polynomial in $\cos(\theta).$ So the second part of the problem asks to ""use appropriate trig functions"" to show that $$T_{n+1}(z) + T_{n-1}(z) = 2zT_{n}(z).$$ Here i am stuck. Since i have never encountered Chebyshev polynomials before, is the RHS i found for $\cos(n\theta)$ the $T_{n}(z)$? And if so, exactly how would i approach the second part of the problem? I tried induction, but either i am too tired right now, or it really does get hairy too fast. Thanks in advance.","the problem states: ""Show that $\cos(n\theta)$ is a polynomial in $\cos(\theta).$"" Now, using De Moivre's and Binomial theorems i get that  $$\cos(n\theta) = \sum_{k = 0, evens}^{n}\binom{n}{k}\cos^{n-k}(\theta)(\pm(1-\cos^{2}(\theta))^{k/2})$$ Note that the $\pm$ here does not mean both, but it rather means ""we don't care which one,"" and so it is obvious that the RHS is a polynomial in $\cos(\theta).$ So the second part of the problem asks to ""use appropriate trig functions"" to show that $$T_{n+1}(z) + T_{n-1}(z) = 2zT_{n}(z).$$ Here i am stuck. Since i have never encountered Chebyshev polynomials before, is the RHS i found for $\cos(n\theta)$ the $T_{n}(z)$? And if so, exactly how would i approach the second part of the problem? I tried induction, but either i am too tired right now, or it really does get hairy too fast. Thanks in advance.",,"['complex-analysis', 'complex-numbers', 'chebyshev-polynomials']"
47,What is the residue of the reciprocal of Klein's $j$-invariant $1/j(\tau)$ at $e^{2\pi i /3}$,What is the residue of the reciprocal of Klein's -invariant  at,j 1/j(\tau) e^{2\pi i /3},"In Mathematica, Residue[1/KleinInvariantJ[t], {t,Exp[2*pi*I/3]}] results in a very ungainly expression involving complete elliptic integrals of the first and second kind evaluated at the modular lambda function $\lambda(\mathrm{e}^{2\pi i /3})$. Is there a more elegant representation of this residue? (poking around for the numerical value on the Inverse Symbolic Calculator didn't return anything) What about the residues of the other poles of $\frac{1}{J(\tau)}$?","In Mathematica, Residue[1/KleinInvariantJ[t], {t,Exp[2*pi*I/3]}] results in a very ungainly expression involving complete elliptic integrals of the first and second kind evaluated at the modular lambda function $\lambda(\mathrm{e}^{2\pi i /3})$. Is there a more elegant representation of this residue? (poking around for the numerical value on the Inverse Symbolic Calculator didn't return anything) What about the residues of the other poles of $\frac{1}{J(\tau)}$?",,"['complex-analysis', 'special-functions', 'modular-forms']"
48,Why is Euler's formula defined for non-integer values?,Why is Euler's formula defined for non-integer values?,,"Say that for some complex number $w$ $$e^{wi} = a$$ Now raise both sides to $1/4$. $$e^{wi/4} = a^{1/4}$$ Now $e^{wi/4}$ has a single defined  value. Yet $a^{1/4}$ can have multiple values. So why is Euler's formula well defined for non-integer powers, since non-integer powers can yield multiple values?","Say that for some complex number $w$ $$e^{wi} = a$$ Now raise both sides to $1/4$. $$e^{wi/4} = a^{1/4}$$ Now $e^{wi/4}$ has a single defined  value. Yet $a^{1/4}$ can have multiple values. So why is Euler's formula well defined for non-integer powers, since non-integer powers can yield multiple values?",,"['complex-analysis', 'complex-numbers']"
49,Every line or circle in $\mathbb{C}$ are solution sets to the equation...,Every line or circle in  are solution sets to the equation...,\mathbb{C},"Here is a complex analysis homework problem I can't quite figure out: Prove that every line or circle in $\mathbb{C}$ is the solution set of an equation of the form $a|z|^2+\bar{w}z+w\bar{z}+b=0$, where $a,b\in\mathbb{R}$ and $w,z\in\mathbb{C}$. Conversely, show that every equation of this form has a line, circle, point, or the empty set as its solution set. So far, I've tried to rewrite the equation of a line in $\mathbb{R}^2$ as $y=mx+b$ in $\mathbb{C}$, where $m$ is real and $x,b$ are complex. I know that a circle in the complex plane is given by $|z-a|=r$, where $a$ is the center and $r$ is the radius. I also noticed that $\bar{w}z+w\bar{z}=2\text{Re}(\bar{w}z)$. I'm just not sure how all these pieces fit together in answering the question. Any help would be greatly appreciated.","Here is a complex analysis homework problem I can't quite figure out: Prove that every line or circle in $\mathbb{C}$ is the solution set of an equation of the form $a|z|^2+\bar{w}z+w\bar{z}+b=0$, where $a,b\in\mathbb{R}$ and $w,z\in\mathbb{C}$. Conversely, show that every equation of this form has a line, circle, point, or the empty set as its solution set. So far, I've tried to rewrite the equation of a line in $\mathbb{R}^2$ as $y=mx+b$ in $\mathbb{C}$, where $m$ is real and $x,b$ are complex. I know that a circle in the complex plane is given by $|z-a|=r$, where $a$ is the center and $r$ is the radius. I also noticed that $\bar{w}z+w\bar{z}=2\text{Re}(\bar{w}z)$. I'm just not sure how all these pieces fit together in answering the question. Any help would be greatly appreciated.",,"['complex-analysis', 'complex-numbers']"
50,$f(z)$ and $g(z)$ are Meromorphic functions such $|f(z)|\le|g(z)|$ for all $z\in\mathbb{C} $ then $ f=ag$,and  are Meromorphic functions such  for all  then,f(z) g(z) |f(z)|\le|g(z)| z\in\mathbb{C}   f=ag,"We know that if $f(z)$ and $g(z)$ are entire functions such that $g(z)\ne0$ and $|f(z)|\le|g(z)|$ for all $z\in\mathbb{C} $ then by Liouville's theorem $$ f=ag$$ for some constant $a\in \mathbb{C} $ . Now my question is this that similar to above argument, if $f(z)$ and $g(z)$ are Meromorphic functions such $|f(z)|\le|g(z)|$ for all $z\in\mathbb{C} $ then I want to show $$ f=ag$$ for some constant $a\in \mathbb{C} $ . I am thinking in this way that because because poles and zeros of Meromorphic functions are isolated , by the Riemann's theorem on removable singularities and By using analytic continuation to eliminate removable singularities also we can have $$ f=ag$$ for some constant $a\in \mathbb{C} $ . Is this true way?","We know that if $f(z)$ and $g(z)$ are entire functions such that $g(z)\ne0$ and $|f(z)|\le|g(z)|$ for all $z\in\mathbb{C} $ then by Liouville's theorem $$ f=ag$$ for some constant $a\in \mathbb{C} $ . Now my question is this that similar to above argument, if $f(z)$ and $g(z)$ are Meromorphic functions such $|f(z)|\le|g(z)|$ for all $z\in\mathbb{C} $ then I want to show $$ f=ag$$ for some constant $a\in \mathbb{C} $ . I am thinking in this way that because because poles and zeros of Meromorphic functions are isolated , by the Riemann's theorem on removable singularities and By using analytic continuation to eliminate removable singularities also we can have $$ f=ag$$ for some constant $a\in \mathbb{C} $ . Is this true way?",,['complex-analysis']
51,where does $\frac{1}{1-z}$ about the point $5i$ converge.,where does  about the point  converge.,\frac{1}{1-z} 5i,"Hi: Th next question in John D'Angelo's text is exercise 4.8: where does the series for $\frac{1}{1-z}$ about the point $5i$ converge ? I understand that the expansion is : $\sum_{n=0}^{\infty} (z - 5i)^{n}$. Now, for the series to converge, $|z-5i|$ has to be less than 1 because the series is geometric. So is that the answer ? that $|z-5i|$ < 1$. This exercise is after another exercise which was much harder ( required abel's convergence for complex series test ) so I'm thinking that maybe I'm not correct. Thanks.","Hi: Th next question in John D'Angelo's text is exercise 4.8: where does the series for $\frac{1}{1-z}$ about the point $5i$ converge ? I understand that the expansion is : $\sum_{n=0}^{\infty} (z - 5i)^{n}$. Now, for the series to converge, $|z-5i|$ has to be less than 1 because the series is geometric. So is that the answer ? that $|z-5i|$ < 1$. This exercise is after another exercise which was much harder ( required abel's convergence for complex series test ) so I'm thinking that maybe I'm not correct. Thanks.",,['complex-analysis']
52,Entire function bounded below by a polynomial,Entire function bounded below by a polynomial,,"Let $f$ be an entire function such for some $N \in \mathbb{N}$ and $R >0$ , the following property holds: $|f(z)| \geq |z|^N$ $\forall z \in \mathbb{C}$ with $|z| \geq R$ . Show that $f$ is a polynomial of degree greater than or equal to $N$ . Progress thus far: Clearly, $f$ is not identically zero. Case 1) If $f$ is also nowhere 0, it's not hard to show $f$ is bounded and therefore, by Louisville's Theorem, a constant. Case 2) If $f$ is neither identically zero nor nowhere 0, then we can show that it has a finite number of zeros in the ball $B(0,R)$ .  From these zeros we can get a polynomial $p$ , whose zeros are exactly those of $f$ , and an entire function $g$ such that $f = pg$ .  Consequently, $g$ is nowhere zero. At this point, I'd like to show $g \equiv c$ , where $c$ is some complex constant. A more general problem has been solved here , but I'm trying to avoid using big hammers like Casorati-Weierstrass.  (When this problem was assigned, we hadn't covered it yet.)","Let be an entire function such for some and , the following property holds: with . Show that is a polynomial of degree greater than or equal to . Progress thus far: Clearly, is not identically zero. Case 1) If is also nowhere 0, it's not hard to show is bounded and therefore, by Louisville's Theorem, a constant. Case 2) If is neither identically zero nor nowhere 0, then we can show that it has a finite number of zeros in the ball .  From these zeros we can get a polynomial , whose zeros are exactly those of , and an entire function such that .  Consequently, is nowhere zero. At this point, I'd like to show , where is some complex constant. A more general problem has been solved here , but I'm trying to avoid using big hammers like Casorati-Weierstrass.  (When this problem was assigned, we hadn't covered it yet.)","f N \in \mathbb{N} R >0 |f(z)| \geq |z|^N \forall z \in \mathbb{C} |z| \geq R f N f f f f B(0,R) p f g f = pg g g \equiv c c",['complex-analysis']
53,Recommendations for books on complex analysis and on measure theory?,Recommendations for books on complex analysis and on measure theory?,,"I'm looking for a book on complex analysis that has a similar writing style to either Terry Tao's Analysis II or Nathan Jacobson's Basic Algebra series. I have found both of these extremely easy to read and follow the proofs given quite easily, or at least I have so far. Preferably the level would be for an advanced undergraduate course or a book used in a first year graduate class on complex analysis. For the measure theory book, I was wondering what a good book would be for a study of the subject starting from almost the ground level (like why Riemann's criteria for integrability is not entirely sufficient), but would be accessible to an advanced undergraduate.","I'm looking for a book on complex analysis that has a similar writing style to either Terry Tao's Analysis II or Nathan Jacobson's Basic Algebra series. I have found both of these extremely easy to read and follow the proofs given quite easily, or at least I have so far. Preferably the level would be for an advanced undergraduate course or a book used in a first year graduate class on complex analysis. For the measure theory book, I was wondering what a good book would be for a study of the subject starting from almost the ground level (like why Riemann's criteria for integrability is not entirely sufficient), but would be accessible to an advanced undergraduate.",,"['complex-analysis', 'measure-theory', 'reference-request']"
54,Laurent series for $\frac1{z^2+1}$,Laurent series for,\frac1{z^2+1},"I have this problem: Find the Laurent series around $z=0$, for $\dfrac{10}{(z+2)(z^2+1)}$ in the region $1<|z|<2$. I did partial fractions and found this: $\dfrac{2}{z+2}-\dfrac{2z-4}{z^2+1}$, then I have to know what's the Laurent series for $\dfrac{1}{z^2+1}$ to solve the problem. Do you know that series? Thank you.","I have this problem: Find the Laurent series around $z=0$, for $\dfrac{10}{(z+2)(z^2+1)}$ in the region $1<|z|<2$. I did partial fractions and found this: $\dfrac{2}{z+2}-\dfrac{2z-4}{z^2+1}$, then I have to know what's the Laurent series for $\dfrac{1}{z^2+1}$ to solve the problem. Do you know that series? Thank you.",,"['complex-analysis', 'laurent-series']"
55,Finding the poles and residues of a complex function $\frac{\cos(z)-1}{(e^z - 1)^2}$,Finding the poles and residues of a complex function,\frac{\cos(z)-1}{(e^z - 1)^2},"I'm trying to find the poles and residues of: $$f(z) = \frac{\cos(z)-1}{(e^z - 1)^2}$$ I can see that this has a removable singularity at $z=0$ and double poles at $z=2k \pi i$. I'm having trouble finding the residues of these. In general, when we have more than a single pole, i.e a double pole, triple pole etc. is it best to just try and find the Laurent expansion about the pole? In this case, writing $(e^z + 1)^{-2} = (e^{z+2k\pi i - 2k \pi i} - 1)^{-2}$ and then expanding this:  $$(e^{2k \pi i}(e^{z- 2k \pi i}) + 1)^{-2} = ((e^{2k \pi i}(1+(z-2k \pi i) + \cdots -1)^{-2}$$ I can't seem to arrive at a sensible answer proceeding like this, and I'm not even sure it is the right method. Any help is much appreciated","I'm trying to find the poles and residues of: $$f(z) = \frac{\cos(z)-1}{(e^z - 1)^2}$$ I can see that this has a removable singularity at $z=0$ and double poles at $z=2k \pi i$. I'm having trouble finding the residues of these. In general, when we have more than a single pole, i.e a double pole, triple pole etc. is it best to just try and find the Laurent expansion about the pole? In this case, writing $(e^z + 1)^{-2} = (e^{z+2k\pi i - 2k \pi i} - 1)^{-2}$ and then expanding this:  $$(e^{2k \pi i}(e^{z- 2k \pi i}) + 1)^{-2} = ((e^{2k \pi i}(1+(z-2k \pi i) + \cdots -1)^{-2}$$ I can't seem to arrive at a sensible answer proceeding like this, and I'm not even sure it is the right method. Any help is much appreciated",,"['complex-analysis', 'residue-calculus']"
56,Finding an upper bound for $|\int_{\gamma}e^{1/z}dz|$.,Finding an upper bound for .,|\int_{\gamma}e^{1/z}dz|,"Find the upper bound for $|\int_{\gamma}e^{1/z}dz|$ where $\gamma$ is the part of the circle $|z| = \sqrt{8}$ from $2+2i$ to $-\sqrt{8}$.  This is a question my professor went through quickly during class and so I am trying to fill in the blanks. I know we will use the mL inequality here.  $L$ is pretty easy to find (just the length of the line), but I am struggling on how to find the maximum of $e^{1/z}$ on this interval. This is where I am: Using the fact that $|z|=\sqrt{8}$ and $x^2+y^2=8$, then the $e^{1/z}$ has a max of $e^{1/ \sqrt8}$. But this is where I get stuck...","Find the upper bound for $|\int_{\gamma}e^{1/z}dz|$ where $\gamma$ is the part of the circle $|z| = \sqrt{8}$ from $2+2i$ to $-\sqrt{8}$.  This is a question my professor went through quickly during class and so I am trying to fill in the blanks. I know we will use the mL inequality here.  $L$ is pretty easy to find (just the length of the line), but I am struggling on how to find the maximum of $e^{1/z}$ on this interval. This is where I am: Using the fact that $|z|=\sqrt{8}$ and $x^2+y^2=8$, then the $e^{1/z}$ has a max of $e^{1/ \sqrt8}$. But this is where I get stuck...",,"['complex-analysis', 'contour-integration']"
57,Motivation for the study of Jacobi Theta Functions,Motivation for the study of Jacobi Theta Functions,,"The wikipedia definition says: ""There are several closely related functions called Jacobi theta functions, and many different and incompatible systems of notation for them. One Jacobi theta function (named after Carl Gustav Jacob Jacobi) is a function defined for two complex variables z and τ, where z can be any complex number and τ is confined to the upper half-plane, which means it has positive imaginary part. It is given by the formula"" $$\vartheta(z; \tau) = \sum_{n=-\infty}^\infty \exp (\pi i n^2 \tau + 2 \pi i n z)= 1 + 2 \sum_{n=1}^\infty \left(e^{\pi i\tau}\right)^{n^2} \cos(2\pi n z) = \sum_{n=-\infty}^\infty q^{n^2}\eta^n""$$ This definition is perfectly fine for me, no problem. But why would somebody think of a function in this way? Is there na historical reason to study functions this way, or does these types of functions apear naturally in some field of study of mathematic?","The wikipedia definition says: ""There are several closely related functions called Jacobi theta functions, and many different and incompatible systems of notation for them. One Jacobi theta function (named after Carl Gustav Jacob Jacobi) is a function defined for two complex variables z and τ, where z can be any complex number and τ is confined to the upper half-plane, which means it has positive imaginary part. It is given by the formula"" $$\vartheta(z; \tau) = \sum_{n=-\infty}^\infty \exp (\pi i n^2 \tau + 2 \pi i n z)= 1 + 2 \sum_{n=1}^\infty \left(e^{\pi i\tau}\right)^{n^2} \cos(2\pi n z) = \sum_{n=-\infty}^\infty q^{n^2}\eta^n""$$ This definition is perfectly fine for me, no problem. But why would somebody think of a function in this way? Is there na historical reason to study functions this way, or does these types of functions apear naturally in some field of study of mathematic?",,['complex-analysis']
58,Closed form of $\int _{0}^{\infty }\!{\frac {x\cos \left( x \right) -\sin \left( x \right) }{{x}^{3} \left( {{\rm e}^{x}}+1 \right) }}{dx}$,Closed form of,\int _{0}^{\infty }\!{\frac {x\cos \left( x \right) -\sin \left( x \right) }{{x}^{3} \left( {{\rm e}^{x}}+1 \right) }}{dx},Does it possibly have a closed form? $$\int _{0}^{\infty }\!{\frac {x\cos \left( x \right) -\sin \left( x  \right) }{{x}^{3} \left( {{\rm e}^{x}}+1 \right) }}{dx}$$ Thank you! I found it. No more need for efforts.,Does it possibly have a closed form? $$\int _{0}^{\infty }\!{\frac {x\cos \left( x \right) -\sin \left( x  \right) }{{x}^{3} \left( {{\rm e}^{x}}+1 \right) }}{dx}$$ Thank you! I found it. No more need for efforts.,,"['calculus', 'real-analysis', 'complex-analysis']"
59,A problem related to Schwarz reflection principle,A problem related to Schwarz reflection principle,,"Let $\Omega$ be a bounded domain in $\mathbb{C}$. Suppose there is a function $f$ which is analytic in $\Omega$ except a simple pole at $a\in\Omega$, such that $(z-a)f(z)$ is continuous on $\bar{\Omega}$ with $f(z)=\bar{z}$ on $\partial\Omega$. Prove that the function $g(z)=(z-a)f(z)-(z-a)\bar{a}$ is constant. What is $\Omega$? It should be consistent with the problem if we assume $\Omega$ to be the unit disc $\mathbb{D}$, then we may use the reflection principle with respect to $\mathbb{D}$ to extend $g$ to an entire function and then conclude using the Liouville theorem that $g$ is a constant. But how can we see that this is the most general case that can happen?","Let $\Omega$ be a bounded domain in $\mathbb{C}$. Suppose there is a function $f$ which is analytic in $\Omega$ except a simple pole at $a\in\Omega$, such that $(z-a)f(z)$ is continuous on $\bar{\Omega}$ with $f(z)=\bar{z}$ on $\partial\Omega$. Prove that the function $g(z)=(z-a)f(z)-(z-a)\bar{a}$ is constant. What is $\Omega$? It should be consistent with the problem if we assume $\Omega$ to be the unit disc $\mathbb{D}$, then we may use the reflection principle with respect to $\mathbb{D}$ to extend $g$ to an entire function and then conclude using the Liouville theorem that $g$ is a constant. But how can we see that this is the most general case that can happen?",,['complex-analysis']
60,The $\frac{1}{x+i\varepsilon}$ distribution.,The  distribution.,\frac{1}{x+i\varepsilon},"I read that the distribution defined as: $$ \lim_{\varepsilon \rightarrow 0}\frac{1}{x+i\varepsilon}$$ is equal to $$p.v. \frac{1}{x} -i\pi \delta(x)$$ So that for any test function $f$, $$\lim_{\varepsilon\rightarrow 0} \int_{-\infty}^\infty \frac{f(x)dx}{x+i\varepsilon} = p.v.\int_{-\infty}^\infty \frac{f(x)}{x}dx - i\pi f(0).$$ But when I calculate the integral of $f(z)/z+i\varepsilon$ along this contour: and then the limit $R\to \infty$, the result I arrive at is the following: $$\lim_{\varepsilon\rightarrow 0} \int_{-\infty}^\infty \frac{f(x)dx}{x+i\varepsilon} = \lim_{\varepsilon\rightarrow 0} \left( \int_\varepsilon^\infty \frac{f(x+i\varepsilon)dx}{x+i\varepsilon} + \int_{-\infty}^{-\varepsilon} \frac{f(x+i\varepsilon)dx}{x+i\varepsilon} \right) -i \int_0^\pi f(\varepsilon e^{i \theta} -i\varepsilon) d\theta$$ I can more or less accept the second term being equal to $-i\pi f(0)$, but I don't see why the first one should be the principal value - the epsilons inside the integral are bugging me. But any change of variables, say $z=x+i\varepsilon$, would damage the contour so it would no longer look like a p.v. How can I retrieve the desired result from this?","I read that the distribution defined as: $$ \lim_{\varepsilon \rightarrow 0}\frac{1}{x+i\varepsilon}$$ is equal to $$p.v. \frac{1}{x} -i\pi \delta(x)$$ So that for any test function $f$, $$\lim_{\varepsilon\rightarrow 0} \int_{-\infty}^\infty \frac{f(x)dx}{x+i\varepsilon} = p.v.\int_{-\infty}^\infty \frac{f(x)}{x}dx - i\pi f(0).$$ But when I calculate the integral of $f(z)/z+i\varepsilon$ along this contour: and then the limit $R\to \infty$, the result I arrive at is the following: $$\lim_{\varepsilon\rightarrow 0} \int_{-\infty}^\infty \frac{f(x)dx}{x+i\varepsilon} = \lim_{\varepsilon\rightarrow 0} \left( \int_\varepsilon^\infty \frac{f(x+i\varepsilon)dx}{x+i\varepsilon} + \int_{-\infty}^{-\varepsilon} \frac{f(x+i\varepsilon)dx}{x+i\varepsilon} \right) -i \int_0^\pi f(\varepsilon e^{i \theta} -i\varepsilon) d\theta$$ I can more or less accept the second term being equal to $-i\pi f(0)$, but I don't see why the first one should be the principal value - the epsilons inside the integral are bugging me. But any change of variables, say $z=x+i\varepsilon$, would damage the contour so it would no longer look like a p.v. How can I retrieve the desired result from this?",,"['integration', 'complex-analysis', 'distribution-theory']"
61,Holomorphic functions on algebraic curves,Holomorphic functions on algebraic curves,,"I have been asked to solve the following problem, but I really need some help... How are the holomorphic functions $f:C\to D$, where $C,D$ are nonsingular algebraic curves of genus 1? I know that I have to use Hurwitz' Formula, but I didn't understand it at all. Thanks!","I have been asked to solve the following problem, but I really need some help... How are the holomorphic functions $f:C\to D$, where $C,D$ are nonsingular algebraic curves of genus 1? I know that I have to use Hurwitz' Formula, but I didn't understand it at all. Thanks!",,"['complex-analysis', 'algebraic-geometry', 'riemann-surfaces']"
62,Integral $\int_0^{\pi/2} \log^n (\sin t)\log^p (\cos t) dt$,Integral,\int_0^{\pi/2} \log^n (\sin t)\log^p (\cos t) dt,"I am looking for a closed form expression for the logarithmic trigonometric  integral $$ I_{n,p}=\int_0^{\pi/2} \log^n (\sin t)\log^p (\cos t) dt \quad (n\geq 0, p\geq 0). $$ Closed form expression does exist except I cannot seem to find it when looking through my collection.  This integral comes from this paper which was quite a big hit in the early 80's.   There are many other excellent integrals you can find in here!  I am not sure how to approach this integral due to the powers of $n,p$. Thanks","I am looking for a closed form expression for the logarithmic trigonometric  integral $$ I_{n,p}=\int_0^{\pi/2} \log^n (\sin t)\log^p (\cos t) dt \quad (n\geq 0, p\geq 0). $$ Closed form expression does exist except I cannot seem to find it when looking through my collection.  This integral comes from this paper which was quite a big hit in the early 80's.   There are many other excellent integrals you can find in here!  I am not sure how to approach this integral due to the powers of $n,p$. Thanks",,"['calculus', 'real-analysis', 'integration', 'complex-analysis', 'definite-integrals']"
63,Winding number of a point outside the curve is 0,Winding number of a point outside the curve is 0,,"I've been looking for the answer to the following question for a little while now: Let $γ$ be a closed (C1-)curve whose image is contained in ${z: |z| < R}$ for some $R > 0$. Show that for any $z$ with $|z| > R$ we have $\operatorname{Ind}(γ,z) = 0$. I think I am supposed to use the definition of the index of a winding number, but I have absolutely no idea of how to do it. To me if $z$ is outside the curve then the index is 0 by definition... Any pointers would be greatly appreciated thanks!","I've been looking for the answer to the following question for a little while now: Let $γ$ be a closed (C1-)curve whose image is contained in ${z: |z| < R}$ for some $R > 0$. Show that for any $z$ with $|z| > R$ we have $\operatorname{Ind}(γ,z) = 0$. I think I am supposed to use the definition of the index of a winding number, but I have absolutely no idea of how to do it. To me if $z$ is outside the curve then the index is 0 by definition... Any pointers would be greatly appreciated thanks!",,"['complex-analysis', 'winding-number']"
64,Limit point of isolated singularities,Limit point of isolated singularities,,"Suppose $f$ is analytic on $\mathbb{C}$ (or some open domain) except at a sequence $(c_n)$ and its limit point $c$. If each $c_n$ is a removable singularity, what can we say about $c$? While $c$ was not an isolated singularity for $f$, it becomes isolated once we remove the $c_n$'s, right? Is $c$ now necessarily a certain type of isolated singularity, or it can be either removable, pole, or essential? What about when $a_n$'s are all poles or all essential, can we say anything about the singularity $c$? For example, is $f$ necessarily unbounded near $c$?","Suppose $f$ is analytic on $\mathbb{C}$ (or some open domain) except at a sequence $(c_n)$ and its limit point $c$. If each $c_n$ is a removable singularity, what can we say about $c$? While $c$ was not an isolated singularity for $f$, it becomes isolated once we remove the $c_n$'s, right? Is $c$ now necessarily a certain type of isolated singularity, or it can be either removable, pole, or essential? What about when $a_n$'s are all poles or all essential, can we say anything about the singularity $c$? For example, is $f$ necessarily unbounded near $c$?",,['complex-analysis']
65,Hints on evaluating this $\frac{3}{2\pi}\int_0^{2\pi}\frac{e^{-ikx}}{5 - 4\cos(x)} \mathrm dx$?,Hints on evaluating this ?,\frac{3}{2\pi}\int_0^{2\pi}\frac{e^{-ikx}}{5 - 4\cos(x)} \mathrm dx,"I have the following integral I'm trying to solve: $$\frac{3}{2\pi}\int_0^{2\pi}\frac{e^{-ikx}}{5 - 4\cos(x)} \mathrm dx, \quad k \in \mathbb{Z}.$$ I've tried writing the exponential in terms of sines and cosines and then using the usual rational trig function substitutions, i.e. rewriting the integrand as $$\frac{\cos(kx)}{5 - 4\cos(x)} - \frac{i\sin(kx)}{5 - 4\cos(x)}$$ and then using the substitution $t = \tan{x/2}$ , but this doesn't result in anything useful that I could come up because of the different fequencies in the trig functions.  I also tried writing the cosine in terms of complex exponentials, but didn't end up with anything useful either. If the only solution involves residue calculus then please let me know, as I'm not familiar with that subject so I haven't tried anything like that.  Thanks! UPDATE: As was suggested I wrote the $\frac{1}{5 - 4\cos(x)}$ term as a geometric series $\frac{1}{5}\sum\limits_{n = 0}^\infty (\frac{4}{5}\cos(x))^n$ , so now I am trying to evaluate $$\int_0^{2\pi} \cos^n(x) e^{-ikx} dx,$$ but am stuck here again.  I am trying to do this without using the residue theorem, but if that's the only way then so be it!","I have the following integral I'm trying to solve: I've tried writing the exponential in terms of sines and cosines and then using the usual rational trig function substitutions, i.e. rewriting the integrand as and then using the substitution , but this doesn't result in anything useful that I could come up because of the different fequencies in the trig functions.  I also tried writing the cosine in terms of complex exponentials, but didn't end up with anything useful either. If the only solution involves residue calculus then please let me know, as I'm not familiar with that subject so I haven't tried anything like that.  Thanks! UPDATE: As was suggested I wrote the term as a geometric series , so now I am trying to evaluate but am stuck here again.  I am trying to do this without using the residue theorem, but if that's the only way then so be it!","\frac{3}{2\pi}\int_0^{2\pi}\frac{e^{-ikx}}{5 - 4\cos(x)} \mathrm dx, \quad k \in \mathbb{Z}. \frac{\cos(kx)}{5 - 4\cos(x)} - \frac{i\sin(kx)}{5 - 4\cos(x)} t = \tan{x/2} \frac{1}{5 - 4\cos(x)} \frac{1}{5}\sum\limits_{n = 0}^\infty (\frac{4}{5}\cos(x))^n \int_0^{2\pi} \cos^n(x) e^{-ikx} dx,","['calculus', 'integration', 'complex-analysis']"
66,When does analytic continuation respect functional equation,When does analytic continuation respect functional equation,,"This is a subtle point about analytic continuation. Let $\Gamma(s)$ be the analytic continuation of $\gamma(s) := \int_0^\infty e^{-t}t^{s-1}dt$ to $\Bbb C \setminus \Bbb Z_{<0}$, the latter function being only defined for $\operatorname {Re}(s)\ge 0$. Notice that one can prove from the definition of $\gamma(s)$ that it satifies the functional equation $\gamma(s+1) = s\gamma(s)$ where it is defined. Stein and Shakarchi claim on page 162 of their book complex analysis that because $\Gamma (s)$ and $\gamma(s)$ agree on $\operatorname {Re}(s)\ge 0$ and $\Gamma(s)$ is holomorphic away from its poles, the functional equation stated above is also true $\Gamma(s)$ wherever it is holomorphic, and takes the form $\operatorname{res}_{s=-n} \Gamma(s+1)=(-n)\operatorname{res}_{s=-n} \Gamma(s)$ at the poles of $\Gamma(s)$. My question is whether the above reasoning is really correct, and, if so, why. I see why it is true for the gamma function because $\Gamma(s)$ was extended from $\gamma(s)$ using precisely the functional equation of $\gamma(s)$, but could one know that this is true if one extended $\gamma(s)$ by a power series? In other words, (why) is it in general true that any functional equation $E(f(s),s)=0$  of a holomorphic function $f(s)$ defined on a connected domain $\omega$ will also hold for the analytic continuation $F(z)$ of $f(s)$ into a larger connected domain $\Omega \supset \omega$.","This is a subtle point about analytic continuation. Let $\Gamma(s)$ be the analytic continuation of $\gamma(s) := \int_0^\infty e^{-t}t^{s-1}dt$ to $\Bbb C \setminus \Bbb Z_{<0}$, the latter function being only defined for $\operatorname {Re}(s)\ge 0$. Notice that one can prove from the definition of $\gamma(s)$ that it satifies the functional equation $\gamma(s+1) = s\gamma(s)$ where it is defined. Stein and Shakarchi claim on page 162 of their book complex analysis that because $\Gamma (s)$ and $\gamma(s)$ agree on $\operatorname {Re}(s)\ge 0$ and $\Gamma(s)$ is holomorphic away from its poles, the functional equation stated above is also true $\Gamma(s)$ wherever it is holomorphic, and takes the form $\operatorname{res}_{s=-n} \Gamma(s+1)=(-n)\operatorname{res}_{s=-n} \Gamma(s)$ at the poles of $\Gamma(s)$. My question is whether the above reasoning is really correct, and, if so, why. I see why it is true for the gamma function because $\Gamma(s)$ was extended from $\gamma(s)$ using precisely the functional equation of $\gamma(s)$, but could one know that this is true if one extended $\gamma(s)$ by a power series? In other words, (why) is it in general true that any functional equation $E(f(s),s)=0$  of a holomorphic function $f(s)$ defined on a connected domain $\omega$ will also hold for the analytic continuation $F(z)$ of $f(s)$ into a larger connected domain $\Omega \supset \omega$.",,"['complex-analysis', 'analyticity']"
67,Conformal map from unit disk to strip,Conformal map from unit disk to strip,,"I have the following question: Write down the solution $u(x, y)$ to the Dirichlet problem for the following region and boundary conditions: $U = \{x + iy : 0\le y\le1\}; u(x, 0) = 0, u(x, 1) = 1$. Hence use appropriate conformal maps to find to a solution  in the following region and with the following boundary conditions: $A = \{z : \lvert z \lvert \le 1\}, u(z)=0$ when $\lvert z \lvert=1$ and $Im(z)<0, u(z)=0$ when $\lvert z \lvert=1$ and $Im(z)>0$. In the region $U$ I have the solution $u(x,y)=y$. Now I need to find a conformal map, but I am struggling to get one that gives the right boundary conditions. Something like $(4i/\pi)arctan(z)$ maps the region correctly but does not give the right conditions for the answer. I think the solution may have something to do with mapping the lower half of the disk to $\{x + iy : -1 \le y\le 0\}$ and the upper half to $\{x + iy : 0 \le y \le 1\}$ and then adjusting appropriately, but I can't see how to do this. Any help would be appreciated.","I have the following question: Write down the solution $u(x, y)$ to the Dirichlet problem for the following region and boundary conditions: $U = \{x + iy : 0\le y\le1\}; u(x, 0) = 0, u(x, 1) = 1$. Hence use appropriate conformal maps to find to a solution  in the following region and with the following boundary conditions: $A = \{z : \lvert z \lvert \le 1\}, u(z)=0$ when $\lvert z \lvert=1$ and $Im(z)<0, u(z)=0$ when $\lvert z \lvert=1$ and $Im(z)>0$. In the region $U$ I have the solution $u(x,y)=y$. Now I need to find a conformal map, but I am struggling to get one that gives the right boundary conditions. Something like $(4i/\pi)arctan(z)$ maps the region correctly but does not give the right conditions for the answer. I think the solution may have something to do with mapping the lower half of the disk to $\{x + iy : -1 \le y\le 0\}$ and the upper half to $\{x + iy : 0 \le y \le 1\}$ and then adjusting appropriately, but I can't see how to do this. Any help would be appreciated.",,"['complex-analysis', 'conformal-geometry']"
68,"Behavior of $f(z)=\int_0^1\mathrm{e}^{\alpha t^2}\sin(tz)\,dt$ when $\alpha <0$",Behavior of  when,"f(z)=\int_0^1\mathrm{e}^{\alpha t^2}\sin(tz)\,dt \alpha <0","Define $$f(z)=\int_0^1\mathrm{e}^{\alpha t^2}\sin(tz)\,dt,$$ where $\alpha \in  \mathbb{R}$. If $\alpha >0$ then $f(z)$ has infinitely many real zeros   and at most a finite number of complex zeros. What if $\alpha <0$? Hint. Integrate by parts. My attempt so far. To get some intuition about the problem, I tried to demonstrate the claim in the question. If $x\in \mathbb{R}$, it seems that $$f(x) = 0 \iff \int_0^1\mathrm{e}^{\alpha t^2 + tx}dt= \int_0^1\mathrm{e}^{\alpha t^2 - tx}dt.$$ I was unable to simplify that condition. I then attempted to integrate by parts blindly, and turn the $\alpha <0$ case into the $\alpha>0$ case, and use the claim. $$\int_0^1 \mathrm{e}^{\alpha t^2}\sin(tz)\,dt = -\frac1z \mathrm{e}^\alpha \cos(z) + \frac1z + \frac1z \int_0^1 \cos(tz)\,\mathrm{e}^{\alpha t^2}2\alpha t \, dt.$$ And there I got stuck. Any ideas?","Define $$f(z)=\int_0^1\mathrm{e}^{\alpha t^2}\sin(tz)\,dt,$$ where $\alpha \in  \mathbb{R}$. If $\alpha >0$ then $f(z)$ has infinitely many real zeros   and at most a finite number of complex zeros. What if $\alpha <0$? Hint. Integrate by parts. My attempt so far. To get some intuition about the problem, I tried to demonstrate the claim in the question. If $x\in \mathbb{R}$, it seems that $$f(x) = 0 \iff \int_0^1\mathrm{e}^{\alpha t^2 + tx}dt= \int_0^1\mathrm{e}^{\alpha t^2 - tx}dt.$$ I was unable to simplify that condition. I then attempted to integrate by parts blindly, and turn the $\alpha <0$ case into the $\alpha>0$ case, and use the claim. $$\int_0^1 \mathrm{e}^{\alpha t^2}\sin(tz)\,dt = -\frac1z \mathrm{e}^\alpha \cos(z) + \frac1z + \frac1z \int_0^1 \cos(tz)\,\mathrm{e}^{\alpha t^2}2\alpha t \, dt.$$ And there I got stuck. Any ideas?",,"['integration', 'complex-analysis', 'definite-integrals', 'roots', 'complex-integration']"
69,Existence of holomorphic function with a sequence of zeros in the unit disc,Existence of holomorphic function with a sequence of zeros in the unit disc,,"The question is : Prove that there exists a holomorphic function $f$ on the open unit disc $\{z \in \mathbb{C} : |z| <1\}$ with the properties that $f(0) = 0$ and $f(1-1/n)=1$ for every integer $n$ greater than $1$. My first idea was to use the general version of the Weierstrass factorization theorem to say that there exists a holomorphic function, $g(z)$ in $\mathbb{D}$ with zeros at $z_n = 1-1/n$ and no other zeros. Thus $g(z)+1$ is a candidate for our function. However we need to ensure that $g(0) = -1$. I don't know how. Note: If such a function exists then it will be unbounded as for bounded holomorphic functions in $\mathbb{D}$ with zeros at $z_n$, $\sum (1-|z_n|)$ must converge.","The question is : Prove that there exists a holomorphic function $f$ on the open unit disc $\{z \in \mathbb{C} : |z| <1\}$ with the properties that $f(0) = 0$ and $f(1-1/n)=1$ for every integer $n$ greater than $1$. My first idea was to use the general version of the Weierstrass factorization theorem to say that there exists a holomorphic function, $g(z)$ in $\mathbb{D}$ with zeros at $z_n = 1-1/n$ and no other zeros. Thus $g(z)+1$ is a candidate for our function. However we need to ensure that $g(0) = -1$. I don't know how. Note: If such a function exists then it will be unbounded as for bounded holomorphic functions in $\mathbb{D}$ with zeros at $z_n$, $\sum (1-|z_n|)$ must converge.",,"['complex-analysis', 'complex-numbers', 'roots']"
70,Does there exist an analytic function $f$ such that $f(\overline{\mathbb{D}})=\overline{\mathbb{H}}$?,Does there exist an analytic function  such that ?,f f(\overline{\mathbb{D}})=\overline{\mathbb{H}},"Does there exist an analytic function $f$, defined in a neighborhood of $\overline{\mathbb{D}}$, such that $f(\overline{\mathbb{D}})=\overline{\mathbb{H}}$ ? where $ \overline{\mathbb{H}} = \{ z \in \mathbb{C} | \ Imz \geq 0\} $ and $\overline{\mathbb{D}} = \{ z \in \mathbb{C} | \ |z| \leq 1\}$. The first thing that comes to my mind is the linear fractional transformation $T(z)=\frac{i-iz}{1+z}$ (is not analytic in any neighborhood of $ \overline{\mathbb{D}}$, right? since we are not considering the Riemann sphere, or equivalently $f'(-1)=\infty \notin  \overline{\mathbb{H}}$). But using this or any other linear fractional transformation you have to map the unit circle onto the real line, hence one point , say $z_0$ on the unit circle gets mapped to $\infty$; therefore $ f(z_0) \notin  \overline{\mathbb{H}}$. Is it correct that no linear fractional transformation can do the job ? How can we show that such a map does not exist ? Any hint or idea is appreciated.","Does there exist an analytic function $f$, defined in a neighborhood of $\overline{\mathbb{D}}$, such that $f(\overline{\mathbb{D}})=\overline{\mathbb{H}}$ ? where $ \overline{\mathbb{H}} = \{ z \in \mathbb{C} | \ Imz \geq 0\} $ and $\overline{\mathbb{D}} = \{ z \in \mathbb{C} | \ |z| \leq 1\}$. The first thing that comes to my mind is the linear fractional transformation $T(z)=\frac{i-iz}{1+z}$ (is not analytic in any neighborhood of $ \overline{\mathbb{D}}$, right? since we are not considering the Riemann sphere, or equivalently $f'(-1)=\infty \notin  \overline{\mathbb{H}}$). But using this or any other linear fractional transformation you have to map the unit circle onto the real line, hence one point , say $z_0$ on the unit circle gets mapped to $\infty$; therefore $ f(z_0) \notin  \overline{\mathbb{H}}$. Is it correct that no linear fractional transformation can do the job ? How can we show that such a map does not exist ? Any hint or idea is appreciated.",,['complex-analysis']
71,Odd and even square roots of $z^2-1$,Odd and even square roots of,z^2-1,"This is a very interesting exercise (provided that it is correct). Find two holomorphic functions $\,f_1: \Omega_1\to\mathbb C$ and $f_2:\Omega_2\to\mathbb C$, which are both square roots of $z^2-1$, with maximal domains (i.e., they can not be extended analytically any further), and $f_1$ is even while $f_2$ is odd. The most interesting part is that $f_2$ is an odd function, and therefore, it can not be thought of as a composition of $\sqrt{}$ and $z^2-1$, which is even!","This is a very interesting exercise (provided that it is correct). Find two holomorphic functions $\,f_1: \Omega_1\to\mathbb C$ and $f_2:\Omega_2\to\mathbb C$, which are both square roots of $z^2-1$, with maximal domains (i.e., they can not be extended analytically any further), and $f_1$ is even while $f_2$ is odd. The most interesting part is that $f_2$ is an odd function, and therefore, it can not be thought of as a composition of $\sqrt{}$ and $z^2-1$, which is even!",,"['complex-analysis', 'analysis', 'analyticity', 'radicals']"
72,Magnitude of $\Gamma(1/2+it)$,Magnitude of,\Gamma(1/2+it),"I want to prove that $$|\Gamma(1/2+it)|=\sqrt{\frac{2\pi}{e^{\pi t}+e^{-\pi t}}}$$ My idea is to use the formula $\Gamma(s)\Gamma(1-s)=\pi/\sin \pi s$. Plugging in $s=1/2+it$ and taking absolute values, we get $$|\Gamma(1/2+it)\Gamma(1/2-it)|=\dfrac{\pi}{\sin(\frac{\pi}{2}+it\pi)}$$ How to continue from here?","I want to prove that $$|\Gamma(1/2+it)|=\sqrt{\frac{2\pi}{e^{\pi t}+e^{-\pi t}}}$$ My idea is to use the formula $\Gamma(s)\Gamma(1-s)=\pi/\sin \pi s$. Plugging in $s=1/2+it$ and taking absolute values, we get $$|\Gamma(1/2+it)\Gamma(1/2-it)|=\dfrac{\pi}{\sin(\frac{\pi}{2}+it\pi)}$$ How to continue from here?",,"['complex-analysis', 'gamma-function']"
73,Finding the taylor series of $f(z) = \frac{1}{1+z^2}$,Finding the taylor series of,f(z) = \frac{1}{1+z^2},"I am working on the following exercise: Find the Taylor expansion of the function $f(z) = \frac{1}{1+z^2}$ about $z = 3i$. We had the Taylor Series Theorem in the lecture: Let $D \subset \mathbb C$ be a domain and $f: D \to \mathbb C$ a differentiable function. Then $f$ is analytic in $D$ and for any ball $B_R(z_0) \subset D$ the power series expansion   \begin{align*} f(z) = \sum_{n = 0}^\infty \frac{f^{(n)}(z_0)}{n!}(z-z_0)^n \end{align*}   is valid. Further, if $r \in (0,R)$ then   \begin{align*} f^{(n)}(z_0) = \frac{n!}{2\pi i} \int_{S_r^+(z_0)} \frac{f(w)}{(w-z_0)^{n+1}}dw, \end{align*}   where $S_r^+(z_0) = z_0+re^{it}$ with $0\le t \le 2\pi$. The solution that I don't understand goes like this: Represent $f$ as partial fractions: \begin{align*} f(z) = \frac{1}{1+z^2} = \frac{1}{2\pi i} \left(\frac{1}{z-i} - \frac{1}{z+i}\right). \end{align*} Then we compute \begin{align*} f^{(n)}(z) = \left(\frac{1}{1+z^2}\right)^{(n)} = \frac{1}{2\pi i}\left(\frac{(-1)^nn!}{(z-i)^{n+1}}-\frac{(-1)^nn!}{(z+i)^{n+1}}\right). \end{align*} Then one can plug this in the formula and is done. I don't understand why one can compute so easily the $n$th derivative.","I am working on the following exercise: Find the Taylor expansion of the function $f(z) = \frac{1}{1+z^2}$ about $z = 3i$. We had the Taylor Series Theorem in the lecture: Let $D \subset \mathbb C$ be a domain and $f: D \to \mathbb C$ a differentiable function. Then $f$ is analytic in $D$ and for any ball $B_R(z_0) \subset D$ the power series expansion   \begin{align*} f(z) = \sum_{n = 0}^\infty \frac{f^{(n)}(z_0)}{n!}(z-z_0)^n \end{align*}   is valid. Further, if $r \in (0,R)$ then   \begin{align*} f^{(n)}(z_0) = \frac{n!}{2\pi i} \int_{S_r^+(z_0)} \frac{f(w)}{(w-z_0)^{n+1}}dw, \end{align*}   where $S_r^+(z_0) = z_0+re^{it}$ with $0\le t \le 2\pi$. The solution that I don't understand goes like this: Represent $f$ as partial fractions: \begin{align*} f(z) = \frac{1}{1+z^2} = \frac{1}{2\pi i} \left(\frac{1}{z-i} - \frac{1}{z+i}\right). \end{align*} Then we compute \begin{align*} f^{(n)}(z) = \left(\frac{1}{1+z^2}\right)^{(n)} = \frac{1}{2\pi i}\left(\frac{(-1)^nn!}{(z-i)^{n+1}}-\frac{(-1)^nn!}{(z+i)^{n+1}}\right). \end{align*} Then one can plug this in the formula and is done. I don't understand why one can compute so easily the $n$th derivative.",,"['complex-analysis', 'derivatives', 'taylor-expansion']"
74,Generalized argument principle and elliptic functions,Generalized argument principle and elliptic functions,,"This is a homework question, so please only hints / suggestions if at all possible.  The question asks If $f$ is an elliptic function with respect to some lattice $\Lambda$ and $z_1, \dotsc, z_k \in \Pi$ are the zeros and poles of $f$ (where $\Pi$ is a fundamental parallelogram) with degrees $d_1, \dotsc, d_k$, then $\sum_k d_k z_k \in \Lambda$.   ( Hint . Consider $\int_{\partial \Pi} z \frac{f'(z)}{f(z)} dz$). Say $\Lambda$ is spanned by $\omega_1$ and $\omega_2$.  I need to show that $\sum_k d_k z_k = n_1 \omega_1 + n_2 \omega_2$ for some $n_1, n_2 \in \mathbb{Z}$.  I am aware of the generalized argument principle, so that $$ \int_{\partial \Pi} z \frac{f'(z)}{f(z)} dz = 2 \pi i \left( \sum_{z_k \text{ zero}} n(\partial \Pi, z_k) z_k - \sum_{z_k \text{ pole}} n(\partial \Pi, z_k) z_k \right), $$ but I'm not sure how this helps me.  Any hints or suggestions would be welcomed!","This is a homework question, so please only hints / suggestions if at all possible.  The question asks If $f$ is an elliptic function with respect to some lattice $\Lambda$ and $z_1, \dotsc, z_k \in \Pi$ are the zeros and poles of $f$ (where $\Pi$ is a fundamental parallelogram) with degrees $d_1, \dotsc, d_k$, then $\sum_k d_k z_k \in \Lambda$.   ( Hint . Consider $\int_{\partial \Pi} z \frac{f'(z)}{f(z)} dz$). Say $\Lambda$ is spanned by $\omega_1$ and $\omega_2$.  I need to show that $\sum_k d_k z_k = n_1 \omega_1 + n_2 \omega_2$ for some $n_1, n_2 \in \mathbb{Z}$.  I am aware of the generalized argument principle, so that $$ \int_{\partial \Pi} z \frac{f'(z)}{f(z)} dz = 2 \pi i \left( \sum_{z_k \text{ zero}} n(\partial \Pi, z_k) z_k - \sum_{z_k \text{ pole}} n(\partial \Pi, z_k) z_k \right), $$ but I'm not sure how this helps me.  Any hints or suggestions would be welcomed!",,"['complex-analysis', 'elliptic-functions']"
75,What is the best way to supplement a complex variables class to make it more complete for a math major?,What is the best way to supplement a complex variables class to make it more complete for a math major?,,"For the upcoming semester I plan on a taking a “complex variables” course that many people, including myself, would not consider a true complex analysis class. I know that the course will likely use a text similar those by Saff & Snider or Brown & Churchill because it is more of a survey class meant to give the basics for leading into to true complex analysis classes and giving the appropriate tools for physicists and engineers. As someone interested in theoretical mathematics, I naturally want to expand my knowledge beyond what is taught, see a more rigorous presentation of the material, have applications leaning more toward number theory than physics, and see topological constructions in action. I know that Ahlfors’ Complex Analysis is the a very common text instructors and students turn to for what I am looking for, but it is very expensive ($200 USD + for a ~300 page text), and I have heard people describe it as “difficult” for independent study unless you really know what you’re doing beforehand. Is there a better text for me to follow? I see that MIT has its 18.112 course (Functions of a Complex Variable), an undergraduate level course based on Ahlfors , listed on OCW, so I would have something to follow and test myself on, but I would prefer to not use Ahlfors. I have seen recommendations to other people to use Visual Complex Analysis for self-study, but this book is still more directed at undergraduate physics students and the like. What are the best alternatives to a text like Ahlfors? Which are the best suited for independent study for someone working alongside a less mathematically rigorous course? Which are the more comprehensive? Are there any that follow naturally from where books like that by Brown & Church leave off? Which are the most comprehensive, and are there any that lead into analytic number theory or give a taste of complex analysis in several variables?","For the upcoming semester I plan on a taking a “complex variables” course that many people, including myself, would not consider a true complex analysis class. I know that the course will likely use a text similar those by Saff & Snider or Brown & Churchill because it is more of a survey class meant to give the basics for leading into to true complex analysis classes and giving the appropriate tools for physicists and engineers. As someone interested in theoretical mathematics, I naturally want to expand my knowledge beyond what is taught, see a more rigorous presentation of the material, have applications leaning more toward number theory than physics, and see topological constructions in action. I know that Ahlfors’ Complex Analysis is the a very common text instructors and students turn to for what I am looking for, but it is very expensive ($200 USD + for a ~300 page text), and I have heard people describe it as “difficult” for independent study unless you really know what you’re doing beforehand. Is there a better text for me to follow? I see that MIT has its 18.112 course (Functions of a Complex Variable), an undergraduate level course based on Ahlfors , listed on OCW, so I would have something to follow and test myself on, but I would prefer to not use Ahlfors. I have seen recommendations to other people to use Visual Complex Analysis for self-study, but this book is still more directed at undergraduate physics students and the like. What are the best alternatives to a text like Ahlfors? Which are the best suited for independent study for someone working alongside a less mathematically rigorous course? Which are the more comprehensive? Are there any that follow naturally from where books like that by Brown & Church leave off? Which are the most comprehensive, and are there any that lead into analytic number theory or give a taste of complex analysis in several variables?",,"['complex-analysis', 'analytic-number-theory']"
76,convergence of analytic functions,convergence of analytic functions,,"I am trying to prove analyticity of a limit and I am at this situation. I have a sequence of meromorphic functions $\{f_n\}$ and all of them have singularities at the same points. I have proved uniform convergence in an open disk around $0$, $U$. If I have pointwise convergence in an open set $V$, such that $U\subset V$, is this enough to get analyticity in $V$? If not what else do I need?","I am trying to prove analyticity of a limit and I am at this situation. I have a sequence of meromorphic functions $\{f_n\}$ and all of them have singularities at the same points. I have proved uniform convergence in an open disk around $0$, $U$. If I have pointwise convergence in an open set $V$, such that $U\subset V$, is this enough to get analyticity in $V$? If not what else do I need?",,['complex-analysis']
77,complex integral problem,complex integral problem,,"I have to evaluate this $$\int_{c} \dfrac {|z| e^{z} }{z^2}$$ where C is the circunference with radius 2. I have tried to apply the Cauchy formula but $|z|e^{z} $ is not holomorfic. I know the resut is$ 4 \pi i$ I have also tried to do it as a line int, but i dont manage anything","I have to evaluate this $$\int_{c} \dfrac {|z| e^{z} }{z^2}$$ where C is the circunference with radius 2. I have tried to apply the Cauchy formula but $|z|e^{z} $ is not holomorfic. I know the resut is$ 4 \pi i$ I have also tried to do it as a line int, but i dont manage anything",,"['calculus', 'complex-analysis', 'complex-numbers']"
78,Root of $f(z)$ inside $|z|<1$,Root of  inside,f(z) |z|<1,"Let $c\in\mathbb{R}$. A non-constant function $f(z)$ is holomorphic in $|z|<2$. Suppose $|f(z)|=c$ for all $|z|=1$. Show that  $f(z)$ must have a root in $|z|<1$. I'm thinking about the maximum principle, which says $f(z)$ cannot attain a maximum inside $|z|<1$. But that still doesn't yield a root. Also, Rouche's theorem might be applicable if there's another function $g(z)$ to be used.","Let $c\in\mathbb{R}$. A non-constant function $f(z)$ is holomorphic in $|z|<2$. Suppose $|f(z)|=c$ for all $|z|=1$. Show that  $f(z)$ must have a root in $|z|<1$. I'm thinking about the maximum principle, which says $f(z)$ cannot attain a maximum inside $|z|<1$. But that still doesn't yield a root. Also, Rouche's theorem might be applicable if there's another function $g(z)$ to be used.",,['complex-analysis']
79,Separating out zero factor from holomorphic function,Separating out zero factor from holomorphic function,,I encountered this line of argument. Suppose $z_k=k\pi$. We clearly have $\sin z_k=0$. Then we can write $\sin z=(z-z_k)(\cos(z_k)+g_k(z))$ where $g_k$ is holomorphic and $g_k(z_k)=0$. It seems the argument that's being used is like: Suppose we have $f(z)$ holomorphic and $f(a)=0$. Then we can write $f(z)=(z-a)(f'(a)+g(z))$ where $g(z)$ is holomorphic and $g(a)=0$. Why is this true?,I encountered this line of argument. Suppose $z_k=k\pi$. We clearly have $\sin z_k=0$. Then we can write $\sin z=(z-z_k)(\cos(z_k)+g_k(z))$ where $g_k$ is holomorphic and $g_k(z_k)=0$. It seems the argument that's being used is like: Suppose we have $f(z)$ holomorphic and $f(a)=0$. Then we can write $f(z)=(z-a)(f'(a)+g(z))$ where $g(z)$ is holomorphic and $g(a)=0$. Why is this true?,,['complex-analysis']
80,Integral of a disk automorphism,Integral of a disk automorphism,,Let $|\alpha|<1$ and $\psi_{\alpha}(z)=(\alpha-z)/(1-\bar\alpha z)$. I want to prove that $$\frac 1 {\pi} \int\int_{\mathbb{D}}|{\psi_{\alpha}}^{'}|dxdy = \frac{1-|\alpha|^2}{|\alpha|^2}\log\frac{1}{1-|\alpha|^2}$$ I calculated ${\psi_\alpha}^{'}(z)=(|\alpha|^2-1)/(1-\bar\alpha z)^2$. I substituted it and use $z=re^{i \theta}$ and need to integrate $1/|1-\bar\alpha re^{i \theta}|^2$ along circle of radius r (fixed). But how can I do this?,Let $|\alpha|<1$ and $\psi_{\alpha}(z)=(\alpha-z)/(1-\bar\alpha z)$. I want to prove that $$\frac 1 {\pi} \int\int_{\mathbb{D}}|{\psi_{\alpha}}^{'}|dxdy = \frac{1-|\alpha|^2}{|\alpha|^2}\log\frac{1}{1-|\alpha|^2}$$ I calculated ${\psi_\alpha}^{'}(z)=(|\alpha|^2-1)/(1-\bar\alpha z)^2$. I substituted it and use $z=re^{i \theta}$ and need to integrate $1/|1-\bar\alpha re^{i \theta}|^2$ along circle of radius r (fixed). But how can I do this?,,['complex-analysis']
81,Laurent series in all possible regions of convergence,Laurent series in all possible regions of convergence,,"Let $f=\frac{2}{z}-\frac{3}{z-2}+\frac{1}{z+4}$ . Find the Laurent series in all possible regions of convergence about z=0 and read the residuum. I am not sure if I have to consider all 3 regions (inside circle pf radius 2,  inside annulus  $2<r<4$  and ouside circle of radius 4). Can someone guide me on how to continue? Thank you!","Let $f=\frac{2}{z}-\frac{3}{z-2}+\frac{1}{z+4}$ . Find the Laurent series in all possible regions of convergence about z=0 and read the residuum. I am not sure if I have to consider all 3 regions (inside circle pf radius 2,  inside annulus  $2<r<4$  and ouside circle of radius 4). Can someone guide me on how to continue? Thank you!",,"['complex-analysis', 'laurent-series']"
82,Power rule derivative in complex,Power rule derivative in complex,,"Problem: Prove that if $f(z)= z^n$, then $f' (z)$ = $n z^{n-1} $ using the definition of the derivative.","Problem: Prove that if $f(z)= z^n$, then $f' (z)$ = $n z^{n-1} $ using the definition of the derivative.",,"['calculus', 'complex-analysis']"
83,was asked to find out the value of $f(\sqrt{2})$,was asked to find out the value of,f(\sqrt{2}),I was given $f(1+{\sqrt{2}i\over n})=-{2\over n^2}$ where $f$ analytic from $|z|<3\to\mathbb{C}$. and was asked to find out the value of $f(\sqrt{2})$ I defined $g(z)=f(1+z)-z^2$ and then got $f(1+z)=z^2$ by Identity Theorem and then just put $f(z)=(z-1)^2$ and then $f(\sqrt{2})=3-2\sqrt{2}$ am I right in every step?,I was given $f(1+{\sqrt{2}i\over n})=-{2\over n^2}$ where $f$ analytic from $|z|<3\to\mathbb{C}$. and was asked to find out the value of $f(\sqrt{2})$ I defined $g(z)=f(1+z)-z^2$ and then got $f(1+z)=z^2$ by Identity Theorem and then just put $f(z)=(z-1)^2$ and then $f(\sqrt{2})=3-2\sqrt{2}$ am I right in every step?,,['complex-analysis']
84,"""Close-to-analytic"", but ""not quite"", functions on the complex numbers.","""Close-to-analytic"", but ""not quite"", functions on the complex numbers.",,"I heard of a way by which one can say that a given complex function is ""close to analytic"", namely if its Wirtinger partial $\frac{\partial f}{\partial \bar{z}}$ is small, meaning it ""depends only a little bit on $\bar{z}$"". So one may consider a kind of complex function which is more general than analytic (here, I mean ""entire"") functions: namely where $\frac{\partial f}{\partial \bar{z}}$ is bounded, and the function is real-smooth everywhere. So my question is: can we get ""close-to-analytic"" ""bump function""-like objects this way? Namely, can we make a function with compact support in the complex plane, real-smooth, and whose $\frac{\partial f}{\partial \bar{z}}$ is close to, but not quite, zero, across the domain -- i.e. $\left| \frac{\partial f}{\partial \bar{z}} \right| < \epsilon$ for all $z$ in the domain and some real $\epsilon > 0$ which is sufficiently small? If no, what's the reason and proof? If yes, what happens as we reduce $\epsilon$ toward 0? What that last part means is, what is the behavior of a parameterized function (or function family) $f_\epsilon(z)$ with $\epsilon > 0$ where as a function of $z$ it meets the given criteria and its Wirtinger $\bar{z}$-partial is bounded by $\epsilon$, as $\epsilon \rightarrow 0$? My guess is the bump gets flatter (i.e. $\max |f_\epsilon(z)|$ gets smaller). Is this right, or always right? If the bump gets flatter, then does that imply the existence of a limiting amplitude for a given $\epsilon$? If so, what is it? What happens if one considers such a family for a fixed support set?","I heard of a way by which one can say that a given complex function is ""close to analytic"", namely if its Wirtinger partial $\frac{\partial f}{\partial \bar{z}}$ is small, meaning it ""depends only a little bit on $\bar{z}$"". So one may consider a kind of complex function which is more general than analytic (here, I mean ""entire"") functions: namely where $\frac{\partial f}{\partial \bar{z}}$ is bounded, and the function is real-smooth everywhere. So my question is: can we get ""close-to-analytic"" ""bump function""-like objects this way? Namely, can we make a function with compact support in the complex plane, real-smooth, and whose $\frac{\partial f}{\partial \bar{z}}$ is close to, but not quite, zero, across the domain -- i.e. $\left| \frac{\partial f}{\partial \bar{z}} \right| < \epsilon$ for all $z$ in the domain and some real $\epsilon > 0$ which is sufficiently small? If no, what's the reason and proof? If yes, what happens as we reduce $\epsilon$ toward 0? What that last part means is, what is the behavior of a parameterized function (or function family) $f_\epsilon(z)$ with $\epsilon > 0$ where as a function of $z$ it meets the given criteria and its Wirtinger $\bar{z}$-partial is bounded by $\epsilon$, as $\epsilon \rightarrow 0$? My guess is the bump gets flatter (i.e. $\max |f_\epsilon(z)|$ gets smaller). Is this right, or always right? If the bump gets flatter, then does that imply the existence of a limiting amplitude for a given $\epsilon$? If so, what is it? What happens if one considers such a family for a fixed support set?",,['complex-analysis']
85,Schwarz's lemma $\Rightarrow$ an analytic conformal map UHP$\to$UHP must be an FLT?,Schwarz's lemma  an analytic conformal map UHPUHP must be an FLT?,\Rightarrow \to,"I read a solution to a conformal mapping problem that made the claim, ""Schwarz's lemma implies that any analytic conformal map taking the upper half-plane to the upper half-plane must be a fractional linear transformation."" I had not heard this, and I wonder why this is true. If you don't care to write out the whole proof, could you perhaps provide me with a reference? Apologies if this is a repeat, I wasn't able to find this question on the site.","I read a solution to a conformal mapping problem that made the claim, ""Schwarz's lemma implies that any analytic conformal map taking the upper half-plane to the upper half-plane must be a fractional linear transformation."" I had not heard this, and I wonder why this is true. If you don't care to write out the whole proof, could you perhaps provide me with a reference? Apologies if this is a repeat, I wasn't able to find this question on the site.",,"['complex-analysis', 'reference-request']"
86,Does This Condition Characterize $e^z$?,Does This Condition Characterize ?,e^z,"The following is a question from a Complex Analysis qualifying exam I was studying from: Does there exist an entire function $f$, distinct from $e^z$, such that $f(0)=1$ and $f'(n)=f(n)$ for all $n\geq 1$? My instinct is that such a function should exist, although I have tried cooking one up and I have been unable to do so. I then decided my instinct may have been incorrect, so I tried proving $e^z$ is the only such function, but I have been unable to do so. The roadblock to one potential method: A common way to show two analytic functions are the same is showing they agree on a set in their domains with a limit point. If I could show any function $f$ and $e^z$ agreed on the positive integers, then they would agree with $\infty$ as the limit point (under the transformation $z\mapsto 1/z$, this is the same as saying the limit point is zero) but $e^z$ is not a function on $\mathbb{C}_{\infty}$ (i.e., $e^{1/z}$ has an essential singularity at $z=0$). Another method I haven't been able to make work: Showing the coefficients of their respective power series are equal.","The following is a question from a Complex Analysis qualifying exam I was studying from: Does there exist an entire function $f$, distinct from $e^z$, such that $f(0)=1$ and $f'(n)=f(n)$ for all $n\geq 1$? My instinct is that such a function should exist, although I have tried cooking one up and I have been unable to do so. I then decided my instinct may have been incorrect, so I tried proving $e^z$ is the only such function, but I have been unable to do so. The roadblock to one potential method: A common way to show two analytic functions are the same is showing they agree on a set in their domains with a limit point. If I could show any function $f$ and $e^z$ agreed on the positive integers, then they would agree with $\infty$ as the limit point (under the transformation $z\mapsto 1/z$, this is the same as saying the limit point is zero) but $e^z$ is not a function on $\mathbb{C}_{\infty}$ (i.e., $e^{1/z}$ has an essential singularity at $z=0$). Another method I haven't been able to make work: Showing the coefficients of their respective power series are equal.",,['complex-analysis']
87,question involving analycity of $f=u+iv$,question involving analycity of,f=u+iv,Let $f=u+iv:\mathbb C\to\mathbb C$ be analytic. Then is it true that $\dfrac{\delta^2 v}{\delta x^2}+\dfrac{\delta^2 v}{\delta y^2}=0?$,Let $f=u+iv:\mathbb C\to\mathbb C$ be analytic. Then is it true that $\dfrac{\delta^2 v}{\delta x^2}+\dfrac{\delta^2 v}{\delta y^2}=0?$,,"['complex-analysis', 'analyticity']"
88,"Trying to find more information about ""Darboux's method/theorem"" on coefficients of an analytic function","Trying to find more information about ""Darboux's method/theorem"" on coefficients of an analytic function",,"My supervisor briefly showed me a statement of something she called ""Darboux's theorem,"" but I am having trouble finding more information about it on the internet. Here is what I have written down (some details may be incorrect): Let function $R$ be analytic in a neighborhood about $z=0$ of radius $\rho$. Suppose it has exactly one singularity at distance $\rho$ from $z=0$ (not sure about this sentence). If $R$  can be written in the form $$R(z) = \left(1-\frac zp\right)^{-s} G(z) + H(z)$$ where $s \notin \{0, -1, -2,\ldots\}$, where $G$ and $H$ are analytic in neighborhoods about $z=0$ of radius larger than $\rho$, and $G(\rho)\ne 0$, then the coefficient of $z^n$ in the power expansion of $R(z)$ follows this asymptotic description $$[z^n] R(z) = \rho^{-n} n^{s-1} \frac{G(s)}{\Gamma(s)} \left(1 + O\left(\frac 1n\right)\right)$$ My guess is that it's called ""Darboux's method"" in English, but still I only have these two links ( here and here ), that don't have a statement that is exactly the above, although they seem close. Can anyone comment or help me find what I'm looking for? Also any corrections to what I've written above would be appreciated.","My supervisor briefly showed me a statement of something she called ""Darboux's theorem,"" but I am having trouble finding more information about it on the internet. Here is what I have written down (some details may be incorrect): Let function $R$ be analytic in a neighborhood about $z=0$ of radius $\rho$. Suppose it has exactly one singularity at distance $\rho$ from $z=0$ (not sure about this sentence). If $R$  can be written in the form $$R(z) = \left(1-\frac zp\right)^{-s} G(z) + H(z)$$ where $s \notin \{0, -1, -2,\ldots\}$, where $G$ and $H$ are analytic in neighborhoods about $z=0$ of radius larger than $\rho$, and $G(\rho)\ne 0$, then the coefficient of $z^n$ in the power expansion of $R(z)$ follows this asymptotic description $$[z^n] R(z) = \rho^{-n} n^{s-1} \frac{G(s)}{\Gamma(s)} \left(1 + O\left(\frac 1n\right)\right)$$ My guess is that it's called ""Darboux's method"" in English, but still I only have these two links ( here and here ), that don't have a statement that is exactly the above, although they seem close. Can anyone comment or help me find what I'm looking for? Also any corrections to what I've written above would be appreciated.",,"['complex-analysis', 'asymptotics', 'power-series', 'generating-functions', 'analyticity']"
89,Analytic extension for a a function defined in $\mathbb{N}$,Analytic extension for a a function defined in,\mathbb{N},"I would like to know if it is possible to extend analytically any function of the type $f:\mathbb{N} \to \mathbb{C}$ to all complex plane. If it isn't possible, what should I assume to do so? If Just an example: the function number of divisors of $n$. EDIT: Is it unique?","I would like to know if it is possible to extend analytically any function of the type $f:\mathbb{N} \to \mathbb{C}$ to all complex plane. If it isn't possible, what should I assume to do so? If Just an example: the function number of divisors of $n$. EDIT: Is it unique?",,"['complex-analysis', 'analyticity']"
90,Solving a transcendental equation consisting of a quadratic part and a part involving inverse Lambert W functions,Solving a transcendental equation consisting of a quadratic part and a part involving inverse Lambert W functions,,"Question statement I would like to solve the following equation in the two variables $x$ and $y$: \begin{gather} 0 = x^2 - a y^2 + i b [x y - W^{-1}(x)W^{-1}(y)] , \end{gather} where $a$ and $b$ are purely real parameters, and $W^{-1}(x)$ is the inverse Lambert W function of $x$. Domain constraints exist due to physicality: for all physical solutions $y$ is purely imaginary, and for some physical solution $x$ is purely imaginary. Answer attempt Put the above equation in the alternative form thus: \begin{gather} 0 = x^2 - a y^2 + i b x y (1 - e^x e^y) . \end{gather} Then, by inspection (separate terms into pairs), we have at least the solutions \begin{gather} \begin{aligned} \text{(i)}&\text{ } x = \sqrt{a} y \text{ and } y = \frac{2 i n \pi}{1 + \sqrt{a}} \text{, where } n \in \mathbb{Z} \text{,}\\ \text{(ii)}&\text{ } x = - \sqrt{a} y \text{ and } y = \frac{2 i n \pi}{1 - \sqrt{a}} \text{, where } n \in \mathbb{Z} \text{,}\\ \text{(iii)}&\text{ } x = - i b y \text{ and } y = \frac{\operatorname{Log}(- a / b^2)}{1 - i b} \text{, and}\\ \text{(iv)}&\text{ } x = - i \frac{a}{b} y \text{ and } y = \frac{\operatorname{Log}(- a / b^2)}{1 - i (a / b)} . \end{aligned} \end{gather} The method of this answer attempt is quite obviously not general; hence I post. I might ask more specifically: Can we prove that (i) to (iv) are the only solutions? and if not, is there a more elegant method that derives all solutions? Thanks I extend sincere thanks for any help.","Question statement I would like to solve the following equation in the two variables $x$ and $y$: \begin{gather} 0 = x^2 - a y^2 + i b [x y - W^{-1}(x)W^{-1}(y)] , \end{gather} where $a$ and $b$ are purely real parameters, and $W^{-1}(x)$ is the inverse Lambert W function of $x$. Domain constraints exist due to physicality: for all physical solutions $y$ is purely imaginary, and for some physical solution $x$ is purely imaginary. Answer attempt Put the above equation in the alternative form thus: \begin{gather} 0 = x^2 - a y^2 + i b x y (1 - e^x e^y) . \end{gather} Then, by inspection (separate terms into pairs), we have at least the solutions \begin{gather} \begin{aligned} \text{(i)}&\text{ } x = \sqrt{a} y \text{ and } y = \frac{2 i n \pi}{1 + \sqrt{a}} \text{, where } n \in \mathbb{Z} \text{,}\\ \text{(ii)}&\text{ } x = - \sqrt{a} y \text{ and } y = \frac{2 i n \pi}{1 - \sqrt{a}} \text{, where } n \in \mathbb{Z} \text{,}\\ \text{(iii)}&\text{ } x = - i b y \text{ and } y = \frac{\operatorname{Log}(- a / b^2)}{1 - i b} \text{, and}\\ \text{(iv)}&\text{ } x = - i \frac{a}{b} y \text{ and } y = \frac{\operatorname{Log}(- a / b^2)}{1 - i (a / b)} . \end{aligned} \end{gather} The method of this answer attempt is quite obviously not general; hence I post. I might ask more specifically: Can we prove that (i) to (iv) are the only solutions? and if not, is there a more elegant method that derives all solutions? Thanks I extend sincere thanks for any help.",,"['complex-analysis', 'logarithms', 'roots', 'exponential-function']"
91,Radius of convergence of the Bernoulli polynomial generating function power series.,Radius of convergence of the Bernoulli polynomial generating function power series.,,"The generating function of the Bernoulli Polynomials is: $$\frac{te^{xt}}{e^t-1}=\sum_{k=0}^\infty B_k(x)\frac{t^k}{k!}.$$ Would it be right to say that the radius of convergence of this power series is $2\pi$ ? I'm not sure since the power series above is in fact a double series: $$\sum_{k=0}^\infty\left(\sum_{j=0}^k {k\choose j}B_{k-j} x^j\right)\frac{t^k}{k!}.$$ What if I were to choose a fixed value for $x$? Would the radius be $2\pi$ then, even for the double power series?","The generating function of the Bernoulli Polynomials is: $$\frac{te^{xt}}{e^t-1}=\sum_{k=0}^\infty B_k(x)\frac{t^k}{k!}.$$ Would it be right to say that the radius of convergence of this power series is $2\pi$ ? I'm not sure since the power series above is in fact a double series: $$\sum_{k=0}^\infty\left(\sum_{j=0}^k {k\choose j}B_{k-j} x^j\right)\frac{t^k}{k!}.$$ What if I were to choose a fixed value for $x$? Would the radius be $2\pi$ then, even for the double power series?",,"['complex-analysis', 'analysis', 'bernoulli-numbers']"
92,measure of the image of the the unit open disc by a holomorphic map,measure of the image of the the unit open disc by a holomorphic map,,"I found the following interesting exercice in a textbook: Let $f$: $\Bbb E \to \mathbb{C}$ be a holomorphic and injective map ('Schlicht function'), where $\Bbb E=\{z \in \Bbb C:|z|<1\}$. $f(z)=\sum_{n=0}^{\infty} c_{n}z^n$. While it is clear to me that $f$ is a diffeomorphism from $\Bbb E$ to $f(\Bbb E)$ (which is open) the following is not clear: If $\sum_{n=0}^{\infty} n|c_{n}|^2<\infty$ then $f(\Bbb E)$ is measurable (as a Borel subset of $\mathbb{C}$) and $\lambda_{2}(f(\Bbb E))=\pi\cdot\sum_{n=1}^{\infty}n|c_{n}|^2$. ($\lambda_{2}$ for the Lebsegue measure on $\mathbb{C}$ ) If you could give me a hint to show the measurability of the set $f(\Bbb E)$. For the formula I use the transformation formula, I have not yet finished but it should work.","I found the following interesting exercice in a textbook: Let $f$: $\Bbb E \to \mathbb{C}$ be a holomorphic and injective map ('Schlicht function'), where $\Bbb E=\{z \in \Bbb C:|z|<1\}$. $f(z)=\sum_{n=0}^{\infty} c_{n}z^n$. While it is clear to me that $f$ is a diffeomorphism from $\Bbb E$ to $f(\Bbb E)$ (which is open) the following is not clear: If $\sum_{n=0}^{\infty} n|c_{n}|^2<\infty$ then $f(\Bbb E)$ is measurable (as a Borel subset of $\mathbb{C}$) and $\lambda_{2}(f(\Bbb E))=\pi\cdot\sum_{n=1}^{\infty}n|c_{n}|^2$. ($\lambda_{2}$ for the Lebsegue measure on $\mathbb{C}$ ) If you could give me a hint to show the measurability of the set $f(\Bbb E)$. For the formula I use the transformation formula, I have not yet finished but it should work.",,"['complex-analysis', 'measure-theory', 'lebesgue-integral']"
93,Use the Contour Integral to Show a Fourier Transformation,Use the Contour Integral to Show a Fourier Transformation,,"Well, this is a physics class problem, and I did not learn anything about the contour integral. But I wish to show that: Use the contour integration to show that the transformation of $$f(x)={{1}\over{x^2+a^2}}$$ is $$f(k)={\pi\over a}e^{-|k|a}.$$ Could anyone give me any hint about this? I can only get: $f(k)=\int_{-\infty}^{+\infty}e^{-ikx}{{1}\over{x^2+a^2}}dx$, but I have no idea how to move on to integrate this. Any help, please.","Well, this is a physics class problem, and I did not learn anything about the contour integral. But I wish to show that: Use the contour integration to show that the transformation of $$f(x)={{1}\over{x^2+a^2}}$$ is $$f(k)={\pi\over a}e^{-|k|a}.$$ Could anyone give me any hint about this? I can only get: $f(k)=\int_{-\infty}^{+\infty}e^{-ikx}{{1}\over{x^2+a^2}}dx$, but I have no idea how to move on to integrate this. Any help, please.",,['complex-analysis']
94,How to verify this equation $\prod_{j=1}^\infty{1+\exp(i2^{-j}\omega)\over2}={1-\exp(i\omega)\over i\omega}$?,How to verify this equation ?,\prod_{j=1}^\infty{1+\exp(i2^{-j}\omega)\over2}={1-\exp(i\omega)\over i\omega},"This equation comes from A Wavelet Tour of Signal Processing, 3rd Ed. page 288. $$\prod_{j=1}^\infty{1+\exp(i2^{-j}\omega)\over2}={1-\exp(i\omega)\over i\omega}$$ I don't think it is right because when $\omega\to0$, the RHS tends toward $-1$, but the LHS is $1$. I have checked the errata of this book and found nothing. Can anyone tell me if this equation is right? If it is, how to prove it? Thanks.","This equation comes from A Wavelet Tour of Signal Processing, 3rd Ed. page 288. $$\prod_{j=1}^\infty{1+\exp(i2^{-j}\omega)\over2}={1-\exp(i\omega)\over i\omega}$$ I don't think it is right because when $\omega\to0$, the RHS tends toward $-1$, but the LHS is $1$. I have checked the errata of this book and found nothing. Can anyone tell me if this equation is right? If it is, how to prove it? Thanks.",,"['complex-analysis', 'infinite-product']"
95,Cauchy's Residue Theorem,Cauchy's Residue Theorem,,"I need to evaluate $\int_C \frac{5z-2}{z(z-1)}dz$ where $C$ is the circle $|z|$=2. I used partial fraction decomposition to get $$\frac{5z-2}{z(z-1)}=\frac{2}{z}+\frac{3}{z-1}$$ I have the answer ($10\pi i$) in my book but I don't fully understand how to get it. I think I have to evaluate in the two domains $0<|z|<1$ and $0<|z-1|<1$, is it because the singularities are at $z=0$ and $z=1$? I ask mainly because of the $|z-1|$ in the second inequality.","I need to evaluate $\int_C \frac{5z-2}{z(z-1)}dz$ where $C$ is the circle $|z|$=2. I used partial fraction decomposition to get $$\frac{5z-2}{z(z-1)}=\frac{2}{z}+\frac{3}{z-1}$$ I have the answer ($10\pi i$) in my book but I don't fully understand how to get it. I think I have to evaluate in the two domains $0<|z|<1$ and $0<|z-1|<1$, is it because the singularities are at $z=0$ and $z=1$? I ask mainly because of the $|z-1|$ in the second inequality.",,['complex-analysis']
96,Bound for analytic function from unit disk into punctured unit disk,Bound for analytic function from unit disk into punctured unit disk,,Suppose $f$ is analytic in the unit disk $D$ and satisfies $0<|f(z)|<1$. Show that $|f(z)|\leq|f(0)|^{\frac{1-|z|}{1+|z|}}$ for all $z\in D$. I tried to work with $\log|f|$. It seems that $\log|f|$ is harmonic but I couldn't get estimates.,Suppose $f$ is analytic in the unit disk $D$ and satisfies $0<|f(z)|<1$. Show that $|f(z)|\leq|f(0)|^{\frac{1-|z|}{1+|z|}}$ for all $z\in D$. I tried to work with $\log|f|$. It seems that $\log|f|$ is harmonic but I couldn't get estimates.,,"['complex-analysis', 'harmonic-functions', 'analyticity']"
97,A improper integral with complex parameter,A improper integral with complex parameter,,"For a complex number $\displaystyle z$, How to evaluate $$\int_0^\infty\frac{\text{d}x}{x^2+(1-z^2x^2)^2}$$","For a complex number $\displaystyle z$, How to evaluate $$\int_0^\infty\frac{\text{d}x}{x^2+(1-z^2x^2)^2}$$",,"['calculus', 'complex-analysis', 'integration']"
98,$\int_0^{\infty} \frac{\sin(x)}{ \sqrt{x}}dx$ [duplicate],[duplicate],\int_0^{\infty} \frac{\sin(x)}{ \sqrt{x}}dx,"This question already has answers here : Proof of $\int_0^\infty \frac{\sin x}{\sqrt{x}}dx=\sqrt{\frac{\pi}{2}}$ (8 answers) Closed 9 years ago . I want to know how to solve this using contour integration: $$\int_0^{\infty} \frac{\sin(x)}{\sqrt{x}}dx.$$ So I let the integral become: $$\oint_c \frac{\sin(z)}{\sqrt{z}}dz$$ where c is a ""half doughnut"" shape avoiding the singularity at z = 0 and extending into the upper half of the complex plane towards infinity. $$\oint_c = \int_{up} + \int_{-R}^{- \epsilon} + \int_{low} + \int_ {\epsilon}^R = 0$$  (Because no singularities are actually contained within the contour.) By a bound argument, the $\int_{up}$ contributes nothing to the integral. Therefore: $$\lim{R \to \infty}, {\epsilon \to 0}$$ $$- \int_{low} = \int_{- \infty}^{\infty} $$ Where $\int_{low}$ is the integral over the bump going over the point z = 0. So can I use the Cauchy Integral theorem to say $$\int_{low} = \pi i\, \text{Res} \left( \frac{\sin x}{ \sqrt{x}}, 0 \right)$$ Because there is no residue for this function, which would imply the integral is zero, which I know it is actually $\sqrt \frac{ \pi}{2}$.","This question already has answers here : Proof of $\int_0^\infty \frac{\sin x}{\sqrt{x}}dx=\sqrt{\frac{\pi}{2}}$ (8 answers) Closed 9 years ago . I want to know how to solve this using contour integration: $$\int_0^{\infty} \frac{\sin(x)}{\sqrt{x}}dx.$$ So I let the integral become: $$\oint_c \frac{\sin(z)}{\sqrt{z}}dz$$ where c is a ""half doughnut"" shape avoiding the singularity at z = 0 and extending into the upper half of the complex plane towards infinity. $$\oint_c = \int_{up} + \int_{-R}^{- \epsilon} + \int_{low} + \int_ {\epsilon}^R = 0$$  (Because no singularities are actually contained within the contour.) By a bound argument, the $\int_{up}$ contributes nothing to the integral. Therefore: $$\lim{R \to \infty}, {\epsilon \to 0}$$ $$- \int_{low} = \int_{- \infty}^{\infty} $$ Where $\int_{low}$ is the integral over the bump going over the point z = 0. So can I use the Cauchy Integral theorem to say $$\int_{low} = \pi i\, \text{Res} \left( \frac{\sin x}{ \sqrt{x}}, 0 \right)$$ Because there is no residue for this function, which would imply the integral is zero, which I know it is actually $\sqrt \frac{ \pi}{2}$.",,"['complex-analysis', 'integration']"
99,Automorphisms on Punctured Disc,Automorphisms on Punctured Disc,,"I have to find the automorphism group of the punctured unit disc $D = \{|z| <1\}\setminus \{0\}$. I understand that if $f$ is an automorphism on $D$, then it will have either a (i) removable singularity or (ii) a pole of order 1 at $z=0$. If it has a removable singularity at 0, then $f$ is a rotation. I am stuck at case (ii). Also, using this result, later I also have to find the automorphism group of $\{|z|<1\}\setminus \{1/2\}$ Can anybody please help ?","I have to find the automorphism group of the punctured unit disc $D = \{|z| <1\}\setminus \{0\}$. I understand that if $f$ is an automorphism on $D$, then it will have either a (i) removable singularity or (ii) a pole of order 1 at $z=0$. If it has a removable singularity at 0, then $f$ is a rotation. I am stuck at case (ii). Also, using this result, later I also have to find the automorphism group of $\{|z|<1\}\setminus \{1/2\}$ Can anybody please help ?",,['complex-analysis']
