,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Solve limit using the concept of equivalent functions,Solve limit using the concept of equivalent functions,,"How to solve this limit $$\lim_{x\rightarrow 0}{\frac{(2+x)^x-2^x}{x^2}}$$ using the concept of equivalent functions? For example, if $x\rightarrow 0 $ function $\sin x$ is equivalent to $x$, $\ln(1+x)\sim x$,  $a^x-1 \sim x \ln a$, etc.","How to solve this limit $$\lim_{x\rightarrow 0}{\frac{(2+x)^x-2^x}{x^2}}$$ using the concept of equivalent functions? For example, if $x\rightarrow 0 $ function $\sin x$ is equivalent to $x$, $\ln(1+x)\sim x$,  $a^x-1 \sim x \ln a$, etc.",,['limits']
1,How to solve this limit $\lim_{n\to\infty} ((\frac{1}{\sqrt{n^2+1}}) + \cdots + (\frac{1}{\sqrt{n^2+n}}))$,How to solve this limit,\lim_{n\to\infty} ((\frac{1}{\sqrt{n^2+1}}) + \cdots + (\frac{1}{\sqrt{n^2+n}})),"How do I solve this limit $$\lim_{n\to\infty} \left(\frac{1}{\sqrt{n^2+1}} + \cdots + \frac{1}{\sqrt{n^2+n}}\right)\text{ ?}$$ (n goes to plus infinity.) I tried putting in $n=1,2,3,4,\ldots$ to find some pattern but it's hard to see where it's going. For example, $n=1$, limit is $\dfrac{1}{\sqrt{2}}$ For example, $n=2$, limit is $\dfrac{1}{\sqrt{2}} + \dfrac{1}{\sqrt{6}}$ For example, $n=3$, limit is $\dfrac{1}{\sqrt{2}} + \dfrac{1}{\sqrt{6}} + \dfrac{1}{\sqrt{12}}$ For example, $n=4$, limit is $\dfrac{1}{\sqrt{2}} + \dfrac{1}{\sqrt{6}} + \dfrac{1}{\sqrt{12}} + \dfrac{1}{\sqrt{20}}$ I'm not exactly sure what this limit is converging to...","How do I solve this limit $$\lim_{n\to\infty} \left(\frac{1}{\sqrt{n^2+1}} + \cdots + \frac{1}{\sqrt{n^2+n}}\right)\text{ ?}$$ (n goes to plus infinity.) I tried putting in $n=1,2,3,4,\ldots$ to find some pattern but it's hard to see where it's going. For example, $n=1$, limit is $\dfrac{1}{\sqrt{2}}$ For example, $n=2$, limit is $\dfrac{1}{\sqrt{2}} + \dfrac{1}{\sqrt{6}}$ For example, $n=3$, limit is $\dfrac{1}{\sqrt{2}} + \dfrac{1}{\sqrt{6}} + \dfrac{1}{\sqrt{12}}$ For example, $n=4$, limit is $\dfrac{1}{\sqrt{2}} + \dfrac{1}{\sqrt{6}} + \dfrac{1}{\sqrt{12}} + \dfrac{1}{\sqrt{20}}$ I'm not exactly sure what this limit is converging to...",,['limits']
2,Limit $\lim_{{x\rightarrow 0}}{\left(\frac{\frac{1}{\sqrt{1+x}}-1}{x}\right)}$,Limit,\lim_{{x\rightarrow 0}}{\left(\frac{\frac{1}{\sqrt{1+x}}-1}{x}\right)},"I am a high school student in Calculus, and we are finishing learning basic limits. I am reviewing for a big test tomorrow, and I could do all of the problems correctly except this one. I have no idea how to solve the problem this problem correctly. I looked up the answer online, but I can't figure out how they got their answer. All of the online tools show the steps using L'Hospital's rule or derivation, but I haven't learned either yet. This is the problem: $$\large\lim_{x\rightarrow 0}{\left(\frac{\frac{1}{\sqrt{1+x}}-1}{x}\right)}$$ This is the problem that I did incorrectly. I converted the $-1$ to $\frac{\sqrt{1+x}}{\sqrt{1+x}}$, then subtracted the fraction, and multiplied the result by $\frac{1}{x}$ to remove the double division. $$\large\frac{1-\sqrt{1+x}}{x\sqrt{1+x}}$$ When I substitute $x$, I get $0$, but the answer is $-\frac{1}{2}$. I am doing something simple incorrectly, but I really cannot figure it out.","I am a high school student in Calculus, and we are finishing learning basic limits. I am reviewing for a big test tomorrow, and I could do all of the problems correctly except this one. I have no idea how to solve the problem this problem correctly. I looked up the answer online, but I can't figure out how they got their answer. All of the online tools show the steps using L'Hospital's rule or derivation, but I haven't learned either yet. This is the problem: $$\large\lim_{x\rightarrow 0}{\left(\frac{\frac{1}{\sqrt{1+x}}-1}{x}\right)}$$ This is the problem that I did incorrectly. I converted the $-1$ to $\frac{\sqrt{1+x}}{\sqrt{1+x}}$, then subtracted the fraction, and multiplied the result by $\frac{1}{x}$ to remove the double division. $$\large\frac{1-\sqrt{1+x}}{x\sqrt{1+x}}$$ When I substitute $x$, I get $0$, but the answer is $-\frac{1}{2}$. I am doing something simple incorrectly, but I really cannot figure it out.",,"['calculus', 'limits', 'rational-functions']"
3,How do I find $\lim\limits_{x \to 0} x\cot(6x) $ without using L'Hôpital's rule?,How do I find  without using L'Hôpital's rule?,\lim\limits_{x \to 0} x\cot(6x) ,"How do I find $\lim\limits_{x \to 0} x\cot(6x) $ without using L'Hôpital's rule? I'm a freshman in college in the 3rd week of a calculus 1 class. I know the $\lim\limits_{x \to 0} x\cot(6x) = \frac{1}{6}$ by looking at the graph, but I'm not sure how to get here without using L'Hôpital's rule. Here is how I solved it (and got the wrong answer). Hopefully someone could tell me where I went wrong. $$\lim\limits_{x \to 0} x\cot(6x) = (\lim\limits_{x \to 0} x) (\lim\limits_{x \to 0}\cot(6x)) = (0)\left(\lim\limits_{x \to 0}\frac{\cos(6x)}{\sin(6x)}\right) = (0)(\frac{1}{0}).$$ Therefore the limit does not exist. I am also unsure of how to solve $\lim\limits_{x \to 0} \frac{\sin(5x)}{7x^2} $ without using L'Hôpital's rule.","How do I find without using L'Hôpital's rule? I'm a freshman in college in the 3rd week of a calculus 1 class. I know the by looking at the graph, but I'm not sure how to get here without using L'Hôpital's rule. Here is how I solved it (and got the wrong answer). Hopefully someone could tell me where I went wrong. Therefore the limit does not exist. I am also unsure of how to solve without using L'Hôpital's rule.",\lim\limits_{x \to 0} x\cot(6x)  \lim\limits_{x \to 0} x\cot(6x) = \frac{1}{6} \lim\limits_{x \to 0} x\cot(6x) = (\lim\limits_{x \to 0} x) (\lim\limits_{x \to 0}\cot(6x)) = (0)\left(\lim\limits_{x \to 0}\frac{\cos(6x)}{\sin(6x)}\right) = (0)(\frac{1}{0}). \lim\limits_{x \to 0} \frac{\sin(5x)}{7x^2} ,"['calculus', 'limits', 'limits-without-lhopital']"
4,Evaluating the limit of a function,Evaluating the limit of a function,,"I just solved the following limit, to which the answer is $0$ to me, but I couldn't help but make use of L'Hôpital's Rule. $$\lim_{x \to \infty} \left(x^2 - x \log(1+\mathrm{e}^x)\right)$$ Can someone suggest an approach that doesn't involve L'Hôpital's Rule?","I just solved the following limit, to which the answer is $0$ to me, but I couldn't help but make use of L'Hôpital's Rule. $$\lim_{x \to \infty} \left(x^2 - x \log(1+\mathrm{e}^x)\right)$$ Can someone suggest an approach that doesn't involve L'Hôpital's Rule?",,"['calculus', 'limits']"
5,Find the limit of $\prod_{k = 4}^{\infty}\cos\left(\pi \over k\right)$,Find the limit of,\prod_{k = 4}^{\infty}\cos\left(\pi \over k\right),"Find the limit of  $$\prod_{k = 4}^{\infty}\cos\left(\pi \over k\right)$$ The limit does exist, but I can not get it. Thanks Willie-Wong &  Lee Mosher for correcting the expression.","Find the limit of  $$\prod_{k = 4}^{\infty}\cos\left(\pi \over k\right)$$ The limit does exist, but I can not get it. Thanks Willie-Wong &  Lee Mosher for correcting the expression.",,"['calculus', 'limits', 'infinite-product', 'trigonometric-series']"
6,"lim cos(1/θ) = 0, when θ → 0. Why?","lim cos(1/θ) = 0, when θ → 0. Why?",,"Let $f(x)=x^2\sin\left(\frac{1}{x}\right)$ for $x\ne0$ and $f(0)=0$. => If we use Lagrange's theorem: $\exists \theta \in (0;x)$ and $f(x) - f(0) = f′(\theta)(x-0)$ => $$x^2\sin\left(\frac{1}{x}\right) - 0 = \left(2x\sin\left(\frac{1}{\theta}\right) - \cos\left(\frac{1}{\theta}\right)\right)(x - 0)$$ => Because $x>0$, we can divide both parts of equality on it => $$x\sin\left(\frac{1}{x}\right) = 2x\sin\left(\frac{1}{\theta}\right) - \cos\left(\frac{1}{\theta}\right)$$ Also notice: if $x \to 0$, than obviously $\theta \to 0$ => $$\lim_{x\to 0}\sin\left(\frac{1}{x}\right) = \lim_{x\to 0}2x\sin\left(\frac{1}{\theta}\right) - \cos\left(\frac{1}{\theta}\right)$$ => $$0 = 0 - \lim_{x\to 0}\cos\left(\frac{1}{\theta}\right)$$ => $$\lim_{\theta \to 0}\cos\left(\frac{1}{\theta}\right) = 0$$ Why?","Let $f(x)=x^2\sin\left(\frac{1}{x}\right)$ for $x\ne0$ and $f(0)=0$. => If we use Lagrange's theorem: $\exists \theta \in (0;x)$ and $f(x) - f(0) = f′(\theta)(x-0)$ => $$x^2\sin\left(\frac{1}{x}\right) - 0 = \left(2x\sin\left(\frac{1}{\theta}\right) - \cos\left(\frac{1}{\theta}\right)\right)(x - 0)$$ => Because $x>0$, we can divide both parts of equality on it => $$x\sin\left(\frac{1}{x}\right) = 2x\sin\left(\frac{1}{\theta}\right) - \cos\left(\frac{1}{\theta}\right)$$ Also notice: if $x \to 0$, than obviously $\theta \to 0$ => $$\lim_{x\to 0}\sin\left(\frac{1}{x}\right) = \lim_{x\to 0}2x\sin\left(\frac{1}{\theta}\right) - \cos\left(\frac{1}{\theta}\right)$$ => $$0 = 0 - \lim_{x\to 0}\cos\left(\frac{1}{\theta}\right)$$ => $$\lim_{\theta \to 0}\cos\left(\frac{1}{\theta}\right) = 0$$ Why?",,"['analysis', 'limits']"
7,"$ \lim\limits_{x \to +\infty}x\, e^{-x^2}\int_{0}^{x}e^{t^2}dt $",," \lim\limits_{x \to +\infty}x\, e^{-x^2}\int_{0}^{x}e^{t^2}dt ","Hello every one Please I need your help for the 3rd question, I tried but i fail every time. for every real $ x $, we put $ f(x)=e^{-x^2}\int_{0}^{x}e^{t^2}dt $. Show that $ f $ is odd of class $ C^{\infty} $ on $ \mathbb{R} $. Show that $ f $ is a solution of the functional equation $ y'+2xy=1$. Prove that $ \lim\limits_{x \to +\infty}2xf(x)=1 $. thanks.","Hello every one Please I need your help for the 3rd question, I tried but i fail every time. for every real $ x $, we put $ f(x)=e^{-x^2}\int_{0}^{x}e^{t^2}dt $. Show that $ f $ is odd of class $ C^{\infty} $ on $ \mathbb{R} $. Show that $ f $ is a solution of the functional equation $ y'+2xy=1$. Prove that $ \lim\limits_{x \to +\infty}2xf(x)=1 $. thanks.",,"['real-analysis', 'integration', 'limits']"
8,What is $\lim_{n \to \infty} \sum_{x=0}^{n-1} \frac{n-x}{n+x}$?,What is ?,\lim_{n \to \infty} \sum_{x=0}^{n-1} \frac{n-x}{n+x},"These are two little questions that came to mind while I was looking at this problem . What is $\displaystyle \lim_{n \to \infty} \sum_{x=0}^{n-1} \frac{n-x}{n+x}$? I am fairly certain that the answer is $\infty$ because as $n$ gets closer to $\infty$ there are more terms that are very close to $1$ (if $n = 1,000,000$ then all the terms until $x = 5026$ are greater than or equal to $0.99$, and if $n = 1,000,000,000$ then you have to get to $x = 5025126$ for the terms to drop below $0.99$), but I don't know how to prove it. I also checked the partial differences (i.e. between $n = 1$ and $n = 2$, between $n = 2$ and $n = 3$, and so forth) and noticed that they all tend to some number around $0.386294$. Is there a name for this number, and what's its significance? WolframAlpha seems to suggest it has something to do with the Digamma function but I'm not sure what it's all about.","These are two little questions that came to mind while I was looking at this problem . What is $\displaystyle \lim_{n \to \infty} \sum_{x=0}^{n-1} \frac{n-x}{n+x}$? I am fairly certain that the answer is $\infty$ because as $n$ gets closer to $\infty$ there are more terms that are very close to $1$ (if $n = 1,000,000$ then all the terms until $x = 5026$ are greater than or equal to $0.99$, and if $n = 1,000,000,000$ then you have to get to $x = 5025126$ for the terms to drop below $0.99$), but I don't know how to prove it. I also checked the partial differences (i.e. between $n = 1$ and $n = 2$, between $n = 2$ and $n = 3$, and so forth) and noticed that they all tend to some number around $0.386294$. Is there a name for this number, and what's its significance? WolframAlpha seems to suggest it has something to do with the Digamma function but I'm not sure what it's all about.",,"['limits', 'summation', 'fractions']"
9,Limit of $\sqrt[x]{\frac{\tan x}{x}}$ as $x \to 0$,Limit of  as,\sqrt[x]{\frac{\tan x}{x}} x \to 0,I am trying to calculate the Limit $$\lim_{x \to 0} \sqrt[x]{\frac{\tan x}{x}}$$ Wolfram Alpha says it's $1$ . But I get $$\lim_{x \to 0} \sqrt[x]{\frac{\tan x}{x}}$$ $$= \exp \lim_{x \to 0} \ln \left(\left(\frac{\tan x}{x}\right)^{1/x}\right)$$ $$= \exp \lim_{x \to 0} \frac{\ln(\tan(x)) - \ln(x)}{x}$$ Using L'Hospital: $$= \exp \lim_{x \to 0} \frac{\frac{1}{\tan(x)\cos^2(x)} - \frac{1}{x}}{1}$$ $$= \exp \lim_{x \to 0} \frac{1}{\sin(x)\cos(x)} - \frac{1}{x}$$ $$= \exp \lim_{x \to 0} \frac{1}{\sin(2x)} - \frac{1}{x}$$ $$= \exp \lim_{x \to 0} \frac{x - \sin(2x)}{\sin(2x) x}$$ But when I calculate $$\lim_{x \to 0} \frac{x - \sin(2x)}{\sin(2x) x}$$ with Wolfram Alpha I get $\pm \infty$ . So the limit of $\lim_{x \to 0} \sqrt[x]{\frac{\tan x}{x}}$ should be $e^{\pm \infty} = 0 \text{ or } \infty \neq 1$. Which is both wrong. Where is my mistake?,I am trying to calculate the Limit $$\lim_{x \to 0} \sqrt[x]{\frac{\tan x}{x}}$$ Wolfram Alpha says it's $1$ . But I get $$\lim_{x \to 0} \sqrt[x]{\frac{\tan x}{x}}$$ $$= \exp \lim_{x \to 0} \ln \left(\left(\frac{\tan x}{x}\right)^{1/x}\right)$$ $$= \exp \lim_{x \to 0} \frac{\ln(\tan(x)) - \ln(x)}{x}$$ Using L'Hospital: $$= \exp \lim_{x \to 0} \frac{\frac{1}{\tan(x)\cos^2(x)} - \frac{1}{x}}{1}$$ $$= \exp \lim_{x \to 0} \frac{1}{\sin(x)\cos(x)} - \frac{1}{x}$$ $$= \exp \lim_{x \to 0} \frac{1}{\sin(2x)} - \frac{1}{x}$$ $$= \exp \lim_{x \to 0} \frac{x - \sin(2x)}{\sin(2x) x}$$ But when I calculate $$\lim_{x \to 0} \frac{x - \sin(2x)}{\sin(2x) x}$$ with Wolfram Alpha I get $\pm \infty$ . So the limit of $\lim_{x \to 0} \sqrt[x]{\frac{\tan x}{x}}$ should be $e^{\pm \infty} = 0 \text{ or } \infty \neq 1$. Which is both wrong. Where is my mistake?,,['limits']
10,"Give an example where $\lim_{x\to a}f(x)=b$, $\lim_{x\to b}g(x)=c$ but $\lim_{x\to a}g(f(x))\neq c$.","Give an example where ,  but .",\lim_{x\to a}f(x)=b \lim_{x\to b}g(x)=c \lim_{x\to a}g(f(x))\neq c,"Give an example where $\lim_{x\to a}f(x)=b$, $\lim_{x\to b}g(x)=c$ but $\lim_{x\to a}g(f(x))\neq c$. I got pretty stuck on this one. I thought maybe I can define the function $f(x)$ to only produce rational numbers like $f(x)=\left \lceil{x}\right \rceil $ which is basically a staircase function. Then $\lim\limits_{x \to a}=\left \lceil{a}\right \rceil $. And then I wanted to define some second function $g$ such that it doesn't take rational inputs. However this doesnt work because then the limit $\lim\limits_{x \to b}g(x)$ does not exist for any $b \in \mathbb R$. In short, my attempt failed miserably. Then for any continuous function $f$ I am pretty sure that it doesn't work. If anyone could help me on my way that would be great. Thanks in advance!","Give an example where $\lim_{x\to a}f(x)=b$, $\lim_{x\to b}g(x)=c$ but $\lim_{x\to a}g(f(x))\neq c$. I got pretty stuck on this one. I thought maybe I can define the function $f(x)$ to only produce rational numbers like $f(x)=\left \lceil{x}\right \rceil $ which is basically a staircase function. Then $\lim\limits_{x \to a}=\left \lceil{a}\right \rceil $. And then I wanted to define some second function $g$ such that it doesn't take rational inputs. However this doesnt work because then the limit $\lim\limits_{x \to b}g(x)$ does not exist for any $b \in \mathbb R$. In short, my attempt failed miserably. Then for any continuous function $f$ I am pretty sure that it doesn't work. If anyone could help me on my way that would be great. Thanks in advance!",,"['real-analysis', 'limits']"
11,Limit of Sequence n/(n+1),Limit of Sequence n/(n+1),,"One of my homework problems asks, ""Are the terms of the sequence n/(n+1) also getting closer and closer to π?"" I'm confused because I thought that the limit was 1... Please help!","One of my homework problems asks, ""Are the terms of the sequence n/(n+1) also getting closer and closer to π?"" I'm confused because I thought that the limit was 1... Please help!",,['limits']
12,How many paths would confirm the existence of limit of a two variable function?,How many paths would confirm the existence of limit of a two variable function?,,"My question is : Suppose we know that $\lim_{(x,y) \to (a,b)}f(x,y)$ exists in infinitely many paths for a function $f : \mathbb{R}^2\rightarrow \mathbb{R}$ then can we say that limit exists and it can be obtained from choosing any path. May be i should have been more careful when saying so... Actual question is to evaluate $\lim_{(x,y) \to (0,0)} \dfrac{x^3y}{x^4+y^2}$ First thing one would do is to check for ""Non existence"" by which i mean trying out some paths hoping that limit in those two paths would differ and then conclude that limit does not exist. But then what if the limit in more than one path coincide.. In this situation i would take $y=mx$ then : $$\dfrac{x^3y}{x^4+y^2}=\dfrac{mx^4}{x^4+m^2x^2}\rightarrow 0 \text { as x $\rightarrow$ 0}$$ We realize that irrespective of $m$ we would end up with $\lim_{(x,y) \to (0,0)} \dfrac{x^3y}{x^4+y^2}=0$ along the path $y=mx$. I am sure with this we can not say that limit exists... so, how many paths (I have checked uncountably many as my $m\in \mathbb{R}$) should i check to confirm the existence. There might be some other ways to calculate the limit by some squeeze principle or some but then Is there any thing that if you verify that limit coincide in this many paths then you can conclude limit exist. P.S : My question is not about evaluating the limit but actually Existence of limit knowing its value in some paths... so please do not answer with keeping in mind  the word ""Evaluate"" Thank you :)","My question is : Suppose we know that $\lim_{(x,y) \to (a,b)}f(x,y)$ exists in infinitely many paths for a function $f : \mathbb{R}^2\rightarrow \mathbb{R}$ then can we say that limit exists and it can be obtained from choosing any path. May be i should have been more careful when saying so... Actual question is to evaluate $\lim_{(x,y) \to (0,0)} \dfrac{x^3y}{x^4+y^2}$ First thing one would do is to check for ""Non existence"" by which i mean trying out some paths hoping that limit in those two paths would differ and then conclude that limit does not exist. But then what if the limit in more than one path coincide.. In this situation i would take $y=mx$ then : $$\dfrac{x^3y}{x^4+y^2}=\dfrac{mx^4}{x^4+m^2x^2}\rightarrow 0 \text { as x $\rightarrow$ 0}$$ We realize that irrespective of $m$ we would end up with $\lim_{(x,y) \to (0,0)} \dfrac{x^3y}{x^4+y^2}=0$ along the path $y=mx$. I am sure with this we can not say that limit exists... so, how many paths (I have checked uncountably many as my $m\in \mathbb{R}$) should i check to confirm the existence. There might be some other ways to calculate the limit by some squeeze principle or some but then Is there any thing that if you verify that limit coincide in this many paths then you can conclude limit exist. P.S : My question is not about evaluating the limit but actually Existence of limit knowing its value in some paths... so please do not answer with keeping in mind  the word ""Evaluate"" Thank you :)",,['real-analysis']
13,Help with limit calculation,Help with limit calculation,,Can anyone help me with this limit please: I have been trying to solve this for 2 hours with no success: $$\lim_{n\to \infty } \frac {1^3+4^3+7^3+...+(3n-2)^3}{[1+4+7+...+(3n-2)]^2}$$,Can anyone help me with this limit please: I have been trying to solve this for 2 hours with no success: $$\lim_{n\to \infty } \frac {1^3+4^3+7^3+...+(3n-2)^3}{[1+4+7+...+(3n-2)]^2}$$,,['limits']
14,Evaluation of $ \displaystyle \lim_{x \to 0} \frac{\sin ( \pi \cos(x) )}{x \sin x}$ using a Taylor Approximation,Evaluation of  using a Taylor Approximation, \displaystyle \lim_{x \to 0} \frac{\sin ( \pi \cos(x) )}{x \sin x},"Compute the limit: $$ \displaystyle \lim_{x \to 0} \frac{\sin ( \pi \cos(x) )}{x \sin (x)}$$   using a Taylor approximation It seems very intuitive for me to use a Taylor Approximation for this kind of a problem, since the values of $x$ get arbitrary small. My Approach (wrong): $$\cos (x)= 1 - \frac{x^2}{2}+O(x^4) \implies \pi \cos (x)= \pi - \frac{\pi x^2}{2}+ \dots  \\ \sin (x) = x - \frac{x^3}{6}+O(x^6)$$ My problem now is to compute $\sin ( \pi \cos (x)) $. One of my tutors once told me for small values of $x$ I can always use $\sin (x) \sim x$, so I thought that the following must be true as well for small values of $x$: $$\sin (\pi \cos (x))= \sin\left(\pi - \frac{\pi x^2}{2}+ \dots \right) \sim \pi - \frac{\pi x^2}{2}+ \dots$$ Which is indeed very wrong, the correct answer is: $$\sin (\pi \cos (x))\sim \frac{\pi x^2}{2}\pm O(x^4)$$ While it seems clear to me that my answer cannot be true, (I did it by naively plugging in the values and obtained the same result as I already had for $\pi \cos (x)$) , I don't see how the above result is obtained. Could somebody show me how to correctly process in that manner? Note : In class we were not yet introduced to the $O$-Notation. In the book by C.T. Michaels he simply uses dots for the higher terms and says that they can be neglected. I tried to include the $O$-Notation in my question, but only with my intuitive understanding of it.","Compute the limit: $$ \displaystyle \lim_{x \to 0} \frac{\sin ( \pi \cos(x) )}{x \sin (x)}$$   using a Taylor approximation It seems very intuitive for me to use a Taylor Approximation for this kind of a problem, since the values of $x$ get arbitrary small. My Approach (wrong): $$\cos (x)= 1 - \frac{x^2}{2}+O(x^4) \implies \pi \cos (x)= \pi - \frac{\pi x^2}{2}+ \dots  \\ \sin (x) = x - \frac{x^3}{6}+O(x^6)$$ My problem now is to compute $\sin ( \pi \cos (x)) $. One of my tutors once told me for small values of $x$ I can always use $\sin (x) \sim x$, so I thought that the following must be true as well for small values of $x$: $$\sin (\pi \cos (x))= \sin\left(\pi - \frac{\pi x^2}{2}+ \dots \right) \sim \pi - \frac{\pi x^2}{2}+ \dots$$ Which is indeed very wrong, the correct answer is: $$\sin (\pi \cos (x))\sim \frac{\pi x^2}{2}\pm O(x^4)$$ While it seems clear to me that my answer cannot be true, (I did it by naively plugging in the values and obtained the same result as I already had for $\pi \cos (x)$) , I don't see how the above result is obtained. Could somebody show me how to correctly process in that manner? Note : In class we were not yet introduced to the $O$-Notation. In the book by C.T. Michaels he simply uses dots for the higher terms and says that they can be neglected. I tried to include the $O$-Notation in my question, but only with my intuitive understanding of it.",,"['calculus', 'analysis', 'limits']"
15,Using L'Hopital's rule with the indeterminate form of infinity minus infinity,Using L'Hopital's rule with the indeterminate form of infinity minus infinity,,"I'm aware that with L'Hopital's rule, we're dealing with indeterminate forms of  $ \lim_{x\to a} \frac{f(x)}{g(x)} $, and that includes re-writing $\lim_{x\to a} \infty - \infty$ into that format. However, I'm not sure how to proceed with the following: $$ \lim_{x\to \infty} {\ln3x}-{\ln(x+1)} $$ Should I take the derivative first and then simplify for L'Hopital's rule? I'm not sure where to go.","I'm aware that with L'Hopital's rule, we're dealing with indeterminate forms of  $ \lim_{x\to a} \frac{f(x)}{g(x)} $, and that includes re-writing $\lim_{x\to a} \infty - \infty$ into that format. However, I'm not sure how to proceed with the following: $$ \lim_{x\to \infty} {\ln3x}-{\ln(x+1)} $$ Should I take the derivative first and then simplify for L'Hopital's rule? I'm not sure where to go.",,"['calculus', 'limits']"
16,"$\lim_{n \to \infty} n\sqrt 2\, \big(\sqrt{\ln(n+1)}-\sqrt{\ln n}\big) = 0$",,"\lim_{n \to \infty} n\sqrt 2\, \big(\sqrt{\ln(n+1)}-\sqrt{\ln n}\big) = 0","I'm trying to prove that $$ \lim_{n \to \infty} n\sqrt{2}\,\left(\sqrt{\ln(n+1)}-\sqrt{\ln n}\right) = 0 $$ But I haven't any ideas how to do it... My calculations shows that this sequence is monotonously decreasing. I've proved that using inequality $\ln(1+x^a) \le ax$ and double-sided theorem.","I'm trying to prove that $$ \lim_{n \to \infty} n\sqrt{2}\,\left(\sqrt{\ln(n+1)}-\sqrt{\ln n}\right) = 0 $$ But I haven't any ideas how to do it... My calculations shows that this sequence is monotonously decreasing. I've proved that using inequality $\ln(1+x^a) \le ax$ and double-sided theorem.",,"['calculus', 'analysis', 'limits', 'logarithms', 'radicals']"
17,limit of a sequence. might be related to Cesaro theorem,limit of a sequence. might be related to Cesaro theorem,,"this it the limit to evaluate: $$\mathop {\lim }\limits_{n \to \infty } {1 \over {{n^{k + 1}}}}(k! + {{(k + 1)!} \over {1!}} + ... + {{(k + n)!} \over {n!}})$$ I've given an hint which is: $$(1 - q)(1 + q + ... + {q^N}) = (1 - {q^{N + 1}})$$ I tried to use Cesaro theorem but got to sort of a dead end.. I also noticed a similarity to the Binomial coefficient , is that going to help me? Any help will be appreciated","this it the limit to evaluate: $$\mathop {\lim }\limits_{n \to \infty } {1 \over {{n^{k + 1}}}}(k! + {{(k + 1)!} \over {1!}} + ... + {{(k + n)!} \over {n!}})$$ I've given an hint which is: $$(1 - q)(1 + q + ... + {q^N}) = (1 - {q^{N + 1}})$$ I tried to use Cesaro theorem but got to sort of a dead end.. I also noticed a similarity to the Binomial coefficient , is that going to help me? Any help will be appreciated",,"['calculus', 'limits']"
18,Finding the limit of $\frac{e^{x}+x-\cos(2x)}{x^2}$,Finding the limit of,\frac{e^{x}+x-\cos(2x)}{x^2},How would one find the limit for the following problem. $x\rightarrow\infty$ $\frac{e^{x}+x-\cos(2x)}{x^2}$ I did the hospital rule. $\frac{e^x+1+2\sin(2x)}{2x}$ But now I am stuck I did this but I feel it diverges. $e^x+1+2\sin(2x)*\frac{1}{2x}$,How would one find the limit for the following problem. $x\rightarrow\infty$ $\frac{e^{x}+x-\cos(2x)}{x^2}$ I did the hospital rule. $\frac{e^x+1+2\sin(2x)}{2x}$ But now I am stuck I did this but I feel it diverges. $e^x+1+2\sin(2x)*\frac{1}{2x}$,,"['calculus', 'limits']"
19,Use the $\varepsilon$-$\delta$ definition of a limit to prove this.,Use the - definition of a limit to prove this.,\varepsilon \delta,"I know to how prove normal limits using the epsilon-delta definition, say: $$\lim_{x\to a}f(x) = L$$ But, there was a question on my textbook which I couldn't quite figure out to do, even though I've thought about it for a while I don't even know how to go about starting it. Use $\varepsilon$-$\delta$ definition of a limit to prove that $$\lim \limits _{x\to c}f(x) = 0$$ iff  $$\lim \limits_{x\to c}|f(x)| = 0$$ Could anyone help me with this, even a hint on where to start? Thank you in advance.","I know to how prove normal limits using the epsilon-delta definition, say: $$\lim_{x\to a}f(x) = L$$ But, there was a question on my textbook which I couldn't quite figure out to do, even though I've thought about it for a while I don't even know how to go about starting it. Use $\varepsilon$-$\delta$ definition of a limit to prove that $$\lim \limits _{x\to c}f(x) = 0$$ iff  $$\lim \limits_{x\to c}|f(x)| = 0$$ Could anyone help me with this, even a hint on where to start? Thank you in advance.",,"['calculus', 'limits', 'epsilon-delta']"
20,Proving Limit False,Proving Limit False,,"I'm trying to prove that the limit of sin x as x->infinity is not equal to 1/2. I know that this is true, but I can't seen to figure out how to prove it using the precise definition of a limit. What I have so far is this, e>0, M>0 abs(sin x - 1/2)<e whenever x>M I also think that I can use the fact that, abs(sin x)<=1 for all x But I don't know for sure. I've also seen some really extensive proofs for stuff like sin x/x (ref 1). So I may be doing this completely wrong. Thanks for any help. http://tutorial.math.lamar.edu/Classes/CalcI/ProofTrigDeriv.aspx","I'm trying to prove that the limit of sin x as x->infinity is not equal to 1/2. I know that this is true, but I can't seen to figure out how to prove it using the precise definition of a limit. What I have so far is this, e>0, M>0 abs(sin x - 1/2)<e whenever x>M I also think that I can use the fact that, abs(sin x)<=1 for all x But I don't know for sure. I've also seen some really extensive proofs for stuff like sin x/x (ref 1). So I may be doing this completely wrong. Thanks for any help. http://tutorial.math.lamar.edu/Classes/CalcI/ProofTrigDeriv.aspx",,['limits']
21,How to find the limit $x_n=\frac{(a)(a+1)(a+2)..(a+n)}{(b)(b+1)(b+2)..(b+n)}$,How to find the limit,x_n=\frac{(a)(a+1)(a+2)..(a+n)}{(b)(b+1)(b+2)..(b+n)},"Let a,b be positive number then how to find the limit of $x_n=\frac{(a)(a+1)(a+2)..(a+n)}{(b)(b+1)(b+2)..(b+n)}$ when $n\rightarrow \infty $ when a=b obviously the limit is 1 but what about $a<b$ ? this problem reminded me of the limit $0<A_n=\frac{1*3*5*..*(2n-1)}{2*4*6*..*(2n)} \rightarrow 0 $ I can show this by denote $B_n=\frac{2*4*6*..*(2n)}{3*5*7*..*(2n+1)}$ then $A_n<B_n$ and $A_nB_n=\frac{1}{(2n+1)}$ so $A_n<\sqrt{\frac{1}{2n+1}}\rightarrow0$ when $n\rightarrow \infty$ but the same method seem to be useless in the above problem.I now also consider using delta-epsilon method or even using Gamma function to assure that the limit should be zero.What method should I use?","Let a,b be positive number then how to find the limit of $x_n=\frac{(a)(a+1)(a+2)..(a+n)}{(b)(b+1)(b+2)..(b+n)}$ when $n\rightarrow \infty $ when a=b obviously the limit is 1 but what about $a<b$ ? this problem reminded me of the limit $0<A_n=\frac{1*3*5*..*(2n-1)}{2*4*6*..*(2n)} \rightarrow 0 $ I can show this by denote $B_n=\frac{2*4*6*..*(2n)}{3*5*7*..*(2n+1)}$ then $A_n<B_n$ and $A_nB_n=\frac{1}{(2n+1)}$ so $A_n<\sqrt{\frac{1}{2n+1}}\rightarrow0$ when $n\rightarrow \infty$ but the same method seem to be useless in the above problem.I now also consider using delta-epsilon method or even using Gamma function to assure that the limit should be zero.What method should I use?",,"['calculus', 'limits']"
22,Prove $\lim_{n\to \infty}\frac{n}{n+1} = 1$ using epsilon delta,Prove  using epsilon delta,\lim_{n\to \infty}\frac{n}{n+1} = 1,$\lim_{n\to \infty}\frac{n}{n+1} = 1$ Prove using epsilon delta.,$\lim_{n\to \infty}\frac{n}{n+1} = 1$ Prove using epsilon delta.,,"['limits', 'epsilon-delta']"
23,Show $x\sqrt{n} - n \ln\left(1+\frac{x}{\sqrt{n}}\right) \to \frac{x^2}{2}$,Show,x\sqrt{n} - n \ln\left(1+\frac{x}{\sqrt{n}}\right) \to \frac{x^2}{2},"With $x > 0$, show $$ L=\lim_{n \to \infty} x\sqrt{n} - n \ln\left(1+\frac{x}{\sqrt{n}}\right) = \frac{x^2}{2}.  $$ I tried to write $$ x\sqrt{n}=\ln \left( e^{x\sqrt{n}} \right), $$ so that  $$ L  = \lim_{n\to \infty} \frac{e^{x\sqrt{n}}}{\left(1+x/\sqrt{n}\right)^n}. $$ The last expression is of the form $\frac{\infty}{\infty}$. However, l'hospital rule won't change the denumerator. I don't see what to do.","With $x > 0$, show $$ L=\lim_{n \to \infty} x\sqrt{n} - n \ln\left(1+\frac{x}{\sqrt{n}}\right) = \frac{x^2}{2}.  $$ I tried to write $$ x\sqrt{n}=\ln \left( e^{x\sqrt{n}} \right), $$ so that  $$ L  = \lim_{n\to \infty} \frac{e^{x\sqrt{n}}}{\left(1+x/\sqrt{n}\right)^n}. $$ The last expression is of the form $\frac{\infty}{\infty}$. However, l'hospital rule won't change the denumerator. I don't see what to do.",,['calculus']
24,"Let $f>0$ differentiable in $[0,\infty)$. Assume $\lim \limits_{x \to \infty} (\log\circ f)^\prime(x) < 0$. Show that $\int_0^\infty f$ converges.",Let  differentiable in . Assume . Show that  converges.,"f>0 [0,\infty) \lim \limits_{x \to \infty} (\log\circ f)^\prime(x) < 0 \int_0^\infty f","So what I gathered from the givens about $f$, since $(\log\circ f)^\prime(x)=\frac{f^\prime(x)}{f(x)}$ it would mean that far enough, $f^\prime(x)<0$. I don't know how to go about this from here. Another question in the same kind of area that I'm currently struggling with fruitlessly, assuming that $f$ is still positive and differentiable in $[0,\infty)$ - now the givens are different: Assume that $\int_0^\infty f$ exists, and that $f^\prime$ is bounded. Show that $\lim \limits_{x\to\infty} f(x)=0$. About this question I'm thinking about Lagrange's theorem, and using Cauchy's criterion for the convergence of improper integrals to show (somehow) that $f(x)$ can be made arbitrarily small far enough. That didn't get me very far, and frustration quickly ensued. I appreciate any thoughts and hints, I feel like I'm missing something rather obvious.. Thank you!","So what I gathered from the givens about $f$, since $(\log\circ f)^\prime(x)=\frac{f^\prime(x)}{f(x)}$ it would mean that far enough, $f^\prime(x)<0$. I don't know how to go about this from here. Another question in the same kind of area that I'm currently struggling with fruitlessly, assuming that $f$ is still positive and differentiable in $[0,\infty)$ - now the givens are different: Assume that $\int_0^\infty f$ exists, and that $f^\prime$ is bounded. Show that $\lim \limits_{x\to\infty} f(x)=0$. About this question I'm thinking about Lagrange's theorem, and using Cauchy's criterion for the convergence of improper integrals to show (somehow) that $f(x)$ can be made arbitrarily small far enough. That didn't get me very far, and frustration quickly ensued. I appreciate any thoughts and hints, I feel like I'm missing something rather obvious.. Thank you!",,"['limits', 'integration', 'improper-integrals']"
25,Find $\lim \limits_{n \to \infty}(n^5+4n^3)^{1/5}-n$,Find,\lim \limits_{n \to \infty}(n^5+4n^3)^{1/5}-n,"$$\lim \limits_{n \to \infty}(n^5+4n^3)^{1/5}-n=?$$ I see that   $$\lim_{n \to \infty}(n^5+4n^3)^{1/5}-n=\lim_{n \to \infty}n[(1+ \frac {4}{n^2})^{1/5}-1]=\lim_{z \to 0} \frac {1}{z}[(1+ {4}{z^2})^{1/5}-1]$$,where $n=\frac {1}{z}$. Now I do not know how to proceed. Can someone point me in the right direction? Thanks in advance for your time.","$$\lim \limits_{n \to \infty}(n^5+4n^3)^{1/5}-n=?$$ I see that   $$\lim_{n \to \infty}(n^5+4n^3)^{1/5}-n=\lim_{n \to \infty}n[(1+ \frac {4}{n^2})^{1/5}-1]=\lim_{z \to 0} \frac {1}{z}[(1+ {4}{z^2})^{1/5}-1]$$,where $n=\frac {1}{z}$. Now I do not know how to proceed. Can someone point me in the right direction? Thanks in advance for your time.",,[]
26,$\lim_{n \to \infty}\int_0^\infty\left ( \log \left ( {\frac{x+n}{x+\frac{1}{n}}}\right )\right )^2dx$,,\lim_{n \to \infty}\int_0^\infty\left ( \log \left ( {\frac{x+n}{x+\frac{1}{n}}}\right )\right )^2dx,"Let $n=1,2,...$ and define $f(n)$ by $$f(n)=\int_0^\infty\left ( \log \left ( {\frac{x+n}{x+\frac{1}{n}}}\right )\right )^2dx$$ For some values of $n$, Matehamtica's shows that $f(n)$ is finite and seems to converge to $\infty$ as $n\rightarrow \infty$. 1 - How to find a bound for $f(n)$? 2- $f(n)\rightarrow\infty$, as $n\rightarrow\infty$? Thank you for your time.","Let $n=1,2,...$ and define $f(n)$ by $$f(n)=\int_0^\infty\left ( \log \left ( {\frac{x+n}{x+\frac{1}{n}}}\right )\right )^2dx$$ For some values of $n$, Matehamtica's shows that $f(n)$ is finite and seems to converge to $\infty$ as $n\rightarrow \infty$. 1 - How to find a bound for $f(n)$? 2- $f(n)\rightarrow\infty$, as $n\rightarrow\infty$? Thank you for your time.",,['limits']
27,"$\sum_{n=2}^\infty \frac{1}{(\ln\, n)^2}$ c0nvergence",c0nvergence,"\sum_{n=2}^\infty \frac{1}{(\ln\, n)^2}","$$\sum_{n=2}^\infty \frac{1}{(\ln\, n)^2}$$ The series converge? Please verify my solution below","$$\sum_{n=2}^\infty \frac{1}{(\ln\, n)^2}$$ The series converge? Please verify my solution below",,"['real-analysis', 'analysis', 'limits', 'convergence-divergence']"
28,limit at infinity $f(x)=x+ax \sin(x)$,limit at infinity,f(x)=x+ax \sin(x),"Let $f:\Bbb R\rightarrow \Bbb R$ be defined by $f(x)= x+ ax\sin x$. I would like to show that if $|a| < 1$, then $\lim\limits_{x\rightarrow\pm \infty}f(x)=\pm \infty$. Thanks for your time.","Let $f:\Bbb R\rightarrow \Bbb R$ be defined by $f(x)= x+ ax\sin x$. I would like to show that if $|a| < 1$, then $\lim\limits_{x\rightarrow\pm \infty}f(x)=\pm \infty$. Thanks for your time.",,"['real-analysis', 'limits']"
29,The Set of All Subsequential Limits,The Set of All Subsequential Limits,,"Given $\{a_n\}_{n=0}^\infty$ and $\{b_n\}_{n=0}^\infty$ bounded sequences; show that if $\lim \limits_{n\to \infty}a_n-b_n=0$ then both sequences have the same subsequential limits. My attempt to prove this begins with: Let $E_A=\{L|L$ subsequential limit of $a_n$} and $E_B=\{L|L$ subsequential limit of $b_n$}. We need to show that $E_A=E_B$. Given bounded sequence $a_n$ and $b_n$ we know from B.W that each sequence has a subsequence that converges, therefore both $E_A$ and $E_B$ are not empty; Let $L\in E_A$.  How can I show that $L\in E_B$? Thank you very much.","Given $\{a_n\}_{n=0}^\infty$ and $\{b_n\}_{n=0}^\infty$ bounded sequences; show that if $\lim \limits_{n\to \infty}a_n-b_n=0$ then both sequences have the same subsequential limits. My attempt to prove this begins with: Let $E_A=\{L|L$ subsequential limit of $a_n$} and $E_B=\{L|L$ subsequential limit of $b_n$}. We need to show that $E_A=E_B$. Given bounded sequence $a_n$ and $b_n$ we know from B.W that each sequence has a subsequence that converges, therefore both $E_A$ and $E_B$ are not empty; Let $L\in E_A$.  How can I show that $L\in E_B$? Thank you very much.",,"['calculus', 'real-analysis', 'limits']"
30,"$f(x)$ is positive, continuous, monotone and integrable in (0,1]. Is $\lim_{x \rightarrow 0} xf(x) = 0$?","is positive, continuous, monotone and integrable in (0,1]. Is ?",f(x) \lim_{x \rightarrow 0} xf(x) = 0,"I'm having trouble with this question from an example test. We have a positive function $f(x)$ that's monotone, continuous and integrable in $(0,1]$. Is $\lim_{x \rightarrow 0} xf(x) = 0$? Progress The only problematic case seems to be when $f(x)$ is unbounded and monotonic decreasing. For that case, I found out that $xf(x)=\int_{0}^{x} f(x)dt$ and that $0\leq xf(x)\leq \int_{0}^{x} f(t)dt$. From here I'm not sure how to go on. Thanks!","I'm having trouble with this question from an example test. We have a positive function $f(x)$ that's monotone, continuous and integrable in $(0,1]$. Is $\lim_{x \rightarrow 0} xf(x) = 0$? Progress The only problematic case seems to be when $f(x)$ is unbounded and monotonic decreasing. For that case, I found out that $xf(x)=\int_{0}^{x} f(x)dt$ and that $0\leq xf(x)\leq \int_{0}^{x} f(t)dt$. From here I'm not sure how to go on. Thanks!",,"['calculus', 'limits', 'integration']"
31,"Evaluate $\lim_{a \to0,Q \to\infty} \frac{Q}{2\pi}\big[ \log(z-a)-\log(z+a) \big]$",Evaluate,"\lim_{a \to0,Q \to\infty} \frac{Q}{2\pi}\big[ \log(z-a)-\log(z+a) \big]","Can anyone help me find $$\lim_{a \to 0,Q \to\infty} \frac{Q}{2\pi}\left[ \log(z-a)-\log(z+a) \right]$$ Where $aQ=A$ where $A$ is kept constant. I know it is in the form $\mu/z$ for some $\mu$ Thanks very much in advance","Can anyone help me find $$\lim_{a \to 0,Q \to\infty} \frac{Q}{2\pi}\left[ \log(z-a)-\log(z+a) \right]$$ Where $aQ=A$ where $A$ is kept constant. I know it is in the form $\mu/z$ for some $\mu$ Thanks very much in advance",,['limits']
32,Find limit of polynomials,Find limit of polynomials,,"Suppose we  want to  find limit of the following polynomial $$\lim_{x\to-\infty}(x^4+x^5).$$ If we directly put here $-\infty$, we   get  ""$-\infty +\infty$"" which is definitely undefined form, but otherwise  if factor out $x^5$, our polynomial will be of the form $x^5(1/x+1)$. $\lim_{x\to-\infty}\frac 1x=0$, so our result will be $-\infty*(0+1)$,which equal to $-\infty$. I have exam in a 3 days and interested if  my last procedure is correct? Directly putting $x$ values  gives me undefined form, but factorization  on the other hand, negative infinity, which one is correct?","Suppose we  want to  find limit of the following polynomial $$\lim_{x\to-\infty}(x^4+x^5).$$ If we directly put here $-\infty$, we   get  ""$-\infty +\infty$"" which is definitely undefined form, but otherwise  if factor out $x^5$, our polynomial will be of the form $x^5(1/x+1)$. $\lim_{x\to-\infty}\frac 1x=0$, so our result will be $-\infty*(0+1)$,which equal to $-\infty$. I have exam in a 3 days and interested if  my last procedure is correct? Directly putting $x$ values  gives me undefined form, but factorization  on the other hand, negative infinity, which one is correct?",,"['calculus', 'limits']"
33,Trigonometric limit: $\lim_{x \to 0}\frac{1-\cos(ax)}{ax}=0$,Trigonometric limit:,\lim_{x \to 0}\frac{1-\cos(ax)}{ax}=0,"In order to prove that $\displaystyle\lim_{x \to 0}\frac{1-\cos(ax)}{ax}=0$, with $a \ne 0$, I managed that $a=2$ and evaluated this limit: $$ \begin{align*} \quad \lim_{x \to 0}\frac{1-\cos(2x)}{2x}&=     \lim_{x \to 0}\frac{1-(1-2\sin^2(x))}{2x}\\ &= \lim_{x \to 0}\frac{1-1+2\sin^2(x)}{2x}\\ &=  \lim_{x \to 0}\frac{2\sin^2(x)}{2x}\\ &= \lim_{x \to 0}\frac{\sin^2(x)}{x}\\  &= \lim_{x \to 0} \frac{\sin(x)}{x} \cdot \sin(x)\\ &= 1 \cdot 0\\ &=0 \end{align*}$$ Can I generalize it?","In order to prove that $\displaystyle\lim_{x \to 0}\frac{1-\cos(ax)}{ax}=0$, with $a \ne 0$, I managed that $a=2$ and evaluated this limit: $$ \begin{align*} \quad \lim_{x \to 0}\frac{1-\cos(2x)}{2x}&=     \lim_{x \to 0}\frac{1-(1-2\sin^2(x))}{2x}\\ &= \lim_{x \to 0}\frac{1-1+2\sin^2(x)}{2x}\\ &=  \lim_{x \to 0}\frac{2\sin^2(x)}{2x}\\ &= \lim_{x \to 0}\frac{\sin^2(x)}{x}\\  &= \lim_{x \to 0} \frac{\sin(x)}{x} \cdot \sin(x)\\ &= 1 \cdot 0\\ &=0 \end{align*}$$ Can I generalize it?",,"['calculus', 'trigonometry', 'limits']"
34,Algebraic manipulations for a simple limit,Algebraic manipulations for a simple limit,,"I can't seem to prove that $e^a=\lim\limits_{x\rightarrow\infty}(1+\frac{a}{x})^x$. I'm sure there must be some algebraic manipulations that can be done in order to show that $\lim\limits_{x\rightarrow\infty}(1+\frac{a}{x})^x=$$\lim\limits_{x\rightarrow\infty}(1+\frac{1}{x})^{xa}$. What are these algebraic operations? I apologize in advance if maybe this question is a little too simple, but I can't for the life of me figure it out. Thanks.","I can't seem to prove that $e^a=\lim\limits_{x\rightarrow\infty}(1+\frac{a}{x})^x$. I'm sure there must be some algebraic manipulations that can be done in order to show that $\lim\limits_{x\rightarrow\infty}(1+\frac{a}{x})^x=$$\lim\limits_{x\rightarrow\infty}(1+\frac{1}{x})^{xa}$. What are these algebraic operations? I apologize in advance if maybe this question is a little too simple, but I can't for the life of me figure it out. Thanks.",,"['real-analysis', 'limits']"
35,How to show $\lim\limits_{t\to 0}\frac{|f+tg|^{p}-|f|^{p}}{t}=pfg|f|^{p-2}$,How to show,\lim\limits_{t\to 0}\frac{|f+tg|^{p}-|f|^{p}}{t}=pfg|f|^{p-2},"Could anyone help to compute this limit? Thank you! This is part of a proof in Analysis by E. Lieb. Let $f$ and $g$ be real numbers and $p>1$, show the following limit: $$\lim\limits_{t\to 0}\frac{|f+tg|^{p}-|f|^{p}}{t}=pfg|f|^{p-2}$$","Could anyone help to compute this limit? Thank you! This is part of a proof in Analysis by E. Lieb. Let $f$ and $g$ be real numbers and $p>1$, show the following limit: $$\lim\limits_{t\to 0}\frac{|f+tg|^{p}-|f|^{p}}{t}=pfg|f|^{p-2}$$",,"['calculus', 'limits']"
36,$\lim\limits_{x\to 0} \dfrac{e^x-e^{x\cos x}}{x+\sin x}$ [duplicate],[duplicate],\lim\limits_{x\to 0} \dfrac{e^x-e^{x\cos x}}{x+\sin x},"This question already has answers here : Limit of the exponential functions: $\lim_{x\to 0} \frac{e^x-e^{x \cos x}} {x +\sin x}$ (6 answers) Closed 2 months ago . $\operatorname{lim}_{x\to 0} \dfrac{e^x-e^{x\cos x}}{x+\sin x}$ , L'hopital is not allowed. Divide all limit by $x$ then $\lim\limits_{x\to 0} \dfrac{\dfrac{e^x}{x}-\dfrac{e^{x\cos x}}{x}}{1+\dfrac {\sin x}{x}}$ Denumerator goes to $2$ . What about numerator? The limit $\lim\limits_{x\to 0} \dfrac{e^x}{x}$ does not exist. Neither the limit of $x\to 0$ $\dfrac{e^{x\cos x}}{x}$ exists","This question already has answers here : Limit of the exponential functions: $\lim_{x\to 0} \frac{e^x-e^{x \cos x}} {x +\sin x}$ (6 answers) Closed 2 months ago . , L'hopital is not allowed. Divide all limit by then Denumerator goes to . What about numerator? The limit does not exist. Neither the limit of exists",\operatorname{lim}_{x\to 0} \dfrac{e^x-e^{x\cos x}}{x+\sin x} x \lim\limits_{x\to 0} \dfrac{\dfrac{e^x}{x}-\dfrac{e^{x\cos x}}{x}}{1+\dfrac {\sin x}{x}} 2 \lim\limits_{x\to 0} \dfrac{e^x}{x} x\to 0 \dfrac{e^{x\cos x}}{x},"['calculus', 'limits', 'limits-without-lhopital']"
37,"Showing $\lim_{n \to \infty}\;( (2n+1)! )^{1/n}\,\sin\left(\frac {1}{n^2-n}\right) = \frac{4}{e^2}$",Showing,"\lim_{n \to \infty}\;( (2n+1)! )^{1/n}\,\sin\left(\frac {1}{n^2-n}\right) = \frac{4}{e^2}",$ \displaystyle \lim_{n \to \infty}( (2n+1)! )^{1/n} \sin(\frac {1}{n^2-n})  $ = $\frac{4}{e^2}$ the factorial part tends to $ \infty$ while the sin part to $0$ considering that sin is continous : $ \lim_{n\to\infty}  \sin(\frac {1}{n^2-n})=0$ because the denominator tends to infinity ( the $n^2$ grows asimptotically faster than $n$ ) while using the quotion theorem we can find $ a_n:= (( 2n+1)!)^{1/n}$ let $ \lambda = \frac{a_{n+1}}{a_n}= \frac{(( 2n+3)!)^{1/(n+1)}}{(( 2n+1)!)^{1/n}} > \frac{(( 2n+3)!)^{1/(n+1)}}{(( 2n+1)!)^{1/n+1}} = ( ( (2n+3)(2n+2 ) ) ^{1/n+1} = (4n^2 +10n +6)^{n+1}=(1+(4n^2 +10n +5 ))^{  \frac{1}{4n^2 +10n +5}   (4n +10 +5/n)} = e^\infty = \infty$ therefore $ \lambda \rightarrow \infty>0 \implies a_n \rightarrow \infty$ now i know that  the limit is of the form $ \infty 0$,= the factorial part tends to while the sin part to considering that sin is continous : because the denominator tends to infinity ( the grows asimptotically faster than ) while using the quotion theorem we can find let therefore now i know that  the limit is of the form, \displaystyle \lim_{n \to \infty}( (2n+1)! )^{1/n} \sin(\frac {1}{n^2-n})   \frac{4}{e^2}  \infty 0  \lim_{n\to\infty}  \sin(\frac {1}{n^2-n})=0 n^2 n  a_n:= (( 2n+1)!)^{1/n}  \lambda = \frac{a_{n+1}}{a_n}= \frac{(( 2n+3)!)^{1/(n+1)}}{(( 2n+1)!)^{1/n}} > \frac{(( 2n+3)!)^{1/(n+1)}}{(( 2n+1)!)^{1/n+1}} = ( ( (2n+3)(2n+2 ) ) ^{1/n+1} = (4n^2 +10n +6)^{n+1}=(1+(4n^2 +10n +5 ))^{  \frac{1}{4n^2 +10n +5}   (4n +10 +5/n)} = e^\infty = \infty  \lambda \rightarrow \infty>0 \implies a_n \rightarrow \infty  \infty 0,"['real-analysis', 'limits', 'limits-without-lhopital']"
38,An alternative definition of the limit of a function,An alternative definition of the limit of a function,,"In a course on real analysis one usually comes across the definition of the limit of a function: Given a function $f:A\to \mathbb{R}$ where $A\subseteq\mathbb{R}$ , then if $c\in A$ is an limit point of $A$ , we say that \begin{align} \lim_{x\to c}f(x) = L \end{align} If \begin{align} \forall_{\varepsilon>0}\exists_{\delta>0}  0<|x-c|<\delta \implies |f(x)-L|<\varepsilon  \end{align} When one uses this definition of a limit in a proof, it tends to get a bit messy, sometimes you have to do this ""trick"" where you restrict $\delta$ to always be less than a certain constant, to get some constant lower bounds in either of the inequalities. It also happens frequently that one starts with a $\delta$ and investigates what happens to $|f(x)-L|$ , and then from that guess what a suitable relationship between $\varepsilon$ and $\delta$ should be. This approach seems to be a bit convoluted at times, so I propose an alternative definition which I believe is more rational Given $f:A\to\mathbb{R}$ with $c\in A$ as before, then if there is a surjective function \begin{align} g:(0,a)\to(0,b) \end{align} That satisfies \begin{align}  0<|x-c|<\delta \implies |f(x)-L|<g(\delta) \end{align} Then \begin{align} \lim_{x\to c}=L \end{align} This seems superficially more complicated, because now suddenly we have to check the surjectivity of a function, but what is interesting is that both quantifiers and a whole variable ( $\varepsilon$ ) is now imbedded into a single statement about a function. The motivation behind the definition is that if one can find such a $g$ , then given any $\varepsilon>0$ , one can find $0<\varepsilon'<\varepsilon$ where $\varepsilon'\in(0,b)$ , and since it is in the image of $g$ there is some $\delta$ such that $g(\delta)=\varepsilon'$ and from there you can prove that the limit holds in the traditional sense. Note that one can also prove surjectivity by proving that a function is bijective, and you can prove the latter by constructing the inverse, thereby entirely avoiding the use of quantifiers. My questions then are: Does this alternative definition seem correct, and useful? Is there something analogous to this that is already used?","In a course on real analysis one usually comes across the definition of the limit of a function: Given a function where , then if is an limit point of , we say that If When one uses this definition of a limit in a proof, it tends to get a bit messy, sometimes you have to do this ""trick"" where you restrict to always be less than a certain constant, to get some constant lower bounds in either of the inequalities. It also happens frequently that one starts with a and investigates what happens to , and then from that guess what a suitable relationship between and should be. This approach seems to be a bit convoluted at times, so I propose an alternative definition which I believe is more rational Given with as before, then if there is a surjective function That satisfies Then This seems superficially more complicated, because now suddenly we have to check the surjectivity of a function, but what is interesting is that both quantifiers and a whole variable ( ) is now imbedded into a single statement about a function. The motivation behind the definition is that if one can find such a , then given any , one can find where , and since it is in the image of there is some such that and from there you can prove that the limit holds in the traditional sense. Note that one can also prove surjectivity by proving that a function is bijective, and you can prove the latter by constructing the inverse, thereby entirely avoiding the use of quantifiers. My questions then are: Does this alternative definition seem correct, and useful? Is there something analogous to this that is already used?","f:A\to \mathbb{R} A\subseteq\mathbb{R} c\in A A \begin{align}
\lim_{x\to c}f(x) = L
\end{align} \begin{align}
\forall_{\varepsilon>0}\exists_{\delta>0} 
0<|x-c|<\delta \implies |f(x)-L|<\varepsilon 
\end{align} \delta \delta |f(x)-L| \varepsilon \delta f:A\to\mathbb{R} c\in A \begin{align}
g:(0,a)\to(0,b)
\end{align} \begin{align} 
0<|x-c|<\delta \implies |f(x)-L|<g(\delta)
\end{align} \begin{align}
\lim_{x\to c}=L
\end{align} \varepsilon g \varepsilon>0 0<\varepsilon'<\varepsilon \varepsilon'\in(0,b) g \delta g(\delta)=\varepsilon'","['real-analysis', 'limits', 'alternative-proof']"
39,How to find the limit: $\lim\limits_{x \to \infty} \frac{x^8+4x+2^x}{2^x+x^6+1}$,How to find the limit:,\lim\limits_{x \to \infty} \frac{x^8+4x+2^x}{2^x+x^6+1},"I have this limit: $$\lim\limits_{x \to \infty} \frac{x^8+4x+2^x}{2^x+x^6+1}.$$ I think I know how to solve it using L'Hôpital's rule (please correct me if this is wrong): $$\lim\limits_{x \to \infty} \frac{x^8+4x+2^x}{2^x+x^6+1}= \lim\limits_{x \to \infty} \frac{8x^7+4+2^x\cdot \ln{2}}{2^x\cdot  \ln{2} +6x^5}= \lim\limits_{x \to \infty} \frac{56x^6+2^x\cdot (\ln{2})^2}{2^x\cdot (\ln{2})^2 +30x^4}= \lim\limits_{x \to \infty} \frac{336x^5+2^x\cdot (\ln{2})^3}{2^x\cdot (\ln{2})^3 +160x^3}= \lim\limits_{x \to \infty} \frac{1680x^4+2^x\cdot (\ln{2})^4}{2^x\cdot (\ln{2})^4 +480x^2}= \lim\limits_{x \to \infty} \frac{6720x^3+2^x\cdot (\ln{2})^5}{2^x\cdot (\ln{2})^5 +960x}= \lim\limits_{x \to \infty} \frac{20160x^2+2^x\cdot (\ln{2})^6}{2^x\cdot (\ln{2})^6 +960}= \lim\limits_{x \to \infty} \frac{40320x+2^x\cdot (\ln{2})^7}{2^x\cdot (\ln{2})^7}= \lim\limits_{x \to \infty} \frac{40320+2^x\cdot (\ln{2})^8}{2^x\cdot (\ln{2})^8}= \lim\limits_{x \to \infty} \frac{2^x\cdot (\ln{2})^9}{2^x\cdot (\ln{2})^9}=1.$$ This seems overly complicated though. I think an easier way would be to factor out the ""dominating"" term. I'm a bit new to that so I would appreciate some guidance. $x^8$ grows faster than $2^x$ when $x$ is small. But in this limit, $x$ is approaching $\infty$ . I'm not sure, but I think $2^x$ will have passed $x^8$ at that point. Does that mean I should factor out $2^x$ and if so how do I do that? Thanks in advance.","I have this limit: I think I know how to solve it using L'Hôpital's rule (please correct me if this is wrong): This seems overly complicated though. I think an easier way would be to factor out the ""dominating"" term. I'm a bit new to that so I would appreciate some guidance. grows faster than when is small. But in this limit, is approaching . I'm not sure, but I think will have passed at that point. Does that mean I should factor out and if so how do I do that? Thanks in advance.","\lim\limits_{x \to \infty} \frac{x^8+4x+2^x}{2^x+x^6+1}. \lim\limits_{x \to \infty} \frac{x^8+4x+2^x}{2^x+x^6+1}=
\lim\limits_{x \to \infty} \frac{8x^7+4+2^x\cdot \ln{2}}{2^x\cdot  \ln{2} +6x^5}=
\lim\limits_{x \to \infty} \frac{56x^6+2^x\cdot (\ln{2})^2}{2^x\cdot (\ln{2})^2 +30x^4}=
\lim\limits_{x \to \infty} \frac{336x^5+2^x\cdot (\ln{2})^3}{2^x\cdot (\ln{2})^3 +160x^3}=
\lim\limits_{x \to \infty} \frac{1680x^4+2^x\cdot (\ln{2})^4}{2^x\cdot (\ln{2})^4 +480x^2}=
\lim\limits_{x \to \infty} \frac{6720x^3+2^x\cdot (\ln{2})^5}{2^x\cdot (\ln{2})^5 +960x}=
\lim\limits_{x \to \infty} \frac{20160x^2+2^x\cdot (\ln{2})^6}{2^x\cdot (\ln{2})^6 +960}=
\lim\limits_{x \to \infty} \frac{40320x+2^x\cdot (\ln{2})^7}{2^x\cdot (\ln{2})^7}=
\lim\limits_{x \to \infty} \frac{40320+2^x\cdot (\ln{2})^8}{2^x\cdot (\ln{2})^8}=
\lim\limits_{x \to \infty} \frac{2^x\cdot (\ln{2})^9}{2^x\cdot (\ln{2})^9}=1. x^8 2^x x x \infty 2^x x^8 2^x","['calculus', 'limits']"
40,L'Hospital's Rule of infinity over infinity,L'Hospital's Rule of infinity over infinity,,"I am troubled for understanding the L'Hospital's Rule of $\infty/\infty$ : $$\lim_{x\rightarrow a}\frac{f(x)}{g(x)}= \lim_{x\rightarrow a}\frac{f^\prime(x)}{g^\prime(x)} \tag{1}$$ where $\lim_{x\rightarrow a}\{f(x),g(x)\} \rightarrow \infty$ . The equation (1) is well understood for me in the case of $\lim_{x\rightarrow a}\{f(x),g(x)\} \rightarrow 0$ , in which case : $$\lim_{x\rightarrow a}\frac{f(x)}{g(x)}=\lim_{\Delta x\rightarrow 0}\frac{f(a)+f^\prime(a)\Delta x}{g(a)+g^\prime(a)\Delta x}= \lim_{x\rightarrow a}\frac{f^\prime(x)}{g^\prime(x)} \tag{2}$$ However, if $\lim_{x\rightarrow a}\{f(x),g(x)\} \rightarrow \infty$ , here is my attempt : $$\lim_{x\rightarrow a}\frac{f(x)}{g(x)}=\lim_{x\rightarrow a}\frac{1/g(x)}{1/f(x)}= \lim_{x\rightarrow a}\frac{-\frac{1}{g^2(x)}g^\prime(x) }{-\frac{1}{f^2(x)}f^\prime(x)} \tag{3}$$ I don't understand why this last result can be turned into $\lim_{x\rightarrow a}\frac{f^\prime(x)}{g^\prime(x)}$ ?","I am troubled for understanding the L'Hospital's Rule of : where . The equation (1) is well understood for me in the case of , in which case : However, if , here is my attempt : I don't understand why this last result can be turned into ?","\infty/\infty \lim_{x\rightarrow a}\frac{f(x)}{g(x)}= \lim_{x\rightarrow a}\frac{f^\prime(x)}{g^\prime(x)} \tag{1} \lim_{x\rightarrow a}\{f(x),g(x)\} \rightarrow \infty \lim_{x\rightarrow a}\{f(x),g(x)\} \rightarrow 0 \lim_{x\rightarrow a}\frac{f(x)}{g(x)}=\lim_{\Delta x\rightarrow 0}\frac{f(a)+f^\prime(a)\Delta x}{g(a)+g^\prime(a)\Delta x}= \lim_{x\rightarrow a}\frac{f^\prime(x)}{g^\prime(x)} \tag{2} \lim_{x\rightarrow a}\{f(x),g(x)\} \rightarrow \infty \lim_{x\rightarrow a}\frac{f(x)}{g(x)}=\lim_{x\rightarrow a}\frac{1/g(x)}{1/f(x)}= \lim_{x\rightarrow a}\frac{-\frac{1}{g^2(x)}g^\prime(x) }{-\frac{1}{f^2(x)}f^\prime(x)} \tag{3} \lim_{x\rightarrow a}\frac{f^\prime(x)}{g^\prime(x)}","['limits', 'functions', 'derivatives', 'infinity', 'indeterminate-forms']"
41,"How do we evaluate ""a"" in this limit?","How do we evaluate ""a"" in this limit?",,"If $\quad \lim _{x \rightarrow 0}\left(\frac{a \sin ^4 \sqrt{x}}{\sqrt{\cos x}-1}\right)^{\frac{\tan \left(\ln ^2(1+\sqrt{2} x)\right)}{\ln \left(1+\sin ^2 x\right)}}=16$ , sum of all possible values of $a$ is On seeing this , the first thing that immediately ran through my mind is limit does not exist. Becasue $\sqrt x$ is given and when x approaches 0 from left side of 0, it take negative values and thus root x cant be defined. If I'm wrong I don't find any other way to simplify this. Can you help?","If , sum of all possible values of is On seeing this , the first thing that immediately ran through my mind is limit does not exist. Becasue is given and when x approaches 0 from left side of 0, it take negative values and thus root x cant be defined. If I'm wrong I don't find any other way to simplify this. Can you help?",\quad \lim _{x \rightarrow 0}\left(\frac{a \sin ^4 \sqrt{x}}{\sqrt{\cos x}-1}\right)^{\frac{\tan \left(\ln ^2(1+\sqrt{2} x)\right)}{\ln \left(1+\sin ^2 x\right)}}=16 a \sqrt x,"['real-analysis', 'calculus', 'limits']"
42,"find limit of $ \lim\limits_{(x,y)\to (2,0)} \frac{x+y-2}{x^2+y^2-4} $",find limit of," \lim\limits_{(x,y)\to (2,0)} \frac{x+y-2}{x^2+y^2-4} ","I have a problem with finding a limit of this: $$\lim_{(x,y)\to(2,0)}\frac{x+y-2}{x^2+y^2-4}$$ I was thinking about using this: $\;\dfrac{1}{x^2+y^2}\leqslant\dfrac{1}{2|xy|}$ I also looked at some sequences to determine, whether the limit exists or not and my intuition is that it exists. Any ideas how to calculate this limit? (Sorry, there was a mistake in the first question)","I have a problem with finding a limit of this: I was thinking about using this: I also looked at some sequences to determine, whether the limit exists or not and my intuition is that it exists. Any ideas how to calculate this limit? (Sorry, there was a mistake in the first question)","\lim_{(x,y)\to(2,0)}\frac{x+y-2}{x^2+y^2-4} \;\dfrac{1}{x^2+y^2}\leqslant\dfrac{1}{2|xy|}","['limits', 'analysis']"
43,"Prove that $\lim_{(x,y) \to (x_0,0)} \frac{1-e^{-xy}}{y} = x_0$",Prove that,"\lim_{(x,y) \to (x_0,0)} \frac{1-e^{-xy}}{y} = x_0","I have to prove that $$\lim_{(x,y) \to (x_0,0)} \frac{1-e^{-xy}}{y} = x_0$$ I have tried the following, but I'm not sure if it is rigorous, especially in one step: We have by L'Hôpital that $$\lim_{h \to 0} \frac{1 - e^{-h}}{h}=\lim_{h\to 0} e^{-h}=1$$ Then, because $$\lim_{(x,y)\to (x_0,0)} xy = 0$$ we have that \begin{equation} 1 = \lim_{h \to 0} \frac{1 - e^{-h}}{h} = \lim_{(x,y) \to (x_0,0)} \frac{1 - e^{-xy}}{xy} \tag{1}\end{equation} So $$ \lim_{(x,y) \to (x_0,0)} \frac{1-e^{-xy}}{y} = \lim_{(x,y) \to (x_0,0)} x\frac{1-e^{-xy}}{xy} = \lim_{(x,y) \to (x_0,0)} x  \cdot \lim_{(x,y) \to (x_0,0)} \frac{1-e^{-xy}}{xy}= x_0 \cdot 1 = x_0$$ The step where I used a reasoning that I think it may not always be true is $(1)$","I have to prove that I have tried the following, but I'm not sure if it is rigorous, especially in one step: We have by L'Hôpital that Then, because we have that So The step where I used a reasoning that I think it may not always be true is","\lim_{(x,y) \to (x_0,0)} \frac{1-e^{-xy}}{y} = x_0 \lim_{h \to 0} \frac{1 - e^{-h}}{h}=\lim_{h\to 0} e^{-h}=1 \lim_{(x,y)\to (x_0,0)} xy = 0 \begin{equation} 1 = \lim_{h \to 0} \frac{1 - e^{-h}}{h} = \lim_{(x,y) \to (x_0,0)} \frac{1 - e^{-xy}}{xy} \tag{1}\end{equation}  \lim_{(x,y) \to (x_0,0)} \frac{1-e^{-xy}}{y} = \lim_{(x,y) \to (x_0,0)} x\frac{1-e^{-xy}}{xy} = \lim_{(x,y) \to (x_0,0)} x  \cdot \lim_{(x,y) \to (x_0,0)} \frac{1-e^{-xy}}{xy}= x_0 \cdot 1 = x_0 (1)","['calculus', 'limits', 'multivariable-calculus']"
44,Find the limit $\displaystyle{\lim_{x\to 0}\frac{\sin(x)\sin^{-1}(x)-\sinh(x)\sinh^{-1}(x)}{x^2(\cos(x)-\cosh(x)+\sec(x)-\text{sech}(x))}}$,Find the limit,\displaystyle{\lim_{x\to 0}\frac{\sin(x)\sin^{-1}(x)-\sinh(x)\sinh^{-1}(x)}{x^2(\cos(x)-\cosh(x)+\sec(x)-\text{sech}(x))}},"Here is an example from the book ""Asymptotic Analysis and Perturbation Theory"" by William Paulsen. Example 1.10 p.18. Find $$\lim_{x\to 0}\frac{\sin(x)\sin^{-1}(x)-\sinh(x)\sinh^{-1}(x)}{x^2(\cos(x)-\cosh(x)+\sec(x)-\text{sech}(x))}$$ As this is an asymptotic book, the solution in the book uses the Maclaurin expansion of all the trig functions and simplifies the denominator to $x^8/6+\mathcal{O}(x^{10})$ . Then keeping just the right number of terms, the numerator is computed as $x^8/15+\mathcal{O}(x^{10})$ . Finally, $$\frac{\sin(x)\sin^{-1}(x)-\sinh(x)\sinh^{-1}(x)}{x^2(\cos(x)-\cosh(x)+\sec(x)-\text{sech}(x))}\sim\frac{x^8/15+\mathcal{O}(x^{10})}{x^8/6+\mathcal{O}(x^{10})}=\frac{2}{5}+\mathcal{O}(x^2)$$ I wonder if there are any ways to find the higher terms in the asymptotics or just any other ways to evaluate the limit. Thanks in advance.","Here is an example from the book ""Asymptotic Analysis and Perturbation Theory"" by William Paulsen. Example 1.10 p.18. Find As this is an asymptotic book, the solution in the book uses the Maclaurin expansion of all the trig functions and simplifies the denominator to . Then keeping just the right number of terms, the numerator is computed as . Finally, I wonder if there are any ways to find the higher terms in the asymptotics or just any other ways to evaluate the limit. Thanks in advance.",\lim_{x\to 0}\frac{\sin(x)\sin^{-1}(x)-\sinh(x)\sinh^{-1}(x)}{x^2(\cos(x)-\cosh(x)+\sec(x)-\text{sech}(x))} x^8/6+\mathcal{O}(x^{10}) x^8/15+\mathcal{O}(x^{10}) \frac{\sin(x)\sin^{-1}(x)-\sinh(x)\sinh^{-1}(x)}{x^2(\cos(x)-\cosh(x)+\sec(x)-\text{sech}(x))}\sim\frac{x^8/15+\mathcal{O}(x^{10})}{x^8/6+\mathcal{O}(x^{10})}=\frac{2}{5}+\mathcal{O}(x^2),"['limits', 'asymptotics', 'approximation']"
45,I don't understand the hint given when proving the limit of a log function,I don't understand the hint given when proving the limit of a log function,,"The question is to prove the following limit, $n \to \infty $ $$ \frac{n}{t} \ln({1 + \frac{t}{n}}) \to 1 $$ I could do this using something like L'Hôpital's rule but the hint is ""Use the differentiability of log at 1 to show that for each t"" I don't know how to prove it using the hint. Any help would be appreciated?","The question is to prove the following limit, I could do this using something like L'Hôpital's rule but the hint is ""Use the differentiability of log at 1 to show that for each t"" I don't know how to prove it using the hint. Any help would be appreciated?","n \to \infty  
\frac{n}{t} \ln({1 + \frac{t}{n}}) \to 1
","['limits', 'logarithms']"
46,Finding $\lim_{x\to0}\tan(x)^{1/x}$,Finding,\lim_{x\to0}\tan(x)^{1/x},"I'm not sure how to evaluate this limit. $$ \lim_{x\to0^{+}} \tan(x)^{\frac{1}{x}} $$ I've attempted to use L'Hopital's rule, but I'm not sure  if the indeterminate form (which I'll show below) from which I differentiate the numerator and denominator, is actually a true indeterminate form. Here is my process. $$ \lim_{x\to0^{+}} \tan(x)^{\frac{1}{x}} $$ $$ \lim_{x\to0^{+}} e^{\ln(\tan(x)^{\frac{1}{x}})} $$ $$ \lim_{x\to0^{+}} e^{\frac{\ln(\tan(x))}{x}} $$ $$ \exp \lim_{x\to0^{+}} \frac{\ln(\tan(x))}{x} $$ From here, direct substitution yields $ -\infty $ on top and 0 on the bottom, so what I did in order to get it into indeterminate form (as previously stated, what I do here is somewhat odd so I'm not sure if this is correct): $$ \exp \lim_{x\to0^{+}} \frac{\ln(\tan(x))}{\frac{1}{\frac{1}{x}}} $$ At this point, direct substitution gives $ -\infty $ on top, and, on the bottom as soon as 0 is plugged in we get a $ \frac{1}{0} $ . Now I know that division by zero is undefined, but the reason why I assumed that it was safe to treat it as infinity in the bottom was because, first of all, as $\frac{1}{x}$ approaches infinity it approaches $ 0 $ , and additionally I've seen a similar technique of turning $ ux $ into $ \frac{u}{\frac{1}{x}} $ and using that to our advantage in limits like $ \lim_{x\to0^{+}} x^{x} $ . From this point on: $$ \exp \lim_{x\to0^{+}} \frac{\ln(\tan(x))}{\frac{1}{\frac{1}{x}}} $$ We apply L'Hopital's Rule to yield $$ \exp \lim_{x\to0^{+}} \frac{\frac{\sec^{2}(x)}{\tan(x)}}{\frac{-1}{x^{2}}}$$ $$ \exp \lim_{x\to0^{+}} \frac{-x^{2}}{\cos(x)\sin(x)} $$ And, once again, from here I got a $ \frac{0}{0} $ indeterminate form, and this I L'Hopitaled yet another time. $$ \exp \lim_{x\to0^{+}} \frac{-2x}{\cos^{2}(x)-\sin^{2}(x)} $$ Finally, direct substitution gives $ \exp(0) $ , so $ 1 $ . Now, the issue is, that according to almost every calculator like desmos and Wolfram Alpha , it is quite clear that the limit is actually $ 0 $ , not what I have gotten. I apologize for any blatant errors, over complications, and silly mistakes in my math and post. This is my first question on the Mathematics Stack Exchange. Could somebody please point out where I have made my error and how the limit is properly evaluated? Thank You","I'm not sure how to evaluate this limit. I've attempted to use L'Hopital's rule, but I'm not sure  if the indeterminate form (which I'll show below) from which I differentiate the numerator and denominator, is actually a true indeterminate form. Here is my process. From here, direct substitution yields on top and 0 on the bottom, so what I did in order to get it into indeterminate form (as previously stated, what I do here is somewhat odd so I'm not sure if this is correct): At this point, direct substitution gives on top, and, on the bottom as soon as 0 is plugged in we get a . Now I know that division by zero is undefined, but the reason why I assumed that it was safe to treat it as infinity in the bottom was because, first of all, as approaches infinity it approaches , and additionally I've seen a similar technique of turning into and using that to our advantage in limits like . From this point on: We apply L'Hopital's Rule to yield And, once again, from here I got a indeterminate form, and this I L'Hopitaled yet another time. Finally, direct substitution gives , so . Now, the issue is, that according to almost every calculator like desmos and Wolfram Alpha , it is quite clear that the limit is actually , not what I have gotten. I apologize for any blatant errors, over complications, and silly mistakes in my math and post. This is my first question on the Mathematics Stack Exchange. Could somebody please point out where I have made my error and how the limit is properly evaluated? Thank You", \lim_{x\to0^{+}} \tan(x)^{\frac{1}{x}}   \lim_{x\to0^{+}} \tan(x)^{\frac{1}{x}}   \lim_{x\to0^{+}} e^{\ln(\tan(x)^{\frac{1}{x}})}   \lim_{x\to0^{+}} e^{\frac{\ln(\tan(x))}{x}}   \exp \lim_{x\to0^{+}} \frac{\ln(\tan(x))}{x}   -\infty   \exp \lim_{x\to0^{+}} \frac{\ln(\tan(x))}{\frac{1}{\frac{1}{x}}}   -\infty   \frac{1}{0}  \frac{1}{x}  0   ux   \frac{u}{\frac{1}{x}}   \lim_{x\to0^{+}} x^{x}   \exp \lim_{x\to0^{+}} \frac{\ln(\tan(x))}{\frac{1}{\frac{1}{x}}}   \exp \lim_{x\to0^{+}} \frac{\frac{\sec^{2}(x)}{\tan(x)}}{\frac{-1}{x^{2}}}  \exp \lim_{x\to0^{+}} \frac{-x^{2}}{\cos(x)\sin(x)}   \frac{0}{0}   \exp \lim_{x\to0^{+}} \frac{-2x}{\cos^{2}(x)-\sin^{2}(x)}   \exp(0)   1   0 ,['limits']
47,Evaluating $\lim_{n\to \infty} \sin(\sqrt{n^2+1}\pi)$. (WolframAlpha says it doesn't exist; I get $0$.),Evaluating . (WolframAlpha says it doesn't exist; I get .),\lim_{n\to \infty} \sin(\sqrt{n^2+1}\pi) 0,"I have tried to solve limit, which wolfram says that DNE, but according to my calculations it is equal to 0. Limit is given below $$\begin{align} \lim_{n\to \infty} \sin(\sqrt{n^2+1}\pi) &=\sin(\sqrt{n^2+1}\pi-n\pi+n\pi) \\ &=(-1)^n\sin(\sqrt{n^2+1}\pi-n\pi) \\ &=(-1)^n\sin\left(\frac{(\sqrt{n^2+1}\pi-n\pi)(\sqrt{n^2+1}\pi+n\pi)}{(\sqrt{n^2+1}\pi+n\pi)}\right) \\ &=(-1)^n\sin\left(\frac{n^2\pi^2+\pi^2-n^2\pi^2}{\sqrt{n^2+1}\pi+n\pi}\right) \\ &=(-1)^n\sin\left(\frac{\pi^2}{n\pi(\sqrt{1+\frac{1}{n^2}}+1}\right) \\ &=0  \end{align}$$ It is because denominator of sin goes to infinity so everything inside sin goes to 0. as we know, sin of that would go to 0 too. And we know that $(-1)^n$ is bounded so we got that bounded * 0 has to be equal to 0. Am I doing some mistake here ?","I have tried to solve limit, which wolfram says that DNE, but according to my calculations it is equal to 0. Limit is given below It is because denominator of sin goes to infinity so everything inside sin goes to 0. as we know, sin of that would go to 0 too. And we know that is bounded so we got that bounded * 0 has to be equal to 0. Am I doing some mistake here ?","\begin{align}
\lim_{n\to \infty} \sin(\sqrt{n^2+1}\pi)
&=\sin(\sqrt{n^2+1}\pi-n\pi+n\pi) \\
&=(-1)^n\sin(\sqrt{n^2+1}\pi-n\pi) \\
&=(-1)^n\sin\left(\frac{(\sqrt{n^2+1}\pi-n\pi)(\sqrt{n^2+1}\pi+n\pi)}{(\sqrt{n^2+1}\pi+n\pi)}\right) \\
&=(-1)^n\sin\left(\frac{n^2\pi^2+\pi^2-n^2\pi^2}{\sqrt{n^2+1}\pi+n\pi}\right) \\
&=(-1)^n\sin\left(\frac{\pi^2}{n\pi(\sqrt{1+\frac{1}{n^2}}+1}\right) \\
&=0 
\end{align} (-1)^n",['limits']
48,Evaluate $\lim_{n\to \infty}{1+{1\over 2}+\cdots +{1\over n}\over (\pi ^n +e^n)^{1\over n}\log_e n}$,Evaluate,\lim_{n\to \infty}{1+{1\over 2}+\cdots +{1\over n}\over (\pi ^n +e^n)^{1\over n}\log_e n},Evaluate $$\lim_{n\to \infty}{1+{1\over 2}+\cdots +{1\over n}\over (\pi ^n +e^n)^{1\over n}\log_e n}.$$ My attempt: $${1\over \pi}\lim_{n\to \infty}{1+{1\over 2}+\cdots +{1\over n}\over (1 +({e\over \pi})^n)^{1\over n}\log_e n}={1\over \pi}\lim_{n\to \infty}{1+{1\over 2}+\cdots +{1\over n}\over \log_e n}={1\over \pi}\times 1.$$ As $\lim_{n\to \infty}(1 +({e\over \pi})^n)^{1\over n}=1$ . Is there any mistake in this. If so please rectify this. Also any other way to solve this will be appreciated. Thanks in advance.,Evaluate My attempt: As . Is there any mistake in this. If so please rectify this. Also any other way to solve this will be appreciated. Thanks in advance.,\lim_{n\to \infty}{1+{1\over 2}+\cdots +{1\over n}\over (\pi ^n +e^n)^{1\over n}\log_e n}. {1\over \pi}\lim_{n\to \infty}{1+{1\over 2}+\cdots +{1\over n}\over (1 +({e\over \pi})^n)^{1\over n}\log_e n}={1\over \pi}\lim_{n\to \infty}{1+{1\over 2}+\cdots +{1\over n}\over \log_e n}={1\over \pi}\times 1. \lim_{n\to \infty}(1 +({e\over \pi})^n)^{1\over n}=1,"['limits', 'solution-verification']"
49,Function that makes limit finite,Function that makes limit finite,,"Question: Let $n > 0$ . How can I find a function $f:\mathbb{N}\rightarrow\mathbb{R}^+$ such that $$ \lim_{n\to\infty} \frac{f(n)^2}{n} \log \left(\frac{f(n)}{n}\right) = L $$ with $0<L<\infty$ ? Background : The term above appears in my research on subexponential bounds for binary words containing a limited number of ones. I have been able to elimate all other terms, but I am stuck with this one. What I tried so far: I applied L'Hôpital's rule to get $$ \lim_{n\to\infty} \frac{\log\left(\frac{f(n)}{n}\right)}{\frac{-n}{f(n)^2}} = \lim_{n\to\infty} \frac{\frac{f'(n)}{f(n)}-\frac{1}{n}}{\frac{1}{f(n)^2}-\frac{2nf'(n)}{f(n)^3}} $$ which got rid of the $\log()$ . Since the limit should be finite, it seems to me that $\lim_{n\to\infty} \frac{f(n)}{\sqrt{n}} < \infty$ , but I haven't been able to come up with an $f(n)$ that doesn't lead to $L=0$ .","Question: Let . How can I find a function such that with ? Background : The term above appears in my research on subexponential bounds for binary words containing a limited number of ones. I have been able to elimate all other terms, but I am stuck with this one. What I tried so far: I applied L'Hôpital's rule to get which got rid of the . Since the limit should be finite, it seems to me that , but I haven't been able to come up with an that doesn't lead to .","n > 0 f:\mathbb{N}\rightarrow\mathbb{R}^+ 
\lim_{n\to\infty} \frac{f(n)^2}{n} \log \left(\frac{f(n)}{n}\right) = L
 0<L<\infty 
\lim_{n\to\infty} \frac{\log\left(\frac{f(n)}{n}\right)}{\frac{-n}{f(n)^2}} = \lim_{n\to\infty} \frac{\frac{f'(n)}{f(n)}-\frac{1}{n}}{\frac{1}{f(n)^2}-\frac{2nf'(n)}{f(n)^3}}
 \log() \lim_{n\to\infty} \frac{f(n)}{\sqrt{n}} < \infty f(n) L=0","['limits', 'logarithms']"
50,Interchanging a limit and a parametric improper integral,Interchanging a limit and a parametric improper integral,,"Suppose I have the limit: $$\lim _{t\to 0^+}\int _0^{\sqrt{\sqrt{t}+4}}\sqrt{1+\frac{t}{4\sqrt{x}}}\:dx$$ How can I prove that the limit is $2$ ? It is easy to prove that for all $t > 0$ the improper inegral converges by using the limit comparison test (the problem is at x = 0). I also see that the upper bound approaches $2$ . If I try to write the improper integral as a limit of a proper integral I get: $$\lim _{t\to 0^+}\:\left(\lim _{a\to 0^+}\int _a^{\sqrt{\sqrt{t}+4}}\sqrt{1+\frac{t}{4\sqrt{x}}}\:dx\right)$$ However, I don't know how to deal with an iterated limit. When can I switch the order? Is it even the proper way to tackle the limit? Note that I haven't learned measure theory so I would prefer a solution which doesn't require it.","Suppose I have the limit: How can I prove that the limit is ? It is easy to prove that for all the improper inegral converges by using the limit comparison test (the problem is at x = 0). I also see that the upper bound approaches . If I try to write the improper integral as a limit of a proper integral I get: However, I don't know how to deal with an iterated limit. When can I switch the order? Is it even the proper way to tackle the limit? Note that I haven't learned measure theory so I would prefer a solution which doesn't require it.",\lim _{t\to 0^+}\int _0^{\sqrt{\sqrt{t}+4}}\sqrt{1+\frac{t}{4\sqrt{x}}}\:dx 2 t > 0 2 \lim _{t\to 0^+}\:\left(\lim _{a\to 0^+}\int _a^{\sqrt{\sqrt{t}+4}}\sqrt{1+\frac{t}{4\sqrt{x}}}\:dx\right),"['limits', 'definite-integrals', 'improper-integrals', 'leibniz-integral-rule']"
51,Why do I have to perform polynomial division when trying to find slant asymptotes,Why do I have to perform polynomial division when trying to find slant asymptotes,,"When trying to find the slant asymptote of $\frac{2x^2+x}{x-3}$ , the way I thought was correct is to divide everything by $x$ to get $\frac{2x+1}{1-\frac{3}x}$ . All that was left was to say that as $x$ tends to $\infty$ , $\frac{3}x$ tends to $0$ , so the asymptote is $2x+1$ . Spoiler: it was not. If I would do it the polynomial division way, I would get that the asymptote is $2x+7$ . My question is: what is wrong with my way? Helpful link though it did not answer my question here","When trying to find the slant asymptote of , the way I thought was correct is to divide everything by to get . All that was left was to say that as tends to , tends to , so the asymptote is . Spoiler: it was not. If I would do it the polynomial division way, I would get that the asymptote is . My question is: what is wrong with my way? Helpful link though it did not answer my question here",\frac{2x^2+x}{x-3} x \frac{2x+1}{1-\frac{3}x} x \infty \frac{3}x 0 2x+1 2x+7,"['real-analysis', 'limits', 'asymptotics', 'rational-functions']"
52,"If $f(x)=\frac{1}{3} \biggl ( f(x+1)+\frac{5}{f(x+2)}\biggl)$ and $f(x)>0$, $\forall$ $x\in \mathbb R$ then $\lim_{x \rightarrow \infty} f(x)$ is?","If  and ,   then  is?",f(x)=\frac{1}{3} \biggl ( f(x+1)+\frac{5}{f(x+2)}\biggl) f(x)>0 \forall x\in \mathbb R \lim_{x \rightarrow \infty} f(x),"If $f(x)=\frac{1}{3} \biggl ( f(x+1)+\frac{5}{f(x+2)}\biggl)$ and $f(x)>0$ , $\forall$ $x\in \mathbb R$ then $\lim_{x \rightarrow \infty} f(x)$ is? Doubt: In solution provided in book they assumed that $\displaystyle \lim_{x \rightarrow \infty} f(x)=\displaystyle \lim_{x \rightarrow \infty}f(x+1)=\displaystyle \lim_{x \rightarrow \infty}f(x+2)=l$ . How can they all be equal?","If and , then is? Doubt: In solution provided in book they assumed that . How can they all be equal?",f(x)=\frac{1}{3} \biggl ( f(x+1)+\frac{5}{f(x+2)}\biggl) f(x)>0 \forall x\in \mathbb R \lim_{x \rightarrow \infty} f(x) \displaystyle \lim_{x \rightarrow \infty} f(x)=\displaystyle \lim_{x \rightarrow \infty}f(x+1)=\displaystyle \lim_{x \rightarrow \infty}f(x+2)=l,"['calculus', 'limits', 'limits-without-lhopital']"
53,$~A:=\text{matrix} ~\rightarrow~\lim_{n\to\infty}A^{n}=?~;~$How should I approach against it first?,How should I approach against it first?,~A:=\text{matrix} ~\rightarrow~\lim_{n\to\infty}A^{n}=?~;~,"$$A:=\begin{pmatrix} \alpha&1-\alpha\\1-\beta&\beta\\\end{pmatrix}$$ $$\left(0<\alpha,\beta<1\right)~~\wedge~~\left(\alpha+\beta\neq 1\right)$$ $$\underbrace{\lim_{n\to\infty}A^{n}}_{\text{What can I do?}}$$ The problem didn't specified whether $~n~$ is an natural number. I think this problem is of a quite typical problem. $$\det\left(B-\lambda I\right)$$ $$=\det\left( \begin{matrix} \alpha-\lambda&1-\alpha\\ 1-\beta&\beta-\lambda\\ \end{matrix}\right)$$ $$=\det\left(\left(\alpha-\lambda\right)\left(\beta-\lambda\right)-\left(1-\alpha\right)\left(1-\beta\right)\right)$$ $$=\det\left(\left(\lambda-\alpha\right)\left(\lambda-\beta\right)-\left(\alpha-1\right)\left(\beta-1\right)\right)$$ $$=\det\left(\lambda^{2}-\left(\alpha+\beta\right)\lambda+\alpha\beta-\left(\alpha\beta-\alpha-\beta+1\right)\right)$$ $$=\det\left(\lambda^{2}-\left(\alpha+\beta\right)\lambda+\alpha\beta-\alpha\beta+\alpha+\beta-1\right)$$ $$=\det\left(\lambda^{2}-\left(\alpha+\beta\right)\lambda+\left(\left(\alpha+\beta\right)-1\right)\right)$$ $$\lambda=\frac{\left(\alpha+\beta\right)\pm\sqrt{\left(\alpha+\beta\right)^{2}-4\left(\left(\alpha+\beta\right)-1\right)}}{2}$$ About inside the square root. $$\left(\alpha+\beta\right)^{2}-4\left(\left(\alpha+\beta\right)-1\right)$$ $$=\left(\alpha+\beta\right)^{2}-4\left(\alpha+\beta\right)+4$$ $$=\left(\left(\alpha+\beta\right)-2\right)^{2}\geq0$$ $$\therefore~~~\lambda=\frac{\left(\alpha+\beta\right)\pm\sqrt{\left(\left(\alpha+\beta\right)-2\right)^{2}}}{2}$$ $$=\frac{\left(\alpha+\beta\right)\pm\sqrt{\left(2-\left(\alpha+\beta\right)\right)^{2}}}{2}$$ $$=\frac{\left(\alpha+\beta\right)\pm\left|2-\left(\alpha+\beta\right)\right|}{2}$$ Since $~\alpha+\beta<2~$ is held, $$\lambda=\frac{\left(\alpha+\beta\right)\pm\left(2-\left(\alpha+\beta\right)\right)}{2}~~\leftarrow~~\text{Removed operator of absolute value}$$ $$\lambda^{+}=\frac{\left(\alpha+\beta\right)+\left(2-\left(\alpha+\beta\right)\right)}{2}$$ $$=1$$ $$\lambda^{-}=\frac{\left(\alpha+\beta\right)-\left(2-\left(\alpha+\beta\right)\right)}{2}$$ $$=\frac{\left(\alpha+\beta\right)-2+\left(\alpha+\beta\right)}{2}$$ $$=\frac{2\left(\alpha+\beta\right)-2}{2}$$ $$=\left(\alpha+\beta\right)-1$$ $$\therefore~~~\lambda=1,\underbrace{\left(\alpha+\beta\right)-1}_{\neq0}$$ $$p_{A}\left(x\right)=x^{2}-sx+s-1$$ $$n\in\mathbb{N}_{\geq2}$$ $$q\left(x\right)=n-2~\text{degree polynomial}$$ $$a_{n},b_{n}\in\mathbb{R}$$ $$\underbrace{x^{n}=q\left(x\right)p_{A}\left(x\right)+a_{n}x+b_{n}}_{\text{I've been struggling to derive it}}$$ $$x^{n}=q\left(x\right)p_{A}\left(x\right)+a_{n}x+b_{n}$$ $$=\left\{\text{const}_{n-2}x^{n-2}+\sum_{i=0}^{n-3?}\text{const}_{i}x^{i}\right\}\left(x^{2}-sx+s-1\right)+a_{n}x+b_{n}$$ About above, at least, I can understand that RHS of the above equation is n degree polynomial but unable to prove that other $~x^{i}~~\leftrightarrow~~i\in\mathbb{N}\setminus\left\{n-2\right\}~$ disappears. I think as $~n~$ is greater than 2, then any const takes zero hence $~a_n, b_n~$ is always zero except as n is 2.","The problem didn't specified whether is an natural number. I think this problem is of a quite typical problem. About inside the square root. Since is held, About above, at least, I can understand that RHS of the above equation is n degree polynomial but unable to prove that other disappears. I think as is greater than 2, then any const takes zero hence is always zero except as n is 2.","A:=\begin{pmatrix} \alpha&1-\alpha\\1-\beta&\beta\\\end{pmatrix} \left(0<\alpha,\beta<1\right)~~\wedge~~\left(\alpha+\beta\neq 1\right) \underbrace{\lim_{n\to\infty}A^{n}}_{\text{What can I do?}} ~n~ \det\left(B-\lambda I\right) =\det\left( \begin{matrix} \alpha-\lambda&1-\alpha\\ 1-\beta&\beta-\lambda\\ \end{matrix}\right) =\det\left(\left(\alpha-\lambda\right)\left(\beta-\lambda\right)-\left(1-\alpha\right)\left(1-\beta\right)\right) =\det\left(\left(\lambda-\alpha\right)\left(\lambda-\beta\right)-\left(\alpha-1\right)\left(\beta-1\right)\right) =\det\left(\lambda^{2}-\left(\alpha+\beta\right)\lambda+\alpha\beta-\left(\alpha\beta-\alpha-\beta+1\right)\right) =\det\left(\lambda^{2}-\left(\alpha+\beta\right)\lambda+\alpha\beta-\alpha\beta+\alpha+\beta-1\right) =\det\left(\lambda^{2}-\left(\alpha+\beta\right)\lambda+\left(\left(\alpha+\beta\right)-1\right)\right) \lambda=\frac{\left(\alpha+\beta\right)\pm\sqrt{\left(\alpha+\beta\right)^{2}-4\left(\left(\alpha+\beta\right)-1\right)}}{2} \left(\alpha+\beta\right)^{2}-4\left(\left(\alpha+\beta\right)-1\right) =\left(\alpha+\beta\right)^{2}-4\left(\alpha+\beta\right)+4 =\left(\left(\alpha+\beta\right)-2\right)^{2}\geq0 \therefore~~~\lambda=\frac{\left(\alpha+\beta\right)\pm\sqrt{\left(\left(\alpha+\beta\right)-2\right)^{2}}}{2} =\frac{\left(\alpha+\beta\right)\pm\sqrt{\left(2-\left(\alpha+\beta\right)\right)^{2}}}{2} =\frac{\left(\alpha+\beta\right)\pm\left|2-\left(\alpha+\beta\right)\right|}{2} ~\alpha+\beta<2~ \lambda=\frac{\left(\alpha+\beta\right)\pm\left(2-\left(\alpha+\beta\right)\right)}{2}~~\leftarrow~~\text{Removed operator of absolute value} \lambda^{+}=\frac{\left(\alpha+\beta\right)+\left(2-\left(\alpha+\beta\right)\right)}{2} =1 \lambda^{-}=\frac{\left(\alpha+\beta\right)-\left(2-\left(\alpha+\beta\right)\right)}{2} =\frac{\left(\alpha+\beta\right)-2+\left(\alpha+\beta\right)}{2} =\frac{2\left(\alpha+\beta\right)-2}{2} =\left(\alpha+\beta\right)-1 \therefore~~~\lambda=1,\underbrace{\left(\alpha+\beta\right)-1}_{\neq0} p_{A}\left(x\right)=x^{2}-sx+s-1 n\in\mathbb{N}_{\geq2} q\left(x\right)=n-2~\text{degree polynomial} a_{n},b_{n}\in\mathbb{R} \underbrace{x^{n}=q\left(x\right)p_{A}\left(x\right)+a_{n}x+b_{n}}_{\text{I've been struggling to derive it}} x^{n}=q\left(x\right)p_{A}\left(x\right)+a_{n}x+b_{n} =\left\{\text{const}_{n-2}x^{n-2}+\sum_{i=0}^{n-3?}\text{const}_{i}x^{i}\right\}\left(x^{2}-sx+s-1\right)+a_{n}x+b_{n} ~x^{i}~~\leftrightarrow~~i\in\mathbb{N}\setminus\left\{n-2\right\}~ ~n~ ~a_n, b_n~","['linear-algebra', 'limits', 'systems-of-equations', 'exponentiation']"
54,"Points of discontinuity of $\left[\frac{f(x)}3\right], f(x)=\lim_{n\to\infty}\ln(\sqrt{e^{\cos x}\sqrt{e^{3\cos x}...\sqrt{e^{(2n+1)\cos x}}}})$",Points of discontinuity of,"\left[\frac{f(x)}3\right], f(x)=\lim_{n\to\infty}\ln(\sqrt{e^{\cos x}\sqrt{e^{3\cos x}...\sqrt{e^{(2n+1)\cos x}}}})","Let $f(x)=\lim_{n\to\infty}\ln\left(\sqrt{e^{\cos x}\sqrt{e^{3\cos x}\sqrt{e^{5\cos x}...\sqrt{e^{(2n+1)\cos x}}}}}\right)$ and if $g(x)=\left[\frac{f(x)}3\right]$ , then the number of points in $[0,2\pi]$ where $g(x)$ is discontinuous, is/are (where $[*]$ represents greatest integer function)... $\cos x$ varies from $-1$ to $1$ . If $\cos x=-1$ then as $n\to\infty$ , $e^{(2n+1)\cos x}=0$ If $\cos x=0$ then as $n\to\infty$ , $e^{(2n+1)\cos x}=1$ If $\cos x=\infty$ then as $n\to\infty$ , $e^{(2n+1)\cos x}=\infty$ Also, since $\cos x$ is changing these values in continuous manner, can we use that to comment about the continuity of $f(x)$ ? But before that, I would need to solve the limit. Not able to do so. Can you give any pointers? Thanks. EDIT: $f(x)=\lim_{n\to\infty}\ln\left(e^{\left(\frac12+\frac3{2^2}+\frac5{2^3}+...+\frac{(2n+1)}{2^{n+1}}\right)\cos x}\right)$ Let $$S=\frac12+\frac3{2^2}+\frac5{2^3}+...+\frac{(2n+1)}{2^{n+1}}\\\frac S2=\frac1{2^2}+\frac3{2^3}+\frac5{2^4}+...+\frac{(2n+1)}{2^{n+2}}$$ Subtracting, $$\frac S2=\frac12+\frac12+...\text{(n+1) times}-\frac{2n+1}{2^{n+2}}=\frac {n+1}2-\frac{2n+1}{2^{n+2}}\\\implies S=n+1-\frac{2n+1}{2^{n+1}}$$ I think my $S$ is coming out to be $\infty$ . Can you point out the mistake? Thanks. EDIT $2$ : After reading the comments, I reworked and found $S=3$ . Thus, $f(x)=3\cos x\implies\left[\frac{f(x)}3\right]=[\cos x]$ Thus, there are $4$ points of discontinuity $\{0,\frac\pi2,\frac{3\pi}2,2\pi\}$ .","Let and if , then the number of points in where is discontinuous, is/are (where represents greatest integer function)... varies from to . If then as , If then as , If then as , Also, since is changing these values in continuous manner, can we use that to comment about the continuity of ? But before that, I would need to solve the limit. Not able to do so. Can you give any pointers? Thanks. EDIT: Let Subtracting, I think my is coming out to be . Can you point out the mistake? Thanks. EDIT : After reading the comments, I reworked and found . Thus, Thus, there are points of discontinuity .","f(x)=\lim_{n\to\infty}\ln\left(\sqrt{e^{\cos x}\sqrt{e^{3\cos x}\sqrt{e^{5\cos x}...\sqrt{e^{(2n+1)\cos x}}}}}\right) g(x)=\left[\frac{f(x)}3\right] [0,2\pi] g(x) [*] \cos x -1 1 \cos x=-1 n\to\infty e^{(2n+1)\cos x}=0 \cos x=0 n\to\infty e^{(2n+1)\cos x}=1 \cos x=\infty n\to\infty e^{(2n+1)\cos x}=\infty \cos x f(x) f(x)=\lim_{n\to\infty}\ln\left(e^{\left(\frac12+\frac3{2^2}+\frac5{2^3}+...+\frac{(2n+1)}{2^{n+1}}\right)\cos x}\right) S=\frac12+\frac3{2^2}+\frac5{2^3}+...+\frac{(2n+1)}{2^{n+1}}\\\frac S2=\frac1{2^2}+\frac3{2^3}+\frac5{2^4}+...+\frac{(2n+1)}{2^{n+2}} \frac S2=\frac12+\frac12+...\text{(n+1) times}-\frac{2n+1}{2^{n+2}}=\frac {n+1}2-\frac{2n+1}{2^{n+2}}\\\implies S=n+1-\frac{2n+1}{2^{n+1}} S \infty 2 S=3 f(x)=3\cos x\implies\left[\frac{f(x)}3\right]=[\cos x] 4 \{0,\frac\pi2,\frac{3\pi}2,2\pi\}","['calculus', 'limits', 'functions', 'trigonometry', 'exponential-function']"
55,Finding the limit as $x$ tends to $0^{+}$,Finding the limit as  tends to,x 0^{+},Question: $$\lim_{x\rightarrow 0^{+}} x \ \tan(\frac{\pi }{2}-x)$$ My Work: To begin with I re-arranged the the question to the $\frac{\infty}{\infty}$ form: $$\lim_{x\rightarrow 0^{+}} \frac{\tan(\frac{\pi }{2}-x)}{\frac{1}{x}}$$ Then applying L'Hospital's rule I got the following: $$\lim_{x\rightarrow 0^{+}}\frac{\sec ^{2}(\frac{\pi }{2}-x)}{\frac{1}{x^{2}}}$$ which I rearranged to $$\lim_{x\rightarrow 0^{+}} \frac{x^{2}}{\cos ^{2}(\frac{\pi}{2}-x)}$$ Applying L'Hospital's rule again I got the following: $$\lim_{x\rightarrow 0^{+}} \frac{2x}{(-2)(-1))\cos(\frac{\pi }{2}-x)\sin(\frac{\pi }{2}-x) )} \ = \lim_{x\rightarrow 0^{+}} \frac{2x}{\sin(\pi-2x) )}$$ Above I used the property $\sin(2x) = 2\sin(x) \ \cos(x) $ And then applying L'Hospital's rule for the final time I got the following: $$ \lim_{x\rightarrow 0^{+}} \frac{-1}{\cos(\pi-2x) )} = 1$$ Is my answer and method correct?,Question: My Work: To begin with I re-arranged the the question to the form: Then applying L'Hospital's rule I got the following: which I rearranged to Applying L'Hospital's rule again I got the following: Above I used the property And then applying L'Hospital's rule for the final time I got the following: Is my answer and method correct?,\lim_{x\rightarrow 0^{+}} x \ \tan(\frac{\pi }{2}-x) \frac{\infty}{\infty} \lim_{x\rightarrow 0^{+}} \frac{\tan(\frac{\pi }{2}-x)}{\frac{1}{x}} \lim_{x\rightarrow 0^{+}}\frac{\sec ^{2}(\frac{\pi }{2}-x)}{\frac{1}{x^{2}}} \lim_{x\rightarrow 0^{+}} \frac{x^{2}}{\cos ^{2}(\frac{\pi}{2}-x)} \lim_{x\rightarrow 0^{+}} \frac{2x}{(-2)(-1))\cos(\frac{\pi }{2}-x)\sin(\frac{\pi }{2}-x) )} \ = \lim_{x\rightarrow 0^{+}} \frac{2x}{\sin(\pi-2x) )} \sin(2x) = 2\sin(x) \ \cos(x)   \lim_{x\rightarrow 0^{+}} \frac{-1}{\cos(\pi-2x) )} = 1,"['limits', 'derivatives', 'self-learning']"
56,Does the limit $\lim_{x\to a^+}\frac{\cos{x}\ln(x-a)}{\ln(e^x-e^a)} $ exist?,Does the limit  exist?,\lim_{x\to a^+}\frac{\cos{x}\ln(x-a)}{\ln(e^x-e^a)} ,"I am very confused about the limit of the expression below: $$\lim_{x\to a^+}\frac{\cos{x}\ln(x-a)}{\ln(e^x-e^a)} $$ By using L'Hospital's rule, I was managed to find the result which was $\cos a$ , same as other answers that I could possibly find on the Internet. However, when I used GeoGebra to sketch the graph, the value of $f(x)$ tends to jump to infinity, both negative and positive. I wonder if my result was wrong, or the limit does not exist at all? (In the picture below, I chose $a=15$ for easy re-check). Thanks in advance!","I am very confused about the limit of the expression below: By using L'Hospital's rule, I was managed to find the result which was , same as other answers that I could possibly find on the Internet. However, when I used GeoGebra to sketch the graph, the value of tends to jump to infinity, both negative and positive. I wonder if my result was wrong, or the limit does not exist at all? (In the picture below, I chose for easy re-check). Thanks in advance!",\lim_{x\to a^+}\frac{\cos{x}\ln(x-a)}{\ln(e^x-e^a)}  \cos a f(x) a=15,"['calculus', 'limits']"
57,What's wrong with this way of manipulating Grandi's series,What's wrong with this way of manipulating Grandi's series,,"Problem: evaluate $S = 1 - 1 + 1 - 1 + 1-\cdots$ $1 = \lim_{t \rightarrow 1^{-}} t^n$ for any positive integer $n$ . Here $t \rightarrow 1^{-}$ means $t \rightarrow 1$ and $t<1$ . $$S = \lim_{t \rightarrow 1^{-} } 1 - \lim_{t \rightarrow 1^{-} } t + \lim_{t \rightarrow 1^{-} } t^2 - \lim_{t \rightarrow 1^{-} } t^3 + \cdots = \lim_{t \rightarrow 1^{-}} (1-t+t^2-t^3 + t^4 - t^5 +\cdots ) = \lim_{t \rightarrow 1^{-}} \frac{1}{1+t} = \frac{1}{2}$$ What's wrong with this reasoning? It seems like the limit exists for $1 = \lim_{t \rightarrow 1^{-}} t^n$ , so every step seems to follow?","Problem: evaluate for any positive integer . Here means and . What's wrong with this reasoning? It seems like the limit exists for , so every step seems to follow?",S = 1 - 1 + 1 - 1 + 1-\cdots 1 = \lim_{t \rightarrow 1^{-}} t^n n t \rightarrow 1^{-} t \rightarrow 1 t<1 S = \lim_{t \rightarrow 1^{-} } 1 - \lim_{t \rightarrow 1^{-} } t + \lim_{t \rightarrow 1^{-} } t^2 - \lim_{t \rightarrow 1^{-} } t^3 + \cdots = \lim_{t \rightarrow 1^{-}} (1-t+t^2-t^3 + t^4 - t^5 +\cdots ) = \lim_{t \rightarrow 1^{-}} \frac{1}{1+t} = \frac{1}{2} 1 = \lim_{t \rightarrow 1^{-}} t^n,"['real-analysis', 'limits', 'infinity', 'fake-proofs']"
58,Calculate $\lim_{x\rightarrow0}\frac{(e^{\sin x}+ \sin x)^{\frac{1}{\sin x}}-(e^{\tan x}+ \tan x)^{\frac{1}{\tan x}}}{x^3}$ [closed],Calculate  [closed],\lim_{x\rightarrow0}\frac{(e^{\sin x}+ \sin x)^{\frac{1}{\sin x}}-(e^{\tan x}+ \tan x)^{\frac{1}{\tan x}}}{x^3},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question How to calculate the following limit? $$\lim_{x\rightarrow0}\frac{(e^{\sin x}+ \sin x)^{\frac{1}{\sin x}}-(e^{\tan x}+ \tan x)^{\frac{1}{\tan x}}}{x^3}$$ I thought of L'Hopital's rule, Taylor expansion, and limit the form of $e^x$ , but the presence of $\sin x$ and $\tan x$ make it hard to apply them. Could anyone give me a hint?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question How to calculate the following limit? I thought of L'Hopital's rule, Taylor expansion, and limit the form of , but the presence of and make it hard to apply them. Could anyone give me a hint?",\lim_{x\rightarrow0}\frac{(e^{\sin x}+ \sin x)^{\frac{1}{\sin x}}-(e^{\tan x}+ \tan x)^{\frac{1}{\tan x}}}{x^3} e^x \sin x \tan x,"['calculus', 'limits']"
59,Proving the existence/non-existence of $\lim_{x\rightarrow0} x\tan\frac1x$,Proving the existence/non-existence of,\lim_{x\rightarrow0} x\tan\frac1x,"Find $$\lim_{x\rightarrow0} x\tan\frac1x$$ Now I tried to find the form of the limit ( $0/0$ or $0\cdot \infty$ or $\infty/\infty$ ), but as $x\rightarrow 0$ , $\tan(1/x)$ tends to $\tan \infty$ , and since $\tan x$ is unbounded unlike $\sin x$ or $\cos x$ , no particular value or range can be assumed for $\tan(1/x)$ . Then I tried to find LHL and RHL. Let $\lim_{x\rightarrow0^+} x\tan{(1/x)}=L$ . Then $\lim_{x\rightarrow0^-} x\tan{(1/x)}=-L$ , since $x$ is approaching from the negative side, the input $1/x$ of $\tan$ is the negative of the input in RHL, and $\tan (-x)=-\tan x$ Now if the limit exists, then $LHL=RHL$ , thus $L=0$ . Thus I got that if the limit exists, then it must be equal to $0$ . But this doesn't confirm that the limit exists (and it doesn't). Please help me in proving that the limit doesn't exist, and also please point out the mistakes (if any) in the argument I presented above (sorry for I might be weak in limits and the basics of it) EDIT: As pointed out by Shubham in the comments, I forgot to take the sign of $x$ too in the $LHL$ , thus rendering the argument which proved $L=0$ moot. THANK YOU","Find Now I tried to find the form of the limit ( or or ), but as , tends to , and since is unbounded unlike or , no particular value or range can be assumed for . Then I tried to find LHL and RHL. Let . Then , since is approaching from the negative side, the input of is the negative of the input in RHL, and Now if the limit exists, then , thus . Thus I got that if the limit exists, then it must be equal to . But this doesn't confirm that the limit exists (and it doesn't). Please help me in proving that the limit doesn't exist, and also please point out the mistakes (if any) in the argument I presented above (sorry for I might be weak in limits and the basics of it) EDIT: As pointed out by Shubham in the comments, I forgot to take the sign of too in the , thus rendering the argument which proved moot. THANK YOU",\lim_{x\rightarrow0} x\tan\frac1x 0/0 0\cdot \infty \infty/\infty x\rightarrow 0 \tan(1/x) \tan \infty \tan x \sin x \cos x \tan(1/x) \lim_{x\rightarrow0^+} x\tan{(1/x)}=L \lim_{x\rightarrow0^-} x\tan{(1/x)}=-L x 1/x \tan \tan (-x)=-\tan x LHL=RHL L=0 0 x LHL L=0,"['real-analysis', 'calculus', 'limits']"
60,"How to prove $\lim_{h\rightarrow 0} \frac{\exp\left\{\int_t ^{t+h}A(s)\,\mathrm{d}s\right\}-I_n}{h}=A(t)$ [closed]",How to prove  [closed],"\lim_{h\rightarrow 0} \frac{\exp\left\{\int_t ^{t+h}A(s)\,\mathrm{d}s\right\}-I_n}{h}=A(t)","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let $t\mapsto A(t)\in C(\mathbb{R},M_n(\mathbb{R}))$ , it seems ""obvious"" that we should have: \begin{equation} \lim_{h\rightarrow 0} \frac{\exp\left\{\int_t ^{t+h}A(s)\,\mathrm{d}s\right\}-I_n}{h}=A(t)\end{equation} However, I'm having a hard time finding rigorous proof of this result. I don't even know where to start?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let , it seems ""obvious"" that we should have: However, I'm having a hard time finding rigorous proof of this result. I don't even know where to start?","t\mapsto A(t)\in C(\mathbb{R},M_n(\mathbb{R})) \begin{equation}
\lim_{h\rightarrow 0} \frac{\exp\left\{\int_t
^{t+h}A(s)\,\mathrm{d}s\right\}-I_n}{h}=A(t)\end{equation}","['limits', 'derivatives', 'matrix-calculus', 'matrix-exponential']"
61,Existence of derivative at a point.,Existence of derivative at a point.,,"Assume that f : (a, b) → R is differentiable on (a, b) except possibly at c ∈ (a, b). Assume that lim $_{x→c}$ f '(x) exists. Prove that f '(c) exists and f ' is continuous at c. I am getting a counter example for this statement. Consider the function f(x) defined on (-1,1) by f(x) = x , x ∈ (-1,0) U (0,1) 5 , x = 0 Here f '(x) is 1 for all x ∈ (-1,0) U (0,1).Thus lim $_{x→0}$ f '(x) exists. But we know f(x) is not continuous at 0. Thus , f'(0) doesn't exist. I don't know where I have made a wrong assumption in the example. Please help.","Assume that f : (a, b) → R is differentiable on (a, b) except possibly at c ∈ (a, b). Assume that lim f '(x) exists. Prove that f '(c) exists and f ' is continuous at c. I am getting a counter example for this statement. Consider the function f(x) defined on (-1,1) by f(x) = x , x ∈ (-1,0) U (0,1) 5 , x = 0 Here f '(x) is 1 for all x ∈ (-1,0) U (0,1).Thus lim f '(x) exists. But we know f(x) is not continuous at 0. Thus , f'(0) doesn't exist. I don't know where I have made a wrong assumption in the example. Please help.",_{x→c} _{x→0},"['real-analysis', 'limits', 'functions', 'derivatives']"
62,How can I prove that the limit doesn't exist?,How can I prove that the limit doesn't exist?,,"I have to study the following limit $$\lim_{(x,y)\to(0,0)}\frac{1-\cos(\sqrt{|xy|})}{x}.$$ I think that this limit does not exist, so I'm trying to prove it. First, I discovered that, if $x=y$ , then, the limit is equal to zero. Is there any other variable changing that I can use?","I have to study the following limit I think that this limit does not exist, so I'm trying to prove it. First, I discovered that, if , then, the limit is equal to zero. Is there any other variable changing that I can use?","\lim_{(x,y)\to(0,0)}\frac{1-\cos(\sqrt{|xy|})}{x}. x=y","['calculus', 'limits', 'analysis']"
63,Transform Limit definition of $e$,Transform Limit definition of,e,"The limit definition of $e$ can be written as: $$ \lim_{x \to \infty} {\left(1 + \frac{1}{x}\right)^x} . $$ This is equal to another similar form: $$ \lim_{x \to 0} {(1 + x)^{\frac{1}{x}}} . $$ I am wondering how to prove these 2 forms are equivalent, any help is appreciated thank you.","The limit definition of can be written as: This is equal to another similar form: I am wondering how to prove these 2 forms are equivalent, any help is appreciated thank you.",e  \lim_{x \to \infty} {\left(1 + \frac{1}{x}\right)^x} .   \lim_{x \to 0} {(1 + x)^{\frac{1}{x}}} . ,"['calculus', 'limits']"
64,if $\lim _{x\rightarrow \infty}{f'(x)}=0$ then does $\lim_{x \rightarrow \infty}{f(x)}$ exist in the broad sense,if  then does  exist in the broad sense,\lim _{x\rightarrow \infty}{f'(x)}=0 \lim_{x \rightarrow \infty}{f(x)},"Let $f$ be a differentiable a function in $\mathbb{R}$ , and let $\lim _{x\rightarrow \infty}{f'(x)}=0$ Does $\lim_{x \rightarrow \infty}{f(x)}$ exist in the broad sense? I'm really lost here. This exercise is from a section on MVT, and intuitively it seems to be correct, but I can't seem to find a lead. If someone could just give me a hint that would be great. So far my best shot has been using Heine's definition of the limit, but no dice.","Let be a differentiable a function in , and let Does exist in the broad sense? I'm really lost here. This exercise is from a section on MVT, and intuitively it seems to be correct, but I can't seem to find a lead. If someone could just give me a hint that would be great. So far my best shot has been using Heine's definition of the limit, but no dice.",f \mathbb{R} \lim _{x\rightarrow \infty}{f'(x)}=0 \lim_{x \rightarrow \infty}{f(x)},"['real-analysis', 'calculus', 'limits', 'derivatives']"
65,Find the derivative using the definition of derivative (limit).,Find the derivative using the definition of derivative (limit).,,Given $f(x)=\dfrac{5x+1}{2\sqrt{x}}$ . Find $\dfrac{df(x)}{dx}=f'(x)$ using the definition of derivative. I have tried as below. \begin{align*} f'(x)&=\lim\limits_{h\to 0} \dfrac{f(x+h)-f(x)}{h}\\ 		&= \lim\limits_{h\to 0} 		\dfrac{\dfrac{5(x+h)+1}{2\sqrt{x+h}}-\dfrac{5x+1}{2\sqrt{x}}}{h}\\ 		&= \lim\limits_{h\to 0} 		\dfrac{\dfrac{\left(5(x+h)+1\right)\sqrt{x}-(5x+1)\sqrt{x+h}}{2\sqrt{x+h}\sqrt{x}}}{h}\\ 		&= \lim\limits_{h\to 0} 		\dfrac{\dfrac{5x\sqrt{x}+5h\sqrt{x}+\sqrt{x}-5x\sqrt{x+h}-\sqrt{x+h}}{2\sqrt{x+h}\sqrt{x}}}{h}\\ \end{align*} Now I can't find the limit. I confused how to simplify the limit. Anyone can give me  hint to solve it? Note: We were asked to find this derivative using $$f'(x)=\lim\limits_{h\to 0} \dfrac{f(x+h)-f(x)}{h}$$ instead of $$f(x)=\dfrac{u(x)}{v(x)}\iff f'(x)=\dfrac{u'(x)v(x)-u(x)v'(x)}{v(x)^2}.$$,Given . Find using the definition of derivative. I have tried as below. Now I can't find the limit. I confused how to simplify the limit. Anyone can give me  hint to solve it? Note: We were asked to find this derivative using instead of,"f(x)=\dfrac{5x+1}{2\sqrt{x}} \dfrac{df(x)}{dx}=f'(x) \begin{align*}
f'(x)&=\lim\limits_{h\to 0} \dfrac{f(x+h)-f(x)}{h}\\
		&= \lim\limits_{h\to 0}
		\dfrac{\dfrac{5(x+h)+1}{2\sqrt{x+h}}-\dfrac{5x+1}{2\sqrt{x}}}{h}\\
		&= \lim\limits_{h\to 0}
		\dfrac{\dfrac{\left(5(x+h)+1\right)\sqrt{x}-(5x+1)\sqrt{x+h}}{2\sqrt{x+h}\sqrt{x}}}{h}\\
		&= \lim\limits_{h\to 0}
		\dfrac{\dfrac{5x\sqrt{x}+5h\sqrt{x}+\sqrt{x}-5x\sqrt{x+h}-\sqrt{x+h}}{2\sqrt{x+h}\sqrt{x}}}{h}\\
\end{align*} f'(x)=\lim\limits_{h\to 0} \dfrac{f(x+h)-f(x)}{h} f(x)=\dfrac{u(x)}{v(x)}\iff f'(x)=\dfrac{u'(x)v(x)-u(x)v'(x)}{v(x)^2}.","['limits', 'derivatives']"
66,can we say that $\lim\limits_{x\to0} \sqrt{-x^2}=0$ even if the function domain is a singleton $\{0\}$,can we say that  even if the function domain is a singleton,\lim\limits_{x\to0} \sqrt{-x^2}=0 \{0\},"In Real analysis, the strict definition of a limit, we take a sequence of point that converging to the point a ""limit point"" . which is not verified here in this case we have only one element in the function domain : $$\lim_{x\to 0} \sqrt{-x^2}$$ but by replacing $0$ in the function we get $0$ so my question is : in a formal way can we say that $$\lim_{x\to 0} \sqrt{-x^2}=0$$","In Real analysis, the strict definition of a limit, we take a sequence of point that converging to the point a ""limit point"" . which is not verified here in this case we have only one element in the function domain : but by replacing in the function we get so my question is : in a formal way can we say that",\lim_{x\to 0} \sqrt{-x^2} 0 0 \lim_{x\to 0} \sqrt{-x^2}=0,"['real-analysis', 'limits']"
67,Misconception about evaluating limits,Misconception about evaluating limits,,"Question Find the limit of $$\lim\limits_{x\to\infty}\ \left[\frac 1 3 (3^{\frac 1 x} + 8^{\frac 1 x} + 9^{\frac 1 x})\right]^x\ .$$ My working I know that the limit is $6$ , which can be found through exponentiation. However, I would like to know why the following method (which I tried initially) gives the wrong answer of $1$ . So, I thought that, since $x \rightarrow \infty\ $ , $\frac 1 x \rightarrow 0\ $ . Thus, $\lim\limits_{x\to\infty}\ \left[\frac 1 3 (3^{\frac 1 x} + 8^{\frac 1 x} + 9^{\frac 1 x})\right]^x = [\frac 1 3 (3^0 + 8^0 + 9^0)]^{\infty} = 1^\infty = 1\ $ . Any explanations as to why my original method is incorrect will be greatly appreciated :) Edit Thanks to some helpful comments/answers, I now know that $1^\infty$ is actually not $1$ but indeterminate!","Question Find the limit of My working I know that the limit is , which can be found through exponentiation. However, I would like to know why the following method (which I tried initially) gives the wrong answer of . So, I thought that, since , . Thus, . Any explanations as to why my original method is incorrect will be greatly appreciated :) Edit Thanks to some helpful comments/answers, I now know that is actually not but indeterminate!",\lim\limits_{x\to\infty}\ \left[\frac 1 3 (3^{\frac 1 x} + 8^{\frac 1 x} + 9^{\frac 1 x})\right]^x\ . 6 1 x \rightarrow \infty\  \frac 1 x \rightarrow 0\  \lim\limits_{x\to\infty}\ \left[\frac 1 3 (3^{\frac 1 x} + 8^{\frac 1 x} + 9^{\frac 1 x})\right]^x = [\frac 1 3 (3^0 + 8^0 + 9^0)]^{\infty} = 1^\infty = 1\  1^\infty 1,"['real-analysis', 'calculus', 'limits']"
68,How can we prove that there is a number $a$ such that $\lim_{h\to 0}\frac{a^{h} -1}{h}=1$?,How can we prove that there is a number  such that ?,a \lim_{h\to 0}\frac{a^{h} -1}{h}=1,"One definition of $e$ that I am fond of is that it is the number $a$ such that $$ \lim_{h\to 0}\frac{a^{h} -1}{h}=1 $$ The reason for this is that it cuts to the heart of the special property of all exponential functions. If we have $f(x)=a^x$ , then \begin{align} f'(x)&=\lim_{\Delta x \to 0}\frac{a^{x+\Delta x} -a^x}{\Delta x} \\ &=\lim_{\Delta x \to 0}a^x\frac{a^{\Delta x} - 1}{\Delta x} \\ &=a^x\lim_{\Delta x \to 0}\frac{a^{\Delta x} - 1}{\Delta x} \end{align} However, presumably there is a caveat to this approach. We need to show that a number like $e$ exists in the first place! In other words, we need to show that $g(a)=\lim_{\Delta x \to 0}\frac{a^{\Delta x} -1}{\Delta x}$ takes the value of $1$ for some value of $a$ . How might we do this?","One definition of that I am fond of is that it is the number such that The reason for this is that it cuts to the heart of the special property of all exponential functions. If we have , then However, presumably there is a caveat to this approach. We need to show that a number like exists in the first place! In other words, we need to show that takes the value of for some value of . How might we do this?","e a 
\lim_{h\to 0}\frac{a^{h} -1}{h}=1
 f(x)=a^x \begin{align}
f'(x)&=\lim_{\Delta x \to 0}\frac{a^{x+\Delta x} -a^x}{\Delta x} \\
&=\lim_{\Delta x \to 0}a^x\frac{a^{\Delta x} - 1}{\Delta x} \\
&=a^x\lim_{\Delta x \to 0}\frac{a^{\Delta x} - 1}{\Delta x}
\end{align} e g(a)=\lim_{\Delta x \to 0}\frac{a^{\Delta x} -1}{\Delta x} 1 a","['real-analysis', 'calculus', 'limits', 'exponential-function']"
69,"Defining rigorously, the intuition of Limits","Defining rigorously, the intuition of Limits",,"This is an attempt to define rigorously from scratch, the following intuitive definition of limits: $\displaystyle{\lim_{x \to c}f(x)}=L$ means that $f(x)$ can be made arbitrarily close to $L$ by making $x$ be sufficiently close to $c$ . Given the above definition of limits, we can say that $\displaystyle{\lim_{x \to c}f(x)}=L$ means that for every $x \ne c$ in the domain of $f$ such that $f(x)\ne L$ there exists some $x_0$ in the domain of $f$ that is closer to $c$ than $x$ is and for which $f(x_0)$ is closer to $L$ than $f(x)$ is. Making $f(x)$ be arbitrarily close to $L$ : If for some $x$ you give me, I can give you some $x_0$ such that $f(x_0)$ is closer to $L$ than $f(x)$ is then we will say that $f(x)$ can be made closer to $L$ at that particular $x$ value. If I can do this for every $x\ne c$ in the domain of $f$ such that $f(x)\ne L$ then we will say that $f(x)$ can be made arbitrarily close to L . The relationship between $x$ and its corresponding $x_0$ can be stated as follows: $$|f(x)-L|>|f(x_0)-L|; f(x)\ne0$$ Making $x$ be sufficiently close to $c$ : Now that we have made the first condition true, we need $x_0$ to be closer to $c$ than $x$ is. We don't want an $x_0$ that is farther away from $c$ than $x$ is. If $f(x_0)$ does get $f$ closer to $L$ but $x_0$ is farther away from $c$ than $x$ is and we can't find any $x_0$ which: Gets $f(x)$ closer to $L$ and Is itself closer to $c$ than $x$ is. Then we would say that $\displaystyle{\lim_{x \to c}f(x)}$ does not exist. The relationship between $x$ and $x_0$ can be stated as follows: $$|x-c|>|x_0-c|;x\ne c$$ Reason for specifying that $x\ne c$ and $f(x)\ne L$ : If $x$ is exactly at $c$ then it is impossible to make $x$ be any closer to $c$ than it already is. The distance between $x$ and $c$ is $0$ and it can't be made any smaller. Similarly, $f(x)$ can't get any closer to $L$ if $f(x)=L$ . Putting it all together: $\displaystyle{\lim_{x \to c}f(x)}=L$ means that for every $x\ne c$ in the domain of $f$ such that $f(x)\ne L$ , there exists an $x_0$ in the domain of $f$ such that: $$|x-c|>|x_0-c|$$ and $$|f(x)-L|>|f(x_0)-L|$$ Is my reasoning correct? If not, where did I go wrong?","This is an attempt to define rigorously from scratch, the following intuitive definition of limits: means that can be made arbitrarily close to by making be sufficiently close to . Given the above definition of limits, we can say that means that for every in the domain of such that there exists some in the domain of that is closer to than is and for which is closer to than is. Making be arbitrarily close to : If for some you give me, I can give you some such that is closer to than is then we will say that can be made closer to at that particular value. If I can do this for every in the domain of such that then we will say that can be made arbitrarily close to L . The relationship between and its corresponding can be stated as follows: Making be sufficiently close to : Now that we have made the first condition true, we need to be closer to than is. We don't want an that is farther away from than is. If does get closer to but is farther away from than is and we can't find any which: Gets closer to and Is itself closer to than is. Then we would say that does not exist. The relationship between and can be stated as follows: Reason for specifying that and : If is exactly at then it is impossible to make be any closer to than it already is. The distance between and is and it can't be made any smaller. Similarly, can't get any closer to if . Putting it all together: means that for every in the domain of such that , there exists an in the domain of such that: and Is my reasoning correct? If not, where did I go wrong?",\displaystyle{\lim_{x \to c}f(x)}=L f(x) L x c \displaystyle{\lim_{x \to c}f(x)}=L x \ne c f f(x)\ne L x_0 f c x f(x_0) L f(x) f(x) L x x_0 f(x_0) L f(x) f(x) L x x\ne c f f(x)\ne L f(x) x x_0 |f(x)-L|>|f(x_0)-L|; f(x)\ne0 x c x_0 c x x_0 c x f(x_0) f L x_0 c x x_0 f(x) L c x \displaystyle{\lim_{x \to c}f(x)} x x_0 |x-c|>|x_0-c|;x\ne c x\ne c f(x)\ne L x c x c x c 0 f(x) L f(x)=L \displaystyle{\lim_{x \to c}f(x)}=L x\ne c f f(x)\ne L x_0 f |x-c|>|x_0-c| |f(x)-L|>|f(x_0)-L|,"['limits', 'epsilon-delta']"
70,A limits with substitution,A limits with substitution,,"Evaluate $$\lim_{n\rightarrow \infty}\frac{\sqrt{1-x_0^2}}{x_1x_2...x_n}$$ where $x_{r+1}=\sqrt{\frac{1+x_r}{2}}; 0\leq r<n;\space r,n\in \mathbb{Z}$ My teacher says to substitute $x_0=\cos(\theta)$ but I don't understand why that is the case. Is the $\cos(\theta)$ substitution arbitrary or is there any underlying logic to it?",Evaluate where My teacher says to substitute but I don't understand why that is the case. Is the substitution arbitrary or is there any underlying logic to it?,"\lim_{n\rightarrow \infty}\frac{\sqrt{1-x_0^2}}{x_1x_2...x_n} x_{r+1}=\sqrt{\frac{1+x_r}{2}}; 0\leq r<n;\space r,n\in \mathbb{Z} x_0=\cos(\theta) \cos(\theta)",['limits']
71,Why does $\frac{|\sin\theta|}{2}<\frac{|\theta|}{2}<\frac{|\tan\theta|}{2}$ not imply that $1>\lim_{\theta\to 0}\frac{\sin\theta}{\theta}>1$?,Why does  not imply that ?,\frac{|\sin\theta|}{2}<\frac{|\theta|}{2}<\frac{|\tan\theta|}{2} 1>\lim_{\theta\to 0}\frac{\sin\theta}{\theta}>1,I was watching this proof of the equality $$\lim_{\theta\to 0} \frac{\sin \theta}{\theta} = 1$$ The author says about the following areas that red area <= yellow area <= blue area . Which leads to the following inequality: $$\frac{|\sin\theta|}{2} \le \frac{|\theta|}{2} \le \frac{|\tan\theta|}{2}$$ and in the end proofs the theorem. $$1 \ge \lim_{\theta\to 0} \frac{\sin \theta}{\theta} \ge 1 $$ I noticed that the statement red area < yellow area < blue area about the areas is also true and in fact more accurate. But this would lead to the following: $$\frac{|\sin\theta|}{2} \lt \frac{|\theta|}{2} \lt \frac{|\tan\theta|}{2}$$ ... $$1 \gt \lim_{\theta\to 0} \frac{\sin \theta}{\theta} \gt 1 $$ Obviously that cannot be true. Have I just broken the proof?,I was watching this proof of the equality The author says about the following areas that red area <= yellow area <= blue area . Which leads to the following inequality: and in the end proofs the theorem. I noticed that the statement red area < yellow area < blue area about the areas is also true and in fact more accurate. But this would lead to the following: ... Obviously that cannot be true. Have I just broken the proof?,\lim_{\theta\to 0} \frac{\sin \theta}{\theta} = 1 \frac{|\sin\theta|}{2} \le \frac{|\theta|}{2} \le \frac{|\tan\theta|}{2} 1 \ge \lim_{\theta\to 0} \frac{\sin \theta}{\theta} \ge 1  \frac{|\sin\theta|}{2} \lt \frac{|\theta|}{2} \lt \frac{|\tan\theta|}{2} 1 \gt \lim_{\theta\to 0} \frac{\sin \theta}{\theta} \gt 1 ,"['limits', 'trigonometry', 'proof-explanation', 'solution-verification']"
72,"Suppose $f(x) \rightarrow M$ as $x \rightarrow a$. Prove that if $f(x) \leq L$ for all $x$ near $a$, then $M \leq L$.","Suppose  as . Prove that if  for all  near , then .",f(x) \rightarrow M x \rightarrow a f(x) \leq L x a M \leq L,"I'm am a student taking a real analysis paper at university. I'm going through some problems on my problem sheet and I've been asked the question above. I'm still getting a hang on what it means for $x$ to be ""near"" $a$ but gather, that if $f(a) \leq L$ and $f(a) = M$ then $M \leq L$ is implied. If anyone can help me understand the mathematical definition of something being ""near"" something else and some tips on how to carve a rigorous proof of the above. It would be much appreciated! Thank you for your time!","I'm am a student taking a real analysis paper at university. I'm going through some problems on my problem sheet and I've been asked the question above. I'm still getting a hang on what it means for to be ""near"" but gather, that if and then is implied. If anyone can help me understand the mathematical definition of something being ""near"" something else and some tips on how to carve a rigorous proof of the above. It would be much appreciated! Thank you for your time!",x a f(a) \leq L f(a) = M M \leq L,"['real-analysis', 'limits']"
73,What is $\lim_{x \to 0} \frac{|x+1|+|x-1|-2}{|x+1|+|x-1|-2}$?,What is ?,\lim_{x \to 0} \frac{|x+1|+|x-1|-2}{|x+1|+|x-1|-2},"$\displaystyle \lim_{x \to 0} \frac{|x+1|+|x-1|-2}{|x+1|+|x-1|-2}$ If $x \to 0$ , then it does not matter the value when $x=0$ , then would not it be just equivalent to $\displaystyle \lim_{x \to 0} 1$ which is equal to $1$ ? But Wolfram´s answer is: Limit does not exist on the real line, there are infinitely many singularities in every neighborhood of $0$ . Wolfram Is Wolfram wrong?","If , then it does not matter the value when , then would not it be just equivalent to which is equal to ? But Wolfram´s answer is: Limit does not exist on the real line, there are infinitely many singularities in every neighborhood of . Wolfram Is Wolfram wrong?",\displaystyle \lim_{x \to 0} \frac{|x+1|+|x-1|-2}{|x+1|+|x-1|-2} x \to 0 x=0 \displaystyle \lim_{x \to 0} 1 1 0,['calculus']
74,Does this limit converge on e?,Does this limit converge on e?,,"Playing around with some math in python today I came across what appears to be an interesting pattern: Starting at n=1 as n approaches positive infinity, take (n+1)^(n+2)/n^(n+1) and get a list of ratios of exponential expressions. At first glance the ratios between the numbers appeared to be converging to something so... Next, I took the difference between consecutive ratios, e.g. (n+2)^(n+3)/(n+1)^(n+2)-(n+1)^(n+2)/n^(n+1). The differences appear to be approaching e (2.718...) as n gets larger. The first few ratios rounded to the third decimal place are... 2^3/1^2 = 8 3^4/2^3 = 10.125 4^5/3^4 = 12.642 5^6/4^5 = 15.259 6^7/5^6 = 17.916 ... With their differences being... 10.125 - 8 = 2.125 12.642 - 10.125 = 2.517 15.259 - 12.642 = 2.617 17.916 - 15.259 = 2.657 ... After the 13th iteration you get 2.711, and it looks like the series will converge on e as it gets arbitrarily large. That or likely positive infinity and my hunch is off! Can anyone with better knowledge of limits tell me if I've stumbled across a novel way of calculating e or not? Here's the python code for those curious (first loop stops at 15 because that's all my cheap phone could handle): import numpy as np  ratios = [] i = 1 while i < 15:     a = np.power(i,i+1)     b = np.power(i+1,i+2)     print(a)     ratios.append(b/a)     i+=1 print(ratios)  x=0 diffs = [] while x < len(ratios) - 1:     temp = ratios[x+1] - ratios[x]     diffs.append(temp)     x+=1  print(diffs) This reminds of the time I thought I discovered a novel formula for exponents about the golden ratio. I didn't, it was already known and I think this may be the case too but my brief search hasn't turned up anything yet. Thanks!","Playing around with some math in python today I came across what appears to be an interesting pattern: Starting at n=1 as n approaches positive infinity, take (n+1)^(n+2)/n^(n+1) and get a list of ratios of exponential expressions. At first glance the ratios between the numbers appeared to be converging to something so... Next, I took the difference between consecutive ratios, e.g. (n+2)^(n+3)/(n+1)^(n+2)-(n+1)^(n+2)/n^(n+1). The differences appear to be approaching e (2.718...) as n gets larger. The first few ratios rounded to the third decimal place are... 2^3/1^2 = 8 3^4/2^3 = 10.125 4^5/3^4 = 12.642 5^6/4^5 = 15.259 6^7/5^6 = 17.916 ... With their differences being... 10.125 - 8 = 2.125 12.642 - 10.125 = 2.517 15.259 - 12.642 = 2.617 17.916 - 15.259 = 2.657 ... After the 13th iteration you get 2.711, and it looks like the series will converge on e as it gets arbitrarily large. That or likely positive infinity and my hunch is off! Can anyone with better knowledge of limits tell me if I've stumbled across a novel way of calculating e or not? Here's the python code for those curious (first loop stops at 15 because that's all my cheap phone could handle): import numpy as np  ratios = [] i = 1 while i < 15:     a = np.power(i,i+1)     b = np.power(i+1,i+2)     print(a)     ratios.append(b/a)     i+=1 print(ratios)  x=0 diffs = [] while x < len(ratios) - 1:     temp = ratios[x+1] - ratios[x]     diffs.append(temp)     x+=1  print(diffs) This reminds of the time I thought I discovered a novel formula for exponents about the golden ratio. I didn't, it was already known and I think this may be the case too but my brief search hasn't turned up anything yet. Thanks!",,"['limits', 'convergence-divergence', 'exponential-function', 'python']"
75,Find the value of $a$ where $a^x = \frac{\log(x)}{\log(a)}$ has only one solution,Find the value of  where  has only one solution,a a^x = \frac{\log(x)}{\log(a)},I have those two functions $f(x) = a^x$ $g(x) = \frac{\log(x)}{\log(a)}$ Where $g(x)$ is symmetric to $f(x)$ w.r.t. the $y=x$ axis. With $a = 1.3$ we have two solutions to $f(x) = g(x)$ : With a = 1.5 we have no solutions to $f(x) = g(x)$ : So there is a value $a$ (between 1.3 and 1.5) where $f(x) = g(x)$ admit one and only one solution . Graphically I've noticed that those value should be close to 1.4446 but I cannot find a more precise answer. I don't think that it is possible to isolate $x$ in the equation $f(x) = g(x)$ so how could I determine this value ?,I have those two functions Where is symmetric to w.r.t. the axis. With we have two solutions to : With a = 1.5 we have no solutions to : So there is a value (between 1.3 and 1.5) where admit one and only one solution . Graphically I've noticed that those value should be close to 1.4446 but I cannot find a more precise answer. I don't think that it is possible to isolate in the equation so how could I determine this value ?,f(x) = a^x g(x) = \frac{\log(x)}{\log(a)} g(x) f(x) y=x a = 1.3 f(x) = g(x) f(x) = g(x) a f(x) = g(x) x f(x) = g(x),"['limits', 'exponential-function']"
76,"Where is my mistake in finding this lim ? $\lim\limits_{(x,y)\to (0,0)}\frac{|y|}{x^{2}}~e ^{-\frac{|y|}{x^{2}}}$",Where is my mistake in finding this lim ?,"\lim\limits_{(x,y)\to (0,0)}\frac{|y|}{x^{2}}~e ^{-\frac{|y|}{x^{2}}}","Im going to find the mistake in this two solutions : Question $\to $ find : $$\Omega =\lim\limits_{(x,y)\to (0,0)}\frac{|y|}{x^{2}}~e ^{-\frac{|y|}{x^{2}}}$$ The first suggested solution Let prove does not exist lim : $•\color{red}{y=x^{2}}$ then : $$\Omega =\lim\limits_{(x,x^{2})\to (0,0)}\frac{|x^{2}|}{x^{2}}~e ^{-\frac{|x^{2}|}{x^{2}}}$$ $$=\lim\limits_{(x,x^{2})\to (0,0)}e ^{-\frac{x^{2}}{x^{2}}}=\color{green}{\frac{1}{e}}$$ $•\color{red}{y=x}$ then : $$\Omega =\lim\limits_{(x,x)\to (0,0)}\frac{|x|}{x^{2}}~e ^{-\frac{|x|}{x^{2}}}$$ $$\Omega =\lim\limits_{(x,y)\to (0,0)}\frac{1}{|x|}~e ^{-\frac{1}{|x|}}$$ $$=\lim\limits_{t\to +\infty}te^{-t}=\color{green}{0}$$ This mean that : does not exist lim! The second suggested solution Using the polar coordinates, we find: $$x=r\cos \theta , y=r\sin \theta $$ So : $$\Omega =\lim\limits_{r\to 0}\frac{|\sin \theta |}{r\cos^{2} \theta }e^{-\frac{|\sin \theta |}{r\cos^{2} \theta }}$$ $$=\lim\limits_{t\to +\infty}te^{-t}=\color{red}{0}$$ I am waiting for your explanation, comments and advice, I will be happy if i see other ways! Thanks!","Im going to find the mistake in this two solutions : Question find : The first suggested solution Let prove does not exist lim : then : then : This mean that : does not exist lim! The second suggested solution Using the polar coordinates, we find: So : I am waiting for your explanation, comments and advice, I will be happy if i see other ways! Thanks!","\to  \Omega =\lim\limits_{(x,y)\to (0,0)}\frac{|y|}{x^{2}}~e ^{-\frac{|y|}{x^{2}}} •\color{red}{y=x^{2}} \Omega =\lim\limits_{(x,x^{2})\to (0,0)}\frac{|x^{2}|}{x^{2}}~e ^{-\frac{|x^{2}|}{x^{2}}} =\lim\limits_{(x,x^{2})\to (0,0)}e ^{-\frac{x^{2}}{x^{2}}}=\color{green}{\frac{1}{e}} •\color{red}{y=x} \Omega =\lim\limits_{(x,x)\to (0,0)}\frac{|x|}{x^{2}}~e ^{-\frac{|x|}{x^{2}}} \Omega =\lim\limits_{(x,y)\to (0,0)}\frac{1}{|x|}~e ^{-\frac{1}{|x|}} =\lim\limits_{t\to +\infty}te^{-t}=\color{green}{0} x=r\cos \theta , y=r\sin \theta  \Omega =\lim\limits_{r\to 0}\frac{|\sin \theta |}{r\cos^{2} \theta }e^{-\frac{|\sin \theta |}{r\cos^{2} \theta }} =\lim\limits_{t\to +\infty}te^{-t}=\color{red}{0}","['calculus', 'limits', 'multivariable-calculus']"
77,"Is it possible to approximate the natural logarithm by integrating $x^n$ with respect to $x$, where $n \approx -1$?","Is it possible to approximate the natural logarithm by integrating  with respect to , where ?",x^n x n \approx -1,"In general, $$ \int x^{n} dx = \frac{x^{n+1}}{n+1} + C $$ However, this rule does not work when $n=-1$ because it leads to division by zero. Instead, $\int x^{-1} dx = \ln(|x|) + C$ . This standard result made me wonder if the natural logarithm could be approximated by using $n$ -values that are close to, but not equal to, $-1$ . For example, setting n  as equal to $-0.99$ : $$ \int x^{-0.99} dx = \frac{x^{0.01}}{0.01} +C = 100x^{0.01}+C $$ The $C$ value that translated the graph so that it became a good approximation was $-100$ . Here is the general case. My suspicion is that as $k$ tends to infinity, the approximation becomes better and better: $$ \int x^{-1+1/k} dx = \frac{x^{1/k}}{1/k}+C=kx^{1/k}+C $$ Using $-k$ as the constant of integration, I produced the following result: As you can see, it is difficult to see any difference between the two graphs. I have two questions: Why does $C$ have to equal $-k$ in order for the approximation to work? Can this approach be formalised by using limits? E.g. as $k \to \infty$ , $kx^{1/k}-k$ becomes arbitrarily close to $\ln(x)$ ?","In general, However, this rule does not work when because it leads to division by zero. Instead, . This standard result made me wonder if the natural logarithm could be approximated by using -values that are close to, but not equal to, . For example, setting n  as equal to : The value that translated the graph so that it became a good approximation was . Here is the general case. My suspicion is that as tends to infinity, the approximation becomes better and better: Using as the constant of integration, I produced the following result: As you can see, it is difficult to see any difference between the two graphs. I have two questions: Why does have to equal in order for the approximation to work? Can this approach be formalised by using limits? E.g. as , becomes arbitrarily close to ?","
\int x^{n} dx = \frac{x^{n+1}}{n+1} + C
 n=-1 \int x^{-1} dx = \ln(|x|) + C n -1 -0.99 
\int x^{-0.99} dx = \frac{x^{0.01}}{0.01} +C = 100x^{0.01}+C
 C -100 k 
\int x^{-1+1/k} dx = \frac{x^{1/k}}{1/k}+C=kx^{1/k}+C
 -k C -k k \to \infty kx^{1/k}-k \ln(x)","['real-analysis', 'limits', 'logarithms', 'indefinite-integrals', 'approximation']"
78,Intro analysis question related to MVT,Intro analysis question related to MVT,,"Q) Let $f$ be a real-valued function which is continuous in a   neighbourhood $N$ of some point $c∈R$ . Suppose that $f$ is   differentiable on N\ {c} and that $\lim_{x->c} f'(x)=L$ . Show that $f$ is differentiable at $c$ with $f'(c) = L$ . My try: $f$ is differentiable at $c$ if the limit $\lim_{x->c+}(f(x)-f(c))/(x-c)$ exists. As $f$ is differentiable in $(c, c+h)$ , from MVT, there is some $y\in (c, c+h)$ such that interval such that $f'(y)=\frac{f(c+h)-f(c)}{c+h-c}=L$ . This implies that: $\lim_{x->c} f'(y)=\lim_{x->c} L = f'(c)=L$ . I know this isn't correct, but I don't know where I'm going wrong.","Q) Let be a real-valued function which is continuous in a   neighbourhood of some point . Suppose that is   differentiable on N\ {c} and that . Show that is differentiable at with . My try: is differentiable at if the limit exists. As is differentiable in , from MVT, there is some such that interval such that . This implies that: . I know this isn't correct, but I don't know where I'm going wrong.","f N c∈R f \lim_{x->c} f'(x)=L f c f'(c) = L f c \lim_{x->c+}(f(x)-f(c))/(x-c) f (c, c+h) y\in (c, c+h) f'(y)=\frac{f(c+h)-f(c)}{c+h-c}=L \lim_{x->c} f'(y)=\lim_{x->c} L = f'(c)=L","['real-analysis', 'limits', 'analysis', 'derivatives']"
79,Limit of $ \frac{f(h+k) - f(k) - f(h) + f(0)}{hk}$,Limit of, \frac{f(h+k) - f(k) - f(h) + f(0)}{hk},"Calculate the following limit when $(h,k)\to (0,0)$ when $f$ is twice differentiable in 0. By removing $f(0) + xf'(0) + x^2f''(0)/2$ to $f$ , we can suppose WLoG that $f(0)=f'(0) = f''(0)=0$ . Let $g:h\mapsto f(h+k) -f(h) - f(k)$ Then $g$ is differentiable around 0 and $g'(h) = f'(h+k) - f'(h)$ . When $f$ is twice continuously differentiable around 0, I managed to conclude by writing the difference as an integral and using the fact that $f''(0) = 0$ to find an upper bound on $g'$ around 0.  So the limit here should be 0. So that in the general case we should  get $f''(0)$ But I am stuck in the general case ! When I try to find an upper bound on this derivative, I can only get something of the form $\varepsilon |h+k| + \varepsilon |h|$ and I cannot conclude with that... Any tips ?","Calculate the following limit when when is twice differentiable in 0. By removing to , we can suppose WLoG that . Let Then is differentiable around 0 and . When is twice continuously differentiable around 0, I managed to conclude by writing the difference as an integral and using the fact that to find an upper bound on around 0.  So the limit here should be 0. So that in the general case we should  get But I am stuck in the general case ! When I try to find an upper bound on this derivative, I can only get something of the form and I cannot conclude with that... Any tips ?","(h,k)\to (0,0) f f(0) + xf'(0) + x^2f''(0)/2 f f(0)=f'(0) = f''(0)=0 g:h\mapsto f(h+k) -f(h) - f(k) g g'(h) = f'(h+k) - f'(h) f f''(0) = 0 g' f''(0) \varepsilon |h+k| + \varepsilon |h|","['real-analysis', 'limits']"
80,Evaluate $\lim\limits_{x \to { \infty } } (\frac{x}{x+2})^x$. Need for explanation.,Evaluate . Need for explanation.,\lim\limits_{x \to { \infty } } (\frac{x}{x+2})^x,"My question is about the procedure for this limit problem: $$\lim\limits_{x \to  { \infty } } (\frac{x}{x+2})^x$$ My solution was like that: $$(\frac{x}{x+2})^x=e^{x\ln\frac{x}{x+2}} = e^u$$ with $\ u = x \ln(\frac{x}{x+2})$ . Then $$\lim\limits_{x \to  { \infty } } x\ln(\frac{x}{x+2}) =\lim\limits_{x \to  { \infty } }{\ln{x\over x+2}\over {1\over x}}$$ Applying L'Hôpital's rule: $$\lim\limits_{x \to  { \infty } } -{{2\over x(x+2)}\over   {1\over x^2}} = \lim\limits_{x \to  { \infty } } -{2x\over x+2} = -2 $$ $$\lim\limits_{x \to  { \infty } } u = -2 $$ ∴ $\lim\limits_{u \to  { \ -2 } } e^{u} = e^{-2} = {1\over e^{2}} $ However, according to my answer sheet, the correct answer is $e^{2}$ . So, Please I need to know where's my mistake here. Thank you.","My question is about the procedure for this limit problem: My solution was like that: with . Then Applying L'Hôpital's rule: ∴ However, according to my answer sheet, the correct answer is . So, Please I need to know where's my mistake here. Thank you.","\lim\limits_{x \to  { \infty } } (\frac{x}{x+2})^x (\frac{x}{x+2})^x=e^{x\ln\frac{x}{x+2}}
= e^u \ u = x \ln(\frac{x}{x+2}) \lim\limits_{x \to  { \infty } } x\ln(\frac{x}{x+2})
=\lim\limits_{x \to  { \infty } }{\ln{x\over x+2}\over {1\over x}} \lim\limits_{x \to  { \infty } } -{{2\over x(x+2)}\over 
 {1\over x^2}} = \lim\limits_{x \to  { \infty } } -{2x\over x+2} = -2  \lim\limits_{x \to  { \infty } } u = -2  \lim\limits_{u \to  { \ -2 } } e^{u} = e^{-2} = {1\over e^{2}}  e^{2}","['limits', 'analysis', 'proof-verification', 'exponential-function']"
81,Evaluate $\lim_{n\rightarrow \infty} \left[ \frac{1}{(n+1)(n+2)} + \frac{2}{(n+2)(n+4)} + \cdots + \frac{n}{6n^2} \right]$,Evaluate,\lim_{n\rightarrow \infty} \left[ \frac{1}{(n+1)(n+2)} + \frac{2}{(n+2)(n+4)} + \cdots + \frac{n}{6n^2} \right],"Evaluate: $$\lim_{n\rightarrow \infty} \left[ \dfrac{1}{(n+1)(n+2)} + \dfrac{2}{(n+2)(n+4)} + \cdots + \dfrac{n}{6n^2} \right]$$ $\text{My Attempt:}$ breaking down the summation series into: $$\sum_{r=1}^{n} \dfrac{r}{(n+r)(n+2r)}$$ .  Further breaking down into two separate series: $$\sum_{r=1}^{n} \dfrac{r}{(n+r)(n+2r)}=\sum_{r=1}^{n} \dfrac{(n+2r)-(n+r)}{(n+r)(n+2r)}$$ This will reduce to give: $$\sum_{r=1}^{n} \dfrac{1}{n+r} - \sum_{r=1}^{n}\dfrac{1}{n+2r}$$ Now, applying limits to the sum: $$\lim_{n\rightarrow\infty}\left[\sum_{r=1}^{n} \dfrac{1}{n+r} -  \sum_{r=1}^{n} \dfrac{1}{n+2r}\right]$$ Taking $n$ common in denominator and converting to Definite integral taking $\dfrac{r}{n}=x$ this reduces to: $$\int_{0}^{1}\dfrac{\text{dx}}{1+x}-\int_{0}^{1} \dfrac{\text{dx}}{1+2x}$$ Edit: Solving this we will get the answer as $\ln\left(\dfrac{2}{\sqrt{3}}\right)$ . I have had committed an error in the evaluation of the 2nd integral as Mr. Robert Z has pointed out below.","Evaluate: breaking down the summation series into: .  Further breaking down into two separate series: This will reduce to give: Now, applying limits to the sum: Taking common in denominator and converting to Definite integral taking this reduces to: Edit: Solving this we will get the answer as . I have had committed an error in the evaluation of the 2nd integral as Mr. Robert Z has pointed out below.",\lim_{n\rightarrow \infty} \left[ \dfrac{1}{(n+1)(n+2)} + \dfrac{2}{(n+2)(n+4)} + \cdots + \dfrac{n}{6n^2} \right] \text{My Attempt:} \sum_{r=1}^{n} \dfrac{r}{(n+r)(n+2r)} \sum_{r=1}^{n} \dfrac{r}{(n+r)(n+2r)}=\sum_{r=1}^{n} \dfrac{(n+2r)-(n+r)}{(n+r)(n+2r)} \sum_{r=1}^{n} \dfrac{1}{n+r} - \sum_{r=1}^{n}\dfrac{1}{n+2r} \lim_{n\rightarrow\infty}\left[\sum_{r=1}^{n} \dfrac{1}{n+r} -  \sum_{r=1}^{n} \dfrac{1}{n+2r}\right] n \dfrac{r}{n}=x \int_{0}^{1}\dfrac{\text{dx}}{1+x}-\int_{0}^{1} \dfrac{\text{dx}}{1+2x} \ln\left(\dfrac{2}{\sqrt{3}}\right),"['limits', 'definite-integrals', 'summation', 'riemann-sum']"
82,Compute $\lim \limits _{n\to \infty} \frac{1}{n^2}\sum_{1\le i < j \le n}^n \cos \left(\frac{i}{n}\right) \cos \left(\frac{j}{n} \right)$,Compute,\lim \limits _{n\to \infty} \frac{1}{n^2}\sum_{1\le i < j \le n}^n \cos \left(\frac{i}{n}\right) \cos \left(\frac{j}{n} \right),"Compute $\lim \limits _{n\to \infty} \frac{1}{n^2}\sum_{1\le i < j \le n}^n \cos \left(\frac{i}{n}\right) \cos \left(\frac{j}{n} \right)$ . I think that this limit can be computed by writing it as a Riemann sum. However, what puzzles me is that there are $2$ summation indices and I don't know how to find the integral. Note: This should be solveable without double integrals since it comes from a single variable calculus book.","Compute . I think that this limit can be computed by writing it as a Riemann sum. However, what puzzles me is that there are summation indices and I don't know how to find the integral. Note: This should be solveable without double integrals since it comes from a single variable calculus book.",\lim \limits _{n\to \infty} \frac{1}{n^2}\sum_{1\le i < j \le n}^n \cos \left(\frac{i}{n}\right) \cos \left(\frac{j}{n} \right) 2,"['integration', 'limits']"
83,Function that converges to $\infty$ at every point,Function that converges to  at every point,\infty,"I was wondering whether there exists a function $f:\Bbb R\to\Bbb R$ that satisfies: $$\text{For all } y\in\Bbb R: \lim_{x\to y} f(x)=\infty.$$ Intuitively it seems to me like this is impossible. But I don't see how to prove it. By definition we would have $$\forall y \in \Bbb R: \forall r \in \Bbb R_+: \exists \delta > 0: \forall x \in (y-\delta, y+\delta)\setminus\{y\}: f(x)>r,$$ and not I don't know how to proceed.",I was wondering whether there exists a function that satisfies: Intuitively it seems to me like this is impossible. But I don't see how to prove it. By definition we would have and not I don't know how to proceed.,"f:\Bbb R\to\Bbb R \text{For all } y\in\Bbb R: \lim_{x\to y} f(x)=\infty. \forall y \in \Bbb R: \forall r \in \Bbb R_+: \exists \delta > 0: \forall x \in (y-\delta, y+\delta)\setminus\{y\}: f(x)>r,",['real-analysis']
84,Find $\lim_{n \rightarrow\infty } P_n$whreas $P_n=\frac{2^3-1}{2^3+1}\cdot\frac{3^3-1}{3^3+1}\cdot\cdot\cdot\frac{n^3-1}{n^3+1}$.,Find whreas .,\lim_{n \rightarrow\infty } P_n P_n=\frac{2^3-1}{2^3+1}\cdot\frac{3^3-1}{3^3+1}\cdot\cdot\cdot\frac{n^3-1}{n^3+1},"$\lim_{n \rightarrow\infty }  P_n$ whreas $P_n=\frac{2^3-1}{2^3+1}\cdot\frac{3^3-1}{3^3+1}\cdot\cdot\cdot\frac{n^3-1}{n^3+1}$ . This is a past problem of a high-school level math compettion. My tries: 1.Initially I thought of finding the product of the sequence.But then I realize there is no need of product coz' it'll make the function more complicated. 2.Then I tried to simplify first few terms so that may be in some way some of the middle terms may be cancelled out . So the product of first few terms look sth like this, $\frac{7}{9}\cdot\frac{26}{28}\cdot\frac{63}{65}\cdot\cdot\frac{n^3-1}{n^3+1}$ But I could'nt find any pattern in this.So how  the limit can be evaluated?","whreas . This is a past problem of a high-school level math compettion. My tries: 1.Initially I thought of finding the product of the sequence.But then I realize there is no need of product coz' it'll make the function more complicated. 2.Then I tried to simplify first few terms so that may be in some way some of the middle terms may be cancelled out . So the product of first few terms look sth like this, But I could'nt find any pattern in this.So how  the limit can be evaluated?",\lim_{n \rightarrow\infty }  P_n P_n=\frac{2^3-1}{2^3+1}\cdot\frac{3^3-1}{3^3+1}\cdot\cdot\cdot\frac{n^3-1}{n^3+1} \frac{7}{9}\cdot\frac{26}{28}\cdot\frac{63}{65}\cdot\cdot\frac{n^3-1}{n^3+1},"['real-analysis', 'limits']"
85,Find $ \lim\limits_{x\to \infty} \left(x-x^2 \ln (1+\frac{1}{x})\right) $ with Taylor,Find  with Taylor, \lim\limits_{x\to \infty} \left(x-x^2 \ln (1+\frac{1}{x})\right) ,"I have to calculate some limits and try to solve them in use of taylor. $$  \lim\limits_{x\to \infty} \left(x-x^2 \ln (1+\frac{1}{x})\right)  $$ In taylor pattern I have $x_0$ to put, but there $x_0$ is $\infty$ so I want to replace it with something other $$  y = \frac{1}{x} \\ \lim_{y\to 0^+} \left(\frac{1}{y}-\frac{1}{y^2} \ln (1+y)\right) $$ Let $$ f(y) = \frac{1}{y}-\frac{1}{y^2} \ln (1+y) $$ $$f'(y) = -\frac{1}{y^2} + \left(-\frac{2}{y^3}\ln (1+y) - \frac{y^2}{1+y}\right) $$ but $f'(0)$ does not exists because I have $0$ in denominator.","I have to calculate some limits and try to solve them in use of taylor. In taylor pattern I have to put, but there is so I want to replace it with something other Let but does not exists because I have in denominator."," 
\lim\limits_{x\to \infty} \left(x-x^2 \ln (1+\frac{1}{x})\right) 
 x_0 x_0 \infty  
y = \frac{1}{x} \\
\lim_{y\to 0^+} \left(\frac{1}{y}-\frac{1}{y^2} \ln (1+y)\right)   f(y) = \frac{1}{y}-\frac{1}{y^2} \ln (1+y)  f'(y) = -\frac{1}{y^2} + \left(-\frac{2}{y^3}\ln (1+y) - \frac{y^2}{1+y}\right)  f'(0) 0","['real-analysis', 'limits', 'taylor-expansion']"
86,"Evaluating $\lim_{(x,y)\to(0,0)}\frac{x^2+y^2}{\sin^2y+\ln(1+x^2)}$",Evaluating,"\lim_{(x,y)\to(0,0)}\frac{x^2+y^2}{\sin^2y+\ln(1+x^2)}","$$\lim_{(x,y)\to(0,0)}\frac{x^2+y^2}{\sin^2y+\ln(1+x^2)}$$ If I use a specific path I know I can use Cauchy Theorem to get a number, but how do I prove this for all paths? Thank you!","If I use a specific path I know I can use Cauchy Theorem to get a number, but how do I prove this for all paths? Thank you!","\lim_{(x,y)\to(0,0)}\frac{x^2+y^2}{\sin^2y+\ln(1+x^2)}","['calculus', 'limits', 'multivariable-calculus']"
87,How do I choose $\delta$ in the $\epsilon-\delta$ proofs of limits.,How do I choose  in the  proofs of limits.,\delta \epsilon-\delta,"While I understand how $\delta$ is chosen when a funtion is nice and easy, linear function. But I'm having trouble understanding how the $\delta$ is selected for quadratic function or rational functions. For instance, I have to prove that, $\lim\limits_{x \to 2} \dfrac{x^3-4}{x^2+1} = \dfrac{4}{5}$ So let $f(x)$ be the given function, Fixing an $\epsilon>0$ , and simplifying $|f(x)- 4/5|$ I get, $\left| f(x)- \dfrac{4}{5} \right| = \dfrac{|5x^3 +6x+12|}{5(x^2+1)} \cdot |x-2| $ Now I understand I need to get rid of everything except $|x-2|$ possibly by replacing the entire thing by a number. But I have no clue as to how you choose this number. What should be my thought process now? Thanks!","While I understand how is chosen when a funtion is nice and easy, linear function. But I'm having trouble understanding how the is selected for quadratic function or rational functions. For instance, I have to prove that, So let be the given function, Fixing an , and simplifying I get, Now I understand I need to get rid of everything except possibly by replacing the entire thing by a number. But I have no clue as to how you choose this number. What should be my thought process now? Thanks!",\delta \delta \lim\limits_{x \to 2} \dfrac{x^3-4}{x^2+1} = \dfrac{4}{5} f(x) \epsilon>0 |f(x)- 4/5| \left| f(x)- \dfrac{4}{5} \right| = \dfrac{|5x^3 +6x+12|}{5(x^2+1)} \cdot |x-2|  |x-2|,"['real-analysis', 'limits']"
88,Show that $\lim_{x \rightarrow \infty} f'(x)<1$ implies $f(x_0)<x_0$ for some $x_0$,Show that  implies  for some,\lim_{x \rightarrow \infty} f'(x)<1 f(x_0)<x_0 x_0,"Let $f:[0,\infty)\rightarrow R $ be a continuously differentiable function. Show that if $ \lim_{x \rightarrow \infty} f'(x)<1   $ then $ f(x_0)<x_0 $ for some $x_0$ large enough. (An example of a function that satisfies these assumption is $f(x) = \sqrt x $ ). I am struggling with the proof. I've tried with the mean value theorem: Choose $0<x<y$ . Then by the MVT there esists a number $c \in (x,y)$ such that $ \dfrac{f(y)-f(x)}{y-x} = f'(c)  $ But at this point I got stuck... The other info I have is that there exists a number $M>0$ such that if $x>M$ then $f'(x)<1$ (the limit condition stated in the hp). Is there a way to combine these two facts in order to prove what I want?",Let be a continuously differentiable function. Show that if then for some large enough. (An example of a function that satisfies these assumption is ). I am struggling with the proof. I've tried with the mean value theorem: Choose . Then by the MVT there esists a number such that But at this point I got stuck... The other info I have is that there exists a number such that if then (the limit condition stated in the hp). Is there a way to combine these two facts in order to prove what I want?,"f:[0,\infty)\rightarrow R   \lim_{x \rightarrow \infty} f'(x)<1     f(x_0)<x_0  x_0 f(x) = \sqrt x  0<x<y c \in (x,y)  \dfrac{f(y)-f(x)}{y-x} = f'(c)   M>0 x>M f'(x)<1","['real-analysis', 'limits', 'inequality', 'infinity']"
89,Complete proof about the limits of a multivariable function,Complete proof about the limits of a multivariable function,,"I just started learning about multivariable functions and I have a question about the complete proof of the existence of a limit of a function.  So let's take for example the function $$f(x,y)=\frac{x^3y}{x^2+y^2}$$  This function has a limit in $(x,y)=(0,0)$ and I'll have to prove it So according to my understanding, I'll have to examine the behavior of the function while it approaches $(0,0)$ from every possible path. First I examined the trivial limits when $x=0$ and $y=0$ cases which both wielded the result $0$ as expected. Then I tried for  $t \in (0,1]$ the approach from every different line of origin $y=kx$ by setting $x=at$ and $y=bt$ (with a and b never both equal to $0$) to test the limit $$\lim_{t\to0} f(x(t),y(t))$$ which also gave $0$.  At this point, I don't think that I've covered every single approach of $f$ to the point $(x,y)=(0,0)$, and even if I have, I think that in order to complete the proof I'll have to also mention the definition of limits, for which I am completely unfamiliar in multivariable functions, but I think that for this example it goes like this: Since for every $ε>0$ there is a $δ>0$ so that for every $(x,y)$ with $0 < ||(x,y)-(0,0)|| < δ$ then $|f(x,y)-0|<ε$ and the limit exists. Any thoughts or insight would be really helpful.","I just started learning about multivariable functions and I have a question about the complete proof of the existence of a limit of a function.  So let's take for example the function $$f(x,y)=\frac{x^3y}{x^2+y^2}$$  This function has a limit in $(x,y)=(0,0)$ and I'll have to prove it So according to my understanding, I'll have to examine the behavior of the function while it approaches $(0,0)$ from every possible path. First I examined the trivial limits when $x=0$ and $y=0$ cases which both wielded the result $0$ as expected. Then I tried for  $t \in (0,1]$ the approach from every different line of origin $y=kx$ by setting $x=at$ and $y=bt$ (with a and b never both equal to $0$) to test the limit $$\lim_{t\to0} f(x(t),y(t))$$ which also gave $0$.  At this point, I don't think that I've covered every single approach of $f$ to the point $(x,y)=(0,0)$, and even if I have, I think that in order to complete the proof I'll have to also mention the definition of limits, for which I am completely unfamiliar in multivariable functions, but I think that for this example it goes like this: Since for every $ε>0$ there is a $δ>0$ so that for every $(x,y)$ with $0 < ||(x,y)-(0,0)|| < δ$ then $|f(x,y)-0|<ε$ and the limit exists. Any thoughts or insight would be really helpful.",,"['limits', 'multivariable-calculus', 'proof-verification']"
90,Limit of successive approximation,Limit of successive approximation,,"I want to calculate the limit when $n\rightarrow \infty$of the successive approximation \begin{equation*}y_{n+1}(x)=1+\int_0^xty_n(t)\, dt\end{equation*} with $y_0(x)=1$, $x\in [-1,1]$. $$$$ We have that \begin{align*}&y_0(x)=1 \\ &y_{1}(x)=1+\int_0^xty_0(t)\, dt=1+\int_0^xt\cdot 1\, dt=1+\int_0^xt\, dt=1+\frac{x^2}{2} \\ &y_{2}(x)=1+\int_0^xty_1(t)\, dt=1+\int_0^xt\left (1+\frac{t^2}{2}\right ) \, dt=1+\frac{x^2}{2}+\frac{x^4}{8}\end{align*} Do we have to find a general formula for $y_{n+1}(x)$ or how can we calculate the limit ?","I want to calculate the limit when $n\rightarrow \infty$of the successive approximation \begin{equation*}y_{n+1}(x)=1+\int_0^xty_n(t)\, dt\end{equation*} with $y_0(x)=1$, $x\in [-1,1]$. $$$$ We have that \begin{align*}&y_0(x)=1 \\ &y_{1}(x)=1+\int_0^xty_0(t)\, dt=1+\int_0^xt\cdot 1\, dt=1+\int_0^xt\, dt=1+\frac{x^2}{2} \\ &y_{2}(x)=1+\int_0^xty_1(t)\, dt=1+\int_0^xt\left (1+\frac{t^2}{2}\right ) \, dt=1+\frac{x^2}{2}+\frac{x^4}{8}\end{align*} Do we have to find a general formula for $y_{n+1}(x)$ or how can we calculate the limit ?",,"['analysis', 'limits']"
91,Convergence of sequence of power series implies convergence of coefficients,Convergence of sequence of power series implies convergence of coefficients,,"Suppose we are given that a sequence of functions $f_n(z)$ convergences pointwise to $f(z)$ on the interval $[0,1]$.  Suppose further that all of these functions are given by power series centered at 0 with radius of convergence $R > 1$. To fix notation, say $f_n(z) = a_{n, 0} + a_{n, 1}z + a_{n, 2} z^2 + \dots$ and $f(z) = a_0  + a_1 z + a_2 z^2 + \dots$. We are given $f_n(z) \to f(z)$ as $n \to \infty$, for each fixed $z \in [0,1]$. Is it true that $a_{n, k} \to a_k$ as $n \to \infty$, for each $k$? Why?  We can't use complex analysis it seems, since we are only on $[0,1]$. If not, is it true under the additional assumption that all the $a_{n, k}$ and $a_n$ are uniformly bounded by some $M$?","Suppose we are given that a sequence of functions $f_n(z)$ convergences pointwise to $f(z)$ on the interval $[0,1]$.  Suppose further that all of these functions are given by power series centered at 0 with radius of convergence $R > 1$. To fix notation, say $f_n(z) = a_{n, 0} + a_{n, 1}z + a_{n, 2} z^2 + \dots$ and $f(z) = a_0  + a_1 z + a_2 z^2 + \dots$. We are given $f_n(z) \to f(z)$ as $n \to \infty$, for each fixed $z \in [0,1]$. Is it true that $a_{n, k} \to a_k$ as $n \to \infty$, for each $k$? Why?  We can't use complex analysis it seems, since we are only on $[0,1]$. If not, is it true under the additional assumption that all the $a_{n, k}$ and $a_n$ are uniformly bounded by some $M$?",,"['real-analysis', 'limits', 'convergence-divergence', 'power-series']"
92,Evaluating the limit ${\lim_\limits{x\to0^+}\frac{e^x-\cos(\lambda \sqrt x)}{\sqrt {1+\sin(\lambda x)}-1}}$,Evaluating the limit,{\lim_\limits{x\to0^+}\frac{e^x-\cos(\lambda \sqrt x)}{\sqrt {1+\sin(\lambda x)}-1}},"Evaluate $$\lim_\limits{x\to0^+}\frac{e^x-\cos(\lambda \sqrt x)}{\sqrt {1+\sin(\lambda x)}-1}=(*)$$ My attempt: I have used Taylor expansion of $e^x, \ \cos x, \ \sin x:$ $$(*)=\lim_\limits{x\to0^+}\frac{1+x-1+\frac{\lambda^2 x}2+ o(x)}{\sqrt {1+\lambda x+o(x)}-1}=\lim_\limits{x\to0^+}\frac{(x+\frac{\lambda^2 x}2)(\sqrt{1+\lambda x+o(x)}+1)}{\lambda x}=\\ =\left(\frac1{\lambda}+\frac{\lambda}2\right)\lim_\limits{x\to0^+}\frac{\sqrt{1+\lambda x}+1}{\lambda x}$$ $\left(\dfrac1{\lambda}+\dfrac{\lambda}2\right)$ is the result written on my textbook, but there seems to be a typo. Thanks in advance P.S. the exercise comes from Calculus Problems , $8.20$ page $144$ EDIT: Actually the last step should have been: $$\left(\frac1{\lambda}+\frac{\lambda}2\right)\lim_\limits{x\to0^+}\sqrt{1+\lambda x}+1=\frac2{\lambda}+\lambda$$","Evaluate $$\lim_\limits{x\to0^+}\frac{e^x-\cos(\lambda \sqrt x)}{\sqrt {1+\sin(\lambda x)}-1}=(*)$$ My attempt: I have used Taylor expansion of $e^x, \ \cos x, \ \sin x:$ $$(*)=\lim_\limits{x\to0^+}\frac{1+x-1+\frac{\lambda^2 x}2+ o(x)}{\sqrt {1+\lambda x+o(x)}-1}=\lim_\limits{x\to0^+}\frac{(x+\frac{\lambda^2 x}2)(\sqrt{1+\lambda x+o(x)}+1)}{\lambda x}=\\ =\left(\frac1{\lambda}+\frac{\lambda}2\right)\lim_\limits{x\to0^+}\frac{\sqrt{1+\lambda x}+1}{\lambda x}$$ $\left(\dfrac1{\lambda}+\dfrac{\lambda}2\right)$ is the result written on my textbook, but there seems to be a typo. Thanks in advance P.S. the exercise comes from Calculus Problems , $8.20$ page $144$ EDIT: Actually the last step should have been: $$\left(\frac1{\lambda}+\frac{\lambda}2\right)\lim_\limits{x\to0^+}\sqrt{1+\lambda x}+1=\frac2{\lambda}+\lambda$$",,"['calculus', 'real-analysis', 'limits', 'taylor-expansion']"
93,Let $(a_n)_{n=1}^\infty$ be an infinite sequence of complex numbers. Prove the following limit.,Let  be an infinite sequence of complex numbers. Prove the following limit.,(a_n)_{n=1}^\infty,"Given $$\lim_{x\to \infty} \frac 1x \sum_{n\le x} a_n = k,$$ I want to prove that  $$\lim_{x\to \infty} \frac {1}{\log x} \sum_{n\le x} \frac {a_n}{n} = k.$$ I'm much more interested in learning the technique(s) necessary in order to prove this rather than a direct proof. Specifically, we have learned about asymptotic estimates and summation by parts, but I don't see how I can use those techniques to prove the problem statement. Thank you for any insight!","Given $$\lim_{x\to \infty} \frac 1x \sum_{n\le x} a_n = k,$$ I want to prove that  $$\lim_{x\to \infty} \frac {1}{\log x} \sum_{n\le x} \frac {a_n}{n} = k.$$ I'm much more interested in learning the technique(s) necessary in order to prove this rather than a direct proof. Specifically, we have learned about asymptotic estimates and summation by parts, but I don't see how I can use those techniques to prove the problem statement. Thank you for any insight!",,"['limits', 'summation', 'asymptotics', 'analytic-number-theory']"
94,Limits with Taylor series,Limits with Taylor series,,"I'm stuck computing these two limits using Taylor series.  The first is 1) $$\lim_{x\to \pi/2}\frac{\cos^2(x)}{\log[\sin(x)]}$$ and the second one is  2) $$\lim_{x\to \infty}\frac{x(\pi/2) - x\arctan(x)}{1}$$ I tried using the already known Taylor series, in both the two limits (and I also tried using higher orders) but I don't seem to get anywhere. For example,  in the second limit doing a sobstitution that seems obvious to me $$\{x\to \frac{1}{t}$$ leads to $$\lim_{t\to 0} {\frac{1}{t}\left [\frac{\pi}{2} -\frac {1}{t} +\frac{3}{t^3} -\frac{5}{t^5} +\frac{o\left(t^5\right)}{1}\right]}$$ that is the same form I had at the beginning. Using an higher grade of the Taylor expansion doesn't change this form.  I'm probably missing something. Can someone please explain to me what has to be done or what I'm doing wrong?","I'm stuck computing these two limits using Taylor series.  The first is 1) and the second one is  2) I tried using the already known Taylor series, in both the two limits (and I also tried using higher orders) but I don't seem to get anywhere. For example,  in the second limit doing a sobstitution that seems obvious to me leads to that is the same form I had at the beginning. Using an higher grade of the Taylor expansion doesn't change this form.  I'm probably missing something. Can someone please explain to me what has to be done or what I'm doing wrong?",\lim_{x\to \pi/2}\frac{\cos^2(x)}{\log[\sin(x)]} \lim_{x\to \infty}\frac{x(\pi/2) - x\arctan(x)}{1} \{x\to \frac{1}{t} \lim_{t\to 0} {\frac{1}{t}\left [\frac{\pi}{2} -\frac {1}{t} +\frac{3}{t^3} -\frac{5}{t^5} +\frac{o\left(t^5\right)}{1}\right]},"['real-analysis', 'analysis', 'limits', 'taylor-expansion', 'substitution']"
95,Solve this limit using equivalent infinitesimals,Solve this limit using equivalent infinitesimals,,"I am given the following limit, which I'm asked to solve. $$L=\lim_{x\to 0}\dfrac{2(\tan x-\sin x)-x^3}{x^5}$$ I get confused with equivalent infinitesimals most of the time. I know the correct answer to this limit is $\boxed{1/4}$. However, this is what I did: $$\left. \begin{array}{l} &\sin x \approx x\\ &\tan x \approx x \end{array} \right\} \Rightarrow L=-\lim_{x \to 0} \dfrac{x^3}{x^5}=-\lim_{x \to 0} \dfrac{1}{x^2}=\boxed{-\infty}$$ I know this problem can indeed be solved by taking 3 terms in the MacLaurin Series of each function (i.e. for both the sine and tangent functions). But sometimes this is not always necessary. Sometimes it's sufficient to take the first non-zero term in its MacLaurin Series. But as far as I was taught in school, the equivalent infinitesimal is defined as the first non-zero term in the MacLaurin Series of a function. How many terms should I grab to go safe for every case? Why doesn't it suffice to take just the 1st non-zero term?","I am given the following limit, which I'm asked to solve. $$L=\lim_{x\to 0}\dfrac{2(\tan x-\sin x)-x^3}{x^5}$$ I get confused with equivalent infinitesimals most of the time. I know the correct answer to this limit is $\boxed{1/4}$. However, this is what I did: $$\left. \begin{array}{l} &\sin x \approx x\\ &\tan x \approx x \end{array} \right\} \Rightarrow L=-\lim_{x \to 0} \dfrac{x^3}{x^5}=-\lim_{x \to 0} \dfrac{1}{x^2}=\boxed{-\infty}$$ I know this problem can indeed be solved by taking 3 terms in the MacLaurin Series of each function (i.e. for both the sine and tangent functions). But sometimes this is not always necessary. Sometimes it's sufficient to take the first non-zero term in its MacLaurin Series. But as far as I was taught in school, the equivalent infinitesimal is defined as the first non-zero term in the MacLaurin Series of a function. How many terms should I grab to go safe for every case? Why doesn't it suffice to take just the 1st non-zero term?",,"['calculus', 'limits', 'terminology', 'taylor-expansion']"
96,Calculate $\lim\limits_{n\to\infty}\frac{\ln(n!)}{n\ln(n)}$. [duplicate],Calculate . [duplicate],\lim\limits_{n\to\infty}\frac{\ln(n!)}{n\ln(n)},"This question already has an answer here : Proving Asymptotic Barrier - O notation for $\ln(n!)$ [duplicate] (1 answer) Closed 6 years ago . :) I need some help with calculating the limit $$\lim_{n\to\infty}\dfrac{\ln(n!)}{n\ln(n)}.$$ I think that it's easy to see that we can find it using d'Alembert (square root) criterion, because, obviously, $\forall n\in\mathbb{N}_{\geqslant 2}:\phi_n>0$, where $\left(\phi_n\right)_{n\in\mathbb{N}_{\geqslant 2}},\,\phi_n:=\dfrac{\ln(n!)}{n\ln(n)}$, so I did the following observation: $$\dfrac{\ln(n!)}{n\ln(n)}=\dfrac{1}{n}\cdot\dfrac{\ln(n!)}{\ln(n)}=\dfrac{\dfrac{1}{n}\ln(n!)}{\ln(n)}=\dfrac{\ln(n!)^{\frac{1}{n}}}{\ln(n)}=\dfrac{\displaystyle\sqrt[n]{\ln(n!)}}{\ln(n)}=\displaystyle\sqrt[n]{\dfrac{\ln(n!)}{\ln^n(n)}}.$$ Ok. d'Alembert tells me that I should do the limit $$\ell:=\lim_{n\to\infty}\bigg\lvert\dfrac{x_{n+1}}{x_n}\bigg\lvert=\lim_{n\to\infty}\dfrac{x_{n+1}}{x_n},$$ where $\left(x_n\right)_{n\in\mathbb{N}_{\geqslant 2}},\,x_n:=\dfrac{\ln(n!)}{\ln^n(n)}$. We have, then: $$\ell=\lim_{n\to\infty}\dfrac{\ln[(n+1)!]}{\ln^{n+1}(n+1)}\cdot\dfrac{\ln^n(n)}{\ln(n!)}=\cdots=\lim_{n\to\infty}\left[\dfrac{\ln(n)}{\ln(n+1)}\right]^n\left[\dfrac{1}{\ln(n+1)}+\dfrac{1}{\ln(n!)}\right]$$ but what about the next?","This question already has an answer here : Proving Asymptotic Barrier - O notation for $\ln(n!)$ [duplicate] (1 answer) Closed 6 years ago . :) I need some help with calculating the limit $$\lim_{n\to\infty}\dfrac{\ln(n!)}{n\ln(n)}.$$ I think that it's easy to see that we can find it using d'Alembert (square root) criterion, because, obviously, $\forall n\in\mathbb{N}_{\geqslant 2}:\phi_n>0$, where $\left(\phi_n\right)_{n\in\mathbb{N}_{\geqslant 2}},\,\phi_n:=\dfrac{\ln(n!)}{n\ln(n)}$, so I did the following observation: $$\dfrac{\ln(n!)}{n\ln(n)}=\dfrac{1}{n}\cdot\dfrac{\ln(n!)}{\ln(n)}=\dfrac{\dfrac{1}{n}\ln(n!)}{\ln(n)}=\dfrac{\ln(n!)^{\frac{1}{n}}}{\ln(n)}=\dfrac{\displaystyle\sqrt[n]{\ln(n!)}}{\ln(n)}=\displaystyle\sqrt[n]{\dfrac{\ln(n!)}{\ln^n(n)}}.$$ Ok. d'Alembert tells me that I should do the limit $$\ell:=\lim_{n\to\infty}\bigg\lvert\dfrac{x_{n+1}}{x_n}\bigg\lvert=\lim_{n\to\infty}\dfrac{x_{n+1}}{x_n},$$ where $\left(x_n\right)_{n\in\mathbb{N}_{\geqslant 2}},\,x_n:=\dfrac{\ln(n!)}{\ln^n(n)}$. We have, then: $$\ell=\lim_{n\to\infty}\dfrac{\ln[(n+1)!]}{\ln^{n+1}(n+1)}\cdot\dfrac{\ln^n(n)}{\ln(n!)}=\cdots=\lim_{n\to\infty}\left[\dfrac{\ln(n)}{\ln(n+1)}\right]^n\left[\dfrac{1}{\ln(n+1)}+\dfrac{1}{\ln(n!)}\right]$$ but what about the next?",,"['calculus', 'limits', 'logarithms', 'factorial', 'radicals']"
97,difference between $+\infty$ and $\infty$,difference between  and,+\infty \infty,"I'm taking Mathematical Analysis ""I"" and I'm studying limits where I have limits to the infinity, but I don't know what's the difference between $\lim_{x \to \infty}$ and $\lim_{x \to +\infty}$ I guess they are the same but I'm not sure. If you could help me I would appreciate it. Thank you very much!","I'm taking Mathematical Analysis ""I"" and I'm studying limits where I have limits to the infinity, but I don't know what's the difference between and I guess they are the same but I'm not sure. If you could help me I would appreciate it. Thank you very much!",\lim_{x \to \infty} \lim_{x \to +\infty},"['calculus', 'real-analysis', 'limits', 'notation', 'infinity']"
98,Different results in the apparently same improper integral (wolfram),Different results in the apparently same improper integral (wolfram),,"I thought the both limits above would give the same results, but it doesn't. Can someone explain why?","I thought the both limits above would give the same results, but it doesn't. Can someone explain why?",,"['real-analysis', 'integration', 'limits', 'improper-integrals', 'wolfram-alpha']"
99,"Prove $\displaystyle{\lim_{x \to 2}}\,x^3 + 1 = 9$ $(\delta < 1 \text{ or } \delta \leq 1)?$",Prove,"\displaystyle{\lim_{x \to 2}}\,x^3 + 1 = 9 (\delta < 1 \text{ or } \delta \leq 1)?","My math prof demonstrated this proof today and I'm not sure I understand all the steps. I don't understand why the $\delta$ has to be divided by 2 after selecting the minimum. Here are the steps he showed: We should show $\forall\epsilon > 0, \exists\delta > 0$ (let's call this eq1): $$|x-2| < \delta \implies |x^3 + 1 - 9| = |x-2||x^2 + 2x + 4| < \epsilon$$ Assume $\delta < 1$, this bounds $|x - 2| < 1$ and implies $1 < x < 3$. Now we know: $$|x^2 + 2x + 4| < 19$$ So, if we can show: $$|x-2| < \delta \implies |x-2||x^2 + 2x + 4| < 19|x-2| < \epsilon$$ eq1 follows for $\delta < 1$. The above is trivially true for $\delta = \epsilon/19$. But we must account for $\delta >= 1$ and therefore set: $$ \delta = \frac{1}{2}\min(\epsilon/19,1) $$ QED. Why is the $\frac{1}{2}$ factor needed? To me it looks redundant. According to the prof it was because $\delta = 1$ is a possibility. But if $\delta = 1$ then $\epsilon = 19$ and: $$|x-2| < 1 \implies |x-2||x^2 + 2x + 4| < 19$$ is obviously true. Could the $\frac{1}{2}$ factor have been avoided by instead assuming $\delta <= 1$? I'm not even sure why I have to ""soil"" my proof by covering the $\delta >= 1$ case with the $\min$ function. Can't I just say ""The proof holds for small deltas ($\delta < 1$) which is all that matters for limits?""","My math prof demonstrated this proof today and I'm not sure I understand all the steps. I don't understand why the $\delta$ has to be divided by 2 after selecting the minimum. Here are the steps he showed: We should show $\forall\epsilon > 0, \exists\delta > 0$ (let's call this eq1): $$|x-2| < \delta \implies |x^3 + 1 - 9| = |x-2||x^2 + 2x + 4| < \epsilon$$ Assume $\delta < 1$, this bounds $|x - 2| < 1$ and implies $1 < x < 3$. Now we know: $$|x^2 + 2x + 4| < 19$$ So, if we can show: $$|x-2| < \delta \implies |x-2||x^2 + 2x + 4| < 19|x-2| < \epsilon$$ eq1 follows for $\delta < 1$. The above is trivially true for $\delta = \epsilon/19$. But we must account for $\delta >= 1$ and therefore set: $$ \delta = \frac{1}{2}\min(\epsilon/19,1) $$ QED. Why is the $\frac{1}{2}$ factor needed? To me it looks redundant. According to the prof it was because $\delta = 1$ is a possibility. But if $\delta = 1$ then $\epsilon = 19$ and: $$|x-2| < 1 \implies |x-2||x^2 + 2x + 4| < 19$$ is obviously true. Could the $\frac{1}{2}$ factor have been avoided by instead assuming $\delta <= 1$? I'm not even sure why I have to ""soil"" my proof by covering the $\delta >= 1$ case with the $\min$ function. Can't I just say ""The proof holds for small deltas ($\delta < 1$) which is all that matters for limits?""",,"['calculus', 'limits', 'epsilon-delta']"
