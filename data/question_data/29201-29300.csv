,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is this a correct Monte-Carlo expression for $\pi$?,Is this a correct Monte-Carlo expression for ?,\pi,"I have a bicycle with one of those O-locks on it and too often when I park the bike and I want to lock it, the lock hits one of the spokes of the rim. This can be frustrating and surprises me that it occurs so often. I mean, the spokes are so thin and not that many really so one would think that this should not happen that often (like every day or so). And so every time this happened I reminded myself to calculate the probability of this happening . I just did it (after a year) and now I want to know what you guys think about my calculation, is it OK? This is not a textbook example so there is no answer to look up or anything, that's why I need your feedback. I have modeled the situation as shown in the figure below, where I have included one spoke only. Let the O-lock have diameter $d_{L}$ and the spoke have a diameter $d_S$. Let $R$ denote the ""radius"" from center of wheel to the point where the O-lock comes and goes (this is approximately equal to the radius of the rim). Then, we have that the corresponding angles are given by $w_S=d_S/R$ and $w_L = d_L/R$ so that the spoke will hit the lock (the shaded disk in figure below) when $\theta$ is in the interval $[0, w_L+w_S]$ modulo $2\pi$ (See figure: $R$ is fixed so the point $(R,\theta)$ is on a circle). Then the probability for hit (wheel with one spoke) is given by  $$ P(1) = \frac{w_L+w_S}{2\pi}\times 1 = \frac{1}{2\pi R}(d_L+d_S).$$ Generalizing to $N$ equally spaced spokes we get  $$ P(N) =\begin{cases} \frac{N}{2\pi R}(d_L+d_S)& \text{for } N=0,1\dots\\1 & \text{for } N\geq M= \Big\lceil\frac{2\pi R}{d_L+d_S}\Big\rceil\end{cases}. $$ Example: plugging in some typical numbers; $N=36, R\approx 0.3$m, $d_S\approx 2\times 10^{-3}$m , $d_L\approx \times 10^{-2}$m we find $$P(36) \approx 0.23$$ which kind of agrees with my everyday experience of this problem. I guess one could obtain a (Monte-Carlo)-value for $\pi$ this way? Could someone tell me what I have done wrong above? Or perhaps derive the correct expression for the probability?","I have a bicycle with one of those O-locks on it and too often when I park the bike and I want to lock it, the lock hits one of the spokes of the rim. This can be frustrating and surprises me that it occurs so often. I mean, the spokes are so thin and not that many really so one would think that this should not happen that often (like every day or so). And so every time this happened I reminded myself to calculate the probability of this happening . I just did it (after a year) and now I want to know what you guys think about my calculation, is it OK? This is not a textbook example so there is no answer to look up or anything, that's why I need your feedback. I have modeled the situation as shown in the figure below, where I have included one spoke only. Let the O-lock have diameter $d_{L}$ and the spoke have a diameter $d_S$. Let $R$ denote the ""radius"" from center of wheel to the point where the O-lock comes and goes (this is approximately equal to the radius of the rim). Then, we have that the corresponding angles are given by $w_S=d_S/R$ and $w_L = d_L/R$ so that the spoke will hit the lock (the shaded disk in figure below) when $\theta$ is in the interval $[0, w_L+w_S]$ modulo $2\pi$ (See figure: $R$ is fixed so the point $(R,\theta)$ is on a circle). Then the probability for hit (wheel with one spoke) is given by  $$ P(1) = \frac{w_L+w_S}{2\pi}\times 1 = \frac{1}{2\pi R}(d_L+d_S).$$ Generalizing to $N$ equally spaced spokes we get  $$ P(N) =\begin{cases} \frac{N}{2\pi R}(d_L+d_S)& \text{for } N=0,1\dots\\1 & \text{for } N\geq M= \Big\lceil\frac{2\pi R}{d_L+d_S}\Big\rceil\end{cases}. $$ Example: plugging in some typical numbers; $N=36, R\approx 0.3$m, $d_S\approx 2\times 10^{-3}$m , $d_L\approx \times 10^{-2}$m we find $$P(36) \approx 0.23$$ which kind of agrees with my everyday experience of this problem. I guess one could obtain a (Monte-Carlo)-value for $\pi$ this way? Could someone tell me what I have done wrong above? Or perhaps derive the correct expression for the probability?",,['probability']
1,Random point distribtion,Random point distribtion,,"How to generate numerically a set of random points $(x_1,y_1), (x_2,y_2),\cdots, (x_N,y_N)$ such that the pair-wise distances $d = \sqrt { (x_i-x_j)^2 + (y_i-y_j)^2}$, for all $ 0<i\le N, 0<j\le N $ satisfy some given distribution $P(d)$ (e.g., Gaussian, exponential, etc.).","How to generate numerically a set of random points $(x_1,y_1), (x_2,y_2),\cdots, (x_N,y_N)$ such that the pair-wise distances $d = \sqrt { (x_i-x_j)^2 + (y_i-y_j)^2}$, for all $ 0<i\le N, 0<j\le N $ satisfy some given distribution $P(d)$ (e.g., Gaussian, exponential, etc.).",,"['probability', 'statistics']"
2,"Ruin time for a two-input ""risk only"" slot machine","Ruin time for a two-input ""risk only"" slot machine",,"Imagine a ""risk only"" slot machine that takes 'coins' corresponding to some real number fraction of a dollar $p$, returns the coin with probability $p$, and eats the coin with probability $(1-p)$.  For example, a dime would be eaten with a probability of 90%, a nickel with probability 95%, and so forth. So let's keep feeding the machine two kinds of coins, $A$ and $B$, with fractional dollar values of $p_A$ and $p_B$, respectively.  I have $n_A$ coins of type $A$ and $n_B$ coins of type $B$.  Each time I use the slot machine, I randomly select a coin, ignoring its type, and place it in the machine.  I stop feeding coins into the machine when I run out of either type. CLARIFICATION - By ""randomly select a coin"" I mean that we select a coin from the population of all coins uniformly and randomly.  For instance, if we have $100$ dimes and $567$ nickels, we'd draw a dime with probability $\frac{100}{667}$. At this stopping point, what is the probability of ending with only coins of type A or only coins of Type B?  Provided we end with coins of one type / denomination, what probability distribution and expectation do we have for the number of remaining coins of this type / denomination? I'd also be curious on the number of coins of either type we needed to feed to the machine to reach this end-state?  E.g. how many times did we feed the machine a dime, and how many times did we feed the machine a nickel before stopping? ** If it helps, I can provide some simulation data.  For example, starting with $100$ dimes and $100$ nickels: $n_A = 100$ $n_B = 100$ $p_A = 0.10$ $p_B = 0.05$ We achieve the following results for $10^4$ trials: The mean number of times we place a dime in the machine $= 109.721$  (Median $ = 110$) The mean number of times we place a nickel in the machine $= 104.42$ (Median $ = 104$) The number of times we end with only dimes: $5669$ The number of times we end with only nickels: $4331$ The average number of dimes at the end state (conditioned on running out of nickels first): $2.18328$  (Median $= 2$) The average number of nickels at the end state (conditioned on running out of dimes first): $1.80513$  (Median $= 1$) ** Let's do another simulation starting with $82$ copies of hypothetical 75 cent coins and $432$ copies of 5 cent nickels, and again perform $10^4$ trials: $n_A = 82$ $n_B = 432$ $p_A = 0.75$ $p_B = 0.05$ We achieve the following results for $10^4$ trials: The mean number of times we place a 75 cent coin in the machine $= 268.213$  (Median $ = 267$) The mean number of times we place a 5 cent nickel in the machine $= 454.734$ (Median $ = 455$) The number of times we end with only 75 cent pieces: $9999$ The number of times we end with only 5 cent nickels: $1$ The average number of 75 cent coins at the end state (conditioned on running out of 5 cent nickels first): $14.9384$  (Median $= 15$) The average number of nickels at the end state (conditioned on running out of dimes first): $1$  (Median $= 1$)","Imagine a ""risk only"" slot machine that takes 'coins' corresponding to some real number fraction of a dollar $p$, returns the coin with probability $p$, and eats the coin with probability $(1-p)$.  For example, a dime would be eaten with a probability of 90%, a nickel with probability 95%, and so forth. So let's keep feeding the machine two kinds of coins, $A$ and $B$, with fractional dollar values of $p_A$ and $p_B$, respectively.  I have $n_A$ coins of type $A$ and $n_B$ coins of type $B$.  Each time I use the slot machine, I randomly select a coin, ignoring its type, and place it in the machine.  I stop feeding coins into the machine when I run out of either type. CLARIFICATION - By ""randomly select a coin"" I mean that we select a coin from the population of all coins uniformly and randomly.  For instance, if we have $100$ dimes and $567$ nickels, we'd draw a dime with probability $\frac{100}{667}$. At this stopping point, what is the probability of ending with only coins of type A or only coins of Type B?  Provided we end with coins of one type / denomination, what probability distribution and expectation do we have for the number of remaining coins of this type / denomination? I'd also be curious on the number of coins of either type we needed to feed to the machine to reach this end-state?  E.g. how many times did we feed the machine a dime, and how many times did we feed the machine a nickel before stopping? ** If it helps, I can provide some simulation data.  For example, starting with $100$ dimes and $100$ nickels: $n_A = 100$ $n_B = 100$ $p_A = 0.10$ $p_B = 0.05$ We achieve the following results for $10^4$ trials: The mean number of times we place a dime in the machine $= 109.721$  (Median $ = 110$) The mean number of times we place a nickel in the machine $= 104.42$ (Median $ = 104$) The number of times we end with only dimes: $5669$ The number of times we end with only nickels: $4331$ The average number of dimes at the end state (conditioned on running out of nickels first): $2.18328$  (Median $= 2$) The average number of nickels at the end state (conditioned on running out of dimes first): $1.80513$  (Median $= 1$) ** Let's do another simulation starting with $82$ copies of hypothetical 75 cent coins and $432$ copies of 5 cent nickels, and again perform $10^4$ trials: $n_A = 82$ $n_B = 432$ $p_A = 0.75$ $p_B = 0.05$ We achieve the following results for $10^4$ trials: The mean number of times we place a 75 cent coin in the machine $= 268.213$  (Median $ = 267$) The mean number of times we place a 5 cent nickel in the machine $= 454.734$ (Median $ = 455$) The number of times we end with only 75 cent pieces: $9999$ The number of times we end with only 5 cent nickels: $1$ The average number of 75 cent coins at the end state (conditioned on running out of 5 cent nickels first): $14.9384$  (Median $= 15$) The average number of nickels at the end state (conditioned on running out of dimes first): $1$  (Median $= 1$)",,"['probability', 'combinatorics', 'stochastic-processes']"
3,Mean hitting time: reference request,Mean hitting time: reference request,,"After answering [this question] ( Expectation of a stopping time uniquely determined by a function ) I was looking for the literature on the mean hitting/exit time for a discrete-time Markov process. In Meyn and Tweedie, Durett and some other books I haven't found much information. Google also didn't help much for the discrete-time setting. I guess that for the uncountable state space, mean hitting time equation shares the same properties as for the countable state space. However, I would prefer to read a book chapter on this topic. Dynkin briefly discussed it, though for the continuous time and too briefly.","After answering [this question] ( Expectation of a stopping time uniquely determined by a function ) I was looking for the literature on the mean hitting/exit time for a discrete-time Markov process. In Meyn and Tweedie, Durett and some other books I haven't found much information. Google also didn't help much for the discrete-time setting. I guess that for the uncountable state space, mean hitting time equation shares the same properties as for the countable state space. However, I would prefer to read a book chapter on this topic. Dynkin briefly discussed it, though for the continuous time and too briefly.",,"['probability', 'reference-request', 'stochastic-processes', 'markov-process']"
4,Proportion of spanning trees in a network in a social media messaging context,Proportion of spanning trees in a network in a social media messaging context,,"Consider a graph, such as the following: I'm considering a model of message propagation ( e.g. re-tweeting) in this network, starting from a root node ( e.g. the node 1 in the lower-left). I'm modelling the message propagation in terms of trees rooted at the message source, where a node v is a parent to another node w if w first hears the message from v . The message propagates outward from 1 , in a tree which ""grows"" in an iterative process. In this process, nodes which have been reached are either branching nodes ( i.e. are the parent of some other node), live leaves (nodes which may become branch nodes), or dead leaves . Initially, all the neighbors of node 1 are children of 1 , and are live leaves. The message propagates by iterations, as follows. We consider an arbitrary ordering L = (ℓ 1 , ..., ℓ n ) of the live leaves at the beginning of the iteration. For each 1 ≤ j ≤ n, we do the following: Decide whether the node ℓ j dies (doesn't propagate the message) or becomes a branch node (propagates the message). If all of the nodes adjacent to ℓ j are already in the tree, then it dies by default. If ℓ j becomes a branch node, we attach every neighbor v of ℓ j which is not already in the tree to ℓ j , as a live leaf node for the following iteration. After iterating through the elements of L , we proceed to the next iteration. If there are no more live leaves in the tree, we stop. For the graph above, here are the trees that may be generated by this process: I'm interested in considering how many of the trees which can be generated by this process are spanning trees , i.e. contain every node in the graph. Is there any formula to determine the ratio of the spanning trees to the total number of such trees? N.B. The construction above is similar to a Galton-Watson process. However, there isn't meant to be a probabilistic model underlying the growth; the above is meant only to implicity  describe a recursive process to recognise whether a subtree in the graph is valid in my model. I've added the probability tag just in case there is a useful approach from that direction. Thanks!","Consider a graph, such as the following: I'm considering a model of message propagation ( e.g. re-tweeting) in this network, starting from a root node ( e.g. the node 1 in the lower-left). I'm modelling the message propagation in terms of trees rooted at the message source, where a node v is a parent to another node w if w first hears the message from v . The message propagates outward from 1 , in a tree which ""grows"" in an iterative process. In this process, nodes which have been reached are either branching nodes ( i.e. are the parent of some other node), live leaves (nodes which may become branch nodes), or dead leaves . Initially, all the neighbors of node 1 are children of 1 , and are live leaves. The message propagates by iterations, as follows. We consider an arbitrary ordering L = (ℓ 1 , ..., ℓ n ) of the live leaves at the beginning of the iteration. For each 1 ≤ j ≤ n, we do the following: Decide whether the node ℓ j dies (doesn't propagate the message) or becomes a branch node (propagates the message). If all of the nodes adjacent to ℓ j are already in the tree, then it dies by default. If ℓ j becomes a branch node, we attach every neighbor v of ℓ j which is not already in the tree to ℓ j , as a live leaf node for the following iteration. After iterating through the elements of L , we proceed to the next iteration. If there are no more live leaves in the tree, we stop. For the graph above, here are the trees that may be generated by this process: I'm interested in considering how many of the trees which can be generated by this process are spanning trees , i.e. contain every node in the graph. Is there any formula to determine the ratio of the spanning trees to the total number of such trees? N.B. The construction above is similar to a Galton-Watson process. However, there isn't meant to be a probabilistic model underlying the growth; the above is meant only to implicity  describe a recursive process to recognise whether a subtree in the graph is valid in my model. I've added the probability tag just in case there is a useful approach from that direction. Thanks!",,"['probability', 'combinatorics', 'graph-theory']"
5,"What is the expected length of the ""Slimy Slug"" cellular automata","What is the expected length of the ""Slimy Slug"" cellular automata",,"A ""Slimy Slug"" is a simple probabilistic cellular automata defined as follows: The Slimy Slug lives on an infinite, two-dimensional, white-coloured, square grid. For each iteration, the slug follows these rules: Paint the cell the Slug is on black. Look at the 4 orthogonal adjacent cells (i.e. N,E,S,W) If zero of the cells are white, Halt . If exactly one of the cells is white, move to the white cell. If more than one of the cells are white, randomly move to one of the white cells. (e.g. if the white cells are N,E,W, each cell has a 1/3 probability of being the destination.) Go to rule 1. The slug will follow a random walk, and although it could theoretically continue for an infinite number of steps, it will generally halt when it traps itself. An example of a possible trail of the slug is shown below (Instead of black and white, I have false-coloured the cells with a gradient to illustrate the path of the slug). This trail has a length of 99 steps, and the slug started in the top right, and worked it's way down to the bottom left. Is it possible to arrive at an expression for the expected length of the Slimy Slug's trail? This is outside my field, so I haven't had much success in researching if this is a studied problem or not. Via numerical simulation, I have arrived at a value of 70.799611 for a set of 1,000,000 runs, but I'm interested in seeing if a value can be arrived at without numerical simulation. This is motivated by a related problem in game design/educational exercise design.","A ""Slimy Slug"" is a simple probabilistic cellular automata defined as follows: The Slimy Slug lives on an infinite, two-dimensional, white-coloured, square grid. For each iteration, the slug follows these rules: Paint the cell the Slug is on black. Look at the 4 orthogonal adjacent cells (i.e. N,E,S,W) If zero of the cells are white, Halt . If exactly one of the cells is white, move to the white cell. If more than one of the cells are white, randomly move to one of the white cells. (e.g. if the white cells are N,E,W, each cell has a 1/3 probability of being the destination.) Go to rule 1. The slug will follow a random walk, and although it could theoretically continue for an infinite number of steps, it will generally halt when it traps itself. An example of a possible trail of the slug is shown below (Instead of black and white, I have false-coloured the cells with a gradient to illustrate the path of the slug). This trail has a length of 99 steps, and the slug started in the top right, and worked it's way down to the bottom left. Is it possible to arrive at an expression for the expected length of the Slimy Slug's trail? This is outside my field, so I haven't had much success in researching if this is a studied problem or not. Via numerical simulation, I have arrived at a value of 70.799611 for a set of 1,000,000 runs, but I'm interested in seeing if a value can be arrived at without numerical simulation. This is motivated by a related problem in game design/educational exercise design.",,"['probability', 'random-walk', 'cellular-automata']"
6,Proof of inversion formula in Probability,Proof of inversion formula in Probability,,"Theorem : Let $X$ be a real random variable such that $\phi_X \in L^1$ i.e $\int_{\mathbb{R}} \vert \phi_X(t) \vert < \infty$ , then $X$ has density $f_X(x) \in C_b(\mathbb{R})$ given by $$f_X(x) = \frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt$$ (Where $\phi_X$ denotes the characteristic function of $X$ ) The proof articulates in two parts : The first where we assume we already know $X$ has a density $f$ and we prove the inequality above, the second where we don't know such $f$ exists and we lead back to the first case using the trick of taking $X+\epsilon N$ where $N \sim N(0,1)$ . The sketch of the first part of the proof, which is where my problems are is the following : We consider a $g \geq 0, g \in C_{b}(\mathbb{R})$ , such that $g = 0$ outside a compact, i.e $g \in C_{c}(\mathbb{R})$ and we apply the isometry lemma to $f_X + g$ which leads us to (Using Fubini-Tonelli and the fact that $\frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt$ is real) $$\int g(x)f_X(x)dx = \mathbb{E}[g(X)] = \int g(x)[\frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt]dx$$ Which concludes the proofs for $g$ assumed as mentioned at the beginning. But how to extend the result to just continuos and bounded functions ? During this next proof the following three observation are made : $1) \frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt$ is continuos in $x$ (and I was able to prove it as a consequence of dominated convergence theorem, prooving continuity by sequences). $2) \frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt \geq 0$ 3) $\hspace{0.1cm} \exists \hspace{0.1cm} g_n \uparrow 1 $ with $g_n \in C_b(\mathbb{R})$ I was able to prove step $2)$ in the following way with an hint which I was unable to prove (so this should be the way to prove it). The proof goes like this : if it was strictly negative, by continuity (prooved in the first observation) exists an open set $U$ where the function is still strictly negative, and then I can find a $g > 0, g \in C_b(\mathbb{R})$ defined on $U$ and conclude by contradiction thanks to the fact that in this case we would have $0 > \frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt = E[g(X)] > 0$ , thanks to $g$ . As far concerned the third point I don't know where to start, I thought it could be useful to use a simplified version of Urysohn Lemma but unsuccefully. I was unable to prove the highlighted sentences, there are any way to explicit such functions ? Any direct proof, explicit or not, would be appreciated, and some reference of using Fourier trasfrom in Probability as well, those seemed nice tricks to know.","Theorem : Let be a real random variable such that i.e , then has density given by (Where denotes the characteristic function of ) The proof articulates in two parts : The first where we assume we already know has a density and we prove the inequality above, the second where we don't know such exists and we lead back to the first case using the trick of taking where . The sketch of the first part of the proof, which is where my problems are is the following : We consider a , such that outside a compact, i.e and we apply the isometry lemma to which leads us to (Using Fubini-Tonelli and the fact that is real) Which concludes the proofs for assumed as mentioned at the beginning. But how to extend the result to just continuos and bounded functions ? During this next proof the following three observation are made : is continuos in (and I was able to prove it as a consequence of dominated convergence theorem, prooving continuity by sequences). 3) with I was able to prove step in the following way with an hint which I was unable to prove (so this should be the way to prove it). The proof goes like this : if it was strictly negative, by continuity (prooved in the first observation) exists an open set where the function is still strictly negative, and then I can find a defined on and conclude by contradiction thanks to the fact that in this case we would have , thanks to . As far concerned the third point I don't know where to start, I thought it could be useful to use a simplified version of Urysohn Lemma but unsuccefully. I was unable to prove the highlighted sentences, there are any way to explicit such functions ? Any direct proof, explicit or not, would be appreciated, and some reference of using Fourier trasfrom in Probability as well, those seemed nice tricks to know.","X \phi_X \in L^1 \int_{\mathbb{R}} \vert \phi_X(t) \vert < \infty X f_X(x) \in C_b(\mathbb{R}) f_X(x) = \frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt \phi_X X X f f X+\epsilon N N \sim N(0,1) g \geq 0, g \in C_{b}(\mathbb{R}) g = 0 g \in C_{c}(\mathbb{R}) f_X + g \frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt \int g(x)f_X(x)dx = \mathbb{E}[g(X)] = \int g(x)[\frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt]dx g 1) \frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt x 2) \frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt \geq 0 \hspace{0.1cm} \exists \hspace{0.1cm} g_n \uparrow 1  g_n \in C_b(\mathbb{R}) 2) U g > 0, g \in C_b(\mathbb{R}) U 0 > \frac{1}{2\pi}\int_{\mathbb{R}}\phi_X(t)e^{-itx}dt = E[g(X)] > 0 g","['probability', 'integration', 'probability-theory', 'lebesgue-integral', 'fourier-transform']"
7,Find $\int_{0}^{\frac{r}{2}} {\binom{n}{p} \binom{n-p}{r-2p} 2^{r-2p}}{\binom{2n}{r}^{-1}} \ \text{d}p$,Find,\int_{0}^{\frac{r}{2}} {\binom{n}{p} \binom{n-p}{r-2p} 2^{r-2p}}{\binom{2n}{r}^{-1}} \ \text{d}p,"Now also asked on MathOverflow and answered affirmatively there . Let there be $n$ pairs of shoes in a box. The the probability that from the $r \le n$ shoes I am taking out of the box there are exactly $p$ pairs is given by \begin{equation*}         \mathbb{P}_{n}^{(r)}(p)         = \frac{\binom{n}{p} \binom{n-p}{r-2p} 2^{r-2p}}{\binom{2n}{r}}. \end{equation*} For $n = 15$ and $r \in \{6,8,10\}$ . The function (assuming the continuous factorial equivalents) looks like this: I am interested in finding the area under that curve, namely $$\int_{0}^{\frac{r}{2}} \frac{\binom{n}{p} \binom{n-p}{r-2p} 2^{r-2p}}{\binom{2n}{r}} \ \text{d}p$$ According to numerical estimates in the comments I suspect that it converges to 1 for $n = r \to \infty$ . I consulted this question but could derive how that would help me. I also thought about writing the first product of binomial coefficients as $$ \binom{n}{n - p}\binom{n - p}{r - 2p} $$ which is similar to the form $\binom{f(x)}{f(y)} \binom{f(y)}{f(x)}$ mentioned in this question .","Now also asked on MathOverflow and answered affirmatively there . Let there be pairs of shoes in a box. The the probability that from the shoes I am taking out of the box there are exactly pairs is given by For and . The function (assuming the continuous factorial equivalents) looks like this: I am interested in finding the area under that curve, namely According to numerical estimates in the comments I suspect that it converges to 1 for . I consulted this question but could derive how that would help me. I also thought about writing the first product of binomial coefficients as which is similar to the form mentioned in this question .","n r \le n p \begin{equation*}
        \mathbb{P}_{n}^{(r)}(p)
        = \frac{\binom{n}{p} \binom{n-p}{r-2p} 2^{r-2p}}{\binom{2n}{r}}.
\end{equation*} n = 15 r \in \{6,8,10\} \int_{0}^{\frac{r}{2}} \frac{\binom{n}{p} \binom{n-p}{r-2p} 2^{r-2p}}{\binom{2n}{r}} \ \text{d}p n = r \to \infty 
\binom{n}{n - p}\binom{n - p}{r - 2p}
 \binom{f(x)}{f(y)} \binom{f(y)}{f(x)}","['probability', 'integration', 'combinatorics']"
8,Reversal of an Autoregressive Cauchy Markov Chain,Reversal of an Autoregressive Cauchy Markov Chain,,"Let $\mu_0 (dx)$ be the standard one-dimensional Cauchy distribution, i.e. \begin{align} \mu_0 (dx) = \frac{1}{\pi} \frac{1}{1+x^2} dx. \end{align} Suppose I fix $h \in [0, 1]$ , and form a Markov chain $\{X_n\}_{n \geqslant 0}$ as follows: At step $n$ , I sample $Y_n \sim \mu_0$ . I then set $X_{n+1} = (1 - h) X_n + h Y_n$ It is not so hard to show that this chain admits $\mu_0$ as a stationary measure, as this essentially comes from the fact that Cauchy distribution is a stable distribution. What I'm interested in is the reversal of this Markov chain. More precisely, if the chain I describe above uses the Markov kernel $q (x \to dy)$ , I want to understand the Markov kernel $r$ such that \begin{align} \mu_0 (dx) q (x \to dy) = \mu_0 (dy) r (y \to dx). \end{align} Fortunately, all of the quantities involved have densities with respect to Lebesgue measure, and as such, I can write down what $r (y \to dx)$ is: \begin{align} r (y \to dx) = \frac{1 + y^2}{\pi} \frac{1}{1 + x^2} \frac{h}{ h^2 + (y - (1 - h) x)^2} dx. \end{align} My question is then: is there a simple, elegant way to draw exact samples from $r$ ? I would highlight that this is not a purely algorithmic question; I'd really like to understand what this reversal kernel $r$ is doing. A nice byproduct of that would then be that I could simulate from it easily. For completeness, some of the `purely algorithmic' solutions I had considered were the following. I could try rejection sampling, and in principle this would work, but it wouldn't really give me insight into the nature of the Markov chain. I could try something like the inverse CDF method, but it seems to me that the CDF of $r$ is not particularly nice to work with. As such, I'd have to use e.g. Newton iterations to use this method, and I'd prefer to not have to do this.","Let be the standard one-dimensional Cauchy distribution, i.e. Suppose I fix , and form a Markov chain as follows: At step , I sample . I then set It is not so hard to show that this chain admits as a stationary measure, as this essentially comes from the fact that Cauchy distribution is a stable distribution. What I'm interested in is the reversal of this Markov chain. More precisely, if the chain I describe above uses the Markov kernel , I want to understand the Markov kernel such that Fortunately, all of the quantities involved have densities with respect to Lebesgue measure, and as such, I can write down what is: My question is then: is there a simple, elegant way to draw exact samples from ? I would highlight that this is not a purely algorithmic question; I'd really like to understand what this reversal kernel is doing. A nice byproduct of that would then be that I could simulate from it easily. For completeness, some of the `purely algorithmic' solutions I had considered were the following. I could try rejection sampling, and in principle this would work, but it wouldn't really give me insight into the nature of the Markov chain. I could try something like the inverse CDF method, but it seems to me that the CDF of is not particularly nice to work with. As such, I'd have to use e.g. Newton iterations to use this method, and I'd prefer to not have to do this.","\mu_0 (dx) \begin{align}
\mu_0 (dx) = \frac{1}{\pi} \frac{1}{1+x^2} dx.
\end{align} h \in [0, 1] \{X_n\}_{n \geqslant 0} n Y_n \sim \mu_0 X_{n+1} = (1 - h) X_n + h Y_n \mu_0 q (x \to dy) r \begin{align}
\mu_0 (dx) q (x \to dy) = \mu_0 (dy) r (y \to dx).
\end{align} r (y \to dx) \begin{align}
r (y \to dx) = \frac{1 + y^2}{\pi} \frac{1}{1 + x^2} \frac{h}{ h^2 + (y - (1 - h) x)^2} dx.
\end{align} r r r","['probability', 'markov-chains']"
9,Generating function for number of $r$-disjoint subsets each of size $k$,Generating function for number of -disjoint subsets each of size,r k,"Fix $n, k$. Then $$ C^{n,k}_r =\frac{1}{r!} \binom{n}{\underbrace{k, \ldots, k}_{\text{r times}}, n-rk} = \frac{n!}{r!(k!)^r(n - kr)!} $$ is the number of ways to form $r$ disjoint subsets each of size $k$, of $\{1 \ldots n\}$. Is there a closed form expression for its generating function $g(t) = \sum_{r=0}^{\infty} C^{n, k}_r t^r$ ? EDIT: I should explain my motivation for this problem. Let $\mathcal{C}$ be a (possibly empty) random collection of $k$-sized disjoint subsets of $\{ 1 \ldots n\}$. That is: Let $\mathcal{P}_{n, k} = \{ A \, | \, A \subseteq \{ 1 \ldots n\}, |A|=k\}$ Then $\mathcal{C} = \{A_1, A_2 \ldots A_r\} \subseteq \mathcal{P}_{n, k}$  so that $A_i \cap A_j = \emptyset$ when $i \neq j$. $\mathcal{C}$ is random. If we assume that: $\mathbb{P}(A \in \mathcal{C}) = \alpha$ for any $A \in \mathcal{P}_{n,k}$. Whenever we have a collection of disjoint sets $A_1, A_2, \ldots, A_r \in \mathcal{P}_{n,k}$ the events $\{ A_i \in \mathcal{C} \}$ are independent, i.e. $$ \mathbb{P}(A_1 \in \mathcal{C}, A_2 \in \mathcal{C}, \ldots, A_r \in \mathcal{C}) = \prod_{i=1}^r \mathbb{P}(A_i \in \mathcal{C}) = \alpha^r. $$ Then $$ \begin{align} \mathbb{P}(\mathcal{C} \neq \emptyset) &= \mathbb{P}(\bigcup_{A \in \mathcal{P}_{n,k}} \{ A \in \mathcal{C}\})\\     &= - \sum_{r=1}^{\infty} C^{n,k}_{r} (-\alpha)^{r}. \tag{By inclusion exclusion formula}  \end{align} $$","Fix $n, k$. Then $$ C^{n,k}_r =\frac{1}{r!} \binom{n}{\underbrace{k, \ldots, k}_{\text{r times}}, n-rk} = \frac{n!}{r!(k!)^r(n - kr)!} $$ is the number of ways to form $r$ disjoint subsets each of size $k$, of $\{1 \ldots n\}$. Is there a closed form expression for its generating function $g(t) = \sum_{r=0}^{\infty} C^{n, k}_r t^r$ ? EDIT: I should explain my motivation for this problem. Let $\mathcal{C}$ be a (possibly empty) random collection of $k$-sized disjoint subsets of $\{ 1 \ldots n\}$. That is: Let $\mathcal{P}_{n, k} = \{ A \, | \, A \subseteq \{ 1 \ldots n\}, |A|=k\}$ Then $\mathcal{C} = \{A_1, A_2 \ldots A_r\} \subseteq \mathcal{P}_{n, k}$  so that $A_i \cap A_j = \emptyset$ when $i \neq j$. $\mathcal{C}$ is random. If we assume that: $\mathbb{P}(A \in \mathcal{C}) = \alpha$ for any $A \in \mathcal{P}_{n,k}$. Whenever we have a collection of disjoint sets $A_1, A_2, \ldots, A_r \in \mathcal{P}_{n,k}$ the events $\{ A_i \in \mathcal{C} \}$ are independent, i.e. $$ \mathbb{P}(A_1 \in \mathcal{C}, A_2 \in \mathcal{C}, \ldots, A_r \in \mathcal{C}) = \prod_{i=1}^r \mathbb{P}(A_i \in \mathcal{C}) = \alpha^r. $$ Then $$ \begin{align} \mathbb{P}(\mathcal{C} \neq \emptyset) &= \mathbb{P}(\bigcup_{A \in \mathcal{P}_{n,k}} \{ A \in \mathcal{C}\})\\     &= - \sum_{r=1}^{\infty} C^{n,k}_{r} (-\alpha)^{r}. \tag{By inclusion exclusion formula}  \end{align} $$",,"['probability', 'combinatorics', 'generating-functions']"
10,Upper Bound Lemma implies the Ergodic Theorem for Random Walks on Groups?,Upper Bound Lemma implies the Ergodic Theorem for Random Walks on Groups?,,"Cross posted on Mathoverflow Ergodic Theorem A random walk on a finite group $G$ driven by a probability $\nu\in M_p(G)$ is ergodic if $\operatorname{supp}(\nu)$ is not concentrated   on a proper subgroup $S\subset G$ nor the coset of a normal subgroup   $N\triangleleft G$. In this case the convolution powers of $\nu$ converge to the uniform distribution $\pi$ on $G$: $$\nu^{\star k}\rightarrow \pi.$$ Where $\|\cdot \|=\frac12\|\cdot\|_{\ell_1}$,  $$(\nu\star \nu)(g)=\sum_{t\in G}\nu(gt^{-1})\nu(t),$$ $d_\alpha$ is the dimension of a representation $\rho_\alpha:G\rightarrow \operatorname{GL}(V)$,  $$\hat{\nu}(\rho)=\sum_{t\in G}\nu(t)\rho(t),$$ and $T^*$ denotes the conjugate transpose of $T$ in $\operatorname{GL}(V)$, Diaconis & Shahshahani proved the following: Upper Bound Lemma Where $\operatorname{Irr}(G)\backslash \tau$ is the set of non-trivial unitary irreducible representations on $G$:   $$\|\nu^{\star k}-\pi\|^2\leq \frac{1}{4}\sum_{\rho_\alpha\in \operatorname{Irr}(G)\backslash \tau}d_\alpha \operatorname{Tr}[\widehat{\nu}(\rho_\alpha)^k(\widehat{\nu}(\rho_\alpha)^*)^k].$$ The Upper Bound Lemma still holds if the random walk driven by $\nu$ is not ergodic. Question: Can the Upper Bound Lemma be used to prove the Ergodic Theorem? Can the Upper Bound Lemma show that for $\nu^{\star k}$ to converge to $\pi$ it is necessary that $\nu$ is not supported on a subgroup (irreducibility)? I suspect aperiodicity (not concentrated on the coset of normal subgroup) might be harder. My own MSc thesis should be a good reference for some of this.","Cross posted on Mathoverflow Ergodic Theorem A random walk on a finite group $G$ driven by a probability $\nu\in M_p(G)$ is ergodic if $\operatorname{supp}(\nu)$ is not concentrated   on a proper subgroup $S\subset G$ nor the coset of a normal subgroup   $N\triangleleft G$. In this case the convolution powers of $\nu$ converge to the uniform distribution $\pi$ on $G$: $$\nu^{\star k}\rightarrow \pi.$$ Where $\|\cdot \|=\frac12\|\cdot\|_{\ell_1}$,  $$(\nu\star \nu)(g)=\sum_{t\in G}\nu(gt^{-1})\nu(t),$$ $d_\alpha$ is the dimension of a representation $\rho_\alpha:G\rightarrow \operatorname{GL}(V)$,  $$\hat{\nu}(\rho)=\sum_{t\in G}\nu(t)\rho(t),$$ and $T^*$ denotes the conjugate transpose of $T$ in $\operatorname{GL}(V)$, Diaconis & Shahshahani proved the following: Upper Bound Lemma Where $\operatorname{Irr}(G)\backslash \tau$ is the set of non-trivial unitary irreducible representations on $G$:   $$\|\nu^{\star k}-\pi\|^2\leq \frac{1}{4}\sum_{\rho_\alpha\in \operatorname{Irr}(G)\backslash \tau}d_\alpha \operatorname{Tr}[\widehat{\nu}(\rho_\alpha)^k(\widehat{\nu}(\rho_\alpha)^*)^k].$$ The Upper Bound Lemma still holds if the random walk driven by $\nu$ is not ergodic. Question: Can the Upper Bound Lemma be used to prove the Ergodic Theorem? Can the Upper Bound Lemma show that for $\nu^{\star k}$ to converge to $\pi$ it is necessary that $\nu$ is not supported on a subgroup (irreducibility)? I suspect aperiodicity (not concentrated on the coset of normal subgroup) might be harder. My own MSc thesis should be a good reference for some of this.",,"['probability', 'group-theory', 'finite-groups', 'representation-theory', 'markov-chains']"
11,Probability that a random edge coloring of the complete graph is proper,Probability that a random edge coloring of the complete graph is proper,,"Suppose we color the edges $\{1,\ldots, {n \choose 2}\}$ of the complete graph on $n$ vertices with $m$ colors each edge being assigned a color picked uniformly at random from $\{1,\ldots, m\}.$ I would like to estimate the probability that the obtained random coloring is proper, that is all edges incident with a vertex $v$ are colored with different colors. One way to do this is as follows. Suppose $E_i$ is the event that the edge $e_i$ of $K_n$ is colored with a color that already occurs at its adjacent edges. Then $$Pr[E_i] = \frac{1}{m} (1 - (1-\frac{1}{m})^{2n-4})$$ and thus the probability that $G$ is not colored properly is estimated as $$Pr[E_1\cup \ldots E_{n \choose 2}] \leq \frac{n(n-1)}{2m}  (1 - (1-\frac{1}{m})^{2n-4} )$$ Now this is not a good estimate since the right hand size is larger then one for any $m$ that is not ""large enough"". Another way to estimate this is to define the event $V_i$ to be that the $i$th vertex of our graph is incident with edges of distinct colors and use a similar estimate. But again the given bound is not very sharp. Hence I am wondering is there a more delicate way to estimate the mentioned probability? Is this known? Is there a different way to model this ?","Suppose we color the edges $\{1,\ldots, {n \choose 2}\}$ of the complete graph on $n$ vertices with $m$ colors each edge being assigned a color picked uniformly at random from $\{1,\ldots, m\}.$ I would like to estimate the probability that the obtained random coloring is proper, that is all edges incident with a vertex $v$ are colored with different colors. One way to do this is as follows. Suppose $E_i$ is the event that the edge $e_i$ of $K_n$ is colored with a color that already occurs at its adjacent edges. Then $$Pr[E_i] = \frac{1}{m} (1 - (1-\frac{1}{m})^{2n-4})$$ and thus the probability that $G$ is not colored properly is estimated as $$Pr[E_1\cup \ldots E_{n \choose 2}] \leq \frac{n(n-1)}{2m}  (1 - (1-\frac{1}{m})^{2n-4} )$$ Now this is not a good estimate since the right hand size is larger then one for any $m$ that is not ""large enough"". Another way to estimate this is to define the event $V_i$ to be that the $i$th vertex of our graph is incident with edges of distinct colors and use a similar estimate. But again the given bound is not very sharp. Hence I am wondering is there a more delicate way to estimate the mentioned probability? Is this known? Is there a different way to model this ?",,"['probability', 'combinatorics', 'graph-theory', 'coloring']"
12,Extracting an (almost) independent large subset from a pairwise independent set of Bernoulli variables,Extracting an (almost) independent large subset from a pairwise independent set of Bernoulli variables,,"Let $n>1$, and let $X_1,X_2, \ldots ,X_n$ be non-constant random variables with values in $\lbrace 0,1 \rbrace$. Let us say that a subset of variables $X_{i_1},X_{i_2}, \ldots,X_{i_d}$ is complete if the vector $\overrightarrow{X}=(X_{i_1},\ldots,X_{i_d})$ satisfies $P(\overrightarrow{X}=\overrightarrow{c})>0$ for any $\overrightarrow{c}\in \lbrace 0,1 \rbrace^d$. Prove or find a counterexample :  if $X_1,X_2, \ldots ,X_n$ are pairwise independent Bernoulli variables, then we may extract a complete subset of cardinality at least $t+1$, where $t$ is the largest integer satisfying $2^{t} \leq n$. This is true for $n=3$ (and hence also true for $n$ between $3$ and $7$), as is shown  in the main answer to that MathOverflow question . (That other MathOverflow question is also related, and provides several links) If true, this result is sharp, as can be seen by the classical example of taking all arbitrary sums modulo 2 of an initial set of fully independent $t+1$ Bernoulli variables. This produces a set of pairwise independent $2^{t+1}-1$ variables, and where the maximal cardinality of a complete subset is $t+1$. Update 10/10/2012 : By induction, it would suffice to show the following : if $X_1, \ldots ,X_t$ is a fully independent set of $t$ Bernoulli variables and $X$ is another Bernoulli variable, such that the pair $(X_i,X)$ is independent for each $i$, then there are coefficients $\varepsilon_0,\varepsilon_1, \ldots ,\varepsilon_t$ in $\lbrace 0,1 \rbrace$ such that, if we put $$ H=\Bigg\lbrace (x_1,\ldots,x_t,x) \in \lbrace 0,1 \rbrace ^{t+1} \Bigg| x=\varepsilon_0+\sum_{k=1}^{t}\varepsilon_kx_k \ {\sf mod} \ 2\Bigg\rbrace,  \ \overrightarrow{X}=(X_{1},\ldots,X_{t},X) $$ then $P(\overrightarrow{X}=h)>0$ for any $h\in H$.","Let $n>1$, and let $X_1,X_2, \ldots ,X_n$ be non-constant random variables with values in $\lbrace 0,1 \rbrace$. Let us say that a subset of variables $X_{i_1},X_{i_2}, \ldots,X_{i_d}$ is complete if the vector $\overrightarrow{X}=(X_{i_1},\ldots,X_{i_d})$ satisfies $P(\overrightarrow{X}=\overrightarrow{c})>0$ for any $\overrightarrow{c}\in \lbrace 0,1 \rbrace^d$. Prove or find a counterexample :  if $X_1,X_2, \ldots ,X_n$ are pairwise independent Bernoulli variables, then we may extract a complete subset of cardinality at least $t+1$, where $t$ is the largest integer satisfying $2^{t} \leq n$. This is true for $n=3$ (and hence also true for $n$ between $3$ and $7$), as is shown  in the main answer to that MathOverflow question . (That other MathOverflow question is also related, and provides several links) If true, this result is sharp, as can be seen by the classical example of taking all arbitrary sums modulo 2 of an initial set of fully independent $t+1$ Bernoulli variables. This produces a set of pairwise independent $2^{t+1}-1$ variables, and where the maximal cardinality of a complete subset is $t+1$. Update 10/10/2012 : By induction, it would suffice to show the following : if $X_1, \ldots ,X_t$ is a fully independent set of $t$ Bernoulli variables and $X$ is another Bernoulli variable, such that the pair $(X_i,X)$ is independent for each $i$, then there are coefficients $\varepsilon_0,\varepsilon_1, \ldots ,\varepsilon_t$ in $\lbrace 0,1 \rbrace$ such that, if we put $$ H=\Bigg\lbrace (x_1,\ldots,x_t,x) \in \lbrace 0,1 \rbrace ^{t+1} \Bigg| x=\varepsilon_0+\sum_{k=1}^{t}\varepsilon_kx_k \ {\sf mod} \ 2\Bigg\rbrace,  \ \overrightarrow{X}=(X_{1},\ldots,X_{t},X) $$ then $P(\overrightarrow{X}=h)>0$ for any $h\in H$.",,"['probability', 'combinatorics']"
13,Prove there are no hidden messages in Pi,Prove there are no hidden messages in Pi,,"Assume that a proof that pi is normal existed. Is it then possible that starting at some finite position x in pi, from there on every p(n)'th digit is 0, where p(n) is the n'th prime? I know probability arguments say no, but do they also prove that it is impossible? Is there a way to disprove the statement? Also, the digits of Pi can tell us certain mathematical truths, for instance that the circumference of a circle is less then any other shape with same area. The question is, is there a limit to the information one can extract from the digits of Pi? Is it possible to reconstruct all theorems from the digits of Pi? What sort of truths can be extracted from the digits of Pi? Is entire math and all truths somehow encoded within the digits of Pi ?","Assume that a proof that pi is normal existed. Is it then possible that starting at some finite position x in pi, from there on every p(n)'th digit is 0, where p(n) is the n'th prime? I know probability arguments say no, but do they also prove that it is impossible? Is there a way to disprove the statement? Also, the digits of Pi can tell us certain mathematical truths, for instance that the circumference of a circle is less then any other shape with same area. The question is, is there a limit to the information one can extract from the digits of Pi? Is it possible to reconstruct all theorems from the digits of Pi? What sort of truths can be extracted from the digits of Pi? Is entire math and all truths somehow encoded within the digits of Pi ?",,"['probability', 'logic', 'pi', 'decimal-expansion']"
14,Three white and one red ball probability,Three white and one red ball probability,,"Three boys play a game as follows. They put three white balls and a red ball in a box. Andy, Bruce, and Charles, in this order, each choose a ball at random from the box, without replacement.  Whoever gets the red ball wins. If none of the three draws the red ball, nobody wins.  Which one of the three boys has the largest probability of winning? Since the balls aren't being replaced, I thought Charles should have the highest probability, but it seems that they all have equal chances of winning. How is this possible?","Three boys play a game as follows. They put three white balls and a red ball in a box. Andy, Bruce, and Charles, in this order, each choose a ball at random from the box, without replacement.  Whoever gets the red ball wins. If none of the three draws the red ball, nobody wins.  Which one of the three boys has the largest probability of winning? Since the balls aren't being replaced, I thought Charles should have the highest probability, but it seems that they all have equal chances of winning. How is this possible?",,['probability']
15,Probability of selecting two numbers with a sum of squares divisible by 10,Probability of selecting two numbers with a sum of squares divisible by 10,,Two natural numbers $x$ and $y$ are chosen at random.  Find the probability that $x^2 + y^2$ is divisible by 10. I could not understand how select two numbers from any natural number (infinite).,Two natural numbers $x$ and $y$ are chosen at random.  Find the probability that $x^2 + y^2$ is divisible by 10. I could not understand how select two numbers from any natural number (infinite).,,['probability']
16,High school Math: confusion about the basic probability,High school Math: confusion about the basic probability,,"I am confused about the following two scenarios: Out of a bag of 3 apples and 3 oranges, you pick 2 items. 1) What is the probability that you will have 2 apples? 2) What is the probability that you will have 1 apple and 1 orange? My attempt: 1) $$ \begin{aligned} P(\mbox{2 apples}) &= P(\mbox{1st apple}) \times P(\mbox{2nd apple}) \\ &= \frac{3}{6} \times \frac{2}{5}. \end{aligned} $$ 2) $$ \begin{aligned} P(\mbox{1 apple and 1 orange}) &= P(\mbox{1st apple}) \times P(\mbox{2nd orange}) \\ & + P(\mbox{1st orange}) \times P(\mbox{2nd apple}) \\ &= \frac{3}{6} \times \frac{2}{5} \times 2. \end{aligned} $$ My confusion is with case number 1: why you don't need to multiply the result by 2? Since your first pick could be apple #1, #2, #3.","I am confused about the following two scenarios: Out of a bag of 3 apples and 3 oranges, you pick 2 items. 1) What is the probability that you will have 2 apples? 2) What is the probability that you will have 1 apple and 1 orange? My attempt: 1) $$ \begin{aligned} P(\mbox{2 apples}) &= P(\mbox{1st apple}) \times P(\mbox{2nd apple}) \\ &= \frac{3}{6} \times \frac{2}{5}. \end{aligned} $$ 2) $$ \begin{aligned} P(\mbox{1 apple and 1 orange}) &= P(\mbox{1st apple}) \times P(\mbox{2nd orange}) \\ & + P(\mbox{1st orange}) \times P(\mbox{2nd apple}) \\ &= \frac{3}{6} \times \frac{2}{5} \times 2. \end{aligned} $$ My confusion is with case number 1: why you don't need to multiply the result by 2? Since your first pick could be apple #1, #2, #3.",,"['probability', 'probability-theory']"
17,Expected value of sums,Expected value of sums,,Suppose we draw cards out of a deck without replacement. How many cards do we expect to draw out before we get an ace?,Suppose we draw cards out of a deck without replacement. How many cards do we expect to draw out before we get an ace?,,['probability']
18,Probability of drawing exactly $1$ ace upon drawing $2$ cards from a deck,Probability of drawing exactly  ace upon drawing  cards from a deck,1 2,I got this question and answered it incorrectly . I haven't yet seen the correct answer. The possible answers were: $\frac{4}{52}$ $\frac{16}{221}$ (my answer) $\frac{2}{52}$ $\frac{32}{221}$ My reasoning is the following: Event A: Card is not an ace. Event B: Card is an ace. $$P(A)\times P(B|A)=\frac{4}{52}\times \frac{48}{51}=\frac{16}{221}$$ This is assuming the cards are drawn sequentially. Drawing exactly one ace from a single draw is $4/52$ but to ensure that only a single ace was drawn one should consider the probability of not getting a second ace. How am I wrong?,I got this question and answered it incorrectly . I haven't yet seen the correct answer. The possible answers were: $\frac{4}{52}$ $\frac{16}{221}$ (my answer) $\frac{2}{52}$ $\frac{32}{221}$ My reasoning is the following: Event A: Card is not an ace. Event B: Card is an ace. $$P(A)\times P(B|A)=\frac{4}{52}\times \frac{48}{51}=\frac{16}{221}$$ This is assuming the cards are drawn sequentially. Drawing exactly one ace from a single draw is $4/52$ but to ensure that only a single ace was drawn one should consider the probability of not getting a second ace. How am I wrong?,,['probability']
19,A weird probability question,A weird probability question,,"This is the problem in question: You have two identical bowls: the first one contains 3 white balls and 4 black balls, and the second one contains 4 white balls and 5 black balls. If you choose randomly a ball from the two bowls, what is the probability it is white ? Let's define our events as such: A1 = choosing a ball from the first bowl A2 = choosing a ball from the second bowl B  = choosing a white ball One approach would be using the theorem of total probability: $$\text{We know that }P(B|A_1) = \frac34\text{ and }P(B|A_2) = \frac45\text{, and that:}$$ $$P(A_1) = P(A_2) = \frac12\text{, because the bowls are identical}$$ $$P(B) = P(B |A_1)\times P(A_1) + P(B|A_2)\times P(A_2) = \frac37 \times \frac12 + \frac49 \times \frac12 = 55/126$$ The second approach would be simplifying the problem: Because the two bowls are identical, we could just say we don't even choose between two bowls, but just between the set of all balls. Then we could calculate the probability directly: $$P(B) = \frac {\text{number of white balls}} {\text{total number of balls}} = \frac7 {16}$$ Now, which one is correct? (and why?) Both solutions seem reasonable, and they have approximately the same value $$\frac{55}{126}\approx0.4365$$ $$\frac{7}{16}\approx0.4375$$ However, mathematically speaking, they are different results. Which one is correct?","This is the problem in question: You have two identical bowls: the first one contains 3 white balls and 4 black balls, and the second one contains 4 white balls and 5 black balls. If you choose randomly a ball from the two bowls, what is the probability it is white ? Let's define our events as such: A1 = choosing a ball from the first bowl A2 = choosing a ball from the second bowl B  = choosing a white ball One approach would be using the theorem of total probability: The second approach would be simplifying the problem: Because the two bowls are identical, we could just say we don't even choose between two bowls, but just between the set of all balls. Then we could calculate the probability directly: Now, which one is correct? (and why?) Both solutions seem reasonable, and they have approximately the same value However, mathematically speaking, they are different results. Which one is correct?","\text{We know that }P(B|A_1) = \frac34\text{ and }P(B|A_2) = \frac45\text{, and that:} P(A_1) = P(A_2) = \frac12\text{, because the bowls are identical} P(B) = P(B |A_1)\times P(A_1) + P(B|A_2)\times P(A_2) = \frac37 \times \frac12 + \frac49 \times \frac12 = 55/126 P(B) = \frac {\text{number of white balls}} {\text{total number of balls}} = \frac7 {16} \frac{55}{126}\approx0.4365 \frac{7}{16}\approx0.4375","['probability', 'combinatorics', 'solution-verification']"
20,A die is rolled and a coin is flipped. What is wrong with the following reasoning?,A die is rolled and a coin is flipped. What is wrong with the following reasoning?,,"A die is rolled and a coin is flipped. What is wrong with the following reasoning?: Let $A=\{1,3,6\}$ (event from die roll), let $B=\{H\}$ (event of heads) then, $A\cap B=\emptyset$ (since they have no common elements) and $\Pr(A\cap B)=\Pr(\emptyset)=0$. I realize that the probability of the intersection of two independent events is the product of their probabilities but I want to know what is 'wrong' with this reasoning.","A die is rolled and a coin is flipped. What is wrong with the following reasoning?: Let $A=\{1,3,6\}$ (event from die roll), let $B=\{H\}$ (event of heads) then, $A\cap B=\emptyset$ (since they have no common elements) and $\Pr(A\cap B)=\Pr(\emptyset)=0$. I realize that the probability of the intersection of two independent events is the product of their probabilities but I want to know what is 'wrong' with this reasoning.",,"['probability', 'dice', 'independence']"
21,Probability question about cherry picking,Probability question about cherry picking,,"Question: Amy has a bowl of 5 red cherries and 8 purple cherries. She takes out cherries one at a time until there are no red cherries left. What is the probability that there are exactly 2 cherries left in the bowl? Solution attempt: I imagine that the $13$ cherries are arranged in a random sequence $X_1\ldots X_{13}$ , and Amy picks them in that order. There are $13!$ possible orderings of this sequence. Out of these orderings, the ones for which exactly $2$ cherries are left in a bowl have the form $X_1\ldots X_{10}{\rm RPP}$ , i.e. the sequence ends with a red cherry followed by two purple cherries. There are $5$ ways to select the red cherry, ${8\choose 2}$ ways to pick the two purple cherries, and $10!$ ways to arrange the remaining $10$ cherries. The probability is then $$\frac{5\times{8\choose 2}\times 10!}{13!} = \frac{35}{429} \approx .082$$ I'm solving this on a website, and it does not accept my answer. I ran a Monte Carlo simulation as a sanity check, and it gave me values around $.1$ , so it seems I am indeed lowballing. What am I missing? Thanks!","Question: Amy has a bowl of 5 red cherries and 8 purple cherries. She takes out cherries one at a time until there are no red cherries left. What is the probability that there are exactly 2 cherries left in the bowl? Solution attempt: I imagine that the cherries are arranged in a random sequence , and Amy picks them in that order. There are possible orderings of this sequence. Out of these orderings, the ones for which exactly cherries are left in a bowl have the form , i.e. the sequence ends with a red cherry followed by two purple cherries. There are ways to select the red cherry, ways to pick the two purple cherries, and ways to arrange the remaining cherries. The probability is then I'm solving this on a website, and it does not accept my answer. I ran a Monte Carlo simulation as a sanity check, and it gave me values around , so it seems I am indeed lowballing. What am I missing? Thanks!",13 X_1\ldots X_{13} 13! 2 X_1\ldots X_{10}{\rm RPP} 5 {8\choose 2} 10! 10 \frac{5\times{8\choose 2}\times 10!}{13!} = \frac{35}{429} \approx .082 .1,"['probability', 'combinatorics']"
22,"Can independence go one way? I.e., so that P(A|B) = P(A), but P(B|A) ≠ P(B)","Can independence go one way? I.e., so that P(A|B) = P(A), but P(B|A) ≠ P(B)",,"As I understand it, independence of A and B can be informally established by asking whether learning something about one of those events tells you something new about the other. This must be borne out mathematically, however. For example: If P(A|B) = P(A), then A and B are independent. And if P(A & B) equals P(A) x P(B), then A and B are independent. The above imply that P(B|A) = P(B) It’s this last statement that confuses me, at least in application to certain cases. For example: You devise a way to randomly choose a number from all real numbers, uniformly distributed. The probability of the chosen number being prime is 0, given that 0% of the reals are prime. Similarly, choosing the number 2 from the set of all real numbers has a probability of 0. Likewise, the probability of choosing a 2 from the set of all prime numbers has a probability of 0. Given that 2 is a prime number, it seems that choosing a 2 and choosing a prime number must be dependent events, at least in one direction (namely, if I know I’ve chosen a 2, then I’m certain I’ve chosen a prime number). Here’s what I mean: P(2|prime number) = P(2) = 0 (passes for independence) P(prime number|2) = 1 (i.e., not 0, or P(prime number), and so fails for independence) But can also test as follows: P(2 & prime number) = P(2) x P(prime number) = 0 P(2 & prime number) = P(2) x P(prime number|2) = 0 P(2 & prime number) = p(prime number) x P(2|prime number) = 0 Everything here comes out to 0, as I suppose it should. This also aligns with my understanding that anything with probability 0 is independent from any other event. (Right?) And yet, I’m stuck with the intuition that: If I learn I got a 2, I know I got a prime number, wherein learning I got a prime is insufficient for updating my beliefs about getting a 2 (provided I really do believe that the probability of pulling a 2 from the primes is 0), and the same goes for learning I got an even, a natural, an integer, and so on. Yet I learn I got all those things if I learn I got a 2. I’ve thought of other examples, though all of them deal with some single event occurring out of a set of infinite possible outcomes. E.g., pulling from the natural numbers: P(2|even) = P(2) = 0; but P(even|2) = 1 (rather than the P(even) = 1/2). So I imagine there’s something I’m naive about in the domain of infinite possible outcomes. What am I missing?","As I understand it, independence of A and B can be informally established by asking whether learning something about one of those events tells you something new about the other. This must be borne out mathematically, however. For example: If P(A|B) = P(A), then A and B are independent. And if P(A & B) equals P(A) x P(B), then A and B are independent. The above imply that P(B|A) = P(B) It’s this last statement that confuses me, at least in application to certain cases. For example: You devise a way to randomly choose a number from all real numbers, uniformly distributed. The probability of the chosen number being prime is 0, given that 0% of the reals are prime. Similarly, choosing the number 2 from the set of all real numbers has a probability of 0. Likewise, the probability of choosing a 2 from the set of all prime numbers has a probability of 0. Given that 2 is a prime number, it seems that choosing a 2 and choosing a prime number must be dependent events, at least in one direction (namely, if I know I’ve chosen a 2, then I’m certain I’ve chosen a prime number). Here’s what I mean: P(2|prime number) = P(2) = 0 (passes for independence) P(prime number|2) = 1 (i.e., not 0, or P(prime number), and so fails for independence) But can also test as follows: P(2 & prime number) = P(2) x P(prime number) = 0 P(2 & prime number) = P(2) x P(prime number|2) = 0 P(2 & prime number) = p(prime number) x P(2|prime number) = 0 Everything here comes out to 0, as I suppose it should. This also aligns with my understanding that anything with probability 0 is independent from any other event. (Right?) And yet, I’m stuck with the intuition that: If I learn I got a 2, I know I got a prime number, wherein learning I got a prime is insufficient for updating my beliefs about getting a 2 (provided I really do believe that the probability of pulling a 2 from the primes is 0), and the same goes for learning I got an even, a natural, an integer, and so on. Yet I learn I got all those things if I learn I got a 2. I’ve thought of other examples, though all of them deal with some single event occurring out of a set of infinite possible outcomes. E.g., pulling from the natural numbers: P(2|even) = P(2) = 0; but P(even|2) = 1 (rather than the P(even) = 1/2). So I imagine there’s something I’m naive about in the domain of infinite possible outcomes. What am I missing?",,"['probability', 'independence']"
23,How to describe this structure in spoken words?,How to describe this structure in spoken words?,,"$$\large f(0) = P(X = 0) = \frac{\binom{3}{0}\binom{17}{2}}{\binom{20}{2}} = \frac{68}{95},$$ I'm working on annotating math (probability and statistics) for the visually impaired that is to be read aloud by a screen reader and don't know what to put for this structure. As of now, I've just got something like, ""$f$ of zero equals"", then I am not sure how to phrase $P(X=0)$ (is it the probability where $X = 0? $), and then really have no idea about those structures in parentheses in the quotient portion. Thank you.","$$\large f(0) = P(X = 0) = \frac{\binom{3}{0}\binom{17}{2}}{\binom{20}{2}} = \frac{68}{95},$$ I'm working on annotating math (probability and statistics) for the visually impaired that is to be read aloud by a screen reader and don't know what to put for this structure. As of now, I've just got something like, ""$f$ of zero equals"", then I am not sure how to phrase $P(X=0)$ (is it the probability where $X = 0? $), and then really have no idea about those structures in parentheses in the quotient portion. Thank you.",,"['probability', 'notation', 'terminology', 'binomial-coefficients']"
24,Die that never rolls the same number consecutively,Die that never rolls the same number consecutively,,"Suppose we have a ""magic"" die $[1-6]$ that never rolls the same number consecutively. That means you will never find the same number repeated in a row. Now let's suppose that we roll this die $1000$ times. How can I find the PDF, expected number of times and variance of getting a specific value?","Suppose we have a ""magic"" die $[1-6]$ that never rolls the same number consecutively. That means you will never find the same number repeated in a row. Now let's suppose that we roll this die $1000$ times. How can I find the PDF, expected number of times and variance of getting a specific value?",,"['probability', 'probability-distributions', 'dice']"
25,Why is a simulation of a probability experiment off by a factor of 10?,Why is a simulation of a probability experiment off by a factor of 10?,,"From a university homework assignment: There are $8$ numbered cells and $12$ indistinct balls. All $12$ balls are randomly divided between all of the $8$ cells. What is the probability that there is not a single empty cell ( $i.e.$ each cell has at least $1$ ball)? The answer is $\large\frac{\binom{11}{7}}{\binom{19}{7}}$ which is about $0.0065$ . I reached this result independently, and it was confirmed by the official homework solution of the university. A friend of mine and I independently wrote Python simulations that run the experiment many times (tested up to $1,000,000$ ). We used both Pythons' random generator and several randomly generated lists from www.random.org. Results were similar and consistently hovering around $0.09$ which is a factor of $10$ or even a bit more off from the expected theoretical result. Have we made some wrong assumptions? Any ideas for this discrepancy? P.S.: Here is the Python code that I wrote, and maybe there is some faulty logic there. def run_test():     global count, N      def run_experiment(n_balls, n_cells, offset):         cells = [0] * n_cells         # toss balls randomly to cells:         for j in range(n_balls):             cells[random.randrange(0, n_cells)] += 1             # cells[int(lines[offset + j])] += 1         cells = sorted(cells)         # print(cells)          # check if there is an empty cell. if so return 0, otherwise 1:         if cells[0] == 0:             return 0         return 1      count = 0     N = 1000000     offset = 0     N_CELLS = 8     N_BALLS = 12     # iterate experiment     for i in range(N):         result = run_experiment(N_BALLS, N_CELLS, offset=offset)         count += result         offset += N_CELLS      print(""probability:"", count, ""/"", N, ""(~"", count / N, "")"")","From a university homework assignment: There are numbered cells and indistinct balls. All balls are randomly divided between all of the cells. What is the probability that there is not a single empty cell ( each cell has at least ball)? The answer is which is about . I reached this result independently, and it was confirmed by the official homework solution of the university. A friend of mine and I independently wrote Python simulations that run the experiment many times (tested up to ). We used both Pythons' random generator and several randomly generated lists from www.random.org. Results were similar and consistently hovering around which is a factor of or even a bit more off from the expected theoretical result. Have we made some wrong assumptions? Any ideas for this discrepancy? P.S.: Here is the Python code that I wrote, and maybe there is some faulty logic there. def run_test():     global count, N      def run_experiment(n_balls, n_cells, offset):         cells = [0] * n_cells         # toss balls randomly to cells:         for j in range(n_balls):             cells[random.randrange(0, n_cells)] += 1             # cells[int(lines[offset + j])] += 1         cells = sorted(cells)         # print(cells)          # check if there is an empty cell. if so return 0, otherwise 1:         if cells[0] == 0:             return 0         return 1      count = 0     N = 1000000     offset = 0     N_CELLS = 8     N_BALLS = 12     # iterate experiment     for i in range(N):         result = run_experiment(N_BALLS, N_CELLS, offset=offset)         count += result         offset += N_CELLS      print(""probability:"", count, ""/"", N, ""(~"", count / N, "")"")","8 12 12 8 i.e. 1 \large\frac{\binom{11}{7}}{\binom{19}{7}} 0.0065 1,000,000 0.09 10","['probability', 'simulation', 'python']"
26,"If $P(A) \neq 0$ and $P(B) \neq 0$, then $P(B|A) \geq P(B)$ is equivalent to $P(A|B) \geq P(A)$","If  and , then  is equivalent to",P(A) \neq 0 P(B) \neq 0 P(B|A) \geq P(B) P(A|B) \geq P(A),"I am puzzled by the intuition behind the following fact: If $P(A) \neq 0$ and $P(B) \neq 0$, then $P(B|A) \geq P(B)$ is equivalent to $P(A|B) \geq P(A)$. This is easy enough to show by definition of conditional probability, but I would like to have some sort of geometric intuition behind this. I can create positive example pictures, but not one that shows me why this statement must hold. I would greatly appreciate some help. Thanks","I am puzzled by the intuition behind the following fact: If $P(A) \neq 0$ and $P(B) \neq 0$, then $P(B|A) \geq P(B)$ is equivalent to $P(A|B) \geq P(A)$. This is easy enough to show by definition of conditional probability, but I would like to have some sort of geometric intuition behind this. I can create positive example pictures, but not one that shows me why this statement must hold. I would greatly appreciate some help. Thanks",,"['probability', 'probability-theory']"
27,Derivation for hypergeometric distribution formula and comparsion with Bernoulli formula,Derivation for hypergeometric distribution formula and comparsion with Bernoulli formula,,"To understand the binomial probability distribution function, I was lucky to see the connection between the Bernoulli probability: $P(X=k) = {n\choose k}p^k(1-p)^{1-k}$, which is based on the formula for one try: $P(x=k) = p^k(1-p)^{1-k}$ which is $p$ for $k=1$ and $1-p$ for $k=0$. The Bernoulli probability distribution function is a function that represents the probability of having k successes on $n$ trials of something. If we do the experiment more than one time, let's say, $k$ times and the probability stays the same on every trial, then the probability function $P(s)$ is just the number of $s$ successes in these $k$ trials. This is exactly $kCs$ or $k\choose s$. Why? See the text at $(1)$in the end. Now, for the hypergeometric distribution, we're doing kinda like in the Bernoulli case, but the probability changes after very trial. We can think of the success and failure as being the removal of a ball of color $A$ from a sack of balls of color $A$ or $B$. In the Bernoulli case, it's like we putting the ball back in the sack for the next trial, so the probability of getting a ball of color $A$ is the same on every trial. In the hypergeometric case is like we were not putting it back again, so the probability of getting a ball of color $A$ changes after each trial. For some reason, its formula is: $$P(X=k) = \frac{{K\choose k} {{N-K}\choose {n-k}}}{N\choose n}$$ Main question: How to  find the formula for the hypergeometric distribution? ** (1) Explanation for the Bernoulli formula (the combinatoric part):** Our experiment for let's say, $k=5$ trials when $S$ means success and $F$ means failure looks like this: $$SSSSS\\ SSSSF \\ SSSFS \\ SSFSS \\ \cdots \\ FFFFF$$ Our function $P(s=3)$ should count how many objects exists in the set above with exactly 3 $S$ letters, for example: $SSSFF, SFSFS, SSFFS, \cdots$. To count this, we're gonna think about how many permutations of $A,B,C$ exist in $A,B,C,D,E$, that is, how many ways can we do things like: $$ABCDE\\ABDCE\\ADEBC\\ \cdots \\ EDBCA$$ We know that there are $5!$ ways to permute every symbol, but we just care about the permutations on $A,B,C$, so $ABCDE$ and $ABCED$ are the same for this case. In general, for every permutation in the set above, there will be an equivalent one with $D$ and $E$ switched. Other example can be: $ABDEC$ being the same as $ABEDC$, so we're gonna divide by how many ways there are to permute $E$ and $D$, which is $2!$. So the number of ways to permute $A,B,C$ in $A,B,C,D,E$ is $\frac{5!}{2!} = \frac{5!}{(5-3)!}$. This is the known formula $\frac{p!}{(p-k)!}$. Getting back to our case, I see the problem of counting how many $3$ $S$ucesses in $5$ trials as counting how many permutations of letters $A,B,C$ in the set $A,B,C,D,E$, with the restriction that we don't want to count repetitions (you'll understand this part soon). For example, the $3$ sucesses would look like this: $$SSSFF\\SSFSF\\SFSFS\\\cdots\\FFSSS$$ I don't know exactly how to explain this part, but I see this as being the same as counting the permutations $A,B,C$ inside $A,B,C,D,E$, except that now, $ABCDE = ACBDE = BACDE = BCADE = CABDE = CBADE$, that is, $S_1S_2S_3FF = S_2S_1S_3FF = S_3S_1S_2FF = S_1S_3S_2FF = S_2S_3S_1FF = S_3S_2S_1FF$. I could differentiate the $F$ letters by $F_1, F_2$ but since we're not gonna count repetitions on $F$ as in the formula $\frac{p!}{(p-k)!}$, I'm considering that there exists only one case. Now we must just se that in general there will be $3!$ equal cases for each object, because $ABCDE = ACBDE = \cdots$. The reason is obvious: there is $3!$ ways to permute $A,B,C$ or $S_1,S_2,S_3$, so we just divide the formula by $3!$ or $k!$, that's why the formula for combination is ${p\choose k} = \frac{p!}{k!(p-k)!}$ UPDATE : While writing this, I realized that it's a lot simpler if we just consider the permutations of the following letters: $S_1,S_2,S_3,F_1,F_2$, eliminate the permutations for $F_1,F_2$ by dividing by $2!$ and eliminate the permutations of $S_1S_2S_3$ because $S_1S_2S_3F_1F_2 = S_1S_3S_2F_1F_2 = \cdots $, which is $3!$ in total. I made a mess but I think it's good to see my thinking process. Now that we counted how many successes there are, it's just a matter of multiplying by $p^k(1-p)^{1-k}$ to get the formula.","To understand the binomial probability distribution function, I was lucky to see the connection between the Bernoulli probability: $P(X=k) = {n\choose k}p^k(1-p)^{1-k}$, which is based on the formula for one try: $P(x=k) = p^k(1-p)^{1-k}$ which is $p$ for $k=1$ and $1-p$ for $k=0$. The Bernoulli probability distribution function is a function that represents the probability of having k successes on $n$ trials of something. If we do the experiment more than one time, let's say, $k$ times and the probability stays the same on every trial, then the probability function $P(s)$ is just the number of $s$ successes in these $k$ trials. This is exactly $kCs$ or $k\choose s$. Why? See the text at $(1)$in the end. Now, for the hypergeometric distribution, we're doing kinda like in the Bernoulli case, but the probability changes after very trial. We can think of the success and failure as being the removal of a ball of color $A$ from a sack of balls of color $A$ or $B$. In the Bernoulli case, it's like we putting the ball back in the sack for the next trial, so the probability of getting a ball of color $A$ is the same on every trial. In the hypergeometric case is like we were not putting it back again, so the probability of getting a ball of color $A$ changes after each trial. For some reason, its formula is: $$P(X=k) = \frac{{K\choose k} {{N-K}\choose {n-k}}}{N\choose n}$$ Main question: How to  find the formula for the hypergeometric distribution? ** (1) Explanation for the Bernoulli formula (the combinatoric part):** Our experiment for let's say, $k=5$ trials when $S$ means success and $F$ means failure looks like this: $$SSSSS\\ SSSSF \\ SSSFS \\ SSFSS \\ \cdots \\ FFFFF$$ Our function $P(s=3)$ should count how many objects exists in the set above with exactly 3 $S$ letters, for example: $SSSFF, SFSFS, SSFFS, \cdots$. To count this, we're gonna think about how many permutations of $A,B,C$ exist in $A,B,C,D,E$, that is, how many ways can we do things like: $$ABCDE\\ABDCE\\ADEBC\\ \cdots \\ EDBCA$$ We know that there are $5!$ ways to permute every symbol, but we just care about the permutations on $A,B,C$, so $ABCDE$ and $ABCED$ are the same for this case. In general, for every permutation in the set above, there will be an equivalent one with $D$ and $E$ switched. Other example can be: $ABDEC$ being the same as $ABEDC$, so we're gonna divide by how many ways there are to permute $E$ and $D$, which is $2!$. So the number of ways to permute $A,B,C$ in $A,B,C,D,E$ is $\frac{5!}{2!} = \frac{5!}{(5-3)!}$. This is the known formula $\frac{p!}{(p-k)!}$. Getting back to our case, I see the problem of counting how many $3$ $S$ucesses in $5$ trials as counting how many permutations of letters $A,B,C$ in the set $A,B,C,D,E$, with the restriction that we don't want to count repetitions (you'll understand this part soon). For example, the $3$ sucesses would look like this: $$SSSFF\\SSFSF\\SFSFS\\\cdots\\FFSSS$$ I don't know exactly how to explain this part, but I see this as being the same as counting the permutations $A,B,C$ inside $A,B,C,D,E$, except that now, $ABCDE = ACBDE = BACDE = BCADE = CABDE = CBADE$, that is, $S_1S_2S_3FF = S_2S_1S_3FF = S_3S_1S_2FF = S_1S_3S_2FF = S_2S_3S_1FF = S_3S_2S_1FF$. I could differentiate the $F$ letters by $F_1, F_2$ but since we're not gonna count repetitions on $F$ as in the formula $\frac{p!}{(p-k)!}$, I'm considering that there exists only one case. Now we must just se that in general there will be $3!$ equal cases for each object, because $ABCDE = ACBDE = \cdots$. The reason is obvious: there is $3!$ ways to permute $A,B,C$ or $S_1,S_2,S_3$, so we just divide the formula by $3!$ or $k!$, that's why the formula for combination is ${p\choose k} = \frac{p!}{k!(p-k)!}$ UPDATE : While writing this, I realized that it's a lot simpler if we just consider the permutations of the following letters: $S_1,S_2,S_3,F_1,F_2$, eliminate the permutations for $F_1,F_2$ by dividing by $2!$ and eliminate the permutations of $S_1S_2S_3$ because $S_1S_2S_3F_1F_2 = S_1S_3S_2F_1F_2 = \cdots $, which is $3!$ in total. I made a mess but I think it's good to see my thinking process. Now that we counted how many successes there are, it's just a matter of multiplying by $p^k(1-p)^{1-k}$ to get the formula.",,"['probability', 'combinatorics', 'statistics', 'combinations']"
28,The mode of the Poisson Distribution,The mode of the Poisson Distribution,,"Lately, I am doing an investigation on Stirling's formula and its applications. So I thought I could use it to prove that the mode of the Poisson model is approximately equal to the mean. Of course, you do that by considering the curve that is formed by connecting the points of the probabilities of occurrence and the different values of the discrete random variable. Then you differentiate the p.d.f. where for $x!$ you use Stirling's formula $x!\approx \sqrt{2\pi x}~x^xe^{-x}$. The result is $\lnλ-1/(2x)-\ln x$ whose roots cannot be found analytically, but by iterative methods we find that as λ is larger and larger, the mode~mean. Problem is, I found the following paper online, which seems to be the solution from a Harvard's undergraduate problem set. http://www.physics.harvard.edu/academics/undergrad/probweek/sol84.pdf It reads ""You can also show this by taking the derivative of eq. (2), with Stirling’s expression in place of the $x!$. Furthermore, you can show that $x = a[=λ ~\text{in my case}~]-1/2$ leads to a maximum $P(x)$ value of $P_\max\approx1/\sqrt{2\pi a}$."" Does this puzzle you as much as it puzzles me? My main concern is over the ""="" sign: how does this hold? The derivative=0 equation cannot have such an exact solution. Furthermore at such x, how does $P(X=a-1/2)$ give $1/\sqrt{2\pi a}$? Am I (and my professor) missing something rather obvious or is the solution wrong? Discuss! PS: This sort of question might have been asked before, but still, I am really curious that somebody reads the paper in the link above, so that I can figure out what's going on.","Lately, I am doing an investigation on Stirling's formula and its applications. So I thought I could use it to prove that the mode of the Poisson model is approximately equal to the mean. Of course, you do that by considering the curve that is formed by connecting the points of the probabilities of occurrence and the different values of the discrete random variable. Then you differentiate the p.d.f. where for $x!$ you use Stirling's formula $x!\approx \sqrt{2\pi x}~x^xe^{-x}$. The result is $\lnλ-1/(2x)-\ln x$ whose roots cannot be found analytically, but by iterative methods we find that as λ is larger and larger, the mode~mean. Problem is, I found the following paper online, which seems to be the solution from a Harvard's undergraduate problem set. http://www.physics.harvard.edu/academics/undergrad/probweek/sol84.pdf It reads ""You can also show this by taking the derivative of eq. (2), with Stirling’s expression in place of the $x!$. Furthermore, you can show that $x = a[=λ ~\text{in my case}~]-1/2$ leads to a maximum $P(x)$ value of $P_\max\approx1/\sqrt{2\pi a}$."" Does this puzzle you as much as it puzzles me? My main concern is over the ""="" sign: how does this hold? The derivative=0 equation cannot have such an exact solution. Furthermore at such x, how does $P(X=a-1/2)$ give $1/\sqrt{2\pi a}$? Am I (and my professor) missing something rather obvious or is the solution wrong? Discuss! PS: This sort of question might have been asked before, but still, I am really curious that somebody reads the paper in the link above, so that I can figure out what's going on.",,"['probability', 'probability-distributions', 'numerical-methods']"
29,More direct approach to a combinatorial problem,More direct approach to a combinatorial problem,,"Suppose we randomly arrange $n$ objects of which $s$ are of silver, $1$ is of gold and the remaining $n-s-1$ are of copper. The question I looked at is: what is the probability that all eventual predecessors of the golden object are of silver? We could rephrase this as: what is the probability that among the eventual predecessors of the golden object are no copper objects. I defined the described event as $E$ and approached the answer by first defining $E_i$ (this for $i=0,1,\dots,s$ ) as the event that the golden object is on spot $i+1$ and its predecessors are all of silver. Then we find: $$P(E_i)=\frac1n\binom{s}i\binom{n-1}i^{-1}=\frac1n\binom{n-1}s^{-1}\binom{n-i-1}{n-s-1}$$ and making use of the hockey-stick identity we arrive at: $$P(E)=\sum_{i=0}^sP(E_i)=\frac1n\binom{n-1}s^{-1}\binom{n}{n-s}=\frac1{n-s}$$ That is a nice result. So nice that IMV it clearly indicates the existence of more direct way to find it. I tried to, but failed. So my question is: Can you provide me a more direct solution? Thank you for taking notice of this and sorry in advance if this appears to be a duplicate question. Edit My original question did not mention the word ""copper"" neither the rephrasing of the question that uses the word ""copper"". In my (narrow) thinking I was purely focused on gold and silver. This fact provided the blind spot that I am now released from. In situations like this a sort of battle takes place within me. I am very eager to find the smart solution myself . I can pose it as a question but my pride first forbids me to do so. After some struggling I set this (stupid) pride aside and decide to show my shortcomings. A healthy process. Thank you all for your answers.","Suppose we randomly arrange objects of which are of silver, is of gold and the remaining are of copper. The question I looked at is: what is the probability that all eventual predecessors of the golden object are of silver? We could rephrase this as: what is the probability that among the eventual predecessors of the golden object are no copper objects. I defined the described event as and approached the answer by first defining (this for ) as the event that the golden object is on spot and its predecessors are all of silver. Then we find: and making use of the hockey-stick identity we arrive at: That is a nice result. So nice that IMV it clearly indicates the existence of more direct way to find it. I tried to, but failed. So my question is: Can you provide me a more direct solution? Thank you for taking notice of this and sorry in advance if this appears to be a duplicate question. Edit My original question did not mention the word ""copper"" neither the rephrasing of the question that uses the word ""copper"". In my (narrow) thinking I was purely focused on gold and silver. This fact provided the blind spot that I am now released from. In situations like this a sort of battle takes place within me. I am very eager to find the smart solution myself . I can pose it as a question but my pride first forbids me to do so. After some struggling I set this (stupid) pride aside and decide to show my shortcomings. A healthy process. Thank you all for your answers.","n s 1 n-s-1 E E_i i=0,1,\dots,s i+1 P(E_i)=\frac1n\binom{s}i\binom{n-1}i^{-1}=\frac1n\binom{n-1}s^{-1}\binom{n-i-1}{n-s-1} P(E)=\sum_{i=0}^sP(E_i)=\frac1n\binom{n-1}s^{-1}\binom{n}{n-s}=\frac1{n-s}","['probability', 'combinatorics', 'alternative-proof']"
30,What is the probability of a four occurring in 300 dice rolls?,What is the probability of a four occurring in 300 dice rolls?,,"If I rolled a die 300 times and recorded each outcome, what is the chance of rolling at least one four? I know that the answer will be very close to $1$, but I don't know if there is a formula for finding that exact value. If I did this with two dice, then $P(4)=\frac{11}{36}$, which I only know how to work out if I draw a two-way table. Any help is appreciated, thanks!","If I rolled a die 300 times and recorded each outcome, what is the chance of rolling at least one four? I know that the answer will be very close to $1$, but I don't know if there is a formula for finding that exact value. If I did this with two dice, then $P(4)=\frac{11}{36}$, which I only know how to work out if I draw a two-way table. Any help is appreciated, thanks!",,"['probability', 'dice']"
31,Please prove that the Probability Mass Function (in Binomial Distribution) is less than 1.,Please prove that the Probability Mass Function (in Binomial Distribution) is less than 1.,,"I have finished elementary probability and I know the sum of all probabilites in a data set is 1.But while reading Binomial Distribution,I encountered the formula for the Probability mass distribution : $$f(k ; n, p)=\operatorname{Pr}(K=k)= {n \choose k} p^{k}(1-p)^{n-k}$$ Well, I know that probability is a fraction less than $1$ , and fractions multiplied with fractions will still yield a lesser fraction as the product. But what I am confused about is that the "" ${n \choose k}$ "" that we multiply at the start of the formula is a positive integer, and I am confused that why shouldn't the net product be more than one? I mean, the fraction that we get after multiplying the probabilities, wouldn't that turn greater than $1$ if we multiply (which is repeated addition by itself) that fraction by the positive integer we get as a result of "" ${n \choose k}$ "" ? Sorry about my roundabout way of talking. You are only requested to prove that the whole thing is a value less than $1$ . I tried and just couldn't see why it shouldn't be greater than $1$ . I am in learner's stage (I could have learnt the forumla by rote, but my video instructor says if I proceed like that without understanding things and asking questions, then I will be like a monkey on a type-writer) Here's the wikipedia page about it","I have finished elementary probability and I know the sum of all probabilites in a data set is 1.But while reading Binomial Distribution,I encountered the formula for the Probability mass distribution : Well, I know that probability is a fraction less than , and fractions multiplied with fractions will still yield a lesser fraction as the product. But what I am confused about is that the "" "" that we multiply at the start of the formula is a positive integer, and I am confused that why shouldn't the net product be more than one? I mean, the fraction that we get after multiplying the probabilities, wouldn't that turn greater than if we multiply (which is repeated addition by itself) that fraction by the positive integer we get as a result of "" "" ? Sorry about my roundabout way of talking. You are only requested to prove that the whole thing is a value less than . I tried and just couldn't see why it shouldn't be greater than . I am in learner's stage (I could have learnt the forumla by rote, but my video instructor says if I proceed like that without understanding things and asking questions, then I will be like a monkey on a type-writer) Here's the wikipedia page about it","f(k ; n, p)=\operatorname{Pr}(K=k)= {n \choose k} p^{k}(1-p)^{n-k} 1 {n \choose k} 1 {n \choose k} 1 1",['probability']
32,Probability of having at least one pair by drawing 4 shoes from 12 pairs.,Probability of having at least one pair by drawing 4 shoes from 12 pairs.,,"There are $12$ pairs of shoes in a cupboard. $4$ are drawn at random. What is the probability that there is at least one pair? My first attempt: If we chose a pair at first and then draw any two at random from the rest, then there will be at least one pair.  We can choose one pair in ${12}\choose 4$ ways and chose any $2$ from the rest in ${22}\choose 2$ ways. Therefore, the required probability= $\frac{{12\choose 4} \times {22\choose 2}}{{24\choose 4}}$ = $\frac{6}{23} =\frac{42}{161}$ But the given answer is $\frac{41}{161}$. Another attempt: Each of the 4 shoes we choose, will come from one of the pairs. We can choose the four pairs in ${12\choose 4}$ ways and can select a shoe from each of the pairs in $2$ ways so that no pair is obtained. Therefore, required probability =$1-$ $\frac{{12\choose 4} \times 2^4}{{24\choose 4}}$ = $\frac{41}{161}$ What is wrong with the first attempt?","There are $12$ pairs of shoes in a cupboard. $4$ are drawn at random. What is the probability that there is at least one pair? My first attempt: If we chose a pair at first and then draw any two at random from the rest, then there will be at least one pair.  We can choose one pair in ${12}\choose 4$ ways and chose any $2$ from the rest in ${22}\choose 2$ ways. Therefore, the required probability= $\frac{{12\choose 4} \times {22\choose 2}}{{24\choose 4}}$ = $\frac{6}{23} =\frac{42}{161}$ But the given answer is $\frac{41}{161}$. Another attempt: Each of the 4 shoes we choose, will come from one of the pairs. We can choose the four pairs in ${12\choose 4}$ ways and can select a shoe from each of the pairs in $2$ ways so that no pair is obtained. Therefore, required probability =$1-$ $\frac{{12\choose 4} \times 2^4}{{24\choose 4}}$ = $\frac{41}{161}$ What is wrong with the first attempt?",,"['probability', 'combinatorics', 'permutations']"
33,"What's the probability of a an outcome after N trials, if you stop trying once you're ""successful""?","What's the probability of a an outcome after N trials, if you stop trying once you're ""successful""?",,"This follows on from this question about being hit by a bus. In this question, there is a 1/1000 chance of being hit and the question was about the probability of being hit if you cross the road 1000 time. I wondered what would happen to this probability if I stopped trying to cross the road as soon as I get hit. Does the probability change? As far as I can figure it, the probability then just becomes the sum of the geometric series $$P(\text{hit by bus within 1000 crossings}) = \sum_{n=0}^{999} 1/1000 * (999/1000)^n$$ thus $$ P(\text{hit by bus within 1000 crossings}) = 1/1000 * \frac{1-(999/1000)^{1000}}{1-999/1000} $$ However, this is identical to $$P(\text{hit by bus within 1000 crossings}) = 1-P(\text{not hit by bus within 1000 crossing}) = 1-(999/1000)^{1000}$$ which is the answer to the previous question. I'm curious as to why they are not different, since the first approach is specifically ignoring all instances where (for instance) I get hit by a bus on the first try and then keep trying and get hit by subsequent buses.","This follows on from this question about being hit by a bus. In this question, there is a 1/1000 chance of being hit and the question was about the probability of being hit if you cross the road 1000 time. I wondered what would happen to this probability if I stopped trying to cross the road as soon as I get hit. Does the probability change? As far as I can figure it, the probability then just becomes the sum of the geometric series $$P(\text{hit by bus within 1000 crossings}) = \sum_{n=0}^{999} 1/1000 * (999/1000)^n$$ thus $$ P(\text{hit by bus within 1000 crossings}) = 1/1000 * \frac{1-(999/1000)^{1000}}{1-999/1000} $$ However, this is identical to $$P(\text{hit by bus within 1000 crossings}) = 1-P(\text{not hit by bus within 1000 crossing}) = 1-(999/1000)^{1000}$$ which is the answer to the previous question. I'm curious as to why they are not different, since the first approach is specifically ignoring all instances where (for instance) I get hit by a bus on the first try and then keep trying and get hit by subsequent buses.",,['probability']
34,"Why is $P(X,Y|Z)=P(Y|X,Z)P(X|Z)$?",Why is ?,"P(X,Y|Z)=P(Y|X,Z)P(X|Z)","Could anyone derive or explain why the formula $P(X,Y|Z)=P(Y|X,Z)P(X|Z)$ is true? I understand conditional probability definition, but this formula confuses me and makes my head hurt x) Here's another similar which I have struggled to understand: $$p(\mathbf{x}, \mathbf{\theta}|\mathcal{X})=p(\mathbf{x}|\mathbf{\theta},\mathcal{X})p(\mathbf{\theta}|\mathcal{X})$$ Could someone explain this one to me as well? This formula is from my neural networks book, but I have no idea why this is true, even though I understand the basic conditional probability formula $P(A|B) = \displaystyle\frac{P(A,B)}{P(B)}$. If I use this formula, what I would do for my book example is this: $P(\mathbf{x},\mathbf{\theta}|\mathcal{X}) = \displaystyle\frac{P(\mathbf{x},\mathbf{\theta},\mathcal{X})}{P(\mathcal{X})}$ Could someone ease my frustration ;D Thank you!","Could anyone derive or explain why the formula $P(X,Y|Z)=P(Y|X,Z)P(X|Z)$ is true? I understand conditional probability definition, but this formula confuses me and makes my head hurt x) Here's another similar which I have struggled to understand: $$p(\mathbf{x}, \mathbf{\theta}|\mathcal{X})=p(\mathbf{x}|\mathbf{\theta},\mathcal{X})p(\mathbf{\theta}|\mathcal{X})$$ Could someone explain this one to me as well? This formula is from my neural networks book, but I have no idea why this is true, even though I understand the basic conditional probability formula $P(A|B) = \displaystyle\frac{P(A,B)}{P(B)}$. If I use this formula, what I would do for my book example is this: $P(\mathbf{x},\mathbf{\theta}|\mathcal{X}) = \displaystyle\frac{P(\mathbf{x},\mathbf{\theta},\mathcal{X})}{P(\mathcal{X})}$ Could someone ease my frustration ;D Thank you!",,"['probability', 'bayesian']"
35,Conditional Expectation: What happens if you take conditional expectation on trivial sigma field?,Conditional Expectation: What happens if you take conditional expectation on trivial sigma field?,,"Consider for the trvial $\sigma$ - field $\mathcal{F}_0 = \{\emptyset , \Omega\}$, What is Conditional expectation of the following in the following cases when $A = \emptyset$ and $A = \Omega$ ??? ? Can someone please help me fill in the ?? below, as this would help improve my understanding a lot ? $$\int_? E[X | \mathcal{F}_0]1_A dP =  ?    \;\; \forall A \in \mathcal{F}_0$$ Question 2: And What if I just condition on the $\sigma$-field, $$ \int_? E[X | \mathcal{F}] dP = ? $$ For the second question, I guess it is = X right? Since X is already $\mathcal{F}$- measurable by definition of random variable, if given the $\sigma$ - feld $\mathcal{F}$, everything is known, there is no randomness in X.","Consider for the trvial $\sigma$ - field $\mathcal{F}_0 = \{\emptyset , \Omega\}$, What is Conditional expectation of the following in the following cases when $A = \emptyset$ and $A = \Omega$ ??? ? Can someone please help me fill in the ?? below, as this would help improve my understanding a lot ? $$\int_? E[X | \mathcal{F}_0]1_A dP =  ?    \;\; \forall A \in \mathcal{F}_0$$ Question 2: And What if I just condition on the $\sigma$-field, $$ \int_? E[X | \mathcal{F}] dP = ? $$ For the second question, I guess it is = X right? Since X is already $\mathcal{F}$- measurable by definition of random variable, if given the $\sigma$ - feld $\mathcal{F}$, everything is known, there is no randomness in X.",,"['probability', 'probability-theory', 'stochastic-processes']"
36,I have 100 boxes. C of them have a gift. I can open up to 16 boxes. What is the number of C that will give me probability over 0.5 to find a gift?,I have 100 boxes. C of them have a gift. I can open up to 16 boxes. What is the number of C that will give me probability over 0.5 to find a gift?,,"Details: We start by opening a box. If nothing is in there, we open another one. Once we find a gift, we can stop. Each empty box that was opened is discarded (no revisit). I can find the number of $C$ that will give probability over $0.5$ by writing a program to try for $C=1, C=2$ .. etc.. , but I can't solve the equation for $C$ to find a more ""mathematical"" and elegant answer. My work until now is: 1) Found in 1st box: $P(1) = \frac{C}{N}$ 2) Found in 2nd box: $P(2) = \frac{1-C}{N}\cdot\frac{C}{N-1}$ 4) Found in 3rd box: $P(3) = \frac{1-C}{N}\cdot\frac{1-C/}{N-1}\cdot\frac{C}{N-2}$ Etc... Adding them up makes things very complicated to solve for $C$ . Any ideas? Thank you in advance!","Details: We start by opening a box. If nothing is in there, we open another one. Once we find a gift, we can stop. Each empty box that was opened is discarded (no revisit). I can find the number of that will give probability over by writing a program to try for .. etc.. , but I can't solve the equation for to find a more ""mathematical"" and elegant answer. My work until now is: 1) Found in 1st box: 2) Found in 2nd box: 4) Found in 3rd box: Etc... Adding them up makes things very complicated to solve for . Any ideas? Thank you in advance!","C 0.5 C=1, C=2 C P(1) = \frac{C}{N} P(2) = \frac{1-C}{N}\cdot\frac{C}{N-1} P(3) = \frac{1-C}{N}\cdot\frac{1-C/}{N-1}\cdot\frac{C}{N-2} C","['probability', 'probability-theory']"
37,a part of expected value of Poisson distribution $E(X^2)=λ^2+λ$ proof?,a part of expected value of Poisson distribution  proof?,E(X^2)=λ^2+λ,a part of expected value of Poisson distribution : $E(X^2)=λ^2+λ$ What is the proof? (except using the Moment-generating function ),a part of expected value of Poisson distribution : $E(X^2)=λ^2+λ$ What is the proof? (except using the Moment-generating function ),,['probability']
38,Self-study resources for basic probability?,Self-study resources for basic probability?,,"I am taking a Computer Science class soon that requires a solid knowledge of the basics of probability.  I've only had minimal exposure to probability in classes I've taken in the past, so I need to get up to speed quickly.  Can anyone recommend some good self-study resources (e.g. books, online classes, web sites) that I could use to teach myself the fundamentals?","I am taking a Computer Science class soon that requires a solid knowledge of the basics of probability.  I've only had minimal exposure to probability in classes I've taken in the past, so I need to get up to speed quickly.  Can anyone recommend some good self-study resources (e.g. books, online classes, web sites) that I could use to teach myself the fundamentals?",,"['probability', 'reference-request', 'self-learning']"
39,The likelihood of being an accountant vs being an accountant and a plumber [duplicate],The likelihood of being an accountant vs being an accountant and a plumber [duplicate],,"This question already has answers here : Probability Question: Would A always have a greater chance of $A\cap B$? (5 answers) Closed 8 years ago . This is a very interesting word problem that I came across in an old textbook of mine. So I know it's got something to do with probability, but other than that, the textbook gave no hints really and I'm really not sure about how to approach it. Probability has always given me headaches but in fact, I've been racking my head over it so long that I've got a huge headache. Any guidance hints or help would be truly greatly appreciated. ""Last week, the heat in my apartment crapped out because my water heater broke. I went to a person, showed him the water heater and asked him to fix it ."" Ignoring the practicality side of this problem and instead focusing on the math probability side of it, Is this person more likely: An accountant OR An accountant and a plumber?","This question already has answers here : Probability Question: Would A always have a greater chance of $A\cap B$? (5 answers) Closed 8 years ago . This is a very interesting word problem that I came across in an old textbook of mine. So I know it's got something to do with probability, but other than that, the textbook gave no hints really and I'm really not sure about how to approach it. Probability has always given me headaches but in fact, I've been racking my head over it so long that I've got a huge headache. Any guidance hints or help would be truly greatly appreciated. ""Last week, the heat in my apartment crapped out because my water heater broke. I went to a person, showed him the water heater and asked him to fix it ."" Ignoring the practicality side of this problem and instead focusing on the math probability side of it, Is this person more likely: An accountant OR An accountant and a plumber?",,['probability']
40,Double Summation Switch,Double Summation Switch,,"I have a question about switching the order of summation in this probability question.  I'll give the probability background, but it's not necessary to understand my question.  We have a random variable X that takes on nonnegative integer values.  We want to show that: $\operatorname{E}[X]=\sum\limits_{i=1}^\infty P(X\geq i)$ We start off by noting that: $\sum\limits_{i=1}^\infty P(X\geq i) = \sum\limits_{i=1}^\infty \sum\limits_{j=i}^\infty P(X = j). $ My question comes in at this next part: $\begin{align} \sum\limits_{i=1}^\infty \sum\limits_{j=i}^\infty P(X = j) &=\sum\limits_{j=1}^\infty \sum\limits_{i=1}^j P(X = j)\\ \end{align}$ If I explicitly write out the first several terms of the left hand side, I can convince myself that these two double sums are indeed the same.  But is there an intuitive, heuristic way to see that these two sums are equivalent without explicitly writing out any terms? Thanks! Note: If you need more background, you can read about this problem on the Wiki page: http://en.wikipedia.org/wiki/Expected_value#Discrete_distribution_taking_only_non-negative_integer_values","I have a question about switching the order of summation in this probability question.  I'll give the probability background, but it's not necessary to understand my question.  We have a random variable X that takes on nonnegative integer values.  We want to show that: $\operatorname{E}[X]=\sum\limits_{i=1}^\infty P(X\geq i)$ We start off by noting that: $\sum\limits_{i=1}^\infty P(X\geq i) = \sum\limits_{i=1}^\infty \sum\limits_{j=i}^\infty P(X = j). $ My question comes in at this next part: $\begin{align} \sum\limits_{i=1}^\infty \sum\limits_{j=i}^\infty P(X = j) &=\sum\limits_{j=1}^\infty \sum\limits_{i=1}^j P(X = j)\\ \end{align}$ If I explicitly write out the first several terms of the left hand side, I can convince myself that these two double sums are indeed the same.  But is there an intuitive, heuristic way to see that these two sums are equivalent without explicitly writing out any terms? Thanks! Note: If you need more background, you can read about this problem on the Wiki page: http://en.wikipedia.org/wiki/Expected_value#Discrete_distribution_taking_only_non-negative_integer_values",,"['probability', 'summation']"
41,What number would you bet on to maximize your chances of winning?,What number would you bet on to maximize your chances of winning?,,"You have an asymmetrical die with $20$ faces: it has $30\%$ chance for $20$ to be rolled, while the other faces ( $1,2,\dots,19)$ are equiprobable. You and your friend each choose a number, and the die is rolled once. Whoever's number is closer to the result will win. What number do you choose? Do you just compute the expected value of the roll and round to the closest integer? My intuition says ""yes"" but I'm not sure.","You have an asymmetrical die with faces: it has chance for to be rolled, while the other faces ( are equiprobable. You and your friend each choose a number, and the die is rolled once. Whoever's number is closer to the result will win. What number do you choose? Do you just compute the expected value of the roll and round to the closest integer? My intuition says ""yes"" but I'm not sure.","20 30\% 20 1,2,\dots,19)","['probability', 'game-theory', 'expected-value']"
42,Gambler coin problem: fair coin and two-headed coin,Gambler coin problem: fair coin and two-headed coin,,"The following problem was posed to me: A gambler has in his pocket a fair coin and a two-headed coin. He selects one of the coins at random, i.e. the probability that the fair coin is selected is 0.5. When the gambler flips the chosen coin, it shows heads. (A) What is the probability that it is the fair coin? (B) Suppose that he flips the same coin a second time and again it shows heads. Now what is the probability that it is the fair coin? (C) Suppose that he flips the same coin a third time and it shows tails. Now what is the probability that it is the fair coin? I am concerned with (C). The following solution was provided: Let $F$ be the event that the coin is fair, $F^c$ is the complement of $F$ . Let also $H$ be the event that it shows a head. $$P(F|HHH) = \dfrac{P(HHH|F)P(F)}{P(HHH)} = \dfrac{P(HHH|F)P(F)}{P(HHH|F)P(F) + P(HHH|F^c)P(F^c)} = \dfrac{1/2 \cdot 1/2 \cdot 1/2 \cdot 1/2}{9/6} = 1/9$$ But isn't this a solution to the problem of probability that it is the fair coin when flipping the coin a third time and it showing heads ? Shouldn't we instead be calculating $P(F|HHT)$ ? But if we should be calculating $P(F|HHT)$ , since only one of the coins (the fair coin) has a tails side, wouldn't $P(F|HHT)$ (the probability that the coin is fair instead of the two-headed coin) equal to $1$ ? In that case, we wouldn't even need to calculate anything. I would greatly appreciate it if people could please take the time to clarify this.","The following problem was posed to me: A gambler has in his pocket a fair coin and a two-headed coin. He selects one of the coins at random, i.e. the probability that the fair coin is selected is 0.5. When the gambler flips the chosen coin, it shows heads. (A) What is the probability that it is the fair coin? (B) Suppose that he flips the same coin a second time and again it shows heads. Now what is the probability that it is the fair coin? (C) Suppose that he flips the same coin a third time and it shows tails. Now what is the probability that it is the fair coin? I am concerned with (C). The following solution was provided: Let be the event that the coin is fair, is the complement of . Let also be the event that it shows a head. But isn't this a solution to the problem of probability that it is the fair coin when flipping the coin a third time and it showing heads ? Shouldn't we instead be calculating ? But if we should be calculating , since only one of the coins (the fair coin) has a tails side, wouldn't (the probability that the coin is fair instead of the two-headed coin) equal to ? In that case, we wouldn't even need to calculate anything. I would greatly appreciate it if people could please take the time to clarify this.",F F^c F H P(F|HHH) = \dfrac{P(HHH|F)P(F)}{P(HHH)} = \dfrac{P(HHH|F)P(F)}{P(HHH|F)P(F) + P(HHH|F^c)P(F^c)} = \dfrac{1/2 \cdot 1/2 \cdot 1/2 \cdot 1/2}{9/6} = 1/9 P(F|HHT) P(F|HHT) P(F|HHT) 1,"['probability', 'bayes-theorem']"
43,Linearity of expectations - Why does it hold intuitively even when the r.v.s are correlated?,Linearity of expectations - Why does it hold intuitively even when the r.v.s are correlated?,,"An experiment - say rolling a die, is performed a large number of times, $n$. Let $X$ and $Y$ be two random variables that summarize this experiment. Intuitively(by the law of large numbers), if I observe the values of $X$, over a large number of trials, take their mean, $m_{X}=\frac{1}{n}\sum_{i}{x_{i}}$, and observe the values of $Y$, take their mean $m_{Y}=\frac{1}{n}\sum_{i}{y_{i}}$ and the add the two column means, this is very close to $E(X)+E(Y)$. If we observe the values of $X+Y$ in a third column, and take their arithmetic mean, $m_{X+Y}$, this will be very close to $E(X+Y)$. Therefore, linearity of expectation, that $E(X+Y)=E(X)+E(Y)$ emerges as a simple fact of arithmetic (we're just adding two numbers in different orders). I know linearity of expectations holds, even when the $X$ and $Y$ are dependent. For example, the binomial and hypergeometric expectation is $E(X)=np$, although in the binomial story, the $Bern(p)$ random variables are i.i.d., but in the hypergeometric story, they are dependent. If two random variables are correlated, wouldn't that affect the average of their sum, than if they were uncorrelated? Any insight or intuition would be great!","An experiment - say rolling a die, is performed a large number of times, $n$. Let $X$ and $Y$ be two random variables that summarize this experiment. Intuitively(by the law of large numbers), if I observe the values of $X$, over a large number of trials, take their mean, $m_{X}=\frac{1}{n}\sum_{i}{x_{i}}$, and observe the values of $Y$, take their mean $m_{Y}=\frac{1}{n}\sum_{i}{y_{i}}$ and the add the two column means, this is very close to $E(X)+E(Y)$. If we observe the values of $X+Y$ in a third column, and take their arithmetic mean, $m_{X+Y}$, this will be very close to $E(X+Y)$. Therefore, linearity of expectation, that $E(X+Y)=E(X)+E(Y)$ emerges as a simple fact of arithmetic (we're just adding two numbers in different orders). I know linearity of expectations holds, even when the $X$ and $Y$ are dependent. For example, the binomial and hypergeometric expectation is $E(X)=np$, although in the binomial story, the $Bern(p)$ random variables are i.i.d., but in the hypergeometric story, they are dependent. If two random variables are correlated, wouldn't that affect the average of their sum, than if they were uncorrelated? Any insight or intuition would be great!",,['probability']
44,Secret-Santa: Probability of two people drawing each other.,Secret-Santa: Probability of two people drawing each other.,,"When playing Secret Santa this year, where a group of $n$ people buy presents and these $n$ presents get randomly distributed to the other people, excluding the possibility of someone getting his or her own present (we did it with a online-distributer, so this possibility really is excluded), someone in this round asked the question about the probabilty of two people giving presents to each other . Since then I've been thinking about this problem, but I didnt get very far. The only thing that comes to my mind is working with the symmetric group $S_{n}$ , and considering the possibilities $S_{n}\setminus F$ , with $F$ being the set of all permuations with at least one fixpoint, as this is not possible in the game of Secret Santa. The probabilty I'm interested in now can be calculated by coming up with the cardinality of the set $\{\pi \in S_{n}\setminus F\ \mid \pi $ contains at least a two-cycle $\}$ . Any futher ideas?","When playing Secret Santa this year, where a group of people buy presents and these presents get randomly distributed to the other people, excluding the possibility of someone getting his or her own present (we did it with a online-distributer, so this possibility really is excluded), someone in this round asked the question about the probabilty of two people giving presents to each other . Since then I've been thinking about this problem, but I didnt get very far. The only thing that comes to my mind is working with the symmetric group , and considering the possibilities , with being the set of all permuations with at least one fixpoint, as this is not possible in the game of Secret Santa. The probabilty I'm interested in now can be calculated by coming up with the cardinality of the set contains at least a two-cycle . Any futher ideas?",n n S_{n} S_{n}\setminus F F \{\pi \in S_{n}\setminus F\ \mid \pi  \},"['probability', 'combinatorics', 'symmetric-groups', 'permutation-cycles']"
45,"Probabilities : A red die, a blue die, and a yellow die (all six-sided) are rolled.","Probabilities : A red die, a blue die, and a yellow die (all six-sided) are rolled.",,"A red die, a blue die, and a yellow die (all six-sided) are rolled. We are interested in the probability that the number appearing on the blue die is less than that appearing on the yellow die which is less than that appearing on the red die $P(B < Y < R)$. I know one way to calculate this is: E = event that no two dice land on the same number: $$P(E) = \frac{6 \cdot 5 \cdot 4}{6 \cdot 6 \cdot 6} = \frac{5}{9}$$ F = event that B < Y < R and no two dice land on the same number $$P(F) = P(E) \cdot P(B < Y < R|E) = \frac{5}{9} \cdot \frac{1}{6} = \frac{5}{54}$$ Is there another way to find the number of outcomes where $B < Y < R$ using the formula $N(E)/N(S)$, where $N(S) = 6 \cdot 6 \cdot 6 = 216$?","A red die, a blue die, and a yellow die (all six-sided) are rolled. We are interested in the probability that the number appearing on the blue die is less than that appearing on the yellow die which is less than that appearing on the red die $P(B < Y < R)$. I know one way to calculate this is: E = event that no two dice land on the same number: $$P(E) = \frac{6 \cdot 5 \cdot 4}{6 \cdot 6 \cdot 6} = \frac{5}{9}$$ F = event that B < Y < R and no two dice land on the same number $$P(F) = P(E) \cdot P(B < Y < R|E) = \frac{5}{9} \cdot \frac{1}{6} = \frac{5}{54}$$ Is there another way to find the number of outcomes where $B < Y < R$ using the formula $N(E)/N(S)$, where $N(S) = 6 \cdot 6 \cdot 6 = 216$?",,"['probability', 'combinatorics', 'combinations']"
46,"Intuitively, why does Bayes' theorem work?","Intuitively, why does Bayes' theorem work?",,"I'm not looking for a cryptic math demonstration. Rather, I'm interested in the intuition behind the theorem that reveals the a posteriori probability, given the prior probability $\times$ the likelihood.","I'm not looking for a cryptic math demonstration. Rather, I'm interested in the intuition behind the theorem that reveals the a posteriori probability, given the prior probability $\times$ the likelihood.",,"['probability', 'intuition', 'bayes-theorem']"
47,Probability a random walk is back at the origin,Probability a random walk is back at the origin,,"I have a symmetric random walk that starts at the origin. With probability $1/6$ it goes right by one and with probability $1/6$ it goes left by one. With probability $4/6$ it stays put.  After $n$ time steps, what is the probability that it is at the origin? The answer should be the probability that you go left by the same amount you go right.  I am having difficulty working this out however.","I have a symmetric random walk that starts at the origin. With probability $1/6$ it goes right by one and with probability $1/6$ it goes left by one. With probability $4/6$ it stays put.  After $n$ time steps, what is the probability that it is at the origin? The answer should be the probability that you go left by the same amount you go right.  I am having difficulty working this out however.",,['probability']
48,Expected value of rolling dice until getting a $3$,Expected value of rolling dice until getting a,3,I am having trouble with this question with regards to random variables and calculating expected values: Suppose I keep tossing a fair six-sided dice until I roll a $3$. Let $X$ be the number of times I roll the dice. What is the value of $E[X]$? So for this problem I was thinking that the answer would just be $1$. Here is my thought behind it. For each turn there is a $1/6$ chance of hitting a three. If I keep rolling and rolling I will eventually hit a $3$. So the math works out to be $(1/6)*6$ which is equal to $1$. Does this logic make sense? I am a bit confused with how exactly I would go about picking the values for $P(X=x)$ and how to calculate expected value. Some insight would be very helpful.,I am having trouble with this question with regards to random variables and calculating expected values: Suppose I keep tossing a fair six-sided dice until I roll a $3$. Let $X$ be the number of times I roll the dice. What is the value of $E[X]$? So for this problem I was thinking that the answer would just be $1$. Here is my thought behind it. For each turn there is a $1/6$ chance of hitting a three. If I keep rolling and rolling I will eventually hit a $3$. So the math works out to be $(1/6)*6$ which is equal to $1$. Does this logic make sense? I am a bit confused with how exactly I would go about picking the values for $P(X=x)$ and how to calculate expected value. Some insight would be very helpful.,,"['probability', 'random-variables']"
49,Coin tosses until I'm out of money,Coin tosses until I'm out of money,,"The question I think is a simple one, but I've been unable to answer or find an answer for it yet: There's a simple game: if you flip heads you win a dollar (from the house), but if you flip tails you lose a dollar (to the house). If I start with n dollars (and the house has infinite money), how many flips can I expect to do before I've lost all my money?  This is different than the common question of how many flips can I do before I have a run of length 'n'.  In this case you can lose your money by never having a run of length more than 2, for example, simply by repeating win 1, lose 2, win 1, lose 2, etc... I can write out a decision tree on this, but I haven't been able to generalize it into a formula yet.","The question I think is a simple one, but I've been unable to answer or find an answer for it yet: There's a simple game: if you flip heads you win a dollar (from the house), but if you flip tails you lose a dollar (to the house). If I start with n dollars (and the house has infinite money), how many flips can I expect to do before I've lost all my money?  This is different than the common question of how many flips can I do before I have a run of length 'n'.  In this case you can lose your money by never having a run of length more than 2, for example, simply by repeating win 1, lose 2, win 1, lose 2, etc... I can write out a decision tree on this, but I haven't been able to generalize it into a formula yet.",,"['probability', 'combinatorics', 'statistics']"
50,Probability of a fraction $a/b$ that cannot be simplified [duplicate],Probability of a fraction  that cannot be simplified [duplicate],a/b,"This question already has answers here : Probability that two random numbers are coprime is $\frac{6}{\pi^2}$ (2 answers) Closed 3 years ago . Locked . This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions. Let $a$ and $b$ be random integers chosen independently from the uniform distribution on $\{1, 2,\dotsc, N\}$ . As $N \rightarrow \infty$ , what is the probability that the fraction: $$\frac{a}{b}$$ cannot be simplified? Note: As specified in the comments, the question is the same as this one .","This question already has answers here : Probability that two random numbers are coprime is $\frac{6}{\pi^2}$ (2 answers) Closed 3 years ago . Locked . This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions. Let and be random integers chosen independently from the uniform distribution on . As , what is the probability that the fraction: cannot be simplified? Note: As specified in the comments, the question is the same as this one .","a b \{1, 2,\dotsc, N\} N \rightarrow \infty \frac{a}{b}","['probability', 'elementary-number-theory', 'gcd-and-lcm']"
51,Probability of a Full House for five-card hand.,Probability of a Full House for five-card hand.,,"So I know this can be solved easily by counting the total ways to make a full house and dividing that by the total possible hands, but I want to know why another way I thought of to solve it is wrong. My calculation is: $$1 \times \frac{3}{51} \times \frac{2}{50} \times \frac{48}{49} \times \frac{3}{48} \times 5!$$ To break this down, the first card can be any. The second card must be the same number as the first ($\frac{3}{51}$) and the third card must also be the same number ($\frac{2}{50}$). The fourth card can be any from the deck with the exception of whatever card makes a 4-of-a-kind ($\frac{48}{49}$). And the fifth card must be the same number as the fourth card ($\frac{3}{48}$). Since order should not matter for a hand of cards, I multiply this probability by $5!$. I can't figure out where I went wrong, but evidently this does not give me the correct answer. Can anyone help me find my error?","So I know this can be solved easily by counting the total ways to make a full house and dividing that by the total possible hands, but I want to know why another way I thought of to solve it is wrong. My calculation is: $$1 \times \frac{3}{51} \times \frac{2}{50} \times \frac{48}{49} \times \frac{3}{48} \times 5!$$ To break this down, the first card can be any. The second card must be the same number as the first ($\frac{3}{51}$) and the third card must also be the same number ($\frac{2}{50}$). The fourth card can be any from the deck with the exception of whatever card makes a 4-of-a-kind ($\frac{48}{49}$). And the fifth card must be the same number as the fourth card ($\frac{3}{48}$). Since order should not matter for a hand of cards, I multiply this probability by $5!$. I can't figure out where I went wrong, but evidently this does not give me the correct answer. Can anyone help me find my error?",,"['probability', 'combinatorics', 'card-games', 'poker']"
52,expected length of broken stick,expected length of broken stick,,"You break a stick of unit length in two. You then subsequently break the biggest of the resulting two sides in two, thus obtaining three pieces. What is the expected length of the smallest of the three? (Each breaking of a stick is assumed to be at a random point in that stick, uniformly distributed.)","You break a stick of unit length in two. You then subsequently break the biggest of the resulting two sides in two, thus obtaining three pieces. What is the expected length of the smallest of the three? (Each breaking of a stick is assumed to be at a random point in that stick, uniformly distributed.)",,['probability']
53,"Probability that no two consecutive throws of some (A,B,C,D,E,F)-die show up consonants","Probability that no two consecutive throws of some (A,B,C,D,E,F)-die show up consonants",,"I have a question on probability. I am looking people presenting different approaches on solving this. I already have one solution but I was not satisfied like a true mathematician ;).....so go ahead and take a dig.....if no one answers....I will post my solution....thanks! There is an unbiased cubical die with its faces labeled as A, B, C, D, E and F. If the die is thrown $n$ times, what is the probability that no two consecutive throws show up consonants? If someone has already asked a problem of this type then I will be grateful to be redirected :)","I have a question on probability. I am looking people presenting different approaches on solving this. I already have one solution but I was not satisfied like a true mathematician ;).....so go ahead and take a dig.....if no one answers....I will post my solution....thanks! There is an unbiased cubical die with its faces labeled as A, B, C, D, E and F. If the die is thrown $n$ times, what is the probability that no two consecutive throws show up consonants? If someone has already asked a problem of this type then I will be grateful to be redirected :)",,"['probability', 'combinatorics']"
54,Biased coin with a $3/4$ chance to land on the side it was before the flip,Biased coin with a  chance to land on the side it was before the flip,3/4,"Consider a hypothetical coin (with two sides: heads and tails) that has a $3/4$ probability of landing on the side it was before the flip (meaning, if I flip it starting heads-up, then it will have an only $1/4$ probability of landing tails-up). If it begins on heads, what is the probability that it is on tails after 10 flips? What about 100 flips? Assume that each flip starts on the same side as it landed on the previous flip. Note: this is not a homework problem, just something I thought up myself.","Consider a hypothetical coin (with two sides: heads and tails) that has a $3/4$ probability of landing on the side it was before the flip (meaning, if I flip it starting heads-up, then it will have an only $1/4$ probability of landing tails-up). If it begins on heads, what is the probability that it is on tails after 10 flips? What about 100 flips? Assume that each flip starts on the same side as it landed on the previous flip. Note: this is not a homework problem, just something I thought up myself.",,['probability']
55,Finding a Correlation between Bernoulli Variables?,Finding a Correlation between Bernoulli Variables?,,"Let X and Y be Bernoulli random variables. We don't assume independence or identical distribution, but we do assume that all 4 of the following probabilities are nonzero. Let a := P[X = 1, Y = 1], b := P[X = 1, Y = 0], c := P[X = 0, Y = 1], and d := P[X = 0, Y = 0]. How do I obtain a formula for a correlation between random variables X and Y?","Let X and Y be Bernoulli random variables. We don't assume independence or identical distribution, but we do assume that all 4 of the following probabilities are nonzero. Let a := P[X = 1, Y = 1], b := P[X = 1, Y = 0], c := P[X = 0, Y = 1], and d := P[X = 0, Y = 0]. How do I obtain a formula for a correlation between random variables X and Y?",,"['probability', 'statistics', 'correlation', 'bernoulli-numbers']"
56,Prove that $\sum_{k=0}^r {m \choose k} {n \choose r-k} = {m+n \choose r}$ [duplicate],Prove that  [duplicate],\sum_{k=0}^r {m \choose k} {n \choose r-k} = {m+n \choose r},"This question already has answers here : How to prove Vandermonde's Identity: $\sum_{k=0}^{n}\binom{R}{k}\binom{M}{n-k}=\binom{R+M}{n}$? (7 answers) Closed 10 years ago . Prove that $$\sum_{k=0}^r {m \choose k} {n \choose r-k} = {m+n \choose r}.$$ This problem is in the chapter about discrete random variables, but I have no idea what to go about substituting. I can't get it to be a featured formula without screwing stuff up, sorry about that.","This question already has answers here : How to prove Vandermonde's Identity: $\sum_{k=0}^{n}\binom{R}{k}\binom{M}{n-k}=\binom{R+M}{n}$? (7 answers) Closed 10 years ago . Prove that $$\sum_{k=0}^r {m \choose k} {n \choose r-k} = {m+n \choose r}.$$ This problem is in the chapter about discrete random variables, but I have no idea what to go about substituting. I can't get it to be a featured formula without screwing stuff up, sorry about that.",,"['probability', 'combinatorics', 'proof-writing', 'summation']"
57,Conditional probability - sum of dice is even given that at least one is a five,Conditional probability - sum of dice is even given that at least one is a five,,"Question: Calculate the conditional probability that the sum of two dice tosses is even given that at least one of the tosses gives a five. I'm a bit confused by this. Shouldn't the probability just be 1/2, since we know that at least one of the dice tosses gave us a five, thus the other must give us an odd number?","Question: Calculate the conditional probability that the sum of two dice tosses is even given that at least one of the tosses gives a five. I'm a bit confused by this. Shouldn't the probability just be 1/2, since we know that at least one of the dice tosses gave us a five, thus the other must give us an odd number?",,['probability']
58,Probability of Bride entering the Church?,Probability of Bride entering the Church?,,"A Bride is standing at the entrance of a church with her father (one step forward will take her into the church). Her father has a basket containing $10$ White roses and $10$ Red roses. He takes $1$ rose at a time from the basket and gives it to the Bride. If the rose is Red, the Bride takes $1$ step towards the church and if it is White, she takes $1$ step away from the church. What is the probability that the Bride enters the church? Assume that Bride's father can not see the rose until he takes the rose out of the basket. I am stuck at this point: If the first rose is Red then the Bride enters the Church and in that case the probability is $\frac{10}{20}$. But then come the cases when the first rose is White: WRR, WWRRR, WRWRR and so on. No matter what, if the first rose is White, the last two roses must be Red. And the total number of roses required (⩽20) to enter the church is Odd, where the number of Red roses will never exceed that of the White roses but once when the Bride finally enters the church. Leaves me in doldrums, though","A Bride is standing at the entrance of a church with her father (one step forward will take her into the church). Her father has a basket containing $10$ White roses and $10$ Red roses. He takes $1$ rose at a time from the basket and gives it to the Bride. If the rose is Red, the Bride takes $1$ step towards the church and if it is White, she takes $1$ step away from the church. What is the probability that the Bride enters the church? Assume that Bride's father can not see the rose until he takes the rose out of the basket. I am stuck at this point: If the first rose is Red then the Bride enters the Church and in that case the probability is $\frac{10}{20}$. But then come the cases when the first rose is White: WRR, WWRRR, WRWRR and so on. No matter what, if the first rose is White, the last two roses must be Red. And the total number of roses required (⩽20) to enter the church is Odd, where the number of Red roses will never exceed that of the White roses but once when the Bride finally enters the church. Leaves me in doldrums, though",,"['probability', 'combinatorics', 'discrete-mathematics']"
59,Boy and Girl paradox [duplicate],Boy and Girl paradox [duplicate],,"This question already has answers here : In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? (21 answers) Closed 10 years ago . I am trying to understand the boy and girl paradox.  The paradox states that if a family has two children and one of them is a boy, then the probability of the other being a girl is 2/3.  When you write out the set of possible outcomes { bb, bg, gb, gg } it makes a little more sense.  My question is why does age/order matter?  The two possible outcomes boy/girl and girl/ boy are the same right?","This question already has answers here : In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? (21 answers) Closed 10 years ago . I am trying to understand the boy and girl paradox.  The paradox states that if a family has two children and one of them is a boy, then the probability of the other being a girl is 2/3.  When you write out the set of possible outcomes { bb, bg, gb, gg } it makes a little more sense.  My question is why does age/order matter?  The two possible outcomes boy/girl and girl/ boy are the same right?",,"['probability', 'paradoxes']"
60,How to win at roulette?,How to win at roulette?,,"I know that the answer to my attention-grabbing question is : ""You can't win at roulette, it's a negative Expected Value game"". Yes, you're right, long term speaking . Let's imagine a medium-short term situation (just an after-dinner at the casinò) where there will be <100 bets. What's the best strategy to use to win some money? I imagine a hypothetical formula that considers our ""money target"" and percentage of success as inversely proportional (the more we want to win the less likely we are going to succeed). What do you think? Are those ""red-black double if lose"" systems useful?","I know that the answer to my attention-grabbing question is : ""You can't win at roulette, it's a negative Expected Value game"". Yes, you're right, long term speaking . Let's imagine a medium-short term situation (just an after-dinner at the casinò) where there will be <100 bets. What's the best strategy to use to win some money? I imagine a hypothetical formula that considers our ""money target"" and percentage of success as inversely proportional (the more we want to win the less likely we are going to succeed). What do you think? Are those ""red-black double if lose"" systems useful?",,['probability']
61,Showing $\cos(t^2)$ is not a Characteristic Function,Showing  is not a Characteristic Function,\cos(t^2),"Usually when we try to show a function is not a characteristic function, we would prove it is not uniformly continuous. I am wondering if there is any other way to show $\cos(t^2)$ is not a characteristic function. $%fooling edit check$","Usually when we try to show a function is not a characteristic function, we would prove it is not uniformly continuous. I am wondering if there is any other way to show $\cos(t^2)$ is not a characteristic function. $%fooling edit check$",,"['probability', 'probability-theory', 'probability-distributions']"
62,"If Monty Hall doesn't know where the prize is, should the contestant still switch doors, after Monty opens one door and unveiss a goat?","If Monty Hall doesn't know where the prize is, should the contestant still switch doors, after Monty opens one door and unveiss a goat?",,"The other day I was asked a variation of the Monty Hall Problem . The answer of the original question is, of course, $ 66\% $ in favor of changing doors, but this is based on the fact that the game show host knows where the prize is. Suppose Monty does not know where the prize is, and after you  pick, he opens one of the other two doors and it happens to be a goat. Is it still better to change doors when he asks? I believe it is. (After all it still leaves us with two chances instead of one.) But some of my friends think otherwise. We are not mathematicians, just a couple of riddle-likers, so we are not sure of the correct answer. So I thought to post it here. Edit What are your thoughts on the following on Wikipedia ? This quotation  seems to support my answer. Morgan et al. (1991) and Gillman (1992) both show a more general solution where the car is (uniformly) randomly placed but the host is not constrained to pick uniformly randomly if the player has initially selected the car, which is how they both interpret the well known statement of the problem in Parade despite the author's disclaimers. Both changed the wording of the Parade version to emphasize that point when they restated the problem. They consider a scenario where the host chooses between revealing two goats with a preference expressed as a probability q, having a value between 0 and 1. If the host picks randomly q would be 1/2 and switching wins with probability 2/3 regardless of which door the host opens. If the player picks Door 1 and the host's preference for Door 3 is q, then in the case where the host opens Door 3 switching wins with probability 1/3 if the car is behind Door 2 and loses with probability (1/3)q if the car is behind Door 1. The conditional probability of winning by switching given the host opens Door 3 is therefore (1/3)/(1/3 + (1/3)q) which simplifies to 1/(1+q). Since q can vary between 0 and 1 this conditional probability can vary between 1/2 and 1. This means even without constraining the host to pick randomly if the player initially selects the car, the player is never worse off switching. However, it is important to note that neither source suggests the player knows what the value of q is, so the player cannot attribute a probability other than the 2/3 that vos Savant assumed was implicit.","The other day I was asked a variation of the Monty Hall Problem . The answer of the original question is, of course, in favor of changing doors, but this is based on the fact that the game show host knows where the prize is. Suppose Monty does not know where the prize is, and after you  pick, he opens one of the other two doors and it happens to be a goat. Is it still better to change doors when he asks? I believe it is. (After all it still leaves us with two chances instead of one.) But some of my friends think otherwise. We are not mathematicians, just a couple of riddle-likers, so we are not sure of the correct answer. So I thought to post it here. Edit What are your thoughts on the following on Wikipedia ? This quotation  seems to support my answer. Morgan et al. (1991) and Gillman (1992) both show a more general solution where the car is (uniformly) randomly placed but the host is not constrained to pick uniformly randomly if the player has initially selected the car, which is how they both interpret the well known statement of the problem in Parade despite the author's disclaimers. Both changed the wording of the Parade version to emphasize that point when they restated the problem. They consider a scenario where the host chooses between revealing two goats with a preference expressed as a probability q, having a value between 0 and 1. If the host picks randomly q would be 1/2 and switching wins with probability 2/3 regardless of which door the host opens. If the player picks Door 1 and the host's preference for Door 3 is q, then in the case where the host opens Door 3 switching wins with probability 1/3 if the car is behind Door 2 and loses with probability (1/3)q if the car is behind Door 1. The conditional probability of winning by switching given the host opens Door 3 is therefore (1/3)/(1/3 + (1/3)q) which simplifies to 1/(1+q). Since q can vary between 0 and 1 this conditional probability can vary between 1/2 and 1. This means even without constraining the host to pick randomly if the player initially selects the car, the player is never worse off switching. However, it is important to note that neither source suggests the player knows what the value of q is, so the player cannot attribute a probability other than the 2/3 that vos Savant assumed was implicit.", 66\% ,"['probability', 'monty-hall']"
63,Is it an abuse to refer to constant (or constant functions) as random variables?,Is it an abuse to refer to constant (or constant functions) as random variables?,,"I am reading a lecture notes that makes the following assertion, which I quote in verbatim. Let $s \in \{0,1\}$ , then $s$ is a random variable. We assume that $\Pr[s = 0] = 0.5$ and $\Pr[s = 1] = 0.5$ . Technically $s$ does take on the value of $0$ , $1$ because it is $0$ or $1$ . But to me this is not defined properly, because it does not mention anything about the sample space. This is something that has kept confusing me because a random variable is a function, but in the case this function is a constant function (or takes on constant value), then difference between the function and the value that it takes on gets blurred. To simply this question to its logical extreme, is the number $s = 1$ a random variable with $\Pr[s = 1] = 1$ ?","I am reading a lecture notes that makes the following assertion, which I quote in verbatim. Let , then is a random variable. We assume that and . Technically does take on the value of , because it is or . But to me this is not defined properly, because it does not mention anything about the sample space. This is something that has kept confusing me because a random variable is a function, but in the case this function is a constant function (or takes on constant value), then difference between the function and the value that it takes on gets blurred. To simply this question to its logical extreme, is the number a random variable with ?","s \in \{0,1\} s \Pr[s = 0] = 0.5 \Pr[s = 1] = 0.5 s 0 1 0 1 s = 1 \Pr[s = 1] = 1","['probability', 'probability-theory', 'probability-distributions', 'notation', 'random-variables']"
64,"How long until a random word with letters ""A"", ""B"", ""C"" ends in the pattern ""ABC""?","How long until a random word with letters ""A"", ""B"", ""C"" ends in the pattern ""ABC""?",,"Let's say I have word constructed from random letters, A B and C with $\mathbf{P}(A) = \mathbf{P}(B) = \mathbf{P}(C) = \frac{1}{3}$ .  I am going to do a random trial and record the letters I got.  The experiment stops the first time I spell out the word ABC .  Let $N$ be the number of trials until I make the word ABC out of letters. Here are some trial words: BBBBACCCCBABAABBBBCBCCBBBCACBCAACBABC BBACCCCACABABC CBBCCCABBABC BABBBCAAAABC CBBBCCBCCABABC CCBCBBABC ACCACCCCBCBBBCBACCBBAABBABBACCCBCBAABC ABAAABBBABC ABABC BBCACAACCACCAABAAABBCABBBBACABACBACBAABACCCBCBCCCBCCCBAAAABC I am asking for the expected length of this word.  And the variance. $\mathbb{E}[N]$ expectation $\mathbb{E}[N^2] - \mathbb{E}[N]^2$ variance Sounding more like a textbook: Our random variable is $X \in \{ A,B,C\}$ where each letter appears with equal probability.  Let's examine the sequence $(X_1, X_2, X_3, \dots , X_n)$ where $X_i$ are iid random variables with probability the same as $X$ .  Our process stops at time $t = N$ when $(X_{N-2}, X_{N-1}, X_N) = (A,B,C)$ .  What is the expected value of $N$ ?","Let's say I have word constructed from random letters, A B and C with .  I am going to do a random trial and record the letters I got.  The experiment stops the first time I spell out the word ABC .  Let be the number of trials until I make the word ABC out of letters. Here are some trial words: BBBBACCCCBABAABBBBCBCCBBBCACBCAACBABC BBACCCCACABABC CBBCCCABBABC BABBBCAAAABC CBBBCCBCCABABC CCBCBBABC ACCACCCCBCBBBCBACCBBAABBABBACCCBCBAABC ABAAABBBABC ABABC BBCACAACCACCAABAAABBCABBBBACABACBACBAABACCCBCBCCCBCCCBAAAABC I am asking for the expected length of this word.  And the variance. expectation variance Sounding more like a textbook: Our random variable is where each letter appears with equal probability.  Let's examine the sequence where are iid random variables with probability the same as .  Our process stops at time when .  What is the expected value of ?","\mathbf{P}(A) = \mathbf{P}(B) = \mathbf{P}(C) = \frac{1}{3} N \mathbb{E}[N] \mathbb{E}[N^2] - \mathbb{E}[N]^2 X \in \{ A,B,C\} (X_1, X_2, X_3, \dots , X_n) X_i X t = N (X_{N-2}, X_{N-1}, X_N) = (A,B,C) N","['probability', 'markov-chains', 'martingales']"
65,Why is the expected number coin tosses to get $HTH$ is $10$?,Why is the expected number coin tosses to get  is ?,HTH 10,Can someone please explain why is the expected number of coin tosses to get the sequence of $HTH$ is $10$? What is the intuition and formulas behind this?,Can someone please explain why is the expected number of coin tosses to get the sequence of $HTH$ is $10$? What is the intuition and formulas behind this?,,"['probability', 'intuition']"
66,Probability for pairing up,Probability for pairing up,,"A set of 200 people, consisting of 100 men and 100 women, is randomly divided into 100 pairs of 2 each. Give an upper bound to the probability that at most 30 of these pairs will consist of a man and a woman. I intend to use the Chebyshev Inequality to solve it but it turns out that the prob. dist. for # of pairs consisting of a man and a woman is hard to find. Anyone have any thought on it? Thanks a lot!","A set of 200 people, consisting of 100 men and 100 women, is randomly divided into 100 pairs of 2 each. Give an upper bound to the probability that at most 30 of these pairs will consist of a man and a woman. I intend to use the Chebyshev Inequality to solve it but it turns out that the prob. dist. for # of pairs consisting of a man and a woman is hard to find. Anyone have any thought on it? Thanks a lot!",,['probability']
67,"If we draw cards from a deck without replacement, how many cards would I have to draw on average until I obtain two kings","If we draw cards from a deck without replacement, how many cards would I have to draw on average until I obtain two kings",,"You have probably heard a similar problem from 50 challenging problems in probability: ""How many cards do I have to draw until I obtain an ace from a standard deck of playing cards?"" The answer for the above problem is 10.6, which can be obtain through manual calculation or using partitions. I wanted to extend this problem to drawing two cards of a set, and I was wondering how this could be done. My initial thoughts on the two approaches were: Brute force approach: $E[\text{two kings}] = P[\text{two kings in 2 draws}]\times2 + P[\text{two kings in 3 draws}]\times 3 + \dots + P[\text{two kings in 52 draws}]\times 52$ $E[X] = (\frac{4}{52} \frac{3}{51} 2) + {2 \choose 1} (\frac{4}{52}\frac{48}{51}\frac{3}{50}) + \dots + {52 \choose 1} (\frac{4}{52} \frac{48}{51} \dots \frac{1}{1})$ Partition Approach: $E[\text{two kings}] = E[\text{second king|first king}] + E[\text{first king}]$ And this is where I draw a blank, if I take the average value of the first king here, I get 10.6, and the partition approach no longer works. Any assistance on this would be great.","You have probably heard a similar problem from 50 challenging problems in probability: ""How many cards do I have to draw until I obtain an ace from a standard deck of playing cards?"" The answer for the above problem is 10.6, which can be obtain through manual calculation or using partitions. I wanted to extend this problem to drawing two cards of a set, and I was wondering how this could be done. My initial thoughts on the two approaches were: Brute force approach: Partition Approach: And this is where I draw a blank, if I take the average value of the first king here, I get 10.6, and the partition approach no longer works. Any assistance on this would be great.",E[\text{two kings}] = P[\text{two kings in 2 draws}]\times2 + P[\text{two kings in 3 draws}]\times 3 + \dots + P[\text{two kings in 52 draws}]\times 52 E[X] = (\frac{4}{52} \frac{3}{51} 2) + {2 \choose 1} (\frac{4}{52}\frac{48}{51}\frac{3}{50}) + \dots + {52 \choose 1} (\frac{4}{52} \frac{48}{51} \dots \frac{1}{1}) E[\text{two kings}] = E[\text{second king|first king}] + E[\text{first king}],"['probability', 'expected-value', 'conditional-expectation']"
68,Probability that new baby born is a boy in a nursery,Probability that new baby born is a boy in a nursery,,"There are $2$ boys and unknown number of girls in a nursery. A new baby is just born inside the room. We pick randomly a baby from the room, it turns out that the baby is a boy. What is the probability that the new baby just born is a boy? We can solve this using Bayes' rule, as follows, $P(\text{new baby is boy} | \text{picked a boy})$ . We end up getting $\frac{3}{5}$ . Why is this answer intuitively not dependent on the number of girls in the nursery?","There are boys and unknown number of girls in a nursery. A new baby is just born inside the room. We pick randomly a baby from the room, it turns out that the baby is a boy. What is the probability that the new baby just born is a boy? We can solve this using Bayes' rule, as follows, . We end up getting . Why is this answer intuitively not dependent on the number of girls in the nursery?",2 P(\text{new baby is boy} | \text{picked a boy}) \frac{3}{5},['probability']
69,"I got the answer as 7/16 , can anyone confirm it?","I got the answer as 7/16 , can anyone confirm it?",,"Box A contains 5 red and 3 white marbles Box b contains 2 red and 6 white marbles if a marble is drawn from each box, what is the prob that they are of same colour. My solution: RR  or WW = (5/8)(2/8)  + (3/8)(6/8) = 10/64 + 18/64 = 28/64 = 7/16 My teacher's solution: Let E1 be the event that marble is from Box A and is Red: P(E1)=(1/2)(5/8)= 5/16 Let E2 be the event that marble is from Box B and is Red: P(E2)=(1/2)(2/8)= 1/8 Let E3 be the event that marble is from Box B and is White: P(E3)=(1/2)(3/8)= 3/16 Let E4 be the event that marble is from Box B and is White: P(E4)=(1/2)(6/8)= 3/8 Required Probability= P(E1nE2)+P(E3nE4)= (5/16)(1/8)+(3/16)(3/8)= 7/64 can anyone confirm which one is correct?","Box A contains 5 red and 3 white marbles Box b contains 2 red and 6 white marbles if a marble is drawn from each box, what is the prob that they are of same colour. My solution: RR  or WW = (5/8)(2/8)  + (3/8)(6/8) = 10/64 + 18/64 = 28/64 = 7/16 My teacher's solution: Let E1 be the event that marble is from Box A and is Red: P(E1)=(1/2)(5/8)= 5/16 Let E2 be the event that marble is from Box B and is Red: P(E2)=(1/2)(2/8)= 1/8 Let E3 be the event that marble is from Box B and is White: P(E3)=(1/2)(3/8)= 3/16 Let E4 be the event that marble is from Box B and is White: P(E4)=(1/2)(6/8)= 3/8 Required Probability= P(E1nE2)+P(E3nE4)= (5/16)(1/8)+(3/16)(3/8)= 7/64 can anyone confirm which one is correct?",,"['probability', 'combinatorics']"
70,One of two independent flip sequences reaches two heads simultaneously. What is the distribution of others tosses.,One of two independent flip sequences reaches two heads simultaneously. What is the distribution of others tosses.,,"Two people start flipping fair coins. We wait for one of them to reach two heads in a row. When that happens, we look at the last two tosses of the other guy. The other guy might have HH, HT, TH and TT. Naively, we might think all of these four are equally likely. However, that would mean there is a 25% chance the two sequences would reach two heads simultaneously. Now that seems high and as a matter of fact is. If you look at the code here (method named get_loser_state_prob at the very end) - https://github.com/ryu577/stochproc/blob/master/stochproc/competitivecointoss/simulation.py you will see the distribution actually looks like this - HH: 0.12 HT: 0.24 TH: 0.32 TT: 0.32 It's completely unintuitive to me why HT and TH should have different probabilities and the distribution in general is something I can't wrap my mind around. Can someone explain why we should expect - 1) HH should be the lowest 2) HT should be lower than TH 3) TH and TT should be roughly the same (since it's simulation, can't tell if they are exactly the same but certainly very close).","Two people start flipping fair coins. We wait for one of them to reach two heads in a row. When that happens, we look at the last two tosses of the other guy. The other guy might have HH, HT, TH and TT. Naively, we might think all of these four are equally likely. However, that would mean there is a 25% chance the two sequences would reach two heads simultaneously. Now that seems high and as a matter of fact is. If you look at the code here (method named get_loser_state_prob at the very end) - https://github.com/ryu577/stochproc/blob/master/stochproc/competitivecointoss/simulation.py you will see the distribution actually looks like this - HH: 0.12 HT: 0.24 TH: 0.32 TT: 0.32 It's completely unintuitive to me why HT and TH should have different probabilities and the distribution in general is something I can't wrap my mind around. Can someone explain why we should expect - 1) HH should be the lowest 2) HT should be lower than TH 3) TH and TT should be roughly the same (since it's simulation, can't tell if they are exactly the same but certainly very close).",,"['probability', 'probability-theory']"
71,$n$ bugs moving in a line,bugs moving in a line,n,"I have a line of $n$ bugs, where no $2$ bugs have the same size. They all move in the same direction. If a bigger bug is behind a smaller bug, it will eat the smaller bug. What is the expectation of the number of bugs left after a long enough time? I am not sure how to approach this. From $n=1, 2, 3, 4$ I guess the answer might be $$ 2- \frac{1}{n!} $$ but I am not sure if this is correct and how to derive this. For example, when $n=3$, if my bugs are $a,b,c$, where $a>b>c$, assuming they are moving from left to right, then I have the following $6$ situations. $a,b,c$ — 1 left $a,c,b$ — 1 left $b,c,a$ — 2 left $b,a,c$ — 2 left $c,a,b$ — 2 left $c,b,a$ — 3 left then the expectation is 1*2/6+ 2*3/6 + 3*1/6 = 11/6 = 2-1/3!","I have a line of $n$ bugs, where no $2$ bugs have the same size. They all move in the same direction. If a bigger bug is behind a smaller bug, it will eat the smaller bug. What is the expectation of the number of bugs left after a long enough time? I am not sure how to approach this. From $n=1, 2, 3, 4$ I guess the answer might be $$ 2- \frac{1}{n!} $$ but I am not sure if this is correct and how to derive this. For example, when $n=3$, if my bugs are $a,b,c$, where $a>b>c$, assuming they are moving from left to right, then I have the following $6$ situations. $a,b,c$ — 1 left $a,c,b$ — 1 left $b,c,a$ — 2 left $b,a,c$ — 2 left $c,a,b$ — 2 left $c,b,a$ — 3 left then the expectation is 1*2/6+ 2*3/6 + 3*1/6 = 11/6 = 2-1/3!",,"['probability', 'expectation', 'puzzle']"
72,Probability of second ball being black,Probability of second ball being black,,"I was taking Caltech - ML Course and solving problem 1.3 in this link We have 2 opaque bags, each containing 2 balls. One bag has 2 black balls and the other has a black ball and a white ball. You pick a bag at random and then pick one of the balls in that bag at random. When you look at the ball, it is black. You now pick the second ball from that same bag. What is the probability that this ball is also black? I tried to do this way: Since we are trying to find the probability of 2nd being ball being black when we already know that first ball is black. This reduces our problem to probability by which we picked the bag with two black balls. So the answer should be 1/2. PS: This is not a homework/assignment. This course has been already finished. I am just taking it offline for learning purpose.","I was taking Caltech - ML Course and solving problem 1.3 in this link We have 2 opaque bags, each containing 2 balls. One bag has 2 black balls and the other has a black ball and a white ball. You pick a bag at random and then pick one of the balls in that bag at random. When you look at the ball, it is black. You now pick the second ball from that same bag. What is the probability that this ball is also black? I tried to do this way: Since we are trying to find the probability of 2nd being ball being black when we already know that first ball is black. This reduces our problem to probability by which we picked the bag with two black balls. So the answer should be 1/2. PS: This is not a homework/assignment. This course has been already finished. I am just taking it offline for learning purpose.",,['probability']
73,Old Maid Card Game Probability Question,Old Maid Card Game Probability Question,,"I am not a math person but was shocked by something that happened when I played Old Maid for the first time ever with with my two young sons tonight. We were playing with a deck that had 37 cards in total, which means 18 pairs plus the Old Maid. When I dealt the cards into three groups (12+12+13), not one of us had a single pair in our hands. What is the statistical likelihood that this could happen? Can anyone figure out the math for me? I doubt this will ever happen again in our lifetimes, but maybe I'm wrong..","I am not a math person but was shocked by something that happened when I played Old Maid for the first time ever with with my two young sons tonight. We were playing with a deck that had 37 cards in total, which means 18 pairs plus the Old Maid. When I dealt the cards into three groups (12+12+13), not one of us had a single pair in our hands. What is the statistical likelihood that this could happen? Can anyone figure out the math for me? I doubt this will ever happen again in our lifetimes, but maybe I'm wrong..",,"['probability', 'combinatorics', 'graph-theory', 'card-games']"
74,"What is the probability that three babies are boys, given that at least one is a boy?","What is the probability that three babies are boys, given that at least one is a boy?",,"I know this is a simple problem but I am arguing with a friend about its solution, so I want to show him an ""official"" proof! Suppose that in any birth, the probability to have a boy is $48.5\%$ . If we have three persons expecting to deliver, what is the probability that at least one of them gives birth to a boy? If we know that at least one will give birth to a boy (suppose we have accurate ultra-sound results), what is the probability all three will have a boy? For the first question, we calculate the probability of one NOT having a boy, which is $1-0.485 = 0.515$ and then the required probability of all three not having a boy is $0.515^3 = 0.1365$ so the probability that at least one will have a boy is $1-0.1365 = 0.8634 = 86.34\%$ . For the second question, since the three events are independent, the probability that all three will have a boy given that at least one will have a boy is equal to the probability that the other two will have a boy. Is it $0.485^2$ ? I am not sure about the second one.","I know this is a simple problem but I am arguing with a friend about its solution, so I want to show him an ""official"" proof! Suppose that in any birth, the probability to have a boy is . If we have three persons expecting to deliver, what is the probability that at least one of them gives birth to a boy? If we know that at least one will give birth to a boy (suppose we have accurate ultra-sound results), what is the probability all three will have a boy? For the first question, we calculate the probability of one NOT having a boy, which is and then the required probability of all three not having a boy is so the probability that at least one will have a boy is . For the second question, since the three events are independent, the probability that all three will have a boy given that at least one will have a boy is equal to the probability that the other two will have a boy. Is it ? I am not sure about the second one.",48.5\% 1-0.485 = 0.515 0.515^3 = 0.1365 1-0.1365 = 0.8634 = 86.34\% 0.485^2,"['probability', 'conditional-probability']"
75,"Two players throw a die until the sequence $1,2,3$ appears, and the winner is the one who roll $3$. What is the probability the second player wins?","Two players throw a die until the sequence  appears, and the winner is the one who roll . What is the probability the second player wins?","1,2,3 3","Alameda and Belisario alternate turns throwing a fair die. Alameda plays first and they continue throwing, one at a time, until the sequence $1$ - $2$ - $3$ appears. Whoever throws the $3$ is the winner. What is the probability that Belisario wins? Hmmm - probabilities is not my strong domain! First let's see what the chances are to get a $1$ - $2$ - $3$ regardless who gets it. Is it $1$ in $6\cdot 6\cdot 6$ ? Then if this probability is $p$ , my understanding is that the probability for Belisario to win is smaller, but I can't compute it :(","Alameda and Belisario alternate turns throwing a fair die. Alameda plays first and they continue throwing, one at a time, until the sequence - - appears. Whoever throws the is the winner. What is the probability that Belisario wins? Hmmm - probabilities is not my strong domain! First let's see what the chances are to get a - - regardless who gets it. Is it in ? Then if this probability is , my understanding is that the probability for Belisario to win is smaller, but I can't compute it :(",1 2 3 3 1 2 3 1 6\cdot 6\cdot 6 p,"['probability', 'dice']"
76,"double decker, 13 card flush vs. 18+ of each color card. Who has the better odds of winning?","double decker, 13 card flush vs. 18+ of each color card. Who has the better odds of winning?",,"Two people, call them $A$ and $B$, decide to play a card game. They take 2 standard decks of playing cards and combine them into a ""superdeck"" of 104 cards, shuffle them well, and then draw 1 card at a time randomly without replacement. $A$ immediately wins if 13 cards of any single suit are drawn.  $B$ immediately wins if at least 18 black and at least 18 red cards are drawn. If they both ""win"" on the same card draw it is a tie (no decision) and they start over with all 104 cards after reshuffling. They bet even money—dollar for dollar matching. Who, if anyone, has the advantage of winning and by how much? Note that all cards are shared ""community"" cards so the players are not drawing their own set of cards. If someone would like to comment on if and how the probability changes if they draw their cards in tandem, that would be very interesting and informative. For example, two cards would be drawn at a time, giving one to $A$ and one to $B$, and then checked if anyone won or if they tied. This is an optional bonus question and not required to earn the checkmark for best answer. Simulating 1,000,000,000 (1 billion) decisions (including ties) of the original question (shared cards), I got the following winning percentages: $$ A\quad 38.7855918\%\\ B\quad 59.7770491\%\\ \textrm{Tie}\quad 1.4373591\% $$ Minimum # of cards : $14$ (A disappointment as I was expecting it to be $13$) Maximum # of cards : $42$ Average # of cards : $37.1902$ Note that at ""first glance"", some people might think that $A$ has the advantage because $A$ can win with as few as 13 cards but B needs 36 cards at a minimum to win. However, look at how much $B$ is actually favored to win. Another thing that somewhat surprised me is the average number of cards for someone to win (or tie) is about 37, only about 1 card more than $B$'s minimum needed to win. That might also imply that $A$ has an advantage. What if I reworded the question to also state that the average number of cards for a decision is slightly over 37, would most people then think at first glance that $A$ has an advantage, possibly a huge one? Yet another thing that might mislead people into thinking that $A$ has a large advantage is that $A$ is guaranteed not to lose if at least 42 cards are drawn. At that point either $A$ has won or tied. Kudos to the person that suspected that $B$ was the favorite from the start because he didn't let these false biases sway him towards $A$ being the favorite. UPDATE: I ran the alternate simulation giving each player their own cards and got some interesting results. $B$ remains the favorite at about $57.1\%$ to $A$'s $36.8\%$ which means the ties more than quadrupled to about $6.1\%$. The average number of cards slightly more than doubled from about 37 to about 75 with a low of 28 and a high of 94 (in ten million decisions). Perhaps one way to simplify getting the answer to this original problem is to start the game by immediately turning over 35 cards since $B$ cannot win with less than 36 cards. Check if $A$ won at 35 cards. If not, then draw cards 36 thru 42 one at a time checking for a winner.  By draw 42 someone will have won or there is a tie. So would the prob of $A$ winning on a 35 card draw be: $$ \large \frac{4\times {26 \choose 13} \times {78 \choose 22}}{{104 \choose 35}} $$ That is about $10\%$. There may be two 13 card flushes in that but we don't care as long as there is at least 1. Also it is interesting to note that in the original game with shared cards, $42$ cards is the max for a win or tie because of the $25+17$ situation but with separate hands, that doesn't happen so the max # of cards drawn can exceed $84$ (which is $2$ * $42$) and in my simulation is did exceed it as it maxxed out at $94$ cards, not $84$.  For example, B could get $29$ black cards and $17$ red cards but A could have $12, 12, 11,$ and $11$ of each suit (respectively) so at that point, neither is a winner and $2$ more cards would be drawn (almost exhausting the deck of $104$).  The max number of cards ever for the separate card variation of this game seems like $94$ but I am not certain yet. Another interesting point is that simulation of the separate card variation is considerably slower because the average approximate number of cards needed is about double ($75$ vs. $37$) and can go as high as $94$ which is almost the entire deck so it becomes ""harder"" (slower).","Two people, call them $A$ and $B$, decide to play a card game. They take 2 standard decks of playing cards and combine them into a ""superdeck"" of 104 cards, shuffle them well, and then draw 1 card at a time randomly without replacement. $A$ immediately wins if 13 cards of any single suit are drawn.  $B$ immediately wins if at least 18 black and at least 18 red cards are drawn. If they both ""win"" on the same card draw it is a tie (no decision) and they start over with all 104 cards after reshuffling. They bet even money—dollar for dollar matching. Who, if anyone, has the advantage of winning and by how much? Note that all cards are shared ""community"" cards so the players are not drawing their own set of cards. If someone would like to comment on if and how the probability changes if they draw their cards in tandem, that would be very interesting and informative. For example, two cards would be drawn at a time, giving one to $A$ and one to $B$, and then checked if anyone won or if they tied. This is an optional bonus question and not required to earn the checkmark for best answer. Simulating 1,000,000,000 (1 billion) decisions (including ties) of the original question (shared cards), I got the following winning percentages: $$ A\quad 38.7855918\%\\ B\quad 59.7770491\%\\ \textrm{Tie}\quad 1.4373591\% $$ Minimum # of cards : $14$ (A disappointment as I was expecting it to be $13$) Maximum # of cards : $42$ Average # of cards : $37.1902$ Note that at ""first glance"", some people might think that $A$ has the advantage because $A$ can win with as few as 13 cards but B needs 36 cards at a minimum to win. However, look at how much $B$ is actually favored to win. Another thing that somewhat surprised me is the average number of cards for someone to win (or tie) is about 37, only about 1 card more than $B$'s minimum needed to win. That might also imply that $A$ has an advantage. What if I reworded the question to also state that the average number of cards for a decision is slightly over 37, would most people then think at first glance that $A$ has an advantage, possibly a huge one? Yet another thing that might mislead people into thinking that $A$ has a large advantage is that $A$ is guaranteed not to lose if at least 42 cards are drawn. At that point either $A$ has won or tied. Kudos to the person that suspected that $B$ was the favorite from the start because he didn't let these false biases sway him towards $A$ being the favorite. UPDATE: I ran the alternate simulation giving each player their own cards and got some interesting results. $B$ remains the favorite at about $57.1\%$ to $A$'s $36.8\%$ which means the ties more than quadrupled to about $6.1\%$. The average number of cards slightly more than doubled from about 37 to about 75 with a low of 28 and a high of 94 (in ten million decisions). Perhaps one way to simplify getting the answer to this original problem is to start the game by immediately turning over 35 cards since $B$ cannot win with less than 36 cards. Check if $A$ won at 35 cards. If not, then draw cards 36 thru 42 one at a time checking for a winner.  By draw 42 someone will have won or there is a tie. So would the prob of $A$ winning on a 35 card draw be: $$ \large \frac{4\times {26 \choose 13} \times {78 \choose 22}}{{104 \choose 35}} $$ That is about $10\%$. There may be two 13 card flushes in that but we don't care as long as there is at least 1. Also it is interesting to note that in the original game with shared cards, $42$ cards is the max for a win or tie because of the $25+17$ situation but with separate hands, that doesn't happen so the max # of cards drawn can exceed $84$ (which is $2$ * $42$) and in my simulation is did exceed it as it maxxed out at $94$ cards, not $84$.  For example, B could get $29$ black cards and $17$ red cards but A could have $12, 12, 11,$ and $11$ of each suit (respectively) so at that point, neither is a winner and $2$ more cards would be drawn (almost exhausting the deck of $104$).  The max number of cards ever for the separate card variation of this game seems like $94$ but I am not certain yet. Another interesting point is that simulation of the separate card variation is considerably slower because the average approximate number of cards needed is about double ($75$ vs. $37$) and can go as high as $94$ which is almost the entire deck so it becomes ""harder"" (slower).",,['probability']
77,Determine the PDF from the MGF [closed],Determine the PDF from the MGF [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How can I calculate PDF using MGF? .e.g If the moment generating function is given as; $ \psi_X(s) = e^{s^2}$ How can I determine the PDF of $X$ ?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How can I calculate PDF using MGF? .e.g If the moment generating function is given as; How can I determine the PDF of ?", \psi_X(s) = e^{s^2} X,"['probability', 'probability-distributions', 'moment-generating-functions']"
78,Largest Part of a Random Weak Composition,Largest Part of a Random Weak Composition,,"Suppose we have a weak composition of the integer n into k parts. (A weak compositions is essentially a partition in which order matters and 0 is allowed) My question is, what is the expected value of the largest part of the composition? The assumption is that all compositions have equal probability.","Suppose we have a weak composition of the integer n into k parts. (A weak compositions is essentially a partition in which order matters and 0 is allowed) My question is, what is the expected value of the largest part of the composition? The assumption is that all compositions have equal probability.",,"['probability', 'combinatorics']"
79,Expected number of strikes to kill a $3$-headed dragon,Expected number of strikes to kill a -headed dragon,3,"You want to slay a dragon with $3$ heads. There is $0.7$ chance of destroying a head and $0.3$ chance of missing. If you miss, a new head will grow. $X$ is a random variable for the number of rounds until you slay all $3$ heads. Find $E[X]$ . I get the following pmf that $P(X = n) = {?}\ 0.7^{k} 0.3^{k-3}$ where $n$ is the number of slays ( $3$ , $5$ , $7$ ...) and $k$ is the number of strikes that destroy a head. I am struggling with coming up with a coefficient for the expression or number of ways to permute successes and failures. I understand that the missing strikes cannot be at the end, and there also cannot be more than $2$ successful strikes before the 1st miss. How to think of a expression to capture the coefficient?","You want to slay a dragon with heads. There is chance of destroying a head and chance of missing. If you miss, a new head will grow. is a random variable for the number of rounds until you slay all heads. Find . I get the following pmf that where is the number of slays ( , , ...) and is the number of strikes that destroy a head. I am struggling with coming up with a coefficient for the expression or number of ways to permute successes and failures. I understand that the missing strikes cannot be at the end, and there also cannot be more than successful strikes before the 1st miss. How to think of a expression to capture the coefficient?",3 0.7 0.3 X 3 E[X] P(X = n) = {?}\ 0.7^{k} 0.3^{k-3} n 3 5 7 k 2,"['probability', 'stochastic-processes', 'expected-value', 'random-walk', 'stopping-times']"
80,Expected number of times until getting two 6's,Expected number of times until getting two 6's,,"What is the expected number of times we need to roll a die until we get two consecutive 6's? By definition, it is $\sum_{i=1}^\infty i\cdot Pr[X=i]$. If we need $i$ rolls, that means the last two rolls are 6's. But how do we compute the probability that no two consecutive 6's occur before that?","What is the expected number of times we need to roll a die until we get two consecutive 6's? By definition, it is $\sum_{i=1}^\infty i\cdot Pr[X=i]$. If we need $i$ rolls, that means the last two rolls are 6's. But how do we compute the probability that no two consecutive 6's occur before that?",,"['probability', 'expectation']"
81,Maximum possible variance,Maximum possible variance,,"From this biology article , end of page 4, the author talks about a random variable which never takes value outside the range $[0,1]$ ($0$ and $1$ included in the range). He says that the maximum variance that this random variable can take equals to the product expected value of the random variable by the expected value of one minus the random variable. In other words: $$\max\mathrm{Var}\left(X\right) = \mathrm{E}(X) \cdot \mathrm{E}(1-X)$$ Is it true? Why is it true?","From this biology article , end of page 4, the author talks about a random variable which never takes value outside the range $[0,1]$ ($0$ and $1$ included in the range). He says that the maximum variance that this random variable can take equals to the product expected value of the random variable by the expected value of one minus the random variable. In other words: $$\max\mathrm{Var}\left(X\right) = \mathrm{E}(X) \cdot \mathrm{E}(1-X)$$ Is it true? Why is it true?",,"['probability', 'probability-theory', 'random-variables', 'applications']"
82,Fewest number of moves to win the game 2048?,Fewest number of moves to win the game 2048?,,"I'm trying to figure out the fewest number of moves one could make to win the game 2048 . In another thread, someone placed the figure at 520, but I'm wondering if anyone knows how to mathematically approach this problem given the game's statistical/probabilistic complexities.","I'm trying to figure out the fewest number of moves one could make to win the game 2048 . In another thread, someone placed the figure at 520, but I'm wondering if anyone knows how to mathematically approach this problem given the game's statistical/probabilistic complexities.",,"['probability', 'combinatorics', 'statistics']"
83,Taking seats on a plane: probability that the last two persons take their proper seats [duplicate],Taking seats on a plane: probability that the last two persons take their proper seats [duplicate],,"This question already has answers here : Taking Seats on a Plane (21 answers) Closed 2 years ago . 100 men are getting on a plane (containing 100 chairs) one by one. Each one has a seat number but the first one forgot his number. So he randomly chooses a chair and sits on it. Others do know their own number. Therefore if their seat is not occupied, they sit on it and otherwise they randomly choose a chair and sit. What is the probability that the last two persons sit on their own chair !? Edit: As @ByronSchmuland mentioned, a similar but different problem is HERE","This question already has answers here : Taking Seats on a Plane (21 answers) Closed 2 years ago . 100 men are getting on a plane (containing 100 chairs) one by one. Each one has a seat number but the first one forgot his number. So he randomly chooses a chair and sits on it. Others do know their own number. Therefore if their seat is not occupied, they sit on it and otherwise they randomly choose a chair and sit. What is the probability that the last two persons sit on their own chair !? Edit: As @ByronSchmuland mentioned, a similar but different problem is HERE",,"['probability', 'combinatorics']"
84,Why does P(HH) differ from P(TH)?,Why does P(HH) differ from P(TH)?,,Suppose I keep tossing a fair coin until I get two consecutive heads or a tail and then immediately a head following it. Why are these two patterns not equally probable? I thought they were since the coin is fair... Should I model this problem using a geometric distribution or some other distribution? Perhaps I should just think in terms of conditional probability?,Suppose I keep tossing a fair coin until I get two consecutive heads or a tail and then immediately a head following it. Why are these two patterns not equally probable? I thought they were since the coin is fair... Should I model this problem using a geometric distribution or some other distribution? Perhaps I should just think in terms of conditional probability?,,['probability']
85,"""infinite moments"" or ""moments don't exist""?","""infinite moments"" or ""moments don't exist""?",,"what is the difference between ""infinite moment"" and ""moments don't exist""? moreover, if I find out the moment generating function for some distribution, and take first derivative set s=1, and if I get $\infty$, what does it mean? infinite mean? or mean doesn't exist? Thanks in advance.","what is the difference between ""infinite moment"" and ""moments don't exist""? moreover, if I find out the moment generating function for some distribution, and take first derivative set s=1, and if I get $\infty$, what does it mean? infinite mean? or mean doesn't exist? Thanks in advance.",,"['probability', 'generating-functions']"
86,"Examples of the events for which we cannot assign ""meaningful"" probabilities","Examples of the events for which we cannot assign ""meaningful"" probabilities",,"Quote from the book I'm reading: Any collection of possible outcomes, including the sample space $\Omega$ and its complement, the empty set $\emptyset$ , may qualify as an event. Strictly speaking, however, some sets have to be excluded . In particular, when dealing with probabilistic models involving an uncountably infinite sample space; there are certain unusual subsets for which one cannot associate meaningful probabilities . Question 1 What is meant by ""meaningful"" probabilities? Question 2 Can you provide an example in which we cannot assign meaningful probabilities to the events of the sample space?","Quote from the book I'm reading: Any collection of possible outcomes, including the sample space and its complement, the empty set , may qualify as an event. Strictly speaking, however, some sets have to be excluded . In particular, when dealing with probabilistic models involving an uncountably infinite sample space; there are certain unusual subsets for which one cannot associate meaningful probabilities . Question 1 What is meant by ""meaningful"" probabilities? Question 2 Can you provide an example in which we cannot assign meaningful probabilities to the events of the sample space?",\Omega \emptyset,['probability']
87,Cat / mouse probability question,Cat / mouse probability question,,"There exist 7 doors numbered in order from 1 to 7 (going from left to right).  A mouse is initially placed at center door 4.  The mouse can only move 1 door at a time to either adjacent door and does so, but is twice as likely to move to a lower numbered door than to a higher numbered door each time it moves 1 door.  There are cats waiting at doors 1 and 7 that will eat the mouse immediately after the mouse moves to either of those 2 doors. So for example, the mouse starts at door 4.  He could then move to door 3, then to door 2, then back to 3, then back to 2, then to door 1 where he gets eaten.  That counts as 5 moves total.  Skipping doors is not allowed. So there are 2 questions I have regarding this: 1) What is the expected average number of moves before the mouse gets eaten?  (do not count the initial start at door 4 as a move but count any final move to doors 1 or 7 and any ""intermediate"" moves between those 2 states). 2) What is the probability that the mouse will survive for 100 or more moves?","There exist 7 doors numbered in order from 1 to 7 (going from left to right).  A mouse is initially placed at center door 4.  The mouse can only move 1 door at a time to either adjacent door and does so, but is twice as likely to move to a lower numbered door than to a higher numbered door each time it moves 1 door.  There are cats waiting at doors 1 and 7 that will eat the mouse immediately after the mouse moves to either of those 2 doors. So for example, the mouse starts at door 4.  He could then move to door 3, then to door 2, then back to 3, then back to 2, then to door 1 where he gets eaten.  That counts as 5 moves total.  Skipping doors is not allowed. So there are 2 questions I have regarding this: 1) What is the expected average number of moves before the mouse gets eaten?  (do not count the initial start at door 4 as a move but count any final move to doors 1 or 7 and any ""intermediate"" moves between those 2 states). 2) What is the probability that the mouse will survive for 100 or more moves?",,['probability']
88,Finding the Fisher's Information in a normal distribution with known $\mu$ and unknown $\sigma^{2}$,Finding the Fisher's Information in a normal distribution with known  and unknown,\mu \sigma^{2},"I have a point statistic $x_{i},...,x_{n} X \in N(\mu,\sigma^{2}), \mu$ is known. I have to apply the Rao-cramer theorem but calculating the Fisher's information I stumbled upon this problem: $I(\sigma)=-E(\frac{n}{\gamma}+3\sum(\frac{x_{i}-\mu)^{2}}{\sigma^{2}})=\frac{n}{\gamma}+ 3\frac{E(\sum(x_{i}-\mu)^{2})}{E\sigma^{4}}=\frac{n}{\gamma}+\frac{3}{\sigma^{4}}E(\sum(x_{i}-\mu)^{2})$ $$E(\sum(x_{i}-\mu)^{2})=?$$ ${\displaystyle \operatorname {E} [X]=\int _{\mathbb {R} }xf(x)\,dx.}$ But what is f(x) here ? Could it possibly be the function itself ${\displaystyle \operatorname {E} [X]=\int _{\mathbb {R} }x∑(x_i−μ)2\,dx.}$ From wiki, we know that Fisher's information is: $$(  \begin{matrix}   \frac{1}{\sigma^{2}} & 0  \\   0 & \frac{1}{2\sigma^{4}}    \end{matrix}) $$ But I need a number, what is that matrix supposed to mean? What is $I(\sigma^{2})$ for a normal distribution with $\mu$ - known and $\sigma^{2}$- unknown?","I have a point statistic $x_{i},...,x_{n} X \in N(\mu,\sigma^{2}), \mu$ is known. I have to apply the Rao-cramer theorem but calculating the Fisher's information I stumbled upon this problem: $I(\sigma)=-E(\frac{n}{\gamma}+3\sum(\frac{x_{i}-\mu)^{2}}{\sigma^{2}})=\frac{n}{\gamma}+ 3\frac{E(\sum(x_{i}-\mu)^{2})}{E\sigma^{4}}=\frac{n}{\gamma}+\frac{3}{\sigma^{4}}E(\sum(x_{i}-\mu)^{2})$ $$E(\sum(x_{i}-\mu)^{2})=?$$ ${\displaystyle \operatorname {E} [X]=\int _{\mathbb {R} }xf(x)\,dx.}$ But what is f(x) here ? Could it possibly be the function itself ${\displaystyle \operatorname {E} [X]=\int _{\mathbb {R} }x∑(x_i−μ)2\,dx.}$ From wiki, we know that Fisher's information is: $$(  \begin{matrix}   \frac{1}{\sigma^{2}} & 0  \\   0 & \frac{1}{2\sigma^{4}}    \end{matrix}) $$ But I need a number, what is that matrix supposed to mean? What is $I(\sigma^{2})$ for a normal distribution with $\mu$ - known and $\sigma^{2}$- unknown?",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
89,Drawing two cards from a deck of 16 (4 ranks and 4 suits),Drawing two cards from a deck of 16 (4 ranks and 4 suits),,"I'm reviewing for an exam and have come across a problem marked incorrect on my homework. The problem reads, There are 16 cards in a deck. The cards have 4 ranks (Jack, Queen, King, and Ace) and 4 suits (Clubs, Diamonds, Hearts, and Spades). You are dealt two cards. What is the probability you get a Diamond card? I misread this question when I first asnwered it, and I'm unsure how to get the correct solution. The solution page says that the solution is $\frac{9}{20}$. What is the probability you get two cards of the same rank? I said that once the first card is drawn, you'll have three remaining cards with that same rank out of a total of 15 cards, so you have a $\frac{3}{15} = \frac{1}{5}$ chance. This answer was the same as the solution manual. Is my logic correct? What is the probability you don't get a Diamond card? This is just 1 - (the solution to part a) = $\frac{11}{20}$. What is the probability you don't get a Diamond card and you get two cards of the same rank? Let A be the event you don't get a Diamond card. Let B be the event you get two cards of the same rank. $P(A' \cup B) = P(B) - P(A \cap B) = \frac{1}{5} - \frac{1}{10} = \frac{1}{10}$ Is there an easier way to think about this? I believe I have the most misunderstanding on the first question. Thank you for any assistance.","I'm reviewing for an exam and have come across a problem marked incorrect on my homework. The problem reads, There are 16 cards in a deck. The cards have 4 ranks (Jack, Queen, King, and Ace) and 4 suits (Clubs, Diamonds, Hearts, and Spades). You are dealt two cards. What is the probability you get a Diamond card? I misread this question when I first asnwered it, and I'm unsure how to get the correct solution. The solution page says that the solution is $\frac{9}{20}$. What is the probability you get two cards of the same rank? I said that once the first card is drawn, you'll have three remaining cards with that same rank out of a total of 15 cards, so you have a $\frac{3}{15} = \frac{1}{5}$ chance. This answer was the same as the solution manual. Is my logic correct? What is the probability you don't get a Diamond card? This is just 1 - (the solution to part a) = $\frac{11}{20}$. What is the probability you don't get a Diamond card and you get two cards of the same rank? Let A be the event you don't get a Diamond card. Let B be the event you get two cards of the same rank. $P(A' \cup B) = P(B) - P(A \cap B) = \frac{1}{5} - \frac{1}{10} = \frac{1}{10}$ Is there an easier way to think about this? I believe I have the most misunderstanding on the first question. Thank you for any assistance.",,['probability']
90,What is the intuition behind right-continuous filtration?,What is the intuition behind right-continuous filtration?,,"I cannot understand the concept of it. So a filtration is right continuous if for every $t$ it holds that: $\mathcal{F_t}=\bigcap\limits_{\varepsilon>0}\mathcal{F_{t+\varepsilon}}$ But if for every $t$, then it also holds for $t=0$. And if I choose a large $\epsilon$, then it means that at time zero I know every information about the process?","I cannot understand the concept of it. So a filtration is right continuous if for every $t$ it holds that: $\mathcal{F_t}=\bigcap\limits_{\varepsilon>0}\mathcal{F_{t+\varepsilon}}$ But if for every $t$, then it also holds for $t=0$. And if I choose a large $\epsilon$, then it means that at time zero I know every information about the process?",,"['probability', 'stochastic-processes', 'filtrations']"
91,Probability of getting a job when applying for 3 places,Probability of getting a job when applying for 3 places,,"I have the following problem. You apply for jobs and know that if you send your application then every job appointment procedure has two stages: You can be either invited or not invited to a personal interview and then You can either be selected or not selected for a job. Assuming that you do not have any further information about the process and the selection criteria, please compute the a priori probability to get at least one job offer after sending your application to three different places . My thoughts I started thinking about what events are independent and which ones are dependent. I thought that being able to get a job from place $A$ is an independent event of being able to get a job from place $B$. For this reason, I decided to consider independently the problem what is the probability of getting a job from a place $X$ . Now, the probability of being called to go to the interview (lets call this event $I$) is $\frac{1}{2}$, in other words $P(I) = \frac{1}{2}$, because we can either be called or not. Then, the probability of getting the job (lets call this event $J$) strictly depends on event $I$, because, for example, you cannot get the job, if you don't first go to the interview. What we actually want to know is the probability of being called and getting the job, in other words we want to know $P(I \text{ and } J)$. Since these events are dependent, we can use the rule that $P(A \text{ and } B) = P(A) \cdot P(B | A)$, where $P(B|A)$ is the probability of event $B$ happens given the fact that event $A$ has happened. Applying this rule to my case, I need to find $P(J | I)$, because I already know $P(I) = \frac{1}{2}$. I was thinking that this probability is $\frac{1}{4}$. Why? Basically, from $\frac{1}{2}$ of the possibilities remaining we have half of the chances to get the job, so $\frac{1}{2}$ of $\frac{1}{2}$ is $\frac{1}{4}$. I can now calculate $P(I \text{ and } J)$, which should be $P(I) \cdot P(J | I) = \frac{1}{2} \cdot \frac{1}{4} = \frac{1}{8}$. If my reasonings are correct, this should represent the probability of getting job from one place.  Since I am applying for three different jobs (which are not dependent between each other), then I have more possibilities than $\frac{1}{8}$, so I thought we could sum the possibilities of getting a job for each individual place, thus my answer would be $\frac{1}{8} + \frac{1}{8} + \frac{1}{8} = \frac{3}{8}$. What am I doing wrong, what am I doing correct? Or can I improve something?","I have the following problem. You apply for jobs and know that if you send your application then every job appointment procedure has two stages: You can be either invited or not invited to a personal interview and then You can either be selected or not selected for a job. Assuming that you do not have any further information about the process and the selection criteria, please compute the a priori probability to get at least one job offer after sending your application to three different places . My thoughts I started thinking about what events are independent and which ones are dependent. I thought that being able to get a job from place $A$ is an independent event of being able to get a job from place $B$. For this reason, I decided to consider independently the problem what is the probability of getting a job from a place $X$ . Now, the probability of being called to go to the interview (lets call this event $I$) is $\frac{1}{2}$, in other words $P(I) = \frac{1}{2}$, because we can either be called or not. Then, the probability of getting the job (lets call this event $J$) strictly depends on event $I$, because, for example, you cannot get the job, if you don't first go to the interview. What we actually want to know is the probability of being called and getting the job, in other words we want to know $P(I \text{ and } J)$. Since these events are dependent, we can use the rule that $P(A \text{ and } B) = P(A) \cdot P(B | A)$, where $P(B|A)$ is the probability of event $B$ happens given the fact that event $A$ has happened. Applying this rule to my case, I need to find $P(J | I)$, because I already know $P(I) = \frac{1}{2}$. I was thinking that this probability is $\frac{1}{4}$. Why? Basically, from $\frac{1}{2}$ of the possibilities remaining we have half of the chances to get the job, so $\frac{1}{2}$ of $\frac{1}{2}$ is $\frac{1}{4}$. I can now calculate $P(I \text{ and } J)$, which should be $P(I) \cdot P(J | I) = \frac{1}{2} \cdot \frac{1}{4} = \frac{1}{8}$. If my reasonings are correct, this should represent the probability of getting job from one place.  Since I am applying for three different jobs (which are not dependent between each other), then I have more possibilities than $\frac{1}{8}$, so I thought we could sum the possibilities of getting a job for each individual place, thus my answer would be $\frac{1}{8} + \frac{1}{8} + \frac{1}{8} = \frac{3}{8}$. What am I doing wrong, what am I doing correct? Or can I improve something?",,['probability']
92,Why weak law of large number still alive?,Why weak law of large number still alive?,,"I know the difference between WLLN and SLLN in terms of a convergence type. Then, as revealed in any statistical textbook saying sufficient conditions to two theorems are the same, I think that we do not need WLLN anymore. I also know that there is some example for which WLLN holds but SLLN not. Then, From this examples we would have needed to establish another conditions only needed for SLLN, still I could not find any explanations for this. Is there anyone to explain difference between WLLN and SLLN in terms of this issue? Thanks!","I know the difference between WLLN and SLLN in terms of a convergence type. Then, as revealed in any statistical textbook saying sufficient conditions to two theorems are the same, I think that we do not need WLLN anymore. I also know that there is some example for which WLLN holds but SLLN not. Then, From this examples we would have needed to establish another conditions only needed for SLLN, still I could not find any explanations for this. Is there anyone to explain difference between WLLN and SLLN in terms of this issue? Thanks!",,"['probability', 'law-of-large-numbers']"
93,Calculating probabilities in horse racing!,Calculating probabilities in horse racing!,,"I've seen a few similar threads to this on different forums but they don't seem to conclude to a satisfactory answer. My question is this: If you have 3 horses, A, B, and C and you know the winning probabilities of each horse racing against each other as a pair, how do you work out their winning probabilities if all 3 horses race together? Is there a formula for n number of horses? So you know the probabilities of: A beating B A beating C BA BC CA CB I initially thought that: p(A winning) = p(A beat B). p(A beat C) But this is clearly wrong. Can someone please help!! Many thanks Matt","I've seen a few similar threads to this on different forums but they don't seem to conclude to a satisfactory answer. My question is this: If you have 3 horses, A, B, and C and you know the winning probabilities of each horse racing against each other as a pair, how do you work out their winning probabilities if all 3 horses race together? Is there a formula for n number of horses? So you know the probabilities of: A beating B A beating C BA BC CA CB I initially thought that: p(A winning) = p(A beat B). p(A beat C) But this is clearly wrong. Can someone please help!! Many thanks Matt",,"['probability', 'puzzle']"
94,Binomial random variable with number of trials being a Poisson random variable,Binomial random variable with number of trials being a Poisson random variable,,Let $Y$ be the number of heads in a an $X$ toss sequence of flipping a coin with probability $p$ of heads. Show that $Y \sim \mathrm{Pois}(p \lambda)$ if $X \sim \mathrm{Pois}(\lambda)$.,Let $Y$ be the number of heads in a an $X$ toss sequence of flipping a coin with probability $p$ of heads. Show that $Y \sim \mathrm{Pois}(p \lambda)$ if $X \sim \mathrm{Pois}(\lambda)$.,,['probability']
95,Poisson distribution with exponential parameter,Poisson distribution with exponential parameter,,"I don't know how to solve Exercise 8, Section 5.2 from Geoffrey G. Grimmett, David R. Stirzaker, Probability and Random Processes , Oxford University Press 2001. For those who don't have this book: Let $X$ have a Poisson distribution with parameter $\Lambda$, where $\Lambda$ is exponential with parameter $\mu$. Show that $X$ has a geometric distribution. $X \sim Poiss(\Lambda),\ \  \Lambda \sim Exp(\mu)$. So we know that generating function of $X$ is $G_x(s) = \sum_{i=0} s^i \frac{\Lambda^i}{i!} e^{-\Lambda}= e^{\Lambda(s-1)}$. Probability density function of $\Lambda$ is $f_{\Lambda} = \mu e^{-\mu x}$. And I don't know what I should do next. How to decompose $\Lambda$ in $G_x$ (or maybe this is not a good idea?). Thanks in advance for your help.","I don't know how to solve Exercise 8, Section 5.2 from Geoffrey G. Grimmett, David R. Stirzaker, Probability and Random Processes , Oxford University Press 2001. For those who don't have this book: Let $X$ have a Poisson distribution with parameter $\Lambda$, where $\Lambda$ is exponential with parameter $\mu$. Show that $X$ has a geometric distribution. $X \sim Poiss(\Lambda),\ \  \Lambda \sim Exp(\mu)$. So we know that generating function of $X$ is $G_x(s) = \sum_{i=0} s^i \frac{\Lambda^i}{i!} e^{-\Lambda}= e^{\Lambda(s-1)}$. Probability density function of $\Lambda$ is $f_{\Lambda} = \mu e^{-\mu x}$. And I don't know what I should do next. How to decompose $\Lambda$ in $G_x$ (or maybe this is not a good idea?). Thanks in advance for your help.",,"['probability', 'probability-distributions', 'generating-functions']"
96,Correlated Poisson Distribution,Correlated Poisson Distribution,,"$X_1$ and $X_2$ are discrete stochastic variables. They can both be modeled by a Poisson process with arrival rates $\lambda_1$ and $\lambda_2$ respectively. $X_1$ and $X_2$ have a constant correlation $\rho$. Is there an analytic equation that describes the probability density function: $P(X_1= i,X_2= k)$","$X_1$ and $X_2$ are discrete stochastic variables. They can both be modeled by a Poisson process with arrival rates $\lambda_1$ and $\lambda_2$ respectively. $X_1$ and $X_2$ have a constant correlation $\rho$. Is there an analytic equation that describes the probability density function: $P(X_1= i,X_2= k)$",,"['probability', 'statistics', 'probability-distributions']"
97,How can I (algorithmically) count the number of ways n m-sided dice can add up to a given number?,How can I (algorithmically) count the number of ways n m-sided dice can add up to a given number?,,"I am trying to identify the general case algorithm for counting the different ways dice can add to a given number.  For instance, there are six ways to roll a seven with two 6-dice. I've spent quite a bit of time working on this (for a while my friend and I were using Figurate numbers, as the early items in the series match up) but at this point I'm tired and stumped, and would love some assistance. So far we've got something to this effect (apologies for the feeble attempt at mathematical notation - I usually reside on StackOverflow): count(x):    x = min(x,n*m-x+n)    if x = n       1    else       some sort of (recursive?) operation The first line simplifies the problem to just the lower numbers - where the count is increasing.  Then, if we're looking for the count of the minimum possible (which is also now the max because of the previous line) there is only one way to do that so it is 1, no matter the n or m.","I am trying to identify the general case algorithm for counting the different ways dice can add to a given number.  For instance, there are six ways to roll a seven with two 6-dice. I've spent quite a bit of time working on this (for a while my friend and I were using Figurate numbers, as the early items in the series match up) but at this point I'm tired and stumped, and would love some assistance. So far we've got something to this effect (apologies for the feeble attempt at mathematical notation - I usually reside on StackOverflow): count(x):    x = min(x,n*m-x+n)    if x = n       1    else       some sort of (recursive?) operation The first line simplifies the problem to just the lower numbers - where the count is increasing.  Then, if we're looking for the count of the minimum possible (which is also now the max because of the previous line) there is only one way to do that so it is 1, no matter the n or m.",,"['probability', 'combinatorics', 'algorithms', 'dice']"
98,Expected number of random diagonals before intersection,Expected number of random diagonals before intersection,,"Background Motivation: There are various questions asked about randomly drawn chords and their number of intersections in a circle; for example, MSE 73033 and MO 284124 . I am interested here as to a discretized version where the circle is replaced by an $n$ -gon and, if all goes well, then one can consider what happens as $n \rightarrow \infty$ . (I originally asked this question on twitter, and, although there are some proposed small case computations, I cannot vouch for their correctness. See the thread here .) Question: Consider an $n$ -gon ( $n \geq 4$ ) and a list of all non-adjacent vertex pairs. Pick an unchosen pair from the list at random and connect the vertices. If you continue this process without replacement, then what is the expected number of diagonals drawn before two intersect in the interior of the $n$ -gon? (I am, in particular, looking for a formula that is a function of $n$ .) Note 1: If there is an alternative formulation of the problem with a different method of choosing the diagonals ""at random"" that yields a different result, then I would welcome such answers in that direction, too. Note 2: If this result is already known, then a pointer to its answer would be appreciated! I did not locate an answer in my exploration of MSE, but it seems a natural enough question for me to have missed it here (or elsewhere).","Background Motivation: There are various questions asked about randomly drawn chords and their number of intersections in a circle; for example, MSE 73033 and MO 284124 . I am interested here as to a discretized version where the circle is replaced by an -gon and, if all goes well, then one can consider what happens as . (I originally asked this question on twitter, and, although there are some proposed small case computations, I cannot vouch for their correctness. See the thread here .) Question: Consider an -gon ( ) and a list of all non-adjacent vertex pairs. Pick an unchosen pair from the list at random and connect the vertices. If you continue this process without replacement, then what is the expected number of diagonals drawn before two intersect in the interior of the -gon? (I am, in particular, looking for a formula that is a function of .) Note 1: If there is an alternative formulation of the problem with a different method of choosing the diagonals ""at random"" that yields a different result, then I would welcome such answers in that direction, too. Note 2: If this result is already known, then a pointer to its answer would be appreciated! I did not locate an answer in my exploration of MSE, but it seems a natural enough question for me to have missed it here (or elsewhere).",n n \rightarrow \infty n n \geq 4 n n,"['probability', 'geometry', 'reference-request', 'recreational-mathematics', 'problem-solving']"
99,Probability - A Conceptual Doubt,Probability - A Conceptual Doubt,,"Why, when calculating the conditional probability of A given B, do we assume that the probability of B is greater than zero?","Why, when calculating the conditional probability of A given B, do we assume that the probability of B is greater than zero?",,"['probability', 'combinatorics']"
