,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Conditional expectation maximum of sample,Conditional expectation maximum of sample,,"Find the conditional expectation $\mathbb{E}\left[\left.X_{1}\right|Y\right]$  if $X_1,..., X_n\sim\mathrm{Uniform}\left(0,1\right)$, where $Y=\max\left\{ X_{1},...,X_{n}\right\}$. MY ATTEMPT: We have $\mathbb{E}\left[\left.X_{1}\right|Y\right]=\dfrac{1}{n}\cdot\mathbb{E}\left[\left.X_{1}\right|\left(X_{1}=Y\right)\cap Y\right]+\dfrac{n-1}{n}\cdot\mathbb{E}\left[\left.X_{1}\right|\left(X_{1}<Y\right)\cap Y\right]$. If $X_{1}=Y$, then $\mathrm{\mathbb{E}}\left[\left.X_{1}\right|\left(X_{1}=Y\right)\cap Y\right]=Y$. If $X_{1}<Y$, then $X_{1}\sim\textrm{Uniform}\left[0,\mathbb{E}\left(Y\right)\right]$, therefore $\mathbb{E}\left[\left(\left.X_{1}\right|X_{1}<Y\right)\cap Y\right]=\dfrac{\mathbb{E}\left[Y\right]}{2}$. Therefore $\mathbb{E}\left[\left.X_{1}\right|Y\right]=\dfrac{1}{n}\cdot Y+\dfrac{n-1}{n}\cdot\dfrac{\mathbb{E}\left[Y\right]}{2}$. On the other hand, we have that $f_{Y}(y)=n\cdot\left[F_{X}(y)\right]^{n-1}\cdot f_{X}(y)=\left\{ \begin{array}{cc} ny^{n-1} & \textrm{if }0\leq y\leq1\\ 0 & \textrm{otherwise} \end{array}\right.$ is the density function of $Y$. Therefore, $\mathbb{E}\left[Y\right]=\int_{0}^{1}y\cdot f_{Y}(y)dy=\int_{0}^{1}y\cdot ny^{n-1}dy=\dfrac{n}{n+1}$. Thus, $\mathbb{E}\left[\left.X_{1}\right|Y\right]=\dfrac{1}{n}\cdot Y+\dfrac{n-1}{n}\cdot\dfrac{1}{2}\cdot\dfrac{n}{n+1}=\dfrac{1}{n}\cdot Y+\dfrac{1}{2}\cdot\dfrac{n-1}{n+1}$. It's ok?","Find the conditional expectation $\mathbb{E}\left[\left.X_{1}\right|Y\right]$  if $X_1,..., X_n\sim\mathrm{Uniform}\left(0,1\right)$, where $Y=\max\left\{ X_{1},...,X_{n}\right\}$. MY ATTEMPT: We have $\mathbb{E}\left[\left.X_{1}\right|Y\right]=\dfrac{1}{n}\cdot\mathbb{E}\left[\left.X_{1}\right|\left(X_{1}=Y\right)\cap Y\right]+\dfrac{n-1}{n}\cdot\mathbb{E}\left[\left.X_{1}\right|\left(X_{1}<Y\right)\cap Y\right]$. If $X_{1}=Y$, then $\mathrm{\mathbb{E}}\left[\left.X_{1}\right|\left(X_{1}=Y\right)\cap Y\right]=Y$. If $X_{1}<Y$, then $X_{1}\sim\textrm{Uniform}\left[0,\mathbb{E}\left(Y\right)\right]$, therefore $\mathbb{E}\left[\left(\left.X_{1}\right|X_{1}<Y\right)\cap Y\right]=\dfrac{\mathbb{E}\left[Y\right]}{2}$. Therefore $\mathbb{E}\left[\left.X_{1}\right|Y\right]=\dfrac{1}{n}\cdot Y+\dfrac{n-1}{n}\cdot\dfrac{\mathbb{E}\left[Y\right]}{2}$. On the other hand, we have that $f_{Y}(y)=n\cdot\left[F_{X}(y)\right]^{n-1}\cdot f_{X}(y)=\left\{ \begin{array}{cc} ny^{n-1} & \textrm{if }0\leq y\leq1\\ 0 & \textrm{otherwise} \end{array}\right.$ is the density function of $Y$. Therefore, $\mathbb{E}\left[Y\right]=\int_{0}^{1}y\cdot f_{Y}(y)dy=\int_{0}^{1}y\cdot ny^{n-1}dy=\dfrac{n}{n+1}$. Thus, $\mathbb{E}\left[\left.X_{1}\right|Y\right]=\dfrac{1}{n}\cdot Y+\dfrac{n-1}{n}\cdot\dfrac{1}{2}\cdot\dfrac{n}{n+1}=\dfrac{1}{n}\cdot Y+\dfrac{1}{2}\cdot\dfrac{n-1}{n+1}$. It's ok?",,"['probability', 'probability-distributions', 'conditional-expectation']"
1,Deductible and Policy limit [closed],Deductible and Policy limit [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I'm trying to figure out the solution to the following problem. I was working with the Adapt program for the p exam but I can't find the solution anywhere. Problem: Consider an insurance policy that reimburses collision damages for an insured individual. The probability that an individual has a collision is 80%. Given an individual has a collision, the resulting damage is denoted by X. X has the following pdf: f(x)=\begin{cases}     1/100, & \text{if $100<x<200$}.\\     0, & \text{otherwise}.   \end{cases} The policy has a deductible of 20 and a policy limit of 150. Calculate the median insurance disbursement. Attempt: $\Large .8*\int_{20}^{170}(x-2)*\frac{1}{100}dx + 150*S_x(170)$ (where $S_x$ represents the survival function) = $\large 184.5 * .8$ = 147.6","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I'm trying to figure out the solution to the following problem. I was working with the Adapt program for the p exam but I can't find the solution anywhere. Problem: Consider an insurance policy that reimburses collision damages for an insured individual. The probability that an individual has a collision is 80%. Given an individual has a collision, the resulting damage is denoted by X. X has the following pdf: f(x)=\begin{cases}     1/100, & \text{if $100<x<200$}.\\     0, & \text{otherwise}.   \end{cases} The policy has a deductible of 20 and a policy limit of 150. Calculate the median insurance disbursement. Attempt: $\Large .8*\int_{20}^{170}(x-2)*\frac{1}{100}dx + 150*S_x(170)$ (where $S_x$ represents the survival function) = $\large 184.5 * .8$ = 147.6",,"['calculus', 'probability', 'statistics', 'actuarial-science']"
2,Counterexample for r.v does not converge in distribution,Counterexample for r.v does not converge in distribution,,"Give an example where there exist $C>0, q>2$ such that $\mathbf{E}|X-\mathbb{E}X_k|^{q}\leq C\text{Var}(X_k)^{q/2}$ for all $k$ and $\sigma_n\rightarrow\infty$, yet $(S_n-\mathbb{E}S_n)/\sigma_n$ doesn't converge in distribution. Note: $S_n=X_1+...+X_n$ where $X_i$ are r.v, $\sigma_n^2=VarS_n<\infty$ I have been thinking about this for a while anyone have a good and easy example?","Give an example where there exist $C>0, q>2$ such that $\mathbf{E}|X-\mathbb{E}X_k|^{q}\leq C\text{Var}(X_k)^{q/2}$ for all $k$ and $\sigma_n\rightarrow\infty$, yet $(S_n-\mathbb{E}S_n)/\sigma_n$ doesn't converge in distribution. Note: $S_n=X_1+...+X_n$ where $X_i$ are r.v, $\sigma_n^2=VarS_n<\infty$ I have been thinking about this for a while anyone have a good and easy example?",,['probability']
3,Cardinality of the intersection of two random sets,Cardinality of the intersection of two random sets,,"Informal description and motivation I am comparing the output of two search engines. Each engine is searching over the same set of 2,000 documents and returning the top 20 hits. I'm trying to construct a hypothesis test where $H_0$ is the hypothesis that the search results are being randomly generated by both engines (i.e., that the results of one search engine are independent of the results of the other search engine). My first strategy is to answer the question: If I select 20 numbers at random (and without replacement) from the integers 1 to 2,000 to form one hitlist, and repeat to form another hitlist of 20, how likely is it that they these two lists will share $0 \leq X\leq 20$ hits in common? More formal, and general, description Let $S_X:=\{1,2,...,N\},S_Y:=\{1,2,...,M\}$. Let $X_k\subset S_X:|X_k|=k\leq N$ and $Y_j\subset S_Y:|Y_j|=j \leq M$ Finally, let $P(x\in X_1)=\frac{1}{N}\; \forall x \in S_X, \textrm{and}\; P(y \in Y_1)=\frac{1}{M}\;\forall y \in S_Y$, and, more generally: $$P(x\in X_{k+1}|x \notin X_k) = \frac{1}{N-k} \; \forall x \notin X_k$$ and $$P(y\in Y_{k+1}|x \notin Y_k) = \frac{1}{M-k} \; \forall y \notin Y_k$$ Question Given $0\leq k \leq N$, $0 \leq j \leq M$, and $ 0 \leq c \leq \min \{k,j\}$, find $P(|X_k\cap Y_j|\leq c)$","Informal description and motivation I am comparing the output of two search engines. Each engine is searching over the same set of 2,000 documents and returning the top 20 hits. I'm trying to construct a hypothesis test where $H_0$ is the hypothesis that the search results are being randomly generated by both engines (i.e., that the results of one search engine are independent of the results of the other search engine). My first strategy is to answer the question: If I select 20 numbers at random (and without replacement) from the integers 1 to 2,000 to form one hitlist, and repeat to form another hitlist of 20, how likely is it that they these two lists will share $0 \leq X\leq 20$ hits in common? More formal, and general, description Let $S_X:=\{1,2,...,N\},S_Y:=\{1,2,...,M\}$. Let $X_k\subset S_X:|X_k|=k\leq N$ and $Y_j\subset S_Y:|Y_j|=j \leq M$ Finally, let $P(x\in X_1)=\frac{1}{N}\; \forall x \in S_X, \textrm{and}\; P(y \in Y_1)=\frac{1}{M}\;\forall y \in S_Y$, and, more generally: $$P(x\in X_{k+1}|x \notin X_k) = \frac{1}{N-k} \; \forall x \notin X_k$$ and $$P(y\in Y_{k+1}|x \notin Y_k) = \frac{1}{M-k} \; \forall y \notin Y_k$$ Question Given $0\leq k \leq N$, $0 \leq j \leq M$, and $ 0 \leq c \leq \min \{k,j\}$, find $P(|X_k\cap Y_j|\leq c)$",,[]
4,NBA Draft Pick for Worst Team Probability,NBA Draft Pick for Worst Team Probability,,"This is actually a question from ""A First Course in Probability"" by Sheldon Ross, and I have the solution, but am unclear as to why the solution is the case. Would anyone please clarify? The question is as follows: 11 teams are entered into the NBA draft lottery. A total of 66 balls   are placed in an urn, with the worst team having 11 balls placed, the   second worst team having 10 balls placed, etc (with 1 ball having the   name of the team with the eleventh worst record). A ball is chosen at   random and the team whose name is on the ball is given the first pick   in the draft. Another ball is chosen, and if that ball is different   from the first pick team, that team becomes the second pick team. If   the ball is the same, the ball is discarded and the drawing continues.   This goes on for the first three draft pick teams. After the first three draft pick teams are chosen, the rest of the   teams that did not win the lottery invert their win-loss records and   that order is awarded for draft picks 4 through 11. For example, if   the team with the worst record didn't receive any of the 3 lottery   picks, it becomes the 4th pick. Let X denote the draft pick of the team with the worst record. Find   the probability mass function of X. For P(X = 1), the answer is simply $\frac{11}{16}$. However, for $P(X = 2)$, the solution in the book is $$\sum\limits_{j=2}^{11} \bigl( \frac{12-j}{66} \bigr)\bigl( \frac{11}{54+j} \bigr)$$. This solution doesn't make sense to me, because it doesn't account for the repeated drawing of the same first draft pick team. For example, if the team with 10 balls gets the first draft pick, the second draft pick team would be decided from another draw. If the first pick team is drawn again, that ball is discarded and the process is repeated. So shouldn't the solution account for when, for example, the first draft pick is the second worst team, the second and up to tenth draws are still the second worst team, and the 11th draw (still choosing the 2nd draft pick) is the worst team? Sorry for the long post. I didn't know how else to summarize this. Thank you so much for your help!","This is actually a question from ""A First Course in Probability"" by Sheldon Ross, and I have the solution, but am unclear as to why the solution is the case. Would anyone please clarify? The question is as follows: 11 teams are entered into the NBA draft lottery. A total of 66 balls   are placed in an urn, with the worst team having 11 balls placed, the   second worst team having 10 balls placed, etc (with 1 ball having the   name of the team with the eleventh worst record). A ball is chosen at   random and the team whose name is on the ball is given the first pick   in the draft. Another ball is chosen, and if that ball is different   from the first pick team, that team becomes the second pick team. If   the ball is the same, the ball is discarded and the drawing continues.   This goes on for the first three draft pick teams. After the first three draft pick teams are chosen, the rest of the   teams that did not win the lottery invert their win-loss records and   that order is awarded for draft picks 4 through 11. For example, if   the team with the worst record didn't receive any of the 3 lottery   picks, it becomes the 4th pick. Let X denote the draft pick of the team with the worst record. Find   the probability mass function of X. For P(X = 1), the answer is simply $\frac{11}{16}$. However, for $P(X = 2)$, the solution in the book is $$\sum\limits_{j=2}^{11} \bigl( \frac{12-j}{66} \bigr)\bigl( \frac{11}{54+j} \bigr)$$. This solution doesn't make sense to me, because it doesn't account for the repeated drawing of the same first draft pick team. For example, if the team with 10 balls gets the first draft pick, the second draft pick team would be decided from another draw. If the first pick team is drawn again, that ball is discarded and the process is repeated. So shouldn't the solution account for when, for example, the first draft pick is the second worst team, the second and up to tenth draws are still the second worst team, and the 11th draw (still choosing the 2nd draft pick) is the worst team? Sorry for the long post. I didn't know how else to summarize this. Thank you so much for your help!",,"['probability', 'combinatorics', 'order-statistics']"
5,Expected win in a selection game,Expected win in a selection game,,"You've got a game where you have two 5x4 boards. In each board there are 20 hidden prizes from 1 to 20 (each board has all 20 prizes). You have 8 moves. In each move you choose a board and a unrevealed cell in that board. Then you get the prize that was hidden there and a cell in the other board is revealed, showing a prize that you'll be no longer able to get in that board. That way, there's always the same number of revealed cells in each board. Obviously the best strategy is to always pick a cell in the board where the lowest sum of prizes had been revealed. My question, though, is: What's the expected win in this game? I tried to think about creating a random variable $X_n$ that gives the win in a board after $n$ selections if you choose that board. And $Y_n$ the variable that gives the win following this strategy. Then I'd say something like $E[Y_n]=\max(X_n,X'_n)$","You've got a game where you have two 5x4 boards. In each board there are 20 hidden prizes from 1 to 20 (each board has all 20 prizes). You have 8 moves. In each move you choose a board and a unrevealed cell in that board. Then you get the prize that was hidden there and a cell in the other board is revealed, showing a prize that you'll be no longer able to get in that board. That way, there's always the same number of revealed cells in each board. Obviously the best strategy is to always pick a cell in the board where the lowest sum of prizes had been revealed. My question, though, is: What's the expected win in this game? I tried to think about creating a random variable $X_n$ that gives the win in a board after $n$ selections if you choose that board. And $Y_n$ the variable that gives the win following this strategy. Then I'd say something like $E[Y_n]=\max(X_n,X'_n)$",,"['probability', 'expectation']"
6,Probability that after n trials the sum of values would be more than x.,Probability that after n trials the sum of values would be more than x.,,"Suppose we have a bag with cards, each card has a number $2$,$3$ or $4$ on it, so sample space is $\{2, 3, 4\}$. Each sample point is equally likely (so $1/3$). We than pick $n$ cards from the bag. What is the probability that sum of numbers on the cards will be more than $x$? Also the overall number of cards in the bag is infinite or so high it is negligible (I suppose it doesn't matter at all in this question). I want to find general formula, but at least solve some example would be good also, I'm kinda stuck. So suppose we pick $12$ cards and need to find what is the probability that we will get more than $40$ if we sum all the numbers on them. $$n=12, p=1/3, P[X\geq40]=?$$ It looks kinda like Binomial distribution, but here $X$ does not mean ""number of successes obtained in $n$ trials"". In fact, I don't think we have any kind of ""success"" here. What should I use in this case?","Suppose we have a bag with cards, each card has a number $2$,$3$ or $4$ on it, so sample space is $\{2, 3, 4\}$. Each sample point is equally likely (so $1/3$). We than pick $n$ cards from the bag. What is the probability that sum of numbers on the cards will be more than $x$? Also the overall number of cards in the bag is infinite or so high it is negligible (I suppose it doesn't matter at all in this question). I want to find general formula, but at least solve some example would be good also, I'm kinda stuck. So suppose we pick $12$ cards and need to find what is the probability that we will get more than $40$ if we sum all the numbers on them. $$n=12, p=1/3, P[X\geq40]=?$$ It looks kinda like Binomial distribution, but here $X$ does not mean ""number of successes obtained in $n$ trials"". In fact, I don't think we have any kind of ""success"" here. What should I use in this case?",,"['probability', 'probability-theory', 'statistics', 'discrete-mathematics', 'probability-distributions']"
7,Exponential Waiting Times for Bus Arrivals,Exponential Waiting Times for Bus Arrivals,,"I thought I understood the Memoryless property for Exponential Distributions but I am unable to get the intuition behind the answer to this question: You are waiting for a bus at a bus station. The buses arrive at the station according to a Poisson process with an average arrival time of 10 mins. If the buses have been running for a long time and you arrive at the bus station at a random time, what is your expected waiting time. On average, how many minutes ago did the last bus leave? Clearly expected waiting time is 10 mins. However, I dont get this part: ""On average, how many minutes ago did the last bus leave"". The explanation in the book is that if you look back in time, the memoryless property implies on average the last bus arrived 10 mins ago as well. I'm basically struggling to see how the memoryless property implies this above statement. Thanks","I thought I understood the Memoryless property for Exponential Distributions but I am unable to get the intuition behind the answer to this question: You are waiting for a bus at a bus station. The buses arrive at the station according to a Poisson process with an average arrival time of 10 mins. If the buses have been running for a long time and you arrive at the bus station at a random time, what is your expected waiting time. On average, how many minutes ago did the last bus leave? Clearly expected waiting time is 10 mins. However, I dont get this part: ""On average, how many minutes ago did the last bus leave"". The explanation in the book is that if you look back in time, the memoryless property implies on average the last bus arrived 10 mins ago as well. I'm basically struggling to see how the memoryless property implies this above statement. Thanks",,"['probability', 'probability-distributions']"
8,"sum of all entries of the inverse matrix of a positive definite, symmetric matrix","sum of all entries of the inverse matrix of a positive definite, symmetric matrix",,"Let $A$ be a positive definite, symmetric $n\times n$ matrix such that each entry $a_{i,j}$ of $A$ is a number in $[0,1]$ and $\text{diag}[A]=(1,1,\cdots,1)$. Does the sum of all entries of $A^{-1}$ have a finite bound? That is, $$ \text{sup}_{A}\sum_{1\leq i,j\leq n}\text{entry}_{i,j}[A^{-1}]<\infty? $$ What is the exact value of the supremum?","Let $A$ be a positive definite, symmetric $n\times n$ matrix such that each entry $a_{i,j}$ of $A$ is a number in $[0,1]$ and $\text{diag}[A]=(1,1,\cdots,1)$. Does the sum of all entries of $A^{-1}$ have a finite bound? That is, $$ \text{sup}_{A}\sum_{1\leq i,j\leq n}\text{entry}_{i,j}[A^{-1}]<\infty? $$ What is the exact value of the supremum?",,"['linear-algebra', 'probability', 'matrices', 'statistics', 'matrix-calculus']"
9,A complicated problem on probabilistic conditioning,A complicated problem on probabilistic conditioning,,"The real random variables $X$ and $Y$ are independent and both have a Poisson distribution with the parameter 1, i.e. Po(1). Find: $$\mathbb{E}\left[ \left( 2^{2X}+2^{Y} \right)^2|X+Y \right]$$ Answer: $$\left(\frac{9}{2}\right)^{X+Y} +2\cdot 3^{X+Y}+\left(\frac{5}{2} \right)^{X+Y}$$ My steps: $$\left( 2^{2X}+2^{Y} \right)^2=2^{4X}+2^{2Y}+2\cdot 2^{2X+Y}=2^{4X}+2^{2Y}+2^{X+1}2^{X+Y}$$ Hence we have $$\mathbb{E}\left[ \left( 2^{2X}+2^{Y} \right)^2|X+Y \right]=2^{X+Y}\mathbb{E}\left[ 2^{X+1}|X+Y\right]+\mathbb{E}\left[ 2^{4X}|X+Y\right]+\mathbb{E}\left[ 2^{2Y}|X+Y\right]$$ So, if we know how to calculate $\mathbb{E}\left[ 2^{cX+d}|X+Y\right]$ for $c,d\in \mathbb{R}$, we'll get the answer, but I don't know how to do it. Please help.","The real random variables $X$ and $Y$ are independent and both have a Poisson distribution with the parameter 1, i.e. Po(1). Find: $$\mathbb{E}\left[ \left( 2^{2X}+2^{Y} \right)^2|X+Y \right]$$ Answer: $$\left(\frac{9}{2}\right)^{X+Y} +2\cdot 3^{X+Y}+\left(\frac{5}{2} \right)^{X+Y}$$ My steps: $$\left( 2^{2X}+2^{Y} \right)^2=2^{4X}+2^{2Y}+2\cdot 2^{2X+Y}=2^{4X}+2^{2Y}+2^{X+1}2^{X+Y}$$ Hence we have $$\mathbb{E}\left[ \left( 2^{2X}+2^{Y} \right)^2|X+Y \right]=2^{X+Y}\mathbb{E}\left[ 2^{X+1}|X+Y\right]+\mathbb{E}\left[ 2^{4X}|X+Y\right]+\mathbb{E}\left[ 2^{2Y}|X+Y\right]$$ So, if we know how to calculate $\mathbb{E}\left[ 2^{cX+d}|X+Y\right]$ for $c,d\in \mathbb{R}$, we'll get the answer, but I don't know how to do it. Please help.",,['probability']
10,A colored ball problem,A colored ball problem,,"Say you have $2n+2b$ balls where $2n$ balls are colored white, $b$ balls are colored blue and $b$ balls are colored red. You have two urns. You randomly choose $n+b$ balls and throw in urn $1$ while you place the remaining $n+b$ balls in urn $2$. What is the probability that the blue balls and red balls are in separate urns? I am most interested in case $\frac{n}b\rightarrow\infty$ such as $b=n^{\frac1c}$ with $c>1$ being fixed and in case $\frac{n}b\rightarrow c$ such as $b={\frac nc}$ with $c>1$.","Say you have $2n+2b$ balls where $2n$ balls are colored white, $b$ balls are colored blue and $b$ balls are colored red. You have two urns. You randomly choose $n+b$ balls and throw in urn $1$ while you place the remaining $n+b$ balls in urn $2$. What is the probability that the blue balls and red balls are in separate urns? I am most interested in case $\frac{n}b\rightarrow\infty$ such as $b=n^{\frac1c}$ with $c>1$ being fixed and in case $\frac{n}b\rightarrow c$ such as $b={\frac nc}$ with $c>1$.",,[]
11,Which answer is correct for this product rule based probability problem,Which answer is correct for this product rule based probability problem,,"The question reads like this: A bag contains 5 black and 3 red balls. A ball is taken out of the bag and is not returned to it. If this process is repeated three times, then what is the probability of drawing a black ball in the next draw? Solution 1 I think the three balls can be drawn in 4 ways All the three balls are black = 5/8 .4/7 .3/6 then the probability of next black ball can be drawn is 2/5. 2 black and 1 red = 5/8 . 4/7 . 3/6 then the probability of next black ball can be drawn is 3/5. 1 black and 2 red = 5/8 . 3/7 . 2/6 then the probability of next black ball can be drawn is 4/5. All red = 3/8 . 2/7 . 1/6 then the probability of next black ball can be drawn is 1. And probability of each way is 1/4. Hence desired probability $=\frac{1}{4}\times\frac{2}{5}+\frac{1}{4}\times\frac{3}{5}+\frac{1}{4}\times\frac{4}{5}+\frac{1}{4}\times1=\frac{7}{10} = 0.7$ Solution 2 Probability of 4th ball being black when All first first 3 draws are black balls $=\frac{5}{8}\times\frac{4}{7}\times\frac{3}{6}\times\frac{2}{5}=\frac{120}{1680}$ First three draws contain all red balls $=\frac{3}{8}\times\frac{2}{7}\times\frac{1}{6}\times\frac{5}{5}=\frac{30}{1680}$ First three draws contain 2 red and 1 black ball $=\frac{3}{8}\times\frac{2}{7}\times\frac{5}{6}\times\frac{4}{5}\times 3=\frac{360}{1680}$ First three draws contain 1 red and 2 black ball $=\frac{3}{8}\times\frac{5}{7}\times\frac{4}{6}\times\frac{3}{5}\times 3=\frac{540}{1680}$ Summing all above probabilities gives $=\frac{5}{8}=0.625$ I cant decide which one is correct. I feel the second one is just far more precise. Is it?","The question reads like this: A bag contains 5 black and 3 red balls. A ball is taken out of the bag and is not returned to it. If this process is repeated three times, then what is the probability of drawing a black ball in the next draw? Solution 1 I think the three balls can be drawn in 4 ways All the three balls are black = 5/8 .4/7 .3/6 then the probability of next black ball can be drawn is 2/5. 2 black and 1 red = 5/8 . 4/7 . 3/6 then the probability of next black ball can be drawn is 3/5. 1 black and 2 red = 5/8 . 3/7 . 2/6 then the probability of next black ball can be drawn is 4/5. All red = 3/8 . 2/7 . 1/6 then the probability of next black ball can be drawn is 1. And probability of each way is 1/4. Hence desired probability $=\frac{1}{4}\times\frac{2}{5}+\frac{1}{4}\times\frac{3}{5}+\frac{1}{4}\times\frac{4}{5}+\frac{1}{4}\times1=\frac{7}{10} = 0.7$ Solution 2 Probability of 4th ball being black when All first first 3 draws are black balls $=\frac{5}{8}\times\frac{4}{7}\times\frac{3}{6}\times\frac{2}{5}=\frac{120}{1680}$ First three draws contain all red balls $=\frac{3}{8}\times\frac{2}{7}\times\frac{1}{6}\times\frac{5}{5}=\frac{30}{1680}$ First three draws contain 2 red and 1 black ball $=\frac{3}{8}\times\frac{2}{7}\times\frac{5}{6}\times\frac{4}{5}\times 3=\frac{360}{1680}$ First three draws contain 1 red and 2 black ball $=\frac{3}{8}\times\frac{5}{7}\times\frac{4}{6}\times\frac{3}{5}\times 3=\frac{540}{1680}$ Summing all above probabilities gives $=\frac{5}{8}=0.625$ I cant decide which one is correct. I feel the second one is just far more precise. Is it?",,"['probability', 'combinatorics']"
12,How do i calculate the probability of the relay in the circuits?,How do i calculate the probability of the relay in the circuits?,,"I am trying to solve my following probability question but I can't see how to make any progress. Any help will be highly appreciated Question: The probability of the closing of the $i$-th relay in the circuits shown is given by $p_i$ for $i = 1,2,3,4,5$. If all relays function independently, what is the probability that a current flows between $A$ and $B$ for the respective circuits?","I am trying to solve my following probability question but I can't see how to make any progress. Any help will be highly appreciated Question: The probability of the closing of the $i$-th relay in the circuits shown is given by $p_i$ for $i = 1,2,3,4,5$. If all relays function independently, what is the probability that a current flows between $A$ and $B$ for the respective circuits?",,"['probability', 'probability-distributions']"
13,On the proof of lemma 1.2.4 of Stroock and Varadhan A question concerning stopping times,On the proof of lemma 1.2.4 of Stroock and Varadhan A question concerning stopping times,,"In the book Multidimensional diffusion processes , of Stroock and Varadhan one reads (page 23): This is the proof of $(i)$ . Here the authors say Define $f_t$ on $(\{\tau \leq t\}, \mathcal{F}_t [\{\tau \leq t\}])$ What is the $\sigma$ -algebra $\mathcal{F}_t [\{\tau \leq t\}]$ ? Is it $\{A \cap \{\tau \leq t\}\mid A \in \mathcal{F}_t\}$ ? Why do we consider such a sigma algebra instead of $\mathcal{F}_t$ ? after proving $(ii)$ the authors say (page 24) The proof of $(iii)$ is readily seen by the following reasoning: $$A \in \mathcal{F}_{\sigma}: \quad A \cap \{\tau \leq t\}  =A \cap \{\sigma \leq t\} \cap \{\tau \leq t\}  \in \mathcal{F}_t \Rightarrow A \in\mathcal{F}_{\tau}. $$ But I can't see why this result follows from $(ii)$ Using $(ii)$ the sole thing I arrived at was $$A \in \mathcal{F}_{\sigma}: \quad A =A \cap \{\sigma \leq \tau\}  \in \mathcal{F}_{\tau \wedge \sigma} = \mathcal{F}_{\sigma}, $$ which is not the desired result. What am I missing here?","In the book Multidimensional diffusion processes , of Stroock and Varadhan one reads (page 23): This is the proof of . Here the authors say Define on What is the -algebra ? Is it ? Why do we consider such a sigma algebra instead of ? after proving the authors say (page 24) The proof of is readily seen by the following reasoning: But I can't see why this result follows from Using the sole thing I arrived at was which is not the desired result. What am I missing here?","(i) f_t (\{\tau \leq t\}, \mathcal{F}_t [\{\tau \leq t\}]) \sigma \mathcal{F}_t [\{\tau \leq t\}] \{A \cap \{\tau \leq t\}\mid A \in \mathcal{F}_t\} \mathcal{F}_t (ii) (iii) A \in \mathcal{F}_{\sigma}: \quad A \cap \{\tau \leq t\}  =A \cap \{\sigma \leq t\} \cap \{\tau \leq t\}  \in \mathcal{F}_t \Rightarrow A \in\mathcal{F}_{\tau}.  (ii) (ii) A \in \mathcal{F}_{\sigma}: \quad A =A \cap \{\sigma \leq \tau\}  \in \mathcal{F}_{\tau \wedge \sigma} = \mathcal{F}_{\sigma}, ","['stochastic-processes', 'stopping-times', 'probability']"
14,Why is the measure of a boundary of an open ball positive in only a countable number of cases?,Why is the measure of a boundary of an open ball positive in only a countable number of cases?,,"Let $X$ be a Polish (complete separable metric) space and $\mathbb{P}$ a Borel probability measure on $X$. Let $x_1, x_2, \ldots$ be a sequence of points dense in $X$. How can you prove that there is at most a denumerable number of values $r > 0$ where $\mathbb{P}(\partial B(x_i, r)) > 0$ for all $i \in \mathbb{N}$? (Here $\partial A$ denotes the boundary of the set $A$ and $B(a, b)$ denotes an open ball with center $a$ and radius $b$.) This assertion is taken for granted in Skorohod's paper ""Limit theorems for stochastic processes"" on p. 281. I would be very grateful if you could explain to me why it holds and apologies if it's meant to be obvious. Thank you very much in advance.","Let $X$ be a Polish (complete separable metric) space and $\mathbb{P}$ a Borel probability measure on $X$. Let $x_1, x_2, \ldots$ be a sequence of points dense in $X$. How can you prove that there is at most a denumerable number of values $r > 0$ where $\mathbb{P}(\partial B(x_i, r)) > 0$ for all $i \in \mathbb{N}$? (Here $\partial A$ denotes the boundary of the set $A$ and $B(a, b)$ denotes an open ball with center $a$ and radius $b$.) This assertion is taken for granted in Skorohod's paper ""Limit theorems for stochastic processes"" on p. 281. I would be very grateful if you could explain to me why it holds and apologies if it's meant to be obvious. Thank you very much in advance.",,"['probability', 'general-topology', 'measure-theory']"
15,Uniformly integrability and convergence,Uniformly integrability and convergence,,"Question 1 : $X_n$'s are non-negative, uniformly integrable . Then $E\left[\dfrac{\max_{1\leq k \leq n} X_k}{n}\right]\rightarrow 0$. Question 2 : If u.i. is dropped then the above may fail. My thought : If I can show $\dfrac{\max_{1\leq k \leq n} X_k}{n}$ is u.i. as well as converges in probability to $0$ then I am done. Probably I am not thinking in the right direction. Any kind of help/hint is what I am looking for and will appreciate. Thank you.","Question 1 : $X_n$'s are non-negative, uniformly integrable . Then $E\left[\dfrac{\max_{1\leq k \leq n} X_k}{n}\right]\rightarrow 0$. Question 2 : If u.i. is dropped then the above may fail. My thought : If I can show $\dfrac{\max_{1\leq k \leq n} X_k}{n}$ is u.i. as well as converges in probability to $0$ then I am done. Probably I am not thinking in the right direction. Any kind of help/hint is what I am looking for and will appreciate. Thank you.",,"['probability', 'probability-theory', 'random-variables', 'uniform-integrability']"
16,Solve the following simple congruence,Solve the following simple congruence,,"$$560x \equiv 1 \pmod{429}$$ I am close, I used Euclid's algorithm but the remainder is hard to go backwards. $$560 = 1(429) + 131 $$ $$429 = 3(131) + 36$$ $$131 = 3(36) + 23$$ $$36 = 1(23) + 13$$ $$23 = 1(13) + 10$$ $$13 = 1(10) + 3$$ $$10 = 3(3) + 1$$ Working backwards anyway, $1 = 10 - 3(13 - 1(23 - 1(13)))$ then, $$1 = 10 - 3(13 - 1(23 - 1(36 - 1(131 - 3(429 - 3(560 - 429))))))$$ yikes. What should I do now?","$$560x \equiv 1 \pmod{429}$$ I am close, I used Euclid's algorithm but the remainder is hard to go backwards. $$560 = 1(429) + 131 $$ $$429 = 3(131) + 36$$ $$131 = 3(36) + 23$$ $$36 = 1(23) + 13$$ $$23 = 1(13) + 10$$ $$13 = 1(10) + 3$$ $$10 = 3(3) + 1$$ Working backwards anyway, $1 = 10 - 3(13 - 1(23 - 1(13)))$ then, $$1 = 10 - 3(13 - 1(23 - 1(36 - 1(131 - 3(429 - 3(560 - 429))))))$$ yikes. What should I do now?",,"['probability', 'combinatorics', 'algebra-precalculus', 'elementary-number-theory', 'contest-math']"
17,How long before the prey can escape?,How long before the prey can escape?,,"I've (sort of) come across the following problem in my research. The actual scenario is a little abstract to explain, so I'm rephrasing the problem in terms of a predator/prey scenario. I'm tagging this as a soft question because: I'm not even sure if the problem is analytically tractable, and I'm interested to know what others think about this; I'm not familiar with this kind of mathematics (which I'm assuming has mostly to do with cellular automata and probability?), and so even hints as to which techniques might be useful would be helpful; The formulation is not set in stone, and I'm open to modifications that make the problem more tractable. A prey (red) is being guarded by 8 predators (blue) on a square lattice (left diagram). The predators' discipline slowly wanes away, and they start pacing around. If at any time the prey is not being guarded by at least one predator, it finds itself free to escape by flying away (right diagram). I am interested in the expected time for which the predators are able to keep the prey from escaping. I propose the following rules for the predators' movement: The prey remains stationary. At each time step $k$, each predator randomly chooses 1 out of its 8 neighboring squares to move into (regardless of these squares' occupancy). For each predator whose chosen square has not also been chosen by another predator, and is not the prey's square, the predator moves into its chosen square. Repeat Step 3 until no predator can make a further move. $k \leftarrow k+1$ and go to Step 1 if the prey is not free, or terminate if it is.","I've (sort of) come across the following problem in my research. The actual scenario is a little abstract to explain, so I'm rephrasing the problem in terms of a predator/prey scenario. I'm tagging this as a soft question because: I'm not even sure if the problem is analytically tractable, and I'm interested to know what others think about this; I'm not familiar with this kind of mathematics (which I'm assuming has mostly to do with cellular automata and probability?), and so even hints as to which techniques might be useful would be helpful; The formulation is not set in stone, and I'm open to modifications that make the problem more tractable. A prey (red) is being guarded by 8 predators (blue) on a square lattice (left diagram). The predators' discipline slowly wanes away, and they start pacing around. If at any time the prey is not being guarded by at least one predator, it finds itself free to escape by flying away (right diagram). I am interested in the expected time for which the predators are able to keep the prey from escaping. I propose the following rules for the predators' movement: The prey remains stationary. At each time step $k$, each predator randomly chooses 1 out of its 8 neighboring squares to move into (regardless of these squares' occupancy). For each predator whose chosen square has not also been chosen by another predator, and is not the prey's square, the predator moves into its chosen square. Repeat Step 3 until no predator can make a further move. $k \leftarrow k+1$ and go to Step 1 if the prey is not free, or terminate if it is.",,"['probability', 'probability-distributions', 'soft-question', 'expectation', 'cellular-automata']"
18,What is the probability of an event happening in some interval given probability of it in x interval?,What is the probability of an event happening in some interval given probability of it in x interval?,,"Suppose there is an event that happens with a probability of y in x interval of time, what would be the probability of it happening in x/2 interval of time? Would that be y/2 or is there something more to be considered? To be a bit more specific, why do use exponential probability in this case: The probability of a car passing a certain intersection in a 20 minute windows is 0.9. What is the probability of a car passing the intersection in a 5 minute window? (Assuming a constant probability throughout) The answer is computed using the logic that the  probability of a car not passing in 20 mts = (probability of a car not passing in 5 mts)^4. While that makes logical sense why is it exponentiation and not something as directly as (probability of car passing in 20 mts/4)? I find the latter more intuitive. I believe there is something fundamental that I am missing here. Am I assuming that the probability curve is |_|_|_| where the bar indicates the exact time a car passes by as opposed to ----- where the probability is just uniform i.e no time instance has any significant edge over the other?","Suppose there is an event that happens with a probability of y in x interval of time, what would be the probability of it happening in x/2 interval of time? Would that be y/2 or is there something more to be considered? To be a bit more specific, why do use exponential probability in this case: The probability of a car passing a certain intersection in a 20 minute windows is 0.9. What is the probability of a car passing the intersection in a 5 minute window? (Assuming a constant probability throughout) The answer is computed using the logic that the  probability of a car not passing in 20 mts = (probability of a car not passing in 5 mts)^4. While that makes logical sense why is it exponentiation and not something as directly as (probability of car passing in 20 mts/4)? I find the latter more intuitive. I believe there is something fundamental that I am missing here. Am I assuming that the probability curve is |_|_|_| where the bar indicates the exact time a car passes by as opposed to ----- where the probability is just uniform i.e no time instance has any significant edge over the other?",,['probability']
19,Coin flipping game with stop-loss,Coin flipping game with stop-loss,,"You play 100 rounds of a coin flipping game where you win \$2 for a head and lose \$1 for a tail on each round. Clearly since the coin tosses are independent the expected winnings are \$50. Now, suppose you play at most 100 rounds of this game as before, but this time you stop early if you accumulated \$50 of losses. How does this change the expected winnings? Naively one would think that this ""stop-loss"" reduces the losses leading to higher expected winnings compared to the first game, but this does not take into account scenarios where we subsequently recover from the losses: for example the stop-loss throws away the profitable scenario where we throw 50 tails followed by 50 heads ending with positive winnings of \$50.","You play 100 rounds of a coin flipping game where you win \$2 for a head and lose \$1 for a tail on each round. Clearly since the coin tosses are independent the expected winnings are \$50. Now, suppose you play at most 100 rounds of this game as before, but this time you stop early if you accumulated \$50 of losses. How does this change the expected winnings? Naively one would think that this ""stop-loss"" reduces the losses leading to higher expected winnings compared to the first game, but this does not take into account scenarios where we subsequently recover from the losses: for example the stop-loss throws away the profitable scenario where we throw 50 tails followed by 50 heads ending with positive winnings of \$50.",,['probability']
20,Why doesnt this Combinatoric work two ways?,Why doesnt this Combinatoric work two ways?,,"There are two distinguishable flagpoles, and there are $19$ flags, of which $10$ are identical blue flags, and $9$ are identical green flags. Let $N$ be the number of distinguishable arrangements using all of the flags in which each flagpole has at least one flag and no two green flags on either pole are adjacent. Find the remainder when $N$ is divided by $1000$. Method One: Arrange the blues then divider then greens. $BBBBBBBBBB$ then there are $9$ places for a flag divider $X$. In turn, $BBBBBBBBXBB$ then there are $\binom{12}{3} = 220$ places for pluggin in $G$'s. In total: $220 \cdot 9 = 1980$.  Then you add $2\binom{11}{8} = 2310$. Method Two: Arrange the blues then green then divider. $BBBBBBBBBB$ then there are $\binom{11}{9}$ locations for Green $=G$. Then: $GBGBGBGBGBGBGBGBGBB$. Then there are $18$ places to locate the divider. $\sum = 18(55) = 990$. Which gives the wrong answer?","There are two distinguishable flagpoles, and there are $19$ flags, of which $10$ are identical blue flags, and $9$ are identical green flags. Let $N$ be the number of distinguishable arrangements using all of the flags in which each flagpole has at least one flag and no two green flags on either pole are adjacent. Find the remainder when $N$ is divided by $1000$. Method One: Arrange the blues then divider then greens. $BBBBBBBBBB$ then there are $9$ places for a flag divider $X$. In turn, $BBBBBBBBXBB$ then there are $\binom{12}{3} = 220$ places for pluggin in $G$'s. In total: $220 \cdot 9 = 1980$.  Then you add $2\binom{11}{8} = 2310$. Method Two: Arrange the blues then green then divider. $BBBBBBBBBB$ then there are $\binom{11}{9}$ locations for Green $=G$. Then: $GBGBGBGBGBGBGBGBGBB$. Then there are $18$ places to locate the divider. $\sum = 18(55) = 990$. Which gives the wrong answer?",,"['probability', 'combinatorics', 'algebra-precalculus', 'elementary-number-theory', 'contest-math']"
21,Failure time and exponential distribution,Failure time and exponential distribution,,"One hundred items are simultaneously put on a life test. Suppose the   lifetimes of the individual items are independent exponential random   variables with mean $200$ hours. The test will end when there have   been a total of $5$ failures. If T is the time at which the test ends,   find $E[T]$ and $Var(T)$. I'm stuck in this exercise. If $T$ is the time at which test ends, then $T$ is the time of fifth failure, suppose $T_i$ for $i=1,2,3,4,5$ are the times that the five failures occurred, how I can find the distribution of each $T_i$? In a previous exercise I saw that the failure rate is $$r(t)=\frac{f(t)}{1-F(t)}$$ this means that failure time is a exponential random variable with parameter $r(t)$? EDIT: The answer of @Did in this post rate parameter seems to have a relationship with what I'm asking, the failure time has no distribution?","One hundred items are simultaneously put on a life test. Suppose the   lifetimes of the individual items are independent exponential random   variables with mean $200$ hours. The test will end when there have   been a total of $5$ failures. If T is the time at which the test ends,   find $E[T]$ and $Var(T)$. I'm stuck in this exercise. If $T$ is the time at which test ends, then $T$ is the time of fifth failure, suppose $T_i$ for $i=1,2,3,4,5$ are the times that the five failures occurred, how I can find the distribution of each $T_i$? In a previous exercise I saw that the failure rate is $$r(t)=\frac{f(t)}{1-F(t)}$$ this means that failure time is a exponential random variable with parameter $r(t)$? EDIT: The answer of @Did in this post rate parameter seems to have a relationship with what I'm asking, the failure time has no distribution?",,"['probability', 'stochastic-processes', 'self-learning']"
22,Interesting facts and problems to motivate high school combinatorics students,Interesting facts and problems to motivate high school combinatorics students,,I will give some classes in combinatorics to high school students and I would like to know some facts (and proof) I can show to my students to motivate them to study this beautiful subject. I'm thinking to talk about this: 15 Things More Likely to Happen than Winning Mega Millions . The problem is I don't know how to calculate these facts and I'm looking for interesting real life problems to solve with my students. So my question is do you know some interesting real life problems I could show and proof to my students? Thanks,I will give some classes in combinatorics to high school students and I would like to know some facts (and proof) I can show to my students to motivate them to study this beautiful subject. I'm thinking to talk about this: 15 Things More Likely to Happen than Winning Mega Millions . The problem is I don't know how to calculate these facts and I'm looking for interesting real life problems to solve with my students. So my question is do you know some interesting real life problems I could show and proof to my students? Thanks,,"['probability', 'combinatorics', 'soft-question', 'big-list']"
23,Probability and Expectation People in Line,Probability and Expectation People in Line,,"A group of n people all have distinct heights. They are waiting in a straight line at the bank (one person in front of the other), with all orderings of the people equally likely.  A person can see ahead to the front of the line if they are taller than everyone in front of them. (a) What is the probability that the i th person in line can see to the front of the line (where the first person is at the front of the line, the second person is behind the first, etc.)? (b) What is the expected number of people in line that can see to the front of the line? (Hint: Linearity of expectation.) There are n! ways to arrange those people in line. For the first person to see in line: nC1 , then for the i th person it is going to be nCi ? I am not sure how to approach (b)?  Any hint or advice is helpful!","A group of n people all have distinct heights. They are waiting in a straight line at the bank (one person in front of the other), with all orderings of the people equally likely.  A person can see ahead to the front of the line if they are taller than everyone in front of them. (a) What is the probability that the i th person in line can see to the front of the line (where the first person is at the front of the line, the second person is behind the first, etc.)? (b) What is the expected number of people in line that can see to the front of the line? (Hint: Linearity of expectation.) There are n! ways to arrange those people in line. For the first person to see in line: nC1 , then for the i th person it is going to be nCi ? I am not sure how to approach (b)?  Any hint or advice is helpful!",,['probability']
24,Urn with increasing number of distinct balls,Urn with increasing number of distinct balls,,"Suppose we have an urn that initially has only one labelled ball inside. At each time step, we flip a biased coin with probability $p$ $(\in(0,1))$ of landing on heads and probability $1-p$ of landing on tails. If we get heads, we add a new ball into the urn that has a distinct label from all the other balls. If we get tails, we draw a random ball from the urn, note its label, then put it back. What I would like to know is whether or not, w.p. 1, there will be a ball that will be drawn infinitely often from the urn as we indefinitely continue this experiment. My hunch tells me that such a ball does exist a.s., but I can't seem to prove it. I tried using Borel-Cantelli on the sequence of events in which the initial ball is drawn at time $n$. However, I found the sum of the probabilities of those events to be infinite, so Borel-Cantelli can't help us (the events are neither independent nor monotone increasing). If you have any help to offer me for this problem, I'll very much appreciate it.","Suppose we have an urn that initially has only one labelled ball inside. At each time step, we flip a biased coin with probability $p$ $(\in(0,1))$ of landing on heads and probability $1-p$ of landing on tails. If we get heads, we add a new ball into the urn that has a distinct label from all the other balls. If we get tails, we draw a random ball from the urn, note its label, then put it back. What I would like to know is whether or not, w.p. 1, there will be a ball that will be drawn infinitely often from the urn as we indefinitely continue this experiment. My hunch tells me that such a ball does exist a.s., but I can't seem to prove it. I tried using Borel-Cantelli on the sequence of events in which the initial ball is drawn at time $n$. However, I found the sum of the probabilities of those events to be infinite, so Borel-Cantelli can't help us (the events are neither independent nor monotone increasing). If you have any help to offer me for this problem, I'll very much appreciate it.",,"['probability', 'probability-theory']"
25,Basic Approach To Independence In Probability,Basic Approach To Independence In Probability,,"If we have an event $A$ and a sample space $\Omega$, can we say that the event $A$ is Independent on an event $B$ if the occurrence of $B$ keep the ratio of $\frac{|A|}{|\Omega|}$? For example: looking at a deck of cards, P(heart)=$\frac{13}{52}$ and P(king)=$\frac{4}{52}$ assume we show the card is red. now P(heart|red)=$\frac{13}{52-26}=\frac{13}{26}\neq$ P(heart)=$\frac{13}{52}$ but P(king|red)=$\frac{4-2}{52-26}=\frac{2}{26}=$P(king)=$\frac{4}{52}=\frac{2}{26}$","If we have an event $A$ and a sample space $\Omega$, can we say that the event $A$ is Independent on an event $B$ if the occurrence of $B$ keep the ratio of $\frac{|A|}{|\Omega|}$? For example: looking at a deck of cards, P(heart)=$\frac{13}{52}$ and P(king)=$\frac{4}{52}$ assume we show the card is red. now P(heart|red)=$\frac{13}{52-26}=\frac{13}{26}\neq$ P(heart)=$\frac{13}{52}$ but P(king|red)=$\frac{4-2}{52-26}=\frac{2}{26}=$P(king)=$\frac{4}{52}=\frac{2}{26}$",,['probability']
26,Dice Roll Probabilities,Dice Roll Probabilities,,"I'm trying to figure out the probabilities for the following casino game: You and the dealer each roll a pair of dice and the person with the highest individual die roll wins. If its a tie, you win. First, what is the probability you win? Second, given that you've won, whats the probability that the game resulted in a tie? -- Here are my thoughts: For the first - the expected value of your die roll is 4.25; which means you will win unless the dealer rolls a 5 or 6, giving you a 2/3 chance of winning. For the second I'm not sure how to think about it.","I'm trying to figure out the probabilities for the following casino game: You and the dealer each roll a pair of dice and the person with the highest individual die roll wins. If its a tie, you win. First, what is the probability you win? Second, given that you've won, whats the probability that the game resulted in a tie? -- Here are my thoughts: For the first - the expected value of your die roll is 4.25; which means you will win unless the dealer rolls a 5 or 6, giving you a 2/3 chance of winning. For the second I'm not sure how to think about it.",,['probability']
27,$W(t)=t^2 Z(t)-2\int_0^t sZ(s)ds$. What is $dW(t)$?,. What is ?,W(t)=t^2 Z(t)-2\int_0^t sZ(s)ds dW(t),"This is a sample question for the actuarial exam MFE. Let $Z(t)$ be a standard Brownian motion. Let $W(t)=t^2 Z(t)-2\int_0^t sZ(s)ds$ . What is $dW(t)$ ? The only thing I know is Ito's Lemma. So I computed the following: $\frac{\partial W}{\partial Z}=t^2-\frac{\partial}{\partial Z} \big( 2\int_0^t sZ(s)ds\big).$ $\frac{\partial^2 W}{\partial Z^2}=-\frac{\partial}{\partial Z^2}\big(2\int_0^t sZ(s)ds\big)$ . $\frac{\partial W}{\partial t}=2Z(t)t-\frac{\partial}{\partial t}\big(2\int_0^t sZ(s)ds\big)$ But then I don't know how to deal with the parts with integral? Here's the solution which I don't fully trust (partially because I haven't taken a proof-based class in stochastic calculus). $dW(t)=d[t^2Z(t)]-2tZ(t)dt$ . Because $d[t^2Z(t)]=t^2dZ(t)+2tZ(t)dt$ , we have $dW(t)=t^2dZ(t)$ .","This is a sample question for the actuarial exam MFE. Let be a standard Brownian motion. Let . What is ? The only thing I know is Ito's Lemma. So I computed the following: . But then I don't know how to deal with the parts with integral? Here's the solution which I don't fully trust (partially because I haven't taken a proof-based class in stochastic calculus). . Because , we have .",Z(t) W(t)=t^2 Z(t)-2\int_0^t sZ(s)ds dW(t) \frac{\partial W}{\partial Z}=t^2-\frac{\partial}{\partial Z} \big( 2\int_0^t sZ(s)ds\big). \frac{\partial^2 W}{\partial Z^2}=-\frac{\partial}{\partial Z^2}\big(2\int_0^t sZ(s)ds\big) \frac{\partial W}{\partial t}=2Z(t)t-\frac{\partial}{\partial t}\big(2\int_0^t sZ(s)ds\big) dW(t)=d[t^2Z(t)]-2tZ(t)dt d[t^2Z(t)]=t^2dZ(t)+2tZ(t)dt dW(t)=t^2dZ(t),"['probability', 'probability-theory', 'stochastic-processes']"
28,Polya's random walk and gambler's ruin: interpretation in higher dimensions,Polya's random walk and gambler's ruin: interpretation in higher dimensions,,"I've read that Polya coined the term ""Random Walk."" He analyzed the 1-dimension example and proved that the chances of returning to any point on the line is ultimately 100%. This is how one can think of a gambler's ruin: a person playing a fair random game against a casino will eventually lose all his money. Now, Polya also showed that this scheme breaks down in higher dimensions. For instance, in the 3 dimensional lattice, the player has a lower chance of going back to its starting point (0.34, although I realized in my research that there is no closed form answer for higher dimensions). Question: how can we understand the gambler analogy in the context of Polya's higher dimension examples? Does the case for the 3-dimensional lattice mean that for example somehow playing in 3 casinos with 3 different currencies lowers the risk of ruin? p.s. This is not for gambling. I have never played at a casino, nor intend to... I'm just fascinated with the topic and have researched it as much as I could as a non-mathematician. Thanks for any insights!","I've read that Polya coined the term ""Random Walk."" He analyzed the 1-dimension example and proved that the chances of returning to any point on the line is ultimately 100%. This is how one can think of a gambler's ruin: a person playing a fair random game against a casino will eventually lose all his money. Now, Polya also showed that this scheme breaks down in higher dimensions. For instance, in the 3 dimensional lattice, the player has a lower chance of going back to its starting point (0.34, although I realized in my research that there is no closed form answer for higher dimensions). Question: how can we understand the gambler analogy in the context of Polya's higher dimension examples? Does the case for the 3-dimensional lattice mean that for example somehow playing in 3 casinos with 3 different currencies lowers the risk of ruin? p.s. This is not for gambling. I have never played at a casino, nor intend to... I'm just fascinated with the topic and have researched it as much as I could as a non-mathematician. Thanks for any insights!",,"['probability', 'random-walk']"
29,Show that if $P(0 \leq X \leq c)=1$ then $Var(X) \leq \frac{c^2}{4}$,Show that if  then,P(0 \leq X \leq c)=1 Var(X) \leq \frac{c^2}{4},"I need to show that if $$P(0 \leq X \leq c)=1$$ then $$Var(X) \leq \frac{c^2}{4}$$ I can show that using 2 things: First, that $E[X^2] \leq cE[X]$ and secondly that $Var(X) \leq c^2[\alpha(1-\alpha)]$ for $\alpha=\frac{E[X]}{c}$. Could anyone help me prove these 2 steps? Last step is quite immediate.","I need to show that if $$P(0 \leq X \leq c)=1$$ then $$Var(X) \leq \frac{c^2}{4}$$ I can show that using 2 things: First, that $E[X^2] \leq cE[X]$ and secondly that $Var(X) \leq c^2[\alpha(1-\alpha)]$ for $\alpha=\frac{E[X]}{c}$. Could anyone help me prove these 2 steps? Last step is quite immediate.",,['probability']
30,Filtration of Markov Chains in general state space,Filtration of Markov Chains in general state space,,"I am reading the book Markov Chains and Stochastic Stability from Meyn and Tweedie. They define Markov chains on a measurable state space $(E,\Sigma)$ (Chapter 3.4) and they define it on the space $\Omega = \prod_{i \in \mathbb{N}}E, $ with an $\sigma$-algebra $\mathcal{A}$ which is the smallest $\sigma$-algebra that contains all cylinder sets with only finitly many sets different from $E$ $$A_1 \times A_2 \times \dots A_n \times E \times E \times \dots$$ Then they define the Markov chain as a family of random variables $(X_n)_{n \in \mathbb{N}}$ where for $\omega=(x_n)_{n \in \mathbb{N}}\in \Omega$ they set $$X_n(\omega)=x_n .$$ Thus, all Markov chains are defined on the same set $\Omega$ and the random variables $(X_n)$ are also always the same. Now if they talk about a certain initial distribution $\mu$ and transition kernel $p(x,A)$; then they assoicate a Markov chain to it by constructing a specific measure $\mathbb{P}_\mu$. Thus, by this definition, two Markov chains only differ on the probability measure of the probability space. My problem is that in the book they define the term $$ \mathcal{F}_n = \sigma(X_0,\dots,X_n) \subseteq \mathcal{B}(X^{n+1})$$ and they say which is the smallest $\sigma$-field for which the random variable   $\{X_0,\dots,X_n\}$ is measurable. In many cases $\mathcal{F}_n$ will   coincide with $\mathcal{B}(X^{n+1})$, although this depend in   particular on the initial measure $\mu$ choosen for a particular   chain. How can $\mathcal{F}_n$ depend on the initial measure? The random variable is already defined as $X_n(\omega)=x_n$, and thus the measurability of $\{X_0,\dots,X_n\}$ depends only on $\Sigma$ and $\mathcal{A}$ where does the intial measure $\mu$ comes into play? Update: After seeing the answers, I think it is a good thing to provide my question with an example. Lets consider the case where $E=\{1,2\}$ and $\Omega = E \times E$, then the random variables $X_0$ and $X_1$ are already defined as above, in particular $X_0$ is defined as $$ X_0 ((1,1))=X_0((1,2))=1$$ and $$X_0((2,1))=X_0((2,2))=2.$$  Now if $\mathbb{P}_\mu$ is the probability that $X_0 = 1 $, then we must have $$  \mathbb{P}_\mu[\{(1,1),(1,2)\}]=1.$$ But this is completely independent from  defining $\mathcal{F}_0$ (or $\mathcal{F}_n$). In this case we always have $$\mathcal{F}_0 = \{\{(1,1),(1,2)\},\{(2,1),(2,2)\},E,\emptyset \} $$ which does not depend on $\mu$. It seems to me that in the answers one believes that $\mathbb{P}_\mu[\{(2,1),(2,2)\}]=0$ implies somehow that this set should not belong to $\mathcal{F}_0$, but I think this is not correct.","I am reading the book Markov Chains and Stochastic Stability from Meyn and Tweedie. They define Markov chains on a measurable state space $(E,\Sigma)$ (Chapter 3.4) and they define it on the space $\Omega = \prod_{i \in \mathbb{N}}E, $ with an $\sigma$-algebra $\mathcal{A}$ which is the smallest $\sigma$-algebra that contains all cylinder sets with only finitly many sets different from $E$ $$A_1 \times A_2 \times \dots A_n \times E \times E \times \dots$$ Then they define the Markov chain as a family of random variables $(X_n)_{n \in \mathbb{N}}$ where for $\omega=(x_n)_{n \in \mathbb{N}}\in \Omega$ they set $$X_n(\omega)=x_n .$$ Thus, all Markov chains are defined on the same set $\Omega$ and the random variables $(X_n)$ are also always the same. Now if they talk about a certain initial distribution $\mu$ and transition kernel $p(x,A)$; then they assoicate a Markov chain to it by constructing a specific measure $\mathbb{P}_\mu$. Thus, by this definition, two Markov chains only differ on the probability measure of the probability space. My problem is that in the book they define the term $$ \mathcal{F}_n = \sigma(X_0,\dots,X_n) \subseteq \mathcal{B}(X^{n+1})$$ and they say which is the smallest $\sigma$-field for which the random variable   $\{X_0,\dots,X_n\}$ is measurable. In many cases $\mathcal{F}_n$ will   coincide with $\mathcal{B}(X^{n+1})$, although this depend in   particular on the initial measure $\mu$ choosen for a particular   chain. How can $\mathcal{F}_n$ depend on the initial measure? The random variable is already defined as $X_n(\omega)=x_n$, and thus the measurability of $\{X_0,\dots,X_n\}$ depends only on $\Sigma$ and $\mathcal{A}$ where does the intial measure $\mu$ comes into play? Update: After seeing the answers, I think it is a good thing to provide my question with an example. Lets consider the case where $E=\{1,2\}$ and $\Omega = E \times E$, then the random variables $X_0$ and $X_1$ are already defined as above, in particular $X_0$ is defined as $$ X_0 ((1,1))=X_0((1,2))=1$$ and $$X_0((2,1))=X_0((2,2))=2.$$  Now if $\mathbb{P}_\mu$ is the probability that $X_0 = 1 $, then we must have $$  \mathbb{P}_\mu[\{(1,1),(1,2)\}]=1.$$ But this is completely independent from  defining $\mathcal{F}_0$ (or $\mathcal{F}_n$). In this case we always have $$\mathcal{F}_0 = \{\{(1,1),(1,2)\},\{(2,1),(2,2)\},E,\emptyset \} $$ which does not depend on $\mu$. It seems to me that in the answers one believes that $\mathbb{P}_\mu[\{(2,1),(2,2)\}]=0$ implies somehow that this set should not belong to $\mathcal{F}_0$, but I think this is not correct.",,"['probability', 'measure-theory', 'markov-chains']"
31,This is a variation of the colored socks in a drawer problem.,This is a variation of the colored socks in a drawer problem.,,"Suppose that instead of having one drawer, you have two drawers.  Each drawer has some socks that are white and some that are black.  Drawer 1 has w black socks and x white socks.  Drawer 2 has y black socks and z white socks.  w+x=y+z.  If you take out all the socks randomly, 1 each from each drawer to make pairs, until both drawers are empty, what is expected (or average) number of times you pulled out a black sock from drawer 1 and 2?  Is it [{w/(w+x)} {y/(y+z)}] (w+x)?","Suppose that instead of having one drawer, you have two drawers.  Each drawer has some socks that are white and some that are black.  Drawer 1 has w black socks and x white socks.  Drawer 2 has y black socks and z white socks.  w+x=y+z.  If you take out all the socks randomly, 1 each from each drawer to make pairs, until both drawers are empty, what is expected (or average) number of times you pulled out a black sock from drawer 1 and 2?  Is it [{w/(w+x)} {y/(y+z)}] (w+x)?",,['probability']
32,Suppose a city with Three type of coins ?!,Suppose a city with Three type of coins ?!,,"in a city we have tree type 1 dollar, 2 dollar, 3 dollar of coins. we want to pay for a 20 dollar product. how many ways we can pay for a 20 dollar product, if the seller has no money and number of 1 dollar coin is more than 2 dollar coin. 1) 20 2) 21 3) 38 4) 40 This is a 2010 contest question that the answer sheet say (2) is True, but there is no way to reach it ! any hint or idea ?","in a city we have tree type 1 dollar, 2 dollar, 3 dollar of coins. we want to pay for a 20 dollar product. how many ways we can pay for a 20 dollar product, if the seller has no money and number of 1 dollar coin is more than 2 dollar coin. 1) 20 2) 21 3) 38 4) 40 This is a 2010 contest question that the answer sheet say (2) is True, but there is no way to reach it ! any hint or idea ?",,"['probability', 'combinatorics', 'statistics', 'discrete-mathematics', 'combinations']"
33,A question related to reflection principle,A question related to reflection principle,,"Question: $$P(X_1\gt 0, ..., X_n\gt 0, X_n=a-b)=?$$ Its Answer: $= (1,1)   \rightarrow (n,a-b) $ that meet  neither touch nor cross paths. $=[(1,1)   \rightarrow (n,a-b) \ \ \text{all paths}]-[(1,1)   \rightarrow (n,a-b)  \ \text{that meet  touch or cross paths.}]$ $$=[(1,1)   \rightarrow (n,a-b) \ \ \text{all paths}]-[(1,-1)   \rightarrow (n,a-b) \ \ \text{all paths}]$$ $$=\binom{n-1}{n-1+a-b-1\over 2}-\binom{n-1}{n-1+a-b+1\over 2}$$ $$=\binom{a+b-1}{a-1}-\binom{a+b-1}{a}$$ where $n=a+b$ I have used reflection principe that $= (1,1)   \rightarrow (n,a-b) $ that meet  touch or cross paths. equal to $(1,-1)   \rightarrow (n,a-b) \ \ \text{all paths}$ My real question: But if I have $$P(X_1\ge 0, ..., X_n\ge 0, X_n=a-b)=?$$ how can I solve this question like my above solution. How can I use reflection principle? Please explain it. Thank you so much:)","Question: $$P(X_1\gt 0, ..., X_n\gt 0, X_n=a-b)=?$$ Its Answer: $= (1,1)   \rightarrow (n,a-b) $ that meet  neither touch nor cross paths. $=[(1,1)   \rightarrow (n,a-b) \ \ \text{all paths}]-[(1,1)   \rightarrow (n,a-b)  \ \text{that meet  touch or cross paths.}]$ $$=[(1,1)   \rightarrow (n,a-b) \ \ \text{all paths}]-[(1,-1)   \rightarrow (n,a-b) \ \ \text{all paths}]$$ $$=\binom{n-1}{n-1+a-b-1\over 2}-\binom{n-1}{n-1+a-b+1\over 2}$$ $$=\binom{a+b-1}{a-1}-\binom{a+b-1}{a}$$ where $n=a+b$ I have used reflection principe that $= (1,1)   \rightarrow (n,a-b) $ that meet  touch or cross paths. equal to $(1,-1)   \rightarrow (n,a-b) \ \ \text{all paths}$ My real question: But if I have $$P(X_1\ge 0, ..., X_n\ge 0, X_n=a-b)=?$$ how can I solve this question like my above solution. How can I use reflection principle? Please explain it. Thank you so much:)",,"['probability', 'stochastic-processes', 'stochastic-calculus', 'stochastic-analysis']"
34,Complement Probability- Choose A Ball,Complement Probability- Choose A Ball,,"An urn contains $n$ balls, one of which is special. If $k$ of these balls are withdrawn one at a time, with each selection being equally likely to be any of the balls that remain at the time, what is the probability that the special ball is chosen? Can we say the following? $\# \Omega={n\choose k}$ $A\equiv special\ ball\ was\ chosen $ $\# A^C={n-1 \choose k}$ $P(A)=1-\frac{{n-1 \choose k}}{{n\choose k}}$","An urn contains $n$ balls, one of which is special. If $k$ of these balls are withdrawn one at a time, with each selection being equally likely to be any of the balls that remain at the time, what is the probability that the special ball is chosen? Can we say the following? $\# \Omega={n\choose k}$ $A\equiv special\ ball\ was\ chosen $ $\# A^C={n-1 \choose k}$ $P(A)=1-\frac{{n-1 \choose k}}{{n\choose k}}$",,"['probability', 'combinatorics']"
35,How to find expected angle between two randomly generated vectors?,How to find expected angle between two randomly generated vectors?,,Let us say two random points have been generated in a d-dimensional space by uniformly sampling from a unit cube centered at origin. How to calculate the expected angle between them?,Let us say two random points have been generated in a d-dimensional space by uniformly sampling from a unit cube centered at origin. How to calculate the expected angle between them?,,"['probability', 'geometry', 'probability-theory']"
36,Coffee Shop Meeting,Coffee Shop Meeting,,"$A$ and $B$ decide to meet at a cafe between $5$ p.m. and $6$ p.m. They agree that the person who arrives first at the cafe would wait for exactly $15$ minutes for the other. If each of them arrives at a random time between $5$ p.m. and $6$ p.m., what is the probability that the meeting takes place? I figured that if one of them arrive at the first minute then the probability of the two meeting each other would be $15/60$, because the second person could arrive from the $1^{st}$ minute till the $15^{th}$ minute and meet with him. Similarly if the first person arrives at the second minute the probability would be $16/60$. This will go on till the $14^{th}$ minute and the probability would be $29/60$. The probability will remain $29/60$ till the $45^{th}$ minute, after which it will gradually decrease in the order $28/60, 27/60,... , 15/60.$ I am not sure if my approach is correct. Also I am stuck after a point with my approach. Please explain elaborately how to solve such questions.","$A$ and $B$ decide to meet at a cafe between $5$ p.m. and $6$ p.m. They agree that the person who arrives first at the cafe would wait for exactly $15$ minutes for the other. If each of them arrives at a random time between $5$ p.m. and $6$ p.m., what is the probability that the meeting takes place? I figured that if one of them arrive at the first minute then the probability of the two meeting each other would be $15/60$, because the second person could arrive from the $1^{st}$ minute till the $15^{th}$ minute and meet with him. Similarly if the first person arrives at the second minute the probability would be $16/60$. This will go on till the $14^{th}$ minute and the probability would be $29/60$. The probability will remain $29/60$ till the $45^{th}$ minute, after which it will gradually decrease in the order $28/60, 27/60,... , 15/60.$ I am not sure if my approach is correct. Also I am stuck after a point with my approach. Please explain elaborately how to solve such questions.",,['probability']
37,What are the chances of winning Higher/Lower?,What are the chances of winning Higher/Lower?,,"Given the game 'higher/lower': A deck of cards of size N is uniquely ranked. The deck is shuffled, lain in a row, and the first card is turned over. You have to guess whether the next card to be turned over is higher than this one or lower. The next card is flipped. If you're right, you continue with that card for the remaining deck. (After this, the next card flipped is compared to this one.) If you make it to the end, you win. Otherwise, you lose. It is obvious that if someone keeps track of all cards in the deck, they can make the best call between the two choices of ""higher"" and ""lower"" (with the highest chance of winning). Given that the deck is shuffled completely random, what is the chance that someone will win this game (through N cards) if this person tracks all cards in the deck and plays optimally? I thought of this question myself and was intrigued by it, but couldn't find any clues to the answer.","Given the game 'higher/lower': A deck of cards of size N is uniquely ranked. The deck is shuffled, lain in a row, and the first card is turned over. You have to guess whether the next card to be turned over is higher than this one or lower. The next card is flipped. If you're right, you continue with that card for the remaining deck. (After this, the next card flipped is compared to this one.) If you make it to the end, you win. Otherwise, you lose. It is obvious that if someone keeps track of all cards in the deck, they can make the best call between the two choices of ""higher"" and ""lower"" (with the highest chance of winning). Given that the deck is shuffled completely random, what is the chance that someone will win this game (through N cards) if this person tracks all cards in the deck and plays optimally? I thought of this question myself and was intrigued by it, but couldn't find any clues to the answer.",,"['probability', 'card-games']"
38,Prove $E[XE[Y\mid\mathcal{G}]] = E[YE[X\mid\mathcal{G}]]$,Prove,E[XE[Y\mid\mathcal{G}]] = E[YE[X\mid\mathcal{G}]],"Show that for bounded $X$ and $Y$ that $E[XE[Y\mid\mathcal{G}]] = E[YE[X\mid\mathcal{G}]]$. Attempt: Suppose that $X = _{\mathcal{X}_F}$, where $F \in \mathcal{D}$. Then for every $B \in \mathcal{D}$: \begin{align} & \int_B E[Y\mid\mathcal{D}\hspace{2mm} dP_{\mathcal{D}}] = \int_B  Y \, dP_{\mathcal{D}} = \int_{B \cap F}  Y \, dP_{\mathcal{D}} = \int_{B \cap F}  E[Y\mid\mathcal{D}] \, dP_{\mathcal{D}} \\[8pt] = {} & \int_{B} E[Y\mid\mathcal{D}] \, dP_{\mathcal{D}}  = X[E[Y\mid G]]\text{ a.s.} \tag 1 \end{align} (I'm trying to write out an $_{\mathcal{X}_F}$ infront of the conditional expectations in the last part, but it won't work) Then we can follow the same process for $Y = {\mathcal{Y}_F}$ to complete the proof (calling it $(2)$). Then saying by both $(1)$ and $(2)$, $E[XE[Y\mid\mathcal{G}]] = E[YE[X\mid\mathcal{G}]]$.","Show that for bounded $X$ and $Y$ that $E[XE[Y\mid\mathcal{G}]] = E[YE[X\mid\mathcal{G}]]$. Attempt: Suppose that $X = _{\mathcal{X}_F}$, where $F \in \mathcal{D}$. Then for every $B \in \mathcal{D}$: \begin{align} & \int_B E[Y\mid\mathcal{D}\hspace{2mm} dP_{\mathcal{D}}] = \int_B  Y \, dP_{\mathcal{D}} = \int_{B \cap F}  Y \, dP_{\mathcal{D}} = \int_{B \cap F}  E[Y\mid\mathcal{D}] \, dP_{\mathcal{D}} \\[8pt] = {} & \int_{B} E[Y\mid\mathcal{D}] \, dP_{\mathcal{D}}  = X[E[Y\mid G]]\text{ a.s.} \tag 1 \end{align} (I'm trying to write out an $_{\mathcal{X}_F}$ infront of the conditional expectations in the last part, but it won't work) Then we can follow the same process for $Y = {\mathcal{Y}_F}$ to complete the proof (calling it $(2)$). Then saying by both $(1)$ and $(2)$, $E[XE[Y\mid\mathcal{G}]] = E[YE[X\mid\mathcal{G}]]$.",,"['probability', 'measure-theory', 'probability-theory', 'lebesgue-measure']"
39,Rectangle randomly thrown on chessboard,Rectangle randomly thrown on chessboard,,") I'm an electrical engineer and having a tough problem with... math :) geometry and probability... Here's the problem : We have an infinite chessboard. Each square of the chessboard is of known height/width (x). I have four points, distances between these points being FIXED. They can be arranged as a rectangle, square, diamond, on a circle... Question : I want to throw the rectangle (or square, or diamond...) on the chessboard and get a 100% probability for two points of the rectangle to land on a white square and the two other points on a black square. What shape/dimensions regarding to x, do I have to adopt for this condition to be fullfilled ? Thanks for your help :) !",") I'm an electrical engineer and having a tough problem with... math :) geometry and probability... Here's the problem : We have an infinite chessboard. Each square of the chessboard is of known height/width (x). I have four points, distances between these points being FIXED. They can be arranged as a rectangle, square, diamond, on a circle... Question : I want to throw the rectangle (or square, or diamond...) on the chessboard and get a 100% probability for two points of the rectangle to land on a white square and the two other points on a black square. What shape/dimensions regarding to x, do I have to adopt for this condition to be fullfilled ? Thanks for your help :) !",,"['probability', 'geometry', 'random']"
40,Choosing 10 balls out of a box of 90 balls,Choosing 10 balls out of a box of 90 balls,,"A box contains $ 30$ red balls, $30$ white balls and $30$ blue balls. If $10$ balls are selected at random without replacement, what is the probability that at least one color will be missing from the selection? The answer is: Solution : Let $A_1, A_2$ and $A_3$ be the events that there is no red, no white and no blue balls, respectively. Then by the inclusion-exclusion principle, $P(A_1\cup A_2\cup A_3) = \sum_{i}P(A_i)-\sum_{i<j}P(A_i\cap A_j)+ P(A_1\cap A_2\cap A_3)$. Clearly, $P(A_1\cap A_2\cap A_3)=0$ and $P(A_i\cap A_j)={\binom{30}{10}\over{\binom{90}{10}}}$ for $i\ne j$. Finally, $P(A_i)= {{\sum\limits_{k=1}^{10}\binom{30}{k}\binom{30}{10-k}}\over{\binom{90}{10}}}={{\sum\limits_{k=0}^{10}\binom{30}{k}\binom{30}{10-k}-\binom{30}{10}}\over{\binom{90}{10}}}={{\binom{60}{10}-\binom{30}{10}}\over{\binom{90}{10}}}$ Why isn't it just $\binom{60}{10}\over\binom{90}{10}$?","A box contains $ 30$ red balls, $30$ white balls and $30$ blue balls. If $10$ balls are selected at random without replacement, what is the probability that at least one color will be missing from the selection? The answer is: Solution : Let $A_1, A_2$ and $A_3$ be the events that there is no red, no white and no blue balls, respectively. Then by the inclusion-exclusion principle, $P(A_1\cup A_2\cup A_3) = \sum_{i}P(A_i)-\sum_{i<j}P(A_i\cap A_j)+ P(A_1\cap A_2\cap A_3)$. Clearly, $P(A_1\cap A_2\cap A_3)=0$ and $P(A_i\cap A_j)={\binom{30}{10}\over{\binom{90}{10}}}$ for $i\ne j$. Finally, $P(A_i)= {{\sum\limits_{k=1}^{10}\binom{30}{k}\binom{30}{10-k}}\over{\binom{90}{10}}}={{\sum\limits_{k=0}^{10}\binom{30}{k}\binom{30}{10-k}-\binom{30}{10}}\over{\binom{90}{10}}}={{\binom{60}{10}-\binom{30}{10}}\over{\binom{90}{10}}}$ Why isn't it just $\binom{60}{10}\over\binom{90}{10}$?",,['probability']
41,Difference between Frequentist and Bayesian approach to Statistics,Difference between Frequentist and Bayesian approach to Statistics,,What is the difference between the Frequentist vs. the Bayesian approach to Statistics? Would someone be so kind to come up with a simple example that shows how the approaches and possibly the results differ.,What is the difference between the Frequentist vs. the Bayesian approach to Statistics? Would someone be so kind to come up with a simple example that shows how the approaches and possibly the results differ.,,"['probability', 'bayesian']"
42,Coin weighting problem,Coin weighting problem,,"There are n coins, among which there may or may not be one counterfeit coin. If there is a counterfeit coin, it may be either heavier or lighter than the other coins. The coins are to be weighed by a balance. What is the coin-weighing strategy for 3 weighings and 12 coins(find the counterfeit coin if it is there and tell me whether it is too lighter or heavier)? I think I can find the counterfeit coin between two(4-2-1). But I cannot determine which one of the two and whether it is too lighter or heavier. I'm not sure what tags the problem belongs to. I put it in probability,everyone can help me retag it.","There are n coins, among which there may or may not be one counterfeit coin. If there is a counterfeit coin, it may be either heavier or lighter than the other coins. The coins are to be weighed by a balance. What is the coin-weighing strategy for 3 weighings and 12 coins(find the counterfeit coin if it is there and tell me whether it is too lighter or heavier)? I think I can find the counterfeit coin between two(4-2-1). But I cannot determine which one of the two and whether it is too lighter or heavier. I'm not sure what tags the problem belongs to. I put it in probability,everyone can help me retag it.",,"['probability', 'probability-theory']"
43,"Expectation of an increasing, bounded concave function of a non-negative random variable","Expectation of an increasing, bounded concave function of a non-negative random variable",,"Let $h:[0,\infty)\to [0,1)$ be a strictly increasing and strictly concave function. Let the argument of this function be a random variable $C$ with probability density function (pdf) $f_{C}(c)$ with support on some subset of $[0,\infty)$. By an application of Jensen's inequality, we have $$\mathrm{E}(h(C)) = \int_{0}^{\infty}h(c)f_{C}(c)dc < h\left(\int_{0}^{\infty}cf_{C}(c)dc\right) = h(\mathrm{E}(C))$$ where the expectations are assumed to exist. I wonder if this can be generalized as outlined below when the function $h$ is defined as above. Assume that we have two random variables $C_{1}$ and $C_{2}$ for which $\mathrm{E}(C_{1}) = \mathrm{E}(C_{2})$, but the higher moments of their distributions $f_{C_{1}}$ and $f_{C_{2}}$ differ in general. In particular, we may take $\mathrm{Var}(C_{2})>\mathrm{Var}(C_{1})$. Can anything be said about which quantity is larger in this case, $\mathrm{E}(h(C_{1}))$ or $\mathrm{E}(h(C_{2}))$? Intuitively, since $h$ is concave and increasing, I expect $\mathrm{E}(h(C_{2})) < \mathrm{E}(h(C_{1}))$ (the variable with the largest variance produces the smallest expectation), and certainly if $f_{C_{1}}$ and $f_{C_{2}}$ are both symmetric. But does this hold in general? I would be a little surprised if it does, but I haven't been able to find a simple counterexample.","Let $h:[0,\infty)\to [0,1)$ be a strictly increasing and strictly concave function. Let the argument of this function be a random variable $C$ with probability density function (pdf) $f_{C}(c)$ with support on some subset of $[0,\infty)$. By an application of Jensen's inequality, we have $$\mathrm{E}(h(C)) = \int_{0}^{\infty}h(c)f_{C}(c)dc < h\left(\int_{0}^{\infty}cf_{C}(c)dc\right) = h(\mathrm{E}(C))$$ where the expectations are assumed to exist. I wonder if this can be generalized as outlined below when the function $h$ is defined as above. Assume that we have two random variables $C_{1}$ and $C_{2}$ for which $\mathrm{E}(C_{1}) = \mathrm{E}(C_{2})$, but the higher moments of their distributions $f_{C_{1}}$ and $f_{C_{2}}$ differ in general. In particular, we may take $\mathrm{Var}(C_{2})>\mathrm{Var}(C_{1})$. Can anything be said about which quantity is larger in this case, $\mathrm{E}(h(C_{1}))$ or $\mathrm{E}(h(C_{2}))$? Intuitively, since $h$ is concave and increasing, I expect $\mathrm{E}(h(C_{2})) < \mathrm{E}(h(C_{1}))$ (the variable with the largest variance produces the smallest expectation), and certainly if $f_{C_{1}}$ and $f_{C_{2}}$ are both symmetric. But does this hold in general? I would be a little surprised if it does, but I haven't been able to find a simple counterexample.",,"['probability', 'convex-analysis']"
44,How do you calculate the sum of combinations of 1000 dice rolls?,How do you calculate the sum of combinations of 1000 dice rolls?,,"For two dice rolls we can calculate the number of combinations for each summed total: Rolling a 2: one chance (1&1) Rolling a 3: two chances (2&1)(1&2) Rolling a 4: three chances (3&1)(1&3)(2&2) Rolling a 5: four chances (4&1)(1&4)(3&2)(2&3) Rolling a 6: five chances (5&1)(1&5)(4&2)(2&4)(2&2) Rolling a 7: six chances (6&1)(1&6)(5&2)(2&5)(4&3)(3&4) Rolling an 8: five chances (6&2)(2&5)(5&3)(3&5)(4&4) Rolling a 9: four chances (6&3)(3&6)(5&4)(4&5) Rolling a 10: three chances (6&4)(4&6)(5&5) Rolling an 11: two chances (6&5)(5&6) Rolling a 12: one chance (6,6) How do we go about this for n dice rolls? For example how do we find the total number of values which will sum to 150 if we roll 100 die?","For two dice rolls we can calculate the number of combinations for each summed total: Rolling a 2: one chance (1&1) Rolling a 3: two chances (2&1)(1&2) Rolling a 4: three chances (3&1)(1&3)(2&2) Rolling a 5: four chances (4&1)(1&4)(3&2)(2&3) Rolling a 6: five chances (5&1)(1&5)(4&2)(2&4)(2&2) Rolling a 7: six chances (6&1)(1&6)(5&2)(2&5)(4&3)(3&4) Rolling an 8: five chances (6&2)(2&5)(5&3)(3&5)(4&4) Rolling a 9: four chances (6&3)(3&6)(5&4)(4&5) Rolling a 10: three chances (6&4)(4&6)(5&5) Rolling an 11: two chances (6&5)(5&6) Rolling a 12: one chance (6,6) How do we go about this for n dice rolls? For example how do we find the total number of values which will sum to 150 if we roll 100 die?",,['probability']
45,"Distribution of the lifetime of a system consisting of two exponentially distributed components, one being backup","Distribution of the lifetime of a system consisting of two exponentially distributed components, one being backup",,"I have a system consisting of components $S_1$ and $S_2$ whose lifetimes $T_1$ and $T_2$ follow the exponential distribution with parameter $\lambda$. At time $t=0$ the component $S_1$ is switched on and $S_2$ is kept off until $S_1$ fails (and is immediately switched on). What is the distribution of the lifetime of the system? To me the logical solution would be $f(T_1,\lambda)+f(T_2,\lambda)$ where f is the probability density function $f(x,\lambda)=\lambda e^{-\lambda x}$. $\Rightarrow$ $\lambda e^{-\lambda T_1}+\lambda e^{-\lambda T_2}$ but I have nothing to verify it with. Am I on the right track?","I have a system consisting of components $S_1$ and $S_2$ whose lifetimes $T_1$ and $T_2$ follow the exponential distribution with parameter $\lambda$. At time $t=0$ the component $S_1$ is switched on and $S_2$ is kept off until $S_1$ fails (and is immediately switched on). What is the distribution of the lifetime of the system? To me the logical solution would be $f(T_1,\lambda)+f(T_2,\lambda)$ where f is the probability density function $f(x,\lambda)=\lambda e^{-\lambda x}$. $\Rightarrow$ $\lambda e^{-\lambda T_1}+\lambda e^{-\lambda T_2}$ but I have nothing to verify it with. Am I on the right track?",,"['probability', 'probability-distributions', 'random-variables']"
46,Trivial question about product measures on the real line,Trivial question about product measures on the real line,,"Let $\mathbb{R}^2 = \mathbb{R} \times \mathbb{R} $. Denote by $\mathscr{B}^2$ the borel sigma algebra of $\mathbb{R}^2$ and $\mathscr{B}$ the borel sigma algebra of $\mathbb{R}$. I know this question may seem trivial, but how can I justify that in fact $\mathscr{B}^2 = \mathscr{B} \otimes \mathscr{B}$ ( the smallest sigma algebra containing $\mathscr{B} \times \mathscr{B} $ )?","Let $\mathbb{R}^2 = \mathbb{R} \times \mathbb{R} $. Denote by $\mathscr{B}^2$ the borel sigma algebra of $\mathbb{R}^2$ and $\mathscr{B}$ the borel sigma algebra of $\mathbb{R}$. I know this question may seem trivial, but how can I justify that in fact $\mathscr{B}^2 = \mathscr{B} \otimes \mathscr{B}$ ( the smallest sigma algebra containing $\mathscr{B} \times \mathscr{B} $ )?",,[]
47,"For a random variable $X$ such that $P(a<X<b)=1$, showing $E(X)E\left(\frac{1}{X}\right) \le\frac{(a+b)^2}{4ab}$","For a random variable  such that , showing",X P(a<X<b)=1 E(X)E\left(\frac{1}{X}\right) \le\frac{(a+b)^2}{4ab},"I've worked on the following problem and have a solution (included below), but I would like to know if there are any other solutions to this problem, particularly more elegant solutions that apply well known inequalities that I've overlooked. QUESTION : Suppose we have a random variable s.t. $P(a<X<b) =1$  where $0 < a < X < b$ , $a$ and $b$ both positive constants. Show that $$E(X)E\left(\frac{1}{X}\right) \le \frac{(a+b)^2}{4ab}$$ Hint :  find constant c and d s.t. $\frac{1}{x} \le cx+d$ when $a<x<b$, and argue that then we shall have $E(\frac{1}{X}) \le cE(X)+d$ MY SOLUTION : For a line $cx+d$ that cuts through $\frac{1}{X}$ at the points $x=a$ and $x = b$, it's easy to show that $ c = - \frac{1}{ab} $  and $d = \frac{a+b}{ab} $, $$ E\left(\frac{1}{X}\right) \le - \frac{1}{ab} E(X) + \frac{a+b}{ab} $$ $$ abE\left(\frac{1}{X}\right) + E(X) \le (a+b) $$ and because both sides of the inequality are positive, it follows that: $$ \left(abE\left(\frac{1}{X}\right) + E(X)\right)^2 \le (a+b)^2 $$ $$ (ab)^2E\left(\frac{1}{X}\right)^2 + 2abE\left(\frac{1}{X}\right)E(X) + E(X)^2  \le (a+b)^2 $$ Now, for the LHS, we can see that  $2abE\left(\frac{1}{X}\right)E(X) \le (ab)^2E\left(\frac{1}{X}\right)^2 + E(X)^2$ because $0 \le (ab)^2E\left(\frac{1}{X}\right)^2 - 2ab\,E\left(\frac{1}{X}\right)E(X) + E(X)^2 = \left(ab\,E\left(\frac{1}{X}\right) - E(X)\right)^2 $ So, $$ 4ab\,E\left(\frac{1}{X}\right)E(X) \le (ab)^2E\left(\frac{1}{X}\right)^2 + 2ab\,E\left(\frac{1}{X}\right)E(X) + E(X)^2  \le (a+b)^2 $$ and therefore: $$ E\left(\frac{1}{X}\right)E(X) \le \frac{(a+b)^2}{4ab} $$  Q.E.D. Thanks for any additional solutions you might be able to provide.  Cheers!","I've worked on the following problem and have a solution (included below), but I would like to know if there are any other solutions to this problem, particularly more elegant solutions that apply well known inequalities that I've overlooked. QUESTION : Suppose we have a random variable s.t. $P(a<X<b) =1$  where $0 < a < X < b$ , $a$ and $b$ both positive constants. Show that $$E(X)E\left(\frac{1}{X}\right) \le \frac{(a+b)^2}{4ab}$$ Hint :  find constant c and d s.t. $\frac{1}{x} \le cx+d$ when $a<x<b$, and argue that then we shall have $E(\frac{1}{X}) \le cE(X)+d$ MY SOLUTION : For a line $cx+d$ that cuts through $\frac{1}{X}$ at the points $x=a$ and $x = b$, it's easy to show that $ c = - \frac{1}{ab} $  and $d = \frac{a+b}{ab} $, $$ E\left(\frac{1}{X}\right) \le - \frac{1}{ab} E(X) + \frac{a+b}{ab} $$ $$ abE\left(\frac{1}{X}\right) + E(X) \le (a+b) $$ and because both sides of the inequality are positive, it follows that: $$ \left(abE\left(\frac{1}{X}\right) + E(X)\right)^2 \le (a+b)^2 $$ $$ (ab)^2E\left(\frac{1}{X}\right)^2 + 2abE\left(\frac{1}{X}\right)E(X) + E(X)^2  \le (a+b)^2 $$ Now, for the LHS, we can see that  $2abE\left(\frac{1}{X}\right)E(X) \le (ab)^2E\left(\frac{1}{X}\right)^2 + E(X)^2$ because $0 \le (ab)^2E\left(\frac{1}{X}\right)^2 - 2ab\,E\left(\frac{1}{X}\right)E(X) + E(X)^2 = \left(ab\,E\left(\frac{1}{X}\right) - E(X)\right)^2 $ So, $$ 4ab\,E\left(\frac{1}{X}\right)E(X) \le (ab)^2E\left(\frac{1}{X}\right)^2 + 2ab\,E\left(\frac{1}{X}\right)E(X) + E(X)^2  \le (a+b)^2 $$ and therefore: $$ E\left(\frac{1}{X}\right)E(X) \le \frac{(a+b)^2}{4ab} $$  Q.E.D. Thanks for any additional solutions you might be able to provide.  Cheers!",,"['probability', 'inequality', 'expectation', 'functional-inequalities']"
48,probability set theory proof,probability set theory proof,,"Denote by A, B and C subsets of the sample space , Please advice me on my solutions below as I am unsure and help me answer the part iii. (ii) if P(A) > 0,P(B) > 0, and A,B are mutually exclusive, then are A and B independent? I did: If A and B are mutually exclusive then $P(A\cap B)=0$ as $(A\cap B)=\phi$ Since, $P(A\cap B)=0\ne P(A)P(B)> 0$  as $ P(A),P(B) > 0.$ It implies A and B are dependent. (iii) if A, B, C are (mutually) independent, prove that $A^c, B^c $ and $ C^c$ are (mutually) independent. I did: $P(A\cap B\cap C)=P(A)P(B)P(C).$ $((AB)C)^c=(A\cap B)^c\cup C^c=A^c\cup B^c\cup C^c - $ DeMorgan's Laws $P((AB)C)^c=1-P(A)P(B)P(C)=P(A^c\cup B^c\cup C^c)=P(A^c)+P(B^c)+P(C^c)$ I don't know what to do from now on. Please help. Also advice on the above solution.","Denote by A, B and C subsets of the sample space , Please advice me on my solutions below as I am unsure and help me answer the part iii. (ii) if P(A) > 0,P(B) > 0, and A,B are mutually exclusive, then are A and B independent? I did: If A and B are mutually exclusive then $P(A\cap B)=0$ as $(A\cap B)=\phi$ Since, $P(A\cap B)=0\ne P(A)P(B)> 0$  as $ P(A),P(B) > 0.$ It implies A and B are dependent. (iii) if A, B, C are (mutually) independent, prove that $A^c, B^c $ and $ C^c$ are (mutually) independent. I did: $P(A\cap B\cap C)=P(A)P(B)P(C).$ $((AB)C)^c=(A\cap B)^c\cup C^c=A^c\cup B^c\cup C^c - $ DeMorgan's Laws $P((AB)C)^c=1-P(A)P(B)P(C)=P(A^c\cup B^c\cup C^c)=P(A^c)+P(B^c)+P(C^c)$ I don't know what to do from now on. Please help. Also advice on the above solution.",,"['probability', 'elementary-set-theory']"
49,Inequality involving taking expectations,Inequality involving taking expectations,,"There are three convexly decreasing functions $f, g, h:\mathbb{R^+}\rightarrow \mathbb{R^+}$, and $f(x)h(x)<1$ for $\forall x$. I need to prove that $E[f(x)^2]E[g(x)h(x)]<E[f(x)g(x)]\left(1+E\left[f(x)h(x)\right]\right)$ for an arbitrary probability distribution.","There are three convexly decreasing functions $f, g, h:\mathbb{R^+}\rightarrow \mathbb{R^+}$, and $f(x)h(x)<1$ for $\forall x$. I need to prove that $E[f(x)^2]E[g(x)h(x)]<E[f(x)g(x)]\left(1+E\left[f(x)h(x)\right]\right)$ for an arbitrary probability distribution.",,"['calculus', 'probability']"
50,Predicting the size of a uniform distribution from a sample,Predicting the size of a uniform distribution from a sample,,"Every bottle of Snapple Iced tea has a fun fact with a fact number on its cap. Ex) #939 The penny was the first U.S. coin to feature the likeness of an actual person. I always wondered just how many facts there were in total (i.e. what the highest number was), and if there was a fact #1 (i.e. the distribution includes 1). So I started collecting the caps from friends and logging their numbers. If I assume that the distribution of Snapple facts is random and rectangular (i.e. I have an equal probability of receiving any given fact number within the range of available fact numbers), can I approximate the upper and lower bounds of the population space by collecting a sample of caps? How? Thank you!","Every bottle of Snapple Iced tea has a fun fact with a fact number on its cap. Ex) #939 The penny was the first U.S. coin to feature the likeness of an actual person. I always wondered just how many facts there were in total (i.e. what the highest number was), and if there was a fact #1 (i.e. the distribution includes 1). So I started collecting the caps from friends and logging their numbers. If I assume that the distribution of Snapple facts is random and rectangular (i.e. I have an equal probability of receiving any given fact number within the range of available fact numbers), can I approximate the upper and lower bounds of the population space by collecting a sample of caps? How? Thank you!",,['probability']
51,Donald Knuth's Nontransitive Bingo Cards,Donald Knuth's Nontransitive Bingo Cards,,"In Time Travel and Other Mathematical Bewilderments , Martin Gardner presents a set of four nontransitive bingo cards designed by Donald Knuth (pp. 61). The rules are that the first player to complete a horizontal row wins. Gardner does not delve into the mathematics but merely mentions that, probabilistically , A beats B, B beats C, C beats D, and D beats A. I was so baffled that I immediately went on to to verify those results. He was right. Now, with dice or heads tails sequences, I can understand nontransitivity; can someone please give the mathematical explanation of how and why nontransitivity occurs in the above game.","In Time Travel and Other Mathematical Bewilderments , Martin Gardner presents a set of four nontransitive bingo cards designed by Donald Knuth (pp. 61). The rules are that the first player to complete a horizontal row wins. Gardner does not delve into the mathematics but merely mentions that, probabilistically , A beats B, B beats C, C beats D, and D beats A. I was so baffled that I immediately went on to to verify those results. He was right. Now, with dice or heads tails sequences, I can understand nontransitivity; can someone please give the mathematical explanation of how and why nontransitivity occurs in the above game.",,"['probability', 'game-theory', 'combinatorial-game-theory']"
52,Adding distances/weights to absorbing markov chain,Adding distances/weights to absorbing markov chain,,"in presence of an absorbing state, I want to calculate mean/expected 'distance' from any state to that absorbing state. What I mean by distance is that I want to give different lengths from one particular state to another. For example, below i wrote a simple coin toss, 2 levels deep. One player is in Start S, with a coin toss he goes A or B. If he reaches A, with %100 probability he reaches End after. But if he reaches B, he either reaches End or he turns back to Start with equal probability. \begin{align*} \begin{pmatrix}  & S & A & B & E \\  S & 0 & \frac{1}{2} & \frac{1}{2} & 0\\  A & 0 & 0 & 0 & 1  \\  B & \frac{1}{2} & 0 & 0 & \frac{1}{2} \\  E & 0 & 0 & 0 & 1 \end{pmatrix} \end{align*} Later I found total transition matrix between transient states \begin{align*}     (I-Q)^{-1} = \left(\begin{array}{rr} \frac{4}{3} & \frac{2}{3} & \frac{2}{3} \\ 0 & 1 & 0 \\ \frac{2}{3} & \frac{1}{3} & \frac{4}{3} \end{array}\right)   \end{align*} So if I sum first row, I find 8/3 , that is expected number of steps from Start to End Now where I am stuck is, probabilities stay same but if going from one state to another  differs, I dont know how to manipulate these matrices to take distances. For example, distance from A-> E may be 1 km, but B -> E may be 5 kms. S-> A may be 20 kms, rest can be 1 km. How can I manipulate these matrices to get this information. Thanks in advance","in presence of an absorbing state, I want to calculate mean/expected 'distance' from any state to that absorbing state. What I mean by distance is that I want to give different lengths from one particular state to another. For example, below i wrote a simple coin toss, 2 levels deep. One player is in Start S, with a coin toss he goes A or B. If he reaches A, with %100 probability he reaches End after. But if he reaches B, he either reaches End or he turns back to Start with equal probability. \begin{align*} \begin{pmatrix}  & S & A & B & E \\  S & 0 & \frac{1}{2} & \frac{1}{2} & 0\\  A & 0 & 0 & 0 & 1  \\  B & \frac{1}{2} & 0 & 0 & \frac{1}{2} \\  E & 0 & 0 & 0 & 1 \end{pmatrix} \end{align*} Later I found total transition matrix between transient states \begin{align*}     (I-Q)^{-1} = \left(\begin{array}{rr} \frac{4}{3} & \frac{2}{3} & \frac{2}{3} \\ 0 & 1 & 0 \\ \frac{2}{3} & \frac{1}{3} & \frac{4}{3} \end{array}\right)   \end{align*} So if I sum first row, I find 8/3 , that is expected number of steps from Start to End Now where I am stuck is, probabilities stay same but if going from one state to another  differs, I dont know how to manipulate these matrices to take distances. For example, distance from A-> E may be 1 km, but B -> E may be 5 kms. S-> A may be 20 kms, rest can be 1 km. How can I manipulate these matrices to get this information. Thanks in advance",,"['probability', 'markov-chains']"
53,Random walk with finite expected stopping time,Random walk with finite expected stopping time,,"Let's say each $X_i$ is a simple random variable taking on values 1 or -1 with probability $1/2$ each. Then $S_n = \sum_{i=1}^{n} X_i$ is a random walk. Set $T = \min \{n\in\mathbb{N} \, : \, S_n = 1\}$. One can show that $E[T] = \infty$. Can we choose the $X_i$ instead in such a way that $E[T] < \infty$? They don't necessarily have to be identically distributed, but I would be interested to see if we can do it with the restriction that each $X_i$ takes on two possible values, each with probability $1/2$.","Let's say each $X_i$ is a simple random variable taking on values 1 or -1 with probability $1/2$ each. Then $S_n = \sum_{i=1}^{n} X_i$ is a random walk. Set $T = \min \{n\in\mathbb{N} \, : \, S_n = 1\}$. One can show that $E[T] = \infty$. Can we choose the $X_i$ instead in such a way that $E[T] < \infty$? They don't necessarily have to be identically distributed, but I would be interested to see if we can do it with the restriction that each $X_i$ takes on two possible values, each with probability $1/2$.",,"['probability', 'probability-theory', 'random-walk']"
54,Probability question involving derangements,Probability question involving derangements,,"$n$ married couples came to a dancing night. For a dance women randomly choose men, $X$ is the number of dancing married couples, we need to find the distribution of $X$ and its probability generating function. My attempt: If $k$ married couples are dancing, then there are $\binom n k$ ways to select those $k$ couples out of $n$, also all other $n-k$ women and $n-k$ men are mixed so that $n-k$ married couples do not dance together. The number of ways to do that mixing is the number of derangements for $n-k$ elements, i.e. $(n-k)!\sum_{i=0}^{n-k}\frac{(-1)^i}{i!}$. There are $n!$ possible ways to build dancing couples. Thus: $$P(X=k)=\binom n k \frac{(n-k)!}{n!}\sum_{i=0}^{n-k}\frac{(-1)^i}{i!}=\frac{1}{k!} \sum_{i=0}^{n-k}\frac{(-1)^i}{i!} \tag{A}$$ $$g_X(t)=E[t^X]=\sum_{k=0}^{n}t^k\frac{1}{k!} \sum_{i=0}^{n-k}\frac{(-1)^i}{i!} \tag{B}$$ I know that $g_X(t)$ is supposed to be $\sum_{k=0}^{n}\frac{(t-1)^k}{k!}$. Any ideas how can I get there?","$n$ married couples came to a dancing night. For a dance women randomly choose men, $X$ is the number of dancing married couples, we need to find the distribution of $X$ and its probability generating function. My attempt: If $k$ married couples are dancing, then there are $\binom n k$ ways to select those $k$ couples out of $n$, also all other $n-k$ women and $n-k$ men are mixed so that $n-k$ married couples do not dance together. The number of ways to do that mixing is the number of derangements for $n-k$ elements, i.e. $(n-k)!\sum_{i=0}^{n-k}\frac{(-1)^i}{i!}$. There are $n!$ possible ways to build dancing couples. Thus: $$P(X=k)=\binom n k \frac{(n-k)!}{n!}\sum_{i=0}^{n-k}\frac{(-1)^i}{i!}=\frac{1}{k!} \sum_{i=0}^{n-k}\frac{(-1)^i}{i!} \tag{A}$$ $$g_X(t)=E[t^X]=\sum_{k=0}^{n}t^k\frac{1}{k!} \sum_{i=0}^{n-k}\frac{(-1)^i}{i!} \tag{B}$$ I know that $g_X(t)$ is supposed to be $\sum_{k=0}^{n}\frac{(t-1)^k}{k!}$. Any ideas how can I get there?",,"['probability', 'combinatorics', 'probability-theory', 'probability-distributions']"
55,How do you interpret probabilities?,How do you interpret probabilities?,,"I am a college student, and i have been doin probabilities since 4 years and I always had one question which puzzled me.... Its like this : If i were told to  find the probability of getting a head in a single toss of a coin ,the answer is pretty easy right? Its 1/2. But i cant  interpret this answer logically. like does it mean  1 out of every 2 two tosses of the coin would be a head ( which is so obvoiusly false ) or does it mean that my chances of getting a heads is like 'half'. What im tryin to say is i really cant find any real life significance  of the concept of probability.  Can anyone help me out, please? P.S.: THNX PEOPLE, ithink i have a fairly good idea now, mainly from the frequentist interpretation","I am a college student, and i have been doin probabilities since 4 years and I always had one question which puzzled me.... Its like this : If i were told to  find the probability of getting a head in a single toss of a coin ,the answer is pretty easy right? Its 1/2. But i cant  interpret this answer logically. like does it mean  1 out of every 2 two tosses of the coin would be a head ( which is so obvoiusly false ) or does it mean that my chances of getting a heads is like 'half'. What im tryin to say is i really cant find any real life significance  of the concept of probability.  Can anyone help me out, please? P.S.: THNX PEOPLE, ithink i have a fairly good idea now, mainly from the frequentist interpretation",,['probability']
56,"Does this argument suffice to show a ""record"" occurs at time n with probability 1/n?","Does this argument suffice to show a ""record"" occurs at time n with probability 1/n?",,"I think it does, but, in addition to checking for correctness, I'd like to know what other argument we might use. Let $X_1, X_2,...X_n$ be be a sequence of independent identically distributed continuous random variables.  We say a record occurs at time $n$ if $ X_n \gt \max(X_1, .\dots ,X_{n1})$ . Show $P$ {Record occurs at time n}= $1/n$ . Since the distributions are identical and independent, then all the $n!$ ways to order the $n$ $X_i's$ are equally as probable. Since there are exactly $(n-1)!$ ways to order the $n$ $X_i's$ such that the $n$ th element is the largest, then $P$ {Record occurs at time n}= $(n-1)!/n!=1/n$ .","I think it does, but, in addition to checking for correctness, I'd like to know what other argument we might use. Let be be a sequence of independent identically distributed continuous random variables.  We say a record occurs at time if . Show {Record occurs at time n}= . Since the distributions are identical and independent, then all the ways to order the are equally as probable. Since there are exactly ways to order the such that the th element is the largest, then {Record occurs at time n}= .","X_1, X_2,...X_n n  X_n \gt \max(X_1, .\dots ,X_{n1}) P 1/n n! n X_i's (n-1)! n X_i's n P (n-1)!/n!=1/n","['probability', 'combinatorics', 'probability-theory', 'probability-distributions']"
57,"$X_n \stackrel{d}{\to}X$, $Y_n \stackrel{d}{\to} c \implies X_n+Y_n \stackrel{d}{\to} X+c$",",",X_n \stackrel{d}{\to}X Y_n \stackrel{d}{\to} c \implies X_n+Y_n \stackrel{d}{\to} X+c,"Let $X_n\Rightarrow X$ and $Y_n\Rightarrow c$. Show that $X_n+Y_n\Rightarrow X+c$. Prove: There exists sequences of random variables $(X^{(*)}_n)$ and $(Y^{(*)}_n)$ such that $(X^{(*)}_n)$ and $X_n$ have the same distribution and $X_n\rightarrow X_{\infty}$ a.s. $(Y^{(*)}_n)$ and $Y_n$ have the same distribution and $Y_n\rightarrow Y_{\infty}=c$ a.s. Hence we can conclude that $X_n+Y_n\rightarrow X+c$ almost surely, which implies convergence in distribution. Can someone take a look at it?","Let $X_n\Rightarrow X$ and $Y_n\Rightarrow c$. Show that $X_n+Y_n\Rightarrow X+c$. Prove: There exists sequences of random variables $(X^{(*)}_n)$ and $(Y^{(*)}_n)$ such that $(X^{(*)}_n)$ and $X_n$ have the same distribution and $X_n\rightarrow X_{\infty}$ a.s. $(Y^{(*)}_n)$ and $Y_n$ have the same distribution and $Y_n\rightarrow Y_{\infty}=c$ a.s. Hence we can conclude that $X_n+Y_n\rightarrow X+c$ almost surely, which implies convergence in distribution. Can someone take a look at it?",,"['probability', 'probability-theory', 'weak-convergence']"
58,Monty Hall problem with pre-specified probabilites,Monty Hall problem with pre-specified probabilites,,"Suppose that a player is given the probabilities for a prize behind each of the three doors. $p_1$, the probability of the prize being behind door 1, is $p_1=\frac{1}{2}$, the other probabilities are $p_2 = \frac{1}{3}$, $p_3 = \frac{1}{6}$. The player chooses door 1 and after his choice one of the doors 2 or 3 is randomly revealed behind which the prize does not reside and the player is offered to change his choice. The question is: Should the player still change his decision after one of the doors was revealed? I'm having trouble with this problem, since I don't really know how to interpret the probabilities given at the start of the game. Since door 1 is more likely than the others to have the prize, it seems logical that after one of the doors was revealed the probability of door 1 having the prize should increase, but I cannot explain this probabilistically. My attempt: Let A = door 1 has the prize, B = door 2 has prize, C = door 3 has prize. Let D = door 2 is chosen, E = door 3 is chosen. We're looking for $P(A|D)+P(A|E)\gt P(A)$? But I'm having trouble finding $P(A|D)$ and $P(A|E)$. Using Bayes I could write $P(A|D)=\frac{P(D|A)P(A)}{P(D)}$, but then again it seems as if the choice of door 2 or door 3, i.e. D or E are independent of A. I'm just sort of confused right now and I'm kind of under time pressure, so I' very much appreciate some help.","Suppose that a player is given the probabilities for a prize behind each of the three doors. $p_1$, the probability of the prize being behind door 1, is $p_1=\frac{1}{2}$, the other probabilities are $p_2 = \frac{1}{3}$, $p_3 = \frac{1}{6}$. The player chooses door 1 and after his choice one of the doors 2 or 3 is randomly revealed behind which the prize does not reside and the player is offered to change his choice. The question is: Should the player still change his decision after one of the doors was revealed? I'm having trouble with this problem, since I don't really know how to interpret the probabilities given at the start of the game. Since door 1 is more likely than the others to have the prize, it seems logical that after one of the doors was revealed the probability of door 1 having the prize should increase, but I cannot explain this probabilistically. My attempt: Let A = door 1 has the prize, B = door 2 has prize, C = door 3 has prize. Let D = door 2 is chosen, E = door 3 is chosen. We're looking for $P(A|D)+P(A|E)\gt P(A)$? But I'm having trouble finding $P(A|D)$ and $P(A|E)$. Using Bayes I could write $P(A|D)=\frac{P(D|A)P(A)}{P(D)}$, but then again it seems as if the choice of door 2 or door 3, i.e. D or E are independent of A. I'm just sort of confused right now and I'm kind of under time pressure, so I' very much appreciate some help.",,['probability']
59,$Y_n = \sup_{k \geq n} E(X_k | F_n)$ is a martingale if $X_n$ is $L^1$ bounded non-negative submartingale,is a martingale if  is  bounded non-negative submartingale,Y_n = \sup_{k \geq n} E(X_k | F_n) X_n L^1,"Let $X_n$ be a $L^1$ bounded non-negative submartingale. Let $Y_n = \sup_{k \geq n} E(X_k | F_n)$. Show that (1) $Y_n$ is a martingale (2) $X_n \leq Y_n$ for all $n$ a.s. (3) $\sup \|X_n\|_1 = \sup \|Y_n\|_1$ (4) If $T_n$ is an $F_n$ martingale st $X_n \leq T_n$ a.s. then $Y_n \leq T_n$ a.s. Comment: I have been stuck on part (1) already. (2) seems quite obvious because we can take $k = n$. I'm not sure how to do (3) and (4). Does anyone have idea how to solve (1),(3),(4) ? Thanks!","Let $X_n$ be a $L^1$ bounded non-negative submartingale. Let $Y_n = \sup_{k \geq n} E(X_k | F_n)$. Show that (1) $Y_n$ is a martingale (2) $X_n \leq Y_n$ for all $n$ a.s. (3) $\sup \|X_n\|_1 = \sup \|Y_n\|_1$ (4) If $T_n$ is an $F_n$ martingale st $X_n \leq T_n$ a.s. then $Y_n \leq T_n$ a.s. Comment: I have been stuck on part (1) already. (2) seems quite obvious because we can take $k = n$. I'm not sure how to do (3) and (4). Does anyone have idea how to solve (1),(3),(4) ? Thanks!",,"['real-analysis', 'probability', 'stochastic-processes']"
60,Weighted Average Proof,Weighted Average Proof,,"Been stuck on this for a while now, seems pretty straightforward but can't seem to prove it. Given $\mu$ is a weighted average of $\mu_1$ and $\mu_2$ such that $\mu = x_1\mu_1 + x_2\mu_2$ where $x_1$ and $x_2$ are positive real numbers and $x_1 + x_2 = 1$, prove that $\mu$ must lie between $\mu_1$ and $\mu_2$. And then in the more general case suppose $\mu = x_1\mu_1 + x_2\mu_2 + \cdots + x_n\mu_n$ where again the $x_i$'s are positive and $\sum x_i = 1$, prove that $\mu$ must lie between the smallest and largest of the $\mu_i$'s.","Been stuck on this for a while now, seems pretty straightforward but can't seem to prove it. Given $\mu$ is a weighted average of $\mu_1$ and $\mu_2$ such that $\mu = x_1\mu_1 + x_2\mu_2$ where $x_1$ and $x_2$ are positive real numbers and $x_1 + x_2 = 1$, prove that $\mu$ must lie between $\mu_1$ and $\mu_2$. And then in the more general case suppose $\mu = x_1\mu_1 + x_2\mu_2 + \cdots + x_n\mu_n$ where again the $x_i$'s are positive and $\sum x_i = 1$, prove that $\mu$ must lie between the smallest and largest of the $\mu_i$'s.",,"['probability', 'statistics']"
61,Formula for encountering C different marbles out of D total draws,Formula for encountering C different marbles out of D total draws,,"Say we draw $D$ marbles out of a bag (with infinite marbles), where each marble could be one color out of $C$ colors (each with equal probability). What is the expected value of the number of different colors our total draw includes? So for example, if $D=4$ and $C=3$, we are drawing $4$ marbles total, where each could be red, green, or blue with equal likelihood. What is the average number of different colors represented in our draw (anywhere from $1$ to $3$) we can expect to have? After playing around, I came up with the following way to express it: $$E[C;D] = \frac{1}{C^D} \big[ (1)(C) + (2)(\text{number of arrangements of two different colors}) + ... + (C)(\text{number of arrangements of $C$ different colors}) \big]$$ And after testing with some low numbers, I came up with the following formula: $$E[C;D] = C - \frac{(C-1)^{D}}{C^{D-1}}$$ It works for the numbers I tested, and also makes intuitive sense since $\lim_{D \rightarrow \infty}E[C;D] = C$. But I'm curious to know: Is this formula correct? If so, how can I prove it?","Say we draw $D$ marbles out of a bag (with infinite marbles), where each marble could be one color out of $C$ colors (each with equal probability). What is the expected value of the number of different colors our total draw includes? So for example, if $D=4$ and $C=3$, we are drawing $4$ marbles total, where each could be red, green, or blue with equal likelihood. What is the average number of different colors represented in our draw (anywhere from $1$ to $3$) we can expect to have? After playing around, I came up with the following way to express it: $$E[C;D] = \frac{1}{C^D} \big[ (1)(C) + (2)(\text{number of arrangements of two different colors}) + ... + (C)(\text{number of arrangements of $C$ different colors}) \big]$$ And after testing with some low numbers, I came up with the following formula: $$E[C;D] = C - \frac{(C-1)^{D}}{C^{D-1}}$$ It works for the numbers I tested, and also makes intuitive sense since $\lim_{D \rightarrow \infty}E[C;D] = C$. But I'm curious to know: Is this formula correct? If so, how can I prove it?",,['probability']
62,"Sum of squares of Binom(n,p) values","Sum of squares of Binom(n,p) values",,"Let $x_{n,p}(j)$ be the probability that a random variable distributed according to a binomial distribution with parameters $n \in \mathbf{N}_+$ and $p \in (0,1)$ takes the value $j \in \{0,1,\ldots,n\}$, i.e. $$x_{n,p}(j)=\binom{n}{j}p^j(1-p)^{n-j}.$$ Is it true that, independently of the value of $p$, we have that  $$\sum_{j=0}^n x_{n,p}^2(j)=o(1)?$$ I am aware of Vandermonde identity which implies the claim holds true for $p=1/2$: indeed  $\binom{2n}{n}=\sum_{i=0}^n \binom{n}{i}^2$, so that  $$\sum_{j=0}^n x_{n,p}^2(j)=\sum_{j=0}^n \binom{n}{j}^2 \frac{1}{2^{2j}}\frac{1}{2^{2n-2j}}=\frac{1}{4^n}\binom{2n}{n}=O\left(\frac{1}{\sqrt{n}}\right),$$ where the last approximation has been obtained with Stirling's formula. Does a similar result hold in general?","Let $x_{n,p}(j)$ be the probability that a random variable distributed according to a binomial distribution with parameters $n \in \mathbf{N}_+$ and $p \in (0,1)$ takes the value $j \in \{0,1,\ldots,n\}$, i.e. $$x_{n,p}(j)=\binom{n}{j}p^j(1-p)^{n-j}.$$ Is it true that, independently of the value of $p$, we have that  $$\sum_{j=0}^n x_{n,p}^2(j)=o(1)?$$ I am aware of Vandermonde identity which implies the claim holds true for $p=1/2$: indeed  $\binom{2n}{n}=\sum_{i=0}^n \binom{n}{i}^2$, so that  $$\sum_{j=0}^n x_{n,p}^2(j)=\sum_{j=0}^n \binom{n}{j}^2 \frac{1}{2^{2j}}\frac{1}{2^{2n-2j}}=\frac{1}{4^n}\binom{2n}{n}=O\left(\frac{1}{\sqrt{n}}\right),$$ where the last approximation has been obtained with Stirling's formula. Does a similar result hold in general?",,"['probability', 'summation', 'asymptotics', 'binomial-coefficients']"
63,Why is this intuitive method valid?,Why is this intuitive method valid?,,"Problem . There are $2$ white and $3$ black balls in the urn. A person randomly picked $2$ balls and put $1$ white ball. What is the probability of the event that the next randomly-picked ball would be white . To solve this problem formally you have to consider conditional probabilities and so on. But in the childhood I did not know such words so I was solving problems of this type in the following way. Intuitive solution . Let's grind balls into powder and mix it. We will have $5$ (whatever you want, for instance) kilograms of powder. $\frac{2}{5}$ of each kilogram is white and $\frac{3}{5}$ is black . A person randomly took $2$ balls in my model means that he took $2$ kilogram of powder. Putting $1$ white ball means that he put $1$ kilogram of white powder. After all actions there are $\left(5 \cdot\frac35-2\cdot \frac35\right)=\frac95$ kilograms of black powder and $\left(5 \cdot\frac25-2\cdot \frac25\right) + 1=\frac95=\frac{11}5$ kilograms of white powder. So the final probability of picking white ball is $\frac{11}{5}/\left(\frac{11}{5}+\frac{9}{5}\right) = \frac{11}{20}$. You can check that this is the right answer, but the question is why is this intuitive method valid?","Problem . There are $2$ white and $3$ black balls in the urn. A person randomly picked $2$ balls and put $1$ white ball. What is the probability of the event that the next randomly-picked ball would be white . To solve this problem formally you have to consider conditional probabilities and so on. But in the childhood I did not know such words so I was solving problems of this type in the following way. Intuitive solution . Let's grind balls into powder and mix it. We will have $5$ (whatever you want, for instance) kilograms of powder. $\frac{2}{5}$ of each kilogram is white and $\frac{3}{5}$ is black . A person randomly took $2$ balls in my model means that he took $2$ kilogram of powder. Putting $1$ white ball means that he put $1$ kilogram of white powder. After all actions there are $\left(5 \cdot\frac35-2\cdot \frac35\right)=\frac95$ kilograms of black powder and $\left(5 \cdot\frac25-2\cdot \frac25\right) + 1=\frac95=\frac{11}5$ kilograms of white powder. So the final probability of picking white ball is $\frac{11}{5}/\left(\frac{11}{5}+\frac{9}{5}\right) = \frac{11}{20}$. You can check that this is the right answer, but the question is why is this intuitive method valid?",,"['probability', 'intuition']"
64,Generalization of Central Limit Theorem?,Generalization of Central Limit Theorem?,,"In my probability class we learned the Central Limit Theorem in the following form. Theorem: Let $\{X_i\}_{i=1}^\infty$ be a sequence of independent identically distributed random variables and suppose that $E(X_i)=\mu$, $\operatorname{Var}(X_i)=\sigma^2<\infty$. Then, $$\sqrt{n}\frac{\frac{1}{n}\sum_{i=1}^nX_i-\mu}{\sigma}\stackrel{P}{\longrightarrow}N(0,1),\quad\text{as }n\to\infty$$ in probability, where the notation $N(\mu,\sigma^2)$ means normal distribution of mean $\mu$ and variance $\sigma^2$. Now, if we remove $\sigma$ and $\mu$, do we get $$\sqrt{n}\frac{1}{n}\sum_{i=1}^nX_i\stackrel{P}{\longrightarrow}N(\mu,\sigma^2)?$$ This seems very natural, but I cannot prove it. Is it true? I think I can prove it by removeing only $\sigma$, but I am not sure for $\mu$.","In my probability class we learned the Central Limit Theorem in the following form. Theorem: Let $\{X_i\}_{i=1}^\infty$ be a sequence of independent identically distributed random variables and suppose that $E(X_i)=\mu$, $\operatorname{Var}(X_i)=\sigma^2<\infty$. Then, $$\sqrt{n}\frac{\frac{1}{n}\sum_{i=1}^nX_i-\mu}{\sigma}\stackrel{P}{\longrightarrow}N(0,1),\quad\text{as }n\to\infty$$ in probability, where the notation $N(\mu,\sigma^2)$ means normal distribution of mean $\mu$ and variance $\sigma^2$. Now, if we remove $\sigma$ and $\mu$, do we get $$\sqrt{n}\frac{1}{n}\sum_{i=1}^nX_i\stackrel{P}{\longrightarrow}N(\mu,\sigma^2)?$$ This seems very natural, but I cannot prove it. Is it true? I think I can prove it by removeing only $\sigma$, but I am not sure for $\mu$.",,['probability']
65,Reference for entropy of the binomial distribution?,Reference for entropy of the binomial distribution?,,"The Wikipedia page Binomial distribution says that the entropy of the Binomial(n,p) is $\frac{1}{2}\log_2\left(2\pi e n p (1-p)\right) + O\left(\frac{1}{n}\right)$. What is a reference (paper or textbook) for this fact? In particular I care about the $O\left(\frac{1}{n}\right)$. It would be ideal to find a source that gives the constant in this expression. After much searching online, the closest I could find is this pdf of ""Entropy Computations Via Analytic Depoissonization"", Jacquet and Szpankowski 1997, which gives a full expansion of the error term but no hint as to how one might actually bound this error term. Also, I don't know if that would be the right paper to cite even if I deduce such a bound from their paper myself.","The Wikipedia page Binomial distribution says that the entropy of the Binomial(n,p) is $\frac{1}{2}\log_2\left(2\pi e n p (1-p)\right) + O\left(\frac{1}{n}\right)$. What is a reference (paper or textbook) for this fact? In particular I care about the $O\left(\frac{1}{n}\right)$. It would be ideal to find a source that gives the constant in this expression. After much searching online, the closest I could find is this pdf of ""Entropy Computations Via Analytic Depoissonization"", Jacquet and Szpankowski 1997, which gives a full expansion of the error term but no hint as to how one might actually bound this error term. Also, I don't know if that would be the right paper to cite even if I deduce such a bound from their paper myself.",,"['probability', 'reference-request', 'probability-distributions', 'entropy']"
66,Infinite samples from uncountable sample space,Infinite samples from uncountable sample space,,"I'm drawing one single sample from an uncountable sample space. I know the probability of sampling any given single point is zero. Now, what if I draw samples again and again and again, to infinity?  What is the probability for any single point to be eventually drawn (as time goes to infinity)? My guess is that it is still zero, since I cannot touch all the points in an continuum even if you give me infinite time.  At infinity, I will still have infinite points left to touch.  But is this reasoning correct?  Every now and then a math professor starts talking about subtleties of this kind, but where do I find related bibliography? In this case, what difference does it make to sample with replacement (after sampling a point, that point is not removed from the sample space) or without replacement (the sampled point is removed from the sample space)? Thanks!","I'm drawing one single sample from an uncountable sample space. I know the probability of sampling any given single point is zero. Now, what if I draw samples again and again and again, to infinity?  What is the probability for any single point to be eventually drawn (as time goes to infinity)? My guess is that it is still zero, since I cannot touch all the points in an continuum even if you give me infinite time.  At infinity, I will still have infinite points left to touch.  But is this reasoning correct?  Every now and then a math professor starts talking about subtleties of this kind, but where do I find related bibliography? In this case, what difference does it make to sample with replacement (after sampling a point, that point is not removed from the sample space) or without replacement (the sampled point is removed from the sample space)? Thanks!",,"['probability', 'integration', 'sampling']"
67,"If $XY$ is degenerate and $X, Y$ are independent, then $X, Y$ are degenerate.","If  is degenerate and  are independent, then  are degenerate.","XY X, Y X, Y","Let $X$ and $Y$ be independent random variables such that   $$P(XY=c)=1,$$   for some $c\neq 0$. Why are $X$ and $Y$ necessarily also degenerate? That is, I want to prove that there exists $a,b\in\mathbb{R}$ such that   $$P(X=a)=1,\quad\text{and}\quad P(X=b)=1.$$ It seems hard because there is no way in which we can tell what $a$ and $b$ will be. Any numbers such that $ab=c$ could work. So I have to prove they exist without finding them explicitly. How to do that?","Let $X$ and $Y$ be independent random variables such that   $$P(XY=c)=1,$$   for some $c\neq 0$. Why are $X$ and $Y$ necessarily also degenerate? That is, I want to prove that there exists $a,b\in\mathbb{R}$ such that   $$P(X=a)=1,\quad\text{and}\quad P(X=b)=1.$$ It seems hard because there is no way in which we can tell what $a$ and $b$ will be. Any numbers such that $ab=c$ could work. So I have to prove they exist without finding them explicitly. How to do that?",,['probability']
68,Simplest Solution for a Round Table Q,Simplest Solution for a Round Table Q,,"Company of 3 Turks, 3 British and 3 French sit at a round table. What is the probability that no two countrymans sitting next to each other? All the people are different, but sitting orders different by rotations are equal It seems like that problem A round table probability question But this is much harder because there are 3 groups, and every group of 3 people. I counted total choices as 9! / 9 = 8!, but having no ideas how easily count good choices without big ""brute force""","Company of 3 Turks, 3 British and 3 French sit at a round table. What is the probability that no two countrymans sitting next to each other? All the people are different, but sitting orders different by rotations are equal It seems like that problem A round table probability question But this is much harder because there are 3 groups, and every group of 3 people. I counted total choices as 9! / 9 = 8!, but having no ideas how easily count good choices without big ""brute force""",,"['probability', 'probability-theory']"
69,Series of independent gaussian variables and brownian motion,Series of independent gaussian variables and brownian motion,,"I am checking the proof of the construction of a brownian motion in $[0,\pi]$. We show that \begin{gather*} t \mapsto B^m_t = \frac{t}{\sqrt{\pi}}X_0 + \sqrt{\frac{2}{\pi}}\sum_{n=1}^{2^m-1}X_n \frac{\sin(nt)}{n}, \end{gather*} where $(X_n,n\in\mathbb{N})$ is a sequence of i.i.d. random variables $N(0,1)$, converges uniformly on $[0,\pi]$ with probability $1$ to a continuous function, denoted $t \mapsto B_t$, that is a standard brownian motion. When we have proved this, it remains to show that \begin{gather*} B_t = \frac{t}{\sqrt{\pi}}X_0 + \sqrt{\frac{2}{\pi}}\sum_{n=1}^{+\infty}X_n \frac{\sin(nt)}{n} \end{gather*} is indeed a brownian motion. A sentence in this proof says that ""For $s,t \in \mathbb{R}_+$, $B_{s+t} - B_s$ is gaussian as a sum of independent gaussian random variables"". Why is it true for series ?","I am checking the proof of the construction of a brownian motion in $[0,\pi]$. We show that \begin{gather*} t \mapsto B^m_t = \frac{t}{\sqrt{\pi}}X_0 + \sqrt{\frac{2}{\pi}}\sum_{n=1}^{2^m-1}X_n \frac{\sin(nt)}{n}, \end{gather*} where $(X_n,n\in\mathbb{N})$ is a sequence of i.i.d. random variables $N(0,1)$, converges uniformly on $[0,\pi]$ with probability $1$ to a continuous function, denoted $t \mapsto B_t$, that is a standard brownian motion. When we have proved this, it remains to show that \begin{gather*} B_t = \frac{t}{\sqrt{\pi}}X_0 + \sqrt{\frac{2}{\pi}}\sum_{n=1}^{+\infty}X_n \frac{\sin(nt)}{n} \end{gather*} is indeed a brownian motion. A sentence in this proof says that ""For $s,t \in \mathbb{R}_+$, $B_{s+t} - B_s$ is gaussian as a sum of independent gaussian random variables"". Why is it true for series ?",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'brownian-motion']"
70,Sum of n iid random variables,Sum of n iid random variables,,"Let $X_1,X_2,\ldots,X_n$ be iid poisson random variables with mean $\lambda$ , then it can be verified using mgf that the sum $S=\sum\limits_{i=1}^n X_i$ is also poisson with mean $n\lambda$. However, let $X_i$ be iid random variables having the pmf $$ f_X(x;\theta)=\frac{h(x)\theta^x}{\sum\limits_{y=0}^{\infty}h(y)\theta^y} ,x=0,1,2,\ldots$$ with  $\theta >0$. How do we verify that $S=\sum\limits_{i=1}^n X_i$ is also a member of the same distributional family? Using mgf seems tedious or is there a trick to calculate mgf?","Let $X_1,X_2,\ldots,X_n$ be iid poisson random variables with mean $\lambda$ , then it can be verified using mgf that the sum $S=\sum\limits_{i=1}^n X_i$ is also poisson with mean $n\lambda$. However, let $X_i$ be iid random variables having the pmf $$ f_X(x;\theta)=\frac{h(x)\theta^x}{\sum\limits_{y=0}^{\infty}h(y)\theta^y} ,x=0,1,2,\ldots$$ with  $\theta >0$. How do we verify that $S=\sum\limits_{i=1}^n X_i$ is also a member of the same distributional family? Using mgf seems tedious or is there a trick to calculate mgf?",,"['probability', 'statistics']"
71,Bernoulli event expansion in 0 to 3 occurrences cancel to first order,Bernoulli event expansion in 0 to 3 occurrences cancel to first order,,"I am working through Hamming's The Art of Probability and am having trouble with a problem in the Bernouilli Trials section. The wording is the following Expand the binomials in the probabilities of 0, 1, 2, and 3 occurrences, and show that the expansions cancel out to the next term provided $np \lt 1$. Hence if $np \ll 1$, the first term neglected in the expansion is close to the exact result for 4 or more events. I am assuming that the solution should give something like $\sum_{k = 0}^{3}B(k; n, p) = np + \mathcal{O}\left [(np)^4 \right ]$ but I can't actually get anything that cancels to the first order. Using the recursion relation of Bernouilli trials, $B(k+1; n, p) = \frac{n - k}{k+1}\frac{p}{q}B(k; n,p)$, I get $$(1 - p)^n \left (1 + \frac{np}{q} + \frac{n(n-1)}{2}\frac{p^2}{q^2} + \frac{n(n-1)(n-2)}{6}\frac{p^3}{q^3} \right)$$ Expanding this and keeping the terms 0th and first order in $np$ yields $$(1-p)^n \left (1 - \frac{1}{6}\frac{6 p^3 -29 p^2 + 33 p - 12}{(1-p)^3} + \mathcal{O}\left [(np)^2 \right ]\right )$$ Am I misunderstanding the question? I expected the second term to cancel. Edit: I guess one could use the expansion for $\exp (-np) \approx \left ((1-p)^{\frac{1}{p}} \right )^{-np}$ and then expand it in a Taylor series, $\exp (-np) = 1 - np + \frac{(np)^2}{2} - \frac{(np)^3}{6} + \mathcal{O}\left [(np)^4\right ]$. This matches the terms of the form $(np)^k$ and they do have the opposite signs, but I don't quite understand why you can get away with ignoring the $q$ in the denominator. That is, $$\begin{eqnarray} & \exp (-np) + \frac{np}{q} + \frac{n(n-1)}{2}\frac{p^2}{q^2} + \frac{n(n-1)(n-2)}{6}\frac{p^3}{q^3} \\  \approx & 1 - np + \frac{(np)^2}{2} - \frac{(np)^3}{6} + \frac{np}{q} + \frac{n^2p^2}{2q^2} + \frac{n^3p^3}{6q^3} + \mathcal{O}\left [(np)^4\right ]\\ \approx &1 + \mathcal{O}\left [(np)^4\right ] ? \end{eqnarray}$$","I am working through Hamming's The Art of Probability and am having trouble with a problem in the Bernouilli Trials section. The wording is the following Expand the binomials in the probabilities of 0, 1, 2, and 3 occurrences, and show that the expansions cancel out to the next term provided $np \lt 1$. Hence if $np \ll 1$, the first term neglected in the expansion is close to the exact result for 4 or more events. I am assuming that the solution should give something like $\sum_{k = 0}^{3}B(k; n, p) = np + \mathcal{O}\left [(np)^4 \right ]$ but I can't actually get anything that cancels to the first order. Using the recursion relation of Bernouilli trials, $B(k+1; n, p) = \frac{n - k}{k+1}\frac{p}{q}B(k; n,p)$, I get $$(1 - p)^n \left (1 + \frac{np}{q} + \frac{n(n-1)}{2}\frac{p^2}{q^2} + \frac{n(n-1)(n-2)}{6}\frac{p^3}{q^3} \right)$$ Expanding this and keeping the terms 0th and first order in $np$ yields $$(1-p)^n \left (1 - \frac{1}{6}\frac{6 p^3 -29 p^2 + 33 p - 12}{(1-p)^3} + \mathcal{O}\left [(np)^2 \right ]\right )$$ Am I misunderstanding the question? I expected the second term to cancel. Edit: I guess one could use the expansion for $\exp (-np) \approx \left ((1-p)^{\frac{1}{p}} \right )^{-np}$ and then expand it in a Taylor series, $\exp (-np) = 1 - np + \frac{(np)^2}{2} - \frac{(np)^3}{6} + \mathcal{O}\left [(np)^4\right ]$. This matches the terms of the form $(np)^k$ and they do have the opposite signs, but I don't quite understand why you can get away with ignoring the $q$ in the denominator. That is, $$\begin{eqnarray} & \exp (-np) + \frac{np}{q} + \frac{n(n-1)}{2}\frac{p^2}{q^2} + \frac{n(n-1)(n-2)}{6}\frac{p^3}{q^3} \\  \approx & 1 - np + \frac{(np)^2}{2} - \frac{(np)^3}{6} + \frac{np}{q} + \frac{n^2p^2}{2q^2} + \frac{n^3p^3}{6q^3} + \mathcal{O}\left [(np)^4\right ]\\ \approx &1 + \mathcal{O}\left [(np)^4\right ] ? \end{eqnarray}$$",,"['probability', 'probability-distributions']"
72,Expected value of inverse of a random variable,Expected value of inverse of a random variable,,"My problem is as follows: I have a point $A$ and a circle with center $B$ and radius $R$. Points $A$ and $B$ are fixed, also $A$ is outside of the circle. A random point $C$ is picked with uniform distribution in the area of disk $B$. My question is how to calculate the expected value of $AC^{-4}$. I am working with the path loss in Wireless Communication so $AC^{-4}$ measures how much energy is dissipated along the distance $AC$ My approach is to first denote $\theta$ as the angle between AB and BC then $\theta$ is uniformly distributed between $[0,2\pi]$. Denote $r$ as the distance of BC then distribution of $r$ in $[0,R]$ is $\frac{2r}{R^2}$. Using the formula $AC^2 = AB^2 + BC^2 - 2AB\times BC \times \cos\theta$ , I have \begin{align} E[AC^{-4}] & = \int_0^{2\pi}\int_0^R (AB^2 + BC^2 - 2AB\times BC \times  \cos\theta)^{-2} f_\theta f_r \, dr \, d\theta \\ & = \int_0^{2\pi}\int_0^R (AB^2 + r^2 - 2AB\times r \times \cos\theta)^{-2} \frac{1}{2\pi} \frac{2r}{R^2} \, dr \, d\theta  \end{align} However, I am unable to solve this integration. I want to ask if anyone know any method that can give me the closed-form of the above expected value. If not, then maybe an approximation method that can give a closed-form is also good. Thanks in advance.","My problem is as follows: I have a point $A$ and a circle with center $B$ and radius $R$. Points $A$ and $B$ are fixed, also $A$ is outside of the circle. A random point $C$ is picked with uniform distribution in the area of disk $B$. My question is how to calculate the expected value of $AC^{-4}$. I am working with the path loss in Wireless Communication so $AC^{-4}$ measures how much energy is dissipated along the distance $AC$ My approach is to first denote $\theta$ as the angle between AB and BC then $\theta$ is uniformly distributed between $[0,2\pi]$. Denote $r$ as the distance of BC then distribution of $r$ in $[0,R]$ is $\frac{2r}{R^2}$. Using the formula $AC^2 = AB^2 + BC^2 - 2AB\times BC \times \cos\theta$ , I have \begin{align} E[AC^{-4}] & = \int_0^{2\pi}\int_0^R (AB^2 + BC^2 - 2AB\times BC \times  \cos\theta)^{-2} f_\theta f_r \, dr \, d\theta \\ & = \int_0^{2\pi}\int_0^R (AB^2 + r^2 - 2AB\times r \times \cos\theta)^{-2} \frac{1}{2\pi} \frac{2r}{R^2} \, dr \, d\theta  \end{align} However, I am unable to solve this integration. I want to ask if anyone know any method that can give me the closed-form of the above expected value. If not, then maybe an approximation method that can give a closed-form is also good. Thanks in advance.",,"['probability', 'integration', 'geometry']"
73,sigma algebra and corresponding random variable,sigma algebra and corresponding random variable,,"We know that for a probability space $(X,F,\mu)$, if X is a random variable, then $\sigma(X)$ is a subset of F. But my question is given a sigma algebra $\tilde{F} \subset F$, can we find a r.v X, s.t. $\sigma(X) = \tilde{F}$  ? if it's not true always, under what conditions it's true?","We know that for a probability space $(X,F,\mu)$, if X is a random variable, then $\sigma(X)$ is a subset of F. But my question is given a sigma algebra $\tilde{F} \subset F$, can we find a r.v X, s.t. $\sigma(X) = \tilde{F}$  ? if it's not true always, under what conditions it's true?",,"['probability', 'measure-theory']"
74,Frankie and Johnny game. What should Johnny strategy if he wants to minimize his expected loss?,Frankie and Johnny game. What should Johnny strategy if he wants to minimize his expected loss?,,"Frankie and Johnny play the following game. Frankie selects a number at random from the interval $[a, b]$. Johnny, not knowing Frankies number, is to pick a second number from that same inverval and pay Frankie an amount, W, equal to the squared difference between the two [so $0  W  (b  a)^2]$. What should be Johnnys strategy if he wants to minimize his expected loss? Attempt: Let $Y$ be Frankie's choice.  Then Johnny wants to choose $k$ so that $E(Y - k)^2$ is minimize. Can someone please help me? I am having trouble. The answer is Johnny should pick $(a+b)/2$ to minimize his loss.","Frankie and Johnny play the following game. Frankie selects a number at random from the interval $[a, b]$. Johnny, not knowing Frankies number, is to pick a second number from that same inverval and pay Frankie an amount, W, equal to the squared difference between the two [so $0  W  (b  a)^2]$. What should be Johnnys strategy if he wants to minimize his expected loss? Attempt: Let $Y$ be Frankie's choice.  Then Johnny wants to choose $k$ so that $E(Y - k)^2$ is minimize. Can someone please help me? I am having trouble. The answer is Johnny should pick $(a+b)/2$ to minimize his loss.",,"['probability', 'random-variables', 'expectation']"
75,Binomial/Poisson distribution question,Binomial/Poisson distribution question,,"Someone asked me to help with assignment, but I am confused about the question, so basically, it is really easy: Batches of 100 components have a mean number of 5 defects per batch. What is the probability at least 9 defective component in a batch? Calculate using (i) Binomial distribution (ii) Poisson distribution (iii) Normal approximation to binomial (iv) Poisson approximation to binomial (v) Briefly discuss how good the approximations to the binomial distribution are, in reference to (ii), (iii), (iv) (i), (iii), (iv) are easy and so is (v) once I got the number. I do not understand what it means by calculating using Poisson distribution? Clearly this is not Poisson distributed by the way it is described.... If I see batches of 100 as a kind of 'time' of arrival (like in a Poisson arrival), then part (ii) gives Poisson(5), which is the same as part (iv) anyway, so I do not follow...","Someone asked me to help with assignment, but I am confused about the question, so basically, it is really easy: Batches of 100 components have a mean number of 5 defects per batch. What is the probability at least 9 defective component in a batch? Calculate using (i) Binomial distribution (ii) Poisson distribution (iii) Normal approximation to binomial (iv) Poisson approximation to binomial (v) Briefly discuss how good the approximations to the binomial distribution are, in reference to (ii), (iii), (iv) (i), (iii), (iv) are easy and so is (v) once I got the number. I do not understand what it means by calculating using Poisson distribution? Clearly this is not Poisson distributed by the way it is described.... If I see batches of 100 as a kind of 'time' of arrival (like in a Poisson arrival), then part (ii) gives Poisson(5), which is the same as part (iv) anyway, so I do not follow...",,['probability']
76,Show that $P(X=c)=1 $for some constant c,Show that for some constant c,P(X=c)=1 ,"Suppose $X$ and $Y$ are independent random variables, also $X$ and $X-Y$ are independent. Prove that $$P(X=c)=1$$ for some constant c. I tried using moment generating function, please give me some hints.","Suppose $X$ and $Y$ are independent random variables, also $X$ and $X-Y$ are independent. Prove that $$P(X=c)=1$$ for some constant c. I tried using moment generating function, please give me some hints.",,"['probability', 'statistics']"
77,What is the expected value of the mean of the highest $m$ numbers in a population of $N$ normally distributed random variables?,What is the expected value of the mean of the highest  numbers in a population of  normally distributed random variables?,m N,"Suppose that I randomly generate $N$ numbers according to the standard normal distribution, $\mathcal{N}(0,1)$.  Then suppose I pick the highest $m$ numbers, $x_1\leq x_2 \leq \cdots \leq x_m$.  What is the expected value of the (arithmetic) average of $x_1,\dotsc , x_m$? Forgive me, I couldn't get my probability theory phrasing 100% accurate here.  Hopefully my meaning is clear. EDIT: A better attempt at proper phrasing might be, If $a_1,\dotsc , a_N$ are real numbers and $m<N$, define $y_m(a_1,\dotsc , a_N)$ to be the average of the top $m$ values among $a_1,\ldots ,a_N$.  If $X_1,\dotsc ,X_N\sim \mathcal{N}(0,1)$ are i.i.d. r.v.'s, define $Y=y_m(X_1,\dotsc ,X_N)$.  What is $\mathbb{E}(Y)$? (Would be greatful foro suggestions on how to improve the formal statement here.)","Suppose that I randomly generate $N$ numbers according to the standard normal distribution, $\mathcal{N}(0,1)$.  Then suppose I pick the highest $m$ numbers, $x_1\leq x_2 \leq \cdots \leq x_m$.  What is the expected value of the (arithmetic) average of $x_1,\dotsc , x_m$? Forgive me, I couldn't get my probability theory phrasing 100% accurate here.  Hopefully my meaning is clear. EDIT: A better attempt at proper phrasing might be, If $a_1,\dotsc , a_N$ are real numbers and $m<N$, define $y_m(a_1,\dotsc , a_N)$ to be the average of the top $m$ values among $a_1,\ldots ,a_N$.  If $X_1,\dotsc ,X_N\sim \mathcal{N}(0,1)$ are i.i.d. r.v.'s, define $Y=y_m(X_1,\dotsc ,X_N)$.  What is $\mathbb{E}(Y)$? (Would be greatful foro suggestions on how to improve the formal statement here.)",,"['probability', 'statistics', 'probability-theory']"
78,Simple question about weak law of large number with characteristic function version,Simple question about weak law of large number with characteristic function version,,"I was reading a textbook about showing the following Weak Law of Large Number but I stuck in some intermediate steps. Here is the statement I work with Let $\{X_i\}$ be i.i.d. random variables with same characteristic function $\phi$, and $\phi(0) = 1$, $\phi'(0)=ai$. Then, $$\frac{S_n}{n} \rightarrow a \;\;\text{ in probability}$$ where $S_n := X_1 + X_2 + ... + X_n.$ My approach : If I can show $\phi_{S_n/n}(t) \rightarrow e^{iat} : = \phi_\infty(t)$ as $n \rightarrow \infty$ for all $t$, and, $\lim_{t \rightarrow 0}\phi_\infty(t) =1$, then the associated sequence of distributions $\mu_n$ (whose characteristic function is $\phi_{S_n/n}$) converges to $\mu$ (whose characteristic function is $\phi_\infty$); Then I can infer that $S_n/n \rightarrow a$ in distribution and then since $a$ is constant, can further conclude $S_n/n \rightarrow a$ in probability. Therefore, I first compute the characteristic function and using the i.i.d. fact to get $$ {\phi _{{S_n}/n}} = E[{e^{it\frac{{{S_n}}}{n}}}] = E[{e^{i\frac{t}{n}{S_n}}}] = E[{e^{i\frac{t}{n}\left( {{X_1} + ...{X_n}} \right)}}] = \prod\limits_{i = 1}^n {\underbrace {E[{e^{i\frac{t}{n}{X_i}}}]}_{ = \phi \left( {\frac{t}{n}} \right)}}  = {\left[ {\phi \left( {\frac{t}{n}} \right)} \right]^n} $$ But I stuck to go further and show  $$\phi_{S_n/n}(t) = {\left[ {\phi \left( {\frac{t}{n}} \right)} \right]^n}   \rightarrow e^{iat}...$$ Any thought is appreciated.","I was reading a textbook about showing the following Weak Law of Large Number but I stuck in some intermediate steps. Here is the statement I work with Let $\{X_i\}$ be i.i.d. random variables with same characteristic function $\phi$, and $\phi(0) = 1$, $\phi'(0)=ai$. Then, $$\frac{S_n}{n} \rightarrow a \;\;\text{ in probability}$$ where $S_n := X_1 + X_2 + ... + X_n.$ My approach : If I can show $\phi_{S_n/n}(t) \rightarrow e^{iat} : = \phi_\infty(t)$ as $n \rightarrow \infty$ for all $t$, and, $\lim_{t \rightarrow 0}\phi_\infty(t) =1$, then the associated sequence of distributions $\mu_n$ (whose characteristic function is $\phi_{S_n/n}$) converges to $\mu$ (whose characteristic function is $\phi_\infty$); Then I can infer that $S_n/n \rightarrow a$ in distribution and then since $a$ is constant, can further conclude $S_n/n \rightarrow a$ in probability. Therefore, I first compute the characteristic function and using the i.i.d. fact to get $$ {\phi _{{S_n}/n}} = E[{e^{it\frac{{{S_n}}}{n}}}] = E[{e^{i\frac{t}{n}{S_n}}}] = E[{e^{i\frac{t}{n}\left( {{X_1} + ...{X_n}} \right)}}] = \prod\limits_{i = 1}^n {\underbrace {E[{e^{i\frac{t}{n}{X_i}}}]}_{ = \phi \left( {\frac{t}{n}} \right)}}  = {\left[ {\phi \left( {\frac{t}{n}} \right)} \right]^n} $$ But I stuck to go further and show  $$\phi_{S_n/n}(t) = {\left[ {\phi \left( {\frac{t}{n}} \right)} \right]^n}   \rightarrow e^{iat}...$$ Any thought is appreciated.",,"['probability', 'probability-theory']"
79,"What does it mean for a random variable to ""admit"" a distribution?","What does it mean for a random variable to ""admit"" a distribution?",,"Can someone explain the word ""admit"" and explain what would happen if it does not admit a distribution?","Can someone explain the word ""admit"" and explain what would happen if it does not admit a distribution?",,['probability']
80,Show the following definition does not give a $\sigma$-addtive measure pathwisely,Show the following definition does not give a -addtive measure pathwisely,\sigma,"Given the space of all square-integral functions over $[0,1]$: $L^2([0,1], \mathcal{B}([0,1]), m)$ and a Brownian motion $W_t$ defined on the probability space $(\Omega, \mathcal{F}, P)$, we define $$h(A) = \int_0^1 1_A(t)dW_t$$ for all $A \in \mathcal{B}([0,1])$. Then for disjoint $(A_n)_{n\geq 1}$, we know that $$h\left(\bigcup\limits_n A_n\right) = \sum_n h(A_n)$$ in $L^2$ and almost surely It is well known that despite the above identity, $h$ does not define a signed measure pathwisely because although $h\left(\bigcup\limits_n A_n\right) = \sum\limits_n h(A_n)$ almost surely, the set of exceptional $\omega$s depends on the sequence $(A_n)$. I learned about this fact a long time ago, but I am still a bit confused. The above statement only says that since ""the exceptional set of $\omega$s depends on the sequence $A_n$"", we didn't manage to prove $h$ is a measure pathwisely. But why is it not possible that ""by chance"" all the exceptional $\omega$s turns out to be in a negligeable set so we can still define a pathwise measure for almost every $\omega$? In summary, I am asking for help to prove, no matter how we modify $h(A)$ for negligible $\omega$s, there is always a set $S$ of positive probability, such that for all $\omega \in S$, we can find a sequence of disjoint $A_n \in \mathcal{B}([0,1])$ such that $h\left(\bigcup\limits_n A_n\right)(\omega) \neq \sum\limits_n h(A_n)(\omega)$.","Given the space of all square-integral functions over $[0,1]$: $L^2([0,1], \mathcal{B}([0,1]), m)$ and a Brownian motion $W_t$ defined on the probability space $(\Omega, \mathcal{F}, P)$, we define $$h(A) = \int_0^1 1_A(t)dW_t$$ for all $A \in \mathcal{B}([0,1])$. Then for disjoint $(A_n)_{n\geq 1}$, we know that $$h\left(\bigcup\limits_n A_n\right) = \sum_n h(A_n)$$ in $L^2$ and almost surely It is well known that despite the above identity, $h$ does not define a signed measure pathwisely because although $h\left(\bigcup\limits_n A_n\right) = \sum\limits_n h(A_n)$ almost surely, the set of exceptional $\omega$s depends on the sequence $(A_n)$. I learned about this fact a long time ago, but I am still a bit confused. The above statement only says that since ""the exceptional set of $\omega$s depends on the sequence $A_n$"", we didn't manage to prove $h$ is a measure pathwisely. But why is it not possible that ""by chance"" all the exceptional $\omega$s turns out to be in a negligeable set so we can still define a pathwise measure for almost every $\omega$? In summary, I am asking for help to prove, no matter how we modify $h(A)$ for negligible $\omega$s, there is always a set $S$ of positive probability, such that for all $\omega \in S$, we can find a sequence of disjoint $A_n \in \mathcal{B}([0,1])$ such that $h\left(\bigcup\limits_n A_n\right)(\omega) \neq \sum\limits_n h(A_n)(\omega)$.",,"['probability', 'probability-theory', 'stochastic-integrals']"
81,Product of sequence of uniform integrable random variables are uniformly integrable?,Product of sequence of uniform integrable random variables are uniformly integrable?,,"If $\{X_i\}$ for $i \in I $ and $\{Y_j\}$ for $j \in J$ are uniformly integrable.Then prove that, $\{X_i+Y_j\}$ for $(i,j) \in I \times J$ is uniformly integrable.What about $ \{X_iY_j\} $ for $(i,j) \in I \times J$ ?","If $\{X_i\}$ for $i \in I $ and $\{Y_j\}$ for $j \in J$ are uniformly integrable.Then prove that, $\{X_i+Y_j\}$ for $(i,j) \in I \times J$ is uniformly integrable.What about $ \{X_iY_j\} $ for $(i,j) \in I \times J$ ?",,"['probability', 'random-variables', 'uniform-integrability']"
82,Probability of 1 billion monkeys typing a sentence if they type for 10 billion years,Probability of 1 billion monkeys typing a sentence if they type for 10 billion years,,"Suppose a billion monkeys type on word processors at a rate of 10 symbols per second. Assume that the word processors produce 27 symbols, namely, 26 letters of the English alphabet and a space. These monkeys type for 10 billion years. What is the probability that they can type the first sentence of Lincolns Gettysburg Address? Four score and seven years ago our fathers brought forth on this continent a new nation conceived in liberty and dedicated to the proposition that all men are created equal. Hint: Look up Booles inequality to provide an upper bound for the probability! This is a homework question. I just want some pointers how to move forward from what I have done so far. Below I will explain my research so far. First I calculated the probability of the monkey 1 typing the sentence ( this question helped me do that); let's say that probability is $p$ : $$P(\text{Monkey 1 types our sentence}) = P(M_1)= p$$ Now let's say that the monkeys are labeled $M_1$ to $M_{10^9}$ , so given the hint in the question I calculated the upper bound for the probabilities of union of all $P(M_i)$ (the probability that i-th monkey types the sentence) using Boole's inequality. Since $P(M_i)=P(M_1)=p$ , $$ P\left(\bigcup_i M_i\right) \le \sum_{i=1}^{10^9}P(M_i)=\sum^{10^9} p=10^9 \,p$$ Am I correct till this point? If yes, what can I do more in this question? I tried to study Bonferroni inequality for lower bounds but was unsuccessful to obtain a logical step. If not, how to approach the problem? As I am new, edit suggestions will also be appreciated.","Suppose a billion monkeys type on word processors at a rate of 10 symbols per second. Assume that the word processors produce 27 symbols, namely, 26 letters of the English alphabet and a space. These monkeys type for 10 billion years. What is the probability that they can type the first sentence of Lincolns Gettysburg Address? Four score and seven years ago our fathers brought forth on this continent a new nation conceived in liberty and dedicated to the proposition that all men are created equal. Hint: Look up Booles inequality to provide an upper bound for the probability! This is a homework question. I just want some pointers how to move forward from what I have done so far. Below I will explain my research so far. First I calculated the probability of the monkey 1 typing the sentence ( this question helped me do that); let's say that probability is : Now let's say that the monkeys are labeled to , so given the hint in the question I calculated the upper bound for the probabilities of union of all (the probability that i-th monkey types the sentence) using Boole's inequality. Since , Am I correct till this point? If yes, what can I do more in this question? I tried to study Bonferroni inequality for lower bounds but was unsuccessful to obtain a logical step. If not, how to approach the problem? As I am new, edit suggestions will also be appreciated.","p P(\text{Monkey 1 types our sentence}) = P(M_1)= p M_1 M_{10^9} P(M_i) P(M_i)=P(M_1)=p  P\left(\bigcup_i M_i\right) \le \sum_{i=1}^{10^9}P(M_i)=\sum^{10^9} p=10^9 \,p","['probability', 'probability-theory']"
83,Probability of a minimum sum of card values when drawing cards from a custom deck,Probability of a minimum sum of card values when drawing cards from a custom deck,,"Apologies if this question has been answered -- I tried searching for an answer but wasn't sure what terminology to use. Suppose I have a deck of cards, consisting of $n_1$ ones, $n_2$ twos, etc. (where each $n_x$ can be a different number). I draw $k$ cards from the deck, and I want to know the probability that they will add up to at least $x$. I'm looking for a general-purpose formula that I can use for different amounts and values of $n$s, and different values of $k$ and $x$. Example: I have a deck of 7 ones, 4 twos, 13 threes, and 9 fours.  What is the   probability of drawing 6 cards and having them add up to at least 13? I have a basic knowledge of probability, but this problem has a few too many variables for me to work it out.  An explanation of the solution would be most welcome, if anyone is willing and able.","Apologies if this question has been answered -- I tried searching for an answer but wasn't sure what terminology to use. Suppose I have a deck of cards, consisting of $n_1$ ones, $n_2$ twos, etc. (where each $n_x$ can be a different number). I draw $k$ cards from the deck, and I want to know the probability that they will add up to at least $x$. I'm looking for a general-purpose formula that I can use for different amounts and values of $n$s, and different values of $k$ and $x$. Example: I have a deck of 7 ones, 4 twos, 13 threes, and 9 fours.  What is the   probability of drawing 6 cards and having them add up to at least 13? I have a basic knowledge of probability, but this problem has a few too many variables for me to work it out.  An explanation of the solution would be most welcome, if anyone is willing and able.",,"['probability', 'summation', 'card-games']"
84,Infinite Tree Probability Question,Infinite Tree Probability Question,,Suppose I have 10 dollars and I'm able to make fair 50/50 bets like flipping a coin.  Now suppose each bet is for 1 dollar.  What is the probability that if I keep making bets until I hit 0 dollars that the highest amount of money reached is k dollars? This may help:  In the past I solved a similar problem I was wondering about of the form what is the probability that I will hit k dollars before I hit 0 dollars by drawing it out and seeing that the possibilities formed an infinite tree and that an equation could be formed by creating an equation which expresses the probability sought in terms of itself. What I'm asking above is not just that I would reach k dollars but that k dollars would be the highest level if I kept betting until I hit 0.,Suppose I have 10 dollars and I'm able to make fair 50/50 bets like flipping a coin.  Now suppose each bet is for 1 dollar.  What is the probability that if I keep making bets until I hit 0 dollars that the highest amount of money reached is k dollars? This may help:  In the past I solved a similar problem I was wondering about of the form what is the probability that I will hit k dollars before I hit 0 dollars by drawing it out and seeing that the possibilities formed an infinite tree and that an equation could be formed by creating an equation which expresses the probability sought in terms of itself. What I'm asking above is not just that I would reach k dollars but that k dollars would be the highest level if I kept betting until I hit 0.,,['probability']
85,Conditional return time of simple random walk,Conditional return time of simple random walk,,"Consider a simple symmetric random walk on $\mathbb{Z}$, $(S_t)_{t \geq 0}$. Call $\tau_k = \min\{t \in \mathbb{N}\, : \, \, S_t =k \}$, the hitting time of $k \in \mathbb{N}$. Call $\tau^* = \min\{t >0\, : \, \, S_t =0 \}$, the return time to the origin. Let $c<1$ be a positive constant. Is there a way to compute the next formula explicitly? $$\sum_{k=1}^{\infty} \sum\limits_{j=1}^{\infty} P ( \tau_k = j \, | \, \tau_k < \tau^*) \cdot c^{j-1}$$","Consider a simple symmetric random walk on $\mathbb{Z}$, $(S_t)_{t \geq 0}$. Call $\tau_k = \min\{t \in \mathbb{N}\, : \, \, S_t =k \}$, the hitting time of $k \in \mathbb{N}$. Call $\tau^* = \min\{t >0\, : \, \, S_t =0 \}$, the return time to the origin. Let $c<1$ be a positive constant. Is there a way to compute the next formula explicitly? $$\sum_{k=1}^{\infty} \sum\limits_{j=1}^{\infty} P ( \tau_k = j \, | \, \tau_k < \tau^*) \cdot c^{j-1}$$",,"['probability', 'probability-distributions', 'random-variables', 'markov-chains', 'random-walk']"
86,Deducing an optimal gambling strategy (using martingales).,Deducing an optimal gambling strategy (using martingales).,,"Apologies in advance for the length, I tried being precise. Suppose a game where in each turn you can gamble a certain amount of money on the result of a fair coin toss. If the coin comes out tails you lose what you gambled and if it comes out heads you gain double what you gambled, this goes on for $n$ turns. To formalize this let $X_{1},X_{2},...$ be i.i.d r.vs such that $\mathbb{P}\left(X_{i}=2\right)=\mathbb{P}\left(X_{i}=-1\right)=\frac{1}{2}$ and let $\mathcal{F}_{k}=\sigma\left(X_{1},...,X_{k}\right)$ be the natural filtration. A gambling strategy is a sequence of non-negative r.vs $C_{1},C_{2},...$ which are previsible relative to $\mathcal{F}$ (that is $C_{k}$ is $\mathcal{F}_{k-1}$-measurable). Your initial wealth is $Y_{0}=1$ and for each $1\leq k \leq n$ your accumulated wealth is $$Y_{k}=1+\sum_{j=1}^{k}C_{j}X_{j}$$ A gambling strategy is said to be: Legal if $C_{k}\leq Y_{k-1}$ for all $k$. Conservative if $C_{k}\leq 0.99Y_{k-1}$ for all $k$ Now for the actual question: Show that the legal strategy that maximizes $\mathbb{E}\left[\log Y_{n}\right]$ is always gambling a constant proportion $A$ of the current wealth and using this strategy there is a constant $B$ such that $\mathbb{E}\left[\log Y_{n}\right]=Bn$. Denote $M_{k}=\log\left(Y_{k}\right)-Bk$ ($B$ is an arbitrary constant), show that there is a $K<\infty$ such that under any conservative strategy $\left|M_{i}-M_{i-1}\right|<K$ almost surely. Attempted solution: For the first question I worked in a sort of recursive fashion. Suppose we are at time $n-1$ with $Y_{n-1}=x$ and we need to choose the ratio A. Define: $$V_{1}\left(x\right):=\mathbb{E}_{A}\left[\ln\left(Y_{n}\right)|Y_{n-1}=x\right]$$ By direct calculation we get: $$V_{1}\left(x,A\right)=\frac{1}{2}\mathbb{E}\left[\ln\left(\left(1+2A\right)x\right)\right]+\frac{1}{2}\mathbb{E}\left[\ln\left(\left(1-A\right)x\right)\right] =\frac{1}{2}\ln\left(\left(1+2A\right)x\right)+\frac{1}{2}\ln\left(\left(1-A\right)x\right)=\frac{1}{2}\left(\ln\left(1+2A\right)+\ln\left(1-A\right)\right)+\ln\left(x\right)  $$ Derivating twice gives: $$\frac{\partial}{\partial A}V_{1}\left(x,A\right)=\frac{4A-1}{2\left(A-1\right)\left(2A+1\right)}\qquad\frac{\partial^{2}}{\partial A^{2}}V_{1}\left(x,A\right)=\frac{-8A^{2}+4A-5}{2\left(A-1\right)^{2}\left(2A+1\right)^{2}}  $$  Which shows that $A=\frac{1}{4} $ is unique maximum of $V_{1}$ for which: $$V_{1}\left(x,\frac{1}{4}\right)=\frac{1}{2}\left(\ln\left(1\frac{1}{2}\right)+\ln\left(\frac{3}{4}\right)\right)+\ln\left(x\right)=\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(x\right)$$ Now by similar logic if we are at time $n-2$ and we got $Y_{n-2}=x$   to invest: $$V_{2}\left(x,A\right):=\mathbb{E}_{A}\left[\ln\left(Y_{n}\right)|Y_{n-2}=x\right]=\frac{1}{2}\mathbb{E}_{A^{'}}\left[\ln\left(Y_{n}\right)|Y_{n-1}=\left(1+2A\right)x\right]+\frac{1}{2}\mathbb{E}_{A^{'}}\left[\ln\left(Y_{n}\right)|Y_{n-1}=\left(1-A\right)x\right] =\frac{1}{2}V_{1}\left(\left(1+2A\right)x,A^{'}\right)+\frac{1}{2}V_{1}\left(\left(1-A\right)x,A^{'}\right)\overbrace{\leq}^{1}\frac{1}{2}\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(\left(1+2A\right)x\right)\right)+\frac{1}{2}\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(\left(1-A\right)x\right)\right) =\frac{1}{2}\ln\left(\left(1+2A\right)x\right)+\frac{1}{2}\ln\left(\left(1-2A\right)x\right)+\frac{1}{2}\ln\left(\frac{9}{8}\right)=\underbrace{\frac{1}{2}\ln\left(1+2A\right)+\frac{1}{2}\ln\left(1-A\right)+\ln\left(x\right)+\frac{1}{2}\ln\left(\frac{9}{8}\right)}_{*}  $$ Where the marked inequality is a result of $A^{'}=\frac{1}{4}$ being optimal for time $n-1$. Maximizing the new equaiton * is exactly the same as maximizing the equation we had at time $n-1$ and it is maximized again for $A=\frac{1}{4}$ for which we get $$V_{2}\left(x,\frac{1}{4}\right)=\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(x\right)+\frac{1}{2}\ln\left(\frac{9}{8}\right)=2\cdot\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)\right)+\ln\left(x\right)$$ Continuing this inductively we obtain: $$\mathbb{E}\left[\ln\left(Y_{n}\right)\right]=n\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)\right)+\ln\left(Y_{0}\right)=n\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)\right)  $$  This is indeed of the form $\mathbb{E}\left[\ln\left(Y_{n}\right)\right]=Bn$   for $B=\frac{1}{2}\ln\left(\frac{9}{8}\right)$. Additionally, I tried writing this ""solution path"" using conditioning on $\mathcal{\mathcal{F}}_{n-1}$, that is by doing a similar analysis for $\mathbb{E}_{A}\left[\ln\left(Y_{n}\right)|\mathcal{F}_{n-1}\right]$ which seems more formally accurate however I couldn't make it work out. As for the second question, I showed that $M_{k}$ is a supermartingale and I know that if it had bounded differences then relative to a well chosen stopping time the Optional Stopping Theorem could be applied. Is it possible to deduce that $M_{k}$ has bounded differences by way of contradiction by showing some contradiction to the Optional Stopping Theorem if the opposite was true? If so what stopping time should be used? Sorry for the lengthy read, help would be very appreciated.","Apologies in advance for the length, I tried being precise. Suppose a game where in each turn you can gamble a certain amount of money on the result of a fair coin toss. If the coin comes out tails you lose what you gambled and if it comes out heads you gain double what you gambled, this goes on for $n$ turns. To formalize this let $X_{1},X_{2},...$ be i.i.d r.vs such that $\mathbb{P}\left(X_{i}=2\right)=\mathbb{P}\left(X_{i}=-1\right)=\frac{1}{2}$ and let $\mathcal{F}_{k}=\sigma\left(X_{1},...,X_{k}\right)$ be the natural filtration. A gambling strategy is a sequence of non-negative r.vs $C_{1},C_{2},...$ which are previsible relative to $\mathcal{F}$ (that is $C_{k}$ is $\mathcal{F}_{k-1}$-measurable). Your initial wealth is $Y_{0}=1$ and for each $1\leq k \leq n$ your accumulated wealth is $$Y_{k}=1+\sum_{j=1}^{k}C_{j}X_{j}$$ A gambling strategy is said to be: Legal if $C_{k}\leq Y_{k-1}$ for all $k$. Conservative if $C_{k}\leq 0.99Y_{k-1}$ for all $k$ Now for the actual question: Show that the legal strategy that maximizes $\mathbb{E}\left[\log Y_{n}\right]$ is always gambling a constant proportion $A$ of the current wealth and using this strategy there is a constant $B$ such that $\mathbb{E}\left[\log Y_{n}\right]=Bn$. Denote $M_{k}=\log\left(Y_{k}\right)-Bk$ ($B$ is an arbitrary constant), show that there is a $K<\infty$ such that under any conservative strategy $\left|M_{i}-M_{i-1}\right|<K$ almost surely. Attempted solution: For the first question I worked in a sort of recursive fashion. Suppose we are at time $n-1$ with $Y_{n-1}=x$ and we need to choose the ratio A. Define: $$V_{1}\left(x\right):=\mathbb{E}_{A}\left[\ln\left(Y_{n}\right)|Y_{n-1}=x\right]$$ By direct calculation we get: $$V_{1}\left(x,A\right)=\frac{1}{2}\mathbb{E}\left[\ln\left(\left(1+2A\right)x\right)\right]+\frac{1}{2}\mathbb{E}\left[\ln\left(\left(1-A\right)x\right)\right] =\frac{1}{2}\ln\left(\left(1+2A\right)x\right)+\frac{1}{2}\ln\left(\left(1-A\right)x\right)=\frac{1}{2}\left(\ln\left(1+2A\right)+\ln\left(1-A\right)\right)+\ln\left(x\right)  $$ Derivating twice gives: $$\frac{\partial}{\partial A}V_{1}\left(x,A\right)=\frac{4A-1}{2\left(A-1\right)\left(2A+1\right)}\qquad\frac{\partial^{2}}{\partial A^{2}}V_{1}\left(x,A\right)=\frac{-8A^{2}+4A-5}{2\left(A-1\right)^{2}\left(2A+1\right)^{2}}  $$  Which shows that $A=\frac{1}{4} $ is unique maximum of $V_{1}$ for which: $$V_{1}\left(x,\frac{1}{4}\right)=\frac{1}{2}\left(\ln\left(1\frac{1}{2}\right)+\ln\left(\frac{3}{4}\right)\right)+\ln\left(x\right)=\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(x\right)$$ Now by similar logic if we are at time $n-2$ and we got $Y_{n-2}=x$   to invest: $$V_{2}\left(x,A\right):=\mathbb{E}_{A}\left[\ln\left(Y_{n}\right)|Y_{n-2}=x\right]=\frac{1}{2}\mathbb{E}_{A^{'}}\left[\ln\left(Y_{n}\right)|Y_{n-1}=\left(1+2A\right)x\right]+\frac{1}{2}\mathbb{E}_{A^{'}}\left[\ln\left(Y_{n}\right)|Y_{n-1}=\left(1-A\right)x\right] =\frac{1}{2}V_{1}\left(\left(1+2A\right)x,A^{'}\right)+\frac{1}{2}V_{1}\left(\left(1-A\right)x,A^{'}\right)\overbrace{\leq}^{1}\frac{1}{2}\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(\left(1+2A\right)x\right)\right)+\frac{1}{2}\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(\left(1-A\right)x\right)\right) =\frac{1}{2}\ln\left(\left(1+2A\right)x\right)+\frac{1}{2}\ln\left(\left(1-2A\right)x\right)+\frac{1}{2}\ln\left(\frac{9}{8}\right)=\underbrace{\frac{1}{2}\ln\left(1+2A\right)+\frac{1}{2}\ln\left(1-A\right)+\ln\left(x\right)+\frac{1}{2}\ln\left(\frac{9}{8}\right)}_{*}  $$ Where the marked inequality is a result of $A^{'}=\frac{1}{4}$ being optimal for time $n-1$. Maximizing the new equaiton * is exactly the same as maximizing the equation we had at time $n-1$ and it is maximized again for $A=\frac{1}{4}$ for which we get $$V_{2}\left(x,\frac{1}{4}\right)=\frac{1}{2}\ln\left(\frac{9}{8}\right)+\ln\left(x\right)+\frac{1}{2}\ln\left(\frac{9}{8}\right)=2\cdot\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)\right)+\ln\left(x\right)$$ Continuing this inductively we obtain: $$\mathbb{E}\left[\ln\left(Y_{n}\right)\right]=n\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)\right)+\ln\left(Y_{0}\right)=n\left(\frac{1}{2}\ln\left(\frac{9}{8}\right)\right)  $$  This is indeed of the form $\mathbb{E}\left[\ln\left(Y_{n}\right)\right]=Bn$   for $B=\frac{1}{2}\ln\left(\frac{9}{8}\right)$. Additionally, I tried writing this ""solution path"" using conditioning on $\mathcal{\mathcal{F}}_{n-1}$, that is by doing a similar analysis for $\mathbb{E}_{A}\left[\ln\left(Y_{n}\right)|\mathcal{F}_{n-1}\right]$ which seems more formally accurate however I couldn't make it work out. As for the second question, I showed that $M_{k}$ is a supermartingale and I know that if it had bounded differences then relative to a well chosen stopping time the Optional Stopping Theorem could be applied. Is it possible to deduce that $M_{k}$ has bounded differences by way of contradiction by showing some contradiction to the Optional Stopping Theorem if the opposite was true? If so what stopping time should be used? Sorry for the lengthy read, help would be very appreciated.",,"['probability', 'probability-theory', 'stochastic-processes', 'martingales']"
87,Gamma distribution Norming constant for extreme minima,Gamma distribution Norming constant for extreme minima,,"the norming constants for extreme maxima of Gamma distribution is known and is give in link.springer.com/article/10.1007/s10687-010-0125-3. I would like to know is there reference or paper that states the norming constant for the extreme minima. The exact problem is stated below: Let the random variable $Y_n$ be $Y_n=max(a_1,a_{2},\cdots, a_n)$ and $X_{n}$ be $X_n=min(a_1,a_{2},\cdots, a_n)$, where $a_i$s are Gamma random variables. It is well-known in extreme value theory that the CDF of $X_n$ and $Y_n$ converges (in distribution) as follows: $$\lim_{n\rightarrow \infty}~~~Pr\left(\frac{Y_n-\mu}{\sigma}\leq x\right)\rightarrow G_M(x)~~~~~~~~~~(P1)$$ $$\lim_{n\rightarrow \infty}~~~Pr\left(\frac{X_n-\mu_{1}}{\sigma_{1}}\leq x\right)\rightarrow W_m(x)~~~~~~~~~~(P2)$$ where $G_M(x)$ is the Gumbel and $W_m(x)$ is the Weibull CDFs for maxima and minima respectively and the values of $\mu$ and $\sigma$ can be given explicitly (see for example link.springer.com/article/10.1007/s10687-010-0125-3). My question is: Is there a literature that provides the norming constants $\mu_1$ and $\sigma_1$ for the minima?  will appreciate your answer and possible references.","the norming constants for extreme maxima of Gamma distribution is known and is give in link.springer.com/article/10.1007/s10687-010-0125-3. I would like to know is there reference or paper that states the norming constant for the extreme minima. The exact problem is stated below: Let the random variable $Y_n$ be $Y_n=max(a_1,a_{2},\cdots, a_n)$ and $X_{n}$ be $X_n=min(a_1,a_{2},\cdots, a_n)$, where $a_i$s are Gamma random variables. It is well-known in extreme value theory that the CDF of $X_n$ and $Y_n$ converges (in distribution) as follows: $$\lim_{n\rightarrow \infty}~~~Pr\left(\frac{Y_n-\mu}{\sigma}\leq x\right)\rightarrow G_M(x)~~~~~~~~~~(P1)$$ $$\lim_{n\rightarrow \infty}~~~Pr\left(\frac{X_n-\mu_{1}}{\sigma_{1}}\leq x\right)\rightarrow W_m(x)~~~~~~~~~~(P2)$$ where $G_M(x)$ is the Gumbel and $W_m(x)$ is the Weibull CDFs for maxima and minima respectively and the values of $\mu$ and $\sigma$ can be given explicitly (see for example link.springer.com/article/10.1007/s10687-010-0125-3). My question is: Is there a literature that provides the norming constants $\mu_1$ and $\sigma_1$ for the minima?  will appreciate your answer and possible references.",,"['probability', 'statistics', 'probability-distributions', 'order-statistics']"
88,What is the probability of a specific sequence of 11 digits occurring in a random sequence of one billion digits?,What is the probability of a specific sequence of 11 digits occurring in a random sequence of one billion digits?,,"This isn't homework, I'm actually (please don't ask me why) wondering how likely it is that any particular 11-digit telephone number will occur in the first billion digits of pi. My probability course was way too long ago, and the idea of creating a monte carlo simulation to figure this out seems a little extreme! (And I realize that pi is not a random number, I'm just assuming that the digits are sequenced in a randomlike way.)","This isn't homework, I'm actually (please don't ask me why) wondering how likely it is that any particular 11-digit telephone number will occur in the first billion digits of pi. My probability course was way too long ago, and the idea of creating a monte carlo simulation to figure this out seems a little extreme! (And I realize that pi is not a random number, I'm just assuming that the digits are sequenced in a randomlike way.)",,"['probability', 'random', 'pi']"
89,"Probability a 9-digit number has the digits 2,4, and 6 next to each other.","Probability a 9-digit number has the digits 2,4, and 6 next to each other.",,"The integers $1,2,3,....,9$ are arraned (at random) in a row, resulting in a $9$-digit integer (without replacement). What is the probability that: The result is even? $\frac49$ or $\frac{4(8!)}{9!}$ The result is divisible by $5$? The number must end in $0$ or $5$. Edit: As Andre pointed out we have no $0$. So, $\frac19$. or $\frac{(8!)}{9!}$ The digits $2, 4,$ and $6$ are next to each other (in any order)? The above two I have confidence in, it is this last one I'm a little confused on. $9\choose 3$ ways to position $2,4,6$ in the 9-digit number and $3!$ ways they can be arranged. This doesn't appear to be right as after you divide by $9!$ you get $.13$% which seems unreasonably low. So, I thought to multiple by $6!$ to account for the number of ways the other $6$ numbers can be arranged. This gives you: $9\choose 3$$3!6!/9!$ which equals $1$, and obviously isn't right. Any suggestions as to where I went wrong would be great.","The integers $1,2,3,....,9$ are arraned (at random) in a row, resulting in a $9$-digit integer (without replacement). What is the probability that: The result is even? $\frac49$ or $\frac{4(8!)}{9!}$ The result is divisible by $5$? The number must end in $0$ or $5$. Edit: As Andre pointed out we have no $0$. So, $\frac19$. or $\frac{(8!)}{9!}$ The digits $2, 4,$ and $6$ are next to each other (in any order)? The above two I have confidence in, it is this last one I'm a little confused on. $9\choose 3$ ways to position $2,4,6$ in the 9-digit number and $3!$ ways they can be arranged. This doesn't appear to be right as after you divide by $9!$ you get $.13$% which seems unreasonably low. So, I thought to multiple by $6!$ to account for the number of ways the other $6$ numbers can be arranged. This gives you: $9\choose 3$$3!6!/9!$ which equals $1$, and obviously isn't right. Any suggestions as to where I went wrong would be great.",,"['probability', 'combinatorics']"
90,Convergence of random harmonic series,Convergence of random harmonic series,,"The problem is to show that the random harmonic series $X_n:=\sum_{n=1}^{\infty}\frac{\nu_n}{n}$ with $P[\nu_n = 1] = P[\nu_n = -1] = \frac{1}{2}$ converges. It is obvious that the harmonic series diverges and the alternating harmonic series converges. Also I am positive that the random harmonic series converges almost surely. Say I want to prove this with Kolmogorov's 3 series theorem where I need to show convergence of the three following series. $\sum_{n=1}^{\infty}P[X_n \neq Y_n]$ $\sum_{n=1}^{\infty} E[Y_n]$ $\sum_{n=1}^{\infty}var[Y_n]$ where $Y_n:= X_n 1_{\{|X_n|\leq c\}}$ I already have $E[\nu_n] = 0$ $E[X_n] = 0$ $var[\frac{\nu_n}{n}] = \frac{1}{n^2}$ and $var[\sum_{n=1}^{\infty}\frac{\nu_n}{n}] = \sum_{n=1}^{\infty}\frac{1}{n^2} = \frac{\pi^2}{6}$ I need help with 1. and I am not really sure what the difference between $X_n$ and $Y_n$ is. Is it just enough to say that since $X_n \geq Y_n$ and $\sum_{n=1}^{\infty} E[X_n]$ converges, 2. converges and $\sum_{n=1}^{\infty}var[X_n]$ converges, so 3. converges? I don't really understand this. Any help would be great.","The problem is to show that the random harmonic series $X_n:=\sum_{n=1}^{\infty}\frac{\nu_n}{n}$ with $P[\nu_n = 1] = P[\nu_n = -1] = \frac{1}{2}$ converges. It is obvious that the harmonic series diverges and the alternating harmonic series converges. Also I am positive that the random harmonic series converges almost surely. Say I want to prove this with Kolmogorov's 3 series theorem where I need to show convergence of the three following series. $\sum_{n=1}^{\infty}P[X_n \neq Y_n]$ $\sum_{n=1}^{\infty} E[Y_n]$ $\sum_{n=1}^{\infty}var[Y_n]$ where $Y_n:= X_n 1_{\{|X_n|\leq c\}}$ I already have $E[\nu_n] = 0$ $E[X_n] = 0$ $var[\frac{\nu_n}{n}] = \frac{1}{n^2}$ and $var[\sum_{n=1}^{\infty}\frac{\nu_n}{n}] = \sum_{n=1}^{\infty}\frac{1}{n^2} = \frac{\pi^2}{6}$ I need help with 1. and I am not really sure what the difference between $X_n$ and $Y_n$ is. Is it just enough to say that since $X_n \geq Y_n$ and $\sum_{n=1}^{\infty} E[X_n]$ converges, 2. converges and $\sum_{n=1}^{\infty}var[X_n]$ converges, so 3. converges? I don't really understand this. Any help would be great.",,"['probability', 'convergence-divergence']"
91,Derivation of the negative hypergeometric distribution,Derivation of the negative hypergeometric distribution,,"Suppose we've given an urn which contains $R$ red and $W$ white balls. These balls are drawn randomly from the urn and are not placed back. Let $X:=$ number of attempts, before we've drawn at least $r\le R$ red balls $Y:=$ number of red balls after $n-1$ attempts I want to calculate $\text{Pr}(X=n)$. Suppose we've already drawn $n-1$ balls from the urn and received $r-1$ red balls. The probability of this to happen is given by $$\text{Pr}(Y=r-1)=h(r-1|R+W,R,n-1):=\frac{\begin{pmatrix} R \\ r-1 \end{pmatrix}\begin{pmatrix} W \\ n-r \end{pmatrix}}{\begin{pmatrix} R+W \\ n-1 \end{pmatrix}}$$ where $h$ denotes the hypergeometric distribution. The probability that now another red ball is drawn is given by $$\text{Pr}(X=n)=\text{Pr}(Y=r-1)\;h(1|R+W-(n-1),R-(r-1),1)=\frac{\begin{pmatrix} R \\ r-1 \end{pmatrix}\begin{pmatrix} W \\ n-r \end{pmatrix}}{\begin{pmatrix} R+W \\ n-1 \end{pmatrix}}\frac{R-(r-1)}{R+W-(n-1)}$$ While I think that's correct, I would really like to get a more compact form of that. After some research on the internet, I found out, that I should be able to receive $$\text{Pr}(X=n)=\ldots =\frac{\begin{pmatrix} r-1 \\ n-1 \end{pmatrix}\begin{pmatrix} R+W-(r-1) \\ R-(n-1) \end{pmatrix}}{\begin{pmatrix} R+W \\ R \end{pmatrix}}$$ But I don't see how I get the $\ldots$ filled.","Suppose we've given an urn which contains $R$ red and $W$ white balls. These balls are drawn randomly from the urn and are not placed back. Let $X:=$ number of attempts, before we've drawn at least $r\le R$ red balls $Y:=$ number of red balls after $n-1$ attempts I want to calculate $\text{Pr}(X=n)$. Suppose we've already drawn $n-1$ balls from the urn and received $r-1$ red balls. The probability of this to happen is given by $$\text{Pr}(Y=r-1)=h(r-1|R+W,R,n-1):=\frac{\begin{pmatrix} R \\ r-1 \end{pmatrix}\begin{pmatrix} W \\ n-r \end{pmatrix}}{\begin{pmatrix} R+W \\ n-1 \end{pmatrix}}$$ where $h$ denotes the hypergeometric distribution. The probability that now another red ball is drawn is given by $$\text{Pr}(X=n)=\text{Pr}(Y=r-1)\;h(1|R+W-(n-1),R-(r-1),1)=\frac{\begin{pmatrix} R \\ r-1 \end{pmatrix}\begin{pmatrix} W \\ n-r \end{pmatrix}}{\begin{pmatrix} R+W \\ n-1 \end{pmatrix}}\frac{R-(r-1)}{R+W-(n-1)}$$ While I think that's correct, I would really like to get a more compact form of that. After some research on the internet, I found out, that I should be able to receive $$\text{Pr}(X=n)=\ldots =\frac{\begin{pmatrix} r-1 \\ n-1 \end{pmatrix}\begin{pmatrix} R+W-(r-1) \\ R-(n-1) \end{pmatrix}}{\begin{pmatrix} R+W \\ R \end{pmatrix}}$$ But I don't see how I get the $\ldots$ filled.",,"['probability', 'probability-theory', 'probability-distributions']"
92,Find the PDF of exponential distribution from its characteristic function,Find the PDF of exponential distribution from its characteristic function,,"I know that the characteristics function of the exponential distribution is as following: $$ \phi_x(t)  =\frac{\lambda}{(\lambda -it)}$$ Also, I know that the pdf of the exponential distribution is: $$f_x(x)=\lambda e^{-\lambda x}$$ Moreover, I know that the relation ship between the pdf and the characteristics function can be describe as following: $$ f_x(x)= \int_0^\infty e^{-itx} \phi_x(t) $$ $$ f_x(x)= \int_0^\infty e^{-itx} \frac{\lambda}{(\lambda -it)} $$ However, I can't compute the last equation to find the exactly pdf that i already mentioned before. Could you guys help me to solve this integral. I used wolfram, but without any result. Thanks .","I know that the characteristics function of the exponential distribution is as following: Also, I know that the pdf of the exponential distribution is: Moreover, I know that the relation ship between the pdf and the characteristics function can be describe as following: However, I can't compute the last equation to find the exactly pdf that i already mentioned before. Could you guys help me to solve this integral. I used wolfram, but without any result. Thanks .", \phi_x(t)  =\frac{\lambda}{(\lambda -it)} f_x(x)=\lambda e^{-\lambda x}  f_x(x)= \int_0^\infty e^{-itx} \phi_x(t)   f_x(x)= \int_0^\infty e^{-itx} \frac{\lambda}{(\lambda -it)} ,"['probability', 'integration', 'probability-distributions', 'density-function', 'characteristic-functions']"
93,Mean and Variance of Correct Answers for various ways of Multiple Choice Questions,Mean and Variance of Correct Answers for various ways of Multiple Choice Questions,,"I picked this question out of the blue while thinking about multiple choice questions. Consider I set, say $8$ multiple choice questions. Now, I want to find out, out of the three methods below, what is the mean and variance of correct answers the student will get correct, considering that the student selects an answer at random for each question Each question has $5$ possible answers and only $1$ of them is correct. There is a pool of $30$ possible answers, of which $8$ of them are the right answers to each question. The student is notified that no two questions share the same answer. There is a pool of $20$ possible answers. Each question has only one correct answer out of the pool of $20$. However, the student is notified that each answer could be the right answer to up to $2$ questions. The first one is obviously binomial so the mean is $1.6$ and the variance is $1.28$. For the second one, I am thinking of enumerating all possible permutations of $8$ answers, but am not sure how to proceed from there. For the third one, I am not even sure how to begin. Any ideas?","I picked this question out of the blue while thinking about multiple choice questions. Consider I set, say $8$ multiple choice questions. Now, I want to find out, out of the three methods below, what is the mean and variance of correct answers the student will get correct, considering that the student selects an answer at random for each question Each question has $5$ possible answers and only $1$ of them is correct. There is a pool of $30$ possible answers, of which $8$ of them are the right answers to each question. The student is notified that no two questions share the same answer. There is a pool of $20$ possible answers. Each question has only one correct answer out of the pool of $20$. However, the student is notified that each answer could be the right answer to up to $2$ questions. The first one is obviously binomial so the mean is $1.6$ and the variance is $1.28$. For the second one, I am thinking of enumerating all possible permutations of $8$ answers, but am not sure how to proceed from there. For the third one, I am not even sure how to begin. Any ideas?",,"['probability', 'permutations']"
94,expected value of a game with a n sided die,expected value of a game with a n sided die,,"Suppose we have a n-sided die. When we roll it, we can be paid the outcome or we can choose to re-roll by paying $1/n$. What is the best strategy and what is the expected value of this game? As an approximation, I thought that to get the maximum value $n$ we need to roll $n$ times. So the best strategy is to roll until we get the maximum value $n$ and the expected value should be $n-1$. Is it right as an approximation? How can we calculate the exact best strategy and the exact expected value?","Suppose we have a n-sided die. When we roll it, we can be paid the outcome or we can choose to re-roll by paying $1/n$. What is the best strategy and what is the expected value of this game? As an approximation, I thought that to get the maximum value $n$ we need to roll $n$ times. So the best strategy is to roll until we get the maximum value $n$ and the expected value should be $n-1$. Is it right as an approximation? How can we calculate the exact best strategy and the exact expected value?",,"['probability', 'recreational-mathematics', 'puzzle']"
95,Probability a polynomial has a root which is a root of unity,Probability a polynomial has a root which is a root of unity,,"Consider a degree $n$ polynomial $P(x)$ with coefficients $c_i \in \{-1,0,1\}$ chosen uniformly and independently. What is the probability that $P(x)$ has a root which is a root of   unity? For a particular polynomial you can test the property by just seeing if it is divisible by $x^k-1$ for some $k$.","Consider a degree $n$ polynomial $P(x)$ with coefficients $c_i \in \{-1,0,1\}$ chosen uniformly and independently. What is the probability that $P(x)$ has a root which is a root of   unity? For a particular polynomial you can test the property by just seeing if it is divisible by $x^k-1$ for some $k$.",,['probability']
96,"N balls and M boxes, probability that there is at least 1 box contains at least 2 balls","N balls and M boxes, probability that there is at least 1 box contains at least 2 balls",,I have $N$ balls and $M$ boxes. Balls are thrown to the boxes at random.   What is the probability that there is at least 1 box contains at least 2 balls? Thank you very much,I have $N$ balls and $M$ boxes. Balls are thrown to the boxes at random.   What is the probability that there is at least 1 box contains at least 2 balls? Thank you very much,,"['probability', 'combinatorics']"
97,Two different sequences of random variables each converge in distribution; does their sum?,Two different sequences of random variables each converge in distribution; does their sum?,,"My question is about basic probability. We have two sequences of random variables, $ \{ X_n \}$ and $\{ Y_n \}$, such that each converge in distribution - i.e. there exist random variables $X$ and $Y$ such that: $X_n \rightarrow X$ as $n \rightarrow \infty$ in law, and $Y_n \rightarrow Y$ as $n \rightarrow \infty$ in law. What can we say about the sequence $X_n + Y_n$? I would like to say that it converges in law to $X +Y$ - but is this true? Many apologies if this question has already been asked and answered. Thank you so much!! John p.s. Feel free to add some assumptions like independence of the $X_n$ and $Y_n$ in the process of answering this question.","My question is about basic probability. We have two sequences of random variables, $ \{ X_n \}$ and $\{ Y_n \}$, such that each converge in distribution - i.e. there exist random variables $X$ and $Y$ such that: $X_n \rightarrow X$ as $n \rightarrow \infty$ in law, and $Y_n \rightarrow Y$ as $n \rightarrow \infty$ in law. What can we say about the sequence $X_n + Y_n$? I would like to say that it converges in law to $X +Y$ - but is this true? Many apologies if this question has already been asked and answered. Thank you so much!! John p.s. Feel free to add some assumptions like independence of the $X_n$ and $Y_n$ in the process of answering this question.",,"['probability', 'convergence-divergence']"
98,Derivation 9.97 in Jaynes' Probability Theory,Derivation 9.97 in Jaynes' Probability Theory,,"In page 298 of Jaynes' Probability Theory: the Logic of Science, equation (9.97), Jaynes says: We expect that, if hypothesis $H$ is true, then $n_k$ will be close to $np_k$ , in the sense that the difference $|n_k-np_k|$ will grow with $n$ only as $\sqrt n$ . Call this 'condition A'. Then using the expansion $\log(x) = (x-1)-(x-1)^2/2+...$ , we find that $$\sum_{k=1}^mn_k\log\left[\frac{n_k}{np_k}\right] = \frac 1 2\sum_k\frac{(n_k-np_k)^2}{np_k} + O\left(\frac 1 {\sqrt n}\right)$$ In the above, $\sum_kp_k = 1$ and $\sum_kn_k=n$ , where $n$ is the total number of trials in a series of Bernoulli trials and $n_k$ is the number of trials that had outcome $k$ . I'd like to know how he got from that expansion to the quoted equation, especially given that the squared term in the expansion has negative sign. --EDIT to add info-- Jaynes' nomenclature confused me a bit. He calls hypotheses of the type ""there are $m$ possible outcomes of an experiment, each being observed with probability $p_k$ independent of previous or future repetitions of that experiment"" the ""Bernoulli class."" $n_k$ is the number of performed experiments that had outcome $k$ , $n$ is the total number of experiments performed. But that is all that's defined by Jaynes, and all that's known about the hypotheses. (A thought occurs: what if Jaynes meant that condition A is that $|n_k -np_k| \approx O(1/\sqrt n)$ ? I haven't explored this possibility to know whether it makes sense.)","In page 298 of Jaynes' Probability Theory: the Logic of Science, equation (9.97), Jaynes says: We expect that, if hypothesis is true, then will be close to , in the sense that the difference will grow with only as . Call this 'condition A'. Then using the expansion , we find that In the above, and , where is the total number of trials in a series of Bernoulli trials and is the number of trials that had outcome . I'd like to know how he got from that expansion to the quoted equation, especially given that the squared term in the expansion has negative sign. --EDIT to add info-- Jaynes' nomenclature confused me a bit. He calls hypotheses of the type ""there are possible outcomes of an experiment, each being observed with probability independent of previous or future repetitions of that experiment"" the ""Bernoulli class."" is the number of performed experiments that had outcome , is the total number of experiments performed. But that is all that's defined by Jaynes, and all that's known about the hypotheses. (A thought occurs: what if Jaynes meant that condition A is that ? I haven't explored this possibility to know whether it makes sense.)",H n_k np_k |n_k-np_k| n \sqrt n \log(x) = (x-1)-(x-1)^2/2+... \sum_{k=1}^mn_k\log\left[\frac{n_k}{np_k}\right] = \frac 1 2\sum_k\frac{(n_k-np_k)^2}{np_k} + O\left(\frac 1 {\sqrt n}\right) \sum_kp_k = 1 \sum_kn_k=n n n_k k m p_k n_k k n |n_k -np_k| \approx O(1/\sqrt n),"['calculus', 'probability', 'probability-theory', 'taylor-expansion']"
99,Distribution function of an exponential random variable,Distribution function of an exponential random variable,,I am trying to answer the question $F(x)$ is distribution with $F(0)=0$ and $F(x)<1$ for some $x>0$. Show $F(x)$ is the distribution function of an exponential random variable iff $$F(x+y)-F(y)=F(x)\left(1-F(y)\right).$$ I started with the CDF of the exponential function which is $F(x)=1-e^{-kx}$. I then took this function and plugged it into the inequality $F(x+y)-F(y)=F(x)\left(1-F(y)\right)$ and got the let side equal to the right side. However where I am stuck is I am unsure how to prove the reverse.,I am trying to answer the question $F(x)$ is distribution with $F(0)=0$ and $F(x)<1$ for some $x>0$. Show $F(x)$ is the distribution function of an exponential random variable iff $$F(x+y)-F(y)=F(x)\left(1-F(y)\right).$$ I started with the CDF of the exponential function which is $F(x)=1-e^{-kx}$. I then took this function and plugged it into the inequality $F(x+y)-F(y)=F(x)\left(1-F(y)\right)$ and got the let side equal to the right side. However where I am stuck is I am unsure how to prove the reverse.,,['probability']
