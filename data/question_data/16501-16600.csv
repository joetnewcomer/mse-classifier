,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,What is the derivative of $x^i$?,What is the derivative of ?,x^i,"What would the derivative be of $x^i$? Would it simply be $ix^{(1-i)} $? I tried running the Power rule, and I got that is that right?","What would the derivative be of $x^i$? Would it simply be $ix^{(1-i)} $? I tried running the Power rule, and I got that is that right?",,"['calculus', 'derivatives']"
1,Is the Riemann integral of a strictly smaller function strictly smaller?,Is the Riemann integral of a strictly smaller function strictly smaller?,,"We all know that if $f\leq{}g$ in $[a,b]$ then $$ \int_a^bf\,dx\leq\int_a^bg\,dx $$ now, imagine that we have $f<g$, is it true that $$ \int_a^bf\,dx<\int_a^bg\,dx $$","We all know that if $f\leq{}g$ in $[a,b]$ then $$ \int_a^bf\,dx\leq\int_a^bg\,dx $$ now, imagine that we have $f<g$, is it true that $$ \int_a^bf\,dx<\int_a^bg\,dx $$",,"['calculus', 'integration', 'inequality', 'integral-inequality', 'riemann-integration']"
2,Why not every integral is zero?,Why not every integral is zero?,,"if we start axioming area to be a mapping from a collection of points on a plane to the set of real numbers, this is:                                  a: M → R                                    S↦a(S), where S is the set of points as aforementioned and M is the collection of sets S (measurable sets..) . Stating the following axioms: (i) a(S) is non negative for every S (ii) if S and T are elements of M then S∪T and S∩T are also member of M and: a(S∪T) = a(S) + a(T) - a(S∩T) (iii) Every retangule R is member of M and if h and k are sides of R then a(R)= k.h --> Finaly, with thiss if we want to measure a area of anything, namely a retangule, we need to define the set of all point that compose this thing, so for example if we integrate the area of retangule with sides h and k we define the set A={(x,y):(0≤x≤h ^ 0≤y≤k)} what by the axioms: a(A)=h.k but if we think that A as union of lines horizontal or vertical for example A being the reunion of all lines C={(x,t):0≤x≤h} where t obey 0≤t≤k and is diferent for each line, but thnking in this way lead us that a(A) is equal to the sum of all areas a(C) for all lines that compose A, but each area a(C) is equal to zero with implies that a(A)=0 what is clearly absurd! My question is where is the failure in this procedure?","if we start axioming area to be a mapping from a collection of points on a plane to the set of real numbers, this is:                                  a: M → R                                    S↦a(S), where S is the set of points as aforementioned and M is the collection of sets S (measurable sets..) . Stating the following axioms: (i) a(S) is non negative for every S (ii) if S and T are elements of M then S∪T and S∩T are also member of M and: a(S∪T) = a(S) + a(T) - a(S∩T) (iii) Every retangule R is member of M and if h and k are sides of R then a(R)= k.h --> Finaly, with thiss if we want to measure a area of anything, namely a retangule, we need to define the set of all point that compose this thing, so for example if we integrate the area of retangule with sides h and k we define the set A={(x,y):(0≤x≤h ^ 0≤y≤k)} what by the axioms: a(A)=h.k but if we think that A as union of lines horizontal or vertical for example A being the reunion of all lines C={(x,t):0≤x≤h} where t obey 0≤t≤k and is diferent for each line, but thnking in this way lead us that a(A) is equal to the sum of all areas a(C) for all lines that compose A, but each area a(C) is equal to zero with implies that a(A)=0 what is clearly absurd! My question is where is the failure in this procedure?",,"['calculus', 'integration']"
3,How to evaluate this series using fourier series?,How to evaluate this series using fourier series?,,"With the help of Hermite's Integral ,I got $$\sum_{n=1}^{\infty }\frac{1}{n}\int_{2\pi n}^{\infty }\frac{\sin x}{x}\mathrm{d}x=\pi-\frac{\pi}{2}\ln(2\pi)$$ I'd like to know can we solve this one using fourier series?","With the help of Hermite's Integral ,I got $$\sum_{n=1}^{\infty }\frac{1}{n}\int_{2\pi n}^{\infty }\frac{\sin x}{x}\mathrm{d}x=\pi-\frac{\pi}{2}\ln(2\pi)$$ I'd like to know can we solve this one using fourier series?",,"['calculus', 'integration', 'sequences-and-series', 'fourier-series']"
4,How do you integrate $(x+2)\ln(x-3)$?,How do you integrate ?,(x+2)\ln(x-3),"I got $$\left(\frac {x^2}{2} +2x\right)\ln(x-3)-\left(\frac {x^2}{4}-\frac {7x}{2} -\frac {21}{2}\right)\ln(2x-6)$$ as my answer... Not sure If I got it right. Please correct me, thank you!","I got $$\left(\frac {x^2}{2} +2x\right)\ln(x-3)-\left(\frac {x^2}{4}-\frac {7x}{2} -\frac {21}{2}\right)\ln(2x-6)$$ as my answer... Not sure If I got it right. Please correct me, thank you!",,"['calculus', 'integration', 'indefinite-integrals']"
5,"Show that for any positive integer $n$ there is $x \in [0,1-\frac{1}{n}]$ for which $f(x) = f(x+\frac{1}{n})$",Show that for any positive integer  there is  for which,"n x \in [0,1-\frac{1}{n}] f(x) = f(x+\frac{1}{n})","Suppose $f$ is a continuous function over $[0,1]$ such that $f(0) = f(1).$ Show that for any positive integer $n$ there is $x \in [0,1-\frac{1}{n}]$ for which $f(x) = f(x+\frac{1}{n})$. We seem to be saying that $f(x+\frac{1}{n})$ is periodic with respect to any positive integer $n$. Also this seems to make sense since we start and end at the same spot there have to be values of $x$ with the same $f(x)$ as other $x$'s. But I am struggling to see how to prove this specific statement.","Suppose $f$ is a continuous function over $[0,1]$ such that $f(0) = f(1).$ Show that for any positive integer $n$ there is $x \in [0,1-\frac{1}{n}]$ for which $f(x) = f(x+\frac{1}{n})$. We seem to be saying that $f(x+\frac{1}{n})$ is periodic with respect to any positive integer $n$. Also this seems to make sense since we start and end at the same spot there have to be values of $x$ with the same $f(x)$ as other $x$'s. But I am struggling to see how to prove this specific statement.",,['calculus']
6,How to evaluate $\displaystyle \int_{0}^{\infty }\frac{\cos x}{\left ( x^2+a^{2} \right )\left ( x^2+b^{2} \right )}~\mathrm{d}x$,How to evaluate,\displaystyle \int_{0}^{\infty }\frac{\cos x}{\left ( x^2+a^{2} \right )\left ( x^2+b^{2} \right )}~\mathrm{d}x,"With the Fourier Transformation ,we can easily get  $$\int_{0}^{\infty }\frac{\cos x}{x^{2}+a^{2}}~\mathrm{d}x=\frac{\pi e^{-a}}{2a}~,~\Re\left ( a \right )> 0$$ and with help of wolframalpha I found $$\int_{0}^{\infty }\frac{\cos x}{\left ( x^2+a^{2} \right )\left ( x^2+b^{2} \right )}~\mathrm{d}x=\frac{\pi ae^{-b}-\pi be^{-a}}{2a^{3}b-2ab^{3}}~,~\Re\left ( a \right )>0,\Re\left ( b \right )>0$$ But I don't know how to prove it. In addition,I'd like to know is there a closed form for the general form below $${\Large{\int}}_{0}^{\infty }\frac{\cos x}{\displaystyle \prod_{i=1}^{\infty }\left ( x^{2}+a_{i}^{2} \right )}~\mathrm{d}x~,~\Re(a_i)＞0$$","With the Fourier Transformation ,we can easily get  $$\int_{0}^{\infty }\frac{\cos x}{x^{2}+a^{2}}~\mathrm{d}x=\frac{\pi e^{-a}}{2a}~,~\Re\left ( a \right )> 0$$ and with help of wolframalpha I found $$\int_{0}^{\infty }\frac{\cos x}{\left ( x^2+a^{2} \right )\left ( x^2+b^{2} \right )}~\mathrm{d}x=\frac{\pi ae^{-b}-\pi be^{-a}}{2a^{3}b-2ab^{3}}~,~\Re\left ( a \right )>0,\Re\left ( b \right )>0$$ But I don't know how to prove it. In addition,I'd like to know is there a closed form for the general form below $${\Large{\int}}_{0}^{\infty }\frac{\cos x}{\displaystyle \prod_{i=1}^{\infty }\left ( x^{2}+a_{i}^{2} \right )}~\mathrm{d}x~,~\Re(a_i)＞0$$",,"['calculus', 'integration', 'complex-analysis']"
7,How to calculate volume of a right circular cone's hyperbola segment?,How to calculate volume of a right circular cone's hyperbola segment?,,"PROBLEM I am working on calculating volumes of geometric solids. All shapes have been pretty basic until now.  I am bewildered on how to attack the problem of calculating the volume of a slice of a right circle cone. Visualizing: The cone sits on a circular base with the apex directly above. The axis of symmetry passes through the apex and the center of the circle oriented normal to the circle.  Now, when you pass a cutting plane parallel with the cone's axis of symmetry at a distance between the circle's center and the circle's perimeter, a segment is 'cleaved' off.  I am looking to determine the volume of that segment. Note: All cone dimensions are known. RESEARCH I have looked at numerous math and analytical geometry websites.  The most information I can seem to find just about the equations of lines or basic formulas (volume, surface area, etc.) I have even dug up my ancient Calculus textbook (yes, an actual paper book) yet still cannot find an approach. POSSIBLE SOLUTION I suspect that the solution will use DOUBLE INTEGRALS in some fashion but I am not sure. Frankly, even if it does use double integrals, I have been away from this for so long that I will need an example for how to work out the problem. I want to apply calculus to more of my work but do not fully have the confidence to do so. Thank you for any assistance or direction to a solution.","PROBLEM I am working on calculating volumes of geometric solids. All shapes have been pretty basic until now.  I am bewildered on how to attack the problem of calculating the volume of a slice of a right circle cone. Visualizing: The cone sits on a circular base with the apex directly above. The axis of symmetry passes through the apex and the center of the circle oriented normal to the circle.  Now, when you pass a cutting plane parallel with the cone's axis of symmetry at a distance between the circle's center and the circle's perimeter, a segment is 'cleaved' off.  I am looking to determine the volume of that segment. Note: All cone dimensions are known. RESEARCH I have looked at numerous math and analytical geometry websites.  The most information I can seem to find just about the equations of lines or basic formulas (volume, surface area, etc.) I have even dug up my ancient Calculus textbook (yes, an actual paper book) yet still cannot find an approach. POSSIBLE SOLUTION I suspect that the solution will use DOUBLE INTEGRALS in some fashion but I am not sure. Frankly, even if it does use double integrals, I have been away from this for so long that I will need an example for how to work out the problem. I want to apply calculus to more of my work but do not fully have the confidence to do so. Thank you for any assistance or direction to a solution.",,"['calculus', 'analytic-geometry']"
8,How to define the derivative of a vector wrt to a matrix?,How to define the derivative of a vector wrt to a matrix?,,"Given the equation $$ Ax = b $$ where $A$ is a matrix, and $b$ and $x$ are vectors, I'm trying to make sense of $ \frac{\partial b}{\partial A} $. By ""opening up"" the matrix equation into several 1D equations, I managed to get to $$ \frac{\partial b_{i}}{\partial A_{jk}}=\begin{cases} x_{j} & \text{ if } i=j \\  0 & \text{ if } i \neq j  \end{cases} $$ I was wondering: how can I define this partial derivative for all terms without resorting to ""opening up"" the matrix equation into several 1D equations? Also, this definition of the partial derivative of a vector with relation to a matrix should hopefully abide by something that resembles the differentiation rules that I'm used to in 1D. The wikipedia article on matrix calculus doesn't define this partial derivative (as far as I understood, the furthest they go is vector wrt to vector) and this question is the closest I could find in math.se, but the answer provided isn't really helpful for what I'm trying to achieve. Any help would be appreciated.","Given the equation $$ Ax = b $$ where $A$ is a matrix, and $b$ and $x$ are vectors, I'm trying to make sense of $ \frac{\partial b}{\partial A} $. By ""opening up"" the matrix equation into several 1D equations, I managed to get to $$ \frac{\partial b_{i}}{\partial A_{jk}}=\begin{cases} x_{j} & \text{ if } i=j \\  0 & \text{ if } i \neq j  \end{cases} $$ I was wondering: how can I define this partial derivative for all terms without resorting to ""opening up"" the matrix equation into several 1D equations? Also, this definition of the partial derivative of a vector with relation to a matrix should hopefully abide by something that resembles the differentiation rules that I'm used to in 1D. The wikipedia article on matrix calculus doesn't define this partial derivative (as far as I understood, the furthest they go is vector wrt to vector) and this question is the closest I could find in math.se, but the answer provided isn't really helpful for what I'm trying to achieve. Any help would be appreciated.",,"['calculus', 'matrix-calculus']"
9,Closed form of $\sum\limits_{n=1}^\infty \frac{4^n(x+4)^{2n}}n$,Closed form of,\sum\limits_{n=1}^\infty \frac{4^n(x+4)^{2n}}n,"Let   $$S(x) = \sum_{n=1}^\infty \frac{4^n(x+4)^{2n}}n$$   1. Find the radius of convergence. 2. Calculate $S(x)$. 3. Find $S^{(n)}(x)$ without computing the derivatives of $S(x)$. From the root test I find $R = 1/4$. It's the second point that troubles me. This is my attempt: $$\begin{align} S(x) &= \sum\limits_{n=1}^\infty \frac{4^n(x+4)^{2n}}n =\\ &= \sum\limits_{n=1}^\infty 2^{2n+1}\int_{-4}^x (t + 4)^{2n-1}\mathrm dt =\\ &= \int_{-4}^x \sum\limits_{n=1}^\infty 2^{2n+1}(t + 4)^{2n-1}\mathrm dt =\\ &= 4\int_{-4}^x \sum\limits_{n=1}^\infty 2^{2n-1}(t + 4)^{2n-1}\mathrm dt =\\ &=\ ??? \end{align}$$ I don't know how to continue from there. I know that I should transform the inner sum into a known Taylor expansion or a geometric series, but I don't see how I could do that. As for the last point, we have that $$S(x) = \sum_{n=1}^\infty \frac{4^n(x+4)^{2n}}n = \sum_{n = 0}^\infty \frac{S^{(n)}(x)}{n!}(x + 4)^n,$$ as per the Taylor series definition. However, I don't know how to reconcile the indices and the two powers $2n$ and $n$.","Let   $$S(x) = \sum_{n=1}^\infty \frac{4^n(x+4)^{2n}}n$$   1. Find the radius of convergence. 2. Calculate $S(x)$. 3. Find $S^{(n)}(x)$ without computing the derivatives of $S(x)$. From the root test I find $R = 1/4$. It's the second point that troubles me. This is my attempt: $$\begin{align} S(x) &= \sum\limits_{n=1}^\infty \frac{4^n(x+4)^{2n}}n =\\ &= \sum\limits_{n=1}^\infty 2^{2n+1}\int_{-4}^x (t + 4)^{2n-1}\mathrm dt =\\ &= \int_{-4}^x \sum\limits_{n=1}^\infty 2^{2n+1}(t + 4)^{2n-1}\mathrm dt =\\ &= 4\int_{-4}^x \sum\limits_{n=1}^\infty 2^{2n-1}(t + 4)^{2n-1}\mathrm dt =\\ &=\ ??? \end{align}$$ I don't know how to continue from there. I know that I should transform the inner sum into a known Taylor expansion or a geometric series, but I don't see how I could do that. As for the last point, we have that $$S(x) = \sum_{n=1}^\infty \frac{4^n(x+4)^{2n}}n = \sum_{n = 0}^\infty \frac{S^{(n)}(x)}{n!}(x + 4)^n,$$ as per the Taylor series definition. However, I don't know how to reconcile the indices and the two powers $2n$ and $n$.",,"['calculus', 'sequences-and-series']"
10,Find the integral $\int \frac{1+x}{\sqrt{1-x^2}}\mathrm dx$,Find the integral,\int \frac{1+x}{\sqrt{1-x^2}}\mathrm dx,The integral can be represented as  $$ \int \frac{1+x}{\sqrt{1-x^2}}\mathrm dx= \int \left(\frac{1+x}{1-x}\right)^{1/2}\mathrm dx $$ Substitution $$t=\frac{1+x}{1-x}\Rightarrow x=\frac{t-1}{t+1}\Rightarrow dx=\frac{2}{(t+1)^2}dt\Rightarrow \int\limits \left(\frac{1+x}{1-x}\right)^{1/2}\mathrm dx=2\int\limits \frac{\sqrt{t}}{(t+1)^2}\mathrm dt$$ What substitution to use for solving the integral $\int\limits \frac{\sqrt{t}}{(t+1)^2}\mathrm dt$?,The integral can be represented as  $$ \int \frac{1+x}{\sqrt{1-x^2}}\mathrm dx= \int \left(\frac{1+x}{1-x}\right)^{1/2}\mathrm dx $$ Substitution $$t=\frac{1+x}{1-x}\Rightarrow x=\frac{t-1}{t+1}\Rightarrow dx=\frac{2}{(t+1)^2}dt\Rightarrow \int\limits \left(\frac{1+x}{1-x}\right)^{1/2}\mathrm dx=2\int\limits \frac{\sqrt{t}}{(t+1)^2}\mathrm dt$$ What substitution to use for solving the integral $\int\limits \frac{\sqrt{t}}{(t+1)^2}\mathrm dt$?,,"['calculus', 'integration']"
11,"Show that a homogeneous function satisfies the PDE $x \frac{\partial f}{\partial x} + y\frac{\partial f}{\partial y} = n f(x,y)$",Show that a homogeneous function satisfies the PDE,"x \frac{\partial f}{\partial x} + y\frac{\partial f}{\partial y} = n f(x,y)","I'm using the following definition of a homogeneous function. A function $f(x,y)$ is homogeneous of degree n if it satisfies the following equation $$f(tx, ty) = t^n f(x,y) \quad (1) $$ for all $t$ where $n>0$ Problem Show that if $f$ is homogeneous of degree n, then $$x \frac{\partial f}{\partial x} + y\frac{\partial f}{\partial y} = n f(x,y) $$ Attempted Solution I differentiated $(1)$ w.r.t $t$ giving me $$ \begin{align*}\frac{\partial f}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial f}{\partial y}\frac{\partial y}{\partial t} &= nt^{n-1} f(x,y)  \\ x\frac{\partial f}{\partial x} + y\frac{\partial f}{\partial y}&=nt^{n-1} f(x,y) \end{align*} $$ The LHS looks okay, but I'm not sure how to handle the $t^{n-1}$ term on the RHS.","I'm using the following definition of a homogeneous function. A function $f(x,y)$ is homogeneous of degree n if it satisfies the following equation $$f(tx, ty) = t^n f(x,y) \quad (1) $$ for all $t$ where $n>0$ Problem Show that if $f$ is homogeneous of degree n, then $$x \frac{\partial f}{\partial x} + y\frac{\partial f}{\partial y} = n f(x,y) $$ Attempted Solution I differentiated $(1)$ w.r.t $t$ giving me $$ \begin{align*}\frac{\partial f}{\partial x} \frac{\partial x}{\partial t} + \frac{\partial f}{\partial y}\frac{\partial y}{\partial t} &= nt^{n-1} f(x,y)  \\ x\frac{\partial f}{\partial x} + y\frac{\partial f}{\partial y}&=nt^{n-1} f(x,y) \end{align*} $$ The LHS looks okay, but I'm not sure how to handle the $t^{n-1}$ term on the RHS.",,"['calculus', 'partial-differential-equations', 'partial-derivative']"
12,Limit $ \lim\limits_{n \rightarrow \infty} \left(\lim\limits_{k \rightarrow \infty} \left(\frac{1}{1+2^{n-k}}\right) \right) $,Limit, \lim\limits_{n \rightarrow \infty} \left(\lim\limits_{k \rightarrow \infty} \left(\frac{1}{1+2^{n-k}}\right) \right) ,"I have to calculate the following limit: $A=\displaystyle \lim_{n \rightarrow \infty} \left(\displaystyle \lim_{k \rightarrow \infty} \left(\frac{1}{1+2^{n-k}}\right) \right) $ Where $\ n  $ and $\ k $ are elements of the natural numbers. Because we never did that in class, I am not sure as what I did is right. I got the following: $\ 1 \leqslant  A=\displaystyle \lim_{n \rightarrow \infty} (\displaystyle \lim_{k \rightarrow \infty} (\frac{1}{1+2^{n-k}}) ) \leqslant \displaystyle \lim_{n \rightarrow \infty} (\displaystyle \lim_{k \rightarrow \infty} (\frac{1}{2^{n-k}}) ) \leqslant \displaystyle \lim_{n \rightarrow \infty} (\displaystyle \lim_{k \rightarrow \infty} (\frac{2^{k}}{2^{n}}) ) = \frac{\displaystyle \lim_{k \rightarrow \infty}2^{k}}{\displaystyle \lim_{n \rightarrow \infty}2^{n}} $ Now its obvious that both limes are going to infinity, but how can I argue that they both like start at the same index $\ k $ and $\ n $ and so we could substitute both to the same variable and take the same limes so we would get the limit of 1 and then I could use the Sandwich theorem to tell that the limit of A is equal to 1. Thank you","I have to calculate the following limit: $A=\displaystyle \lim_{n \rightarrow \infty} \left(\displaystyle \lim_{k \rightarrow \infty} \left(\frac{1}{1+2^{n-k}}\right) \right) $ Where $\ n  $ and $\ k $ are elements of the natural numbers. Because we never did that in class, I am not sure as what I did is right. I got the following: $\ 1 \leqslant  A=\displaystyle \lim_{n \rightarrow \infty} (\displaystyle \lim_{k \rightarrow \infty} (\frac{1}{1+2^{n-k}}) ) \leqslant \displaystyle \lim_{n \rightarrow \infty} (\displaystyle \lim_{k \rightarrow \infty} (\frac{1}{2^{n-k}}) ) \leqslant \displaystyle \lim_{n \rightarrow \infty} (\displaystyle \lim_{k \rightarrow \infty} (\frac{2^{k}}{2^{n}}) ) = \frac{\displaystyle \lim_{k \rightarrow \infty}2^{k}}{\displaystyle \lim_{n \rightarrow \infty}2^{n}} $ Now its obvious that both limes are going to infinity, but how can I argue that they both like start at the same index $\ k $ and $\ n $ and so we could substitute both to the same variable and take the same limes so we would get the limit of 1 and then I could use the Sandwich theorem to tell that the limit of A is equal to 1. Thank you",,"['calculus', 'analysis', 'limits', 'limits-without-lhopital']"
13,Finding $\sum\limits_{k=0}^n k$ using summation by parts,Finding  using summation by parts,\sum\limits_{k=0}^n k,"This is another exercise from Smoryński's Logical Number Theory ; not being a mathematician, I'm a bit new to this finite difference stuff, so, please, bear with me! In a previous exercise, Smoryński asked us to prove the following formula for summation by parts: $\sum\limits_{k=0}^n f(k)g(k) = g(n)(\sum\limits_{k=0}^n f(k)) - \sum\limits_{k=0}^{n-1} [\Delta g(k) (\sum\limits_{i=0}^k f(i))]$ Next, he wants us to apply this formula to derive $\sum\limits_{k=0}^n k = \frac{n(n+1)}{2}$. I've tried but I obviously got something wrong. First, note the obvious $\sum\limits_{k=0}^n 1 = n+1$ and $\Delta k = 0$ for $k$ constant. Thus, I got: $\sum\limits_{k=0}^n k = \sum\limits_{k=0}^n 1 \times k = n (\sum\limits_{k=0}^n 1) - \sum\limits_{k=0}^{n-1}[\Delta k \sum\limits_{i=0}^k 1] = n(n+1) - \sum\limits_{k=0}^{n-1}0 = n(n+1) - 0 = n(n+1)$ Where did I go wrong?","This is another exercise from Smoryński's Logical Number Theory ; not being a mathematician, I'm a bit new to this finite difference stuff, so, please, bear with me! In a previous exercise, Smoryński asked us to prove the following formula for summation by parts: $\sum\limits_{k=0}^n f(k)g(k) = g(n)(\sum\limits_{k=0}^n f(k)) - \sum\limits_{k=0}^{n-1} [\Delta g(k) (\sum\limits_{i=0}^k f(i))]$ Next, he wants us to apply this formula to derive $\sum\limits_{k=0}^n k = \frac{n(n+1)}{2}$. I've tried but I obviously got something wrong. First, note the obvious $\sum\limits_{k=0}^n 1 = n+1$ and $\Delta k = 0$ for $k$ constant. Thus, I got: $\sum\limits_{k=0}^n k = \sum\limits_{k=0}^n 1 \times k = n (\sum\limits_{k=0}^n 1) - \sum\limits_{k=0}^{n-1}[\Delta k \sum\limits_{i=0}^k 1] = n(n+1) - \sum\limits_{k=0}^{n-1}0 = n(n+1) - 0 = n(n+1)$ Where did I go wrong?",,"['calculus', 'summation']"
14,Solution of limit $\lim\limits_{x\to 0} \frac {e^{-1/x^2}}{x} $ [duplicate],Solution of limit  [duplicate],\lim\limits_{x\to 0} \frac {e^{-1/x^2}}{x} ,"This question already has answers here : Evaluating $\lim\limits_{x\rightarrow0}\frac{e^{-1/x^2}}{x}$ (3 answers) Closed 3 years ago . Small question, I'm trying to solve this limit but I just can't wrap my head around this problem. $$\lim_{x\to 0} \frac {e^{-1/x^2}}{x} $$ L'Hopital just seems to make it messier. It's probably pretty simple - I'd like to hear what I'm missing.","This question already has answers here : Evaluating $\lim\limits_{x\rightarrow0}\frac{e^{-1/x^2}}{x}$ (3 answers) Closed 3 years ago . Small question, I'm trying to solve this limit but I just can't wrap my head around this problem. $$\lim_{x\to 0} \frac {e^{-1/x^2}}{x} $$ L'Hopital just seems to make it messier. It's probably pretty simple - I'd like to hear what I'm missing.",,"['calculus', 'limits', 'limits-without-lhopital']"
15,Slow decreasing function that exhibits asymptotic behaviour,Slow decreasing function that exhibits asymptotic behaviour,,"I am currently doing some work on modelling the effects of treated nets usage on mosquito populations. Nets do not retain their maximum efficacy forever. They lose their chemical efficacy after about three years and all that is left is the physical protection offered by the net which I estimate to be $20\%$ of the original efficacy. I am trying to model this behaviour. I need a continuous function over the interval $[0,1095]$ which decreases slowly  from 1 when $x=0$ and asymptotically approaches $0.2$ when $x \to 1095 $. I tried an ellipse of the form $y=\sqrt{1-\dfrac{x^2}{(1095)^2}}$, but I realized the function is equal to zero when $x=1095$, which is not what I want. Any help will be appreciated.","I am currently doing some work on modelling the effects of treated nets usage on mosquito populations. Nets do not retain their maximum efficacy forever. They lose their chemical efficacy after about three years and all that is left is the physical protection offered by the net which I estimate to be $20\%$ of the original efficacy. I am trying to model this behaviour. I need a continuous function over the interval $[0,1095]$ which decreases slowly  from 1 when $x=0$ and asymptotically approaches $0.2$ when $x \to 1095 $. I tried an ellipse of the form $y=\sqrt{1-\dfrac{x^2}{(1095)^2}}$, but I realized the function is equal to zero when $x=1095$, which is not what I want. Any help will be appreciated.",,"['calculus', 'asymptotics', 'special-functions']"
16,An unusual limit involving $e$,An unusual limit involving,e,"From MathWorld I have the following quote: $e$ is given by the unusual limit $$\lim_{n \to \infty}\left(\frac{(n + 1)^{n + 1}}{n^{n}} - \frac{n^{n}}{(n - 1)^{n - 1}}\right) = e\tag{1}$$ Now if we put $$a_{n} = \frac{(n + 1)^{n + 1}}{n^{n}}$$ then the above result says that $$\lim_{n \to \infty}(a_{n} - a_{n - 1}) = e$$ Now we know that Theorem: If $a_{n} - a_{n - 1} \to L$ then $a_{n}/n \to L$ . Using the example here we see that $$\frac{a_{n}}{n} = \frac{n + 1}{n}\left(1 + \frac{1}{n}\right)^{n} \to e$$ I am thinking of some partial converse to the standard theorem above which can get us from limit of $a_{n}/n$ to limit of $a_{n} - a_{n - 1}$. Another option to prove $(1)$ is to make use of real variable theory. Thus we can put $x = 1/n$ and deal with function $f(x) = \left(1 + \dfrac{1}{x}\right)(1 + x)^{1/x}$ and use Taylor expansion $$(1 + x)^{1/x} = e - \frac{ex}{2} + \frac{11e}{24}x^{2} + \cdots$$ and $$g(x) = \left(\frac{1}{x} - 1\right)(1 - x)^{-1/x}$$ and calculate the limit of $f(x) - g(x)$ as $x \to 0$. This way we see that $$f(x) = \frac{e}{2} + \frac{e}{x} + o(1), g(x) = -\frac{e}{2} + \frac{e}{x} + o(1)$$ and clearly $f(x) - g(x) \to e$ as $x \to 0$. Is there a proof without using real variable theory and just dealing with theorems on sequences which establishes the result $(1)$?","From MathWorld I have the following quote: $e$ is given by the unusual limit $$\lim_{n \to \infty}\left(\frac{(n + 1)^{n + 1}}{n^{n}} - \frac{n^{n}}{(n - 1)^{n - 1}}\right) = e\tag{1}$$ Now if we put $$a_{n} = \frac{(n + 1)^{n + 1}}{n^{n}}$$ then the above result says that $$\lim_{n \to \infty}(a_{n} - a_{n - 1}) = e$$ Now we know that Theorem: If $a_{n} - a_{n - 1} \to L$ then $a_{n}/n \to L$ . Using the example here we see that $$\frac{a_{n}}{n} = \frac{n + 1}{n}\left(1 + \frac{1}{n}\right)^{n} \to e$$ I am thinking of some partial converse to the standard theorem above which can get us from limit of $a_{n}/n$ to limit of $a_{n} - a_{n - 1}$. Another option to prove $(1)$ is to make use of real variable theory. Thus we can put $x = 1/n$ and deal with function $f(x) = \left(1 + \dfrac{1}{x}\right)(1 + x)^{1/x}$ and use Taylor expansion $$(1 + x)^{1/x} = e - \frac{ex}{2} + \frac{11e}{24}x^{2} + \cdots$$ and $$g(x) = \left(\frac{1}{x} - 1\right)(1 - x)^{-1/x}$$ and calculate the limit of $f(x) - g(x)$ as $x \to 0$. This way we see that $$f(x) = \frac{e}{2} + \frac{e}{x} + o(1), g(x) = -\frac{e}{2} + \frac{e}{x} + o(1)$$ and clearly $f(x) - g(x) \to e$ as $x \to 0$. Is there a proof without using real variable theory and just dealing with theorems on sequences which establishes the result $(1)$?",,"['calculus', 'limits']"
17,"Integral of $\frac{\sin^2(nx/2)}{\sin^2(x/2)}$ over $[-\pi,\pi]$.",Integral of  over .,"\frac{\sin^2(nx/2)}{\sin^2(x/2)} [-\pi,\pi]","I would like to show that $$\frac{1}{n\pi}\int_{-\pi}^\pi \frac{\sin^2(nx/2)}{2\sin^2(x/2)} dx = 1$$ My attempt is very similar to the accepted answer to this question. $$\int_{-\pi}^\pi \frac{\sin^2(nx/2)}{2\sin^2(x/2)} dx = \frac{1}{2} \int_{-\pi}^\pi {1-\cos(n x)\over 1-\cos(x)}dx$$ I have $\int_{-\pi}^{\pi}{1-\cos(n x)\over 1-\cos(x)}dx$, then  $$\cos\bigl((n+1)x\bigr)+\cos\bigl((n-1)x\bigr)=2\cos x\, \cos(nx)\ ,$$ that gives $$1-\cos\bigl((n+1)x\bigr)=2(1-\cos x)\cos(nx)+ 2\bigl(1-\cos(nx)\bigr)-\bigl(1-\cos((n-1)x\bigr)\ .$$ Except $$\int_{-\pi}^{\pi}\cos(nx)\ dx= \frac{1}{n} \sin(n\pi) \ne 0$$ does not go away. So I do not get the right conclusion in the recursion at the end. Where is my mistake?","I would like to show that $$\frac{1}{n\pi}\int_{-\pi}^\pi \frac{\sin^2(nx/2)}{2\sin^2(x/2)} dx = 1$$ My attempt is very similar to the accepted answer to this question. $$\int_{-\pi}^\pi \frac{\sin^2(nx/2)}{2\sin^2(x/2)} dx = \frac{1}{2} \int_{-\pi}^\pi {1-\cos(n x)\over 1-\cos(x)}dx$$ I have $\int_{-\pi}^{\pi}{1-\cos(n x)\over 1-\cos(x)}dx$, then  $$\cos\bigl((n+1)x\bigr)+\cos\bigl((n-1)x\bigr)=2\cos x\, \cos(nx)\ ,$$ that gives $$1-\cos\bigl((n+1)x\bigr)=2(1-\cos x)\cos(nx)+ 2\bigl(1-\cos(nx)\bigr)-\bigl(1-\cos((n-1)x\bigr)\ .$$ Except $$\int_{-\pi}^{\pi}\cos(nx)\ dx= \frac{1}{n} \sin(n\pi) \ne 0$$ does not go away. So I do not get the right conclusion in the recursion at the end. Where is my mistake?",,"['calculus', 'integration', 'trigonometry', 'definite-integrals']"
18,Evaluating: $I_1 = \int\sin^{-1} \left(\sqrt{\frac{x}{x+a}}\;\right) dx$,Evaluating:,I_1 = \int\sin^{-1} \left(\sqrt{\frac{x}{x+a}}\;\right) dx,"$$I_1 =\int \sin^{-1} \left(\sqrt{\frac{x}{x+a}}\;\right) dx= ?$$ I tried substitution: $\sin^{-1} \left(\sqrt{\frac{x}{x+a}}\;\right) = \Xi$, but then I'm not able to do anything after the resulting integral. Could someone help? There must be a simple way to solve this...","$$I_1 =\int \sin^{-1} \left(\sqrt{\frac{x}{x+a}}\;\right) dx= ?$$ I tried substitution: $\sin^{-1} \left(\sqrt{\frac{x}{x+a}}\;\right) = \Xi$, but then I'm not able to do anything after the resulting integral. Could someone help? There must be a simple way to solve this...",,"['calculus', 'integration', 'trigonometry', 'indefinite-integrals']"
19,"What is the difference between ""closed "" and ""bounded"" in terms of domains?","What is the difference between ""closed "" and ""bounded"" in terms of domains?",,"I'm working on understanding double & triple integrals (and 3-space geometry in general) and I often encounter in my textbooks the requirement that f is continuous on ""a closed bounded domain"". Wouldn't these concepts be the same thing? Like, if a domain is closed, it contains it's endpoints, and it thus necessarily finite, and if it is bounded it is contained within some ""ball"" of finite radius centered around the origin and is so finite. I can't really imagine a domain being closed, and not bound, or vice versa. Am I missing some detail in distinguishing these two?","I'm working on understanding double & triple integrals (and 3-space geometry in general) and I often encounter in my textbooks the requirement that f is continuous on ""a closed bounded domain"". Wouldn't these concepts be the same thing? Like, if a domain is closed, it contains it's endpoints, and it thus necessarily finite, and if it is bounded it is contained within some ""ball"" of finite radius centered around the origin and is so finite. I can't really imagine a domain being closed, and not bound, or vice versa. Am I missing some detail in distinguishing these two?",,"['calculus', 'definite-integrals']"
20,About the series $\sum_{n\geq 0}\frac{1}{(2n+1)^2+k}$ and the digamma function,About the series  and the digamma function,\sum_{n\geq 0}\frac{1}{(2n+1)^2+k},"Let we provide a closed form for  $$ S_k = \sum_{n\geq 0}\frac{1}{(2n+1)^2+k} $$ for $k>0$ in terms of elementary functions. It is quite easy to check that $S_k$ can be computed in terms of the digamma function $\psi(x)$, but it is also true that: $$ \int_{0}^{+\infty}\frac{\sin(mx)}{m}e^{-\sqrt{k}\,x}\,dx =\frac{1}{m^2+k}\tag{1} $$ and that, almost everywhere: $$ \sum_{n\geq 0}\frac{\sin((2n+1) x)}{2n+1} = \frac{\pi}{4}(-1)^{\left\lfloor\frac{x}{\pi}\right\rfloor}, \tag{2}$$ hence: $$\begin{eqnarray*} S_k &=& \frac{\pi}{4}\int_{0}^{+\infty}(-1)^{\left\lfloor\frac{x}{\pi}\right\rfloor} e^{-\sqrt{k}\,x}\,dx = \frac{\pi}{4}\sum_{n\geq 0}(-1)^n \int_{n\pi}^{(n+1)\pi}e^{-\sqrt{k}\,x}\,dx \\&=&\frac{\pi}{4\sqrt{k}}\sum_{n\geq 0}(-1)^n\left(e^{-n\pi\sqrt{k}}-e^{-(n+1)\pi\sqrt{k}}\right)\\&=&\frac{\pi\left(1-e^{-\pi\sqrt{k}}\right)  }{4\sqrt{k}}\sum_{n\geq 0}(-1)^n e^{-n\pi\sqrt{k}}=\color{red}{\frac{\pi}{4\sqrt{k}}\cdot\frac{e^{\pi\sqrt{k}}-1}{e^{\pi\sqrt{k}}+1}}.\tag{3} \end{eqnarray*}$$ Does this identity provide something interesting about special values of the digamma function?","Let we provide a closed form for  $$ S_k = \sum_{n\geq 0}\frac{1}{(2n+1)^2+k} $$ for $k>0$ in terms of elementary functions. It is quite easy to check that $S_k$ can be computed in terms of the digamma function $\psi(x)$, but it is also true that: $$ \int_{0}^{+\infty}\frac{\sin(mx)}{m}e^{-\sqrt{k}\,x}\,dx =\frac{1}{m^2+k}\tag{1} $$ and that, almost everywhere: $$ \sum_{n\geq 0}\frac{\sin((2n+1) x)}{2n+1} = \frac{\pi}{4}(-1)^{\left\lfloor\frac{x}{\pi}\right\rfloor}, \tag{2}$$ hence: $$\begin{eqnarray*} S_k &=& \frac{\pi}{4}\int_{0}^{+\infty}(-1)^{\left\lfloor\frac{x}{\pi}\right\rfloor} e^{-\sqrt{k}\,x}\,dx = \frac{\pi}{4}\sum_{n\geq 0}(-1)^n \int_{n\pi}^{(n+1)\pi}e^{-\sqrt{k}\,x}\,dx \\&=&\frac{\pi}{4\sqrt{k}}\sum_{n\geq 0}(-1)^n\left(e^{-n\pi\sqrt{k}}-e^{-(n+1)\pi\sqrt{k}}\right)\\&=&\frac{\pi\left(1-e^{-\pi\sqrt{k}}\right)  }{4\sqrt{k}}\sum_{n\geq 0}(-1)^n e^{-n\pi\sqrt{k}}=\color{red}{\frac{\pi}{4\sqrt{k}}\cdot\frac{e^{\pi\sqrt{k}}-1}{e^{\pi\sqrt{k}}+1}}.\tag{3} \end{eqnarray*}$$ Does this identity provide something interesting about special values of the digamma function?",,"['calculus', 'sequences-and-series', 'special-functions', 'closed-form', 'polylogarithm']"
21,Help to understand this property: $\int\limits_{ka}^{kb}s\left(\frac{x}{k}\right)dx = k\int\limits_a^bs(x)dx$,Help to understand this property:,\int\limits_{ka}^{kb}s\left(\frac{x}{k}\right)dx = k\int\limits_a^bs(x)dx,"I'm reading the part explaining the properties of the integral of a step function in Apostol's Calculus I and he explains this property: $$\int\limits_{ka}^{kb}s\left(\frac{x}{k}\right)dx = k\int\limits_a^bs(x)dx$$ by saying that if we distort the horizontal direction (say, the length) by a $k > 0$, it is the same as multiplying the integral by $k$. Intuitively it makes sense: if the area of a rectangle is $\text{Length} \cdot \text{Height}$, then $$(k\cdot \text{Length}) \cdot \text{Height} = k\cdot(\text{Length} \cdot \text{Height})$$ But I have some troubles in understanding the form this property takes with ''trickier'' stretching of the interval of integration. I have been playing with the symbol $\int\limits_a^bs(x)dx$ since then, but I'm not sure whether what I did is right. For instance: Would: $$ \begin{align*} &1. \qquad \int\limits_{ka}^{kb}s(x)dx = k\int\limits_a^bs\left(\frac{x}{k}\right)dx\qquad \text{?}\\ &2. \qquad \int\limits_{\sqrt{a}}^{\sqrt{b}}s(x)dx = \left[\int\limits_a^bs(x^2)dx\right]^{1/2}\qquad \text{?}\\ &3. \qquad \int\limits_{a^2}^{b^2}s(x)dx = \left[\int\limits_a^bs(\sqrt{x})dx\right]^{2}\qquad \text{?}\\ &4. \qquad \int\limits_{a/k}^{b/k}s(x)dx = \frac{1}{k}\int\limits_a^bs(kx)dx\qquad \text{?} \end{align*} $$ In each case what I did was the following: Let take $2.$ as an example. If $\sqrt{a} < x < \sqrt{b} \implies a < x^2 < b \implies x^2$ is in the domain of $s$. Then the integrand is $s(x^2)$ on $[a,b]$ and the stretching of the interval (the square root) ''drops'' to the whole integral: $\left[\int\limits_a^bs(x^2)dx\right]^{1/2}$. If this is correct, then mechanically I know how it works but I'm not able to explain why (in particular, that part where the stretching of $[a,b]$ drops to the integral). Thanks!!","I'm reading the part explaining the properties of the integral of a step function in Apostol's Calculus I and he explains this property: $$\int\limits_{ka}^{kb}s\left(\frac{x}{k}\right)dx = k\int\limits_a^bs(x)dx$$ by saying that if we distort the horizontal direction (say, the length) by a $k > 0$, it is the same as multiplying the integral by $k$. Intuitively it makes sense: if the area of a rectangle is $\text{Length} \cdot \text{Height}$, then $$(k\cdot \text{Length}) \cdot \text{Height} = k\cdot(\text{Length} \cdot \text{Height})$$ But I have some troubles in understanding the form this property takes with ''trickier'' stretching of the interval of integration. I have been playing with the symbol $\int\limits_a^bs(x)dx$ since then, but I'm not sure whether what I did is right. For instance: Would: $$ \begin{align*} &1. \qquad \int\limits_{ka}^{kb}s(x)dx = k\int\limits_a^bs\left(\frac{x}{k}\right)dx\qquad \text{?}\\ &2. \qquad \int\limits_{\sqrt{a}}^{\sqrt{b}}s(x)dx = \left[\int\limits_a^bs(x^2)dx\right]^{1/2}\qquad \text{?}\\ &3. \qquad \int\limits_{a^2}^{b^2}s(x)dx = \left[\int\limits_a^bs(\sqrt{x})dx\right]^{2}\qquad \text{?}\\ &4. \qquad \int\limits_{a/k}^{b/k}s(x)dx = \frac{1}{k}\int\limits_a^bs(kx)dx\qquad \text{?} \end{align*} $$ In each case what I did was the following: Let take $2.$ as an example. If $\sqrt{a} < x < \sqrt{b} \implies a < x^2 < b \implies x^2$ is in the domain of $s$. Then the integrand is $s(x^2)$ on $[a,b]$ and the stretching of the interval (the square root) ''drops'' to the whole integral: $\left[\int\limits_a^bs(x^2)dx\right]^{1/2}$. If this is correct, then mechanically I know how it works but I'm not able to explain why (in particular, that part where the stretching of $[a,b]$ drops to the integral). Thanks!!",,"['calculus', 'integration', 'definite-integrals']"
22,Differential equation $\cos(f')=\cos(f)'$,Differential equation,\cos(f')=\cos(f)',The differential equation $$\sin(f')=\sin(f)'$$ has the trivial solution $f=0$. Does the equation $$\cos(f')=\cos(f)'$$ have any solutions?,The differential equation $$\sin(f')=\sin(f)'$$ has the trivial solution $f=0$. Does the equation $$\cos(f')=\cos(f)'$$ have any solutions?,,['calculus']
23,Is the integral of the sum really the sum of the integrals?,Is the integral of the sum really the sum of the integrals?,,"I was asked to find the mclaurin series of $\int_0^x\frac{\arctan (t)}{t}dt$ using the known mclaurin for arctan: $\arctan(t)=\sum_{n=1}^{\infty} \frac{(-1)^{n+1}t^{2n-1}}{2n-1}$ Ok, so what I did is use the known formula: $$\int_0^x\frac{\arctan (t)}{t}=\int_0^x\frac{\sum_{n=1}^{\infty} \frac{(-1)^{n+1}t^{2n-1}}{2n-1}}{t}dt=\int_0^x\sum_{n=1}^{\infty}\frac{(-1)^{n+1}t^{2n-2}}{2n-1}dt$$ This is nothing more than $\int_0^x1-\frac{t^2}{3}+\frac{t^4}{5}-\cdots dt$. If this was a finite sum, then yes, for sure I can divide it into separate integrals. But this is an infinite sum. The integrand is a polynomial, an integrable and even continuous function so I don't see any reason why we can't separate that integral of the sum into the sum of the integrals, but it's not apparent to me why it's obvious that we can do that either. But if we can, then the mclaurin series we were looking for is $\sum_{n=1}^{\infty}\int_0^x\frac{(-1)^{n+1}t^{2n-2}}{2n-1}dt$ is this correct? if so - can we always separate the integral of the sum into sum of integrals? even infinite sums?","I was asked to find the mclaurin series of $\int_0^x\frac{\arctan (t)}{t}dt$ using the known mclaurin for arctan: $\arctan(t)=\sum_{n=1}^{\infty} \frac{(-1)^{n+1}t^{2n-1}}{2n-1}$ Ok, so what I did is use the known formula: $$\int_0^x\frac{\arctan (t)}{t}=\int_0^x\frac{\sum_{n=1}^{\infty} \frac{(-1)^{n+1}t^{2n-1}}{2n-1}}{t}dt=\int_0^x\sum_{n=1}^{\infty}\frac{(-1)^{n+1}t^{2n-2}}{2n-1}dt$$ This is nothing more than $\int_0^x1-\frac{t^2}{3}+\frac{t^4}{5}-\cdots dt$. If this was a finite sum, then yes, for sure I can divide it into separate integrals. But this is an infinite sum. The integrand is a polynomial, an integrable and even continuous function so I don't see any reason why we can't separate that integral of the sum into the sum of the integrals, but it's not apparent to me why it's obvious that we can do that either. But if we can, then the mclaurin series we were looking for is $\sum_{n=1}^{\infty}\int_0^x\frac{(-1)^{n+1}t^{2n-2}}{2n-1}dt$ is this correct? if so - can we always separate the integral of the sum into sum of integrals? even infinite sums?",,"['calculus', 'integration', 'summation', 'taylor-expansion', 'infinity']"
24,Derivative of an integral with respect to a function,Derivative of an integral with respect to a function,,"Can some one help me out this derivative: $$ \frac{\partial\int_{-\infty}^\infty f(x)g(x)\,dx}{\partial g} $$ Appreciate any explanation! Many thanks to those who answered or commented on my question! Maybe I am not very clear about my question or I might have misunderstood what I need. I was reading a Quantum Field Theory textbook and trying to verify the following equation: $$ \langle 0\mid 0\rangle_{f, h} = \int Dp\,Dq \exp \left[i\int_{-\infty}^\infty dt(p\dot q-H_0(p, q)-H_1(p, q)+fq+hp)\right] $$ $$ =\exp \left[ -i\int_{-\infty}^\infty dt \, H_1 \left( \frac 1 i \frac \delta {\delta h(t)}, \frac 1 i \frac{\delta}{\delta f(t)} \right) \right]\times \int Dp\,Dq\, \exp \left[ i\int_{-\infty}^\infty dt\,(p\dot q-H_0(p, q)+fq+hp) \right] $$ I expanded the first exponential of the second line to a Taylor series. Thus every term is a derivative with respect to either $h(t)$ or $g(t)$. And then I got lost. I guess this is related to functional derivatives and I tried to search some examples but I failed. Or maybe it's just I didn't realize I have seen the same thing because of my poor math.","Can some one help me out this derivative: $$ \frac{\partial\int_{-\infty}^\infty f(x)g(x)\,dx}{\partial g} $$ Appreciate any explanation! Many thanks to those who answered or commented on my question! Maybe I am not very clear about my question or I might have misunderstood what I need. I was reading a Quantum Field Theory textbook and trying to verify the following equation: $$ \langle 0\mid 0\rangle_{f, h} = \int Dp\,Dq \exp \left[i\int_{-\infty}^\infty dt(p\dot q-H_0(p, q)-H_1(p, q)+fq+hp)\right] $$ $$ =\exp \left[ -i\int_{-\infty}^\infty dt \, H_1 \left( \frac 1 i \frac \delta {\delta h(t)}, \frac 1 i \frac{\delta}{\delta f(t)} \right) \right]\times \int Dp\,Dq\, \exp \left[ i\int_{-\infty}^\infty dt\,(p\dot q-H_0(p, q)+fq+hp) \right] $$ I expanded the first exponential of the second line to a Taylor series. Thus every term is a derivative with respect to either $h(t)$ or $g(t)$. And then I got lost. I guess this is related to functional derivatives and I tried to search some examples but I failed. Or maybe it's just I didn't realize I have seen the same thing because of my poor math.",,"['calculus', 'functional-analysis', 'derivatives']"
25,"What is the operator ""capital D"" and how can the chain rule be used in this way","What is the operator ""capital D"" and how can the chain rule be used in this way",,"I ought to know this but I was somehow always able to avoid mixing partials and $d$s My book notes the following: (with some intermediate steps which are less important than the time taken to write) Here $f$ is a function of $x(t),y(t),z(t),t$ and $u=\frac{dx}{dt}$ and """" for others. $\frac{Df}{Dt}=\frac{\partial f}{\partial t}+(\mathbf{u}\cdot\nabla)f$ I was taught to use $D$ for total derivative but there's no malformed interpretation I could apply here. What is going on and if you were to look it up in an index of a book what would the book be on, and what would you look up? (E.G: Real analysis, partial differentiation) Also I'm not sure how to use bold with LaTeX nor get a special dot. If someone could tell me in the comments I'd be very grateful.","I ought to know this but I was somehow always able to avoid mixing partials and $d$s My book notes the following: (with some intermediate steps which are less important than the time taken to write) Here $f$ is a function of $x(t),y(t),z(t),t$ and $u=\frac{dx}{dt}$ and """" for others. $\frac{Df}{Dt}=\frac{\partial f}{\partial t}+(\mathbf{u}\cdot\nabla)f$ I was taught to use $D$ for total derivative but there's no malformed interpretation I could apply here. What is going on and if you were to look it up in an index of a book what would the book be on, and what would you look up? (E.G: Real analysis, partial differentiation) Also I'm not sure how to use bold with LaTeX nor get a special dot. If someone could tell me in the comments I'd be very grateful.",,"['calculus', 'multivariable-calculus', 'reference-request']"
26,Evaluating the Definite Integral $\int_0^{\pi}\cos^{2n} \theta d\theta$,Evaluating the Definite Integral,\int_0^{\pi}\cos^{2n} \theta d\theta,"$$\int_0^{\pi}\cos^{2n} \theta d\theta$$ $$u=\cos \theta \implies du= -\sin \theta d\theta \implies d\theta= -\frac{du}{1-u^2} $$ $$\int_{-1}^1 \frac{u^n}{1-u^2} du=\int_{-1}^1 \frac{u^n}{(1-u)(1+u)}du$$ I have no idea what to do next, any guidance is appreciated!","$$\int_0^{\pi}\cos^{2n} \theta d\theta$$ $$u=\cos \theta \implies du= -\sin \theta d\theta \implies d\theta= -\frac{du}{1-u^2} $$ $$\int_{-1}^1 \frac{u^n}{1-u^2} du=\int_{-1}^1 \frac{u^n}{(1-u)(1+u)}du$$ I have no idea what to do next, any guidance is appreciated!",,"['calculus', 'integration', 'definite-integrals', 'trigonometric-integrals']"
27,Is this a correct use of the squeeze theorem?,Is this a correct use of the squeeze theorem?,,"I have to find the following limit: $$ \lim_{x\to0,y\to0} \frac{x^2y^2}{x^2+y^4}=[\frac{0}{0}] $$ I try to reach the origin moving on the y-axis ($x=0$): $$ \lim_{y\to0} \frac{0}{y^4}=0 $$ I get the same result when I am moving on the x-axis ($y=0$): $$ \lim_{x\to0} \frac{0}{x^2}=0 $$ The same if I move over ($y=x$): $$ \lim_{y\to0} \frac{x^2x^2}{x^2+x^4}=\lim_{y\to0} \frac{x^2}{1+x^2} = 0 $$ So I start to get confident that the limit should be 0. Let's prove it. $$ \left| f(x,y) - l \right| = \left| f(x,y) - 0 \right| =  \left| \frac{x^2y^2}{x^2+y^4} \right|  $$ Looking at the fraction we know that: $$ x^2 \leq x^2+y^4 $$ So... $$ \frac {x^2} {x^2+y^4} \leq 1 \forall (x,y) \neq (0,0) $$ We can now say that: $$ \left|y^2\frac{x^2}{x^2+y^4}\right|\leq \left|y^2\right| $$ So for the squeeze theorem we have to get: $$ -h(x,y) \leq f(x,y) \leq h(x,y) $$ And.. $$ \lim_{x\to0,y\to0} h(x,y) = \lim_{x\to0,y\to0} y^2 = 0 $$ So we can say that the limit is 0. Is this prove right? Are there other kind of prove I can learn?","I have to find the following limit: $$ \lim_{x\to0,y\to0} \frac{x^2y^2}{x^2+y^4}=[\frac{0}{0}] $$ I try to reach the origin moving on the y-axis ($x=0$): $$ \lim_{y\to0} \frac{0}{y^4}=0 $$ I get the same result when I am moving on the x-axis ($y=0$): $$ \lim_{x\to0} \frac{0}{x^2}=0 $$ The same if I move over ($y=x$): $$ \lim_{y\to0} \frac{x^2x^2}{x^2+x^4}=\lim_{y\to0} \frac{x^2}{1+x^2} = 0 $$ So I start to get confident that the limit should be 0. Let's prove it. $$ \left| f(x,y) - l \right| = \left| f(x,y) - 0 \right| =  \left| \frac{x^2y^2}{x^2+y^4} \right|  $$ Looking at the fraction we know that: $$ x^2 \leq x^2+y^4 $$ So... $$ \frac {x^2} {x^2+y^4} \leq 1 \forall (x,y) \neq (0,0) $$ We can now say that: $$ \left|y^2\frac{x^2}{x^2+y^4}\right|\leq \left|y^2\right| $$ So for the squeeze theorem we have to get: $$ -h(x,y) \leq f(x,y) \leq h(x,y) $$ And.. $$ \lim_{x\to0,y\to0} h(x,y) = \lim_{x\to0,y\to0} y^2 = 0 $$ So we can say that the limit is 0. Is this prove right? Are there other kind of prove I can learn?",,"['calculus', 'limits', 'multivariable-calculus']"
28,Stuck on integrating $\int x/(1-x)dx$,Stuck on integrating,\int x/(1-x)dx,"My attempt: Let $u = 1-x$ , $du = -dx$ , $x = 1-u$, so:  \begin{align*} \int \frac{x}{1-x}\, dx &= - \int \frac{1-u}u\, du \\ &= - \left( \int \frac 1 u\, du - \int 1 \, du \right) \\ &= - \ln(|u|) + u \\  &= -\ln(|1-x|) + (1-x) \end{align*} But the answer is supposed to be $-x - \ln(|1-x|)$. Why do I have an extra 1?","My attempt: Let $u = 1-x$ , $du = -dx$ , $x = 1-u$, so:  \begin{align*} \int \frac{x}{1-x}\, dx &= - \int \frac{1-u}u\, du \\ &= - \left( \int \frac 1 u\, du - \int 1 \, du \right) \\ &= - \ln(|u|) + u \\  &= -\ln(|1-x|) + (1-x) \end{align*} But the answer is supposed to be $-x - \ln(|1-x|)$. Why do I have an extra 1?",,"['calculus', 'integration']"
29,Generalized forms of Curl and Divergence,Generalized forms of Curl and Divergence,,"The definitions I learned in my calculus courses for curl and divergence were rather, at least to me, unintuitive and seemed to work only for $\mathbb{R}^3$. I took a look on Wikipedia: ""The divergence of a vector field $F$ at a point $p$ is defined as the limit of the net flow of $F$ across the smooth boundary of a three-dimensional region $V$ divided by the volume of V as $V$ shrinks to $p$. Formally: $$\operatorname{div}\,\mathbf{F}(p) =  \lim_{V \rightarrow \{p\}} \iint_{S(V)} {\mathbf{F}\cdot\mathbf{n} \over |V| } \; dS$$ The curl of a vector field F, denoted by $\operatorname{curl} \, \mathbf{F}$, or $\nabla \times F$, at a point is defined in terms of its projection onto various lines through the point. If $\scriptstyle\mathbf{\hat{n}}$ is any unit vector, the projection of the curl of $F$ onto $\scriptstyle\mathbf{\hat{n}}$ is defined to be the limiting value of a closed line integral in a plane orthogonal to $\scriptstyle\mathbf{\hat{n}}$ as the path used in the integral becomes infinitesimally close to the point, divided by the area enclosed. As such, the curl operator maps continuously differentiable functions $f : \mathbb{R}^3 \to \mathbb{R}^3$ to continuous functions $g : \mathbb{R}^3 \to \mathbb{R}^3$. Implicitly, curl is defined by: $$(\nabla \times \mathbf{F}) \cdot \mathbf{\hat{n}} \ \overset{\underset{\mathrm{def}}{}}{=} \lim_{A \to 0}\left( \frac{1}{|A|}\oint_{C} \mathbf{F} \cdot d\mathbf{r}\right)$$ "" To me, ""intuitively"", it seems that divergence at a point involves making a closed surface around the point, measuring the total flux, and dividing that by the volume of the closed surface. Even more simply put, it is the net measure of how much ""flow"" is going in or out. For the curl at a point, we formulate a plane around the point, take an integral of the closed loop around the point and divide by the area enclosed by the loop. More simply, one could imagine a tiny sphere in $\mathbb{R}^3$. The curl tells us how that sphere is rotating by giving a vector. The vector tells us the direction and speed of rotation. Does anyone perhaps have a better or more intuitive way of viewing curl and divergence? I was also wondering if there is a general definition that works for any given vector space over any field, even finite fields. But then integration and dot products and even limits might not make sense.","The definitions I learned in my calculus courses for curl and divergence were rather, at least to me, unintuitive and seemed to work only for $\mathbb{R}^3$. I took a look on Wikipedia: ""The divergence of a vector field $F$ at a point $p$ is defined as the limit of the net flow of $F$ across the smooth boundary of a three-dimensional region $V$ divided by the volume of V as $V$ shrinks to $p$. Formally: $$\operatorname{div}\,\mathbf{F}(p) =  \lim_{V \rightarrow \{p\}} \iint_{S(V)} {\mathbf{F}\cdot\mathbf{n} \over |V| } \; dS$$ The curl of a vector field F, denoted by $\operatorname{curl} \, \mathbf{F}$, or $\nabla \times F$, at a point is defined in terms of its projection onto various lines through the point. If $\scriptstyle\mathbf{\hat{n}}$ is any unit vector, the projection of the curl of $F$ onto $\scriptstyle\mathbf{\hat{n}}$ is defined to be the limiting value of a closed line integral in a plane orthogonal to $\scriptstyle\mathbf{\hat{n}}$ as the path used in the integral becomes infinitesimally close to the point, divided by the area enclosed. As such, the curl operator maps continuously differentiable functions $f : \mathbb{R}^3 \to \mathbb{R}^3$ to continuous functions $g : \mathbb{R}^3 \to \mathbb{R}^3$. Implicitly, curl is defined by: $$(\nabla \times \mathbf{F}) \cdot \mathbf{\hat{n}} \ \overset{\underset{\mathrm{def}}{}}{=} \lim_{A \to 0}\left( \frac{1}{|A|}\oint_{C} \mathbf{F} \cdot d\mathbf{r}\right)$$ "" To me, ""intuitively"", it seems that divergence at a point involves making a closed surface around the point, measuring the total flux, and dividing that by the volume of the closed surface. Even more simply put, it is the net measure of how much ""flow"" is going in or out. For the curl at a point, we formulate a plane around the point, take an integral of the closed loop around the point and divide by the area enclosed by the loop. More simply, one could imagine a tiny sphere in $\mathbb{R}^3$. The curl tells us how that sphere is rotating by giving a vector. The vector tells us the direction and speed of rotation. Does anyone perhaps have a better or more intuitive way of viewing curl and divergence? I was also wondering if there is a general definition that works for any given vector space over any field, even finite fields. But then integration and dot products and even limits might not make sense.",,"['calculus', 'multivariable-calculus']"
30,Why does substitution work for a maclaurin series but not a taylor series?,Why does substitution work for a maclaurin series but not a taylor series?,,Say I was trying to calculate the taylor expansion of $\sin(x^2)$ around $x = 0$. I could assume that $u = x^2$ and solve for taylor expansion around $x=0$ of $\sin(u)$. I would just need to substitute $x^2$ back in for $u$ when I am completed. I have been informed that this process of substitution works only for the maclaurin series and not for any taylor series centered about a non-zero point? Why is this the case? Why is substitution even allowed in the first place?,Say I was trying to calculate the taylor expansion of $\sin(x^2)$ around $x = 0$. I could assume that $u = x^2$ and solve for taylor expansion around $x=0$ of $\sin(u)$. I would just need to substitute $x^2$ back in for $u$ when I am completed. I have been informed that this process of substitution works only for the maclaurin series and not for any taylor series centered about a non-zero point? Why is this the case? Why is substitution even allowed in the first place?,,['calculus']
31,Physical intuition behind Green's theorem?,Physical intuition behind Green's theorem?,,"I get what the theorem is saying. The circulation of the curve is equal to adding up the ""microscopic"" curls. But why? Why does adding up the ""microscopic curls"" give you the circulation? Could someone give me an explanation of it using a physical analogy? I.e. an object rotating in moving body of water?","I get what the theorem is saying. The circulation of the curve is equal to adding up the ""microscopic"" curls. But why? Why does adding up the ""microscopic curls"" give you the circulation? Could someone give me an explanation of it using a physical analogy? I.e. an object rotating in moving body of water?",,"['calculus', 'multivariable-calculus', 'differential-geometry', 'vector-analysis']"
32,Why limit $\sqrt{\frac{\sin(x)}{x}}$ as $x \rightarrow \infty$ is not a real number?,Why limit  as  is not a real number?,\sqrt{\frac{\sin(x)}{x}} x \rightarrow \infty,"Let  $f(x)=\sqrt{\frac{\sin(x)}{x}}$. Why isn't the $\lim\limits_{x\rightarrow \infty} f(x)$ equals to some $l \in \mathbb{R}$? The definition of a finite limit at inifinity is: $$\forall \epsilon>0, \exists X \in \mathbb{R}, \forall x \ge X,|f(x)-l| <\epsilon  \tag{1}$$ It looks to me that $l=0$ meets the above definition... I know that the negation of the definition of a finite limit at infinity is: $\exists \epsilon >0 , \forall X \in \mathbb{R}, \exists x \in \mathbb{R}, x\ge X \Rightarrow  |f(x)-l| >=\epsilon \tag{2}$ Is $(2)$ true because, for any $X\in \mathbb{R}$, there will be an $x\ge X$ and $f(x)$ is undefined (i.e. the points where $\frac{\sin(x)}{x} < 0$) and we say the distance between $f(x)$ at these points and any $l\in\mathbb{R}$ is undefined and hence considered as greater than or equal to any $\epsilon > 0$? If yes, how do I write this out using the delta-epsilon proof? Otherwise, please tell me how to prove $(2)$ EDIT: The definition for a finite limit and infinity according to my text is: We say that $f(x)\rightarrow l$ as $x\rightarrow \infty$ for some real number,$l$, if: for any $\epsilon>0$, there is an $X$ such that, for all $x\ge X$, $|f(x)-l|<\epsilon$","Let  $f(x)=\sqrt{\frac{\sin(x)}{x}}$. Why isn't the $\lim\limits_{x\rightarrow \infty} f(x)$ equals to some $l \in \mathbb{R}$? The definition of a finite limit at inifinity is: $$\forall \epsilon>0, \exists X \in \mathbb{R}, \forall x \ge X,|f(x)-l| <\epsilon  \tag{1}$$ It looks to me that $l=0$ meets the above definition... I know that the negation of the definition of a finite limit at infinity is: $\exists \epsilon >0 , \forall X \in \mathbb{R}, \exists x \in \mathbb{R}, x\ge X \Rightarrow  |f(x)-l| >=\epsilon \tag{2}$ Is $(2)$ true because, for any $X\in \mathbb{R}$, there will be an $x\ge X$ and $f(x)$ is undefined (i.e. the points where $\frac{\sin(x)}{x} < 0$) and we say the distance between $f(x)$ at these points and any $l\in\mathbb{R}$ is undefined and hence considered as greater than or equal to any $\epsilon > 0$? If yes, how do I write this out using the delta-epsilon proof? Otherwise, please tell me how to prove $(2)$ EDIT: The definition for a finite limit and infinity according to my text is: We say that $f(x)\rightarrow l$ as $x\rightarrow \infty$ for some real number,$l$, if: for any $\epsilon>0$, there is an $X$ such that, for all $x\ge X$, $|f(x)-l|<\epsilon$",,"['calculus', 'limits', 'definition', 'epsilon-delta']"
33,Integrating $\int_0^{\pi/2}{x^2}\ln^2(\sin x)\ln(\cos x)dx$ and $\int_0^{\pi/2}x\ln(\sin x)\ln^2(\cos x)dx$,Integrating  and,\int_0^{\pi/2}{x^2}\ln^2(\sin x)\ln(\cos x)dx \int_0^{\pi/2}x\ln(\sin x)\ln^2(\cos x)dx,How to evaluate these integrals? $$\int_0^{\pi/2}{x^2}\ln^2(\sin x)\ln(\cos x)dx \tag{1}$$ $$\int_0^{\pi/2}x\ln(\sin x)\ln^2(\cos x)dx \tag{2}$$,How to evaluate these integrals?,\int_0^{\pi/2}{x^2}\ln^2(\sin x)\ln(\cos x)dx \tag{1} \int_0^{\pi/2}x\ln(\sin x)\ln^2(\cos x)dx \tag{2},"['calculus', 'integration', 'trigonometry']"
34,permutation and f(n) challenge,permutation and f(n) challenge,,"Suppose $f(n)$ be the number of permutation from set ${1,2,..,n}$ such that for each $ 1 \leq i \leq n$ we have: $ | \pi(i)-i| \leq 1 $. meaning of $ \pi(i)$ is an elements whose in place $i$ of permutation. for example in permutation $<2,3,1>$, $ \pi(1)=2$. how we reach to $f(10)= 89$","Suppose $f(n)$ be the number of permutation from set ${1,2,..,n}$ such that for each $ 1 \leq i \leq n$ we have: $ | \pi(i)-i| \leq 1 $. meaning of $ \pi(i)$ is an elements whose in place $i$ of permutation. for example in permutation $<2,3,1>$, $ \pi(1)=2$. how we reach to $f(10)= 89$",,"['calculus', 'discrete-mathematics', 'permutations', 'recurrence-relations', 'contest-math']"
35,How can I evaluate this indefinite integral? $\int\frac{dx}{1+x^8}$,How can I evaluate this indefinite integral?,\int\frac{dx}{1+x^8},How do I find $\displaystyle\int\dfrac{dx}{1+x^8}$? My friend asked me to find $\displaystyle\int\dfrac{dx}{1+x^{2n}}$ for a positive integer $n$. But looking up I am getting pretty noisy answer for a general value. I have seen that $\displaystyle\int\dfrac{dx}{1+x^6}$ can be broken into partial fractions because of the odd factor of $6$. So I am curious what is the algorithm to compute the integral for $n$ being a power of $2$.,How do I find $\displaystyle\int\dfrac{dx}{1+x^8}$? My friend asked me to find $\displaystyle\int\dfrac{dx}{1+x^{2n}}$ for a positive integer $n$. But looking up I am getting pretty noisy answer for a general value. I have seen that $\displaystyle\int\dfrac{dx}{1+x^6}$ can be broken into partial fractions because of the odd factor of $6$. So I am curious what is the algorithm to compute the integral for $n$ being a power of $2$.,,"['calculus', 'integration', 'indefinite-integrals']"
36,Is $\int^x \cos \frac1t$ differentiable at zero?,Is  differentiable at zero?,\int^x \cos \frac1t,"From Spivak's Calculus , 4th ed., exc 14-20: Let  $$f(x) = \begin{cases} \cos \frac1x, & x\neq 0\\ 0, &x=0.  \end{cases}$$  Is the function $\int_0^xf$ differentiable at zero? I'm having trouble with this one; I'm sure I'm just missing something easy. We seek $$\lim_{h\to0} \frac1h \int_0^h \cos\frac1\xi d\xi.$$ A crude estimation tells us that $\frac1h \int_0^h \cos\frac1\xi d\xi$ is between $-1$ and $1$. Intuitively, it seems that $\int_0^h\cos\frac1\xi d\xi$ is going to zero like $h$. I considered changing variables (although Spivak has not yet introduced this technique, so it shouldn't be necessary) to $$\frac1h \int_{1/h}^\infty \frac{1}{u^2} \cos u,$$ but that didn't really help.","From Spivak's Calculus , 4th ed., exc 14-20: Let  $$f(x) = \begin{cases} \cos \frac1x, & x\neq 0\\ 0, &x=0.  \end{cases}$$  Is the function $\int_0^xf$ differentiable at zero? I'm having trouble with this one; I'm sure I'm just missing something easy. We seek $$\lim_{h\to0} \frac1h \int_0^h \cos\frac1\xi d\xi.$$ A crude estimation tells us that $\frac1h \int_0^h \cos\frac1\xi d\xi$ is between $-1$ and $1$. Intuitively, it seems that $\int_0^h\cos\frac1\xi d\xi$ is going to zero like $h$. I considered changing variables (although Spivak has not yet introduced this technique, so it shouldn't be necessary) to $$\frac1h \int_{1/h}^\infty \frac{1}{u^2} \cos u,$$ but that didn't really help.",,"['calculus', 'integration', 'derivatives']"
37,Integral equals to the intermediate value,Integral equals to the intermediate value,,"Let $f$ be twice continuously differentiable. Prove that there exists $\xi\in (-1,1)$ such that $$\int_{-1}^1 xf(x)dx=\frac{2}{3}f'(\xi)+\frac{1}{3}\xi f''(\xi).$$ What I have tried is as follows. $$\frac{2}{3}f'(\xi)+\frac{1}{3}\xi f''(\xi)=\frac{1}{3}[xf(x)]''|_{x=\xi}.$$ But then how can we do...","Let $f$ be twice continuously differentiable. Prove that there exists $\xi\in (-1,1)$ such that $$\int_{-1}^1 xf(x)dx=\frac{2}{3}f'(\xi)+\frac{1}{3}\xi f''(\xi).$$ What I have tried is as follows. $$\frac{2}{3}f'(\xi)+\frac{1}{3}\xi f''(\xi)=\frac{1}{3}[xf(x)]''|_{x=\xi}.$$ But then how can we do...",,['calculus']
38,Prove that $f(x)=O(x)$ as $x\to 0$,Prove that  as,f(x)=O(x) x\to 0,"Let $f$ be a function defined on $R$. for any absoulutely convergent series $\sum_{n=1}^{\infty}a_{n}$,the series $\sum_{n=1}^{\infty}f(a_{n})$ converges,Prove that $$ f(x)=O(x)\qquad (x\to 0) $$. I have tried to prove the contradiction side,assume that there exist a series which makes  $$ \lim_{n\to\infty}\left|\frac{f(a_{n})}{a_{n}}\right|=+\infty $$ Then I stuck here,Can anybody help me? Thank you very much!","Let $f$ be a function defined on $R$. for any absoulutely convergent series $\sum_{n=1}^{\infty}a_{n}$,the series $\sum_{n=1}^{\infty}f(a_{n})$ converges,Prove that $$ f(x)=O(x)\qquad (x\to 0) $$. I have tried to prove the contradiction side,assume that there exist a series which makes  $$ \lim_{n\to\infty}\left|\frac{f(a_{n})}{a_{n}}\right|=+\infty $$ Then I stuck here,Can anybody help me? Thank you very much!",,['calculus']
39,Moving average as ODE,Moving average as ODE,,Is it possible to represent or approximate the moving average $m(t) = \frac{1}{w}\int_{t-w}^t x(\tau) d\tau$ of a function $x(t)$ as a set of ordinary differential equations $\dot{y} = \ldots$? I am wondering this because I would like to understand if it is possible to encode the moving average (or a suitable approximation) in state space form. Thanks for your input.,Is it possible to represent or approximate the moving average $m(t) = \frac{1}{w}\int_{t-w}^t x(\tau) d\tau$ of a function $x(t)$ as a set of ordinary differential equations $\dot{y} = \ldots$? I am wondering this because I would like to understand if it is possible to encode the moving average (or a suitable approximation) in state space form. Thanks for your input.,,"['calculus', 'ordinary-differential-equations', 'approximation', 'signal-processing']"
40,Evaluation of Integral $ \int\ln(\tan x)dx$,Evaluation of Integral, \int\ln(\tan x)dx,"Compute the indefinite integral   $$ \int\ln(\tan x)\,dx $$ My Attempt: Using $\sin x = \frac{e^{ix}-e^{-ix}}{2i}$ and $\cos x = \frac{e^{ix}-e^{-ix}}{2}$ and remembering that $\ln(\tan x) = \ln(\sin x) - \ln(\cos x)$, we have $$ \begin{align} \int\ln(\tan x)dx &= \int \ln(\sin x)\,dx - \int \ln (\cos x)\,dx\\ &= \int \ln \left(\frac{e^{ix}-e^{-ix}}{2i}\right)\,dx - \int \ln \left(\frac{e^{ix}-e^{-ix}}{2}\right)\,dx\\ &= \int (e^{ix}-e^{-ix})\,dx-\int \ln(2i)\,dx-\int \ln \left(e^{ix}-e^{-ix}\right)\,dx+\int \ln(2)\,dx \end{align} $$ What should I do next to get to the solution?","Compute the indefinite integral   $$ \int\ln(\tan x)\,dx $$ My Attempt: Using $\sin x = \frac{e^{ix}-e^{-ix}}{2i}$ and $\cos x = \frac{e^{ix}-e^{-ix}}{2}$ and remembering that $\ln(\tan x) = \ln(\sin x) - \ln(\cos x)$, we have $$ \begin{align} \int\ln(\tan x)dx &= \int \ln(\sin x)\,dx - \int \ln (\cos x)\,dx\\ &= \int \ln \left(\frac{e^{ix}-e^{-ix}}{2i}\right)\,dx - \int \ln \left(\frac{e^{ix}-e^{-ix}}{2}\right)\,dx\\ &= \int (e^{ix}-e^{-ix})\,dx-\int \ln(2i)\,dx-\int \ln \left(e^{ix}-e^{-ix}\right)\,dx+\int \ln(2)\,dx \end{align} $$ What should I do next to get to the solution?",,"['calculus', 'integration']"
41,Intuition behind Taylor/Maclaurin Series,Intuition behind Taylor/Maclaurin Series,,"** This is a different question than Intuition explanation of taylor expansion? ** I understand some of the intuition behind a Taylor/Maclaurin expansion. More specifically, I understand that adding higher and higher degree polynomials will add more 'turning points' on a graph to better represent the curves of the function you wish to approximate. I don't understand why a.) you add the terms; shouldn't adding terms shift the graph left/right, up/down?  In addition to the question of shifting the graph, I just don't understand why you would add more terms, rather than just change your first term accordingly. I now understand the above, thanks to microarm15 and Nicholas Stull.  I now just do not understand part b of this question b.) the terms added are the successive derivatives of the function.  What does adding successive derivatives mean/give you? Any help on the matter is greatly appreciated. Thanks!","** This is a different question than Intuition explanation of taylor expansion? ** I understand some of the intuition behind a Taylor/Maclaurin expansion. More specifically, I understand that adding higher and higher degree polynomials will add more 'turning points' on a graph to better represent the curves of the function you wish to approximate. I don't understand why a.) you add the terms; shouldn't adding terms shift the graph left/right, up/down?  In addition to the question of shifting the graph, I just don't understand why you would add more terms, rather than just change your first term accordingly. I now understand the above, thanks to microarm15 and Nicholas Stull.  I now just do not understand part b of this question b.) the terms added are the successive derivatives of the function.  What does adding successive derivatives mean/give you? Any help on the matter is greatly appreciated. Thanks!",,"['calculus', 'sequences-and-series', 'taylor-expansion']"
42,Taking Limits with Binomial Coefficients,Taking Limits with Binomial Coefficients,,"I am interested in taking the following limit: \begin{equation} \lim_{n \to \infty}\frac{{n/2 \choose m}}{n \choose m}. \end{equation} Provided that $m$ is fixed the solution is: \begin{equation} \lim_{n \to \infty}\frac{{n/2 \choose m}}{n \choose m}=2^{-m}. \end{equation} This can be seen by writing: \begin{aligned} \frac{{n/2 \choose m}}{n \choose m}&=\frac{\left(\frac{n}{2}\right)!(n-m)!}{\left(\frac{n}{2}-m\right)!n!}\\ &=\prod_{j=0}^{m-1}\frac{\frac{n}{2} -j}{n-j}\\ &=\frac{1}{2^m}\prod_{j=1}^{m-1}\frac{n-2j}{n-j} \end{aligned} and letting $n$ tend to infinity. What however, can be said when $m$ depends on $n$? For example, if $m=\sqrt{n}$? Do we still have the quantity behaving asymptotically like $2^{-\sqrt{n}}$?","I am interested in taking the following limit: \begin{equation} \lim_{n \to \infty}\frac{{n/2 \choose m}}{n \choose m}. \end{equation} Provided that $m$ is fixed the solution is: \begin{equation} \lim_{n \to \infty}\frac{{n/2 \choose m}}{n \choose m}=2^{-m}. \end{equation} This can be seen by writing: \begin{aligned} \frac{{n/2 \choose m}}{n \choose m}&=\frac{\left(\frac{n}{2}\right)!(n-m)!}{\left(\frac{n}{2}-m\right)!n!}\\ &=\prod_{j=0}^{m-1}\frac{\frac{n}{2} -j}{n-j}\\ &=\frac{1}{2^m}\prod_{j=1}^{m-1}\frac{n-2j}{n-j} \end{aligned} and letting $n$ tend to infinity. What however, can be said when $m$ depends on $n$? For example, if $m=\sqrt{n}$? Do we still have the quantity behaving asymptotically like $2^{-\sqrt{n}}$?",,"['calculus', 'algebra-precalculus', 'limits', 'asymptotics', 'binomial-coefficients']"
43,Would you provide a study routine for Spivak's Calculus? [closed],Would you provide a study routine for Spivak's Calculus? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 10 years ago . Improve this question I've been working on Spivak's Calculus for the past few days and although I can manage to solve most problems, they take a lot of time. Some chapters have over 20 exercises and it can take several days to get through the whole list. Would anyone care to provide a list of recommended exercises for each chapter? I take it that this book has been used in several honours course in Calculus, therefore someone should have a related material. Thanks in advance.","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 10 years ago . Improve this question I've been working on Spivak's Calculus for the past few days and although I can manage to solve most problems, they take a lot of time. Some chapters have over 20 exercises and it can take several days to get through the whole list. Would anyone care to provide a list of recommended exercises for each chapter? I take it that this book has been used in several honours course in Calculus, therefore someone should have a related material. Thanks in advance.",,"['calculus', 'self-learning']"
44,Evaluate: $I=\int\limits_{0}^{\frac{\pi}{2}}\ln\frac{(1+\sin x)^{1+\cos x}}{1+\cos x}dx$,Evaluate:,I=\int\limits_{0}^{\frac{\pi}{2}}\ln\frac{(1+\sin x)^{1+\cos x}}{1+\cos x}dx,Evaluate: $$I=\int\limits_{0}^{\frac\pi2}\ln\frac{(1+\sin x)^{1+\cos x}}{1+\cos x}dx$$,Evaluate: $$I=\int\limits_{0}^{\frac\pi2}\ln\frac{(1+\sin x)^{1+\cos x}}{1+\cos x}dx$$,,"['calculus', 'integration', 'definite-integrals']"
45,"Prove there are $\xi$, $\eta$ with $f'(\xi)f'(\eta)=1$","Prove there are ,  with",\xi \eta f'(\xi)f'(\eta)=1,"Let $f:[0,1]\to\mathbb{R}$ be continuous with $f(0)=0$, $f(1)=1$ and $f$ is differentiable on $(0,1)$. Show that there are distinct $\xi,\eta\in(0,1)$ so that $f'(\xi)f'(\eta)=1$. I think this requires mean value theorem. But this does not help since if apply the theorem to $f$ we can only get $f'(c)=1$ for some $c$.","Let $f:[0,1]\to\mathbb{R}$ be continuous with $f(0)=0$, $f(1)=1$ and $f$ is differentiable on $(0,1)$. Show that there are distinct $\xi,\eta\in(0,1)$ so that $f'(\xi)f'(\eta)=1$. I think this requires mean value theorem. But this does not help since if apply the theorem to $f$ we can only get $f'(c)=1$ for some $c$.",,"['calculus', 'derivatives']"
46,Prove: If $|a_n|$ doesn't converge to $\infty$ then $a_n$ must have a finite partial limit.,Prove: If  doesn't converge to  then  must have a finite partial limit.,|a_n| \infty a_n,"Prove: If $|a_n|$ doesn't converges to $\infty$ then $a_n$ must have a finite partial  limit. My thoughts: if $|a_n|$ doesn't converges to $\infty$ there must be two other posibilities: $|a_n|$ converges to a finite number,  $L$ $|a_n|$ doesn't have a limit at all (neither finite, nor $\infty$) for option #1, we can infer $a_n$ is bounded by $L$ and has a converges parital limit (by BW Theorem). EDIT: The correct demand is to prove $a_n$ has a finite partial limit. for option #1 I proved it using BW Theorem. Now I need to prove $a_n$ has a partial finite limit for option #2","Prove: If $|a_n|$ doesn't converges to $\infty$ then $a_n$ must have a finite partial  limit. My thoughts: if $|a_n|$ doesn't converges to $\infty$ there must be two other posibilities: $|a_n|$ converges to a finite number,  $L$ $|a_n|$ doesn't have a limit at all (neither finite, nor $\infty$) for option #1, we can infer $a_n$ is bounded by $L$ and has a converges parital limit (by BW Theorem). EDIT: The correct demand is to prove $a_n$ has a finite partial limit. for option #1 I proved it using BW Theorem. Now I need to prove $a_n$ has a partial finite limit for option #2",,"['calculus', 'limits']"
47,Finding roots of a function in an interval,Finding roots of a function in an interval,,"Does the equation $x^3-12x+2=0$ have three solutions in the interval $[-4,4]$? We know that this is a continuous function because it's a polynomial, and so we can use the Intermediate Value Theorem to do this problem: If $f(x)$ is continuous on $[a,b]$, let $M$ be any number between $f(a)$ and $f(b)$. Then there exists a number $c$ such that: 1) $a<c<b$ 2) $f(c)=M$ If we define $M=0$, $a=-4$ and $b=4$, then $-4<c<4$ and $f(-4)<0<f(4)$. Compute $f(-4)$ and $f(4)$ to show that $f(-4)<0<f(4)$ $\implies -14=f(-4)<0<f(4)<18$. So I've shown that $M$ is between $f(-4)$ and $f(4)$, and thus there must be some number $c$ such that $f(c)=M=0$. Is all of this correct? How do I show that there are three solutions (roots) in this interval? Thank you.","Does the equation $x^3-12x+2=0$ have three solutions in the interval $[-4,4]$? We know that this is a continuous function because it's a polynomial, and so we can use the Intermediate Value Theorem to do this problem: If $f(x)$ is continuous on $[a,b]$, let $M$ be any number between $f(a)$ and $f(b)$. Then there exists a number $c$ such that: 1) $a<c<b$ 2) $f(c)=M$ If we define $M=0$, $a=-4$ and $b=4$, then $-4<c<4$ and $f(-4)<0<f(4)$. Compute $f(-4)$ and $f(4)$ to show that $f(-4)<0<f(4)$ $\implies -14=f(-4)<0<f(4)<18$. So I've shown that $M$ is between $f(-4)$ and $f(4)$, and thus there must be some number $c$ such that $f(c)=M=0$. Is all of this correct? How do I show that there are three solutions (roots) in this interval? Thank you.",,"['calculus', 'functions', 'polynomials', 'roots']"
48,Find $\lim_{x\rightarrow 0} \frac{\cos x - 1}{x}$,Find,\lim_{x\rightarrow 0} \frac{\cos x - 1}{x},I'm trying to find the following limit: $$\lim_{x\rightarrow 0} \frac{\cos x - 1}{x}$$ I tried to use squeeze theorem but it's not making much sense. I did the following: $$\begin{align} &\lim_{x\rightarrow 0} \frac{\cos x - 1}{x} \\ -1 \le &\lim_{x\rightarrow 0} (\cos x)(x^{-1}) \le 1 \\ \lim_{x\rightarrow 0} -x^{-1} \le &\lim_{x\rightarrow 0} \cos x \le \lim_{x\rightarrow 0} x^{-1} \quad \text{*} \end{align}$$ The last line is where I'm confused. I don't think I'm doing squeeze theorem correctly. I'm guessing you have to manipulate $\cos x - 1$ somehow. Please provide some hints. Thanks a bunch! P.S You cannot use L'Hopital.,I'm trying to find the following limit: $$\lim_{x\rightarrow 0} \frac{\cos x - 1}{x}$$ I tried to use squeeze theorem but it's not making much sense. I did the following: $$\begin{align} &\lim_{x\rightarrow 0} \frac{\cos x - 1}{x} \\ -1 \le &\lim_{x\rightarrow 0} (\cos x)(x^{-1}) \le 1 \\ \lim_{x\rightarrow 0} -x^{-1} \le &\lim_{x\rightarrow 0} \cos x \le \lim_{x\rightarrow 0} x^{-1} \quad \text{*} \end{align}$$ The last line is where I'm confused. I don't think I'm doing squeeze theorem correctly. I'm guessing you have to manipulate $\cos x - 1$ somehow. Please provide some hints. Thanks a bunch! P.S You cannot use L'Hopital.,,"['calculus', 'limits']"
49,Find this limit without L'hopital Rule : $\lim_{x\rightarrow +\infty}\frac{x(1+\sin(x))}{x-\sqrt{(1+x^2)}}$,Find this limit without L'hopital Rule :,\lim_{x\rightarrow +\infty}\frac{x(1+\sin(x))}{x-\sqrt{(1+x^2)}},Find this limit without l'Hopital rule : $$\lim_{x\rightarrow +\infty}\frac{x(1+ \sin x)}{x-\sqrt{1+x^2}}$$ I tried much but can't get any progress!,Find this limit without l'Hopital rule : $$\lim_{x\rightarrow +\infty}\frac{x(1+ \sin x)}{x-\sqrt{1+x^2}}$$ I tried much but can't get any progress!,,"['calculus', 'limits', 'limits-without-lhopital']"
50,showing $a_n = \frac{\tan(1)}{2^1} + \frac{\tan(2)}{2^2} + \dots + \frac{\tan(n)}{2^n}$ is not Cauchy,showing  is not Cauchy,a_n = \frac{\tan(1)}{2^1} + \frac{\tan(2)}{2^2} + \dots + \frac{\tan(n)}{2^n},"My gut telling me that the following sequence is not Cauchy, but I don't know how to show that. $$a_n = \frac{\tan(1)}{2^1} + \frac{\tan(2)}{2^2} + \dots + \frac{\tan(n)}{2^n}$$","My gut telling me that the following sequence is not Cauchy, but I don't know how to show that. $$a_n = \frac{\tan(1)}{2^1} + \frac{\tan(2)}{2^2} + \dots + \frac{\tan(n)}{2^n}$$",,"['calculus', 'sequences-and-series', 'proof-writing', 'cauchy-sequences']"
51,How to prove that this recursively defined sequence converges to $e$?,How to prove that this recursively defined sequence converges to ?,e,"Let $a_1=0,a_2=1,$ and $a_{n+2}=\dfrac{(n+2) a_{n+1}-a_n}{n+1}$. Prove that $\lim_{n\to \infty}a_n=e$. I know that $\lim_{n\to\infty}\left(1+\frac1{2!}+\frac1{3!}+...+\frac1{n!}\right)=e$ and $a_n = \dfrac{(n) a_{n-1}-a_{n-2}}{n-1}$ from $a_{n+2}=\dfrac{(n+2) a_{n+1}-a_n}{n+1}$. However, I don't know how to link them together.","Let $a_1=0,a_2=1,$ and $a_{n+2}=\dfrac{(n+2) a_{n+1}-a_n}{n+1}$. Prove that $\lim_{n\to \infty}a_n=e$. I know that $\lim_{n\to\infty}\left(1+\frac1{2!}+\frac1{3!}+...+\frac1{n!}\right)=e$ and $a_n = \dfrac{(n) a_{n-1}-a_{n-2}}{n-1}$ from $a_{n+2}=\dfrac{(n+2) a_{n+1}-a_n}{n+1}$. However, I don't know how to link them together.",,"['calculus', 'sequences-and-series', 'recurrence-relations']"
52,At what angle do these curves cut one another?,At what angle do these curves cut one another?,,"I'm working on an exercise that asks this: At what angle do the curves $$y = 3.5x^2 + 2$$ and $$y = x^2 - 5x + 9.5$$ cut one another? I have set these equations equal to one another to find two values for x. Namely, $x = 1$ and $x = -3$ as intersections. How should I proceed? Most everyone here is always extremely helpful so I can't thank you all enough in advance for any assistance.","I'm working on an exercise that asks this: At what angle do the curves $$y = 3.5x^2 + 2$$ and $$y = x^2 - 5x + 9.5$$ cut one another? I have set these equations equal to one another to find two values for x. Namely, $x = 1$ and $x = -3$ as intersections. How should I proceed? Most everyone here is always extremely helpful so I can't thank you all enough in advance for any assistance.",,"['calculus', 'derivatives']"
53,How to determine the series for $ f(x) = \sqrt{1-\sqrt{1+\sqrt{1-\sqrt{1+x}}}} $ around $0$?,How to determine the series for  around ?, f(x) = \sqrt{1-\sqrt{1+\sqrt{1-\sqrt{1+x}}}}  0,"In trying to answer a recent MSE-question I came on the partial problem to determine the power series for the function $$ f(x) = \sqrt{1-\sqrt{1+\sqrt{1-\sqrt{1+x}}}} $$ I was not successful with developing this series myself but when I asked wolframalpha I got this  $$ \small -(-1/2)^{3/4} x^{1/4}    -{1 (-1/2)^{1/4} x^{3/4} \over 16}    +{23 (-1/2)^{3/4} x^{5/4}\over 256}    +{81 (-1/2)^{1/4} x^{7/4} \over 4096}    -{5163 (-1/2)^{3/4} x^{9/4})\over 131072}    -{23111 (-1/2)^{1/4} x^{11/4})\over 2097152}    +{794707 (-1/2)^{3/4} x^{13/4}\over 33554432}     +{3986865 (-1/2)^{1/4} x^{15/4} \over 536870912}    -{563081651 (-1/2)^{3/4} x^{17/4}\over 34359738368}    -{3029331403 (-1/2)^{1/4} x^{19/4} \over 549755813888}    +{108017005065 (-1/2)^{3/4} x^{21/4} \over 8796093022208}    +{610056649623 (-1/2)^{1/4} x^{23/4} \over 140737488355328}    +O(x^{25/4}) $$ This expansion even has no constant term, so the fixpoint $x_0=0$ becomes immediately understandable. (Remark: There are more fixpoints :$\small t\approx 0.222986+0.413364 i$ and $\small  u\approx 0.222986-0.413364 i$ , see also the answer of G Edgar in that mentioned question. Using that complex-positive fixpoint $t$ we can get a power series without constant term - but with complex coefficients: $ \small f(x+t)-t = g(x) \approx 0.21947 x + (-0.10260 + 0.17758 i) x^2 + $ $\small (-0.13374 - 0.22046 i) x^3 + (0.37558 - 0.02179 i) x^4 + O(x^5)$ end remark) How can such an expansion be found? When I used Carlemanmatrices to resolve the function-composition I ran into singularities, and as well when I tried to get the first derivative at zero I ran into the same singularities - so how is this been done?","In trying to answer a recent MSE-question I came on the partial problem to determine the power series for the function $$ f(x) = \sqrt{1-\sqrt{1+\sqrt{1-\sqrt{1+x}}}} $$ I was not successful with developing this series myself but when I asked wolframalpha I got this  $$ \small -(-1/2)^{3/4} x^{1/4}    -{1 (-1/2)^{1/4} x^{3/4} \over 16}    +{23 (-1/2)^{3/4} x^{5/4}\over 256}    +{81 (-1/2)^{1/4} x^{7/4} \over 4096}    -{5163 (-1/2)^{3/4} x^{9/4})\over 131072}    -{23111 (-1/2)^{1/4} x^{11/4})\over 2097152}    +{794707 (-1/2)^{3/4} x^{13/4}\over 33554432}     +{3986865 (-1/2)^{1/4} x^{15/4} \over 536870912}    -{563081651 (-1/2)^{3/4} x^{17/4}\over 34359738368}    -{3029331403 (-1/2)^{1/4} x^{19/4} \over 549755813888}    +{108017005065 (-1/2)^{3/4} x^{21/4} \over 8796093022208}    +{610056649623 (-1/2)^{1/4} x^{23/4} \over 140737488355328}    +O(x^{25/4}) $$ This expansion even has no constant term, so the fixpoint $x_0=0$ becomes immediately understandable. (Remark: There are more fixpoints :$\small t\approx 0.222986+0.413364 i$ and $\small  u\approx 0.222986-0.413364 i$ , see also the answer of G Edgar in that mentioned question. Using that complex-positive fixpoint $t$ we can get a power series without constant term - but with complex coefficients: $ \small f(x+t)-t = g(x) \approx 0.21947 x + (-0.10260 + 0.17758 i) x^2 + $ $\small (-0.13374 - 0.22046 i) x^3 + (0.37558 - 0.02179 i) x^4 + O(x^5)$ end remark) How can such an expansion be found? When I used Carlemanmatrices to resolve the function-composition I ran into singularities, and as well when I tried to get the first derivative at zero I ran into the same singularities - so how is this been done?",,"['calculus', 'taylor-expansion']"
54,Is my proof correct about limit of $\sin\left(\frac{1}{x}\right)$?,Is my proof correct about limit of ?,\sin\left(\frac{1}{x}\right),"Apostol's book Calculus asks to show that there is not a value $A$ such that $f(x)=\sin\left(\frac{1}{x}\right)\to A$ when $x \to 0$. And my proof is: Suppose for the sake of contradiction that there exists such $A$. If we take $\epsilon=1$, we have two cases: If $A>0$, then $A - \epsilon > -1$, so $-1$ does not satisfy $|-1-A|<\epsilon$ inequality. Now for given $\delta>0$ we can take a natural number $n$ such that $\frac{2-3\pi\delta}{4\pi\delta}<n $ and then $0<\frac{1}{\pi\left( \frac{3}{2}+2n \right)}<\delta$. But  $$f\left( \left( \frac{3}{2}\pi+2n\pi \right)^{-1} \right)=\sin \pi\left( \frac{3}{2}+2n \right)=-1. $$ If $A\le0$, then $A+\epsilon\le1$ so $1$ does not satisfy $|1-A|<\epsilon $ inequality. Now for given $\delta>0$ we can take a natural number $n$ such that  $\frac{2-\pi\delta}{4\pi\delta}<n $ and then  $0<\frac{1}{\pi\left( \frac{1}{2}+2n \right)}<\delta$. But  $$f\left( \left( \frac{1}{2}\pi+2n\pi \right)^{-1} \right)=\sin \pi\left( \frac{1}{2}+2n \right)=1.$$ We have proved that with $\epsilon=1$ for every $\delta>0$ there exist $x$ such that $0<x<\delta$ but $|\sin \frac{1}{x} - A|<\epsilon$ does not hold. Therefore we have a contradiction, so such $A$ does not exist. Is my proof correct? there is a shorter argument?. Thanks in advance.","Apostol's book Calculus asks to show that there is not a value $A$ such that $f(x)=\sin\left(\frac{1}{x}\right)\to A$ when $x \to 0$. And my proof is: Suppose for the sake of contradiction that there exists such $A$. If we take $\epsilon=1$, we have two cases: If $A>0$, then $A - \epsilon > -1$, so $-1$ does not satisfy $|-1-A|<\epsilon$ inequality. Now for given $\delta>0$ we can take a natural number $n$ such that $\frac{2-3\pi\delta}{4\pi\delta}<n $ and then $0<\frac{1}{\pi\left( \frac{3}{2}+2n \right)}<\delta$. But  $$f\left( \left( \frac{3}{2}\pi+2n\pi \right)^{-1} \right)=\sin \pi\left( \frac{3}{2}+2n \right)=-1. $$ If $A\le0$, then $A+\epsilon\le1$ so $1$ does not satisfy $|1-A|<\epsilon $ inequality. Now for given $\delta>0$ we can take a natural number $n$ such that  $\frac{2-\pi\delta}{4\pi\delta}<n $ and then  $0<\frac{1}{\pi\left( \frac{1}{2}+2n \right)}<\delta$. But  $$f\left( \left( \frac{1}{2}\pi+2n\pi \right)^{-1} \right)=\sin \pi\left( \frac{1}{2}+2n \right)=1.$$ We have proved that with $\epsilon=1$ for every $\delta>0$ there exist $x$ such that $0<x<\delta$ but $|\sin \frac{1}{x} - A|<\epsilon$ does not hold. Therefore we have a contradiction, so such $A$ does not exist. Is my proof correct? there is a shorter argument?. Thanks in advance.",,"['calculus', 'limits', 'alternative-proof', 'proof-verification']"
55,Interesting Harmonic Sum $\sum_{k\geq 1}\frac{(-1)^{k-1}}{k^2}H_k^{(2)}$,Interesting Harmonic Sum,\sum_{k\geq 1}\frac{(-1)^{k-1}}{k^2}H_k^{(2)},Here http://integralsandseries.prophpbb.com/topic119.html We came across the following harmonic sum $$\tag{1} \sum_{k\geq 1}\frac{(-1)^{k-1}}{k^2}H_k^{(2)}$$ Note that we define $$H_k^{(2)}=\sum_{n\geq 1}^k\frac{1}{n^2} $$ Also we have $$\psi_1(k+1)= \zeta(2) -H_k^{(2)} $$ Any ideas how to evaluate (1) ?,Here http://integralsandseries.prophpbb.com/topic119.html We came across the following harmonic sum $$\tag{1} \sum_{k\geq 1}\frac{(-1)^{k-1}}{k^2}H_k^{(2)}$$ Note that we define $$H_k^{(2)}=\sum_{n\geq 1}^k\frac{1}{n^2} $$ Also we have $$\psi_1(k+1)= \zeta(2) -H_k^{(2)} $$ Any ideas how to evaluate (1) ?,,"['calculus', 'integration', 'sequences-and-series', 'closed-form', 'harmonic-numbers']"
56,"Spivak's Calculus exercise, possible error in text. Chapter 10, problem 24(a).","Spivak's Calculus exercise, possible error in text. Chapter 10, problem 24(a).",,"Working through all the problems in Spivak's Calculus (3E) and hit a snag here. Given $c, d \in R$, and distinct $x_1, ..., x_n \in R$, show that for any given $1 \leq i \leq n$ there exists a polynomial function $f$ of degree $2n-1$ such that $f(x_i) = c$, $f'(x_i) = d$, and $f$ has a double root at every other $x_j$. Here's what I have so far: In order for it to have a double root at those points, such a function must take the form $f(x) = (x - x_1)^2...(x-x_{i-1})^2(x-x_{i+1})^2...(x-{x_n})^2H(x)$ Where $H(x)$ is some polynomial. Furthermore, since the double roots already give it an order of $2n-2$, $H(x) = ax+b$. So we have $f(x) = (x - x_1)^2...(x-x_{i-1})^2(x-x_{i+1})^2...(x-{x_n})^2(ax+b)$ Or $f(x) = g(x)(ax+b)$ to shorten it. Now we end up with a system of equations with two unknowns $a$ and $b$: $g(x_i)x_ia+g(x_i)b = c$ $(g'(x_i)x_i + g(x_i))a + g'(x_i)b = d$ The determinant of the coefficient matrix is just $(g(x_i))^2$, which is non-zero since its only roots are the other $x_j$, i.e. the matrix is invertible, so it has a unique solution. There's just one problem: What if $c = g(x_i)$ and $d = g'(x_i)$? Then the solution is $(a,b) = (0, 1)$ and our polynomial $f$ has degree $2n-2$ instead of $2n-1$. Am I missing something or is this an error in Spivak? Also, is there a list of errors somewhere online? Tried looking online but couldn't find one.","Working through all the problems in Spivak's Calculus (3E) and hit a snag here. Given $c, d \in R$, and distinct $x_1, ..., x_n \in R$, show that for any given $1 \leq i \leq n$ there exists a polynomial function $f$ of degree $2n-1$ such that $f(x_i) = c$, $f'(x_i) = d$, and $f$ has a double root at every other $x_j$. Here's what I have so far: In order for it to have a double root at those points, such a function must take the form $f(x) = (x - x_1)^2...(x-x_{i-1})^2(x-x_{i+1})^2...(x-{x_n})^2H(x)$ Where $H(x)$ is some polynomial. Furthermore, since the double roots already give it an order of $2n-2$, $H(x) = ax+b$. So we have $f(x) = (x - x_1)^2...(x-x_{i-1})^2(x-x_{i+1})^2...(x-{x_n})^2(ax+b)$ Or $f(x) = g(x)(ax+b)$ to shorten it. Now we end up with a system of equations with two unknowns $a$ and $b$: $g(x_i)x_ia+g(x_i)b = c$ $(g'(x_i)x_i + g(x_i))a + g'(x_i)b = d$ The determinant of the coefficient matrix is just $(g(x_i))^2$, which is non-zero since its only roots are the other $x_j$, i.e. the matrix is invertible, so it has a unique solution. There's just one problem: What if $c = g(x_i)$ and $d = g'(x_i)$? Then the solution is $(a,b) = (0, 1)$ and our polynomial $f$ has degree $2n-2$ instead of $2n-1$. Am I missing something or is this an error in Spivak? Also, is there a list of errors somewhere online? Tried looking online but couldn't find one.",,['calculus']
57,integral involving cot coth and e using contour,integral involving cot coth and e using contour,,"I am thinking it is possible to evaluate this integral using contours, but I got hung up. $\displaystyle \int_{0}^{\infty}e^{-ax}\sin(ax)\left(\cot(x)+\coth(x)\right)dx=\frac{\pi}{2}\cdot \frac{\sinh(\pi a)}{\cosh(\pi a)-\cos(\pi a)}, \;\ a\in \mathbb{N}$ For instance, I broke it up by considering $\displaystyle\frac{e^{-az}e^{iaz}\cos(z)}{\sin(z)}$ and $\displaystyle\frac{e^{-az}e^{iaz}\cosh(z)}{\sinh(z)}$ This means there are infinite poles for the first one at $z=n\pi$ and at $z=\pi n i$ for the second one.  I tried a semi-circle and a rectangle, but got rather hung up. I got a residue for $z=n\pi$ of $\displaystyle\frac{e^{n a \pi i}}{e^{n\pi a}}$ and a residue for $\displaystyle n\pi i$ of $\frac{1}{e^{n\pi a i}e^{n\pi a}}$ Since the poles are infinite, there are series to evaluate. Summing these gave a closed form of $\displaystyle \frac{2e^{\pi a}\cos(\pi a)-2e^{2\pi a}}{2e^{\pi a}\cos(\pi a)-e^{2\pi a}-1}$ Of course, this does not lead to the correct solution. Another thing to consider is rather 'a' is odd or even. May I ask what would be the best function to consider or contour to use for this one?. Thanks","I am thinking it is possible to evaluate this integral using contours, but I got hung up. $\displaystyle \int_{0}^{\infty}e^{-ax}\sin(ax)\left(\cot(x)+\coth(x)\right)dx=\frac{\pi}{2}\cdot \frac{\sinh(\pi a)}{\cosh(\pi a)-\cos(\pi a)}, \;\ a\in \mathbb{N}$ For instance, I broke it up by considering $\displaystyle\frac{e^{-az}e^{iaz}\cos(z)}{\sin(z)}$ and $\displaystyle\frac{e^{-az}e^{iaz}\cosh(z)}{\sinh(z)}$ This means there are infinite poles for the first one at $z=n\pi$ and at $z=\pi n i$ for the second one.  I tried a semi-circle and a rectangle, but got rather hung up. I got a residue for $z=n\pi$ of $\displaystyle\frac{e^{n a \pi i}}{e^{n\pi a}}$ and a residue for $\displaystyle n\pi i$ of $\frac{1}{e^{n\pi a i}e^{n\pi a}}$ Since the poles are infinite, there are series to evaluate. Summing these gave a closed form of $\displaystyle \frac{2e^{\pi a}\cos(\pi a)-2e^{2\pi a}}{2e^{\pi a}\cos(\pi a)-e^{2\pi a}-1}$ Of course, this does not lead to the correct solution. Another thing to consider is rather 'a' is odd or even. May I ask what would be the best function to consider or contour to use for this one?. Thanks",,"['calculus', 'integration', 'contour-integration']"
58,Proving a complex sum equals factorial,Proving a complex sum equals factorial,,"I have just stumbled across the equality that: $$ \sum_{j=0}^{n}(-1) ^ {n + j}  j ^ {n} \binom{n}{j} = n! $$ How would I go about proving this equality? Also, what is the left hand side equal to if the power of j is increased: $$ \sum_{j=0}^{n}(-1) ^ {n + j}  j ^ {n+k} \binom{n}{j} = ? $$ where k=1,2,3... Thanks!","I have just stumbled across the equality that: $$ \sum_{j=0}^{n}(-1) ^ {n + j}  j ^ {n} \binom{n}{j} = n! $$ How would I go about proving this equality? Also, what is the left hand side equal to if the power of j is increased: $$ \sum_{j=0}^{n}(-1) ^ {n + j}  j ^ {n+k} \binom{n}{j} = ? $$ where k=1,2,3... Thanks!",,"['calculus', 'factorial']"
59,Trig substitution $\int x^3 \sqrt{1-x^2} dx$,Trig substitution,\int x^3 \sqrt{1-x^2} dx,$$\int x^3 \sqrt{1-x^2} dx$$ $x = \sin \theta $ $dx = \cos \theta d \theta$ $$\int \sin^3 \theta d \theta$$ $$\int (1 - \cos^2 \theta) \sin \theta  d \theta$$ $u = \cos  \theta$ $du = -\sin\theta d \theta$ $$-\int u^2 du$$ $$\frac{-u^3}{3} $$ $$\frac{\cos^3 \theta}{3}$$ With the triangle trick I get: $$\frac{-\sqrt{1-x^2}^3}{3}$$ This is wrong but I am not sure where I went wrong.,$$\int x^3 \sqrt{1-x^2} dx$$ $x = \sin \theta $ $dx = \cos \theta d \theta$ $$\int \sin^3 \theta d \theta$$ $$\int (1 - \cos^2 \theta) \sin \theta  d \theta$$ $u = \cos  \theta$ $du = -\sin\theta d \theta$ $$-\int u^2 du$$ $$\frac{-u^3}{3} $$ $$\frac{\cos^3 \theta}{3}$$ With the triangle trick I get: $$\frac{-\sqrt{1-x^2}^3}{3}$$ This is wrong but I am not sure where I went wrong.,,['calculus']
60,"Convergence of $\int_0^\infty x \sin e^x \, dx$",Convergence of,"\int_0^\infty x \sin e^x \, dx","I'm trying to demonstrate the convergence/divergence of a couple of integrals. They are: $\int_0^\infty x \sin e^x\,dx$ $\int_0^{\pi/2} \sin(\sec x)\,dx$ There was a previous exercise similar to the first one, $\int_0^\infty e^x \sin e^x \, dx$. I concluded that this one diverges, since by substitution I was able to change it to $\int_1^\infty \sin u\ du$. But I haven't been as successful in substitution for the first one: if we try $u=e^x$, we get $x \sin e^x \, dx = \ln(u)\ e^{-u}\sin u \,du$, but now we can't make the limits work. For the second one, obviously the problem is that $\sec$ goes to infinity as $x\to \pi/2$, so $\sin$ oscillates wildly. How can we investigate the convergence here?","I'm trying to demonstrate the convergence/divergence of a couple of integrals. They are: $\int_0^\infty x \sin e^x\,dx$ $\int_0^{\pi/2} \sin(\sec x)\,dx$ There was a previous exercise similar to the first one, $\int_0^\infty e^x \sin e^x \, dx$. I concluded that this one diverges, since by substitution I was able to change it to $\int_1^\infty \sin u\ du$. But I haven't been as successful in substitution for the first one: if we try $u=e^x$, we get $x \sin e^x \, dx = \ln(u)\ e^{-u}\sin u \,du$, but now we can't make the limits work. For the second one, obviously the problem is that $\sec$ goes to infinity as $x\to \pi/2$, so $\sin$ oscillates wildly. How can we investigate the convergence here?",,"['calculus', 'integration', 'convergence-divergence']"
61,Show that $\lim\limits_{n\to\infty} x_n$ exists for $0 \le x_{n+1} \le x_n + \frac1{n^2}$,Show that  exists for,\lim\limits_{n\to\infty} x_n 0 \le x_{n+1} \le x_n + \frac1{n^2},"Let $x_1, x_2,\ldots$ be a sequence of non-negative real numbers such that $$ x_{n+1} ≤ x_n + \frac 1{n^2}\text{ for }1≤n. $$ Show that $\lim\limits_{n\to\infty} x_n$ exists. Help please...","Let $x_1, x_2,\ldots$ be a sequence of non-negative real numbers such that $$ x_{n+1} ≤ x_n + \frac 1{n^2}\text{ for }1≤n. $$ Show that $\lim\limits_{n\to\infty} x_n$ exists. Help please...",,"['calculus', 'sequences-and-series', 'limits']"
62,"How to integrate $\int x\sin {(\sqrt{x})}\, dx$",How to integrate,"\int x\sin {(\sqrt{x})}\, dx","I tried using integration by parts twice, the same way we do for  $\int \sin {(\sqrt{x})}$ but in the second integral, I'm not getting an expression that is equal to  $\int x\sin {(\sqrt{x})}$. I let $\sqrt x = t$ thus, $$\int t^2 \cdot \sin({t})\cdot 2t dt =  2\int t^3\sin(t)dt = 2[(-\cos(t)\cdot t^3 + \int 3t^2\cos(t))] = 2[-\cos(t)\cdot t^3+(\sin(t)\cdot 3t^3 - \int 6t \cdot \sin(t))]]$$ which I can't find useful.","I tried using integration by parts twice, the same way we do for  $\int \sin {(\sqrt{x})}$ but in the second integral, I'm not getting an expression that is equal to  $\int x\sin {(\sqrt{x})}$. I let $\sqrt x = t$ thus, $$\int t^2 \cdot \sin({t})\cdot 2t dt =  2\int t^3\sin(t)dt = 2[(-\cos(t)\cdot t^3 + \int 3t^2\cos(t))] = 2[-\cos(t)\cdot t^3+(\sin(t)\cdot 3t^3 - \int 6t \cdot \sin(t))]]$$ which I can't find useful.",,"['calculus', 'integration', 'indefinite-integrals']"
63,"Definite integral involving modified bessel function of first kind, exponentials, and powers","Definite integral involving modified bessel function of first kind, exponentials, and powers",,"Is there any solution for this integral? $$ \int_a^b xe^{-\alpha x^2}J_n(\beta x) dx\,. $$ I looked up in all books i could find and only found this: $$ \int_0^{\infty} xe^{-\alpha x^2}J_n(\beta x) dx=\frac{\sqrt{\pi}\beta}{8\alpha^{\frac{3}{2}}} \exp \left( -\frac{\beta^2}{8\alpha}\right)\left[ I_{\frac{1}{2}  n-\frac{1}{2} } \left(\frac{\beta^2}{8\alpha} \right)- I_{\frac{1}{2} n+\frac{1}{2} }       \left( \frac{\beta^2}{8\alpha}\right)\right] \,, $$ for $\Re[\alpha] >0, and \ \ \ \Re[n]>-2$ Should I use a Gaussian distribution to approximately transform this integral into a definite one?","Is there any solution for this integral? $$ \int_a^b xe^{-\alpha x^2}J_n(\beta x) dx\,. $$ I looked up in all books i could find and only found this: $$ \int_0^{\infty} xe^{-\alpha x^2}J_n(\beta x) dx=\frac{\sqrt{\pi}\beta}{8\alpha^{\frac{3}{2}}} \exp \left( -\frac{\beta^2}{8\alpha}\right)\left[ I_{\frac{1}{2}  n-\frac{1}{2} } \left(\frac{\beta^2}{8\alpha} \right)- I_{\frac{1}{2} n+\frac{1}{2} }       \left( \frac{\beta^2}{8\alpha}\right)\right] \,, $$ for $\Re[\alpha] >0, and \ \ \ \Re[n]>-2$ Should I use a Gaussian distribution to approximately transform this integral into a definite one?",,"['calculus', 'integration', 'special-functions', 'definite-integrals']"
64,Integral proof of logarithm of a product property,Integral proof of logarithm of a product property,,"In one of my textbooks, the expansion of a logarithm product is proved using integrals. $$\ln xy = \ln x + \ln y\iff \int_1^\left(xy\right)dt/t$$ $$\ = \int_1^xdt/t + \int_x^\left(xy\right)dt/t$$ Then, let $ u = t/x $ and substitute in the second integral: $$= \int_1^x dt/t + \int_1^y du/u = ln x + ln y $$ While the expansion is rather quaint, I find the u-substitution difficult to follow: If $u = t/x$ then $du/dt = 1/x$ and $du = dt/x $ ... I am unsure how $ du/u $ is obtained for substitution. Any help or hints are appreciated!","In one of my textbooks, the expansion of a logarithm product is proved using integrals. $$\ln xy = \ln x + \ln y\iff \int_1^\left(xy\right)dt/t$$ $$\ = \int_1^xdt/t + \int_x^\left(xy\right)dt/t$$ Then, let $ u = t/x $ and substitute in the second integral: $$= \int_1^x dt/t + \int_1^y du/u = ln x + ln y $$ While the expansion is rather quaint, I find the u-substitution difficult to follow: If $u = t/x$ then $du/dt = 1/x$ and $du = dt/x $ ... I am unsure how $ du/u $ is obtained for substitution. Any help or hints are appreciated!",,"['calculus', 'logarithms']"
65,What is the domain of $x^x$ when $ x<0$,What is the domain of  when,x^x  x<0,I know that $x^x$ for all $x>0$ but what is negative values for that function which give a real number for example  $$f(-1)=(-1)^{-1}=-1\in R$$ I try to put sequence for that but i faild is there any help thanks for all,I know that $x^x$ for all $x>0$ but what is negative values for that function which give a real number for example  $$f(-1)=(-1)^{-1}=-1\in R$$ I try to put sequence for that but i faild is there any help thanks for all,,"['calculus', 'analysis']"
66,"Why can we ""separate"" variables? [duplicate]","Why can we ""separate"" variables? [duplicate]",,"This question already has answers here : Closed 11 years ago . Possible Duplicate: What am I doing when I separate the variables of a differential equation? My school textbook has a section on differential equations. One of the tricks used is the following- $$\frac{dx}{dy}=\frac{x}{y}\implies\frac{dx}{x}=\frac{dy}{y} $$ Integration is then duly carried out.Sparation of the variables leaves an impression on me that somehow, $dy$ is ""dividing"" $dx$. Whereas,when I studied the definition of the derivative, it was like $$f'(x)=\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}.$$ I am not convinced how the so-called separation of variables is legal .Does it follow from the definition of the derivative ? Can anyone guide me to a proof?","This question already has answers here : Closed 11 years ago . Possible Duplicate: What am I doing when I separate the variables of a differential equation? My school textbook has a section on differential equations. One of the tricks used is the following- $$\frac{dx}{dy}=\frac{x}{y}\implies\frac{dx}{x}=\frac{dy}{y} $$ Integration is then duly carried out.Sparation of the variables leaves an impression on me that somehow, $dy$ is ""dividing"" $dx$. Whereas,when I studied the definition of the derivative, it was like $$f'(x)=\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}.$$ I am not convinced how the so-called separation of variables is legal .Does it follow from the definition of the derivative ? Can anyone guide me to a proof?",,[]
67,"log sin and log cos integral, maybe relate to fourier series","log sin and log cos integral, maybe relate to fourier series",,"I try to use the method of differentiation under integral sign for the first one And integrate it back, but I failed to find the constant $c$ .... Anyone hav other method?  $$\begin{align}   & \int_{0}^{\frac{\pi }{2}}{{{x}^{2}}{{\ln }^{2}}\left( 2\cos x \right)\text{d}x} \\   & \int_{0}^{\frac{\pi }{3}}{x{{\ln }^{2}}\left( 2\sin \frac{x}{2} \right)}\text{d}x \\  \end{align}$$","I try to use the method of differentiation under integral sign for the first one And integrate it back, but I failed to find the constant $c$ .... Anyone hav other method?  $$\begin{align}   & \int_{0}^{\frac{\pi }{2}}{{{x}^{2}}{{\ln }^{2}}\left( 2\cos x \right)\text{d}x} \\   & \int_{0}^{\frac{\pi }{3}}{x{{\ln }^{2}}\left( 2\sin \frac{x}{2} \right)}\text{d}x \\  \end{align}$$",,"['calculus', 'sequences-and-series', 'integration', 'fourier-analysis', 'fourier-series']"
68,prove the divergence of cauchy product of convergent series $a_{n}:=b_{n}:=\dfrac{(-1)^n}{\sqrt{n+1}}$,prove the divergence of cauchy product of convergent series,a_{n}:=b_{n}:=\dfrac{(-1)^n}{\sqrt{n+1}},"i am given these series which converge. $a_{n}:=b_{n}:=\dfrac{(-1)^n}{\sqrt{n+1}}$ i solved this with quotient test and came to $-1$, which is obviously wrong. because it must be $0<\theta<1$ so that the series converges. my steps: $\dfrac{(-1)^{n+1}}{\sqrt{n+2}}\cdot \dfrac{\sqrt{n+1}}{(-1)^{n}} = - \dfrac{\sqrt{n+1}}{\sqrt{n+2}} = - \dfrac{\sqrt{n+1}}{\sqrt{n+2}}\cdot \dfrac{\sqrt{n+2}}{\sqrt{n+2}} = - \dfrac{(n+1)\cdot (n+2)}{(n+2)\cdot (n+2)} = - \dfrac{n^2+3n+2}{n^2+4n+4} = -1 $ did i do something wrong somewhere? and i tried to know whether the cauchy produkt diverges as task says: $\sum_{k=0}^{n}\dfrac{(-1)^{n-k}}{\sqrt{n-k+1}}\cdot \dfrac{(-1)^{k}}{\sqrt{k+1}} = \dfrac{(-1)^n}{nk+n-k^2+1} = ..help.. = diverging $ i am stuck here how to show that the produkt diverges, thanks for any help!","i am given these series which converge. $a_{n}:=b_{n}:=\dfrac{(-1)^n}{\sqrt{n+1}}$ i solved this with quotient test and came to $-1$, which is obviously wrong. because it must be $0<\theta<1$ so that the series converges. my steps: $\dfrac{(-1)^{n+1}}{\sqrt{n+2}}\cdot \dfrac{\sqrt{n+1}}{(-1)^{n}} = - \dfrac{\sqrt{n+1}}{\sqrt{n+2}} = - \dfrac{\sqrt{n+1}}{\sqrt{n+2}}\cdot \dfrac{\sqrt{n+2}}{\sqrt{n+2}} = - \dfrac{(n+1)\cdot (n+2)}{(n+2)\cdot (n+2)} = - \dfrac{n^2+3n+2}{n^2+4n+4} = -1 $ did i do something wrong somewhere? and i tried to know whether the cauchy produkt diverges as task says: $\sum_{k=0}^{n}\dfrac{(-1)^{n-k}}{\sqrt{n-k+1}}\cdot \dfrac{(-1)^{k}}{\sqrt{k+1}} = \dfrac{(-1)^n}{nk+n-k^2+1} = ..help.. = diverging $ i am stuck here how to show that the produkt diverges, thanks for any help!",,"['calculus', 'sequences-and-series', 'problem-solving']"
69,"Finding $\lim_{x\to \pm\infty}f(x)$ where $a,b>0$",Finding  where,"\lim_{x\to \pm\infty}f(x) a,b>0","I found this problem interesting to be here: If $a,b>0$ then find the following limit: $$\lim_{x\to\pm\infty}\left(\frac{a^{\frac{1}{x}}+b^{\frac{1}{x}}}{2}\right)^x$$ Thanks!","I found this problem interesting to be here: If $a,b>0$ then find the following limit: $$\lim_{x\to\pm\infty}\left(\frac{a^{\frac{1}{x}}+b^{\frac{1}{x}}}{2}\right)^x$$ Thanks!",,"['calculus', 'limits']"
70,Study of functions from $\mathbb{Q}$ to $\mathbb{Q}$,Study of functions from  to,\mathbb{Q} \mathbb{Q},"Is it possible to study functions from $\mathbb{Q}$ to $\mathbb{Q}$ with ordinary calculus ? Obviously with the limitation that $\mathbb{Q}$ is not complete. So much less limits, derivatives and integrals exist; but does it make sense a tangent in $\mathbb{Q^2}$","Is it possible to study functions from to with ordinary calculus ? Obviously with the limitation that is not complete. So much less limits, derivatives and integrals exist; but does it make sense a tangent in",\mathbb{Q} \mathbb{Q} \mathbb{Q} \mathbb{Q^2},['calculus']
71,Find the equation of the plane that contains,Find the equation of the plane that contains,,"Find the equation of the plane that contains, the lines: $$ \frac{x-2}{2} = \frac{y+4}{3} = \frac{2 - z}{5} $$ and $$\begin{align} x &= 3 + 4t \\ y &= -4 +6t \\ z &= 5 -10t. \end{align} $$ I'm not exactly sure on how to tackle this problem.","Find the equation of the plane that contains, the lines: $$ \frac{x-2}{2} = \frac{y+4}{3} = \frac{2 - z}{5} $$ and $$\begin{align} x &= 3 + 4t \\ y &= -4 +6t \\ z &= 5 -10t. \end{align} $$ I'm not exactly sure on how to tackle this problem.",,"['calculus', 'linear-algebra', 'algebra-precalculus']"
72,My proof that a harmonic series diverges..,My proof that a harmonic series diverges..,,Suppose $\sum_{n=1}^\infty \frac{1}{n} = S$ where $S$ is finite.  Then $$S =\sum_{n=1}^\infty \frac{1}{n}= \sum_{n=1}^\infty \frac{1}{2n-1} + \frac{1}{2n} > \sum_{n=1}^\infty \frac{1}{2n} + \frac{1}{2n} = S$$ which is a contradiction.  Is this valid?,Suppose $\sum_{n=1}^\infty \frac{1}{n} = S$ where $S$ is finite.  Then $$S =\sum_{n=1}^\infty \frac{1}{n}= \sum_{n=1}^\infty \frac{1}{2n-1} + \frac{1}{2n} > \sum_{n=1}^\infty \frac{1}{2n} + \frac{1}{2n} = S$$ which is a contradiction.  Is this valid?,,"['calculus', 'sequences-and-series']"
73,Show $ \int_{-\pi}^{\pi}  \frac{1 - \cos (n+1) x}{1- \cos x} dx = (n+1) 2 \pi$ for $n \in \mathbb N$ [duplicate],Show  for  [duplicate], \int_{-\pi}^{\pi}  \frac{1 - \cos (n+1) x}{1- \cos x} dx = (n+1) 2 \pi n \in \mathbb N,"This question already has answers here : Closed 11 years ago . Possible Duplicate: Compute the trigonometric integrals For $n \in \mathbb N$, $$ \int_{-\pi}^{\pi}  \frac{1 - \cos (n+1) x}{1- \cos x} dx = (n+1) 2 \pi$$","This question already has answers here : Closed 11 years ago . Possible Duplicate: Compute the trigonometric integrals For $n \in \mathbb N$, $$ \int_{-\pi}^{\pi}  \frac{1 - \cos (n+1) x}{1- \cos x} dx = (n+1) 2 \pi$$",,"['calculus', 'integration', 'definite-integrals']"
74,Integral - using Euler Substitution,Integral - using Euler Substitution,,"I've been trying to solve one simple Integral with Euler substitution several times, but can't find where I'm going wrong. The integral is (+ the answer given here, too): $$\int\frac{1}{x\sqrt{x^2+x+1}} dx=\log(x)-\log(2\sqrt{x^2+x+1}+x+2)+\text{ constant}$$ The problem is, I cannot get this result. Below is my solution of the problem. I've checked it many times, must be something very obvious that I'm missing: ( original image ) Euler Substituion $\displaystyle\int\frac{dx}{x\sqrt{x^2+x+1}}$ Let $\sqrt{x^2+x+1}=t-x$ . $x^2+x+1=t^2-2xt+x^2$ $x(1+2t)=t^2-1\implies x=\dfrac{t^2-1}{1+2t}$ $dx=\left(\dfrac{t^2-1}{1+2t}\right)'dt=\dfrac{2t(1+2t)-(t^2-1)2}{(1+2t)^2}=\dfrac{2t+4t^2-2t^2+2}{(1+2t)^2}=\dfrac{2(t^2+t+1)}{(1+2t)^2}$ $\sqrt{x^2+x+1}=t-x=t-\dfrac{t^2-1}{1+2t}=\dfrac{t^2+t+1}{1+2t}$ $\implies\displaystyle\int\frac{dx}{x\sqrt{x^2+x+1}}=2\int\frac{\frac{t^2+t+1}{(1+2t)^2}\;dt}{\frac{t^2-1}{1+2t}\cdot\frac{t^2+t+1}{1+2t}}=2\int \frac{1}{t^2-1}\,dt$ $\dfrac{1}{t^2-1}=\dfrac{1}{(t+1)(t-1)}=\dfrac{A}{t+1}+\dfrac{B}{t-1}\implies \begin{eqnarray}&&At-A+Bt+B=1\\&&A+B=0\implies A=-B\\ &&B-A=1\implies B=\frac{1}{2},A=-\frac{1}{2}\end{eqnarray}$ $\implies \displaystyle 2\int \frac{1}{2}\frac{1}{2t-1}\,dt-2\int\frac{1}{2}\frac{1}{t+1}\,dt=\int\frac{1}{t-1}\,dt-\int\frac{1}{t+1}\,dt=$ $=\ln|t-1|-\ln|t+1|=\ln\left|\dfrac{t-1}{t+1}\right|$ $t-x=\sqrt{x^2+x+1}\implies t=\sqrt{x^2+x+1}+x$ $\implies \ln\left|\dfrac{t-1}{t+1}\right|=\ln\left|\dfrac{\sqrt{x^2+x+1}+x-1}{\sqrt{x^2+x+1}+x+1}\right|$ I'll appreciate any help. Thanks in advance!","I've been trying to solve one simple Integral with Euler substitution several times, but can't find where I'm going wrong. The integral is (+ the answer given here, too): The problem is, I cannot get this result. Below is my solution of the problem. I've checked it many times, must be something very obvious that I'm missing: ( original image ) Euler Substituion Let . I'll appreciate any help. Thanks in advance!","\int\frac{1}{x\sqrt{x^2+x+1}} dx=\log(x)-\log(2\sqrt{x^2+x+1}+x+2)+\text{ constant} \displaystyle\int\frac{dx}{x\sqrt{x^2+x+1}} \sqrt{x^2+x+1}=t-x x^2+x+1=t^2-2xt+x^2 x(1+2t)=t^2-1\implies x=\dfrac{t^2-1}{1+2t} dx=\left(\dfrac{t^2-1}{1+2t}\right)'dt=\dfrac{2t(1+2t)-(t^2-1)2}{(1+2t)^2}=\dfrac{2t+4t^2-2t^2+2}{(1+2t)^2}=\dfrac{2(t^2+t+1)}{(1+2t)^2} \sqrt{x^2+x+1}=t-x=t-\dfrac{t^2-1}{1+2t}=\dfrac{t^2+t+1}{1+2t} \implies\displaystyle\int\frac{dx}{x\sqrt{x^2+x+1}}=2\int\frac{\frac{t^2+t+1}{(1+2t)^2}\;dt}{\frac{t^2-1}{1+2t}\cdot\frac{t^2+t+1}{1+2t}}=2\int \frac{1}{t^2-1}\,dt \dfrac{1}{t^2-1}=\dfrac{1}{(t+1)(t-1)}=\dfrac{A}{t+1}+\dfrac{B}{t-1}\implies \begin{eqnarray}&&At-A+Bt+B=1\\&&A+B=0\implies A=-B\\ &&B-A=1\implies B=\frac{1}{2},A=-\frac{1}{2}\end{eqnarray} \implies \displaystyle 2\int \frac{1}{2}\frac{1}{2t-1}\,dt-2\int\frac{1}{2}\frac{1}{t+1}\,dt=\int\frac{1}{t-1}\,dt-\int\frac{1}{t+1}\,dt= =\ln|t-1|-\ln|t+1|=\ln\left|\dfrac{t-1}{t+1}\right| t-x=\sqrt{x^2+x+1}\implies t=\sqrt{x^2+x+1}+x \implies \ln\left|\dfrac{t-1}{t+1}\right|=\ln\left|\dfrac{\sqrt{x^2+x+1}+x-1}{\sqrt{x^2+x+1}+x+1}\right|","['calculus', 'integration']"
75,Derivative of an implicit function,Derivative of an implicit function,,"I am asked to take the derivative of the following equation for $y$: $$y = x + xe^y$$ However, I get lost. I thought that it would be $$\begin{align} & y' = 1 + e^y + xy'e^y\\ & y'(1 - xe^y) = 1 + e^y\\ & y' = \frac{1+e^y}{1-xe^y} \end{align}$$ However, the text book gives me a different answer.  Can anyone help me with this? Thank you and sorry if I got any terms wrong, my math studies were not done in English... :)","I am asked to take the derivative of the following equation for $y$: $$y = x + xe^y$$ However, I get lost. I thought that it would be $$\begin{align} & y' = 1 + e^y + xy'e^y\\ & y'(1 - xe^y) = 1 + e^y\\ & y' = \frac{1+e^y}{1-xe^y} \end{align}$$ However, the text book gives me a different answer.  Can anyone help me with this? Thank you and sorry if I got any terms wrong, my math studies were not done in English... :)",,['calculus']
76,solve equation $y^{\alpha} + y^{1 + \alpha} = x $,solve equation,y^{\alpha} + y^{1 + \alpha} = x ,"how to solve this equation: $y^{\alpha} + y^{1 + \alpha} = x $ where $\alpha \in (-1, 0)$ Is there trick to solve it? EDIT. I want to find $y(x)$.","how to solve this equation: $y^{\alpha} + y^{1 + \alpha} = x $ where $\alpha \in (-1, 0)$ Is there trick to solve it? EDIT. I want to find $y(x)$.",,['calculus']
77,"Prove that if $a\in [0,1]$, then $\lim\limits_{x \to a} f(x) =0$","Prove that if , then","a\in [0,1] \lim\limits_{x \to a} f(x) =0","Supose that for any natural number $n$, $A_n$ is a finite set of numbers from $[0,1]$, and that $A_m$ and $A_n$ have no common elements if $m \neq n$, ie $$m \neq n \Rightarrow A_n\cap A_m=\emptyset$$ Let $f$ $$f(x)=  \begin{cases} 1/n & \text{for } x \in A_n \cr 0 & \text{for } x \notin A_n \text{ for any }n \end{cases}$$ I guess the definition is clear: If $x$ is in some of the $A_n$ then we map it to $1/n$, and if $x$ is in no $A_n$ the function is zero. It's like a modified characteristic function. $$f(x) =\sum_{n \in \Bbb N} \frac 1 n  \chi_{A_n}$$ (Thanks Asaf) I have to prove that $$\lim_{x \to a }f(x)=0$$ for all $a$ in $[0,1]$ This is my inutuitive interpretation of the problem. Since all the $A_n$ are finite sets, the union  $S= \bigcup_{n \in \Bbb N}A_n$ of the sets is countably infinite. (Maybe this has to be proven before, but I think it is true.) This means that $f(x)\neq 0$ for countable infinite many $x$. But then the set of $x$ such that $f(x)=0$ is uncountable, since $[0,1]$ is uncountable so $f$ is $0$ almost everywhere in $[0,1]$. Although this is not homework, I'd like you to help me find the way to the ""solving argument"", maybe show how it can be done for $a=1/2$. This is from Spivak's Calculus, so all the set theoretic things I wrote don't really apply, it should probably be proven by some basic set arguments and the definition of the limit. Attempt of proof: DEFINITION : $$\lim_{x \to a}f(x)=L$$ if $\forall \epsilon >0 \exists \delta >0 : 0<|x-a|<\delta \Rightarrow |f(x)-L|<\epsilon$. This is Spivak's definition. Note that $0<|x-a|$ means the limit excludes the point $a$. Suggested by t.b. is the notation $$\lim_{\substack{x \to a \\ x \neq a}} f(x)$$ T Let $f : [0,1] \to \mathbb Q$ such that $$f(x) = \sum_{n \in \Bbb N} \frac{\chi_{A_n}(x)}{n}$$ then $$a \in [0,1] \Rightarrow \lim_{x \to a} f(x) = 0$$ P (Based on Zhang's idea). Since $A_1$ is finite, there exists a $\delta_1 >0$ such that no $x \in A_1$ is in $(a-\delta_1,a)\cup (a,a+\delta_1)$. Thus, $|f(x)|< \dfrac 1 2$ for $0<|x-a|<\delta_1$. Similarily, $\exists \delta_2 >0 : x\in A_2 \wedge x \notin (a-\delta_2,a)\cup (a,a+\delta_2) $ so $|f(x)|< \dfrac 1 3 $ for $0<|x-a|<\delta_2$. Analogously, $$\exists \delta_n >0 : x\in A_n \wedge x \notin (a-\delta_n,a)\cup (a,a+\delta_n) $$, so $$|f(x)|< \dfrac 1 n \text{ for } 0<|x-a|<\delta_n$$ Revised: Let $\epsilon>0$ be given. Let $N\in \mathbb N$ such that $1/N < \epsilon$. Let $n \geq N$, and $$\delta = \min    \{ \delta_1,\cdots,\delta_n\}$$ Then $$0<|x-a|<\delta \Rightarrow |f(x)|<\epsilon$$  ∎. Today I was discussing this problem with a professor and at first glance he thought it was the case that $$S= \bigcup_{n \in \Bbb N}A_n= [0,1]$$ I provided the following explanation. By Cantor's proof, $[0,1]$ is uncountable. I'll use $\sim$ to say there is a bijection between two sets $A$ and $B$. Since all the $A_n$ are finite, their cardinality is a natural number, so $$A_1 \sim \left \{ 1,2,\cdots, |A_1| \right \}$$ $$A_2 \sim \{ |A_1|+1,\cdots, |A_1|+|A_2| \}$$ $$\cdots$$ $$A_n \sim \left\{ \sum_{k <n}|A_k|+1,\cdots, \sum_{k \leq n} |A_k|\right\}$$ Then, taking the union produces  $$\bigcup_{n \in \Bbb N}A_n\sim  \Bbb N$$ so the set $S$ is countable and thus can't be $[0,1]$. So far, I have these satisfactory ideas, but I want to write an acceptable proof. anon : If $g$ and $f$ differ at only a finite number of points then $\lim f = \lim g$. We define a useful $g_m$ such that it differs with $f$ at only a finite amount of points, and we show $0 \leq g_m \leq 1/m$. I got this one and hope I can devise a proof. Levon/Glouglou/Zhang Show that for any sequence $x_n$ s.t. $x_n \to a$, there exists an $n_0$ such that $$\{ x_k \}_{k \geq n_0}\cap A_n=\emptyset$$ for all $n \in \Bbb N$. This means that for a suitable $\delta$, the set $M=\{ x : x \in [a-\delta,a+\delta]\}$ contains no $x \in A_n$, so $f(x) < \epsilon$ (actually it is strictly $0$) in that neighborhood of $a$.","Supose that for any natural number $n$, $A_n$ is a finite set of numbers from $[0,1]$, and that $A_m$ and $A_n$ have no common elements if $m \neq n$, ie $$m \neq n \Rightarrow A_n\cap A_m=\emptyset$$ Let $f$ $$f(x)=  \begin{cases} 1/n & \text{for } x \in A_n \cr 0 & \text{for } x \notin A_n \text{ for any }n \end{cases}$$ I guess the definition is clear: If $x$ is in some of the $A_n$ then we map it to $1/n$, and if $x$ is in no $A_n$ the function is zero. It's like a modified characteristic function. $$f(x) =\sum_{n \in \Bbb N} \frac 1 n  \chi_{A_n}$$ (Thanks Asaf) I have to prove that $$\lim_{x \to a }f(x)=0$$ for all $a$ in $[0,1]$ This is my inutuitive interpretation of the problem. Since all the $A_n$ are finite sets, the union  $S= \bigcup_{n \in \Bbb N}A_n$ of the sets is countably infinite. (Maybe this has to be proven before, but I think it is true.) This means that $f(x)\neq 0$ for countable infinite many $x$. But then the set of $x$ such that $f(x)=0$ is uncountable, since $[0,1]$ is uncountable so $f$ is $0$ almost everywhere in $[0,1]$. Although this is not homework, I'd like you to help me find the way to the ""solving argument"", maybe show how it can be done for $a=1/2$. This is from Spivak's Calculus, so all the set theoretic things I wrote don't really apply, it should probably be proven by some basic set arguments and the definition of the limit. Attempt of proof: DEFINITION : $$\lim_{x \to a}f(x)=L$$ if $\forall \epsilon >0 \exists \delta >0 : 0<|x-a|<\delta \Rightarrow |f(x)-L|<\epsilon$. This is Spivak's definition. Note that $0<|x-a|$ means the limit excludes the point $a$. Suggested by t.b. is the notation $$\lim_{\substack{x \to a \\ x \neq a}} f(x)$$ T Let $f : [0,1] \to \mathbb Q$ such that $$f(x) = \sum_{n \in \Bbb N} \frac{\chi_{A_n}(x)}{n}$$ then $$a \in [0,1] \Rightarrow \lim_{x \to a} f(x) = 0$$ P (Based on Zhang's idea). Since $A_1$ is finite, there exists a $\delta_1 >0$ such that no $x \in A_1$ is in $(a-\delta_1,a)\cup (a,a+\delta_1)$. Thus, $|f(x)|< \dfrac 1 2$ for $0<|x-a|<\delta_1$. Similarily, $\exists \delta_2 >0 : x\in A_2 \wedge x \notin (a-\delta_2,a)\cup (a,a+\delta_2) $ so $|f(x)|< \dfrac 1 3 $ for $0<|x-a|<\delta_2$. Analogously, $$\exists \delta_n >0 : x\in A_n \wedge x \notin (a-\delta_n,a)\cup (a,a+\delta_n) $$, so $$|f(x)|< \dfrac 1 n \text{ for } 0<|x-a|<\delta_n$$ Revised: Let $\epsilon>0$ be given. Let $N\in \mathbb N$ such that $1/N < \epsilon$. Let $n \geq N$, and $$\delta = \min    \{ \delta_1,\cdots,\delta_n\}$$ Then $$0<|x-a|<\delta \Rightarrow |f(x)|<\epsilon$$  ∎. Today I was discussing this problem with a professor and at first glance he thought it was the case that $$S= \bigcup_{n \in \Bbb N}A_n= [0,1]$$ I provided the following explanation. By Cantor's proof, $[0,1]$ is uncountable. I'll use $\sim$ to say there is a bijection between two sets $A$ and $B$. Since all the $A_n$ are finite, their cardinality is a natural number, so $$A_1 \sim \left \{ 1,2,\cdots, |A_1| \right \}$$ $$A_2 \sim \{ |A_1|+1,\cdots, |A_1|+|A_2| \}$$ $$\cdots$$ $$A_n \sim \left\{ \sum_{k <n}|A_k|+1,\cdots, \sum_{k \leq n} |A_k|\right\}$$ Then, taking the union produces  $$\bigcup_{n \in \Bbb N}A_n\sim  \Bbb N$$ so the set $S$ is countable and thus can't be $[0,1]$. So far, I have these satisfactory ideas, but I want to write an acceptable proof. anon : If $g$ and $f$ differ at only a finite number of points then $\lim f = \lim g$. We define a useful $g_m$ such that it differs with $f$ at only a finite amount of points, and we show $0 \leq g_m \leq 1/m$. I got this one and hope I can devise a proof. Levon/Glouglou/Zhang Show that for any sequence $x_n$ s.t. $x_n \to a$, there exists an $n_0$ such that $$\{ x_k \}_{k \geq n_0}\cap A_n=\emptyset$$ for all $n \in \Bbb N$. This means that for a suitable $\delta$, the set $M=\{ x : x \in [a-\delta,a+\delta]\}$ contains no $x \in A_n$, so $f(x) < \epsilon$ (actually it is strictly $0$) in that neighborhood of $a$.",,"['calculus', 'elementary-set-theory', 'limits']"
78,Derivative of $\ln\sqrt{\frac{e^{x^2}}{e^x+2}}$?,Derivative of ?,\ln\sqrt{\frac{e^{x^2}}{e^x+2}},"Being: $\ln f(x)=\log_ef(x)$ I started derivating $$\ln\sqrt{\dfrac{e^{x^2}}{e^x+2}}$$ but I get to a point that I don't know how to follow. I try to get it by derivating the logarithm directly and by using the logarithmic properties such us: $$\ln f(x)^n=n\ln f(x)$$ and $$\ln \frac{f(x)}{Q(x)}=\ln f(x)-\ln Q(x)$$ but I don't get it. By the time I have done this: \begin{align} f(x)&=\ln\sqrt{\dfrac{e^{x^2}}{e^x+2}}\\ &=\frac{\ln e^{x^2}-\ln (e^x+2)}{2}\\ &=\frac{x^2-\ln (e^x+2)}{2}\\ \text{And derivating:}\\ f'(x)&=\frac{1}{2}\left(\frac{d}{dx}x^2-\frac{d}{dx}\ln (e^x+2)\right)\\ &=x-\frac{1}{2}\left(\frac{e^x}{e^x+2}\right) \end{align} So I finally get this: $f'(x)=x-\dfrac{e^x}{2e^x+4}$ But WolframAlpha says that $$f'(x)=\frac{x(x^2-5)}{x^2-4}$$ If I'm wrong, what do I do wrong? And if I'm right, how can I get from $x-\dfrac{e^x}{2e^x+4}$ to $\dfrac{x(x^2-5)}{x^2-4}$","Being: $\ln f(x)=\log_ef(x)$ I started derivating $$\ln\sqrt{\dfrac{e^{x^2}}{e^x+2}}$$ but I get to a point that I don't know how to follow. I try to get it by derivating the logarithm directly and by using the logarithmic properties such us: $$\ln f(x)^n=n\ln f(x)$$ and $$\ln \frac{f(x)}{Q(x)}=\ln f(x)-\ln Q(x)$$ but I don't get it. By the time I have done this: \begin{align} f(x)&=\ln\sqrt{\dfrac{e^{x^2}}{e^x+2}}\\ &=\frac{\ln e^{x^2}-\ln (e^x+2)}{2}\\ &=\frac{x^2-\ln (e^x+2)}{2}\\ \text{And derivating:}\\ f'(x)&=\frac{1}{2}\left(\frac{d}{dx}x^2-\frac{d}{dx}\ln (e^x+2)\right)\\ &=x-\frac{1}{2}\left(\frac{e^x}{e^x+2}\right) \end{align} So I finally get this: $f'(x)=x-\dfrac{e^x}{2e^x+4}$ But WolframAlpha says that $$f'(x)=\frac{x(x^2-5)}{x^2-4}$$ If I'm wrong, what do I do wrong? And if I'm right, how can I get from $x-\dfrac{e^x}{2e^x+4}$ to $\dfrac{x(x^2-5)}{x^2-4}$",,"['calculus', 'derivatives']"
79,Convergence or divergence of $\sum _{k=1}^{\infty} \left [ \cos(\frac {1} {k^{2}})-\cos(\frac {1} {(k+1)^{2}}) \right ]$,Convergence or divergence of,\sum _{k=1}^{\infty} \left [ \cos(\frac {1} {k^{2}})-\cos(\frac {1} {(k+1)^{2}}) \right ],"I am working on a two part question. It asks me to determine whether two different infinite series are divergent or convergent. Here are the two infinite series: (a) $\sum _{i=1}^{\infty} \cos(\frac {1} {i^{2}})$ (b) $\sum _{k=1}^{\infty} \left [ \cos(\frac {1} {k^{2}})-\cos(\frac {1} {(k+1)^{2}}) \right ]$ For part (a) I have determined it is divergent by finding $\lim_{i \to \infty} cos(\frac {1} {i^{2}})=1$ , which shows that the series must be divergent. For part (b) I've found that both terms of the series approach 1 as $k \to \infty$ . This means each term is divergent on its own. This doesn't tell me whether the series is convergent or divergent, it just tells me that the series could be convergent, because $\lim_{k \to \infty}a_{k}=0$ . I am wondering what I can do to get a proper answer.","I am working on a two part question. It asks me to determine whether two different infinite series are divergent or convergent. Here are the two infinite series: (a) (b) For part (a) I have determined it is divergent by finding , which shows that the series must be divergent. For part (b) I've found that both terms of the series approach 1 as . This means each term is divergent on its own. This doesn't tell me whether the series is convergent or divergent, it just tells me that the series could be convergent, because . I am wondering what I can do to get a proper answer.",\sum _{i=1}^{\infty} \cos(\frac {1} {i^{2}}) \sum _{k=1}^{\infty} \left [ \cos(\frac {1} {k^{2}})-\cos(\frac {1} {(k+1)^{2}}) \right ] \lim_{i \to \infty} cos(\frac {1} {i^{2}})=1 k \to \infty \lim_{k \to \infty}a_{k}=0,"['calculus', 'sequences-and-series']"
80,Question about substitution,Question about substitution,,"[ Note :] The error described here has been corrected in the meantime in response to this question. When checking wikipedia on substition they say that $\int f(g(t))g'(t) dt = \int f(x)dx$ with x = g(t). Which is true. However, when checking example 1 on the page ( http://en.wikipedia.org/wiki/Integration_by_substitution ) They say that when evaluating $\int x\cos(x^2 +1) dx$ in example one, they use the substition $u=x^2 + 1$ and say that they use the rule mentioned above from right to left, however this isn't the case right? Aren't they using that rule from left to right?","[ Note :] The error described here has been corrected in the meantime in response to this question. When checking wikipedia on substition they say that $\int f(g(t))g'(t) dt = \int f(x)dx$ with x = g(t). Which is true. However, when checking example 1 on the page ( http://en.wikipedia.org/wiki/Integration_by_substitution ) They say that when evaluating $\int x\cos(x^2 +1) dx$ in example one, they use the substition $u=x^2 + 1$ and say that they use the rule mentioned above from right to left, however this isn't the case right? Aren't they using that rule from left to right?",,['calculus']
81,Tauber theorem?,Tauber theorem?,,"Let $f(x) = \sum\limits_{k = 0}^\infty  {{a_k}{x^k}} $, where $a_k\ge0 $, and when $0 \le x < 1$ , $f(x)$ converges. Then please show that $\mathop {\lim }\limits_{n \to \infty } \frac{1}{{n + 1}}\sum\limits_{k = 0}^n {{a_k}}  = \mathop {\lim }\limits_{x \to {1^ - }} (1 - x)f(x)$.","Let $f(x) = \sum\limits_{k = 0}^\infty  {{a_k}{x^k}} $, where $a_k\ge0 $, and when $0 \le x < 1$ , $f(x)$ converges. Then please show that $\mathop {\lim }\limits_{n \to \infty } \frac{1}{{n + 1}}\sum\limits_{k = 0}^n {{a_k}}  = \mathop {\lim }\limits_{x \to {1^ - }} (1 - x)f(x)$.",,['calculus']
82,"If $f''(x)=0$ but is not an inflection point, what is it called?","If  but is not an inflection point, what is it called?",f''(x)=0,"If the second derivative of a function $f(x)$ equals zero at point $x_0$ ( $f''(x_0)=0$ ), the point is an inflection point if the concavity changes. Here's an example of an inflection point. If the concavity does not change, what is the point called? Does it have any specific name?","If the second derivative of a function $f(x)$ equals zero at point $x_0$ ( $f''(x_0)=0$ ), the point is an inflection point if the concavity changes. Here's an example of an inflection point. If the concavity does not change, what is the point called? Does it have any specific name?",,"['calculus', 'terminology']"
83,A proof for Landau inequality and similar cases,A proof for Landau inequality and similar cases,,"Landau inequality is about the bounds of derivatives of a real(complex)-valued function defined on some interval of the real line (I heard this from a lecture). I learned the simplest case is:  $$ \| f' \|_{L^\infty (-\infty,+\infty)}^2 \leq 4 \|f\| \cdot \|f''\| ,$$  the later norms are the same as the first one. I tried several functions $f$, and they are indeed the case, yet I don't have any idea how to get the general result (or the proof). Can someone be kind enough to give me some hints on this? Besides, does this inequality have similar results on finite intervals? Can someone give me some references on this? Thank you very much!","Landau inequality is about the bounds of derivatives of a real(complex)-valued function defined on some interval of the real line (I heard this from a lecture). I learned the simplest case is:  $$ \| f' \|_{L^\infty (-\infty,+\infty)}^2 \leq 4 \|f\| \cdot \|f''\| ,$$  the later norms are the same as the first one. I tried several functions $f$, and they are indeed the case, yet I don't have any idea how to get the general result (or the proof). Can someone be kind enough to give me some hints on this? Besides, does this inequality have similar results on finite intervals? Can someone give me some references on this? Thank you very much!",,"['calculus', 'inequality']"
84,Prove the reduction formula,Prove the reduction formula,,"The question is to ""prove the reduction formula"" $$ \int{ \frac{ x^2 }{ \left(a^2 + x^2\right)^n } dx } = \frac{ 1 }{ 2n-2 } \left(  -\frac{x}{ \left( a^2+x^2 \right)^{n-1}  }  +  \int{  \frac{dx}{ \left(  a^2 + x^2  \right)^{n-1} }  } \right) $$ What I got is Set $ u = x $ $ du = dx $ $\displaystyle{ dv = \frac{ x }{ \left(  a^2 + x^2  \right)^{n} } dx }$ $\displaystyle{ v = \frac{ 1 }{ 2(n+1) \left( a^2 + x^2 \right)^{n+1} }  }$ So I got $$ \frac{ 1 }{ 2n+2 } \left(   \frac{x}{ \left( a^2 + x^2 \right)^{n+1}} - \int{ \frac{dx}{ \left(  a^2+x^2  \right)^{n+1} } }  \right) $$ Which I believe is correct.  They are subtracting from n in the integration step and I'm not sure why","The question is to ""prove the reduction formula"" $$ \int{ \frac{ x^2 }{ \left(a^2 + x^2\right)^n } dx } = \frac{ 1 }{ 2n-2 } \left(  -\frac{x}{ \left( a^2+x^2 \right)^{n-1}  }  +  \int{  \frac{dx}{ \left(  a^2 + x^2  \right)^{n-1} }  } \right) $$ What I got is Set $ u = x $ $ du = dx $ $\displaystyle{ dv = \frac{ x }{ \left(  a^2 + x^2  \right)^{n} } dx }$ $\displaystyle{ v = \frac{ 1 }{ 2(n+1) \left( a^2 + x^2 \right)^{n+1} }  }$ So I got $$ \frac{ 1 }{ 2n+2 } \left(   \frac{x}{ \left( a^2 + x^2 \right)^{n+1}} - \int{ \frac{dx}{ \left(  a^2+x^2  \right)^{n+1} } }  \right) $$ Which I believe is correct.  They are subtracting from n in the integration step and I'm not sure why",,"['calculus', 'integration']"
85,Young inequality,Young inequality,,"I am trying to prove young's inequality for integrals $$ ab \leq \int\nolimits_0^a \! f(x) \, \mathrm{d}x + \int_0^b \! f^{-1}(x) \, \mathrm{d}x. $$ Can you help me please?","I am trying to prove young's inequality for integrals $$ ab \leq \int\nolimits_0^a \! f(x) \, \mathrm{d}x + \int_0^b \! f^{-1}(x) \, \mathrm{d}x. $$ Can you help me please?",,"['calculus', 'integration', 'inequality']"
86,The limit (and function) changes after rationalizing?,The limit (and function) changes after rationalizing?,,"I want to evaluate the following: $$\lim_{r \rightarrow 0}\frac{-r^2}{2 \left(\sqrt{1-\frac{r^2}{4}}-1 \right)}$$ I look at the graph and see that it seems to be going to zero. This makes sense to me because if I replace r with zero this function is defined and continuous near zero and the value of the function is zero. So, I think: $$\lim_{r \rightarrow 0}\frac{-r^2}{2 \left(\sqrt{1-\frac{r^2}{4}}-1 \right)}=0$$ But next I try something else I rationalize the denominator since this is a good technique for solving limits. $$\lim_{r \rightarrow 0}\frac{-r^2 \left(\sqrt{1-\frac{r^2}{4}}+1 \right)}{2 \left(1-\frac{r^2}{4}-1 \right)}$$ Then, $$\lim_{r \rightarrow 0}\frac{-r^2 \left(\sqrt{1-\frac{r^2}{4}}+1 \right)}{\frac{-r^2}{2}}$$ so... $$\lim_{r \rightarrow 0} 2 \left(\sqrt{1-\frac{r^2}{2}}+1 \right)=4$$ What have I done? How can rationalizing change the graph? My guess is that the denominator $2 \left(\sqrt{1-\frac{r^2}{2}}-1 \right)$ is ""divisible by $r^2$ in some not obvious way? I know my original reasoning was sloppy, (not a proof) but the fact that the graph shows a limit of zero has me very confused. How do I avoid this error? Just always rationalize everything? Why would I do that?","I want to evaluate the following: $$\lim_{r \rightarrow 0}\frac{-r^2}{2 \left(\sqrt{1-\frac{r^2}{4}}-1 \right)}$$ I look at the graph and see that it seems to be going to zero. This makes sense to me because if I replace r with zero this function is defined and continuous near zero and the value of the function is zero. So, I think: $$\lim_{r \rightarrow 0}\frac{-r^2}{2 \left(\sqrt{1-\frac{r^2}{4}}-1 \right)}=0$$ But next I try something else I rationalize the denominator since this is a good technique for solving limits. $$\lim_{r \rightarrow 0}\frac{-r^2 \left(\sqrt{1-\frac{r^2}{4}}+1 \right)}{2 \left(1-\frac{r^2}{4}-1 \right)}$$ Then, $$\lim_{r \rightarrow 0}\frac{-r^2 \left(\sqrt{1-\frac{r^2}{4}}+1 \right)}{\frac{-r^2}{2}}$$ so... $$\lim_{r \rightarrow 0} 2 \left(\sqrt{1-\frac{r^2}{2}}+1 \right)=4$$ What have I done? How can rationalizing change the graph? My guess is that the denominator $2 \left(\sqrt{1-\frac{r^2}{2}}-1 \right)$ is ""divisible by $r^2$ in some not obvious way? I know my original reasoning was sloppy, (not a proof) but the fact that the graph shows a limit of zero has me very confused. How do I avoid this error? Just always rationalize everything? Why would I do that?",,"['calculus', 'limits']"
87,Does monotonicity and derivability of a function $f\colon \mathbb{R}\to\mathbb{R}$ imply bijectiveness?,Does monotonicity and derivability of a function  imply bijectiveness?,f\colon \mathbb{R}\to\mathbb{R},"I have to prove that $f \colon x \mapsto e^{4x} + x^5 + 2$ ($f\colon \mathbb{R}\to\mathbb{R}$) is bijective. The argument given in the solution is that since the first two summands of the image is a bijective function of $x$, then so is $f$. Nonetheless, this ""proof"" doesn't seem at all rigorous to me, since there are many counterexamples to this argument. So I proved that $f$ is strictly increasing by looking at its derivative, thus injective, and that every $c \in \mathbb{R}$ has at least one preimage, applying Bolzano's theorem to $f(x) - c$ and evaluating its limit at $-\infty$ and $+\infty$, and so, demonstrating $f$ to be surjective. In consequence, $f$ is bijective. I am much more pleased about this proof than the one given in the solutions, but I want to know if I missed something, or if my hypothesis are insufficient. I gave an example to illustrate my argument, but the question I want to ask in the general form is in the title. Also, I would like to know whether the converse holds as well. Thanks. Update: I've been thinking about this, and realized that only monotonicity and continuity (together with unboundedness, as Mariano pointed out) are necessary for bijectiveness, and derivability only helps to prove monotonicity. Is this correct?","I have to prove that $f \colon x \mapsto e^{4x} + x^5 + 2$ ($f\colon \mathbb{R}\to\mathbb{R}$) is bijective. The argument given in the solution is that since the first two summands of the image is a bijective function of $x$, then so is $f$. Nonetheless, this ""proof"" doesn't seem at all rigorous to me, since there are many counterexamples to this argument. So I proved that $f$ is strictly increasing by looking at its derivative, thus injective, and that every $c \in \mathbb{R}$ has at least one preimage, applying Bolzano's theorem to $f(x) - c$ and evaluating its limit at $-\infty$ and $+\infty$, and so, demonstrating $f$ to be surjective. In consequence, $f$ is bijective. I am much more pleased about this proof than the one given in the solutions, but I want to know if I missed something, or if my hypothesis are insufficient. I gave an example to illustrate my argument, but the question I want to ask in the general form is in the title. Also, I would like to know whether the converse holds as well. Thanks. Update: I've been thinking about this, and realized that only monotonicity and continuity (together with unboundedness, as Mariano pointed out) are necessary for bijectiveness, and derivability only helps to prove monotonicity. Is this correct?",,['calculus']
88,How to compute the volume of this object via integration? [closed],How to compute the volume of this object via integration? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question What is the volume of intersection of the three cylinders with axes of length $1$ in $x, y, z$ directions starting from the origin, and with radius $1$?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question What is the volume of intersection of the three cylinders with axes of length $1$ in $x, y, z$ directions starting from the origin, and with radius $1$?",,[]
89,Why does “propositional calculus” have the word “calculus” in it?,Why does “propositional calculus” have the word “calculus” in it?,,"We define “calculus” like this: “ Calculus is the mathematical study of continuous change. ” But if that’s the case, then why is the study of (true or false) propositions and their relations called: “ Propositional calculus ”? These are some example statements from both fields: This is something from calculus: $\int_{0}^{3} x^2 dx = 3$ This is something from propositional calculus: $((A \rightarrow B)\land A) \rightarrow B$ What I know from a historical standpoint is that “calculus” was originally a word for “small pebble” and then evolved into a word for “calculation”. However, I also know that propositional calculus was developed somewhere in the 19th century, which is way after calculus was used for “calculation”. Why are both of these using the term “calculus”? Is its meaning as “calculation” related?","We define “calculus” like this: “ Calculus is the mathematical study of continuous change. ” But if that’s the case, then why is the study of (true or false) propositions and their relations called: “ Propositional calculus ”? These are some example statements from both fields: This is something from calculus: This is something from propositional calculus: What I know from a historical standpoint is that “calculus” was originally a word for “small pebble” and then evolved into a word for “calculation”. However, I also know that propositional calculus was developed somewhere in the 19th century, which is way after calculus was used for “calculation”. Why are both of these using the term “calculus”? Is its meaning as “calculation” related?",\int_{0}^{3} x^2 dx = 3 ((A \rightarrow B)\land A) \rightarrow B,"['calculus', 'analysis']"
90,Proving $ \sum_{k=0}^{n-1}\cos^2\left(\frac{2k\pi}{n}\right) = \frac{n}{2}$ with Euler's formula,Proving  with Euler's formula, \sum_{k=0}^{n-1}\cos^2\left(\frac{2k\pi}{n}\right) = \frac{n}{2},"I am working on proving some trigonometric identities and I am currently working on the following: For all $n \in \mathbb{N} ,  n \ge 2$ show that $$ \sum_{k=0}^{n-1}\cos^2\left(\frac{2k\pi}{n}\right) = \frac{n}{2}$$ I know that usually the term ""for all n"" might hint a proof with induction, however I have done it a little differently this time and wanted to see how far I can get with some Algebra, like so: $$ \sum_{k=0}^{n-1}\cos^2\left(\frac{2k\pi}{n}\right) =  \sum_{k=0}^{n-1}\frac{\left(e^{\frac{i2k\pi}{n}} + e^{\frac{-i2k\pi}{n}}\right)^{2}}{2^2} $$ $$= \sum_{k=0}^{n-1}\frac{e^{\frac{i4k\pi}{n}} + 2 + e^{\frac{-i4k\pi}{n}}}{4} = \frac{1}{4}\sum_{k=0}^{n-1}\left(e^{\frac{(i4k\pi)}{n}} + 2 + e^{\frac{(-i4k\pi)}{n}}\right) $$ which further gives me $$\frac{1}{4}\left(\sum_{k=0}^{n-1}e^{\frac{i4k\pi}{n}} + \sum_{k=0}^{n-1}2 + \sum_{k=0}^{n-1}e^{\frac{-i4k\pi}{n}}\right) =$$ $$ \frac{1}{4} \left(\frac{1-(x)^{n}}{1-x} +2(n-1) + \frac{1-(y)^{n}}{1-y}\right) $$ for $x$ being $$ x = e^{\frac{i 4 \pi}{n}}$$ and $y$ being $$y = e^{\frac{-i4\pi}{n}}$$ (I apologize, somehow it won't let me format the e-forms into the fractions) and since the fractions both equal zero, I am left with $$\frac{2(n-1)}{4} = \frac{n-1}{2} $$ and now I am confused as to what I have missed to do or where I made my error which prevented me from getting to n/2 .I would be so so grateful if someone could help me double checking my proof and point me to my oversight; as well I always love to see different approaches on how to reach the result and further suggestions are always appreciated. Thank you a lot !! Edit: Error was found. Thanks a lot! Corrected version: $$ \frac{1}{4} \left(\frac{1-(x)^{n}}{1-x} + (2+2(n-1)) + \frac{1-(y)^{n}}{1-y}\right) $$ for $x$ being $$ x = e^{\frac{i 4 \pi}{n}}$$ and $y$ being $$y = e^{\frac{-i4\pi}{n}}$$ which then gives the desired result of $$\frac{2n}{4} = \frac{n}{2} $$","I am working on proving some trigonometric identities and I am currently working on the following: For all show that I know that usually the term ""for all n"" might hint a proof with induction, however I have done it a little differently this time and wanted to see how far I can get with some Algebra, like so: which further gives me for being and being (I apologize, somehow it won't let me format the e-forms into the fractions) and since the fractions both equal zero, I am left with and now I am confused as to what I have missed to do or where I made my error which prevented me from getting to n/2 .I would be so so grateful if someone could help me double checking my proof and point me to my oversight; as well I always love to see different approaches on how to reach the result and further suggestions are always appreciated. Thank you a lot !! Edit: Error was found. Thanks a lot! Corrected version: for being and being which then gives the desired result of","n \in \mathbb{N} ,  n \ge 2  \sum_{k=0}^{n-1}\cos^2\left(\frac{2k\pi}{n}\right) = \frac{n}{2}  \sum_{k=0}^{n-1}\cos^2\left(\frac{2k\pi}{n}\right) =  \sum_{k=0}^{n-1}\frac{\left(e^{\frac{i2k\pi}{n}} + e^{\frac{-i2k\pi}{n}}\right)^{2}}{2^2}  = \sum_{k=0}^{n-1}\frac{e^{\frac{i4k\pi}{n}} + 2 + e^{\frac{-i4k\pi}{n}}}{4} = \frac{1}{4}\sum_{k=0}^{n-1}\left(e^{\frac{(i4k\pi)}{n}} + 2 + e^{\frac{(-i4k\pi)}{n}}\right)  \frac{1}{4}\left(\sum_{k=0}^{n-1}e^{\frac{i4k\pi}{n}} + \sum_{k=0}^{n-1}2 + \sum_{k=0}^{n-1}e^{\frac{-i4k\pi}{n}}\right) =  \frac{1}{4} \left(\frac{1-(x)^{n}}{1-x} +2(n-1) + \frac{1-(y)^{n}}{1-y}\right)  x  x = e^{\frac{i 4 \pi}{n}} y y = e^{\frac{-i4\pi}{n}} \frac{2(n-1)}{4} = \frac{n-1}{2}   \frac{1}{4} \left(\frac{1-(x)^{n}}{1-x} + (2+2(n-1)) + \frac{1-(y)^{n}}{1-y}\right)  x  x = e^{\frac{i 4 \pi}{n}} y y = e^{\frac{-i4\pi}{n}} \frac{2n}{4} = \frac{n}{2} ","['calculus', 'sequences-and-series', 'trigonometry', 'complex-numbers']"
91,Integrate $\sqrt{\frac{e^x-1}{e^x+1}}$,Integrate,\sqrt{\frac{e^x-1}{e^x+1}},The question was as follows: $$\int{\sqrt{\frac{e^x-1}{e^x+1}}}dx$$ Which I evaluated as follows: $$\int{\sqrt{\frac{e^x-1}{e^x+1}}}dx$$ $$=\int{\frac{e^x-1}{\sqrt{e^{2x}-1}}}dx$$ $$=\int{\frac{t-1}{t \sqrt{t^2-1}}}dt$$ (Taking $t=e^x$ and $dt= tdx$ ) $$=\int{\frac{t}{t\sqrt{t^2-1}}}dt-\int{\frac{1}{t\sqrt{t^2-1}}}dt$$ $$=\sin^{-1}(t)-\int{\frac{z}{z×t^2}}dz$$ (Taking $z^2=t^2-1$ and $dt=\cfrac{z}{t}dz$ ) $$=\sin^{-1}(t)-\int{\frac{1}{z^2+1}}dz$$ $$=\sin^{-1}(t)-\tan^{-1}(z)$$ $$=\sin^{-1}(e^x)-\tan^{-1}(\sqrt{e^{2x}-1})+C$$ But the answer given is: $$\ln (e^x+\sqrt{e^{2x}-1})-\sec^{-1}(e^x)+C$$ What did I do wrong and How to obtain the correct answer?,The question was as follows: Which I evaluated as follows: (Taking and ) (Taking and ) But the answer given is: What did I do wrong and How to obtain the correct answer?,\int{\sqrt{\frac{e^x-1}{e^x+1}}}dx \int{\sqrt{\frac{e^x-1}{e^x+1}}}dx =\int{\frac{e^x-1}{\sqrt{e^{2x}-1}}}dx =\int{\frac{t-1}{t \sqrt{t^2-1}}}dt t=e^x dt= tdx =\int{\frac{t}{t\sqrt{t^2-1}}}dt-\int{\frac{1}{t\sqrt{t^2-1}}}dt =\sin^{-1}(t)-\int{\frac{z}{z×t^2}}dz z^2=t^2-1 dt=\cfrac{z}{t}dz =\sin^{-1}(t)-\int{\frac{1}{z^2+1}}dz =\sin^{-1}(t)-\tan^{-1}(z) =\sin^{-1}(e^x)-\tan^{-1}(\sqrt{e^{2x}-1})+C \ln (e^x+\sqrt{e^{2x}-1})-\sec^{-1}(e^x)+C,"['calculus', 'integration', 'solution-verification', 'proof-explanation', 'indefinite-integrals']"
92,Why this solids also lives below z axis?,Why this solids also lives below z axis?,,"The base of a certain solid is the circle $x^2 + y^2 = a^2$ . Each plane perpendicular to the x-axis intersects the solid in a square cross-section with one side in the base of the solid. Find its volume. Here is my try : $$y = \sqrt{a^2-x^2}$$ $$dV = (a^2-x^2)dx$$ $$V= 8\int_0^a  (a^2-x^2)dx = \frac{16}{3}a^3$$ which is the correct answer given by textbook. I know that solid has eight octants, for the book answer is $16a^3/3$ , Can someone help me understand why it has 8 octants, I integrate one part of the solid and then multiply by eight, why do I have to multiply by eight instead of four? If the solids live above the z-axis then I have to multiply by four but in this case, how do I know the solid is also above the z-axis then multiply by eight","The base of a certain solid is the circle . Each plane perpendicular to the x-axis intersects the solid in a square cross-section with one side in the base of the solid. Find its volume. Here is my try : which is the correct answer given by textbook. I know that solid has eight octants, for the book answer is , Can someone help me understand why it has 8 octants, I integrate one part of the solid and then multiply by eight, why do I have to multiply by eight instead of four? If the solids live above the z-axis then I have to multiply by four but in this case, how do I know the solid is also above the z-axis then multiply by eight",x^2 + y^2 = a^2 y = \sqrt{a^2-x^2} dV = (a^2-x^2)dx V= 8\int_0^a  (a^2-x^2)dx = \frac{16}{3}a^3 16a^3/3,"['calculus', 'integration', 'definite-integrals', 'solid-of-revolution']"
93,Help with integrating $\int \frac{dx}{1+\sqrt{\tan(x)}}$,Help with integrating,\int \frac{dx}{1+\sqrt{\tan(x)}},"Starting off with subbing $u^2 = \tan(x)$ to remove the square root, I got: $$\int \frac{2u}{(1+u)(1+u^4)} du$$ (Deriving that $\sec^2(x) = 1+u^4$ ) Then by applying the partial fractions method, I get: $$\int \frac{-1}{1+u} du + \int \frac{u^3-u^2+u+1}{1+u^4} du$$ The first integral is manageable but for the second one I had to split the individual terms in the numerator into their own fractions to further obtain: $$\int \frac{u^3}{1+u^4}du +\int \frac{u}{1+u^4}du + \int \frac{1-u^2}{1+u^4}du $$ Now, the first two I could solve however it is the last one that I am unable to move forward with; $$ \int \frac{1-u^2}{1+u^4}du $$","Starting off with subbing to remove the square root, I got: (Deriving that ) Then by applying the partial fractions method, I get: The first integral is manageable but for the second one I had to split the individual terms in the numerator into their own fractions to further obtain: Now, the first two I could solve however it is the last one that I am unable to move forward with;",u^2 = \tan(x) \int \frac{2u}{(1+u)(1+u^4)} du \sec^2(x) = 1+u^4 \int \frac{-1}{1+u} du + \int \frac{u^3-u^2+u+1}{1+u^4} du \int \frac{u^3}{1+u^4}du +\int \frac{u}{1+u^4}du + \int \frac{1-u^2}{1+u^4}du   \int \frac{1-u^2}{1+u^4}du ,"['calculus', 'integration']"
94,Formula for $\int_0^{\infty} \frac{\ln \left(x^4+a^4\right)}{b^2+x^2} d x =\frac{\pi}{ b} \ln \left(a^2+b^2+a b \sqrt{2}\right) $,Formula for,\int_0^{\infty} \frac{\ln \left(x^4+a^4\right)}{b^2+x^2} d x =\frac{\pi}{ b} \ln \left(a^2+b^2+a b \sqrt{2}\right) ,"In my post , I had proved that $$ \int_0^{\infty} \frac{\ln \left(x^2+a^2\right)}{b^2+x^2} d x=\frac{ \pi}{b} \ln (a+b) \tag*{(*)}  $$ To go further, I guess that $$\int_0^{\infty} \frac{\ln \left(x^4+a^4\right)}{b^2+x^2} d x =\frac{\pi}{ |b|} \ln \left(a^2+b^2+|a|| b| \sqrt{2}\right) $$ Proof: For $a,b>0$ , Using $\ln \left(a^2+b^2\right)=2 Re(\ln (a+b i))$ , we can reduce the power $4$ to $2$ . $$ \begin{aligned} \int_0^{\infty} \frac{\ln \left(x^4+a^4\right)}{b^2+x^2} d x & = 2\int_{0}^{\infty} \frac {Re\left[\ln \left(x^2+a ^2i\right)\right]}{b^2+x^2} d x \\ & =2  Re\left(\int_0^{\infty} \frac{\ln \left(x^2+\left[\left(\frac{1+i}{\sqrt{2}}\right) a\right]^2\right)}{b^2+x^2} d x\right) \end{aligned} $$ Using (*), we have $$ \begin{aligned}\int_0^{\infty} \frac{\ln \left(x^4+a^4\right)}{b^2+x^2} d x&=2 Re\left[\frac{\pi}{b} \ln \left(\frac{1+i}{\sqrt{2}} a+b\right)\right] \\&=\frac{2 \pi}{b} R e\left[\ln \left(\frac{a}{\sqrt{2}}+b+\frac{a}{\sqrt{2}}i\right)\right] \\&= \boxed{\frac{\pi}{b} \ln \left(a^2+b^2+a b \sqrt{2}\right)}\end{aligned} $$ In general, for any $a, b \in \mathbb{R} \backslash\{0\}$ , replacing $a$ and $b$ by $|a|$ and $|b|$ yields $$\boxed{\int_0^{\infty} \frac{\ln \left(x^4+a^4\right)}{b^2+x^2} d x =\frac{\pi}{ |b|} \ln \left(a^2+b^2+|a|| b| \sqrt{2}\right) }$$ For example, $$ \int_0^{\infty} \frac{\ln \left(x^4+16\right)}{9+x^2} d x= \frac{\pi}{3} \ln (13+6 \sqrt{2}) $$ Comments and alternative methods are highly appreciated.","In my post , I had proved that To go further, I guess that Proof: For , Using , we can reduce the power to . Using (*), we have In general, for any , replacing and by and yields For example, Comments and alternative methods are highly appreciated.","
\int_0^{\infty} \frac{\ln \left(x^2+a^2\right)}{b^2+x^2} d x=\frac{ \pi}{b} \ln (a+b) \tag*{(*)} 
 \int_0^{\infty} \frac{\ln \left(x^4+a^4\right)}{b^2+x^2} d x =\frac{\pi}{ |b|} \ln \left(a^2+b^2+|a|| b| \sqrt{2}\right)  a,b>0 \ln \left(a^2+b^2\right)=2 Re(\ln (a+b i)) 4 2 
\begin{aligned}
\int_0^{\infty} \frac{\ln \left(x^4+a^4\right)}{b^2+x^2} d x
& = 2\int_{0}^{\infty} \frac {Re\left[\ln \left(x^2+a ^2i\right)\right]}{b^2+x^2} d x \\
& =2  Re\left(\int_0^{\infty} \frac{\ln \left(x^2+\left[\left(\frac{1+i}{\sqrt{2}}\right) a\right]^2\right)}{b^2+x^2} d x\right)
\end{aligned}
 
\begin{aligned}\int_0^{\infty} \frac{\ln \left(x^4+a^4\right)}{b^2+x^2} d x&=2 Re\left[\frac{\pi}{b} \ln \left(\frac{1+i}{\sqrt{2}} a+b\right)\right] \\&=\frac{2 \pi}{b} R e\left[\ln \left(\frac{a}{\sqrt{2}}+b+\frac{a}{\sqrt{2}}i\right)\right] \\&= \boxed{\frac{\pi}{b} \ln \left(a^2+b^2+a b \sqrt{2}\right)}\end{aligned}
 a, b \in \mathbb{R} \backslash\{0\} a b |a| |b| \boxed{\int_0^{\infty} \frac{\ln \left(x^4+a^4\right)}{b^2+x^2} d x =\frac{\pi}{ |b|} \ln \left(a^2+b^2+|a|| b| \sqrt{2}\right) } 
\int_0^{\infty} \frac{\ln \left(x^4+16\right)}{9+x^2} d x= \frac{\pi}{3} \ln (13+6 \sqrt{2})
","['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
95,How to find $\int_0^\infty\frac{x!}{x^x}dx$,How to find,\int_0^\infty\frac{x!}{x^x}dx,"I wonder how I could evaluate $$\lim_{a\rightarrow0}\int_a^\infty\frac{x!}{x^x}dx$$ Where $x!$ is defined for all complex numbers with a positive real part. This is inspired by a limit I found on BlackPenRedPen. I tried using the Residue theorem using the quarter circle contour on the complex plane with a singularity at the origin, but I don't know how to use it. This is the contour I am using. Consider the outer circle as a contour $\Gamma$ . Let the smaller semicircle be $\gamma$ . Let the radius of the big semicircle be $R$ and the radius of the smaller semicircle be $r$ . Then $$\int_0^\infty f(z)dz=\lim_{(r,R)\rightarrow(0,\infty)}\left(\int_\Gamma+\int_\gamma+\int_r^Rf(z)dz+\int_{ri}^{Ri}f(z)dz\right)=2\pi i\sum_k\text{Res}(f, z_k)$$ Where $f(z)=\dfrac{z!}{z^z}$ , $0^0=1$ , and $z_k$ are the poles of $f(z)$ . After that I am stuck as I don't think $f(z)$ has any poles. Any ideas?","I wonder how I could evaluate Where is defined for all complex numbers with a positive real part. This is inspired by a limit I found on BlackPenRedPen. I tried using the Residue theorem using the quarter circle contour on the complex plane with a singularity at the origin, but I don't know how to use it. This is the contour I am using. Consider the outer circle as a contour . Let the smaller semicircle be . Let the radius of the big semicircle be and the radius of the smaller semicircle be . Then Where , , and are the poles of . After that I am stuck as I don't think has any poles. Any ideas?","\lim_{a\rightarrow0}\int_a^\infty\frac{x!}{x^x}dx x! \Gamma \gamma R r \int_0^\infty f(z)dz=\lim_{(r,R)\rightarrow(0,\infty)}\left(\int_\Gamma+\int_\gamma+\int_r^Rf(z)dz+\int_{ri}^{Ri}f(z)dz\right)=2\pi i\sum_k\text{Res}(f, z_k) f(z)=\dfrac{z!}{z^z} 0^0=1 z_k f(z) f(z)","['calculus', 'integration', 'definite-integrals', 'residue-calculus']"
96,Evaluate $\int_{0}^{\infty}\text{sech}^2(x+\tan(x))dx$,Evaluate,\int_{0}^{\infty}\text{sech}^2(x+\tan(x))dx,"Evaluate the Integral: $$\int_{0}^{\infty}\text{sech}^2(x+\tan(x))dx$$ Source: MIT Integration Bee My Try: Applying Glasser's Master Theorem, the value of improper integral doesn't change. Substituting $x$ in place of $x+\tan(x)$ we have $$\int_{0}^{\infty}\text{sech}^2(x)dx=\left[ \tanh (x) \right]_{0}^{\infty}=\lim_{x \to \infty} \tanh(x)=\lim_{x \to \infty} \frac{e^{2x}-1}{e^{2x}+1}= 1$$ I don't know whether the solution is  correct; can anyone tell me please?  Also Is there any other method of solving it? Any help would be appreciated .","Evaluate the Integral: Source: MIT Integration Bee My Try: Applying Glasser's Master Theorem, the value of improper integral doesn't change. Substituting in place of we have I don't know whether the solution is  correct; can anyone tell me please?  Also Is there any other method of solving it? Any help would be appreciated .",\int_{0}^{\infty}\text{sech}^2(x+\tan(x))dx x x+\tan(x) \int_{0}^{\infty}\text{sech}^2(x)dx=\left[ \tanh (x) \right]_{0}^{\infty}=\lim_{x \to \infty} \tanh(x)=\lim_{x \to \infty} \frac{e^{2x}-1}{e^{2x}+1}= 1,"['calculus', 'integration', 'trigonometry', 'improper-integrals', 'infinity']"
97,An alternating sum,An alternating sum,,"I ran into an alternating sum in my research and would like to know if the following identity is true: $$ \sum_{i = 0}^{\left\lfloor \left(n + 1\right)/2\right\rfloor} \frac{\left(n + 1 - 2i\right)^{n + 1}}{2^{n}\left(n + 1\right)!}\binom{n + 1}{i}\left(-1\right)^{i} = 1\quad \forall\ \mbox{positive integers}\ n\geq 3 $$ Any help would be appreciated!. Edit. We might try to use an Iverson bracket $[[2q\le n]]$ in attempting to evaluate $$S_n = \sum_{q=0}^{\lfloor n/2\rfloor} (n-2q)^n {n\choose q} (-1)^q.$$ We obtain $$[v^n] \frac{1}{1-v} \sum_{q\ge 0} v^{2q} (n-2q)^n {n\choose q} (-1)^q$$ Using a coefficient extractor, $$n! [z^n] \exp(nz) \;\underset{v}{\mathrm{res}}\; \frac{1}{v^{n+1}} \frac{1}{1-v} \sum_{q\ge 0} v^{2q} \exp(-2qz) {n\choose q} (-1)^q \\ = n! [z^n] \exp(nz) \;\underset{v}{\mathrm{res}}\; \frac{1}{v^{n+1}} \frac{1}{1-v} (1-v^2\exp(-2z))^n.$$ Now residues sum to zero and the residue at one yields $$- n! [z^n] \exp(nz) (1-\exp(-2z))^n.$$ We have that since $(1-\exp(-2z))^n = (2z-2z^2\pm\cdots)^n = 2^n z^n +\cdots$ this evaluates to $-2^n n!.$ We find for the residue at infinity $$- n! [z^n] \exp(nz) \;\underset{v}{\mathrm{res}}\; \frac{1}{v^2} v^{n+1} \frac{1}{1-1/v} (1-\exp(-2z)/v^2)^n \\ = n! [z^n] \exp(nz) \;\underset{v}{\mathrm{res}}\; \frac{1}{v^n} \frac{1}{1-v} (v^2-\exp(-2z))^n \\ = n! [z^n] \exp(nz) \;\underset{v}{\mathrm{res}}\; \frac{1}{v^n} \frac{1}{1-v} \sum_{q=0}^n {n\choose q} (-1)^{n-q} \exp(-2(n-q)z) v^{2q} \\ = \;\underset{v}{\mathrm{res}}\; \frac{1}{v^n} \frac{1}{1-v} \sum_{q=0}^n {n\choose q} (-1)^{n-q} (2q-n)^n v^{2q} \\ = \sum_{q=0}^n {n\choose q} (-1)^q (n-2q)^n [[2q\le n-1]].$$ Now when $n$ is odd this gives the upper limit $\lfloor n/2\rfloor$ and when $n$ is even $\lfloor n/2\rfloor -1$ however in the latter case we may raise to $\lfloor n/2\rfloor$ because the added term is zero in the sum per $(n-2q)^n = 0$ . We have obtained $$\sum_{q=0}^{\lfloor n/2\rfloor} {n\choose q} (-1)^q (n-2q)^n = S_n.$$ Collecting everything we have shown that $S_n - 2^n n! + S_n = 0$ or $S_n = 2^{n-1} n!.$ The question now becomes, is there a simpler proof?","I ran into an alternating sum in my research and would like to know if the following identity is true: Any help would be appreciated!. Edit. We might try to use an Iverson bracket in attempting to evaluate We obtain Using a coefficient extractor, Now residues sum to zero and the residue at one yields We have that since this evaluates to We find for the residue at infinity Now when is odd this gives the upper limit and when is even however in the latter case we may raise to because the added term is zero in the sum per . We have obtained Collecting everything we have shown that or The question now becomes, is there a simpler proof?","
\sum_{i = 0}^{\left\lfloor \left(n + 1\right)/2\right\rfloor} \frac{\left(n + 1 - 2i\right)^{n + 1}}{2^{n}\left(n + 1\right)!}\binom{n + 1}{i}\left(-1\right)^{i} = 1\quad
\forall\ \mbox{positive integers}\ n\geq 3
 [[2q\le n]] S_n = \sum_{q=0}^{\lfloor n/2\rfloor}
(n-2q)^n {n\choose q} (-1)^q. [v^n] \frac{1}{1-v}
\sum_{q\ge 0} v^{2q} (n-2q)^n {n\choose q} (-1)^q n! [z^n] \exp(nz) \;\underset{v}{\mathrm{res}}\;
\frac{1}{v^{n+1}} \frac{1}{1-v}
\sum_{q\ge 0} v^{2q} \exp(-2qz) {n\choose q} (-1)^q
\\ = n! [z^n] \exp(nz) \;\underset{v}{\mathrm{res}}\;
\frac{1}{v^{n+1}} \frac{1}{1-v} (1-v^2\exp(-2z))^n. - n! [z^n] \exp(nz) (1-\exp(-2z))^n. (1-\exp(-2z))^n = (2z-2z^2\pm\cdots)^n = 2^n z^n +\cdots -2^n n!. - n! [z^n] \exp(nz) \;\underset{v}{\mathrm{res}}\;
\frac{1}{v^2}
v^{n+1} \frac{1}{1-1/v} (1-\exp(-2z)/v^2)^n
\\ = n! [z^n] \exp(nz) \;\underset{v}{\mathrm{res}}\;
\frac{1}{v^n} \frac{1}{1-v} (v^2-\exp(-2z))^n
\\ = n! [z^n] \exp(nz) \;\underset{v}{\mathrm{res}}\;
\frac{1}{v^n} \frac{1}{1-v}
\sum_{q=0}^n {n\choose q} (-1)^{n-q} \exp(-2(n-q)z) v^{2q}
\\ = \;\underset{v}{\mathrm{res}}\;
\frac{1}{v^n} \frac{1}{1-v}
\sum_{q=0}^n {n\choose q} (-1)^{n-q} (2q-n)^n v^{2q}
\\ = \sum_{q=0}^n {n\choose q} (-1)^q (n-2q)^n [[2q\le n-1]]. n \lfloor n/2\rfloor n \lfloor n/2\rfloor -1 \lfloor n/2\rfloor (n-2q)^n = 0 \sum_{q=0}^{\lfloor n/2\rfloor} {n\choose q} (-1)^q (n-2q)^n
= S_n. S_n - 2^n n! + S_n = 0 S_n = 2^{n-1} n!.","['calculus', 'elementary-number-theory', 'summation', 'binomial-coefficients']"
98,The Maclaurin series of $1-(1-\frac{x^2}{2} + \frac{x^4}{24})^{2/3}$ has all coefficients positive,The Maclaurin series of  has all coefficients positive,1-(1-\frac{x^2}{2} + \frac{x^4}{24})^{2/3},"It was shown in a previous post that the Maclaurin series of $1 - \cos^{2/3} x$ has positive coefficients. There @Dr. Wolfgang Hintze: has noticed that the truncation $1- \frac{x^2}{2} + \frac{x^4}{24}$ can be substituted for $\cos x$ (  seems to be true for all the truncations). The proof is escaping me. Thank you for your attention! $\bf{Added:}$ Thomas Laffey in this paper directs to a proof of the fact that if $a_1$ , $\ldots$ , $a_n\ge 0$ then $\alpha = \frac{1}{n}$ makes the following series positive: $$1- (\prod_{i=1}^n (1- a_i x))^{\alpha}$$ Numerical testing suggests that $\alpha = \frac{\sum a_i^2}{(\sum a_i)^2} \ge \frac{1}{n}$ works as well ( see the case $n=2$ tested here ). So in our case, instead of $\alpha = \frac{1}{2}$ we can take $\alpha = \frac{2}{3}$ . Clearly, this would then be the optimal value. This would be a test case for $n=2$ . The result for $\cos x$ used the special properties of the function ( solution of a certain differential equation of second order). Maybe $1- x/2 + x^2/24$ is as general as any quadratic with two positive (distinct) roots.","It was shown in a previous post that the Maclaurin series of has positive coefficients. There @Dr. Wolfgang Hintze: has noticed that the truncation can be substituted for (  seems to be true for all the truncations). The proof is escaping me. Thank you for your attention! Thomas Laffey in this paper directs to a proof of the fact that if , , then makes the following series positive: Numerical testing suggests that works as well ( see the case tested here ). So in our case, instead of we can take . Clearly, this would then be the optimal value. This would be a test case for . The result for used the special properties of the function ( solution of a certain differential equation of second order). Maybe is as general as any quadratic with two positive (distinct) roots.",1 - \cos^{2/3} x 1- \frac{x^2}{2} + \frac{x^4}{24} \cos x \bf{Added:} a_1 \ldots a_n\ge 0 \alpha = \frac{1}{n} 1- (\prod_{i=1}^n (1- a_i x))^{\alpha} \alpha = \frac{\sum a_i^2}{(\sum a_i)^2} \ge \frac{1}{n} n=2 \alpha = \frac{1}{2} \alpha = \frac{2}{3} n=2 \cos x 1- x/2 + x^2/24,"['calculus', 'taylor-expansion']"
99,Integral Representation of a Double Sum,Integral Representation of a Double Sum,,Let us assume we know the value of $x$ and $y$ . I'm trying to write the following double sum as an integral. I went through many pages and saw various methods but I'm completely lost with my problem. $$\sum_{n = 1}^{\infty} \frac{x^{n}}{n!} \sum_{m = 1}^{n} \frac{\left( m - 1 \right)!}{\left( m + y \right)!}$$ Could anyone please give me a hint so I can go about solving it myself?,Let us assume we know the value of and . I'm trying to write the following double sum as an integral. I went through many pages and saw various methods but I'm completely lost with my problem. Could anyone please give me a hint so I can go about solving it myself?,x y \sum_{n = 1}^{\infty} \frac{x^{n}}{n!} \sum_{m = 1}^{n} \frac{\left( m - 1 \right)!}{\left( m + y \right)!},"['calculus', 'integration']"
