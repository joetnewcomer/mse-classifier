,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Square of the Absolute Value of a Characteristic Function is a Characteristic Function,Square of the Absolute Value of a Characteristic Function is a Characteristic Function,,I am working on the following problem: Suppose that $\varphi(t)$ is the characteristic function for some random variable. Show that $|\varphi(t)|^2$ is a characteristic function. For what random variable? So I know that $\varphi(t)=E\left(e^{itX}\right)$ Also I get that $|\varphi(t)|^2=\varphi(t) \overline{\varphi(t)}=E\left(e^{itX}\right)\overline{E\left(e^{itX}\right)}=E\left(e^{itX}\right)E\left(e^{-itX}\right).$ Here I get stuck trying to continue the calculation. Any help would be appreciated!,I am working on the following problem: Suppose that is the characteristic function for some random variable. Show that is a characteristic function. For what random variable? So I know that Also I get that Here I get stuck trying to continue the calculation. Any help would be appreciated!,\varphi(t) |\varphi(t)|^2 \varphi(t)=E\left(e^{itX}\right) |\varphi(t)|^2=\varphi(t) \overline{\varphi(t)}=E\left(e^{itX}\right)\overline{E\left(e^{itX}\right)}=E\left(e^{itX}\right)E\left(e^{-itX}\right).,"['probability', 'probability-theory', 'characteristic-functions']"
1,Can a sample space consist of only the empty set?,Can a sample space consist of only the empty set?,,"On the axioms of probability we have that on the one hand the probability of the sample space $\Omega$ to happen is 1; in other words: $$ \mathbb{P}(\Omega) = 1$$ But on the other hand we also have that for any probability space the probability of the empty set is 0; in other words: $$ \mathbb{P}(\emptyset) = 0$$ So my question is, what if we choose our sample space $\Omega$ to be $\Omega = \emptyset$? What's the probability then?","On the axioms of probability we have that on the one hand the probability of the sample space $\Omega$ to happen is 1; in other words: $$ \mathbb{P}(\Omega) = 1$$ But on the other hand we also have that for any probability space the probability of the empty set is 0; in other words: $$ \mathbb{P}(\emptyset) = 0$$ So my question is, what if we choose our sample space $\Omega$ to be $\Omega = \emptyset$? What's the probability then?",,['probability']
2,How many experiments we should run to have one success with probability at least $50\%$?,How many experiments we should run to have one success with probability at least ?,50\%,"Could you tell me if my reasoning is right? I'm new in probability so I'm still not secure of how I should use the classical distributions to model problems. My problem is the following: I have a success-failure experiment such that the probability of success is $p\in(0,1)$ ($p$ is supposed to be very little, but this shouldn't change the reasoning). If we run the experiment one time, the probability of success is $p$. If we run the experiment $n$ times, the probability of having $k$ successes is $\binom{n}{k}p^k(1-p)^{n-k}$, for $0\leq k\leq n$. This is modeled by the binomial distribution. What I want to know is an inverse problem, we can say. How many experiments we should run to have one success with probability at least $50\%$? I'm looking for the minimal number $n$ of experiments. My idea: We can keep $n$ unknown and ask for the probability of having at least one success in $n$ experiments. This is given by $\sum_{k=1}^n \binom{n}{k}p^k(1-p)^{n-k}$. It's possible to use some program to find the minimum $n$ such that $\sum_{k=1}^n \binom{n}{k}p^k(1-p)^{n-k}\geq \frac{1}{2}$. In fact, I did this for some values of $p$, in particular, for $p=\frac{1}{10000}$ we have $n=6932$. But I'm not sure of this argument. I was looking for the number of experiments necessary to have one success with probability at least $50\%$, but ended up calculating the number of experiments necessary to have at least one success with probability at least $50\%$.","Could you tell me if my reasoning is right? I'm new in probability so I'm still not secure of how I should use the classical distributions to model problems. My problem is the following: I have a success-failure experiment such that the probability of success is $p\in(0,1)$ ($p$ is supposed to be very little, but this shouldn't change the reasoning). If we run the experiment one time, the probability of success is $p$. If we run the experiment $n$ times, the probability of having $k$ successes is $\binom{n}{k}p^k(1-p)^{n-k}$, for $0\leq k\leq n$. This is modeled by the binomial distribution. What I want to know is an inverse problem, we can say. How many experiments we should run to have one success with probability at least $50\%$? I'm looking for the minimal number $n$ of experiments. My idea: We can keep $n$ unknown and ask for the probability of having at least one success in $n$ experiments. This is given by $\sum_{k=1}^n \binom{n}{k}p^k(1-p)^{n-k}$. It's possible to use some program to find the minimum $n$ such that $\sum_{k=1}^n \binom{n}{k}p^k(1-p)^{n-k}\geq \frac{1}{2}$. In fact, I did this for some values of $p$, in particular, for $p=\frac{1}{10000}$ we have $n=6932$. But I'm not sure of this argument. I was looking for the number of experiments necessary to have one success with probability at least $50\%$, but ended up calculating the number of experiments necessary to have at least one success with probability at least $50\%$.",,"['probability', 'binomial-distribution']"
3,What is the maximum entropy distribution over all integers (ie. including negative ones) with fixed mean and variance?,What is the maximum entropy distribution over all integers (ie. including negative ones) with fixed mean and variance?,,"I know that the maximum entropy distribution with over the non-negative integers fixed mean is a geometric distributions. However, I cannot find conclusive information about what are the maximum entropy distributions over the whole integers (negative + non-negatives). As per the comment below, in this case, we need at least to specify both the mean and the standard deviation of the distribution for the ""maximum entropy"" criterion to make sense. It is well known that if we consider the whole real line, the maximum entropy distribution with a given mean and variance is a Gaussian normal distribution. My questions are therefore: 1- For a given mean and variance, is there a maximum entropy distribution over the integers?  2- If it exists, can it be expressed in a closed form, like gaussian or geometric distributions? My guess is that the answer is ""yes"" for 1) and ""no"" for 2) (since I cannot find any mention of a closed form anywhere). But I would be very happy to see a confirmation of this. EDIT: Since it is now clear that the variance needs to be specified for the ""maximum entropy"" criterion to make sense, I rewrote the question accordingly.","I know that the maximum entropy distribution with over the non-negative integers fixed mean is a geometric distributions. However, I cannot find conclusive information about what are the maximum entropy distributions over the whole integers (negative + non-negatives). As per the comment below, in this case, we need at least to specify both the mean and the standard deviation of the distribution for the ""maximum entropy"" criterion to make sense. It is well known that if we consider the whole real line, the maximum entropy distribution with a given mean and variance is a Gaussian normal distribution. My questions are therefore: 1- For a given mean and variance, is there a maximum entropy distribution over the integers?  2- If it exists, can it be expressed in a closed form, like gaussian or geometric distributions? My guess is that the answer is ""yes"" for 1) and ""no"" for 2) (since I cannot find any mention of a closed form anywhere). But I would be very happy to see a confirmation of this. EDIT: Since it is now clear that the variance needs to be specified for the ""maximum entropy"" criterion to make sense, I rewrote the question accordingly.",,"['probability', 'statistics', 'probability-distributions', 'entropy']"
4,Sum of discrete and continuous random variables with uniform distribution,Sum of discrete and continuous random variables with uniform distribution,,"Could you tell me how to find the distribution of $Z = X+Y$ if $X$ is a random variable with uniform distribution on $[0,1]$ and $Y$ has uniform distribution on $\{-1,0,1\}$? $X$ and $Y$ are independent. I know how to find distributions of sums of random variables if both are discrete or both are continuous. But here we have a mix. I guess I should consider $P(Z<-1) = P(\{X<-1, Y<0\} \cup \{X<0, Y<-1\})=0$ $P(Z \in [-1,0)) = P(X \in [-1,0), Y=0 \ \text{or} \ X \in [0,1), Y=-1 \ \text{or} \ X \in [-2, -1), Y=1) = \frac{1}{3}$ $P(Z \in [0,1)) = P(X \in [0,1), Y=0 \ \text{or} \ X \in [1,2), Y=-1 \ \text{or} \ X \in [-1, 0), Y=1) = \frac{2}{3}$ $P(Z \in [1,2)) = P(X \in [1,2), Y=0 \ \text{or} \ X \in [2,3), Y=-1 \ \text{or} \ X \in [0, 1), Y=1) = 1$ And so $P(Z \ge 1) = 1$ Is that correct?","Could you tell me how to find the distribution of $Z = X+Y$ if $X$ is a random variable with uniform distribution on $[0,1]$ and $Y$ has uniform distribution on $\{-1,0,1\}$? $X$ and $Y$ are independent. I know how to find distributions of sums of random variables if both are discrete or both are continuous. But here we have a mix. I guess I should consider $P(Z<-1) = P(\{X<-1, Y<0\} \cup \{X<0, Y<-1\})=0$ $P(Z \in [-1,0)) = P(X \in [-1,0), Y=0 \ \text{or} \ X \in [0,1), Y=-1 \ \text{or} \ X \in [-2, -1), Y=1) = \frac{1}{3}$ $P(Z \in [0,1)) = P(X \in [0,1), Y=0 \ \text{or} \ X \in [1,2), Y=-1 \ \text{or} \ X \in [-1, 0), Y=1) = \frac{2}{3}$ $P(Z \in [1,2)) = P(X \in [1,2), Y=0 \ \text{or} \ X \in [2,3), Y=-1 \ \text{or} \ X \in [0, 1), Y=1) = 1$ And so $P(Z \ge 1) = 1$ Is that correct?",,"['probability', 'probability-distributions', 'uniform-distribution']"
5,Making triangles out of a triangular lattice?,Making triangles out of a triangular lattice?,,"First off: Yes, I am well aware that this question has been posted before. However, the answer in that one was incorrect, so I decided to make another thread to gain more input, as well as provide what I have figured out on the problem so far. The problem asks: How many equilateral triangles in the plane have AT LEAST TWO of the points in the triangular lattice below as vertices? Using the formula found here: Link , I found out that the number of triangles with THREE vertices in the triangular lattice is 48. However, I am having trouble finding the number of triangles with TWO vertices in the triangular lattice. Would the two vertices in the triangular lattice come from the points bordering the triangular lattice? If so, I came up with 24. I am also worried about overcounting...and I also do not think I counted ALL of the possibilities. Can someone guide me in the right direction and provide me with some hints?","First off: Yes, I am well aware that this question has been posted before. However, the answer in that one was incorrect, so I decided to make another thread to gain more input, as well as provide what I have figured out on the problem so far. The problem asks: How many equilateral triangles in the plane have AT LEAST TWO of the points in the triangular lattice below as vertices? Using the formula found here: Link , I found out that the number of triangles with THREE vertices in the triangular lattice is 48. However, I am having trouble finding the number of triangles with TWO vertices in the triangular lattice. Would the two vertices in the triangular lattice come from the points bordering the triangular lattice? If so, I came up with 24. I am also worried about overcounting...and I also do not think I counted ALL of the possibilities. Can someone guide me in the right direction and provide me with some hints?",,['probability']
6,How many combinations from rolling 5 identical dice?,How many combinations from rolling 5 identical dice?,,"Where, for example: (1,3,1,4,6) is considered the same outcome as (1,1,3,6,4) How many total outcomes are there? Edit 1: My hunch is that there are: 6 outcomes from choosing 1 dice to be missing. 6*5 = 30 outcomes from choosing 1 number to be the same and one missing from the 5 remaining. 6*5*4 = 120 from choosing 1 to be triple, 1 from 5 to be missing, and 1 from 4 to be missing. 6*5 = 30 from choosing 1 to be the quadruple and 1 from 5 to be remaining. and 6 from choosing 1 to be all the same number. Which gives 192 in total. Edit 2: Thanks JimmyK for correct answer: 252. Obtained by: C(6+6-1, 6-1) = C(10,5) Can also get the answer by summing these possibilities, of which I missed out loads above: C(6,1) + C(6,5) + C(6,1)*C(5,3) + C(6,2)*C(4,1) + C(6,1)*C(5,2) + C(6,1)*C(5,1) = 252","Where, for example: (1,3,1,4,6) is considered the same outcome as (1,1,3,6,4) How many total outcomes are there? Edit 1: My hunch is that there are: 6 outcomes from choosing 1 dice to be missing. 6*5 = 30 outcomes from choosing 1 number to be the same and one missing from the 5 remaining. 6*5*4 = 120 from choosing 1 to be triple, 1 from 5 to be missing, and 1 from 4 to be missing. 6*5 = 30 from choosing 1 to be the quadruple and 1 from 5 to be remaining. and 6 from choosing 1 to be all the same number. Which gives 192 in total. Edit 2: Thanks JimmyK for correct answer: 252. Obtained by: C(6+6-1, 6-1) = C(10,5) Can also get the answer by summing these possibilities, of which I missed out loads above: C(6,1) + C(6,5) + C(6,1)*C(5,3) + C(6,2)*C(4,1) + C(6,1)*C(5,2) + C(6,1)*C(5,1) = 252",,"['probability', 'dice']"
7,Probability based on Hamming distance,Probability based on Hamming distance,,"Two $n$ bit binary strings $S_1$ and $S_2$ are chosen randomly with uniform probability. The probability that the Hamming distance in between these strings (the number of bit positions where the two strings differ) is equal to $d$ is: $\binom{n}{d} \over {2^n}$ $\binom{n}{d} \over {2^n}$ $d\over2^n$ $1\over2^d$ ...choose the right answer. I tried to solve the problem, but I didn't find any suitable way to tackle this problem.","Two $n$ bit binary strings $S_1$ and $S_2$ are chosen randomly with uniform probability. The probability that the Hamming distance in between these strings (the number of bit positions where the two strings differ) is equal to $d$ is: $\binom{n}{d} \over {2^n}$ $\binom{n}{d} \over {2^n}$ $d\over2^n$ $1\over2^d$ ...choose the right answer. I tried to solve the problem, but I didn't find any suitable way to tackle this problem.",,['probability']
8,Rolling standard deviations,Rolling standard deviations,,"I am trying to calculate standard deviations on an array of numbers. My psuedo code looks like this: deviation = getStandardDeviation(array(32, 47, 42, 45, 80, 90)); In the above example, deviation is equal to 23.26 . However, what if I wanted to add an additional number, e.g. 52 , to the above calculation, but I no longer had the original array of numbers? In other words, is there a way for me to calculate the standard deviation using these two variables: The new number (e.g. 52 ) The old standard deviation (e.g. 23.26 ) Or would I always need the complete array of numbers?","I am trying to calculate standard deviations on an array of numbers. My psuedo code looks like this: deviation = getStandardDeviation(array(32, 47, 42, 45, 80, 90)); In the above example, deviation is equal to 23.26 . However, what if I wanted to add an additional number, e.g. 52 , to the above calculation, but I no longer had the original array of numbers? In other words, is there a way for me to calculate the standard deviation using these two variables: The new number (e.g. 52 ) The old standard deviation (e.g. 23.26 ) Or would I always need the complete array of numbers?",,"['probability', 'statistics', 'standard-deviation', 'statistical-inference']"
9,Result and proof on the conditional expectation of the product of two random variables,Result and proof on the conditional expectation of the product of two random variables,,"My problem is the following: $X$ and $Y$ are two random variables and $\mathcal{F}$ is a $\sigma$-algebra. Given that $X$ and $Y$ are independent, and that $X$ is independent of $\mathcal{F}$, can I affirm that  $$\mathbb{E}(XY \mid \mathcal{F}) = \mathbb{E}(X) \cdot \mathbb{E}(Y \mid \mathcal{F})?$$ My intuition is yes but I did not manage to find a formal proof. Any idea ? Thanks a lot.","My problem is the following: $X$ and $Y$ are two random variables and $\mathcal{F}$ is a $\sigma$-algebra. Given that $X$ and $Y$ are independent, and that $X$ is independent of $\mathcal{F}$, can I affirm that  $$\mathbb{E}(XY \mid \mathcal{F}) = \mathbb{E}(X) \cdot \mathbb{E}(Y \mid \mathcal{F})?$$ My intuition is yes but I did not manage to find a formal proof. Any idea ? Thanks a lot.",,"['probability', 'probability-theory', 'probability-distributions', 'expectation']"
10,How many times do we need to roll a fair die to get a better than evens chance of at least one six?,How many times do we need to roll a fair die to get a better than evens chance of at least one six?,,"""How many times do we need to roll a fair die to get a better than evens chance of at least one six?"" This is the question i need to answer as it is on a practice exam paper. I simply cannot understand how you can increase the chance of getting a 6? Is it asking me how many times i need to roll a fair die in order to have more than a 50 percent chance of getting at least one 6? If it is then how can you increase your chance? I thought no matter how many times you roll it it will be a $${1}/{6}$$ chance of getting a 6 thus never will have a better than evens chance of at least one 6? Im completely confused and have been for days now. I dont know if it is a badly asked question or if i am just not understanding it very well?! Could someone please explain what i would have to do. would i have to use something like $$P(A^c)=1-P(A)$$? Many thanks in advance for any help. It would be much appreciated as i cannot find even a similar style question to do anywhere online.","""How many times do we need to roll a fair die to get a better than evens chance of at least one six?"" This is the question i need to answer as it is on a practice exam paper. I simply cannot understand how you can increase the chance of getting a 6? Is it asking me how many times i need to roll a fair die in order to have more than a 50 percent chance of getting at least one 6? If it is then how can you increase your chance? I thought no matter how many times you roll it it will be a $${1}/{6}$$ chance of getting a 6 thus never will have a better than evens chance of at least one 6? Im completely confused and have been for days now. I dont know if it is a badly asked question or if i am just not understanding it very well?! Could someone please explain what i would have to do. would i have to use something like $$P(A^c)=1-P(A)$$? Many thanks in advance for any help. It would be much appreciated as i cannot find even a similar style question to do anywhere online.",,['probability']
11,How to Make a PDF 'Look' Uniform?,How to Make a PDF 'Look' Uniform?,,"Let $X$ be a normally-distributed random variable with mean zero and variance $\sigma^2$: $X \sim N(0,\sigma^2)$. Let $Y$ be a mapping from $X$ onto the interval $(0,1)$ using the sigmoid function: $Y=\text{sig}(X)=\frac{1}{1+e^{-X}}$. It can be shown that $Y$ has the following probability density function: $ f_Y (y) = \frac{1}{y(1-y)} \frac{1}{\sqrt{2 \pi \sigma^2}} \exp{\left(-\frac{\left(\ln\frac{y}{1-y}\right)^2}{2\sigma^2}\right)} $ My question is: for what value of $\sigma$ is $f_y (y)$ the flattest ? (i.e., is the most similar to a uniform distribution over $(0,1)$). Is a closed-form solution to this problem possible? PS: I am leaving the definition of ""the flattest"" open, because I am OK with any one that makes sense. For instance, a simple one could be the one that minimizes the integral of $\left[f_Y(y)-1\right]^2$ over $(0,1)$.","Let $X$ be a normally-distributed random variable with mean zero and variance $\sigma^2$: $X \sim N(0,\sigma^2)$. Let $Y$ be a mapping from $X$ onto the interval $(0,1)$ using the sigmoid function: $Y=\text{sig}(X)=\frac{1}{1+e^{-X}}$. It can be shown that $Y$ has the following probability density function: $ f_Y (y) = \frac{1}{y(1-y)} \frac{1}{\sqrt{2 \pi \sigma^2}} \exp{\left(-\frac{\left(\ln\frac{y}{1-y}\right)^2}{2\sigma^2}\right)} $ My question is: for what value of $\sigma$ is $f_y (y)$ the flattest ? (i.e., is the most similar to a uniform distribution over $(0,1)$). Is a closed-form solution to this problem possible? PS: I am leaving the definition of ""the flattest"" open, because I am OK with any one that makes sense. For instance, a simple one could be the one that minimizes the integral of $\left[f_Y(y)-1\right]^2$ over $(0,1)$.",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
12,Probability problem (withdraw balls from the urn),Probability problem (withdraw balls from the urn),,"Problem :   An urn contains 3 red and 7 black balls. Player A and B withdraw balls from the urn consecutively until a red ball is selected. Find the probability that A selects the red ball. (A draws the first ball, then B, and so on. There is no replacement of the balls drawn) I have the solution: $$\Bbb{P}(A)=\frac{3\cdot 9!+6\cdot 3 \cdot 7!+ 7\cdot6\cdot5\cdot4\cdot3\cdot5!+7\cdot6\cdot5\cdot4\cdot3\cdot2\cdot3\cdot3!}{10!}$$ But i have no idea how they came up with this. Can someone explain  this? Thank you.","Problem :   An urn contains 3 red and 7 black balls. Player A and B withdraw balls from the urn consecutively until a red ball is selected. Find the probability that A selects the red ball. (A draws the first ball, then B, and so on. There is no replacement of the balls drawn) I have the solution: $$\Bbb{P}(A)=\frac{3\cdot 9!+6\cdot 3 \cdot 7!+ 7\cdot6\cdot5\cdot4\cdot3\cdot5!+7\cdot6\cdot5\cdot4\cdot3\cdot2\cdot3\cdot3!}{10!}$$ But i have no idea how they came up with this. Can someone explain  this? Thank you.",,['probability']
13,example of irreducible transient markov chain,example of irreducible transient markov chain,,"Can anyone give me a simple example of an irreducible (all elements communicate) and transient markov chain? I can't think of any such chain, yet it exists (but has to have an infinite number of elements) thanks","Can anyone give me a simple example of an irreducible (all elements communicate) and transient markov chain? I can't think of any such chain, yet it exists (but has to have an infinite number of elements) thanks",,"['probability', 'markov-chains']"
14,Probability two people will talk at the same time,Probability two people will talk at the same time,,"The other day, I was talking to a friend, and then one of those lulls in the conversation came, where we had nothing more to say on the current subject and a new topic didn't immediately come to mind. We both decided to end the gap and start talking at the same time, as sometimes happens. What are the odds of that happening? I thought. I tried to work it out, but my lack of knowledge in probability and statistics (a class I'm taking next semester, though) prevented me from getting very far. First, let's count two people talking within one second of each other as breaking the gap. That seems like a reasonable number. Second, it seems that the average length of these gaps between topics is only a few minutes, and more often than not, they're broken by one person or the other, rather than both attempting it simultaneously. I assume there's some reasonable first approximation formula $p(t)$ to model the probability that a given person will talk at time $t$, then those probabilities are somehow combined (addition? multiplication?) for the number of people in the conversation, and you get the result. How can I find the solution from here?","The other day, I was talking to a friend, and then one of those lulls in the conversation came, where we had nothing more to say on the current subject and a new topic didn't immediately come to mind. We both decided to end the gap and start talking at the same time, as sometimes happens. What are the odds of that happening? I thought. I tried to work it out, but my lack of knowledge in probability and statistics (a class I'm taking next semester, though) prevented me from getting very far. First, let's count two people talking within one second of each other as breaking the gap. That seems like a reasonable number. Second, it seems that the average length of these gaps between topics is only a few minutes, and more often than not, they're broken by one person or the other, rather than both attempting it simultaneously. I assume there's some reasonable first approximation formula $p(t)$ to model the probability that a given person will talk at time $t$, then those probabilities are somehow combined (addition? multiplication?) for the number of people in the conversation, and you get the result. How can I find the solution from here?",,['probability']
15,How can a Markov chain be written as a measure-preserving dynamic system,How can a Markov chain be written as a measure-preserving dynamic system,,"From http://masi.cscs.lsa.umich.edu/~crshalizi/notabene/ergodic-theory.html irreducible Markov chains with finite state spaces are ergodic   processes, since they have a unique invariant distribution over the   states. (In the Markov chain case, each of the ergodic components   corresponds to an irreducible sub-space.) By ""ergodic processes"", I understand it to be the same as ""ergodic measure-preserving dynamic system"", if I am correct. As far as I know an ergodic measure-preserving dynamic system is a mapping $\Phi: T \times S \to S$ that satisfies a couple of properties, where $S$ is the state space, and $T$ is the time space. Sometimes there is a measure preserving mapping on $S$ that can generate the system by repeating itself. So I wonder how a Markov chain can be written as a mapping $\Phi: T \times S \to S$, and what the measure preserving mapping that generates the Markov chain is? Thanks!","From http://masi.cscs.lsa.umich.edu/~crshalizi/notabene/ergodic-theory.html irreducible Markov chains with finite state spaces are ergodic   processes, since they have a unique invariant distribution over the   states. (In the Markov chain case, each of the ergodic components   corresponds to an irreducible sub-space.) By ""ergodic processes"", I understand it to be the same as ""ergodic measure-preserving dynamic system"", if I am correct. As far as I know an ergodic measure-preserving dynamic system is a mapping $\Phi: T \times S \to S$ that satisfies a couple of properties, where $S$ is the state space, and $T$ is the time space. Sometimes there is a measure preserving mapping on $S$ that can generate the system by repeating itself. So I wonder how a Markov chain can be written as a mapping $\Phi: T \times S \to S$, and what the measure preserving mapping that generates the Markov chain is? Thanks!",,"['probability', 'stochastic-processes', 'dynamical-systems', 'markov-chains']"
16,Estimate total song ('coupon') number by number of repeats,Estimate total song ('coupon') number by number of repeats,,"If shuffle-playing playlist ×100 resulted in [10 13 10  3  2  2] different songs being repeated [1 2 3 4 5 6] times, what is the estimate for the total number of songs? (assuming shuffle play was completely random) Update: (R code) k <- 50 # k number of songs on the disk indexed 1:k n <- 100 # n number of random song selections m <- 20 # m number of repeat experiments colnum <- 10 mat <- matrix(data=NA,nrow=m,ncol=colnum) df <- as.data.frame(mat) for(i in 1:m){   played <- 1+floor(k*runif(n)) # actual song indices (1:k) selected    freq <- sapply(1:k,function(x){sum(played==x)})   # = number of times song with index x is being played   histo <- sapply(1:colnum,function(x){sum(freq==x)});   for(j in 1:colnum){    df[i,j] <- histo[j]   } } df Resulting in: e.g. 20 distributions (V1=number of single plays, V2=number of double plays, etc): V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 1  15 13 11  1  2  2  0  0  0   0 2  15 12 10  1  4  0  1  0  0   0 3  12 14  7  6  3  0  0  0  0   0 4  17 16  6  4  2  0  1  0  0   0 5  17 10 12  5  0  0  1  0  0   0 6  13 15 11  6  0  0  0  0  0   0 7  10 14  9  3  2  1  1  0  0   0 8  12 17  5  6  3  0  0  0  0   0 9   9 19  8  3  1  2  0  0  0   0 10 13  9 11  6  1  0  1  0  0   0 11 16  9 12  5  2  0  0  0  0   0 12 15  9 11  6  2  0  0  0  0   0 13 19  9  7  4  4  1  0  0  0   0 14 17 11  4  7  3  1  0  0  0   0 15 11 20  8  1  3  1  0  0  0   0 16 14 12 10  5  0  2  0  0  0   0 17  9 12  8  7  3  0  0  0  0   0 18 10 15  9  4  2  0  1  0  0   0 19 14 11 12  7  0  0  0  0  0   0 20 16 14 11  3  1  1  0  0  0   0 Now I need to get from here to the Poisson modelling--my R is a bit rusty (? lmer )...--Any help would be appreciated... Attempted Poisson modelling: disappointing fit?! plot(1:colnum,df[1,1:colnum],ylim=c(0,30),    type=""l"",xlab=""repeats"",ylab=""count"") for(i in 1:m){   clr <- rainbow(m)[i]   lines(1:colnum,df[i,1:colnum],type=""l"",col=clr)   points(1:colnum,df[i,1:colnum],col=clr) }  df.lambda=data.frame(lambda=seq(1,5,0.1),ssq=c(NA));df.lambda for(ii in 1:dim(df.lambda)[1]){   l <- df.lambda$lambda[ii]       ssq <- 0       for(i in 1:20){         for(j in 1:10){           ssq <- ssq + (df[i,j] - n*dpois(j,l))^2         }       }       print(ssq)       df.lambda$lambda[ii] <- l   df.lambda$ssq[ii] <- ssq     }     df.lambda     lambda.est <- df.lambda$lambda[which.min(df.lambda$ssq)] lambda.est # 2.4 points(x <- 1:10, n*dpois(1:10,lambda.est),type=""l"",lwd=2)  100*dpois(1:10,3) n/lambda.est the estimated lambda stays around 2.3, with an n estimate of around 43; the fitted curve seems very discrepant , and seems to worsen with rising n !?  Doesn't this have to do with the fact, that our repeats are different from the 'classical' Poisson distributions: it's not just ONE event that repeats itself x number of times, but the sum of repeats of different items (songs)?!","If shuffle-playing playlist ×100 resulted in [10 13 10  3  2  2] different songs being repeated [1 2 3 4 5 6] times, what is the estimate for the total number of songs? (assuming shuffle play was completely random) Update: (R code) k <- 50 # k number of songs on the disk indexed 1:k n <- 100 # n number of random song selections m <- 20 # m number of repeat experiments colnum <- 10 mat <- matrix(data=NA,nrow=m,ncol=colnum) df <- as.data.frame(mat) for(i in 1:m){   played <- 1+floor(k*runif(n)) # actual song indices (1:k) selected    freq <- sapply(1:k,function(x){sum(played==x)})   # = number of times song with index x is being played   histo <- sapply(1:colnum,function(x){sum(freq==x)});   for(j in 1:colnum){    df[i,j] <- histo[j]   } } df Resulting in: e.g. 20 distributions (V1=number of single plays, V2=number of double plays, etc): V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 1  15 13 11  1  2  2  0  0  0   0 2  15 12 10  1  4  0  1  0  0   0 3  12 14  7  6  3  0  0  0  0   0 4  17 16  6  4  2  0  1  0  0   0 5  17 10 12  5  0  0  1  0  0   0 6  13 15 11  6  0  0  0  0  0   0 7  10 14  9  3  2  1  1  0  0   0 8  12 17  5  6  3  0  0  0  0   0 9   9 19  8  3  1  2  0  0  0   0 10 13  9 11  6  1  0  1  0  0   0 11 16  9 12  5  2  0  0  0  0   0 12 15  9 11  6  2  0  0  0  0   0 13 19  9  7  4  4  1  0  0  0   0 14 17 11  4  7  3  1  0  0  0   0 15 11 20  8  1  3  1  0  0  0   0 16 14 12 10  5  0  2  0  0  0   0 17  9 12  8  7  3  0  0  0  0   0 18 10 15  9  4  2  0  1  0  0   0 19 14 11 12  7  0  0  0  0  0   0 20 16 14 11  3  1  1  0  0  0   0 Now I need to get from here to the Poisson modelling--my R is a bit rusty (? lmer )...--Any help would be appreciated... Attempted Poisson modelling: disappointing fit?! plot(1:colnum,df[1,1:colnum],ylim=c(0,30),    type=""l"",xlab=""repeats"",ylab=""count"") for(i in 1:m){   clr <- rainbow(m)[i]   lines(1:colnum,df[i,1:colnum],type=""l"",col=clr)   points(1:colnum,df[i,1:colnum],col=clr) }  df.lambda=data.frame(lambda=seq(1,5,0.1),ssq=c(NA));df.lambda for(ii in 1:dim(df.lambda)[1]){   l <- df.lambda$lambda[ii]       ssq <- 0       for(i in 1:20){         for(j in 1:10){           ssq <- ssq + (df[i,j] - n*dpois(j,l))^2         }       }       print(ssq)       df.lambda$lambda[ii] <- l   df.lambda$ssq[ii] <- ssq     }     df.lambda     lambda.est <- df.lambda$lambda[which.min(df.lambda$ssq)] lambda.est # 2.4 points(x <- 1:10, n*dpois(1:10,lambda.est),type=""l"",lwd=2)  100*dpois(1:10,3) n/lambda.est the estimated lambda stays around 2.3, with an n estimate of around 43; the fitted curve seems very discrepant , and seems to worsen with rising n !?  Doesn't this have to do with the fact, that our repeats are different from the 'classical' Poisson distributions: it's not just ONE event that repeats itself x number of times, but the sum of repeats of different items (songs)?!",,['probability']
17,Conditional Entropy is less than entropy,Conditional Entropy is less than entropy,,"Let $p_{ij}=P(X=i,Y=j)$ be the joint distribution, $P(X=i)=p_i=\sum_j p_{ij}, P(Y=j)=q_j=\sum_i p_{ij}$ be the marginal distributions, and $p_{i|j}=\frac{p_{ij}}{q_j}$ be the conditional distribution. Then the conditional entropy is defined as $$E[h(X|Y)]=-\sum_j \sum_i p_{i|j} \ln p_{i|j} q_j $$ Show $E[h(X|Y)]\leq h(X)$ where $h(X)$ is the entropy of $X$. I'm at a lost as to even know where to begin.","Let $p_{ij}=P(X=i,Y=j)$ be the joint distribution, $P(X=i)=p_i=\sum_j p_{ij}, P(Y=j)=q_j=\sum_i p_{ij}$ be the marginal distributions, and $p_{i|j}=\frac{p_{ij}}{q_j}$ be the conditional distribution. Then the conditional entropy is defined as $$E[h(X|Y)]=-\sum_j \sum_i p_{i|j} \ln p_{i|j} q_j $$ Show $E[h(X|Y)]\leq h(X)$ where $h(X)$ is the entropy of $X$. I'm at a lost as to even know where to begin.",,['probability']
18,Probability of balls in the box,Probability of balls in the box,,"In a box there are 12 balls; 4 defective, 8 not defective. What is the probability that when 3 balls are drawn, at least two of them are defective. I know the answer is $$\frac{{4 \choose 2}{8 \choose 1} + {4 \choose 3}}{{12 \choose 3}}$$ But why isn't the answer also $$\frac{{4 \choose 2}{10 \choose 1}}{{12 \choose 3}} $$? Because I choose 2 balls from the 4 defective, and 1 from the remaining 10 (it will either be defective or not).","In a box there are 12 balls; 4 defective, 8 not defective. What is the probability that when 3 balls are drawn, at least two of them are defective. I know the answer is $$\frac{{4 \choose 2}{8 \choose 1} + {4 \choose 3}}{{12 \choose 3}}$$ But why isn't the answer also $$\frac{{4 \choose 2}{10 \choose 1}}{{12 \choose 3}} $$? Because I choose 2 balls from the 4 defective, and 1 from the remaining 10 (it will either be defective or not).",,['probability']
19,How to calculate the expected number of distinct items when drawing pairs?,How to calculate the expected number of distinct items when drawing pairs?,,"Suppose I have a set $\mathcal{S}$ of $N$ distinct items. Now consider the set $\mathcal{P}$ of all possible pairs that I can draw from $S$. Naturally, $|\mathcal{P}| = \binom{N}{2}$. Now when I draw $k$ items (pairs) from $\mathcal{P}$ with a uniform distribution, what is the expected number of distinct items from $S$ in those $k$ pairs? P.S.: I also asked this question over at stats , but got no answers so far, so I am trying here. Thanks for your time! Edit I pick the pairs without replacement.","Suppose I have a set $\mathcal{S}$ of $N$ distinct items. Now consider the set $\mathcal{P}$ of all possible pairs that I can draw from $S$. Naturally, $|\mathcal{P}| = \binom{N}{2}$. Now when I draw $k$ items (pairs) from $\mathcal{P}$ with a uniform distribution, what is the expected number of distinct items from $S$ in those $k$ pairs? P.S.: I also asked this question over at stats , but got no answers so far, so I am trying here. Thanks for your time! Edit I pick the pairs without replacement.",,"['combinatorics', 'probability']"
20,Expectation of squared time-scaled Brownian process,Expectation of squared time-scaled Brownian process,,"According to an article I'm studying (""Time series, self-similarity and network traffic by Mark Crovella) the expectation of the square of a time-scaled Brownian motion process $E[ B(ct)^2 ]$ where $c$ is the time scaling is equal to $ct$. I'd appreciate help proving this; i.e. $E[  B(ct)^2 ] = c t$","According to an article I'm studying (""Time series, self-similarity and network traffic by Mark Crovella) the expectation of the square of a time-scaled Brownian motion process $E[ B(ct)^2 ]$ where $c$ is the time scaling is equal to $ct$. I'd appreciate help proving this; i.e. $E[  B(ct)^2 ] = c t$",,"['probability', 'statistics']"
21,"A false ""proof"" that record setting events are dependent","A false ""proof"" that record setting events are dependent",,"Let $\{X_i\}$ be a sequence of i.i.d continuous RV.  Call $i$ record-setting if $$X_i > \max_{1 \leq j < i} X_j.$$ It is well - established on math.SE and elsewhere that the events "" $X_n$ is record-setting"" and "" $X_{n+1}$ is record-setting"" are independent.  Below is a ""proof"" that they are indeed dependent.  Where's the error? Let $$M_{n} := \max\limits_{1 \leq j \leq n} X_j.$$ The event "" $n$ and $n+1$ are both record-setting"" occurs if and only if: $X_n > M_{n-1}$ $X_{n+1} > M_{n-1}$ $X_{n+1} > X_n$ . By symmetry, event #1 has probability $1/n$ .  Since the $X$ are i.i.d, event #2 has probability $1/n$ as well, and is independent of event #1.  Finally, given events #1 and #2, the conditional probability of event #3 is $1/2$ .  Therefore the probability that both $n$ and $n+1$ are record-setters is $$P(A\cap B) = \frac 1 {2n^2} \neq \frac 1 {n(n+1)} = P(A)P(B)$$ and so the events are dependent.","Let be a sequence of i.i.d continuous RV.  Call record-setting if It is well - established on math.SE and elsewhere that the events "" is record-setting"" and "" is record-setting"" are independent.  Below is a ""proof"" that they are indeed dependent.  Where's the error? Let The event "" and are both record-setting"" occurs if and only if: . By symmetry, event #1 has probability .  Since the are i.i.d, event #2 has probability as well, and is independent of event #1.  Finally, given events #1 and #2, the conditional probability of event #3 is .  Therefore the probability that both and are record-setters is and so the events are dependent.",\{X_i\} i X_i > \max_{1 \leq j < i} X_j. X_n X_{n+1} M_{n} := \max\limits_{1 \leq j \leq n} X_j. n n+1 X_n > M_{n-1} X_{n+1} > M_{n-1} X_{n+1} > X_n 1/n X 1/n 1/2 n n+1 P(A\cap B) = \frac 1 {2n^2} \neq \frac 1 {n(n+1)} = P(A)P(B),"['probability', 'conditional-probability', 'independence', 'fake-proofs']"
22,Candies Withdrawal Game,Candies Withdrawal Game,,"You are taking out candies one by one from a jar that has 10 red candies, 20 blue candies, and 30 green candies in it. What is the probability that there are at least 1 blue candy and 1 green candy left in the jar when you have taken out all the red candies? Why is my approach wrong: $$\frac{2 \cdot 58!}{10! \cdot 29! \cdot 19!} \,\Big / \frac{60!}{10! \cdot 30! \cdot 20!}$$ Reasoning: There are 2 cases: last candy is green, 2nd last candy is blue last candy is blue, 2nd last candy is green For each of the cases, where the last and 2nd last candy withdrawn is fixed, there are $\frac{58!}{10!29!19!}$ ways to arrange the rest of the candies. Hence, the numerator. For the denominator, it is the total number of ways to arrange all the candies, $\frac{60!}{10!30!20!}$ . However, as compared to the answer, $7/12$ , my approach seems to be undercounting. Why?","You are taking out candies one by one from a jar that has 10 red candies, 20 blue candies, and 30 green candies in it. What is the probability that there are at least 1 blue candy and 1 green candy left in the jar when you have taken out all the red candies? Why is my approach wrong: Reasoning: There are 2 cases: last candy is green, 2nd last candy is blue last candy is blue, 2nd last candy is green For each of the cases, where the last and 2nd last candy withdrawn is fixed, there are ways to arrange the rest of the candies. Hence, the numerator. For the denominator, it is the total number of ways to arrange all the candies, . However, as compared to the answer, , my approach seems to be undercounting. Why?","\frac{2 \cdot 58!}{10! \cdot 29! \cdot 19!} \,\Big / \frac{60!}{10! \cdot 30! \cdot 20!} \frac{58!}{10!29!19!} \frac{60!}{10!30!20!} 7/12","['probability', 'combinatorics']"
23,Calculate $\mathbb EB_1B_2^2 B_3^3$ for Brownian motion,Calculate  for Brownian motion,\mathbb EB_1B_2^2 B_3^3,"Calculate $\mathbb EB_1B_2^2 B_3^3$ cleverly (expressing the result, e.g. in terms of $\mathcal N(0,1)$ moments), where $B_t$ is standard Brownian motion. I know that in tasks like this, it's often useful to use $W_s = W_t + (W_s - W_t)$ (like for example here ). However, I don't know if my way is correct: $$\begin{align}\mathbb E(B_1B_2^2B_3^3) &= \mathbb E(B_1B_3)\mathbb E(B_2^2)\mathbb E(B_3^2) \\ &= \mathbb E \left[ -\frac 12 (B_1-B_3)^2 + \frac 12 (B_1^2+B_3^2) \right] \cdot \mathcal N(0,2)\cdot \mathcal N(0,3) \\ &= \left[ -\frac 12 \mathbb E(B_1-B_3)^2 + \frac 12 \mathbb E (B_1^2)+\frac 12 \mathbb E(B_3^2) \right] \cdot \mathcal N(0,2)\cdot \mathcal N(0,3) \\ &=   \left[ - \frac 12 \mathcal N(0,3-1)+\frac 12 \mathcal N(0,1)+ \frac 12 \mathcal N(0,3) \right) \cdot \mathcal N(0,2)\cdot \mathcal N(0,3)\end{align}$$","Calculate cleverly (expressing the result, e.g. in terms of moments), where is standard Brownian motion. I know that in tasks like this, it's often useful to use (like for example here ). However, I don't know if my way is correct:","\mathbb EB_1B_2^2 B_3^3 \mathcal N(0,1) B_t W_s = W_t + (W_s - W_t) \begin{align}\mathbb E(B_1B_2^2B_3^3) &= \mathbb E(B_1B_3)\mathbb E(B_2^2)\mathbb E(B_3^2) \\ &= \mathbb E \left[ -\frac 12 (B_1-B_3)^2 + \frac 12 (B_1^2+B_3^2) \right] \cdot \mathcal N(0,2)\cdot \mathcal N(0,3) \\ &= \left[ -\frac 12 \mathbb E(B_1-B_3)^2 + \frac 12 \mathbb E (B_1^2)+\frac 12 \mathbb E(B_3^2) \right] \cdot \mathcal N(0,2)\cdot \mathcal N(0,3) \\ &= 
 \left[ - \frac 12 \mathcal N(0,3-1)+\frac 12 \mathcal N(0,1)+ \frac 12 \mathcal N(0,3) \right) \cdot \mathcal N(0,2)\cdot \mathcal N(0,3)\end{align}","['probability', 'stochastic-processes', 'brownian-motion']"
24,"The two envelopes problem, only we know which envelope has the ""original"" amount","The two envelopes problem, only we know which envelope has the ""original"" amount",,"This problem is from Sheldon Ross's book, a first course in probability: Problem Body: A philanthropist writes a positive number $x$ on a piece of red paper, shows the paper to an impartial observer, and then turns it face down on the table. The observer then flips a fair coin. If it shows heads, she writes the value $2x$ and, if tails, the value $x/2$ , on a piece of blue paper, which she then turns face down on the table. Without knowing either the value $x$ or the result of the coin flip, you have the option of turning over either the red or the blue piece of paper. After doing so and observing the number written on that paper, you may elect to receive as a reward either that amount or the (unknown) amount written on the other piece of paper. For instance, if you elect to turn over the blue paper and observe the value $100$ , then you can elect either to accept $100$ as your reward or to take the amount (either $200$ or $50$ ) on the red paper. Suppose that you would like your expected reward to be large. Let $y$ be a fixed nonnegative value, and consider the following strategy: Turn over the blue paper, and if its value is at least $y$ , then accept that amount. If it is less than $y$ , then switch to the red paper. Let $R_y(x)$ denote the reward obtained if the philanthropist writes the amount $x$ and you employ this strategy. Find $E[R_y(x)]$ . Note that $E[R_0(x)]$ is the expected reward if the philanthropist writes the amount $x$ when you employ the strategy of always choosing the blue paper. My doubts: Now this is different from the usual envelope problem because we know which paper ""envelop"" has the original i.e. $x$ amount; so it's always beneficial to pick the blue paper. Concerning the $E[R_y(x)]$ ; I don't know how to calculate it for any $y, x$ ; that's because $x$ can be any positive number for example let's call the amount on the blue paper $b$ , if we have $y=1$ ; then for any $b$ if $b \geq y$ then we stay with the blue paper and if $b < y$ then we switch to the red paper; for each of those cases we can easily calculate the expected gain, the issue arises when I want to calculate the overall expected gain; that's because $0 < b \leq +\infty$ ; so it doesn't make sense to calculate the probability for $b \geq y$ and $b < y$ . I'm very confused so any help will be much appreciated. Thanks in advance!","This problem is from Sheldon Ross's book, a first course in probability: Problem Body: A philanthropist writes a positive number on a piece of red paper, shows the paper to an impartial observer, and then turns it face down on the table. The observer then flips a fair coin. If it shows heads, she writes the value and, if tails, the value , on a piece of blue paper, which she then turns face down on the table. Without knowing either the value or the result of the coin flip, you have the option of turning over either the red or the blue piece of paper. After doing so and observing the number written on that paper, you may elect to receive as a reward either that amount or the (unknown) amount written on the other piece of paper. For instance, if you elect to turn over the blue paper and observe the value , then you can elect either to accept as your reward or to take the amount (either or ) on the red paper. Suppose that you would like your expected reward to be large. Let be a fixed nonnegative value, and consider the following strategy: Turn over the blue paper, and if its value is at least , then accept that amount. If it is less than , then switch to the red paper. Let denote the reward obtained if the philanthropist writes the amount and you employ this strategy. Find . Note that is the expected reward if the philanthropist writes the amount when you employ the strategy of always choosing the blue paper. My doubts: Now this is different from the usual envelope problem because we know which paper ""envelop"" has the original i.e. amount; so it's always beneficial to pick the blue paper. Concerning the ; I don't know how to calculate it for any ; that's because can be any positive number for example let's call the amount on the blue paper , if we have ; then for any if then we stay with the blue paper and if then we switch to the red paper; for each of those cases we can easily calculate the expected gain, the issue arises when I want to calculate the overall expected gain; that's because ; so it doesn't make sense to calculate the probability for and . I'm very confused so any help will be much appreciated. Thanks in advance!","x 2x x/2 x 100 100 200 50 y y y R_y(x) x E[R_y(x)] E[R_0(x)] x x E[R_y(x)] y, x x b y=1 b b \geq y b < y 0 < b \leq +\infty b \geq y b < y","['probability', 'random-variables']"
25,"Probability - Choosing two numbers from $\{1,2,3,4,5,6\}$ such that the minimum is less than $4$",Probability - Choosing two numbers from  such that the minimum is less than,"\{1,2,3,4,5,6\} 4","Two numbers are selected randomly from the set $S = \{1, 2, 3, 4, 5, 6\}$ without replacement one by one. The probability that minimum of the two numbers is less than 4, is? The correct method to solve this question is to take two cases : one in which both numbers are less than $4$ ( ${}^3C_2$ ), and the other in which one is greater than $4$ and one is less than $4$ ( ${}^3C_1 \times {}^3C_1$ ) The solution that I came up with is to take one number from $\{1,2,3\}$ and the other number from the remaining numbers ( $ {}^3C_1 \times {}^5C_1$ ) but my answer is wrong. Can someone please explain me why my answer is wrong?","Two numbers are selected randomly from the set without replacement one by one. The probability that minimum of the two numbers is less than 4, is? The correct method to solve this question is to take two cases : one in which both numbers are less than ( ), and the other in which one is greater than and one is less than ( ) The solution that I came up with is to take one number from and the other number from the remaining numbers ( ) but my answer is wrong. Can someone please explain me why my answer is wrong?","S = \{1, 2, 3, 4, 5, 6\} 4 {}^3C_2 4 4 {}^3C_1 \times {}^3C_1 \{1,2,3\}  {}^3C_1 \times {}^5C_1","['probability', 'combinatorics', 'combinations']"
26,Independent and identically distributed random variable,Independent and identically distributed random variable,,"It is my first time learning probability theory, and if I understand correctly, the following is the meaning/motivation behind the definition of a random variable: "" A function's output is uniquely determined by its input. Random variable $f$ is a function defined on a sample space of a random phenomenon. Only after a realisation of the random phenomenon, we can know what is $x$ and hence $f(x).$ Additionaly, if the function is measurable, knowing the distribution of the underlying random phenomenon(on the sample space $\Omega$ ), one can understand the probability distribution of $f(\Omega).$ Thus, the so-called measurable functions are used to model this and are referred to as random variables. Now let $f$ and $g$ two measurable functions defined on a measurable sample space $(\Omega,\mu).$ We say that $f$ and $g$ are independent random variables if the elements of sigma algebra generated by them are mutually independent. What is the motivation behind this definition. ? I understand that by independence of two events, we mean that occurrence of one does not change the  chance of occurrence of others. Also, I am looking for some explicit real-world examples of a few functions that are all defined on the same sample space $\Omega$ to better understand the following: Random variables are independent but not identically distributed. Identically distributed but not independent. Practical ones are appreciated. Thanks in advance.","It is my first time learning probability theory, and if I understand correctly, the following is the meaning/motivation behind the definition of a random variable: "" A function's output is uniquely determined by its input. Random variable is a function defined on a sample space of a random phenomenon. Only after a realisation of the random phenomenon, we can know what is and hence Additionaly, if the function is measurable, knowing the distribution of the underlying random phenomenon(on the sample space ), one can understand the probability distribution of Thus, the so-called measurable functions are used to model this and are referred to as random variables. Now let and two measurable functions defined on a measurable sample space We say that and are independent random variables if the elements of sigma algebra generated by them are mutually independent. What is the motivation behind this definition. ? I understand that by independence of two events, we mean that occurrence of one does not change the  chance of occurrence of others. Also, I am looking for some explicit real-world examples of a few functions that are all defined on the same sample space to better understand the following: Random variables are independent but not identically distributed. Identically distributed but not independent. Practical ones are appreciated. Thanks in advance.","f x f(x). \Omega f(\Omega). f g (\Omega,\mu). f g \Omega","['probability', 'probability-theory', 'random-variables']"
27,Probability of teacher being in the last room: $\frac 45$ divided by $8$,Probability of teacher being in the last room:  divided by,\frac 45 8,"A student is looking for his teacher. There is a 4/5 chance that the teacher is in one of 8 rooms, and he has no specific room preferences. Student checked 7 of the rooms, but the teacher wasn't in any of them. What's the probability that he is in one of the 8 rooms? I tried dividing the P(4/5) by 8 and getting probability of teacher being in any one room of 0.1, and then subtracting 0.1*7 from 1 to get 0.3 - probability that he is in the last room. However that's not the right answer.","A student is looking for his teacher. There is a 4/5 chance that the teacher is in one of 8 rooms, and he has no specific room preferences. Student checked 7 of the rooms, but the teacher wasn't in any of them. What's the probability that he is in one of the 8 rooms? I tried dividing the P(4/5) by 8 and getting probability of teacher being in any one room of 0.1, and then subtracting 0.1*7 from 1 to get 0.3 - probability that he is in the last room. However that's not the right answer.",,"['probability', 'discrete-mathematics']"
28,Conditional expectation of $X+Y$ given $Y-X$,Conditional expectation of  given,X+Y Y-X,"Consider the following joint density function $$f_{X,Y}(x,y)=e^{-y}$$ if $0<x<y$ and 0 in other case. If I want to find the following expectation $$E[X+Y|Y-X]$$ How do I calculate? My attempt is correct? I know that by definition $$E[X |Y]=\int x f_{X|Y}(x,Y)dx$$ So if I make the following variable change (Is allowed?) $U=X+Y$ and $V=Y-X$ then the expectation only would be $E[U|V]$ And by above definition I need to find the conditional of U given V. To do this, I try to apply the following equation $$f_{U,V}(u,v)=f_{X,Y}(x=\frac{u-v}{2},v=\frac{u+v}{2})|J|$$ Where the Jacobian is \begin{vmatrix} \frac{\partial x}{\partial u} & \frac{\partial x}{\partial v}\\ \frac{\partial y}{\partial u} & \frac{\partial y}{\partial v} \end{vmatrix} and that is $\frac{1}{2}$ So the function with new variables is $f_{U,V}(u,v)=\frac{1}{2}e^{\frac{-u-v}{2}}$ So, now we can find the conditional, $f_{U|V}=\frac{f_{U,V}(u,v)}{f_{V}(v)}$ where $f_{V}(v)=\int_{0}^{\infty} f_{U,V}(u,v)du = \int_{0}^{\infty}\frac{1}{2}e^{\frac{-u-v}{2}}du = \frac{1}{2}e^{-\frac{v}{2}}(2e^{\frac{-0}{2}})$ Is from 0 to $\infty$ because $0<U=x+y$ (is there something wrong here? Somebody told me that in this step there is an error but I don't know) Finally $$f_{U|V}=\frac{1}{2}e^{-u/2}$$ So $$E[U|V]=\int_{0}^{\infty} u\frac{1}{2}e^{-u/2}du  =\frac{1}{2}(0+2(0)e^{-\frac{0}{2}}+4e^{\frac{-0}{2}})=2$$ Please, if I do something wrong or all is wrong and there's another path to get the correct answer let me know please. Technically although I am in a course of probability, I am teaching to myself.","Consider the following joint density function if and 0 in other case. If I want to find the following expectation How do I calculate? My attempt is correct? I know that by definition So if I make the following variable change (Is allowed?) and then the expectation only would be And by above definition I need to find the conditional of U given V. To do this, I try to apply the following equation Where the Jacobian is and that is So the function with new variables is So, now we can find the conditional, where Is from 0 to because (is there something wrong here? Somebody told me that in this step there is an error but I don't know) Finally So Please, if I do something wrong or all is wrong and there's another path to get the correct answer let me know please. Technically although I am in a course of probability, I am teaching to myself.","f_{X,Y}(x,y)=e^{-y} 0<x<y E[X+Y|Y-X] E[X |Y]=\int x f_{X|Y}(x,Y)dx U=X+Y V=Y-X E[U|V] f_{U,V}(u,v)=f_{X,Y}(x=\frac{u-v}{2},v=\frac{u+v}{2})|J| \begin{vmatrix}
\frac{\partial x}{\partial u} & \frac{\partial x}{\partial v}\\
\frac{\partial y}{\partial u} & \frac{\partial y}{\partial v}
\end{vmatrix} \frac{1}{2} f_{U,V}(u,v)=\frac{1}{2}e^{\frac{-u-v}{2}} f_{U|V}=\frac{f_{U,V}(u,v)}{f_{V}(v)} f_{V}(v)=\int_{0}^{\infty} f_{U,V}(u,v)du = \int_{0}^{\infty}\frac{1}{2}e^{\frac{-u-v}{2}}du = \frac{1}{2}e^{-\frac{v}{2}}(2e^{\frac{-0}{2}}) \infty 0<U=x+y f_{U|V}=\frac{1}{2}e^{-u/2} E[U|V]=\int_{0}^{\infty} u\frac{1}{2}e^{-u/2}du  =\frac{1}{2}(0+2(0)e^{-\frac{0}{2}}+4e^{\frac{-0}{2}})=2","['probability', 'expected-value', 'conditional-expectation']"
29,"$E[X_T]$ for $T=\min\{n: \sum_{i=1}^nX_i\geq1\}$ where $X_i\sim U[0,1]$.",for  where .,"E[X_T] T=\min\{n: \sum_{i=1}^nX_i\geq1\} X_i\sim U[0,1]","Assume $X_i\overset{i.i.d}{\sim} U[0,1]$ . Let $S_n=\sum_{i=1}^nX_i$ and $T=\min\{n:S_n\geq 1\}$ . Find: (1) $E[T]$ , (2) $E[S_T]$ , (3) $E[X_T]$ For the first one, $E[T]=e$ (see e.g. this question ). For the second one we can use Wald's equation to get $E[S_T]=E[T]E[X_1]=\frac e2$ . How about the third one?","Assume . Let and . Find: (1) , (2) , (3) For the first one, (see e.g. this question ). For the second one we can use Wald's equation to get . How about the third one?","X_i\overset{i.i.d}{\sim} U[0,1] S_n=\sum_{i=1}^nX_i T=\min\{n:S_n\geq 1\} E[T] E[S_T] E[X_T] E[T]=e E[S_T]=E[T]E[X_1]=\frac e2","['probability', 'probability-theory', 'expected-value']"
30,The Birthday Paradox with combinatorics,The Birthday Paradox with combinatorics,,"Assume a year has $365$ days, how many are required to have a $50%$ chance of $2$ people having the same birthday? According to Scientific American , there are $23$ people needed to achieve the goal. $${\begin{pmatrix} 23 \\ 2\end{pmatrix}}=253$$ $$1-(1-\frac{1}{365})^{253}\approx 0.50048$$ However, I have a different approach but I'm not sure if this is correct. One could be any day in a year. And $23$ people would be $365^{23}$ possibilities. Suppose no one in $23$ people has the same birthday. That would be :- ${\begin{pmatrix} 365 \\ 23 \end{pmatrix}} \cdot23!$ The possibility of having at least 2 people having the same birthday is :- $$1-\frac{{\begin{pmatrix} 365 \\ 23 \end{pmatrix}} \cdot23!}{365^{23}}\approx0.5072972$$ Although $0.50048\approx 0.5072972$ , these two numbers are not equal to each other. Can anyone explain this difference and the reason behind this phenomenon?","Assume a year has days, how many are required to have a chance of people having the same birthday? According to Scientific American , there are people needed to achieve the goal. However, I have a different approach but I'm not sure if this is correct. One could be any day in a year. And people would be possibilities. Suppose no one in people has the same birthday. That would be :- The possibility of having at least 2 people having the same birthday is :- Although , these two numbers are not equal to each other. Can anyone explain this difference and the reason behind this phenomenon?",365 50% 2 23 {\begin{pmatrix} 23 \\ 2\end{pmatrix}}=253 1-(1-\frac{1}{365})^{253}\approx 0.50048 23 365^{23} 23 {\begin{pmatrix} 365 \\ 23 \end{pmatrix}} \cdot23! 1-\frac{{\begin{pmatrix} 365 \\ 23 \end{pmatrix}} \cdot23!}{365^{23}}\approx0.5072972 0.50048\approx 0.5072972,"['probability', 'combinatorics', 'birthday']"
31,Generate a Poisson random variable from a standard uniform random variable.,Generate a Poisson random variable from a standard uniform random variable.,,"I can't solve the following exercise: A random number generator generates random values $U \sim \text{U}(0,1)$ from the standard uniform distribution.  Use $U$ to generate a random variable $P \sim \text{Pois}(\lambda = 5)$ from a Poisson distribution with rate parameter equal to five. Comment: In previous tasks I was asked to use $U$ to generate an exponential random variable $E \sim \text{Exp}(\lambda)$ .  The solution was to take $E \equiv -\tfrac{1}{\lambda} \ln(1-U)$ . I think that this can be helpful because of the relation between Poisson distributions and exponential, but I'm not sure.","I can't solve the following exercise: A random number generator generates random values from the standard uniform distribution.  Use to generate a random variable from a Poisson distribution with rate parameter equal to five. Comment: In previous tasks I was asked to use to generate an exponential random variable .  The solution was to take . I think that this can be helpful because of the relation between Poisson distributions and exponential, but I'm not sure.","U \sim \text{U}(0,1) U P \sim \text{Pois}(\lambda = 5) U E \sim \text{Exp}(\lambda) E \equiv -\tfrac{1}{\lambda} \ln(1-U)","['probability', 'statistics']"
32,variance of maximum,variance of maximum,,"Let $(X_i)_{i\leq n}$ be random variables, which may be dependent. Is it true that \begin{align*} \text{Var}(\max X_i) \leq \sum_{i=1}^n \text{Var}(X_i). \end{align*} I have tried integrating the tail probability, \begin{align*} \text{Var}(\max X_i) &= E\left( \max X_i - E \max X_i \right)^2 \\ &= \int_0^\infty P\left((\max X_i - E \max X_j)^2 > t \right) dt \\ &\leq \int_0^\infty P\left(\bigcup_{i=1}^n \{(X_i - E \max X_j)^2 > t\} \right) dt \\ &\leq \sum_{i=1}^n \int_0^\infty P((X_i-E \max X_j)^2 > t) dt \\ &= \sum_{i=1}^n E (X_i - E \max X_j)^2, \end{align*} but this is not quite what we need. It seems that if the $X_i$ are independent, then I shouldn't have lost anything in the union bound. Does anyone know of a counter example or a proof?","Let be random variables, which may be dependent. Is it true that I have tried integrating the tail probability, but this is not quite what we need. It seems that if the are independent, then I shouldn't have lost anything in the union bound. Does anyone know of a counter example or a proof?","(X_i)_{i\leq n} \begin{align*}
\text{Var}(\max X_i) \leq \sum_{i=1}^n \text{Var}(X_i).
\end{align*} \begin{align*}
\text{Var}(\max X_i) &= E\left( \max X_i - E \max X_i \right)^2 \\
&= \int_0^\infty P\left((\max X_i - E \max X_j)^2 > t \right) dt \\
&\leq \int_0^\infty P\left(\bigcup_{i=1}^n \{(X_i - E \max X_j)^2 > t\} \right) dt \\
&\leq \sum_{i=1}^n \int_0^\infty P((X_i-E \max X_j)^2 > t) dt \\
&= \sum_{i=1}^n E (X_i - E \max X_j)^2,
\end{align*} X_i","['probability', 'probability-theory']"
33,How to determine the number of possible combinations of letters that contain a degenerate substring,How to determine the number of possible combinations of letters that contain a degenerate substring,,"I've been racking my brain for a couple of days to work out a series or closed-form equation to the following problem: Specifically: given all strings of length $N$ that draws from an alphabet of $L$ letters (starting with 'A', for example {A, B}, {A, B, C}, ...), how many of those strings contain a substring that matches the pattern: 'A', more than 1 not-'A', 'A'. The standard regular expression for that pattern would be A[^A][^A]+A . The number of possible strings is simple enough: $L^N$ . For small values of $N$ and $L$ , it's also very practical to simply create all possible combinations and use a regular expression to find the substrings that match the pattern; in R: all.combinations <- function(N, L) {     apply(         expand.grid(rep(list(LETTERS[1:L]), N)),         1,         paste,         collapse = ''     ) }  matching.pattern <- function(N, L, pattern = 'A[^A][^A]+A') {     sum(grepl(pattern, all.combinations(N, L))) }  all.combinations(4, 2) matching.pattern(4, 2) I had come up with the following, which works for N < 7: $$M(N, L) = \sum_{g=2}^{N-2} (N - g - 1) \cdot (L - 1)^g \cdot L^{(N - g -2)}$$ Unfortunately, that only works while N < 7 because it's simply adding the combinations that have substrings A..A, A...A, A....A, etc. and some combinations obviously have multiple matching substrings (e.g., A..A..A, A..A...A), which are counted twice. For example: when N = 4 and L = 2 ({A, B}), there are $L^N = 16$ possible strings: AAAA, BAAA, ABAA, BBAA, AABA, BABA, ABBA, BBBA, AAAB, BAAB, ABAB, BBAB, AABB, BABB, ABBB, BBBB . Only one of those strings matches the pattern 'A', more than 1 not-'A', 'A': ABBA . If you are familiar with regular expression syntax, the pattern is expressed as A[^A][^A]+A . When N = 4, and L = 3 ({A, B, C}), there are $L^N = 81$ possible strings, and there are 4 strings that match the pattern: ABBA, ABCA, ACBA, ACCA . When N = 6, and L = 2, there are $L^N = 64$ combinations, and 17 strings that match the pattern: ABBAAA, AABBAA, BABBAA, ABBBAA, ABBABA, AAABBA, BAABBA, ABABBA, BBABBA, AABBBA, BABBBA, ABBBBA, ABBAAB, AABBAB, BABBAB, ABBBAB, ABBABB Any suggestions? For what it is worth, here's the number of combinations, and matching combinations for some values of N and L that are tractable to determine by generating all combinations and doing a regular expression match: N  L  combinations  matching --  -  ------------  --------  4  2            16         1  5  2            32         5  6  2            64        17  7  2           128        48  8  2           256       122  9  2           512       290 10  2          1024       659  4  3            81         4  5  3           243        32  6  3           729       172  7  3          2187       760  8  3          6561      2996  9  3         19683     10960 10  3         59049     38076  4  4           256         9  5  4          1024        99  6  4          4096       729  7  4         16384      4410  8  4         65536     23778  9  4        262144    118854 10  4       1048576    563499","I've been racking my brain for a couple of days to work out a series or closed-form equation to the following problem: Specifically: given all strings of length that draws from an alphabet of letters (starting with 'A', for example {A, B}, {A, B, C}, ...), how many of those strings contain a substring that matches the pattern: 'A', more than 1 not-'A', 'A'. The standard regular expression for that pattern would be A[^A][^A]+A . The number of possible strings is simple enough: . For small values of and , it's also very practical to simply create all possible combinations and use a regular expression to find the substrings that match the pattern; in R: all.combinations <- function(N, L) {     apply(         expand.grid(rep(list(LETTERS[1:L]), N)),         1,         paste,         collapse = ''     ) }  matching.pattern <- function(N, L, pattern = 'A[^A][^A]+A') {     sum(grepl(pattern, all.combinations(N, L))) }  all.combinations(4, 2) matching.pattern(4, 2) I had come up with the following, which works for N < 7: Unfortunately, that only works while N < 7 because it's simply adding the combinations that have substrings A..A, A...A, A....A, etc. and some combinations obviously have multiple matching substrings (e.g., A..A..A, A..A...A), which are counted twice. For example: when N = 4 and L = 2 ({A, B}), there are possible strings: AAAA, BAAA, ABAA, BBAA, AABA, BABA, ABBA, BBBA, AAAB, BAAB, ABAB, BBAB, AABB, BABB, ABBB, BBBB . Only one of those strings matches the pattern 'A', more than 1 not-'A', 'A': ABBA . If you are familiar with regular expression syntax, the pattern is expressed as A[^A][^A]+A . When N = 4, and L = 3 ({A, B, C}), there are possible strings, and there are 4 strings that match the pattern: ABBA, ABCA, ACBA, ACCA . When N = 6, and L = 2, there are combinations, and 17 strings that match the pattern: ABBAAA, AABBAA, BABBAA, ABBBAA, ABBABA, AAABBA, BAABBA, ABABBA, BBABBA, AABBBA, BABBBA, ABBBBA, ABBAAB, AABBAB, BABBAB, ABBBAB, ABBABB Any suggestions? For what it is worth, here's the number of combinations, and matching combinations for some values of N and L that are tractable to determine by generating all combinations and doing a regular expression match: N  L  combinations  matching --  -  ------------  --------  4  2            16         1  5  2            32         5  6  2            64        17  7  2           128        48  8  2           256       122  9  2           512       290 10  2          1024       659  4  3            81         4  5  3           243        32  6  3           729       172  7  3          2187       760  8  3          6561      2996  9  3         19683     10960 10  3         59049     38076  4  4           256         9  5  4          1024        99  6  4          4096       729  7  4         16384      4410  8  4         65536     23778  9  4        262144    118854 10  4       1048576    563499","N L L^N N L M(N, L) = \sum_{g=2}^{N-2} (N - g - 1) \cdot (L - 1)^g \cdot L^{(N - g -2)} L^N = 16 L^N = 81 L^N = 64",['probability']
34,Singular correlation matrix implies linear dependence,Singular correlation matrix implies linear dependence,,"Given a random vector $X = \begin{bmatrix} X_1 \\ \vdots \\ X_n\end{bmatrix}$ Suppose that $R = \mathbb{E}[XX^T]$ is the correlation matrix of the random vector $X$ We claim that if $R$ is singular, then the components of $X$ must   not be linearly independent (i.e. they are linearly dependent). Does anyone see how to prove this claim? I've tried some thought experiments (e.g. when $R$ is diagonal) but I couldn't see how you would go about proving this.","Given a random vector $X = \begin{bmatrix} X_1 \\ \vdots \\ X_n\end{bmatrix}$ Suppose that $R = \mathbb{E}[XX^T]$ is the correlation matrix of the random vector $X$ We claim that if $R$ is singular, then the components of $X$ must   not be linearly independent (i.e. they are linearly dependent). Does anyone see how to prove this claim? I've tried some thought experiments (e.g. when $R$ is diagonal) but I couldn't see how you would go about proving this.",,"['probability', 'probability-theory', 'random-variables', 'expectation', 'covariance']"
35,"Probability that exactly k bins are empty, given m balls and n bins?","Probability that exactly k bins are empty, given m balls and n bins?",,"I've searched for an understandable answer to this exact question and have failed to find it. How do you find the probability that exactly $k$ bins are empty, given $m$ balls and $n$ bins? (Each ball drop is independent). The solution to this similar question does not explain how to find the probability that exactly $k$ bins are empty. It mentions the solution in passing in the comments, but does not thoroughly explain how to find the answer.","I've searched for an understandable answer to this exact question and have failed to find it. How do you find the probability that exactly $k$ bins are empty, given $m$ balls and $n$ bins? (Each ball drop is independent). The solution to this similar question does not explain how to find the probability that exactly $k$ bins are empty. It mentions the solution in passing in the comments, but does not thoroughly explain how to find the answer.",,"['probability', 'binomial-distribution', 'balls-in-bins']"
36,Infinite divisibility of bounded random variables,Infinite divisibility of bounded random variables,,"I am trying to prove that if a random variable $X$ is bounded, it cannot be infinitely divisible unless it's degenerate. My attempt: Suppose not. Let $|X| \leq B$. Since $X$ is infinitely divisible, for any integer $n \in \mathbb{N}$, there exists i.i.d random variables $X_1,\ldots,X_n$ such that $X=\sum_{i=1}^N X_i$. After this step, I think I should prove that each $X_i$ is also bounded by $B/n$ but I don't know how to prove this. Any suggestion would be appreciated.","I am trying to prove that if a random variable $X$ is bounded, it cannot be infinitely divisible unless it's degenerate. My attempt: Suppose not. Let $|X| \leq B$. Since $X$ is infinitely divisible, for any integer $n \in \mathbb{N}$, there exists i.i.d random variables $X_1,\ldots,X_n$ such that $X=\sum_{i=1}^N X_i$. After this step, I think I should prove that each $X_i$ is also bounded by $B/n$ but I don't know how to prove this. Any suggestion would be appreciated.",,"['probability', 'probability-theory']"
37,Determining probability of a normal random variable at a single point?,Determining probability of a normal random variable at a single point?,,"I tried to do this exercise from A first course in probability by Sheldon Ross: An image is partitioned into two regions, one   white and the other black. A reading taken from   a randomly chosen point in the white section will   give a reading that is normally distributed with $μ = 4$ and $σ^2 = 4$, whereas one taken from a randomly chosen point in the black region will have a normally   distributed reading with parameters $(6, 9)$.   A point is randomly chosen on the image and has   a reading of $5$. If the fraction of the image that is   black is $α$, for what value of α would the probability   of making an error be the same, regardless of   whether one concluded that the point was in the   black region or in the white region? My attempt at the problem: Let $A$ be the event that the chosen point has a reading of $5$, and $B$ that it's in the black region. We need to show that $P(B\mid A)=P(B'\mid A)$, which is equivalent to $P(B\mid A)=\frac12$. We know that $$P(B\mid A)=\frac{P(B)P(A\mid B)}{P(B)P(A\mid B)+P(B')P(A\mid B')}$$ Here is my problem. Isn't $P(A)=0$, because of the normal random variable being continuous? If so, how can I compute $P(A\mid B)$ and $P(A\mid B')$? Or maybe my whole approach is wrong?","I tried to do this exercise from A first course in probability by Sheldon Ross: An image is partitioned into two regions, one   white and the other black. A reading taken from   a randomly chosen point in the white section will   give a reading that is normally distributed with $μ = 4$ and $σ^2 = 4$, whereas one taken from a randomly chosen point in the black region will have a normally   distributed reading with parameters $(6, 9)$.   A point is randomly chosen on the image and has   a reading of $5$. If the fraction of the image that is   black is $α$, for what value of α would the probability   of making an error be the same, regardless of   whether one concluded that the point was in the   black region or in the white region? My attempt at the problem: Let $A$ be the event that the chosen point has a reading of $5$, and $B$ that it's in the black region. We need to show that $P(B\mid A)=P(B'\mid A)$, which is equivalent to $P(B\mid A)=\frac12$. We know that $$P(B\mid A)=\frac{P(B)P(A\mid B)}{P(B)P(A\mid B)+P(B')P(A\mid B')}$$ Here is my problem. Isn't $P(A)=0$, because of the normal random variable being continuous? If so, how can I compute $P(A\mid B)$ and $P(A\mid B')$? Or maybe my whole approach is wrong?",,"['probability', 'random-variables']"
38,"If A and B are independent sequences of Bernoulli trials w/ different p, what is the probability that success occurs in A before success occurs in B? [closed]","If A and B are independent sequences of Bernoulli trials w/ different p, what is the probability that success occurs in A before success occurs in B? [closed]",,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Suppose a sequence of Bernoulli trials continues until a success occurs. For two independent such sequences, say $A$ and $B$, with respective success-probabilities $a$ and $b$, what is the probability that $A$ is shorter than $B$? Here's an example of what I mean: Suppose that I have two unfair coins. Coin 1 has a probability of coming up heads of $\frac{1}{3}$, and coin 2 has a probability of coming up heads of $\frac{2}{3}$. I flip both coins at the same time. What is the probability that Coin 1 is heads before coin 2? Let $C_n$ be the number of flips it takes coin $n$ to come up heads. $P(C_1<C_2) = ?$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Suppose a sequence of Bernoulli trials continues until a success occurs. For two independent such sequences, say $A$ and $B$, with respective success-probabilities $a$ and $b$, what is the probability that $A$ is shorter than $B$? Here's an example of what I mean: Suppose that I have two unfair coins. Coin 1 has a probability of coming up heads of $\frac{1}{3}$, and coin 2 has a probability of coming up heads of $\frac{2}{3}$. I flip both coins at the same time. What is the probability that Coin 1 is heads before coin 2? Let $C_n$ be the number of flips it takes coin $n$ to come up heads. $P(C_1<C_2) = ?$",,"['probability', 'geometric-series']"
39,Why is this not a valid algorithm for counting poker hands?,Why is this not a valid algorithm for counting poker hands?,,"In my probability class, we had an example asking what is the probability of getting three of a kind when randomly drawing $5$ cards from a typical deck ($13$ denomination and $4$ suits, total of $52$ cards). Three of a kind is defines as getting three cards with the same denomination and two other cards which each have a unique denomination (looks like $AAABC$). The correct answer is as follows: 1) Choose denomination $A$, this can be done in $\binom{13}{1}$ ways 2) Choose the 3 suits for denomination $A$, this can be done in $\binom{4}{3}$ ways 3) Choose the remaining two denominations, $B$ and $C$, this can be done in $\binom{12}{2}$ ways 4) Choose the suits for the remaining two denominations, this can be done in $\binom{4}{1}$ ways for each So the probability of getting three of a kind is: $$\frac {\binom{13}{1}\binom{4}{3}\binom{12}{2}\binom{4}{1}\binom{4}{1}}{\binom{52}{5}} \approx 0.02112845$$ Now my solution is mostly the same, however when selecting the denominations $B$ and $C$ I say that this can be done by selecting denomination $B$ in $\binom{12}{1}$ ways with $\binom{4}{1}$ possible suits. Then selecting denomination $C$ from the remaining $11$ denominations for any $4$ suits, so my answer is: $$\frac {\binom{13}{1}\binom{4}{3}\binom{12}{1}\binom{4}{1}\binom{11}{1}\binom{4}{1}}{\binom{52}{5}} \approx 0.0422569$$ which turns out to be exactly double the answer above, this comes from the fact that $\binom{12}{1}\binom{11}{1}=2\binom{12}{2}$. My question is, which solution is correct and why? To me they both seem like valid solutions. Am I double counting certain hands?","In my probability class, we had an example asking what is the probability of getting three of a kind when randomly drawing $5$ cards from a typical deck ($13$ denomination and $4$ suits, total of $52$ cards). Three of a kind is defines as getting three cards with the same denomination and two other cards which each have a unique denomination (looks like $AAABC$). The correct answer is as follows: 1) Choose denomination $A$, this can be done in $\binom{13}{1}$ ways 2) Choose the 3 suits for denomination $A$, this can be done in $\binom{4}{3}$ ways 3) Choose the remaining two denominations, $B$ and $C$, this can be done in $\binom{12}{2}$ ways 4) Choose the suits for the remaining two denominations, this can be done in $\binom{4}{1}$ ways for each So the probability of getting three of a kind is: $$\frac {\binom{13}{1}\binom{4}{3}\binom{12}{2}\binom{4}{1}\binom{4}{1}}{\binom{52}{5}} \approx 0.02112845$$ Now my solution is mostly the same, however when selecting the denominations $B$ and $C$ I say that this can be done by selecting denomination $B$ in $\binom{12}{1}$ ways with $\binom{4}{1}$ possible suits. Then selecting denomination $C$ from the remaining $11$ denominations for any $4$ suits, so my answer is: $$\frac {\binom{13}{1}\binom{4}{3}\binom{12}{1}\binom{4}{1}\binom{11}{1}\binom{4}{1}}{\binom{52}{5}} \approx 0.0422569$$ which turns out to be exactly double the answer above, this comes from the fact that $\binom{12}{1}\binom{11}{1}=2\binom{12}{2}$. My question is, which solution is correct and why? To me they both seem like valid solutions. Am I double counting certain hands?",,"['probability', 'poker']"
40,joint distribution of x with..itself,joint distribution of x with..itself,,"I have a weird question about probability and density functions :  Let's take a random variable X whose p.d.f exists and let's denote it $f_{X}\left(x\right)$. Does the definition of the joint probability $f_{X,X}\left(x,x\right)$ exist ? clearly it's not continuous but i wanted to ""check"" that the marginal of X ($f_{X}\left(x\right)$) would be the integral of this joint distribution... Can you give me more insight about it? thanks, Romain","I have a weird question about probability and density functions :  Let's take a random variable X whose p.d.f exists and let's denote it $f_{X}\left(x\right)$. Does the definition of the joint probability $f_{X,X}\left(x,x\right)$ exist ? clearly it's not continuous but i wanted to ""check"" that the marginal of X ($f_{X}\left(x\right)$) would be the integral of this joint distribution... Can you give me more insight about it? thanks, Romain",,"['probability', 'functions']"
41,Car parking related probability,Car parking related probability,,A driver parks a car in a row of $25$ cars randomly at any place but not ends. After coming back he finds $10$ cars are gone so what is the probability that both the neighbouring cars have gone? What I did $$\dfrac{{24\choose 8}}{{23\choose 1}{24\choose 10}}$$  $24C8$ as we want two cars to go so we want to select only $8$ cars. And driver can park in $23$ ways and cars can go in $24C10$ ways. But that doesn't yield the answer what am I missing on? Please any hints using basic probability equations.,A driver parks a car in a row of $25$ cars randomly at any place but not ends. After coming back he finds $10$ cars are gone so what is the probability that both the neighbouring cars have gone? What I did $$\dfrac{{24\choose 8}}{{23\choose 1}{24\choose 10}}$$  $24C8$ as we want two cars to go so we want to select only $8$ cars. And driver can park in $23$ ways and cars can go in $24C10$ ways. But that doesn't yield the answer what am I missing on? Please any hints using basic probability equations.,,"['probability', 'combinatorics']"
42,Derivation of multivariate transformation of random variables,Derivation of multivariate transformation of random variables,,"I encounter the formula for transformation of random variables and I would like to try to derive it: Given random variables $X_1$ and $X_2$, we have $Y_1 = u(X_1, X_2)$ and $Y_2 = v(X_1, X_2)$, then the pdf wrt Ys is: $f_{Y_1,Y_2}(y_1, y_2) = \frac{1}{{|J(x_1,x_2})|}f_{X_1,X_2}(x_1, x_2)$ I know that $\iint{f(x_1,x_2)dx_1dx_2} = \iint{f(u^{-1}(y_1),v^{-1}(y_2))J(y_1,y_2)dy_1dy_2}$, but I can't seem to proceed from there. Probability textbooks tell me to refer to a text on calculus for the formula, but I can't find any text that proves this probabilistic modification of the formula. Please shed some light.","I encounter the formula for transformation of random variables and I would like to try to derive it: Given random variables $X_1$ and $X_2$, we have $Y_1 = u(X_1, X_2)$ and $Y_2 = v(X_1, X_2)$, then the pdf wrt Ys is: $f_{Y_1,Y_2}(y_1, y_2) = \frac{1}{{|J(x_1,x_2})|}f_{X_1,X_2}(x_1, x_2)$ I know that $\iint{f(x_1,x_2)dx_1dx_2} = \iint{f(u^{-1}(y_1),v^{-1}(y_2))J(y_1,y_2)dy_1dy_2}$, but I can't seem to proceed from there. Probability textbooks tell me to refer to a text on calculus for the formula, but I can't find any text that proves this probabilistic modification of the formula. Please shed some light.",,"['probability', 'multivariable-calculus']"
43,Mean and Variance both equal to $\lambda$ for a Poisson Distribution,Mean and Variance both equal to  for a Poisson Distribution,\lambda,"Given a Poisson distributed random variable with parameter $\lambda$ that take the values $0,1,\ldots$ Show that mean and variance both equal to $\lambda$. I differentiated the Taylor series and then tried to proved but I am not able to figure it out. I am stuck what to do after differentiation. Please help me. How to solve this question?","Given a Poisson distributed random variable with parameter $\lambda$ that take the values $0,1,\ldots$ Show that mean and variance both equal to $\lambda$. I differentiated the Taylor series and then tried to proved but I am not able to figure it out. I am stuck what to do after differentiation. Please help me. How to solve this question?",,"['probability', 'probability-distributions', 'poisson-distribution']"
44,Probability of winning a game of craps,Probability of winning a game of craps,,"The dice game craps is played as follows: The player throws 2 dice, and if the sum is 7 or 11, he/she wins. If the sum is 2, 3, or 12, he/she loses. If the sum is anything else, then he/she continues throwing until that number appears again, or throws a 7, where the game ends in a loss. What I do know is that $P(7) = 6/36$, $P(11)=2/36$. So P(winning) in first roll is $8/36$. Furthermore, the probability of having to roll again will be $1-[P($winning 1st roll$) +P($losing 1st roll$)]=24/36$. It's what happens if the game doesn't end in the 1st roll that's got me a bit confused, since it could go on and indeterminate number of rolls. But since it can't be 7,11,2,3,or 12, it depends on if they roll a 4,5,6,8,9, or 10. Note, this is not a homework problem, but an intriguing one I found in a different book ""Probability Models, Sheldon Ross""","The dice game craps is played as follows: The player throws 2 dice, and if the sum is 7 or 11, he/she wins. If the sum is 2, 3, or 12, he/she loses. If the sum is anything else, then he/she continues throwing until that number appears again, or throws a 7, where the game ends in a loss. What I do know is that $P(7) = 6/36$, $P(11)=2/36$. So P(winning) in first roll is $8/36$. Furthermore, the probability of having to roll again will be $1-[P($winning 1st roll$) +P($losing 1st roll$)]=24/36$. It's what happens if the game doesn't end in the 1st roll that's got me a bit confused, since it could go on and indeterminate number of rolls. But since it can't be 7,11,2,3,or 12, it depends on if they roll a 4,5,6,8,9, or 10. Note, this is not a homework problem, but an intriguing one I found in a different book ""Probability Models, Sheldon Ross""",,"['probability', 'dice', 'gambling']"
45,What is the average number of draws (2 cards per draw with shuffles in between) before I had seen all 52 cards in the deck?,What is the average number of draws (2 cards per draw with shuffles in between) before I had seen all 52 cards in the deck?,,"On average, how many times would I have to draw two cards from a deck (replacing  and shuffling between each draw) before I had seen each of 52 cards in the deck? The process is: Draw the top two cards of a shuffled deck and note their face values. Place those two cards back in the deck and shuffle. Draw the top two cards and note their values Statistically, how may times would I have to repeat that process until I had noted every card in the deck?","On average, how many times would I have to draw two cards from a deck (replacing  and shuffling between each draw) before I had seen each of 52 cards in the deck? The process is: Draw the top two cards of a shuffled deck and note their face values. Place those two cards back in the deck and shuffle. Draw the top two cards and note their values Statistically, how may times would I have to repeat that process until I had noted every card in the deck?",,"['probability', 'expectation']"
46,How many ways to arrange the flags?,How many ways to arrange the flags?,,"There are two distinguishable flagpoles, and there are $19$ flags, of which $10$ are identical blue flags, and $9$ are identical green flags. Let $N$ be the number of distinguishable arrangements using all of the flags in which each flagpole has at least one flag and no two green flags on either pole are adjacent. Find the remainder when $N$ is divided by $1000$. This is a tricky problem to be honest. Let $|$ distinguish the two flagpoles. I tried arranging it as: $$G B GBGBGB | BGBGBGBGBGB$$ $$G G G GB | BGGGGGB$$ There are:  $\binom{12}{3} = 220$ to arrange the blue/green. Then multiply by $11$ because of the divider of the poles. $$= 220(11) = 2420$$ And this multiplication by $11$ takes care of the at least one flag on pole condition. Then why is this the wrong answer?","There are two distinguishable flagpoles, and there are $19$ flags, of which $10$ are identical blue flags, and $9$ are identical green flags. Let $N$ be the number of distinguishable arrangements using all of the flags in which each flagpole has at least one flag and no two green flags on either pole are adjacent. Find the remainder when $N$ is divided by $1000$. This is a tricky problem to be honest. Let $|$ distinguish the two flagpoles. I tried arranging it as: $$G B GBGBGB | BGBGBGBGBGB$$ $$G G G GB | BGGGGGB$$ There are:  $\binom{12}{3} = 220$ to arrange the blue/green. Then multiply by $11$ because of the divider of the poles. $$= 220(11) = 2420$$ And this multiplication by $11$ takes care of the at least one flag on pole condition. Then why is this the wrong answer?",,"['probability', 'combinatorics', 'algebra-precalculus', 'elementary-number-theory', 'contest-math']"
47,How to prove it is a strictly stationary process?,How to prove it is a strictly stationary process?,,"$ξ(t) = z*sin(ωt + θ)$ where $z$ is a random variable and its distribution is unknown and $θ$ is another random variable that is independent of $z$ and $θ$ is uniformly distributed on $(0, 2\pi)$. Besides, $ω$ is a constant greater than $0$. I've been asked to show $ξ(t)$ is a strictly stationary stochastic process using characteristic function or say $E(e^{jvξ(t)})$. I've tried but it seems that $E(e^{jvξ(t)})$ depends on the $t$ I choose, which means it is not a strictly stationary stochastic process. I think my answer can be wrong and how to prove it? One more question: I've got quite confused why a characteristic function of a stochastic process can be used to prove property of strictly stationary? The definition of strictly stationary is $F_ξ(x_1, x_2, x_3,..., x_n; t_1, t_2, t_3,...,t_n) = F_ξ(x_1, x_2, x_3,..., x_n; t_1 + τ, t_2 + τ, t_3 + τ,...,t_n + τ)$ where capital $F$ denotes the probability distribution function(PDF) of ξ(t). My book never told me anything about relationship between characteristic function of a stochastic process and its PDF. So when this problem appeared, I think they want me to show $E(e^{jvξ(t)})$ does not depend on $t$ while forget to tell me why not depending on $t$ imply its strictly stationary?","$ξ(t) = z*sin(ωt + θ)$ where $z$ is a random variable and its distribution is unknown and $θ$ is another random variable that is independent of $z$ and $θ$ is uniformly distributed on $(0, 2\pi)$. Besides, $ω$ is a constant greater than $0$. I've been asked to show $ξ(t)$ is a strictly stationary stochastic process using characteristic function or say $E(e^{jvξ(t)})$. I've tried but it seems that $E(e^{jvξ(t)})$ depends on the $t$ I choose, which means it is not a strictly stationary stochastic process. I think my answer can be wrong and how to prove it? One more question: I've got quite confused why a characteristic function of a stochastic process can be used to prove property of strictly stationary? The definition of strictly stationary is $F_ξ(x_1, x_2, x_3,..., x_n; t_1, t_2, t_3,...,t_n) = F_ξ(x_1, x_2, x_3,..., x_n; t_1 + τ, t_2 + τ, t_3 + τ,...,t_n + τ)$ where capital $F$ denotes the probability distribution function(PDF) of ξ(t). My book never told me anything about relationship between characteristic function of a stochastic process and its PDF. So when this problem appeared, I think they want me to show $E(e^{jvξ(t)})$ does not depend on $t$ while forget to tell me why not depending on $t$ imply its strictly stationary?",,"['probability', 'statistics', 'stochastic-processes', 'random-variables']"
48,Find the distribution of linear combination of independent random variables,Find the distribution of linear combination of independent random variables,,"Given independent and identically distributed random variables $X_1, X_2, \dots, X_n$, each of them has the same p.d.f $f(x) = Pr(X = x)$ on support $(a, b)$. How do I find the pdf or cdf of $Y = \sum_{i = 1}^n a_iX_i$, where $1 \le i \le n$ and $a_i$'s are constants?","Given independent and identically distributed random variables $X_1, X_2, \dots, X_n$, each of them has the same p.d.f $f(x) = Pr(X = x)$ on support $(a, b)$. How do I find the pdf or cdf of $Y = \sum_{i = 1}^n a_iX_i$, where $1 \le i \le n$ and $a_i$'s are constants?",,"['probability', 'statistics', 'probability-distributions']"
49,Help with understanding an example from the book 'Fooled by Randomness',Help with understanding an example from the book 'Fooled by Randomness',,"This is an example from the book ""Fooled by Randomness"": (...)We know a priori that he is an excellent investor, and that he will be expected to earn a return of 15% in excess of Treasury bills, with a 10% error rate per annum (what we call volatility). It means that out of 100 sample paths, we expect close to 68 of them to fall within a band of plus and minus 10% around the 15% excess return, i.e., between 5% and 25% (to be technical; the bell-shaped normal distribution has 68% of all observations falling between -1 and 1 standard deviations). It also means that 95 sample paths would fall between -5% and 35%. A 15% return with a 10% volatility (or uncertainty) per annum translates into a 93% probability of success in any given year. But seen at a narrow time scale, this translates into a mere 50.02% probability of success over any given second. Table 3.1 Probability of success at different scales Scale      Probability 1 year     93% 1 quarter  77% 1 month    67% 1 day      54% 1 hour     51.3% 1 minute   50.17% 1 second   50.02% How do I calculate the probability of success at different scales (Table 3.1)? E.g. where does 77% for a quarter come from?","This is an example from the book ""Fooled by Randomness"": (...)We know a priori that he is an excellent investor, and that he will be expected to earn a return of 15% in excess of Treasury bills, with a 10% error rate per annum (what we call volatility). It means that out of 100 sample paths, we expect close to 68 of them to fall within a band of plus and minus 10% around the 15% excess return, i.e., between 5% and 25% (to be technical; the bell-shaped normal distribution has 68% of all observations falling between -1 and 1 standard deviations). It also means that 95 sample paths would fall between -5% and 35%. A 15% return with a 10% volatility (or uncertainty) per annum translates into a 93% probability of success in any given year. But seen at a narrow time scale, this translates into a mere 50.02% probability of success over any given second. Table 3.1 Probability of success at different scales Scale      Probability 1 year     93% 1 quarter  77% 1 month    67% 1 day      54% 1 hour     51.3% 1 minute   50.17% 1 second   50.02% How do I calculate the probability of success at different scales (Table 3.1)? E.g. where does 77% for a quarter come from?",,"['probability', 'probability-distributions']"
50,Claim from an Actuarial Textbook: limits imply the existence of mean and variance,Claim from an Actuarial Textbook: limits imply the existence of mean and variance,,"This is from Actuarial Mathematics for Life Contingent Risks , 2nd ed., by Dickson et al. Some definitions (not directly from the book): Definitions/Notation . $T_x$ is defined to be the future lifetime of a life age $x \geq 0$ . We also define the cumulative distribution function of $T_x$ , denoted either $F_{T_x}$ or $F_x$ , as $$F_{T_x}(t) = F_{x}(t) = \mathbb{P}\{T_x \leq t\}\text{.}$$ The survival function of $T_x$ , denoted $S_x$ , is defined as $$S_{x}(t) = 1 - F_{x}(t)\text{.}$$ It should also make sense that $T_x$ takes on only nonnegative values; i.e., $T_x \geq 0$ . So, of course, $$\mathbb{E}\left[T_x\right] = \int\limits_{0}^{\infty}tf_{x}(t)\text{ d}t$$ where $f_{x}$ is the probability density function of $T_x$ . Throughout this textbook, it is assumed that $S_{x}$ is differentiable for all $t > 0$ . The text also makes the following assumptions: Assumption 2.2 : $\lim_{t \to \infty}tS_{x}(t) = 0$ Assumption 2.3 : $\lim_{t \to \infty}t^2S_{x}(t) = 0$ ""These last two assumptions ensure that the mean and variance of the distribution of $T_x$ exist."" Now here's the main question : why is this true ? I can no longer find where I asked this before, but I recall that the converse is actually true (i.e., what the authors are stating here is indeed false), but never was able to find justification for why . I also know for a fact that IF $\mathbb{E}[T_x]$ exists that $$\mathbb{E}[T_x] = \int_{0}^{\infty}S_{x}(t) \text{ d}t\text{,}$$ but this is of course, not helpful, since it assumes that $\mathbb{E}[T_x]$ exists to begin with. FYI: I am including probability-theory in this question in case we need tools from measure-theoretic probability to solve this question. Unfortunately, I don't know the topic very well.","This is from Actuarial Mathematics for Life Contingent Risks , 2nd ed., by Dickson et al. Some definitions (not directly from the book): Definitions/Notation . is defined to be the future lifetime of a life age . We also define the cumulative distribution function of , denoted either or , as The survival function of , denoted , is defined as It should also make sense that takes on only nonnegative values; i.e., . So, of course, where is the probability density function of . Throughout this textbook, it is assumed that is differentiable for all . The text also makes the following assumptions: Assumption 2.2 : Assumption 2.3 : ""These last two assumptions ensure that the mean and variance of the distribution of exist."" Now here's the main question : why is this true ? I can no longer find where I asked this before, but I recall that the converse is actually true (i.e., what the authors are stating here is indeed false), but never was able to find justification for why . I also know for a fact that IF exists that but this is of course, not helpful, since it assumes that exists to begin with. FYI: I am including probability-theory in this question in case we need tools from measure-theoretic probability to solve this question. Unfortunately, I don't know the topic very well.","T_x x \geq 0 T_x F_{T_x} F_x F_{T_x}(t) = F_{x}(t) = \mathbb{P}\{T_x \leq t\}\text{.} T_x S_x S_{x}(t) = 1 - F_{x}(t)\text{.} T_x T_x \geq 0 \mathbb{E}\left[T_x\right] = \int\limits_{0}^{\infty}tf_{x}(t)\text{ d}t f_{x} T_x S_{x} t > 0 \lim_{t \to \infty}tS_{x}(t) = 0 \lim_{t \to \infty}t^2S_{x}(t) = 0 T_x \mathbb{E}[T_x] \mathbb{E}[T_x] = \int_{0}^{\infty}S_{x}(t) \text{ d}t\text{,} \mathbb{E}[T_x]","['probability', 'probability-theory', 'actuarial-science']"
51,Finding variance of the sample mean of a random sample of size n without replacement from finite population of size N.,Finding variance of the sample mean of a random sample of size n without replacement from finite population of size N.,,"I encountered this problem in the book ""Introduction to the Theory of Statistics"" (by Mood, Graybill and Boes) and I have not been able to solve part (c): ""A bowl contains five chips numbered from 1 to 5. A sample of two drawn without replacement from this finite population is said to be random if all possible pairs of the five chips have an equal chance to be drawn. (a) What is the expected value of the sample mean? What is the variance of the sample mean? (b) Suppose that the two chips of part (a) were drawn with replacement. What would be the variance of the sample mean? Why might one guess that this variance would be larger than the one obtained before? (c) Generalize part (a) by considering N chips and samples of size n. Show that the variance of the sample mean is $$\frac{N-n}{N-1}\frac{\sigma^{2}}{n}$$ where $\sigma^{2}$ is the population variance, that is $$\sigma^{2}=\frac{1}{N}\sum_{i=1}^{N}\Big(i-\frac{N+1}{2}\Big)^{2}$$"" * To solve part (a) I explicitly wrote the set of possible pairs with equal probability: $\Omega=\{(1,2),(1,3),(1,4),(1,5),(2,3),(2,4),(2,5),(3,4),(3,5),(4,5)\}$ From this it is easy to see that $Im\bar{X}=\{1.5,2,2.5,3,3.5,4,4.5\}$ where $\bar{X}=\frac{1}{n}\sum_{i=1}^{n} X_{i}$ Correspondingly the probabilities for this values are $(0.1,0.1,0.2,0.2,0.2,0.1,0.1)$ Hence, by definition, the expected value and the variance are: $E[\bar{X}]=3$ and $V[\bar{X}]=\frac{3}{4}$. * For part (b) the same procedure gives us $E[\bar{X}]=3$ and $V[\bar{X}]=\frac{7}{6}$. * Finally, for part (c) I tried to generalize what I did noticing that the least value for $\sum X_{i}$ is $\frac{n(n+1)}{2}$ and its greatest possible value is $\frac{n(2N-n+1)}{2}$. Hence $Im\bar{X}=\{\frac{n+1}{2},\frac{n+1}{2}+\frac{1}{n},\frac{n+1}{2}+\frac{2}{n},\dots,\frac{n+1}{2}+(N-n)\}$ Clearly the probability for the first and last values is $\frac{1}{C^{N}_{n}}=\frac{n!(N-n)!}{N!}$ but I haven't come up with an idea of how to find the other probabilities. How can I get the rest of them?","I encountered this problem in the book ""Introduction to the Theory of Statistics"" (by Mood, Graybill and Boes) and I have not been able to solve part (c): ""A bowl contains five chips numbered from 1 to 5. A sample of two drawn without replacement from this finite population is said to be random if all possible pairs of the five chips have an equal chance to be drawn. (a) What is the expected value of the sample mean? What is the variance of the sample mean? (b) Suppose that the two chips of part (a) were drawn with replacement. What would be the variance of the sample mean? Why might one guess that this variance would be larger than the one obtained before? (c) Generalize part (a) by considering N chips and samples of size n. Show that the variance of the sample mean is $$\frac{N-n}{N-1}\frac{\sigma^{2}}{n}$$ where $\sigma^{2}$ is the population variance, that is $$\sigma^{2}=\frac{1}{N}\sum_{i=1}^{N}\Big(i-\frac{N+1}{2}\Big)^{2}$$"" * To solve part (a) I explicitly wrote the set of possible pairs with equal probability: $\Omega=\{(1,2),(1,3),(1,4),(1,5),(2,3),(2,4),(2,5),(3,4),(3,5),(4,5)\}$ From this it is easy to see that $Im\bar{X}=\{1.5,2,2.5,3,3.5,4,4.5\}$ where $\bar{X}=\frac{1}{n}\sum_{i=1}^{n} X_{i}$ Correspondingly the probabilities for this values are $(0.1,0.1,0.2,0.2,0.2,0.1,0.1)$ Hence, by definition, the expected value and the variance are: $E[\bar{X}]=3$ and $V[\bar{X}]=\frac{3}{4}$. * For part (b) the same procedure gives us $E[\bar{X}]=3$ and $V[\bar{X}]=\frac{7}{6}$. * Finally, for part (c) I tried to generalize what I did noticing that the least value for $\sum X_{i}$ is $\frac{n(n+1)}{2}$ and its greatest possible value is $\frac{n(2N-n+1)}{2}$. Hence $Im\bar{X}=\{\frac{n+1}{2},\frac{n+1}{2}+\frac{1}{n},\frac{n+1}{2}+\frac{2}{n},\dots,\frac{n+1}{2}+(N-n)\}$ Clearly the probability for the first and last values is $\frac{1}{C^{N}_{n}}=\frac{n!(N-n)!}{N!}$ but I haven't come up with an idea of how to find the other probabilities. How can I get the rest of them?",,"['probability', 'statistics']"
52,Birthday problem: Let X be number of people needed for a match. Find the PMF of X.,Birthday problem: Let X be number of people needed for a match. Find the PMF of X.,,"People are arriving at a party one at a time. While waiting for more people to arrive they entertain themselves by comparing their birthdays. Let X be the number of people needed to obtain a birthday match, i.e., before person X arrives there are no two people with the same birthday, but when person X arrives there is a match. Find the PMF of X. (Introduction to Probability, Blitzstein and Hwang, p.128) The CDF is $P(X\leq k) = 1 - \frac{\binom{365}{k}k!}{365^k}$ , so the PMF can be obtained by: \begin{align} \\ P(X=k) &= P(X\leq k) - P(X\leq k-1)\\\\ &= \left( 1 - \frac{\binom{365}{k}k!}{365^k} \right) - \left( 1 - \frac{\binom{365}{k-1}(k-1)!}{365^{k-1}} \right) \\\\ &= \frac{(k-1)}{365^k} \binom{365}{k-1}  (k-1)! \\\\ &=(k-1)*\left(1-P(X \leq k-1 \right)) \\\\ &= (k-1) * P(X > k-1) \end{align} Is this correct? How do you interpret the results? How to arrive at the PMF without using the CDF?","People are arriving at a party one at a time. While waiting for more people to arrive they entertain themselves by comparing their birthdays. Let X be the number of people needed to obtain a birthday match, i.e., before person X arrives there are no two people with the same birthday, but when person X arrives there is a match. Find the PMF of X. (Introduction to Probability, Blitzstein and Hwang, p.128) The CDF is , so the PMF can be obtained by: Is this correct? How do you interpret the results? How to arrive at the PMF without using the CDF?","P(X\leq k) = 1 - \frac{\binom{365}{k}k!}{365^k} \begin{align}
\\
P(X=k) &= P(X\leq k) - P(X\leq k-1)\\\\
&= \left( 1 - \frac{\binom{365}{k}k!}{365^k} \right) - \left( 1 - \frac{\binom{365}{k-1}(k-1)!}{365^{k-1}} \right) \\\\
&= \frac{(k-1)}{365^k} \binom{365}{k-1}  (k-1)! \\\\
&=(k-1)*\left(1-P(X \leq k-1 \right)) \\\\
&= (k-1) * P(X > k-1)
\end{align}","['probability', 'combinatorics']"
53,Probability that a cow is black given that I've observed at least one side is black,Probability that a cow is black given that I've observed at least one side is black,,"I'm on a farm with six cows; three are white, two are black and one is completely black on one side and completely white on the other. I see one cow from the side, who appears to be black (that is, the side that I see is black). What's the probability that the cow is black? I tried to figure out a solution, but it's wrong as it conflicts with the solution I'm given. I don't understand completely what I'm missing and where I'm going wrong, so I would appreciate some advice which would lead me in the right direction. Let $P$ be the event that the cow I observe is completely black, and $S$ be the event that at least one side is black. $S$ is given, so I need to find $P(B|S)$. $P(B|S) = \frac{P(S|B)P(B)}{P(S)}$ $P(S|B) = 1$, since if the entire cow is black then at least one side is black. $P(B) = \frac{1}{3}$ since there are two black cows among a group of six. And $P(S) = \frac{1}{2}$ since there are three out of six cows with at least one black side. so $P(B|S) = \frac{P(B)}{P(S)} = \frac{2}{3}$ However the answer I'm given is $\frac{4}{5}$","I'm on a farm with six cows; three are white, two are black and one is completely black on one side and completely white on the other. I see one cow from the side, who appears to be black (that is, the side that I see is black). What's the probability that the cow is black? I tried to figure out a solution, but it's wrong as it conflicts with the solution I'm given. I don't understand completely what I'm missing and where I'm going wrong, so I would appreciate some advice which would lead me in the right direction. Let $P$ be the event that the cow I observe is completely black, and $S$ be the event that at least one side is black. $S$ is given, so I need to find $P(B|S)$. $P(B|S) = \frac{P(S|B)P(B)}{P(S)}$ $P(S|B) = 1$, since if the entire cow is black then at least one side is black. $P(B) = \frac{1}{3}$ since there are two black cows among a group of six. And $P(S) = \frac{1}{2}$ since there are three out of six cows with at least one black side. so $P(B|S) = \frac{P(B)}{P(S)} = \frac{2}{3}$ However the answer I'm given is $\frac{4}{5}$",,"['probability', 'bayes-theorem']"
54,"What is the probability that a number chosen at random in $[0,1]$ is transcendental?",What is the probability that a number chosen at random in  is transcendental?,"[0,1]","Consider the interval $[0,1]$. What is the probability that a number chosen at random in $[0,1]$ is transcendental? Please give me some points on how to start this problem.","Consider the interval $[0,1]$. What is the probability that a number chosen at random in $[0,1]$ is transcendental? Please give me some points on how to start this problem.",,"['probability', 'transcendental-numbers']"
55,What is the probability of two out of three events happening?,What is the probability of two out of three events happening?,,"All events are independent. $$\Pr(A) = \frac{9}{10}$$ $$\Pr(B) = \frac{9}{10}$$ $$\Pr(C) = \frac{6}{10}$$ What is the probability of at least two events happening? I'd like to use negation, to negate the possibility that event no event happen plus the probability that only one happens. $$D = \text{at least two events happen}$$ $$\Pr(D) = 1-\Pr(\text{none happens})-\Pr(\text{exactly one happens})$$ $$\Pr(D) = 1 - \left(\frac{1}{10}\cdot \frac{1}{10}\cdot\frac{4}{10}\right) - \left(\frac{1}{10}\cdot\frac{6}{10}\cdot\frac{1}{10} + \frac{9}{10}\cdot\frac{1}{10}\cdot\frac{4}{10} + \frac{9}{10}\cdot\frac{1}{10}\cdot\frac{4}{10}\right) = 0.918$$ The answer seems a little larger, I can't convince myself that I'm right.","All events are independent. $$\Pr(A) = \frac{9}{10}$$ $$\Pr(B) = \frac{9}{10}$$ $$\Pr(C) = \frac{6}{10}$$ What is the probability of at least two events happening? I'd like to use negation, to negate the possibility that event no event happen plus the probability that only one happens. $$D = \text{at least two events happen}$$ $$\Pr(D) = 1-\Pr(\text{none happens})-\Pr(\text{exactly one happens})$$ $$\Pr(D) = 1 - \left(\frac{1}{10}\cdot \frac{1}{10}\cdot\frac{4}{10}\right) - \left(\frac{1}{10}\cdot\frac{6}{10}\cdot\frac{1}{10} + \frac{9}{10}\cdot\frac{1}{10}\cdot\frac{4}{10} + \frac{9}{10}\cdot\frac{1}{10}\cdot\frac{4}{10}\right) = 0.918$$ The answer seems a little larger, I can't convince myself that I'm right.",,['probability']
56,Expected value equal to expected value of expected value squared?,Expected value equal to expected value of expected value squared?,,"I am trying to rederive the canonical expression for variance $V[X] = E[X^2] - E[X]^2$ . What I don't understand is the second line. If you multiply E( ... ) by the last term, wouldn't you get $E(E[X]^2)$ ? Is $E(E[X]^2) = E[X]^2$ ? $E(E[X]^2) = E[X]^2$","I am trying to rederive the canonical expression for variance . What I don't understand is the second line. If you multiply E( ... ) by the last term, wouldn't you get ? Is ?",V[X] = E[X^2] - E[X]^2 E(E[X]^2) E(E[X]^2) = E[X]^2 E(E[X]^2) = E[X]^2,"['probability', 'statistics']"
57,What is the expected value of A?,What is the expected value of A?,,"The Happy Animals Kennel has 18 cages in a row. They allocate these cages at random to 6 dogs, 6 cats, and 6 pot-bellied pigs (with one animal per cage). All arrangements are equally likely. Let A be the number of times in the row of cages that two animals of the same species are adjacent. For example, in the arrangement DCPCDPPPDCDPCDCCPD (where D=dog, C=cat, and P=pig), we have A=3. What is the expected value of A? (not sure if expectation is the correct tag here)","The Happy Animals Kennel has 18 cages in a row. They allocate these cages at random to 6 dogs, 6 cats, and 6 pot-bellied pigs (with one animal per cage). All arrangements are equally likely. Let A be the number of times in the row of cages that two animals of the same species are adjacent. For example, in the arrangement DCPCDPPPDCDPCDCCPD (where D=dog, C=cat, and P=pig), we have A=3. What is the expected value of A? (not sure if expectation is the correct tag here)",,['probability']
58,Chance of marrying a girl,Chance of marrying a girl,,"My girlfriend's father has a magic - fair - coin, he agrees to let me marry his daughter if I play his game: I have to toss the coin couple times until I see the head comes up. Then if the number of times I have tossed is divisible by three, I cannot marry his daughter, otherwise I can marry his daughter. What is the possibility that I can marry my girlfriend? Suppose $0 < \alpha < 1$; can you design a game like this, such that the probability of winning is $\alpha$? Your game still requires the player to toss the coin but you are allow to change when is pass/no pass case. ($\alpha\in\mathbb{Q})$ This is a really good and interesting question but I cannot solve it. Can you please help?","My girlfriend's father has a magic - fair - coin, he agrees to let me marry his daughter if I play his game: I have to toss the coin couple times until I see the head comes up. Then if the number of times I have tossed is divisible by three, I cannot marry his daughter, otherwise I can marry his daughter. What is the possibility that I can marry my girlfriend? Suppose $0 < \alpha < 1$; can you design a game like this, such that the probability of winning is $\alpha$? Your game still requires the player to toss the coin but you are allow to change when is pass/no pass case. ($\alpha\in\mathbb{Q})$ This is a really good and interesting question but I cannot solve it. Can you please help?",,"['probability', 'probability-theory', 'conditional-probability']"
59,What is the probability of exactly two out of n persons sharing a birthday?,What is the probability of exactly two out of n persons sharing a birthday?,,The classical Birthday problem asks for the probability of at least two out of $n$ people sharing the same birthday or sometimes for the least amount $n$ of people required such that with a probability of 50% at least two of them share their birthday. But what about the question how probable it is that also no more than two people share their birthday?,The classical Birthday problem asks for the probability of at least two out of $n$ people sharing the same birthday or sometimes for the least amount $n$ of people required such that with a probability of 50% at least two of them share their birthday. But what about the question how probable it is that also no more than two people share their birthday?,,['probability']
60,Interview Puzzle,Interview Puzzle,,"Suppose $5$ blue points and $5$ red points are selected in the interval $[0,1]$. What is the probability that the points will interleave each other? Interleave as in one blue point followed by one red point and so on or one red point followed by a blue point and so on. Any tips for solving such problems is highly appreciated. Thanks in advance.","Suppose $5$ blue points and $5$ red points are selected in the interval $[0,1]$. What is the probability that the points will interleave each other? Interleave as in one blue point followed by one red point and so on or one red point followed by a blue point and so on. Any tips for solving such problems is highly appreciated. Thanks in advance.",,['probability']
61,Complete convergence is equivalent to convergence a.s. under independence,Complete convergence is equivalent to convergence a.s. under independence,,"$X_1,X_2,\ldots$ is a sequence of random variables that are complete convergent to $X$ if $$\sum_{n=1}^{\infty} P(\mid X_n-X\mid >\epsilon)<\infty \space\forall\epsilon > 0$$. Show if $X_n$ are independent, then complete convergence is equivalent to convergence a.s. I showed that complete convergence implies convergence a.s. using the Borel-Cantelli lemma, but I'm not sure how to use show the converse using independence. This is what I have so far: $$X_n\rightarrow_{a.s.} X \implies X_n\rightarrow_{p} 0$$ WLOG, $X=0$. $$\forall\epsilon >0, P(\mid X_n\mid > \epsilon)\rightarrow 0$$ $$P(\limsup_{n\rightarrow\infty} \mid X_n\mid > \epsilon)=0$$ Since they are independent, then $\{\mid X\mid > \epsilon\}$ are independent, and can I use Borel-Cantelli (ii) to say $\sum P(\mid X_n\mid >\epsilon) < \infty$?","$X_1,X_2,\ldots$ is a sequence of random variables that are complete convergent to $X$ if $$\sum_{n=1}^{\infty} P(\mid X_n-X\mid >\epsilon)<\infty \space\forall\epsilon > 0$$. Show if $X_n$ are independent, then complete convergence is equivalent to convergence a.s. I showed that complete convergence implies convergence a.s. using the Borel-Cantelli lemma, but I'm not sure how to use show the converse using independence. This is what I have so far: $$X_n\rightarrow_{a.s.} X \implies X_n\rightarrow_{p} 0$$ WLOG, $X=0$. $$\forall\epsilon >0, P(\mid X_n\mid > \epsilon)\rightarrow 0$$ $$P(\limsup_{n\rightarrow\infty} \mid X_n\mid > \epsilon)=0$$ Since they are independent, then $\{\mid X\mid > \epsilon\}$ are independent, and can I use Borel-Cantelli (ii) to say $\sum P(\mid X_n\mid >\epsilon) < \infty$?",,"['probability', 'measure-theory']"
62,Probability of 2 Cards being adjacent,Probability of 2 Cards being adjacent,,"I read about a magic trick yesterday that relied on probability - I gave it a try a few times and it seemed to work, but I was wondering what the actual probability of success is. I understand basic probability but I'm not quite sure how I would calculate this. The basic premise stands as follows: choose two distinct card ranks (without a suit) e.g. king and a 7 (but you cannot choose both the same). Shuffle the cards and now fan them out. There should be a king and a 7 adjacent to each other in the pack, just based on probabilities. My question is what are the chances of success here? Or how do you calculate it?","I read about a magic trick yesterday that relied on probability - I gave it a try a few times and it seemed to work, but I was wondering what the actual probability of success is. I understand basic probability but I'm not quite sure how I would calculate this. The basic premise stands as follows: choose two distinct card ranks (without a suit) e.g. king and a 7 (but you cannot choose both the same). Shuffle the cards and now fan them out. There should be a king and a 7 adjacent to each other in the pack, just based on probabilities. My question is what are the chances of success here? Or how do you calculate it?",,[]
63,Probability puzzle - the 3 cannons,Probability puzzle - the 3 cannons,,"(Apologies if this is the wrong venue to ask such a question, but I don't understand how to arrive at a solution to this math puzzle). Three cannons are fighting each other. Cannon A hits 1/2 of the time. Cannon B hits 1/3 the time. Cannon C hits 1/6 of the time. Each cannon fires at the current ""best"" cannon. So B and C will start shooting at A, while A will shoot at B, the next best. Cannons die when they get hit. Which cannon has the highest probability of survival? Why? Clarification: B and C will start shooting at A.","(Apologies if this is the wrong venue to ask such a question, but I don't understand how to arrive at a solution to this math puzzle). Three cannons are fighting each other. Cannon A hits 1/2 of the time. Cannon B hits 1/3 the time. Cannon C hits 1/6 of the time. Each cannon fires at the current ""best"" cannon. So B and C will start shooting at A, while A will shoot at B, the next best. Cannons die when they get hit. Which cannon has the highest probability of survival? Why? Clarification: B and C will start shooting at A.",,['probability']
64,Probability puzzler involving roots of unity,Probability puzzler involving roots of unity,,Problem: Let $v$ and $w$ be roots of $z^{1997} = 1$ chosen at random (uniformly and independently). What is the probability that $|v + w| \ge \sqrt{2 + \sqrt 3}$? This problem comes from the 1997 AIME.,Problem: Let $v$ and $w$ be roots of $z^{1997} = 1$ chosen at random (uniformly and independently). What is the probability that $|v + w| \ge \sqrt{2 + \sqrt 3}$? This problem comes from the 1997 AIME.,,"['probability', 'contest-math']"
65,What is the expected size of the convex hull of $n$-points selected randomly in a $2d$-circle?,What is the expected size of the convex hull of -points selected randomly in a -circle?,n 2d,"We know $n>2$ and worst case its a triangle, best case the points all lie on a circle. Can we generalize to higher dimensions? What's the probability that the size of the convex hull of $n$ points randomly selected in a circle is $k$?","We know $n>2$ and worst case its a triangle, best case the points all lie on a circle. Can we generalize to higher dimensions? What's the probability that the size of the convex hull of $n$ points randomly selected in a circle is $k$?",,"['probability', 'geometry', 'geometric-probability']"
66,Why aren't probability measures required to use $2^X$ as the underlying $\sigma$-algebra?,Why aren't probability measures required to use  as the underlying -algebra?,2^X \sigma,"Let $Y$ be a random variable that takes values in some set $X$ according to a probability measure $\mu$.  If the $\sigma$-algebra on which $\mu$ is defined is not $2^X$, then there exists $A \subset X$ with $\mu(A)$ undefined.  This implies that the event ""A realization $y$ of $Y$ satisfies $y \in A$"" has undefined probability.  But that can't be right: if we sample $Y$ over and over, the frequency with which our event comes true should converge to some value, so the event does have a probability. Must all probability measures be defined on $2^X$?  Or is my intuition that in the real world, all events have a probability wrong?","Let $Y$ be a random variable that takes values in some set $X$ according to a probability measure $\mu$.  If the $\sigma$-algebra on which $\mu$ is defined is not $2^X$, then there exists $A \subset X$ with $\mu(A)$ undefined.  This implies that the event ""A realization $y$ of $Y$ satisfies $y \in A$"" has undefined probability.  But that can't be right: if we sample $Y$ over and over, the frequency with which our event comes true should converge to some value, so the event does have a probability. Must all probability measures be defined on $2^X$?  Or is my intuition that in the real world, all events have a probability wrong?",,"['probability', 'measure-theory', 'probability-theory']"
67,"Three dice having sides labelled $e,i,π,1,0,\sqrt2$ are rolled. Find the probability of getting the product of the three results a real number.",Three dice having sides labelled  are rolled. Find the probability of getting the product of the three results a real number.,"e,i,π,1,0,\sqrt2","There are three fair six-sided dice with sides $0,1,e,\pi,i,\sqrt2$. If these dice are rolled, the probability that the product of all the numbers is real can be expressed as $\frac ab$ where $a$ and $b$ are positive, co-prime integers. What is $a+b$? When I tried I got the total possibilities to be 216 and the rest I got wrong. Can you help me find the answer to the problem? (I think it is $\frac{99}{216}$).","There are three fair six-sided dice with sides $0,1,e,\pi,i,\sqrt2$. If these dice are rolled, the probability that the product of all the numbers is real can be expressed as $\frac ab$ where $a$ and $b$ are positive, co-prime integers. What is $a+b$? When I tried I got the total possibilities to be 216 and the rest I got wrong. Can you help me find the answer to the problem? (I think it is $\frac{99}{216}$).",,"['probability', 'combinatorics', 'dice']"
68,Kelly criterion for multiple gambles,Kelly criterion for multiple gambles,,"Kelly says you should invest $x\%$ of your bankroll in a gamble: $$x = \frac{pE-1}{p-1}$$ where $p$ is the probability of winning and $E$ is the expected payoff multiplier if you win (i.e. $E$ times how much you bet). But lets say you have two options to invest in: One that has high risk and high payoff potential and another one that's absolutely safe, but only pays very little (e.g., FDIC insured bank account). Is there a formula for this case? I was thinking to subtract the yield of the absolutely safe instrument from the expected payoff of the high risk venture and then just using the formula above. EDIT: I found the formula: [pE-(1+r)]/[E-(1+r)] where r is the interest rate","Kelly says you should invest $x\%$ of your bankroll in a gamble: $$x = \frac{pE-1}{p-1}$$ where $p$ is the probability of winning and $E$ is the expected payoff multiplier if you win (i.e. $E$ times how much you bet). But lets say you have two options to invest in: One that has high risk and high payoff potential and another one that's absolutely safe, but only pays very little (e.g., FDIC insured bank account). Is there a formula for this case? I was thinking to subtract the yield of the absolutely safe instrument from the expected payoff of the high risk venture and then just using the formula above. EDIT: I found the formula: [pE-(1+r)]/[E-(1+r)] where r is the interest rate",,['probability']
69,Expectation value of a product of an Ito integral and a function of a Brownian motion,Expectation value of a product of an Ito integral and a function of a Brownian motion,,"this problem has come up in my research and is confusing me immensely, any light you can shed would be deeply appreciated. Let $B(t)$ denote a standard Brownian motion (Wiener process), such that the difference $B(t)-B(s)$ has a normal distribution with zero mean and variance $t-s$. I am seeking an expression for $$E\left[ \cos(B(t))\int\limits_0^t \sin(B(s))\,\textrm{d}B(s) \right],$$ where the integral is a stochastic It$\hat{\textrm{o}}$ integral.  My first thought was that the expectation of the integral alone is zero, and that the two terms are statistically independent, hence the whole thing gives zero.  However, I can't prove this. To give you a little background: this expression arises as one of several terms in a calculation of the second moment of the integral $$\int\limits_{0}^{t}\cos(B(s))\,\textrm{d}s,$$ after applying It$\hat{\textrm{o}}$'s lemma and squaring.  I can simulate this numerically, so I should know when I get the right final expression! Thanks.","this problem has come up in my research and is confusing me immensely, any light you can shed would be deeply appreciated. Let $B(t)$ denote a standard Brownian motion (Wiener process), such that the difference $B(t)-B(s)$ has a normal distribution with zero mean and variance $t-s$. I am seeking an expression for $$E\left[ \cos(B(t))\int\limits_0^t \sin(B(s))\,\textrm{d}B(s) \right],$$ where the integral is a stochastic It$\hat{\textrm{o}}$ integral.  My first thought was that the expectation of the integral alone is zero, and that the two terms are statistically independent, hence the whole thing gives zero.  However, I can't prove this. To give you a little background: this expression arises as one of several terms in a calculation of the second moment of the integral $$\int\limits_{0}^{t}\cos(B(s))\,\textrm{d}s,$$ after applying It$\hat{\textrm{o}}$'s lemma and squaring.  I can simulate this numerically, so I should know when I get the right final expression! Thanks.",,"['probability', 'stochastic-processes', 'stochastic-integrals', 'brownian-motion', 'stochastic-calculus']"
70,"A question in Probability, aces drawn from two halves of a shuffled deck","A question in Probability, aces drawn from two halves of a shuffled deck",,"""A deck of cards is shuffled and then divided into two halves of 26 cards each. A card is drawn from one of the halves, it turns out to be an ace. The ace is then placed in the second half-deck. The half is then shuffled and a card is drawn from it. Compute the probability that this drawn card is an ace."" Source : A First Course in Probability, Sheldon Ross, Chapter 3, Exercise 37 (My intention was not to be lazy and let the community do all the work for me, but I think that is what has been misunderstood seeing the 2 dislikes this question received. I just thought I should not clutter the question with more text than necessary) What I've tried : Probability that the second half already contained 0,1,2 or 3 aces before the ace from the first half was added to it. Then, when the new ace was added to it from the first half, we could calculate the probabilities of drawing an ace considering each of these cases, and add them to get the answer. But I am not sure how do I calculate the P(second half contained 0/1/2/3 aces)..","""A deck of cards is shuffled and then divided into two halves of 26 cards each. A card is drawn from one of the halves, it turns out to be an ace. The ace is then placed in the second half-deck. The half is then shuffled and a card is drawn from it. Compute the probability that this drawn card is an ace."" Source : A First Course in Probability, Sheldon Ross, Chapter 3, Exercise 37 (My intention was not to be lazy and let the community do all the work for me, but I think that is what has been misunderstood seeing the 2 dislikes this question received. I just thought I should not clutter the question with more text than necessary) What I've tried : Probability that the second half already contained 0,1,2 or 3 aces before the ace from the first half was added to it. Then, when the new ace was added to it from the first half, we could calculate the probabilities of drawing an ace considering each of these cases, and add them to get the answer. But I am not sure how do I calculate the P(second half contained 0/1/2/3 aces)..",,"['probability', 'card-games']"
71,"If $X_i$ are iid, finding $E(X_1 + X_2 + \cdots + X_k \mid X_1 + X_2+ \cdots +X_n=b)$","If  are iid, finding",X_i E(X_1 + X_2 + \cdots + X_k \mid X_1 + X_2+ \cdots +X_n=b),"I just wonder if anybody can help me to prove the following identity: Given a series of i.i.d. non-negative random variables $X_1, X_2, ..., X_n$, then $$E(X_1+X_2+ \cdots +X_k \mid X_1+X_2+ \cdots +X_n=b)=b \cdot \frac{k}{n} .$$","I just wonder if anybody can help me to prove the following identity: Given a series of i.i.d. non-negative random variables $X_1, X_2, ..., X_n$, then $$E(X_1+X_2+ \cdots +X_k \mid X_1+X_2+ \cdots +X_n=b)=b \cdot \frac{k}{n} .$$",,['probability']
72,Laguerre polynomials and inclusion-exclusion,Laguerre polynomials and inclusion-exclusion,,"Does anyone know a reference for the solution of the  generalized derangement problem via Laguerre polynomials? The Wikipedia article here says that this is an application of inclusion-exclusion, but I don't see how. This formula was used by joriki in a nice MSE answer here . The article below solves the generalized derangement problem with inclusion-exclusion, but without Laguerre polynomials. Reference: Finn F. Knudsen and Ivar Skau, ""On the Asymptotic Solution of a Card-Matching Problem"", Mathematics Magazine 69 (1996), 190-197.","Does anyone know a reference for the solution of the  generalized derangement problem via Laguerre polynomials? The Wikipedia article here says that this is an application of inclusion-exclusion, but I don't see how. This formula was used by joriki in a nice MSE answer here . The article below solves the generalized derangement problem with inclusion-exclusion, but without Laguerre polynomials. Reference: Finn F. Knudsen and Ivar Skau, ""On the Asymptotic Solution of a Card-Matching Problem"", Mathematics Magazine 69 (1996), 190-197.",,"['probability', 'combinatorics']"
73,Linear MMSE estimate of MMSE estimator,Linear MMSE estimate of MMSE estimator,,"This question is prompted by a recent discussion ( Conditional Expectation a Decreasing Function Implies Covariance is nonpositive ) about the relationship between conditional expectation and covariance. Suppose that $X$ and $Y$ are zero-mean unit-variance random variables with covariance (and correlation coefficient) $\rho$ .  The minimum-mean-square error (MMSE) estimator of $Y$ given $X$ is  the random variable $g(X)$ that minimizes $E[(Y-g(X))^2]$ , and as is well known, $$g(X) = E[Y \mid X] ~\text{minimizes}~E[(Y-g(X))^2]$$ It is also well known that $E[g(X)] = E[E[Y\mid X]] = E[Y] = 0$ .  In general, $g(X)$ is a nonlinear function. On the other hand, if the estimator is restricted to being  of the form $\hat{Y} = aX + b$ where $a$ and $b$ are real numbers,  then the linear MMSE estimator of $Y$ given $X$ is $\hat{Y} = \rho X$ , that is, $$a = \rho, ~ b = 0, ~\text{minimizes}~E[(Y-aX-b)^2].$$ The linear MMSE estimator $\rho X$ has a mean-square-error $E[(Y-\rho X)^2] = 1 - \rho^2$ and so the mean-square-error  of the MMSE estimator $g(X)$ can be no larger: $$E[(Y-g(X))^2] \leq 1 - \rho^2.$$ A simplified version of the question in the previous discussion is:  if $g(\cdot)$ is a decreasing function of its argument, show that $\rho$ is nonpositive. My question is: what is the linear MMSE estimate of $g(X) = E[Y \mid X]$ given $X$ ?  That is, what choice of real numbers $c$ and $d$ minimizes $E[(g(X) - cX - d)^2]$ ?  Since $g(X)$ and $X$ both have zero mean and $X$ has unit variance, standard linear MMSE estimator theory gives that $d = 0$ and $$c = \frac{\text{cov}(g(X),X)}{\text{var}(X)} = \text{cov}(g(X),X) = E[Xg(X)]$$ which I think might work out to be $\rho$ , but I am not sure about this. Any suggestions on how to proceed further would be appreciated.","This question is prompted by a recent discussion ( Conditional Expectation a Decreasing Function Implies Covariance is nonpositive ) about the relationship between conditional expectation and covariance. Suppose that and are zero-mean unit-variance random variables with covariance (and correlation coefficient) .  The minimum-mean-square error (MMSE) estimator of given is  the random variable that minimizes , and as is well known, It is also well known that .  In general, is a nonlinear function. On the other hand, if the estimator is restricted to being  of the form where and are real numbers,  then the linear MMSE estimator of given is , that is, The linear MMSE estimator has a mean-square-error and so the mean-square-error  of the MMSE estimator can be no larger: A simplified version of the question in the previous discussion is:  if is a decreasing function of its argument, show that is nonpositive. My question is: what is the linear MMSE estimate of given ?  That is, what choice of real numbers and minimizes ?  Since and both have zero mean and has unit variance, standard linear MMSE estimator theory gives that and which I think might work out to be , but I am not sure about this. Any suggestions on how to proceed further would be appreciated.","X Y \rho Y X g(X) E[(Y-g(X))^2] g(X) = E[Y \mid X] ~\text{minimizes}~E[(Y-g(X))^2] E[g(X)] = E[E[Y\mid X]] = E[Y] = 0 g(X) \hat{Y} = aX + b a b Y X \hat{Y} = \rho X a = \rho, ~ b = 0, ~\text{minimizes}~E[(Y-aX-b)^2]. \rho X E[(Y-\rho X)^2] = 1 - \rho^2 g(X) E[(Y-g(X))^2] \leq 1 - \rho^2. g(\cdot) \rho g(X) = E[Y \mid X] X c d E[(g(X) - cX - d)^2] g(X) X X d = 0 c = \frac{\text{cov}(g(X),X)}{\text{var}(X)} = \text{cov}(g(X),X) = E[Xg(X)] \rho","['probability', 'probability-theory', 'mean-square-error']"
74,Expectation of pairwise differences between uniform random points in hypercube,Expectation of pairwise differences between uniform random points in hypercube,,"Say you have 2 iid random variables $x,y\sim U[0,1]^k$, i.e. the uniform distribution over the k-dimensional unit cube. What's the expected value of the Euclidean distance between them when they have been normalized by the maximum distance possible, i.e. $\sqrt k$? For $k=1$, I worked out that this is 1/3. For $k=100$, monte carlo simulations tell me it's a little over 0.4. I tried  to work out the math but $$\frac{1}{\sqrt{k}}\int_{S_x} \int_{S_y} \sqrt{(x-y)^T (x-y)}\;dx\;dy$$ where $S_x,S_y=[0,1]^k$ for general $k$ is beyond me.","Say you have 2 iid random variables $x,y\sim U[0,1]^k$, i.e. the uniform distribution over the k-dimensional unit cube. What's the expected value of the Euclidean distance between them when they have been normalized by the maximum distance possible, i.e. $\sqrt k$? For $k=1$, I worked out that this is 1/3. For $k=100$, monte carlo simulations tell me it's a little over 0.4. I tried  to work out the math but $$\frac{1}{\sqrt{k}}\int_{S_x} \int_{S_y} \sqrt{(x-y)^T (x-y)}\;dx\;dy$$ where $S_x,S_y=[0,1]^k$ for general $k$ is beyond me.",,"['probability', 'integration']"
75,Solving a simple recurrence relation,Solving a simple recurrence relation,,"I have the following recurrence relation: $a_0=1$ $a_{n}=pa_{n+1}+qa_{n-1}$ Where $p+q=1$. This relation arises in analyzing a ""gambler's ruin"" situation. It is claimed that the general solution is $A+B(q/p)^i$ but I fail to see why (trying the usual method of solving the characteristic equation does not seem to work for me). Also, and this is maybe even more interesting to me - what is the solution if the relation is finite, i.e. if we have $a_{k}=a_{k-1}$ for some $k$ and onwards?","I have the following recurrence relation: $a_0=1$ $a_{n}=pa_{n+1}+qa_{n-1}$ Where $p+q=1$. This relation arises in analyzing a ""gambler's ruin"" situation. It is claimed that the general solution is $A+B(q/p)^i$ but I fail to see why (trying the usual method of solving the characteristic equation does not seem to work for me). Also, and this is maybe even more interesting to me - what is the solution if the relation is finite, i.e. if we have $a_{k}=a_{k-1}$ for some $k$ and onwards?",,"['probability', 'recurrence-relations']"
76,Probability of a biased random walk hitting an absorbing barrier in some number of steps,Probability of a biased random walk hitting an absorbing barrier in some number of steps,,"Let's say I have a biased random walk over the integers in some interval [0, L] where the endpoints of the interval ('0' and 'L', respectively) are fully absorbing.  The walker starts at some position x(i), and has a probability of taking a '+1' step and a '-1' step of 'p' & 'q', respectively.  Here p + q = 1, there is no stationary step. My question is: conditional on the walker eventually absorbing, specifically at one boundary, what is the probability that absorption will occur prior to some number of steps, 'M'? Update - I would also be quite interested in tight lower-bound estimates!","Let's say I have a biased random walk over the integers in some interval [0, L] where the endpoints of the interval ('0' and 'L', respectively) are fully absorbing.  The walker starts at some position x(i), and has a probability of taking a '+1' step and a '-1' step of 'p' & 'q', respectively.  Here p + q = 1, there is no stationary step. My question is: conditional on the walker eventually absorbing, specifically at one boundary, what is the probability that absorption will occur prior to some number of steps, 'M'? Update - I would also be quite interested in tight lower-bound estimates!",,"['probability', 'random-walk']"
77,Independent Poisson processes: Race to 5,Independent Poisson processes: Race to 5,,I have this problem to solve: Hockey teams 1 and 2 score goals at times of Poisson process with rates 1 and 2. Suppose that $N_1(0)=3$ and $N_2(0)=1$.   What is the probability that $N_1(t)$ will reach 5 before $N_2(t)$ does? I've re-worded this to: What is the prob that in the next 5 goals at least 2 of them are scored by team 1? The only problem I have is finding out the probability of team one scoring a goal. Can we use the rates to work this out?,I have this problem to solve: Hockey teams 1 and 2 score goals at times of Poisson process with rates 1 and 2. Suppose that $N_1(0)=3$ and $N_2(0)=1$.   What is the probability that $N_1(t)$ will reach 5 before $N_2(t)$ does? I've re-worded this to: What is the prob that in the next 5 goals at least 2 of them are scored by team 1? The only problem I have is finding out the probability of team one scoring a goal. Can we use the rates to work this out?,,"['probability', 'probability-distributions']"
78,Does equality in distribution imply equality of expected value?,Does equality in distribution imply equality of expected value?,,"In other words, if X = Y in distribution, is it true that EX = EY? I think this must be true, but I've tried to prove it a few times and I always get stuck. Thanks in advance for any hints or reference.","In other words, if X = Y in distribution, is it true that EX = EY? I think this must be true, but I've tried to prove it a few times and I always get stuck. Thanks in advance for any hints or reference.",,[]
79,Probability of flips n to 2n-1 being all tails?,Probability of flips n to 2n-1 being all tails?,,"Let us perform infinitely many fair coin flips and write them down. I want to find the probability of the event in which there exists $n \ge 2$ where the $n$ th, $(n+1)$ th, …, $(2n-1)$ th flips are all tails. I am not sure if there exists some closed form of this. I wrote code to approximate this probability (with a lower bound) with the first $2i-1$ flips, up to $i=20$ : use rayon::prelude::*;  fn flip_n(n: usize) -> (usize, usize) {     let total_count = 1 << (2 * n - 1);     let success_count = (0..total_count)         .into_par_iter()         .filter(|&sequence| {             (2..=n).any(|n| {                 let end_index = 2 * n - 1;                 let mask = (1 << end_index) - (1 << (n - 1));                 sequence & mask == mask             })         })         .count();      (success_count, total_count) }  fn main() {     for i in 2..=20 {         let (success_count, total_count) = flip_n(i);         println!(             ""{} / {} ≈ {:.7}"",             success_count,             total_count,             success_count as f64 / total_count as f64         );     } } And I got this output: 2 / 8 ≈ 0.2500000 10 / 32 ≈ 0.3125000 44 / 128 ≈ 0.3437500 182 / 512 ≈ 0.3554688 740 / 2048 ≈ 0.3613281 2982 / 8192 ≈ 0.3640137 11972 / 32768 ≈ 0.3653564 47972 / 131072 ≈ 0.3659973 192056 / 524288 ≈ 0.3663177 768554 / 2097152 ≈ 0.3664751 3074876 / 8388608 ≈ 0.3665538 12300812 / 33554432 ≈ 0.3665928 49205864 / 134217728 ≈ 0.3666123 196828666 / 536870912 ≈ 0.3666220 787325084 / 2147483648 ≈ 0.3666268 3149321132 / 8589934592 ≈ 0.3666292 12597326120 / 34359738368 ≈ 0.3666304 50389387580 / 137438953472 ≈ 0.3666310 201557716520 / 549755813888 ≈ 0.3666314 The difference between consecutive lower bounds here has a rather interesting pattern which makes me think that there might be some exact solution for infinite flips, but I have not succeeded in finding such a solution. Any help would be appreciated!","Let us perform infinitely many fair coin flips and write them down. I want to find the probability of the event in which there exists where the th, th, …, th flips are all tails. I am not sure if there exists some closed form of this. I wrote code to approximate this probability (with a lower bound) with the first flips, up to : use rayon::prelude::*;  fn flip_n(n: usize) -> (usize, usize) {     let total_count = 1 << (2 * n - 1);     let success_count = (0..total_count)         .into_par_iter()         .filter(|&sequence| {             (2..=n).any(|n| {                 let end_index = 2 * n - 1;                 let mask = (1 << end_index) - (1 << (n - 1));                 sequence & mask == mask             })         })         .count();      (success_count, total_count) }  fn main() {     for i in 2..=20 {         let (success_count, total_count) = flip_n(i);         println!(             ""{} / {} ≈ {:.7}"",             success_count,             total_count,             success_count as f64 / total_count as f64         );     } } And I got this output: 2 / 8 ≈ 0.2500000 10 / 32 ≈ 0.3125000 44 / 128 ≈ 0.3437500 182 / 512 ≈ 0.3554688 740 / 2048 ≈ 0.3613281 2982 / 8192 ≈ 0.3640137 11972 / 32768 ≈ 0.3653564 47972 / 131072 ≈ 0.3659973 192056 / 524288 ≈ 0.3663177 768554 / 2097152 ≈ 0.3664751 3074876 / 8388608 ≈ 0.3665538 12300812 / 33554432 ≈ 0.3665928 49205864 / 134217728 ≈ 0.3666123 196828666 / 536870912 ≈ 0.3666220 787325084 / 2147483648 ≈ 0.3666268 3149321132 / 8589934592 ≈ 0.3666292 12597326120 / 34359738368 ≈ 0.3666304 50389387580 / 137438953472 ≈ 0.3666310 201557716520 / 549755813888 ≈ 0.3666314 The difference between consecutive lower bounds here has a rather interesting pattern which makes me think that there might be some exact solution for infinite flips, but I have not succeeded in finding such a solution. Any help would be appreciated!",n \ge 2 n (n+1) (2n-1) 2i-1 i=20,"['probability', 'combinatorics']"
80,Expected value exponential inequality non-negative random variable,Expected value exponential inequality non-negative random variable,,"Let $X$ be a non-negative random variable and $p \geq e$ , $q > 0$ be two constant values such that $$ P [X \geq x] \leq p e^{-x^2/q^2} \quad \forall x \geq 0. $$ Prove that $$ \mathbb{E}[X] \leq q(1+\sqrt{\log p}). $$ There's my first attempt. Using the identity $$ \mathbb{E}[X] = \int_0^\infty (1-F(x)) d x - \int_{-\infty}^0 F(x) d x $$ and the fact that $X \geq 0$ I obtain: $$ \mathbb{E}[X] = \int_0^\infty (1-F(x)) d x $$ and using the hypothesis I get $$ \mathbb{E}[X] \leq \int_0^{+\infty} p e^{-x^2/q^2} d x = pq \int_0^{+\infty} e^{-z^2} dz = \frac{pq \sqrt{\pi}}{2} $$ where the last equality is given by the gaussian integral . But then I'm stuck. The second attempt I tried was to partition the events set in some smart way, that is using $( X \geq q )$ or $(X \geq \sqrt{\log p} )$ but I couldn't go anywhere.","Let be a non-negative random variable and , be two constant values such that Prove that There's my first attempt. Using the identity and the fact that I obtain: and using the hypothesis I get where the last equality is given by the gaussian integral . But then I'm stuck. The second attempt I tried was to partition the events set in some smart way, that is using or but I couldn't go anywhere.","X p \geq e q > 0 
P [X \geq x] \leq p e^{-x^2/q^2} \quad \forall x \geq 0.
 
\mathbb{E}[X] \leq q(1+\sqrt{\log p}).
 
\mathbb{E}[X] = \int_0^\infty (1-F(x)) d x - \int_{-\infty}^0 F(x) d x
 X \geq 0 
\mathbb{E}[X] = \int_0^\infty (1-F(x)) d x
 
\mathbb{E}[X] \leq \int_0^{+\infty} p e^{-x^2/q^2} d x = pq \int_0^{+\infty} e^{-z^2} dz = \frac{pq \sqrt{\pi}}{2}
 ( X \geq q ) (X \geq \sqrt{\log p} )","['probability', 'probability-theory', 'expected-value']"
81,"What is the probability that Carlos's purchase of 5 CDs includes at least one rap, country, and heavy metal CD out of a total of 12?","What is the probability that Carlos's purchase of 5 CDs includes at least one rap, country, and heavy metal CD out of a total of 12?",,"Full Problem Carlos has chosen $12$ different CDs he would like to buy: $4$ are rap music, $5$ are country music, and $3$ are heavy metal music. (Carlos has very eclectic tastes in music!) Unfortunately, he has only enough money to afford to buy $5$ of them (they all cost the same price). So he selects $5$ of them at random. What is the probability that his purchase includes at least one CD from each of the three categories? My Response First, there are a total of $\dbinom{12}5$ total ways for Carlos to choose, without order, $5$ CDs from $12$ CDs. Then, there are a total of $\dbinom41 \dbinom51 \dbinom31 \dbinom92$ ways for Carlos to choose at least one CD from each category. This simplifies to $\dfrac{30}{11}$ , which is obviously not correct. What went wrong in my process?","Full Problem Carlos has chosen different CDs he would like to buy: are rap music, are country music, and are heavy metal music. (Carlos has very eclectic tastes in music!) Unfortunately, he has only enough money to afford to buy of them (they all cost the same price). So he selects of them at random. What is the probability that his purchase includes at least one CD from each of the three categories? My Response First, there are a total of total ways for Carlos to choose, without order, CDs from CDs. Then, there are a total of ways for Carlos to choose at least one CD from each category. This simplifies to , which is obviously not correct. What went wrong in my process?",12 4 5 3 5 5 \dbinom{12}5 5 12 \dbinom41 \dbinom51 \dbinom31 \dbinom92 \dfrac{30}{11},"['probability', 'combinatorics']"
82,Concentration of measure on sphere: Bounding the probability of a large angle,Concentration of measure on sphere: Bounding the probability of a large angle,,"Fix any $y$ on the sphere $S^{n-1}:=\{x\in\mathbb{R}^n : \|x\|_2=1\}$ . Let $z$ be a random variable, uniformly distributed on $S^{n-1}$ . Show that for any $\epsilon\in(0,1/\sqrt{2})$ . $$ \mathbb{P}[|y^Tz|> \epsilon]\leq \left(1-\epsilon^2\right)^{n/2} $$ This is an exercise left to the reader in Martin Wainwright's High Dimensional Statistics , p. 69. The author statest that it is a ""geometric calculation"". What I tried: The most promising approach I have is the observation that the term $\sqrt{1-\epsilon^2}$ is the length of the leg of a right-angled triangle with hypotenuse of length 1 and leg of length $\epsilon$ . Such a triangle indeed readily appears when one draws a two-dimensional sphere, and the region $\{x\in\mathbb{R}^n : |y^Tx|>\epsilon\}$ . But I don't understand how to connect this to the probability in question, and consequentially how to get the exponent $n$ . Can anyone help?","Fix any on the sphere . Let be a random variable, uniformly distributed on . Show that for any . This is an exercise left to the reader in Martin Wainwright's High Dimensional Statistics , p. 69. The author statest that it is a ""geometric calculation"". What I tried: The most promising approach I have is the observation that the term is the length of the leg of a right-angled triangle with hypotenuse of length 1 and leg of length . Such a triangle indeed readily appears when one draws a two-dimensional sphere, and the region . But I don't understand how to connect this to the probability in question, and consequentially how to get the exponent . Can anyone help?","y S^{n-1}:=\{x\in\mathbb{R}^n : \|x\|_2=1\} z S^{n-1} \epsilon\in(0,1/\sqrt{2}) 
\mathbb{P}[|y^Tz|> \epsilon]\leq \left(1-\epsilon^2\right)^{n/2}
 \sqrt{1-\epsilon^2} \epsilon \{x\in\mathbb{R}^n : |y^Tx|>\epsilon\} n","['probability', 'geometry', 'trigonometry', 'spheres', 'concentration-of-measure']"
83,Can we approximate the most likely event's probability if we know the distribution's entropy?,Can we approximate the most likely event's probability if we know the distribution's entropy?,,"Suppose that we know that a distribution $p$ over small $n$ elements has entropy $H(p)=0.01$ . I intentionally chose a small number. Is there some kind of inequality or aproximation to the probability $p_i$ for $i = \arg\max_j p_j$ ? What I came up with so far is the following inequality: $H(p) = \sum _j -p_j \log(p_j) \geq -p_i \log(p_i)$ . This gives us in principle an inequality for $p_i$ , because if we assume that the most likely event has probability larger than $0.5$ (a consequence of the entropy being sufficiently small for a given $n$ ), then this inequality $H(p) \geq -p_i \log(p_i)$ should give us a bound on $p_i$ in terms of the entropy. I'm not sure how to solve that inequality for $p_i$ though, or if it's even possible. Maybe an approximation would help as well, that works for small entropy. Is there a bound or approximation on the maximum probability $p_i$ in terms of the entropy, that works for sufficiently small entropy?","Suppose that we know that a distribution over small elements has entropy . I intentionally chose a small number. Is there some kind of inequality or aproximation to the probability for ? What I came up with so far is the following inequality: . This gives us in principle an inequality for , because if we assume that the most likely event has probability larger than (a consequence of the entropy being sufficiently small for a given ), then this inequality should give us a bound on in terms of the entropy. I'm not sure how to solve that inequality for though, or if it's even possible. Maybe an approximation would help as well, that works for small entropy. Is there a bound or approximation on the maximum probability in terms of the entropy, that works for sufficiently small entropy?",p n H(p)=0.01 p_i i = \arg\max_j p_j H(p) = \sum _j -p_j \log(p_j) \geq -p_i \log(p_i) p_i 0.5 n H(p) \geq -p_i \log(p_i) p_i p_i p_i,"['probability', 'approximation', 'information-theory', 'upper-lower-bounds', 'entropy']"
84,"Probability of ""winning a race""?","Probability of ""winning a race""?",,"Suppose there are three people, A, B, and C. Each person starts at $x=0$ and then randomly one person moves forward by 1, with equal probability among all three people. The winner is the first person to reach $x=3$ . By symmetry, the probability of each person winning is 1/3. But now suppose person A wins if they reach $x=2$ , while person B and C still only win at $x=3$ . How can I calculate $P(\text{A wins})$ ? EDIT: Using a simulation in R I obtained these probabilities, but I'm still unsure about the analytical approach. A         B         C  0.5472412 0.2263920 0.2263668","Suppose there are three people, A, B, and C. Each person starts at and then randomly one person moves forward by 1, with equal probability among all three people. The winner is the first person to reach . By symmetry, the probability of each person winning is 1/3. But now suppose person A wins if they reach , while person B and C still only win at . How can I calculate ? EDIT: Using a simulation in R I obtained these probabilities, but I'm still unsure about the analytical approach. A         B         C  0.5472412 0.2263920 0.2263668",x=0 x=3 x=2 x=3 P(\text{A wins}),['probability']
85,Probability of A and not B,Probability of A and not B,,"I'm studying Introduction to probability and currently, I'm stuck with the following problem. Given: $P(A)=0.7$ , $P(B)=0.5$ , $P(A\cap B)=0.45$ What is the probability of A and not B? I've checked this similar question but I don't understand the answers. Also I've asked my instructor and she told me that $1-P(A\cap B)(P(B^c))$ is the answer (As the answers suggested, this result is not correct) . Why is that? She does not provided me a completely explanation. Update 1: The original problem is the following In a multiplex cinema, there are two different rooms, $A$ and $B$ , working simultaneously. Let $SA$ be the event that, during a certain showing, room $A$ becomes full before the film begins, and let $SB$ be the event that, during the same showing, room $B$ becomes full before the beginning of the movie. We know that $P(SA)=0.7$ ; $P(SB)=0.5$ and $P(SA∩SB)=0.45$ Calculate the probability that room $A$ will become full and room $B$ will not. Did I state the problem correctly? Update 2: Add a Venn diagram . Following the advice of Ethan Bolker. Here is the Venn diagram that I made.","I'm studying Introduction to probability and currently, I'm stuck with the following problem. Given: , , What is the probability of A and not B? I've checked this similar question but I don't understand the answers. Also I've asked my instructor and she told me that is the answer (As the answers suggested, this result is not correct) . Why is that? She does not provided me a completely explanation. Update 1: The original problem is the following In a multiplex cinema, there are two different rooms, and , working simultaneously. Let be the event that, during a certain showing, room becomes full before the film begins, and let be the event that, during the same showing, room becomes full before the beginning of the movie. We know that ; and Calculate the probability that room will become full and room will not. Did I state the problem correctly? Update 2: Add a Venn diagram . Following the advice of Ethan Bolker. Here is the Venn diagram that I made.",P(A)=0.7 P(B)=0.5 P(A\cap B)=0.45 1-P(A\cap B)(P(B^c)) A B SA A SB B P(SA)=0.7 P(SB)=0.5 P(SA∩SB)=0.45 A B,['probability']
86,What is the expected number of ingredients used to make $4$ pizzas if each pizza must contain $4$ of $100$ possible ingredients?,What is the expected number of ingredients used to make  pizzas if each pizza must contain  of  possible ingredients?,4 4 100,"I'm trying to solve an optimization problem of the Google Hashcode contest and by analyzing the dataset I reduced a part of it down to a statistics problem, which I'm not able to solve. Any help would be appreciated. Assume we have $100$ types of ingredients (from each type infinitely many) and we want to make $4$ pizzas. Each pizza must contain exactly $4$ distinct ingredients. All of the $100$ ingredients are equally likely for a candidate position of an ingredient for a pizza. What is the expected value of the total distinct ingredients used in all $4$ pizzas? Here is my initial thought which is unlikely to be true: $$E[N] = \sum_{i = 4}^{16}{i \times \frac{\binom{100}{i} {\binom{i}{4}}^4 - \binom{100}{i - 1} {\binom{i - 1}{4}}^4}{\binom{100}{16}{\binom{16}{4}}^4}} =15.9. $$ Numerator is essentially difference of total number of states with $i$ ingredients at most and with $i-1$ ingredients at most which gives the total number of states with exactly $i$ ingredients, while denominator is the total number of states with $16$ ingredients. I think the answer for the above method ( $15.9$ ) is not very intuitive. It seems more logical for the answer to be much more lower. ps. I previously tried to put ${\binom{100}{4}}^4$ in the denominator but after doing a simple summation I ended up with a very unreasonable quantity. ps2. Order of pizzas are not important.","I'm trying to solve an optimization problem of the Google Hashcode contest and by analyzing the dataset I reduced a part of it down to a statistics problem, which I'm not able to solve. Any help would be appreciated. Assume we have types of ingredients (from each type infinitely many) and we want to make pizzas. Each pizza must contain exactly distinct ingredients. All of the ingredients are equally likely for a candidate position of an ingredient for a pizza. What is the expected value of the total distinct ingredients used in all pizzas? Here is my initial thought which is unlikely to be true: Numerator is essentially difference of total number of states with ingredients at most and with ingredients at most which gives the total number of states with exactly ingredients, while denominator is the total number of states with ingredients. I think the answer for the above method ( ) is not very intuitive. It seems more logical for the answer to be much more lower. ps. I previously tried to put in the denominator but after doing a simple summation I ended up with a very unreasonable quantity. ps2. Order of pizzas are not important.",100 4 4 100 4 E[N] = \sum_{i = 4}^{16}{i \times \frac{\binom{100}{i} {\binom{i}{4}}^4 - \binom{100}{i - 1} {\binom{i - 1}{4}}^4}{\binom{100}{16}{\binom{16}{4}}^4}} =15.9.  i i-1 i 16 15.9 {\binom{100}{4}}^4,"['probability', 'statistics']"
87,What is the expectation of $B_s^2B_t^2$ where $B_t$ is a standard Brownian motion?,What is the expectation of  where  is a standard Brownian motion?,B_s^2B_t^2 B_t,"I am tring to find the variance of the integral $I=\int_0^T B_t^2 dt$ . I have found that $\mathbb{E}[I] = \int_0^T \mathbb{E}[B_t^2] dt = \frac{T^2}{2}$ . Since $\mathbb{E}[I^2] = \mathbb{E}[\int_0^T \int_0^T B_t^2 B_s^2 \ dt\ ds] = \int_0^T \int_0^T \mathbb{E}[B_t^2 B_s^2] \ dt \ ds$ , I want to know the value of $\mathbb{E}\left[B_t^2 B_s^2\right]$ .","I am tring to find the variance of the integral . I have found that . Since , I want to know the value of .",I=\int_0^T B_t^2 dt \mathbb{E}[I] = \int_0^T \mathbb{E}[B_t^2] dt = \frac{T^2}{2} \mathbb{E}[I^2] = \mathbb{E}[\int_0^T \int_0^T B_t^2 B_s^2 \ dt\ ds] = \int_0^T \int_0^T \mathbb{E}[B_t^2 B_s^2] \ dt \ ds \mathbb{E}\left[B_t^2 B_s^2\right],"['probability', 'stochastic-processes', 'expected-value', 'brownian-motion']"
88,Four-letter word contains no two consecutive equal letters.,Four-letter word contains no two consecutive equal letters.,,"This is taken from the book on Combinatorics, by Daniel Marcus. Request vetting: A16: Find the probability that a four-letter word that uses letters from $A,B,C,D,E$ contains (a) no repeated letters; (b) no two consecutive equal letters. (a) Total (Inclusion) ways to form four-letter word from five letters: $5^4$ . Ways to have repetitions of $A$ : Two $A$ : Choose two positions for $A$ in $\binom{4}2= 6$ ways. Rest two positions can be filled in : $4\times 3= 12$ ways. So, by product rule: $72$ words. Also, the same for other $4$ letters, leading to $72\times 5= 360$ words. Three $A$ : Choose three positions for $A$ in $\binom{4}3= 4$ ways. Rest one position can be filled in : $4$ ways. So, by product rule: $16$ words. Also, the same for other $4$ letters, leading to $16\times 5= 80$ words. Four $A$ : Choose all four positions for $A$ in $\binom{4}4= 1$ ways. Also, the same for other $4$ letters, leading to $5$ words. Sum of above three cases: $360+80+5= 445.$ Left are: $5^4 - 445= 180.$ $p= \frac{180}{625}$ (b) no two consecutive same letters' case. Approach#1: To get, need subtract from $5^4$ the chances of having two consecutive same letters. This is divided into cases: Case 1: Position #1,2 are the same, and position #4 can match too : $5\times 1\times 4\times 5= 100$ cases. Case 2: position #2,3 are the same: $5\times 4\times 1 \times 4= 80$ cases. Case 3: Position #3,4 are the same, and position #1 can match too: $5\times 4\times 1\times 5=100$ So, get : $625- 280= 345$ cases. Approach#2: Alternatively, can 'directly' calculate by having $5$ choices for the first position, then $4$ choices, then again need eliminate one choice (of the second element) to have $4$ choices for the third position, and same for the fourth position. This leads to: $5\times 4^3= 320$ choices possible. The second approach seems correct, but not clear why first approach is faulty. Seems there are too many factors to consider in the first approach & hence error-prone (to miss some case(s) as here). So, second approach seems better.","This is taken from the book on Combinatorics, by Daniel Marcus. Request vetting: A16: Find the probability that a four-letter word that uses letters from contains (a) no repeated letters; (b) no two consecutive equal letters. (a) Total (Inclusion) ways to form four-letter word from five letters: . Ways to have repetitions of : Two : Choose two positions for in ways. Rest two positions can be filled in : ways. So, by product rule: words. Also, the same for other letters, leading to words. Three : Choose three positions for in ways. Rest one position can be filled in : ways. So, by product rule: words. Also, the same for other letters, leading to words. Four : Choose all four positions for in ways. Also, the same for other letters, leading to words. Sum of above three cases: Left are: (b) no two consecutive same letters' case. Approach#1: To get, need subtract from the chances of having two consecutive same letters. This is divided into cases: Case 1: Position #1,2 are the same, and position #4 can match too : cases. Case 2: position #2,3 are the same: cases. Case 3: Position #3,4 are the same, and position #1 can match too: So, get : cases. Approach#2: Alternatively, can 'directly' calculate by having choices for the first position, then choices, then again need eliminate one choice (of the second element) to have choices for the third position, and same for the fourth position. This leads to: choices possible. The second approach seems correct, but not clear why first approach is faulty. Seems there are too many factors to consider in the first approach & hence error-prone (to miss some case(s) as here). So, second approach seems better.","A,B,C,D,E 5^4 A A A \binom{4}2= 6 4\times 3= 12 72 4 72\times 5= 360 A A \binom{4}3= 4 4 16 4 16\times 5= 80 A A \binom{4}4= 1 4 5 360+80+5= 445. 5^4 - 445= 180. p= \frac{180}{625} 5^4 5\times 1\times 4\times 5= 100 5\times 4\times 1 \times 4= 80 5\times 4\times 1\times 5=100 625- 280= 345 5 4 4 5\times 4^3= 320","['probability', 'combinatorics', 'discrete-mathematics', 'combinatorics-on-words']"
89,Computing the finite-dimensional marginal distributions of Brownian Bridge,Computing the finite-dimensional marginal distributions of Brownian Bridge,,"I'm working through Le Gall's Brownian Motion, Martingales, and Stochastic Calculus , and I'm struggling on an exercise. The question concerns computing the finite-dimensional marginal distributions of a Brownian bridge. In particular, let $B_{t}$ be a Brownian motion on $[0,1]$ or $\mathbb{R}^{+}$ (doesn't matter which), and for $t\in [0,1]$ define the Brownian Bridge to be $W_t = B_t - t B_1$ . I've shown that $W_t$ is a centered Gaussian process with covariance function $K(s,t) = \min\{s,t\}- st$ . I'm now asked to prove that for $0<t_1<\cdots<t_p<1$ , the law of $(W_{t_1}, \dots, W_{t_p})$ has density $$ g(w_1, \dots, w_p) = \sqrt{2\pi} \,p_{t_1}(w_1)\,p_{t_2 - t_1}(w_2 - w_1)\,\cdots\, p_{t_p - t_{p-1}}(w_p-w_{p-1})\,p_{1-t_{p}}(-w_p), $$ where $$ p_{t}(w)= \frac{1}{\sqrt{2\pi t}}\exp(-w^2/2t). $$ Solution Progress: Attempt 1: The density is factored into a bunch of products of Gaussian densities, where the variance of each is $t_{i}-t_{i-1}$ . This makes me want to relate the vector of Brownian Bridge terms $(W_{t_1}, \dots, W_{t_p})$ to either the vector of Brownian motion $(B_{t_1}, \dots, B_{t_p})$ or to the independent increments $(B_{t_1}-B_{0}, B_{t_2}-B_{t_1},\dots ,B_{t_p}-B_{t_{p-1}})$ . Both of these vectors have densities which are a product of individual gaussians. We note that $$ \begin{pmatrix} W_{t_p}\\ \vdots\\ W_{t_1} \end{pmatrix}= \begin{pmatrix} B_{t_p}-t_{p}B_{1}\\ \vdots\\ B_{t_1}-t_{1}B_{1} \end{pmatrix}= \begin{pmatrix} -t_p&1&{}&{}&{}\\ -t_{p-1}&{}&1&{}&{}\\ \vdots&{}&{}&\ddots&{}\\ -t_1&{}&{}&{}&1 \end{pmatrix} \begin{pmatrix} B_{1}\\ B_{t_p}\\ \vdots\\ B_{t_1} \end{pmatrix} $$ I would love to use a change of variables, but the issue is that I'm required to bring in the additional $B_1$ term, and so the linear transformation above maps $p+1$ -dimensional space into $p$ dimensional space. Thus, the determinant isn't defined. I'm not sure if I'm just being stupid, or this is really a problem? Attempt 2: Another approach I've thought of is that since the density $g(w_1, \dots, w_p)$ factors into densities of differences, let's first focus on the density of $(W_1 - W_{t_p}, \dots, W_{t_2} - W_{t_1}, W_{t_1})$ . We have \begin{align*} \begin{pmatrix} W_{1} - W_{t_p}\\ W_{t_p}-W_{t_{p-1}}\\ \vdots\\ W_{t_2}-W_{t_1}\\ W_{t_1} \end{pmatrix}&= \begin{pmatrix} (B_{1}-B_{t_p})-(1-t_p)B_{1}\\ (B_{t_p}-B_{t_{p-1}})-(t_{p}-t_{p-1})B_{1}\\ \vdots\\ (B_{t_2}-B_{t_1})-(t_2-t_1)B_{1}\\ B_{t_1} - t_{1} B_{1} \end{pmatrix}\\ &= \bigg\{ \begin{pmatrix} 1&{}&{}\\ {}&\ddots&{}\\ {}&{}&1 \end{pmatrix}- \begin{pmatrix} (1-t_p)&\cdots&(1-t_p)\\ (t_p -t_{p-1})&\cdots&(t_p - t_{p-1})\\ \vdots&{}&\vdots\\ t_{1}&\cdots&t_1 \end{pmatrix} \bigg\} \begin{pmatrix} B_{1}-B_{t_p}\\ B_{t_p}-B_{t_{p-1}}\\ \vdots\\ B_{t_2}-B_{t_1}\\ B_{t_1} \end{pmatrix}. \end{align*} The matrix in curly braces is equal to $$ \begin{pmatrix} 1&{}&{}\\ {}&\ddots &{}\\ {}&{}&1 \end{pmatrix} - \begin{pmatrix} 1-t_p\\ \vdots\\ t_1 \end{pmatrix} \begin{pmatrix}1&\cdots&1\end{pmatrix}. $$ This is a rank-p $(p+1)\times (p+1)$ matrix. And thus, change of variables is not possible. Attempt 3: Let us first consider the density of the increments $W_{t_1}, W_{t_2}-W_{t_1}, \dots, W_{t_p}-W_{t_{p-1}}, W_{1}-W_{t_p}$ , and factor it by successively conditioning $$ g(W_{t_1}, W_{t_2}-W_{t_1},\dots, W_{1}-W_{t_p})= g(W_{1}-W_{t_p}|W_{t_{p-1}}-W_{t_{p-2}},\dots, W_{t_1})\cdots g(W_{t_1}). $$ One can compute that \begin{align*} g(W_{t_1})&= \sqrt{2\pi} p_{t_1}(W_{t_1})p_{1-t_1}(-W_{t_1})\\ &= \frac{\sqrt{2\pi}}{\sqrt{2\pi t_1}\sqrt{2\pi (1-t_1)}}\exp\bigg( -\frac{W_{t_1}^{2}}{2t_1}\bigg) \exp\bigg(-\frac{W_{t_1}^{2}}{2(1-t_1)}\bigg) \end{align*} This is promising, as we have the desired form for a product of distributions. The next step is computing the conditional distributions $g(W_{t_2}-W_{t_1}|W_{t_1})$ onwards.","I'm working through Le Gall's Brownian Motion, Martingales, and Stochastic Calculus , and I'm struggling on an exercise. The question concerns computing the finite-dimensional marginal distributions of a Brownian bridge. In particular, let be a Brownian motion on or (doesn't matter which), and for define the Brownian Bridge to be . I've shown that is a centered Gaussian process with covariance function . I'm now asked to prove that for , the law of has density where Solution Progress: Attempt 1: The density is factored into a bunch of products of Gaussian densities, where the variance of each is . This makes me want to relate the vector of Brownian Bridge terms to either the vector of Brownian motion or to the independent increments . Both of these vectors have densities which are a product of individual gaussians. We note that I would love to use a change of variables, but the issue is that I'm required to bring in the additional term, and so the linear transformation above maps -dimensional space into dimensional space. Thus, the determinant isn't defined. I'm not sure if I'm just being stupid, or this is really a problem? Attempt 2: Another approach I've thought of is that since the density factors into densities of differences, let's first focus on the density of . We have The matrix in curly braces is equal to This is a rank-p matrix. And thus, change of variables is not possible. Attempt 3: Let us first consider the density of the increments , and factor it by successively conditioning One can compute that This is promising, as we have the desired form for a product of distributions. The next step is computing the conditional distributions onwards.","B_{t} [0,1] \mathbb{R}^{+} t\in [0,1] W_t = B_t - t B_1 W_t K(s,t) = \min\{s,t\}- st 0<t_1<\cdots<t_p<1 (W_{t_1}, \dots, W_{t_p}) 
g(w_1, \dots, w_p) = \sqrt{2\pi} \,p_{t_1}(w_1)\,p_{t_2 - t_1}(w_2 - w_1)\,\cdots\, p_{t_p - t_{p-1}}(w_p-w_{p-1})\,p_{1-t_{p}}(-w_p),
 
p_{t}(w)= \frac{1}{\sqrt{2\pi t}}\exp(-w^2/2t).
 t_{i}-t_{i-1} (W_{t_1}, \dots, W_{t_p}) (B_{t_1}, \dots, B_{t_p}) (B_{t_1}-B_{0}, B_{t_2}-B_{t_1},\dots ,B_{t_p}-B_{t_{p-1}}) 
\begin{pmatrix}
W_{t_p}\\
\vdots\\
W_{t_1}
\end{pmatrix}=
\begin{pmatrix}
B_{t_p}-t_{p}B_{1}\\
\vdots\\
B_{t_1}-t_{1}B_{1}
\end{pmatrix}=
\begin{pmatrix}
-t_p&1&{}&{}&{}\\
-t_{p-1}&{}&1&{}&{}\\
\vdots&{}&{}&\ddots&{}\\
-t_1&{}&{}&{}&1
\end{pmatrix}
\begin{pmatrix}
B_{1}\\
B_{t_p}\\
\vdots\\
B_{t_1}
\end{pmatrix}
 B_1 p+1 p g(w_1, \dots, w_p) (W_1 - W_{t_p}, \dots, W_{t_2} - W_{t_1}, W_{t_1}) \begin{align*}
\begin{pmatrix}
W_{1} - W_{t_p}\\
W_{t_p}-W_{t_{p-1}}\\
\vdots\\
W_{t_2}-W_{t_1}\\
W_{t_1}
\end{pmatrix}&=
\begin{pmatrix}
(B_{1}-B_{t_p})-(1-t_p)B_{1}\\
(B_{t_p}-B_{t_{p-1}})-(t_{p}-t_{p-1})B_{1}\\
\vdots\\
(B_{t_2}-B_{t_1})-(t_2-t_1)B_{1}\\
B_{t_1} - t_{1} B_{1}
\end{pmatrix}\\
&=
\bigg\{
\begin{pmatrix}
1&{}&{}\\
{}&\ddots&{}\\
{}&{}&1
\end{pmatrix}-
\begin{pmatrix}
(1-t_p)&\cdots&(1-t_p)\\
(t_p -t_{p-1})&\cdots&(t_p - t_{p-1})\\
\vdots&{}&\vdots\\
t_{1}&\cdots&t_1
\end{pmatrix}
\bigg\}
\begin{pmatrix}
B_{1}-B_{t_p}\\
B_{t_p}-B_{t_{p-1}}\\
\vdots\\
B_{t_2}-B_{t_1}\\
B_{t_1}
\end{pmatrix}.
\end{align*} 
\begin{pmatrix}
1&{}&{}\\
{}&\ddots &{}\\
{}&{}&1
\end{pmatrix}
-
\begin{pmatrix}
1-t_p\\
\vdots\\
t_1
\end{pmatrix} \begin{pmatrix}1&\cdots&1\end{pmatrix}.
 (p+1)\times (p+1) W_{t_1}, W_{t_2}-W_{t_1}, \dots, W_{t_p}-W_{t_{p-1}}, W_{1}-W_{t_p} 
g(W_{t_1}, W_{t_2}-W_{t_1},\dots, W_{1}-W_{t_p})= g(W_{1}-W_{t_p}|W_{t_{p-1}}-W_{t_{p-2}},\dots, W_{t_1})\cdots g(W_{t_1}).
 \begin{align*}
g(W_{t_1})&= \sqrt{2\pi} p_{t_1}(W_{t_1})p_{1-t_1}(-W_{t_1})\\
&= \frac{\sqrt{2\pi}}{\sqrt{2\pi t_1}\sqrt{2\pi (1-t_1)}}\exp\bigg( -\frac{W_{t_1}^{2}}{2t_1}\bigg) \exp\bigg(-\frac{W_{t_1}^{2}}{2(1-t_1)}\bigg)
\end{align*} g(W_{t_2}-W_{t_1}|W_{t_1})","['probability', 'stochastic-processes', 'brownian-motion', 'marginal-distribution']"
90,Balls are placed into 3 urns. Expected time until some urn has 100 balls.,Balls are placed into 3 urns. Expected time until some urn has 100 balls.,,"We have $3$ urns. At each round a ball is placed is placed into one of them, at random, with uniform probability. The game stops when some urn has $100$ balls. What is expected duration of the game (number of rounds)? Results from a simulation:","We have urns. At each round a ball is placed is placed into one of them, at random, with uniform probability. The game stops when some urn has balls. What is expected duration of the game (number of rounds)? Results from a simulation:",3 100,"['probability', 'statistics', 'numerical-methods']"
91,"What Does ""Collection of Measure is Tight?'' Mean","What Does ""Collection of Measure is Tight?'' Mean",,"I know that a collection of probability measure $(\mu_\varepsilon )_{\varepsilon > 0}$ on a (topological) measure space $(X,\mu)$ is tight if for all $\varepsilon >0$ , there is a compact $K_\varepsilon \subset X$ such that $\mu_\varepsilon (K_\varepsilon)>1-\varepsilon $ for all $\varepsilon >0$ . Question : What does this mean concretely, and why is this important ?","I know that a collection of probability measure on a (topological) measure space is tight if for all , there is a compact such that for all . Question : What does this mean concretely, and why is this important ?","(\mu_\varepsilon )_{\varepsilon > 0} (X,\mu) \varepsilon >0 K_\varepsilon \subset X \mu_\varepsilon (K_\varepsilon)>1-\varepsilon  \varepsilon >0","['probability', 'measure-theory']"
92,Minimal example of Simpson's paradox,Minimal example of Simpson's paradox,,"Let's say that a finite probability space $(\Omega,\mathscr P(\Omega),P)$ has Simpson's property if you can find events $A,B,C\in\mathscr P(\Omega)$ such that $P(C) \in (0,1)$ . $A$ and $B$ are positively correlated: $P(A\cap B) > P(A)P(B)$ . $A$ and $B$ are negatively correlated conditionally to both $C$ and $\overline C$ : $$P(A\cap B\mid C) < P(A\mid C) P(B\mid C) \text{ and } P(A\cap B\mid\overline C) < P(A\mid\overline C)  P(B\mid\overline C).$$ One way to state Simpson's paradox is that there are probability spaces with Simpson's property. The cat-vs-human example given in this nice video , for instance, boils down to this: (The four small points each have a probability of $1/10$ , and the two big ones weigh $3/10$ each). My (very naïve and probably not very interesting) question is to know if it is possible to find a smaller example (with fewer points) and, if so, to find a provably minimal example.","Let's say that a finite probability space has Simpson's property if you can find events such that . and are positively correlated: . and are negatively correlated conditionally to both and : One way to state Simpson's paradox is that there are probability spaces with Simpson's property. The cat-vs-human example given in this nice video , for instance, boils down to this: (The four small points each have a probability of , and the two big ones weigh each). My (very naïve and probably not very interesting) question is to know if it is possible to find a smaller example (with fewer points) and, if so, to find a provably minimal example.","(\Omega,\mathscr P(\Omega),P) A,B,C\in\mathscr P(\Omega) P(C) \in (0,1) A B P(A\cap B) > P(A)P(B) A B C \overline C P(A\cap B\mid C) < P(A\mid C) P(B\mid C) \text{ and } P(A\cap B\mid\overline C) < P(A\mid\overline C)  P(B\mid\overline C). 1/10 3/10","['probability', 'statistics', 'conditional-probability', 'paradoxes']"
93,Understanding the central limit theorem,Understanding the central limit theorem,,"I am an aspiring probabilist, and I definitely know the central limit theorem. However, I am trying to understand what idea it really embodies. I am aware that normal distribution arises as the limit even when the averages are taken over non-independent random variables. But in some sense, it seems the correlations among the $X_i$ 's are weak. Is this intuition correct? In other words, when can we expect a central limit theorem? Is there some deeper notion embodied in this limit law? It is so universal, it seems it is quite mysterious...","I am an aspiring probabilist, and I definitely know the central limit theorem. However, I am trying to understand what idea it really embodies. I am aware that normal distribution arises as the limit even when the averages are taken over non-independent random variables. But in some sense, it seems the correlations among the 's are weak. Is this intuition correct? In other words, when can we expect a central limit theorem? Is there some deeper notion embodied in this limit law? It is so universal, it seems it is quite mysterious...",X_i,"['probability', 'central-limit-theorem']"
94,A car park has 10 empty spaces. 5 cars park in the car park. What is the probability of no two cars being parked next to each other?,A car park has 10 empty spaces. 5 cars park in the car park. What is the probability of no two cars being parked next to each other?,,"I have been trying to work out the answer to this question, but I don't have a markscheme so I'd like to confirm if I'm correct or not. I drew out the number of orientations in which no two cars are parked next to each other and found that there are 6 combinations that fit the criteria. I then found 6/(10C5), which gave me 6/252 or 1/42 as the probability. Is my working/answer correct?","I have been trying to work out the answer to this question, but I don't have a markscheme so I'd like to confirm if I'm correct or not. I drew out the number of orientations in which no two cars are parked next to each other and found that there are 6 combinations that fit the criteria. I then found 6/(10C5), which gave me 6/252 or 1/42 as the probability. Is my working/answer correct?",,"['probability', 'statistics']"
95,Probability of meeting,Probability of meeting,,This is a basic probability question. Persons A and B decide to arrive and meet sometime between 7 and 8 pm. Whoever arrives first will wait for ten minutes for the other person. If the other person doesn't turn up inside ten minutes then the person waiting will leave. What is the probability that they will meet? I am assuming uniform distribution for arrival time between 7 pm and 8 pm for both of them.,This is a basic probability question. Persons A and B decide to arrive and meet sometime between 7 and 8 pm. Whoever arrives first will wait for ten minutes for the other person. If the other person doesn't turn up inside ten minutes then the person waiting will leave. What is the probability that they will meet? I am assuming uniform distribution for arrival time between 7 pm and 8 pm for both of them.,,['probability']
96,What is the value of $m+n$??,What is the value of ??,m+n,Suppose that there are $5$ red points and $4$ blue points on a circle . Let $\frac{m}{n}$ be the probability that a convex polygon whose vertices are among the 9 points has at least one blue vertex when $m$ & $n$ are relatively prime. Then the value of $(m+n)$ is? This question came in recent JEE Advanced (unofficial) test and I'm stumped on how to approach this problem. The answer given is $460$ . I'm new to geometric probability and permutational concepts. Please someone help me out on how to approacch this problem.,Suppose that there are $5$ red points and $4$ blue points on a circle . Let $\frac{m}{n}$ be the probability that a convex polygon whose vertices are among the 9 points has at least one blue vertex when $m$ & $n$ are relatively prime. Then the value of $(m+n)$ is? This question came in recent JEE Advanced (unofficial) test and I'm stumped on how to approach this problem. The answer given is $460$ . I'm new to geometric probability and permutational concepts. Please someone help me out on how to approacch this problem.,,"['probability', 'permutations']"
97,How to calculate the expectation of the Wishart distribution?,How to calculate the expectation of the Wishart distribution?,,"Let $X \sim \mathcal{W}_p(V,\nu)$ follow a central Wishart distribution with scale matrix $V$ and $\nu$ degrees of freedom. Its p.d.f. is given by: $$ \frac{|\mathbf{X}|^{(\nu-p-1)/2} e^{-\operatorname{tr}(\mathbf{V}^{-1}\mathbf{X})/2}}{2^\frac{\nu p}{2}|{\mathbf V}|^{\nu/2}\Gamma_p(\frac \nu 2)}  $$ Its expectation is given by: $$ E[X]=\nu V $$ How do we actually calculate this expected value? What is the general procedure for matrix valued distributions?","Let $X \sim \mathcal{W}_p(V,\nu)$ follow a central Wishart distribution with scale matrix $V$ and $\nu$ degrees of freedom. Its p.d.f. is given by: $$ \frac{|\mathbf{X}|^{(\nu-p-1)/2} e^{-\operatorname{tr}(\mathbf{V}^{-1}\mathbf{X})/2}}{2^\frac{\nu p}{2}|{\mathbf V}|^{\nu/2}\Gamma_p(\frac \nu 2)}  $$ Its expectation is given by: $$ E[X]=\nu V $$ How do we actually calculate this expected value? What is the general procedure for matrix valued distributions?",,"['probability', 'probability-distributions', 'expectation', 'random-matrices']"
98,"On $Z = \max \left(X_1, X_2, \dots, X_N \right)$ where $X_i \sim \mathcal{N}(\mu_i, \sigma_i^2)$",On  where,"Z = \max \left(X_1, X_2, \dots, X_N \right) X_i \sim \mathcal{N}(\mu_i, \sigma_i^2)","How does the maximum of $N$ normal random variables behave? If they are i.i.d., then on the right tail ($x \rightarrow \infty$) it behaves as if it is distributed with Gumbel. But any results for the generic case? That is, how does $Z = \max \left(X_1, X_2, \dots, X_N \right)$ behave where $X_i \sim \mathcal{N}(\mu_i, \sigma_i^2)$, or with shared variance $X_i \sim \mathcal{N}(\mu_i, \sigma^2)$. I assume the shared variance & different mean case should behave similar to the i.i.d. case, but are there any known results?","How does the maximum of $N$ normal random variables behave? If they are i.i.d., then on the right tail ($x \rightarrow \infty$) it behaves as if it is distributed with Gumbel. But any results for the generic case? That is, how does $Z = \max \left(X_1, X_2, \dots, X_N \right)$ behave where $X_i \sim \mathcal{N}(\mu_i, \sigma_i^2)$, or with shared variance $X_i \sim \mathcal{N}(\mu_i, \sigma^2)$. I assume the shared variance & different mean case should behave similar to the i.i.d. case, but are there any known results?",,"['probability', 'probability-theory', 'random-variables', 'normal-distribution']"
99,Odds of winning Orchard Game?,Odds of winning Orchard Game?,,"I recently started playing the Orchard Game with my sons.  It is a simple children's game but I cannot figure out how to calculate the probability that you win.  Here are the setup/rules: There are 4 pieces of 4 different fruits (4 plums (blue), 4 green apples (green), 4 red apples (red) and 4 pears (yellow)). There is a bird There is a basket All the fruit starts outside the basket There are no teams, you rotate rolling the dice but everyone is on the same team On the dice there are 4 colors - one for each fruit - a basket and a bird If you roll a color of the fruit, you place one piece of that fruit in the basket.  If all four pieces of that fruit are in the basket, nothing happens If you roll the basket you can pick any one piece of any fruit you want and put it into the basket If you roll the bird the bird moves forward one space Win/loss You win if you get all the pieces of fruit into the basket before the bird moves 5 spaces.  If the bird moves 5 spaces before you get all the fruit into the basket you lose. What are the odds that you win?  The basket along with rolling a color when there is nothing of that color left complicates the calculation and it is beyond abilities. Thanks!","I recently started playing the Orchard Game with my sons.  It is a simple children's game but I cannot figure out how to calculate the probability that you win.  Here are the setup/rules: There are 4 pieces of 4 different fruits (4 plums (blue), 4 green apples (green), 4 red apples (red) and 4 pears (yellow)). There is a bird There is a basket All the fruit starts outside the basket There are no teams, you rotate rolling the dice but everyone is on the same team On the dice there are 4 colors - one for each fruit - a basket and a bird If you roll a color of the fruit, you place one piece of that fruit in the basket.  If all four pieces of that fruit are in the basket, nothing happens If you roll the basket you can pick any one piece of any fruit you want and put it into the basket If you roll the bird the bird moves forward one space Win/loss You win if you get all the pieces of fruit into the basket before the bird moves 5 spaces.  If the bird moves 5 spaces before you get all the fruit into the basket you lose. What are the odds that you win?  The basket along with rolling a color when there is nothing of that color left complicates the calculation and it is beyond abilities. Thanks!",,"['probability', 'recreational-mathematics']"
