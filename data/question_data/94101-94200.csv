,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Complex polynomials and lines of constant argument,Complex polynomials and lines of constant argument,,"Here are three domain plots of a complex polynomial of degree $5$ . The left picture is very zoomed out, and the right picture is more zoomed into the zeroes. (Pictures are taken from Elias Wegert's book "" Visual Complex Functions "".) The color indicates the argument of the function; the modulus is not featured. Say we focus our attention on one color, like yellow. Then we can see that the yellow lines coming in from infinity seem to ""end"" at the zeroes of the polynomial. My confusion is: I cannot justify why this should be the case in general. Why is it true that every yellow line (that is, a line of constant argument) coming in from infinity should terminate at a zero of the polynomial? It makes sense to me that around a zero of order $n$ , the polynomial should look like $z^n$ -- that is, there should be $n$ yellow lines emanating from that point. What is not clear to me, though, is why every yellow line coming in from infinity should terminate at a zero in particular. Why can't it terminate at any other point? Any suggestions / hints would be greatly appreciated. Thanks!","Here are three domain plots of a complex polynomial of degree . The left picture is very zoomed out, and the right picture is more zoomed into the zeroes. (Pictures are taken from Elias Wegert's book "" Visual Complex Functions "".) The color indicates the argument of the function; the modulus is not featured. Say we focus our attention on one color, like yellow. Then we can see that the yellow lines coming in from infinity seem to ""end"" at the zeroes of the polynomial. My confusion is: I cannot justify why this should be the case in general. Why is it true that every yellow line (that is, a line of constant argument) coming in from infinity should terminate at a zero of the polynomial? It makes sense to me that around a zero of order , the polynomial should look like -- that is, there should be yellow lines emanating from that point. What is not clear to me, though, is why every yellow line coming in from infinity should terminate at a zero in particular. Why can't it terminate at any other point? Any suggestions / hints would be greatly appreciated. Thanks!",5 n z^n n,"['complex-analysis', 'analysis']"
1,Estimate of Bernoulli numbers from the contour integral,Estimate of Bernoulli numbers from the contour integral,,"One knows (see https://mathworld.wolfram.com/BernoulliNumber.html ) that the Bernoulli number $B_n$ is $B_n=\frac{n!}{2i\pi}\int_{\mathcal C}\frac z{e^z-1}\frac{\mathrm dz}{z^{n+1}}$ , where $\mathcal C$ is a closed contour included in $\{z\in\mathbb C\mid |z|<2\pi\}$ . With this formula, is it possible to obtain the estimate: $|B_{2n}|\sim4\sqrt{\pi n}\left(\frac n{\pi e}\right)^n$ ? The proof I know depends on the zeta function, that I do not want to use.","One knows (see https://mathworld.wolfram.com/BernoulliNumber.html ) that the Bernoulli number is , where is a closed contour included in . With this formula, is it possible to obtain the estimate: ? The proof I know depends on the zeta function, that I do not want to use.",B_n B_n=\frac{n!}{2i\pi}\int_{\mathcal C}\frac z{e^z-1}\frac{\mathrm dz}{z^{n+1}} \mathcal C \{z\in\mathbb C\mid |z|<2\pi\} |B_{2n}|\sim4\sqrt{\pi n}\left(\frac n{\pi e}\right)^n,"['complex-analysis', 'number-theory']"
2,Understanding meromorphic/holomorphic forms on Riemann surface,Understanding meromorphic/holomorphic forms on Riemann surface,,"I refer to Rick Miranda - Algebraic curves and Riemann surfaces chapter IV.1 ( p. 105 , p. 106 , p. 107 ). I think I understand the regular Euclidean $\mathbb C$ case: the idea of meromorphic/holomorphic $1$ -form on open set $V_1$ of $\mathbb C$ : $\omega_1 = f(z)dz$ , for $f$ mero/holo function on $V$ and the idea of the transformation rule: for $\omega_2 = g(w)dw$ on open set $V_2$ of $\mathbb C$ with $g$ mero/holo on $V$ , we say that $\omega_1$ transforms to $\omega_2$ under $T$ if $g(w)=f(T(w))T'(w)$ for some holo $T: V_2 \to V_1$ Where it gets fuzzy for me is the case of Riemann surfaces. I wish Miranda would have 1st defined for charts on Riemann surface, but Miranda instead goes straight to Riemann surfaces. Apparently $\omega$ , a mero/holo $1$ -form on Riemann surface $X$ (in this book, all Riemann surfaces are connected), is a 'collection' (see (A1)) of mero/holo $$\{\omega_{\phi} | \phi: U \to V \ \text{is a chart in, I think, the max atlas of X}\} \tag{see (A2)}$$ such that for all charts $\phi_1: U_1 \to V_1$ , $\phi_2: U_2 \to V_2$ , with overlapping domains, we have that $\omega_{\phi_1}$ transforms to $\omega_{\phi_2}$ under $T=\phi_1 \circ \phi_2^{-1}$ . I guess this is $T: \phi_2(U_1 \cap U_2) \to \phi_1 (U_1 \cap U_2)$ . Ostensibly, we have that for, say, $\omega_{\phi_1}$ , the expression for $\omega_{\phi_1}$ is like ' $\omega_{\phi_1} = f_1(z) dz$ ', for coordinate $z = \phi_1(x)$ and some mero/holo $f_1=f_1(z)$ on open subset $V_1$ of $\mathbb C$ . But what I expected was something an expression involving some mero/holo $h_1=h_1(x)$ on the chart $U_1$ of $X$ , like $\omega$ is some map $$\omega: X \to \{\text{probably some bundle thing in complex geometry that I didn't learn yet}\},$$ where the restriction $\omega|_{U_1}$ is a well-defined (because of the transformation rule for overlapping domains) mero/holo $1$ -form on the chart domain $U_1$ ,  given as $\omega|_{U_1} = h_1(x) dx$ , where the ' $|_{U_1}$ ', is just omitted. And then we can map this from $X$ to $\mathbb C$ like maybe there's some correspondence to the mero/holo $1$ -form ' $\omega|_{V_1}$ ' on the chart image $V_1$ , given as something like $\omega|_{V_1} = (h_1 \circ \phi_1^{-1})(z) dz$ or even like $(h_1 \circ \phi_1^{-1})(z) d(\phi_1^{-1}(z))$ . This way $f_1 = h_1 \circ \phi_1^{-1}: \phi_1(U_1) =V_1 \to U_1 \to \mathbb C$ . Question 1 : Are $\omega$ 's indeed locally like $\omega|_U = h(x) dx$ and then converted from $X$ 's local coordinate $x$ on $U$ into $\mathbb C$ 's local coordinate $z$ on $V$ into ' $\omega|_{V}$ ' = $(h \circ \phi^{-1})(z) dz$ ? Question 2 : Later on, there's a definition for order. How should I understand the definition for order in terms of the above? In particular, is my definition as follows correct? The definition is given as ' $ord_p(\omega) := ord_0(f)$ ', for ' $\omega = f(z) dz$ ', where $z=\phi(x)$ , for chart $\phi: (U,p) \to (V,0)$ , centred at $p \in U$ . I understand this as $ord_p(\omega)$ $:= ord_{\{\phi(p)=0\}}(f \circ \phi^{-1}(z))$ , for $\omega|_V = (f \circ \phi_1^{-1})(z) dz$ , which in turn is from $\omega|_U = f(x) dx$ . Therefore, I can make this kind of definition chain: $ord_p(\omega) := ord_p(\omega|_U)$ and then $ord_p(\omega|_U) := ord_p(f)$ (and then finally $ord_p(f) := ord_{\{\phi(p)=0\}} (f \circ \phi^{-1})$ ). In particular, this is why I was hoping we would 1st have a definition for $1$ -forms on charts: like if a Riemann surface $X$ is covered by a single chart $\phi: U = X \to V$ then we can do for its 1-forms $\omega$ like $ord_p(\omega|_U) := ord_p(f)$ (where $\omega$ = $\omega|_U$ since $U=X$ ). Question 2.1 : Btw, for the original definition of ' $ord_p(\omega) := ord_0(f)$ ', for ' $\omega = f(z) dz$ ', can I just instead of any chart, that's not necessarily centred at $p$ ? This way, I would define $ord_p(\omega) := ord_{\phi(p)}(f)$ , whether or not the chart $\phi: U \to V$ , that gives us the local coordinate $z=\phi(x)$ , is centred at $p$ . Of course, it's more convenient to have Laurent series about 0, but just wondering if there's anything particular about the number 0. Edit: Btw, there's also this thing in the text (but this is on 2-forms now) i noticed that goes like $$\int \int_{T} \eta = \int \int_{\phi(T)} f(z, \overline z) dz \wedge d \overline z,$$ where ' $\eta = f(z, \overline z) dz \wedge d \overline z$ '. I mean, if ' $\eta = f(z, \overline z) dz \wedge d \overline z$ ', then one might think you wouldn't have to change the region of integration when replacing $\eta$ with $f(z, \overline z) dz \wedge d \overline z$ . If this were 1-form, like $\eta = f(z) dz$ , I'd think ' $f(z)$ ' is actually like $f \circ \phi^{-1}(z)$ (A1): I guess similar to how a holo function on a non-connected open set is a 'collection' of holo functions on connected open sets. (A2): I think initially mero/holo $1$ -form is defined in Def IV.1.7/3 for every chart in max atlas and then later it's defined for every chart in an atlas in Lemma IV.1.8/4.","I refer to Rick Miranda - Algebraic curves and Riemann surfaces chapter IV.1 ( p. 105 , p. 106 , p. 107 ). I think I understand the regular Euclidean case: the idea of meromorphic/holomorphic -form on open set of : , for mero/holo function on and the idea of the transformation rule: for on open set of with mero/holo on , we say that transforms to under if for some holo Where it gets fuzzy for me is the case of Riemann surfaces. I wish Miranda would have 1st defined for charts on Riemann surface, but Miranda instead goes straight to Riemann surfaces. Apparently , a mero/holo -form on Riemann surface (in this book, all Riemann surfaces are connected), is a 'collection' (see (A1)) of mero/holo such that for all charts , , with overlapping domains, we have that transforms to under . I guess this is . Ostensibly, we have that for, say, , the expression for is like ' ', for coordinate and some mero/holo on open subset of . But what I expected was something an expression involving some mero/holo on the chart of , like is some map where the restriction is a well-defined (because of the transformation rule for overlapping domains) mero/holo -form on the chart domain ,  given as , where the ' ', is just omitted. And then we can map this from to like maybe there's some correspondence to the mero/holo -form ' ' on the chart image , given as something like or even like . This way . Question 1 : Are 's indeed locally like and then converted from 's local coordinate on into 's local coordinate on into ' ' = ? Question 2 : Later on, there's a definition for order. How should I understand the definition for order in terms of the above? In particular, is my definition as follows correct? The definition is given as ' ', for ' ', where , for chart , centred at . I understand this as , for , which in turn is from . Therefore, I can make this kind of definition chain: and then (and then finally ). In particular, this is why I was hoping we would 1st have a definition for -forms on charts: like if a Riemann surface is covered by a single chart then we can do for its 1-forms like (where = since ). Question 2.1 : Btw, for the original definition of ' ', for ' ', can I just instead of any chart, that's not necessarily centred at ? This way, I would define , whether or not the chart , that gives us the local coordinate , is centred at . Of course, it's more convenient to have Laurent series about 0, but just wondering if there's anything particular about the number 0. Edit: Btw, there's also this thing in the text (but this is on 2-forms now) i noticed that goes like where ' '. I mean, if ' ', then one might think you wouldn't have to change the region of integration when replacing with . If this were 1-form, like , I'd think ' ' is actually like (A1): I guess similar to how a holo function on a non-connected open set is a 'collection' of holo functions on connected open sets. (A2): I think initially mero/holo -form is defined in Def IV.1.7/3 for every chart in max atlas and then later it's defined for every chart in an atlas in Lemma IV.1.8/4.","\mathbb C 1 V_1 \mathbb C \omega_1 = f(z)dz f V \omega_2 = g(w)dw V_2 \mathbb C g V \omega_1 \omega_2 T g(w)=f(T(w))T'(w) T: V_2 \to V_1 \omega 1 X \{\omega_{\phi} | \phi: U \to V \ \text{is a chart in, I think, the max atlas of X}\} \tag{see (A2)} \phi_1: U_1 \to V_1 \phi_2: U_2 \to V_2 \omega_{\phi_1} \omega_{\phi_2} T=\phi_1 \circ \phi_2^{-1} T: \phi_2(U_1 \cap U_2) \to \phi_1 (U_1 \cap U_2) \omega_{\phi_1} \omega_{\phi_1} \omega_{\phi_1} = f_1(z) dz z = \phi_1(x) f_1=f_1(z) V_1 \mathbb C h_1=h_1(x) U_1 X \omega \omega: X \to \{\text{probably some bundle thing in complex geometry that I didn't learn yet}\}, \omega|_{U_1} 1 U_1 \omega|_{U_1} = h_1(x) dx |_{U_1} X \mathbb C 1 \omega|_{V_1} V_1 \omega|_{V_1} = (h_1 \circ \phi_1^{-1})(z) dz (h_1 \circ \phi_1^{-1})(z) d(\phi_1^{-1}(z)) f_1 = h_1 \circ \phi_1^{-1}: \phi_1(U_1) =V_1 \to U_1 \to \mathbb C \omega \omega|_U = h(x) dx X x U \mathbb C z V \omega|_{V} (h \circ \phi^{-1})(z) dz ord_p(\omega) := ord_0(f) \omega = f(z) dz z=\phi(x) \phi: (U,p) \to (V,0) p \in U ord_p(\omega) := ord_{\{\phi(p)=0\}}(f \circ \phi^{-1}(z)) \omega|_V = (f \circ \phi_1^{-1})(z) dz \omega|_U = f(x) dx ord_p(\omega) := ord_p(\omega|_U) ord_p(\omega|_U) := ord_p(f) ord_p(f) := ord_{\{\phi(p)=0\}} (f \circ \phi^{-1}) 1 X \phi: U = X \to V \omega ord_p(\omega|_U) := ord_p(f) \omega \omega|_U U=X ord_p(\omega) := ord_0(f) \omega = f(z) dz p ord_p(\omega) := ord_{\phi(p)}(f) \phi: U \to V z=\phi(x) p \int \int_{T} \eta = \int \int_{\phi(T)} f(z, \overline z) dz \wedge d \overline z, \eta = f(z, \overline z) dz \wedge d \overline z \eta = f(z, \overline z) dz \wedge d \overline z \eta f(z, \overline z) dz \wedge d \overline z \eta = f(z) dz f(z) f \circ \phi^{-1}(z) 1","['complex-analysis', 'differential-geometry', 'complex-geometry', 'differential-forms', 'riemann-surfaces']"
3,Logarithm over complex numbers,Logarithm over complex numbers,,"The logarithm function is not certainly defined for every $\text{Re}(z)\leq0$ , but the question is where is it defined? I also know $\displaystyle \int_{C} \frac{1}{z} dz\neq0$ where $C$ is the unit circle defined by $ \gamma(t)=e^{it} $ for $0\leq t\leq 2\pi$ , which implies that $\frac{1}{z}$ has no antiderivative. Is this true because any set $U\supset C$ contains $z\in \mathbb{C}:Re(z)\leq0$ ? If $U$ does not contain $z\in \mathbb{C}:Re(z)\leq0$ , is $\log(z)$ ""well behaved"" in $U$ ?","The logarithm function is not certainly defined for every , but the question is where is it defined? I also know where is the unit circle defined by for , which implies that has no antiderivative. Is this true because any set contains ? If does not contain , is ""well behaved"" in ?",\text{Re}(z)\leq0 \displaystyle \int_{C} \frac{1}{z} dz\neq0 C  \gamma(t)=e^{it}  0\leq t\leq 2\pi \frac{1}{z} U\supset C z\in \mathbb{C}:Re(z)\leq0 U z\in \mathbb{C}:Re(z)\leq0 \log(z) U,['complex-analysis']
4,Proof of Morera's Theorem for Triangular Contours,Proof of Morera's Theorem for Triangular Contours,,"Sorry if this has been proven previously on MSE but I cannot find an obvious duplicate. I am attempting to prove the stronger version of Morera's theorem namely: If $f:U\mapsto\mathbb{C}$ is a continuous function on an open set $U$ such that $\int_\gamma f(z)\,\mathrm{d}z=0$ for all triangular contours $\gamma$ contained in $U$ , then $f$ is holomorphic on $U$ . Proof (attempt): Let $a\in U$ . Since $U$ is open, $\exists\,r\gt0$ such that $B(a,r)=\{z\in\mathbb{C}:|z-a|\lt r\}\subseteq U$ . Now consider $f$ restricted to the domain $B(a,r)$ . Using the given assumptions, this restriction of $f$ is continuous and satisfies $\int_\gamma f(z)\,\mathrm{d}z=0$ for all triangular contours $\gamma$ contained in $B(a,r)$ . Then we can define $F:B(a,r)\mapsto\mathbb{C}$ by $$F(z)=\int_{[a,z]}f(w)\,\mathrm{d}w$$ where $[a,z]$ is the line segment from $a$ to $z$ in $\mathbb{C}$ . This function is now well-defined as $B(a,r)$ is connected. Next we can calculate \begin{align} F'(z) &=\lim_{h\to0}\frac{F(z+h)-F(z)}h\\ &=\lim_{h\to0}\frac{\int_{[a,z+h]}f(w)\,\mathrm{d}w-\int_{[a,z]}f(w)\,\mathrm{d}w}h\\ &=\lim_{h\to0}\frac{\overbrace{\int_{[a,z+h]}f(w)\,\mathrm{d}w+\int_{[z+h,z]}f(w)\,\mathrm{d}w+\int_{[z,a]}f(w)\,\mathrm{d}w}^{=\int_\gamma f(w)\,\mathrm{d}w=0}+\int_{[z,z+h]}f(w)\,\mathrm{d}w}h\\ &=\lim_{h\to0}\frac{\int_{[z,z+h]}f(w)\,\mathrm{d}w}h\\ &=\lim_{h\to0}\frac1h\int_0^1f(z+ht)\cdot h\,\mathrm{d}t\\ &=\lim_{h\to0}\int_0^1f(z+ht)\,\mathrm{d}t\\ &=\int_0^1\lim_{h\to0}f(z+ht)\,\mathrm{d}t\\ &=\int_0^1f(z)\,\mathrm{d}t\qquad(f\text{ continuous})\\ &=f(z)\\ \end{align} Thus $F$ is holomorphic on $B(a,r)$ with derivative $f$ . So, in particular, we can apply Cauchy's differentiation formula to give $$f'(a)=F''(a)=\frac1{\pi i}\int_\gamma\frac{F(z)}{(z-a)^3}\mathrm{d}z$$ for a suitable contour $\gamma$ . But $a\in U$ was chosen arbitrarily and hence $f$ is holomorphic on $U$ .","Sorry if this has been proven previously on MSE but I cannot find an obvious duplicate. I am attempting to prove the stronger version of Morera's theorem namely: If is a continuous function on an open set such that for all triangular contours contained in , then is holomorphic on . Proof (attempt): Let . Since is open, such that . Now consider restricted to the domain . Using the given assumptions, this restriction of is continuous and satisfies for all triangular contours contained in . Then we can define by where is the line segment from to in . This function is now well-defined as is connected. Next we can calculate Thus is holomorphic on with derivative . So, in particular, we can apply Cauchy's differentiation formula to give for a suitable contour . But was chosen arbitrarily and hence is holomorphic on .","f:U\mapsto\mathbb{C} U \int_\gamma f(z)\,\mathrm{d}z=0 \gamma U f U a\in U U \exists\,r\gt0 B(a,r)=\{z\in\mathbb{C}:|z-a|\lt r\}\subseteq U f B(a,r) f \int_\gamma f(z)\,\mathrm{d}z=0 \gamma B(a,r) F:B(a,r)\mapsto\mathbb{C} F(z)=\int_{[a,z]}f(w)\,\mathrm{d}w [a,z] a z \mathbb{C} B(a,r) \begin{align}
F'(z)
&=\lim_{h\to0}\frac{F(z+h)-F(z)}h\\
&=\lim_{h\to0}\frac{\int_{[a,z+h]}f(w)\,\mathrm{d}w-\int_{[a,z]}f(w)\,\mathrm{d}w}h\\
&=\lim_{h\to0}\frac{\overbrace{\int_{[a,z+h]}f(w)\,\mathrm{d}w+\int_{[z+h,z]}f(w)\,\mathrm{d}w+\int_{[z,a]}f(w)\,\mathrm{d}w}^{=\int_\gamma f(w)\,\mathrm{d}w=0}+\int_{[z,z+h]}f(w)\,\mathrm{d}w}h\\
&=\lim_{h\to0}\frac{\int_{[z,z+h]}f(w)\,\mathrm{d}w}h\\
&=\lim_{h\to0}\frac1h\int_0^1f(z+ht)\cdot h\,\mathrm{d}t\\
&=\lim_{h\to0}\int_0^1f(z+ht)\,\mathrm{d}t\\
&=\int_0^1\lim_{h\to0}f(z+ht)\,\mathrm{d}t\\
&=\int_0^1f(z)\,\mathrm{d}t\qquad(f\text{ continuous})\\
&=f(z)\\
\end{align} F B(a,r) f f'(a)=F''(a)=\frac1{\pi i}\int_\gamma\frac{F(z)}{(z-a)^3}\mathrm{d}z \gamma a\in U f U","['complex-analysis', 'solution-verification', 'contour-integration', 'cauchy-integral-formula']"
5,A kind of isoperimetric inequality for polynomials?,A kind of isoperimetric inequality for polynomials?,,"During my programming of an app I stumbled upon the following question: Suppose you are given a monic polynomial $f \in \mathbb{C}[x]$ . Consider $f$ as a function and let $D \subset \mathbb{C}$ be the unit disc in the target complex plane. Then we can compute the volume $V_f := \int_{f^{-1}(D)} 1 dx$ of the preimage of $D$ with respect to the Lebesgue measure $dx$ on the source. Computational experiments yield that there is an upper bound on $V_f$ as $f$ ranges over all (Edit) monic polynomials. My guess is that the maximum is achieved whenever $f$ has exactly one root of multiplicity $n = \operatorname{deg} f$ . To me, this is very similar to the isoperimetric inequality in the sense that we are looking for an ""optimal shape"" determined by the polynomial $f$ in order to maximize a volume. Yet, I do not know of any mathematics that treat this or a related question. Do you?","During my programming of an app I stumbled upon the following question: Suppose you are given a monic polynomial . Consider as a function and let be the unit disc in the target complex plane. Then we can compute the volume of the preimage of with respect to the Lebesgue measure on the source. Computational experiments yield that there is an upper bound on as ranges over all (Edit) monic polynomials. My guess is that the maximum is achieved whenever has exactly one root of multiplicity . To me, this is very similar to the isoperimetric inequality in the sense that we are looking for an ""optimal shape"" determined by the polynomial in order to maximize a volume. Yet, I do not know of any mathematics that treat this or a related question. Do you?",f \in \mathbb{C}[x] f D \subset \mathbb{C} V_f := \int_{f^{-1}(D)} 1 dx D dx V_f f f n = \operatorname{deg} f f,"['complex-analysis', 'measure-theory', 'euler-lagrange-equation']"
6,Complex Ordinary Differential Equations,Complex Ordinary Differential Equations,,"I would like to understand a bit on complex ordinary differential equations, since I just learned some theorems on complex integration. So I proposed my-self to solve the following one: $$f(z) = f'(z), \,\,\,\, f(1)=z_0$$ Let's suppose $f$ is analytic on $D$ such that the initial value is in. If it were a real ODE, that would could be solved through separation of variables. But that's not the case here, since we would have to integrate over a path. Any ideas or even the solution would be appreciated. However, I also would like to read any book on this subject. Thanks EDIT Well, as far as I know. There may be two ways: 1) Integrate $f$ over a rectifiable path and use the FTC for complex functions or 2) Separate $f$ into real and imaginary parts. The thing is, how do to the first way. Any ideas or comments?","I would like to understand a bit on complex ordinary differential equations, since I just learned some theorems on complex integration. So I proposed my-self to solve the following one: Let's suppose is analytic on such that the initial value is in. If it were a real ODE, that would could be solved through separation of variables. But that's not the case here, since we would have to integrate over a path. Any ideas or even the solution would be appreciated. However, I also would like to read any book on this subject. Thanks EDIT Well, as far as I know. There may be two ways: 1) Integrate over a rectifiable path and use the FTC for complex functions or 2) Separate into real and imaginary parts. The thing is, how do to the first way. Any ideas or comments?","f(z) = f'(z), \,\,\,\, f(1)=z_0 f D f f","['complex-analysis', 'ordinary-differential-equations', 'complex-integration']"
7,A function that satisfies Cauchy-Riemann but is not holomorphic,A function that satisfies Cauchy-Riemann but is not holomorphic,,"I'm attempting Chapter 1, Exercise 12 in Stein & Shakarchi's Complex Analysis , which is as follows: Consider the function defined by $$f(x+iy) = \sqrt{|x||y|}$$ whenever $x, y \in \mathbb{R}$ . Show that $f$ satisfies the Cauchy-Riemann equations at the origin, yet $f$ is not holomorphic at $0$ . I think that I have solved it, but since I don't have much experience with complex analysis, I'm not sure if my argument is valid/correct: If, for $x, y \in \mathbb{R}$ , we write $$f(x+iy) = \sqrt{|x||y|} = u(x,y)$$ and $v(x,y) = 0$ , since $f$ is a real-valued function, then, for $h \in \mathbb{R}$ , $$\frac{\partial u}{\partial x} = \lim_{h\rightarrow 0} \frac{u(x+h,y)-u(x,y)}{h} = \lim_{h\rightarrow 0}\frac{0}{h} = 0 = \frac{\partial v}{\partial y}$$ and similarly we find that $\partial u/\partial y = 0 = -\partial v/\partial x$ , so this function satisfies the Cauchy-Riemann equations. Now, for $h = h_1 + ih_2 \in \mathbb{C}$ , $$\lim_{h\rightarrow 0} \frac{f(z+h)-f(z)}{h} = \lim_{h\rightarrow 0} \frac{\sqrt{|h_1||h_2|}}{h_1+ih_2}$$ at the origin. Suppose that $h_1 = ab = h_2$ for real numbers $a,b > 0$ . Then $$\lim_{h\rightarrow 0} \frac{f(z+h)-f(z)}{h} = \lim_{ab\rightarrow 0} \frac{ab}{ab + iab} = \frac{1}{1+i}.$$ But if instead $h_1 = -ab = -h_2$ , then $$\lim_{h\rightarrow 0} \frac{f(z+h)-f(z)}{h} = \lim_{ab\rightarrow 0} \frac{ab}{-ab + iab} = \frac{1}{-1+i},$$ so the limit does not exist and hence $f$ is not holomorphic at the origin. I would greatly appreciate if somebody could check the above for correctness. (In particular, can I just assume that the $ab$ factorization exists? And is it sufficient to show that the limit is not the same by approaching from different directions?)","I'm attempting Chapter 1, Exercise 12 in Stein & Shakarchi's Complex Analysis , which is as follows: Consider the function defined by whenever . Show that satisfies the Cauchy-Riemann equations at the origin, yet is not holomorphic at . I think that I have solved it, but since I don't have much experience with complex analysis, I'm not sure if my argument is valid/correct: If, for , we write and , since is a real-valued function, then, for , and similarly we find that , so this function satisfies the Cauchy-Riemann equations. Now, for , at the origin. Suppose that for real numbers . Then But if instead , then so the limit does not exist and hence is not holomorphic at the origin. I would greatly appreciate if somebody could check the above for correctness. (In particular, can I just assume that the factorization exists? And is it sufficient to show that the limit is not the same by approaching from different directions?)","f(x+iy) = \sqrt{|x||y|} x, y \in \mathbb{R} f f 0 x, y \in \mathbb{R} f(x+iy) = \sqrt{|x||y|} = u(x,y) v(x,y) = 0 f h \in \mathbb{R} \frac{\partial u}{\partial x} = \lim_{h\rightarrow 0} \frac{u(x+h,y)-u(x,y)}{h} = \lim_{h\rightarrow 0}\frac{0}{h} = 0 = \frac{\partial v}{\partial y} \partial u/\partial y = 0 = -\partial v/\partial x h = h_1 + ih_2 \in \mathbb{C} \lim_{h\rightarrow 0} \frac{f(z+h)-f(z)}{h} = \lim_{h\rightarrow 0} \frac{\sqrt{|h_1||h_2|}}{h_1+ih_2} h_1 = ab = h_2 a,b > 0 \lim_{h\rightarrow 0} \frac{f(z+h)-f(z)}{h} = \lim_{ab\rightarrow 0} \frac{ab}{ab + iab} = \frac{1}{1+i}. h_1 = -ab = -h_2 \lim_{h\rightarrow 0} \frac{f(z+h)-f(z)}{h} = \lim_{ab\rightarrow 0} \frac{ab}{-ab + iab} = \frac{1}{-1+i}, f ab",['complex-analysis']
8,Equation of the type polynomial${}= \bar{z}$,Equation of the type polynomial,{}= \bar{z},"Let $P(z)$ be a complex polynomial of degree 3. How many roots equation $P(z) = \bar{z}$ could have? I had tried the following ideas but was unable to push through: Research the ring $\mathbb{C}[X]\otimes \mathbb{C}[\bar{X}]$ and ideals of it that annul specific amount of points. But polynomials like $X - \bar X$ had spoiled this idea, maybe it would be better if we will limit ourselves to polynomial with different inversion degree and straight degree but no idea how to approach it further Try to find out how polynomials twist the space and find amount of points that are gluing together and their image is a symmetry relative to real line, i had stopped at trivial case $aX^3$ and it was hard to add another degree. All polynomials of degree 3 are path-connected in $\mathbb{C}$ . Maybe I can find out that amount of solutions of $P(z) = \bar z$ is some nice characteristic of polynomials that have some properties to use. But this one was quite desperate measure already.","Let be a complex polynomial of degree 3. How many roots equation could have? I had tried the following ideas but was unable to push through: Research the ring and ideals of it that annul specific amount of points. But polynomials like had spoiled this idea, maybe it would be better if we will limit ourselves to polynomial with different inversion degree and straight degree but no idea how to approach it further Try to find out how polynomials twist the space and find amount of points that are gluing together and their image is a symmetry relative to real line, i had stopped at trivial case and it was hard to add another degree. All polynomials of degree 3 are path-connected in . Maybe I can find out that amount of solutions of is some nice characteristic of polynomials that have some properties to use. But this one was quite desperate measure already.",P(z) P(z) = \bar{z} \mathbb{C}[X]\otimes \mathbb{C}[\bar{X}] X - \bar X aX^3 \mathbb{C} P(z) = \bar z,"['complex-analysis', 'polynomials']"
9,Isometric isomorphism between Hardy Space $h^p(\mathbb{D})$ and $L^p(\mathbb{T})$,Isometric isomorphism between Hardy Space  and,h^p(\mathbb{D}) L^p(\mathbb{T}),"I know the question below is a known result but, I would need some help to prove it! Well, I know that in the Poisson integral induces an isometric isomorphism between $L^p(\mathbb{T})$ and the Hardy space $h^p(\mathbb{D})$ for $p>1$ . I'm reading Function Spaces and Partial Differential Equations: Classical analysis and this question is the remark 5.24 but it's not proved. Now how can I do to prove this? Thanks. EDIT: The definition of $h^p$ that I have is this: $h^p(\mathbb{D})=\{u\in Har{\mathbb{D}: ||u||_{h^p}=sup_{0<r<1}M_{p}(u,r)< \infty}$ }, where the $Har\{\mathbb{D}\}$ are the group of harmonic functions while $M_{p}(u,r)=(\int_{-\pi}^{\pi}|u(re^{it})|^p\frac{dt}{2 \pi})^\frac{1}{p}$ .","I know the question below is a known result but, I would need some help to prove it! Well, I know that in the Poisson integral induces an isometric isomorphism between and the Hardy space for . I'm reading Function Spaces and Partial Differential Equations: Classical analysis and this question is the remark 5.24 but it's not proved. Now how can I do to prove this? Thanks. EDIT: The definition of that I have is this: }, where the are the group of harmonic functions while .","L^p(\mathbb{T}) h^p(\mathbb{D}) p>1 h^p h^p(\mathbb{D})=\{u\in Har{\mathbb{D}: ||u||_{h^p}=sup_{0<r<1}M_{p}(u,r)< \infty} Har\{\mathbb{D}\} M_{p}(u,r)=(\int_{-\pi}^{\pi}|u(re^{it})|^p\frac{dt}{2 \pi})^\frac{1}{p}","['complex-analysis', 'harmonic-analysis', 'group-isomorphism', 'isometry']"
10,Help with the Euler-type integral $\int_{0}^{m}\frac{1-e^{2\pi i x}}{x-j}\frac{x^{s-1}}{(1+x)^{z}}dx$,Help with the Euler-type integral,\int_{0}^{m}\frac{1-e^{2\pi i x}}{x-j}\frac{x^{s-1}}{(1+x)^{z}}dx,"Consider the integral : $$I=\int_{0}^{m}\frac{1-e^{2\pi i x}}{x-j}\frac{x^{s-1}}{(1+x)^{z}}dx\;\;\;\;s,z\in\mathbb{C}\;\;\;\;j,m \in \mathbb{N}\;\;0\leq j\leq m$$ i have tried using the Mellin integral representation of $\frac{1}{(1+x)^{z}}$ , which is given in terms of the beta function, but that didn't get me anywhere. I have tried using the generalized binomial theorem, and split the integral at $1$ , but that didn't get me anywhere either. Any help is highly appreciated. EDIT Using the Taylor expansion : $$\frac{1-e^{2\pi i x}}{x-j}=-\sum_{n=0}^{\infty}\frac{(2\pi  i)^{n+1}}{(n+1)!}(x-j)^{n}$$ And substituting $x=my$ , we have : $$I=-m^{s}\sum_{n=0}^{\infty}\frac{(2\pi  i)^{n+1}}{(n+1)!}\int_{0}^{1}(my-j)^{n}\frac{y^{s-1}}{(1+my)^{z}}dy$$ Using the integral representation of the Appell's hypergeometric function : $$F_{1}(a,b_{1},b_{2},c,x,y)=\frac{\Gamma(c)}{\Gamma(a)\Gamma(c-a)}\int_{0}^{1}t^{a-1}(1-t)^{c-a-1}(1-xt)^{-b_{1}}(1-yt)^{-b_{2}}dt$$ we have : $$I=\frac{m^{s}}{sj}\sum_{n=0}^{\infty}\frac{(-2\pi i j)^{n+1}}{(n+1)!}F_{1}\left(s,z,-n,s+1,-m,\frac{m}{j}\right)$$ Now, is there any way to simplify this, say, using the exponential generating function of $F_{1}(\cdot)$ ? i have looked for one, but could find any !","Consider the integral : i have tried using the Mellin integral representation of , which is given in terms of the beta function, but that didn't get me anywhere. I have tried using the generalized binomial theorem, and split the integral at , but that didn't get me anywhere either. Any help is highly appreciated. EDIT Using the Taylor expansion : And substituting , we have : Using the integral representation of the Appell's hypergeometric function : we have : Now, is there any way to simplify this, say, using the exponential generating function of ? i have looked for one, but could find any !","I=\int_{0}^{m}\frac{1-e^{2\pi i x}}{x-j}\frac{x^{s-1}}{(1+x)^{z}}dx\;\;\;\;s,z\in\mathbb{C}\;\;\;\;j,m \in \mathbb{N}\;\;0\leq j\leq m \frac{1}{(1+x)^{z}} 1 \frac{1-e^{2\pi i x}}{x-j}=-\sum_{n=0}^{\infty}\frac{(2\pi  i)^{n+1}}{(n+1)!}(x-j)^{n} x=my I=-m^{s}\sum_{n=0}^{\infty}\frac{(2\pi  i)^{n+1}}{(n+1)!}\int_{0}^{1}(my-j)^{n}\frac{y^{s-1}}{(1+my)^{z}}dy F_{1}(a,b_{1},b_{2},c,x,y)=\frac{\Gamma(c)}{\Gamma(a)\Gamma(c-a)}\int_{0}^{1}t^{a-1}(1-t)^{c-a-1}(1-xt)^{-b_{1}}(1-yt)^{-b_{2}}dt I=\frac{m^{s}}{sj}\sum_{n=0}^{\infty}\frac{(-2\pi i j)^{n+1}}{(n+1)!}F_{1}\left(s,z,-n,s+1,-m,\frac{m}{j}\right) F_{1}(\cdot)","['complex-analysis', 'definite-integrals', 'hypergeometric-function', 'beta-function', 'mellin-transform']"
11,"How to show the ""naive"" Weierstrass elliptic function does not converge absolutely","How to show the ""naive"" Weierstrass elliptic function does not converge absolutely",,"Several resources (e.g., Stein and Shakarchi, Complex Analysis) begin a discussion of the Weierstrass $\wp$ function by saying that, in order to construct a doubly periodic meromorphic function with lattice $L$ , a good first guess is the function $$ f(z) = \sum_{\omega \in L}\frac{1}{(z-\omega)^2}$$ however, the series fails to converge absolutely, which is why the $\wp$ function is defined the way it is.  I cannot, however, find any resource that actually goes about showing why the series fails to converge.  Maybe it is a trivial calculation and I am just not seeing the answer, but could someone please rigorously show that this series fails to converge absolutely?  Part of the problem I am having in understanding this series is that it is indexed over a set that is not the positive integers, so I'm not sure what a partial sum would even look like exactly. Any help is greatly appreciated, thanks!","Several resources (e.g., Stein and Shakarchi, Complex Analysis) begin a discussion of the Weierstrass function by saying that, in order to construct a doubly periodic meromorphic function with lattice , a good first guess is the function however, the series fails to converge absolutely, which is why the function is defined the way it is.  I cannot, however, find any resource that actually goes about showing why the series fails to converge.  Maybe it is a trivial calculation and I am just not seeing the answer, but could someone please rigorously show that this series fails to converge absolutely?  Part of the problem I am having in understanding this series is that it is indexed over a set that is not the positive integers, so I'm not sure what a partial sum would even look like exactly. Any help is greatly appreciated, thanks!",\wp L  f(z) = \sum_{\omega \in L}\frac{1}{(z-\omega)^2} \wp,"['complex-analysis', 'elliptic-functions']"
12,Explain why Mandelbrot set escape radius is 2 to a dummy,Explain why Mandelbrot set escape radius is 2 to a dummy,,"I'm curious, in the Mandelbrot set, why is the escape radius $2$ ? I've seen few proofs of that on the internet, but i can't understand them enough. Why is the bailout value of the Mandelbrot set 2? Mandelbrot sets and radius of convergence https://mrob.com/pub/muency/escaperadius.html Some of the statements in them seem ""out of the blue"" for me. For example, in the second in-site link I gave above: $ |c|≤2 \Rightarrow|z_n+1|≥|z_n|2−|c|>2|z_n|−2$ Where does $2|z_n|−2$ come from?","I'm curious, in the Mandelbrot set, why is the escape radius ? I've seen few proofs of that on the internet, but i can't understand them enough. Why is the bailout value of the Mandelbrot set 2? Mandelbrot sets and radius of convergence https://mrob.com/pub/muency/escaperadius.html Some of the statements in them seem ""out of the blue"" for me. For example, in the second in-site link I gave above: Where does come from?",2  |c|≤2 \Rightarrow|z_n+1|≥|z_n|2−|c|>2|z_n|−2 2|z_n|−2,"['complex-analysis', 'complex-numbers', 'fractals']"
13,Issue when applying the residue theorem,Issue when applying the residue theorem,,"I encounter a problem when computing the following integral in two ways $$ \frac{1}{2\pi i}\int_\gamma \frac{e^{s^2}}{s\cosh(\pi As)}ds$$ where $\gamma$ is contour defined by the rectangle $[-1,1]\times[-K,K]$ , $AK\in\mathbb{N}$ and $A>0$ . On the one hand, the poles are $0$ and $iA^{-1}(k+1/2)$ with $k$ integer with residue (respectively) $1$ and $(-1)^{k+1}i\pi^{-1} e^{-(k+1/2)A^{-1}}(k+1/2)^{-1}$ . The real part of the integral must the be $1$ . On the other hand, one can bound directly the integral. For the vertical lines (for instance $\Re(s) = 1$ ), one gets $$\frac{1}{2\pi}\int_{-K}^K \frac{e^{(1+it)^2}}{(1+it)\cosh(\pi A(1+it))}dt\ll e^{-\pi A}$$ with the constant independant of $K$ . For the horizontal lines, one has $$\cosh(\pi A(x+iK))^{-1}\leq 2 $$ so the integrals are bounded by $O(e^{-K^2})$ with constant independant on $A$ . In the end, after applying the residue theorem, I get $$1-i\pi^{-1}\sum_{{|k+1/2|<K}} (-1)^{k}e^{-((k+1/2)A^{-1})^2}(k+1/2)^{-1} =O(e^{-\pi A}+e^{-K^2})$$ . Now taking the real part and $K\to \infty$ (everything is converging), I get a contradiction of the type $1 \ll e^{-A}$ which is stupid since $A$ can be as big as we want. I don't seem to find my mistake and any help would be welcome. EDIT: To be clear I will write how I get the estimates for the bounds on the vertical lines. First we have $\cosh(A\pi(\pm 1+it))^{-1}< 2e^{-\pi A}$ uniformly in $t$ . This gives $$ \left|\frac{1}{2\pi}\int_{-K}^K \frac{e^{(\pm 1+it)^2}}{(\pm 1+it)\cosh(\pi A(\pm 1+it))}dt\right|< 2e^{-\pi A}\frac{1}{2\pi}\int_{-K}^K \frac{e^{1-t^2}}{\sqrt{1+t^2}}dt<Ce^{-\pi A}$$ where $$ C = \pi^{-1}\int_{-\infty}^\infty \frac{e^{1-t^2}}{\sqrt{1+t^2}}dt.$$ EDIT 2: For the horizontal lines, let us use the fact that, for $-1\leq\sigma\leq 1$ , one has $|\cosh(\pi A \sigma \pm i\pi AK)| = |\cosh(\pi A \sigma)|\geq1$ since $AK$ was chosen to be an integer. This gives $$\left|\frac{1}{2\pi i}\int_{-1}^1\frac{e^{\sigma^2-K^2}}{(\sigma\pm iK)\cosh(\pi A(\sigma\pm iK))}d\sigma\right|\leq (2\pi K)^{-1}e^{-K^2}\int_{-1}^1e^{\sigma^2}d\sigma.$$ Clearly, when $K$ gets big this goes to $0$ .","I encounter a problem when computing the following integral in two ways where is contour defined by the rectangle , and . On the one hand, the poles are and with integer with residue (respectively) and . The real part of the integral must the be . On the other hand, one can bound directly the integral. For the vertical lines (for instance ), one gets with the constant independant of . For the horizontal lines, one has so the integrals are bounded by with constant independant on . In the end, after applying the residue theorem, I get . Now taking the real part and (everything is converging), I get a contradiction of the type which is stupid since can be as big as we want. I don't seem to find my mistake and any help would be welcome. EDIT: To be clear I will write how I get the estimates for the bounds on the vertical lines. First we have uniformly in . This gives where EDIT 2: For the horizontal lines, let us use the fact that, for , one has since was chosen to be an integer. This gives Clearly, when gets big this goes to ."," \frac{1}{2\pi i}\int_\gamma \frac{e^{s^2}}{s\cosh(\pi As)}ds \gamma [-1,1]\times[-K,K] AK\in\mathbb{N} A>0 0 iA^{-1}(k+1/2) k 1 (-1)^{k+1}i\pi^{-1} e^{-(k+1/2)A^{-1}}(k+1/2)^{-1} 1 \Re(s) = 1 \frac{1}{2\pi}\int_{-K}^K \frac{e^{(1+it)^2}}{(1+it)\cosh(\pi A(1+it))}dt\ll e^{-\pi A} K \cosh(\pi A(x+iK))^{-1}\leq 2  O(e^{-K^2}) A 1-i\pi^{-1}\sum_{{|k+1/2|<K}} (-1)^{k}e^{-((k+1/2)A^{-1})^2}(k+1/2)^{-1} =O(e^{-\pi A}+e^{-K^2}) K\to \infty 1 \ll e^{-A} A \cosh(A\pi(\pm 1+it))^{-1}< 2e^{-\pi A} t  \left|\frac{1}{2\pi}\int_{-K}^K \frac{e^{(\pm 1+it)^2}}{(\pm 1+it)\cosh(\pi A(\pm 1+it))}dt\right|< 2e^{-\pi A}\frac{1}{2\pi}\int_{-K}^K \frac{e^{1-t^2}}{\sqrt{1+t^2}}dt<Ce^{-\pi A}  C = \pi^{-1}\int_{-\infty}^\infty \frac{e^{1-t^2}}{\sqrt{1+t^2}}dt. -1\leq\sigma\leq 1 |\cosh(\pi A \sigma \pm i\pi AK)| = |\cosh(\pi A \sigma)|\geq1 AK \left|\frac{1}{2\pi i}\int_{-1}^1\frac{e^{\sigma^2-K^2}}{(\sigma\pm iK)\cosh(\pi A(\sigma\pm iK))}d\sigma\right|\leq (2\pi K)^{-1}e^{-K^2}\int_{-1}^1e^{\sigma^2}d\sigma. K 0","['complex-analysis', 'contour-integration', 'residue-calculus']"
14,Non-real roots of $z^2=\sin(z)$,Non-real roots of,z^2=\sin(z),"What is the number of roots of $$z^2= \sin(z)$$ in $\left\{z\in\mathbb C\setminus\mathbb R\left||z|<2\right.\right\}$ ? This task is related to the Argument principle and Rouché's theorem. Maybe I should estimate $f(z)=z^2$ and $g(z)= \sin(z)$ using an inequality that would hold when $|z|<2$ . I would be grateful if you provide an explanation, so I could learn how to solve similar problems.","What is the number of roots of in ? This task is related to the Argument principle and Rouché's theorem. Maybe I should estimate and using an inequality that would hold when . I would be grateful if you provide an explanation, so I could learn how to solve similar problems.",z^2= \sin(z) \left\{z\in\mathbb C\setminus\mathbb R\left||z|<2\right.\right\} f(z)=z^2 g(z)= \sin(z) |z|<2,"['complex-analysis', 'rouches-theorem']"
15,An element $f$ that is integral over its affine coordinate ring: show there exists this open neighborhood,An element  that is integral over its affine coordinate ring: show there exists this open neighborhood,f,"(Recall first the following definition: Let $R$ be an integral domain and $K$ its field of fractions. An element $a \in K$ is called an integral element over $R$ if there exists a polynomial $g = x^n + a_{n-1} x^{n-1} + \ldots + a_1 x + a_0 \in R[x]$ such that $g(a) = 0$ . ) Problem: Consider an affine variety $X$ over $\mathbb{C}$ . Let $R = \mathbb{C}[x_1, \ldots, x_n] / I$ be its affine coordinate ring, and let $K$ be its field of fractions. Prove that if $f \in K$ is an integral element over $R$ , then for each point $x \in X$ there exists an open (in the usual Euclidean topology) neighborhood $U$ of $x$ and a real constant $B > 0$ such that $|f(y)| < B$ for all $y \in U$ where $f$ is regular. Show that this claim is false in general if $U$ is required to be Zariski open. Attempt: I'm given a hint that I should use the maximum principle for holomorphic functions. I don't really know how to find this open neighborhood $U$ . First, I believe that $K \cong \mathbb{C}(x_1, \ldots, x_n)/I$ (can someone confirm this)? So I assume $f \in K$ is integral over $R$ . By definition there exists a polynomial $p(t) \in R[t]$ such that $p(f) = 0$ . Can I assume that $f \in K$ is holomorphic? Any help with this problem is appreciated!","(Recall first the following definition: Let be an integral domain and its field of fractions. An element is called an integral element over if there exists a polynomial such that . ) Problem: Consider an affine variety over . Let be its affine coordinate ring, and let be its field of fractions. Prove that if is an integral element over , then for each point there exists an open (in the usual Euclidean topology) neighborhood of and a real constant such that for all where is regular. Show that this claim is false in general if is required to be Zariski open. Attempt: I'm given a hint that I should use the maximum principle for holomorphic functions. I don't really know how to find this open neighborhood . First, I believe that (can someone confirm this)? So I assume is integral over . By definition there exists a polynomial such that . Can I assume that is holomorphic? Any help with this problem is appreciated!","R K a \in K R g = x^n + a_{n-1} x^{n-1} + \ldots + a_1 x + a_0 \in R[x] g(a) = 0 X \mathbb{C} R = \mathbb{C}[x_1, \ldots, x_n] / I K f \in K R x \in X U x B > 0 |f(y)| < B y \in U f U U K \cong \mathbb{C}(x_1, \ldots, x_n)/I f \in K R p(t) \in R[t] p(f) = 0 f \in K","['complex-analysis', 'algebraic-geometry']"
16,How to prove $S^2$ has a unique complex structure without using the Riemann-Roch theorem?,How to prove  has a unique complex structure without using the Riemann-Roch theorem?,S^2,"It's known that $S^2$ has a unique complex structure, which can be proved using the Riemann-Roch theorem. Is there an elementary proof without using the Riemann-Roch theorem? By an ""elementary"" proof, I mean a proof using mainly techniques from complex analysis. In other words, suppose we were in the early to mid of 19th century (before 1865, so the Riemann-Roch theorem was not proved yet). So we didn't know future concepts such as divisors, line bundles, cohomology and even didn't know formal definitions of groups and rings. But we did have plenty knowledge of complex analysis. Suppose we knew how to define a complex manifold and we believed $S^2$ has a unique complex structure. How would we prove it?","It's known that has a unique complex structure, which can be proved using the Riemann-Roch theorem. Is there an elementary proof without using the Riemann-Roch theorem? By an ""elementary"" proof, I mean a proof using mainly techniques from complex analysis. In other words, suppose we were in the early to mid of 19th century (before 1865, so the Riemann-Roch theorem was not proved yet). So we didn't know future concepts such as divisors, line bundles, cohomology and even didn't know formal definitions of groups and rings. But we did have plenty knowledge of complex analysis. Suppose we knew how to define a complex manifold and we believed has a unique complex structure. How would we prove it?",S^2 S^2,"['complex-analysis', 'complex-geometry', 'math-history']"
17,Divergence of sum over lattice.,Divergence of sum over lattice.,,"This is  follow up to my last question on summing over countably infinite sets. I understand the idea conceptually now but I am still stuck when dealing with a concrete example. Specifically, consider $$\sum_{\omega \in \Lambda^*}\frac{1}{\omega^2}$$ where $\Lambda^*$ is a lattice in the complex plane without the origin. This sum has come up in several books when the author is defining the $\wp$ elliptic function. Apparently, it diverges but I haven't been able to find the details of why it does. Intuitively, I would think it would converge since for large $|\omega|$ one would expect $|1/\omega^2|$ to decay very rapidly. How would I even begin to analyze such a sum? I think the issue is my intuition from the sum $\sum \frac{1}{n^2}$ which does converge is corrupting my understanding. Thanks.","This is  follow up to my last question on summing over countably infinite sets. I understand the idea conceptually now but I am still stuck when dealing with a concrete example. Specifically, consider where is a lattice in the complex plane without the origin. This sum has come up in several books when the author is defining the elliptic function. Apparently, it diverges but I haven't been able to find the details of why it does. Intuitively, I would think it would converge since for large one would expect to decay very rapidly. How would I even begin to analyze such a sum? I think the issue is my intuition from the sum which does converge is corrupting my understanding. Thanks.",\sum_{\omega \in \Lambda^*}\frac{1}{\omega^2} \Lambda^* \wp |\omega| |1/\omega^2| \sum \frac{1}{n^2},"['complex-analysis', 'elliptic-functions']"
18,$f(z)=z^n+a_{n-1}z^{n-1}+\cdots+ a_0\in\mathbb Z[z]$ has all its roots on the unit circle. Prove that any root of $f(z)=0$ is a root of unity.,has all its roots on the unit circle. Prove that any root of  is a root of unity.,f(z)=z^n+a_{n-1}z^{n-1}+\cdots+ a_0\in\mathbb Z[z] f(z)=0,"Suppose that $f(z)=z^n+a_{n-1}z^{n-1}+\cdots+ a_0\in\mathbb Z[z]$ has all its roots on the unit circle in the complex plane. Prove that any root of $f(z)=0$ is a root of unity. This question has been asked before, yet it links to another MO post which proves a stronger result: Let $f$ be a monic polynomial with integer coefficients in $x$ . If all roots of $f$ have absolute value at most $1$ , then $f$ is a product of cyclotomic polynomials and/or a power of $x$ (that is, all nonzero roots are roots of unity). David E Speyer gave a short and relatively elementary proof. But other answers, and most likely the standard approaches, involve Galois theory. So I am looking for other methods proving the statement which requires the roots lying on the unit circle without invoking Galois theory. Thank you.","Suppose that has all its roots on the unit circle in the complex plane. Prove that any root of is a root of unity. This question has been asked before, yet it links to another MO post which proves a stronger result: Let be a monic polynomial with integer coefficients in . If all roots of have absolute value at most , then is a product of cyclotomic polynomials and/or a power of (that is, all nonzero roots are roots of unity). David E Speyer gave a short and relatively elementary proof. But other answers, and most likely the standard approaches, involve Galois theory. So I am looking for other methods proving the statement which requires the roots lying on the unit circle without invoking Galois theory. Thank you.",f(z)=z^n+a_{n-1}z^{n-1}+\cdots+ a_0\in\mathbb Z[z] f(z)=0 f x f 1 f x,"['complex-analysis', 'number-theory', 'polynomials']"
19,Analytic Continuation of Complex Function,Analytic Continuation of Complex Function,,"I am triyng to solve the following problem in Brown and Churchill's complex variables textbook. Show that the function $f_2 (z) = 1/z^2$ ( $z \neq 0$ ) is the analytic continuation of the function \begin{align*} f_1 (z) = \sum\limits_{n=0}^{\infty} (n+1)(z + 1)^n \ \ \ (|z+1| < 1) \end{align*} into the domain consisting of all points in the $z$ plane except $z = 0$ . As a first note, I am having difficulty mapping the definition of analytic continuation to this problem. The definition in the textbook is that if we have two domains, say $D_1$ and $D_2$ , where some function $f_1$ is analytic on $D_1$ , some function $f_2$ is analytic on $D_2$ , and $f_1 (z) = f_2 (z)$ on $D_1 \cap D_2$ , where this intersection is nonempty, then $f_2$ is the analytic continuation of $f_1$ into $D_2$ . Assuming that I have not misstated that (please tell me if I have), we have: \begin{align*} D_1 = \{z \in \mathbb{C} : |z + 1| < 1\}, \ \ \ D_2 = \{z \in \mathbb{C} : z \neq 0\}. \end{align*} So we have \begin{align*} D_1 \cap D_2 = \{z \in \mathbb{C} : |z + 1| < 1 \text{ and } z \neq 0\}. \end{align*} From here, I am stuck. I know I need to prove that $\frac{1}{z^2} = \sum\limits_{n=0}^{\infty} (n+1)(z + 1)^n$ for any $z \in D_1 \cap D_2$ . I don't know if I should try to demonstrate that the moduli are equal or expand $\frac{1}{z^2}$ in a power series and hope that these results will match, subject to the given constraint. Any help would be greatly appreciated. EDIT: I do not believe this question is a duplicate. I looked through the link below, and it does not address this problem, nor does it seem to deal with concepts in complex analysis.","I am triyng to solve the following problem in Brown and Churchill's complex variables textbook. Show that the function ( ) is the analytic continuation of the function into the domain consisting of all points in the plane except . As a first note, I am having difficulty mapping the definition of analytic continuation to this problem. The definition in the textbook is that if we have two domains, say and , where some function is analytic on , some function is analytic on , and on , where this intersection is nonempty, then is the analytic continuation of into . Assuming that I have not misstated that (please tell me if I have), we have: So we have From here, I am stuck. I know I need to prove that for any . I don't know if I should try to demonstrate that the moduli are equal or expand in a power series and hope that these results will match, subject to the given constraint. Any help would be greatly appreciated. EDIT: I do not believe this question is a duplicate. I looked through the link below, and it does not address this problem, nor does it seem to deal with concepts in complex analysis.","f_2 (z) = 1/z^2 z \neq 0 \begin{align*}
f_1 (z) = \sum\limits_{n=0}^{\infty} (n+1)(z + 1)^n \ \ \ (|z+1| < 1)
\end{align*} z z = 0 D_1 D_2 f_1 D_1 f_2 D_2 f_1 (z) = f_2 (z) D_1 \cap D_2 f_2 f_1 D_2 \begin{align*}
D_1 = \{z \in \mathbb{C} : |z + 1| < 1\}, \ \ \ D_2 = \{z \in \mathbb{C} : z \neq 0\}.
\end{align*} \begin{align*}
D_1 \cap D_2 = \{z \in \mathbb{C} : |z + 1| < 1 \text{ and } z \neq 0\}.
\end{align*} \frac{1}{z^2} = \sum\limits_{n=0}^{\infty} (n+1)(z + 1)^n z \in D_1 \cap D_2 \frac{1}{z^2}",['complex-analysis']
20,Question for finding bound for $f'(z)$[CSIR-December 2011],Question for finding bound for [CSIR-December 2011],f'(z),"My attempt:- (1)Taking $f(z)=.5$ , So, $g(z)= \begin{cases}        \frac{.5}{z} & z\neq 0 \\      0 & z=0    \end{cases} $ So, I can eliminate (1) and (2) I am trying to apply Schwarz pick lemma for (c), But I am not able to make $|f'(z)|\leq \frac{1-|f(z)|^2}{1-|z|^2}\leq 1$ Please help me.","My attempt:- (1)Taking , So, So, I can eliminate (1) and (2) I am trying to apply Schwarz pick lemma for (c), But I am not able to make Please help me.","f(z)=.5 g(z)= \begin{cases} 
      \frac{.5}{z} & z\neq 0 \\
     0 & z=0
   \end{cases}
 |f'(z)|\leq \frac{1-|f(z)|^2}{1-|z|^2}\leq 1",[]
21,Why is the interchange of a sum and an integral not justified here?,Why is the interchange of a sum and an integral not justified here?,,"This problem arose when I was studying the analytic continuation of the $\Gamma$ function. Consider $$f(z) = \int_{0}^1 e^{-t}t^{z-1} dt$$ This integral converges only for $\Re(z)>0$ . However, if we expand $e^{-t}$ into power series and interchange the summation and integration, we get that $$f(z) = \sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!(n+z)}$$ which converges for every $z \not = -n$ . This of course means that the interchange of summation and integration was not justified. However, I attempted to come up with a justification anyway, and I cannot find the mistake. Can you help me find it please? Justification We will use the Weierstrass $M$ -test. First, if we replace $e^{-t}$ by a power seires and simplify, we get $$f(z) = \int_0^1 \left[\sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1} \right]dt$$ We will now show that for $0< \delta < 1$ , the series converges uniformly on $[\delta, 1]$ . We have $$\left|\dfrac {(-1)^n}{n!}t^{n+z-1}  \right| = \dfrac {1}{n!}t^{\Re(z)+n-1}$$ For $n$ large enough (greater than some $N$ ), we have $\Re(z)+n-1 > 0$ , and as a result, $$\dfrac {1}{n!}t^{\Re(z)+n-1} < \dfrac {1}{n!} = M_n, \text{ and } \sum_{n=N}^{\infty} M_n \text{converges}$$ Therefore $$\sum_{n=N}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1}$$ converges uniformly on $[\delta, 1]$ , and as a result, $$\sum_{n=0}^{N-1} \dfrac {(-1)^n}{n!}t^{n+z-1}  + \sum_{n=N}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1} = \sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1} $$ converges uniformly on $[\delta, 1].$ Therefore $$\int_{\delta}^1 \left[\sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1} \right]dt = \sum_{n=0}^{\infty} \left[ \int_{\delta}^1  \dfrac {(-1)^n}{n!}t^{n+z-1} dt \right] = \sum_{n=0}^{\infty} \left[ \dfrac {(-1)^n}{n!(n+z)}- \dfrac {(-1)^n}{n!(n+z)} \delta^{n+z} \right]$$ $$= \sum_{n=0}^{\infty}  \dfrac {(-1)^n}{n!(n+z)} - \sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!(n+z)} \delta^{n+z}$$ Now looking at the sum on the right as a function of $\delta$ , we can argue that the series converges uniformly by splitting up the series as we did above. Thus if we take the limit as $\delta \to 0$ , that sum vanishes and we get that $$\int_{0}^1 \left[\sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1} \right]dt = \sum_{n=0}^{\infty}  \dfrac {(-1)^n}{n!(n+z)} $$ , as desired.","This problem arose when I was studying the analytic continuation of the function. Consider This integral converges only for . However, if we expand into power series and interchange the summation and integration, we get that which converges for every . This of course means that the interchange of summation and integration was not justified. However, I attempted to come up with a justification anyway, and I cannot find the mistake. Can you help me find it please? Justification We will use the Weierstrass -test. First, if we replace by a power seires and simplify, we get We will now show that for , the series converges uniformly on . We have For large enough (greater than some ), we have , and as a result, Therefore converges uniformly on , and as a result, converges uniformly on Therefore Now looking at the sum on the right as a function of , we can argue that the series converges uniformly by splitting up the series as we did above. Thus if we take the limit as , that sum vanishes and we get that , as desired.","\Gamma f(z) = \int_{0}^1 e^{-t}t^{z-1} dt \Re(z)>0 e^{-t} f(z) = \sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!(n+z)} z \not = -n M e^{-t} f(z) = \int_0^1 \left[\sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1} \right]dt 0< \delta < 1 [\delta, 1] \left|\dfrac {(-1)^n}{n!}t^{n+z-1}  \right| = \dfrac {1}{n!}t^{\Re(z)+n-1} n N \Re(z)+n-1 > 0 \dfrac {1}{n!}t^{\Re(z)+n-1} < \dfrac {1}{n!} = M_n, \text{ and } \sum_{n=N}^{\infty} M_n \text{converges} \sum_{n=N}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1} [\delta, 1] \sum_{n=0}^{N-1} \dfrac {(-1)^n}{n!}t^{n+z-1}  + \sum_{n=N}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1} = \sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1}  [\delta, 1]. \int_{\delta}^1 \left[\sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1} \right]dt = \sum_{n=0}^{\infty} \left[ \int_{\delta}^1  \dfrac {(-1)^n}{n!}t^{n+z-1} dt \right] = \sum_{n=0}^{\infty} \left[ \dfrac {(-1)^n}{n!(n+z)}- \dfrac {(-1)^n}{n!(n+z)} \delta^{n+z} \right] = \sum_{n=0}^{\infty}  \dfrac {(-1)^n}{n!(n+z)} - \sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!(n+z)} \delta^{n+z} \delta \delta \to 0 \int_{0}^1 \left[\sum_{n=0}^{\infty} \dfrac {(-1)^n}{n!}t^{n+z-1} \right]dt = \sum_{n=0}^{\infty}  \dfrac {(-1)^n}{n!(n+z)} ","['real-analysis', 'complex-analysis', 'analysis', 'gamma-function']"
22,Composition of subharmonic with holomorphic is subharmonic,Composition of subharmonic with holomorphic is subharmonic,,"I need to prove the following claim: PROBLEM: Asuume $U_1,U_2\subseteq\mathbb C$ are domains in $\mathbb C$ .    Show that if $f:U_1→U_2$ is holomorphic and $u:U_2\to\mathbb R$ is subharmonic and continuous, then $u∘f:U_1\to\mathbb R$ is subharmonic. This problem has already been answered here , but I need a proof that does not use the smooth approximation of subharmonic functions. A solution for the case in which $f$ is invertible can be found here . I'm trying to generalize the latter solution into every $f\in Hol(U_1)$ ( $f$ is not necessarily invertible and $u$ is not necessarily differentiable). The definition of subharmonic function is: We say that $u:\Omega\to\mathbb R$ is subharmonic if for every $\bar B(z_0,r)\subseteq\Omega $ we have $$ u(z_0)\leq \frac{1}{2\pi} \int_0^{2\pi} u(z_0+re^{it})dt$$ I have also learned the following theorem : A continuous function $v:\Omega\to\mathbb R$ is subharmonic if and only if for any harmonic function $u:\Omega'\to\mathbb R$ where $\Omega'\subseteq\Omega$ the difference $v-u$ satisfies the maximum principle in $\Omega'$ . And this claim (I'm not sure it's necessary here): Let $\Omega=B(z_0,r)$ . Assume $v:\Omega\to\mathbb R$ is subharmonic and continuous, and $u:\bar\Omega\to\mathbb R$ is continuous in $\bar\Omega$ and harmonic in $\Omega$ . Then if $$\forall a\in\partial\Omega. \limsup_{z\to a} v(z) \leq u(a)$$ , then $\forall z\in\Omega. v(z)\leq u(z)$ . Any help would be appreciated!","I need to prove the following claim: PROBLEM: Asuume are domains in .    Show that if is holomorphic and is subharmonic and continuous, then is subharmonic. This problem has already been answered here , but I need a proof that does not use the smooth approximation of subharmonic functions. A solution for the case in which is invertible can be found here . I'm trying to generalize the latter solution into every ( is not necessarily invertible and is not necessarily differentiable). The definition of subharmonic function is: We say that is subharmonic if for every we have I have also learned the following theorem : A continuous function is subharmonic if and only if for any harmonic function where the difference satisfies the maximum principle in . And this claim (I'm not sure it's necessary here): Let . Assume is subharmonic and continuous, and is continuous in and harmonic in . Then if , then . Any help would be appreciated!","U_1,U_2\subseteq\mathbb C \mathbb C f:U_1→U_2 u:U_2\to\mathbb R u∘f:U_1\to\mathbb R f f\in Hol(U_1) f u u:\Omega\to\mathbb R \bar B(z_0,r)\subseteq\Omega   u(z_0)\leq \frac{1}{2\pi} \int_0^{2\pi} u(z_0+re^{it})dt v:\Omega\to\mathbb R u:\Omega'\to\mathbb R \Omega'\subseteq\Omega v-u \Omega' \Omega=B(z_0,r) v:\Omega\to\mathbb R u:\bar\Omega\to\mathbb R \bar\Omega \Omega \forall a\in\partial\Omega. \limsup_{z\to a} v(z) \leq u(a) \forall z\in\Omega. v(z)\leq u(z)","['complex-analysis', 'harmonic-functions']"
23,$ |1+z+z^2 +...+z^n| \geq |z|^n $ is valid [closed],is valid [closed], |1+z+z^2 +...+z^n| \geq |z|^n ,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $z=a+ib$ , where $a>0$ & $b $ are integers, then $  |1+z+z^2 +...+z^n| \geq |z|^n $ is always holds... I tried to prove the because this seems to be true... But in vain","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let , where & are integers, then is always holds... I tried to prove the because this seems to be true... But in vain",z=a+ib a>0 b    |1+z+z^2 +...+z^n| \geq |z|^n ,"['complex-analysis', 'inequality', 'complex-numbers']"
24,Mellin inverse of $\sum_{n=0}^{\infty}\frac{\Gamma(n+s)\zeta(n+s)\zeta(n+1+s)}{\zeta(s)n!}\left(-\omega\right)^{n}$,Mellin inverse of,\sum_{n=0}^{\infty}\frac{\Gamma(n+s)\zeta(n+s)\zeta(n+1+s)}{\zeta(s)n!}\left(-\omega\right)^{n},"I am trying to compute the inverse Mellin transform of : $$\sum_{n=0}^{\infty}\frac{\Gamma(n+s)\zeta(n+s)\zeta(n+1+s)}{\zeta(s)n!}\left(-\omega\right)^{n}$$ w.r.t. the complex number $s$ . $\omega$ being a real parameter. My Attempt : it can be easily verified that the function $\phi(s,\omega)$ given by : $$\phi(s,\omega)=\frac{(s-1)}{\Gamma(s)^{2}}\sum_{n=0}^{\infty}\frac{\Gamma(n+s)\zeta(n+s)\zeta(n+1+s)}{n!}\left(-\omega\right)^{n}$$ is entire in $s$ . Thus, the Mellin inverse may be written as : $$\frac{1}{2\pi i }\int_{\sigma-i\infty}^{\sigma+i\infty}\frac{\Gamma(s)^{2}\phi(s,\omega)}{(s-1)\zeta(s)}x^{-s}ds$$ which can be computed using the residue theorem. The problem now is to find $\phi(s,\omega)$ , and it's derivatives at negative integers, and the non-trivial zeros of the Riemann zeta function. hence my question.","I am trying to compute the inverse Mellin transform of : w.r.t. the complex number . being a real parameter. My Attempt : it can be easily verified that the function given by : is entire in . Thus, the Mellin inverse may be written as : which can be computed using the residue theorem. The problem now is to find , and it's derivatives at negative integers, and the non-trivial zeros of the Riemann zeta function. hence my question.","\sum_{n=0}^{\infty}\frac{\Gamma(n+s)\zeta(n+s)\zeta(n+1+s)}{\zeta(s)n!}\left(-\omega\right)^{n} s \omega \phi(s,\omega) \phi(s,\omega)=\frac{(s-1)}{\Gamma(s)^{2}}\sum_{n=0}^{\infty}\frac{\Gamma(n+s)\zeta(n+s)\zeta(n+1+s)}{n!}\left(-\omega\right)^{n} s \frac{1}{2\pi i }\int_{\sigma-i\infty}^{\sigma+i\infty}\frac{\Gamma(s)^{2}\phi(s,\omega)}{(s-1)\zeta(s)}x^{-s}ds \phi(s,\omega)","['complex-analysis', 'number-theory', 'mellin-transform']"
25,"Given two biholomorphic maps such that $f(z_0)=g(z_0)=0$, prove there exists $c$ such that $f(z)=cg(z)$","Given two biholomorphic maps such that , prove there exists  such that",f(z_0)=g(z_0)=0 c f(z)=cg(z),"Given two biholomorphic maps $f:\Omega\rightarrow\mathbb{D}$ and $g:\Omega\rightarrow\mathbb{D}$ such that $f(z_0)=g(z_0)=0$ , prove that there exists $c\in\mathbb{C}$ with $|c|=1$ such that $f(z)=cg(z)$ If $f$ or $g$ is identically zero, it is trivial as $0=c0$ , so assume they are both not identically zero. Assume WLOG, $|f|\leq|g|$ . Then, $f(z)=(z-z_0)^mk(z)$ and $g(z)=(z-z_0)^nh(z)$ where $k(z_0)$ and $h(z_0)$ are both not zero. Then, for $z\neq z_0$ , $$\left|\frac{(z-z_0)^{m-n}k(z)}{h(z)}\right|\leq1$$ and there exists some constant $k$ such that $\left|\frac{k(z)}{h(z)}\right|\geq \frac{1}{k}$ so we have $$\frac{|z-z_0|^{m-n}}{k}\leq\left|\frac{(z-z_0)^{m-n}k(z)}{h(z)}\right|\leq 1\Rightarrow|z-z_0|^{m-n}\leq k$$ How do I proceed further to show that there is a constant $c$ ? or am I totally wrong?","Given two biholomorphic maps and such that , prove that there exists with such that If or is identically zero, it is trivial as , so assume they are both not identically zero. Assume WLOG, . Then, and where and are both not zero. Then, for , and there exists some constant such that so we have How do I proceed further to show that there is a constant ? or am I totally wrong?",f:\Omega\rightarrow\mathbb{D} g:\Omega\rightarrow\mathbb{D} f(z_0)=g(z_0)=0 c\in\mathbb{C} |c|=1 f(z)=cg(z) f g 0=c0 |f|\leq|g| f(z)=(z-z_0)^mk(z) g(z)=(z-z_0)^nh(z) k(z_0) h(z_0) z\neq z_0 \left|\frac{(z-z_0)^{m-n}k(z)}{h(z)}\right|\leq1 k \left|\frac{k(z)}{h(z)}\right|\geq \frac{1}{k} \frac{|z-z_0|^{m-n}}{k}\leq\left|\frac{(z-z_0)^{m-n}k(z)}{h(z)}\right|\leq 1\Rightarrow|z-z_0|^{m-n}\leq k c,['complex-analysis']
26,Help with proof of the Symmetry Principle on extending holomorphic functions on symmetric sets about the real axis,Help with proof of the Symmetry Principle on extending holomorphic functions on symmetric sets about the real axis,,"I am looking at the proof of the Symmetry Principle from Stein and Shakarchi's Complex Analysis. Here, we try to prove the theorem using Morera's theorem.  My question here is regarding the argument given below in diagram (a). So, from Morera's theorem, we have that $\int_{T_\epsilon} f=0$. We then let $\epsilon \to 0$, and conclude that $\int_T f(z)dz =0$. It says that we have this convergence by continuity. However, while this is intuitively clear, I can't think of a rigorous argument that guarantees  $$\int_{T_\epsilon} f(z)dz = \int_T f(z)dz.$$ How do we get this result by continuity?","I am looking at the proof of the Symmetry Principle from Stein and Shakarchi's Complex Analysis. Here, we try to prove the theorem using Morera's theorem.  My question here is regarding the argument given below in diagram (a). So, from Morera's theorem, we have that $\int_{T_\epsilon} f=0$. We then let $\epsilon \to 0$, and conclude that $\int_T f(z)dz =0$. It says that we have this convergence by continuity. However, while this is intuitively clear, I can't think of a rigorous argument that guarantees  $$\int_{T_\epsilon} f(z)dz = \int_T f(z)dz.$$ How do we get this result by continuity?",,['complex-analysis']
27,How did Euler prove $\frac{d}{dx}e^{ix}=ie^{ix}$?,How did Euler prove ?,\frac{d}{dx}e^{ix}=ie^{ix},"Surely, $\frac{d}{dx}e^{ax}$ is $ae^{ax}$ when $a$ is a real number. However, it does not mean $\frac{d}{dx}e^{ax}$ is $ae^{ax}$ when $a$ is a complex number, I think. if he didn’t prove it, Euler’s formula is not a formula but a definition of $e^{ix}$. Please tell me whether Euler’s formula is a formula or a definition. Additionally, I want to know whether Euler thought this equation as a formula or a definition when he found this.","Surely, $\frac{d}{dx}e^{ax}$ is $ae^{ax}$ when $a$ is a real number. However, it does not mean $\frac{d}{dx}e^{ax}$ is $ae^{ax}$ when $a$ is a complex number, I think. if he didn’t prove it, Euler’s formula is not a formula but a definition of $e^{ix}$. Please tell me whether Euler’s formula is a formula or a definition. Additionally, I want to know whether Euler thought this equation as a formula or a definition when he found this.",,"['calculus', 'complex-analysis']"
28,Are essential isolated singularities preserved under non-zero holomorphic functions?,Are essential isolated singularities preserved under non-zero holomorphic functions?,,"Question. In univariate complex analysis, are essential isolated singularities preserved under non-zero holomorphic functions? For example, if we've already proved that $e^{1/z}$ has an essential singularity at $0$, can we deduce that $e^{e^{1/z}}$ also has one at zero, without making any computations?","Question. In univariate complex analysis, are essential isolated singularities preserved under non-zero holomorphic functions? For example, if we've already proved that $e^{1/z}$ has an essential singularity at $0$, can we deduce that $e^{e^{1/z}}$ also has one at zero, without making any computations?",,"['complex-analysis', 'singularity']"
29,Complex Integration using Cauchy's Theorem,Complex Integration using Cauchy's Theorem,,The problem is the integration of  $$I=\int_{\left\lvert z-1\right\rvert=1} f(z) dz$$ where  $$f(z)=\frac{1}{z^3-1}$$ and the path goes $1$ loop in positive direction. I tried to solve the problem using Cauchy's Theorem by finding $z$ that makes $f(z)$ denominator be $0$. That was $z=1$. And I got struck. I think the integral is needed to be treat somehow so that $$\int_{C_a}\frac{1}{(z-\alpha)^n}dz = 2{\pi}i \text{ when } n=1$$ can be used. My question is how should I continue with the integral?,The problem is the integration of  $$I=\int_{\left\lvert z-1\right\rvert=1} f(z) dz$$ where  $$f(z)=\frac{1}{z^3-1}$$ and the path goes $1$ loop in positive direction. I tried to solve the problem using Cauchy's Theorem by finding $z$ that makes $f(z)$ denominator be $0$. That was $z=1$. And I got struck. I think the integral is needed to be treat somehow so that $$\int_{C_a}\frac{1}{(z-\alpha)^n}dz = 2{\pi}i \text{ when } n=1$$ can be used. My question is how should I continue with the integral?,,"['complex-analysis', 'complex-integration', 'cauchy-integral-formula']"
30,About Hadamard products,About Hadamard products,,"in the following problem I have some questions. Show that if $f$ is an entire function of finite order thar omits two values, then $f$ is constant. I know that by Hadamard products, if $f$ omits the values $a$ and $b$, I can write $f(z)-a=e^{p(z)}$ and $f(z)-b=e^{q(z)}$, where $p(z)$, $q(z)$ are polynomials of degree $n,m$ respectively. Then $$e^{p(z)}-e^{q(z)}=b-a.$$ Now, if $z\to\infty$ the leading terms of $p$ and $q$ must be the same, why? And then, how can I conclude that $f$ is constant? Thanks in advance !","in the following problem I have some questions. Show that if $f$ is an entire function of finite order thar omits two values, then $f$ is constant. I know that by Hadamard products, if $f$ omits the values $a$ and $b$, I can write $f(z)-a=e^{p(z)}$ and $f(z)-b=e^{q(z)}$, where $p(z)$, $q(z)$ are polynomials of degree $n,m$ respectively. Then $$e^{p(z)}-e^{q(z)}=b-a.$$ Now, if $z\to\infty$ the leading terms of $p$ and $q$ must be the same, why? And then, how can I conclude that $f$ is constant? Thanks in advance !",,"['complex-analysis', 'infinite-product']"
31,Zeroes of derivative of Weierstrass's elliptic function,Zeroes of derivative of Weierstrass's elliptic function,,"I'm asked to show that the Weierstrass's elliptic function $\wp: \mathbb{C}/\Gamma \rightarrow \mathbb{C}P^1$ has exactly 4 branch points. My problem is that I don't see why there are 4 branch points and not just 3. I looked at the zeroes of the derivative $\wp '$. Since $\wp '$ is doubly periodic and odd this implies that $\frac{w_1}{2}$, $\frac{w_2}{2}$ and $\frac{w_1+w_2}{2}$ are zeros of $\wp '$, where $w_1,w_2$ span $\Gamma$. But I know that an elliptic function has the same number of poles as it has zeros (where the order of the poles / zeroes matters). Since $\wp '$ has only one pole (of order 3) I know that the three zeros are all of order 1 and in particular there can't be a fourth zero. Where is my mistake?","I'm asked to show that the Weierstrass's elliptic function $\wp: \mathbb{C}/\Gamma \rightarrow \mathbb{C}P^1$ has exactly 4 branch points. My problem is that I don't see why there are 4 branch points and not just 3. I looked at the zeroes of the derivative $\wp '$. Since $\wp '$ is doubly periodic and odd this implies that $\frac{w_1}{2}$, $\frac{w_2}{2}$ and $\frac{w_1+w_2}{2}$ are zeros of $\wp '$, where $w_1,w_2$ span $\Gamma$. But I know that an elliptic function has the same number of poles as it has zeros (where the order of the poles / zeroes matters). Since $\wp '$ has only one pole (of order 3) I know that the three zeros are all of order 1 and in particular there can't be a fourth zero. Where is my mistake?",,"['complex-analysis', 'riemann-surfaces']"
32,About the order of a meromorphic function,About the order of a meromorphic function,,"In Gunning's book, lectures on Riemann surfaces, the order of a meromorphic function is defined as the order of the first non-zero coefficient in Laurent series of the function.  About this assertion, ""the order of a meromorphic function f is non-zero only at a discrete set of points "", I don't understand the meaning, as we all know, locally a meromorphic function f is a quotient  of two holomorphic functions, say f=g/h, so ord(f)=Z(h) where Z(h) is the zero set of h, Z(h) is non-zero only at a discrete set of points? There must be some wrong of my understanding. So where is the wrong ? Any help will be greatly appreciated. Thanks","In Gunning's book, lectures on Riemann surfaces, the order of a meromorphic function is defined as the order of the first non-zero coefficient in Laurent series of the function.  About this assertion, ""the order of a meromorphic function f is non-zero only at a discrete set of points "", I don't understand the meaning, as we all know, locally a meromorphic function f is a quotient  of two holomorphic functions, say f=g/h, so ord(f)=Z(h) where Z(h) is the zero set of h, Z(h) is non-zero only at a discrete set of points? There must be some wrong of my understanding. So where is the wrong ? Any help will be greatly appreciated. Thanks",,"['complex-analysis', 'riemann-surfaces']"
33,The Hilbert transform of analytic function is still analytic.,The Hilbert transform of analytic function is still analytic.,,"If a function $f$ is analytic in the strip $\mathcal{D}_d = \left\{ z \in \mathbb{C} : |\Im(z)| < d \right\}$, how to show that the Hilbert transform of $f$, which is $\mathcal{H}f(x) = p.v. \int_{\mathbb{R}} \frac{f(t)}{x-t}dt$ ($p.v.$ means Cauchy principal value), is also analytic in this strip?","If a function $f$ is analytic in the strip $\mathcal{D}_d = \left\{ z \in \mathbb{C} : |\Im(z)| < d \right\}$, how to show that the Hilbert transform of $f$, which is $\mathcal{H}f(x) = p.v. \int_{\mathbb{R}} \frac{f(t)}{x-t}dt$ ($p.v.$ means Cauchy principal value), is also analytic in this strip?",,['complex-analysis']
34,Transformation of $|z-1|=1$ and $\mathrm{Re}(z)^2 = \mathrm{Im }(z)^2-1$ under $f(z) = \sqrt{z}$,Transformation of  and  under,|z-1|=1 \mathrm{Re}(z)^2 = \mathrm{Im }(z)^2-1 f(z) = \sqrt{z},"I have two regions in the complex plane, defined by $|z-1|=1$ and $(\,\mathrm{Im}(z))^2 = (\,\mathrm{Re}(z))^2-1$, $\mathrm{Re}(z)>0$. I am being asked to find and sketch the image of those regions  under the mapping $f(z) = \sqrt{z}$ . My attempt We have $f(z) = \sqrt{r}e^{i\frac{\theta}{2}}$ and $|z-1|=1 \iff r = 2\cos(\theta)$ If $|z-1|=1 $, then:  $$f(z) =  \sqrt{2|\cos(\theta)|}\cos\left(\frac{\theta}{2}\right) +  i\sqrt{2|\cos(\theta)|}\sin\left(\frac{\theta}{2}\right)$$ It means that $f(z)$ lies on the trace of the curve $\left(\sqrt{2|\cos(\theta)|}\cos\left(\frac{\theta}{2}\right);  \sqrt{2|\cos(\theta)|}\sin\left(\frac{\theta}{2}\right) \right)$ if $|z-1| = 1.$ Am I right so far? I couldn't recognize this plane curve. And I don't know how to proceed in the region  $(\,\mathrm{Im}(z))^2 = (\,\mathrm{Re}(z))^2-1$. How can I do it?","I have two regions in the complex plane, defined by $|z-1|=1$ and $(\,\mathrm{Im}(z))^2 = (\,\mathrm{Re}(z))^2-1$, $\mathrm{Re}(z)>0$. I am being asked to find and sketch the image of those regions  under the mapping $f(z) = \sqrt{z}$ . My attempt We have $f(z) = \sqrt{r}e^{i\frac{\theta}{2}}$ and $|z-1|=1 \iff r = 2\cos(\theta)$ If $|z-1|=1 $, then:  $$f(z) =  \sqrt{2|\cos(\theta)|}\cos\left(\frac{\theta}{2}\right) +  i\sqrt{2|\cos(\theta)|}\sin\left(\frac{\theta}{2}\right)$$ It means that $f(z)$ lies on the trace of the curve $\left(\sqrt{2|\cos(\theta)|}\cos\left(\frac{\theta}{2}\right);  \sqrt{2|\cos(\theta)|}\sin\left(\frac{\theta}{2}\right) \right)$ if $|z-1| = 1.$ Am I right so far? I couldn't recognize this plane curve. And I don't know how to proceed in the region  $(\,\mathrm{Im}(z))^2 = (\,\mathrm{Re}(z))^2-1$. How can I do it?",,['complex-analysis']
35,subharmonic on punctured disk but extends continuously to origin,subharmonic on punctured disk but extends continuously to origin,,"Suppose that $f$ is bounded and subharmonic on $\Omega = D(0,1) - \{0\}$.  Suppose also that $L = \sup_{z \in \Omega} f(z)$ and $\lim_{z \to 0}f(z) = L$. How can I prove that $f$ extends subharmonically to all of $D(0, 1)$ with $f(0) = L$?","Suppose that $f$ is bounded and subharmonic on $\Omega = D(0,1) - \{0\}$.  Suppose also that $L = \sup_{z \in \Omega} f(z)$ and $\lim_{z \to 0}f(z) = L$. How can I prove that $f$ extends subharmonically to all of $D(0, 1)$ with $f(0) = L$?",,"['complex-analysis', 'analysis', 'harmonic-analysis', 'harmonic-functions']"
36,"Entire function bounded on every horizontal and vertical line , then is it bounded on every horizontal and vertical strip?","Entire function bounded on every horizontal and vertical line , then is it bounded on every horizontal and vertical strip?",,"Let $f:\mathbb C \to \mathbb C$ be an entire function such that $f$ is bounded on every horizontal and every vertical line , then is it true that $f$ is bounded on any set of the form $V_{[a,b]}:=\{x+iy : y\in \mathbb R , a \le x \le b\}$ and any set of the form $H_{[a,b]}:=\{x+iy : x\in \mathbb R , a \le y \le b\}$ ?","Let $f:\mathbb C \to \mathbb C$ be an entire function such that $f$ is bounded on every horizontal and every vertical line , then is it true that $f$ is bounded on any set of the form $V_{[a,b]}:=\{x+iy : y\in \mathbb R , a \le x \le b\}$ and any set of the form $H_{[a,b]}:=\{x+iy : x\in \mathbb R , a \le y \le b\}$ ?",,['complex-analysis']
37,holomorphic function on punctured disk satisfying $\left|f\left(\frac{1}{n}\right)\right|\leq\frac{1}{n!}$ has an essential singularity at $0$,holomorphic function on punctured disk satisfying  has an essential singularity at,\left|f\left(\frac{1}{n}\right)\right|\leq\frac{1}{n!} 0,"Let $f$ be holomorphic non-constant on $D=\left\{ 0<\left|z\right|<10\right\}$ . Given that for all $n\in\mathbb{N}$: $\left|f\left(\frac{1}{n}\right)\right|\leq\frac{1}{n!}$ prove that $f$ has an essential singularity at $0$. Find an example of $f$ satisfying the condition. My idea was to assume for contradiction the singularity is not essential, which means that either the limit $z\to0$ of $f$ exists or of $1/f$, and from $\left|f\left(\frac{1}{n}\right)\right|\leq\frac{1}{n!}$ we get that the limit of $f$ exists and is $0$. I then define $h(z)=f(z)$ for $z\neq0$ and $h(0)=0$, which is holomorphic on the entire disk, and derive a contradiction from there and the uniqueness theorem. But then the suitable holomorphic function is the Gamma function, which we have not really discussed in class and I'm not sure about it's properties. Any ways of solving this which avoids using the gamma function?","Let $f$ be holomorphic non-constant on $D=\left\{ 0<\left|z\right|<10\right\}$ . Given that for all $n\in\mathbb{N}$: $\left|f\left(\frac{1}{n}\right)\right|\leq\frac{1}{n!}$ prove that $f$ has an essential singularity at $0$. Find an example of $f$ satisfying the condition. My idea was to assume for contradiction the singularity is not essential, which means that either the limit $z\to0$ of $f$ exists or of $1/f$, and from $\left|f\left(\frac{1}{n}\right)\right|\leq\frac{1}{n!}$ we get that the limit of $f$ exists and is $0$. I then define $h(z)=f(z)$ for $z\neq0$ and $h(0)=0$, which is holomorphic on the entire disk, and derive a contradiction from there and the uniqueness theorem. But then the suitable holomorphic function is the Gamma function, which we have not really discussed in class and I'm not sure about it's properties. Any ways of solving this which avoids using the gamma function?",,['complex-analysis']
38,$|z-3| + |z| + |z+3| = 12$,,|z-3| + |z| + |z+3| = 12,"Let $z$ be a complex number such that $|z-3|+ |z|+ |z+3| = 12$. If $a = \lfloor|z|\rfloor$ and $b = \lceil|z|\rceil$, where $\lfloor i\rfloor$ denote the greatest integer less than or equal to $i$ and  $\lceil i\rceil$ denotes the least integer greater or equal to $i$, then find $k = a + b$. There will be two answers possible. $z=4$ is a trivial solution, for which value of $k=8$. There will be one more solution of $z$ for which $k=7$. I used the triangular inequality: $$12=|z-3|+|z|+|z+3| \ge |z-3+z+z+3|=3|z|.$$ I used the RMS$\ge$AM inequality to find the upper bound of |z|. $sqrt{frac{|z-3|^2+|z|^2+|z+3|^2}{3}}\ge \frac{|z-3|+|z|+|z+3|}{3}$ : $|z| \ge \sqrt{10}$ which implies that $a=3$ or $a=4$, $b=4$ hence $k = 7$ or $k=8$. Suggest some other ways to find the upper limit of $|z|$.","Let $z$ be a complex number such that $|z-3|+ |z|+ |z+3| = 12$. If $a = \lfloor|z|\rfloor$ and $b = \lceil|z|\rceil$, where $\lfloor i\rfloor$ denote the greatest integer less than or equal to $i$ and  $\lceil i\rceil$ denotes the least integer greater or equal to $i$, then find $k = a + b$. There will be two answers possible. $z=4$ is a trivial solution, for which value of $k=8$. There will be one more solution of $z$ for which $k=7$. I used the triangular inequality: $$12=|z-3|+|z|+|z+3| \ge |z-3+z+z+3|=3|z|.$$ I used the RMS$\ge$AM inequality to find the upper bound of |z|. $sqrt{frac{|z-3|^2+|z|^2+|z+3|^2}{3}}\ge \frac{|z-3|+|z|+|z+3|}{3}$ : $|z| \ge \sqrt{10}$ which implies that $a=3$ or $a=4$, $b=4$ hence $k = 7$ or $k=8$. Suggest some other ways to find the upper limit of $|z|$.",,"['complex-analysis', 'complex-numbers']"
39,"Is it true that $f(z)=u(z,0)+iv(z,0)$ for complex $z$ and why?",Is it true that  for complex  and why?,"f(z)=u(z,0)+iv(z,0) z","As in the title, i came across this equivalence $$f(z)=f(x+iy)=u(x,y)+iv(x,y)=u(z,0)+iv(z,0)$$ while reading my notes on complex analysis, and tried to see why is it true, but i couldn't figure it out. Maybe it could be true only in the case that f is holomorphic.","As in the title, i came across this equivalence $$f(z)=f(x+iy)=u(x,y)+iv(x,y)=u(z,0)+iv(z,0)$$ while reading my notes on complex analysis, and tried to see why is it true, but i couldn't figure it out. Maybe it could be true only in the case that f is holomorphic.",,['complex-analysis']
40,Complex analysis vs Real Analysis of $\lim_{x\to0}{x}^{x}$,Complex analysis vs Real Analysis of,\lim_{x\to0}{x}^{x},"In attempting to solve $\lim_{x\to0}x^x$, I tried two different approaches. One is to convert $x^x$ into a complex function and solve the limit in $\mathbb{C}$. The other is to take the limit of the points of the dense sets in $\mathbb{R}^{-}$ and $\mathbb{R}^{+}$. According to this article , $\lim_{x\to0}{x}^{x}$ can be converted into $\lim_{x\to{0}}|x|^{x}(\cos((2n+1)\pi x)+i\sin((2n+1)\pi x)$ where $n\in\mathbb{N}$ are the branches of complex logarithm. This leads to $$\lim_{x\to0}{|x|}^{x}\lim_{x\to0}\cos((2n+1)\pi x)+i\lim_{x\to0}|x|^{x}\lim_{x\to0}\sin((2n+1)\pi x)=1$$ So using complex analysis $\lim_{x\to0}{x^x}=1$ However, if we take the points on real axis, where x-values of the complex function of $|x|^{x}(\cos((2n+1)\pi x)+i\sin((2n+1)\pi x)=a+0i$ (see this graph) , we have the following domain.  $$\left\{x=\left.-\frac{m}{2k+1}\right|m,k\in\mathbb{N}\right\}\bigcup{\mathbb{R}^{+}}$$ Which is divided into $$x^x=\begin{cases} x^x & x>0\\ |x|^x & x=\left\{ -{2m\over 2k+1}\ |\ m, k \in \Bbb N\right\}\\ -|x|^{x} & x=\left\{ -{2m+1\over 2k+1}\ |\ m, k \in \Bbb N\right\}\ \\ \text{undefined} & x=\left\{ -{2m+1\over 2k}\ |\ m, k \in \Bbb N\right\}\bigcup \left\{\mathbb{R}^{-}\backslash \mathbb{Q}^{-}\right\} \end{cases}$$ Since $\left.-\frac{2m+1}{2k+1}\right|m,k \in \mathbb{N}$ and $\left.-\frac{2m}{2k+1}\right|m,k \in \mathbb{N}$ are dense sets; they can approximate arbitrarily close to any  $x\in{\mathbb{R}}^{-}$. Thus a limit can exist if the subsets converge to the same value. Hence $\lim_{x\to0}x^x$ exists if $$\lim_{\left\{x\in-\frac{2m+1}{2k+1}\right\}\to0^{-}}x^x=\lim_{\left\{x\in-\frac{2m}{2k+1}\right\}\to0^{-}}x^x=\lim_{x\to0^{+}}{x^x}$$ Which is the same as $$\lim_{x\to0^{-}}-|x|^x=\lim_{x\to0^{-}}|x|^x=\lim_{x\to0^{+}}x^x$$ However this equality fails since $\lim_{x\to0^{-}}-|x|^x=-1$ and the other limit are equal to $1$. So using real analysis, $\lim_{x\to0}x^x$ does not exist. I believe that the limit should be the same by real or complex analysis but I am no expert in either feild. Did I do both approaches correctly? Does my answer depend on which analysis I use?","In attempting to solve $\lim_{x\to0}x^x$, I tried two different approaches. One is to convert $x^x$ into a complex function and solve the limit in $\mathbb{C}$. The other is to take the limit of the points of the dense sets in $\mathbb{R}^{-}$ and $\mathbb{R}^{+}$. According to this article , $\lim_{x\to0}{x}^{x}$ can be converted into $\lim_{x\to{0}}|x|^{x}(\cos((2n+1)\pi x)+i\sin((2n+1)\pi x)$ where $n\in\mathbb{N}$ are the branches of complex logarithm. This leads to $$\lim_{x\to0}{|x|}^{x}\lim_{x\to0}\cos((2n+1)\pi x)+i\lim_{x\to0}|x|^{x}\lim_{x\to0}\sin((2n+1)\pi x)=1$$ So using complex analysis $\lim_{x\to0}{x^x}=1$ However, if we take the points on real axis, where x-values of the complex function of $|x|^{x}(\cos((2n+1)\pi x)+i\sin((2n+1)\pi x)=a+0i$ (see this graph) , we have the following domain.  $$\left\{x=\left.-\frac{m}{2k+1}\right|m,k\in\mathbb{N}\right\}\bigcup{\mathbb{R}^{+}}$$ Which is divided into $$x^x=\begin{cases} x^x & x>0\\ |x|^x & x=\left\{ -{2m\over 2k+1}\ |\ m, k \in \Bbb N\right\}\\ -|x|^{x} & x=\left\{ -{2m+1\over 2k+1}\ |\ m, k \in \Bbb N\right\}\ \\ \text{undefined} & x=\left\{ -{2m+1\over 2k}\ |\ m, k \in \Bbb N\right\}\bigcup \left\{\mathbb{R}^{-}\backslash \mathbb{Q}^{-}\right\} \end{cases}$$ Since $\left.-\frac{2m+1}{2k+1}\right|m,k \in \mathbb{N}$ and $\left.-\frac{2m}{2k+1}\right|m,k \in \mathbb{N}$ are dense sets; they can approximate arbitrarily close to any  $x\in{\mathbb{R}}^{-}$. Thus a limit can exist if the subsets converge to the same value. Hence $\lim_{x\to0}x^x$ exists if $$\lim_{\left\{x\in-\frac{2m+1}{2k+1}\right\}\to0^{-}}x^x=\lim_{\left\{x\in-\frac{2m}{2k+1}\right\}\to0^{-}}x^x=\lim_{x\to0^{+}}{x^x}$$ Which is the same as $$\lim_{x\to0^{-}}-|x|^x=\lim_{x\to0^{-}}|x|^x=\lim_{x\to0^{+}}x^x$$ However this equality fails since $\lim_{x\to0^{-}}-|x|^x=-1$ and the other limit are equal to $1$. So using real analysis, $\lim_{x\to0}x^x$ does not exist. I believe that the limit should be the same by real or complex analysis but I am no expert in either feild. Did I do both approaches correctly? Does my answer depend on which analysis I use?",,"['real-analysis', 'complex-analysis', 'limits', 'differential-topology']"
41,Is $f(x)$ constant under these conditions?,Is  constant under these conditions?,f(x),"Statement Let $f:\mathbb{R}\rightarrow \mathbb{R}$ be an function that is concave up and increasing. If $\displaystyle \lim_{x\to \infty}\frac{f(x)}{x}=0$, then $f$ is constant. It'll be easy if we assume $f$ is second differentiable, the conditions just mean $f''(x)\geq 0$ and $f'(x)\geq 0$. (If $f'(x)=a>0$ at $x=b$ then for $x>b$ we have $f(x)>a(x-b)+f(b)$ by MVT and clearly in this case the limit cannot be $0$ and therefore $f'(x)$ has to be $0$ everywhere). Can this statement be proved without assuming $f$ differentiable? Here concave up is defined by for any $x,y\in \mathbb{R}$, $t\in [0,1]$, $f(tx+(1-t)y)\leq tf(x)+(1-t)f(y)$. Increasing is defined by $y>x\Rightarrow f(y)\geq f(x)$. Context of this problem: If the given statement is proved, then the solution in the thread How to prove Liouville's theorem for subharmonic functions given by Martin R can be extended to prove a stronger version of the result (see my comment on that answer).","Statement Let $f:\mathbb{R}\rightarrow \mathbb{R}$ be an function that is concave up and increasing. If $\displaystyle \lim_{x\to \infty}\frac{f(x)}{x}=0$, then $f$ is constant. It'll be easy if we assume $f$ is second differentiable, the conditions just mean $f''(x)\geq 0$ and $f'(x)\geq 0$. (If $f'(x)=a>0$ at $x=b$ then for $x>b$ we have $f(x)>a(x-b)+f(b)$ by MVT and clearly in this case the limit cannot be $0$ and therefore $f'(x)$ has to be $0$ everywhere). Can this statement be proved without assuming $f$ differentiable? Here concave up is defined by for any $x,y\in \mathbb{R}$, $t\in [0,1]$, $f(tx+(1-t)y)\leq tf(x)+(1-t)f(y)$. Increasing is defined by $y>x\Rightarrow f(y)\geq f(x)$. Context of this problem: If the given statement is proved, then the solution in the thread How to prove Liouville's theorem for subharmonic functions given by Martin R can be extended to prove a stronger version of the result (see my comment on that answer).",,['real-analysis']
42,Derive zeta values of even integers from the Euler-Maclaurin formula.,Derive zeta values of even integers from the Euler-Maclaurin formula.,,"Euler showed: \begin{equation} 	B_{2 k} = (-1)^{k+1} \frac{2 \,  (2 \, k)!}{ (2 \, \pi)^{2 k}}  			\zeta(2 k) \end{equation} for $k=1,2, \cdots$. We could from here find $\zeta(2k)$ in terms of the even Bernoulli coefficients $B_{2k}$. How can we derive the equivalent representation by using the Euler Maclaurin formula ? Thanks. Update Here is what I have done: \begin{eqnarray*}   \zeta(s) = \sum_{n=1}^{\infty} \frac{1}{n^s} \quad , \quad  \mathrm{Re}(s) > 1. \end{eqnarray*} Euler used the Euler-Maclaurin series to find values of the Riemann Zeta function.   We want to use  the  Euler-Maclaurin formula with $f(x)=1/x^s=x^{-s}$. We know that \begin{eqnarray*}   f^{(0)}(x) &=& \frac{1}{x^s} \\   f^{(1)}(x) &=& -\frac{s}{x^{s+1}} \\   f^{(2)}(x) &=& \frac{s(s+1)}{x^{s+2}} \\   &\vdots& \\   f^{(i)}(x) &=& (-1)^{i+1} \frac{s(s+1) \dots (s+i-2)}{x^{s+i}}  =   (-1)^{i+1}   \frac{\Gamma(s+i)}{ \Gamma(s)} \frac{1}{ x^{s+i}}. \end{eqnarray*} We then write using $h=1$, $a=1$, $b=\infty$ \begin{eqnarray*}   \sum_{i=1}^{\infty} \frac{1}{n^s} = \int_1^{\infty} \frac{dx}{x^s} + \frac{1}{2}  +   \left . \sum_{i=1}^{m} \frac{B_{2i}}{(2i)!}    \frac{\Gamma(s+2 i-1)}{ \Gamma(s)} \frac{1}{ x^{s+2 i-1}} \right |_1^{\infty} + R_{2m} \end{eqnarray*} with \begin{eqnarray*}   R_{2m} =   -\int_1^{\infty} \mathrm{B}_{2m}    \left \{ x-1 \right \}    \frac{\Gamma(s+2 m)}{(2m)! \, \Gamma(s)} \frac{dx}{x^{s+2m}}. \end{eqnarray*} That is \begin{eqnarray}   \zeta(s) =  \frac{1}{s-1} + \frac{1}{2} -    \sum_{i=1}^{m} \frac{B_{2i}}{(2i)!}    \frac{\Gamma(s+2 i-1)}{ \Gamma(s)}  + R_{2m}   \label{zetazeta} \end{eqnarray} This is an important equation since it establishes an analytic continuation for the  $\zeta(s)$ function. We observe that the first fraction is an analytic function except for $s=1$, then the sum of quotients of $\Gamma$  functions is analytic except for isolated singularities in the negative integer arguments. Finally, since the Bernoulli polynomial $B_{2m}\{x-1\}$ is bounded the residual is a convergent integral for $s + 2m >1$, so we can extend the  convergence as far as $s > 1-2m$, for any positive number $m$. The question here is what ""$m$"" to choose. If I choose $m=1$, I did the computations and found something which made no sense.","Euler showed: \begin{equation} 	B_{2 k} = (-1)^{k+1} \frac{2 \,  (2 \, k)!}{ (2 \, \pi)^{2 k}}  			\zeta(2 k) \end{equation} for $k=1,2, \cdots$. We could from here find $\zeta(2k)$ in terms of the even Bernoulli coefficients $B_{2k}$. How can we derive the equivalent representation by using the Euler Maclaurin formula ? Thanks. Update Here is what I have done: \begin{eqnarray*}   \zeta(s) = \sum_{n=1}^{\infty} \frac{1}{n^s} \quad , \quad  \mathrm{Re}(s) > 1. \end{eqnarray*} Euler used the Euler-Maclaurin series to find values of the Riemann Zeta function.   We want to use  the  Euler-Maclaurin formula with $f(x)=1/x^s=x^{-s}$. We know that \begin{eqnarray*}   f^{(0)}(x) &=& \frac{1}{x^s} \\   f^{(1)}(x) &=& -\frac{s}{x^{s+1}} \\   f^{(2)}(x) &=& \frac{s(s+1)}{x^{s+2}} \\   &\vdots& \\   f^{(i)}(x) &=& (-1)^{i+1} \frac{s(s+1) \dots (s+i-2)}{x^{s+i}}  =   (-1)^{i+1}   \frac{\Gamma(s+i)}{ \Gamma(s)} \frac{1}{ x^{s+i}}. \end{eqnarray*} We then write using $h=1$, $a=1$, $b=\infty$ \begin{eqnarray*}   \sum_{i=1}^{\infty} \frac{1}{n^s} = \int_1^{\infty} \frac{dx}{x^s} + \frac{1}{2}  +   \left . \sum_{i=1}^{m} \frac{B_{2i}}{(2i)!}    \frac{\Gamma(s+2 i-1)}{ \Gamma(s)} \frac{1}{ x^{s+2 i-1}} \right |_1^{\infty} + R_{2m} \end{eqnarray*} with \begin{eqnarray*}   R_{2m} =   -\int_1^{\infty} \mathrm{B}_{2m}    \left \{ x-1 \right \}    \frac{\Gamma(s+2 m)}{(2m)! \, \Gamma(s)} \frac{dx}{x^{s+2m}}. \end{eqnarray*} That is \begin{eqnarray}   \zeta(s) =  \frac{1}{s-1} + \frac{1}{2} -    \sum_{i=1}^{m} \frac{B_{2i}}{(2i)!}    \frac{\Gamma(s+2 i-1)}{ \Gamma(s)}  + R_{2m}   \label{zetazeta} \end{eqnarray} This is an important equation since it establishes an analytic continuation for the  $\zeta(s)$ function. We observe that the first fraction is an analytic function except for $s=1$, then the sum of quotients of $\Gamma$  functions is analytic except for isolated singularities in the negative integer arguments. Finally, since the Bernoulli polynomial $B_{2m}\{x-1\}$ is bounded the residual is a convergent integral for $s + 2m >1$, so we can extend the  convergence as far as $s > 1-2m$, for any positive number $m$. The question here is what ""$m$"" to choose. If I choose $m=1$, I did the computations and found something which made no sense.",,"['calculus', 'complex-analysis', 'analytic-number-theory']"
43,Evaluation of $ \int_0^\infty\frac{x^{1/3}\log x}{x^2+1}\ dx $,Evaluation of, \int_0^\infty\frac{x^{1/3}\log x}{x^2+1}\ dx ,"The following is an exercisein complex analysis: Use contour integrals with $-\pi/2<\operatorname{arg} z<3\pi/2$ to compute   $$ I:=\int_0^\infty\frac{x^{1/3}\log x}{x^2+1}\ dx. $$ I don't see why the branch $-\pi/2<\operatorname{arg} z<3\pi/2$ would work. Let $$ f(z)=\frac{z^{1/3}\log z}{z^2+1}. $$ Denote $\Gamma_r={re^{it}:0\leq t\leq \pi}$. One can then consider a contour consisting of $\Gamma_R$, $\Gamma_r$, and $[-R,-r]\cup[r,R]$. The integral along $[r,R]$ will give $I$. But without symmetries, how could one deal with the integral along $[-R,-r]$?","The following is an exercisein complex analysis: Use contour integrals with $-\pi/2<\operatorname{arg} z<3\pi/2$ to compute   $$ I:=\int_0^\infty\frac{x^{1/3}\log x}{x^2+1}\ dx. $$ I don't see why the branch $-\pi/2<\operatorname{arg} z<3\pi/2$ would work. Let $$ f(z)=\frac{z^{1/3}\log z}{z^2+1}. $$ Denote $\Gamma_r={re^{it}:0\leq t\leq \pi}$. One can then consider a contour consisting of $\Gamma_R$, $\Gamma_r$, and $[-R,-r]\cup[r,R]$. The integral along $[r,R]$ will give $I$. But without symmetries, how could one deal with the integral along $[-R,-r]$?",,['calculus']
44,Normal convergence implies uniform absolute convergence but not the other way round,Normal convergence implies uniform absolute convergence but not the other way round,,"How do I show that normal convergence of a series implies uniform and absolute convergence? So, a series $f_1+f_2+...$ of functions $f_n:D\rightarrow\mathbb{C}, D\subset\mathbb{C}$ is normally convergent if for all $a\in D$ there is a neighborhood $U$ and a sequence $M_n$ of nonnegative real numbers such that $$|f_n(z)|\leq M_n\text{ for all } z\in U\cap D,$$ and $\sum M_n$ converges. However I have no idea how to use this definition to prove the above.","How do I show that normal convergence of a series implies uniform and absolute convergence? So, a series $f_1+f_2+...$ of functions $f_n:D\rightarrow\mathbb{C}, D\subset\mathbb{C}$ is normally convergent if for all $a\in D$ there is a neighborhood $U$ and a sequence $M_n$ of nonnegative real numbers such that $$|f_n(z)|\leq M_n\text{ for all } z\in U\cap D,$$ and $\sum M_n$ converges. However I have no idea how to use this definition to prove the above.",,"['complex-analysis', 'convergence-divergence', 'uniform-convergence', 'absolute-convergence']"
45,Zeros of analytic function accumulating to the boundary,Zeros of analytic function accumulating to the boundary,,"By $\mathbb D$ denote the open unit disc in $\mathbb C$. Suppose that $f : \overline{\mathbb D}\to\mathbb C$ is analytic on $\mathbb D$ and continuous on $\overline{\mathbb D}$. Assume now that there are infinitely many distinct points $z_n\in\mathbb D$ which accumulate to the boundary of $\mathbb D$ such that $f(z_n) = 0$ for all $n\in\mathbb N$. Does it then follow that $f\equiv 0$? The point is, we cannot make use of the usual identity theorem because the accumulation point of the zeros is not in $\mathbb D$. So, is there any ""improvement"" of that theorem covering the above case?","By $\mathbb D$ denote the open unit disc in $\mathbb C$. Suppose that $f : \overline{\mathbb D}\to\mathbb C$ is analytic on $\mathbb D$ and continuous on $\overline{\mathbb D}$. Assume now that there are infinitely many distinct points $z_n\in\mathbb D$ which accumulate to the boundary of $\mathbb D$ such that $f(z_n) = 0$ for all $n\in\mathbb N$. Does it then follow that $f\equiv 0$? The point is, we cannot make use of the usual identity theorem because the accumulation point of the zeros is not in $\mathbb D$. So, is there any ""improvement"" of that theorem covering the above case?",,"['complex-analysis', 'roots']"
46,Analytic function on unit disk has finitely many zeros,Analytic function on unit disk has finitely many zeros,,"I am studying complex analysis from Theodore Gamelin's text and Exercise 1 of chapter IX.2 says that if $f$ is analytic inside the open unit disk and continuous on its boundary that satisfies $|f(z)| = 1$ for $|z| = 1$, then $f$ is a finite Blaschke product. Clearly, this would imply that $f$ has only finitely many zeros in the open unit disk.  But the proof of it already assumes this fact.  So my question is that is it trivial that such an $f$ has finitely many zeros in the open unit disk?","I am studying complex analysis from Theodore Gamelin's text and Exercise 1 of chapter IX.2 says that if $f$ is analytic inside the open unit disk and continuous on its boundary that satisfies $|f(z)| = 1$ for $|z| = 1$, then $f$ is a finite Blaschke product. Clearly, this would imply that $f$ has only finitely many zeros in the open unit disk.  But the proof of it already assumes this fact.  So my question is that is it trivial that such an $f$ has finitely many zeros in the open unit disk?",,"['complex-analysis', 'analyticity', 'conformal-geometry', 'blaschke-products']"
47,Pullback of a complex $ 1$-form,Pullback of a complex -form, 1,"Let $p = \operatorname{exp} : \mathbb{C} \to \mathbb{C}^*$ be a covering and $(U,z)$ a chart of $\mathbb{C}^*$ with $z = x + iy$. Let $\omega = dz/z$ be a one-form on $U$. Problem: Find the pullback $p^*\omega$. My try: We can write $p^* \frac{1}{z}dz = p^*\frac{1}{z} \, d(p^*z) = p^*\frac{1}{z} \, p^*(dz) = (\frac{1}{z} \circ p)(dz \circ p)$. I also tried making sens of $\frac{1}{z} \circ p (a)$ for some $a \in U$. Then we get $$ \frac{1}{z} e^a = \frac{1}{x(e^a) + iy(e^a)}. $$ I have no idea what makes sense to do or try. I have very little intuition for this.","Let $p = \operatorname{exp} : \mathbb{C} \to \mathbb{C}^*$ be a covering and $(U,z)$ a chart of $\mathbb{C}^*$ with $z = x + iy$. Let $\omega = dz/z$ be a one-form on $U$. Problem: Find the pullback $p^*\omega$. My try: We can write $p^* \frac{1}{z}dz = p^*\frac{1}{z} \, d(p^*z) = p^*\frac{1}{z} \, p^*(dz) = (\frac{1}{z} \circ p)(dz \circ p)$. I also tried making sens of $\frac{1}{z} \circ p (a)$ for some $a \in U$. Then we get $$ \frac{1}{z} e^a = \frac{1}{x(e^a) + iy(e^a)}. $$ I have no idea what makes sense to do or try. I have very little intuition for this.",,"['complex-analysis', 'differential-geometry', 'differential-forms', 'riemann-surfaces']"
48,Evaluate $\displaystyle \int_{|z-i|=R}\frac{z^{4}+z^{2}+1}{z(z^{2}+1)}dz$ as a function of $R>0$,Evaluate  as a function of,\displaystyle \int_{|z-i|=R}\frac{z^{4}+z^{2}+1}{z(z^{2}+1)}dz R>0,"I need to evaluate the integral $\displaystyle \int_{|z-i|=R}\frac{z^{4}+z^{2}+1}{z(z^{2}+1)} dz$ as a function of $R>0$. I may omit values of $R$ for which the denominator turns to $0$. Now, using partial fraction decomposition, the integral can be split up as follows: $\displaystyle \int_{|z-i|=R} z \,dz + \int_{|z-i|=R}\frac{1}{z}\,dz-\frac{1}{2}\int_{|z-i|=R}\frac{1}{z+i}\,dz -\frac{1}{2}\int_{|z-i|=R} \frac{1}{z-i}\,dz$ Values for which the denominator of the non-decomposed function turns to $0$ include $R=1$ (when $R=1$, the curve intersects the singularity $z=0$) and $R=2$ (when $R=2$, the curve intersects the singularity $z=-i$). Also, as $R$ grows to encompass all the singularities, the integral will go to $0$, by Cauchy's Theorem. However, I am not really sure what to do with this problem. I tried actually parametrizing each integral, letting $|z-i|=R$ become $z = Re^{i \theta} + i$, but for the second and third integrals, I wound up getting $\ln|0|$, which is undefined. Anyway, this is not evaluating the integral as a function of $R$, but as a function of $z$ (or $\theta$). Please help! Any help is needed, but any answers cannot use Residues or Cauchy's Integral Formula (Cauchy's Theorem for either simply or multiply connected domains is fine). And I would prefer something completely worked out. Thank you.","I need to evaluate the integral $\displaystyle \int_{|z-i|=R}\frac{z^{4}+z^{2}+1}{z(z^{2}+1)} dz$ as a function of $R>0$. I may omit values of $R$ for which the denominator turns to $0$. Now, using partial fraction decomposition, the integral can be split up as follows: $\displaystyle \int_{|z-i|=R} z \,dz + \int_{|z-i|=R}\frac{1}{z}\,dz-\frac{1}{2}\int_{|z-i|=R}\frac{1}{z+i}\,dz -\frac{1}{2}\int_{|z-i|=R} \frac{1}{z-i}\,dz$ Values for which the denominator of the non-decomposed function turns to $0$ include $R=1$ (when $R=1$, the curve intersects the singularity $z=0$) and $R=2$ (when $R=2$, the curve intersects the singularity $z=-i$). Also, as $R$ grows to encompass all the singularities, the integral will go to $0$, by Cauchy's Theorem. However, I am not really sure what to do with this problem. I tried actually parametrizing each integral, letting $|z-i|=R$ become $z = Re^{i \theta} + i$, but for the second and third integrals, I wound up getting $\ln|0|$, which is undefined. Anyway, this is not evaluating the integral as a function of $R$, but as a function of $z$ (or $\theta$). Please help! Any help is needed, but any answers cannot use Residues or Cauchy's Integral Formula (Cauchy's Theorem for either simply or multiply connected domains is fine). And I would prefer something completely worked out. Thank you.",,['complex-analysis']
49,"How exactly does writing $f(z)=f(z,\bar{z})$ work?",How exactly does writing  work?,"f(z)=f(z,\bar{z})","I know that we can just define the differential operators $$\frac{\partial}{\partial z} = \frac{1}{2}(\frac{\partial}{\partial x} - i \frac{\partial}{\partial y})$$ $$\frac{\partial}{\partial \bar{z}} = \frac{1}{2}(\frac{\partial}{\partial x} + i \frac{\partial}{\partial y})$$ and that $f$ is holomorphic means that $\frac{\partial f}{\partial \bar{z}}=0$, that's all clear. However, what I don't get it is how we can write any arbitrary function $f(z)=f(z,\bar{z})$, and then calculate 'formally' with the above differential operators and expect the outcomes to be as expected (or even well defined). So this question is really not about the derivation/definition of the  Wirtinger Derivatives, that's all document very well. It's about why we can write for example \begin{align} \frac{\partial (g\circ f)}{\partial z}&=\frac{\partial (g(f(z,\bar z),\bar f(z,\bar z))}{\partial z}\\\\ &=\left.\frac{\partial g(w,\bar w)}{\partial w}\right|_{w=f(z,\bar z)}\times \frac{\partial f(z,\bar z)}{\partial z}+\left.\frac{\partial g(w,\bar w)}{\partial \bar w}\right|_{\bar w=\bar f(z,\bar z)}\times \frac{\partial \bar f(z,\bar z)}{\partial z}\\\\ &=\left(\frac{\partial g}{\partial z}\circ f\right)\frac{\partial f}{\partial z}+\left(\frac{\partial g}{\partial \bar z}\circ f\right)\frac{\partial \bar f}{\partial z} \end{align} (copied from here ). I just don't see how the formal definition of the Wirtinger derivatives makes it so that all of this goes through. An answer to this question would explain, rigorously, why the steps in the above calculation are justified, starting from the fact we can write $f(z)=f(z,\bar{z})$ in a well-defined way s.t. the operators $\frac{\partial}{\partial z}$ and $\frac{\partial}{\partial \bar{z}}$ behave as expected. Thank you","I know that we can just define the differential operators $$\frac{\partial}{\partial z} = \frac{1}{2}(\frac{\partial}{\partial x} - i \frac{\partial}{\partial y})$$ $$\frac{\partial}{\partial \bar{z}} = \frac{1}{2}(\frac{\partial}{\partial x} + i \frac{\partial}{\partial y})$$ and that $f$ is holomorphic means that $\frac{\partial f}{\partial \bar{z}}=0$, that's all clear. However, what I don't get it is how we can write any arbitrary function $f(z)=f(z,\bar{z})$, and then calculate 'formally' with the above differential operators and expect the outcomes to be as expected (or even well defined). So this question is really not about the derivation/definition of the  Wirtinger Derivatives, that's all document very well. It's about why we can write for example \begin{align} \frac{\partial (g\circ f)}{\partial z}&=\frac{\partial (g(f(z,\bar z),\bar f(z,\bar z))}{\partial z}\\\\ &=\left.\frac{\partial g(w,\bar w)}{\partial w}\right|_{w=f(z,\bar z)}\times \frac{\partial f(z,\bar z)}{\partial z}+\left.\frac{\partial g(w,\bar w)}{\partial \bar w}\right|_{\bar w=\bar f(z,\bar z)}\times \frac{\partial \bar f(z,\bar z)}{\partial z}\\\\ &=\left(\frac{\partial g}{\partial z}\circ f\right)\frac{\partial f}{\partial z}+\left(\frac{\partial g}{\partial \bar z}\circ f\right)\frac{\partial \bar f}{\partial z} \end{align} (copied from here ). I just don't see how the formal definition of the Wirtinger derivatives makes it so that all of this goes through. An answer to this question would explain, rigorously, why the steps in the above calculation are justified, starting from the fact we can write $f(z)=f(z,\bar{z})$ in a well-defined way s.t. the operators $\frac{\partial}{\partial z}$ and $\frac{\partial}{\partial \bar{z}}$ behave as expected. Thank you",,['complex-analysis']
50,Is there a rational surjection $\Bbb N\to\Bbb Q$?,Is there a rational surjection ?,\Bbb N\to\Bbb Q,"The question is in the title. Is there a one-dimensional rational function $f\in\Bbb R(X)$ which restricts to $\Bbb N\to\Bbb Q$, which is a surjection onto $\Bbb Q$? My guess is no. Expanding the scope a little (at the expense of precision), are there any ""nice"" functions that enumerate $\Bbb Q$? Here ""nice"" is meant to exclude the floor function or absolute value function and related trickery. At first I thought it might work to use analytic functions here, but there is an analytic function taking any chosen values on $\Bbb N$ subject to a mild growth hypothesis (I think $f(n)\in o(n)$), by defining $f(z)=\sum_{n\in\Bbb N}a_n{\rm sinc}(\frac{z-n}\pi)$, where ${\rm sinc}(z)=\frac{\sin(z)}z$ continuously extended over zero. I will let answerers supply their own definitions of ""nice"" if they want to tackle the broader question.","The question is in the title. Is there a one-dimensional rational function $f\in\Bbb R(X)$ which restricts to $\Bbb N\to\Bbb Q$, which is a surjection onto $\Bbb Q$? My guess is no. Expanding the scope a little (at the expense of precision), are there any ""nice"" functions that enumerate $\Bbb Q$? Here ""nice"" is meant to exclude the floor function or absolute value function and related trickery. At first I thought it might work to use analytic functions here, but there is an analytic function taking any chosen values on $\Bbb N$ subject to a mild growth hypothesis (I think $f(n)\in o(n)$), by defining $f(z)=\sum_{n\in\Bbb N}a_n{\rm sinc}(\frac{z-n}\pi)$, where ${\rm sinc}(z)=\frac{\sin(z)}z$ continuously extended over zero. I will let answerers supply their own definitions of ""nice"" if they want to tackle the broader question.",,"['complex-analysis', 'number-theory', 'rational-numbers', 'rational-functions']"
51,"Prob 15, Chap. 1 in Baby Rudin: If this condition also sufficient for equality?","Prob 15, Chap. 1 in Baby Rudin: If this condition also sufficient for equality?",,"Here's Prob. 15, Chap. 1 in the book Principles of Mathematical Analysis by Wlater Rudin, 3rd edition: Under what conditions does equality hold in the Schwarz inequality? Now the Schwarz inequality, which is Theorem 1.35 in Rudin, is as follows: If $a_1, \ldots, a_n$ and $b_1, \ldots, b_n$ are complex numbers, then $$ \left\vert \sum_{j=1}^n a_j \overline{b_j} \right\vert^2 \leq \sum_{j=1}^n \left\vert a_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2.$$ If there is a complex number $z$ such that $a_j = z b_j$ for each $j=1, \ldots, n$ , then we have $$ \begin{align} \left\vert \sum_{j=1}^n a_j \overline{b_j} \right\vert^2 &= \left\vert \sum_{j=1}^n z b_j \overline{b_j} \right\vert^2 \\  &= \left\vert z \ \sum_{j=1}^n \left\vert b_j \right\vert^2 \right\vert^2 \\ &= \vert z \vert^2 \cdot \left\vert  \sum_{j=1}^n \left\vert b_j \right\vert^2 \right\vert^2 \\ &= \vert z \vert^2 \cdot \left( \sum_{j=1}^n \left\vert b_j \right\vert^2 \right)^2,   \end{align} $$ whereas $$ \begin{align} \sum_{j=1}^n \left\vert a_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2 &= \sum_{j=1}^n \left\vert z b_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2 \\  &=  \sum_{j=1}^n  \vert z \vert^2 \left\vert  b_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2 \\ &= \vert z \vert^2 \cdot \left( \sum_{j=1}^n \left\vert b_j \right\vert^2 \right)^2 \\  &= \left\vert \sum_{j=1}^n a_j \overline{b_j} \right\vert^2. \end{align} $$ Now is this condition also a necessary condition for the equality to hold in the Schwarz ""inequality""?","Here's Prob. 15, Chap. 1 in the book Principles of Mathematical Analysis by Wlater Rudin, 3rd edition: Under what conditions does equality hold in the Schwarz inequality? Now the Schwarz inequality, which is Theorem 1.35 in Rudin, is as follows: If and are complex numbers, then If there is a complex number such that for each , then we have whereas Now is this condition also a necessary condition for the equality to hold in the Schwarz ""inequality""?","a_1, \ldots, a_n b_1, \ldots, b_n  \left\vert \sum_{j=1}^n a_j \overline{b_j} \right\vert^2 \leq \sum_{j=1}^n \left\vert a_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2. z a_j = z b_j j=1, \ldots, n 
\begin{align}
\left\vert \sum_{j=1}^n a_j \overline{b_j} \right\vert^2 &= \left\vert \sum_{j=1}^n z b_j \overline{b_j} \right\vert^2 \\ 
&= \left\vert z \ \sum_{j=1}^n \left\vert b_j \right\vert^2 \right\vert^2 \\
&= \vert z \vert^2 \cdot \left\vert  \sum_{j=1}^n \left\vert b_j \right\vert^2 \right\vert^2 \\
&= \vert z \vert^2 \cdot \left( \sum_{j=1}^n \left\vert b_j \right\vert^2 \right)^2,  
\end{align}
 
\begin{align}
\sum_{j=1}^n \left\vert a_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2 &= \sum_{j=1}^n \left\vert z b_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2 \\ 
&=  \sum_{j=1}^n  \vert z \vert^2 \left\vert  b_j \right\vert^2 \sum_{j=1}^n \left\vert b_j \right\vert^2 \\
&= \vert z \vert^2 \cdot \left( \sum_{j=1}^n \left\vert b_j \right\vert^2 \right)^2 \\ 
&= \left\vert \sum_{j=1}^n a_j \overline{b_j} \right\vert^2.
\end{align}
","['calculus', 'real-analysis', 'complex-analysis', 'analysis', 'inequality']"
52,Is $\frac{z-\alpha}{1-\overline{\alpha}z}$ some special function in complex analysis?,Is  some special function in complex analysis?,\frac{z-\alpha}{1-\overline{\alpha}z},Many homework problems seem to use the following function (or something very close to it): $$F_\alpha(z)=\frac{z-\alpha}{1-\overline{\alpha}z}$$ Does it serve some special purposes in complex analysis? It does revolve around the unit circle.,Many homework problems seem to use the following function (or something very close to it): $$F_\alpha(z)=\frac{z-\alpha}{1-\overline{\alpha}z}$$ Does it serve some special purposes in complex analysis? It does revolve around the unit circle.,,['complex-analysis']
53,Error on a complex analysis qualifying exam?,Error on a complex analysis qualifying exam?,,"Let $f(z) = \sum_{n = 0}^\infty c_n z^n$ for $\left| z \right| < R$. The problem as stated. For all $r < R$, $$\int_{\left\{ |z| = r \right\}} \left| f(z) \right|^2 \, dz = 2\pi \sum_{n=0}^\infty \left| c_n \right|^2 r^{2n}. $$ What I think the statement should be. For all $r < R$, $$\int_{\left\{ |z| = r \right\}} \frac{\left| f(z) \right|^2}{iz} \, dz = 2\pi \sum_{n=0}^\infty \left| c_n \right|^2 r^{2n}. $$ Basically, I think the professor forgot to account for the derivative $\gamma^\prime(t) = ire^{it}$ that enters into the integrand when we calculate the integral over $[0, 2\pi]$. Question. Am I correct? Thanks for your help.","Let $f(z) = \sum_{n = 0}^\infty c_n z^n$ for $\left| z \right| < R$. The problem as stated. For all $r < R$, $$\int_{\left\{ |z| = r \right\}} \left| f(z) \right|^2 \, dz = 2\pi \sum_{n=0}^\infty \left| c_n \right|^2 r^{2n}. $$ What I think the statement should be. For all $r < R$, $$\int_{\left\{ |z| = r \right\}} \frac{\left| f(z) \right|^2}{iz} \, dz = 2\pi \sum_{n=0}^\infty \left| c_n \right|^2 r^{2n}. $$ Basically, I think the professor forgot to account for the derivative $\gamma^\prime(t) = ire^{it}$ that enters into the integrand when we calculate the integral over $[0, 2\pi]$. Question. Am I correct? Thanks for your help.",,['complex-analysis']
54,Location of roots of degree six complex polynomial,Location of roots of degree six complex polynomial,,"I want to prove that $z^6 +192 z + 640 =0$ has one root in the first and fourth quadrants and two roots in the second and third quadrants. How can I do this? I have tried some ideas like using Vieta's formulas, but still no result.","I want to prove that $z^6 +192 z + 640 =0$ has one root in the first and fourth quadrants and two roots in the second and third quadrants. How can I do this? I have tried some ideas like using Vieta's formulas, but still no result.",,['complex-analysis']
55,On what domain is the dilogarithm analytic?,On what domain is the dilogarithm analytic?,,"The series $\displaystyle\sum \dfrac{z^n}{n^2}$ converges for $\lvert z\rvert<1$ by the ratio test, meaning that the dilogarithm function $\text{Li}_2(z),$ which is equal to the series $\displaystyle\sum \dfrac{z^n}{n^2}$ when it converges, is certainly analytic on $\lvert z\rvert<1$. Similarly, by the ratio test, the series diverges for $\lvert z\rvert>1$. And we know that for a meromorphic function, the radius of convergence is always the distance from the center to the nearest singularity (wikipedia). Hence we should conclude that this function has a pole somewhere on $\lvert z\rvert=1$? On the other hand, at the point $z=1$ it converges to $\pi^2/6$ (see Basel problem ), it must also converge at the point $z=-1$, and it is stated on this question by Ben that the series is convergent on the whole circle $\lvert z\rvert=1$ (this confused me and prompted the question), and on a comment to an answer to a related question, one is reminded by user 23rd that if a function is analytic on a closed disk, then it is analytic on an open disk of larger radius. So we should conclude that this series is convergent for some $z$ with $\lvert z\rvert>1$? For the whole complex plane? In fact, this Wolfram alpha page does claim that the function is analytic on all of $\mathbb{C}$ (if I'm reading it correctly; it's very terse). Actually that second related question ( singularity of analytic continuation of $f(z) = \sum_{n=1}^\infty \frac{z^n}{n^2}$ ) already contains the answer to my question: the dilogarithm is analytic on $\mathbb{C}\setminus [1,\infty)$. But I can't understand how that answer is consistent with the other remarks, and the Wolfram page. How is this situation reconciled? Could I get an explanation that's a little more detailed than what's already there?","The series $\displaystyle\sum \dfrac{z^n}{n^2}$ converges for $\lvert z\rvert<1$ by the ratio test, meaning that the dilogarithm function $\text{Li}_2(z),$ which is equal to the series $\displaystyle\sum \dfrac{z^n}{n^2}$ when it converges, is certainly analytic on $\lvert z\rvert<1$. Similarly, by the ratio test, the series diverges for $\lvert z\rvert>1$. And we know that for a meromorphic function, the radius of convergence is always the distance from the center to the nearest singularity (wikipedia). Hence we should conclude that this function has a pole somewhere on $\lvert z\rvert=1$? On the other hand, at the point $z=1$ it converges to $\pi^2/6$ (see Basel problem ), it must also converge at the point $z=-1$, and it is stated on this question by Ben that the series is convergent on the whole circle $\lvert z\rvert=1$ (this confused me and prompted the question), and on a comment to an answer to a related question, one is reminded by user 23rd that if a function is analytic on a closed disk, then it is analytic on an open disk of larger radius. So we should conclude that this series is convergent for some $z$ with $\lvert z\rvert>1$? For the whole complex plane? In fact, this Wolfram alpha page does claim that the function is analytic on all of $\mathbb{C}$ (if I'm reading it correctly; it's very terse). Actually that second related question ( singularity of analytic continuation of $f(z) = \sum_{n=1}^\infty \frac{z^n}{n^2}$ ) already contains the answer to my question: the dilogarithm is analytic on $\mathbb{C}\setminus [1,\infty)$. But I can't understand how that answer is consistent with the other remarks, and the Wolfram page. How is this situation reconciled? Could I get an explanation that's a little more detailed than what's already there?",,"['complex-analysis', 'special-functions', 'polylogarithm']"
56,How is the function$ f\left ( z \right )=\left ( x^{3}+3xy^{2}-3x \right )+i\left ( y^{3}+3x^{2}y-3y \right )$ nowhere analytic,How is the function nowhere analytic, f\left ( z \right )=\left ( x^{3}+3xy^{2}-3x \right )+i\left ( y^{3}+3x^{2}y-3y \right ),"In a problem I've been doing it is stated to show that even though the function is differentiable along the coordinate axes, it is nowhere analytic. By definition, a function is differentiable if the following limit exists and is finite $$\lim _{\Delta z \to0 }\frac{f\left ( z+\Delta z \right )-f\left ( z \right )}{\Delta z}.$$ Along the x-axis I got something like $f^{'}\left ( z \right )=3x^{2}+3x$(it's important that it exists). Similar analysis holds for the y-axis. The Cauchy-Riemann equations yield the following system : $$x^{2}+y^{2}=y^{2}+x^{2}$$ $$xy=-xy$$ That means the the necessary conditions are met only along the lines $x=0$ or $y=0$. The partials of $u$ and $v$ are elementary functions and as such are continuous on their whole domain(which includes the axes).  I have, thus proven that the function IS differentiable along the axes, which is contrary to the problem's statement. This seemed a bit odd, so I tried doing this analysis by definition, namely, after proving differentiability(the difference between analyticity and differentiabilty is subtle) I used the following two definitions: Definition 1. A function is analytic in a point if it is differentiable in SOME neighborhood of that point. This obviously holds true for every point on the axes. Definition 2.  A function is analytic in some region if it is analytic in every point of that region. This intuitively also holds true. One point where this might break down is the fact that the axes might not even be considered regions(which are open here, in the topological sense.). By all definitions I have read and searched for, a line is to be considered an open region. Please, feel free to prove me wrong, as I have been thinking this over for a long period.","In a problem I've been doing it is stated to show that even though the function is differentiable along the coordinate axes, it is nowhere analytic. By definition, a function is differentiable if the following limit exists and is finite $$\lim _{\Delta z \to0 }\frac{f\left ( z+\Delta z \right )-f\left ( z \right )}{\Delta z}.$$ Along the x-axis I got something like $f^{'}\left ( z \right )=3x^{2}+3x$(it's important that it exists). Similar analysis holds for the y-axis. The Cauchy-Riemann equations yield the following system : $$x^{2}+y^{2}=y^{2}+x^{2}$$ $$xy=-xy$$ That means the the necessary conditions are met only along the lines $x=0$ or $y=0$. The partials of $u$ and $v$ are elementary functions and as such are continuous on their whole domain(which includes the axes).  I have, thus proven that the function IS differentiable along the axes, which is contrary to the problem's statement. This seemed a bit odd, so I tried doing this analysis by definition, namely, after proving differentiability(the difference between analyticity and differentiabilty is subtle) I used the following two definitions: Definition 1. A function is analytic in a point if it is differentiable in SOME neighborhood of that point. This obviously holds true for every point on the axes. Definition 2.  A function is analytic in some region if it is analytic in every point of that region. This intuitively also holds true. One point where this might break down is the fact that the axes might not even be considered regions(which are open here, in the topological sense.). By all definitions I have read and searched for, a line is to be considered an open region. Please, feel free to prove me wrong, as I have been thinking this over for a long period.",,['complex-analysis']
57,"Evaluate the integration $\int_{|z|=100}f(z)\,dz$",Evaluate the integration,"\int_{|z|=100}f(z)\,dz","Let , $$f(z)=\frac{1}{z}.\frac{1-2z}{z-2}\cdots \frac{1-10z}{z-10}$$Find $$\int_{|z|=100}f(z)\,dz$$ We find that the function $f(z)$ has simple pole at the points $z=0,2,4,6,8,10$ , and all the points lie in $|z|=100$. So the required integral equal to $2\pi i\times\text{sum of the residues}$. But that process is too much laborious in this case. Does there any other simplest way to evaluate the integral ?","Let , $$f(z)=\frac{1}{z}.\frac{1-2z}{z-2}\cdots \frac{1-10z}{z-10}$$Find $$\int_{|z|=100}f(z)\,dz$$ We find that the function $f(z)$ has simple pole at the points $z=0,2,4,6,8,10$ , and all the points lie in $|z|=100$. So the required integral equal to $2\pi i\times\text{sum of the residues}$. But that process is too much laborious in this case. Does there any other simplest way to evaluate the integral ?",,['complex-analysis']
58,Suppose $\sum_{k=-\infty}^{\infty}a_kz^k$ and $\sum_{-\infty}^{\infty}b_kz^k$ converge to $1/\sin(\pi z)$. Find $b_k-a_k$.,Suppose  and  converge to . Find .,\sum_{k=-\infty}^{\infty}a_kz^k \sum_{-\infty}^{\infty}b_kz^k 1/\sin(\pi z) b_k-a_k,"Suppose that the Laurent series $\sum_{k=-\infty}^{\infty}a_kz^k$ converges to $1/\sin(\pi z)$ when $0<|z|<1$, and suppose that the Laurent series $\sum_{k=-\infty}^{\infty}b_kz^k$ converges to $1/\sin(\pi z)$ when $1<|z|<2$. Find, for every integer $k$, a simple expression for the difference $(b_k-a_k)$. I don't quite know where to start with this. I was thinking that $1/\sin(\pi z)$ has simple poles at $z=\pm 1$, so we might be able to say $(z^2-1)\sum_{k=-\infty}^{\infty}a_kz^k$ and $(z^2-1)\sum_{k=-\infty}^{\infty}b_kz^k$ both converge for $0<|z|<2$, but I'm not quite sure. I was also considering using Euler's product representation for sine somehow, but I couldn't quite figure out how. Any help is greatly appreicated (hints or tips preferred). Thanks","Suppose that the Laurent series $\sum_{k=-\infty}^{\infty}a_kz^k$ converges to $1/\sin(\pi z)$ when $0<|z|<1$, and suppose that the Laurent series $\sum_{k=-\infty}^{\infty}b_kz^k$ converges to $1/\sin(\pi z)$ when $1<|z|<2$. Find, for every integer $k$, a simple expression for the difference $(b_k-a_k)$. I don't quite know where to start with this. I was thinking that $1/\sin(\pi z)$ has simple poles at $z=\pm 1$, so we might be able to say $(z^2-1)\sum_{k=-\infty}^{\infty}a_kz^k$ and $(z^2-1)\sum_{k=-\infty}^{\infty}b_kz^k$ both converge for $0<|z|<2$, but I'm not quite sure. I was also considering using Euler's product representation for sine somehow, but I couldn't quite figure out how. Any help is greatly appreicated (hints or tips preferred). Thanks",,"['complex-analysis', 'power-series']"
59,"$\lim\limits_{|z| \to \infty} f(z) = \infty$, show that $f$ is a polynomial. [duplicate]",", show that  is a polynomial. [duplicate]",\lim\limits_{|z| \to \infty} f(z) = \infty f,"This question already has answers here : Show that this entire function is polynomial. (2 answers) Closed 2 years ago . I had an approach to the following problem which now I'm not sure will work: If $f$ is entire, and $\lim\limits_{z \to \infty} f(z) = \infty$, show that $f$ is a polynomial. Case 1: there exist $C > 0, N \in \mathbb{N}$ such that $|f(z)| \leq C \cdot |z|^N$ for all $z$.  A standard argument shows that $f$ has to be a polynomial. Case 2 is where Case 1 does not hold.  Since $f(z)$ goes to infinity, $f$ can have only finitely many zeroes $c_1, ... , c_r$ with multiplicities $m_1, ... , m_r$.  Then I'd like to say that $f$ grows so fast that $$g(z) := \frac{f(z)}{(z-c_1)^{m_1} \cdots (z - c_r)^{m_r}}$$ also goes to infinity as $z \to \infty$.  But it's not clear that this will actually be the case.  I might have to weaken the hypothesis of Case 1 to make this work, but I'm not sure how weak I can make it. Assuming I can have $g$ go to infinity, then $g$ will be an entire function with no zeroes, so $\frac{1}{g}$ will be bounded, hence constant.  Thus $f(z) = k(z-c_1)^{m_1} \cdots (z - c_r)^{m_r}$ for some $k \in \mathbb{C}$, as required.","This question already has answers here : Show that this entire function is polynomial. (2 answers) Closed 2 years ago . I had an approach to the following problem which now I'm not sure will work: If $f$ is entire, and $\lim\limits_{z \to \infty} f(z) = \infty$, show that $f$ is a polynomial. Case 1: there exist $C > 0, N \in \mathbb{N}$ such that $|f(z)| \leq C \cdot |z|^N$ for all $z$.  A standard argument shows that $f$ has to be a polynomial. Case 2 is where Case 1 does not hold.  Since $f(z)$ goes to infinity, $f$ can have only finitely many zeroes $c_1, ... , c_r$ with multiplicities $m_1, ... , m_r$.  Then I'd like to say that $f$ grows so fast that $$g(z) := \frac{f(z)}{(z-c_1)^{m_1} \cdots (z - c_r)^{m_r}}$$ also goes to infinity as $z \to \infty$.  But it's not clear that this will actually be the case.  I might have to weaken the hypothesis of Case 1 to make this work, but I'm not sure how weak I can make it. Assuming I can have $g$ go to infinity, then $g$ will be an entire function with no zeroes, so $\frac{1}{g}$ will be bounded, hence constant.  Thus $f(z) = k(z-c_1)^{m_1} \cdots (z - c_r)^{m_r}$ for some $k \in \mathbb{C}$, as required.",,['complex-analysis']
60,Roots of a polynomial,Roots of a polynomial,,"I am working the next problem: Consider the polynomials    $$ p_n(z)=\sum_{j=0}^{n}\frac{z^j}{j!} $$   For $n \geq 2$, show that if $a \in \mathbb{C}$ is such that $|a|=1$ or $|a|=n$, then $p_n(a)\neq 0$ For the case $|a|=1$, I think i have a partial solution: Suppose that $a\in \mathbb{C}$ is such that $p_n(a)=0$ and $|a|=1$, then by the revers triangle inequality $$ 0 = | p_n(a)| > \left| 1 - \left|a+\frac{a^2}{2}+\cdots+\frac{a^n}{n!}\right|\right| $$ which is a contradiction, because since $n\geq 2$, the RHS of the last inequality must be positive (I said partial solution because I am not sure how to prove this, I am almost sure that this follows because $| a + \cdots a^n/n!|>1$ if $n\geq 2$ but I can't prove that either) EDIT: According to the comments this is wrong, so my question now extends to both cases! . For the case $|a|=n$, i tried something similar but it gets worst. My questions are: 1) Is my approach for the first case correct? If it is, how can I prove the details I am missing, and if is not how can I approach it? 2) How can I approach the second case ? Any help or hints will be very appreciated","I am working the next problem: Consider the polynomials    $$ p_n(z)=\sum_{j=0}^{n}\frac{z^j}{j!} $$   For $n \geq 2$, show that if $a \in \mathbb{C}$ is such that $|a|=1$ or $|a|=n$, then $p_n(a)\neq 0$ For the case $|a|=1$, I think i have a partial solution: Suppose that $a\in \mathbb{C}$ is such that $p_n(a)=0$ and $|a|=1$, then by the revers triangle inequality $$ 0 = | p_n(a)| > \left| 1 - \left|a+\frac{a^2}{2}+\cdots+\frac{a^n}{n!}\right|\right| $$ which is a contradiction, because since $n\geq 2$, the RHS of the last inequality must be positive (I said partial solution because I am not sure how to prove this, I am almost sure that this follows because $| a + \cdots a^n/n!|>1$ if $n\geq 2$ but I can't prove that either) EDIT: According to the comments this is wrong, so my question now extends to both cases! . For the case $|a|=n$, i tried something similar but it gets worst. My questions are: 1) Is my approach for the first case correct? If it is, how can I prove the details I am missing, and if is not how can I approach it? 2) How can I approach the second case ? Any help or hints will be very appreciated",,"['complex-analysis', 'polynomials', 'roots']"
61,$e^{2\pi i x} = (e^{2\pi i})^x$: What happens if x is rational? [duplicate],: What happens if x is rational? [duplicate],e^{2\pi i x} = (e^{2\pi i})^x,"This question already has answers here : What is wrong with this fake proof $e^i = 1$? (2 answers) Closed 9 years ago . I'm a bit embarrassed that I've had difficulty on getting around this one: $$e^{2\pi i x}$$ Solving it by itself, we can reduce it down to $(e^{2\pi i})^x = 1^x$ such that $e^{2\pi i x} = 1$ for all $x$. However, directly plugging in non-integer rational numbers, chiefly $x = 1/2$, we get results that does not stay true to the above equality. I'm a bit perplexed of trying to explain the different results for this one. I admit that I haven't had too much experience with complex numbers compared to other fields.","This question already has answers here : What is wrong with this fake proof $e^i = 1$? (2 answers) Closed 9 years ago . I'm a bit embarrassed that I've had difficulty on getting around this one: $$e^{2\pi i x}$$ Solving it by itself, we can reduce it down to $(e^{2\pi i})^x = 1^x$ such that $e^{2\pi i x} = 1$ for all $x$. However, directly plugging in non-integer rational numbers, chiefly $x = 1/2$, we get results that does not stay true to the above equality. I'm a bit perplexed of trying to explain the different results for this one. I admit that I haven't had too much experience with complex numbers compared to other fields.",,['complex-analysis']
62,Show that an entire function is a proper if and only if it is a nonconstant polynomial,Show that an entire function is a proper if and only if it is a nonconstant polynomial,,Show that an entire function (Holomorphic on $ \mathbb C$) is  proper if and only if it is a non constant polynomial. Def :A map $f:X\to Y$  is called proper if $f^{-1}(K)$ is compact for every compact set $K$ in $Y$. Clearly every non constant polynomial is an entire proper fuction.Also if $f: \mathbb C \to \mathbb C$ is an entire proper function then $f$ will be nonconstant otherwise $C$ is bounded.I am having problem in showing that $f$ is a polynomial.Please help.,Show that an entire function (Holomorphic on $ \mathbb C$) is  proper if and only if it is a non constant polynomial. Def :A map $f:X\to Y$  is called proper if $f^{-1}(K)$ is compact for every compact set $K$ in $Y$. Clearly every non constant polynomial is an entire proper fuction.Also if $f: \mathbb C \to \mathbb C$ is an entire proper function then $f$ will be nonconstant otherwise $C$ is bounded.I am having problem in showing that $f$ is a polynomial.Please help.,,['complex-analysis']
63,Evaluating contour integral without using Residue Theorem,Evaluating contour integral without using Residue Theorem,,"Find the value of the integration without using Cauchy integral   formula/Residue theorem: $\int_{C}\cfrac{dz}{z^2+1}$ where C is a simple closed contour   oriented in counter clockwise direction containing z = i as an   interior point and also C lies in the interior of the circle $|z-i| =  \cfrac{1}{2}$. Now, I tried to solve it in this way: $\int_{C}\cfrac{dz}{z^2+1}$ = $\int_{C}\cfrac{dz}{(z+i)(z-i)}$ = $\cfrac{i}{2}(\int_{C}\cfrac{dz}{z+i} - \int_{C}\cfrac{dz}{z-i})$ I was thinking of using the fact that both the integrals inside the brackets would be equal to $\pi i$, but I am not sure about that. Can someone please give me a hint for solving this question? Thanks","Find the value of the integration without using Cauchy integral   formula/Residue theorem: $\int_{C}\cfrac{dz}{z^2+1}$ where C is a simple closed contour   oriented in counter clockwise direction containing z = i as an   interior point and also C lies in the interior of the circle $|z-i| =  \cfrac{1}{2}$. Now, I tried to solve it in this way: $\int_{C}\cfrac{dz}{z^2+1}$ = $\int_{C}\cfrac{dz}{(z+i)(z-i)}$ = $\cfrac{i}{2}(\int_{C}\cfrac{dz}{z+i} - \int_{C}\cfrac{dz}{z-i})$ I was thinking of using the fact that both the integrals inside the brackets would be equal to $\pi i$, but I am not sure about that. Can someone please give me a hint for solving this question? Thanks",,"['complex-analysis', 'contour-integration']"
64,Showing $f(z)=x^2+iy^3$ is not analytic anywhere,Showing  is not analytic anywhere,f(z)=x^2+iy^3,"I want to show that the following function is not analytic anywhere. $$f(z)=x^2+iy^3$$ Now I don't really understand the Cauchy-Riemann equations, but it seems we take: $$u(x,y)=x^2,v(x,y)=y^3$$ as we normally would, and take the partial derivatives: $$u_x =2x, u_v = 0$$ $$v_x = 0, v_y = 3y^2$$ And we want: $$u_x=v_y,u_y = -v_x$$ For necessary condition for being analytic at some point. $$2x=3y^2,0=0$$ So we are potentially(not necessarily) analytic and any point such that $2x=3y^2$ I believe. Now, how then I have ruled out almost every point, how do I rule out these remaining points?","I want to show that the following function is not analytic anywhere. $$f(z)=x^2+iy^3$$ Now I don't really understand the Cauchy-Riemann equations, but it seems we take: $$u(x,y)=x^2,v(x,y)=y^3$$ as we normally would, and take the partial derivatives: $$u_x =2x, u_v = 0$$ $$v_x = 0, v_y = 3y^2$$ And we want: $$u_x=v_y,u_y = -v_x$$ For necessary condition for being analytic at some point. $$2x=3y^2,0=0$$ So we are potentially(not necessarily) analytic and any point such that $2x=3y^2$ I believe. Now, how then I have ruled out almost every point, how do I rule out these remaining points?",,['complex-analysis']
65,Power series expansion of Blaschke product,Power series expansion of Blaschke product,,"Suppose $B$ is a Blaschke product with at least one zero off the origin, and $B(z)=\sum_{k=0}^\infty {c_kz^k}$. Is it possible that $c_k\ge0$ for all $k=0,1,\ldots$? My try: Since $B(z)$ takes real values on the real axis, by Schwarz reflection principle, we know $B(\bar z)=\overline{B(z)}$. This happens if and only if, for every zero of $B$, its conjugate must be a zero of $B$ too. I have no idea how to use the assumption $c_k\ge0$. Can anyone give a hint? Thanks. By the way, I guess the answer is negative, isn't it? Note: A Blaschke product is referred to the infinite/finite product $$B(z)=z^k\prod_n\frac{z-\alpha_n}{1-\bar\alpha_nz}\frac{|\alpha_n|}{\alpha_n},$$ where $k\in\mathbb N$ and $\sum_n(1-|\alpha_n|)<+\infty$, $\color{red}{0<|\alpha_n|<1}$.","Suppose $B$ is a Blaschke product with at least one zero off the origin, and $B(z)=\sum_{k=0}^\infty {c_kz^k}$. Is it possible that $c_k\ge0$ for all $k=0,1,\ldots$? My try: Since $B(z)$ takes real values on the real axis, by Schwarz reflection principle, we know $B(\bar z)=\overline{B(z)}$. This happens if and only if, for every zero of $B$, its conjugate must be a zero of $B$ too. I have no idea how to use the assumption $c_k\ge0$. Can anyone give a hint? Thanks. By the way, I guess the answer is negative, isn't it? Note: A Blaschke product is referred to the infinite/finite product $$B(z)=z^k\prod_n\frac{z-\alpha_n}{1-\bar\alpha_nz}\frac{|\alpha_n|}{\alpha_n},$$ where $k\in\mathbb N$ and $\sum_n(1-|\alpha_n|)<+\infty$, $\color{red}{0<|\alpha_n|<1}$.",,"['complex-analysis', 'power-series', 'infinite-product']"
66,what is a Möbius transformation with no fixed points?,what is a Möbius transformation with no fixed points?,,"is there a Mobius transformation with no fixed points? I have the equation $$\frac{az+b}{cz+d}=z\implies cz^2+dz-az-b=0$$ given the fixed points when this is true. So if we set $c\ne 0$ we get two roots and thus two fixed points, but in the case of $c=0$ we get one fixed point. I can't see where there is a case with no fixed points?","is there a Mobius transformation with no fixed points? I have the equation $$\frac{az+b}{cz+d}=z\implies cz^2+dz-az-b=0$$ given the fixed points when this is true. So if we set $c\ne 0$ we get two roots and thus two fixed points, but in the case of $c=0$ we get one fixed point. I can't see where there is a case with no fixed points?",,"['complex-analysis', 'mobius-transformation']"
67,"Why does Titchmarsh say that we can move the derivative under $\frac{2}{\pi}\int_0^\infty \frac{\Xi(t)}{t^2 + \frac{1}{4}} \cosh(\alpha t) \, dt$",Why does Titchmarsh say that we can move the derivative under,"\frac{2}{\pi}\int_0^\infty \frac{\Xi(t)}{t^2 + \frac{1}{4}} \cosh(\alpha t) \, dt","If we define the Riemann-Xi function as $$ \Xi(t) = \xi(\frac{1}{2} + it)$$ where $$\xi(s) = \frac{1}{2}s(s-1)\pi^{-\frac{s}{2}}\Gamma(\frac{s}{2})\zeta(s),$$ then according to Titchmarsh in his adaptation of Hardy's proof that the zeta function has infinitely many zeros on the critical line, if we consider the integral $$ \frac{2}{\pi}\int_0^\infty \frac{\Xi(t)}{t^2 + \frac{1}{4}} \cosh(\alpha t) dt, $$ then ""since $\zeta(\frac{1}{2} + it) = O(t^A)$, $\Xi(t) = O(t^Ae^{-\frac{1}{4}\pi t})$, and the above integral may be differentiated with respect to $\alpha$ any number of times provided that $\alpha < \frac{1}{4}\pi$."" I don't really understand either of the claims; that is, why is $\Xi(T) = O(t^Ae^{-\frac{1}{4}\pi t})$ and why does this imply that we can move the derivative under the integral sign any number of times as long as $\alpha < \frac{1}{4}$.  Can someone explain these things? Here is my work so far: After plugging the definition of $\xi(s)$ into the definition of $\Xi(t)$ we get that $$ \Xi(t) = \frac{1}{2}(-\frac{1}{4} - t^2)\pi^{-\frac{1}{4} - \frac{it}{2}}\Gamma(\frac{1}{4} + \frac{it}{2})\zeta(\frac{1}{2} + it).$$ I can prove that for $|t| \geq 1$ and $Re(s) \geq \frac{1}{2}$, $|\zeta(s)| \leq |t|^{\frac{1}{2} + \epsilon}$ and I can also show that $|\Gamma(\frac{1}{4} + \frac{it}{2})| \leq \frac{\Gamma(\frac{1}{4})}{|t|}. $ Additionally, $|\pi^{-\frac{1}{4} - \frac{it}{2}}| = \pi^{-\frac{1}{4}} = e^{-\frac{1}{4} \log(\pi)}$.  I'm stuck after this.  Can anyone help?","If we define the Riemann-Xi function as $$ \Xi(t) = \xi(\frac{1}{2} + it)$$ where $$\xi(s) = \frac{1}{2}s(s-1)\pi^{-\frac{s}{2}}\Gamma(\frac{s}{2})\zeta(s),$$ then according to Titchmarsh in his adaptation of Hardy's proof that the zeta function has infinitely many zeros on the critical line, if we consider the integral $$ \frac{2}{\pi}\int_0^\infty \frac{\Xi(t)}{t^2 + \frac{1}{4}} \cosh(\alpha t) dt, $$ then ""since $\zeta(\frac{1}{2} + it) = O(t^A)$, $\Xi(t) = O(t^Ae^{-\frac{1}{4}\pi t})$, and the above integral may be differentiated with respect to $\alpha$ any number of times provided that $\alpha < \frac{1}{4}\pi$."" I don't really understand either of the claims; that is, why is $\Xi(T) = O(t^Ae^{-\frac{1}{4}\pi t})$ and why does this imply that we can move the derivative under the integral sign any number of times as long as $\alpha < \frac{1}{4}$.  Can someone explain these things? Here is my work so far: After plugging the definition of $\xi(s)$ into the definition of $\Xi(t)$ we get that $$ \Xi(t) = \frac{1}{2}(-\frac{1}{4} - t^2)\pi^{-\frac{1}{4} - \frac{it}{2}}\Gamma(\frac{1}{4} + \frac{it}{2})\zeta(\frac{1}{2} + it).$$ I can prove that for $|t| \geq 1$ and $Re(s) \geq \frac{1}{2}$, $|\zeta(s)| \leq |t|^{\frac{1}{2} + \epsilon}$ and I can also show that $|\Gamma(\frac{1}{4} + \frac{it}{2})| \leq \frac{\Gamma(\frac{1}{4})}{|t|}. $ Additionally, $|\pi^{-\frac{1}{4} - \frac{it}{2}}| = \pi^{-\frac{1}{4}} = e^{-\frac{1}{4} \log(\pi)}$.  I'm stuck after this.  Can anyone help?",,"['complex-analysis', 'analysis', 'asymptotics', 'analytic-number-theory', 'riemann-zeta']"
68,Prove that $\frac{1}{z+i} +\sin(z)=0$ has infinite solutions over $\mathbb{C}$,Prove that  has infinite solutions over,\frac{1}{z+i} +\sin(z)=0 \mathbb{C},Prove that $\frac{1}{z+i} +\sin(z)=0$ has infinite solutions over $\mathbb{C}$ Can someone give me a clue?,Prove that $\frac{1}{z+i} +\sin(z)=0$ has infinite solutions over $\mathbb{C}$ Can someone give me a clue?,,['complex-analysis']
69,How to determine the radius of convergence if the Taylor series cannot be written in a neat way?,How to determine the radius of convergence if the Taylor series cannot be written in a neat way?,,"I am trying to evaluate the radius of convergence of Taylor series centered at zero of function $$f(z)=\frac{\sin(3z)}{\sin(z+\pi/6)}$$ I guess the answer should be $\pi/6$ because the function will not be bounded if $x$ approaches $\pi/6$. And it is easy to show that $f$ is convergent for all $z$ with norm less than $\pi/6$ because the denominator will not reach zero. However, outside the circle with radius $\pi/6$ there do exist points that makes $f$ converge. So I am confused whether I get the right answer. Usually for a simple power series, if we determine the radius of convergence we will have the series diverge for all $z$ outside the circle. So I am really not sure what is the situation here.","I am trying to evaluate the radius of convergence of Taylor series centered at zero of function $$f(z)=\frac{\sin(3z)}{\sin(z+\pi/6)}$$ I guess the answer should be $\pi/6$ because the function will not be bounded if $x$ approaches $\pi/6$. And it is easy to show that $f$ is convergent for all $z$ with norm less than $\pi/6$ because the denominator will not reach zero. However, outside the circle with radius $\pi/6$ there do exist points that makes $f$ converge. So I am confused whether I get the right answer. Usually for a simple power series, if we determine the radius of convergence we will have the series diverge for all $z$ outside the circle. So I am really not sure what is the situation here.",,['complex-analysis']
70,Conway Complex Analysis Book Exercise 8 in the Riemann Zeta Function Chapter,Conway Complex Analysis Book Exercise 8 in the Riemann Zeta Function Chapter,,"I am studying the book of John B. Conway Functions of One Complex Variable(1978), and in the section of Riemann Zeta Function chapter 7 I couldn't solve the last exercise. Here it is: Let $\zeta (z)$ be the Riemann zeta function, which is meromorphic on C with a simple pole at z = 1 and holomorphic elsewhere, and set $$\eta(z)=\frac{\zeta'(z)}{\zeta(z)}$$ for $\operatorname{Re} z > 1$. Show that for any $z_0$ with $\operatorname{Re} z_0 \geq 1$ $\lim\limits_{z \to z_0}(z-z_0) \eta(z)=N$, where $N \in \mathbb{Z}$. There are 3 more following questions, this is only part (a) but I didn't wanted ask them all since if I can understand this one I might be able do the rest. So any hints/help is appreciated.","I am studying the book of John B. Conway Functions of One Complex Variable(1978), and in the section of Riemann Zeta Function chapter 7 I couldn't solve the last exercise. Here it is: Let $\zeta (z)$ be the Riemann zeta function, which is meromorphic on C with a simple pole at z = 1 and holomorphic elsewhere, and set $$\eta(z)=\frac{\zeta'(z)}{\zeta(z)}$$ for $\operatorname{Re} z > 1$. Show that for any $z_0$ with $\operatorname{Re} z_0 \geq 1$ $\lim\limits_{z \to z_0}(z-z_0) \eta(z)=N$, where $N \in \mathbb{Z}$. There are 3 more following questions, this is only part (a) but I didn't wanted ask them all since if I can understand this one I might be able do the rest. So any hints/help is appreciated.",,"['complex-analysis', 'riemann-zeta']"
71,Residue of $\frac{\cos(\frac{\pi}{z-1})}{z^2 \sin z}$ at $z=1$,Residue of  at,\frac{\cos(\frac{\pi}{z-1})}{z^2 \sin z} z=1,"Residue of $$\frac{1}{z^2 \sin z}\cos\left(\frac{\pi}{z-1}\right)$$ at $z=1$. More importantly, I don't even know whether it exists or not. The one who creates this question has made questions that are unsolvable. I have tried some methods while they are not so successful. Wolfram alpha. It doesn't even give an answer this times. Series expansion. But this turns out to be too ugly. Expanding $\cos$, $z^2$ and $\sin $ respectively, and evaluate the coefficient of $\frac{1}{z-1}$ seems impossible and silly (without aid of matlab). see if it is a removable singularity. Considering $\lim_{z \to 1} (z-1) f(z)$, I once thought I made it by $-1 \leq \cos z \leq 1$, but this inequality doesn't apply in complex. Please help.","Residue of $$\frac{1}{z^2 \sin z}\cos\left(\frac{\pi}{z-1}\right)$$ at $z=1$. More importantly, I don't even know whether it exists or not. The one who creates this question has made questions that are unsolvable. I have tried some methods while they are not so successful. Wolfram alpha. It doesn't even give an answer this times. Series expansion. But this turns out to be too ugly. Expanding $\cos$, $z^2$ and $\sin $ respectively, and evaluate the coefficient of $\frac{1}{z-1}$ seems impossible and silly (without aid of matlab). see if it is a removable singularity. Considering $\lim_{z \to 1} (z-1) f(z)$, I once thought I made it by $-1 \leq \cos z \leq 1$, but this inequality doesn't apply in complex. Please help.",,"['complex-analysis', 'residue-calculus']"
72,Stein simply connected slit,Stein simply connected slit,,"STATEMENT: Prove that the complex plane slit along the union of the rays $\cup_{k=1}^n\left\{A_k+iy: y\leq 0\right\}$ is simply connected. This is question 19 in chapter 8 of Stein's Complex Analysis text. QUESTION: I don't understand what it's asking for. Could someone please provide a picture or rewording of the statement to make it clearer. Note that I don't want an answer, rather I just want help with parsing what is being said in the question. Thanks. QUESTION 2: I am unsure of how to proceed with this problem. I assume that given two points and two curves connecting those points that I could shift it into the upper half plane which is connected, but I can't seem to find a homotopy that deforms one curve into another without conflict. The only resolution I can think of is that since the upper half plane is connected we might be able to assume that there exists a homotopy that is completedly contained in the space between the two curves, inclusive. Any suggestions.","STATEMENT: Prove that the complex plane slit along the union of the rays $\cup_{k=1}^n\left\{A_k+iy: y\leq 0\right\}$ is simply connected. This is question 19 in chapter 8 of Stein's Complex Analysis text. QUESTION: I don't understand what it's asking for. Could someone please provide a picture or rewording of the statement to make it clearer. Note that I don't want an answer, rather I just want help with parsing what is being said in the question. Thanks. QUESTION 2: I am unsure of how to proceed with this problem. I assume that given two points and two curves connecting those points that I could shift it into the upper half plane which is connected, but I can't seem to find a homotopy that deforms one curve into another without conflict. The only resolution I can think of is that since the upper half plane is connected we might be able to assume that there exists a homotopy that is completedly contained in the space between the two curves, inclusive. Any suggestions.",,"['complex-analysis', 'analysis']"
73,Why do we need a branch cut for $\int_0^{\infty} \frac{x^{\frac{1}{2}}}{{(1 + x)^2}}dx$?,Why do we need a branch cut for ?,\int_0^{\infty} \frac{x^{\frac{1}{2}}}{{(1 + x)^2}}dx,"What is the significance of the $x^{\frac{1}{2}}$ in the numerator of this integral. I have read this kind of integral requires taking a branch cut. Why do we need a branch cut, what does it enable us to do? What happens if we don't take one? $$\int_0^{\infty} \frac{x^{\frac{1}{2}}}{{(1 + x)^2}}dx$$ Also, the pole in this problem lies on the real axis so we can use the method of ""a semicircle $C_R$ and joined at its endpoints by a line on the real axis $C_L$...So what method do we use for such an integral?","What is the significance of the $x^{\frac{1}{2}}$ in the numerator of this integral. I have read this kind of integral requires taking a branch cut. Why do we need a branch cut, what does it enable us to do? What happens if we don't take one? $$\int_0^{\infty} \frac{x^{\frac{1}{2}}}{{(1 + x)^2}}dx$$ Also, the pole in this problem lies on the real axis so we can use the method of ""a semicircle $C_R$ and joined at its endpoints by a line on the real axis $C_L$...So what method do we use for such an integral?",,"['complex-analysis', 'contour-integration', 'residue-calculus', 'complex-integration', 'branch-cuts']"
74,Show that $\log\log z$ is analytic,Show that  is analytic,\log\log z,"Show that $\log\log z$ is analytic in the domain consisting of the $z$ plane with a branch cut along the line $y = 0$ , $x \le 1$ . As of now I'm not too sure on how to solve this problem, so I was thinking you may have to use the Cauchy-Riemann equations to find the answer. I honestly tried it but I don't know what to do. If someone can help me out in solving this problem that would be great. Thanks!","Show that is analytic in the domain consisting of the plane with a branch cut along the line , . As of now I'm not too sure on how to solve this problem, so I was thinking you may have to use the Cauchy-Riemann equations to find the answer. I honestly tried it but I don't know what to do. If someone can help me out in solving this problem that would be great. Thanks!",\log\log z z y = 0 x \le 1,"['complex-analysis', 'complex-numbers', 'logarithms', 'real-numbers']"
75,Why isn't Euler's formula multivalued?,Why isn't Euler's formula multivalued?,,So it seems that all complex exponential functions are multivalued except for ones with base $e$. Why? Shouldn't all exponentials be multivalued?,So it seems that all complex exponential functions are multivalued except for ones with base $e$. Why? Shouldn't all exponentials be multivalued?,,"['complex-analysis', 'exponential-function', 'multivalued-functions']"
76,Orientation on Riemann surfaces,Orientation on Riemann surfaces,,$\mathcal{X}$ is a Riemann surface and $\mathcal{E}^{(2)}(\mathcal{X})$ is the $\mathbb{C}$-Vector space of all differentiable $2$-forms on $\mathcal{X}$. I want to define the orientation of $\mathcal{X}$: Why is $\mathcal{X}$ orientable if and only if there exists a  $2$-form $\omega \in \mathcal{E}^{(2)}(\mathcal{X})$ without zeros? What do we mean with the Standard-Orientation of $\mathcal{X}$? (Maybe my question is a bit easier if we take  $\mathcal{X}=\mathbb{C}$ as an example.),$\mathcal{X}$ is a Riemann surface and $\mathcal{E}^{(2)}(\mathcal{X})$ is the $\mathbb{C}$-Vector space of all differentiable $2$-forms on $\mathcal{X}$. I want to define the orientation of $\mathcal{X}$: Why is $\mathcal{X}$ orientable if and only if there exists a  $2$-form $\omega \in \mathcal{E}^{(2)}(\mathcal{X})$ without zeros? What do we mean with the Standard-Orientation of $\mathcal{X}$? (Maybe my question is a bit easier if we take  $\mathcal{X}=\mathbb{C}$ as an example.),,"['complex-analysis', 'differential-geometry', 'riemannian-geometry', 'riemann-surfaces']"
77,The complex function $\log(1+e^{iz})$,The complex function,\log(1+e^{iz}),"G.H. Hardy states the following: The function of the complex variable $z$ $$ e^{i p z} \log(1 \pm e^{iz})\frac{1}{z^{2} \pm \theta^{2}} = f(z), \  (-1 < p <1, \theta >0),$$         is infinitely-many valued, but can made single-valued by slitting the plane along the real axis and restricting the variable to the   upper half. He then later says, Again, $\log(1+e^{iz})$ will be shown immediately to have an imaginary   part which does not numerically exceed $i \pi$ as $z$ travels along the real axis. I don't quite understand the second statement. The function $\log(1+e^{iz})$ can be defined by the complex integral $$\int_{0}^{z}\frac{ie^{iw}}{1+e^{iw}} \, dw + \log 2.$$ The integrand has simple poles at $(2n+1) \pi$ with residue $1$. Each time we move around one of theses points from left to right, the imaginary part of $\log (1+e^{iz})$ decreases by $\pi$. Why then does the imaginary part of $\log(1+e^{iz})$ remain bounded as $z$ travels along the real axis?","G.H. Hardy states the following: The function of the complex variable $z$ $$ e^{i p z} \log(1 \pm e^{iz})\frac{1}{z^{2} \pm \theta^{2}} = f(z), \  (-1 < p <1, \theta >0),$$         is infinitely-many valued, but can made single-valued by slitting the plane along the real axis and restricting the variable to the   upper half. He then later says, Again, $\log(1+e^{iz})$ will be shown immediately to have an imaginary   part which does not numerically exceed $i \pi$ as $z$ travels along the real axis. I don't quite understand the second statement. The function $\log(1+e^{iz})$ can be defined by the complex integral $$\int_{0}^{z}\frac{ie^{iw}}{1+e^{iw}} \, dw + \log 2.$$ The integrand has simple poles at $(2n+1) \pi$ with residue $1$. Each time we move around one of theses points from left to right, the imaginary part of $\log (1+e^{iz})$ decreases by $\pi$. Why then does the imaginary part of $\log(1+e^{iz})$ remain bounded as $z$ travels along the real axis?",,"['complex-analysis', 'complex-integration']"
78,"When does conformal equivalence guarantee the existence of a ""conformal homotopy""?","When does conformal equivalence guarantee the existence of a ""conformal homotopy""?",,"Suppose $f$ is a conformal equivalence between two domains $D_1$ and $D_2$ in $\mathbb{C}$. Does this imply the existence of a map $F_t(z): D_1 \times [0, a] \rightarrow \mathbb{C}$ such that each $F_t$ is conformal in $z$ and smooth in $t$, $F_0 = \text{id}$, and $F_{a} = f$? If not, does this hold if we make stronger assumptions, such as requiring that the boundary be a Jordan domain, etc.?","Suppose $f$ is a conformal equivalence between two domains $D_1$ and $D_2$ in $\mathbb{C}$. Does this imply the existence of a map $F_t(z): D_1 \times [0, a] \rightarrow \mathbb{C}$ such that each $F_t$ is conformal in $z$ and smooth in $t$, $F_0 = \text{id}$, and $F_{a} = f$? If not, does this hold if we make stronger assumptions, such as requiring that the boundary be a Jordan domain, etc.?",,['complex-analysis']
79,Meromorphic and even,Meromorphic and even,,"I would like to do the following exercise : Let $f$ be a meromorphic function and $\mathcal{P}$ the set of its poles. We also assume that $f$ is even ($\forall z \in \mathbb{C}, \; f(z)=f(-z)$). Prove that $\mathcal{P}$ is symmetric with respect to $0$ and that, if $a \in \mathcal{P}$ and $\mathrm{Res}_{a}(f)$ denotes the residue of $f$ at $a$, then $\mathrm{Res}_{-a}(f) = - \mathrm{Res}_{a}(f)$. My try : let $a \in \mathcal{P}$ a pole of $f$ of order $k \in \mathbb{N}^{\ast}$. Since $f$ is even, $f$ is not defined at $-a$ and to prove that $a$ is also a pole of $f$ of order $k$, I need to prove that $(z+a)^{k}f(z)$ has a finite limit when $z \to -a$. It follows from : $$ \begin{align*} \lim \limits_{z \to -a}(z+a)^{k}f(z) &= {} \lim \limits_{z \to -a}(-1)^{k}(-z-a)^{k}f(-z) \\[2mm]  &= (-1)^{k}\lim \limits_{z \to a}(z-a)^{k}f(z) \\ \end{align*} $$ And $\displaystyle \lim \limits_{z \to a} (z-a)^{k}f(z)$ exists because $a$ is a pole of order $k$ of $f$. As a consequence, $-a$ is also a pole of $f$. For the residue relation, we can note that if $a$ is a pole of order $k$ of $f$, then : $$  \begin{align*} \mathrm{Res}_{-a}(f) &= {} \frac{1}{(k-1)!}\frac{d^{k-1}}{dz^{k-1}} \Big((z+a)^{k}f(z) \Big) \\[2mm]  &= \frac{1}{(k-1)!} \frac{d^{k-1}}{dz^{k-1}} \Big( (-1)^{k} (-z-a)^{k}f(z) \Big) \\[2mm]  &= (-1)^{k-1} \frac{1}{(k-1)!} \frac{d^{k-1}}{dz^{k-1}} (-1)^{k} \Big( (z-a)^{k}f(-z) \Big) \\[2mm]  &= - \mathrm{Res}_{a}(f) \\ \end{align*} $$ Is this OK or can it be improved ? Thanks.","I would like to do the following exercise : Let $f$ be a meromorphic function and $\mathcal{P}$ the set of its poles. We also assume that $f$ is even ($\forall z \in \mathbb{C}, \; f(z)=f(-z)$). Prove that $\mathcal{P}$ is symmetric with respect to $0$ and that, if $a \in \mathcal{P}$ and $\mathrm{Res}_{a}(f)$ denotes the residue of $f$ at $a$, then $\mathrm{Res}_{-a}(f) = - \mathrm{Res}_{a}(f)$. My try : let $a \in \mathcal{P}$ a pole of $f$ of order $k \in \mathbb{N}^{\ast}$. Since $f$ is even, $f$ is not defined at $-a$ and to prove that $a$ is also a pole of $f$ of order $k$, I need to prove that $(z+a)^{k}f(z)$ has a finite limit when $z \to -a$. It follows from : $$ \begin{align*} \lim \limits_{z \to -a}(z+a)^{k}f(z) &= {} \lim \limits_{z \to -a}(-1)^{k}(-z-a)^{k}f(-z) \\[2mm]  &= (-1)^{k}\lim \limits_{z \to a}(z-a)^{k}f(z) \\ \end{align*} $$ And $\displaystyle \lim \limits_{z \to a} (z-a)^{k}f(z)$ exists because $a$ is a pole of order $k$ of $f$. As a consequence, $-a$ is also a pole of $f$. For the residue relation, we can note that if $a$ is a pole of order $k$ of $f$, then : $$  \begin{align*} \mathrm{Res}_{-a}(f) &= {} \frac{1}{(k-1)!}\frac{d^{k-1}}{dz^{k-1}} \Big((z+a)^{k}f(z) \Big) \\[2mm]  &= \frac{1}{(k-1)!} \frac{d^{k-1}}{dz^{k-1}} \Big( (-1)^{k} (-z-a)^{k}f(z) \Big) \\[2mm]  &= (-1)^{k-1} \frac{1}{(k-1)!} \frac{d^{k-1}}{dz^{k-1}} (-1)^{k} \Big( (z-a)^{k}f(-z) \Big) \\[2mm]  &= - \mathrm{Res}_{a}(f) \\ \end{align*} $$ Is this OK or can it be improved ? Thanks.",,"['complex-analysis', 'proof-verification', 'residue-calculus']"
80,Analytic $F(z)$ has $f(z)$ as derivative $\implies$ $\int_\gamma f(z)\ dz = 0$ for $\gamma$ a closed curve,Analytic  has  as derivative   for  a closed curve,F(z) f(z) \implies \int_\gamma f(z)\ dz = 0 \gamma,"Hypothesis: Suppose that $F(z)$ has $f(z)$ as a derivative.  Suppose further that $F(z)$ is analytic.  Now consider the complex line integral $$ \tag{1} \int_\gamma f(z)\ dz $$ Question: Does this imply that $(1)$ is equal to zero if $\gamma$ is a closed curve?  If so, why? Attempt: There is a theorem that says that for $\gamma$ a closed curve, we have that $$ \int_\gamma p\ dx + q\ dy = 0 \iff p\ dx + q\ dy \text{ is an exact differential} $$ Then $f(z)\ dz = f(z)\ dx + i f(z)\ dy$ implies that $$ f(z)\ dz = f(z)\ dx + i f(z)\ dy = \underbrace{{\partial F \over \partial x}\ dx + i \left(- i{\partial F \over \partial y}\right)\ dy}_{\text{applying CR-equations to $F(z)$}} = {\partial F \over \partial x}\ dx + \left({\partial F \over \partial y}\right)\ dy $$ Then $f(z)\ dz = dF = {\partial F \over \partial x}dx + {\partial F \over \partial y} dy$ so that $f(z)\ dz$ is an exact differential as desired. Then via $(1)$ we have that $$ \int_\gamma f(z)\ dz = 0 $$ as desired. Is my proof correct?","Hypothesis: Suppose that $F(z)$ has $f(z)$ as a derivative.  Suppose further that $F(z)$ is analytic.  Now consider the complex line integral $$ \tag{1} \int_\gamma f(z)\ dz $$ Question: Does this imply that $(1)$ is equal to zero if $\gamma$ is a closed curve?  If so, why? Attempt: There is a theorem that says that for $\gamma$ a closed curve, we have that $$ \int_\gamma p\ dx + q\ dy = 0 \iff p\ dx + q\ dy \text{ is an exact differential} $$ Then $f(z)\ dz = f(z)\ dx + i f(z)\ dy$ implies that $$ f(z)\ dz = f(z)\ dx + i f(z)\ dy = \underbrace{{\partial F \over \partial x}\ dx + i \left(- i{\partial F \over \partial y}\right)\ dy}_{\text{applying CR-equations to $F(z)$}} = {\partial F \over \partial x}\ dx + \left({\partial F \over \partial y}\right)\ dy $$ Then $f(z)\ dz = dF = {\partial F \over \partial x}dx + {\partial F \over \partial y} dy$ so that $f(z)\ dz$ is an exact differential as desired. Then via $(1)$ we have that $$ \int_\gamma f(z)\ dz = 0 $$ as desired. Is my proof correct?",,"['complex-analysis', 'analysis', 'proof-verification']"
81,Prove that an entire function is constant,Prove that an entire function is constant,,"Is the following statement true? Suppose, $f:\mathbb C\to \mathbb C $ be an entire function. $ |f(z)| $ is bounded in a region where $ \alpha\le \arg(z)\le \beta $ with $|\beta-\alpha|>\pi $. Then $f(z) $ is constant.","Is the following statement true? Suppose, $f:\mathbb C\to \mathbb C $ be an entire function. $ |f(z)| $ is bounded in a region where $ \alpha\le \arg(z)\le \beta $ with $|\beta-\alpha|>\pi $. Then $f(z) $ is constant.",,['complex-analysis']
82,Bound for Analytic Function on Unit Disk,Bound for Analytic Function on Unit Disk,,"The following is an old qualifying exam problem that I can't seem to piece together: Suppose we have an analytic function $f$ on the unit disk $\mathbb{D}$ s.t. $|f|  \leq 1$. Show $$ \frac{|f(0)|-|z|}{1-|f(0)||z|} \leq |f(z)| \leq \frac{|f(0)|+|z|}{1+|f(0)||z|}  $$. I've tried two things. First, decomposing $f$ into its real and imaginary parts and applying the Harnack inequality to each (after adding 1 so that it is nonnegative) and then piecing them together so they say something about $f$. I couldn't get that to look close to the inequality.  Second, I define $h(z) = \frac{f(z)-f(0)}{1+|f(0)|}$ and apply the Schwartz lemma. This comes close but I couldn't get it to work.","The following is an old qualifying exam problem that I can't seem to piece together: Suppose we have an analytic function $f$ on the unit disk $\mathbb{D}$ s.t. $|f|  \leq 1$. Show $$ \frac{|f(0)|-|z|}{1-|f(0)||z|} \leq |f(z)| \leq \frac{|f(0)|+|z|}{1+|f(0)||z|}  $$. I've tried two things. First, decomposing $f$ into its real and imaginary parts and applying the Harnack inequality to each (after adding 1 so that it is nonnegative) and then piecing them together so they say something about $f$. I couldn't get that to look close to the inequality.  Second, I define $h(z) = \frac{f(z)-f(0)}{1+|f(0)|}$ and apply the Schwartz lemma. This comes close but I couldn't get it to work.",,['complex-analysis']
83,A complex problem.,A complex problem.,,"We have a set $S:= \{e^{inr\pi} | n\in\Bbb N\}$. Where r is an irrational number. I wonder whether this set is dense in $\partial D(0,1)$. i.e. I want to see if $\overline S=\partial D(0,1).$ I think we can show that the set of arguments of $S$ in $[0,2\pi]$ is dense. And as $r$ is irrational, we can show that $\forall \epsilon \exists n\in \Bbb R$ s.t. $e^{inr\pi}$ has argument in $(0,\epsilon).$ Or equivalently $nr\pi \equiv \epsilon(mod 2\pi)$ Also I want to know if $r\in \Bbb Q$ then What can we say about above statement!!","We have a set $S:= \{e^{inr\pi} | n\in\Bbb N\}$. Where r is an irrational number. I wonder whether this set is dense in $\partial D(0,1)$. i.e. I want to see if $\overline S=\partial D(0,1).$ I think we can show that the set of arguments of $S$ in $[0,2\pi]$ is dense. And as $r$ is irrational, we can show that $\forall \epsilon \exists n\in \Bbb R$ s.t. $e^{inr\pi}$ has argument in $(0,\epsilon).$ Or equivalently $nr\pi \equiv \epsilon(mod 2\pi)$ Also I want to know if $r\in \Bbb Q$ then What can we say about above statement!!",,"['real-analysis', 'complex-analysis', 'analysis', 'several-complex-variables']"
84,Problem related to continuous complex mapping.,Problem related to continuous complex mapping.,,"We are given with a map $g:\bar D\to \Bbb C $, which is continuous on $\bar D$ and analytic on $D$. Where $D$ is a bounded domain and $\bar D=D\cup\partial D$. 1) I want to show that: $\partial(g(D))\subseteq g(\partial D).$ And further, I need two examples: a) First, to show that the above inclusion can be strict, that is: $\partial(g(D))\not= g(\partial D).$ b) Second example, I need to show that conclusion in (1) is not true if $D$ is  not bounded. So basically we have to show that the boundary of the open set $g(D)$ is contained in image of boundary of $D$ (and sometimes strictly contained). I think that we will use open mapping theorem. But how this theorem will help us here that is not clear.","We are given with a map $g:\bar D\to \Bbb C $, which is continuous on $\bar D$ and analytic on $D$. Where $D$ is a bounded domain and $\bar D=D\cup\partial D$. 1) I want to show that: $\partial(g(D))\subseteq g(\partial D).$ And further, I need two examples: a) First, to show that the above inclusion can be strict, that is: $\partial(g(D))\not= g(\partial D).$ b) Second example, I need to show that conclusion in (1) is not true if $D$ is  not bounded. So basically we have to show that the boundary of the open set $g(D)$ is contained in image of boundary of $D$ (and sometimes strictly contained). I think that we will use open mapping theorem. But how this theorem will help us here that is not clear.",,"['complex-analysis', 'analysis', 'several-complex-variables']"
85,Partial derivatives in $\mathbb{C}^n$,Partial derivatives in,\mathbb{C}^n,I'm trying to figure out an equality from a proof by Griffiths and Harris to the holomorphic inverse function theorem (in Principles of Algebraic Geometry). They state: $$\frac{\partial}{\partial \overline{z}_i}(f^{-1}(f(z))) = \sum_k\frac{\partial f_j^{-1}}{\partial z_k} \cdot \frac{\partial f_k}{\partial \overline{z}_i} + \sum_k\frac{\partial f_j^{-1}}{\partial \overline{z}_k} \cdot \frac{\partial \overline{f}_k}{\partial \overline{z}_i}$$ I'm a bit confused about how this deriviation came about... I would expect from the chain rule to have something in the lines of $ \frac{\partial f_j^{-1}}{\partial f_k} \cdot \frac{\partial f_k}{\partial \overline{z}_i}$. Or do i have it all wrong? And how did this sum get here? I understand the definition $$df = \sum_k\frac{\partial f}{\partial z_k}dz_k + \sum_k\frac{\partial f}{\partial \overline{z}_k}d\overline{z}_k $$ but how does this relate to partial derivatives such as the one above? Thank you.,I'm trying to figure out an equality from a proof by Griffiths and Harris to the holomorphic inverse function theorem (in Principles of Algebraic Geometry). They state: $$\frac{\partial}{\partial \overline{z}_i}(f^{-1}(f(z))) = \sum_k\frac{\partial f_j^{-1}}{\partial z_k} \cdot \frac{\partial f_k}{\partial \overline{z}_i} + \sum_k\frac{\partial f_j^{-1}}{\partial \overline{z}_k} \cdot \frac{\partial \overline{f}_k}{\partial \overline{z}_i}$$ I'm a bit confused about how this deriviation came about... I would expect from the chain rule to have something in the lines of $ \frac{\partial f_j^{-1}}{\partial f_k} \cdot \frac{\partial f_k}{\partial \overline{z}_i}$. Or do i have it all wrong? And how did this sum get here? I understand the definition $$df = \sum_k\frac{\partial f}{\partial z_k}dz_k + \sum_k\frac{\partial f}{\partial \overline{z}_k}d\overline{z}_k $$ but how does this relate to partial derivatives such as the one above? Thank you.,,"['complex-analysis', 'algebraic-geometry', 'partial-derivative']"
86,Continuity of Green's function,Continuity of Green's function,,"Suppose $\Omega \subset \mathbb C$ is a region (open and connected set) and let $$g(z,z_0)=G(z,z_0)-\log|z-z_0| $$ be its Green's function with pole at $z_0 \in \Omega$. Here $G(z,z_0)$ is the solution to the Dirichlet problem in $\Omega$ with boundary values $\log|\zeta-z_0|$. I'm trying to solve the following problem (from Ahlfors): Prove that $g(z,z_0)$ is simultaneously continuous in both variables, for $z \neq z_0$. Hint: Apply the maximum-minimum principle to $G(z,z_0)$. I know that $\log|z-z_0|$ is simultaneously continuous in both variables for $z \neq z_0$, being the composition of continuous functions. Thus it remains to show the same for $G(z,z_0)$. So far I know that $G(z,z_0)$ is symmetric and harmonic in each variable. How can I prove that $G(z,z_0)$ is simultaneously continuous in both variables for $z \neq z_0$? I can't see how to follow the hint unfortunately. Thanks!","Suppose $\Omega \subset \mathbb C$ is a region (open and connected set) and let $$g(z,z_0)=G(z,z_0)-\log|z-z_0| $$ be its Green's function with pole at $z_0 \in \Omega$. Here $G(z,z_0)$ is the solution to the Dirichlet problem in $\Omega$ with boundary values $\log|\zeta-z_0|$. I'm trying to solve the following problem (from Ahlfors): Prove that $g(z,z_0)$ is simultaneously continuous in both variables, for $z \neq z_0$. Hint: Apply the maximum-minimum principle to $G(z,z_0)$. I know that $\log|z-z_0|$ is simultaneously continuous in both variables for $z \neq z_0$, being the composition of continuous functions. Thus it remains to show the same for $G(z,z_0)$. So far I know that $G(z,z_0)$ is symmetric and harmonic in each variable. How can I prove that $G(z,z_0)$ is simultaneously continuous in both variables for $z \neq z_0$? I can't see how to follow the hint unfortunately. Thanks!",,"['complex-analysis', 'analysis', 'continuity']"
87,Prove that $f$ is constant,Prove that  is constant,f,Let $f:\mathbb{C}\rightarrow \mathbb{C}$ be an entire function. if there exists $\delta> 0$ and $w\in \mathbb{C}$  such that $$\left | f(z)-w \right | \geq \delta \qquad \forall z\in\mathbb C $$ Prove that $f$ is constant.,Let $f:\mathbb{C}\rightarrow \mathbb{C}$ be an entire function. if there exists $\delta> 0$ and $w\in \mathbb{C}$  such that $$\left | f(z)-w \right | \geq \delta \qquad \forall z\in\mathbb C $$ Prove that $f$ is constant.,,['complex-analysis']
88,Radius of Convergence of a Series,Radius of Convergence of a Series,,"How would I find the radius of convergence of the following series? $$ \sum_{n=1}^{\infty}\frac{(-1)^n}{n}z^{n(n+1)} $$ The ratio test and root test are inconclusive, so I think I have to use the definition of the radius of convergence $$\frac{1}{R}=\limsup|a_n|^{\frac{1}{n}}.$$ I have been told that the $n$-th coefficient of this series is not $$\frac{(-1)^n}{n}.$$ I am not sure what exactly I should equate to $|a_n|$. Any help is appreciated.","How would I find the radius of convergence of the following series? $$ \sum_{n=1}^{\infty}\frac{(-1)^n}{n}z^{n(n+1)} $$ The ratio test and root test are inconclusive, so I think I have to use the definition of the radius of convergence $$\frac{1}{R}=\limsup|a_n|^{\frac{1}{n}}.$$ I have been told that the $n$-th coefficient of this series is not $$\frac{(-1)^n}{n}.$$ I am not sure what exactly I should equate to $|a_n|$. Any help is appreciated.",,"['real-analysis', 'complex-analysis', 'power-series']"
89,Contour integration with 2 simple poles on contour,Contour integration with 2 simple poles on contour,,"Ok for this one I would appreciate if someone could give me a conceptual answer first. I am supposed to integrate $\int_{-\infty}^{\infty} \frac{e^{-i q t}}{p^2 - q^2} dq$ along a half circle C (whose radius goes to infinity), which comprises a horizontal path along the real line circumventing the two real poles -p & +p with a semicircle in the upper half plane, just as in part (a) I am to prove that the result is 0 if t<0 and $2 \pi i (-\frac{i}{p} ) \sin{pt}$ if t>0. Now I don't quite understand why the sign of t would change anything. Can someone enlighten me?","Ok for this one I would appreciate if someone could give me a conceptual answer first. I am supposed to integrate $\int_{-\infty}^{\infty} \frac{e^{-i q t}}{p^2 - q^2} dq$ along a half circle C (whose radius goes to infinity), which comprises a horizontal path along the real line circumventing the two real poles -p & +p with a semicircle in the upper half plane, just as in part (a) I am to prove that the result is 0 if t<0 and $2 \pi i (-\frac{i}{p} ) \sin{pt}$ if t>0. Now I don't quite understand why the sign of t would change anything. Can someone enlighten me?",,['complex-analysis']
90,A conformal map from $\mathbb{H} \setminus \mathbb{D}$ to $\mathbb{D}$,A conformal map from  to,\mathbb{H} \setminus \mathbb{D} \mathbb{D},"I want to find a conformal map from $W=\{Im(z) > 0, |z|>1\}$ (which is the upper half plane excluding the unit circle), to the unit circle itself. The problem was unclear as to whether we need to include the boundary of the circle or not. Let's assume it is included. The obvious first choice for me was to use $1/z^2$ but I don't think this works since the positive real axis is not part of the image. The map $\frac{1+iz}{1-iz}$ works for the entire upper half plane, so I'm not sure if I can use this to my advantage. Can anyone suggest a method to find such a map?","I want to find a conformal map from $W=\{Im(z) > 0, |z|>1\}$ (which is the upper half plane excluding the unit circle), to the unit circle itself. The problem was unclear as to whether we need to include the boundary of the circle or not. Let's assume it is included. The obvious first choice for me was to use $1/z^2$ but I don't think this works since the positive real axis is not part of the image. The map $\frac{1+iz}{1-iz}$ works for the entire upper half plane, so I'm not sure if I can use this to my advantage. Can anyone suggest a method to find such a map?",,"['complex-analysis', 'conformal-geometry']"
91,Where is $\log(z+z^{-1} -2)$ analytic?,Where is  analytic?,\log(z+z^{-1} -2),"I need some help in determining where $\log(z+z^{-1} -2)$ is analytic, where $z$ is a complex number and $\log(z)=\ln|z|+\arg(z+2k\pi),k\in\mathbb{Z}$ . Thank you in advance.","I need some help in determining where is analytic, where is a complex number and . Thank you in advance.","\log(z+z^{-1} -2) z \log(z)=\ln|z|+\arg(z+2k\pi),k\in\mathbb{Z}","['complex-analysis', 'analysis', 'analyticity']"
92,Find the number of zeroes of the polynomial $h(z)=z^{5} + 5z^{3} + 2z^{2} + 4z + 1$ in the right half-plane.,Find the number of zeroes of the polynomial  in the right half-plane.,h(z)=z^{5} + 5z^{3} + 2z^{2} + 4z + 1,"Question: Find the number of zeroes of the polynomial $h(z)=z^{5}+5z^{3}+2z^{2}+4z+1$ in the right half-plane. Comments: There may be a number of ways to arrive at a solution to this problem, but it would be instructive for me to know if anyone can solve it using Rouché's theorem (or the principle of the argument if that proves impossible). My idea is to count the zeros on an area bounded by the imaginary axis and a half-circle $C$ on the right half-plane with center in $z=0$ and of radius $R$ where $R$ is a large enough number to contain all the zeros in the right-half plane. To do so using Rouché, I would need to see if there is a $g(z)$ which has an absolute value larger than $|f(z)-g(z)|$ on the boundary (that is, on the imaginary axis and on $C$). I am unsure however which $g(z)$ to choose. This is a problem from an old complex analysis exam, it is similar to this problem which I posted earlier. All input appreciated.","Question: Find the number of zeroes of the polynomial $h(z)=z^{5}+5z^{3}+2z^{2}+4z+1$ in the right half-plane. Comments: There may be a number of ways to arrive at a solution to this problem, but it would be instructive for me to know if anyone can solve it using Rouché's theorem (or the principle of the argument if that proves impossible). My idea is to count the zeros on an area bounded by the imaginary axis and a half-circle $C$ on the right half-plane with center in $z=0$ and of radius $R$ where $R$ is a large enough number to contain all the zeros in the right-half plane. To do so using Rouché, I would need to see if there is a $g(z)$ which has an absolute value larger than $|f(z)-g(z)|$ on the boundary (that is, on the imaginary axis and on $C$). I am unsure however which $g(z)$ to choose. This is a problem from an old complex analysis exam, it is similar to this problem which I posted earlier. All input appreciated.",,['complex-analysis']
93,"""completing the cube""","""completing the cube""",,"Given a quadratic polynomial $p(z) = z^2 +a z +b$ in $\mathbb{C}[x]$, we can ""complete the square"" to write $p(z) = g(f(z)^2)$ where $f,g$ are translations. \begin{align*} f(z) = z + a/2 && g(z) = z+ b - a^2/4 \end{align*} In particular, $f,g$ are entire diffeomorphisms homeomorphisms of $\mathbb{C}$. Question: Given a monic degree 3 polynomial $p(z)$ with complex coefficients, is it always possible to find entire diffeomorphisms homeomorphisms $f,g$ of $\mathbb{C}$ such that $p(z) = g( f(z)^3)$? It the answer is yes, how explicit can the maps $f,g$ be? Does this work for higher degree polynomials?","Given a quadratic polynomial $p(z) = z^2 +a z +b$ in $\mathbb{C}[x]$, we can ""complete the square"" to write $p(z) = g(f(z)^2)$ where $f,g$ are translations. \begin{align*} f(z) = z + a/2 && g(z) = z+ b - a^2/4 \end{align*} In particular, $f,g$ are entire diffeomorphisms homeomorphisms of $\mathbb{C}$. Question: Given a monic degree 3 polynomial $p(z)$ with complex coefficients, is it always possible to find entire diffeomorphisms homeomorphisms $f,g$ of $\mathbb{C}$ such that $p(z) = g( f(z)^3)$? It the answer is yes, how explicit can the maps $f,g$ be? Does this work for higher degree polynomials?",,"['complex-analysis', 'polynomials']"
94,Where are the zeros of $\prod\limits_p (1-(p-1)^z)$?,Where are the zeros of ?,\prod\limits_p (1-(p-1)^z),Define $f(z)$ as the analytic continuation of $\prod\limits_p (1-(p-1)^z)$ where $z$ is complex and the product is over the odd primes $p$. Where are the zeros ($f(z)=0$) of this function ?,Define $f(z)$ as the analytic continuation of $\prod\limits_p (1-(p-1)^z)$ where $z$ is complex and the product is over the odd primes $p$. Where are the zeros ($f(z)=0$) of this function ?,,"['complex-analysis', 'prime-numbers', 'zeta-functions', 'infinite-product']"
95,Holomorphic function zeros on the circle,Holomorphic function zeros on the circle,,"I'm learning to use some methods of complex analysis, solving some problems. Could you give me a hint to solve the following problem? $f$ is holomorphic in $D^2=\{z: |z|<1\}$ and continious in $\partial D^2\cup D^2$. Also, there is an open subset $U$ of $\partial D^2$ such as $f|_U=0.$ I am to prove $f|_U=0$. Unfortunately, I have a lack of techniques, but I think somethin like maximum modulus principle would be useful. Perhaps there is some general result?","I'm learning to use some methods of complex analysis, solving some problems. Could you give me a hint to solve the following problem? $f$ is holomorphic in $D^2=\{z: |z|<1\}$ and continious in $\partial D^2\cup D^2$. Also, there is an open subset $U$ of $\partial D^2$ such as $f|_U=0.$ I am to prove $f|_U=0$. Unfortunately, I have a lack of techniques, but I think somethin like maximum modulus principle would be useful. Perhaps there is some general result?",,[]
96,"Quaternion exponential map, rotations and interpolation","Quaternion exponential map, rotations and interpolation",,"A code snippet I need to optimize is performing something peculiar. It seems that it's somehow related to transforming from a frame of reference to another. This is what it does, in mathematical terms: $ \mathfrak{q}_{prevToCurrExpMap} = \exp ( \mathfrak{q}_{PrevToCurr} ) $ then $ \mathfrak{q}_{prevToCurrExpMap} = \mathfrak{q}_{prevToCurrExpMap} + \mathfrak{q}_{rotationInduction}$ and finally $ \mathfrak{q}_{prevToCurr} = \ln (\mathfrak{q}_{prevToCurrExpMap} ) $ Essentially, the orientation quaternion's exponential map is altered by a quaternion addition, and then the result is extracted by taking the logarithm. I am trying to understand the logic behind this piece of ""code"", but nothing comes to mind. Is there any obvious reason for replacing a quat $\mathfrak{q}$ with $\ln(\exp(\mathfrak{q}) + \mathfrak{p})$? (at a first glance, it does not seem to encode any kind of interpolation, but it might be trickier than it appears.)","A code snippet I need to optimize is performing something peculiar. It seems that it's somehow related to transforming from a frame of reference to another. This is what it does, in mathematical terms: $ \mathfrak{q}_{prevToCurrExpMap} = \exp ( \mathfrak{q}_{PrevToCurr} ) $ then $ \mathfrak{q}_{prevToCurrExpMap} = \mathfrak{q}_{prevToCurrExpMap} + \mathfrak{q}_{rotationInduction}$ and finally $ \mathfrak{q}_{prevToCurr} = \ln (\mathfrak{q}_{prevToCurrExpMap} ) $ Essentially, the orientation quaternion's exponential map is altered by a quaternion addition, and then the result is extracted by taking the logarithm. I am trying to understand the logic behind this piece of ""code"", but nothing comes to mind. Is there any obvious reason for replacing a quat $\mathfrak{q}$ with $\ln(\exp(\mathfrak{q}) + \mathfrak{p})$? (at a first glance, it does not seem to encode any kind of interpolation, but it might be trickier than it appears.)",,"['geometry', 'complex-analysis', 'algebra-precalculus', 'rotations', 'quaternions']"
97,Rational trigonometric integral,Rational trigonometric integral,,"I am asked to show that $\int \limits_{0}^{2\pi} \frac{\sin(x)^2}{5+4\cos(x)} dx=\frac{\pi}{4}$. I substitute in $\sin(x)=\frac{1}{2i}(z-\frac{1}{z})$, $\cos(x)=\frac{1}{2}(z+\frac{1}{z})$ and $dx=\frac{1}{z i}dz$ to get: $\int_{|z|=1} \frac{i (z^2-1)^2}{4z^2(z+2)(2z+1)} dz$. Now, the pole inside the unit circle are $z=0$ (double pole), $z=-\frac{1}{2}$. I get residues $-\frac{5i}{16}$ and $\frac{3}{8i}$, respectively. So the integral should be $2 \pi i (-\frac{5}{16i}+\frac{3}{8i})=\frac{\pi}{8}$. Where am i wrong? Calculating the residues? Thanks [I know a similar question has been already asked. However, I would like a pious man to check my calculation of the residues. I don't know where everything went tits up.]","I am asked to show that $\int \limits_{0}^{2\pi} \frac{\sin(x)^2}{5+4\cos(x)} dx=\frac{\pi}{4}$. I substitute in $\sin(x)=\frac{1}{2i}(z-\frac{1}{z})$, $\cos(x)=\frac{1}{2}(z+\frac{1}{z})$ and $dx=\frac{1}{z i}dz$ to get: $\int_{|z|=1} \frac{i (z^2-1)^2}{4z^2(z+2)(2z+1)} dz$. Now, the pole inside the unit circle are $z=0$ (double pole), $z=-\frac{1}{2}$. I get residues $-\frac{5i}{16}$ and $\frac{3}{8i}$, respectively. So the integral should be $2 \pi i (-\frac{5}{16i}+\frac{3}{8i})=\frac{\pi}{8}$. Where am i wrong? Calculating the residues? Thanks [I know a similar question has been already asked. However, I would like a pious man to check my calculation of the residues. I don't know where everything went tits up.]",,[]
98,What is the difference between integrals and contour integrals?,What is the difference between integrals and contour integrals?,,I understand integrals but what are contour integrals?,I understand integrals but what are contour integrals?,,"['complex-analysis', 'contour-integration']"
99,Show that $\exp(\sin z)$ has an antiderivative on $\mathbb{C}$,Show that  has an antiderivative on,\exp(\sin z) \mathbb{C},How can we show that $\exp(\sin z)$ has an antiderivative on $\mathbb{C}$?,How can we show that $\exp(\sin z)$ has an antiderivative on $\mathbb{C}$?,,['complex-analysis']
