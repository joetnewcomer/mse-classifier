,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Coupon Collector ""Paradox""","Coupon Collector ""Paradox""",,"Example Scenario: Imagine a Player has an unfair die with sides: $\{A,B,C,D,E,F\}$ The probability of each side $p_i = \{1/12,1/6,1/4,1/12,1/6,1/4\}$ The player's goal is to obtain at least one of each $S = \{A,B,C\}$ Questions: The Player wishes to answer 3 questions about the game. What is the Expected Number of die rolls until obtaining the 1st successful roll? What is the Expected Number of desired sides seen at least once in $n$ rolls? What is the Expected Number of die rolls to complete the collection? My Solutions to the Questions: Using a Geometric Distribution approach we have that the expected waiting time until the 1st success is $$E[x] = 1/p$$ where $$p = \sum_{i\in S} p_i$$ therefor $$p = 1/12 + 1/6 + 1/4 = 1/2$$ and $$E[x] = 1/(1/2) = 2$$ I believe this solution can be obtained from the the inclusion-exclusion principle: $$E[x] = \sum_{i\in S} 1-(1-p_i)^n$$ thus for $$n = 2$$ $$E[x] = 1-(1-1/12)^2 + 1-(1-1/6)^2 + 1-(1-1/4)^2 \approx 0.902777778$$ This answer comes from Ross; Introduction to Probability Models as the solution to the Unequal Coupon Collector Problem: $$\int_0^\infty1-(1-e^\frac{-x}{12})(1-e^\frac{-x}{6})(1-e^\frac{-x}{4})dx = 14.6$$ My ""Paradox"": I am not 100% confident in the solution to question 2. I do not know how to prove that formula is correct, but feels correct to me. However, the confusing thing to me is that under the $n = 2$ scenario why does the result not equal 1.0? It feels to me like the result for that question should either equal 1.0 to match the solution to question 1 since they feel like the same question just from two different view points. Or if the result was slightly higher than 1.0 I could also reason to my self that the excess is attributable to the scenarios where you obtain 2 successes in 2 rolls. But with the solution of $\approx 0.9$ I do not have an intuitive understanding of why that is true. So I am asking if my solution to question 2 is correct. And if it is, is there an intuitive explanation for why the solution to question 2 for when n = solution from question 1 the result is not 1.0?","Example Scenario: Imagine a Player has an unfair die with sides: The probability of each side The player's goal is to obtain at least one of each Questions: The Player wishes to answer 3 questions about the game. What is the Expected Number of die rolls until obtaining the 1st successful roll? What is the Expected Number of desired sides seen at least once in rolls? What is the Expected Number of die rolls to complete the collection? My Solutions to the Questions: Using a Geometric Distribution approach we have that the expected waiting time until the 1st success is where therefor and I believe this solution can be obtained from the the inclusion-exclusion principle: thus for This answer comes from Ross; Introduction to Probability Models as the solution to the Unequal Coupon Collector Problem: My ""Paradox"": I am not 100% confident in the solution to question 2. I do not know how to prove that formula is correct, but feels correct to me. However, the confusing thing to me is that under the scenario why does the result not equal 1.0? It feels to me like the result for that question should either equal 1.0 to match the solution to question 1 since they feel like the same question just from two different view points. Or if the result was slightly higher than 1.0 I could also reason to my self that the excess is attributable to the scenarios where you obtain 2 successes in 2 rolls. But with the solution of I do not have an intuitive understanding of why that is true. So I am asking if my solution to question 2 is correct. And if it is, is there an intuitive explanation for why the solution to question 2 for when n = solution from question 1 the result is not 1.0?","\{A,B,C,D,E,F\} p_i = \{1/12,1/6,1/4,1/12,1/6,1/4\} S = \{A,B,C\} n E[x] = 1/p p = \sum_{i\in S} p_i p = 1/12 + 1/6 + 1/4 = 1/2 E[x] = 1/(1/2) = 2 E[x] = \sum_{i\in S} 1-(1-p_i)^n n = 2 E[x] = 1-(1-1/12)^2 + 1-(1-1/6)^2 + 1-(1-1/4)^2 \approx 0.902777778 \int_0^\infty1-(1-e^\frac{-x}{12})(1-e^\frac{-x}{6})(1-e^\frac{-x}{4})dx = 14.6 n = 2 \approx 0.9","['statistics', 'expected-value', 'paradoxes', 'coupon-collector']"
1,"Given, $X_n \to \xi \sim N(0, A)$, Show $X_n = o_P(1)$ iff $A = 0$","Given, , Show  iff","X_n \to \xi \sim N(0, A) X_n = o_P(1) A = 0","The title is a general statement, and I am trying to apply it in the following problem. Suppose $$ X_n\stackrel{\mathcal{D}}{\rightarrow} N\left(0, E\left\{\left(\varphi-\varphi^*\right)\left(\varphi-\varphi^*\right)^T\right\}\right) $$ In the textbook Semiparametric theory by Tsiatis Chapter 3, the author mentioned in order for this limiting normal distribution to be $o_p(1)$ , we would require that the covariance matrix $$E\left\{\left(\varphi-\varphi^*\right)\left(\varphi-\varphi^*\right)^T\right\}=0^{q \times q}$$ . Intuitively it makes sense,  but I don't know how the formal proof goes. Is it just simply because - if we want derive converges to 0 in probability, we need the variance to be zero?","The title is a general statement, and I am trying to apply it in the following problem. Suppose In the textbook Semiparametric theory by Tsiatis Chapter 3, the author mentioned in order for this limiting normal distribution to be , we would require that the covariance matrix . Intuitively it makes sense,  but I don't know how the formal proof goes. Is it just simply because - if we want derive converges to 0 in probability, we need the variance to be zero?","
X_n\stackrel{\mathcal{D}}{\rightarrow} N\left(0, E\left\{\left(\varphi-\varphi^*\right)\left(\varphi-\varphi^*\right)^T\right\}\right)
 o_p(1) E\left\{\left(\varphi-\varphi^*\right)\left(\varphi-\varphi^*\right)^T\right\}=0^{q \times q}","['probability', 'statistics', 'expected-value', 'random']"
2,Convex Independence,Convex Independence,,"I have a difficulty in understanding a given definition for convex independence: A set of beliefs $\beta$ of an agent $i$ satisfy convex independence if beliefs of no type $t_i$ can be represented as a convex combination of other types $t'_i \neq t_i$ I read the Wikipedia article about convex combinations and I think I get what it means. Thus, also the definition of convex independence should be clear but I can't make sense of the given example: example of convex independence why does convex independence fail for the bottom example? I can't see how I can create a convex combination (of the red row?) to match another row (belief) what is the fastest way to check for convex independence in such a case? Checking each row vs. the other ones would take quite some time Notation: $\beta_i(.) = \pi_j(.)$ : belief of player i (expressed as a probability) about player $j$ being of a certain type given his own type $\theta_1^i$ : type â€ž $\theta_1$ â€œ of player $i$","I have a difficulty in understanding a given definition for convex independence: A set of beliefs of an agent satisfy convex independence if beliefs of no type can be represented as a convex combination of other types I read the Wikipedia article about convex combinations and I think I get what it means. Thus, also the definition of convex independence should be clear but I can't make sense of the given example: example of convex independence why does convex independence fail for the bottom example? I can't see how I can create a convex combination (of the red row?) to match another row (belief) what is the fastest way to check for convex independence in such a case? Checking each row vs. the other ones would take quite some time Notation: : belief of player i (expressed as a probability) about player being of a certain type given his own type : type â€ž â€œ of player",\beta i t_i t'_i \neq t_i \beta_i(.) = \pi_j(.) j \theta_1^i \theta_1 i,"['probability', 'probability-theory', 'statistics', 'independence', 'economics']"
3,Using Chebyshev Inequality to find lower bound of an interval,Using Chebyshev Inequality to find lower bound of an interval,,"Given a random variable $X$ with $\mu = 200$ and $\sigma = 10$ . Find a lower bound for $P(130 \leq X \leq 270)$ using Chebyshev Inequality. What I've tried was: The inequality is $P(|X - E[X]| \geq k\sigma) \leq \frac{1}{k^2}$ , so for $P(130 \leq X \leq 270)$ we have $P(|X-200| \geq 700) \leq \frac{1}{70^2} = P(|X-220| \leq 700) \geq 1 - \frac{1}{70^2} = P(|X-200| \leq 700) \geq 0.9997$ But in the solutions the answer is $\frac{48}{49} = 0.98$ What am I doing wrong?","Given a random variable with and . Find a lower bound for using Chebyshev Inequality. What I've tried was: The inequality is , so for we have But in the solutions the answer is What am I doing wrong?",X \mu = 200 \sigma = 10 P(130 \leq X \leq 270) P(|X - E[X]| \geq k\sigma) \leq \frac{1}{k^2} P(130 \leq X \leq 270) P(|X-200| \geq 700) \leq \frac{1}{70^2} = P(|X-220| \leq 700) \geq 1 - \frac{1}{70^2} = P(|X-200| \leq 700) \geq 0.9997 \frac{48}{49} = 0.98,"['probability', 'statistics']"
4,How far are the Mode and the Median of the Log-Normal distribution from behaving as Linear functions?,How far are the Mode and the Median of the Log-Normal distribution from behaving as Linear functions?,,"How far are the Mode and the Median of the Log-Normal distribution from behaving as Linear functions? Intro_______________ Recently I made a question where later I figure out I was requiring that the Mode $\nu[x]$ of a distribution were behaving as it was a linear function $\nu\left[\sum_i^N a_iX_i\right]=\sum_i^N a_i\nu[X_i]$ , which I know is not true in general. But also, if the random variables $X_i$ belong to the same symmetrical distribution , then I will have that $\nu = \mu = m$ with "" $\mu[x]$ "" the mean value and ""m[x]"" the Median of the distribution ( $m$ is the value such it split the probabilities as $P(X\geq m) = P(X\leq m) = \frac12$ ). Since the mean value is a linear operator $\mu\left[\sum_i^N a_iX_i\right]=\sum_i^N a_i\mu[X_i]$ , under this ""symmetric"" scenario I think it should be true also that $\nu\left[\sum_i^N a_iX_i\right]=\sum_i^N a_i\nu[X_i]$ and $m\left[\sum_i^N a_iX_i\right]=\sum_i^N a_im[X_i]$ (this because $\mu$ , $\nu$ , and $m$ are homogeneous of degree $1$ ), so at least there are some conditions where they could be split as a weighted sum. Question__________________ If the variables $X_i$ belongs each to some non-necessarily identical Log-Normal distributions with some parameters $X_i \sim \text{Lognormal}(\mu_i,\ \sigma_i)$ (so each of them have their individual parameters $\nu[X_i]=\nu_i$ and $m[X_i]=m_i$ ), and for some real-valued weights $0\leq a_i\leq 1$ such as $\sum\limits_{i=1}^N a_i = 1$ , I want to know How far are from behaving as a linear function each of: $$\nu\left[\sum_{i=1}^N a_i X_i\right] \overset{?}{\approx}\sum_{i=1}^N a_i\ \nu\left[X_i\right]=\sum_{i=1}^N a_i\ \nu_i$$ $$m\left[\sum_{i=1}^N a_i X_i\right] \overset{?}{\approx}\sum_{i=1}^N a_i\ m\left[X_i\right]=\sum_{i=1}^N a_i\ m_i$$ Could we say something about the Left-Hand Sides (LHS) being always bigger/lower than the Right-Hand Sides (RHS)? Are there any inequalities setting bounds of how much spread could have the LHS from the RHS? Are there any ways of split somehow the LHS expressions? Like having a known formula? Since the Log-Normal distribution is already positively skewed (so non-symmetric): Are there any conditions under the RHS could be considered as an approximation of the LHS? PS: If you are currently a undergraduate student, I will really appreciate if you could share this question with your probability/statistic teachers. Added later After the answer by @Amir I realized that without without assuming anything regarding independence, correlations, or unimodality, one could do the following: $$\begin{array}{r c l} |\sum a_i m[x_i]-m\left[\sum a_i x_i\right]| & = & |\sum a_i m[x_i]+E\left[\sum a_i x_i\right]-E\left[\sum a_i x_i\right]-m\left[\sum a_i x_i\right]| \\ & \overset{\text{triangle ineq.}}{\leq} & |E\left[\sum a_i x_i\right]-m\left[\sum a_i x_i\right]|+|\sum a_i m[x_i]-E\left[\sum a_i x_i\right]| \\ & \overset{|\mu - m|\leq \sigma}{\leq} & \sqrt{\text{Var}\left[\sum a_i x_i\right]}+\left|\sum a_i\left(m[x_i]-E[x_i]\right)\right| \end{array}$$ due the linearity of the expected value. All the values from the RHS could be taken from the individual variable distributions. From this last result could be inferred conditions for having both terms near one from each other, and also tells that the mistaken formula from this another question could be useful at last as a selection figure since it will be penalizing strongly those variables which makes both $\sum a_i m[x_i]$ and $m\left[\sum a_i x_i\right]$ drift apart (note it was done from the mode, but identical construction could be made for the median). Do you think this formula could be improved for LogNormal distributed variables without assuming independence? I already know it could be improved if assuming unimodality, but would be also better to not taking it as assumption.","How far are the Mode and the Median of the Log-Normal distribution from behaving as Linear functions? Intro_______________ Recently I made a question where later I figure out I was requiring that the Mode of a distribution were behaving as it was a linear function , which I know is not true in general. But also, if the random variables belong to the same symmetrical distribution , then I will have that with "" "" the mean value and ""m[x]"" the Median of the distribution ( is the value such it split the probabilities as ). Since the mean value is a linear operator , under this ""symmetric"" scenario I think it should be true also that and (this because , , and are homogeneous of degree ), so at least there are some conditions where they could be split as a weighted sum. Question__________________ If the variables belongs each to some non-necessarily identical Log-Normal distributions with some parameters (so each of them have their individual parameters and ), and for some real-valued weights such as , I want to know How far are from behaving as a linear function each of: Could we say something about the Left-Hand Sides (LHS) being always bigger/lower than the Right-Hand Sides (RHS)? Are there any inequalities setting bounds of how much spread could have the LHS from the RHS? Are there any ways of split somehow the LHS expressions? Like having a known formula? Since the Log-Normal distribution is already positively skewed (so non-symmetric): Are there any conditions under the RHS could be considered as an approximation of the LHS? PS: If you are currently a undergraduate student, I will really appreciate if you could share this question with your probability/statistic teachers. Added later After the answer by @Amir I realized that without without assuming anything regarding independence, correlations, or unimodality, one could do the following: due the linearity of the expected value. All the values from the RHS could be taken from the individual variable distributions. From this last result could be inferred conditions for having both terms near one from each other, and also tells that the mistaken formula from this another question could be useful at last as a selection figure since it will be penalizing strongly those variables which makes both and drift apart (note it was done from the mode, but identical construction could be made for the median). Do you think this formula could be improved for LogNormal distributed variables without assuming independence? I already know it could be improved if assuming unimodality, but would be also better to not taking it as assumption.","\nu[x] \nu\left[\sum_i^N a_iX_i\right]=\sum_i^N a_i\nu[X_i] X_i \nu = \mu = m \mu[x] m P(X\geq m) = P(X\leq m) = \frac12 \mu\left[\sum_i^N a_iX_i\right]=\sum_i^N a_i\mu[X_i] \nu\left[\sum_i^N a_iX_i\right]=\sum_i^N a_i\nu[X_i] m\left[\sum_i^N a_iX_i\right]=\sum_i^N a_im[X_i] \mu \nu m 1 X_i X_i \sim \text{Lognormal}(\mu_i,\ \sigma_i) \nu[X_i]=\nu_i m[X_i]=m_i 0\leq a_i\leq 1 \sum\limits_{i=1}^N a_i = 1 \nu\left[\sum_{i=1}^N a_i X_i\right] \overset{?}{\approx}\sum_{i=1}^N a_i\ \nu\left[X_i\right]=\sum_{i=1}^N a_i\ \nu_i m\left[\sum_{i=1}^N a_i X_i\right] \overset{?}{\approx}\sum_{i=1}^N a_i\ m\left[X_i\right]=\sum_{i=1}^N a_i\ m_i \begin{array}{r c l}
|\sum a_i m[x_i]-m\left[\sum a_i x_i\right]| & = & |\sum a_i m[x_i]+E\left[\sum a_i x_i\right]-E\left[\sum a_i x_i\right]-m\left[\sum a_i x_i\right]| \\
& \overset{\text{triangle ineq.}}{\leq} & |E\left[\sum a_i x_i\right]-m\left[\sum a_i x_i\right]|+|\sum a_i m[x_i]-E\left[\sum a_i x_i\right]| \\
& \overset{|\mu - m|\leq \sigma}{\leq} & \sqrt{\text{Var}\left[\sum a_i x_i\right]}+\left|\sum a_i\left(m[x_i]-E[x_i]\right)\right|
\end{array} \sum a_i m[x_i] m\left[\sum a_i x_i\right]","['probability', 'probability-theory', 'measure-theory', 'statistics', 'stochastic-processes']"
5,Two sample test - distribution of pooled variance estimator,Two sample test - distribution of pooled variance estimator,,"I am attending a statistics course this semester and although it is offered by the math department the precise assumptions underlying the main theorems are not provided, let alone the proofs. That being said, I would like to get a reference or at least discuss the proof of the following fact: Suppose that we are given two normal iid samples $(X_{11},\ldots,X_{1n_1})$ and $(X_{21},\ldots,X_{2n_2})$ with standard derivations $\sigma_i$ and means $\mu_i$ and set $$S^2_i:=S^2_{X_i}:=S_{X_iX_i}:=\sum_{j=1}^{n_i}(X_{ij}-\bar{X}_i)^2$$ as well as $$S^2:=S_1^2+S_2^2$$ and finally $\nu:=n_1+n_2-2$ . Then it is claimed that $$T:=\frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)}{\sqrt{\frac{S^2/\nu}{n_1}+\frac{S^2/\nu}{n_2}}}\sim t_\nu$$ Note that if $\bar{X}_1\perp\bar{X}_2$ then $^1$ $$Z:=\frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma^2}{n_1}+\frac{\sigma^2}{n_2}}}\sim N(0,1)$$ and it can easily be shown that $$T=\frac{Z}{\sqrt{W/\nu}}$$ with $W=S^2/\sigma^2$ , so perhaps we can show that $W_1:=S_1^2/\sigma^2$ and $W_2:=S_2^2/\sigma^2$ are independent, i.e. $W_1\perp W_2$ and $W\perp Z$ as this would yield the desired result. $^{2}$ Is this indeed the usual strategy? Where can I look this up? $^1$ If $(X_1,\ldots,X_n)$ is iid with $X_i\sim N(\mu,\sigma^2)$ , then $\bar X\sim N(\mu,\sigma^2/n)$ and hence $$\bar X_1-\bar X_2\sim N(\mu_1-\mu^2,\sigma_1^2/n_1+\sigma_2^2/n_2)$$ (just look up ""linear combination of independent normal variables""). $^2$ It is well known that $W_i\in\chi^2(n_i)$ and hence $W_1+W_2\in\chi^2(n_1+n_2)$ if $W_1\perp W_2$ . Furthermore $Z/\sqrt{W/n}\in t_n$ if $Z\in N(0,1)$ , $W\in\chi^2(n)$ and $W\perp Z$ .","I am attending a statistics course this semester and although it is offered by the math department the precise assumptions underlying the main theorems are not provided, let alone the proofs. That being said, I would like to get a reference or at least discuss the proof of the following fact: Suppose that we are given two normal iid samples and with standard derivations and means and set as well as and finally . Then it is claimed that Note that if then and it can easily be shown that with , so perhaps we can show that and are independent, i.e. and as this would yield the desired result. Is this indeed the usual strategy? Where can I look this up? If is iid with , then and hence (just look up ""linear combination of independent normal variables""). It is well known that and hence if . Furthermore if , and .","(X_{11},\ldots,X_{1n_1}) (X_{21},\ldots,X_{2n_2}) \sigma_i \mu_i S^2_i:=S^2_{X_i}:=S_{X_iX_i}:=\sum_{j=1}^{n_i}(X_{ij}-\bar{X}_i)^2 S^2:=S_1^2+S_2^2 \nu:=n_1+n_2-2 T:=\frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)}{\sqrt{\frac{S^2/\nu}{n_1}+\frac{S^2/\nu}{n_2}}}\sim t_\nu \bar{X}_1\perp\bar{X}_2 ^1 Z:=\frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma^2}{n_1}+\frac{\sigma^2}{n_2}}}\sim N(0,1) T=\frac{Z}{\sqrt{W/\nu}} W=S^2/\sigma^2 W_1:=S_1^2/\sigma^2 W_2:=S_2^2/\sigma^2 W_1\perp W_2 W\perp Z ^{2} ^1 (X_1,\ldots,X_n) X_i\sim N(\mu,\sigma^2) \bar X\sim N(\mu,\sigma^2/n) \bar X_1-\bar X_2\sim N(\mu_1-\mu^2,\sigma_1^2/n_1+\sigma_2^2/n_2) ^2 W_i\in\chi^2(n_i) W_1+W_2\in\chi^2(n_1+n_2) W_1\perp W_2 Z/\sqrt{W/n}\in t_n Z\in N(0,1) W\in\chi^2(n) W\perp Z","['probability-theory', 'statistics', 'probability-distributions', 'confidence-interval']"
6,Trouble understanding order statistics,Trouble understanding order statistics,,"Order statistics were introduced in my text as follows: I am trying to understand what this means. $X_1 , \dots , X_n$ is a random sample, i.e. an independent and identically distributed sequence of random variables. $Y_1$ is the ""smallest"" of these $X_i$ . Do I interpret this as $Y_1 = \min \{ X_1 , \dots , X_n \}$ ? Then $Y_2$ is the second smallest of the $X_i$ when realized, $Y_3$ the third smallest, and so on until $Y_n = \max \{ X_1 , \dots , X_n \}$ ? An example to illustrate my thinking: Suppose we perform an experiment and the random variables $X_i$ are realized as $x_i = i$ (so $x_1 = 1, x_2 = 2$ etc..). Then the random variables $Y_i$ are realized as $y_i = i$ as well because the $x_i$ are already in order. If we perform another experiment and the $X_i$ are realized as $x_i = -i$ (so $x_1 = -1, x_2 = -2$ etc..), then this time the variables $Y_i$ were realized as $y_i = -n + i - 1$ (so $y_1 = -n, y_2 = -n + 1, \dots , y_n = -1$ ). Is this the correction interpretation? My confusion/hesitation comes from the fact that these $X_i, Y_i$ are random variables and therefore functions instead of values and it's not really clear from the text what is meant by ordering them.","Order statistics were introduced in my text as follows: I am trying to understand what this means. is a random sample, i.e. an independent and identically distributed sequence of random variables. is the ""smallest"" of these . Do I interpret this as ? Then is the second smallest of the when realized, the third smallest, and so on until ? An example to illustrate my thinking: Suppose we perform an experiment and the random variables are realized as (so etc..). Then the random variables are realized as as well because the are already in order. If we perform another experiment and the are realized as (so etc..), then this time the variables were realized as (so ). Is this the correction interpretation? My confusion/hesitation comes from the fact that these are random variables and therefore functions instead of values and it's not really clear from the text what is meant by ordering them.","X_1 , \dots , X_n Y_1 X_i Y_1 = \min \{ X_1 , \dots , X_n \} Y_2 X_i Y_3 Y_n = \max \{ X_1 , \dots , X_n \} X_i x_i = i x_1 = 1, x_2 = 2 Y_i y_i = i x_i X_i x_i = -i x_1 = -1, x_2 = -2 Y_i y_i = -n + i - 1 y_1 = -n, y_2 = -n + 1, \dots , y_n = -1 X_i, Y_i","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'order-statistics']"
7,Problem of drawing poker,Problem of drawing poker,,"Randomly shuffle a deck of poker cards (52) and continually draw the card without replacement. On average how many cards you need to draw in order to get a card which has a same value as the cards you've drawn? That is to say, if the card you've drawn is 1->2->3->4, then you would stop at the next step if you draw one of the 1,2,3 or 4. This is a problem I came upwith when I was playing desk card games... I thought ""on average"" it could be seen as $E(\sum_{i=1}^{52}I_i)$ of which $I_i$ means the i-th card has already been seen (0) or not (1). Then $E(\sum_{i=1}^{52}I_i) = \sum_{i=1}^{52}P_i$ of which $P_i$ is the prob that the i-th card is a new card (not seen before). But apparently the $P_i$ depends on $i$ ....so what can I do next? =============== The original post is ""stop when you draw a card with a same face value as the first card"". I think that's just splitting the remaining deck (52-1=51 cards) by 3 cards, i.e. we have (51-3)/4 cards per subdeck. Then the answer could be (51-3)/4 + 1 + 1. But not so sure... The background comes from a Chinese desk card game. The game aims to kill other characters (lower down the life points). One special hero has a special skill, i.e. when he is almost dying (life point goes from 1 to 0 due to the attack) he could draw a card from the deck and collect it, if the card has a same face value compared to the cards he collected by this method (i.e. draw a card when life point goes from 1 to 0) then he dies. I am just wondering on average how many cards he could collect (or how many times you need to ""attack"" him).","Randomly shuffle a deck of poker cards (52) and continually draw the card without replacement. On average how many cards you need to draw in order to get a card which has a same value as the cards you've drawn? That is to say, if the card you've drawn is 1->2->3->4, then you would stop at the next step if you draw one of the 1,2,3 or 4. This is a problem I came upwith when I was playing desk card games... I thought ""on average"" it could be seen as of which means the i-th card has already been seen (0) or not (1). Then of which is the prob that the i-th card is a new card (not seen before). But apparently the depends on ....so what can I do next? =============== The original post is ""stop when you draw a card with a same face value as the first card"". I think that's just splitting the remaining deck (52-1=51 cards) by 3 cards, i.e. we have (51-3)/4 cards per subdeck. Then the answer could be (51-3)/4 + 1 + 1. But not so sure... The background comes from a Chinese desk card game. The game aims to kill other characters (lower down the life points). One special hero has a special skill, i.e. when he is almost dying (life point goes from 1 to 0 due to the attack) he could draw a card from the deck and collect it, if the card has a same face value compared to the cards he collected by this method (i.e. draw a card when life point goes from 1 to 0) then he dies. I am just wondering on average how many cards he could collect (or how many times you need to ""attack"" him).",E(\sum_{i=1}^{52}I_i) I_i E(\sum_{i=1}^{52}I_i) = \sum_{i=1}^{52}P_i P_i P_i i,"['probability', 'statistics', 'card-games']"
8,Deducing an incorrect statement when the mean and median are given,Deducing an incorrect statement when the mean and median are given,,"$~a,~b,~c,~d$ are positive integers such that $a~<~b~<~c~<~d$ If mean and median of $~a, ~b, ~c,~d$ are $35$ and $39$ respectively, then which one of the following statements cannot be true? a = 21 a+c =71 a+c=60 d = 61 I after some attempts made it up to $b+c = 78$ and $a+d = 62$ but can't proceed further. Moreover, please suggest a good title for this post.","are positive integers such that If mean and median of are and respectively, then which one of the following statements cannot be true? a = 21 a+c =71 a+c=60 d = 61 I after some attempts made it up to and but can't proceed further. Moreover, please suggest a good title for this post.","~a,~b,~c,~d a~<~b~<~c~<~d ~a, ~b, ~c,~d 35 39 b+c = 78 a+d = 62","['algebra-precalculus', 'statistics', 'means', 'median']"
9,Showing Sum of Normal Random Variables More than Additive,Showing Sum of Normal Random Variables More than Additive,,"Hopefully this is a quick question. I am not a statistician, so I would like to just make sure that I am approaching this problem correctly. I have some data that I am working with which is meant to monitor cell death and I am trying to compare the effects of different treatments on the cells. Since the research is proprietary, I cannot give the full details here, but I will give an example. I am monitoring cell death in response to stimuli. My control group contains 39 samples and is normally distributed with a mean death percentage of 0.05 and a variance $\sigma^2$ of 0.001. My first sample of size 37 is given treatment X has an approximately normal distribution with a mean death percentage of 0.1 and a variance $\sigma^2$ of 0.04. Likewise, the 43 cells given treatment Y have a death percentage of 0.18 and variance of 0.09. Lastly, the sample containing treatments X and Y with size 34 has a mean death percentage of 0.54 with a variance of 0.16. My question is then how do I show that the effect of treatments X and Y together is more than what would be expected from adding the random variables? Since I do not know that the variables are guaranteed to be independent (in fact, their effects seem to be very much not independent), my idea was to use the formulas $$E[X + Y] = E[X] + E[Y]$$ and $$Var[X + Y] = Var[X] + Var[Y] + 2Cov[X,Y]$$ to obtain the normal distribution for the sum of the random variables where I believe that the covariance of samples would be computed via $$Cov[X,Y] = \frac{\left(\sum\limits_{i = 1}^{N_x}(x_i - \mu_x)\right) \left(\sum\limits_{j=1}^{N_y}(y_j - \mu_y)\right)}{(N_x - 1)(N_y - 1)}$$ where the loss of 1 in each of the terms in the denominator comes from the loss of 1 d.o.f. from using each of the means (I am not sure if this is the correct formula as I could not find a reference for two different random variables, but it would make sense to me given the situation). Then, my idea was to construct two 95% confidence intervals -- one for my sample and one for the computed $X + Y$ random variable, and, provided that the confidence intervals did not overlap, I believe that I can reject the assumption that the effect of the two random variables is additive. Is this the correct approach, or have I lost my mind here? Thank you in advance for any help that you can give!","Hopefully this is a quick question. I am not a statistician, so I would like to just make sure that I am approaching this problem correctly. I have some data that I am working with which is meant to monitor cell death and I am trying to compare the effects of different treatments on the cells. Since the research is proprietary, I cannot give the full details here, but I will give an example. I am monitoring cell death in response to stimuli. My control group contains 39 samples and is normally distributed with a mean death percentage of 0.05 and a variance of 0.001. My first sample of size 37 is given treatment X has an approximately normal distribution with a mean death percentage of 0.1 and a variance of 0.04. Likewise, the 43 cells given treatment Y have a death percentage of 0.18 and variance of 0.09. Lastly, the sample containing treatments X and Y with size 34 has a mean death percentage of 0.54 with a variance of 0.16. My question is then how do I show that the effect of treatments X and Y together is more than what would be expected from adding the random variables? Since I do not know that the variables are guaranteed to be independent (in fact, their effects seem to be very much not independent), my idea was to use the formulas and to obtain the normal distribution for the sum of the random variables where I believe that the covariance of samples would be computed via where the loss of 1 in each of the terms in the denominator comes from the loss of 1 d.o.f. from using each of the means (I am not sure if this is the correct formula as I could not find a reference for two different random variables, but it would make sense to me given the situation). Then, my idea was to construct two 95% confidence intervals -- one for my sample and one for the computed random variable, and, provided that the confidence intervals did not overlap, I believe that I can reject the assumption that the effect of the two random variables is additive. Is this the correct approach, or have I lost my mind here? Thank you in advance for any help that you can give!","\sigma^2 \sigma^2 E[X + Y] = E[X] + E[Y] Var[X + Y] = Var[X] + Var[Y] + 2Cov[X,Y] Cov[X,Y] = \frac{\left(\sum\limits_{i = 1}^{N_x}(x_i - \mu_x)\right) \left(\sum\limits_{j=1}^{N_y}(y_j - \mu_y)\right)}{(N_x - 1)(N_y - 1)} X + Y","['statistics', 'probability-distributions', 'normal-distribution']"
10,Prove that $nS_{tt}(\sum_{i=1}^nc_i^2)\geq \sum_{i=1}^nt_i^2$,Prove that,nS_{tt}(\sum_{i=1}^nc_i^2)\geq \sum_{i=1}^nt_i^2,"Let $c_1,\cdots, c_n,t_1,\cdots,t_n\in\mathbb{R}$ such that $\sum_{i=1}^nc_it_i=0$ and $\sum_{i=1}^nc_i=1$ . Suppose that there're $i,j$ such that $t_i\neq t_j$ . Prove that $nS_{tt}(\sum_{i=1}^nc_i^2)\geq \sum_{i=1}^nt_i^2$ with $S_{tt}:=\sum_{i=1}^n(t_i-\overline t)^2$ and $\overline t:=(\sum_{i=1}^nt_i)/n$ . I know that $\sum_{i=1}^nt_i^2=S_{tt}+n(\overline t)^2$ and I tried to use Cauchy-Schwartz to prove that inequality, however I failed. Please help me to prove that inequality EDIT: That inequality is related to the fact that among the unbiased linear estimators of $\alpha$ in simple regression analysis the least square estimator $\hat\alpha$ is the one of minimum variance.So that inequality is expected to attain its minimum when $c_i=\frac{S_{tt}-n\overline t(t_i-\overline t)}{nS_{tt}}$ for all $i=1,\cdots,n$","Let such that and . Suppose that there're such that . Prove that with and . I know that and I tried to use Cauchy-Schwartz to prove that inequality, however I failed. Please help me to prove that inequality EDIT: That inequality is related to the fact that among the unbiased linear estimators of in simple regression analysis the least square estimator is the one of minimum variance.So that inequality is expected to attain its minimum when for all","c_1,\cdots, c_n,t_1,\cdots,t_n\in\mathbb{R} \sum_{i=1}^nc_it_i=0 \sum_{i=1}^nc_i=1 i,j t_i\neq t_j nS_{tt}(\sum_{i=1}^nc_i^2)\geq \sum_{i=1}^nt_i^2 S_{tt}:=\sum_{i=1}^n(t_i-\overline t)^2 \overline t:=(\sum_{i=1}^nt_i)/n \sum_{i=1}^nt_i^2=S_{tt}+n(\overline t)^2 \alpha \hat\alpha c_i=\frac{S_{tt}-n\overline t(t_i-\overline t)}{nS_{tt}} i=1,\cdots,n","['statistics', 'inequality']"
11,Pdf of Y knowing pdf of X,Pdf of Y knowing pdf of X,,"Let $Y=1-X^2, f_X(x)=\frac{3}{8} \cdot(x+1)^2 \cdot \mathbf 1_{(-1,1)}(x).$ I think the pdf of $Y$ should be the derivative of $F_Y(y)= F_X(-\sqrt{1-y} )-F_X(\sqrt{1-y})$ , but it can't be negative. Where is my mistake?","Let I think the pdf of should be the derivative of , but it can't be negative. Where is my mistake?","Y=1-X^2, f_X(x)=\frac{3}{8} \cdot(x+1)^2 \cdot \mathbf 1_{(-1,1)}(x). Y F_Y(y)= F_X(-\sqrt{1-y} )-F_X(\sqrt{1-y})",['probability']
12,where is the error in fake proof that a gaussian has 0 variance,where is the error in fake proof that a gaussian has 0 variance,,"Consider the exponential family $$p_\theta(dy) = h(y)\exp(\langle \theta,T(y)\rangle - \Phi(\theta))\mu(dy)$$ with $\theta \in \mathbb R^d$ and the partition function $\Phi(\theta)<\infty$ for all $\theta \in \mathbb R^d$ . Suppose $\nabla \Phi: (\mathbb R^d,\|\cdot\|_2) \to (\mathbb R^d,\|\cdot\|_2)$ is L-Lipschitz. Fix any $v$ on the $d-1$ dimensional sphere. Then it can be shown $X = \langle v, T(Y)\rangle$ is $2L$ sub-Gaussian. Now, consider the family $$p_\theta(dy) = \exp(-(y-\mu)^2/2)/\sqrt{2\pi}\,dy$$ This is an exponential family with $\theta = [\mu \mid \mu^2]$ and $T(y) = [y\mid -1/2]$ . But then this implies $$X = \langle e_1,T(Y)\rangle = Y$$ is $2L$ sub-Gaussian for every $L>0$ (since $\Phi(\theta) \equiv \log \sqrt{2\pi}$ ) In a similar vein, by taking $\theta = [\mu \mid \mu^2 \mid -1/2]$ and $T(y) = [y \mid -1/2 \mid y^2]$ , one can deduce the problematic statements that $Y^2$ is 1) sub-Gaussian, and 2) has zero variance. Where is the error?","Consider the exponential family with and the partition function for all . Suppose is L-Lipschitz. Fix any on the dimensional sphere. Then it can be shown is sub-Gaussian. Now, consider the family This is an exponential family with and . But then this implies is sub-Gaussian for every (since ) In a similar vein, by taking and , one can deduce the problematic statements that is 1) sub-Gaussian, and 2) has zero variance. Where is the error?","p_\theta(dy) = h(y)\exp(\langle \theta,T(y)\rangle - \Phi(\theta))\mu(dy) \theta \in \mathbb R^d \Phi(\theta)<\infty \theta \in \mathbb R^d \nabla \Phi: (\mathbb R^d,\|\cdot\|_2) \to (\mathbb R^d,\|\cdot\|_2) v d-1 X = \langle v, T(Y)\rangle 2L p_\theta(dy) = \exp(-(y-\mu)^2/2)/\sqrt{2\pi}\,dy \theta = [\mu \mid \mu^2] T(y) = [y\mid -1/2] X = \langle e_1,T(Y)\rangle = Y 2L L>0 \Phi(\theta) \equiv \log \sqrt{2\pi} \theta = [\mu \mid \mu^2 \mid -1/2] T(y) = [y \mid -1/2 \mid y^2] Y^2","['probability', 'statistics', 'fake-proofs']"
13,Why is the expected value of Kolmogorov Smirnov statistic converges to 0?,Why is the expected value of Kolmogorov Smirnov statistic converges to 0?,,"Let $X_1,...,X_n$ be a random sample with distribution function $F$ and let $F_n$ be the corresponding empirical distribution function: $$F_n(x) = \frac{1}{n} \sum_{i=1}^{n}1_{(-\infty,x]}(X_i)$$ My book says that $\lim_{n->\infty}E(\sup_{x\in R}|F_n(x) - F(x)|) = 0$ can be proved? How do I do this using Glivenko Cantelli?",Let be a random sample with distribution function and let be the corresponding empirical distribution function: My book says that can be proved? How do I do this using Glivenko Cantelli?,"X_1,...,X_n F F_n F_n(x) = \frac{1}{n} \sum_{i=1}^{n}1_{(-\infty,x]}(X_i) \lim_{n->\infty}E(\sup_{x\in R}|F_n(x) - F(x)|) = 0",['statistics']
14,What is the Rademacher complexity of kernelbased hypotheses with offset?,What is the Rademacher complexity of kernelbased hypotheses with offset?,,"Let $\mathcal{H}=\{ x\rightarrow \langle \mathbf{w},\Phi(x)\rangle+b : \|  \mathbf{w}\|_{\mathbb{H}} \le \Lambda, b\in \mathbb{R}\}$ be a function family, where $\Phi$ is a feature mapping, and $\mathbb{H}$ denotes the feature space, i.e., Hilber space. How can we bound the Rademacher complexity of $\mathcal{H}$ ? I know that when $b=0$ , the Rademacher complexity of $\mathcal{H}$ is bounded by $\sqrt{\frac{r^2\Lambda^2}{m}}$ , where $K(x,x) \le r^2$ and $m$ is the number of samples. But when the offset $b$ exists, how can we bound this Rademacher complexity?","Let be a function family, where is a feature mapping, and denotes the feature space, i.e., Hilber space. How can we bound the Rademacher complexity of ? I know that when , the Rademacher complexity of is bounded by , where and is the number of samples. But when the offset exists, how can we bound this Rademacher complexity?","\mathcal{H}=\{ x\rightarrow \langle \mathbf{w},\Phi(x)\rangle+b : \|  \mathbf{w}\|_{\mathbb{H}} \le \Lambda, b\in \mathbb{R}\} \Phi \mathbb{H} \mathcal{H} b=0 \mathcal{H} \sqrt{\frac{r^2\Lambda^2}{m}} K(x,x) \le r^2 m b","['real-analysis', 'linear-algebra', 'statistics', 'machine-learning']"
15,Convergence in distribution of weighted average,Convergence in distribution of weighted average,,"Consider the following setting: $X_i\sim P_X$ iid for $i = 1,2,\dots, n_X$ , where $P_X$ is a probability distribution with mean $\mu_X$ and variance $1$ , $Y_i\sim P_Y$ iid for $i = 1,2,\dots, n_Y$ , where $P_Y$ is a probability distribution with mean $\mu_Y$ and variance $1$ , $P_X$ and $P_Y$ are independent. Assume that $\frac{n_X}{n_X + n_Y}\rightarrow\lambda_X$ and $\frac{n_Y}{n_X + n_Y}\rightarrow\lambda_Y$ as $\min(n_X,n_Y)\rightarrow\infty$ . Consider the following definitions: \begin{align*}M &:= \frac{n_X}{n_X+n_Y}\left(\frac{1}{n_X}\sum_{k=1}^{n_X}X_k\right) + \frac{n_Y}{n_X+n_Y}\left(\frac{1}{n_X}\sum_{k=1}^{n_Y}Y_k\right),\\ \nu &:= \frac{n_X}{n_X+n_Y}\mu_X + \frac{n_Y}{n_X+n_Y}\mu_Y \end{align*} Then $$\sqrt{\frac{n_Xn_Y}{n_X+n_Y}}(M - \nu) = \underbrace{\sqrt{\frac{n_Y}{n_X+n_Y}}}_{\rightarrow\sqrt{\lambda_Y}}\underbrace{\frac{n_X}{n_X + n_Y}}_{\rightarrow\lambda_X}\underbrace{\sqrt{n_X}(\hat\mu_X - \mu_X)}_{\leadsto\mathcal N(0,1)} + \underbrace{\sqrt{\frac{n_X}{n_X+n_Y}}}_{\rightarrow\sqrt{\lambda_X}}\underbrace{\frac{n_Y}{n_X + n_Y}}_{\rightarrow\lambda_Y}\underbrace{\sqrt{n_Y}(\hat\mu_Y - \mu_Y)}_{\leadsto\mathcal N(0,1)}.$$ That is, the resulting limiting distribution is $\sqrt{\lambda_X\lambda_Y}(\sqrt{\lambda_X} + \sqrt{\lambda_Y})\mathcal N(0,1)$ . Is that correct? Two things confuse me: 1. the result looks not very familiar, and 2. usually we have that the ""parameter"", in this case, $\nu$ does not depend on the sample size. Thanks for any help!","Consider the following setting: iid for , where is a probability distribution with mean and variance , iid for , where is a probability distribution with mean and variance , and are independent. Assume that and as . Consider the following definitions: Then That is, the resulting limiting distribution is . Is that correct? Two things confuse me: 1. the result looks not very familiar, and 2. usually we have that the ""parameter"", in this case, does not depend on the sample size. Thanks for any help!","X_i\sim P_X i = 1,2,\dots, n_X P_X \mu_X 1 Y_i\sim P_Y i = 1,2,\dots, n_Y P_Y \mu_Y 1 P_X P_Y \frac{n_X}{n_X + n_Y}\rightarrow\lambda_X \frac{n_Y}{n_X + n_Y}\rightarrow\lambda_Y \min(n_X,n_Y)\rightarrow\infty \begin{align*}M &:= \frac{n_X}{n_X+n_Y}\left(\frac{1}{n_X}\sum_{k=1}^{n_X}X_k\right) + \frac{n_Y}{n_X+n_Y}\left(\frac{1}{n_X}\sum_{k=1}^{n_Y}Y_k\right),\\
\nu &:= \frac{n_X}{n_X+n_Y}\mu_X + \frac{n_Y}{n_X+n_Y}\mu_Y
\end{align*} \sqrt{\frac{n_Xn_Y}{n_X+n_Y}}(M - \nu) = \underbrace{\sqrt{\frac{n_Y}{n_X+n_Y}}}_{\rightarrow\sqrt{\lambda_Y}}\underbrace{\frac{n_X}{n_X + n_Y}}_{\rightarrow\lambda_X}\underbrace{\sqrt{n_X}(\hat\mu_X - \mu_X)}_{\leadsto\mathcal N(0,1)} + \underbrace{\sqrt{\frac{n_X}{n_X+n_Y}}}_{\rightarrow\sqrt{\lambda_X}}\underbrace{\frac{n_Y}{n_X + n_Y}}_{\rightarrow\lambda_Y}\underbrace{\sqrt{n_Y}(\hat\mu_Y - \mu_Y)}_{\leadsto\mathcal N(0,1)}. \sqrt{\lambda_X\lambda_Y}(\sqrt{\lambda_X} + \sqrt{\lambda_Y})\mathcal N(0,1) \nu",['statistics']
16,"$X$ is sub-Gaussian, then $X^2$ is sub-exponential","is sub-Gaussian, then  is sub-exponential",X X^2,"My goal is to show the following statement without using sub-exponential or sub-Gaussian norm; Let $X$ be a zero-mean sub-Gaussian random variable with the variance proxy $\sigma^2$ . Then $X^2$ is sub-exponential with parameters $(\nu, \alpha) = (16\sigma^2, 16\sigma^2)$ . For reference, the original material is on this site (complete lecture note) in lemma 1.12. Also, $X \in SG(\sigma^2)$ with $E[X] = \mu$ means sub-Gaussian and variance proxy $\sigma^2$ ; $$E[e^{t(X-\mu)}] \le e^{\frac{\sigma^2 t^2}{2}}, \forall t \in \mathbb R,$$ and $Z \in SE(\nu, \alpha)$ with $E[z] = \theta$ means sub-exponential with nonnegative parameter $(\nu, \alpha)$ ; $$E[e^{t(Z-\theta)}] \le e^{\frac{\nu^2 t^2}{2}}, \forall |t| < 1/\alpha.$$ Here is the partial proof; Let $Z = X^2 - E[X^2]$ for simplicity. Then, for $s \in \mathbb R$ , $$e^{sZ} = \sum_{k = 0}^{\infty} \frac{(sZ)^k}{k!} = 1 + \frac{sZ}{1!} + \frac{(sZ)^2}{2!} + ...$$ Using this property, the proof goes as follows; $$\begin{align} E[e^{sZ}] &= 1 + 0 +  \sum_{k = 2}^{\infty} \frac{s^kE[Z^k]}{k!} \sim (1) \\  &= 1 +  \sum_{k = 2}^{\infty} \frac{s^kE[(X^2 - E[X^2])^k]}{k!} \sim (2) \\  & \le 1 +  \sum_{k = 2}^{\infty} \frac{s^k2^{kâˆ’1}(E[X^{2k}]+(E[X^2])^k)}{k!} \sim (3) \\  & \le  1 +  \sum_{k = 2}^{\infty} \frac{s^k4^kE[X^{2k}]}{2(k!)} \sim (4)\\  & \le 1 +  \sum_{k = 2}^{\infty} \frac{s^k4^k2(2\sigma^2)^k k!}{2(k!)} \sim (5)\\  &= 1 + (8s\sigma^2)^2\sum_{k = 0}^{\infty} (8s\sigma^2)^k \sim (6) \\  &= 1 + 128s^2\sigma^4 \sim (7)\\  & \le exp(128s^2\sigma^4) \sim (8)\\  \end{align} $$ for $ |s| \le \frac{1}{16\sigma^2} $ . Now, let me explain what I can't understand for sure. It claims that (2) -> (3) holds due to the Jensen's inequality , but I can't obtain the inequality using Jensen. (for reference, (4) -> (5) holds due to the property that if $X \in SG(\sigma^2)$ , then $E[|X|^k] \le (2\sigma^2)^{k/2}k\Gamma(k/2)$ , which is on the lemma 1.4 of the site) Any help about this proof would be grateful. Thank you.","My goal is to show the following statement without using sub-exponential or sub-Gaussian norm; Let be a zero-mean sub-Gaussian random variable with the variance proxy . Then is sub-exponential with parameters . For reference, the original material is on this site (complete lecture note) in lemma 1.12. Also, with means sub-Gaussian and variance proxy ; and with means sub-exponential with nonnegative parameter ; Here is the partial proof; Let for simplicity. Then, for , Using this property, the proof goes as follows; for . Now, let me explain what I can't understand for sure. It claims that (2) -> (3) holds due to the Jensen's inequality , but I can't obtain the inequality using Jensen. (for reference, (4) -> (5) holds due to the property that if , then , which is on the lemma 1.4 of the site) Any help about this proof would be grateful. Thank you.","X \sigma^2 X^2 (\nu, \alpha) = (16\sigma^2, 16\sigma^2) X \in SG(\sigma^2) E[X] = \mu \sigma^2 E[e^{t(X-\mu)}] \le e^{\frac{\sigma^2 t^2}{2}}, \forall t \in \mathbb R, Z \in SE(\nu, \alpha) E[z] = \theta (\nu, \alpha) E[e^{t(Z-\theta)}] \le e^{\frac{\nu^2 t^2}{2}}, \forall |t| < 1/\alpha. Z = X^2 - E[X^2] s \in \mathbb R e^{sZ} = \sum_{k = 0}^{\infty} \frac{(sZ)^k}{k!} = 1 + \frac{sZ}{1!} + \frac{(sZ)^2}{2!} + ... \begin{align}
E[e^{sZ}] &= 1 + 0 +  \sum_{k = 2}^{\infty} \frac{s^kE[Z^k]}{k!} \sim (1) \\ 
&= 1 +  \sum_{k = 2}^{\infty} \frac{s^kE[(X^2 - E[X^2])^k]}{k!} \sim (2) \\ 
& \le 1 +  \sum_{k = 2}^{\infty} \frac{s^k2^{kâˆ’1}(E[X^{2k}]+(E[X^2])^k)}{k!} \sim (3) \\ 
& \le  1 +  \sum_{k = 2}^{\infty} \frac{s^k4^kE[X^{2k}]}{2(k!)} \sim (4)\\ 
& \le 1 +  \sum_{k = 2}^{\infty} \frac{s^k4^k2(2\sigma^2)^k k!}{2(k!)} \sim (5)\\ 
&= 1 + (8s\sigma^2)^2\sum_{k = 0}^{\infty} (8s\sigma^2)^k \sim (6) \\ 
&= 1 + 128s^2\sigma^4 \sim (7)\\ 
& \le exp(128s^2\sigma^4) \sim (8)\\ 
\end{align}
  |s| \le \frac{1}{16\sigma^2}  X \in SG(\sigma^2) E[|X|^k] \le (2\sigma^2)^{k/2}k\Gamma(k/2)","['probability', 'probability-theory', 'statistics', 'jensen-inequality']"
17,Probability of selected ball color,Probability of selected ball color,,"You are on a game show. There are 3 bins in front of you labelled ð´, ðµ, ð¶, with bin ð´ having 1 white balls and 1 black ball, bin ðµ have 3 White and 2 Black balls, and bin ð¶ having 5 White and 2 black balls. Without you seeing, the game show host chooses one of the bins at random (so that bin ð´ gets selected with probability 1/3, the same for bins ðµ, ð¶) and then selects a ball at random from the bin selected. a) What is the probability the ball selected by the game show host is White? b) Conditional on the event that the ball selected is White, what is the chance the game show host selected bin ð¶ was selected? I am honestly very lost on both of these questions- I think we'd have to do the probability of the white over the probability of all outcomes for a, which I think could be (1/3)(1/2) + (1/3)(3/5) + (1/3)(5/7) = 127/210. For b. (5/7)(1/3)/(127/210). Can anyone let me know if I'm doing something wrong, and how I should go about the problem?","You are on a game show. There are 3 bins in front of you labelled ð´, ðµ, ð¶, with bin ð´ having 1 white balls and 1 black ball, bin ðµ have 3 White and 2 Black balls, and bin ð¶ having 5 White and 2 black balls. Without you seeing, the game show host chooses one of the bins at random (so that bin ð´ gets selected with probability 1/3, the same for bins ðµ, ð¶) and then selects a ball at random from the bin selected. a) What is the probability the ball selected by the game show host is White? b) Conditional on the event that the ball selected is White, what is the chance the game show host selected bin ð¶ was selected? I am honestly very lost on both of these questions- I think we'd have to do the probability of the white over the probability of all outcomes for a, which I think could be (1/3)(1/2) + (1/3)(3/5) + (1/3)(5/7) = 127/210. For b. (5/7)(1/3)/(127/210). Can anyone let me know if I'm doing something wrong, and how I should go about the problem?",,"['probability', 'statistics']"
18,Well-urned balls,Well-urned balls,,"You want to maximize the number of red balls you get. Any red ball you draw you may keep. Any green ball you draw ends the game. Urn A contains one red and one green ball. You just draw. You get an expectation value $E(A)=1/2$ ( $p=1/2$ you get the red and draw the green, $1-p=1/2$ you immediately draw a green one). Urn B also contains one red and one green ball, but if you draw the red one, another red goes into B. You can do the infinite sum in your head, the expectation value is $1$ ball. Urn C contains two balls, where the content is equidistributed over the number of red balls. This means with $p=1/3$ both balls are red and you get both, with $q=1/3$ both are green and you get none, and with $1-p-q=1/3$ it contains one red and one green as in A, giving a red ball with fifty-fifty chance again. Makes $(2+0+1/2)/3=5/6$ balls. Urn D is like C, but has the first ball being red with $p=1/2$ and the other too. You get both red balls with $p=1/2*1/2=1/4$ , none with $q=1/4$ and a half with $1-p-q=1/2$ . Makes $3/4$ balls. Putting back would make no sense for C and D, since with finite probability you have only red balls and the expectation value thus is $\infty$ . Observe $E(A)<E(D)<E(C)<E(B)$ . Is this true generally for Urn A and B containing $n$ red and $n$ green balls, Urn C $2n$ balls equidistributed over the number of red balls and Urn D as C, only having each ball the probability $p=1/2$ that it is red? (I sorta doubt it, the advantage of Urn B gets close to zero with large $n$ .) Please give general formulae for any $n$ .","You want to maximize the number of red balls you get. Any red ball you draw you may keep. Any green ball you draw ends the game. Urn A contains one red and one green ball. You just draw. You get an expectation value ( you get the red and draw the green, you immediately draw a green one). Urn B also contains one red and one green ball, but if you draw the red one, another red goes into B. You can do the infinite sum in your head, the expectation value is ball. Urn C contains two balls, where the content is equidistributed over the number of red balls. This means with both balls are red and you get both, with both are green and you get none, and with it contains one red and one green as in A, giving a red ball with fifty-fifty chance again. Makes balls. Urn D is like C, but has the first ball being red with and the other too. You get both red balls with , none with and a half with . Makes balls. Putting back would make no sense for C and D, since with finite probability you have only red balls and the expectation value thus is . Observe . Is this true generally for Urn A and B containing red and green balls, Urn C balls equidistributed over the number of red balls and Urn D as C, only having each ball the probability that it is red? (I sorta doubt it, the advantage of Urn B gets close to zero with large .) Please give general formulae for any .",E(A)=1/2 p=1/2 1-p=1/2 1 p=1/3 q=1/3 1-p-q=1/3 (2+0+1/2)/3=5/6 p=1/2 p=1/2*1/2=1/4 q=1/4 1-p-q=1/2 3/4 \infty E(A)<E(D)<E(C)<E(B) n n 2n p=1/2 n n,"['statistics', 'probability-distributions']"
19,Strong consistency of kernel density estimator,Strong consistency of kernel density estimator,,"I am studying the book Nonparametric and Semiparametric Models written by Wolfgang Hardle and have difficulty with the following exercise: $\textbf{Exercise 3.13}$ Show that $\hat{f_h}^{(n)}(x) \xrightarrow {a.s.}f(x)$ . Assume that $f$ possesses a second derivative and $\Vert > K \Vert_2 <\infty$ . where $\hat{f_h}^{(n)}(x)=\dfrac{1}{n}\sum\limits_{i=1}^n K_h(x-X_i)$ is the density kernel estimator, $\Vert K \Vert_2=(\int_{\mathbb{R}}K^2(s)ds)^{\frac{1}{2}}$ and we set $h=O(n^{-\frac{1}{5}})$ which is the optimal bandwidth parameter in this exercise. Here is my attempt: I want to use Borel-Cantelli lemma to prove the almost sure convergence. By Chebyshev inequality we have $$ \mathbb{P}(\vert \hat{f_h}^{(n)}(x)-f(x)\vert>\epsilon)\le \dfrac{\mathbb{E}(\hat{f_h}^{(n)}(x)-f(x))^2}{\epsilon ^2}=\dfrac{MSE(\hat{f_h}^{(n)}(x))}{\epsilon^2}, $$ and it is known that $$ MSE(\hat{f_h}^{(n)}(x))=\dfrac{f(x)}{nh}\Vert K \Vert_2^2+\dfrac{1}{4}(f''(x))^2h^4(\mu_2(K))^2+o(h^4)+o(\dfrac{1}{nh}) $$ where $\mu_2(K)=\int_{\mathbb{R}}s^2K(s)ds$ . By replacing $h$ with $h_{opt}=O(n^{-\frac{1}{5}})$ we derive that $$MSE(\hat{f_h}^{(n)}(x))=O(n^{-\frac{4}{5}})$$ However, $\sum\limits_{n=1}^{\infty} n^{-\frac{4}{5}}=\infty$ and I was stuck here. Can anyone help me with this?","I am studying the book Nonparametric and Semiparametric Models written by Wolfgang Hardle and have difficulty with the following exercise: Show that . Assume that possesses a second derivative and . where is the density kernel estimator, and we set which is the optimal bandwidth parameter in this exercise. Here is my attempt: I want to use Borel-Cantelli lemma to prove the almost sure convergence. By Chebyshev inequality we have and it is known that where . By replacing with we derive that However, and I was stuck here. Can anyone help me with this?","\textbf{Exercise 3.13} \hat{f_h}^{(n)}(x) \xrightarrow
{a.s.}f(x) f \Vert
> K \Vert_2 <\infty \hat{f_h}^{(n)}(x)=\dfrac{1}{n}\sum\limits_{i=1}^n K_h(x-X_i) \Vert K \Vert_2=(\int_{\mathbb{R}}K^2(s)ds)^{\frac{1}{2}} h=O(n^{-\frac{1}{5}}) 
\mathbb{P}(\vert \hat{f_h}^{(n)}(x)-f(x)\vert>\epsilon)\le \dfrac{\mathbb{E}(\hat{f_h}^{(n)}(x)-f(x))^2}{\epsilon ^2}=\dfrac{MSE(\hat{f_h}^{(n)}(x))}{\epsilon^2},
 
MSE(\hat{f_h}^{(n)}(x))=\dfrac{f(x)}{nh}\Vert K \Vert_2^2+\dfrac{1}{4}(f''(x))^2h^4(\mu_2(K))^2+o(h^4)+o(\dfrac{1}{nh})
 \mu_2(K)=\int_{\mathbb{R}}s^2K(s)ds h h_{opt}=O(n^{-\frac{1}{5}}) MSE(\hat{f_h}^{(n)}(x))=O(n^{-\frac{4}{5}}) \sum\limits_{n=1}^{\infty} n^{-\frac{4}{5}}=\infty","['statistics', 'probability-limit-theorems', 'strong-convergence', 'nonparametric-statistics']"
20,Does pairwise phase incoherence satisfy the triangle inequality?,Does pairwise phase incoherence satisfy the triangle inequality?,,"Let $S$ be the unit circle in the complex plane, $$ S = \{z \in \mathbb{C} : |z| = 1\}. $$ For values $z_1^{(1)},z_1^{(2)},z_2^{(1)},z_2^{(2)},\ldots,z_k^{(1)},z_k^{(2)} \in S$ , letting \begin{align*}  A &:= \left|\sum_{j=1}^k z_j^{(1)}z_j^{(2)}\right| \\  B_1 &:= \left|\sum_{j=1}^k z_j^{(1)}\right| \\  B_2 &:= \left|\sum_{j=1}^k z_j^{(2)}\right|,  \end{align*} do we necessarily have that \begin{equation} \hspace{30mm} A \geq B_1 + B_2 - k \, ? \hspace{30mm} (1) \end{equation} If not, do we necessarily at least have that \begin{equation} \hspace{30mm} A^2 \geq B_1^2 + B_2^2 - k^2 \, ? \hspace{26mm} (2) \end{equation} Note that (1) does indeed imply (2): the triangle inequality gives that $B_1$ and $B_2$ are each at most $k$ , and hence $$ [\text{RHS of (1)}]^2 - \text{RHS of (2)} \ = \ 2(k-B_1)(k-B_2) \ \geq \ 0. $$ Context: For multivariate data where each coordinate is an angle, it is common to measure the coherence (resp. squared coherence ) between two of the coordinates across the data set, by taking the magnitude (resp. squared magnitude) of the mean of the complex exponential of the difference between the two coordinates. The question is then essentially whether one minus this value defines a metric on the set of coordinates (with Eq. (1) being for coherence and Eq. (2) being for squared coherence). This is a highly relevant question both for phase-coherence of stationary stochastic processes as defined in https://en.wikipedia.org/wiki/Coherence_(signal_processing) , and for various notions of time-localised phase-coherence such as in Appendix B.1 of https://www.sciencedirect.com/science/article/pii/S1063520320300750 .","Let be the unit circle in the complex plane, For values , letting do we necessarily have that If not, do we necessarily at least have that Note that (1) does indeed imply (2): the triangle inequality gives that and are each at most , and hence Context: For multivariate data where each coordinate is an angle, it is common to measure the coherence (resp. squared coherence ) between two of the coordinates across the data set, by taking the magnitude (resp. squared magnitude) of the mean of the complex exponential of the difference between the two coordinates. The question is then essentially whether one minus this value defines a metric on the set of coordinates (with Eq. (1) being for coherence and Eq. (2) being for squared coherence). This is a highly relevant question both for phase-coherence of stationary stochastic processes as defined in https://en.wikipedia.org/wiki/Coherence_(signal_processing) , and for various notions of time-localised phase-coherence such as in Appendix B.1 of https://www.sciencedirect.com/science/article/pii/S1063520320300750 .","S  S = \{z \in \mathbb{C} : |z| = 1\}.  z_1^{(1)},z_1^{(2)},z_2^{(1)},z_2^{(2)},\ldots,z_k^{(1)},z_k^{(2)} \in S \begin{align*}
 A &:= \left|\sum_{j=1}^k z_j^{(1)}z_j^{(2)}\right| \\
 B_1 &:= \left|\sum_{j=1}^k z_j^{(1)}\right| \\
 B_2 &:= \left|\sum_{j=1}^k z_j^{(2)}\right|,
 \end{align*} \begin{equation} \hspace{30mm} A \geq B_1 + B_2 - k \, ? \hspace{30mm} (1) \end{equation} \begin{equation} \hspace{30mm} A^2 \geq B_1^2 + B_2^2 - k^2 \, ? \hspace{26mm} (2) \end{equation} B_1 B_2 k  [\text{RHS of (1)}]^2 - \text{RHS of (2)} \ = \ 2(k-B_1)(k-B_2) \ \geq \ 0. ","['statistics', 'inequality', 'complex-numbers', 'signal-processing', 'time-series']"
21,Help with starting a proof regarding empirical distribution function of a uniform distribution,Help with starting a proof regarding empirical distribution function of a uniform distribution,,"Suppose $U_1,...,U_n$ is a simple sampling from a uniform distribution $U(0,1)$ and $G_n(u)$ is an empirical distribution function. Prove that $$ \begin{gathered} n \int_0^1\left(G_n(s)-s\right)^2 d s=\frac{1}{12 n}+\sum_{k=1}^n\left(U_{(k)}-\frac{2 k-1}{2 n}\right)^2, \\ \int_0^1\left(G_n(s)-s\right)^2 d s \leq \frac{1}{3} \end{gathered} $$ Look, I don't even know where to start. This is a recent task, but I don't remember any integral-related theorems or properties, I am not very comfortable with the Law of Large Numbers (even if applicable here). I am, of course, not looking for a complete solution, but any hints at which direction to even look.","Suppose is a simple sampling from a uniform distribution and is an empirical distribution function. Prove that Look, I don't even know where to start. This is a recent task, but I don't remember any integral-related theorems or properties, I am not very comfortable with the Law of Large Numbers (even if applicable here). I am, of course, not looking for a complete solution, but any hints at which direction to even look.","U_1,...,U_n U(0,1) G_n(u) 
\begin{gathered}
n \int_0^1\left(G_n(s)-s\right)^2 d s=\frac{1}{12 n}+\sum_{k=1}^n\left(U_{(k)}-\frac{2 k-1}{2 n}\right)^2, \\
\int_0^1\left(G_n(s)-s\right)^2 d s \leq \frac{1}{3}
\end{gathered}
","['integration', 'statistics', 'uniform-distribution', 'law-of-large-numbers']"
22,Connection between z-scores and a non-standard normal distribution,Connection between z-scores and a non-standard normal distribution,,"If you have a non-standard normal distribution $N(0,\sigma^2)$ , and you're interested the relative likelihood that $x=x$ , is there a way to use the z score $\frac{x'}{\sigma}$ with the PDF of the standard normal distribution in the same way you could if you were interested in $\Pr(x < x')$ . Of course, I am not interested in explicitly solving $\Pr(x=x')$ , but I am interested in the relative likelihood of $x'$ as you vary $\sigma^2$ to answer a question like ""if I have two non-standard normal distributions with different variance and I observe $x'$ , which distribution is more likely for that to have come from?""","If you have a non-standard normal distribution , and you're interested the relative likelihood that , is there a way to use the z score with the PDF of the standard normal distribution in the same way you could if you were interested in . Of course, I am not interested in explicitly solving , but I am interested in the relative likelihood of as you vary to answer a question like ""if I have two non-standard normal distributions with different variance and I observe , which distribution is more likely for that to have come from?""","N(0,\sigma^2) x=x \frac{x'}{\sigma} \Pr(x < x') \Pr(x=x') x' \sigma^2 x'",['probability']
23,Why is the sample space of n tossed coins identical to the expansion of a binomial to the nth power?,Why is the sample space of n tossed coins identical to the expansion of a binomial to the nth power?,,"I'm a newbie in math and also in this StackExchange. I apologize for any mistakes. The sample space of $n$ coins tossed seems identical to the expanded form of a binomial at the $n$ th power. Let's take the sample space $S$ of a situation with $n=3$ coins tossed. $$S=\{HHH,\ HHT,\ HTH,\ HTT,\ THH,\ THT,\ TTH,\ TTT\}$$ Now, let's treat $H$ and $T$ as algebraic variables (I don't think it's legal to do that, but let's do it anyway). So, due to commutative properties of multiplication, $HHT=HTH=THH$ , etc. So the new set now looks like this $$S=\{H^3,\ H^2T,\ H^2T,\ HT^2,\ H^2T,\ HT^2,\ HT^2,\ T^3\}$$ Now, let's add up the elements of the set, and we get- \begin{align} &\quad\ \ H^3\, +\, H^2T\, +\, H^2T\, +\, HT^2\, +\, H^2T\, +\, HT^2\, +\, HT^2\, +\, T^3 \\ &= H^3\, +\, 3H^2T\, +\, 3HT^2\, +\, T^3 \end{align} -which is the binomial expansion of $(H+T)^3$ . Why does this happen? How are sample space of $n$ tossed coins and the binomial expansion of $(H+T)^n$ related?","I'm a newbie in math and also in this StackExchange. I apologize for any mistakes. The sample space of coins tossed seems identical to the expanded form of a binomial at the th power. Let's take the sample space of a situation with coins tossed. Now, let's treat and as algebraic variables (I don't think it's legal to do that, but let's do it anyway). So, due to commutative properties of multiplication, , etc. So the new set now looks like this Now, let's add up the elements of the set, and we get- -which is the binomial expansion of . Why does this happen? How are sample space of tossed coins and the binomial expansion of related?","n n S n=3 S=\{HHH,\ HHT,\ HTH,\ HTT,\ THH,\ THT,\ TTH,\ TTT\} H T HHT=HTH=THH S=\{H^3,\ H^2T,\ H^2T,\ HT^2,\ H^2T,\ HT^2,\ HT^2,\ T^3\} \begin{align}
&\quad\ \ H^3\, +\, H^2T\, +\, H^2T\, +\, HT^2\, +\, H^2T\, +\, HT^2\, +\, HT^2\, +\, T^3 \\
&= H^3\, +\, 3H^2T\, +\, 3HT^2\, +\, T^3
\end{align} (H+T)^3 n (H+T)^n","['probability', 'statistics', 'binomial-theorem']"
24,Probability of student not taking course,Probability of student not taking course,,"An elementary school is offering 3 language classes: one in Spanish, one in French, and one in German. These classes are open to any of the 87 students in the school. There are 34 in the Spanish class, 31 in the French class, and 19 in the German class. There are 14 students that in both Spanish and French, 5 are in both Spanish and German, and 6 are in both French and German. In addition, there are 2 students taking all 3 classes. If two students are chosen randomly, what is the probability that neither of them are taking Spanish? My thought process was to first find the probability that the first and second student was taking Spanish, which would be 34/87 * 33/86. We have to find the complement of this, which would be 1-(187/1247) = 1060/1247. Is this correct? If not, can someone tell me how to go about the problem?","An elementary school is offering 3 language classes: one in Spanish, one in French, and one in German. These classes are open to any of the 87 students in the school. There are 34 in the Spanish class, 31 in the French class, and 19 in the German class. There are 14 students that in both Spanish and French, 5 are in both Spanish and German, and 6 are in both French and German. In addition, there are 2 students taking all 3 classes. If two students are chosen randomly, what is the probability that neither of them are taking Spanish? My thought process was to first find the probability that the first and second student was taking Spanish, which would be 34/87 * 33/86. We have to find the complement of this, which would be 1-(187/1247) = 1060/1247. Is this correct? If not, can someone tell me how to go about the problem?",,['statistics']
25,"When we say limit in probability, what do we mean?","When we say limit in probability, what do we mean?",,"We have a parameter $\theta$ and an estimator $\hat{\theta}$ . There are various ways to define consistency, this is one I've seen often. $\hat{\theta_n}$ , where $n$ indexes the sample size, is consistent for $\theta$ if $$ \lim_{n \to \infty} P( |\theta - \hat{\theta}| > \epsilon) = 0, \forall \epsilon >0. $$ Now $\hat{\theta}$ is a random variable with a distribution, so it's a ``spread out'' thing, and I don't see any way for the distribution (even in probability) to equal a single value. Do we mean by this statement that the probability that the difference between a value drawn from $\hat{\theta_n}$ and $\theta$ is greater than $\epsilon$ is zero? If yes, then good, I can understand that. If not, I'm lost.","We have a parameter and an estimator . There are various ways to define consistency, this is one I've seen often. , where indexes the sample size, is consistent for if Now is a random variable with a distribution, so it's a ``spread out'' thing, and I don't see any way for the distribution (even in probability) to equal a single value. Do we mean by this statement that the probability that the difference between a value drawn from and is greater than is zero? If yes, then good, I can understand that. If not, I'm lost.","\theta \hat{\theta} \hat{\theta_n} n \theta 
\lim_{n \to \infty} P( |\theta - \hat{\theta}| > \epsilon) = 0, \forall \epsilon >0.
 \hat{\theta} \hat{\theta_n} \theta \epsilon","['limits', 'statistics']"
26,Statistics of list permutations - expected similarity of rankings?,Statistics of list permutations - expected similarity of rankings?,,"I created a website where users create rankings, so for each user I have an ordered list of distinct elements $[e_1, e_2, ..., e_n]$ I calculate the similarity of two users by summing up the absolute index differences for each element and dividing the result by the maximum possible total difference ( $ \lfloor n^2/2 \rfloor $ ), then subtracting that from one. Users with similarity 1 have the exact same ranking. Now it seems that for most users the average difference to all other users isn't 50%, but below that. I calculated the difference for all permutations for $n=10$ from one specific ranking and got this result: and this seems to confirm this phenomenon - assuming that user rankings (element permutations) are random, the average similarity to other users is indeed less than 50%. But why? What kind of distribution is this and what is its most common value for a given $n$ ? Since with $n$ elements, there are $n!$ possible permutations, it isn't possible to ""brute-force-plot"" this for large n, unless (randomly) sampling a subset which I've done here:","I created a website where users create rankings, so for each user I have an ordered list of distinct elements I calculate the similarity of two users by summing up the absolute index differences for each element and dividing the result by the maximum possible total difference ( ), then subtracting that from one. Users with similarity 1 have the exact same ranking. Now it seems that for most users the average difference to all other users isn't 50%, but below that. I calculated the difference for all permutations for from one specific ranking and got this result: and this seems to confirm this phenomenon - assuming that user rankings (element permutations) are random, the average similarity to other users is indeed less than 50%. But why? What kind of distribution is this and what is its most common value for a given ? Since with elements, there are possible permutations, it isn't possible to ""brute-force-plot"" this for large n, unless (randomly) sampling a subset which I've done here:","[e_1, e_2, ..., e_n]  \lfloor n^2/2 \rfloor  n=10 n n n!","['statistics', 'permutations']"
27,Expectation value of stochastic differential equation using Fokker-Planck distributions,Expectation value of stochastic differential equation using Fokker-Planck distributions,,"Suppose we have a stochastic variable $x(t)$ with known steady-state Fokker-Planck distribution $P(x)$ , i.e. for any $f(x)$ , its expectation value is $$\overline{(f(x))}=\int dx f(x) P(x) $$ My question is what happens to $f(x)=\dot{x}(t)$ ? Is it correct to assume that $$\int dx \dot{x}(t) P(x) = \overline{\dot{x}(t)}$$ I do know the form of $\dot{x}(t)=-a x(t)+b \eta(t)$ , where $\overline{\eta(t)}=0$ and $\overline{\eta(t)\eta(t')}=\delta(t-t')$ . What can I say about $\overline{\dot{x}}$ ?","Suppose we have a stochastic variable with known steady-state Fokker-Planck distribution , i.e. for any , its expectation value is My question is what happens to ? Is it correct to assume that I do know the form of , where and . What can I say about ?",x(t) P(x) f(x) \overline{(f(x))}=\int dx f(x) P(x)  f(x)=\dot{x}(t) \int dx \dot{x}(t) P(x) = \overline{\dot{x}(t)} \dot{x}(t)=-a x(t)+b \eta(t) \overline{\eta(t)}=0 \overline{\eta(t)\eta(t')}=\delta(t-t') \overline{\dot{x}},"['statistics', 'partial-differential-equations', 'stochastic-processes']"
28,"How to get probability of $X \le Y + Z$ for $X, Y, Z$ all from the same specific distribution?",How to get probability of  for  all from the same specific distribution?,"X \le Y + Z X, Y, Z","I'm struggling to get the probability of $\mathbb{P}[X\le Y+Z]$ where all three are from the same distribution with the following pdf: $$f_X (x) = \frac{2(x-a)}{(b-a)^2}$$ where $0<a<b$ .  (Notice the pdf above comes from taking the maximum of two random variables uniformly distributed between $a,b$ ). However, I know that I need to use convolution to compute $\mathbb{P}[X\le Y+Z]$ where $X,Y,Z$ are i.i.d.  But I admit that I'm stuck on this convolution step.  How do I convolve these and get $\mathbb{P}[X\le Y+Z]$ ?","I'm struggling to get the probability of where all three are from the same distribution with the following pdf: where .  (Notice the pdf above comes from taking the maximum of two random variables uniformly distributed between ). However, I know that I need to use convolution to compute where are i.i.d.  But I admit that I'm stuck on this convolution step.  How do I convolve these and get ?","\mathbb{P}[X\le Y+Z] f_X (x) = \frac{2(x-a)}{(b-a)^2} 0<a<b a,b \mathbb{P}[X\le Y+Z] X,Y,Z \mathbb{P}[X\le Y+Z]","['probability', 'statistics', 'convolution']"
29,How can I simulate on R the total variation distance between the Law of the number of fixed points and Pois(1)?,How can I simulate on R the total variation distance between the Law of the number of fixed points and Pois(1)?,,"I am trying to make a graph on the Total Variation Distance between the Law of the number of Fixed Points of a Random Permutation and the Poisson( $\lambda = 1$ ) distribution. I know that the Total Variation distance is given by ${ ||\mu - \upsilon ||_{TV} }  = \frac{1}{2}{\sum_{x \in \Omega} |\mu(x)-\upsilon(x)|}$ or, equivalently by the $max_{x \subseteq \Omega}|\mu(x)-\upsilon(x)|$ . Actually I should make a graph by sampling something (that I do not understand what, yet) where it is possible to see that the TV decrease as N goes to infinity and that the TV curve stays below a bound that is given by $\frac{2^{N+1}}{(N+1)!}$ . Here is the formula to obtain the law of the number of fixed points in a random permutation $\pi(x) = {\displaystyle \frac{1}{x!} \sum _{k=0}^{n-x} \frac{{(-1)}^{k}}{k!}}$ I tried to plot something on R but I was told that it was very wrong because I set on the x axis the number of elements to permutate (n) and on the y axis the distance between $\pi$ and pois(1). I understand that I was wrong because I plotted the sigle difference over n and not the sum over all sets, but I do not how I can find all this sets by sampling. Well, I am very confused because I do not understand how and what I should sample to estimate the TV so any suggestions, comments or corrections to help me to understand it better will be very useful (also only related to the theory). I hope I explained me decently. Thank you very much","I am trying to make a graph on the Total Variation Distance between the Law of the number of Fixed Points of a Random Permutation and the Poisson( ) distribution. I know that the Total Variation distance is given by or, equivalently by the . Actually I should make a graph by sampling something (that I do not understand what, yet) where it is possible to see that the TV decrease as N goes to infinity and that the TV curve stays below a bound that is given by . Here is the formula to obtain the law of the number of fixed points in a random permutation I tried to plot something on R but I was told that it was very wrong because I set on the x axis the number of elements to permutate (n) and on the y axis the distance between and pois(1). I understand that I was wrong because I plotted the sigle difference over n and not the sum over all sets, but I do not how I can find all this sets by sampling. Well, I am very confused because I do not understand how and what I should sample to estimate the TV so any suggestions, comments or corrections to help me to understand it better will be very useful (also only related to the theory). I hope I explained me decently. Thank you very much",\lambda = 1 { ||\mu - \upsilon ||_{TV} }  = \frac{1}{2}{\sum_{x \in \Omega} |\mu(x)-\upsilon(x)|} max_{x \subseteq \Omega}|\mu(x)-\upsilon(x)| \frac{2^{N+1}}{(N+1)!} \pi(x) = {\displaystyle \frac{1}{x!} \sum _{k=0}^{n-x} \frac{{(-1)}^{k}}{k!}} \pi,"['combinatorics', 'statistics', 'probability-distributions', 'graphing-functions', 'total-variation']"
30,Function proportional to the log likelihood for the Gaussian distribution,Function proportional to the log likelihood for the Gaussian distribution,,"The following question has been crossposted to CrossValidated upon recommendation from the community and a lack of responses here. Consider the following problem from a course on statistical inference: If we generate a sample $x_i$ for $i \in$ { $1 ... n$ } from $ p(x_i) = \sum_{k=1}^2 w_kp(x_i| \mu _k, \sigma^2_k)$ where $p(x_i| \mu _k, \sigma ^2_k)$ are Gaussian densities and $w_2 = 1 - w_1$ (where we assume that all the parameters are unknown) Find the log-likelihood function for the sample $x_{1:n}$ . The log-likelihood is defined as: $$ l( \theta | x_{1:n}) = \log(p(x_{1:n})) = \log( \Pi _{i=1}^n p(x_i)) = \sum _{i=1}^n \log(p(x_i))$$ Now substituting in for $p(x_i)$ we get: $$ l( \theta | x_{1:n}) = \sum_{i=1}^n \log \Big{(} \sum_{k=1}^2 w_k p(x_i | \mu _k , \sigma^2_k) \Big{)} $$ We can now substitute in the Gaussian densities which gives us: $$ l( \theta | x_{1:n}) = \sum_{i=1}^n \log \Big{[} w_1(2 \pi \sigma ^2 _1)^{-1/2} \exp \Big{(}\frac{(x - \mu _1)^2}{2 \sigma ^2 _1} \Big{)} + w_2 (2 \pi \sigma ^2 _2)^{-1/2} \exp \Big{(}\frac{(x - \mu _2)^2}{2 \sigma ^2 _2} \Big{)} \Big{]} $$ The following solution aligns with my working, however, there is a proportionality relation on the last line that is unclear to me. Why does the final line hold? I can't see a clear and obvious way to get from the point at which I have substituted the Gaussian densities into the sum to it being proportional to the given double summation. I understand that we can exclude any multiplicative constants, however, it seems as though the summation has been taken out of the logarithm at some stage in order to derive a proportionality relation. Although I'm not sure if this holds and if it does, why does it hold?","The following question has been crossposted to CrossValidated upon recommendation from the community and a lack of responses here. Consider the following problem from a course on statistical inference: If we generate a sample for { } from where are Gaussian densities and (where we assume that all the parameters are unknown) Find the log-likelihood function for the sample . The log-likelihood is defined as: Now substituting in for we get: We can now substitute in the Gaussian densities which gives us: The following solution aligns with my working, however, there is a proportionality relation on the last line that is unclear to me. Why does the final line hold? I can't see a clear and obvious way to get from the point at which I have substituted the Gaussian densities into the sum to it being proportional to the given double summation. I understand that we can exclude any multiplicative constants, however, it seems as though the summation has been taken out of the logarithm at some stage in order to derive a proportionality relation. Although I'm not sure if this holds and if it does, why does it hold?","x_i i \in 1 ... n  p(x_i) = \sum_{k=1}^2 w_kp(x_i| \mu _k, \sigma^2_k) p(x_i| \mu _k, \sigma ^2_k) w_2 = 1 - w_1 x_{1:n}  l( \theta | x_{1:n}) = \log(p(x_{1:n})) = \log( \Pi _{i=1}^n p(x_i)) = \sum _{i=1}^n \log(p(x_i)) p(x_i)  l( \theta | x_{1:n}) = \sum_{i=1}^n \log \Big{(} \sum_{k=1}^2 w_k p(x_i | \mu _k , \sigma^2_k) \Big{)}   l( \theta | x_{1:n}) = \sum_{i=1}^n \log \Big{[} w_1(2 \pi \sigma ^2 _1)^{-1/2} \exp \Big{(}\frac{(x - \mu _1)^2}{2 \sigma ^2 _1} \Big{)} + w_2 (2 \pi \sigma ^2 _2)^{-1/2} \exp \Big{(}\frac{(x - \mu _2)^2}{2 \sigma ^2 _2} \Big{)} \Big{]} ","['probability', 'statistics', 'normal-distribution', 'statistical-inference', 'log-likelihood']"
31,Minimum of n iid chi-squared with k degrees of freedom,Minimum of n iid chi-squared with k degrees of freedom,,"I am currently trying to compute the expectation (a nice closed form distribution would be even better) of the minimum of n iid chi-squared with k degrees of freedom. After struggling with the pdf easily derived from the definition, I tried some numerical experiments and by making log-log plots, I have a strong belief (R2 of the regression > 0.998) that the solution is: $$\mathbb{E}\left[\min_{i \in [n]}X_i\right] = kn^{-\frac{1}{\sqrt{k}}}$$ Where $X_i \sim \chi^2(k)$ are iid. I don't find any way to prove it yet and would be grateful of any help or reference (I didn't find any either).","I am currently trying to compute the expectation (a nice closed form distribution would be even better) of the minimum of n iid chi-squared with k degrees of freedom. After struggling with the pdf easily derived from the definition, I tried some numerical experiments and by making log-log plots, I have a strong belief (R2 of the regression > 0.998) that the solution is: Where are iid. I don't find any way to prove it yet and would be grateful of any help or reference (I didn't find any either).",\mathbb{E}\left[\min_{i \in [n]}X_i\right] = kn^{-\frac{1}{\sqrt{k}}} X_i \sim \chi^2(k),"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'order-statistics']"
32,Non-negative least-squares with random variables,Non-negative least-squares with random variables,,"I've been working on a side project for a while that requires a huge amount of simple optimization, and have run into a pretty nasty problem while working on it. If any of you could give some advice I would really appreciate it. Background I have the three following variables: A known MxN matrix A A known length M column vector b An unknown length N column vector x . Furthermore, in my problem they are related by the following expression: $$Ax=b$$ In my project, I need a solution for x that satisfies this expression accurately as possible. By itself, this is a pretty well-studied problem! For instance, I am aware that I can multiply by the Pseudoinverse of A to find a good solution for x . However, in my problem, I also have the constraint that x must be non-negative. Thus, I instead am using a Non-Negative Least Squares Algorithm to solve for x : $$x=NNLS(A,b)$$ So far, this solution has worked pretty well for my application! The Problem Recently, I have run into situations where every variable inside A is a gaussian random variable. Fortunately, I know both the mean and variance of every element in A with pretty high precision. In addition, x is entirely non-random. Under these conditions, the problem slightly changes. I now want to find the optimal solution of x such that the result of the multiplication $Ax$ will have a mean value of b and a low variance in every element. However, I am struggling to figure out how to find the best solution for x with this information. If I just use non-negative least squares to solve for this, I run into some issues. I would imagine that, if column j has many elements with extremely large standard deviations, the jth element of x should be very small. This is because it would not be advantageous to include noisy matrix elements when trying to generate an approximation of b with little variance. However, all versions of the non-negative least squares algorithm, that I have seen, do not consider the possibility of noise or any randomness. This means that they would allow for large variance in b because they would only consider the mean of A ! The Question Is there any way to make a non-negative least squares algorithm consider noise when optimizing for x ? If not, are there alternative optimization methods I could use to solve for x so that the vector b has relatively low variance? Note about my background: I've been told it is useful to responders to know the background of people who ask questions here. I'm an engineer. While I am pretty familiar with mathematics, I am not very familiar with many optimization algorithms, and do not know a massive amount about statistics.","I've been working on a side project for a while that requires a huge amount of simple optimization, and have run into a pretty nasty problem while working on it. If any of you could give some advice I would really appreciate it. Background I have the three following variables: A known MxN matrix A A known length M column vector b An unknown length N column vector x . Furthermore, in my problem they are related by the following expression: In my project, I need a solution for x that satisfies this expression accurately as possible. By itself, this is a pretty well-studied problem! For instance, I am aware that I can multiply by the Pseudoinverse of A to find a good solution for x . However, in my problem, I also have the constraint that x must be non-negative. Thus, I instead am using a Non-Negative Least Squares Algorithm to solve for x : So far, this solution has worked pretty well for my application! The Problem Recently, I have run into situations where every variable inside A is a gaussian random variable. Fortunately, I know both the mean and variance of every element in A with pretty high precision. In addition, x is entirely non-random. Under these conditions, the problem slightly changes. I now want to find the optimal solution of x such that the result of the multiplication will have a mean value of b and a low variance in every element. However, I am struggling to figure out how to find the best solution for x with this information. If I just use non-negative least squares to solve for this, I run into some issues. I would imagine that, if column j has many elements with extremely large standard deviations, the jth element of x should be very small. This is because it would not be advantageous to include noisy matrix elements when trying to generate an approximation of b with little variance. However, all versions of the non-negative least squares algorithm, that I have seen, do not consider the possibility of noise or any randomness. This means that they would allow for large variance in b because they would only consider the mean of A ! The Question Is there any way to make a non-negative least squares algorithm consider noise when optimizing for x ? If not, are there alternative optimization methods I could use to solve for x so that the vector b has relatively low variance? Note about my background: I've been told it is useful to responders to know the background of people who ask questions here. I'm an engineer. While I am pretty familiar with mathematics, I am not very familiar with many optimization algorithms, and do not know a massive amount about statistics.","Ax=b x=NNLS(A,b) Ax","['statistics', 'optimization', 'convex-optimization', 'least-squares']"
33,Role of variance in consistent estimators,Role of variance in consistent estimators,,"By definition, a consistent estimator or rather a weak consistent estimator is one that causes data points to converges to their true value as the number of data points increases. So naturally, bias which is defined as $||{E[\hat{\theta}]-\theta}||$ converges to $0$ as number of points $m \rightarrow \infty$ . So, even variance is $0$ as $E[(\hat{\theta}-\theta)(\hat{\theta}-\theta)^{T}]$ will have $\hat{\theta}-\theta=0$ . However, I am still not too sure if I am thinking in the right direction due to the Kolmogorov SLLN as well as the no-free-lunch-theorem. Just another question, since an unbiased estimator has bias=0 and hence, the points are all at their true places in the empirical distribution, then is it not the definition of ""strong"" consistency?","By definition, a consistent estimator or rather a weak consistent estimator is one that causes data points to converges to their true value as the number of data points increases. So naturally, bias which is defined as converges to as number of points . So, even variance is as will have . However, I am still not too sure if I am thinking in the right direction due to the Kolmogorov SLLN as well as the no-free-lunch-theorem. Just another question, since an unbiased estimator has bias=0 and hence, the points are all at their true places in the empirical distribution, then is it not the definition of ""strong"" consistency?",||{E[\hat{\theta}]-\theta}|| 0 m \rightarrow \infty 0 E[(\hat{\theta}-\theta)(\hat{\theta}-\theta)^{T}] \hat{\theta}-\theta=0,"['probability-theory', 'statistics', 'statistical-inference', 'machine-learning', 'parameter-estimation']"
34,Average Duration Normal Distribution,Average Duration Normal Distribution,,"The average duration of Alzheimerâ€™s disease is $8$ years and the standard deviation is $4$ years. For a clinical study $30$ patients, who have been determined to be at the very beginning stage of the disease, are randomly selected. (i) What is the probability that the average duration of the disease among the sampled patients will be less than $7$ years? I believe if I let $Y$ denote the time it is normally distributed with parameters $8$ and $4^2$ . I worked out $P(Y<7) = 0.4013$ . However, I need to work out the probability of the average duration being less than $7$ years. How would I do this ? I know there are $30$ patients in total so the total sum must add to a number less than $210$ years.","The average duration of Alzheimerâ€™s disease is years and the standard deviation is years. For a clinical study patients, who have been determined to be at the very beginning stage of the disease, are randomly selected. (i) What is the probability that the average duration of the disease among the sampled patients will be less than years? I believe if I let denote the time it is normally distributed with parameters and . I worked out . However, I need to work out the probability of the average duration being less than years. How would I do this ? I know there are patients in total so the total sum must add to a number less than years.",8 4 30 7 Y 8 4^2 P(Y<7) = 0.4013 7 30 210,['probability']
35,Why do variances add when summing independent random variables?,Why do variances add when summing independent random variables?,,"I understand intuitively why spread would be additive, but not precisely why variances add rather than, say, the standard deviations. And how does this relate to the pythagorean theorem/euclidean distance? It appears the SDs can be treated as vectors perpendicular to (i.e. independent from) each other and the length of the vector when you sum them is equal to the SD when you sum the distributions. (This seems similar to how the SD itself can be seen as the euclidean distance of summed perpendicular deviations, divided by $\sqrt{n}$ ). (To be clear, I am not asking why variances can be added but not SDs, I am asking why variances are added rather than SDs (or anything else), so this is not a duplicate question) Thanks so much! Edit: I've gotten a great simple algebraic answer to my question, which is probably as far as you can go, but if anyone has some insight into the intuition behind it, that would be greatly appreciated too. It's probably like the pythagorean theorem and doesn't have a satisfying intuition, but I'd be more than happy with an explanation for why the standard deviations act like the sides of a right-angled triangle!","I understand intuitively why spread would be additive, but not precisely why variances add rather than, say, the standard deviations. And how does this relate to the pythagorean theorem/euclidean distance? It appears the SDs can be treated as vectors perpendicular to (i.e. independent from) each other and the length of the vector when you sum them is equal to the SD when you sum the distributions. (This seems similar to how the SD itself can be seen as the euclidean distance of summed perpendicular deviations, divided by ). (To be clear, I am not asking why variances can be added but not SDs, I am asking why variances are added rather than SDs (or anything else), so this is not a duplicate question) Thanks so much! Edit: I've gotten a great simple algebraic answer to my question, which is probably as far as you can go, but if anyone has some insight into the intuition behind it, that would be greatly appreciated too. It's probably like the pythagorean theorem and doesn't have a satisfying intuition, but I'd be more than happy with an explanation for why the standard deviations act like the sides of a right-angled triangle!",\sqrt{n},"['statistics', 'normed-spaces', 'variance', 'standard-deviation']"
36,Order Statistic as a Consistent Estimator,Order Statistic as a Consistent Estimator,,"Problem. Let $X_{1},\ldots,X_{n}$ denote a random sample from the distribution with common pdf $$ f(x;\theta) = e^{-(x-\theta)} 1_{(\theta,+\infty)}(x), \;\; \theta \in \mathbb{R} $$ Let $Y_{n} = \min \{X_{1},\ldots,X_{n}\}$ . Is $Y_{n}$ a consistent estimator of $\theta$ ? Attempt. Note that if $ \displaystyle \lim_{n \to \infty} \mathbb{P}[|Y_n - \theta| < \epsilon]=1$ , then $Y_n$ is a consistent estimator for $\theta$ . The CDF of $X_{1},\ldots,X_{n}$ is \begin{align*} F(x) &= \int_{0}^{x} e^{-(t-\theta)} \, dt \\ &= e^{\theta-x}(e^x-1) && x \in (\theta, \infty) \end{align*} So $F_{Y_n}(x) = [e^{\theta-x}(e^x-1)]^n$ . Moreover, \begin{align*} \lim_{n \to \infty} \mathbb{P}[|Y_n - \theta| < \epsilon] &= \lim_{n \to \infty} \mathbb{P}[\theta - \epsilon < Y_n < \epsilon + \theta] \\ &= \lim_{n \to \infty}  [F_{Y_n}(\theta + \epsilon) - F_{Y_n}(\theta - \epsilon)] \\ &= \lim_{n \to \infty} (e^{-\epsilon}(\epsilon^{\theta+\epsilon}-1))^{n} \\ &= \infty \end{align*} So $Y_n$ is not a consistent estimator for $\theta$ . Is this correct?","Problem. Let denote a random sample from the distribution with common pdf Let . Is a consistent estimator of ? Attempt. Note that if , then is a consistent estimator for . The CDF of is So . Moreover, So is not a consistent estimator for . Is this correct?","X_{1},\ldots,X_{n}  f(x;\theta) = e^{-(x-\theta)} 1_{(\theta,+\infty)}(x), \;\; \theta \in \mathbb{R}  Y_{n} = \min \{X_{1},\ldots,X_{n}\} Y_{n} \theta  \displaystyle \lim_{n \to \infty} \mathbb{P}[|Y_n - \theta| < \epsilon]=1 Y_n \theta X_{1},\ldots,X_{n} \begin{align*}
F(x) &= \int_{0}^{x} e^{-(t-\theta)} \, dt \\
&= e^{\theta-x}(e^x-1) && x \in (\theta, \infty)
\end{align*} F_{Y_n}(x) = [e^{\theta-x}(e^x-1)]^n \begin{align*}
\lim_{n \to \infty} \mathbb{P}[|Y_n - \theta| < \epsilon] &= \lim_{n \to \infty} \mathbb{P}[\theta - \epsilon < Y_n < \epsilon + \theta] \\
&= \lim_{n \to \infty}  [F_{Y_n}(\theta + \epsilon) - F_{Y_n}(\theta - \epsilon)] \\
&= \lim_{n \to \infty} (e^{-\epsilon}(\epsilon^{\theta+\epsilon}-1))^{n} \\
&= \infty
\end{align*} Y_n \theta","['statistics', 'solution-verification']"
37,Given this weak property is it possible to demonstrate that the difference of expected value is negative?,Given this weak property is it possible to demonstrate that the difference of expected value is negative?,,"Let's assume that we have $X,Y$ as random variables and we have as hypothesis that $$X-\mathbb{E}_x \leq Y-\mathbb{E}_y$$ where $\mathbb{E}_x$ is the expected value of x. Is it possible to demonstrate the following sentence? $$ P(X>l) \leq P(Y>l)$$ A classic result is obtained when $X\leq Y$ , but I was wondering if it is possible to obtain using the previous equation. If no, can you give me a counter example? What if we restrict $X,Y$ to be only positive random variables?","Let's assume that we have as random variables and we have as hypothesis that where is the expected value of x. Is it possible to demonstrate the following sentence? A classic result is obtained when , but I was wondering if it is possible to obtain using the previous equation. If no, can you give me a counter example? What if we restrict to be only positive random variables?","X,Y X-\mathbb{E}_x \leq Y-\mathbb{E}_y \mathbb{E}_x  P(X>l) \leq P(Y>l) X\leq Y X,Y","['probability', 'probability-theory', 'statistics', 'random-variables', 'expected-value']"
38,"How to calculate the expected correlation between N normally distributed variables which are all coupled by the same correlation, given a sample set?","How to calculate the expected correlation between N normally distributed variables which are all coupled by the same correlation, given a sample set?",,"I have N normally distributed variables, each with the same known standard deviation and mean. They are not independant, and are each correlated with the other with a Pearson's correlation coefficient of P, which we do not know. If we take a single sample of each of the N variables, I would like to derive a MLE of the underlying correlation P. It stands to reason that we should be able to etimate the value P, given the clustering of the sampled values and how close they are to the sample mean (a high value of P would result in a high level of clustering etc). I imagine some form of MLE would work here, but I'm coming a little unstuck on how to derive a PDF. My current train of thought would be to derive a PDF for the RMSE of each of the N samples relative to the mean sample value (which should be highly dependant on P as stated), and interpret this as a function of P and then derive the MLE formualtion etc but this seems like it would be an incredibly hard PDF to derive. Is there something I'm missing? Is there a better way of doing this?","I have N normally distributed variables, each with the same known standard deviation and mean. They are not independant, and are each correlated with the other with a Pearson's correlation coefficient of P, which we do not know. If we take a single sample of each of the N variables, I would like to derive a MLE of the underlying correlation P. It stands to reason that we should be able to etimate the value P, given the clustering of the sampled values and how close they are to the sample mean (a high value of P would result in a high level of clustering etc). I imagine some form of MLE would work here, but I'm coming a little unstuck on how to derive a PDF. My current train of thought would be to derive a PDF for the RMSE of each of the N samples relative to the mean sample value (which should be highly dependant on P as stated), and interpret this as a function of P and then derive the MLE formualtion etc but this seems like it would be an incredibly hard PDF to derive. Is there something I'm missing? Is there a better way of doing this?",,"['statistics', 'statistical-inference']"
39,Testing hypotheses about parameter function $\lambda^T\beta$,Testing hypotheses about parameter function,\lambda^T\beta,"I have a hypothetical situation, where the parameter function $\lambda^T\beta=\alpha_1-\alpha_2$ for the model $$y_{ij}=\mu+\alpha_i+\epsilon_{ij}, i=1,2, j=1,\cdots n_i$$ is estimated on two independent samples. So $\beta^T=(\mu,\alpha_1,\alpha_2)$ and $\lambda^T=(0,1,-1).$ The first sample has $n_1=2$ and $n_2=5$ , the second sample has $n_1=10$ and $n_2 = 20$ . From the first sample we know the estimate $\lambda^T\hat{\beta}$ and from the second sample we have the mean squared error $\text{(MSE}_2\text{)}$ . If I would like to test the hypothesis $H_0: \lambda^T\beta = 0,$ I would use the test statistic $$t := \frac{\lambda^T\hat{\beta}}{\sqrt{\text{MSE}_2\cdot \lambda^T(X^TX)^{-}\lambda}}.$$ For calculating $t$ , am I right to use the design matrix from the first sample, from where we have the estimate for the parameter function? I assume this because for deriving the formula of the statistic we need to use the fact that $$\frac{\lambda^T\hat{\beta}}{\sqrt{\lambda^T(X^TX)^{-}\lambda\sigma^2}}\sim N(0,1).$$ Am I right to assume this? A second topic of interest for me is how would one show that under $H_0$ the statistic $t$ indeed has t-distribution?","I have a hypothetical situation, where the parameter function for the model is estimated on two independent samples. So and The first sample has and , the second sample has and . From the first sample we know the estimate and from the second sample we have the mean squared error . If I would like to test the hypothesis I would use the test statistic For calculating , am I right to use the design matrix from the first sample, from where we have the estimate for the parameter function? I assume this because for deriving the formula of the statistic we need to use the fact that Am I right to assume this? A second topic of interest for me is how would one show that under the statistic indeed has t-distribution?","\lambda^T\beta=\alpha_1-\alpha_2 y_{ij}=\mu+\alpha_i+\epsilon_{ij}, i=1,2, j=1,\cdots n_i \beta^T=(\mu,\alpha_1,\alpha_2) \lambda^T=(0,1,-1). n_1=2 n_2=5 n_1=10 n_2 = 20 \lambda^T\hat{\beta} \text{(MSE}_2\text{)} H_0: \lambda^T\beta = 0, t := \frac{\lambda^T\hat{\beta}}{\sqrt{\text{MSE}_2\cdot \lambda^T(X^TX)^{-}\lambda}}. t \frac{\lambda^T\hat{\beta}}{\sqrt{\lambda^T(X^TX)^{-}\lambda\sigma^2}}\sim N(0,1). H_0 t","['statistics', 'parameter-estimation', 'hypothesis-testing']"
40,Inequality involving changing order of limits and probability,Inequality involving changing order of limits and probability,,"I read this paper , in Corollary 1 the author claims that $$\underset{\pi \in [0, 1]}{\sup}\ W_T(\pi) \overset{p}{\to} \infty$$ as $T \to \infty$ . Where $W_T(\pi)$ is Wald statistics but I think it should not matter for my question. The first step of the proof (formula A.35 in the paper) goes like this: Take any positive $c$ , $$\lim_{T \to \infty} \mathbb{P}(\underset{\pi \in [0, 1]}{\sup}\ W_T(\pi) < c) \le \lim_{\varepsilon \to 0}\sup\ \lim_{T \to \infty} \mathbb{P}(\underset{\pi \in [\varepsilon, 1-\varepsilon]}{\sup}\ W_T(\pi) < c)$$ and then he proves that the expression on the RHS is zero. For me it is unclear where this first inequality comes from. I think, using the monotone convergence theorem we can get $$\lim_{T \to \infty} \mathbb{P}(\underset{\pi \in [0, 1]}{\sup}\ W_T(\pi) < c) = \lim_{T \to \infty} \lim_{\varepsilon \to 0} \mathbb{P}(\underset{\pi \in [\varepsilon, 1-\varepsilon]}{\sup}\ W_T(\pi) < c)$$ but I do not think that in general we can say that $$\lim_{T \to \infty} \lim_{\varepsilon \to 0} \mathbb{P}(\underset{\pi \in [\varepsilon, 1-\varepsilon]}{\sup}\ W_T(\pi) < c) \le \lim_{\varepsilon \to 0}\sup\ \lim_{T \to \infty} \mathbb{P}(\underset{\pi \in [\varepsilon, 1-\varepsilon]}{\sup}\ W_T(\pi) < c)$$ take for example $a_{T, \varepsilon} = 1\ \{ \frac{1}{\varepsilon} > T \}$ then $$1 = \lim_{T \to \infty} \lim_{\varepsilon \to 0} a_{T, \varepsilon} > \lim_{\varepsilon \to 0}\sup\ \lim_{T \to \infty} a_{T, \varepsilon} = 0$$ Do you have any ideas what is implicitly assumed in the proof to justify this step? Or am I missing something? Thanks so much!","I read this paper , in Corollary 1 the author claims that as . Where is Wald statistics but I think it should not matter for my question. The first step of the proof (formula A.35 in the paper) goes like this: Take any positive , and then he proves that the expression on the RHS is zero. For me it is unclear where this first inequality comes from. I think, using the monotone convergence theorem we can get but I do not think that in general we can say that take for example then Do you have any ideas what is implicitly assumed in the proof to justify this step? Or am I missing something? Thanks so much!","\underset{\pi \in [0, 1]}{\sup}\ W_T(\pi) \overset{p}{\to} \infty T \to \infty W_T(\pi) c \lim_{T \to \infty} \mathbb{P}(\underset{\pi \in [0, 1]}{\sup}\ W_T(\pi) < c) \le \lim_{\varepsilon \to 0}\sup\ \lim_{T \to \infty} \mathbb{P}(\underset{\pi \in [\varepsilon, 1-\varepsilon]}{\sup}\ W_T(\pi) < c) \lim_{T \to \infty} \mathbb{P}(\underset{\pi \in [0, 1]}{\sup}\ W_T(\pi) < c) = \lim_{T \to \infty} \lim_{\varepsilon \to 0} \mathbb{P}(\underset{\pi \in [\varepsilon, 1-\varepsilon]}{\sup}\ W_T(\pi) < c) \lim_{T \to \infty} \lim_{\varepsilon \to 0} \mathbb{P}(\underset{\pi \in [\varepsilon, 1-\varepsilon]}{\sup}\ W_T(\pi) < c) \le \lim_{\varepsilon \to 0}\sup\ \lim_{T \to \infty} \mathbb{P}(\underset{\pi \in [\varepsilon, 1-\varepsilon]}{\sup}\ W_T(\pi) < c) a_{T, \varepsilon} = 1\ \{ \frac{1}{\varepsilon} > T \} 1 = \lim_{T \to \infty} \lim_{\varepsilon \to 0} a_{T, \varepsilon} > \lim_{\varepsilon \to 0}\sup\ \lim_{T \to \infty} a_{T, \varepsilon} = 0","['probability-theory', 'statistics', 'limsup-and-liminf', 'time-series']"
41,How to prove this characterisation of convergence by distribution?,How to prove this characterisation of convergence by distribution?,,"We solved the following problem in class and I do not understand what happens. Definition: A sequence of random variables $W_1, W_2, \ldots$ converges in distribution to random variable $W$ if for every $w \in \mathbb{R}$ s.t. $P(W = w) = 0$ , it is true that $\lim_{n \to \infty} P(W_n \leq w) = P(W \leq w)$ . Claim: Sequence of random variables $W_n$ converges weakly to $W$ iff for every $w \in \mathbb{R}$ , s.t. $P(W = w) = 0$ , it is true that $\lim_{n \to \infty} P(W_n < w) = P(W < w)$ . I do not understand the proof that we did. We only argued $(\Rightarrow)$ , as the converse is similar. We used the fact that $ \{ W_n \leq w \} = \cap_k \{ W_n < w + \frac{1}{k} \}$ . Then we wrote: \begin{multline*} P(W \leq w) = \lim_{n \to \infty} P(W_n \leq w) = \lim_{n \to \infty} P \left( \cap_k \left( W_n < w + \frac{1}{k} \right) \right) = \lim_{n \to \infty} \left( \lim_{k \to \infty} P \left( W_n < w + \frac{1}{k} \right) \right) = \\ = \lim_{k \to \infty} \left( \lim_{n \to \infty} P \left( W_n < w + \frac{1}{k} \right) \right) = \lim_{k \to \infty} P \left(W < n + \frac{1}{k} \right) \end{multline*} I have no idea why, first of all, $\lim_{k \to \infty} \left( \lim_{n \to \infty} P \left( W_n < w + \frac{1}{k} \right) \right) = \lim_{k \to \infty} P \left(W < n + \frac{1}{k} \right)$ . Then I also do not understand why what we did is enough; how does the claim (at least $(\Rightarrow)$ ) follow from what we have shown? We also stated that $F_X(x)$ has at most finitely many points of discontinuity and that this is crucial to our argument. Which makes me even more confused.","We solved the following problem in class and I do not understand what happens. Definition: A sequence of random variables converges in distribution to random variable if for every s.t. , it is true that . Claim: Sequence of random variables converges weakly to iff for every , s.t. , it is true that . I do not understand the proof that we did. We only argued , as the converse is similar. We used the fact that . Then we wrote: I have no idea why, first of all, . Then I also do not understand why what we did is enough; how does the claim (at least ) follow from what we have shown? We also stated that has at most finitely many points of discontinuity and that this is crucial to our argument. Which makes me even more confused.","W_1, W_2, \ldots W w \in \mathbb{R} P(W = w) = 0 \lim_{n \to \infty} P(W_n \leq w) = P(W \leq w) W_n W w \in \mathbb{R} P(W = w) = 0 \lim_{n \to \infty} P(W_n < w) = P(W < w) (\Rightarrow)  \{ W_n \leq w \} = \cap_k \{ W_n < w + \frac{1}{k} \} \begin{multline*}
P(W \leq w) = \lim_{n \to \infty} P(W_n \leq w) = \lim_{n \to \infty} P \left( \cap_k \left( W_n < w + \frac{1}{k} \right) \right) = \lim_{n \to \infty} \left( \lim_{k \to \infty} P \left( W_n < w + \frac{1}{k} \right) \right) = \\ = \lim_{k \to \infty} \left( \lim_{n \to \infty} P \left( W_n < w + \frac{1}{k} \right) \right) = \lim_{k \to \infty} P \left(W < n + \frac{1}{k} \right)
\end{multline*} \lim_{k \to \infty} \left( \lim_{n \to \infty} P \left( W_n < w + \frac{1}{k} \right) \right) = \lim_{k \to \infty} P \left(W < n + \frac{1}{k} \right) (\Rightarrow) F_X(x)","['probability', 'measure-theory', 'statistics', 'weak-convergence', 'conditional-convergence']"
42,Variance of sample fourth moment,Variance of sample fourth moment,,"Let $X_1,X_2,\dots$ be i.i.d. standard normal variables. We assume we know that they are standardized and i.i.d., but we don't know the distribution. We want to estimate $M_4:=E[X^4_i]=3$ . One possibility is to compute the sample fourth moment: $$\hat{M}_4:=\frac{1}{n} \sum_{i=1}^n X_i^4$$ By the law of large numbers $\hat{M}_4$ will converge in probability to $M_4$ . Another possible estimator for $M_4$ is $$\hat{M}_{4}^{'}:=\frac{\hat{M}_4}{(\frac{1}{n}\sum_{i=1}^n X_i^2)^2} $$ Simulations seem to indicate that $\hat{M}_{4}^{'}$ is more precise than $\hat{M}_4$ , with a mean squared error smaller by a around $1/2$ . Are there theoretical reasons for this? Am looking for a formal calculation. Thanks a lot for your help.","Let be i.i.d. standard normal variables. We assume we know that they are standardized and i.i.d., but we don't know the distribution. We want to estimate . One possibility is to compute the sample fourth moment: By the law of large numbers will converge in probability to . Another possible estimator for is Simulations seem to indicate that is more precise than , with a mean squared error smaller by a around . Are there theoretical reasons for this? Am looking for a formal calculation. Thanks a lot for your help.","X_1,X_2,\dots M_4:=E[X^4_i]=3 \hat{M}_4:=\frac{1}{n} \sum_{i=1}^n X_i^4 \hat{M}_4 M_4 M_4 \hat{M}_{4}^{'}:=\frac{\hat{M}_4}{(\frac{1}{n}\sum_{i=1}^n X_i^2)^2}  \hat{M}_{4}^{'} \hat{M}_4 1/2","['probability', 'probability-theory', 'statistics', 'statistical-inference', 'probability-limit-theorems']"
43,How to get the joint pdf of $X$ and $Y$ and check if $X$ and $Y$ are independent? [closed],How to get the joint pdf of  and  and check if  and  are independent? [closed],X Y X Y,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question Suppose $X \sim Binomial(1, 0.4)$ and $Y \sim Binomial(2, 0.4)$ , respectively. Assume $P(X = 1, Y = 2) = 0$ and X and Y are uncorrelated. What is the joint probability of $X$ and $Y$ ? Also, how to find $P(X\le Y)$ ? [That they are not independent. Because $P(X=1)P(Y=2)=0.4\times 0.4^2\neq 0$ .] I am confused about the question. Because it seems that the information is not enough to get the joint pdf of $X$ and $Y$ . We know that $$ f_X(x)=0.4^x0.6^{1-x}, x=0, 1 $$ and $$ f_Y(y)=\frac{y(y-1)}{2}0.4^y0.6^{2-y}, y=0,1,2 $$ But how to get the joint pdf of $X$ and $Y$ and check if $X$ and $Y$ are independent?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question Suppose and , respectively. Assume and X and Y are uncorrelated. What is the joint probability of and ? Also, how to find ? [That they are not independent. Because .] I am confused about the question. Because it seems that the information is not enough to get the joint pdf of and . We know that and But how to get the joint pdf of and and check if and are independent?","X \sim Binomial(1, 0.4) Y \sim Binomial(2, 0.4) P(X = 1, Y = 2) = 0 X Y P(X\le Y) P(X=1)P(Y=2)=0.4\times 0.4^2\neq 0 X Y 
f_X(x)=0.4^x0.6^{1-x}, x=0, 1
 
f_Y(y)=\frac{y(y-1)}{2}0.4^y0.6^{2-y}, y=0,1,2
 X Y X Y","['probability', 'statistics']"
44,Statistics and distributions,Statistics and distributions,,"How do you know if a distribution fits the data you are analyzing? For example, if I had data that based on my assumption can be distributed geometrically, how can I check that this distribution fits my data and how can I be sure that any model of this type will fit my data?","How do you know if a distribution fits the data you are analyzing? For example, if I had data that based on my assumption can be distributed geometrically, how can I check that this distribution fits my data and how can I be sure that any model of this type will fit my data?",,"['statistics', 'probability-distributions']"
45,Probability of computer chips being defective?,Probability of computer chips being defective?,,"Out of 10 computer chips, four are defective. Find the following. If three chips are randomly chosen for testing (without replacement), compute the probability that at most 2 of them are defective. Three scenarios possible, zero chips are defective. One chip is defective and lastly two chips are defective. Using Combination Formula. $$ C(n,k)=\frac{n!}{k!(n-k)!}. $$ defective $=4 $ non defective $= 6$ Total Ways = $\binom{10}{3}$ X= $2 $ defective chips from $3 $ selected chips. $$P(X\le2)=P(0)+P(1)+P(2)\\\frac{\binom{4}{0}\binom{6}{3}+\binom{4}{1}\binom{6}{2}+\binom{4}{2}\binom{6}{1}}{\binom{10}{3}}=.96667$$ Based on the above, would this be an appropriate way to solve the problem?","Out of 10 computer chips, four are defective. Find the following. If three chips are randomly chosen for testing (without replacement), compute the probability that at most 2 of them are defective. Three scenarios possible, zero chips are defective. One chip is defective and lastly two chips are defective. Using Combination Formula. defective non defective Total Ways = X= defective chips from selected chips. Based on the above, would this be an appropriate way to solve the problem?","
C(n,k)=\frac{n!}{k!(n-k)!}.
 =4  = 6 \binom{10}{3} 2  3  P(X\le2)=P(0)+P(1)+P(2)\\\frac{\binom{4}{0}\binom{6}{3}+\binom{4}{1}\binom{6}{2}+\binom{4}{2}\binom{6}{1}}{\binom{10}{3}}=.96667","['probability', 'combinatorics', 'statistics', 'conditional-probability']"
46,Example of tightness of Sauer-Shelah lemma,Example of tightness of Sauer-Shelah lemma,,"I was given the task of finding an example of a family of events (or hypothesis, concepts, etc.) such that the Sauer-Shelah lemma is tight. The lemma states: Assume that the Vapnik-Chervonenkis dimension (VC-dim) of a family of events $\mathcal{A}$ is $d$ . Then for $n \geq d$ $$\mathcal{S}_\mathcal{A}(n) \leq \sum_{i=0}^d{n \choose i}$$ Where $\mathcal{S}_\mathcal{A}$ is the shatter function. My solution: let $\mathcal{X} = \mathbb{R}$ and $\mathcal{A} = \{x\}_{x \in \mathcal{X}}$ . My understanding of VC-dim tells me that $\mathcal{A}$ has VC-dim = 1, since we are not able to shatter more than one point with sets in $\mathcal{A}$ . Now, choose a set with $n$ points $S =\{x_1, ..., x_n\}$ . Notice there  are $n+1$ different ways to shatter this set using $\mathcal{A}$ (choose each point once and then choose a point $x \not\in S$ ). Moreover, $$n+1 = \sum_{i=0}^1{n \choose i} = \underbrace{n \choose 0}_1 + \underbrace{{n \choose 1}}_n$$ Is this example correct ?","I was given the task of finding an example of a family of events (or hypothesis, concepts, etc.) such that the Sauer-Shelah lemma is tight. The lemma states: Assume that the Vapnik-Chervonenkis dimension (VC-dim) of a family of events is . Then for Where is the shatter function. My solution: let and . My understanding of VC-dim tells me that has VC-dim = 1, since we are not able to shatter more than one point with sets in . Now, choose a set with points . Notice there  are different ways to shatter this set using (choose each point once and then choose a point ). Moreover, Is this example correct ?","\mathcal{A} d n \geq d \mathcal{S}_\mathcal{A}(n) \leq \sum_{i=0}^d{n \choose i} \mathcal{S}_\mathcal{A} \mathcal{X} = \mathbb{R} \mathcal{A} = \{x\}_{x \in \mathcal{X}} \mathcal{A} \mathcal{A} n S =\{x_1, ..., x_n\} n+1 \mathcal{A} x \not\in S n+1 = \sum_{i=0}^1{n \choose i} = \underbrace{n \choose 0}_1 + \underbrace{{n \choose 1}}_n","['probability', 'statistics', 'machine-learning', 'computational-geometry', 'learning']"
47,How to calculate the Cramer-Rao lower bound,How to calculate the Cramer-Rao lower bound,,"I am having trouble calculating the Cramer-Rao lower bound for an unbiased estimator $\theta$ for the following function: $$f(x|\theta) = \theta^{2} x e^{-\theta x} , x>0$$ I have already calculated the maximum likelihood estimation which is $$\widehat{\theta} = \frac{2}{\overline{X}}.$$ I have been using the following equation to calculate the Fisher Information: $$I_{n}(\theta)=E[(\dfrac{\partial }{\partial \theta}\ln f(X|\theta))^{2}]$$ However, I cannot move forward past this point, since whenever I tried to calculate the Fisher Information $I(\theta)$ . $$\ln f(X|\theta) =2\ln (\theta)+\ln(x)-(\theta x)$$ $$\dfrac{\partial}{\partial \theta} \ln f(X|\theta)= \frac{2}{\theta}-x $$ $$(\dfrac{\partial}{\partial \theta} \ln f(X|\theta))^{2}= \frac{4}{\theta^{2}}-\frac{4x}{\theta}+x^{2}$$ When I calculate the expected value of this equation it does not equal to the solution that I was given for the problem, which is $\frac{\theta^{2}}{2n}$ .","I am having trouble calculating the Cramer-Rao lower bound for an unbiased estimator for the following function: I have already calculated the maximum likelihood estimation which is I have been using the following equation to calculate the Fisher Information: However, I cannot move forward past this point, since whenever I tried to calculate the Fisher Information . When I calculate the expected value of this equation it does not equal to the solution that I was given for the problem, which is .","\theta f(x|\theta) = \theta^{2} x e^{-\theta x} , x>0 \widehat{\theta} = \frac{2}{\overline{X}}. I_{n}(\theta)=E[(\dfrac{\partial }{\partial \theta}\ln f(X|\theta))^{2}] I(\theta) \ln f(X|\theta) =2\ln (\theta)+\ln(x)-(\theta x) \dfrac{\partial}{\partial \theta} \ln f(X|\theta)= \frac{2}{\theta}-x  (\dfrac{\partial}{\partial \theta} \ln f(X|\theta))^{2}= \frac{4}{\theta^{2}}-\frac{4x}{\theta}+x^{2} \frac{\theta^{2}}{2n}","['statistics', 'parameter-estimation', 'fisher-information']"
48,$\frac{Y}{Y+Z}$ is independent of $Y+Z$,is independent of,\frac{Y}{Y+Z} Y+Z,"Let $$X = Y + Z,$$ where $Y,Z$ are independent continuous random variables. Can it happen that $$ X \text{ and }\frac{Y}{X} \text{ are independent}? $$ If yes (I believe it can happen, but only in some weird degenerative case), can you somehow characterize such pairs of variables? I was trying to work it out by conditioning. Write $W(a):= [Y\mid X=a]$ which is a random variable $Y$ conditioned on $X=a$ . Then, $ W(a)/a \overset{d}{=} W(b)/b$ for all $a,b$ in the support of $X$ . However, explicitly writing down a distribution of $W(a)$ is typically non-trivial. Some other ideas on how to proceed?","Let where are independent continuous random variables. Can it happen that If yes (I believe it can happen, but only in some weird degenerative case), can you somehow characterize such pairs of variables? I was trying to work it out by conditioning. Write which is a random variable conditioned on . Then, for all in the support of . However, explicitly writing down a distribution of is typically non-trivial. Some other ideas on how to proceed?","X = Y + Z, Y,Z 
X \text{ and }\frac{Y}{X} \text{ are independent}?
 W(a):= [Y\mid X=a] Y X=a  W(a)/a \overset{d}{=} W(b)/b a,b X W(a)","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'conditional-probability']"
49,Unbiased estimator of binomially distributed random variables,Unbiased estimator of binomially distributed random variables,,"Let be $X_1, X_2\dots X_n$ independent binomially distributed random variables with probability $p$ and length $m$ . We denote $P(X_i=k)$ , the probability of $k$ sucesses, by $b(k;m,p)$ . Both parameters $p$ and $m$ are unknown. We know that $X_{(n)}=\max(X_1,X_2,...,X_n)$ is a consistent estimator for length $m$ (see https://math.stackexchange.com/a/4618523/579544 ). Is $X_{(n)}$ unbiased? My approach: For sake of simplicity I assume that $n=3$ and $X_{(3)}=\max(X_1,X_2,X_3)=k$ . By inclusion-exclusion principle we see that \begin{align*} &P(X_{(n)}=k)=P(\{X_1=k\}\cup \{X_2=k\}\cup \{X_3=k\})\\ &=P(X_1=k)+P(X_2=k)+P(X_3=k)\\ &-P(\{X_1=k\}\cap \{X_2=k\})-P(\{X_1=k\}\cap \{X_3=k\})-P(\{X_2=k\}\cap \{X_3=k\})\\ &+P\left(\{X_1=k\}\cap \{X_2=k\}\cap \{X_3=k\}\right)\\ &=3\cdot b(k;m,p)-3\cdot b(k;m,p)^2+b(k;m,p)^3. \end{align*} So the expected value $\mathbb{E}(X_{(n)})$ can be calculated by \begin{align*} \mathbb{E}(X_{(n)})=\sum\limits_{m=k}^{\infty}3m\cdot b(k;m,p)-3m\cdot b(k;m,p)^2+m b(k;m,p)^3. \end{align*} I don't know how to proceed/manipulate the series to get any further results? Is this a valid approach at all? Or is there a different/easier one? Maybe the expected value doesn't exist at all?","Let be independent binomially distributed random variables with probability and length . We denote , the probability of sucesses, by . Both parameters and are unknown. We know that is a consistent estimator for length (see https://math.stackexchange.com/a/4618523/579544 ). Is unbiased? My approach: For sake of simplicity I assume that and . By inclusion-exclusion principle we see that So the expected value can be calculated by I don't know how to proceed/manipulate the series to get any further results? Is this a valid approach at all? Or is there a different/easier one? Maybe the expected value doesn't exist at all?","X_1, X_2\dots X_n p m P(X_i=k) k b(k;m,p) p m X_{(n)}=\max(X_1,X_2,...,X_n) m X_{(n)} n=3 X_{(3)}=\max(X_1,X_2,X_3)=k \begin{align*}
&P(X_{(n)}=k)=P(\{X_1=k\}\cup \{X_2=k\}\cup \{X_3=k\})\\
&=P(X_1=k)+P(X_2=k)+P(X_3=k)\\
&-P(\{X_1=k\}\cap \{X_2=k\})-P(\{X_1=k\}\cap \{X_3=k\})-P(\{X_2=k\}\cap \{X_3=k\})\\
&+P\left(\{X_1=k\}\cap \{X_2=k\}\cap \{X_3=k\}\right)\\
&=3\cdot b(k;m,p)-3\cdot b(k;m,p)^2+b(k;m,p)^3.
\end{align*} \mathbb{E}(X_{(n)}) \begin{align*}
\mathbb{E}(X_{(n)})=\sum\limits_{m=k}^{\infty}3m\cdot b(k;m,p)-3m\cdot b(k;m,p)^2+m b(k;m,p)^3.
\end{align*}","['statistics', 'expected-value', 'parameter-estimation']"
50,Probability question from 2000 STEP III Exam (Question 13),Probability question from 2000 STEP III Exam (Question 13),,"I got on the first part of the question fine but I'm really confused about the expression "" the last of the dice to show a six does so on the $r$ th roll"" in the second part of the question. I interpret this line as in the following situations but none make sense. If this is to ask the result of rolling the very last dice on the $r$ th roll, then wouldn't it be independent from $n$ and $r$ , and result simply be $p$ ? If this is to ask the probability of at least one six shows up on the $r$ th roll which we consider as the last roll, then wouldn't the probability simply be $1-q^n$ , which is independent from $r$ If this is to ask the probability that result of six would never occur on the rolls after the $r$ th roll, then wouldn't it simply be zero since the number of rolls would be infinity and no occurrence of a six would be impossible? (i) A set of $n$ dice is rolled repeatedly. For each die the probability of showing a six is $p$ . Show that the probability that the first of the dice to show a six does so on the $r$ th roll is $$ q^{nr}\left ( q^{-n} - 1\right ) $$ where $q = 1 âˆ’ p$ . Determine, and simplify, an expression for the probability generating function for this distribution, in terms of $q$ and $n$ . The first of the dice to show a six does so on the R th roll. Find the expected value of $R$ and show that, in the case $n = 2$ , $p = 1/6$ , this value is 36/11. (ii) Show that the probability that the last of the dice to show a six does so on the rth roll is $$ \left ( 1-q^{r} \right )^{n}-\left ( 1-q^{r-1} \right )^{n}. $$ Find, for the case $n = 2$ , the probability generating function. The last of the dice to show a six does so on the $S$ th roll. Find the expected value of $S$ and evaluate this when $p = 1/6$ .","I got on the first part of the question fine but I'm really confused about the expression "" the last of the dice to show a six does so on the th roll"" in the second part of the question. I interpret this line as in the following situations but none make sense. If this is to ask the result of rolling the very last dice on the th roll, then wouldn't it be independent from and , and result simply be ? If this is to ask the probability of at least one six shows up on the th roll which we consider as the last roll, then wouldn't the probability simply be , which is independent from If this is to ask the probability that result of six would never occur on the rolls after the th roll, then wouldn't it simply be zero since the number of rolls would be infinity and no occurrence of a six would be impossible? (i) A set of dice is rolled repeatedly. For each die the probability of showing a six is . Show that the probability that the first of the dice to show a six does so on the th roll is where . Determine, and simplify, an expression for the probability generating function for this distribution, in terms of and . The first of the dice to show a six does so on the R th roll. Find the expected value of and show that, in the case , , this value is 36/11. (ii) Show that the probability that the last of the dice to show a six does so on the rth roll is Find, for the case , the probability generating function. The last of the dice to show a six does so on the th roll. Find the expected value of and evaluate this when .","r r n r p r 1-q^n r r n p r  q^{nr}\left (
q^{-n} - 1\right )  q = 1 âˆ’ p q n R n = 2 p = 1/6  \left ( 1-q^{r} \right )^{n}-\left (
1-q^{r-1} \right )^{n}.  n = 2 S S p =
1/6","['probability', 'combinatorics', 'statistics', 'dice']"
51,Definition about probability mass function by Rober V. Hogg,Definition about probability mass function by Rober V. Hogg,,"The following definition of pmf is on page51 from Probability and statistical inference by Robert V. Hogg, etc. The pmf $f(x)$ of a discrete random variable X is a function that satisfies the following properties: (a) $f(x)\gt 0, x\in S;$ (b) $\sum_{x\in S}f(x)=1;$ (c) $P(X\in A)=\sum_{x\in A}f(x),$ where $A\subset S$ . My question is about part(c). X is a random variable, and A is a subset of sample space S, how can $X\in A$ . Moreover, how can ${x\in A}$ ? In my opinion, the LHS of part(c) just means that we want to compute the probability of a single event, and the RHS of part(c) just means that we sum up all the related possibilities that we need. For example, if X: numbers of the sum of a fair six-side dice. Then P(X=3)=P({(1,2),(2,1)})=1/36+1/36=2/36, where A is a subset of S. Am I right? And could someone explain more about part(c)? It's better if someone can give me an example.","The following definition of pmf is on page51 from Probability and statistical inference by Robert V. Hogg, etc. The pmf of a discrete random variable X is a function that satisfies the following properties: (a) (b) (c) where . My question is about part(c). X is a random variable, and A is a subset of sample space S, how can . Moreover, how can ? In my opinion, the LHS of part(c) just means that we want to compute the probability of a single event, and the RHS of part(c) just means that we sum up all the related possibilities that we need. For example, if X: numbers of the sum of a fair six-side dice. Then P(X=3)=P({(1,2),(2,1)})=1/36+1/36=2/36, where A is a subset of S. Am I right? And could someone explain more about part(c)? It's better if someone can give me an example.","f(x) f(x)\gt 0, x\in S; \sum_{x\in S}f(x)=1; P(X\in A)=\sum_{x\in A}f(x), A\subset S X\in A {x\in A}","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'statistical-inference']"
52,"Create samples that are the same when unordered, but have some specific correlation when ordered","Create samples that are the same when unordered, but have some specific correlation when ordered",,"I have 100,000 random samples (with replacement) X_i from an otherwise unknown distribution. I want to create a series Y_i that is the same as X_i except for the ordering and gives a correlation between X and Y of some given number (or a correlation close to that given number). Is there a known technique/procedure/algorithm for this?","I have 100,000 random samples (with replacement) X_i from an otherwise unknown distribution. I want to create a series Y_i that is the same as X_i except for the ordering and gives a correlation between X and Y of some given number (or a correlation close to that given number). Is there a known technique/procedure/algorithm for this?",,"['statistics', 'probability-distributions', 'correlation']"
53,Likelihood ratio test.,Likelihood ratio test.,,"Consider a random sample from a distribution with density function $$ f(y)=\frac{1}{2 \lambda} e^{-\frac{y}{2 \lambda}} $$ when $\lambda,y>0$ . I want to construct a likelihood ratio test to determine when we can discard $H_0 :\lambda = 1$ in favor of $H_1 :\lambda \ne 1$ , with significance level $\alpha=0.01$ . I obtain the following likelihood: $$ L(\theta)=\prod_i^n \frac{1}{2 \lambda} e^{-\frac{1}{2 \lambda} y_i}=\frac{1}{2^n \lambda^n} e^{-\frac{1}{2 \lambda} \sum_{i=1}^n y_i}=\frac{1}{2^n \lambda^n} e^{-\frac{n \bar{y}}{2 \lambda}} $$ and the MLE for $\lambda$ : $$ \hat{\lambda}=\frac{1}{\bar{y}} $$ The likelihood ratio is then: $$ \Lambda=\frac{L\left(\lambda_0=1\right)}{L\left(\hat{\lambda}=\bar{y}^{-1}\right)}=\frac{\bar{y}^n}{2^n} e^{-\frac{n \bar{y}}{2}+n} $$ We discard $H_0$ if $\Lambda\le c$ for some $c$ determined by the signifinance level. My book states that we can use that $-2 \log \Lambda \stackrel{D}{\rightarrow} \chi^2(1)$ under the null hypothesis $H_0 :\lambda=\lambda_0$ . Hence, I assume that we can discard $H_0$ if $$ -2 \log\Lambda\ge \chi^2_{.01} $$ where $\chi^2_{.01}$ is the $.01$ -quantile of the chi-squared distribution with 1 degree of freedom: $\chi^2_{.01}=1.57\times10^{-4}$ . Is this the correct procedure, or have I misunderstood something?","Consider a random sample from a distribution with density function when . I want to construct a likelihood ratio test to determine when we can discard in favor of , with significance level . I obtain the following likelihood: and the MLE for : The likelihood ratio is then: We discard if for some determined by the signifinance level. My book states that we can use that under the null hypothesis . Hence, I assume that we can discard if where is the -quantile of the chi-squared distribution with 1 degree of freedom: . Is this the correct procedure, or have I misunderstood something?","
f(y)=\frac{1}{2 \lambda} e^{-\frac{y}{2 \lambda}}
 \lambda,y>0 H_0 :\lambda = 1 H_1 :\lambda \ne 1 \alpha=0.01 
L(\theta)=\prod_i^n \frac{1}{2 \lambda} e^{-\frac{1}{2 \lambda} y_i}=\frac{1}{2^n \lambda^n} e^{-\frac{1}{2 \lambda} \sum_{i=1}^n y_i}=\frac{1}{2^n \lambda^n} e^{-\frac{n \bar{y}}{2 \lambda}}
 \lambda 
\hat{\lambda}=\frac{1}{\bar{y}}
 
\Lambda=\frac{L\left(\lambda_0=1\right)}{L\left(\hat{\lambda}=\bar{y}^{-1}\right)}=\frac{\bar{y}^n}{2^n} e^{-\frac{n \bar{y}}{2}+n}
 H_0 \Lambda\le c c -2 \log \Lambda \stackrel{D}{\rightarrow} \chi^2(1) H_0 :\lambda=\lambda_0 H_0 
-2 \log\Lambda\ge \chi^2_{.01}
 \chi^2_{.01} .01 \chi^2_{.01}=1.57\times10^{-4}","['probability', 'statistics', 'probability-distributions', 'solution-verification', 'random-variables']"
54,How to optimally label three boxes. [closed],How to optimally label three boxes. [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question The problem: I have three infinite boxes. One contains both Apples and Bananas, one contains Apples and Cherries and the other contains Bananas and Cherries. All fruit in all boxes are in equal proportion, that is the probability of receiving one of the two available fruit is $\frac{1}{2}$ . You do not know which of the boxes are which but to correctly label them you may randomly draw fruit from them in order order you wish to. What is the optimal (with respected to expected draws) way to do this. What is the expected number of draws? My Result: I only managed to solve this nuts and bolts by manual analysis of combinations. I get $4.75$ . Is there a nice and clean way to solve this. Do you get a different answer?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question The problem: I have three infinite boxes. One contains both Apples and Bananas, one contains Apples and Cherries and the other contains Bananas and Cherries. All fruit in all boxes are in equal proportion, that is the probability of receiving one of the two available fruit is . You do not know which of the boxes are which but to correctly label them you may randomly draw fruit from them in order order you wish to. What is the optimal (with respected to expected draws) way to do this. What is the expected number of draws? My Result: I only managed to solve this nuts and bolts by manual analysis of combinations. I get . Is there a nice and clean way to solve this. Do you get a different answer?",\frac{1}{2} 4.75,"['probability', 'statistics']"
55,Calculate estimator's asymptotic distribution,Calculate estimator's asymptotic distribution,,"Let $W_1,\ldots,W_n \sim f_w(w;\lambda)=\frac{3w^2}{\lambda}e^{\frac{-w^3}{\lambda}}\mathbf{1}_{w>0}$ for some $\lambda>0$ . Give the asymptotic behavior of $\sqrt{n}(\lambda_{\text{MoM}}-\lambda)$ as $n\rightarrow \infty$ Give the asymptotic behavior of $\sqrt{n}(\lambda_{\text{MLE}}-\lambda)$ as $n\rightarrow \infty$ Give the asymptotic $(1-\alpha)\cdot100 \% $ confidence interval for $\log(\lambda)$ Note: MoM means method of moment, MLE means maximum likelihood estimator Try: I have use MoM: $\frac{\sum{Xi}}{n}=E[X]$ and $l=\operatorname{Log}(\text{Likelihood})$ to calculate the estimators, but don't know how to solve the asymptoic distribution $\sqrt{n}(\lambda_{\text{estimator}}-\lambda)$ .","Let for some . Give the asymptotic behavior of as Give the asymptotic behavior of as Give the asymptotic confidence interval for Note: MoM means method of moment, MLE means maximum likelihood estimator Try: I have use MoM: and to calculate the estimators, but don't know how to solve the asymptoic distribution .","W_1,\ldots,W_n \sim f_w(w;\lambda)=\frac{3w^2}{\lambda}e^{\frac{-w^3}{\lambda}}\mathbf{1}_{w>0} \lambda>0 \sqrt{n}(\lambda_{\text{MoM}}-\lambda) n\rightarrow \infty \sqrt{n}(\lambda_{\text{MLE}}-\lambda) n\rightarrow \infty (1-\alpha)\cdot100 \%  \log(\lambda) \frac{\sum{Xi}}{n}=E[X] l=\operatorname{Log}(\text{Likelihood}) \sqrt{n}(\lambda_{\text{estimator}}-\lambda)","['probability', 'statistics', 'parameter-estimation']"
56,How this exponential family is rewritten using dominating measure,How this exponential family is rewritten using dominating measure,,"The exponential family is given by : $$p(x;\theta)=\exp\left\{C(x)+\theta^{i}F_{i}(x)-\psi(\theta)\right\}\hspace{3cm} (1)$$ the $n$ functions $F_{1}(x),...,F_{n}(x)$ are random variables. Let $x_i=F_{i}(x)$ . Suppose we define the probability density function on the $n$ -dimensional random variable $x=[x_i]$ with respect to the dominating measure $$d\mu(x)=\exp\{C(x)\}dx\hspace{3cm}(2)$$ Then we may rewrite equation $(1)$ as $$p(x;\theta)=\exp\{\theta^{i}x_{i}-\psi(\theta)\}\hspace{3cm} (3)$$ Can how we wrote $(3)$ ??",The exponential family is given by : the functions are random variables. Let . Suppose we define the probability density function on the -dimensional random variable with respect to the dominating measure Then we may rewrite equation as Can how we wrote ??,"p(x;\theta)=\exp\left\{C(x)+\theta^{i}F_{i}(x)-\psi(\theta)\right\}\hspace{3cm} (1) n F_{1}(x),...,F_{n}(x) x_i=F_{i}(x) n x=[x_i] d\mu(x)=\exp\{C(x)\}dx\hspace{3cm}(2) (1) p(x;\theta)=\exp\{\theta^{i}x_{i}-\psi(\theta)\}\hspace{3cm} (3) (3)","['probability-theory', 'measure-theory', 'statistics']"
57,Show that $\sqrt{n}(\overline{X}_n^2 - \mu^2) \to 2\mu|\sigma Z$ in distribution,Show that  in distribution,\sqrt{n}(\overline{X}_n^2 - \mu^2) \to 2\mu|\sigma Z,"(Full disclosure--this is a homework problem.) Let $(X_n)_{n=1}^{\infty}$ be a sequence of i.i.d. random variables with mean $\mu$ and variance $\sigma^2 < \infty$ . I want to show that if $\mu \neq 0$ then \begin{align*}     \sqrt{n}(\overline{X}_n^2 - \mu^2) \to 2 \mu \sigma Z \quad \text{in distribution as } n \to \infty, \end{align*} where $Z$ is a standard normal random variable. My attempt . We have \begin{align*}     \frac{\sqrt{n}}{\sigma} (\overline{X}_n^2 - \mu^2) = \frac{\overline{X}_n^2 - \mu^2}{\sigma/\sqrt{n}} = \left(\frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} \right)\left(\overline{X}_n + \mu \right). \end{align*} Now $\frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} \to Z$ in distribution as $n \to \infty$ by the Central Limit Theorem. And $\overline{X}_n \to \mu$ almost surely by the Strong Law of Large Numbers. Therefore, $\overline{X}_n \to 2\mu$ almost surely, and hence $\overline{X}_n \to 2\mu$ in probability. Then by Slutsky's Theorem, \begin{align*}    \left(\frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} \right)\left(\overline{X}_n + \mu \right) \to 2\mu Z \quad \text{in distribution as } n \to \infty, \end{align*} and therefore, \begin{align*}     \sqrt{n}(\overline{X}_n^2 - \mu^2) \to 2\mu \sigma Z \quad \text{in distribution as } n \to \infty. \end{align*} How do we get the absolute value sign? I'm not seeing my mistake...","(Full disclosure--this is a homework problem.) Let be a sequence of i.i.d. random variables with mean and variance . I want to show that if then where is a standard normal random variable. My attempt . We have Now in distribution as by the Central Limit Theorem. And almost surely by the Strong Law of Large Numbers. Therefore, almost surely, and hence in probability. Then by Slutsky's Theorem, and therefore, How do we get the absolute value sign? I'm not seeing my mistake...","(X_n)_{n=1}^{\infty} \mu \sigma^2 < \infty \mu \neq 0 \begin{align*}
    \sqrt{n}(\overline{X}_n^2 - \mu^2) \to 2 \mu \sigma Z \quad \text{in distribution as } n \to \infty,
\end{align*} Z \begin{align*}
    \frac{\sqrt{n}}{\sigma} (\overline{X}_n^2 - \mu^2) = \frac{\overline{X}_n^2 - \mu^2}{\sigma/\sqrt{n}} = \left(\frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} \right)\left(\overline{X}_n + \mu \right).
\end{align*} \frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} \to Z n \to \infty \overline{X}_n \to \mu \overline{X}_n \to 2\mu \overline{X}_n \to 2\mu \begin{align*}
   \left(\frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} \right)\left(\overline{X}_n + \mu \right) \to 2\mu Z \quad \text{in distribution as } n \to \infty,
\end{align*} \begin{align*}
    \sqrt{n}(\overline{X}_n^2 - \mu^2) \to 2\mu \sigma Z \quad \text{in distribution as } n \to \infty.
\end{align*}","['probability', 'statistics']"
58,Show a closer correlation between random variables,Show a closer correlation between random variables,,"Thank you for paying attention on my post! The Original Question (informal): I have $(2n+1)$ random variables $X, Y_1, \cdots, Y_n, Z_1,\cdots,Z_n$ satisfying that $\forall i,j,Cov(X,Y_i)=\sigma^2\rho(X,Y_i)>Cov(X,Z_j)=\sigma^2\rho(X,Z_j)\ge 0$ , $\forall i,Var(X)=Var(Y_i)=Var(Z_i)=\sigma^2$ , and $\forall i\ne j, Cov(Y_i,Y_j)=Cov(Z_i,Z_j)$ (this condition can be removed in some situations), where $\sigma\in\mathbb{R}^+$ is a constant, $\rho$ denotes the Pearson's correlation coefficient. In addition, $\rho(X,Z_i)$ s are positive numbers convergent to $0$ in some situations. (We can discuss the case of $\forall i,\rho(X,Z_i)\equiv0$ .) And $\rho(X,Y_i)$ s are positive constants and not larger than $1$ . Is there a way to show that for any weighting factors $w_i$ s, the weighted variable $Y=\sum_{i}w_iY_i$ is more closely correlated to $X$ than $Z=\sum_{i}w_iZ_i$ ? My Efforts and Supplemental Information: There may be some intuitions: $(A1)$ All the $Y_i$ s are more closely related to $X$ , compared to $Z_i$ s; $(A2)$ $Y=\sum_{i}w_iY_i$ has a closer relation to $X$ , compared to $Z=\sum_{i}w_iZ_i$ . (For example, $Y_i$ s are actually scaled versions of $X$ , and $Z_i$ s are some values of random noise.) However, since $w_i$ s are not limited to be positive or negative, it is difficult to show this through some metrics like Pearson's correlation coefficient. In other words, I may know that if all $w_i$ s are non-negative, the above $(A2)$ can be revealed by the Pearson's correlation coefficient or covariance: \begin{align*} Cov(X,Y)&=\sum_i{w_iCov(X,Y_i)}>\sum_i{w_iCov(X,Z_i)}=Cov(X,Z),\\ \rho(X,Y)&=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}=\frac{\sum_i{w_iCov(X,Y_i)}}{\sqrt{Var(X)Var(Y)}}\\ &>\frac{\sum_i{w_iCov(X,Z_i)}}{\sqrt{Var(X)Var(Z)}}=\frac{Cov(X,Z)}{\sqrt{Var(X)Var(Z)}}=\rho(X,Z). \end{align*} But the $w_i$ s are not guaranteed to be non-negative. :( There are some things that should not be changed: $(B1)$ The weighting factors $w_i$ s are randomly produced and can be positive or negative. $(B2)$ The weighted summation form of $Y=\sum_{i}w_iY_i$ and $Z=\sum_{i}w_iZ_i$ should not be changed or modified. $(B3)$ I may want to show $(A2)$ through some metrics/indices/measures (not limited to Pearson's correlation coefficient or the covariance). Therefore, I am trying in the following aspects: $(C1)$ (Change the goal) I am finding some other variables $Y^\prime$ and $Z^\prime$ constructed upon $Y$ and $Z$ (for example, $Y^\prime=Y^2$ and $Z^\prime=Z^2$ ), and trying to show that $Y^\prime$ is more closely related to $X$ , compared to $Z^\prime$ . $(C2)$ (Change the metrics/indices/measures) Beyond Pearson's correlation coefficient and the covariance, I am trying to find some other metrics/indices/measures which can reflect that $Y$ is more closely related to $X$ , compared to $Z$ . But after a long struggle (about a week), I can still not find a solution to show something like $(A2)$ . Is there a way to modify something or made some operations like $(C1)$ and $(C2)$ to show some conclusions like $(A2)$ ? I am still thinking and finding ... Why do I try to find a solution toward a conclusion like $(A2)$ ? This is actually an intermediate step in my work. I am stuck by it for a long time. Now I am feeling that my thoughts may be in a muddle. I am refining and re-organizing my above words and sentences to make the expressions clearer. Any ideas/suggestions about ""explicitly showing a closer relation"" are very welcomed. Thank you very much for reading such a long informal post!","Thank you for paying attention on my post! The Original Question (informal): I have random variables satisfying that , , and (this condition can be removed in some situations), where is a constant, denotes the Pearson's correlation coefficient. In addition, s are positive numbers convergent to in some situations. (We can discuss the case of .) And s are positive constants and not larger than . Is there a way to show that for any weighting factors s, the weighted variable is more closely correlated to than ? My Efforts and Supplemental Information: There may be some intuitions: All the s are more closely related to , compared to s; has a closer relation to , compared to . (For example, s are actually scaled versions of , and s are some values of random noise.) However, since s are not limited to be positive or negative, it is difficult to show this through some metrics like Pearson's correlation coefficient. In other words, I may know that if all s are non-negative, the above can be revealed by the Pearson's correlation coefficient or covariance: But the s are not guaranteed to be non-negative. :( There are some things that should not be changed: The weighting factors s are randomly produced and can be positive or negative. The weighted summation form of and should not be changed or modified. I may want to show through some metrics/indices/measures (not limited to Pearson's correlation coefficient or the covariance). Therefore, I am trying in the following aspects: (Change the goal) I am finding some other variables and constructed upon and (for example, and ), and trying to show that is more closely related to , compared to . (Change the metrics/indices/measures) Beyond Pearson's correlation coefficient and the covariance, I am trying to find some other metrics/indices/measures which can reflect that is more closely related to , compared to . But after a long struggle (about a week), I can still not find a solution to show something like . Is there a way to modify something or made some operations like and to show some conclusions like ? I am still thinking and finding ... Why do I try to find a solution toward a conclusion like ? This is actually an intermediate step in my work. I am stuck by it for a long time. Now I am feeling that my thoughts may be in a muddle. I am refining and re-organizing my above words and sentences to make the expressions clearer. Any ideas/suggestions about ""explicitly showing a closer relation"" are very welcomed. Thank you very much for reading such a long informal post!","(2n+1) X, Y_1, \cdots, Y_n, Z_1,\cdots,Z_n \forall i,j,Cov(X,Y_i)=\sigma^2\rho(X,Y_i)>Cov(X,Z_j)=\sigma^2\rho(X,Z_j)\ge 0 \forall i,Var(X)=Var(Y_i)=Var(Z_i)=\sigma^2 \forall i\ne j, Cov(Y_i,Y_j)=Cov(Z_i,Z_j) \sigma\in\mathbb{R}^+ \rho \rho(X,Z_i) 0 \forall i,\rho(X,Z_i)\equiv0 \rho(X,Y_i) 1 w_i Y=\sum_{i}w_iY_i X Z=\sum_{i}w_iZ_i (A1) Y_i X Z_i (A2) Y=\sum_{i}w_iY_i X Z=\sum_{i}w_iZ_i Y_i X Z_i w_i w_i (A2) \begin{align*}
Cov(X,Y)&=\sum_i{w_iCov(X,Y_i)}>\sum_i{w_iCov(X,Z_i)}=Cov(X,Z),\\
\rho(X,Y)&=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}=\frac{\sum_i{w_iCov(X,Y_i)}}{\sqrt{Var(X)Var(Y)}}\\
&>\frac{\sum_i{w_iCov(X,Z_i)}}{\sqrt{Var(X)Var(Z)}}=\frac{Cov(X,Z)}{\sqrt{Var(X)Var(Z)}}=\rho(X,Z).
\end{align*} w_i (B1) w_i (B2) Y=\sum_{i}w_iY_i Z=\sum_{i}w_iZ_i (B3) (A2) (C1) Y^\prime Z^\prime Y Z Y^\prime=Y^2 Z^\prime=Z^2 Y^\prime X Z^\prime (C2) Y X Z (A2) (C1) (C2) (A2) (A2)","['probability-theory', 'measure-theory', 'statistics', 'random-variables', 'correlation']"
59,Hypothesis Testing Two Measures Coin Tosses Martingale,Hypothesis Testing Two Measures Coin Tosses Martingale,,"Consider a sequence of iid tosses of a coin with $X_i$ denoting the outcome of the $i^{th}$ toss. These random variables are defined on some $(\Omega, \mathcal{F})$ on which we have two probability measures $\mathbb{P}_{A}$ and $\mathbb{P}_{B}$ . Under hypothesis $A$ , $\mathbb{P}_{A}$ is the true measure, and the probability of a head on any toss is $p=a$ . Under hypothesis $B$ , the measure is $\mathbb{P}_{B}$ and $p=b$ for some $a,b \in (0,1)$ . Let $P_{A}(x_1, x_2, \dots, x_n)$ denote the probability of a sequence of outcomes $(x_1, x_2,\dots, x_n)$ under the hypothesis $A$ , i.e. $$P_{A}(x_1, x_2, \dots, x_n) = \mathbb{P}_{A}(X_1 = x_1, X_2 = x_2, \dots, X_n = x_n),$$ with the analogous definition for $P_B$ . I need to show that $$Z_n = \frac{P_A(X_1, X_2, \dots, X_n)}{P_B(X_1, X_2, \dots, X_n)}$$ is a martingale under $\mathbb{P}_{B}$ , relative to the filtration generated by the tosses, $\mathcal{F}_n = \sigma(X_k : k \le n)$ . Then I need to see what happens to the distribution of its limit (which I will know exists almost surely by the Martingale Convergence Property). I am struggling to prove that $Z_n$ is indeed a martingale: it is clear that it is adapted, but I am not sure how to show integrability and the expectation property. Would it also follow that $\frac{1}{Z_n}$ is a $\mathbb{P}_{A}-$ martingale?","Consider a sequence of iid tosses of a coin with denoting the outcome of the toss. These random variables are defined on some on which we have two probability measures and . Under hypothesis , is the true measure, and the probability of a head on any toss is . Under hypothesis , the measure is and for some . Let denote the probability of a sequence of outcomes under the hypothesis , i.e. with the analogous definition for . I need to show that is a martingale under , relative to the filtration generated by the tosses, . Then I need to see what happens to the distribution of its limit (which I will know exists almost surely by the Martingale Convergence Property). I am struggling to prove that is indeed a martingale: it is clear that it is adapted, but I am not sure how to show integrability and the expectation property. Would it also follow that is a martingale?","X_i i^{th} (\Omega, \mathcal{F}) \mathbb{P}_{A} \mathbb{P}_{B} A \mathbb{P}_{A} p=a B \mathbb{P}_{B} p=b a,b \in (0,1) P_{A}(x_1, x_2, \dots, x_n) (x_1, x_2,\dots, x_n) A P_{A}(x_1, x_2, \dots, x_n) = \mathbb{P}_{A}(X_1 = x_1, X_2 = x_2, \dots, X_n = x_n), P_B Z_n = \frac{P_A(X_1, X_2, \dots, X_n)}{P_B(X_1, X_2, \dots, X_n)} \mathbb{P}_{B} \mathcal{F}_n = \sigma(X_k : k \le n) Z_n \frac{1}{Z_n} \mathbb{P}_{A}-","['probability', 'probability-theory', 'measure-theory', 'statistics', 'martingales']"
60,Determine sample size so that it guarantees that the length of the confidence interval is less than $\frac{\sigma}{4}$,Determine sample size so that it guarantees that the length of the confidence interval is less than,\frac{\sigma}{4},"Suposing $\sigma^2$ unkown, find the minimum value for n that gurantees with a probability of 90% that the 95% confidence interval for $\mu$ is of a length no more than $\frac{\sigma}{4}$ Ive been trying to figure this one out using the method to find confidence intervals for sample means, but i get stuck on how to implement the 90% probability i used that when $\sigma^2$ is uknown the confidence interval is given by: $P(\overline{X}-t^{1-\alpha/2}_{n-1}\frac{S}{\sqrt{n}}<\mu<\overline{X}+t^{1-\alpha/2}_{n-1}\frac{S}{\sqrt{n}})=1-\alpha$ and from there i get that the inequality for the length of the interval will be given by: $2t^{0.975}_{n-1}\frac{S}{\sqrt{n}}<\frac{\sigma}{4}$ (using $\alpha =.05$ ) but i dont know how to proceed from here because i need to achieve: $P(2t^{0.975}_{n-1}\frac{S}{\sqrt{n}}<\frac{\sigma}{4})=.9$","Suposing unkown, find the minimum value for n that gurantees with a probability of 90% that the 95% confidence interval for is of a length no more than Ive been trying to figure this one out using the method to find confidence intervals for sample means, but i get stuck on how to implement the 90% probability i used that when is uknown the confidence interval is given by: and from there i get that the inequality for the length of the interval will be given by: (using ) but i dont know how to proceed from here because i need to achieve:",\sigma^2 \mu \frac{\sigma}{4} \sigma^2 P(\overline{X}-t^{1-\alpha/2}_{n-1}\frac{S}{\sqrt{n}}<\mu<\overline{X}+t^{1-\alpha/2}_{n-1}\frac{S}{\sqrt{n}})=1-\alpha 2t^{0.975}_{n-1}\frac{S}{\sqrt{n}}<\frac{\sigma}{4} \alpha =.05 P(2t^{0.975}_{n-1}\frac{S}{\sqrt{n}}<\frac{\sigma}{4})=.9,"['probability', 'statistics', 'statistical-inference']"
61,Distribution of t-statistic with two small sample sizes,Distribution of t-statistic with two small sample sizes,,"Let $X_1,...,X_n\stackrel{i.i.d}\sim N(Î¼_0,Ïƒ_0^2)$ $Y_1,...,Y_m\stackrel{i.i.d}\sim N(Î¼_1,Ïƒ_1^2)$ the $X_i$ 's are independent of the $Y_i$ 's where $Î¼_0,Î¼_1,Ïƒ_0^2,Ïƒ_1^2$ are unknown parameters. Suppose the data collected are summarized as follows: Sample sizes: $n=m=5$ ; Sample means: $\bar{X}_{n}=1.2$ $\bar{Y}_{m}=1.0$ Sample variances: $\hat{\sigma}_1^2=\hat{\sigma}_2^2=0.5$ . Choosing from the following distributions that best approximates the distribution of the $t$ -statistic $T_{n=5,m=5}$ under the null hypothesis $H_0 âˆ¶Î¼_0=Î¼_1$ : Normal distribution with mean $Î¼â‰ 0$ Standard normal distribution $t$ -distribution $F$ -distribution The most ""plausible"" distribution would be the $t$ -distribution. Seems about right? My question is related to the degrees of freedom (assuming my choice of distribution is correct). For the $t$ -distribution, the $t$ -statistic is given by $$ T_n =\frac{\bar{X_{n}}-\bar{Y_{m}}}{\sqrt{\hat{\sigma}_1^2/m+\hat{\sigma}_0^2/n}}$$ The general formula is $df = n_1 + n_2 - 2$ , where $n_1,n_2$ are $n,m$ respectively so $T_n \sim t_{n+m-2, \alpha/2}$ therefore $df=8$ . On the other hand, according to Welch-Satterthwaite's (WS) formula (which calculates an approximation to the effective degrees of freedom), under $H_0$ , $T_n$ is approximately distributed as $t_{40}$ where $df=40$ . Which $df$ value is the correct one? The problem says "" best approximates "" so WS makes sense but I'm not completely sure.","Let the 's are independent of the 's where are unknown parameters. Suppose the data collected are summarized as follows: Sample sizes: ; Sample means: Sample variances: . Choosing from the following distributions that best approximates the distribution of the -statistic under the null hypothesis : Normal distribution with mean Standard normal distribution -distribution -distribution The most ""plausible"" distribution would be the -distribution. Seems about right? My question is related to the degrees of freedom (assuming my choice of distribution is correct). For the -distribution, the -statistic is given by The general formula is , where are respectively so therefore . On the other hand, according to Welch-Satterthwaite's (WS) formula (which calculates an approximation to the effective degrees of freedom), under , is approximately distributed as where . Which value is the correct one? The problem says "" best approximates "" so WS makes sense but I'm not completely sure.","X_1,...,X_n\stackrel{i.i.d}\sim N(Î¼_0,Ïƒ_0^2) Y_1,...,Y_m\stackrel{i.i.d}\sim N(Î¼_1,Ïƒ_1^2) X_i Y_i Î¼_0,Î¼_1,Ïƒ_0^2,Ïƒ_1^2 n=m=5 \bar{X}_{n}=1.2 \bar{Y}_{m}=1.0 \hat{\sigma}_1^2=\hat{\sigma}_2^2=0.5 t T_{n=5,m=5} H_0 âˆ¶Î¼_0=Î¼_1 Î¼â‰ 0 t F t t t  T_n =\frac{\bar{X_{n}}-\bar{Y_{m}}}{\sqrt{\hat{\sigma}_1^2/m+\hat{\sigma}_0^2/n}} df = n_1 + n_2 - 2 n_1,n_2 n,m T_n \sim t_{n+m-2, \alpha/2} df=8 H_0 T_n t_{40} df=40 df","['statistics', 'probability-distributions', 'normal-distribution', 'independence', 'sampling']"
62,Confidence intervals for a population proportion: Why do we use a z-distribution (instead of a t-distribution) even who we estimate $\sigma_{\hat{p}}$,Confidence intervals for a population proportion: Why do we use a z-distribution (instead of a t-distribution) even who we estimate,\sigma_{\hat{p}},"When deriving a confidence interval for a population mean $\mu$ where we do not know the value of the population standard deviation $\sigma$ , we use the sample standard deviation $s$ to estimate $\sigma$ and so our margin of error ends up being related to a $t$ -distrubition: $E = t_c \frac{s}{\sqrt{n}}$ Now, when deriving a confidence interval for an unknown population proportion $p$ , we substitute $\hat{p}$ for $p$ into the formula for the standard deviation of $\hat{p}$ : $\sigma_{\hat{p}}=\sqrt{\frac{p(1-p)}{n}} \rightarrow \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$ However, when we make this substitution, for some reason we still say that the margin of error on our resulting confidence interval depends on a $z$ -distribution!!! $E = z_c \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$ I don't understand why this is. In both cases, we are using some type of sample standard deviation to estimate the population standard deviation. Why in the former case (for a population mean) do we use a $t$ distribution (which I feel is very appropriate), but in the case of a population proportion we still use a $z$ -distribution?? Insight appreciated. Here's me asking (what I view) to be the exact same question but in a different way: Does $\frac{\hat{p}-p}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}}$ ever have a t-distribution? It seems like it should since we are using $\hat{p}$ for $p$ in the formula for $\sigma_{\hat{p}}$ ; this closely resembles how we get to a t distribution for sample means (by substituting in $s$ for $\sigma$ ).","When deriving a confidence interval for a population mean where we do not know the value of the population standard deviation , we use the sample standard deviation to estimate and so our margin of error ends up being related to a -distrubition: Now, when deriving a confidence interval for an unknown population proportion , we substitute for into the formula for the standard deviation of : However, when we make this substitution, for some reason we still say that the margin of error on our resulting confidence interval depends on a -distribution!!! I don't understand why this is. In both cases, we are using some type of sample standard deviation to estimate the population standard deviation. Why in the former case (for a population mean) do we use a distribution (which I feel is very appropriate), but in the case of a population proportion we still use a -distribution?? Insight appreciated. Here's me asking (what I view) to be the exact same question but in a different way: Does ever have a t-distribution? It seems like it should since we are using for in the formula for ; this closely resembles how we get to a t distribution for sample means (by substituting in for ).",\mu \sigma s \sigma t E = t_c \frac{s}{\sqrt{n}} p \hat{p} p \hat{p} \sigma_{\hat{p}}=\sqrt{\frac{p(1-p)}{n}} \rightarrow \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} z E = z_c \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} t z \frac{\hat{p}-p}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \hat{p} p \sigma_{\hat{p}} s \sigma,['statistics']
63,"Putting $n$ balls into $n$ boxes, what is the expected value of the number of balls that are in the right boxes?","Putting  balls into  boxes, what is the expected value of the number of balls that are in the right boxes?",n n,"I have the following probability question, with two different solutions, and I would like to determine which one is right. Here is the problem: $n$ balls are labeled $1$ to $n$ , and $n$ boxes are also labeled $1$ to $n$ . Now put these $n$ balls randomly into these $n$ boxes, such that each box contains only one ball. If a ball is in the box with the same number it has (e.g. ball #3 is in box #3), then we say that this ball is in the right box. Let $X$ be the number of balls that are in the right boxes, what is the expected value of $X$ ? Here are the two solutions I have: Solution 1: The probability that at least $k$ balls are in the right box is $$P(X\ge k)=\frac{\binom{n}{k}(n-k)!}{n!}=\frac{1}{k!},\quad k=0,1,2,\dots,n,$$ so the expected value of $X$ is $$E(X)=\sum_{k=0}^n P(X\ge k)=\sum_{k=0}^n\frac{1}{k!}.$$ Solution 2: For $j=1,\dots,n$ , let $X_j$ be the random variable such that $$X_j=\begin{cases}1, &\text{if ball }\#j\text{ is in the right box},\\ 0, &\text{otherwise},\end{cases}$$ Then we have $X=\sum_{j=1}^n X_j$ . For each $j=1,\dots,n$ , we have $$P(X_j=1)=\frac{(n-1)!}{n!}=\frac{1}{n},$$ therefore, $$E(X)=\sum_{j=1}^n E(X_j)=1.$$ From my instinct, I feel that the first solution is the right one, but I cannot tell what is wrong with the second solution (Maybe I am wrong?). Any suggestions would be greatly appreciated! Edit: Now I've figured out that the second one is right. The problem with the first one is that the relation $P(X\ge k)=\frac{\binom{n}{k}(n-k)!}{n!}$ is incorrect, and thus caused the wrong answer.","I have the following probability question, with two different solutions, and I would like to determine which one is right. Here is the problem: balls are labeled to , and boxes are also labeled to . Now put these balls randomly into these boxes, such that each box contains only one ball. If a ball is in the box with the same number it has (e.g. ball #3 is in box #3), then we say that this ball is in the right box. Let be the number of balls that are in the right boxes, what is the expected value of ? Here are the two solutions I have: Solution 1: The probability that at least balls are in the right box is so the expected value of is Solution 2: For , let be the random variable such that Then we have . For each , we have therefore, From my instinct, I feel that the first solution is the right one, but I cannot tell what is wrong with the second solution (Maybe I am wrong?). Any suggestions would be greatly appreciated! Edit: Now I've figured out that the second one is right. The problem with the first one is that the relation is incorrect, and thus caused the wrong answer.","n 1 n n 1 n n n X X k P(X\ge k)=\frac{\binom{n}{k}(n-k)!}{n!}=\frac{1}{k!},\quad k=0,1,2,\dots,n, X E(X)=\sum_{k=0}^n P(X\ge k)=\sum_{k=0}^n\frac{1}{k!}. j=1,\dots,n X_j X_j=\begin{cases}1, &\text{if ball }\#j\text{ is in the right box},\\
0, &\text{otherwise},\end{cases} X=\sum_{j=1}^n X_j j=1,\dots,n P(X_j=1)=\frac{(n-1)!}{n!}=\frac{1}{n}, E(X)=\sum_{j=1}^n E(X_j)=1. P(X\ge k)=\frac{\binom{n}{k}(n-k)!}{n!}","['probability', 'probability-theory', 'statistics', 'probability-distributions']"
64,Find the probability of the sum of two chips equal to $10$,Find the probability of the sum of two chips equal to,10,"Ten chips numbered $1$ through $10$ are mixed in a bowl. Two chips numbered (X,Y) are drawn from the bowl, successively and without replacement. What is the probability that $X +Y = 10$ ? Answer: $\frac{4}{45}$ My attempt: The possible ways to satisfy the condition would be $(1, 9); (2, 8); (3, 7); (4, 6)$ and the same numbers with the other order. And all the possible ways to drawn two chips from the bowl would be $10\times9$ . So the asked probability is given by: $P=\frac{8}{90}=\frac{4}{45}$ I think that my attempt is reasonable, I just want to know if problems like this could be solve in a more general way, without actually having to know all the ways the condition is satisfied.","Ten chips numbered through are mixed in a bowl. Two chips numbered (X,Y) are drawn from the bowl, successively and without replacement. What is the probability that ? Answer: My attempt: The possible ways to satisfy the condition would be and the same numbers with the other order. And all the possible ways to drawn two chips from the bowl would be . So the asked probability is given by: I think that my attempt is reasonable, I just want to know if problems like this could be solve in a more general way, without actually having to know all the ways the condition is satisfied.","1 10 X +Y = 10 \frac{4}{45} (1, 9); (2, 8); (3, 7); (4, 6) 10\times9 P=\frac{8}{90}=\frac{4}{45}","['probability', 'statistics']"
65,$L^1$ convergence kernel convolutions implies weak convergence of probability measures,convergence kernel convolutions implies weak convergence of probability measures,L^1,"I was reading a paper where they claim the following. Let $\mathscr{M}$ be the space of measures on compact $\mathfrak{X} \subset \mathbb{R}$ . Let $\phi(\cdot - \theta)$ be the normal kernel with location $\theta$ : $$ f_P(x) = \int \phi (x - \theta) dP(\theta)$$ They claim the following: The map $P \mapsto f_{P}$ is one-to-one, onto $\mathscr{F}$ , where $\mathscr{F}=\left\{f_{P}: P \in \mathscr{M}\right\}$ . Further $P_n \rightarrow P_0$ weakly if and only if $\left\|f_{P_n}-f_{P_0}\right\|_1 \rightarrow 0$ . For the part abount injectivity I found solution here: Is ""Convolution operator"" well-defined and injective? Clearly, by the definition of $\mathscr{F}$ it is also onto. So on this part I agree. For the direction $\Rightarrow$ the claim follows upon noticing that the Gaussian kernel in one variable is bounded Lipschitz continuous (see Is the Gaussian density Lipschitz continuous? ). Then an application of Portmanteau's Lemma yields for any fixed $x$ : $$ \int \phi dP_n \rightarrow \int \phi dP_0$$ Then using again the boundedness of the kernels and nonnegativity of our integrals, an application of Dominated Convergence Theorem yields: $\left\|f_{P_n}-f_{P_0}\right\|_1 \rightarrow 0$ . Now for the other direction, I am stuck. I tried to use Scheffe's Lemma to use later the Portmanteau's Lemma with the classical convergence $P_n \rightarrow P_0$ weakly iff $P_n(\theta) \rightarrow P_0 (\theta)$ at all continuity points $\theta$ . Indeed the application of Scheffe's Lemma gives from $\left\|f_{P_n}-f_{P_0}\right\|_1 \rightarrow 0$ that: $$\int \int \phi(x-\theta) dP_n(\theta) dx \rightarrow \int \int \phi(x-\theta) dP_0(\theta) dx$$ Then one could use Fubini's Theorem and the fact that for fixed $\theta$ it holds: $\int \phi(x-\theta) dx = 1$ since it is a Gaussian Kernel. However, it doesn't give the claim eventually. I also tried to argue by contradiction but I did not manage to get anywhere useful. I also tried to use this knowledge: Is this theorem an extension of ScheffÃ© Lemma Maybe you will find it helpful. Q: Do you have any idea on how to tackle this problem? Or any reference that I could consult?","I was reading a paper where they claim the following. Let be the space of measures on compact . Let be the normal kernel with location : They claim the following: The map is one-to-one, onto , where . Further weakly if and only if . For the part abount injectivity I found solution here: Is ""Convolution operator"" well-defined and injective? Clearly, by the definition of it is also onto. So on this part I agree. For the direction the claim follows upon noticing that the Gaussian kernel in one variable is bounded Lipschitz continuous (see Is the Gaussian density Lipschitz continuous? ). Then an application of Portmanteau's Lemma yields for any fixed : Then using again the boundedness of the kernels and nonnegativity of our integrals, an application of Dominated Convergence Theorem yields: . Now for the other direction, I am stuck. I tried to use Scheffe's Lemma to use later the Portmanteau's Lemma with the classical convergence weakly iff at all continuity points . Indeed the application of Scheffe's Lemma gives from that: Then one could use Fubini's Theorem and the fact that for fixed it holds: since it is a Gaussian Kernel. However, it doesn't give the claim eventually. I also tried to argue by contradiction but I did not manage to get anywhere useful. I also tried to use this knowledge: Is this theorem an extension of ScheffÃ© Lemma Maybe you will find it helpful. Q: Do you have any idea on how to tackle this problem? Or any reference that I could consult?",\mathscr{M} \mathfrak{X} \subset \mathbb{R} \phi(\cdot - \theta) \theta  f_P(x) = \int \phi (x - \theta) dP(\theta) P \mapsto f_{P} \mathscr{F} \mathscr{F}=\left\{f_{P}: P \in \mathscr{M}\right\} P_n \rightarrow P_0 \left\|f_{P_n}-f_{P_0}\right\|_1 \rightarrow 0 \mathscr{F} \Rightarrow x  \int \phi dP_n \rightarrow \int \phi dP_0 \left\|f_{P_n}-f_{P_0}\right\|_1 \rightarrow 0 P_n \rightarrow P_0 P_n(\theta) \rightarrow P_0 (\theta) \theta \left\|f_{P_n}-f_{P_0}\right\|_1 \rightarrow 0 \int \int \phi(x-\theta) dP_n(\theta) dx \rightarrow \int \int \phi(x-\theta) dP_0(\theta) dx \theta \int \phi(x-\theta) dx = 1,"['probability', 'probability-theory', 'measure-theory', 'statistics', 'weak-convergence']"
66,If 10 items were chosen at random (with replacement) how many combinations are there to draw exactly x of the n items?,If 10 items were chosen at random (with replacement) how many combinations are there to draw exactly x of the n items?,,"I'm sure this has been asked in this forum before but I don't even know where to begin wording the question to find it. Here's what I'm trying to do: We have n number of items of one color and m number of items of another color. If y items are chosen at random (with replacement) how many combinations are there to draw exactly x of the n items? x < y. I found the formula for combinations with replacement is (ð‘›+ð‘˜âˆ’1 choose ð‘˜) but how does this formula apply if, for example, x = 3 and y = 10? Because 10 items are chosen out of n+m total items, but we only care about the combinations of the 3 items, not of the other 7.","I'm sure this has been asked in this forum before but I don't even know where to begin wording the question to find it. Here's what I'm trying to do: We have n number of items of one color and m number of items of another color. If y items are chosen at random (with replacement) how many combinations are there to draw exactly x of the n items? x < y. I found the formula for combinations with replacement is (ð‘›+ð‘˜âˆ’1 choose ð‘˜) but how does this formula apply if, for example, x = 3 and y = 10? Because 10 items are chosen out of n+m total items, but we only care about the combinations of the 3 items, not of the other 7.",,"['probability', 'statistics', 'permutations', 'combinations']"
67,Rate of convergence with Weak Law of Large Numbers,Rate of convergence with Weak Law of Large Numbers,,"Assume $X_i$ are i.i.d with mean $Î¼$ and the fourth moment of $X_i$ exists. Let $Î´ < 2$ . Show $n^Î´ Pr(| X_n âˆ’ Î¼| >) â†’ 0$ as $n â†’ âˆž$ . I know $Pr(| X_n âˆ’ Î¼| >)â†’ 0$ as $n â†’ âˆž$ by the WLLN, but I have no idea what to do with $Î´$ , since that value doesn't converge. I have thought about using Slutsky's Theorem, but again, $n^Î´$ doesn't really converge to anything, so I don't know what to do with this.","Assume are i.i.d with mean and the fourth moment of exists. Let . Show as . I know as by the WLLN, but I have no idea what to do with , since that value doesn't converge. I have thought about using Slutsky's Theorem, but again, doesn't really converge to anything, so I don't know what to do with this.",X_i Î¼ X_i Î´ < 2 n^Î´ Pr(| X_n âˆ’ Î¼| >) â†’ 0 n â†’ âˆž Pr(| X_n âˆ’ Î¼| >)â†’ 0 n â†’ âˆž Î´ n^Î´,"['statistics', 'law-of-large-numbers']"
68,Polya's urn martingale proof,Polya's urn martingale proof,,"At time $0$ , an urn contains $1$ black ball and $1$ white ball. At each time $1,2,3,...,$ a ball is chosen at random from the urn and is replaced together with a new ball of the same colour. Just after time $n$ , there are therefore $n+2$ balls in the urn, of which $B_n+1$ are black, where $B_n$ is the number of black balls chosen by time $n$ . Let $M_n = \frac{B_n + 1}{(n + 2)}$ , the proportion of black balls in the urn just after time $n$ . Prove that (relative to a natural filtration which you should specify) $M$ is a martingale. There are several ways of solving the problem. One proof starts off by letting $\mathcal{F}_n=\sigma(B_1,...,B_n)$ and then stating $$E[M_n|\mathcal{F}_{n-1}]=P(B_n=B_{n-1})\frac{B_{n-1}+1}{n+2}+P(B_n=B_{n-1}+1)\frac{B_{n-1}+2}{n+2}$$ Intuitively speaking, I agree completely with the equation. It reminds of the basic definition of conditional expectation for discrete rv $X$ given $Y=y$ : $$E(X|Y=y)=\sum_xx\cdot P(x|y)$$ How can one prove the equation rigorously? There are similar problems like De Moivre's martingale ( https://en.wikipedia.org/wiki/Martingale_(probability_theory) ) which make use of the same property of conditional expectation to state: $$E(Y_{n+1}|X_1,...,X_n)=p\left(\frac{q}{p}\right)^{X_n+1}q\left(\frac{q}{p}\right)^{X_n-1}$$ from which it is easy to then show that $(Y_n)_{n\in\mathbb{N}}$ is a martingale. What is the general formula that I am missing which applies to both of these problems?","At time , an urn contains black ball and white ball. At each time a ball is chosen at random from the urn and is replaced together with a new ball of the same colour. Just after time , there are therefore balls in the urn, of which are black, where is the number of black balls chosen by time . Let , the proportion of black balls in the urn just after time . Prove that (relative to a natural filtration which you should specify) is a martingale. There are several ways of solving the problem. One proof starts off by letting and then stating Intuitively speaking, I agree completely with the equation. It reminds of the basic definition of conditional expectation for discrete rv given : How can one prove the equation rigorously? There are similar problems like De Moivre's martingale ( https://en.wikipedia.org/wiki/Martingale_(probability_theory) ) which make use of the same property of conditional expectation to state: from which it is easy to then show that is a martingale. What is the general formula that I am missing which applies to both of these problems?","0 1 1 1,2,3,..., n n+2 B_n+1 B_n n M_n = \frac{B_n + 1}{(n + 2)} n M \mathcal{F}_n=\sigma(B_1,...,B_n) E[M_n|\mathcal{F}_{n-1}]=P(B_n=B_{n-1})\frac{B_{n-1}+1}{n+2}+P(B_n=B_{n-1}+1)\frac{B_{n-1}+2}{n+2} X Y=y E(X|Y=y)=\sum_xx\cdot P(x|y) E(Y_{n+1}|X_1,...,X_n)=p\left(\frac{q}{p}\right)^{X_n+1}q\left(\frac{q}{p}\right)^{X_n-1} (Y_n)_{n\in\mathbb{N}}","['probability-theory', 'measure-theory', 'statistics', 'conditional-probability', 'martingales']"
69,Variations of permutations and Combinations,Variations of permutations and Combinations,,"In my script about combinatorics, until now we have considered and studied the following cases: Permutation without repetition and distinguished objects. Permutation with repetition and distinguished objects. Combination without repetition and distinguished objects. Combination without repetition and distinguished objects. Then, in the end we consider the case of: Permutations without repetition and indistinguishable objects. (Here I'd like to point out, that we considered the case when we want to find the nr. of permutations when we use n elements from a set with n elements, in other words all the elements of the set. The formula, which was given but I was also able to derive on my own, is: $\frac{n!}{n_1!n_2!...n_k!}$ , where n_1 is the nr. of indistinguishable elements of type one in the set,etc etc. Would the formula be the same if we would want to find the nr. of permutations using r ( $r \le n$ ) elements?) Would it make sense to consider case 2-4 for when we have indistinguishable elements? How would the formulas change?","In my script about combinatorics, until now we have considered and studied the following cases: Permutation without repetition and distinguished objects. Permutation with repetition and distinguished objects. Combination without repetition and distinguished objects. Combination without repetition and distinguished objects. Then, in the end we consider the case of: Permutations without repetition and indistinguishable objects. (Here I'd like to point out, that we considered the case when we want to find the nr. of permutations when we use n elements from a set with n elements, in other words all the elements of the set. The formula, which was given but I was also able to derive on my own, is: , where n_1 is the nr. of indistinguishable elements of type one in the set,etc etc. Would the formula be the same if we would want to find the nr. of permutations using r ( ) elements?) Would it make sense to consider case 2-4 for when we have indistinguishable elements? How would the formulas change?",\frac{n!}{n_1!n_2!...n_k!} r \le n,"['probability', 'combinatorics', 'statistics', 'stochastic-calculus']"
70,"Meaning of ""$X$ is a sample from population $P \in \mathcal{P}$"" in Jun Shao's ""Mathematical Statistics""","Meaning of "" is a sample from population "" in Jun Shao's ""Mathematical Statistics""",X P \in \mathcal{P},"I am reading the textbook ""Mathematical Statistics"" 2nd edition written by Jun Shao http://www.mim.ac.mw/books/Mathematical%20statistics%202nd%20edition.pdf . In precise terms, what does the author mean by "" $X$ is a sample from population $P \in \mathcal{P}$ ""? To phrase my question in another way, how is $X$ related to probability measure $P \in \mathcal{P}$ ? Lots of theorems are started with this sentence and no precise definition was found. I need to sort it out before moving on. Here are the earliest related definitions I can find: On page 91-92: In statistical inference and decision theory, the data set is viewed as a realization or observation of a random element defined on a probability space $(\Omega, \mathcal{F}, P)$ related to the random experiment. The probability measure $P$ is called the population. The data set or the random element that produces the data is called a sample from $P$ . A population $P$ is known if and only if $P(A)$ is a known value for every event $A \in \mathcal{F}$ . Later on page 92: In statistical inference and decision theory, the data set, $(x_1, ..., x_n)$ , is viewed as an outcome of the experiment whose sample space is $\Omega = \mathcal{R}^n$ . We usually assume that the $n$ measurements are obtained in n independent trials of the experiment. Hence, we can define a random $n$ -vector $X = (X_1, ..., X_n)$ on $\prod_{i=1}^n(\mathcal{R}, \mathcal{B},P)$ whose realization is $(x_1, ..., x_n)$ . The population in this problem is $P$ (note that the product probability measure is determined by $P$ ) and is at least partially unknown. But later, the author does not seem to be very certain about this. For example, on page 96, there is a sentence saying "" $\Omega$ is usually $\mathcal{R}^k$ . On page 100, the beginning of chapter 2.2 says ""Let us assume now that our data set is a realization of a sample $X$ (a random vector) from an unknown population $P$ on a probability space."" The paragraph on page 92 seems to suggest that $X = (X_1, \cdots, X_n)$ has nothing to do with $P$ : it just seems to be a random variable defined on a measurable space $\prod_{i=1}^n(\mathcal{R}, \mathcal{B})$ . The way the sentence in question constructed seems to suggest that $X$ and $P$ are somehow related: and they should be related as many important theorems (like theorem 2.2 on page 104) all start with this sentence. My guess to make sense of it: Whenever the sentence "" $X$ is a sample from population $P \in \mathcal{P}$ "" is mentioned, assume the following: There is a probability space $(\Omega, \mathcal{F}, \mu)$ and $X = (X_1, \cdots, X_n): \Omega \to \mathcal{R}^n$ is a Borel function (i.e. $\mathcal{R}^n$ valued random variable or $n$ -dimensional random vector). $\mathcal{P}$ is a (given) collection of Borel probability measures on $\mathcal{R}$ . The probability measure $\mu$ on $\mathcal{F}$ is on a different space and is a priori assumed to be unrelated to $\mathcal{P}$ . $X_1, \cdots, X_n$ are independent and identically distributed with common law $P$ and it just happens that $P \in \mathcal{P}$ . Is my guess correct ?","I am reading the textbook ""Mathematical Statistics"" 2nd edition written by Jun Shao http://www.mim.ac.mw/books/Mathematical%20statistics%202nd%20edition.pdf . In precise terms, what does the author mean by "" is a sample from population ""? To phrase my question in another way, how is related to probability measure ? Lots of theorems are started with this sentence and no precise definition was found. I need to sort it out before moving on. Here are the earliest related definitions I can find: On page 91-92: In statistical inference and decision theory, the data set is viewed as a realization or observation of a random element defined on a probability space related to the random experiment. The probability measure is called the population. The data set or the random element that produces the data is called a sample from . A population is known if and only if is a known value for every event . Later on page 92: In statistical inference and decision theory, the data set, , is viewed as an outcome of the experiment whose sample space is . We usually assume that the measurements are obtained in n independent trials of the experiment. Hence, we can define a random -vector on whose realization is . The population in this problem is (note that the product probability measure is determined by ) and is at least partially unknown. But later, the author does not seem to be very certain about this. For example, on page 96, there is a sentence saying "" is usually . On page 100, the beginning of chapter 2.2 says ""Let us assume now that our data set is a realization of a sample (a random vector) from an unknown population on a probability space."" The paragraph on page 92 seems to suggest that has nothing to do with : it just seems to be a random variable defined on a measurable space . The way the sentence in question constructed seems to suggest that and are somehow related: and they should be related as many important theorems (like theorem 2.2 on page 104) all start with this sentence. My guess to make sense of it: Whenever the sentence "" is a sample from population "" is mentioned, assume the following: There is a probability space and is a Borel function (i.e. valued random variable or -dimensional random vector). is a (given) collection of Borel probability measures on . The probability measure on is on a different space and is a priori assumed to be unrelated to . are independent and identically distributed with common law and it just happens that . Is my guess correct ?","X P \in \mathcal{P} X P \in \mathcal{P} (\Omega, \mathcal{F}, P) P P P P(A) A \in \mathcal{F} (x_1, ..., x_n) \Omega = \mathcal{R}^n n n X = (X_1, ..., X_n) \prod_{i=1}^n(\mathcal{R}, \mathcal{B},P) (x_1, ..., x_n) P P \Omega \mathcal{R}^k X P X = (X_1, \cdots, X_n) P \prod_{i=1}^n(\mathcal{R}, \mathcal{B}) X P X P \in \mathcal{P} (\Omega, \mathcal{F}, \mu) X = (X_1, \cdots, X_n): \Omega \to \mathcal{R}^n \mathcal{R}^n n \mathcal{P} \mathcal{R} \mu \mathcal{F} \mathcal{P} X_1, \cdots, X_n P P \in \mathcal{P}","['probability-theory', 'measure-theory', 'statistics', 'statistical-inference']"
71,What is the formal definition of the breakdown value of a statistic,What is the formal definition of the breakdown value of a statistic,,"On page 482 of Statistical Inference (Second Edition) by Casella & Berger, the authors define the breakdown value as follows: Defintion 10.2.2 Let $X_{(1)} < \dots < X_{(n)} $ be an ordered sample of size $n$ , and let $T_n$ be a statistic based on the sample. $T_n$ has a breakdown value $b$ , $0 \leq b \leq 1$ , if, for every $\epsilon > 0$ , $\lim_{X_{(\{(1-b)n\})} \rightarrow \infty} T_n < \infty$ and $\lim_{X_{(\{(1-(b+\epsilon))n\})} \rightarrow \infty} T_n = \infty$ where the round brackets $\{\cdot \}$ indicate rounding to the closest integer. Now on the next page Casella & Berger state that the breakdown value of the mean is $0$ , which is generally accepted, I think. But if I apply the definition, both of the limits would go to infinity, would they not? I would appreciate if anybody could point out my error in understanding or provide a different formal definition. I am aware that the breakdown value is the proportion of the sample that can be changed without changing the statistic (very generally speaking).","On page 482 of Statistical Inference (Second Edition) by Casella & Berger, the authors define the breakdown value as follows: Defintion 10.2.2 Let be an ordered sample of size , and let be a statistic based on the sample. has a breakdown value , , if, for every , and where the round brackets indicate rounding to the closest integer. Now on the next page Casella & Berger state that the breakdown value of the mean is , which is generally accepted, I think. But if I apply the definition, both of the limits would go to infinity, would they not? I would appreciate if anybody could point out my error in understanding or provide a different formal definition. I am aware that the breakdown value is the proportion of the sample that can be changed without changing the statistic (very generally speaking).",X_{(1)} < \dots < X_{(n)}  n T_n T_n b 0 \leq b \leq 1 \epsilon > 0 \lim_{X_{(\{(1-b)n\})} \rightarrow \infty} T_n < \infty \lim_{X_{(\{(1-(b+\epsilon))n\})} \rightarrow \infty} T_n = \infty \{\cdot \} 0,"['probability', 'probability-theory', 'statistics', 'robust-statistics']"
72,standard error of sample mean,standard error of sample mean,,"I am asked to calculate the standard error of the sample mean using bootstrapping for this data set y = c(4.9, 3.3, 2.2, 2.3, 1.6, 2.4, 4.7, 1.4, 1.7, 5.1) The solutions are as follows: set.seed(12345)  nsim = 10^6  ybar.sim = numeric(nsim)  for (i in 1:nsim){   y.sim = sample(y, replace=T)   ybar.sim[i] = mean(y.sim)  }  se.boot = sd(ybar.sim); se.boot  [1] 0.4322378 whereas I thought it would be this way: mean(replicate(1000000, sd(sample(   y, replace=T))/sqrt(length(y)))) which gives [1] 0.4264217 and using the boot lbrary gives: bootmean <- function(d, i) mean(d[i]) bs <- boot(y, bootmean, R=1000000, stype=""i"") print(bs)   Bootstrap Statistics :     original     bias    std. error t1*     2.96 0.00021043   0.4318501 which is similar to the first answer. I do not understand why the first answer is correct given the formula for standard error is the standard deviation divided by the length of the vector. Why is the second answer wrong?","I am asked to calculate the standard error of the sample mean using bootstrapping for this data set y = c(4.9, 3.3, 2.2, 2.3, 1.6, 2.4, 4.7, 1.4, 1.7, 5.1) The solutions are as follows: set.seed(12345)  nsim = 10^6  ybar.sim = numeric(nsim)  for (i in 1:nsim){   y.sim = sample(y, replace=T)   ybar.sim[i] = mean(y.sim)  }  se.boot = sd(ybar.sim); se.boot  [1] 0.4322378 whereas I thought it would be this way: mean(replicate(1000000, sd(sample(   y, replace=T))/sqrt(length(y)))) which gives [1] 0.4264217 and using the boot lbrary gives: bootmean <- function(d, i) mean(d[i]) bs <- boot(y, bootmean, R=1000000, stype=""i"") print(bs)   Bootstrap Statistics :     original     bias    std. error t1*     2.96 0.00021043   0.4318501 which is similar to the first answer. I do not understand why the first answer is correct given the formula for standard error is the standard deviation divided by the length of the vector. Why is the second answer wrong?",,['statistics']
73,How to interpret the (possible) relationship between Jacobian and Covariance matrix,How to interpret the (possible) relationship between Jacobian and Covariance matrix,,"I'm researching a problem which suggests that progress could be achieved if the Jacobian of a vector function might be in some way considered in the manner of a covariance matrix. Specifically, and to take the case in $\mathbb{R}^2$ , let $f_1 := f_1(x,y)$ and $f_2 := f_2(x,y)$ for $x,y \in \mathbb{R}$ and $f_1,f_2: \mathbb{R}^2 \rightarrow \mathbb{R}$ , the quadratic form of the Jacobian is $$ \mathbf{J}^{\intercal}\mathbf{J} =  \left[ \begin{array}{cc} \left(\frac{df_1}{dx}\right)^2+\left(\frac{df_2}{dx}\right)^2 & \frac{df_1}{dx}\frac{df_1}{dy}+\frac{df_2}{dx}\frac{df_2}{dy} \\ \frac{df_1}{dx}\frac{df_1}{dy}+\frac{df_2}{dx}\frac{df_2}{dy} & \left(\frac{df_1}{dy}\right)^2+\left(\frac{df_2}{dy}\right)^2 \end{array} \right]. $$ Suppose we were to compare with the form of covariance matrix $\mathbb{\Sigma}$ expressed as $$ \mathbb{\Sigma} =  \left[ \begin{array}{cc} \sigma_x^2 & \rho \sigma_x \sigma_y \\ \rho\sigma_x \sigma_y & \sigma_y^2 \end{array} \right], $$ it would impose that the correlation coefficient is given by $$ \rho = \frac{\frac{df_1}{dx}\frac{df_1}{dy}+\frac{df_2}{dx}\frac{df_2}{dy}} {\sqrt{\left(\frac{df_1}{dx}\right)^2+\left(\frac{df_2}{dx}\right)^2} \sqrt{\left(\frac{df_1}{dy}\right)^2+\left(\frac{df_2}{dy}\right)^2} }. $$ My questions are therefore: Is $\rho$ admissible as a correlation coefficient in the sense that $|\rho| \leq 1$ ? Are there conditions on $f_1,f_2$ under which (1) is satisfied if not satisfied always? What is the geometric/functional interpretation of the two terms in the denominator?  Clearly they represent norms or 'distances' but is there an intuitive characterisation in terms of $f_1,f_2$ ? Are there any immediate implications for finding the eigenvalues of $\mathbf{J}^{\intercal}\mathbf{J}$ ? What branch of mathematics have I happened upon? Any suggestions for reading?","I'm researching a problem which suggests that progress could be achieved if the Jacobian of a vector function might be in some way considered in the manner of a covariance matrix. Specifically, and to take the case in , let and for and , the quadratic form of the Jacobian is Suppose we were to compare with the form of covariance matrix expressed as it would impose that the correlation coefficient is given by My questions are therefore: Is admissible as a correlation coefficient in the sense that ? Are there conditions on under which (1) is satisfied if not satisfied always? What is the geometric/functional interpretation of the two terms in the denominator?  Clearly they represent norms or 'distances' but is there an intuitive characterisation in terms of ? Are there any immediate implications for finding the eigenvalues of ? What branch of mathematics have I happened upon? Any suggestions for reading?","\mathbb{R}^2 f_1 := f_1(x,y) f_2 := f_2(x,y) x,y \in \mathbb{R} f_1,f_2: \mathbb{R}^2 \rightarrow \mathbb{R} 
\mathbf{J}^{\intercal}\mathbf{J} = 
\left[
\begin{array}{cc}
\left(\frac{df_1}{dx}\right)^2+\left(\frac{df_2}{dx}\right)^2 & \frac{df_1}{dx}\frac{df_1}{dy}+\frac{df_2}{dx}\frac{df_2}{dy} \\
\frac{df_1}{dx}\frac{df_1}{dy}+\frac{df_2}{dx}\frac{df_2}{dy} & \left(\frac{df_1}{dy}\right)^2+\left(\frac{df_2}{dy}\right)^2
\end{array}
\right].
 \mathbb{\Sigma} 
\mathbb{\Sigma} = 
\left[
\begin{array}{cc}
\sigma_x^2 & \rho \sigma_x \sigma_y \\
\rho\sigma_x \sigma_y & \sigma_y^2
\end{array}
\right],
 
\rho = \frac{\frac{df_1}{dx}\frac{df_1}{dy}+\frac{df_2}{dx}\frac{df_2}{dy}}
{\sqrt{\left(\frac{df_1}{dx}\right)^2+\left(\frac{df_2}{dx}\right)^2}
\sqrt{\left(\frac{df_1}{dy}\right)^2+\left(\frac{df_2}{dy}\right)^2}
}.
 \rho |\rho| \leq 1 f_1,f_2 f_1,f_2 \mathbf{J}^{\intercal}\mathbf{J}","['real-analysis', 'linear-algebra', 'statistics', 'derivatives']"
74,Is $X$ (independent variable) considered random in linear regression? Does correlation make sense as an unbiased estimator?,Is  (independent variable) considered random in linear regression? Does correlation make sense as an unbiased estimator?,X,"Basically my question comes from two parts. In simple definitions of LR, we consider X to be a known constant. Thus $$var(Y) = Var(b_0+ b_1x + e) = Var(e)$$ . Great. However, a great deal of linear regression has to do with Cov(X,Y). This is used to estimate our parameters, and it assumes that X is a random variable. How do we distinguish between these two schools of thought? I'm ultimately trying to show that sample correlation between X and Y for simple linear regression is an unbiased estimator of true correlation between X and Y. Does this question even make sense, given that sample correlation of $$Corr(X,\hat Y) = Corr(X, b_0 + b_1 X) = Corr(X, b_1 X)=1$$ always? But even if this doesn't make sense, aren't we still able to make claims in linear regression about the correlation between X and Y because $$E[b_1] = E[\beta_1] \\ b_1 = r\frac{\sigma_y}{\sigma_x}$$","Basically my question comes from two parts. In simple definitions of LR, we consider X to be a known constant. Thus . Great. However, a great deal of linear regression has to do with Cov(X,Y). This is used to estimate our parameters, and it assumes that X is a random variable. How do we distinguish between these two schools of thought? I'm ultimately trying to show that sample correlation between X and Y for simple linear regression is an unbiased estimator of true correlation between X and Y. Does this question even make sense, given that sample correlation of always? But even if this doesn't make sense, aren't we still able to make claims in linear regression about the correlation between X and Y because","var(Y) = Var(b_0+ b_1x + e) = Var(e) Corr(X,\hat Y) = Corr(X, b_0 + b_1 X) = Corr(X, b_1 X)=1 E[b_1] = E[\beta_1] \\ b_1 = r\frac{\sigma_y}{\sigma_x}","['statistics', 'self-learning', 'covariance', 'linear-regression']"
75,How can I increase the value of a multiplier the larger it gets?,How can I increase the value of a multiplier the larger it gets?,,"I'm creating an app that turns fitness data into ""scores"". An example will better describe the problem I'm having... Let's say you do 5 sets of Squats as an example. Below are your sets (weight and reps) 1. 20 kg x 20 reps 2. 30 kg x 15 reps 3. 35 kg x 12 reps 4. 40 kg x 10 reps 5. 45 kg x  8 reps I create a ""score"" for each set by multiplying the weight x reps . In this case 1. 20 kg x 20 reps = 400 2. 30 kg x 15 reps = 450 3. 35 kg x 12 reps = 420 4. 40 kg x 10 reps = 400 5. 45 kg x  8 reps = 360 I want the weight to have more of a ""value"" the larger it gets. Preferably, in this example, I'd want the score of the 5th set to be greater than the score of the 4th set. The best solution I've found so far is to square the weight value like so $weight^2*reps$ 1. 20 kg x 20 reps = 8000 2. 30 kg x 15 reps = 13500 3. 35 kg x 12 reps = 14700 4. 40 kg x 10 reps = 16000 5. 45 kg x  8 reps = 16200 The actual numeric values are arbitrary because I use them to create a percentage score so it doesn't matter that it's in the thousands. It's mostly the difference in between the values that I'm interested in. However this causes too great an increase as the weight value gets higher. The difference between set 1 and set 5 is too drastic. Is there another way I can cause an exponential increase with a flatter curve? Should I instead be using the initial weight value as a base value or something along those lines? Apologies for the long question, my math knowledge is limited and I've been mulling this over for a while but still can't seem to word the problem correctly.","I'm creating an app that turns fitness data into ""scores"". An example will better describe the problem I'm having... Let's say you do 5 sets of Squats as an example. Below are your sets (weight and reps) 1. 20 kg x 20 reps 2. 30 kg x 15 reps 3. 35 kg x 12 reps 4. 40 kg x 10 reps 5. 45 kg x  8 reps I create a ""score"" for each set by multiplying the weight x reps . In this case 1. 20 kg x 20 reps = 400 2. 30 kg x 15 reps = 450 3. 35 kg x 12 reps = 420 4. 40 kg x 10 reps = 400 5. 45 kg x  8 reps = 360 I want the weight to have more of a ""value"" the larger it gets. Preferably, in this example, I'd want the score of the 5th set to be greater than the score of the 4th set. The best solution I've found so far is to square the weight value like so 1. 20 kg x 20 reps = 8000 2. 30 kg x 15 reps = 13500 3. 35 kg x 12 reps = 14700 4. 40 kg x 10 reps = 16000 5. 45 kg x  8 reps = 16200 The actual numeric values are arbitrary because I use them to create a percentage score so it doesn't matter that it's in the thousands. It's mostly the difference in between the values that I'm interested in. However this causes too great an increase as the weight value gets higher. The difference between set 1 and set 5 is too drastic. Is there another way I can cause an exponential increase with a flatter curve? Should I instead be using the initial weight value as a base value or something along those lines? Apologies for the long question, my math knowledge is limited and I've been mulling this over for a while but still can't seem to word the problem correctly.",weight^2*reps,"['statistics', 'exponential-function', 'data-analysis']"
76,What is $\left(\bigcup\limits_{n=1}^\infty E_n\right)^c$?,What is ?,\left(\bigcup\limits_{n=1}^\infty E_n\right)^c,"In an experiment, die is rolled continually until a 6 appears, at which point the experiment stops. What is the sample space of this experiment? The sample space consists of sequence where the last entry must be equal to six and no other entry can be six. Mathematically, we can describe the space as $$ S = \{(6), (x_1,6), (x_1,x_2,6), \dots, (x_1,x_2,\dots,x_i,6) | \text{ where } x_i=\{1,2,3,4,5\} \text{ and } i\geq 1\}$$ Let $E_n$ denote the event that $n$ rolls are necessary to complete the experiment. What points of the sample space are contained in $E_n$ ? $E_n$ contains all sequences in the sample space of length $n$ . Mathematically, we can $E_n$ as $$ E_n=\{(x_1,\dots,x_{n-1},6) | \text{ where } x_i=\{1,2,3,4,5\} \} $$ What is $\left(\bigcup\limits_{n=1}^\infty E_n\right)^c$ ? By De Morgan's Law, $$ \left(\bigcup\limits_{n=1}^\infty E_n\right)^c = \bigcap\limits_{n=1}^\infty E_n^c $$ So here is my question: Is $E_n^c$ is the set of $n$ length sequences where the last entry is anything but 6? I am having a hard time believing that because then those sequences would not belong in the sample space $S$ ?","In an experiment, die is rolled continually until a 6 appears, at which point the experiment stops. What is the sample space of this experiment? The sample space consists of sequence where the last entry must be equal to six and no other entry can be six. Mathematically, we can describe the space as Let denote the event that rolls are necessary to complete the experiment. What points of the sample space are contained in ? contains all sequences in the sample space of length . Mathematically, we can as What is ? By De Morgan's Law, So here is my question: Is is the set of length sequences where the last entry is anything but 6? I am having a hard time believing that because then those sequences would not belong in the sample space ?"," S = \{(6), (x_1,6), (x_1,x_2,6), \dots, (x_1,x_2,\dots,x_i,6) | \text{ where } x_i=\{1,2,3,4,5\} \text{ and } i\geq 1\} E_n n E_n E_n n E_n  E_n=\{(x_1,\dots,x_{n-1},6) | \text{ where } x_i=\{1,2,3,4,5\} \}  \left(\bigcup\limits_{n=1}^\infty E_n\right)^c 
\left(\bigcup\limits_{n=1}^\infty E_n\right)^c = \bigcap\limits_{n=1}^\infty E_n^c
 E_n^c n S",['statistics']
77,How to reduce the mean on a dataset without changing the order of the data,How to reduce the mean on a dataset without changing the order of the data,,"I created a list of anime I have completed and for each anime that I have completed I give it a score based on how good I thought it was. Now over time there are like 200+ anime in that list. But I now feel like my scores are very inflated. I want to change my scores such that it reduces the mean score a bit. Also whatever I do to the score of a single anime must be done to all the scores on the list to keep it fair. So I was wondering if there is a mathematically correct way of changing each score in such a way that for any 2 anime A and B, if A had a higher score than B before the transformation, it must have a higher score than B after the transformation. Some simple transformation like reducing every score by some amount 'x' would not work since the minimum score you can have is 0 and if there is an anime which had score < x before the transformation then after the transformation it will end up having a negative score which is not allowed. I just want some way to shift the whole bell curve to the left a bit properly. There has to be a proper function that can do this right? I am not that good at math so please forgive me if my description of the problem is not technical enough. Edit: Thanks to bobeyt6 for suggesting I should divide every value with a number to reduce the mean. But I still have a question. If I want my mean to go to a specific number. Lets say my mean right now is 7.6 and I want it to be exactly 5 after I do the transformation, how do I pick which number I should divide with?","I created a list of anime I have completed and for each anime that I have completed I give it a score based on how good I thought it was. Now over time there are like 200+ anime in that list. But I now feel like my scores are very inflated. I want to change my scores such that it reduces the mean score a bit. Also whatever I do to the score of a single anime must be done to all the scores on the list to keep it fair. So I was wondering if there is a mathematically correct way of changing each score in such a way that for any 2 anime A and B, if A had a higher score than B before the transformation, it must have a higher score than B after the transformation. Some simple transformation like reducing every score by some amount 'x' would not work since the minimum score you can have is 0 and if there is an anime which had score < x before the transformation then after the transformation it will end up having a negative score which is not allowed. I just want some way to shift the whole bell curve to the left a bit properly. There has to be a proper function that can do this right? I am not that good at math so please forgive me if my description of the problem is not technical enough. Edit: Thanks to bobeyt6 for suggesting I should divide every value with a number to reduce the mean. But I still have a question. If I want my mean to go to a specific number. Lets say my mean right now is 7.6 and I want it to be exactly 5 after I do the transformation, how do I pick which number I should divide with?",,['statistics']
78,Semi-orthogonal tall matrices with zero column-means,Semi-orthogonal tall matrices with zero column-means,,"For a semi-orthogonal $m\times n$ matrix $\mathbf{A}$ with $m\gt n$ , such that $\mathbf A^T\mathbf A=\mathbf I_n$ , can we prove or disprove the proposition that, for some given $m, n$ an $\mathbf A$ exists such that $$\sum_{i=1}^m a_{ij} = 0\qquad\forall j \in [1, n]$$ Further, from an optimization perspective, regardless of whether the above proposition holds or not: Starting from an arbitrary semi-orthogonal matrix $\mathbf A_{m\times n}$ which does not meet zero column mean criteria, how close can we approach the criteria? The other way around could be to start with a matrix with zero column means and optimize $\Vert\mathbf A^T\mathbf A-\mathbf I\Vert_F$ under the constraint. Could a Lagrangian do the trick here? Say, if we start with the orthogonality, we could begin with $\mathbf{QR}$ decomposition of a random matrix and optimize $\Vert\mathbf Q^T\mathbf Q-\mathbf I\Vert_F$ subject to $\sum a_{ij}$ . But how exactly do we proceed for the multidimensional case? Alternatively under a statistical view, assuming $n$ zero-centered distributions each with sample size $m$ , can we somehow optimize an equivalent distance metric? I am not too sure about this intuition. I also looked into possibility of using normalized Hadamard matrices , although they are surely known to exist only when $m=2^k$ , and possibly also exist whenever $m=4k$ . I also found an outdated paper discussing the weights (total number of 1s) in these matrices and they provide upper and lower bounds for many cases, but their definition of weights is not columnar. Hadamard matrices that fit my query must only have $m/2$ weight per column in at least $n$ columns. They are not easy to find in the first place for an arbitrary space and I suspect, even harder to optimize as we have to start with binary elements. Approaching from a combinatorial perspective, I looked into a related concept from coding theory, the so called equidistant constant weight codes but could not glean much from it. Then also, my problem is not necessarily combinatorial in nature although such a solution would be equally acceptable. Kindly pardon any mistakes in text or notations. An easy to understand explanation would be preferred and much appreciated. Thanks.","For a semi-orthogonal matrix with , such that , can we prove or disprove the proposition that, for some given an exists such that Further, from an optimization perspective, regardless of whether the above proposition holds or not: Starting from an arbitrary semi-orthogonal matrix which does not meet zero column mean criteria, how close can we approach the criteria? The other way around could be to start with a matrix with zero column means and optimize under the constraint. Could a Lagrangian do the trick here? Say, if we start with the orthogonality, we could begin with decomposition of a random matrix and optimize subject to . But how exactly do we proceed for the multidimensional case? Alternatively under a statistical view, assuming zero-centered distributions each with sample size , can we somehow optimize an equivalent distance metric? I am not too sure about this intuition. I also looked into possibility of using normalized Hadamard matrices , although they are surely known to exist only when , and possibly also exist whenever . I also found an outdated paper discussing the weights (total number of 1s) in these matrices and they provide upper and lower bounds for many cases, but their definition of weights is not columnar. Hadamard matrices that fit my query must only have weight per column in at least columns. They are not easy to find in the first place for an arbitrary space and I suspect, even harder to optimize as we have to start with binary elements. Approaching from a combinatorial perspective, I looked into a related concept from coding theory, the so called equidistant constant weight codes but could not glean much from it. Then also, my problem is not necessarily combinatorial in nature although such a solution would be equally acceptable. Kindly pardon any mistakes in text or notations. An easy to understand explanation would be preferred and much appreciated. Thanks.","m\times n \mathbf{A} m\gt n \mathbf A^T\mathbf A=\mathbf I_n m, n \mathbf A \sum_{i=1}^m a_{ij} = 0\qquad\forall j \in [1, n] \mathbf A_{m\times n} \Vert\mathbf A^T\mathbf A-\mathbf I\Vert_F \mathbf{QR} \Vert\mathbf Q^T\mathbf Q-\mathbf I\Vert_F \sum a_{ij} n m m=2^k m=4k m/2 n","['linear-algebra', 'statistics', 'optimization', 'coding-theory', 'orthogonal-matrices']"
79,Fisher information of product model,Fisher information of product model,,"Consider the following regular statistical model: $(\mathbb{R}^n, \mathcal{B}(\mathbb{R}^n), \mathbb{P}_{\theta}: \theta \in \mathbb{R}_+ )$ . Assume $\mathbb{P}_{\theta}$ has the density $$\rho(\theta,.) = \frac{1}{\theta} f\left(\frac{x}{\theta}\right)$$ , where $f(x)>0$ and $f'(x)$ exists. I want to show that the fisher- information is given by: $$I(\theta) = \int_{\mathbb{R}}\frac{n}{\theta^2} \frac{(xf'(x)+f(x))^2}{f(x)} dx $$ Therefore I have to compute $$E[U_{\theta}^2]$$ $U_{\theta}$ is the score, which is given by: $$U_{\theta} = \partial_{\theta} ln(\rho(\theta,x))$$ for $x \in \mathbb{R}^n$ Then we have: $$\partial_{\theta}  ln(\prod_{i=1}^n \rho(\theta,x_i)) = \sum_{i=1}^n\partial_{\theta}  \frac{1}{\theta} f\left(\frac{x_i}{\theta}\right) =   \sum_{i=1}^n  \frac{\frac{-1}{\theta^2}f\left(\frac{x_i}{\theta}\right)+ \frac{1}{\theta}f'\left(\frac{x_i}{\theta}\right)\frac{-x_i}{\theta^2}}{\frac{1}{\theta}f\left(\frac{x_i}{\theta}\right)}$$ How can I go on from there. How can I make it independent from $i$ as the solution suggests to compute $$E[U_{\theta}^2]$$","Consider the following regular statistical model: . Assume has the density , where and exists. I want to show that the fisher- information is given by: Therefore I have to compute is the score, which is given by: for Then we have: How can I go on from there. How can I make it independent from as the solution suggests to compute","(\mathbb{R}^n, \mathcal{B}(\mathbb{R}^n), \mathbb{P}_{\theta}: \theta \in \mathbb{R}_+ ) \mathbb{P}_{\theta} \rho(\theta,.) = \frac{1}{\theta} f\left(\frac{x}{\theta}\right) f(x)>0 f'(x) I(\theta) = \int_{\mathbb{R}}\frac{n}{\theta^2} \frac{(xf'(x)+f(x))^2}{f(x)} dx  E[U_{\theta}^2] U_{\theta} U_{\theta} = \partial_{\theta} ln(\rho(\theta,x)) x \in \mathbb{R}^n \partial_{\theta}  ln(\prod_{i=1}^n \rho(\theta,x_i)) = \sum_{i=1}^n\partial_{\theta}  \frac{1}{\theta} f\left(\frac{x_i}{\theta}\right) = 
 \sum_{i=1}^n  \frac{\frac{-1}{\theta^2}f\left(\frac{x_i}{\theta}\right)+ \frac{1}{\theta}f'\left(\frac{x_i}{\theta}\right)\frac{-x_i}{\theta^2}}{\frac{1}{\theta}f\left(\frac{x_i}{\theta}\right)} i E[U_{\theta}^2]","['statistics', 'expected-value', 'density-function', 'fisher-information']"
80,A question about derivation of kalman gain,A question about derivation of kalman gain,,"I read the derivation of Kalman gain. In the derivation, we have: $$(\mathbf{H}\mathbf{P_{n,n-1}})^T = \mathbf{K_n}(\mathbf{H}\mathbf{P_{n,n-1}}\mathbf{H}^T+\mathbf{R_n})$$ where $\mathbf{H}$ is observation matrix, $\mathbf{P_{n,n-1}}$ is the predicted estimate uncertainty, $\mathbf{R_n}$ is the measurement uncertainty, and $\mathbf{K_n}$ is our desired Kalman gain. Then, $$\mathbf{K_n} = (\mathbf{H}\mathbf{P_{n,n-1}})^T(\mathbf{H}\mathbf{P_{n,n-1}}\mathbf{H}^T+\mathbf{R_n})^{-1}$$ My question is why $\mathbf{H}\mathbf{P_{n,n-1}}\mathbf{H}^T+\mathbf{R_n}$ must have inverse?","I read the derivation of Kalman gain. In the derivation, we have: where is observation matrix, is the predicted estimate uncertainty, is the measurement uncertainty, and is our desired Kalman gain. Then, My question is why must have inverse?","(\mathbf{H}\mathbf{P_{n,n-1}})^T = \mathbf{K_n}(\mathbf{H}\mathbf{P_{n,n-1}}\mathbf{H}^T+\mathbf{R_n}) \mathbf{H} \mathbf{P_{n,n-1}} \mathbf{R_n} \mathbf{K_n} \mathbf{K_n} = (\mathbf{H}\mathbf{P_{n,n-1}})^T(\mathbf{H}\mathbf{P_{n,n-1}}\mathbf{H}^T+\mathbf{R_n})^{-1} \mathbf{H}\mathbf{P_{n,n-1}}\mathbf{H}^T+\mathbf{R_n}","['linear-algebra', 'matrices', 'statistics', 'optimal-control', 'kalman-filter']"
81,Current value of option,Current value of option,,"risk free rate= $r$ volatility of stock price= $\sigma$ continuous dividend rate= $q$ $a>0,K>0$ If your stock price S becomes below $K$ at maturity T, the option A pays you $aS_T$ . Otherwise, this option pays you zero. I have to prove that the curret value( $v_0$ ) of this option A is $v_0=aS_0e^{-qT}\phi(-d)$ where $d=\frac{(ln\frac{S_0}{K}+(r-q+\sigma^2/2))}{\sigma\sqrt{T}}$ and $\phi$ is the cumulative distribution function of standard normal distribution. I learned Black-Scholes formula but I can't even figure out how to start. Any suggestions please?","risk free rate= volatility of stock price= continuous dividend rate= If your stock price S becomes below at maturity T, the option A pays you . Otherwise, this option pays you zero. I have to prove that the curret value( ) of this option A is where and is the cumulative distribution function of standard normal distribution. I learned Black-Scholes formula but I can't even figure out how to start. Any suggestions please?","r \sigma q a>0,K>0 K aS_T v_0 v_0=aS_0e^{-qT}\phi(-d) d=\frac{(ln\frac{S_0}{K}+(r-q+\sigma^2/2))}{\sigma\sqrt{T}} \phi","['statistics', 'normal-distribution', 'finance', 'economics']"
82,Bound on $p$-th moment from tail probability,Bound on -th moment from tail probability,p,"In Corollary 2 of this paper , the following result is given: Under some assumptions, there exists a constant $C>0$ such that for all $t \ge 1$ , with probability at least $1-e^{-t}$ , $$ \| \hat{\Sigma} - \Sigma\| \le C \|\Sigma\| \left ( \sqrt{\frac{r}{n}} \lor \frac{r}{n} \lor \sqrt{\frac{t}{n}} \lor \frac{t}{n}\right ). $$ This implies for $p \ge 1$ , $$ E^{1/p} \|\hat{\Sigma} - \Sigma\|^p \lesssim_p \|\Sigma\|  \left ( \sqrt{\frac{r}{n}} \lor \frac{r}{n}\right ). $$ The notation $\lesssim_p $ here means that the left hand side is smaller than the right hand side multiplied by a constant that depends only on $p$ . My question is about how to go from the tail bound in the first line to the second. The proof in the paper states that one can do so by integrating the tail probabilities, but I am not really sure how this follows so easily for all $p$ .","In Corollary 2 of this paper , the following result is given: Under some assumptions, there exists a constant such that for all , with probability at least , This implies for , The notation here means that the left hand side is smaller than the right hand side multiplied by a constant that depends only on . My question is about how to go from the tail bound in the first line to the second. The proof in the paper states that one can do so by integrating the tail probabilities, but I am not really sure how this follows so easily for all .","C>0 t \ge 1 1-e^{-t} 
\| \hat{\Sigma} - \Sigma\| \le C \|\Sigma\| \left ( \sqrt{\frac{r}{n}} \lor \frac{r}{n} \lor \sqrt{\frac{t}{n}} \lor \frac{t}{n}\right ).
 p \ge 1 
E^{1/p} \|\hat{\Sigma} - \Sigma\|^p \lesssim_p \|\Sigma\| 
\left ( \sqrt{\frac{r}{n}} \lor \frac{r}{n}\right ).
 \lesssim_p  p p","['probability', 'probability-theory', 'statistics']"
83,Given the CDF $F(x)=1-e^{-x^2};0â‰¤x<âˆž$. Derive the moment generating function of $X$,Given the CDF . Derive the moment generating function of,F(x)=1-e^{-x^2};0â‰¤x<âˆž X,"I know you use $âˆ«e^{tx}f(x)\,dx$ but I cant figure out the calculation. Any help would be appreciated",I know you use but I cant figure out the calculation. Any help would be appreciated,"âˆ«e^{tx}f(x)\,dx","['probability', 'statistics', 'moment-generating-functions']"
84,"Find the relationship among adjusted 3-pointer (not parameter, but formula like Pythagenport, Pythagenpat), goals scored and goals allowed in football","Find the relationship among adjusted 3-pointer (not parameter, but formula like Pythagenport, Pythagenpat), goals scored and goals allowed in football",,"I was seeking a formula to relate goals scored and goals allowed to points in association football . In association football, three points are awarded to the team winning a match, with no points awarded to the losing team. If the game is drawn, each team receives one point. Firstly, I worked with points percentage â€” points divided by available points, which I set to the number of matches multiplied by adjusted 3-pointer. The general form was: $${\rm points}\,{\rm percentage}= \frac{{\rm goals}\,{\rm scored}^{\mathcal{A}}}{{\rm goals}\,{\rm scored}^{\mathcal{A}}+ {\rm goals}\,{\rm allowed}^{\mathcal{B}}}$$ The league tables' total points percentage is almost sure not an integer . This is Pythagorean expectation (only for wins/losses, not for draws) with two forced different exponents! Football presents a Pythagorean challenge because about a quarter of its matches end in draws (*related to trimean ? no .), worth one point each in the league tables. Because wins are worth three points, the most accurate Pythagorean analyses overestimate most teamsâ€™ points totals, as football analyst Howard Hamilton has found . I call adjusted 3-pointer instead of three because how many average points each team receives are not same. I want to achieve 'reasonable' relationship among adjusted 3-pointer (not parameter, but formula like Pythagenport , Pythagenpat ), goals scored and goals allowed for each team: $${\rm points}_{predicted}= {\rm points}\,{\rm percentage}\cdot{\rm adjusted}\,3{\rm -pointer}$$ If you treat adjusted 3-pointer as parameter : Here is the win estimator (Python Code) # 17 Th12 '12 https://docs.google.com/spreadsheets/d/1XwKs4Do3x95hGTnzgwJWJqCXa4Zqns74bXPwXFFv3IE  import scipy.optimize import numpy as np x=np.array([33,43,28,26,28,30,26,24,15,21,23,28,19,18,19,22,15,19,18,15]) y=np.array([15,24,17,16,21,25,22,21,13,20,23,29,25,24,26,32,24,31,32,30]) z=np.array([36,42,29,24,27,29,23,27,24,23,22,20,25,16,17,15,18, 9,15,10]) N=np.array([17,17,16,16,17,17,17,17,17,17,17,17,17,17,17,16,17,16,17,17]) pred=lambda w: (x**w[0]/(x**w[0]+y**w[1]))*(2+1/(w[2]**2+1))*N w,_=scipy.optimize.leastsq(lambda w: (z-pred(w)),(1,1,.0009332150)) w print(w[0]) print(w[1]) print(2+1/(w[2]**2+1)) Hence, we obtain A=1.5981207542056926 B=1.6055482567109685 adjusted 3-pointer=2.742957368624336 As you can see, I choose ${\rm adjusted}\,3{\rm -pointer}= 2+ 1/(w^{2}+ 1)\in\left ( 2, 3 \right )$ because the average total points of football matches is on this interval. And ${\rm adjusted}\,3{\rm -pointer}\lessapprox 2.75$ is scientific* (noted above). On the other side, $w> {\rm Best}\,w\Rightarrow 2\lessapprox{\rm adjusted}\,3{\rm -pointer}$ leads to many under-performing teams, despite of well RMSE, I still want adjusted 3-pointer as a formula ( function ), but parameter. I have tried to turning that into an ODE (In fact, a PDE.) but unsuccessfully. I need your help to find it.","I was seeking a formula to relate goals scored and goals allowed to points in association football . In association football, three points are awarded to the team winning a match, with no points awarded to the losing team. If the game is drawn, each team receives one point. Firstly, I worked with points percentage â€” points divided by available points, which I set to the number of matches multiplied by adjusted 3-pointer. The general form was: The league tables' total points percentage is almost sure not an integer . This is Pythagorean expectation (only for wins/losses, not for draws) with two forced different exponents! Football presents a Pythagorean challenge because about a quarter of its matches end in draws (*related to trimean ? no .), worth one point each in the league tables. Because wins are worth three points, the most accurate Pythagorean analyses overestimate most teamsâ€™ points totals, as football analyst Howard Hamilton has found . I call adjusted 3-pointer instead of three because how many average points each team receives are not same. I want to achieve 'reasonable' relationship among adjusted 3-pointer (not parameter, but formula like Pythagenport , Pythagenpat ), goals scored and goals allowed for each team: If you treat adjusted 3-pointer as parameter : Here is the win estimator (Python Code) # 17 Th12 '12 https://docs.google.com/spreadsheets/d/1XwKs4Do3x95hGTnzgwJWJqCXa4Zqns74bXPwXFFv3IE  import scipy.optimize import numpy as np x=np.array([33,43,28,26,28,30,26,24,15,21,23,28,19,18,19,22,15,19,18,15]) y=np.array([15,24,17,16,21,25,22,21,13,20,23,29,25,24,26,32,24,31,32,30]) z=np.array([36,42,29,24,27,29,23,27,24,23,22,20,25,16,17,15,18, 9,15,10]) N=np.array([17,17,16,16,17,17,17,17,17,17,17,17,17,17,17,16,17,16,17,17]) pred=lambda w: (x**w[0]/(x**w[0]+y**w[1]))*(2+1/(w[2]**2+1))*N w,_=scipy.optimize.leastsq(lambda w: (z-pred(w)),(1,1,.0009332150)) w print(w[0]) print(w[1]) print(2+1/(w[2]**2+1)) Hence, we obtain A=1.5981207542056926 B=1.6055482567109685 adjusted 3-pointer=2.742957368624336 As you can see, I choose because the average total points of football matches is on this interval. And is scientific* (noted above). On the other side, leads to many under-performing teams, despite of well RMSE, I still want adjusted 3-pointer as a formula ( function ), but parameter. I have tried to turning that into an ODE (In fact, a PDE.) but unsuccessfully. I need your help to find it.","{\rm points}\,{\rm percentage}= \frac{{\rm goals}\,{\rm scored}^{\mathcal{A}}}{{\rm goals}\,{\rm scored}^{\mathcal{A}}+ {\rm goals}\,{\rm allowed}^{\mathcal{B}}} {\rm points}_{predicted}= {\rm points}\,{\rm percentage}\cdot{\rm adjusted}\,3{\rm -pointer} {\rm adjusted}\,3{\rm -pointer}= 2+ 1/(w^{2}+ 1)\in\left ( 2, 3 \right ) {\rm adjusted}\,3{\rm -pointer}\lessapprox 2.75 w> {\rm Best}\,w\Rightarrow 2\lessapprox{\rm adjusted}\,3{\rm -pointer}","['statistics', 'optimization']"
85,"MLE of cdf, consistency and asymptotic confidence interval","MLE of cdf, consistency and asymptotic confidence interval",,"Let $\{X_i\}_{i=1}^{n}$ be i.i.d. random variables with distribution $N(\mu, 1)$ . Let $p = \mathbb{P}[X_i > 0]$ . Find the MLE for $p$ and compute the 95% asymptotic confidence interval. My attempt: I know that $\bar{X}$ is the MLE for $\mu$ in normal distribution, and $$p = \mathbb{P}[X_i > 0] = \mathbb{P}[Z > -\mu] = 1 - \Phi_Z\left(-\mu\right) = 1 - \left[1-\Phi_Z(\mu) \right] = \Phi_Z\left(\mu\right)$$ then, the MLE for $p$ is $\hat{p} = \Phi_Z(\bar{X}).$ The part where you have to calculate the asymptotic confidence interval has me a bit confused since I am working with the estimator of a probability, but I did the following procedure $$\sqrt{n}(\hat{p}-p) \sim N(0, I(p)^{-1})$$ Then, by calculating Fisher's information, I obtained the following: $$I(p) = -\mathbb{E}\left[\dfrac{\partial^2}{\partial p^2}\ \log f(X;p)\ \bigg\vert \ p \right] = -\mathbb{E}\left[\dfrac{\partial^2}{\partial p^2}\ \left( \log\left(\dfrac{1}{\sqrt{2\pi}}\right) - \dfrac{(X-p)^2}{2} \right)\ \bigg\vert \ p \right] = -\mathbb{E}[-1] = 1. $$ Then, the 95% asymptotic confidence interval would be as follows: $$\hat{p} - \dfrac{1.96}{\sqrt{n}}\ \leq \ p \ \leq \ \hat{p} + \dfrac{1.96}{\sqrt{n}}$$ My doubts are as follows: Is my procedure for finding the asymptotic confidence interval correct? I know that $\bar{X}$ is consistent for $\mu$ in a Normal random sample, and $\Phi_Z(\cdot)$ is a real-valued function continuous in $\mathbb{R}$ , so, $\hat{p} = \Phi_Z(\bar{X})$ is consistent. Using this information, is there any other way I can compute the asymptotic confidence interval? I have a doubt about consistency: assuming that the sample of random variables is not normal, is it correct to assume that the estimator would still be consistent? My intuition says yes, however, I get confused when I start demonstrating convergence in probability because apparently I am calculating the probability of a probability $\left(i.e.\ \mathbb{P}[\vert \hat{p} - p\vert > \epsilon] \right) $ . Can you tell me if my intuition is correct that the estimator would be consistent regardless of the sample distribution, and if possible, give me a hint so I can find the necessary convergence?","Let be i.i.d. random variables with distribution . Let . Find the MLE for and compute the 95% asymptotic confidence interval. My attempt: I know that is the MLE for in normal distribution, and then, the MLE for is The part where you have to calculate the asymptotic confidence interval has me a bit confused since I am working with the estimator of a probability, but I did the following procedure Then, by calculating Fisher's information, I obtained the following: Then, the 95% asymptotic confidence interval would be as follows: My doubts are as follows: Is my procedure for finding the asymptotic confidence interval correct? I know that is consistent for in a Normal random sample, and is a real-valued function continuous in , so, is consistent. Using this information, is there any other way I can compute the asymptotic confidence interval? I have a doubt about consistency: assuming that the sample of random variables is not normal, is it correct to assume that the estimator would still be consistent? My intuition says yes, however, I get confused when I start demonstrating convergence in probability because apparently I am calculating the probability of a probability . Can you tell me if my intuition is correct that the estimator would be consistent regardless of the sample distribution, and if possible, give me a hint so I can find the necessary convergence?","\{X_i\}_{i=1}^{n} N(\mu, 1) p = \mathbb{P}[X_i > 0] p \bar{X} \mu p = \mathbb{P}[X_i > 0] = \mathbb{P}[Z > -\mu] = 1 - \Phi_Z\left(-\mu\right) = 1 - \left[1-\Phi_Z(\mu) \right] = \Phi_Z\left(\mu\right) p \hat{p} = \Phi_Z(\bar{X}). \sqrt{n}(\hat{p}-p) \sim N(0, I(p)^{-1}) I(p) = -\mathbb{E}\left[\dfrac{\partial^2}{\partial p^2}\ \log f(X;p)\ \bigg\vert \ p \right] = -\mathbb{E}\left[\dfrac{\partial^2}{\partial p^2}\ \left( \log\left(\dfrac{1}{\sqrt{2\pi}}\right) - \dfrac{(X-p)^2}{2} \right)\ \bigg\vert \ p \right] = -\mathbb{E}[-1] = 1.  \hat{p} - \dfrac{1.96}{\sqrt{n}}\ \leq \ p \ \leq \ \hat{p} + \dfrac{1.96}{\sqrt{n}} \bar{X} \mu \Phi_Z(\cdot) \mathbb{R} \hat{p} = \Phi_Z(\bar{X}) \left(i.e.\ \mathbb{P}[\vert \hat{p} - p\vert > \epsilon] \right) ","['statistics', 'normal-distribution', 'statistical-inference', 'maximum-likelihood', 'parameter-estimation']"
86,Conditional Variance of PDF,Conditional Variance of PDF,,"A random vector $(X,Y)$ has a continuous distribution with a density function $$f(x,y)=\begin{cases}câ‹…x & \text{when }0 â‰¤ x â‰¤ 2, \max\{0,1âˆ’x\} â‰¤ y â‰¤2âˆ’x\\ 0& \text{otherwise}\end{cases}$$ where $c > 0$ is a constant. Find variance of a $Y$ conditioned on $X = 1.5$ , $Var(Y |X = 1.5)$ . I found $c = \frac 67$ with the given integral. Now I want to ask how can I find variance? I found variance as -87/3136. Is it possible ? Here is my attempt Thank you","A random vector has a continuous distribution with a density function where is a constant. Find variance of a conditioned on , . I found with the given integral. Now I want to ask how can I find variance? I found variance as -87/3136. Is it possible ? Here is my attempt Thank you","(X,Y) f(x,y)=\begin{cases}câ‹…x & \text{when }0 â‰¤ x â‰¤ 2, \max\{0,1âˆ’x\} â‰¤ y â‰¤2âˆ’x\\ 0& \text{otherwise}\end{cases} c > 0 Y X = 1.5 Var(Y |X = 1.5) c = \frac 67","['probability', 'statistics']"
87,Probability of $X+Y>Z$ for i.i.d. random variables [closed],Probability of  for i.i.d. random variables [closed],X+Y>Z,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question $X,Y,Z$ are i.i.d. $\operatorname{U}(0,1)$ random variables. What is the probability that $X+Y>Z$ ? Not sure how to solve this problem, does this has anything to do with volume of simplex?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question are i.i.d. random variables. What is the probability that ? Not sure how to solve this problem, does this has anything to do with volume of simplex?","X,Y,Z \operatorname{U}(0,1) X+Y>Z","['calculus', 'probability', 'statistics', 'problem-solving']"
88,"Mathematical notation in a machine learning problem, majority rule","Mathematical notation in a machine learning problem, majority rule",,"(I apologise that the title may be a bit confusing and I don't know if this is the right community to ask my question.) This is a mathematical notation problem in the field of machine learning. A little context: In my machine learning problem, I want to classify an individual based on the samples I have of each individual (i.e. each person has multiple samples). Once I have made the prediction, I get the predicted class for each of the samples, but what I want is a global classification of the individual to one of the two classes. What I do is to count the number of samples that have been assigned to each class, and depending on this establishing a threshold, k, where an individual will be classified as Class 1 if the number of samples classified as Class 1 exceeds that threshold. My problem is that I don't have much knowledge of formal mathematical writing, and I would like to translate the above into mathematical notation. I have written the following but I don't know if it is correct. $$ Y=1, \sum_{i=0}^{n}\hat{y_{i}}\Leftrightarrow \hat{y_{i}}=1 > k\sum_{i=0}^{n}\hat{y_{i}} $$ where $\hat{y_{i}}$ , denotes each individual element of the vector with the predictions for each sample. In summary, what I want to write is: The individual will be assigned to class 1 if, the number of samples classified as '1' is greater than k times the total number of samples of the individual.","(I apologise that the title may be a bit confusing and I don't know if this is the right community to ask my question.) This is a mathematical notation problem in the field of machine learning. A little context: In my machine learning problem, I want to classify an individual based on the samples I have of each individual (i.e. each person has multiple samples). Once I have made the prediction, I get the predicted class for each of the samples, but what I want is a global classification of the individual to one of the two classes. What I do is to count the number of samples that have been assigned to each class, and depending on this establishing a threshold, k, where an individual will be classified as Class 1 if the number of samples classified as Class 1 exceeds that threshold. My problem is that I don't have much knowledge of formal mathematical writing, and I would like to translate the above into mathematical notation. I have written the following but I don't know if it is correct. where , denotes each individual element of the vector with the predictions for each sample. In summary, what I want to write is: The individual will be assigned to class 1 if, the number of samples classified as '1' is greater than k times the total number of samples of the individual.","
Y=1, \sum_{i=0}^{n}\hat{y_{i}}\Leftrightarrow \hat{y_{i}}=1 > k\sum_{i=0}^{n}\hat{y_{i}}
 \hat{y_{i}}","['statistics', 'notation', 'machine-learning']"
89,"Given a group number and an potentially infinite number of groups, how would you calculate the predicted total number of groups?","Given a group number and an potentially infinite number of groups, how would you calculate the predicted total number of groups?",,"Sorry for the confusing title, Iâ€™ll elaborate with an example. You have been assigned group #4, and you are curious how many groups in total there are. Assuming groups are numbered sequentially starting at 1 and group assignment is random, you can assume there are at least 4 groups. So far, I know that the most probable number of groups is your group number. You are more likely to be in group 4 if there are 4 groups, than if there were 1000. There is some kind of decay model where the larger the guess, the less probable it is, but I canâ€™t figure it out. Whatever the probability model is, the area under it should equal 1.","Sorry for the confusing title, Iâ€™ll elaborate with an example. You have been assigned group #4, and you are curious how many groups in total there are. Assuming groups are numbered sequentially starting at 1 and group assignment is random, you can assume there are at least 4 groups. So far, I know that the most probable number of groups is your group number. You are more likely to be in group 4 if there are 4 groups, than if there were 1000. There is some kind of decay model where the larger the guess, the less probable it is, but I canâ€™t figure it out. Whatever the probability model is, the area under it should equal 1.",,"['probability', 'statistics', 'probability-distributions', 'word-problem']"
90,Missing Values in a Dataset for Multiple Regression,Missing Values in a Dataset for Multiple Regression,,"I've seen countless projects and tutorials on Kaggle where authors use calculated mean values to replace missing values in a column. However, I am now reading the Multiple Regression. A Primer. book by Paul D. Allison in which the author writes this: [...] Even worse than pairwise deletion is replacement with means. In this method, the missing values are replaced with the mean value of the variable for those individuals without the missing data. So, I am curious is replacement with means a legitimate way to deal with missing values or are there more common and preferrable ways to do it?","I've seen countless projects and tutorials on Kaggle where authors use calculated mean values to replace missing values in a column. However, I am now reading the Multiple Regression. A Primer. book by Paul D. Allison in which the author writes this: [...] Even worse than pairwise deletion is replacement with means. In this method, the missing values are replaced with the mean value of the variable for those individuals without the missing data. So, I am curious is replacement with means a legitimate way to deal with missing values or are there more common and preferrable ways to do it?",,"['statistics', 'linear-regression']"
91,Expectancy of 10 mutually independent random variables and conditional probability,Expectancy of 10 mutually independent random variables and conditional probability,,"I've been given the following question, which has 2 parts: Consider 10 (mutually) independent experiments (each is a random variable) numbered 1 through 10. The probability that the i-th experiment will be over within an hour from the moment it began is $\frac{i}{10}, 1\leq i\leq 10$ 1st part: (Assuming all the experiments are started at the same time,) what is the expected number of experiments that will be over within an hour? The solution just says 1 (without further explanation) but I disagree. At least one (the 10th experiment) will be over within an hour with probability 1, and the rest also have non-zero probability to end within the same time, so the expectancy has to be at least greater than 1. My way of solving this was to define each experiment as a random variable $x_i$ such that $$ x_i= \begin{cases} \displaystyle 1,  & \text{w.p. $\frac{i}{10}$ } \\ 0, & \text{w.p. $\frac{10-i}{10}$ } \end{cases} $$ each with expectancy $E[x_i]=\frac{i}{10}$ , and then define $$Y=\sum_{i=1}^{10} x_i$$ Thus, the expectancy would be $$ E[Y]=E[\sum_{i=1}^{10} x_i]=\sum_{i=1}^{10}E[x_i]=\sum_{i=1}^{10}\frac{i}{10}=5.5 $$ By linearity of expectation. To verify my solution, I tried calculating $P(y)$ for each $y, 0\leq y\leq 10$ and then finding out the expectancy using its definition for discrete random variables. I've got the values for $y=0, 1, 9, 10$ but the rest were too difficult to generalize. The 2nd part is as follows (it's unrelated to the 1st one, just to the main question): What's the probability that the 5th experiment was over (within an hour), given a randomly selected experiment is over? It wasn't quite clear in the question, but I'm assuming that they meant all the experiments had started, and after an hour we picked one randomly and it was over, what's the probability that it's the 5th one? I calculated the probability for a randomly selected experiment to be over by multipling the probability for each experiment to be over with the probability for choosing it (using the law of total probability). Each experiment is equally likely to be choosen, so $$ P(B)=\sum_{i=1}^{10}\frac{i}{10}\frac{1}{10}=0.55 $$ Then, if $A_5$ is the event that the 5th experiment was over, $$ P(A_5 | B)=\frac{P(B|A_5)P(A_5)}{P(B)}=\frac{1\cdot \frac{1}{10}}{0.55}=0.182 $$ But in the solution they defined $A_5$ as the event that the 5th experiment was choosen (so in general $P(A_i)=\frac{1}{10}$ for every $i$ ) and said $$ P(A_5 | B)=\frac{P(B|A_5)P(A_5)}{P(B)}=\frac{\frac{5}{10}\cdot \frac{1}{10}}{0.55}=0.091 $$ But this doesn't make much sense to me. Did I interrupt the question differently than I should have? Edit: Added the second part which wasn't included when I posted the question at first.","I've been given the following question, which has 2 parts: Consider 10 (mutually) independent experiments (each is a random variable) numbered 1 through 10. The probability that the i-th experiment will be over within an hour from the moment it began is 1st part: (Assuming all the experiments are started at the same time,) what is the expected number of experiments that will be over within an hour? The solution just says 1 (without further explanation) but I disagree. At least one (the 10th experiment) will be over within an hour with probability 1, and the rest also have non-zero probability to end within the same time, so the expectancy has to be at least greater than 1. My way of solving this was to define each experiment as a random variable such that each with expectancy , and then define Thus, the expectancy would be By linearity of expectation. To verify my solution, I tried calculating for each and then finding out the expectancy using its definition for discrete random variables. I've got the values for but the rest were too difficult to generalize. The 2nd part is as follows (it's unrelated to the 1st one, just to the main question): What's the probability that the 5th experiment was over (within an hour), given a randomly selected experiment is over? It wasn't quite clear in the question, but I'm assuming that they meant all the experiments had started, and after an hour we picked one randomly and it was over, what's the probability that it's the 5th one? I calculated the probability for a randomly selected experiment to be over by multipling the probability for each experiment to be over with the probability for choosing it (using the law of total probability). Each experiment is equally likely to be choosen, so Then, if is the event that the 5th experiment was over, But in the solution they defined as the event that the 5th experiment was choosen (so in general for every ) and said But this doesn't make much sense to me. Did I interrupt the question differently than I should have? Edit: Added the second part which wasn't included when I posted the question at first.","\frac{i}{10}, 1\leq i\leq 10 x_i 
x_i=
\begin{cases}
\displaystyle 1,  & \text{w.p. \frac{i}{10} } \\
0, & \text{w.p. \frac{10-i}{10} }
\end{cases}
 E[x_i]=\frac{i}{10} Y=\sum_{i=1}^{10} x_i 
E[Y]=E[\sum_{i=1}^{10} x_i]=\sum_{i=1}^{10}E[x_i]=\sum_{i=1}^{10}\frac{i}{10}=5.5
 P(y) y, 0\leq y\leq 10 y=0, 1, 9, 10 
P(B)=\sum_{i=1}^{10}\frac{i}{10}\frac{1}{10}=0.55
 A_5 
P(A_5 | B)=\frac{P(B|A_5)P(A_5)}{P(B)}=\frac{1\cdot \frac{1}{10}}{0.55}=0.182
 A_5 P(A_i)=\frac{1}{10} i 
P(A_5 | B)=\frac{P(B|A_5)P(A_5)}{P(B)}=\frac{\frac{5}{10}\cdot \frac{1}{10}}{0.55}=0.091
","['probability', 'statistics', 'random-variables', 'expected-value', 'conditional-probability']"
92,MCMC sampling of $\beta_0+\beta_1x_i$ separately,MCMC sampling of  separately,\beta_0+\beta_1x_i,"I'm trying to sample $\beta_0$ and $\beta_1$ from a set of data modelled by a Bernoulli distribution. \begin{equation} p(y)=Î¸^{y}(1âˆ’Î¸)^{1âˆ’y} \end{equation} Where the relationship between $y$ and my primary $x_i$ is modelled by a logistic regression. \begin{equation} \nu = log(\frac{\theta}{1-\theta}) = \beta_0 + \beta_1x_i \ \end{equation} And my prior is: \begin{equation} \pi(\beta_0,\beta_1) \propto 1 \end{equation} I've found my posterior $\pi(\beta_0,\beta_1|y)$ : \begin{equation} \pi(\beta_0,\beta_1|y) = f(y|\beta_0,\beta_1)\pi(\beta_0,\beta_1) \\ \pi(\beta_0,\beta_1|y) = (\frac{e^{\beta_0+\beta_1x_i}}{1+e^{\beta_0+\beta_1x_i}})^{\sum_{i=1}^ny_i}(\frac{1}{1+e^{\beta_0+\beta_1x_i}})^{n-\sum_{i=1}^ny_i} \end{equation} So first I'm trying to sample $\beta_0$ and $\beta_1$ separately, so sampling from $\pi(\beta_0|y,\beta_1)$ then from $\pi(\beta_1|y,\beta_0)$ . But since $\pi(\beta_0,\beta_1) \propto 1$ , would those posteriors be the same thing and I'd be sampling from the same posterior twice? Or am I missing something? Would I just sub in $\nu$ instead of $\beta_0 + \beta_1x_i$ in the posterior written above and sample from that? Any help would be greatly appreciated.","I'm trying to sample and from a set of data modelled by a Bernoulli distribution. Where the relationship between and my primary is modelled by a logistic regression. And my prior is: I've found my posterior : So first I'm trying to sample and separately, so sampling from then from . But since , would those posteriors be the same thing and I'd be sampling from the same posterior twice? Or am I missing something? Would I just sub in instead of in the posterior written above and sample from that? Any help would be greatly appreciated.","\beta_0 \beta_1 \begin{equation}
p(y)=Î¸^{y}(1âˆ’Î¸)^{1âˆ’y}
\end{equation} y x_i \begin{equation}
\nu = log(\frac{\theta}{1-\theta}) = \beta_0 + \beta_1x_i \
\end{equation} \begin{equation}
\pi(\beta_0,\beta_1) \propto 1
\end{equation} \pi(\beta_0,\beta_1|y) \begin{equation}
\pi(\beta_0,\beta_1|y) = f(y|\beta_0,\beta_1)\pi(\beta_0,\beta_1) \\
\pi(\beta_0,\beta_1|y) = (\frac{e^{\beta_0+\beta_1x_i}}{1+e^{\beta_0+\beta_1x_i}})^{\sum_{i=1}^ny_i}(\frac{1}{1+e^{\beta_0+\beta_1x_i}})^{n-\sum_{i=1}^ny_i}
\end{equation} \beta_0 \beta_1 \pi(\beta_0|y,\beta_1) \pi(\beta_1|y,\beta_0) \pi(\beta_0,\beta_1) \propto 1 \nu \beta_0 + \beta_1x_i","['statistics', 'bayesian', 'sampling', 'bernoulli-distribution']"
93,Bayes theorem and probability of a man [duplicate],Bayes theorem and probability of a man [duplicate],,"This question already has answers here : A man who lies a fourth of the time throws a die and says it is a six. What is the probability it is actually a six? (2 answers) Closed 2 years ago . A man is known to speak truth 3 out of 4 times he throws a die and reports that it is a six. What is the probability that it's actually a six. So I applied Bayes theorem and found the answer as 3/8. And I felt weird because of my common sense, If a man says truth 75% of the time, shouldn't the six on the dice probability be 3/4 as he said it's a six. I am really confused. Am I missing something really obvious here? Or is there a flaw in my thought process please help me","This question already has answers here : A man who lies a fourth of the time throws a die and says it is a six. What is the probability it is actually a six? (2 answers) Closed 2 years ago . A man is known to speak truth 3 out of 4 times he throws a die and reports that it is a six. What is the probability that it's actually a six. So I applied Bayes theorem and found the answer as 3/8. And I felt weird because of my common sense, If a man says truth 75% of the time, shouldn't the six on the dice probability be 3/4 as he said it's a six. I am really confused. Am I missing something really obvious here? Or is there a flaw in my thought process please help me",,"['probability', 'statistics', 'bayes-theorem']"
94,Closure of balls in Reproducing Kernel Hilbert Space (RKHS),Closure of balls in Reproducing Kernel Hilbert Space (RKHS),,"Let $X \subset \mathbb{R}^m$ be compact, and $k: X\times X \rightarrow \mathbb{R}$ be a universal kernel function, in the sense that the corresponding RKHS $\mathcal{H}_k$ is dense in $C(X)$ under the uniform metric $\| \cdot \|_{\infty}$ . Denote by $\| \cdot \|_{\mathcal{H}_k}$ the RKHS-norm. The literature in statistical learning tends to argue for the use of kernel methods based on the denseness of $\mathcal{H}_k$ in $(C(X),\|\cdot\|_{\infty})$ . However, most of times the rigorous analysis in statistical learning theory is restricted to a subset of $\mathcal{H}_k$ , say $$ B_M := \{ h\in \mathcal{H}_k : \|h\|_{\mathcal{H}_k} \leq M \} $$ for some constant $M>0$ . I am wondering how well $B_M$ can approximate $C(X)$ . For that, I would like to know more about the closure (with respect to $\|\cdot\|_{\infty}$ ) of $B_M$ . Is there a clean form of the closure? Here is what I tried: By Mercer's theorem, we have $$ k(x,x') = \sum_{j=1}^{\infty} \lambda_j \phi_j(x) \phi_j(x'). $$ Let $\varphi_j(x) = \sqrt{\lambda_j} \phi_j(x)$ , and then $(\varphi_j)$ is an orthonormal basis of $\mathcal{H}_k$ . We rewrite $$ B_M = \{ x \mapsto \langle\beta, \varphi(x) \rangle_{\ell_2} : \|\beta\|_{\ell_2} \leq M \}. $$ But I don't know how to proceed further.","Let be compact, and be a universal kernel function, in the sense that the corresponding RKHS is dense in under the uniform metric . Denote by the RKHS-norm. The literature in statistical learning tends to argue for the use of kernel methods based on the denseness of in . However, most of times the rigorous analysis in statistical learning theory is restricted to a subset of , say for some constant . I am wondering how well can approximate . For that, I would like to know more about the closure (with respect to ) of . Is there a clean form of the closure? Here is what I tried: By Mercer's theorem, we have Let , and then is an orthonormal basis of . We rewrite But I don't know how to proceed further.","X \subset \mathbb{R}^m k: X\times X \rightarrow \mathbb{R} \mathcal{H}_k C(X) \| \cdot \|_{\infty} \| \cdot \|_{\mathcal{H}_k} \mathcal{H}_k (C(X),\|\cdot\|_{\infty}) \mathcal{H}_k 
B_M := \{ h\in \mathcal{H}_k : \|h\|_{\mathcal{H}_k} \leq M \}
 M>0 B_M C(X) \|\cdot\|_{\infty} B_M 
k(x,x') = \sum_{j=1}^{\infty} \lambda_j \phi_j(x) \phi_j(x').
 \varphi_j(x) = \sqrt{\lambda_j} \phi_j(x) (\varphi_j) \mathcal{H}_k 
B_M = \{ x \mapsto \langle\beta, \varphi(x) \rangle_{\ell_2} : \|\beta\|_{\ell_2} \leq M \}.
","['functional-analysis', 'statistics', 'machine-learning', 'reproducing-kernel-hilbert-spaces']"
95,"efficiency of estimator, $\overline{\frac{1}{X^2}}$ vs $\frac{1}{\overline{X}^2}$ vs $\frac{1}{\overline{X^2}}$","efficiency of estimator,  vs  vs",\overline{\frac{1}{X^2}} \frac{1}{\overline{X}^2} \frac{1}{\overline{X^2}},"I was studying point estimator, and I tried to compare the variances of the estimators to find out which one is more efficient. (Hogg, Tanis ""Probability and Statistical Inference"" Ch.6) It was a regression model with $Y_i=\theta x_i+e_i$ ( $x_i$ is a constant, and $e_i$ is a random variable with $e_i$ ~ $N(0,\sigma^2)$ ) The variances of the estimators $\hat \theta$ are $\left(\frac{\sigma^2}{\sum_{i=1}^n x_i^2}\right)=\left(\frac{\sigma^2}{n \overline{X^2}}\right)$ $\left(\frac{n\sigma^2}{(\sum_{i=1}^n x_i)^2}\right)=\left(\frac{\sigma^2}{n \bar X^2}\right)$ $\left(\frac{\sigma^2}{n^2}\sum_{i=1}^n\frac{1}{x_i^2}\right)=\left(\frac{\sigma^2}{n} \overline {\frac{1}{X^2}}\right)$ I could easily figure out that var of 1)<var of 2) from $\sum(X_i- \bar X)^2=\sum X_i^2-n\bar X^2$ The tricky part is 3). How can I compare $\overline{\frac{1}{X^2}}$ with the others? I could not find a similar question. If there is, please let me know.","I was studying point estimator, and I tried to compare the variances of the estimators to find out which one is more efficient. (Hogg, Tanis ""Probability and Statistical Inference"" Ch.6) It was a regression model with ( is a constant, and is a random variable with ~ ) The variances of the estimators are I could easily figure out that var of 1)<var of 2) from The tricky part is 3). How can I compare with the others? I could not find a similar question. If there is, please let me know.","Y_i=\theta x_i+e_i x_i e_i e_i N(0,\sigma^2) \hat \theta \left(\frac{\sigma^2}{\sum_{i=1}^n x_i^2}\right)=\left(\frac{\sigma^2}{n \overline{X^2}}\right) \left(\frac{n\sigma^2}{(\sum_{i=1}^n x_i)^2}\right)=\left(\frac{\sigma^2}{n \bar X^2}\right) \left(\frac{\sigma^2}{n^2}\sum_{i=1}^n\frac{1}{x_i^2}\right)=\left(\frac{\sigma^2}{n} \overline {\frac{1}{X^2}}\right) \sum(X_i- \bar X)^2=\sum X_i^2-n\bar X^2 \overline{\frac{1}{X^2}}","['statistics', 'self-learning', 'linear-regression', 'parameter-estimation']"
96,Variance-stabilizing transformation on a simple linear regression,Variance-stabilizing transformation on a simple linear regression,,"I am currently working with variance-stabilizer method and readed something about it from my textbook. I want to understand it better so I would like to consider a case where I for instance have a simple linear regression, let's say I have a model with response $y$ , intercept and explanatory variable $x$ , that is, $$y_k=\beta_0+\beta_1x_k+\epsilon_k, \;\;\;\;\;\;\;\; k=1,...,n.$$ with the residual variance proportional to the square of $x_k$ : $V(\epsilon_k)=\sigma^2x^2_k$ . Then I would take the following as data transformation: $$\tilde{y}_k:=\frac{y_k}{x_k} \text{ and } \tilde{x_k}:=\frac{1}{x_k}, \;\;\;\;\;\;\;\; k=1,...,n.$$ Here is what I don't understand. The first thing is: Can I say something about the above is indeed a variance-stabilizing transformation? Second: Can I say something about the parameters from the models with original or transformed data related to each other? I've found examples of variance-stabilizing transformation on wikipedia where they use integrals and so on, but I cannot se how it could be applied in my example. I hope anyone can help me to better understand the variance-stabilizing transformation.","I am currently working with variance-stabilizer method and readed something about it from my textbook. I want to understand it better so I would like to consider a case where I for instance have a simple linear regression, let's say I have a model with response , intercept and explanatory variable , that is, with the residual variance proportional to the square of : . Then I would take the following as data transformation: Here is what I don't understand. The first thing is: Can I say something about the above is indeed a variance-stabilizing transformation? Second: Can I say something about the parameters from the models with original or transformed data related to each other? I've found examples of variance-stabilizing transformation on wikipedia where they use integrals and so on, but I cannot se how it could be applied in my example. I hope anyone can help me to better understand the variance-stabilizing transformation.","y x y_k=\beta_0+\beta_1x_k+\epsilon_k, \;\;\;\;\;\;\;\; k=1,...,n. x_k V(\epsilon_k)=\sigma^2x^2_k \tilde{y}_k:=\frac{y_k}{x_k} \text{ and } \tilde{x_k}:=\frac{1}{x_k}, \;\;\;\;\;\;\;\; k=1,...,n.","['statistics', 'transformation', 'variance', 'regression-analysis']"
97,Time series: ARMA characteristic polynomials have common roots,Time series: ARMA characteristic polynomials have common roots,,"I have a question regarding the idea that if the roots of the characteristic polynomials of a time series (say some ARMA process) lie outside the unit circle, then the series will be invertible/causal (depending on which characteristic polynomial we're talking about). In addition to such roots lying outside the unit circle, the two characteristic polynomials must share no common roots. On the problems such a violation could cause, I found the following in Brockwell and Davis (pg 86 (1991). Time series: theory and methods. SpringerVerlag ) so with respect to point (a), say I had some ARMA(2,2) process which could be factorised in terms of the backshift operator as $$(1-\alpha_1B)(1-\beta_1B)X_t=(1-\alpha_1B)(1-\alpha_2B)Z_t$$ and all the roots of the characteristic polynomials lay outside the unit circle but we had the obvious common root $(1-\alpha_1B)$ . What point (a) says, is that I can simply cancel such root to leave a causal and invertible ARMA(1,1) process? $$ (1-\beta_1B)X_t=(1-\alpha_2B)Z_t $$","I have a question regarding the idea that if the roots of the characteristic polynomials of a time series (say some ARMA process) lie outside the unit circle, then the series will be invertible/causal (depending on which characteristic polynomial we're talking about). In addition to such roots lying outside the unit circle, the two characteristic polynomials must share no common roots. On the problems such a violation could cause, I found the following in Brockwell and Davis (pg 86 (1991). Time series: theory and methods. SpringerVerlag ) so with respect to point (a), say I had some ARMA(2,2) process which could be factorised in terms of the backshift operator as and all the roots of the characteristic polynomials lay outside the unit circle but we had the obvious common root . What point (a) says, is that I can simply cancel such root to leave a causal and invertible ARMA(1,1) process?","(1-\alpha_1B)(1-\beta_1B)X_t=(1-\alpha_1B)(1-\alpha_2B)Z_t (1-\alpha_1B) 
(1-\beta_1B)X_t=(1-\alpha_2B)Z_t
","['statistics', 'stochastic-processes', 'estimation', 'time-series', 'causality']"
98,FIFO (M/D/1/N queue) Overflow probability,FIFO (M/D/1/N queue) Overflow probability,,"I'm an engineer, trying to figure out the optimal FIFO depth for a particular application. The events I usually work with follow a Poisson distribution, and a fixed readout rate (thus the M/D/1/N naming). In an example, events arrive with an expected rate of 1MHz, and they are to be read out with a fixed rate of 1Mevents/s. If the incoming events had a fixed timing distribution (1 event every 1us) there would be no need for event storage at all, but the Poissonian nature of the process dictates that it's possible to receive multiple events in any 1-us interval: it is necessary to store (buffer) these excess events (where the local event rate exceeds 1MHz) for later readout. In this example, data is lost when the FIFO is full and I have a new event that needs to be written. Until now, I've designed FIFOs by using simulations, and adjusting their size according to the data loss that I experience. But I wanted to be able to make educated guesses to the appropriate FIFO size beforehand. I've found the following resources online, which however turned out to be of little help to me, given my poor knowledge of the topic: https://en.wikipedia.org/wiki/M/D/1_queue#Stationary_distribution https://www.physicsforums.com/threads/m-d-1-n-queueing-theory-help.600325/ Most often posts online focus on average waiting time or busy period, which I don't think apply to my problem. What I thought would work The probability of event loss can be described as (1) the probability that the FIFO is full, and (2) that I receive another event before the readout. $P_{overflow} = P_{full} * P_{1\,event\,in\,\mu}$ where $\mu$ is the readout time (1us) Now, $P_{1 event in \mu}$ is trivial, and given by the PDF of the Poisson distribution. $P_{full}$ ... is another matter. I think it can be evaluated as: $P_{full} = P_{full\,-\,1} * P_{1\,event\,in\,\mu}$ . And, thus, recursively: $P_{full} = \prod_i^{FIFO\,Depth} P_{1\,event\,in\,\mu} * P_{empty}$ Although I don't think this is actually right, and I don't know how to evaluate $P_{empty}$ so... I'm at loss. Is this the right way to proceed? I'm guessing that the matter is far more complex than I anticipated. Which road should I pursue in studying it? PS: I would eventually like to embed this in a small FIFO depth calculator in Python, so I can use SciPy primitives.","I'm an engineer, trying to figure out the optimal FIFO depth for a particular application. The events I usually work with follow a Poisson distribution, and a fixed readout rate (thus the M/D/1/N naming). In an example, events arrive with an expected rate of 1MHz, and they are to be read out with a fixed rate of 1Mevents/s. If the incoming events had a fixed timing distribution (1 event every 1us) there would be no need for event storage at all, but the Poissonian nature of the process dictates that it's possible to receive multiple events in any 1-us interval: it is necessary to store (buffer) these excess events (where the local event rate exceeds 1MHz) for later readout. In this example, data is lost when the FIFO is full and I have a new event that needs to be written. Until now, I've designed FIFOs by using simulations, and adjusting their size according to the data loss that I experience. But I wanted to be able to make educated guesses to the appropriate FIFO size beforehand. I've found the following resources online, which however turned out to be of little help to me, given my poor knowledge of the topic: https://en.wikipedia.org/wiki/M/D/1_queue#Stationary_distribution https://www.physicsforums.com/threads/m-d-1-n-queueing-theory-help.600325/ Most often posts online focus on average waiting time or busy period, which I don't think apply to my problem. What I thought would work The probability of event loss can be described as (1) the probability that the FIFO is full, and (2) that I receive another event before the readout. where is the readout time (1us) Now, is trivial, and given by the PDF of the Poisson distribution. ... is another matter. I think it can be evaluated as: . And, thus, recursively: Although I don't think this is actually right, and I don't know how to evaluate so... I'm at loss. Is this the right way to proceed? I'm guessing that the matter is far more complex than I anticipated. Which road should I pursue in studying it? PS: I would eventually like to embed this in a small FIFO depth calculator in Python, so I can use SciPy primitives.","P_{overflow} = P_{full} * P_{1\,event\,in\,\mu} \mu P_{1 event in \mu} P_{full} P_{full} = P_{full\,-\,1} * P_{1\,event\,in\,\mu} P_{full} = \prod_i^{FIFO\,Depth} P_{1\,event\,in\,\mu} * P_{empty} P_{empty}","['probability', 'probability-theory', 'statistics', 'queueing-theory']"
99,Need help understanding how these assumptions imply?,Need help understanding how these assumptions imply?,,"I am trying to understand the assumption proof of Theorem 3 in the paper ""A Universal Law of Robustness via isoperimetry"" by Bubeck and Sellke. Theorem 3. Let $\mathcal{F}$ be a class of functions from $\mathbb{R}^{d} \rightarrow \mathbb{R}$ and let $\left(x_{i}, y_{i}\right)_{i=1}^{n}$ be i.i.d. input-output pairs in $\mathbb{R}^{d} \times[-1,1]$ . Fix $\epsilon, \delta \in(0,1)$ . Assume that: The function class can be written as $\mathcal{F}=\left\{f_{\boldsymbol{w}}, \boldsymbol{w} \in \mathcal{W}\right\}$ with $\mathcal{W} \subset \mathbb{R}^{p}$ , $\operatorname{diam}(\mathcal{W}) \leq W$ and for any $\boldsymbol{w}_{1}, \boldsymbol{w}_{2} \in \mathcal{W}$ , $$ \left\|f_{\boldsymbol{w}_{1}}-f_{\boldsymbol{w}_{2}}\right\|_{\infty} \leq J\left\|\boldsymbol{w}_{1}-\boldsymbol{w}_{2}\right\| $$ The distribution $\mu$ of the covariates $x_{i}$ can be written as $\mu=\sum_{\ell=1}^{k} \alpha_{\ell} \mu_{\ell}$ , where each $\mu_{\ell}$ satisfies c-isoperimetry, $\alpha_{\ell} \geq 0, \sum_{\ell=1}^{k} \alpha_{\ell}=1$ , and $k$ is such that $9^{4} k \log (8 k / \delta) \leq n \epsilon^{2}$ . The expected conditional variance of the output is strictly positive, denoted $\sigma^{2}:=\mathbb{E}^{\mu}[\operatorname{Var}[y \mid x]]>0$ . Then, with probability at least $1-\delta$ with respect to the sampling of the data, one has simultaneously for all $f \in \mathcal{F}$ : $$ \frac{1}{n} \sum_{i=1}^{n}\left(f\left(x_{i}\right)-y_{i}\right)^{2} \leq \sigma^{2}-\epsilon \Rightarrow \operatorname{Lip}(f) \geq \frac{\epsilon}{2^{9} \sqrt{c}} \sqrt{\frac{n d}{p \log \left(60 W J \epsilon^{-1}\right)+\log (4 / \delta)}} . $$ I want to clearly understand these 3 assumptions, typically they want to mean the max component of the absolute value of the subtraction is atleast J times $l2$ norm of the subtraction of those two $w$ vectors. Have not understood the intuition at all noise should be positive , but what does ""expected conditional variance of the output"" mean , I am unable to figure it out. Can anyone explain it naively in a lucid manner why these assumptions they have taken and what is the significance of it?","I am trying to understand the assumption proof of Theorem 3 in the paper ""A Universal Law of Robustness via isoperimetry"" by Bubeck and Sellke. Theorem 3. Let be a class of functions from and let be i.i.d. input-output pairs in . Fix . Assume that: The function class can be written as with , and for any , The distribution of the covariates can be written as , where each satisfies c-isoperimetry, , and is such that . The expected conditional variance of the output is strictly positive, denoted . Then, with probability at least with respect to the sampling of the data, one has simultaneously for all : I want to clearly understand these 3 assumptions, typically they want to mean the max component of the absolute value of the subtraction is atleast J times norm of the subtraction of those two vectors. Have not understood the intuition at all noise should be positive , but what does ""expected conditional variance of the output"" mean , I am unable to figure it out. Can anyone explain it naively in a lucid manner why these assumptions they have taken and what is the significance of it?","\mathcal{F} \mathbb{R}^{d} \rightarrow \mathbb{R} \left(x_{i}, y_{i}\right)_{i=1}^{n} \mathbb{R}^{d} \times[-1,1] \epsilon, \delta \in(0,1) \mathcal{F}=\left\{f_{\boldsymbol{w}}, \boldsymbol{w} \in \mathcal{W}\right\} \mathcal{W} \subset \mathbb{R}^{p} \operatorname{diam}(\mathcal{W}) \leq W \boldsymbol{w}_{1}, \boldsymbol{w}_{2} \in \mathcal{W} 
\left\|f_{\boldsymbol{w}_{1}}-f_{\boldsymbol{w}_{2}}\right\|_{\infty} \leq J\left\|\boldsymbol{w}_{1}-\boldsymbol{w}_{2}\right\|
 \mu x_{i} \mu=\sum_{\ell=1}^{k} \alpha_{\ell} \mu_{\ell} \mu_{\ell} \alpha_{\ell} \geq 0, \sum_{\ell=1}^{k} \alpha_{\ell}=1 k 9^{4} k \log (8 k / \delta) \leq n \epsilon^{2} \sigma^{2}:=\mathbb{E}^{\mu}[\operatorname{Var}[y \mid x]]>0 1-\delta f \in \mathcal{F} 
\frac{1}{n} \sum_{i=1}^{n}\left(f\left(x_{i}\right)-y_{i}\right)^{2} \leq \sigma^{2}-\epsilon \Rightarrow \operatorname{Lip}(f) \geq \frac{\epsilon}{2^{9} \sqrt{c}} \sqrt{\frac{n d}{p \log \left(60 W J \epsilon^{-1}\right)+\log (4 / \delta)}} .
 l2 w","['probability-theory', 'statistics']"
