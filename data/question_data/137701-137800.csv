,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,$e^{Ax}=\cosh(x)I_{n}+\sinh(x)A$,,e^{Ax}=\cosh(x)I_{n}+\sinh(x)A,"Let $A\in\mathbb{M}_{n}$ such that $A^2=I_n$ . Show that for every $x\in\mathbb{R}$ , $$e^{Ax}=\cosh(x)I_{n}+\sinh(x)A$$ . Attempt: $$\begin{align*}         e^{xA}&=\begin{pmatrix}         \sum_{i=0}^{\infty}\frac{(xa_{11})^{i}}{i!} & \cdots  & \sum_{i=0}^{\infty}\frac{(xa_{1n})^{i}}{i!} \\         \vdots  & \ddots  & \vdots  \\         \sum_{i=0}^{\infty}\frac{(xa_{n1})^{i}}{i!} & \cdots  & \sum_{i=0}^{\infty}\frac{(xa_{nn})^{i}}{i!} \\         \end{pmatrix}\\         &=\begin{pmatrix} \sum_{k=0}^{\infty}\frac{(a_{11}x)^{2k}}{(2k)!}+\sum_{k=0}^{\infty}\frac{(a_{11}x)^{2k+1}}{(2k+1)!} & \cdots  & \sum_{k=0}^{\infty}\frac{(a_{1n}x)^{2k}}{(2k)!}+\sum_{k=0}^{\infty}\frac{(a_{1n}x)^{2k+1}}{(2k+1)!} \\ \vdots  & \ddots  & \vdots  \\ \sum_{k=0}^{\infty}\frac{(a_{n1}x)^{2k+1}}{(2k+1)!}+\sum_{k=0}^{\infty}\frac{(a_{n1}x)^{2k+1}}{(2k+1)!} & \cdots  & \sum_{k=0}^{\infty}\frac{(a_{nn}x)^{2k+1}}{(2k+1)!}+\sum_{k=0}^{\infty}\frac{(a_{nn}x)^{2k+1}}{(2k+1)!} \\ \end{pmatrix}\\         &=\begin{pmatrix} \cosh(x)a_{11}^{2k} & \cdots  & \cosh(x)a_{1n}^{2k} \\ \vdots  & \ddots  & \vdots  \\ \cosh(x)a_{n1}^{2k} & \cdots  & \cosh(x)a_{nn}^{2k} \\ \end{pmatrix}+\begin{pmatrix} \sinh(x)a_{11}^{2k}a_{11} & \cdots  & \sinh(x)a_{1n}^{2k}a_{1n} \\ \vdots  & \ddots  & \vdots  \\ \sinh(x)a_{n1}^{2k}a_{n1} & \cdots  & \sinh(x)a_{nn}^{2k}a_{nn} \\ \end{pmatrix}\\         &=\cos(x)A^{2k}+\sinh(x)A^{2k}A\\         &=\cosh(x)I_{n}+\sinh(x)A.     \end{align*}$$ Is this correct?","Let such that . Show that for every , . Attempt: Is this correct?","A\in\mathbb{M}_{n} A^2=I_n x\in\mathbb{R} e^{Ax}=\cosh(x)I_{n}+\sinh(x)A \begin{align*}
        e^{xA}&=\begin{pmatrix}
        \sum_{i=0}^{\infty}\frac{(xa_{11})^{i}}{i!} & \cdots  & \sum_{i=0}^{\infty}\frac{(xa_{1n})^{i}}{i!} \\
        \vdots  & \ddots  & \vdots  \\
        \sum_{i=0}^{\infty}\frac{(xa_{n1})^{i}}{i!} & \cdots  & \sum_{i=0}^{\infty}\frac{(xa_{nn})^{i}}{i!} \\
        \end{pmatrix}\\
        &=\begin{pmatrix} \sum_{k=0}^{\infty}\frac{(a_{11}x)^{2k}}{(2k)!}+\sum_{k=0}^{\infty}\frac{(a_{11}x)^{2k+1}}{(2k+1)!} & \cdots  & \sum_{k=0}^{\infty}\frac{(a_{1n}x)^{2k}}{(2k)!}+\sum_{k=0}^{\infty}\frac{(a_{1n}x)^{2k+1}}{(2k+1)!} \\ \vdots  & \ddots  & \vdots  \\ \sum_{k=0}^{\infty}\frac{(a_{n1}x)^{2k+1}}{(2k+1)!}+\sum_{k=0}^{\infty}\frac{(a_{n1}x)^{2k+1}}{(2k+1)!} & \cdots  & \sum_{k=0}^{\infty}\frac{(a_{nn}x)^{2k+1}}{(2k+1)!}+\sum_{k=0}^{\infty}\frac{(a_{nn}x)^{2k+1}}{(2k+1)!} \\ \end{pmatrix}\\
        &=\begin{pmatrix} \cosh(x)a_{11}^{2k} & \cdots  & \cosh(x)a_{1n}^{2k} \\ \vdots  & \ddots  & \vdots  \\ \cosh(x)a_{n1}^{2k} & \cdots  & \cosh(x)a_{nn}^{2k} \\ \end{pmatrix}+\begin{pmatrix} \sinh(x)a_{11}^{2k}a_{11} & \cdots  & \sinh(x)a_{1n}^{2k}a_{1n} \\ \vdots  & \ddots  & \vdots  \\ \sinh(x)a_{n1}^{2k}a_{n1} & \cdots  & \sinh(x)a_{nn}^{2k}a_{nn} \\ \end{pmatrix}\\
        &=\cos(x)A^{2k}+\sinh(x)A^{2k}A\\
        &=\cosh(x)I_{n}+\sinh(x)A.
    \end{align*}","['matrices', 'ordinary-differential-equations', 'solution-verification']"
1,Can you row reduce the Wronskian with functions?,Can you row reduce the Wronskian with functions?,,"UPDATED BELOW Recently, I came across a problem asking me to exploit the Wronskian to determine the independence of a few functions. The functions were $\sin(x), \cos(x), x\sin(x)$ , and $x\cos(x)$ . I immediately noticed it would be a $4\times 4$ matrix with (probably?) some cyclical functions. I absolutely refused to ""brute force"" the matrix -- but I still wanted to solve it by hand. I noticed in this case if I could use row reduction I could get some zero entries, expand the determinate across that row, or down that column and lessen the work. I don't immediately see a problem with this, if you do row reduction aren't you stating that the two systems are equivalent? I asked my professor if this is a valid approach and he stated he has never thought about it. He then further challenged me to use his solutions which were done ""long and painfully"" and compare what I would do if row reduction is valid. It seems we got the same answer -- but I'm not sure if that will always happen. TL;DR: Can you do row reduction after setting up the Wronskian, but before you take the determinate? Is this always valid? How can one prove either way? Furthermore, can you do column reduction? Problem Statement My work: Professor's Solution: $W=4$ Update: Guidance from a previous professor. Credit Glenn Lahodony, UTSA mathematics. ""This is a very interesting question! The short answer to your question is yes, you can perform row reduction on a matrix of functions.  However, we may have to be careful when performing row reduction on such a matrix depending on the problem of interest.  The matrix you are considering in your problem has entries involving sin(x), cos(x), xsin(x), and xcos(x).  The domain of these functions (and their derivatives) is all real numbers.  However, if we perform certain row reduction operations such as multiplying by 1/sin(x), we have restrictions on the domain (i.e. x is not an integer multiple of pi).  If we then find the Wronskian is nonzero, the set of functions is still linearly independent on any interval not containing integer multiples of pi.  However, if we need to prove linear independence on every interval, we would have to consider a separate case where x is an integer multiple of pi.  Depending on the row operations performed, we may also end up multiplying a row by zero (i.e. multiplying by sin(x) amounts to multiplying a row by zero if x is an integer multiple of pi) which could result in a zero Wronskian for certain values. We can perform row reduction operations to columns of a matrix as well, but the applications are very limited as the system of algebraic equations is not equivalent if column operations are performed.  The only case I can think that column operations would be needed is in studying properties of the transpose of a matrix.""","UPDATED BELOW Recently, I came across a problem asking me to exploit the Wronskian to determine the independence of a few functions. The functions were , and . I immediately noticed it would be a matrix with (probably?) some cyclical functions. I absolutely refused to ""brute force"" the matrix -- but I still wanted to solve it by hand. I noticed in this case if I could use row reduction I could get some zero entries, expand the determinate across that row, or down that column and lessen the work. I don't immediately see a problem with this, if you do row reduction aren't you stating that the two systems are equivalent? I asked my professor if this is a valid approach and he stated he has never thought about it. He then further challenged me to use his solutions which were done ""long and painfully"" and compare what I would do if row reduction is valid. It seems we got the same answer -- but I'm not sure if that will always happen. TL;DR: Can you do row reduction after setting up the Wronskian, but before you take the determinate? Is this always valid? How can one prove either way? Furthermore, can you do column reduction? Problem Statement My work: Professor's Solution: Update: Guidance from a previous professor. Credit Glenn Lahodony, UTSA mathematics. ""This is a very interesting question! The short answer to your question is yes, you can perform row reduction on a matrix of functions.  However, we may have to be careful when performing row reduction on such a matrix depending on the problem of interest.  The matrix you are considering in your problem has entries involving sin(x), cos(x), xsin(x), and xcos(x).  The domain of these functions (and their derivatives) is all real numbers.  However, if we perform certain row reduction operations such as multiplying by 1/sin(x), we have restrictions on the domain (i.e. x is not an integer multiple of pi).  If we then find the Wronskian is nonzero, the set of functions is still linearly independent on any interval not containing integer multiples of pi.  However, if we need to prove linear independence on every interval, we would have to consider a separate case where x is an integer multiple of pi.  Depending on the row operations performed, we may also end up multiplying a row by zero (i.e. multiplying by sin(x) amounts to multiplying a row by zero if x is an integer multiple of pi) which could result in a zero Wronskian for certain values. We can perform row reduction operations to columns of a matrix as well, but the applications are very limited as the system of algebraic equations is not equivalent if column operations are performed.  The only case I can think that column operations would be needed is in studying properties of the transpose of a matrix.""","\sin(x), \cos(x), x\sin(x) x\cos(x) 4\times 4 W=4","['linear-algebra', 'ordinary-differential-equations', 'wronskian']"
2,Convergence of Euler's Method,Convergence of Euler's Method,,"I am to show the IVP as defined by $$y' = ay + b, \quad y(0) = y_0$$ converges using Euler's method. To do this, I need to show that $$\lim_{h \to 0} u_n = y_n$$ where $u_n$ is the approximated value and $y_n$ is the exact value (given by $y(t) = (y_0 + \frac{b}{a}) e^{at} - \frac{b}{a}$ ). Then $$y_0 = y_0$$ and $$y_1 = y_0 + hf(t_0, y_0) = y_0 + hay_0 + hb$$ $$y_2 = y_1 + hf(t_1, y_1) = y_1 + hay_1 + hb = y_0 + hay_0 + hb + ha(y_0 + hay_0 + hb) + hb$$ However, when I go up until $y_n$ , I can't find a function that yields the sequence. I have tried FindSequenceFunction but it didn't help either. How can I find such a function? If there's no such function, is there perhaps a better way to show the convergence? Edit: Using @Lutz Lehmann's hint; $$ y_1 = q y_0 + d $$ $$ y_2 = q y_1 + d = q(qy_0 + d) + d$$ $$ y_3 = q y_2 + q = q(q(qy_0 + d) + d) + d $$ Continuing this, don't we obtain $$ y_n = q^n y_0 + q^{n - 1} d + d $$ where $d = hb$ and $q = (1 + h)$ and $$ \lim_{h \to 0} (1+h) y_0 + (1+h)^{n -1} + hb = y_0$$ I must be missing something critical.","I am to show the IVP as defined by converges using Euler's method. To do this, I need to show that where is the approximated value and is the exact value (given by ). Then and However, when I go up until , I can't find a function that yields the sequence. I have tried FindSequenceFunction but it didn't help either. How can I find such a function? If there's no such function, is there perhaps a better way to show the convergence? Edit: Using @Lutz Lehmann's hint; Continuing this, don't we obtain where and and I must be missing something critical.","y' = ay + b, \quad y(0) = y_0 \lim_{h \to 0} u_n = y_n u_n y_n y(t) = (y_0 + \frac{b}{a}) e^{at} - \frac{b}{a} y_0 = y_0 y_1 = y_0 + hf(t_0, y_0) = y_0 + hay_0 + hb y_2 = y_1 + hf(t_1, y_1) = y_1 + hay_1 + hb = y_0 + hay_0 + hb + ha(y_0 + hay_0 + hb) + hb y_n  y_1 = q y_0 + d   y_2 = q y_1 + d = q(qy_0 + d) + d  y_3 = q y_2 + q = q(q(qy_0 + d) + d) + d   y_n = q^n y_0 + q^{n - 1} d + d  d = hb q = (1 + h)  \lim_{h \to 0} (1+h) y_0 + (1+h)^{n -1} + hb = y_0","['ordinary-differential-equations', 'numerical-methods', 'eulers-method']"
3,Find the solution of the sistem $x''=2x+y$ and $y''=x+2y$,Find the solution of the sistem  and,x''=2x+y y''=x+2y,"I have to find the solution of the sistem $x''=2x+y$ and $y''=x+2y$ to which it applies $x(0)=0$ , $x'(0)=2$ , $y(0)=0$ and $y'(0)=0$ . First I wrote this two formulas in matrix like this $$\begin{bmatrix} x'' \\ y'' \end{bmatrix}=\begin{bmatrix} 2 & 1 \\ 1 & 2 \end{bmatrix}\begin{bmatrix} x\\ y \end{bmatrix}$$ Then I calculate eigenvalues of the matrix $\begin{bmatrix} 2 & 1 \\ 1 & 2 \end{bmatrix}$ where I get $\lambda_{1}=1$ and $\lambda_{2}=3$ For each eigenvalues we got eigenvectors $v_{1}=\begin{bmatrix} 1\\ -1 \end{bmatrix}$ and $v_{2}=\begin{bmatrix} 1 \\ 1 \end{bmatrix}$ For that we get the solution $$\begin{bmatrix} x'\\ y' \end{bmatrix}=\begin{bmatrix} e^{t} & e^{3t} \\ -e^{t} & e^{3t} \end{bmatrix} \begin{bmatrix} C_{1} \\ C_{2} \end{bmatrix}$$ We use $x'(0)=2$ and $y'(0)=0$ and we get $C_{1}=C_{2}=1$ Now I have to find solution for $$\begin{bmatrix} x'\\ y' \end{bmatrix}=\begin{bmatrix} e^{t} & e^{3t} \\ -e^{t} & e^{3t} \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix}$$ I tried to find eigenvalues for that matrix but I can not find them. Any help?","I have to find the solution of the sistem and to which it applies , , and . First I wrote this two formulas in matrix like this Then I calculate eigenvalues of the matrix where I get and For each eigenvalues we got eigenvectors and For that we get the solution We use and and we get Now I have to find solution for I tried to find eigenvalues for that matrix but I can not find them. Any help?","x''=2x+y y''=x+2y x(0)=0 x'(0)=2 y(0)=0 y'(0)=0 \begin{bmatrix}
x'' \\
y''
\end{bmatrix}=\begin{bmatrix}
2 & 1 \\
1 & 2
\end{bmatrix}\begin{bmatrix}
x\\
y
\end{bmatrix} \begin{bmatrix}
2 & 1 \\
1 & 2
\end{bmatrix} \lambda_{1}=1 \lambda_{2}=3 v_{1}=\begin{bmatrix}
1\\
-1
\end{bmatrix} v_{2}=\begin{bmatrix}
1 \\
1
\end{bmatrix} \begin{bmatrix}
x'\\
y'
\end{bmatrix}=\begin{bmatrix}
e^{t} & e^{3t} \\
-e^{t} & e^{3t}
\end{bmatrix} \begin{bmatrix}
C_{1} \\
C_{2}
\end{bmatrix} x'(0)=2 y'(0)=0 C_{1}=C_{2}=1 \begin{bmatrix}
x'\\
y'
\end{bmatrix}=\begin{bmatrix}
e^{t} & e^{3t} \\
-e^{t} & e^{3t}
\end{bmatrix} \begin{bmatrix}
x \\
y
\end{bmatrix}","['real-analysis', 'ordinary-differential-equations', 'eigenvalues-eigenvectors']"
4,Can't find particular integral of a differential equation,Can't find particular integral of a differential equation,,"I have been trying to solve this differential equation using Method of undetermined coefficients and all my guesses are incorrect and not working : $$y''' + 3y'' + 3y' + y = 30e^{-x}$$ When I try to find the Particular Integral, the whole LHS is becoming 0. So I can't get any value for 'A'. Can anyone solve this differential equation for me? Or just the particular integral is enough I stared with the guess that it could be $Ae^{-x}$ . But it didn't work.  When i looked online, i came across an article, it said that i have to add an extra term x^s, where s is the smallest positive integer that renders all summands of a solution independent of the homogeneous solutions. Now i didn't exactly understand what they meant. But like in few examples they gave, i tried with just t first, then i tried $t^2$ . That also didn't work. Then I tried $t^3$ , and then got $\frac{5}{x-1}$ as a value for A. I don't think that's the right answer. Is there any shortcut to guessing the correct one? I know that I can try doing it with the method of variation of parameters but in our exams sometimes they specifically say that you have to use this specific method..Can anyone help?","I have been trying to solve this differential equation using Method of undetermined coefficients and all my guesses are incorrect and not working : When I try to find the Particular Integral, the whole LHS is becoming 0. So I can't get any value for 'A'. Can anyone solve this differential equation for me? Or just the particular integral is enough I stared with the guess that it could be . But it didn't work.  When i looked online, i came across an article, it said that i have to add an extra term x^s, where s is the smallest positive integer that renders all summands of a solution independent of the homogeneous solutions. Now i didn't exactly understand what they meant. But like in few examples they gave, i tried with just t first, then i tried . That also didn't work. Then I tried , and then got as a value for A. I don't think that's the right answer. Is there any shortcut to guessing the correct one? I know that I can try doing it with the method of variation of parameters but in our exams sometimes they specifically say that you have to use this specific method..Can anyone help?",y''' + 3y'' + 3y' + y = 30e^{-x} Ae^{-x} t^2 t^3 \frac{5}{x-1},"['calculus', 'integration', 'ordinary-differential-equations']"
5,"Find $\int_0^e f(x) \ dx$, where $f(y) e^{f(y)} = y$","Find , where",\int_0^e f(x) \ dx f(y) e^{f(y)} = y,"The Question: (a) Prove that for all $y \ge 0,$ there exists a unique real number $x$ such that $$xe^x = y.$$ (b) By part (a), for $y \ge 0,$ we can let $f(y)$ be the unique real number such that $f(y) e^{f(y)} = y$ . Find $\int_0^e f(x) \ dx.$ What I know: I know how to prove part a, you graph $xe^x=y$ , and it's clear to see that for all $y \ge 0,$ there exists a unique real number $x$ such that $xe^x = y.$ My struggle is with part b. I just don't know how to write the differential equation to find the $f(x)$ present. Any help on that front is greatly appreciated. Wikipedia articles, anything.","The Question: (a) Prove that for all there exists a unique real number such that (b) By part (a), for we can let be the unique real number such that . Find What I know: I know how to prove part a, you graph , and it's clear to see that for all there exists a unique real number such that My struggle is with part b. I just don't know how to write the differential equation to find the present. Any help on that front is greatly appreciated. Wikipedia articles, anything.","y \ge 0, x xe^x = y. y \ge 0, f(y) f(y) e^{f(y)} = y \int_0^e f(x) \ dx. xe^x=y y \ge 0, x xe^x = y. f(x)","['calculus', 'integration', 'ordinary-differential-equations']"
6,A question regarding Differential Equation,A question regarding Differential Equation,,"$f'(x) = 1+f(x) \implies \frac{df(x)}{1+f(x)} = dx$ Now on integrating both sides we get $f(x) = e^{x+c} -1$ So $f(x) = e^{x+c}  -1$ for all $x \in \mathbb R$ This is done in my text book. But I can not understand why they did not care about $1+f(x) $ being $0$ . I would rather prefer to do the following. Let's supose $1+f(x) \neq 0$ when $x\in A$ . So we can say $f(x) = e^{x+c}  -1$ when $x \in A$ by using the previous method. And $f(x) = -1$ when $x \in \mathbb R -A$ Now as $\mathbb R$ is a connected set and $f(x)$ is continuous , we can say either $A= \mathbb R$ or $B= \mathbb R$ . Can anyone please tell me if I have gone wrong anywhere?","Now on integrating both sides we get So for all This is done in my text book. But I can not understand why they did not care about being . I would rather prefer to do the following. Let's supose when . So we can say when by using the previous method. And when Now as is a connected set and is continuous , we can say either or . Can anyone please tell me if I have gone wrong anywhere?",f'(x) = 1+f(x) \implies \frac{df(x)}{1+f(x)} = dx f(x) = e^{x+c} -1 f(x) = e^{x+c}  -1 x \in \mathbb R 1+f(x)  0 1+f(x) \neq 0 x\in A f(x) = e^{x+c}  -1 x \in A f(x) = -1 x \in \mathbb R -A \mathbb R f(x) A= \mathbb R B= \mathbb R,"['real-analysis', 'ordinary-differential-equations']"
7,A trigonometric non-linear differential equation,A trigonometric non-linear differential equation,,"I am stuck with the following initial value problem: \begin{equation} \dot{Y}_t = 4 \arctan(1/Y_t) = 2\pi - 4\arctan(Y_t), \quad Y_0 = y > 0 \end{equation} (These are the same thing, by a trig identity.) I tried rewriting a couple of times, but didn't succeed in determining an explicit solution. Is there one? I appreciate any hint. Edit: If we differentiate, the above line, we get $$ (1+Y_t^2)\ddot{Y}_t + 4 \dot{Y}_t = 0. $$ This seems helpful. Is this explicitly solvable?","I am stuck with the following initial value problem: (These are the same thing, by a trig identity.) I tried rewriting a couple of times, but didn't succeed in determining an explicit solution. Is there one? I appreciate any hint. Edit: If we differentiate, the above line, we get This seems helpful. Is this explicitly solvable?","\begin{equation}
\dot{Y}_t = 4 \arctan(1/Y_t) = 2\pi - 4\arctan(Y_t), \quad Y_0 = y > 0
\end{equation} 
(1+Y_t^2)\ddot{Y}_t + 4 \dot{Y}_t = 0.
","['real-analysis', 'ordinary-differential-equations']"
8,How to analyze the following ODE with 2 variables [closed],How to analyze the following ODE with 2 variables [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question THE ODEs has the following form: \begin{align*} \frac{dy}{dt} &= - \lambda xy\\ \frac{dx}{dt} &= -\eta y^2, \end{align*} where $\lambda$ and $\eta$ are constants. $y(0) = C_1 >0$ and $x(0) = C_2 >0$ . Is there any standard tool to analyze it? Thanks.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question THE ODEs has the following form: where and are constants. and . Is there any standard tool to analyze it? Thanks.","\begin{align*}
\frac{dy}{dt} &= - \lambda xy\\
\frac{dx}{dt} &= -\eta y^2,
\end{align*} \lambda \eta y(0) = C_1 >0 x(0) = C_2 >0",['ordinary-differential-equations']
9,Find the area under curve using the given data,Find the area under curve using the given data,,"Consider the curve $y=f(x)$ which satisfies the DE $(1+x^2)\frac{dy}{dx} +2xy=4x^2$ and passes through the origin. Find area enclosed by $f^{-1}x$ , x axis, and $x=2/3$ After some calculation which I don’t think is necessary to show here, I got $$y=\frac{4x^3}{3(1+x^2)}$$ Now the inverse for this function can’t be found directly, and I don’t know how else to do it. Can I get a hint?","Consider the curve which satisfies the DE and passes through the origin. Find area enclosed by , x axis, and After some calculation which I don’t think is necessary to show here, I got Now the inverse for this function can’t be found directly, and I don’t know how else to do it. Can I get a hint?",y=f(x) (1+x^2)\frac{dy}{dx} +2xy=4x^2 f^{-1}x x=2/3 y=\frac{4x^3}{3(1+x^2)},"['calculus', 'integration', 'ordinary-differential-equations', 'definite-integrals', 'inverse-function']"
10,Orthogonal polynomials with respect to $e^{-|x|} \mathrm{d} x$ on the entire real line?,Orthogonal polynomials with respect to  on the entire real line?,e^{-|x|} \mathrm{d} x,"The Laguerre polynomials https://en.wikipedia.org/wiki/Laguerre_polynomials form a system of orthogonal polynomials with respect to the measure $e^{ -x} \mathrm{d} x$ on $(0,\infty)$ . Is anything known about the orthogonal polynomials with respect to the measure $e^{ -|x|} \mathrm{d} x$ on $(-\infty,\infty)$ ? Thank you!",The Laguerre polynomials https://en.wikipedia.org/wiki/Laguerre_polynomials form a system of orthogonal polynomials with respect to the measure on . Is anything known about the orthogonal polynomials with respect to the measure on ? Thank you!,"e^{ -x} \mathrm{d} x (0,\infty) e^{ -|x|} \mathrm{d} x (-\infty,\infty)","['real-analysis', 'ordinary-differential-equations', 'polynomials', 'orthogonal-polynomials', 'laguerre-polynomials']"
11,"Calculus: Isn't the velocity & tangent at a critical point = 0, and therefore a function is not increasing at that point?","Calculus: Isn't the velocity & tangent at a critical point = 0, and therefore a function is not increasing at that point?",,"I encountered a question from Khan Acad that asked, at what intervals of x does the function increase. My intuition is that all ranges except for 0 and 1, because tangents at those points are flat per green graph below. Backed up by the red graph, showing h'(1)=0 & h'(0)=0, zero velocity. I need help figuring out my knowledge gap: Am I misinterpreting what ""increasing"" here? Am I missing the point of what a critical point is..?","I encountered a question from Khan Acad that asked, at what intervals of x does the function increase. My intuition is that all ranges except for 0 and 1, because tangents at those points are flat per green graph below. Backed up by the red graph, showing h'(1)=0 & h'(0)=0, zero velocity. I need help figuring out my knowledge gap: Am I misinterpreting what ""increasing"" here? Am I missing the point of what a critical point is..?",,"['calculus', 'ordinary-differential-equations', 'derivatives']"
12,Find a general solution,Find a general solution,,"$$(y+e^x)\frac{dy}{dx}=-\frac{y^2}{2}-2ye^x$$ I attempted to turn this inexact eq. to exact: I multiply by IF = $e^t$ and got: $$(ye^x+e^{2x})dy+(\frac{y^2}{2}e^x+2ye^{2x})dx = 0$$ which is exact. Then I integrate, and I get $y^2e^x+2ye^{2x} + c = 0$ . My question is if this is considerate a general solution? or does this expression need to be expressed in terms of y? If so, how can I do this? Thanks","I attempted to turn this inexact eq. to exact: I multiply by IF = and got: which is exact. Then I integrate, and I get . My question is if this is considerate a general solution? or does this expression need to be expressed in terms of y? If so, how can I do this? Thanks",(y+e^x)\frac{dy}{dx}=-\frac{y^2}{2}-2ye^x e^t (ye^x+e^{2x})dy+(\frac{y^2}{2}e^x+2ye^{2x})dx = 0 y^2e^x+2ye^{2x} + c = 0,['ordinary-differential-equations']
13,Solving $\int_{0}^{x}(x-t)y(t)dt = 2x+\int_{0}^{x}y(t)dt$,Solving,\int_{0}^{x}(x-t)y(t)dt = 2x+\int_{0}^{x}y(t)dt,Solve: $$ \int_{0}^{x}(x-t)y(t)dt = 2x + \int_{0}^{x}y(t)dt $$ The farthest I got is to: $$ \int_{0}^{x}(x-t)y(t)dt-\int_{0}^{x}y(t)dt = 2x $$ Combining the integrals we get: $$ \int_{0}^{x}y(t)(x-t-1)dt = 2x $$ And here I’m pretty stuck. Can someone please give me a hint? Thanks.,Solve: The farthest I got is to: Combining the integrals we get: And here I’m pretty stuck. Can someone please give me a hint? Thanks.,"
\int_{0}^{x}(x-t)y(t)dt = 2x + \int_{0}^{x}y(t)dt
 
\int_{0}^{x}(x-t)y(t)dt-\int_{0}^{x}y(t)dt = 2x
 
\int_{0}^{x}y(t)(x-t-1)dt = 2x
","['calculus', 'integration', 'ordinary-differential-equations']"
14,"If $a\frac {dy}{dx} + by = c$ has constant coeffcients, does that means that $a=b=c$?","If  has constant coeffcients, does that means that ?",a\frac {dy}{dx} + by = c a=b=c,I am trying to identify if a differential equation has constant coefficients. Let $A = a\dfrac {dy}{dx} + by = c$ The $A$ has constant coefficients only if $a=b=c$ correct?,I am trying to identify if a differential equation has constant coefficients. Let The has constant coefficients only if correct?,A = a\dfrac {dy}{dx} + by = c A a=b=c,"['ordinary-differential-equations', 'definition']"
15,What is a suitable Lyapunov function for this system?,What is a suitable Lyapunov function for this system?,,"I have verified using the eigenvalue method that around $(0,0)$ the system \begin{align}\dot x&=y - 3x - x^3 \\ \dot y &= 6x - 2y \end{align} is stable. However, I have been trying to find a suitable Lyapunov function $V$ but from the expressions I have come up with so far, I cannot definitively deduce that the derivative is less than zero. I have tried the classical $V = x^2 + y^2$ and tried changing up the coefficients and exponents so that I can have some cancellations of the odd terms. It has been several hours now and still no luck. Any hints will be much appreciated.","I have verified using the eigenvalue method that around the system is stable. However, I have been trying to find a suitable Lyapunov function but from the expressions I have come up with so far, I cannot definitively deduce that the derivative is less than zero. I have tried the classical and tried changing up the coefficients and exponents so that I can have some cancellations of the odd terms. It has been several hours now and still no luck. Any hints will be much appreciated.","(0,0) \begin{align}\dot x&=y - 3x - x^3 \\ \dot y &= 6x - 2y \end{align} V V = x^2 + y^2","['ordinary-differential-equations', 'dynamical-systems', 'stability-in-odes', 'stability-theory', 'lyapunov-functions']"
16,Is it necessary for a Lyapunov Candidate to be Differentiable at an Equilibrium Point?,Is it necessary for a Lyapunov Candidate to be Differentiable at an Equilibrium Point?,,"For example, given a general nonlinear system where we want to show that the error system is stable $e=x-x_d$ is it necessary for the Lyapunov candidate to be continuously differentiable at the equilibrium point since we are only concerned about what happens around the equilibrium point? At the end of the day I would like to show that $\vert\vert e\vert\vert$ is a valid Lyapunov candidate. However, this is not differentiable at $e=0$ since the derivative is $\frac{e^{T}\dot{e}}{\vert\vert e\vert\vert}$ . My current digging into this topic has found the following paper: Vector Norms as Lyapunov Functions for Linear Systems by Kiendl. However, this paper is restricted to linear systems (plus other restrictions). Note: this is a follow up to a question I asked yesterday but I believe this is better said and is more direct. Thanks for your input","For example, given a general nonlinear system where we want to show that the error system is stable is it necessary for the Lyapunov candidate to be continuously differentiable at the equilibrium point since we are only concerned about what happens around the equilibrium point? At the end of the day I would like to show that is a valid Lyapunov candidate. However, this is not differentiable at since the derivative is . My current digging into this topic has found the following paper: Vector Norms as Lyapunov Functions for Linear Systems by Kiendl. However, this paper is restricted to linear systems (plus other restrictions). Note: this is a follow up to a question I asked yesterday but I believe this is better said and is more direct. Thanks for your input",e=x-x_d \vert\vert e\vert\vert e=0 \frac{e^{T}\dot{e}}{\vert\vert e\vert\vert},"['ordinary-differential-equations', 'lyapunov-functions']"
17,Problem on the general solution of the differential equation $ [y+xf(x^2+y^2)]dx+[yf(x^2+y^2)-x]dy=0 $,Problem on the general solution of the differential equation, [y+xf(x^2+y^2)]dx+[yf(x^2+y^2)-x]dy=0 ,"This question has stumped me: $$ [y+xf(x^2+y^2)]dx+[yf(x^2+y^2)-x]dy=0  $$ I've tried finding $M_x-N_y$ thinking it would help find some integrating factor, but it came out to be 2 and I don't think I can use an integrating factor now. I've also tried diving by $x^2,xy$ , but I'm not sure how to proceed now.","This question has stumped me: I've tried finding thinking it would help find some integrating factor, but it came out to be 2 and I don't think I can use an integrating factor now. I've also tried diving by , but I'm not sure how to proceed now."," [y+xf(x^2+y^2)]dx+[yf(x^2+y^2)-x]dy=0   M_x-N_y x^2,xy",['ordinary-differential-equations']
18,Solve the differential equation $ x^4y^3=xy' + y$,Solve the differential equation, x^4y^3=xy' + y,"Using the change of the dependent variable $z = y^{−2}$ , solve the differential equation: $$xy' + y = x^4y^3$$ . My attempt: $$xy' + y = x^4y^3 \tag 1$$ Now dividing $(1)$ by $y^2$ $$\frac{xy'}{y^2} + \frac{1}{y} = x^4y$$ Now put $z= \frac{1}{y^2}$ , $$\frac{dz}{dx} = \frac{-2}{y^3}\frac{dy}{dx}=\frac{-2}{y^3}y'$$ $$y'=\frac{-y^3dz}{2dx}$$ $$xy' z +\frac{1}{y} = x^4y$$ After that im not able to proceed further.","Using the change of the dependent variable , solve the differential equation: . My attempt: Now dividing by Now put , After that im not able to proceed further.",z = y^{−2} xy' + y = x^4y^3 xy' + y = x^4y^3 \tag 1 (1) y^2 \frac{xy'}{y^2} + \frac{1}{y} = x^4y z= \frac{1}{y^2} \frac{dz}{dx} = \frac{-2}{y^3}\frac{dy}{dx}=\frac{-2}{y^3}y' y'=\frac{-y^3dz}{2dx} xy' z +\frac{1}{y} = x^4y,['ordinary-differential-equations']
19,"Checking the solution to $2yy'=x(y')^2+4x,\ y(1)=-2$",Checking the solution to,"2yy'=x(y')^2+4x,\ y(1)=-2","I have to find a particular solution to the following differential equation: $$ 2yy'=x(y')^2+4x,\ y(1)=-2 $$ I decided to substitute the values $x=1$ and $y=-2$ into the given equations. So, I got: $$ \begin{aligned} &-4y'=(y')^2+4\iff(y'+2)^2=0\iff y'=-2\iff y=-2x+C\Rightarrow\\ &\Rightarrow [\text{Substitute $y$ into the initial diff. eq.}]\Rightarrow (-4x+2C)(-2)=4x+4x\Rightarrow C=0\\ &\text{Answer: } y=-2x \end{aligned} $$ But I'm not sure of my solution. Could anyone check it please?","I have to find a particular solution to the following differential equation: I decided to substitute the values and into the given equations. So, I got: But I'm not sure of my solution. Could anyone check it please?","
2yy'=x(y')^2+4x,\ y(1)=-2
 x=1 y=-2 
\begin{aligned}
&-4y'=(y')^2+4\iff(y'+2)^2=0\iff y'=-2\iff y=-2x+C\Rightarrow\\
&\Rightarrow [\text{Substitute y into the initial diff. eq.}]\Rightarrow (-4x+2C)(-2)=4x+4x\Rightarrow C=0\\
&\text{Answer: } y=-2x
\end{aligned}
","['calculus', 'ordinary-differential-equations']"
20,Solve $(D^2 + 3D + 2)y = e^{e^x}$ using method of variation of parameters?,Solve  using method of variation of parameters?,(D^2 + 3D + 2)y = e^{e^x},"This question was asked in a test and I'm stuck while solving this using method of variation of parameters. Here's an screenshot of my solution, While finding particular integral I was not able to solve integration of e^e^x? Can anyone please help me out a bit here. I was not able to understand how to solve it further.","This question was asked in a test and I'm stuck while solving this using method of variation of parameters. Here's an screenshot of my solution, While finding particular integral I was not able to solve integration of e^e^x? Can anyone please help me out a bit here. I was not able to understand how to solve it further.",,"['linear-algebra', 'integration', 'ordinary-differential-equations', 'derivatives']"
21,Resonance and Repeated Factors,Resonance and Repeated Factors,,"When studying Calculus, I asked this question about why non-repeated and repeated factors are handled differently in partial fraction decomposition.  As I work Laplace Transform problems, I'm noticing repeated factors occur when there is resonance between an ODE's forcing term and associated homogeneous solution.  This makes at least half of a bit of sense, since the algebraic step of a Laplace Transform problem involves dividing everything by the characteristic polynomial, which is related to the associated homogeneous solution.  Perhaps the denominator of a forcing term's Laplace Transform is related to the homogeneous linear ODE which that forcing term would solve, creating this overlap in the resonant case. Is it accurate to say that repeated factors in the s-domain occur if, only if, or if and only if the ODE has resonance?  If so, is my linked question about the additional term in a repeated-factor partial fraction decomposition nothing more than the s-domain framing of the common question of why an additional factor of $t$ appears in the particular solution to a resonant linear ODE?","When studying Calculus, I asked this question about why non-repeated and repeated factors are handled differently in partial fraction decomposition.  As I work Laplace Transform problems, I'm noticing repeated factors occur when there is resonance between an ODE's forcing term and associated homogeneous solution.  This makes at least half of a bit of sense, since the algebraic step of a Laplace Transform problem involves dividing everything by the characteristic polynomial, which is related to the associated homogeneous solution.  Perhaps the denominator of a forcing term's Laplace Transform is related to the homogeneous linear ODE which that forcing term would solve, creating this overlap in the resonant case. Is it accurate to say that repeated factors in the s-domain occur if, only if, or if and only if the ODE has resonance?  If so, is my linked question about the additional term in a repeated-factor partial fraction decomposition nothing more than the s-domain framing of the common question of why an additional factor of appears in the particular solution to a resonant linear ODE?",t,"['ordinary-differential-equations', 'laplace-transform', 'partial-fractions']"
22,Intuition for multiplying by x for independent solutions,Intuition for multiplying by x for independent solutions,,"I'm taking a differential equations course, and I was wondering what the intuition behind multiplying by x to get a linearly independent solution to a 2nd order homogeneous linear ODE is. Consider the DE: $$ y^{\prime\prime} + 4y^{\prime} + 4y = 0 $$ Evaluating the characteristic polynomial: $$ \lambda^2 + 4\lambda + 4 = 0\\ (\lambda+2)^2=0, \lambda=-2\ \text{(double root)}\\ y=c_1e^{-2x}+c_2xe^{-2x} $$ I'm trying to get a hold of why multiplying by $x$ makes sense. I understand the  derivation via variation of coefficients, but I don't get why it makes sense. Why does multiplying a solution to a differential equation by $x$ to get another solution that is linearly independent make sense? Is it a guess, or is there some deeper intuition for why this makes sense in the case of a double root? Does multiplying a function of $x$ by $x$ always produce a new linearly independent function? My teacher mentioned something about it being the first term of some taylor series expansion for $f(\epsilon)$ when nudging $x$ by $\epsilon$ in the first solution to the DE, but I didn't really understand that explanation. Is there more to that explanation?","I'm taking a differential equations course, and I was wondering what the intuition behind multiplying by x to get a linearly independent solution to a 2nd order homogeneous linear ODE is. Consider the DE: Evaluating the characteristic polynomial: I'm trying to get a hold of why multiplying by makes sense. I understand the  derivation via variation of coefficients, but I don't get why it makes sense. Why does multiplying a solution to a differential equation by to get another solution that is linearly independent make sense? Is it a guess, or is there some deeper intuition for why this makes sense in the case of a double root? Does multiplying a function of by always produce a new linearly independent function? My teacher mentioned something about it being the first term of some taylor series expansion for when nudging by in the first solution to the DE, but I didn't really understand that explanation. Is there more to that explanation?","
y^{\prime\prime} + 4y^{\prime} + 4y = 0
 
\lambda^2 + 4\lambda + 4 = 0\\
(\lambda+2)^2=0, \lambda=-2\ \text{(double root)}\\
y=c_1e^{-2x}+c_2xe^{-2x}
 x x x x f(\epsilon) x \epsilon","['linear-algebra', 'ordinary-differential-equations', 'taylor-expansion']"
23,"Integrating $\int \frac{-\sin x}{1+\cos x}\, dx$, I get $\ln(1 + \cos x)$. WolframAlpha gives $2 \ln(\cos \frac x 2)$. Is WA wrong?","Integrating , I get . WolframAlpha gives . Is WA wrong?","\int \frac{-\sin x}{1+\cos x}\, dx \ln(1 + \cos x) 2 \ln(\cos \frac x 2)","So, I'm watching a tutorial on differential equations, where I encountered this little trick: $$\int \frac{y'}{y}\, dx = \ln(y)$$ It seems perfectly logical and easy to justify, but something fishy happens to this integral: $$\int \frac{-\sin x}{1+\cos x}\, dx$$ The trick gives $\int \frac{-\sin x}{1+\cos x}\, dx = \ln(1 + \cos x)$ while WolframAlpha gives $\int \frac{-\sin x}{1+\cos x}\, dx = 2 \ln(\cos \frac x 2)$ . You guys who know this stuff - does WolframAlpha mess up here or is it something I've missed? Taking the derivative of $2 \ln(\cos \frac x 2)$ gives me $-\tan \frac x 2$ , so I don't see how WA may be right.","So, I'm watching a tutorial on differential equations, where I encountered this little trick: It seems perfectly logical and easy to justify, but something fishy happens to this integral: The trick gives while WolframAlpha gives . You guys who know this stuff - does WolframAlpha mess up here or is it something I've missed? Taking the derivative of gives me , so I don't see how WA may be right.","\int \frac{y'}{y}\, dx = \ln(y) \int \frac{-\sin x}{1+\cos x}\, dx \int \frac{-\sin x}{1+\cos x}\, dx = \ln(1 + \cos x) \int \frac{-\sin x}{1+\cos x}\, dx = 2 \ln(\cos \frac x 2) 2 \ln(\cos \frac x 2) -\tan \frac x 2","['integration', 'ordinary-differential-equations', 'derivatives']"
24,Solve the second-order equation $y''=(2y+3)(y')^2$,Solve the second-order equation,y''=(2y+3)(y')^2,"Solve the second-order equation $y''=(2y+3)(y')^2$ My Trial Let $z=z(y):\;y'=z.$ Then, \begin{align} y''=\dfrac{dz}{dx}=\dfrac{dz}{dy} \dfrac{dy}{dx}=z'\dfrac{dy}{dx}  .\end{align} So, \begin{align} \dfrac{dz}{dx}=(2y+3)(z)^2\iff \dfrac{1}{z^2}\dfrac{dz}{dx}=(2y+3)\iff \dfrac{1}{z^2}dz=(2y+3)dx\end{align} I'm stuck here as I am not sure of how to deal with the right-hand side, maybe I should treat it as partial integration or not. Can anyone provide a hint or help me continue?","Solve the second-order equation My Trial Let Then, So, I'm stuck here as I am not sure of how to deal with the right-hand side, maybe I should treat it as partial integration or not. Can anyone provide a hint or help me continue?",y''=(2y+3)(y')^2 z=z(y):\;y'=z. \begin{align} y''=\dfrac{dz}{dx}=\dfrac{dz}{dy} \dfrac{dy}{dx}=z'\dfrac{dy}{dx}  .\end{align} \begin{align} \dfrac{dz}{dx}=(2y+3)(z)^2\iff \dfrac{1}{z^2}\dfrac{dz}{dx}=(2y+3)\iff \dfrac{1}{z^2}dz=(2y+3)dx\end{align},['ordinary-differential-equations']
25,Solution to $ xy \ \frac {d^2y} {dx^2} + (x\ \frac {dy}{dx} - 2\ y) \frac {dy}{dx} = 0$,Solution to, xy \ \frac {d^2y} {dx^2} + (x\ \frac {dy}{dx} - 2\ y) \frac {dy}{dx} = 0,How can I find the general solution to this: $ xy \ \frac {d^2y} {dx^2} + (x\  \frac {dy}{dx} - 2\ y) \frac {dy}{dx} = 0$ I have learned various methods including: 1. integrating factor method 2. undetermined coefficient 3. variations of parameters 4. bernoulli equation 5. cauchy euler 6. second order ODE with constant coefficient 7. reduction of order 8. separation of variable But none seems to be applicable to this one. I have tried various ways arranging the equation to this: $xy \ y'' = - (xy'-2y)y'$ or $y'' + y^{-1} y'' - 2x^{-1} \ y' = 0$ But then I'm stuck. Any help would be apreciated! :),How can I find the general solution to this: I have learned various methods including: 1. integrating factor method 2. undetermined coefficient 3. variations of parameters 4. bernoulli equation 5. cauchy euler 6. second order ODE with constant coefficient 7. reduction of order 8. separation of variable But none seems to be applicable to this one. I have tried various ways arranging the equation to this: or But then I'm stuck. Any help would be apreciated! :), xy \ \frac {d^2y} {dx^2} + (x\  \frac {dy}{dx} - 2\ y) \frac {dy}{dx} = 0 xy \ y'' = - (xy'-2y)y' y'' + y^{-1} y'' - 2x^{-1} \ y' = 0,['ordinary-differential-equations']
26,Analytically determine if $f(x) = f'(x)$ is possible?,Analytically determine if  is possible?,f(x) = f'(x),"I was taking a test and two true/false type questions were asked. In one of them, I had to say if there is a function $f(x)$ such that $f(x) = f'(x)$ . Of course, $e^x$ is such a function and almost everyone who has taken a calculus course knows this fact well. In the other question, I had to determine if $f(x) = -f'(x)$ was possible. I was completely stumped at this one. I had never before encountered a function with such property nor did I know how to approach this problem analytically as I am just a high school student. My question is: is there an analytical way to determine if such a function exists? By analytical, I mean no guessing allowed and just giving an example won't be enough. Is this possible? If not, can you give an example of a function with the above property?","I was taking a test and two true/false type questions were asked. In one of them, I had to say if there is a function such that . Of course, is such a function and almost everyone who has taken a calculus course knows this fact well. In the other question, I had to determine if was possible. I was completely stumped at this one. I had never before encountered a function with such property nor did I know how to approach this problem analytically as I am just a high school student. My question is: is there an analytical way to determine if such a function exists? By analytical, I mean no guessing allowed and just giving an example won't be enough. Is this possible? If not, can you give an example of a function with the above property?",f(x) f(x) = f'(x) e^x f(x) = -f'(x),"['calculus', 'ordinary-differential-equations', 'functions', 'derivatives', 'exponential-function']"
27,Using polar coordinates to find the critical points,Using polar coordinates to find the critical points,,"I have written the following DE system $$\dot{x} = x+y-x(x^2+y^2)\\ \dot{y} = -x+3y-y(x^2+y^2) $$ as follows in Polar form: $$\dot{r} = -2r\cos^2\theta+r(3-r^2) $$ $$\dot{\theta} = 2\sin\theta\cos\theta-1$$ What I wonder is could I also find all the critical points of this system by setting $\dot{\theta}$ and $\dot{r}$ equal to zero? Since these two systems are actually equivalent to each other this seemed like a logical thing to me and at the same time finding the critical points through setting $\dot{x}$ and $\dot{y}$ equal to zero seems like much more tedious in this state. Solving for $\dot{\theta}=0$ leads to $2\sin\theta\cos\theta = 1$ which is the same as $\sin2\theta=1$ leading to $\theta = \frac{\pi}{4}$ or $\theta = -\frac{3\pi}{4}$ . Substituting these within $\dot{r}$ leads to: $$-2r\cos^2\theta+r(3-r^2) = -2r(\pm\frac{\sqrt{2}}{2})^2 +r(3-r^2)=r(2-r^2)$$ So $\dot{r}=0$ if $r=0$ or $r^2=2$ . This leads us to the following critical points: $(0,0)$ , $(\sqrt{2},\sqrt{2})$ , $(-\sqrt{2},-\sqrt{2})$ .  However what bugs me is that entering these points into the non-polar system does not lead to $\dot{x}=\dot{y}=0$ for $(\sqrt{2},\sqrt{2})$ , $(-\sqrt{2},-\sqrt{2})$ . What am I missing here? Is the whole thought of trying to find critical points through putting $\dot{\theta}$ and $\dot{r}$ equal to zero unwise? Any help or hint with this will be much appreciated.","I have written the following DE system as follows in Polar form: What I wonder is could I also find all the critical points of this system by setting and equal to zero? Since these two systems are actually equivalent to each other this seemed like a logical thing to me and at the same time finding the critical points through setting and equal to zero seems like much more tedious in this state. Solving for leads to which is the same as leading to or . Substituting these within leads to: So if or . This leads us to the following critical points: , , .  However what bugs me is that entering these points into the non-polar system does not lead to for , . What am I missing here? Is the whole thought of trying to find critical points through putting and equal to zero unwise? Any help or hint with this will be much appreciated.","\dot{x} = x+y-x(x^2+y^2)\\
\dot{y} = -x+3y-y(x^2+y^2)  \dot{r} = -2r\cos^2\theta+r(3-r^2)  \dot{\theta} = 2\sin\theta\cos\theta-1 \dot{\theta} \dot{r} \dot{x} \dot{y} \dot{\theta}=0 2\sin\theta\cos\theta = 1 \sin2\theta=1 \theta = \frac{\pi}{4} \theta = -\frac{3\pi}{4} \dot{r} -2r\cos^2\theta+r(3-r^2) = -2r(\pm\frac{\sqrt{2}}{2})^2 +r(3-r^2)=r(2-r^2) \dot{r}=0 r=0 r^2=2 (0,0) (\sqrt{2},\sqrt{2}) (-\sqrt{2},-\sqrt{2}) \dot{x}=\dot{y}=0 (\sqrt{2},\sqrt{2}) (-\sqrt{2},-\sqrt{2}) \dot{\theta} \dot{r}","['ordinary-differential-equations', 'systems-of-equations', 'polar-coordinates']"
28,"If $f$ is a polynomial, how does $f(\frac{d}{dt})$ act on $y$?","If  is a polynomial, how does  act on ?",f f(\frac{d}{dt}) y,"If $f\left(\frac{d}{dt}\right)=a_n\frac{d^n}{dt^n}+\dots+a_1\frac{d}{dt}+a_0$ , then whether $$f\left(\frac{d}{dt}\right)(y)=a_n\frac{d^n}{dt^n}y+\dots+a_1\frac{d}{dt}y+a_0y$$ or $$f\left(\frac{d}{dt}\right)(y)=a_n\frac{d^n}{dt^n}y+\dots+a_1\frac{d}{dt}y+a_0$$ I am confused.","If , then whether or I am confused.",f\left(\frac{d}{dt}\right)=a_n\frac{d^n}{dt^n}+\dots+a_1\frac{d}{dt}+a_0 f\left(\frac{d}{dt}\right)(y)=a_n\frac{d^n}{dt^n}y+\dots+a_1\frac{d}{dt}y+a_0y f\left(\frac{d}{dt}\right)(y)=a_n\frac{d^n}{dt^n}y+\dots+a_1\frac{d}{dt}y+a_0,[]
29,"Free,Undamped Mechanical Vibrations","Free,Undamped Mechanical Vibrations",,"In the case of free, undamped vibrations,the differential equation is $mu''+ku=0$ and solution to this differential equation is \begin{align} \tag{1} u(t)=c_1\cos{(\omega_0 t)}+c_2\sin{(\omega_0 t)} \end{align} Now this has been written by the author in the following form, \begin{align} \tag{2} u(t)=R\cos{(\omega_0 t-\delta)} \end{align} where he says R is the amplitude of displacement $u(t)$ and $\delta$ is the phase shift or phase angle of displacement $u(t)$ Now why did he assume that both the equations $(1)$ and $(2)$ are equivalent and on what ground?","In the case of free, undamped vibrations,the differential equation is and solution to this differential equation is Now this has been written by the author in the following form, where he says R is the amplitude of displacement and is the phase shift or phase angle of displacement Now why did he assume that both the equations and are equivalent and on what ground?","mu''+ku=0 \begin{align} \tag{1}
u(t)=c_1\cos{(\omega_0 t)}+c_2\sin{(\omega_0 t)}
\end{align} \begin{align} \tag{2}
u(t)=R\cos{(\omega_0 t-\delta)}
\end{align} u(t) \delta u(t) (1) (2)","['ordinary-differential-equations', 'trigonometry', 'homogeneous-equation']"
30,Equation of Simple Harmonic Oscillator,Equation of Simple Harmonic Oscillator,,"So I know that the differential equation of a simple harmonic oscillator is $\dfrac{d^2x}{dt^2}=-\omega^2x$ and it's solution is $y = A\sin(\omega t+\phi)$ . Now I learned for a solution with $n$ independent constants, the differential equation will be of order $n$ . In this case, there are 3 independent constants, $A, \omega, \phi$ , so shouldn't the differential equation be of order three? How is it two? Edit: Also when I start with the solution itself $y=A\sin(\omega t + \phi)$ $y'=A\omega\cos(\omega t + \phi)$ $\dfrac{\omega^2y^2}{A^2\omega^2}+\dfrac{y'^2}{A^2w^2} = 1$ $\omega^2\cdot2yy'+2y'y''=0$ $\omega^2=-\dfrac{y''}{y}$ $0=\dfrac{yy'''-y''y'}{y^2}$ $yy'''=y''y'$","So I know that the differential equation of a simple harmonic oscillator is and it's solution is . Now I learned for a solution with independent constants, the differential equation will be of order . In this case, there are 3 independent constants, , so shouldn't the differential equation be of order three? How is it two? Edit: Also when I start with the solution itself","\dfrac{d^2x}{dt^2}=-\omega^2x y = A\sin(\omega t+\phi) n n A, \omega, \phi y=A\sin(\omega t + \phi) y'=A\omega\cos(\omega t + \phi) \dfrac{\omega^2y^2}{A^2\omega^2}+\dfrac{y'^2}{A^2w^2} = 1 \omega^2\cdot2yy'+2y'y''=0 \omega^2=-\dfrac{y''}{y} 0=\dfrac{yy'''-y''y'}{y^2} yy'''=y''y'","['calculus', 'ordinary-differential-equations']"
31,Equation with one variable unknow how to solve easily,Equation with one variable unknow how to solve easily,,"I have $$\left|\begin{array}{ccc} x & -2 & 3x-6 \\ 2x & \phantom{-}0 & 2-x \\ -x & \phantom{-}5 & x-2  \end{array}\right| = 0$$ How can I solve this with a fast way? I thought I can do  $$x-2+3x-6=0 \implies 4x=-8 \implies x=-2$$  and I will continue with the other two, but I don't know if I am right.","I have $$\left|\begin{array}{ccc} x & -2 & 3x-6 \\ 2x & \phantom{-}0 & 2-x \\ -x & \phantom{-}5 & x-2  \end{array}\right| = 0$$ How can I solve this with a fast way? I thought I can do  $$x-2+3x-6=0 \implies 4x=-8 \implies x=-2$$  and I will continue with the other two, but I don't know if I am right.",,"['linear-algebra', 'ordinary-differential-equations']"
32,Solving $y''-k^2y=0$ without substituting $e^{kx}$,Solving  without substituting,y''-k^2y=0 e^{kx},As the title says I am trying to solve $y''-k^2y=0$. The method that I want to use is to assume $y'=p$ which gives us $y''=p\frac{dp}{dy}$. Substituting above values in original equation gives me $p\frac{dp}{dy}-k^2y=0$ which further reduces to $\frac{dy}{dx}=\sqrt{k^2y^2+c}$. On trying to solve this differential equation I am not reaching any close to the expected answer which should be summation of two exponential terms.,As the title says I am trying to solve $y''-k^2y=0$. The method that I want to use is to assume $y'=p$ which gives us $y''=p\frac{dp}{dy}$. Substituting above values in original equation gives me $p\frac{dp}{dy}-k^2y=0$ which further reduces to $\frac{dy}{dx}=\sqrt{k^2y^2+c}$. On trying to solve this differential equation I am not reaching any close to the expected answer which should be summation of two exponential terms.,,"['calculus', 'ordinary-differential-equations']"
33,Zeros of solution of a ODE,Zeros of solution of a ODE,,Let $a$ be a real differentiable function $a(0)>0$ and $a(t)\geq 0$. Consider the solution $\phi$ of the differential equation   $$x''+ ax=0$$   with initial conditions $\phi(0)=1$ and $\phi'(0)=0$. Prove that there exist $t_0<0<t_1$ such that $\phi(t_0)=\phi(t_1)=0$. I don't know exactly what to do with this problem. It is clear that $0$ is local maximum of $\phi$ because of the initial conditions. Any hint?,Let $a$ be a real differentiable function $a(0)>0$ and $a(t)\geq 0$. Consider the solution $\phi$ of the differential equation   $$x''+ ax=0$$   with initial conditions $\phi(0)=1$ and $\phi'(0)=0$. Prove that there exist $t_0<0<t_1$ such that $\phi(t_0)=\phi(t_1)=0$. I don't know exactly what to do with this problem. It is clear that $0$ is local maximum of $\phi$ because of the initial conditions. Any hint?,,['ordinary-differential-equations']
34,Help with Method of Undetermined Coefficients,Help with Method of Undetermined Coefficients,,"Solve the following ODE using the method of undetermined coefficients: $$y''-4y'+4y=(x+1)e^{2x}$$ My work . I have the homogeneous solution: $$y_h=C_1e^{2t}+C_2te^{2t}$$ I use this function to get the particular solution of the ODE: $$y=(Ax+B)xe^{2x}$$ And after substitution on the ODE, I get: $$2A=(x+1)e^{2x}$$ What about $B$? I don't know what I am missing. Could someone give me a hint? Thank you.","Solve the following ODE using the method of undetermined coefficients: $$y''-4y'+4y=(x+1)e^{2x}$$ My work . I have the homogeneous solution: $$y_h=C_1e^{2t}+C_2te^{2t}$$ I use this function to get the particular solution of the ODE: $$y=(Ax+B)xe^{2x}$$ And after substitution on the ODE, I get: $$2A=(x+1)e^{2x}$$ What about $B$? I don't know what I am missing. Could someone give me a hint? Thank you.",,"['calculus', 'ordinary-differential-equations']"
35,ODE system - finding the general solution given 2 solutions,ODE system - finding the general solution given 2 solutions,,"Given the following ode system $\begin{cases}tx_1'=2x_2+2x_3+t^3e^t\\tx_2'=-x_1+3x_2+x_3+t^4\\tx_3'=-x_1+x_2+3x_3+t^3e^t\end{cases}$ and $2$ solutions of the system $$u_{(1)}=\begin{pmatrix}(a+b)t^2\\at^2\\bt^2\end{pmatrix},\quad u_{(2)}=\begin{pmatrix}2\ln t+1\\ \ln t+1\\\ln t+1\end{pmatrix}$$ What is the system's general solution ? Attempt I think it is quite clear that some sort of parameters variation is required due to given solutions. The only problem is that I am not sure how to approach this solution. I tried to develop some sort of a matrix  $$\psi(t)=\begin{pmatrix}(a+b)t^2&2\ln t+1\\at^2&\ln t+1\\bt^2&\ln t+1\end{pmatrix}$$ such that for some $v=\begin{pmatrix}v_1\\v_2\\v_3\end{pmatrix}$ fulfills $\psi(t)v'(t)=\begin{pmatrix}t^2e^t\\t^3\\t^2e^t\end{pmatrix}$; the same method we solve linear ode systems, but clearly this matrix multipication is undefined. How should I approach this? Thank you very much!","Given the following ode system $\begin{cases}tx_1'=2x_2+2x_3+t^3e^t\\tx_2'=-x_1+3x_2+x_3+t^4\\tx_3'=-x_1+x_2+3x_3+t^3e^t\end{cases}$ and $2$ solutions of the system $$u_{(1)}=\begin{pmatrix}(a+b)t^2\\at^2\\bt^2\end{pmatrix},\quad u_{(2)}=\begin{pmatrix}2\ln t+1\\ \ln t+1\\\ln t+1\end{pmatrix}$$ What is the system's general solution ? Attempt I think it is quite clear that some sort of parameters variation is required due to given solutions. The only problem is that I am not sure how to approach this solution. I tried to develop some sort of a matrix  $$\psi(t)=\begin{pmatrix}(a+b)t^2&2\ln t+1\\at^2&\ln t+1\\bt^2&\ln t+1\end{pmatrix}$$ such that for some $v=\begin{pmatrix}v_1\\v_2\\v_3\end{pmatrix}$ fulfills $\psi(t)v'(t)=\begin{pmatrix}t^2e^t\\t^3\\t^2e^t\end{pmatrix}$; the same method we solve linear ode systems, but clearly this matrix multipication is undefined. How should I approach this? Thank you very much!",,['ordinary-differential-equations']
36,Is it possible to solve this ODE by separation of variables?,Is it possible to solve this ODE by separation of variables?,,Consider the equation $ydx +3xdy =14y^4dy$. Is there a clever trick which would allow to solve this equation by the method of separation of variables?,Consider the equation $ydx +3xdy =14y^4dy$. Is there a clever trick which would allow to solve this equation by the method of separation of variables?,,['ordinary-differential-equations']
37,Solve $f''(x) = \cos (f(x))$,Solve,f''(x) = \cos (f(x)),"I wanted to solve the differential equation : $$\frac{d^2y}{dx^2} = \cos y$$ I know how to solve it if it was a first derivative ($y'=\cos y $), But I have no intuition on this one. Either an explicit or an implicit relation is good for me,  but I was more curious about the process than the answer, as I am generally stuck at second derivatives in differential equations.","I wanted to solve the differential equation : $$\frac{d^2y}{dx^2} = \cos y$$ I know how to solve it if it was a first derivative ($y'=\cos y $), But I have no intuition on this one. Either an explicit or an implicit relation is good for me,  but I was more curious about the process than the answer, as I am generally stuck at second derivatives in differential equations.",,['ordinary-differential-equations']
38,Proof by contradiction that there are no periodic solutions to $\dot x =f(x)$,Proof by contradiction that there are no periodic solutions to,\dot x =f(x),"I need to finish the proof (by contradiction) that there do not exist any periodic (oscillating) solutions to the system $\dot x =f(x)$. The proof starts out as follows: Suppose on the contrary that $x(t)$ is a nontrivial periodic solution - I.e., that $x(t)=x(t+T)$ for some $T>0$ and $x(t)\neq x(t+s)$ for all $0<s<t$. I'm supposed to derive a contradiction by considering $$ \int_{t}^{t+T}f(x)\frac{dx}{dt}dt$$ I saw a solution where the person said that $$\int_{t}^{t+T}f(x)\frac{dx}{dt}dt = \int_{x(t)}^{x(t+T)}f(x)dx=0$$ and i do not understand why that's true. Next, they said that $$\int_{t}^{t+T}f(x)\frac{dx}{dt}dt=\int_{t}^{t+T}f(x)^2 dt \geq 0, \quad \text{for}\, t^{*}\in (t, T+t)$$ which I also don't understand. And finally, they said that this tells us that $f(x(t^{*}))=0$, which implies that the only solution is the trivial solution. Now, I am not sure how those two things imply that $f(x(t^{*}))=0$, and then how that in turn implies that the only solution is the trivial solution. Im assuming that all of these steps come perhaps from some form of the fundamental theorem of calculus, but I'm not exactly sure how it allows us to do these things. So, if someone could please explain these steps to me, I would appreciate it very much. Note : I am not at all interested in alternative proofs for this result. They exist already aplenty on MSE for someone who is interested to find them. I am interested only in finishing/understanding the proof the way it is presented here.","I need to finish the proof (by contradiction) that there do not exist any periodic (oscillating) solutions to the system $\dot x =f(x)$. The proof starts out as follows: Suppose on the contrary that $x(t)$ is a nontrivial periodic solution - I.e., that $x(t)=x(t+T)$ for some $T>0$ and $x(t)\neq x(t+s)$ for all $0<s<t$. I'm supposed to derive a contradiction by considering $$ \int_{t}^{t+T}f(x)\frac{dx}{dt}dt$$ I saw a solution where the person said that $$\int_{t}^{t+T}f(x)\frac{dx}{dt}dt = \int_{x(t)}^{x(t+T)}f(x)dx=0$$ and i do not understand why that's true. Next, they said that $$\int_{t}^{t+T}f(x)\frac{dx}{dt}dt=\int_{t}^{t+T}f(x)^2 dt \geq 0, \quad \text{for}\, t^{*}\in (t, T+t)$$ which I also don't understand. And finally, they said that this tells us that $f(x(t^{*}))=0$, which implies that the only solution is the trivial solution. Now, I am not sure how those two things imply that $f(x(t^{*}))=0$, and then how that in turn implies that the only solution is the trivial solution. Im assuming that all of these steps come perhaps from some form of the fundamental theorem of calculus, but I'm not exactly sure how it allows us to do these things. So, if someone could please explain these steps to me, I would appreciate it very much. Note : I am not at all interested in alternative proofs for this result. They exist already aplenty on MSE for someone who is interested to find them. I am interested only in finishing/understanding the proof the way it is presented here.",,"['calculus', 'ordinary-differential-equations']"
39,Solve the differential equation $\frac{\mathrm{d}y}{\mathrm{d}x} = \cos(x+y) + \sin(x+y)$,Solve the differential equation,\frac{\mathrm{d}y}{\mathrm{d}x} = \cos(x+y) + \sin(x+y),"Problem: Solve the differential equation,$$\frac{\mathrm{d}y}{\mathrm{d}x}   =\cos(x+y) + \sin(x+y)$$ My attempt at the problem: $$\frac{\mathrm{d}y}{\mathrm{d}x}   =\cos(x+y) + \sin(x+y)=\cos(x+y)\biggr(1+\tan(x+y)\biggr)$$ Now let, $$\cos(x+y)=u$$ So that, $$\frac{\mathrm{d}y}{\mathrm{d}x}   = u(1+\sqrt{\frac{1}{u^2}-1})$$ using    $\tan^2A = \sec^2A - 1$ Also, $$\frac{\mathrm{d}(\cos(x+y))}{\mathrm{d}x}   = -\sin(x+y)\biggr(1 + \frac{\mathrm{d}y}{\mathrm{d}x} \biggr) $$ and $$\frac{\mathrm{d}u}{\mathrm{d}x}   = -\sqrt{1-u^2}\biggr(1 + \frac{\mathrm{d}y}{\mathrm{d}x} \biggr)$$ Solving for $\frac{\mathrm{d}y}{\mathrm{d}x}$ and plugging it in the problem gives a very ugly integral upon separating variables $$\int{\mathrm{d}x} = - \int \frac{\mathrm{d}u}{\biggr((u+1)+\sqrt{1-u^2}\biggr)\sqrt{1-u^2}}$$ I just can't solve it any further. Please correct me if I'm wrong or please direct me towards an alternate solution. All help appreciated!","Problem: Solve the differential equation,$$\frac{\mathrm{d}y}{\mathrm{d}x}   =\cos(x+y) + \sin(x+y)$$ My attempt at the problem: $$\frac{\mathrm{d}y}{\mathrm{d}x}   =\cos(x+y) + \sin(x+y)=\cos(x+y)\biggr(1+\tan(x+y)\biggr)$$ Now let, $$\cos(x+y)=u$$ So that, $$\frac{\mathrm{d}y}{\mathrm{d}x}   = u(1+\sqrt{\frac{1}{u^2}-1})$$ using    $\tan^2A = \sec^2A - 1$ Also, $$\frac{\mathrm{d}(\cos(x+y))}{\mathrm{d}x}   = -\sin(x+y)\biggr(1 + \frac{\mathrm{d}y}{\mathrm{d}x} \biggr) $$ and $$\frac{\mathrm{d}u}{\mathrm{d}x}   = -\sqrt{1-u^2}\biggr(1 + \frac{\mathrm{d}y}{\mathrm{d}x} \biggr)$$ Solving for $\frac{\mathrm{d}y}{\mathrm{d}x}$ and plugging it in the problem gives a very ugly integral upon separating variables $$\int{\mathrm{d}x} = - \int \frac{\mathrm{d}u}{\biggr((u+1)+\sqrt{1-u^2}\biggr)\sqrt{1-u^2}}$$ I just can't solve it any further. Please correct me if I'm wrong or please direct me towards an alternate solution. All help appreciated!",,"['calculus', 'integration', 'ordinary-differential-equations']"
40,"Let $\dot x=f(x), x(0)=x_0$ an initial value problem. Show that if $f\in C^1(\Bbb R)$ the solution is unique",Let  an initial value problem. Show that if  the solution is unique,"\dot x=f(x), x(0)=x_0 f\in C^1(\Bbb R)","Let $\dot x=f(x), x(0)=x_0$ an initial value problem. Show that if $f\in C^1(\Bbb R)$ the solution is unique. This is the problem 1.10 of the book ODE and dynamical systems of Teschl. I dont have a clue about how to show it. My work so far: Let $\phi,\psi$ two distinct solutions to the IVP, and we will denote by $I$ it maximal and common interval of existence. Intuitive approach: WLOG exists some $t_1\in I$ (a bifurcation point) and a $\delta>0$ such that $\phi\neq\psi$ in $(t_1,t_1+\delta)$ and they are also injective (what imply that $\dot\phi\neq\dot\psi$ ). From this idea (assuming that it is correct) I dont know exactly how to develop a proof by the contrapositive of the statement to be proved, that is, that under this condition $f\notin C^1(\Bbb R)$ . Some other thoughts related: if $f$ is not continuously differentiable then there are two possible reasons: there is a point where the derivative is not defined, or there is a point where the derivative is not continuous (essential discontinuity). But I dont get any useful idea from here. Some hints will be appreciated, thank you.","Let an initial value problem. Show that if the solution is unique. This is the problem 1.10 of the book ODE and dynamical systems of Teschl. I dont have a clue about how to show it. My work so far: Let two distinct solutions to the IVP, and we will denote by it maximal and common interval of existence. Intuitive approach: WLOG exists some (a bifurcation point) and a such that in and they are also injective (what imply that ). From this idea (assuming that it is correct) I dont know exactly how to develop a proof by the contrapositive of the statement to be proved, that is, that under this condition . Some other thoughts related: if is not continuously differentiable then there are two possible reasons: there is a point where the derivative is not defined, or there is a point where the derivative is not continuous (essential discontinuity). But I dont get any useful idea from here. Some hints will be appreciated, thank you.","\dot x=f(x), x(0)=x_0 f\in C^1(\Bbb R) \phi,\psi I t_1\in I \delta>0 \phi\neq\psi (t_1,t_1+\delta) \dot\phi\neq\dot\psi f\notin C^1(\Bbb R) f",['ordinary-differential-equations']
41,Solution of the Differential equation $ u'(t)=4u^{3/4}(t) $,Solution of the Differential equation, u'(t)=4u^{3/4}(t) ,"Let u(t) be a continuously differentiable function taking nonnegative values for $t\gt 0$ and satisfying $ u'(t)=4u^{3/4}(t) $; $ u(0)=0.\; Then \\ 1. u(t)=0 \\2. u(t)=t^4. \\3. u(t)= \begin{cases} 0 \qquad \qquad for \;\;0\lt t\lt 1 \\ (t-1)^4 \qquad for \;\;t\ge 1. \end{cases}\\4. u(t)=\begin{cases} 0 \qquad \qquad  for \;\;0\lt t\lt 10 \\ (t-10)^4 \qquad for \;\;t\ge 10. \end{cases}  $ My Attempt: given equation $\frac{du}{dt}=4u^{3/4} \\$ By variable seperable method, $\frac{du}{4u^{3/4}}=dt $ On integrating we get $ u^{1/4}=t \Rightarrow u=t^4 $ which gives option 2. But i am not getting the other three solutions. given that all the options are correct. thanks in advance.","Let u(t) be a continuously differentiable function taking nonnegative values for $t\gt 0$ and satisfying $ u'(t)=4u^{3/4}(t) $; $ u(0)=0.\; Then \\ 1. u(t)=0 \\2. u(t)=t^4. \\3. u(t)= \begin{cases} 0 \qquad \qquad for \;\;0\lt t\lt 1 \\ (t-1)^4 \qquad for \;\;t\ge 1. \end{cases}\\4. u(t)=\begin{cases} 0 \qquad \qquad  for \;\;0\lt t\lt 10 \\ (t-10)^4 \qquad for \;\;t\ge 10. \end{cases}  $ My Attempt: given equation $\frac{du}{dt}=4u^{3/4} \\$ By variable seperable method, $\frac{du}{4u^{3/4}}=dt $ On integrating we get $ u^{1/4}=t \Rightarrow u=t^4 $ which gives option 2. But i am not getting the other three solutions. given that all the options are correct. thanks in advance.",,['ordinary-differential-equations']
42,"If functions are linearly independent for one $x\in I$, are they linearly independent for all $x\in I$?","If functions are linearly independent for one , are they linearly independent for all ?",x\in I x\in I,"This theorem comes up when talking about ordinary differential equations. Basically, if we have a fundamental system, i.e. a basis $B=(f_1,f_2,...,f_n)$ of the vector space of solutions for a differential equation $$y'=A(x)y$$, we can check for linear independence ( if we are unsure if it really is a basis ) by checking that  $$(f_1(x_0),f_2(x_0),...,f_n(x_0))$$ is linearly independent for some $x_0 \in I$. The theorem says that if they are linearly independent for some $x_0 \in I$, that's equivalent to them being linearly independent for all $x \in I$. The proof is omitted, because this equivalence is supposed to be trivial, says the author of the textbook. Could you explain why the implication from some to all holds true? I'd actually think there would be functions for which there is an $x\in I$ where all the functions happen to be zero, and then you can find coefficients which are non-zero so that you can say $$ c_1 * f_1(x) + ... + c_n * f_n(x) = 0$$ $c\in \mathbb{R}$, but why does this imply that they must be linearly independent for all $x$?","This theorem comes up when talking about ordinary differential equations. Basically, if we have a fundamental system, i.e. a basis $B=(f_1,f_2,...,f_n)$ of the vector space of solutions for a differential equation $$y'=A(x)y$$, we can check for linear independence ( if we are unsure if it really is a basis ) by checking that  $$(f_1(x_0),f_2(x_0),...,f_n(x_0))$$ is linearly independent for some $x_0 \in I$. The theorem says that if they are linearly independent for some $x_0 \in I$, that's equivalent to them being linearly independent for all $x \in I$. The proof is omitted, because this equivalence is supposed to be trivial, says the author of the textbook. Could you explain why the implication from some to all holds true? I'd actually think there would be functions for which there is an $x\in I$ where all the functions happen to be zero, and then you can find coefficients which are non-zero so that you can say $$ c_1 * f_1(x) + ... + c_n * f_n(x) = 0$$ $c\in \mathbb{R}$, but why does this imply that they must be linearly independent for all $x$?",,"['linear-algebra', 'ordinary-differential-equations']"
43,Find all solutions of $(xy^2+x)dx+(y-x^2y)dy=0$,Find all solutions of,(xy^2+x)dx+(y-x^2y)dy=0,"Find all solutions of $$(xy^2+x)dx+(y-x^2y)dy=0$$ What I know is that: Assuming $M=xy^2+x, N=y-x^2y$ then if $xN+yM\neq0$ then solution of above equation is unique for every point. In our case it is true when $x\neq0$ or $y\neq0$. However I do not know how to continue this one. Well, what I've written above is not true because $M,N$ are not homogeneous.","Find all solutions of $$(xy^2+x)dx+(y-x^2y)dy=0$$ What I know is that: Assuming $M=xy^2+x, N=y-x^2y$ then if $xN+yM\neq0$ then solution of above equation is unique for every point. In our case it is true when $x\neq0$ or $y\neq0$. However I do not know how to continue this one. Well, what I've written above is not true because $M,N$ are not homogeneous.",,['ordinary-differential-equations']
44,Find the solution to the Integral Equation:,Find the solution to the Integral Equation:,,"Find the solution to the Integral Equation: $\phi(x)=x+\int _0^x \sin (x-t)\phi(t) dt $ The solution is given as $x+\dfrac{x^3}{3!}$ . My try : $K(x,t)=\sin (x-t)=K_1(x,t)$ ; $K_n(x,t)=\int _t^x K(x,z) K_{n-1}( z,t) dz$ ; I got $K_2(x,t)=\sin(-x-t)-\sin (x-3t)-(x-t)\cos (x-t)$ . So it's getting difficult.I am appearing for an exam where the time given will be small for this 1 mark question. Is there any easy way to do this?",Find the solution to the Integral Equation: The solution is given as . My try : ; ; I got . So it's getting difficult.I am appearing for an exam where the time given will be small for this 1 mark question. Is there any easy way to do this?,"\phi(x)=x+\int _0^x \sin (x-t)\phi(t) dt  x+\dfrac{x^3}{3!} K(x,t)=\sin (x-t)=K_1(x,t) K_n(x,t)=\int _t^x K(x,z) K_{n-1}( z,t) dz K_2(x,t)=\sin(-x-t)-\sin (x-3t)-(x-t)\cos (x-t)","['integration', 'ordinary-differential-equations']"
45,How to get solutions in elementary functions to the following non-linear ODE,How to get solutions in elementary functions to the following non-linear ODE,,$y\frac{\text{d}^2y}{\text{d}x^2}-2\left(\frac{\text{d}y}{\text{d}x}\right)^2+xy^3\frac{\text{d}y}{\text{d}x}=0$. I want to get solution in elementary functions in order to do asymptotic analysis. I tried the problem with Mathematica. It did not give any solutions.,$y\frac{\text{d}^2y}{\text{d}x^2}-2\left(\frac{\text{d}y}{\text{d}x}\right)^2+xy^3\frac{\text{d}y}{\text{d}x}=0$. I want to get solution in elementary functions in order to do asymptotic analysis. I tried the problem with Mathematica. It did not give any solutions.,,['ordinary-differential-equations']
46,How to solve $x'^2-1-2xx''=0$,How to solve,x'^2-1-2xx''=0,Find the general solution of:   $$(x')^2-1-2xx''=0$$ Is there a well-known technique for solving  this ODE?,Find the general solution of:   $$(x')^2-1-2xx''=0$$ Is there a well-known technique for solving  this ODE?,,['ordinary-differential-equations']
47,Fourier Series of $\cos(ax)$,Fourier Series of,\cos(ax),"I would like to ask some help on this problem.. 01) Expand the following function in fourier series. $f(x)=cosax,−π<x<π$ where '$a$' is not an integer. Hence, Show that $\frac{1}{sint} = \frac{1}{t} + \sum_{n=0}^{\infty}(-1)^{n}\left \{ \frac{1}{t-n\pi} + \frac{1}{t+ n\pi}\right \}$ Where '$t$' is any number which is not an integer multiple of $\pi$ Someone please show me some work done and steps to solve it so that I can understand better. I'm a beginner in Fourier series part.","I would like to ask some help on this problem.. 01) Expand the following function in fourier series. $f(x)=cosax,−π<x<π$ where '$a$' is not an integer. Hence, Show that $\frac{1}{sint} = \frac{1}{t} + \sum_{n=0}^{\infty}(-1)^{n}\left \{ \frac{1}{t-n\pi} + \frac{1}{t+ n\pi}\right \}$ Where '$t$' is any number which is not an integer multiple of $\pi$ Someone please show me some work done and steps to solve it so that I can understand better. I'm a beginner in Fourier series part.",,"['ordinary-differential-equations', 'fourier-series']"
48,solve differential equation $y'' = 1+ y'^2$,solve differential equation,y'' = 1+ y'^2,"Solve $$y'' = 1+ y'^2$$ My attempt, let $p = y'$, $$ y''= \frac{dy'}{dx} = \frac{dp}{dy} \frac{dy}{dx} = p \frac{dp}{dy}$$ $$ p \frac{dp}{dy}=1+p^2$$ $$ \int \frac p{1+p^2} dp = \int dy $$ $$ \frac12 ln(1+p^2) = y + ln c_1,\ \sqrt{1+p^2} = c_1 e^y $$ $$ |p|=\sqrt{(c_1 e^y)^2 - 1}$$ I don't know how to continue to solve $ \frac{dy}{dx} = \pm \sqrt{(c_1 e^y)^2 - 1}$?","Solve $$y'' = 1+ y'^2$$ My attempt, let $p = y'$, $$ y''= \frac{dy'}{dx} = \frac{dp}{dy} \frac{dy}{dx} = p \frac{dp}{dy}$$ $$ p \frac{dp}{dy}=1+p^2$$ $$ \int \frac p{1+p^2} dp = \int dy $$ $$ \frac12 ln(1+p^2) = y + ln c_1,\ \sqrt{1+p^2} = c_1 e^y $$ $$ |p|=\sqrt{(c_1 e^y)^2 - 1}$$ I don't know how to continue to solve $ \frac{dy}{dx} = \pm \sqrt{(c_1 e^y)^2 - 1}$?",,"['integration', 'ordinary-differential-equations']"
49,Motivating $y'=y \implies y=Ce^x$,Motivating,y'=y \implies y=Ce^x,"Is there some intuitive reason why one should think that a function which is its own derivative should be of the form $Ca^x$ for some number $a$?  Of course I can prove that the unique solution set to $f'(x) = f(x)$ is the set $\{f\mid f(x) = Ce^x\}$, but pretending I don't know this, what would be a good rationale for checking a function of this type?","Is there some intuitive reason why one should think that a function which is its own derivative should be of the form $Ca^x$ for some number $a$?  Of course I can prove that the unique solution set to $f'(x) = f(x)$ is the set $\{f\mid f(x) = Ce^x\}$, but pretending I don't know this, what would be a good rationale for checking a function of this type?",,"['calculus', 'ordinary-differential-equations', 'intuition']"
50,Difference between two solution of inhomogeneous linear equation,Difference between two solution of inhomogeneous linear equation,,"Show that the difference between two solutions of an inhomogeneous linear equation $Lu =g$ with the same $g$ is the solution of the homogenous equation $Lu=0$ I know the definition of linearity, but how can I use it to show they have the same solution. Can someone please help me with it.","Show that the difference between two solutions of an inhomogeneous linear equation $Lu =g$ with the same $g$ is the solution of the homogenous equation $Lu=0$ I know the definition of linearity, but how can I use it to show they have the same solution. Can someone please help me with it.",,"['ordinary-differential-equations', 'partial-differential-equations']"
51,Which of these 1-D representations of the Navier-Stokes equations is correct?,Which of these 1-D representations of the Navier-Stokes equations is correct?,,The incompressible Navier Stokes equations can be written as A. $$\frac{\partial (\rho \mathbf{v})}{\partial t} + \nabla \cdot (\rho \mathbf{v} \mathbf{v}) = S$$ or B . $$\frac{\partial \mathbf{v}}{\partial t} + (\mathbf{v} \cdot \nabla) \mathbf{v} = \frac{S}{\rho}$$ where $S$ is some source term. But it seems these not the same in 1-d...? A. $$\frac{\partial (\rho v)}{\partial t} + \frac{\partial (\rho v^2)}{\partial z}= S$$ $$\frac{\partial (\rho v)}{\partial t} + \rho\frac{\partial v^2}{\partial z} + v^2\frac{\partial \rho}{\partial z}= S$$ Let $\rho = 1$ $$\frac{\partial v}{\partial t} + \frac{\partial v^2}{\partial z} = S$$ $$\frac{\partial v}{\partial t} + 2v\frac{\partial v}{\partial z} = S$$ is not the same as B. $$\frac{\partial v}{\partial t} + v\frac{\partial v}{\partial z} = \frac{S}{\rho}$$ Let $\rho = 1$ $$\frac{\partial v}{\partial t} + v\frac{\partial v}{\partial z} = S$$ So what am I missing? Which version is correct?,The incompressible Navier Stokes equations can be written as A. $$\frac{\partial (\rho \mathbf{v})}{\partial t} + \nabla \cdot (\rho \mathbf{v} \mathbf{v}) = S$$ or B . $$\frac{\partial \mathbf{v}}{\partial t} + (\mathbf{v} \cdot \nabla) \mathbf{v} = \frac{S}{\rho}$$ where $S$ is some source term. But it seems these not the same in 1-d...? A. $$\frac{\partial (\rho v)}{\partial t} + \frac{\partial (\rho v^2)}{\partial z}= S$$ $$\frac{\partial (\rho v)}{\partial t} + \rho\frac{\partial v^2}{\partial z} + v^2\frac{\partial \rho}{\partial z}= S$$ Let $\rho = 1$ $$\frac{\partial v}{\partial t} + \frac{\partial v^2}{\partial z} = S$$ $$\frac{\partial v}{\partial t} + 2v\frac{\partial v}{\partial z} = S$$ is not the same as B. $$\frac{\partial v}{\partial t} + v\frac{\partial v}{\partial z} = \frac{S}{\rho}$$ Let $\rho = 1$ $$\frac{\partial v}{\partial t} + v\frac{\partial v}{\partial z} = S$$ So what am I missing? Which version is correct?,,"['ordinary-differential-equations', 'partial-differential-equations', 'fluid-dynamics']"
52,How to construct first order differential equation that solution would be $y=(x+C)^2$,How to construct first order differential equation that solution would be,y=(x+C)^2,please help. I have no clue how to construct first order diff. equation when the solution is already given $y=(x+C)^2$. Though I can do it vice versa. I just need some hints.,please help. I have no clue how to construct first order diff. equation when the solution is already given $y=(x+C)^2$. Though I can do it vice versa. I just need some hints.,,['ordinary-differential-equations']
53,$f(x) = x \tan^{-1}(x\ln(x))$ find $f'(e)$,find,f(x) = x \tan^{-1}(x\ln(x)) f'(e),$f(x) = x \tan^{-1}(x\ln(x))$ find $f'(e)$ my work $f'(x)=\tan^{-1}(x\ln(x)) *1 + x$ ---> stack here I know $\tan^{-1}(x)'=  \frac{1}{1+x^2}$ so $\tan^{-1}(x\ln(x)) = ???$ I need help to solve that question please,$f(x) = x \tan^{-1}(x\ln(x))$ find $f'(e)$ my work $f'(x)=\tan^{-1}(x\ln(x)) *1 + x$ ---> stack here I know $\tan^{-1}(x)'=  \frac{1}{1+x^2}$ so $\tan^{-1}(x\ln(x)) = ???$ I need help to solve that question please,,"['calculus', 'ordinary-differential-equations']"
54,Finding particular solution to $y'' + 2y' - 8y = e^{2x} $,Finding particular solution to,y'' + 2y' - 8y = e^{2x} ,$$y'' + 2y' - 8y = e^{2x} $$ How do I find the particular solution? I tried setting: $y = Ae^{2x} => y' = 2Ae^{2x} => y''= 4Ae^{2x}$ If I substitute I get: $4Ae^{2x} + 4Ae^{2x} - 8Ae^{2x} = e^{2x} => 0 = e^{2x}$ What am I doing wrong?,$$y'' + 2y' - 8y = e^{2x} $$ How do I find the particular solution? I tried setting: $y = Ae^{2x} => y' = 2Ae^{2x} => y''= 4Ae^{2x}$ If I substitute I get: $4Ae^{2x} + 4Ae^{2x} - 8Ae^{2x} = e^{2x} => 0 = e^{2x}$ What am I doing wrong?,,['ordinary-differential-equations']
55,What is the tip for this exact differential equation?,What is the tip for this exact differential equation?,,$$ xdx + ydy = \frac{xdy - ydx}{x^2 + y^2} $$ I have multiplied the left part $x^2+y^2$ for $x dx + y dy$ getting $$(x^3+xy^2+y)dx+(x^2y+y^3-x)dy=0$$ And the derivative test give me: $\frac{dM}{dy}= 0+2xy+1$ and $\frac{dN}{dx} = 2xy+0-1$. Where´s my mistake?,$$ xdx + ydy = \frac{xdy - ydx}{x^2 + y^2} $$ I have multiplied the left part $x^2+y^2$ for $x dx + y dy$ getting $$(x^3+xy^2+y)dx+(x^2y+y^3-x)dy=0$$ And the derivative test give me: $\frac{dM}{dy}= 0+2xy+1$ and $\frac{dN}{dx} = 2xy+0-1$. Where´s my mistake?,,['ordinary-differential-equations']
56,Non-linear (?) differential equation,Non-linear (?) differential equation,,"I'm walking through differential equations on my own, but I found example which make me stop for some time. $$(t^{2} - y^{2}) \cdot y' = 2ty$$ Any help would be appreciated - is this any special method for particular kind of square equations? Cheers!","I'm walking through differential equations on my own, but I found example which make me stop for some time. $$(t^{2} - y^{2}) \cdot y' = 2ty$$ Any help would be appreciated - is this any special method for particular kind of square equations? Cheers!",,['ordinary-differential-equations']
57,How to solve the differential equation $(2xy^2-y){dx}+(y^2+x+y){dy}=0$? [closed],How to solve the differential equation ? [closed],(2xy^2-y){dx}+(y^2+x+y){dy}=0,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I'm weak at solving equations like this: $$(2xy^2-y){dx}+(y^2+x+y){dy}=0$$ Please show how to complete equation, so that it becomes exact. Thank you for help in advance.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I'm weak at solving equations like this: $$(2xy^2-y){dx}+(y^2+x+y){dy}=0$$ Please show how to complete equation, so that it becomes exact. Thank you for help in advance.",,['ordinary-differential-equations']
58,Exponential of matrix,Exponential of matrix,,"So, I'm wondering if there is an easy way (as in not calculating the eigenvalues, Jordan canonical form, change of basis matrix, etc.) to calculate this exponential $e^{At}$ with $$A=\begin{pmatrix} 0&9 \\ -1&0 \end{pmatrix}.$$ I'd suppose it stumbles around cosines and sines, but I'm not really sure... In fact, something of the kind $$A=\begin{pmatrix} 3 & 5\cr-5 & -3\end{pmatrix}$$ would also interest me.","So, I'm wondering if there is an easy way (as in not calculating the eigenvalues, Jordan canonical form, change of basis matrix, etc.) to calculate this exponential $e^{At}$ with $$A=\begin{pmatrix} 0&9 \\ -1&0 \end{pmatrix}.$$ I'd suppose it stumbles around cosines and sines, but I'm not really sure... In fact, something of the kind $$A=\begin{pmatrix} 3 & 5\cr-5 & -3\end{pmatrix}$$ would also interest me.",,"['matrices', 'ordinary-differential-equations', 'exponential-function']"
59,"high order DE :$y''''+y'''=1-x^2\,e^{-x}$",high order DE :,"y''''+y'''=1-x^2\,e^{-x}","I am doing some exercise and I got to this question: SOLVE:  $ y''''+y'''=1-x^2e^{-x}$, the associated homegeneous eqation  solution is simple to calculate that is, $y_h=c_1+c_2x+c_3x^2+c_4e^{-x}$ However, when it comes to particular solution ,it is really trivial and hard. can anyone teach me how to solve the problem in the easiet way?that is ,solve the problem as quick as possible","I am doing some exercise and I got to this question: SOLVE:  $ y''''+y'''=1-x^2e^{-x}$, the associated homegeneous eqation  solution is simple to calculate that is, $y_h=c_1+c_2x+c_3x^2+c_4e^{-x}$ However, when it comes to particular solution ,it is really trivial and hard. can anyone teach me how to solve the problem in the easiet way?that is ,solve the problem as quick as possible",,['ordinary-differential-equations']
60,Find the differential equation given the general solution,Find the differential equation given the general solution,,"Given that $x(t)=(c_1+c_2 t + c_3 t^2)e^t$ is the general solution to a differential equation, how do you work backwards to find the differential equation?","Given that $x(t)=(c_1+c_2 t + c_3 t^2)e^t$ is the general solution to a differential equation, how do you work backwards to find the differential equation?",,['ordinary-differential-equations']
61,Prove second derivative of $g$ is proportional to $g^2$,Prove second derivative of  is proportional to,g g^2,"From Apostol's Calculus Vol. 1, chapter 6.26, exercise 30: Let $f(x) = \int_0^x (1+t^3)^{-1/2} dt$. $a)$ Prove $f$ is strictly monotonic. $b)$ Let $g$ be the inverse of $f$.  Show that the second derivative of $g$ is proportional to $g^2$ and find the constant of proportionality $c$. The first part is simple, since the derivative is $( 1+x^3 )^{-1/2} > 0$ if $x \ge 0$. However, I'm having a lot of difficulty with the second part.  Since $g' = 1 / f'$, I calculated that $g''(x) = - \frac{3x^2}{2(1+x^3)^{3/2}}$.  However, this doesn't seem to get us any closer to finding the constant of proportionality since it doesn't seem at all obvious how to calculate $g$. I also tried applying the chain rule so that $g''(x) = - f''(x) / f'(x)^2 = - f''(x) g'(x)^2$.  Again, this expression doesn't seem to bring us any closer to solving the problem, since we are again left with the problem of calculating $g$, or at least $g^2$, in terms of $f''$ and $g'$. So how can these equations be manipulated so that we arrive at $g''(x) = cg^2(x)$?","From Apostol's Calculus Vol. 1, chapter 6.26, exercise 30: Let $f(x) = \int_0^x (1+t^3)^{-1/2} dt$. $a)$ Prove $f$ is strictly monotonic. $b)$ Let $g$ be the inverse of $f$.  Show that the second derivative of $g$ is proportional to $g^2$ and find the constant of proportionality $c$. The first part is simple, since the derivative is $( 1+x^3 )^{-1/2} > 0$ if $x \ge 0$. However, I'm having a lot of difficulty with the second part.  Since $g' = 1 / f'$, I calculated that $g''(x) = - \frac{3x^2}{2(1+x^3)^{3/2}}$.  However, this doesn't seem to get us any closer to finding the constant of proportionality since it doesn't seem at all obvious how to calculate $g$. I also tried applying the chain rule so that $g''(x) = - f''(x) / f'(x)^2 = - f''(x) g'(x)^2$.  Again, this expression doesn't seem to bring us any closer to solving the problem, since we are again left with the problem of calculating $g$, or at least $g^2$, in terms of $f''$ and $g'$. So how can these equations be manipulated so that we arrive at $g''(x) = cg^2(x)$?",,"['calculus', 'ordinary-differential-equations']"
62,How to solve $tx''-x'-4t^3x=0$,How to solve,tx''-x'-4t^3x=0,Solve $$tx''-x'-4t^3x=0$$ I came across this example and it seems difficult to me. Any hints on how to start solving it?,Solve $$tx''-x'-4t^3x=0$$ I came across this example and it seems difficult to me. Any hints on how to start solving it?,,['ordinary-differential-equations']
63,Asymptotic Behavior of the solution of the DE $y'=-2-y+t$ for $t \to \infty$,Asymptotic Behavior of the solution of the DE  for,y'=-2-y+t t \to \infty,"I'm new to differential equations, so any help will be grateful. I've been looking at this problem: Examine the slope field of the following differential equation. Based on the direction field, determine the behavior of $y$ as $t→∞$.   $$y' = -2 -y + t$$ After plotting the slope field, I could not seem to deduce anything, so curiously, I looked at the solution and this is what it stated: y is asymptotic to $t − 3$ as $t→∞$. Could someone explain to me what they mean by ""asymptotic to ..."" My textbook didn't give me an example regarding this type of question so I do not understand what it means. NOTE I've noticed that the solution to this differential equation is: $$y = c_1e^{-t} + t -3$$ $t-3$ is apparent in the solution. Could this be in connection with the solution that they provided? Again help will be appreciated. Thanks in advance.","I'm new to differential equations, so any help will be grateful. I've been looking at this problem: Examine the slope field of the following differential equation. Based on the direction field, determine the behavior of $y$ as $t→∞$.   $$y' = -2 -y + t$$ After plotting the slope field, I could not seem to deduce anything, so curiously, I looked at the solution and this is what it stated: y is asymptotic to $t − 3$ as $t→∞$. Could someone explain to me what they mean by ""asymptotic to ..."" My textbook didn't give me an example regarding this type of question so I do not understand what it means. NOTE I've noticed that the solution to this differential equation is: $$y = c_1e^{-t} + t -3$$ $t-3$ is apparent in the solution. Could this be in connection with the solution that they provided? Again help will be appreciated. Thanks in advance.",,"['ordinary-differential-equations', 'asymptotics']"
64,Linearize a first order differential equation,Linearize a first order differential equation,,The system described by $x'=2x^2-8$ is linearized about the equilibrium point -2. What is the  resulting linearized equation? Answer is $x'=-8x-16$. How? I have no idea how it went from the first equation to the 2nd. Thanks.,The system described by $x'=2x^2-8$ is linearized about the equilibrium point -2. What is the  resulting linearized equation? Answer is $x'=-8x-16$. How? I have no idea how it went from the first equation to the 2nd. Thanks.,,['ordinary-differential-equations']
65,Solving $\frac{\partial z}{\partial x} + \frac{\partial z}{\partial y} = 0$ by changing variables,Solving  by changing variables,\frac{\partial z}{\partial x} + \frac{\partial z}{\partial y} = 0,Transform the differential equation $\frac{\partial z}{\partial x} + \frac{\partial z}{\partial y} = 0 $ by introducing new variables $x = u+v$ and $y=u-v$. then solve it. I which I could show some effort but I don't even know where to start and I can't find anything about this in my course literature (the subject is very basic multi-variable calculus and I found the question in an old exam). Could anyone show me how to solve this?,Transform the differential equation $\frac{\partial z}{\partial x} + \frac{\partial z}{\partial y} = 0 $ by introducing new variables $x = u+v$ and $y=u-v$. then solve it. I which I could show some effort but I don't even know where to start and I can't find anything about this in my course literature (the subject is very basic multi-variable calculus and I found the question in an old exam). Could anyone show me how to solve this?,,"['ordinary-differential-equations', 'multivariable-calculus', 'partial-differential-equations']"
66,On integration when solving differential equations (specifically separable equations),On integration when solving differential equations (specifically separable equations),,"So here is the differential equation and inititial conditions: $$x \frac{\mathrm{d}y}{\mathrm{d}x}=y(3−y) $$ and $$y(2) = 2$$ We have to find the equation $y$ in terms of $x ~~[y(x)]$ that is a solution to this differential equation. Note: Question taken from: Differential equation . My question essentially is: can someone explain to me, in a conceptual intuitive sense, why we integrate from $2$ to $x$ in the following derivation? So it is can be algebraically manipulated into: $$ \frac{1}{x}~\mathrm{d}x= \frac{1}{y(3−y)}~\mathrm{d}y $$ Then integrated as: $$\int_2^x \frac{1}{x}~\mathrm{d}x= \int_2^x \frac{1}{y(3−y)}~\mathrm{d}y $$ Which is simplified to $$x^3 = \frac{4y}{3-y}$$The implicit solution. And then $y$ is isolated and we get: $$ y(x) = \frac{3x^3}{4+x^3} $$ Now, as stated at the top, can someone explain to me, in a conceptual intuitive sense, why we integrate from $2$ to $x$?","So here is the differential equation and inititial conditions: $$x \frac{\mathrm{d}y}{\mathrm{d}x}=y(3−y) $$ and $$y(2) = 2$$ We have to find the equation $y$ in terms of $x ~~[y(x)]$ that is a solution to this differential equation. Note: Question taken from: Differential equation . My question essentially is: can someone explain to me, in a conceptual intuitive sense, why we integrate from $2$ to $x$ in the following derivation? So it is can be algebraically manipulated into: $$ \frac{1}{x}~\mathrm{d}x= \frac{1}{y(3−y)}~\mathrm{d}y $$ Then integrated as: $$\int_2^x \frac{1}{x}~\mathrm{d}x= \int_2^x \frac{1}{y(3−y)}~\mathrm{d}y $$ Which is simplified to $$x^3 = \frac{4y}{3-y}$$The implicit solution. And then $y$ is isolated and we get: $$ y(x) = \frac{3x^3}{4+x^3} $$ Now, as stated at the top, can someone explain to me, in a conceptual intuitive sense, why we integrate from $2$ to $x$?",,"['calculus', 'integration', 'ordinary-differential-equations', 'derivatives']"
67,Differential equations of the form $\frac{dy}{dt}=ky\left(1-\frac{y}{N(t)}\right)$,Differential equations of the form,\frac{dy}{dt}=ky\left(1-\frac{y}{N(t)}\right),"Is there a general method to solve differential equations of the form $$\frac{dy}{dt}=ky\left(1-\frac{y}{N(t)}\right)$$ where $N(t)$ is a non-constant function? In particular I would be interested in linear, exponential, logarithmic, or polynomial $N(t)$s.","Is there a general method to solve differential equations of the form $$\frac{dy}{dt}=ky\left(1-\frac{y}{N(t)}\right)$$ where $N(t)$ is a non-constant function? In particular I would be interested in linear, exponential, logarithmic, or polynomial $N(t)$s.",,['ordinary-differential-equations']
68,Hint for solving $ y (y')^2 + (x-y) y' - x = 0$,Hint for solving, y (y')^2 + (x-y) y' - x = 0,Need to solve the following ODE: $$ y (y')^2 + (x-y) y' - x = 0$$ I don't really know how to start. Any hints?,Need to solve the following ODE: $$ y (y')^2 + (x-y) y' - x = 0$$ I don't really know how to start. Any hints?,,['ordinary-differential-equations']
69,How to transform a differential equation to a system of differential equations,How to transform a differential equation to a system of differential equations,,Lets say I have a differential equation like $$y''+y+4=0$$ and I have to convert it to a system of first order equations? How is that done. I am interested in the method (and an explanation of it) rather than the answer.,Lets say I have a differential equation like $$y''+y+4=0$$ and I have to convert it to a system of first order equations? How is that done. I am interested in the method (and an explanation of it) rather than the answer.,,['ordinary-differential-equations']
70,Solving $df/dx = x\log x$,Solving,df/dx = x\log x,"I have the following differential equation $$\frac{df}{dx} = Kx\log x,$$ $K$ a constant. I'm wandering how one might solve for $f$.","I have the following differential equation $$\frac{df}{dx} = Kx\log x,$$ $K$ a constant. I'm wandering how one might solve for $f$.",,['ordinary-differential-equations']
71,Particular integral of $\frac{d^2y}{dx^2} - 5\frac{dy}{dx} + 4y = \mathrm{e}^x\ $,Particular integral of,\frac{d^2y}{dx^2} - 5\frac{dy}{dx} + 4y = \mathrm{e}^x\ ,"I need to find the particular integral for the following equation: $\dfrac{d^2y}{dx^2} - 5\dfrac{dy}{dx} + 4y = \mathrm{e}^x\ $ So far I have found that $y = A\mathrm{e}^{4x}+B\mathrm{e}^x $. Then for PI, $y = C\mathrm{e}^x $, $\dfrac{dy}{dx} =C\mathrm{e}^x $, $\dfrac{d^2y}{dx^2}=C\mathrm{e}^x $. But when I tried to substitute this to the equation at the top, the result came out to be $0$. Does this mean $C$ is zero? I was told by my teacher that the answer is not zero and can't seem to find the answer. Many thanks!","I need to find the particular integral for the following equation: $\dfrac{d^2y}{dx^2} - 5\dfrac{dy}{dx} + 4y = \mathrm{e}^x\ $ So far I have found that $y = A\mathrm{e}^{4x}+B\mathrm{e}^x $. Then for PI, $y = C\mathrm{e}^x $, $\dfrac{dy}{dx} =C\mathrm{e}^x $, $\dfrac{d^2y}{dx^2}=C\mathrm{e}^x $. But when I tried to substitute this to the equation at the top, the result came out to be $0$. Does this mean $C$ is zero? I was told by my teacher that the answer is not zero and can't seem to find the answer. Many thanks!",,"['calculus', 'integration', 'ordinary-differential-equations']"
72,"Change of variables of differential equations, and in particular, initial value problems","Change of variables of differential equations, and in particular, initial value problems",,"Consider the following task: Transform the given initial value problem into an equivalent problem with the initial point at the origin: $\frac{dy}{dt} = 4 - y^3$, $y(-1) = 2$ I have a feeling that there is an elementary operation that I have failed to learn during my education, seeing as the text writes: ...if some other initial point is given, then we can always make a preliminary change of variables, corresponding to a translation of the coordinate axes, that will take the given point $(t_0, y_0)$ into the origin. I'd appreciate it if anyone could spoonfeed me on this point, and in particular, describe how one transforms the given problem to $\frac{dw}{ds} = 4 - (w + 2)^3$, $w(0) = 0$","Consider the following task: Transform the given initial value problem into an equivalent problem with the initial point at the origin: $\frac{dy}{dt} = 4 - y^3$, $y(-1) = 2$ I have a feeling that there is an elementary operation that I have failed to learn during my education, seeing as the text writes: ...if some other initial point is given, then we can always make a preliminary change of variables, corresponding to a translation of the coordinate axes, that will take the given point $(t_0, y_0)$ into the origin. I'd appreciate it if anyone could spoonfeed me on this point, and in particular, describe how one transforms the given problem to $\frac{dw}{ds} = 4 - (w + 2)^3$, $w(0) = 0$",,['ordinary-differential-equations']
73,"Characterize the polynomial bijections from $(0,1)$ to$ (0,1)$ [closed]",Characterize the polynomial bijections from  to [closed],"(0,1)  (0,1)","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question That is, show which polynomials, taken as functions, truncated to $(0,1)$, biject with $(0,1)$. I know for the increasing case, it is equivalent to (the derivative is greater than or equal to $0$ on $[0,1]$, $p$ is non-constant, and $p(0)=0$). The problem is with the first part. Bonus: characterize the continuous bijections, or differentiable bijections.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question That is, show which polynomials, taken as functions, truncated to $(0,1)$, biject with $(0,1)$. I know for the increasing case, it is equivalent to (the derivative is greater than or equal to $0$ on $[0,1]$, $p$ is non-constant, and $p(0)=0$). The problem is with the first part. Bonus: characterize the continuous bijections, or differentiable bijections.",,"['linear-algebra', 'ordinary-differential-equations']"
74,How find this ODE:$y''-y'+y=x^2e^x\cos{x}$,How find this ODE:,y''-y'+y=x^2e^x\cos{x},"Find this follow ODe solution $$y''-y'+y=x^2e^x\cos{x}$$ I konw  solve this follow three case $$y''-y'+y=x^2\cos{x}$$ $$y''-y'+y=e^x\cos{x}$$ $$y''-y'+y=x^2e^x$$ But for $f(x)=x^2e^x\cos{x}$, I can't. Thank you  very much!","Find this follow ODe solution $$y''-y'+y=x^2e^x\cos{x}$$ I konw  solve this follow three case $$y''-y'+y=x^2\cos{x}$$ $$y''-y'+y=e^x\cos{x}$$ $$y''-y'+y=x^2e^x$$ But for $f(x)=x^2e^x\cos{x}$, I can't. Thank you  very much!",,[]
75,Solve this differential equation (can't do the integral in the last step),Solve this differential equation (can't do the integral in the last step),,"$\displaystyle{% {\rm y}'\left(x\right) = \sqrt{x\,}\,\, {\rm y}\left(x\right) + {{\rm e}^{x} \over \sqrt{x\,}\,}\,, \qquad{\rm y}\left(0\right) = 2}$ I don't know how to do the integral in the last step.","$\displaystyle{% {\rm y}'\left(x\right) = \sqrt{x\,}\,\, {\rm y}\left(x\right) + {{\rm e}^{x} \over \sqrt{x\,}\,}\,, \qquad{\rm y}\left(0\right) = 2}$ I don't know how to do the integral in the last step.",,['ordinary-differential-equations']
76,Proof: Legendre Polynomials Solving the Corresponding Differential Equation,Proof: Legendre Polynomials Solving the Corresponding Differential Equation,,"In a homework question, we are asked to show that the Legendre polynomials do indeed solve the Legendre Differential Equation: $$ \frac{d}{dx} \left[ (1 - x^2) \frac{d}{dx} P_n(x) \right] + n (n + 1) P_n(x) = 0. $$ According to Wikipedia, it is sufficient to show that after deriving it n+1 times the following equation must hold true: $$ (x^2 - 1) \frac{d}{dx} (x^2 - 1)^n = 2 n x (x^2 - 1)^n. $$ This was also given as a hint in the problem. Since I don't want to blindly accept the hint, I was trying to figure out how it was deduced, but didn't manage to. My question therefore is, how do we arrive at the equation above (the ""hint equation"")? I can see, that the left part of the equation is nearly equal to the first part of the Legendre Differential Equation, except for a missing outer derivative. However, I am somehow missing the steps taken to arrive at the right side: Where does the $2nx$ come from?","In a homework question, we are asked to show that the Legendre polynomials do indeed solve the Legendre Differential Equation: According to Wikipedia, it is sufficient to show that after deriving it n+1 times the following equation must hold true: This was also given as a hint in the problem. Since I don't want to blindly accept the hint, I was trying to figure out how it was deduced, but didn't manage to. My question therefore is, how do we arrive at the equation above (the ""hint equation"")? I can see, that the left part of the equation is nearly equal to the first part of the Legendre Differential Equation, except for a missing outer derivative. However, I am somehow missing the steps taken to arrive at the right side: Where does the come from?","
\frac{d}{dx} \left[ (1 - x^2) \frac{d}{dx} P_n(x) \right] + n (n + 1) P_n(x)
= 0.
 
(x^2 - 1) \frac{d}{dx} (x^2 - 1)^n
= 2 n x (x^2 - 1)^n.
 2nx","['real-analysis', 'analysis', 'ordinary-differential-equations', 'legendre-polynomials']"
77,Lotka Volterra predator prey system,Lotka Volterra predator prey system,,"I am doing a project work mainly saying the relation between jacobian matrix and lotka volterra predator prey method , and I had a doubt,when I find eigenvalues of the system,I got purely imaginary values.what did it mean and how can I conclude my project","I am doing a project work mainly saying the relation between jacobian matrix and lotka volterra predator prey method , and I had a doubt,when I find eigenvalues of the system,I got purely imaginary values.what did it mean and how can I conclude my project",,"['ordinary-differential-equations', 'dynamical-systems']"
78,Linear Independence with Absolute Value Question,Linear Independence with Absolute Value Question,,"Are functions $t^3$ and $|t|^3$ linearly independent on $(−∞,∞)$? I'm fairly certain $t^3$ is linearly independent, as I don't see anything that would cause it to be linearly dependent.  Please do correct me if I'm mistaken. However, I don't know if $|t|^3$ changes the nature of things.  What difference does the absolute value mean, if it means anything at all?  Thanks.","Are functions $t^3$ and $|t|^3$ linearly independent on $(−∞,∞)$? I'm fairly certain $t^3$ is linearly independent, as I don't see anything that would cause it to be linearly dependent.  Please do correct me if I'm mistaken. However, I don't know if $|t|^3$ changes the nature of things.  What difference does the absolute value mean, if it means anything at all?  Thanks.",,['ordinary-differential-equations']
79,meaning of fundamental solution,meaning of fundamental solution,,"I would like to understand what is a mathematical, even physical meaning of fundamental solution,let us consider following problem from Wikipedia. $Lf=sin(x)$ where $L$ is operator of second derivative, as I know first it solves differential equation,that involves  delta function like because integral of delta function is Heaviside function H, or we have first of all in Wikipedia there is written,that for convenience  they took constant $C=-1/2$ does it matter what we took?for example if we take $C=0$ or $C=10$ ? and finally  what fundamental solution is convolution of right hand side functions with  solution of delta function, like this so my questions is 1.should we see another function instead of delta function,for example Dirac comb or others? 2.what is  physical meaning of this convolution? as i know  solution related to delta function is called generalized function,or functions which are not continuous and have not  derivatives,maybe i am wrong,but is it related to  to such situation,when we have  random events?or in deterministic  events?hanks in advance","I would like to understand what is a mathematical, even physical meaning of fundamental solution,let us consider following problem from Wikipedia. where is operator of second derivative, as I know first it solves differential equation,that involves  delta function like because integral of delta function is Heaviside function H, or we have first of all in Wikipedia there is written,that for convenience  they took constant does it matter what we took?for example if we take or ? and finally  what fundamental solution is convolution of right hand side functions with  solution of delta function, like this so my questions is 1.should we see another function instead of delta function,for example Dirac comb or others? 2.what is  physical meaning of this convolution? as i know  solution related to delta function is called generalized function,or functions which are not continuous and have not  derivatives,maybe i am wrong,but is it related to  to such situation,when we have  random events?or in deterministic  events?hanks in advance",Lf=sin(x) L C=-1/2 C=0 C=10,"['ordinary-differential-equations', 'distribution-theory']"
80,Understading the idea behind Gradient vector fields..,Understading the idea behind Gradient vector fields..,,"Example 3: Sketch the gradient vector field for $f(x,y) = x^2 + y^2$ as well as several contours for this function. The gradient of the vector field is  $$ \nabla f(x,y)=2x\vec{i}+2y\vec{j}. $$ But when i plot those 2 functions, I get a vector field that doesn't make sense. What does the Gradient vectors (the purple ones) tell me abouth the function?","Example 3: Sketch the gradient vector field for $f(x,y) = x^2 + y^2$ as well as several contours for this function. The gradient of the vector field is  $$ \nabla f(x,y)=2x\vec{i}+2y\vec{j}. $$ But when i plot those 2 functions, I get a vector field that doesn't make sense. What does the Gradient vectors (the purple ones) tell me abouth the function?",,"['calculus', 'ordinary-differential-equations', 'vector-analysis']"
81,Solve system of first order differential equations,Solve system of first order differential equations,,"I have to solve differential systems like this: $$ \left\{  \begin{array}{c} x' = 3x - y + z \\ y' = x + 5y - z \\ z' = x - y + 3z \end{array} \right.  $$ Until now I computed the eigenvalues $k = \{2,4,5\}$ by solving the equation resulted from this determinant of this matrix: $$ \begin{pmatrix} 3 && -1 && 1 \\ 1 && 5 && -1 \\ 1 && -1 && 3 \end{pmatrix} - kI_3 =  \begin{pmatrix} 3-k && -1 && 1 \\ 1 && 5-k && -1 \\ 1 && -1 && 3-k \end{pmatrix} $$ I don't know what to do next. NOTE: This is an example but from it I want to learn the method to solve any system of this kind. I learn better from particular examples than directly from generalization.","I have to solve differential systems like this: $$ \left\{  \begin{array}{c} x' = 3x - y + z \\ y' = x + 5y - z \\ z' = x - y + 3z \end{array} \right.  $$ Until now I computed the eigenvalues $k = \{2,4,5\}$ by solving the equation resulted from this determinant of this matrix: $$ \begin{pmatrix} 3 && -1 && 1 \\ 1 && 5 && -1 \\ 1 && -1 && 3 \end{pmatrix} - kI_3 =  \begin{pmatrix} 3-k && -1 && 1 \\ 1 && 5-k && -1 \\ 1 && -1 && 3-k \end{pmatrix} $$ I don't know what to do next. NOTE: This is an example but from it I want to learn the method to solve any system of this kind. I learn better from particular examples than directly from generalization.",,"['ordinary-differential-equations', 'dynamical-systems']"
82,Bernoulli differential equation help?,Bernoulli differential equation help?,,"We have the equation $$3xy' -2y=\frac{x^3}{y^2}$$ It is a type of Bernouli differential equation. So, since B. diff equation type is  $$y'+P(x)y=Q(x)y^n$$ I modify it a little to: $$y'- \frac{2y}{3x} = \frac{x^2}{3y^2}$$ $$y'-\frac{2y}{3x}=\frac{1}{3}x^2y^{-2}$$ Now I divide both sides by $y^{-2}$. What should I do now?","We have the equation $$3xy' -2y=\frac{x^3}{y^2}$$ It is a type of Bernouli differential equation. So, since B. diff equation type is  $$y'+P(x)y=Q(x)y^n$$ I modify it a little to: $$y'- \frac{2y}{3x} = \frac{x^2}{3y^2}$$ $$y'-\frac{2y}{3x}=\frac{1}{3}x^2y^{-2}$$ Now I divide both sides by $y^{-2}$. What should I do now?",,['ordinary-differential-equations']
83,Solve $\;\;y+(x^2y^3-x)y'=0;\;\;y(4)=1$,Solve,\;\;y+(x^2y^3-x)y'=0;\;\;y(4)=1,"I wish to solve $$\;y(x)+(x^2y(x)^3-x)y(x)'=0;\quad y(4)=1$$ It is supposed to be by multiplying by an integrand factor to turn it into an exact equation, but wolfram alpha gives these solutions which don't look so good. Is this problem OK or is there probably something wrong with it? If it is ok, how can I solve it?","I wish to solve $$\;y(x)+(x^2y(x)^3-x)y(x)'=0;\quad y(4)=1$$ It is supposed to be by multiplying by an integrand factor to turn it into an exact equation, but wolfram alpha gives these solutions which don't look so good. Is this problem OK or is there probably something wrong with it? If it is ok, how can I solve it?",,['ordinary-differential-equations']
84,Picard iteration and Taylor series,Picard iteration and Taylor series,,"I'm trying to derive the Taylor series for $\cos(t)$ by applying the Picard method to the first-order system corresponding to the second-order initial value problem $x"" = −x; x(0) = 1, x'(0) = 0$ For the above, I was thinking of converting the 2nd order DE to a first order, get a matrix which looks like: $A = (0 0, 0 -1)^T$, but unsure on the Picard iteration here.","I'm trying to derive the Taylor series for $\cos(t)$ by applying the Picard method to the first-order system corresponding to the second-order initial value problem $x"" = −x; x(0) = 1, x'(0) = 0$ For the above, I was thinking of converting the 2nd order DE to a first order, get a matrix which looks like: $A = (0 0, 0 -1)^T$, but unsure on the Picard iteration here.",,['ordinary-differential-equations']
85,Solve the following homogeneous differential equation,Solve the following homogeneous differential equation,,"Initial value problem: $\displaystyle \frac{dy}{dx}= \frac{y}{x}+2 \frac{x^2}{y^2}$, $y(1)=1$.  Can anyone help","Initial value problem: $\displaystyle \frac{dy}{dx}= \frac{y}{x}+2 \frac{x^2}{y^2}$, $y(1)=1$.  Can anyone help",,['ordinary-differential-equations']
86,Is this a typo or alternative notation?,Is this a typo or alternative notation?,,"I am reading Calculus:Volume II by Chen, Liu, etc. on page 201, the book states this. ...For example, $$ y^{\prime\prime} +xy^{\prime 3} + 5y = e^x $$ is a third-order equation. I have seen $y^{(3)}$ as meaning the third derivative of y in prime notation; however, I have never seen $y^{\prime N}$ where $N$ is a natural numer for the $N$th derivative of a variable.","I am reading Calculus:Volume II by Chen, Liu, etc. on page 201, the book states this. ...For example, $$ y^{\prime\prime} +xy^{\prime 3} + 5y = e^x $$ is a third-order equation. I have seen $y^{(3)}$ as meaning the third derivative of y in prime notation; however, I have never seen $y^{\prime N}$ where $N$ is a natural numer for the $N$th derivative of a variable.",,"['ordinary-differential-equations', 'notation']"
87,Diff eq. transformation polar coordinates,Diff eq. transformation polar coordinates,,"I have $(x',y')=(x-y-x(x^2+y^2)+\frac{xy}{\sqrt{x^2+y^2}},x+y-y(x^2+y^2)-\frac{x^2}{\sqrt{x^2+y^2}} )$ Now I want to use polar coordinates $(x,y)=(r\cos(t),r\sin(t))$ to get $(r',t')=(r(1-r^2),2\sin(\frac{t}{2})^2)$ I do not see this relation. When I put $x=\cos t$, $y=\sin t$ into the system of differential equations, I only get $(r\cos(t)-r\sin(t)-r^3\cos(t)+r\cos(t)\sin(t),r\cos(t)+r\sin(t)-r^3\cos(t)-r\cos(t)^2)$.","I have $(x',y')=(x-y-x(x^2+y^2)+\frac{xy}{\sqrt{x^2+y^2}},x+y-y(x^2+y^2)-\frac{x^2}{\sqrt{x^2+y^2}} )$ Now I want to use polar coordinates $(x,y)=(r\cos(t),r\sin(t))$ to get $(r',t')=(r(1-r^2),2\sin(\frac{t}{2})^2)$ I do not see this relation. When I put $x=\cos t$, $y=\sin t$ into the system of differential equations, I only get $(r\cos(t)-r\sin(t)-r^3\cos(t)+r\cos(t)\sin(t),r\cos(t)+r\sin(t)-r^3\cos(t)-r\cos(t)^2)$.",,"['ordinary-differential-equations', 'derivatives', 'transformation', 'polar-coordinates']"
88,Differential equation - quick question (first order differential ),Differential equation - quick question (first order differential ),,I am new to the differential equation and I need some ideas how to solve this problem. $x^2y'=x^2y^2-2$ $y'=y^2-\dfrac{2}{x^2}$,I am new to the differential equation and I need some ideas how to solve this problem. $x^2y'=x^2y^2-2$ $y'=y^2-\dfrac{2}{x^2}$,,['ordinary-differential-equations']
89,How to apply reduction of order to find a 2nd linearly independent solution?,How to apply reduction of order to find a 2nd linearly independent solution?,,"I have some questions about writing a general solution, $y$, for $y''-y=0$ when $y_1 = e^x$ is a known solution. I do not understand the logic of the method of reduction of order. How do we apply this to find a second, linearly independent solution?","I have some questions about writing a general solution, $y$, for $y''-y=0$ when $y_1 = e^x$ is a known solution. I do not understand the logic of the method of reduction of order. How do we apply this to find a second, linearly independent solution?",,['ordinary-differential-equations']
90,simple question involving trigonometry,simple question involving trigonometry,,"Can anybody explain what $$\tan(\sin^{-1}(\frac x y))$$ equals? I have to determine whether $$y'' \left(\tan \left(\sin^{-1}\left(\frac x y \right)\right) - \frac{x}{\sqrt{y^2-x^2}} \right)=0$$ is a linear differential equation. I thought that the left term might be equal to the right term, but I guess not.","Can anybody explain what $$\tan(\sin^{-1}(\frac x y))$$ equals? I have to determine whether $$y'' \left(\tan \left(\sin^{-1}\left(\frac x y \right)\right) - \frac{x}{\sqrt{y^2-x^2}} \right)=0$$ is a linear differential equation. I thought that the left term might be equal to the right term, but I guess not.",,"['ordinary-differential-equations', 'trigonometry']"
91,Solving $3y + 2y^2 = -e^{-x} - e^x + c$ for $y$,Solving  for,3y + 2y^2 = -e^{-x} - e^x + c y,"So, I am failing to understand some potentially simple algebra here. I have a separable equation: $$\frac{dy}{dx} = \frac{e^{-x} - e^x}{3+4y},$$ and after the easy integration I get $$3y + 2y^2 = -e^{-x} - e^x + c .$$ Now, how do I solve for $y$ ? The book has a fairly long answer involving a square root... It could come down to, I did the separable/integration part incorrectly or I've lost my mind but I'm kind of shaking my head over my lack of algebra skills.","So, I am failing to understand some potentially simple algebra here. I have a separable equation: and after the easy integration I get Now, how do I solve for ? The book has a fairly long answer involving a square root... It could come down to, I did the separable/integration part incorrectly or I've lost my mind but I'm kind of shaking my head over my lack of algebra skills.","\frac{dy}{dx} = \frac{e^{-x} - e^x}{3+4y}, 3y + 2y^2 = -e^{-x} - e^x + c . y","['algebra-precalculus', 'ordinary-differential-equations', 'roots', 'quadratics']"
92,Differential equation of $y = e^{rx}$,Differential equation of,y = e^{rx},"I am trying to find what values of r in $y = e^{rx}$ satsify $2y'' + y' - y = 0$ I thought I was being clever and knew how to do this so this is how I proceeded. $$y' = re^{rx}$$ $$y'' = r^2 e^{rx}$$ $$2(r^2 e^{rx}) +re^{rx} -e^{rx} = 0 $$ I am not sure how to proceed from here, the biggest thing I am confused on is that I am working with a variable x, with no input conditions at all, and a variable r (the constant) so how do I do this?","I am trying to find what values of r in $y = e^{rx}$ satsify $2y'' + y' - y = 0$ I thought I was being clever and knew how to do this so this is how I proceeded. $$y' = re^{rx}$$ $$y'' = r^2 e^{rx}$$ $$2(r^2 e^{rx}) +re^{rx} -e^{rx} = 0 $$ I am not sure how to proceed from here, the biggest thing I am confused on is that I am working with a variable x, with no input conditions at all, and a variable r (the constant) so how do I do this?",,['calculus']
93,solving Differential Equation,solving Differential Equation,,"I have the following problem: $$(t+2)dx=2x^2dt$$ First I divide both sides by $t+2$ to get: $$dx = \frac {2x^2}{t+2}\,dt $$ Then, divide by $2x^2$ to gey: $$\frac{dx}{2x^2}=\frac{dt}{t+2}$$ This will end up to: $$\int \frac1{2x^2}dx=\int\frac{dt}{t+2}$$ From now on I am not sure how to continue! I ended up having this equation: $$\frac 1 5 x^3 = \ln (t+2)+c$$ I need to find $x(t)$ now. Can somone help please? update This is how I got $\frac 1{5} x^3$: I said because $\int \frac 1{2x^2}dx$ is $\frac 12 \int x^-2$ isnt it right?","I have the following problem: $$(t+2)dx=2x^2dt$$ First I divide both sides by $t+2$ to get: $$dx = \frac {2x^2}{t+2}\,dt $$ Then, divide by $2x^2$ to gey: $$\frac{dx}{2x^2}=\frac{dt}{t+2}$$ This will end up to: $$\int \frac1{2x^2}dx=\int\frac{dt}{t+2}$$ From now on I am not sure how to continue! I ended up having this equation: $$\frac 1 5 x^3 = \ln (t+2)+c$$ I need to find $x(t)$ now. Can somone help please? update This is how I got $\frac 1{5} x^3$: I said because $\int \frac 1{2x^2}dx$ is $\frac 12 \int x^-2$ isnt it right?",,"['calculus', 'ordinary-differential-equations']"
94,Identifying Independent And Dependent Variables In Differential Equations,Identifying Independent And Dependent Variables In Differential Equations,,I've been given a second order differential equation $$x^2y'' + xy' + (x^2 - v^2)v = 0$$(where $v$ is a parameter)* and asked to identify the dependent and independent variables. Question is How do i know which are dependent and independent? I'am only used to equations of the form $x^2\frac{d^2y}{dx^2} + \frac{dy}{dx} = 0$ where i can easily tell that $y = f(x)$. *I don't know what that means! Thanks In Advance.,I've been given a second order differential equation $$x^2y'' + xy' + (x^2 - v^2)v = 0$$(where $v$ is a parameter)* and asked to identify the dependent and independent variables. Question is How do i know which are dependent and independent? I'am only used to equations of the form $x^2\frac{d^2y}{dx^2} + \frac{dy}{dx} = 0$ where i can easily tell that $y = f(x)$. *I don't know what that means! Thanks In Advance.,,"['ordinary-differential-equations', 'soft-question']"
95,Verifying a remark about fundamental matrices,Verifying a remark about fundamental matrices,,"There is a remark which gets used many times in a theorem I am trying to work through: If $X(t)$ is a fundamental matrix of $x'(t) = A(t)x(t)$ (1), then $x(t) = X(t)X^{-1}(t_{0})x_{0}$. In this setting, we are taking $x_{0} = x(t_{0})$. To be honest, I'm not exactly sure what it is claiming exactly.  Is just just a closed form of a particular solution to (1)? or is it a general solution to (1)?  Since fundamental matrices can differ by multiples of constant matrices, this couldn't be describing all the solutions, right?","There is a remark which gets used many times in a theorem I am trying to work through: If $X(t)$ is a fundamental matrix of $x'(t) = A(t)x(t)$ (1), then $x(t) = X(t)X^{-1}(t_{0})x_{0}$. In this setting, we are taking $x_{0} = x(t_{0})$. To be honest, I'm not exactly sure what it is claiming exactly.  Is just just a closed form of a particular solution to (1)? or is it a general solution to (1)?  Since fundamental matrices can differ by multiples of constant matrices, this couldn't be describing all the solutions, right?",,['ordinary-differential-equations']
96,$y'[x] = \frac{y}{x-y}$ Non-linear differential equation or not?,Non-linear differential equation or not?,y'[x] = \frac{y}{x-y},"$\displaystyle \qquad y'[x] = \frac{y}{x-y}=\frac{ \frac{y}{x} }{ 1-\frac{y}{x} }=\frac{u}{1-u}$ so $\displaystyle \qquad u = \frac{y}{x} \rightarrow y=ux,\qquad y'[x] = u$ $\displaystyle \qquad u = \frac{u}{1-u} \rightarrow u^{2}=0$ But wolframalpha states that it a first order non-linear ODE here and its solution: $$y(x) = - \frac{x} {W(-e^{-C_{1} x})}$$ where $W(z)$ is a product log function(?!). Could someone explain which way is the right and which is really the solution. My friend just said that he solved it by integrating, separating $x$'s and $y$'s to different sides but I cannot get it that way. [update] thanks to joriki: $$\frac{d u}{d x} = \frac{u}{1-u}-u=\frac{u^{2}}{1-u}$$ and after integrating $$\frac{-1}{u}-\ln(u)-x+C=0$$ but not yet the solution, thinking...but how to get to the solution suggested by WA now? I cannot see a way to solve it now just for x or just for y. Ideas?","$\displaystyle \qquad y'[x] = \frac{y}{x-y}=\frac{ \frac{y}{x} }{ 1-\frac{y}{x} }=\frac{u}{1-u}$ so $\displaystyle \qquad u = \frac{y}{x} \rightarrow y=ux,\qquad y'[x] = u$ $\displaystyle \qquad u = \frac{u}{1-u} \rightarrow u^{2}=0$ But wolframalpha states that it a first order non-linear ODE here and its solution: $$y(x) = - \frac{x} {W(-e^{-C_{1} x})}$$ where $W(z)$ is a product log function(?!). Could someone explain which way is the right and which is really the solution. My friend just said that he solved it by integrating, separating $x$'s and $y$'s to different sides but I cannot get it that way. [update] thanks to joriki: $$\frac{d u}{d x} = \frac{u}{1-u}-u=\frac{u^{2}}{1-u}$$ and after integrating $$\frac{-1}{u}-\ln(u)-x+C=0$$ but not yet the solution, thinking...but how to get to the solution suggested by WA now? I cannot see a way to solve it now just for x or just for y. Ideas?",,['ordinary-differential-equations']
97,Variations of Dawson's function,Variations of Dawson's function,,"I am studying Dawson's function : $\displaystyle F : x \mapsto e^{-x^2}\int_0^x e^{t^2} dt$ . I would like to prove that $F$ attains a maximum at a certain value $x_0 \in (0,1)$ , and is increasing over $[0,x_0]$ and decreasing over $[x_0, +\infty)$ . The only thing I managed to prove about this function is that $\displaystyle\lim_{x \rightarrow +\infty} F(x)=0$ , which gives the existence of a maximum over $[0,+\infty)$ , but does not help to determine the variations of $F$ . I also know that $F$ is solution of the differential equation $y'+2xy=1$ , but I cannot see how it could help. So the question is : how to determine the variations of $F$ ? (and bonus : how to prove that $x_0 <1$ ?) EDIT : Thanks to @NinadMunshi's answer, I understand now why there exists $x_0 \in (0,1)$ such that $F'(x_0)=0$ . But I still don't understand how to prove that $x_0$ is the only root of $F'$ over $[0,+\infty)$ (which would solve my initial question) Does anybody know how to tackle this question ?","I am studying Dawson's function : . I would like to prove that attains a maximum at a certain value , and is increasing over and decreasing over . The only thing I managed to prove about this function is that , which gives the existence of a maximum over , but does not help to determine the variations of . I also know that is solution of the differential equation , but I cannot see how it could help. So the question is : how to determine the variations of ? (and bonus : how to prove that ?) EDIT : Thanks to @NinadMunshi's answer, I understand now why there exists such that . But I still don't understand how to prove that is the only root of over (which would solve my initial question) Does anybody know how to tackle this question ?","\displaystyle F : x \mapsto e^{-x^2}\int_0^x e^{t^2} dt F x_0 \in (0,1) [0,x_0] [x_0, +\infty) \displaystyle\lim_{x \rightarrow +\infty} F(x)=0 [0,+\infty) F F y'+2xy=1 F x_0 <1 x_0 \in (0,1) F'(x_0)=0 x_0 F' [0,+\infty)","['real-analysis', 'integration', 'ordinary-differential-equations', 'calculus-of-variations']"
98,"How to calculate $\int(yy'' + (y')^2)\,dx$?",How to calculate ?,"\int(yy'' + (y')^2)\,dx","Context : I have the following second-order differential equation: $$yy'' + (y')^2 = x$$ I noticed that $$yy'' + (y')^2 = (yy')'_x \,\,\,\, (1)$$ So I integrate both sides with respect of $x$ : $$\int(yy'' + (y')^2)\,dx = \int{x\,dx}$$ I already know the answer for the left integral: $\int(yy'' + (y')^2)\,dx = yy' + C_1$ . But what if I didn't notice $(1)$ ? How would I solve the integral? I'm struggling for some reason..",Context : I have the following second-order differential equation: I noticed that So I integrate both sides with respect of : I already know the answer for the left integral: . But what if I didn't notice ? How would I solve the integral? I'm struggling for some reason..,"yy'' + (y')^2 = x yy'' + (y')^2 = (yy')'_x \,\,\,\, (1) x \int(yy'' + (y')^2)\,dx = \int{x\,dx} \int(yy'' + (y')^2)\,dx = yy' + C_1 (1)","['integration', 'ordinary-differential-equations', 'derivatives']"
99,Using integration by parts to solve a differential equation,Using integration by parts to solve a differential equation,,"I am stuck on the following analysis problem. Suppose that $u\in C([a,b])$ is twice continuously differentiable, $V\in C([a,b])$ , $V(x)\geq 0$ for all $x\in[a,b]$ and $$ -u''(x)+V(x)u(x)=0, \forall x\in[a,b]$$ $$u(a)=u(b)=0$$ Show that $u(x)=0$ for all $x\in[a,b]$ . The hint tells me to use integration by parts to solve this problem, but I can't see where to use it. I tried the following, but it doesn't lead to a meaningful result. Let $v(x)=\int_a^x V(t)dt$ . Then, integrating by parts, we have $$ \int_a^b V(x)u(x)dx = v(b)u(b)-v(a)u(a)-\int_a^bv(x)u'(x)dx = -\int_a^bv(x)u'(x)dx $$ and because $u''(x)=V(x)u(x)$ , $$\int_a^bV(x)u(x)dx = \int_a^bu''(x)dx = u'(b)-u'(a) = -\int_a^bv(x)u'(x)dx $$ I'd appreciate if anyone could tell me where to use the integration by parts in this problem. Thank you!","I am stuck on the following analysis problem. Suppose that is twice continuously differentiable, , for all and Show that for all . The hint tells me to use integration by parts to solve this problem, but I can't see where to use it. I tried the following, but it doesn't lead to a meaningful result. Let . Then, integrating by parts, we have and because , I'd appreciate if anyone could tell me where to use the integration by parts in this problem. Thank you!","u\in C([a,b]) V\in C([a,b]) V(x)\geq 0 x\in[a,b]  -u''(x)+V(x)u(x)=0, \forall x\in[a,b] u(a)=u(b)=0 u(x)=0 x\in[a,b] v(x)=\int_a^x V(t)dt  \int_a^b V(x)u(x)dx = v(b)u(b)-v(a)u(a)-\int_a^bv(x)u'(x)dx = -\int_a^bv(x)u'(x)dx  u''(x)=V(x)u(x) \int_a^bV(x)u(x)dx = \int_a^bu''(x)dx = u'(b)-u'(a) = -\int_a^bv(x)u'(x)dx ","['real-analysis', 'integration', 'ordinary-differential-equations']"
