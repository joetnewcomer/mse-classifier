,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Conditions for Rouché's theorem,Conditions for Rouché's theorem,,"For the statement of Rouché's theorem, I've always seen that both $f$ and $g$ have to be holomorphic on and inside a simple closed curve $ C $ . However, I am solving a problem which seems to suggest that I should use Rouché's theorem even though I only know that $ f $ is holomorphic in the unit disk $ D $ and continuous in $ \bar{D} $ . I also check Wikipedia's page on Rouché's theorem which says that $ f $ and $ g $ only need to be holomorphic inside the region, not on the boundary. Is this sufficient?","For the statement of Rouché's theorem, I've always seen that both and have to be holomorphic on and inside a simple closed curve . However, I am solving a problem which seems to suggest that I should use Rouché's theorem even though I only know that is holomorphic in the unit disk and continuous in . I also check Wikipedia's page on Rouché's theorem which says that and only need to be holomorphic inside the region, not on the boundary. Is this sufficient?",f g  C   f   D   \bar{D}   f   g ,['complex-analysis']
1,Is this zeta-type function meromorphic?,Is this zeta-type function meromorphic?,,"In An older question I asked : ( See A Thue-Morse Zeta function (Generalized Riemann Zeta function and new GRH) ) —— Consider $t_n$ as the Thue-Morse sequence . Let $m$ be a positive integer and $s$ a complex number, and recall that the Odiuos numbers are the indices of nonzero entries in the Thue-Morse sequence. Now consider the sequence of functions below: $$f(1,s)=1+2^{-s}+3^{-s}+4^{-s}+\dotsb$$ This is the zeta function valid for $\mathrm{Real}(s)>1$ . $$f(2,s)=1-2^{-s}+3^{-s}-4^{-s}+\dotsb$$ This is the alternating zeta function valid for $\mathrm{Real}(s)>0$ . $$f(3,s)=1-2^{-s}-3^{-s}+4^{-s}+5^{-s}-6^{-s}-7^{-s}+8^{-s}+\dotsb = 4^{-s} (\zeta(s,1/4) - \zeta(s,2/4) - \zeta(s,3/4) + \zeta(s,4/4) ) $$ ( $\zeta(s,a)$ is Hurwitz zeta ) I'm not sure if this has an official name yet but it clear that it is valid for $\mathrm{Real}(s)>-1$ . This sequence of functions is constructed in the similar way the Thue-Morse sequence is constructed. $$\begin{align} &\vdots\\ f(\infty,s)&= \sum (-1)^{t_n} n^{-s} \end{align}$$ This is a nice generalization/variant of the Riemann Zeta function and the Dirichlet eta or Dirichlet $L$ -functions. It follows that $f(m, s)$ is valid for $\mathrm{Real}(s)>-m+2$ . Now there are two logical questions analogue to the questions about the Riemann Zeta function: What are the functional equations for $f(m,s)$ ? Call the $N^\text{th}$ zero $Z_n(m)$ . Are all the zero's of $f(m,s)$ for any $m$ with $0<\mathrm{Real}(s)<1$ on the critical line $(\mathrm{Real}(Z_N(m))=1/2)$ ? Is clearly a generalizations of the Riemann Hypothesis. And I think it might be true! (I made some plots that were convincing but the accuracy was low.) I wonder if these functions have a name yet and what the answers to the 2 logical questions are. I also invite the readers to make more conjectures and variants with this. —— Some additional questions : let $T(s) = f(\infty,s) $ . 1) Is $T(s)$ meromorphic on The entire complex plane ? 2) how Many poles does $T(s)$ have ? Is it one ? 3) assuming 1) : What is The infinite product representation for $T(s)$ ? ( hadamard type product ) 4) assuming 1),2) how fast is this function growing on The complex plane ? As fast as Riemann zeta ?? I assume so. I think all of these are true. Maybe 2) can Be shown by induction from $f(n,z) $ To $f(n+1,z) $ ?? But infinity is no integer , so maybe not.","In An older question I asked : ( See A Thue-Morse Zeta function (Generalized Riemann Zeta function and new GRH) ) —— Consider as the Thue-Morse sequence . Let be a positive integer and a complex number, and recall that the Odiuos numbers are the indices of nonzero entries in the Thue-Morse sequence. Now consider the sequence of functions below: This is the zeta function valid for . This is the alternating zeta function valid for . ( is Hurwitz zeta ) I'm not sure if this has an official name yet but it clear that it is valid for . This sequence of functions is constructed in the similar way the Thue-Morse sequence is constructed. This is a nice generalization/variant of the Riemann Zeta function and the Dirichlet eta or Dirichlet -functions. It follows that is valid for . Now there are two logical questions analogue to the questions about the Riemann Zeta function: What are the functional equations for ? Call the zero . Are all the zero's of for any with on the critical line ? Is clearly a generalizations of the Riemann Hypothesis. And I think it might be true! (I made some plots that were convincing but the accuracy was low.) I wonder if these functions have a name yet and what the answers to the 2 logical questions are. I also invite the readers to make more conjectures and variants with this. —— Some additional questions : let . 1) Is meromorphic on The entire complex plane ? 2) how Many poles does have ? Is it one ? 3) assuming 1) : What is The infinite product representation for ? ( hadamard type product ) 4) assuming 1),2) how fast is this function growing on The complex plane ? As fast as Riemann zeta ?? I assume so. I think all of these are true. Maybe 2) can Be shown by induction from To ?? But infinity is no integer , so maybe not.","t_n m s f(1,s)=1+2^{-s}+3^{-s}+4^{-s}+\dotsb \mathrm{Real}(s)>1 f(2,s)=1-2^{-s}+3^{-s}-4^{-s}+\dotsb \mathrm{Real}(s)>0 f(3,s)=1-2^{-s}-3^{-s}+4^{-s}+5^{-s}-6^{-s}-7^{-s}+8^{-s}+\dotsb = 4^{-s} (\zeta(s,1/4) - \zeta(s,2/4) - \zeta(s,3/4) + \zeta(s,4/4) )  \zeta(s,a) \mathrm{Real}(s)>-1 \begin{align}
&\vdots\\
f(\infty,s)&= \sum (-1)^{t_n} n^{-s}
\end{align} L f(m, s) \mathrm{Real}(s)>-m+2 f(m,s) N^\text{th} Z_n(m) f(m,s) m 0<\mathrm{Real}(s)<1 (\mathrm{Real}(Z_N(m))=1/2) T(s) = f(\infty,s)  T(s) T(s) T(s) f(n,z)  f(n+1,z) ","['complex-analysis', 'analytic-number-theory', 'infinite-product', 'zeta-functions']"
2,Let $a_k\gt 0$ and $a_0\gt \sum_{k=1}^n a_k$ . Show that $\int_0^{\infty} \prod_{k=0}^n \frac {\sin (a_k x)}{x} dx=\frac {\pi}{2}\prod_{k=1}^n a_k$,Let  and  . Show that,a_k\gt 0 a_0\gt \sum_{k=1}^n a_k \int_0^{\infty} \prod_{k=0}^n \frac {\sin (a_k x)}{x} dx=\frac {\pi}{2}\prod_{k=1}^n a_k,Let $a_k\gt 0$ and $a_0\gt \sum_{k=1}^n a_k$ . Show that $$\int_0^{\infty} \prod_{k=0}^n \frac {\sin (a_k x)}{x} dx=\frac {\pi}{2}\prod_{k=1}^n a_k$$ I saw this question on the internet somewhere a few days back and thought to give it a try. The question looks so absurd due to the arbitrary inputs in the sines and their products. I tried giving it a shot using Laplace and Mellin transforms but realized they were turning to dead end. i also tried using a little complex analysis by writing sines in terms of $e$ but to no avail. One method which seemed quite promising was the Feynman's technique because one peculiar thing about RHS is that it is independent of $a_0$ and also a point to note is the constraint on $a_0$ ( It is greater than sum of other $a_k$ 's). Differentiating both sides w.r.t $a_0$ would give a $0$ on RHS while some integral on LHS which we need to prove is $0$ . But couldn't much continue with this thought. The place where I saw this question also had an answer but it used principle of induction which I pretty don't like much so it would be very much better if I could get methods without involving any type of induction. Thanks!!!!,Let and . Show that I saw this question on the internet somewhere a few days back and thought to give it a try. The question looks so absurd due to the arbitrary inputs in the sines and their products. I tried giving it a shot using Laplace and Mellin transforms but realized they were turning to dead end. i also tried using a little complex analysis by writing sines in terms of but to no avail. One method which seemed quite promising was the Feynman's technique because one peculiar thing about RHS is that it is independent of and also a point to note is the constraint on ( It is greater than sum of other 's). Differentiating both sides w.r.t would give a on RHS while some integral on LHS which we need to prove is . But couldn't much continue with this thought. The place where I saw this question also had an answer but it used principle of induction which I pretty don't like much so it would be very much better if I could get methods without involving any type of induction. Thanks!!!!,a_k\gt 0 a_0\gt \sum_{k=1}^n a_k \int_0^{\infty} \prod_{k=0}^n \frac {\sin (a_k x)}{x} dx=\frac {\pi}{2}\prod_{k=1}^n a_k e a_0 a_0 a_k a_0 0 0,"['calculus', 'integration', 'complex-analysis', 'definite-integrals', 'improper-integrals']"
3,Find the zeros of $f(z)=z^3-\sin^3z$,Find the zeros of,f(z)=z^3-\sin^3z,"I want to find the zeros of $f(z)$ , $$f(z)=z^3-\sin^3z$$ My attempt $f(z)=0$ $z^3-(z-z^3/3!+z^5/5!-\dots)^3=0$ $z^3-z^3(1-z^2/3!+z^4/5!-\dots)^3=0$ $z^3[1-(1-z^2/3!+z^4/5!-\dots)^3]=0$ So $z=0$ is a zero of order $3$ . I don't feel good about this answer. Please give me some hints if I am incorrect. Edit: What is the order of root $z=0$ ?","I want to find the zeros of , My attempt So is a zero of order . I don't feel good about this answer. Please give me some hints if I am incorrect. Edit: What is the order of root ?",f(z) f(z)=z^3-\sin^3z f(z)=0 z^3-(z-z^3/3!+z^5/5!-\dots)^3=0 z^3-z^3(1-z^2/3!+z^4/5!-\dots)^3=0 z^3[1-(1-z^2/3!+z^4/5!-\dots)^3]=0 z=0 3 z=0,"['complex-analysis', 'power-series', 'analytic-functions']"
4,How does Weierstrass' theorem follow from Mergelyan's theorem?,How does Weierstrass' theorem follow from Mergelyan's theorem?,,"According to Theorems 1 and 3 in this review article we have Weierstrass: Suppose $f$ is a continuous function on a closed bounded interval $[a,b] \subset\mathbb{R}$ . For every $\epsilon > 0$ there exists a polynomial $p$ such that for all $x \in [a,b]$ we have $| f(x)− p(x)| < \epsilon$ . Mergelyan: If $K$ is a compact set in $C$ with connected complement, then every continuous function $f\colon K\to \mathbb{C}$ that is holomorphic in the interior of $K$ can be approximated   uniformly on $K$ by holomorphic polynomials. Both Wikipedia and the review say that the latter is a generalization of the former. In which sense is this true?  How does Weierstrass' theorem follow from Mergelyan's?","According to Theorems 1 and 3 in this review article we have Weierstrass: Suppose is a continuous function on a closed bounded interval . For every there exists a polynomial such that for all we have . Mergelyan: If is a compact set in with connected complement, then every continuous function that is holomorphic in the interior of can be approximated   uniformly on by holomorphic polynomials. Both Wikipedia and the review say that the latter is a generalization of the former. In which sense is this true?  How does Weierstrass' theorem follow from Mergelyan's?","f [a,b] \subset\mathbb{R} \epsilon > 0 p x \in [a,b] | f(x)− p(x)| < \epsilon K C f\colon K\to \mathbb{C} K K","['complex-analysis', 'approximation-theory', 'weierstrass-approximation']"
5,Find all $n\in\mathbb{N}$ such that the nonzero roots of $(z+1)^n-z^n-1$ are all on the unit circle.,Find all  such that the nonzero roots of  are all on the unit circle.,n\in\mathbb{N} (z+1)^n-z^n-1,"I try to use Mathematica to find such $n$, and I believe that only $n=2,3,4,5,6,7$ meet the requirement but I don't know how to prove that for $n\ge 8$, there is always some root lying outside the unit ball by using the basic complex analysis knowledge. In fact, I do have a dirty way to deal with this problem, which only involves the property of polynomial. But I don't think it is an efficient and elegant solution.","I try to use Mathematica to find such $n$, and I believe that only $n=2,3,4,5,6,7$ meet the requirement but I don't know how to prove that for $n\ge 8$, there is always some root lying outside the unit ball by using the basic complex analysis knowledge. In fact, I do have a dirty way to deal with this problem, which only involves the property of polynomial. But I don't think it is an efficient and elegant solution.",,"['complex-analysis', 'polynomials']"
6,Problem with simply connected 3D domains,Problem with simply connected 3D domains,,"I was going through this website . I am not understanding the definition of a simply connected domain, it says ""A simply connected domain is a path-connected domain where one can continuously shrink any simple closed curve into a point while remaining in the domain "" I thought I understood it and my understanding went well with the bellow 2D domains: I can understand that a closed loop path can be shrunk to a point and still be in the domain for the left figure but not for the right one because if it's shrunk to a point then it will breach the inner boundary and form a point inside the inner boundary, which is not in the domain. (Please correct me if my understanding is wrong) But now when I see the bellow 3D domains, I get confused. I don't understand why the $2^{nd}$ figure (A sphere having a hollow spherical region) from the left is simply connected . There is a small hollow sphere ( out of domain region) at the centre so if I try to shrink a closed curve (not just any curve but a big circle with radius 99% of the radius of the sphere which is enclosed in the sphere) won't it shrink to a point that's inside the hollow sphere (which is out of the domain)? Note : The 3D figures with the caption ""Non-simply connected"" have holes that are drilled all the way through.","I was going through this website . I am not understanding the definition of a simply connected domain, it says ""A simply connected domain is a path-connected domain where one can continuously shrink any simple closed curve into a point while remaining in the domain "" I thought I understood it and my understanding went well with the bellow 2D domains: I can understand that a closed loop path can be shrunk to a point and still be in the domain for the left figure but not for the right one because if it's shrunk to a point then it will breach the inner boundary and form a point inside the inner boundary, which is not in the domain. (Please correct me if my understanding is wrong) But now when I see the bellow 3D domains, I get confused. I don't understand why the figure (A sphere having a hollow spherical region) from the left is simply connected . There is a small hollow sphere ( out of domain region) at the centre so if I try to shrink a closed curve (not just any curve but a big circle with radius 99% of the radius of the sphere which is enclosed in the sphere) won't it shrink to a point that's inside the hollow sphere (which is out of the domain)? Note : The 3D figures with the caption ""Non-simply connected"" have holes that are drilled all the way through.",2^{nd},['complex-analysis']
7,"Are two real, two variable polynomials, satisfying the Cauchy-Riemann equations, a complex polynomial?","Are two real, two variable polynomials, satisfying the Cauchy-Riemann equations, a complex polynomial?",,"Let $u, v \in \mathbb{R}[x,y]$ satisfying $u_{x} = v_{y}$ and $u_{y} = -v_{x}$ everywhere in $\mathbb{C}$. Is the function $f(x + iy) = u(x,y) + iv(x,y)$ a polynomial in the variable $z = x +  iy$? I really don't know where to start with this. I tried to build a counterexample, but I had no success.","Let $u, v \in \mathbb{R}[x,y]$ satisfying $u_{x} = v_{y}$ and $u_{y} = -v_{x}$ everywhere in $\mathbb{C}$. Is the function $f(x + iy) = u(x,y) + iv(x,y)$ a polynomial in the variable $z = x +  iy$? I really don't know where to start with this. I tried to build a counterexample, but I had no success.",,"['complex-analysis', 'polynomials', 'analytic-functions']"
8,Degree of a map $f:S^1 \to S^1$ given a polynomial $p$,Degree of a map  given a polynomial,f:S^1 \to S^1 p,"I'm preparing for some comprehensive exams and this is a question from a previous year that I think I'm close to solving but some details may need to be filled in. Any help would be great. ""Let $p:\mathbb{C} \to \mathbb{C}$ be a polynomial with simple roots, none of which lie on the unit circle $S^1$. Show that the number of roots inside the unit disk $D$ is the degree of the map $f:S^1 \to S^1$ defined by $f(e^{i \theta}) = \frac{p(e^{i \theta})}{|p(e^{i \theta})|}$."" First, let $p, q$ be two polynomials satisfying the above. If $f_p (e^{i \theta}) = \frac{p(e^{i \theta})}{|p(e^{i \theta})|}$ and $f_q(e^{i \theta}) = \frac{q(e^{i \theta})}{|q(e^{i \theta})|}$, observe that $f_{pq}$ defined as just taking the polynomial $pq = p(z)q(z)$ (multiplication, not composition) and churning out a function $f$ as we have been doing, then $f_{pq} = f_p \cdot f_q$ (it is multiplicative). Then,  $$\frac{f'_{pq}}{f_{pq}} = \frac{d}{d \theta}(\log f_{pq}) = \frac{d}{d \theta}(\log f_{p}) + \frac{d}{d \theta}(\log f_{q}) =\frac{f'_p}{f_p}+\frac{f'_q}{f_q}.$$ Now, these $f$ functions are maps from $S^1 \to S^1$ so they're loops in $S^1$; thus, $[f] \in \pi_1(S^1) = \mathbb{Z}$. So we can consider degree of these $f$ by considering their winding numbers. The winding number of $f$ can be given as an integral: $$\deg  f = \int^{2 \pi}_0 \frac{f'}{f} \, d \theta = \text{winding number of $f$ around 0.}$$ From the above, we have then that $\deg f_{pq} = \deg f_p + \deg f_q$. So now just consider one polynomial $p(z) = \prod^n (z-a_i)$. Setting $p_i = z-a_i$, we have that $\deg f = \sum^n \deg f_{p_i}$. We want to show that if $a_i \notin D$, then $\deg f_{p_i} = 0$. WLOG, we can suppose that $a_i \in \mathbb{R}^+$ (just rotate the picture). Draw a vector from $0$ to $z \in S^1$ and a vector from $0$ to $a_i$. Then the vector $z-a_i$ makes an obtuse angle with the real axis; this means that $z-a_i$ lies somewhere in the left half plane and when normalized, is on the left semicircle. Thus, $f_{p_i}$ is not surjective as everything on the right semicircle is missed. So $\deg f_{p_i} = 0$. On the other hand, if $a_i \in D$, then we can use similar simple geometry as above to show that for each point on $S^1$, there is a unique point mapping to it. Just choose your point $w \in S^1$ and draw its vector. Then translate that vector to $a_i$ and extend it till it hits $S^1$. Where it intersects $S^1$ is the point $z$ which maps to $w$. Thus, $f_{p_i}$ in this case is bijective and hence, the winding number must be $1 = \deg f_{p_i}$ (all other positive degrees = other positive winding numbers imply a non-injective map $f$). Therefore, if there are $k$ roots of $p$ inside $D$, $\deg f = k$. Issues that I would like help resolving: $\log$ isn't well-defined though I think this isn't a problem when we consider its derivative. The last part about $f_{p_i}$ being bijective when $a_i \in D$ doesn't seem airtight to me and could be wrong. However, when picturing the map, I think I can visualize a clear homotopy between $f$ and $g(z)=z$. I'm not really familiar with this definition for degree on $S^1$; I was told that it's equivalent and the bit about $[f] \in \pi_1(S^1)$ convinces me that it's true but I couldn't justify it that rigorously from the definition about regular values or differential forms.","I'm preparing for some comprehensive exams and this is a question from a previous year that I think I'm close to solving but some details may need to be filled in. Any help would be great. ""Let $p:\mathbb{C} \to \mathbb{C}$ be a polynomial with simple roots, none of which lie on the unit circle $S^1$. Show that the number of roots inside the unit disk $D$ is the degree of the map $f:S^1 \to S^1$ defined by $f(e^{i \theta}) = \frac{p(e^{i \theta})}{|p(e^{i \theta})|}$."" First, let $p, q$ be two polynomials satisfying the above. If $f_p (e^{i \theta}) = \frac{p(e^{i \theta})}{|p(e^{i \theta})|}$ and $f_q(e^{i \theta}) = \frac{q(e^{i \theta})}{|q(e^{i \theta})|}$, observe that $f_{pq}$ defined as just taking the polynomial $pq = p(z)q(z)$ (multiplication, not composition) and churning out a function $f$ as we have been doing, then $f_{pq} = f_p \cdot f_q$ (it is multiplicative). Then,  $$\frac{f'_{pq}}{f_{pq}} = \frac{d}{d \theta}(\log f_{pq}) = \frac{d}{d \theta}(\log f_{p}) + \frac{d}{d \theta}(\log f_{q}) =\frac{f'_p}{f_p}+\frac{f'_q}{f_q}.$$ Now, these $f$ functions are maps from $S^1 \to S^1$ so they're loops in $S^1$; thus, $[f] \in \pi_1(S^1) = \mathbb{Z}$. So we can consider degree of these $f$ by considering their winding numbers. The winding number of $f$ can be given as an integral: $$\deg  f = \int^{2 \pi}_0 \frac{f'}{f} \, d \theta = \text{winding number of $f$ around 0.}$$ From the above, we have then that $\deg f_{pq} = \deg f_p + \deg f_q$. So now just consider one polynomial $p(z) = \prod^n (z-a_i)$. Setting $p_i = z-a_i$, we have that $\deg f = \sum^n \deg f_{p_i}$. We want to show that if $a_i \notin D$, then $\deg f_{p_i} = 0$. WLOG, we can suppose that $a_i \in \mathbb{R}^+$ (just rotate the picture). Draw a vector from $0$ to $z \in S^1$ and a vector from $0$ to $a_i$. Then the vector $z-a_i$ makes an obtuse angle with the real axis; this means that $z-a_i$ lies somewhere in the left half plane and when normalized, is on the left semicircle. Thus, $f_{p_i}$ is not surjective as everything on the right semicircle is missed. So $\deg f_{p_i} = 0$. On the other hand, if $a_i \in D$, then we can use similar simple geometry as above to show that for each point on $S^1$, there is a unique point mapping to it. Just choose your point $w \in S^1$ and draw its vector. Then translate that vector to $a_i$ and extend it till it hits $S^1$. Where it intersects $S^1$ is the point $z$ which maps to $w$. Thus, $f_{p_i}$ in this case is bijective and hence, the winding number must be $1 = \deg f_{p_i}$ (all other positive degrees = other positive winding numbers imply a non-injective map $f$). Therefore, if there are $k$ roots of $p$ inside $D$, $\deg f = k$. Issues that I would like help resolving: $\log$ isn't well-defined though I think this isn't a problem when we consider its derivative. The last part about $f_{p_i}$ being bijective when $a_i \in D$ doesn't seem airtight to me and could be wrong. However, when picturing the map, I think I can visualize a clear homotopy between $f$ and $g(z)=z$. I'm not really familiar with this definition for degree on $S^1$; I was told that it's equivalent and the bit about $[f] \in \pi_1(S^1)$ convinces me that it's true but I couldn't justify it that rigorously from the definition about regular values or differential forms.",,"['complex-analysis', 'differential-geometry', 'differential-topology']"
9,Discussing $\frac{d}{d\theta}e^{i\theta}$ aka cis before complex derivatives and complex exponential,Discussing  aka cis before complex derivatives and complex exponential,\frac{d}{d\theta}e^{i\theta},"A First Course in Complex Analysis by Matthias Beck, Gerald Marchesi, Dennis Pixton, and Lucas Sabalka Definition of $e^{i \theta}$ (or cis in other texts) About Prop 1.3f, how is it possible to discuss derivative of $e^{i \theta}$ before both defining derivatives of complex functions (Ch2) (including functions of a real variable I think!) and defining the complex exponential (Ch3)? In particular, the proof of Prop 1.3f seems to assume linearity of the derivatives of complex functions. There's even this exercise later on: Exer 1.6b I know how to do this with Ch3's definition of the complex exponential. I don't believe this is possible to do with only Ch1 even if we write $e^{\phi + i\phi} = e^{(i+1)\phi}$ .","A First Course in Complex Analysis by Matthias Beck, Gerald Marchesi, Dennis Pixton, and Lucas Sabalka Definition of (or cis in other texts) About Prop 1.3f, how is it possible to discuss derivative of before both defining derivatives of complex functions (Ch2) (including functions of a real variable I think!) and defining the complex exponential (Ch3)? In particular, the proof of Prop 1.3f seems to assume linearity of the derivatives of complex functions. There's even this exercise later on: Exer 1.6b I know how to do this with Ch3's definition of the complex exponential. I don't believe this is possible to do with only Ch1 even if we write .",e^{i \theta} e^{i \theta} e^{\phi + i\phi} = e^{(i+1)\phi},"['complex-analysis', 'derivatives', 'complex-numbers', 'exponential-function']"
10,Cauchy's principal part equation,Cauchy's principal part equation,,"In the book Many-Body Physics by Coleman, on page 110 there is the following statement: Using Cauchy's principal part equation, $1/(x-i \delta) = P(1/x) + i \pi \delta(x)$ , where $P$ is the principal part. Here $\delta$ is a number and $\delta(x)$ I presume to be the Dirac delta. I am not sure what this means. I assume it is related to the principal part of a function but, otherwise, I don't know how to obtain this. Help would be appreciated.","In the book Many-Body Physics by Coleman, on page 110 there is the following statement: Using Cauchy's principal part equation, , where is the principal part. Here is a number and I presume to be the Dirac delta. I am not sure what this means. I assume it is related to the principal part of a function but, otherwise, I don't know how to obtain this. Help would be appreciated.",1/(x-i \delta) = P(1/x) + i \pi \delta(x) P \delta \delta(x),['complex-analysis']
11,Holomorphic function on unit disk,Holomorphic function on unit disk,,Suppose $f$ is a holomorphic function on the open unit disk $\mathbb{D}$ with $f(0)=0$ and  $| f(z) + zf^{'}(z)| <1$ for all $z \in \mathbb{D}$. I have to show that $|f(z)| \leq \frac{|z|}{2}$ for all $z\in \mathbb{D}$. I have tried to apply Schwarz Lemma but failed to obtain the inequality.,Suppose $f$ is a holomorphic function on the open unit disk $\mathbb{D}$ with $f(0)=0$ and  $| f(z) + zf^{'}(z)| <1$ for all $z \in \mathbb{D}$. I have to show that $|f(z)| \leq \frac{|z|}{2}$ for all $z\in \mathbb{D}$. I have tried to apply Schwarz Lemma but failed to obtain the inequality.,,['complex-analysis']
12,entire function with bounded multiplicity is a polynomial [duplicate],entire function with bounded multiplicity is a polynomial [duplicate],,"This question already has an answer here : Proof that a certain entire function is a polynomial (1 answer) Closed 5 years ago . Let $f:\mathbb{C}\to\mathbb{C}$ be an entire function. Let $n\in\mathbb{N}$ and suppose that $$\forall w\in\mathbb{C}:\#\{z\in\mathbb{C}:f(z)=w\}\leq n$$ In words, every complex value is attained by $f$ in at most $n$ different places. Prove that $f$ is a polynomial of degree at most $n$.","This question already has an answer here : Proof that a certain entire function is a polynomial (1 answer) Closed 5 years ago . Let $f:\mathbb{C}\to\mathbb{C}$ be an entire function. Let $n\in\mathbb{N}$ and suppose that $$\forall w\in\mathbb{C}:\#\{z\in\mathbb{C}:f(z)=w\}\leq n$$ In words, every complex value is attained by $f$ in at most $n$ different places. Prove that $f$ is a polynomial of degree at most $n$.",,"['complex-analysis', 'entire-functions']"
13,Existence of complex branch for real exponents,Existence of complex branch for real exponents,,"I've recently encountered a problem regarding complex branches that made me feel like there is something fundamental about branches I do not understand: The problem Let $G$ be an open subset of $\mathbb{C}$ and $z_1,z_2,...z_m \in \mathbb C \setminus G$ be distinct points such that there are real numbers $a_1,a_2,...a_m$ satisfying: $$\sum_{j=1}^ma_jInd_\gamma(z_j)=0$$ for every closed path $\gamma \subset G$. Show that there is a holomorphic branch of $(z-z_1)^{a_1}(z-z_2)^{a_2}...(z-z_m)^{a_m}$ in $G$. My confusion The basic idea behind the statement of the problem seems intuitively obvious to me, but I've had great difficulty expressing a solution rigurously, which makes me believe there's something fundamental I'm missing here. My approach was to try and utilize a theorem that states $logf$ has a holomorphic branch in $G$ if and only if $$\int_\gamma \frac{f'}{f}dz=0$$ for every closed path $\gamma \subset G$. However, the only sensible way I can think of to define $f$ is by $f=\exp[\sum_{j=1}^{m}a_jlog(z-z_j)]$ Obviously if the exponent is holomorphic, so is $f$, but how can it be shown that it is indeed holomorphic? Induction does not work because the separate $log(z-z_j)$ may not exist on their own, even though their weighted sum does. It is also quite simple to show that $f$ as defined in the problem satisfies the conditions of the theorem, and hence the sum of logarithms in the above exponent is indeed holomorphic.. but that presumes that $f$ exists (and is holomorphic) in the first place. Can $f$ be defined in some other way that makes this all fall into place?","I've recently encountered a problem regarding complex branches that made me feel like there is something fundamental about branches I do not understand: The problem Let $G$ be an open subset of $\mathbb{C}$ and $z_1,z_2,...z_m \in \mathbb C \setminus G$ be distinct points such that there are real numbers $a_1,a_2,...a_m$ satisfying: $$\sum_{j=1}^ma_jInd_\gamma(z_j)=0$$ for every closed path $\gamma \subset G$. Show that there is a holomorphic branch of $(z-z_1)^{a_1}(z-z_2)^{a_2}...(z-z_m)^{a_m}$ in $G$. My confusion The basic idea behind the statement of the problem seems intuitively obvious to me, but I've had great difficulty expressing a solution rigurously, which makes me believe there's something fundamental I'm missing here. My approach was to try and utilize a theorem that states $logf$ has a holomorphic branch in $G$ if and only if $$\int_\gamma \frac{f'}{f}dz=0$$ for every closed path $\gamma \subset G$. However, the only sensible way I can think of to define $f$ is by $f=\exp[\sum_{j=1}^{m}a_jlog(z-z_j)]$ Obviously if the exponent is holomorphic, so is $f$, but how can it be shown that it is indeed holomorphic? Induction does not work because the separate $log(z-z_j)$ may not exist on their own, even though their weighted sum does. It is also quite simple to show that $f$ as defined in the problem satisfies the conditions of the theorem, and hence the sum of logarithms in the above exponent is indeed holomorphic.. but that presumes that $f$ exists (and is holomorphic) in the first place. Can $f$ be defined in some other way that makes this all fall into place?",,"['complex-analysis', 'logarithms', 'winding-number']"
14,Checking whether a complex function has an antiderivative,Checking whether a complex function has an antiderivative,,"There is a function $f(z)$ given: $$f(z) = \frac{z}{z^2 + 1}.$$ $z \in \Omega = \mathbb{C} \setminus \overline{D(0,1)}$, where $D(0, 1)$ is a disc centered at zero and its radius is equal to 1. I am to check whether the given function has an antiderivative. What am I to check? To my mind it is necessary to check if integral over any line from point $a$ to point $b$ is equal to $0$. Is this condition equivalent to the statement that $f$ is holomorphic on every single-coherent area which is included in $\Omega$? Calculations If $1$ is true how can I check if integrals over any line is equal to $0$?","There is a function $f(z)$ given: $$f(z) = \frac{z}{z^2 + 1}.$$ $z \in \Omega = \mathbb{C} \setminus \overline{D(0,1)}$, where $D(0, 1)$ is a disc centered at zero and its radius is equal to 1. I am to check whether the given function has an antiderivative. What am I to check? To my mind it is necessary to check if integral over any line from point $a$ to point $b$ is equal to $0$. Is this condition equivalent to the statement that $f$ is holomorphic on every single-coherent area which is included in $\Omega$? Calculations If $1$ is true how can I check if integrals over any line is equal to $0$?",,"['integration', 'complex-analysis', 'holomorphic-functions']"
15,"How do I solve $\frac{1}{2\pi}\int_{-\infty}^\infty \frac{e^{i(t-t')u}\,du}{-u^2 + \omega^2 -i\epsilon}$ to find Green's function?",How do I solve  to find Green's function?,"\frac{1}{2\pi}\int_{-\infty}^\infty \frac{e^{i(t-t')u}\,du}{-u^2 + \omega^2 -i\epsilon}","I want to find the Green's function defined by the following equation: $$\left(\frac{d^2}{dt^2} + \omega^2 - i\epsilon \right)G(t,t') = \delta(t-t').$$ For this I performed the Fourier transform of both sides, using identities for the Fourier transform of a second derivative to get the algebraic equation: $$\left(-u^2 + \omega^2 -i\epsilon \right) \tilde{G}(u,t') = \frac{1}{\sqrt{2\pi}} e^{-it'u}.$$ We can solve this algebraically and perform the inverse Fourier transform: \begin{align} G(t,t') &= \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}} \frac{e^{-it'u}}{-u^2 + \omega^2 -i\epsilon} \: e^{itu}\,du \\ &=  \frac{1}{2\pi}\int_{-\infty}^\infty \frac{e^{i(t-t')u}\,du}{-u^2 + \omega^2 -i\epsilon} \end{align} I can solve this by identifying the poles and using the residue theorem, but it's not clear to me how to do this. Can someone explain? How do I identify the poles and what contour should I choose to get the result?","I want to find the Green's function defined by the following equation: $$\left(\frac{d^2}{dt^2} + \omega^2 - i\epsilon \right)G(t,t') = \delta(t-t').$$ For this I performed the Fourier transform of both sides, using identities for the Fourier transform of a second derivative to get the algebraic equation: $$\left(-u^2 + \omega^2 -i\epsilon \right) \tilde{G}(u,t') = \frac{1}{\sqrt{2\pi}} e^{-it'u}.$$ We can solve this algebraically and perform the inverse Fourier transform: \begin{align} G(t,t') &= \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}} \frac{e^{-it'u}}{-u^2 + \omega^2 -i\epsilon} \: e^{itu}\,du \\ &=  \frac{1}{2\pi}\int_{-\infty}^\infty \frac{e^{i(t-t')u}\,du}{-u^2 + \omega^2 -i\epsilon} \end{align} I can solve this by identifying the poles and using the residue theorem, but it's not clear to me how to do this. Can someone explain? How do I identify the poles and what contour should I choose to get the result?",,"['integration', 'complex-analysis', 'greens-function']"
16,Proof similarity of complex power series,Proof similarity of complex power series,,"Let be the functions $$ f(x)=\sqrt{2}\frac{\cos(\frac{\pi}{4}-\frac{1}{2}\arctan(x))}{(1+x^2)^{1/4}} \qquad g(x)=\frac{1}{\sqrt{1-x}} $$ Obviously, they are holomorphic functions in a neighborhood of $0$. The series of $g(z)$ is well known and using Mathematica we have $$ f(x)= 1+\frac{x}{2}- \frac{3x^2}{8}-\frac{5x^3}{16}+\frac{35x^4}{128}+\frac{63x^5}{256}-\frac{231x^6}{1024}-\frac{429x^7}{2048}+\dotsc $$ $$ g(x)= 1+\frac{x}{2}+ \frac{3x^2}{8}+\frac{5x^3}{16}+\frac{35x^4}{128}+\frac{63x^5}{256}+\frac{231x^6}{1024}+\frac{429x^7}{2048}+\dotsc $$ Exercise . Proof the absolute value of the coefficients of the two series are the same. Attemp . With trigonometric manipulation I get $$ f(x)=\frac{1+x+\sqrt{1+x^2}}{\sqrt{2}(1+x^2)^{3/4}\sqrt{1+\frac{1}{\sqrt{1+x^2}}}} $$ My idea is use the Cauchy Integral Theorem to calculate the coefficients  $$ a_n = \frac{1}{2\pi i}\int_C \frac{f(z)}{z^{n+1}}dz $$ and with changes of variables get something that seems to $$ \frac{1}{2\pi i}\int_C \frac{g(z)}{z^{n+1}}dz $$  But if I work in $\mathbb{C}$ I need to define $\log(1+z^2)$ and work with it in changes of variables doesn't look so friendly. Can you give me a hint to prove it?","Let be the functions $$ f(x)=\sqrt{2}\frac{\cos(\frac{\pi}{4}-\frac{1}{2}\arctan(x))}{(1+x^2)^{1/4}} \qquad g(x)=\frac{1}{\sqrt{1-x}} $$ Obviously, they are holomorphic functions in a neighborhood of $0$. The series of $g(z)$ is well known and using Mathematica we have $$ f(x)= 1+\frac{x}{2}- \frac{3x^2}{8}-\frac{5x^3}{16}+\frac{35x^4}{128}+\frac{63x^5}{256}-\frac{231x^6}{1024}-\frac{429x^7}{2048}+\dotsc $$ $$ g(x)= 1+\frac{x}{2}+ \frac{3x^2}{8}+\frac{5x^3}{16}+\frac{35x^4}{128}+\frac{63x^5}{256}+\frac{231x^6}{1024}+\frac{429x^7}{2048}+\dotsc $$ Exercise . Proof the absolute value of the coefficients of the two series are the same. Attemp . With trigonometric manipulation I get $$ f(x)=\frac{1+x+\sqrt{1+x^2}}{\sqrt{2}(1+x^2)^{3/4}\sqrt{1+\frac{1}{\sqrt{1+x^2}}}} $$ My idea is use the Cauchy Integral Theorem to calculate the coefficients  $$ a_n = \frac{1}{2\pi i}\int_C \frac{f(z)}{z^{n+1}}dz $$ and with changes of variables get something that seems to $$ \frac{1}{2\pi i}\int_C \frac{g(z)}{z^{n+1}}dz $$  But if I work in $\mathbb{C}$ I need to define $\log(1+z^2)$ and work with it in changes of variables doesn't look so friendly. Can you give me a hint to prove it?",,"['complex-analysis', 'complex-numbers', 'power-series']"
17,Laurent series of complex function,Laurent series of complex function,,"So I want to calculate the Laurent series of this function $$ f: \mathbb{C}   \to \mathbb{C}, \quad f(z) = \frac{1}{z^{2}+1}.$$ The Laurent series has to be in this form: $$\sum_{n=- \infty }^{ \infty } a_{n} (z-i)^n$$ for a circular disc $$ 0<| z-i|<p,$$  where $p$ has to be found. With partial fraction expansion I am getting $$ f(z) =\frac{i}{2}\left( \frac{1}{z+i} - \frac{1}{z-i}\right).$$ For the first summand, $$\frac{1}{z+i} = \frac{1}{2i} \frac{1}{1+\frac{z-i}{2i}} = \frac{1}{2i} \sum_{n= 0 }^{ \infty }\left(\frac{-(z-i)}{2i}\right)^n = \frac{1}{2i} \sum_{n= 0 }^{ \infty } \left(\frac{i}{2}\right)^n (z-i)^n $$ for $$\left|\frac{-(z-i)}{2i}\right| < 1  \Longrightarrow \left| z-i \right| < 2.$$ Now I don't know how to continue with $$\frac{1}{z-i} .$$","So I want to calculate the Laurent series of this function $$ f: \mathbb{C}   \to \mathbb{C}, \quad f(z) = \frac{1}{z^{2}+1}.$$ The Laurent series has to be in this form: $$\sum_{n=- \infty }^{ \infty } a_{n} (z-i)^n$$ for a circular disc $$ 0<| z-i|<p,$$  where $p$ has to be found. With partial fraction expansion I am getting $$ f(z) =\frac{i}{2}\left( \frac{1}{z+i} - \frac{1}{z-i}\right).$$ For the first summand, $$\frac{1}{z+i} = \frac{1}{2i} \frac{1}{1+\frac{z-i}{2i}} = \frac{1}{2i} \sum_{n= 0 }^{ \infty }\left(\frac{-(z-i)}{2i}\right)^n = \frac{1}{2i} \sum_{n= 0 }^{ \infty } \left(\frac{i}{2}\right)^n (z-i)^n $$ for $$\left|\frac{-(z-i)}{2i}\right| < 1  \Longrightarrow \left| z-i \right| < 2.$$ Now I don't know how to continue with $$\frac{1}{z-i} .$$",,"['complex-analysis', 'laurent-series']"
18,Integration of $\int_{-1}^{1}\frac{dx}{(x-a)\sqrt{1-x^2}}$ using Residue Calculus,Integration of  using Residue Calculus,\int_{-1}^{1}\frac{dx}{(x-a)\sqrt{1-x^2}},"I would like to use residue calculus to prove that $\int_{-1}^{1}\frac{dx}{(x-a)\sqrt{1-x^2}} = \frac{\pi}{\sqrt{a^2-1}}$ , where $a$ is a complex constant outside of the real interval $[-1, 1]$. My idea for a strategy is to use a contour shaped like a dog-bone. It consists of two small circles (of radius $\varepsilon$) around $-1$ and $1$, that are connected by two segments near the real axis (one slightly above, and one slightly below). We know that the poles at $1$ and $-1$ are contained in the contour, and the pole at $z=a$ is not (for small enough $\varepsilon$). I would like to show integral goes to zero on the circle segments but I am having trouble doing this. Since the integrand is odd, we know that the segments along the axis will give us twice the required integral . By the residue theorem, we know that the integral over the contour equals $2\pi i$ times the sum of the residues of the poles contained within the contour. However, I am also having trouble calculating these two residues. I don't think any other contour would work because we do not  know where $a$ is on the complex plane. Any help would be greatly appreciated. - Progress Update: I have figured out how to show that the integral goes to zero on the circle segments. However, I have also realized that the integrand is actually not odd (it was silly of me to make such a mistake). So now I am stuck trying to find a relationship between the integral along the top segment and the integral along the bottom segment. One of these is the desired integral, depending on the direction of the contour. But I do not know how to handle the other segment.","I would like to use residue calculus to prove that $\int_{-1}^{1}\frac{dx}{(x-a)\sqrt{1-x^2}} = \frac{\pi}{\sqrt{a^2-1}}$ , where $a$ is a complex constant outside of the real interval $[-1, 1]$. My idea for a strategy is to use a contour shaped like a dog-bone. It consists of two small circles (of radius $\varepsilon$) around $-1$ and $1$, that are connected by two segments near the real axis (one slightly above, and one slightly below). We know that the poles at $1$ and $-1$ are contained in the contour, and the pole at $z=a$ is not (for small enough $\varepsilon$). I would like to show integral goes to zero on the circle segments but I am having trouble doing this. Since the integrand is odd, we know that the segments along the axis will give us twice the required integral . By the residue theorem, we know that the integral over the contour equals $2\pi i$ times the sum of the residues of the poles contained within the contour. However, I am also having trouble calculating these two residues. I don't think any other contour would work because we do not  know where $a$ is on the complex plane. Any help would be greatly appreciated. - Progress Update: I have figured out how to show that the integral goes to zero on the circle segments. However, I have also realized that the integrand is actually not odd (it was silly of me to make such a mistake). So now I am stuck trying to find a relationship between the integral along the top segment and the integral along the bottom segment. One of these is the desired integral, depending on the direction of the contour. But I do not know how to handle the other segment.",,"['complex-analysis', 'residue-calculus', 'complex-integration']"
19,Looking for complex roots of unity which also happen to be complex primes,Looking for complex roots of unity which also happen to be complex primes,,"Can someone point me to resources that could either give examples of complex roots of unity which also happen to be complex primes (Eisenstein primes, Gauss primes, or any other type if they exist) or a proof that such complex numbers can’t exist? Have searched google but couldn’t find information on such intersection of the two types of complex numbers. Thanks!","Can someone point me to resources that could either give examples of complex roots of unity which also happen to be complex primes (Eisenstein primes, Gauss primes, or any other type if they exist) or a proof that such complex numbers can’t exist? Have searched google but couldn’t find information on such intersection of the two types of complex numbers. Thanks!",,"['complex-analysis', 'number-theory', 'complex-numbers', 'prime-numbers', 'prime-factorization']"
20,Combining strictly positive numbers to complex powers?,Combining strictly positive numbers to complex powers?,,"Given complex numbers $z_1,z_2\in\mathbb{C}$ and strictly positive numbers $a,b>0$, are the following statements true in general? $$a^{z_1}b^{z_1}=(ab)^{z_1}~~~,~~~a^{z_1}a^{z_2}=a^{z_1+z_2}$$ If so, how to prove it? If not, which restriction would have to be applied to make it true? Thanks for any suggestion!","Given complex numbers $z_1,z_2\in\mathbb{C}$ and strictly positive numbers $a,b>0$, are the following statements true in general? $$a^{z_1}b^{z_1}=(ab)^{z_1}~~~,~~~a^{z_1}a^{z_2}=a^{z_1+z_2}$$ If so, how to prove it? If not, which restriction would have to be applied to make it true? Thanks for any suggestion!",,"['complex-analysis', 'complex-numbers']"
21,Criteria of the holomorphic subbundle,Criteria of the holomorphic subbundle,,"Note that $\mathcal{E} = (E, \bar{\partial}_{\mathcal{E}})$ is a holomorphic vector bundle over complex manifold $X$, where $\bar{\partial}_{\mathcal{E}}$ is a integrable Dolbeault operator on $E$. Now, I consider a $h_0$-orthogonal projection $\pi \in C^{\infty}(End(E))$, that is $\pi^\ast = \pi = \pi^2$, where $h_0$ is a Hermitian metric on $\mathcal{E}$. Why the following statement is true: if $\pi$ satisfies  $$(Id_{\mathcal{E}} - \pi) \circ \bar{\partial}_{\mathcal{E}} \circ \pi = 0,$$ then $F := im(\pi)$ is a holomorphic subbundle on $\mathcal{E}$?","Note that $\mathcal{E} = (E, \bar{\partial}_{\mathcal{E}})$ is a holomorphic vector bundle over complex manifold $X$, where $\bar{\partial}_{\mathcal{E}}$ is a integrable Dolbeault operator on $E$. Now, I consider a $h_0$-orthogonal projection $\pi \in C^{\infty}(End(E))$, that is $\pi^\ast = \pi = \pi^2$, where $h_0$ is a Hermitian metric on $\mathcal{E}$. Why the following statement is true: if $\pi$ satisfies  $$(Id_{\mathcal{E}} - \pi) \circ \bar{\partial}_{\mathcal{E}} \circ \pi = 0,$$ then $F := im(\pi)$ is a holomorphic subbundle on $\mathcal{E}$?",,"['complex-analysis', 'differential-geometry', 'complex-geometry']"
22,Integral of rational function - which contour to use?,Integral of rational function - which contour to use?,,"Evaluate : $$\int_{-\infty}^{+\infty} \frac {x}{(x^2+2x+2)(x^2+4)}$$ I found that the integrand can be extended to a function on a complex plane has simple poles at $\pm 2i$ and  $-1\pm i$. Now I want to compute the integral by contour integration but I am unable to assume any contour here. Do excuse me , if my approach is wrong.","Evaluate : $$\int_{-\infty}^{+\infty} \frac {x}{(x^2+2x+2)(x^2+4)}$$ I found that the integrand can be extended to a function on a complex plane has simple poles at $\pm 2i$ and  $-1\pm i$. Now I want to compute the integral by contour integration but I am unable to assume any contour here. Do excuse me , if my approach is wrong.",,"['complex-analysis', 'improper-integrals', 'complex-integration']"
23,"Distinct solutions of $f(z) - w_0 = 0$ for $f$ holomorphic, $w_0$ in a punctured neighborhood of $f(z_0) = 0$","Distinct solutions of  for  holomorphic,  in a punctured neighborhood of",f(z) - w_0 = 0 f w_0 f(z_0) = 0,"Problem: Let $f:\Omega\to\Bbb C$ be a holomorphic function ( $\Omega$ is open), and $f$ has a zero of order $k$ at $z_0\in\Omega.$ Show that there is a neighborhood $U$ of $z_0$ and a neighborhood $V$ of $f(z_0)$ such that if $w_0 \in V-\{f(z_0)\},$ then $f(z)-w_0=0$ has $k$ distinct roots in $U - \{z_0 \}.$ Attempt at solution: I was thinking about showing that there are $z_1,\ldots,z_k$ such that $f(z_i)=w_0$ and $f'(z_i) = (f(z_i) - w_0)'\ne 0,$ thus, showing that there are $k$ distinct solutions to the equation. Maybe I can make use of the Cauchy integral formula and $f(z_0) = 0$ and $w_0$ being near $f(z_0)$ to show that the derivatives are indeed nonzero, however, I am having trouble making this intuition precise and actually finding the $k$ solutions. Any help is appreciated!","Problem: Let be a holomorphic function ( is open), and has a zero of order at Show that there is a neighborhood of and a neighborhood of such that if then has distinct roots in Attempt at solution: I was thinking about showing that there are such that and thus, showing that there are distinct solutions to the equation. Maybe I can make use of the Cauchy integral formula and and being near to show that the derivatives are indeed nonzero, however, I am having trouble making this intuition precise and actually finding the solutions. Any help is appreciated!","f:\Omega\to\Bbb C \Omega f k z_0\in\Omega. U z_0 V f(z_0) w_0 \in V-\{f(z_0)\}, f(z)-w_0=0 k U - \{z_0 \}. z_1,\ldots,z_k f(z_i)=w_0 f'(z_i) = (f(z_i) - w_0)'\ne 0, k f(z_0) = 0 w_0 f(z_0) k","['complex-analysis', 'roots']"
24,$P \in \mathbb C[X]$ such that $P(\mathbb R\setminus\mathbb Q) \subset \mathbb R\setminus\mathbb Q$ [closed],such that  [closed],P \in \mathbb C[X] P(\mathbb R\setminus\mathbb Q) \subset \mathbb R\setminus\mathbb Q,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question Which polynomials $P(X)$ in $\mathbb C[X]$ satisfy $5) \ P(\mathbb R\setminus\mathbb Q) \subset \mathbb R\setminus\mathbb Q$? The followings have already been solved: $1) \ P(\mathbb C) \subset \mathbb R$? $2) \ P(\mathbb U) \subset \mathbb U$ with $\mathbb U$ being the unit circle $\big\{z\in\mathbb{Z}\,\big|\,|z|=1\big\}$? $2') \ P(\mathbb U) = \mathbb U$? $3) \ P(\mathbb Z) \subset \mathbb Z$? $4) \ P(\mathbb Q) \subset \mathbb Q$? $4') \ P(\mathbb Q) = \mathbb Q$?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question Which polynomials $P(X)$ in $\mathbb C[X]$ satisfy $5) \ P(\mathbb R\setminus\mathbb Q) \subset \mathbb R\setminus\mathbb Q$? The followings have already been solved: $1) \ P(\mathbb C) \subset \mathbb R$? $2) \ P(\mathbb U) \subset \mathbb U$ with $\mathbb U$ being the unit circle $\big\{z\in\mathbb{Z}\,\big|\,|z|=1\big\}$? $2') \ P(\mathbb U) = \mathbb U$? $3) \ P(\mathbb Z) \subset \mathbb Z$? $4) \ P(\mathbb Q) \subset \mathbb Q$? $4') \ P(\mathbb Q) = \mathbb Q$?",,"['real-analysis', 'abstract-algebra']"
25,Problem computing $\int_{-\infty}^\infty \frac{\tan^{-1}(x)}{x}dx$ using contour integral.,Problem computing  using contour integral.,\int_{-\infty}^\infty \frac{\tan^{-1}(x)}{x}dx,"I am trying to solve $$\int_{-\infty}^\infty \frac{\tan^{-1}x}{x}\ dx$$ using a contour integral. My Work: Define a contour $C$ such that: Now we have $$\int_{C}\frac{\tan^{-1}x}{x}\ dx=\int_{-\infty}^\infty \frac{\tan^{-1}x}{x}\ dx+\int_{\text{Arc}}\frac{\tan^{-1}x}{x}\ dx$$ Now parametizing the integral over the arc: $$\int_{\text{Arc}}\frac{\tan^{-1}x}{x}\ dx=\lim_{R\to \infty}\int_{0}^\pi \frac{\tan^{-1}(Re^{i\theta})}{Re^{i\theta}}iRe^{i\theta}\ d\theta=\lim_{R\to \infty} i\int_{0}^\pi \tan^{-1}(Re^{i\theta})\ d\theta=\frac{i\pi^2}{2}$$ We also note that the entire contour integral does not contain any poles, so it is $0$. However this is where I run into a problem because that implies:$$\int_{-\infty}^\infty \frac{\tan^{-1}x}{x}\ dx=-\frac{i\pi^2}{2}$$ Which is obviously not true. If anyone can point out why my approach does not work or where I went wrong that would be great. Any help is appreciated.","I am trying to solve $$\int_{-\infty}^\infty \frac{\tan^{-1}x}{x}\ dx$$ using a contour integral. My Work: Define a contour $C$ such that: Now we have $$\int_{C}\frac{\tan^{-1}x}{x}\ dx=\int_{-\infty}^\infty \frac{\tan^{-1}x}{x}\ dx+\int_{\text{Arc}}\frac{\tan^{-1}x}{x}\ dx$$ Now parametizing the integral over the arc: $$\int_{\text{Arc}}\frac{\tan^{-1}x}{x}\ dx=\lim_{R\to \infty}\int_{0}^\pi \frac{\tan^{-1}(Re^{i\theta})}{Re^{i\theta}}iRe^{i\theta}\ d\theta=\lim_{R\to \infty} i\int_{0}^\pi \tan^{-1}(Re^{i\theta})\ d\theta=\frac{i\pi^2}{2}$$ We also note that the entire contour integral does not contain any poles, so it is $0$. However this is where I run into a problem because that implies:$$\int_{-\infty}^\infty \frac{\tan^{-1}x}{x}\ dx=-\frac{i\pi^2}{2}$$ Which is obviously not true. If anyone can point out why my approach does not work or where I went wrong that would be great. Any help is appreciated.",,"['calculus', 'integration', 'complex-analysis', 'contour-integration']"
26,An over-zigzag (if not silly) writing of definition of analyticity in Amann's Analysis Book.,An over-zigzag (if not silly) writing of definition of analyticity in Amann's Analysis Book.,,"In a famous textbook, Amann's Analysis I , the author introduce the analyticity as the below picture. Notice that the author defined this terminology with respect to a set $D$, rather than a point $c$. Actually, there is no a definition for being able to say something like ""a function $f$ is analytic at a point $c$"" in this book. And then, in Remarks (c) , the author said that ""analyticity"" is a local property; that is, for $f:E\to\Bbb R$, if ($\forall x\in E,~f$ is analytic on a neighborhood of $x$), then $f$ is analytic on the whole domain $E$. Let's stop here, and look at how the same thing is discussed in Terrence Tao's Analysis I : The difference is that Tao first defined what is called analytic at a point $c$, then simply extend to what is called analytic on a set $E$, which is more straightforward and intuitive. Actually, Amann didn't really get rid of defining the ""one point"" version. Look closer at Amann's definition, his definition is essentially equivalent to say $f$ is called analytic on $D$ if for each $x_o\in D$, $f$ is ""somewhat analytic at $x_0$"", the remaing all words is his original definition that I omitted is just the definition of ""$f$ is somewhat analytic at $x_0$"". So I think the way he write is quite zigzag and unnatural, if not silly. Why not give the version of one-point analytic first? On the other hand, if he had stated the ""one point"" definition first, then ""set version"", then his Remark (c) might been at least quite easy enough, if not too trivial. Am I correct? Or is there other reason that he chose so?","In a famous textbook, Amann's Analysis I , the author introduce the analyticity as the below picture. Notice that the author defined this terminology with respect to a set $D$, rather than a point $c$. Actually, there is no a definition for being able to say something like ""a function $f$ is analytic at a point $c$"" in this book. And then, in Remarks (c) , the author said that ""analyticity"" is a local property; that is, for $f:E\to\Bbb R$, if ($\forall x\in E,~f$ is analytic on a neighborhood of $x$), then $f$ is analytic on the whole domain $E$. Let's stop here, and look at how the same thing is discussed in Terrence Tao's Analysis I : The difference is that Tao first defined what is called analytic at a point $c$, then simply extend to what is called analytic on a set $E$, which is more straightforward and intuitive. Actually, Amann didn't really get rid of defining the ""one point"" version. Look closer at Amann's definition, his definition is essentially equivalent to say $f$ is called analytic on $D$ if for each $x_o\in D$, $f$ is ""somewhat analytic at $x_0$"", the remaing all words is his original definition that I omitted is just the definition of ""$f$ is somewhat analytic at $x_0$"". So I think the way he write is quite zigzag and unnatural, if not silly. Why not give the version of one-point analytic first? On the other hand, if he had stated the ""one point"" definition first, then ""set version"", then his Remark (c) might been at least quite easy enough, if not too trivial. Am I correct? Or is there other reason that he chose so?",,"['real-analysis', 'complex-analysis', 'analysis', 'power-series']"
27,Evaluate $\int_{-\infty}^\infty \frac{\cos x}{1-x^4}dx.$,Evaluate,\int_{-\infty}^\infty \frac{\cos x}{1-x^4}dx.,"It equals $\Re \int_{-\infty}^\infty \frac{e^{iz}}{1-z^4}dz.$ The integrand $f(z)=\frac{e^{iz}}{1-z^4}$ has one simple pole$(z=i)$ in the upper half-plane, two simple poles$(z=\pm1)$ on the real axis. $Res(f,i)=\frac{ze^{iz}}{-4} |_{z=i}=-\frac{ie^{-1}}{4}, Res(f,1)=-\frac{e^i}{4}, Res(f,-1)=\frac{e^{-i}}{4}.$ By contour integration, $\Re \int_{-\infty}^\infty \frac{e^{iz}}{1-z^4}dz = \Re[2\pi iRes(f,i)+\pi i\big(Res(f,1)+Res(f,-1)\big)]=\frac \pi 2(\sin 1+e^{-1}).$ But the answer gives ""$\frac \pi 4(e^{-1}-\sin1)$"". Where is wrong?","It equals $\Re \int_{-\infty}^\infty \frac{e^{iz}}{1-z^4}dz.$ The integrand $f(z)=\frac{e^{iz}}{1-z^4}$ has one simple pole$(z=i)$ in the upper half-plane, two simple poles$(z=\pm1)$ on the real axis. $Res(f,i)=\frac{ze^{iz}}{-4} |_{z=i}=-\frac{ie^{-1}}{4}, Res(f,1)=-\frac{e^i}{4}, Res(f,-1)=\frac{e^{-i}}{4}.$ By contour integration, $\Re \int_{-\infty}^\infty \frac{e^{iz}}{1-z^4}dz = \Re[2\pi iRes(f,i)+\pi i\big(Res(f,1)+Res(f,-1)\big)]=\frac \pi 2(\sin 1+e^{-1}).$ But the answer gives ""$\frac \pi 4(e^{-1}-\sin1)$"". Where is wrong?",,"['complex-analysis', 'contour-integration', 'residue-calculus']"
28,Prove $f(z)$ is continuous at $z_o$ iff its real and imaginary parts are continuous at $z_o$,Prove  is continuous at  iff its real and imaginary parts are continuous at,f(z) z_o z_o,"Was wondering if I could get some suggestions/second looks at my proof where $f(z) = f(x +iy) = u(x, y) + iv(x,y).$ I'm not sure about the right direction especially show $u, v$ are continuous. ($\implies$) Suppose $f(z)$ is continuous at $z_o = x_o + iy_o$. Then for all $\epsilon > 0, \exists \delta > 0$ so that if $|z - z_o| < \delta$ then $|f(z) - f(z_o)| < \epsilon$. Note that: $|u(x, y) - u(x_o, y_o)|, |v(x, y) - v(x_o, y_o)| \leq |f(z) - f(z_o)| \leq |u(x, y) - u(x_o, y_o)|+ |v(x, y) - v(x_o, y_o)|$ Since $f(z) - f(z_o) = u(x,y) + iv(x,y) - [u(x_o, y_o) + iv(x_o, y_o)] = [u(x,y) - u(x_o, y_o)] +i[v(x,y) - v(x_o, y_o)]$ And we know that $|Re z|, |Imz| \leq |z| \leq |Rez| + |Imz|$. Since $|(x,y) - (x_o, y_o)| \leq |z-z_o| < \delta$ then $|u(x, y) - u(x_o, y_o)| \leq |f(z) - f(z_o)| < \epsilon$ and so $u(x, y)$ is continuous at $z_o$. Similarly, since $|(x,y) - (x_o, y_o)| \leq |z-z_o| < \delta$ then $|v(x, y) - v(x_o, y_o)| \leq |f(z) - f(z_o)| < \epsilon$ and so $v(x, y)$ is continuous at $z_o$. ($\impliedby$) Suppose $u(x,y), v(x,y)$ are continuous. Then for $\epsilon_1, \epsilon_2 > 0, \exists \delta_1, \delta_2 > 0$ so that if $|(x,y) - (x_o, y_o)| < \delta_1$ then $|u(x,y) - u(x_o, y_o)| < \epsilon_1$. Likewise, if $|(x,y) - (x_o, y_o)| < \delta_2$ then $|v(x,y) - v(x_o, y_o)| < \epsilon_2$. Let $\epsilon > \epsilon_1 + \epsilon_2 > 0$ and take $\delta = \min\{\delta_1, \delta_2\}$. Then if $|z - z_o| < \delta$ this means $|(x,y) - (x_o, y_o)| < |z -  z_o| < \delta_1, \delta_2$ so we have: $|f(z) - f(z_o)| \leq |u(x,y) - u(x_o, y_o)| + |v(x,y) - v(x_o, y_o)| < \epsilon_1 + \epsilon_2 < \epsilon \ \ \ \ \ \ \ \square$","Was wondering if I could get some suggestions/second looks at my proof where $f(z) = f(x +iy) = u(x, y) + iv(x,y).$ I'm not sure about the right direction especially show $u, v$ are continuous. ($\implies$) Suppose $f(z)$ is continuous at $z_o = x_o + iy_o$. Then for all $\epsilon > 0, \exists \delta > 0$ so that if $|z - z_o| < \delta$ then $|f(z) - f(z_o)| < \epsilon$. Note that: $|u(x, y) - u(x_o, y_o)|, |v(x, y) - v(x_o, y_o)| \leq |f(z) - f(z_o)| \leq |u(x, y) - u(x_o, y_o)|+ |v(x, y) - v(x_o, y_o)|$ Since $f(z) - f(z_o) = u(x,y) + iv(x,y) - [u(x_o, y_o) + iv(x_o, y_o)] = [u(x,y) - u(x_o, y_o)] +i[v(x,y) - v(x_o, y_o)]$ And we know that $|Re z|, |Imz| \leq |z| \leq |Rez| + |Imz|$. Since $|(x,y) - (x_o, y_o)| \leq |z-z_o| < \delta$ then $|u(x, y) - u(x_o, y_o)| \leq |f(z) - f(z_o)| < \epsilon$ and so $u(x, y)$ is continuous at $z_o$. Similarly, since $|(x,y) - (x_o, y_o)| \leq |z-z_o| < \delta$ then $|v(x, y) - v(x_o, y_o)| \leq |f(z) - f(z_o)| < \epsilon$ and so $v(x, y)$ is continuous at $z_o$. ($\impliedby$) Suppose $u(x,y), v(x,y)$ are continuous. Then for $\epsilon_1, \epsilon_2 > 0, \exists \delta_1, \delta_2 > 0$ so that if $|(x,y) - (x_o, y_o)| < \delta_1$ then $|u(x,y) - u(x_o, y_o)| < \epsilon_1$. Likewise, if $|(x,y) - (x_o, y_o)| < \delta_2$ then $|v(x,y) - v(x_o, y_o)| < \epsilon_2$. Let $\epsilon > \epsilon_1 + \epsilon_2 > 0$ and take $\delta = \min\{\delta_1, \delta_2\}$. Then if $|z - z_o| < \delta$ this means $|(x,y) - (x_o, y_o)| < |z -  z_o| < \delta_1, \delta_2$ so we have: $|f(z) - f(z_o)| \leq |u(x,y) - u(x_o, y_o)| + |v(x,y) - v(x_o, y_o)| < \epsilon_1 + \epsilon_2 < \epsilon \ \ \ \ \ \ \ \square$",,"['complex-analysis', 'proof-verification']"
29,Intuition behind Simply Connected Open Set,Intuition behind Simply Connected Open Set,,"Sometimes we state mathematical properties on a ""simply connected open set"". Some examples include Green Theorem, Cauchy Theorem, etc. Aside from being technically required by the proofs, what would be the intuition behind this condition, i.e. when will mathematicians resort to impose such a condition? What are the motivations?","Sometimes we state mathematical properties on a ""simply connected open set"". Some examples include Green Theorem, Cauchy Theorem, etc. Aside from being technically required by the proofs, what would be the intuition behind this condition, i.e. when will mathematicians resort to impose such a condition? What are the motivations?",,"['calculus', 'complex-analysis', 'intuition']"
30,What is the derivative of the modulus of a complex function?,What is the derivative of the modulus of a complex function?,,"For $|f(z)| = |z|$, where $z = x + iy$, $x$, $y$ real, it is known that the modulus $|z|$ is complex differentiable only at $z = 0$, i.e. $x = y = 0$. My question concerns the differentiability of the modulus of a general complex function $|f(z)|^2 = |U(z) + iV(z)|^2 = U^2 + V^2$. I have found no reference that deals with this question. My reasoning is that this differentiability should be at $U = V = 0$, not at $x = y = 0$ Related questions: (1) what is the expression of this derivative?  (2) Is this derivative equal to zero? I would say yes, it is.","For $|f(z)| = |z|$, where $z = x + iy$, $x$, $y$ real, it is known that the modulus $|z|$ is complex differentiable only at $z = 0$, i.e. $x = y = 0$. My question concerns the differentiability of the modulus of a general complex function $|f(z)|^2 = |U(z) + iV(z)|^2 = U^2 + V^2$. I have found no reference that deals with this question. My reasoning is that this differentiability should be at $U = V = 0$, not at $x = y = 0$ Related questions: (1) what is the expression of this derivative?  (2) Is this derivative equal to zero? I would say yes, it is.",,['complex-analysis']
31,An Entire function with growth estimate implies $f(z) = \sin{z}$,An Entire function with growth estimate implies,f(z) = \sin{z},"Saw this one from an old exam and have been having trouble trying to crack it. Suppose $f(z)$ is an entire function satisfying $f'(0)=1$, $f(k\pi)=0$ for every integer $k$, and $|f(x+iy)| \leq e^{|y|}$ for $x,\, y \in \mathbb{R}$. Show that $f(z) = \sin{(z)}$. As with similiar problems involving growth estimates and entire functions, my initial idea was to exploit a function like $g(z) = \dfrac{f(z)}{e^{|y|}}$, however I almost feel like its a better idea attacking the coefficients of $f's$ series expansion. Any ideas would be helpful.","Saw this one from an old exam and have been having trouble trying to crack it. Suppose $f(z)$ is an entire function satisfying $f'(0)=1$, $f(k\pi)=0$ for every integer $k$, and $|f(x+iy)| \leq e^{|y|}$ for $x,\, y \in \mathbb{R}$. Show that $f(z) = \sin{(z)}$. As with similiar problems involving growth estimates and entire functions, my initial idea was to exploit a function like $g(z) = \dfrac{f(z)}{e^{|y|}}$, however I almost feel like its a better idea attacking the coefficients of $f's$ series expansion. Any ideas would be helpful.",,['complex-analysis']
32,Path-Independence and the Residue Theorem,Path-Independence and the Residue Theorem,,"My question concerns the path-independence integrals calculated using the residue theorem. Consider the integral $$I=\int_{-\infty}^\infty\! \frac{1}{(z+i)(z+2i)(z+3i)}\ \mathrm{d}z. $$ It seems that by integrating over different contours, one could arrive at different values of $I$.  For example, if one chose a semi-circle in the upper half-plane as a contour, applying Cauchy's Residue Theorem would show $I=0$.  On the other hand if, if one chose a contour in the lower half-plane, one would arrive at $I=-2\pi i\sum_{j=1}^3\mathrm{Res}(f;z_j)$, where $z_j=-i,\ -2i, -3i$.  However, it seems like the value of $I$ should be unique and not depend upon the chosen contour. Is this logic correct?  This question is driving me mad, and I would very much appreciate any help!! Edit: Forgot a minus sign in application of Residue Theorem.","My question concerns the path-independence integrals calculated using the residue theorem. Consider the integral $$I=\int_{-\infty}^\infty\! \frac{1}{(z+i)(z+2i)(z+3i)}\ \mathrm{d}z. $$ It seems that by integrating over different contours, one could arrive at different values of $I$.  For example, if one chose a semi-circle in the upper half-plane as a contour, applying Cauchy's Residue Theorem would show $I=0$.  On the other hand if, if one chose a contour in the lower half-plane, one would arrive at $I=-2\pi i\sum_{j=1}^3\mathrm{Res}(f;z_j)$, where $z_j=-i,\ -2i, -3i$.  However, it seems like the value of $I$ should be unique and not depend upon the chosen contour. Is this logic correct?  This question is driving me mad, and I would very much appreciate any help!! Edit: Forgot a minus sign in application of Residue Theorem.",,"['complex-analysis', 'contour-integration', 'residue-calculus']"
33,Proving $f$ is holomorphic or antiholomorphic if $e^f$ and $f$ are harmonic,Proving  is holomorphic or antiholomorphic if  and  are harmonic,f e^f f,"Suppose we have a harmonic function $f$ such that $e^f$ is also harmonic. I want to prove $f$ is either holomorphic or antiholomorphic. I tried using the fact that $\Delta u= 4\partial_z(\partial_{\overline{z}} u)=0$ but I didn't get anywhere with that and I assumed that does not imply $\partial_{\overline{z}}=0$ or $\partial_z =0$. I actually have the same problem but with $f^2$ instead of $e^f$ and I suppose it is similar, so I hope I can do one knowing how to do the other one.","Suppose we have a harmonic function $f$ such that $e^f$ is also harmonic. I want to prove $f$ is either holomorphic or antiholomorphic. I tried using the fact that $\Delta u= 4\partial_z(\partial_{\overline{z}} u)=0$ but I didn't get anywhere with that and I assumed that does not imply $\partial_{\overline{z}}=0$ or $\partial_z =0$. I actually have the same problem but with $f^2$ instead of $e^f$ and I suppose it is similar, so I hope I can do one knowing how to do the other one.",,"['complex-analysis', 'harmonic-functions']"
34,Summing series in the form: $\sum_{n=\infty}^{\infty}f(n)$ via Complex Methods?,Summing series in the form:  via Complex Methods?,\sum_{n=\infty}^{\infty}f(n),"$(1.)$ $$\sum_{n=\infty}^{\infty}f(n)$$ $(2.)$ $$\sum_{n=1}^{\infty}f(n)=\lim_{n\to\infty}\sum_{n=1}^{n}f(n)$$ How would via the tools of Complex Analysis approach the summation of series in the from defined in $(1.)$ via the tools of Complex Variables ? If possible provide applicable examples. $$EDIT$$ Adding to our original question how would handle the upper bound and lower bound of sum defined in $(1.)$ as $n \, \rightarrow \infty$, how would generalize the approach seen in real-variable methods as seen and defined in $(2.)$.","$(1.)$ $$\sum_{n=\infty}^{\infty}f(n)$$ $(2.)$ $$\sum_{n=1}^{\infty}f(n)=\lim_{n\to\infty}\sum_{n=1}^{n}f(n)$$ How would via the tools of Complex Analysis approach the summation of series in the from defined in $(1.)$ via the tools of Complex Variables ? If possible provide applicable examples. $$EDIT$$ Adding to our original question how would handle the upper bound and lower bound of sum defined in $(1.)$ as $n \, \rightarrow \infty$, how would generalize the approach seen in real-variable methods as seen and defined in $(2.)$.",,"['complex-analysis', 'summation']"
35,Complex analysis question.,Complex analysis question.,,"Which of the following are not true? $(a)$ There exists an analytic function $f:\mathbb{C}\to\mathbb{C}$ such that for all $z\in \mathbb{C}$ , $Re(f(z))=e^x$. $(b)$ There exists an analytic function $f:\mathbb{C}\to\mathbb{C}$ such that $f(0)=1$ and for all $z\in \mathbb{C}$ such that $|z|\geq1$ such that $|f(z)|\leq e^{-|z|}$. could you please give me some hints? I have applied liouville thorem for $(b)$ and got $f(z)$ is constant but not necessarily $f(z)=1$. Am I correct?","Which of the following are not true? $(a)$ There exists an analytic function $f:\mathbb{C}\to\mathbb{C}$ such that for all $z\in \mathbb{C}$ , $Re(f(z))=e^x$. $(b)$ There exists an analytic function $f:\mathbb{C}\to\mathbb{C}$ such that $f(0)=1$ and for all $z\in \mathbb{C}$ such that $|z|\geq1$ such that $|f(z)|\leq e^{-|z|}$. could you please give me some hints? I have applied liouville thorem for $(b)$ and got $f(z)$ is constant but not necessarily $f(z)=1$. Am I correct?",,"['complex-analysis', 'complex-numbers', 'analyticity', 'analytic-functions']"
36,Exact Pole-Zero Cancellation in a SISO Transfer Function,Exact Pole-Zero Cancellation in a SISO Transfer Function,,"Pole-Zero cancellation is one of those phantoms in control which are often either sidestepped or only treated informally. Personally, I've never deeply understood the reasoning behind some of the rules--in fact, there isn't even really a consensus on what that reasoning is. For the purpose of this question, suppose $G$ is a SISO transfer function. Let $p$ be a pole which is exactly cancelled by a zero at the same location. We treat the system $G$ formally in the sense that we assume 100% fidelity to whatever we are trying to model. If you prefer to think of the system in terms of differential equations, this is equivalent to saying the differential equations perfectly model the system. The question is whether or not the system $\tilde{G}$ obtained from cancelling $p$ is distinguishable from $G$. My answer is no by the following reasoning. If $G$ has 100% fidelity then every system parameter is uniquely determined by $G$. It follows that if $H$ is another transfer function and $H(s) = G(s)$ for all $s$, then $H$ is mathematically indistinguishable from $G$ and by extension so too are their system parameters. As regard $G$ and $\tilde{G}$ we have $$G(s) = \frac{s-p}{s-p}\tilde{G}(s)$$ by their definition. Clearly $G(s) = \tilde{G}(s)$ whenever $s\neq p$, so we need only check that $G(p) = \tilde{G}(p).$ To do so we may evaluate $$ \lim_{s\rightarrow p}G(s) = \lim_{s\rightarrow p}\frac{(s-p)\tilde{G}(s)}{s-p}, $$ which by L'Hopital's rule is equivalent to $$ \lim_{s\rightarrow p}\ (s-p)\tilde{G}'(s) + \lim_{s\rightarrow p}\ \tilde{G}(s) = \tilde{G}(p). $$ This calculation finds $G = \tilde{G}$, showing the system before and after pole-zero cancellation are equivalent. I therefore conclude that exact SISO pole-zero cancellation under the assumption of 100% model fidelity has no affect on the system. What are the thoughts of others? Edit Stelios has made some thoughtful points regarding the nature of $p$ as a removable singularity. Unfortunately some of the conventions I've used also appear to have caused confusion, and I will clear them up presently. (1) When I write $G(p)$ I mean $\lim_{s\rightarrow p}G(s)$. I concede that it is unclear whether showing $\lim_{s\rightarrow p}G(s) = \lim_{s\rightarrow p}\tilde{G}(s)$ is equivalent to saying $G(s) = \tilde{G}(s)$ for all $s$, since, as Stelios has argued, it is unclear whether or not $G(p)$ can be assigned any meaning in this way. (2) Supposing that two transfer functions $G$ and $H$ can be assigned meaning for every $s$ in a domain which they share, it is no more than a basic set theoretic statement to define $G =H$ iff $G(s) = H(s)$ for all $s$. In fact, if $A$ and $B$ are sets and $f$ maps $A$ to $B$, then WLOG we may regard $f$ as a subset of $A \times B$ consisting of the points $(x,f(x))$ for $x \in D(f)$. If $g$ is another function and $D(g) = D(f)$, then if $g(x) = f(x)$ for each $x$ in their domain it follows that $f$ and $g$ describe the same subset of $A \times B$. This is surely enough to say $f = g$.","Pole-Zero cancellation is one of those phantoms in control which are often either sidestepped or only treated informally. Personally, I've never deeply understood the reasoning behind some of the rules--in fact, there isn't even really a consensus on what that reasoning is. For the purpose of this question, suppose $G$ is a SISO transfer function. Let $p$ be a pole which is exactly cancelled by a zero at the same location. We treat the system $G$ formally in the sense that we assume 100% fidelity to whatever we are trying to model. If you prefer to think of the system in terms of differential equations, this is equivalent to saying the differential equations perfectly model the system. The question is whether or not the system $\tilde{G}$ obtained from cancelling $p$ is distinguishable from $G$. My answer is no by the following reasoning. If $G$ has 100% fidelity then every system parameter is uniquely determined by $G$. It follows that if $H$ is another transfer function and $H(s) = G(s)$ for all $s$, then $H$ is mathematically indistinguishable from $G$ and by extension so too are their system parameters. As regard $G$ and $\tilde{G}$ we have $$G(s) = \frac{s-p}{s-p}\tilde{G}(s)$$ by their definition. Clearly $G(s) = \tilde{G}(s)$ whenever $s\neq p$, so we need only check that $G(p) = \tilde{G}(p).$ To do so we may evaluate $$ \lim_{s\rightarrow p}G(s) = \lim_{s\rightarrow p}\frac{(s-p)\tilde{G}(s)}{s-p}, $$ which by L'Hopital's rule is equivalent to $$ \lim_{s\rightarrow p}\ (s-p)\tilde{G}'(s) + \lim_{s\rightarrow p}\ \tilde{G}(s) = \tilde{G}(p). $$ This calculation finds $G = \tilde{G}$, showing the system before and after pole-zero cancellation are equivalent. I therefore conclude that exact SISO pole-zero cancellation under the assumption of 100% model fidelity has no affect on the system. What are the thoughts of others? Edit Stelios has made some thoughtful points regarding the nature of $p$ as a removable singularity. Unfortunately some of the conventions I've used also appear to have caused confusion, and I will clear them up presently. (1) When I write $G(p)$ I mean $\lim_{s\rightarrow p}G(s)$. I concede that it is unclear whether showing $\lim_{s\rightarrow p}G(s) = \lim_{s\rightarrow p}\tilde{G}(s)$ is equivalent to saying $G(s) = \tilde{G}(s)$ for all $s$, since, as Stelios has argued, it is unclear whether or not $G(p)$ can be assigned any meaning in this way. (2) Supposing that two transfer functions $G$ and $H$ can be assigned meaning for every $s$ in a domain which they share, it is no more than a basic set theoretic statement to define $G =H$ iff $G(s) = H(s)$ for all $s$. In fact, if $A$ and $B$ are sets and $f$ maps $A$ to $B$, then WLOG we may regard $f$ as a subset of $A \times B$ consisting of the points $(x,f(x))$ for $x \in D(f)$. If $g$ is another function and $D(g) = D(f)$, then if $g(x) = f(x)$ for each $x$ in their domain it follows that $f$ and $g$ describe the same subset of $A \times B$. This is surely enough to say $f = g$.",,"['complex-analysis', 'signal-processing', 'control-theory', 'linear-control']"
37,Solve $\cos(z)=\frac 34+\frac i4$,Solve,\cos(z)=\frac 34+\frac i4,"How can I proceed to solve $$\cos(z)=\frac 34+\frac i4$$ I'm not very good in complex variable... But I know the definition of the complex functions, can you help me?","How can I proceed to solve $$\cos(z)=\frac 34+\frac i4$$ I'm not very good in complex variable... But I know the definition of the complex functions, can you help me?",,"['complex-analysis', 'complex-numbers']"
38,Find all meromorphic functions $f: C \to C$ s.t. $|f(z)|=1$ wherever $|z|=1$,Find all meromorphic functions  s.t.  wherever,f: C \to C |f(z)|=1 |z|=1,"Problem. Find all meromorphic functions $f: C \to C$ s.t. $|f(z)|=1$ wherever $|z|=1$ . $f(z)$ should be like $f=g(z)/h(z)$ , where $g(z)$ , $h(z)$ are holomorphic functions. I know that if $f(z)$ is also meromorphic at infinity, then it is easy to conclude that $f(z) = g(z)/h(z)$ , where $g(z)$ , $h(z)$ are polynomials. But now this condition is not satisfied, so I was stuck. Thanks for opinion.","Problem. Find all meromorphic functions s.t. wherever . should be like , where , are holomorphic functions. I know that if is also meromorphic at infinity, then it is easy to conclude that , where , are polynomials. But now this condition is not satisfied, so I was stuck. Thanks for opinion.",f: C \to C |f(z)|=1 |z|=1 f(z) f=g(z)/h(z) g(z) h(z) f(z) f(z) = g(z)/h(z) g(z) h(z),"['complex-analysis', 'meromorphic-functions']"
39,Determine where $f'(z)$ exists and find its value at those points.,Determine where  exists and find its value at those points.,f'(z),"I am revising complex analysis for an upcoming test and I am finding it hard to finish off certain questions. I feel I start well but cannot remember how to wrap up the answers in proper form. $--------------------------------------$ Letting $z = x + iy$, for each of the following functions determine where $f'(z)$ exists and find its value at those points. (a) $f(z) = z$ Im$(z)$ (b) $f(z) = x^3 + i(1-y)^3$ $--------------------------------------$ For part (a) I am pretty certain $f'(z)$ does not exist: Let $f(z) = $Im$(z)$, then for $z, h \in \Bbb C,$ with $h \ne 0,$ we have $\frac{Im(z+h) - Im(z)}{h}$ = $\frac{Im(z)+Im(h)-Im(z)}{h}$ = $\frac{Im(h)}{h}$. Now, if $h \rightarrow 0  $ through real values, Im$(h)=0$, and $\lim \limits_{h \to 0} {\frac{Im(z+h)-Im(z)}{h}}$ = $\lim \limits_{h \to 0}{\frac{Im(h)}{h}}$. At this point I think I need to mention imaginary values and conclude that $f'(z)$ doesn't exist by using the real and imaginary values, but my notes are giving me limited assistance in how to do this correctly. $--------------------------------------$ For part (b) I had done a very similar question before, but again, I struggle to conclude my answers in a mathematical way. If $f(z) = x^3 + i(1-y)^3$ , then $u(x,y)=x^3$ and $v(x,y)=(1-y)^3$ , so that $\frac{\partial u}{\partial x}$=$3x^2$,     $\frac{\partial v}{\partial y} =-3(1-y)^2$ $\frac{\partial u}{\partial y}=0$,     $\frac{\partial v}{\partial x}=0$. The Cauchy-Riemann equations become $3x^2 +3(1-y)^2=0$ How do I then find the points at which $f'(z)$ exists? Any help is much appreciated!!","I am revising complex analysis for an upcoming test and I am finding it hard to finish off certain questions. I feel I start well but cannot remember how to wrap up the answers in proper form. $--------------------------------------$ Letting $z = x + iy$, for each of the following functions determine where $f'(z)$ exists and find its value at those points. (a) $f(z) = z$ Im$(z)$ (b) $f(z) = x^3 + i(1-y)^3$ $--------------------------------------$ For part (a) I am pretty certain $f'(z)$ does not exist: Let $f(z) = $Im$(z)$, then for $z, h \in \Bbb C,$ with $h \ne 0,$ we have $\frac{Im(z+h) - Im(z)}{h}$ = $\frac{Im(z)+Im(h)-Im(z)}{h}$ = $\frac{Im(h)}{h}$. Now, if $h \rightarrow 0  $ through real values, Im$(h)=0$, and $\lim \limits_{h \to 0} {\frac{Im(z+h)-Im(z)}{h}}$ = $\lim \limits_{h \to 0}{\frac{Im(h)}{h}}$. At this point I think I need to mention imaginary values and conclude that $f'(z)$ doesn't exist by using the real and imaginary values, but my notes are giving me limited assistance in how to do this correctly. $--------------------------------------$ For part (b) I had done a very similar question before, but again, I struggle to conclude my answers in a mathematical way. If $f(z) = x^3 + i(1-y)^3$ , then $u(x,y)=x^3$ and $v(x,y)=(1-y)^3$ , so that $\frac{\partial u}{\partial x}$=$3x^2$,     $\frac{\partial v}{\partial y} =-3(1-y)^2$ $\frac{\partial u}{\partial y}=0$,     $\frac{\partial v}{\partial x}=0$. The Cauchy-Riemann equations become $3x^2 +3(1-y)^2=0$ How do I then find the points at which $f'(z)$ exists? Any help is much appreciated!!",,['complex-analysis']
40,Characterising holomorphic functions,Characterising holomorphic functions,,"I am trying to revise for an exam and I cannot get my head around what this question is asking me: Characterise those holomorphic functions $f: \mathbb{C} \rightarrow \mathbb{C}$ such that $\hat f$ is holomorphic, where $\hat f$ is the function sending $x+iy$ to  $v(x,y)+iu(x,y)$  for $x,y$ are real numbers and $u$ is the real part and $v$ is he imaginary part. The question is very vague and i'm not really sure what its asking me to do and has a few different acceptable answers according to the feedback. Any help would be great","I am trying to revise for an exam and I cannot get my head around what this question is asking me: Characterise those holomorphic functions $f: \mathbb{C} \rightarrow \mathbb{C}$ such that $\hat f$ is holomorphic, where $\hat f$ is the function sending $x+iy$ to  $v(x,y)+iu(x,y)$  for $x,y$ are real numbers and $u$ is the real part and $v$ is he imaginary part. The question is very vague and i'm not really sure what its asking me to do and has a few different acceptable answers according to the feedback. Any help would be great",,['complex-analysis']
41,Asymptotic expansion of Polygamma functions,Asymptotic expansion of Polygamma functions,,"According to Wikipedia, the log-Gamma and Polygamma functions have the following asymptotic behaviour on the real line for $x\to\infty$: $$\ln\Gamma(x) = (x - \tfrac{1}{2}) \ln(x) - x + \tfrac{1}{2}\ln (2\pi) + \sum_{k=1}^\infty \frac{B_{k+1}}{k(k+1)x^{k}} \\ \psi^{(0)}(x) \sim \ln(x) - \sum_{k=1}^\infty \frac{B_k}{kx^k}\\ \psi^{(m)}(x) \sim (-1)^{m+1} \sum_{k=0}^\infty \frac{(k+m-1)}{k!} \frac{B_k}{x^{k+m}}\quad\text{for}\ m>0$$ The second one can be obtained from the first one by term-wise differentiation, and the third one from the second one by iterated term-wise iteration. The problem is that term-wise differention of asymptotic power series such as this is not valid in general. The book Asymptotic Expansions by A. Erdelyi mentions that one may perform term-wise differentiation of asymptotic power series like this one the function being expanded is a complex-valued function that is holomorphic on a suitably-shaped set (which $\ln\Gamma$ is). The proof uses Cauchy's integral formula and requires the power series expansion to hold uniformly . However, I am working on a computer-aided proof and for technical reasons, I would like to avoid talking about the complex-valued $\ln\Gamma$ function and uniform asymptotic expansions if possible. Is there any other way of obtaining the above results directly for the real $\psi^{(m)}$ functions? I already have the result $$\ln\Gamma(x) = (x - \tfrac{1}{2})\ln(x) - s + \tfrac{1}{2}\ln(2\pi) + \sum_{k=1}^m \frac{B_{k+1}}{k(k+1)x^k}-\\\hskip-1em\frac{1}{m+1} \int_0^\infty \frac{B_{n+1}([t])}{(t+x)^{n+1}}\,\text{d}t$$ and, since the integral is ${\!}\in O(x^{-m-1})$, the above asymptotic expansion for $\ln\Gamma$, so I can use that – but is there any other way to get the other two expansions than the one described above? One way that I thought about is somehow directly estimating the growth of the derivatives of the integral, but I did not get very far with that.","According to Wikipedia, the log-Gamma and Polygamma functions have the following asymptotic behaviour on the real line for $x\to\infty$: $$\ln\Gamma(x) = (x - \tfrac{1}{2}) \ln(x) - x + \tfrac{1}{2}\ln (2\pi) + \sum_{k=1}^\infty \frac{B_{k+1}}{k(k+1)x^{k}} \\ \psi^{(0)}(x) \sim \ln(x) - \sum_{k=1}^\infty \frac{B_k}{kx^k}\\ \psi^{(m)}(x) \sim (-1)^{m+1} \sum_{k=0}^\infty \frac{(k+m-1)}{k!} \frac{B_k}{x^{k+m}}\quad\text{for}\ m>0$$ The second one can be obtained from the first one by term-wise differentiation, and the third one from the second one by iterated term-wise iteration. The problem is that term-wise differention of asymptotic power series such as this is not valid in general. The book Asymptotic Expansions by A. Erdelyi mentions that one may perform term-wise differentiation of asymptotic power series like this one the function being expanded is a complex-valued function that is holomorphic on a suitably-shaped set (which $\ln\Gamma$ is). The proof uses Cauchy's integral formula and requires the power series expansion to hold uniformly . However, I am working on a computer-aided proof and for technical reasons, I would like to avoid talking about the complex-valued $\ln\Gamma$ function and uniform asymptotic expansions if possible. Is there any other way of obtaining the above results directly for the real $\psi^{(m)}$ functions? I already have the result $$\ln\Gamma(x) = (x - \tfrac{1}{2})\ln(x) - s + \tfrac{1}{2}\ln(2\pi) + \sum_{k=1}^m \frac{B_{k+1}}{k(k+1)x^k}-\\\hskip-1em\frac{1}{m+1} \int_0^\infty \frac{B_{n+1}([t])}{(t+x)^{n+1}}\,\text{d}t$$ and, since the integral is ${\!}\in O(x^{-m-1})$, the above asymptotic expansion for $\ln\Gamma$, so I can use that – but is there any other way to get the other two expansions than the one described above? One way that I thought about is somehow directly estimating the growth of the derivatives of the integral, but I did not get very far with that.",,"['real-analysis', 'complex-analysis', 'asymptotics', 'gamma-function', 'polygamma']"
42,Equivalence of two smooth curves in the plane having the same image,Equivalence of two smooth curves in the plane having the same image,,"The book I read is complex analysis by stein, he first define what is the equivalence of two parametrized curve, and then define the complex intagral on a smooth curve which is indepentent of our choice of parametrization. And, my question is about a basic fundamental definition as the following: If two smooth complex curve $z(t):[a,b]\to C$ and $z_1(s):[c,d]\to C$ have the same image, then does there exists real function $f:[a,b]\to[c,d]$ such that $z(t)=z_1(f(t))$ for all $t$ on $[a,b]$, and $f$ is a continuously differentiable functoin on $[a,b]$, and $f'(x)>0$? The way of the author use is that if there exist a continuouly differentiable real function $f:[a,b]\to[c,d]$, $f'(x)>0$, and $z(t)=z_1(f(t))=z_1(s)$, then we call the two curve $z(t)$ and $z_1(s)$ are equivalent, but I want to try to claim that it only needs that if two curve have the same image, i.e., $z(t)=z_1(f(t))=z_1(s)$ , and then we can imply the other two requirement to be equivalent. My attempt: Since $z(t)=z_1(s)=z_1(f(t))$ and $z(t)$ is smooth on $[a,b]$, so $z_1(f(t))$ is continuously differentiable. Next, I guess that we can write $z_1^{-1}$ since $z_1$ is a one to one map, but I don't know how to say that $z_1^{-1}$ is differentiable, if $z_1^{-1}$ is continuously differentiable, then $z_1^{-1}(z_1(f(t)))=f(t)$ is continuously differentiable. Thanks for any comment and help~!","The book I read is complex analysis by stein, he first define what is the equivalence of two parametrized curve, and then define the complex intagral on a smooth curve which is indepentent of our choice of parametrization. And, my question is about a basic fundamental definition as the following: If two smooth complex curve $z(t):[a,b]\to C$ and $z_1(s):[c,d]\to C$ have the same image, then does there exists real function $f:[a,b]\to[c,d]$ such that $z(t)=z_1(f(t))$ for all $t$ on $[a,b]$, and $f$ is a continuously differentiable functoin on $[a,b]$, and $f'(x)>0$? The way of the author use is that if there exist a continuouly differentiable real function $f:[a,b]\to[c,d]$, $f'(x)>0$, and $z(t)=z_1(f(t))=z_1(s)$, then we call the two curve $z(t)$ and $z_1(s)$ are equivalent, but I want to try to claim that it only needs that if two curve have the same image, i.e., $z(t)=z_1(f(t))=z_1(s)$ , and then we can imply the other two requirement to be equivalent. My attempt: Since $z(t)=z_1(s)=z_1(f(t))$ and $z(t)$ is smooth on $[a,b]$, so $z_1(f(t))$ is continuously differentiable. Next, I guess that we can write $z_1^{-1}$ since $z_1$ is a one to one map, but I don't know how to say that $z_1^{-1}$ is differentiable, if $z_1^{-1}$ is continuously differentiable, then $z_1^{-1}(z_1(f(t)))=f(t)$ is continuously differentiable. Thanks for any comment and help~!",,"['complex-analysis', 'curves']"
43,How can we characterize polynomials in $\mathbb{R}^2$ that are harmonic,How can we characterize polynomials in  that are harmonic,\mathbb{R}^2,"How can we characterize polynomials $p(x,y)$ in  $\mathbb{R}^2$ ( in two variables ) that are harmonic (that is $\Delta p(x,y) = 0$)?","How can we characterize polynomials $p(x,y)$ in  $\mathbb{R}^2$ ( in two variables ) that are harmonic (that is $\Delta p(x,y) = 0$)?",,"['calculus', 'real-analysis']"
44,Branch points and Branch cuts,Branch points and Branch cuts,,"I am currently studying about Branch points and Branch cuts. I think, I understood the definition of these two concepts and I can find Branch points and Branch cuts of some functions. For example: $z\to\sqrt{z(1-z)}$ has two branch points $0$ and $1.$ Because as we travel along a small circle around $0$ or $1,$ one time, argument of the function changes to $0\to \pm\pi i.$ On the other hand, $z\to\sqrt{z}+\sqrt{1-z}$ has three branch points $0, 1$ and $\infty.$ (Correct me if I am wrong.) Here my question is: There are identities which fails on some branches of logarithm. Is there any way to determine the region for which these familiar identities valid using Branch points and Branch cuts? For example: $$\color{Green}{\sqrt{z-1}\sqrt{z+1}=\sqrt{z^2-1}}$$ does hot holds for $z=-2,$ if we choose $\sqrt{-1}=i.$","I am currently studying about Branch points and Branch cuts. I think, I understood the definition of these two concepts and I can find Branch points and Branch cuts of some functions. For example: $z\to\sqrt{z(1-z)}$ has two branch points $0$ and $1.$ Because as we travel along a small circle around $0$ or $1,$ one time, argument of the function changes to $0\to \pm\pi i.$ On the other hand, $z\to\sqrt{z}+\sqrt{1-z}$ has three branch points $0, 1$ and $\infty.$ (Correct me if I am wrong.) Here my question is: There are identities which fails on some branches of logarithm. Is there any way to determine the region for which these familiar identities valid using Branch points and Branch cuts? For example: $$\color{Green}{\sqrt{z-1}\sqrt{z+1}=\sqrt{z^2-1}}$$ does hot holds for $z=-2,$ if we choose $\sqrt{-1}=i.$",,"['complex-analysis', 'complex-numbers', 'branch-cuts', 'analytic-functions', 'branch-points']"
45,Evaluating $\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx$ by method of residues.,Evaluating  by method of residues.,\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx,"Im trying to solve $$\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx$$ using the method of residues. This function has two simple poles at $x=\pm i$ and so $$\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx=2\pi i\text{Res}_{z=i }\frac{z^2 \cos(z)}{(z^2+1)^2}=2\pi i \lim_{z\to i} \frac d{dz}\Big[ (x-i)\frac{z^2 \cos(z)}{(z^2+1)^2}\Big]=2\pi i\lim_{z\to i}\frac d{dz}\Big[\frac{z^2\cos(z)}{(z+i)^2} \Big]=2\pi i \lim_{z\to i} \Big[ \frac{(z+i)^2(2z\cos z-z^2 \sin z)-2z^2(z+i)\cos z}{(z+i)^4} \Big]=2\pi i(-\frac{ei}{4})=\frac{\pi e}{4}$$ However wolfram alpha says that $$\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx=0$$ I'm almost certain that the residue calculated above is correct, so why am I not able to apply the method here?","Im trying to solve $$\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx$$ using the method of residues. This function has two simple poles at $x=\pm i$ and so $$\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx=2\pi i\text{Res}_{z=i }\frac{z^2 \cos(z)}{(z^2+1)^2}=2\pi i \lim_{z\to i} \frac d{dz}\Big[ (x-i)\frac{z^2 \cos(z)}{(z^2+1)^2}\Big]=2\pi i\lim_{z\to i}\frac d{dz}\Big[\frac{z^2\cos(z)}{(z+i)^2} \Big]=2\pi i \lim_{z\to i} \Big[ \frac{(z+i)^2(2z\cos z-z^2 \sin z)-2z^2(z+i)\cos z}{(z+i)^4} \Big]=2\pi i(-\frac{ei}{4})=\frac{\pi e}{4}$$ However wolfram alpha says that $$\int_{-\infty}^{\infty}\frac{x^2 \cos(x)}{(x^2+1)^2}dx=0$$ I'm almost certain that the residue calculated above is correct, so why am I not able to apply the method here?",,"['integration', 'complex-analysis', 'residue-calculus']"
46,Beginner to complex integration,Beginner to complex integration,,Unfortunately I missed one a week of lectures last week due to a family bereavement and my lecturer doesn't put up her notes (I put a request online if someone could share their notes with me but no one will). I missed quiet an important portion of complex integration. I have searched online for videos or examples but just don't understand whats happening with it. I've attempted a question but don't think I've done it correctly any advice would be brilliant. Evaluate $$\ \int_C (z^2-z+2)\;dz $$ if C is the upper half of the unit circle (in a counter clockwise direction) $$\ \int_{-1}^1 (z^2-z+2)\;dz = \left[\frac {z^3} {3}-\frac {z^2}{2}+2z\right]_{-1}^1 $$ $$\ \left[\frac {1} {3}-\frac {1}{2}+2\right] - \left[-\frac {1} {3}-\frac {1}{2}-2\right]$$ $$\ =\frac {14} {3} $$ Do I need to use cos and sin or am I right? Thanks,Unfortunately I missed one a week of lectures last week due to a family bereavement and my lecturer doesn't put up her notes (I put a request online if someone could share their notes with me but no one will). I missed quiet an important portion of complex integration. I have searched online for videos or examples but just don't understand whats happening with it. I've attempted a question but don't think I've done it correctly any advice would be brilliant. Evaluate $$\ \int_C (z^2-z+2)\;dz $$ if C is the upper half of the unit circle (in a counter clockwise direction) $$\ \int_{-1}^1 (z^2-z+2)\;dz = \left[\frac {z^3} {3}-\frac {z^2}{2}+2z\right]_{-1}^1 $$ $$\ \left[\frac {1} {3}-\frac {1}{2}+2\right] - \left[-\frac {1} {3}-\frac {1}{2}-2\right]$$ $$\ =\frac {14} {3} $$ Do I need to use cos and sin or am I right? Thanks,,"['complex-analysis', 'complex-integration']"
47,Showing an analytic function on the unit disk is nonzero in a certain neighborhood,Showing an analytic function on the unit disk is nonzero in a certain neighborhood,,"Suppose $f(z)$ is analytic for $|z|\le 1$ and $f(0) = a_0 \ne 0$. If $M = \max_{|z|=1} |f(z)|$, then show $f(z)\ne 0$ for all $z$ with $|z| < \frac{|a_0|}{|a_0|+M} =:r$. I know we can write $f(z) = a_0 + z^kg(z)$, some $k\ge 1$ and $g$ analytic and $g(0)\ne 0$. From here, I've tried various techniques, like contradiction by assuming $f$ has a root in the disk $\{|z| < r\}$, or trying to use Rouche's Theorem on the disk by examining $|f(z)-a_0|$, but I haven't really gotten anywhere. Any hints would be greatly appreciated.","Suppose $f(z)$ is analytic for $|z|\le 1$ and $f(0) = a_0 \ne 0$. If $M = \max_{|z|=1} |f(z)|$, then show $f(z)\ne 0$ for all $z$ with $|z| < \frac{|a_0|}{|a_0|+M} =:r$. I know we can write $f(z) = a_0 + z^kg(z)$, some $k\ge 1$ and $g$ analytic and $g(0)\ne 0$. From here, I've tried various techniques, like contradiction by assuming $f$ has a root in the disk $\{|z| < r\}$, or trying to use Rouche's Theorem on the disk by examining $|f(z)-a_0|$, but I haven't really gotten anywhere. Any hints would be greatly appreciated.",,['complex-analysis']
48,Prove that the functions $f_n(x) = \frac{(x-i)^n}{\sqrt{\pi}(x+i)^{n+1}}$ are orthonormal using the residue theorem,Prove that the functions  are orthonormal using the residue theorem,f_n(x) = \frac{(x-i)^n}{\sqrt{\pi}(x+i)^{n+1}},"Note: edited a mistake in parametrizing the integral! Question: Let the complex valued function $f_n$, $n\in Z$, be defined on $R$ by:  $$f_n(x) = \frac{(x-i)^n}{\sqrt{\pi}(x+i)^{n+1}}.$$  Prove that these functions are orthonormal; that is, $$\int_{-\infty}^\infty f_m(x)\overline{f_n(x)}dx = \delta_{nm}.$$ My attempt: So, I think I have most of this problem, but I'm struggling to come up with a rigorous justification of one of the steps. Here is what I have so far: The case where $n=m$ is straightforward: we then have $$f_m(x)\overline{f_n(x)} = \frac{1}{\pi(x^2+1)},$$ and thus $$\int_{-\infty}^\infty f_m(x)\overline{f_n(x)}dx = \frac{1}{\pi}\arctan(x)|_{-\infty}^\infty = 1.$$ Next, we assume that $m < n$. Then, $$f_m(x)\overline{f_n(x)} = \frac{1}{x^2+1}\frac{(x+i)^{n-m}}{\pi(x-i)^{n-m}}.$$ Consider the contour $\gamma_R = C_R \cup [-R,R]$, where $C_R$ is the semi-circle of positive orientation in the upper half plane with radius $R$. Now, by the residue theorem (I'm being lazy and not writing out the steps, but I swear it works out!), for large enough $R$, since the function has a pole at $i$, we have: $$\int_{\gamma_R}\frac{(z+i)^{(n-m)-1}}{\pi(z-i)^{(n-m)+1}}dz = 0,$$ so if we can show that  $$\lim_{R\to\infty}\int_{C_R}\frac{(z+i)^{(n-m)-1}}{\pi(z-i)^{(n-m)+1}}dz = 0,$$ we will be done. So, this is the part that I always struggle with on these integrals. I parametrized the integral as: $$\int_{0}^\pi\frac{(Re^{i\theta}+i)^{(n-m)-1}}{\pi(Re^{i\theta}-i)^{(n-m)+1}}iRe^{i\theta}d\theta,$$ and I've been trying to use the basic absolute value/length inequality to write: $$\int_{0}^\pi\frac{(Re^{i\theta}+i)^{(n-m)-1}}{\pi(Re^{i\theta}-i)^{(n-m)+1}}iRe^{i\theta}d\theta\le R \cdot \sup_{z \in C_R} \left|\frac{1}{(Re^{i\theta}+1)^2} \right|\frac{|Re^{i\theta}+1|^{n-m}}{|Re^{i\theta}-1|^{n-m}}\cdot |Re^{i\theta}|$$ But I can't seem to get anywhere from here. Normally I ask for just hints, but because I am so very bad at this, I'm hoping that someone would be willing to walk through a super rigorous method for showing this in baby steps. I can kindof see generally why it would work, since the denominator has a lower degree than the numerator, but I would really like to understand a step-by-step version. Thanks!","Note: edited a mistake in parametrizing the integral! Question: Let the complex valued function $f_n$, $n\in Z$, be defined on $R$ by:  $$f_n(x) = \frac{(x-i)^n}{\sqrt{\pi}(x+i)^{n+1}}.$$  Prove that these functions are orthonormal; that is, $$\int_{-\infty}^\infty f_m(x)\overline{f_n(x)}dx = \delta_{nm}.$$ My attempt: So, I think I have most of this problem, but I'm struggling to come up with a rigorous justification of one of the steps. Here is what I have so far: The case where $n=m$ is straightforward: we then have $$f_m(x)\overline{f_n(x)} = \frac{1}{\pi(x^2+1)},$$ and thus $$\int_{-\infty}^\infty f_m(x)\overline{f_n(x)}dx = \frac{1}{\pi}\arctan(x)|_{-\infty}^\infty = 1.$$ Next, we assume that $m < n$. Then, $$f_m(x)\overline{f_n(x)} = \frac{1}{x^2+1}\frac{(x+i)^{n-m}}{\pi(x-i)^{n-m}}.$$ Consider the contour $\gamma_R = C_R \cup [-R,R]$, where $C_R$ is the semi-circle of positive orientation in the upper half plane with radius $R$. Now, by the residue theorem (I'm being lazy and not writing out the steps, but I swear it works out!), for large enough $R$, since the function has a pole at $i$, we have: $$\int_{\gamma_R}\frac{(z+i)^{(n-m)-1}}{\pi(z-i)^{(n-m)+1}}dz = 0,$$ so if we can show that  $$\lim_{R\to\infty}\int_{C_R}\frac{(z+i)^{(n-m)-1}}{\pi(z-i)^{(n-m)+1}}dz = 0,$$ we will be done. So, this is the part that I always struggle with on these integrals. I parametrized the integral as: $$\int_{0}^\pi\frac{(Re^{i\theta}+i)^{(n-m)-1}}{\pi(Re^{i\theta}-i)^{(n-m)+1}}iRe^{i\theta}d\theta,$$ and I've been trying to use the basic absolute value/length inequality to write: $$\int_{0}^\pi\frac{(Re^{i\theta}+i)^{(n-m)-1}}{\pi(Re^{i\theta}-i)^{(n-m)+1}}iRe^{i\theta}d\theta\le R \cdot \sup_{z \in C_R} \left|\frac{1}{(Re^{i\theta}+1)^2} \right|\frac{|Re^{i\theta}+1|^{n-m}}{|Re^{i\theta}-1|^{n-m}}\cdot |Re^{i\theta}|$$ But I can't seem to get anywhere from here. Normally I ask for just hints, but because I am so very bad at this, I'm hoping that someone would be willing to walk through a super rigorous method for showing this in baby steps. I can kindof see generally why it would work, since the denominator has a lower degree than the numerator, but I would really like to understand a step-by-step version. Thanks!",,"['complex-analysis', 'residue-calculus', 'complex-integration']"
49,"Of rotations, $S^2$, the Riemann sphere, $\text{SU}(2)$, $\text{SO}(3)$, and the precise relationship between two maps.","Of rotations, , the Riemann sphere, , , and the precise relationship between two maps.",S^2 \text{SU}(2) \text{SO}(3),"Let $\mathbb{C} \cup \{\infty\}$ be the Riemann sphere and let$$S^2 = \{(x, y, z) \in \mathbb{R}^3 : x^2 + y^2 + z^2 = 1\}$$be the unit sphere in $\mathbb{R}^3$. The stereographic projection with center $(0, 0, 1) \in S^2$ is an explicit bijection between the unit sphere and the Riemann sphere provided by the following map:$$p: S^2 \overset{\sim}{\to} \mathbb{C} \cup \{\infty\}, \quad (x, y, z) \mapsto {{x + iy}\over{1 - z}}.$$For any invertible matrix$$g = \begin{pmatrix} a & b \\ c & d \end{pmatrix} \in \text{GL}_2(\mathbb{C})$$there is an associated fractional linear transformation$$\phi_g: \mathbb{C} \cup \{\infty\} \to \mathbb{C} \cup \{\infty\},$$of the Riemann sphere, given by$$\phi_g(z) := {{az + b}\over{cz + d}} \quad (\text{in particular, we have }\phi_g(\infty) = {a\over c} \text{ and }\phi_g\left(-{d\over c}\right) = \infty, \text{ if }c \neq 0).$$One may use the bijection $p$ to transport the map $\phi_g$ to the unit sphere. That is, we consider the following composite map$$F_g: S^2 \overset{p}{\to} \mathbb{C} \cup \{\infty\} \overset{\phi_g}{\to} \mathbb{C} \cup \{\infty\} \overset{p^{-1}}{\to} S^2.$$ Question. What is the precise relationship between the following two things? A continuous and surjective group homomorphism $\pi: \text{SU}(2) \twoheadrightarrow \text{SO}(3)$ with kernel $\{\pm \text{Id}\}$. The map $g \mapsto F_g$.","Let $\mathbb{C} \cup \{\infty\}$ be the Riemann sphere and let$$S^2 = \{(x, y, z) \in \mathbb{R}^3 : x^2 + y^2 + z^2 = 1\}$$be the unit sphere in $\mathbb{R}^3$. The stereographic projection with center $(0, 0, 1) \in S^2$ is an explicit bijection between the unit sphere and the Riemann sphere provided by the following map:$$p: S^2 \overset{\sim}{\to} \mathbb{C} \cup \{\infty\}, \quad (x, y, z) \mapsto {{x + iy}\over{1 - z}}.$$For any invertible matrix$$g = \begin{pmatrix} a & b \\ c & d \end{pmatrix} \in \text{GL}_2(\mathbb{C})$$there is an associated fractional linear transformation$$\phi_g: \mathbb{C} \cup \{\infty\} \to \mathbb{C} \cup \{\infty\},$$of the Riemann sphere, given by$$\phi_g(z) := {{az + b}\over{cz + d}} \quad (\text{in particular, we have }\phi_g(\infty) = {a\over c} \text{ and }\phi_g\left(-{d\over c}\right) = \infty, \text{ if }c \neq 0).$$One may use the bijection $p$ to transport the map $\phi_g$ to the unit sphere. That is, we consider the following composite map$$F_g: S^2 \overset{p}{\to} \mathbb{C} \cup \{\infty\} \overset{\phi_g}{\to} \mathbb{C} \cup \{\infty\} \overset{p^{-1}}{\to} S^2.$$ Question. What is the precise relationship between the following two things? A continuous and surjective group homomorphism $\pi: \text{SU}(2) \twoheadrightarrow \text{SO}(3)$ with kernel $\{\pm \text{Id}\}$. The map $g \mapsto F_g$.",,"['linear-algebra', 'abstract-algebra', 'complex-analysis', 'lie-groups', 'projective-geometry']"
50,On the definition of a meromorphic differential on a Riemann surface,On the definition of a meromorphic differential on a Riemann surface,,"In the book ""Complex Algebraic Curves"", Frances Kirwan gives the following definition of a meromorphic differential on a Riemann surface. Definition . Let $\{\phi_\alpha:U_\alpha\rightarrow V_\alpha: \alpha \in A\}$ be a holomorphic atlas on a Riemann surface $S$. Then a meromorphic differential $\eta$ on $S$ is given by a collection $$\{\eta_\alpha: V_\alpha \rightarrow \mathbb{C}\cup\{\infty\}: \alpha \in A\}$$ of meromorphic functions on the open subsets $V_\alpha$ of $\mathbb{C}$ such that if $\alpha,\beta \in A$ and $u\in U_\alpha\cap U_\beta$ then $$\eta_\alpha(\phi_\alpha(u))=\eta_\beta(\phi_\beta(u))(\phi_\beta \circ \phi_\alpha^{-1})'(\phi_\alpha(u)).$$ For two meromorphic functions $f$ and $g$ on $S$, the differential $fdg$ on $S$ is defined by $fdg=\eta$, where $\eta_\alpha=(f\circ \phi_\alpha^{-1})(g\circ\phi_\alpha^{-1})'$. Further, the following remark is given: If $\eta$ and $\zeta$ are meromorphic differentials according to this definition and $\zeta$ is not identically zero on any connected component of $S$ then the ratios $\eta_\alpha/\zeta_\alpha$ define meromorphic functions on the open subsets of $V_\alpha$ of $\mathbb{C}$ satisfying $$\frac{\eta_\alpha(\phi_\alpha(u))}{\zeta_\alpha(\phi_\alpha(u))}=\frac{\eta_\beta(\phi_\beta(u))}{\zeta_\beta(\phi_\beta(u))}$$ for all $u\in U_\alpha$; or equivalently $\eta=f\zeta$. Therefore to show that every meromorphic differential $\eta$ in the sense of definition 6.6 is a meromorphic differential of the form $fdg$ it is enough to show that there is at least one nonconstant meromorphic function $g$ on every Riemann suraface Here are my questions: Why the differential $fdg$ is well-defined, i.e., why $(f\circ \phi_\alpha^{-1})(g\circ\phi_\alpha^{-1})'(\phi_\alpha(u))=(f\circ \phi_\beta^{-1})(g\circ\phi_\beta^{-1})'(\phi_\beta(u))(\phi_\beta \circ \phi_\alpha^{-1})'(\phi_\alpha(u))$ for $u\in U_\alpha\cap U_\beta$ and $\alpha,\beta \in A$? Why the equality $\frac{\eta_\alpha(\phi_\alpha(u))}{\zeta_\alpha(\phi_\alpha(u))}=\frac{\eta_\beta(\phi_\beta(u))}{\zeta_\beta(\phi_\beta(u))}$ is the same as $\eta=f\zeta$, and what is $f$ in the end? If it is some function, on which the notation hints, my mind still refuses to understand how a set (formally, $\eta$ is a set, isn't it?) can be equal to another set times a function. How the existence of a meromorphic functioon $g$ on every Riemann surface implies that every meromorphic differential on $S$ in the sence of the given definition is of the form $fdg$? Finally, an ""ideological question"": is it ideologically correct to think of meromorphic differentials on Riemann surfaces according to this definition? I like this definition because on the one hand it requires no knowledge about cotangent bundles and its sections for example, and on the other hand it is quite rigorous (unlike the definition which says that a differential is ""something that can be written as $fdz$""). And by the way, is ""differential"" the same as ""differential 1-form""?","In the book ""Complex Algebraic Curves"", Frances Kirwan gives the following definition of a meromorphic differential on a Riemann surface. Definition . Let $\{\phi_\alpha:U_\alpha\rightarrow V_\alpha: \alpha \in A\}$ be a holomorphic atlas on a Riemann surface $S$. Then a meromorphic differential $\eta$ on $S$ is given by a collection $$\{\eta_\alpha: V_\alpha \rightarrow \mathbb{C}\cup\{\infty\}: \alpha \in A\}$$ of meromorphic functions on the open subsets $V_\alpha$ of $\mathbb{C}$ such that if $\alpha,\beta \in A$ and $u\in U_\alpha\cap U_\beta$ then $$\eta_\alpha(\phi_\alpha(u))=\eta_\beta(\phi_\beta(u))(\phi_\beta \circ \phi_\alpha^{-1})'(\phi_\alpha(u)).$$ For two meromorphic functions $f$ and $g$ on $S$, the differential $fdg$ on $S$ is defined by $fdg=\eta$, where $\eta_\alpha=(f\circ \phi_\alpha^{-1})(g\circ\phi_\alpha^{-1})'$. Further, the following remark is given: If $\eta$ and $\zeta$ are meromorphic differentials according to this definition and $\zeta$ is not identically zero on any connected component of $S$ then the ratios $\eta_\alpha/\zeta_\alpha$ define meromorphic functions on the open subsets of $V_\alpha$ of $\mathbb{C}$ satisfying $$\frac{\eta_\alpha(\phi_\alpha(u))}{\zeta_\alpha(\phi_\alpha(u))}=\frac{\eta_\beta(\phi_\beta(u))}{\zeta_\beta(\phi_\beta(u))}$$ for all $u\in U_\alpha$; or equivalently $\eta=f\zeta$. Therefore to show that every meromorphic differential $\eta$ in the sense of definition 6.6 is a meromorphic differential of the form $fdg$ it is enough to show that there is at least one nonconstant meromorphic function $g$ on every Riemann suraface Here are my questions: Why the differential $fdg$ is well-defined, i.e., why $(f\circ \phi_\alpha^{-1})(g\circ\phi_\alpha^{-1})'(\phi_\alpha(u))=(f\circ \phi_\beta^{-1})(g\circ\phi_\beta^{-1})'(\phi_\beta(u))(\phi_\beta \circ \phi_\alpha^{-1})'(\phi_\alpha(u))$ for $u\in U_\alpha\cap U_\beta$ and $\alpha,\beta \in A$? Why the equality $\frac{\eta_\alpha(\phi_\alpha(u))}{\zeta_\alpha(\phi_\alpha(u))}=\frac{\eta_\beta(\phi_\beta(u))}{\zeta_\beta(\phi_\beta(u))}$ is the same as $\eta=f\zeta$, and what is $f$ in the end? If it is some function, on which the notation hints, my mind still refuses to understand how a set (formally, $\eta$ is a set, isn't it?) can be equal to another set times a function. How the existence of a meromorphic functioon $g$ on every Riemann surface implies that every meromorphic differential on $S$ in the sence of the given definition is of the form $fdg$? Finally, an ""ideological question"": is it ideologically correct to think of meromorphic differentials on Riemann surfaces according to this definition? I like this definition because on the one hand it requires no knowledge about cotangent bundles and its sections for example, and on the other hand it is quite rigorous (unlike the definition which says that a differential is ""something that can be written as $fdz$""). And by the way, is ""differential"" the same as ""differential 1-form""?",,"['complex-analysis', 'algebraic-geometry', 'complex-geometry', 'riemann-surfaces']"
51,if $\frac{\theta_1-\theta_2}{2\pi}$ is irrational then $f$ is a constant.,if  is irrational then  is a constant.,\frac{\theta_1-\theta_2}{2\pi} f,"Let $f: B(0,1)\to\mathbb{C}$ be analytic with the property that there exists $\theta_1, \theta_2\in\mathbb{R}$ such that $$|f(re^{i\theta_1})|=|f(0)|=|f(re^{i\theta_2})|$$ for all $r\in(0,1)$. Show that if $\frac{\theta_1-\theta_2}{2\pi}$ is irrational then $f$ is a constant. Could anyone kindly help? I have been thinking for a long time and still have no clue. How to use $\frac{\theta_1-\theta_2}{2\pi}$ is irrational to prove $f$ is constant? Thanks so much!","Let $f: B(0,1)\to\mathbb{C}$ be analytic with the property that there exists $\theta_1, \theta_2\in\mathbb{R}$ such that $$|f(re^{i\theta_1})|=|f(0)|=|f(re^{i\theta_2})|$$ for all $r\in(0,1)$. Show that if $\frac{\theta_1-\theta_2}{2\pi}$ is irrational then $f$ is a constant. Could anyone kindly help? I have been thinking for a long time and still have no clue. How to use $\frac{\theta_1-\theta_2}{2\pi}$ is irrational to prove $f$ is constant? Thanks so much!",,"['complex-analysis', 'analysis']"
52,"How to give a ""quick proof"" of properties of the Hecke-operators?","How to give a ""quick proof"" of properties of the Hecke-operators?",,"In ""Analytic Number Theory"" by Kowalski, Iwaniec p. 370 the authors prove a formula for the Fourier-coefficients of the Hecke-operators. Namely: If $$T(n) f(z) = \frac{1}{n} \sum_{ad = n} a^k \sum_{0 \leq b < d } \sum_m a_f(m) e\left( m \frac{az+b}{d} \right) = \sum_{m=0}^\infty b(m)e(mz)$$ is the Hecke operator $T(n)$ applied to a weight $k$ modular form $f = \sum_{n\geq 0} c(n) e(nz)$ (let's assume, contrary to the book, that $f$ is a modular form over the full modular group), then the formula derived for $b(m)$ then is $$\sum_{d \mid (m, n)} d^{k-1} c\left( \frac{mn}{d^2}\right)$$ The authors then state that this can be used to ""give [a] quick proof"" of $$T(n) T(m) = \sum_{d \mid (m, n)} d^{k - 1} T\left( \frac{mn}{d^2} \right)$$ I've tried to do the proof using that the Fourier-coefficients determine a modular form. But I got only long expressions for the Fourier coefficients of the LHS and the RHS, and couldn't really conclude anything. So my question is: How can I prove this quickly using the fomula for the Fourier-coefficients? Thanks! Added: I've had the following idea: One can prove that the cusp-forms have a basis of normalized eigenforms. For eigenforms one can derive the desired formula by our expression of the Fourier-coefficients (which happen to be the eigenvalues of the eigenforms), which then holds for the whole space of cusp-forms. However, showing that the space of cusp-forms has a basis of normalized eigenforms is not a quick proof. I still think I'm missing something here...","In ""Analytic Number Theory"" by Kowalski, Iwaniec p. 370 the authors prove a formula for the Fourier-coefficients of the Hecke-operators. Namely: If $$T(n) f(z) = \frac{1}{n} \sum_{ad = n} a^k \sum_{0 \leq b < d } \sum_m a_f(m) e\left( m \frac{az+b}{d} \right) = \sum_{m=0}^\infty b(m)e(mz)$$ is the Hecke operator $T(n)$ applied to a weight $k$ modular form $f = \sum_{n\geq 0} c(n) e(nz)$ (let's assume, contrary to the book, that $f$ is a modular form over the full modular group), then the formula derived for $b(m)$ then is $$\sum_{d \mid (m, n)} d^{k-1} c\left( \frac{mn}{d^2}\right)$$ The authors then state that this can be used to ""give [a] quick proof"" of $$T(n) T(m) = \sum_{d \mid (m, n)} d^{k - 1} T\left( \frac{mn}{d^2} \right)$$ I've tried to do the proof using that the Fourier-coefficients determine a modular form. But I got only long expressions for the Fourier coefficients of the LHS and the RHS, and couldn't really conclude anything. So my question is: How can I prove this quickly using the fomula for the Fourier-coefficients? Thanks! Added: I've had the following idea: One can prove that the cusp-forms have a basis of normalized eigenforms. For eigenforms one can derive the desired formula by our expression of the Fourier-coefficients (which happen to be the eigenvalues of the eigenforms), which then holds for the whole space of cusp-forms. However, showing that the space of cusp-forms has a basis of normalized eigenforms is not a quick proof. I still think I'm missing something here...",,"['complex-analysis', 'number-theory', 'analytic-number-theory', 'modular-forms', 'automorphic-forms']"
53,Showing two integrals are equal,Showing two integrals are equal,,"I would like to show that $$ \frac{1}{\Gamma\left(\, -\alpha\,\right)} \int_{-\infty}^{x}\frac{\,\mathrm{f}\left(\, t\,\right)} {\left(\, x - t\,\right)^{\alpha + 1}}\,\mathrm{d}t = \frac{1}{2\pi} \int_{-\infty}^{\infty}(\mathrm{i}t)^{\alpha}\,\mathrm{e}^{\mathrm{i}kt} \int_{-\infty}^{\infty}\,\mathrm{e}^{-\mathrm{i}kt} \,\mathrm{f}\left(\, k\,\right)\,\mathrm{d}k\,\mathrm{d}t$$ for fixed $\alpha$ such that $\Re(\alpha) < 0$ and square integrable $f$. I was under the impression that this is a straight forward computation, but I am having difficulty getting anywhere. I apologize for the weak effort in advance. So far, I've tried considering rewriting the LHS in terms of the Cauchy Integral formula by writing something like $$\frac{1}{\Gamma(-\alpha)} \left(\int_{-\infty}^{\infty} \frac{f(t)}{(x-t)^{\alpha+1}}dt - \int_{x}^{\infty} \frac{f(t)}{(x-t)^{\alpha+1}}dt\right)$$ but I can't get anything that is both useful and makes sense from here. I've also considered trying to solve one of the integrals on the RHS using some contour integration technique by considering something like $$\int_{-\infty}^{\infty} e^{-itx}f(x)dx = \lim_{R\rightarrow \infty}\int_{-R}^{R} e^{-itz} f(z)dz + \int_{\gamma} e^{itz}f(z)dz$$ but it is difficult for me to decide how I can choose a $\gamma$ which makes sense knowing nothing about the poles of $f$. The only other ideas I have might be to try to use integration by parts to rewrite both sides using properties of the Fourier transform or possibly try to rewrite the integrals as infinite sums but I'm not getting anywhere.","I would like to show that $$ \frac{1}{\Gamma\left(\, -\alpha\,\right)} \int_{-\infty}^{x}\frac{\,\mathrm{f}\left(\, t\,\right)} {\left(\, x - t\,\right)^{\alpha + 1}}\,\mathrm{d}t = \frac{1}{2\pi} \int_{-\infty}^{\infty}(\mathrm{i}t)^{\alpha}\,\mathrm{e}^{\mathrm{i}kt} \int_{-\infty}^{\infty}\,\mathrm{e}^{-\mathrm{i}kt} \,\mathrm{f}\left(\, k\,\right)\,\mathrm{d}k\,\mathrm{d}t$$ for fixed $\alpha$ such that $\Re(\alpha) < 0$ and square integrable $f$. I was under the impression that this is a straight forward computation, but I am having difficulty getting anywhere. I apologize for the weak effort in advance. So far, I've tried considering rewriting the LHS in terms of the Cauchy Integral formula by writing something like $$\frac{1}{\Gamma(-\alpha)} \left(\int_{-\infty}^{\infty} \frac{f(t)}{(x-t)^{\alpha+1}}dt - \int_{x}^{\infty} \frac{f(t)}{(x-t)^{\alpha+1}}dt\right)$$ but I can't get anything that is both useful and makes sense from here. I've also considered trying to solve one of the integrals on the RHS using some contour integration technique by considering something like $$\int_{-\infty}^{\infty} e^{-itx}f(x)dx = \lim_{R\rightarrow \infty}\int_{-R}^{R} e^{-itz} f(z)dz + \int_{\gamma} e^{itz}f(z)dz$$ but it is difficult for me to decide how I can choose a $\gamma$ which makes sense knowing nothing about the poles of $f$. The only other ideas I have might be to try to use integration by parts to rewrite both sides using properties of the Fourier transform or possibly try to rewrite the integrals as infinite sums but I'm not getting anywhere.",,"['calculus', 'complex-analysis']"
54,Double periodic entire function,Double periodic entire function,,Suppose f is entire and $f(z)=f(z+1)=f(z+\pi)$. Does this imply $f$ is constant? I want to prove that it is constant.I see that it is enough to consider the value of $f(z)$ in between the lines $z=1$ and $z=-1$. Clearly $f$ does not have a pole at $\infty$ (gonig to $\infty$ along the real line). I only need to show that it does not have essential singularity at $\infty$. But I cannot proceed further.Also I am not using the second condition. Any help is highly appreciated. Also I am not sure if the answer is yes.,Suppose f is entire and $f(z)=f(z+1)=f(z+\pi)$. Does this imply $f$ is constant? I want to prove that it is constant.I see that it is enough to consider the value of $f(z)$ in between the lines $z=1$ and $z=-1$. Clearly $f$ does not have a pole at $\infty$ (gonig to $\infty$ along the real line). I only need to show that it does not have essential singularity at $\infty$. But I cannot proceed further.Also I am not using the second condition. Any help is highly appreciated. Also I am not sure if the answer is yes.,,[]
55,Why is holomorphic function with non-zero derivative a conformal map?,Why is holomorphic function with non-zero derivative a conformal map?,,"I am new to complex analysis, interested to know why non-zero derivative implies a conformal map. Intuitively, I would think that non-zero derivative means the function is non-constant. Why would that be related to preserving angles? Any intuitive reasons? I understand that this may be a standard result in complex analysis. If so, please point out a good source where I can read more about it. (Suitable text for undergraduate level student) Thanks!","I am new to complex analysis, interested to know why non-zero derivative implies a conformal map. Intuitively, I would think that non-zero derivative means the function is non-constant. Why would that be related to preserving angles? Any intuitive reasons? I understand that this may be a standard result in complex analysis. If so, please point out a good source where I can read more about it. (Suitable text for undergraduate level student) Thanks!",,['complex-analysis']
56,Analytic continuation of $\sum (z/a)^n$,Analytic continuation of,\sum (z/a)^n,"I'm having trouble continuing this function beyond its convergence radius, $R=a$. $$f(z)=\sum (z/a)^n$$ Given the context (a textbook in complex analysis) I suspect it should have a simple closed-form expression. I've tried differentiating and trying to relate it to the geomtric series, but so far I haven't had any success. Any hint or idea on how to analytic continuate it? Thanks in advance!","I'm having trouble continuing this function beyond its convergence radius, $R=a$. $$f(z)=\sum (z/a)^n$$ Given the context (a textbook in complex analysis) I suspect it should have a simple closed-form expression. I've tried differentiating and trying to relate it to the geomtric series, but so far I haven't had any success. Any hint or idea on how to analytic continuate it? Thanks in advance!",,"['complex-analysis', 'power-series', 'analytic-continuation']"
57,"Compute $\int_{0}^{2\pi}\frac{1}{(2+\cos\theta)^2}\,d\theta$",Compute,"\int_{0}^{2\pi}\frac{1}{(2+\cos\theta)^2}\,d\theta","I''m stuck in a exercise in complex analysis concerning integration of rational trigonometric functions. Here it goes: We want to evaluate $\int_{0}^{2\pi}\frac{1}{(2+\cos\theta)^2}\,d\theta$. Here's my work: Let $z=e^{i\theta}$ so that $d\theta=dz/iz$ and $\cos \theta = \frac12 (z+z^{-1})$.  We have $$\begin{align} I&=\int_{0}^{2\pi}\frac{1}{(2+\cos\theta)^2}\,d\theta \quad (1)\\\\  &=\oint_C \frac{1}{(2+\frac{z+z^{-1}}{2})^2}\frac{dz}{iz} \quad (2)\\\\  &=\frac1i\oint_C \frac{4}{(4+z+z^{-1})^2}\frac{dz}{z} \quad (3) \\\\  &=\frac4i\oint_C \frac{1}{(z^2+4z+1)^2}\,dz \quad (4) \\\\  &=\frac4i\oint_C \frac{1}{(z-(-2+\sqrt3)^2(z-(-2-\sqrt3)^2}\,dz \quad (5)\\\\ &=\frac4i\oint_Cf(z)\,dz \quad (6) \end{align}$$ where $C$ is the unit circle in the complex $z$-plane. The function $f(z)$ has singularities at $(-2\pm\sqrt3)$ but only $(-2+\sqrt3)\in int(C)$. Therefore, $$\oint_Cf(z)\,dz=2\pi i (Res(f, (-2+\sqrt3))) \quad (*)$$ Since $(-2+\sqrt3)$ is a pole of order $2$, after a quick calculation I get $$Res(f, (-2+\sqrt3)=-\frac{\sqrt3}{3}$$ and so for $(*)$ I get $$\oint_Cf(z)\,dz=2\pi i (-\frac{\sqrt3}{3})=-\frac{2\pi\sqrt3i}{3}.$$ Hence, by $(6)$, I find $$\frac4i\oint_Cf(z)\,dz=\frac4i \left(\frac{-2\pi\sqrt3i}{3}\right)=-\frac{8\pi\sqrt3}{3}.$$ My solution however is not correct. The given integral evaluates to $\frac{4\pi}{3\sqrt3}$ (verified with Wolfram). I suspect there must be a flaw in one of my steps from $(1)$ to $(6)$ but I can't find it.","I''m stuck in a exercise in complex analysis concerning integration of rational trigonometric functions. Here it goes: We want to evaluate $\int_{0}^{2\pi}\frac{1}{(2+\cos\theta)^2}\,d\theta$. Here's my work: Let $z=e^{i\theta}$ so that $d\theta=dz/iz$ and $\cos \theta = \frac12 (z+z^{-1})$.  We have $$\begin{align} I&=\int_{0}^{2\pi}\frac{1}{(2+\cos\theta)^2}\,d\theta \quad (1)\\\\  &=\oint_C \frac{1}{(2+\frac{z+z^{-1}}{2})^2}\frac{dz}{iz} \quad (2)\\\\  &=\frac1i\oint_C \frac{4}{(4+z+z^{-1})^2}\frac{dz}{z} \quad (3) \\\\  &=\frac4i\oint_C \frac{1}{(z^2+4z+1)^2}\,dz \quad (4) \\\\  &=\frac4i\oint_C \frac{1}{(z-(-2+\sqrt3)^2(z-(-2-\sqrt3)^2}\,dz \quad (5)\\\\ &=\frac4i\oint_Cf(z)\,dz \quad (6) \end{align}$$ where $C$ is the unit circle in the complex $z$-plane. The function $f(z)$ has singularities at $(-2\pm\sqrt3)$ but only $(-2+\sqrt3)\in int(C)$. Therefore, $$\oint_Cf(z)\,dz=2\pi i (Res(f, (-2+\sqrt3))) \quad (*)$$ Since $(-2+\sqrt3)$ is a pole of order $2$, after a quick calculation I get $$Res(f, (-2+\sqrt3)=-\frac{\sqrt3}{3}$$ and so for $(*)$ I get $$\oint_Cf(z)\,dz=2\pi i (-\frac{\sqrt3}{3})=-\frac{2\pi\sqrt3i}{3}.$$ Hence, by $(6)$, I find $$\frac4i\oint_Cf(z)\,dz=\frac4i \left(\frac{-2\pi\sqrt3i}{3}\right)=-\frac{8\pi\sqrt3}{3}.$$ My solution however is not correct. The given integral evaluates to $\frac{4\pi}{3\sqrt3}$ (verified with Wolfram). I suspect there must be a flaw in one of my steps from $(1)$ to $(6)$ but I can't find it.",,['complex-analysis']
58,Book 2 of Visual Complex Functions,Book 2 of Visual Complex Functions,,"I am having a lot of fun in reading Visual Complex Functions by Professor Wegert. (It is a very interesting read and well-recommended by me.) Inside it, he regularly lets things be and postpones until part 2 or book 2. I have asked Professor Wegert himself about his plans with it (or a title), but unfortunately he seems to be busy at the moment. That's why I am asking the community: Does anyone know of the book 2 mentioned in Visual Complex Functions, or when it is due ?","I am having a lot of fun in reading Visual Complex Functions by Professor Wegert. (It is a very interesting read and well-recommended by me.) Inside it, he regularly lets things be and postpones until part 2 or book 2. I have asked Professor Wegert himself about his plans with it (or a title), but unfortunately he seems to be busy at the moment. That's why I am asking the community: Does anyone know of the book 2 mentioned in Visual Complex Functions, or when it is due ?",,"['complex-analysis', 'reference-request', 'visualization']"
59,$f$ is holomorphic in Ω such that $|f|^2$ is harmonic; we need to show that $f$ is constant.,is holomorphic in Ω such that  is harmonic; we need to show that  is constant.,f |f|^2 f,"$f$ is holomorphic in Ω such that $|f|^2$ is harmonic; we need to show that $f$ is constant. solution of the question In the solution attached, I don't really understand the transition between $∆|f(z)|^2 = 4|f'_z(z)|^2$. It would be great someone could answer this.","$f$ is holomorphic in Ω such that $|f|^2$ is harmonic; we need to show that $f$ is constant. solution of the question In the solution attached, I don't really understand the transition between $∆|f(z)|^2 = 4|f'_z(z)|^2$. It would be great someone could answer this.",,"['complex-analysis', 'harmonic-functions', 'holomorphic-functions']"
60,Show that $\frac{z^2}{z-3}$ is analytic.,Show that  is analytic.,\frac{z^2}{z-3},"Explain why $\displaystyle \int_{C_1(0)} f(z) dz =0$ for the function $\dfrac{z^2}{z-3}$. In case there's some confusion with the notation, $C_1(0)=$ circle of radius $1$ centered at $0$ in $\mathbb{C}$. We were given several theorems in class for this, but here's one that I think might be applicable: Assume $f(z)$ analytic in domain $\Omega$ and $\Gamma \subset \Omega$ a closed Jordan curve whose interior is contained in $\Omega$ so that $f(z)$ is analytic on and inside $\Gamma$. Then $$\int_{\Gamma} f(z) dz = 0.$$ since $\Gamma=C_1(0)$ is a Jordan curve sitting inside the disk $\Omega=D_2(0)$. The function $f(z)$ has discontinuity at the point $z=3$, but that's okay since $\left|3-0 \right|^2=9 > 4$, so $3 \not\in D_2(0)$. Thus it is left to show that $f(z)$ is analytic on the disk. Is everything correct so far? Am I using the right theorem here? Now I want to prove that $\dfrac{z^2}{z-3}$ is analytic, but I'm having trouble breaking it into real and complex parts so that I can check that the first order partial derivatives are continuous and that the Cauchy Riemann equations are satisfied. After expanding the $z^2$ term it just gets ugly. Assuming $z=x+iy$, I get $$\frac{x^2-y^2+i(2xy)}{(x+iy)-3}.$$ How do I show that this function is analytic?","Explain why $\displaystyle \int_{C_1(0)} f(z) dz =0$ for the function $\dfrac{z^2}{z-3}$. In case there's some confusion with the notation, $C_1(0)=$ circle of radius $1$ centered at $0$ in $\mathbb{C}$. We were given several theorems in class for this, but here's one that I think might be applicable: Assume $f(z)$ analytic in domain $\Omega$ and $\Gamma \subset \Omega$ a closed Jordan curve whose interior is contained in $\Omega$ so that $f(z)$ is analytic on and inside $\Gamma$. Then $$\int_{\Gamma} f(z) dz = 0.$$ since $\Gamma=C_1(0)$ is a Jordan curve sitting inside the disk $\Omega=D_2(0)$. The function $f(z)$ has discontinuity at the point $z=3$, but that's okay since $\left|3-0 \right|^2=9 > 4$, so $3 \not\in D_2(0)$. Thus it is left to show that $f(z)$ is analytic on the disk. Is everything correct so far? Am I using the right theorem here? Now I want to prove that $\dfrac{z^2}{z-3}$ is analytic, but I'm having trouble breaking it into real and complex parts so that I can check that the first order partial derivatives are continuous and that the Cauchy Riemann equations are satisfied. After expanding the $z^2$ term it just gets ugly. Assuming $z=x+iy$, I get $$\frac{x^2-y^2+i(2xy)}{(x+iy)-3}.$$ How do I show that this function is analytic?",,['complex-analysis']
61,Embedding Complex Tori in Projective Space,Embedding Complex Tori in Projective Space,,"When we talk about projectively embedding complex tori $\mathbb{C}^{g}/\Lambda$ (i.e in Lefshetz Embedding Theorem), what exactly do we mean by an embedding. Is it in the differential geometry sense of needing to be immersive (injective on tangent spaces), or is less required ? I suppose what I'm really asking is, what do we actually need the embedding to do to call our complex tori an abelian variety?","When we talk about projectively embedding complex tori $\mathbb{C}^{g}/\Lambda$ (i.e in Lefshetz Embedding Theorem), what exactly do we mean by an embedding. Is it in the differential geometry sense of needing to be immersive (injective on tangent spaces), or is less required ? I suppose what I'm really asking is, what do we actually need the embedding to do to call our complex tori an abelian variety?",,"['complex-analysis', 'algebraic-geometry', 'complex-geometry', 'abelian-varieties']"
62,Why is the function $a^z$ multi-valued?,Why is the function  multi-valued?,a^z,"For $a \in \mathbb C$, $z \in \mathbb C \mapsto f(z) = a^z$ is multi-valued. Why so? Can you please explain this to me?","For $a \in \mathbb C$, $z \in \mathbb C \mapsto f(z) = a^z$ is multi-valued. Why so? Can you please explain this to me?",,['complex-analysis']
63,"Complex function is continuous, satisfies C-R, but is not differentiable","Complex function is continuous, satisfies C-R, but is not differentiable",,"Let $f : \mathbb{C} \to \mathbb{C}$ be given by $$ f(z) = f(x + iy) = \frac{xy(x + iy)}{x^2 + y^2}, ~~~~ (x, y) \neq (0, 0) $$ and $f(0) = 0$. It is easy to show that $f$ is continuous at 0 and satisfies the Cauchy-Riemann equations at 0. But, I know that the function is not differentiable at $z = 0$. How do I prove this? I know that $\mathbb{C}$ can be identified with $\mathbb{R}^2$ and that a function from $\mathbb{R}^2$ to $\mathbb{R}$ is not differentiable at a point if its partial derivatives are not continuous there. However, my complex function $f$ can only be ""transformed"" to a function from $\mathbb{R}^2$ to $\mathbb{R}^2$ (by using $f(x, y) = u(x, y) + i v(x, y)$). Does this mean $f$ has 4 partial derivatives (2 for $u$, 2 for $v$) and that I have to prove that one of them is not continuous at $z = 0$? Frankly, I have never even heard of partial derivatives of functions whose codomain is not $\mathbb{R}$. Any ideas on how to prove that $f$ is not continuous at $z = 0$ are welcome.","Let $f : \mathbb{C} \to \mathbb{C}$ be given by $$ f(z) = f(x + iy) = \frac{xy(x + iy)}{x^2 + y^2}, ~~~~ (x, y) \neq (0, 0) $$ and $f(0) = 0$. It is easy to show that $f$ is continuous at 0 and satisfies the Cauchy-Riemann equations at 0. But, I know that the function is not differentiable at $z = 0$. How do I prove this? I know that $\mathbb{C}$ can be identified with $\mathbb{R}^2$ and that a function from $\mathbb{R}^2$ to $\mathbb{R}$ is not differentiable at a point if its partial derivatives are not continuous there. However, my complex function $f$ can only be ""transformed"" to a function from $\mathbb{R}^2$ to $\mathbb{R}^2$ (by using $f(x, y) = u(x, y) + i v(x, y)$). Does this mean $f$ has 4 partial derivatives (2 for $u$, 2 for $v$) and that I have to prove that one of them is not continuous at $z = 0$? Frankly, I have never even heard of partial derivatives of functions whose codomain is not $\mathbb{R}$. Any ideas on how to prove that $f$ is not continuous at $z = 0$ are welcome.",,"['complex-analysis', 'derivatives', 'partial-derivative']"
64,Modular Discriminant and Pentagonal Numbers,Modular Discriminant and Pentagonal Numbers,,"I am asked to show $$(2\pi)^{-12}\Delta(\tau) = q \cdot \Big (\sum_{n\in \mathbb{Z}} (-1)^n \cdot q^{(3n^2+n)/2} \Big)^{24}$$ where $\Delta:\mathbb{H} \to \mathbb{C}$ is the modular discriminant, $q=e^{2\pi i \tau}$. My approach: Call the RHS $\vartheta(\tau)$. I've shown $\vartheta$ converges normally on $\mathbb{H}$. Now, $\Delta$ is a (holomorphic) cusp form of weight $12$ on $SL_2(\mathbb{Z})$. Since the vector space of such cusp forms is one-dimensional, if we show $\vartheta$ is a cusp form then we know $\delta = \alpha \vartheta$ for some constant $\alpha$. Then examining the Fourier expansion one can show $\alpha = (2\pi)^{12}$. To show $\vartheta \in S_k$ we must check for any $\begin{pmatrix} a & b \\ c & d \end{pmatrix} \in SL_2(\mathbb{Z})$ that $\vartheta(\gamma \tau) = (c\tau+d)^{12}\vartheta(\tau)$, where $\gamma$ is the Mobius transform induced by the matrix. For this its enough to verify on the generators, which give transformations $\tau \to \tau + 1$, $\tau \to -1/\tau$. The first transformation is easy, but I can't figure out how to prove $\vartheta(-1/\tau) = \tau^{12} \vartheta(\tau)$. I did a similar problem following the exact same procedure. It was to show $(2\pi)^{-12}\Delta(\tau) = 2^{-8}(\vartheta_1\vartheta_2\vartheta_3(\tau))^8$ for similar looking functions $\vartheta_j$. I was able to recognize these functions as theta functions and manipulate the theta transformation formula. In this problem, I'm failing to get theta transformation to work. Does anyone have any ideas? It should also be noted that we have been discussing vector valued theta functions recently on quadratic lattices, so maybe this is a necessary tool. Again, I can't find a way to apply these ideas though. Another approach to the problem is using my previous exercise: note $\vartheta_1 = \sum_{n \in \mathbb{Z}}q^{n^2/2}$, $\vartheta_2 = \sum_{n \in \mathbb{Z}}(-1)^n \cdot q^{n^2/2}$, $\vartheta_3 = \sum_{n \in \mathbb{Z}}q^{(n+1/2)^2/2}$. Maybe one can quickly do the problem by the Cauchy product formula, but I'm bad at manipulating these messy sums. Thanks a lot.","I am asked to show $$(2\pi)^{-12}\Delta(\tau) = q \cdot \Big (\sum_{n\in \mathbb{Z}} (-1)^n \cdot q^{(3n^2+n)/2} \Big)^{24}$$ where $\Delta:\mathbb{H} \to \mathbb{C}$ is the modular discriminant, $q=e^{2\pi i \tau}$. My approach: Call the RHS $\vartheta(\tau)$. I've shown $\vartheta$ converges normally on $\mathbb{H}$. Now, $\Delta$ is a (holomorphic) cusp form of weight $12$ on $SL_2(\mathbb{Z})$. Since the vector space of such cusp forms is one-dimensional, if we show $\vartheta$ is a cusp form then we know $\delta = \alpha \vartheta$ for some constant $\alpha$. Then examining the Fourier expansion one can show $\alpha = (2\pi)^{12}$. To show $\vartheta \in S_k$ we must check for any $\begin{pmatrix} a & b \\ c & d \end{pmatrix} \in SL_2(\mathbb{Z})$ that $\vartheta(\gamma \tau) = (c\tau+d)^{12}\vartheta(\tau)$, where $\gamma$ is the Mobius transform induced by the matrix. For this its enough to verify on the generators, which give transformations $\tau \to \tau + 1$, $\tau \to -1/\tau$. The first transformation is easy, but I can't figure out how to prove $\vartheta(-1/\tau) = \tau^{12} \vartheta(\tau)$. I did a similar problem following the exact same procedure. It was to show $(2\pi)^{-12}\Delta(\tau) = 2^{-8}(\vartheta_1\vartheta_2\vartheta_3(\tau))^8$ for similar looking functions $\vartheta_j$. I was able to recognize these functions as theta functions and manipulate the theta transformation formula. In this problem, I'm failing to get theta transformation to work. Does anyone have any ideas? It should also be noted that we have been discussing vector valued theta functions recently on quadratic lattices, so maybe this is a necessary tool. Again, I can't find a way to apply these ideas though. Another approach to the problem is using my previous exercise: note $\vartheta_1 = \sum_{n \in \mathbb{Z}}q^{n^2/2}$, $\vartheta_2 = \sum_{n \in \mathbb{Z}}(-1)^n \cdot q^{n^2/2}$, $\vartheta_3 = \sum_{n \in \mathbb{Z}}q^{(n+1/2)^2/2}$. Maybe one can quickly do the problem by the Cauchy product formula, but I'm bad at manipulating these messy sums. Thanks a lot.",,"['abstract-algebra', 'complex-analysis', 'number-theory', 'modular-forms', 'theta-functions']"
65,Proving complex trigonometric identity using power series,Proving complex trigonometric identity using power series,,Prove $2$cos$^2(z) = 1+$cos$(2z)$ using power series. I know that cos$(z) = \sum (-1)^n\frac{z^{2n}}{(2n)!}$ I also know that if $a(z) = \sum a_nz^n$ and $b(z) = \sum b_nz^n$ then $a(z)b(z) = \sum c_nz^n $ where $c_n = a_0b_n + a_1b_{n-1}+a_2b_{n-2}+...+a_nb_{0}$ Combining this I got cos$^2(z) = \sum \left [   (-1)^nz^{2n} \sum_{k=0}^{n} \frac{1}{(2n-2k)!(2k)!} \right]$ and cos$(2z) = \sum \left [(-1)^nz^{2n} \frac{4^n}{(2n)!} \right]$ I havent really gotten further than this. I tried writing $\sum_{k=0}^{n}\frac{1}{(2n-2k)!(2k)!}$ as $\frac{1}{(2n)!}\sum_{k=0}^{n}\binom{2n}{2k}$ but no luck! Any ideas? EDIT So we have cos$^2(z) = \sum \left [   (-1)^nz^{2n} \sum_{k=0}^{n} \frac{1}{(2n-2k)!(2k)!} \right]$ $= \sum \left [  \frac{ (-1)^n}{(2n)!}z^{2n} \sum_{k=0}^{n} \binom{2n}{2k}  \right]$ $= \sum \left [  \frac{ (-1)^n}{(2n)!}z^{2n} \frac{4^n}{2}  \right]$ $= \frac{1}{2} \sum \left [ (-1)^n \frac{4^n}{(2n)!}z^{2n}  \right]$ $= \frac{1}{2}$cos$(2z)$ Therefore $2$cos$^2(z) = $cos$(2z)$,Prove $2$cos$^2(z) = 1+$cos$(2z)$ using power series. I know that cos$(z) = \sum (-1)^n\frac{z^{2n}}{(2n)!}$ I also know that if $a(z) = \sum a_nz^n$ and $b(z) = \sum b_nz^n$ then $a(z)b(z) = \sum c_nz^n $ where $c_n = a_0b_n + a_1b_{n-1}+a_2b_{n-2}+...+a_nb_{0}$ Combining this I got cos$^2(z) = \sum \left [   (-1)^nz^{2n} \sum_{k=0}^{n} \frac{1}{(2n-2k)!(2k)!} \right]$ and cos$(2z) = \sum \left [(-1)^nz^{2n} \frac{4^n}{(2n)!} \right]$ I havent really gotten further than this. I tried writing $\sum_{k=0}^{n}\frac{1}{(2n-2k)!(2k)!}$ as $\frac{1}{(2n)!}\sum_{k=0}^{n}\binom{2n}{2k}$ but no luck! Any ideas? EDIT So we have cos$^2(z) = \sum \left [   (-1)^nz^{2n} \sum_{k=0}^{n} \frac{1}{(2n-2k)!(2k)!} \right]$ $= \sum \left [  \frac{ (-1)^n}{(2n)!}z^{2n} \sum_{k=0}^{n} \binom{2n}{2k}  \right]$ $= \sum \left [  \frac{ (-1)^n}{(2n)!}z^{2n} \frac{4^n}{2}  \right]$ $= \frac{1}{2} \sum \left [ (-1)^n \frac{4^n}{(2n)!}z^{2n}  \right]$ $= \frac{1}{2}$cos$(2z)$ Therefore $2$cos$^2(z) = $cos$(2z)$,,"['complex-analysis', 'power-series']"
66,Explicit formula for conformal map from ellipse to unit disc (interior to interior),Explicit formula for conformal map from ellipse to unit disc (interior to interior),,"I was originally looking for a conformal map that maps a punctured unit disc to unit disc. The only answer I can find lead to this resource. The final step of the answer given rely on a conformal map that maps an ellipse to a unit disc. Although we know such a map exist by Riemann Mapping Theorem, is there any way to write down the map explicitly (let's say, length of axes are given)? The only related formula I can find is Joukowski transformation which does the other way around.","I was originally looking for a conformal map that maps a punctured unit disc to unit disc. The only answer I can find lead to this resource. The final step of the answer given rely on a conformal map that maps an ellipse to a unit disc. Although we know such a map exist by Riemann Mapping Theorem, is there any way to write down the map explicitly (let's say, length of axes are given)? The only related formula I can find is Joukowski transformation which does the other way around.",,['complex-analysis']
67,Number of roots of a sequence of a uniformly convergent holomorphic functions implies an upper bound for the number of roots of their limit,Number of roots of a sequence of a uniformly convergent holomorphic functions implies an upper bound for the number of roots of their limit,,"Let $G$ be an open, simply connected region in $\mathbb{C}$. We define a sequence of holomorphic functions $(f_n)_{n \in \mathbb{N}}, f_n: G \to \mathbb{C}$ as almost uniformly convergent iff $(f_n)$ converges uniformly on all compact subsets of $G$. I now want to show that, if $f_n \to f$ for a non-constant function $f: G \to \mathbb{C}$, and none of the $f_n$ has more than $m \in \mathbb{N}$ roots, then $f$ also has not more than $m$ roots. (If we count roots with their multiplicities.) I already know that the limit of an almost uniformly convergent sequence of holomorphic functions is also holomorphic, and (although I don't think that's helpful here), I also know that $(f_n')$ then converges almost uniformly against $f'$. So I only have to show this statement about the roots. I thought about using Rouché's Theorem , mostly because I couldn't think about any other Theorem I know that concretly talks about the actual number of roots of different functions. But I don't know how exactly I can apply Rouché here: what would I choose as the functions $f$ and $g$ that Rouché's Theorem demands, in order to show the inequality in the Theorem?","Let $G$ be an open, simply connected region in $\mathbb{C}$. We define a sequence of holomorphic functions $(f_n)_{n \in \mathbb{N}}, f_n: G \to \mathbb{C}$ as almost uniformly convergent iff $(f_n)$ converges uniformly on all compact subsets of $G$. I now want to show that, if $f_n \to f$ for a non-constant function $f: G \to \mathbb{C}$, and none of the $f_n$ has more than $m \in \mathbb{N}$ roots, then $f$ also has not more than $m$ roots. (If we count roots with their multiplicities.) I already know that the limit of an almost uniformly convergent sequence of holomorphic functions is also holomorphic, and (although I don't think that's helpful here), I also know that $(f_n')$ then converges almost uniformly against $f'$. So I only have to show this statement about the roots. I thought about using Rouché's Theorem , mostly because I couldn't think about any other Theorem I know that concretly talks about the actual number of roots of different functions. But I don't know how exactly I can apply Rouché here: what would I choose as the functions $f$ and $g$ that Rouché's Theorem demands, in order to show the inequality in the Theorem?",,"['complex-analysis', 'analysis', 'convergence-divergence', 'uniform-convergence']"
68,Trying to express a polynomial as $(z-\text{root}_1)(z-\text{root}_2)$,Trying to express a polynomial as,(z-\text{root}_1)(z-\text{root}_2),"I'm probably making some stupid mistake, but here's my problem: I have the polynomial $0.5z^2+9iz-0.5$, the roots I calculated are $a=-9i-4\sqrt5i,\;\;\;b=-9i+4\sqrt5i$. I tried to express the polynomial as $(z-a)(z-b)$, and I plugged some numbers to check if it works - but it seems like I always get double the result, what am I doing wrong? (Results were calculated with a calculator)","I'm probably making some stupid mistake, but here's my problem: I have the polynomial $0.5z^2+9iz-0.5$, the roots I calculated are $a=-9i-4\sqrt5i,\;\;\;b=-9i+4\sqrt5i$. I tried to express the polynomial as $(z-a)(z-b)$, and I plugged some numbers to check if it works - but it seems like I always get double the result, what am I doing wrong? (Results were calculated with a calculator)",,['complex-analysis']
69,Where is this function holomorphic?,Where is this function holomorphic?,,"I've never really had to think about this problem before, and to be honest complex analysis isn't my strongest suit, so when I suddenly needed to know where $z^z$ is holomorphic, I didn't know where to begin to start proving my hunches. My guess is that it's holomorphic away from $0$. More generally, given two entire functions $f$ and $g$, where is $f(z)^{g(z)}$ holomorphic? Again, my hunch is that it is away from the zeroes of $f$. This isn't a time sensitive question, so any help you can provide would be appreciated, from proofs to thoughts to hints!","I've never really had to think about this problem before, and to be honest complex analysis isn't my strongest suit, so when I suddenly needed to know where $z^z$ is holomorphic, I didn't know where to begin to start proving my hunches. My guess is that it's holomorphic away from $0$. More generally, given two entire functions $f$ and $g$, where is $f(z)^{g(z)}$ holomorphic? Again, my hunch is that it is away from the zeroes of $f$. This isn't a time sensitive question, so any help you can provide would be appreciated, from proofs to thoughts to hints!",,['complex-analysis']
70,The roots of the equation $z^n=(z+3)^n$,The roots of the equation,z^n=(z+3)^n,"Prove that the roots of the equation $z^n=(z+3)^n$ are collinear Taking modulus on both sides, $$\vert z-0\vert =\vert z-3\vert$$ This represents the perpendicular bisector of line joining $x=0$ and $x=3$ That was easy. But I tried to solve it using algebra: $$\frac{z+3}{z}=1^{\frac{1}{n}}=\cos{\frac{2k\pi}{n}}+i\sin{\frac{2k\pi}{n}}$$ After simplifying, I got $$z=\frac{3i ( \cos{\frac{k\pi}{n} }+i\sin{ \frac{k\pi}{n}})}{2\sin{ \frac{k\pi}{n}}}$$ What should I do next?","Prove that the roots of the equation $z^n=(z+3)^n$ are collinear Taking modulus on both sides, $$\vert z-0\vert =\vert z-3\vert$$ This represents the perpendicular bisector of line joining $x=0$ and $x=3$ That was easy. But I tried to solve it using algebra: $$\frac{z+3}{z}=1^{\frac{1}{n}}=\cos{\frac{2k\pi}{n}}+i\sin{\frac{2k\pi}{n}}$$ After simplifying, I got $$z=\frac{3i ( \cos{\frac{k\pi}{n} }+i\sin{ \frac{k\pi}{n}})}{2\sin{ \frac{k\pi}{n}}}$$ What should I do next?",,"['complex-analysis', 'complex-numbers']"
71,Laplace equation in two dimensions and complex analysis,Laplace equation in two dimensions and complex analysis,,I was playing around with Laplace's equation: $$\frac{\partial^2 u}{\partial x ^2}+\frac{\partial^2 u}{\partial y ^2}=0$$ It occured to me that it can be written as: $$\bigg(\frac{\partial}{\partial x}-\frac{1}{i}\frac{\partial}{\partial y}\bigg)\bigg(\frac{\partial}{\partial x}+\frac{1}{i}\frac{\partial}{\partial y}\bigg)u=0$$ That means that the most general solution to the equation is: $$u=f(x+iy)+g(x-iy)$$ That is: $$u=f(z)+g(\bar z)$$ Suppose we want to solve the equation in a finite domain of $\mathbb{R}^2$ with Dirichlet boundary conditions. Isn't it possible to reduce the problem to an integral using Cauchy's formula of complex analysis?,I was playing around with Laplace's equation: $$\frac{\partial^2 u}{\partial x ^2}+\frac{\partial^2 u}{\partial y ^2}=0$$ It occured to me that it can be written as: $$\bigg(\frac{\partial}{\partial x}-\frac{1}{i}\frac{\partial}{\partial y}\bigg)\bigg(\frac{\partial}{\partial x}+\frac{1}{i}\frac{\partial}{\partial y}\bigg)u=0$$ That means that the most general solution to the equation is: $$u=f(x+iy)+g(x-iy)$$ That is: $$u=f(z)+g(\bar z)$$ Suppose we want to solve the equation in a finite domain of $\mathbb{R}^2$ with Dirichlet boundary conditions. Isn't it possible to reduce the problem to an integral using Cauchy's formula of complex analysis?,,"['complex-analysis', 'partial-differential-equations', 'harmonic-functions', 'boundary-value-problem']"
72,If $f$ is analytic in $|z|<1$ then prove that $f(z^n)=f(0)+(g(z))^n$,If  is analytic in  then prove that,f |z|<1 f(z^n)=f(0)+(g(z))^n,"If $f(z)$ is analytic in $|z|<1$ and $f'(0)\not =0$ prove that there exists an analytic function $g(z)$ such that $f(z^n)=f(0)+(g(z))^n$ in the nbd. of origin. Since $f$ is analytic so Taylor's series expansion of $f$ about $z=0$ is $\displaystyle f(z)=\sum_{k=0}^{\infty}a_kz^k$. Also , $f(0)=a_0$. Then $\displaystyle f(z^n)=f(0)+\sum_{k=1}^{\infty}a_kz^{nk}=f(0)+z^nh(z^n)$ , where $h$ is analytic. But from here how I can prove the required result ?","If $f(z)$ is analytic in $|z|<1$ and $f'(0)\not =0$ prove that there exists an analytic function $g(z)$ such that $f(z^n)=f(0)+(g(z))^n$ in the nbd. of origin. Since $f$ is analytic so Taylor's series expansion of $f$ about $z=0$ is $\displaystyle f(z)=\sum_{k=0}^{\infty}a_kz^k$. Also , $f(0)=a_0$. Then $\displaystyle f(z^n)=f(0)+\sum_{k=1}^{\infty}a_kz^{nk}=f(0)+z^nh(z^n)$ , where $h$ is analytic. But from here how I can prove the required result ?",,['complex-analysis']
73,How to show this equation equals zero?,How to show this equation equals zero?,,"Let $P(z)$ denote a complex polynomial of degree $n$ with simple zeros $a_1, . . . , a_n$. Show that $\sum\limits_{k=1}^{n}\dfrac{a_k^p}{P'(a_k)}=0$, for $p=0,1,...n-2$. I have no idea where to start and the naive way of solving it by brute force is just not working. Any hint would be appreciated.","Let $P(z)$ denote a complex polynomial of degree $n$ with simple zeros $a_1, . . . , a_n$. Show that $\sum\limits_{k=1}^{n}\dfrac{a_k^p}{P'(a_k)}=0$, for $p=0,1,...n-2$. I have no idea where to start and the naive way of solving it by brute force is just not working. Any hint would be appreciated.",,"['complex-analysis', 'polynomials', 'complex-numbers']"
74,"Prove $e^x=1+\frac{1}{\sqrt{\pi }}{\int_0^x \frac{e^t \text{erf}\left(\sqrt{t}\right)}{\sqrt{x-t}} \, dt}$",Prove,"e^x=1+\frac{1}{\sqrt{\pi }}{\int_0^x \frac{e^t \text{erf}\left(\sqrt{t}\right)}{\sqrt{x-t}} \, dt}","It seems to me that $$e^x=1+\frac{1}{\sqrt{\pi }}{\int_0^x \frac{e^t \text{erf}\left(\sqrt{t}\right)}{\sqrt{x-t}} \, dt}$$ This integral seems to converge for all $x\in\mathbb{C}$ I came upon this conjecture by following the instructions here to do a half integral twice. Can anyone prove this conjecture is true?","It seems to me that $$e^x=1+\frac{1}{\sqrt{\pi }}{\int_0^x \frac{e^t \text{erf}\left(\sqrt{t}\right)}{\sqrt{x-t}} \, dt}$$ This integral seems to converge for all $x\in\mathbb{C}$ I came upon this conjecture by following the instructions here to do a half integral twice. Can anyone prove this conjecture is true?",,"['complex-analysis', 'definite-integrals', 'error-function']"
75,"If $0<|z|<1$, show that $\frac{1}{4}|z|<|1-e^z|<\frac{7}{4}|z|$","If , show that",0<|z|<1 \frac{1}{4}|z|<|1-e^z|<\frac{7}{4}|z|,"My question: If $0<|z|<1$, show that $\frac{1}{4}|z|<|1-e^z|<\frac{7}{4}|z|$ ($z$ is complex) what I have tried: I tried to expand the middle term in its Taylor series but I can't get the appropriate bound.","My question: If $0<|z|<1$, show that $\frac{1}{4}|z|<|1-e^z|<\frac{7}{4}|z|$ ($z$ is complex) what I have tried: I tried to expand the middle term in its Taylor series but I can't get the appropriate bound.",,"['calculus', 'complex-analysis', 'taylor-expansion']"
76,"Conformal points, branch points, and analyticity of the mapping $z=w+e^w$?","Conformal points, branch points, and analyticity of the mapping ?",z=w+e^w,"Consider the mapping of the $z$-plane to the $w$-plane given by $$z=w+e^w$$ There is no closed-form $w(z)$ that matches the map, but we can still discuss conformity. $$\frac{dz}{dw}=1+e^w \implies \frac{dw}{dz} = \frac{1}{1+e^w}$$ It appears that $w$ is differentiable and thus analytic where $e^w \ne -1$. So the $w$ mapping fails to conform where $w_n = (2n+1)\pi i$. On the $z$ plane, that corresponds to where $z_n=w_n+e^{w_n}$ or $$z_n=-1 + (2n+1)\pi i$$ But I was instructed that this mapping has two branch points on the $z$-plane, $z= -1\pm \pi i$. And, barring placement of the branch cut, I was instructed that the mapping of the $w$-plane is conformal all $z$ except for those two branch points (and their cuts). Where does this come from? These two points are in the set I found, but if anything, it seems like I have infinitely many $z_n$ that could be contenders for the branch point. Without knowing $w(z)$, how can I actually determine where the branch points are? Additional details: It may be important that I was mapping the two rays parametrized below, which were supposed to run along the branch cuts and end at the two branch points. $$z=x\pm i\pi \quad\quad x\in(-\infty,-1]$$","Consider the mapping of the $z$-plane to the $w$-plane given by $$z=w+e^w$$ There is no closed-form $w(z)$ that matches the map, but we can still discuss conformity. $$\frac{dz}{dw}=1+e^w \implies \frac{dw}{dz} = \frac{1}{1+e^w}$$ It appears that $w$ is differentiable and thus analytic where $e^w \ne -1$. So the $w$ mapping fails to conform where $w_n = (2n+1)\pi i$. On the $z$ plane, that corresponds to where $z_n=w_n+e^{w_n}$ or $$z_n=-1 + (2n+1)\pi i$$ But I was instructed that this mapping has two branch points on the $z$-plane, $z= -1\pm \pi i$. And, barring placement of the branch cut, I was instructed that the mapping of the $w$-plane is conformal all $z$ except for those two branch points (and their cuts). Where does this come from? These two points are in the set I found, but if anything, it seems like I have infinitely many $z_n$ that could be contenders for the branch point. Without knowing $w(z)$, how can I actually determine where the branch points are? Additional details: It may be important that I was mapping the two rays parametrized below, which were supposed to run along the branch cuts and end at the two branch points. $$z=x\pm i\pi \quad\quad x\in(-\infty,-1]$$",,['complex-analysis']
77,"Finding a contour to evaluate$\int_{-\infty}^{\infty}\frac{x\sin x}{x^2+a^2}\,dx$",Finding a contour to evaluate,"\int_{-\infty}^{\infty}\frac{x\sin x}{x^2+a^2}\,dx","I am looking to evaluate to evaluate the real integral $I=\int_{-\infty}^{\infty}\frac{x\sin x}{x^2+a^2}\,dx$ ($a>0$) using Cauchy's residue formula. My strategy is to use the residue theorem to calculate the value of a contour that encircles the a pole and has a side coincides with the real axis. My hope was that the other sides of the contour would be simple to evaluate, but I am struggling to find an appropriate contour. Finding a Pole Defining $f(z)=\frac{z\sin z}{z^2+a^2}$, we quickly see that $1/f$ vanishes at $z_{0}=ai$. Moreover one can check that $g(z)=\begin{cases} \frac{1}{f(z)} \text{   if  } z\neq z_{0},\\ 0 \text{   if  } z= z_{0}.\end{cases} $ is holomorphic, so $ai$ is indeed a pole of $f$. Calculating the Residue Writing $\frac{z\sin z}{z^2+a^2}=\frac{z\sin z}{(z+ai)(z-ai)}$ we see that $\text{res}_{z_{0}}f=$$\lim_{z\to ai}\frac{z\sin z}{(z+ai)}=\frac{\sin ai}{2}$. Finding a ""nice"" Contour By the residue theorem we know that $\int_{\gamma}f(z)\,dz=\pi i\sin ai $ where $\gamma$ is a closed contour that contains our pole (note $\gamma$ doesn't contain other poles). I was hoping to use the semi-circle of radius $R$ with its base along the real line so that $I=\pi i\sin ai -\lim_{R\to\infty}\int_{\gamma_{1}}f(z)\,dz$ where $\gamma_{1}$ is the contour along the arc of the semi-circle. I'm finding it hard to evaluate $\int_{\gamma_{1}}f(z)\,dz$, is there a better choice of contour?","I am looking to evaluate to evaluate the real integral $I=\int_{-\infty}^{\infty}\frac{x\sin x}{x^2+a^2}\,dx$ ($a>0$) using Cauchy's residue formula. My strategy is to use the residue theorem to calculate the value of a contour that encircles the a pole and has a side coincides with the real axis. My hope was that the other sides of the contour would be simple to evaluate, but I am struggling to find an appropriate contour. Finding a Pole Defining $f(z)=\frac{z\sin z}{z^2+a^2}$, we quickly see that $1/f$ vanishes at $z_{0}=ai$. Moreover one can check that $g(z)=\begin{cases} \frac{1}{f(z)} \text{   if  } z\neq z_{0},\\ 0 \text{   if  } z= z_{0}.\end{cases} $ is holomorphic, so $ai$ is indeed a pole of $f$. Calculating the Residue Writing $\frac{z\sin z}{z^2+a^2}=\frac{z\sin z}{(z+ai)(z-ai)}$ we see that $\text{res}_{z_{0}}f=$$\lim_{z\to ai}\frac{z\sin z}{(z+ai)}=\frac{\sin ai}{2}$. Finding a ""nice"" Contour By the residue theorem we know that $\int_{\gamma}f(z)\,dz=\pi i\sin ai $ where $\gamma$ is a closed contour that contains our pole (note $\gamma$ doesn't contain other poles). I was hoping to use the semi-circle of radius $R$ with its base along the real line so that $I=\pi i\sin ai -\lim_{R\to\infty}\int_{\gamma_{1}}f(z)\,dz$ where $\gamma_{1}$ is the contour along the arc of the semi-circle. I'm finding it hard to evaluate $\int_{\gamma_{1}}f(z)\,dz$, is there a better choice of contour?",,"['complex-analysis', 'contour-integration']"
78,Does Cauchy's estimate imply analyticity?,Does Cauchy's estimate imply analyticity?,,"Komatsu says here (Proc. Japan Acad. Volume 36, Number 3 (1960), 90-93) that a smooth function which satisfies Cauchy's estimate is analytic. How does one prove this? Surely, if Cauchy's estimates hold for the derivatives of a function, then its Taylor series converges, but that is not enough for analyticity. Is it necessary to consider the smooth function on a compact interval? In the second answer to this question, the above fact is used for a function defined on the whole real line.","Komatsu says here (Proc. Japan Acad. Volume 36, Number 3 (1960), 90-93) that a smooth function which satisfies Cauchy's estimate is analytic. How does one prove this? Surely, if Cauchy's estimates hold for the derivatives of a function, then its Taylor series converges, but that is not enough for analyticity. Is it necessary to consider the smooth function on a compact interval? In the second answer to this question, the above fact is used for a function defined on the whole real line.",,"['complex-analysis', 'taylor-expansion', 'analyticity']"
79,"Integrate by parts to prove that this integral provides an analytic continuation ,","Integrate by parts to prove that this integral provides an analytic continuation ,",,"Suppose $f(z) = \sum_0^\infty a_nz^n$ converges for $|z| \le 1$. a) Prove $\phi(z) = \sum_0^\infty \frac{a_n}{n!}z^n$ is entire and $|\phi(z)|\le Me^{|z|}$. b) Prove $f(z) = \int_0^\infty e^{-s}\phi(sz)ds$. (Hint: Integrate by parts.) Apply this result to $f(z) = \sum_0^\infty z^{2n}$, which converges in $|z| < 1$ and show that the integral provides an analytic continuation of $f(z)$. I have proved part(a), but am stuck on part(b). With integration by parts, I am currently at: $$-\phi(sz)e^{-s}|_0^{\infty} + z\int_0^\infty e^{-s}\phi'(sz)ds$$ Thanks, EDIT:  if I ignore the convergence of $f(z)$ on the boundary, and just assume that the convergence is for $|z|<1$, then repeated integration by parts, and the fact that $\phi$ is infinitely differentiable, pushes out the terms $a_0 + a_1z + a_2z^2 + ... = \sum_0^\infty a_nz^n = f(z)$, which is what we needed to prove for part(b).  But, is it ok to ignore the convergence on the boundary? I.e., only consider $z$ such that $|z|<1$, but the I feel that we haven't proved that the integral is exactly $f(z)$.  Or, I might just be interpreting the question incorrectly, too.","Suppose $f(z) = \sum_0^\infty a_nz^n$ converges for $|z| \le 1$. a) Prove $\phi(z) = \sum_0^\infty \frac{a_n}{n!}z^n$ is entire and $|\phi(z)|\le Me^{|z|}$. b) Prove $f(z) = \int_0^\infty e^{-s}\phi(sz)ds$. (Hint: Integrate by parts.) Apply this result to $f(z) = \sum_0^\infty z^{2n}$, which converges in $|z| < 1$ and show that the integral provides an analytic continuation of $f(z)$. I have proved part(a), but am stuck on part(b). With integration by parts, I am currently at: $$-\phi(sz)e^{-s}|_0^{\infty} + z\int_0^\infty e^{-s}\phi'(sz)ds$$ Thanks, EDIT:  if I ignore the convergence of $f(z)$ on the boundary, and just assume that the convergence is for $|z|<1$, then repeated integration by parts, and the fact that $\phi$ is infinitely differentiable, pushes out the terms $a_0 + a_1z + a_2z^2 + ... = \sum_0^\infty a_nz^n = f(z)$, which is what we needed to prove for part(b).  But, is it ok to ignore the convergence on the boundary? I.e., only consider $z$ such that $|z|<1$, but the I feel that we haven't proved that the integral is exactly $f(z)$.  Or, I might just be interpreting the question incorrectly, too.",,"['integration', 'sequences-and-series', 'complex-analysis', 'convergence-divergence', 'analyticity']"
80,Branch cut and contour integration along a special function,Branch cut and contour integration along a special function,,"Define for all complex $z$ except for a slit on the real interval $[0,1]$, the analytic function $f(z)=(z^2-z^3)^{-1/3}$, so that $f(z)$ is real valued on the upper side of the slit. a) How are the values of $f(z)$ on the lower side of the slit related to those on the upper side of the slit b) Compute $\int_\gamma f$ taken once around any smooth curve $\gamma$ enclosing the slit. For a), should I pick the branch cut on the interval $[0,1]$. Namely, $0<\arg z<2\pi$ and $-\pi <\arg (z-1)<\pi$. Then we see that the difference between the argument is $\pi/3$ between the top and bottom of the slit. For b), the gamma is taken around the interval $[0,1]$, so we should just use Cauchy integral formula correct? But this is different from the answer given.","Define for all complex $z$ except for a slit on the real interval $[0,1]$, the analytic function $f(z)=(z^2-z^3)^{-1/3}$, so that $f(z)$ is real valued on the upper side of the slit. a) How are the values of $f(z)$ on the lower side of the slit related to those on the upper side of the slit b) Compute $\int_\gamma f$ taken once around any smooth curve $\gamma$ enclosing the slit. For a), should I pick the branch cut on the interval $[0,1]$. Namely, $0<\arg z<2\pi$ and $-\pi <\arg (z-1)<\pi$. Then we see that the difference between the argument is $\pi/3$ between the top and bottom of the slit. For b), the gamma is taken around the interval $[0,1]$, so we should just use Cauchy integral formula correct? But this is different from the answer given.",,['complex-analysis']
81,A problem regarding meromorphic functions,A problem regarding meromorphic functions,,"I was trying to solve problems from Gamelin's complex analysis book, and I came across the following question: Suppose $f(z) = \sum_{k} a_k z^k$ is analytic for $|z| < R$, and suppose that $f$ extends to be meromorphic for $|z| < R+\epsilon,$ with only one pole $z_0$ on the circle $|z|=R$. Prove that $\frac {a_k}{a_{k+1}}\rightarrow z_0$ as $k\rightarrow \infty$. Now it's clear that $\lim_{k\rightarrow \infty}|a_k/a_{k+1}| = |z_0| = R,$ as the limit is the radius of convergence for the power series of $f$, and $f$ extends to be analytic only upto $|z|< R$. But I can't figure out how to prove the actual statement. I was trying to work with the Laurent series of $f$ near $z_0$, but I got stuck. Any help would be appreciated.","I was trying to solve problems from Gamelin's complex analysis book, and I came across the following question: Suppose $f(z) = \sum_{k} a_k z^k$ is analytic for $|z| < R$, and suppose that $f$ extends to be meromorphic for $|z| < R+\epsilon,$ with only one pole $z_0$ on the circle $|z|=R$. Prove that $\frac {a_k}{a_{k+1}}\rightarrow z_0$ as $k\rightarrow \infty$. Now it's clear that $\lim_{k\rightarrow \infty}|a_k/a_{k+1}| = |z_0| = R,$ as the limit is the radius of convergence for the power series of $f$, and $f$ extends to be analytic only upto $|z|< R$. But I can't figure out how to prove the actual statement. I was trying to work with the Laurent series of $f$ near $z_0$, but I got stuck. Any help would be appreciated.",,['complex-analysis']
82,Green's function for Helmholtz equation for the plane with a hole,Green's function for Helmholtz equation for the plane with a hole,,"That is find $G$ which satisfies \begin{align} (\nabla^2+k^2)G(\mathbf{x}, \mathbf{y},\omega) = \delta(\mathbf{x}- \mathbf{y}) \end{align} subject to $$\frac{\partial G}{\partial y_n} = 0 ~~~~~\mathrm{on} ~~~~~~S$$ where $S$ is the unit circle centered on the origin. The domain should be taken to mean the exterior of $S$. This means the normal derivative is zero on the boundary. I use the notation with $\omega$ because it is implied that the forcing is at frequency $\omega$. This follows from the wave equation. Note that I would ideally like the 2D version of the above, that is $\mathbf{x} = (x_1,x_2)$.","That is find $G$ which satisfies \begin{align} (\nabla^2+k^2)G(\mathbf{x}, \mathbf{y},\omega) = \delta(\mathbf{x}- \mathbf{y}) \end{align} subject to $$\frac{\partial G}{\partial y_n} = 0 ~~~~~\mathrm{on} ~~~~~~S$$ where $S$ is the unit circle centered on the origin. The domain should be taken to mean the exterior of $S$. This means the normal derivative is zero on the boundary. I use the notation with $\omega$ because it is implied that the forcing is at frequency $\omega$. This follows from the wave equation. Note that I would ideally like the 2D version of the above, that is $\mathbf{x} = (x_1,x_2)$.",,"['calculus', 'complex-analysis', 'greens-function']"
83,Identity Principle type question: Prove that $f=g$,Identity Principle type question: Prove that,f=g,"While reading a complex analysis textbook the following assertion came up Since $f,g:D\equiv D(a,r) \to \mathbb{C}$ are analytic and injective functions such that $f(D)=g(D)$, $f(a)=g(a)$ and $f'(a)=g'(a)$ then $f=g$. I do not think this follows directly! To prove it I think we need to use the Identity Principle. What I did is take a sequence $(z_n)_n \subset D $ such that $z_n \neq a$ and $z_n \to a$, then for each $n$ there exist $w_n \neq a$ such that $f(z_n)=g(w_n)$. By injectivity and since $f(a)=g(a)$, it follows that also $w_n \to a$. Now I am trying to use the condition $f'(a)=g'(a)$ to see that $z_n=w_n$ for infinitely many $n$'s and hence by the Identity Principle $f=g$. However this argumentation seems to lead nowhere. Any help is very appreciated, perhaps there is a much more simple argument that do not uses anything that I have thought so far.","While reading a complex analysis textbook the following assertion came up Since $f,g:D\equiv D(a,r) \to \mathbb{C}$ are analytic and injective functions such that $f(D)=g(D)$, $f(a)=g(a)$ and $f'(a)=g'(a)$ then $f=g$. I do not think this follows directly! To prove it I think we need to use the Identity Principle. What I did is take a sequence $(z_n)_n \subset D $ such that $z_n \neq a$ and $z_n \to a$, then for each $n$ there exist $w_n \neq a$ such that $f(z_n)=g(w_n)$. By injectivity and since $f(a)=g(a)$, it follows that also $w_n \to a$. Now I am trying to use the condition $f'(a)=g'(a)$ to see that $z_n=w_n$ for infinitely many $n$'s and hence by the Identity Principle $f=g$. However this argumentation seems to lead nowhere. Any help is very appreciated, perhaps there is a much more simple argument that do not uses anything that I have thought so far.",,"['complex-analysis', 'analyticity']"
84,Maximum Modulus path,Maximum Modulus path,,"Consider any entire, non constant function $f:\Bbb C\to \Bbb C$. Choose any $z\in\Bbb C$ and define $m(r)\in\overline D(z,r)$, for any $r\ge 0$, with this property: $$|f(m(r))|\ge|f(w)|\;\forall w\in \overline D(z,r)$$ I'm aware that this definition may be ambiguous, since the maximum modulus needn't be met in a single point. I'm also aware that $|m(r)-z|=r$, by the maximum modulus principle. Questions : Is it always possible to choose $m(r)$ in such a way that $m$ is continuous, as a function from $[0,\infty)$ to $\Bbb C$? If/when it is the case, has this $m$ any known properties? Is there some theory about this? EDIT: I suspect that the answer to the first question is yes, since the modulus of an entire function can't have any local maxima. But I haven't anything rigorous.","Consider any entire, non constant function $f:\Bbb C\to \Bbb C$. Choose any $z\in\Bbb C$ and define $m(r)\in\overline D(z,r)$, for any $r\ge 0$, with this property: $$|f(m(r))|\ge|f(w)|\;\forall w\in \overline D(z,r)$$ I'm aware that this definition may be ambiguous, since the maximum modulus needn't be met in a single point. I'm also aware that $|m(r)-z|=r$, by the maximum modulus principle. Questions : Is it always possible to choose $m(r)$ in such a way that $m$ is continuous, as a function from $[0,\infty)$ to $\Bbb C$? If/when it is the case, has this $m$ any known properties? Is there some theory about this? EDIT: I suspect that the answer to the first question is yes, since the modulus of an entire function can't have any local maxima. But I haven't anything rigorous.",,['complex-analysis']
85,How do limits work in complex functions?,How do limits work in complex functions?,,"I don't quite understand one example in my notes it says. My query is this: I don't understand what the significance of $\theta$ is. Why does it matter that $\theta \in (-\pi,\pi]$? I see the argument as this, clearly anyway in which we approach $0$ must each give the same limit otherwise the limit doesn't exist since the limit is independent of $w$ the limit only depends on $\theta$ hence for any two distinct values of $\theta$ of which there are infinitely many the limit is different $\implies$ the limit does not exist. Is this correct? Also what is $\theta$ changes as the complex number $w$ approaches zero what is to say we need to approach along a straight line with constant $\theta$? Could anyone clear up my misconceptions? Thanks.","I don't quite understand one example in my notes it says. My query is this: I don't understand what the significance of $\theta$ is. Why does it matter that $\theta \in (-\pi,\pi]$? I see the argument as this, clearly anyway in which we approach $0$ must each give the same limit otherwise the limit doesn't exist since the limit is independent of $w$ the limit only depends on $\theta$ hence for any two distinct values of $\theta$ of which there are infinitely many the limit is different $\implies$ the limit does not exist. Is this correct? Also what is $\theta$ changes as the complex number $w$ approaches zero what is to say we need to approach along a straight line with constant $\theta$? Could anyone clear up my misconceptions? Thanks.",,"['complex-analysis', 'complex-numbers']"
86,Why the complex number system is not an ordered field [duplicate],Why the complex number system is not an ordered field [duplicate],,"This question already has answers here : Total ordering on complex numbers (3 answers) Closed 8 years ago . In high school, we are taught that we do not have $2i < 3i$, i.e., the complex number system is not an ordered field. (Real number, for example, is an ordered field. For example, $2 < 3$). Why? My comment to this is because in the complex corrdinate, in $Re-Im$ coordinate, the concept of complex number is somewhat a rotation around the origin.","This question already has answers here : Total ordering on complex numbers (3 answers) Closed 8 years ago . In high school, we are taught that we do not have $2i < 3i$, i.e., the complex number system is not an ordered field. (Real number, for example, is an ordered field. For example, $2 < 3$). Why? My comment to this is because in the complex corrdinate, in $Re-Im$ coordinate, the concept of complex number is somewhat a rotation around the origin.",,"['complex-analysis', 'field-theory']"
87,"Prove that the equation $az^3-z+b=e^{-z}(z+2)$ has two solutions in the right half-plane $\{z\in\mathbb{C}\,:\,\Re z>0\}$ when $a>0$ and $b>2$.",Prove that the equation  has two solutions in the right half-plane  when  and .,"az^3-z+b=e^{-z}(z+2) \{z\in\mathbb{C}\,:\,\Re z>0\} a>0 b>2","Prove that the equation   $$ az^3-z+b=e^{-z}(z+2) $$   has two solutions in the right half-plane $\{z\in\mathbb{C}\,:\,\Re z>0\}$ when $a>0$ and $b>2$. This is an old qualifying exam question. I'm sure it uses Rouché's theorem somehow, but I can't quite figure it out. From my experience, the way Rouché's theorem works is that you basically create an equation that you know has the right number of zeroes by adding/subtracting terms from your original equation, then compare it to your original. The problem is I can't create an equation which has the number of zeroes I want. The best choice I have is comparing it to $az^3-z+b$, but after I would even show that it has the same number of zeroes as $az^3-z+b-e^{-z}(z+2)$, I would have to somehow justify that $az^3-a+b$ has $2$ zeroes in the right half-plane. I also considered using the conformal map $z\mapsto\frac{1-z}{1+z}$ and working with the unit disk as the domain which I generally find to be easier to work with (as opposed to using some arbitrarily large rectangle), but it doesn't seem to help. Any help is greatly appreciated. Thanks in advance.","Prove that the equation   $$ az^3-z+b=e^{-z}(z+2) $$   has two solutions in the right half-plane $\{z\in\mathbb{C}\,:\,\Re z>0\}$ when $a>0$ and $b>2$. This is an old qualifying exam question. I'm sure it uses Rouché's theorem somehow, but I can't quite figure it out. From my experience, the way Rouché's theorem works is that you basically create an equation that you know has the right number of zeroes by adding/subtracting terms from your original equation, then compare it to your original. The problem is I can't create an equation which has the number of zeroes I want. The best choice I have is comparing it to $az^3-z+b$, but after I would even show that it has the same number of zeroes as $az^3-z+b-e^{-z}(z+2)$, I would have to somehow justify that $az^3-a+b$ has $2$ zeroes in the right half-plane. I also considered using the conformal map $z\mapsto\frac{1-z}{1+z}$ and working with the unit disk as the domain which I generally find to be easier to work with (as opposed to using some arbitrarily large rectangle), but it doesn't seem to help. Any help is greatly appreciated. Thanks in advance.",,"['complex-analysis', 'roots']"
88,Conformal maps onto open right half plane,Conformal maps onto open right half plane,,"On the Big Rudin there is the conformal map $$\varphi(z) = \frac {1+z}{1-z}$$ which sends $\{-1, 0, 1\}$ to $\{0, 1, \infty\}$. The book says: The segment $(-1, 1)$ maps onto the positive real axis. The unit   circle $T$ passes through $-1$ and $1$, hence $\varphi(T)$ is a   straight line passing through $\varphi(-1) = 0$. Since $T$ makes a   right angle in $-1$ with the real axis, $\varphi(T)$ is the imaginary   axis. Up until now it's clear. But then he says: Since $\varphi(0) = 1$, it follows that $\varphi$ is a conformal   one-to-one mapping of the open unit disc onto the open right half   plane. I lost him. Why does all that implies that $\varphi$ maps onto the open right half plane?","On the Big Rudin there is the conformal map $$\varphi(z) = \frac {1+z}{1-z}$$ which sends $\{-1, 0, 1\}$ to $\{0, 1, \infty\}$. The book says: The segment $(-1, 1)$ maps onto the positive real axis. The unit   circle $T$ passes through $-1$ and $1$, hence $\varphi(T)$ is a   straight line passing through $\varphi(-1) = 0$. Since $T$ makes a   right angle in $-1$ with the real axis, $\varphi(T)$ is the imaginary   axis. Up until now it's clear. But then he says: Since $\varphi(0) = 1$, it follows that $\varphi$ is a conformal   one-to-one mapping of the open unit disc onto the open right half   plane. I lost him. Why does all that implies that $\varphi$ maps onto the open right half plane?",,"['complex-analysis', 'analysis', 'conformal-geometry']"
89,Holomorphic function definition. Am I missing something very obvious?,Holomorphic function definition. Am I missing something very obvious?,,"I'm reading a book of complex analysis in which the definition of holomorphic function is given as follows: Definition : If  $V$ is an open set of complex numbers, a function $f:V \to \mathbb C$ is called holomorphic if the first derivative $z \to f'(z)$ is defined and ""continuous"" as a function from $V$ to $\mathbb C$. Can someone please illustrate why do we need the derivative map to be continuous? I know this may be a easy doubt but I am unable to answer this.Thank you for your help !","I'm reading a book of complex analysis in which the definition of holomorphic function is given as follows: Definition : If  $V$ is an open set of complex numbers, a function $f:V \to \mathbb C$ is called holomorphic if the first derivative $z \to f'(z)$ is defined and ""continuous"" as a function from $V$ to $\mathbb C$. Can someone please illustrate why do we need the derivative map to be continuous? I know this may be a easy doubt but I am unable to answer this.Thank you for your help !",,"['complex-analysis', 'definition']"
90,Proving $\int_\mathbb R\frac{\sin(x)}{x}dx = \pi$ using the residue theorem [duplicate],Proving  using the residue theorem [duplicate],\int_\mathbb R\frac{\sin(x)}{x}dx = \pi,"This question already has answers here : Evaluating the integral $\int_0^\infty \frac{\sin x} x \,\mathrm dx = \frac \pi 2$? (32 answers) Closed 6 years ago . I've been searching the web for a way to prove that $\int^{\infty}_{-\infty}{\sin(x)/x} = \pi$ with complex analysis, because I have a problem of consistency. I found two, carried in the following link : Computing $\int_{-\infty}^\infty \frac{\sin x}{x} \mathrm{d}x$ with residue calculus . But then I wanted to find it by using the fact that : $\sin(x)/x = \text{Im}(e^{ix}/x)$ To do so, I shifted the integration by $-i$ in the complex plane, showing that the integral on $[-\infty , \infty]$ is equal to the one on $[-\infty -i, \infty -i]$, since the integrand vanish on the vertical borders of the rectangle when we tend to infinity. I did this to get rid of the pole on the contour of integration. Then, by using the residues theorem on the contour $C_1 : z = y-i, y \in [-R,R]$ and $C_2 : z = Re^{it}-i, t \in [0,\pi]$. Given the integral on $C_2$ vanishes, we have then that : $\int^{\infty}_{-\infty}{\sin(x)/x} = \text{Im}(\int^{\infty}_{-\infty}{e^{ix}/x}) = \text{Im}(2\pi i\,\text{Res}(e^{iz}/z, 0)) = 2 \pi$ Which gives me the answer with a factor of $2$. I don't understand were did I go wrong ? I think it has something to do with the fact that I take the imaginary part of the integral, but I don't really know... Can someone spot my mistake ? If needed, I can provide further detail on my calculations.","This question already has answers here : Evaluating the integral $\int_0^\infty \frac{\sin x} x \,\mathrm dx = \frac \pi 2$? (32 answers) Closed 6 years ago . I've been searching the web for a way to prove that $\int^{\infty}_{-\infty}{\sin(x)/x} = \pi$ with complex analysis, because I have a problem of consistency. I found two, carried in the following link : Computing $\int_{-\infty}^\infty \frac{\sin x}{x} \mathrm{d}x$ with residue calculus . But then I wanted to find it by using the fact that : $\sin(x)/x = \text{Im}(e^{ix}/x)$ To do so, I shifted the integration by $-i$ in the complex plane, showing that the integral on $[-\infty , \infty]$ is equal to the one on $[-\infty -i, \infty -i]$, since the integrand vanish on the vertical borders of the rectangle when we tend to infinity. I did this to get rid of the pole on the contour of integration. Then, by using the residues theorem on the contour $C_1 : z = y-i, y \in [-R,R]$ and $C_2 : z = Re^{it}-i, t \in [0,\pi]$. Given the integral on $C_2$ vanishes, we have then that : $\int^{\infty}_{-\infty}{\sin(x)/x} = \text{Im}(\int^{\infty}_{-\infty}{e^{ix}/x}) = \text{Im}(2\pi i\,\text{Res}(e^{iz}/z, 0)) = 2 \pi$ Which gives me the answer with a factor of $2$. I don't understand were did I go wrong ? I think it has something to do with the fact that I take the imaginary part of the integral, but I don't really know... Can someone spot my mistake ? If needed, I can provide further detail on my calculations.",,"['integration', 'complex-analysis', 'definite-integrals', 'improper-integrals', 'residue-calculus']"
91,Showing that $Q(x)-\frac{6x}{\pi^2}=\Omega_{\pm}(x^{1/4})$,Showing that,Q(x)-\frac{6x}{\pi^2}=\Omega_{\pm}(x^{1/4}),"Let $Q(x)$ denote the number of square-free numbers not exceeding $x$. How can we show that $Q(x)-\frac{6x}{\pi^2}=\Omega_{\pm}(x^{1/4})$, i.e. $$\liminf_{x\to +\infty} \frac{Q(x) - \frac{6x}{\pi^2}}{x^{1/4}} < 0 \qquad\text{and}\qquad \limsup_{x \to +\infty} \frac{Q(x) - \frac{6x}{\pi^2}}{x^{1/4}} > 0\,?$$ The computation \begin{align} Q(x) &= \sum_{k \leqslant \sqrt{x}} \mu(k)\biggl\lfloor \frac{x}{k^2}\biggr\rfloor \\ &= \sum_{k \leqslant \sqrt{x}} \mu(k)\,\frac{x}{k^2} - \sum_{k \leqslant \sqrt{x}} \mu(k)\biggl\lbrace \frac{x}{k^2}\biggr\rbrace \\ &= \frac{6x}{\pi} - x\sum_{k > \sqrt{x}} \frac{\mu(k)}{k^2} - \sum_{k \leqslant \sqrt{x}} \mu(k)\biggl\lbrace \frac{x}{k^2}\biggr\rbrace \end{align} yields $Q(x) - \frac{6x}{\pi^2} = O(\sqrt{x})$ easily, but it is not at all obvious if we can obtain a lower bound on the magnitude of $Q(x) - \frac{6x}{\pi^2}$ from this. How does one go about proving these?","Let $Q(x)$ denote the number of square-free numbers not exceeding $x$. How can we show that $Q(x)-\frac{6x}{\pi^2}=\Omega_{\pm}(x^{1/4})$, i.e. $$\liminf_{x\to +\infty} \frac{Q(x) - \frac{6x}{\pi^2}}{x^{1/4}} < 0 \qquad\text{and}\qquad \limsup_{x \to +\infty} \frac{Q(x) - \frac{6x}{\pi^2}}{x^{1/4}} > 0\,?$$ The computation \begin{align} Q(x) &= \sum_{k \leqslant \sqrt{x}} \mu(k)\biggl\lfloor \frac{x}{k^2}\biggr\rfloor \\ &= \sum_{k \leqslant \sqrt{x}} \mu(k)\,\frac{x}{k^2} - \sum_{k \leqslant \sqrt{x}} \mu(k)\biggl\lbrace \frac{x}{k^2}\biggr\rbrace \\ &= \frac{6x}{\pi} - x\sum_{k > \sqrt{x}} \frac{\mu(k)}{k^2} - \sum_{k \leqslant \sqrt{x}} \mu(k)\biggl\lbrace \frac{x}{k^2}\biggr\rbrace \end{align} yields $Q(x) - \frac{6x}{\pi^2} = O(\sqrt{x})$ easily, but it is not at all obvious if we can obtain a lower bound on the magnitude of $Q(x) - \frac{6x}{\pi^2}$ from this. How does one go about proving these?",,"['complex-analysis', 'analytic-number-theory']"
92,"Image of the upper half complex plane, under the function $g(z) = e^{2\pi i z}$","Image of the upper half complex plane, under the function",g(z) = e^{2\pi i z},"Problem: Given $W = \{z: z=x+iy, \ y>0\}$ and $g(z) = e^{2 \pi i z},$ what does the set $g(W)$ look like, and is it simply connected? Attempt: $W$ represents the upper-half complex plane. And $$g(z) = e^{2 \pi i (x+iy)} = \cdots = e^{-2\pi y}(\cos (2 \pi x) + i \sin (2 \pi x)).$$ (Am I on the right track?) I know simply connected means that there are no holes in the set, but I don't know how to describe the set geometrically. Further attempt: Since $e^{2 \pi i z} = e^{-2 \pi y}(e^{2 \pi i x})$ then $|e^{2 \pi i z}| = |e^{-2 \pi y}|$ and $y>0 \implies |e^{-2 \pi y}| \in (0,1).$ So $|e^{2 \pi i z}| \in (0, e^{2 \pi i x}).$ Right? Thanks in advance for help.","Problem: Given $W = \{z: z=x+iy, \ y>0\}$ and $g(z) = e^{2 \pi i z},$ what does the set $g(W)$ look like, and is it simply connected? Attempt: $W$ represents the upper-half complex plane. And $$g(z) = e^{2 \pi i (x+iy)} = \cdots = e^{-2\pi y}(\cos (2 \pi x) + i \sin (2 \pi x)).$$ (Am I on the right track?) I know simply connected means that there are no holes in the set, but I don't know how to describe the set geometrically. Further attempt: Since $e^{2 \pi i z} = e^{-2 \pi y}(e^{2 \pi i x})$ then $|e^{2 \pi i z}| = |e^{-2 \pi y}|$ and $y>0 \implies |e^{-2 \pi y}| \in (0,1).$ So $|e^{2 \pi i z}| \in (0, e^{2 \pi i x}).$ Right? Thanks in advance for help.",,['complex-analysis']
93,Find the maximum of a |cos(z)|,Find the maximum of a |cos(z)|,,"How do you find the maximum of the complex function $|\cos{z}|$ on $[0,2\pi]\times[0,2\pi]$. I believe I'm to use the maximum modulus principle, since the function is entire. I'm just having problems starting. Any suggestions?","How do you find the maximum of the complex function $|\cos{z}|$ on $[0,2\pi]\times[0,2\pi]$. I believe I'm to use the maximum modulus principle, since the function is entire. I'm just having problems starting. Any suggestions?",,['complex-analysis']
94,Computing the complex integral?,Computing the complex integral?,,"I am dealing with the following: $$\int_{0}^{\infty}\frac{x\sin(x)}{(x^2+a^2)(x^2+b^2)}dx$$ Furthermore, I know $a,b>0$ and I know $a\neq b$. I believe this is using Jordan's Lemma? I see that the singularities in the upper half of the plane are $ai$ and $bi$ where $R>a$. I'm stuck writing out my function of z. I think it should be: $$f(z)=\frac{1}{(z^2+a^2)(z^2+b^2)}.$$ But I do not know how exactly the $x\sin(x)$ numerator comes back into play.","I am dealing with the following: $$\int_{0}^{\infty}\frac{x\sin(x)}{(x^2+a^2)(x^2+b^2)}dx$$ Furthermore, I know $a,b>0$ and I know $a\neq b$. I believe this is using Jordan's Lemma? I see that the singularities in the upper half of the plane are $ai$ and $bi$ where $R>a$. I'm stuck writing out my function of z. I think it should be: $$f(z)=\frac{1}{(z^2+a^2)(z^2+b^2)}.$$ But I do not know how exactly the $x\sin(x)$ numerator comes back into play.",,"['complex-analysis', 'contour-integration']"
95,Complex differential operators,Complex differential operators,,"Consider the differential operators $\dfrac{\partial}{\partial z}$ and $\dfrac{\partial}{\partial \bar{z} }$ defined by $\frac{\partial}{\partial z}  = \frac {1}{2} (\frac{\partial}{\partial x} - \frac{i \partial}{\partial y}$) ; $\frac{\partial}{\partial \bar{z} } = \frac {1}{2} (\frac{\partial}{\partial x} +\frac{i \partial}{\partial y}$). Prove that if $f$ is holomorphic then $\frac{\partial}{\partial \bar{z} } = 0$ . I start like that Proof: let $f$ be a holomorphic function such that $f = u + iv$ meaning $f(x,y) = u(x,y) + iv(x,y)$ so that means $f$ has a first partial derivatives that satisfy the cauchy riemann equations. So i am thinking something like that $\frac{\partial f}{\partial z}  = (\frac{\partial u}{\partial x} + \frac{i \partial v}{\partial x}$) ; $\frac{\partial f}{\partial y } = (\frac{\partial u}{\partial y} +\frac{i \partial v}{\partial y}$) and the cauchy rieman equation is $\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}$ and $\frac{\partial u}{\partial y} =- \frac{\partial v}{\partial x}$. Now i really do not know how to go about this problem, i kept asking what exactly am i looking for here. Help anyone.","Consider the differential operators $\dfrac{\partial}{\partial z}$ and $\dfrac{\partial}{\partial \bar{z} }$ defined by $\frac{\partial}{\partial z}  = \frac {1}{2} (\frac{\partial}{\partial x} - \frac{i \partial}{\partial y}$) ; $\frac{\partial}{\partial \bar{z} } = \frac {1}{2} (\frac{\partial}{\partial x} +\frac{i \partial}{\partial y}$). Prove that if $f$ is holomorphic then $\frac{\partial}{\partial \bar{z} } = 0$ . I start like that Proof: let $f$ be a holomorphic function such that $f = u + iv$ meaning $f(x,y) = u(x,y) + iv(x,y)$ so that means $f$ has a first partial derivatives that satisfy the cauchy riemann equations. So i am thinking something like that $\frac{\partial f}{\partial z}  = (\frac{\partial u}{\partial x} + \frac{i \partial v}{\partial x}$) ; $\frac{\partial f}{\partial y } = (\frac{\partial u}{\partial y} +\frac{i \partial v}{\partial y}$) and the cauchy rieman equation is $\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}$ and $\frac{\partial u}{\partial y} =- \frac{\partial v}{\partial x}$. Now i really do not know how to go about this problem, i kept asking what exactly am i looking for here. Help anyone.",,"['complex-analysis', 'differential-operators']"
96,integral of harmonic function,integral of harmonic function,,"I'm having trouble with this one: Let $u$ be a real-valued harmonic function on $D(0,1)$, and let $\gamma$ be a closed curve in that disk. Then $\int_\gamma u=0.$ I'm supposed to prove or disprove this statement. I'm inclined to believe it's true. What I have so far is: Since $u$ is real-valued and harmonic, there exists a harmonic function $v$ such that $f=u+iv$ is holomorphic on $D(0,1)$. Now since $\gamma$ is a closed curve in $D(0,1)$ it follows that $\int_\gamma f=\int_\gamma(u+iv)=0$. I don't know what to do from here, I don't think I can conclude that $\int_\gamma u=0$ just from this last part.","I'm having trouble with this one: Let $u$ be a real-valued harmonic function on $D(0,1)$, and let $\gamma$ be a closed curve in that disk. Then $\int_\gamma u=0.$ I'm supposed to prove or disprove this statement. I'm inclined to believe it's true. What I have so far is: Since $u$ is real-valued and harmonic, there exists a harmonic function $v$ such that $f=u+iv$ is holomorphic on $D(0,1)$. Now since $\gamma$ is a closed curve in $D(0,1)$ it follows that $\int_\gamma f=\int_\gamma(u+iv)=0$. I don't know what to do from here, I don't think I can conclude that $\int_\gamma u=0$ just from this last part.",,['complex-analysis']
97,What are the zeros of the j-function?,What are the zeros of the j-function?,,"Recall that, for a complex number $\tau$ with positive imaginary part, the $j$-invariant is given by $j(\tau)=1728 \frac{g_2(\tau)^3}{g_2(\tau)^3-27g_3(\tau)^2}$ where $g_2(\tau)=60 \sum_{(m,n)\neq(0,0)}(m+n\tau)^{-4}$ and $g_3$ is unimportant. Clearly the zeros of $j$ are the same as the zeros of $g_2$ (and, if we are only considering the zeros, we can forget about the 60 and just consider the sum.) Is there a way to directly see that $g_2(\rho)=0$, where $\rho=exp(\frac{2}{3} \pi i)$? (e.g. is there an algebraic trick to see that the terms in the sum cancel each other out?) If not is there a reasonably simple indirect proof?","Recall that, for a complex number $\tau$ with positive imaginary part, the $j$-invariant is given by $j(\tau)=1728 \frac{g_2(\tau)^3}{g_2(\tau)^3-27g_3(\tau)^2}$ where $g_2(\tau)=60 \sum_{(m,n)\neq(0,0)}(m+n\tau)^{-4}$ and $g_3$ is unimportant. Clearly the zeros of $j$ are the same as the zeros of $g_2$ (and, if we are only considering the zeros, we can forget about the 60 and just consider the sum.) Is there a way to directly see that $g_2(\rho)=0$, where $\rho=exp(\frac{2}{3} \pi i)$? (e.g. is there an algebraic trick to see that the terms in the sum cancel each other out?) If not is there a reasonably simple indirect proof?",,"['complex-analysis', 'elliptic-curves', 'modular-forms']"
98,Showing $iz+\sqrt{1-z^2}$ has positive real part,Showing  has positive real part,iz+\sqrt{1-z^2},"Claim: for all $z\in\Bbb C$, $\Re[iz+\sqrt{1-z^2}]\ge0$. Note that this square root function has its branch cut defined to take the square root with positive real part when one is available, or nonnegative imaginary part if both solutions are pure imaginary. The claim is false on the other branch, so this is important. This problem comes up in the course of finding basic properties of the arcsin function via its definition in terms of $\log$, namely $\arcsin z=-i\log(iz+\sqrt{1-z^2})$, and it was verified ""by inspection"" in Mathematica by graphing it. The problem is of course reducible to $\Re[\sqrt{1-z^2}]\ge\Im[z]$ or $\Re[\sqrt{1-(x+iy)^2}]\ge y$ (switching $z\mapsto -z$ to get rid of the extra sign), but beyond this requires more detailed information on the behavior of the complex square root function. If $1-z^2$ is a nonpositive real, then $z=x$ for some real $|x|\ge1$, in which case the expression reduces to $0\ge0$, because $\Im[z]=0$ and $\sqrt{1-x^2}$ is pure imaginary. Otherwise, we can use the following expansion for $\sqrt z$, which is valid when $|z|\ne-z$, i.e. $z$ is not a nonpositive real: $$\sqrt z=\sqrt{|z|}\frac{|z|+z}{||z|+z|}.$$ Plugging in $z=1-(x+iy)^2$ to this expression, we get $$\Re[\sqrt{1-(x+iy)^2}]=\frac{\sqrt{\alpha}(\alpha+x)}{\sqrt{1+2\alpha x-x^2+x^4+3y^2+2x^2y^2+y^4}},$$ where $\alpha=\sqrt{(2xy)^2+(1-x^2+y^2)^2}$, and this expansion includes only square roots of positive real numbers. Then the claim is that this expression is greater than $-y$. I'll stop here, since the algebra only gets worse from here and I'm not certain I haven't made the original expression unnecessarily complicated. What is a nice way to derive the Claim? More solution progress: We can assume that $x,y\ge0$, because the stronger equation $\Re[\sqrt{1-(x+iy)^2}]\ge|y|$ (with $|y|$ replacing $y$) is symmetric with respect to both $x\mapsto -x$ and $y\mapsto -y$, and reduces to the original equation when $y\ge0$. (To see the $x,y$ symmetries, note that $\Re[\sqrt{1-z^2}]=\Re[\sqrt{1-(-z)^2}]$, and we also have $\Re[\sqrt{1-\bar z^2}]=\Re[\overline{\sqrt{1-z^2}}]=\Re[\sqrt{1-z^2}]$ assuming $1-z^2$ is not a nonpositive real, which we have already dealt with above.) Then since all the terms are manifestly nonnegative (except possibly the $-x^2$ term in the denominator, but this is not a problem since $1-x^2+x^4\ge0$) we can feel free to cross-multiply and square: $$\frac{\sqrt{\alpha}(\alpha+x)}{\sqrt{1+2\alpha x-x^2+x^4+3y^2+2x^2y^2+y^4}}\ge y\iff$$ $$\sqrt{\alpha}(\alpha+x)\ge y\sqrt{1+2\alpha x-x^2+x^4+3y^2+2x^2y^2+y^4}\iff$$ $$\alpha^3+2\alpha^2 x+\alpha x^2\ge y^2(1+2\alpha x-x^2+x^4+3y^2+2x^2y^2+y^4)\iff$$ $$\overbrace{2x^5 - x^4y^2 + 4x^3 (y^2-1) + 2 x (y^2+1)^2 +   x^2 (y^2-2y^4) - y^2 (y^4+3y^2+1)}^u +   \alpha \overbrace{(x^4 - 2 x y^2 + (1 + y^2)^2 + x^2 (2 y^2-1))}^v\ge0$$ Now at this stage, I would like to rewrite the equation as $u\ge -\alpha v$ so I can square it, but unfortunately the terms are not nonnegative any longer. However, $v\ge0$ appears to hold for all $x,y\ge0$ (proof by graphing), so it suffices to prove $u^2\le\alpha^2v^2$ for all $u\le0$: $$u^2\le((2xy)^2+(1-x^2+y^2)^2)v^2\iff$$ $$1 + x^{12} + 6 y^2 + 2 x^9 y^2 + 14 y^4 + 14 y^6 + 4 y^8 +   x^{10} (-9 + 6 y^2) +\\ 2 x (y + y^3)^2 (1 + 4 y^2 + y^4) +   x^7 (-4 y^2 + 8 y^4) + x^8 (27 - 30 y^2 + 14 y^4) +\\  4 x^3 y^2 (-1 - 2 y^2 + 5 y^4 + 2 y^6) + 4 x^5 (y^2 + y^4 + 3 y^6) +   2 x^6 (-19 + 12 y^2 - 14 y^4 + 8 y^6) +\\  x^4 (27 + 24 y^2 - 21 y^4 - 2 y^6 + 9 y^8) +   x^2 (-9 - 30 y^2 - 28 y^4 + 2 y^6 + 5 y^8 + 2 y^{10})\ge0$$ $$\mbox{when}\quad 2x^5 - x^4y^2 + 4x^3 (y^2-1) + 2 x (y^2+1)^2 +   x^2 (y^2-2y^4) - y^2 (y^4+3y^2+1)\le0.$$ Now it is finally a pure polynomial inequality. However, it is now a total mess, considering that the original problem doesn't seem like it should get this ugly, and this is some kind of polynomial optimization problem that I have no idea how to solve.","Claim: for all $z\in\Bbb C$, $\Re[iz+\sqrt{1-z^2}]\ge0$. Note that this square root function has its branch cut defined to take the square root with positive real part when one is available, or nonnegative imaginary part if both solutions are pure imaginary. The claim is false on the other branch, so this is important. This problem comes up in the course of finding basic properties of the arcsin function via its definition in terms of $\log$, namely $\arcsin z=-i\log(iz+\sqrt{1-z^2})$, and it was verified ""by inspection"" in Mathematica by graphing it. The problem is of course reducible to $\Re[\sqrt{1-z^2}]\ge\Im[z]$ or $\Re[\sqrt{1-(x+iy)^2}]\ge y$ (switching $z\mapsto -z$ to get rid of the extra sign), but beyond this requires more detailed information on the behavior of the complex square root function. If $1-z^2$ is a nonpositive real, then $z=x$ for some real $|x|\ge1$, in which case the expression reduces to $0\ge0$, because $\Im[z]=0$ and $\sqrt{1-x^2}$ is pure imaginary. Otherwise, we can use the following expansion for $\sqrt z$, which is valid when $|z|\ne-z$, i.e. $z$ is not a nonpositive real: $$\sqrt z=\sqrt{|z|}\frac{|z|+z}{||z|+z|}.$$ Plugging in $z=1-(x+iy)^2$ to this expression, we get $$\Re[\sqrt{1-(x+iy)^2}]=\frac{\sqrt{\alpha}(\alpha+x)}{\sqrt{1+2\alpha x-x^2+x^4+3y^2+2x^2y^2+y^4}},$$ where $\alpha=\sqrt{(2xy)^2+(1-x^2+y^2)^2}$, and this expansion includes only square roots of positive real numbers. Then the claim is that this expression is greater than $-y$. I'll stop here, since the algebra only gets worse from here and I'm not certain I haven't made the original expression unnecessarily complicated. What is a nice way to derive the Claim? More solution progress: We can assume that $x,y\ge0$, because the stronger equation $\Re[\sqrt{1-(x+iy)^2}]\ge|y|$ (with $|y|$ replacing $y$) is symmetric with respect to both $x\mapsto -x$ and $y\mapsto -y$, and reduces to the original equation when $y\ge0$. (To see the $x,y$ symmetries, note that $\Re[\sqrt{1-z^2}]=\Re[\sqrt{1-(-z)^2}]$, and we also have $\Re[\sqrt{1-\bar z^2}]=\Re[\overline{\sqrt{1-z^2}}]=\Re[\sqrt{1-z^2}]$ assuming $1-z^2$ is not a nonpositive real, which we have already dealt with above.) Then since all the terms are manifestly nonnegative (except possibly the $-x^2$ term in the denominator, but this is not a problem since $1-x^2+x^4\ge0$) we can feel free to cross-multiply and square: $$\frac{\sqrt{\alpha}(\alpha+x)}{\sqrt{1+2\alpha x-x^2+x^4+3y^2+2x^2y^2+y^4}}\ge y\iff$$ $$\sqrt{\alpha}(\alpha+x)\ge y\sqrt{1+2\alpha x-x^2+x^4+3y^2+2x^2y^2+y^4}\iff$$ $$\alpha^3+2\alpha^2 x+\alpha x^2\ge y^2(1+2\alpha x-x^2+x^4+3y^2+2x^2y^2+y^4)\iff$$ $$\overbrace{2x^5 - x^4y^2 + 4x^3 (y^2-1) + 2 x (y^2+1)^2 +   x^2 (y^2-2y^4) - y^2 (y^4+3y^2+1)}^u +   \alpha \overbrace{(x^4 - 2 x y^2 + (1 + y^2)^2 + x^2 (2 y^2-1))}^v\ge0$$ Now at this stage, I would like to rewrite the equation as $u\ge -\alpha v$ so I can square it, but unfortunately the terms are not nonnegative any longer. However, $v\ge0$ appears to hold for all $x,y\ge0$ (proof by graphing), so it suffices to prove $u^2\le\alpha^2v^2$ for all $u\le0$: $$u^2\le((2xy)^2+(1-x^2+y^2)^2)v^2\iff$$ $$1 + x^{12} + 6 y^2 + 2 x^9 y^2 + 14 y^4 + 14 y^6 + 4 y^8 +   x^{10} (-9 + 6 y^2) +\\ 2 x (y + y^3)^2 (1 + 4 y^2 + y^4) +   x^7 (-4 y^2 + 8 y^4) + x^8 (27 - 30 y^2 + 14 y^4) +\\  4 x^3 y^2 (-1 - 2 y^2 + 5 y^4 + 2 y^6) + 4 x^5 (y^2 + y^4 + 3 y^6) +   2 x^6 (-19 + 12 y^2 - 14 y^4 + 8 y^6) +\\  x^4 (27 + 24 y^2 - 21 y^4 - 2 y^6 + 9 y^8) +   x^2 (-9 - 30 y^2 - 28 y^4 + 2 y^6 + 5 y^8 + 2 y^{10})\ge0$$ $$\mbox{when}\quad 2x^5 - x^4y^2 + 4x^3 (y^2-1) + 2 x (y^2+1)^2 +   x^2 (y^2-2y^4) - y^2 (y^4+3y^2+1)\le0.$$ Now it is finally a pure polynomial inequality. However, it is now a total mess, considering that the original problem doesn't seem like it should get this ugly, and this is some kind of polynomial optimization problem that I have no idea how to solve.",,"['complex-analysis', 'algebra-precalculus']"
99,Chain rule in several complex variables: Wirtinger derivatives,Chain rule in several complex variables: Wirtinger derivatives,,"Let $\Omega,\Omega'\subseteq\Bbb C^n$ open, $F:\Omega\to\Omega'$ holomorphic invertible function; it's a variable change, so let's call $F(z)=\tilde z$. Let $r:\Omega\to\Bbb R$ twice differentiable, and $\tilde r:\Omega'\to\Bbb R$ such that $r=\tilde r\circ F$. Now we want to differentiate $r=\tilde r\circ F$. To be precise we want to compute $$ \partial_{z_h}\partial_{\bar{z_k}}(\tilde r\circ F)\;\;. $$ First of all I should compute $\partial_{\bar{z_k}}(\tilde r\circ F)$. Now I'd use the chain rule to get $$ \partial_{\bar{z_k}}(\tilde r\circ F)(z)= \nabla\tilde r(\tilde z)\cdot\partial_{\bar{z_k}}\tilde z= \sum_{i=1}^{n}\partial_{\widetilde{z_i}}\tilde{r}(\tilde z)\partial_{\bar{z_k}}\tilde z_i $$ but the book says that $$ \partial_{\bar{z_k}}(\tilde r\circ F)(z)= \sum_{i=1}^{n}\partial_{\widetilde{z_i}}\tilde{r}(\tilde z)\partial_{\bar{z_k}}\tilde z_i+ \sum_{i=1}^{n}\partial_{\bar{\widetilde{z_i}}}\tilde{r}(\tilde z)\overline{\partial_{{z_k}}\tilde z_i}\;\; $$ so I missed the second sum. I suspect the fact that $df=\partial f+\bar{\partial}f$ and $df=2\Re\partial f$ are taken in account but I can't put all the pieces togheter. (from this, I think it should be easy to compute the second derivative). EDIT As suggested by the user mrf, this computation is simply a Wirtinger derivative. However I don't know nothing about this and I wasn't able to find anything on internet or on the Ahlfors. I really want (and need) to understand how these basic real/complex differential operators behaves, how do they work. Can someone suggest me an appropriate reference? Many thanks!","Let $\Omega,\Omega'\subseteq\Bbb C^n$ open, $F:\Omega\to\Omega'$ holomorphic invertible function; it's a variable change, so let's call $F(z)=\tilde z$. Let $r:\Omega\to\Bbb R$ twice differentiable, and $\tilde r:\Omega'\to\Bbb R$ such that $r=\tilde r\circ F$. Now we want to differentiate $r=\tilde r\circ F$. To be precise we want to compute $$ \partial_{z_h}\partial_{\bar{z_k}}(\tilde r\circ F)\;\;. $$ First of all I should compute $\partial_{\bar{z_k}}(\tilde r\circ F)$. Now I'd use the chain rule to get $$ \partial_{\bar{z_k}}(\tilde r\circ F)(z)= \nabla\tilde r(\tilde z)\cdot\partial_{\bar{z_k}}\tilde z= \sum_{i=1}^{n}\partial_{\widetilde{z_i}}\tilde{r}(\tilde z)\partial_{\bar{z_k}}\tilde z_i $$ but the book says that $$ \partial_{\bar{z_k}}(\tilde r\circ F)(z)= \sum_{i=1}^{n}\partial_{\widetilde{z_i}}\tilde{r}(\tilde z)\partial_{\bar{z_k}}\tilde z_i+ \sum_{i=1}^{n}\partial_{\bar{\widetilde{z_i}}}\tilde{r}(\tilde z)\overline{\partial_{{z_k}}\tilde z_i}\;\; $$ so I missed the second sum. I suspect the fact that $df=\partial f+\bar{\partial}f$ and $df=2\Re\partial f$ are taken in account but I can't put all the pieces togheter. (from this, I think it should be easy to compute the second derivative). EDIT As suggested by the user mrf, this computation is simply a Wirtinger derivative. However I don't know nothing about this and I wasn't able to find anything on internet or on the Ahlfors. I really want (and need) to understand how these basic real/complex differential operators behaves, how do they work. Can someone suggest me an appropriate reference? Many thanks!",,"['complex-analysis', 'reference-request', 'several-complex-variables']"
