,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Calculate the area of a $N \times N$ grid using a $2D$ random walk.,Calculate the area of a  grid using a  random walk.,N \times N 2D,"Is there a formula to determine the approx. steps needed to calculate the area of a $N \times N$ grid? Suppose we have a discrete random walk on $\mathbb{Z}^2$ starting at $(0,0)$ and each ""step"" is determined by adding one of the vectors $(1,0), (−1,0), (0,1), (0,−1)$ . The walk continues in the same manner for many steps and cannot step outside its boundary edges or corners. Anytime the walk completes a unit square perimeter, it's added to the total area so far. This walk continues until every unit square has been completed. As the comment section noted, this is equivalent to walking every segment. Example A random walk on a $150\times150$ grid in progress... EDIT Finally wrote a C program to traverse $N \times N$ grids. For example, the $10 \times 10$ grid is iterated $100$ times and the average steps taken. 10x10 Grid, Total Steps: 2455 10x10 Grid, Total Steps: 2206 10x10 Grid, Total Steps: 1872 10x10 Grid, Total Steps: 2390 10x10 Grid, Total Steps: 2044 10x10 Grid, Total Steps: 2411 10x10 Grid, Total Steps: 2976 10x10 Grid, Total Steps: 2718 10x10 Grid, Total Steps: 2669 10x10 Grid, Total Steps: 3641 10x10 Grid, Total Steps: 1879 10x10 Grid, Total Steps: 2288 10x10 Grid, Total Steps: 1906 10x10 Grid, Total Steps: 1688 10x10 Grid, Total Steps: 1857 10x10 Grid, Total Steps: 2571 10x10 Grid, Total Steps: 3085 10x10 Grid, Total Steps: 2274 10x10 Grid, Total Steps: 3288 10x10 Grid, Total Steps: 2096 10x10 Grid, Total Steps: 2415 10x10 Grid, Total Steps: 1850 10x10 Grid, Total Steps: 2113 10x10 Grid, Total Steps: 1926 10x10 Grid, Total Steps: 3149 10x10 Grid, Total Steps: 2189 10x10 Grid, Total Steps: 1873 10x10 Grid, Total Steps: 1662 10x10 Grid, Total Steps: 3776 10x10 Grid, Total Steps: 3109 10x10 Grid, Total Steps: 1723 10x10 Grid, Total Steps: 2088 10x10 Grid, Total Steps: 2726 10x10 Grid, Total Steps: 1897 10x10 Grid, Total Steps: 1935 10x10 Grid, Total Steps: 1719 10x10 Grid, Total Steps: 2358 10x10 Grid, Total Steps: 2501 10x10 Grid, Total Steps: 3118 10x10 Grid, Total Steps: 2870 10x10 Grid, Total Steps: 2459 10x10 Grid, Total Steps: 3090 10x10 Grid, Total Steps: 1862 10x10 Grid, Total Steps: 2370 10x10 Grid, Total Steps: 1905 10x10 Grid, Total Steps: 2063 10x10 Grid, Total Steps: 2255 10x10 Grid, Total Steps: 2484 10x10 Grid, Total Steps: 2861 10x10 Grid, Total Steps: 1535 10x10 Grid, Total Steps: 2026 10x10 Grid, Total Steps: 3210 10x10 Grid, Total Steps: 3116 10x10 Grid, Total Steps: 2013 10x10 Grid, Total Steps: 2204 10x10 Grid, Total Steps: 1668 10x10 Grid, Total Steps: 1614 10x10 Grid, Total Steps: 2347 10x10 Grid, Total Steps: 2694 10x10 Grid, Total Steps: 4518 10x10 Grid, Total Steps: 2213 10x10 Grid, Total Steps: 3105 10x10 Grid, Total Steps: 2483 10x10 Grid, Total Steps: 1900 10x10 Grid, Total Steps: 2732 10x10 Grid, Total Steps: 3267 10x10 Grid, Total Steps: 2392 10x10 Grid, Total Steps: 2540 10x10 Grid, Total Steps: 2805 10x10 Grid, Total Steps: 2872 10x10 Grid, Total Steps: 5039 10x10 Grid, Total Steps: 3851 10x10 Grid, Total Steps: 2909 10x10 Grid, Total Steps: 2081 10x10 Grid, Total Steps: 2621 10x10 Grid, Total Steps: 2561 10x10 Grid, Total Steps: 2296 10x10 Grid, Total Steps: 1655 10x10 Grid, Total Steps: 3922 10x10 Grid, Total Steps: 3123 10x10 Grid, Total Steps: 4437 10x10 Grid, Total Steps: 2631 10x10 Grid, Total Steps: 2175 10x10 Grid, Total Steps: 2606 10x10 Grid, Total Steps: 2214 10x10 Grid, Total Steps: 2831 10x10 Grid, Total Steps: 2565 10x10 Grid, Total Steps: 3157 10x10 Grid, Total Steps: 2268 10x10 Grid, Total Steps: 1704 10x10 Grid, Total Steps: 2817 10x10 Grid, Total Steps: 2695 10x10 Grid, Total Steps: 2102 10x10 Grid, Total Steps: 4982 10x10 Grid, Total Steps: 2618 10x10 Grid, Total Steps: 2219 10x10 Grid, Total Steps: 4198 10x10 Grid, Total Steps: 3987 10x10 Grid, Total Steps: 1868 10x10 Grid, Total Steps: 2375 10x10 Grid, Average Steps: 2564 Similar grid and graph results follow: 10x10   Grid, Average Steps: 2564 20x20   Grid, Average Steps: 13829 30x30   Grid, Average Steps: 34849 40x40   Grid, Average Steps: 69704 50x50   Grid, Average Steps: 112535 60x60   Grid, Average Steps: 178182 70x70   Grid, Average Steps: 249028 80x80   Grid, Average Steps: 354800 90x90   Grid, Average Steps: 456223 100x100 Grid, Average Steps: 575570 QUESTION Given an $N \times N$ grid, is there a way to devise a formula to find the approx. number of random steps needed to compute its area based upon these program results? Maybe a Lagrange Interpolating Polynomial like this: $f(x) = \\ \begin{array}{c}  \frac{31381 x^9}{8640000000000}-\frac{1427173 x^8}{806400000000}+\frac{1549913 x^7}{4200000000}-\frac{123941687 x^6}{2880000000}+\frac{886369883 x^5}{288000000}-\frac{1602458819 x^4}{11520000}+\frac{17031670657 x^3}{4320000}-\frac{67368570503 x^2}{1008000}+\frac{1020468443 x}{1680}-2208005 \end{array}$ Thanks. // Calculate the area of a N×N grid using a 2D random walk.  #include <stdio.h> #include <stdbool.h> #include <stdlib.h> #include <time.h> #include <random>  unsigned int GRID_SIZE; std::minstd_rand simple_rand;  typedef struct {     int xF;     int yF;     int xT;     int yT; } FromTo;   typedef struct {     FromTo FT;     bool walked; } segment;  int xFrom, yFrom, xTo, yTo;  segment* xPaths[1000]; segment* yPaths[1000];   void PathsCheck(segment** Paths) {     int i=0, j=0;     segment* Segments;      for (i = 0; i < GRID_SIZE; i++)     {         Segments = Paths[i];          for (j = 0; j < GRID_SIZE; j++)         {             // Check for reversible walks {(0,0),(1,0)} or {(1,0),(0,0)}             if ((((Segments[j].FT.xF == xFrom) && (Segments[j].FT.yF == yFrom)) &&                 ((Segments[j].FT.xT == xTo) && (Segments[j].FT.yT == yTo))) ||                 (((Segments[j].FT.xT == xFrom) && (Segments[j].FT.yT == yFrom)) &&                 ((Segments[j].FT.xF == xTo) && (Segments[j].FT.yF == yTo))))             {                                 Segments[j].walked = true;                 return;             }         }     } }   int PathsStats(segment** Paths) {     int i = 0, j = 0, segmentsTraversed = 0;     segment* Segments;      for (i = 0; i < GRID_SIZE; i++)     {         Segments = Paths[i];          for (j = 0; j < (GRID_SIZE - 1); j++)         {             if (Segments[j].walked)             {                 segmentsTraversed++;             }         }     }      return segmentsTraversed; }   void GenerateRandomWalk(void) {     // (0,3) (1,3) (2,3) (3,3)      // (0,2) (1,2) (2,2) (3,2)      // (0,1) (1,1) (2,1) (3,1)      // (0,0) (1,0) (2,0) (3,0)      xFrom = xTo;     yFrom = yTo;      do     {         switch (simple_rand() % 4)         {         case 0: if (yTo != (GRID_SIZE - 1)) yTo++; break; // up                     case 1: if (yTo != 0) yTo--; break;               // down                     case 2: if (xTo != 0) xTo--; break;               // left                     case 3: if (xTo != (GRID_SIZE - 1)) xTo++; break; // right         }     } while ((xFrom == xTo) && (yFrom == yTo)); }   void CreateXsegments(void) {     int x, y, i=0, j;     segment* xSegments;      // xSegments[0] = {(0,3),(1,3)} {(1,3),(2,3)} {(2,3),(3,3)}     // xSegments[1] = {(0,2),(1,2)} {(1,2),(2,2)} {(2,2),(3,2)}     // xSegments[2] = {(0,1),(1,1)} {(1,1),(2,1)} {(2,1),(3,1)}     // xSegments[3] = {(0,0),(1,0)} {(1,0),(2,0)} {(2,0),(3,0)}      for (y = (GRID_SIZE - 1); y >= 0; y--)     {         xSegments = (segment*)malloc((GRID_SIZE - 1) * sizeof(segment));         if (!xSegments)         {             exit(-1);         }                      xPaths[i++] = xSegments;          j = 0;          for (x = 0; x < (GRID_SIZE - 1); x++)         {             xSegments[j++] = { {x,y,x + 1,y},false };         }     } }   void CreateYsegments(void) {     int x, y, i = 0, j;     segment* ySegments;      // ySegments[0] = {(0,3),(0,2)} {(0,2),(0,1)} {(0,1),(0,0)}     // ySegments[1] = {(1,3),(1,2)} {(1,2),(1,1)} {(1,1),(1,0)}     // ySegments[2] = {(2,3),(2,2)} {(2,2),(2,1)} {(2,1),(2,0)}     // ySegments[3] = {(3,3),(3,2)} {(3,2),(3,1)} {(3,1),(3,0)}      for (x = 0; x < GRID_SIZE; x++)     {         ySegments = (segment*)malloc((GRID_SIZE - 1) * sizeof(segment));          if (!ySegments)         {             exit(-1);         }          yPaths[i++] = ySegments;          j = 0;          for (y = (GRID_SIZE - 1); y > 0; y--)         {             ySegments[j++] = {{x,y,x,y - 1},false};         }     } }   int main(int argc, char *argv[]) {     int WalksDone;     int xWalks, yWalks;     int TotalSteps, AvgSteps;     int ctr,ctrmax=102,avg,avgmax=100;      simple_rand.seed((unsigned int)time(0));      // Compute Grids 10x10, 20x20, ... ,100x100      for (ctr = 11; ctr < ctrmax; ctr += 10)     {         AvgSteps = 0;          for (avg = 0; avg < avgmax; avg++)         {             GRID_SIZE = ctr;             WalksDone = (GRID_SIZE * (GRID_SIZE - 1));              TotalSteps = 0;              xWalks = yWalks = 0;             xFrom = yFrom = xTo = yTo = 0;              CreateXsegments();             CreateYsegments();              do             {                 TotalSteps++;                  GenerateRandomWalk();                  if (xWalks != WalksDone)                 {                     PathsCheck(xPaths);                     xWalks = PathsStats(xPaths);                 }                 if (yWalks != WalksDone)                 {                     PathsCheck(yPaths);                     yWalks = PathsStats(yPaths);                 }              } while ((xWalks != WalksDone) || (yWalks != WalksDone));              printf(""%ux%u Grid, Total Steps: %d\n"", GRID_SIZE - 1, GRID_SIZE - 1, TotalSteps);              AvgSteps += TotalSteps;              // Release memory....             for (int i = 0; i < GRID_SIZE; i++)             {                 free(xPaths[i]); xPaths[i] = NULL;                 free(yPaths[i]); yPaths[i] = NULL;             }         }          printf(""%ux%u Grid, Average Steps: %d\n"", GRID_SIZE - 1, GRID_SIZE - 1, AvgSteps/avgmax);     }      return 0; }","Is there a formula to determine the approx. steps needed to calculate the area of a grid? Suppose we have a discrete random walk on starting at and each ""step"" is determined by adding one of the vectors . The walk continues in the same manner for many steps and cannot step outside its boundary edges or corners. Anytime the walk completes a unit square perimeter, it's added to the total area so far. This walk continues until every unit square has been completed. As the comment section noted, this is equivalent to walking every segment. Example A random walk on a grid in progress... EDIT Finally wrote a C program to traverse grids. For example, the grid is iterated times and the average steps taken. 10x10 Grid, Total Steps: 2455 10x10 Grid, Total Steps: 2206 10x10 Grid, Total Steps: 1872 10x10 Grid, Total Steps: 2390 10x10 Grid, Total Steps: 2044 10x10 Grid, Total Steps: 2411 10x10 Grid, Total Steps: 2976 10x10 Grid, Total Steps: 2718 10x10 Grid, Total Steps: 2669 10x10 Grid, Total Steps: 3641 10x10 Grid, Total Steps: 1879 10x10 Grid, Total Steps: 2288 10x10 Grid, Total Steps: 1906 10x10 Grid, Total Steps: 1688 10x10 Grid, Total Steps: 1857 10x10 Grid, Total Steps: 2571 10x10 Grid, Total Steps: 3085 10x10 Grid, Total Steps: 2274 10x10 Grid, Total Steps: 3288 10x10 Grid, Total Steps: 2096 10x10 Grid, Total Steps: 2415 10x10 Grid, Total Steps: 1850 10x10 Grid, Total Steps: 2113 10x10 Grid, Total Steps: 1926 10x10 Grid, Total Steps: 3149 10x10 Grid, Total Steps: 2189 10x10 Grid, Total Steps: 1873 10x10 Grid, Total Steps: 1662 10x10 Grid, Total Steps: 3776 10x10 Grid, Total Steps: 3109 10x10 Grid, Total Steps: 1723 10x10 Grid, Total Steps: 2088 10x10 Grid, Total Steps: 2726 10x10 Grid, Total Steps: 1897 10x10 Grid, Total Steps: 1935 10x10 Grid, Total Steps: 1719 10x10 Grid, Total Steps: 2358 10x10 Grid, Total Steps: 2501 10x10 Grid, Total Steps: 3118 10x10 Grid, Total Steps: 2870 10x10 Grid, Total Steps: 2459 10x10 Grid, Total Steps: 3090 10x10 Grid, Total Steps: 1862 10x10 Grid, Total Steps: 2370 10x10 Grid, Total Steps: 1905 10x10 Grid, Total Steps: 2063 10x10 Grid, Total Steps: 2255 10x10 Grid, Total Steps: 2484 10x10 Grid, Total Steps: 2861 10x10 Grid, Total Steps: 1535 10x10 Grid, Total Steps: 2026 10x10 Grid, Total Steps: 3210 10x10 Grid, Total Steps: 3116 10x10 Grid, Total Steps: 2013 10x10 Grid, Total Steps: 2204 10x10 Grid, Total Steps: 1668 10x10 Grid, Total Steps: 1614 10x10 Grid, Total Steps: 2347 10x10 Grid, Total Steps: 2694 10x10 Grid, Total Steps: 4518 10x10 Grid, Total Steps: 2213 10x10 Grid, Total Steps: 3105 10x10 Grid, Total Steps: 2483 10x10 Grid, Total Steps: 1900 10x10 Grid, Total Steps: 2732 10x10 Grid, Total Steps: 3267 10x10 Grid, Total Steps: 2392 10x10 Grid, Total Steps: 2540 10x10 Grid, Total Steps: 2805 10x10 Grid, Total Steps: 2872 10x10 Grid, Total Steps: 5039 10x10 Grid, Total Steps: 3851 10x10 Grid, Total Steps: 2909 10x10 Grid, Total Steps: 2081 10x10 Grid, Total Steps: 2621 10x10 Grid, Total Steps: 2561 10x10 Grid, Total Steps: 2296 10x10 Grid, Total Steps: 1655 10x10 Grid, Total Steps: 3922 10x10 Grid, Total Steps: 3123 10x10 Grid, Total Steps: 4437 10x10 Grid, Total Steps: 2631 10x10 Grid, Total Steps: 2175 10x10 Grid, Total Steps: 2606 10x10 Grid, Total Steps: 2214 10x10 Grid, Total Steps: 2831 10x10 Grid, Total Steps: 2565 10x10 Grid, Total Steps: 3157 10x10 Grid, Total Steps: 2268 10x10 Grid, Total Steps: 1704 10x10 Grid, Total Steps: 2817 10x10 Grid, Total Steps: 2695 10x10 Grid, Total Steps: 2102 10x10 Grid, Total Steps: 4982 10x10 Grid, Total Steps: 2618 10x10 Grid, Total Steps: 2219 10x10 Grid, Total Steps: 4198 10x10 Grid, Total Steps: 3987 10x10 Grid, Total Steps: 1868 10x10 Grid, Total Steps: 2375 10x10 Grid, Average Steps: 2564 Similar grid and graph results follow: 10x10   Grid, Average Steps: 2564 20x20   Grid, Average Steps: 13829 30x30   Grid, Average Steps: 34849 40x40   Grid, Average Steps: 69704 50x50   Grid, Average Steps: 112535 60x60   Grid, Average Steps: 178182 70x70   Grid, Average Steps: 249028 80x80   Grid, Average Steps: 354800 90x90   Grid, Average Steps: 456223 100x100 Grid, Average Steps: 575570 QUESTION Given an grid, is there a way to devise a formula to find the approx. number of random steps needed to compute its area based upon these program results? Maybe a Lagrange Interpolating Polynomial like this: Thanks. // Calculate the area of a N×N grid using a 2D random walk.  #include <stdio.h> #include <stdbool.h> #include <stdlib.h> #include <time.h> #include <random>  unsigned int GRID_SIZE; std::minstd_rand simple_rand;  typedef struct {     int xF;     int yF;     int xT;     int yT; } FromTo;   typedef struct {     FromTo FT;     bool walked; } segment;  int xFrom, yFrom, xTo, yTo;  segment* xPaths[1000]; segment* yPaths[1000];   void PathsCheck(segment** Paths) {     int i=0, j=0;     segment* Segments;      for (i = 0; i < GRID_SIZE; i++)     {         Segments = Paths[i];          for (j = 0; j < GRID_SIZE; j++)         {             // Check for reversible walks {(0,0),(1,0)} or {(1,0),(0,0)}             if ((((Segments[j].FT.xF == xFrom) && (Segments[j].FT.yF == yFrom)) &&                 ((Segments[j].FT.xT == xTo) && (Segments[j].FT.yT == yTo))) ||                 (((Segments[j].FT.xT == xFrom) && (Segments[j].FT.yT == yFrom)) &&                 ((Segments[j].FT.xF == xTo) && (Segments[j].FT.yF == yTo))))             {                                 Segments[j].walked = true;                 return;             }         }     } }   int PathsStats(segment** Paths) {     int i = 0, j = 0, segmentsTraversed = 0;     segment* Segments;      for (i = 0; i < GRID_SIZE; i++)     {         Segments = Paths[i];          for (j = 0; j < (GRID_SIZE - 1); j++)         {             if (Segments[j].walked)             {                 segmentsTraversed++;             }         }     }      return segmentsTraversed; }   void GenerateRandomWalk(void) {     // (0,3) (1,3) (2,3) (3,3)      // (0,2) (1,2) (2,2) (3,2)      // (0,1) (1,1) (2,1) (3,1)      // (0,0) (1,0) (2,0) (3,0)      xFrom = xTo;     yFrom = yTo;      do     {         switch (simple_rand() % 4)         {         case 0: if (yTo != (GRID_SIZE - 1)) yTo++; break; // up                     case 1: if (yTo != 0) yTo--; break;               // down                     case 2: if (xTo != 0) xTo--; break;               // left                     case 3: if (xTo != (GRID_SIZE - 1)) xTo++; break; // right         }     } while ((xFrom == xTo) && (yFrom == yTo)); }   void CreateXsegments(void) {     int x, y, i=0, j;     segment* xSegments;      // xSegments[0] = {(0,3),(1,3)} {(1,3),(2,3)} {(2,3),(3,3)}     // xSegments[1] = {(0,2),(1,2)} {(1,2),(2,2)} {(2,2),(3,2)}     // xSegments[2] = {(0,1),(1,1)} {(1,1),(2,1)} {(2,1),(3,1)}     // xSegments[3] = {(0,0),(1,0)} {(1,0),(2,0)} {(2,0),(3,0)}      for (y = (GRID_SIZE - 1); y >= 0; y--)     {         xSegments = (segment*)malloc((GRID_SIZE - 1) * sizeof(segment));         if (!xSegments)         {             exit(-1);         }                      xPaths[i++] = xSegments;          j = 0;          for (x = 0; x < (GRID_SIZE - 1); x++)         {             xSegments[j++] = { {x,y,x + 1,y},false };         }     } }   void CreateYsegments(void) {     int x, y, i = 0, j;     segment* ySegments;      // ySegments[0] = {(0,3),(0,2)} {(0,2),(0,1)} {(0,1),(0,0)}     // ySegments[1] = {(1,3),(1,2)} {(1,2),(1,1)} {(1,1),(1,0)}     // ySegments[2] = {(2,3),(2,2)} {(2,2),(2,1)} {(2,1),(2,0)}     // ySegments[3] = {(3,3),(3,2)} {(3,2),(3,1)} {(3,1),(3,0)}      for (x = 0; x < GRID_SIZE; x++)     {         ySegments = (segment*)malloc((GRID_SIZE - 1) * sizeof(segment));          if (!ySegments)         {             exit(-1);         }          yPaths[i++] = ySegments;          j = 0;          for (y = (GRID_SIZE - 1); y > 0; y--)         {             ySegments[j++] = {{x,y,x,y - 1},false};         }     } }   int main(int argc, char *argv[]) {     int WalksDone;     int xWalks, yWalks;     int TotalSteps, AvgSteps;     int ctr,ctrmax=102,avg,avgmax=100;      simple_rand.seed((unsigned int)time(0));      // Compute Grids 10x10, 20x20, ... ,100x100      for (ctr = 11; ctr < ctrmax; ctr += 10)     {         AvgSteps = 0;          for (avg = 0; avg < avgmax; avg++)         {             GRID_SIZE = ctr;             WalksDone = (GRID_SIZE * (GRID_SIZE - 1));              TotalSteps = 0;              xWalks = yWalks = 0;             xFrom = yFrom = xTo = yTo = 0;              CreateXsegments();             CreateYsegments();              do             {                 TotalSteps++;                  GenerateRandomWalk();                  if (xWalks != WalksDone)                 {                     PathsCheck(xPaths);                     xWalks = PathsStats(xPaths);                 }                 if (yWalks != WalksDone)                 {                     PathsCheck(yPaths);                     yWalks = PathsStats(yPaths);                 }              } while ((xWalks != WalksDone) || (yWalks != WalksDone));              printf(""%ux%u Grid, Total Steps: %d\n"", GRID_SIZE - 1, GRID_SIZE - 1, TotalSteps);              AvgSteps += TotalSteps;              // Release memory....             for (int i = 0; i < GRID_SIZE; i++)             {                 free(xPaths[i]); xPaths[i] = NULL;                 free(yPaths[i]); yPaths[i] = NULL;             }         }          printf(""%ux%u Grid, Average Steps: %d\n"", GRID_SIZE - 1, GRID_SIZE - 1, AvgSteps/avgmax);     }      return 0; }","N \times N \mathbb{Z}^2 (0,0) (1,0), (−1,0), (0,1), (0,−1) 150\times150 N \times N 10 \times 10 100 N \times N f(x) = \\ \begin{array}{c}  \frac{31381 x^9}{8640000000000}-\frac{1427173 x^8}{806400000000}+\frac{1549913 x^7}{4200000000}-\frac{123941687 x^6}{2880000000}+\frac{886369883 x^5}{288000000}-\frac{1602458819 x^4}{11520000}+\frac{17031670657 x^3}{4320000}-\frac{67368570503 x^2}{1008000}+\frac{1020468443 x}{1680}-2208005 \end{array}","['probability', 'stochastic-processes', 'euclidean-geometry', 'random-walk']"
1,The equivalence of Lindeberg with CLT & Feller for a given example,The equivalence of Lindeberg with CLT & Feller for a given example,,"I consider Gabriel's example "" Showing that Lindeberg condition does not hold "" where we deal with a sequence of random variables $(X_n)_n$ with $X_k = Y_k + Z_k$ and $P(Y_k = \pm 1) = \frac{1}{2}$ and $$ P(Z_k = \pm k) = \frac{1}{2k^2} = \frac{1 - P(Z_k = 0)}{2}. $$ As in the solution there, it can be shown, that the CLT for $S_n = \sum_{k=1}^{n} X_n$ holds, that is $$ \frac{S_n}{\sqrt{n}} {\stackrel{d}{\longrightarrow}} \eta \sim \mathcal{N}(0,1) \quad \text{for } {n \rightarrow \infty} $$ but the Lindeberg condition is not fullfilled (even for the little more genereal Case where $Y_k$ is iid with expectation 0 and variance 1). But I struggle with the Feller condition. As fare as I know this is (if I use the triangular array with $X_{n_k}:=(\frac{X_k}{\sqrt{n}})$ ): $$ 	\max_{1 \leqslant k \leqslant n} \sigma_{n_k} = \max_{1 \leqslant k \leqslant n} \mathbb{E}\left[\left(\frac{X_k}{\sqrt{n}}\right)^2\right] = \max_{1 \leqslant k \leqslant n} \frac{\mathbb{E}(X_k^2)}{n} = \frac{2}{n} \stackrel{n \to \infty}{\longrightarrow} 0, $$ as it may be found in mathworld . However, if the Feller condition is fulfilled, the Lindeberg condition is necessary and sufficient for the CLT. Do I have a mistake with the Feller condition or is there another assumption for the equivalence Lindeberg $\Leftrightarrow$ Feller & CLT I do not considere/know? And maybe another but minor important question: the example shows that the second moment of $\frac{S_n}{\sqrt{n}}$ does not converge. What do I need that $\mathbb{V}\left(\frac{S_n}{\sqrt{n}}\right) \stackrel{n \to \infty}{\longrightarrow} \mathbb{V}(\eta)$ ?","I consider Gabriel's example "" Showing that Lindeberg condition does not hold "" where we deal with a sequence of random variables with and and As in the solution there, it can be shown, that the CLT for holds, that is but the Lindeberg condition is not fullfilled (even for the little more genereal Case where is iid with expectation 0 and variance 1). But I struggle with the Feller condition. As fare as I know this is (if I use the triangular array with ): as it may be found in mathworld . However, if the Feller condition is fulfilled, the Lindeberg condition is necessary and sufficient for the CLT. Do I have a mistake with the Feller condition or is there another assumption for the equivalence Lindeberg Feller & CLT I do not considere/know? And maybe another but minor important question: the example shows that the second moment of does not converge. What do I need that ?","(X_n)_n X_k = Y_k + Z_k P(Y_k = \pm 1) = \frac{1}{2} 
P(Z_k = \pm k) = \frac{1}{2k^2} = \frac{1 - P(Z_k = 0)}{2}.
 S_n = \sum_{k=1}^{n} X_n 
\frac{S_n}{\sqrt{n}} {\stackrel{d}{\longrightarrow}} \eta \sim \mathcal{N}(0,1) \quad \text{for } {n \rightarrow \infty}
 Y_k X_{n_k}:=(\frac{X_k}{\sqrt{n}}) 
	\max_{1 \leqslant k \leqslant n} \sigma_{n_k} = \max_{1 \leqslant k \leqslant n} \mathbb{E}\left[\left(\frac{X_k}{\sqrt{n}}\right)^2\right] = \max_{1 \leqslant k \leqslant n} \frac{\mathbb{E}(X_k^2)}{n} = \frac{2}{n} \stackrel{n \to \infty}{\longrightarrow} 0,
 \Leftrightarrow \frac{S_n}{\sqrt{n}} \mathbb{V}\left(\frac{S_n}{\sqrt{n}}\right) \stackrel{n \to \infty}{\longrightarrow} \mathbb{V}(\eta)","['probability', 'probability-theory', 'central-limit-theorem', 'probability-limit-theorems']"
2,A transformation for independent variables to be dependent,A transformation for independent variables to be dependent,,"I ran into a confusing question. If two variables are independent, maybe they will be dependent after linear transformation. How it can happen? Is it possible for independent variables? What is the operation that it makes variables to be dependent? In my opinion the transformation that maps all variables to a point is true for this fact. What is wrong with my answer? The mean of Variables are features of data.","I ran into a confusing question. If two variables are independent, maybe they will be dependent after linear transformation. How it can happen? Is it possible for independent variables? What is the operation that it makes variables to be dependent? In my opinion the transformation that maps all variables to a point is true for this fact. What is wrong with my answer? The mean of Variables are features of data.",,['probability']
3,$30$ Sided Dice Problem. Interview Preparation. [closed],Sided Dice Problem. Interview Preparation. [closed],30,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . The community reviewed whether to reopen this question 11 months ago and left it closed: Original close reason(s) were not resolved Improve this question I came through this problem three years ago when I prepared for interview. Today when reviewing it, I still couldn't think out a mathematical way to solve it. Any help would be appreciated. $4$ players roll a fair $30$ -sided dice. Each of them rolls once and the $4$ numbers rolled are different. The $2$ individuals that rolled the biggest and small value will be in a team while the $2$ individuals who rolled the $2^{\text{nd}}$ and $3^{\text{rd}}$ smallest value will be on the opposite team. The team with the largest average wins and the loser has to pay the winners' average number ( for example, if the dice outcome is $27, 20, 15,$ and $11,$ then the people who get $27$ and $11$ get paid $19$ ). Q) If you are the first to roll, what number would you prefer to maximize your payout?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . The community reviewed whether to reopen this question 11 months ago and left it closed: Original close reason(s) were not resolved Improve this question I came through this problem three years ago when I prepared for interview. Today when reviewing it, I still couldn't think out a mathematical way to solve it. Any help would be appreciated. players roll a fair -sided dice. Each of them rolls once and the numbers rolled are different. The individuals that rolled the biggest and small value will be in a team while the individuals who rolled the and smallest value will be on the opposite team. The team with the largest average wins and the loser has to pay the winners' average number ( for example, if the dice outcome is and then the people who get and get paid ). Q) If you are the first to roll, what number would you prefer to maximize your payout?","4 30 4 2 2 2^{\text{nd}} 3^{\text{rd}} 27, 20, 15, 11, 27 11 19","['probability', 'expected-value', 'dice', 'expectation-maximization']"
4,How to measure the width,How to measure the width,,"In the attached picture, RS can be determined as follows: RS is obtained from fitting the function $$0.5(1+\operatorname{erf}((I\%-50)/RS))$$ where $I\%$ is the current pulse amplitude as percentage of threshold and $\operatorname{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x}e^{-\lambda^2}d \lambda$ . It is about determining the spread of a curve.","In the attached picture, RS can be determined as follows: RS is obtained from fitting the function where is the current pulse amplitude as percentage of threshold and . It is about determining the spread of a curve.",0.5(1+\operatorname{erf}((I\%-50)/RS)) I\% \operatorname{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x}e^{-\lambda^2}d \lambda,"['calculus', 'probability', 'probability-theory', 'statistics', 'discrete-mathematics']"
5,Sub-Gaussian norm is proper norm,Sub-Gaussian norm is proper norm,,"I am trying to show that the sub-Gaussian norm is a proper norm: $$\|X\|_{\psi_2}=\text{inf}\bigg\{t>0:\mathbb{E}\bigg[\text{exp}\bigg(\frac{X^2}{t^2}\bigg)\bigg]\bigg\}$$ I was able to show the triangle inequality, and just want to make sure my logic on showing the homogeneity property is correct: $$\|cX\|_{\psi_2}=\text{inf}\bigg\{t>0:\mathbb{E}\bigg[\text{exp}\bigg(\frac{c^2X^2}{t^2}\bigg)\bigg]\bigg\}$$ Def $k=\frac{t}{|c|}$ then $$\|cX\|_{\psi_2}=\text{inf}\bigg\{|c|k>0:\mathbb{E}\bigg[\text{exp}\bigg(\frac{X^2}{k^2}\bigg)\bigg]\bigg\}=|c|\text{inf}\bigg\{k>0:\mathbb{E}\bigg[\text{exp}\bigg(\frac{X^2}{k^2}\bigg)\bigg]\bigg\}=|c|\|X\|_{\psi_2}$$ Is this  correct?","I am trying to show that the sub-Gaussian norm is a proper norm: I was able to show the triangle inequality, and just want to make sure my logic on showing the homogeneity property is correct: Def then Is this  correct?",\|X\|_{\psi_2}=\text{inf}\bigg\{t>0:\mathbb{E}\bigg[\text{exp}\bigg(\frac{X^2}{t^2}\bigg)\bigg]\bigg\} \|cX\|_{\psi_2}=\text{inf}\bigg\{t>0:\mathbb{E}\bigg[\text{exp}\bigg(\frac{c^2X^2}{t^2}\bigg)\bigg]\bigg\} k=\frac{t}{|c|} \|cX\|_{\psi_2}=\text{inf}\bigg\{|c|k>0:\mathbb{E}\bigg[\text{exp}\bigg(\frac{X^2}{k^2}\bigg)\bigg]\bigg\}=|c|\text{inf}\bigg\{k>0:\mathbb{E}\bigg[\text{exp}\bigg(\frac{X^2}{k^2}\bigg)\bigg]\bigg\}=|c|\|X\|_{\psi_2},"['probability', 'probability-theory']"
6,Probability that the connection broke down in this grid,Probability that the connection broke down in this grid,,"See below chart. The yellow blocks are two islands. It's connected by a grid of cables. There are 16 vertical cables and 9 horizontal cables and 12 nodes (blue highlighted) in between. Hurricane strike and each cable has 1/2 probability of breaking. Two islands lost contact when there is no path to go from one island to the other on the grid. What's the probability that these two islands lost contact? I am thinking of something like letting $f(1,1)$ be the probability that the top left node cannot be reached from top island. Then $f(1,1) = 0.5 \cdot (0.5 \cdot (1-f(1,2)) + f(1,2))$ . Reason is you need the direct cable from top island to first node broke, and you either need cable from $(1,1)$ to $(1,2)$ broke, or $f(1,2)$ broke. But the equation starts to get a bit messy. It looks like this might be able to expressed in matrix form or Markov Chain or some sort though..","See below chart. The yellow blocks are two islands. It's connected by a grid of cables. There are 16 vertical cables and 9 horizontal cables and 12 nodes (blue highlighted) in between. Hurricane strike and each cable has 1/2 probability of breaking. Two islands lost contact when there is no path to go from one island to the other on the grid. What's the probability that these two islands lost contact? I am thinking of something like letting be the probability that the top left node cannot be reached from top island. Then . Reason is you need the direct cable from top island to first node broke, and you either need cable from to broke, or broke. But the equation starts to get a bit messy. It looks like this might be able to expressed in matrix form or Markov Chain or some sort though..","f(1,1) f(1,1) = 0.5 \cdot (0.5 \cdot (1-f(1,2)) + f(1,2)) (1,1) (1,2) f(1,2)","['probability', 'combinatorics', 'contest-math', 'reliability']"
7,fourth moments of truncated unit-variance variables are summable,fourth moments of truncated unit-variance variables are summable,,"In an article I found the following: If $X$ is a r.v. with zero mean and finite variance, then $$ \sum_N \frac 1 {N^2} \mathbb E\left[ |X|^4 \mathbf 1_{|X|<\sqrt N} \right]<+\infty  $$ and I am struggling to understand how to prove it. I tried to do the classical estimation, that is $$ \mathbb E\left[ |X|^4 \mathbf 1_{|X|<\sqrt N} \right] \le N \mathbb E\left[ |X|^2 \mathbf 1_{|X|<\sqrt N} \right] \le N $$ but it is not enough. I guess I can get $o(N)$ , but that is still not enough. I also tried to come up with some counterexample, but for example a continuous distribution with a density with tail $O(x^{-k})$ needs $k>3$ to have finite variance, that coincides with the condition to get summability. And  if $X$ has a distribution with compact support, then all the moments are bounded by a same constant, so the summability follows.","In an article I found the following: If is a r.v. with zero mean and finite variance, then and I am struggling to understand how to prove it. I tried to do the classical estimation, that is but it is not enough. I guess I can get , but that is still not enough. I also tried to come up with some counterexample, but for example a continuous distribution with a density with tail needs to have finite variance, that coincides with the condition to get summability. And  if has a distribution with compact support, then all the moments are bounded by a same constant, so the summability follows.","X  \sum_N \frac 1 {N^2} \mathbb E\left[ |X|^4 \mathbf 1_{|X|<\sqrt N} \right]<+\infty   
\mathbb E\left[ |X|^4 \mathbf 1_{|X|<\sqrt N} \right] \le N \mathbb E\left[ |X|^2 \mathbf 1_{|X|<\sqrt N} \right] \le N
 o(N) O(x^{-k}) k>3 X","['probability', 'random-variables', 'expected-value', 'distribution-tails']"
8,"Let $X_1,X_2,\dots$ be i.i.d. with cdf $F(x)$ with $\lim_{x\to\infty}x^\alpha\left[1-F(x)\right]=b$.",Let  be i.i.d. with cdf  with .,"X_1,X_2,\dots F(x) \lim_{x\to\infty}x^\alpha\left[1-F(x)\right]=b","Problem: Let $X_1,X_2,\dots$ be i.i.d. random variables with distribution function $F(x)$ . Denote the maximum of the first $n$ elements by $M_n$ . Show that if $$\lim_{x\to\infty}x^\alpha\left[1-F(x)\right]=b$$ with fixed positive constants $\alpha,b$ then $n^{-1/\alpha}M_n$ converges in distribution and identify the limiting distribution. What I have so far: Put $Y_n=n^{-1/\alpha}M_n$ . Then we have \begin{align*} F_{Y_n}(x) &=P\left(\max_{1\leq k\leq n}X_k\leq n^{1/\alpha}x\right)\\ &=[F(xn^{1/\alpha})]^n\\ &=[1-P(X_1>xn^{1/\alpha})]^n\\ &=\left[1-\frac{x^\alpha n}{x^\alpha n}P(X_1>xn^{1/\alpha})\right]^n. \end{align*} Now I need to evaluate the limit above. It seems to me that this limit evaluates to $e^{-b/x^\alpha}$ , but upon graphing this function, I note that it is not a valid CDF. Therefore, this cannot be the right answer. Could anyone help with a hint on how to evaluate the limit above rigorously? Thank you for your time and appreciate any feedback.","Problem: Let be i.i.d. random variables with distribution function . Denote the maximum of the first elements by . Show that if with fixed positive constants then converges in distribution and identify the limiting distribution. What I have so far: Put . Then we have Now I need to evaluate the limit above. It seems to me that this limit evaluates to , but upon graphing this function, I note that it is not a valid CDF. Therefore, this cannot be the right answer. Could anyone help with a hint on how to evaluate the limit above rigorously? Thank you for your time and appreciate any feedback.","X_1,X_2,\dots F(x) n M_n \lim_{x\to\infty}x^\alpha\left[1-F(x)\right]=b \alpha,b n^{-1/\alpha}M_n Y_n=n^{-1/\alpha}M_n \begin{align*}
F_{Y_n}(x)
&=P\left(\max_{1\leq k\leq n}X_k\leq n^{1/\alpha}x\right)\\
&=[F(xn^{1/\alpha})]^n\\
&=[1-P(X_1>xn^{1/\alpha})]^n\\
&=\left[1-\frac{x^\alpha n}{x^\alpha n}P(X_1>xn^{1/\alpha})\right]^n.
\end{align*} e^{-b/x^\alpha}","['probability', 'probability-theory', 'probability-distributions']"
9,Freidlin-Wentzell theory: clarification of a theorem,Freidlin-Wentzell theory: clarification of a theorem,,"I am studying Freidlin and Wentzell large deviation theory from their 2012 book ""Random perturbations of dynamical systems"" and I have a problem in justifying two steps of the proof of theorem 1.3. The theorem states Theorem We assume that there exists a continuous function $\bar{b}(t, x), t > 0,x \in \mathbb{R}^{r}$ such that for any $δ > 0, T > 0, x ∈ R^r$ we have \begin{equation} \label{eqn: hp1} \lim_{\epsilon \to 0} \mathbb{P} \Big( \Big| \int_{t_0}^{t_0+T}b(\epsilon,t,x,\omega)dt - \int_{t_0}^{t_0+T} \bar{b}(t,x)dt \Big| > \delta \Big) = 0 \end{equation} uniformly in $t_0 \ge 0$ . Then the equation \begin{equation} \label{eqn: hp2} \dot{\bar{x}}_t=\bar{b}(t,\bar{x}_t), \qquad \bar{x}_0=x \end{equation} has a unique solution and \begin{equation} \lim_{\epsilon \to 0} \mathbb{P} \big( \max_{0 \le t \le T}|X_{t}^{\epsilon}-\bar{x}_t| > \delta \big) =0 \end{equation} for every $T>0$ and $\delta>0$ . Proof Since the function $\bar{b}(t,x)$ is continuous, by the mean value theorem we have $ \int_{t}^{t+\Delta}\bar{b}(s,x) ds =\bar{b}(t,x)\Delta+o(\Delta), \qquad \Delta \to 0 $ Taking into account the first hypothesis, we get \begin{equation} \begin{split} |\bar{b}(t,x)-\bar{b}(t,y)| &= \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} \bar{b}(s,x)ds - \int_{t}^{t+\Delta} \bar{b}(s,y)ds \Big| + \frac{o(\Delta)}{\Delta}\\ & \le  \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} b(\epsilon,s,x,\omega)ds - \int_{t}^{t+\Delta} b(\epsilon,s,y,\omega)ds \Big| \\ & + \frac{o(\Delta)}{\Delta} +\delta_{\epsilon} \\ & \le K|x-y|+\frac{o(\Delta)}{\Delta} +\delta_{\epsilon} \end{split} \end{equation} where $\delta_{\epsilon}=\delta_{\epsilon}(t,\omega) \to 0$ in probability as $\epsilon \to 0$ . And from this follows the Lipschitz condition on $\bar{b}$ and so the existence and uniqueness. Here I don't understand how to get $\delta_{\epsilon}$ , which I don't even know how it is defined. I tried in this way: from the hypotesis I remark that $-\delta \le  \int_{t_0}^{t_0+T}b(\epsilon,t,x,\omega)dt - \int_{t_0}^{t_0+T} \bar{b}(t,x)dt \le \delta$ and so, after adding and subtracting both $\int_{t}^{t+\Delta}b(\epsilon,t,x,\omega)dt$ and $\int_{t}^{t+\Delta}b(\epsilon,t,y,\omega)dt$ and use the remark above and I obtain \begin{equation} \begin{split} |\bar{b}(t,x)-\bar{b}(t,y)| &= \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} \bar{b}(s,x)ds - \int_{t}^{t+\Delta} \bar{b}(s,y)ds \Big| + \frac{o(\Delta)}{\Delta}\\ & \le  \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} b(\epsilon,s,x,\omega)ds - \int_{t}^{t+\Delta} b(\epsilon,s,y,\omega)ds \Big| \\ & + \frac{o(\Delta)}{\Delta} +\frac{2}{\Delta}\delta \\ & \le K|x-y|+\frac{o(\Delta)}{\Delta} +\delta_{\epsilon} \end{split} \end{equation} where $\delta_{\epsilon}=\frac{2}{\Delta}\delta$ . But it doesn't seem right since it is not random and so how can I say that it converges in probability as the quantity of the authors? The other doubt is some steps after this. I have the estimate that follows: \begin{equation} \begin{split} & \int_{0}^{t} [b(\epsilon,s,\bar{x}_s,\omega)-\bar{b}(s,\bar{x}_s)]ds \\ &= \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_s,\omega)-\bar{b}(s,\bar{x}_s)]ds \\ &= \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_{kt/n},\omega)-\bar{b}(s,\bar{x}_{kt/n})]ds \\ &+ \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_s,\omega)-b(\epsilon,s,\bar{x}_{kt/n},\omega)]ds \\ &+ \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [\bar{b}(s,\bar{x}_{kt/n},)-\bar{b}(s,\bar{x}_s)]ds \\ &= \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_{kt/n},\omega)-\bar{b}(s,\bar{x}_{kt/n})]ds + \rho_{n,t}^{\epsilon} \end{split} \end{equation} where they say that $|\rho_{n,t}^{\epsilon}| \le C/n$ with $C=C(T,K)$ . I tried in this way but I'm stuck and don't know how to go on \begin{equation} \begin{split} |\rho_{n,t}^{\epsilon}| &\le \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} |b(\epsilon,s,\bar{x}_s,\omega)-b(\epsilon,s,\bar{x}_{kt/n},\omega)|ds \\ &+ \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} |\bar{b}(s,\bar{x}_{kt/n},)-\bar{b}(s,\bar{x}_s|ds \\ & \le 2K \sum_{k=0}^{n-1}\int_{kt/n}^{(k+1)t/n}|\bar{x}_s - \bar{x}_{kt/n}|ds \end{split} \end{equation} Now I don't know how to procede: how can I get the same result as in the book? Questions is what I did at the beginning correct? If not, how do I change it? how do I go on in the second part? Thanks to anyone who will have the patience to read and answer.","I am studying Freidlin and Wentzell large deviation theory from their 2012 book ""Random perturbations of dynamical systems"" and I have a problem in justifying two steps of the proof of theorem 1.3. The theorem states Theorem We assume that there exists a continuous function such that for any we have uniformly in . Then the equation has a unique solution and for every and . Proof Since the function is continuous, by the mean value theorem we have Taking into account the first hypothesis, we get where in probability as . And from this follows the Lipschitz condition on and so the existence and uniqueness. Here I don't understand how to get , which I don't even know how it is defined. I tried in this way: from the hypotesis I remark that and so, after adding and subtracting both and and use the remark above and I obtain where . But it doesn't seem right since it is not random and so how can I say that it converges in probability as the quantity of the authors? The other doubt is some steps after this. I have the estimate that follows: where they say that with . I tried in this way but I'm stuck and don't know how to go on Now I don't know how to procede: how can I get the same result as in the book? Questions is what I did at the beginning correct? If not, how do I change it? how do I go on in the second part? Thanks to anyone who will have the patience to read and answer.","\bar{b}(t, x), t > 0,x \in \mathbb{R}^{r} δ > 0, T > 0, x ∈ R^r \begin{equation}
\label{eqn: hp1}
\lim_{\epsilon \to 0} \mathbb{P} \Big( \Big| \int_{t_0}^{t_0+T}b(\epsilon,t,x,\omega)dt - \int_{t_0}^{t_0+T} \bar{b}(t,x)dt \Big| > \delta \Big) = 0
\end{equation} t_0 \ge 0 \begin{equation}
\label{eqn: hp2}
\dot{\bar{x}}_t=\bar{b}(t,\bar{x}_t), \qquad \bar{x}_0=x
\end{equation} \begin{equation}
\lim_{\epsilon \to 0} \mathbb{P} \big( \max_{0 \le t \le T}|X_{t}^{\epsilon}-\bar{x}_t| > \delta \big) =0
\end{equation} T>0 \delta>0 \bar{b}(t,x) 
\int_{t}^{t+\Delta}\bar{b}(s,x) ds =\bar{b}(t,x)\Delta+o(\Delta), \qquad \Delta \to 0
 \begin{equation}
\begin{split}
|\bar{b}(t,x)-\bar{b}(t,y)| &= \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} \bar{b}(s,x)ds - \int_{t}^{t+\Delta} \bar{b}(s,y)ds \Big| + \frac{o(\Delta)}{\Delta}\\
& \le  \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} b(\epsilon,s,x,\omega)ds - \int_{t}^{t+\Delta} b(\epsilon,s,y,\omega)ds \Big| \\
& + \frac{o(\Delta)}{\Delta} +\delta_{\epsilon} \\
& \le K|x-y|+\frac{o(\Delta)}{\Delta} +\delta_{\epsilon}
\end{split}
\end{equation} \delta_{\epsilon}=\delta_{\epsilon}(t,\omega) \to 0 \epsilon \to 0 \bar{b} \delta_{\epsilon} -\delta \le  \int_{t_0}^{t_0+T}b(\epsilon,t,x,\omega)dt - \int_{t_0}^{t_0+T} \bar{b}(t,x)dt \le \delta \int_{t}^{t+\Delta}b(\epsilon,t,x,\omega)dt \int_{t}^{t+\Delta}b(\epsilon,t,y,\omega)dt \begin{equation}
\begin{split}
|\bar{b}(t,x)-\bar{b}(t,y)| &= \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} \bar{b}(s,x)ds - \int_{t}^{t+\Delta} \bar{b}(s,y)ds \Big| + \frac{o(\Delta)}{\Delta}\\
& \le  \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} b(\epsilon,s,x,\omega)ds - \int_{t}^{t+\Delta} b(\epsilon,s,y,\omega)ds \Big| \\
& + \frac{o(\Delta)}{\Delta} +\frac{2}{\Delta}\delta \\
& \le K|x-y|+\frac{o(\Delta)}{\Delta} +\delta_{\epsilon}
\end{split}
\end{equation} \delta_{\epsilon}=\frac{2}{\Delta}\delta \begin{equation}
\begin{split}
& \int_{0}^{t} [b(\epsilon,s,\bar{x}_s,\omega)-\bar{b}(s,\bar{x}_s)]ds \\
&= \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_s,\omega)-\bar{b}(s,\bar{x}_s)]ds \\
&= \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_{kt/n},\omega)-\bar{b}(s,\bar{x}_{kt/n})]ds \\
&+ \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_s,\omega)-b(\epsilon,s,\bar{x}_{kt/n},\omega)]ds \\
&+ \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [\bar{b}(s,\bar{x}_{kt/n},)-\bar{b}(s,\bar{x}_s)]ds \\
&= \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_{kt/n},\omega)-\bar{b}(s,\bar{x}_{kt/n})]ds + \rho_{n,t}^{\epsilon}
\end{split}
\end{equation} |\rho_{n,t}^{\epsilon}| \le C/n C=C(T,K) \begin{equation}
\begin{split}
|\rho_{n,t}^{\epsilon}| &\le \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} |b(\epsilon,s,\bar{x}_s,\omega)-b(\epsilon,s,\bar{x}_{kt/n},\omega)|ds \\
&+ \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} |\bar{b}(s,\bar{x}_{kt/n},)-\bar{b}(s,\bar{x}_s|ds \\
& \le 2K \sum_{k=0}^{n-1}\int_{kt/n}^{(k+1)t/n}|\bar{x}_s - \bar{x}_{kt/n}|ds
\end{split}
\end{equation}","['probability', 'probability-theory', 'estimation', 'large-deviation-theory']"
10,Likelihood of random spanning tree given distribution of edge weights?,Likelihood of random spanning tree given distribution of edge weights?,,"Suppose I have a complete graph $G=(V,E)$ with $n$ vertices, whose edge weights $W\in\mathbb R_+^{n\times n}$ are drawn from some distribution $P(W)\in\mathrm{Prob}(\mathbb R_+^{n\times n})$ .  I randomly draw a set of edge weights $W\sim P$ and then compute the resulting minimum spanning tree $T\subseteq E$ of the weighted graph. Is it possible to compute the probability of a given spanning tree $T$ given the distribution $P(\cdot)$ ? A value proportional to this probability would suffice.  If it helps, I'm happy to assume that each weight is chosen independently, i.e. $P(W)=\prod_{ij}P_{ij}(W_{ij})$ , but I do not want to assume that the $W_{ij}$ 's are iid.  Even assuming each $P_{ij}$ is a Bernoulli (or exponential or Gaussian) distribution with a different parameter would be a great start.","Suppose I have a complete graph with vertices, whose edge weights are drawn from some distribution .  I randomly draw a set of edge weights and then compute the resulting minimum spanning tree of the weighted graph. Is it possible to compute the probability of a given spanning tree given the distribution ? A value proportional to this probability would suffice.  If it helps, I'm happy to assume that each weight is chosen independently, i.e. , but I do not want to assume that the 's are iid.  Even assuming each is a Bernoulli (or exponential or Gaussian) distribution with a different parameter would be a great start.","G=(V,E) n W\in\mathbb R_+^{n\times n} P(W)\in\mathrm{Prob}(\mathbb R_+^{n\times n}) W\sim P T\subseteq E T P(\cdot) P(W)=\prod_{ij}P_{ij}(W_{ij}) W_{ij} P_{ij}","['probability', 'combinatorics', 'graph-theory', 'trees', 'random-graphs']"
11,Probability that amoeba population dies out completely - why can't the probability be 1?,Probability that amoeba population dies out completely - why can't the probability be 1?,,"Consider an amoeba. At each iteration, it can split into 2, 3 amoebas, stay the same, or die. These 4 events occur with equal probability. Let $E$ denote the event that all current amoeba dies, and $F_1, F_2, F_3, F_4$ denote the above 4 events, then we have \begin{align}     P(E) = P(E|F_1)P(F_1) + P(E|F_2)P(F_2) + P(E|F_3)P(F_3) + P(E|F_4)P(F_4) \\     P(F_i) = \frac{1}{4} \\     P(E|F_1) = 1 \\     P(E|F_2) = P(E)^2 \\     P(E|F_3) = P(E)^3 \\     P(E|F_4) = P(E) \\     P(E) = \frac{1}{4}[1 + P(E) + P(E)^2 + P(E)^3] \\ \end{align} Solving this cubic, we find $P(E) = 1, 1 \pm \sqrt{2}$ . We throw out the negative root, and we are left with $P(E) = 1, \sqrt{2} - 1$ . In the book I am reading, it restricts the probabilities to $P(E) < 1$ . But intuitively, I do not understand why $P(E) = 1$ isn't possible. Can someone intuitively explain this? In addition, using $P(E) = \sqrt{2} - 1$ , does this mean that the expectation of the number of iterations that the amoeba population dies out is infinity? One thought that occurred to me is that the expected number of amoeba after one iteration is $0.25(1 + 2 + 3 + 0) = 1.5$ , and by induction we see that this continues to grow.","Consider an amoeba. At each iteration, it can split into 2, 3 amoebas, stay the same, or die. These 4 events occur with equal probability. Let denote the event that all current amoeba dies, and denote the above 4 events, then we have Solving this cubic, we find . We throw out the negative root, and we are left with . In the book I am reading, it restricts the probabilities to . But intuitively, I do not understand why isn't possible. Can someone intuitively explain this? In addition, using , does this mean that the expectation of the number of iterations that the amoeba population dies out is infinity? One thought that occurred to me is that the expected number of amoeba after one iteration is , and by induction we see that this continues to grow.","E F_1, F_2, F_3, F_4 \begin{align}
    P(E) = P(E|F_1)P(F_1) + P(E|F_2)P(F_2) + P(E|F_3)P(F_3) + P(E|F_4)P(F_4) \\
    P(F_i) = \frac{1}{4} \\
    P(E|F_1) = 1 \\
    P(E|F_2) = P(E)^2 \\
    P(E|F_3) = P(E)^3 \\
    P(E|F_4) = P(E) \\
    P(E) = \frac{1}{4}[1 + P(E) + P(E)^2 + P(E)^3] \\
\end{align} P(E) = 1, 1 \pm \sqrt{2} P(E) = 1, \sqrt{2} - 1 P(E) < 1 P(E) = 1 P(E) = \sqrt{2} - 1 0.25(1 + 2 + 3 + 0) = 1.5","['probability', 'expected-value']"
12,Optimal stopping strategy to capture Feebas in Pokemon Emerald,Optimal stopping strategy to capture Feebas in Pokemon Emerald,,"Some exposition for those who may not be too familiar with the game: A Feebas is a fish-like pokemon which only appears in one location in the entire game - Route 119. To be specific, it can be encountered only on the waters of Route 119, by fishing. There are 400 water ""tiles"" in Route 119. Among these 400, Feebas can appear in exactly 6 specific tiles, with a probability of 0.5. These tiles are randomly chosen when a new game is initialized, and their locations are unknown to the player. If a player can determine that a particular tile contains Feebas however, he can always find Feebas in that specific tile with a 50% probability. According to Bulbapedia , if a player fishes exactly once in each of the 400 tiles, he approximately has a 1.6% chance of not finding any Feebas (or alternatively, a 98.4% chance of finding at least one). This calculation is fairly simple - the probability of finding at least one Feebas by searching just once (S = 1) in each tile (T = 400) is: $P(F>=1|T=400,S=1) = 1 - 0.5^6 = 0.984375$ While this is great, this approach requires a player to make 400 search operations. In fact, if the player fishes twice in each tile, at the cost of 800 operations, his probability of finding at least one fish goes up to: $P(F>=1|T=400,S=2) = 1 - (0.5^2)^6 = 0.999755$ So I was wondering if this problem can be approached a bit differently, maybe from the perspective of optimal stopping problems? What would be a good strategy to minimize the number of search operations/tiles explored, while retaining a reasonable probability $P >= 0.9$ of finding at least one Feebas? Last tidbit: it is actually possible for the player to manually reset the locations of the Feebas into 6 new random unknown positions. (This can perhaps facilitate a different class of strategies, like searching only in 40 tiles, and then resetting the random 6 positions, again trying in those 40 tiles and so on. Not sure how good or bad this would be - just putting it out there.)","Some exposition for those who may not be too familiar with the game: A Feebas is a fish-like pokemon which only appears in one location in the entire game - Route 119. To be specific, it can be encountered only on the waters of Route 119, by fishing. There are 400 water ""tiles"" in Route 119. Among these 400, Feebas can appear in exactly 6 specific tiles, with a probability of 0.5. These tiles are randomly chosen when a new game is initialized, and their locations are unknown to the player. If a player can determine that a particular tile contains Feebas however, he can always find Feebas in that specific tile with a 50% probability. According to Bulbapedia , if a player fishes exactly once in each of the 400 tiles, he approximately has a 1.6% chance of not finding any Feebas (or alternatively, a 98.4% chance of finding at least one). This calculation is fairly simple - the probability of finding at least one Feebas by searching just once (S = 1) in each tile (T = 400) is: While this is great, this approach requires a player to make 400 search operations. In fact, if the player fishes twice in each tile, at the cost of 800 operations, his probability of finding at least one fish goes up to: So I was wondering if this problem can be approached a bit differently, maybe from the perspective of optimal stopping problems? What would be a good strategy to minimize the number of search operations/tiles explored, while retaining a reasonable probability of finding at least one Feebas? Last tidbit: it is actually possible for the player to manually reset the locations of the Feebas into 6 new random unknown positions. (This can perhaps facilitate a different class of strategies, like searching only in 40 tiles, and then resetting the random 6 positions, again trying in those 40 tiles and so on. Not sure how good or bad this would be - just putting it out there.)","P(F>=1|T=400,S=1) = 1 - 0.5^6 = 0.984375 P(F>=1|T=400,S=2) = 1 - (0.5^2)^6 = 0.999755 P >= 0.9","['probability', 'optimization', 'stochastic-processes']"
13,Triangle greater than (probability),Triangle greater than (probability),,"This one is a follow up of my previous question. But a different problem. And this one should have a more interesting answer. I don't really know how to approach this problem nonetheless reach a solution, so again help is appreciated. Question: You have a circle with radius $R$ . If three points are randomly chosen inside this circle. What is the probability that the three points form a triangle with an area greater than $\displaystyle \frac{R^2}{5}$ ? Edit: Is anyone trying or maybe found an approach that might work? Is there any similar problems you've seen before that could work as a guide towards solving this one? What do you consider being the difficulties? I literally don't have any idea on where to even start.","This one is a follow up of my previous question. But a different problem. And this one should have a more interesting answer. I don't really know how to approach this problem nonetheless reach a solution, so again help is appreciated. Question: You have a circle with radius . If three points are randomly chosen inside this circle. What is the probability that the three points form a triangle with an area greater than ? Edit: Is anyone trying or maybe found an approach that might work? Is there any similar problems you've seen before that could work as a guide towards solving this one? What do you consider being the difficulties? I literally don't have any idea on where to even start.",R \displaystyle \frac{R^2}{5},"['probability', 'geometric-probability']"
14,What is constraining the Kullback-Leibler divergence to not be infinitely negative?,What is constraining the Kullback-Leibler divergence to not be infinitely negative?,,"I'm trying to understand t-SNE, based on this video , and everything is clear except for one key part of the logic right at the time point linked to above: namely, minimizing the Kullback-Leibler divergence. The stated problem is that we want to choose $ q_{ij} $ such that $$ \sum\limits_{i}\sum\limits_{j \neq i} p_{ij} {\rm log} \left( \frac{p_{ij}}{q_{ij}} \right) $$ is as small as possible, and $$ q_{ij}=\frac{(1+|y_i-y_j|^2)^{-1}}{ \sum\limits_{k} \sum\limits_{l\neq k} \left( 1+|y_{k}-y_{l}|^2 \right)^{-1}} $$ (I'm a little unsure about those $^{-1}$ exponents in the expression, but I'm copying what's in the video)( Edit: they're right. The quantities are weighted inversely to squared distances ) I understand that $q_{ij}$ is constrained to the range $0..1$ , but ... these aren't probabilities ( Edit: They actually are referred to as ""probabilities of choosing each other as neighbours"" ), they're just normalized distances, so why is this a sensible comparison? does this just work for any set of numbers that are confined to the 0..1 range and which add up to one? (I updated this question because I missed something obvious, but I'm still stuck. Thanks for any help you can offer)","I'm trying to understand t-SNE, based on this video , and everything is clear except for one key part of the logic right at the time point linked to above: namely, minimizing the Kullback-Leibler divergence. The stated problem is that we want to choose such that is as small as possible, and (I'm a little unsure about those exponents in the expression, but I'm copying what's in the video)( Edit: they're right. The quantities are weighted inversely to squared distances ) I understand that is constrained to the range , but ... these aren't probabilities ( Edit: They actually are referred to as ""probabilities of choosing each other as neighbours"" ), they're just normalized distances, so why is this a sensible comparison? does this just work for any set of numbers that are confined to the 0..1 range and which add up to one? (I updated this question because I missed something obvious, but I'm still stuck. Thanks for any help you can offer)"," q_{ij}  
\sum\limits_{i}\sum\limits_{j \neq i} p_{ij} {\rm log} \left( \frac{p_{ij}}{q_{ij}} \right)
 
q_{ij}=\frac{(1+|y_i-y_j|^2)^{-1}}{ \sum\limits_{k} \sum\limits_{l\neq k} \left( 1+|y_{k}-y_{l}|^2 \right)^{-1}}
 ^{-1} q_{ij} 0..1","['probability', 'entropy']"
15,Upperbound for Covariance Matrix,Upperbound for Covariance Matrix,,"Suppose $X_t \in \mathbb{R}^d$ is a vector valued time series, or in other words a vector valued stochastic process indexed by $t \in \mathbb{Z}$ . Assume for the moment that $X_t$ is (weakly) stationary with $EX_t=0$ , $E\|X_t\|^2<\infty$ , and let $$ C_h = E[X_0 X_h^\top] $$ denote the autocovariance matrix at lag $h$ . What I wish to show is that $$ \|C_h\|_2 \le \|C_0\|_2, $$ or find a counterexample to this statement. Here $\|\cdot\|_2$ is the Hilbert-Schmidt Norm: $$\|A\|_2^2 = \sum_{i,j=1}^d a_{i,j}^2. $$ So far all I can show is the weaker statement that $$ \|C_h\|_2 \le trace(C_0). $$ To see this, we have by the Cauchy-Schwarz inequality for expectation and stationarity that $$ \|C_h\|_2^2 = \sum_{i,j=1}^d (E[X_{0,i}X_{h,j}])^2 \le  \sum_{i,j=1}^d E[X_{0,i}^2]E[X_{h,j}^2] = \sum_{i,j=1}^d E[X_{0,i}^2]E[X_{0,j}^2] =[trace(C_0)]^2. $$ Part of me believes that this bound must be sharp, i.e. there is a counter example where $\|C_h\|_2 > \|C_0\|_2$ , but I really have no idea! Whatever simple examples I have tried have $\|C_h\|_2 \le \|C_0\|_2$ , for instance vector autoregressive processes. Any help/advice is much appreciated.","Suppose is a vector valued time series, or in other words a vector valued stochastic process indexed by . Assume for the moment that is (weakly) stationary with , , and let denote the autocovariance matrix at lag . What I wish to show is that or find a counterexample to this statement. Here is the Hilbert-Schmidt Norm: So far all I can show is the weaker statement that To see this, we have by the Cauchy-Schwarz inequality for expectation and stationarity that Part of me believes that this bound must be sharp, i.e. there is a counter example where , but I really have no idea! Whatever simple examples I have tried have , for instance vector autoregressive processes. Any help/advice is much appreciated.","X_t \in \mathbb{R}^d t \in \mathbb{Z} X_t EX_t=0 E\|X_t\|^2<\infty 
C_h = E[X_0 X_h^\top]
 h 
\|C_h\|_2 \le \|C_0\|_2,
 \|\cdot\|_2 \|A\|_2^2 = \sum_{i,j=1}^d a_{i,j}^2.  
\|C_h\|_2 \le trace(C_0).
 
\|C_h\|_2^2 = \sum_{i,j=1}^d (E[X_{0,i}X_{h,j}])^2 \le  \sum_{i,j=1}^d E[X_{0,i}^2]E[X_{h,j}^2] = \sum_{i,j=1}^d E[X_{0,i}^2]E[X_{0,j}^2] =[trace(C_0)]^2.
 \|C_h\|_2 > \|C_0\|_2 \|C_h\|_2 \le \|C_0\|_2","['linear-algebra', 'probability', 'probability-theory', 'statistics', 'stochastic-processes']"
16,Expected number of coin tosses untill number of head exceeds number of tails?,Expected number of coin tosses untill number of head exceeds number of tails?,,This problem is basically from MIT OCW probability section. A fair coin is flipped until the number of heads exceeds the number of tails. What is the expected number of flips? I tried this question and landed with 25/12 as the expected number of flips required. I want to check if this is correct.,This problem is basically from MIT OCW probability section. A fair coin is flipped until the number of heads exceeds the number of tails. What is the expected number of flips? I tried this question and landed with 25/12 as the expected number of flips required. I want to check if this is correct.,,"['probability', 'expected-value']"
17,Does this bound hold beyond the domain where the function is convex?,Does this bound hold beyond the domain where the function is convex?,,"Let $F:(0,\infty) \to [0,\infty)$ be a continuous  function satisfying $F(1)=0$ , which is strictly increasing on $[1,\infty)$ , and strictly decreasing on $(0,1]$ . Suppose also that $F|_{(1-\epsilon,1+\epsilon)}$ is convex and smooth for some $\epsilon>0$ . Choose some $\delta \in (0,1)$ , such that $F$ is convex at every point $y \in (\delta,1)$ , where by convexity at a point $y$ , I mean that that for any $x_1,x_2>0, \alpha \in [0,1]$ satisfying $\alpha x_1 + (1- \alpha)x_2 =y$ , we have $$ F(y)=F\left(\alpha x_1 + (1- \alpha)x_2 \right) \leq \alpha F(x_1) + (1-\alpha)F(x_2). \tag{1} $$ Such a $\delta$ always exists. Question: Let $X$ be a probability space and let $g:X \to (0,\infty)$ be measurable. Suppose that $\int_X g < \delta$ . Is it true that $\int_X F \circ g \ge F(\delta)$ ? If $F$ were convex at the point $\int_X g$ , then by Jensen inequality, we would have $$ \int_X F \circ g \ge F(\int_X g) \ge F(\delta), $$ where in the last step, we have used the fact that $$ 0<\int_X g \le \delta<1 $$ together with the fact that $f$ is decreasing on $(0,1]$ . Since $F$ does not need to be convex at $\int_X g$ , I suspect that the answer can be negative in general.","Let be a continuous  function satisfying , which is strictly increasing on , and strictly decreasing on . Suppose also that is convex and smooth for some . Choose some , such that is convex at every point , where by convexity at a point , I mean that that for any satisfying , we have Such a always exists. Question: Let be a probability space and let be measurable. Suppose that . Is it true that ? If were convex at the point , then by Jensen inequality, we would have where in the last step, we have used the fact that together with the fact that is decreasing on . Since does not need to be convex at , I suspect that the answer can be negative in general.","F:(0,\infty) \to [0,\infty) F(1)=0 [1,\infty) (0,1] F|_{(1-\epsilon,1+\epsilon)} \epsilon>0 \delta \in (0,1) F y \in (\delta,1) y x_1,x_2>0, \alpha \in [0,1] \alpha x_1 + (1- \alpha)x_2 =y 
F(y)=F\left(\alpha x_1 + (1- \alpha)x_2 \right) \leq \alpha F(x_1) + (1-\alpha)F(x_2). \tag{1}
 \delta X g:X \to (0,\infty) \int_X g < \delta \int_X F \circ g \ge F(\delta) F \int_X g 
\int_X F \circ g \ge F(\int_X g) \ge F(\delta),
 
0<\int_X g \le \delta<1
 f (0,1] F \int_X g","['real-analysis', 'calculus', 'probability', 'convex-analysis', 'convexity-inequality']"
18,Negative expected value for iid standard normal random variables,Negative expected value for iid standard normal random variables,,"I would like to show analytically that: $$\Bbb{E}\left[\frac{(X_2-X_1)(Y_2-Y_1)}{|X_2+Y_2-X_1-Y_1|}\right] < 0$$ I would be happy just showing that this is true when $(X_1,Y_1,X_2,Y_2)$ are iid standard normal random variables, but a more general demonstration would be even better. Montecarlo integration shows the expectation to be strongly negative (much less than zero) for pretty much any distribution governing the $X_1, Y_1, X_2, Y_2$ .","I would like to show analytically that: I would be happy just showing that this is true when are iid standard normal random variables, but a more general demonstration would be even better. Montecarlo integration shows the expectation to be strongly negative (much less than zero) for pretty much any distribution governing the .","\Bbb{E}\left[\frac{(X_2-X_1)(Y_2-Y_1)}{|X_2+Y_2-X_1-Y_1|}\right] < 0 (X_1,Y_1,X_2,Y_2) X_1, Y_1, X_2, Y_2","['probability', 'integration']"
19,Distribution of highest numbered occupied box and number of balls therein?,Distribution of highest numbered occupied box and number of balls therein?,,"Say we have $N$ boxes, numbered $1,2,...,N$ . We select $K$ numbers uniformly from $1,2,...,N$ , and for each result we place one ball into the correspondingly numbered box. We then select $L$ numbers uniformly from the same $1,2,...,N$ and for each result we remove one ball (if any are left) from the corresponding box. In both iterations, the numbers are selected with replacement. The boxes have no capacity limit, that is, more than one ball can be placed into any given box. To clarify the mechanic, say we had 4 boxes, and we'd tossed some number $K$ balls into them as specified. Now, say $L$ was 4, and the resulting samples of numbers were ${1,3,4,4}$ . We'd remove one ball from box 1 (if any were there), one ball from box 3 (if any...), and two balls from box 4 (if any were there, so if box 4 had 2 or fewer balls it will be left empty). I'm interested in the probability distribution of the highest numbered occupied box (if any) and the associated number of remaining balls in that box. I've written a couple of methods in my CAS to arrive at the result, one simply enumerating the multinomial possibilities and doing the corresponding machinations, the other using a generating function and pulling the coefficients with corresponding machinations. As requested in comments, an example for the results for the case of $N=6$ boxes, $K=3$ tosses, and $L=2$ removals is as follows (left column is box number, followed left-to-right with probabilities that box is the highest numbered occupied box, with number of remaining balls $1,2,3$ seen there): Both work fine up to $K$ and $L$ of 15 with $N$ up to ~6, but the complexity of the methods means it gets slow pretty quickly. Is there a more efficient means to arrive at the desired results?","Say we have boxes, numbered . We select numbers uniformly from , and for each result we place one ball into the correspondingly numbered box. We then select numbers uniformly from the same and for each result we remove one ball (if any are left) from the corresponding box. In both iterations, the numbers are selected with replacement. The boxes have no capacity limit, that is, more than one ball can be placed into any given box. To clarify the mechanic, say we had 4 boxes, and we'd tossed some number balls into them as specified. Now, say was 4, and the resulting samples of numbers were . We'd remove one ball from box 1 (if any were there), one ball from box 3 (if any...), and two balls from box 4 (if any were there, so if box 4 had 2 or fewer balls it will be left empty). I'm interested in the probability distribution of the highest numbered occupied box (if any) and the associated number of remaining balls in that box. I've written a couple of methods in my CAS to arrive at the result, one simply enumerating the multinomial possibilities and doing the corresponding machinations, the other using a generating function and pulling the coefficients with corresponding machinations. As requested in comments, an example for the results for the case of boxes, tosses, and removals is as follows (left column is box number, followed left-to-right with probabilities that box is the highest numbered occupied box, with number of remaining balls seen there): Both work fine up to and of 15 with up to ~6, but the complexity of the methods means it gets slow pretty quickly. Is there a more efficient means to arrive at the desired results?","N 1,2,...,N K 1,2,...,N L 1,2,...,N K L {1,3,4,4} N=6 K=3 L=2 1,2,3 K L N","['probability', 'balls-in-bins']"
20,Markov chains - first hitting times between transient states satisfy either $\mathbb{P}^i(T_j < \infty) < 1$ or $\mathbb{P}^j(T_i < \infty) < 1$,Markov chains - first hitting times between transient states satisfy either  or,\mathbb{P}^i(T_j < \infty) < 1 \mathbb{P}^j(T_i < \infty) < 1,"We have a irreducible Markov chain $X=(X_n)_{n\geq0}$ on a state space $I$ with transition matrix $P$ and we denote by $T_i=\inf\{n\geq1: X_n=i\}$ the first hitting time of state $i$ . I have to prove the following: Let $i\neq j \in I$ be connected transient states. Then either $\mathbb{P}^i(T_j < \infty) < 1$ or $\mathbb{P}^j(T_i < \infty) < 1$ . First I need to show that $\mathbb{P}^i(T_j < \infty) < 1$ or $\mathbb{P}^j(T_i < \infty) < 1$ hold. And then if one of them holds, the other doesn't. I have a lack of intuition here. If $i$ is a tranient state, that means, starting in $i$ , we visit $i$ only a finite number of times ( $\mathbb{P}^i(V_i < \infty) =1$ ). I have already shown, that an equivalent definition of transience is that $\mathbb{P}^i (T_i < \infty) <1$ . If I now assume that both $\mathbb{P}^i(T_j < \infty) < 1$ and $\mathbb{P}^j(T_i < \infty) < 1$ hold, this would mean that starting in $i$ there is a possibility to never hit $j$ and that starting in $j$ , there is the possibility to never hit $i$ . I don't see, where this gives a contradiction. Maybe this is the point where it kicks in that $i$ and $j$ are connected, so there has to be a positive probability of going from $i$ to $j$ or (and?) from $j$ to $i$ . Could you please help me to concretize my intuition and give me hints for a formal proof of the statement? UPDATE: I came in contact with the person stating the result which should be proven. The ""either ... or..."" is not an exclusive or as I thought, it is just the normal inclusive or.","We have a irreducible Markov chain on a state space with transition matrix and we denote by the first hitting time of state . I have to prove the following: Let be connected transient states. Then either or . First I need to show that or hold. And then if one of them holds, the other doesn't. I have a lack of intuition here. If is a tranient state, that means, starting in , we visit only a finite number of times ( ). I have already shown, that an equivalent definition of transience is that . If I now assume that both and hold, this would mean that starting in there is a possibility to never hit and that starting in , there is the possibility to never hit . I don't see, where this gives a contradiction. Maybe this is the point where it kicks in that and are connected, so there has to be a positive probability of going from to or (and?) from to . Could you please help me to concretize my intuition and give me hints for a formal proof of the statement? UPDATE: I came in contact with the person stating the result which should be proven. The ""either ... or..."" is not an exclusive or as I thought, it is just the normal inclusive or.",X=(X_n)_{n\geq0} I P T_i=\inf\{n\geq1: X_n=i\} i i\neq j \in I \mathbb{P}^i(T_j < \infty) < 1 \mathbb{P}^j(T_i < \infty) < 1 \mathbb{P}^i(T_j < \infty) < 1 \mathbb{P}^j(T_i < \infty) < 1 i i i \mathbb{P}^i(V_i < \infty) =1 \mathbb{P}^i (T_i < \infty) <1 \mathbb{P}^i(T_j < \infty) < 1 \mathbb{P}^j(T_i < \infty) < 1 i j j i i j i j j i,"['probability', 'markov-chains', 'conditional-probability', 'markov-process']"
21,Interpretation of probability statements in Nina Zubrilina's paper,Interpretation of probability statements in Nina Zubrilina's paper,,"In the paper https://content.sciendo.com/view/journals/dmgt/ahead-of-print/article-10.7151-dmgt.2210/article-10.7151-dmgt.2210.xml?language=en The main result is $$\operatorname{edim}(G(n,p)) \leq (1+o(1))\frac{4 \log n}{\log(1/q)},$$ where $q= 1-2p(1-p)^2(2-p)$ My first question is how should I interpret the result, what is $\operatorname{edim}$ of random graph. Should I interpret it as $$\mathbb{P} \left[ \operatorname{edim}(G(n,p)) \leq (1+o(1))\frac{4 \log n}{\log(1/q)} \right] \rightarrow 1 \text{ as } n \rightarrow \infty \text{ ?}$$ My second question is concerned with how to interpret lemma 2.2, it is stated that Let $G=G(n,p)$ be the random graph. Let $V,E$ denote the vertex and edge sets. Let $\omega \in \{1,\cdots,n\}$ be such that for any two distinct edges $e_1,e_2$ of $E$ , a uniformly random subset $W \subset V$ of size $\omega$ satisfies $$\mathbb{P}( W \text{ does not distinguish } e_1,e_2) \leq 1/n^4p^2 $$ Then $$\operatorname{edim}(G) \leq \omega$$ So, firstly how should I understand $E$ as subset of a random graph, and how can I fix two edges of this seemingly random set by saying ""for any two distinct edges $e_1,e_2 \in E$ "". I am confused about how I interpret such statement. Can any one clarify them ?","In the paper https://content.sciendo.com/view/journals/dmgt/ahead-of-print/article-10.7151-dmgt.2210/article-10.7151-dmgt.2210.xml?language=en The main result is where My first question is how should I interpret the result, what is of random graph. Should I interpret it as My second question is concerned with how to interpret lemma 2.2, it is stated that Let be the random graph. Let denote the vertex and edge sets. Let be such that for any two distinct edges of , a uniformly random subset of size satisfies Then So, firstly how should I understand as subset of a random graph, and how can I fix two edges of this seemingly random set by saying ""for any two distinct edges "". I am confused about how I interpret such statement. Can any one clarify them ?","\operatorname{edim}(G(n,p)) \leq (1+o(1))\frac{4 \log n}{\log(1/q)}, q= 1-2p(1-p)^2(2-p) \operatorname{edim} \mathbb{P} \left[ \operatorname{edim}(G(n,p)) \leq (1+o(1))\frac{4 \log n}{\log(1/q)} \right] \rightarrow 1 \text{ as } n \rightarrow \infty \text{ ?} G=G(n,p) V,E \omega \in \{1,\cdots,n\} e_1,e_2 E W \subset V \omega \mathbb{P}( W \text{ does not distinguish } e_1,e_2) \leq 1/n^4p^2  \operatorname{edim}(G) \leq \omega E e_1,e_2 \in E","['probability', 'combinatorics', 'graph-theory']"
22,Is the probability of getting at least the average number of heads monotone?,Is the probability of getting at least the average number of heads monotone?,,"Let $f(n,k)$ be the probability of getting heads at least $n$ times with $nk$ coins that independently show heads with probability $1/k$ . For $k$ fixed, is $f(n,k)$ monotone in $n$ ? With the central limit theorem it is easy to show that $f(n,k)$ converges to $1/2$ as $n\to\infty$ . By experimentation and intuition I expect this convergence to be monotone, but I can not come up with a proof.","Let be the probability of getting heads at least times with coins that independently show heads with probability . For fixed, is monotone in ? With the central limit theorem it is easy to show that converges to as . By experimentation and intuition I expect this convergence to be monotone, but I can not come up with a proof.","f(n,k) n nk 1/k k f(n,k) n f(n,k) 1/2 n\to\infty","['probability', 'central-limit-theorem']"
23,Sampling from a distribution,Sampling from a distribution,,"In many cases we use sampling from a distribution. Also in programming languages they implement it. But I wonder now what is the process of generating a sample from a probability distribution? What happens behind the scene that given the parameters a model, a function returns a sample? Also how can I know more on this topic? I want to understand it clearly.","In many cases we use sampling from a distribution. Also in programming languages they implement it. But I wonder now what is the process of generating a sample from a probability distribution? What happens behind the scene that given the parameters a model, a function returns a sample? Also how can I know more on this topic? I want to understand it clearly.",,"['probability', 'statistics', 'probability-distributions', 'sampling', 'programming']"
24,What is the limiting probability distribution of a prime random walk,What is the limiting probability distribution of a prime random walk,,"This random walk has an infinite amount of possibility. these are the moves ranked most common to least $(\times 0+1,+1,\times2,\times3,\times5,\times7,\times11,\times13,\times17,\times19,\times23,\times29,...,\times P(n),...)$ the most common operation has a probability of 1/2, the second 1/4, the kth most common has a $1/(2^k)$ chance to happen. So a possible walk would be $((((((1)\times0+1)+1)\times7)+1)\times2)$ the place it would have landed on would be $30$ . so let's say $P_m(k)$ is the probability that k is the end of an m step walk I would like to know the limit as m goes to infinity or a good estimation for $f(k)$ $$f(k) = \lim_{m \to \infty} P_m(k)?$$","This random walk has an infinite amount of possibility. these are the moves ranked most common to least the most common operation has a probability of 1/2, the second 1/4, the kth most common has a chance to happen. So a possible walk would be the place it would have landed on would be . so let's say is the probability that k is the end of an m step walk I would like to know the limit as m goes to infinity or a good estimation for","(\times 0+1,+1,\times2,\times3,\times5,\times7,\times11,\times13,\times17,\times19,\times23,\times29,...,\times P(n),...) 1/(2^k) ((((((1)\times0+1)+1)\times7)+1)\times2) 30 P_m(k) f(k) f(k) = \lim_{m \to \infty} P_m(k)?","['probability', 'prime-numbers', 'markov-chains', 'random-walk']"
25,Colliding color balloons in a room,Colliding color balloons in a room,,"Suppose there are a total of $N$ balloons in a closed room out of which n are blue and the rest are red. After every unit of time,say a minute, any two balloons collide with independent probability $p$ .The rule is when a red and a blue balloon  collide the blue one turns red; in all other cases nothing changes. What is the distribution of the number of red balloons after $t$ minutes? Here are my thoughts about the problem: If $m_i$ is the number of red balloons after $i$ minutes, then the probability $q_{i+1}$ that a blue balloon will have become red after $i+1$ minutes is given by $$1-\prod_{k=0}^{i}(1-p)^{(N-m_i)}.$$ Hence the  probability that of there being $j$ red balloons after $i+1$ minutes is a binomial variate with parameters $q_{i+1}$ and $ N-m_i$ . What I do not understand is how we can deal with probabilistically changing parameter $m_i$ . Or, is there some better way of tackling the problem? Thanking you in anticipation!","Suppose there are a total of balloons in a closed room out of which n are blue and the rest are red. After every unit of time,say a minute, any two balloons collide with independent probability .The rule is when a red and a blue balloon  collide the blue one turns red; in all other cases nothing changes. What is the distribution of the number of red balloons after minutes? Here are my thoughts about the problem: If is the number of red balloons after minutes, then the probability that a blue balloon will have become red after minutes is given by Hence the  probability that of there being red balloons after minutes is a binomial variate with parameters and . What I do not understand is how we can deal with probabilistically changing parameter . Or, is there some better way of tackling the problem? Thanking you in anticipation!",N p t m_i i q_{i+1} i+1 1-\prod_{k=0}^{i}(1-p)^{(N-m_i)}. j i+1 q_{i+1}  N-m_i m_i,['probability']
26,A subsequence of a Markov chain is a Markov chain,A subsequence of a Markov chain is a Markov chain,,"How to show it? In other words, I want to show that if $  \{X_n\}$ is a Markov chain then for every $ n\in\mathbb{N} $ and $ 1\le i_1<\dots<i_k\le n $ such that $P(X_{i_1}=x_1,\dots ,X_{i_k}=x_k)>0 $ it holds that $ P(X_{n+1}=x |X_{i_1}=x_1,\dots ,X_{i_k}=x_k)=P(X_{n+1}=x |X_{i_k}=x_k) $ I have tried to prove it by induction on $n$ and by using the formula $ P(X_{n+1}=x|A)= \sum_{a} P(X_n=a|A)P(X_{n+1}=x|A,X_n=a)$ where $A=\{X_{i_1}=x_1,\dots ,X_{i_k}=x_k\}$ , but the expression $P(X_{n+1}=x|A,X_n=a)$ isn't any better. Another attempt was to ""fill the holes"": let $\{j_1,\dots,j_{m}\}=\{1,\dots,n\}\setminus\{i_1,\dots i_k\}$ so $\\ P(X_{n+1}=x|A)=\sum_{b_1,\dots , b_m}P(X_{n+1}=x|A,X_{j_1}=b_1, \dots ,X_{j_m}=b_m)P(X_{j_1}=b_1, \dots ,X_{j_m}=b_m|A) $ but again I didn't know how to deal with the second expression.","How to show it? In other words, I want to show that if is a Markov chain then for every and such that it holds that I have tried to prove it by induction on and by using the formula where , but the expression isn't any better. Another attempt was to ""fill the holes"": let so but again I didn't know how to deal with the second expression.","  \{X_n\}  n\in\mathbb{N}   1\le i_1<\dots<i_k\le n  P(X_{i_1}=x_1,\dots ,X_{i_k}=x_k)>0   P(X_{n+1}=x |X_{i_1}=x_1,\dots ,X_{i_k}=x_k)=P(X_{n+1}=x |X_{i_k}=x_k)  n  P(X_{n+1}=x|A)= \sum_{a} P(X_n=a|A)P(X_{n+1}=x|A,X_n=a) A=\{X_{i_1}=x_1,\dots ,X_{i_k}=x_k\} P(X_{n+1}=x|A,X_n=a) \{j_1,\dots,j_{m}\}=\{1,\dots,n\}\setminus\{i_1,\dots i_k\} \\ P(X_{n+1}=x|A)=\sum_{b_1,\dots , b_m}P(X_{n+1}=x|A,X_{j_1}=b_1, \dots ,X_{j_m}=b_m)P(X_{j_1}=b_1, \dots ,X_{j_m}=b_m|A) ","['probability', 'probability-theory', 'markov-chains']"
27,Coin Flip Problem: a competition based on the probability of flipping heads,Coin Flip Problem: a competition based on the probability of flipping heads,,"I encountered a difficult coin problem and I wasn't sure how to solve the problem. A has 30 coins and B has 20 coins. Each coin is only flipped once, and the winner is the individual which received the most amount of heads. If both individuals receive the same amount of heads, A wins. What is the probability that B wins? I tried searching online but was unable to find any questions of this type. Given my lack of mathematical background, I tried to rely on my intuition. Because both individuals have the same probability of flipping heads when it comes to the first 20 choices, we should only consider the possibility of flipping a head for coins 21-30 for A . However, I believe this to be incorrect, so I would love to hear what the community thinks on this question. Thank you very much for your help!","I encountered a difficult coin problem and I wasn't sure how to solve the problem. A has 30 coins and B has 20 coins. Each coin is only flipped once, and the winner is the individual which received the most amount of heads. If both individuals receive the same amount of heads, A wins. What is the probability that B wins? I tried searching online but was unable to find any questions of this type. Given my lack of mathematical background, I tried to rely on my intuition. Because both individuals have the same probability of flipping heads when it comes to the first 20 choices, we should only consider the possibility of flipping a head for coins 21-30 for A . However, I believe this to be incorrect, so I would love to hear what the community thinks on this question. Thank you very much for your help!",,"['probability', 'combinatorics', 'permutations', 'recreational-mathematics', 'problem-solving']"
28,Compute the expected number of tiles needed filled to fill a row in a grid,Compute the expected number of tiles needed filled to fill a row in a grid,,"I want to compute the expected number of tiles I would have to fill to fill a row of $n$ tiles in a $n\times k$ -grid. No tiles can be filled more than once. In other words, if we fill a tile in a $n\times k$ -grid each turn with uniform probability and if $X$ is the number of turns needed to fill a row of $n$ tiles in the grid, what is $E[X]$ ? I have tried with some small examples. For example for a $2\times 3$ -grid, I reason as follows:  It does not matter which tile we fill first.  Then it is a one in five chance to pick the same row as the first one, so the probability of filling a row in two turns is $\frac{1}{5}$ . To complete a row in three turns, we need to fill a tile in a different row, and then in one of the same. To complete a row in four turns, we need to fill a tile in each different row, then any tile we fill will complete a row.  We get the following table: $$\begin{array}{c|c|}     & \text{Probability to fill a row in $x$ turns} \\ \hline \text{P(X=2)} & \frac{1}{5} \\ \hline \text{P(X=3)} & \frac{4}{5}\cdot\frac{2}{4} \\ \hline \text{P(X=4)} & \frac{4}{5}\cdot\frac{2}{4}\cdot1 \end{array}$$ From here we can calculate the expected value as $E[X] = 2\cdot\frac{1}{5}+3\cdot\frac{2}{5}+4\cdot\frac{2}{5} = \frac{16}{5}$ , so we expect to complete a row in a little more than 3 turns. It quickly gets convoluted with larger examples though, and I can't find a pattern. I know factorials in the denominators are involved in probabilities, because the number of tiles to choose to fill decreases by one each time. I have not been able to find any similar sounding questions. In this question they answer something related, namely what the probability of filling a row of 10 after 20 turns in a $7\times10$ -grid. I feel like this might be of some help, but I am not able to generalize the solution provided there. Furthermore this does not answer what the expected number of turns to fill a row in a given grid is. It would also be interesting to see what kind of probability distribution this process has. Intuitively I think this shares some similarities with the geometric distribution, but not directly. I thought of this problem when doing a picture puzzle, and wondered how many puzzle pieces one would need to expect a row to be filled.","I want to compute the expected number of tiles I would have to fill to fill a row of tiles in a -grid. No tiles can be filled more than once. In other words, if we fill a tile in a -grid each turn with uniform probability and if is the number of turns needed to fill a row of tiles in the grid, what is ? I have tried with some small examples. For example for a -grid, I reason as follows:  It does not matter which tile we fill first.  Then it is a one in five chance to pick the same row as the first one, so the probability of filling a row in two turns is . To complete a row in three turns, we need to fill a tile in a different row, and then in one of the same. To complete a row in four turns, we need to fill a tile in each different row, then any tile we fill will complete a row.  We get the following table: From here we can calculate the expected value as , so we expect to complete a row in a little more than 3 turns. It quickly gets convoluted with larger examples though, and I can't find a pattern. I know factorials in the denominators are involved in probabilities, because the number of tiles to choose to fill decreases by one each time. I have not been able to find any similar sounding questions. In this question they answer something related, namely what the probability of filling a row of 10 after 20 turns in a -grid. I feel like this might be of some help, but I am not able to generalize the solution provided there. Furthermore this does not answer what the expected number of turns to fill a row in a given grid is. It would also be interesting to see what kind of probability distribution this process has. Intuitively I think this shares some similarities with the geometric distribution, but not directly. I thought of this problem when doing a picture puzzle, and wondered how many puzzle pieces one would need to expect a row to be filled.","n n\times k n\times k X n E[X] 2\times 3 \frac{1}{5} \begin{array}{c|c|} 
   & \text{Probability to fill a row in x turns} \\ \hline
\text{P(X=2)} & \frac{1}{5} \\ \hline
\text{P(X=3)} & \frac{4}{5}\cdot\frac{2}{4} \\ \hline
\text{P(X=4)} & \frac{4}{5}\cdot\frac{2}{4}\cdot1
\end{array} E[X] = 2\cdot\frac{1}{5}+3\cdot\frac{2}{5}+4\cdot\frac{2}{5} = \frac{16}{5} 7\times10","['probability', 'combinatorics', 'recreational-mathematics', 'puzzle', 'expected-value']"
29,Proof of ${ \prod_{i=0}^{n}{x_i} < \overline{x}^{n} }$,Proof of,{ \prod_{i=0}^{n}{x_i} < \overline{x}^{n} },"Problem Definition: I was studying randomized algorithms and the following appeared: ${ 1- \prod_{i=0}^{N}{(1- {y_i})} \ge  \beta_k {z_j} }$ We also know that ${ {y_i} + ... + {y_k} \ge {z_j} }$ And ${ {y_i},{z_j} \in [0,1] }$ And the following was written: ""The expression on the left is minimized when ${ {y_i} = {z_j}/k}$ "" by minimizing, it means: ${ 1- \prod_{i=0}^{N}{(1- {y_i})} \ge  1- \prod_{i=0}^{N}{(1- {{z_j}/k})}  }$ (Randomized Algorithms, Montwani && Raghavn; page 106, 107). My reasoning, first try: So, I figure that to minimize ${ 1- \prod_{i=0}^{N}{(1- {y_i})} }$ you need to minimize ${{y_i}}$ Now, At the very least: ${ {y_i} + ... + {y_k} \ge {z_j} }$ meaning, ${z_j/k}$ is the minimum average possible of all the y. ${z_j/k}$ can't then be always smaller than ${y_i}$ . Ok, so that didn't work... So, It seems to me that the only way possible out of this is if: ${ \prod_{i=0}^{n}{x_i} <  \overline{x}^{ n} }$ holds as a general property and if ${x_i}$ in this example would be ${1-y_i}$ My apologies if anything is wrongly explained or out of what's normal around mathematicians and this website, I'm fairly modest at math! Thanks for your help! I've search quite a bit, but I don't seem to find a proof about it or any mention. It's also hard to google math. Can you help me?","Problem Definition: I was studying randomized algorithms and the following appeared: We also know that And And the following was written: ""The expression on the left is minimized when "" by minimizing, it means: (Randomized Algorithms, Montwani && Raghavn; page 106, 107). My reasoning, first try: So, I figure that to minimize you need to minimize Now, At the very least: meaning, is the minimum average possible of all the y. can't then be always smaller than . Ok, so that didn't work... So, It seems to me that the only way possible out of this is if: holds as a general property and if in this example would be My apologies if anything is wrongly explained or out of what's normal around mathematicians and this website, I'm fairly modest at math! Thanks for your help! I've search quite a bit, but I don't seem to find a proof about it or any mention. It's also hard to google math. Can you help me?","{ 1- \prod_{i=0}^{N}{(1- {y_i})} \ge  \beta_k {z_j} } { {y_i} + ... + {y_k} \ge {z_j} } { {y_i},{z_j} \in [0,1] } { {y_i} = {z_j}/k} { 1- \prod_{i=0}^{N}{(1- {y_i})} \ge  1- \prod_{i=0}^{N}{(1- {{z_j}/k})}  } { 1- \prod_{i=0}^{N}{(1- {y_i})} } {{y_i}} { {y_i} + ... + {y_k} \ge {z_j} } {z_j/k} {z_j/k} {y_i} { \prod_{i=0}^{n}{x_i} <  \overline{x}^{ n} } {x_i} {1-y_i}","['calculus', 'linear-algebra', 'probability', 'probability-theory', 'algorithms']"
30,Computing the cdf of some Discrete Distribution...,Computing the cdf of some Discrete Distribution...,,"I'm trying to find the cdf of the following discrete distribution: $$f(k)=\frac{(1-\rho )^2 \rho ^{k-1}}{\left(1-\rho ^k\right) \left(1-\rho ^{k+1}\right)}+\frac{(1-\rho ) \rho ^{M-1}}{1-\rho ^M}$$ with domain of support $$k\in \{1,...,M-1\}, k < M, \mbox{and}\ M \in Z.\ \mbox{Also}, 0<\rho<1.$$ I know its a proper pmf because, when $M=10$ , I can compute $$\sum _{k=1}^9 \left(\frac{(1-\rho )^2 \rho ^{k-1}}{\left(1-\rho ^k\right) \left(1-\rho ^{k+1}\right)}\right)+\frac{(1-\rho ) \rho ^{9}}{1-\rho ^{10}} = 1.$$ I'd like to compute the cdf, but I simply don't know how to do this. I can compute the pmf from the cdf for other distributions, but I can't do it in reverse. Any help would be greatly appreciated.","I'm trying to find the cdf of the following discrete distribution: with domain of support I know its a proper pmf because, when , I can compute I'd like to compute the cdf, but I simply don't know how to do this. I can compute the pmf from the cdf for other distributions, but I can't do it in reverse. Any help would be greatly appreciated.","f(k)=\frac{(1-\rho )^2 \rho ^{k-1}}{\left(1-\rho ^k\right) \left(1-\rho ^{k+1}\right)}+\frac{(1-\rho ) \rho ^{M-1}}{1-\rho ^M} k\in \{1,...,M-1\}, k < M, \mbox{and}\ M \in Z.\ \mbox{Also}, 0<\rho<1. M=10 \sum _{k=1}^9 \left(\frac{(1-\rho )^2 \rho ^{k-1}}{\left(1-\rho ^k\right) \left(1-\rho ^{k+1}\right)}\right)+\frac{(1-\rho ) \rho ^{9}}{1-\rho ^{10}} = 1.","['probability', 'probability-distributions', 'cumulative-distribution-functions']"
31,Verify the formula of bivariate Poisson distribution,Verify the formula of bivariate Poisson distribution,,"suppose that $X$ has a Poisson distribution with the rate $\lambda $ and suppose the conditional distribution of $Y$ , given $X=x$ , is binomial with parameters $x$ and $p$ . Problem: Let $Z=X-Y$ and $q=1-p$ , verify $$p _{Y,Z}(y,z)=\frac{(p \lambda)^y}{y!} e^{-p \lambda} \frac{(q \lambda)^z)}{z!} e^{-q \lambda}$$ for non-negative integers $y$ and $z$ . I know that \begin{align} p_{Y,Z}(y,z) & =P(Y=y,Z=z)  \\ &= P(Y=y,X=y+z)  \\& =P(Y=y \mid X=y+z) P(X=y+z) \end{align} But I am still not sure how to tackle this problem, any help is appreciated.","suppose that has a Poisson distribution with the rate and suppose the conditional distribution of , given , is binomial with parameters and . Problem: Let and , verify for non-negative integers and . I know that But I am still not sure how to tackle this problem, any help is appreciated.","X \lambda  Y X=x x p Z=X-Y q=1-p p _{Y,Z}(y,z)=\frac{(p \lambda)^y}{y!} e^{-p \lambda} \frac{(q \lambda)^z)}{z!} e^{-q \lambda} y z \begin{align} p_{Y,Z}(y,z) & =P(Y=y,Z=z)  \\ &= P(Y=y,X=y+z)  \\& =P(Y=y \mid X=y+z) P(X=y+z) \end{align}","['probability', 'probability-distributions']"
32,Cat chasing mouse on a straight line coin toss,Cat chasing mouse on a straight line coin toss,,"I recently got keen on ""brainteasers"" and now I am trying to solve and code my daily one. A cat is chasing a mouse in a 1-D space, for example, a tunnel. The mouse is Y meters away from its hole and the cat is further X meters behind the mouse. In every turn, with an equal probability of 1/3, the mouse moves 1 meter forward to it's hole OR the cat moves 2 meters forward OR both of them move +1 meter forward. What is the probability of the mouse getting to its hole or not? What I am trying is to approach by an absorbing Markov chain but I am a bit confused how exactly to formulate it and generalize it in the case of an  asymmetric dice toss each turn to determine who moves and by how far? Could you please recommend any interesting graph theory basics directly applicable to the problem?","I recently got keen on ""brainteasers"" and now I am trying to solve and code my daily one. A cat is chasing a mouse in a 1-D space, for example, a tunnel. The mouse is Y meters away from its hole and the cat is further X meters behind the mouse. In every turn, with an equal probability of 1/3, the mouse moves 1 meter forward to it's hole OR the cat moves 2 meters forward OR both of them move +1 meter forward. What is the probability of the mouse getting to its hole or not? What I am trying is to approach by an absorbing Markov chain but I am a bit confused how exactly to formulate it and generalize it in the case of an  asymmetric dice toss each turn to determine who moves and by how far? Could you please recommend any interesting graph theory basics directly applicable to the problem?",,"['probability', 'graph-theory', 'markov-chains', 'random-walk']"
33,A supremum of independent increments is independent of the brownian motion,A supremum of independent increments is independent of the brownian motion,,"I am now having difficulty in showing that $\sup_{t \geq 1} (W_t - W_1)$ is independent of $W_1$ , where the $W_i$ is a Brownian motion. I know that $W_t - W_1$ is independent of $W_1$ for all $t \geq 1$ due to the independent increment property. But, how can I show that the supremum is also independent of $W_1$ ? I thought that it suffices to show that $\sup_{t \geq 1} (W_t - W_1)$ is $\sigma((W_t - W_1)_{t\geq1})$ -measurable, because $\sigma((W_t - W_1)_{t\geq1})$ is independent of $\sigma(W_1)$ . Thus, instead of any Borel set, it suffices to show that the set $\big(\sup_{t \geq 1} (W_t - W_1) > a \big)$ is in $\sigma((W_t - W_1)_{t\geq1})$ for any $a \in \mathbb{R}.$ First, let me define, as C, the set on which $(W_t-W_1)_{t\geq1}$ has continuous sample paths. Then, clearly $\mathbb{P}(C)=1$ due to the defining property of Brownian motion, where $\mathbb{P}$ is the underlying probability measure. Now, I tried to prove in this way : $$\big(\sup_{t \geq 1} (W_t - W_1) > a \big) = \bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C \bigg) \sqcup \bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C^\complement \bigg)$$ For $\bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C \bigg),$ using continuity, I can take rationals so that the set $\big(\sup_{t \geq 1} (W_t - W_1) > a \big)$ can be expressed as a countable union of sets contained in $\sigma(W_t - W_1)_{t\geq1}.$ Now, it remains to show that $C$ and $\bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C^\complement \bigg)$ are both contained in $\sigma(W_t - W_1)_{t\geq1}.$ But, then, I feel that there appears some delicacy that I find it somewhat hard to deal with. How can I show rigorously that $C$ is contained in $\sigma(W_t - W_1)_{t\geq1}.$ ? Assuming that $C$ is in $\sigma(W_t - W_1)_{t\geq1},$ $C^\complement$ is also in $\sigma(W_t - W_1)_{t\geq1}, $ and the measure of $C^\complement$ is evidently zero. Then, I feel that I need to use the completeness of the underlying probability measure $\mathbb{P}$ to deduce that $\bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C^\complement \bigg)$ is contained in $\sigma(W_t - W_1)_{t\geq1}.$ If my guess were right, then, if needed at all, on which probability space(triple) is the completion taken? Thank you so much for reading and anything correcting my logic will be enormously appreciated!","I am now having difficulty in showing that is independent of , where the is a Brownian motion. I know that is independent of for all due to the independent increment property. But, how can I show that the supremum is also independent of ? I thought that it suffices to show that is -measurable, because is independent of . Thus, instead of any Borel set, it suffices to show that the set is in for any First, let me define, as C, the set on which has continuous sample paths. Then, clearly due to the defining property of Brownian motion, where is the underlying probability measure. Now, I tried to prove in this way : For using continuity, I can take rationals so that the set can be expressed as a countable union of sets contained in Now, it remains to show that and are both contained in But, then, I feel that there appears some delicacy that I find it somewhat hard to deal with. How can I show rigorously that is contained in ? Assuming that is in is also in and the measure of is evidently zero. Then, I feel that I need to use the completeness of the underlying probability measure to deduce that is contained in If my guess were right, then, if needed at all, on which probability space(triple) is the completion taken? Thank you so much for reading and anything correcting my logic will be enormously appreciated!","\sup_{t \geq 1} (W_t - W_1) W_1 W_i W_t - W_1 W_1 t \geq 1 W_1 \sup_{t \geq 1} (W_t - W_1) \sigma((W_t - W_1)_{t\geq1}) \sigma((W_t - W_1)_{t\geq1}) \sigma(W_1) \big(\sup_{t \geq 1} (W_t - W_1) > a \big) \sigma((W_t - W_1)_{t\geq1}) a \in \mathbb{R}. (W_t-W_1)_{t\geq1} \mathbb{P}(C)=1 \mathbb{P} \big(\sup_{t \geq 1} (W_t - W_1) > a \big) = \bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C \bigg) \sqcup \bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C^\complement \bigg) \bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C \bigg), \big(\sup_{t \geq 1} (W_t - W_1) > a \big) \sigma(W_t - W_1)_{t\geq1}. C \bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C^\complement \bigg) \sigma(W_t - W_1)_{t\geq1}. C \sigma(W_t - W_1)_{t\geq1}. C \sigma(W_t - W_1)_{t\geq1}, C^\complement \sigma(W_t - W_1)_{t\geq1},  C^\complement \mathbb{P} \bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C^\complement \bigg) \sigma(W_t - W_1)_{t\geq1}.","['real-analysis', 'probability', 'measure-theory', 'brownian-motion']"
34,Probability that an integral of brownian motion is greater than $\frac{2}{\sqrt{3}}$,Probability that an integral of brownian motion is greater than,\frac{2}{\sqrt{3}},"Compute the probability $\mathbb{P}\big(\int_0^1 W(t) dt > \frac{2}{\sqrt 3} \big)$ Clearly, as I am not sure about where to start I am confused about how the $W(t)$ relates to an integral and how this number could relate to a probability. 1) Should I evaluate the integral first? Not sure how to do this. 2) Should I square both sides (risky)?","Compute the probability Clearly, as I am not sure about where to start I am confused about how the relates to an integral and how this number could relate to a probability. 1) Should I evaluate the integral first? Not sure how to do this. 2) Should I square both sides (risky)?",\mathbb{P}\big(\int_0^1 W(t) dt > \frac{2}{\sqrt 3} \big) W(t),"['probability', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion', 'stochastic-integrals']"
35,Bertrand's Paradox and uniform distribution,Bertrand's Paradox and uniform distribution,,"This is a problem from Hans-Otto Georgii's textbook. Recall the situation of Bertrand’s paradox, and let X be the distance of the random chord to the centre of the circle. Find the distribution density of X if (a) the midpoint of the chord is uniformly distributed on the disk $|x|<r$ , (b) the angle under which the chord is seen from the centre of the circle is uniformly distributed on the interval $\Omega_2$ = $[0,\pi]$ . The solutions are given as: a. the distribution density of X on [0,r] is $\rho_1(x)$ = $2x/r^2$ . b. $\rho_2(x) = 2/(\pi*\sqrt(r^2 - x^2))$ , x $\in [0,r]$ . edit: the overall approach is to derive cdf then differentiate. a. cdf = $\pi x^2/ \pi r^2$ ; pdf = $2x/r^2$ . my thoughts for b: The probability formula for continuous uniform distribution in my textbook: $U_\Omega(A) = \lambda^n(A) / \lambda^n(\Omega)$ . So I tried expressing cdf like some probability: $\Omega = [0,\pi]$ , so $\lambda^n(\Omega) = \pi$ . A is the range of angle POQ when the distance is in $[0,x]$ . PQ is the chord. A = $2arccos(x/r)$ for x in $[0,x]$ . cdf = $2arccos(x/r) / \pi$ ; pdf = $- 2 / \pi \sqrt(r^2 - x^2)$ . However there is an extra negative sign here. could anybody help correct my workings?","This is a problem from Hans-Otto Georgii's textbook. Recall the situation of Bertrand’s paradox, and let X be the distance of the random chord to the centre of the circle. Find the distribution density of X if (a) the midpoint of the chord is uniformly distributed on the disk , (b) the angle under which the chord is seen from the centre of the circle is uniformly distributed on the interval = . The solutions are given as: a. the distribution density of X on [0,r] is = . b. , x . edit: the overall approach is to derive cdf then differentiate. a. cdf = ; pdf = . my thoughts for b: The probability formula for continuous uniform distribution in my textbook: . So I tried expressing cdf like some probability: , so . A is the range of angle POQ when the distance is in . PQ is the chord. A = for x in . cdf = ; pdf = . However there is an extra negative sign here. could anybody help correct my workings?","|x|<r \Omega_2 [0,\pi] \rho_1(x) 2x/r^2 \rho_2(x) = 2/(\pi*\sqrt(r^2 - x^2)) \in [0,r] \pi x^2/ \pi r^2 2x/r^2 U_\Omega(A) = \lambda^n(A) / \lambda^n(\Omega) \Omega = [0,\pi] \lambda^n(\Omega) = \pi [0,x] 2arccos(x/r) [0,x] 2arccos(x/r) / \pi - 2 / \pi \sqrt(r^2 - x^2)",['probability']
36,"Compute $E\left[ \|U\|^2 \mid U+V \in S , V\in S \right]$ is $U,V$ are standard normal, $S=\{ x \in \mathbb{R}^k: x_1 \le x_2 \le ... \le x_k \}$","Compute  is  are standard normal,","E\left[ \|U\|^2 \mid U+V \in S , V\in S \right] U,V S=\{ x \in \mathbb{R}^k: x_1 \le x_2 \le ... \le x_k \}","Let $U \in \mathbb{R}^k$ and $V\in \mathbb{R}^k$ be two independent standard normal vectors (i.e., $U \sim \mathcal{N}(0,I)$ and $U \sim \mathcal{N}(0,I)$ ).   Define a set $S$ as \begin{align}  S=\{ x \in \mathbb{R}^k: x_1 \le x_2 \le x_3 \le ... \le x_k  \} \end{align} We are interested in computing the following conditional expectation \begin{align} E\left[ \|U\|^2 \mid   U+V \in  S , V\in S \right]. \end{align} My guess is that, most likely, there is no closed-form expression, so an upper bound would be also fine. One upper bound I that I tried is via Cauchy-Schwarz: \begin{align} E\left[ \|U\|^2 \mid   U+V \in  S , V\in S \right]&= \frac{E\left[ \|U\|^2 1_{ \{  U+V \in  S , V\in S \}} \right] }{P [  U+V \in  S , V\in S ]}\\ &\le \frac{ \sqrt{E\left[ \|U\|^4 \right]} \sqrt{ P [  U+V \in  S , V\in S ]} }{P [  U+V \in  S , V\in S ]}\\ &= \frac{ \sqrt{E\left[ \|U\|^4 \right]}  }{\sqrt{ P [  U+V \in  S , V\in S ]}}. \end{align} Now computing $E\left[ \|U\|^4 \right]$ is simple.  However, $P [  U+V \in  S , V\in S ]$ is not so much.   I tried using inclusion-exclusion principle \begin{align}  P [  U+V \in  S , V\in S ]&=   P [  U+V \in  S  ]+  P [   V\in S ]- P [  U+V \in  S \text{ or } V\in S ]\\ &= \frac{2}{k!}-P [  U+V \in  S \text{ or } V\in S ] \end{align} where we used that $P [  U+V \in  S  ]=  P [   V\in S ]=\frac{1}{k!}$","Let and be two independent standard normal vectors (i.e., and ).   Define a set as We are interested in computing the following conditional expectation My guess is that, most likely, there is no closed-form expression, so an upper bound would be also fine. One upper bound I that I tried is via Cauchy-Schwarz: Now computing is simple.  However, is not so much.   I tried using inclusion-exclusion principle where we used that","U \in \mathbb{R}^k V\in \mathbb{R}^k U \sim \mathcal{N}(0,I) U \sim \mathcal{N}(0,I) S \begin{align} 
S=\{ x \in \mathbb{R}^k: x_1 \le x_2 \le x_3 \le ... \le x_k  \}
\end{align} \begin{align}
E\left[ \|U\|^2 \mid   U+V \in  S , V\in S \right].
\end{align} \begin{align}
E\left[ \|U\|^2 \mid   U+V \in  S , V\in S \right]&= \frac{E\left[ \|U\|^2 1_{ \{  U+V \in  S , V\in S \}} \right] }{P [  U+V \in  S , V\in S ]}\\
&\le \frac{ \sqrt{E\left[ \|U\|^4 \right]} \sqrt{ P [  U+V \in  S , V\in S ]} }{P [  U+V \in  S , V\in S ]}\\
&= \frac{ \sqrt{E\left[ \|U\|^4 \right]}  }{\sqrt{ P [  U+V \in  S , V\in S ]}}.
\end{align} E\left[ \|U\|^4 \right] P [  U+V \in  S , V\in S ] \begin{align}
 P [  U+V \in  S , V\in S ]&=   P [  U+V \in  S  ]+  P [   V\in S ]- P [  U+V \in  S \text{ or } V\in S ]\\
&= \frac{2}{k!}-P [  U+V \in  S \text{ or } V\in S ]
\end{align} P [  U+V \in  S  ]=  P [   V\in S ]=\frac{1}{k!}","['probability', 'conditional-expectation']"
37,Large deviation bound for squared norm of the sum of two random variables,Large deviation bound for squared norm of the sum of two random variables,,"I want to pose this question as general as possible and ask for reference of what to do in similar situations. I'll incrementally add details to narrow down the problem. I want to derive large deviation bound for $\| X + Y \|_2^2$ , where $X$ and $Y$ are $p$ -dimensional dependent vectors; I believe in my situation it is impossible to compute the quantiles of $Z = \| X + Y \|_2^2$ . Formally, I want to get something like $$ \mathbb{P}( \| X + Y \|_2^2 > \lambda(x)) \le e^{-x}, $$ where $\lambda(x)$ is a deterministic function of $x$ and characteristics of $X$ and $Y$ . Are there any general techniques, approaches or ways of thinking in this most generic situation? Detail 1. I know that $Y \sim \mathcal{N}(0, \mathbf\Sigma)$ . Detail 2. I know that $\mathbb{E} \| X \|_2^2 \le \Delta$ , for fixed $\Delta$ . Detail 3. I know that the magnitude of $Y$ is much higher than that of $X$ , but I cannot formally deduce the above-mentioned inequality to something similar to $$ \mathbb{P}(\| Y \|_2^2 \ge \lambda_Y(x)) \le e^{-x}.  $$ However, I know that $\lambda(x)$ should be large only because of $Y$ and not $X$ . Notice that if $\lambda(x)$ is allowed to be random then the choice $\lambda(x) = \lambda_Y(x) + \| X \|_2 + 2X^\top Y$ would do the job just fine. I'd appreciate any ideas, suggestions and/or comments.","I want to pose this question as general as possible and ask for reference of what to do in similar situations. I'll incrementally add details to narrow down the problem. I want to derive large deviation bound for , where and are -dimensional dependent vectors; I believe in my situation it is impossible to compute the quantiles of . Formally, I want to get something like where is a deterministic function of and characteristics of and . Are there any general techniques, approaches or ways of thinking in this most generic situation? Detail 1. I know that . Detail 2. I know that , for fixed . Detail 3. I know that the magnitude of is much higher than that of , but I cannot formally deduce the above-mentioned inequality to something similar to However, I know that should be large only because of and not . Notice that if is allowed to be random then the choice would do the job just fine. I'd appreciate any ideas, suggestions and/or comments.","\| X + Y \|_2^2 X Y p Z = \| X + Y \|_2^2 
\mathbb{P}( \| X + Y \|_2^2 > \lambda(x)) \le e^{-x},
 \lambda(x) x X Y Y \sim \mathcal{N}(0, \mathbf\Sigma) \mathbb{E} \| X \|_2^2 \le \Delta \Delta Y X 
\mathbb{P}(\| Y \|_2^2 \ge \lambda_Y(x)) \le e^{-x}. 
 \lambda(x) Y X \lambda(x) \lambda(x) = \lambda_Y(x) + \| X \|_2 + 2X^\top Y","['probability', 'statistics', 'normal-distribution', 'concentration-of-measure', 'large-deviation-theory']"
38,How to calculate the probability of matching ONLY the Thunderball?,How to calculate the probability of matching ONLY the Thunderball?,,"I'm looking for an explanation of a probability value. The UK has a lottery game called Thunderball. The player chooses 5 Main Numbers from 1 to 39 and also 1 Thunderball from 1 to 14. The Thunderball machine does the same and if all of your 6 numbers match then you win the jackpot. Odds for Thunderball Game I understand that the odds of winning the jackpot are 1 in 8,060,598. What I don't understand is why the odds of matching ONLY the Thunderball are 1 in 29? Surely it should be 1 in 14? For more info on the Thunderball game, please visit Wikipedia at: https://en.wikipedia.org/wiki/National_Lottery_(United_Kingdom)#Thunderball Thank you for your help.","I'm looking for an explanation of a probability value. The UK has a lottery game called Thunderball. The player chooses 5 Main Numbers from 1 to 39 and also 1 Thunderball from 1 to 14. The Thunderball machine does the same and if all of your 6 numbers match then you win the jackpot. Odds for Thunderball Game I understand that the odds of winning the jackpot are 1 in 8,060,598. What I don't understand is why the odds of matching ONLY the Thunderball are 1 in 29? Surely it should be 1 in 14? For more info on the Thunderball game, please visit Wikipedia at: https://en.wikipedia.org/wiki/National_Lottery_(United_Kingdom)#Thunderball Thank you for your help.",,"['probability', 'combinatorics']"
39,"Probability of guessing $0 \le k \le 6$ numbers and their positions correctly, if 6 numbers are drawn from a pool of 49 numbers.","Probability of guessing  numbers and their positions correctly, if 6 numbers are drawn from a pool of 49 numbers.",0 \le k \le 6,"Suppose 6 numbers are drawn one after another from a pool of 49 distinct  numbers. Once a number has been drawn, it is not put back in the pool. The number itself and its position are noted. You are now asked to guess 6 distinct numbers from 1 to 49. What is the probability that $0 \le k \le 6$ of the numbers you guessed are the correct number and in the correct position and that the other $6-k$ numbers are either in the wrong position, or not among the drawn numbers? I'm not sure what the combinatorial argument is, to calculate this probability correctly. There are $49^\underline{6} = 49*48*\dotsc*44$ possible ways to choose 6 numbers and hence the probability of guessing all six numbers correctly (in the correct order) is $1/49^\underline{6}$ . However, what happens, for example, if $k=4$ ? Do I have to simply multiply this probability by the number of ways to select 4 out of 6 numbers and the number of ways to choose 2 numbers from the remaining 43 numbers or do I still have to take the ordering of these 4 or 2 numbers into account? I'm not sure which of the following two terms is correct or if they are both equally wrong (for $k = 4$ ): \begin{align*} \frac{{6 \choose 4}{43 \choose 2}}{49^\underline{6}}, \quad \frac{{6 \choose 4}4!{43 \choose 2}2!}{49^\underline{6}} \end{align*} For clarification: Let 1,2,3,4,5,6 be the numbers drawn from the pool in this order. If $k=6$ then the only valid guess is 1,2,3,4,5,6 ( 2,1,3,4,5,6 would be not) If $k=3$ then 1,2,3,6,4,5 , 1,2,3,43,20,10 , 43,2,3,4,20,10 , 43,20,10,4,5,6 are all valid but a guess like 1,2,4,43,20,10 is not (but would be for $k=2$ ). If $k=0$ then all numbers from 1 to 6 must be at different positions or not included in the guess.","Suppose 6 numbers are drawn one after another from a pool of 49 distinct  numbers. Once a number has been drawn, it is not put back in the pool. The number itself and its position are noted. You are now asked to guess 6 distinct numbers from 1 to 49. What is the probability that of the numbers you guessed are the correct number and in the correct position and that the other numbers are either in the wrong position, or not among the drawn numbers? I'm not sure what the combinatorial argument is, to calculate this probability correctly. There are possible ways to choose 6 numbers and hence the probability of guessing all six numbers correctly (in the correct order) is . However, what happens, for example, if ? Do I have to simply multiply this probability by the number of ways to select 4 out of 6 numbers and the number of ways to choose 2 numbers from the remaining 43 numbers or do I still have to take the ordering of these 4 or 2 numbers into account? I'm not sure which of the following two terms is correct or if they are both equally wrong (for ): For clarification: Let 1,2,3,4,5,6 be the numbers drawn from the pool in this order. If then the only valid guess is 1,2,3,4,5,6 ( 2,1,3,4,5,6 would be not) If then 1,2,3,6,4,5 , 1,2,3,43,20,10 , 43,2,3,4,20,10 , 43,20,10,4,5,6 are all valid but a guess like 1,2,4,43,20,10 is not (but would be for ). If then all numbers from 1 to 6 must be at different positions or not included in the guess.","0 \le k \le 6 6-k 49^\underline{6} = 49*48*\dotsc*44 1/49^\underline{6} k=4 k = 4 \begin{align*}
\frac{{6 \choose 4}{43 \choose 2}}{49^\underline{6}}, \quad \frac{{6 \choose 4}4!{43 \choose 2}2!}{49^\underline{6}}
\end{align*} k=6 k=3 k=2 k=0","['probability', 'combinatorics']"
40,Can we take out an integrand random variable which does not depend on time from the stochastic integral?,Can we take out an integrand random variable which does not depend on time from the stochastic integral?,,"Let $Y$ is a ${\mathbb R}$ -valued random variable, $(X_{t})_{t \geq 0}$ is one-dimensional stochastic process and $(W_{t})_{t \geq 0}$ is a one-dimensional Brownian motion. Then is the following formula correct? $$ Y \int_{0}^{t}X_{s}{\rm d}W_{s}=\int_{0}^{t}YX_{s}{\rm d}W_{s}, \quad t \geq 0. $$ Here, these integrands $(X_{t})_{t \geq 0}$ and $(YX_{t})_{t \geq 0}$ have some conditions that allow the stochastic integrals to be defined.","Let is a -valued random variable, is one-dimensional stochastic process and is a one-dimensional Brownian motion. Then is the following formula correct? Here, these integrands and have some conditions that allow the stochastic integrals to be defined.","Y {\mathbb R} (X_{t})_{t \geq 0} (W_{t})_{t \geq 0} 
Y \int_{0}^{t}X_{s}{\rm d}W_{s}=\int_{0}^{t}YX_{s}{\rm d}W_{s}, \quad t \geq 0.
 (X_{t})_{t \geq 0} (YX_{t})_{t \geq 0}","['probability', 'stochastic-calculus', 'stochastic-integrals']"
41,"Random Walk on n+1 cycle, T is time such that walk returns to the initial vertex.","Random Walk on n+1 cycle, T is time such that walk returns to the initial vertex.",,"Random Walk on n+1 cycle, T is time such that walk returns to the initial vertex.  Find the probability of visiting every vertex prior to time T. Where walk moves clockwise w.p. $p \in (0,1)$ and counter-clockwise w.p. $(1-p)$ . This seems to be similar to gamblers ruin or any random walk with boundaries. My approach is to consider : $S_0 = k$ where $k = 0,1,\ldots,n$ It would move to $k-1$ with probability $1-p$ so then consider the probability of hitting $k+1$ before hitting $k$ and similarly, walk moves to $k+1$ with probability $p$ then consider probability of hitting $k-1$ before $k$ . Im not sure if this is the correct approach, it seems along the correct lines but not quite.","Random Walk on n+1 cycle, T is time such that walk returns to the initial vertex.  Find the probability of visiting every vertex prior to time T. Where walk moves clockwise w.p. and counter-clockwise w.p. . This seems to be similar to gamblers ruin or any random walk with boundaries. My approach is to consider : where It would move to with probability so then consider the probability of hitting before hitting and similarly, walk moves to with probability then consider probability of hitting before . Im not sure if this is the correct approach, it seems along the correct lines but not quite.","p \in (0,1) (1-p) S_0 = k k = 0,1,\ldots,n k-1 1-p k+1 k k+1 p k-1 k","['probability', 'random-walk']"
42,Explaining the concept of having data distributed in some probability distribution,Explaining the concept of having data distributed in some probability distribution,,"Cordially, can someone explain, in a plain simple way, what do we mean by saying ""input data are distributed according to some probability distribution"" Possibly this question sounds trivial to the community here but in fact I've never been able to understand it. I truly appreciate any answer.","Cordially, can someone explain, in a plain simple way, what do we mean by saying ""input data are distributed according to some probability distribution"" Possibly this question sounds trivial to the community here but in fact I've never been able to understand it. I truly appreciate any answer.",,"['probability', 'probability-distributions']"
43,Probability of more than k balls in any m buckets given n total balls,Probability of more than k balls in any m buckets given n total balls,,"Say there are 100 balls that are randomly distributed across 64 buckets, with the same probability of ending up in any bucket and trials are independent. What is the probability that at least one of the 64 buckets will have more than 20 balls? A similar problem to this is calculating the probability of a specific bucket having more than 20 balls, which can be solved using the survival function or CDF function of the binomial distribution: $1-\sum_{i=0}^{20} \binom{100}{i}(1/64)^{i}(1-1/64)^{100-i}=7.33\times10^{-18}$ However, I'm not sure how to bridge the gap to determine the probability of any bucket in our population having more than 20 balls. Thank you!","Say there are 100 balls that are randomly distributed across 64 buckets, with the same probability of ending up in any bucket and trials are independent. What is the probability that at least one of the 64 buckets will have more than 20 balls? A similar problem to this is calculating the probability of a specific bucket having more than 20 balls, which can be solved using the survival function or CDF function of the binomial distribution: However, I'm not sure how to bridge the gap to determine the probability of any bucket in our population having more than 20 balls. Thank you!",1-\sum_{i=0}^{20} \binom{100}{i}(1/64)^{i}(1-1/64)^{100-i}=7.33\times10^{-18},"['probability', 'binomial-distribution']"
44,"Approximate the probability of $n$, given the sum of $n$ stochastic variables.","Approximate the probability of , given the sum of  stochastic variables.",n n,"I've been given the following problem to solve (hastily translated to English) in an undergraduate course in probability theory: A small library has 46 running meters of books. The thickness of each book can be seen as independent stochastic variables which all have the expected value of 1.8cm and standard deviation 0.7cm. Approximate the probability of the library containing more than 2500 books. I'm certain it's an application of the central limit theorem but can't really get my head around it. I've started with some notation: given that $X_i$ is the thickness of book $i$ , we have that $\sum_{i=1}^nX_i=4600$ , $\mu=1.8$ and $\sigma=0.7$ . Via the central limit theorem one could approximate the probability of the sum of $n$ books thickness' being between $a$ and $b$ cm as $$P(a<\sum_{i=1}^nX_i\leq b)\approx\Phi\left(\frac{b-n\mu}{\sigma\sqrt{n}}\right)-\Phi\left(\frac{a-n\mu}{\sigma\sqrt{n}}\right)=\Phi\left(\frac{b-1.8n}{0.7\sqrt{n}}\right)-\Phi\left(\frac{a-1.8n}{0.7\sqrt{n}}\right)$$ but that's not really the probability I'm looking for since the total length is known (and $n$ not). Another different approach could be to let $Y_k$ denote the no. of books in meter $k$ and calculate $$P\left(\sum_{k=1}^{46}Y_k >2500\right)$$ given that $\sum_{i=1}^nX_i=4600$ but to do so with the given information one must formulate how $Y$ depends on $X$ and that I am unsure of. Do anyone have a solution?","I've been given the following problem to solve (hastily translated to English) in an undergraduate course in probability theory: A small library has 46 running meters of books. The thickness of each book can be seen as independent stochastic variables which all have the expected value of 1.8cm and standard deviation 0.7cm. Approximate the probability of the library containing more than 2500 books. I'm certain it's an application of the central limit theorem but can't really get my head around it. I've started with some notation: given that is the thickness of book , we have that , and . Via the central limit theorem one could approximate the probability of the sum of books thickness' being between and cm as but that's not really the probability I'm looking for since the total length is known (and not). Another different approach could be to let denote the no. of books in meter and calculate given that but to do so with the given information one must formulate how depends on and that I am unsure of. Do anyone have a solution?",X_i i \sum_{i=1}^nX_i=4600 \mu=1.8 \sigma=0.7 n a b P(a<\sum_{i=1}^nX_i\leq b)\approx\Phi\left(\frac{b-n\mu}{\sigma\sqrt{n}}\right)-\Phi\left(\frac{a-n\mu}{\sigma\sqrt{n}}\right)=\Phi\left(\frac{b-1.8n}{0.7\sqrt{n}}\right)-\Phi\left(\frac{a-1.8n}{0.7\sqrt{n}}\right) n Y_k k P\left(\sum_{k=1}^{46}Y_k >2500\right) \sum_{i=1}^nX_i=4600 Y X,"['probability', 'central-limit-theorem']"
45,subtlety around minimisation of expectation of an r.v,subtlety around minimisation of expectation of an r.v,,"I'm attempting the following questions The first question is fine. However i feel like things get interesting in the second question. Now i'm not too familiar with things like functionals but this kind of approach made sense to me the most because i feel as simplified solutions i have found overlook a subtlety and just say c) follows from b) by essentially noticing $\mathbb{E}(\mathbb{E}(Y|X)) = \mathbb{E}(Y)$ . As far as i'm aware $\mathbb{E}((Y-f(X))^2|X)$ returns a random variable and not a value in $\mathbb{R}$ . Where as $\mathbb{E}(Y-f(X))^2$ returns a value in $\mathbb{R}$ . If this is correct then what does it mean to minimise the random variable in b. ? Well we can deduce that $\mathbb{E}((Y-f(x))^2|X) = (f(x) - \mathbb{E}(Y|X))^2 - (\mathbb{E}(Y|X))^2 + E(Y^2|X)$ . Now if we let $\mathcal{F}$ denote the space of functions we want $f' \in \mathcal{F}$ that satisfies $(f'(x) - \mathbb{E}(Y|X))^2 - (\mathbb{E}(Y|X))^2 + E(Y^2|X) \leq (f(x) - \mathbb{E}(Y|X))^2 - (\mathbb{E}(Y|X))^2 + E(Y^2|X)$ for all $f \in \mathcal{F}$ . Now clearly $f'(x) = \mathbb{E}(Y|X)$ satisfies this as the square term is then $0$ . $\textbf{Key Result}$ : So let the random variable $F' =(f'(x) - \mathbb{E}(Y|X))^2 - (\mathbb{E}(Y|X))^2 + E(Y^2|X)$ where $f'(x) = \mathbb{E}(Y|X)$ and let the random variable $F = (f(x) - \mathbb{E}(Y|X))^2 - (\mathbb{E}(Y|X))^2 + E(Y^2|X)$ where $f$ is any function in $\mathcal{F}$ then i know it's always the case that $F' \leq F$ Now i can use the key result for part c. I know that $\mathbb{E}(Y-f(x))^2 = \mathbb{E}(\mathbb{E}((Y-f(x))|X)$ . For two random variables $X, Y$ its trivial that if $X \leq Y \Rightarrow \mathbb{E}(X) \leq \mathbb{E}(Y)$ . So again considering the space of functions $\mathcal{F}$ . Let $f' = \mathbb{E}(Y|X)$ and obtain $F'$ from $f'$ and $F$ from any other $f$ like we did before. Then i know that $F' \leq F$ and thus $\mathbb{E}(F') \leq \mathbb{E}(F)$ . So i can conclude that to minimize $(Y- f(X))^2$ we require $f(x) = \mathbb{E}(Y|X)$ . Firstly is my reasoning correct? If it is correct have i over complicated it and is there a simpler solution? Thanks.",I'm attempting the following questions The first question is fine. However i feel like things get interesting in the second question. Now i'm not too familiar with things like functionals but this kind of approach made sense to me the most because i feel as simplified solutions i have found overlook a subtlety and just say c) follows from b) by essentially noticing . As far as i'm aware returns a random variable and not a value in . Where as returns a value in . If this is correct then what does it mean to minimise the random variable in b. ? Well we can deduce that . Now if we let denote the space of functions we want that satisfies for all . Now clearly satisfies this as the square term is then . : So let the random variable where and let the random variable where is any function in then i know it's always the case that Now i can use the key result for part c. I know that . For two random variables its trivial that if . So again considering the space of functions . Let and obtain from and from any other like we did before. Then i know that and thus . So i can conclude that to minimize we require . Firstly is my reasoning correct? If it is correct have i over complicated it and is there a simpler solution? Thanks.,"\mathbb{E}(\mathbb{E}(Y|X)) = \mathbb{E}(Y) \mathbb{E}((Y-f(X))^2|X) \mathbb{R} \mathbb{E}(Y-f(X))^2 \mathbb{R} \mathbb{E}((Y-f(x))^2|X) = (f(x) - \mathbb{E}(Y|X))^2 - (\mathbb{E}(Y|X))^2 + E(Y^2|X) \mathcal{F} f' \in \mathcal{F} (f'(x) - \mathbb{E}(Y|X))^2 - (\mathbb{E}(Y|X))^2 + E(Y^2|X) \leq (f(x) - \mathbb{E}(Y|X))^2 - (\mathbb{E}(Y|X))^2 + E(Y^2|X) f \in \mathcal{F} f'(x) = \mathbb{E}(Y|X) 0 \textbf{Key Result} F' =(f'(x) - \mathbb{E}(Y|X))^2 - (\mathbb{E}(Y|X))^2 + E(Y^2|X) f'(x) = \mathbb{E}(Y|X) F = (f(x) - \mathbb{E}(Y|X))^2 - (\mathbb{E}(Y|X))^2 + E(Y^2|X) f \mathcal{F} F' \leq F \mathbb{E}(Y-f(x))^2 = \mathbb{E}(\mathbb{E}((Y-f(x))|X) X, Y X \leq Y \Rightarrow \mathbb{E}(X) \leq \mathbb{E}(Y) \mathcal{F} f' = \mathbb{E}(Y|X) F' f' F f F' \leq F \mathbb{E}(F') \leq \mathbb{E}(F) (Y- f(X))^2 f(x) = \mathbb{E}(Y|X)","['probability', 'probability-theory', 'probability-distributions', 'conditional-probability']"
46,Sum of two sequences bounded in probability,Sum of two sequences bounded in probability,,"I have two sequences of random variables which are bounded in probability, denoted as $X_n=\mathcal{O}_p(\sqrt{n})$ and $Y_n=\mathcal{O}_p(\lVert\theta\rVert)$ , where $\lVert\theta\lVert=\sum_{i=1}^n\theta_i^2$ with $\theta_i \in \mathbb R$ . I would like to show that $X_n+Y_n$ = $\mathcal{O}_p(\sqrt{n+\lVert\theta\rVert^2})$ . Typically, when adding 'big O' terms, the dominant one would be all that remains. However, since $\lVert\theta\rVert$ depends on the sample size $n$ , it is not clear in this case which term dominates. The definition of bounded in probability tells us that $X_n=\mathcal{O}_p(a_n)$ if for all $\varepsilon>0$ there exists a constant $M_\varepsilon>0$ and an integer $N_\varepsilon>0$ such that $$P\left(\biggr\lvert\frac{X_n}{a_n}\biggr\lvert\geq M_\varepsilon\right)\leq\varepsilon \text{ for all } n\geq N_\varepsilon$$ Here is what I have tried to show so far. I am mostly having issues with stating the right conditions. We have that for all $\varepsilon>0$ , there exists $M_1>0$ and $N_1>0$ s.t. $P\left(\biggr\lvert\frac{X_n}{\sqrt{n}}\biggr\lvert\geq M_1\right)\leq\varepsilon \text{ for all } n\geq N_1$ . Similarly, for all $\varepsilon>0$ , there exists $M_2>0$ and $N_2>0$ s.t. $P\left(\biggr\lvert\frac{Y_n}{\sqrt{\lVert\theta\rVert^2}}\biggr\lvert\geq M_2\right)\leq\varepsilon \text{ for all } n\geq N_2$ . Note that $\{|X_n+Y_n|>M\} \subset \{|X_n|\geq M/2\}\cup \{|Y_n|\geq M/2\}$ and hence $P(|X_n|+|Y_n|>M)\leq P(|X_n|\geq M/2)+P(|Y_n|\geq M/2).$ Then we can write \begin{align} P\left(\biggr\lvert\frac{X_n+Y_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> M\right)&\leq P\left(\biggr\lvert\frac{X_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert+\biggr\lvert\frac{Y_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> M\right)\\ &\leq P\left(\biggr\lvert\frac{X_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> \frac{M}{2}\right)+P\left(\biggr\lvert\frac{Y_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> \frac{M}{2}\right)\\ &\leq P\left(\biggr\lvert\frac{X_n}{\sqrt{n}}\biggr\lvert> \frac{M}{2}\right)+P\left(\biggr\lvert\frac{Y_n}{\sqrt{\lVert\theta\rVert^2}}\biggr\lvert> \frac{M}{2}\right) \end{align} I would like to say that the last part $\leq \frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon \text{ for all } n \geq N$ , but I'm not sure what conditions I need on $M$ , $N$ , and $\varepsilon$ to make this true. It has been a while since I've done a real analysis course and I am not very familiar with asymptotics. I would appreciate any help!","I have two sequences of random variables which are bounded in probability, denoted as and , where with . I would like to show that = . Typically, when adding 'big O' terms, the dominant one would be all that remains. However, since depends on the sample size , it is not clear in this case which term dominates. The definition of bounded in probability tells us that if for all there exists a constant and an integer such that Here is what I have tried to show so far. I am mostly having issues with stating the right conditions. We have that for all , there exists and s.t. . Similarly, for all , there exists and s.t. . Note that and hence Then we can write I would like to say that the last part , but I'm not sure what conditions I need on , , and to make this true. It has been a while since I've done a real analysis course and I am not very familiar with asymptotics. I would appreciate any help!","X_n=\mathcal{O}_p(\sqrt{n}) Y_n=\mathcal{O}_p(\lVert\theta\rVert) \lVert\theta\lVert=\sum_{i=1}^n\theta_i^2 \theta_i \in \mathbb R X_n+Y_n \mathcal{O}_p(\sqrt{n+\lVert\theta\rVert^2}) \lVert\theta\rVert n X_n=\mathcal{O}_p(a_n) \varepsilon>0 M_\varepsilon>0 N_\varepsilon>0 P\left(\biggr\lvert\frac{X_n}{a_n}\biggr\lvert\geq M_\varepsilon\right)\leq\varepsilon \text{ for all } n\geq N_\varepsilon \varepsilon>0 M_1>0 N_1>0 P\left(\biggr\lvert\frac{X_n}{\sqrt{n}}\biggr\lvert\geq M_1\right)\leq\varepsilon \text{ for all } n\geq N_1 \varepsilon>0 M_2>0 N_2>0 P\left(\biggr\lvert\frac{Y_n}{\sqrt{\lVert\theta\rVert^2}}\biggr\lvert\geq M_2\right)\leq\varepsilon \text{ for all } n\geq N_2 \{|X_n+Y_n|>M\} \subset \{|X_n|\geq M/2\}\cup \{|Y_n|\geq M/2\} P(|X_n|+|Y_n|>M)\leq P(|X_n|\geq M/2)+P(|Y_n|\geq M/2). \begin{align}
P\left(\biggr\lvert\frac{X_n+Y_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> M\right)&\leq P\left(\biggr\lvert\frac{X_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert+\biggr\lvert\frac{Y_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> M\right)\\
&\leq P\left(\biggr\lvert\frac{X_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> \frac{M}{2}\right)+P\left(\biggr\lvert\frac{Y_n}{\sqrt{n+\lVert\theta\rVert^2}}\biggr\lvert> \frac{M}{2}\right)\\
&\leq P\left(\biggr\lvert\frac{X_n}{\sqrt{n}}\biggr\lvert> \frac{M}{2}\right)+P\left(\biggr\lvert\frac{Y_n}{\sqrt{\lVert\theta\rVert^2}}\biggr\lvert> \frac{M}{2}\right)
\end{align} \leq \frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon \text{ for all } n \geq N M N \varepsilon","['probability', 'inequality']"
47,Probability law of waiting times,Probability law of waiting times,,"Yousha takes the train every day from Jangpura, where he lives, to go to his school at INA train station. Jangpura is on the Violet line, while INA is on the yellow line and the interchange is at Lajpat Nagar station.   The waiting times in Jangpura and Lajpat Nagar are independent random variables following the exponential law with parameter λ.   Find the probability law of the total waiting time in the two stations. Any help will be appreciated. I have no idea where to take it from! I thought I was familiar with combinatorics and probabilities but this is completely out of my knowledge base!!","Yousha takes the train every day from Jangpura, where he lives, to go to his school at INA train station. Jangpura is on the Violet line, while INA is on the yellow line and the interchange is at Lajpat Nagar station.   The waiting times in Jangpura and Lajpat Nagar are independent random variables following the exponential law with parameter λ.   Find the probability law of the total waiting time in the two stations. Any help will be appreciated. I have no idea where to take it from! I thought I was familiar with combinatorics and probabilities but this is completely out of my knowledge base!!",,['probability']
48,Sharpness of Kolmogorov-Chentsov,Sharpness of Kolmogorov-Chentsov,,"The Kolmogorov-Chentsov continuity theorem is a general way to estimate the Hölder continuity of a process $X$ (up to taking a different version $\tilde{X}$ of $X$ ). However, I would like to know if this criterium is optimal. That is, given a process $X:[0,K] \longrightarrow \mathbb{R}$ define: $$ \alpha := \sup\Big\{ \frac{\log \mathbb{E}[|X_t-X_s|^p]}{p\log |t-s|}-\frac{1}{p}  \; \Big| \; t,s \in [0,K], p> 1, \mathbb{E}[|X_t-X_s|^p]<\infty   \Big\} $$ Then, is it true that there exists no version $\tilde{X}$ of $X$ s.t $\tilde{X}$ is $\alpha$ -Hölder? Or maybe, just for $\beta >\alpha$ ? For instance, this statement is true for the Brownian Motion, however, at least in the proof I know for such fact uses the exact scaling $B_{at} \sim \sqrt{a}B_t$ , however, the moment condition is more general. Is there an additional assumption you need to make the statement true? I appreciate any references or ideas. EDIT: I suppose the constant I am ignoring is actually going to make a difference. So let me rephrase it. For $p > 1$ , define $\alpha(p)$ via $$   \log \mathbb{E}|X_t - X_s|^p =   \alpha(p)\log|t-s| + O(1). $$ if such expansion is possible. Now, define $\alpha_c = \sup\{ \frac{\alpha(p)-1}{p}: p \text{ s.t }\mathbb{E}[|X_t-X_s|^p] <\infty \}$ . And then, the question is wether $X$ has a $C^\beta$ version for $\beta>\alpha_c$ .","The Kolmogorov-Chentsov continuity theorem is a general way to estimate the Hölder continuity of a process (up to taking a different version of ). However, I would like to know if this criterium is optimal. That is, given a process define: Then, is it true that there exists no version of s.t is -Hölder? Or maybe, just for ? For instance, this statement is true for the Brownian Motion, however, at least in the proof I know for such fact uses the exact scaling , however, the moment condition is more general. Is there an additional assumption you need to make the statement true? I appreciate any references or ideas. EDIT: I suppose the constant I am ignoring is actually going to make a difference. So let me rephrase it. For , define via if such expansion is possible. Now, define . And then, the question is wether has a version for .","X \tilde{X} X X:[0,K] \longrightarrow \mathbb{R} 
\alpha :=
\sup\Big\{ \frac{\log \mathbb{E}[|X_t-X_s|^p]}{p\log |t-s|}-\frac{1}{p}  \; \Big| \; t,s \in [0,K], p> 1, \mathbb{E}[|X_t-X_s|^p]<\infty   \Big\}
 \tilde{X} X \tilde{X} \alpha \beta >\alpha B_{at} \sim \sqrt{a}B_t p > 1 \alpha(p) 
  \log \mathbb{E}|X_t - X_s|^p =   \alpha(p)\log|t-s| + O(1).
 \alpha_c = \sup\{ \frac{\alpha(p)-1}{p}: p \text{ s.t }\mathbb{E}[|X_t-X_s|^p] <\infty \} X C^\beta \beta>\alpha_c","['probability', 'probability-distributions', 'stochastic-processes', 'brownian-motion', 'holder-spaces']"
49,A “branching process” for finite groups,A “branching process” for finite groups,,"Suppose $G$ is a finite group and $\{X_{i,j}\}_{i, j \in \mathbb{N}}$ are a set of i.i.d. random elements of $G$ . Now suppose that $\{A_i\}_{i = 0}^\infty$ is a sequence of random elements of $G$ defined by the following relations: $$P(A_0 = e) = 1$$ $$A_{n+1} = \Pi_{i = 1}^{ord{A_{n}}} X_{(n+1), i}$$ Here $\Pi$ stands for iterated group product, and $ord$ for the order of an element. My question is: Is it always true, that $\exists H \leq G$ , such that $\forall g \in G$ $\lim_{n \to \infty} P(A_{n} = g) = \frac{I_H(g)}{|G|}$ ? Here $I_H$ stands for indicator function of $H$ . This statement is true for the following borderline cases: If $X_{1, 1}$ is uniformly distributed on $G$ , then $H$ is equal to $G$ . This is because if $A$ and $B$ are two independent uniformly distributed random elements of a finite group, then $AB$ is also uniformly distributed. If $X_{1, 1}$ is degenerate ( $\exists g \in G$ , such that $P(X_{1, 1} = g) = 1)$ ), then $H$ is trivial, as $\forall g \in G$ $g^{ord(g)} = e$ by definition of group element order. But is that statement true in general?","Suppose is a finite group and are a set of i.i.d. random elements of . Now suppose that is a sequence of random elements of defined by the following relations: Here stands for iterated group product, and for the order of an element. My question is: Is it always true, that , such that ? Here stands for indicator function of . This statement is true for the following borderline cases: If is uniformly distributed on , then is equal to . This is because if and are two independent uniformly distributed random elements of a finite group, then is also uniformly distributed. If is degenerate ( , such that ), then is trivial, as by definition of group element order. But is that statement true in general?","G \{X_{i,j}\}_{i, j \in \mathbb{N}} G \{A_i\}_{i = 0}^\infty G P(A_0 = e) = 1 A_{n+1} = \Pi_{i = 1}^{ord{A_{n}}} X_{(n+1), i} \Pi ord \exists H \leq G \forall g \in G \lim_{n \to \infty} P(A_{n} = g) = \frac{I_H(g)}{|G|} I_H H X_{1, 1} G H G A B AB X_{1, 1} \exists g \in G P(X_{1, 1} = g) = 1) H \forall g \in G g^{ord(g)} = e","['probability', 'group-theory', 'probability-theory', 'stochastic-processes', 'finite-groups']"
50,Probablity/Statistical Inference Important Questions (problems) Collection for Interviews and Understanding of Concept,Probablity/Statistical Inference Important Questions (problems) Collection for Interviews and Understanding of Concept,,This might be irrelevant here! But I would really appreciate your help! It would definitely help lot of us preparing for Interviews in Data Science domain. I am looking for a book/github/ any resource where I can find Probablity & STatistical Inference questions/puzzles (just like leetcode has programming) to prepare for interviews. Any suggestions on books/resources which has probablity problems I can solve to get thorough on all sort of probablity and statistical inference questions. Thank you,This might be irrelevant here! But I would really appreciate your help! It would definitely help lot of us preparing for Interviews in Data Science domain. I am looking for a book/github/ any resource where I can find Probablity & STatistical Inference questions/puzzles (just like leetcode has programming) to prepare for interviews. Any suggestions on books/resources which has probablity problems I can solve to get thorough on all sort of probablity and statistical inference questions. Thank you,,"['probability', 'statistics', 'reference-request', 'statistical-inference', 'book-recommendation']"
51,probability of infinite union of events,probability of infinite union of events,,"Let $(U_i)_{i\in\mathbb N}$ be iid with $U_1\sim U[0,1]$ . Calculate $P(\,\bigcup_{i=1}^\infty \{U_i\in [0,x]\}\,)$ where $x\in (0,1]$ . I tried to apply $$P(\,\bigcup_{i=1}^\infty \{U_i\in [0,x]\}\,)=1-P(\,\bigcap_{i=1}^\infty \{U_i\notin [0,x]\}\,)=1-\prod_{i=1}^\infty P(U_i\notin [0,x])=1-\prod_{i=1}^\infty (1-x)=1$$ Right?",Let be iid with . Calculate where . I tried to apply Right?,"(U_i)_{i\in\mathbb N} U_1\sim U[0,1] P(\,\bigcup_{i=1}^\infty \{U_i\in [0,x]\}\,) x\in (0,1] P(\,\bigcup_{i=1}^\infty \{U_i\in [0,x]\}\,)=1-P(\,\bigcap_{i=1}^\infty \{U_i\notin [0,x]\}\,)=1-\prod_{i=1}^\infty P(U_i\notin [0,x])=1-\prod_{i=1}^\infty (1-x)=1","['probability', 'probability-theory']"
52,Indicator method for isolated chairs,Indicator method for isolated chairs,,"I am working on the following problem for an applied probability qualifying exam. Fix positive integers $m\leq n$ with $n>4$ . Suppose $m$ people sit at a circular table with n seats, with all ${n \choose m}$ seatings equally likely. A seat is called isolated if it is occupied and both adjacent seats are vacant. Find the mean and variance of the number of isolated seats. Letting $X$ be the number of isolated seats, I have written $X=\sum_{i=1}^{n}\mathbb{1}_{A_{i}}$ , where $A_{i}=\{$$i^{th}$ seat is isolated $\}$ for i=2,...,n-1, and $A_{1}$ and $A_{n}$ defined appropriately given the circular arrangement. This yields $\mathbb{E}X=\sum_{i=1}^{n}\mathbb{P}(A_{i})$ . Now I know that $A_{i}$ occurs only when chairs $i\pm1$ are vacant and chair $i$ is occupied. I mistakenly initially computed that the probability is $p(1-p)^2$ where $p$ is the probability of a single chair being occupied (which turned out to be $m/n$ ). However, since these events are not independent, I am unsure how to compute the actual probability.","I am working on the following problem for an applied probability qualifying exam. Fix positive integers with . Suppose people sit at a circular table with n seats, with all seatings equally likely. A seat is called isolated if it is occupied and both adjacent seats are vacant. Find the mean and variance of the number of isolated seats. Letting be the number of isolated seats, I have written , where seat is isolated for i=2,...,n-1, and and defined appropriately given the circular arrangement. This yields . Now I know that occurs only when chairs are vacant and chair is occupied. I mistakenly initially computed that the probability is where is the probability of a single chair being occupied (which turned out to be ). However, since these events are not independent, I am unsure how to compute the actual probability.",m\leq n n>4 m {n \choose m} X X=\sum_{i=1}^{n}\mathbb{1}_{A_{i}} A_{i}=\{i^{th} \} A_{1} A_{n} \mathbb{E}X=\sum_{i=1}^{n}\mathbb{P}(A_{i}) A_{i} i\pm1 i p(1-p)^2 p m/n,"['probability', 'conditional-probability']"
53,Four vertices of a regular dodecagon are randomly selected. Find the probability that they form a rectangle (including squares).,Four vertices of a regular dodecagon are randomly selected. Find the probability that they form a rectangle (including squares).,,"Four points are randomly selected from the set of the vertices of a regular  dodecagon (or 12 sided regular polygon). Find the probability that those four points  form a rectangle (including squares). I tried by trying to see the cases where there are rectangles or squares by connecting some vertices, but ended up resorting to bashing. It would be helpful if someone gives a less bashy way to solve this.","Four points are randomly selected from the set of the vertices of a regular  dodecagon (or 12 sided regular polygon). Find the probability that those four points  form a rectangle (including squares). I tried by trying to see the cases where there are rectangles or squares by connecting some vertices, but ended up resorting to bashing. It would be helpful if someone gives a less bashy way to solve this.",,"['probability', 'geometry']"
54,Uniformly Distributed Random-Variable With Specific Ordering,Uniformly Distributed Random-Variable With Specific Ordering,,"Let $0\leq a<b$ .  Define the subset of $[a,b]^n$ by $$ X=\{(x_1,\cdots,x_{n-1})\mid b^{2n}\geq x_1^{2(n-1)}\geq\cdots\geq x_{n-1}^2\geq a\} $$ What is the probability that a uniformly distributed random-vector in $[a,b]^n$ is an element of $X$ ? ie: Obeys that ordering? Comment: So far..I only can note that: If the powers of $2$ are omitted that this quantity is equal to $\frac1{(n-1)!}$ .",Let .  Define the subset of by What is the probability that a uniformly distributed random-vector in is an element of ? ie: Obeys that ordering? Comment: So far..I only can note that: If the powers of are omitted that this quantity is equal to .,"0\leq a<b [a,b]^n 
X=\{(x_1,\cdots,x_{n-1})\mid b^{2n}\geq x_1^{2(n-1)}\geq\cdots\geq x_{n-1}^2\geq a\}
 [a,b]^n X 2 \frac1{(n-1)!}","['probability', 'combinatorics']"
55,Martingales: why bother conditioning on the filtration when we can condition on random variables instead?,Martingales: why bother conditioning on the filtration when we can condition on random variables instead?,,"In some discussion regarding martingales, suppose we have a random process $\{X_k\}_{k \geq 0}$ , authors use $$\mathbb{E}[X_{k+1}|\mathcal{F}_k]$$ to denote the expectation with respect to a filtration, i.e., a increasing $\sigma$ -algebra of the past random variables, $\mathcal{F}_k = \sigma(X_0, X_1, \ldots, X_k\}$ . A rough interpretation is that we are conditioning on increasing amount of information. But why bother conditioning on a $\sigma$ -algebra? (which is not unique, and can be very large, i.e., $\mathcal{F}_k = \text{power set}$ , and contains things like $\varnothing$ which makes no sense in terms of information necessary) Why not simply condition on the past random variables themselves? That is, $$\mathbb{E}[X_{k+1}|X_k, X_{k-1}, \ldots, X_0]$$ Isn't the latter expression more interpretable and direct? In what situation is conditioning on the filtration better than conditioning on the random variables themselves? Ultimately, I don't see why we need to condition on the filtration.","In some discussion regarding martingales, suppose we have a random process , authors use to denote the expectation with respect to a filtration, i.e., a increasing -algebra of the past random variables, . A rough interpretation is that we are conditioning on increasing amount of information. But why bother conditioning on a -algebra? (which is not unique, and can be very large, i.e., , and contains things like which makes no sense in terms of information necessary) Why not simply condition on the past random variables themselves? That is, Isn't the latter expression more interpretable and direct? In what situation is conditioning on the filtration better than conditioning on the random variables themselves? Ultimately, I don't see why we need to condition on the filtration.","\{X_k\}_{k \geq 0} \mathbb{E}[X_{k+1}|\mathcal{F}_k] \sigma \mathcal{F}_k = \sigma(X_0, X_1, \ldots, X_k\} \sigma \mathcal{F}_k = \text{power set} \varnothing \mathbb{E}[X_{k+1}|X_k, X_{k-1}, \ldots, X_0]","['probability', 'probability-theory', 'conditional-expectation', 'martingales']"
56,Portuguese card game probabilities with a 40 card deck,Portuguese card game probabilities with a 40 card deck,,"I'm working on a Portuguese card game for 4 players for a personal java project, and need help modelling. For this game, the 8's, 9's, and 10's are removed, leaving the deck with 40 cards, 10 for each suit. In each round, each player plays 1 card, in their turn. For a given player's turn, the probability I'm trying to calculate is if at least 1 player who plays after the given player's turn has at least 1 card of suit x in their hand, while having no cards of suit y . Looking at an example, player 1                 A♠ 7♥ K♥  player 2                        player 4     A♥                              6♠     J♥                              2♠     7♠                              6♥                  player 3                 A♣ 2♥ K♦ Suppose player 3 is the first to play in this round, and suit x is ♠ (defined in the beginning of the game, it's the ""trump suit""). For y = ♣ there is at least 1 player with at least 1 ♠, while having no ♣. For y = ♥, the opposite is true, all players have ♥, regardless of having ♠ or not. The question arises from the rule that trump cards beat any card, but you have to play the same suit as the first player in the round, if you can. Players know how many cards from each suit remain because they remember which cards have been played. I think that's all the relevant information, if something is not clear, I'm happy to explain. The game in question is Sueca","I'm working on a Portuguese card game for 4 players for a personal java project, and need help modelling. For this game, the 8's, 9's, and 10's are removed, leaving the deck with 40 cards, 10 for each suit. In each round, each player plays 1 card, in their turn. For a given player's turn, the probability I'm trying to calculate is if at least 1 player who plays after the given player's turn has at least 1 card of suit x in their hand, while having no cards of suit y . Looking at an example, player 1                 A♠ 7♥ K♥  player 2                        player 4     A♥                              6♠     J♥                              2♠     7♠                              6♥                  player 3                 A♣ 2♥ K♦ Suppose player 3 is the first to play in this round, and suit x is ♠ (defined in the beginning of the game, it's the ""trump suit""). For y = ♣ there is at least 1 player with at least 1 ♠, while having no ♣. For y = ♥, the opposite is true, all players have ♥, regardless of having ♠ or not. The question arises from the rule that trump cards beat any card, but you have to play the same suit as the first player in the round, if you can. Players know how many cards from each suit remain because they remember which cards have been played. I think that's all the relevant information, if something is not clear, I'm happy to explain. The game in question is Sueca",,"['probability', 'card-games']"
57,Random graph connectivity with different probability for each edge,Random graph connectivity with different probability for each edge,,"Let $G_{0}=(V,E)$ be a connected graph. Let $G_{1}=(V,E')$ be the probalistic subgraph of $G_{0}$ such that for each $e_{i}\in E$ the probability of $e\in E'$ is $p_{i}$ (each edge can get different probability) I need to find a way to describe the probability of $G_{1}$ to stay connected, meaning that we might lose some of $G_{0}$ edges but still stay connected. I have found only papers that describe the $G(n,p)$ model and the $G(n,m)$ model or related issues, all of them describe an equal p probability for each edge. I have tried to build a function of the vertices degree, something like $\Sigma_{i=0}^{n}\Pi_{j\in N(V_{i})}P_{j}$ where $n$ is the number of vertices and $N(v_{i})$ represents $v_{i}$ neighbors but I have duplications. I am thinking about the probability of finding a tree in $G_{1}$ but I can't find any material. Does anyone have any idea if there is a relevant material that is related to my problem?","Let be a connected graph. Let be the probalistic subgraph of such that for each the probability of is (each edge can get different probability) I need to find a way to describe the probability of to stay connected, meaning that we might lose some of edges but still stay connected. I have found only papers that describe the model and the model or related issues, all of them describe an equal p probability for each edge. I have tried to build a function of the vertices degree, something like where is the number of vertices and represents neighbors but I have duplications. I am thinking about the probability of finding a tree in but I can't find any material. Does anyone have any idea if there is a relevant material that is related to my problem?","G_{0}=(V,E) G_{1}=(V,E') G_{0} e_{i}\in E e\in E' p_{i} G_{1} G_{0} G(n,p) G(n,m) \Sigma_{i=0}^{n}\Pi_{j\in N(V_{i})}P_{j} n N(v_{i}) v_{i} G_{1}","['probability', 'graph-theory', 'connectedness', 'random-graphs']"
58,Lottery - Probability,Lottery - Probability,,"Looking over Canada's Western Lotto Max and Daily Grand lottery probabilities, a combinations calculator shows the actual chance of getting 7/7 with 50 numbers is 1 in 99,884,400. However, that's if you only had 1 selection per ticket. Since there are 3 selections per ticket, their website accurately shows the chance is 3 times better (99,884,400/3 = 33,294,800). There are also 14 additional draws to the main draw where you must match 7/7 for another chance to win a jackpot. Their website shows that winning 1 of the 14 additional draws has an equal chance of 1 in 33,294,800 just as the main draw. Now, this is where my question comes in: aren't the odds of winning the jackpot of 7/7 actually better than 1 in 33,294,800 considering there is more than 1 jackpot of 7/7? With 15 draws (1 main draw + 14 additional draws), aren't the odds of winning 7/7 for any 1 of the 15 draws actually 1 in 2,219,653 (33,294,800/15)? The odds should be 1 in 33,294,800 if there was only one main draw, but with 14 additional draws, it seems like the number is wrong. Also, the Daily Grand lottery shows that winning 5/5 from a range of 49 numbers per one ticket has a chance of 1 in 2,224,698. However, the combinations calculator shows the real chance is 1 in 1,906,884. It seems that matching 5/5 has a higher probability than what is shown on the official lottery website. While their website is correct that matching a specific 7/7 combination has a chance of 1 in 33,294,800 - my question is whether matching 7/7 for any 1 of the 15 main draws has a probability of 1 in 2,219,653 (33,294,800/15) versus 1 in 33,294,800? Since it doesn't matter which of the 15 specific combinations you match, any 1 of the 15 has a better chance than the website claims, am I right?","Looking over Canada's Western Lotto Max and Daily Grand lottery probabilities, a combinations calculator shows the actual chance of getting 7/7 with 50 numbers is 1 in 99,884,400. However, that's if you only had 1 selection per ticket. Since there are 3 selections per ticket, their website accurately shows the chance is 3 times better (99,884,400/3 = 33,294,800). There are also 14 additional draws to the main draw where you must match 7/7 for another chance to win a jackpot. Their website shows that winning 1 of the 14 additional draws has an equal chance of 1 in 33,294,800 just as the main draw. Now, this is where my question comes in: aren't the odds of winning the jackpot of 7/7 actually better than 1 in 33,294,800 considering there is more than 1 jackpot of 7/7? With 15 draws (1 main draw + 14 additional draws), aren't the odds of winning 7/7 for any 1 of the 15 draws actually 1 in 2,219,653 (33,294,800/15)? The odds should be 1 in 33,294,800 if there was only one main draw, but with 14 additional draws, it seems like the number is wrong. Also, the Daily Grand lottery shows that winning 5/5 from a range of 49 numbers per one ticket has a chance of 1 in 2,224,698. However, the combinations calculator shows the real chance is 1 in 1,906,884. It seems that matching 5/5 has a higher probability than what is shown on the official lottery website. While their website is correct that matching a specific 7/7 combination has a chance of 1 in 33,294,800 - my question is whether matching 7/7 for any 1 of the 15 main draws has a probability of 1 in 2,219,653 (33,294,800/15) versus 1 in 33,294,800? Since it doesn't matter which of the 15 specific combinations you match, any 1 of the 15 has a better chance than the website claims, am I right?",,['probability']
59,Probability of no pair of consecutive heads in $n$ flips of a coin,Probability of no pair of consecutive heads in  flips of a coin,n,"I am trying to solve the following problem. A biased coin shows heads with probability $p=1-q$ when it is flipped. Let $u_{n}$ be the probability that in $n$ flips, no pair of heads occur successively. Show that for $n \geq q$ , $$u_{n+2} = qu_{n+1} + pqu_{n}.$$ I know I need to use the partition theorem $P(X) = \sum P(X|B_{i})P(B_{i})$ where the set of events $B_{i}$ partition the sample space (the question event gives the hint ""use partition theorem with $B_{i}$ the event that first $i-1$ flips yield heads and the $i$ th yields tails""), but I still have no idea as to how to proceed and to how to choose the partition. I intuitively see why the answer is what it is, but I can't rigorously formulate the approach to the solution in my head.","I am trying to solve the following problem. A biased coin shows heads with probability when it is flipped. Let be the probability that in flips, no pair of heads occur successively. Show that for , I know I need to use the partition theorem where the set of events partition the sample space (the question event gives the hint ""use partition theorem with the event that first flips yield heads and the th yields tails""), but I still have no idea as to how to proceed and to how to choose the partition. I intuitively see why the answer is what it is, but I can't rigorously formulate the approach to the solution in my head.",p=1-q u_{n} n n \geq q u_{n+2} = qu_{n+1} + pqu_{n}. P(X) = \sum P(X|B_{i})P(B_{i}) B_{i} B_{i} i-1 i,"['probability', 'probability-theory', 'conditional-probability']"
60,"If $S_n$ is Binomial $(n,p)$ then $\mathbb P(S_n=k)\approx \frac{(np)^k}{k!}e^{-np}$.",If  is Binomial  then .,"S_n (n,p) \mathbb P(S_n=k)\approx \frac{(np)^k}{k!}e^{-np}","I was reading this post , and I have to admit that I was quite confused. The question was : If $S_n$ is a Binomial r.v. with parameter $(n,p)$ s.t. $n$ large, $p$ very small and $np$ not to big (for instance $np\leq 10$ ), then $$\mathbb P(S_n=k)\approx \frac{(np)^k}{k!}e^{-np}.$$ What I completely agree is (using notation of the link I put) if $(B_m)$ is a sequence of $Binomial(m,p_m)$ where $\lim_{m\to \infty }mp_m=\lambda $ , then $$\lim_{m\to \infty }\mathbb P(B_m=k)=\frac{\lambda ^k}{k!}e^{-\lambda }.$$ I can prove it without any problem. Now, if $np\leq 10$ , $n$ big and $p$ small, I'm indeed confuse with $\mathbb P(S_n=k)\approx \frac{(np)^k}{k!}e^{-(np)}$ . Atempts Let $n\in\mathbb N$ large and $p$ small s.t. $np\leq 10$ . I set $\lambda =np$ . Then, define the sequence $p_m=\frac{\lambda }{m}$ , i.e. $mp_m=\lambda $ for all $m$ . So now, $\mathbb E[S_n]=\mathbb E[B_m]$ for all $m$ and if $p_m$ is very small, then $p_m\approx p$ and thus $$\text{Var}(S_n)=np(1-p)=mp_m(1-p)\underset{(*)}{\approx} mp_m(1-p_m)=\text{Var}(B_m).$$ Therefore, if $m$ is big enough, then $B_m$ and $S_n$ are Binomial distributed with same expectation and very close variance. Q1) Does this implies that $$\mathbb P(S_n=k)\approx \mathbb P(B_m=k) \ \ ?$$ i.e. that a Binomial is uniquely determined by its variance and expectation ? Q2) In what the fact that $np\leq 10$ is relevant ? I hope my question is clear, and if not, please let me know.","I was reading this post , and I have to admit that I was quite confused. The question was : If is a Binomial r.v. with parameter s.t. large, very small and not to big (for instance ), then What I completely agree is (using notation of the link I put) if is a sequence of where , then I can prove it without any problem. Now, if , big and small, I'm indeed confuse with . Atempts Let large and small s.t. . I set . Then, define the sequence , i.e. for all . So now, for all and if is very small, then and thus Therefore, if is big enough, then and are Binomial distributed with same expectation and very close variance. Q1) Does this implies that i.e. that a Binomial is uniquely determined by its variance and expectation ? Q2) In what the fact that is relevant ? I hope my question is clear, and if not, please let me know.","S_n (n,p) n p np np\leq 10 \mathbb P(S_n=k)\approx \frac{(np)^k}{k!}e^{-np}. (B_m) Binomial(m,p_m) \lim_{m\to \infty }mp_m=\lambda  \lim_{m\to \infty }\mathbb P(B_m=k)=\frac{\lambda ^k}{k!}e^{-\lambda }. np\leq 10 n p \mathbb P(S_n=k)\approx \frac{(np)^k}{k!}e^{-(np)} n\in\mathbb N p np\leq 10 \lambda =np p_m=\frac{\lambda }{m} mp_m=\lambda  m \mathbb E[S_n]=\mathbb E[B_m] m p_m p_m\approx p \text{Var}(S_n)=np(1-p)=mp_m(1-p)\underset{(*)}{\approx} mp_m(1-p_m)=\text{Var}(B_m). m B_m S_n \mathbb P(S_n=k)\approx \mathbb P(B_m=k) \ \ ? np\leq 10",['probability']
61,On a proof of strong consistency of the maximum likelihood estimator.,On a proof of strong consistency of the maximum likelihood estimator.,,"let $X_1, \dots, X_n$ be IID random variables with continous density $g(x|\theta_0)$ , where $\theta_0 \in \Theta \subset \mathbb{R}$ and $\Theta = \{ \theta_0, \theta_1, \dots, \theta_m \}$ (the parameter space is finite, we are in a very simple case). We define the log-likelihood as $$ \ell_n(\theta) : = \sum_{i= 1}^n \log g(X_i | \theta)$$ Suppose we have proven that $\ell_n(\theta_0) - \ell_n(\theta) \rightarrow \infty$ almost surely. Fixed an $\epsilon > 0$ there exists a $n_0 \in \mathbb{N}$ s.t defining $$A_j = \{ \ell_n(\theta_0)  -   \ell_n(\theta_j) > \epsilon , \ \forall{n} > n_0 \}$$ we have $P(A_j) > 1- \delta$ where $\delta > 0$ is arbitraty. ( this can be done since we know that $\ell_n(\theta_0) - \ell_n(\theta) \rightarrow \infty$ almost surely). Then we have that $$ P \left( \bigcap_{j = 1}^m A_j \right) \ge 1-  \sum_{j=1}^mP \left(  A_j^c \right) \ge 1- m \delta $$ we have thus shown that $ P\{ \ell_n(\theta_0)  -   \ell_n(\theta_j) > \epsilon , \ \forall{j} \ne 0 , \ \forall{n} > n_0 \} \ge 1- m \delta  \tag{1}$ it is then apparently immediate (and here is my problem) that the maximim likelihood estimator $ \hat{\theta} : = \arg \max \ell_n(\theta)$ converges almost surely to $\theta_0$ . Why is this last step ""obvious""? My attempt: In particular $(1)$ implies that $ P\{ \ell_n(\theta_0)  -  \max_{\theta} \ell_n(\theta) > \epsilon ,  \ \forall{n} > n_0 \} \ge 1- m \delta$ and somehow we should get that $\ell_n ( \hat{\theta}) $ converges almost surely to $\ell(\theta_0)$ that should give us that $\hat{\theta} \rightarrow \theta_0$ .","let be IID random variables with continous density , where and (the parameter space is finite, we are in a very simple case). We define the log-likelihood as Suppose we have proven that almost surely. Fixed an there exists a s.t defining we have where is arbitraty. ( this can be done since we know that almost surely). Then we have that we have thus shown that it is then apparently immediate (and here is my problem) that the maximim likelihood estimator converges almost surely to . Why is this last step ""obvious""? My attempt: In particular implies that and somehow we should get that converges almost surely to that should give us that .","X_1, \dots, X_n g(x|\theta_0) \theta_0 \in \Theta \subset \mathbb{R} \Theta = \{ \theta_0, \theta_1, \dots, \theta_m \}  \ell_n(\theta) : = \sum_{i= 1}^n \log g(X_i | \theta) \ell_n(\theta_0) - \ell_n(\theta) \rightarrow \infty \epsilon > 0 n_0 \in \mathbb{N} A_j = \{ \ell_n(\theta_0)  -   \ell_n(\theta_j) > \epsilon , \ \forall{n} > n_0 \} P(A_j) > 1- \delta \delta > 0 \ell_n(\theta_0) - \ell_n(\theta) \rightarrow \infty  P \left( \bigcap_{j = 1}^m A_j \right) \ge 1-  \sum_{j=1}^mP \left(  A_j^c \right) \ge 1- m \delta   P\{ \ell_n(\theta_0)  -   \ell_n(\theta_j) > \epsilon , \ \forall{j} \ne 0 , \ \forall{n} > n_0 \} \ge 1- m \delta  \tag{1}  \hat{\theta} : = \arg \max \ell_n(\theta) \theta_0 (1)  P\{ \ell_n(\theta_0)  -  \max_{\theta} \ell_n(\theta) > \epsilon ,  \ \forall{n} > n_0 \} \ge 1- m \delta \ell_n ( \hat{\theta})  \ell(\theta_0) \hat{\theta} \rightarrow \theta_0","['probability', 'probability-theory', 'statistics', 'convergence-divergence']"
62,Probability of failing 2 out of the last 3 consecutive trials,Probability of failing 2 out of the last 3 consecutive trials,,"In a test with a series of trials, you'd fail the test if you fail 2 out of the last 3 trials (i.e. window of 3). For example, for a series of trials (starting from index 0, 1, ..., 7), we have results: 0, 1, 0, 0, 0, 1, 0, 1 (Fail is 1, Not failing is 0). Thus you fail the test at trial number 7. Now assume the probability of failure in each trial is 1/3 (each trial is independent of each other), and call the trial where you fail the test Y (so in the example above Y = 7). Find P(Y = y) for y = 0, 1, 2, ..., 20. In other words, the probability you fail the test in each of those years. By default then we know P(Y=0) = P(Y=1) = 0, and P(Y=2) = (1/3)^2. However, I have no idea how to proceed from here to higher values of Y. I've tried multiple values but they just don't work. I'm also given as a hint that E(Y) over that range is around 8.5. You can use this as a sanity check for your answer....","In a test with a series of trials, you'd fail the test if you fail 2 out of the last 3 trials (i.e. window of 3). For example, for a series of trials (starting from index 0, 1, ..., 7), we have results: 0, 1, 0, 0, 0, 1, 0, 1 (Fail is 1, Not failing is 0). Thus you fail the test at trial number 7. Now assume the probability of failure in each trial is 1/3 (each trial is independent of each other), and call the trial where you fail the test Y (so in the example above Y = 7). Find P(Y = y) for y = 0, 1, 2, ..., 20. In other words, the probability you fail the test in each of those years. By default then we know P(Y=0) = P(Y=1) = 0, and P(Y=2) = (1/3)^2. However, I have no idea how to proceed from here to higher values of Y. I've tried multiple values but they just don't work. I'm also given as a hint that E(Y) over that range is around 8.5. You can use this as a sanity check for your answer....",,['probability']
63,When is supremum of the expectation equal to the expectation of the supremum using control processes,When is supremum of the expectation equal to the expectation of the supremum using control processes,,"This is a question I have from stochastic control. I know that in general $\underset{y\in \mathcal Y} \sup \mathbb E\left[f(X,y)\right]\leqslant \mathbb E\left[\underset{y\in \mathcal Y} \sup f(X,y)\right]$ . I normally would assume that the reverse inequality does not always hold, just like in typical inequalities, such as with Jensen's inequality , but in the proof below, I see that a similar equality is proven, which makes it seem as if $\underset{y\in \mathcal Y} \sup \mathbb E\left[f(X,y)\right] = \mathbb E\left[\underset{y\in \mathcal Y} \sup f(X,y)\right]$ holds, but I don't fully understand/agree with part of the proof. In the following, $\mathbb E\left[f(X_T)|\mathcal F_t;\pi\right]$ , is saying that the stochastic process $X_t$ is controlled by the process $\pi$ , not that $\pi$ is assumed known. The argument is from Markov Decision Processes and Dynamic Programming at the top of page 9. In the solution for Bellman's principle (discrete time), I have seen that the following is done, for admissible control processes $\pi$ : \begin{equation} \underset{\pi} \sup \mathbb E\left[V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right] = E\left[\underset{\pi} \sup V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right] \end{equation} which is proven by showing both inequalities hold. So: \begin{equation} \underset{\pi} \sup \mathbb E\left[V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right]\leqslant E\left[\underset{\pi} \sup V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right] \end{equation} which I can see follows from $\underset{y\in \mathcal Y} \sup \mathbb E\left[f(X,y)\right]\leqslant \mathbb E\left[\underset{y\in \mathcal Y} \sup f(X,y)\right]$ Then the reverse inequality is proven, where $\pi^* =   \underset{\pi} {\text{argmax}}\left[\underset{\pi}\sup V^{\pi}(t+1,X_{t+1})\right]$ \begin{equation}  E\left[\underset{\pi} \sup V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right] =  E\left[V^{\pi^*}(t+1,X_{t+1})|X_t=x; \pi^* \right]\leqslant \underset{\pi} \sup \mathbb E\left[V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right] \end{equation} which follows by the definition of supremum. I am wondering how come we can't just do this same procedure for $\underset{y\in \mathcal Y} \sup \mathbb E\left[f(X,y)\right]\leqslant \mathbb E\left[\underset{y\in \mathcal Y} \sup f(X,y)\right]$ , and show that equality holds there as well. The issue seems to be with the step of the reverse inequality and I also can think of some simple examples that seem to defy the equality. For example: There is just one time step, from $T-1$ to $T$ , and the probability space has just $3$ points: $\{ \omega_1,\omega_2,\omega_3\}$ , all with equal likelihood. There is a function $f(y,X_T(\omega))$ , for $y \in \{0,1\}$ , such that whenever $y = 0$ , $f(0,X_T(\omega)) = 30$ , and that when $y = 1$ , $f(1,X_T(\omega_1)) = -3000$ , $f(1,X_T(\omega_2)) = -3000$ , and $f(1,X_T(\omega_3)) = 300$ . So if we wanted to calculate $\underset{y\in \{0,1\}} \sup \mathbb E\left[f(y,X_T(\omega))\right]$ , we maximize the expectation over choices of $y$ , so the choice would be $y = 0$ , for a value of $30$ , regardless of the state of the world. And for $ \mathbb E\left[ \underset{y\in \{0,1\}} \sup f(y,X_T(\omega))\right]$ , we choose $y = 1$ when the state of the world is $\omega_3$ and $y = 0$ otherwise, and so since each possibility has equal weighting, the value of the expression is $\frac{300 + 30 + 30}{3} = 120$ , which doesn't match the $30$ from $\underset{y\in \{0,1\}} \sup \mathbb E\big[f(y,X_T(\omega))\big]$ . So if we consider the control process to be the choice of $y$ , then this poses a contradiction with the proof of the Bellman principle . One issue I see with my example is that the supremum on the outside of the expectation seems to not be able to 'look into the future' while the supremum on the inside of the expectation can. I'm not sure how to reconcile this. So I think my main questions are: Can my simple (possibly incorrect) example be reconciled with how the proof for the Bellman principle was done? What exactly $\underset{\pi} \sup V^{\pi}(X_{t+1})$ means and how it can be evaluated. Is it a random variable, where the maximum of $V^{\pi}(X_{t+1})$ is chosen across policies, depending on the state of the world? Any clarification would be appreciated. I've been trying to get this answered for a while now. I'll award the bounty and correct answer even for just a link that'll help explain things! Thanks a lot!","This is a question I have from stochastic control. I know that in general . I normally would assume that the reverse inequality does not always hold, just like in typical inequalities, such as with Jensen's inequality , but in the proof below, I see that a similar equality is proven, which makes it seem as if holds, but I don't fully understand/agree with part of the proof. In the following, , is saying that the stochastic process is controlled by the process , not that is assumed known. The argument is from Markov Decision Processes and Dynamic Programming at the top of page 9. In the solution for Bellman's principle (discrete time), I have seen that the following is done, for admissible control processes : which is proven by showing both inequalities hold. So: which I can see follows from Then the reverse inequality is proven, where which follows by the definition of supremum. I am wondering how come we can't just do this same procedure for , and show that equality holds there as well. The issue seems to be with the step of the reverse inequality and I also can think of some simple examples that seem to defy the equality. For example: There is just one time step, from to , and the probability space has just points: , all with equal likelihood. There is a function , for , such that whenever , , and that when , , , and . So if we wanted to calculate , we maximize the expectation over choices of , so the choice would be , for a value of , regardless of the state of the world. And for , we choose when the state of the world is and otherwise, and so since each possibility has equal weighting, the value of the expression is , which doesn't match the from . So if we consider the control process to be the choice of , then this poses a contradiction with the proof of the Bellman principle . One issue I see with my example is that the supremum on the outside of the expectation seems to not be able to 'look into the future' while the supremum on the inside of the expectation can. I'm not sure how to reconcile this. So I think my main questions are: Can my simple (possibly incorrect) example be reconciled with how the proof for the Bellman principle was done? What exactly means and how it can be evaluated. Is it a random variable, where the maximum of is chosen across policies, depending on the state of the world? Any clarification would be appreciated. I've been trying to get this answered for a while now. I'll award the bounty and correct answer even for just a link that'll help explain things! Thanks a lot!","\underset{y\in \mathcal Y} \sup \mathbb E\left[f(X,y)\right]\leqslant \mathbb E\left[\underset{y\in \mathcal Y} \sup f(X,y)\right] \underset{y\in \mathcal Y} \sup \mathbb E\left[f(X,y)\right] = \mathbb E\left[\underset{y\in \mathcal Y} \sup f(X,y)\right] \mathbb E\left[f(X_T)|\mathcal F_t;\pi\right] X_t \pi \pi \pi \begin{equation}
\underset{\pi} \sup \mathbb E\left[V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right] = E\left[\underset{\pi} \sup V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right]
\end{equation} \begin{equation}
\underset{\pi} \sup \mathbb E\left[V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right]\leqslant E\left[\underset{\pi} \sup V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right]
\end{equation} \underset{y\in \mathcal Y} \sup \mathbb E\left[f(X,y)\right]\leqslant \mathbb E\left[\underset{y\in \mathcal Y} \sup f(X,y)\right] \pi^* =   \underset{\pi} {\text{argmax}}\left[\underset{\pi}\sup V^{\pi}(t+1,X_{t+1})\right] \begin{equation}
 E\left[\underset{\pi} \sup V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right] =  E\left[V^{\pi^*}(t+1,X_{t+1})|X_t=x; \pi^* \right]\leqslant \underset{\pi} \sup \mathbb E\left[V^{\pi}(t+1,X_{t+1})|X_t=x; \pi\right]
\end{equation} \underset{y\in \mathcal Y} \sup \mathbb E\left[f(X,y)\right]\leqslant \mathbb E\left[\underset{y\in \mathcal Y} \sup f(X,y)\right] T-1 T 3 \{ \omega_1,\omega_2,\omega_3\} f(y,X_T(\omega)) y \in \{0,1\} y = 0 f(0,X_T(\omega)) = 30 y = 1 f(1,X_T(\omega_1)) = -3000 f(1,X_T(\omega_2)) = -3000 f(1,X_T(\omega_3)) = 300 \underset{y\in \{0,1\}} \sup \mathbb E\left[f(y,X_T(\omega))\right] y y = 0 30  \mathbb E\left[ \underset{y\in \{0,1\}} \sup f(y,X_T(\omega))\right] y = 1 \omega_3 y = 0 \frac{300 + 30 + 30}{3} = 120 30 \underset{y\in \{0,1\}} \sup \mathbb E\big[f(y,X_T(\omega))\big] y \underset{\pi} \sup V^{\pi}(X_{t+1}) V^{\pi}(X_{t+1})","['real-analysis', 'probability', 'probability-theory', 'stochastic-processes', 'stochastic-analysis']"
64,Probability not to get a coupon : Coupon Collector's Problem,Probability not to get a coupon : Coupon Collector's Problem,,"We buy coupons for $m$ rounds (no matter if we have already collected them all or not and  we buy one coupon each round). What is the probability that we will not get the coupon number 1 in any of the $m$ rounds? Assume we have the Coupon Collector's Problem with $1 \dots n$ Coupons. Assume the event $X_1 = \text{""We don't get the first coupon""}$ so i think $X_1 \sim Bernoulli(1 - \frac{1}{n})$ . And after $m$ rounds we have the probability of $(1 - \frac{1}{n})^m$ to get not the first coupon - right ? And with the bernoulli's inequality we get $(1 - \frac{1}{n})^m \geq 1 - \frac{m}{n} $ . How can I calculate the expected value of the  number of  coupons that have not yet been collected after $m = n \cdot ln(n) + t$ round ( with m is an integer) ?  Is it $ E \geq m \cdot (1 - \frac{m}{n})$ ?",We buy coupons for rounds (no matter if we have already collected them all or not and  we buy one coupon each round). What is the probability that we will not get the coupon number 1 in any of the rounds? Assume we have the Coupon Collector's Problem with Coupons. Assume the event so i think . And after rounds we have the probability of to get not the first coupon - right ? And with the bernoulli's inequality we get . How can I calculate the expected value of the  number of  coupons that have not yet been collected after round ( with m is an integer) ?  Is it ?,"m m 1 \dots n X_1 = \text{""We don't get the first coupon""} X_1 \sim Bernoulli(1 - \frac{1}{n}) m (1 - \frac{1}{n})^m (1 - \frac{1}{n})^m \geq 1 - \frac{m}{n}  m = n \cdot ln(n) + t  E \geq m \cdot (1 - \frac{m}{n})","['probability', 'probability-theory', 'probability-distributions']"
65,What is the probability of being the last to touch an object passed around a circle of $N+1$ people?,What is the probability of being the last to touch an object passed around a circle of  people?,N+1,"We have $n+ 1$ people numbered by $0,1,...,n$ standing in a circle.  Person $0$ has a bag of chips to start passing around.  Every time, the person $k$ who is holding the bag of chips has probability $j$ to pass to person $k+ 1$ and probability $i = 1-j$ to pass to person $n−1$ with $j >0.5$ .  The game ends when all but one have held the bag, the one who hasn't held the chips gets to eat them. Calculate $P_k$ : the probability that the person $k$ will eat the chips The way I wanted to approach this is the following. I realize that for person $K$ to be the one, both person $k+ 1$ and person $k−1$ must have held the bag. I wanted to condition  on  whether  person $k−1$ will have touched  the bag before person $k+ 1$ or vice versa. This is my first time in probability and I am having trouble approaching the question. I know that we need to A)  compute the probability that the $k-1$ person has held the bag before the $k+1$ person. B) Consider that given $k-1$ held the bag before the $k+1$ person, Calculate is the probability that person K wins  C) Given that person $k + 1$ touches the bag before $k-1$ , calculate the probability person k eventually wins. And then use those to calculate the probability of $K$ winning. But I am not sure how to calculate the individual probabilities","We have people numbered by standing in a circle.  Person has a bag of chips to start passing around.  Every time, the person who is holding the bag of chips has probability to pass to person and probability to pass to person with .  The game ends when all but one have held the bag, the one who hasn't held the chips gets to eat them. Calculate : the probability that the person will eat the chips The way I wanted to approach this is the following. I realize that for person to be the one, both person and person must have held the bag. I wanted to condition  on  whether  person will have touched  the bag before person or vice versa. This is my first time in probability and I am having trouble approaching the question. I know that we need to A)  compute the probability that the person has held the bag before the person. B) Consider that given held the bag before the person, Calculate is the probability that person K wins  C) Given that person touches the bag before , calculate the probability person k eventually wins. And then use those to calculate the probability of winning. But I am not sure how to calculate the individual probabilities","n+ 1 0,1,...,n 0 k j k+ 1 i = 1-j n−1 j >0.5 P_k k K k+ 1 k−1 k−1 k+ 1 k-1 k+1 k-1 k+1 k + 1 k-1 K","['probability', 'statistics', 'puzzle', 'conditional-probability']"
66,Expected number of times of choosing a word out of a given vocabulary when words are grouped,Expected number of times of choosing a word out of a given vocabulary when words are grouped,,"Two players (player C and player G) are playing a (modified) word guessing game. Both players share the same vocabulary $V$ and words in $V$ are grouped into $K$ bins, denoted as $b_1$ , $b_2$ , ..., $b_{K}$ . Furthermore, we know that $b_{i} \subset V$ and $\cup_{i=1}^{K} b_i = V$ . Note here we do not have $b_i \cap b_j = \emptyset$ for $i \neq j$ . The game protocol is described as follows: Player C uniformly chooses a word $w$ from the vocabulary $V$ . Player G does not know which word $w$ is. Player G chooses one bin and asks Player C whether his/her chosen word $w$ is in the bin. If it is, the game ends. Otherwise, Player G will choose another bin. Questions : What is the best bin choosing order and what is the expected number of times of choosing the bin, according to the best possible order? Example: Suppose we have a vocabulary consisting of ten words $V = \{w_1, w_2, ..., w_{10} \}$ and three bins $b_1 = \{w_1, w_2, ..., w_5\}$ , $b_2 = \{w_6, w_7 \}$ , and $b_3 = \{w_8, w_9, w_{10} \}$ . One possible bin choosing order is $b_1 \rightarrow b_3 \rightarrow b_2$ and the expected number of times of choosing the bin is $\frac{1}{2}*1 + \frac{1}{2}*\frac{3}{5}*2 + \frac{1}{2}*\frac{2}{5}*\frac{2}{2}*3 = 1.7$ . I suspect this is the best bin choosing order but how can we prove this result? Thanks. Note A related question (which has additional non-overlapping constraints on the bins) is asked in MO and in its comment, the user @DavidG.Stork gives a good answer (an intuitive proof of best ordering) for the case when those bins have no overlap.","Two players (player C and player G) are playing a (modified) word guessing game. Both players share the same vocabulary and words in are grouped into bins, denoted as , , ..., . Furthermore, we know that and . Note here we do not have for . The game protocol is described as follows: Player C uniformly chooses a word from the vocabulary . Player G does not know which word is. Player G chooses one bin and asks Player C whether his/her chosen word is in the bin. If it is, the game ends. Otherwise, Player G will choose another bin. Questions : What is the best bin choosing order and what is the expected number of times of choosing the bin, according to the best possible order? Example: Suppose we have a vocabulary consisting of ten words and three bins , , and . One possible bin choosing order is and the expected number of times of choosing the bin is . I suspect this is the best bin choosing order but how can we prove this result? Thanks. Note A related question (which has additional non-overlapping constraints on the bins) is asked in MO and in its comment, the user @DavidG.Stork gives a good answer (an intuitive proof of best ordering) for the case when those bins have no overlap.","V V K b_1 b_2 b_{K} b_{i} \subset V \cup_{i=1}^{K} b_i = V b_i \cap b_j = \emptyset i \neq j w V w w V = \{w_1, w_2, ..., w_{10} \} b_1 = \{w_1, w_2, ..., w_5\} b_2 = \{w_6, w_7 \} b_3 = \{w_8, w_9, w_{10} \} b_1 \rightarrow b_3 \rightarrow b_2 \frac{1}{2}*1 + \frac{1}{2}*\frac{3}{5}*2 + \frac{1}{2}*\frac{2}{5}*\frac{2}{2}*3 = 1.7","['probability', 'combinatorics']"
67,Probability of match in three elements choosing from a group,Probability of match in three elements choosing from a group,,"One of my teachers asked all 26 ( $t$ ) of the students in our class to randomly choose 5 ( $k$ ) exercises from a website from a set of 20 ( $n$ ). He then said that no two students in the class should have 3 ( $s$ ) or more of the same exercises solved. I want to know the probability of two students in the class having 3 ( $s$ ) of the same exercises solved. I know if $s$ was equal to $k$ , it would be the same as the birthday problem with ( $n$ choose $k$ ) days and a room of $t$ , but what about the other case of $s<k$ ?","One of my teachers asked all 26 ( ) of the students in our class to randomly choose 5 ( ) exercises from a website from a set of 20 ( ). He then said that no two students in the class should have 3 ( ) or more of the same exercises solved. I want to know the probability of two students in the class having 3 ( ) of the same exercises solved. I know if was equal to , it would be the same as the birthday problem with ( choose ) days and a room of , but what about the other case of ?",t k n s s s k n k t s<k,"['probability', 'birthday']"
68,If you are wrong twice you have more chance of being right [closed],If you are wrong twice you have more chance of being right [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Imagine you are having a test in high school,  the teacher says ""you have two minutes until I take your test"".  You are doing the last question and you are clearly wrong, you have no time to redo the question.  what should you do?  my theory says that you should try to make one of your calculations wrong,  because if you are one hundred percent sure you are wrong and you are making a mistake at being wrong,  than you increase your chances of being right. So to make it short it is better to be wrong twice then being wrong once if you are trying to get the right answer.  If someone want to help me prove this it would be great i am just a high school kid Thanks for reading, comment your thoughts.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Imagine you are having a test in high school,  the teacher says ""you have two minutes until I take your test"".  You are doing the last question and you are clearly wrong, you have no time to redo the question.  what should you do?  my theory says that you should try to make one of your calculations wrong,  because if you are one hundred percent sure you are wrong and you are making a mistake at being wrong,  than you increase your chances of being right. So to make it short it is better to be wrong twice then being wrong once if you are trying to get the right answer.  If someone want to help me prove this it would be great i am just a high school kid Thanks for reading, comment your thoughts.",,['probability']
69,The draw for the fifth round of the FA Cup,The draw for the fifth round of the FA Cup,,"The draw for the fifth round of the FA Cup is about to be made. There are 16 teams, leading to eight matches. Your task is to pair the teams off, in an attempt to guess as many as possible of the actual matches in the real Cup draw. You are not asked which teams will be drawn at home, just which pairs will be selected. What is the probability of at least four correct guesses? I thought about using a conditional probability tree, after the third level it became too large and confusing. I split the tree into 8 different levels, at level one probability of selecting a correct pair is 1/15, then, level 2 depends on whether level one guess picked a correct pair or not. Previous correct pair will compute to 1/13, a previous wrong selection will compute to 6/91. As I developed d tree it became a little complex.","The draw for the fifth round of the FA Cup is about to be made. There are 16 teams, leading to eight matches. Your task is to pair the teams off, in an attempt to guess as many as possible of the actual matches in the real Cup draw. You are not asked which teams will be drawn at home, just which pairs will be selected. What is the probability of at least four correct guesses? I thought about using a conditional probability tree, after the third level it became too large and confusing. I split the tree into 8 different levels, at level one probability of selecting a correct pair is 1/15, then, level 2 depends on whether level one guess picked a correct pair or not. Previous correct pair will compute to 1/13, a previous wrong selection will compute to 6/91. As I developed d tree it became a little complex.",,['probability']
70,An example of a submartingale $X=\{X_n\}$ such that $\{X_n^2\}$ is a supermartingale.,An example of a submartingale  such that  is a supermartingale.,X=\{X_n\} \{X_n^2\},"A submartingale is a real-valued stochastic process $X=\{X_n\}$ adapted to a filtration $\{\mathcal{F}_n\}$ such that $$E[X_{n+1}\mid \mathcal{F}_n] \geq X_n.$$ For a supermartingale just reverse the inequality. So I don't want someone to just give me the answer, but I'm having trouble just coming up with a submartingale at all. I've been using Durrett's book and there is a lack of examples for sure. Could someone point me in the right direction? Thank you so much!","A submartingale is a real-valued stochastic process adapted to a filtration such that For a supermartingale just reverse the inequality. So I don't want someone to just give me the answer, but I'm having trouble just coming up with a submartingale at all. I've been using Durrett's book and there is a lack of examples for sure. Could someone point me in the right direction? Thank you so much!",X=\{X_n\} \{\mathcal{F}_n\} E[X_{n+1}\mid \mathcal{F}_n] \geq X_n.,"['probability', 'probability-theory', 'stochastic-processes', 'martingales']"
71,Unbiased real vector with respect to arbitrary orthonormal basis for a finite Hilbert space,Unbiased real vector with respect to arbitrary orthonormal basis for a finite Hilbert space,,"Here I use Dirac notation to denote vectors. I would like to show that for an arbitrary orthonormal basis $\{ |\psi_k\rangle \}_{k=1}^n \subset \mathbb C^n$ , $$\langle \psi_i | \psi_j \rangle = \begin{cases} 1 & i = j \\ 0 & i \neq j \end{cases}$$ there exists phases $\{\theta_k\}_{k=1}^n \subset [0, 2\pi]$ such that $\sum_{k=1}^n e^{i\theta_k}|\psi_k\rangle \in \mathbb R^n$ . Or equivalently, there exists a real vector $|v\rangle \in \mathbb R^n (|v\rangle \neq 0)$ such that $$|\langle v|\psi_1 \rangle| = \cdots = |\langle v|\psi_n \rangle|$$ The case $n=2$ is easy. Let $$| \psi_1 \rangle = \begin{pmatrix} \alpha_1 \\ \beta_1 \end{pmatrix} \ \ \ \    | \psi_2 \rangle = \begin{pmatrix} \alpha_2 \\ \beta_2 \end{pmatrix} \ \ \ \    | v \rangle = \begin{pmatrix} x \\ y \end{pmatrix}$$ It is easy to check that the quadratic equation of $x, y$ $$|\langle v|\psi_1 \rangle|^2-|\langle v|\psi_2 \rangle|^2 = (|\alpha_1|^2 - |\alpha_2|^2)x^2 + (|\beta_1|^2 - |\beta_2|^2)y^2 + 2\operatorname{Re}(\alpha_1\bar\beta_1 - \alpha_2\bar\beta_2)xy= 0$$ has non-trivial real roots. However, it seems that the high dimensional cases are more serious. Are there any suggestions to me?","Here I use Dirac notation to denote vectors. I would like to show that for an arbitrary orthonormal basis , there exists phases such that . Or equivalently, there exists a real vector such that The case is easy. Let It is easy to check that the quadratic equation of has non-trivial real roots. However, it seems that the high dimensional cases are more serious. Are there any suggestions to me?","\{ |\psi_k\rangle \}_{k=1}^n \subset \mathbb C^n \langle \psi_i | \psi_j \rangle = \begin{cases} 1 & i = j \\ 0 & i \neq j \end{cases} \{\theta_k\}_{k=1}^n \subset [0, 2\pi] \sum_{k=1}^n e^{i\theta_k}|\psi_k\rangle \in \mathbb R^n |v\rangle \in \mathbb R^n (|v\rangle \neq 0) |\langle v|\psi_1 \rangle| = \cdots = |\langle v|\psi_n \rangle| n=2 | \psi_1 \rangle = \begin{pmatrix} \alpha_1 \\ \beta_1 \end{pmatrix} \ \ \ \ 
  | \psi_2 \rangle = \begin{pmatrix} \alpha_2 \\ \beta_2 \end{pmatrix} \ \ \ \ 
  | v \rangle = \begin{pmatrix} x \\ y \end{pmatrix} x, y |\langle v|\psi_1 \rangle|^2-|\langle v|\psi_2 \rangle|^2 = (|\alpha_1|^2 - |\alpha_2|^2)x^2 + (|\beta_1|^2 - |\beta_2|^2)y^2 + 2\operatorname{Re}(\alpha_1\bar\beta_1 - \alpha_2\bar\beta_2)xy= 0","['probability', 'vector-spaces']"
72,An inequality involving two probability densities,An inequality involving two probability densities,,"I cannot prove the following inequality, which I state below: Let $p, q$ be two positive real numbers such that $p+q=1$ . Let $f$ and $g$ be two probability density functions. Then, show that: $$\int_{\mathbb{R}} \frac{p^2 f^2 + q^2 g^2}{pf + qg} \geq p^2+q^2~.$$ I tried to use Cauchy-Schwarz and even Titu's lemma, but got nowhere. Any help will be greatly appreciated. Thanks!","I cannot prove the following inequality, which I state below: Let be two positive real numbers such that . Let and be two probability density functions. Then, show that: I tried to use Cauchy-Schwarz and even Titu's lemma, but got nowhere. Any help will be greatly appreciated. Thanks!","p, q p+q=1 f g \int_{\mathbb{R}} \frac{p^2 f^2 + q^2 g^2}{pf + qg} \geq p^2+q^2~.","['probability', 'inequality']"
73,A Probabilistic Drinking Problem,A Probabilistic Drinking Problem,,"This question was asked by a fellow MSE user in chat. Motivational credits to @ Quintec . Question: Bob goes to a bar and drinks a drink. On drink $n$ , Bob has a $1-\left(\frac12\right)^n$ probability of getting drunk. If he doesn't get drunk that drink, then he will add $n$ drinks to the amount of drinks he drinks. Even if he gets drunk before finishing his ""queue"" of drinks, he will still finish the rest of the drinks. He will stop drinking after that. What is his expected number of drinks? Attempt: We have the following relationships: 1  drunk -> 1 (probability 1/2)  not drunk -> 1 2 (adds on one drink - probability 1/2)  1 2  drunk -> 1 2 (probability 3/4)  not drunk -> 1 2 3 4 (adds on two drinks - probability 1/4)  1 2 3 4  drunk -> 1 2 3 4 (probability 7/8)  not drunk -> 1 2 3 4 5 6 7 (adds on three drinks - probability 1/8)  1 2 3 4 5 6 7 and so on Therefore the expectation is given by $$\frac12\times1+\frac12\left[\frac34\times2+\frac14\left[\frac78\times4+\frac18\left[\cdots\right]\right]\right]=\sum_{i=1}^\infty\left[\frac1{2^{i(i-1)/2}}\times\frac{2^i-1}{2^i}\times\left(1+\frac{i(i-1)}2\right)\right]$$ on noticing that $1,2,4,7,\cdots$ are the sequence of one plus the triangular numbers, and this can be written as $$\sum_{i=1}^\infty \frac{2^i-1}{2^{(i^2+i+2)/2}}\left(i^2-i+2\right)\approx1.800$$ Unfortunately, W|A does not return a closed form . So is there any methods to find such a form, if any exists?","This question was asked by a fellow MSE user in chat. Motivational credits to @ Quintec . Question: Bob goes to a bar and drinks a drink. On drink , Bob has a probability of getting drunk. If he doesn't get drunk that drink, then he will add drinks to the amount of drinks he drinks. Even if he gets drunk before finishing his ""queue"" of drinks, he will still finish the rest of the drinks. He will stop drinking after that. What is his expected number of drinks? Attempt: We have the following relationships: 1  drunk -> 1 (probability 1/2)  not drunk -> 1 2 (adds on one drink - probability 1/2)  1 2  drunk -> 1 2 (probability 3/4)  not drunk -> 1 2 3 4 (adds on two drinks - probability 1/4)  1 2 3 4  drunk -> 1 2 3 4 (probability 7/8)  not drunk -> 1 2 3 4 5 6 7 (adds on three drinks - probability 1/8)  1 2 3 4 5 6 7 and so on Therefore the expectation is given by on noticing that are the sequence of one plus the triangular numbers, and this can be written as Unfortunately, W|A does not return a closed form . So is there any methods to find such a form, if any exists?","n 1-\left(\frac12\right)^n n \frac12\times1+\frac12\left[\frac34\times2+\frac14\left[\frac78\times4+\frac18\left[\cdots\right]\right]\right]=\sum_{i=1}^\infty\left[\frac1{2^{i(i-1)/2}}\times\frac{2^i-1}{2^i}\times\left(1+\frac{i(i-1)}2\right)\right] 1,2,4,7,\cdots \sum_{i=1}^\infty \frac{2^i-1}{2^{(i^2+i+2)/2}}\left(i^2-i+2\right)\approx1.800","['probability', 'sequences-and-series', 'closed-form', 'expected-value']"
74,Conditional probability given only an average,Conditional probability given only an average,,"I’ve been working on this question, which I found on physics.SE. Unfortunately it was closed because it’s a homework question, but I’d like to get more of a hint than the original poster got. I know that I’m supposed to use Bayes’ Theorem, but I don’t see how I’m supposed to use the fact that $\bar{N}$ is known. Every effort so far has yielded an unwieldy fraction that can’t be simplified. Edit: Apparently I'm supposed to copy/paste the question. Here it is: This is one of the exercises of Barnett's book on quantum information . A particle counter records counts with an efficiency $\eta$ . This means that each particle is detected with probability $\eta$ and missed with probability $1-\eta$ . Let $N$ be the number of particles present and $n$ be  the number of detected.  Then: \begin{equation} P(n|N)=\frac{N!}{n!(N-n)!}\eta^n (1-\eta)^{N-n} \end{equation} I know the mean number of particle present is: \begin{equation} \bar{N}=\sum N P(N) \end{equation} I want to calculate $P(N|n)$ . I'm stuck here by a while, so I do not know how to proceed. Edit 2: I'm adding a screenshot of the question in question:","I’ve been working on this question, which I found on physics.SE. Unfortunately it was closed because it’s a homework question, but I’d like to get more of a hint than the original poster got. I know that I’m supposed to use Bayes’ Theorem, but I don’t see how I’m supposed to use the fact that is known. Every effort so far has yielded an unwieldy fraction that can’t be simplified. Edit: Apparently I'm supposed to copy/paste the question. Here it is: This is one of the exercises of Barnett's book on quantum information . A particle counter records counts with an efficiency . This means that each particle is detected with probability and missed with probability . Let be the number of particles present and be  the number of detected.  Then: I know the mean number of particle present is: I want to calculate . I'm stuck here by a while, so I do not know how to proceed. Edit 2: I'm adding a screenshot of the question in question:","\bar{N} \eta \eta 1-\eta N n \begin{equation}
P(n|N)=\frac{N!}{n!(N-n)!}\eta^n (1-\eta)^{N-n}
\end{equation} \begin{equation}
\bar{N}=\sum N P(N)
\end{equation} P(N|n)","['probability', 'conditional-probability', 'bayes-theorem', 'quantum-information']"
75,Why does PageRank use 0.85 as a standard damping factor?,Why does PageRank use 0.85 as a standard damping factor?,,"I understand that for a low damping factor, some nodes will rarely be reached and a high damping factor will slow down the algorithm and cause the random walk to be stuck in 'sinks', and as such a middle ground is preferable. However, is there a precise reason for a 0.85 factor ? Does 0.8, 0.9, or 0.75 work just as well ?","I understand that for a low damping factor, some nodes will rarely be reached and a high damping factor will slow down the algorithm and cause the random walk to be stuck in 'sinks', and as such a middle ground is preferable. However, is there a precise reason for a 0.85 factor ? Does 0.8, 0.9, or 0.75 work just as well ?",,"['linear-algebra', 'probability', 'page-rank']"
76,How to play a betting game,How to play a betting game,,"I have been interviewing in a few trading firms recently. I came up with the following question myself, but it is similar to some of the questions they ask and ways of thinking they expect. Suppose you have some capital to invest (for example \$100). You can play a game where you bet \$x of your money and with probability $\frac{2}{3}$ your bet is doubled (so now you have \$(100 + x)) and with probability $\frac{1}{3}$ you lose your bet (so now you have \$(100 - x)). How much should you bet on this game. I can see two ways of thinking about this problem. Firstly, there is the expected value maximisation approach. It can be easily seen that your expected gain in this game is $\frac{x}{3}$ . So in order to maximise EV you should bet all of your money instantly. And if you were to play this game a million times, you should bet all of your money each time. Of course this approach has the obvious flaw that when you play a few times, you will almost certainly go bankrupt. So we decide not to maximise EV and instead first make sure that we never go bankrupt. We do it by deciding to, at each point of the game, always bet exactly the same proportion of our money, say $p$ . Then after $n=n_1+n_2$ games, where our bet was doubled $n_1$ times and we lost $n_2$ times, we will have $M \cdot (1+p)^{n_1} \cdot (1-p)^{n_2}$ money, where $M$ was our initial amount. Differentiating the log of this with respect to $p$ we can see that this function has its maximum for $p=\frac{n_1-n_2}{n} \rightarrow \frac{2}{3}-\frac{1}{3} = \frac{1}{3}$ as $n \rightarrow \infty$ . So if we bet just a third of our money every time, we are (almost) guaranteed not to go bankrupt and, out of the strategies that bet a constant proportion every time, this one maximises our gain in the most likely outcome. So here is my question - does this second strategy make sense to you? If you were to play this game with your own money would you use it? Does it make any sense to use a different strategy if you only play once, and not many times? I personally would be tempted to bet more than a third if I only got one chance, because it would increase my EV even if it is potentially bad in the long term. Does this sentiment make any sense? Also, I just described two ways of thinking about the game above. Do you know of any other ways to think about it? Other strategies? Please share your thoughts!","I have been interviewing in a few trading firms recently. I came up with the following question myself, but it is similar to some of the questions they ask and ways of thinking they expect. Suppose you have some capital to invest (for example \$100). You can play a game where you bet \$x of your money and with probability your bet is doubled (so now you have \$(100 + x)) and with probability you lose your bet (so now you have \$(100 - x)). How much should you bet on this game. I can see two ways of thinking about this problem. Firstly, there is the expected value maximisation approach. It can be easily seen that your expected gain in this game is . So in order to maximise EV you should bet all of your money instantly. And if you were to play this game a million times, you should bet all of your money each time. Of course this approach has the obvious flaw that when you play a few times, you will almost certainly go bankrupt. So we decide not to maximise EV and instead first make sure that we never go bankrupt. We do it by deciding to, at each point of the game, always bet exactly the same proportion of our money, say . Then after games, where our bet was doubled times and we lost times, we will have money, where was our initial amount. Differentiating the log of this with respect to we can see that this function has its maximum for as . So if we bet just a third of our money every time, we are (almost) guaranteed not to go bankrupt and, out of the strategies that bet a constant proportion every time, this one maximises our gain in the most likely outcome. So here is my question - does this second strategy make sense to you? If you were to play this game with your own money would you use it? Does it make any sense to use a different strategy if you only play once, and not many times? I personally would be tempted to bet more than a third if I only got one chance, because it would increase my EV even if it is potentially bad in the long term. Does this sentiment make any sense? Also, I just described two ways of thinking about the game above. Do you know of any other ways to think about it? Other strategies? Please share your thoughts!",\frac{2}{3} \frac{1}{3} \frac{x}{3} p n=n_1+n_2 n_1 n_2 M \cdot (1+p)^{n_1} \cdot (1-p)^{n_2} M p p=\frac{n_1-n_2}{n} \rightarrow \frac{2}{3}-\frac{1}{3} = \frac{1}{3} n \rightarrow \infty,"['probability', 'puzzle', 'finance', 'gambling']"
77,Calculating the expectation of a sum of dependent random variables,Calculating the expectation of a sum of dependent random variables,,"Let $(X_i)_{i=1}^m$ be a sequence of i.i.d. Bernoulli random variables such that $\Pr(X_i=1)=p<0.5$ and $\Pr(X_i=0)=1-p$ . Let $(Y_i)_{i=1}^m$ be defined as follows: $Y_1=X_1$ , and for $2\leq i\leq m$ $$ Y_i = \begin{cases} 1,\ &\mathrm{if\ \ \ }p\left(1-\frac{1}{i-1}\sum_{j=1}^{i-1}Y_j\right)+(1-p)\frac{1}{i-1}\sum_{j=1}^{i-1}Y_j<\frac{1}{i}\sum_{j=1}^iX_j\\ 0,\ & \mathrm{otherwise} \end{cases} $$ Finally, define $$ Z_i=\begin{cases} Y_i,\ &\mathrm{w.p. }\ \ 1-p\\ 1-Y_i,\ & \mathrm{w.p. }\ \ p \end{cases} $$ for $i=1,2,\ldots,m$ . I want to calculate or get an upper bound on the expectation $\mathbb{E}\left(\sum_{i=1}^mZ_i\right)$ and the variance $\mathrm{Var}\left(\sum_{i=1}^mZ_i\right)$ . For any $i$ , we have $\mathbb{E}Z_i = p+(1-2p)\mathbb{E}Y_i$ . So a trivial upper bound is $$ \mathbb{E}\left(\sum_{i=1}^mZ_i\right) =mp+(1-2p)\sum_{i=1}^m\mathbb{E}Y_i\leq mp+m(1-2p) = m(1-p) $$ becasue $\mathbb{E}Y_i\leq1$ . Unfortunately, when trying to calculate explicitly $\mathbb{E}Y_i$ things quickly become quite involved. Is there any way to get better bounds? Numerical calculation (as well as analytical calculation of the first few) of the means of the random variables $Y_i$ suggest that $\mathbb{E}Y_i\leq \mathbb{E}Y_1 = p$ for any $i$ , which would give $$ \mathbb{E}\left(\sum_{i=1}^mZ_i\right)\leq 2mp(1-p) $$ However, it is not clear if $\mathbb{E}Y_i\leq \mathbb{E}Y_1$ is indeed true.","Let be a sequence of i.i.d. Bernoulli random variables such that and . Let be defined as follows: , and for Finally, define for . I want to calculate or get an upper bound on the expectation and the variance . For any , we have . So a trivial upper bound is becasue . Unfortunately, when trying to calculate explicitly things quickly become quite involved. Is there any way to get better bounds? Numerical calculation (as well as analytical calculation of the first few) of the means of the random variables suggest that for any , which would give However, it is not clear if is indeed true.","(X_i)_{i=1}^m \Pr(X_i=1)=p<0.5 \Pr(X_i=0)=1-p (Y_i)_{i=1}^m Y_1=X_1 2\leq i\leq m 
Y_i = \begin{cases}
1,\ &\mathrm{if\ \ \ }p\left(1-\frac{1}{i-1}\sum_{j=1}^{i-1}Y_j\right)+(1-p)\frac{1}{i-1}\sum_{j=1}^{i-1}Y_j<\frac{1}{i}\sum_{j=1}^iX_j\\
0,\ & \mathrm{otherwise}
\end{cases}
 
Z_i=\begin{cases}
Y_i,\ &\mathrm{w.p. }\ \ 1-p\\
1-Y_i,\ & \mathrm{w.p. }\ \ p
\end{cases}
 i=1,2,\ldots,m \mathbb{E}\left(\sum_{i=1}^mZ_i\right) \mathrm{Var}\left(\sum_{i=1}^mZ_i\right) i \mathbb{E}Z_i = p+(1-2p)\mathbb{E}Y_i 
\mathbb{E}\left(\sum_{i=1}^mZ_i\right) =mp+(1-2p)\sum_{i=1}^m\mathbb{E}Y_i\leq mp+m(1-2p) = m(1-p)
 \mathbb{E}Y_i\leq1 \mathbb{E}Y_i Y_i \mathbb{E}Y_i\leq \mathbb{E}Y_1 = p i 
\mathbb{E}\left(\sum_{i=1}^mZ_i\right)\leq 2mp(1-p)
 \mathbb{E}Y_i\leq \mathbb{E}Y_1","['probability', 'probability-theory']"
78,"If $\phi$ is a characteristic function, then $1-|\phi(2t)|\leq 8\{1-|\phi(t)|\}$","If  is a characteristic function, then",\phi 1-|\phi(2t)|\leq 8\{1-|\phi(t)|\},"Question If $\phi$ is a characteristic function, show that $\text{Re}\{1-\phi(t)\}\geq \frac{1}{4}\text{Re}(1-\phi(2t))$ and deduce that $1-|\phi(2t)|\leq 8\{1-|\phi(t)|\}$ . My attempt I have managed to show the first part, but unable to deduce the second part. Here is a proof of the first part. It is immediate that $\text{Re}\{1-\phi(t)\}=E(1-\cos tX)$ and $\text{Re}(1-\phi(2t))=E(1-\cos 2tX)$ , but then $$ 4E(1-\cos tX)-E(1-\cos2tX)=2E(1-\cos tX)^2\geq 0 $$ from which the first claim follows. My problem I have not been able to use the first part to deduce the second claim. I tried squaring and both sides and using the fact that $|\text{Re}\; z|\leq |z|$ (so in particular $1-|\phi(2t)|\leq 1-|\text{Re}\;\phi(2t)|$ ) but did not get too far. Any help is appreciated.","Question If is a characteristic function, show that and deduce that . My attempt I have managed to show the first part, but unable to deduce the second part. Here is a proof of the first part. It is immediate that and , but then from which the first claim follows. My problem I have not been able to use the first part to deduce the second claim. I tried squaring and both sides and using the fact that (so in particular ) but did not get too far. Any help is appreciated.","\phi \text{Re}\{1-\phi(t)\}\geq \frac{1}{4}\text{Re}(1-\phi(2t)) 1-|\phi(2t)|\leq 8\{1-|\phi(t)|\} \text{Re}\{1-\phi(t)\}=E(1-\cos tX) \text{Re}(1-\phi(2t))=E(1-\cos 2tX) 
4E(1-\cos tX)-E(1-\cos2tX)=2E(1-\cos tX)^2\geq 0
 |\text{Re}\; z|\leq |z| 1-|\phi(2t)|\leq 1-|\text{Re}\;\phi(2t)|","['real-analysis', 'probability', 'probability-theory', 'characteristic-functions']"
79,Probability of guessing correct password (out of n) on k-th try when trying them at random,Probability of guessing correct password (out of n) on k-th try when trying them at random,,"I am currently reading the course notes on probability theory from Stanford CS109 . In order to practice a bit and get used to the topics presented, I am also trying to solve the problem sets, but I came across one which I find a bit ambiguous. It's problem 11a from Problem Set 1 : Say a hacker has a list of n distinct password candidates, only one of which will successfully log her into a secure system. a. If she tries passwords from the list at random, deleting those passwords that do not work, what is the probability that her first successful login will be (exactly) on her k-th try? We suppose that k is between 1 and n (inclusive), otherwise the problem is trivial. One way of thinking about the problem would be the following: the probability of being successful on the k-th try is the product of the probabilities of choosing a wrong password on the first k - 1 steps multiplied by the probability of being successful on the k-th step, which is: $$ p = \frac{n - 1}{n} \frac{n - 2}{n - 1} \cdots \frac{n - k + 1}{n - k + 2} \frac{1}{n - k + 1}  = \frac{1}{n} $$ Another way would be to think of all the n! permutations of the n passwords and see every permutation as the order in which the hacker will try the passwords. We are interested in finding the number of permutations that have, let's say, element x (the correct password) on the k-th position. There are (n - 1)! such permutations, therefore the answer will be still $ \frac{1}{n} $ . There is one problem with this approach: Let's suppose there are 3 passwords: $p_1$ , $p_2$ and $p_3$ . There are 6 possible permutations of these 3 passwords: $$ p_1, p_2, p_3, \\    p_1, p_3, p_2, \\    p_2, p_1, p_3, \\    p_2, p_3, p_1, \\    p_3, p_1, p_2, \\    p_3, p_2, p_1, $$ so if we want to find the probability of guessing the correct password from the first try, using the above formula we'd say it is $\frac{1}{3}$ . However, as long as the hacker found the correct password from the first try, the first 2 permutations are actually equivalent (we are not interested in the order in which the hacker was supposed to try the next passwords - as long as she found the correct one, she stops - or at least this is how I interpret the problem), so the correct probability would actually be $\frac{1}{5}$ . Because of this reason, the first approach is also incorrect. My explanation for this would be the following: if we denote by $T_i$ the i-th trial and $T_k=1$ when the hacker guesses the correct password on the k-th try, what we want to find is $$ P(T_0 = 0 \wedge T_1 = 0 \wedge \cdots \wedge  T_{k-1} = 0 \wedge T_k = 1) ,$$ (where by $\wedge$ we denote the probability of the events occuring together) which would be equal to the product of the probabilities of each event only in the case when all the events are independent (and in our case they are not, as we stop trying passwords once we guess the correct one) The final (and I suppose, correct) perspective is: the probability of guessing on the k-th try is represented by the number of ways in which the hacker can guess on the k-th try divided by the total number of ways in which the hacker can guess the password in general (which is the sum of ways in which the hacker can guess the password on the i-th try, with i from 1 to n). There are: $$ (n-1)(n-2)\cdots(n-k+1) = \prod_{i = 1}^{k - 1} (n-i), \text{if k > 1} $$ $$ 1, \text{if k = 1} $$ ways in which she can guess the correct password on the k-th try, so the result would be: $$ \frac{\prod_{i = 1}^{k - 1} (n-i)}{1 + \sum_{j=2}^{j=n} \prod_{i = 1}^{i = j - 1} (n-i) } $$ My question is: is my reasoning correct and if not, where is the mistake ? The different perspectives are the result of a debate with someone, but we couldn't agree on the correct answer (although I am pretty sure that the last one is correct, but there might be something I am missing) Thank you!","I am currently reading the course notes on probability theory from Stanford CS109 . In order to practice a bit and get used to the topics presented, I am also trying to solve the problem sets, but I came across one which I find a bit ambiguous. It's problem 11a from Problem Set 1 : Say a hacker has a list of n distinct password candidates, only one of which will successfully log her into a secure system. a. If she tries passwords from the list at random, deleting those passwords that do not work, what is the probability that her first successful login will be (exactly) on her k-th try? We suppose that k is between 1 and n (inclusive), otherwise the problem is trivial. One way of thinking about the problem would be the following: the probability of being successful on the k-th try is the product of the probabilities of choosing a wrong password on the first k - 1 steps multiplied by the probability of being successful on the k-th step, which is: Another way would be to think of all the n! permutations of the n passwords and see every permutation as the order in which the hacker will try the passwords. We are interested in finding the number of permutations that have, let's say, element x (the correct password) on the k-th position. There are (n - 1)! such permutations, therefore the answer will be still . There is one problem with this approach: Let's suppose there are 3 passwords: , and . There are 6 possible permutations of these 3 passwords: so if we want to find the probability of guessing the correct password from the first try, using the above formula we'd say it is . However, as long as the hacker found the correct password from the first try, the first 2 permutations are actually equivalent (we are not interested in the order in which the hacker was supposed to try the next passwords - as long as she found the correct one, she stops - or at least this is how I interpret the problem), so the correct probability would actually be . Because of this reason, the first approach is also incorrect. My explanation for this would be the following: if we denote by the i-th trial and when the hacker guesses the correct password on the k-th try, what we want to find is (where by we denote the probability of the events occuring together) which would be equal to the product of the probabilities of each event only in the case when all the events are independent (and in our case they are not, as we stop trying passwords once we guess the correct one) The final (and I suppose, correct) perspective is: the probability of guessing on the k-th try is represented by the number of ways in which the hacker can guess on the k-th try divided by the total number of ways in which the hacker can guess the password in general (which is the sum of ways in which the hacker can guess the password on the i-th try, with i from 1 to n). There are: ways in which she can guess the correct password on the k-th try, so the result would be: My question is: is my reasoning correct and if not, where is the mistake ? The different perspectives are the result of a debate with someone, but we couldn't agree on the correct answer (although I am pretty sure that the last one is correct, but there might be something I am missing) Thank you!"," p = \frac{n - 1}{n} \frac{n - 2}{n - 1} \cdots \frac{n - k + 1}{n - k + 2} \frac{1}{n - k + 1}  = \frac{1}{n}   \frac{1}{n}  p_1 p_2 p_3  p_1, p_2, p_3, \\
   p_1, p_3, p_2, \\
   p_2, p_1, p_3, \\
   p_2, p_3, p_1, \\
   p_3, p_1, p_2, \\
   p_3, p_2, p_1,  \frac{1}{3} \frac{1}{5} T_i T_k=1  P(T_0 = 0 \wedge T_1 = 0 \wedge \cdots \wedge  T_{k-1} = 0 \wedge T_k = 1) , \wedge  (n-1)(n-2)\cdots(n-k+1) = \prod_{i = 1}^{k - 1} (n-i), \text{if k > 1}   1, \text{if k = 1}   \frac{\prod_{i = 1}^{k - 1} (n-i)}{1 + \sum_{j=2}^{j=n} \prod_{i = 1}^{i = j - 1} (n-i) } ","['probability', 'combinatorics']"
80,Random Variable with Characteristic function $\frac{1}{2-\phi(t)}$,Random Variable with Characteristic function,\frac{1}{2-\phi(t)},"I am given that $X$ has c.f. $\phi(t)$ , I need to find the random variable whose c.f. is equal to $\frac{1}{2-\phi(t)}$ in terms of $X$ . My idea is that express $\frac{1}{2-\phi(t)}$ as a series, since $|\phi(t)| \leq 1$ so we have $$ \frac{1}{2-\phi(t)} = \sum_{n = 0}^{\infty}\frac{\phi(t)^n}{2^{n+1}} $$ From the question asked here , I am guessing that this c.f. corresponds to the random variable (I may be wrong): $$ Z = \sum_{n = 0}^{\infty}I(A = n)Z_n $$ where $P(A = n) = \frac{1}{2^{n+1}}, \ n = 0,1,2,...$ and $Z_n = \sum_{i = 1}^{n}Y_i$ , $Z_0 = 0$ , $Y_i$ are iid r.v.'s s.t. $Y_i \sim X$ . But I don't know how to prove this, can anyone point out a general direction? Thanks so much!","I am given that has c.f. , I need to find the random variable whose c.f. is equal to in terms of . My idea is that express as a series, since so we have From the question asked here , I am guessing that this c.f. corresponds to the random variable (I may be wrong): where and , , are iid r.v.'s s.t. . But I don't know how to prove this, can anyone point out a general direction? Thanks so much!","X \phi(t) \frac{1}{2-\phi(t)} X \frac{1}{2-\phi(t)} |\phi(t)| \leq 1 
\frac{1}{2-\phi(t)} = \sum_{n = 0}^{\infty}\frac{\phi(t)^n}{2^{n+1}}
 
Z = \sum_{n = 0}^{\infty}I(A = n)Z_n
 P(A = n) = \frac{1}{2^{n+1}}, \ n = 0,1,2,... Z_n = \sum_{i = 1}^{n}Y_i Z_0 = 0 Y_i Y_i \sim X","['probability', 'characteristic-functions']"
81,A martingale converging in distribution but not a.s. or in probability,A martingale converging in distribution but not a.s. or in probability,,"I am now working on R. Durrett's Probability Theory and Examples . In his book, I am asked to construct a martingale $(X_n)$ satisfying the following three conditions. (1) $P(X_n=a$ i.o. $)=1, a=-1,0,1$ (2) $\sup_n|X_n|<\infty$ (3) For some preassigned $p \in (0,1/2)$ , $P(X_n=1),P(X_n=-1)\rightarrow p, P(X_n=0) \rightarrow 1-2p$ So that this martingale converges in distribution but not a.s. or in probability. I know there already exists an answered question regarding (1)&(2), but so far I haven't found any identical question. So I guess this question is not a duplicate. I have been spending 2 days and could not come up with an example. Especially, condition (3) is hard to manage since I cannot make use of the similar trick used in the answer of Martingale oscillating between three values Any hint would be appreciated! Thanks and regards.","I am now working on R. Durrett's Probability Theory and Examples . In his book, I am asked to construct a martingale satisfying the following three conditions. (1) i.o. (2) (3) For some preassigned , So that this martingale converges in distribution but not a.s. or in probability. I know there already exists an answered question regarding (1)&(2), but so far I haven't found any identical question. So I guess this question is not a duplicate. I have been spending 2 days and could not come up with an example. Especially, condition (3) is hard to manage since I cannot make use of the similar trick used in the answer of Martingale oscillating between three values Any hint would be appreciated! Thanks and regards.","(X_n) P(X_n=a )=1, a=-1,0,1 \sup_n|X_n|<\infty p \in (0,1/2) P(X_n=1),P(X_n=-1)\rightarrow p, P(X_n=0) \rightarrow 1-2p","['probability', 'sequences-and-series', 'probability-theory', 'convergence-divergence', 'martingales']"
82,Expected value of measurement error for the maximum,Expected value of measurement error for the maximum,,"Suppose that we have $n$ independently and identically distributed variables $X_1, \cdots, X_n$ which we observe with zero mean measurement error. More precisely, we observe $X^*_i = X_i + U_i$ where the errors $U_1, \cdots, U_n$ are independently and identically distributed, $E[U_i] = 0$ and every $U_i$ is independent of every $X_i$ . I need to show that $$E[U_i \mid X^*_i \geq X^*_j \hspace{0.1cm}\forall j] \geq 0.$$ Intuitively, this is obvious: one reason why $X_i + U_i$ could be maximal is that $U_i$ is high, which in turn suggests that the expected value of $U_i$ is high given that $X_i + U_i$ is maximal. However, I am struggling to show this formally and would be grateful for some help. Here is my 'progress' so far (I may have over-complicated matters, if so please point me towards a better way forward): First, I note that by Bayes' theorem, we can write the density of $U$ given that $X + U$ takes some particular value $c$ : \begin{align*} f_{U \mid U+X=c}(u) &= \frac{f_{U+X}(c \mid U=u)f_U(u)}{f_{U+X}(c)} = \frac{f_{X}(c-u)f_U(u)}{f_{U+X}(c)}\\ &= \frac{f_X(c-u)f_U(u)}{\displaystyle \int_{-\infty}^{\infty}f_U(k)f_X(c-k)\,\mathrm{d}k}. \end{align*} From this, I get the expected value of $U$ given that $X+U=c$ : $$E[U \mid U+X=c]= \int_{\underline{u}}^{\bar{u}}f_{U \mid U+X=c}(u)u\,\mathrm{d}u = \int_{\underline{u}}^{\bar{u}}\frac{f_X(c-u)f_U(u)}{\displaystyle\int_{-\infty}^{\infty}f_U(k)f_X(c-k)\,\mathrm{d}k}(u)u\,\mathrm{d}u,$$ where $\bar{u}$ and $\underline{u}$ bound the support of $U$ (I will assume a finite support, but presumably the argument goes through without this assumption?) This tells us the expected value of $U_i$ given that $X_i + U_i = c$ . However, we wanted to know the expected value of $U_i$ given that $X_i + U_i$ is maximal. Fortunately, we know the distribution of $X_i + U_i$ given that it is maximal, i.e. the distribution of the 'highest order statistic' of $X_i + U_i$ : $$f_{X + U \mid X + U \text{ is maximal}}(c) = \left(\int_{-\infty}^{\infty}f_U(k)f_X(c-k)\,\mathrm{d}k\right)^n.$$ By the law of iterated expectations, we thus obtain: \begin{align*} &\mathrel{\phantom{=}}{} E[U_i \mid X^*_i \geq X^*_j\ \forall j]\\ &= \int{E[U \mid U+X=c]}f_{X+U \mid X + U \text{ is maximal}}(c)\,\mathrm{d}c\\ &= \int\Biggl(\int_{\underline{u}}^{\bar{u}}\frac{f_X(c-u)f_U(u)}{\displaystyle\int_{-\infty}^{\infty}f_U(k)f_X(c-k)\,\mathrm{d}k}u\,\mathrm{d}u\Biggr)\left(\int_{-\infty}^{\infty}f_U(k)f_X(c-k)\,\mathrm{d}k\right)^n \,\mathrm{d}c \end{align*} It thus seems that I have found the expression I am after. However, when looking at this rather complicated expression, I see no way to show that it is non-negative (the whole point of the exercise!) If you can see a way, or can think of a simpler approach than the one I have adopted, please do let me know. Thanks again in advance!","Suppose that we have independently and identically distributed variables which we observe with zero mean measurement error. More precisely, we observe where the errors are independently and identically distributed, and every is independent of every . I need to show that Intuitively, this is obvious: one reason why could be maximal is that is high, which in turn suggests that the expected value of is high given that is maximal. However, I am struggling to show this formally and would be grateful for some help. Here is my 'progress' so far (I may have over-complicated matters, if so please point me towards a better way forward): First, I note that by Bayes' theorem, we can write the density of given that takes some particular value : From this, I get the expected value of given that : where and bound the support of (I will assume a finite support, but presumably the argument goes through without this assumption?) This tells us the expected value of given that . However, we wanted to know the expected value of given that is maximal. Fortunately, we know the distribution of given that it is maximal, i.e. the distribution of the 'highest order statistic' of : By the law of iterated expectations, we thus obtain: It thus seems that I have found the expression I am after. However, when looking at this rather complicated expression, I see no way to show that it is non-negative (the whole point of the exercise!) If you can see a way, or can think of a simpler approach than the one I have adopted, please do let me know. Thanks again in advance!","n X_1, \cdots, X_n X^*_i = X_i + U_i U_1, \cdots, U_n E[U_i] = 0 U_i X_i E[U_i \mid X^*_i \geq X^*_j \hspace{0.1cm}\forall j] \geq 0. X_i + U_i U_i U_i X_i + U_i U X + U c \begin{align*}
f_{U \mid U+X=c}(u) &= \frac{f_{U+X}(c \mid U=u)f_U(u)}{f_{U+X}(c)} = \frac{f_{X}(c-u)f_U(u)}{f_{U+X}(c)}\\
&= \frac{f_X(c-u)f_U(u)}{\displaystyle \int_{-\infty}^{\infty}f_U(k)f_X(c-k)\,\mathrm{d}k}.
\end{align*} U X+U=c E[U \mid U+X=c]= \int_{\underline{u}}^{\bar{u}}f_{U \mid U+X=c}(u)u\,\mathrm{d}u = \int_{\underline{u}}^{\bar{u}}\frac{f_X(c-u)f_U(u)}{\displaystyle\int_{-\infty}^{\infty}f_U(k)f_X(c-k)\,\mathrm{d}k}(u)u\,\mathrm{d}u, \bar{u} \underline{u} U U_i X_i + U_i = c U_i X_i + U_i X_i + U_i X_i + U_i f_{X + U \mid X + U \text{ is maximal}}(c) = \left(\int_{-\infty}^{\infty}f_U(k)f_X(c-k)\,\mathrm{d}k\right)^n. \begin{align*}
&\mathrel{\phantom{=}}{} E[U_i \mid X^*_i \geq X^*_j\ \forall j]\\
&= \int{E[U \mid U+X=c]}f_{X+U \mid X + U \text{ is maximal}}(c)\,\mathrm{d}c\\
&= \int\Biggl(\int_{\underline{u}}^{\bar{u}}\frac{f_X(c-u)f_U(u)}{\displaystyle\int_{-\infty}^{\infty}f_U(k)f_X(c-k)\,\mathrm{d}k}u\,\mathrm{d}u\Biggr)\left(\int_{-\infty}^{\infty}f_U(k)f_X(c-k)\,\mathrm{d}k\right)^n \,\mathrm{d}c
\end{align*}","['probability', 'conditional-probability', 'expected-value']"
83,Equivalence of conditions for Convergence of Non-negative Random Series,Equivalence of conditions for Convergence of Non-negative Random Series,,"Question Let $X_n\geq 0$ be independent for $n\geq 1$ . The following are equivalent. $\sum_{n=1}^\infty X_n<\infty$ a.s. $\sum_{n=1}^\infty[P(X_n>1)+E(X_nI(X_n\leq 1)]<\infty$ $\sum_{n=1}^\infty E(X_n/(1+X_n))<\infty$ My attempt I was able to prove $(1)$ implies $(2)$ and $(2)$ implies $(3)$ but not $(3)$ implies $(1)$ . For $(1)$ implies $(2)$ , observe that by Borel-Cantelli $\sum_{n=1}^\infty P(X_n>1)<\infty$ , else $X_n>1$ infinitely often w.p.1 so that $(1)$ is violated. To see that $\sum_{n=1}^\infty E(X_nI(X_n\leq 1)]<\infty$ , apply Kolmogorov three-series theorem (I think). For $(2)$ implies $(3)$ we can write that $$ \begin{align} \frac{X_n}{1+X_n}& =\frac{X_n}{1+X_n}I(X_n\leq 1)+\frac{X_n}{1+X_n}I(X_n>1)\\ &\leq X_nI(X_n\leq 1)+ I(X_n>1). \end{align} $$ Now take the expectation of both sides and sum on $n$ using $(2)$ to conclude $(3)$ . For the last implication $(3)$ implies $(1)$ , I tried to use Kolmogorov three series theorem. To this end put $Y_n=X_nI(X_n\leq 1)$ . First note that $\sum_{n=1}^\infty P(X_n>1)<\infty$ since $$ P(X_n>1)\leq P\left(\frac{X_n}{1+X_n}>\frac{1}{2}\right)\leq 2E\frac{X_n}{1+X_n} $$ by Markov's inequality. But I am unable to show that $\sum EY_n<\infty$ and $\sum\text{Var}(Y_n)<\infty$ . Any help is appreciated.","Question Let be independent for . The following are equivalent. a.s. My attempt I was able to prove implies and implies but not implies . For implies , observe that by Borel-Cantelli , else infinitely often w.p.1 so that is violated. To see that , apply Kolmogorov three-series theorem (I think). For implies we can write that Now take the expectation of both sides and sum on using to conclude . For the last implication implies , I tried to use Kolmogorov three series theorem. To this end put . First note that since by Markov's inequality. But I am unable to show that and . Any help is appreciated.","X_n\geq 0 n\geq 1 \sum_{n=1}^\infty X_n<\infty \sum_{n=1}^\infty[P(X_n>1)+E(X_nI(X_n\leq 1)]<\infty \sum_{n=1}^\infty E(X_n/(1+X_n))<\infty (1) (2) (2) (3) (3) (1) (1) (2) \sum_{n=1}^\infty P(X_n>1)<\infty X_n>1 (1) \sum_{n=1}^\infty E(X_nI(X_n\leq 1)]<\infty (2) (3) 
\begin{align}
\frac{X_n}{1+X_n}&
=\frac{X_n}{1+X_n}I(X_n\leq 1)+\frac{X_n}{1+X_n}I(X_n>1)\\
&\leq X_nI(X_n\leq 1)+ I(X_n>1).
\end{align}
 n (2) (3) (3) (1) Y_n=X_nI(X_n\leq 1) \sum_{n=1}^\infty P(X_n>1)<\infty 
P(X_n>1)\leq P\left(\frac{X_n}{1+X_n}>\frac{1}{2}\right)\leq 2E\frac{X_n}{1+X_n}
 \sum EY_n<\infty \sum\text{Var}(Y_n)<\infty","['real-analysis', 'probability', 'probability-theory', 'convergence-divergence']"
84,"What numbers in $[0,1]$ can be generated by tossing a fair coin?",What numbers in  can be generated by tossing a fair coin?,"[0,1]","What numbers in the interval $[0,1]$ can be generated by tossing a   fair coin? By generating a number using a coin, we mean finding an event that its probability is the given number. I think that any number in $[0,1]$ can be generated by tossing a fair coin for an infinite number of times because we can generate the binary expansion. And by generating, I mean finding an event that gives the desired probability. So, it seems that if tossing a coin for an infinite number is allowed, the problem's done. However, what if we disallowed tossing for infinitely many times? Then I think only those numbers whose denominator are a power of $2$ can be expressed. Others cannot be expressed. But I am not sure. Any help is appreciated.","What numbers in the interval can be generated by tossing a   fair coin? By generating a number using a coin, we mean finding an event that its probability is the given number. I think that any number in can be generated by tossing a fair coin for an infinite number of times because we can generate the binary expansion. And by generating, I mean finding an event that gives the desired probability. So, it seems that if tossing a coin for an infinite number is allowed, the problem's done. However, what if we disallowed tossing for infinitely many times? Then I think only those numbers whose denominator are a power of can be expressed. Others cannot be expressed. But I am not sure. Any help is appreciated.","[0,1] [0,1] 2",['probability']
85,"What is the number of subsets of $\{1, ..., n\}$ which sum to a given number $k \leq \frac{n(n+1)}{2}$?",What is the number of subsets of  which sum to a given number ?,"\{1, ..., n\} k \leq \frac{n(n+1)}{2}","I'm trying to compute the number of ways to sum the first $n$ unique positive integers to a number $k$ . This is not a partition of $n$ since we can't repeat numbers. Any hints on how I can derive a generating function for this? I encountered this in trying to compute the variance of the sum of $k$ balls randomly drawn from an urn of $n$ balls (where each ball is labeled with a unique positive integer from $1...n$ ). Letting $S$ be the random variable which is this sum, computing the variance using the definition of expectation directly uses $P(S = k) = \frac{N_{n,k}}{{n\choose k}}$ , where $N_{n,k}$ denotes the desired quantity above. I can compute the variance by writing $S$ as a sum of indicators and expanding the expression inside of the expectation, but I was wondering if there was a nice expression for the above quantity. Thank you!","I'm trying to compute the number of ways to sum the first unique positive integers to a number . This is not a partition of since we can't repeat numbers. Any hints on how I can derive a generating function for this? I encountered this in trying to compute the variance of the sum of balls randomly drawn from an urn of balls (where each ball is labeled with a unique positive integer from ). Letting be the random variable which is this sum, computing the variance using the definition of expectation directly uses , where denotes the desired quantity above. I can compute the variance by writing as a sum of indicators and expanding the expression inside of the expectation, but I was wondering if there was a nice expression for the above quantity. Thank you!","n k n k n 1...n S P(S = k) = \frac{N_{n,k}}{{n\choose k}} N_{n,k} S","['probability', 'combinatorics']"
86,"If five cards are drawn randomly from an ordinary deck, what is the probability of drawing exactly three face cards?","If five cards are drawn randomly from an ordinary deck, what is the probability of drawing exactly three face cards?",,"From an ordinary deck of $52$ cards, five are drawn randomly. What is the probability of drawing exactly three face cards? (assume no replacement) I wrote the probability as a fraction with denominator $\binom{52}{5}$. For the numerator I wrote $\binom{12}{3}\binom{40}{2}$. My answer was approximately $.0660$.","From an ordinary deck of $52$ cards, five are drawn randomly. What is the probability of drawing exactly three face cards? (assume no replacement) I wrote the probability as a fraction with denominator $\binom{52}{5}$. For the numerator I wrote $\binom{12}{3}\binom{40}{2}$. My answer was approximately $.0660$.",,"['probability', 'combinatorics']"
87,How one can show the joint probability density fucntion does not exist?,How one can show the joint probability density fucntion does not exist?,,"Let $X \sim \mathcal{U}(0,1)$ be an unifrom random variable and $Y = X$. I am trying to show that the joint pdf of $X$ and $Y$ does not exist. Here is what I have gone so far. Suppose there exists a function $f(x,y)$ such that  $$ F(x,y) = P(X \le x, Y \le y) = \int_0^x \int_0^y f(t_1,t_2)dt_1dt_2. $$ Note that $1 = f_X(t_1) = \int_0^1 f(t_1,t_2)dt_2$  and $1 = f_X(t_2) = f_Y(t_2) = \int_0^1 f(t_1,t_2)dt_1$. Since $X = Y$, we have  $$ F(x,y) = P(X \le \min\{x,y\}) = \int_0^{\min\{x,y\}} f_X(t_1)dt_1 = \int_0^{\min\{x,y\}} dt_1 = \min\{x,y\}. $$ I was trying to show somehow $f(t_1,t_2) = 1$ based on $f_X(t_1)=1=f_Y(t_2)$ to draw a contradiction. But not sure how to do this. Any comments/answers will be very appreciated. Thanks.","Let $X \sim \mathcal{U}(0,1)$ be an unifrom random variable and $Y = X$. I am trying to show that the joint pdf of $X$ and $Y$ does not exist. Here is what I have gone so far. Suppose there exists a function $f(x,y)$ such that  $$ F(x,y) = P(X \le x, Y \le y) = \int_0^x \int_0^y f(t_1,t_2)dt_1dt_2. $$ Note that $1 = f_X(t_1) = \int_0^1 f(t_1,t_2)dt_2$  and $1 = f_X(t_2) = f_Y(t_2) = \int_0^1 f(t_1,t_2)dt_1$. Since $X = Y$, we have  $$ F(x,y) = P(X \le \min\{x,y\}) = \int_0^{\min\{x,y\}} f_X(t_1)dt_1 = \int_0^{\min\{x,y\}} dt_1 = \min\{x,y\}. $$ I was trying to show somehow $f(t_1,t_2) = 1$ based on $f_X(t_1)=1=f_Y(t_2)$ to draw a contradiction. But not sure how to do this. Any comments/answers will be very appreciated. Thanks.",,"['probability', 'probability-theory', 'probability-distributions']"
88,Proving convergence in probability.,Proving convergence in probability.,,"Let $Y_k$ be independently Bernoulli distributed rvs holding $P(Y_k = 1) = \frac{1}{k}$ for every $k = 1,2,...,n$. I need to prove that the sum $\frac{1}{\log n} \sum_{k=1}^n Y_k$ converges in probability to $1$. How can I also check if it converges or not almost surely? Well, I tried to use some well known inequalities but they don't work. Also Kolmogorov's theorem is of no use here.","Let $Y_k$ be independently Bernoulli distributed rvs holding $P(Y_k = 1) = \frac{1}{k}$ for every $k = 1,2,...,n$. I need to prove that the sum $\frac{1}{\log n} \sum_{k=1}^n Y_k$ converges in probability to $1$. How can I also check if it converges or not almost surely? Well, I tried to use some well known inequalities but they don't work. Also Kolmogorov's theorem is of no use here.",,"['probability', 'weak-convergence']"
89,Average distance detween two random points on two line segments,Average distance detween two random points on two line segments,,"Suppose you have two straight line of length $L_1$ and $L_2$, and a point is chosen at random along each line. What is the expected distance between these points? This question is a complement of Average Distance Between Random Points on a Line Segment . Best regards!","Suppose you have two straight line of length $L_1$ and $L_2$, and a point is chosen at random along each line. What is the expected distance between these points? This question is a complement of Average Distance Between Random Points on a Line Segment . Best regards!",,"['probability', 'geometry', 'geometric-probability']"
90,"Compute the expectation of $X_{\tau}$ and related probability given its SDE $dX_t = X_t\,dt + \sigma \, dB_t$",Compute the expectation of  and related probability given its SDE,"X_{\tau} dX_t = X_t\,dt + \sigma \, dB_t","Suppose there is a stochastic process $X_t$ satisfying the SDE $dX_t = X_t\,dt + \sigma \,dB_t$ where $B_t$ denotes the standard Brownian motion starting from $0$. Let $a<b$ being two real numbers. Define $\tau = \inf\{t:X_t\notin [a,b]\}$ and I want to find $E[X_\tau\mid X_0=x]$. I know one method using Feynman-Kac theorem. Denote $u(t,X_t) = E[X_\tau\mid X_t]$ exploiting its markovian property. Then $u$ is a martingale by Tower property. By Ito's lemma: $$ du(t,X_t)=u_t\ dt+u_x\ dX_t+\frac{1}{2}u_{xx}\ d[X]_t=(u_t + u_xX_t + \frac{\sigma^2}{2} u_{xx})\ dt + \sigma u_x\ dB_t $$ So we get the PDE: \begin{cases} u_t + xu_x + \frac{\sigma^2}{2} u_{xx}=0\\ u(t,a)=a\\ u(t,b)=b \end{cases} Notice $u_t=0$, we simply swich $u(t,x)=u(x)=E[X_\tau\mid X_t=x]$ to get \begin{cases} xu_x + \frac{\sigma^2}{2} u_{xx}=0\\ u(a)=a\\ u(b)=b \end{cases} Solve this and we get $$ u(x)=a\frac{\int_x^{b}e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx} + b\frac{\int_a^x e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx} $$ Since $u(x)$ should have a form like $$ u(x)=aP(X_\tau=a) + bP(X_\tau=b) $$ Is it safe to guess $P(X_\tau=a \mid X_t=x)=\frac{\int_x^b e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx}$ and $P(X_\tau=b \mid X_t=x)=\frac{\int_a^x e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx}$? My reason is that it seems very reasonable if $x$ increases from $a$ to $b$, $X_\tau$ varies from $a$ and more and more likely becomes $b$ when $x$ increases. Besides, $\frac{\int_a^x e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx} + \frac{\int_x^b e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx}=1$. I generally have three questions: How to justify $P(X_\tau = a) + P(X_\tau = b) = 1$, namely $P(\tau = \infty) = 0$? How to justify $P(X_\tau = a)$ and $P(X_\tau = b)$ happen to be the coefficient of $a$ and $b$ in the expression of $u(x)$? I also learned a technique to compute this type of problem by constructing martingales like $B_t^2-t$ when we compute the exit time of Brownian motion. Is there similar way to solve this problem? I notice $e^{-t}X_t$ is a martingale but don't know how to proceed. Thank you for any help!","Suppose there is a stochastic process $X_t$ satisfying the SDE $dX_t = X_t\,dt + \sigma \,dB_t$ where $B_t$ denotes the standard Brownian motion starting from $0$. Let $a<b$ being two real numbers. Define $\tau = \inf\{t:X_t\notin [a,b]\}$ and I want to find $E[X_\tau\mid X_0=x]$. I know one method using Feynman-Kac theorem. Denote $u(t,X_t) = E[X_\tau\mid X_t]$ exploiting its markovian property. Then $u$ is a martingale by Tower property. By Ito's lemma: $$ du(t,X_t)=u_t\ dt+u_x\ dX_t+\frac{1}{2}u_{xx}\ d[X]_t=(u_t + u_xX_t + \frac{\sigma^2}{2} u_{xx})\ dt + \sigma u_x\ dB_t $$ So we get the PDE: \begin{cases} u_t + xu_x + \frac{\sigma^2}{2} u_{xx}=0\\ u(t,a)=a\\ u(t,b)=b \end{cases} Notice $u_t=0$, we simply swich $u(t,x)=u(x)=E[X_\tau\mid X_t=x]$ to get \begin{cases} xu_x + \frac{\sigma^2}{2} u_{xx}=0\\ u(a)=a\\ u(b)=b \end{cases} Solve this and we get $$ u(x)=a\frac{\int_x^{b}e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx} + b\frac{\int_a^x e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx} $$ Since $u(x)$ should have a form like $$ u(x)=aP(X_\tau=a) + bP(X_\tau=b) $$ Is it safe to guess $P(X_\tau=a \mid X_t=x)=\frac{\int_x^b e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx}$ and $P(X_\tau=b \mid X_t=x)=\frac{\int_a^x e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx}$? My reason is that it seems very reasonable if $x$ increases from $a$ to $b$, $X_\tau$ varies from $a$ and more and more likely becomes $b$ when $x$ increases. Besides, $\frac{\int_a^x e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx} + \frac{\int_x^b e^{-\frac{x^2}{\sigma^2}}\ dx}{\int_a^b e^{-\frac{x^2}{\sigma^2}}\ dx}=1$. I generally have three questions: How to justify $P(X_\tau = a) + P(X_\tau = b) = 1$, namely $P(\tau = \infty) = 0$? How to justify $P(X_\tau = a)$ and $P(X_\tau = b)$ happen to be the coefficient of $a$ and $b$ in the expression of $u(x)$? I also learned a technique to compute this type of problem by constructing martingales like $B_t^2-t$ when we compute the exit time of Brownian motion. Is there similar way to solve this problem? I notice $e^{-t}X_t$ is a martingale but don't know how to proceed. Thank you for any help!",,"['probability', 'stochastic-processes', 'expectation', 'martingales']"
91,Find the probability that atleast one valve is defective.,Find the probability that atleast one valve is defective.,,"A factory A produces $10$% defective valves and another factory $B$ produces 20% defective valves.A bag contains $4$ valves of factory $A$ and $5$ valves of factory B.If two valves are drawn at random from the bag,find the probability that at least one valve is defective. $P(\text{at least one valve is defective})=\\=1-P(\text{none of the two valves are defective})=\\=1-\left(\frac{\binom{4}{2}}{\binom{9}{2}}(0.9)^2+\frac{\binom{5}{2}}{\binom{9}{2}}(0.8)^2+\frac{\binom{4}{1}\binom{5}{1}}{\binom{9}{2}}(0.9)(0.8)\right)=\frac{517}{1800}$, but the answer given is $\frac{303}{1800}$ I don't know where i am wrong.","A factory A produces $10$% defective valves and another factory $B$ produces 20% defective valves.A bag contains $4$ valves of factory $A$ and $5$ valves of factory B.If two valves are drawn at random from the bag,find the probability that at least one valve is defective. $P(\text{at least one valve is defective})=\\=1-P(\text{none of the two valves are defective})=\\=1-\left(\frac{\binom{4}{2}}{\binom{9}{2}}(0.9)^2+\frac{\binom{5}{2}}{\binom{9}{2}}(0.8)^2+\frac{\binom{4}{1}\binom{5}{1}}{\binom{9}{2}}(0.9)(0.8)\right)=\frac{517}{1800}$, but the answer given is $\frac{303}{1800}$ I don't know where i am wrong.",,"['probability', 'combinatorics']"
92,Calculate weak limit of $S_n/\sqrt{n}$,Calculate weak limit of,S_n/\sqrt{n},"Let $(X_n)_{n\in \mathbb N}$ be independent continuous random variables with cdf $$f_n(x) := f_{X_n}(x) = \frac{n+1}{2}\lvert x \rvert ^n \mathbb 1_{[-1,1]}.$$ Let $S_n := \sum_{k=1}^nX_k$  and calculate the weak limit of $S_n/\sqrt{n}.$ Approach: The first thing I tried is to find the density of $X_1 + X_2$ by calculating the convolution of $f_1, f_2$ but that gets a little messy to calculate. Also, trying to calculate the characteristic function of $X_n$ is not very smooth either (You could use partial integration $n$ times), there must be an easier way. Is there maybe a way to invoke the central limit theorem by modifying stuff? Any help appreciated!","Let $(X_n)_{n\in \mathbb N}$ be independent continuous random variables with cdf $$f_n(x) := f_{X_n}(x) = \frac{n+1}{2}\lvert x \rvert ^n \mathbb 1_{[-1,1]}.$$ Let $S_n := \sum_{k=1}^nX_k$  and calculate the weak limit of $S_n/\sqrt{n}.$ Approach: The first thing I tried is to find the density of $X_1 + X_2$ by calculating the convolution of $f_1, f_2$ but that gets a little messy to calculate. Also, trying to calculate the characteristic function of $X_n$ is not very smooth either (You could use partial integration $n$ times), there must be an easier way. Is there maybe a way to invoke the central limit theorem by modifying stuff? Any help appreciated!",,"['probability', 'limits', 'probability-theory', 'probability-distributions', 'central-limit-theorem']"
93,Probability given in the form of $a^{-x}$. Is my answer correct?,Probability given in the form of . Is my answer correct?,a^{-x},"I'm having trouble solving this exercise about probability, as I'm new to the subject. It says: There is a bus supposed to arrive at 8:00. The probability of it to set out with $m$ minutes of delay is $p_m = 3^{-m} (m = 1; 2; 3; ... ;m \neq 0)$. Due to regulatory issues, the set out is never advanced (i.e. it never sets out before 8:00). 1) What's the probability of the bus setting out at 8:00? 2) Prove that the probability of the bus to set out at 8:10 is double the probability that of after 8:10. Here is what I think about it, but I have no answer to check with: I assume all possible values go from 8:00 to infinity, so if I add all those values the probability should be 1. Now, $3^{-m}$ looks like a series I know, and I know it converges as 1/3 is less than 1, so the sum of all terms is $1*\frac{1}{1-1/3}=\frac{3}{2}$, but as that formula is when n starts at 0, then I have to do $\frac{3}{2}-3^0$, which is 0.5. Then, I guess that 1-0.5 is the remaining probability, that is, of the bus setting out exactly at 8:00. Is what I've done correct? Because I don't think we're mixing calculus with probabability in the course. For 2), my guess is calculate $3^{-10}$, and I have to prove that $3^{-10} = 2*\sum_{m=11}^\infty 3^{-m}$. Is it correct? What I do next is calculate the sum, which I don't really know how to do, so I do $3/2 -\sum_{m=0}^{10} 3^{-m}$, put that in the calculator and I get that it's true. So, to wrap it all up... Have I done everything ok? Because I don't have the results. I suppose the second one is correct because I've proven it, but I've no idea about the first one, whether I'm meant to do that or there is another way. I hope you can help me. Thank you!","I'm having trouble solving this exercise about probability, as I'm new to the subject. It says: There is a bus supposed to arrive at 8:00. The probability of it to set out with $m$ minutes of delay is $p_m = 3^{-m} (m = 1; 2; 3; ... ;m \neq 0)$. Due to regulatory issues, the set out is never advanced (i.e. it never sets out before 8:00). 1) What's the probability of the bus setting out at 8:00? 2) Prove that the probability of the bus to set out at 8:10 is double the probability that of after 8:10. Here is what I think about it, but I have no answer to check with: I assume all possible values go from 8:00 to infinity, so if I add all those values the probability should be 1. Now, $3^{-m}$ looks like a series I know, and I know it converges as 1/3 is less than 1, so the sum of all terms is $1*\frac{1}{1-1/3}=\frac{3}{2}$, but as that formula is when n starts at 0, then I have to do $\frac{3}{2}-3^0$, which is 0.5. Then, I guess that 1-0.5 is the remaining probability, that is, of the bus setting out exactly at 8:00. Is what I've done correct? Because I don't think we're mixing calculus with probabability in the course. For 2), my guess is calculate $3^{-10}$, and I have to prove that $3^{-10} = 2*\sum_{m=11}^\infty 3^{-m}$. Is it correct? What I do next is calculate the sum, which I don't really know how to do, so I do $3/2 -\sum_{m=0}^{10} 3^{-m}$, put that in the calculator and I get that it's true. So, to wrap it all up... Have I done everything ok? Because I don't have the results. I suppose the second one is correct because I've proven it, but I've no idea about the first one, whether I'm meant to do that or there is another way. I hope you can help me. Thank you!",,[]
94,Probability that a delaunay triangle contains the center of its circumcircle,Probability that a delaunay triangle contains the center of its circumcircle,,"A Delaunay triangulation for a given set P of discrete points in a plane is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). https://en.wikipedia.org/wiki/Delaunay_triangulation In the Delaunay triangulation of a Poisson point process in the plane, the probability that a triangle contains the center of its circumcircle is ? https://en.wikipedia.org/wiki/Poisson_point_process I know for a fact that it is not $\frac{1}{4}$ which is the probability that the center of the circle is contained within the triangle formed by three random points on the circle. I find this troubling, I don't know how the probability changes from $\frac{1}{4}$ for the delaunay triangle probability.","A Delaunay triangulation for a given set P of discrete points in a plane is a triangulation DT(P) such that no point in P is inside the circumcircle of any triangle in DT(P). https://en.wikipedia.org/wiki/Delaunay_triangulation In the Delaunay triangulation of a Poisson point process in the plane, the probability that a triangle contains the center of its circumcircle is ? https://en.wikipedia.org/wiki/Poisson_point_process I know for a fact that it is not $\frac{1}{4}$ which is the probability that the center of the circle is contained within the triangle formed by three random points on the circle. I find this troubling, I don't know how the probability changes from $\frac{1}{4}$ for the delaunay triangle probability.",,"['probability', 'geometry', 'geometric-probability', 'triangulation']"
95,Sequence of normal random variables converging in distribution,Sequence of normal random variables converging in distribution,,Let $X_{n}$ be a sequence of normal random variables with mean $\mu_{n}$ and variance $\sigma^{2}_{n}$ for $n \geq 1$. Suppose $X_{n} \rightarrow X$ in distribution where $X \neq c$ almost surely for a constant $c \in \mathbb{R}$. It is to show that in this case there exist $\mu \in \mathbb{R}$ and  $\sigma^{2} > 0$ such that $X$ is normal distributed with mean $\mu$ and variance $\sigma^{2}$. Anyone has an idea how to prove it?,Let $X_{n}$ be a sequence of normal random variables with mean $\mu_{n}$ and variance $\sigma^{2}_{n}$ for $n \geq 1$. Suppose $X_{n} \rightarrow X$ in distribution where $X \neq c$ almost surely for a constant $c \in \mathbb{R}$. It is to show that in this case there exist $\mu \in \mathbb{R}$ and  $\sigma^{2} > 0$ such that $X$ is normal distributed with mean $\mu$ and variance $\sigma^{2}$. Anyone has an idea how to prove it?,,"['probability', 'probability-theory']"
96,How to compute density function of $Y=X-\lfloor X \rfloor$?,How to compute density function of ?,Y=X-\lfloor X \rfloor,"We're given that X is a continous r.v. and has a density function of $f_X(x)$ and we're asked to find the density function of $Y=X-\lfloor X \rfloor$ in terms of $f_X(x)$. We're also given the hint : to use the expression $P(Y \le x ,\lfloor X \rfloor =i)$ where $i$ is integer. $$P(Y \le x ,\lfloor X \rfloor =i) = P(X - \lfloor X \rfloor  \le x, \lfloor X \rfloor  = i)$$ $$=P(X - i \le x, \lfloor X \rfloor  = i)$$ $$=P(X \le x + i, \lfloor X \rfloor  = i)$$ $$=P(X \le x + i,i \le X \lt  i + 1)$$ I tried to expand it but this doesn't lead to anywhere. (I'm glad to see any answer with or without the hint). The follow up question in the book is to specify $f_Y(y)$ if $X \sim exp(\lambda)$. (So I need to find a ""general"" form first)","We're given that X is a continous r.v. and has a density function of $f_X(x)$ and we're asked to find the density function of $Y=X-\lfloor X \rfloor$ in terms of $f_X(x)$. We're also given the hint : to use the expression $P(Y \le x ,\lfloor X \rfloor =i)$ where $i$ is integer. $$P(Y \le x ,\lfloor X \rfloor =i) = P(X - \lfloor X \rfloor  \le x, \lfloor X \rfloor  = i)$$ $$=P(X - i \le x, \lfloor X \rfloor  = i)$$ $$=P(X \le x + i, \lfloor X \rfloor  = i)$$ $$=P(X \le x + i,i \le X \lt  i + 1)$$ I tried to expand it but this doesn't lead to anywhere. (I'm glad to see any answer with or without the hint). The follow up question in the book is to specify $f_Y(y)$ if $X \sim exp(\lambda)$. (So I need to find a ""general"" form first)",,"['probability', 'ceiling-and-floor-functions']"
97,Can someone explain to me why hot hand phenomenon is considered a fallacy?,Can someone explain to me why hot hand phenomenon is considered a fallacy?,,"Hot hands refers to the idea that a player who has scored a basket (therefore, has ""hot hands"") is more likely to score the next basket. It is suggested that this is a fallacy because apparently scoring is considered a random event (as far as I understand it).  It is the equivalent of flipping coins.  And just as when you flip coins, you  might get three heads in a row by chance, the same applies to scoring in basketball.  So players probably remember those sequences when they scores several baskets in a row and think it had something to do with them. Now I can not shake the feeling that this explanation is incomplete. Let me compare scoring with my efforts to learn probability on my own, which I have been doing for a while. When I get some question right, I become more energized and confident, and am more likely to work on the following question because I feel more hopeful that I will figure it out. But when I try several probability questions and get them all wrong, I am quite unlikely to try my best on the next one.  I have sometimes later returned to questions that I had failed at, noting that they were quite easy but that earlier I had simply lost the will to put in any effort. Anyhow, so to go back to the basketball example, why is each shot is assumed to be completely independent of the previous shots.  Why doesn't a player's effort or confidence level is irrelevant?  I can imagine hot hands applying to someone blindingly throwing the ball and once in a while getting lucky, but the same thing applies to professional players even?  Yes, the ball has no memory but the person throwing the ball does. No?","Hot hands refers to the idea that a player who has scored a basket (therefore, has ""hot hands"") is more likely to score the next basket. It is suggested that this is a fallacy because apparently scoring is considered a random event (as far as I understand it).  It is the equivalent of flipping coins.  And just as when you flip coins, you  might get three heads in a row by chance, the same applies to scoring in basketball.  So players probably remember those sequences when they scores several baskets in a row and think it had something to do with them. Now I can not shake the feeling that this explanation is incomplete. Let me compare scoring with my efforts to learn probability on my own, which I have been doing for a while. When I get some question right, I become more energized and confident, and am more likely to work on the following question because I feel more hopeful that I will figure it out. But when I try several probability questions and get them all wrong, I am quite unlikely to try my best on the next one.  I have sometimes later returned to questions that I had failed at, noting that they were quite easy but that earlier I had simply lost the will to put in any effort. Anyhow, so to go back to the basketball example, why is each shot is assumed to be completely independent of the previous shots.  Why doesn't a player's effort or confidence level is irrelevant?  I can imagine hot hands applying to someone blindingly throwing the ball and once in a while getting lucky, but the same thing applies to professional players even?  Yes, the ball has no memory but the person throwing the ball does. No?",,"['probability', 'random']"
98,Exchangeable matrix,Exchangeable matrix,,"An infinite random sequence $(X_i)_{i \ge 1}$ is defined exchangeable if its distribution is invariant to finite permutations of the indexes, that is $$(X_i)_{i \ge 1} \overset{d}{=} (X_{\sigma(i)})_{i \ge 1},$$ for any finite permutation $\sigma$ of $\mathbb{N}$. An infinite random matrix $(X_{ij})_{ij}$ is defined row-column exchangeable (RCE) if its distribution is invariant to two different permutations of the row indexes and column indexes, that is $$(X_{i j})_{ij} \overset{d}{=} (X_{\sigma(i) \sigma^{\prime}(j)})_{ij},$$ for any pairs of finite permutations $\sigma$ and $\sigma^{\prime}$ of $\mathbb{N}$. This is equivalent to ask that the sequence of rows $(X_{i\cdot})_{i \ge 1}$ are exchangeable and also the sequence of the columns $(X_{\cdot j})_{j \ge 1}$, see Aldus1983 . Question: if fixed an arbitrary row $i \in \mathbb{N}$, $(X_{ij})_{j \ge 1}$ is an exchangeable sequence and fixed an arbitrary column $j \in \mathbb{N}$, $(X_{ij})_{i \ge 1}$ is an exchangeable sequence, the random matrix $(X_{ij})_{ij}$ is row-column exchangeable? Guess: I believe that it is false. More precisely, RCE implies immediately exchangeability inside an arbitrary row and inside an arbitrary column, but I think that from the marginal assumption we can not recover the global one, but I can not find a counterexample.","An infinite random sequence $(X_i)_{i \ge 1}$ is defined exchangeable if its distribution is invariant to finite permutations of the indexes, that is $$(X_i)_{i \ge 1} \overset{d}{=} (X_{\sigma(i)})_{i \ge 1},$$ for any finite permutation $\sigma$ of $\mathbb{N}$. An infinite random matrix $(X_{ij})_{ij}$ is defined row-column exchangeable (RCE) if its distribution is invariant to two different permutations of the row indexes and column indexes, that is $$(X_{i j})_{ij} \overset{d}{=} (X_{\sigma(i) \sigma^{\prime}(j)})_{ij},$$ for any pairs of finite permutations $\sigma$ and $\sigma^{\prime}$ of $\mathbb{N}$. This is equivalent to ask that the sequence of rows $(X_{i\cdot})_{i \ge 1}$ are exchangeable and also the sequence of the columns $(X_{\cdot j})_{j \ge 1}$, see Aldus1983 . Question: if fixed an arbitrary row $i \in \mathbb{N}$, $(X_{ij})_{j \ge 1}$ is an exchangeable sequence and fixed an arbitrary column $j \in \mathbb{N}$, $(X_{ij})_{i \ge 1}$ is an exchangeable sequence, the random matrix $(X_{ij})_{ij}$ is row-column exchangeable? Guess: I believe that it is false. More precisely, RCE implies immediately exchangeability inside an arbitrary row and inside an arbitrary column, but I think that from the marginal assumption we can not recover the global one, but I can not find a counterexample.",,"['probability', 'probability-theory', 'independence']"
99,What's the expected value of working modules?,What's the expected value of working modules?,,"An electric system is made up of $k$ modules. In each module, there are $N$ resistors in series. What is the expected value of working modules if $m$ resistor break down? A module is not working if there is at least $1$ bad resistor in it. I can calculate the trivial cases (for example, $m=1$ , or $m>(k-1)*N$ ), but I can't find out the general solution. For $m\leq N$ , I think I can use the binomial distribution: The probability for a module to have $n$ bad resistor is $$p(n)=\binom{N}{n}\left(\frac{1}{N}\right)^n\left(1-\frac{1}{N}\right)^{N-n}$$ and we would need to sum up this probability to cover all of the possible cases and multiple them with $1, 2, \dots N$ to get the expected value, but it seems to be a really big sum. Bounty: I'd really like to have a solution to this problem, so I started a bounty.","An electric system is made up of modules. In each module, there are resistors in series. What is the expected value of working modules if resistor break down? A module is not working if there is at least bad resistor in it. I can calculate the trivial cases (for example, , or ), but I can't find out the general solution. For , I think I can use the binomial distribution: The probability for a module to have bad resistor is and we would need to sum up this probability to cover all of the possible cases and multiple them with to get the expected value, but it seems to be a really big sum. Bounty: I'd really like to have a solution to this problem, so I started a bounty.","k N m 1 m=1 m>(k-1)*N m\leq N n p(n)=\binom{N}{n}\left(\frac{1}{N}\right)^n\left(1-\frac{1}{N}\right)^{N-n} 1, 2, \dots N",['probability']
