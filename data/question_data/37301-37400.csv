,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,The probability of maximum of two independent Poisson-distributed variables,The probability of maximum of two independent Poisson-distributed variables,,"I have two Poisson distributions with parameters $\lambda_1$ and $\lambda_2$ and two independent variables $A$ and $B$ from these two distributions. I know that $$\begin{equation*} \mathsf P(\min(A,B)>K)=\mathsf P(A>K) \ast \mathsf P(B>K)   \end{equation*}$$ I'm just wondering what $\mathsf P(\max(A,B)>K)$ is. Thanks.","I have two Poisson distributions with parameters $\lambda_1$ and $\lambda_2$ and two independent variables $A$ and $B$ from these two distributions. I know that $$\begin{equation*} \mathsf P(\min(A,B)>K)=\mathsf P(A>K) \ast \mathsf P(B>K)   \end{equation*}$$ I'm just wondering what $\mathsf P(\max(A,B)>K)$ is. Thanks.",,"['probability', 'poisson-distribution']"
1,"Probability of choosing subsets $A$, $B$ such that $A\cap \!\,B=\varnothing \!\,$ and $A\cup \!\,B=X$","Probability of choosing subsets ,  such that  and","A B A\cap \!\,B=\varnothing \!\, A\cup \!\,B=X","I'm given a set $X={\{\ \!\,1,2,3,...,n\!\ \}} $, and I have to calculate the probability that, for two randomly chosen, different, non-empty sets $A, B$: $A,B\subseteq \!\,X$, we have $A\cap \!\,B=\varnothing \!$ and $A\cup \!\,B=X$. I'm aware that the number of possible cases is $(2^n-1)(2^n-2)$, but I don't know how to count the cases which satisfy the above, which is the gist of the question. Also, what would be the probability for the same problem, just without the $A\cup \!\,B=X$ part? Edit: This was my professor's solution for the first problem (with both conditions): $\frac{\displaystyle\sum_{k=1}^{n-1} {n \choose k} \displaystyle\sum_{i=1}^{n-k} {n-k\choose i}}{(2^n-1)(2^n-2)}$ Does this make any sense to anyone?","I'm given a set $X={\{\ \!\,1,2,3,...,n\!\ \}} $, and I have to calculate the probability that, for two randomly chosen, different, non-empty sets $A, B$: $A,B\subseteq \!\,X$, we have $A\cap \!\,B=\varnothing \!$ and $A\cup \!\,B=X$. I'm aware that the number of possible cases is $(2^n-1)(2^n-2)$, but I don't know how to count the cases which satisfy the above, which is the gist of the question. Also, what would be the probability for the same problem, just without the $A\cup \!\,B=X$ part? Edit: This was my professor's solution for the first problem (with both conditions): $\frac{\displaystyle\sum_{k=1}^{n-1} {n \choose k} \displaystyle\sum_{i=1}^{n-k} {n-k\choose i}}{(2^n-1)(2^n-2)}$ Does this make any sense to anyone?",,"['probability', 'combinatorics']"
2,Probability of infinite intersection.,Probability of infinite intersection.,,"I came to the following problem:  Let $A_1, A_2, ...$ be events in a probability space $(\Omega, F, \mathbb{P})$ and $\mathbb{P}[A_j]=1$ for all $j>1$. I need to show that the probability of the intersection of all those events $A_j$, where j goes from 1 to infinity, is also $1$. From what I understand, the events we have are not dependent so we can use the formula for a joint probability, so it will be the product of the probabilities of the events. However, I am not sure whether that formula holds in the general case. Any suggestions?","I came to the following problem:  Let $A_1, A_2, ...$ be events in a probability space $(\Omega, F, \mathbb{P})$ and $\mathbb{P}[A_j]=1$ for all $j>1$. I need to show that the probability of the intersection of all those events $A_j$, where j goes from 1 to infinity, is also $1$. From what I understand, the events we have are not dependent so we can use the formula for a joint probability, so it will be the product of the probabilities of the events. However, I am not sure whether that formula holds in the general case. Any suggestions?",,"['probability', 'probability-theory', 'stochastic-processes']"
3,Probability concerning a 6-digit password,Probability concerning a 6-digit password,,"Consider the situation of decoding a 6-digit password that consists of the symbols $A$ to $Z$ and $0$ to $9$, where all possible combinations are tried randomly and uniformly. (a) What is the probability that the correct password will never be entered? (b) What is the probability that eventually the same combination will be entered two consecutive times? I am so bad in these combinatorial things. Can anybody explain me how to calculate these two probabilities, please? I know that there are $36^5$ possibilities to try. Edit For (a) I think I have to look at $$ \left(\frac{36^5-1}{36^5}\right)^n\to 0\text{ as }n\to\infty. $$ So the probability that the correct password will never be entered is 0.","Consider the situation of decoding a 6-digit password that consists of the symbols $A$ to $Z$ and $0$ to $9$, where all possible combinations are tried randomly and uniformly. (a) What is the probability that the correct password will never be entered? (b) What is the probability that eventually the same combination will be entered two consecutive times? I am so bad in these combinatorial things. Can anybody explain me how to calculate these two probabilities, please? I know that there are $36^5$ possibilities to try. Edit For (a) I think I have to look at $$ \left(\frac{36^5-1}{36^5}\right)^n\to 0\text{ as }n\to\infty. $$ So the probability that the correct password will never be entered is 0.",,"['probability', 'combinatorics']"
4,Variation of Chebsyhev: How to prove that?,Variation of Chebsyhev: How to prove that?,,"I have the ""job"" to prove that for any random variable with standard deviation $\sigma$ and expectation $\mu$ and for any $t>0$ we have $$Pr[X-\mu \geq t \sigma] \leq \frac{1}{1+t^2}.$$ I thought that this would be quite easy and tried to apply Chebyshev, but here's my result: $$Pr[X - \mu \geq t \sigma] \leq Pr[|X-\mu| \geq t \sigma] \leq \frac{Var[X]}{t^2\sigma^2}=\frac{1}{t^2},$$ so my result is too bad, either because Chebyshev is not good enough or because (what I think is the main reason) my first inequality is too ""weak"". How should I handle this in order to get $\frac{1}{1+t^2}$?","I have the ""job"" to prove that for any random variable with standard deviation $\sigma$ and expectation $\mu$ and for any $t>0$ we have $$Pr[X-\mu \geq t \sigma] \leq \frac{1}{1+t^2}.$$ I thought that this would be quite easy and tried to apply Chebyshev, but here's my result: $$Pr[X - \mu \geq t \sigma] \leq Pr[|X-\mu| \geq t \sigma] \leq \frac{Var[X]}{t^2\sigma^2}=\frac{1}{t^2},$$ so my result is too bad, either because Chebyshev is not good enough or because (what I think is the main reason) my first inequality is too ""weak"". How should I handle this in order to get $\frac{1}{1+t^2}$?",,"['probability', 'probability-distributions', 'random-variables', 'expectation', 'distribution-tails']"
5,Random walk on a finite square grid: probability of given position after 15 or 3600 moves,Random walk on a finite square grid: probability of given position after 15 or 3600 moves,,"An ant is walking on the squares of a 5x5 grid - it starts in the center square. Each second, it will choose (with equal probability) to do one of the following: Move north one square Move south one square Move east one square Move west one square Do not move If it cannot perform the action it has decided on (move west while on the  west edge, for example), it sits in place. After one second, it has a 20% chance of being in the center, and a 20% chance of being in each adjacent square. (and a 0% chance of being in any other square on the board). What is the probability that the ant is on the center square after 15 seconds? What is the probability that the ant is on one of the outermost squares after 1 hour? Any suggestions? In the first question, I don't know how to enumerate all the possible routes that finish on the middle square after 15 moves and divide them by the total number of possible routes. In the second one, I'm completely lost. Thanks for your help :-)","An ant is walking on the squares of a 5x5 grid - it starts in the center square. Each second, it will choose (with equal probability) to do one of the following: Move north one square Move south one square Move east one square Move west one square Do not move If it cannot perform the action it has decided on (move west while on the  west edge, for example), it sits in place. After one second, it has a 20% chance of being in the center, and a 20% chance of being in each adjacent square. (and a 0% chance of being in any other square on the board). What is the probability that the ant is on the center square after 15 seconds? What is the probability that the ant is on one of the outermost squares after 1 hour? Any suggestions? In the first question, I don't know how to enumerate all the possible routes that finish on the middle square after 15 moves and divide them by the total number of possible routes. In the second one, I'm completely lost. Thanks for your help :-)",,"['probability', 'combinatorics', 'random-walk']"
6,"Wolfram|Alpha returns the wrong result: how can I solve this ""high precision"" equation?","Wolfram|Alpha returns the wrong result: how can I solve this ""high precision"" equation?",,"$$1-(1-1.40*10^{-36})^x \ge 1.09*10^{-9}$$ I want to estimate $x$ such that the probability on the left becomes larger than the probability on the right. A solution must exist because $1-(1-1.40*10^{-36})^0=0$, $\lim\limits_{n \to \infty} 1-(1-1.40*10^{-36})^n=1$ and the function is continuous. However Wolfram|Alpha seems to return a wrong result . Is my reasoning correct? Is there any (practical) way to estimate the result? For my problem would be sufficient to find the order of magnitude of $x$.","$$1-(1-1.40*10^{-36})^x \ge 1.09*10^{-9}$$ I want to estimate $x$ such that the probability on the left becomes larger than the probability on the right. A solution must exist because $1-(1-1.40*10^{-36})^0=0$, $\lim\limits_{n \to \infty} 1-(1-1.40*10^{-36})^n=1$ and the function is continuous. However Wolfram|Alpha seems to return a wrong result . Is my reasoning correct? Is there any (practical) way to estimate the result? For my problem would be sufficient to find the order of magnitude of $x$.",,"['probability', 'inequality', 'wolfram-alpha']"
7,Conditional expectation of indicator function,Conditional expectation of indicator function,,"Could someone confirm if the following is correct. If not why? \begin{equation} E[\mathbb{1_{X\leq x}}|Y]=P[X|Y]=\frac{P[X,Y]}{P[Y]} \end{equation} Thank you.","Could someone confirm if the following is correct. If not why? \begin{equation} E[\mathbb{1_{X\leq x}}|Y]=P[X|Y]=\frac{P[X,Y]}{P[Y]} \end{equation} Thank you.",,"['probability', 'probability-theory', 'probability-distributions']"
8,Why does maximum likelihood estimation for uniform distribution give maximum of data?,Why does maximum likelihood estimation for uniform distribution give maximum of data?,,"I am looking at parameters estimation for the uniform distribution in the context of MLEs.  Now, I know the likelihood function of the Uniform distribution $U(0,\theta)$ which is $1/\theta^n$ cannot be differentiated at $\theta$. The conclusion is that the estimate of $\theta$ is $\max(x_i)$, where $x_1,x_2,\ldots,x_n$ is the random sample. I would like a layman's explanation for this.","I am looking at parameters estimation for the uniform distribution in the context of MLEs.  Now, I know the likelihood function of the Uniform distribution $U(0,\theta)$ which is $1/\theta^n$ cannot be differentiated at $\theta$. The conclusion is that the estimate of $\theta$ is $\max(x_i)$, where $x_1,x_2,\ldots,x_n$ is the random sample. I would like a layman's explanation for this.",,"['probability', 'random-variables', 'estimation']"
9,"The difference between ""identically distributed"" and having ""common probability space""","The difference between ""identically distributed"" and having ""common probability space""",,"Suppose that we have two random variables X and Y.  If we say they have a common probability space, does it mean that they are identically distributed? What is the difference between ""identically distributed"" and having ""common probability space""? Would you please give me an example of two random variables having the same probability space and but are not identically distributed, and another example of two random variables identically distributed and but they do not have the same probability space. Thanks.","Suppose that we have two random variables X and Y.  If we say they have a common probability space, does it mean that they are identically distributed? What is the difference between ""identically distributed"" and having ""common probability space""? Would you please give me an example of two random variables having the same probability space and but are not identically distributed, and another example of two random variables identically distributed and but they do not have the same probability space. Thanks.",,"['probability', 'probability-theory']"
10,What is the variance of the number of heads that come up when a fair coin is flipped 10 times?,What is the variance of the number of heads that come up when a fair coin is flipped 10 times?,,"So the answer to this is $5/2$. I get that $E(x)=5$ which means that $\big(E(x)\big)^2 = 25$, therefore meaning that $E(x^2) = 55/2$. How do I compute $E(x^2)$ in this scenario?","So the answer to this is $5/2$. I get that $E(x)=5$ which means that $\big(E(x)\big)^2 = 25$, therefore meaning that $E(x^2) = 55/2$. How do I compute $E(x^2)$ in this scenario?",,"['probability', 'random-variables', 'expectation']"
11,Probability task (Find probability that the chosen ball is white.),Probability task (Find probability that the chosen ball is white.),,"I have this task in my book: First box contains $10$ balls, from which $8$ are white. Second box contains $20$ from which $4$ are white. From each box one ball is chosen. Then from previously chosen two balls, one is chosen. Find probability that the chosen ball is white. The answer is $0.5$. Again I get the different answer: There are four possible outcomes when two balls are chosen: $w$ -white, $a$ - for another color $(a,a),(w,a),(a,w),(w,w)$. Each outcome has probability: $\frac{2}{10} \cdot \frac{16}{20};  \frac{8}{10} \cdot \frac{16}{20}; \frac{2}{10} \cdot \frac{4}{20}; \frac{8}{10} \cdot \frac{4}{20};$ In my opinion the probability that the one ball chosen at the end is white is equal to the sum of last three probabilities $\frac{8}{10} \cdot \frac{16}{20} + \frac{2}{10} \cdot \frac{4}{20} + \frac{8}{10} \cdot \frac{4}{20}=\frac{21}{25}$. Am I wrong or there is a mistake in the answer in the book?","I have this task in my book: First box contains $10$ balls, from which $8$ are white. Second box contains $20$ from which $4$ are white. From each box one ball is chosen. Then from previously chosen two balls, one is chosen. Find probability that the chosen ball is white. The answer is $0.5$. Again I get the different answer: There are four possible outcomes when two balls are chosen: $w$ -white, $a$ - for another color $(a,a),(w,a),(a,w),(w,w)$. Each outcome has probability: $\frac{2}{10} \cdot \frac{16}{20};  \frac{8}{10} \cdot \frac{16}{20}; \frac{2}{10} \cdot \frac{4}{20}; \frac{8}{10} \cdot \frac{4}{20};$ In my opinion the probability that the one ball chosen at the end is white is equal to the sum of last three probabilities $\frac{8}{10} \cdot \frac{16}{20} + \frac{2}{10} \cdot \frac{4}{20} + \frac{8}{10} \cdot \frac{4}{20}=\frac{21}{25}$. Am I wrong or there is a mistake in the answer in the book?",,['probability']
12,No husband can sit next to his wife in this probability question,No husband can sit next to his wife in this probability question,,"I have a probability question that reads: Question: If 4 married couples are arranged in a row, find the probability that no husband sits next to his wife. My attempt: Total outcomes = 8! Outcomes that all of them sit with their wife: 4!*(4*2!) Outcomes that one of them sit with their wife: (2!*4)(6!)-(2!*4)(3!*(3*2!)[subtract the ways that remaining couples are together] Outcomes that two of them sit with their wife: (2!*4C2)(4!)-(2!*4C2)(2!*(2*2!) Outcomes that three of them sit with their wife: (2!*4C3)(2!)-(2!*4C3)(1!*(2*2!) Hence no husband sit with wife is 1 -(Outcomes that all of them sit with their wife+ Outcomes that one of them sit with their wife + Outcomes that two of them sit with their wife + Outcomes that three of them sit with their wife)/8! Am i right? Any easier way?","I have a probability question that reads: Question: If 4 married couples are arranged in a row, find the probability that no husband sits next to his wife. My attempt: Total outcomes = 8! Outcomes that all of them sit with their wife: 4!*(4*2!) Outcomes that one of them sit with their wife: (2!*4)(6!)-(2!*4)(3!*(3*2!)[subtract the ways that remaining couples are together] Outcomes that two of them sit with their wife: (2!*4C2)(4!)-(2!*4C2)(2!*(2*2!) Outcomes that three of them sit with their wife: (2!*4C3)(2!)-(2!*4C3)(1!*(2*2!) Hence no husband sit with wife is 1 -(Outcomes that all of them sit with their wife+ Outcomes that one of them sit with their wife + Outcomes that two of them sit with their wife + Outcomes that three of them sit with their wife)/8! Am i right? Any easier way?",,"['probability', 'combinatorics', 'permutations']"
13,Combinatorics/Probability Distribution Example Question,Combinatorics/Probability Distribution Example Question,,"At a local fast-food restaurant in Oregon (no sales tax), fries, soda, hamburgers, cherry pie, and sundaes cost \$1 each.  Chicken sandwiches cost \$2 each.  You have five dollars.  How many different meals can you order? Let's assign two groups A and B.  Let A consist of \$1 items and B consist of \$2 items. Group A:  \$1 items:  Fries, soda, hamburgers, cherry pie, sundaes = 5 items Group B:  \$2 items:  Chicken sandwich = 1 item I'm assuming this is a combinatorics problem which is unordered and with replacement (meaning more than one of the same item can be selected).  Hence there are 3 possible scenarios because of the \$5 constraint: (I)  AAAAA:  Here we have 5 objects for group A's n=5 obj + 4 dividers = 9, r=5 obj (II) BAAA:  Since there is only one B item here, I thought I could leave it out and only calculate the placement of 3 objects in AAA.  This is because I can have only one object in B, but am free to choose the distribution among the other A's. n= 3 obj + 2 dividers = 5, r = 3 obj (III) BBA:  Again since B's have only one item, and A is only 5 values, this group is simply 5. So my approach is to find the combinations of (I)-(III) and add them together: (I)  $\binom{9}{5}=126$ (II) $\binom{5}{3}=10$ (III) $\binom{5}{1}=5$ This sums to 141 but the answer is 166.  Can anyone see what I am doing wrong or suggest a better method?  I am using the following proposition: The number of unordered samples of r objects, with replacement from, n distinguishable objects is:  $C(n+r-1,r)= \binom{n+r-1}{r}$.  This is equivalent to the number of ways to distribute r indistinguishable balls into n distinguishable urns without exclusion. Thank you!","At a local fast-food restaurant in Oregon (no sales tax), fries, soda, hamburgers, cherry pie, and sundaes cost \$1 each.  Chicken sandwiches cost \$2 each.  You have five dollars.  How many different meals can you order? Let's assign two groups A and B.  Let A consist of \$1 items and B consist of \$2 items. Group A:  \$1 items:  Fries, soda, hamburgers, cherry pie, sundaes = 5 items Group B:  \$2 items:  Chicken sandwich = 1 item I'm assuming this is a combinatorics problem which is unordered and with replacement (meaning more than one of the same item can be selected).  Hence there are 3 possible scenarios because of the \$5 constraint: (I)  AAAAA:  Here we have 5 objects for group A's n=5 obj + 4 dividers = 9, r=5 obj (II) BAAA:  Since there is only one B item here, I thought I could leave it out and only calculate the placement of 3 objects in AAA.  This is because I can have only one object in B, but am free to choose the distribution among the other A's. n= 3 obj + 2 dividers = 5, r = 3 obj (III) BBA:  Again since B's have only one item, and A is only 5 values, this group is simply 5. So my approach is to find the combinations of (I)-(III) and add them together: (I)  $\binom{9}{5}=126$ (II) $\binom{5}{3}=10$ (III) $\binom{5}{1}=5$ This sums to 141 but the answer is 166.  Can anyone see what I am doing wrong or suggest a better method?  I am using the following proposition: The number of unordered samples of r objects, with replacement from, n distinguishable objects is:  $C(n+r-1,r)= \binom{n+r-1}{r}$.  This is equivalent to the number of ways to distribute r indistinguishable balls into n distinguishable urns without exclusion. Thank you!",,"['probability', 'combinatorics']"
14,How do you calculate the probability of simultaneous events?,How do you calculate the probability of simultaneous events?,,"How do you calculate the probability of simultaneous events?  As in, given four simultaneous events each with a 10% probability, what are the odds that ONE of them occurs?  Obviously it isn't 40%, because...well, if you have ten events that probability clearly isn't 100%! (Nope, not homework!  Video games, probability of elemental effects from a given spell)","How do you calculate the probability of simultaneous events?  As in, given four simultaneous events each with a 10% probability, what are the odds that ONE of them occurs?  Obviously it isn't 40%, because...well, if you have ten events that probability clearly isn't 100%! (Nope, not homework!  Video games, probability of elemental effects from a given spell)",,['probability']
15,why is variance so famous that it appears in almost half of the probability textbook? [closed],why is variance so famous that it appears in almost half of the probability textbook? [closed],,"It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened, visit the help center . Closed 11 years ago . why is variance so famous that it appears in almost half of the probability textbook? What is its significant history so that a statistical model would appear in such textbooks and what does it help to evaluate probability? In another word, what useful properties makes variance to get a lot of coverage in some probabilty textbook?","It's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened, visit the help center . Closed 11 years ago . why is variance so famous that it appears in almost half of the probability textbook? What is its significant history so that a statistical model would appear in such textbooks and what does it help to evaluate probability? In another word, what useful properties makes variance to get a lot of coverage in some probabilty textbook?",,"['probability', 'statistics', 'math-history']"
16,Monty Hall problem vs. roulette systems - how are they different?,Monty Hall problem vs. roulette systems - how are they different?,,"So I got interested in the Monty Hall problem - I understand what it's about, but somehow I can't wrap my head around the idea of the final choice not being 50/50. More precisely: we all know (or maybe most of us do) the roulette progression systems which were popular a while ago - they told you that you should wait for a streak of some three-or-more consecutive reds or blacks and then bet on the contrary, always staying with this colour and eventually it has to be drawn as with every other spin, the chances become higher for the streak to be broken. Of course the system is dumb and was shortly afterwards popularly neglected as a fallacy (though surprisingly many people still believe it works) as every spin is independent and even though you had a million reds in a row, in the next spin the odds for red, black and green are still the same as they had been these million spins ago. And here I see an analogy to Monty Hall - sure, if we were proposed ""Do you choose doors k and l (both at the same time!) or m?"", it would be a straightforward 2/3 to 1/3. But why don't we cast aside the fact of some door having a goat and treat the two remaining doors as a simple 50/50 just like we do in roulette? Why aren't we interested in the past in roulette while it does matter in Monty Hall? Isn't the two remaining doors - one with a car - just ""another spin""?","So I got interested in the Monty Hall problem - I understand what it's about, but somehow I can't wrap my head around the idea of the final choice not being 50/50. More precisely: we all know (or maybe most of us do) the roulette progression systems which were popular a while ago - they told you that you should wait for a streak of some three-or-more consecutive reds or blacks and then bet on the contrary, always staying with this colour and eventually it has to be drawn as with every other spin, the chances become higher for the streak to be broken. Of course the system is dumb and was shortly afterwards popularly neglected as a fallacy (though surprisingly many people still believe it works) as every spin is independent and even though you had a million reds in a row, in the next spin the odds for red, black and green are still the same as they had been these million spins ago. And here I see an analogy to Monty Hall - sure, if we were proposed ""Do you choose doors k and l (both at the same time!) or m?"", it would be a straightforward 2/3 to 1/3. But why don't we cast aside the fact of some door having a goat and treat the two remaining doors as a simple 50/50 just like we do in roulette? Why aren't we interested in the past in roulette while it does matter in Monty Hall? Isn't the two remaining doors - one with a car - just ""another spin""?",,"['probability', 'recreational-mathematics', 'puzzle', 'monty-hall']"
17,"5 black, 7 red, 9 blue, and 6 white marbles.","5 black, 7 red, 9 blue, and 6 white marbles.",,"I'm having trouble finding how many ways there is to arrange 5 black, 7 red, 9 blue, and 6 white marbles to find the probability that every white marble is adjacent to at least one other white marble. If you could help me out that would be great!","I'm having trouble finding how many ways there is to arrange 5 black, 7 red, 9 blue, and 6 white marbles to find the probability that every white marble is adjacent to at least one other white marble. If you could help me out that would be great!",,"['probability', 'combinatorics']"
18,How does one find $E\Bigl(\frac{(\sum_{i=1}^nX_i)^2}{\sum_{i=1}^n X_i^2}\Bigr)$,How does one find,E\Bigl(\frac{(\sum_{i=1}^nX_i)^2}{\sum_{i=1}^n X_i^2}\Bigr),"Suppose $X_1,\ldots,X_n$ are a random sample of $N(0,\sigma^2)$. How can find  $$ E\left(\frac{\bigl(\sum_{i=1}^nX_i\bigr)^2}{\sum_{i=1}^n X_i^2}\right) $$","Suppose $X_1,\ldots,X_n$ are a random sample of $N(0,\sigma^2)$. How can find  $$ E\left(\frac{\bigl(\sum_{i=1}^nX_i\bigr)^2}{\sum_{i=1}^n X_i^2}\right) $$",,"['probability', 'statistics']"
19,the limit of a probability density function,the limit of a probability density function,,"I have one maths challenge which I could not resolve. The question is the following. Let f(x) denotes the probability density of a continuous RV., X. I want to know the limit f(x) as x approaches to either -∞ or +∞. It might seem silly, but I have do idea how to do that.","I have one maths challenge which I could not resolve. The question is the following. Let f(x) denotes the probability density of a continuous RV., X. I want to know the limit f(x) as x approaches to either -∞ or +∞. It might seem silly, but I have do idea how to do that.",,"['probability', 'statistics']"
20,Probability of someone being born the same day as you in a group of N people.,Probability of someone being born the same day as you in a group of N people.,,"I got into a discussion with a friend about this simple question: Provided that I went to a class with $N$ people, where everyone was born the same year in the same city where there are $K$ hospitals, what's the probability that someone was born in the same hospital and in the same day as me? My approach would be as follows: $$\left( 1- \left(\frac{364}{365} \right)^N \right) \cdot \left(1-\left(\frac{K-1}{K} \right)^N \right)$$ But I'm not really sure that this is the correct answer :)","I got into a discussion with a friend about this simple question: Provided that I went to a class with $N$ people, where everyone was born the same year in the same city where there are $K$ hospitals, what's the probability that someone was born in the same hospital and in the same day as me? My approach would be as follows: $$\left( 1- \left(\frac{364}{365} \right)^N \right) \cdot \left(1-\left(\frac{K-1}{K} \right)^N \right)$$ But I'm not really sure that this is the correct answer :)",,"['probability', 'combinatorics']"
21,Tennis Probability,Tennis Probability,,Player A wins 90% of matches Player B wins 60% of matches If they play each other what is the probability that; Player A will win Player B will win,Player A wins 90% of matches Player B wins 60% of matches If they play each other what is the probability that; Player A will win Player B will win,,['probability']
22,How to compute this integral involving a cdf?,How to compute this integral involving a cdf?,,$\int_0^\infty\Phi(\frac{-x}{\sqrt{2}})d\Phi(x)=?$ where $\Phi(x)$ is the cumulative distribution function of a standard normal random variable.,$\int_0^\infty\Phi(\frac{-x}{\sqrt{2}})d\Phi(x)=?$ where $\Phi(x)$ is the cumulative distribution function of a standard normal random variable.,,"['probability', 'integration']"
23,Maximum of 2 random variables,Maximum of 2 random variables,,"This might be an easy question but currently I'm fighting over it with our TA who gave it in the final exam. Let $X, Y$ random variables and define $Z= \max \{X, Y\}$ what is the distribution of  $Z \mid \{X > Y\}$? Should be $Z\mid \{X>Y\}\sim X$, right?! Thank you all.","This might be an easy question but currently I'm fighting over it with our TA who gave it in the final exam. Let $X, Y$ random variables and define $Z= \max \{X, Y\}$ what is the distribution of  $Z \mid \{X > Y\}$? Should be $Z\mid \{X>Y\}\sim X$, right?! Thank you all.",,['probability']
24,Set operators vs. Logical operators while discussing probability theory.,Set operators vs. Logical operators while discussing probability theory.,,"Let $S = \{1, 2, \dots, 10\}$  Let $A$ be the event that a number selected from $S$ is even. Let $B$ be the event that a number selected from $S$ is a multiple of $3$. If any number is equally likely to be selected from $S$, the probability that a number selected from the set $S$ is neither even nor a multiple of $3$ is $\frac{3}{10}$. I write it as $P(\overline A \cap \overline B) = \frac{3}{10}$. But I have some people writing it as $P(\neg A \text{ and } \neg B) = \frac{3}{10}$. I don't understand the reason for this notation. They seem to be using logical operators which apply to statements in propositional logic. But $A$ and $B$ are not statements. They are events, and events are sets. Shouldn't we stick strictly to set theory notation while discussing probability? If we have to use logical operators, shouldn't we use $P(\neg A \land \neg B)$ instead of $P(\neg A \text{ and } \neg B)$?","Let $S = \{1, 2, \dots, 10\}$  Let $A$ be the event that a number selected from $S$ is even. Let $B$ be the event that a number selected from $S$ is a multiple of $3$. If any number is equally likely to be selected from $S$, the probability that a number selected from the set $S$ is neither even nor a multiple of $3$ is $\frac{3}{10}$. I write it as $P(\overline A \cap \overline B) = \frac{3}{10}$. But I have some people writing it as $P(\neg A \text{ and } \neg B) = \frac{3}{10}$. I don't understand the reason for this notation. They seem to be using logical operators which apply to statements in propositional logic. But $A$ and $B$ are not statements. They are events, and events are sets. Shouldn't we stick strictly to set theory notation while discussing probability? If we have to use logical operators, shouldn't we use $P(\neg A \land \neg B)$ instead of $P(\neg A \text{ and } \neg B)$?",,"['probability', 'notation']"
25,probability of three random points inside a circle forming a right angle triangle,probability of three random points inside a circle forming a right angle triangle,,three points are randomly chosen on a circle. what the probability that 1.triangle formed is right angled triangle. 2.triangle formed is acute angled triangle. 3.triangle formed is obtuse angled triangle.,three points are randomly chosen on a circle. what the probability that 1.triangle formed is right angled triangle. 2.triangle formed is acute angled triangle. 3.triangle formed is obtuse angled triangle.,,"['probability', 'triangles']"
26,Prove that $N$ has a Poisson distribution with parameter $\lambda$.,Prove that  has a Poisson distribution with parameter .,N \lambda,"Let $\lambda > 0$, define the random variable $N$ as follows: where $U_1$, $U_2$, $\ldots$ is a sequence of iid $U(0,1)$ random variables. $U_1 \geq e^{-\lambda}, U_1U_2 \geq e^{-\lambda}, U_1U_2 \ldots U_N \geq e^{-\lambda}$ but $U_1U_2 \ldots U_N U_{N+1} < e^{-\lambda}$. Can we show that $N$ has a poission distribution with paramter $\lambda$? This is a homework problem. My thought is that we might possibly use $\log U_i/\lambda$, but I'm stuck so far... Any idea is helpful!","Let $\lambda > 0$, define the random variable $N$ as follows: where $U_1$, $U_2$, $\ldots$ is a sequence of iid $U(0,1)$ random variables. $U_1 \geq e^{-\lambda}, U_1U_2 \geq e^{-\lambda}, U_1U_2 \ldots U_N \geq e^{-\lambda}$ but $U_1U_2 \ldots U_N U_{N+1} < e^{-\lambda}$. Can we show that $N$ has a poission distribution with paramter $\lambda$? This is a homework problem. My thought is that we might possibly use $\log U_i/\lambda$, but I'm stuck so far... Any idea is helpful!",,['probability']
27,Throwing coins until get 2 heads,Throwing coins until get 2 heads,,"I have coin, and want to get 2 heads exactly. I will throw it until this condition is met. What is expected number of tries for this condition? I know that it would be $$\sum\limits_{n=2}^\infty P(X=n)n=0.5^n \cdot n\cdot(n-1)$$ however I don't have an idea how to solve that sum because we didn't learn how to. I have knowledge just how to solve geometrical and arithmetical progression's sum. Maybe it's possible to get expected value using Poisson distribution?","I have coin, and want to get 2 heads exactly. I will throw it until this condition is met. What is expected number of tries for this condition? I know that it would be $$\sum\limits_{n=2}^\infty P(X=n)n=0.5^n \cdot n\cdot(n-1)$$ however I don't have an idea how to solve that sum because we didn't learn how to. I have knowledge just how to solve geometrical and arithmetical progression's sum. Maybe it's possible to get expected value using Poisson distribution?",,"['probability', 'statistics']"
28,What's the expected matched pair of shoes when $10$ pairs mixed up?,What's the expected matched pair of shoes when  pairs mixed up?,10,"We've got $10$ different pairs of shoes. Now we mix them up and randomly regroup them into $10$ ""pairs"". Of course some ""pairs"" are not matched and maybe some of them are. So what's the expect number of pairs that are matched? By ""randomly group"", I mean you can randomly pick one from the $20$, then choose one from the remaining $19$ to pair it up, and so on.","We've got $10$ different pairs of shoes. Now we mix them up and randomly regroup them into $10$ ""pairs"". Of course some ""pairs"" are not matched and maybe some of them are. So what's the expect number of pairs that are matched? By ""randomly group"", I mean you can randomly pick one from the $20$, then choose one from the remaining $19$ to pair it up, and so on.",,['probability']
29,Independence of sigma algebra,Independence of sigma algebra,,"I am trying to establish whether the following is true (my intuition tells me it is), more importantly if it is true, I need to establish a proof. If $X_1, X_2$ and $X_3$ are pairwise independent random variables, then if $Y=X_2+X_3$, is $X_1$ independent to $Y$? (One can think of an example where the $X_i$ s are Bernoulli random variables, then the answer is yes, in the general case I have no idea how to prove it.) A related problem is: If $G_1,G_2$ and $G_3$ are pairwise independent sigma algebras, then is $G_1$ independent to the sigma algebra generated by $G_2$ and $G_3$ (which contains all the subsets of both, but has additional sets such as intersection of a set from $G_2$ and a set from $G_3$). This came about as I tried to solve the following: Suppose a Brownian motion $\{W_t\}$ is adapted to filtration $\{F_s\}$, if $0<s<t_1<t_2<t_3<\infty$, then show $a_1(W_{t_2}-W_{t_1})+a_2(W_{t_3}-W_{t_2})$ is independent of $F_s$ where $a_1,a_2$ are constants. By definition individual future increments are independent of $F_s$, for the life of me I don't know how to prove linear combination of future increments are independent of $F_s$, intuitive of course it make sense... Any help is greatly appreciated. Thank you for the hints, I think I have made progress in my understanding, please confirm these if possible. In one of the assumptions of the Brownian motion $\{W_t\}$ is adapted to a filtration $F_t$, do we assume: A) Each increment $(W_t-W_s)$ is independent of $F_u$ for $0<u<s<t$. OR B) Any number of disjoint increments (in the future of time $s$) and $F_s$ are mutually independent. Under B) then the assumption answers my problem.  Under A), if the filtration  is the one generated by the Brownation motion, then the required mutual independence can be deduced from the mutual independence of the Brownian  increments.  However, under A) if the filtration is not necessarily the one generated by the Brownian motion, is it still possible to prove the required mutual independence?  If so please help, I spent a longggg time trying to work it out. Many thanks.","I am trying to establish whether the following is true (my intuition tells me it is), more importantly if it is true, I need to establish a proof. If $X_1, X_2$ and $X_3$ are pairwise independent random variables, then if $Y=X_2+X_3$, is $X_1$ independent to $Y$? (One can think of an example where the $X_i$ s are Bernoulli random variables, then the answer is yes, in the general case I have no idea how to prove it.) A related problem is: If $G_1,G_2$ and $G_3$ are pairwise independent sigma algebras, then is $G_1$ independent to the sigma algebra generated by $G_2$ and $G_3$ (which contains all the subsets of both, but has additional sets such as intersection of a set from $G_2$ and a set from $G_3$). This came about as I tried to solve the following: Suppose a Brownian motion $\{W_t\}$ is adapted to filtration $\{F_s\}$, if $0<s<t_1<t_2<t_3<\infty$, then show $a_1(W_{t_2}-W_{t_1})+a_2(W_{t_3}-W_{t_2})$ is independent of $F_s$ where $a_1,a_2$ are constants. By definition individual future increments are independent of $F_s$, for the life of me I don't know how to prove linear combination of future increments are independent of $F_s$, intuitive of course it make sense... Any help is greatly appreciated. Thank you for the hints, I think I have made progress in my understanding, please confirm these if possible. In one of the assumptions of the Brownian motion $\{W_t\}$ is adapted to a filtration $F_t$, do we assume: A) Each increment $(W_t-W_s)$ is independent of $F_u$ for $0<u<s<t$. OR B) Any number of disjoint increments (in the future of time $s$) and $F_s$ are mutually independent. Under B) then the assumption answers my problem.  Under A), if the filtration  is the one generated by the Brownation motion, then the required mutual independence can be deduced from the mutual independence of the Brownian  increments.  However, under A) if the filtration is not necessarily the one generated by the Brownian motion, is it still possible to prove the required mutual independence?  If so please help, I spent a longggg time trying to work it out. Many thanks.",,"['probability', 'probability-theory']"
30,"Reducing an equation related to logarithms, $\pi$, and probability","Reducing an equation related to logarithms, , and probability",\pi,"In this question , I mentioned that, assuming the digits of pi are independently-random, then at some point in pi's expansion there will be a sequence of one million consecutive 0's.  I decided to determine exactly how many digits ($d$) of $\pi$ we'd have to look at to have a 50% chance of seeing $n$ consecutive 0's. I was able to solve for $d$: $$(1-10^{-n})^d = 0.5$$ $$d = \frac{\log(0.5)}{\log(1-10^{-n})}$$ However, while playing around with this expression, I discovered by accident that it is either equal to or nearly equal to $$d \stackrel{\hbox{?}}{\hbox{=}} \ln(2) \cdot 10^n$$ I've been unable to reduce the first equation to the second, or to show why they should be nearly equal. Could anyone shed some light - are they equal?  And why does the natural-log come into this?  Is this somehow related to other results in probability (which I know uses $e$ extensively) ?","In this question , I mentioned that, assuming the digits of pi are independently-random, then at some point in pi's expansion there will be a sequence of one million consecutive 0's.  I decided to determine exactly how many digits ($d$) of $\pi$ we'd have to look at to have a 50% chance of seeing $n$ consecutive 0's. I was able to solve for $d$: $$(1-10^{-n})^d = 0.5$$ $$d = \frac{\log(0.5)}{\log(1-10^{-n})}$$ However, while playing around with this expression, I discovered by accident that it is either equal to or nearly equal to $$d \stackrel{\hbox{?}}{\hbox{=}} \ln(2) \cdot 10^n$$ I've been unable to reduce the first equation to the second, or to show why they should be nearly equal. Could anyone shed some light - are they equal?  And why does the natural-log come into this?  Is this somehow related to other results in probability (which I know uses $e$ extensively) ?",,"['probability', 'logarithms', 'random', 'pi']"
31,What is the probability that some event happens before another event?,What is the probability that some event happens before another event?,,In the previous question I asked the $\mathbb{P}(X < Y )$  where $X$ is the number of rolls(two dice) it takes to roll a sum of 3 and $Y$ is the the number of rolls it takes to roll a sum of 5. The probability was $\frac{\mathbb{P}(X)}{\mathbb{P}(X)+\mathbb{P}(Y)} = \frac{(2/36)}{(4/36+2/36)} = \frac{1}{3}$. I am not sure why you divide though by $\mathbb{P}(X)$ or $\mathbb{P}(Y)$. Can some one explain this to me intuitively?,In the previous question I asked the $\mathbb{P}(X < Y )$  where $X$ is the number of rolls(two dice) it takes to roll a sum of 3 and $Y$ is the the number of rolls it takes to roll a sum of 5. The probability was $\frac{\mathbb{P}(X)}{\mathbb{P}(X)+\mathbb{P}(Y)} = \frac{(2/36)}{(4/36+2/36)} = \frac{1}{3}$. I am not sure why you divide though by $\mathbb{P}(X)$ or $\mathbb{P}(Y)$. Can some one explain this to me intuitively?,,['probability']
32,Calculate expectation from empirical cdf,Calculate expectation from empirical cdf,,"I have a empirical cumulative probability distribution function for a random variable. The random variable is ""time to failure"" and I have the full curve i.e till the probability reaches $1$. I want to know Mean Time To Failure i.e expectation of that random variable. Is there any standard method to find mean from an empirical distribution. I am getting the empirical CDF (as discrete values) as output from a ""model checking tool"" which uses iterative numerical computation techniques to get those probabilities. For example, let $F(t)=P(X \leq t)$ is the CDF of the random variable $X$ where $X$ stands for time between failure. To plot the curve of ""$F(t)$ vs $t$"" I am varying t with some step size, calculating $F(t)$ for that t using the ""model checking tool"" and adding the points to get the curve. I can use small step size to get the more accurate curve. So, I have access to only this CDF values at different$ t$. From this values I want to do a good estimate of mean value of $X$. Now the parameters will be: 1) $T$, the maximum value of t. We need to find this  with some precision i.e if $F(T_1)-F(T_2)$ is less than some epsilon we set $T=T_1$. 2) Once we have found T we need to find suitable step size $h$ at which we will be calculating the CDF values. How should I choose those parametrs?","I have a empirical cumulative probability distribution function for a random variable. The random variable is ""time to failure"" and I have the full curve i.e till the probability reaches $1$. I want to know Mean Time To Failure i.e expectation of that random variable. Is there any standard method to find mean from an empirical distribution. I am getting the empirical CDF (as discrete values) as output from a ""model checking tool"" which uses iterative numerical computation techniques to get those probabilities. For example, let $F(t)=P(X \leq t)$ is the CDF of the random variable $X$ where $X$ stands for time between failure. To plot the curve of ""$F(t)$ vs $t$"" I am varying t with some step size, calculating $F(t)$ for that t using the ""model checking tool"" and adding the points to get the curve. I can use small step size to get the more accurate curve. So, I have access to only this CDF values at different$ t$. From this values I want to do a good estimate of mean value of $X$. Now the parameters will be: 1) $T$, the maximum value of t. We need to find this  with some precision i.e if $F(T_1)-F(T_2)$ is less than some epsilon we set $T=T_1$. 2) Once we have found T we need to find suitable step size $h$ at which we will be calculating the CDF values. How should I choose those parametrs?",,"['probability', 'probability-distributions']"
33,"If $X$ is uniformly distributed on $ [0,1]$, how is $X^2$ distributed?","If  is uniformly distributed on , how is  distributed?","X  [0,1] X^2","I seem to be getting it equal to the $X$, which can't be right","I seem to be getting it equal to the $X$, which can't be right",,"['probability', 'statistics']"
34,"Are there any random variables so that $\mathrm{E}[XY]$ exists, but $\mathrm{E}[X]$ or $\mathrm{E}[Y]$ doesn't?","Are there any random variables so that  exists, but  or  doesn't?",\mathrm{E}[XY] \mathrm{E}[X] \mathrm{E}[Y],"Are there any random variables so that $\mathrm{E}[XY]$ exists, but $\mathrm{E}[X]$ or $\mathrm{E}[Y]$ doesn't?","Are there any random variables so that $\mathrm{E}[XY]$ exists, but $\mathrm{E}[X]$ or $\mathrm{E}[Y]$ doesn't?",,['probability']
35,Need intuition for dice betting problem,Need intuition for dice betting problem,,"I'm having a little trouble gaining some intuition for this dice betting question: A and B each take turns rolling a fair six-sided dice. A player wins if they roll a 4 which is followed by a 1 from the other player. Would you prefer to be A or B? My intuition said A because if I went first, I could roll a 4 and then B could roll a 1, and I would have the potential to win at the very beginning. If I'm B, I'm, in turn, subjecting myself to this possibility. But the answers say that it is right to be B. I'm not sure why this is the case.","I'm having a little trouble gaining some intuition for this dice betting question: A and B each take turns rolling a fair six-sided dice. A player wins if they roll a 4 which is followed by a 1 from the other player. Would you prefer to be A or B? My intuition said A because if I went first, I could roll a 4 and then B could roll a 1, and I would have the potential to win at the very beginning. If I'm B, I'm, in turn, subjecting myself to this possibility. But the answers say that it is right to be B. I'm not sure why this is the case.",,"['probability', 'probability-theory', 'dice']"
36,Probability of drawing from box B,Probability of drawing from box B,,"I have the exercise: Consider the following scenario. There are two boxes, Box A and Box B. Initially, Box A contains 3 red balls and 3 white balls; Box B contains 6 red balls. We swap the balls in the boxes via the following procedure:  We draw a ball, denoted as ball $x_A$ , uniformly at random from Box A, and draw a ball, denoted as ball $x_B$ , uniformly at random from Box B. We then place ball $x_A$ into Box B and place ball $x_B$ into Box A. After that, we select either Box A or Box B by some uniformly random procedure (like flipping a fair coin), and draw a ball from the selected box. The ball drawn was white. What was the probability that Box B was selected? I use Bayes theorem and Arrive at 1/6 But apparently the correct answer is 11/18, how is that?","I have the exercise: Consider the following scenario. There are two boxes, Box A and Box B. Initially, Box A contains 3 red balls and 3 white balls; Box B contains 6 red balls. We swap the balls in the boxes via the following procedure:  We draw a ball, denoted as ball , uniformly at random from Box A, and draw a ball, denoted as ball , uniformly at random from Box B. We then place ball into Box B and place ball into Box A. After that, we select either Box A or Box B by some uniformly random procedure (like flipping a fair coin), and draw a ball from the selected box. The ball drawn was white. What was the probability that Box B was selected? I use Bayes theorem and Arrive at 1/6 But apparently the correct answer is 11/18, how is that?",x_A x_B x_A x_B,"['probability', 'bayesian', 'bayes-theorem']"
37,Three colors -- Drawing marbles until one color is exhausted,Three colors -- Drawing marbles until one color is exhausted,,"A bag contains three colors of marbles in known quantities. Marbles are drawn randomly one at a time until any color is exhausted. What is the probability a given color exhausts first? For only two colors, the answer is intuitive -- if a color occupies 1/n th of the bag, that is how often it will ""survive"". Simulating three colors,  I'm not seeing the general pattern. (The sim is sanity checked with {1,2,3}. Of the 60 combos of rggbbb , red exhausts first in 35 of them) import random red_out, green_out, blue_out = 0,0,0 runs = 100000 for i in range(0,runs): red = 1 green = 2 blue = 3  while (red > 0 and green > 0 and blue > 0):     rand = random.random()     total = red + green + blue     frac_red = red/total     frac_green = green/total          if (rand <= frac_red): red-=1     elif (frac_red < rand <= frac_red + frac_green): green-=1     else: blue-=1         if (red == 0): red_out+=1     elif (green == 0): green_out+=1     elif (blue == 0): blue_out+=1 print(""RED:"",red_out/runs); print(""GREEN:"",green_out/runs); print(""BLUE:"",blue_out/runs)","A bag contains three colors of marbles in known quantities. Marbles are drawn randomly one at a time until any color is exhausted. What is the probability a given color exhausts first? For only two colors, the answer is intuitive -- if a color occupies 1/n th of the bag, that is how often it will ""survive"". Simulating three colors,  I'm not seeing the general pattern. (The sim is sanity checked with {1,2,3}. Of the 60 combos of rggbbb , red exhausts first in 35 of them) import random red_out, green_out, blue_out = 0,0,0 runs = 100000 for i in range(0,runs): red = 1 green = 2 blue = 3  while (red > 0 and green > 0 and blue > 0):     rand = random.random()     total = red + green + blue     frac_red = red/total     frac_green = green/total          if (rand <= frac_red): red-=1     elif (frac_red < rand <= frac_red + frac_green): green-=1     else: blue-=1         if (red == 0): red_out+=1     elif (green == 0): green_out+=1     elif (blue == 0): blue_out+=1 print(""RED:"",red_out/runs); print(""GREEN:"",green_out/runs); print(""BLUE:"",blue_out/runs)",,['probability']
38,"show that uniform probability measure on $\{1,2,...n\}$ does not converge weakly to any probability measure",show that uniform probability measure on  does not converge weakly to any probability measure,"\{1,2,...n\}","Let $P_n$ be uniform probability measure on $\{1,2,...n\}$ show that $P_n$ does not converge weakly to any probability measure. To prove this by contradiction, assume $P_n\Rightarrow P$ where, $P$ is some probability measure. Then, by definition of weak convergence, for any continuous bounded function, $f$ $$\int fdP_n\overset{n\rightarrow\infty}{\longrightarrow}\int fdP.$$ Let us take $f:[0,1]\rightarrow[0,1]\backepsilon f(x)=x$ , which is continuous and bounded. Then, $$\int f(x)P_n(dx)=\frac{1}{n}\sum_{i=1}^ni=\frac{n+1}{2}\overset{n\rightarrow\infty}{\longrightarrow}\infty$$ but, $$\int f(x)P(dx)=\int xP(dx)\overset{\text{why?}}{<}\infty.$$ Is the attempt correct. If it is, I am not very clear about why the second integral is always finite. Please help. Note. There is a similar question but it doesn't clear my doubt.","Let be uniform probability measure on show that does not converge weakly to any probability measure. To prove this by contradiction, assume where, is some probability measure. Then, by definition of weak convergence, for any continuous bounded function, Let us take , which is continuous and bounded. Then, but, Is the attempt correct. If it is, I am not very clear about why the second integral is always finite. Please help. Note. There is a similar question but it doesn't clear my doubt.","P_n \{1,2,...n\} P_n P_n\Rightarrow P P f \int fdP_n\overset{n\rightarrow\infty}{\longrightarrow}\int fdP. f:[0,1]\rightarrow[0,1]\backepsilon f(x)=x \int f(x)P_n(dx)=\frac{1}{n}\sum_{i=1}^ni=\frac{n+1}{2}\overset{n\rightarrow\infty}{\longrightarrow}\infty \int f(x)P(dx)=\int xP(dx)\overset{\text{why?}}{<}\infty.","['probability', 'measure-theory', 'weak-convergence']"
39,Expected number of elements for the first of $n$ many hash tables to be filled?,Expected number of elements for the first of  many hash tables to be filled?,n,"This is a generalization of the questions: question 1 and question 2 . There are $n$ many hash tables each of size $m$ . Each turn a random element in one of the hash tables is filled. If the element selected for that turn has already been filled then we've wasted that turn, and we go to the next turn as usual. What is the expected number of turns needed for one of the hash tables (whichever is first) to be filled? Another way of asking this problem is: If we have an $n*m$ - sided die and we partition the possible values into $n$ equal sized sets of $m$ elements, what is the expected number of rolls before we complete a set? For example, if we have a 15-sided die and we split the numbers into 3 sets of 5: $\{1,2,3,4,5\}, \{6,7,8,9,10\}$ , and $\{11,12,13,14,15\}$ , then $m = 5$ and $n=3$ . On average, how many times must we roll the die before we've seen all $5$ rolled values for one of the sets (whichever is first)? In question 1 WhatsUp gave a recursive equation for a two hash table scenario: $$E(a, b) = 1 + \frac a {2m}E(a - 1, b) + \frac b {2m} E(a, b - 1) + \left(1 - \frac{a + b}{2m}\right)E(a, b)$$ with $E(a,b)$ defined as the expected number of elements to fill one table, if there are still $a$ and $b$ empty entries in the two tables. Can this be modified for a 3 hash table scenario as: $$E(a, b, c) = 1 + \frac a {3m}E(a - 1, b, c) + \frac b {3m} E(a, b - 1, c) + \frac c {3m} E(a, b, c - 1) + \left(1 - \frac{a + b + c}{3m}\right)E(a, b, c)$$ and if so how do we go about solving for $E(m,m,m)$ ? Could we generalize this equation to deal with $n$ many hash tables, and if so how? In question 2 there are some great answers involving Markov chains, but if $n$ and $m$ get very large, the transition matrix gets very large and impractical to fill out or work with. (At least that's how it seems to me. Are there are tricks to deal with this?) So another approach is necessary. Thomas Andrews gave a very detailed answer which included a generalized solution which should work here $$\sum_{i_1}^{a_1}\cdots\sum_{i_n=1}^{a_n}(-1)^{\sum (i_j-1)}\binom{a_1}{i_1}\cdots\binom{a_n}{i_n}\frac{a}{\sum i_j}$$ but isn't intuitive and I'm struggling to see how it came about. He mentioned, and I can see, that it stems from an inclusion-exclusion argument, but I'm failing to see how to start there and end up with his equation.","This is a generalization of the questions: question 1 and question 2 . There are many hash tables each of size . Each turn a random element in one of the hash tables is filled. If the element selected for that turn has already been filled then we've wasted that turn, and we go to the next turn as usual. What is the expected number of turns needed for one of the hash tables (whichever is first) to be filled? Another way of asking this problem is: If we have an - sided die and we partition the possible values into equal sized sets of elements, what is the expected number of rolls before we complete a set? For example, if we have a 15-sided die and we split the numbers into 3 sets of 5: , and , then and . On average, how many times must we roll the die before we've seen all rolled values for one of the sets (whichever is first)? In question 1 WhatsUp gave a recursive equation for a two hash table scenario: with defined as the expected number of elements to fill one table, if there are still and empty entries in the two tables. Can this be modified for a 3 hash table scenario as: and if so how do we go about solving for ? Could we generalize this equation to deal with many hash tables, and if so how? In question 2 there are some great answers involving Markov chains, but if and get very large, the transition matrix gets very large and impractical to fill out or work with. (At least that's how it seems to me. Are there are tricks to deal with this?) So another approach is necessary. Thomas Andrews gave a very detailed answer which included a generalized solution which should work here but isn't intuitive and I'm struggling to see how it came about. He mentioned, and I can see, that it stems from an inclusion-exclusion argument, but I'm failing to see how to start there and end up with his equation.","n m n*m n m \{1,2,3,4,5\}, \{6,7,8,9,10\} \{11,12,13,14,15\} m = 5 n=3 5 E(a, b) = 1 + \frac a {2m}E(a - 1, b) + \frac b {2m} E(a, b - 1) + \left(1 - \frac{a + b}{2m}\right)E(a, b) E(a,b) a b E(a, b, c) = 1 + \frac a {3m}E(a - 1, b, c) + \frac b {3m} E(a, b - 1, c) + \frac c {3m} E(a, b, c - 1) + \left(1 - \frac{a + b + c}{3m}\right)E(a, b, c) E(m,m,m) n n m \sum_{i_1}^{a_1}\cdots\sum_{i_n=1}^{a_n}(-1)^{\sum (i_j-1)}\binom{a_1}{i_1}\cdots\binom{a_n}{i_n}\frac{a}{\sum i_j}","['probability', 'combinatorics', 'discrete-mathematics', 'inclusion-exclusion', 'coupon-collector']"
40,"$\{X_n,n>1\}$i.i.d,$S_n=X_1+\cdots+X_n$,$E(X_1) = 0$.Prove that $E|S_n|/n→0$","i.i.d,,.Prove that","\{X_n,n>1\} S_n=X_1+\cdots+X_n E(X_1) = 0 E|S_n|/n→0","Suppose $\{X_n,n>1\}$ i.i.d, $S_n=X_1+\cdots+X_n$ , $E(X_1) = 0$ .Prove that $E|S_n|/n→0$ . Attempts: $\{X_n^+\}$ i.i.d and $\{X_n^-\}$ i.i.d,we have $E(|S_n|)$ = $E|\sum_i X_i^+-\sum_j X_j^-|$ and $E(\sum_i X_i^+)=E(\sum_j X_j^-)$ ,and from Strong Law of Large Numbers,we have $\sum_n X_n^+/n\to E(X_1^+)$ a.e and $\sum_n X_n^-/n\to E(X_1^-)$ a.e,but there are still gaps between the final result.","Suppose i.i.d, , .Prove that . Attempts: i.i.d and i.i.d,we have = and ,and from Strong Law of Large Numbers,we have a.e and a.e,but there are still gaps between the final result.","\{X_n,n>1\} S_n=X_1+\cdots+X_n E(X_1) = 0 E|S_n|/n→0 \{X_n^+\} \{X_n^-\} E(|S_n|) E|\sum_i X_i^+-\sum_j X_j^-| E(\sum_i X_i^+)=E(\sum_j X_j^-) \sum_n X_n^+/n\to E(X_1^+) \sum_n X_n^-/n\to E(X_1^-)","['probability', 'probability-theory', 'law-of-large-numbers']"
41,How can differential entropy be negative?,How can differential entropy be negative?,,"Entropy is defined as $$H(x) = E_{x\sim p(x)}[ - \log p(x)]$$ and $- \log p(x) \geq 0$ so it makes sense that the expectation is always non-negative, here is a proof . However, Wikipedia says the entropy of a normal distribution is $\tfrac{1}{2} \ln(e2\pi\sigma^2 $ ), which means that the entropy can be negative for some values e.g. $\sigma = 0.01$ but how can be this be the case and how can it be interpreted?","Entropy is defined as and so it makes sense that the expectation is always non-negative, here is a proof . However, Wikipedia says the entropy of a normal distribution is ), which means that the entropy can be negative for some values e.g. but how can be this be the case and how can it be interpreted?",H(x) = E_{x\sim p(x)}[ - \log p(x)] - \log p(x) \geq 0 \tfrac{1}{2} \ln(e2\pi\sigma^2  \sigma = 0.01,"['probability', 'information-theory']"
42,Probability question about choosing digits between 1 and 9 and that their product is a multiple of 3,Probability question about choosing digits between 1 and 9 and that their product is a multiple of 3,,"Two digits between 1 and 9, inclusive, are selected at random. The same digit may be selected twice. What is the probability that their product is a multiple of 3? I used this logic: if any one of the digits selected is 3, then the product would be a multiple of 3. There are 3 multiples of 3 (3, 6, 9) between 1-9, so $\frac{3}{9}$ = $\frac{1}{3}$ , and since the second number can be anything, $\frac{1}{3} * \frac{1}{1} = \frac{1}{3}$ . Therefore, my final answer is $\frac{1}{3}$ . However, the answer key used complementary counting and got a different answer ( $\frac{5}{9}$ ). What is wrong with my approach?","Two digits between 1 and 9, inclusive, are selected at random. The same digit may be selected twice. What is the probability that their product is a multiple of 3? I used this logic: if any one of the digits selected is 3, then the product would be a multiple of 3. There are 3 multiples of 3 (3, 6, 9) between 1-9, so = , and since the second number can be anything, . Therefore, my final answer is . However, the answer key used complementary counting and got a different answer ( ). What is wrong with my approach?",\frac{3}{9} \frac{1}{3} \frac{1}{3} * \frac{1}{1} = \frac{1}{3} \frac{1}{3} \frac{5}{9},['probability']
43,"Is $\mathcal{A}\vee \mathcal{B}=\{A\cup B : A\in \mathcal{A}, B\in \mathcal{B}\}$ a $\sigma$-Algebra?",Is  a -Algebra?,"\mathcal{A}\vee \mathcal{B}=\{A\cup B : A\in \mathcal{A}, B\in \mathcal{B}\} \sigma","Let $\mathcal{A}$ and $\mathcal{B}$ be $\sigma$ algebras over $\Omega$ . I know that $\mathcal{A}\cup \mathcal{B}$ is not a $\sigma$ -algebra, but what about $\mathcal{A}\vee \mathcal{B}=\{A\cup B : A\in \mathcal{A}, B\in \mathcal{B}\}$ ? It surely contains $\Omega$ and $\emptyset$ . Let $C\in \mathcal{A}\vee \mathcal{B}$ , i. e. we have $C=A\cup B$ and $\Omega\setminus C=\Omega\setminus (A\cup B)=A^C\cap B^C$ , why is this in $\mathcal{A}\vee \mathcal{B}$ and what about the sigma additivity?","Let and be algebras over . I know that is not a -algebra, but what about ? It surely contains and . Let , i. e. we have and , why is this in and what about the sigma additivity?","\mathcal{A} \mathcal{B} \sigma \Omega \mathcal{A}\cup \mathcal{B} \sigma \mathcal{A}\vee \mathcal{B}=\{A\cup B : A\in \mathcal{A}, B\in \mathcal{B}\} \Omega \emptyset C\in \mathcal{A}\vee \mathcal{B} C=A\cup B \Omega\setminus C=\Omega\setminus (A\cup B)=A^C\cap B^C \mathcal{A}\vee \mathcal{B}","['probability', 'measure-theory']"
44,Are characteristic functions always differentiable?,Are characteristic functions always differentiable?,,"I am thinking about the statement if the characteristic function of a random variable $X$ , $\Phi_X$ , is always differentiable. By definition, $$\Phi_X(t)=\int_{\Bbb{R}^d}e^{i\langle t,y \rangle}P_X(dy)$$ Hence, I think it has something to do with changing the integral and the derivative right? But my intuition tells me that there is a counterexample but I can't find one.","I am thinking about the statement if the characteristic function of a random variable , , is always differentiable. By definition, Hence, I think it has something to do with changing the integral and the derivative right? But my intuition tells me that there is a counterexample but I can't find one.","X \Phi_X \Phi_X(t)=\int_{\Bbb{R}^d}e^{i\langle t,y \rangle}P_X(dy)","['probability', 'probability-theory', 'derivatives', 'stochastic-calculus', 'characteristic-functions']"
45,Randomly drawing socks out of a bag,Randomly drawing socks out of a bag,,"There are 5 pairs of socks in a bag, so a total of 10 socks. Each pair of socks is of a different color from the others. After having randomly drawn 4 socks from the bag, what's the probability of picking 4 socks of different colors? My answer was to first get the total number of possible draws as ${10 \choose 4} = 210$ . Then I'd proceed to compute the number of possible pickings of 2 pairs of socks out of the 4 draws: ${4 \choose 2} {4 \choose 2} = 36$ . Similarly, the number of pickings of 1 pair of socks + 2 loose socks would be ${4 \choose 2} {4 \choose 1} {4 \choose 1} = 96$ . The probability of picking 4 socks of different colours would then be the complementary set of events to the sum of the previous 2: $P($ no matching pair $) = 1 - \frac{36 + 96}{210} = 0.372$ . However the answer to the problem points to a different result. I understand the fact there are 5 colors should factor in somewhere, I only considered the number 4 (the draws) in my combinatorics and I guess this is the source of my mistake.","There are 5 pairs of socks in a bag, so a total of 10 socks. Each pair of socks is of a different color from the others. After having randomly drawn 4 socks from the bag, what's the probability of picking 4 socks of different colors? My answer was to first get the total number of possible draws as . Then I'd proceed to compute the number of possible pickings of 2 pairs of socks out of the 4 draws: . Similarly, the number of pickings of 1 pair of socks + 2 loose socks would be . The probability of picking 4 socks of different colours would then be the complementary set of events to the sum of the previous 2: no matching pair . However the answer to the problem points to a different result. I understand the fact there are 5 colors should factor in somewhere, I only considered the number 4 (the draws) in my combinatorics and I guess this is the source of my mistake.",{10 \choose 4} = 210 {4 \choose 2} {4 \choose 2} = 36 {4 \choose 2} {4 \choose 1} {4 \choose 1} = 96 P( ) = 1 - \frac{36 + 96}{210} = 0.372,"['probability', 'combinatorics']"
46,"$30\%$ students have glasses. $20\%$ of students with glasses play. $60\%$ of students without glasses play. Probability, student without glass plays.","students have glasses.  of students with glasses play.  of students without glasses play. Probability, student without glass plays.",30\% 20\% 60\%,"Problem: In a school, $30\%$ of students have glasses. $20\%$ of students with glasses play sports. $60\%$ of students without glasses play sports. If we randomly choose a student, find probability that a student without glasses (chosen randomly) plays a sport. My Approach $P(O)=0.3$ is the probability that a student has glasses. $P(S|O) = 0.2$ is the probability that a student with glasses plays sport (P of S given O). $P(S|O^c)=0.6$ , where $O^c$ is {Sample Space - $O$ }. The probability that a student without glasses plays sport $(P(S\text{ given }O^c)$ . I have to find $P(O^c|S)$ (the opposite of $P(S|O^c)$ , meaning ""a student plays sport without glasses""). I know that $80\%$ of students play a sport, and that $70\%$ of students don't have glasses. So in order to solve the problem I have to do $$P(O^c|S) = \frac{0.8 \times 0.7}{0.8} = 0.7 $$ but given correct solution is $0.87$ $(0.7\neq0.87)$ . EDIT: I think the problem is in this assumption: I've assumed that $0.8$ and $0.7$ were two independent probabilities, therefore I've multiplied $0.8$ with $0.7$ . If this is not correct, then I don't know how to find probability of intersection.","Problem: In a school, of students have glasses. of students with glasses play sports. of students without glasses play sports. If we randomly choose a student, find probability that a student without glasses (chosen randomly) plays a sport. My Approach is the probability that a student has glasses. is the probability that a student with glasses plays sport (P of S given O). , where is {Sample Space - }. The probability that a student without glasses plays sport . I have to find (the opposite of , meaning ""a student plays sport without glasses""). I know that of students play a sport, and that of students don't have glasses. So in order to solve the problem I have to do but given correct solution is . EDIT: I think the problem is in this assumption: I've assumed that and were two independent probabilities, therefore I've multiplied with . If this is not correct, then I don't know how to find probability of intersection.",30\% 20\% 60\% P(O)=0.3 P(S|O) = 0.2 P(S|O^c)=0.6 O^c O (P(S\text{ given }O^c) P(O^c|S) P(S|O^c) 80\% 70\% P(O^c|S) = \frac{0.8 \times 0.7}{0.8} = 0.7  0.87 (0.7\neq0.87) 0.8 0.7 0.8 0.7,"['probability', 'conditional-probability', 'bayes-theorem', 'word-problem', 'intersection-theory']"
47,How can I use the Cauchy-Schwarz inequality in this function of random variables?,How can I use the Cauchy-Schwarz inequality in this function of random variables?,,I have the function $\rho_{\lambda}:RV(\Omega)\rightarrow \mathbb{R}$ defined on the space $RV(\Omega)$ supported over some scenario set $\Omega$ : $\rho_\gamma(X)=\frac{1}{\gamma} \log (\mathbb{E}[e^{-\gamma X}])$ where $\gamma>0$ . Now in my book they claim that the Cauchy-Schwarz inequality shows that $\rho_\gamma(2X)\geqslant2\rho_\gamma(X)$ for every random variable $X$ and every positive $\gamma$ . I am having trouble seeing why this is the case though. Anyone have any ideas?,I have the function defined on the space supported over some scenario set : where . Now in my book they claim that the Cauchy-Schwarz inequality shows that for every random variable and every positive . I am having trouble seeing why this is the case though. Anyone have any ideas?,\rho_{\lambda}:RV(\Omega)\rightarrow \mathbb{R} RV(\Omega) \Omega \rho_\gamma(X)=\frac{1}{\gamma} \log (\mathbb{E}[e^{-\gamma X}]) \gamma>0 \rho_\gamma(2X)\geqslant2\rho_\gamma(X) X \gamma,"['probability', 'random-variables', 'expected-value', 'cauchy-schwarz-inequality']"
48,Probability of a Rubik's Cube being solvable in two moves.,Probability of a Rubik's Cube being solvable in two moves.,,"So, I have recently gotten into speed-cubing, and I ran into a very interesting problem. According to the World Cube Association, a cube is legal if it takes at least two moves to solve. So, I want to find the probability that any given Rubik's Cube is solvable in two moves. So, I wanted to find out the probability that you get a cube that is solvable in exactly two moves, as a figure like that could put in perspective how much luck is involved in speed-cubing. I have no idea where to start because I have no idea how probability works except for the stuff you learn in high-school and early college. Any ideas where to start?","So, I have recently gotten into speed-cubing, and I ran into a very interesting problem. According to the World Cube Association, a cube is legal if it takes at least two moves to solve. So, I want to find the probability that any given Rubik's Cube is solvable in two moves. So, I wanted to find out the probability that you get a cube that is solvable in exactly two moves, as a figure like that could put in perspective how much luck is involved in speed-cubing. I have no idea where to start because I have no idea how probability works except for the stuff you learn in high-school and early college. Any ideas where to start?",,"['probability', 'rubiks-cube']"
49,Indicator random variables of two events,Indicator random variables of two events,,"Before someone closes this question or marks it as a duplicate, I would like to point out that this question is based on another identical asked question here . It never got a real answer so this is my own attempt at solving the problem. Let A be an event, and let $I_{A}$ be the associated indicator random variable: $I_{A} (\omega)=1$ if $ω∈A$ , and $I_{A}(ω)=0$ if $ω∉A$ . Similarly, let $I_{B}$ be the indicator of another event, $B$ . Suppose that, $P(A)=p$ , $P(B)=q$ , and $P(A∪B)=r$ . To find $E[(I_{A}−I_{B})^2]$ in terms of $p$ , $q$ and $r$ $$E[(I_{A}−I_{B})^2]=E[(I_{A}−I_{B})(I_{A}−I_{B})]$$ $$E[(I_{A}−I_{B})^2]=E(I^2_{A}-2I_{A}I_{B}+I^2_{B}]$$ Given $I^2_𝐴=I_𝐴$ and $I_𝐴I_𝐵=I_{𝐴∩𝐵}$ , then $$E[(I_{A}−I_{B})^2]=E[I_{A}-2I_{A∩B}+I_{B}]$$ $$E[(I_{A}−I_{B})^2]=E[I_{A}]-2E[I_{A∩B}]+E[I_{B}]$$ $$E[(I_{A}−I_{B})^2]=P(A)-2P(A∩B)+P(B)$$ Given $𝑃(𝐴∩𝐵)=𝑃(𝐴)+𝑃(𝐵)−𝑃(𝐴∪𝐵)$ , then $$E[(I_{A}−I_{B})^2]=P(A)-2(P(A)+P(B)-𝑃(𝐴∪𝐵))+P(B)$$ $$E[(I_{A}−I_{B})^2]=2𝑃(𝐴∪𝐵)-P(A)-P(B)=2r-p-q$$ I am not completely certain about going from $-2I_{A∩B}$ to $-2E[I_{A∩B}]$ What I would like to know, is this transition legit? If so, determine $\text{Var}(I_{A}−I_{B})$ in terms of $p$ , $q$ and $r$ by substituting. Given $𝖵𝖺𝗋(𝑋)=E[𝑋]^2−(E[𝑋])^2$ , then $$𝖵𝖺𝗋(I_{A}−I_{B})=E[I_{A}−I_{B}]^2−(E[I_{A}−I_{B}])^2$$ $$𝖵𝖺𝗋(I_{A}−I_{B})=E[(I_{A}−I_{B})^2]−(E[I_{A}]−E[I_{B}])^2$$ $$𝖵𝖺𝗋(I_{A}−I_{B})=2r-p-q−(p−q)^2$$ Anyone feel free to show another method or to correct me if I am wrong.","Before someone closes this question or marks it as a duplicate, I would like to point out that this question is based on another identical asked question here . It never got a real answer so this is my own attempt at solving the problem. Let A be an event, and let be the associated indicator random variable: if , and if . Similarly, let be the indicator of another event, . Suppose that, , , and . To find in terms of , and Given and , then Given , then I am not completely certain about going from to What I would like to know, is this transition legit? If so, determine in terms of , and by substituting. Given , then Anyone feel free to show another method or to correct me if I am wrong.",I_{A} I_{A} (\omega)=1 ω∈A I_{A}(ω)=0 ω∉A I_{B} B P(A)=p P(B)=q P(A∪B)=r E[(I_{A}−I_{B})^2] p q r E[(I_{A}−I_{B})^2]=E[(I_{A}−I_{B})(I_{A}−I_{B})] E[(I_{A}−I_{B})^2]=E(I^2_{A}-2I_{A}I_{B}+I^2_{B}] I^2_𝐴=I_𝐴 I_𝐴I_𝐵=I_{𝐴∩𝐵} E[(I_{A}−I_{B})^2]=E[I_{A}-2I_{A∩B}+I_{B}] E[(I_{A}−I_{B})^2]=E[I_{A}]-2E[I_{A∩B}]+E[I_{B}] E[(I_{A}−I_{B})^2]=P(A)-2P(A∩B)+P(B) 𝑃(𝐴∩𝐵)=𝑃(𝐴)+𝑃(𝐵)−𝑃(𝐴∪𝐵) E[(I_{A}−I_{B})^2]=P(A)-2(P(A)+P(B)-𝑃(𝐴∪𝐵))+P(B) E[(I_{A}−I_{B})^2]=2𝑃(𝐴∪𝐵)-P(A)-P(B)=2r-p-q -2I_{A∩B} -2E[I_{A∩B}] \text{Var}(I_{A}−I_{B}) p q r 𝖵𝖺𝗋(𝑋)=E[𝑋]^2−(E[𝑋])^2 𝖵𝖺𝗋(I_{A}−I_{B})=E[I_{A}−I_{B}]^2−(E[I_{A}−I_{B}])^2 𝖵𝖺𝗋(I_{A}−I_{B})=E[(I_{A}−I_{B})^2]−(E[I_{A}]−E[I_{B}])^2 𝖵𝖺𝗋(I_{A}−I_{B})=2r-p-q−(p−q)^2,"['probability', 'random-variables', 'expected-value']"
50,A paradox in probability,A paradox in probability,,"I am trying to calculate the probability of picking perfect squares out of first $n$ positive integers. There are $\operatorname{floor}(\sqrt n)$ number of perfect squares less than $n$ , if we assume picking each number is equally likely then probability of picking perfect squares less than $n$ is $p(n) =\operatorname {floor}(\sqrt n) /n$ But if we consider all positive integers then ( I think but I am not sure) the probability is $\lim_{n\to \infty} p(n) = 0$ . That means the probability of selecting a square is $0$ even though there are infinitely many squares! Does this mean I that I will not get any squares when I pick any positive integers? This appears like a paradox. I think I have not very much understood what it means by $P(A) = 0$ , does this mean the event $A$ is impossible or something else? Can you give some insights about this?","I am trying to calculate the probability of picking perfect squares out of first positive integers. There are number of perfect squares less than , if we assume picking each number is equally likely then probability of picking perfect squares less than is But if we consider all positive integers then ( I think but I am not sure) the probability is . That means the probability of selecting a square is even though there are infinitely many squares! Does this mean I that I will not get any squares when I pick any positive integers? This appears like a paradox. I think I have not very much understood what it means by , does this mean the event is impossible or something else? Can you give some insights about this?",n \operatorname{floor}(\sqrt n) n n p(n) =\operatorname {floor}(\sqrt n) /n \lim_{n\to \infty} p(n) = 0 0 P(A) = 0 A,"['probability', 'paradoxes']"
51,Prove the random variable is bounded,Prove the random variable is bounded,,Let $g_n$ be given by $$g_n=\prod_{i=1}^n \left(1+\frac{X_i}{\sqrt{i}}\right)$$ where $X_i$ 's are independent random variables with $P(X_i=1)=P(X_i=-1)=0.5$ .Then is it true that $P(g_n \rightarrow \infty)=0$ .If yes how can I show it? My attempt:I think I have to use Borel Cantelli lemma but I am not sure how.,Let be given by where 's are independent random variables with .Then is it true that .If yes how can I show it? My attempt:I think I have to use Borel Cantelli lemma but I am not sure how.,g_n g_n=\prod_{i=1}^n \left(1+\frac{X_i}{\sqrt{i}}\right) X_i P(X_i=1)=P(X_i=-1)=0.5 P(g_n \rightarrow \infty)=0,"['probability', 'probability-theory']"
52,Repeatedly selecting a random number from $\mathbb{N}_{≤n}$ always reaches $0$?,Repeatedly selecting a random number from  always reaches ?,\mathbb{N}_{≤n} 0,"Let $S$ be the set of natural numbers from zero to $n$ , namely $S = \{ s : s∈\mathbb{N} ∧ s ≤ n \}$ . With each turn we pick a random number from the set. If we get one specific number (let's say $0$ ), the experiment is complete. If we get any other number, we go on with the next turn (hoping to get $0$ and going on with yet another turn otherwise). Is it possible to prove that such an experiment always ends with a finite number of turns?","Let be the set of natural numbers from zero to , namely . With each turn we pick a random number from the set. If we get one specific number (let's say ), the experiment is complete. If we get any other number, we go on with the next turn (hoping to get and going on with yet another turn otherwise). Is it possible to prove that such an experiment always ends with a finite number of turns?",S n S = \{ s : s∈\mathbb{N} ∧ s ≤ n \} 0 0,['probability']
53,"Define ""Almost Always Less Than""","Define ""Almost Always Less Than""",,"Is there a formal definition of ""almost always less than"" or ""almost always greater than""? I think one could define it using probabilities but not sure how to go about it. If one could show the following, then I think you could say $X$ is almost always less than a value $x$ . Is there other ways of going about this? $$ P(X<x)=1 $$","Is there a formal definition of ""almost always less than"" or ""almost always greater than""? I think one could define it using probabilities but not sure how to go about it. If one could show the following, then I think you could say is almost always less than a value . Is there other ways of going about this?","X x 
P(X<x)=1
",['probability']
54,Probability of creating two same groups,Probability of creating two same groups,,"There are 10 different types of stickers. We have a collection of 20 stickers, where each sticker appears twice (each and every sticker has a duplicate). Now we are asked to put 10 stickers in two bags (each bag contains exactly 10 stickers), when there are no same stickers in every bag, so they are distinct. What is the probability of this arrangement? My attempt was to think about ways to choose an $x$ which will suit the general formula $\cfrac{ x}{{20 \choose 10}}$ but with no success. I also thought about calculating the probability using the intuitive method of choosing the first bag: $\cfrac{2}{{20}}⋅\cfrac{2}{{19}}⋅\cfrac{2}{{18}}⋅\cfrac{2}{{17}}⋅\cfrac{2}{{16}}⋅\cfrac{2}{{15}}⋅\cfrac{2}{{14}}⋅\cfrac{2}{{13}}⋅\cfrac{2}{{12}}⋅\cfrac{2}{{11}}$ When we have 10 iterations of probabilities of choosing one of 2 different stickers out of what we have at the moment of choosing. But I was wrong. The book says that the probability is just: $$\cfrac{ 2^{10}}{{20 \choose 10}}$$ Which looks like a combination of my two attempts. I still don't get the point. It seems like a relatively easy question, but I find it confusing.","There are 10 different types of stickers. We have a collection of 20 stickers, where each sticker appears twice (each and every sticker has a duplicate). Now we are asked to put 10 stickers in two bags (each bag contains exactly 10 stickers), when there are no same stickers in every bag, so they are distinct. What is the probability of this arrangement? My attempt was to think about ways to choose an which will suit the general formula but with no success. I also thought about calculating the probability using the intuitive method of choosing the first bag: When we have 10 iterations of probabilities of choosing one of 2 different stickers out of what we have at the moment of choosing. But I was wrong. The book says that the probability is just: Which looks like a combination of my two attempts. I still don't get the point. It seems like a relatively easy question, but I find it confusing.",x \cfrac{ x}{{20 \choose 10}} \cfrac{2}{{20}}⋅\cfrac{2}{{19}}⋅\cfrac{2}{{18}}⋅\cfrac{2}{{17}}⋅\cfrac{2}{{16}}⋅\cfrac{2}{{15}}⋅\cfrac{2}{{14}}⋅\cfrac{2}{{13}}⋅\cfrac{2}{{12}}⋅\cfrac{2}{{11}} \cfrac{ 2^{10}}{{20 \choose 10}},"['probability', 'combinatorics']"
55,What is the expected number of flips you need to get k changeovers?,What is the expected number of flips you need to get k changeovers?,,"Flip a fair coin several times. Say that a changeover occurs whenever an outcome differs from the one preceding it. For instance, if you flip the coin 5 times and the outcome is HHTHT, then there are 3 changeovers. Consider n independent flips of this coin, what is the expected number of changeovers? What is the expected number of flips you need to get k changeovers? My Attempt This one isn't too hard. Let $I_j$ be an indicator random variable that equals $1$ if we have a changeover and $0$ otherwise. For $I_j=1$ , we need to have a heads on the $j^{th}$ flip and tails on the $(j+1)^{th}$ flip or tails first then heads for $j\in[1,n-1]$ . Thus, $$\mathbb{P}(I_j=1)=2p(1-p)$$ Our coin is fair, so $p=\frac{1}{2}$ . Thus, $\mathbb{P}(I_j=1)=\frac{1}{2}$ If X is a random variable representing the number of changeovers. Then by linearity of the expectation, we have that $$\mathbb{E}(X)=\sum_j\mathbb{P}(I_j)=(n-1)\cdot\frac{1}{2}=\frac{n-1}{2}$$ For this part, I am not so sure how to start. Would I use a binomial distribution? As in $X\sim\text{Bin}(n,\frac{1}{2})$ so that our probability is $$\mathbb{P}(X=k)=\binom{n}{k}(\frac{1}{2})^k(1-\frac{1}{2})^{n-k}$$ I'm not too sure that this is the right approach or how to continue. Edit Second attempt for the second part: (I know this is wrong from the comments below, but can I get pointers on where I went wrong?) Let X be the number of flips before k changeovers. Then $X\sim\text{Geom}(p)$ . The probability is given by the formula $$\mathbb{P}(X=k)=(1-p)^{k-1}p$$ We know that $p=\frac{1}{2}$ from the last part, so $\mathbb{P}(X=k)=\frac{1}{2^k}$ The expectation of a geometric distribution is $\mathbb{E}[X]=\frac{1}{p}$ , so we have $E[X]=2^k$","Flip a fair coin several times. Say that a changeover occurs whenever an outcome differs from the one preceding it. For instance, if you flip the coin 5 times and the outcome is HHTHT, then there are 3 changeovers. Consider n independent flips of this coin, what is the expected number of changeovers? What is the expected number of flips you need to get k changeovers? My Attempt This one isn't too hard. Let be an indicator random variable that equals if we have a changeover and otherwise. For , we need to have a heads on the flip and tails on the flip or tails first then heads for . Thus, Our coin is fair, so . Thus, If X is a random variable representing the number of changeovers. Then by linearity of the expectation, we have that For this part, I am not so sure how to start. Would I use a binomial distribution? As in so that our probability is I'm not too sure that this is the right approach or how to continue. Edit Second attempt for the second part: (I know this is wrong from the comments below, but can I get pointers on where I went wrong?) Let X be the number of flips before k changeovers. Then . The probability is given by the formula We know that from the last part, so The expectation of a geometric distribution is , so we have","I_j 1 0 I_j=1 j^{th} (j+1)^{th} j\in[1,n-1] \mathbb{P}(I_j=1)=2p(1-p) p=\frac{1}{2} \mathbb{P}(I_j=1)=\frac{1}{2} \mathbb{E}(X)=\sum_j\mathbb{P}(I_j)=(n-1)\cdot\frac{1}{2}=\frac{n-1}{2} X\sim\text{Bin}(n,\frac{1}{2}) \mathbb{P}(X=k)=\binom{n}{k}(\frac{1}{2})^k(1-\frac{1}{2})^{n-k} X\sim\text{Geom}(p) \mathbb{P}(X=k)=(1-p)^{k-1}p p=\frac{1}{2} \mathbb{P}(X=k)=\frac{1}{2^k} \mathbb{E}[X]=\frac{1}{p} E[X]=2^k","['probability', 'random-variables', 'expected-value']"
56,Reference Needed: $m$-faced dice with $n$ options,Reference Needed: -faced dice with  options,m n,"I would like to investigate the following question and I am not sure if similar ideas have been investigated. I cannot really find a detail discussion about this matter on the Internet. It will be great if you can tell me what domain I should look into, or you may also give your view on the following questions. Suppose we have one fair dice. We would like to choose an option randomly from 6 possible options. We roll the dice once then we can decide which option we should choose. Suppose we now have 8 options. To choose an option randomly, different algorithms can be used. For example, roll the dice once first. If the result is odd, we focus on option 1 to 4. Then roll the dice again, if we get 1 to 4, we know which option to use. If it is a 5 or 6, repeat the second step again. If the result is even, we focus on option 5 to 8. Then roll the dice again, if we get $n$ , which $1\leq n\leq 4$ , we choose option $n+4$ . If it is a 5 or 6, repeat the second step again. One can check the the probability of choosing each option is exactly $\frac{1}{8}$ . My question now is to investigate if it is possible that for whatever number of options we have, we can always use a dice to choose an option randomly. And is there a general algorithm to follow in order to choose an option? My second question is more advance. Suppose we have a fair $m$ -faced dice and we have $n$ total options. Can we choose an option randomly by using the dice for any $m$ and $n$ ? Once again, you don't have to answer the above two questions. I am looking for hints or domain that I should look into. Thank you.","I would like to investigate the following question and I am not sure if similar ideas have been investigated. I cannot really find a detail discussion about this matter on the Internet. It will be great if you can tell me what domain I should look into, or you may also give your view on the following questions. Suppose we have one fair dice. We would like to choose an option randomly from 6 possible options. We roll the dice once then we can decide which option we should choose. Suppose we now have 8 options. To choose an option randomly, different algorithms can be used. For example, roll the dice once first. If the result is odd, we focus on option 1 to 4. Then roll the dice again, if we get 1 to 4, we know which option to use. If it is a 5 or 6, repeat the second step again. If the result is even, we focus on option 5 to 8. Then roll the dice again, if we get , which , we choose option . If it is a 5 or 6, repeat the second step again. One can check the the probability of choosing each option is exactly . My question now is to investigate if it is possible that for whatever number of options we have, we can always use a dice to choose an option randomly. And is there a general algorithm to follow in order to choose an option? My second question is more advance. Suppose we have a fair -faced dice and we have total options. Can we choose an option randomly by using the dice for any and ? Once again, you don't have to answer the above two questions. I am looking for hints or domain that I should look into. Thank you.",n 1\leq n\leq 4 n+4 \frac{1}{8} m n m n,"['probability', 'reference-request', 'dice']"
57,Probability of both members of a committee being girls,Probability of both members of a committee being girls,,"A small committee of two is formed from a group of 4 boys and 8 girls. If at least one of the members of the committee is a girl, what is the probability that both members are girls? So far I have tried: Multiplying the original number of original girls ( $\frac{8}{12}$ ) by one minus hence it is given to us one is already part of the committee ( $\frac{7}{11}$ ) to no avail. Also did some other things similar to what i just said before that I don't remember since I was trying everything that I could conjure up.How do i tackle this problem?.","A small committee of two is formed from a group of 4 boys and 8 girls. If at least one of the members of the committee is a girl, what is the probability that both members are girls? So far I have tried: Multiplying the original number of original girls ( ) by one minus hence it is given to us one is already part of the committee ( ) to no avail. Also did some other things similar to what i just said before that I don't remember since I was trying everything that I could conjure up.How do i tackle this problem?.",\frac{8}{12} \frac{7}{11},"['probability', 'conditional-probability']"
58,Covariance of sum and maximum,Covariance of sum and maximum,,"I have the task :) $X_1, X_2$ are independent and have uniform distribution on $(0,1).$ Calculate $\operatorname{Cov}(X_1+X_2,\max(X_1,X_2))$ . I did it in this way. The distriburion of $\max(X_1,X_2)$ is $P(\max(X_1,X_2)=x)=2x$ on $(0,1)$ . In this way we have: $E(X_1+X_2)\cdot E\max(X_1,X_2)=1 \cdot \frac{2}{3}$ \begin{align} & E((X_1+X_2) \cdot \max(X_1,X_2))=2 E(X_1\cdot \max(X_1,X_2)) \\[6pt] = {} &2 \cdot  \int_0^1 E(t \cdot \max(t,X_2))\cdot f_{X_1}(t) \,dt=2\cdot  \int_0^1 t \cdot \frac{t+1}{2} \, dt=\frac{5}{6} \end{align} So the covariance is equal $\frac{1}{6}$ But I have the correct answer to this task and it is $\frac{1}{12}$ Where did I mistake? Thanks in advance.",I have the task :) are independent and have uniform distribution on Calculate . I did it in this way. The distriburion of is on . In this way we have: So the covariance is equal But I have the correct answer to this task and it is Where did I mistake? Thanks in advance.,"X_1, X_2 (0,1). \operatorname{Cov}(X_1+X_2,\max(X_1,X_2)) \max(X_1,X_2) P(\max(X_1,X_2)=x)=2x (0,1) E(X_1+X_2)\cdot E\max(X_1,X_2)=1 \cdot \frac{2}{3} \begin{align}
& E((X_1+X_2) \cdot \max(X_1,X_2))=2 E(X_1\cdot \max(X_1,X_2)) \\[6pt]
= {} &2 \cdot  \int_0^1 E(t \cdot \max(t,X_2))\cdot f_{X_1}(t) \,dt=2\cdot  \int_0^1 t \cdot \frac{t+1}{2} \, dt=\frac{5}{6}
\end{align} \frac{1}{6} \frac{1}{12}","['probability', 'probability-distributions', 'expected-value', 'uniform-distribution', 'covariance']"
59,probability that first $2$ drawn balls are red,probability that first  drawn balls are red,2,"A bag contain $9$ red and $12$ blue balls. If $4$ balls are selected randomly without replacement, then find the probability that the first $2$ balls are red. What I tried: Let $A$ be the event the first drawn ball is red and $B$ be the event that the second drawn ball is red. Then $P(A)=8/21$ and $P(B)=7/20$ . If first $2$ drawn balls are red. Then other $2$ drawn balls are both red or blue or one red one blue. But I don't understand how this helps. Please help me! Thanks!","A bag contain red and blue balls. If balls are selected randomly without replacement, then find the probability that the first balls are red. What I tried: Let be the event the first drawn ball is red and be the event that the second drawn ball is red. Then and . If first drawn balls are red. Then other drawn balls are both red or blue or one red one blue. But I don't understand how this helps. Please help me! Thanks!",9 12 4 2 A B P(A)=8/21 P(B)=7/20 2 2,['probability']
60,Interpreting almost sure convergence,Interpreting almost sure convergence,,"I'm reading: https://en.wikipedia.org/wiki/Convergence_of_random_variables#Almost_sure_convergence and here it says that Given a probability space $(\Omega,\mathcal{F},P)$ and a random variable $X:\Omega \rightarrow \mathbb{R}$ almost sure convergence stands for $$P\left(\omega \in \Omega: \lim_{n \rightarrow \infty} X_n(\omega)=X\right)=1.$$ [...] almost sure convergence can also be defined as follows: $$P\left(\limsup_{n \rightarrow \infty} \left\{\omega \in \Omega: |X_n(\omega) - X(\omega)| > \varepsilon\right\}\right)=0, \quad \forall \; \varepsilon>0.$$ My question is, what is the intuition behind this equivalence? I understand the first definition, but why do we use $\limsup$ in the second one to make the equivalence work? Thanks","I'm reading: https://en.wikipedia.org/wiki/Convergence_of_random_variables#Almost_sure_convergence and here it says that Given a probability space and a random variable almost sure convergence stands for [...] almost sure convergence can also be defined as follows: My question is, what is the intuition behind this equivalence? I understand the first definition, but why do we use in the second one to make the equivalence work? Thanks","(\Omega,\mathcal{F},P) X:\Omega \rightarrow \mathbb{R} P\left(\omega \in \Omega: \lim_{n \rightarrow \infty} X_n(\omega)=X\right)=1. P\left(\limsup_{n \rightarrow \infty} \left\{\omega \in \Omega: |X_n(\omega) - X(\omega)| > \varepsilon\right\}\right)=0, \quad \forall \; \varepsilon>0. \limsup","['probability', 'probability-theory', 'convergence-divergence', 'random-variables', 'almost-everywhere']"
61,Generalization of Jensen's inequality,Generalization of Jensen's inequality,,"Let $X=(X_1,\dots,X_n)$ be a $\mathbb R^n$ -valued random vector such that $E(|X_i|)<\infty$ for all $i$ . Let $f: \mathbb R^n \to \mathbb R$ be a convex function. Jensen's inequality tells us that $E(f(X_1,\dots,X_n))$ exists (in $]-\infty,\infty]$ ) and that $$E(f(X_1,\dots,X_n)) \ge f(E(X_1),\dots,E(X_n)).$$ So if we replace each $X_i$ by its expectation $E(X_i)$ we get something smaller. Does this still hold if we substitute only some of the $X_i$ by their expectations? Question: Does it hold that $E(f(X_1,\dots,X_n)) \ge E(f(E(X_1),X_2\dots,X_n))$ ? Here are my thoughts: Using the conditional Jensen's inequality we get that \begin{align*} E(f(X_1,\dots,X_n)) &= E(E(f(X_1,\dots,X_n)|X_2,\dots,X_n))\\                     &\ge E(f(E(X_1|X_2,\dots,X_n),X_2\dots,X_n)) \end{align*} holds whenever $E(|X_1||X_2,\dots,X_n)$ is a.s. finite. If $X_1,\dots,X_n$ are independent it follows that $$E(f(X_1,\dots,X_n)) \ge E(f(E(X_1),X_2\dots,X_n))$$ and we can iterate this to get $$E(f(E(X_1),X_2\dots,X_n)) \ge E(f(E(X_1),E(X_2),X_3\dots,X_n)),$$ etc. But what if $X_1, \dots, X_n$ are not independent?",Let be a -valued random vector such that for all . Let be a convex function. Jensen's inequality tells us that exists (in ) and that So if we replace each by its expectation we get something smaller. Does this still hold if we substitute only some of the by their expectations? Question: Does it hold that ? Here are my thoughts: Using the conditional Jensen's inequality we get that holds whenever is a.s. finite. If are independent it follows that and we can iterate this to get etc. But what if are not independent?,"X=(X_1,\dots,X_n) \mathbb R^n E(|X_i|)<\infty i f: \mathbb R^n \to \mathbb R E(f(X_1,\dots,X_n)) ]-\infty,\infty] E(f(X_1,\dots,X_n)) \ge f(E(X_1),\dots,E(X_n)). X_i E(X_i) X_i E(f(X_1,\dots,X_n)) \ge E(f(E(X_1),X_2\dots,X_n)) \begin{align*}
E(f(X_1,\dots,X_n)) &= E(E(f(X_1,\dots,X_n)|X_2,\dots,X_n))\\
                    &\ge E(f(E(X_1|X_2,\dots,X_n),X_2\dots,X_n))
\end{align*} E(|X_1||X_2,\dots,X_n) X_1,\dots,X_n E(f(X_1,\dots,X_n)) \ge E(f(E(X_1),X_2\dots,X_n)) E(f(E(X_1),X_2\dots,X_n)) \ge E(f(E(X_1),E(X_2),X_3\dots,X_n)), X_1, \dots, X_n","['real-analysis', 'probability', 'probability-theory', 'measure-theory', 'jensen-inequality']"
62,"Has anyone invented a computationally simple method to calculate the probability of at least n1-consecutive die rolls, for n2-sided die, n3-rolls?","Has anyone invented a computationally simple method to calculate the probability of at least n1-consecutive die rolls, for n2-sided die, n3-rolls?",,"I think I have invented a formula that allows a computer to very easily calculate the probability of at least n1-consecutive die rolls, on an n2-sided die, rolling it n3-times. For example, for a 3-sided die being rolled 4 times, the probability of at least 3 consecutive rolls being the same is: $$\frac{5}{27} \sim 0.185185$$ A 10-sided die being rolled 20 times with at least 4 consecutive rolls: $$\frac{153252438815221561}{10000000000000000000} \sim 0.0153252$$ A 20-sided die being rolled 100 times with at least 5 consecutive rolls: $$\frac{36138486362801675395834082841530471263391618236217471764311872542282160082804618163213    4714483039586709049484138205953646876021}{63382530011411470074835160268800000000000000000    0000000000000000000000000000000000000000000000000000000000000000000000000000000000} \sim 0.000570165$$ A 150-sided die being rolled 250 times with at least 10 consecutive rolls: $$\frac{43754862099840059340989164536890668843600275210242353790609200399332108157129005621344    12966072844123998821529817954285993344643635690087672932957210052124849484632371945364241    27895214917314522967829996314996884843354909465711479333655125328467972639354192054002381    80358736161798175079981214320161396998878382245814510025222948918658240716181935621089269    06271521762936897812401688121481273594338138312959838934408957524646299446591373165468391    26633170992252043228387167654509762247790434963321680468677569650750302475087706401}{7026    24848833633473725832814569816725466578833488064526319504046334823913293570611014402352480    20759777065059629450925139424048788112889589987529495486017499085597652471999291372698929    85667366792663663798677273390781336908763915319543616880317198383190582106072596957346831    91403746604919433593750000000000000000000000000000000000000000000000000000000000000000000    00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000    00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000    0000} \sim \text{6.2273433927754916$\grave{ }$*${}^{\wedge}$-18}$$ What I want to know, is there a method out there that already exists which is finding what I am already able to find?  I am really scared that I have wasted my time 'inventing' something that someone has already done before as my literature review has come up empty.  I am also a bit weary to share my method at the moment because I would ideally want to write a paper on this if this has not been done before. Edit:  You can generate tables with this easily too.  For a 6-sided die for up to 15-rolls and -consecutive: $$ \left( \begin{array}{ccccccccccccccc}  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & \frac{1}{6} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & \frac{11}{36} & \frac{1}{36} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & \frac{91}{216} & \frac{11}{216} & \frac{1}{216} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & \frac{671}{1296} & \frac{2}{27} & \frac{11}{1296} & \frac{1}{1296} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & \frac{4651}{7776} & \frac{751}{7776} & \frac{1}{81} & \frac{11}{7776} & \frac{1}{7776} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & \frac{31031}{46656} & \frac{5531}{46656} & \frac{7}{432} & \frac{1}{486} & \frac{11}{46656} & \frac{1}{46656} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & \frac{201811}{279936} & \frac{2177}{15552} & \frac{5611}{279936} & \frac{7}{2592} & \frac{1}{2916} & \frac{11}{279936} & \frac{1}{279936} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & \frac{1288991}{1679616} & \frac{270241}{1679616} & \frac{40091}{1679616} & \frac{13}{3888} & \frac{7}{15552} & \frac{1}{17496} & \frac{11}{1679616} & \frac{1}{1679616} & 0 & 0 & 0 & 0 & 0 & 0 \\  1 & \frac{8124571}{10077696} & \frac{1827071}{10077696} & \frac{15497}{559872} & \frac{40171}{10077696} & \frac{13}{23328} & \frac{7}{93312} & \frac{1}{104976} & \frac{11}{10077696} & \frac{1}{10077696} & 0 & 0 & 0 & 0 & 0 \\  1 & \frac{50700551}{60466176} & \frac{126731}{629856} & \frac{979}{31104} & \frac{279851}{60466176} & \frac{31}{46656} & \frac{13}{139968} & \frac{7}{559872} & \frac{1}{629856} & \frac{11}{60466176} & \frac{1}{60466176} & 0 & 0 & 0 & 0 \\  1 & \frac{313968931}{362797056} & \frac{80043931}{362797056} & \frac{12790681}{362797056} & \frac{106217}{20155392} & \frac{279931}{362797056} & \frac{31}{279936} & \frac{13}{839808} & \frac{7}{3359232} & \frac{1}{3779136} & \frac{11}{362797056} &    \frac{1}{362797056} & 0 & 0 & 0 \\  1 & \frac{1932641711}{2176782336} & \frac{521516711}{2176782336} & \frac{84941711}{2176782336} & \frac{6619}{1119744} & \frac{1912811}{2176782336} & \frac{1}{7776} & \frac{31}{1679616} & \frac{13}{5038848} & \frac{7}{20155392} & \frac{1}{22674816} &    \frac{11}{2176782336} & \frac{1}{2176782336} & 0 & 0 \\  1 & \frac{11839990891}{13060694016} & \frac{561766711}{2176782336} & \frac{11638417}{272097792} & \frac{24761}{3779136} & \frac{715337}{725594112} & \frac{1912891}{13060694016} & \frac{1}{46656} & \frac{31}{10077696} & \frac{13}{30233088} &    \frac{7}{120932352} & \frac{1}{136048896} & \frac{11}{13060694016} & \frac{1}{13060694016} & 0 \\  1 & \frac{72260648471}{78364164096} & \frac{21637367221}{78364164096} & \frac{50620543}{1088391168} & \frac{563631721}{78364164096} & \frac{44059}{40310784} & \frac{12876971}{78364164096} & \frac{41}{1679616} & \frac{1}{279936} & \frac{31}{60466176} &    \frac{13}{181398528} & \frac{7}{725594112} & \frac{1}{816293376} & \frac{11}{78364164096} & \frac{1}{78364164096} \\ \end{array} \right) $$","I think I have invented a formula that allows a computer to very easily calculate the probability of at least n1-consecutive die rolls, on an n2-sided die, rolling it n3-times. For example, for a 3-sided die being rolled 4 times, the probability of at least 3 consecutive rolls being the same is: A 10-sided die being rolled 20 times with at least 4 consecutive rolls: A 20-sided die being rolled 100 times with at least 5 consecutive rolls: A 150-sided die being rolled 250 times with at least 10 consecutive rolls: What I want to know, is there a method out there that already exists which is finding what I am already able to find?  I am really scared that I have wasted my time 'inventing' something that someone has already done before as my literature review has come up empty.  I am also a bit weary to share my method at the moment because I would ideally want to write a paper on this if this has not been done before. Edit:  You can generate tables with this easily too.  For a 6-sided die for up to 15-rolls and -consecutive:","\frac{5}{27} \sim 0.185185 \frac{153252438815221561}{10000000000000000000} \sim 0.0153252 \frac{36138486362801675395834082841530471263391618236217471764311872542282160082804618163213
   4714483039586709049484138205953646876021}{63382530011411470074835160268800000000000000000
   0000000000000000000000000000000000000000000000000000000000000000000000000000000000} \sim 0.000570165 \frac{43754862099840059340989164536890668843600275210242353790609200399332108157129005621344
   12966072844123998821529817954285993344643635690087672932957210052124849484632371945364241
   27895214917314522967829996314996884843354909465711479333655125328467972639354192054002381
   80358736161798175079981214320161396998878382245814510025222948918658240716181935621089269
   06271521762936897812401688121481273594338138312959838934408957524646299446591373165468391
   26633170992252043228387167654509762247790434963321680468677569650750302475087706401}{7026
   24848833633473725832814569816725466578833488064526319504046334823913293570611014402352480
   20759777065059629450925139424048788112889589987529495486017499085597652471999291372698929
   85667366792663663798677273390781336908763915319543616880317198383190582106072596957346831
   91403746604919433593750000000000000000000000000000000000000000000000000000000000000000000
   00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
   00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
   0000} \sim \text{6.2273433927754916\grave{ }*{}^{\wedge}-18} 
\left(
\begin{array}{ccccccccccccccc}
 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{1}{6} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{11}{36} & \frac{1}{36} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{91}{216} & \frac{11}{216} & \frac{1}{216} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{671}{1296} & \frac{2}{27} & \frac{11}{1296} & \frac{1}{1296} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{4651}{7776} & \frac{751}{7776} & \frac{1}{81} & \frac{11}{7776} & \frac{1}{7776} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{31031}{46656} & \frac{5531}{46656} & \frac{7}{432} & \frac{1}{486} & \frac{11}{46656} & \frac{1}{46656} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{201811}{279936} & \frac{2177}{15552} & \frac{5611}{279936} & \frac{7}{2592} & \frac{1}{2916} & \frac{11}{279936} & \frac{1}{279936} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{1288991}{1679616} & \frac{270241}{1679616} & \frac{40091}{1679616} & \frac{13}{3888} & \frac{7}{15552} & \frac{1}{17496} & \frac{11}{1679616} & \frac{1}{1679616} & 0 & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{8124571}{10077696} & \frac{1827071}{10077696} & \frac{15497}{559872} & \frac{40171}{10077696} & \frac{13}{23328} & \frac{7}{93312} & \frac{1}{104976} & \frac{11}{10077696} & \frac{1}{10077696} & 0 & 0 & 0 & 0 & 0 \\
 1 & \frac{50700551}{60466176} & \frac{126731}{629856} & \frac{979}{31104} & \frac{279851}{60466176} & \frac{31}{46656} & \frac{13}{139968} & \frac{7}{559872} & \frac{1}{629856} & \frac{11}{60466176} & \frac{1}{60466176} & 0 & 0 & 0 & 0 \\
 1 & \frac{313968931}{362797056} & \frac{80043931}{362797056} & \frac{12790681}{362797056} & \frac{106217}{20155392} & \frac{279931}{362797056} & \frac{31}{279936} & \frac{13}{839808} & \frac{7}{3359232} & \frac{1}{3779136} & \frac{11}{362797056} &
   \frac{1}{362797056} & 0 & 0 & 0 \\
 1 & \frac{1932641711}{2176782336} & \frac{521516711}{2176782336} & \frac{84941711}{2176782336} & \frac{6619}{1119744} & \frac{1912811}{2176782336} & \frac{1}{7776} & \frac{31}{1679616} & \frac{13}{5038848} & \frac{7}{20155392} & \frac{1}{22674816} &
   \frac{11}{2176782336} & \frac{1}{2176782336} & 0 & 0 \\
 1 & \frac{11839990891}{13060694016} & \frac{561766711}{2176782336} & \frac{11638417}{272097792} & \frac{24761}{3779136} & \frac{715337}{725594112} & \frac{1912891}{13060694016} & \frac{1}{46656} & \frac{31}{10077696} & \frac{13}{30233088} &
   \frac{7}{120932352} & \frac{1}{136048896} & \frac{11}{13060694016} & \frac{1}{13060694016} & 0 \\
 1 & \frac{72260648471}{78364164096} & \frac{21637367221}{78364164096} & \frac{50620543}{1088391168} & \frac{563631721}{78364164096} & \frac{44059}{40310784} & \frac{12876971}{78364164096} & \frac{41}{1679616} & \frac{1}{279936} & \frac{31}{60466176} &
   \frac{13}{181398528} & \frac{7}{725594112} & \frac{1}{816293376} & \frac{11}{78364164096} & \frac{1}{78364164096} \\
\end{array}
\right)
","['probability', 'statistics', 'fibonacci-numbers']"
63,Probability: Random variable dice problem,Probability: Random variable dice problem,,"I'm not sure how to approach the below problem using random variable. Can I consider this as distinct events and calculate the average of each and then add them together? Can I use a binomial distribution? I'm very lost... You have 1 dice. Each face has a probability of 1/6. You roll the dice and if you get a 6, you win 50\$ otherwise you roll again. This time, if you get a 6, you get 10\$ otherwise you get nothing. The initial cost to play is 10\$. What is the average if you play 5 times?","I'm not sure how to approach the below problem using random variable. Can I consider this as distinct events and calculate the average of each and then add them together? Can I use a binomial distribution? I'm very lost... You have 1 dice. Each face has a probability of 1/6. You roll the dice and if you get a 6, you win 50\$ otherwise you roll again. This time, if you get a 6, you get 10\$ otherwise you get nothing. The initial cost to play is 10\$. What is the average if you play 5 times?",,"['probability', 'random-variables']"
64,Probability regarding die faces,Probability regarding die faces,,"Problem: Six faces of a cube are numbered randomly 1,2,3,4,5,6. The probability that faces 1 & 6, 6 & 3 and 3 & 1 will share an edge is: I guess the other way of asking this problem is ""probability that faces 1, 6 and 3 will share a corner"" and then it will be simply: $$ \frac{^3P_3}{^6P_3} = \frac{1}{20} $$ (Here, $^nP_r$ denotes permutations of $r$ things from $n$ total things) But, I was wrong. Any hints? The correct answer was: $\dfrac{2}{5}$","Problem: Six faces of a cube are numbered randomly 1,2,3,4,5,6. The probability that faces 1 & 6, 6 & 3 and 3 & 1 will share an edge is: I guess the other way of asking this problem is ""probability that faces 1, 6 and 3 will share a corner"" and then it will be simply: (Here, denotes permutations of things from total things) But, I was wrong. Any hints? The correct answer was:", \frac{^3P_3}{^6P_3} = \frac{1}{20}  ^nP_r r n \dfrac{2}{5},"['probability', 'combinatorics']"
65,Is it true that $\int_0^t W_s ds = tW_t?$,Is it true that,\int_0^t W_s ds = tW_t?,"Given a Brownian motion $(W_t)_{t\geq 0},$ it is well-known that $W_t^3$ is not a Brownian motion as its SDE $$d(W_t^3) = 3W_t^2 dW_t + 3W_t dt$$ contains a nonzero drift term. To make it to be a martingale, one can consider $$W_t^3 - 3\int_0^t W_s ds.$$ On the other hand, this post shows that $W_t^3 - 3tW_t$ is a martingale. Question: Is it true that $$\int_0^t W_s ds = tW_t?$$ I have a feeling that they are no equal as LHS is deterministic whereas RHS is random.","Given a Brownian motion it is well-known that is not a Brownian motion as its SDE contains a nonzero drift term. To make it to be a martingale, one can consider On the other hand, this post shows that is a martingale. Question: Is it true that I have a feeling that they are no equal as LHS is deterministic whereas RHS is random.","(W_t)_{t\geq 0}, W_t^3 d(W_t^3) = 3W_t^2 dW_t + 3W_t dt W_t^3 - 3\int_0^t W_s ds. W_t^3 - 3tW_t \int_0^t W_s ds = tW_t?","['probability', 'stochastic-calculus', 'brownian-motion', 'stochastic-integrals']"
66,How could outcomes be equally likely?,How could outcomes be equally likely?,,"Hi I've just started learning probability but I have some questions. When sloving a problem like ""If 3 balls are “randomly drawn” from a bowl containing 6 white and 5 black balls, what is the probability that one of the balls is white and the other two black?"" , they assume outcomes in the sample space are equally likely. However when considering picking 2 balls from 2 white and 1000000 black balls, how could (w,w) (w,b) be (b,b) (unordered) considered equally likely?  In my opinion (b,b) are much more likely than (w,w) because there are way much black balls than white balls.  Of course their numbers are considered when solving the probability, I still wonder   is it valid that (w,w) (w,b) be (b,b) be assumed equally likely. Sorry for my bad english because i'm not a native speaker. Please excuse me. Thank you. -edited In a textbook, it says that ""When the experiment consists of a random selection of k items from a set of n items, we have the flexibility of either letting the outcome of the experiment be the ordered selection of the k items or letting it be the unordered set of items selected. In the former case we would assume that each new selection is equally likely to be any of the so far unselected items of the set, and in the latter case we would assume that all (n k) possible subsets of k items are equally likely to be the set selected ."" I'm curious about emphasied part.","Hi I've just started learning probability but I have some questions. When sloving a problem like ""If 3 balls are “randomly drawn” from a bowl containing 6 white and 5 black balls, what is the probability that one of the balls is white and the other two black?"" , they assume outcomes in the sample space are equally likely. However when considering picking 2 balls from 2 white and 1000000 black balls, how could (w,w) (w,b) be (b,b) (unordered) considered equally likely?  In my opinion (b,b) are much more likely than (w,w) because there are way much black balls than white balls.  Of course their numbers are considered when solving the probability, I still wonder   is it valid that (w,w) (w,b) be (b,b) be assumed equally likely. Sorry for my bad english because i'm not a native speaker. Please excuse me. Thank you. -edited In a textbook, it says that ""When the experiment consists of a random selection of k items from a set of n items, we have the flexibility of either letting the outcome of the experiment be the ordered selection of the k items or letting it be the unordered set of items selected. In the former case we would assume that each new selection is equally likely to be any of the so far unselected items of the set, and in the latter case we would assume that all (n k) possible subsets of k items are equally likely to be the set selected ."" I'm curious about emphasied part.",,"['probability', 'combinations']"
67,Expected number of coin flips to see $3$ heads,Expected number of coin flips to see  heads,3,"You toss a coin until you see $3$ (not necessarily consecutive heads).   What's the expected number of coin tosses you make? I tried a lot of things, and I've seen the solution for three consecutive heads, but I'm not so sure how to do it if they are non-consecutive. With probability $1/8$ , we stop after the first three coin tosses (if we get HHH). With probability $3/16$ , we will terminate after the first four coin tosses (we can get THHH, HTHH, HHTH). It gets really messy for the rest of them, and so I don't think this approach is quite correct. Can anyone please help me solve this problem?","You toss a coin until you see (not necessarily consecutive heads).   What's the expected number of coin tosses you make? I tried a lot of things, and I've seen the solution for three consecutive heads, but I'm not so sure how to do it if they are non-consecutive. With probability , we stop after the first three coin tosses (if we get HHH). With probability , we will terminate after the first four coin tosses (we can get THHH, HTHH, HHTH). It gets really messy for the rest of them, and so I don't think this approach is quite correct. Can anyone please help me solve this problem?",3 1/8 3/16,['probability']
68,"If you draw two cards in consecutively in a standard deck of 52 cards, what is the probability of getting black on the second draw?","If you draw two cards in consecutively in a standard deck of 52 cards, what is the probability of getting black on the second draw?",,This is my thought process: $P(2^{nd}\ \text{black}) = P(2^{nd}\ \text{black} \mid 1^{st}\ \text{red}) P(1^{st}\ \text{red}) + P(2^{nd}\ \text{black} \mid 1^{st}\ \text{black}) P(1^{st} \ \text{black}) $ $\frac{26}{51}*\frac{26}{52} + \frac{25}{51}*\frac{26}{52} = \frac{1}{2} $ Is this correct?,This is my thought process: Is this correct?,P(2^{nd}\ \text{black}) = P(2^{nd}\ \text{black} \mid 1^{st}\ \text{red}) P(1^{st}\ \text{red}) + P(2^{nd}\ \text{black} \mid 1^{st}\ \text{black}) P(1^{st} \ \text{black})  \frac{26}{51}*\frac{26}{52} + \frac{25}{51}*\frac{26}{52} = \frac{1}{2} ,['probability']
69,Selecting $2$ cards from a full deck of cards.,Selecting  cards from a full deck of cards.,2,"I thought of a problem earlier and I am quite clueless on how to solve it, or begin solving it, because I cannot find a way to easily compute the amount of combinations of $2$ cards that sum to a certain value $x$ . Anyway, the first part of the problem is as follows We have a full deck of $52$ cards, and randomly select $2$ cards from this deck. We look at the cards and compute the sum of the values of the cards, ace being $1$ and K, Q and J being $13$ , $12$ and $11$ respectively. We then shuffle the cards back into the deck and randomly select $2$ cards once more. What is the probability that the sum of the value of these $2$ cards, is the same as the sum of the values of the first $2$ selected cards? This brought me to think of another problem, which is comparable. It is as follows Let's say we have a full deck of $52$ cards, we randomly select $2$ cards, and we do this twice, yielding $2$ sets of $2$ cards. What is the probability that the sum of the values of the cards in the first set, equals the sum of the values of the cards in the second set? Again, I'm quite confused about this problem, because I cannot think of an easy way to compute the amount of possible configurations of two cards, that sum to some value $x$ . Any help on solving these problems is appreciated. Furthermore, what would be a good guesstimate for these probabilities that could be given without any computations?","I thought of a problem earlier and I am quite clueless on how to solve it, or begin solving it, because I cannot find a way to easily compute the amount of combinations of cards that sum to a certain value . Anyway, the first part of the problem is as follows We have a full deck of cards, and randomly select cards from this deck. We look at the cards and compute the sum of the values of the cards, ace being and K, Q and J being , and respectively. We then shuffle the cards back into the deck and randomly select cards once more. What is the probability that the sum of the value of these cards, is the same as the sum of the values of the first selected cards? This brought me to think of another problem, which is comparable. It is as follows Let's say we have a full deck of cards, we randomly select cards, and we do this twice, yielding sets of cards. What is the probability that the sum of the values of the cards in the first set, equals the sum of the values of the cards in the second set? Again, I'm quite confused about this problem, because I cannot think of an easy way to compute the amount of possible configurations of two cards, that sum to some value . Any help on solving these problems is appreciated. Furthermore, what would be a good guesstimate for these probabilities that could be given without any computations?",2 x 52 2 1 13 12 11 2 2 2 52 2 2 2 x,"['probability', 'combinatorics', 'combinations', 'card-games']"
70,Tail probabilities of identically distributed variables.,Tail probabilities of identically distributed variables.,,"I'm struggling with following problem: Let $X_1, X_2, \dots $ be identically distributed (not necessarily independent) non-negative random variables with finite expected values. Show that for any $\epsilon > 0$ , $$\lim_{n \to \infty}P\left(\max_{1\le i\leq n} X_i > n\epsilon\right) = 0$$ I can easily solve it if the variables are independent (e.g. using Doob's martingale inequality), but I'm struggling to prove above without that assumption. I've tried e.g. bounding the probabilities in the following way: $$P\left(\max_{1\le i\leq n} X_i > n\epsilon\right) \leq \sum P(X_i > n\epsilon)$$ But after applying Markov's inequality the bound seems 'too loose'. I was also considering using Doob's inequality in that case as well, but I was not able to construct appropriate martingale. The exact question I'm asking is: is the theorem in question true?","I'm struggling with following problem: Let be identically distributed (not necessarily independent) non-negative random variables with finite expected values. Show that for any , I can easily solve it if the variables are independent (e.g. using Doob's martingale inequality), but I'm struggling to prove above without that assumption. I've tried e.g. bounding the probabilities in the following way: But after applying Markov's inequality the bound seems 'too loose'. I was also considering using Doob's inequality in that case as well, but I was not able to construct appropriate martingale. The exact question I'm asking is: is the theorem in question true?","X_1, X_2, \dots  \epsilon > 0 \lim_{n \to \infty}P\left(\max_{1\le i\leq n} X_i > n\epsilon\right) = 0 P\left(\max_{1\le i\leq n} X_i > n\epsilon\right) \leq \sum P(X_i > n\epsilon)","['probability', 'probability-theory', 'martingales']"
71,What will be the pdf of $X+Y$ if $X$ and $Y$ are iid from Cauchy? [duplicate],What will be the pdf of  if  and  are iid from Cauchy? [duplicate],X+Y X Y,"This question already has answers here : Proving the sum of two independent Cauchy Random Variables is Cauchy (2 answers) Closed 5 years ago . Suppose $X$ and $Y$ follow Cauchy distribution independent of each other. What will be the pdf of $X+Y$ ? What I got by using convolution theorem is that the density $g$ of $X+Y$ is $:$ $$g(x) = \int_{-\infty}^{\infty} f(y) f(x-y)\ \mathrm {dy}$$ where $f$ is the density of the Cauchy distribution given by $f(x)=\frac {1} {\pi ({1+ x^2})},x \in \Bbb R$ . Then the whole integration becomes $$\frac  {1} {\pi^2} \int_{-\infty}^{\infty} \frac {\mathrm {dy}} {(1+y^2)(1+(x-y)^2)}.$$ Now how do I solve this integral? Please help me in this regard. Thank you very much.",This question already has answers here : Proving the sum of two independent Cauchy Random Variables is Cauchy (2 answers) Closed 5 years ago . Suppose and follow Cauchy distribution independent of each other. What will be the pdf of ? What I got by using convolution theorem is that the density of is where is the density of the Cauchy distribution given by . Then the whole integration becomes Now how do I solve this integral? Please help me in this regard. Thank you very much.,"X Y X+Y g X+Y : g(x) = \int_{-\infty}^{\infty} f(y) f(x-y)\ \mathrm {dy} f f(x)=\frac {1} {\pi ({1+ x^2})},x \in \Bbb R \frac  {1} {\pi^2} \int_{-\infty}^{\infty} \frac {\mathrm {dy}} {(1+y^2)(1+(x-y)^2)}.","['probability', 'probability-theory', 'random-variables', 'independence', 'density-function']"
72,Probability of sum of N dice being above certain value X,Probability of sum of N dice being above certain value X,,"In Dnd, sometimes you have to roll n, m-sided dice (say 5, d20s) and have the sum be greater than or equal to a certain value, x (say 90). This is easy for me to calculate by brute force, for most typical examples. I simply take the total number of possibilities that meet the criteria, and divide by the total number of possibilities, by running through each combination of dice rolls.  My result for the above example is 3003 dice combinations that sum to > 90, out of 3200000 combinations in total p = 0.009384375 chance of getting 90 or over. Is there a way (e.g. an equation) to reach this value directly?","In Dnd, sometimes you have to roll n, m-sided dice (say 5, d20s) and have the sum be greater than or equal to a certain value, x (say 90). This is easy for me to calculate by brute force, for most typical examples. I simply take the total number of possibilities that meet the criteria, and divide by the total number of possibilities, by running through each combination of dice rolls.  My result for the above example is 3003 dice combinations that sum to > 90, out of 3200000 combinations in total p = 0.009384375 chance of getting 90 or over. Is there a way (e.g. an equation) to reach this value directly?",,"['probability', 'dice']"
73,What is the difference between identically distributed random variables ?,What is the difference between identically distributed random variables ?,,"I know that two random variables X and Y are identical distributed, iff $$ P(X \leq x) = P(Y \leq x) $$ for all $x \in \mathbb{R}$. Doesn't that mean, that $$ P(X = x) = P(Y = x) $$  for all $x \in \mathbb{R}$?  I can't  see,  where they could differ then. Where does   $$ P(X \leq x) = P(Y \leq x) \Rightarrow P(X = x) = P(Y = x) \Rightarrow X=Y $$ go wrong ? A counterexample would be perfect.","I know that two random variables X and Y are identical distributed, iff $$ P(X \leq x) = P(Y \leq x) $$ for all $x \in \mathbb{R}$. Doesn't that mean, that $$ P(X = x) = P(Y = x) $$  for all $x \in \mathbb{R}$?  I can't  see,  where they could differ then. Where does   $$ P(X \leq x) = P(Y \leq x) \Rightarrow P(X = x) = P(Y = x) \Rightarrow X=Y $$ go wrong ? A counterexample would be perfect.",,"['probability', 'probability-theory', 'probability-distributions']"
74,"An urn contains n red balls, n white, n black. What is the probability of not getting all colors?","An urn contains n red balls, n white, n black. What is the probability of not getting all colors?",,"I have this problem which I have been struggling with for a while now An urn contains n red balls, n white balls and n black balls. You   draw k balls at random without replacement ($k\leqq n$). Find an   expression for the probability that you do not get all colors. I tried to solve this in the following way: I note that it should be logical to think P(not getting all colours in k draws) = P(getting exactly one color only in k draws OR get exactly two different colors only in k draws). Therefore, I choose the events $A_1=\{$get one color k times$\}$ and $A_2=\{$get two colors k times$\}$ Therefore, we seek $P(A_1 \cup A_2)$. Clearly, $A_1 = \frac{{n\choose k}}{3n\choose k}$ and  $A_2 = \frac{{2n\choose k}}{3n\choose k}$. And because the both events are disjoint, we simply get $P(A_1 \cup A_2) = P(A_1) + P(A_2) = \frac{1}{3n\choose k}\big({n\choose k}+{2n\choose k}\big)$. According to my textbook, however, the answer should be $\frac{3}{3n\choose k}\big({2n\choose k}-{n\choose k}\big)$. What am I doing wrong? Are the answers equivalent because of some mystical binomial-identity?","I have this problem which I have been struggling with for a while now An urn contains n red balls, n white balls and n black balls. You   draw k balls at random without replacement ($k\leqq n$). Find an   expression for the probability that you do not get all colors. I tried to solve this in the following way: I note that it should be logical to think P(not getting all colours in k draws) = P(getting exactly one color only in k draws OR get exactly two different colors only in k draws). Therefore, I choose the events $A_1=\{$get one color k times$\}$ and $A_2=\{$get two colors k times$\}$ Therefore, we seek $P(A_1 \cup A_2)$. Clearly, $A_1 = \frac{{n\choose k}}{3n\choose k}$ and  $A_2 = \frac{{2n\choose k}}{3n\choose k}$. And because the both events are disjoint, we simply get $P(A_1 \cup A_2) = P(A_1) + P(A_2) = \frac{1}{3n\choose k}\big({n\choose k}+{2n\choose k}\big)$. According to my textbook, however, the answer should be $\frac{3}{3n\choose k}\big({2n\choose k}-{n\choose k}\big)$. What am I doing wrong? Are the answers equivalent because of some mystical binomial-identity?",,"['probability', 'combinatorics', 'probability-theory', 'statistics', 'binomial-coefficients']"
75,Construction of random variables,Construction of random variables,,A proof for the existence of a Wiener process is based on using Gaussian random variables to construct such a process with the properties we need from it. That got me thinking that I never actually learned how a random variable with a certain distribution is constructed. How does one prove that there exists $X:\Omega\rightarrow\mathbb{R}$ with $\mathbb{P}\{X\leq x\}=F(x)$ for a given $F$ ? More importantly what would $\Omega$ be in the case of usual R.V (e.g normal) and what would $X(\omega)$ represent ?,A proof for the existence of a Wiener process is based on using Gaussian random variables to construct such a process with the properties we need from it. That got me thinking that I never actually learned how a random variable with a certain distribution is constructed. How does one prove that there exists $X:\Omega\rightarrow\mathbb{R}$ with $\mathbb{P}\{X\leq x\}=F(x)$ for a given $F$ ? More importantly what would $\Omega$ be in the case of usual R.V (e.g normal) and what would $X(\omega)$ represent ?,,"['probability', 'probability-theory', 'probability-distributions']"
76,Calculating keno odds?,Calculating keno odds?,,"In keno, the casino picks 20 balls from a set of 80 numbered 1 to 80. Before the draw is over, you are allowed to choose 10 balls. What is the probability that 5 of the balls you choose will be in the 20 balls selected by the casino? My attempt: The total number of combinations for the 20 balls is $80\choose20$. However, I get stuck at the numerator. I thought it will be $\binom{80}{10}\binom{10}5$ but that's wrong. Thanks.","In keno, the casino picks 20 balls from a set of 80 numbered 1 to 80. Before the draw is over, you are allowed to choose 10 balls. What is the probability that 5 of the balls you choose will be in the 20 balls selected by the casino? My attempt: The total number of combinations for the 20 balls is $80\choose20$. However, I get stuck at the numerator. I thought it will be $\binom{80}{10}\binom{10}5$ but that's wrong. Thanks.",,['probability']
77,A counterintuitive problem in conditional probability/combinatorics,A counterintuitive problem in conditional probability/combinatorics,,"Please help me to finish/validate my solution for the following problem: Three players $A,B,C$ play a game. A game is played between two   players. After a game the winner plays against player who did not play   last time. Everyone has equal winning chance of $\frac12$. To become a   champion a player have to win 2 games in a row. Find the probabilities   of being a champion for each player, if the first game is played   between $A$ and $B$. Ok, my attempt: Let ${PL}_n$ is the probability of an event ""player $PL$ became a champion after game $n$"". Then it is easy to get that $A_1=B_1=C_1 =C_2=0,A_2=B_2=\frac14$, $C_3=\frac14$. With the probability $\frac14$ $4$-th game is played between $A$ and $B$, so the game tree with winning leaves cut off will repeat itself with a period $3$. So $A_{3n}=B_{3n}= {\frac14(\frac14)}^{n-1}={(\frac14)}^{n}$,$C_{3n+1}= {\frac14(\frac14)}^{n-1}={(\frac14)}^{n}$. Then $A_{\infty}=B_{\infty}=$ sum of infinite sequence with first term $\frac14$ and factor $\frac14$, so  $A_{\infty}=B_{\infty}=\frac13$. Since the probability the no one will will win the game after game $3n+1$ is equal to ${(\frac14)}^{n}\to0$ for large $n$, we get $C_{\infty}=1-A_{\infty}-B_{\infty}=\frac13$. I do not see any errors in my solution and I like it and believe it is correct, but the result looks counterintuitive - it looks like players $A$ and $B$ should have better chance of being a champion. Is my solution correct? Thanks a lot for your help!","Please help me to finish/validate my solution for the following problem: Three players $A,B,C$ play a game. A game is played between two   players. After a game the winner plays against player who did not play   last time. Everyone has equal winning chance of $\frac12$. To become a   champion a player have to win 2 games in a row. Find the probabilities   of being a champion for each player, if the first game is played   between $A$ and $B$. Ok, my attempt: Let ${PL}_n$ is the probability of an event ""player $PL$ became a champion after game $n$"". Then it is easy to get that $A_1=B_1=C_1 =C_2=0,A_2=B_2=\frac14$, $C_3=\frac14$. With the probability $\frac14$ $4$-th game is played between $A$ and $B$, so the game tree with winning leaves cut off will repeat itself with a period $3$. So $A_{3n}=B_{3n}= {\frac14(\frac14)}^{n-1}={(\frac14)}^{n}$,$C_{3n+1}= {\frac14(\frac14)}^{n-1}={(\frac14)}^{n}$. Then $A_{\infty}=B_{\infty}=$ sum of infinite sequence with first term $\frac14$ and factor $\frac14$, so  $A_{\infty}=B_{\infty}=\frac13$. Since the probability the no one will will win the game after game $3n+1$ is equal to ${(\frac14)}^{n}\to0$ for large $n$, we get $C_{\infty}=1-A_{\infty}-B_{\infty}=\frac13$. I do not see any errors in my solution and I like it and believe it is correct, but the result looks counterintuitive - it looks like players $A$ and $B$ should have better chance of being a champion. Is my solution correct? Thanks a lot for your help!",,"['probability', 'combinatorics']"
78,"If two people play tic tac toe choosing their moves randomly, what are the odds that they will tie? [closed]","If two people play tic tac toe choosing their moves randomly, what are the odds that they will tie? [closed]",,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question What is the probability that it is a tie game? What is the probability that X wins? What is the probability that O wins? Assume X goes first and all moves are random.,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question What is the probability that it is a tie game? What is the probability that X wins? What is the probability that O wins? Assume X goes first and all moves are random.,,"['probability', 'probability-theory']"
79,"Optimal strategy for rolling die consecutively without getting a ""1""","Optimal strategy for rolling die consecutively without getting a ""1""",,"Consider rolling a 6-sided die continuously and trying to tally as high a score as possible (the sum of all rolls).  If you roll a 1, then your turn is over and your score is 0.  So for each successful roll, the expectation value should be 4.  According to Knizia (1999), an approximately optimal strategy would be to attempt to roll to a score of 20 and then stop.  (S)he states: ""...we know the true odds of such a bet are 1 to 5.  If you ask yourself how much you should risk, you need to know how much there is to gain.....If you put 20 points at stake, this brings the odds to 4 to 20, that is 1 to 5, and makes a fair game....Whenever your accumulated points are less than 20, you should continue throwing, because the odds are in your favor. "" Don't understand this, is not rolling to 20 on average essentially rolling five times (without getting a 1)?  The probability of this happening is only about 40%.  So wouldn't the odds be about 60% that you would roll a 1 and score 0 if you always try to roll up to 20?","Consider rolling a 6-sided die continuously and trying to tally as high a score as possible (the sum of all rolls).  If you roll a 1, then your turn is over and your score is 0.  So for each successful roll, the expectation value should be 4.  According to Knizia (1999), an approximately optimal strategy would be to attempt to roll to a score of 20 and then stop.  (S)he states: ""...we know the true odds of such a bet are 1 to 5.  If you ask yourself how much you should risk, you need to know how much there is to gain.....If you put 20 points at stake, this brings the odds to 4 to 20, that is 1 to 5, and makes a fair game....Whenever your accumulated points are less than 20, you should continue throwing, because the odds are in your favor. "" Don't understand this, is not rolling to 20 on average essentially rolling five times (without getting a 1)?  The probability of this happening is only about 40%.  So wouldn't the odds be about 60% that you would roll a 1 and score 0 if you always try to roll up to 20?",,['probability']
80,What is the intuitive meaning of Expected Value?,What is the intuitive meaning of Expected Value?,,"What exactly does this number mean? I am aware on how to calculate the them given the variables. I have watched several videos and articles about it but no one seems to explain it. Maybe I am just missing something and it is just a meaningless number? I watched this example about a survey of students that rate their class overall satisfactions. 1 - very dissatisfied and 5 very satisfied. x = 1,2,3,4,5 and the count in the order of x is count - 5,10,11,44,38 = 108 After calculating the E(X) = 3.7 I noticed it is weighing more towards the very satisfied side. What exactly is this number telling us aside from being just an average?","What exactly does this number mean? I am aware on how to calculate the them given the variables. I have watched several videos and articles about it but no one seems to explain it. Maybe I am just missing something and it is just a meaningless number? I watched this example about a survey of students that rate their class overall satisfactions. 1 - very dissatisfied and 5 very satisfied. x = 1,2,3,4,5 and the count in the order of x is count - 5,10,11,44,38 = 108 After calculating the E(X) = 3.7 I noticed it is weighing more towards the very satisfied side. What exactly is this number telling us aside from being just an average?",,"['probability', 'statistics', 'statistical-inference', 'descriptive-statistics']"
81,"We deal 52 cards to 4 players, what is the probability that each player has an ace?","We deal 52 cards to 4 players, what is the probability that each player has an ace?",,"I saw on internet the answer is : $$\frac{13^4}{{52}\choose{4}} $$ but I don't intuitively understand it. So I tried another one that is : $$\frac{{52}\choose{13 \ 13 \ 13 \ 13}}{52!} \cdot 4!$$ Because we will divide 52 cards into 4 groups of 13 cards , there is 52! ways to shuffle the deck and 4! ways to order the 4 aces . But this doesn't give me a correct result..","I saw on internet the answer is : $$\frac{13^4}{{52}\choose{4}} $$ but I don't intuitively understand it. So I tried another one that is : $$\frac{{52}\choose{13 \ 13 \ 13 \ 13}}{52!} \cdot 4!$$ Because we will divide 52 cards into 4 groups of 13 cards , there is 52! ways to shuffle the deck and 4! ways to order the 4 aces . But this doesn't give me a correct result..",,"['probability', 'combinatorics', 'card-games']"
82,"Probability of two vowels from the word MATE if two letters are chosen at random, without a replacement?","Probability of two vowels from the word MATE if two letters are chosen at random, without a replacement?",,"My textbook seems to have given me an answer without explaining. It states that the answer is 1/6 but it's a four-letter word, someone please explain. :)","My textbook seems to have given me an answer without explaining. It states that the answer is 1/6 but it's a four-letter word, someone please explain. :)",,"['probability', 'combinatorics']"
83,Six men and six women are paired to dance. What is the probability each pair is wearing the same color shirt?,Six men and six women are paired to dance. What is the probability each pair is wearing the same color shirt?,,"Six men and six women are paired to dance. Two men wear red shirts, two men wear white shirts, and two men wear blue shirts. Similarly, two women wear red shirts, two women wear white shirts, and two women wear blue shirts. The men and women are paired off into couples (one man, one woman) at random. What is the probability all the couples are wearing the same color shirts? My answer is $\frac{1}{90}$. There are $6! = 720$ ways to pair the couples and for each color there are $2$ ways to pair the men and women such that partners have the same color shirt. Thus there are $2^3=8$ pairings in which all partners wear the same color shirt, and $\frac{8}{720} = \frac{1}{90}$. But my textbook says the answer is $\frac{1}{9}$. Thanks in advance.","Six men and six women are paired to dance. Two men wear red shirts, two men wear white shirts, and two men wear blue shirts. Similarly, two women wear red shirts, two women wear white shirts, and two women wear blue shirts. The men and women are paired off into couples (one man, one woman) at random. What is the probability all the couples are wearing the same color shirts? My answer is $\frac{1}{90}$. There are $6! = 720$ ways to pair the couples and for each color there are $2$ ways to pair the men and women such that partners have the same color shirt. Thus there are $2^3=8$ pairings in which all partners wear the same color shirt, and $\frac{8}{720} = \frac{1}{90}$. But my textbook says the answer is $\frac{1}{9}$. Thanks in advance.",,"['probability', 'combinatorics', 'self-learning']"
84,Unbiased estimator of the variance with known population size,Unbiased estimator of the variance with known population size,,"The variance is defined as $$\sigma^2 = \frac{\sum_{i=1}^n (x_i - \bar x)^2}{n}$$ where, $\bar x = \frac{\sum_{i=1}^n x_i}{n}$ If someone wants to estimate this parameter from a sample (s)he must do $$s^2 = \frac{\sum_{i=1}^n (x_i - \bar x)^2}{n-1}$$ as the variance (as would be calculated by $\sigma^2$) of a sample decreases with the size of the sample. $s^2$ is an unbiased estimator of $\sigma^2$ only if sampling is with replacement (which is not the case in the model of interest here) or if the population is infinite. Let's call $N$ the size of the population ($n$ being the size of the sample). To the extreme, if $n=N$ (so that every individual is sampled), then $s^2$ will definitely be a biased estimator of the variance in the population. What is an unbiased estimator of the variance of the population from a sample knowing the population size $N$?","The variance is defined as $$\sigma^2 = \frac{\sum_{i=1}^n (x_i - \bar x)^2}{n}$$ where, $\bar x = \frac{\sum_{i=1}^n x_i}{n}$ If someone wants to estimate this parameter from a sample (s)he must do $$s^2 = \frac{\sum_{i=1}^n (x_i - \bar x)^2}{n-1}$$ as the variance (as would be calculated by $\sigma^2$) of a sample decreases with the size of the sample. $s^2$ is an unbiased estimator of $\sigma^2$ only if sampling is with replacement (which is not the case in the model of interest here) or if the population is infinite. Let's call $N$ the size of the population ($n$ being the size of the sample). To the extreme, if $n=N$ (so that every individual is sampled), then $s^2$ will definitely be a biased estimator of the variance in the population. What is an unbiased estimator of the variance of the population from a sample knowing the population size $N$?",,"['probability', 'probability-theory', 'statistics', 'variance', 'parameter-estimation']"
85,What is the best algebraic proof of the Monty Hall problem (e.g.: xor(a xor { C < B or B < C }) = 1),What is the best algebraic proof of the Monty Hall problem (e.g.: xor(a xor { C < B or B < C }) = 1),,"I want to look at the Monty Hall problem as a way of measuring the host's involvement in the game.  Namely: The game show host's knowledge and action results in a change of the outcome of the game Since the host has a is nonzero effect on the game, then what is that value? Example Given 3 doors (a,b,c), solve for the most efficient & concise function of the game show host's involvement in the show m . m = A function that is the lesser of B or C a xor m = 1 or a xor  { C < B or B < C } = 1 My goal is to quantify and isolate m Question Is there any mathematical model, or proof that captures ""Monty's knowledge"" of the door's contents? Alternatively, is there a model proof that expresses the relative ""side channel"" of information that would cause a savvy person to switch? I'm asking because I think that a difference in statistical behaviors are an indicator that some variables are not accounted for in the problem. (hence common sense often fails this problem) Is there any algebraic proof, or other discipline of mathematics that would capture the data I'm seeking? Edit To make this more concrete, if a ""Montecule"" represents the if/then logic that the host goes through in order to play the game, then I want to isolate that on one side of an equals sign.  Why?  I think it can be a building block to Artificial Intelligence, and learning. The components of a 'Montecule' consist of Private knowledge of which door contains the prize A shared values system (between host and contestant) of what is most important. (typically the car) Ranking of whats less important and exposing that (decision making) It seems to me that if I can identify a 'Montecule', I can chain them together to form more complex learning and decision systems.","I want to look at the Monty Hall problem as a way of measuring the host's involvement in the game.  Namely: The game show host's knowledge and action results in a change of the outcome of the game Since the host has a is nonzero effect on the game, then what is that value? Example Given 3 doors (a,b,c), solve for the most efficient & concise function of the game show host's involvement in the show m . m = A function that is the lesser of B or C a xor m = 1 or a xor  { C < B or B < C } = 1 My goal is to quantify and isolate m Question Is there any mathematical model, or proof that captures ""Monty's knowledge"" of the door's contents? Alternatively, is there a model proof that expresses the relative ""side channel"" of information that would cause a savvy person to switch? I'm asking because I think that a difference in statistical behaviors are an indicator that some variables are not accounted for in the problem. (hence common sense often fails this problem) Is there any algebraic proof, or other discipline of mathematics that would capture the data I'm seeking? Edit To make this more concrete, if a ""Montecule"" represents the if/then logic that the host goes through in order to play the game, then I want to isolate that on one side of an equals sign.  Why?  I think it can be a building block to Artificial Intelligence, and learning. The components of a 'Montecule' consist of Private knowledge of which door contains the prize A shared values system (between host and contestant) of what is most important. (typically the car) Ranking of whats less important and exposing that (decision making) It seems to me that if I can identify a 'Montecule', I can chain them together to form more complex learning and decision systems.",,"['probability', 'proof-writing', 'mathematical-modeling', 'monty-hall']"
86,"What is the chance of picking y in a set of x objects, given x chances to pick at random?","What is the chance of picking y in a set of x objects, given x chances to pick at random?",,"Suppose you have a set of x objects. In it is an object y. Suppose you pick at random one object from this set. This set is uniformly distributed. There is a 1 / x chance of picking y. Let's say that you pick x times from the set, then eliminating it from the set. This means there is a 100% chance of picking y. But, let's say that after you picked an object from this set, it is not eliminated. What is the probability of picking y in that case? Would this (Link 1) apply? No, because it presumes you leave the marbles out of the bag, which is not what I mean. That would mean that logically scaling it up, there would be a 100% chance of picking object y, which I know not to be true. Or, would this (Link 2) apply? To simplify things, let's use an example. We have a bag with 10 marbles. 9 of them are white, and one is black. You pick one marble at a time at random, then drop it back in. If you do this 3 times, according logically, this would yield a 3/10 chance of picking the black marble. Now, suppose we scale this up to picking 10 marbles. At a quick glance, a 100% chance would be the logical answer, but if you think about it longer, you can pick the same marble more than once. So what is the probability, in this case, of picking the black marble? Link 1: Probability: best chance of picking a desired marble out of 10 Link 2: Picking a uniformly at random element from a random set","Suppose you have a set of x objects. In it is an object y. Suppose you pick at random one object from this set. This set is uniformly distributed. There is a 1 / x chance of picking y. Let's say that you pick x times from the set, then eliminating it from the set. This means there is a 100% chance of picking y. But, let's say that after you picked an object from this set, it is not eliminated. What is the probability of picking y in that case? Would this (Link 1) apply? No, because it presumes you leave the marbles out of the bag, which is not what I mean. That would mean that logically scaling it up, there would be a 100% chance of picking object y, which I know not to be true. Or, would this (Link 2) apply? To simplify things, let's use an example. We have a bag with 10 marbles. 9 of them are white, and one is black. You pick one marble at a time at random, then drop it back in. If you do this 3 times, according logically, this would yield a 3/10 chance of picking the black marble. Now, suppose we scale this up to picking 10 marbles. At a quick glance, a 100% chance would be the logical answer, but if you think about it longer, you can pick the same marble more than once. So what is the probability, in this case, of picking the black marble? Link 1: Probability: best chance of picking a desired marble out of 10 Link 2: Picking a uniformly at random element from a random set",,['probability']
87,"If the expected value of $X^n$ is $n!$, what is the probability density function of the random variable $X$?","If the expected value of  is , what is the probability density function of the random variable ?",X^n n! X,"I am working through my homework and this problem has me stumped. I don't know how  to come up with a pdf just by being given an expected value? We are learning about exponential distributions, but this detail isn't stated. Is that because simply the fact that the function is $X^n$ implies it's an exponential distribution? I am also wondering if it has to do with the gamma function because I know that $$E[X^s] = \frac{\Gamma(s+1)}{\gamma^s}.$$ Any direction at all would be greatly appreciated as I am thoroughly confused.","I am working through my homework and this problem has me stumped. I don't know how  to come up with a pdf just by being given an expected value? We are learning about exponential distributions, but this detail isn't stated. Is that because simply the fact that the function is $X^n$ implies it's an exponential distribution? I am also wondering if it has to do with the gamma function because I know that $$E[X^s] = \frac{\Gamma(s+1)}{\gamma^s}.$$ Any direction at all would be greatly appreciated as I am thoroughly confused.",,"['probability', 'statistics', 'probability-distributions', 'gamma-function', 'exponential-distribution']"
88,The conditional expectation of an almost surely positive random variable,The conditional expectation of an almost surely positive random variable,,"I am trying to prove this claim. Short version: Let $\ X$ be an almost surely positive random variable (i.e. $\ X > 0$ a.s.) defined on the probability space $\ (\Omega, \mathcal G, P)$. Let $\mathcal F$ be a sub $\sigma$-algebra of $\mathcal G$, then  $\ Y =  E[X|\mathcal F] > 0$ a.s. Long version: Let $\mathcal F(t), 0\le t \le T, $ be a filtration. Define $\ V(t) =  E[V(T)\ exp{(-\int_t^T R(u)du)}\ |\mathcal F(t)]$, and assume $\ V(T)$ is almost surely positive, $\ R(t)$ is an adapted process, We are asked to show that $\ V(t)$ is almost surely positive. If one defines $\ X = V(T)\ exp{(-\int_t^T R(u)du)} $, and given that $\ V(T)$ and $\ exp{(-\int_t^T R(u)du)}$ are almost surely positive random variables, we obtain the short version.","I am trying to prove this claim. Short version: Let $\ X$ be an almost surely positive random variable (i.e. $\ X > 0$ a.s.) defined on the probability space $\ (\Omega, \mathcal G, P)$. Let $\mathcal F$ be a sub $\sigma$-algebra of $\mathcal G$, then  $\ Y =  E[X|\mathcal F] > 0$ a.s. Long version: Let $\mathcal F(t), 0\le t \le T, $ be a filtration. Define $\ V(t) =  E[V(T)\ exp{(-\int_t^T R(u)du)}\ |\mathcal F(t)]$, and assume $\ V(T)$ is almost surely positive, $\ R(t)$ is an adapted process, We are asked to show that $\ V(t)$ is almost surely positive. If one defines $\ X = V(T)\ exp{(-\int_t^T R(u)du)} $, and given that $\ V(T)$ and $\ exp{(-\int_t^T R(u)du)}$ are almost surely positive random variables, we obtain the short version.",,"['probability', 'probability-theory', 'stochastic-calculus', 'conditional-expectation']"
89,Poisson process and probabilities,Poisson process and probabilities,,"Let $\{X(t); t\ge 0\}$ be a Poisson process with rate $\lambda =2$. Find the probability $\Pr\{X(1)=1, X(2)=3\}$ And here is my solution: As there is a Poisson process then the intervals are independent random variables thus $\Pr\{X(1)=1, X(2)=3\}$=$\Pr\{X(1)=1\}$$\Pr\{ X(2)=3\}$=$\frac{2e^{-2}}{1!} \frac{[2(2)]^3e^{-4}}{3!} =\frac{e^{-6}4^3}{3}$ But the book's answer is $4e^{-4}$. I don't see where is my mistake. Can someone tell me?","Let $\{X(t); t\ge 0\}$ be a Poisson process with rate $\lambda =2$. Find the probability $\Pr\{X(1)=1, X(2)=3\}$ And here is my solution: As there is a Poisson process then the intervals are independent random variables thus $\Pr\{X(1)=1, X(2)=3\}$=$\Pr\{X(1)=1\}$$\Pr\{ X(2)=3\}$=$\frac{2e^{-2}}{1!} \frac{[2(2)]^3e^{-4}}{3!} =\frac{e^{-6}4^3}{3}$ But the book's answer is $4e^{-4}$. I don't see where is my mistake. Can someone tell me?",,"['probability', 'statistics', 'stochastic-processes', 'poisson-distribution']"
90,Applications of the CLT for the Sample Mean,Applications of the CLT for the Sample Mean,,"Related to Confusion of central limit theory , and the fact that I just finished my first course in (Master's-level) graduate-level probability, which relates to this material. The Central Limit Theorem states that if you have an iid sample $X_1, \dots, X_n$ with mean $\mu$ and variance $\sigma^2<\infty$, denoting $\bar{X}_n = \dfrac{1}{n}\sum_{i=1}^{n}X_i$, we have $$\sqrt{n}(\bar{X}_n - \mu) \overset{d}{\to}\mathcal{N}(0, \sigma^2)$$ as $n \to \infty$. By Slutsky's theorem, since $\sigma = \sqrt{\sigma^2}$ is constant (let's assume in addition $\sigma \neq 0$), obviously $\sigma \overset{p}{\to}\sigma$, hence  $$\dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}\overset{d}{\to}\dfrac{1}{\sigma}\cdot\mathcal{N}(0, \sigma^2) = \mathcal{N}(0, 1)$$ as $n \to \infty$. This justifies (to me) what is commonly what is done in intro stats classes: basically, if $n \geq 30$, if you want to, say, find  $$\mathbb{P}(a \leq \bar{X}_n \leq b)$$ where $a$ and $b$ are usually finite, the idea is that when you standardize it as follows: $$\mathbb{P}(a \leq \bar{X}_n \leq b)\approx\mathbb{P}\left(\dfrac{a-\mu}{\sigma/\sqrt{n}} \leq \dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} \leq \dfrac{b-\mu}{\sigma/\sqrt{n}}\right)$$ you can approximate $$\dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}$$ to be a $\mathcal{N}(0, 1)$ random variable if $n$ is ""large enough;"" the standard usually being $30$. Now the question I have: this implies, then, that we can't necessarily assume $$\bar{X}_n\overset{d}{\to}\mathcal{N}\left(\mu, \dfrac{\sigma^2}{n}\right)$$ as $n \to \infty$. Is it correct that this isn't true? For one thing, this makes no sense, as $n$ is still showing up in the normal distribution (in the variance) as $n \to \infty$. Obviously, Slutsky's theorem will not work (as far as I can tell). But this seems to be contradicted by a select few websites: https://onlinecourses.science.psu.edu/stat800/node/36 http://onlinestatbook.com/2/sampling_distributions/samp_dist_mean.html What am I missing? Edit : The reason why I believe Slutsky's Theorem will not work is as follows: denote $Y_n = \dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}$ and let $F_{Z}$ denote the CDF of $Z \sim \mathcal{N}(0, 1)$. Then for all $y \in \mathbb{R}$ for which $F_{Y_n}$ is continuous (notice, particularly, that $y$ is a constant), $$\lim_{n \to \infty}F_{Y_n}(y) = F_{Z}(y)$$ but $$F_{\bar{X}_n}(x) = \mathbb{P}(\bar{X}_n \leq x) = \mathbb{P}\left(\dfrac{\sigma Y_n}{\sqrt{n}}+\mu \leq x\right) = \mathbb{P}\left(Y_n\leq\dfrac{x-\mu}{\sigma/\sqrt{n}}\right) = F_{Y_n}\left(\dfrac{x-\mu}{\sigma/\sqrt{n}}\right)\text{.}$$ Unfortunately, the argument $\dfrac{x-\mu}{\sigma/\sqrt{n}}$ is dependent on $n$, so Slutsky's Theorem won't help.","Related to Confusion of central limit theory , and the fact that I just finished my first course in (Master's-level) graduate-level probability, which relates to this material. The Central Limit Theorem states that if you have an iid sample $X_1, \dots, X_n$ with mean $\mu$ and variance $\sigma^2<\infty$, denoting $\bar{X}_n = \dfrac{1}{n}\sum_{i=1}^{n}X_i$, we have $$\sqrt{n}(\bar{X}_n - \mu) \overset{d}{\to}\mathcal{N}(0, \sigma^2)$$ as $n \to \infty$. By Slutsky's theorem, since $\sigma = \sqrt{\sigma^2}$ is constant (let's assume in addition $\sigma \neq 0$), obviously $\sigma \overset{p}{\to}\sigma$, hence  $$\dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}\overset{d}{\to}\dfrac{1}{\sigma}\cdot\mathcal{N}(0, \sigma^2) = \mathcal{N}(0, 1)$$ as $n \to \infty$. This justifies (to me) what is commonly what is done in intro stats classes: basically, if $n \geq 30$, if you want to, say, find  $$\mathbb{P}(a \leq \bar{X}_n \leq b)$$ where $a$ and $b$ are usually finite, the idea is that when you standardize it as follows: $$\mathbb{P}(a \leq \bar{X}_n \leq b)\approx\mathbb{P}\left(\dfrac{a-\mu}{\sigma/\sqrt{n}} \leq \dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} \leq \dfrac{b-\mu}{\sigma/\sqrt{n}}\right)$$ you can approximate $$\dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}$$ to be a $\mathcal{N}(0, 1)$ random variable if $n$ is ""large enough;"" the standard usually being $30$. Now the question I have: this implies, then, that we can't necessarily assume $$\bar{X}_n\overset{d}{\to}\mathcal{N}\left(\mu, \dfrac{\sigma^2}{n}\right)$$ as $n \to \infty$. Is it correct that this isn't true? For one thing, this makes no sense, as $n$ is still showing up in the normal distribution (in the variance) as $n \to \infty$. Obviously, Slutsky's theorem will not work (as far as I can tell). But this seems to be contradicted by a select few websites: https://onlinecourses.science.psu.edu/stat800/node/36 http://onlinestatbook.com/2/sampling_distributions/samp_dist_mean.html What am I missing? Edit : The reason why I believe Slutsky's Theorem will not work is as follows: denote $Y_n = \dfrac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}$ and let $F_{Z}$ denote the CDF of $Z \sim \mathcal{N}(0, 1)$. Then for all $y \in \mathbb{R}$ for which $F_{Y_n}$ is continuous (notice, particularly, that $y$ is a constant), $$\lim_{n \to \infty}F_{Y_n}(y) = F_{Z}(y)$$ but $$F_{\bar{X}_n}(x) = \mathbb{P}(\bar{X}_n \leq x) = \mathbb{P}\left(\dfrac{\sigma Y_n}{\sqrt{n}}+\mu \leq x\right) = \mathbb{P}\left(Y_n\leq\dfrac{x-\mu}{\sigma/\sqrt{n}}\right) = F_{Y_n}\left(\dfrac{x-\mu}{\sigma/\sqrt{n}}\right)\text{.}$$ Unfortunately, the argument $\dfrac{x-\mu}{\sigma/\sqrt{n}}$ is dependent on $n$, so Slutsky's Theorem won't help.",,"['probability', 'probability-theory', 'statistics', 'central-limit-theorem']"
91,Show that the random variables $Y_1$ and $Y_2$ are independent,Show that the random variables  and  are independent,Y_1 Y_2,"Let $X_1,X_2$ be i.i.d with pdf   $$f_X(x)=\begin{cases} e^{-x} & \text{for } 0< x<\infty{} \\0 & \text{elsewhere } \end{cases}$$   Show that the random variables $Y_1$ and $Y_2$ with $Y_1=X_1+X_2$ and $Y_2=\frac{X_1}{X_1+X_2}$ are independent. I know that for $Y_1$ and $Y_2$ to be independent. $P(Y_1\cap Y_2)=P(Y_1)P(Y_2)$.","Let $X_1,X_2$ be i.i.d with pdf   $$f_X(x)=\begin{cases} e^{-x} & \text{for } 0< x<\infty{} \\0 & \text{elsewhere } \end{cases}$$   Show that the random variables $Y_1$ and $Y_2$ with $Y_1=X_1+X_2$ and $Y_2=\frac{X_1}{X_1+X_2}$ are independent. I know that for $Y_1$ and $Y_2$ to be independent. $P(Y_1\cap Y_2)=P(Y_1)P(Y_2)$.",,"['probability', 'statistics', 'probability-distributions', 'random-variables', 'independence']"
92,Continuous function keeps the convergence in distribution,Continuous function keeps the convergence in distribution,,"Let $(X_n)_{n\in \mathbb{N}}$ be a sequence of real random variables and $X_n\to X$ in distribution. If $f$ is a contiuous function, then $f(X_n)\to f(X)$ in distribution. How do I prove this? Is this correct: let $f:\mathbb{R}\to \mathbb{R^+}$ then  $$\mathbb{E}(f(X_n))=\underbrace{\int f(x_n)P(X_n\geq x)}_{\text{is this correct?}}\xrightarrow{(d)}\int f(x)P(X\geq x)= \mathbb{E}(f(X))$$","Let $(X_n)_{n\in \mathbb{N}}$ be a sequence of real random variables and $X_n\to X$ in distribution. If $f$ is a contiuous function, then $f(X_n)\to f(X)$ in distribution. How do I prove this? Is this correct: let $f:\mathbb{R}\to \mathbb{R^+}$ then  $$\mathbb{E}(f(X_n))=\underbrace{\int f(x_n)P(X_n\geq x)}_{\text{is this correct?}}\xrightarrow{(d)}\int f(x)P(X\geq x)= \mathbb{E}(f(X))$$",,"['probability', 'probability-theory', 'probability-distributions']"
93,"Events in a measure preserving system satisfying $\mu (A \cap T^{-n}B) = \mu(A)\mu(B)$ for all $n$ large imply $\mu(A) \in \{0,1\}$",Events in a measure preserving system satisfying  for all  large imply,"\mu (A \cap T^{-n}B) = \mu(A)\mu(B) n \mu(A) \in \{0,1\}","Let $(X, \mathscr B_X, \mu, T)$ be a measure-preserving system such that the condition in the title is satisfied for all $n$ larger than $N \in \Bbb N$ . How can we conclude that $A$ is trivial? Any help\hints are appreciated.",Let be a measure-preserving system such that the condition in the title is satisfied for all larger than . How can we conclude that is trivial? Any help\hints are appreciated.,"(X, \mathscr B_X, \mu, T) n N \in \Bbb N A","['probability', 'ergodic-theory']"
94,Probability in coin flip,Probability in coin flip,,"The question: Two persons $A$, $B$ simultaneously toss their individual coins, and win $1$ point if head is face up and $0$ points if tails is face up. The probability that the points of $A$ exceeds the points of $B$ after $3$ tosses is... My attempt: Because each person have $4$ available options of how many points they will have in the end $(0,1,2,$ and $3)$, the total amount of ways the score could be after $3$ tosses would be $4 \cdot 4 = 16$. The cases in which person $A$ wins would be $(1,0)$, $(2,0)$, $(2,1)$, $(3,0)$, $(3,1)$, and $(3,2)$. So the answer should be $\frac{6}{16}$ or $\frac{3}{8}$. The actual answer is $\frac{11}{32}$ My question: Where did I go wrong and how do I do it correctly? Thank you!","The question: Two persons $A$, $B$ simultaneously toss their individual coins, and win $1$ point if head is face up and $0$ points if tails is face up. The probability that the points of $A$ exceeds the points of $B$ after $3$ tosses is... My attempt: Because each person have $4$ available options of how many points they will have in the end $(0,1,2,$ and $3)$, the total amount of ways the score could be after $3$ tosses would be $4 \cdot 4 = 16$. The cases in which person $A$ wins would be $(1,0)$, $(2,0)$, $(2,1)$, $(3,0)$, $(3,1)$, and $(3,2)$. So the answer should be $\frac{6}{16}$ or $\frac{3}{8}$. The actual answer is $\frac{11}{32}$ My question: Where did I go wrong and how do I do it correctly? Thank you!",,['probability']
95,what is the conditional probability that the card following it is the ace of spades?,what is the conditional probability that the card following it is the ace of spades?,,"i have seen a couple of different answers for this question, but i still cant understand why. Suppose that an ordinary deck of 52 cards is shufﬂed and the cards are then turned over one at a time until the ﬁrst ace appears. Given that the ﬁrst ace is the 20th card to appear, what is the conditional probability that the card following it is the ace of spades? this is what i was trying. \begin{equation*} \begin{aligned} P(\text{following is the ace of spades} | \text{first ace is the 20th card})  & = \dfrac{P(\text{following is the ace of spades} \cap \text{first ace is the 20th card})}{P(\text{first ace is the 20th card})} \\ & = \dfrac{\dfrac{4C1}{32C1}\times\dfrac{3C1}{31C1}}{\dfrac{4C1}{32C1}} \\ & =\dfrac{\dfrac{4!/3!}{32!/31!}\times\dfrac{3!/2!}{31!/30!}}{\dfrac{4!/3!}{32!/31!}} \end{aligned} \end{equation*}","i have seen a couple of different answers for this question, but i still cant understand why. Suppose that an ordinary deck of 52 cards is shufﬂed and the cards are then turned over one at a time until the ﬁrst ace appears. Given that the ﬁrst ace is the 20th card to appear, what is the conditional probability that the card following it is the ace of spades? this is what i was trying.","\begin{equation*}
\begin{aligned}
P(\text{following is the ace of spades} | \text{first ace is the 20th card}) 
& = \dfrac{P(\text{following is the ace of spades} \cap \text{first ace is the 20th card})}{P(\text{first ace is the 20th card})} \\
& = \dfrac{\dfrac{4C1}{32C1}\times\dfrac{3C1}{31C1}}{\dfrac{4C1}{32C1}} \\
& =\dfrac{\dfrac{4!/3!}{32!/31!}\times\dfrac{3!/2!}{31!/30!}}{\dfrac{4!/3!}{32!/31!}}
\end{aligned}
\end{equation*}",['probability']
96,"Find the probability of getting one diamond and one spade in a five-card hand, using binomial coefficients.","Find the probability of getting one diamond and one spade in a five-card hand, using binomial coefficients.",,A five card hand is dealt at random from a standard $52$ card deck. Let $X = \text{# spades}$ and $Y = \text{# diamonds}$ . Find $P(X = 1\text{ and }Y =1)$ . Leave your answer as a ratio of products of binomial coefficients. Image. Please help me with this question. I don't know how to apply the binomial coefficient in to this question. My attempt would be: $ ^{52}C_5 \times^{13}C_1\times^{13}C_1$ But I know for sure that this is not the right answer. Could you please help me out?,A five card hand is dealt at random from a standard card deck. Let and . Find . Leave your answer as a ratio of products of binomial coefficients. Image. Please help me with this question. I don't know how to apply the binomial coefficient in to this question. My attempt would be: But I know for sure that this is not the right answer. Could you please help me out?,52 X = \text{# spades} Y = \text{# diamonds} P(X = 1\text{ and }Y =1)  ^{52}C_5 \times^{13}C_1\times^{13}C_1,"['probability', 'binomial-coefficients']"
97,Probability that $5$ or $6$ are rolled $k$ times after $12$ rolls,Probability that  or  are rolled  times after  rolls,5 6 k 12,"Suppose you roll a fair dice $12$ times in a row. What is the probability of the event ""exactly $k$ of the rolls are a $5$ or a $6$"" ? I'm just asking for some verification of my counting. Let $X$ be the random variable that counts the number of $5$ and $6$ rolled. $$\begin{align}\displaystyle P(X=k)&=P\left((X=k)\bigcap \left(\bigcup_{i=0}^k \text{5 rolled $i$ times}\right)\right)\\&=\sum_{i=0}^kp\left((\text{5 rolled $i$ times})\cap (\text{6 rolled $k-i$ times}) \right)\\&=\sum_{i=0}^k \frac{\binom{12}{i}\binom{12-i}{k-i}}{6^{12}}=\frac1{6^{12}}\binom{12}{k}2^k \end{align}$$ Is that right ? I think I'm supposed to find some Binomial distribution, so I must be wrong.","Suppose you roll a fair dice $12$ times in a row. What is the probability of the event ""exactly $k$ of the rolls are a $5$ or a $6$"" ? I'm just asking for some verification of my counting. Let $X$ be the random variable that counts the number of $5$ and $6$ rolled. $$\begin{align}\displaystyle P(X=k)&=P\left((X=k)\bigcap \left(\bigcup_{i=0}^k \text{5 rolled $i$ times}\right)\right)\\&=\sum_{i=0}^kp\left((\text{5 rolled $i$ times})\cap (\text{6 rolled $k-i$ times}) \right)\\&=\sum_{i=0}^k \frac{\binom{12}{i}\binom{12-i}{k-i}}{6^{12}}=\frac1{6^{12}}\binom{12}{k}2^k \end{align}$$ Is that right ? I think I'm supposed to find some Binomial distribution, so I must be wrong.",,"['probability', 'combinatorics']"
98,What is the probability that a unit disk centered at a random point $P$ has exactly two lattice points in its interior?,What is the probability that a unit disk centered at a random point  has exactly two lattice points in its interior?,P,"A point $P$ is chosen at random in the coordinate plane.  What is the probability that the unit disk with center $P$ contains exactly two lattice points in its interior? In short I've been trying to wrap my head around this problem but I have not been able to produce anything of value. Below I provide my thinking: In the Cartesian plane we'll use grid lines as reference points for our coordinate system (each integer is represented by the intersection of two grid lines). As you can see in the image above (I just worked on first quadrant for sake of simplicity), we can achieve our scope if and only if the point $P$ lies exactly on any grid line but without being on any crossroads or exactly strictly below any vertical line or ""strictly"" to the left or right of any horizontal grid line. (I know, I am abusing the meaning of the word ""strictly"".)","A point $P$ is chosen at random in the coordinate plane.  What is the probability that the unit disk with center $P$ contains exactly two lattice points in its interior? In short I've been trying to wrap my head around this problem but I have not been able to produce anything of value. Below I provide my thinking: In the Cartesian plane we'll use grid lines as reference points for our coordinate system (each integer is represented by the intersection of two grid lines). As you can see in the image above (I just worked on first quadrant for sake of simplicity), we can achieve our scope if and only if the point $P$ lies exactly on any grid line but without being on any crossroads or exactly strictly below any vertical line or ""strictly"" to the left or right of any horizontal grid line. (I know, I am abusing the meaning of the word ""strictly"".)",,"['probability', 'geometry']"
99,Variance of Negative Binomial Distribution (without Moment Generating Series),Variance of Negative Binomial Distribution (without Moment Generating Series),,"Given the discrete probability distribution for the negative binomial distribution in the form $$P(X = r) = \sum_{n\geq r} {n-1\choose r-1} (1-p)^{n-r}p^r$$ It appears there are no derivations on the entire www of the variance formula $V(X) = \frac{r(1-p)}{p^2}$ that do not make use of the moment generating function. I have successfully managed to compute the mean without this as follows; \begin{align*} \mu = \sum_{n\geq r} n{n-1\choose r-1} (1-p)^{n-r}p^r  &= \sum_{n\geq r} \frac{n(n-1)!}{(r-1)!(n-r)!}(1-p)^{n-r}p^r \\ &= \frac{r}{p} \sum_{n\geq r} \frac{n!}{r!(n-r)!}(1-p)^{n-r} p^{r+1}\\ \end{align*} Having already factored our claimed mean of $r/p$, it remains to show that $\sum_{n\geq r} \frac{n!}{r!(n-r)!}(1-p)^{n-r} p^{r+1} = 1$ which is done by reindexing (both $r$ and $n$) and realizing this as the sum of a probability mass function for a negative binomial distribution. Indeed, letting $k = r+1$ followed by $m = n+1$, we find \begin{align*} \sum_{n\geq r} \frac{n!}{r!(n-r)!}(1-p)^{n-r} p^{r+1} &= \sum_{n\geq k-1}\frac{n!}{(k-1)!(n-k+1)!}(1-p)^{n-k+1}p^k\\ &=  \sum_{m\geq k}\frac{(m-1)!}{(k-1)!(m-k)!}(1-p)^{m-k}p^k\\ &=  \sum_{m\geq k}{m-1\choose k-1}(1-p)^{m-k}p^k  = 1 \end{align*} Does anyone know of a way to demonstrate that $\sigma^2 = V(X) = \frac{r(1-p)}{p^2}$ in this fashion?","Given the discrete probability distribution for the negative binomial distribution in the form $$P(X = r) = \sum_{n\geq r} {n-1\choose r-1} (1-p)^{n-r}p^r$$ It appears there are no derivations on the entire www of the variance formula $V(X) = \frac{r(1-p)}{p^2}$ that do not make use of the moment generating function. I have successfully managed to compute the mean without this as follows; \begin{align*} \mu = \sum_{n\geq r} n{n-1\choose r-1} (1-p)^{n-r}p^r  &= \sum_{n\geq r} \frac{n(n-1)!}{(r-1)!(n-r)!}(1-p)^{n-r}p^r \\ &= \frac{r}{p} \sum_{n\geq r} \frac{n!}{r!(n-r)!}(1-p)^{n-r} p^{r+1}\\ \end{align*} Having already factored our claimed mean of $r/p$, it remains to show that $\sum_{n\geq r} \frac{n!}{r!(n-r)!}(1-p)^{n-r} p^{r+1} = 1$ which is done by reindexing (both $r$ and $n$) and realizing this as the sum of a probability mass function for a negative binomial distribution. Indeed, letting $k = r+1$ followed by $m = n+1$, we find \begin{align*} \sum_{n\geq r} \frac{n!}{r!(n-r)!}(1-p)^{n-r} p^{r+1} &= \sum_{n\geq k-1}\frac{n!}{(k-1)!(n-k+1)!}(1-p)^{n-k+1}p^k\\ &=  \sum_{m\geq k}\frac{(m-1)!}{(k-1)!(m-k)!}(1-p)^{m-k}p^k\\ &=  \sum_{m\geq k}{m-1\choose k-1}(1-p)^{m-k}p^k  = 1 \end{align*} Does anyone know of a way to demonstrate that $\sigma^2 = V(X) = \frac{r(1-p)}{p^2}$ in this fashion?",,"['probability', 'probability-distributions', 'variance', 'negative-binomial']"
