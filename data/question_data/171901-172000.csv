,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Calculate size and power of a given PMF,Calculate size and power of a given PMF,,"Let $X$ be a random variable having probability mass function $f(x) = \begin{cases} \dfrac{2+4a_1+a_2}{6},  & \text{if $x=1$} \\ \dfrac{2-2a_1+a_2}{6}, & \text{if $x=2$} \\ \dfrac{1-a_1-a_2}{3}, & \text{if $x=3$} \end{cases}$ where $a_1>0$ and $a_2>0$ are unknown parameters such that $a_1+a_2\leq 1$. For testing the null hypothesis $H_0:a_1+a_2=1$, against the alternative hypothesis $H_1:a_1=a_2=0$, suppose that the critical region is $C=\{2,3\}$. Then calculate the size and power for the critical region. Power=$1-\beta$ where $\beta=P(\text{accept }H_0\mid H_1\text{ is true})=\dfrac{2+4a_1+a_2}{6}=\dfrac{1}{3}$ So Power = 2/3 Now, size $= P(\text{reject }H_0\mid H_0\text{ is true})=\text{critical region} = \dfrac{2-2a_1+a_2}{6}+\dfrac{1-a_1-a_2}{3}$. So, how do I calculate a numerical value here ? Please advise.","Let $X$ be a random variable having probability mass function $f(x) = \begin{cases} \dfrac{2+4a_1+a_2}{6},  & \text{if $x=1$} \\ \dfrac{2-2a_1+a_2}{6}, & \text{if $x=2$} \\ \dfrac{1-a_1-a_2}{3}, & \text{if $x=3$} \end{cases}$ where $a_1>0$ and $a_2>0$ are unknown parameters such that $a_1+a_2\leq 1$. For testing the null hypothesis $H_0:a_1+a_2=1$, against the alternative hypothesis $H_1:a_1=a_2=0$, suppose that the critical region is $C=\{2,3\}$. Then calculate the size and power for the critical region. Power=$1-\beta$ where $\beta=P(\text{accept }H_0\mid H_1\text{ is true})=\dfrac{2+4a_1+a_2}{6}=\dfrac{1}{3}$ So Power = 2/3 Now, size $= P(\text{reject }H_0\mid H_0\text{ is true})=\text{critical region} = \dfrac{2-2a_1+a_2}{6}+\dfrac{1-a_1-a_2}{3}$. So, how do I calculate a numerical value here ? Please advise.",,"['statistics', 'statistical-inference', 'hypothesis-testing']"
1,Prove convergence in distribution,Prove convergence in distribution,,"I need help with the following problem. Let $X_{n1}, X_{n2}, . . . , X_{nn}$ be independent random variables, with the same distribution as follows. Let for k = 1, 2, . . . , n och n = 1, 2, . . . , $$P(X_{nk} = 0) = 1 − \frac{2}{n} − \frac{4}{n^3}$$ $$P(X_{nk} = 1) = \frac{2}{n}$$ $$P(X_{nk} = 2) = \frac{4}{n^3}$$ and $S_n =\sum^n_{k=1} X_{nk}$. Show that $Sn → P o(λ)$ when $n → ∞$ and determine $λ$. I was thinking of using $G_{s_n}(t)=G_N(G_X(t))$ I got that $G_X(t)=1-\frac{2}{n}(1+t)+\frac{4}{n^3}(t^2-1)$ I don't know if this is the correct approach and if it is I don't know how to continue from here. How do I then find $G_N(t)$ Anyone know? Thanks!","I need help with the following problem. Let $X_{n1}, X_{n2}, . . . , X_{nn}$ be independent random variables, with the same distribution as follows. Let for k = 1, 2, . . . , n och n = 1, 2, . . . , $$P(X_{nk} = 0) = 1 − \frac{2}{n} − \frac{4}{n^3}$$ $$P(X_{nk} = 1) = \frac{2}{n}$$ $$P(X_{nk} = 2) = \frac{4}{n^3}$$ and $S_n =\sum^n_{k=1} X_{nk}$. Show that $Sn → P o(λ)$ when $n → ∞$ and determine $λ$. I was thinking of using $G_{s_n}(t)=G_N(G_X(t))$ I got that $G_X(t)=1-\frac{2}{n}(1+t)+\frac{4}{n^3}(t^2-1)$ I don't know if this is the correct approach and if it is I don't know how to continue from here. How do I then find $G_N(t)$ Anyone know? Thanks!",,"['probability', 'statistics', 'probability-theory', 'convergence-divergence']"
2,Checking the consistency and Bias of $\frac{\sum X_i +\sqrt{n}/2}{n+\sqrt{n}}$,Checking the consistency and Bias of,\frac{\sum X_i +\sqrt{n}/2}{n+\sqrt{n}},"Let $X_1,\ldots,X_n$ be i.i.d. $B(1,\theta)$ random variables, $0<\theta<1$. Then, as an estimator $\theta$, check if $T(X_1,\ldots,X_n)= \dfrac{\sum_{i=1}^n X_i +\sqrt{n}/2}{n+\sqrt{n}}$ is consistent and/or unbiased. $$T=\frac{\frac{1}{n}\sum_{i=1}^n X_i +\frac{1}{2\sqrt{n}}}{1+\frac{1}{\sqrt{n}}}$$ $$T=\frac{\bar{X} +\frac{1}{2\sqrt{n}}}{1+\frac{1}{\sqrt{n}}}$$ $$E(T)=\frac{E(\bar{X} +\frac{1}{2\sqrt{n}})}{1+\frac{1}{\sqrt{n}}}=\dfrac{\theta +\frac{1}{2\sqrt{n}}}{1+\frac{1}{\sqrt{n}}}.$$ So, $T$ is biased. Consistency: $\lim\limits_{n \to\infty}E(T)=\lim\limits_{n \to\infty}\dfrac{E(\theta +\frac{1}{2\sqrt{n}})}{1+\frac{1}{\sqrt{n}}}$ So $T$ is consistent. But The given answer is ""neither unbiased nor consistent"" Where did I go wrong ? Please advise.","Let $X_1,\ldots,X_n$ be i.i.d. $B(1,\theta)$ random variables, $0<\theta<1$. Then, as an estimator $\theta$, check if $T(X_1,\ldots,X_n)= \dfrac{\sum_{i=1}^n X_i +\sqrt{n}/2}{n+\sqrt{n}}$ is consistent and/or unbiased. $$T=\frac{\frac{1}{n}\sum_{i=1}^n X_i +\frac{1}{2\sqrt{n}}}{1+\frac{1}{\sqrt{n}}}$$ $$T=\frac{\bar{X} +\frac{1}{2\sqrt{n}}}{1+\frac{1}{\sqrt{n}}}$$ $$E(T)=\frac{E(\bar{X} +\frac{1}{2\sqrt{n}})}{1+\frac{1}{\sqrt{n}}}=\dfrac{\theta +\frac{1}{2\sqrt{n}}}{1+\frac{1}{\sqrt{n}}}.$$ So, $T$ is biased. Consistency: $\lim\limits_{n \to\infty}E(T)=\lim\limits_{n \to\infty}\dfrac{E(\theta +\frac{1}{2\sqrt{n}})}{1+\frac{1}{\sqrt{n}}}$ So $T$ is consistent. But The given answer is ""neither unbiased nor consistent"" Where did I go wrong ? Please advise.",,"['statistics', 'statistical-inference', 'estimation']"
3,Why is the $0$th percentile of the standard normal distribution $-\infty$?,Why is the th percentile of the standard normal distribution ?,0 -\infty,Why is the $0$th percentile of the standard normal distribution $-\infty$? I can't explain the cause except saying there is no area under the curve. So it goes beyond the bell-shaped curve.,Why is the $0$th percentile of the standard normal distribution $-\infty$? I can't explain the cause except saying there is no area under the curve. So it goes beyond the bell-shaped curve.,,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
4,"For random variable X, is there any general result for satisfying $E[X] = E[X^k]$ for $k>0, k \neq 1, k \in \mathbb{R}$?","For random variable X, is there any general result for satisfying  for ?","E[X] = E[X^k] k>0, k \neq 1, k \in \mathbb{R}","For random variable $X$, is  there any general result for satisfying $E[X] = E[X^k]$ for $k>0$, $k \neq 1$, $k \in \mathbb R$ and where $k$ is given? I do not assume any distribution here, but if there is no general result for all distributions, normal distribution case is fine.","For random variable $X$, is  there any general result for satisfying $E[X] = E[X^k]$ for $k>0$, $k \neq 1$, $k \in \mathbb R$ and where $k$ is given? I do not assume any distribution here, but if there is no general result for all distributions, normal distribution case is fine.",,"['statistics', 'random-variables']"
5,Statistics: parameter estimation,Statistics: parameter estimation,,"Let $X$ be a random variable characterized by the following density function: $f(x; \theta) = ((\theta + x) / (\theta + 1)) * exp (-x)$,  if $x >= 0$ $f(x; \theta) = 0$,  if $x < 0$ Assuming that 0 <= theta <= 4, determine a maximum likelihood estimate of the parameter theta based on the realization sample x1 = 1/2. This is my partial solution, but I cannot do the first derivative... Thank you for considering my request.","Let $X$ be a random variable characterized by the following density function: $f(x; \theta) = ((\theta + x) / (\theta + 1)) * exp (-x)$,  if $x >= 0$ $f(x; \theta) = 0$,  if $x < 0$ Assuming that 0 <= theta <= 4, determine a maximum likelihood estimate of the parameter theta based on the realization sample x1 = 1/2. This is my partial solution, but I cannot do the first derivative... Thank you for considering my request.",,"['statistics', 'parameter-estimation']"
6,"Stats probability addition rule, multination rule","Stats probability addition rule, multination rule",,The directions are to calculate the following probability based on drawing cards without replacement from a standard deck of 52. What is the probability of drawing a 2 or a king on the first draw and drawing a queen on the second draw?,The directions are to calculate the following probability based on drawing cards without replacement from a standard deck of 52. What is the probability of drawing a 2 or a king on the first draw and drawing a queen on the second draw?,,"['probability', 'statistics']"
7,Number of samples needed to get a given expected distance,Number of samples needed to get a given expected distance,,"Suppose I have a surface in $\mathbb{R}^3$ with surface area $A$. How many points do I need to (uniformly at random) sample so that the expected distance from each point to its nearest neighbor is $d$? Dimensional analysis suggests the number of samples should be proportional to $\frac{A}{d^2}$. Can anything be said about the proportionality constant, if we don't know anything about the geometry of the surface?","Suppose I have a surface in $\mathbb{R}^3$ with surface area $A$. How many points do I need to (uniformly at random) sample so that the expected distance from each point to its nearest neighbor is $d$? Dimensional analysis suggests the number of samples should be proportional to $\frac{A}{d^2}$. Can anything be said about the proportionality constant, if we don't know anything about the geometry of the surface?",,"['geometry', 'statistics']"
8,"In a game, $0.38$ buy hotdogs, how large an order should she place if she wants to have no more that a 20% chance of demand exceeding supply?.","In a game,  buy hotdogs, how large an order should she place if she wants to have no more that a 20% chance of demand exceeding supply?.",0.38,"A sell-out crowd of 42,200 is expected at Cleveland's Jacobs Field for next Tuesday's game with the Baltimore Orioles, the last before a long road trip. The ballpark's records from games played either in the season, she knows that, on the average, 38% of all those in attendance will buy a hot dog. How large an order should she place if she wants to have no more that a 20% chance of demand exceeding supply?. Attempt: Let $X$ = amount of order. Here X is a binomial distribution with $p = 0.38$ and $n = 42,200$. Then $P(X > x) = 0.20$  $\rightarrow$ $P(X \leq x) = 0.80$. Then from the continuity correction we have $P(X \leq x)$ = $P(\frac{(x - np)}{\sqrt{np(1-p)}} \leq \frac{(X - 42,200(0.38))}{\sqrt{42,200(0.38)(1-0.38)}}) = 0.80$ Then putting $P( z \leq \frac{(x - 42,200(0.38))}{\sqrt{42,200(0.38)(1-0.38)}}) = P(z  \leq \frac{x - 16036}{99.7111}) = 0.80$ I know I have to use the standard normal table to determine where $\frac{x - 16036}{99.7111}$ is about the standard normal table, then solve for $x$. But I don't know how to continue. Can anyone please help? Any feedback/help can help. Thank you.","A sell-out crowd of 42,200 is expected at Cleveland's Jacobs Field for next Tuesday's game with the Baltimore Orioles, the last before a long road trip. The ballpark's records from games played either in the season, she knows that, on the average, 38% of all those in attendance will buy a hot dog. How large an order should she place if she wants to have no more that a 20% chance of demand exceeding supply?. Attempt: Let $X$ = amount of order. Here X is a binomial distribution with $p = 0.38$ and $n = 42,200$. Then $P(X > x) = 0.20$  $\rightarrow$ $P(X \leq x) = 0.80$. Then from the continuity correction we have $P(X \leq x)$ = $P(\frac{(x - np)}{\sqrt{np(1-p)}} \leq \frac{(X - 42,200(0.38))}{\sqrt{42,200(0.38)(1-0.38)}}) = 0.80$ Then putting $P( z \leq \frac{(x - 42,200(0.38))}{\sqrt{42,200(0.38)(1-0.38)}}) = P(z  \leq \frac{x - 16036}{99.7111}) = 0.80$ I know I have to use the standard normal table to determine where $\frac{x - 16036}{99.7111}$ is about the standard normal table, then solve for $x$. But I don't know how to continue. Can anyone please help? Any feedback/help can help. Thank you.",,"['probability', 'statistics', 'random-variables', 'normal-distribution']"
9,"Conditional expectation, sum of exponential i.i.d variables. Integral of conditional density.","Conditional expectation, sum of exponential i.i.d variables. Integral of conditional density.",,"We have $\xi_i \geq 0$, $\forall i = \overline{1,n}$ (exponetial i.i.d. variables).  Assume that $S_n = \xi_1 +...+ \xi_n$. It is easy to show that $\mathrm{E} (\xi_1\vert S_n = 1) = \frac{1}{n}$. $$f_{\xi\vert\eta} = \frac{f_{\xi\eta}(x,y)}{f_{\eta}(y)}$$ On the other hand: $\mathrm{E} (\xi_1\vert S_n = 1) = \int\limits_0^1 \frac{xf^{*(n-1)}(1-x)}{f^{*n}(1)}\:\mathrm{d}x$, where $$f^{*n}(x) = \idotsint\limits_{z_{1}+...+z_{n} = x}f(z_1)...f(z_n)\:\mathrm{d}z_1\dots\:\mathrm{d}z_n;\quad f(t) = \lambda e^{-\lambda t}$$ Am I right? I suppose that I am not. I think that in exponential case $f^{*n}(t) = \frac{\lambda e^{-\lambda t}(\lambda t)^{n-1}}{\Gamma(n)}$ because of the fact that sum of exponential i.i.d. variables has gamma distribution. For example, let $n=2$. $$\frac{1}{2} = \mathrm{E} (\xi_1\vert S_n = 1) = \int\limits_0^1 \frac{x\lambda e^{-\lambda (1-x)}}{\lambda^2 e^{-\lambda }}\:\mathrm{d}x \neq \frac{1}{2}$$ So tell me please where I'm wrong and how to calculate such expectations correctly. P.S. This question has appeared after my other question where @Did commented an answer to an exponential case, but I can't calculate the result. Here is a link. Conditional expectation of second moment given sum of iid variables.","We have $\xi_i \geq 0$, $\forall i = \overline{1,n}$ (exponetial i.i.d. variables).  Assume that $S_n = \xi_1 +...+ \xi_n$. It is easy to show that $\mathrm{E} (\xi_1\vert S_n = 1) = \frac{1}{n}$. $$f_{\xi\vert\eta} = \frac{f_{\xi\eta}(x,y)}{f_{\eta}(y)}$$ On the other hand: $\mathrm{E} (\xi_1\vert S_n = 1) = \int\limits_0^1 \frac{xf^{*(n-1)}(1-x)}{f^{*n}(1)}\:\mathrm{d}x$, where $$f^{*n}(x) = \idotsint\limits_{z_{1}+...+z_{n} = x}f(z_1)...f(z_n)\:\mathrm{d}z_1\dots\:\mathrm{d}z_n;\quad f(t) = \lambda e^{-\lambda t}$$ Am I right? I suppose that I am not. I think that in exponential case $f^{*n}(t) = \frac{\lambda e^{-\lambda t}(\lambda t)^{n-1}}{\Gamma(n)}$ because of the fact that sum of exponential i.i.d. variables has gamma distribution. For example, let $n=2$. $$\frac{1}{2} = \mathrm{E} (\xi_1\vert S_n = 1) = \int\limits_0^1 \frac{x\lambda e^{-\lambda (1-x)}}{\lambda^2 e^{-\lambda }}\:\mathrm{d}x \neq \frac{1}{2}$$ So tell me please where I'm wrong and how to calculate such expectations correctly. P.S. This question has appeared after my other question where @Did commented an answer to an exponential case, but I can't calculate the result. Here is a link. Conditional expectation of second moment given sum of iid variables.",,"['probability', 'statistics', 'stochastic-processes', 'conditional-expectation']"
10,"Does the concept of ""dynamic average"" makes any sense?","Does the concept of ""dynamic average"" makes any sense?",,"While making an excel table about how many times an event happens per day I thought that it could be interesting to see what is the growth rate of those events. If in $2$ days the event happens two times on the first day and three times on the second, I have a an average of $X_1 + X_2/2=2.5$ per day. So I had the idea to calculate the average of the first $n$ days as $\frac {\sum^{n}_{i=0}X_i}{n}$, where $X_i$ is the number of events that occurred on the $i$th day. If $f:\mathbb N \rightarrow \mathbb N$ describes the number of events, the ""dynamic average"" can tell us if the average is growing or not: $$\mathfrak M(f)(n)=\frac {\sum^{n}_{i=0}f(i)}{n}$$ $\mathfrak M(f)(n)$ should tell us how many events/day we have the $n$th day. I'm not sure if this has a name (probably yes), but I was wondering what happens if we want to see the ""dynamic average"" of a an event/quantity that doesn't happen once a day but always at any time. I understand that explained in this way the concept makes little sense and is inaccurate, but let's see it as a function on the real, where the real axis is a time line. $f(x_0)$ tells us what happens at the moment $x_0$. I tried the following formula. $$\mathfrak M^*(f)(x)=\lim_{n\rightarrow +\infty}\frac {\sum^{n}_{i=0}f(i\frac x n)}{n}$$ The idea is to take alot of little strips of decreasing width in order to have infinite cases in the time interval $[0,x]$, and with infinite events we take the average of all the events that occour before the moment $x$. Is this a good way to catch the concept of ""dynamic average""? How the problem was tackled in statistics? What is the right way to catch this concept? I've plotted some graph and I see that $\mathfrak M(f)(n)$ is discontinuous, while $\mathfrak M^*(f)(n)$ is continuous. What is the relation between $\mathfrak M$ and $\mathfrak M^*$ and what is the big picture? I'm really sorry for my horrible english. I used google translator massively but I still think I've made some big mistake somewhere, sorry again.","While making an excel table about how many times an event happens per day I thought that it could be interesting to see what is the growth rate of those events. If in $2$ days the event happens two times on the first day and three times on the second, I have a an average of $X_1 + X_2/2=2.5$ per day. So I had the idea to calculate the average of the first $n$ days as $\frac {\sum^{n}_{i=0}X_i}{n}$, where $X_i$ is the number of events that occurred on the $i$th day. If $f:\mathbb N \rightarrow \mathbb N$ describes the number of events, the ""dynamic average"" can tell us if the average is growing or not: $$\mathfrak M(f)(n)=\frac {\sum^{n}_{i=0}f(i)}{n}$$ $\mathfrak M(f)(n)$ should tell us how many events/day we have the $n$th day. I'm not sure if this has a name (probably yes), but I was wondering what happens if we want to see the ""dynamic average"" of a an event/quantity that doesn't happen once a day but always at any time. I understand that explained in this way the concept makes little sense and is inaccurate, but let's see it as a function on the real, where the real axis is a time line. $f(x_0)$ tells us what happens at the moment $x_0$. I tried the following formula. $$\mathfrak M^*(f)(x)=\lim_{n\rightarrow +\infty}\frac {\sum^{n}_{i=0}f(i\frac x n)}{n}$$ The idea is to take alot of little strips of decreasing width in order to have infinite cases in the time interval $[0,x]$, and with infinite events we take the average of all the events that occour before the moment $x$. Is this a good way to catch the concept of ""dynamic average""? How the problem was tackled in statistics? What is the right way to catch this concept? I've plotted some graph and I see that $\mathfrak M(f)(n)$ is discontinuous, while $\mathfrak M^*(f)(n)$ is continuous. What is the relation between $\mathfrak M$ and $\mathfrak M^*$ and what is the big picture? I'm really sorry for my horrible english. I used google translator massively but I still think I've made some big mistake somewhere, sorry again.",,"['statistics', 'terminology', 'big-picture']"
11,Combined Distribution of Random variable,Combined Distribution of Random variable,,"How to compute $P[T1 \le T2 \le t]$ for T1, T2 is independent random variable with exponential distribution in terms of cmf, pdf of T1 and T2? Similarly for $P[T1 \le T2 \le T3.. \le t]$  ? I tried this: $P[T1 \le T2 \le t] = P [T2 \le t] P[T1 \le T2]$ $= P [T2 \le t] \int_{x=0}^\infty P[T1 \le x ]P[x = T2] dx$ $= F_{T2}(t) \int_{x=0}^\infty F_{T1}(x) f_{T2}(x)dx $ which does not seem to give me the right result.. I think I made mistake at the first expansion, but could not think of any other way. Thanks","How to compute $P[T1 \le T2 \le t]$ for T1, T2 is independent random variable with exponential distribution in terms of cmf, pdf of T1 and T2? Similarly for $P[T1 \le T2 \le T3.. \le t]$  ? I tried this: $P[T1 \le T2 \le t] = P [T2 \le t] P[T1 \le T2]$ $= P [T2 \le t] \int_{x=0}^\infty P[T1 \le x ]P[x = T2] dx$ $= F_{T2}(t) \int_{x=0}^\infty F_{T1}(x) f_{T2}(x)dx $ which does not seem to give me the right result.. I think I made mistake at the first expansion, but could not think of any other way. Thanks",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'exponential-function']"
12,Conditional expectation of second moment given sum of iid variables.,Conditional expectation of second moment given sum of iid variables.,,"We have $\xi_i \geq 0$, $\forall i = \overline{1,n}$ (i.i.d. variables).  Assume that $S_n = \xi_1 +...+ \xi_n$. It is easy to show that $\mathrm{E} (\xi_1\vert S_n = 1) = \frac{1}{n}$. Now we want to look at the second moment: $\mathrm{E}(\xi_1^2\vert S_n = 1)$. 1) Since $0\leq\xi_i\leq 1$ then $\xi_i\geq \xi_i^2,\: \forall i=\overline{1,n},$ finally, $\mathrm{E}(\xi_1^2\vert S_n = 1) \leq \mathrm{E}(\xi_1\vert S_n = 1) = \frac{1}{n}$. 2) On the other hand, by Jensen's  inequality we have: $(\mathrm{E}(\xi_1\vert S_n = 1))^2\leq \mathrm{E}(\xi_1^2\vert S_n = 1),$ where$(\mathrm{E}(\xi_1\vert S_n = 1))^2 = \frac{1}{n^2}$. The question is: how can we prove that the second moment has order of $\frac{1}{n^2}$; namely how we can get upper bound as $\frac{c}{n^2}$, where $c$ is a constant?","We have $\xi_i \geq 0$, $\forall i = \overline{1,n}$ (i.i.d. variables).  Assume that $S_n = \xi_1 +...+ \xi_n$. It is easy to show that $\mathrm{E} (\xi_1\vert S_n = 1) = \frac{1}{n}$. Now we want to look at the second moment: $\mathrm{E}(\xi_1^2\vert S_n = 1)$. 1) Since $0\leq\xi_i\leq 1$ then $\xi_i\geq \xi_i^2,\: \forall i=\overline{1,n},$ finally, $\mathrm{E}(\xi_1^2\vert S_n = 1) \leq \mathrm{E}(\xi_1\vert S_n = 1) = \frac{1}{n}$. 2) On the other hand, by Jensen's  inequality we have: $(\mathrm{E}(\xi_1\vert S_n = 1))^2\leq \mathrm{E}(\xi_1^2\vert S_n = 1),$ where$(\mathrm{E}(\xi_1\vert S_n = 1))^2 = \frac{1}{n^2}$. The question is: how can we prove that the second moment has order of $\frac{1}{n^2}$; namely how we can get upper bound as $\frac{c}{n^2}$, where $c$ is a constant?",,"['probability', 'statistics', 'stochastic-processes', 'conditional-expectation']"
13,Joint probability distribution,Joint probability distribution,,"$Y_1$ and $Y_2$ are jointly distributed with density $f(y_1,y_2)=4y_2^2 \qquad 0 \leq y_1 \leq y_2 \leq 1$ Determine the following: $P(\text{max} \{Y_1,Y_2\} <1/2) = \int_{y_2=0}^{1/2}\int_{y_1=0}^{y_2}4y_2^2dy_1dy_2  \approx 0.0625$  $P(Y_1+Y_2 < 1/2) = \int_{y_1=0}^{1/4}\int^{1/2-y_1}_{y_2=y_1}4y_2^2dy_2dy_1 \approx 0.0182292$  $P(Y_1Y_2 <1/2) = \int_{y_2=0}^{\sqrt{1/2}}\int_{y_1=0}^{y_2}4y_2^2dy_1dy_2 + \int_{y_2=\sqrt{1/2}}^{1}\int_{y_1=0}^{1/(2y_2)}4y_2^2dy_1dy_2 = 1/4 + 1/2 = 0.75$  $P(Y_1/Y_2<1/2) = \int_{y_2=0}^{1}\int_{y_1=(1/2)y_2}^{y_2}4y_2^2dy_1dy_2 = 0.5$  $P(Y_2-Y_1 < 1/2) = \int_{y_2=0}^{1/2}\int_{y_1=0}^{y_2}4y^2_2dy_1dy_2 + \int_{y_2=1/2}^{1}\int_{y_1=y_2-(1/2)}^{y_2}4y^2_2dy_1dy_2 \approx 0.583333+0.0625 = 0.645833$  $P(\text{min} \{Y_1,Y_2\}<1/2) = \int_{y_2=1/2}^{1}\int_{dy_1=0}^{y_2}4y^2_2dy_1dy_2 \approx 0.9375 $","$Y_1$ and $Y_2$ are jointly distributed with density $f(y_1,y_2)=4y_2^2 \qquad 0 \leq y_1 \leq y_2 \leq 1$ Determine the following: $P(\text{max} \{Y_1,Y_2\} <1/2) = \int_{y_2=0}^{1/2}\int_{y_1=0}^{y_2}4y_2^2dy_1dy_2  \approx 0.0625$  $P(Y_1+Y_2 < 1/2) = \int_{y_1=0}^{1/4}\int^{1/2-y_1}_{y_2=y_1}4y_2^2dy_2dy_1 \approx 0.0182292$  $P(Y_1Y_2 <1/2) = \int_{y_2=0}^{\sqrt{1/2}}\int_{y_1=0}^{y_2}4y_2^2dy_1dy_2 + \int_{y_2=\sqrt{1/2}}^{1}\int_{y_1=0}^{1/(2y_2)}4y_2^2dy_1dy_2 = 1/4 + 1/2 = 0.75$  $P(Y_1/Y_2<1/2) = \int_{y_2=0}^{1}\int_{y_1=(1/2)y_2}^{y_2}4y_2^2dy_1dy_2 = 0.5$  $P(Y_2-Y_1 < 1/2) = \int_{y_2=0}^{1/2}\int_{y_1=0}^{y_2}4y^2_2dy_1dy_2 + \int_{y_2=1/2}^{1}\int_{y_1=y_2-(1/2)}^{y_2}4y^2_2dy_1dy_2 \approx 0.583333+0.0625 = 0.645833$  $P(\text{min} \{Y_1,Y_2\}<1/2) = \int_{y_2=1/2}^{1}\int_{dy_1=0}^{y_2}4y^2_2dy_1dy_2 \approx 0.9375 $",,"['statistics', 'probability-distributions']"
14,do discrete probability distribution functions need a countable number of outcomes?,do discrete probability distribution functions need a countable number of outcomes?,,"Everywhere I see on the internet they say that discrete probability distribution functions have a countable number of outcomes, and continuous have uncountable infinite number of outcomes. However if your domain is infinite dimensional with finite number of elements in each dimension, then clearly there is uncountable infinite many outcomes but discrete. An example is a single experiment of flipping a coin infinite number of times. So what am I missing?","Everywhere I see on the internet they say that discrete probability distribution functions have a countable number of outcomes, and continuous have uncountable infinite number of outcomes. However if your domain is infinite dimensional with finite number of elements in each dimension, then clearly there is uncountable infinite many outcomes but discrete. An example is a single experiment of flipping a coin infinite number of times. So what am I missing?",,['statistics']
15,Find $E(X)$ and $Var(X)$,Find  and,E(X) Var(X),"In a box there are $30$ balls, $20$ are black and $10$ are red. Let $X$ be the number of red in a selection of two balls drawn without replacement then $$X=I_1 + I_2$$ where $I_1 = 1$ if red is drawn first, else 0 the same thing applies to $I_2$ in the second draw. Find $$E(I_1),\,\, E(I_2),\,\, E(I^2 _1),\,\, E(I^2 _2),\,\, E(I_1 I_2), \,\,E(X)$$ and $Var(X)$.","In a box there are $30$ balls, $20$ are black and $10$ are red. Let $X$ be the number of red in a selection of two balls drawn without replacement then $$X=I_1 + I_2$$ where $I_1 = 1$ if red is drawn first, else 0 the same thing applies to $I_2$ in the second draw. Find $$E(I_1),\,\, E(I_2),\,\, E(I^2 _1),\,\, E(I^2 _2),\,\, E(I_1 I_2), \,\,E(X)$$ and $Var(X)$.",,"['probability', 'statistics']"
16,prove convergence almost surely,prove convergence almost surely,,"Let {$X_n$} be a sequence of i.i.d. random variables with $E[|X_1|]<\infty$, and $S_n=\sum_{j=1}^nX_j$. Show that if $E[X_1]\neq0$, then $$\frac{\max_{1\leq k\leq n} |X_k|}{|S_n|}\rightarrow 0 $$ almost surely. I'm thinking of using strong law of large numbers to prove this, but don't know how to start. Please help.","Let {$X_n$} be a sequence of i.i.d. random variables with $E[|X_1|]<\infty$, and $S_n=\sum_{j=1}^nX_j$. Show that if $E[X_1]\neq0$, then $$\frac{\max_{1\leq k\leq n} |X_k|}{|S_n|}\rightarrow 0 $$ almost surely. I'm thinking of using strong law of large numbers to prove this, but don't know how to start. Please help.",,"['probability', 'statistics']"
17,How can I uniformly draw points from an ellipsoid?,How can I uniformly draw points from an ellipsoid?,,"Specifically, given a positive definite matrix $A \in \mathbb{R}^{n \times n}$, how can I efficiently generate points $x \in \mathbb{R}^n$ that satisfy $x^TAx \leq 1$? I know how to do this when the matrix is just the identity, because then this question reduces to simply generating uniformly from the unit ball. However, I am not sure how to extend this to drawing from a general ellipsoid (if that is the correct term?). For a ball centered at the origin with radius r, I would simply generate $Z_1, \dots, Z_n$ all iid $ N(0,1)$ random variables. Then if $Z := (Z_1, \dots, Z_n)$ and $U$ is $UNIF(0,r)$ then we have that $$\frac{UZ}{\|Z\|} \sim UNIF(B_r(0))$$ However I am not sure how to generalize this process to an ellipsoid...","Specifically, given a positive definite matrix $A \in \mathbb{R}^{n \times n}$, how can I efficiently generate points $x \in \mathbb{R}^n$ that satisfy $x^TAx \leq 1$? I know how to do this when the matrix is just the identity, because then this question reduces to simply generating uniformly from the unit ball. However, I am not sure how to extend this to drawing from a general ellipsoid (if that is the correct term?). For a ball centered at the origin with radius r, I would simply generate $Z_1, \dots, Z_n$ all iid $ N(0,1)$ random variables. Then if $Z := (Z_1, \dots, Z_n)$ and $U$ is $UNIF(0,r)$ then we have that $$\frac{UZ}{\|Z\|} \sim UNIF(B_r(0))$$ However I am not sure how to generalize this process to an ellipsoid...",,"['statistics', 'euclidean-geometry', 'sampling', 'geometric-probability', 'ellipsoids']"
18,You purchased stock for \$1m. What is the probability that it is worth more than $30m after 10 years?,You purchased stock for \30m after 10 years?,1m. What is the probability that it is worth more than ,"The change in value of the investment each year is modeled as follows: Divided by 2: 1/4 Remain unchanged: 3/8 Doubles: 1/4 Quadruples: 1/8 Where I'm at: I'm aware that this needs to be formulated into a normal distribution, but I'm not sure how to come up with the right formula, or how to correctly approximate it to normal. Would really appreciate some insights!","The change in value of the investment each year is modeled as follows: Divided by 2: 1/4 Remain unchanged: 3/8 Doubles: 1/4 Quadruples: 1/8 Where I'm at: I'm aware that this needs to be formulated into a normal distribution, but I'm not sure how to come up with the right formula, or how to correctly approximate it to normal. Would really appreciate some insights!",,"['statistics', 'normal-distribution']"
19,Fill chart using final data,Fill chart using final data,,"so all I know is that: n=100. i have 5 departments within the numbers: 0-1000. md = 500. avg =490. lower decile=200. upper quarter=600. I really don't know how to use the formulas of each if I don't have any data.(fx,Fx etc) notice: this chart is filled by the correct answers(2. 15 = box 2, the answer is 15), how to i get to them?","so all I know is that: n=100. i have 5 departments within the numbers: 0-1000. md = 500. avg =490. lower decile=200. upper quarter=600. I really don't know how to use the formulas of each if I don't have any data.(fx,Fx etc) notice: this chart is filled by the correct answers(2. 15 = box 2, the answer is 15), how to i get to them?",,['statistics']
20,Generating a data set that approximates another given random variable,Generating a data set that approximates another given random variable,,"One of the question my friend was asked in technical interview : The probability density function for a normal random variable with μ =   0.6 and σ = 0.7:​ Below is the code to generate the graph : {μ, σ} = {0.6, 0.7}; {xlow, xhigh} = {μ - 4 σ, μ + 4 σ}; Clear[pdf, x, t]; pdf[x_] = D[Normalcumdist[x, μ, σ], x]; pdfplot = Plot[pdf[x], {x, xlow, xhigh}, PlotStyle -> {{Thickness[0.01], Purple}}, AxesLabel -> {""x"", ""pdf[x]""}, AspectRatio -> 1/GoldenRatio] The natural logarithm of a certain random variable Y has the   probability density function plotted above. Your job is to generate a data set whose cumulative distribution   function can be expected to give a good approximation of the true   cumulative distribution function of Y. My friend answered with below code but is incorrect. x = RandomReal[{-2, 2}, 50]; z = x - Mean[x]; stdNorm = 0.7/StandardDeviation[z]; StandardDeviation[stdNorm z]; new = stdNorm z + 0.6 {Mean[new], StandardDeviation[new]} Can anyone please explain what is wrong here ? How to transform the result set we obtained in the our code to meet the question requirement ?","One of the question my friend was asked in technical interview : The probability density function for a normal random variable with μ =   0.6 and σ = 0.7:​ Below is the code to generate the graph : {μ, σ} = {0.6, 0.7}; {xlow, xhigh} = {μ - 4 σ, μ + 4 σ}; Clear[pdf, x, t]; pdf[x_] = D[Normalcumdist[x, μ, σ], x]; pdfplot = Plot[pdf[x], {x, xlow, xhigh}, PlotStyle -> {{Thickness[0.01], Purple}}, AxesLabel -> {""x"", ""pdf[x]""}, AspectRatio -> 1/GoldenRatio] The natural logarithm of a certain random variable Y has the   probability density function plotted above. Your job is to generate a data set whose cumulative distribution   function can be expected to give a good approximation of the true   cumulative distribution function of Y. My friend answered with below code but is incorrect. x = RandomReal[{-2, 2}, 50]; z = x - Mean[x]; stdNorm = 0.7/StandardDeviation[z]; StandardDeviation[stdNorm z]; new = stdNorm z + 0.6 {Mean[new], StandardDeviation[new]} Can anyone please explain what is wrong here ? How to transform the result set we obtained in the our code to meet the question requirement ?",,"['probability', 'statistics', 'standard-deviation', 'mathematica']"
21,Standard Error in OLS Regression,Standard Error in OLS Regression,,"Assuming I have the following linear regression set-up: $y_i = \alpha + x_i * \beta + \epsilon_i$ for $i = 1,2,..., n$. When I run the regession, I get a $\beta$ and $\alpha$ estimates, along with their standard errors. Let $\sigma_{\alpha}$ and $\sigma_{\beta}$ be the standard error of $\alpha$ and $\beta$ respectively. If I want to compute the standard error of the expression $\hat{\alpha} + x_i * {\hat\beta}$ for each value of $i$, would that be: $\sqrt{\sigma^2_{\alpha} + x^2_i * \sigma^2_{\beta}}$   ??? Any help would be appreciated! Thanks!","Assuming I have the following linear regression set-up: $y_i = \alpha + x_i * \beta + \epsilon_i$ for $i = 1,2,..., n$. When I run the regession, I get a $\beta$ and $\alpha$ estimates, along with their standard errors. Let $\sigma_{\alpha}$ and $\sigma_{\beta}$ be the standard error of $\alpha$ and $\beta$ respectively. If I want to compute the standard error of the expression $\hat{\alpha} + x_i * {\hat\beta}$ for each value of $i$, would that be: $\sqrt{\sigma^2_{\alpha} + x^2_i * \sigma^2_{\beta}}$   ??? Any help would be appreciated! Thanks!",,"['statistics', 'regression', 'standard-deviation']"
22,General Gaussian distribution relation,General Gaussian distribution relation,,"I'm trying to solve a question from Pathria's statistical mechanics textbook (10.21) but it is more math oriented. Show that, for a general Gaussian distribution of variables $u_j$ , the average of the exponential of a linear combination of the variables obeys the relation: $\left\langle \exp\left(\sum_j a_j u_j\right) \right\rangle=\exp\left(\dfrac{1}{2}\left\langle\left(\sum_j a_j u_j\right)^2 \right\rangle \right)$ I'm not entirely sure how to write this; I was doing Taylor series expansions of exponentials and I could solve it easily if it were a standard normal (mean=0).  I believe the linear combination of normal variables is normal, so this seems to have something to do with the log-normal distribution? I don't need a full solution; just a hint to go forward.","I'm trying to solve a question from Pathria's statistical mechanics textbook (10.21) but it is more math oriented. Show that, for a general Gaussian distribution of variables $u_j$ , the average of the exponential of a linear combination of the variables obeys the relation: $\left\langle \exp\left(\sum_j a_j u_j\right) \right\rangle=\exp\left(\dfrac{1}{2}\left\langle\left(\sum_j a_j u_j\right)^2 \right\rangle \right)$ I'm not entirely sure how to write this; I was doing Taylor series expansions of exponentials and I could solve it easily if it were a standard normal (mean=0).  I believe the linear combination of normal variables is normal, so this seems to have something to do with the log-normal distribution? I don't need a full solution; just a hint to go forward.",,"['statistical-mechanics', 'probability', 'statistics']"
23,Inconsistency in two-sided hypothesis testing,Inconsistency in two-sided hypothesis testing,,"Suppose you have two sets of data with known population variances and want to test the null hypothesis that two means are equal, ie. $H_{0}: \mu_{1} = \mu_{2}$ against $H_{1}: \mu_{1} > \mu_{2}$. There's a certain way I want to think about it, which is the following: \begin{align} P(\mu_{1} > \mu_{2}) &= P(-(\mu_{1} - \mu_{2}) < 0) \\ &= P\left(\frac{\bar{x}_{1} - \bar{x}_{2} - (\mu_{1} - \mu_{2})}{\sigma_{\delta \bar{x}}}<\frac{\bar{x}_{1} - \bar{x}_{2}}{\sigma_{\delta \bar{x}}} \right) \\ &=P\left(z < \frac{\bar{x}_{1} - \bar{x}_{2}}{\sigma_{\delta \bar{x}}}  \right) \end{align} To me, this 'derivation' makes it perfectly clear what's actually going on. You're actually calculating the probability that $H_{1}$ is true and not just blindly looking up some $z$-score. However, now suppose that $H_{1}: \mu_{1} \neq \mu_{2}$. The problem with this is that the method I just described doesn't seem to work. If I write $$ P(\mu_{1} \neq \mu_{2}) =  P(\mu_{1} < \mu_{2}) + P(\mu_{1} > \mu_{2}) $$ Then all that happens is $P(\mu_{1} \neq \mu_{2}) = 1$. I think I'm probably not interpreting the above equation correctly.","Suppose you have two sets of data with known population variances and want to test the null hypothesis that two means are equal, ie. $H_{0}: \mu_{1} = \mu_{2}$ against $H_{1}: \mu_{1} > \mu_{2}$. There's a certain way I want to think about it, which is the following: \begin{align} P(\mu_{1} > \mu_{2}) &= P(-(\mu_{1} - \mu_{2}) < 0) \\ &= P\left(\frac{\bar{x}_{1} - \bar{x}_{2} - (\mu_{1} - \mu_{2})}{\sigma_{\delta \bar{x}}}<\frac{\bar{x}_{1} - \bar{x}_{2}}{\sigma_{\delta \bar{x}}} \right) \\ &=P\left(z < \frac{\bar{x}_{1} - \bar{x}_{2}}{\sigma_{\delta \bar{x}}}  \right) \end{align} To me, this 'derivation' makes it perfectly clear what's actually going on. You're actually calculating the probability that $H_{1}$ is true and not just blindly looking up some $z$-score. However, now suppose that $H_{1}: \mu_{1} \neq \mu_{2}$. The problem with this is that the method I just described doesn't seem to work. If I write $$ P(\mu_{1} \neq \mu_{2}) =  P(\mu_{1} < \mu_{2}) + P(\mu_{1} > \mu_{2}) $$ Then all that happens is $P(\mu_{1} \neq \mu_{2}) = 1$. I think I'm probably not interpreting the above equation correctly.",,['statistics']
24,Find the probability of at most two accidents per day in total on these highways,Find the probability of at most two accidents per day in total on these highways,,"this is a question in my textbook that doesn't have a solution. Any help on an answer would be great. There are three highways in the county. Independently from one another, the number of daily accidents that occur on these highways are Poisson random variables with respective parameters $.3$, $.5$, and $.7$. Find the probability of at most two accidents per day in total on these highways. My attempt: let $X =$ number of accidents on each highway. We want to find $P(X \leq 2) = P(X = 0, 1, 2) = P(X=0) +P(X= 1) + P(X=2)$ so $P(X=0) = (e^{-0.3})(e^{-0.5})(e^{-0.7})$ but I am having trouble finding $P(X = 1) $ and $P(X=2)$","this is a question in my textbook that doesn't have a solution. Any help on an answer would be great. There are three highways in the county. Independently from one another, the number of daily accidents that occur on these highways are Poisson random variables with respective parameters $.3$, $.5$, and $.7$. Find the probability of at most two accidents per day in total on these highways. My attempt: let $X =$ number of accidents on each highway. We want to find $P(X \leq 2) = P(X = 0, 1, 2) = P(X=0) +P(X= 1) + P(X=2)$ so $P(X=0) = (e^{-0.3})(e^{-0.5})(e^{-0.7})$ but I am having trouble finding $P(X = 1) $ and $P(X=2)$",,"['probability', 'statistics', 'probability-distributions', 'poisson-distribution']"
25,Proof the concave transformation of the tail distribution is always above the tail distribution,Proof the concave transformation of the tail distribution is always above the tail distribution,,"I need to prove that for a given continuous non-decreasing distribution $F_X(x)$, and a concave non-decreasing distortion function $g(.)$ defined on $[0,1]$, the following holds: $$g(1-F_X(x)) \ge 1-F_X(x)$$  We know that $g(0) = 0$ and $g(1) = 1$. I was thinking to use the fact that if $g$ is concave then for $t$ in $[0,1]: g(tx + (1-t)y) \ge tg(x) + (1-t)g(y)$ , for any $x,y$ in the domain of the distribution but can't seem to find a solution. It's probably pretty obvious, but I'm stuck so any help would be truly appreciated. Best, tb","I need to prove that for a given continuous non-decreasing distribution $F_X(x)$, and a concave non-decreasing distortion function $g(.)$ defined on $[0,1]$, the following holds: $$g(1-F_X(x)) \ge 1-F_X(x)$$  We know that $g(0) = 0$ and $g(1) = 1$. I was thinking to use the fact that if $g$ is concave then for $t$ in $[0,1]: g(tx + (1-t)y) \ge tg(x) + (1-t)g(y)$ , for any $x,y$ in the domain of the distribution but can't seem to find a solution. It's probably pretty obvious, but I'm stuck so any help would be truly appreciated. Best, tb",,['statistics']
26,Finding simplest function to distinguish 2 sets,Finding simplest function to distinguish 2 sets,,"I wish to find a function that distinguishes $2$ sets. I have m data values in form of n-tuples out of which k are supposed to be mapped to a value less than $0$ and other m-k are supposed to be mapped to a value greater than or equal to $0$.  My main Aim is that The function needs to be simple to compute, so not neccessary polynomial.(anything better than a $(m-1)$ degree polynomial in the worst case). For example for the data$(m=6,k=3,n=2)$; $A((1,3), (2,5), (12,67))$ $B((3,4), (14,20),(4,6))$ i.e the latter tuples $(x,y)$ belong to set $B$ and the former $3$ belong to set $A$. Here, my dream (or at least a very good) function would be $f(y,x)=(y/x) -2$ . Which sends A to positive and B to negative values. Of course i can have a trivial polynomial fit of degree 5 but that thing gets messy when m is large. Since there is lot of freedom on values and nature of function, I m certain something better is achievable. But I am not sure how to do this.  And if not a general solution is available, even for the case of n=2 or 3 variables will be very very much appreciated. Even related links without explanation will be of great help. Thankyou","I wish to find a function that distinguishes $2$ sets. I have m data values in form of n-tuples out of which k are supposed to be mapped to a value less than $0$ and other m-k are supposed to be mapped to a value greater than or equal to $0$.  My main Aim is that The function needs to be simple to compute, so not neccessary polynomial.(anything better than a $(m-1)$ degree polynomial in the worst case). For example for the data$(m=6,k=3,n=2)$; $A((1,3), (2,5), (12,67))$ $B((3,4), (14,20),(4,6))$ i.e the latter tuples $(x,y)$ belong to set $B$ and the former $3$ belong to set $A$. Here, my dream (or at least a very good) function would be $f(y,x)=(y/x) -2$ . Which sends A to positive and B to negative values. Of course i can have a trivial polynomial fit of degree 5 but that thing gets messy when m is large. Since there is lot of freedom on values and nature of function, I m certain something better is achievable. But I am not sure how to do this.  And if not a general solution is available, even for the case of n=2 or 3 variables will be very very much appreciated. Even related links without explanation will be of great help. Thankyou",,"['functional-analysis', 'statistics', 'functions', 'data-analysis']"
27,Probability: How to find what proportion is between the 2 values,Probability: How to find what proportion is between the 2 values,,Assume that head sizes (circumference) of new recruits in the Canadian armed forces can be approximated by a normal distribution with a mean of 22.8 inches and a standard deviation of 1.1 inches. What proportion of recruits have head sizes between 22 and 23 inches? What rule do I use for this? Do I use chebyshev's rule for this where 1-1/k? If anyone can help me out. It would be appreciated!,Assume that head sizes (circumference) of new recruits in the Canadian armed forces can be approximated by a normal distribution with a mean of 22.8 inches and a standard deviation of 1.1 inches. What proportion of recruits have head sizes between 22 and 23 inches? What rule do I use for this? Do I use chebyshev's rule for this where 1-1/k? If anyone can help me out. It would be appreciated!,,"['probability', 'statistics']"
28,Normal distributions sums,Normal distributions sums,,"I read this property about normal distribution If $X\sim\mathcal N(\mu_X,\sigma_X^2)$ and $Y\sim\mathcal N(\mu_Y,\sigma_Y^2)$ are independent, then $$ X+Y\sim\mathcal N(\mu_X+\mu_Y,\sigma_X^2+\sigma_Y^2). $$ However I also read $$ X = \sigma Z + \mu\, $$ If I sum X + Y using this property I get $$ X+Y = (\sigma_x + \sigma_y) Z +  \mu_x + \mu_y = N(\mu_x + \mu_y, (\sigma_x + \sigma_y)^2), $$ Why do I get different result on variance?","I read this property about normal distribution If $X\sim\mathcal N(\mu_X,\sigma_X^2)$ and $Y\sim\mathcal N(\mu_Y,\sigma_Y^2)$ are independent, then $$ X+Y\sim\mathcal N(\mu_X+\mu_Y,\sigma_X^2+\sigma_Y^2). $$ However I also read $$ X = \sigma Z + \mu\, $$ If I sum X + Y using this property I get $$ X+Y = (\sigma_x + \sigma_y) Z +  \mu_x + \mu_y = N(\mu_x + \mu_y, (\sigma_x + \sigma_y)^2), $$ Why do I get different result on variance?",,"['statistics', 'normal-distribution']"
29,"Poisson distribution variance, probability, and mean.","Poisson distribution variance, probability, and mean.",,"Let $X$ be the poisson random variable such that $\mathbb P(X=2)=9\mathbb P(X=4)+90\mathbb P(X=6)$ . a) Find the mean and variance of $X$ . b) Find $\mathbb P(X\geq1)$ . c) Find $\mathbb P(X\leq10)$ . For a), I need to turn each probability into its respective $p(x)$ form and solve for $\lambda$ . I got that $\lambda$ was $1$ so therefore, the mean and variance should be $1$ . Now, for the second question, I have that $\mathbb P(X\geq 1)=1- \mathbb P(X<1)$ . Am I to assume that $\lambda$ is still $1$ ? If so, is $1-\mathrm e^{-1}$ the correct answer for b)? For c), I'm just lost here... it was asked to solve this problem through R programming language. Correct me if I'm wrong, but is is not just simply $\mathbb P(X \leq10)=1-\mathbb P(X>10)$ ? If so, I'd think that solving for $\mathbb P(X>10)$ would be plugging in ppois(10,1) into R, but I'm just getting $1$ as the output... that means a $100\%$ change of $\mathbb P(X>10)$ ... sorry if this question isn't what this MSE is for but if you know what I'm talking about, that'd be really helpful.","Let be the poisson random variable such that . a) Find the mean and variance of . b) Find . c) Find . For a), I need to turn each probability into its respective form and solve for . I got that was so therefore, the mean and variance should be . Now, for the second question, I have that . Am I to assume that is still ? If so, is the correct answer for b)? For c), I'm just lost here... it was asked to solve this problem through R programming language. Correct me if I'm wrong, but is is not just simply ? If so, I'd think that solving for would be plugging in ppois(10,1) into R, but I'm just getting as the output... that means a change of ... sorry if this question isn't what this MSE is for but if you know what I'm talking about, that'd be really helpful.",X \mathbb P(X=2)=9\mathbb P(X=4)+90\mathbb P(X=6) X \mathbb P(X\geq1) \mathbb P(X\leq10) p(x) \lambda \lambda 1 1 \mathbb P(X\geq 1)=1- \mathbb P(X<1) \lambda 1 1-\mathrm e^{-1} \mathbb P(X \leq10)=1-\mathbb P(X>10) \mathbb P(X>10) 1 100\% \mathbb P(X>10),"['probability', 'statistics', 'random-variables', 'poisson-distribution']"
30,When to use Central Limit Theorem or Cramers Theorem,When to use Central Limit Theorem or Cramers Theorem,,"In for example this paper the authors say The central limit theorem provides an estimate of the probability   \begin{align} P\left( \frac{\sum_{i=1}^n X_i - n\mu}{\sigma \sqrt{n}} > x \right) \end{align}   ... the CLT estimates the probability of $O(\sqrt{n})$ deviations from the mean of the sum of random variables ... On the other hand, large deviations of the order of the mean itself, i.e., $O(n)$ deviations, is the subject of this section [Cramer-Chernoff Theorem]. It is not clear to my why the CTL can't be used to calculate large deviations. Following the answer of my previous question for large $n$, the CTL tells me, that the mean is approximately normally distributed as $$P\left(|\sum_{i=1}^n X_i - n\mu| \geq x\right) \approx 2\Phi\left(-\frac{x \sqrt{n}}{\sigma}\right)$$ Why (and in which cases) should Cramers theorem be used if $x$ is large and not the CTL?","In for example this paper the authors say The central limit theorem provides an estimate of the probability   \begin{align} P\left( \frac{\sum_{i=1}^n X_i - n\mu}{\sigma \sqrt{n}} > x \right) \end{align}   ... the CLT estimates the probability of $O(\sqrt{n})$ deviations from the mean of the sum of random variables ... On the other hand, large deviations of the order of the mean itself, i.e., $O(n)$ deviations, is the subject of this section [Cramer-Chernoff Theorem]. It is not clear to my why the CTL can't be used to calculate large deviations. Following the answer of my previous question for large $n$, the CTL tells me, that the mean is approximately normally distributed as $$P\left(|\sum_{i=1}^n X_i - n\mu| \geq x\right) \approx 2\Phi\left(-\frac{x \sqrt{n}}{\sigma}\right)$$ Why (and in which cases) should Cramers theorem be used if $x$ is large and not the CTL?",,"['probability', 'statistics', 'probability-theory', 'parameter-estimation']"
31,What is Neyman-Pearson lemma? Why is this proof of Neyman-Pearson's lemma look so diffcult?,What is Neyman-Pearson lemma? Why is this proof of Neyman-Pearson's lemma look so diffcult?,,"What is Neyman-Pearson lemma? Why is this proof of Neyman-Pearson's lemma look so diffcult? I am consider taking a undergraduate course in my college called mathematics of statistics and in the course description, a term comes up and it look so difficult to me. What is a book that including a proof that is easy to read? Please including an alternative proof that is easier if you want to! Appreciate in advance.","What is Neyman-Pearson lemma? Why is this proof of Neyman-Pearson's lemma look so diffcult? I am consider taking a undergraduate course in my college called mathematics of statistics and in the course description, a term comes up and it look so difficult to me. What is a book that including a proof that is easy to read? Please including an alternative proof that is easier if you want to! Appreciate in advance.",,"['probability', 'statistics', 'reference-request', 'soft-question', 'alternative-proof']"
32,If $E(W) = \mu$ and $Var(W) = \sigma^2$,If  and,E(W) = \mu Var(W) = \sigma^2,"This is one of two HW problems that I'm positing that I have no clue how to go about. If $E(W) = \mu$ and $\operatorname{Var}(W) = \sigma^2$ show that $E\left(\frac{W - \mu}{\sigma}\right) = 0$ and $\operatorname{Var}\left(\frac{W - \mu}{\sigma}\right) = 1$ For the first section, based on something out of the book, I'm thinking I should be able to do $$E\left(\frac{W}{\sigma} - \frac{\mu}{\sigma}\right) = E\left(\frac{W}{\sigma}\right) - \frac{\mu}{\sigma} = \frac{\mu}{\sigma} - \frac{\mu}{\sigma} = 0$$ I'm not sure if that's correct, and I have no clue on the following part.","This is one of two HW problems that I'm positing that I have no clue how to go about. If $E(W) = \mu$ and $\operatorname{Var}(W) = \sigma^2$ show that $E\left(\frac{W - \mu}{\sigma}\right) = 0$ and $\operatorname{Var}\left(\frac{W - \mu}{\sigma}\right) = 1$ For the first section, based on something out of the book, I'm thinking I should be able to do $$E\left(\frac{W}{\sigma} - \frac{\mu}{\sigma}\right) = E\left(\frac{W}{\sigma}\right) - \frac{\mu}{\sigma} = \frac{\mu}{\sigma} - \frac{\mu}{\sigma} = 0$$ I'm not sure if that's correct, and I have no clue on the following part.",,"['statistics', 'standard-deviation']"
33,How do you find variance when not given probability?,How do you find variance when not given probability?,,"A small farmer in a developing country grows cassava and groundnuts. The amount of cassava he grows per year is a random variable, X, with a mean of 500 pounds, and a variance of 625  (pounds-squared). The amount of groundnuts he grows per year is a random variable, Y, with a  mean of 700 pounds, and a variance of 2500 (pounds-squared). The amounts of cassava and  groundnuts he grows have a covariance of 475. The farmer uses 400 pounds of cassava and 300  pounds of groundnuts for consumption by his family. The remainder of each crop is sold for cash. He can sell cassava for \$2 per pound, and groundnuts for \$3 dollars per pound. What is the variance of the farmer’s cash income? Really not sure where to go with this problem. I found the expected cash income but have no probability values to calculate the variance.","A small farmer in a developing country grows cassava and groundnuts. The amount of cassava he grows per year is a random variable, X, with a mean of 500 pounds, and a variance of 625  (pounds-squared). The amount of groundnuts he grows per year is a random variable, Y, with a  mean of 700 pounds, and a variance of 2500 (pounds-squared). The amounts of cassava and  groundnuts he grows have a covariance of 475. The farmer uses 400 pounds of cassava and 300  pounds of groundnuts for consumption by his family. The remainder of each crop is sold for cash. He can sell cassava for \$2 per pound, and groundnuts for \$3 dollars per pound. What is the variance of the farmer’s cash income? Really not sure where to go with this problem. I found the expected cash income but have no probability values to calculate the variance.",,['statistics']
34,Finding the mean of a Maxwell Distribution,Finding the mean of a Maxwell Distribution,,Let the velocity of gas particles be modeled by the Maxwell distribution. The probability density function is $$ f(v) = 4\pi \cdot\left( \frac{m}{2\pi K T} \right) ^ {\frac{3}{2}}v^2\cdot e^{-v^2(m/[2KT])}$$ I found that the mean is $2a \sqrt{\frac{2}{\pi}}$ where $a=\sqrt{\frac{kT}{m}}$ from Wikipedia. Could you please explain how is the mean obtained?,Let the velocity of gas particles be modeled by the Maxwell distribution. The probability density function is $$ f(v) = 4\pi \cdot\left( \frac{m}{2\pi K T} \right) ^ {\frac{3}{2}}v^2\cdot e^{-v^2(m/[2KT])}$$ I found that the mean is $2a \sqrt{\frac{2}{\pi}}$ where $a=\sqrt{\frac{kT}{m}}$ from Wikipedia. Could you please explain how is the mean obtained?,,['statistics']
35,Standard deviation of absolute distance of a 1D random walk,Standard deviation of absolute distance of a 1D random walk,,"Given a 1D random walk (simple +1, -1 movements from the axis) I've seen proofs that the expected absolute distance tends to Sqrt(2*n/PI) and I've plotted graphs of 1D random walks along with this curve along and the associated standard deviation of the absolute distance. As expected most walks can be found in the area around the expected absolute distance curve up to 2 standard deviations from it. Now take a walk that zooms steeply up or down towards the 2 standard deviation line from the expected absolute distance curve. From what little I understand of statistics very few random walks should be found above this line - 95% rule (and indeed my graphs confirm this). So doesn't this imply that such a walk should therefore most likely turn around and head back into the area closer to the expected absolute distance curve? Or at least continue on its original direction but at a less steep path thus following the root(N) curve closely. But this seems silly because it implies to some degree that you can predict the motion of the path (either a bounce or a flattening of the trajectory). Hence my confusion!","Given a 1D random walk (simple +1, -1 movements from the axis) I've seen proofs that the expected absolute distance tends to Sqrt(2*n/PI) and I've plotted graphs of 1D random walks along with this curve along and the associated standard deviation of the absolute distance. As expected most walks can be found in the area around the expected absolute distance curve up to 2 standard deviations from it. Now take a walk that zooms steeply up or down towards the 2 standard deviation line from the expected absolute distance curve. From what little I understand of statistics very few random walks should be found above this line - 95% rule (and indeed my graphs confirm this). So doesn't this imply that such a walk should therefore most likely turn around and head back into the area closer to the expected absolute distance curve? Or at least continue on its original direction but at a less steep path thus following the root(N) curve closely. But this seems silly because it implies to some degree that you can predict the motion of the path (either a bounce or a flattening of the trajectory). Hence my confusion!",,"['probability', 'statistics', 'random-walk']"
36,Confidence Interval has no relation to the probability?,Confidence Interval has no relation to the probability?,,"An Intro to Stats class has the following problem: Find and interpret the 90% confidence interval for the true mean The provided answer is this: The probability is either 1 or 0.  Its either true or it isn't! No maybes. This answer confuses me. I thought the 90% confidence interval means there's a 90% probability that the mean is in that interval. Does the confidence interval really have no bearing on the probability? Can someone explain why the provided answer makes sense at an introductory level? I've looked at this question , but it doesn't seem to answer my question at all.","An Intro to Stats class has the following problem: Find and interpret the 90% confidence interval for the true mean The provided answer is this: The probability is either 1 or 0.  Its either true or it isn't! No maybes. This answer confuses me. I thought the 90% confidence interval means there's a 90% probability that the mean is in that interval. Does the confidence interval really have no bearing on the probability? Can someone explain why the provided answer makes sense at an introductory level? I've looked at this question , but it doesn't seem to answer my question at all.",,"['probability', 'statistics']"
37,to be 99% certain of making a profit? central limit theorem?,to be 99% certain of making a profit? central limit theorem?,,Let $X_i$ be the profit card $i$ makes when its sold. I let $S_n = X_1 + ... + X_n$ so total profit. I found the mean of $X$ to be $0.1$. and $E[X^2] = 25$ so variance $= 24.99$ Are these correct? And then I tried to use the central limit theorem. $P( \frac{S_n -n \mu}{\sigma / \sqrt n} < 2.3263) = 0.99$ But I am trying to find $P(S_n>0)$ right? how would i do this? Thanks.,Let $X_i$ be the profit card $i$ makes when its sold. I let $S_n = X_1 + ... + X_n$ so total profit. I found the mean of $X$ to be $0.1$. and $E[X^2] = 25$ so variance $= 24.99$ Are these correct? And then I tried to use the central limit theorem. $P( \frac{S_n -n \mu}{\sigma / \sqrt n} < 2.3263) = 0.99$ But I am trying to find $P(S_n>0)$ right? how would i do this? Thanks.,,"['probability', 'statistics', 'probability-theory']"
38,"Finding the MLE estimates of a beta, binomial hierarchical model","Finding the MLE estimates of a beta, binomial hierarchical model",,"Consider $M$ observations ($x_i$, $n_i$) where $x_i$ is a realisation from $X_i \sim \mbox{Binomial}(n_i,p_i)$ and $p_i$ is a realisation from $P_i \sim Beta(\alpha, \beta)$. I would like to find the maximum likelihood estimates of $\alpha, \beta$. I begin by writing $$\prod_{i=1}^MPr(x_i|\alpha, \beta, n_i) = \prod_{i=1}^M \int_0^1Pr(x_i|p_i,\alpha, \beta, n_i)Pr(p_i|\alpha, \beta, n_i)dp_i$$ $$=\prod_{i=1}^M \int_0^1 {n_i \choose x_i} x_i^{p_i} (n_i-x_i)^{1-p_i} \frac{p_i^{\alpha-1} (1-p_i)^{\beta-1}}{B(\alpha,\beta)}dp_i$$ $$=B(\alpha,\beta)^{-M}\prod_{i=1}^M {n_i \choose x_i}\int_0^1  x_i^{p_i} (n_i-x_i)^{1-p_i} p_i^{\alpha-1} (1-p_i)^{\beta-1}dp_i$$ By noting that $Pr(x_i|p_i,\alpha, \beta, n_i)= Pr(x_i|p_i, n_i)$ which is $\mbox{Binomial}(n_i,p_i)$ and $Pr(p_i|\alpha, \beta, n_i)= Pr(p_i|\alpha, \beta)$ which is $Beta(\alpha, \beta)$. However I cannot see a good way to proceed from here. I would be happy with a good numerical optimisation that could solve this in a relatively quick way. Is that possible?","Consider $M$ observations ($x_i$, $n_i$) where $x_i$ is a realisation from $X_i \sim \mbox{Binomial}(n_i,p_i)$ and $p_i$ is a realisation from $P_i \sim Beta(\alpha, \beta)$. I would like to find the maximum likelihood estimates of $\alpha, \beta$. I begin by writing $$\prod_{i=1}^MPr(x_i|\alpha, \beta, n_i) = \prod_{i=1}^M \int_0^1Pr(x_i|p_i,\alpha, \beta, n_i)Pr(p_i|\alpha, \beta, n_i)dp_i$$ $$=\prod_{i=1}^M \int_0^1 {n_i \choose x_i} x_i^{p_i} (n_i-x_i)^{1-p_i} \frac{p_i^{\alpha-1} (1-p_i)^{\beta-1}}{B(\alpha,\beta)}dp_i$$ $$=B(\alpha,\beta)^{-M}\prod_{i=1}^M {n_i \choose x_i}\int_0^1  x_i^{p_i} (n_i-x_i)^{1-p_i} p_i^{\alpha-1} (1-p_i)^{\beta-1}dp_i$$ By noting that $Pr(x_i|p_i,\alpha, \beta, n_i)= Pr(x_i|p_i, n_i)$ which is $\mbox{Binomial}(n_i,p_i)$ and $Pr(p_i|\alpha, \beta, n_i)= Pr(p_i|\alpha, \beta)$ which is $Beta(\alpha, \beta)$. However I cannot see a good way to proceed from here. I would be happy with a good numerical optimisation that could solve this in a relatively quick way. Is that possible?",,"['statistics', 'optimization', 'bayesian']"
39,Linear Algebra question relating to eigenvectors,Linear Algebra question relating to eigenvectors,,"Let A be an m x m positive definite symmetric matrix with eigenvalue-eigenvector pairs $(\lambda_1,e_1),....,(\lambda_m,e_m).$ The eigenvectors are orthonormal. Let $C = e_1e_1'+....+e_me_m'$. Find $Ce_j$, $j=1$, ..., $m$. Also, for $x \in R^m$, find $x - Cx$. i) $Ce_j = e_1e_1e_j+....+e_me_m'e_j$. ii) $x - Cx = (x-e_1e_1'x+....+x-e_me_m'x)$ Not sure if I'm heading in the right direction or not.","Let A be an m x m positive definite symmetric matrix with eigenvalue-eigenvector pairs $(\lambda_1,e_1),....,(\lambda_m,e_m).$ The eigenvectors are orthonormal. Let $C = e_1e_1'+....+e_me_m'$. Find $Ce_j$, $j=1$, ..., $m$. Also, for $x \in R^m$, find $x - Cx$. i) $Ce_j = e_1e_1e_j+....+e_me_m'e_j$. ii) $x - Cx = (x-e_1e_1'x+....+x-e_me_m'x)$ Not sure if I'm heading in the right direction or not.",,"['linear-algebra', 'statistics', 'eigenvalues-eigenvectors', 'statistical-inference', 'eigenfunctions']"
40,Calculating Moments,Calculating Moments,,"The following problem is from a Schaum book on statistics. While I thought I did it right, I did not come up with the right answer. Therefore, I am thinking I did something wrong. Problem: Find (a) the moment generating function of the random variable $ x = \begin{cases}     \, \frac{1}{2} &\text{ prob. 1/2} \\     -\frac{1}{2} &\text{ prob. 1/2} \\     \end{cases} $ and (b) the first four moments about the origin. Answer: The moment generating function for $x$ is: $M_x(t) = E(e^{tx})$ Since $x$ can have only two values, this gives us the following function: $ M_x(t) = \frac{1}{2}e^{\frac{t}{2}} + \frac{1}{2}e^{-\frac{t}{2}} $ Now to find the first four moments about the origin, I compute the first four derivatives of $M_x(t)$. $ M_x'(t) = \frac{1}{4}e^{\frac{t}{2}} - \frac{1}{4}e^{-\frac{t}{2}} $ $ M_x''(t) = \frac{1}{8}e^{\frac{t}{2}} + \frac{1}{8}e^{-\frac{t}{2}} $ $ M_x'''(t) = \frac{1}{16}e^{\frac{t}{2}} - \frac{1}{16}e^{-\frac{t}{2}} $ $ M_x''''(t) = \frac{1}{32}e^{\frac{t}{2}} + \frac{1}{32}e^{-\frac{t}{2}} $ Now, let $u_1, u_2, u_3, u_4$ be the first four moments of $x$. $ u_1 = M_x'(0) = \frac{1}{4}e^{\frac{0}{2}} - \frac{1}{4}e^{-\frac{0}{2}} $ $ u_1 = \frac{1}{4} - \frac{1}{4} = 0 $ $ u_2 = M_x''(0) = \frac{1}{8}e^{\frac{0}{2}} + \frac{1}{8}e^{-\frac{0}{2}} $ $ u_2 = \frac{1}{8} + \frac{1}{8} = \frac{1}{4} $ $ u_3 = M_x'''(0) =     \frac{1}{16}e^{\frac{0}{2}} - \frac{1}{16}e^{-\frac{0}{2}} $ $u_3 = \frac{1}{16} - \frac{1}{16} = 0 $ $ u_4 = M_x''''(0) =     \frac{1}{32}e^{\frac{0}{2}} + \frac{1}{32}e^{-\frac{0}{2}} $ $ u_4 = \frac{1}{32} + \frac{1}{32} = \frac{1}{16} $ However, the books answer is: $ u_1 = 0 $ $ u_2 = 1 $ $ u_3 = 0 $ $u_4 = 1 $ I do not understand what I am doing wrong and I am hoping that somebody here can tell me. Thanks Bob","The following problem is from a Schaum book on statistics. While I thought I did it right, I did not come up with the right answer. Therefore, I am thinking I did something wrong. Problem: Find (a) the moment generating function of the random variable $ x = \begin{cases}     \, \frac{1}{2} &\text{ prob. 1/2} \\     -\frac{1}{2} &\text{ prob. 1/2} \\     \end{cases} $ and (b) the first four moments about the origin. Answer: The moment generating function for $x$ is: $M_x(t) = E(e^{tx})$ Since $x$ can have only two values, this gives us the following function: $ M_x(t) = \frac{1}{2}e^{\frac{t}{2}} + \frac{1}{2}e^{-\frac{t}{2}} $ Now to find the first four moments about the origin, I compute the first four derivatives of $M_x(t)$. $ M_x'(t) = \frac{1}{4}e^{\frac{t}{2}} - \frac{1}{4}e^{-\frac{t}{2}} $ $ M_x''(t) = \frac{1}{8}e^{\frac{t}{2}} + \frac{1}{8}e^{-\frac{t}{2}} $ $ M_x'''(t) = \frac{1}{16}e^{\frac{t}{2}} - \frac{1}{16}e^{-\frac{t}{2}} $ $ M_x''''(t) = \frac{1}{32}e^{\frac{t}{2}} + \frac{1}{32}e^{-\frac{t}{2}} $ Now, let $u_1, u_2, u_3, u_4$ be the first four moments of $x$. $ u_1 = M_x'(0) = \frac{1}{4}e^{\frac{0}{2}} - \frac{1}{4}e^{-\frac{0}{2}} $ $ u_1 = \frac{1}{4} - \frac{1}{4} = 0 $ $ u_2 = M_x''(0) = \frac{1}{8}e^{\frac{0}{2}} + \frac{1}{8}e^{-\frac{0}{2}} $ $ u_2 = \frac{1}{8} + \frac{1}{8} = \frac{1}{4} $ $ u_3 = M_x'''(0) =     \frac{1}{16}e^{\frac{0}{2}} - \frac{1}{16}e^{-\frac{0}{2}} $ $u_3 = \frac{1}{16} - \frac{1}{16} = 0 $ $ u_4 = M_x''''(0) =     \frac{1}{32}e^{\frac{0}{2}} + \frac{1}{32}e^{-\frac{0}{2}} $ $ u_4 = \frac{1}{32} + \frac{1}{32} = \frac{1}{16} $ However, the books answer is: $ u_1 = 0 $ $ u_2 = 1 $ $ u_3 = 0 $ $u_4 = 1 $ I do not understand what I am doing wrong and I am hoping that somebody here can tell me. Thanks Bob",,"['probability', 'statistics']"
41,"Prove that $E(\mathbf{u}|\mathbf{X})=\mathbf{0}$ implies $Cov(\mathbf{x},\mathbf{u})=\mathbf{0}$",Prove that  implies,"E(\mathbf{u}|\mathbf{X})=\mathbf{0} Cov(\mathbf{x},\mathbf{u})=\mathbf{0}","Let \begin{equation} \mathbf{y}=\mathbf{X}\mathbf{\beta}+\mathbf{u} \end{equation} where $\mathbf{y}=\begin{bmatrix}y_1 \\ \vdots \\ y_n\end{bmatrix}$, $\mathbf{X}=\begin{bmatrix}X_{11} & \cdots & X_{1k} \\ \vdots & \ddots & \vdots \\ X_{n1} & \cdots & X_{nk}\end{bmatrix}$, or also written $\mathbf{X}=\begin{bmatrix}\mathbf{x}_1 \\ \vdots \\ \mathbf{x}_n\end{bmatrix}$ (where each $\mathbf{x}_i$ is a $k \times 1$ vector), $\mathbf{\beta}=\begin{bmatrix}\beta_1 \\ \vdots \\ \beta_k\end{bmatrix}$, and $\mathbf{u}=\begin{bmatrix}u_1 \\ \vdots \\ u_n\end{bmatrix}$. Suppose that $E(\mathbf{u}|\mathbf{X})=\mathbf{0}$. It is clear this implies that $E(\mathbf{u})=\mathbf{0}$ since by the Law of Iterated Expectations, \begin{equation} E\left(\mathbf{u}\right)=E\left[E\left(\mathbf{u}\middle\vert\mathbf{X}\right)\right]=E\left(\mathbf{0}\right)=\mathbf{0}. \end{equation} However, I want to show a similar result for the covariances, i.e. show that $E(\mathbf{u}|\mathbf{X})=\mathbf{0}$ implies $Cov(\mathbf{x},\mathbf{u})=0$ for all $\mathbf{x}$, where $\mathbf{x}$ is a column of the matrix $\mathbf{X}$. My attempt: Let $\mathbf{x}$ denote a column of the matrix $\mathbf{X}$. Then, \begin{align} Cov\left(\mathbf{u},\mathbf{x}\right)&=E\left[\left(\mathbf{u}-E(\mathbf{u})\right)\left(\mathbf{x}-E(\mathbf{x})\right)^{\top}\right] \\ &=E\left(\mathbf{u}\mathbf{x}^{\top}\right)-E\left(\mathbf{u}\right)E\left(\mathbf{x}^{\top}\right) \\ &=E\left(\mathbf{u}\mathbf{x}^{\top}\right) \\ &=E\left[E\left(\mathbf{u}\mathbf{x}^{\top}|\mathbf{X}\right)\right] \\ &=E\left[E\left(\mathbf{u}|\mathbf{X}\right)\mathbf{x}^{\top}\right] \\ &=E\left[\mathbf{0}\cdot\mathbf{x}^{\top}\right] \\ &=\mathbf{0}_{n\times n} \end{align} Is this argument correct?","Let \begin{equation} \mathbf{y}=\mathbf{X}\mathbf{\beta}+\mathbf{u} \end{equation} where $\mathbf{y}=\begin{bmatrix}y_1 \\ \vdots \\ y_n\end{bmatrix}$, $\mathbf{X}=\begin{bmatrix}X_{11} & \cdots & X_{1k} \\ \vdots & \ddots & \vdots \\ X_{n1} & \cdots & X_{nk}\end{bmatrix}$, or also written $\mathbf{X}=\begin{bmatrix}\mathbf{x}_1 \\ \vdots \\ \mathbf{x}_n\end{bmatrix}$ (where each $\mathbf{x}_i$ is a $k \times 1$ vector), $\mathbf{\beta}=\begin{bmatrix}\beta_1 \\ \vdots \\ \beta_k\end{bmatrix}$, and $\mathbf{u}=\begin{bmatrix}u_1 \\ \vdots \\ u_n\end{bmatrix}$. Suppose that $E(\mathbf{u}|\mathbf{X})=\mathbf{0}$. It is clear this implies that $E(\mathbf{u})=\mathbf{0}$ since by the Law of Iterated Expectations, \begin{equation} E\left(\mathbf{u}\right)=E\left[E\left(\mathbf{u}\middle\vert\mathbf{X}\right)\right]=E\left(\mathbf{0}\right)=\mathbf{0}. \end{equation} However, I want to show a similar result for the covariances, i.e. show that $E(\mathbf{u}|\mathbf{X})=\mathbf{0}$ implies $Cov(\mathbf{x},\mathbf{u})=0$ for all $\mathbf{x}$, where $\mathbf{x}$ is a column of the matrix $\mathbf{X}$. My attempt: Let $\mathbf{x}$ denote a column of the matrix $\mathbf{X}$. Then, \begin{align} Cov\left(\mathbf{u},\mathbf{x}\right)&=E\left[\left(\mathbf{u}-E(\mathbf{u})\right)\left(\mathbf{x}-E(\mathbf{x})\right)^{\top}\right] \\ &=E\left(\mathbf{u}\mathbf{x}^{\top}\right)-E\left(\mathbf{u}\right)E\left(\mathbf{x}^{\top}\right) \\ &=E\left(\mathbf{u}\mathbf{x}^{\top}\right) \\ &=E\left[E\left(\mathbf{u}\mathbf{x}^{\top}|\mathbf{X}\right)\right] \\ &=E\left[E\left(\mathbf{u}|\mathbf{X}\right)\mathbf{x}^{\top}\right] \\ &=E\left[\mathbf{0}\cdot\mathbf{x}^{\top}\right] \\ &=\mathbf{0}_{n\times n} \end{align} Is this argument correct?",,"['probability', 'statistics', 'expectation', 'regression', 'least-squares']"
42,What Field of Probability Deals With The Following,What Field of Probability Deals With The Following,,"Say there is this hypothetical lottery. A ticket is USD 1.00; the chance of winning is 1 in 100,000,000,000,000,000; but the prize is more than  USD 100,000,000,000,000,000. (For he sake of this argument, please ignore things such as “there is no such amount of money in this world,” etc.) Mathematically, I should buy a ticket; on the other hand, any rational person would know that is an awfully-wasted one dollar. What field of statistics, probability, or science, deals with such things? (First I thought it could be Subjective Probability, but I think not.)","Say there is this hypothetical lottery. A ticket is USD 1.00; the chance of winning is 1 in 100,000,000,000,000,000; but the prize is more than  USD 100,000,000,000,000,000. (For he sake of this argument, please ignore things such as “there is no such amount of money in this world,” etc.) Mathematically, I should buy a ticket; on the other hand, any rational person would know that is an awfully-wasted one dollar. What field of statistics, probability, or science, deals with such things? (First I thought it could be Subjective Probability, but I think not.)",,['statistics']
43,Beta/Dirichlet question,Beta/Dirichlet question,,"A generalization of the beta distribution is the Dirichlet distribution. In its bi-variate version, (X,Y) have pdf $f(x,y) = Cx^{a-1}y^{b-1}(1-x-y)^{c-1}, 0<x<1, 0<y<1, 0<y<1-x<1$ , where $a>0,b>0, c> 0 $ are constants. (a)Show that $C = \frac{\Gamma(a)\Gamma(b)\Gamma(c)}{\Gamma(a+b+c)}$ (b) Show that, marginally, both X and Y are beta. (c) Find the conditional distribution of $Y|X=x$ and show that $Y/(1-x)$ is beta(b,c). (d) Show that $E(XY) =\frac{ab}{(a+b+c+1)(a+b+c)}$ , and find their covariance. Attempt at (a): $\int_0^1\int_0^{1-x} x^{a-1}y^{b-1}(1-x-y)^{c-1}dx dy$ $\int_0^1x^{a-1}\int_0^{1-x} y^{b-1}(1-x-y)^{c-1}dx dy$ Let $u=\frac{y}{(1-x)}$ $\int_0^1x^{a-1}(1-x)^{b+c-1}dx\int_0^1 u^{b-1}(1-u)^{c-1}du$ $\int_0^1x^{a-1}(1-x)^{b+c-1}dx*\frac{\Gamma(b)\Gamma(c)}{\Gamma(b+c)}$ $\frac{\Gamma(b)\Gamma(c)}{\Gamma(b+c)}\int_0^1x^{a-1}(1-x)^{b+c-1}dx$ $\frac{\Gamma(b)\Gamma(c)}{\Gamma(b+c)}\frac{\Gamma(a)\Gamma(b+c)}{\Gamma(a+b+c)}$ $\frac{\Gamma(a)\Gamma(b)\Gamma(c)}{\Gamma(a+b+c)}$ Not sure how to correctly do parts b-d","A generalization of the beta distribution is the Dirichlet distribution. In its bi-variate version, (X,Y) have pdf , where are constants. (a)Show that (b) Show that, marginally, both X and Y are beta. (c) Find the conditional distribution of and show that is beta(b,c). (d) Show that , and find their covariance. Attempt at (a): Let Not sure how to correctly do parts b-d","f(x,y) = Cx^{a-1}y^{b-1}(1-x-y)^{c-1}, 0<x<1, 0<y<1, 0<y<1-x<1 a>0,b>0, c> 0  C = \frac{\Gamma(a)\Gamma(b)\Gamma(c)}{\Gamma(a+b+c)} Y|X=x Y/(1-x) E(XY) =\frac{ab}{(a+b+c+1)(a+b+c)} \int_0^1\int_0^{1-x} x^{a-1}y^{b-1}(1-x-y)^{c-1}dx dy \int_0^1x^{a-1}\int_0^{1-x} y^{b-1}(1-x-y)^{c-1}dx dy u=\frac{y}{(1-x)} \int_0^1x^{a-1}(1-x)^{b+c-1}dx\int_0^1 u^{b-1}(1-u)^{c-1}du \int_0^1x^{a-1}(1-x)^{b+c-1}dx*\frac{\Gamma(b)\Gamma(c)}{\Gamma(b+c)} \frac{\Gamma(b)\Gamma(c)}{\Gamma(b+c)}\int_0^1x^{a-1}(1-x)^{b+c-1}dx \frac{\Gamma(b)\Gamma(c)}{\Gamma(b+c)}\frac{\Gamma(a)\Gamma(b+c)}{\Gamma(a+b+c)} \frac{\Gamma(a)\Gamma(b)\Gamma(c)}{\Gamma(a+b+c)}","['probability', 'statistics', 'probability-theory', 'probability-distributions', 'conditional-probability']"
44,Why is $E(u)=0$ when an intercept is included in OLS Estimation?,Why is  when an intercept is included in OLS Estimation?,E(u)=0,"I am reading Wooldridge's graduate econometrics text. There he states that when estimating the equation $y=\mathbf{x\beta}+u$ by OLS, if an intercept (constant term) is included in your $\mathbf{x}$ vector, so that $\mathbf{x}=(1,x_1,...,x_k)$, where $y$ and the other $x_1,...,x_k$ are random variables, then we have automatically that $E(u)=0$. I  am trying to see why. Later on, when the textbook introduces OLS, one of the assumptions is that $E(\mathbf{x}^{\top}u)=\mathbf{0}$. Now note that if $\mathbf{x}$ contains an intercept, then this statement implies that $E(u)=0$. However I believe this assumption is not needed to know that when an intercept is included, then $E(u)=0$, rather we have $E(u)=0$ ""for free"" as the textbook says. I found a similar question (with name not representative of its question/answer) located here: Why the expected value of the error when doing regression by OLS is 0? which says the constant effectively ""absorbs"" $E(u)$ to make $E(u)=0$. How does this work, in theory? My questions: How do we know that an intercept ""absorbs"" $E(u)$ exactly -- no more, no less? Does this rely on the assumption $E(\mathbf{x}^{\top}u)=\mathbf{0}$? Thanks! Edit My econometrics instructor notes that if we include an intercept, so that \begin{equation}y=\beta_0+\mathbf{x\beta}+u,\end{equation} where $E(u)=\alpha\ne0$, then we can always rewrite the first equation as \begin{align*} y&=(\alpha+\beta_0)+\mathbf{x\beta}+(u-\alpha) \\ &=(\alpha+\beta_0)+\mathbf{x\beta}+\tilde{u}, \end{align*} where $\tilde{u}=u-\alpha$ and $E(\tilde{u})=0$. However this still doesn't explain how we get $E(u)$, so that we can ""include"" it in our intercept. (We can only estimate $E(u)$, but how do we do that?) I know that if $x_0=1$ and all the other $x_1,...,x_k$ equal $0$ then what really happens is $\hat{\beta}=(x^{\top}x)^{-1}x^{\top}y=y$... Am I getting there?","I am reading Wooldridge's graduate econometrics text. There he states that when estimating the equation $y=\mathbf{x\beta}+u$ by OLS, if an intercept (constant term) is included in your $\mathbf{x}$ vector, so that $\mathbf{x}=(1,x_1,...,x_k)$, where $y$ and the other $x_1,...,x_k$ are random variables, then we have automatically that $E(u)=0$. I  am trying to see why. Later on, when the textbook introduces OLS, one of the assumptions is that $E(\mathbf{x}^{\top}u)=\mathbf{0}$. Now note that if $\mathbf{x}$ contains an intercept, then this statement implies that $E(u)=0$. However I believe this assumption is not needed to know that when an intercept is included, then $E(u)=0$, rather we have $E(u)=0$ ""for free"" as the textbook says. I found a similar question (with name not representative of its question/answer) located here: Why the expected value of the error when doing regression by OLS is 0? which says the constant effectively ""absorbs"" $E(u)$ to make $E(u)=0$. How does this work, in theory? My questions: How do we know that an intercept ""absorbs"" $E(u)$ exactly -- no more, no less? Does this rely on the assumption $E(\mathbf{x}^{\top}u)=\mathbf{0}$? Thanks! Edit My econometrics instructor notes that if we include an intercept, so that \begin{equation}y=\beta_0+\mathbf{x\beta}+u,\end{equation} where $E(u)=\alpha\ne0$, then we can always rewrite the first equation as \begin{align*} y&=(\alpha+\beta_0)+\mathbf{x\beta}+(u-\alpha) \\ &=(\alpha+\beta_0)+\mathbf{x\beta}+\tilde{u}, \end{align*} where $\tilde{u}=u-\alpha$ and $E(\tilde{u})=0$. However this still doesn't explain how we get $E(u)$, so that we can ""include"" it in our intercept. (We can only estimate $E(u)$, but how do we do that?) I know that if $x_0=1$ and all the other $x_1,...,x_k$ equal $0$ then what really happens is $\hat{\beta}=(x^{\top}x)^{-1}x^{\top}y=y$... Am I getting there?",,"['statistics', 'expectation', 'regression', 'least-squares']"
45,Birthday Problem: Big Numbers and Distribution of the Number of Samples involved in Collisions,Birthday Problem: Big Numbers and Distribution of the Number of Samples involved in Collisions,,"A lot of questions about the birthday problem can be found here, but none seems to address my problem: Background I am thinking of a hash-type data structure design which accepts a certain number of collisions to occur. Collisions shall be detected and handled in a second data structure with substantially lower collision probabilities. The number I'm interested in is the number of datasets which go into the second data structure. Question I do not care if there are 4 'children' having birthday at the same 'day' or 2 pairs of children where each pair shares a certain birthday. Both would be counted as 4 children being involved in collisions. Also I do not care about exact results, approximations would be fine. My Question is: Given n persons and m days possible for birthdays. How to calculate the probability of k=2,3,4,5,... persons being involved in collisions? Clarification Apparently, the main problem is that I need to handle pretty big values. My dimensions are about: ""Lets say a year had 100,000 days (alternatively 1,000,000 days). Then think of a class of 50.000 kids. Whats the probability of everyone has  a unique birthday. Whats the probability of 1-20, 20-50, 50-100 kids not having a unique birthday?"" As I said, results must not be perfectly exact.","A lot of questions about the birthday problem can be found here, but none seems to address my problem: Background I am thinking of a hash-type data structure design which accepts a certain number of collisions to occur. Collisions shall be detected and handled in a second data structure with substantially lower collision probabilities. The number I'm interested in is the number of datasets which go into the second data structure. Question I do not care if there are 4 'children' having birthday at the same 'day' or 2 pairs of children where each pair shares a certain birthday. Both would be counted as 4 children being involved in collisions. Also I do not care about exact results, approximations would be fine. My Question is: Given n persons and m days possible for birthdays. How to calculate the probability of k=2,3,4,5,... persons being involved in collisions? Clarification Apparently, the main problem is that I need to handle pretty big values. My dimensions are about: ""Lets say a year had 100,000 days (alternatively 1,000,000 days). Then think of a class of 50.000 kids. Whats the probability of everyone has  a unique birthday. Whats the probability of 1-20, 20-50, 50-100 kids not having a unique birthday?"" As I said, results must not be perfectly exact.",,"['statistics', 'probability-distributions']"
46,Proving Negative of Standard Normal is Standard Normal,Proving Negative of Standard Normal is Standard Normal,,"Let X be standard normal random variable $N(1, 0)$ prove that $-X$ is also standard normal. I think I am stuck on a technicality but here is my attempt: Let $Y = -X$ P(Y $\leq$ u) = P($-X$ $\leq$ u) = P($X$ > -u) = 1 - P($X$ $\leq$ -u) = 1 - (1 - P($X$ $\leq$ u) = P($X$ $\leq$ u) which proves the result. However I am not sure if my last step 1 - P($X$ $\leq$ -u) = 1 - (1 - P($X$ $\leq$ u) is justified.  I would appreciate a hint.","Let X be standard normal random variable $N(1, 0)$ prove that $-X$ is also standard normal. I think I am stuck on a technicality but here is my attempt: Let $Y = -X$ P(Y $\leq$ u) = P($-X$ $\leq$ u) = P($X$ > -u) = 1 - P($X$ $\leq$ -u) = 1 - (1 - P($X$ $\leq$ u) = P($X$ $\leq$ u) which proves the result. However I am not sure if my last step 1 - P($X$ $\leq$ -u) = 1 - (1 - P($X$ $\leq$ u) is justified.  I would appreciate a hint.",,"['probability', 'statistics', 'random-variables']"
47,Hypothesis Testing help,Hypothesis Testing help,,"Really have no idea where to start :( In an experiment comparing two weight-loss regimes A and B 20 test subjects were matched into 10 pairs so that within each pair the subjects were as similar as possible. Then A was randomly allocated to one of the subjects in each pair, and then B allocated to the other. The number of kilograms lost for each person is obtained and then the ordered A−B differences for each pair (in kg) are given below in the object d, together with some summary statistics: sort(d)   [1] -0.9 -0.3 0.2 0.4 0.6 1.2 1.4 3.3 3.5 4.3 mean(d)   [1] 1.37 sd(d)   [1] 1.755025 By specifying and checking (with a boxplot) an appropriate normality assumption perform a formal hypothesis test of H0:“regimes the same” against H1:“regimes not the same”. Any help is appreciated!","Really have no idea where to start :( In an experiment comparing two weight-loss regimes A and B 20 test subjects were matched into 10 pairs so that within each pair the subjects were as similar as possible. Then A was randomly allocated to one of the subjects in each pair, and then B allocated to the other. The number of kilograms lost for each person is obtained and then the ordered A−B differences for each pair (in kg) are given below in the object d, together with some summary statistics: sort(d)   [1] -0.9 -0.3 0.2 0.4 0.6 1.2 1.4 3.3 3.5 4.3 mean(d)   [1] 1.37 sd(d)   [1] 1.755025 By specifying and checking (with a boxplot) an appropriate normality assumption perform a formal hypothesis test of H0:“regimes the same” against H1:“regimes not the same”. Any help is appreciated!",,"['statistics', 'hypothesis-testing']"
48,Help with financial modelling,Help with financial modelling,,"We deal with ""jobs"" - a mini project involving multiple parties, resources and time constraints, etc. Jobs progresses through 4 well defined states from start to end; call them S1, S2, S3 and S4 where S1 is the start of the job and S4 is where we have invoiced the client and the job is closed. Jobs are for different clients, in different regions and run by different people (project managers) within our company. Not every job in state S1 will make it to S4 as the job may be cancelled.  From historical data we can readily determine for each combination of client/region/project manager the probability of getting from S1 to S4, S2 to S4 and S3 to S4. Also the length of time from S1 to S4 may differ for each of these combinations so we also know historical average time to go from S1 to S4, S2 to S4 and S3 to S4. We may have 1000 jobs currently in progress. ie in states S1, S2 or S3.  We need to predict how much money we will be invoicing each week in the future. I don't think is a problem since it is little more than the sum for each future week of  current estimated value of the job x the probability that it will get from its current state to S4 and then apply this to a future invoicing week based on the historical average length of time to go from the current state to S4.  (be sure to call me out if this is flawed) You can imagine that this will produce a nice bar chart that will get senior management all excited. The problem I am facing is that the finance guys (who are actually really smart) would like to have some confidence intervals, margins or error (or standard deviations or the like) that will help them communicate where the numbers are really solid and where they start to become rubbery. I would imagine that the invoicing for the future few weeks where we are going from S3 to S4 should be highly accurate and the margin of error would be very small yet 3 months out I would like to think that the margin of error could be quite large. My problem is I do not know what to even ""google"" to solve this problem.  How do I go from the data that I have available to a margin of error? It is very binary in that a job either makes it to S4 or it doesn't. I remembered the binomial distribution but that does not look appropriate. I started thinking about standard distributions but this does not seem to work each since it does not make sense to have a standard deviation over boolean logic. One suggestion was that if there is a 50% chance of making it to S4, and the job value is $$1000  then apply $500 to the future invoicing week with $500 either side as a margin of error. On the surface this seems sensible but if there is only a 10% chance of making it S4 then would you attribute $100 to the future invoicing week with a + / -$900 margin of error (or maybe +$900 / -$100).  +$900 seems far too high when the probability of getting to S4 is so low and when all of the work in progress is considered the upper bound of the margin of error will be huge and totally unrealistic. Any tips and pointers would be greatly appreciated.  Keep it simple. I is an engineer but my stats were forgotten two beers after the exam.","We deal with ""jobs"" - a mini project involving multiple parties, resources and time constraints, etc. Jobs progresses through 4 well defined states from start to end; call them S1, S2, S3 and S4 where S1 is the start of the job and S4 is where we have invoiced the client and the job is closed. Jobs are for different clients, in different regions and run by different people (project managers) within our company. Not every job in state S1 will make it to S4 as the job may be cancelled.  From historical data we can readily determine for each combination of client/region/project manager the probability of getting from S1 to S4, S2 to S4 and S3 to S4. Also the length of time from S1 to S4 may differ for each of these combinations so we also know historical average time to go from S1 to S4, S2 to S4 and S3 to S4. We may have 1000 jobs currently in progress. ie in states S1, S2 or S3.  We need to predict how much money we will be invoicing each week in the future. I don't think is a problem since it is little more than the sum for each future week of  current estimated value of the job x the probability that it will get from its current state to S4 and then apply this to a future invoicing week based on the historical average length of time to go from the current state to S4.  (be sure to call me out if this is flawed) You can imagine that this will produce a nice bar chart that will get senior management all excited. The problem I am facing is that the finance guys (who are actually really smart) would like to have some confidence intervals, margins or error (or standard deviations or the like) that will help them communicate where the numbers are really solid and where they start to become rubbery. I would imagine that the invoicing for the future few weeks where we are going from S3 to S4 should be highly accurate and the margin of error would be very small yet 3 months out I would like to think that the margin of error could be quite large. My problem is I do not know what to even ""google"" to solve this problem.  How do I go from the data that I have available to a margin of error? It is very binary in that a job either makes it to S4 or it doesn't. I remembered the binomial distribution but that does not look appropriate. I started thinking about standard distributions but this does not seem to work each since it does not make sense to have a standard deviation over boolean logic. One suggestion was that if there is a 50% chance of making it to S4, and the job value is $$1000  then apply $500 to the future invoicing week with $500 either side as a margin of error. On the surface this seems sensible but if there is only a 10% chance of making it S4 then would you attribute $100 to the future invoicing week with a + / -$900 margin of error (or maybe +$900 / -$100).  +$900 seems far too high when the probability of getting to S4 is so low and when all of the work in progress is considered the upper bound of the margin of error will be huge and totally unrealistic. Any tips and pointers would be greatly appreciated.  Keep it simple. I is an engineer but my stats were forgotten two beers after the exam.",,['statistics']
49,Quibble with Dawkins's reasoning on the watch-stopping probability on a psychic audience,Quibble with Dawkins's reasoning on the watch-stopping probability on a psychic audience,,"In Unweaving the Rainbow (page 150) Richard Dawkins mentions the following (famous) reasoning on why it's almost certain that a psychic with a big audience will accurately predict/command rare events like watch-stopping: We can do a similar calculation for the television guru whose psychic miasma seemed to stop people's watches, but we'll have to use estimates rather than exact figures. Any given watch has a certain low probability of stopping at any moment. I don't know what this probability is, but here's the kind of way in which we could come to an estimate. If we take just digital watches, their battery typically runs out within a year. Approximately, then, a digital watch stops once per year. Presumably clockwork watches stop more often because people forget to wind them and presumably digital watches stop less often because people sometimes remember to renew the battery ahead of time. But both kinds of watches probably stop as often again because they develop faults of one kind or another. So, let our estimate be that any given watch is likely to stop about once a year. It doesn't matter too much how accurate our estimate is. The principle will remain. If somebody's watch stopped three weeks after the spell was cast, even the most credulous would prefer to put it down to chance. We need to decide how large a delay would have been judged by the audience as sufficiently simultaneous with the psychic's announcement to impress. About five minutes is certainly safe, especially since he can keep talking to each caller for a few minutes before the next call ceases to seem roughly simultaneous. There are about 100,000 five-minute periods in a year. The probability that any given watch, say mine, will stop in a designated five-minute period is about 1 in 100,000. Low odds, but there are 10 million people watching the show. If only half of them are wearing watches, we could expect about 25 of those watches to stop in any given minute. If only a quarter of these ring in to the studio, that is 6 calls, more than enough to dumbfound a naive audience. Especially when you add in the calls from people whose watches stopped the day before, people whose watches didn't stop but whose grandfather clocks did, people who died of heart attacks and their bereaved relatives phoned in to say that their ‘ticker’ gave out, and so on. I agree with the general reasoning but I'm confused as to how he gets to 25 there in the middle, I think it should be 50. This would NOT change at all the general point he's making but it seems big enough to point out. Can someone please help me see how he got to 25? Is it just a simple mistake on his part or mine? Here's my reasoning: The minutes in a year are 365 days * 24 hours * 60 min = 525,600 minutes. And that divided by 5, gives 105,120 five-minute periods in a year. So far, consistent with Dawkins account. He then asks us to consider a 10,000,000 audience, only half of whom are wearing watches, so 5,000,000 watch-wearing viewers. If we now multiply these by the probability of stopping in a five-minute period we get, 5,000,000 * (1/104,120) = 47.56. So, in a 5,000,000 watch-wearing audience ABOUT 50 watches are expected to stop in a 5-minute-period, not 25 as he claims. (Note that his statement is rather ambiguous, if we interpret ""in any given minute"" as being literally how many watches we expect to stop in ONE minute then the answer is 9.5, so about 10... still not 25.) Thanks.","In Unweaving the Rainbow (page 150) Richard Dawkins mentions the following (famous) reasoning on why it's almost certain that a psychic with a big audience will accurately predict/command rare events like watch-stopping: We can do a similar calculation for the television guru whose psychic miasma seemed to stop people's watches, but we'll have to use estimates rather than exact figures. Any given watch has a certain low probability of stopping at any moment. I don't know what this probability is, but here's the kind of way in which we could come to an estimate. If we take just digital watches, their battery typically runs out within a year. Approximately, then, a digital watch stops once per year. Presumably clockwork watches stop more often because people forget to wind them and presumably digital watches stop less often because people sometimes remember to renew the battery ahead of time. But both kinds of watches probably stop as often again because they develop faults of one kind or another. So, let our estimate be that any given watch is likely to stop about once a year. It doesn't matter too much how accurate our estimate is. The principle will remain. If somebody's watch stopped three weeks after the spell was cast, even the most credulous would prefer to put it down to chance. We need to decide how large a delay would have been judged by the audience as sufficiently simultaneous with the psychic's announcement to impress. About five minutes is certainly safe, especially since he can keep talking to each caller for a few minutes before the next call ceases to seem roughly simultaneous. There are about 100,000 five-minute periods in a year. The probability that any given watch, say mine, will stop in a designated five-minute period is about 1 in 100,000. Low odds, but there are 10 million people watching the show. If only half of them are wearing watches, we could expect about 25 of those watches to stop in any given minute. If only a quarter of these ring in to the studio, that is 6 calls, more than enough to dumbfound a naive audience. Especially when you add in the calls from people whose watches stopped the day before, people whose watches didn't stop but whose grandfather clocks did, people who died of heart attacks and their bereaved relatives phoned in to say that their ‘ticker’ gave out, and so on. I agree with the general reasoning but I'm confused as to how he gets to 25 there in the middle, I think it should be 50. This would NOT change at all the general point he's making but it seems big enough to point out. Can someone please help me see how he got to 25? Is it just a simple mistake on his part or mine? Here's my reasoning: The minutes in a year are 365 days * 24 hours * 60 min = 525,600 minutes. And that divided by 5, gives 105,120 five-minute periods in a year. So far, consistent with Dawkins account. He then asks us to consider a 10,000,000 audience, only half of whom are wearing watches, so 5,000,000 watch-wearing viewers. If we now multiply these by the probability of stopping in a five-minute period we get, 5,000,000 * (1/104,120) = 47.56. So, in a 5,000,000 watch-wearing audience ABOUT 50 watches are expected to stop in a 5-minute-period, not 25 as he claims. (Note that his statement is rather ambiguous, if we interpret ""in any given minute"" as being literally how many watches we expect to stop in ONE minute then the answer is 9.5, so about 10... still not 25.) Thanks.",,"['probability', 'statistics']"
50,Prove that the the variance estimator $\widehat{\sigma}^2=MSE/(n-2)$ is biased is the simple linear regression model,Prove that the the variance estimator  is biased is the simple linear regression model,\widehat{\sigma}^2=MSE/(n-2),"This is in scope of the simple linear model. Im trying to prove that $\mathbb{E}\left(\widehat{\sigma}^2\right) = \sigma^2$ for $$\widehat{\sigma}^2 = \frac{1}{n-2}\sum^n_{i=1} \left(y_i-\widehat{y}_i\right)^2$$ where $$Y_i\sim N(\beta_0+\beta_1x_i,\sigma^2)$$ and $\widehat{y_i},i=1,2,3,...,n$ are pedricted values and $y_1,y_2,...,y_n$ is a sample from $Y_i$","This is in scope of the simple linear model. Im trying to prove that $\mathbb{E}\left(\widehat{\sigma}^2\right) = \sigma^2$ for $$\widehat{\sigma}^2 = \frac{1}{n-2}\sum^n_{i=1} \left(y_i-\widehat{y}_i\right)^2$$ where $$Y_i\sim N(\beta_0+\beta_1x_i,\sigma^2)$$ and $\widehat{y_i},i=1,2,3,...,n$ are pedricted values and $y_1,y_2,...,y_n$ is a sample from $Y_i$",,"['statistics', 'regression', 'statistical-inference', 'regression-analysis']"
51,Log likelihood function for logistic regression,Log likelihood function for logistic regression,,"If the training set S represents are an independent and identically distributed (i.i.d.) sample of a Bernoulli distribution and in logistic regression log likelihood function is given as, $$L(y_i,f)=-\sum_{i=1}^m {{y_i} \text{log } \pi(x_i)+ (1-y_i)\text{log }(1-\pi(x_i)}$$ but in paper's log likelihood function is also written as $$L(y_i,f)=\sum_{i=1}^n \log(1+e^{-y_if(x_i)})$$ I am confused are these two expression same or they are different. If same how to derive the second equation from first.","If the training set S represents are an independent and identically distributed (i.i.d.) sample of a Bernoulli distribution and in logistic regression log likelihood function is given as, $$L(y_i,f)=-\sum_{i=1}^m {{y_i} \text{log } \pi(x_i)+ (1-y_i)\text{log }(1-\pi(x_i)}$$ but in paper's log likelihood function is also written as $$L(y_i,f)=\sum_{i=1}^n \log(1+e^{-y_if(x_i)})$$ I am confused are these two expression same or they are different. If same how to derive the second equation from first.",,"['statistics', 'regression-analysis']"
52,Distribution Weibull,Distribution Weibull,,"I'm trying to find the parameters of the weibull distribution, the only thing that they gave me were the mean=EX=40 and the standard deviation=VX=35^2 I have gotten there so far but I'm stuck, have any idea of how to solve for beta and delta.  The values are supposed to be beta=1.14566 and delta=41.98348","I'm trying to find the parameters of the weibull distribution, the only thing that they gave me were the mean=EX=40 and the standard deviation=VX=35^2 I have gotten there so far but I'm stuck, have any idea of how to solve for beta and delta.  The values are supposed to be beta=1.14566 and delta=41.98348",,"['probability', 'statistics', 'descriptive-statistics']"
53,Kernel density estimation including measureed uncertainty,Kernel density estimation including measureed uncertainty,,"I am trying to plot the distribution of a measured variable from a scientific experiment, in this case a velocity. After making a simple histogram, I have been reading this, http://en.wikipedia.org/wiki/Kernel_density_estimation This seems to suggest that one can pretend each value actually is better represented by a normal distribution and that the total distribution can be found as the sum of the individual distributions, i.e. the kernels. It goes on to discuss the art of choosing the correct bandwidth for the kernel. My data, however, has known uncertainty. That is to say, I measure the velocity in six different ways, each of which gives me a slightly different answer. I then take the mean of these values and calculate the standard deviation as an estimate of my measurement uncertainty. My question is, can this extra information be included explicitly into the kernel density estimation process? Intuitively I feel that I could give each point a kernel whose bandwidth is the measured uncertainty for that point. Does this make sense? Is there an established way to do this? Thanks in advance, Nick","I am trying to plot the distribution of a measured variable from a scientific experiment, in this case a velocity. After making a simple histogram, I have been reading this, http://en.wikipedia.org/wiki/Kernel_density_estimation This seems to suggest that one can pretend each value actually is better represented by a normal distribution and that the total distribution can be found as the sum of the individual distributions, i.e. the kernels. It goes on to discuss the art of choosing the correct bandwidth for the kernel. My data, however, has known uncertainty. That is to say, I measure the velocity in six different ways, each of which gives me a slightly different answer. I then take the mean of these values and calculate the standard deviation as an estimate of my measurement uncertainty. My question is, can this extra information be included explicitly into the kernel density estimation process? Intuitively I feel that I could give each point a kernel whose bandwidth is the measured uncertainty for that point. Does this make sense? Is there an established way to do this? Thanks in advance, Nick",,"['statistics', 'probability-distributions']"
54,Errors and Residual,Errors and Residual,,"Why are errors independent but residuals dependent? As far i know the sum of the residuals within a random sample is necessarily zero, and thus the residuals are necessarily not independent. But also we assume that $\mathbb E(\epsilon)=0$. Why doesn't it imply errors are also not independent?","Why are errors independent but residuals dependent? As far i know the sum of the residuals within a random sample is necessarily zero, and thus the residuals are necessarily not independent. But also we assume that $\mathbb E(\epsilon)=0$. Why doesn't it imply errors are also not independent?",,"['statistics', 'normal-distribution', 'regression', 'statistical-inference', 'sampling']"
55,How to predict next number from a given set of measurement data?,How to predict next number from a given set of measurement data?,,"I have to do some experiment and measure it on a specific time  0, 3, 6, 9, 12, 18, 24, 36 months $$ \begin{array}{l|c|c|c|c|c|c} \text{Month}	&ID1 &    ID2	&    ID3	&    ID4	&    ID5	&    ID6\\\hline 0	   & 101.7&	102.6&	101.7	&100.5	&100.4	&103.4\\ 3	    &103.4	&103.3	&101.4	&101.7&	100.5	&101.2\\ 6	    &100.7	&103.7	&101.6	&102	   & 102.9&	102\\ 9	    &100.2	&100.6&	101.2&	97.9&	98.7	&99.5\\ 12	   & 99.8	&100.1&	x  &     98.6&	100.4	&100.1\\ 18	    &98.7&	x&		x	&	x      & x       &x\\ 24	    &101.3	&x		&x	&	x &      x&       x\\ 36	    &100.8	&x		&x&		x       &x  &     x\\ \end{array} $$ Basically, all the numbers are from the measurement. So, could anyone please suggest how do I predict the numbers represented as ""x"" here ? Assume each ID are different type of items/products/equipment to be measured. I would prefer to use the arithmetic mean and variance for the prediction. However, if anyone could suggest better idea, it would be nice. Thank you in advance, PTP","I have to do some experiment and measure it on a specific time  0, 3, 6, 9, 12, 18, 24, 36 months $$ \begin{array}{l|c|c|c|c|c|c} \text{Month}	&ID1 &    ID2	&    ID3	&    ID4	&    ID5	&    ID6\\\hline 0	   & 101.7&	102.6&	101.7	&100.5	&100.4	&103.4\\ 3	    &103.4	&103.3	&101.4	&101.7&	100.5	&101.2\\ 6	    &100.7	&103.7	&101.6	&102	   & 102.9&	102\\ 9	    &100.2	&100.6&	101.2&	97.9&	98.7	&99.5\\ 12	   & 99.8	&100.1&	x  &     98.6&	100.4	&100.1\\ 18	    &98.7&	x&		x	&	x      & x       &x\\ 24	    &101.3	&x		&x	&	x &      x&       x\\ 36	    &100.8	&x		&x&		x       &x  &     x\\ \end{array} $$ Basically, all the numbers are from the measurement. So, could anyone please suggest how do I predict the numbers represented as ""x"" here ? Assume each ID are different type of items/products/equipment to be measured. I would prefer to use the arithmetic mean and variance for the prediction. However, if anyone could suggest better idea, it would be nice. Thank you in advance, PTP",,['statistics']
56,How to prove a given statistical test has the greatest power,How to prove a given statistical test has the greatest power,,"It is very conventional in evaluating the null hypothesis to consider the distribution of the mean of a sample of some size if the null hypothesis were true and to compare the mean of your own sample to that distribution.  (At least if the underlying distribution is thought to be normal) But why, even given the normality assumption, do statisticians generally compare the distribution of the mean to the sample mean as opposed to comparing the distribution of some other statistic, say the median or the minimum, to the median (or minimum) of the sample. I believe the answer to my question is that the mean is a powerful statistic.  If the sample indeed did not come from the null hypothesis distribution, then the mean test is likely to pick it up.  It might take a much greater effect for the median or min test to obtain an adequately low p-value?  But, how do we KNOW that there are not better statistics than the mean?  Is there a proof out there in the literature?  Or how would one possibly go about proving it?","It is very conventional in evaluating the null hypothesis to consider the distribution of the mean of a sample of some size if the null hypothesis were true and to compare the mean of your own sample to that distribution.  (At least if the underlying distribution is thought to be normal) But why, even given the normality assumption, do statisticians generally compare the distribution of the mean to the sample mean as opposed to comparing the distribution of some other statistic, say the median or the minimum, to the median (or minimum) of the sample. I believe the answer to my question is that the mean is a powerful statistic.  If the sample indeed did not come from the null hypothesis distribution, then the mean test is likely to pick it up.  It might take a much greater effect for the median or min test to obtain an adequately low p-value?  But, how do we KNOW that there are not better statistics than the mean?  Is there a proof out there in the literature?  Or how would one possibly go about proving it?",,['statistics']
57,Finding similarity between elements using statistics,Finding similarity between elements using statistics,,I have a dataset of DJs in which I'm trying to find DJs similar to a specific DJ. Each DJ has a set of a genres with a certain percentage. How can I find the similarity between 2 DJs? The following is sample data of DJs with their song count and their percentage of songs in each genre. DJ Antoine: Songs: 105 Pop / Rock 0.95% Indie Dance / Nu Disco 0.95% Electronica 40.95% House 21.9% Electro House 10.48% Tech House 0.95% Progressive House 23.81%   Quentin Mosimann: Songs: 31 Progressive House 48.39% House 19.35% Hard Dance 3.23% Electro House 29.03%   Project 46: Songs: 20 Progressive House 80.0% Electro House 20.0%   Blasterjaxx: Songs: 62 Progressive House 20.97% House 12.9% Electro House 66.13%   D-Block & S-te-Fan: Songs: 13 Hard Dance 92.31% Hardcore / Hard Techno 7.69%   Dillon Francis: Songs: 53 Indie Dance / Nu Disco 15.09% Electronica 1.89% House 7.55% Breaks 1.89% Electro House 52.83% Chill Out 1.89% Dubstep 15.09% Tech House 1.89% Progressive House 1.89%   Dannic: Songs: 37 Progressive House 91.89% Trance 2.7% Electro House 2.7% House 2.7%   Adaro: Songs: 24 Trance 4.17% Hard Dance 62.5% House 4.17% Hardcore / Hard Techno 29.17%   Richie Hawtin: Songs: 79 Electronica 6.33% Chill Out 25.32% Techno 60.76% Minimal 5.06% Tech House 2.53%   Martin Solveig: Songs: 51 Electronica 7.84% House 37.25% Electro House 11.76% Chill Out 11.76% Deep House 9.8% Indie Dance / Nu Disco 13.73% Progressive House 1.96% Hip-Hop 5.88%   Felguk: Songs: 49 Psy-Trance 2.04% Dubstep 4.08% Electro House 93.88%   Myon & Shane 54: Songs: 68 Progressive House 10.29% Trance 83.82% Techno 1.47% Electro House 2.94% Tech House 1.47%   Cosmic Gate: Songs: 99 Progressive House 2.02% Trance 97.98%,I have a dataset of DJs in which I'm trying to find DJs similar to a specific DJ. Each DJ has a set of a genres with a certain percentage. How can I find the similarity between 2 DJs? The following is sample data of DJs with their song count and their percentage of songs in each genre. DJ Antoine: Songs: 105 Pop / Rock 0.95% Indie Dance / Nu Disco 0.95% Electronica 40.95% House 21.9% Electro House 10.48% Tech House 0.95% Progressive House 23.81%   Quentin Mosimann: Songs: 31 Progressive House 48.39% House 19.35% Hard Dance 3.23% Electro House 29.03%   Project 46: Songs: 20 Progressive House 80.0% Electro House 20.0%   Blasterjaxx: Songs: 62 Progressive House 20.97% House 12.9% Electro House 66.13%   D-Block & S-te-Fan: Songs: 13 Hard Dance 92.31% Hardcore / Hard Techno 7.69%   Dillon Francis: Songs: 53 Indie Dance / Nu Disco 15.09% Electronica 1.89% House 7.55% Breaks 1.89% Electro House 52.83% Chill Out 1.89% Dubstep 15.09% Tech House 1.89% Progressive House 1.89%   Dannic: Songs: 37 Progressive House 91.89% Trance 2.7% Electro House 2.7% House 2.7%   Adaro: Songs: 24 Trance 4.17% Hard Dance 62.5% House 4.17% Hardcore / Hard Techno 29.17%   Richie Hawtin: Songs: 79 Electronica 6.33% Chill Out 25.32% Techno 60.76% Minimal 5.06% Tech House 2.53%   Martin Solveig: Songs: 51 Electronica 7.84% House 37.25% Electro House 11.76% Chill Out 11.76% Deep House 9.8% Indie Dance / Nu Disco 13.73% Progressive House 1.96% Hip-Hop 5.88%   Felguk: Songs: 49 Psy-Trance 2.04% Dubstep 4.08% Electro House 93.88%   Myon & Shane 54: Songs: 68 Progressive House 10.29% Trance 83.82% Techno 1.47% Electro House 2.94% Tech House 1.47%   Cosmic Gate: Songs: 99 Progressive House 2.02% Trance 97.98%,,"['probability', 'statistics', 'data-analysis', 'clustering']"
58,Non-linear least squares with two dependent variables,Non-linear least squares with two dependent variables,,"I have data in the form $(t_i,x_i,y_i)$, i.e. position in 2D as a function of time. I have non-linear equations which I want to fit to the data. They give me a position $(X,Y)$ as a function of time and some other parameters. Let's call these $X(t;\theta)$ and $Y(t;\theta)$, where $\theta$ is a stand-in for a number of parameters. In a usual least squares fit of data with one dependent variable, say $(t_i,y_i)$, you minimise the sum of the squares of the residuals over your parameters $\theta$, where the residuals are given by $r_i=y_i-Y(t_i;\theta)$. My question is about the generalisation to two dependent variables. My intuition is that it is the same idea: minimise the sum of the squares of the residuals, but with the residuals given by $r_i=\sqrt{[x_i-X(t_i;\theta)]^2+[y_i-Y(t_i;\theta)]^2}$. However I cannot find a reference to confirm this. 1) Is this the correct method or not? 2) Also, and I am not sure if the following question is well-posed, do I have to worry about any covariance between $x$ and $y$? Or maybe equivalently, I have $\partial X/\partial Y \ne 0$, so is this something that must be taken into account somehow?","I have data in the form $(t_i,x_i,y_i)$, i.e. position in 2D as a function of time. I have non-linear equations which I want to fit to the data. They give me a position $(X,Y)$ as a function of time and some other parameters. Let's call these $X(t;\theta)$ and $Y(t;\theta)$, where $\theta$ is a stand-in for a number of parameters. In a usual least squares fit of data with one dependent variable, say $(t_i,y_i)$, you minimise the sum of the squares of the residuals over your parameters $\theta$, where the residuals are given by $r_i=y_i-Y(t_i;\theta)$. My question is about the generalisation to two dependent variables. My intuition is that it is the same idea: minimise the sum of the squares of the residuals, but with the residuals given by $r_i=\sqrt{[x_i-X(t_i;\theta)]^2+[y_i-Y(t_i;\theta)]^2}$. However I cannot find a reference to confirm this. 1) Is this the correct method or not? 2) Also, and I am not sure if the following question is well-posed, do I have to worry about any covariance between $x$ and $y$? Or maybe equivalently, I have $\partial X/\partial Y \ne 0$, so is this something that must be taken into account somehow?",,"['statistics', 'nonlinear-optimization', 'least-squares', 'covariance']"
59,How do you test if the observed data have the same mean?,How do you test if the observed data have the same mean?,,"This seems like it should be straightforward but I am at a loss. How does one test the following hypothesis: the observed data have the same mean (or, alternatively, the observed data have the same variance)? To provide context, I read the following online: ""Here's another way of getting at whether there's a real pattern: How much variation in the standard deviations would you expect if all the players had the same underlying standard deviation (and the observed differences were just a result of sampling)?""  It then occurred to me that I did not know what statistical test to run to confirm this.  That is, if I have a set of numbers, how do I determine if observed differences between the numbers are the result of sampling uncertainty or if such differences are the result of variance in individual-specific means.  Or is this impossible and the question is not well-specified.  It would seem to me that if the observed sample were bi-modal or clustered around two points, for example, one could conclude that there are two population means generating the data, with observations clustered around these two points according to sampling uncertainty.  But how does one draw such a conclusion more rigorously. Any thoughts would be greatly appreciated.","This seems like it should be straightforward but I am at a loss. How does one test the following hypothesis: the observed data have the same mean (or, alternatively, the observed data have the same variance)? To provide context, I read the following online: ""Here's another way of getting at whether there's a real pattern: How much variation in the standard deviations would you expect if all the players had the same underlying standard deviation (and the observed differences were just a result of sampling)?""  It then occurred to me that I did not know what statistical test to run to confirm this.  That is, if I have a set of numbers, how do I determine if observed differences between the numbers are the result of sampling uncertainty or if such differences are the result of variance in individual-specific means.  Or is this impossible and the question is not well-specified.  It would seem to me that if the observed sample were bi-modal or clustered around two points, for example, one could conclude that there are two population means generating the data, with observations clustered around these two points according to sampling uncertainty.  But how does one draw such a conclusion more rigorously. Any thoughts would be greatly appreciated.",,"['statistics', 'hypothesis-testing']"
60,Neyman-Pearson lemma. Doubt on the text of the lemma,Neyman-Pearson lemma. Doubt on the text of the lemma,,"In my book: $\mathbf{X}=(X_1,\ldots,X_n)$ $f(\mathbf{x})$ is the joint density, where $f$ is either $f_0 \text{ or } f_1$. Suppose we want to test $H_0: f=f_0$ or $H_1: f=f_1$. The test, whose test function is $$\phi(\mathbf{X})=1\text{ if }\frac{f_1}{f_0}\geq k;$$ $$\phi(\mathbf{X})=0 \text{ otherwise,}$$ (for some $0<k<\infty$) is a most powerful test of $H_0$ versus $H_1$ at level $E_0(\phi(\mathbf{X}))$. My question is how is $k$ defined? Can I interpret the lemma as if $\forall k \in (0,\infty)$ there will be a test function $\phi(\mathbf{X})$ such that it will determine the size for which the test with test function $\phi(\mathbf{X})$ is most powerful? I'm just trying to understand which kind of relationship $k$ and the size of the test have between each other. EDIT: Here is a citation from the book I'm using: «the Neyman-Pearson lemma as stated here does not guarantee the existence of an MP $\alpha$ level test but merely states that the test that rejects $H_0$ for $T(X)\geq k$ will be an MP for some level $\alpha$» This makes me want to interpret as $\forall k \exists \alpha$. May I?","In my book: $\mathbf{X}=(X_1,\ldots,X_n)$ $f(\mathbf{x})$ is the joint density, where $f$ is either $f_0 \text{ or } f_1$. Suppose we want to test $H_0: f=f_0$ or $H_1: f=f_1$. The test, whose test function is $$\phi(\mathbf{X})=1\text{ if }\frac{f_1}{f_0}\geq k;$$ $$\phi(\mathbf{X})=0 \text{ otherwise,}$$ (for some $0<k<\infty$) is a most powerful test of $H_0$ versus $H_1$ at level $E_0(\phi(\mathbf{X}))$. My question is how is $k$ defined? Can I interpret the lemma as if $\forall k \in (0,\infty)$ there will be a test function $\phi(\mathbf{X})$ such that it will determine the size for which the test with test function $\phi(\mathbf{X})$ is most powerful? I'm just trying to understand which kind of relationship $k$ and the size of the test have between each other. EDIT: Here is a citation from the book I'm using: «the Neyman-Pearson lemma as stated here does not guarantee the existence of an MP $\alpha$ level test but merely states that the test that rejects $H_0$ for $T(X)\geq k$ will be an MP for some level $\alpha$» This makes me want to interpret as $\forall k \exists \alpha$. May I?",,"['probability', 'statistics']"
61,Simple way to derive formula from dataset?,Simple way to derive formula from dataset?,,"I'm not too good at math but I'm going to give this ago anyway and try and explain. Say I have a dataset, where each object in the set (not too sure about my correct use of terminology!) has $4$ different characteristics, and an overall score. If I had $5$ different objects, with all the data for each one, is there a way to try and find a formula which when applied to the characteristics for each object will give the overall score?","I'm not too good at math but I'm going to give this ago anyway and try and explain. Say I have a dataset, where each object in the set (not too sure about my correct use of terminology!) has $4$ different characteristics, and an overall score. If I had $5$ different objects, with all the data for each one, is there a way to try and find a formula which when applied to the characteristics for each object will give the overall score?",,['statistics']
62,Deriving a lower bound for a probability involving a random variable $X$ with the Gamma distribution.,Deriving a lower bound for a probability involving a random variable  with the Gamma distribution.,X,"Question Let $X$ have the $Gamma(\alpha, \beta)$ density. I.e. $$f_X(x) = \frac{1}{\gamma(\alpha)\beta^\alpha}x^{\alpha-1}e^{-\frac{x}{\beta}}$$ when $x >0$ and $0$ elsewhere. The moment generating function of $X$ is $M(t) = \frac{1}{(1-\beta t)^\alpha}, t < \frac{1}{\beta}.$ (*) Accept that $P(X \ge r) \le e^{-rt}M(t)$ for every $r$ and all t, $0 < t < \frac{1}{\beta}$. Derive a lower bound (depending only on $\alpha$) for $P(X \ge 2\alpha\beta)$ Answer Using (*) and letting $r = 2\alpha\beta$ we have $$P(X \ge 2\alpha\beta) \le e^{-2\alpha\beta t} \frac{1}{(1-\beta t)^\alpha}$$ $$\iff P(X \ge 2\alpha\beta) \le \frac{(e^{-2\beta t})^\alpha}{(1-\beta t)^\alpha}$$ $$\iff P(X \ge 2\alpha\beta) \le \bigg(\frac{e^{-2\beta t}}{(1-\beta t)}\bigg)^\alpha$$ But all I have now is an upper bound, and not only that, it is dependent on $\beta$ and $t$ as well as $\alpha$. Am I completely off track here? Anyone know how to solve this problem?","Question Let $X$ have the $Gamma(\alpha, \beta)$ density. I.e. $$f_X(x) = \frac{1}{\gamma(\alpha)\beta^\alpha}x^{\alpha-1}e^{-\frac{x}{\beta}}$$ when $x >0$ and $0$ elsewhere. The moment generating function of $X$ is $M(t) = \frac{1}{(1-\beta t)^\alpha}, t < \frac{1}{\beta}.$ (*) Accept that $P(X \ge r) \le e^{-rt}M(t)$ for every $r$ and all t, $0 < t < \frac{1}{\beta}$. Derive a lower bound (depending only on $\alpha$) for $P(X \ge 2\alpha\beta)$ Answer Using (*) and letting $r = 2\alpha\beta$ we have $$P(X \ge 2\alpha\beta) \le e^{-2\alpha\beta t} \frac{1}{(1-\beta t)^\alpha}$$ $$\iff P(X \ge 2\alpha\beta) \le \frac{(e^{-2\beta t})^\alpha}{(1-\beta t)^\alpha}$$ $$\iff P(X \ge 2\alpha\beta) \le \bigg(\frac{e^{-2\beta t}}{(1-\beta t)}\bigg)^\alpha$$ But all I have now is an upper bound, and not only that, it is dependent on $\beta$ and $t$ as well as $\alpha$. Am I completely off track here? Anyone know how to solve this problem?",,"['probability', 'statistics', 'probability-distributions']"
63,What do I need in order to draw conclusions from this data?,What do I need in order to draw conclusions from this data?,,"I have three techniques, called A, B and C. Each can be used independently when trying to perform four related tasks (Tasks 1, 2, 3 and 4). I have run lots of tests, and tried all combinations of each technique being on or off. My results look something like this. Let's say that higher numbers are better. $$ \begin{array}{l|r|r|r|r|r|r|r|r|r|} \mbox{Technique $A$} & - & - & - & - & X & X & X & X \\ \mbox{Technique $B$} & - & - & X & X & - & - & X & X \\ \mbox{Technique $C$} & - & X & - & X & - & X & - & X \\ \hline \mbox{Task $1$} & 433 & 277 & 911 & 492 & 686 & 4211 & 3775 & {\bf 9732}\\ \mbox{Task $2$} & 149 & 1063 & 5562 & {\bf 6035} & 3 & 58 & 1391 & 1708\\ \mbox{Task $3$} & 220 & 1278 & 7014 & {\bf 7018} & 10 & 97 & 2083 & 4452\\ \mbox{Task $4$} & 218 & 1255 & 6142 & {\bf 8656} & 1 & 73 & 1087 & 2056\\ \end{array} $$ Looking at the numbers, it seems that $B+C$ is good for Tasks 2,3 and 4, and that $A$ on its own is best for Task 1. But I want to say a bit more. I'd like to be quantitative if I can. My question is: can I deduce anything quantitative from this data? Or do I really need some measure of the variance of the observations? That is, I suspect the numbers might be different if I ran all the tests again.","I have three techniques, called A, B and C. Each can be used independently when trying to perform four related tasks (Tasks 1, 2, 3 and 4). I have run lots of tests, and tried all combinations of each technique being on or off. My results look something like this. Let's say that higher numbers are better. $$ \begin{array}{l|r|r|r|r|r|r|r|r|r|} \mbox{Technique $A$} & - & - & - & - & X & X & X & X \\ \mbox{Technique $B$} & - & - & X & X & - & - & X & X \\ \mbox{Technique $C$} & - & X & - & X & - & X & - & X \\ \hline \mbox{Task $1$} & 433 & 277 & 911 & 492 & 686 & 4211 & 3775 & {\bf 9732}\\ \mbox{Task $2$} & 149 & 1063 & 5562 & {\bf 6035} & 3 & 58 & 1391 & 1708\\ \mbox{Task $3$} & 220 & 1278 & 7014 & {\bf 7018} & 10 & 97 & 2083 & 4452\\ \mbox{Task $4$} & 218 & 1255 & 6142 & {\bf 8656} & 1 & 73 & 1087 & 2056\\ \end{array} $$ Looking at the numbers, it seems that $B+C$ is good for Tasks 2,3 and 4, and that $A$ on its own is best for Task 1. But I want to say a bit more. I'd like to be quantitative if I can. My question is: can I deduce anything quantitative from this data? Or do I really need some measure of the variance of the observations? That is, I suspect the numbers might be different if I ran all the tests again.",,['statistics']
64,Total boundness of Lipschitz densities,Total boundness of Lipschitz densities,,"In the article Almost Sure Testability of Classes of Densities by Devroye and Lugosi in 1999. They claim in Example 10 (page 9) that Lipschitz densities on [0,1] with Lipschitz constant bounded by some $C$ are a closed set and are as a class of densities totally bounded. Why is this? I cannot find a proof of it.","In the article Almost Sure Testability of Classes of Densities by Devroye and Lugosi in 1999. They claim in Example 10 (page 9) that Lipschitz densities on [0,1] with Lipschitz constant bounded by some $C$ are a closed set and are as a class of densities totally bounded. Why is this? I cannot find a proof of it.",,"['real-analysis', 'probability']"
65,Calculating conditional lottery probabilities - and example from DeGroot.,Calculating conditional lottery probabilities - and example from DeGroot.,,"I'm trying to understand this example in Probability and Statistics in DeGroot: https://i.sstatic.net/b23Sr.jpg ""You learned that the event B = {one of the numbers drawn is 15} has occurred. You want to calculate the probability of the event A that your ticket is a winner [given B]."" It suggests that the probability of P(AnB) = P(A) but how can this be if there exist outcomes in A that aren't in B? Surely it should be equal to P(B) if anything? Thanks.","I'm trying to understand this example in Probability and Statistics in DeGroot: https://i.sstatic.net/b23Sr.jpg ""You learned that the event B = {one of the numbers drawn is 15} has occurred. You want to calculate the probability of the event A that your ticket is a winner [given B]."" It suggests that the probability of P(AnB) = P(A) but how can this be if there exist outcomes in A that aren't in B? Surely it should be equal to P(B) if anything? Thanks.",,"['statistics', 'conditional-probability']"
66,Mean of this experiment,Mean of this experiment,,"Let the following experience : Let $x=n_0\in\mathbb{N}$. Each step, $x$ has a $1/2$ probability of increasing by one and a   $1/2$ probability of decreasing by one. The goal is to determine the Mean of this experience for an   infinite number of steps. If $x$ was varying over $\mathbb{Z}$ then it seems obvious to me that the Mean should be $n_0$. However, if we now limit $x$ to $\mathbb{N}$ (which implies that if $x$ is $0$ and is to decrease then it stays at $0$), what is the Mean of the experience ?","Let the following experience : Let $x=n_0\in\mathbb{N}$. Each step, $x$ has a $1/2$ probability of increasing by one and a   $1/2$ probability of decreasing by one. The goal is to determine the Mean of this experience for an   infinite number of steps. If $x$ was varying over $\mathbb{Z}$ then it seems obvious to me that the Mean should be $n_0$. However, if we now limit $x$ to $\mathbb{N}$ (which implies that if $x$ is $0$ and is to decrease then it stays at $0$), what is the Mean of the experience ?",,['statistics']
67,Calculating optimum values of $u$ and $m$ from $\mathbb V(\bar {y_2}\prime)=\frac{S_2^2(n-u\rho^2)}{n^2-u^2\rho^2}$,Calculating optimum values of  and  from,u m \mathbb V(\bar {y_2}\prime)=\frac{S_2^2(n-u\rho^2)}{n^2-u^2\rho^2},"I have to find optimum sample size in sampling on two occasions. Suppose that the samples are of the same size n on both occasions. In selecting the second sample, $m$ of the units in the first sample are retained. The remaining $u$ units are discarded and replaced by a new selection from the units not previously selected. Notation: $\bar y_{hu}=$mean of unmatched portion on occasion $h$ $\bar y_{hm}=$mean of matched portion on occasion $h$ $\bar y_{h}=$mean of whole sample on occasion $h$ $$\mathbb V(\bar {y_2}\prime)=\frac{S_2^2(n-u\rho^2)}{n^2-u^2\rho^2}\ldots(1)$$ $\rho$ denotes correlation coefficient The optimum value of $u$ is found by minimizing equation (1) with respect to variation in $u$.This gives $$\frac{u}{n}=\frac{1}{1+\sqrt{1-\rho^2}}\ldots (2)$$  How they derived equation (2) from (1)? I supposed to differentiate (1) with respect to $u$ and set it to zero. But i couldn't remove $S_2^2$ of equation (1) to derive (2).","I have to find optimum sample size in sampling on two occasions. Suppose that the samples are of the same size n on both occasions. In selecting the second sample, $m$ of the units in the first sample are retained. The remaining $u$ units are discarded and replaced by a new selection from the units not previously selected. Notation: $\bar y_{hu}=$mean of unmatched portion on occasion $h$ $\bar y_{hm}=$mean of matched portion on occasion $h$ $\bar y_{h}=$mean of whole sample on occasion $h$ $$\mathbb V(\bar {y_2}\prime)=\frac{S_2^2(n-u\rho^2)}{n^2-u^2\rho^2}\ldots(1)$$ $\rho$ denotes correlation coefficient The optimum value of $u$ is found by minimizing equation (1) with respect to variation in $u$.This gives $$\frac{u}{n}=\frac{1}{1+\sqrt{1-\rho^2}}\ldots (2)$$  How they derived equation (2) from (1)? I supposed to differentiate (1) with respect to $u$ and set it to zero. But i couldn't remove $S_2^2$ of equation (1) to derive (2).",,"['calculus', 'algebra-precalculus', 'statistics', 'statistical-inference']"
68,What test should I use to statistically compare two intraclass correlation coefficients (ICC)?,What test should I use to statistically compare two intraclass correlation coefficients (ICC)?,,"I need to compare two generalizability (G) coefficients for data that are from two separate populations. G coefficients are a type of intraclass correlation coefficient (ICC). The literature on statistically comparing G coefficients is sparse by all accounts, so I thought that the best I might do was find out the recommendation for statistically comparing ICCs.","I need to compare two generalizability (G) coefficients for data that are from two separate populations. G coefficients are a type of intraclass correlation coefficient (ICC). The literature on statistically comparing G coefficients is sparse by all accounts, so I thought that the best I might do was find out the recommendation for statistically comparing ICCs.",,"['statistics', 'correlation']"
69,Finding UMVUE for Poisson distribution using Rao Blackwell,Finding UMVUE for Poisson distribution using Rao Blackwell,,"Let $X_1,X_2,\ldots,X_n$ be a random sample from a Poisson distribution with parameter $\lambda$. Let $\gamma(\lambda)=P(X\le 1)$. Find UMVUE for  $\gamma(\lambda)$. This is my attempt: First I defined a indicator function as $T'=I_{(X_1\le 1)}=\begin{cases} 1,  & \text{if $X_1\le1$ } \\ 0, & \text{otherwise}  \\ \end{cases}$ which is unbiased estimator for  $\gamma(\lambda)$. Also since this belongs to one parameter exponential family $T=\sum X_i$ is a sufficient statistic for  $\gamma(\lambda)$. Then by Rao Blackwell Theorem, $E[T'|T=t]$ is a UMVUE for  $\gamma(\lambda).$ \begin{align} & \operatorname E[T'\mid T=t]=1\cdot P[T'=1\mid T=t]+0\cdot P[T'=0\mid T=t] \\[10pt] = {} & {P[X_1\le 1 \text{ and } X_1+ X_2+ X_3+\cdots+ X_n=t] }\over P[\sum X_i=t]  \end{align} Since at this moment$ X_1\le 1$ it becomes that $X_2+ X_3+\cdots X_n\ge t-1$.Then since $ X_1\le 1$ and $X_2+ X_3+\cdots+X_n\ge t-1$ are independent from one another \begin{align} & P[X_1\le 1 \text{ and } X_1+ X_2+ X_3+\cdots+X_n=t] \\[10pt] = {} & P[X_1\le 1] \cdots P\left[\sum_{i=2}^n X_i\ge t-1\right] \end{align} Now I am stuck in computing $P[\sum_{i=2}^n X_i\ge t-1]$. $\sum_{i=2}^n X_i$ follows a poisson with parameter $(n-1) \lambda$.  In finding $P[\sum_{i=2}^n X_i\ge t-1]$ I came up to cumulative of Poisson $e^{-(n-1)\lambda}\sum_{i=0}^{y-1}(({n-1)\lambda)}^i / i!$.Is there a way I can simplify this.Please help me to find a UMVUE for this problem.","Let $X_1,X_2,\ldots,X_n$ be a random sample from a Poisson distribution with parameter $\lambda$. Let $\gamma(\lambda)=P(X\le 1)$. Find UMVUE for  $\gamma(\lambda)$. This is my attempt: First I defined a indicator function as $T'=I_{(X_1\le 1)}=\begin{cases} 1,  & \text{if $X_1\le1$ } \\ 0, & \text{otherwise}  \\ \end{cases}$ which is unbiased estimator for  $\gamma(\lambda)$. Also since this belongs to one parameter exponential family $T=\sum X_i$ is a sufficient statistic for  $\gamma(\lambda)$. Then by Rao Blackwell Theorem, $E[T'|T=t]$ is a UMVUE for  $\gamma(\lambda).$ \begin{align} & \operatorname E[T'\mid T=t]=1\cdot P[T'=1\mid T=t]+0\cdot P[T'=0\mid T=t] \\[10pt] = {} & {P[X_1\le 1 \text{ and } X_1+ X_2+ X_3+\cdots+ X_n=t] }\over P[\sum X_i=t]  \end{align} Since at this moment$ X_1\le 1$ it becomes that $X_2+ X_3+\cdots X_n\ge t-1$.Then since $ X_1\le 1$ and $X_2+ X_3+\cdots+X_n\ge t-1$ are independent from one another \begin{align} & P[X_1\le 1 \text{ and } X_1+ X_2+ X_3+\cdots+X_n=t] \\[10pt] = {} & P[X_1\le 1] \cdots P\left[\sum_{i=2}^n X_i\ge t-1\right] \end{align} Now I am stuck in computing $P[\sum_{i=2}^n X_i\ge t-1]$. $\sum_{i=2}^n X_i$ follows a poisson with parameter $(n-1) \lambda$.  In finding $P[\sum_{i=2}^n X_i\ge t-1]$ I came up to cumulative of Poisson $e^{-(n-1)\lambda}\sum_{i=0}^{y-1}(({n-1)\lambda)}^i / i!$.Is there a way I can simplify this.Please help me to find a UMVUE for this problem.",,"['statistics', 'statistical-inference']"
70,Statistical search for two needles in random haystacks,Statistical search for two needles in random haystacks,,"I have written a script to analyze some data at work, and for each run, it outputs a long list of integers. Each set of results is a frequency distribution (each integer appears one to many times). The result set also includes two particular integers that I have to automatically identify (called a co-pair). [P.S. The ""co-pair"" is just a term my supervisor uses, it is not a standard mathematical term. ] I tested the script with smaller data sets where I already know what the co-pair should be, and realized that neither of the integers in the co-pair are always the most frequent or the least frequent in the set. Now I am at a loss what other way to statistically examine the result set and automatically find the co-pair for ANY set of data. I have a relatively weak background in statistics so I am hoping someone can point me in the right direction. Edit: More context. Essentially after analyzing my data I have many sets of frequency distributions and I want to compare all of the sets at once to find answers ""defining the co-pair"", such as: (a) ""the co-pair are ALWAYS at ogive 35 and ogive 80"" or (b) ""the co-pair are ALWAYS the mode and the least frequent number in each set"" etc. The solution is definitely not either of the above, but what statistical methods can I use to compare many data sets to explore the relevance of particular needles in each haystack, to get an answer that works for identifying the co-pair within ALL the sets, an answer like either (a) or (b)? Edit two: I have thousands of data sets where I already know what the co-pairs are. I want to statistically analyze them and research what possibly defines them within each set, so I can apply the same methods to the other millions of data sets where I DO NOT know the co-pairs.","I have written a script to analyze some data at work, and for each run, it outputs a long list of integers. Each set of results is a frequency distribution (each integer appears one to many times). The result set also includes two particular integers that I have to automatically identify (called a co-pair). [P.S. The ""co-pair"" is just a term my supervisor uses, it is not a standard mathematical term. ] I tested the script with smaller data sets where I already know what the co-pair should be, and realized that neither of the integers in the co-pair are always the most frequent or the least frequent in the set. Now I am at a loss what other way to statistically examine the result set and automatically find the co-pair for ANY set of data. I have a relatively weak background in statistics so I am hoping someone can point me in the right direction. Edit: More context. Essentially after analyzing my data I have many sets of frequency distributions and I want to compare all of the sets at once to find answers ""defining the co-pair"", such as: (a) ""the co-pair are ALWAYS at ogive 35 and ogive 80"" or (b) ""the co-pair are ALWAYS the mode and the least frequent number in each set"" etc. The solution is definitely not either of the above, but what statistical methods can I use to compare many data sets to explore the relevance of particular needles in each haystack, to get an answer that works for identifying the co-pair within ALL the sets, an answer like either (a) or (b)? Edit two: I have thousands of data sets where I already know what the co-pairs are. I want to statistically analyze them and research what possibly defines them within each set, so I can apply the same methods to the other millions of data sets where I DO NOT know the co-pairs.",,['statistics']
71,Geometric generalizations of the arithmetic and geometric means,Geometric generalizations of the arithmetic and geometric means,,"Given a set of $3$ positive real numbers $\{a, b, c \}$, one way of interpreting the geometric mean is that it is the answer to the following question: Find the edge length $\mu_3$ of a cube whose volume is equal to that of a rectangular solid with edge lengths $a, b,$ and $c$. (Here the subscript ""$3$"" indicates that we are trying to equalize volume , a 3-dimensional measure.)  Similarly one way of interpreting the arithmetic mean is that it is the answer to the following question: Find the edge length $\mu_1$ of a cube whose total linear measure (i.e. the sum of the lengths of all edges) is equal to that of a rectangular solid with edge lengths $a, b,$ and $c$. As soon as one notices these geometric interpretations, the following immediately suggests itself as an obvious related question: Find the edge length $\mu_2$ of a cube whose surface area is equal to that of a rectangular solid with edge lengths $a, b,$ and $c$. Solving this problem, one finds that $$\mu_2 = \sqrt{ \frac{ab+ac+bc}{3}}$$ a formula which is a kind of hybrid of the formulas for the AM and GM. Generalizing, for a set of $n$ positive real numbers, one can define $n$ different types of ""mean"", each answering a question of the following type: Find the edge length $\mu_k$ of an $n$-dimensional hypercube whose $k$-dimensional measure (i.e. the sum of the measures of the $k$-dimensional subcubes) is equal to that of the hypersolid whose edge lengths are $a_1, a_2, \ldots a_3$. So for example, with $n=4$ there are four different ""means"" of the set $\{a,b,c,d\}$: $\mu_1(a,b,c,d)=\frac{a+b+c+d}{4}$ is just the arithmetic mean of the four numbers. $\mu_2(a,b,c,d) = \sqrt{ \frac{ab + ac + ad + bc + bd + cd}{6} }$ equalizes the $2$-measure $\mu_3(a,b,c,d) = \sqrt[3] {\frac {abc + abd + acd + bcd}{4} }$ equalizes the $3$-measure $\mu_4(a,b,c,d) = \sqrt[4] {abcd}$ is just the geometric mean of the four numbers. In general, $$\mu_k(a_1,a_2,\ldots a_n) = \sqrt[k]{\frac{\sum \text{all products of } k \text{ members of the set} \{a_1, a_2, \ldots a_n\} }{C_{n,k}}}$$ Okay, my questions: Do these generalized means have a name?  What (if anything) is known about them? In particular it seems to be the case that for any set of numbers, $\mu_1 \geq \mu_2 \geq \mu_3 \geq \cdots \geq \mu_n$, a generalization of the standard $AM-GM$ inequality.  But this seems much harder to prove.  Does anybody see a way to prove this? Please feel free to edit this question (especially its tags; I'm not happy with the ones I am using) for clarity.","Given a set of $3$ positive real numbers $\{a, b, c \}$, one way of interpreting the geometric mean is that it is the answer to the following question: Find the edge length $\mu_3$ of a cube whose volume is equal to that of a rectangular solid with edge lengths $a, b,$ and $c$. (Here the subscript ""$3$"" indicates that we are trying to equalize volume , a 3-dimensional measure.)  Similarly one way of interpreting the arithmetic mean is that it is the answer to the following question: Find the edge length $\mu_1$ of a cube whose total linear measure (i.e. the sum of the lengths of all edges) is equal to that of a rectangular solid with edge lengths $a, b,$ and $c$. As soon as one notices these geometric interpretations, the following immediately suggests itself as an obvious related question: Find the edge length $\mu_2$ of a cube whose surface area is equal to that of a rectangular solid with edge lengths $a, b,$ and $c$. Solving this problem, one finds that $$\mu_2 = \sqrt{ \frac{ab+ac+bc}{3}}$$ a formula which is a kind of hybrid of the formulas for the AM and GM. Generalizing, for a set of $n$ positive real numbers, one can define $n$ different types of ""mean"", each answering a question of the following type: Find the edge length $\mu_k$ of an $n$-dimensional hypercube whose $k$-dimensional measure (i.e. the sum of the measures of the $k$-dimensional subcubes) is equal to that of the hypersolid whose edge lengths are $a_1, a_2, \ldots a_3$. So for example, with $n=4$ there are four different ""means"" of the set $\{a,b,c,d\}$: $\mu_1(a,b,c,d)=\frac{a+b+c+d}{4}$ is just the arithmetic mean of the four numbers. $\mu_2(a,b,c,d) = \sqrt{ \frac{ab + ac + ad + bc + bd + cd}{6} }$ equalizes the $2$-measure $\mu_3(a,b,c,d) = \sqrt[3] {\frac {abc + abd + acd + bcd}{4} }$ equalizes the $3$-measure $\mu_4(a,b,c,d) = \sqrt[4] {abcd}$ is just the geometric mean of the four numbers. In general, $$\mu_k(a_1,a_2,\ldots a_n) = \sqrt[k]{\frac{\sum \text{all products of } k \text{ members of the set} \{a_1, a_2, \ldots a_n\} }{C_{n,k}}}$$ Okay, my questions: Do these generalized means have a name?  What (if anything) is known about them? In particular it seems to be the case that for any set of numbers, $\mu_1 \geq \mu_2 \geq \mu_3 \geq \cdots \geq \mu_n$, a generalization of the standard $AM-GM$ inequality.  But this seems much harder to prove.  Does anybody see a way to prove this? Please feel free to edit this question (especially its tags; I'm not happy with the ones I am using) for clarity.",,"['number-theory', 'statistics', 'combinations']"
72,"Lottery, cumulative distribution function, variance","Lottery, cumulative distribution function, variance",,"Suppose a lottery is played like this: You must pay $\$5$ to play. Then, you select three numbers from $\{0, 1, 2, ..., 9\}$, with each of the three numbers being diﬀerent (order does not matter). Let’s suppose that you choose the numbers $4, 7$, and $9$. The lottery organizers choose the winning numbers in the same manner (three non-repeating numbers), with each combination of three numbers being equally likely. Payouts are as follows: If your numbers match exactly one of the winning numbers, you get your $5$ dollars back. If you match exactly two of the winning numbers, you get your $5$ dollars back, plus an extra $5$ dollars. If you match all three numbers, you get the $5$ dollars plus an extra $50$ dollars. Let the  random variable $X$ represent your net winnings from this game (proﬁt minus cost), in dollars. (a) Give the cumulative distribution function of $X$. (b) Calculate $\mathrm{Var}(X)$.","Suppose a lottery is played like this: You must pay $\$5$ to play. Then, you select three numbers from $\{0, 1, 2, ..., 9\}$, with each of the three numbers being diﬀerent (order does not matter). Let’s suppose that you choose the numbers $4, 7$, and $9$. The lottery organizers choose the winning numbers in the same manner (three non-repeating numbers), with each combination of three numbers being equally likely. Payouts are as follows: If your numbers match exactly one of the winning numbers, you get your $5$ dollars back. If you match exactly two of the winning numbers, you get your $5$ dollars back, plus an extra $5$ dollars. If you match all three numbers, you get the $5$ dollars plus an extra $50$ dollars. Let the  random variable $X$ represent your net winnings from this game (proﬁt minus cost), in dollars. (a) Give the cumulative distribution function of $X$. (b) Calculate $\mathrm{Var}(X)$.",,['statistics']
73,Let X be a discrete random variable with expected value E(X)...,Let X be a discrete random variable with expected value E(X)...,,"Let $X$ be a discrete random variable with expected value $E(X)$. Further, suppose there is a $1/4$ probability of $X$ being exactly $2$ units away from $E(X)$, a $1/4$ probability of $X$ being exactly $3$ units away from $E(X)$, and a $1/2$ probability of $X$ being exactly $5$ units away from $E(X)$. What is $Var(X)$?","Let $X$ be a discrete random variable with expected value $E(X)$. Further, suppose there is a $1/4$ probability of $X$ being exactly $2$ units away from $E(X)$, a $1/4$ probability of $X$ being exactly $3$ units away from $E(X)$, and a $1/2$ probability of $X$ being exactly $5$ units away from $E(X)$. What is $Var(X)$?",,['statistics']
74,Adding stochastic variables random variables where one has time component,Adding stochastic variables random variables where one has time component,,"Based on GLS regression I have identified two random variables lets call them A & B variable A is normal variable with   E(A) = 15  STDEV(A) = 18  variable B is composed as follows    B = X * t E(X) = 0.15 STDEV(X) = 0.02 Given the above, is it possible to make a forecast of STDEV(A+B) at time (t)? I have also created time varying model for the standard deviation of B. Dependent Variable: B                Method: ML - ARCH (Marquardt) - Normal distribution              Date: 17/06/14   Time: 13:02                 Sample: 641 778              Included observations: 138               Convergence achieved after 24 iterations                 Presample variance: backcast (parameter = 0.7)               GARCH = C(3) + C(4)*GARCH(-1) + C(5)*DAY-639                      Variable    Coefficient Std. Error  z-Statistic Prob.    C          -0.332209    1.544698    -0.215064   0.8297 DAY-639     0.156594    0.022257    7.035607    0.0000      Variance Equation             C          -2.821977    0.647196    -4.360314   0.0000 GARCH(-1)   0.030162    0.393119     0.076726   0.9388 DAY-639     1.358799    0.544513     2.495440   0.0126","Based on GLS regression I have identified two random variables lets call them A & B variable A is normal variable with   E(A) = 15  STDEV(A) = 18  variable B is composed as follows    B = X * t E(X) = 0.15 STDEV(X) = 0.02 Given the above, is it possible to make a forecast of STDEV(A+B) at time (t)? I have also created time varying model for the standard deviation of B. Dependent Variable: B                Method: ML - ARCH (Marquardt) - Normal distribution              Date: 17/06/14   Time: 13:02                 Sample: 641 778              Included observations: 138               Convergence achieved after 24 iterations                 Presample variance: backcast (parameter = 0.7)               GARCH = C(3) + C(4)*GARCH(-1) + C(5)*DAY-639                      Variable    Coefficient Std. Error  z-Statistic Prob.    C          -0.332209    1.544698    -0.215064   0.8297 DAY-639     0.156594    0.022257    7.035607    0.0000      Variance Equation             C          -2.821977    0.647196    -4.360314   0.0000 GARCH(-1)   0.030162    0.393119     0.076726   0.9388 DAY-639     1.358799    0.544513     2.495440   0.0126",,"['statistics', 'standard-deviation']"
75,probability in roulette!,probability in roulette!,,"So I have read how to play roulette...still a little confused, and now I'm faced with a probability question about it which makes the problem a little harder. Please help me reason this where possible. Let's say you're in a debt of $500. You have $250 and you're going to use that to try to pay back your debt. What are the advantages of: Betting all on black So if I bet all on black, I have a 0.5 chance of winning \$250 (and then having $500). So simply advantages are quick return if I win...and just being bankrupt otherwise. Probably a risk not taking. Betting $50 on black 5 times (and if you haven't won, then you're just bankrupt). Would this be an expectation question? I can make X~Bern(p). Would I have to use any conditional cases here? Betting in increments of $x until you make it all back or you go bankrupt.","So I have read how to play roulette...still a little confused, and now I'm faced with a probability question about it which makes the problem a little harder. Please help me reason this where possible. Let's say you're in a debt of $500. You have $250 and you're going to use that to try to pay back your debt. What are the advantages of: Betting all on black So if I bet all on black, I have a 0.5 chance of winning \$250 (and then having $500). So simply advantages are quick return if I win...and just being bankrupt otherwise. Probably a risk not taking. Betting $50 on black 5 times (and if you haven't won, then you're just bankrupt). Would this be an expectation question? I can make X~Bern(p). Would I have to use any conditional cases here? Betting in increments of $x until you make it all back or you go bankrupt.",,"['probability', 'statistics', 'probability-distributions', 'gambling']"
76,"probability, expectation, variance","probability, expectation, variance",,"A 10-digit long number is picked randomly and each digit's pick is independent and has an equal probability of being picked (1/9 because there's digits 1 to 9). Let $X = \#\{\text{missing digits}\}$ (i.e. if the # is 1357768931, X = 2 because there's no 2 or 4) What is E(X)? Var(X)? I am so confused as to how to start this. Some guidance please?","A 10-digit long number is picked randomly and each digit's pick is independent and has an equal probability of being picked (1/9 because there's digits 1 to 9). Let $X = \#\{\text{missing digits}\}$ (i.e. if the # is 1357768931, X = 2 because there's no 2 or 4) What is E(X)? Var(X)? I am so confused as to how to start this. Some guidance please?",,"['statistics', 'random-variables', 'expectation', 'covariance']"
77,Probability question? [duplicate],Probability question? [duplicate],,"This question already has an answer here : Probability of waiting for an interview (1 answer) Closed 10 years ago . A manager is interviewing 3 applicants for a job. The duration of each interview follows an exponential distribution  with parameter 1/2, time being measured in hours. The interviews are scheduled to begin at 8:00, 8:15, and 8:30. Assume that the job candidates (interviewees) arrive exactly on time. For each of the three candidates, what is the probability that he/she will have to wait before his/her interview begins? (Provide 3 answers.) How do I work out the answer for the third candidate?","This question already has an answer here : Probability of waiting for an interview (1 answer) Closed 10 years ago . A manager is interviewing 3 applicants for a job. The duration of each interview follows an exponential distribution  with parameter 1/2, time being measured in hours. The interviews are scheduled to begin at 8:00, 8:15, and 8:30. Assume that the job candidates (interviewees) arrive exactly on time. For each of the three candidates, what is the probability that he/she will have to wait before his/her interview begins? (Provide 3 answers.) How do I work out the answer for the third candidate?",,"['probability', 'statistics']"
78,"What methods are performed for regression with trig functions? Eg, $-1,0,1,-1,0,1,\ldots$ to $\frac{2\sqrt3}{3}\cos(\frac{2\pi n}{3}+\frac{\pi}{6})$","What methods are performed for regression with trig functions? Eg,  to","-1,0,1,-1,0,1,\ldots \frac{2\sqrt3}{3}\cos(\frac{2\pi n}{3}+\frac{\pi}{6})","What methods are performed for regression with trigonometric functions? E.g. : Sequence: $$-1, 0, 1, -1, 0, 1, \ldots$$ Regression: $$\frac{2\sqrt3}{3}\;\cos\left(\frac{2\pi n}{3} + \frac{\pi}{6}\right)$$",What methods are performed for regression with trigonometric functions? E.g. : Sequence: Regression:,"-1, 0, 1, -1, 0, 1, \ldots \frac{2\sqrt3}{3}\;\cos\left(\frac{2\pi n}{3} + \frac{\pi}{6}\right)","['statistics', 'trigonometry', 'numerical-methods', 'regression', 'signal-processing']"
79,Correlation with many zero values,Correlation with many zero values,,"I have data for selling books from 2 bookstores for 100 days. For the first 90 days, no book was sold. Then the following books were sold Day# -  BookStore1 - BookStore2 Day1 -   0  -  0 Day2 -  0 -  0 .... Day 90 - 0 - 0 Day 91 - 1 - 10 Day 92 - 2 - 9 Day 93 - 3 - 8 Day 94 - 4- 7 Day 95 - 5 - 6 Day 96 - 6 - 5 Day 97 - 7 - 4 Day 98 - 8 - 3 Day 99 - 9 - 2 Day 100 - 10 - 1 Question: Is there a correlation between selling books from bookstore 1 and 2? The correlation for the last 10 days is negative and -1. However, if I take all the 100 days, Pearson correlation is  0.486413 and Spearman is 0.9351082. My question now, should the zeros be included in the correlation (100 days), or should I just compare the days that books were sold (last 10 days)?","I have data for selling books from 2 bookstores for 100 days. For the first 90 days, no book was sold. Then the following books were sold Day# -  BookStore1 - BookStore2 Day1 -   0  -  0 Day2 -  0 -  0 .... Day 90 - 0 - 0 Day 91 - 1 - 10 Day 92 - 2 - 9 Day 93 - 3 - 8 Day 94 - 4- 7 Day 95 - 5 - 6 Day 96 - 6 - 5 Day 97 - 7 - 4 Day 98 - 8 - 3 Day 99 - 9 - 2 Day 100 - 10 - 1 Question: Is there a correlation between selling books from bookstore 1 and 2? The correlation for the last 10 days is negative and -1. However, if I take all the 100 days, Pearson correlation is  0.486413 and Spearman is 0.9351082. My question now, should the zeros be included in the correlation (100 days), or should I just compare the days that books were sold (last 10 days)?",,"['statistics', 'correlation']"
80,FIFA Probability Problem,FIFA Probability Problem,,"I'm honestly unsure on how to go about this, so can anyone help me out please? There are 32 teams competing in the upcoming World Cup. These 32 teams come from ﬁve diﬀerent continents: Africa, Asia, Europe, North America, and South America. Last December, FIFA (the orginization that governs soccer internationally) separated the 32 teams into four “pots”, each consisting of eight teams. Pot 1 contained the eight teams ranked highest by FIFA, and consisted of four European teams and four South American teams. Pot 2 consisted of ﬁve African teams, two South American teams, and one European team. Pot 3 consisted of four Asian teams and four North American teams. Pot 4 consisted of eight European teams. In the World Cup, the initial stage consists of eight groups of four teams, with all groups containing exactly one team from each pot described above. Suppose that FIFA creates the groups via random selection, so that every possible outcome is equally likely. In actuality, FIFA does not allow a single group to contain more than two European teams, or more than one team from any other continent. If FIFA creates the groups via the random method prescribed, what is the probability that at least one of these rules is broken?","I'm honestly unsure on how to go about this, so can anyone help me out please? There are 32 teams competing in the upcoming World Cup. These 32 teams come from ﬁve diﬀerent continents: Africa, Asia, Europe, North America, and South America. Last December, FIFA (the orginization that governs soccer internationally) separated the 32 teams into four “pots”, each consisting of eight teams. Pot 1 contained the eight teams ranked highest by FIFA, and consisted of four European teams and four South American teams. Pot 2 consisted of ﬁve African teams, two South American teams, and one European team. Pot 3 consisted of four Asian teams and four North American teams. Pot 4 consisted of eight European teams. In the World Cup, the initial stage consists of eight groups of four teams, with all groups containing exactly one team from each pot described above. Suppose that FIFA creates the groups via random selection, so that every possible outcome is equally likely. In actuality, FIFA does not allow a single group to contain more than two European teams, or more than one team from any other continent. If FIFA creates the groups via the random method prescribed, what is the probability that at least one of these rules is broken?",,"['probability', 'statistics']"
81,Showing correlation is between $-1$ and $1$,Showing correlation is between  and,-1 1,"If $X_1$ and $X_2$ are random variables, then $E(X_1^2)E(X_2^2) \geq [E(X_1X_2)]^2$ by Schwarz's inequality. Use this fact to show that $-1 \leq \rho_{12} \leq 1$. I know that $\rho_{12} = \frac{(E(X_1X_2) - E(X_1)E(X_2))}{ \sqrt{(E(X_1^2) - E(X_1)^2)(E(X_2^2) -E(X_2)^2)}}$ But I am stuck from this point on. I believe I need to show that the denominator is always smaller than the denominator, which would show that it would never be greater than 1. Squaring the whole thing gives me some $E(X_1^2)E(X_2^2)$ and $[E(X_1X_2)]^2$ terms in the numerator, which were mentioned in the inequality, but the rest gets really ugly. Any suggestions on where to go from here?","If $X_1$ and $X_2$ are random variables, then $E(X_1^2)E(X_2^2) \geq [E(X_1X_2)]^2$ by Schwarz's inequality. Use this fact to show that $-1 \leq \rho_{12} \leq 1$. I know that $\rho_{12} = \frac{(E(X_1X_2) - E(X_1)E(X_2))}{ \sqrt{(E(X_1^2) - E(X_1)^2)(E(X_2^2) -E(X_2)^2)}}$ But I am stuck from this point on. I believe I need to show that the denominator is always smaller than the denominator, which would show that it would never be greater than 1. Squaring the whole thing gives me some $E(X_1^2)E(X_2^2)$ and $[E(X_1X_2)]^2$ terms in the numerator, which were mentioned in the inequality, but the rest gets really ugly. Any suggestions on where to go from here?",,"['statistics', 'covariance']"
82,Existence of Expectation,Existence of Expectation,,"Question: Let $X_1$, $X_2$, and Z denote independent, real-valued random variables. Assume that $Pr(Z=0) = 1 - Pr(Z=1)$ = $\alpha$ for some $0 < \alpha < 1$. Define $Y = \left\{    \begin{array}{l l}     X_1 & \quad \text{if $Z$ = 1}\\     X_2 & \quad \text{if $Z$ = 0}   \end{array} \right.$ a) Suppose that $E(X_1)$ and $E(X_2)$ exist. Does it follow that $E(Y)$ exists? b) Assume that $E(|X_1|)$ < $\infty$ and $E(|X_2|)$ < $\infty$. Find $E(Y|X_1)$. Answer: For part a), I'm not sure how to go about determining whether or not $E(Y)$ exists. I assume it does, as $E(Y|Z=z)$ = $Pr(Y|Z=0)Pr(Z=0)$ + $Pr(Y|Z=1)Pr(Z=1)$ = $X_1*\alpha$ + $X_2*(1- \alpha)$. For part b), $E(Y|X_1)$ = $\alpha$?","Question: Let $X_1$, $X_2$, and Z denote independent, real-valued random variables. Assume that $Pr(Z=0) = 1 - Pr(Z=1)$ = $\alpha$ for some $0 < \alpha < 1$. Define $Y = \left\{    \begin{array}{l l}     X_1 & \quad \text{if $Z$ = 1}\\     X_2 & \quad \text{if $Z$ = 0}   \end{array} \right.$ a) Suppose that $E(X_1)$ and $E(X_2)$ exist. Does it follow that $E(Y)$ exists? b) Assume that $E(|X_1|)$ < $\infty$ and $E(|X_2|)$ < $\infty$. Find $E(Y|X_1)$. Answer: For part a), I'm not sure how to go about determining whether or not $E(Y)$ exists. I assume it does, as $E(Y|Z=z)$ = $Pr(Y|Z=0)Pr(Z=0)$ + $Pr(Y|Z=1)Pr(Z=1)$ = $X_1*\alpha$ + $X_2*(1- \alpha)$. For part b), $E(Y|X_1)$ = $\alpha$?",,"['probability', 'statistics', 'conditional-probability', 'expectation', 'statistical-inference']"
83,Finding efficiency of an estimator for Poisson random variables,Finding efficiency of an estimator for Poisson random variables,,"$\newcommand{\eff}{\operatorname{eff}}$ I am asked to derive the efficiency of the estimator $\hat{\lambda}_1 = \frac{1}{2}(Y_1+Y_2)$ relative to $\hat{\lambda}_2=\bar{Y}$, where $Y_1,Y_2,\ldots,Y_n$ denotes a random sample of size n from a Poisson distribution with mean $\lambda$. I know that $\eff(\hat{\theta}_1,\hat{\theta}_2)=\frac{V(\hat{\theta}_2)}{V(\hat{\theta}_1)}$ for two unbiased estimators $\hat{\theta_1}$ and $\hat{\theta_2}$. So far I have: $$ \begin{align} \eff(\hat{\lambda}_1,\hat{\lambda}_2) & =\frac{V(\bar{Y})}{V(\frac{1}{2}(Y_1+Y_2))} \\[8pt] & =\frac{\lambda/n}{\frac{1}{4}V(Y_1)+\frac{1}{4}V(Y_2)} \\[8pt] & =\frac{\lambda/n}{\lambda/2} \\[8pt] & =n/2 \end{align} $$ Is this correct, or am I missing something? I have to do a short presentation of this problem in class and I'd like to make sure I didn't screw up somewhere.","$\newcommand{\eff}{\operatorname{eff}}$ I am asked to derive the efficiency of the estimator $\hat{\lambda}_1 = \frac{1}{2}(Y_1+Y_2)$ relative to $\hat{\lambda}_2=\bar{Y}$, where $Y_1,Y_2,\ldots,Y_n$ denotes a random sample of size n from a Poisson distribution with mean $\lambda$. I know that $\eff(\hat{\theta}_1,\hat{\theta}_2)=\frac{V(\hat{\theta}_2)}{V(\hat{\theta}_1)}$ for two unbiased estimators $\hat{\theta_1}$ and $\hat{\theta_2}$. So far I have: $$ \begin{align} \eff(\hat{\lambda}_1,\hat{\lambda}_2) & =\frac{V(\bar{Y})}{V(\frac{1}{2}(Y_1+Y_2))} \\[8pt] & =\frac{\lambda/n}{\frac{1}{4}V(Y_1)+\frac{1}{4}V(Y_2)} \\[8pt] & =\frac{\lambda/n}{\lambda/2} \\[8pt] & =n/2 \end{align} $$ Is this correct, or am I missing something? I have to do a short presentation of this problem in class and I'd like to make sure I didn't screw up somewhere.",,"['statistics', 'probability-distributions', 'random-variables']"
84,Probability question - (Probably) Bayes' Rule and Total Probability Theorem,Probability question - (Probably) Bayes' Rule and Total Probability Theorem,,"I just took a probability final exam and was fairly confident in my solution of 28/31, but I wanted to be sure... because according to http://www.stat.tamu.edu/~derya/stat211/SummerII02/Final.Summer02.doc which has it as the second question, the answer is .6627. What's discerning is that they have the decimal equivalent of 28/31 as one of their answers which makes it seem like they know something I don't... ""Seventy percent of all cattle are treated by an injected vaccine to combat a serious disease. The probability of recovery from the disease is 1 in 20 if untreated and 1 in 5 if treated. Given that an infected cow has recovered, what is the probability that the cow received the preventive vaccine?"" Here's my solution: Let A be the event a cow recovered, let B be the event a cow received the vaccine. We are given: P(A|B) = 1/5  P(A|~B) = 1/20  P(B) = 7/10 We want to find P(B|A), so use Bayes' rule and the total probability theorem to find P(B|A) = P(A|B) x P(B) / (P(A|B) x P(B) + P(A|~B) x P(~B) ). Plugging in the values from what's given above, we get (.2 x .7) / (.2 x .7 + .05 x .3) which gives 28/31. If I'm wrong, I'd love to be pointed in the right direction haha Thank you!","I just took a probability final exam and was fairly confident in my solution of 28/31, but I wanted to be sure... because according to http://www.stat.tamu.edu/~derya/stat211/SummerII02/Final.Summer02.doc which has it as the second question, the answer is .6627. What's discerning is that they have the decimal equivalent of 28/31 as one of their answers which makes it seem like they know something I don't... ""Seventy percent of all cattle are treated by an injected vaccine to combat a serious disease. The probability of recovery from the disease is 1 in 20 if untreated and 1 in 5 if treated. Given that an infected cow has recovered, what is the probability that the cow received the preventive vaccine?"" Here's my solution: Let A be the event a cow recovered, let B be the event a cow received the vaccine. We are given: P(A|B) = 1/5  P(A|~B) = 1/20  P(B) = 7/10 We want to find P(B|A), so use Bayes' rule and the total probability theorem to find P(B|A) = P(A|B) x P(B) / (P(A|B) x P(B) + P(A|~B) x P(~B) ). Plugging in the values from what's given above, we get (.2 x .7) / (.2 x .7 + .05 x .3) which gives 28/31. If I'm wrong, I'd love to be pointed in the right direction haha Thank you!",,"['probability', 'statistics']"
85,Power of a statistical test,Power of a statistical test,,"I was working on the following problem: Consider two probability density functions on $[0,1]: f_0(x) = 1$, and $f_1(x) = 2x$. Among all tests of the null hypothesis $H_0: X \sim f_0(x)$ versus the alternative $X \sim f_1(x)$, with significance level $\alpha = 0.1$, how large can the power possibly be? I think we need to begin by looking at an arbitrary test with significance level $\alpha = 0.1$ but I am having a hard time doing this. I am not even sure this is the direction we want to head in so I was hoping to get some hints regarding this problem.","I was working on the following problem: Consider two probability density functions on $[0,1]: f_0(x) = 1$, and $f_1(x) = 2x$. Among all tests of the null hypothesis $H_0: X \sim f_0(x)$ versus the alternative $X \sim f_1(x)$, with significance level $\alpha = 0.1$, how large can the power possibly be? I think we need to begin by looking at an arbitrary test with significance level $\alpha = 0.1$ but I am having a hard time doing this. I am not even sure this is the direction we want to head in so I was hoping to get some hints regarding this problem.",,['statistics']
86,Finding the marginal density of $ce^{-x^2-y^2-xy-x}$,Finding the marginal density of,ce^{-x^2-y^2-xy-x},"In my probability class, we've started studying joint distrubutions and I've been tasked with the following problem: Let $(X,Y)$ have joint density $ce^{-x^2-y^2-xy-x}$, where $c>0$ is some constant. Find the marginal density of $X$. What this amounts to is evaluating $\int_{-\infty}^{\infty} ce^{-x^2-y^2-xy-x} dy$. I need some help evaluating this integral because nothing I've tried has worked so far. I began by breaking it up and bringing out the terms with $x$: \begin{align*} \int_{-\infty}^{\infty} ce^{-x^2-y^2-xy-x} dy & = ce^{-x^2-x}\int_{-\infty}^{\infty} e^{-y^2-xy} dy \\ \end{align*} However this hasn't given me anything of worth, so maybe breaking it up like this isn't the best approach. I've also tried completing the square in the exponent for both $x^2$ and $y^2$ terms but that hasn't helped either. Any help is appreciated.","In my probability class, we've started studying joint distrubutions and I've been tasked with the following problem: Let $(X,Y)$ have joint density $ce^{-x^2-y^2-xy-x}$, where $c>0$ is some constant. Find the marginal density of $X$. What this amounts to is evaluating $\int_{-\infty}^{\infty} ce^{-x^2-y^2-xy-x} dy$. I need some help evaluating this integral because nothing I've tried has worked so far. I began by breaking it up and bringing out the terms with $x$: \begin{align*} \int_{-\infty}^{\infty} ce^{-x^2-y^2-xy-x} dy & = ce^{-x^2-x}\int_{-\infty}^{\infty} e^{-y^2-xy} dy \\ \end{align*} However this hasn't given me anything of worth, so maybe breaking it up like this isn't the best approach. I've also tried completing the square in the exponent for both $x^2$ and $y^2$ terms but that hasn't helped either. Any help is appreciated.",,"['calculus', 'statistics']"
87,Generate Sequence with given variance and mean,Generate Sequence with given variance and mean,,"Is there a simple way to do this by hand? I mostly want to do this for quick ""straight face"" testing to see if something works, so ideally I want (for example) a sequence with mean 1 and variance 2 with as many 0's as possible (for ease of calculation). Is there an easy way of doing this?","Is there a simple way to do this by hand? I mostly want to do this for quick ""straight face"" testing to see if something works, so ideally I want (for example) a sequence with mean 1 and variance 2 with as many 0's as possible (for ease of calculation). Is there an easy way of doing this?",,['statistics']
88,Margin of error for quotient of two measurements,Margin of error for quotient of two measurements,,"I need to find the total margin of error for calculating velocity, while I have margins of error for time and distance. Actually the margins are the same (as both measurements were based on GPS - but this is not important here), and are given as 1/365000 (20 cm for 730 km). So, I spent quite some time studying various information, most of which was about standard deviation (which I understand vaguely) and found here (but not only) that the formula I should use is: if $S=A×B$ or $A/B$ then $σ_S/S=\sqrt{(σ_A/A)^2+(σ_B/B)^2}$ Well, let's  take an easy example. Say I have two measurements: distance of 40 m and time of 4 sec; both margins are the same and equal 0.2 (huuuuge, I know). The above formula (if I am interpreting it correctly) would give me the margin of $σ_S/S=\sqrt{(0.2)^2+(0.2)^2}=\sqrt{0.04+0.04}= 0.2828$ (for the calculated velocity of 10 m/s). Therefore the lowest actual velocity can be $v=7,172 m/s$. Now, let's try to calculate the maximum error from actual numbers for distance and time. For the distance I can have measured up so the actual distance might even be as low as 33,33333 m, while for the time I can have measured down, which gives me the maximum possible time of 5 s. The real velocity would have been then $v=33,3333m/5s=6,66667 m/s$, which means I was wrong by 0,3333. Obviously, the above calculation shows the theoretical equation underestimated the margin of error, as it said the error cannot exceed 0.2828. On the other hand, I found elsewhere, yet without any explanation (but from a credible source) that in such case I should have calculated the total margin of error as simply a square root of 0,2 (or 1/365000 in my original problem). In such case the total margin of error equals 0.4472, which - although much higher than what I calculated in my example - is not underestimated at least. What do I do wrong, and - if the error of margin in my simple example really is 0.4472 (i.e. square root of a margin of error for the distance or time) than - why do I calculate it this way?","I need to find the total margin of error for calculating velocity, while I have margins of error for time and distance. Actually the margins are the same (as both measurements were based on GPS - but this is not important here), and are given as 1/365000 (20 cm for 730 km). So, I spent quite some time studying various information, most of which was about standard deviation (which I understand vaguely) and found here (but not only) that the formula I should use is: if $S=A×B$ or $A/B$ then $σ_S/S=\sqrt{(σ_A/A)^2+(σ_B/B)^2}$ Well, let's  take an easy example. Say I have two measurements: distance of 40 m and time of 4 sec; both margins are the same and equal 0.2 (huuuuge, I know). The above formula (if I am interpreting it correctly) would give me the margin of $σ_S/S=\sqrt{(0.2)^2+(0.2)^2}=\sqrt{0.04+0.04}= 0.2828$ (for the calculated velocity of 10 m/s). Therefore the lowest actual velocity can be $v=7,172 m/s$. Now, let's try to calculate the maximum error from actual numbers for distance and time. For the distance I can have measured up so the actual distance might even be as low as 33,33333 m, while for the time I can have measured down, which gives me the maximum possible time of 5 s. The real velocity would have been then $v=33,3333m/5s=6,66667 m/s$, which means I was wrong by 0,3333. Obviously, the above calculation shows the theoretical equation underestimated the margin of error, as it said the error cannot exceed 0.2828. On the other hand, I found elsewhere, yet without any explanation (but from a credible source) that in such case I should have calculated the total margin of error as simply a square root of 0,2 (or 1/365000 in my original problem). In such case the total margin of error equals 0.4472, which - although much higher than what I calculated in my example - is not underestimated at least. What do I do wrong, and - if the error of margin in my simple example really is 0.4472 (i.e. square root of a margin of error for the distance or time) than - why do I calculate it this way?",,"['statistics', 'standard-deviation', 'error-propagation']"
89,Joint distribution function if it is geometric and X is uniform,Joint distribution function if it is geometric and X is uniform,,"If $X$ be uniform on the set $\{\frac 12, \frac 13, \frac 14\}$, and the distribution of $Y\mid X = x$ is geometric with parameter $x$; that is, $P(Y=k\mid X=x) = x(1-x)^k$ for $k=0, 1, 2,\dotsc $ How do I find the pmf of this? I'm not sure how X being uniform on that set affects the distribution, which is what is confusing me. And conversely, how would I then obtain $X\mid Y=k$ for $k=0, 1, 2,\dotsc$ ?","If $X$ be uniform on the set $\{\frac 12, \frac 13, \frac 14\}$, and the distribution of $Y\mid X = x$ is geometric with parameter $x$; that is, $P(Y=k\mid X=x) = x(1-x)^k$ for $k=0, 1, 2,\dotsc $ How do I find the pmf of this? I'm not sure how X being uniform on that set affects the distribution, which is what is confusing me. And conversely, how would I then obtain $X\mid Y=k$ for $k=0, 1, 2,\dotsc$ ?",,"['probability', 'statistics']"
90,Maximum likelihood estimate - help with calculating logs!,Maximum likelihood estimate - help with calculating logs!,,"I'm doing a practice question finding the maximum likelihood estimate, but I'm having a bit of trouble with the actual 'pure' maths bit of it (the differentiation) I don't understand how you go from equation 1 to 3? If anyone could help I'd really appreciate it?","I'm doing a practice question finding the maximum likelihood estimate, but I'm having a bit of trouble with the actual 'pure' maths bit of it (the differentiation) I don't understand how you go from equation 1 to 3? If anyone could help I'd really appreciate it?",,"['statistics', 'logarithms']"
91,Incremental Calculation of the Sample Covariance,Incremental Calculation of the Sample Covariance,,"The formula to calculate the sample covariance given $n$ vector samples $x_{i}$ for $i = 1, \ldots, n$ is as follows: \begin{align*} S &= \frac{1}{n-1}\sum\limits_{i=1}^{n}(x_{i} - m)(x_{i} - m)^\intercal \end{align*} where $m$ is defined as the sample mean: \begin{align*} m &= \frac{1}{n}\sum\limits_{i=1}^{n}x_{i} \end{align*} I have to prove that the formula for $S$ can be rewritten as: \begin{align*} S &= \frac{\left(\sum\limits_{i=1}^{n} x_{i} x_{i}^\intercal\right) - n\ mm^\intercal}{n - 1} \end{align*} I have started my proof off as follows: \begin{align*} S &= \frac{1}{n-1}\sum\limits_{i=1}^{n}(x_{i} - m)(x_{i} - m)^\intercal \\ &= \frac{\sum\limits_{i=1}^{n}(x_{i} - m)(x_{i} - m)^\intercal}{n - 1} \\ &= \frac{\sum\limits_{i=1}^{n}(x_{i}x_{i}^\intercal - x_{i}m^\intercal -mx_{i}^\intercal + mm^\intercal)}{n - 1} \\ \end{align*} This is where I do not know how to proceed further. To me it seems that the only way to proceed would be to show that $x_{i}m^\intercal = mx_{i}^\intercal = mm^\intercal$, but I do not think this equality makes sense..","The formula to calculate the sample covariance given $n$ vector samples $x_{i}$ for $i = 1, \ldots, n$ is as follows: \begin{align*} S &= \frac{1}{n-1}\sum\limits_{i=1}^{n}(x_{i} - m)(x_{i} - m)^\intercal \end{align*} where $m$ is defined as the sample mean: \begin{align*} m &= \frac{1}{n}\sum\limits_{i=1}^{n}x_{i} \end{align*} I have to prove that the formula for $S$ can be rewritten as: \begin{align*} S &= \frac{\left(\sum\limits_{i=1}^{n} x_{i} x_{i}^\intercal\right) - n\ mm^\intercal}{n - 1} \end{align*} I have started my proof off as follows: \begin{align*} S &= \frac{1}{n-1}\sum\limits_{i=1}^{n}(x_{i} - m)(x_{i} - m)^\intercal \\ &= \frac{\sum\limits_{i=1}^{n}(x_{i} - m)(x_{i} - m)^\intercal}{n - 1} \\ &= \frac{\sum\limits_{i=1}^{n}(x_{i}x_{i}^\intercal - x_{i}m^\intercal -mx_{i}^\intercal + mm^\intercal)}{n - 1} \\ \end{align*} This is where I do not know how to proceed further. To me it seems that the only way to proceed would be to show that $x_{i}m^\intercal = mx_{i}^\intercal = mm^\intercal$, but I do not think this equality makes sense..",,"['linear-algebra', 'probability', 'statistics']"
92,Sample Covariance: divide by n or n-1,Sample Covariance: divide by n or n-1,,"To obtain the sample covariance, does one divide by $n$ or by $n-1$? I have seen both being used. What is the advantage of using $n-1$? Does it make the covariance unbiased? Or is it so that in the formula for the sample correlation the $n-1$ cancels with the $n-1$ used in the formula for the unbiased variance?","To obtain the sample covariance, does one divide by $n$ or by $n-1$? I have seen both being used. What is the advantage of using $n-1$? Does it make the covariance unbiased? Or is it so that in the formula for the sample correlation the $n-1$ cancels with the $n-1$ used in the formula for the unbiased variance?",,['statistics']
93,"Maximum Likelihood (ML) vs Maximum a Posteriori Estimation (MAP), When to Use Which?","Maximum Likelihood (ML) vs Maximum a Posteriori Estimation (MAP), When to Use Which?",,"ML = Maximum Liklihood MAP = Maximum a-posteriori ML is intuitive/naive in that it starts only with the probability of observation given the parameter (i.e. the likelihood function) and tries to find the parameter best accords with the observation. But it take into no consideration the prior knowledge. MAP seems more reasonable because it does take into consideration the prior knowledge through the Bayes rule. So, I think MAP is much better. Is that right? And when should I use which? Here is a related question, but the answer is not thorough - Differences Using Maximum Likelihood or Maximum a Posteriori for Deconvolution / Deblur ?","ML = Maximum Liklihood MAP = Maximum a-posteriori ML is intuitive/naive in that it starts only with the probability of observation given the parameter (i.e. the likelihood function) and tries to find the parameter best accords with the observation. But it take into no consideration the prior knowledge. MAP seems more reasonable because it does take into consideration the prior knowledge through the Bayes rule. So, I think MAP is much better. Is that right? And when should I use which? Here is a related question, but the answer is not thorough - Differences Using Maximum Likelihood or Maximum a Posteriori for Deconvolution / Deblur ?",,"['probability', 'statistics', 'optimization', 'maximum-likelihood']"
94,Testing hypothesis using significance levels,Testing hypothesis using significance levels,,"A random sample of n=26 observations on escape time (sec) for oil workers in a test resulted in sample mean 370.69 and sample standard deviation 24.36. Suppose the investigators had believed a priori that true average escape time would be at most 6 minutes. Does the data contradict the prior belief? Assuming normality of escape times, test the appropriate hypotheses using a significance level of a=0.05 I've tried using the follow formula to get my results. z_0.05 = 1.645 $z=\dfrac{\overline{x}-\mu_0}{s/\sqrt{n}}$ $= \frac{370.69 - \mu}{24.36/\sqrt{26}} $ My problem is I'm not sure what $\mu$ is supposed to be in this problem and also I don't if I'm supposed to be checking that z > z_0.05  to prove that the data contradicts the belief or vice versa. EDIT: t_.05 = 1.708 t = 2.23762 t_.05 < t so the data contradicts the prior belief.","A random sample of n=26 observations on escape time (sec) for oil workers in a test resulted in sample mean 370.69 and sample standard deviation 24.36. Suppose the investigators had believed a priori that true average escape time would be at most 6 minutes. Does the data contradict the prior belief? Assuming normality of escape times, test the appropriate hypotheses using a significance level of a=0.05 I've tried using the follow formula to get my results. z_0.05 = 1.645 $z=\dfrac{\overline{x}-\mu_0}{s/\sqrt{n}}$ $= \frac{370.69 - \mu}{24.36/\sqrt{26}} $ My problem is I'm not sure what $\mu$ is supposed to be in this problem and also I don't if I'm supposed to be checking that z > z_0.05  to prove that the data contradicts the belief or vice versa. EDIT: t_.05 = 1.708 t = 2.23762 t_.05 < t so the data contradicts the prior belief.",,"['probability', 'statistics', 'hypothesis-testing']"
95,Multinomial distribution from a contingency table,Multinomial distribution from a contingency table,,"Over a period of 100 days, weather forecasters issue forecasts for rain on a daily basis. Based on the forecasts and actual observations, you are supposed to help them ﬁnding out if the forecasts were any good. A forecast is simply one of the following three possible statements: “no rain”, “maybe rain”, or “certainly rain”. The forecasters record the number of days they issued each of these three forecasts, and also the corresponding number of days it rained. The results are collected below: Forecast: ""No rain""      , Days with rain: 4, Days without rain: 18 Forecast: ""Maybe rain""   , Days with rain: 25, Days without rain: 22 Forecast: ""Rain""         , Days with rain: 25, Days without rain: 6 Show that $n_{ij}$ has a multinomial distribution with unknown probabilities $p_{ij}$, which are the unknowns parameters in this problem. Write down the likelihood of the data nij as a function of $p_{ij}$ and N. This is a past exam paper and I have no clue how to answer this in a way that could get me marks! I've written the multinomial distribution: $\frac{n!}{X_1!...X_n!}p_1^{x_1}*p_2^{x_2}...*p_n^{x_n}$ But I can't work out how to do this question for the life of me!  Can anyone help?","Over a period of 100 days, weather forecasters issue forecasts for rain on a daily basis. Based on the forecasts and actual observations, you are supposed to help them ﬁnding out if the forecasts were any good. A forecast is simply one of the following three possible statements: “no rain”, “maybe rain”, or “certainly rain”. The forecasters record the number of days they issued each of these three forecasts, and also the corresponding number of days it rained. The results are collected below: Forecast: ""No rain""      , Days with rain: 4, Days without rain: 18 Forecast: ""Maybe rain""   , Days with rain: 25, Days without rain: 22 Forecast: ""Rain""         , Days with rain: 25, Days without rain: 6 Show that $n_{ij}$ has a multinomial distribution with unknown probabilities $p_{ij}$, which are the unknowns parameters in this problem. Write down the likelihood of the data nij as a function of $p_{ij}$ and N. This is a past exam paper and I have no clue how to answer this in a way that could get me marks! I've written the multinomial distribution: $\frac{n!}{X_1!...X_n!}p_1^{x_1}*p_2^{x_2}...*p_n^{x_n}$ But I can't work out how to do this question for the life of me!  Can anyone help?",,['statistics']
96,CI for two populations,CI for two populations,,The heights (in) for non-Hispanic white females in 2008 was the following:  Age      Sample Size        Sample Mean        Std Error 20-39    866                64.9               0.09 60+      934                63.1               0.11  Calculate and interpret a CI at confidence level 95% for the difference between population mean height of the younger women and that for the older women. Does the above question use the following formula to get the correct answer? $p1 - p2 \stackrel{+}{-} z \sqrt{ \frac{s1^2}{n1} + \frac{s2^2}{n2} }$ where: p1 = 64.9     s1 = 0.09 p2 = 63.1     s2 = 0.11 z = 1.96 n1 = 866 n2 = 934,The heights (in) for non-Hispanic white females in 2008 was the following:  Age      Sample Size        Sample Mean        Std Error 20-39    866                64.9               0.09 60+      934                63.1               0.11  Calculate and interpret a CI at confidence level 95% for the difference between population mean height of the younger women and that for the older women. Does the above question use the following formula to get the correct answer? $p1 - p2 \stackrel{+}{-} z \sqrt{ \frac{s1^2}{n1} + \frac{s2^2}{n2} }$ where: p1 = 64.9     s1 = 0.09 p2 = 63.1     s2 = 0.11 z = 1.96 n1 = 866 n2 = 934,,"['probability', 'statistics']"
97,"Confidence intervals, multiple iid variables","Confidence intervals, multiple iid variables",,"If the weight $X$ of bags of cement is normally distributed with a mean of $40$ kg and a standard deviation of $2$ kg, how many bags can a delivery truck carry so that the probability of the total load exceeding $2000$ kg will be $5\%$? The attempt at a solution: Suppose $n$ bags are required. Their weights are iid normal variables, with mean $40$ kg and variance $4$ kg. Their sum is thus distributed $N(40n, 2 \sqrt{n})$. We can normalize this by defining $$Z = \frac{X - 40n}{2\sqrt{n}}$$ We have $X = 2000$ kg, and from a table of $\Phi(x)$ one obtains $Z = 1.645$, but the equation has no real solutions.","If the weight $X$ of bags of cement is normally distributed with a mean of $40$ kg and a standard deviation of $2$ kg, how many bags can a delivery truck carry so that the probability of the total load exceeding $2000$ kg will be $5\%$? The attempt at a solution: Suppose $n$ bags are required. Their weights are iid normal variables, with mean $40$ kg and variance $4$ kg. Their sum is thus distributed $N(40n, 2 \sqrt{n})$. We can normalize this by defining $$Z = \frac{X - 40n}{2\sqrt{n}}$$ We have $X = 2000$ kg, and from a table of $\Phi(x)$ one obtains $Z = 1.645$, but the equation has no real solutions.",,['statistics']
98,The Objectivity of Statistical Testing,The Objectivity of Statistical Testing,,"I have a very generic question about applied statistics. Suppose, to make things simple, we have a biased coin with probability $p$ of landing heads. We want to determine if our coin is truly fair - that is, if $p=1/2$. We can do this by flipping the coin several times, generating a sequence such as $$0,0,1,0,0,1,1,0,1,0,1,1,1,1,0$$ for example. Now we must determine if that sequence of numbers is ""random"". Typically statistical testing for randomness involves so-called ""suites"" or ""batteries"" which consist of several tests put together. For example, random.org list $15$ different tests on this page which are used to confirm the randomness of its number generator. My first question is: how on earth do they justify the use of all these tests simultaneously? Surely the $15$ tests are all interdependently correlated in a way that is hopelessly complicated? I don't see how it would be possible to make sense out of such a vast array of results. Secondly, and more importantly: let's say we are free to choose any statistical test we want (we can even make one up), after the sequence of coin flips has been generated . Is it always possible to cook up some unsavory mess of a function which returns $p$-values arbitrarily low? That is, can we fabricate a statistic such that its attaining the value for the given event of coin flips has (assuming randomness) probability smaller than any $\epsilon>0$ that is given? If so, what does this say about the objectivity of statistical testing. There are many different statistics which could be measured for a sequence of coin flips. Some of these, undoubtedly, will return very unlikely results. Humans are free to choose both which tests to use and what $p$-values to reject at - does this have implications for the practice of statistics? How can we measure the ""randomness"" of that sequences in an objective fashion, without incorporating human bias? EDIT: Nobody has yet touched on the question of whether, for any given sequence of $1$'s and $0$'s a statistic can be constructed such that $P(\text{stat outcome})$ is arbitrarily small. I believe this demonstrates a negative answer: Since there are $2^n$ possible sequences of length $n$, the statistic can take on at most $2^n$ different values over the event space. Therefore, the least possible probability would be the chance of getting that one outcome alone, which is $2^{-n}$. Therefore the $p$-value cannot be made smaller than any given $\epsilon>0$ - does this look correct?","I have a very generic question about applied statistics. Suppose, to make things simple, we have a biased coin with probability $p$ of landing heads. We want to determine if our coin is truly fair - that is, if $p=1/2$. We can do this by flipping the coin several times, generating a sequence such as $$0,0,1,0,0,1,1,0,1,0,1,1,1,1,0$$ for example. Now we must determine if that sequence of numbers is ""random"". Typically statistical testing for randomness involves so-called ""suites"" or ""batteries"" which consist of several tests put together. For example, random.org list $15$ different tests on this page which are used to confirm the randomness of its number generator. My first question is: how on earth do they justify the use of all these tests simultaneously? Surely the $15$ tests are all interdependently correlated in a way that is hopelessly complicated? I don't see how it would be possible to make sense out of such a vast array of results. Secondly, and more importantly: let's say we are free to choose any statistical test we want (we can even make one up), after the sequence of coin flips has been generated . Is it always possible to cook up some unsavory mess of a function which returns $p$-values arbitrarily low? That is, can we fabricate a statistic such that its attaining the value for the given event of coin flips has (assuming randomness) probability smaller than any $\epsilon>0$ that is given? If so, what does this say about the objectivity of statistical testing. There are many different statistics which could be measured for a sequence of coin flips. Some of these, undoubtedly, will return very unlikely results. Humans are free to choose both which tests to use and what $p$-values to reject at - does this have implications for the practice of statistics? How can we measure the ""randomness"" of that sequences in an objective fashion, without incorporating human bias? EDIT: Nobody has yet touched on the question of whether, for any given sequence of $1$'s and $0$'s a statistic can be constructed such that $P(\text{stat outcome})$ is arbitrarily small. I believe this demonstrates a negative answer: Since there are $2^n$ possible sequences of length $n$, the statistic can take on at most $2^n$ different values over the event space. Therefore, the least possible probability would be the chance of getting that one outcome alone, which is $2^{-n}$. Therefore the $p$-value cannot be made smaller than any given $\epsilon>0$ - does this look correct?",,"['probability', 'statistics']"
99,Unbalanced game: probability of winning over an infinite number of possible match sequences,Unbalanced game: probability of winning over an infinite number of possible match sequences,,"We have 2 players, A and B, competing. The probability that A wins a match is p, making the probability that B wins a match (1-p) = q. The game is won by player A as soon as he gets one more win than B, whereas B wins when he gets ahead x won matches. What is the probability P(B wins) of A losing the game (i.e. B getting ahead x won matches before A gets ahead one)? The difficulty for me is the unbalance in the game and the fact that there is a seemingly infinite amount of sequences that need to be considered. My experience with such games is too little to find an elegant solution. Any help is appreciated.","We have 2 players, A and B, competing. The probability that A wins a match is p, making the probability that B wins a match (1-p) = q. The game is won by player A as soon as he gets one more win than B, whereas B wins when he gets ahead x won matches. What is the probability P(B wins) of A losing the game (i.e. B getting ahead x won matches before A gets ahead one)? The difficulty for me is the unbalance in the game and the fact that there is a seemingly infinite amount of sequences that need to be considered. My experience with such games is too little to find an elegant solution. Any help is appreciated.",,"['probability', 'statistics', 'game-theory']"
