,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to find the area of these sets?,How to find the area of these sets?,,"Let $T_1=[P_1,P_2,P_3]$ be a triangle. Choose a point $P_4$ on $T_1$ such that the area of triangle $T_2=[P_2,P_3,P_4]$ is half the area of $T_1$.  Repeat this process in the natural way. It is not too difficult to see the resulting sequence of triangles converges to a point. One can ask: What the area of the set of possible convergents as compared to the area of $T_1$? A quick hack when $P_1=(1,1)$, $P_2=(2,0)$ and $P_3=(0,0)$ yields the following graph of 30,000 random convergents: A reasonable estimate of the area of the triangle containing these convergents would be $2/9$.  Experimentally, at least, this type of simulation quickly finds an answer to the first question. Now suppose $P_{k+3}$ (and each following point) is chosen randomly either half way between $P_k$ and $P_{k+1}$ or one-third of the way from $P_k$ to $P_{k+2}$. Here is a graph of a few of these convergents: What is the area of the set of possible convergents in this case? Finally, suppose we choose the next point to lie half way on the left side three times as frequently as half way on the right side.  Here is the resulting rather weird graph of 100,000 or so such convergents: It seems to my untrained eyes as though asking questions about area no longer makes much sense, so I won't.","Let $T_1=[P_1,P_2,P_3]$ be a triangle. Choose a point $P_4$ on $T_1$ such that the area of triangle $T_2=[P_2,P_3,P_4]$ is half the area of $T_1$.  Repeat this process in the natural way. It is not too difficult to see the resulting sequence of triangles converges to a point. One can ask: What the area of the set of possible convergents as compared to the area of $T_1$? A quick hack when $P_1=(1,1)$, $P_2=(2,0)$ and $P_3=(0,0)$ yields the following graph of 30,000 random convergents: A reasonable estimate of the area of the triangle containing these convergents would be $2/9$.  Experimentally, at least, this type of simulation quickly finds an answer to the first question. Now suppose $P_{k+3}$ (and each following point) is chosen randomly either half way between $P_k$ and $P_{k+1}$ or one-third of the way from $P_k$ to $P_{k+2}$. Here is a graph of a few of these convergents: What is the area of the set of possible convergents in this case? Finally, suppose we choose the next point to lie half way on the left side three times as frequently as half way on the right side.  Here is the resulting rather weird graph of 100,000 or so such convergents: It seems to my untrained eyes as though asking questions about area no longer makes much sense, so I won't.",,"['sequences-and-series', 'geometry', 'fractals']"
1,"Given $x_{n+1}=x_n+\frac{c}{x_{n-1}}$, find the product of two successive terms $x_kx_{k+1}$","Given , find the product of two successive terms",x_{n+1}=x_n+\frac{c}{x_{n-1}} x_kx_{k+1},"I have the following nonlinear recurrence $$x_{n+1}=x_n+\frac{c}{x_{n-1}}$$ where $c$ is a constant - and if it makes things easier, let's assume it's a positive integer - with initial conditions $x_1=2$ and $x_2=3$. I'm asked to find a product of consecutive terms in the sequence $x_kx_{k+1}$, namely $x_{50}x_{51}$. How can I approach this? One thing that came to mind was to rewrite as $(x_{n+1}-x_n)x_{n-1}=c$. Then $$\begin{cases} (x_{n+1}-x_n)x_{n-1}=c\\ (x_n-x_{n-1})x_{n-2}=c \end{cases}$$the idea being that I might be able to extract some explicit information about $x_nx_{n-1}$. Or perhaps to allow me to write $x_n$ in terms of products of consecutive terms. Dividing one equation by the other gives $$\frac{(x_{n+1}-x_n)x_{n-1}}{(x_n-x_{n-1})x_{n-2}}=1\implies x_{n+1}x_{n-1}-x_nx_{n-1}=x_nx_{n-2}-x_{n-1}x_{n-2}$$ I'm thinking the next step would be to introduce products, like something along the lines of $$\begin{align*} x_{n+1}x_{n-1}-x_nx_{n-1}&=x_{n+1}x_{n-1}-x_{n+1}x_n+x_{n+1}x_n-x_nx_{n-1}\\ &=-x_{n+1}(x_n-x_{n-1})+x_{n+1}x_n-x_nx_{n-1} \end{align*}$$ but I'm not sure if there's any benefit to doing so. Another manipulation that occurred to me would be to recursively expand the right side: $$\begin{align*} x_{n+1}&=\frac{c}{x_{n-1}}+x_n\\ &=c\left(\frac{1}{x_{n-1}}+\frac{1}{x_{n-2}}\right)+x_{n-1}\\ &=c\left(\frac{1}{x_{n-1}}+\frac{1}{x_{n-2}}+\frac{1}{x_{n-3}}\right)+x_{n-2} \end{align*}$$ though I don't really know what this would accomplish.","I have the following nonlinear recurrence $$x_{n+1}=x_n+\frac{c}{x_{n-1}}$$ where $c$ is a constant - and if it makes things easier, let's assume it's a positive integer - with initial conditions $x_1=2$ and $x_2=3$. I'm asked to find a product of consecutive terms in the sequence $x_kx_{k+1}$, namely $x_{50}x_{51}$. How can I approach this? One thing that came to mind was to rewrite as $(x_{n+1}-x_n)x_{n-1}=c$. Then $$\begin{cases} (x_{n+1}-x_n)x_{n-1}=c\\ (x_n-x_{n-1})x_{n-2}=c \end{cases}$$the idea being that I might be able to extract some explicit information about $x_nx_{n-1}$. Or perhaps to allow me to write $x_n$ in terms of products of consecutive terms. Dividing one equation by the other gives $$\frac{(x_{n+1}-x_n)x_{n-1}}{(x_n-x_{n-1})x_{n-2}}=1\implies x_{n+1}x_{n-1}-x_nx_{n-1}=x_nx_{n-2}-x_{n-1}x_{n-2}$$ I'm thinking the next step would be to introduce products, like something along the lines of $$\begin{align*} x_{n+1}x_{n-1}-x_nx_{n-1}&=x_{n+1}x_{n-1}-x_{n+1}x_n+x_{n+1}x_n-x_nx_{n-1}\\ &=-x_{n+1}(x_n-x_{n-1})+x_{n+1}x_n-x_nx_{n-1} \end{align*}$$ but I'm not sure if there's any benefit to doing so. Another manipulation that occurred to me would be to recursively expand the right side: $$\begin{align*} x_{n+1}&=\frac{c}{x_{n-1}}+x_n\\ &=c\left(\frac{1}{x_{n-1}}+\frac{1}{x_{n-2}}\right)+x_{n-1}\\ &=c\left(\frac{1}{x_{n-1}}+\frac{1}{x_{n-2}}+\frac{1}{x_{n-3}}\right)+x_{n-2} \end{align*}$$ though I don't really know what this would accomplish.",,"['sequences-and-series', 'recurrence-relations']"
2,Series of a square of modified Bessel function of first kind,Series of a square of modified Bessel function of first kind,,"I need help with the following series: $$ S(x)=\sum _{n=1}^{+\infty} \frac{(-1)^n \hspace{0.05cm} I_{n}^2 (x)}{2n-1}, \hspace{0.3cm}x \in \mathbb{R}_{>0} $$ where $I_n(x)$ is the modified Bessel function of first kind. Is it possible to obtain a nice relation for it (i.e. not in the form of an infinite sum)? There is this formula (eq. 2.3 in the M. D. Rogers paper ): $$ \sum _{n=-\infty }^{\infty } \frac{J_n^2(z)}{n+y}=J_{y}(z) J_{-y}(z)\frac{\pi}{\sin(\pi y)} $$ If we set $y=-\frac{1}{2}$, $z=ix$ and use $J_n(ix)=i^nI_n(x)$, $J_{-1/2}(z)=\left(\frac2{\pi z}\right)^{1/2}\cos z$, $J_{1/2}(z)=\left(\frac2{\pi z}\right)^{1/2}\sin z$, and $\sin(2ix)=i\sinh(2x)$ , we get $$ \sum _{n=-\infty}^{+\infty} \frac{(-1)^n \hspace{0.05cm} I_{n}^2 (x)}{2n-1}=-\frac{\sinh(2x)}{2x} $$ But it's not the sum $S(x)$, which starts from $n=1$ and not $n=-\infty$. I don't know if it helps, but there is also a formula (from ""Integrals and Series Vol. 2: Special Functions"", also here a similar formula) $$ \sum _{n=1}^{\infty } \frac{(-1)^n I_{n\nu}^2 (z)}{n^2-a^2}=\frac{I_{\nu}^2(z)}{2 a^2}-\frac{\pi  \csc (\pi  a) I_{\nu a}^2(z)}{2 a}.  $$ but I am not sure if we can set $\nu=1$ (but even if we can, it's still not very helpful).","I need help with the following series: $$ S(x)=\sum _{n=1}^{+\infty} \frac{(-1)^n \hspace{0.05cm} I_{n}^2 (x)}{2n-1}, \hspace{0.3cm}x \in \mathbb{R}_{>0} $$ where $I_n(x)$ is the modified Bessel function of first kind. Is it possible to obtain a nice relation for it (i.e. not in the form of an infinite sum)? There is this formula (eq. 2.3 in the M. D. Rogers paper ): $$ \sum _{n=-\infty }^{\infty } \frac{J_n^2(z)}{n+y}=J_{y}(z) J_{-y}(z)\frac{\pi}{\sin(\pi y)} $$ If we set $y=-\frac{1}{2}$, $z=ix$ and use $J_n(ix)=i^nI_n(x)$, $J_{-1/2}(z)=\left(\frac2{\pi z}\right)^{1/2}\cos z$, $J_{1/2}(z)=\left(\frac2{\pi z}\right)^{1/2}\sin z$, and $\sin(2ix)=i\sinh(2x)$ , we get $$ \sum _{n=-\infty}^{+\infty} \frac{(-1)^n \hspace{0.05cm} I_{n}^2 (x)}{2n-1}=-\frac{\sinh(2x)}{2x} $$ But it's not the sum $S(x)$, which starts from $n=1$ and not $n=-\infty$. I don't know if it helps, but there is also a formula (from ""Integrals and Series Vol. 2: Special Functions"", also here a similar formula) $$ \sum _{n=1}^{\infty } \frac{(-1)^n I_{n\nu}^2 (z)}{n^2-a^2}=\frac{I_{\nu}^2(z)}{2 a^2}-\frac{\pi  \csc (\pi  a) I_{\nu a}^2(z)}{2 a}.  $$ but I am not sure if we can set $\nu=1$ (but even if we can, it's still not very helpful).",,"['sequences-and-series', 'bessel-functions']"
3,Proving an alternating Euler sum: $\sum_{k=1}^{\infty} \frac{(-1)^{k+1} H_k}{k} = \frac{1}{2} \zeta(2) - \frac{1}{2} \log^2 2$,Proving an alternating Euler sum:,\sum_{k=1}^{\infty} \frac{(-1)^{k+1} H_k}{k} = \frac{1}{2} \zeta(2) - \frac{1}{2} \log^2 2,"Let $$A(p,q) = \sum_{k=1}^{\infty} \frac{(-1)^{k+1}H^{(p)}_k}{k^q},$$ where $H^{(p)}_n = \sum_{i=1}^n i^{-p}$, the $n$th $p$-harmonic number.  The $A(p,q)$'s are known as alternating Euler sums . Can someone provide a nice proof that    $$A(1,1) = \sum_{k=1}^{\infty} \frac{(-1)^{k+1} H_k}{k} = \frac{1}{2} \zeta(2) - \frac{1}{2} \log^2 2?$$ I worked for a while on this today but was unsuccessful.  Summation by parts, swapping the order of summation, and approximating $H_k$ by $\log k$ were my best ideas, but I could not get any of them to work.  (Perhaps someone else can?)  I would like a nice proof in order to complete my answer here . Bonus points for proving $A(1,2) = \frac{5}{8} \zeta(3)$ and $A(2,1) =  \zeta(3) - \frac{1}{2}\zeta(2) \log 2$, as those are the other two alternating Euler sums needed to complete my answer. Added : I'm going to change the accepted answer to robjohn's $A(1,1)$ calculation as a proxy for the three answers he gave here.  Notwithstanding the other great answers (especially the currently most-upvoted one, the one I first accepted), robjohn's approach is the one I was originally trying.  I am pleased to see that it can be used to do the $A(1,1)$, $A(1,2)$, and $A(2,1)$ derivations.","Let $$A(p,q) = \sum_{k=1}^{\infty} \frac{(-1)^{k+1}H^{(p)}_k}{k^q},$$ where $H^{(p)}_n = \sum_{i=1}^n i^{-p}$, the $n$th $p$-harmonic number.  The $A(p,q)$'s are known as alternating Euler sums . Can someone provide a nice proof that    $$A(1,1) = \sum_{k=1}^{\infty} \frac{(-1)^{k+1} H_k}{k} = \frac{1}{2} \zeta(2) - \frac{1}{2} \log^2 2?$$ I worked for a while on this today but was unsuccessful.  Summation by parts, swapping the order of summation, and approximating $H_k$ by $\log k$ were my best ideas, but I could not get any of them to work.  (Perhaps someone else can?)  I would like a nice proof in order to complete my answer here . Bonus points for proving $A(1,2) = \frac{5}{8} \zeta(3)$ and $A(2,1) =  \zeta(3) - \frac{1}{2}\zeta(2) \log 2$, as those are the other two alternating Euler sums needed to complete my answer. Added : I'm going to change the accepted answer to robjohn's $A(1,1)$ calculation as a proxy for the three answers he gave here.  Notwithstanding the other great answers (especially the currently most-upvoted one, the one I first accepted), robjohn's approach is the one I was originally trying.  I am pleased to see that it can be used to do the $A(1,1)$, $A(1,2)$, and $A(2,1)$ derivations.",,"['real-analysis', 'calculus', 'sequences-and-series', 'harmonic-numbers', 'euler-sums']"
4,Is $\int_0^\infty \frac{dt}{e^t-xt}$ analytic continuation of $\sum_{k=1}^\infty \frac{(k-1)!}{k^k} x^{k-1}$?,Is  analytic continuation of ?,\int_0^\infty \frac{dt}{e^t-xt} \sum_{k=1}^\infty \frac{(k-1)!}{k^k} x^{k-1},"The following power series apparently converges only for $-e \leq x <e$: $$f(x)=\sum_{k=1}^\infty \frac{(k-1)!}{k^k} x^{k-1}$$ We can use it to define a real function $f(x)$, analytic in that interval. However, we can also use an integral to define this function: $$f(x)=\int_0^\infty \frac{dt}{e^t-xt}=\sum_{k=1}^\infty \frac{(k-1)!}{k^k} x^{k-1}$$ In the interval of convergence of the series these two definitions are equivalent. However, for $x<-e$ the power series diverges, but the integral converges: Can the integral serve as the analytic continuation of $f(x)$ for $x<-e$? How to justify this? Edit The integral works great for the complex plane as well. Here I used the integral representation to plot the real and imaginary parts of $f(z)$: We have problems on the real line for $x>e$. For the power series - they converge on a disk $|z|<e$ (with the boundary possibly included):","The following power series apparently converges only for $-e \leq x <e$: $$f(x)=\sum_{k=1}^\infty \frac{(k-1)!}{k^k} x^{k-1}$$ We can use it to define a real function $f(x)$, analytic in that interval. However, we can also use an integral to define this function: $$f(x)=\int_0^\infty \frac{dt}{e^t-xt}=\sum_{k=1}^\infty \frac{(k-1)!}{k^k} x^{k-1}$$ In the interval of convergence of the series these two definitions are equivalent. However, for $x<-e$ the power series diverges, but the integral converges: Can the integral serve as the analytic continuation of $f(x)$ for $x<-e$? How to justify this? Edit The integral works great for the complex plane as well. Here I used the integral representation to plot the real and imaginary parts of $f(z)$: We have problems on the real line for $x>e$. For the power series - they converge on a disk $|z|<e$ (with the boundary possibly included):",,"['sequences-and-series', 'definite-integrals', 'analytic-continuation']"
5,Can this sum over the q-Pochhammer symbol be simplified?,Can this sum over the q-Pochhammer symbol be simplified?,,"While considering the problem of the expected value of a dice fixing strategy on a two-sided die that comes up as $1$ with a probability of $\alpha$ and $0$ otherwise. I was studying the strategy where one fixes every die if they are all $1$'s and otherwise fixes only one die. I found that the expected value of this strategy satisfies the functional equation $$A(x)=C(x)-\frac{\alpha x}{1-x} A(\alpha x)$$ where $C$ is some particular rational function (although, I'd be interested in solutions for any or every rational $C$). By making infinitely many substitutions of this equation into itself, we can solve this as: $$A(x)=\sum_{n=0}^{\infty}\left(\prod_{k=0}^{n-1}\frac{-\alpha^{k+1} x}{1-\alpha^kx}\right)C(\alpha^n x)=\sum_{n=0}^{\infty}\frac{(-1)^n\alpha^{n(n+1)/2}x^nC(\alpha^nx)}{(x;\alpha)_n}$$ where $(x;\alpha)_n$ is the q-Pochhammer symbol defined as $$(x;\alpha)_n = \prod_{k=0}^{n-1}(1-x\alpha^k).$$ Is there a simpler form for the sum for $A$? I am hopeful that there is such a form since I the Wikipedia page on q-Pochhammer symbols lists the following identity: $$(x;q)_{\infty}=\sum_{n=0}^{\infty}\frac{(-1)^nq^{n(n-1)/2}x^n}{(q;q)_n}$$ which looks very similar to what I'm trying to get. In fact, this lets us calculate particular values of our generating function for certain $C$. For instance, if $C(x)=\frac{1}{1-x}$, we would find that at $x=\alpha$, we would have $$A(\alpha)=\sum_{n=0}^{\infty}\frac{(-1)^n\alpha^{n(n+1)/2}\alpha^n}{(\alpha;\alpha)_{n+1}}=\frac{1-(\alpha;\alpha)_{\infty}}{\alpha}.$$ However, I don't see any other useful identites.","While considering the problem of the expected value of a dice fixing strategy on a two-sided die that comes up as $1$ with a probability of $\alpha$ and $0$ otherwise. I was studying the strategy where one fixes every die if they are all $1$'s and otherwise fixes only one die. I found that the expected value of this strategy satisfies the functional equation $$A(x)=C(x)-\frac{\alpha x}{1-x} A(\alpha x)$$ where $C$ is some particular rational function (although, I'd be interested in solutions for any or every rational $C$). By making infinitely many substitutions of this equation into itself, we can solve this as: $$A(x)=\sum_{n=0}^{\infty}\left(\prod_{k=0}^{n-1}\frac{-\alpha^{k+1} x}{1-\alpha^kx}\right)C(\alpha^n x)=\sum_{n=0}^{\infty}\frac{(-1)^n\alpha^{n(n+1)/2}x^nC(\alpha^nx)}{(x;\alpha)_n}$$ where $(x;\alpha)_n$ is the q-Pochhammer symbol defined as $$(x;\alpha)_n = \prod_{k=0}^{n-1}(1-x\alpha^k).$$ Is there a simpler form for the sum for $A$? I am hopeful that there is such a form since I the Wikipedia page on q-Pochhammer symbols lists the following identity: $$(x;q)_{\infty}=\sum_{n=0}^{\infty}\frac{(-1)^nq^{n(n-1)/2}x^n}{(q;q)_n}$$ which looks very similar to what I'm trying to get. In fact, this lets us calculate particular values of our generating function for certain $C$. For instance, if $C(x)=\frac{1}{1-x}$, we would find that at $x=\alpha$, we would have $$A(\alpha)=\sum_{n=0}^{\infty}\frac{(-1)^n\alpha^{n(n+1)/2}\alpha^n}{(\alpha;\alpha)_{n+1}}=\frac{1-(\alpha;\alpha)_{\infty}}{\alpha}.$$ However, I don't see any other useful identites.",,"['sequences-and-series', 'combinatorics', 'pochhammer-symbol']"
6,How to evaluate $ \lim \limits_{n\to \infty} \sum \limits_ {k=1}^n \frac{k^n}{n^n}$?,How to evaluate ?, \lim \limits_{n\to \infty} \sum \limits_ {k=1}^n \frac{k^n}{n^n},I can show that the following limit exists but I am having difficulties to find it. It is $$\lim_{n\to \infty} \sum_{k=1}^n \frac{k^n}{n^n}$$ Can someone please help me?,I can show that the following limit exists but I am having difficulties to find it. It is $$\lim_{n\to \infty} \sum_{k=1}^n \frac{k^n}{n^n}$$ Can someone please help me?,,"['calculus', 'sequences-and-series']"
7,Regularizing the sum of all factorials,Regularizing the sum of all factorials,,"Consider the series $$\sum_{n=0}^\infty n! = 0! + 1! + 2! + 3! + 4! + \ldots = 1 + 1 + 2 + 6 + 24 + \ldots$$ This series clearly diverges. Now, given that the Gamma function is defined by $$n! = \Gamma(n+1) = \int_0^\infty t^n \mathrm{e}^{-t} \mathrm{d}t$$ we obtain $$\sum_{n=0}^\infty n! = \sum_{n=0}^\infty \int_0^\infty t^n \mathrm{e}^{-t} \mathrm{d}t$$ Interchanging limits for the sake of regularization yields \begin{align} \sum_{n=0}^\infty n! &= \int_0^\infty \sum_{n=0}^\infty t^n \mathrm{e}^{-t} \mathrm{d}t \\ &= \int_0^\infty \frac{\mathrm{e}^{-t}}{1 - t} \mathrm{d}t \\ &= \left[ -\mathrm{e}^{-1} \mathrm{Ei}(1-t) \right]_0^\infty \\ &= \mathrm{e}^{-1} \mathrm{Ei}(1) \\ &\approx 0.697175 \end{align} where $\mathrm{Ei}$ is the exponential integral. Notice that we used the Cauchy principal value since the function has a pole at $t = 1$ . Is this a valid regularization of the series? Entering the command N@Sum[n!, {n, 0, Infinity}, Regularization -> ""Borel""] into Mathematica yields 0.697175 + 1.15573 I which is a complex value. Why is the answer different? I know this is a divergent series, but I would like to find its regularized value. EDIT: 0.697175 + 1.15573 I is just $\mathrm{e}^{-1} (\mathrm{Ei}(1) + i\pi)$ .","Consider the series This series clearly diverges. Now, given that the Gamma function is defined by we obtain Interchanging limits for the sake of regularization yields where is the exponential integral. Notice that we used the Cauchy principal value since the function has a pole at . Is this a valid regularization of the series? Entering the command N@Sum[n!, {n, 0, Infinity}, Regularization -> ""Borel""] into Mathematica yields 0.697175 + 1.15573 I which is a complex value. Why is the answer different? I know this is a divergent series, but I would like to find its regularized value. EDIT: 0.697175 + 1.15573 I is just .","\sum_{n=0}^\infty n! = 0! + 1! + 2! + 3! + 4! + \ldots = 1 + 1 + 2 + 6 + 24 + \ldots n! = \Gamma(n+1) = \int_0^\infty t^n \mathrm{e}^{-t} \mathrm{d}t \sum_{n=0}^\infty n! = \sum_{n=0}^\infty \int_0^\infty t^n \mathrm{e}^{-t} \mathrm{d}t \begin{align}
\sum_{n=0}^\infty n! &= \int_0^\infty \sum_{n=0}^\infty t^n \mathrm{e}^{-t} \mathrm{d}t \\
&= \int_0^\infty \frac{\mathrm{e}^{-t}}{1 - t} \mathrm{d}t \\
&= \left[ -\mathrm{e}^{-1} \mathrm{Ei}(1-t) \right]_0^\infty \\
&= \mathrm{e}^{-1} \mathrm{Ei}(1) \\
&\approx 0.697175
\end{align} \mathrm{Ei} t = 1 \mathrm{e}^{-1} (\mathrm{Ei}(1) + i\pi)","['sequences-and-series', 'improper-integrals', 'gamma-function', 'divergent-series', 'regularization']"
8,Show $\sum_{n=2}^{\infty}\frac{1}{n\ln n}$ diverges.,Show  diverges.,\sum_{n=2}^{\infty}\frac{1}{n\ln n},"I wish to show $\sum_{n=2}^{\infty}\frac{1}{n\ln n}$ diverges. I initially wanted to use the comparison test, but couldn't come up with a series that is obviously less than $\frac{1}{n\ln n}$ that diverges. So I moved on to the integral test. The problem here is that I need to show that $f(x)=\frac{1}{x\ln x}$ is continuous on $[2,\infty)$, using $\epsilon$-$\delta$ definition of continuity. I've been given theorems that allow me to just assert that $\ln x$ is continuous on the interval, as I know $1$ is continuous, $x$ is continuous, and so if $\ln x$ is continuous then as we have a composition of continuous functions, $\frac{1}{x\ln x}$ will be continuous on $[2,\infty)$. The trouble I'm having is showing $\ln x$ is continuous. I again got stuck doing this. And now it feels like I've completely over-complicated things. I need to be rigorous when showing that this series diverges, but we've only been given a certain amount of tools to use. We can't use Cauchy's condensation test, and if I wish to use the integral test I have to show that $f(x)$ is monotone (easy) and also that $f(x)$ is continuous (and the only tool we have for that is $\epsilon$-$\delta$). I've seen that there are very similar questions to this on the site, but they don't particularly help in my case. Have I missed something? Thanks for your time. EDIT: Thank you everyone for your help. Much appreciated!","I wish to show $\sum_{n=2}^{\infty}\frac{1}{n\ln n}$ diverges. I initially wanted to use the comparison test, but couldn't come up with a series that is obviously less than $\frac{1}{n\ln n}$ that diverges. So I moved on to the integral test. The problem here is that I need to show that $f(x)=\frac{1}{x\ln x}$ is continuous on $[2,\infty)$, using $\epsilon$-$\delta$ definition of continuity. I've been given theorems that allow me to just assert that $\ln x$ is continuous on the interval, as I know $1$ is continuous, $x$ is continuous, and so if $\ln x$ is continuous then as we have a composition of continuous functions, $\frac{1}{x\ln x}$ will be continuous on $[2,\infty)$. The trouble I'm having is showing $\ln x$ is continuous. I again got stuck doing this. And now it feels like I've completely over-complicated things. I need to be rigorous when showing that this series diverges, but we've only been given a certain amount of tools to use. We can't use Cauchy's condensation test, and if I wish to use the integral test I have to show that $f(x)$ is monotone (easy) and also that $f(x)$ is continuous (and the only tool we have for that is $\epsilon$-$\delta$). I've seen that there are very similar questions to this on the site, but they don't particularly help in my case. Have I missed something? Thanks for your time. EDIT: Thank you everyone for your help. Much appreciated!",,"['real-analysis', 'sequences-and-series']"
9,"Find sequences such that $\lim_{n \to \infty} (\sqrt{a_n}-\sqrt{b_n})=\pi$, with $a_n,b_n \in Q$, increasing and defined by recursion","Find sequences such that , with , increasing and defined by recursion","\lim_{n \to \infty} (\sqrt{a_n}-\sqrt{b_n})=\pi a_n,b_n \in Q","For any real number $r$ we can find a pair of natural numbers $N$ and $M$, such that $\sqrt{N}-\sqrt{M}$ will approximate $r$ with any given precision (if we choose $N,M$ large enough). That's why I tried to think of any increasing sequences of integer numbers which would allow to compute $\pi$ in this way. And I mean, without knowing the digits of $\pi$ beforehand. Thus, $a_n, b_n$ have to be defined by recursion themselves. However, I wasn't able to make any progress. 1) The easiest way is to use the known value of $\pi$ to compute various pairs of $N,p$, such that: $$\sqrt{N+p}-\sqrt{N} \approx \pi$$ $$N=\left[\frac{(p-\pi^2)^2}{4 \pi^2} \right]$$ Here $[]$ is the floor function. For example: $$\sqrt{30268+1103}-\sqrt{30268}=3.14159$$ 2) If we let the numbers be rational, and not necessarily increasing, we can use the known series to make something resembling what I want: $$\pi^2=6 \left(1+\frac{1}{2^2}+\frac{1}{3^2}+\cdots \right)$$ $$\pi=\sqrt{6 \left(1+\frac{1}{2^2}+\frac{1}{3^2}+\cdots \right)}-\sqrt{0}$$ 3) Another way, is to use the Spiral of Theodorus (spiral of square roots): $$\rho (n)=\sqrt{n}$$ $$\phi (n)=\sum_{k=1}^{n} \arcsin \frac{1}{\sqrt{n}}-\frac{\pi}{2}$$ The $\pi$ arises as a limit of radii difference at approximately the same angle: $$\lim_{n \to \infty} \rho(\phi+2\pi)-\rho(\phi)=\pi$$ For example, the first such pair of numbers is: $$\sqrt{21}-\sqrt{2}=3.17$$ However, I'm not sure if it's possible to properly define a sequence I want using this definition for a spiral - it's just too complicated (especially, finding pairs of rays with the closest angles). Can we find sequences $\{a_n\}, \{b_n\}$ with $a_n,b_n \in \mathbb{Q}$, increasing and defined by recursion, such that $$\lim_{n \to \infty} (\sqrt{a_n}-\sqrt{b_n})=\pi$$? Or can we prove that we can't? Edit I only consider rational sequences because I don't believe that any such integer sequences exist. However, I would be very happy if someone answers with integer sequences. The main thing though, I want something different from $$\lim_{n \to \infty} \sqrt{a_n} = \pi+c, ~~~~ \lim_{n \to \infty} \sqrt{b_n}=c$$","For any real number $r$ we can find a pair of natural numbers $N$ and $M$, such that $\sqrt{N}-\sqrt{M}$ will approximate $r$ with any given precision (if we choose $N,M$ large enough). That's why I tried to think of any increasing sequences of integer numbers which would allow to compute $\pi$ in this way. And I mean, without knowing the digits of $\pi$ beforehand. Thus, $a_n, b_n$ have to be defined by recursion themselves. However, I wasn't able to make any progress. 1) The easiest way is to use the known value of $\pi$ to compute various pairs of $N,p$, such that: $$\sqrt{N+p}-\sqrt{N} \approx \pi$$ $$N=\left[\frac{(p-\pi^2)^2}{4 \pi^2} \right]$$ Here $[]$ is the floor function. For example: $$\sqrt{30268+1103}-\sqrt{30268}=3.14159$$ 2) If we let the numbers be rational, and not necessarily increasing, we can use the known series to make something resembling what I want: $$\pi^2=6 \left(1+\frac{1}{2^2}+\frac{1}{3^2}+\cdots \right)$$ $$\pi=\sqrt{6 \left(1+\frac{1}{2^2}+\frac{1}{3^2}+\cdots \right)}-\sqrt{0}$$ 3) Another way, is to use the Spiral of Theodorus (spiral of square roots): $$\rho (n)=\sqrt{n}$$ $$\phi (n)=\sum_{k=1}^{n} \arcsin \frac{1}{\sqrt{n}}-\frac{\pi}{2}$$ The $\pi$ arises as a limit of radii difference at approximately the same angle: $$\lim_{n \to \infty} \rho(\phi+2\pi)-\rho(\phi)=\pi$$ For example, the first such pair of numbers is: $$\sqrt{21}-\sqrt{2}=3.17$$ However, I'm not sure if it's possible to properly define a sequence I want using this definition for a spiral - it's just too complicated (especially, finding pairs of rays with the closest angles). Can we find sequences $\{a_n\}, \{b_n\}$ with $a_n,b_n \in \mathbb{Q}$, increasing and defined by recursion, such that $$\lim_{n \to \infty} (\sqrt{a_n}-\sqrt{b_n})=\pi$$? Or can we prove that we can't? Edit I only consider rational sequences because I don't believe that any such integer sequences exist. However, I would be very happy if someone answers with integer sequences. The main thing though, I want something different from $$\lim_{n \to \infty} \sqrt{a_n} = \pi+c, ~~~~ \lim_{n \to \infty} \sqrt{b_n}=c$$",,"['sequences-and-series', 'limits', 'pi']"
10,A conjecture concerning the irreducibility of characteristic polynomials of Arndt matrices,A conjecture concerning the irreducibility of characteristic polynomials of Arndt matrices,,"Letting $n \in \mathbb{N}$, let $M_{n}$ denote the $n \times n$ binary matrix with ones along the main antidiagonal and everywhere below the main antidiagonal and ones along the antidiagonal two positions above the main antidiagonal, and with zeros everywhere else. For example, we have that: $$M_{7} =\left(  \begin{matrix}   0 & 0 & 0  & 0  & 1  & 0  & 1 \\   0 & 0 & 0  & 1  & 0  & 1  & 1 \\   0 & 0 & 1  & 0  & 1  & 1  & 1 \\   0 & 1 & 0  & 1  & 1  & 1  & 1 \\   1 & 0 & 1  & 1  & 1  & 1  & 1 \\   0 & 1 & 1  & 1  & 1  & 1  & 1 \\   1 & 1 & 1 &  1  &  1  &  1   &  1   \end{matrix}\right).$$ I refer to matrices of this form as Arndt matrices , based on the following conjecture due to Joerg Arndt (see https://oeis.org/A047211 ) which has been tested up to $n=177$: Conjecture (Arndt, 2011): The characteristic polynomial of $M_{n}$ is irreducible over $\mathbb{Q}$ if and only if $n$ is congruent to an element in $\{ 2, 4 \}$ modulo $5$. I have been interested in this conjecture for some time, and have made numerous attempts to prove this conjecture. My first attempt at proving this conjecture was to try to find a general technique for row-reducing matrices of the form $x I_{n} - M_{n}$ in order to evaluate $\text{det}(x I_{n} - M_{n})$. However, the process of row-reducing matrices of this form is very complicated. I have also considered using the Leibniz formula for determinants and cofactor expansion to evaluate $\text{det}(x I_{n} - M_{n})$, but this also seems to be very complicated. I have also considered using a recursive/inductive approach, by considering the possibility of expressing $\text{det}(x I_{n} - M_{n})$ in terms of expressions of the form $\text{det}(x I_{m} - M_{m})$ for $m<n$, but it is not clear how to construct such a recursive formula. I have several questions related to Arndt's conjecture, listed below: (1) Is there a simple way of evaluating $\text{det}(x I_{n} - M_{n})$? Is there a simple combinatorial formula for the coefficients of $\text{det}(x I_{n} - M_{n})$? (2) Is there an intuitive/heuristic explanation as to ""why"" the above conjecture may be true? (3) Do you have any suggestions or general insights as to how to approach the problem of proving the above conjecture?","Letting $n \in \mathbb{N}$, let $M_{n}$ denote the $n \times n$ binary matrix with ones along the main antidiagonal and everywhere below the main antidiagonal and ones along the antidiagonal two positions above the main antidiagonal, and with zeros everywhere else. For example, we have that: $$M_{7} =\left(  \begin{matrix}   0 & 0 & 0  & 0  & 1  & 0  & 1 \\   0 & 0 & 0  & 1  & 0  & 1  & 1 \\   0 & 0 & 1  & 0  & 1  & 1  & 1 \\   0 & 1 & 0  & 1  & 1  & 1  & 1 \\   1 & 0 & 1  & 1  & 1  & 1  & 1 \\   0 & 1 & 1  & 1  & 1  & 1  & 1 \\   1 & 1 & 1 &  1  &  1  &  1   &  1   \end{matrix}\right).$$ I refer to matrices of this form as Arndt matrices , based on the following conjecture due to Joerg Arndt (see https://oeis.org/A047211 ) which has been tested up to $n=177$: Conjecture (Arndt, 2011): The characteristic polynomial of $M_{n}$ is irreducible over $\mathbb{Q}$ if and only if $n$ is congruent to an element in $\{ 2, 4 \}$ modulo $5$. I have been interested in this conjecture for some time, and have made numerous attempts to prove this conjecture. My first attempt at proving this conjecture was to try to find a general technique for row-reducing matrices of the form $x I_{n} - M_{n}$ in order to evaluate $\text{det}(x I_{n} - M_{n})$. However, the process of row-reducing matrices of this form is very complicated. I have also considered using the Leibniz formula for determinants and cofactor expansion to evaluate $\text{det}(x I_{n} - M_{n})$, but this also seems to be very complicated. I have also considered using a recursive/inductive approach, by considering the possibility of expressing $\text{det}(x I_{n} - M_{n})$ in terms of expressions of the form $\text{det}(x I_{m} - M_{m})$ for $m<n$, but it is not clear how to construct such a recursive formula. I have several questions related to Arndt's conjecture, listed below: (1) Is there a simple way of evaluating $\text{det}(x I_{n} - M_{n})$? Is there a simple combinatorial formula for the coefficients of $\text{det}(x I_{n} - M_{n})$? (2) Is there an intuitive/heuristic explanation as to ""why"" the above conjecture may be true? (3) Do you have any suggestions or general insights as to how to approach the problem of proving the above conjecture?",,"['sequences-and-series', 'matrices', 'determinant']"
11,Bijection between $\mathbb{Z}^2$ and bounded sequences - Miklos Schweitzer,Bijection between  and bounded sequences - Miklos Schweitzer,\mathbb{Z}^2,"Let $\alpha \leq-2 $  be an integer. Prove that for every pair $\beta_{0},\beta_{1}$    of integers there exists a uniquely determined sequence    $0 \leq q_{0},...,q_{k}<\alpha^2-\alpha$ of integers, such that $q_{k}\neq0$ if   $(\beta_{0},\beta_{1})\neq(0,0)$ and $\beta_{i}=\sum\limits_{j=0}^k q_{j}(\alpha-i)^j$ for $i=0,1$. This question is from Miklos Schweitzer 2001. My idea was to show that there are unique polynomials $P_1,P_2 \in \mathbb{Z}[x]$ such that: $P(x)=-\beta_{1}(x-\alpha) \displaystyle \frac{P_1(x)}{P_1(\alpha-1)}-\beta_{0}(x-\alpha-1)\displaystyle \frac{P_2(x)}{P_2(\alpha)}$ and all coefficients of $P(x)$ are in the interval $[0,\alpha^2-\alpha).$ However I couldn't go any further.","Let $\alpha \leq-2 $  be an integer. Prove that for every pair $\beta_{0},\beta_{1}$    of integers there exists a uniquely determined sequence    $0 \leq q_{0},...,q_{k}<\alpha^2-\alpha$ of integers, such that $q_{k}\neq0$ if   $(\beta_{0},\beta_{1})\neq(0,0)$ and $\beta_{i}=\sum\limits_{j=0}^k q_{j}(\alpha-i)^j$ for $i=0,1$. This question is from Miklos Schweitzer 2001. My idea was to show that there are unique polynomials $P_1,P_2 \in \mathbb{Z}[x]$ such that: $P(x)=-\beta_{1}(x-\alpha) \displaystyle \frac{P_1(x)}{P_1(\alpha-1)}-\beta_{0}(x-\alpha-1)\displaystyle \frac{P_2(x)}{P_2(\alpha)}$ and all coefficients of $P(x)$ are in the interval $[0,\alpha^2-\alpha).$ However I couldn't go any further.",,"['sequences-and-series', 'number-theory', 'polynomials']"
12,Evaluate $\sum \frac{(-1)^{n+1}}{2(n!)+1}.$ [closed],Evaluate  [closed],\sum \frac{(-1)^{n+1}}{2(n!)+1}.,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question My problem is to find the sum  of the following series  $$\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{2(n!)+1}.$$ I tried but I got struck. Any help/hints are appreciated!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question My problem is to find the sum  of the following series  $$\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{2(n!)+1}.$$ I tried but I got struck. Any help/hints are appreciated!",,"['real-analysis', 'sequences-and-series', 'analysis']"
13,If $x_n\to0$ and $(x_{n+1}-x_n)/x_n^p$ converges then $\sum x_n$ converges or diverges?,If  and  converges then  converges or diverges?,x_n\to0 (x_{n+1}-x_n)/x_n^p \sum x_n,"Let $p>1$ be a real number and $\{x_n\}$ be a sequence of positive real numbers such that    $$\lim_{n \to \infty} x_n=0$$   and such that $\Big\{\frac{x_{n+1}-x_n}{x_n^p}\Big\}$ is convergent with a non-zero limit. Is it true that $\sum x_n$   converges if and only if $p<2$ ? From the given condition it is immediate that $\sum x_n^p$ is convergent , but I cannot proceed further.","Let $p>1$ be a real number and $\{x_n\}$ be a sequence of positive real numbers such that    $$\lim_{n \to \infty} x_n=0$$   and such that $\Big\{\frac{x_{n+1}-x_n}{x_n^p}\Big\}$ is convergent with a non-zero limit. Is it true that $\sum x_n$   converges if and only if $p<2$ ? From the given condition it is immediate that $\sum x_n^p$ is convergent , but I cannot proceed further.",,['real-analysis']
14,"$\sum_{n= 0}^{\infty}a_n$ converges, what other series must then also converge?","converges, what other series must then also converge?",\sum_{n= 0}^{\infty}a_n,I got the following test question: Series $\sum_{n= 0}^{\infty}a_n$ converges. Which of the series below must also converge: 1) $\sum_{n= 0}^{\infty}na_n$ 2) $\sum_{n= 0}^{\infty}a_n^2$ 3 $\sum_{n= 0}^{\infty}(-1)^na_n$ To me it looks like non of the above should necessarily converge. 1) $\sum_{n= 1}^{\infty}\frac{1}{n^2}$ converges but $\sum_{n= 1}^{\infty}\frac{1}{n}$ does not. 2) $\sum_{n= 1}^{\infty}(-1)^n\frac{1}{\sqrt{n}}$ converges (Leibniz criterion) but $\sum_{n= 1}^{\infty}\frac{1}{n}$ does not. 3) $\sum_{n= 1}^{\infty}(-1)^n\frac{1}{n}$ converges but $\sum_{n= 1}^{\infty}(-1)^n(-1)^n\frac{1}{n}=\sum_{n= 1}^{\infty}\frac{1}{n}$ does not. What am I missing?,I got the following test question: Series $\sum_{n= 0}^{\infty}a_n$ converges. Which of the series below must also converge: 1) $\sum_{n= 0}^{\infty}na_n$ 2) $\sum_{n= 0}^{\infty}a_n^2$ 3 $\sum_{n= 0}^{\infty}(-1)^na_n$ To me it looks like non of the above should necessarily converge. 1) $\sum_{n= 1}^{\infty}\frac{1}{n^2}$ converges but $\sum_{n= 1}^{\infty}\frac{1}{n}$ does not. 2) $\sum_{n= 1}^{\infty}(-1)^n\frac{1}{\sqrt{n}}$ converges (Leibniz criterion) but $\sum_{n= 1}^{\infty}\frac{1}{n}$ does not. 3) $\sum_{n= 1}^{\infty}(-1)^n\frac{1}{n}$ converges but $\sum_{n= 1}^{\infty}(-1)^n(-1)^n\frac{1}{n}=\sum_{n= 1}^{\infty}\frac{1}{n}$ does not. What am I missing?,,['sequences-and-series']
15,"Concept of ""eventually almost surely"" as an artefact of measure-theoretic axioms?","Concept of ""eventually almost surely"" as an artefact of measure-theoretic axioms?",,"This is a serious question despite provocative title. Ever since I found out about Cox's theorem , I got quite enthusiastic about an alternative approach to formalising probability theory and started thinking about what are the consequences of our standard measure-theoretic school. This brings me to Borel–Cantelli lemma and its ability to show that a sequence of events will stop happening, almost surely, provided their probabilities are summable. Nice theoretic result, but practitioners of applied probability stress the importance of actually controlling the rate of convergence . In other words, the fact that an event will stop happening doesn't tell us how far down the sequence we have to go for the result to be true: $1, 5, \dots, $ Graham' number. So whilst I don't deny the validity of Borel-Cantelli, I merely want to know whether the emphasis on the significance of almost-sure convergence is misplaced and more mathematicians should strive to control the immediate rate of convergence rather than showing that the rate of converge is eventually dominated by a summable sequence. Answer 1: Can you not say the same thing about a convergence of any sequence? No, many proofs I've seen construct $N_{\varepsilon}$ for any $\varepsilon > 0$ in a proof of convergence, so the rate of convergence is not hard to extract. Also the concept of uniform convergence helps us to control the rate. Answer 2: Pure mathematicians shouldn't worry about immediate applications of their results, so your question is misdirected. Indeed, but what if there's a strong bias to care about a particular set of problems just as a consequence of axiomatising probability theory? Had we started with Cox's approach instead, would propositions like ""In this sequence of events, the events will stop happening, eventually"" be given as much attention? Answer 3: Dealing with infinities often lead to counter-intuitive results, which often, in retrospect, are shown to be useful much later. After many years since accepting measure-theory as underlying axioms, shouldn't we start looking at what kind of useful things came out of it and questioning whether our axioms were indeed conductive to useful research?","This is a serious question despite provocative title. Ever since I found out about Cox's theorem , I got quite enthusiastic about an alternative approach to formalising probability theory and started thinking about what are the consequences of our standard measure-theoretic school. This brings me to Borel–Cantelli lemma and its ability to show that a sequence of events will stop happening, almost surely, provided their probabilities are summable. Nice theoretic result, but practitioners of applied probability stress the importance of actually controlling the rate of convergence . In other words, the fact that an event will stop happening doesn't tell us how far down the sequence we have to go for the result to be true: $1, 5, \dots, $ Graham' number. So whilst I don't deny the validity of Borel-Cantelli, I merely want to know whether the emphasis on the significance of almost-sure convergence is misplaced and more mathematicians should strive to control the immediate rate of convergence rather than showing that the rate of converge is eventually dominated by a summable sequence. Answer 1: Can you not say the same thing about a convergence of any sequence? No, many proofs I've seen construct $N_{\varepsilon}$ for any $\varepsilon > 0$ in a proof of convergence, so the rate of convergence is not hard to extract. Also the concept of uniform convergence helps us to control the rate. Answer 2: Pure mathematicians shouldn't worry about immediate applications of their results, so your question is misdirected. Indeed, but what if there's a strong bias to care about a particular set of problems just as a consequence of axiomatising probability theory? Had we started with Cox's approach instead, would propositions like ""In this sequence of events, the events will stop happening, eventually"" be given as much attention? Answer 3: Dealing with infinities often lead to counter-intuitive results, which often, in retrospect, are shown to be useful much later. After many years since accepting measure-theory as underlying axioms, shouldn't we start looking at what kind of useful things came out of it and questioning whether our axioms were indeed conductive to useful research?",,"['sequences-and-series', 'probability-theory', 'convergence-divergence', 'axioms', 'borel-cantelli-lemmas']"
16,Compact convergence of inverse functions,Compact convergence of inverse functions,,"Consider two metric spaces $X$ and $Y$ and a sequence of functions $f_n\colon X\to Y$ together with a function $f\colon X\to Y$. Assume, all $f_n$ and $f$ have inverse functions $g_n$ and $g$, say. It is true, that if $g$ is continuous and $f_n\to f$ compactly, i.e. uniformly on every compact set, then also the inverse functions $g_n$ converge to $g$ compactly. In Uniform convergence of functions, Spring 2002 they gave a nice proof for a similar result, using uniform convergence of $f_n$ and uniform continuity of $f$ to conclude that $g_n$ converge uniformly. The idea was to show that $f\circ g_n$ converges to $f\circ g$ uniformly and then conclude that also $g_n = g\circ f\circ g_n$ converge uniformly to $g = g\circ f\circ g$. I would be interested if it is possible to adapt this prove to compact convergence. The main problem I see is the following: Showing $f\circ g_n$ converges to $f\circ g$ compactly is equivalent to showing $f\circ g_n$ converges to $f_n\circ g_n$ compactly. But for fixed compact set $K\subset Y$ I do not see how we can guarantee that all $g_n(K)$ stay in the same compact set $L\subset X$. Hence, we can not apply compact convergence of $f_n$. Are there any ideas for finding the compact set $L$?","Consider two metric spaces $X$ and $Y$ and a sequence of functions $f_n\colon X\to Y$ together with a function $f\colon X\to Y$. Assume, all $f_n$ and $f$ have inverse functions $g_n$ and $g$, say. It is true, that if $g$ is continuous and $f_n\to f$ compactly, i.e. uniformly on every compact set, then also the inverse functions $g_n$ converge to $g$ compactly. In Uniform convergence of functions, Spring 2002 they gave a nice proof for a similar result, using uniform convergence of $f_n$ and uniform continuity of $f$ to conclude that $g_n$ converge uniformly. The idea was to show that $f\circ g_n$ converges to $f\circ g$ uniformly and then conclude that also $g_n = g\circ f\circ g_n$ converge uniformly to $g = g\circ f\circ g$. I would be interested if it is possible to adapt this prove to compact convergence. The main problem I see is the following: Showing $f\circ g_n$ converges to $f\circ g$ compactly is equivalent to showing $f\circ g_n$ converges to $f_n\circ g_n$ compactly. But for fixed compact set $K\subset Y$ I do not see how we can guarantee that all $g_n(K)$ stay in the same compact set $L\subset X$. Hence, we can not apply compact convergence of $f_n$. Are there any ideas for finding the compact set $L$?",,"['sequences-and-series', 'convergence-divergence', 'metric-spaces', 'inverse']"
17,Pointwise limits of differentiable functions under constraint,Pointwise limits of differentiable functions under constraint,,"It is known (by definition!) that the space of pointwise limits of continuous functions is the so called Baire class one functions, which can be characterized by their level sets (preimage of opens are all $F_\sigma$), or points of continuity (the Great Baire Theorem). It is not hard to see that any Baire class one function is a pointwise limit of a sequence of differentiable functions. My question is: what are the functions $f:I\to \bf R$ which are pointwise limit of a sequence of differentiable $(f_n)$ with $(f'_n)$ also pointwise convergent to a function $g$ say (we don't ask any link between $f'(x)$ and $g(x)$ whenever the two make sense - this is already known: whatever can happen)? I wonder if the constraint on the derivatives adds somethings about $f$. By using unbounded piecewise linear functions, on can get this way the characteristic functions of any segment, but already the case of the characteristic of open or closed sets is not clear (at least explicitly). Take e.g. $F$ a closed subset of $[0,1]$: I thought of the use of an approximately continuous function $f_n$ defined as zero on $F$ and on $F_n = \{x; dist(x, F) \geq 1/n\}$, and by a constant otherwise, so that its integral on $[0,1]$ is $1$, but in the case of $F = [a,b]$ it gives a kind of cumulative characteristic function ($0$ on $[0,a[$, $1/2$ on $[a,b[$, $1$ on $[b,1]$).","It is known (by definition!) that the space of pointwise limits of continuous functions is the so called Baire class one functions, which can be characterized by their level sets (preimage of opens are all $F_\sigma$), or points of continuity (the Great Baire Theorem). It is not hard to see that any Baire class one function is a pointwise limit of a sequence of differentiable functions. My question is: what are the functions $f:I\to \bf R$ which are pointwise limit of a sequence of differentiable $(f_n)$ with $(f'_n)$ also pointwise convergent to a function $g$ say (we don't ask any link between $f'(x)$ and $g(x)$ whenever the two make sense - this is already known: whatever can happen)? I wonder if the constraint on the derivatives adds somethings about $f$. By using unbounded piecewise linear functions, on can get this way the characteristic functions of any segment, but already the case of the characteristic of open or closed sets is not clear (at least explicitly). Take e.g. $F$ a closed subset of $[0,1]$: I thought of the use of an approximately continuous function $f_n$ defined as zero on $F$ and on $F_n = \{x; dist(x, F) \geq 1/n\}$, and by a constant otherwise, so that its integral on $[0,1]$ is $1$, but in the case of $F = [a,b]$ it gives a kind of cumulative characteristic function ($0$ on $[0,a[$, $1/2$ on $[a,b[$, $1$ on $[b,1]$).",,"['calculus', 'real-analysis', 'sequences-and-series', 'limits', 'derivatives']"
18,Nested Radicals: $\sqrt{a+\sqrt{2a+\sqrt{3a+\ldots}}}$,Nested Radicals:,\sqrt{a+\sqrt{2a+\sqrt{3a+\ldots}}},Let $a>0$ . How we can find the limit of : $$\sqrt{a+\sqrt{2a+\sqrt{3a+\ldots}}}$$ Thanks in advance for your help,Let $a>0$ . How we can find the limit of : $$\sqrt{a+\sqrt{2a+\sqrt{3a+\ldots}}}$$ Thanks in advance for your help,,"['calculus', 'limits']"
19,Approximate zeros of a (hypothetical) analog of $\zeta(s)$,Approximate zeros of a (hypothetical) analog of,\zeta(s),"[Added numbers 11/13.] Motivation (can skip). When prime powers $p_n$ are used to calculate $$y(x) = \sum_{n=1}^{N}\frac{\sin (x \log p_n)}{p_n},\hspace{5mm}(1)$$ for (say) $N= 30,$ $x>5$ , at sign changes $(+/ -)$ $y(x)$ seems to give approximately the imaginary parts $\gamma_r$ of  a subset of zeros of $\zeta(s).$ The first few zero indices, with some ambiguity when zeros are tightly spaced, are $r =  1, 2, 3, 4, 6, 7, 10, 11, 13, 16, 18,...$ It's a lacklustre approximation and I think this has been explained in other questions on this site. When the zeros (+/-) of (1) are used to form a well-known approximation of $$\sum x^{\rho}/\rho$$ which in pertinent part is $$\sum_r \frac{\sin (\gamma_r \log x)}{\gamma_r}\hspace{5mm}(2), $$ the resulting graph has discontinuities at the prime powers. If instead of primes (prime powers) we use non-prime powers $q_r$ in (1), we will also get a sequence of approximate ""zeros"" at sign changes (+/-). If we use them instead of $\gamma_r$ in the approximation(2), we might expect to see discontinuities at non-prime powers. This is apparently the case. Using 100 such ""zeros"" $\alpha_r$ the graph of $$\sum_r \frac{\sin (\alpha_r \log x)}{\alpha_r} $$ appears to show discontinuities at 1,6,10,12,14,15,... in the same way that (2) shows discontinuities at prime powers. Question. When non-prime powers $q_n$ are used to form $Y(x)=\sum_{n=1}^{N}\frac{\sin (x \log q_n)}{q_n},$ the zeros $\alpha_r$ at sign changes (+/-), inserted in $G(x)=\sum_r \frac{\sin (\alpha_r \log x)}{\alpha_r},$ give discontinuities at approximately non-prime powers. What meaning, if any, can be attached to the zeros $\alpha_r$ of $Y(x)$ ? Are they a subset of the complex parts of the zeros of some cousin of $\zeta(s)$ ? Omitting $\alpha_n< 5$ , in G(x) I used: 5.9, 7.3, 8.9, 12.2, 15.6, 19.9, 22.8, 26.0, 29.4, 31.5, 33.9, 36.6, 40, 42.2, 44.2, 47.2, 48.6, 50.85, 54, 55.7, 58.5, 61.6, 64.35, 66.2, 68.4, 70.15, 72.4, 75, 78, 79.9, 82.2, 83.9, 85.8, 89.5, 92.0, 93.8, 96.6, 99.6, 103.1, 104.65, 103.1, 104.7, 106.2, 107.8, 110.3, 113, 114.2, 117.9, 120.8, 124.9, 127.2, 131.6, 135.3, 137.6, 138.8, 140.7, 142, 143, 1, 145.5, 149.1, 151.8, 153.5, 155.8, 159.7, 163.2, 166.2, 168, 170.5, 173, 175.9, 176.2, 180.7, 184.2, 187.6, 189.9, 191.4, 194.5, 198.6, 200.9, 203.3, 205.9, 208.5, 211.5, 215.1, 216.6, 218.8, 222.3, 225.7, 226.7, 229, 230.5, 232.8, 234, 236.1, 241.8, 244.3, 246.6, 249, 250.2. The image using the values above in $G(x)$ shows discontinuities at 1,6,10,12,14,15,18 but quickly deteriorates.","[Added numbers 11/13.] Motivation (can skip). When prime powers are used to calculate for (say) , at sign changes seems to give approximately the imaginary parts of  a subset of zeros of The first few zero indices, with some ambiguity when zeros are tightly spaced, are It's a lacklustre approximation and I think this has been explained in other questions on this site. When the zeros (+/-) of (1) are used to form a well-known approximation of which in pertinent part is the resulting graph has discontinuities at the prime powers. If instead of primes (prime powers) we use non-prime powers in (1), we will also get a sequence of approximate ""zeros"" at sign changes (+/-). If we use them instead of in the approximation(2), we might expect to see discontinuities at non-prime powers. This is apparently the case. Using 100 such ""zeros"" the graph of appears to show discontinuities at 1,6,10,12,14,15,... in the same way that (2) shows discontinuities at prime powers. Question. When non-prime powers are used to form the zeros at sign changes (+/-), inserted in give discontinuities at approximately non-prime powers. What meaning, if any, can be attached to the zeros of ? Are they a subset of the complex parts of the zeros of some cousin of ? Omitting , in G(x) I used: 5.9, 7.3, 8.9, 12.2, 15.6, 19.9, 22.8, 26.0, 29.4, 31.5, 33.9, 36.6, 40, 42.2, 44.2, 47.2, 48.6, 50.85, 54, 55.7, 58.5, 61.6, 64.35, 66.2, 68.4, 70.15, 72.4, 75, 78, 79.9, 82.2, 83.9, 85.8, 89.5, 92.0, 93.8, 96.6, 99.6, 103.1, 104.65, 103.1, 104.7, 106.2, 107.8, 110.3, 113, 114.2, 117.9, 120.8, 124.9, 127.2, 131.6, 135.3, 137.6, 138.8, 140.7, 142, 143, 1, 145.5, 149.1, 151.8, 153.5, 155.8, 159.7, 163.2, 166.2, 168, 170.5, 173, 175.9, 176.2, 180.7, 184.2, 187.6, 189.9, 191.4, 194.5, 198.6, 200.9, 203.3, 205.9, 208.5, 211.5, 215.1, 216.6, 218.8, 222.3, 225.7, 226.7, 229, 230.5, 232.8, 234, 236.1, 241.8, 244.3, 246.6, 249, 250.2. The image using the values above in shows discontinuities at 1,6,10,12,14,15,18 but quickly deteriorates.","p_n y(x) = \sum_{n=1}^{N}\frac{\sin (x \log p_n)}{p_n},\hspace{5mm}(1) N= 30, x>5 (+/ -) y(x) \gamma_r \zeta(s). r =  1, 2, 3, 4, 6, 7, 10, 11, 13, 16, 18,... \sum x^{\rho}/\rho \sum_r \frac{\sin (\gamma_r \log x)}{\gamma_r}\hspace{5mm}(2),  q_r \gamma_r \alpha_r \sum_r \frac{\sin (\alpha_r \log x)}{\alpha_r}  q_n Y(x)=\sum_{n=1}^{N}\frac{\sin (x \log q_n)}{q_n}, \alpha_r G(x)=\sum_r \frac{\sin (\alpha_r \log x)}{\alpha_r}, \alpha_r Y(x) \zeta(s) \alpha_n< 5 G(x)","['sequences-and-series', 'prime-numbers', 'riemann-zeta']"
20,Convergent/divergent series,Convergent/divergent series,,"Is the following series divergent/convergent? $$S=1-\frac{1}{2}-\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}-\frac{1}{7}-\frac{1}{8}-\frac{1}{9}-\frac{1}{10}+\frac{1}{11}+\frac{1}{12}+\frac{1}{13}+\frac{1}{14}+\frac{1}{15}-...$$ I think it is divergent since $$ \begin{align} S&>1-\frac{1}{2}-\frac{1}{2}+4\cdot\frac{1}{6}-\frac{4}{7}+\frac{5}{15}-\frac{6}{16}+...\\ &=1/3-4/7+1/3-6/16+...=\sum_{n=1}^\infty 1/3-\alpha_n \end{align} $$ where $\alpha_n=4/7, 6/16, 8/22$ which tends to 0, so the series on the right hand side is divergent. Is this the right answer? Thanks","Is the following series divergent/convergent? $$S=1-\frac{1}{2}-\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}-\frac{1}{7}-\frac{1}{8}-\frac{1}{9}-\frac{1}{10}+\frac{1}{11}+\frac{1}{12}+\frac{1}{13}+\frac{1}{14}+\frac{1}{15}-...$$ I think it is divergent since $$ \begin{align} S&>1-\frac{1}{2}-\frac{1}{2}+4\cdot\frac{1}{6}-\frac{4}{7}+\frac{5}{15}-\frac{6}{16}+...\\ &=1/3-4/7+1/3-6/16+...=\sum_{n=1}^\infty 1/3-\alpha_n \end{align} $$ where $\alpha_n=4/7, 6/16, 8/22$ which tends to 0, so the series on the right hand side is divergent. Is this the right answer? Thanks",,"['real-analysis', 'sequences-and-series']"
21,Is the longest chain of non-increasing values in this sequence related to cyclotomic polynomials unbounded?,Is the longest chain of non-increasing values in this sequence related to cyclotomic polynomials unbounded?,,"The $n$th order cyclotomic polynomial is defined as $$ \Phi_n(x) = \prod_{\substack{1\le k\le n \\ \gcd(k, n) = 1}}{\left(x - e^{2i\pi k/n}\right)} $$ Define $c_n$ to be the smallest integer $m$ such that $\Phi_m(x)$ contains a coefficient $\pm n$. It is well known that $c_n$ contains long chains of repeated values, ($c_8 = c_9$, and $c_{10}=c_{10+i}$ for $i = 1\dots4$). Now let $C_n$ be the length of the longest chain of repeated values in $\{c_k\}_{k=1\dots n}$. Given the definitions above, is $C_n$ unbounded? I have no idea where to even start with this one. Any ideas?","The $n$th order cyclotomic polynomial is defined as $$ \Phi_n(x) = \prod_{\substack{1\le k\le n \\ \gcd(k, n) = 1}}{\left(x - e^{2i\pi k/n}\right)} $$ Define $c_n$ to be the smallest integer $m$ such that $\Phi_m(x)$ contains a coefficient $\pm n$. It is well known that $c_n$ contains long chains of repeated values, ($c_8 = c_9$, and $c_{10}=c_{10+i}$ for $i = 1\dots4$). Now let $C_n$ be the length of the longest chain of repeated values in $\{c_k\}_{k=1\dots n}$. Given the definitions above, is $C_n$ unbounded? I have no idea where to even start with this one. Any ideas?",,"['sequences-and-series', 'cyclotomic-polynomials']"
22,Prove that for each integer $n \ge 2$ there exists a prime number $p$ dividing $a_n$,Prove that for each integer  there exists a prime number  dividing,n \ge 2 p a_n,"Let $c \ge 1$ be an integer. Define a sequence of positive integers by $a_1 = c$ and $$a_{n+1}=a_n^3-4c\cdot a_n^2+5c^2\cdot a_n+c$$ for all $n\ge 1$. Prove that for each integer $n \ge 2$ there exists a prime number $p$ dividing $a_n$ but none of the numbers $a_1 , \ldots , a_{n -1}$","Let $c \ge 1$ be an integer. Define a sequence of positive integers by $a_1 = c$ and $$a_{n+1}=a_n^3-4c\cdot a_n^2+5c^2\cdot a_n+c$$ for all $n\ge 1$. Prove that for each integer $n \ge 2$ there exists a prime number $p$ dividing $a_n$ but none of the numbers $a_1 , \ldots , a_{n -1}$",,['sequences-and-series']
23,A sequence avoiding 3-term power progressions,A sequence avoiding 3-term power progressions,,"Rankin 1 studied sequences of integers that avoid 3-term geometric progressions, $(a, a c, a c^2)$, e.g., $$\{1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 19, \ldots \} \;$$ So, $18$ is excluded because $(2,6,18)=(2,2 {\cdot} 3, 2 {\cdot} 3^2)$ forms a geometric progression. He showed that the asymptotic density of that greedy sequence exceeds $0.71$. I wondered about sequences that avoid 3-term power progressions , $(a, a c, a c^k)$, where $c\ge 2$ and $k\ge 2$ are natural numbers. Here I start again with $(1,2)$ and continue to add the first number that avoids all 3-term power progressions: $$\{1, 2, 3, 5, 6, 7, 10, 11, 13, 14, 15, 17, 19, 21, 22, 23, 26, 29,  30, 31, 33, 34, 35, 37, \ldots \}\;.$$ For example, $8$ is excluded because $(1,2,8)=(1,1{\cdot} 2, 1 {\cdot} 2^3)$ is a power sequence. Much later, $945$ is excluded because $(35,105,945)=(35, 35{\cdot} 3, 35 {\cdot} 3^3)$. Q . What is the asymptotic density of the above greedy sequence   that avoids all 3-term power progressions? The density appears to be about $0.63$, up to $644$ terms ending in $1021$. Note that the square-free integers have density $6/\pi^2 \approx 0.61$. My sequence is square-free, cube-free, etc., because $(1, c, c^k)$ is a  power progression. 1 R. Rankin. ""Sets of integers containing not more than a given number of terms in arithmetical progression."" Proc. Roy. Soc. Edinburgh Sect. A . 65 (1961). Cited by Nathan McNew in poster, ""Avoiding Geometric Progressions in the Integers."" ( PDF download .)","Rankin 1 studied sequences of integers that avoid 3-term geometric progressions, $(a, a c, a c^2)$, e.g., $$\{1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 19, \ldots \} \;$$ So, $18$ is excluded because $(2,6,18)=(2,2 {\cdot} 3, 2 {\cdot} 3^2)$ forms a geometric progression. He showed that the asymptotic density of that greedy sequence exceeds $0.71$. I wondered about sequences that avoid 3-term power progressions , $(a, a c, a c^k)$, where $c\ge 2$ and $k\ge 2$ are natural numbers. Here I start again with $(1,2)$ and continue to add the first number that avoids all 3-term power progressions: $$\{1, 2, 3, 5, 6, 7, 10, 11, 13, 14, 15, 17, 19, 21, 22, 23, 26, 29,  30, 31, 33, 34, 35, 37, \ldots \}\;.$$ For example, $8$ is excluded because $(1,2,8)=(1,1{\cdot} 2, 1 {\cdot} 2^3)$ is a power sequence. Much later, $945$ is excluded because $(35,105,945)=(35, 35{\cdot} 3, 35 {\cdot} 3^3)$. Q . What is the asymptotic density of the above greedy sequence   that avoids all 3-term power progressions? The density appears to be about $0.63$, up to $644$ terms ending in $1021$. Note that the square-free integers have density $6/\pi^2 \approx 0.61$. My sequence is square-free, cube-free, etc., because $(1, c, c^k)$ is a  power progression. 1 R. Rankin. ""Sets of integers containing not more than a given number of terms in arithmetical progression."" Proc. Roy. Soc. Edinburgh Sect. A . 65 (1961). Cited by Nathan McNew in poster, ""Avoiding Geometric Progressions in the Integers."" ( PDF download .)",,"['sequences-and-series', 'number-theory']"
24,How can I show that the sequence $x_n^2$ is bounded?,How can I show that the sequence  is bounded?,x_n^2,"Two real sequences $(x_n)$ and $(y_n)$ are defined by  $$x_{n+1}=x_n-(x_ny_n+x_{n+1}y_{n+1}-2)(y_n+y_{n+1})$$ $$y_{n+1}=y_n-(x_ny_n+x_{n+1}y_{n+1}-2)(x_n+x_{n+1})$$ with $x_0=1$ and $y_0=2007.$  I need to show that $|x_n|\lt \sqrt{2007}$ for all $n\in\mathbb{N}.$ I proved that $$x_{n+1}^2-x_n^2=y_{n+1}^2-y_n^2\,\,\,\,\,\,\,\,\,\,\forall n\in\mathbb{N},$$ which implies $|x_n|\lt|y_n|$ and $$x_n^2=y_n^2-2007^2+1.$$ Also I would like to know that, Is $x_n$ convergent? Any Idea?","Two real sequences $(x_n)$ and $(y_n)$ are defined by  $$x_{n+1}=x_n-(x_ny_n+x_{n+1}y_{n+1}-2)(y_n+y_{n+1})$$ $$y_{n+1}=y_n-(x_ny_n+x_{n+1}y_{n+1}-2)(x_n+x_{n+1})$$ with $x_0=1$ and $y_0=2007.$  I need to show that $|x_n|\lt \sqrt{2007}$ for all $n\in\mathbb{N}.$ I proved that $$x_{n+1}^2-x_n^2=y_{n+1}^2-y_n^2\,\,\,\,\,\,\,\,\,\,\forall n\in\mathbb{N},$$ which implies $|x_n|\lt|y_n|$ and $$x_n^2=y_n^2-2007^2+1.$$ Also I would like to know that, Is $x_n$ convergent? Any Idea?",,"['real-analysis', 'sequences-and-series', 'recurrence-relations', 'recreational-mathematics']"
25,"Disprove, fix, prove: If {$a_n$} and {$b_n$} are increasing, then {$a_n b_n$} is increasing","Disprove, fix, prove: If {} and {} are increasing, then {} is increasing",a_n b_n a_n b_n,"Prove the statement wrong, fix it, then prove the new statement: If {$a_n$} and {$b_n$} are increasing, then {$a_n b_n$} is increasing. I think I'm headed in the right direction with this but I'm not sure. What I've tried: Consider the increasing sequence $\{\frac{-1}{n}\}$. Then $\{(\frac{-1}{n})(\frac{-1}{n})\}=\{\frac1{n^2}\}$. Since $\{\frac1{n^2}\}$ is decreasing, it makes a counterexample to the statement. The statement can then be amended: If $\{a_n\}$ and $\{b_n\}$ are increasing and $a_n>0 $and $b_n>0$ for every $n\ge1$, then $\{a_n b_n\}$ is increasing. Proof: Since $\{a_n\}$ and $\{b_n\}$ are increasing, we know that $a_{n+1}>a_n$ and $b_{n+1}>b_n$. Then consider two cases for the value of $b_n$: (i) If $b_n>0$, then $(a_n)(b_n)<(a_{n+1})(b_{n+1}) \implies a_nb_n<a_{n+1}b_{n+1}$ and $\{a_nb_n\}$ is increasing. (ii) If $b_n<0$, then $(a_n)(b_n)<(a_{n+1})(b_{n+1}) \implies a_nb_n>a_{n+1}b_{n+1}$ and $\{a_nb_n\}$ is decreasing. Therefore $\{a_nb_n\}$ is increasing when $a_n>0$ and $b_n>0$ for every $n\ge1$.","Prove the statement wrong, fix it, then prove the new statement: If {$a_n$} and {$b_n$} are increasing, then {$a_n b_n$} is increasing. I think I'm headed in the right direction with this but I'm not sure. What I've tried: Consider the increasing sequence $\{\frac{-1}{n}\}$. Then $\{(\frac{-1}{n})(\frac{-1}{n})\}=\{\frac1{n^2}\}$. Since $\{\frac1{n^2}\}$ is decreasing, it makes a counterexample to the statement. The statement can then be amended: If $\{a_n\}$ and $\{b_n\}$ are increasing and $a_n>0 $and $b_n>0$ for every $n\ge1$, then $\{a_n b_n\}$ is increasing. Proof: Since $\{a_n\}$ and $\{b_n\}$ are increasing, we know that $a_{n+1}>a_n$ and $b_{n+1}>b_n$. Then consider two cases for the value of $b_n$: (i) If $b_n>0$, then $(a_n)(b_n)<(a_{n+1})(b_{n+1}) \implies a_nb_n<a_{n+1}b_{n+1}$ and $\{a_nb_n\}$ is increasing. (ii) If $b_n<0$, then $(a_n)(b_n)<(a_{n+1})(b_{n+1}) \implies a_nb_n>a_{n+1}b_{n+1}$ and $\{a_nb_n\}$ is decreasing. Therefore $\{a_nb_n\}$ is increasing when $a_n>0$ and $b_n>0$ for every $n\ge1$.",,"['real-analysis', 'sequences-and-series']"
26,Multinomial Theorem for Negative Exponents,Multinomial Theorem for Negative Exponents,,"Using an analog to Newton's binomial theorem with negative exponents, is it true that $$ \begin{align} \left(\sum_{k=0}^mx^k\right)^{-n} & = \sum_{0\le i_0+...+i_m=n\lt\infty}\binom{-n}{i_0,i_1,...,i_m}1^{i_0}x^{i_1}...x^{mi_m} \\ & =\sum_{0\le i_0+...+i_m=n\lt\infty}\binom{-n}{i_1,...,n-i_0-...-i_{m-1}}x^{i_1}...x^{m(n-i_1-...-i_{m-1})} \\ & = \sum_{0\le i_0+...+i_m=n\lt\infty}\frac{-n(-n-1)...(-n-i_0-...-i_m+1)}{i_0!i_1!...i_{m-1}!}x^\alpha \\ & = \sum_{0\le i_0+...+i_m=n\lt\infty}(-1)^{i_0+...+i_{m-1}}\frac{n(n+1)...(n+i_0+...+i_m-1)}{i_0!i_1!...i_{m-1}!}x^\alpha \\ & = \sum_{0\le i_0+...+i_m=n\lt\infty}(-1)^\beta\frac{(n+i_0+...+i_m-1)!}{i_0!i_1!...i_{m-1}!(n-1)!}x^\alpha \\ & = \sum_{0\le i_0+...+i_m=n\lt\infty}(-1)^\beta\binom{n+i_0+...+i_m-1}{i_0,...,i_{m-1},n-1}x^\alpha \\ \end{align} $$ where $\beta=i_0+...+i_{m}$ and $\alpha=mn-mi_0-(m-1)i_1-...-i_{m-1}$?  I would like to keep the summation to ""1"" Sigma and a single coefficient (multinomial) instead of the product of multiple binomials, so i thought this might be a way to accomplish that... EDIT:  I know that we can use the Binomial theorem in order to get an expression, but I'm looking to see if i can write something ""simpler"" and with less notational devices.","Using an analog to Newton's binomial theorem with negative exponents, is it true that $$ \begin{align} \left(\sum_{k=0}^mx^k\right)^{-n} & = \sum_{0\le i_0+...+i_m=n\lt\infty}\binom{-n}{i_0,i_1,...,i_m}1^{i_0}x^{i_1}...x^{mi_m} \\ & =\sum_{0\le i_0+...+i_m=n\lt\infty}\binom{-n}{i_1,...,n-i_0-...-i_{m-1}}x^{i_1}...x^{m(n-i_1-...-i_{m-1})} \\ & = \sum_{0\le i_0+...+i_m=n\lt\infty}\frac{-n(-n-1)...(-n-i_0-...-i_m+1)}{i_0!i_1!...i_{m-1}!}x^\alpha \\ & = \sum_{0\le i_0+...+i_m=n\lt\infty}(-1)^{i_0+...+i_{m-1}}\frac{n(n+1)...(n+i_0+...+i_m-1)}{i_0!i_1!...i_{m-1}!}x^\alpha \\ & = \sum_{0\le i_0+...+i_m=n\lt\infty}(-1)^\beta\frac{(n+i_0+...+i_m-1)!}{i_0!i_1!...i_{m-1}!(n-1)!}x^\alpha \\ & = \sum_{0\le i_0+...+i_m=n\lt\infty}(-1)^\beta\binom{n+i_0+...+i_m-1}{i_0,...,i_{m-1},n-1}x^\alpha \\ \end{align} $$ where $\beta=i_0+...+i_{m}$ and $\alpha=mn-mi_0-(m-1)i_1-...-i_{m-1}$?  I would like to keep the summation to ""1"" Sigma and a single coefficient (multinomial) instead of the product of multiple binomials, so i thought this might be a way to accomplish that... EDIT:  I know that we can use the Binomial theorem in order to get an expression, but I'm looking to see if i can write something ""simpler"" and with less notational devices.",,"['sequences-and-series', 'combinatorics', 'binomial-theorem', 'multinomial-coefficients']"
27,How to calculate $\sum\frac{1}{(4k-1)(4k+4)}$?,How to calculate ?,\sum\frac{1}{(4k-1)(4k+4)},I'm trying to calculate $\sum_{k=1}^\infty\frac{1}{(4k-1)(4k+4)}$ using telescopic sums. I've already proved this equality: $\sum\frac{1}{(4k-1)(4k+4)}=\frac{1}{5}\big(\sum\frac{1}{4k-1}-\frac{1}{4k+4}\big)$. The problem is I can't cancel the terms of this sum. I need help Thanks,I'm trying to calculate $\sum_{k=1}^\infty\frac{1}{(4k-1)(4k+4)}$ using telescopic sums. I've already proved this equality: $\sum\frac{1}{(4k-1)(4k+4)}=\frac{1}{5}\big(\sum\frac{1}{4k-1}-\frac{1}{4k+4}\big)$. The problem is I can't cancel the terms of this sum. I need help Thanks,,"['real-analysis', 'sequences-and-series']"
28,Prove that a sequence $a_n$ converges iff $a_n^3$ converges,Prove that a sequence  converges iff  converges,a_n a_n^3,"I want to prove that $A\ sequence\ a_n\ converges\ \longleftrightarrow\ a_n^3\ converges$ If $a_n$ converges, then by arithmetics, $a_n^3$ converges. Now let $a_n^3$ converge to a real $L$. Take the function $f(x) = \sqrt[3]{x}$, which is well defined for each $x \in \mathbb{R}$. Then we know that $\forall n\in \mathbb{N}, f(a_n^3) = \sqrt[3]{a_n^3} = a_n$. $f$ is continuous, so by taking the limit: $\lim_{n\to\infty}a_n = \lim_{n\to\infty}f(a_n^3) = f(\lim_{n\to\infty}a_n^3) = f(L) = \sqrt[3]{L}$. Does this proof hold? And also, I was wondering how can you prove it from definition, using $\epsilon$ notation? Thanks!","I want to prove that $A\ sequence\ a_n\ converges\ \longleftrightarrow\ a_n^3\ converges$ If $a_n$ converges, then by arithmetics, $a_n^3$ converges. Now let $a_n^3$ converge to a real $L$. Take the function $f(x) = \sqrt[3]{x}$, which is well defined for each $x \in \mathbb{R}$. Then we know that $\forall n\in \mathbb{N}, f(a_n^3) = \sqrt[3]{a_n^3} = a_n$. $f$ is continuous, so by taking the limit: $\lim_{n\to\infty}a_n = \lim_{n\to\infty}f(a_n^3) = f(\lim_{n\to\infty}a_n^3) = f(L) = \sqrt[3]{L}$. Does this proof hold? And also, I was wondering how can you prove it from definition, using $\epsilon$ notation? Thanks!",,"['calculus', 'sequences-and-series', 'limits', 'proof-verification']"
29,$\zeta(2)=\frac{\pi^2}{6}$ proof improvement.,proof improvement.,\zeta(2)=\frac{\pi^2}{6},"Recently in one of my calculus exercise I have made out a (quite novel to me) proof for $\zeta(2)=\frac{\pi^2}{6}$ via the famous infinite product below: $$\sin(x)=x\prod_{i=1}^{\infty}(1-\frac{x^2}{i^2\pi^2})\tag{0}$$ I feel that the proof which I am to give below should count as one proper way to compute $\zeta(2)$ apart from the others (usually very complicated and requiring advanced knowledge) .I think this proof is more accessible to students who are learning very basic calculus and analysis (me, for example). Therefore, I want to improve this proof so that it can really hold water, and as a greenhand at analysis and caculus I need to seek help from this site to improve this proof, which I cannot finish alone. Any help will be appreciated.Thanks in advance. Here goes the proof: From $(0)$ we immediately know that $\forall x\ne0$ $$\frac{\sin(x)}{x}=\prod_{i=1}^{\infty}(1-\frac{x^2}{i^2\pi^2})\tag{1}$$ Now let $y=x^2>0$ and rewrite $(1)$ as $$\frac{\sin(\sqrt y)}{\sqrt y}=\prod_{i=1}^{\infty}(1-\frac{y}{i^2\pi^2})\tag{2}$$ For RHS in $(2)$, we may as well regard it as a ""polynomial"" with an infinite order and also infinitely many terms.Let's just call it $P(y)$. It is then obvious that all the solutions for $P(y)=0$ are as follows: $$y_i=i^2\pi^2$$ where $i\in\mathbb N^+$. Apparently they are distinct. Now consider a finite polynomial  $$P_n(y)=a_0+a_1 y+a_2 y^2+\cdots+a_{n-1}y^{n-1}+a_ny^n$$ Let $P_n(y)=0$, since $y>0$, it is ok to divide both sides by $y^n$, which yields $$a_0 \Bigl(\frac1y\Bigr)^n+a_1\Bigl(\frac1y\Bigr)^{n-1}+\cdots+a_{n-1}\Bigl(\frac1y\Bigr)+a_n=0\tag{3}$$ For each $y_i$ that is a solution to $P_n(y)=0$, $\frac{1}{y_i}$ will also be a solution to $(3)$ if we regard $(3)$ as a polynomial in terms of $\frac1y$. Therefore, by applying  the fundamental theorem of algebra to $(3)$ we get $$\sum_{i=1}^{n}\frac{1}{y_i}=-\frac{a_1}{a_0}\tag{4}$$ in which $y_i$s are distinct roots for $P_n(y)=0$. Then comes the key part, and that's also where I want more clarity on some issues . Let's return to $P(y)$, then infinite polynomial. By analogue, $(4)$ also holds for $P(y)$ ( clarification needed here!! ). Therefore, $$\sum_{i=1}^{\infty}\frac{1}{i^2\pi^2}=-\frac{a_1}{a_0}\tag{5}$$ in which $y_i=i^2\pi^2$ are distinct roots for $P(y)=0$ and $a_0$, $a_1$ are respectively the ""constant"" and ""coefficient for $y^1$"" in $P(y)$. To calculate $a_0$ and $a_1$, we must use limits since they are in a limit sense themselves. First, we have  $$a_0=\lim_{y\to 0}P(y)=\lim_{y\to 0}\frac{\sin\sqrt y}{\sqrt y}=1\tag{6}$$ Then we go on to calculate $a_1$, recall what we do with a finite polynomial, then by analogue it should be $$a_1=\lim_{y \to 0}\frac{P(y)-a_0}{y}=\lim_{y \to 0}\frac{\frac{\sin\sqrt y}{\sqrt y}-1}{y}=\frac{-\frac16 y+o(y)}{y}=-\frac16\tag{7}$$ (Intuitively I find $(6)$ and $(7)$ acceptable, but I also want some clarification so that they can be convincing.) Hence, at long last $$\sum_{i=1}^{\infty}\frac{1}{i^2}=-(-\frac{1}{6})\pi^2$$","Recently in one of my calculus exercise I have made out a (quite novel to me) proof for $\zeta(2)=\frac{\pi^2}{6}$ via the famous infinite product below: $$\sin(x)=x\prod_{i=1}^{\infty}(1-\frac{x^2}{i^2\pi^2})\tag{0}$$ I feel that the proof which I am to give below should count as one proper way to compute $\zeta(2)$ apart from the others (usually very complicated and requiring advanced knowledge) .I think this proof is more accessible to students who are learning very basic calculus and analysis (me, for example). Therefore, I want to improve this proof so that it can really hold water, and as a greenhand at analysis and caculus I need to seek help from this site to improve this proof, which I cannot finish alone. Any help will be appreciated.Thanks in advance. Here goes the proof: From $(0)$ we immediately know that $\forall x\ne0$ $$\frac{\sin(x)}{x}=\prod_{i=1}^{\infty}(1-\frac{x^2}{i^2\pi^2})\tag{1}$$ Now let $y=x^2>0$ and rewrite $(1)$ as $$\frac{\sin(\sqrt y)}{\sqrt y}=\prod_{i=1}^{\infty}(1-\frac{y}{i^2\pi^2})\tag{2}$$ For RHS in $(2)$, we may as well regard it as a ""polynomial"" with an infinite order and also infinitely many terms.Let's just call it $P(y)$. It is then obvious that all the solutions for $P(y)=0$ are as follows: $$y_i=i^2\pi^2$$ where $i\in\mathbb N^+$. Apparently they are distinct. Now consider a finite polynomial  $$P_n(y)=a_0+a_1 y+a_2 y^2+\cdots+a_{n-1}y^{n-1}+a_ny^n$$ Let $P_n(y)=0$, since $y>0$, it is ok to divide both sides by $y^n$, which yields $$a_0 \Bigl(\frac1y\Bigr)^n+a_1\Bigl(\frac1y\Bigr)^{n-1}+\cdots+a_{n-1}\Bigl(\frac1y\Bigr)+a_n=0\tag{3}$$ For each $y_i$ that is a solution to $P_n(y)=0$, $\frac{1}{y_i}$ will also be a solution to $(3)$ if we regard $(3)$ as a polynomial in terms of $\frac1y$. Therefore, by applying  the fundamental theorem of algebra to $(3)$ we get $$\sum_{i=1}^{n}\frac{1}{y_i}=-\frac{a_1}{a_0}\tag{4}$$ in which $y_i$s are distinct roots for $P_n(y)=0$. Then comes the key part, and that's also where I want more clarity on some issues . Let's return to $P(y)$, then infinite polynomial. By analogue, $(4)$ also holds for $P(y)$ ( clarification needed here!! ). Therefore, $$\sum_{i=1}^{\infty}\frac{1}{i^2\pi^2}=-\frac{a_1}{a_0}\tag{5}$$ in which $y_i=i^2\pi^2$ are distinct roots for $P(y)=0$ and $a_0$, $a_1$ are respectively the ""constant"" and ""coefficient for $y^1$"" in $P(y)$. To calculate $a_0$ and $a_1$, we must use limits since they are in a limit sense themselves. First, we have  $$a_0=\lim_{y\to 0}P(y)=\lim_{y\to 0}\frac{\sin\sqrt y}{\sqrt y}=1\tag{6}$$ Then we go on to calculate $a_1$, recall what we do with a finite polynomial, then by analogue it should be $$a_1=\lim_{y \to 0}\frac{P(y)-a_0}{y}=\lim_{y \to 0}\frac{\frac{\sin\sqrt y}{\sqrt y}-1}{y}=\frac{-\frac16 y+o(y)}{y}=-\frac16\tag{7}$$ (Intuitively I find $(6)$ and $(7)$ acceptable, but I also want some clarification so that they can be convincing.) Hence, at long last $$\sum_{i=1}^{\infty}\frac{1}{i^2}=-(-\frac{1}{6})\pi^2$$",,"['sequences-and-series', 'analysis', 'proof-verification', 'proof-writing', 'riemann-zeta']"
30,Solving recurrence relation varying with parity of n,Solving recurrence relation varying with parity of n,,Given a sequence $u_n$ such that $u_1 = 1$ $u_{2n} = n + u_n$ $u_{2n+1} = n^2 + u_nu_{n+1}$ How to solve for closed-form of $u_n$? I really don't know where to start.,Given a sequence $u_n$ such that $u_1 = 1$ $u_{2n} = n + u_n$ $u_{2n+1} = n^2 + u_nu_{n+1}$ How to solve for closed-form of $u_n$? I really don't know where to start.,,['sequences-and-series']
31,Does the limit of this double sequence exist?,Does the limit of this double sequence exist?,,"Consider  $$a_{mn}=\frac{m^2n^2}{m^2+n^2}\left(1-\cos\left(\frac{1}{m}\right)\cos\left(\frac{1}{n}\right)\right)$$ Does $\lim_{m,n\to\infty}a_{mn}$ exist? It can be seen that $$\lim_{m\to\infty}\left(\lim_{n\to\infty}a_{mn}\right)=\lim_{n\to\infty}\left(\lim_{m\to\infty}a_{mn}\right)=\frac{1}{2}$$ However, I still cannot determine whether the limit exists or not. Any one can help? Thanks!","Consider  $$a_{mn}=\frac{m^2n^2}{m^2+n^2}\left(1-\cos\left(\frac{1}{m}\right)\cos\left(\frac{1}{n}\right)\right)$$ Does $\lim_{m,n\to\infty}a_{mn}$ exist? It can be seen that $$\lim_{m\to\infty}\left(\lim_{n\to\infty}a_{mn}\right)=\lim_{n\to\infty}\left(\lim_{m\to\infty}a_{mn}\right)=\frac{1}{2}$$ However, I still cannot determine whether the limit exists or not. Any one can help? Thanks!",,"['real-analysis', 'sequences-and-series']"
32,Different ways to prove $\sum_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6}$ (the Basel problem),Different ways to prove  (the Basel problem),\sum_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6},"As I have heard people did not trust Euler when he first discovered the formula (solution of the Basel problem ) $$\zeta(2)=\sum_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6}$$ However, Euler was Euler and he gave other proofs. I believe many of you know some nice proofs of this, can you please share it with us?","As I have heard people did not trust Euler when he first discovered the formula (solution of the Basel problem ) However, Euler was Euler and he gave other proofs. I believe many of you know some nice proofs of this, can you please share it with us?",\zeta(2)=\sum_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6},"['sequences-and-series', 'fourier-analysis', 'big-list', 'transcendental-numbers', 'faq']"
33,An infinite series that gives $f(s)=s$. How could it be explained more easily?,An infinite series that gives . How could it be explained more easily?,f(s)=s,"This question loosely builds this one. Equate the following two infinite series for $\zeta(s)$: $$\displaystyle \zeta(s) = \frac{1}{4\,(s-1)} \left(1+s+\sum _{n=1}^{\infty } \left( {\frac {s+1+3\,n}{(n+1)^{s}}} + \frac{3\,s-2-2\,n}{n^s}-{\frac {n-1}{\left(n-1 \right) ^{s}}}\right) \right) \quad -1<\Re(s)<1$$ and $$\displaystyle \zeta(s) = \frac{1}{4\,(s-1)} \left(1+\sum _{n=1}^{\infty } \left( {\frac {2n+1}{(n+1)^{s}}} + \frac{4\,s-3}{n^s}-{\frac {2\,(n-1)}{\left(n-1 \right) ^{s}}}\right) \right) \quad -1<\Re(s)<1$$ Remove the factor $\frac{1}{4\,(s-1)}$ from both sides and then the difference between the remaining parts must be $-s$, so that: $$\displaystyle f(s) = \sum _{n=1}^{\infty } \left( {\frac {-s-n}{(n+1)^{s}}} + \frac{s-1+2 \,n}{n^s}-{\frac {n-1}{\left(n-1 \right) ^{s}}}\right) =s \qquad -1<\Re(s)<1$$ Obviously quite a complex way to express something as simple as $f(s)=s$ (in this restricted domain), however I am keen to understand whether an easier explanation exists for this phenomenon, rather than having to take the difference between the two infinite series. Thanks. ====================== UPDATE ===================== I think I found it :-) For $n=1$ the middle term becomes $s+1$. For $n=2$ the last term becomes $-1$ and together that gives $s$. All the other terms 'telescope' each other out up till a finite $N$ where we are left with: $$\lim_{N \to +\infty} \left(\frac{N}{N^{s}}-\frac{N+s}{(N+1)^s} \right) =0 \qquad \Re(s)>-1$$","This question loosely builds this one. Equate the following two infinite series for $\zeta(s)$: $$\displaystyle \zeta(s) = \frac{1}{4\,(s-1)} \left(1+s+\sum _{n=1}^{\infty } \left( {\frac {s+1+3\,n}{(n+1)^{s}}} + \frac{3\,s-2-2\,n}{n^s}-{\frac {n-1}{\left(n-1 \right) ^{s}}}\right) \right) \quad -1<\Re(s)<1$$ and $$\displaystyle \zeta(s) = \frac{1}{4\,(s-1)} \left(1+\sum _{n=1}^{\infty } \left( {\frac {2n+1}{(n+1)^{s}}} + \frac{4\,s-3}{n^s}-{\frac {2\,(n-1)}{\left(n-1 \right) ^{s}}}\right) \right) \quad -1<\Re(s)<1$$ Remove the factor $\frac{1}{4\,(s-1)}$ from both sides and then the difference between the remaining parts must be $-s$, so that: $$\displaystyle f(s) = \sum _{n=1}^{\infty } \left( {\frac {-s-n}{(n+1)^{s}}} + \frac{s-1+2 \,n}{n^s}-{\frac {n-1}{\left(n-1 \right) ^{s}}}\right) =s \qquad -1<\Re(s)<1$$ Obviously quite a complex way to express something as simple as $f(s)=s$ (in this restricted domain), however I am keen to understand whether an easier explanation exists for this phenomenon, rather than having to take the difference between the two infinite series. Thanks. ====================== UPDATE ===================== I think I found it :-) For $n=1$ the middle term becomes $s+1$. For $n=2$ the last term becomes $-1$ and together that gives $s$. All the other terms 'telescope' each other out up till a finite $N$ where we are left with: $$\lim_{N \to +\infty} \left(\frac{N}{N^{s}}-\frac{N+s}{(N+1)^s} \right) =0 \qquad \Re(s)>-1$$",,"['sequences-and-series', 'number-theory', 'riemann-zeta']"
34,When does the limit of the ratio of consecutive terms of a sequence exist?,When does the limit of the ratio of consecutive terms of a sequence exist?,,"I am trying to understand and obtain some sufficient conditions under which the limit of the ratio of consecutive terms of a sequence exists. Let $x_n$ be a sequence of positive integers, such that $\displaystyle\lim_{n\rightarrow \infty} x_n =\infty$. When does $\displaystyle\lim_{n\rightarrow \infty} \dfrac{x_{n+1}}{x_n}$ exist? If we assume that $\displaystyle\lim_{n\rightarrow \infty}\root n \of {x_n}=a$, then I can show that the required limit, if it exists, is equal to $a$. I don't want to ask the question in extreme generality, so I am assuming that the sequence $x_n$ grows at most exponentially. For instance, since $y_n:=\frac{x_{n+1}}{x_n}$ is bounded (when the growth is at most exponential), one such condition is monotonicity of the sequence $y_n$, which gives me the condition $x_{n+1}x_{n-1}\geq x_n^2$. One of my questions is whether the limit in question exists for exponentially growing sequences. Also, what sufficient conditions are there for sub-exponential sequences? Any help appreciated!","I am trying to understand and obtain some sufficient conditions under which the limit of the ratio of consecutive terms of a sequence exists. Let $x_n$ be a sequence of positive integers, such that $\displaystyle\lim_{n\rightarrow \infty} x_n =\infty$. When does $\displaystyle\lim_{n\rightarrow \infty} \dfrac{x_{n+1}}{x_n}$ exist? If we assume that $\displaystyle\lim_{n\rightarrow \infty}\root n \of {x_n}=a$, then I can show that the required limit, if it exists, is equal to $a$. I don't want to ask the question in extreme generality, so I am assuming that the sequence $x_n$ grows at most exponentially. For instance, since $y_n:=\frac{x_{n+1}}{x_n}$ is bounded (when the growth is at most exponential), one such condition is monotonicity of the sequence $y_n$, which gives me the condition $x_{n+1}x_{n-1}\geq x_n^2$. One of my questions is whether the limit in question exists for exponentially growing sequences. Also, what sufficient conditions are there for sub-exponential sequences? Any help appreciated!",,"['real-analysis', 'sequences-and-series']"
35,Methods of constructing rapidly convergent series,Methods of constructing rapidly convergent series,,"It's fairly easy to see that the series  $$1-\tfrac{1}{3}+\tfrac{1}{5}-\cdots=\tfrac{1}{4}\pi$$ is : 1. Convergent to the value given, and -  2. Very slowly converging, which can be seen just by testing with a calculator. Euler had some methods to turn certain slowly convergent series into more quickly convergent series - applying Euler's method to the above gives the series $$\sum\limits_{n=0}^{\infty}\frac{1}{2^{n+1}}\sum\limits_{k=0}^{n}\binom{n}{k}\frac{(-1)^k}{2k+1}=\sum\limits_{n=0}^{\infty}\frac{(2n)!!}{2^{n+1}(2n+1)!!}=\tfrac{1}{4}\pi$$ which converges much more quickly. What I'm interested in is if your aim was to find a rapidly convergent series right from the get-go, what are the methods for going about this? For example, compare with the 'well-known' formula $$\frac{1}{\pi}=\frac{2\sqrt{2}}{9801}\sum\limits_{n=0}^{\infty}\frac{(4n)!(26390n+1103)}{396^{4n}n!^4}$$ which gives $\pi\simeq\tfrac{9801}{2206\sqrt{2}}=3.141592\dots$ after just the $n=0$ step. So, what I'm asking is - if you are searching for a rapidly convergent series, what qualities do you typically want your result to have, and how do you go about finding one? For example, are there certain 'starting points' that typically give rapid convergence - e.g. if a series is derived via. a hypergeometric function identity (like I believe the second formula above is), for example, does it tend to be rapidly convergent? If so, does the same happen for the gamma function, the circular functions, etc. and why?","It's fairly easy to see that the series  $$1-\tfrac{1}{3}+\tfrac{1}{5}-\cdots=\tfrac{1}{4}\pi$$ is : 1. Convergent to the value given, and -  2. Very slowly converging, which can be seen just by testing with a calculator. Euler had some methods to turn certain slowly convergent series into more quickly convergent series - applying Euler's method to the above gives the series $$\sum\limits_{n=0}^{\infty}\frac{1}{2^{n+1}}\sum\limits_{k=0}^{n}\binom{n}{k}\frac{(-1)^k}{2k+1}=\sum\limits_{n=0}^{\infty}\frac{(2n)!!}{2^{n+1}(2n+1)!!}=\tfrac{1}{4}\pi$$ which converges much more quickly. What I'm interested in is if your aim was to find a rapidly convergent series right from the get-go, what are the methods for going about this? For example, compare with the 'well-known' formula $$\frac{1}{\pi}=\frac{2\sqrt{2}}{9801}\sum\limits_{n=0}^{\infty}\frac{(4n)!(26390n+1103)}{396^{4n}n!^4}$$ which gives $\pi\simeq\tfrac{9801}{2206\sqrt{2}}=3.141592\dots$ after just the $n=0$ step. So, what I'm asking is - if you are searching for a rapidly convergent series, what qualities do you typically want your result to have, and how do you go about finding one? For example, are there certain 'starting points' that typically give rapid convergence - e.g. if a series is derived via. a hypergeometric function identity (like I believe the second formula above is), for example, does it tend to be rapidly convergent? If so, does the same happen for the gamma function, the circular functions, etc. and why?",,"['sequences-and-series', 'soft-question', 'convergence-divergence']"
36,Does the A001921 linear recurrent integer sequence always yield composite numbers?,Does the A001921 linear recurrent integer sequence always yield composite numbers?,,"Let $(a_n)$ be the A001921 sequence $$   a_0 := 0,\ a_1 := 7, \quad a_{n+2} = 14a_{n+1} - a_n + 6. $$ Is it true that $a_n$ is always a composite integer for any $n\geq 2$ ? UPDATE : I now make a much stronger conjecture : if we define $b_k$ as the gcd of all the integers $a_{2^kn+2^{k-1}-1}(n\geq 0)$, then $(b_k)_{k\geq 1}$ is increasing (numerical values suggest it grows very very fast, see below). For example : $a_{2n}$ is always divisible by $b_0=2$. $a_{4n+1}$ is always divisible by $b_1=7$. $a_{8n+3}$ is always divisible by $b_2=97$. $a_{16n+7}$ is always divisible by $b_3=607$. $a_{32n+15}$ is always divisible by $b_4=708158977$. $a_{64n+31}$ is always divisible by $b_5=1002978273411373057$. $a_{128n+63}$ is always divisible by $b_6=2011930833870518011412817828051050497$.","Let $(a_n)$ be the A001921 sequence $$   a_0 := 0,\ a_1 := 7, \quad a_{n+2} = 14a_{n+1} - a_n + 6. $$ Is it true that $a_n$ is always a composite integer for any $n\geq 2$ ? UPDATE : I now make a much stronger conjecture : if we define $b_k$ as the gcd of all the integers $a_{2^kn+2^{k-1}-1}(n\geq 0)$, then $(b_k)_{k\geq 1}$ is increasing (numerical values suggest it grows very very fast, see below). For example : $a_{2n}$ is always divisible by $b_0=2$. $a_{4n+1}$ is always divisible by $b_1=7$. $a_{8n+3}$ is always divisible by $b_2=97$. $a_{16n+7}$ is always divisible by $b_3=607$. $a_{32n+15}$ is always divisible by $b_4=708158977$. $a_{64n+31}$ is always divisible by $b_5=1002978273411373057$. $a_{128n+63}$ is always divisible by $b_6=2011930833870518011412817828051050497$.",,"['sequences-and-series', 'elementary-number-theory', 'recurrence-relations', 'divisibility']"
37,Origin of the words arithmetic and geometric progression [duplicate],Origin of the words arithmetic and geometric progression [duplicate],,This question already has an answer here : Arithmetic and geometric sequences: where does their name come from? (1 answer) Closed 4 years ago . Why are arithmetic progression and geometric progression called arithmetic and geometric respectively?,This question already has an answer here : Arithmetic and geometric sequences: where does their name come from? (1 answer) Closed 4 years ago . Why are arithmetic progression and geometric progression called arithmetic and geometric respectively?,,"['sequences-and-series', 'terminology', 'arithmetic-progressions', 'geometric-progressions']"
38,Forcing series convergence,Forcing series convergence,,"I am trying to figure this out: $\mathscr{S}=\big\{(a_n),(b_n),\dots \big\}$ is a finite set of real, null sequences. Does there exist a sequence $(\epsilon_n)$ , where $\epsilon_k=\pm 1$ for each $k$ , such that: $$\forall\;(x_n)\in\mathscr{S}:\quad \sum_n \epsilon_n x_n<\infty\;?$$ A special case of this problem was posed by one of my lecturers: does every null sequence in $\mathbb{C}$ admit a sequence $(\epsilon_n)$ of signs such that $\sum\epsilon_nz_n$ converges? The answer is yes. We can always choose signs so that $|\epsilon_1z_1+\cdots\epsilon_nz_n|\leq \sqrt{3}$ for all $n$ , with some assumptions on $|z_n|$ . The geometric nature of the proof prevents me from generalising though. Any ideas how to deal with the general case?","I am trying to figure this out: is a finite set of real, null sequences. Does there exist a sequence , where for each , such that: A special case of this problem was posed by one of my lecturers: does every null sequence in admit a sequence of signs such that converges? The answer is yes. We can always choose signs so that for all , with some assumptions on . The geometric nature of the proof prevents me from generalising though. Any ideas how to deal with the general case?","\mathscr{S}=\big\{(a_n),(b_n),\dots \big\} (\epsilon_n) \epsilon_k=\pm 1 k \forall\;(x_n)\in\mathscr{S}:\quad \sum_n \epsilon_n x_n<\infty\;? \mathbb{C} (\epsilon_n) \sum\epsilon_nz_n |\epsilon_1z_1+\cdots\epsilon_nz_n|\leq \sqrt{3} n |z_n|","['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence']"
39,Prove the inequality for all $N$,Prove the inequality for all,N,"Show that the following inequality holds for all integers $N\geq 1$ $$\left|\sum_{n=1}^N\frac{1}{\sqrt{n}}-2\sqrt{N}-c_1\right|\leq\frac{c_2}{\sqrt{N}}$$ where $c_1,c_2$ are some constants. I have tried induction but it doesn't seem promising. Any ideas please?","Show that the following inequality holds for all integers $N\geq 1$ $$\left|\sum_{n=1}^N\frac{1}{\sqrt{n}}-2\sqrt{N}-c_1\right|\leq\frac{c_2}{\sqrt{N}}$$ where $c_1,c_2$ are some constants. I have tried induction but it doesn't seem promising. Any ideas please?",,"['sequences-and-series', 'analysis', 'inequality']"
40,Find the limit of $\sum \frac{1}{\log^n(n)}$,Find the limit of,\sum \frac{1}{\log^n(n)},"Working on convergence and divergence of infinite series, I recently focused my attention on the summation $$\displaystyle\sum\limits_{n=2}^{\infty} \frac{1}{\log^n(n)}$$ While proving the convergence of this series is trivial (e.g., using the root test), finding a closed-form expression for the value to which it converges seems to be hard. The summation converges to $ \displaystyle\approx 3.24261$ . After various searches on Google and other sites, unfortunately I did not find any useful information. What does this series converge to? In particular, does a closed-form expression exist for this limit? I  would also be interested in knowing whether there are contexts where this series arises.","Working on convergence and divergence of infinite series, I recently focused my attention on the summation While proving the convergence of this series is trivial (e.g., using the root test), finding a closed-form expression for the value to which it converges seems to be hard. The summation converges to . After various searches on Google and other sites, unfortunately I did not find any useful information. What does this series converge to? In particular, does a closed-form expression exist for this limit? I  would also be interested in knowing whether there are contexts where this series arises.",\displaystyle\sum\limits_{n=2}^{\infty} \frac{1}{\log^n(n)}  \displaystyle\approx 3.24261,"['sequences-and-series', 'number-theory', 'limits', 'summation']"
41,How to do this Sum? Poisson Resummation?,How to do this Sum? Poisson Resummation?,,"In the paper hep-th/0812.2909 page 34-35, there's a sum that I've been trying to do explicitly but I can't find a way. The sum is $$ \frac{2l}{\pi l! (l-1)!} \sum_{k\in\mathbb{Z}} \sum_{n=0}^{\infty} e^{-i (2n+l+1)t+i k (\phi-t) } \frac{\Gamma(n+|k|+l+1)\Gamma(n+l+1)}{\Gamma(n+|k|+1)\Gamma(n+1)}=\frac{l^{2}/(2^{l}\pi)}{[\cos(t-i\epsilon)-\cos(\phi))]^{l+1}} $$ In page 54 the authors need again to do a similar sum(it's actually the same), where they say you have to use something called ""Poisson Ressumation"" and ""sum over the images"". I tried to use what i found about Poisson ressumation, but I don't know how to Fourier transform a quotient between gammas, and even if I did, I understand it would turn the left hand side into another sum over integers. Thanks for your help! PS: I'm not a native speaker so forgive me if my English is a bit rusty.","In the paper hep-th/0812.2909 page 34-35, there's a sum that I've been trying to do explicitly but I can't find a way. The sum is $$ \frac{2l}{\pi l! (l-1)!} \sum_{k\in\mathbb{Z}} \sum_{n=0}^{\infty} e^{-i (2n+l+1)t+i k (\phi-t) } \frac{\Gamma(n+|k|+l+1)\Gamma(n+l+1)}{\Gamma(n+|k|+1)\Gamma(n+1)}=\frac{l^{2}/(2^{l}\pi)}{[\cos(t-i\epsilon)-\cos(\phi))]^{l+1}} $$ In page 54 the authors need again to do a similar sum(it's actually the same), where they say you have to use something called ""Poisson Ressumation"" and ""sum over the images"". I tried to use what i found about Poisson ressumation, but I don't know how to Fourier transform a quotient between gammas, and even if I did, I understand it would turn the left hand side into another sum over integers. Thanks for your help! PS: I'm not a native speaker so forgive me if my English is a bit rusty.",,"['sequences-and-series', 'fourier-analysis', 'fourier-series']"
42,Ugly-nice double series,Ugly-nice double series,,"I'm trying to evaluate the following ugly double sum (presented in raw notation as used in my calculations): $\sum _{m=1}^{\infty } \sum _{n=1}^{\infty } \frac{4 m \cos \left(\frac{2 \pi  m x}{T_x}\right) \cos \left(\frac{2 \pi  n y}{T_y}\right) \sin \left(\frac{\pi  m l_x}{T_x}\right) \sin \left(\frac{\pi  n l_y}{T_y}\right) \left(1-\exp \left(-\pi  h \sqrt{\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2}\right) \cosh \left(2 \pi  z \sqrt{\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2}\right)\right)}{\pi ^2 \left(n T_x^2 \left(\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2\right)\right)}$ At the first step, the term without the exponentials $\exp \left(-\pi  h \sqrt{\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2}\right) \cosh \left(2 \pi  z \sqrt{\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2}\right)$ is not so difficult to evaluate by using residue calculus. In this case h>2z so Jordan's lemma is valid. The major difficulties arise when dealing with the square roots at the exponent. We have a branch cuts that make things more difficult. At this point I failed to find a nice contour of integration. Although the sum looks quite symmetric, I wasn't able to separate the variables and transform the double sum to a product of sums. I assume, finding the following sum as a function of n $\sum _{m=1}^{\infty } \frac{m \cos \left(\frac{2 \pi  m x}{T_x}\right) \sin \left(\frac{\pi  m l_x}{T_x}\right) \exp \left(-\pi  (h-2 z) \sqrt{\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2}\right)}{n \left(\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2\right)}$ will be instrumental in calculating the whole sum. If following the approach with contour integration, the following integral will be of interest: $\oint \text{d$\xi $}\left(\frac{\xi  \cos (2 \pi  \xi  x) \sin \left(\pi  \xi  l_x\right) \cot \left(\pi  \xi  T_x\right) \exp \left(-\pi  (h-2 z) \sqrt{\xi ^2+\left(\frac{n}{T_y}\right){}^2}\right)}{n \left(\xi ^2+\left(\frac{n}{T_y}\right){}^2\right)}\right)$ I would appreciate any advise on how to tackle this problem.","I'm trying to evaluate the following ugly double sum (presented in raw notation as used in my calculations): $\sum _{m=1}^{\infty } \sum _{n=1}^{\infty } \frac{4 m \cos \left(\frac{2 \pi  m x}{T_x}\right) \cos \left(\frac{2 \pi  n y}{T_y}\right) \sin \left(\frac{\pi  m l_x}{T_x}\right) \sin \left(\frac{\pi  n l_y}{T_y}\right) \left(1-\exp \left(-\pi  h \sqrt{\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2}\right) \cosh \left(2 \pi  z \sqrt{\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2}\right)\right)}{\pi ^2 \left(n T_x^2 \left(\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2\right)\right)}$ At the first step, the term without the exponentials $\exp \left(-\pi  h \sqrt{\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2}\right) \cosh \left(2 \pi  z \sqrt{\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2}\right)$ is not so difficult to evaluate by using residue calculus. In this case h>2z so Jordan's lemma is valid. The major difficulties arise when dealing with the square roots at the exponent. We have a branch cuts that make things more difficult. At this point I failed to find a nice contour of integration. Although the sum looks quite symmetric, I wasn't able to separate the variables and transform the double sum to a product of sums. I assume, finding the following sum as a function of n $\sum _{m=1}^{\infty } \frac{m \cos \left(\frac{2 \pi  m x}{T_x}\right) \sin \left(\frac{\pi  m l_x}{T_x}\right) \exp \left(-\pi  (h-2 z) \sqrt{\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2}\right)}{n \left(\left(\frac{m}{T_x}\right){}^2+\left(\frac{n}{T_y}\right){}^2\right)}$ will be instrumental in calculating the whole sum. If following the approach with contour integration, the following integral will be of interest: $\oint \text{d$\xi $}\left(\frac{\xi  \cos (2 \pi  \xi  x) \sin \left(\pi  \xi  l_x\right) \cot \left(\pi  \xi  T_x\right) \exp \left(-\pi  (h-2 z) \sqrt{\xi ^2+\left(\frac{n}{T_y}\right){}^2}\right)}{n \left(\xi ^2+\left(\frac{n}{T_y}\right){}^2\right)}\right)$ I would appreciate any advise on how to tackle this problem.",,"['calculus', 'sequences-and-series', 'complex-analysis', 'contour-integration', 'residue-calculus']"
43,Closed-form expression for a hypergeometric series,Closed-form expression for a hypergeometric series,,"What is the closed-form expression for $${}_2 F_1 \left(1+2\lceil n/2\rceil,-n;1/2;-z/4\right)$$ According to the book Concrete Mathematics (R.Graham, D.Knuth, O.Patashnik 2nd), the authors say the general sum of $\sum_k {\ n-k \choose k}z^k$ leads to  the closed form of the above series. I understand $\sum_k {\ n-k \choose k}z^k= \frac{1}{\sqrt{1+4z}}((\frac{1+\sqrt{1+4z}}{2})^{n+1}-(\frac{1-\sqrt{1+4z}}{2})^{n+1})$, but I can not see how this sum leads to the closed-form of the the hypergeometric series.","What is the closed-form expression for $${}_2 F_1 \left(1+2\lceil n/2\rceil,-n;1/2;-z/4\right)$$ According to the book Concrete Mathematics (R.Graham, D.Knuth, O.Patashnik 2nd), the authors say the general sum of $\sum_k {\ n-k \choose k}z^k$ leads to  the closed form of the above series. I understand $\sum_k {\ n-k \choose k}z^k= \frac{1}{\sqrt{1+4z}}((\frac{1+\sqrt{1+4z}}{2})^{n+1}-(\frac{1-\sqrt{1+4z}}{2})^{n+1})$, but I can not see how this sum leads to the closed-form of the the hypergeometric series.",,"['sequences-and-series', 'special-functions', 'closed-form', 'hypergeometric-function']"
44,"Combinatorics question - count how many ways to write $1,2,...,n$ with a certain order",Combinatorics question - count how many ways to write  with a certain order,"1,2,...,n","A valid sequence is a sequence of length $n$ from the numbers $1,2,...,n$ such that: 1) every number appears once 2) apart from the first number in the sequence, every number $k$ has either a $k-1$ or a $k+1$ on its left (not necesarily adjacent). For example: the sequences $324156$ and $546321$ are valid. The sequence $435126$ is not (because there is no $2$ on the left side of $1$). Show that the number of valid sequences of length $n$ is $2^{n-1}$ Would love if someone could give me a tip. Not the answer, just a direction. I tried solving it with recurrence relation and induction but it didn't work.","A valid sequence is a sequence of length $n$ from the numbers $1,2,...,n$ such that: 1) every number appears once 2) apart from the first number in the sequence, every number $k$ has either a $k-1$ or a $k+1$ on its left (not necesarily adjacent). For example: the sequences $324156$ and $546321$ are valid. The sequence $435126$ is not (because there is no $2$ on the left side of $1$). Show that the number of valid sequences of length $n$ is $2^{n-1}$ Would love if someone could give me a tip. Not the answer, just a direction. I tried solving it with recurrence relation and induction but it didn't work.",,"['sequences-and-series', 'combinatorics']"
45,How to sum the divergent series $1+2+2+3+3+3+\cdots$ and $1+3+2+6+5+4+\cdots$?,How to sum the divergent series  and ?,1+2+2+3+3+3+\cdots 1+3+2+6+5+4+\cdots,"In a different context, I encountered the divergent series $1+2+2+3+3+3+\cdots$, and I was wondering about its summation. Putting $f(x)=1+2x+2x^2+3x^3+3x^4+3x^5+\cdots$, we have $$(1-x)f(x)=1+x+x^3+x^6+\cdots=\frac12 x^{-1/8}\theta_2(0, \sqrt{x}).$$ This doesn't seem to help a lot, but made me wonder: Is there such a thing as ""theta regularisation""? And how to go about the original series? A similar question concerns the ""summing"" of $1+$ $3+2+$ $6+5+4+$ $10+\dots$","In a different context, I encountered the divergent series $1+2+2+3+3+3+\cdots$, and I was wondering about its summation. Putting $f(x)=1+2x+2x^2+3x^3+3x^4+3x^5+\cdots$, we have $$(1-x)f(x)=1+x+x^3+x^6+\cdots=\frac12 x^{-1/8}\theta_2(0, \sqrt{x}).$$ This doesn't seem to help a lot, but made me wonder: Is there such a thing as ""theta regularisation""? And how to go about the original series? A similar question concerns the ""summing"" of $1+$ $3+2+$ $6+5+4+$ $10+\dots$",,"['sequences-and-series', 'divergent-series']"
46,Prove that $||\sum_{n=0}^{+\infty}{x_n}||\le\sum_{n=0}^{+\infty}||{x_n}||$ when series $\sum_{n=0}^{+\infty}{x_n}$ are absolutely converge?,Prove that  when series  are absolutely converge?,||\sum_{n=0}^{+\infty}{x_n}||\le\sum_{n=0}^{+\infty}||{x_n}|| \sum_{n=0}^{+\infty}{x_n},I think it should be proved that: Since $$||\sum_{n=0}^{N}{x_n}||\le\sum_{n=0}^{N}||{x_n}||$$ so $$\lim_{N\to+\infty}||\sum_{n=0}^{N}{x_n}||\le\lim_{N\to+\infty}\sum_{n=0}^{N}||{x_n}||$$ so $$||\sum_{n=0}^{+\infty}{x_n}||\le\sum_{n=0}^{+\infty}||{x_n}||$$  is it right ??,I think it should be proved that: Since $$||\sum_{n=0}^{N}{x_n}||\le\sum_{n=0}^{N}||{x_n}||$$ so $$\lim_{N\to+\infty}||\sum_{n=0}^{N}{x_n}||\le\lim_{N\to+\infty}\sum_{n=0}^{N}||{x_n}||$$ so $$||\sum_{n=0}^{+\infty}{x_n}||\le\sum_{n=0}^{+\infty}||{x_n}||$$  is it right ??,,"['sequences-and-series', 'limits', 'convergence-divergence']"
47,Can one use $e^n$ instead of $2^n$ in Cauchy condensation test?,Can one use  instead of  in Cauchy condensation test?,e^n 2^n,"Cauchy condensation test is useful for testing the convergence of infinite series.  The test is stated here as follows: for a positive non-increasing sequence $f(n)$, the sum $\sum_{n=1}^\infty f(n)$ converges if and only if the sum $\sum_{n=0}^\infty 2^nf(2^n)$ converges. I am wondering if $2^n$ can be replaced with $e^n$, where $e$ is the base of natural logarithm.  Thus, does the following statement hold: for a positive non-increasing sequence $f(n)$, the sum $\sum_{n=1}^\infty f(n)$ converges if and only if the sum $\sum_{n=0}^\infty e^nf(e^n)$ converges?  The reason I am wondering is because my $f(n)$ has lots of natural logs, and using $e^n$ instead of $2^n$ would be quite convenient.","Cauchy condensation test is useful for testing the convergence of infinite series.  The test is stated here as follows: for a positive non-increasing sequence $f(n)$, the sum $\sum_{n=1}^\infty f(n)$ converges if and only if the sum $\sum_{n=0}^\infty 2^nf(2^n)$ converges. I am wondering if $2^n$ can be replaced with $e^n$, where $e$ is the base of natural logarithm.  Thus, does the following statement hold: for a positive non-increasing sequence $f(n)$, the sum $\sum_{n=1}^\infty f(n)$ converges if and only if the sum $\sum_{n=0}^\infty e^nf(e^n)$ converges?  The reason I am wondering is because my $f(n)$ has lots of natural logs, and using $e^n$ instead of $2^n$ would be quite convenient.",,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
48,Showing a sequence $x_{n+1} = Tx_n$ forms a contraction mapping,Showing a sequence  forms a contraction mapping,x_{n+1} = Tx_n,I want to show that the sequence given by  $$x_{n+1} = Tx_n = x_n-\frac{(x_n^2-2)}{x_n+x_{n-1}}$$ forms a contraction mapping. That is  $$|Tx_1-Tx_2|\leq c|x_1-x_2|.$$ Where $c$ is to be determined. I am also unsure of what the conditions for convergence are.  So far I have $$\begin{align*}|Tx_1-Tx_2| &= \bigg|(x_1-\frac{(x_1^2-2)}{x_1+x_0})-(x_2-\frac{(x_2^2-2)}{x_2+x_1})\bigg| \\ &= \bigg|\frac{(x_1^2-2)(x_0-x_2)}{(x_1+x_0)(x_1+x_2)}\bigg| \end{align*}$$ and I am not really sure where to go from here. I have also thought about  $$|Tx_1-Tx_2| = \bigg|(x_1-x_2)-\frac{(x_1^2-2)}{x_1+x_0}+\frac{(x_2^2-2)}{x_2+x_1}\bigg|$$ and factoring out the $(x_1-x_2)$ term but I am also unsure of where to go from there. I should note that this sequence comes from the secant method with $f(x)=x^2-2$. Would it be better to show that the secant method forms a contraction mapping? If so how would one do that? Any help and comments would be appreciated. Thank you.,I want to show that the sequence given by  $$x_{n+1} = Tx_n = x_n-\frac{(x_n^2-2)}{x_n+x_{n-1}}$$ forms a contraction mapping. That is  $$|Tx_1-Tx_2|\leq c|x_1-x_2|.$$ Where $c$ is to be determined. I am also unsure of what the conditions for convergence are.  So far I have $$\begin{align*}|Tx_1-Tx_2| &= \bigg|(x_1-\frac{(x_1^2-2)}{x_1+x_0})-(x_2-\frac{(x_2^2-2)}{x_2+x_1})\bigg| \\ &= \bigg|\frac{(x_1^2-2)(x_0-x_2)}{(x_1+x_0)(x_1+x_2)}\bigg| \end{align*}$$ and I am not really sure where to go from here. I have also thought about  $$|Tx_1-Tx_2| = \bigg|(x_1-x_2)-\frac{(x_1^2-2)}{x_1+x_0}+\frac{(x_2^2-2)}{x_2+x_1}\bigg|$$ and factoring out the $(x_1-x_2)$ term but I am also unsure of where to go from there. I should note that this sequence comes from the secant method with $f(x)=x^2-2$. Would it be better to show that the secant method forms a contraction mapping? If so how would one do that? Any help and comments would be appreciated. Thank you.,,"['sequences-and-series', 'analysis', 'functional-analysis', 'fixed-point-theorems']"
49,Can this type of limit even be evaluated?,Can this type of limit even be evaluated?,,"This is going to be a long question; please bear with me. We are familiar with the notations $\Sigma^{n}_{k=0} a_k$ and $\Pi^{n}_{k=0}a_k$ for the sum and product of the finite sequence $\{a_n\}$. I've recently been looking into whether we could extend this to exponentiation. [In this context, we will assume $a^{b^c}$ = $a^{(b^c)}$.] We define $$\Delta^n_{k=1}a_k = \large{a_1^{a_2^{a_3^{^\cdots}}}}$$ Hence we see that $$\Delta^n_{k=1}a_k = a_1^{\LARGE{\Delta^n_{k=2}a_k}}$$ I've worked out derivatives etc. for this. It (this notation, or this way of looking at it) also seems to be helpful in finding the derivative of $a$ tetrated to $b$ (analogous to $\frac{d}{dx}f(x)^{g(x)}$). My question is, what does this limit evaluate to? (Does it even exist?) $$\lim_{x\rightarrow\infty}\Large{\Delta^x_{k=1}}\normalsize{\sin \frac{k\pi}{2x}}$$ In the spirit of Math.SE, hints are all I ask for.  I feel (probably mistakenly) that this delta thing is something important I've stumbled upon :)","This is going to be a long question; please bear with me. We are familiar with the notations $\Sigma^{n}_{k=0} a_k$ and $\Pi^{n}_{k=0}a_k$ for the sum and product of the finite sequence $\{a_n\}$. I've recently been looking into whether we could extend this to exponentiation. [In this context, we will assume $a^{b^c}$ = $a^{(b^c)}$.] We define $$\Delta^n_{k=1}a_k = \large{a_1^{a_2^{a_3^{^\cdots}}}}$$ Hence we see that $$\Delta^n_{k=1}a_k = a_1^{\LARGE{\Delta^n_{k=2}a_k}}$$ I've worked out derivatives etc. for this. It (this notation, or this way of looking at it) also seems to be helpful in finding the derivative of $a$ tetrated to $b$ (analogous to $\frac{d}{dx}f(x)^{g(x)}$). My question is, what does this limit evaluate to? (Does it even exist?) $$\lim_{x\rightarrow\infty}\Large{\Delta^x_{k=1}}\normalsize{\sin \frac{k\pi}{2x}}$$ In the spirit of Math.SE, hints are all I ask for.  I feel (probably mistakenly) that this delta thing is something important I've stumbled upon :)",,"['sequences-and-series', 'exponentiation']"
50,Sum involving the Digamma function.,Sum involving the Digamma function.,,"Consider the double sum $$f(x):=\sum_{m=1}^\infty\sum_{n=1}^\infty\frac{1}{m+\frac{1}{n+x}}-\frac{1}{m+\frac{1}{n}},$$ which converges for $x>0$.  One interpretation of this sum is the measure of the double preimage $T^{-2}([0,x])$, in which $T:[0,1]\to [0,1]$ denotes the Gauss map $T(x)=\{1/x\}$ (the fractional part of $1/x$). Let $\psi$ denote the Digamma function $\psi(z):=\Gamma'(z)/\Gamma(z)$.  The identity $$\psi(z)=-\gamma+\sum_{k=0}^\infty\left(\frac{1}{n+1}-\frac{1}{n+z}\right)$$ can then be used to rewrite $f$ as $$f(x)=\sum_{n=1}^\infty \psi\left(1+\frac{1}{n}\right)-\psi\left(1+\frac{1}{n+x}\right).$$ Is there any closed-form simplification of the sum above?  It seems plausible that there may be such a solution involving the higher Polygamma function $\psi^{(2)}$.","Consider the double sum $$f(x):=\sum_{m=1}^\infty\sum_{n=1}^\infty\frac{1}{m+\frac{1}{n+x}}-\frac{1}{m+\frac{1}{n}},$$ which converges for $x>0$.  One interpretation of this sum is the measure of the double preimage $T^{-2}([0,x])$, in which $T:[0,1]\to [0,1]$ denotes the Gauss map $T(x)=\{1/x\}$ (the fractional part of $1/x$). Let $\psi$ denote the Digamma function $\psi(z):=\Gamma'(z)/\Gamma(z)$.  The identity $$\psi(z)=-\gamma+\sum_{k=0}^\infty\left(\frac{1}{n+1}-\frac{1}{n+z}\right)$$ can then be used to rewrite $f$ as $$f(x)=\sum_{n=1}^\infty \psi\left(1+\frac{1}{n}\right)-\psi\left(1+\frac{1}{n+x}\right).$$ Is there any closed-form simplification of the sum above?  It seems plausible that there may be such a solution involving the higher Polygamma function $\psi^{(2)}$.",,"['sequences-and-series', 'gamma-function']"
51,Using discrete calculus to study convergence of series and sequences,Using discrete calculus to study convergence of series and sequences,,"From some personal investigation, I've noticed that all convergence tests for infinite series (at least, the real kind) can be rephrased in terms of the discrete derivative $∆f(x)$ of a function $f(x)$, sometimes to give interesting results. For example, the statement: $$\text{If } \lim_{k → ∞} a_k ≠ 0 \text{ then } ∑a_k \text{ diverges.}$$ Is equivalent to the statement: $$\text{If } \lim_{x → ∞} ∆f(x) ≠ 0 \text{ then } f(x) \text{ diverges.}$$ Except that the second statement is arguably more general, since $f(x)$ is not explicitly required to be in the form of a sum. Note that the limit of $∆ f(x)$ follows the definition of a limit of a sequence, rather than a function. Another example, is the ratio test which is given: $$ \text{If } \lim_{k → ∞} \frac{a_{k+1}}{a_k} < 1 \text{ then } ∑a_k \text{ converges.}$$ This statement is equivalent to: $$ \text{If } \lim_{x → ∞} \frac{∆^{\!2} f(x)}{∆ f(x)} < 0 \text{ then } f(x) \text{ converges.}$$ Besides said generalization, this representation is also interesting because proving convergence tests in terms of $∆ f(x)$ and $f(x)$ does not require manipulating sums directly. Instead, the proofs can be given in terms of basic theorems about $∆ f(x)$. They generally resemble proofs you'd find in calculus. Is anyone familiar with some thorough treatment of studying infinite series using discrete calculus in this way?","From some personal investigation, I've noticed that all convergence tests for infinite series (at least, the real kind) can be rephrased in terms of the discrete derivative $∆f(x)$ of a function $f(x)$, sometimes to give interesting results. For example, the statement: $$\text{If } \lim_{k → ∞} a_k ≠ 0 \text{ then } ∑a_k \text{ diverges.}$$ Is equivalent to the statement: $$\text{If } \lim_{x → ∞} ∆f(x) ≠ 0 \text{ then } f(x) \text{ diverges.}$$ Except that the second statement is arguably more general, since $f(x)$ is not explicitly required to be in the form of a sum. Note that the limit of $∆ f(x)$ follows the definition of a limit of a sequence, rather than a function. Another example, is the ratio test which is given: $$ \text{If } \lim_{k → ∞} \frac{a_{k+1}}{a_k} < 1 \text{ then } ∑a_k \text{ converges.}$$ This statement is equivalent to: $$ \text{If } \lim_{x → ∞} \frac{∆^{\!2} f(x)}{∆ f(x)} < 0 \text{ then } f(x) \text{ converges.}$$ Besides said generalization, this representation is also interesting because proving convergence tests in terms of $∆ f(x)$ and $f(x)$ does not require manipulating sums directly. Instead, the proofs can be given in terms of basic theorems about $∆ f(x)$. They generally resemble proofs you'd find in calculus. Is anyone familiar with some thorough treatment of studying infinite series using discrete calculus in this way?",,"['sequences-and-series', 'discrete-mathematics', 'discrete-calculus']"
52,Is this proof that every convergent sequence is bounded correct?,Is this proof that every convergent sequence is bounded correct?,,"I've tried the following proof that a convergent sequence is bounded but I'm not sure if it is correct or not. Let $(M,d)$ be a metric space and suppose $(x_k)$ is a sequence of points of $M$ that converges to $a \in M$. Since the sequence is convergent, for every $\varepsilon > 0$ there is some $k_0$ such that if $k > k_0$ then $x_k \in B(a;\varepsilon)$. In that case, there is a finite number of points of the sequence, namely $\{x_{1},\dots,x_{k_0} \}$ that can be still outside of the ball. In that case, consider $r = \max\{d(a,x_i) : 1 \leq i \leq k_0\}+1$, then I claim that for every $k \in \mathbb{N}$ we have $x_k \in B(a;r+\varepsilon)$. In truth, first it's obvious that $B(a;\varepsilon)\subset B(a;r+\varepsilon)$ because if $y \in B(a;\varepsilon)$ then $d(y,a) < \varepsilon < \varepsilon + r$ since $r > 0$. Also, by definition of $r$, we know that $\max\{d(a,x_i) : 1 \leq i \leq k_0\} < r < r+\varepsilon$ and so each $d(a,x_i) < r+\varepsilon$ so that $\{x_1, \dots, x_{k_0}\}\subset B(a;\varepsilon+r)$. Since the points $x_k$ for $1 \leq k \leq k_0$ are in the ball and the points $x_k$ for $k > k_0$ are in the ball, we conclude that every $x_k \in B(a;\varepsilon+r)$ and so the sequence is bounded. Is this proof correct or there are any problems with it? Thanks very much in advance!","I've tried the following proof that a convergent sequence is bounded but I'm not sure if it is correct or not. Let $(M,d)$ be a metric space and suppose $(x_k)$ is a sequence of points of $M$ that converges to $a \in M$. Since the sequence is convergent, for every $\varepsilon > 0$ there is some $k_0$ such that if $k > k_0$ then $x_k \in B(a;\varepsilon)$. In that case, there is a finite number of points of the sequence, namely $\{x_{1},\dots,x_{k_0} \}$ that can be still outside of the ball. In that case, consider $r = \max\{d(a,x_i) : 1 \leq i \leq k_0\}+1$, then I claim that for every $k \in \mathbb{N}$ we have $x_k \in B(a;r+\varepsilon)$. In truth, first it's obvious that $B(a;\varepsilon)\subset B(a;r+\varepsilon)$ because if $y \in B(a;\varepsilon)$ then $d(y,a) < \varepsilon < \varepsilon + r$ since $r > 0$. Also, by definition of $r$, we know that $\max\{d(a,x_i) : 1 \leq i \leq k_0\} < r < r+\varepsilon$ and so each $d(a,x_i) < r+\varepsilon$ so that $\{x_1, \dots, x_{k_0}\}\subset B(a;\varepsilon+r)$. Since the points $x_k$ for $1 \leq k \leq k_0$ are in the ball and the points $x_k$ for $k > k_0$ are in the ball, we conclude that every $x_k \in B(a;\varepsilon+r)$ and so the sequence is bounded. Is this proof correct or there are any problems with it? Thanks very much in advance!",,"['sequences-and-series', 'metric-spaces', 'proof-verification']"
53,Generalized Alternating harmonic sum $\sum_{n\geq 1}\frac{\left(1-\frac{1}{2}+\frac{1}{3}-\cdots \pm \frac{1}{n}\right)}{n^p}$,Generalized Alternating harmonic sum,\sum_{n\geq 1}\frac{\left(1-\frac{1}{2}+\frac{1}{3}-\cdots \pm \frac{1}{n}\right)}{n^p},"Is there a general formula for the following $$\sum_{n\geq 1}\frac{\left(1-\frac{1}{2}+\frac{1}{3}-\cdots \pm \frac{1}{n}\right)}{n^p}\,\, p\geq 1$$ What about some restrictions on $p$ , like integers or anything helpful ?","Is there a general formula for the following $$\sum_{n\geq 1}\frac{\left(1-\frac{1}{2}+\frac{1}{3}-\cdots \pm \frac{1}{n}\right)}{n^p}\,\, p\geq 1$$ What about some restrictions on $p$ , like integers or anything helpful ?",,['sequences-and-series']
54,The set of all subsequential limits of a bounded sequence is a non-empty compact set,The set of all subsequential limits of a bounded sequence is a non-empty compact set,,"Let $(x_n)$ be a bounded sequence and let $Y$ be the set of all subsequential limits of $(x_n)$. Prove that $Y$ is a non-empty compact set. I think it's possible to solve this problem by proving that $Y$ is bounded (because if $Y$ is unbounded then $(x_n)$ is not bounded) and closed (because $\mathbb{R}^n-Y$ is open). I guess we can also use the definition of compact set by sequence (but in order to this, it's also necessary to prove that $Y$ is bounded). However, I'd like to prove it by using cover. In other words, I'd like to prove that every open cover of $Y$ has a finite subcover (without using of Borel-Lebesgue Theorem, obviously). Is it possible? Thanks.","Let $(x_n)$ be a bounded sequence and let $Y$ be the set of all subsequential limits of $(x_n)$. Prove that $Y$ is a non-empty compact set. I think it's possible to solve this problem by proving that $Y$ is bounded (because if $Y$ is unbounded then $(x_n)$ is not bounded) and closed (because $\mathbb{R}^n-Y$ is open). I guess we can also use the definition of compact set by sequence (but in order to this, it's also necessary to prove that $Y$ is bounded). However, I'd like to prove it by using cover. In other words, I'd like to prove that every open cover of $Y$ has a finite subcover (without using of Borel-Lebesgue Theorem, obviously). Is it possible? Thanks.",,"['sequences-and-series', 'analysis', 'compactness']"
55,The Tribonacci constant and the Dragon,The Tribonacci constant and the Dragon,,"Let $x = \frac{\ln T}{\ln 2} = 0.879146\dots$ where $T$ is the tribonacci constant , then x solves the transcendental equation, $$4^x(2^x-1)=(2^x+1)$$ Let $x = \frac{\ln y}{\ln 2} = 1.523627\dots$ where $y$ is the real root of the cubic $y^3-y^2-4y-4=0$ (hence $x=1.5236\dots$ is the boundary of the dragon curve ), then x solves, $$4^x(2^x-1)=4(2^x+1)$$ In general, given the transcendental equation with unknown $x$ and algebraic  constants $a_i,b_i,c_i,d_i$, $$ (a_1p_1^x + b_1) (a_2 p_2^x + b_2) \dots  = (c_1q_1^x + d_1) (c_2q_2^x + d_2)\dots\tag{1}$$ for the special case when $p = p_i = q_i$, then the solution to $(1)$ for $p \ne 0, 1$ is $x = \frac{\ln z}{\ln\, p}$ where $z$ is a root of the algebraic equation , $$(a_1z + b_1) (a_2z + b_2) \dots  = (c_1z + d_1) (c_2z + d_2) \dots$$ Question : Excluding using the Lambert W function , is there any other special case of the transcendental equation $(1)$ that has a simple closed-form solution?","Let $x = \frac{\ln T}{\ln 2} = 0.879146\dots$ where $T$ is the tribonacci constant , then x solves the transcendental equation, $$4^x(2^x-1)=(2^x+1)$$ Let $x = \frac{\ln y}{\ln 2} = 1.523627\dots$ where $y$ is the real root of the cubic $y^3-y^2-4y-4=0$ (hence $x=1.5236\dots$ is the boundary of the dragon curve ), then x solves, $$4^x(2^x-1)=4(2^x+1)$$ In general, given the transcendental equation with unknown $x$ and algebraic  constants $a_i,b_i,c_i,d_i$, $$ (a_1p_1^x + b_1) (a_2 p_2^x + b_2) \dots  = (c_1q_1^x + d_1) (c_2q_2^x + d_2)\dots\tag{1}$$ for the special case when $p = p_i = q_i$, then the solution to $(1)$ for $p \ne 0, 1$ is $x = \frac{\ln z}{\ln\, p}$ where $z$ is a root of the algebraic equation , $$(a_1z + b_1) (a_2z + b_2) \dots  = (c_1z + d_1) (c_2z + d_2) \dots$$ Question : Excluding using the Lambert W function , is there any other special case of the transcendental equation $(1)$ that has a simple closed-form solution?",,"['sequences-and-series', 'special-functions', 'fractals', 'transcendental-numbers', 'constants']"
56,Partial sums of $\sin(x)$,Partial sums of,\sin(x),"Is it true that  $$ \left|\sum_{k=1}^n \sin(k) \right|\leq M $$ for every $n$? I tried comparing this to the integral $\int_2^\infty \sin(x)dx$ but it is not monotone. This is part of a problem that says if $A_n=a_1+a_2+\cdots+a_n$ and $|A_n|\leq M$ and $b_n$ is a decreasing sequence to zero, then $\sum a_n b_n$ converges.  Then use this to show that $$ \sum_{n=2}^\infty \frac{\sin(n)}{\log(n)} $$","Is it true that  $$ \left|\sum_{k=1}^n \sin(k) \right|\leq M $$ for every $n$? I tried comparing this to the integral $\int_2^\infty \sin(x)dx$ but it is not monotone. This is part of a problem that says if $A_n=a_1+a_2+\cdots+a_n$ and $|A_n|\leq M$ and $b_n$ is a decreasing sequence to zero, then $\sum a_n b_n$ converges.  Then use this to show that $$ \sum_{n=2}^\infty \frac{\sin(n)}{\log(n)} $$",,['sequences-and-series']
57,Convergence test of a trigonometic series,Convergence test of a trigonometic series,,Test the convergences of the following series $$ \sum_{n=1}^{\infty} (-1)^n  \frac{ \sin n}{\sqrt{n}}$$,Test the convergences of the following series $$ \sum_{n=1}^{\infty} (-1)^n  \frac{ \sin n}{\sqrt{n}}$$,,['sequences-and-series']
58,What is the order of this pole?,What is the order of this pole?,,"$$f(z)=\frac 1{\cos(z^4)-1}$$ $z=0$ is a pole of $f$, and I believe that the Laurent series centred at $0$ is $-\frac 2{z^8}-\frac 16+...$, which looks like the pole is of order $8$, but why does Wolfram Alpha claim that the pole is of order $2$?","$$f(z)=\frac 1{\cos(z^4)-1}$$ $z=0$ is a pole of $f$, and I believe that the Laurent series centred at $0$ is $-\frac 2{z^8}-\frac 16+...$, which looks like the pole is of order $8$, but why does Wolfram Alpha claim that the pole is of order $2$?",,"['sequences-and-series', 'complex-analysis', 'power-series']"
59,"If $f_n(x_n) \to f(x)$ whenever $x_n \to x$, show that $f$ is continuous","If  whenever , show that  is continuous",f_n(x_n) \to f(x) x_n \to x f,"From Pugh's analysis book, prelim problem 57 from Chapter 4: Let $f$ and $f_n$ be functions from $\Bbb R$ to $\Bbb R$. Assume that $f_n(x_n)\to f(x)$ as $n\to\infty$ whenever $x_n\to x$. Prove that $f$ is continuous. (Note: the functions $f_n$ are not assumed to be continuous.) here's my attempt: assume $x_n \to x$. we want to show that $f(x_n) \to f(x)$. so $|f(x_n) - f(x)| \leq |f(x_n)-f_n(x_n)| + |f_n(x_n)-f(x)|$. The second term can be made to be less than any $\varepsilon > 0$ for $n$ sufficiently large. i'm having trouble with the first term. can anyone help? thank you!","From Pugh's analysis book, prelim problem 57 from Chapter 4: Let $f$ and $f_n$ be functions from $\Bbb R$ to $\Bbb R$. Assume that $f_n(x_n)\to f(x)$ as $n\to\infty$ whenever $x_n\to x$. Prove that $f$ is continuous. (Note: the functions $f_n$ are not assumed to be continuous.) here's my attempt: assume $x_n \to x$. we want to show that $f(x_n) \to f(x)$. so $|f(x_n) - f(x)| \leq |f(x_n)-f_n(x_n)| + |f_n(x_n)-f(x)|$. The second term can be made to be less than any $\varepsilon > 0$ for $n$ sufficiently large. i'm having trouble with the first term. can anyone help? thank you!",,['real-analysis']
60,Sum of reciprocals of numbers with certain terms omitted,Sum of reciprocals of numbers with certain terms omitted,,"I know that the harmonic series $1 + \frac12 + \frac13 + \frac14 + \cdots$ diverges. I also know that the sum of the inverse of prime numbers $\frac12 + \frac13 + \frac15 + \frac17 + \frac1{11} + \cdots$ diverges too, even if really slowly since it's $O(\log \log n)$. But I think I read that if we consider the numbers whose decimal representation does not have a certain digit (say, 7) and sum the inverse of these numbers, the sum is finite (usually between 19 and 20, it depends from the missing digit). Does anybody know the result, and some way to prove that the sum is finite?","I know that the harmonic series $1 + \frac12 + \frac13 + \frac14 + \cdots$ diverges. I also know that the sum of the inverse of prime numbers $\frac12 + \frac13 + \frac15 + \frac17 + \frac1{11} + \cdots$ diverges too, even if really slowly since it's $O(\log \log n)$. But I think I read that if we consider the numbers whose decimal representation does not have a certain digit (say, 7) and sum the inverse of these numbers, the sum is finite (usually between 19 and 20, it depends from the missing digit). Does anybody know the result, and some way to prove that the sum is finite?",,"['sequences-and-series', 'convergence-divergence']"
61,Necessary or sufficient conditions for rationality of a limit of a sequence of rational numbers,Necessary or sufficient conditions for rationality of a limit of a sequence of rational numbers,,"Consider a convergent sequence of rational numbers $a_n$ with a limit $\lim_{n\rightarrow\infty} a_n = b$. Does there exists some kind of necessary condition for $b$ to be rational that only uses the elements of the sequence? It is easy to describe sufficient condition for integers, like $\forall n\in \mathbb N, \ a_n \in \mathbb Z \implies b \in \mathbb Z.$ But this is definitely not true for rationals: $\forall n\in \mathbb N, \ a_n \in \mathbb Q \not\implies b \in \mathbb Q.$ Also it is true that: $\forall n\in \mathbb N, \ a_n \in \mathbb R \implies b \in \mathbb R.$ Are there sufficient conditions for $b$ to be rational that are not of the form $$\exists k \in \mathbb N: |\{ n \in \mathbb N \ |  \ a_n = a_k \}| = \infty?$$","Consider a convergent sequence of rational numbers $a_n$ with a limit $\lim_{n\rightarrow\infty} a_n = b$. Does there exists some kind of necessary condition for $b$ to be rational that only uses the elements of the sequence? It is easy to describe sufficient condition for integers, like $\forall n\in \mathbb N, \ a_n \in \mathbb Z \implies b \in \mathbb Z.$ But this is definitely not true for rationals: $\forall n\in \mathbb N, \ a_n \in \mathbb Q \not\implies b \in \mathbb Q.$ Also it is true that: $\forall n\in \mathbb N, \ a_n \in \mathbb R \implies b \in \mathbb R.$ Are there sufficient conditions for $b$ to be rational that are not of the form $$\exists k \in \mathbb N: |\{ n \in \mathbb N \ |  \ a_n = a_k \}| = \infty?$$",,"['sequences-and-series', 'convergence-divergence']"
62,On the series $ \sum_{n=1}^{\infty} \frac{\Lambda(n)}{\sqrt{n}} \cos(x \log(n) + a) $.,On the series ., \sum_{n=1}^{\infty} \frac{\Lambda(n)}{\sqrt{n}} \cos(x \log(n) + a) ,"Is the following series ‘summable’ in the sense that it may be divergent but we can attach a meaning to it? $$ \sum_{n=1}^{\infty} \frac{\Lambda(n)}{\sqrt{n}} \cos(x \log(n) + a) = (\text{reg}) \quad \frac{\zeta'(1/2 + ia + ix)}{\zeta(1/2 + ia + ix)} + \frac{\zeta'(1/2 - ia - ix)}{\zeta(1/2 - ia - ix)}. $$ If we assume that this is correct, then what would be the limit as $ x \to \infty $? This series was obtained simply by setting $ s = 1/2 + ix $ inside the power series $$ \frac{\zeta'(s)}{\zeta(s)} = \sum_{n=1}^{\infty} \Lambda(n) n^{-s}. $$ Also, for large $ x $, this can be applied to the series $$ \sum_{n=1}^{\infty} \frac{\Lambda(n)}{\sqrt{n}} {J_{0}}(x \log(n)). $$","Is the following series ‘summable’ in the sense that it may be divergent but we can attach a meaning to it? $$ \sum_{n=1}^{\infty} \frac{\Lambda(n)}{\sqrt{n}} \cos(x \log(n) + a) = (\text{reg}) \quad \frac{\zeta'(1/2 + ia + ix)}{\zeta(1/2 + ia + ix)} + \frac{\zeta'(1/2 - ia - ix)}{\zeta(1/2 - ia - ix)}. $$ If we assume that this is correct, then what would be the limit as $ x \to \infty $? This series was obtained simply by setting $ s = 1/2 + ix $ inside the power series $$ \frac{\zeta'(s)}{\zeta(s)} = \sum_{n=1}^{\infty} \Lambda(n) n^{-s}. $$ Also, for large $ x $, this can be applied to the series $$ \sum_{n=1}^{\infty} \frac{\Lambda(n)}{\sqrt{n}} {J_{0}}(x \log(n)). $$",,"['sequences-and-series', 'riemann-zeta', 'divergent-series', 'trigonometric-series']"
63,elementary proof for $\sum_{k=0}^n \frac{1}{k!} \le \left(1 + \frac{1}{2n}\right)^{2n+1}$?,elementary proof for ?,\sum_{k=0}^n \frac{1}{k!} \le \left(1 + \frac{1}{2n}\right)^{2n+1},"Is it possible to show using only elementary facts that: $$ \sum_{k=0}^n \frac{1}{k!} \le \left(1 + \frac{1}{2n}\right)^{2n+1} $$ Of course they both have the same limit, $e$, but let's assume I don't know that about series. I guess that I have to use the fact that $\left(1 + \frac{1}{2n}\right)^{2n+1} = \sum_{k=0}^{2n+1} \binom{2n+1}{k} \cdot \frac{1}{(2n)^k}$?","Is it possible to show using only elementary facts that: $$ \sum_{k=0}^n \frac{1}{k!} \le \left(1 + \frac{1}{2n}\right)^{2n+1} $$ Of course they both have the same limit, $e$, but let's assume I don't know that about series. I guess that I have to use the fact that $\left(1 + \frac{1}{2n}\right)^{2n+1} = \sum_{k=0}^{2n+1} \binom{2n+1}{k} \cdot \frac{1}{(2n)^k}$?",,"['real-analysis', 'sequences-and-series']"
64,Sum over squared index,Sum over squared index,,"Is there any way to compute the finite series $$S_M = \sum_{n=1}^{M} r^{n^2}, $$ for some real $r$, integer $M$?","Is there any way to compute the finite series $$S_M = \sum_{n=1}^{M} r^{n^2}, $$ for some real $r$, integer $M$?",,"['sequences-and-series', 'summation']"
65,Determine sum of exponential,Determine sum of exponential,,I am struggling to find an answer of the following series $$\sum_{i=1}^n \frac{1}{1+\exp(a_i+b_ix)}$$ Any suggestion?,I am struggling to find an answer of the following series $$\sum_{i=1}^n \frac{1}{1+\exp(a_i+b_ix)}$$ Any suggestion?,,['sequences-and-series']
66,Convergence of a sequence of real numbers,Convergence of a sequence of real numbers,,"Let $\alpha, \gamma$ be real numbers such that $0<\alpha<1$ and $\gamma>0$. Consider the sequence of real numbers given by $$ \begin{cases} x_0\ne 0&\\ x_{k+1}=x_k\left(1-\frac{\gamma(1+\alpha)}{|x_k|^{1-\alpha}}\right) \quad (k\in \mathbb{N}).& \end{cases} $$ Suppose that $x_k\ne 0$ for all $k\in \mathbb{N}$. Prove that : The sequence $\{x_k\}_{k\in\mathbb{N}}$ does not converge. The sequence $\{|x_k|\}_{k\in\mathbb{N}}$ converges to $[(1/2)(1+\alpha)\gamma]^{1/(1-\alpha)}.$","Let $\alpha, \gamma$ be real numbers such that $0<\alpha<1$ and $\gamma>0$. Consider the sequence of real numbers given by $$ \begin{cases} x_0\ne 0&\\ x_{k+1}=x_k\left(1-\frac{\gamma(1+\alpha)}{|x_k|^{1-\alpha}}\right) \quad (k\in \mathbb{N}).& \end{cases} $$ Suppose that $x_k\ne 0$ for all $k\in \mathbb{N}$. Prove that : The sequence $\{x_k\}_{k\in\mathbb{N}}$ does not converge. The sequence $\{|x_k|\}_{k\in\mathbb{N}}$ converges to $[(1/2)(1+\alpha)\gamma]^{1/(1-\alpha)}.$",,['sequences-and-series']
67,Partial summation of a harmonic prime square series (Prime zeta functions),Partial summation of a harmonic prime square series (Prime zeta functions),,"I am trying to find the following series: $S=\displaystyle\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}\dfrac{1}{p_ip_j},A\leq p_1 < p_2 < \dots < p_n \leq B, \lbrace A,B\rbrace \in \mathbb{N}$ Where $\lbrace p_1,p_2, \dots,p_n\rbrace$ are consecutive primes.   I am stuck at $\displaystyle\sum_{i=1}^{n}\dfrac{1}{{p_i}^2}$. Motivation: This problem is related to checking the number of integers in a sequence that are divisible by two of the $n$ primes. Example of $S$: when $A = 10, B=20$, the primes are $\lbrace 11,13,17,19\rbrace$ and the sum $S$ is: $\dfrac{1}{11\times 13}+\dfrac{1}{11\times 17}+\dfrac{1}{11\times 19}+\dfrac{1}{13\times 17} + \dfrac{1}{13\times 19}+\dfrac{1}{17\times 19}$ Work done thus far: I have worked out that the sum is equivalent to: $S=\dfrac{1}{2}\left( \left(\displaystyle\sum_{i=1}^{n}\dfrac{1}{p_i}\right)^2-\displaystyle\sum_{i=1}^{n}\dfrac{1}{{p_i}^2}\right)=\dfrac{1}{2}\left((S_1)^2-S_2\right)$ This can be done by doubling $S$ and adding $\displaystyle\sum_{i=1}^{n}\dfrac{1}{{p_i}^2}$ and realizing that it equals $\left(\displaystyle\sum_{i=1}^{n}\dfrac{1}{p_i}\right)^2$. Say $S=\dfrac{1}{p_1p_2}+\dfrac{1}{p_1p_3}+\dfrac{1}{p_2p_3}$. Then $2S+\dfrac{1}{p_1p_1}+\dfrac{1}{p_2p_2} +\dfrac{1}{p_3p_3}= $ $\dfrac{1}{p_1p_1}+\dfrac{1}{p_1p_2}+\dfrac{1}{p_1p_3}+$ $\dfrac{1}{p_2p_1}+\dfrac{1}{p_2p_2}+\dfrac{1}{p_2p_3}+$ $\dfrac{1}{p_3p_1}+\dfrac{1}{p_3p_2}+\dfrac{1}{p_3p_3}$ $=(S_1)^2$ $\implies 2S=(S_1)^2+S_2$ This is sort of like completing a square matrix, where original sum is upper triangle, the doubling fills the lower triangle and the squared primes fills the diagonal. Partial solution: There is a nice estimation for $S_1:\displaystyle\sum_{p\in prime}^{x}=ln(ln(x))+B_1+o(1)$. So given $A,B:$ $S_1=\displaystyle\sum_{i=1}^{n}\dfrac{1}{p_i}$ $\approx \displaystyle\sum_{i=1}^{B}\dfrac{1}{p_i}-\displaystyle\sum_{i=1}^{A}\dfrac{1}{p_i}$ $\approx (ln(ln(B))+B_1+o(1))-(ln(ln(A))+B_1+o(1))$ $\approx ln(ln(B))-ln(ln(A))=ln(\dfrac{B}{A})$ Similarly, there is an estimation for the harmonic sum of prime squares . However, this estimation apparently is for an infinite series and so I am unable to use a similar trick that derives $S_1$.","I am trying to find the following series: $S=\displaystyle\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}\dfrac{1}{p_ip_j},A\leq p_1 < p_2 < \dots < p_n \leq B, \lbrace A,B\rbrace \in \mathbb{N}$ Where $\lbrace p_1,p_2, \dots,p_n\rbrace$ are consecutive primes.   I am stuck at $\displaystyle\sum_{i=1}^{n}\dfrac{1}{{p_i}^2}$. Motivation: This problem is related to checking the number of integers in a sequence that are divisible by two of the $n$ primes. Example of $S$: when $A = 10, B=20$, the primes are $\lbrace 11,13,17,19\rbrace$ and the sum $S$ is: $\dfrac{1}{11\times 13}+\dfrac{1}{11\times 17}+\dfrac{1}{11\times 19}+\dfrac{1}{13\times 17} + \dfrac{1}{13\times 19}+\dfrac{1}{17\times 19}$ Work done thus far: I have worked out that the sum is equivalent to: $S=\dfrac{1}{2}\left( \left(\displaystyle\sum_{i=1}^{n}\dfrac{1}{p_i}\right)^2-\displaystyle\sum_{i=1}^{n}\dfrac{1}{{p_i}^2}\right)=\dfrac{1}{2}\left((S_1)^2-S_2\right)$ This can be done by doubling $S$ and adding $\displaystyle\sum_{i=1}^{n}\dfrac{1}{{p_i}^2}$ and realizing that it equals $\left(\displaystyle\sum_{i=1}^{n}\dfrac{1}{p_i}\right)^2$. Say $S=\dfrac{1}{p_1p_2}+\dfrac{1}{p_1p_3}+\dfrac{1}{p_2p_3}$. Then $2S+\dfrac{1}{p_1p_1}+\dfrac{1}{p_2p_2} +\dfrac{1}{p_3p_3}= $ $\dfrac{1}{p_1p_1}+\dfrac{1}{p_1p_2}+\dfrac{1}{p_1p_3}+$ $\dfrac{1}{p_2p_1}+\dfrac{1}{p_2p_2}+\dfrac{1}{p_2p_3}+$ $\dfrac{1}{p_3p_1}+\dfrac{1}{p_3p_2}+\dfrac{1}{p_3p_3}$ $=(S_1)^2$ $\implies 2S=(S_1)^2+S_2$ This is sort of like completing a square matrix, where original sum is upper triangle, the doubling fills the lower triangle and the squared primes fills the diagonal. Partial solution: There is a nice estimation for $S_1:\displaystyle\sum_{p\in prime}^{x}=ln(ln(x))+B_1+o(1)$. So given $A,B:$ $S_1=\displaystyle\sum_{i=1}^{n}\dfrac{1}{p_i}$ $\approx \displaystyle\sum_{i=1}^{B}\dfrac{1}{p_i}-\displaystyle\sum_{i=1}^{A}\dfrac{1}{p_i}$ $\approx (ln(ln(B))+B_1+o(1))-(ln(ln(A))+B_1+o(1))$ $\approx ln(ln(B))-ln(ln(A))=ln(\dfrac{B}{A})$ Similarly, there is an estimation for the harmonic sum of prime squares . However, this estimation apparently is for an infinite series and so I am unable to use a similar trick that derives $S_1$.",,"['sequences-and-series', 'prime-numbers', 'analytic-number-theory']"
68,Fastest convergence Series which approximates function,Fastest convergence Series which approximates function,,"The question is the following: Is there any proof that shows that the Taylor series of an analytical function is the series with the fastest convergence to that function? The motivation to this question comes from numerically calculate $\exp(x)$ with arbitrary precision on the result. Suppose one can only calculate it using simple multiplications, division, sum and subtraction. One approach would be to calculate the Taylor series centered on a particular known value (for instance, for the $\exp$, centered at $0$), and stop when the next term of the series has the desired precision. I.e. considering $$y_n = \sum_{i=0}^n \frac{x^n}{n!}$$ we can call the error of the approximation of $y_n$ as $$\epsilon_n = |y_n - e^x|\simeq \frac{x^{n+1}}{(n+1)!}$$ It is not obvious to me that the Taylor series is the fastest way of approaching $\exp(x)$ (in the sense that the Taylor Series is the one that leads to the n required to achieve a given precision is the minimum). I think the problem can also be stated in the following way: on the set of all series that converge to $e^x$, which converges faster in the sense that it requires the minimum number of terms (and only requires $+,-,\cdot,/$)? Generically, I would like to extent this results to less trivial functions, like $\cos, \arcsin, \log$, etc. So, first I would like to understand which series (or other things like Padé approximants, as Cocopuffs pointed out) should I use...","The question is the following: Is there any proof that shows that the Taylor series of an analytical function is the series with the fastest convergence to that function? The motivation to this question comes from numerically calculate $\exp(x)$ with arbitrary precision on the result. Suppose one can only calculate it using simple multiplications, division, sum and subtraction. One approach would be to calculate the Taylor series centered on a particular known value (for instance, for the $\exp$, centered at $0$), and stop when the next term of the series has the desired precision. I.e. considering $$y_n = \sum_{i=0}^n \frac{x^n}{n!}$$ we can call the error of the approximation of $y_n$ as $$\epsilon_n = |y_n - e^x|\simeq \frac{x^{n+1}}{(n+1)!}$$ It is not obvious to me that the Taylor series is the fastest way of approaching $\exp(x)$ (in the sense that the Taylor Series is the one that leads to the n required to achieve a given precision is the minimum). I think the problem can also be stated in the following way: on the set of all series that converge to $e^x$, which converges faster in the sense that it requires the minimum number of terms (and only requires $+,-,\cdot,/$)? Generically, I would like to extent this results to less trivial functions, like $\cos, \arcsin, \log$, etc. So, first I would like to understand which series (or other things like Padé approximants, as Cocopuffs pointed out) should I use...",,"['calculus', 'sequences-and-series', 'taylor-expansion']"
69,Iterated Root Mean Square-Arithmetic Mean,Iterated Root Mean Square-Arithmetic Mean,,"Can I find iterated Root Mean Square-Arithmetic Mean as a function of Arithmetic-geometric mean (AGM) with some transformations if it is possible? if not possible, what is the closed form of it as known functions ? $$AGM=M(x,y)=\frac{\pi}{4}\frac{x+y}{K(\frac{x-y}{x+y})}$$ where $K(m)$ is the complete elliptic integral of the first kind: $$K(m)=\int_{0}^{\frac{\pi}{2}} \frac{dx}{\sqrt{1-m^2\sin^2(x)}}$$ Iterative Root-Mean Square-Arithmetic Mean calculation: $$r_1=\sqrt{\frac{r_0^2+a_0^2}{2}}$$ $$a_1=\frac{r_0+a_0}{2}$$ $$r_{n+1}=\sqrt{\frac{r_n^2+a_n^2}{2}}$$ $$a_{n+1}=\frac{r_n+a_n}{2}$$ Root Mean Square-Arithmetic Mean of $(r_0,a_0)=RMSAM(r_0,a_0)=\lim\limits_{n\to \infty} r_{n}=\lim\limits_{n\to \infty} a_{n}$ Thanks a lot for answers","Can I find iterated Root Mean Square-Arithmetic Mean as a function of Arithmetic-geometric mean (AGM) with some transformations if it is possible? if not possible, what is the closed form of it as known functions ? where is the complete elliptic integral of the first kind: Iterative Root-Mean Square-Arithmetic Mean calculation: Root Mean Square-Arithmetic Mean of Thanks a lot for answers","AGM=M(x,y)=\frac{\pi}{4}\frac{x+y}{K(\frac{x-y}{x+y})} K(m) K(m)=\int_{0}^{\frac{\pi}{2}} \frac{dx}{\sqrt{1-m^2\sin^2(x)}} r_1=\sqrt{\frac{r_0^2+a_0^2}{2}} a_1=\frac{r_0+a_0}{2} r_{n+1}=\sqrt{\frac{r_n^2+a_n^2}{2}} a_{n+1}=\frac{r_n+a_n}{2} (r_0,a_0)=RMSAM(r_0,a_0)=\lim\limits_{n\to \infty} r_{n}=\lim\limits_{n\to \infty} a_{n}","['sequences-and-series', 'functions', 'special-functions']"
70,How is Lagrange's inversion theorem derived?,How is Lagrange's inversion theorem derived?,,"I am interested in the complex-analysis version of deriving Lagrange's inversion theorem: If $y=f(x)$ with $f(a)=b$ and $f'(a)\neq 0$, then   $$x(y)=a+\sum_{n=1}^{\infty} \left(\lim_{x\to a}\frac{d^{n-1}}{dx^{n-1}}\left(\frac{x-a}{f(x)-b}\right)^n \frac{(y-b)^n}{n!}\right).$$ The derivative expression immediately suggests some type of residue calculation but I'm not able to derive it or find any reference on line that goes over it. Can someone here help me with this?","I am interested in the complex-analysis version of deriving Lagrange's inversion theorem: If $y=f(x)$ with $f(a)=b$ and $f'(a)\neq 0$, then   $$x(y)=a+\sum_{n=1}^{\infty} \left(\lim_{x\to a}\frac{d^{n-1}}{dx^{n-1}}\left(\frac{x-a}{f(x)-b}\right)^n \frac{(y-b)^n}{n!}\right).$$ The derivative expression immediately suggests some type of residue calculation but I'm not able to derive it or find any reference on line that goes over it. Can someone here help me with this?",,"['sequences-and-series', 'complex-analysis', 'power-series']"
71,Beta integral and Chu-Vandermonde identity,Beta integral and Chu-Vandermonde identity,,"Chu vandermonde identity states that     ${s+t \choose n}=\sum_{k=0}^n {s \choose k}{t \choose n-k} $ Now how to prove that this identity is a discrete form of beta integral? i see as a starting point to rewrite this identity for n+1 by replacing n by n+1  , then what?  any help? since after writing that i seem to be getting a very crude expression that leads me no where.","Chu vandermonde identity states that     ${s+t \choose n}=\sum_{k=0}^n {s \choose k}{t \choose n-k} $ Now how to prove that this identity is a discrete form of beta integral? i see as a starting point to rewrite this identity for n+1 by replacing n by n+1  , then what?  any help? since after writing that i seem to be getting a very crude expression that leads me no where.",,"['sequences-and-series', 'special-functions']"
72,"Is there a reasonably simple, non-recursive formula for this sequence?","Is there a reasonably simple, non-recursive formula for this sequence?",,"I have been curious about the following sequence of rational numbers for some time. I identified the numerator and denominators on the Online Encyclopedia of Integer sequences, but there was not much information there, except for an alternate way of calculating the sequence, using series reversions. I've verified that that works, though I don't quite understand why it works. $A_n$ = A097088 / 2 ^ A097088 $a_1$ = 1, $a_2$ = 1/2 If f is the formal series for A (with $a_0$ = 0, so no constant term), then one recurrence formula is: $a_{n+1}$ = - ([$x^{n+1}$] ($a_2$ $f^2$ + $a_3$ $f^3$ + ... $a_n$ ${f}^n$ )) / 2, for n >= 2 This recurrence only depends on the terms of f up to $a_n$, because f has no constant term. Also, f(f(x)) = x + $x^2$, and the values of a can also be defined by using the chain rule repeatedly since f(0)=0. $a_n$ = 1, $\frac{1}{2}$, -$\frac{1}{4}$, $\frac{1}{4}$, -$\frac{5}{16}$, $\frac{27}{64}$, -$\frac{9}{16}$, $\frac{171}{256}$ ... $a_n$ has both negative and positive terms alternating without any clear pattern that I've seen, and I've calculated about 50 terms using Mathematica, and their absolute magnitude generally grows over time, but I haven't seen any way to get to a decent non-recursive formula, and maybe there is no such formula. But I am curious if anyone else has run into this type of sequence and knows of tricks for finding a formula.","I have been curious about the following sequence of rational numbers for some time. I identified the numerator and denominators on the Online Encyclopedia of Integer sequences, but there was not much information there, except for an alternate way of calculating the sequence, using series reversions. I've verified that that works, though I don't quite understand why it works. $A_n$ = A097088 / 2 ^ A097088 $a_1$ = 1, $a_2$ = 1/2 If f is the formal series for A (with $a_0$ = 0, so no constant term), then one recurrence formula is: $a_{n+1}$ = - ([$x^{n+1}$] ($a_2$ $f^2$ + $a_3$ $f^3$ + ... $a_n$ ${f}^n$ )) / 2, for n >= 2 This recurrence only depends on the terms of f up to $a_n$, because f has no constant term. Also, f(f(x)) = x + $x^2$, and the values of a can also be defined by using the chain rule repeatedly since f(0)=0. $a_n$ = 1, $\frac{1}{2}$, -$\frac{1}{4}$, $\frac{1}{4}$, -$\frac{5}{16}$, $\frac{27}{64}$, -$\frac{9}{16}$, $\frac{171}{256}$ ... $a_n$ has both negative and positive terms alternating without any clear pattern that I've seen, and I've calculated about 50 terms using Mathematica, and their absolute magnitude generally grows over time, but I haven't seen any way to get to a decent non-recursive formula, and maybe there is no such formula. But I am curious if anyone else has run into this type of sequence and knows of tricks for finding a formula.",,"['sequences-and-series', 'power-series']"
73,"Prime zeta definition, multiplication by zero","Prime zeta definition, multiplication by zero",,"Wikipedia has a page about the prime zeta function which is defined as follows: $$P(s)=\sum_{p\;\text{prime}} \frac1{p^s}$$ I entered this additional definition: Define a sequence: $$a_n=\prod_{d\mid n} \frac{\Lambda(d)}{\log(d)},$$ where zeros are not included in the multiplication and $a_1=1$ then: $$P(s)=\log\sum_{n=1}^\infty \frac{a_n}{n^s}.$$ Is it a problem that this later definition does not include the zeros in the multiplication?","Wikipedia has a page about the prime zeta function which is defined as follows: $$P(s)=\sum_{p\;\text{prime}} \frac1{p^s}$$ I entered this additional definition: Define a sequence: $$a_n=\prod_{d\mid n} \frac{\Lambda(d)}{\log(d)},$$ where zeros are not included in the multiplication and $a_1=1$ then: $$P(s)=\log\sum_{n=1}^\infty \frac{a_n}{n^s}.$$ Is it a problem that this later definition does not include the zeros in the multiplication?",,"['number-theory', 'sequences-and-series', 'prime-numbers']"
74,Associativity of infinite products,Associativity of infinite products,,"It is well-known that if $\sum_{j=1}^\infty a_j$ is an absolutely convergent complex series and $\mathbb N$ is partitioned as $J_1,J_2,\dots$ , then the series $\sum_{j\in J_n}a_j$ for all $n$ and $\sum_{n=1}^\infty\sum_{j\in J_n}a_j$ are both absolutely convergent, with $\sum_{j=1}^\infty a_j=\sum_{n=1}^\infty\sum_{j\in J_n}a_j$ . I am trying to make sense of the same identity for infinite products. The convention I'm using is The product $\prod_{j=1}^\infty z_j$ is called convergent if there exists an $m$ such that the partial products $\prod_{j=m}^nz_j$ converge to a non-zero number as $n\to\infty$ . Write $z_j=1+w_j$ , the product is said to converge absolutely if $\prod_j(1+|w_j|)$ converges. It is known that $\prod_j(1+|w_j|)$ converges if and only if $\sum_j|w_j|$ does, so it is easy to verify that all the products $\prod_{j\in J_n}z_j$ are absolutely convergent (using the same property for series). If I were to know that $\prod_{n=1}^\infty\prod_{j\in J_n}z_j$ converges (absolutely or not), then after assuming all the $z_j$ are non-zero (since equality is trivial otherwise) I could use the series $\sum_{j=1}^\infty l(z_j)$ (where $l$ is the principal value of the logarithm) and its absolute convergence to confirm the identity. My questions therefore are Is $\prod_{n=1}^\infty\prod_{j\in J_n}z_j$ absolutely convergent? And, assuming it isn't, how do I show $\prod_{n=1}^\infty\prod_{j\in J_n}z_j$ converges.","It is well-known that if is an absolutely convergent complex series and is partitioned as , then the series for all and are both absolutely convergent, with . I am trying to make sense of the same identity for infinite products. The convention I'm using is The product is called convergent if there exists an such that the partial products converge to a non-zero number as . Write , the product is said to converge absolutely if converges. It is known that converges if and only if does, so it is easy to verify that all the products are absolutely convergent (using the same property for series). If I were to know that converges (absolutely or not), then after assuming all the are non-zero (since equality is trivial otherwise) I could use the series (where is the principal value of the logarithm) and its absolute convergence to confirm the identity. My questions therefore are Is absolutely convergent? And, assuming it isn't, how do I show converges.","\sum_{j=1}^\infty a_j \mathbb N J_1,J_2,\dots \sum_{j\in J_n}a_j n \sum_{n=1}^\infty\sum_{j\in J_n}a_j \sum_{j=1}^\infty a_j=\sum_{n=1}^\infty\sum_{j\in J_n}a_j \prod_{j=1}^\infty z_j m \prod_{j=m}^nz_j n\to\infty z_j=1+w_j \prod_j(1+|w_j|) \prod_j(1+|w_j|) \sum_j|w_j| \prod_{j\in J_n}z_j \prod_{n=1}^\infty\prod_{j\in J_n}z_j z_j \sum_{j=1}^\infty l(z_j) l \prod_{n=1}^\infty\prod_{j\in J_n}z_j \prod_{n=1}^\infty\prod_{j\in J_n}z_j","['sequences-and-series', 'complex-analysis', 'convergence-divergence', 'infinite-product', 'absolute-convergence']"
75,Arbitrary decimal value of $A(n)=\left(\frac{11}{10}\right)^n$,Arbitrary decimal value of,A(n)=\left(\frac{11}{10}\right)^n,"For $n\in\mathbb{Z}$ consider the number $$A(n)=\left(1+x\right)^n\bigg{|}_{x=\frac{1}{10}}=\sum_{k=0}^\infty\binom{n}{k}10^{-k}$$ which we have expanded by the Taylor series. It is found that $$a_1=\binom{n}{1},\,a_2=\binom{n}{2},\,\dots ,\,a_k=\binom{n}{k},\dots$$ which I thought gives the explicit formula for the $k$ th digit below the decimal point of any number with the form $$A(n)=\left(\frac{11}{10}\right)^n$$ but take for example $A(5)=(11/10)^5=1.\color{red}{6}{1}051$ and say we want to find the $1$ st digit below the decimal, highlighted red. We see $a_1={}_5C_{1}=5$ which isn't $6$ as $a_2={}_5C_2=10$ contributes $1$ to the next digit. My question is, is it possible to find the $k$ th decimal value of $A(n)$ by means of coefficient extraction from some generating function? Edit 1: To clarify, I am not looking for a generating function, but some explicit formula for the $k$ th digit below the decimal point of $A(n)$ . Now, using generating functions to find the formula is of course fine.","For consider the number which we have expanded by the Taylor series. It is found that which I thought gives the explicit formula for the th digit below the decimal point of any number with the form but take for example and say we want to find the st digit below the decimal, highlighted red. We see which isn't as contributes to the next digit. My question is, is it possible to find the th decimal value of by means of coefficient extraction from some generating function? Edit 1: To clarify, I am not looking for a generating function, but some explicit formula for the th digit below the decimal point of . Now, using generating functions to find the formula is of course fine.","n\in\mathbb{Z} A(n)=\left(1+x\right)^n\bigg{|}_{x=\frac{1}{10}}=\sum_{k=0}^\infty\binom{n}{k}10^{-k} a_1=\binom{n}{1},\,a_2=\binom{n}{2},\,\dots ,\,a_k=\binom{n}{k},\dots k A(n)=\left(\frac{11}{10}\right)^n A(5)=(11/10)^5=1.\color{red}{6}{1}051 1 a_1={}_5C_{1}=5 6 a_2={}_5C_2=10 1 k A(n) k A(n)","['sequences-and-series', 'binomial-coefficients', 'generating-functions', 'decimal-expansion']"
76,"Let $a_1$ be linearly independent to $a_2$ over $\mathbb{Q}.$ For $n\geq 3,$ let $ a_n = \vert a_{n-1} - a_{n-2} \vert.$ Does $\sum_n a_n\ $ converge?",Let  be linearly independent to  over  For  let  Does  converge?,"a_1 a_2 \mathbb{Q}. n\geq 3,  a_n = \vert a_{n-1} - a_{n-2} \vert. \sum_n a_n\ ","Let $a_1$ be linearly independent to $a_2$ over the rational numbers. For $n\geq 3,\ $ let $ a_n = \vert a_{n-1} - a_{n-2} \vert.$ Does $\sum_n a_n\ $ converge? For example, let $a_1 = 1,\ a_2 = \ln 2=0.693\ldots\ .\ $ Then, $\ a_3 = \vert a_2 - a_1 \vert = 0.306\ldots,\ \ a_4 = \vert a_3 - a_2 \vert = 0.386\ldots,\ \ a_5 = \vert a_4 - a_3 \vert = 0.0794\ldots\ .$ I am not sure how to judge how quickly this converges to $0.$","Let be linearly independent to over the rational numbers. For let Does converge? For example, let Then, I am not sure how to judge how quickly this converges to","a_1 a_2 n\geq 3,\   a_n = \vert a_{n-1} - a_{n-2} \vert. \sum_n a_n\  a_1 = 1,\ a_2 = \ln 2=0.693\ldots\ .\  \ a_3 = \vert a_2 - a_1 \vert = 0.306\ldots,\ \ a_4 = \vert a_3 - a_2 \vert = 0.386\ldots,\ \ a_5 = \vert a_4 - a_3 \vert = 0.0794\ldots\ . 0.","['sequences-and-series', 'convergence-divergence', 'euclidean-algorithm', 'irrationality-measure']"
77,Does this table fit the normal distribution?,Does this table fit the normal distribution?,,"The Pascal triangle can be described by the recurrence: $P(n,1)=1, k>1: P(n,k) = P(n-i,k-1) + P(n-i,k)$ This well known triangle has the basic properties that the ratios of consecutive anti-diagonal sums (Fibonacci numbers) tend to the golden ratio, and that the ratios of consecutive row sums certainly tend to $2$. By the central limit theorem, wikipedia quote: ""When divided by $2^n$, the nth row of Pascal's triangle becomes the binomial distribution in the symmetric case where $p = 1/2$. By the central limit theorem, this distribution approaches the normal distribution as n increases."" Another triangle with the same golden ratio - and consecutive rows sums ratio tending to $2$ properties, albeit with somewhat slower convergence, is the cumulative column sums of the Mahonian numbers with the recurrence: $T(n,1)=1, k>1: T(n,k) = \sum\limits_{i=1}^{k-1} T(n-i,k-1)$ starting: $\begin{bmatrix} 1&0&0&0&0&0&0 \\ 1&1&0&0&0&0&0 \\ 1&1&1&0&0&0&0 \\ 1&1&2&1&0&0&0 \\ 1&1&2&3&1&0&0 \\ 1&1&2&5&4&1&0 \\ 1&1&2&6&9&5&1 \end{bmatrix}$ Does this later table also by some argument fit the normal distribution as n gets large? Arguments against this seems to be that the right-hand half of the table gets bigger and bigger while the left-hand side remains constant tending to the factorial numbers. On the other hand by plotting the values of the first few rows it looks like a normal distribution. Edit 4.2.2012: The Mathematica 8 program for the table is: Clear[T]; nn = 15; T[n_, 1] = 1; T[n_, k_] :=   T[n, k] = If[n >= k, Sum[T[n - i, k - 1], {i, 1, k - 1}], 0] MatrixForm[Table[T[n, k], {n, nn}, {k, nn}]] Edit 20.10.2014: Clear[T]; width = 20 height = 35000; T[n_, 1] = 1;  T[n_, k_] :=   T[n, k] = If[n >= k, Sum[T[n - i, k - 1], {i, 1, k - 1}], 0]  Table[ListLinePlot[Flatten[Table[T[n, k], {n, nn, nn}, {k, width}]],     DataRange -> {0, width}, PlotRange -> {0, height},     InterpolationOrder -> If[nn - 1 >= 11, 11, nn - 1]], {nn, 1,     width}]; Show[%, ImageSize -> Large]","The Pascal triangle can be described by the recurrence: $P(n,1)=1, k>1: P(n,k) = P(n-i,k-1) + P(n-i,k)$ This well known triangle has the basic properties that the ratios of consecutive anti-diagonal sums (Fibonacci numbers) tend to the golden ratio, and that the ratios of consecutive row sums certainly tend to $2$. By the central limit theorem, wikipedia quote: ""When divided by $2^n$, the nth row of Pascal's triangle becomes the binomial distribution in the symmetric case where $p = 1/2$. By the central limit theorem, this distribution approaches the normal distribution as n increases."" Another triangle with the same golden ratio - and consecutive rows sums ratio tending to $2$ properties, albeit with somewhat slower convergence, is the cumulative column sums of the Mahonian numbers with the recurrence: $T(n,1)=1, k>1: T(n,k) = \sum\limits_{i=1}^{k-1} T(n-i,k-1)$ starting: $\begin{bmatrix} 1&0&0&0&0&0&0 \\ 1&1&0&0&0&0&0 \\ 1&1&1&0&0&0&0 \\ 1&1&2&1&0&0&0 \\ 1&1&2&3&1&0&0 \\ 1&1&2&5&4&1&0 \\ 1&1&2&6&9&5&1 \end{bmatrix}$ Does this later table also by some argument fit the normal distribution as n gets large? Arguments against this seems to be that the right-hand half of the table gets bigger and bigger while the left-hand side remains constant tending to the factorial numbers. On the other hand by plotting the values of the first few rows it looks like a normal distribution. Edit 4.2.2012: The Mathematica 8 program for the table is: Clear[T]; nn = 15; T[n_, 1] = 1; T[n_, k_] :=   T[n, k] = If[n >= k, Sum[T[n - i, k - 1], {i, 1, k - 1}], 0] MatrixForm[Table[T[n, k], {n, nn}, {k, nn}]] Edit 20.10.2014: Clear[T]; width = 20 height = 35000; T[n_, 1] = 1;  T[n_, k_] :=   T[n, k] = If[n >= k, Sum[T[n - i, k - 1], {i, 1, k - 1}], 0]  Table[ListLinePlot[Flatten[Table[T[n, k], {n, nn, nn}, {k, width}]],     DataRange -> {0, width}, PlotRange -> {0, height},     InterpolationOrder -> If[nn - 1 >= 11, 11, nn - 1]], {nn, 1,     width}]; Show[%, ImageSize -> Large]",,"['sequences-and-series', 'normal-distribution']"
78,Convergence of the random harmonic series $\sum_{n=1}^{\infty}\frac{X_{n}}{n}$,Convergence of the random harmonic series,\sum_{n=1}^{\infty}\frac{X_{n}}{n},"Let $(X_{n})_{n \in \mathbb{N}}$ be independent with Rademacher distribution : \begin{equation} \mathbb{P}(X_{n} = -1) = \frac{1}{2} = \mathbb{P}(X_{n} = 1). \end{equation} I have to investigate \begin{equation} \sum_{n=1}^{\infty}\frac{X_{n}}{n} \end{equation} for convergence. It was given in a textbook and I'm very interested in the solution. It is something between the harmonic series $\sum_{n=1}^{\infty}\frac{1}{n}$ and the series $\sum_{n=1}^{\infty}\frac{(-1)^{n}}{n}$ , but I know the sign changes randomly.","Let be independent with Rademacher distribution : I have to investigate for convergence. It was given in a textbook and I'm very interested in the solution. It is something between the harmonic series and the series , but I know the sign changes randomly.","(X_{n})_{n \in \mathbb{N}} \begin{equation}
\mathbb{P}(X_{n} = -1) = \frac{1}{2} = \mathbb{P}(X_{n} = 1).
\end{equation} \begin{equation}
\sum_{n=1}^{\infty}\frac{X_{n}}{n}
\end{equation} \sum_{n=1}^{\infty}\frac{1}{n} \sum_{n=1}^{\infty}\frac{(-1)^{n}}{n}","['sequences-and-series', 'probability-theory']"
79,Conditions for $\frac{a_{n+1}}{a_n}$ to converge? [closed],Conditions for  to converge? [closed],\frac{a_{n+1}}{a_n},Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 4 years ago . Improve this question Given a sequence $a_n \to 0$. I'm looking for a necessary and sufficient condition for $\frac{a_{n+1}}{a_n}$ to converge.,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 4 years ago . Improve this question Given a sequence $a_n \to 0$. I'm looking for a necessary and sufficient condition for $\frac{a_{n+1}}{a_n}$ to converge.,,"['calculus', 'sequences-and-series', 'limits']"
80,How to show $\ \int_1^\infty\frac1xdx\ $ diverges (not using the harmonic series)?,How to show  diverges (not using the harmonic series)?,\ \int_1^\infty\frac1xdx\ ,"I was reading up on the harmonic series, $H=\sum\limits_{n=1}^\infty\frac1n$ , on Wikipedia, and it's divergent, as can be shown by a comparison test using the fact that $\begin{aligned}H&=1+\frac12+\left(\frac13+\frac14\right)+\left(\frac15+\frac16+\frac17+\frac18\right)+\cdots\\&\geq 1+\frac12+\left(\frac14+\frac14\right)+\left(\frac18+\frac18+\frac18+\frac18\right)+\cdots\\&=1+\frac12+\frac12+\frac12+\cdots,\end{aligned}$ where the expression on the right clearly diverges. But after this proof idea was given, the proof idea using the integral test was given. I understand why $H_n=\sum_{k=1}^n\frac1k\geq \int_1^n \frac{dx}x$ , but how is it shown that $\int_1^\infty \frac{dx}x$ is divergent without using the harmonic series in the following way: $H_n-1\leq \int_1^n \frac{dx}x\leq H_n$ , and then using this in the following way, by comparison test: $\lim\limits_{n\to\infty}H_n=\infty\implies\lim\limits_{n\to\infty}(H_n-1)=\infty\implies\lim\limits_{n\to\infty}\int_1^n \frac{dx}x=\infty$ . So to summarize, is there a way to prove that $\int_1^\infty \frac{dx}x$ without using the fact that $H$ diverges?","I was reading up on the harmonic series, , on Wikipedia, and it's divergent, as can be shown by a comparison test using the fact that where the expression on the right clearly diverges. But after this proof idea was given, the proof idea using the integral test was given. I understand why , but how is it shown that is divergent without using the harmonic series in the following way: , and then using this in the following way, by comparison test: . So to summarize, is there a way to prove that without using the fact that diverges?","H=\sum\limits_{n=1}^\infty\frac1n \begin{aligned}H&=1+\frac12+\left(\frac13+\frac14\right)+\left(\frac15+\frac16+\frac17+\frac18\right)+\cdots\\&\geq 1+\frac12+\left(\frac14+\frac14\right)+\left(\frac18+\frac18+\frac18+\frac18\right)+\cdots\\&=1+\frac12+\frac12+\frac12+\cdots,\end{aligned} H_n=\sum_{k=1}^n\frac1k\geq \int_1^n \frac{dx}x \int_1^\infty \frac{dx}x H_n-1\leq \int_1^n \frac{dx}x\leq H_n \lim\limits_{n\to\infty}H_n=\infty\implies\lim\limits_{n\to\infty}(H_n-1)=\infty\implies\lim\limits_{n\to\infty}\int_1^n \frac{dx}x=\infty \int_1^\infty \frac{dx}x H","['calculus', 'sequences-and-series', 'convergence-divergence', 'improper-integrals']"
81,Infinite series expansions for 3/7?,Infinite series expansions for 3/7?,,"What are some infinite series expansion for $3/7$ (and in general, for fractions with digits in base 10)? I can't think of something useful at all. Please generalize some useful series expression for all those kinds of fraction. Can someone help?","What are some infinite series expansion for $3/7$ (and in general, for fractions with digits in base 10)? I can't think of something useful at all. Please generalize some useful series expression for all those kinds of fraction. Can someone help?",,"['sequences-and-series', 'big-list']"
82,"What is the next number in this sequence: $1, 2, 6, 24, 120$? [closed]",What is the next number in this sequence: ? [closed],"1, 2, 6, 24, 120","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question I was playing through No Man's Sky when I ran into a series of numbers and was asked what the next number would be. $$1, 2, 6, 24, 120$$ This is for a terminal assess code in the game no mans sky.  The 3 choices they give are; 720, 620, 180","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question I was playing through No Man's Sky when I ran into a series of numbers and was asked what the next number would be. This is for a terminal assess code in the game no mans sky.  The 3 choices they give are; 720, 620, 180","1, 2, 6, 24, 120",['sequences-and-series']
83,Convergence or not of infinite series: $\sum^{\infty}_{n=1}\frac{n}{1+n^2}$ [duplicate],Convergence or not of infinite series:  [duplicate],\sum^{\infty}_{n=1}\frac{n}{1+n^2},This question already has an answer here : Prove that $\sum_{n=1}^\infty\frac{n}{n^2+1}$ is divergent (1 answer) Closed 6 years ago . How can we prove that the series $\displaystyle \sum^{\infty}_{n=1}\frac{n}{1+n^2}$ is convergent or divergent? Solution I try: $$\lim_{m\rightarrow \infty}\sum^{m}_{n=1}\frac{n}{1+n^2}<\lim_{m\rightarrow \infty}\sum^{m}_{n=1}\frac{n}{n^2}$$ Did not know how I can solve that problem from that point.,This question already has an answer here : Prove that $\sum_{n=1}^\infty\frac{n}{n^2+1}$ is divergent (1 answer) Closed 6 years ago . How can we prove that the series $\displaystyle \sum^{\infty}_{n=1}\frac{n}{1+n^2}$ is convergent or divergent? Solution I try: $$\lim_{m\rightarrow \infty}\sum^{m}_{n=1}\frac{n}{1+n^2}<\lim_{m\rightarrow \infty}\sum^{m}_{n=1}\frac{n}{n^2}$$ Did not know how I can solve that problem from that point.,,"['calculus', 'real-analysis', 'sequences-and-series']"
84,Does $\sum_{k=1}^{\infty}\frac{k!}{k^k}$ converge?,Does  converge?,\sum_{k=1}^{\infty}\frac{k!}{k^k},"I have tried using ratio test: $$P =\lim_{k\rightarrow\infty}\left|\frac{(k+1)!}{(k+1)^{k+1}}\cdot\frac{k^k}{k!}\right|$$ $$ P=\lim_{k\rightarrow\infty}\left|\frac{(k+1)\cdot k^k}{(k+1)^{k+1}}\right|$$ $$ P=\lim_{k\rightarrow\infty}\left|\frac{k^{k+1}+ k^k}{(k+1)^{k+1}}\right|$$ In the final expression, the highest degrees in the denominator and numerator are both $(k+1)$. So according to the L'Hospital's Rule, the limit would goes to $1$. $$P=1$$ Thus the test failed. Any suggestions on how to test the convergence of this series?","I have tried using ratio test: $$P =\lim_{k\rightarrow\infty}\left|\frac{(k+1)!}{(k+1)^{k+1}}\cdot\frac{k^k}{k!}\right|$$ $$ P=\lim_{k\rightarrow\infty}\left|\frac{(k+1)\cdot k^k}{(k+1)^{k+1}}\right|$$ $$ P=\lim_{k\rightarrow\infty}\left|\frac{k^{k+1}+ k^k}{(k+1)^{k+1}}\right|$$ In the final expression, the highest degrees in the denominator and numerator are both $(k+1)$. So according to the L'Hospital's Rule, the limit would goes to $1$. $$P=1$$ Thus the test failed. Any suggestions on how to test the convergence of this series?",,"['calculus', 'sequences-and-series', 'limits', 'convergence-divergence']"
85,"The general term of the sequence : 1, 1, -1, -1, 1, 1, ...? [duplicate]","The general term of the sequence : 1, 1, -1, -1, 1, 1, ...? [duplicate]",,"This question already has answers here : Generalizing a sequence. (4 answers) Closed 6 years ago . Suppose we have the following sequence: {$a_n$} such as: $a_0 = 1, \\ a_1 = 1, \\ a_2 = -1, \\ a_3 = -1, \\ a_4 = 1, \\ a_5 = 1, \\ ... $ How can we find the general term of this sequence? I tried using a trigonometric function e.g. $\alpha \sin(x+\phi)$, then we impose some constraints on $\alpha$ and $\phi$ to get that sequence, but I get lost, is there any clever way to find the general term? EDIT: The question is identified as duplicate, but that answer does not solve the question, because I am looking for a solution that does not involve floor function.","This question already has answers here : Generalizing a sequence. (4 answers) Closed 6 years ago . Suppose we have the following sequence: {$a_n$} such as: $a_0 = 1, \\ a_1 = 1, \\ a_2 = -1, \\ a_3 = -1, \\ a_4 = 1, \\ a_5 = 1, \\ ... $ How can we find the general term of this sequence? I tried using a trigonometric function e.g. $\alpha \sin(x+\phi)$, then we impose some constraints on $\alpha$ and $\phi$ to get that sequence, but I get lost, is there any clever way to find the general term? EDIT: The question is identified as duplicate, but that answer does not solve the question, because I am looking for a solution that does not involve floor function.",,['sequences-and-series']
86,Is $X_n = 1+\frac12+\frac{1}{2^2}+\cdots+\frac{1}{2^n}; \forall n \ge 0$ bounded?,Is  bounded?,X_n = 1+\frac12+\frac{1}{2^2}+\cdots+\frac{1}{2^n}; \forall n \ge 0,"Is $X_n = 1+\frac12+\frac{1}{2^2}+\cdots+\frac{1}{2^n}; \forall n \ge 0$ bounded? I have to find an upper bound for $X_n$ and i cant figure it out, a lower bound can be 0 or 1 but does it have an upper bound?","Is $X_n = 1+\frac12+\frac{1}{2^2}+\cdots+\frac{1}{2^n}; \forall n \ge 0$ bounded? I have to find an upper bound for $X_n$ and i cant figure it out, a lower bound can be 0 or 1 but does it have an upper bound?",,"['calculus', 'sequences-and-series', 'algebra-precalculus']"
87,Prove that the derivative of $x^w$ is $w x^{w-1}$ for real $w$,Prove that the derivative of  is  for real,x^w w x^{w-1} w,"Can anyone give a proof of the derivative of this type of function? Specifically showing that $\dfrac{d(x^w)}{dx} = wx^{w-1}$ for a real $w$ ? I tried to use the Taylor series expansion for $(x+dx)^w$ and got the correct result. However, the proof of the Taylor series requires knowledge of the derivative of these functions. So this is essentially circular reasoning. I know that the same series is also given by the binomial expansion, but that's not entirely satisfactory either, because where's the proof that the binomial expansion works for all reals (isn't it only apparent for integers)? So far all of the arguments I've come across involve circular reasoning. I was thinking of showing that the binomial expansion is true for all reals using some form of proof by induction e.g. something like this. http://www.math.ucsd.edu/~benchow/BinomialTheorem.pdf I'm really not sure.","Can anyone give a proof of the derivative of this type of function? Specifically showing that for a real ? I tried to use the Taylor series expansion for and got the correct result. However, the proof of the Taylor series requires knowledge of the derivative of these functions. So this is essentially circular reasoning. I know that the same series is also given by the binomial expansion, but that's not entirely satisfactory either, because where's the proof that the binomial expansion works for all reals (isn't it only apparent for integers)? So far all of the arguments I've come across involve circular reasoning. I was thinking of showing that the binomial expansion is true for all reals using some form of proof by induction e.g. something like this. http://www.math.ucsd.edu/~benchow/BinomialTheorem.pdf I'm really not sure.",\dfrac{d(x^w)}{dx} = wx^{w-1} w (x+dx)^w,"['calculus', 'sequences-and-series', 'algebra-precalculus', 'derivatives']"
88,Sequence with all rationals as limit points,Sequence with all rationals as limit points,,"Is it possible to build the sequence that has all rationals as limit points? A limit point of a sequence $(x_n)$ is a point $x$ such that each neighborhood $(x-\varepsilon,x+\varepsilon)$ contains $x_n$ for infinitely many $n$'s. Equivalently, $x$ is a limit point if and only there is a subsequence $(x_{n_k})$ which converges to $x$. Thank you.","Is it possible to build the sequence that has all rationals as limit points? A limit point of a sequence $(x_n)$ is a point $x$ such that each neighborhood $(x-\varepsilon,x+\varepsilon)$ contains $x_n$ for infinitely many $n$'s. Equivalently, $x$ is a limit point if and only there is a subsequence $(x_{n_k})$ which converges to $x$. Thank you.",,"['real-analysis', 'sequences-and-series', 'examples-counterexamples']"
89,Trying to find a flaw in my proof that there are more rearrangements of an infinite series than real numbers,Trying to find a flaw in my proof that there are more rearrangements of an infinite series than real numbers,,"So I had this thought that I was trying to prove as an exercise Let $\mathbb{R}$ be the set of real numbers and let $\mathbb{S}$ be the set of all possible rearrangements of the alternating harmonic series. Prove that $|\mathbb{R}| < |\mathbb{S}|$ I thought I had a proof of this, but I then posted it to Reddit /r/math only to be downvoted and told the proof was wrong. The only comment I received was to ""look at it from the other direction"", but that confused me. Here is my proof: Two sets have the same cardinality iff there exists a bijection between them. From the rearrangement theorem we can show that a the alternating harmonic series can converge to any real number via the following algorithm: Start with $1$ , if this is larger than the target number add the next negative term, otherwise add the next positive term. We create a mapping from the created rearrangement to the limit of this rearrangement. Notice that this maps to all real numbers. Now take one of the series that we had, and switch the first two terms. This is a new rearrangement since it does not begin with $1$ , so it should be mapped to a new real number. However all real numbers have already had a rearrangement mapped to them. As such we have two rearrangements pointing to a single real number, which means that our mapping is not a bijection. As such there must be more rearrangements than real numbers. Now I am not sure where my proof went wrong, so any help would be appreciated!","So I had this thought that I was trying to prove as an exercise Let be the set of real numbers and let be the set of all possible rearrangements of the alternating harmonic series. Prove that I thought I had a proof of this, but I then posted it to Reddit /r/math only to be downvoted and told the proof was wrong. The only comment I received was to ""look at it from the other direction"", but that confused me. Here is my proof: Two sets have the same cardinality iff there exists a bijection between them. From the rearrangement theorem we can show that a the alternating harmonic series can converge to any real number via the following algorithm: Start with , if this is larger than the target number add the next negative term, otherwise add the next positive term. We create a mapping from the created rearrangement to the limit of this rearrangement. Notice that this maps to all real numbers. Now take one of the series that we had, and switch the first two terms. This is a new rearrangement since it does not begin with , so it should be mapped to a new real number. However all real numbers have already had a rearrangement mapped to them. As such we have two rearrangements pointing to a single real number, which means that our mapping is not a bijection. As such there must be more rearrangements than real numbers. Now I am not sure where my proof went wrong, so any help would be appreciated!",\mathbb{R} \mathbb{S} |\mathbb{R}| < |\mathbb{S}| 1 1,"['sequences-and-series', 'general-topology', 'elementary-set-theory', 'real-numbers', 'infinity']"
90,"Finding the $n^{\text{th}}$ term of $-1,-1,-1,-1,1,1,1,1,...$ as a repeating 8-block",Finding the  term of  as a repeating 8-block,"n^{\text{th}} -1,-1,-1,-1,1,1,1,1,...","In my work I came across that sequence $-1,-1,-1,-1,1,1,1,1,\dots$ and repeating this 8-block so on forever Now I cant find an ( e.g. trigonometric/complex ) expression $f(n)$ ( e.g. $f(n) =(-1)^g(n)$ ) which gives me the sequence starting with  $n=2,3,4,5,6,7,8,9,…$ and so on forever.","In my work I came across that sequence $-1,-1,-1,-1,1,1,1,1,\dots$ and repeating this 8-block so on forever Now I cant find an ( e.g. trigonometric/complex ) expression $f(n)$ ( e.g. $f(n) =(-1)^g(n)$ ) which gives me the sequence starting with  $n=2,3,4,5,6,7,8,9,…$ and so on forever.",,['sequences-and-series']
91,Convergence of $\sum \frac{(2n)!}{n!n!}\frac{1}{4^n}$,Convergence of,\sum \frac{(2n)!}{n!n!}\frac{1}{4^n},"Does the series $$\sum \frac{(2n)!}{n!n!}\frac{1}{4^n}$$ converges? My attempt: Since the ratio test is inconclusive, my idea is to use the Stirling Approximation for n! $$\frac{(2n)!}{n!n!4^n} \sim (\frac{1}{4^n} \frac{\sqrt{4\pi n}(\frac{2n}{e})^{2n}}{\sqrt{2 n \pi} \sqrt{2n \pi} (\frac{n}{e})^{2n}} =\frac{(2)^{2n}}{4^n \sqrt{n \pi}}$$ The series of the secomd term diverges. It is correct to conclude thatthe series diverges? Another ideas are welcome! Thanks","Does the series $$\sum \frac{(2n)!}{n!n!}\frac{1}{4^n}$$ converges? My attempt: Since the ratio test is inconclusive, my idea is to use the Stirling Approximation for n! $$\frac{(2n)!}{n!n!4^n} \sim (\frac{1}{4^n} \frac{\sqrt{4\pi n}(\frac{2n}{e})^{2n}}{\sqrt{2 n \pi} \sqrt{2n \pi} (\frac{n}{e})^{2n}} =\frac{(2)^{2n}}{4^n \sqrt{n \pi}}$$ The series of the secomd term diverges. It is correct to conclude thatthe series diverges? Another ideas are welcome! Thanks",,"['calculus', 'sequences-and-series', 'analysis', 'convergence-divergence']"
92,A sequence of real numbers such that $\lim_{n\to+\infty}|x_n-x_{n+1}|=0$ but it is not Cauchy,A sequence of real numbers such that  but it is not Cauchy,\lim_{n\to+\infty}|x_n-x_{n+1}|=0,"Give an example of a sequence $(x_n)$ of real numbers, where $\displaystyle\lim_{n\to+\infty}|x_n-x_{n+1}|=0$, but $(x_n)$ is not a Cauchy sequence","Give an example of a sequence $(x_n)$ of real numbers, where $\displaystyle\lim_{n\to+\infty}|x_n-x_{n+1}|=0$, but $(x_n)$ is not a Cauchy sequence",,"['real-analysis', 'sequences-and-series', 'analysis', 'limits', 'cauchy-sequences']"
93,Prove that a function is indefinitely differentiable,Prove that a function is indefinitely differentiable,,"Show that if $$f: \mathbb{R} \to \mathbb{R}$$ is differentiable in second order which satisfies the equation $$f'' =f'+f$$ then $f$ is indefinitely differentiable. I was thinking to write the $n$ the derivative as $$f^{(n)}=a_nf+b_nf',  a_n=b_{n-1}, b_n=a_{n-1}+b_{n-1} $$ I calculated a few derivatives so I think this must be the form of the sequence, but I don't know how to solve it and I cannot see any other pattern to write the general term.","Show that if is differentiable in second order which satisfies the equation then is indefinitely differentiable. I was thinking to write the the derivative as I calculated a few derivatives so I think this must be the form of the sequence, but I don't know how to solve it and I cannot see any other pattern to write the general term.","f: \mathbb{R} \to \mathbb{R} f'' =f'+f f n f^{(n)}=a_nf+b_nf',  a_n=b_{n-1}, b_n=a_{n-1}+b_{n-1} ","['calculus', 'sequences-and-series', 'functions', 'derivatives', 'recurrence-relations']"
94,Show that $\sum_{n=0}^\infty \frac{1}{n+1} \binom{2n}{n} \frac{1}{2^{2n+1}} = 1.$,Show that,\sum_{n=0}^\infty \frac{1}{n+1} \binom{2n}{n} \frac{1}{2^{2n+1}} = 1.,"Question: Show that $$\sum_{n=0}^\infty \frac{1}{n+1} \binom{2n}{n} \frac{1}{2^{2n+1}} = 1.$$ From Wolfram alpha , it seems that the equality above is indeed correct. But I do not know how to prove it. Any hint is appreciated.","Question: Show that From Wolfram alpha , it seems that the equality above is indeed correct. But I do not know how to prove it. Any hint is appreciated.",\sum_{n=0}^\infty \frac{1}{n+1} \binom{2n}{n} \frac{1}{2^{2n+1}} = 1.,"['calculus', 'sequences-and-series', 'convergence-divergence', 'summation']"
95,Does $\sum_{n=1}^\infty \frac{1}{\log(e^{n}+e^{-n})}$ converge or diverge?,Does  converge or diverge?,\sum_{n=1}^\infty \frac{1}{\log(e^{n}+e^{-n})},How would I show that the following series converges or diverges? $$\sum_{n=1}^\infty  \frac{1}{\log(e^{n}+e^{-n})}$$ Any help would be appreciated.,How would I show that the following series converges or diverges? $$\sum_{n=1}^\infty  \frac{1}{\log(e^{n}+e^{-n})}$$ Any help would be appreciated.,,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
96,"I've shown $\lim_{n\to\infty}\sqrt[n]{n}=e$, but it should be $1$. Where's the mistake?","I've shown , but it should be . Where's the mistake?",\lim_{n\to\infty}\sqrt[n]{n}=e 1,$$\lim_{n\to \infty} \sqrt[n] n = \lim_{n\to \infty} n^{\frac{1}{n}} = \lim_{n \to \infty} \{(1+(n-1))^{\frac{1}{n-1}}\}{^{(n-1)\frac{1}{n}}} = \lim_{n\to \infty} e^{\frac{n-1}{n}} = e$$ But this clearly isn't true as the actual limit is $1$. Where did I go wrong?,$$\lim_{n\to \infty} \sqrt[n] n = \lim_{n\to \infty} n^{\frac{1}{n}} = \lim_{n \to \infty} \{(1+(n-1))^{\frac{1}{n-1}}\}{^{(n-1)\frac{1}{n}}} = \lim_{n\to \infty} e^{\frac{n-1}{n}} = e$$ But this clearly isn't true as the actual limit is $1$. Where did I go wrong?,,"['sequences-and-series', 'algebra-precalculus', 'limits', 'exponential-function', 'radicals']"
97,"Evaluating $\sum\limits_{n=2}^{\infty} \frac{1}{ GPF(n) GPF(n+1)}\,$, where $\operatorname{ GPF}(n)$ is the greatest prime factor","Evaluating , where  is the greatest prime factor","\sum\limits_{n=2}^{\infty} \frac{1}{ GPF(n) GPF(n+1)}\, \operatorname{ GPF}(n)","$\operatorname{ GPF}(n)=$Greatest prime factor of $n$, eg. $\operatorname{ GPF}(17)=17$, $\operatorname{ GPF}(18)=3$. $\operatorname{ LPF}(n)=$Least prime factor of $n$, eg. $\operatorname{ LPF}(17)=17$, $\operatorname{ LPF}(18)=2$. $P_n=n$'th prime number, eg. $P_5=11$. How to evaluate convergence/divergence/value of the sums $$\sum_{n=2}^{\infty} \frac{1}{n\operatorname{ LPF}(n)}\,?$$ $$\sum_{n=2}^{\infty} \frac{1}{P_n\operatorname{ LPF}(n)}\,?$$ $$\sum_{n=2}^{\infty} \frac{1}{\operatorname{ GPF}(n)\operatorname{ GPF}(n+1)}\,?$$ $$\sum_{n=2}^{\infty} \frac{1}{\operatorname{ GPF}(n)\operatorname{ GPF}(n+1)\operatorname{ GPF}(n+2)}\,?$$ How to prove this diverges ? $$\sum_{n=2}^{\infty} \frac{1}{\operatorname{ GPF}(n)\operatorname{ GPF}(n+1)\operatorname{ GPF}(n+2)...\operatorname{ GPF}(n+1000)}\,?$$ Related: Evaluating $\sum\limits_{n=1}^{\infty} \frac{1}{n\operatorname{ GPF}(n)}$, where $\operatorname{ GPF}(n)$ is the greatest prime factor","$\operatorname{ GPF}(n)=$Greatest prime factor of $n$, eg. $\operatorname{ GPF}(17)=17$, $\operatorname{ GPF}(18)=3$. $\operatorname{ LPF}(n)=$Least prime factor of $n$, eg. $\operatorname{ LPF}(17)=17$, $\operatorname{ LPF}(18)=2$. $P_n=n$'th prime number, eg. $P_5=11$. How to evaluate convergence/divergence/value of the sums $$\sum_{n=2}^{\infty} \frac{1}{n\operatorname{ LPF}(n)}\,?$$ $$\sum_{n=2}^{\infty} \frac{1}{P_n\operatorname{ LPF}(n)}\,?$$ $$\sum_{n=2}^{\infty} \frac{1}{\operatorname{ GPF}(n)\operatorname{ GPF}(n+1)}\,?$$ $$\sum_{n=2}^{\infty} \frac{1}{\operatorname{ GPF}(n)\operatorname{ GPF}(n+1)\operatorname{ GPF}(n+2)}\,?$$ How to prove this diverges ? $$\sum_{n=2}^{\infty} \frac{1}{\operatorname{ GPF}(n)\operatorname{ GPF}(n+1)\operatorname{ GPF}(n+2)...\operatorname{ GPF}(n+1000)}\,?$$ Related: Evaluating $\sum\limits_{n=1}^{\infty} \frac{1}{n\operatorname{ GPF}(n)}$, where $\operatorname{ GPF}(n)$ is the greatest prime factor",,"['real-analysis', 'sequences-and-series', 'convergence-divergence', 'analytic-number-theory', 'divergent-series']"
98,A positive sequence which is arbitrarily small and diverging,A positive sequence which is arbitrarily small and diverging,,"Let $(a_n)_{n\in\mathbb{N}}$ be a positive sequence. Assume, that $\lim_{n \to \infty} a_n = \infty$. $\forall\ \zeta > 0, \exists\ n=n(\zeta) \geq 1: a_n < \zeta.$ From 1. we know, that $\forall\ C > 0, \exists\ N = N(C) \geq 1: a_n \geq C, \forall\ n \geq N.$ The difference $N(C) - n(\zeta)$ can be interpreted as the 'recovery time', i.e. the time the sequence needs from being arbitrarily small to become larger than an arbitrary positive constant $C$  for the rest of its existence. Question: Can somebody think of an example where $\forall\ C > 0: N(C) - n(\zeta)$ is arbitrarily large? (Is this even possible?)","Let $(a_n)_{n\in\mathbb{N}}$ be a positive sequence. Assume, that $\lim_{n \to \infty} a_n = \infty$. $\forall\ \zeta > 0, \exists\ n=n(\zeta) \geq 1: a_n < \zeta.$ From 1. we know, that $\forall\ C > 0, \exists\ N = N(C) \geq 1: a_n \geq C, \forall\ n \geq N.$ The difference $N(C) - n(\zeta)$ can be interpreted as the 'recovery time', i.e. the time the sequence needs from being arbitrarily small to become larger than an arbitrary positive constant $C$  for the rest of its existence. Question: Can somebody think of an example where $\forall\ C > 0: N(C) - n(\zeta)$ is arbitrarily large? (Is this even possible?)",,"['calculus', 'real-analysis', 'sequences-and-series']"
99,Show $\sum_{i=0}^\infty {k+i \choose k}a^i=\frac1{(1-a)^{k+1}}.$,Show,\sum_{i=0}^\infty {k+i \choose k}a^i=\frac1{(1-a)^{k+1}}.,"I need to show that for every $k\in\mathbb{N}, |a|<1,$ $$\sum_{i=0}^\infty {k+i \choose k}a^i=\frac1{(1-a)^{k+1}}.$$  It's technically a power series in $a$ but no approach in that direction proved fruitful. My only ideas are that $\sum_{i=0}^\infty i^{k+1}a^i=\frac{p(a)}{(1-a)^{k+1}}$ for some polynomial $p$, and that $${k+i \choose k}=\frac{(i+1)\cdots(i+k)}{1\cdots k}.$$","I need to show that for every $k\in\mathbb{N}, |a|<1,$ $$\sum_{i=0}^\infty {k+i \choose k}a^i=\frac1{(1-a)^{k+1}}.$$  It's technically a power series in $a$ but no approach in that direction proved fruitful. My only ideas are that $\sum_{i=0}^\infty i^{k+1}a^i=\frac{p(a)}{(1-a)^{k+1}}$ for some polynomial $p$, and that $${k+i \choose k}=\frac{(i+1)\cdots(i+k)}{1\cdots k}.$$",,"['sequences-and-series', 'convergence-divergence', 'power-series', 'binomial-coefficients']"
