,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Evaluate $\iint_D\sin(xy)dA$ where $D$ is bounded by $y=\frac 1x, y=\frac2x, y=x, y=2x$ in the first quadrant.",Evaluate  where  is bounded by  in the first quadrant.,"\iint_D\sin(xy)dA D y=\frac 1x, y=\frac2x, y=x, y=2x","Evaluate $\iint_D\sin(xy)dA$ where $D$ is bounded by $y=\frac 1x, y=\frac2x, y=x, y=2x$ in the first quadrant. By subbing numbers into the equation, I see that $1\leq x\leq 2, 1\leq y\leq 2.$ Without solving the equation, can someone tell me if this is correct? The final answer I got was $-\frac14\sin(4)+\frac 54\sin(2)-\sin(1)$","Evaluate $\iint_D\sin(xy)dA$ where $D$ is bounded by $y=\frac 1x, y=\frac2x, y=x, y=2x$ in the first quadrant. By subbing numbers into the equation, I see that $1\leq x\leq 2, 1\leq y\leq 2.$ Without solving the equation, can someone tell me if this is correct? The final answer I got was $-\frac14\sin(4)+\frac 54\sin(2)-\sin(1)$",,"['integration', 'multivariable-calculus']"
1,Exercise with application of inverse function theorem,Exercise with application of inverse function theorem,,"Let $F:\mathbb R^2 \to \mathbb R^2$ be a function of class $C^1$ such that $F(3t^3+2,e^{t^2})=(3,6)$ for all $t \in \mathbb R$. Prove that $DF(2,1)$ is not invertible. ($DF(2,1)$ is the jacobian matrix) My attempt at a solution: I've tried to solve this problem applying the inverse function theorem, i.e, suppose $DF(2,1)$ is invertible, since $f$ is $C^1$, we are under the hypothesis of the inverse function theorem: There exist $U$ neighbourhood of $(2,1)$ and $V$ neighbourhood of $f(2,1)$ such that $F:U \to V$ is bijective, the inverse $F^{-1}:V \to U$ is of class $C^1$ and $DF^{-1}(x,y)={DF(x,y)}^{-1}$. I am trying to get to an absurd and I think that, given the fact that $F(3t^3+2,e^{t^2})=(3,6)$ for all $t \in \mathbb R$, it clearly fails injectivity here. I am not so sure how to show that $F$ is not injective, I could define $h:\mathbb R \to \mathbb R^2$ as $h(t)=(3t^3+2,e^{t^2})$. If I could find $t_1$ and $t_2$ such that $h(t_1), h(t_2) \in U$, then, I would be done, because $F(h(t_1))=F(h(t_2))$. I don't know how to pick $t_1, t_2$ ""appropiately"". I would appreciate if someone could tell me if my idea is correct and give me some help with this last part.","Let $F:\mathbb R^2 \to \mathbb R^2$ be a function of class $C^1$ such that $F(3t^3+2,e^{t^2})=(3,6)$ for all $t \in \mathbb R$. Prove that $DF(2,1)$ is not invertible. ($DF(2,1)$ is the jacobian matrix) My attempt at a solution: I've tried to solve this problem applying the inverse function theorem, i.e, suppose $DF(2,1)$ is invertible, since $f$ is $C^1$, we are under the hypothesis of the inverse function theorem: There exist $U$ neighbourhood of $(2,1)$ and $V$ neighbourhood of $f(2,1)$ such that $F:U \to V$ is bijective, the inverse $F^{-1}:V \to U$ is of class $C^1$ and $DF^{-1}(x,y)={DF(x,y)}^{-1}$. I am trying to get to an absurd and I think that, given the fact that $F(3t^3+2,e^{t^2})=(3,6)$ for all $t \in \mathbb R$, it clearly fails injectivity here. I am not so sure how to show that $F$ is not injective, I could define $h:\mathbb R \to \mathbb R^2$ as $h(t)=(3t^3+2,e^{t^2})$. If I could find $t_1$ and $t_2$ such that $h(t_1), h(t_2) \in U$, then, I would be done, because $F(h(t_1))=F(h(t_2))$. I don't know how to pick $t_1, t_2$ ""appropiately"". I would appreciate if someone could tell me if my idea is correct and give me some help with this last part.",,['multivariable-calculus']
2,PDE using Fourier Transform,PDE using Fourier Transform,,"Using the Fourier Transform, solve: $u_t=u_{xx}+\alpha u$ with $\alpha>0$, for $x \in \mathbb{R}, t>0$ with initial data $u(x,0)=f(x)$, with $f$ continuous in $\mathbb{R}$ Apllying Fourier transform in equation and initial data, we obtain $\partial_t^2 \hat u(\xi)=-\xi^2\hat u + \alpha \hat u $ $\hat u (\xi,0)=\hat f(\xi)$ Solving, we obtain $\hat u(\xi,t)=\hat f(\xi)e^{(\alpha-\xi^2)t}$. To get $u$, we have to apply the inverse Fourier transform, but I'm not getting no useful result.","Using the Fourier Transform, solve: $u_t=u_{xx}+\alpha u$ with $\alpha>0$, for $x \in \mathbb{R}, t>0$ with initial data $u(x,0)=f(x)$, with $f$ continuous in $\mathbb{R}$ Apllying Fourier transform in equation and initial data, we obtain $\partial_t^2 \hat u(\xi)=-\xi^2\hat u + \alpha \hat u $ $\hat u (\xi,0)=\hat f(\xi)$ Solving, we obtain $\hat u(\xi,t)=\hat f(\xi)e^{(\alpha-\xi^2)t}$. To get $u$, we have to apply the inverse Fourier transform, but I'm not getting no useful result.",,"['multivariable-calculus', 'partial-differential-equations']"
3,Show $\int_{\mathbb{R}^n}\Delta_x \Phi(x-y)f(y)dy = \int_{\mathbb{R}^n}\Delta_y \Phi(x-y)f(y)dy.$,Show,\int_{\mathbb{R}^n}\Delta_x \Phi(x-y)f(y)dy = \int_{\mathbb{R}^n}\Delta_y \Phi(x-y)f(y)dy.,I read in an article about Laplace's equation that $$-\int_{\mathbb{R}^n}\Delta_x \Phi(x-y)f(y)dy = -\int_{\mathbb{R}^n}\Delta_y \Phi(x-y)f(y)dy.$$ Could someone explain to me why this is? I understand that one can move the differentiation from one factor of the convolution to the other...,I read in an article about Laplace's equation that $$-\int_{\mathbb{R}^n}\Delta_x \Phi(x-y)f(y)dy = -\int_{\mathbb{R}^n}\Delta_y \Phi(x-y)f(y)dy.$$ Could someone explain to me why this is? I understand that one can move the differentiation from one factor of the convolution to the other...,,"['multivariable-calculus', 'partial-differential-equations', 'convolution', 'potential-theory']"
4,Is a continuously differentiable function convex if all its partial second derivatives are non-negative?,Is a continuously differentiable function convex if all its partial second derivatives are non-negative?,,I'm having trouble understanding the relevant Wikipedia article which begins with a convex set $X$ and then uses functions of single variables for succeeding examples; the MathWorld article seems to be concerned only with functions of a single variable. I would specifically enjoy seeing a proof that is relatively easy to follow.,I'm having trouble understanding the relevant Wikipedia article which begins with a convex set $X$ and then uses functions of single variables for succeeding examples; the MathWorld article seems to be concerned only with functions of a single variable. I would specifically enjoy seeing a proof that is relatively easy to follow.,,"['analysis', 'multivariable-calculus', 'convex-analysis']"
5,"How can I better understand manipulating ""operators"" in mathematical relations?","How can I better understand manipulating ""operators"" in mathematical relations?",,"Sometimes, (especially in physics), it's common to see mathematical relations manipulated and/or derived by separating ""operators"" from the things they ""act on."" I can usually keep up with and follow derivations when reading along in the book, but it bothers me that I don't really understand how it's ""justified"" to do that. A classic example would be: $$ \bigtriangledown = \left<\frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z}\right>$$ We can ""apply"" the operator in different ways, and I can see intuitively how it works - it appears that ""multiplying"" the operator by a ""thing"" is what ""applies"". This is how we can write: $$ \bigtriangledown \cdot F = \frac{\partial U}{\partial x} + \frac{\partial V}{\partial y} + \frac{\partial W}{\partial z}$$ if $$ F = U\hat{x} + V\hat{y} + W\hat{z}$$ And similarly with $\bigtriangledown \times$ to define the curl. But what exactly are we allowed to do with operators and what are we not allowed to do? Is there a name for this kind of treatment? What ""are"" operators and what rules do they obey? For example, it seems obvious that the ""square root"" of an operator wouldn't make any sense. Furthermore, it seems to be a given that ""squaring"" a derivative operator turns it into a ""second derivative"" operator. How can I learn more about this?","Sometimes, (especially in physics), it's common to see mathematical relations manipulated and/or derived by separating ""operators"" from the things they ""act on."" I can usually keep up with and follow derivations when reading along in the book, but it bothers me that I don't really understand how it's ""justified"" to do that. A classic example would be: $$ \bigtriangledown = \left<\frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z}\right>$$ We can ""apply"" the operator in different ways, and I can see intuitively how it works - it appears that ""multiplying"" the operator by a ""thing"" is what ""applies"". This is how we can write: $$ \bigtriangledown \cdot F = \frac{\partial U}{\partial x} + \frac{\partial V}{\partial y} + \frac{\partial W}{\partial z}$$ if $$ F = U\hat{x} + V\hat{y} + W\hat{z}$$ And similarly with $\bigtriangledown \times$ to define the curl. But what exactly are we allowed to do with operators and what are we not allowed to do? Is there a name for this kind of treatment? What ""are"" operators and what rules do they obey? For example, it seems obvious that the ""square root"" of an operator wouldn't make any sense. Furthermore, it seems to be a given that ""squaring"" a derivative operator turns it into a ""second derivative"" operator. How can I learn more about this?",,"['multivariable-calculus', 'operator-theory', 'vector-analysis']"
6,Making a multivariable Function continuous,Making a multivariable Function continuous,,"This function $$f(x,y)=\frac{e^{xy}-\cos (x)+\sin(xy)}{x}$$ can be made continous for $f(0,y)$ by defining $$f(0, y) = 2y .$$ My question is: how can i get to this conclusion (""$2y$ must be it"") on my own? I have tried using limits, substituting $u=xy$,... or polar, but no luck. Is there a list somewhere of things to try? Any help very appreciated.","This function $$f(x,y)=\frac{e^{xy}-\cos (x)+\sin(xy)}{x}$$ can be made continous for $f(0,y)$ by defining $$f(0, y) = 2y .$$ My question is: how can i get to this conclusion (""$2y$ must be it"") on my own? I have tried using limits, substituting $u=xy$,... or polar, but no luck. Is there a list somewhere of things to try? Any help very appreciated.",,"['limits', 'multivariable-calculus', 'continuity']"
7,approaching the border,approaching the border,,"Let $U\subset \mathbb{R}^m$ $(U\neq \mathbb{R}^m)$  open and connected. Given $b \in \partial{U}$ there is some way $\varphi:[0,1]\rightarrow \mathbb{R}^m$ with finite length such that $\varphi(t) \in U$ for all $0\leq t<1$ and $\varphi(1)=b$ ? Any suggestion is welcome.","Let $U\subset \mathbb{R}^m$ $(U\neq \mathbb{R}^m)$  open and connected. Given $b \in \partial{U}$ there is some way $\varphi:[0,1]\rightarrow \mathbb{R}^m$ with finite length such that $\varphi(t) \in U$ for all $0\leq t<1$ and $\varphi(1)=b$ ? Any suggestion is welcome.",,"['real-analysis', 'general-topology', 'analysis', 'multivariable-calculus', 'algebraic-topology']"
8,Can lines that are not parallel or perpendicular to each other fill up $\mathbb{R}^3$?,Can lines that are not parallel or perpendicular to each other fill up ?,\mathbb{R}^3,"As title says, can a union of lines that are not paralell or perpendicular to each other be $\mathbb{R}^3$? The number of lines does not matter. It may be countable or uncountable.","As title says, can a union of lines that are not paralell or perpendicular to each other be $\mathbb{R}^3$? The number of lines does not matter. It may be countable or uncountable.",,['multivariable-calculus']
9,Rotating a curve $z = f(x)$ about the $z$-axis,Rotating a curve  about the -axis,z = f(x) z,"Let $z = f(x)$ be a function from $[0, \infty)$ into $\mathbb{R}$ living in the $xz$-plane, for example. Create a surface $z = g(x,y)$ by rotating the graph of $f$ about the $z$-axis. In other words, the surface is such that $g(x,mx) = f(x)$ for all $m \in \mathbb{R}$ and all $x \in [0, \infty)$. Is there a general method for defining $g$ explicitly given $f$?","Let $z = f(x)$ be a function from $[0, \infty)$ into $\mathbb{R}$ living in the $xz$-plane, for example. Create a surface $z = g(x,y)$ by rotating the graph of $f$ about the $z$-axis. In other words, the surface is such that $g(x,mx) = f(x)$ for all $m \in \mathbb{R}$ and all $x \in [0, \infty)$. Is there a general method for defining $g$ explicitly given $f$?",,"['multivariable-calculus', 'graphing-functions']"
10,"How does one prove that if function's partial derivative respect to every variable is zero, function is constant?","How does one prove that if function's partial derivative respect to every variable is zero, function is constant?",,"How does one prove that if function's partial derivative respect to every variable that the function defines over is zero function is constant function? I just noticed it, but I cannot prove it.","How does one prove that if function's partial derivative respect to every variable that the function defines over is zero function is constant function? I just noticed it, but I cannot prove it.",,"['multivariable-calculus', 'partial-derivative']"
11,showing / proving curl identity $\nabla \times \left( \frac{1}{r^2} \hat r \right) = 0$,showing / proving curl identity,\nabla \times \left( \frac{1}{r^2} \hat r \right) = 0,"OK, I have to show the following: $$ \nabla \times \left( \frac{1}{r^2}  \hat r \right) = 0$$ This should be pretty easy, but I wanted to be sure I was doing this correctly. I set up the matrix: $$         \begin{bmatrix}         \hat r & \hat \theta & \hat \phi \\         \frac{\partial}{\partial r}  & \frac{\partial}{\partial \theta} & \frac{\partial}{\partial \phi} \\         \frac{1}{r^2} & 0 & 0 \\         \end{bmatrix} =\left(\frac{\partial}{\partial \theta}(0)-\frac{\partial}{\partial \phi}(0)\right)\hat r-\left(\frac{\partial}{\partial r}(0)-\frac{\partial}{\partial \phi}(\frac{1}{r^2})\right)\hat \theta-\left(\frac{\partial}{\partial r}(0)-\frac{\partial}{\partial \theta}(\frac{1}{r^2})\right)\hat \phi$$ which leaves me with 0 because $\frac{\partial}{\partial \theta}(\frac{1}{r^2})$ and $\frac{\partial}{\partial \phi}(\frac{1}{r^2})$ are both zero. This is correct, yes? I know this is ridiculously simple a problem but I want to make sure I did not forget everything I learned last semester. (Also, I was curious if there is a more rigorous proof, tho this is for a phys and not a math class). Edit: BTW this is in spherical (I think -- the assignment uses $\hat r$ so I am going with that).","OK, I have to show the following: $$ \nabla \times \left( \frac{1}{r^2}  \hat r \right) = 0$$ This should be pretty easy, but I wanted to be sure I was doing this correctly. I set up the matrix: $$         \begin{bmatrix}         \hat r & \hat \theta & \hat \phi \\         \frac{\partial}{\partial r}  & \frac{\partial}{\partial \theta} & \frac{\partial}{\partial \phi} \\         \frac{1}{r^2} & 0 & 0 \\         \end{bmatrix} =\left(\frac{\partial}{\partial \theta}(0)-\frac{\partial}{\partial \phi}(0)\right)\hat r-\left(\frac{\partial}{\partial r}(0)-\frac{\partial}{\partial \phi}(\frac{1}{r^2})\right)\hat \theta-\left(\frac{\partial}{\partial r}(0)-\frac{\partial}{\partial \theta}(\frac{1}{r^2})\right)\hat \phi$$ which leaves me with 0 because $\frac{\partial}{\partial \theta}(\frac{1}{r^2})$ and $\frac{\partial}{\partial \phi}(\frac{1}{r^2})$ are both zero. This is correct, yes? I know this is ridiculously simple a problem but I want to make sure I did not forget everything I learned last semester. (Also, I was curious if there is a more rigorous proof, tho this is for a phys and not a math class). Edit: BTW this is in spherical (I think -- the assignment uses $\hat r$ so I am going with that).",,"['multivariable-calculus', 'cross-product', 'vector-analysis']"
12,Why $\vec{r}$ is commonly use for vector equation?,Why  is commonly use for vector equation?,\vec{r},"I'm wondering why $\vec{r}$ is commonly use in mathematics (vector calculus, line integrals) and physics for denote the vector equation. Edit/Added clarification : I'm wondering why the letter $r$ is commonly use in mathematics (vector calculus, line integrals) and physics for denote the vector equation.","I'm wondering why $\vec{r}$ is commonly use in mathematics (vector calculus, line integrals) and physics for denote the vector equation. Edit/Added clarification : I'm wondering why the letter $r$ is commonly use in mathematics (vector calculus, line integrals) and physics for denote the vector equation.",,"['multivariable-calculus', 'notation', 'plane-curves']"
13,"Exam question: Multivariable calculus, differentiation","Exam question: Multivariable calculus, differentiation",,"I've decided to finish my education through completing my last exam (I've been working for 5 years). The exam is in multivariable calculus and I took the classes 6 years ago so I am very rusty. Will ask a bunch of questions over the following weeks and I love you all for helping me. Q: Suppose that $f(x,y)$ fulfills the Laplace equation $$\frac{\partial^2f}{\partial x^2}+\frac{\partial^2f}{\partial y^2} = 0$$ Show that $g(x,y) = f(2x+y,x-2y)$ also fulfills the equation. I understand everything about the teachers answer except one early part. A: $$u=2x+y\\\\ v=x-2y$$ The chain rule give: $$\frac{\partial g}{\partial x}=\frac{\partial f}{\partial u}\frac{\partial u}{\partial x}+\frac{\partial f}{\partial v}\frac{\partial v}{\partial x} = 2\frac{\partial f}{\partial u}+\frac{\partial f}{\partial v}$$ $$\frac{\partial g}{\partial y}=\frac{\partial f}{\partial u}\frac{\partial u}{\partial y}+\frac{\partial f}{\partial v}\frac{\partial v}{\partial y} = \frac{\partial f}{\partial u}-2\frac{\partial f}{\partial v}$$ ... My question is: How is he simplifying that last step, where he get 2.. + .. and .. - 2 ..?","I've decided to finish my education through completing my last exam (I've been working for 5 years). The exam is in multivariable calculus and I took the classes 6 years ago so I am very rusty. Will ask a bunch of questions over the following weeks and I love you all for helping me. Q: Suppose that $f(x,y)$ fulfills the Laplace equation $$\frac{\partial^2f}{\partial x^2}+\frac{\partial^2f}{\partial y^2} = 0$$ Show that $g(x,y) = f(2x+y,x-2y)$ also fulfills the equation. I understand everything about the teachers answer except one early part. A: $$u=2x+y\\\\ v=x-2y$$ The chain rule give: $$\frac{\partial g}{\partial x}=\frac{\partial f}{\partial u}\frac{\partial u}{\partial x}+\frac{\partial f}{\partial v}\frac{\partial v}{\partial x} = 2\frac{\partial f}{\partial u}+\frac{\partial f}{\partial v}$$ $$\frac{\partial g}{\partial y}=\frac{\partial f}{\partial u}\frac{\partial u}{\partial y}+\frac{\partial f}{\partial v}\frac{\partial v}{\partial y} = \frac{\partial f}{\partial u}-2\frac{\partial f}{\partial v}$$ ... My question is: How is he simplifying that last step, where he get 2.. + .. and .. - 2 ..?",,"['multivariable-calculus', 'derivatives']"
14,How do I rotate a given point on $\mathbb{S}^n$ so that I send it to the South Pole,How do I rotate a given point on  so that I send it to the South Pole,\mathbb{S}^n,"This seems pretty trivial but I'm not sure what to do.  My coordinates are Cartesian, and I want to send point the $(x_1,...,x_{n-1},x_n)$ to point $(0,...,0,-1)$ so that all the other points are also rotated properly.","This seems pretty trivial but I'm not sure what to do.  My coordinates are Cartesian, and I want to send point the $(x_1,...,x_{n-1},x_n)$ to point $(0,...,0,-1)$ so that all the other points are also rotated properly.",,"['matrices', 'multivariable-calculus', 'rotations']"
15,Derive $\frac1n \|x\|_p^p \leq \|x\| \leq n^{p/2}\|x\|_p^p$ from Holder's inequality?,Derive  from Holder's inequality?,\frac1n \|x\|_p^p \leq \|x\| \leq n^{p/2}\|x\|_p^p,"Given a vector $x = (x_1, \dotsc, x_n)\in \mathbb{C}^n$, I wanted to compare $|x_1|^p + \dotsb + |x_n|^p$ to $\|x\|^p$. I discovered that if $m=\max_i|x_i|$, we have $$m^p \leq \|x\|^p \leq n^{p/2}m^p$$ and $$m^p \leq |x_1|^p + \dotsb + |x_n|^p \leq nm^p,$$ which gives us $$\frac1n (|x_1|^p + \dotsb + |x_n|^p) \leq \|x\|^p \leq n^{p/2}(|x_1|^p + \dotsb + |x_n|^p).$$ Then I noticed I could just express this as $$\frac1n \|x\|_p^p \leq \|x\|^p \leq n^{p/2}\|x\|_p^p.$$ Could I have derived this easily from Holder's inequality in a way I'm missing?","Given a vector $x = (x_1, \dotsc, x_n)\in \mathbb{C}^n$, I wanted to compare $|x_1|^p + \dotsb + |x_n|^p$ to $\|x\|^p$. I discovered that if $m=\max_i|x_i|$, we have $$m^p \leq \|x\|^p \leq n^{p/2}m^p$$ and $$m^p \leq |x_1|^p + \dotsb + |x_n|^p \leq nm^p,$$ which gives us $$\frac1n (|x_1|^p + \dotsb + |x_n|^p) \leq \|x\|^p \leq n^{p/2}(|x_1|^p + \dotsb + |x_n|^p).$$ Then I noticed I could just express this as $$\frac1n \|x\|_p^p \leq \|x\|^p \leq n^{p/2}\|x\|_p^p.$$ Could I have derived this easily from Holder's inequality in a way I'm missing?",,"['calculus', 'linear-algebra', 'measure-theory', 'multivariable-calculus', 'normed-spaces']"
16,Finding Curvature,Finding Curvature,,"A curve is described by the vector $f(t)=(3e^t, 4e^t)$. I found that the curvature is equal to $0$. I am confused on how to explain geometrically why the curvature is zero.","A curve is described by the vector $f(t)=(3e^t, 4e^t)$. I found that the curvature is equal to $0$. I am confused on how to explain geometrically why the curvature is zero.",,"['differential-geometry', 'multivariable-calculus', 'curvature']"
17,What justifies assuming that a level surface contains a differentiable curve?,What justifies assuming that a level surface contains a differentiable curve?,,"My textbook's proof that the Lagrange multiplier method is valid begins: Let $X(t)$ be a differentiable curve on the surface $S$ passing through $P$ Where $S$ is the level surface defining the constraint, and $P$ is an extremum of the function that we're seeking to optimize. But how do we know that such a curve exists? $S$ is specifically defined as the set of points in the (open) domain of the continuously differentiable function $g$ with $g(X) = 0$ but $\operatorname{grad}g(X)\ne0$. The function $f$ that we're seeking to optimize is assumed to be continuously differentiable and defined on the same open domain as $g$, and $P$ is an extremum of $f$ on $S$.","My textbook's proof that the Lagrange multiplier method is valid begins: Let $X(t)$ be a differentiable curve on the surface $S$ passing through $P$ Where $S$ is the level surface defining the constraint, and $P$ is an extremum of the function that we're seeking to optimize. But how do we know that such a curve exists? $S$ is specifically defined as the set of points in the (open) domain of the continuously differentiable function $g$ with $g(X) = 0$ but $\operatorname{grad}g(X)\ne0$. The function $f$ that we're seeking to optimize is assumed to be continuously differentiable and defined on the same open domain as $g$, and $P$ is an extremum of $f$ on $S$.",,"['multivariable-calculus', 'lagrange-multiplier']"
18,How to show $f$ is homogeneous of degree $p$ on an open $S$.,How to show  is homogeneous of degree  on an open .,f p S,"Let $f:S\subseteq \Bbb R^n\to\Bbb R$. One can prove that if $f(\lambda {\bf x})=\lambda^pf({\bf x})$ for each ${\bf x}\in S$ such that $\lambda {\bf x}\in S$, then ${\bf x}\cdot \nabla f({\bf x})=pf({\bf x})$. The proof is not complicated: one defines the function $\varphi(\lambda)=f(\lambda {\bf x})$ for a fixed ${\bf x}$ and evaluates $\varphi'(1)$ in two different ways. I'd like to get a hint to prove the converse: if ${\bf x}\cdot \nabla f({\bf x})=pf({\bf x})$ for each ${\bf x}\in S$, $S$ open, then $f$ is homogeneous of degree $p$ in $S$. This problem is on Apostol's Mathematical Analysis.","Let $f:S\subseteq \Bbb R^n\to\Bbb R$. One can prove that if $f(\lambda {\bf x})=\lambda^pf({\bf x})$ for each ${\bf x}\in S$ such that $\lambda {\bf x}\in S$, then ${\bf x}\cdot \nabla f({\bf x})=pf({\bf x})$. The proof is not complicated: one defines the function $\varphi(\lambda)=f(\lambda {\bf x})$ for a fixed ${\bf x}$ and evaluates $\varphi'(1)$ in two different ways. I'd like to get a hint to prove the converse: if ${\bf x}\cdot \nabla f({\bf x})=pf({\bf x})$ for each ${\bf x}\in S$, $S$ open, then $f$ is homogeneous of degree $p$ in $S$. This problem is on Apostol's Mathematical Analysis.",,['multivariable-calculus']
19,Taking the derivative of an Integral,Taking the derivative of an Integral,,"I would like to express the derivative of an integral in as elegant a form as possible. However, I am struggling at the moment. I would like to find the derivative $f'(y)$ of the function $f(y) = \int_{h(y)}^{g(y)}u(x,y)\,\mathrm{d}x$ in terms of only the functions $g$, $h$ and $u$ which can be assumed to be sufficiently well behaved.","I would like to express the derivative of an integral in as elegant a form as possible. However, I am struggling at the moment. I would like to find the derivative $f'(y)$ of the function $f(y) = \int_{h(y)}^{g(y)}u(x,y)\,\mathrm{d}x$ in terms of only the functions $g$, $h$ and $u$ which can be assumed to be sufficiently well behaved.",,"['calculus', 'integration', 'multivariable-calculus', 'derivatives', 'definite-integrals']"
20,Gauss Theorem example,Gauss Theorem example,,"Verify the Gauss theorem for the vector field $F(x)=\frac{x }{\|x\|},$ where $x \in W \subset \mathbb{R}^3$ and $$W=\left\{(x,y,z) \in \mathbb{R}^3 \left/ a^2\right.\leqslant x^2 + y^2 + z^2 \leqslant b^2\right\}$$ Thanks you very much!","Verify the Gauss theorem for the vector field $F(x)=\frac{x }{\|x\|},$ where $x \in W \subset \mathbb{R}^3$ and $$W=\left\{(x,y,z) \in \mathbb{R}^3 \left/ a^2\right.\leqslant x^2 + y^2 + z^2 \leqslant b^2\right\}$$ Thanks you very much!",,"['multivariable-calculus', 'vector-analysis', 'spherical-geometry']"
21,"What is the definition of curl of $\mathbf{F}(x_1, x_2) = ( F_1 (x_1,x_2) F_2(x_1,x_2))$ in $\mathbb{R}^2?$",What is the definition of curl of  in,"\mathbf{F}(x_1, x_2) = ( F_1 (x_1,x_2) F_2(x_1,x_2)) \mathbb{R}^2?","What is the definition of curl of $\mathbf{F}(x_1, x_2) = ( F_1 (x_1,x_2) F_2(x_1,x_2))$  in $\mathbb{R}^2?$ Most textbook says only of vector fields in the space $\mathbb{R}^3$...","What is the definition of curl of $\mathbf{F}(x_1, x_2) = ( F_1 (x_1,x_2) F_2(x_1,x_2))$  in $\mathbb{R}^2?$ Most textbook says only of vector fields in the space $\mathbb{R}^3$...",,['multivariable-calculus']
22,Limits of functions of 3 variables(not to sure what topic is this),Limits of functions of 3 variables(not to sure what topic is this),,"Find the limits or show that they do not exist: $$\lim_{(x,y,z)\to 0} \frac{xy+xz}{x^2+y^2+z^2}$$ Can anyone lend me a hand and teach me how to do this. I am totally at loss at this. :(","Find the limits or show that they do not exist: $$\lim_{(x,y,z)\to 0} \frac{xy+xz}{x^2+y^2+z^2}$$ Can anyone lend me a hand and teach me how to do this. I am totally at loss at this. :(",,"['calculus', 'limits', 'multivariable-calculus']"
23,Is $f$ a differentiable function?,Is  a differentiable function?,f,"Hello everyone I have this problem, Can somebody help me with this? $f:\mathbb{R}^2\rightarrow{}\mathbb{R}$ is defined by: $$f(x,y) = \left \{ \begin{matrix} \ln\left(\displaystyle\frac{x}{y}\right) & \mbox{if } xy\geq{0} \\ 0 & \mbox{if }xy<0\end{matrix}\right. $$ Is $f$ a differentiable function? Thanks for your help :D , have a nice day","Hello everyone I have this problem, Can somebody help me with this? $f:\mathbb{R}^2\rightarrow{}\mathbb{R}$ is defined by: $$f(x,y) = \left \{ \begin{matrix} \ln\left(\displaystyle\frac{x}{y}\right) & \mbox{if } xy\geq{0} \\ 0 & \mbox{if }xy<0\end{matrix}\right. $$ Is $f$ a differentiable function? Thanks for your help :D , have a nice day",,['multivariable-calculus']
24,Vector valued Mean value theorem: Norm for the gradient,Vector valued Mean value theorem: Norm for the gradient,,"The wikipedia article on the vector valued Mean value theorem, says For $f:\mathbb R^n \to \mathbb R^n$, if the gradient is bounded,   $$ \| \nabla f \| \le M, $$   then   $$ \|f(x)-f(y) \| \le M \|x-y\|. $$ What is the norm used for the gradient $\| \nabla f \|$? I tried to look in some other references. There the matrix-norm is mentionned. They gave one example, where I don't understand how to get the bound of $\frac14$ on $\|\nabla f \|$. Define $g:\mathbb R_+^2 \to \mathbb R_+^2$ with $$ g(x,y)=\left( \frac{1}{4+x+y}, \frac{1}{4+x+y} \right), $$ then, entry-wise, $$ \nabla f \le \begin{pmatrix} \frac{1}{16} & \frac{1}{16} \\ \frac{1}{16} & \frac{1}{16} \end{pmatrix}=A, $$ whence $$ \|\nabla f \| \le \|A\|=\frac14. $$ what norm reduces $\|A\|$ to $\frac14$?","The wikipedia article on the vector valued Mean value theorem, says For $f:\mathbb R^n \to \mathbb R^n$, if the gradient is bounded,   $$ \| \nabla f \| \le M, $$   then   $$ \|f(x)-f(y) \| \le M \|x-y\|. $$ What is the norm used for the gradient $\| \nabla f \|$? I tried to look in some other references. There the matrix-norm is mentionned. They gave one example, where I don't understand how to get the bound of $\frac14$ on $\|\nabla f \|$. Define $g:\mathbb R_+^2 \to \mathbb R_+^2$ with $$ g(x,y)=\left( \frac{1}{4+x+y}, \frac{1}{4+x+y} \right), $$ then, entry-wise, $$ \nabla f \le \begin{pmatrix} \frac{1}{16} & \frac{1}{16} \\ \frac{1}{16} & \frac{1}{16} \end{pmatrix}=A, $$ whence $$ \|\nabla f \| \le \|A\|=\frac14. $$ what norm reduces $\|A\|$ to $\frac14$?",,['calculus']
25,Whats the connection between formss and vector fields?,Whats the connection between formss and vector fields?,,I heard someone talking about how vector fields are the kernels of forms. Can someone give me a detailed explanation about how this works? Thanks.,I heard someone talking about how vector fields are the kernels of forms. Can someone give me a detailed explanation about how this works? Thanks.,,"['multivariable-calculus', 'differential-forms']"
26,Derivative of the linear functional given by an inner product form,Derivative of the linear functional given by an inner product form,,"Let $L\colon\mathbb{R}^n\to \mathbb{R}$ such that $L_y(x)=\langle x,y\rangle$ for some inner product, and $DL$ be the derivative of $L$. Then which of the following is/are true? $DL(u)=DL(v)\quad \forall u,v\in\mathbb{R}^n$; $DL(0,\dots,0)=L$; $DL(x)=\|x\|^2\quad \forall x\in\mathbb{R}^n$; $DL(1,\dots,1)=0$. Could any one help me to solve this problem? I have no Idea how to solve it","Let $L\colon\mathbb{R}^n\to \mathbb{R}$ such that $L_y(x)=\langle x,y\rangle$ for some inner product, and $DL$ be the derivative of $L$. Then which of the following is/are true? $DL(u)=DL(v)\quad \forall u,v\in\mathbb{R}^n$; $DL(0,\dots,0)=L$; $DL(x)=\|x\|^2\quad \forall x\in\mathbb{R}^n$; $DL(1,\dots,1)=0$. Could any one help me to solve this problem? I have no Idea how to solve it",,"['real-analysis', 'linear-algebra', 'multivariable-calculus', 'derivatives']"
27,Gradient of sum of products of matrix traces,Gradient of sum of products of matrix traces,,"For a matrix $X \in \Re_{n\times d}$ find the gradient of $\sum_{i,j}[\langle X_{i.},X_{j.} \rangle\operatorname{tr}(X^TA_{ij}X)]$ w.r.t $X$,  where $A_{ij}=(e_i-e_j)(e_i-e_j)^T$ using the basis vectors while $X_{i.}$ denotes the $i$'th row. Do note that, $\langle X_{i.},X_{j.} \rangle$ can be written as $\langle X_{i.},X_{j.} \rangle = \operatorname{Tr}(X^Te_ie_j^TX)$ making the original question a sum of products of trace functions. Hint: The gradient of $\operatorname{tr}(X^TMX)$ w.r.t $X$ for any real matrix $M$ is given by $MX+M^TX$.","For a matrix $X \in \Re_{n\times d}$ find the gradient of $\sum_{i,j}[\langle X_{i.},X_{j.} \rangle\operatorname{tr}(X^TA_{ij}X)]$ w.r.t $X$,  where $A_{ij}=(e_i-e_j)(e_i-e_j)^T$ using the basis vectors while $X_{i.}$ denotes the $i$'th row. Do note that, $\langle X_{i.},X_{j.} \rangle$ can be written as $\langle X_{i.},X_{j.} \rangle = \operatorname{Tr}(X^Te_ie_j^TX)$ making the original question a sum of products of trace functions. Hint: The gradient of $\operatorname{tr}(X^TMX)$ w.r.t $X$ for any real matrix $M$ is given by $MX+M^TX$.",,"['real-analysis', 'analysis', 'multivariable-calculus', 'derivatives', 'trace']"
28,$ \int_{C}^{} \frac{ydx-(x+1)dy}{x^2+y^2+2x+1} $ where $C$ is $ |x|+|y|=4 $,where  is, \int_{C}^{} \frac{ydx-(x+1)dy}{x^2+y^2+2x+1}  C  |x|+|y|=4 ,"Calculate  $$  \int_{C}^{} \frac{ydx-(x+1)dy}{x^2+y^2+2x+1} $$ where C is the curve $$  |x|+|y|=4 $$ counterclock-wise, a full revolution. Answer: $$-2\pi$$ So, I've tried to figure this out for a while now. I've tried Green's formula, that gives me 0 as its answer, which is wrong. I've tried to parametrized it, which gives me nothing useful. Ideas?","Calculate  $$  \int_{C}^{} \frac{ydx-(x+1)dy}{x^2+y^2+2x+1} $$ where C is the curve $$  |x|+|y|=4 $$ counterclock-wise, a full revolution. Answer: $$-2\pi$$ So, I've tried to figure this out for a while now. I've tried Green's formula, that gives me 0 as its answer, which is wrong. I've tried to parametrized it, which gives me nothing useful. Ideas?",,['multivariable-calculus']
29,How can I determine the values of a third point to make all 3 collinear in $\mathbb{R}^3$,How can I determine the values of a third point to make all 3 collinear in,\mathbb{R}^3,"I am given the points $(1,2,3), (2,4,1)$ and $(x,y,2)$ and I am being asked to find some values for $x$ and $y$ such that these 3 points will be collinear in $\mathbb{R}^3$ Most of this topic is covered with videos and tutorials in $\mathbb{R}^2$ and my teacher did not cover this topic at all, and it is not discussed in the book. So far I have found out that the points are said to be collinear when the two shorter distances summed equals the longer distance between two points. I started with the equation $\sqrt{(x-1)^2 + (y-2)^2 + 1} + \sqrt{(5-x)^2 + (3-y)^2 + 1} = \sqrt{21}$ But with two variables and one equation this does not appear to be the correct approach. I also feel it is incorrect as the $\sqrt{21}$ comes from the distance between the two known points, but not necessarily the longest distance as either the first or second point may be the point in-between. I tried writing a short program which is checking for points between the two known points, but it is not returning any results and I would rather not expand the program to find the solution as this technique will not be available on a test of course. This implies that one of the two known points is somewhere in the middle.","I am given the points $(1,2,3), (2,4,1)$ and $(x,y,2)$ and I am being asked to find some values for $x$ and $y$ such that these 3 points will be collinear in $\mathbb{R}^3$ Most of this topic is covered with videos and tutorials in $\mathbb{R}^2$ and my teacher did not cover this topic at all, and it is not discussed in the book. So far I have found out that the points are said to be collinear when the two shorter distances summed equals the longer distance between two points. I started with the equation $\sqrt{(x-1)^2 + (y-2)^2 + 1} + \sqrt{(5-x)^2 + (3-y)^2 + 1} = \sqrt{21}$ But with two variables and one equation this does not appear to be the correct approach. I also feel it is incorrect as the $\sqrt{21}$ comes from the distance between the two known points, but not necessarily the longest distance as either the first or second point may be the point in-between. I tried writing a short program which is checking for points between the two known points, but it is not returning any results and I would rather not expand the program to find the solution as this technique will not be available on a test of course. This implies that one of the two known points is somewhere in the middle.",,"['linear-algebra', 'multivariable-calculus']"
30,Find the volume of the region contained above $z=1$ and below $x^{2}+y^{2}+z^{2}=4$,Find the volume of the region contained above  and below,z=1 x^{2}+y^{2}+z^{2}=4,"Why doesn't this work? Find the volume of the region contained above $z=1$ and below $x^{2}+y^{2}+z^{2}=4$ going to cylindrical this should be easy. $z=(4-r^{2})^{\frac {1}{2}}$ and $z=1$ Clearly $z=1$ yields  $x^{2}+y^{2}=3 \to r=(3)^{\frac {1}{2}}$ $$\int^{2\pi}_{0}\int^{0}_{(3)^{\frac {1}{2}}} [(4-r^{2})^{\frac {1}{2}} -1] \, r\,dr\,d\theta$$ $$\int^{2\pi}_{0}\left[-\frac {1}{3} (4-r^{2})^{\frac {3}{2}}-\frac{r^{2}}{2}\right]\Bigg|^{0}_{(3)^{\frac {1}{2}}} d\theta$$ $$-\frac{8}{3}-\left[-\frac{1}{3}-\frac{3}{2}\right] \to -\frac{16}{6} +\frac{11}{6} \to -\frac{5}{6} \to -\frac{5\pi}{3}$$ I don't get why the bound isn't supposed to be $\int^{0}_{(3)^{\frac {1}{2}}}$ - why is it $\int^{(3)^{\frac {1}{2}}}_{0}?$ Clearly when I start integrating, my radius is root 3 and it reduces to 0?","Why doesn't this work? Find the volume of the region contained above $z=1$ and below $x^{2}+y^{2}+z^{2}=4$ going to cylindrical this should be easy. $z=(4-r^{2})^{\frac {1}{2}}$ and $z=1$ Clearly $z=1$ yields  $x^{2}+y^{2}=3 \to r=(3)^{\frac {1}{2}}$ $$\int^{2\pi}_{0}\int^{0}_{(3)^{\frac {1}{2}}} [(4-r^{2})^{\frac {1}{2}} -1] \, r\,dr\,d\theta$$ $$\int^{2\pi}_{0}\left[-\frac {1}{3} (4-r^{2})^{\frac {3}{2}}-\frac{r^{2}}{2}\right]\Bigg|^{0}_{(3)^{\frac {1}{2}}} d\theta$$ $$-\frac{8}{3}-\left[-\frac{1}{3}-\frac{3}{2}\right] \to -\frac{16}{6} +\frac{11}{6} \to -\frac{5}{6} \to -\frac{5\pi}{3}$$ I don't get why the bound isn't supposed to be $\int^{0}_{(3)^{\frac {1}{2}}}$ - why is it $\int^{(3)^{\frac {1}{2}}}_{0}?$ Clearly when I start integrating, my radius is root 3 and it reduces to 0?",,"['integration', 'multivariable-calculus']"
31,Function $T = x^2 + 2y^2 + 2z^2$ from $\mathbb{R}^3 \to \mathbb R$,Function  from,T = x^2 + 2y^2 + 2z^2 \mathbb{R}^3 \to \mathbb R,"The function $T : \mathbb{R}^3 \rightarrow \mathbb{R}$ gives the temperature (in degrees) at each point in space. Suppose a particle is at the point $p = (1, 1, 1)$. $$T = x^2 + 2y^2 + 2z^2$$ In which direction should the particle move to get the most rapid decrease in temperature? Call this direction $u$. How far should the particle move away from the point $p$ in the direction of $u$ to get a decrease of $1.2$ degrees?","The function $T : \mathbb{R}^3 \rightarrow \mathbb{R}$ gives the temperature (in degrees) at each point in space. Suppose a particle is at the point $p = (1, 1, 1)$. $$T = x^2 + 2y^2 + 2z^2$$ In which direction should the particle move to get the most rapid decrease in temperature? Call this direction $u$. How far should the particle move away from the point $p$ in the direction of $u$ to get a decrease of $1.2$ degrees?",,"['calculus', 'multivariable-calculus', 'partial-derivative']"
32,"Find $\iint xy(x^2 + y^2)^{1/2} \, \mathrm dA$",Find,"\iint xy(x^2 + y^2)^{1/2} \, \mathrm dA","$$\iint xy(x^2 + y^2)^{1/2}\,  \mathrm dA$$ where the region is square $[0,1] \times [0,1]$ removing its intersection with the circle of radius 1 at origin. i got $\displaystyle{\frac{2^{7/2}-7}{30}}$ as my final answer? Anyone disagree?","$$\iint xy(x^2 + y^2)^{1/2}\,  \mathrm dA$$ where the region is square $[0,1] \times [0,1]$ removing its intersection with the circle of radius 1 at origin. i got $\displaystyle{\frac{2^{7/2}-7}{30}}$ as my final answer? Anyone disagree?",,"['calculus', 'multivariable-calculus']"
33,Show vector (p-q) is orthogonal to the curve at q,Show vector (p-q) is orthogonal to the curve at q,,"Let $f:\mathbb R \to \mathbb R^n$ be a differentiable mapping with $f'(t) \neq 0$ for all $t$ in $\mathbb R$. Let $p$ be a fixed point not on the image curve of $f$. If $q = f(t_0)$ is the point of the curve closest to $p$, that is, $|p-q | \leq |p-f(t)|$ for all $t$ in $\mathbb R$, show that vector $(p-q)$ is orthogonal to the curve at $q$. Hint: Differentiate the function $M(t) = |p-f(t)|^2$ This one was supposed to be the easiest problem on the problem set, but for some reason I cannot come up with an answer... I did the rest of the problems... Any help is much appreciated.","Let $f:\mathbb R \to \mathbb R^n$ be a differentiable mapping with $f'(t) \neq 0$ for all $t$ in $\mathbb R$. Let $p$ be a fixed point not on the image curve of $f$. If $q = f(t_0)$ is the point of the curve closest to $p$, that is, $|p-q | \leq |p-f(t)|$ for all $t$ in $\mathbb R$, show that vector $(p-q)$ is orthogonal to the curve at $q$. Hint: Differentiate the function $M(t) = |p-f(t)|^2$ This one was supposed to be the easiest problem on the problem set, but for some reason I cannot come up with an answer... I did the rest of the problems... Any help is much appreciated.",,"['calculus', 'real-analysis', 'analysis', 'multivariable-calculus']"
34,"Equation of the tangent plane to the surface $z=x^2+2y^3$ at the point $(1,1,3)$",Equation of the tangent plane to the surface  at the point,"z=x^2+2y^3 (1,1,3)","Find the equation of the tangent plane to the surface $z=x^2+2y^3$ at the point $(1,1,3)$. I think that it is $z=2x+6y-5$. Is that right?","Find the equation of the tangent plane to the surface $z=x^2+2y^3$ at the point $(1,1,3)$. I think that it is $z=2x+6y-5$. Is that right?",,['multivariable-calculus']
35,Really Stuck on Partial derivatives question,Really Stuck on Partial derivatives question,,"Ok so im really stuck on a question. It goes:  Consider $$u(x,y) = xy \frac {x^2-y^2}{x^2+y^2} $$ for $(x,y)$ $ \neq $ $(0,0)$ and $u(0,0) = 0$. calculate $\frac{\partial u} {\partial x} (x,y)$ and $\frac{\partial u} {\partial y} (x,y)$ for all $ (x,y) \in \Bbb R^2.  $ show that $ \frac {\partial^2 u} {\partial x \partial y} (0,0) \neq \frac {\partial^2 u} {\partial y \partial x} (0,0)  $. Check, using polar coordinates, that $ \frac {\partial u}{\partial x} and \frac {\partial u}{\partial y} $ are continuous at $(0,0)$ Any help really appreciated. Cheers","Ok so im really stuck on a question. It goes:  Consider $$u(x,y) = xy \frac {x^2-y^2}{x^2+y^2} $$ for $(x,y)$ $ \neq $ $(0,0)$ and $u(0,0) = 0$. calculate $\frac{\partial u} {\partial x} (x,y)$ and $\frac{\partial u} {\partial y} (x,y)$ for all $ (x,y) \in \Bbb R^2.  $ show that $ \frac {\partial^2 u} {\partial x \partial y} (0,0) \neq \frac {\partial^2 u} {\partial y \partial x} (0,0)  $. Check, using polar coordinates, that $ \frac {\partial u}{\partial x} and \frac {\partial u}{\partial y} $ are continuous at $(0,0)$ Any help really appreciated. Cheers",,"['multivariable-calculus', 'polar-coordinates', 'partial-derivative']"
36,Is the space of bounded functions with the Supremum norm a Banach Algebra,Is the space of bounded functions with the Supremum norm a Banach Algebra,,"X is an arbitrary , non empty set, B(X) the set of bounded functions $f:X\rightarrow \mathbb{R}$ and $||f||_\infty = \sup_{x\in X }|f(x)|$. Is $(B(X),||.||_\infty )$ a Banach Algebra? My attempt at showing that this is true: Definition of a Banach Algebra: A normed space E with elements f,g,... is called normed Algebra if it is an Algebra and the multiplication with the norm fulfills: $$||fg||\le ||f||\cdot||g||$$ A normed algebra is a Banach algebra , if it is complete as a space (if it is a Banach space). * Defintion of an Algebra:* If K is a field , A a vector space equipped with multiplication operation in form of $A \times A \rightarrow A$, then A is an algebra if for $x,y,z \in A $ and $a,b \in K$ scalars it holds that: $$1. (x+y)\cdot z = xz+yz \\2: x\cdot(y+z)=xy+xz \\ 3: (ax)\cdot (by)=(ab)(x\cdot y)$$ In this case A is B(X) and x,y,z are bounded functions, $a,b\in \mathbb{R}$ and it fulfills (1-3) of the Algebra definition. Now for the step from  Algebra to normed Algebra one has to check the submultiplicativity :  $$\sup_{x\in X}|f(x)g(x)| \le \sup _{x \in X} |f(x)|\sup_{x\in X}|g(x)|$$ How to show this ???","X is an arbitrary , non empty set, B(X) the set of bounded functions $f:X\rightarrow \mathbb{R}$ and $||f||_\infty = \sup_{x\in X }|f(x)|$. Is $(B(X),||.||_\infty )$ a Banach Algebra? My attempt at showing that this is true: Definition of a Banach Algebra: A normed space E with elements f,g,... is called normed Algebra if it is an Algebra and the multiplication with the norm fulfills: $$||fg||\le ||f||\cdot||g||$$ A normed algebra is a Banach algebra , if it is complete as a space (if it is a Banach space). * Defintion of an Algebra:* If K is a field , A a vector space equipped with multiplication operation in form of $A \times A \rightarrow A$, then A is an algebra if for $x,y,z \in A $ and $a,b \in K$ scalars it holds that: $$1. (x+y)\cdot z = xz+yz \\2: x\cdot(y+z)=xy+xz \\ 3: (ax)\cdot (by)=(ab)(x\cdot y)$$ In this case A is B(X) and x,y,z are bounded functions, $a,b\in \mathbb{R}$ and it fulfills (1-3) of the Algebra definition. Now for the step from  Algebra to normed Algebra one has to check the submultiplicativity :  $$\sup_{x\in X}|f(x)g(x)| \le \sup _{x \in X} |f(x)|\sup_{x\in X}|g(x)|$$ How to show this ???",,"['real-analysis', 'analysis', 'multivariable-calculus', 'banach-algebras']"
37,Surface integral over hemisphere $z = \sqrt{R^2 - x^2 - y^2}$,Surface integral over hemisphere,z = \sqrt{R^2 - x^2 - y^2},"Evaluate: $$\iint_S y\,dS,$$ where $S$ is the hemisphere defined by $z = \sqrt{R^2 -x^2 - y^2}.$ Attempt:I found two tangents, a normal and said $$dS = \frac{R}{\sqrt{R^2 -x^2 - y^2}} dx\,dy$$ In polars, $y = r\sin\theta,$ so I believe I should compute$$ \int_0^{2\pi} \int_0^R \frac{r\sin\theta \cdot R}{\sqrt{R^2 - r^2}} r\,dr\,d\theta$$ Is this okay?","Evaluate: $$\iint_S y\,dS,$$ where $S$ is the hemisphere defined by $z = \sqrt{R^2 -x^2 - y^2}.$ Attempt:I found two tangents, a normal and said $$dS = \frac{R}{\sqrt{R^2 -x^2 - y^2}} dx\,dy$$ In polars, $y = r\sin\theta,$ so I believe I should compute$$ \int_0^{2\pi} \int_0^R \frac{r\sin\theta \cdot R}{\sqrt{R^2 - r^2}} r\,dr\,d\theta$$ Is this okay?",,['multivariable-calculus']
38,"Chain rule computation, need verification","Chain rule computation, need verification",,"Let $z=xy^2, dx/dt=\frac{1}{\sqrt{4+t^3}}, dy/dt=e^t\sqrt{4+t}, x(0)=5, y(0)=2$. I want to determine $dz/dt$ when $t=0$. My computation is that $dz/dx=y^2$ and $dz/dy=2xy$, so therefore $$dz/dt=y^2\cdot \frac{1}{\sqrt{4+t^3}} + 2xy\cdot e^t\sqrt{4+t},$$ and so subbing in $t=0$ I get $dz/dt=\frac12 y^2 + 2xy$. Does this make sense? I don't think I should be getting $x$ and $y$'s left in here.","Let $z=xy^2, dx/dt=\frac{1}{\sqrt{4+t^3}}, dy/dt=e^t\sqrt{4+t}, x(0)=5, y(0)=2$. I want to determine $dz/dt$ when $t=0$. My computation is that $dz/dx=y^2$ and $dz/dy=2xy$, so therefore $$dz/dt=y^2\cdot \frac{1}{\sqrt{4+t^3}} + 2xy\cdot e^t\sqrt{4+t},$$ and so subbing in $t=0$ I get $dz/dt=\frac12 y^2 + 2xy$. Does this make sense? I don't think I should be getting $x$ and $y$'s left in here.",,['multivariable-calculus']
39,Differentiating with respect to x and y,Differentiating with respect to x and y,,"I'm reading a proof and I'm struggling with basic calculus here.  Given the equation,  $F[x, F(y, z)] = F[F(x, y), z] $ set  $u = F(x, y)$ and $v = F(y, z)$ so you have $$F(x, v) = F(u, z)$$ Now differentiate with respect to $x$ and $y$ leads to the following $F_{x}(x,v) = F_{x}(u,z)F_{x}(x,y)$ $F_{y}(x,v)F_{x}(y,z) = F_{x}(u,z)F_{y}(x,y)$ I think, according to the chain rule, the derivative of  $F[x, F(y, z)]$ or $F[x, u]$ with respect to x should equal $F_{x}(u,z)F_{x}(x,y)$. So number 1 makes sense. But when you differentiate that with respect to $y$, I don't understand how you get 2.","I'm reading a proof and I'm struggling with basic calculus here.  Given the equation,  $F[x, F(y, z)] = F[F(x, y), z] $ set  $u = F(x, y)$ and $v = F(y, z)$ so you have $$F(x, v) = F(u, z)$$ Now differentiate with respect to $x$ and $y$ leads to the following $F_{x}(x,v) = F_{x}(u,z)F_{x}(x,y)$ $F_{y}(x,v)F_{x}(y,z) = F_{x}(u,z)F_{y}(x,y)$ I think, according to the chain rule, the derivative of  $F[x, F(y, z)]$ or $F[x, u]$ with respect to x should equal $F_{x}(u,z)F_{x}(x,y)$. So number 1 makes sense. But when you differentiate that with respect to $y$, I don't understand how you get 2.",,"['calculus', 'multivariable-calculus']"
40,Is this question erroneous?  (Stationary points),Is this question erroneous?  (Stationary points),,"Using the second partial derivative test, I have found (-1,1) to be a saddle point but this option is not available in the MCQ. Have I made a mistake? The person who set the question insists that (-1,1) is a minimum, not saddle, because: ""We are talking about the local situation at the 2 points. Since the y coordinate of the 2 points are the same at y=1, that means we pass a vertical plane through the 3-D surface, so it becomes a 2-D curve in terms of x. So using 2nd derivative test (as stated explicitly in the question), it leads to local minimum. ""","Using the second partial derivative test, I have found (-1,1) to be a saddle point but this option is not available in the MCQ. Have I made a mistake? The person who set the question insists that (-1,1) is a minimum, not saddle, because: ""We are talking about the local situation at the 2 points. Since the y coordinate of the 2 points are the same at y=1, that means we pass a vertical plane through the 3-D surface, so it becomes a 2-D curve in terms of x. So using 2nd derivative test (as stated explicitly in the question), it leads to local minimum. """,,"['multivariable-calculus', 'optimization']"
41,"about a good book - Vector Calculus[by Jerold E. Marsden, Anthony J. Tromba ]","about a good book - Vector Calculus[by Jerold E. Marsden, Anthony J. Tromba ]",,"I start reading Vector Calculus by Jerold E. Marsden, Anthony J. Tromba and I want to know if there is a book with the answers of  the exercises. I like a lot this book, it seems to be made for a beginner but also for those who want to assimilate new knowledge. Thanks :)","I start reading Vector Calculus by Jerold E. Marsden, Anthony J. Tromba and I want to know if there is a book with the answers of  the exercises. I like a lot this book, it seems to be made for a beginner but also for those who want to assimilate new knowledge. Thanks :)",,"['reference-request', 'multivariable-calculus']"
42,Reconciling the classical formulation of a surface integral with a general integral over a manifold,Reconciling the classical formulation of a surface integral with a general integral over a manifold,,"So I was just brushing up on some calculus when I came across a problem.  I was trying to perform a surface integral I found online through the more general formulation of a differential form on a manifold.  This led to some trouble. I'm considering the integral over the vector field $F(x,y,z) = (2x,2y,2z)$ along a cylinder of radius $1$ and height $5$ paramtrized by $S(\theta, t) = (\cos(\theta),\sin(\theta),t).$  Calc 2 would tell me to just take the dot product of the vector field and the normal vector to the surface, but I wanted to do this from a manifolds perspective, according to http://en.wikipedia.org/wiki/Differential_form 's integration section.  Following its lead, I identify $F(x,y,z) = 2x dx + 2y dy + 2z dz$ as my differential form.  But now I immediately run into trouble as I'm trying to integrate a 1-form on a 2-manifold. Is there something intrinsically different about a surface integral versus an integral along a manifold?  It seems like a surface integral assigns to each 1-form a 2-form that measures flow through a manifold rather than actually integrating along its surface.","So I was just brushing up on some calculus when I came across a problem.  I was trying to perform a surface integral I found online through the more general formulation of a differential form on a manifold.  This led to some trouble. I'm considering the integral over the vector field $F(x,y,z) = (2x,2y,2z)$ along a cylinder of radius $1$ and height $5$ paramtrized by $S(\theta, t) = (\cos(\theta),\sin(\theta),t).$  Calc 2 would tell me to just take the dot product of the vector field and the normal vector to the surface, but I wanted to do this from a manifolds perspective, according to http://en.wikipedia.org/wiki/Differential_form 's integration section.  Following its lead, I identify $F(x,y,z) = 2x dx + 2y dy + 2z dz$ as my differential form.  But now I immediately run into trouble as I'm trying to integrate a 1-form on a 2-manifold. Is there something intrinsically different about a surface integral versus an integral along a manifold?  It seems like a surface integral assigns to each 1-form a 2-form that measures flow through a manifold rather than actually integrating along its surface.",,['multivariable-calculus']
43,What do level curves signify?,What do level curves signify?,,"Suppose I have a function $z=f(x,y)$, say like $z=\sqrt{x^2+y^2}$. By fixing some value for $z$ and varying all possible $x$ and $y$, we would get a level curve of $z=f(x,y)$. By changing values for $z$, one can get different level curves. For $z=\sqrt{x^2+y^2}$, the level curves would be concentric circles. My question is, What do level curves signify? What all conclusions can be made about the function $z=f(x,y)$ just from the level curves?","Suppose I have a function $z=f(x,y)$, say like $z=\sqrt{x^2+y^2}$. By fixing some value for $z$ and varying all possible $x$ and $y$, we would get a level curve of $z=f(x,y)$. By changing values for $z$, one can get different level curves. For $z=\sqrt{x^2+y^2}$, the level curves would be concentric circles. My question is, What do level curves signify? What all conclusions can be made about the function $z=f(x,y)$ just from the level curves?",,"['differential-geometry', 'multivariable-calculus']"
44,Evaluating a double integral,Evaluating a double integral,,"Using a formula from geometry evaluate $\displaystyle \int_0^3 \! \int_{-\sqrt{9-x^2}}^{\sqrt{9-x^2}} \sqrt{9-x^2-y^2}\,dy\,dx$. Attempt . What formula? Any hints please. I know I could use some trigonometric equations for integrals, but I suppose there is a much easier way to evaluate these integrals.","Using a formula from geometry evaluate $\displaystyle \int_0^3 \! \int_{-\sqrt{9-x^2}}^{\sqrt{9-x^2}} \sqrt{9-x^2-y^2}\,dy\,dx$. Attempt . What formula? Any hints please. I know I could use some trigonometric equations for integrals, but I suppose there is a much easier way to evaluate these integrals.",,"['integration', 'multivariable-calculus']"
45,A question about solving multiple integral,A question about solving multiple integral,,"What i wanna ask is that how do you tackle the problem oif multiple integral when you are not able to draw the diagram?Also how you would determine the order of integrand. For instance, what is the volume bounded by the surface $x^3+xyz^2, x^3y^2+z^y, z+y+2x=10$ Those function are just creat without any try, so may be it is not solvable, but what i want to say is if we face the function which cannot really draw it, how would you deal with it.","What i wanna ask is that how do you tackle the problem oif multiple integral when you are not able to draw the diagram?Also how you would determine the order of integrand. For instance, what is the volume bounded by the surface $x^3+xyz^2, x^3y^2+z^y, z+y+2x=10$ Those function are just creat without any try, so may be it is not solvable, but what i want to say is if we face the function which cannot really draw it, how would you deal with it.",,"['calculus', 'analysis', 'multivariable-calculus']"
46,double integral question,double integral question,,"How to solve the following $$\iint\limits_{x^2+y^2\ge k}\frac{\exp(-(x^2+y^2)/2)}{2\pi}dxdy?$$ I think I should make the substitution $u=x^2+y^2$, but I don't know how the integral will look like.","How to solve the following $$\iint\limits_{x^2+y^2\ge k}\frac{\exp(-(x^2+y^2)/2)}{2\pi}dxdy?$$ I think I should make the substitution $u=x^2+y^2$, but I don't know how the integral will look like.",,['multivariable-calculus']
47,Evaluating $\int_γ y^2 \;dx + x^2\; dy$,Evaluating,\int_γ y^2 \;dx + x^2\; dy,"In an exercise I have to evaluate: $$\int_γ y^2 \; dx + x^2 \; dy$$ where $γ$ is the line from $(1,0)$ to $(0,1)$. I solved line integrals before using $dS = \sqrt{(\frac{dx}{dt})^2 + (\frac{dy}{dt})^2} \cdot dt$. However I have never seen this particular notation before and I don't know what it means. I would appreciate any help.","In an exercise I have to evaluate: $$\int_γ y^2 \; dx + x^2 \; dy$$ where $γ$ is the line from $(1,0)$ to $(0,1)$. I solved line integrals before using $dS = \sqrt{(\frac{dx}{dt})^2 + (\frac{dy}{dt})^2} \cdot dt$. However I have never seen this particular notation before and I don't know what it means. I would appreciate any help.",,"['multivariable-calculus', 'integration']"
48,"Compute $\dfrac{\partial f(x,y,g(x,y))}{\partial x}$",Compute,"\dfrac{\partial f(x,y,g(x,y))}{\partial x}","Question is in the title... I was wondering if someone could help me with that partial derivative, preferably with the total derivative if possible. Thanks a lot","Question is in the title... I was wondering if someone could help me with that partial derivative, preferably with the total derivative if possible. Thanks a lot",,['multivariable-calculus']
49,diffeomorphism-example,diffeomorphism-example,,"Can anyone come up with a diffeomorphism of $\mathbb{R}^{2}$ onto the unit disc $\left \{ (x,y): x^{2}+y^{2}< 1 \right \}$? I tried the following example: $$F(x,y)=(\frac{x}{\sqrt{1+x^{2}+y^{2}}},\frac{y}{\sqrt{1+x^{2}+y^{2}}})$$, but I am not sure if this works out. In addition, it is very hard to prove that $Jf(x)\neq 0$.","Can anyone come up with a diffeomorphism of $\mathbb{R}^{2}$ onto the unit disc $\left \{ (x,y): x^{2}+y^{2}< 1 \right \}$? I tried the following example: $$F(x,y)=(\frac{x}{\sqrt{1+x^{2}+y^{2}}},\frac{y}{\sqrt{1+x^{2}+y^{2}}})$$, but I am not sure if this works out. In addition, it is very hard to prove that $Jf(x)\neq 0$.",,"['real-analysis', 'analysis', 'multivariable-calculus']"
50,Computing partial derivatives.,Computing partial derivatives.,,"I am having trouble solving this problem: If $f$ is $C^{2}$ and $f(x,y)=g(r,\theta)$ where $(r,\theta)$ are polar coordinates in $\mathbb{R}^{2}$, then $$ \left(\frac{\partial^{2}}{\partial x^{2}}+\frac{\partial^{2}}{\partial y^{2}}\right)f(x,y)=\left(\frac{\partial^{2}}{\partial r^{2}}+\frac{1}{r}\frac{\partial}{\partial r}+\frac{1}{r^{2}}\frac{\partial^{2}}{\partial\theta^{2}}\right)g(r,\theta) $$ for all $(x,y)\ne(0,0)$. I computed $$\frac{\partial f}{\partial x}=\frac{\partial f}{\partial r}\frac{\partial r}{\partial x}+\frac{\partial f}{\partial\theta}\frac{\partial\theta}{\partial x}=\cos\theta\frac{\partial f}{\partial r}-\frac{\sin\theta}{r}\frac{\partial f}{\partial\theta} $$ and $$ \frac{\partial f}{\partial y}=\frac{\partial f}{\partial r}\frac{\partial r}{\partial y}+\frac{\partial f}{\partial\theta}\frac{\partial\theta}{\partial y}=\sin\theta\frac{\partial f}{\partial r}+\frac{\cos\theta}{r}\frac{\partial f}{\partial\theta} $$ but I do not know how to compute the second derivatives. Any help is appreciated.","I am having trouble solving this problem: If $f$ is $C^{2}$ and $f(x,y)=g(r,\theta)$ where $(r,\theta)$ are polar coordinates in $\mathbb{R}^{2}$, then $$ \left(\frac{\partial^{2}}{\partial x^{2}}+\frac{\partial^{2}}{\partial y^{2}}\right)f(x,y)=\left(\frac{\partial^{2}}{\partial r^{2}}+\frac{1}{r}\frac{\partial}{\partial r}+\frac{1}{r^{2}}\frac{\partial^{2}}{\partial\theta^{2}}\right)g(r,\theta) $$ for all $(x,y)\ne(0,0)$. I computed $$\frac{\partial f}{\partial x}=\frac{\partial f}{\partial r}\frac{\partial r}{\partial x}+\frac{\partial f}{\partial\theta}\frac{\partial\theta}{\partial x}=\cos\theta\frac{\partial f}{\partial r}-\frac{\sin\theta}{r}\frac{\partial f}{\partial\theta} $$ and $$ \frac{\partial f}{\partial y}=\frac{\partial f}{\partial r}\frac{\partial r}{\partial y}+\frac{\partial f}{\partial\theta}\frac{\partial\theta}{\partial y}=\sin\theta\frac{\partial f}{\partial r}+\frac{\cos\theta}{r}\frac{\partial f}{\partial\theta} $$ but I do not know how to compute the second derivatives. Any help is appreciated.",,['multivariable-calculus']
51,How do I find the limit of $\frac{xy\sqrt{|xy|}}{x^2 + xy + y^2}$ as x and y approach zero?,How do I find the limit of  as x and y approach zero?,\frac{xy\sqrt{|xy|}}{x^2 + xy + y^2},"I am trying to find: $$\lim_{(x,y)\to (0,0)}\frac{xy\sqrt{|xy|}}{x^2 + xy + y^2}$$ I suspect that the limit does exist as the combined power of $x$ and $y$ is higher in the numerator than in the denominator, and I have noticed a pattern where this produces a limit, but the reverse case does not. I have tried using polar coordinates $x = r\cos{\theta}, y = r\sin{\theta}$ and simplifying to get: $$f(r\cos{\theta}, r\sin{\theta}) = \frac{r(\cos{\theta}\sin{\theta})\sqrt{|\cos{\theta}\sin{\theta}|}}{\cos{\theta}\sin{\theta} + 1}$$ I can't seem to get anywhere from here. I was trying to apply the squeezed theorem, but this expression seems like it needs to be simplified more before I can do that. Any hints on how to do that? Or am I barking up the wrong tree and need to try another approach? Many thanks for any insights :)","I am trying to find: $$\lim_{(x,y)\to (0,0)}\frac{xy\sqrt{|xy|}}{x^2 + xy + y^2}$$ I suspect that the limit does exist as the combined power of $x$ and $y$ is higher in the numerator than in the denominator, and I have noticed a pattern where this produces a limit, but the reverse case does not. I have tried using polar coordinates $x = r\cos{\theta}, y = r\sin{\theta}$ and simplifying to get: $$f(r\cos{\theta}, r\sin{\theta}) = \frac{r(\cos{\theta}\sin{\theta})\sqrt{|\cos{\theta}\sin{\theta}|}}{\cos{\theta}\sin{\theta} + 1}$$ I can't seem to get anywhere from here. I was trying to apply the squeezed theorem, but this expression seems like it needs to be simplified more before I can do that. Any hints on how to do that? Or am I barking up the wrong tree and need to try another approach? Many thanks for any insights :)",,"['limits', 'multivariable-calculus', 'polar-coordinates']"
52,Integrating factor and differential 1-forms,Integrating factor and differential 1-forms,,"I am working on the following exercise: The function $f$ is called an integrating factor for the 1-form $\omega$ if $f({\bf x}) \neq 0$ for all $\bf x$ and $d(f\omega) = 0$. If the 1-form $\omega$ has an integrating factor, show that $\omega \wedge d\omega = 0$. I am stuck here... I got $$d(f\omega) = df \wedge \omega + f \wedge d\omega = df \wedge \omega + f\ d\omega = 0$$ but that doesn't seem to get me anywhere. I also tried expanding this further (using the definition of $df$), but this gets quite ugly soon and didn't help either. The same goes for $\omega \wedge d\omega$.","I am working on the following exercise: The function $f$ is called an integrating factor for the 1-form $\omega$ if $f({\bf x}) \neq 0$ for all $\bf x$ and $d(f\omega) = 0$. If the 1-form $\omega$ has an integrating factor, show that $\omega \wedge d\omega = 0$. I am stuck here... I got $$d(f\omega) = df \wedge \omega + f \wedge d\omega = df \wedge \omega + f\ d\omega = 0$$ but that doesn't seem to get me anywhere. I also tried expanding this further (using the definition of $df$), but this gets quite ugly soon and didn't help either. The same goes for $\omega \wedge d\omega$.",,"['multivariable-calculus', 'differential-forms']"
53,Where is the mistake? Two different methods to compute directional derivative lead to do two different results!,Where is the mistake? Two different methods to compute directional derivative lead to do two different results!,,"Problem: Let  $$f(x,y) = \begin{cases}   \frac{xy\sin x}{x^{2}+y^{2}}, & (x,y) \neq (0,0) \cr   0, & (x,y) = (0,0) \end{cases}$$ Let $u=\left ( u_{1},u_{2} \right )$ be a unit vector. Find $\frac{\partial f}{\partial u}\left ( 0,0 \right )$. First Method: I applied the definition:  $$\frac{\partial f}{\partial u}(0,0) =   \lim_{h\to 0} \frac{f(0+u_1 h,0+u_2 h)-f(0,0)}h =    \lim_{h\to 0} \frac{u_1 u_2 h^2 \sin(u_1 h)}{h^2 \cdot h}=u_1^2 u_2.$$ Second Method I applied another definition of directional derivative:  $$\frac{\partial f}{\partial u}(0,0) =     \nabla f(0,0) \cdot (u_1,u_2) =    u_1\frac{\partial f}{\partial x}(0,0) + u_2\frac{\partial f}{\partial y}(0,0) =    u_1\cdot0 + u_2\cdot0=0.$$ Which method is the correct one? and why did we get different results although both definitions are true?","Problem: Let  $$f(x,y) = \begin{cases}   \frac{xy\sin x}{x^{2}+y^{2}}, & (x,y) \neq (0,0) \cr   0, & (x,y) = (0,0) \end{cases}$$ Let $u=\left ( u_{1},u_{2} \right )$ be a unit vector. Find $\frac{\partial f}{\partial u}\left ( 0,0 \right )$. First Method: I applied the definition:  $$\frac{\partial f}{\partial u}(0,0) =   \lim_{h\to 0} \frac{f(0+u_1 h,0+u_2 h)-f(0,0)}h =    \lim_{h\to 0} \frac{u_1 u_2 h^2 \sin(u_1 h)}{h^2 \cdot h}=u_1^2 u_2.$$ Second Method I applied another definition of directional derivative:  $$\frac{\partial f}{\partial u}(0,0) =     \nabla f(0,0) \cdot (u_1,u_2) =    u_1\frac{\partial f}{\partial x}(0,0) + u_2\frac{\partial f}{\partial y}(0,0) =    u_1\cdot0 + u_2\cdot0=0.$$ Which method is the correct one? and why did we get different results although both definitions are true?",,"['real-analysis', 'analysis', 'multivariable-calculus']"
54,Integration/Fundamental Theorem of Calc,Integration/Fundamental Theorem of Calc,,"Problem: Let: $F(x)=\int_{\sin x}^{\cos x}e^{t^{2}+xt}\,dt$. Compute $F^{'}(0)$. I tried the following: $F(x)=\int_{a}^{\cos x}e^{t^{2}+xt}\,dt - \int_{a}^{\sin x}e^{t^{2}+xt}\,dt$ where $a$ is between $\cos x$ and $\sin x$. Then I applied the second Fundamental theorem of Calculus to get:  $F^{'}(x)=e^{\cos^{2}x+x\cos x}-e^{\sin^{2}x+x\sin x}$ and Hence $F^{'}(0)=e-1$. But in the book, the given solution is : $\frac{e-3}{2}$. Can anyone tell me what's wrong with my proof and give me the correct solution?","Problem: Let: $F(x)=\int_{\sin x}^{\cos x}e^{t^{2}+xt}\,dt$. Compute $F^{'}(0)$. I tried the following: $F(x)=\int_{a}^{\cos x}e^{t^{2}+xt}\,dt - \int_{a}^{\sin x}e^{t^{2}+xt}\,dt$ where $a$ is between $\cos x$ and $\sin x$. Then I applied the second Fundamental theorem of Calculus to get:  $F^{'}(x)=e^{\cos^{2}x+x\cos x}-e^{\sin^{2}x+x\sin x}$ and Hence $F^{'}(0)=e-1$. But in the book, the given solution is : $\frac{e-3}{2}$. Can anyone tell me what's wrong with my proof and give me the correct solution?",,"['calculus', 'real-analysis', 'multivariable-calculus', 'derivatives']"
55,Cylindrical body volume,Cylindrical body volume,,"The volume of the solid body bounded by $x^2+y^2=4$ and the planes $y+z=4$ , $z=0$ should be calculated. The class notes say that this type of problem is solved using volume integral $\iiint \limits_G  dV $. Work so far: **Edit (based on tom's inputs) $$ \iint\limits_R \big[\int \limits_0^{4-y}dz\big] dA = \int\limits_{-2}^2 \int\limits_{-\sqrt{4-x^2}}^{\sqrt{4-x^2}} \int\limits_0^{4-y} dz\,dy\,dx = 16\pi$$ I need help with figuring out limits of integration on R, it is not clear from the examples given in class.","The volume of the solid body bounded by $x^2+y^2=4$ and the planes $y+z=4$ , $z=0$ should be calculated. The class notes say that this type of problem is solved using volume integral $\iiint \limits_G  dV $. Work so far: **Edit (based on tom's inputs) $$ \iint\limits_R \big[\int \limits_0^{4-y}dz\big] dA = \int\limits_{-2}^2 \int\limits_{-\sqrt{4-x^2}}^{\sqrt{4-x^2}} \int\limits_0^{4-y} dz\,dy\,dx = 16\pi$$ I need help with figuring out limits of integration on R, it is not clear from the examples given in class.",,['multivariable-calculus']
56,Evaluating integral of Green's theorem,Evaluating integral of Green's theorem,,"Applying Green's theorem, I've obtained a double integral of $$\iint_c 4ye^{-x^2 - y^2} \cos (2xy) dx dy = 0 $$ along the curve $x^2 + y^2 \le R^2$. Why is it equal to $0$? The explanation I got was because ""the integral in anti-symmetric (odd) in $y$ and the area of integration is symmetric in $y$."" Will anyone please tell me what does the above sentence means exactly? Thanks.","Applying Green's theorem, I've obtained a double integral of $$\iint_c 4ye^{-x^2 - y^2} \cos (2xy) dx dy = 0 $$ along the curve $x^2 + y^2 \le R^2$. Why is it equal to $0$? The explanation I got was because ""the integral in anti-symmetric (odd) in $y$ and the area of integration is symmetric in $y$."" Will anyone please tell me what does the above sentence means exactly? Thanks.",,"['integration', 'multivariable-calculus']"
57,flux of vector field through a paraboloid,flux of vector field through a paraboloid,,"I'm trying to find the flux of $$\mathbf{F} = x \, \mathbf{i} + (x^2+2z) \, \mathbf{k}$$ out of the space limited by the paraboloid $2z = 1 -x^2 -y^2$ and the $xy$-plane. I've tried to parametrize from $r(x,y,z)$ to $r(x,y)$ and $r(x,z)$ but they yield impossible integrals to calculate. And at that point spherical/cylindrical coordinates doesn't help either. Does any one have a good tip? Cheers,","I'm trying to find the flux of $$\mathbf{F} = x \, \mathbf{i} + (x^2+2z) \, \mathbf{k}$$ out of the space limited by the paraboloid $2z = 1 -x^2 -y^2$ and the $xy$-plane. I've tried to parametrize from $r(x,y,z)$ to $r(x,y)$ and $r(x,z)$ but they yield impossible integrals to calculate. And at that point spherical/cylindrical coordinates doesn't help either. Does any one have a good tip? Cheers,",,"['calculus', 'multivariable-calculus']"
58,Relationship of Two Harmonic Functions Applications?,Relationship of Two Harmonic Functions Applications?,,"In complex analysis, if you take the second derivatives of the Cauchy-Riemmann equations and add them, you get a LaPlace equation that adds to zero in a harmonic function. In vector analysis, if you add functions that are irrotational (curl=0) and incompressible (div = 0), you also get a Laplacian equation that adds to zero in a harmonic relationship. that is     \nabla^2 \varphi = 0 . http://en.wikipedia.org/wiki/Laplace%27s_equation Are these two applications related in some way? Or is it just coincidental that they both end up on a LaPlacian harmonic function?","In complex analysis, if you take the second derivatives of the Cauchy-Riemmann equations and add them, you get a LaPlace equation that adds to zero in a harmonic function. In vector analysis, if you add functions that are irrotational (curl=0) and incompressible (div = 0), you also get a Laplacian equation that adds to zero in a harmonic relationship. that is     \nabla^2 \varphi = 0 . http://en.wikipedia.org/wiki/Laplace%27s_equation Are these two applications related in some way? Or is it just coincidental that they both end up on a LaPlacian harmonic function?",,"['complex-analysis', 'multivariable-calculus']"
59,Differentiating function with large matrices,Differentiating function with large matrices,,"Let $f$ denote the function defined by $$f(x) = w_{pos} \sum_v \left[ \left(\sum_b d_{v,b} x_b - \theta_v \right)_+\right]^2 + w_{neg} \sum_v \left[ \left(\sum_b d_{v,b} x_b - \theta_v \right)_- \right]^2$$ I would like to find the gradient of $f$. Here, $d_{v,b}$ is a large matrix of dim ${v \times b}$ and $x_b$ is a vector of dim ${b \times 1}$ and $\theta$ is a vector of dim ${n \times 1}$. The first part of the equation penalizes over achieving the goal (theta) and second part penalizes under achieving the goal (theta). The $_+$ indicates that the first sum penalizes the positive results and the $_-$ indicates that the second sum penalizes the negative results. Could someone differentiate this? I believe it has to be done piece wise, and what would the code look like?","Let $f$ denote the function defined by $$f(x) = w_{pos} \sum_v \left[ \left(\sum_b d_{v,b} x_b - \theta_v \right)_+\right]^2 + w_{neg} \sum_v \left[ \left(\sum_b d_{v,b} x_b - \theta_v \right)_- \right]^2$$ I would like to find the gradient of $f$. Here, $d_{v,b}$ is a large matrix of dim ${v \times b}$ and $x_b$ is a vector of dim ${b \times 1}$ and $\theta$ is a vector of dim ${n \times 1}$. The first part of the equation penalizes over achieving the goal (theta) and second part penalizes under achieving the goal (theta). The $_+$ indicates that the first sum penalizes the positive results and the $_-$ indicates that the second sum penalizes the negative results. Could someone differentiate this? I believe it has to be done piece wise, and what would the code look like?",,['multivariable-calculus']
60,How do I calculate the length of a curve given in parameterized form?,How do I calculate the length of a curve given in parameterized form?,,"I am given a function describing a curve: $f(t) = (f_1(t), f_2(t))',\quad t \in \mathbb{R},\quad  f_1, f_2: \ \mathbb{R} \rightarrow \mathbb{R}\ .$ How would I calculate the length of that curve corresponding to a given $t$-interval $[a, b]$?","I am given a function describing a curve: $f(t) = (f_1(t), f_2(t))',\quad t \in \mathbb{R},\quad  f_1, f_2: \ \mathbb{R} \rightarrow \mathbb{R}\ .$ How would I calculate the length of that curve corresponding to a given $t$-interval $[a, b]$?",,"['differential-geometry', 'multivariable-calculus']"
61,planes intersection line,planes intersection line,,"There are 4 points: $A(0, -1, 5)$, $B(1, 3, 3)$, $C(5, 4, 0)$ and $D(3, 0, 4)$.   The first plane($\pi_1$) contains the points $A$, $B$ and $C$.   The second plane ($\pi_2$) contains the points $A$, $B$ and $D$. Find the Cartesian equation of the line where $\pi_2$ intersects $\pi_1$. I just need the concept of how to find that line. Should that be a comparison between $\pi_1$ and $\pi_2$ cartesian equations?","There are 4 points: $A(0, -1, 5)$, $B(1, 3, 3)$, $C(5, 4, 0)$ and $D(3, 0, 4)$.   The first plane($\pi_1$) contains the points $A$, $B$ and $C$.   The second plane ($\pi_2$) contains the points $A$, $B$ and $D$. Find the Cartesian equation of the line where $\pi_2$ intersects $\pi_1$. I just need the concept of how to find that line. Should that be a comparison between $\pi_1$ and $\pi_2$ cartesian equations?",,"['multivariable-calculus', 'vector-analysis']"
62,Divergence and Stokes,Divergence and Stokes,,"Could anyone help with this problem? Evaluate $\iint_S \textbf{F}$ $\cdot$ $\textbf{n}$ $d \alpha$ using Stoke's Theorem or the  Divergence Theorem. c) S is the truncated cone $y=2\sqrt{x^2+z^2}$, $2 \le y \le 4$, $ \textbf{n}$ is the outward-pointing normal, and $\textbf{F}(x,y,z)=(x,-2y,z)$ From the comments I am guessing the answer depends on whether we include the end caps or not. I am not sure if we have to include them. In class we used the divergence theorem to solve this problem and we got 0, but the back of the book has $28\pi$. *It's not homework.","Could anyone help with this problem? Evaluate $\iint_S \textbf{F}$ $\cdot$ $\textbf{n}$ $d \alpha$ using Stoke's Theorem or the  Divergence Theorem. c) S is the truncated cone $y=2\sqrt{x^2+z^2}$, $2 \le y \le 4$, $ \textbf{n}$ is the outward-pointing normal, and $\textbf{F}(x,y,z)=(x,-2y,z)$ From the comments I am guessing the answer depends on whether we include the end caps or not. I am not sure if we have to include them. In class we used the divergence theorem to solve this problem and we got 0, but the back of the book has $28\pi$. *It's not homework.",,['calculus']
63,Differentiable orthogonal 3D vector,Differentiable orthogonal 3D vector,,"Does anybody know a simple and differentiable function that converts a 3D vector u = (x, y, z) to another vector that is orthogonal to u . To be more precise, I am looking for three differentiable functions {f, g, h} such that the vector u = (x, y, z) is orthogonal to v = (f(x,y,z), g(x,y,z), h(x,y,z)) and v is zero only if u is zero. The functions {f, g, h} should be as simple as possible. I prefer them linear, but I think no such linear functions exist. Low degree polynomials are also good. P.S. I found such functions, but they are not polynomials. For example: f(x, y, z) = y*(exp(x) + 3) - z*(exp(x) + 2) g(x, y, z) = z*(exp(x) + 1) - x*(exp(x) + 3) h(x, y, z) = x*(exp(x) + 2) - y*(exp(x) + 1) It's simply the cross product of (x,y,z) with (exp(x)+1, exp(x)+2, exp(x)+3). It satisfies all requirements except for being polynomials. But they are quite simple.","Does anybody know a simple and differentiable function that converts a 3D vector u = (x, y, z) to another vector that is orthogonal to u . To be more precise, I am looking for three differentiable functions {f, g, h} such that the vector u = (x, y, z) is orthogonal to v = (f(x,y,z), g(x,y,z), h(x,y,z)) and v is zero only if u is zero. The functions {f, g, h} should be as simple as possible. I prefer them linear, but I think no such linear functions exist. Low degree polynomials are also good. P.S. I found such functions, but they are not polynomials. For example: f(x, y, z) = y*(exp(x) + 3) - z*(exp(x) + 2) g(x, y, z) = z*(exp(x) + 1) - x*(exp(x) + 3) h(x, y, z) = x*(exp(x) + 2) - y*(exp(x) + 1) It's simply the cross product of (x,y,z) with (exp(x)+1, exp(x)+2, exp(x)+3). It satisfies all requirements except for being polynomials. But they are quite simple.",,"['multivariable-calculus', '3d']"
64,Calculating $\oint_{L} \frac{xdy - ydx}{x^2 + y^2}$ PartII,Calculating  PartII,\oint_{L} \frac{xdy - ydx}{x^2 + y^2},"The orginal problem is ""Calculating $\oint_{L} \frac{xdy - ydx}{x^2 + y^2}$, where L is a smooth, simple closed, and postively oriented curve that does not pass through the orgin"". But what if I modify the hypothesis and allow non-simple closed curve? I mean is there something like green formula that allows us calculuating ""non-simple closed curve integral""? EDIT : It seems to me that this integral should also resemble the simple closed one. Because common interior line integral should be canceled only remaining the outter curve. Am I right?","The orginal problem is ""Calculating $\oint_{L} \frac{xdy - ydx}{x^2 + y^2}$, where L is a smooth, simple closed, and postively oriented curve that does not pass through the orgin"". But what if I modify the hypothesis and allow non-simple closed curve? I mean is there something like green formula that allows us calculuating ""non-simple closed curve integral""? EDIT : It seems to me that this integral should also resemble the simple closed one. Because common interior line integral should be canceled only remaining the outter curve. Am I right?",,"['calculus', 'multivariable-calculus']"
65,How to apply integration by parts to simplify an integral of a cross product?,How to apply integration by parts to simplify an integral of a cross product?,,"I'm reading a physics paper and am trying to figure out how a certain expression is derived (If interested, see Appendix of the paper, Eq. (A7), (A8)). The authors skip a lot of derivation steps and at a certain point an expression like the following is encountered. Suppose we have the following: $$\iint_{S} \left[\nabla^{t}A \times \boldsymbol{B}^{t}\right]^{z} dxdy,$$ where $A$ is a scalar field, $\boldsymbol{B}$ is a vector field, $S$ lies completely in the xy-plane. The superscripts $t$ and $z$ denote the transverse (x, y) and longitudinal (z) components, i.e.: $$\nabla^{t}M = \left(\frac{\partial M}{\partial x}, \frac{\partial M}{\partial y},0\right)$$ is the transverse part of the gradient, and: $$\boldsymbol{N}^{t} = \left(N_{x}, N_{y}, 0\right);$$ $$\boldsymbol{N}^{z} = N_{z}.$$ At this point they state that they use ""an integration by parts"" and they somehow manage to move the nabla so that it is cross-product multiplied with $\boldsymbol{B}$ , i.e. the final expression should contain something like this: $$A(\nabla \times \boldsymbol{B})$$ together with other terms and the correct superscripts, which I have omitted here because I don't know them. Does anyone know some integration by parts formula that can help me get from the original expression to something looking like this? Any help and advice is much appreciated. Also, let me know if you would need more details. I've tried to keep things as abstract as I can.","I'm reading a physics paper and am trying to figure out how a certain expression is derived (If interested, see Appendix of the paper, Eq. (A7), (A8)). The authors skip a lot of derivation steps and at a certain point an expression like the following is encountered. Suppose we have the following: where is a scalar field, is a vector field, lies completely in the xy-plane. The superscripts and denote the transverse (x, y) and longitudinal (z) components, i.e.: is the transverse part of the gradient, and: At this point they state that they use ""an integration by parts"" and they somehow manage to move the nabla so that it is cross-product multiplied with , i.e. the final expression should contain something like this: together with other terms and the correct superscripts, which I have omitted here because I don't know them. Does anyone know some integration by parts formula that can help me get from the original expression to something looking like this? Any help and advice is much appreciated. Also, let me know if you would need more details. I've tried to keep things as abstract as I can.","\iint_{S} \left[\nabla^{t}A \times \boldsymbol{B}^{t}\right]^{z} dxdy, A \boldsymbol{B} S t z \nabla^{t}M = \left(\frac{\partial M}{\partial x}, \frac{\partial M}{\partial y},0\right) \boldsymbol{N}^{t} = \left(N_{x}, N_{y}, 0\right); \boldsymbol{N}^{z} = N_{z}. \boldsymbol{B} A(\nabla \times \boldsymbol{B})","['integration', 'multivariable-calculus', 'vector-analysis', 'electromagnetism']"
66,Integral of $x^2+y^2$ on the domain $(x^2 + y^2)^2 \le x^2-y^2$,Integral of  on the domain,x^2+y^2 (x^2 + y^2)^2 \le x^2-y^2,"I need to calculate the double integral $\iint_D (x^2 + y^2)$ $D = \{ (x, y) \in \mathbb{R}^2 \mid (x^2 + y^2)^2 \leq x^2 - y^2 \}$ The answer is $\frac{\pi}{8}$ I've tried using the substitution rule for double integral with polar transformation, and with $u = (x^2 + y^2)$ , $v = (x^2 - y^2)$ but I couldn't figure out the domain after the substitution.","I need to calculate the double integral The answer is I've tried using the substitution rule for double integral with polar transformation, and with , but I couldn't figure out the domain after the substitution.","\iint_D (x^2 + y^2) D = \{ (x, y) \in \mathbb{R}^2 \mid (x^2 + y^2)^2 \leq x^2 - y^2 \} \frac{\pi}{8} u = (x^2 + y^2) v = (x^2 - y^2)","['calculus', 'multivariable-calculus', 'definite-integrals']"
67,"Evaluating $\int_0^{\infty}\frac{e^{-tx}\sin{t}}{t}dt, x>0$",Evaluating,"\int_0^{\infty}\frac{e^{-tx}\sin{t}}{t}dt, x>0","The task is to compute $$F(x) = \int_0^{\infty}\frac{e^{-tx}\sin{t}}{t}dt, x>0 $$ and from simple integration by parts one can see that $$\int_0^{\infty}e^{-xt}\sin{t}dt = \frac{1}{1+x^2}. $$ What I tried to do was differentiate F(x) with respect to x (under the integral sign) which gave $$ \frac{d}{dx}\int_0^{\infty}\frac{e^{-xt}\sin{t}}{t}dt = \int_0^{\infty}\frac{-te^{-xt}\sin{t}}{t}dt = -\frac{1}{1+x^2}  $$ I think that the answer is then found by integrating with respect to x on both sides ( $x\in(0,\infty)$ ): $$F(x)=\int_0^{\infty}\frac{e^{-xt}\sin{t}}{t}dt = -\int_0^{\infty}\frac{1}{1+x^2}dx=[-arctan(x)]_0^{\infty} = -\frac{\pi}{2}+ 0 = -\frac{\pi}{2}  $$ But the answer sheet says that the answer is $ F(x) = -arctan(x) + \frac{\pi}{2}$ . Where did I go wrong?",The task is to compute and from simple integration by parts one can see that What I tried to do was differentiate F(x) with respect to x (under the integral sign) which gave I think that the answer is then found by integrating with respect to x on both sides ( ): But the answer sheet says that the answer is . Where did I go wrong?,"F(x) = \int_0^{\infty}\frac{e^{-tx}\sin{t}}{t}dt, x>0  \int_0^{\infty}e^{-xt}\sin{t}dt = \frac{1}{1+x^2}.   \frac{d}{dx}\int_0^{\infty}\frac{e^{-xt}\sin{t}}{t}dt = \int_0^{\infty}\frac{-te^{-xt}\sin{t}}{t}dt = -\frac{1}{1+x^2}   x\in(0,\infty) F(x)=\int_0^{\infty}\frac{e^{-xt}\sin{t}}{t}dt = -\int_0^{\infty}\frac{1}{1+x^2}dx=[-arctan(x)]_0^{\infty} = -\frac{\pi}{2}+ 0 = -\frac{\pi}{2}    F(x) = -arctan(x) + \frac{\pi}{2}",['multivariable-calculus']
68,"How to do this limit $L=\lim_{(x,y) \to (1,4)} \frac{y^2 - 4xy}{y^2 - 16x^2}$",How to do this limit,"L=\lim_{(x,y) \to (1,4)} \frac{y^2 - 4xy}{y^2 - 16x^2}","Evaluate : $$L=\lim_{(x,y) \to (1,4)} \frac{y^2 - 4xy}{y^2 - 16x^2}$$ My Work : We can cancel $(y-4x)$ from the numerator and denominator provided $y \neq 4x$ and this comes out as $1/2$ . When the function is evaluated along $y=4x$ it is undefined (i.e. $f(x,4x) = 0/0)$ . This means the limit cannot exist along this line, right? Therefore the limit $L$ does not exist? Is my thinking wrong?","Evaluate : My Work : We can cancel from the numerator and denominator provided and this comes out as . When the function is evaluated along it is undefined (i.e. . This means the limit cannot exist along this line, right? Therefore the limit does not exist? Is my thinking wrong?","L=\lim_{(x,y) \to (1,4)} \frac{y^2 - 4xy}{y^2 - 16x^2} (y-4x) y \neq 4x 1/2 y=4x f(x,4x) = 0/0) L","['limits', 'multivariable-calculus', 'solution-verification', 'indeterminate-forms']"
69,Clarifications on the solution of a double integral: $\iint_X\frac{x^2y}{x^2+y^2}dxdy$,Clarifications on the solution of a double integral:,\iint_X\frac{x^2y}{x^2+y^2}dxdy,"Calculate the following double integral: $$\iint_X\frac{x^2y}{x^2+y^2}dxdy$$ where $X=\{(x,y)\in \Bbb R^2\colon 1\leq x^2+y^2\leq2x\}.$ Here my confusion arises. Looking at the integrand the polar coordinates seem to be better suited to solve the exercise. But I have the problem with the domain. If I used polar coordinates I would write: $$1\leq r^2\leq 2r\cos\vartheta $$ I have drew the domain with an online tool https://www.wolframalpha.com/ and the domain is a half-moon of which I understand from the drawing the limits of $x$ but not those of $y$ (How to find the limits of $x$ and $y$ ?). They are two circumferences of center in $O$ and radius $1$ and the other a circle of center in $(1,0)$ and radius $1$ . I think by eyes that even setting the correct integration extremes, for sure the double integral is very complicated. Staying in polar coordinates if I looked at the drawing I would immediately realize that $1\leq r\leq 2$ which I cannot find from $1\leq r^2\leq 2r\cos\vartheta$ and that $\vartheta\in[-\pi/2,\pi/2]$ . We would have $$\iint_X\frac{x^2y}{x^2+y^2}dxdy=\int_{[1,2]}rdr\int_{[-\pi/2,\pi/2]}\frac{r^3\cos^2\vartheta\sin\vartheta}{r^2}d\vartheta$$ $$=\int_{[1,2]}r^2dr\int_{[-\pi/2,\pi/2]}\cos^2\vartheta\sin\vartheta d\vartheta$$ But the second integral is zero (it is an immediate integral). So the double integral is worth $0$ ? I don't think so. Addendum: Just for curiosity how I obtain the solution using the cartesian coordinates?","Calculate the following double integral: where Here my confusion arises. Looking at the integrand the polar coordinates seem to be better suited to solve the exercise. But I have the problem with the domain. If I used polar coordinates I would write: I have drew the domain with an online tool https://www.wolframalpha.com/ and the domain is a half-moon of which I understand from the drawing the limits of but not those of (How to find the limits of and ?). They are two circumferences of center in and radius and the other a circle of center in and radius . I think by eyes that even setting the correct integration extremes, for sure the double integral is very complicated. Staying in polar coordinates if I looked at the drawing I would immediately realize that which I cannot find from and that . We would have But the second integral is zero (it is an immediate integral). So the double integral is worth ? I don't think so. Addendum: Just for curiosity how I obtain the solution using the cartesian coordinates?","\iint_X\frac{x^2y}{x^2+y^2}dxdy X=\{(x,y)\in \Bbb R^2\colon 1\leq x^2+y^2\leq2x\}. 1\leq r^2\leq 2r\cos\vartheta  x y x y O 1 (1,0) 1 1\leq r\leq 2 1\leq r^2\leq 2r\cos\vartheta \vartheta\in[-\pi/2,\pi/2] \iint_X\frac{x^2y}{x^2+y^2}dxdy=\int_{[1,2]}rdr\int_{[-\pi/2,\pi/2]}\frac{r^3\cos^2\vartheta\sin\vartheta}{r^2}d\vartheta =\int_{[1,2]}r^2dr\int_{[-\pi/2,\pi/2]}\cos^2\vartheta\sin\vartheta d\vartheta 0","['calculus', 'multivariable-calculus', 'inequality', 'polar-coordinates', 'nonlinear-system']"
70,"Why is $ \lim_{(x,y) \to (0,0)} \frac{\sin(xy)}{xy}$ defined while $\lim_{(x,y,z) \to (0,0,0)} \frac{\sin(xyz)}{xyz}$ is not?",Why is  defined while  is not?," \lim_{(x,y) \to (0,0)} \frac{\sin(xy)}{xy} \lim_{(x,y,z) \to (0,0,0)} \frac{\sin(xyz)}{xyz}","I've found an exercise that compares the following limits: $$ \lim_{(x,y) \to (0,0)} \frac{\sin(xy)}{xy} \qquad\text{and}\qquad \lim_{(x,y,z) \to (0,0,0)} \frac{\sin(xyz)}{xyz}$$ The solutions suggests the first limit exists and is equal to 1, whereas the latter limit does not exist. My working is as follows: From a one-variable approach, it is known that $ \lim_{x \to 0} \frac{\sin(x)}{x} = 1$ . Thus, it is reasonable to suppose $ \lim_{\textbf{v} \to (0,0)} \frac{\sin||\textbf{v}||^2}{||\textbf{v}||^2}=1.$ It could be said by epsilon-delta further, that because $ \lim_{x \to 0} \frac{\sin(x)}{x} = 1$ , given $\epsilon > 0$ , we can find a $\delta > 0$ with $0 < \delta < 1$ , such that $0 < |x| < \delta $ implies $|\frac{\sin(x)}{x} - 1| < \epsilon$ . If $0 < ||\textbf{v}|| < \delta$ , then $0 < ||\textbf{v}|| < \delta^2 < \delta$ , and finally, $|f(\textbf{v}) - 1| = |\frac{\sin||\textbf{v}||^2}{||\textbf{v}||^2}-1| < \epsilon$ . I feel comfortable with this logic for two variables, however I am interested in why the logic fails when introducing a third variable. I predict it is largely due to how the variables behave but if someone could provide me with some intuition as to how to spot this behavioural shenanigans I would greatly appreciate it; Thank you in advance!","I've found an exercise that compares the following limits: The solutions suggests the first limit exists and is equal to 1, whereas the latter limit does not exist. My working is as follows: From a one-variable approach, it is known that . Thus, it is reasonable to suppose It could be said by epsilon-delta further, that because , given , we can find a with , such that implies . If , then , and finally, . I feel comfortable with this logic for two variables, however I am interested in why the logic fails when introducing a third variable. I predict it is largely due to how the variables behave but if someone could provide me with some intuition as to how to spot this behavioural shenanigans I would greatly appreciate it; Thank you in advance!"," \lim_{(x,y) \to (0,0)} \frac{\sin(xy)}{xy} \qquad\text{and}\qquad \lim_{(x,y,z) \to (0,0,0)} \frac{\sin(xyz)}{xyz}  \lim_{x \to 0} \frac{\sin(x)}{x} = 1  \lim_{\textbf{v} \to (0,0)} \frac{\sin||\textbf{v}||^2}{||\textbf{v}||^2}=1.  \lim_{x \to 0} \frac{\sin(x)}{x} = 1 \epsilon > 0 \delta > 0 0 < \delta < 1 0 < |x| < \delta  |\frac{\sin(x)}{x} - 1| < \epsilon 0 < ||\textbf{v}|| < \delta 0 < ||\textbf{v}|| < \delta^2 < \delta |f(\textbf{v}) - 1| = |\frac{\sin||\textbf{v}||^2}{||\textbf{v}||^2}-1| < \epsilon","['calculus', 'limits', 'multivariable-calculus', 'epsilon-delta']"
71,Checking KKT Constraint Qualifications,Checking KKT Constraint Qualifications,,"When checking whether the CQ are satisfied in KKT, i.e. checking for Linear Independence amongst all combinations of the constraints. Is it true to say we only need to check combinations that could be simultaneously effective (binding)? So if two constraints can't bind at the same time i.e. they would create the empty set, i don't need to check their gradient vectors for Liner Dependence? This seems to be the case but i recently came across the following in a mark scheme, i'm struggling to interpret it, and wondered if it was stating the above but only for mixed constraint problems. For mixed constraint problems, we follow the same approach as for inequality constraint optimisation problems, but we can restrict our attention to just those combinations of effective constraints that include the equality constraints. I would also appreciate some intuition as to why the importance of Linear Dependence in the context of KKT constraints is I feel like the Lagrange/KKT solutions wouldn't know how to allocate tangent points if multiple constraints were LD - somewhat analogous to how regression fails with perfect collinearity of regressors? Thanks! Example Taking the example in the image below: • I would state that the CQ holds for $h_1, h_3$ because if $h_1$ is binding $x = 0$ which implies $y=5$ , which creates vectors $(0,1)$ and $(6,1)$ which are LI. • Their approach is always the other way round. They say for $h_1$ and $h_3$ to be LD, then $x = -1$ this violates the constraint $h_1$ Are both approaches valid? Does my approach of starting with the implications of the constraints being binding run into any problems, compared with starting with the implications of the constraints being LI.","When checking whether the CQ are satisfied in KKT, i.e. checking for Linear Independence amongst all combinations of the constraints. Is it true to say we only need to check combinations that could be simultaneously effective (binding)? So if two constraints can't bind at the same time i.e. they would create the empty set, i don't need to check their gradient vectors for Liner Dependence? This seems to be the case but i recently came across the following in a mark scheme, i'm struggling to interpret it, and wondered if it was stating the above but only for mixed constraint problems. For mixed constraint problems, we follow the same approach as for inequality constraint optimisation problems, but we can restrict our attention to just those combinations of effective constraints that include the equality constraints. I would also appreciate some intuition as to why the importance of Linear Dependence in the context of KKT constraints is I feel like the Lagrange/KKT solutions wouldn't know how to allocate tangent points if multiple constraints were LD - somewhat analogous to how regression fails with perfect collinearity of regressors? Thanks! Example Taking the example in the image below: • I would state that the CQ holds for because if is binding which implies , which creates vectors and which are LI. • Their approach is always the other way round. They say for and to be LD, then this violates the constraint Are both approaches valid? Does my approach of starting with the implications of the constraints being binding run into any problems, compared with starting with the implications of the constraints being LI.","h_1, h_3 h_1 x = 0 y=5 (0,1) (6,1) h_1 h_3 x = -1 h_1","['multivariable-calculus', 'optimization', 'constraints', 'karush-kuhn-tucker']"
72,"Please explain Figure 24.4 in ""Analysis on Manifolds"" by James R. Munkres.","Please explain Figure 24.4 in ""Analysis on Manifolds"" by James R. Munkres.",,"I am reading ""Analysis on Manifolds"" by James R. Munkres. I am reading the proof of Theorem 24.4. I don't understand Figure 24.4. Is the solid enclosed by the red closed curve in Figure 24.4 $A\cap N$ ? Is the blue surface in Figure 24.4 $A\cap M$ ? Why is the image by $F$ in Figure 24.4 a rectangular parallelepiped?","I am reading ""Analysis on Manifolds"" by James R. Munkres. I am reading the proof of Theorem 24.4. I don't understand Figure 24.4. Is the solid enclosed by the red closed curve in Figure 24.4 ? Is the blue surface in Figure 24.4 ? Why is the image by in Figure 24.4 a rectangular parallelepiped?",A\cap N A\cap M F,"['multivariable-calculus', 'manifolds-with-boundary']"
73,"How to evaluate $\int_{0}^{1} \int_{0}^{1} \frac{{(1 + x) \cdot \log(x) - (1 + y) \cdot \log(y)}}{{x - y}} \cdot (1 + \log(xy)) \,dy \,dx$",How to evaluate,"\int_{0}^{1} \int_{0}^{1} \frac{{(1 + x) \cdot \log(x) - (1 + y) \cdot \log(y)}}{{x - y}} \cdot (1 + \log(xy)) \,dy \,dx","Question: How to evaluate this integral $$\int_{0}^{1} \int_{0}^{1} \frac{{(1 + x) \cdot \log(x) - (1 + y) \cdot \log(y)}}{{x - y}} \cdot (1 + \log(xy)) \,dy \,dx$$ My messy try $$\int_{0}^{1} \int_{0}^{1} \frac{{(1 + x) \cdot \log(x) - (1 + y) \cdot \log(y)}}{{x - y}} \cdot (1 + \log(xy)) \,dy \,dx$$ $$ \begin{array}{r} I=\int_0^1 \int_0^1 \frac{(1+x) \ln (x)-(1+y) \ln (y)}{x-y}(1+\ln (x y)) d y d x \\ I=\int_0^1 \int_0^{\frac{1}{x}} \frac{(1+x) \ln (x)-(1+x t)(\ln (x)+\ln (t))}{1-t}(1+2 \ln (x)+\ln (t)) d t d x \\ =\int_0^1 \int_0^{\frac{1}{x}} x \ln (x)(1+2 \ln (x)+\ln (t)) d t d x- \\ -\int_0^1 \int_0^{\frac{1}{x}} \frac{(1+x t) \ln (t)}{(1-t)}(1+2 \ln (x)+\ln (t)) d t d x \\ =\int_0^1 x \ln (x)\left(\frac{1+2 \ln (x)-\ln (x)-1}{x}\right) d x-\int_0^1 \int_0^1 \frac{(1+x t) \ln (t)}{(1-t)}(1+2 \ln (x) \ln (t)) d x d t +  \end{array} $$ $$- \int_{0}^{\infty} \int_{0}^{\frac{1}{t}} \frac{{(1 + xt) \cdot \ln(t)}}{{1 - t}} \cdot (1 + 2 \cdot \ln(x) + \ln(t)) \,dx \,dt$$ $$I_1 = \int_{0}^{1} x \ln(x) \left( \frac{{1 + 2 \ln(x) - \ln(x) - 1}}{{x}} \right) \,dx - \int_{0}^{1} \int_{0}^{1} \frac{{(1 + xt) \ln(t)}}{{1 - t}} \cdot (1 + 2 \ln(x) + \ln(t)) \,dx \,dt $$ $$I_2 = -\int_{0}^{\infty} \int_{0}^{1/t} \frac{{(1 + xt) \ln(t)}}{{1 - t}} \cdot (1 + 2 \ln(x) + \ln(t)) \,dx \,dt$$ I need hints for figuring out $I_1$ and $I_2$ .",Question: How to evaluate this integral My messy try I need hints for figuring out and .,"\int_{0}^{1} \int_{0}^{1} \frac{{(1 + x) \cdot \log(x) - (1 + y) \cdot \log(y)}}{{x - y}} \cdot (1 + \log(xy)) \,dy \,dx \int_{0}^{1} \int_{0}^{1} \frac{{(1 + x) \cdot \log(x) - (1 + y) \cdot \log(y)}}{{x - y}} \cdot (1 + \log(xy)) \,dy \,dx 
\begin{array}{r}
I=\int_0^1 \int_0^1 \frac{(1+x) \ln (x)-(1+y) \ln (y)}{x-y}(1+\ln (x y)) d y d x \\
I=\int_0^1 \int_0^{\frac{1}{x}} \frac{(1+x) \ln (x)-(1+x t)(\ln (x)+\ln (t))}{1-t}(1+2 \ln (x)+\ln (t)) d t d x \\
=\int_0^1 \int_0^{\frac{1}{x}} x \ln (x)(1+2 \ln (x)+\ln (t)) d t d x- \\
-\int_0^1 \int_0^{\frac{1}{x}} \frac{(1+x t) \ln (t)}{(1-t)}(1+2 \ln (x)+\ln (t)) d t d x \\
=\int_0^1 x \ln (x)\left(\frac{1+2 \ln (x)-\ln (x)-1}{x}\right) d x-\int_0^1 \int_0^1 \frac{(1+x t) \ln (t)}{(1-t)}(1+2 \ln (x) \ln (t)) d x d t + 
\end{array}
 - \int_{0}^{\infty} \int_{0}^{\frac{1}{t}} \frac{{(1 + xt) \cdot \ln(t)}}{{1 - t}} \cdot (1 + 2 \cdot \ln(x) + \ln(t)) \,dx \,dt I_1 = \int_{0}^{1} x \ln(x) \left( \frac{{1 + 2 \ln(x) - \ln(x) - 1}}{{x}} \right) \,dx - \int_{0}^{1} \int_{0}^{1} \frac{{(1 + xt) \ln(t)}}{{1 - t}} \cdot (1 + 2 \ln(x) + \ln(t)) \,dx \,dt  I_2 = -\int_{0}^{\infty} \int_{0}^{1/t} \frac{{(1 + xt) \ln(t)}}{{1 - t}} \cdot (1 + 2 \ln(x) + \ln(t)) \,dx \,dt I_1 I_2","['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'closed-form']"
74,"Understanding limits of integration after transformation $(x,y) \mapsto (x-y,x+y)$",Understanding limits of integration after transformation,"(x,y) \mapsto (x-y,x+y)","Consider the following double-integral: $$ \iint_{[0,a]\times[0,a]} (x-y)^2 dxdy \stackrel{*}{=} \int_0^a \int_0^a (x-y)^2 dxdy = \frac{a^4}{6} $$ where $*$ follows by iterated integration. Suppose instead we consider the substitution $w=x-y, z=x+y$ . The Jacobian of this transformation is $1/2$ , and so $$ \iint_{[0,a]\times[0,a]} (x-y)^2 dx dy = \frac{1}{2} \iint_{R_2} w^2 dw dz =\frac{1}{2} \int_{Y_1}^{Y_2} \left (\int_{X_1}^{X_2} dz\right )w^2 dw. $$ My question is: how do I go about solving this via iterated integration (with respect to $z$ first, then with respect to $w$ ), or more specifically, what should the limits of integration $Y_1,Y_2,X_1,X_2$ be? If we consider the transformation $(x,y)\mapsto (w,z)$ as a linear map $$ A = \begin{bmatrix}1 & -1 \\ 1 & 1\end{bmatrix} $$ then this transforms the square $[0,a]\times [0,a]$ into the parallelogram with vertices: $(0,0), (a,a),(0,2a), (-a,a)$ , which is the region bounded by the lines: $$ y=x, \quad y=x+2a, \quad y=-x+2a, \quad y=-x, $$ or equivalently by the lines $$ w=0, \quad w=-2a, \quad z=0, \quad z=2a, $$ and so $$ R_2 = \{(w,z) : -2a \le w \le 0, ~ 0\le z \le 2a \}. $$ This is not a rectangular region in $(w,z)$ -space, but clearly it is not correct to take $Y_1 = -2a, Y_2=0, X_1 = 0, X_2=2a$ , since it does not lead to the answer found by direct integration mentioned in the first display. My confusion is about how to relate $z$ and $w$ and choose the inner integral limits properly.","Consider the following double-integral: where follows by iterated integration. Suppose instead we consider the substitution . The Jacobian of this transformation is , and so My question is: how do I go about solving this via iterated integration (with respect to first, then with respect to ), or more specifically, what should the limits of integration be? If we consider the transformation as a linear map then this transforms the square into the parallelogram with vertices: , which is the region bounded by the lines: or equivalently by the lines and so This is not a rectangular region in -space, but clearly it is not correct to take , since it does not lead to the answer found by direct integration mentioned in the first display. My confusion is about how to relate and and choose the inner integral limits properly.","
\iint_{[0,a]\times[0,a]} (x-y)^2 dxdy \stackrel{*}{=} \int_0^a \int_0^a (x-y)^2 dxdy = \frac{a^4}{6}
 * w=x-y, z=x+y 1/2 
\iint_{[0,a]\times[0,a]} (x-y)^2 dx dy
=
\frac{1}{2} \iint_{R_2} w^2 dw dz
=\frac{1}{2} \int_{Y_1}^{Y_2} \left (\int_{X_1}^{X_2} dz\right )w^2 dw.
 z w Y_1,Y_2,X_1,X_2 (x,y)\mapsto (w,z) 
A = \begin{bmatrix}1 & -1 \\ 1 & 1\end{bmatrix}
 [0,a]\times [0,a] (0,0), (a,a),(0,2a), (-a,a) 
y=x, \quad y=x+2a, \quad y=-x+2a, \quad y=-x,
 
w=0, \quad w=-2a, \quad z=0, \quad z=2a,
 
R_2 = \{(w,z) : -2a \le w \le 0, ~ 0\le z \le 2a \}.
 (w,z) Y_1 = -2a, Y_2=0, X_1 = 0, X_2=2a z w","['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'multiple-integral']"
75,"Multiindex partial derivative higher order product rule, i.e. formula for $\partial^\alpha(fg)$","Multiindex partial derivative higher order product rule, i.e. formula for",\partial^\alpha(fg),"I want to prove the product rule for higher order partial derivatives. It is given on Wikipedia under the name ""General Leibniz rule"": $$\partial^\alpha(fg)=\sum_{\beta\leq \alpha}\binom\alpha\beta(\partial^\beta f)(\partial^{\alpha-\beta}g),$$ where $\alpha$ and $\beta$ are multiindices. My first attempt is to make a recursion by computing (here $i$ is just an index) $$\partial^{\alpha}\big( \partial^i(fg) \big)=\sum_{\beta\leq\alpha}\binom{\alpha}{\beta}\Big(  (\partial^{(\alpha,i)-\beta}f)(\partial^{\beta}g)+(\partial^{\beta}f)(\partial^{(\alpha,i)-\beta}g) \Big).$$ I'm not sure how to continue at this point. The index $i$ can be one of the components of the multiindex $\alpha$ . I dont'see how to manage the combinatorics... related on MathOverflow: Multivariable Higher Order Chain Rule","I want to prove the product rule for higher order partial derivatives. It is given on Wikipedia under the name ""General Leibniz rule"": where and are multiindices. My first attempt is to make a recursion by computing (here is just an index) I'm not sure how to continue at this point. The index can be one of the components of the multiindex . I dont'see how to manage the combinatorics... related on MathOverflow: Multivariable Higher Order Chain Rule","\partial^\alpha(fg)=\sum_{\beta\leq \alpha}\binom\alpha\beta(\partial^\beta f)(\partial^{\alpha-\beta}g), \alpha \beta i \partial^{\alpha}\big( \partial^i(fg) \big)=\sum_{\beta\leq\alpha}\binom{\alpha}{\beta}\Big(  (\partial^{(\alpha,i)-\beta}f)(\partial^{\beta}g)+(\partial^{\beta}f)(\partial^{(\alpha,i)-\beta}g) \Big). i \alpha","['multivariable-calculus', 'partial-derivative', 'multinomial-coefficients']"
76,How do I know whether a local minima is also global?,How do I know whether a local minima is also global?,,"In the region $0\leq x\leq 1$ and $0\leq y\leq 1$ I have 1 radio broadcaster placed in $(x_b,y_b)$ and N receivers. The position of the broadcaster is not known. The position of each receiver however is known: $(x_i,y_i)$ as is the distance from the receiver to the broadcaster: $d_i$ . There is some noise in the distance measurements that I assume to be normal distributed with mean=0 and the same variance for all receivers. My goal is to estimate the most likely position of the radio broadcaster: $(x_b,y_b)$ . I do this by minimizing: $$ SE = \sum_i \left[\sqrt{(x_b - x_i)^2+(y_b - y_i)^2} - d_i\right]^2 $$ using scipy.optimize.minimize() . This approach seems to work fine. However how do I know that the local minima I find is also the global minima? In this example I can plot $SE(x_b,y_b)$ : However my real problem is estimating the position: $(x,y,z)$ and the orientation of a camera: $(roll,pitch,yaw)$ . There is no way I can visualize 6D space. Therefore I am looking for some other way to check whether a found minima is global. As far as I understand there are only two ways to show that there is only 1 local minima? Method I Show that $$ \frac{\partial SE}{\partial x_b} = \frac{\partial SE}{\partial y_b} = 0 $$ only has 1 solution and that all the eigenvalues of the Hessian of SE in this point are positive. Method II Show that SE is convex by showing that all eigenvalues of the Hessian of SE are positive at all points. Let us try method I. I find that: $$ \frac{\partial SE}{\partial x_b} = \Sigma_i 2 (x_b - x_i)  \frac{\sqrt{(x_b - x_i)^2 + (y_b - y_i)^2} - d_i}{\sqrt{(x_b - x_i)^2 + (y_b - y_i)^2}} $$ $$ \frac{\partial SE}{\partial y_b} = \Sigma_i 2 (y_b - y_i)  \frac{\sqrt{(x_b - x_i)^2 + (y_b - y_i)^2} - d_i}{\sqrt{(x_b - x_i)^2 + (y_b - y_i)^2}} $$ How many solutions do $$ \frac{\partial SE}{\partial x_b} = \frac{\partial SE}{\partial y_b} = 0 $$ have? Difficult to tell, I guess it dependens on the $\{(x_i,y_i,d_i)\}$ values? Method II seems even harder.","In the region and I have 1 radio broadcaster placed in and N receivers. The position of the broadcaster is not known. The position of each receiver however is known: as is the distance from the receiver to the broadcaster: . There is some noise in the distance measurements that I assume to be normal distributed with mean=0 and the same variance for all receivers. My goal is to estimate the most likely position of the radio broadcaster: . I do this by minimizing: using scipy.optimize.minimize() . This approach seems to work fine. However how do I know that the local minima I find is also the global minima? In this example I can plot : However my real problem is estimating the position: and the orientation of a camera: . There is no way I can visualize 6D space. Therefore I am looking for some other way to check whether a found minima is global. As far as I understand there are only two ways to show that there is only 1 local minima? Method I Show that only has 1 solution and that all the eigenvalues of the Hessian of SE in this point are positive. Method II Show that SE is convex by showing that all eigenvalues of the Hessian of SE are positive at all points. Let us try method I. I find that: How many solutions do have? Difficult to tell, I guess it dependens on the values? Method II seems even harder.","0\leq x\leq 1 0\leq y\leq 1 (x_b,y_b) (x_i,y_i) d_i (x_b,y_b) 
SE = \sum_i \left[\sqrt{(x_b - x_i)^2+(y_b - y_i)^2} - d_i\right]^2
 SE(x_b,y_b) (x,y,z) (roll,pitch,yaw) 
\frac{\partial SE}{\partial x_b} = \frac{\partial SE}{\partial y_b} = 0
 
\frac{\partial SE}{\partial x_b} = \Sigma_i 2 (x_b - x_i) 
\frac{\sqrt{(x_b - x_i)^2 + (y_b - y_i)^2} - d_i}{\sqrt{(x_b - x_i)^2 + (y_b - y_i)^2}}
 
\frac{\partial SE}{\partial y_b} = \Sigma_i 2 (y_b - y_i) 
\frac{\sqrt{(x_b - x_i)^2 + (y_b - y_i)^2} - d_i}{\sqrt{(x_b - x_i)^2 + (y_b - y_i)^2}}
 
\frac{\partial SE}{\partial x_b} = \frac{\partial SE}{\partial y_b} = 0
 \{(x_i,y_i,d_i)\}","['multivariable-calculus', 'optimization', 'numerical-methods', 'nonlinear-optimization']"
77,Multi-variate cross-partial derivative of a inverse function,Multi-variate cross-partial derivative of a inverse function,,"I have an invertible mapping $y=f(x,\theta)$ where $x,y\in\mathbb{R}^K$ with a scalar parameter $\theta\in\mathbb R$ . Consider its inverse $x=g(y,\theta)$ . I'm interested in the matrix $\partial^2g/\partial y'\partial\theta$ . Is it possible to express it in terms of the derivatives of $f$ ? For $K=1$ , the answer (in the more general case of an implicit $f$ ) is given here but is there a generalization for $K>1$ ?","I have an invertible mapping where with a scalar parameter . Consider its inverse . I'm interested in the matrix . Is it possible to express it in terms of the derivatives of ? For , the answer (in the more general case of an implicit ) is given here but is there a generalization for ?","y=f(x,\theta) x,y\in\mathbb{R}^K \theta\in\mathbb R x=g(y,\theta) \partial^2g/\partial y'\partial\theta f K=1 f K>1","['multivariable-calculus', 'implicit-differentiation', 'implicit-function-theorem', 'inverse-function-theorem']"
78,Continuous and increasing in every variable does not imply continuous?,Continuous and increasing in every variable does not imply continuous?,,"Let $f:\mathbb R^2\to \mathbb R$ $z=f(x,y)$ $f$ is continuous and strictly increasing in both $x,y$ . It is known that continuous in each linear directions does not imply continuity. But the examples that I found all involve non-monotonic functions. $$f(x,y)=\begin{cases}\frac{xy}{x^2+y^2},&(x,y)\neq(0,0)\\ 0,&(x,y)=(0,0)\\ \end{cases}$$ I wonder if continuous and increasing in every variable implies continuous? I think the answer is no",Let is continuous and strictly increasing in both . It is known that continuous in each linear directions does not imply continuity. But the examples that I found all involve non-monotonic functions. I wonder if continuous and increasing in every variable implies continuous? I think the answer is no,"f:\mathbb R^2\to \mathbb R z=f(x,y) f x,y f(x,y)=\begin{cases}\frac{xy}{x^2+y^2},&(x,y)\neq(0,0)\\
0,&(x,y)=(0,0)\\
\end{cases}","['real-analysis', 'multivariable-calculus', 'functions', 'continuity', 'examples-counterexamples']"
79,Prove $\frac{1}{\sqrt{a+b+7c}}+\frac{1}{\sqrt{c+b+7a}}+\frac{1}{\sqrt{a+c+7b}}\ge 1.$,Prove,\frac{1}{\sqrt{a+b+7c}}+\frac{1}{\sqrt{c+b+7a}}+\frac{1}{\sqrt{a+c+7b}}\ge 1.,"Problem. Given non-negative real numbers $a,b,c$ satisfying $a+b+c+abc=4.$ Prove that $$\color{black}{\frac{1}{\sqrt{a+b+7c}}+\frac{1}{\sqrt{c+b+7a}}+\frac{1}{\sqrt{a+c+7b}}\ge 1.}$$ I found the inequality accidentally and there is no original proof. In case it's old problem, I hope there is nice proof like AM-GM, Cauchy-Schwarz,... Equality holds at $(1,1,1);(0,2,2)$ and that makes some troubles when I tried to use classical inequalities application. You're welcome to share any ideas and comment here. Thank you for your interest. Here is what I tried so far. I thought of Holder inequality but my try is not good enough. $\bullet$ Holder using 1 $$\left(\sum_{cyc}\frac{1}{b+c+7a}\right)^2\cdot \sum_{cyc}(b+c+7a)(b+c+xa)^3\ge (x+2)^3(a+b+c)^3.$$ Choose $x$ such that equality holds at $a=b=2;c=0.$ Thus, we solve the equation $$256+2\cdot16\cdot(2x+2)^3=64(x+2)^3 \iff x=-2;x=0.$$ Notice that $x=0$ is satisfied. We consider $$\left(\sum_{cyc}\frac{1}{b+c+7a}\right)^2\cdot \sum_{cyc}(b+c+7a)(b+c)^3\ge 8(a+b+c)^3.$$ But $$ 8(a+b+c)^3\ge \sum_{cyc}(b+c+7a)(b+c)^3$$ is already wrong at $a=b=\dfrac{9}{10}.$ $\bullet$ Holder using 2 $$\left(\sum_{cyc}\frac{1}{b+c+7a}\right)^2\cdot \sum_{cyc}(b+c+7a)(x+a)^3\ge (a+b+c+3x)^3.$$ Choose $x$ such that equality holds at $a=b=2;c=0.$ Thus, we solve the equation $$4x^3+32(x+2)^3=(4+3x)^3\iff x=-4;x=-\frac{4}{3}. $$ Thus, both Holder using ways are failed. Maybe there is exist a better way.","Problem. Given non-negative real numbers satisfying Prove that I found the inequality accidentally and there is no original proof. In case it's old problem, I hope there is nice proof like AM-GM, Cauchy-Schwarz,... Equality holds at and that makes some troubles when I tried to use classical inequalities application. You're welcome to share any ideas and comment here. Thank you for your interest. Here is what I tried so far. I thought of Holder inequality but my try is not good enough. Holder using 1 Choose such that equality holds at Thus, we solve the equation Notice that is satisfied. We consider But is already wrong at Holder using 2 Choose such that equality holds at Thus, we solve the equation Thus, both Holder using ways are failed. Maybe there is exist a better way.","a,b,c a+b+c+abc=4. \color{black}{\frac{1}{\sqrt{a+b+7c}}+\frac{1}{\sqrt{c+b+7a}}+\frac{1}{\sqrt{a+c+7b}}\ge 1.} (1,1,1);(0,2,2) \bullet \left(\sum_{cyc}\frac{1}{b+c+7a}\right)^2\cdot \sum_{cyc}(b+c+7a)(b+c+xa)^3\ge (x+2)^3(a+b+c)^3. x a=b=2;c=0. 256+2\cdot16\cdot(2x+2)^3=64(x+2)^3 \iff x=-2;x=0. x=0 \left(\sum_{cyc}\frac{1}{b+c+7a}\right)^2\cdot \sum_{cyc}(b+c+7a)(b+c)^3\ge 8(a+b+c)^3.  8(a+b+c)^3\ge \sum_{cyc}(b+c+7a)(b+c)^3 a=b=\dfrac{9}{10}. \bullet \left(\sum_{cyc}\frac{1}{b+c+7a}\right)^2\cdot \sum_{cyc}(b+c+7a)(x+a)^3\ge (a+b+c+3x)^3. x a=b=2;c=0. 4x^3+32(x+2)^3=(4+3x)^3\iff x=-4;x=-\frac{4}{3}. ","['multivariable-calculus', 'inequality', 'lagrange-multiplier']"
80,"Prove $\color{black}{\sqrt{a+1}+\sqrt{b+1}+\sqrt{c+1}\le 1+2\cdot\sqrt{\frac{a+b+c+5}{3}}, }$ when $ab+bc+ca+abc=4.$",Prove  when,"\color{black}{\sqrt{a+1}+\sqrt{b+1}+\sqrt{c+1}\le 1+2\cdot\sqrt{\frac{a+b+c+5}{3}}, } ab+bc+ca+abc=4.","If $a,b,c\ge 0: ab+bc+ca+abc=4.$ Prove that $$\color{black}{\sqrt{a+1}+\sqrt{b+1}+\sqrt{c+1}\le 1+2\cdot\sqrt{\frac{a+b+c+5}{3}}.  }$$ I've tried to square both side but it leads to complicated one. Now, if we use the substitution $a=\dfrac{2x}{y+z};b=\dfrac{2y}{x+z};c=\dfrac{2z}{y+x}.$ The problem turns out $$\sum_{cyc}\sqrt{\frac{2x+y+z}{y+z}}\le 1+\frac{2}{\sqrt{3}}\cdot\sqrt{5+2\sum_{cyc}\frac{x}{y+z}}.$$ From here, I don't know how to continue to full proof. Hope you can share some thoughts to help me out. Also, all idea and comment are welcome. Thanks for interest.","If Prove that I've tried to square both side but it leads to complicated one. Now, if we use the substitution The problem turns out From here, I don't know how to continue to full proof. Hope you can share some thoughts to help me out. Also, all idea and comment are welcome. Thanks for interest.","a,b,c\ge 0: ab+bc+ca+abc=4. \color{black}{\sqrt{a+1}+\sqrt{b+1}+\sqrt{c+1}\le 1+2\cdot\sqrt{\frac{a+b+c+5}{3}}.  } a=\dfrac{2x}{y+z};b=\dfrac{2y}{x+z};c=\dfrac{2z}{y+x}. \sum_{cyc}\sqrt{\frac{2x+y+z}{y+z}}\le 1+\frac{2}{\sqrt{3}}\cdot\sqrt{5+2\sum_{cyc}\frac{x}{y+z}}.","['algebra-precalculus', 'multivariable-calculus', 'inequality', 'lagrange-multiplier']"
81,Missing factor of 1/2 in a multivariable change of variables problem,Missing factor of 1/2 in a multivariable change of variables problem,,"I am interested in evaluating the integral $$ \iint_{E} xy dA $$ where $E$ is the region bounded by $xy = 3$ , $xy = 1$ , $y = 3x$ , and $y = x$ . This gives a region of integration that looks like this: Using the substitution $x = u/v$ and $y = v$ , we obtain a Jacobian of $$\frac{\partial(x,y)}{\partial(u,v)}  = 1 \cdot \frac{1}{v} - 0 \cdot \frac{-u}{v^2} = \frac{1}{v} > 0$$ which I think should turn our integral into: $$ \int_1^3\int_{1}^3 u \cdot \frac{1}{v} du dv = 4 \ln(3). $$ However, the answer is supposed to be $2 \ln (3)$ , so I seem to be missing a factor of $1/2$ somewhere. I changed my bounds by noting that $v = y$ , and $y$ goes from $1$ to $3$ in the graph above.  Also, $x = u/v$ implies $u = xv = xy$ , and $u = xy$ goes from $1$ to $3$ as well. So where is my mistake exactly?","I am interested in evaluating the integral where is the region bounded by , , , and . This gives a region of integration that looks like this: Using the substitution and , we obtain a Jacobian of which I think should turn our integral into: However, the answer is supposed to be , so I seem to be missing a factor of somewhere. I changed my bounds by noting that , and goes from to in the graph above.  Also, implies , and goes from to as well. So where is my mistake exactly?","
\iint_{E} xy dA
 E xy = 3 xy = 1 y = 3x y = x x = u/v y = v \frac{\partial(x,y)}{\partial(u,v)}  = 1 \cdot \frac{1}{v} - 0 \cdot \frac{-u}{v^2} = \frac{1}{v} > 0 
\int_1^3\int_{1}^3 u \cdot \frac{1}{v} du dv = 4 \ln(3).
 2 \ln (3) 1/2 v = y y 1 3 x = u/v u = xv = xy u = xy 1 3","['multivariable-calculus', 'change-of-variable', 'jacobian']"
82,"Find local minima, maxima, and saddle points for $f(x,y) = \sin x + \cos y + \cos(x-y)$ when $0\le x\le\frac\pi2$ and $0\le y\le\frac\pi2$","Find local minima, maxima, and saddle points for  when  and","f(x,y) = \sin x + \cos y + \cos(x-y) 0\le x\le\frac\pi2 0\le y\le\frac\pi2","What I have done for this problem: I differentiated $f(x,y)$ with respect to $x$ and $y$ . Then, I set $f_x$ and $f_y$ to $0$ to find stationary points. $$f(x,y) = \sin(x) + \cos(y) + \cos(x-y)$$ $$f_x = \cos(x) - \sin(x-y)$$ $$f_y = -\sin(y) + \sin(x-y)$$ $$f_x = f_y = 0$$ $$\cos(x) = \sin(x-y)$$ $$\sin(y) = \sin(x-y)$$ $$\cos(x) = \sin(y)$$ Note: $\cos(x) = \sin(y)$ implies $\cos(y) = \sin(x)$ . $$\sin(\pi/2 - x) = \sin(y)$$ $$y = \pi/2 - x \,\,\{0\le x \le\pi/2, 0\le y \le\pi/2\}$$ Using the Second Derivative Test, I categorized the points on the line segment ( $y=\pi/2 - x$ ). $$f_{xx} = -\sin(x) - \cos(x-y)$$ $$f_{yy} = -\cos(y) - \cos(x-y)$$ $$f_{xy} = \cos(x-y)$$ $$f_{yx} = \cos(x-y)$$ $$D = f_{xx}f_{yy} - f_{xy}f_{yx}$$ $$D = \cos(y)(\cos(y) + 2\cos(x-y))$$ Finally, the Second Derivative Test is inconclusive when $y = \pi/2$ and $x = 0$ , and for all the other points on the line segment $f(x,y)$ when $0 \lt x \le \pi/2$ and $0\le y \lt \pi/2$ represents local maximum because $D \gt 0$ and $f_{xx} \lt 0$ . This does not make sense because when I graph $f(x,y)$ on Desmos 3D graphing calculator it only shows one local maximum and one local minimum ( https://www.desmos.com/3d/326ec8bd3d ).","What I have done for this problem: I differentiated with respect to and . Then, I set and to to find stationary points. Note: implies . Using the Second Derivative Test, I categorized the points on the line segment ( ). Finally, the Second Derivative Test is inconclusive when and , and for all the other points on the line segment when and represents local maximum because and . This does not make sense because when I graph on Desmos 3D graphing calculator it only shows one local maximum and one local minimum ( https://www.desmos.com/3d/326ec8bd3d ).","f(x,y) x y f_x f_y 0 f(x,y) = \sin(x) + \cos(y) + \cos(x-y) f_x = \cos(x) - \sin(x-y) f_y = -\sin(y) + \sin(x-y) f_x = f_y = 0 \cos(x) = \sin(x-y) \sin(y) = \sin(x-y) \cos(x) = \sin(y) \cos(x) = \sin(y) \cos(y) = \sin(x) \sin(\pi/2 - x) = \sin(y) y = \pi/2 - x \,\,\{0\le x \le\pi/2, 0\le y \le\pi/2\} y=\pi/2 - x f_{xx} = -\sin(x) - \cos(x-y) f_{yy} = -\cos(y) - \cos(x-y) f_{xy} = \cos(x-y) f_{yx} = \cos(x-y) D = f_{xx}f_{yy} - f_{xy}f_{yx} D = \cos(y)(\cos(y) + 2\cos(x-y)) y = \pi/2 x = 0 f(x,y) 0 \lt x \le \pi/2 0\le y \lt \pi/2 D \gt 0 f_{xx} \lt 0 f(x,y)",['multivariable-calculus']
83,Calculating a formula to express the volume of a rhombic dodecahedron (BEE PRISM WITH HEXAGONAL BASE),Calculating a formula to express the volume of a rhombic dodecahedron (BEE PRISM WITH HEXAGONAL BASE),,"I was trying to optimize the cells in a honeycomb structure and I eventually came across the rhombic dodecahedron (I am aware other figures such as the bitruncated octahedron entail greater efficiency). Bees make (let us assume it is their intention) hexagonal prisms with an apex enclosure as the one in the image to minimize the wax used. I wanted to utilize a Lagrangian function that took into consideration the surface area and volume (equated to a constraint of 0.35) in a multivariable system of equations, but need an actual formula for the volume to be able to carry out the task. The surface area I found was 3s(2h+(s√2)/2) (calculating already for the angle to be 54.7º). I have tried to use integrals of volume and have tried to estimate the irregularities of this prism with regular prisms, but none of these seem to be the correct approach (or at least I have not figured out how to use them appropiately). To sum up, my question is: ¿How can I derive an expression for the volume of a rhombic dodecahedron that has got an hexagonal base as the one shown in the figure? Any help would be appreciated. Edit: I am now looking to optimize the sides of the shape as previously suggested. The area is 3s(2h+(s√2)/2) and the volume is ((3√3)/2 s^2 )(h-s/(2√2))=0.35 (0.35 is the constraint). Utilizing Lagrange I get sides s and h to be approximately 0.4567 and 0.8073 respectively. This yields a surface area of approximately 2.6547. The thing is that I did it as well with a regular hexagonal prism and the surface area was surprisingly less; approximately 2.254. The area used in that case was 3sa+6sh (becuase the hexagonal aperture is open) and the volume 3ash=0.35. I thought this might be because in the long run the rhombic dodecahedron might end up tessellating space more efficiently, but I am not sure. Did I go wrong in my operations, or is there a suitable explanation?","I was trying to optimize the cells in a honeycomb structure and I eventually came across the rhombic dodecahedron (I am aware other figures such as the bitruncated octahedron entail greater efficiency). Bees make (let us assume it is their intention) hexagonal prisms with an apex enclosure as the one in the image to minimize the wax used. I wanted to utilize a Lagrangian function that took into consideration the surface area and volume (equated to a constraint of 0.35) in a multivariable system of equations, but need an actual formula for the volume to be able to carry out the task. The surface area I found was 3s(2h+(s√2)/2) (calculating already for the angle to be 54.7º). I have tried to use integrals of volume and have tried to estimate the irregularities of this prism with regular prisms, but none of these seem to be the correct approach (or at least I have not figured out how to use them appropiately). To sum up, my question is: ¿How can I derive an expression for the volume of a rhombic dodecahedron that has got an hexagonal base as the one shown in the figure? Any help would be appreciated. Edit: I am now looking to optimize the sides of the shape as previously suggested. The area is 3s(2h+(s√2)/2) and the volume is ((3√3)/2 s^2 )(h-s/(2√2))=0.35 (0.35 is the constraint). Utilizing Lagrange I get sides s and h to be approximately 0.4567 and 0.8073 respectively. This yields a surface area of approximately 2.6547. The thing is that I did it as well with a regular hexagonal prism and the surface area was surprisingly less; approximately 2.254. The area used in that case was 3sa+6sh (becuase the hexagonal aperture is open) and the volume 3ash=0.35. I thought this might be because in the long run the rhombic dodecahedron might end up tessellating space more efficiently, but I am not sure. Did I go wrong in my operations, or is there a suitable explanation?",,"['calculus', 'geometry', 'multivariable-calculus', 'volume']"
84,"Is this function differentiable at $(1,0)$?",Is this function differentiable at ?,"(1,0)","Let $f:\mathbb{R}^{2}\to\mathbb{R}^{2}$ be defined by $$f(x,y)=\left\{ \begin{array}[ll] (\left(\dfrac{\sin(x^2 + y^2 -1)}{x^2+y^2-1}, \cos(x^2 + y^2 -1)\right), & \mbox{if }x^2+y^2-1\neq0 \\ (1,1), & \mbox{if  }x^2+y^2-1=0\end{array} \right.$$ Is $f$ differentiable at $(1,0)$ ? I've already proved that $\dfrac{\partial f}{\partial x}(1,0)=(0,0)$ and $\dfrac{\partial f}{\partial y}(1,0)=(0,0)$ . I know the next step is to prove the continuity of $\dfrac{\partial f}{\partial x}$ and $\dfrac{\partial f}{\partial y}$ , but I don't know how to deal with the limit of two variables with such complicated form like this. Could anyone advise? Thank you.","Let be defined by Is differentiable at ? I've already proved that and . I know the next step is to prove the continuity of and , but I don't know how to deal with the limit of two variables with such complicated form like this. Could anyone advise? Thank you.","f:\mathbb{R}^{2}\to\mathbb{R}^{2} f(x,y)=\left\{ \begin{array}[ll] (\left(\dfrac{\sin(x^2 + y^2 -1)}{x^2+y^2-1}, \cos(x^2 + y^2 -1)\right), & \mbox{if }x^2+y^2-1\neq0 \\ (1,1), & \mbox{if  }x^2+y^2-1=0\end{array} \right. f (1,0) \dfrac{\partial f}{\partial x}(1,0)=(0,0) \dfrac{\partial f}{\partial y}(1,0)=(0,0) \dfrac{\partial f}{\partial x} \dfrac{\partial f}{\partial y}","['limits', 'analysis', 'multivariable-calculus', 'derivatives']"
85,Having troubles to understanding differentiation of multivariable vectors,Having troubles to understanding differentiation of multivariable vectors,,"What doesn't seem to get around my head is how differentiation with vectors work. I have seen my (physics) teacher differentiate the unitary vector $\vec{u_r}$ using the following: $$\frac{d\vec{u_r}}{dt}=\frac{\partial \vec{u_r}}{\partial r}\dot{r}+\frac{\partial \vec{u_r}}{\partial \theta}\dot \theta+\frac{\partial \vec{u_r}}{\partial \phi}\dot \phi$$ for the  unitary vectors for the spherical coordinates, which depend on those three variables $\vec{u_r}=\vec{u_r}(r(t),\theta(t),\phi(t))$ . But then for the position vector itself, $\vec{r}=r\vec{u_r}$ (by definition), he used the following to differentiate: $$\frac{d\vec r}{dt}=\dot r\vec{u_r}+\dot{\vec{u_r}}r$$ How?? I know that the chain rule for multivariable scalar functions like $f=f(x(t),y(t))$ is $\dot f=\frac{\partial f}{\partial x}\frac{dx}{dt}+\frac{\partial f}{\partial y}\frac{dy}{dt}$ but is that rule also comparable and usable for the vectorial functions? One thing that really helps me is the tree drawing of the derivatives and it's variables, to see if I have to add or not, is there a vectorial function version of that?","What doesn't seem to get around my head is how differentiation with vectors work. I have seen my (physics) teacher differentiate the unitary vector using the following: for the  unitary vectors for the spherical coordinates, which depend on those three variables . But then for the position vector itself, (by definition), he used the following to differentiate: How?? I know that the chain rule for multivariable scalar functions like is but is that rule also comparable and usable for the vectorial functions? One thing that really helps me is the tree drawing of the derivatives and it's variables, to see if I have to add or not, is there a vectorial function version of that?","\vec{u_r} \frac{d\vec{u_r}}{dt}=\frac{\partial \vec{u_r}}{\partial r}\dot{r}+\frac{\partial \vec{u_r}}{\partial \theta}\dot \theta+\frac{\partial \vec{u_r}}{\partial \phi}\dot \phi \vec{u_r}=\vec{u_r}(r(t),\theta(t),\phi(t)) \vec{r}=r\vec{u_r} \frac{d\vec r}{dt}=\dot r\vec{u_r}+\dot{\vec{u_r}}r f=f(x(t),y(t)) \dot f=\frac{\partial f}{\partial x}\frac{dx}{dt}+\frac{\partial f}{\partial y}\frac{dy}{dt}","['multivariable-calculus', 'derivatives']"
86,Show that integral $\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}\left(1+\frac{y^2}{x^2}\right)\ dy\ dx=\left(\pi+\frac{8}{3}\right)a^2$,Show that integral,\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}\left(1+\frac{y^2}{x^2}\right)\ dy\ dx=\left(\pi+\frac{8}{3}\right)a^2,"Show that the integral $$\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}\left(1+\frac{y^2}{x^2}\right)\ dy\ dx=\left(\pi+\frac{8}{3}\right)a^2$$ by changing the coordinates $x,y$ to $r$ , $\theta$ where, $x=r\cos^2\theta , y=r\sin\theta \cos\theta$ . Solution: $\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx {= {\int_{0}^{2a}\int_{0}^{\sqrt{4ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx} -{\int_{0}^{2a}\int_0^{\sqrt{2ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx} }=I_1+I_2.$ The Jacobian is $J=r cos^2(\theta)$ for the transformation $x=r\cos^2\theta , y=r\sin\theta \cos\theta$ . Hints is given in the link Evaluate the integral $\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx$ by changing the coordinates to r,$\theta$ Q1: Please help me to solve the problem. How to transform $I_1,I_2$ using the given transformation $x=r\cos^2\theta, y=r\sin\theta \cos\theta$ . I evaluate concern Jacobian, but unable to understand the limits in $r-\theta$ plane. Q2: I understand the Fig in x-y plane which is the common portion of two circles in the 1st quadrant which are $(x-a)^2+y^2=a^2$ (inner) and $(x-2a)^2+y^2=(2a)^2$ . But I cannot understand the Fig in $r-\theta$ plane. Please explain the transformation $x=rcos^2θ,\,y=rsinθ\,cosθ$ .","Show that the integral by changing the coordinates to , where, . Solution: The Jacobian is for the transformation . Hints is given in the link Evaluate the integral $\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx$ by changing the coordinates to r,$\theta$ Q1: Please help me to solve the problem. How to transform using the given transformation . I evaluate concern Jacobian, but unable to understand the limits in plane. Q2: I understand the Fig in x-y plane which is the common portion of two circles in the 1st quadrant which are (inner) and . But I cannot understand the Fig in plane. Please explain the transformation .","\int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}\left(1+\frac{y^2}{x^2}\right)\ dy\ dx=\left(\pi+\frac{8}{3}\right)a^2 x,y r \theta x=r\cos^2\theta , y=r\sin\theta \cos\theta \int_{0}^{2a}\int_{\sqrt{2ax-x^2}}^{\sqrt{4ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx
{=
{\int_{0}^{2a}\int_{0}^{\sqrt{4ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx}
-{\int_{0}^{2a}\int_0^{\sqrt{2ax-x^2}}(1+\frac{y^2}{x^2})\ dy\ dx}
}=I_1+I_2. J=r cos^2(\theta) x=r\cos^2\theta , y=r\sin\theta \cos\theta I_1,I_2 x=r\cos^2\theta, y=r\sin\theta \cos\theta r-\theta (x-a)^2+y^2=a^2 (x-2a)^2+y^2=(2a)^2 r-\theta x=rcos^2θ,\,y=rsinθ\,cosθ","['multivariable-calculus', 'multiple-integral']"
87,Finding the range of a function defined as an integral,Finding the range of a function defined as an integral,,"The task is to determine the range of the function $$ f(x) = \int_x^{2x} \frac{e^{-xt^2}}{t}dt, \;\; x>0 $$ and I have tried to do this by studying its derivative in hopes of finding critical points. I differentiate it by introducing an auxiliary function $$ g(x_1,x_2,x_3) = \int_{x_3}^{x_2} \frac{e^{-x_1t^2}}{t}dt $$ so that $f(x) = g(x,2x,x)$ . I compute the total derivative of f by using the Fundamental Theorem of Calculus and by differentiating under the integral sign: $$\frac{d}{dx} g(x_1,x_2,x_3) = \frac{\partial g}{\partial x_1} + \frac{\partial g}{\partial x_2}\frac{\partial x_2}{\partial x} + \frac{\partial g}{\partial x_3}\frac{\partial x_3}{\partial x} $$ $$= \int_{x_3}^{x_2} -te^{x_1 t^2}dt +2\frac{e^{-x_2^2x_1}}{x_2} -\frac{e^{-x_3^2x_1}}{x_3} $$ so $$f'(x)=-\int_{x}^{2x} te^{-t^2x}dt + \frac{e^{-4x^3}}{x}-\frac{e^{-x^3}}{x}  $$ Next, I compute the integral in the expression for $f'(x)$ : $$ -\int_{x}^{2x}te^{-t^2x}dt = \frac{1}{2x}\int_{x}^{2x}(-2xt)e^{-t^2x}dt = \frac{1}{2x}\left[ e^{-t^2x} \right]_x^{2x} \\ = \frac{1}{2x}(e^{-4x^3}-e^{-x^3} ) $$ so it turns out $f'(x) = \frac{3}{2x}(e^{-4x^3}-e^{-x^3}) $ , but this does not have a root that is not also a singular point (let me know if I am using the wrong terms). I do not have any other ideas for how to solve this problem.","The task is to determine the range of the function and I have tried to do this by studying its derivative in hopes of finding critical points. I differentiate it by introducing an auxiliary function so that . I compute the total derivative of f by using the Fundamental Theorem of Calculus and by differentiating under the integral sign: so Next, I compute the integral in the expression for : so it turns out , but this does not have a root that is not also a singular point (let me know if I am using the wrong terms). I do not have any other ideas for how to solve this problem."," f(x) = \int_x^{2x} \frac{e^{-xt^2}}{t}dt, \;\; x>0   g(x_1,x_2,x_3) = \int_{x_3}^{x_2} \frac{e^{-x_1t^2}}{t}dt  f(x) = g(x,2x,x) \frac{d}{dx} g(x_1,x_2,x_3) = \frac{\partial g}{\partial x_1} + \frac{\partial g}{\partial x_2}\frac{\partial x_2}{\partial x} + \frac{\partial g}{\partial x_3}\frac{\partial x_3}{\partial x}  = \int_{x_3}^{x_2} -te^{x_1 t^2}dt +2\frac{e^{-x_2^2x_1}}{x_2} -\frac{e^{-x_3^2x_1}}{x_3}  f'(x)=-\int_{x}^{2x} te^{-t^2x}dt + \frac{e^{-4x^3}}{x}-\frac{e^{-x^3}}{x}   f'(x)  -\int_{x}^{2x}te^{-t^2x}dt = \frac{1}{2x}\int_{x}^{2x}(-2xt)e^{-t^2x}dt = \frac{1}{2x}\left[ e^{-t^2x} \right]_x^{2x} \\
= \frac{1}{2x}(e^{-4x^3}-e^{-x^3} )  f'(x) = \frac{3}{2x}(e^{-4x^3}-e^{-x^3}) ","['analysis', 'multivariable-calculus', 'derivatives']"
88,Help With Fundamental Theorem of Line Integrals,Help With Fundamental Theorem of Line Integrals,,"I am achieving the wrong answer, but I am unsure where I went wrong about it. I am given a conservative vector field and the line $C$ : $$F = \langle \frac{4x}{y^2+1}, -\frac{4y(x^2+1)}{(y^2+1)^2} \rangle, C \textrm{ is parameterized by } x=t^3-1, y=t^6-t, 0 \le t \le 1  .$$ Since I know it is conservative, I find the potential function $f$ : $$\frac{4x^2+2}{y^2+1} + c$$ Then I just apply FTLI, $f(x(1), y(1)) - f(x(0), y(0))$ by recognizing $t$ is in between $0$ and $1$ therefore its initial point must be $(-1,0)$ and its terminal point $(0,0)$ . So I get $2 - 6 = -4$ , but $-4$ is deemed wrong. I am not sure when I went wrong in this, I double checked my integrals for $P$ and $Q$ when getting the potential function, did I go wrong in determining the initial and terminal points?","I am achieving the wrong answer, but I am unsure where I went wrong about it. I am given a conservative vector field and the line : Since I know it is conservative, I find the potential function : Then I just apply FTLI, by recognizing is in between and therefore its initial point must be and its terminal point . So I get , but is deemed wrong. I am not sure when I went wrong in this, I double checked my integrals for and when getting the potential function, did I go wrong in determining the initial and terminal points?","C F = \langle \frac{4x}{y^2+1}, -\frac{4y(x^2+1)}{(y^2+1)^2} \rangle, C \textrm{ is parameterized by } x=t^3-1, y=t^6-t, 0 \le t \le 1  . f \frac{4x^2+2}{y^2+1} + c f(x(1), y(1)) - f(x(0), y(0)) t 0 1 (-1,0) (0,0) 2 - 6 = -4 -4 P Q","['multivariable-calculus', 'line-integrals']"
89,How can I solve this limit of a function defined in $R^2$?,How can I solve this limit of a function defined in ?,R^2,"I have to find out for which $\alpha>0$ this limit equals to $0$ : $$\lim\limits_{(x, y) \to (0, 0)}\frac{1+\sin(|x|^\alpha y)-\cos(x^2+y^4)}{(x^2+y^4)^{3/2}}$$ I tried to separate it in two parts: $$\lim\limits_{(x, y) \to (0, 0)}\frac{1-\cos(x^2+y^4)}{(x^2+y^4)^{3/2}}+\frac{\sin(|x|^\alpha y)}{(x^2+y^4)^{3/2}}$$ Now the first term doesn't depend on $\alpha$ and it is asymptotic to: $$\frac{1-1+\frac{(x^2+y^4)^2}{2}}{(x^2+y^4)^{3/2}}=\frac{(x^2+y^4)^{1/2}}{2}$$ So this term tends to $0$ when $(x, y)$ tends to $(0, 0)$ . Then I tried to study the other term using the squeeze theorem in this way: $$0\le \left \vert \frac{\sin(|x|^\alpha y)}{(x^2+y^4)^{3/2}} \right\vert \le \left \vert \frac{|x|^\alpha y}{(x^2+(y^2)^2)^{3/2}} \right\vert \le \left \vert \frac{|x|^\alpha y}{(2|x||y|^2)^{3/2}} \right\vert \le \frac{|x|^{\alpha-3/2}}{|y|^2} $$ At this point I thought that if x goes to $0$ faster than y, then the whole thing tends to $0$ : meaning, I set $\alpha - \frac{3}{2} > 2$ and therefore $\alpha > \frac{7}{2}$ . Honestly I see so many possible mistakes in this procedure, but I couldn't find another way to solve this problem, so I'd like to know if this is correct, and if not, how should I have done it?","I have to find out for which this limit equals to : I tried to separate it in two parts: Now the first term doesn't depend on and it is asymptotic to: So this term tends to when tends to . Then I tried to study the other term using the squeeze theorem in this way: At this point I thought that if x goes to faster than y, then the whole thing tends to : meaning, I set and therefore . Honestly I see so many possible mistakes in this procedure, but I couldn't find another way to solve this problem, so I'd like to know if this is correct, and if not, how should I have done it?","\alpha>0 0 \lim\limits_{(x, y) \to (0, 0)}\frac{1+\sin(|x|^\alpha y)-\cos(x^2+y^4)}{(x^2+y^4)^{3/2}} \lim\limits_{(x, y) \to (0, 0)}\frac{1-\cos(x^2+y^4)}{(x^2+y^4)^{3/2}}+\frac{\sin(|x|^\alpha y)}{(x^2+y^4)^{3/2}} \alpha \frac{1-1+\frac{(x^2+y^4)^2}{2}}{(x^2+y^4)^{3/2}}=\frac{(x^2+y^4)^{1/2}}{2} 0 (x, y) (0, 0) 0\le \left \vert \frac{\sin(|x|^\alpha y)}{(x^2+y^4)^{3/2}} \right\vert \le \left \vert \frac{|x|^\alpha y}{(x^2+(y^2)^2)^{3/2}} \right\vert \le \left \vert \frac{|x|^\alpha y}{(2|x||y|^2)^{3/2}} \right\vert \le \frac{|x|^{\alpha-3/2}}{|y|^2}  0 0 \alpha - \frac{3}{2} > 2 \alpha > \frac{7}{2}","['real-analysis', 'limits', 'multivariable-calculus']"
90,How can I find the limit of a multivariable function?,How can I find the limit of a multivariable function?,,"I'm a student that start learning Calculus 3 and I came across this problem: $$\lim_{(x,y)\to (0,0)}\frac{\log\left(x^2+2^{y^2}\right)} {\sqrt{x^2+4y^2}}$$ I need to find the limit. I've tried approaching the origin from the $x$ and $y$ axis: Approaching from the $x$ axis: $$\lim_{(x,0)\to (0,0)}\frac{\log\left(x^2+1\right)} {\sqrt{x^2}}$$ Use the L'Hopital's rule: $$\lim_{(x,0)\to (0,0)}\frac{\frac{2x}{x^2+1}} {\frac{2x}{2\sqrt{x^2}}}=\lim_{(x,0)\to (0,0)}\frac{2\sqrt{x^2}}{x^2+1}=0$$ Approaching from $y$ axis and use L'Hopital's rule i got: $$\lim_{(0,y)\to (0,0)}\frac{\log\left(2^{y^2}\right)} {\sqrt{4y^2}}=\lim_{(0,y)\to (0,0)}\frac{\frac{y^2\,2^{y^2-1}}{2^{y^2}}} {\frac{8y}{2\sqrt{4y^2}}}=\lim_{(0,y)\to (0,0)}\frac{2^{y^2-1}2\sqrt{4y^2}}{16y}=\pm \frac18$$ This would mean that the limit doesn't exist. But I'm not so sure about the the way I've handled this problem so can you tell me if I made a mistake somewhere and is there another way to solve problem like this one?",I'm a student that start learning Calculus 3 and I came across this problem: I need to find the limit. I've tried approaching the origin from the and axis: Approaching from the axis: Use the L'Hopital's rule: Approaching from axis and use L'Hopital's rule i got: This would mean that the limit doesn't exist. But I'm not so sure about the the way I've handled this problem so can you tell me if I made a mistake somewhere and is there another way to solve problem like this one?,"\lim_{(x,y)\to (0,0)}\frac{\log\left(x^2+2^{y^2}\right)} {\sqrt{x^2+4y^2}} x y x \lim_{(x,0)\to (0,0)}\frac{\log\left(x^2+1\right)} {\sqrt{x^2}} \lim_{(x,0)\to (0,0)}\frac{\frac{2x}{x^2+1}} {\frac{2x}{2\sqrt{x^2}}}=\lim_{(x,0)\to (0,0)}\frac{2\sqrt{x^2}}{x^2+1}=0 y \lim_{(0,y)\to (0,0)}\frac{\log\left(2^{y^2}\right)} {\sqrt{4y^2}}=\lim_{(0,y)\to (0,0)}\frac{\frac{y^2\,2^{y^2-1}}{2^{y^2}}} {\frac{8y}{2\sqrt{4y^2}}}=\lim_{(0,y)\to (0,0)}\frac{2^{y^2-1}2\sqrt{4y^2}}{16y}=\pm \frac18","['calculus', 'limits', 'multivariable-calculus']"
91,Line integral of closed and otherwise non-intersecting curves on a cylindric surface,Line integral of closed and otherwise non-intersecting curves on a cylindric surface,,"In my multi variable/vector calculus textbook I encountered a problem which led to more questions than answers when i solved it. Let me start by stateing the problem: The problem Let $\gamma$ be a curve on the cylinder surface $x^2+y^2=1$ . $\gamma$ is closed but otherwise it does not intersect with it self. Let $\mathbf{F}=(x+y,2yz,y^2)$ be a vector field. Show that $\oint_\gamma \mathbf{F}\bullet d\mathbf{r}$ only can take on 3 different values depending on how $\gamma$ runs along the cylinder surface. Determine these values and describe the different cases. My attempt and initial thoughts My inital thought was: How many types of closed curves can there be on a cylindric surface given the conditions. The intersect between the cylinder and a plane could give $\gamma$ either as a circle or a ellipse and still be closed. A plane $\Pi : ax+by+cz=d$ where c=0 cannot as I see it give a closed curve $\gamma$ . I also thought about how different geometric shapes could intersect with the cylinder and give a closed curve, spheres e.t.c. But I decided to start by just examine the case of a plane intersecting the cylinder. Let $\Pi$ be the plane $ax+by+cz=d$ with $a,b,c\in\mathbb{R}$ and where $x^2+y^2\leq 1$ . Let $\gamma$ be the intersect curve between the cylinder $x^2+y^2=1$ and $\Pi$ . Then the unit normal of $\Pi$ is $\mathbf{N}=\frac{(a,b,c)}{\sqrt{a^2+b^2+c^2}}$ . In preperation I calculated $\text{curl}(\mathbf{F})=\nabla \times\mathbf{F}=(0,0,-1)$ By Stoke´s theorem: $$\oint_\gamma \mathbf{F}\bullet d \mathbf{r}=\iint_\Pi (\nabla \times\mathbf{F})\bullet\mathbf{N} dS=\frac{-c}{\sqrt{a^2+b^2+c^2}}\iint_\Pi dS=\frac{-c}{\sqrt{a^2+b^2+c^2}}\mu (\Pi)$$ Where $\mu (\Pi)$ is the area of $\Pi$ I then proceed to calculate this area, interpreting the plane as a equipotential surface of $f(x,y)=\frac{d-ax-by}{c}$ , where $x^2+y^2\leq 1$ . Then: $$\mu (\Pi)=\iint_{x^2+y^2\leq 1} \sqrt{1+(f^´_x)^2+(f^´_y)^2}dxdy=\iint_{x^2+y^2\leq 1} \sqrt{1+(\frac{-a}{c})^2+(c{-b}{c})^2}dxdy=\iint_{x^2+y^2\leq 1} \frac{\sqrt{a^2+b^2+c^2}}{|c|}dxdy=\frac{\sqrt{a^2+b^2+c^2}}{|c|} \int_{0}^{2\pi}\int_{0}^{1} rdrd\theta=\ldots=\frac{\pi\sqrt{a^2+b^2+c^2}}{|c|}$$ Then: $$W=\oint_\gamma\mathbf{F}\bullet d\mathbf{r}=\frac{-c\pi}{|c|}$$ Thus: $c>0$ then $\gamma$ has negative orientation around the z-axis and $W=-\pi$ $c=0$ then $\gamma$ does not go around the z-axis and $W=0$ $c<0$ then $\gamma$ has positive orientation around the z-axis and $W=\pi$ Textbook answer sheet $\gamma$ has negative orientation around the z-axis and $W=-\pi$ $\gamma$ does not go around the z-axis and $W=0$ $\gamma$ has positive orientation around the z-axis and $W=\pi$ Questions First of the answer in the textbook is clearly not the same as mine but quite simular, why do they dont have c in their answer? Then, the first and the third case makes sense to me given the problem statement, but second as I meantioned earlier does not. Am I wrong if I think that if $c=0$ then $\gamma$ would just be two straight lines on the of the cylinder? And in the bigger picture, to me it didn´t seem like I covered all possible curves given the conditions. Did I? And if not which most probabilly is the case, how would I do it? For example consider the intersection of the cylinder and the sphere $(x-\frac{1}{2})^2+y^2+z^2=1$ . This is my first post ever and I hope I have been clear and thorough:)","In my multi variable/vector calculus textbook I encountered a problem which led to more questions than answers when i solved it. Let me start by stateing the problem: The problem Let be a curve on the cylinder surface . is closed but otherwise it does not intersect with it self. Let be a vector field. Show that only can take on 3 different values depending on how runs along the cylinder surface. Determine these values and describe the different cases. My attempt and initial thoughts My inital thought was: How many types of closed curves can there be on a cylindric surface given the conditions. The intersect between the cylinder and a plane could give either as a circle or a ellipse and still be closed. A plane where c=0 cannot as I see it give a closed curve . I also thought about how different geometric shapes could intersect with the cylinder and give a closed curve, spheres e.t.c. But I decided to start by just examine the case of a plane intersecting the cylinder. Let be the plane with and where . Let be the intersect curve between the cylinder and . Then the unit normal of is . In preperation I calculated By Stoke´s theorem: Where is the area of I then proceed to calculate this area, interpreting the plane as a equipotential surface of , where . Then: Then: Thus: then has negative orientation around the z-axis and then does not go around the z-axis and then has positive orientation around the z-axis and Textbook answer sheet has negative orientation around the z-axis and does not go around the z-axis and has positive orientation around the z-axis and Questions First of the answer in the textbook is clearly not the same as mine but quite simular, why do they dont have c in their answer? Then, the first and the third case makes sense to me given the problem statement, but second as I meantioned earlier does not. Am I wrong if I think that if then would just be two straight lines on the of the cylinder? And in the bigger picture, to me it didn´t seem like I covered all possible curves given the conditions. Did I? And if not which most probabilly is the case, how would I do it? For example consider the intersection of the cylinder and the sphere . This is my first post ever and I hope I have been clear and thorough:)","\gamma x^2+y^2=1 \gamma \mathbf{F}=(x+y,2yz,y^2) \oint_\gamma \mathbf{F}\bullet d\mathbf{r} \gamma \gamma \Pi : ax+by+cz=d \gamma \Pi ax+by+cz=d a,b,c\in\mathbb{R} x^2+y^2\leq 1 \gamma x^2+y^2=1 \Pi \Pi \mathbf{N}=\frac{(a,b,c)}{\sqrt{a^2+b^2+c^2}} \text{curl}(\mathbf{F})=\nabla \times\mathbf{F}=(0,0,-1) \oint_\gamma \mathbf{F}\bullet d \mathbf{r}=\iint_\Pi (\nabla \times\mathbf{F})\bullet\mathbf{N} dS=\frac{-c}{\sqrt{a^2+b^2+c^2}}\iint_\Pi dS=\frac{-c}{\sqrt{a^2+b^2+c^2}}\mu (\Pi) \mu (\Pi) \Pi f(x,y)=\frac{d-ax-by}{c} x^2+y^2\leq 1 \mu (\Pi)=\iint_{x^2+y^2\leq 1} \sqrt{1+(f^´_x)^2+(f^´_y)^2}dxdy=\iint_{x^2+y^2\leq 1} \sqrt{1+(\frac{-a}{c})^2+(c{-b}{c})^2}dxdy=\iint_{x^2+y^2\leq 1} \frac{\sqrt{a^2+b^2+c^2}}{|c|}dxdy=\frac{\sqrt{a^2+b^2+c^2}}{|c|} \int_{0}^{2\pi}\int_{0}^{1} rdrd\theta=\ldots=\frac{\pi\sqrt{a^2+b^2+c^2}}{|c|} W=\oint_\gamma\mathbf{F}\bullet d\mathbf{r}=\frac{-c\pi}{|c|} c>0 \gamma W=-\pi c=0 \gamma W=0 c<0 \gamma W=\pi \gamma W=-\pi \gamma W=0 \gamma W=\pi c=0 \gamma (x-\frac{1}{2})^2+y^2+z^2=1","['multivariable-calculus', 'analytic-geometry', 'vector-analysis']"
92,what does $\frac{\partial}{\partial x}$ means without the f ( $\frac{\partial f}{\partial x}$),what does  means without the f ( ),\frac{\partial}{\partial x} \frac{\partial f}{\partial x},"I was reading in calculus 3 book , but I am stuck here I don't understand what $\frac{\partial}{\partial x}$ means (I know it is partial derivative but I don't know what it means without f like $\frac{\partial f}{\partial x}$ ) and I don't understand how does $\frac{\partial}{\partial x}*Q=\frac{\partial Q}{\partial x}$ and what does $\nabla $ means without any function ? It is like multiplying a number with a sign, which doesn't make any sense I heard from 3b1b video that this is not only a notional trick but there is a relation between curl and cross product but I didn't understand what he means it is in this video at 11:00","I was reading in calculus 3 book , but I am stuck here I don't understand what means (I know it is partial derivative but I don't know what it means without f like ) and I don't understand how does and what does means without any function ? It is like multiplying a number with a sign, which doesn't make any sense I heard from 3b1b video that this is not only a notional trick but there is a relation between curl and cross product but I didn't understand what he means it is in this video at 11:00",\frac{\partial}{\partial x} \frac{\partial f}{\partial x} \frac{\partial}{\partial x}*Q=\frac{\partial Q}{\partial x} \nabla ,"['calculus', 'multivariable-calculus', 'vectors']"
93,Help - calculation of a multivariable limit,Help - calculation of a multivariable limit,,"Can we prove that $  \displaystyle \lim_{(x,y) \to (0,0)}\frac{x^2 y^2(y-x)}{x^3+y^3}=0$ without using $\epsilon - \delta$ definition? My original idea was to use polar coordinates: $x=r\cos\theta$ , $y=r\sin\theta$ . Then : $$\lim_{ r\to 0^+}\frac{r^5( \cos^2\theta \sin^2\theta)(\sin\theta -\cos\theta)}{r^3(\cos^3\theta+\sin^3\theta)} = \lim_{r \to 0^+} r^2\frac{( \cos^2\theta \sin^2\theta)(\sin\theta -\cos\theta)}{\cos^3\theta+\sin^3\theta}.$$ Now i think the problem is that the expression inside the limit isnt bounded ( for $\theta= -\pi/4 \rightarrow \infty$ ).","Can we prove that without using definition? My original idea was to use polar coordinates: , . Then : Now i think the problem is that the expression inside the limit isnt bounded ( for ).","  \displaystyle \lim_{(x,y) \to (0,0)}\frac{x^2 y^2(y-x)}{x^3+y^3}=0 \epsilon - \delta x=r\cos\theta y=r\sin\theta \lim_{ r\to 0^+}\frac{r^5( \cos^2\theta \sin^2\theta)(\sin\theta -\cos\theta)}{r^3(\cos^3\theta+\sin^3\theta)} = \lim_{r \to 0^+} r^2\frac{( \cos^2\theta \sin^2\theta)(\sin\theta -\cos\theta)}{\cos^3\theta+\sin^3\theta}. \theta= -\pi/4 \rightarrow \infty",['limits']
94,How to use Lagrange's multipliers to solve a problem?,How to use Lagrange's multipliers to solve a problem?,,"A carpenter wants to manufacture a box with a volume of $1 \text{m}^3$ . The box has sides parallel to the coordinate plane, and the side lengths are given by $x$ , $y$ , and $z$ , where $0 \leq x \leq 10$ , $0 \leq y \leq 10$ , and $0 \leq z \leq 10$ . The front and top sides of the box will be made of an expensive type of wood that costs $900$ per $\text{m}^2$ , while the bottom and other sides will be made of a cheaper type of wood that costs $300$ per $\text{m}^2$ . The carpenter wants to choose the side lengths to minimize the cost. a) Formulate the carpenter's problem mathematically as a minimization problem with constraints. b) Use the Lagrange multiplier method to solve the minimization problem in part (a) of the question. No points will be awarded for using other methods. A) : $$f(x,y,z) = 1200xz+1200xy+600yz$$ $$g(x,y,z) = xyz = 1$$ My expression of the the function was correct but when it comes to the constraints there is something wrong. B) Here I used my constraint and function and used Lagrange multipliers to get: $$x= 2^{-\frac23}$$ $$y= 2^{\frac13}$$ $$z= 2^{\frac13}$$ $$f(x,y,z) = 1800 \times 2^{\frac23} $$ So far I'm correct and I thought it was the answer but they continued in the answers They said: Here we have to check edge points, i.e. $x = 10, y = 10 or z = 10. If x = 10$ , then we get minimization problems. After this they did a computation that took over one page to complete but I couldn't understand anything because I'm totally confused. Why aren't we done where I was ""done""? What is my constraint to begin with? What is the point of $0 \leq x \leq 10$ , $0 \leq y \leq 10$ , and $0 \leq z \leq 10$ ?","A carpenter wants to manufacture a box with a volume of . The box has sides parallel to the coordinate plane, and the side lengths are given by , , and , where , , and . The front and top sides of the box will be made of an expensive type of wood that costs per , while the bottom and other sides will be made of a cheaper type of wood that costs per . The carpenter wants to choose the side lengths to minimize the cost. a) Formulate the carpenter's problem mathematically as a minimization problem with constraints. b) Use the Lagrange multiplier method to solve the minimization problem in part (a) of the question. No points will be awarded for using other methods. A) : My expression of the the function was correct but when it comes to the constraints there is something wrong. B) Here I used my constraint and function and used Lagrange multipliers to get: So far I'm correct and I thought it was the answer but they continued in the answers They said: Here we have to check edge points, i.e. , then we get minimization problems. After this they did a computation that took over one page to complete but I couldn't understand anything because I'm totally confused. Why aren't we done where I was ""done""? What is my constraint to begin with? What is the point of , , and ?","1 \text{m}^3 x y z 0 \leq x \leq 10 0 \leq y \leq 10 0 \leq z \leq 10 900 \text{m}^2 300 \text{m}^2 f(x,y,z) = 1200xz+1200xy+600yz g(x,y,z) = xyz = 1 x= 2^{-\frac23} y= 2^{\frac13} z= 2^{\frac13} f(x,y,z) = 1800 \times 2^{\frac23}  x = 10, y = 10 or z = 10. If x = 10 0 \leq x \leq 10 0 \leq y \leq 10 0 \leq z \leq 10","['calculus', 'multivariable-calculus', 'optimization', 'partial-derivative', 'lagrange-multiplier']"
95,How to change from cartesian coordinate to cylindrical coordinates,How to change from cartesian coordinate to cylindrical coordinates,,"Consider the triple integral $$\iiint_{K} \frac{z}{2+ x^2 + y^2} dV$$ , where K is the region defined by $z \geq \sqrt{x^2 + y^2}$ and $x^2 + y^2 + z^2 \leq 9$ . The question then asks me to rewrite the region using cylindrical coordinates which I did but the problem is that my bounds for r is wrong. Here is what I did. $$\vec{r}(r,\theta, z) = (r\cos(\theta),r\sin(\theta), z)$$ $$0\leq r \leq 3$$ $$r\leq z\leq\sqrt{9-r^2}$$ $$0\leq \theta \leq 2\pi$$ The reason why I gave r the bounds it has is because if you see the equation: $$x^2 + y^2 + z^2 \leq 9$$ Here you can see that the radius needs to be less than 3 and then if you look at: $$z \geq \sqrt{x^2 + y^2} \iff 0 \geq x^2 + y^2 - z^2  $$ Here you can see that the radius is greater than $0$ . But is it though? I just assumed because this is not a sphere but a hyperboloid of 2 sheets. But like said the correct bounds for r is $0 \leq r \leq \frac{3}{\sqrt{2}}$ . And I don't see why at all?","Consider the triple integral , where K is the region defined by and . The question then asks me to rewrite the region using cylindrical coordinates which I did but the problem is that my bounds for r is wrong. Here is what I did. The reason why I gave r the bounds it has is because if you see the equation: Here you can see that the radius needs to be less than 3 and then if you look at: Here you can see that the radius is greater than . But is it though? I just assumed because this is not a sphere but a hyperboloid of 2 sheets. But like said the correct bounds for r is . And I don't see why at all?","\iiint_{K} \frac{z}{2+ x^2 + y^2} dV z \geq \sqrt{x^2 + y^2} x^2 + y^2 + z^2 \leq 9 \vec{r}(r,\theta, z) = (r\cos(\theta),r\sin(\theta), z) 0\leq r \leq 3 r\leq z\leq\sqrt{9-r^2} 0\leq \theta \leq 2\pi x^2 + y^2 + z^2 \leq 9 z \geq \sqrt{x^2 + y^2} \iff 0 \geq x^2 + y^2 - z^2   0 0 \leq r \leq \frac{3}{\sqrt{2}}","['calculus', 'multivariable-calculus', 'definite-integrals', 'spherical-coordinates', 'cylindrical-coordinates']"
96,How do I get rid of the $|y-x|$ denominator?,How do I get rid of the  denominator?,|y-x|,"I'm stuck on this problem. I'm trying to prove the limit $\lim_{(x,y)\to(0,1)}\left(\frac{y+x}{y^2-x^2}\right)$ exists from first principles. I have got a value of $1$ for the limit via limit laws, so I know I must work towards that. Here is what I have: $$Let f(x,y)=\frac{y+x}{y^2-x^2}\;and\;\varepsilon > 0$$ $$\therefore f(x,y)-1=\frac{y+x}{y^2-x^2}-1$$ $$\therefore |f(x,y)-1|=\left|\frac{1}{y-x}-\frac{y-x}{y-x}\right|=\left|\frac{x-(y-1)}{y-x}\right|=\frac{|x-(y-1)|}{|y-x|}\le\frac{|x|+|y-1|}{|y-x|}$$ If $|y-x| \ge 1$ then I can remove the denominator without changing the inequality. In that case, I can prove the required limit exists. However, for $|y-x|<1$ , I can't do that. How should I proceed from here to complete the proof that the limit is 1?","I'm stuck on this problem. I'm trying to prove the limit exists from first principles. I have got a value of for the limit via limit laws, so I know I must work towards that. Here is what I have: If then I can remove the denominator without changing the inequality. In that case, I can prove the required limit exists. However, for , I can't do that. How should I proceed from here to complete the proof that the limit is 1?","\lim_{(x,y)\to(0,1)}\left(\frac{y+x}{y^2-x^2}\right) 1 Let f(x,y)=\frac{y+x}{y^2-x^2}\;and\;\varepsilon > 0 \therefore f(x,y)-1=\frac{y+x}{y^2-x^2}-1 \therefore |f(x,y)-1|=\left|\frac{1}{y-x}-\frac{y-x}{y-x}\right|=\left|\frac{x-(y-1)}{y-x}\right|=\frac{|x-(y-1)|}{|y-x|}\le\frac{|x|+|y-1|}{|y-x|} |y-x| \ge 1 |y-x|<1","['limits', 'multivariable-calculus']"
97,"Function $g$ has all directional derivatives at $(0,0)$",Function  has all directional derivatives at,"g (0,0)","Let $g:\mathbb{R}^2\longrightarrow\mathbb{R}$ be the function defined by $$g(x,y)=\begin{cases} \frac{x|y|}{\sqrt{x^2+y^2}} & \text{for } (x,y)\neq(0,0)\\ 0 & \text{for } (x,y)=(0,0) \end{cases}$$ Prove that all directional derivatives of $g$ exist at $(0,0)$ , but $g$ is not differentiable at $(0,0)$ . Problem/Approach: I have already proven that $g$ is not differentiable at $(0,0)$ . I am struggling with the directional derivatives at $(0,0)$ . If $v=(0,0)$ , then it immediately follows that $\nabla_v f(x_0)=0$ . For any vector $v=\begin{pmatrix}v_1\\v_2\end{pmatrix}\in\mathbb{R}^2$ and $\|v\|=1$ with $v\neq(0,0)$ , we have: \begin{align*} \nabla_a f(0,0)&=\lim_{h\rightarrow 0}\frac{f(0+hv)-f(0,0)}{hv_1|v_2|}\\ &=\lim_{h\rightarrow 0}\frac{\sqrt{(hv_1)^2+(hv_2)^2}}{h}\\ &=\lim_{h\rightarrow 0}\frac{hv_1|v_2|}{\sqrt{(hv_1)^2+(hv_2)^2}h}\\ &=\lim_{h\rightarrow 0}\frac{v_1|v_2|}{\sqrt{v_1^2+v_2^2}h}\\(*) &=\lim_{h\rightarrow 0}\frac{v_1|v_2|}{h}\\  &=\lim_{h\rightarrow 0}v_1|v_2|\\ &=v_1|v_2|=0\quad\Longleftrightarrow v_1=0\vee v_2=0 \end{align*} In (*), I referred to $h>0$ . It all seems very artificial to me, and I have to consider many cases, which makes me doubt whether $g$ has directional derivatives everywhere at $(0,0)$ at all. What am I doing wrong? Thanks for any help!","Let be the function defined by Prove that all directional derivatives of exist at , but is not differentiable at . Problem/Approach: I have already proven that is not differentiable at . I am struggling with the directional derivatives at . If , then it immediately follows that . For any vector and with , we have: In (*), I referred to . It all seems very artificial to me, and I have to consider many cases, which makes me doubt whether has directional derivatives everywhere at at all. What am I doing wrong? Thanks for any help!","g:\mathbb{R}^2\longrightarrow\mathbb{R} g(x,y)=\begin{cases}
\frac{x|y|}{\sqrt{x^2+y^2}} & \text{for } (x,y)\neq(0,0)\\
0 & \text{for } (x,y)=(0,0)
\end{cases} g (0,0) g (0,0) g (0,0) (0,0) v=(0,0) \nabla_v f(x_0)=0 v=\begin{pmatrix}v_1\\v_2\end{pmatrix}\in\mathbb{R}^2 \|v\|=1 v\neq(0,0) \begin{align*}
\nabla_a f(0,0)&=\lim_{h\rightarrow 0}\frac{f(0+hv)-f(0,0)}{hv_1|v_2|}\\
&=\lim_{h\rightarrow 0}\frac{\sqrt{(hv_1)^2+(hv_2)^2}}{h}\\
&=\lim_{h\rightarrow 0}\frac{hv_1|v_2|}{\sqrt{(hv_1)^2+(hv_2)^2}h}\\
&=\lim_{h\rightarrow 0}\frac{v_1|v_2|}{\sqrt{v_1^2+v_2^2}h}\\(*)
&=\lim_{h\rightarrow 0}\frac{v_1|v_2|}{h}\\ 
&=\lim_{h\rightarrow 0}v_1|v_2|\\
&=v_1|v_2|=0\quad\Longleftrightarrow v_1=0\vee v_2=0
\end{align*} h>0 g (0,0)","['calculus', 'multivariable-calculus', 'derivatives', 'partial-derivative', 'vector-analysis']"
98,How to solve $\frac{\partial^2\Psi}{\partial x^2} + \frac{1}{1+t}\Psi = \frac{\partial \Psi}{\partial t}$?,How to solve ?,\frac{\partial^2\Psi}{\partial x^2} + \frac{1}{1+t}\Psi = \frac{\partial \Psi}{\partial t},"Is there a solution using $\Psi(x,t)$ such that $$\frac{\partial^2\Psi}{\partial x^2} + \frac{1}{1+t}\Psi = \frac{\partial \Psi}{\partial t}$$ ? I have tried $\Psi=te^xe^t$ , $\Psi=te^xe^{t^2}$ and other similar variations, but could not get the powers of $x$ and $t$ to agree on both sides of the equation. Is there a general method to solve this type of differential equation in 2 variables?","Is there a solution using such that ? I have tried , and other similar variations, but could not get the powers of and to agree on both sides of the equation. Is there a general method to solve this type of differential equation in 2 variables?","\Psi(x,t) \frac{\partial^2\Psi}{\partial x^2} + \frac{1}{1+t}\Psi = \frac{\partial \Psi}{\partial t} \Psi=te^xe^t \Psi=te^xe^{t^2} x t","['multivariable-calculus', 'partial-differential-equations']"
99,Numerical derivative of a matrix with respect to a vector,Numerical derivative of a matrix with respect to a vector,,"I have an expression $$ \mathbf{A}\mathbf{s} $$ where $\mathbf{A}$ is an $n \times n$ matrix and $\mathbf{s}$ is a $n \times 1$ vector. The matrix $\mathbf{A}$ is itself a function of $\mathbf{s}$ $$ \mathbf{A} = \mathbf{f}(\mathbf{s})$$ I am wondering how I firstly, compute the derivative of this expression and secondly, numerically estimate the derivative at some vector $\mathbf{s}_0$ . My attempt has been to apply the product rule in some way $$ \frac{d}{d\mathbf{s}} \mathbf{f}(\mathbf{s})\mathbf{s} = \mathbf{f}(\mathbf{s}) + \mathbf{f}'(\mathbf{s})\mathbf{s} $$ noting that $\mathbf{f}'(\mathbf{s})$ is a $(n \times n) \times n$ matrix so that the derivative above is a matrix of dimension $n \times n$ if we consider the term $\mathbf{f}'(\mathbf{s})\mathbf{s}$ as an $n \times n$ matrix expressed with its columns placed below each other. I am not completely sure whether my approach is correct and additionally, how to proceed from here in terms of numerically evaluating this derivative at a particular vector. I plan to use Matlab to compute a numerical derivative. Any assistance or input would be greatly appreciated!","I have an expression where is an matrix and is a vector. The matrix is itself a function of I am wondering how I firstly, compute the derivative of this expression and secondly, numerically estimate the derivative at some vector . My attempt has been to apply the product rule in some way noting that is a matrix so that the derivative above is a matrix of dimension if we consider the term as an matrix expressed with its columns placed below each other. I am not completely sure whether my approach is correct and additionally, how to proceed from here in terms of numerically evaluating this derivative at a particular vector. I plan to use Matlab to compute a numerical derivative. Any assistance or input would be greatly appreciated!"," \mathbf{A}\mathbf{s}
 \mathbf{A} n \times n \mathbf{s} n \times 1 \mathbf{A} \mathbf{s}  \mathbf{A} = \mathbf{f}(\mathbf{s}) \mathbf{s}_0  \frac{d}{d\mathbf{s}} \mathbf{f}(\mathbf{s})\mathbf{s} = \mathbf{f}(\mathbf{s}) + \mathbf{f}'(\mathbf{s})\mathbf{s}  \mathbf{f}'(\mathbf{s}) (n \times n) \times n n \times n \mathbf{f}'(\mathbf{s})\mathbf{s} n \times n","['linear-algebra', 'matrices', 'multivariable-calculus', 'numerical-methods', 'matrix-calculus']"
