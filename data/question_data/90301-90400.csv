,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Compact Hermitian Operator, closed range implies finite rank","Compact Hermitian Operator, closed range implies finite rank",,"Let $K$ be a compact Hermitian operator on a Hilbert space $H$. How to show that if $K$ has infinite rank then the range of $K$ is not closed in $H$? My thought is that suppose range $K$ is closed in $H$ and then we need to prove that $K$ has finite rank. So far I think that spectral theorem can be applied. I want to find contradiction to compactness, but I still have no idea. Thank you for your help.","Let $K$ be a compact Hermitian operator on a Hilbert space $H$. How to show that if $K$ has infinite rank then the range of $K$ is not closed in $H$? My thought is that suppose range $K$ is closed in $H$ and then we need to prove that $K$ has finite rank. So far I think that spectral theorem can be applied. I want to find contradiction to compactness, but I still have no idea. Thank you for your help.",,['functional-analysis']
1,Convolution on noncommutative group algebras,Convolution on noncommutative group algebras,,"If $G$ is a non-Abelian locally compact group, and $f$ is in $L^1{(G)}$ and $u$ is in $L^{\infty}(G)$, and $f\ast u=0$ can it be concluded that $u\ast f=0$?","If $G$ is a non-Abelian locally compact group, and $f$ is in $L^1{(G)}$ and $u$ is in $L^{\infty}(G)$, and $f\ast u=0$ can it be concluded that $u\ast f=0$?",,"['functional-analysis', 'harmonic-analysis', 'convolution']"
2,MacCluer Exercise 3.2,MacCluer Exercise 3.2,,"In MacCluer's Elementary Functional Analysis, exercise 3.2 states: We introduce some terminology for the purpose of this problem: If $X$ is either a real or complex vector space (meaning that the scalars used in scalar multiplication are real, or, respectively, complex), we say that a real-valued $\phi$ is a real-linear functional if $\phi(x + y) = \phi(x)+ \phi(y)$ and $\phi(\alpha x) = \alpha\phi(x)$ holds for all $x,y \in X$ and $\alpha$ real. For $X$ a complex vector space, we say that (a complex-valued) $\phi$ is a complex linear functional if these relationships hold for all $x,y\in X$ and $\alpha$ complex. (c) Suppose $u$ is a real-linear functional on $X$ . Define $\phi : X \rightarrow \mathbb{C}$ by $\phi(x) = u(x)−iu(ix)$ . Show that $\phi$ is a complex-linear functional on $X$ . (d) Now suppose $X$ is a normed linear space. For $\phi$ and $u$ related as above, show that $\vert\vert \phi \vert\vert $ = $\vert\vert u\vert\vert$ . I am confused by part d): why $\vert\vert \phi \vert\vert $ = $\vert\vert u\vert\vert$ . From my understanding, since $u$ is a real valued functional, we ought to have $$\vert\vert \phi(x)\vert\vert = \vert\vert u(x) - i u(ix)\vert \vert = \sqrt{\vert u(x)\vert^2 + \vert u(ix)\vert^2} \geq \vert u(x) \vert,$$ which means the only possible way for $\vert\vert \phi \vert\vert $ = $\vert\vert u\vert\vert$ is when $\vert\vert\phi(x)\vert\vert$ approaches $\vert\vert \phi\vert\vert$ implies $u(ix)$ approaches $0$ . However, I don't see why this should be true - is there any mistake in my reasoning or any way to prove this?","In MacCluer's Elementary Functional Analysis, exercise 3.2 states: We introduce some terminology for the purpose of this problem: If is either a real or complex vector space (meaning that the scalars used in scalar multiplication are real, or, respectively, complex), we say that a real-valued is a real-linear functional if and holds for all and real. For a complex vector space, we say that (a complex-valued) is a complex linear functional if these relationships hold for all and complex. (c) Suppose is a real-linear functional on . Define by . Show that is a complex-linear functional on . (d) Now suppose is a normed linear space. For and related as above, show that = . I am confused by part d): why = . From my understanding, since is a real valued functional, we ought to have which means the only possible way for = is when approaches implies approaches . However, I don't see why this should be true - is there any mistake in my reasoning or any way to prove this?","X \phi \phi(x + y) = \phi(x)+ \phi(y) \phi(\alpha x) = \alpha\phi(x) x,y \in X \alpha X \phi x,y\in X \alpha u X \phi : X \rightarrow \mathbb{C} \phi(x) =
u(x)−iu(ix) \phi X X \phi u \vert\vert \phi \vert\vert  \vert\vert u\vert\vert \vert\vert \phi \vert\vert  \vert\vert u\vert\vert u \vert\vert \phi(x)\vert\vert = \vert\vert u(x) - i u(ix)\vert \vert = \sqrt{\vert u(x)\vert^2 + \vert u(ix)\vert^2} \geq \vert u(x) \vert, \vert\vert \phi \vert\vert  \vert\vert u\vert\vert \vert\vert\phi(x)\vert\vert \vert\vert \phi\vert\vert u(ix) 0",['functional-analysis']
3,Is it really true that $\mathcal{S}(\mathbb{R}^n)$ is identified with smooth functions on $S^n$ vanishing at a fixed point?,Is it really true that  is identified with smooth functions on  vanishing at a fixed point?,\mathcal{S}(\mathbb{R}^n) S^n,"Let $\mathcal{S}(\mathbb{R}^n)$ be the Schwartz space on $\mathbb{R}^n$ and $C^\infty(S^n)$ be the space of smooth functions on $n$ -sphere. Now fix a point $x \in S^n$ and define \begin{equation} C^\infty_x(S^n) := \{ f \in C^\infty(S^n) \mid f(x)=0\} \end{equation} Then I heard that $\mathcal{S}(\mathbb{R}^n)$ may be identified with $C^\infty_x(S^n)$ . That is, a Schwartz function is one extending smoothly to $S^n$ while vanishing at infinity. However, I wonder why we need such a strong decay condition of Schwartz functions to extend it smoothly to $S^n$ ? Could anyone please clarify for me?","Let be the Schwartz space on and be the space of smooth functions on -sphere. Now fix a point and define Then I heard that may be identified with . That is, a Schwartz function is one extending smoothly to while vanishing at infinity. However, I wonder why we need such a strong decay condition of Schwartz functions to extend it smoothly to ? Could anyone please clarify for me?","\mathcal{S}(\mathbb{R}^n) \mathbb{R}^n C^\infty(S^n) n x \in S^n \begin{equation}
C^\infty_x(S^n) := \{ f \in C^\infty(S^n) \mid f(x)=0\}
\end{equation} \mathcal{S}(\mathbb{R}^n) C^\infty_x(S^n) S^n S^n","['functional-analysis', 'smooth-manifolds', 'smooth-functions', 'schwartz-space', 'compact-manifolds']"
4,Ask a question on adjoint operator?,Ask a question on adjoint operator?,,"Let $H_1,H_2$ be Hilbert spaces with inner products $\langle \cdot, \cdot \rangle_1$ and $\langle \cdot, \cdot \rangle_2$ . Corresponding to every $T \in \mathcal B(H_1,H_2)$ , there is a unique element $T^*$ of $B(H_2,H_1)$ determined by the relation $$\langle T x_1,  x_2 \rangle_2=\langle x_1, T^* x_2 \rangle_1$$ for all $x_1 \in H_1, x_2 \in H_2$ . Proof: Consider $\langle T x_1,  x_2 \rangle_2$ as a function of $x_1$ for fixed $x_2$ . It is bounded and linear so that the Riesz representation theorem may be applied to see that there exists a unique $y \in H_1$ such that $\langle T x_1,  x_2 \rangle_2=\langle x_1, y \rangle_1$ . Thus, we take $T^* x_2=y$ . This definition gives us a linear mapping. To see that it bounded first note that $T$ is necessarily the adjoint of $T^*$ . Then $$|| T^* x_2 ||^2_1=   |       \langle      x_2，T  T^*    x_2 \rangle_2  |$$ $$\leq ||T||   || T^* x_2 ||_1   ||x_2||_2$$ Question: Why $|| T^* x_2 ||^2_1=   |       \langle      x_2，T  T^*    x_2 \rangle_2  |$ ?","Let be Hilbert spaces with inner products and . Corresponding to every , there is a unique element of determined by the relation for all . Proof: Consider as a function of for fixed . It is bounded and linear so that the Riesz representation theorem may be applied to see that there exists a unique such that . Thus, we take . This definition gives us a linear mapping. To see that it bounded first note that is necessarily the adjoint of . Then Question: Why ?","H_1,H_2 \langle \cdot, \cdot \rangle_1 \langle \cdot, \cdot \rangle_2 T \in \mathcal B(H_1,H_2) T^* B(H_2,H_1) \langle T x_1,  x_2 \rangle_2=\langle x_1, T^* x_2 \rangle_1 x_1 \in H_1, x_2 \in H_2 \langle T x_1,  x_2 \rangle_2 x_1 x_2 y \in H_1 \langle T x_1,  x_2 \rangle_2=\langle x_1, y \rangle_1 T^* x_2=y T T^* || T^* x_2 ||^2_1=   |       \langle      x_2，T  T^*    x_2 \rangle_2  | \leq ||T||   || T^* x_2 ||_1   ||x_2||_2 || T^* x_2 ||^2_1=   |       \langle      x_2，T  T^*    x_2 \rangle_2  |","['functional-analysis', 'proof-explanation', 'adjoint-operators']"
5,Can the definition of almost periodic functions be simplified?,Can the definition of almost periodic functions be simplified?,,"A bounded continuous function $f : \mathbb{R} \to \mathbb{C}$ is almost periodic if for every $\epsilon>0$ , there exists some $L>0$ , such that every interval of $\mathbb{R}$ with length $\ge L$ contains some real number $T$ such that $\Vert f(\cdot+T)-f \Vert_\infty \le \epsilon$ . An equivalent definition is the relative compactness of the set of all functions $f(\cdot+T)$ with $T$ varying in $\mathbb{R}$ in the space of all continuous bounded functions endowed with $\Vert \cdot \Vert_\infty$ . It is necessary to have $$\liminf_{T \to \infty} \Vert f(\cdot+T)-f \Vert_\infty = 0.$$ Is it also sufficient? My thought: the triangle inequality and the invariance of the norm $\Vert \cdot \Vert_\infty$ under translations show that the function $T \mapsto \Vert f(\cdot+T)-f \Vert_\infty$ is sub-additive on $\mathbb{R}_+$ .","A bounded continuous function is almost periodic if for every , there exists some , such that every interval of with length contains some real number such that . An equivalent definition is the relative compactness of the set of all functions with varying in in the space of all continuous bounded functions endowed with . It is necessary to have Is it also sufficient? My thought: the triangle inequality and the invariance of the norm under translations show that the function is sub-additive on .",f : \mathbb{R} \to \mathbb{C} \epsilon>0 L>0 \mathbb{R} \ge L T \Vert f(\cdot+T)-f \Vert_\infty \le \epsilon f(\cdot+T) T \mathbb{R} \Vert \cdot \Vert_\infty \liminf_{T \to \infty} \Vert f(\cdot+T)-f \Vert_\infty = 0. \Vert \cdot \Vert_\infty T \mapsto \Vert f(\cdot+T)-f \Vert_\infty \mathbb{R}_+,"['functional-analysis', 'almost-periodic-functions']"
6,"Given dense $A: X\to X$, is $A^2$ dense?","Given dense , is  dense?",A: X\to X A^2,"Let $A: X\to X$ be a densely defined linear operator acting on Banach Space $X$ . Is $A^2$ also dense? Context: I was trying to think of an alternative proof for the Hille-Yosida theorem - specifically $$R(A, \lambda)\leq\frac{M}{\lambda-\omega} \text{ and } A \text{ dense}\Rightarrow e^{tA} \text{ exists and } e^{tA}\leq Me^{t\omega}$$ Similarly to Rudin's proof (Theorem 13.37 of Functional Analysis ) I first define $S(\varepsilon)=(I-\varepsilon A)^{-1}$ and note $AS(\varepsilon)f=S(\varepsilon)Af$ for $f\in\mathcal{D}(A)$ . I also show $\lim_{\varepsilon\to0}S(\varepsilon)f=f$ for all $f\in X$ . I next consider $T(t,\varepsilon)=\exp(tAS(\varepsilon))$ and show $$\|T(t,\varepsilon)\|\leq M\exp\left(\frac{t\omega}{1-\varepsilon A}\right)$$ My proof then diverges from Rudin's (I didn't really understand it). I wanted to show $T$ was differentiable and therefore continuous, and we could define $Q(t)=\lim_{\varepsilon\to 0}T(t,\varepsilon)$ . Given $f\in\mathcal{D}(A^2)$ we have $$\left\|\frac{\partial}{\partial \varepsilon}T(t,\varepsilon)f\right\|=\left\|-te^{tAS(\varepsilon)}S(\varepsilon)^2A^2f\right\|<\infty$$ then given $A^2$ is dense over $X$ , we can show that $Q(t)$ is well-defined over all of $X$ , is generated by $A$ , and is bounded by $M\exp(\omega t)$ as desired. However, I can't figure out how to prove that $A^2$ must be dense, and I'm not sure if this is the case.","Let be a densely defined linear operator acting on Banach Space . Is also dense? Context: I was trying to think of an alternative proof for the Hille-Yosida theorem - specifically Similarly to Rudin's proof (Theorem 13.37 of Functional Analysis ) I first define and note for . I also show for all . I next consider and show My proof then diverges from Rudin's (I didn't really understand it). I wanted to show was differentiable and therefore continuous, and we could define . Given we have then given is dense over , we can show that is well-defined over all of , is generated by , and is bounded by as desired. However, I can't figure out how to prove that must be dense, and I'm not sure if this is the case.","A: X\to X X A^2 R(A, \lambda)\leq\frac{M}{\lambda-\omega} \text{ and } A \text{ dense}\Rightarrow e^{tA} \text{ exists and } e^{tA}\leq Me^{t\omega} S(\varepsilon)=(I-\varepsilon A)^{-1} AS(\varepsilon)f=S(\varepsilon)Af f\in\mathcal{D}(A) \lim_{\varepsilon\to0}S(\varepsilon)f=f f\in X T(t,\varepsilon)=\exp(tAS(\varepsilon)) \|T(t,\varepsilon)\|\leq M\exp\left(\frac{t\omega}{1-\varepsilon A}\right) T Q(t)=\lim_{\varepsilon\to 0}T(t,\varepsilon) f\in\mathcal{D}(A^2) \left\|\frac{\partial}{\partial \varepsilon}T(t,\varepsilon)f\right\|=\left\|-te^{tAS(\varepsilon)}S(\varepsilon)^2A^2f\right\|<\infty A^2 X Q(t) X A M\exp(\omega t) A^2","['functional-analysis', 'analysis', 'banach-spaces', 'semigroup-of-operators']"
7,"If whenever $\psi_n\rightharpoonup 0$, $A\psi_n \rightharpoonup 0$ then $A$ is bounded.","If whenever ,  then  is bounded.",\psi_n\rightharpoonup 0 A\psi_n \rightharpoonup 0 A,"This if from a previous Princeton exam on functional analysis Let $A$ be a linear operator $A: X\rightarrow Y$ between normed vector spaces. If $\psi_n\rightharpoonup 0$ implies $A\psi_n \rightharpoonup 0$ , then $A$ is bounded. I tried to argue by contradiction. Boundedness is equivalent to continuity at zero, so suppose by way of contradiction that there exists a sequence $\psi_n \rightarrow0$ and $\varepsilon>0$ such that $\lVert A\psi_n\rVert\geq \varepsilon$ . Because $\psi_n\rightharpoonup 0$ this would imply $A\psi_n \rightharpoonup 0$ , in spite of the fact $\lVert A\psi_n\rVert\geq \varepsilon$ . I thought this might yield a contradiction, but then I remembered that $e_n\rightharpoonup0$ in $l_2$ in spite of the fact $\lVert e_n \rVert_\infty =1$ , so this is definitely not the way to go for a contradiction.","This if from a previous Princeton exam on functional analysis Let be a linear operator between normed vector spaces. If implies , then is bounded. I tried to argue by contradiction. Boundedness is equivalent to continuity at zero, so suppose by way of contradiction that there exists a sequence and such that . Because this would imply , in spite of the fact . I thought this might yield a contradiction, but then I remembered that in in spite of the fact , so this is definitely not the way to go for a contradiction.",A A: X\rightarrow Y \psi_n\rightharpoonup 0 A\psi_n \rightharpoonup 0 A \psi_n \rightarrow0 \varepsilon>0 \lVert A\psi_n\rVert\geq \varepsilon \psi_n\rightharpoonup 0 A\psi_n \rightharpoonup 0 \lVert A\psi_n\rVert\geq \varepsilon e_n\rightharpoonup0 l_2 \lVert e_n \rVert_\infty =1,"['functional-analysis', 'weak-convergence']"
8,Split monomorphism and split epimorphisms of Banach spaces,Split monomorphism and split epimorphisms of Banach spaces,,"Consider the category Ban of Banach spaces with linear contractions. I want to find a characterization of the split monomorphisms and of the split epimorphisms in this category, however I couldn't make much progress. I know that every split monomorphism is a monomorphism in any category and in Ban these are precisely the injective morphisms, but it seems that not any injective linear contraction is also a split monomorphism. In fact, I am kind of confused. Let $f:X\to Y$ be an injective linear contraction. Then, we can show that it has a linear left inverse, call it $g:Y\to X$ . Now we have $1_X=g\circ f$ , which implies that $1=||g\circ f||\le ||g||\cdot ||f||\le ||g||$ . I guess that this means that $g$ must have norm $1$ in order for it to be a  contraction. But I don't know what other condition I should impose on $f$ so that such a $g$ exists. Similarly, every split epimorphism is an epimorphism, so this means that every split epimorphism in Ban has a dense image, but again I don't think the converse holds and I don't know how to find what other properties I should add.","Consider the category Ban of Banach spaces with linear contractions. I want to find a characterization of the split monomorphisms and of the split epimorphisms in this category, however I couldn't make much progress. I know that every split monomorphism is a monomorphism in any category and in Ban these are precisely the injective morphisms, but it seems that not any injective linear contraction is also a split monomorphism. In fact, I am kind of confused. Let be an injective linear contraction. Then, we can show that it has a linear left inverse, call it . Now we have , which implies that . I guess that this means that must have norm in order for it to be a  contraction. But I don't know what other condition I should impose on so that such a exists. Similarly, every split epimorphism is an epimorphism, so this means that every split epimorphism in Ban has a dense image, but again I don't think the converse holds and I don't know how to find what other properties I should add.",f:X\to Y g:Y\to X 1_X=g\circ f 1=||g\circ f||\le ||g||\cdot ||f||\le ||g|| g 1 f g,"['functional-analysis', 'category-theory', 'banach-spaces']"
9,How to prove that an absolutely continuous function space on a finite closed interval is a separable space in this norm sense?,How to prove that an absolutely continuous function space on a finite closed interval is a separable space in this norm sense?,,"$\quad$ Let a finite closed interval be $[a,b]$ . Consider the absolutely continuous function space $\mathrm{AC}([a,b])$ on it, with a norm as follows: $$\|f\|_{\mathrm{AC}}=\sup_{x\in[a,b]}|f(x)|+\|f'\|_{\mathcal L^1([a,b])}$$ $\quad$ How to prove that $\mathrm{AC}([a,b],\|\cdot\|_{\mathrm{AC}})$ is separable? $\quad$ I already know that this space is Banach, and I want to find a countable dense subset of it. I've tried using Weierstrass approximation theorem, and found polynomials whose coefficients are rational, but I can't say that $\|f'-p'\|_{\mathcal L^1([a,b])}<\varepsilon$ . Although I know that this is equal to the total variation of a function, it doesn't help a lot. Is there a problem with my direction? If yes, how do you find such a subset?","Let a finite closed interval be . Consider the absolutely continuous function space on it, with a norm as follows: How to prove that is separable? I already know that this space is Banach, and I want to find a countable dense subset of it. I've tried using Weierstrass approximation theorem, and found polynomials whose coefficients are rational, but I can't say that . Although I know that this is equal to the total variation of a function, it doesn't help a lot. Is there a problem with my direction? If yes, how do you find such a subset?","\quad [a,b] \mathrm{AC}([a,b]) \|f\|_{\mathrm{AC}}=\sup_{x\in[a,b]}|f(x)|+\|f'\|_{\mathcal L^1([a,b])} \quad \mathrm{AC}([a,b],\|\cdot\|_{\mathrm{AC}}) \quad \|f'-p'\|_{\mathcal L^1([a,b])}<\varepsilon","['real-analysis', 'functional-analysis', 'separable-spaces', 'absolute-continuity', 'weierstrass-approximation']"
10,Spectrum of a operator in $l^2$,Spectrum of a operator in,l^2,"Given a sequence of number $\{ a_{n}\} $ , define an operator on $l^2$ as follows: $$A\left( x_{1},x_{2},...,x_{n},...\right)  =\left( a_{1}x_{1},a_{2}x_{2},...,a_{n}x_{n},...\right)  $$ If $A$ is a bounded operator, determine the spectral point type of $A$ . My attempt: It's easy to see that $\{ a_{n}\} $ is bounded if $A$ is a bounded operator, but I think this condition is not enough to determine the whole spectrum, it depends on the property of $\{ a_{n}\} $ , for example, $a_{n}=\frac{1}{n} $ , we can determine the whole spectrum.","Given a sequence of number , define an operator on as follows: If is a bounded operator, determine the spectral point type of . My attempt: It's easy to see that is bounded if is a bounded operator, but I think this condition is not enough to determine the whole spectrum, it depends on the property of , for example, , we can determine the whole spectrum.","\{ a_{n}\}  l^2 A\left( x_{1},x_{2},...,x_{n},...\right)  =\left( a_{1}x_{1},a_{2}x_{2},...,a_{n}x_{n},...\right)   A A \{ a_{n}\}  A \{ a_{n}\}  a_{n}=\frac{1}{n} ","['functional-analysis', 'operator-theory', 'spectral-theory']"
11,A doubt on invertibility of a bounded linear operator,A doubt on invertibility of a bounded linear operator,,"Let $C[0,1]$ be the Banach space of real valued continuous functions on $[0,1]$ equipped with the supremum norm. Define $T: C[0,1] \to C[0,1] $ by $$T(f(x))=\int_{0}^{x}xf(t)dt.$$ Let $R(T)$ denote the range of $T.$ Consider the following statements. P: $T$ is a bounded linear operator. Q: $T^{-1}:R(T) \to C[0,1]$ exists and is bounded. My attempt: For any $f \in C[0,1],$ we have that $$ || T(f(x))||=\sup_{x \in [0,1]} \bigg| \int_{0}^{x}xf(t) dt\bigg| \leq \sup_{x \in [0,1]} |f(t)| = ||f||.$$ The inequality in the above equation is because we are dealing with $x \in [0,1].$ So, $T$ is a bounded linear operator. So, statement P is TRUE. As for Q, I shall quote a result. Let $T:X \to Y$ be a linear operator between two normed spaces $X,Y,$ and let $T$ be onto. Then, $T^{-1}$ exits and is continuous if and only if there exists $c>0$ such that $c||x|| \leq ||T(x)||$ for each $x \in X.$ One can easily see that $||T|| \leq 1,$ with equality achieved for $f(x)=1.$ Now, set $X=C[0,1],Y=R(T).$ For, $c=1,$ we have satisfied all properties of the above quoted result. So, $T^{-1}$ exits and it is continuous and consequently bounded. So, statement Q is also TRUE. But the answer key says that P is TRUE and Q is FALSE. I am confused as I think I have applied things correctly. Please help me.","Let be the Banach space of real valued continuous functions on equipped with the supremum norm. Define by Let denote the range of Consider the following statements. P: is a bounded linear operator. Q: exists and is bounded. My attempt: For any we have that The inequality in the above equation is because we are dealing with So, is a bounded linear operator. So, statement P is TRUE. As for Q, I shall quote a result. Let be a linear operator between two normed spaces and let be onto. Then, exits and is continuous if and only if there exists such that for each One can easily see that with equality achieved for Now, set For, we have satisfied all properties of the above quoted result. So, exits and it is continuous and consequently bounded. So, statement Q is also TRUE. But the answer key says that P is TRUE and Q is FALSE. I am confused as I think I have applied things correctly. Please help me.","C[0,1] [0,1] T: C[0,1] \to C[0,1]  T(f(x))=\int_{0}^{x}xf(t)dt. R(T) T. T T^{-1}:R(T) \to C[0,1] f \in C[0,1],  || T(f(x))||=\sup_{x \in [0,1]} \bigg| \int_{0}^{x}xf(t) dt\bigg| \leq \sup_{x \in [0,1]} |f(t)| = ||f||. x \in [0,1]. T T:X \to Y X,Y, T T^{-1} c>0 c||x|| \leq ||T(x)|| x \in X. ||T|| \leq 1, f(x)=1. X=C[0,1],Y=R(T). c=1, T^{-1}",['functional-analysis']
12,Finding two extensions of this linear functional,Finding two extensions of this linear functional,,"Let X := $\mathbb{C}^{3}$ equipped with the norm $|(x, y, z)|_{1} := |x| + |y| + |z|$ and $Y := \{(x, y, z) ∈ X|x + y = 0, z = 0\}$ . Find at least two extensions of $ℓ(x, y, z) := x$ from $Y$ to $X$ which preserve the norm. What if we take $Y := \{(x, y, z) ∈ X|x + y = 0\}$ ? My first approach (I am pretty unfamiliar with extensions of linear functionals, so I try to be as precise as possible): clearly our linear functional $l(x,y,z)$ is bounded since $|l(x,y,z)| = |x| \leq |x| + |y| + |z| = |(x,y,z)|_{1}$ . At this point, we can say that Hahn-Banach tells us that the existence of such an extension (which preserves the norm!) is guaranteed. So, we have $||l|| \leq 1$ . I am a little bit unsure about this point but by taking $y = z = 0$ , we see that we get equality and I think therefore we can conclude that $||l|| = 1$ (even though I am open to more elaborate suggestions about that). Now, my guess would be that $l(x,y,z) = y$ and $l(x,y,z) = z$ are two extensions of $l$ which also should preserve the norm. However, I am not really able to show that. Can anybody help me?","Let X := equipped with the norm and . Find at least two extensions of from to which preserve the norm. What if we take ? My first approach (I am pretty unfamiliar with extensions of linear functionals, so I try to be as precise as possible): clearly our linear functional is bounded since . At this point, we can say that Hahn-Banach tells us that the existence of such an extension (which preserves the norm!) is guaranteed. So, we have . I am a little bit unsure about this point but by taking , we see that we get equality and I think therefore we can conclude that (even though I am open to more elaborate suggestions about that). Now, my guess would be that and are two extensions of which also should preserve the norm. However, I am not really able to show that. Can anybody help me?","\mathbb{C}^{3} |(x, y, z)|_{1} := |x| + |y| + |z| Y := \{(x, y, z) ∈ X|x + y = 0, z = 0\} ℓ(x, y, z) := x Y X Y := \{(x, y, z) ∈ X|x + y = 0\} l(x,y,z) |l(x,y,z)| = |x| \leq |x| + |y| + |z| = |(x,y,z)|_{1} ||l|| \leq 1 y = z = 0 ||l|| = 1 l(x,y,z) = y l(x,y,z) = z l",['functional-analysis']
13,Maximal ideal space of the $n$-dimensional ball algebra,Maximal ideal space of the -dimensional ball algebra,n,"Let $B_n \subset \mathbb{C}^n$ be the $n$ -dimensional open ball of radius $1$ centered at the origin. Let $A$ be the set consisting of holomorphic functions in $B_n$ which are continuous in $\overline{B_n}$ , then $A$ is a Banach space with the sup-norm and pointwise operations. Let $M$ be the maximal ideal space of $A$ , that is, $M$ is the set of non-trivial linear multiplicative functionals in $A$ . I want to prove that $M$ and $\overline{B_n}$ are homeomorphic via point-evaluations. In other words, I want to prove that the map $F: \overline{B_n} \longrightarrow M$ defined by $F(x)(\varphi)=\varphi(x)$ is an homeomorphism. Of course, in order to do so the first step is to prove that $F$ is a bijective function. Clearly $F$ is injective. My idea to prove surjectivity was the following: take any $\varphi \in M$ and let $p(z)=\sum_{|\alpha|=0}^{n}{c_{\alpha} z^{\alpha}}$ be a polynomial (here we're using the multi-index notation). For each $i, 1 \leq i \leq n$ , let $f_i:\overline{B_n} \longrightarrow \mathbb{C}$ be the map defined by $f_{i}(z)=z_i$ , then we can write $p=\sum_{|\alpha|=0}^{n}{c_{\alpha} f^{\alpha}}$ , where $f=(f_1,\ldots,f_n)$ . Therefore, since $\varphi \in M$ we have that $$ \varphi(p)=\sum_{|\alpha|=0}^{n}{c_{\alpha} \varphi(f)^{\alpha}}=p(\varphi(f)) $$ therefore, if I could prove that $\varphi(f)=(\varphi(f_1),\ldots,\varphi(f_n))$ is in $\overline{B_n}$ I would be done proving the surjectivity (since polynomials are dense in $A$ ). Of course, I can see that $|\varphi(f_i)| \leq 1$ but I don't see why would we have that $|\varphi(f)| \leq 1$ . Any suggestion in order to prove that $|\varphi(f)| \leq 1$ ?  Or, if my approach is wrong I would appreciate any hint. In advance thank you very much.","Let be the -dimensional open ball of radius centered at the origin. Let be the set consisting of holomorphic functions in which are continuous in , then is a Banach space with the sup-norm and pointwise operations. Let be the maximal ideal space of , that is, is the set of non-trivial linear multiplicative functionals in . I want to prove that and are homeomorphic via point-evaluations. In other words, I want to prove that the map defined by is an homeomorphism. Of course, in order to do so the first step is to prove that is a bijective function. Clearly is injective. My idea to prove surjectivity was the following: take any and let be a polynomial (here we're using the multi-index notation). For each , let be the map defined by , then we can write , where . Therefore, since we have that therefore, if I could prove that is in I would be done proving the surjectivity (since polynomials are dense in ). Of course, I can see that but I don't see why would we have that . Any suggestion in order to prove that ?  Or, if my approach is wrong I would appreciate any hint. In advance thank you very much.","B_n \subset \mathbb{C}^n n 1 A B_n \overline{B_n} A M A M A M \overline{B_n} F: \overline{B_n} \longrightarrow M F(x)(\varphi)=\varphi(x) F F \varphi \in M p(z)=\sum_{|\alpha|=0}^{n}{c_{\alpha} z^{\alpha}} i, 1 \leq i \leq n f_i:\overline{B_n} \longrightarrow \mathbb{C} f_{i}(z)=z_i p=\sum_{|\alpha|=0}^{n}{c_{\alpha} f^{\alpha}} f=(f_1,\ldots,f_n) \varphi \in M 
\varphi(p)=\sum_{|\alpha|=0}^{n}{c_{\alpha} \varphi(f)^{\alpha}}=p(\varphi(f))
 \varphi(f)=(\varphi(f_1),\ldots,\varphi(f_n)) \overline{B_n} A |\varphi(f_i)| \leq 1 |\varphi(f)| \leq 1 |\varphi(f)| \leq 1","['functional-analysis', 'complex-analysis', 'banach-spaces', 'operator-algebras', 'banach-algebras']"
14,Finite dimensional cokernel of a map coming from a product Fedholm map,Finite dimensional cokernel of a map coming from a product Fedholm map,,"Let $X$ , $Y_1$ , $Y_2$ be Banach spaces (if that helps I will be happy to assume they are Hilbert spaces) and let \begin{align} T_1 : X \rightarrow Y_1, \\ T_2 : X \rightarrow Y_2 \end{align} be bounded linear maps such that $T:= T_1 \times T_2 : X \rightarrow Y_1 \times Y_2$ is a Fredholm map. Is it true that $T_1|_{\ker T_2}$ is also Fredholm? Its kernel is finite-dimensional since it is the kernel of $T$ but why is the cokernel finite-dimensional?","Let , , be Banach spaces (if that helps I will be happy to assume they are Hilbert spaces) and let be bounded linear maps such that is a Fredholm map. Is it true that is also Fredholm? Its kernel is finite-dimensional since it is the kernel of but why is the cokernel finite-dimensional?","X Y_1 Y_2 \begin{align}
T_1 : X \rightarrow Y_1, \\
T_2 : X \rightarrow Y_2
\end{align} T:= T_1 \times T_2 : X \rightarrow Y_1 \times Y_2 T_1|_{\ker T_2} T","['functional-analysis', 'analysis', 'hilbert-spaces', 'banach-spaces']"
15,Brezis' exercise 6.1: a compact operator in $\ell^p$,Brezis' exercise 6.1: a compact operator in,\ell^p,"I'm trying to solve an exercise in Brezis' Functional Analysis Let $E:= \ell^p$ with $p \in [1, \infty]$ . Let $(\lambda_n)$ be a bounded sequence in $\mathbb R$ . We consider a bounded linear operator $T:E \to E$ defined by $$ Tx := (\lambda_1 x_1, \lambda_2 x_2, \ldots),  $$ for $x = (x_1, x_2, \ldots) \in E$ . Prove that $T$ is compact iff $\lambda_n \to 0$ . There are possibly subtle mistakes that I could not recognize in below attempt. Could you have a check on it? Thank you so much for your help! Proof Let $B$ be the closed unit ball of $E$ . First, we prove the direction "" $\impliedby$ "". Because $F$ is complete, it suffices to prove that $T(B)$ is totally bounded. Fix $\varepsilon>0$ . There is $m \in \mathbb N$ such that $|\lambda_n| < \varepsilon$ for all $n \ge m$ . Then for $x,y \in B$ , $$ \begin{align} \sum_{n=m}^\infty |\lambda_n x_n-\lambda_n y_n|^p &=\sum_{n=m}^\infty \lambda^p_n |x_n-y_n|^p \\ &\le \varepsilon^p \sum_{n=m}^\infty |x_n-y_n|^p \\ & \le \varepsilon^p \|x-y\|_p^p  \\ &\le \varepsilon^p 2^p (\|x\|^p_p + \|y\|^p_p) \\ &\le 2^{p+1}\varepsilon^p, \end{align} $$ and $$ \sup_{n \ge m} |\lambda_n x_n-\lambda_n y_n| \le \varepsilon \sup_{n \ge m} |x_n- y_n| \le 2 \varepsilon. $$ It remains to prove that $$ C :=\{ (\lambda_1 x_1, \lambda_2 x_2, \ldots, \lambda_{m-1} x_{m-1}, 0, 0, \ldots) : x \in B \} $$ has compact closure. This is indeed true because $C$ is bounded and is contained in a finite-dimensional subspace of $E$ . Second, we prove the direction "" $\implies$ "". We define $x^m \in B$ by $(x^m)_n :=1$ if $n=m$ and $0$ otherwise. Let $y^m := T x^m$ Then $(y^m)_n =\lambda_m$ if $n=m$ and $0$ otherwise. Then $\|y^m\|_p = |\lambda_m|$ . We have $T(B)$ has compact closure and thus $\{y^m :m \ge 1\}$ is bounded. The claim then follows. Update: @Ryszard pointed out in a comment that I incorrectly quoted the exercise and thus my proof for the direction "" $\implies$ "" is incorrect. Could you help me prove this direction?","I'm trying to solve an exercise in Brezis' Functional Analysis Let with . Let be a bounded sequence in . We consider a bounded linear operator defined by for . Prove that is compact iff . There are possibly subtle mistakes that I could not recognize in below attempt. Could you have a check on it? Thank you so much for your help! Proof Let be the closed unit ball of . First, we prove the direction "" "". Because is complete, it suffices to prove that is totally bounded. Fix . There is such that for all . Then for , and It remains to prove that has compact closure. This is indeed true because is bounded and is contained in a finite-dimensional subspace of . Second, we prove the direction "" "". We define by if and otherwise. Let Then if and otherwise. Then . We have has compact closure and thus is bounded. The claim then follows. Update: @Ryszard pointed out in a comment that I incorrectly quoted the exercise and thus my proof for the direction "" "" is incorrect. Could you help me prove this direction?","E:= \ell^p p \in [1, \infty] (\lambda_n) \mathbb R T:E \to E 
Tx := (\lambda_1 x_1, \lambda_2 x_2, \ldots), 
 x = (x_1, x_2, \ldots) \in E T \lambda_n \to 0 B E \impliedby F T(B) \varepsilon>0 m \in \mathbb N |\lambda_n| < \varepsilon n \ge m x,y \in B 
\begin{align}
\sum_{n=m}^\infty |\lambda_n x_n-\lambda_n y_n|^p &=\sum_{n=m}^\infty \lambda^p_n |x_n-y_n|^p \\
&\le \varepsilon^p \sum_{n=m}^\infty |x_n-y_n|^p \\
& \le \varepsilon^p \|x-y\|_p^p  \\
&\le \varepsilon^p 2^p (\|x\|^p_p + \|y\|^p_p) \\
&\le 2^{p+1}\varepsilon^p,
\end{align}
 
\sup_{n \ge m} |\lambda_n x_n-\lambda_n y_n| \le \varepsilon \sup_{n \ge m} |x_n- y_n| \le 2 \varepsilon.
 
C :=\{ (\lambda_1 x_1, \lambda_2 x_2, \ldots, \lambda_{m-1} x_{m-1}, 0, 0, \ldots) : x \in B \}
 C E \implies x^m \in B (x^m)_n :=1 n=m 0 y^m := T x^m (y^m)_n =\lambda_m n=m 0 \|y^m\|_p = |\lambda_m| T(B) \{y^m :m \ge 1\} \implies","['functional-analysis', 'solution-verification', 'lp-spaces', 'compact-operators']"
16,"Find a subspace of $L^2([0,1])$ which is dense in $L^p([0,1])$ for all $p<2$ but not in $L^2([0,1])$",Find a subspace of  which is dense in  for all  but not in,"L^2([0,1]) L^p([0,1]) p<2 L^2([0,1])","For simplicity, I write $L^p$ instead of $L^p([0,1])$ . For $p<q$ , we have $\lVert\cdot\rVert_p\le\lVert\cdot\rVert_q$ and hence $L^q\subseteq L^p$ . Here $L^2\subseteq L^p$ for all $p<2$ . Let us take a non-zero $g\in L^2$ and define $S=\{f\in L^2: \langle g,f\rangle_{L^2}=0\}$ . Then $S^\perp=\text{Span}(g)\ne0$ , hence $S$ is not dense in $L^2$ . I want to examine whether $S$ is dense in $L^p$ or not. Let us take $p<2$ , then S is dense in $L^p$ iff the only linear functional on $L^p$ which vanishes on $S$ is the zero linear functional. We know that $(L^p)^*=L^q$ where $p,q$ are conjugate. As $p<2$ , $q>2$ . Let $h\in L^q$ and $\int hf\ dm=0$ for all $f\in S$ . Now if $\int gh\ dm=0$ i.e. $\overline{h}\in S$ , we have $\int h\overline{h}\ dm=0\implies h=0$ . Therefore, $S$ is dense in $L^p$ for every $p<2$ if and only if there is non-zero $g\in L^2$ such that $\int gh\ dm=0$ for all $h\in L^q$ for every $q>2$ . But is it possible to construct such $g$ ? Can anyone help me in this regard? Is there any alternate way-out to solve the problem? Thanks for your help in advance.","For simplicity, I write instead of . For , we have and hence . Here for all . Let us take a non-zero and define . Then , hence is not dense in . I want to examine whether is dense in or not. Let us take , then S is dense in iff the only linear functional on which vanishes on is the zero linear functional. We know that where are conjugate. As , . Let and for all . Now if i.e. , we have . Therefore, is dense in for every if and only if there is non-zero such that for all for every . But is it possible to construct such ? Can anyone help me in this regard? Is there any alternate way-out to solve the problem? Thanks for your help in advance.","L^p L^p([0,1]) p<q \lVert\cdot\rVert_p\le\lVert\cdot\rVert_q L^q\subseteq L^p L^2\subseteq L^p p<2 g\in L^2 S=\{f\in L^2: \langle g,f\rangle_{L^2}=0\} S^\perp=\text{Span}(g)\ne0 S L^2 S L^p p<2 L^p L^p S (L^p)^*=L^q p,q p<2 q>2 h\in L^q \int hf\ dm=0 f\in S \int gh\ dm=0 \overline{h}\in S \int h\overline{h}\ dm=0\implies h=0 S L^p p<2 g\in L^2 \int gh\ dm=0 h\in L^q q>2 g","['functional-analysis', 'analysis', 'measure-theory', 'lp-spaces']"
17,"Every finite rank operator on a Hilbert space can be written $\sum_{j=1}^n s_j|u_j\rangle\langle v_j|$ with $\{u_j\},\{v_j\}$ orthonormal",Every finite rank operator on a Hilbert space can be written  with  orthonormal,"\sum_{j=1}^n s_j|u_j\rangle\langle v_j| \{u_j\},\{v_j\}","Let $T$ be a finite rank operator on a Hilbert space $H$ . Then there exist orthonormal sets $\{u_j\},\{v_j\}$ and positive scalars $\{s_j\}$ , with $j=1,2,\ldots,n$ , such that $$T=\sum\limits_{j=1}^n s_j|u_j\rangle\langle v_j|.$$ Here $|u\rangle \langle v|(x)=\langle v,x\rangle u$ Given finite rank operator $T$ , $T$ defines a linear correspondence between the finite dimensional spaces $\text{Ker}(T)^\perp$ and $\text{Ran}(T)$ . Let $\{u_1,u_2,\ldots, u_n\}$ be an orthonormal basis for $\text{Ran}(T)$ . Then there is $\{v_1,\ldots,v_j\}\in\text{Ker}(T)^\perp$ such that $Tv_j=u_j$ for $j=1,\ldots,n$ . As $T(v_j/\lVert v_j\rVert)=(1/\lVert v_j\rVert) u_j$ , we may assume without loss of generality that $Tv_j=s_ju_j$ and $\lVert v_j\rVert=1$ . But this $\{v_j\}$ may not be an orthonormal set. If it is, we are done. If we apply Gram Schmidt orthogonalization on $\{v_j\}$ , the $\{u_j\}$ will be changed and may not be orthonormal set any more. Can anyone suggest a way out? Thanks in advance for your help.","Let be a finite rank operator on a Hilbert space . Then there exist orthonormal sets and positive scalars , with , such that Here Given finite rank operator , defines a linear correspondence between the finite dimensional spaces and . Let be an orthonormal basis for . Then there is such that for . As , we may assume without loss of generality that and . But this may not be an orthonormal set. If it is, we are done. If we apply Gram Schmidt orthogonalization on , the will be changed and may not be orthonormal set any more. Can anyone suggest a way out? Thanks in advance for your help.","T H \{u_j\},\{v_j\} \{s_j\} j=1,2,\ldots,n T=\sum\limits_{j=1}^n s_j|u_j\rangle\langle v_j|. |u\rangle \langle v|(x)=\langle v,x\rangle u T T \text{Ker}(T)^\perp \text{Ran}(T) \{u_1,u_2,\ldots, u_n\} \text{Ran}(T) \{v_1,\ldots,v_j\}\in\text{Ker}(T)^\perp Tv_j=u_j j=1,\ldots,n T(v_j/\lVert v_j\rVert)=(1/\lVert v_j\rVert) u_j Tv_j=s_ju_j \lVert v_j\rVert=1 \{v_j\} \{v_j\} \{u_j\}","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'operator-algebras']"
18,Let $x_n := (I +n S)^{-1} f$ for all $n$. How to prove that $(x_n)$ is convergent?,Let  for all . How to prove that  is convergent?,x_n := (I +n S)^{-1} f n (x_n),"Let $(H, \langle \cdot, \cdot \rangle)$ be a real Hilbert space. Let $S :H \to H$ be a bounded linear operator such that $\langle Su, u \rangle \ge 0$ for all $u \in H$ . Then the map $I + t S$ is bijective for all $t>0$ . Here $I:H \to H$ is the identity map. Fix $f\in H$ and let $x_n := (I +n S)^{-1} f$ for all $n \in \mathbb N$ . I'm trying to prove that Theorem $(x_n)$ is convergent in $H$ . It suffices to prove that $(x_n)$ is a Cauchy sequence. Clearly, $$ x_n+n Sx_n = f = x_m + m S x_m \quad \forall m,n \in \mathbb N. $$ Then I don't know how to move forward. Could you elaborate how to prove above theorem?","Let be a real Hilbert space. Let be a bounded linear operator such that for all . Then the map is bijective for all . Here is the identity map. Fix and let for all . I'm trying to prove that Theorem is convergent in . It suffices to prove that is a Cauchy sequence. Clearly, Then I don't know how to move forward. Could you elaborate how to prove above theorem?","(H, \langle \cdot, \cdot \rangle) S :H \to H \langle Su, u \rangle \ge 0 u \in H I + t S t>0 I:H \to H f\in H x_n := (I +n S)^{-1} f n \in \mathbb N (x_n) H (x_n) 
x_n+n Sx_n = f = x_m + m S x_m
\quad \forall m,n \in \mathbb N.
","['sequences-and-series', 'functional-analysis', 'convergence-divergence', 'hilbert-spaces', 'cauchy-sequences']"
19,The application of the open mapping theorem,The application of the open mapping theorem,,"Let $V$ be a Hilbert space and $V_i \subset V(i=1, \ldots, J)$ a number of closed subspaces satisfying $V=\sum_{i=1}^J V_i$ , which, by a simple application of the Open Mapping Theorem, implies $$ \sup _{\|v\|=1} \inf _{\sum_i v_i=v} \sum_{i=1}^J\left\|v_i\right\|^2<\infty $$ I don't know how to use the open mapping theorem. Edit: This claim is made in the paper The method of alternating projections and the method of subspace corrections in Hilbert space by Jinchao Xu and Ludmil Zikatanov. See here .","Let be a Hilbert space and a number of closed subspaces satisfying , which, by a simple application of the Open Mapping Theorem, implies I don't know how to use the open mapping theorem. Edit: This claim is made in the paper The method of alternating projections and the method of subspace corrections in Hilbert space by Jinchao Xu and Ludmil Zikatanov. See here .","V V_i \subset V(i=1, \ldots, J) V=\sum_{i=1}^J V_i 
\sup _{\|v\|=1} \inf _{\sum_i v_i=v} \sum_{i=1}^J\left\|v_i\right\|^2<\infty
",['functional-analysis']
20,Closedness of operator Hardy type,Closedness of operator Hardy type,,"I am having difficulty proving that the operator $$ Af(x) = \int_0^x \frac{f(t)}{t}\,dt$$ is not a closed operator from $D(A) = C_c(0,1)$ to $L^2(0,1)$ . Is there any easy way to see this?",I am having difficulty proving that the operator is not a closed operator from to . Is there any easy way to see this?," Af(x) = \int_0^x \frac{f(t)}{t}\,dt D(A) = C_c(0,1) L^2(0,1)","['real-analysis', 'functional-analysis']"
21,Non-unitary isometry and a norm equality,Non-unitary isometry and a norm equality,,"I am looking at a paper which asserts the following equality relating a non-unitary isometry. There is no explanation given for this, and I cannot figure out why this is true: Here is the proposition: Let $A$ be a unital $C^*$ algebra (some norm closed subalgebra of $B(H)$ where $H$ is a Hilbert space, containing the identity), and let $v$ be a non-unitary isometry. Moreover let $\lambda, \rho$ be positive scalars satisfying $0< \lambda, \rho < 1$ . Then we have the following claim, Claim: $\left|\left|{\rho v - \lambda } \right|\right|= \rho + \lambda$ . I can't seem to find out why this is true (and it certainly does not seem obvious to me). I cannot even show this for the unilateral shift (i.e. the map that sends $e_i \rightarrow e_{i+1}$ for $i \in \mathbb{N}$ on $\ell^2(\mathbb{N})$ ). Here are some things that I tried: First that the inequality $\lvert\lvert {\rho v - \lambda } \rvert\rvert \leq \rho + \lambda$ is obvious. Thus if our $C^*$ algebra is isometrically isomorophic to some subalgebra of $B(H)$ for some Hilbert space $H$ , then if we choose normalized $x \in ran(v)^{\perp}$ then $\lvert\lvert {\rho v(x) - \lambda(x) } \lvert \lvert = \sqrt{\rho^2+\lambda^2}$ , but this is not enough to show the equality. Another hope is to use the $C^{*}$ property and write $\lvert\lvert {\rho v - \lambda } \lvert \lvert ^2 = \lvert\lvert ({\rho v - \lambda })^{*} ({\rho v - \lambda })\lvert \lvert = \lvert\lvert \rho^2+ \lambda^2 - \rho \lambda (v+v^*)\lvert \lvert $ and say something about this quanity and maybe use spectral properties (i.e. use the spectral theorem in a meaningful way) of the self adjoint operator $v+v^*$ , but I am unsure how to proceed.","I am looking at a paper which asserts the following equality relating a non-unitary isometry. There is no explanation given for this, and I cannot figure out why this is true: Here is the proposition: Let be a unital algebra (some norm closed subalgebra of where is a Hilbert space, containing the identity), and let be a non-unitary isometry. Moreover let be positive scalars satisfying . Then we have the following claim, Claim: . I can't seem to find out why this is true (and it certainly does not seem obvious to me). I cannot even show this for the unilateral shift (i.e. the map that sends for on ). Here are some things that I tried: First that the inequality is obvious. Thus if our algebra is isometrically isomorophic to some subalgebra of for some Hilbert space , then if we choose normalized then , but this is not enough to show the equality. Another hope is to use the property and write and say something about this quanity and maybe use spectral properties (i.e. use the spectral theorem in a meaningful way) of the self adjoint operator , but I am unsure how to proceed.","A C^* B(H) H v \lambda, \rho 0< \lambda, \rho < 1 \left|\left|{\rho v - \lambda } \right|\right|= \rho + \lambda e_i \rightarrow e_{i+1} i \in \mathbb{N} \ell^2(\mathbb{N}) \lvert\lvert {\rho v - \lambda } \rvert\rvert \leq \rho + \lambda C^* B(H) H x \in ran(v)^{\perp} \lvert\lvert {\rho v(x) - \lambda(x) } \lvert \lvert = \sqrt{\rho^2+\lambda^2} C^{*} \lvert\lvert {\rho v - \lambda } \lvert \lvert ^2 = \lvert\lvert ({\rho v - \lambda })^{*} ({\rho v - \lambda })\lvert \lvert = \lvert\lvert \rho^2+ \lambda^2 - \rho \lambda (v+v^*)\lvert \lvert  v+v^*","['functional-analysis', 'hilbert-spaces', 'operator-algebras', 'spectral-theory', 'von-neumann-algebras']"
22,Existence of sequence of test functions converging to a constant,Existence of sequence of test functions converging to a constant,,"I read somewhere that it is possible to find a sequence of test functions $\phi_{\epsilon} \in C^{\infty}_{c}(0,1)$ such that $\phi_{\epsilon} \ge 0$ , $\phi_{\epsilon} \to 1$ as $\epsilon \to 0$ , $\|\phi_{\epsilon}'\|_{L^{2}(0,1)} \lesssim  1 $ . I wish to know if this claim is actually true or not. I am doubting this mainly because of the final statement which says that the derivatives are uniformly bounded. The reason I doubt this is because if this sequence is converging to $1$ and each element has compact support then surely the derivatives would have to be 'really large' near the endpoints $x=0$ and $x=1$ ? Intuitively I don't see how you could cook up a sequence of functions which have compact support, converge to $1$ AND have derivative uniformly bounded in $L^{2}$ .","I read somewhere that it is possible to find a sequence of test functions such that , as , . I wish to know if this claim is actually true or not. I am doubting this mainly because of the final statement which says that the derivatives are uniformly bounded. The reason I doubt this is because if this sequence is converging to and each element has compact support then surely the derivatives would have to be 'really large' near the endpoints and ? Intuitively I don't see how you could cook up a sequence of functions which have compact support, converge to AND have derivative uniformly bounded in .","\phi_{\epsilon} \in C^{\infty}_{c}(0,1) \phi_{\epsilon} \ge 0 \phi_{\epsilon} \to 1 \epsilon \to 0 \|\phi_{\epsilon}'\|_{L^{2}(0,1)} \lesssim  1  1 x=0 x=1 1 L^{2}","['real-analysis', 'functional-analysis', 'analysis', 'distribution-theory']"
23,Is Hahn-Banach equivalent to the ultrafilter lemma in ZF,Is Hahn-Banach equivalent to the ultrafilter lemma in ZF,,"I know that the ultrafilter lemma is weaker than the axiom of choice (in ZF) And that in order to prove Choice in ZF from the ultrafilter lemma we need the Krein-Milman theorem so $UF+KM=AC$ Furthermore, I know the Hahn-Banach theorem is weaker than choice but in order to get choice from the Hahn-Banach theorem we need (again) Krein-Milman (in ZF). so $HB+KM=AC$ . (And I please complete ignorance of mathematical logic but...) Doesn't that imply that the Hahn-Banach theorem is logically equivalent to the ultrafilter lemma in ZF? Or if not, does it then imply that we can use a statement that is weaker than Krein-Milman (call such a statement $S$ ) such that $UF+S=AC$ ? So the question is either is $HB=UF$ or if not, what is $S$ ?","I know that the ultrafilter lemma is weaker than the axiom of choice (in ZF) And that in order to prove Choice in ZF from the ultrafilter lemma we need the Krein-Milman theorem so Furthermore, I know the Hahn-Banach theorem is weaker than choice but in order to get choice from the Hahn-Banach theorem we need (again) Krein-Milman (in ZF). so . (And I please complete ignorance of mathematical logic but...) Doesn't that imply that the Hahn-Banach theorem is logically equivalent to the ultrafilter lemma in ZF? Or if not, does it then imply that we can use a statement that is weaker than Krein-Milman (call such a statement ) such that ? So the question is either is or if not, what is ?",UF+KM=AC HB+KM=AC S UF+S=AC HB=UF S,"['functional-analysis', 'logic', 'axiom-of-choice', 'filters', 'hahn-banach-theorem']"
24,Density of normal matrices in $M_n(\mathbb{C})$,Density of normal matrices in,M_n(\mathbb{C}),"A matrix $A\in M_n(\mathbb{C})$ is said to be normal if $A^*A=AA^*$ , where $A^*$ is the Hermitian conjugate. Consider $M_n(\mathbb{C})$ with its norm topology. Question: Is the space of normal matrices dense in $M_n(\mathbb{C})$ ? Thoughts: I know that the space of all diagonalisable matrices is dense in $M_n(\mathbb{C})$ , and that a matrix is normal if and only if it is unitarily diagonalizable. So the question amounts to asking whether the unitarily diagonalizable matrices still form a dense subset.","A matrix is said to be normal if , where is the Hermitian conjugate. Consider with its norm topology. Question: Is the space of normal matrices dense in ? Thoughts: I know that the space of all diagonalisable matrices is dense in , and that a matrix is normal if and only if it is unitarily diagonalizable. So the question amounts to asking whether the unitarily diagonalizable matrices still form a dense subset.",A\in M_n(\mathbb{C}) A^*A=AA^* A^* M_n(\mathbb{C}) M_n(\mathbb{C}) M_n(\mathbb{C}),"['linear-algebra', 'general-topology', 'functional-analysis']"
25,About closed subspaces in infinite Dimensional HIlbert spaces,About closed subspaces in infinite Dimensional HIlbert spaces,,"How can I prove the following? Let $H$ be an infinite-dimensional Hilbert space. Show there exist closed vector subspaces $\{X_t:t\in[0,1]\}$ in $H$ so that $X_s\subset X_t$ for every $0\leq s < t \leq 1$ . My attempt Given that $H$ is isomorphic to $L^2[0,1]$ , I move to the function space. Clearly considering $X_s = \{f\in L^2: f(x) = 0 \ \forall x > s\} $ then the condition is clearly satisfied. So two doubts here: The question doesn't mention separability, but it's necessary for my argument (isomorphism). Is it necessary to prove the statement? Can it be proven without resorting to working in another isomorphic space?","How can I prove the following? Let be an infinite-dimensional Hilbert space. Show there exist closed vector subspaces in so that for every . My attempt Given that is isomorphic to , I move to the function space. Clearly considering then the condition is clearly satisfied. So two doubts here: The question doesn't mention separability, but it's necessary for my argument (isomorphism). Is it necessary to prove the statement? Can it be proven without resorting to working in another isomorphic space?","H \{X_t:t\in[0,1]\} H X_s\subset X_t 0\leq s < t \leq 1 H L^2[0,1] X_s = \{f\in L^2: f(x) = 0 \ \forall x > s\} ","['functional-analysis', 'hilbert-spaces']"
26,Is a weak* limit of a sequence of tempered distributions indeed a tempered distribution?,Is a weak* limit of a sequence of tempered distributions indeed a tempered distribution?,,"The question is as in the title. Let $\{ T_n \}$ be a sequence of tempered distributions such that $\{ T_n(f) \}$ converges for every Schwartz function $f$ . Let us denote the ""pointwise"" or weak* limit as $T(f)$ . Then, is $T$ a tempered distribution? Of course it is a linear functional on the Schwartz space, but I cannot see how to show temperedness. It seems quite confusing and nontrivial. Could anyone please clarify?","The question is as in the title. Let be a sequence of tempered distributions such that converges for every Schwartz function . Let us denote the ""pointwise"" or weak* limit as . Then, is a tempered distribution? Of course it is a linear functional on the Schwartz space, but I cannot see how to show temperedness. It seems quite confusing and nontrivial. Could anyone please clarify?",\{ T_n \} \{ T_n(f) \} f T(f) T,"['functional-analysis', 'distribution-theory']"
27,Sequentially closure on Hilbert separable space,Sequentially closure on Hilbert separable space,,"Let $H$ a Hilbert separable space with a Hilbert basis $(e_n)_{n\in\mathbb{N}}$ . Let $$  F = \{e_m + m e_n \, : \, n,m \geq 1\} $$ Show that 0 is not in the sequentially weak closure of F. Show that 0 in sequentially weak closure of sequentially weak closure of F Any hint of suggestion? I tried by contradiction but I'm stuck",Let a Hilbert separable space with a Hilbert basis . Let Show that 0 is not in the sequentially weak closure of F. Show that 0 in sequentially weak closure of sequentially weak closure of F Any hint of suggestion? I tried by contradiction but I'm stuck,"H (e_n)_{n\in\mathbb{N}} 
 F = \{e_m + m e_n \, : \, n,m \geq 1\}
","['functional-analysis', 'hilbert-spaces', 'weak-topology']"
28,Complex Banach spaces and invertibility in Spectral Theory,Complex Banach spaces and invertibility in Spectral Theory,,"The following question is from my assignment in spectral theory and I am not able to prove the assertions I am asked to prove. Question: Let X be a Complex Banach space, and let $A,B \in L(X)$ . It is assumed that $AB=I$ and $BA\neq I$ . Consider any $\lambda \in \mathbb{C}$ such that $I-\lambda B$ is invertible. Show that $(A- \lambda I) B (I-\lambda B)^{-1} =I $ and $B ( I-\lambda B)^{-1} ( A-\lambda I) \neq I$ . Also deduce that $A-\lambda I$ is not invertible (provided by that $I-\lambda B$ is invertible). Very unfortunately, I am not able to prove any of the assertions asked. For spectral theory, I have been following my class notes only. The problem I think I am facing is that I am not sure which exact proposition could be helpful in the question. I have studied the following concepts in this section: K-algebra, Normed algebra, Spectrum, Spectral radius, unitary Banach algebras, invertible elements. Can you please outline which results I should use to prove the asked assertions. No need to give complete proofs. I shall be grateful!","The following question is from my assignment in spectral theory and I am not able to prove the assertions I am asked to prove. Question: Let X be a Complex Banach space, and let . It is assumed that and . Consider any such that is invertible. Show that and . Also deduce that is not invertible (provided by that is invertible). Very unfortunately, I am not able to prove any of the assertions asked. For spectral theory, I have been following my class notes only. The problem I think I am facing is that I am not sure which exact proposition could be helpful in the question. I have studied the following concepts in this section: K-algebra, Normed algebra, Spectrum, Spectral radius, unitary Banach algebras, invertible elements. Can you please outline which results I should use to prove the asked assertions. No need to give complete proofs. I shall be grateful!","A,B \in L(X) AB=I BA\neq I \lambda \in \mathbb{C} I-\lambda B (A- \lambda I) B (I-\lambda B)^{-1} =I  B ( I-\lambda B)^{-1} ( A-\lambda I) \neq I A-\lambda I I-\lambda B","['functional-analysis', 'operator-theory']"
29,Strictly convex renorming of Banach space,Strictly convex renorming of Banach space,,"Banach space $X$ (or its norm) is said to be strictly convex if its unit sphere $S_X$ does not contain any nontrivial line segment. There is also stronger notion of uniform convexivity. We say that space $X$ is uniformly convex if for any $\varepsilon > 0$ there exists $\delta > 0$ such that for any $x,y \in S_X$ $$ \|x - y\| \geq \varepsilon \implies \Bigl \|\frac{x+y}{2} \Bigr \| \leq 1 - \delta. $$ It follows from parallelogram identity that every inner product space is uniformly convex. Moreover, it is known that $L_p$ spaces are uniformly convex for $1 < p < \infty$ . On the other side there are classical spaces, such as $C[0,1], L_1, c_0, c$ , which are not strictly convex (when equiped with their standard norms). Some of these spaces admit equivalent and strictly convex renorming. For example in $c_0$ space there is norm $$ \|x\|_{sc} = \sup_{n \in \mathbb{N}}|x_n| + \Bigl( \sum_{n=1}^{\infty} \frac{1}{2^n} |x_n|^2 \Bigr)^{\frac{1}{2}}$$ which is strictly convex and equivalent to the classical norm $\|x\| = \sup_{n \in \mathbb{N}} |x_n|$ . $\textbf{My questions}:$ Does every Banach space admit strictly convex (not necessarily equivalent) renorming? If not, is there some class of B spaces, for which such renorming exists? What about uniformly convex renorming?","Banach space (or its norm) is said to be strictly convex if its unit sphere does not contain any nontrivial line segment. There is also stronger notion of uniform convexivity. We say that space is uniformly convex if for any there exists such that for any It follows from parallelogram identity that every inner product space is uniformly convex. Moreover, it is known that spaces are uniformly convex for . On the other side there are classical spaces, such as , which are not strictly convex (when equiped with their standard norms). Some of these spaces admit equivalent and strictly convex renorming. For example in space there is norm which is strictly convex and equivalent to the classical norm . Does every Banach space admit strictly convex (not necessarily equivalent) renorming? If not, is there some class of B spaces, for which such renorming exists? What about uniformly convex renorming?","X S_X X \varepsilon > 0 \delta > 0 x,y \in S_X  \|x - y\| \geq \varepsilon \implies \Bigl \|\frac{x+y}{2} \Bigr \| \leq 1 - \delta.  L_p 1 < p < \infty C[0,1], L_1, c_0, c c_0  \|x\|_{sc} = \sup_{n \in \mathbb{N}}|x_n| + \Bigl( \sum_{n=1}^{\infty} \frac{1}{2^n} |x_n|^2 \Bigr)^{\frac{1}{2}} \|x\| = \sup_{n \in \mathbb{N}} |x_n| \textbf{My questions}:",['functional-analysis']
30,Difference in interval notation,Difference in interval notation,,"What is the difference between these two exercise questions (regarding the intervals)? Show that for each $\epsilon > 0$ , $f_n$ is uniformly convergent on $[\epsilon, \infty)$ Show that $f_n$ is not uniformly convergent on $(0, \infty)$ I mean in the first interval we don't have the 0 because $\epsilon > 0$ and in the second we don't have the 0 because it is an open interval. So what is the difference?","What is the difference between these two exercise questions (regarding the intervals)? Show that for each , is uniformly convergent on Show that is not uniformly convergent on I mean in the first interval we don't have the 0 because and in the second we don't have the 0 because it is an open interval. So what is the difference?","\epsilon > 0 f_n [\epsilon, \infty) f_n (0, \infty) \epsilon > 0","['real-analysis', 'functional-analysis']"
31,How to prove triangle inequality for euclidean distance on $\mathbb{R}^2$ without using Cauchy-Schwarz?,How to prove triangle inequality for euclidean distance on  without using Cauchy-Schwarz?,\mathbb{R}^2,"Joseph Muscat's Functional Analysis asks the reader to prove $d(x,y)= \sqrt{|a_1-b_1|^2+|a_2-b_2|^2}$ on $\mathbb{R}^2$ satisfies the triangle inequality: $\sqrt{|a_1-b_1|^2+|a_2-b_2|^2}\leq\sqrt{|a_1-z_1|^2+|a_2-z_2|^2}+\sqrt{|z_1-b_1|^2+|z_2-b_2|^2}$ This is before the Cauchy-Schwarz inequality is explained. I figured it would be the same as proving the triangle inequality for $|a_1-b_1|$ on $\mathbb{R}$ , but I seriously don't know where to go from there to the inequality. This was my attempt: $d(x,y) = \sqrt{|a_1-b_1|^2+|a_2-b_2|^2} =\sqrt{|a_1-z_1+z_1-b_1|^2+|a_2-z_2+z_2-b_2|^2}$ $|a_1-z_1+z_1-b_1|\leq|a_1-z_1|+|z_1-b_1|$ So $\sqrt{|a_1-z_1+z_1-b_1|^2+|a_2-z_2+z_2-b_2|^2}\leq\sqrt{(|a_1-z_1|+|z_1-b_1|)^2+(|a_2-z_2|+|z_2-b_2|)^2}$ Expanding the right-hand side, we get: $\sqrt{|a_1-z_1+z_1-b_1|^2+|a_2-z_2+z_2-b_2|^2}\leq\sqrt{(|a_1-z_1|^2+|z_1-b_1|^2+2|a_1-z_1||z_1-b_1|+|a_2-z_2|^2+|z_2-b_2|^2+2|a_2-z_2||z_2-b_2|}$ or $\sqrt{|a_1-b_1|^2+|a_2-b_2|^2}\leq\sqrt{(|a_1-z_1|^2+|z_1-b_1|^2+2|a_1-z_1||z_1-b_1|+|a_2-z_2|^2+|z_2-b_2|^2+2|a_2-z_2||z_2-b_2|}$ I don't know where to go from here. Is this approach reasonable?","Joseph Muscat's Functional Analysis asks the reader to prove on satisfies the triangle inequality: This is before the Cauchy-Schwarz inequality is explained. I figured it would be the same as proving the triangle inequality for on , but I seriously don't know where to go from there to the inequality. This was my attempt: So Expanding the right-hand side, we get: or I don't know where to go from here. Is this approach reasonable?","d(x,y)= \sqrt{|a_1-b_1|^2+|a_2-b_2|^2} \mathbb{R}^2 \sqrt{|a_1-b_1|^2+|a_2-b_2|^2}\leq\sqrt{|a_1-z_1|^2+|a_2-z_2|^2}+\sqrt{|z_1-b_1|^2+|z_2-b_2|^2} |a_1-b_1| \mathbb{R} d(x,y) = \sqrt{|a_1-b_1|^2+|a_2-b_2|^2} =\sqrt{|a_1-z_1+z_1-b_1|^2+|a_2-z_2+z_2-b_2|^2} |a_1-z_1+z_1-b_1|\leq|a_1-z_1|+|z_1-b_1| \sqrt{|a_1-z_1+z_1-b_1|^2+|a_2-z_2+z_2-b_2|^2}\leq\sqrt{(|a_1-z_1|+|z_1-b_1|)^2+(|a_2-z_2|+|z_2-b_2|)^2} \sqrt{|a_1-z_1+z_1-b_1|^2+|a_2-z_2+z_2-b_2|^2}\leq\sqrt{(|a_1-z_1|^2+|z_1-b_1|^2+2|a_1-z_1||z_1-b_1|+|a_2-z_2|^2+|z_2-b_2|^2+2|a_2-z_2||z_2-b_2|} \sqrt{|a_1-b_1|^2+|a_2-b_2|^2}\leq\sqrt{(|a_1-z_1|^2+|z_1-b_1|^2+2|a_1-z_1||z_1-b_1|+|a_2-z_2|^2+|z_2-b_2|^2+2|a_2-z_2||z_2-b_2|}","['functional-analysis', 'inequality', 'metric-spaces', 'euclidean-geometry']"
32,Equivalence between $L^{p_0}+ L^{p_1}$ and Orlicz space $L^\Psi$ with suitable $\Psi$,Equivalence between  and Orlicz space  with suitable,L^{p_0}+ L^{p_1} L^\Psi \Psi,"This is from Exercise 24, Chapter 1, in Stein and Shakarchi's Functional Analysis . First a few definitions. $L^{p_0}+L^{p_1}$ is defined as the vector space of measurable functions $f$ on a measure space $X$ , that can be written as a sum $f=f_0+f_1$ with $f_0\in L^{p_0}$ and $f_1\in L^{p_1}$ . Define $$\|f\|_{L^{p_0}+L^{p_1}}=\inf\{\|f_0\|_{L^{p_0}}+\|f_1\|_{L^{p_1}}\},$$ where the infimum is taken over all decomposition $f=f_0+f_1$ with $f_0\in L^{p_0}$ and $f_1\in L^{p_1}$ . Suppose $\phi(t)$ is continuous, convex, increasing function on $[0,\infty)$ , with $\phi(0)=0$ and $\phi(t)$ is not the constant function 0. Define $$L^{\phi}=\{f\hspace{0.2cm} \text{measurable:}\int_{X}\phi(|f(x)|/M)d\mu<\infty, \text{for some}\hspace{0.2cm} M>0\}$$ and $||f||_{\phi}=\inf_{M>0}\int_{X}\phi(|f(x)|/M)d\mu\le1$ . Suppose $1\leq p_0<p_1<\infty$ and define $$\Psi(t) = \int_0^t \psi(u) du \quad \text{where} \; \psi(u) = \begin{cases}   u^{p_1-1} & \text{if $u<1$} \\   u^{p_0-1} & \text{if $1\leq u<\infty$} \end{cases}$$ Show that $L^\Psi$ with its norm is equivalent to the space $L^{p_0} + L^{p_1}$ . In other words, there exist $A, B > 0$ , so that $$A \| f \|_{L^{p_0} + L^{p_1}} \leq \| f \|_{L^\Psi} \leq B \| f \|_{L^{p_0} + L^{p_1}} .$$ The left half of the inequality is easy to prove, as $\Psi(|f|/M)$ effectively defines a decomposition of $f$ . I cannot figure out how to prove the right half of the inequality.","This is from Exercise 24, Chapter 1, in Stein and Shakarchi's Functional Analysis . First a few definitions. is defined as the vector space of measurable functions on a measure space , that can be written as a sum with and . Define where the infimum is taken over all decomposition with and . Suppose is continuous, convex, increasing function on , with and is not the constant function 0. Define and . Suppose and define Show that with its norm is equivalent to the space . In other words, there exist , so that The left half of the inequality is easy to prove, as effectively defines a decomposition of . I cannot figure out how to prove the right half of the inequality.","L^{p_0}+L^{p_1} f X f=f_0+f_1 f_0\in L^{p_0} f_1\in L^{p_1} \|f\|_{L^{p_0}+L^{p_1}}=\inf\{\|f_0\|_{L^{p_0}}+\|f_1\|_{L^{p_1}}\}, f=f_0+f_1 f_0\in L^{p_0} f_1\in L^{p_1} \phi(t) [0,\infty) \phi(0)=0 \phi(t) L^{\phi}=\{f\hspace{0.2cm} \text{measurable:}\int_{X}\phi(|f(x)|/M)d\mu<\infty, \text{for some}\hspace{0.2cm} M>0\} ||f||_{\phi}=\inf_{M>0}\int_{X}\phi(|f(x)|/M)d\mu\le1 1\leq p_0<p_1<\infty \Psi(t) = \int_0^t \psi(u) du \quad \text{where} \; \psi(u) =
\begin{cases}
  u^{p_1-1} & \text{if u<1} \\
  u^{p_0-1} & \text{if 1\leq u<\infty}
\end{cases} L^\Psi L^{p_0} + L^{p_1} A, B > 0 A \| f \|_{L^{p_0} + L^{p_1}} \leq \| f \|_{L^\Psi} \leq B \| f \|_{L^{p_0} + L^{p_1}} . \Psi(|f|/M) f","['functional-analysis', 'analysis', 'orlicz-spaces']"
33,Inverse of a bounded operator on a Hilbert space,Inverse of a bounded operator on a Hilbert space,,"Consider a bounded (linear) operator $T \in \mathcal{L}(H)$ on a Hilbert space $H$ . We say $T$ is invertible if it has a bounded inverse, i.e. if $\exists T^{-1} \in \mathcal{L}(H)$ such that $T^{-1} T = T T^{-1} = I \in \mathcal{L}(H)$ . It is easy to see that, if $T$ is invertible, then $T$ is bounded from below, meaning that $$ \exists c >0 : \, \| Tx \| \geq c \| x \| \, , \quad \forall x \in H $$ (one can take $c = 1/\| T^{-1} \|$ ). My question is: does the converse hold? i.e. does boundedness from below imply invertibility? If no, can you give an example of a $T$ which is bounded from below but not invertible?","Consider a bounded (linear) operator on a Hilbert space . We say is invertible if it has a bounded inverse, i.e. if such that . It is easy to see that, if is invertible, then is bounded from below, meaning that (one can take ). My question is: does the converse hold? i.e. does boundedness from below imply invertibility? If no, can you give an example of a which is bounded from below but not invertible?","T \in \mathcal{L}(H) H T \exists T^{-1} \in \mathcal{L}(H) T^{-1} T = T T^{-1} = I \in \mathcal{L}(H) T T  \exists c >0 : \, \| Tx \| \geq c \| x \| \, , \quad \forall x \in H  c = 1/\| T^{-1} \| T","['functional-analysis', 'hilbert-spaces', 'inverse']"
34,Elliptic partial differential equations with robin boundary condition and domain of fractional power of Robin Laplacian operator,Elliptic partial differential equations with robin boundary condition and domain of fractional power of Robin Laplacian operator,,"When I read the paper ""On the attractor for a semilinear wave equation with critical exponent and nonlinear boundary dissipation"" by Igor Chueshov,Matthias Eller and Irena Lasiecka,I encounter a difficulty: Suppose that $\Omega$ is a simple connected domain with smooth boundary, the authors introduced a Robin Laplacian operator $$\Delta_{R}:L^{2}(\Omega)\to L^{2}(\Omega).$$ This is an unbounded operator with the domain $$D(\Delta_{R})=\{u\in H^{2}(\Omega):\partial_{\nu}u+u=0\ on\ \partial\Omega\}.$$ Moreover, the Robin Laplacian can be extended to a continuous operator $\Delta_{R}:H^{1}(\Omega)\to H^{1}(\Omega)'$ by $$(-\Delta_{R}u,v)_{L^{2}(\Omega)}=(\nabla u,\nabla v)_{L^{2}(\Omega)}+<u,v>_{L^{2}(\partial\Omega)}.$$ Then the authors say ""this extension is the duality map $H^{1}(\Omega)$ into $(H^{1}(\Omega))'$ "" when we equip $H^{1}(\Omega)$ the norm $$\|u\|=\sqrt{(\nabla u,\nabla v)_{L^{2}(\Omega)}+<u,v>_{L^{2}(\partial\Omega)}}.$$ So, firstly, I want to know if this norm is equivalent to the usual Sobolev norm $$\|u\|=\sqrt{(\nabla u,\nabla v)_{L^{2}(\Omega)}+(u,v)_{L^{2}(\Omega)}}$$ when $u$ satisfies the robin boundary conditon? Next, the authors said $$D((-\Delta_{R}))^{\frac{1}{2}}\sim H^{1}(\Omega),$$ why? the authors offered an reference but it is french, but I don't understand french. the reference is ""Grisvard,P. Characterisation de Quelques Esoaces d'interpolation. Archives Rational Mechanics and Analysis 1967,26,40-63"" Any comments and hints are welcome, thank you very much!!!","When I read the paper ""On the attractor for a semilinear wave equation with critical exponent and nonlinear boundary dissipation"" by Igor Chueshov,Matthias Eller and Irena Lasiecka,I encounter a difficulty: Suppose that is a simple connected domain with smooth boundary, the authors introduced a Robin Laplacian operator This is an unbounded operator with the domain Moreover, the Robin Laplacian can be extended to a continuous operator by Then the authors say ""this extension is the duality map into "" when we equip the norm So, firstly, I want to know if this norm is equivalent to the usual Sobolev norm when satisfies the robin boundary conditon? Next, the authors said why? the authors offered an reference but it is french, but I don't understand french. the reference is ""Grisvard,P. Characterisation de Quelques Esoaces d'interpolation. Archives Rational Mechanics and Analysis 1967,26,40-63"" Any comments and hints are welcome, thank you very much!!!","\Omega \Delta_{R}:L^{2}(\Omega)\to L^{2}(\Omega). D(\Delta_{R})=\{u\in H^{2}(\Omega):\partial_{\nu}u+u=0\ on\ \partial\Omega\}. \Delta_{R}:H^{1}(\Omega)\to H^{1}(\Omega)' (-\Delta_{R}u,v)_{L^{2}(\Omega)}=(\nabla u,\nabla v)_{L^{2}(\Omega)}+<u,v>_{L^{2}(\partial\Omega)}. H^{1}(\Omega) (H^{1}(\Omega))' H^{1}(\Omega) \|u\|=\sqrt{(\nabla u,\nabla v)_{L^{2}(\Omega)}+<u,v>_{L^{2}(\partial\Omega)}}. \|u\|=\sqrt{(\nabla u,\nabla v)_{L^{2}(\Omega)}+(u,v)_{L^{2}(\Omega)}} u D((-\Delta_{R}))^{\frac{1}{2}}\sim H^{1}(\Omega),","['functional-analysis', 'partial-differential-equations']"
35,Self adjoint inverse,Self adjoint inverse,,"I'm reading some functional analysis and it's after lunch so I can't think. Can someone please help with this quick question. I have the following: Let $T\in B(H)$ be a self adjoint operator and $\varepsilon>0$ . Let $p$ be the spectral projection of $T$ corresponding to the Borel subset $[-\varepsilon,\varepsilon]$ (that is, the indicator function of $[-\varepsilon,\varepsilon]$ applied to $T$ by Borel functional calculus). Then the following operator $$S = (1-p)T+\varepsilon p$$ has a self adjoint bounded inverse. Why? Is there an obvious inverse I am missing, or is this some bounded inverse theorem (or one of the other functional analysis theorems) business.","I'm reading some functional analysis and it's after lunch so I can't think. Can someone please help with this quick question. I have the following: Let be a self adjoint operator and . Let be the spectral projection of corresponding to the Borel subset (that is, the indicator function of applied to by Borel functional calculus). Then the following operator has a self adjoint bounded inverse. Why? Is there an obvious inverse I am missing, or is this some bounded inverse theorem (or one of the other functional analysis theorems) business.","T\in B(H) \varepsilon>0 p T [-\varepsilon,\varepsilon] [-\varepsilon,\varepsilon] T S = (1-p)T+\varepsilon p","['functional-analysis', 'operator-theory', 'operator-algebras', 'functional-calculus']"
36,Compute the inner product,Compute the inner product,,"For $n\in \mathbb{Z}$ , let $e_n: [-\pi,\pi] \rightarrow \mathbb{C}$ be defeind by $e_n(t)=e^{int}$ . We let $C[-\pi, \pi]$ denote the space of continuous $\mathbb{C}$ -valued functions on the interval $[-\pi,\pi]$ . Compute the inner product $\langle f, \frac{1}{\sqrt{2\pi}}e_n \rangle$ , for $f$ given by $f(t)= \cosh(t) = \frac{1}{2}(e^t+e^{-t})$ , $-\pi \leq t\leq \pi$ . We have $\langle f, \frac{1}{\sqrt{2\pi}}e_n \rangle = \frac{1}{2\sqrt{2\pi}}\int_{-\pi}^{\pi} (e^{t}+e^{-t})e^{int}dt = \frac{1}{2\sqrt{2\pi}}\int_{-\pi}^{\pi} e^{t}e^{int}+e^{-t}e^{int}dt  = \frac{1}{2\sqrt{2\pi}}[(\frac{e^{\pi(in-1)}}{in-1}+\frac{e^{\pi(in+1)}}{in+1})- (\frac{e^{-\pi(in-1)}}{in-1}+\frac{e^{-\pi(in+1)}}{in+1})]$ . From here, is there any way to simplify? I think I need some sort of identities here Thanks in advance!","For , let be defeind by . We let denote the space of continuous -valued functions on the interval . Compute the inner product , for given by , . We have . From here, is there any way to simplify? I think I need some sort of identities here Thanks in advance!","n\in \mathbb{Z} e_n: [-\pi,\pi] \rightarrow \mathbb{C} e_n(t)=e^{int} C[-\pi, \pi] \mathbb{C} [-\pi,\pi] \langle f, \frac{1}{\sqrt{2\pi}}e_n \rangle f f(t)= \cosh(t) = \frac{1}{2}(e^t+e^{-t}) -\pi \leq t\leq \pi \langle f, \frac{1}{\sqrt{2\pi}}e_n \rangle = \frac{1}{2\sqrt{2\pi}}\int_{-\pi}^{\pi} (e^{t}+e^{-t})e^{int}dt = \frac{1}{2\sqrt{2\pi}}\int_{-\pi}^{\pi} e^{t}e^{int}+e^{-t}e^{int}dt  = \frac{1}{2\sqrt{2\pi}}[(\frac{e^{\pi(in-1)}}{in-1}+\frac{e^{\pi(in+1)}}{in+1})- (\frac{e^{-\pi(in-1)}}{in-1}+\frac{e^{-\pi(in+1)}}{in+1})]","['complex-analysis', 'functional-analysis']"
37,On the definition of weak and weak-* topologies,On the definition of weak and weak-* topologies,,"I have been studying topological vector spaces, and despite going over numerous resources, the definitions of weak and weak-* topologies have been causing me some confusion. I am having trouble visualizing and understanding these topologies. Suppose $X$ is a normed vector space. Then the weak topology on $X$ is the topology generated by $X^*$ , in other words the weakest topology making $x \mapsto f(x)$ continuous for all $f \in X^*$ . Similarly, the weak-* topology is the weakest topology making the maps $x \mapsto f(x)$ continuous for all $x \in X$ . I see the big difference here is that one is generated by the dual and the other by the original vector space. However, I have three points of confusion. I suspect part of my difficulty may be due to not properly visualizing topologies generated by a collection of seminorms. The dual space $X^*$ is defined as the set of bounded linear functionals from $X$ to the underlying field. However, I recall reading that the boundedness of a linear map is equivalent to the map being continuous, so I fail to see what sets we are excluding in this new, weaker topology. What do the open sets (or more simply, the basis sets) look like in these two topologies? The resources I am learning this from often note a relation between the double dual $X^{**}$ and the weak-* topology, what is the relation between these spaces exactly?","I have been studying topological vector spaces, and despite going over numerous resources, the definitions of weak and weak-* topologies have been causing me some confusion. I am having trouble visualizing and understanding these topologies. Suppose is a normed vector space. Then the weak topology on is the topology generated by , in other words the weakest topology making continuous for all . Similarly, the weak-* topology is the weakest topology making the maps continuous for all . I see the big difference here is that one is generated by the dual and the other by the original vector space. However, I have three points of confusion. I suspect part of my difficulty may be due to not properly visualizing topologies generated by a collection of seminorms. The dual space is defined as the set of bounded linear functionals from to the underlying field. However, I recall reading that the boundedness of a linear map is equivalent to the map being continuous, so I fail to see what sets we are excluding in this new, weaker topology. What do the open sets (or more simply, the basis sets) look like in these two topologies? The resources I am learning this from often note a relation between the double dual and the weak-* topology, what is the relation between these spaces exactly?",X X X^* x \mapsto f(x) f \in X^* x \mapsto f(x) x \in X X^* X X^{**},"['real-analysis', 'general-topology', 'functional-analysis', 'topological-vector-spaces', 'weak-topology']"
38,Exercise 4.19 (1) of Brezis,Exercise 4.19 (1) of Brezis,,"I am trying to solve the following exercise of Brezis' book on Functional Analysis. Let $(f_n)_{n \in \mathbb{N}}$ be a sequence in $L^p(\Omega)$ with $1 < p < \infty$ and let $f \in L^p(\Omega)$ . Assume that $f_n \rightharpoonup f$ weakly $\sigma(L^p, L^{p'})$ and $\lim_{n \to \infty} ||f_n||_p = ||f||_p$ , then $f_n \rightarrow f$ strongly in $L^p(\Omega)$ . I tried to show that $(f_n)_{n \in  \mathbb{N}}$ is a Cauchy sequence in $L^p(\Omega)$ using that $(||f_n||_p)_{n \in  \mathbb{N}}$ is Cauchy since, by hypothesis, it is convergent. However, I was not able to do it. Could anyone give me a hint to continue? Moreover, in Brezis' exercise 4.19 , it is given a counterexample for this claim when $p=1$ . Is there a counterexample for $p = \infty$ ?","I am trying to solve the following exercise of Brezis' book on Functional Analysis. Let be a sequence in with and let . Assume that weakly and , then strongly in . I tried to show that is a Cauchy sequence in using that is Cauchy since, by hypothesis, it is convergent. However, I was not able to do it. Could anyone give me a hint to continue? Moreover, in Brezis' exercise 4.19 , it is given a counterexample for this claim when . Is there a counterexample for ?","(f_n)_{n \in \mathbb{N}} L^p(\Omega) 1 < p < \infty f \in L^p(\Omega) f_n \rightharpoonup f \sigma(L^p, L^{p'}) \lim_{n \to \infty} ||f_n||_p = ||f||_p f_n \rightarrow f L^p(\Omega) (f_n)_{n \in  \mathbb{N}} L^p(\Omega) (||f_n||_p)_{n \in  \mathbb{N}} p=1 p = \infty","['functional-analysis', 'lp-spaces', 'weak-convergence']"
39,"Normal operator $T$, $\sigma(T) \subset \{0,1\} \Rightarrow$ $T$ is an orthogonal projection","Normal operator ,   is an orthogonal projection","T \sigma(T) \subset \{0,1\} \Rightarrow T","Let $T$ be a bounded normal operator acting from a Hilbert space $H$ to itself. I must check that if the spectrum of $T$ lies in the set defined in the title, then $T$ is an othogonal projection. I know that $T$ is an orthogonal projection iff $T=T^*=T^2$ . I have also at my disposable multiple forms of the spectral theorem, which may come in handy. I must admit though I am still trying to grasp all the notions that are usually used in the statements of the theorem. For instance, I have seen that $T$ can be written as $$T=\int_{\sigma(T)}zE(dz)$$ where $E$ represents a spectral measure, i.e. a map from a sigma algebra to the space of projections on $H$ . Are these facts useful to our goal? Any hints are welcome, thank you.","Let be a bounded normal operator acting from a Hilbert space to itself. I must check that if the spectrum of lies in the set defined in the title, then is an othogonal projection. I know that is an orthogonal projection iff . I have also at my disposable multiple forms of the spectral theorem, which may come in handy. I must admit though I am still trying to grasp all the notions that are usually used in the statements of the theorem. For instance, I have seen that can be written as where represents a spectral measure, i.e. a map from a sigma algebra to the space of projections on . Are these facts useful to our goal? Any hints are welcome, thank you.",T H T T T T=T^*=T^2 T T=\int_{\sigma(T)}zE(dz) E H,"['functional-analysis', 'spectral-theory', 'normal-operator']"
40,"Proving the existence of a weak limit given the convergence of $\lim_{n\to\infty}(x_n,v) \forall v\in H$",Proving the existence of a weak limit given the convergence of,"\lim_{n\to\infty}(x_n,v) \forall v\in H","I've got a problem I'm a little stuck on and was curious as to a way to prove this. I've always sort of just assumed that when defining weak convergence, the weak limit automatically exists but now I cant prove it. More formally, if for a sequence $\{x_n\}$ where $\lim_{n\to\infty}(v,x_n)$ exists for all $v\in H $ , prove that there exists an $x\in H$ such that $\lim_{n\to\infty}(x_n,v)=(x,v)\quad \forall v\in H$ . My first approach was to consider the $\sup_{v\in H} \lim_{n\to\infty} \frac{1}{\Vert x_n\Vert} (x_n,\frac{v}{\Vert v\Vert})$ as something that would give me the weak limit $x$ that I desired, but after thinking about the case where $H=\ell^2$ and $x_n=e_n=(0,...,1,0,...)$ I'm uncertain, as $e_n\overset{w}{\to} 0$ .","I've got a problem I'm a little stuck on and was curious as to a way to prove this. I've always sort of just assumed that when defining weak convergence, the weak limit automatically exists but now I cant prove it. More formally, if for a sequence where exists for all , prove that there exists an such that . My first approach was to consider the as something that would give me the weak limit that I desired, but after thinking about the case where and I'm uncertain, as .","\{x_n\} \lim_{n\to\infty}(v,x_n) v\in H
 x\in H \lim_{n\to\infty}(x_n,v)=(x,v)\quad \forall v\in H \sup_{v\in H} \lim_{n\to\infty} \frac{1}{\Vert x_n\Vert} (x_n,\frac{v}{\Vert v\Vert}) x H=\ell^2 x_n=e_n=(0,...,1,0,...) e_n\overset{w}{\to} 0","['functional-analysis', 'analysis', 'weak-convergence']"
41,Inequalities stated in the solution for Brezis Exercise 5.2,Inequalities stated in the solution for Brezis Exercise 5.2,,"Here are two inequalities stated in the solution given by Brezis for Exercise 5.2 and I am not seeing why this is true: I know that when $p < 2$ , we have $\frac{2}{p} > 1$ and hence we have $$ 2(\alpha + \beta)^{\frac{2}{p}} > \alpha^{\frac{2}{p}} + \beta^{\frac{2}{p}} $$ as $\alpha^{\frac{2}{p}} < (\alpha + \beta)^{\frac{2}{p}}$ and $\beta^{\frac{2}{p}} < (\alpha + \beta)^{\frac{2}{p}}$ . However, this does not seem to be the way to see these two inequalities as there are no constant factors presented here. Moreover, I have no idea how the second inequality is true knowing $\frac{2}{p} < 1$ . It probably has to do with the convexity/concavity of the function $|x|^p$ when $p > 1$ and $p < 1$ . However, I do not see how to justify this. Update: Here is another proof on top of the accepted answer: We first show that $$(\alpha + \beta)^{\frac{2}{p}} > \alpha^{\frac{2}{p}} + \beta^{\frac{2}{p}}$$ for $\alpha, \beta > 0$ if $p < 2$ . In particular, we have $\frac{2}{p} > 1$ . Equivalently, we wish to show that $$ 1 > \left(\frac{\alpha}{\alpha + \beta}\right)^{\frac{p}{2}} + \left(\frac{\beta}{\alpha + \beta}\right)^{\frac{p}{2}}. $$ Equivalently, this is the same as showing the following statement: If $x, y \in \mathbf{R}$ , $x + y = 1$ , $0 < x, y < 1$ and $r > 1$ , then $$ x^r + y^r < 1. $$ To see this, simply note that we have $x < 1$ and $r > 1$ . Therefore, we have $x^r < x$ . Moreover, we have $y < 1$ and $r > 1$ . Therefore, we also have $y^r < y$ . This implies that we have $$ x^r + y^r < x + y = 1. $$ This shows the first inequality. Now to show the second inequality,  for the same reason as above, it is sufficient to show the statement: If $x, y \in \mathbf{R}$ , $x + y = 1$ , $0 < x, y < 1$ and $r < 1$ , then $$ x^r + y^r > 1. $$ Now since $0 < x < 1$ and $r < 1$ , we have $x^r > x$ . Similarly, since $0 < y < 1$ and $r < 1$ , we have $y^r > y$ . Therefore, we have $$ x^r + y^r > x + y = 1. $$ Therefore, we are done.","Here are two inequalities stated in the solution given by Brezis for Exercise 5.2 and I am not seeing why this is true: I know that when , we have and hence we have as and . However, this does not seem to be the way to see these two inequalities as there are no constant factors presented here. Moreover, I have no idea how the second inequality is true knowing . It probably has to do with the convexity/concavity of the function when and . However, I do not see how to justify this. Update: Here is another proof on top of the accepted answer: We first show that for if . In particular, we have . Equivalently, we wish to show that Equivalently, this is the same as showing the following statement: If , , and , then To see this, simply note that we have and . Therefore, we have . Moreover, we have and . Therefore, we also have . This implies that we have This shows the first inequality. Now to show the second inequality,  for the same reason as above, it is sufficient to show the statement: If , , and , then Now since and , we have . Similarly, since and , we have . Therefore, we have Therefore, we are done.","p < 2 \frac{2}{p} > 1 
2(\alpha + \beta)^{\frac{2}{p}} > \alpha^{\frac{2}{p}} + \beta^{\frac{2}{p}}
 \alpha^{\frac{2}{p}} < (\alpha + \beta)^{\frac{2}{p}} \beta^{\frac{2}{p}} < (\alpha + \beta)^{\frac{2}{p}} \frac{2}{p} < 1 |x|^p p > 1 p < 1 (\alpha + \beta)^{\frac{2}{p}} > \alpha^{\frac{2}{p}} + \beta^{\frac{2}{p}} \alpha, \beta > 0 p < 2 \frac{2}{p} > 1 
1 > \left(\frac{\alpha}{\alpha + \beta}\right)^{\frac{p}{2}} + \left(\frac{\beta}{\alpha + \beta}\right)^{\frac{p}{2}}.
 x, y \in \mathbf{R} x + y = 1 0 < x, y < 1 r > 1 
x^r + y^r < 1.
 x < 1 r > 1 x^r < x y < 1 r > 1 y^r < y 
x^r + y^r < x + y = 1.
 x, y \in \mathbf{R} x + y = 1 0 < x, y < 1 r < 1 
x^r + y^r > 1.
 0 < x < 1 r < 1 x^r > x 0 < y < 1 r < 1 y^r > y 
x^r + y^r > x + y = 1.
","['real-analysis', 'functional-analysis', 'inequality', 'solution-verification', 'proof-explanation']"
42,Absolute integrability and limits,Absolute integrability and limits,,"Suppose that $h \in L_1(\mathbb{R})$ and define $$ g(t) = \int_{t}^{\infty}h(\tau)\,\mathrm{d}\tau.  $$ Is it true that $\lim_{t\to\infty}g(t) = 0$ ? Seems 'obviously' true to me, but what's the formal way to argue it?","Suppose that and define Is it true that ? Seems 'obviously' true to me, but what's the formal way to argue it?","h \in L_1(\mathbb{R}) 
g(t) = \int_{t}^{\infty}h(\tau)\,\mathrm{d}\tau. 
 \lim_{t\to\infty}g(t) = 0","['real-analysis', 'functional-analysis']"
43,A sequence of functions in $L^1$ that does not converge weakly,A sequence of functions in  that does not converge weakly,L^1,"I have attempted the following part from exercise 5.49 in https://www.mat.uniroma2.it/~cannarsa/cam_0607.pdf : For every $n \in \mathbb{N}$ , let $f_n \colon \mathbb{R} \to \mathbb{R}$ be defined by: $$ f_n(x) = \begin{cases} \frac{1}{2^n}  &\text{if $x \in [2^n, 2^{n+1}]$} \\ 0 &\text{otherwise} \end{cases} $$ Show that: [...] $\{f_n\}$ does not converge weakly in $L^1(\mathbb{R})$ Is the following proof correct? Can it be made more concise? Aiming for a contradiction, suppose that $(f_n)$ does converge weakly in $L^1(\mathbb{R})$ , i.e. there is $f \in L^1(\mathbb{R})$ such that $f_n \rightharpoonup f$ . By definition, this means that for all $\phi \in (L^1(\mathbb{R}))^*$ , we have $\phi(f_n) \to \phi(f)$ . The dual of $L^1(\mathbb{R})$ contains $L^\infty(\mathbb{R})$ through the following embedding: $$ \begin{aligned} L^\infty(\mathbb{R}) &\to (L^1(\mathbb{R}))^* \\ g &\mapsto \phi_{g} \end{aligned} $$ where $\phi_g$ is defined by: $$ \phi_g(h) = \int_\mathbb{R} gh\,\mathrm{d}\mu $$ First we prove that $f$ is non-negative almost everywhere. Indeed, aiming for a contradiction, suppose it is not. This means there exists a measurable $A \subseteq \mathbb{R}$ with $f(x) < 0 $ for all $x \in A$ . Let $\chi_A$ denote the characteristic function of $A$ , which is in $L^\infty(\mathbb{R})$ , and consider $\phi_{\chi_A} \in (L^1(\mathbb{R}))^*$ . On the one hand we have: $$\phi_{\chi_A}(f) = \int_\mathbb{R} \chi_A f\,\mathrm{d}\mu = \int_A f\,\mathrm{d}\mu < 0$$ On the other hand, for all $n$ , since $f_n \ge 0$ , we have: $$\phi_{\chi_A}(f_n) = \int_\mathbb{R} {\chi_A}f_n\,\mathrm{d}\mu = \int_A f_n\,\mathrm{d}\mu \ge 0$$ So $\phi_{\chi_A}(f_n)$ cannot converge to $\phi_{\chi_A}(f)$ as $n \to \infty$ , contradicting the assumption that $f_n$ converges weakly to $f$ . Now, we prove that $f$ must in fact be zero almost everywhere. For any $m \in \mathbb{N}$ , consider $g_m := {\chi_{[2^m,2^{m+1}]}} \in L^\infty(\mathbb{R})$ and the corresponding functional $\phi_{g_m} \in (L^1(\mathbb{R}))^*$ . Then: $$\phi_{g_m}(f_n) = \int_{[2^m, 2^{m+1}]} f_n \,\mathrm{d}\mu = \begin{cases} \frac{1}{2^n} (2^{n+1}-2^n) = 1 &\text{if $n = m$} \\ 0 &\text{otherwise} \end{cases} $$ Hence $\phi_{g_m}(f_n) \to 0$ as $n \to \infty$ . But by hypothesis $\phi_{g_m}(f_n) \to \phi_{g_m}(f)$ , so $\phi_{g_m}(f) = 0$ . That is: $$\int_{[2^m,2^{m+1}]} f\,\mathrm{d}\mu = 0$$ Since we have shown that $f$ is non-negative almost everywhere, this implies it is in fact zero almost everywhere on $[2^m, 2^{m + 1}]$ . But this is true for all $m \in \mathbb{N}$ , and since a countable union of null sets is still null, this means $f$ is zero almost everywhere on $\bigcup_{m \in \mathbb{N}} [2^m, 2^{m+1}] = [1, \infty)$ . Apply the same kind of argument with $\phi_{\chi_{(-\infty, 1]}}$ to show that $f$ is zero almost everywhere on $(-\infty, 1]$ , concluding that $f$ is zero almost everywhere on all of $\mathbb{R}$ . So far we have proven that, assuming $f_n \rightharpoonup f$ , we have that $f$ is zero almost everywhere. But this leads to a contradiction. Indeed, consider the constantly-1 function ${\chi_{\mathbb{R}}}$ and the corresponding functional $\phi_{\chi_\mathbb{R}} \in (L^1(\mathbb{R}))^*$ , which is just integration (on all of $\mathbb{R}$ ). Then: $$\phi_{\chi_\mathbb{R}}(f_n) = \int_\mathbb{R} f_n\,\mathrm{d}\mu = \frac{1}{2^n}(2^{n+1}-2^n) = 1 \to 1 \text{ as $n \to \infty$}$$ However, since $f$ is zero almost everywhere: $$\phi_{\chi_\mathbb{R}}(f) = \int_\mathbb{R} f\,\mathrm{d}\mu = 0$$ Thus $\phi_{\chi_\mathbb{R}}(f_n) \nrightarrow \phi_{\chi_\mathbb{R}}(f)$ , contradicting our initial assumption of the weak convergence of $(f_n)$ to $f$ .","I have attempted the following part from exercise 5.49 in https://www.mat.uniroma2.it/~cannarsa/cam_0607.pdf : For every , let be defined by: Show that: [...] does not converge weakly in Is the following proof correct? Can it be made more concise? Aiming for a contradiction, suppose that does converge weakly in , i.e. there is such that . By definition, this means that for all , we have . The dual of contains through the following embedding: where is defined by: First we prove that is non-negative almost everywhere. Indeed, aiming for a contradiction, suppose it is not. This means there exists a measurable with for all . Let denote the characteristic function of , which is in , and consider . On the one hand we have: On the other hand, for all , since , we have: So cannot converge to as , contradicting the assumption that converges weakly to . Now, we prove that must in fact be zero almost everywhere. For any , consider and the corresponding functional . Then: Hence as . But by hypothesis , so . That is: Since we have shown that is non-negative almost everywhere, this implies it is in fact zero almost everywhere on . But this is true for all , and since a countable union of null sets is still null, this means is zero almost everywhere on . Apply the same kind of argument with to show that is zero almost everywhere on , concluding that is zero almost everywhere on all of . So far we have proven that, assuming , we have that is zero almost everywhere. But this leads to a contradiction. Indeed, consider the constantly-1 function and the corresponding functional , which is just integration (on all of ). Then: However, since is zero almost everywhere: Thus , contradicting our initial assumption of the weak convergence of to .","n \in \mathbb{N} f_n \colon \mathbb{R} \to \mathbb{R}  f_n(x) = \begin{cases} \frac{1}{2^n}  &\text{if x \in [2^n, 2^{n+1}]} \\ 0 &\text{otherwise} \end{cases}  \{f_n\} L^1(\mathbb{R}) (f_n) L^1(\mathbb{R}) f \in L^1(\mathbb{R}) f_n \rightharpoonup f \phi \in (L^1(\mathbb{R}))^* \phi(f_n) \to \phi(f) L^1(\mathbb{R}) L^\infty(\mathbb{R})  \begin{aligned} L^\infty(\mathbb{R}) &\to (L^1(\mathbb{R}))^* \\ g &\mapsto \phi_{g} \end{aligned}  \phi_g  \phi_g(h) = \int_\mathbb{R} gh\,\mathrm{d}\mu  f A \subseteq \mathbb{R} f(x) < 0  x \in A \chi_A A L^\infty(\mathbb{R}) \phi_{\chi_A} \in (L^1(\mathbb{R}))^* \phi_{\chi_A}(f) = \int_\mathbb{R} \chi_A f\,\mathrm{d}\mu = \int_A f\,\mathrm{d}\mu < 0 n f_n \ge 0 \phi_{\chi_A}(f_n) = \int_\mathbb{R} {\chi_A}f_n\,\mathrm{d}\mu = \int_A f_n\,\mathrm{d}\mu \ge 0 \phi_{\chi_A}(f_n) \phi_{\chi_A}(f) n \to \infty f_n f f m \in \mathbb{N} g_m := {\chi_{[2^m,2^{m+1}]}} \in L^\infty(\mathbb{R}) \phi_{g_m} \in (L^1(\mathbb{R}))^* \phi_{g_m}(f_n) = \int_{[2^m, 2^{m+1}]} f_n \,\mathrm{d}\mu = \begin{cases} \frac{1}{2^n} (2^{n+1}-2^n) = 1 &\text{if n = m} \\ 0 &\text{otherwise} \end{cases}  \phi_{g_m}(f_n) \to 0 n \to \infty \phi_{g_m}(f_n) \to \phi_{g_m}(f) \phi_{g_m}(f) = 0 \int_{[2^m,2^{m+1}]} f\,\mathrm{d}\mu = 0 f [2^m, 2^{m + 1}] m \in \mathbb{N} f \bigcup_{m \in \mathbb{N}} [2^m, 2^{m+1}] = [1, \infty) \phi_{\chi_{(-\infty, 1]}} f (-\infty, 1] f \mathbb{R} f_n \rightharpoonup f f {\chi_{\mathbb{R}}} \phi_{\chi_\mathbb{R}} \in (L^1(\mathbb{R}))^* \mathbb{R} \phi_{\chi_\mathbb{R}}(f_n) = \int_\mathbb{R} f_n\,\mathrm{d}\mu = \frac{1}{2^n}(2^{n+1}-2^n) = 1 \to 1 \text{ as n \to \infty} f \phi_{\chi_\mathbb{R}}(f) = \int_\mathbb{R} f\,\mathrm{d}\mu = 0 \phi_{\chi_\mathbb{R}}(f_n) \nrightarrow \phi_{\chi_\mathbb{R}}(f) (f_n) f","['functional-analysis', 'solution-verification', 'lp-spaces', 'weak-convergence']"
44,When is a group von Neumann algebra a factor?,When is a group von Neumann algebra a factor?,,"It is well-known that a von Neumann algebra (on a separable Hilbert space) can be written as a direct integrals of factors, i.e., von Neumann algebras with center $\mathbb C I$ . As such, factors play a central role in the structure theory of von Neumann algebras. A prime example of von Neumann algebras are group von Neumann algebras, constructed as follows: Given a countable discrete group $G$ , let $$ \lambda\colon G\to B(\ell^2(G)),\,\lambda_g\delta_h=\delta_{gh}. $$ The group von Neumann algebra $L(G)$ is the von Neumann algebra generated by $\lambda(G)$ . Question: When is the group von Neumann algebra a factor?","It is well-known that a von Neumann algebra (on a separable Hilbert space) can be written as a direct integrals of factors, i.e., von Neumann algebras with center . As such, factors play a central role in the structure theory of von Neumann algebras. A prime example of von Neumann algebras are group von Neumann algebras, constructed as follows: Given a countable discrete group , let The group von Neumann algebra is the von Neumann algebra generated by . Question: When is the group von Neumann algebra a factor?","\mathbb C I G 
\lambda\colon G\to B(\ell^2(G)),\,\lambda_g\delta_h=\delta_{gh}.
 L(G) \lambda(G)","['functional-analysis', 'group-theory', 'operator-algebras', 'von-neumann-algebras']"
45,Showing $\int_A f_jg\rightarrow 0$,Showing,\int_A f_jg\rightarrow 0,"Let $f_j\in L^P\cap L^1_{loc}$ and $g\in L^q$ where $p,q$ are conjugates and $||f_j||_p \lt M$ for all $j$ . I have that $\int_S f_j\rightarrow 0$ for all $S\subset{A}$ (measurable) where $A$ is a compact subset of $\mathbb{R}$ and want to show $\int_A f_jg\rightarrow 0$ . Since $A$ is bounded, $g\in L^q\implies g\in L^\infty$ so I want to write down something like $|\int _A f_j g|\le ||g||_{L^\infty} |\int f_j|$ . But this is false. I can only use the tools that I know if I control $\int |f|$ , but I've already come up with counterexamples to show we have no control over that so considering $\int |f_jg|$ is useless.  Another idea was to use Cauchy schwarz but we need not have $\int f_j^2 \rightarrow 0$","Let and where are conjugates and for all . I have that for all (measurable) where is a compact subset of and want to show . Since is bounded, so I want to write down something like . But this is false. I can only use the tools that I know if I control , but I've already come up with counterexamples to show we have no control over that so considering is useless.  Another idea was to use Cauchy schwarz but we need not have","f_j\in L^P\cap L^1_{loc} g\in L^q p,q ||f_j||_p \lt M j \int_S f_j\rightarrow 0 S\subset{A} A \mathbb{R} \int_A f_jg\rightarrow 0 A g\in L^q\implies g\in L^\infty |\int _A f_j g|\le ||g||_{L^\infty} |\int f_j| \int |f| \int |f_jg| \int f_j^2 \rightarrow 0","['real-analysis', 'functional-analysis', 'analysis', 'measure-theory']"
46,"Is the image of a closed subset in a Banach space under a lineal and continuous projection always closed? If the answer is no, is there any example?","Is the image of a closed subset in a Banach space under a lineal and continuous projection always closed? If the answer is no, is there any example?",,"I was wondering if the following conjecture is true: let $X$ be a Banach space, let $P: X\to X$ be a continuous linear projection, and let $C$ be a closed subspace (unrelated to $P$ ) of $X$ . Then the image $P[C]$ is closed. By saying that $C$ is not related to $P$ , I mean that we do not suppose that $C$ is contained in the image of $P$ , that is, we do not know any relationship between $C$ and $P$ . I have thought that the continuity of $P$ implies the continuity of $I-P$ . But it turns out that $Ker (I-P)$ doesn't depend on $C$ . So I don't know how to proceed. Thanks for your help friends.","I was wondering if the following conjecture is true: let be a Banach space, let be a continuous linear projection, and let be a closed subspace (unrelated to ) of . Then the image is closed. By saying that is not related to , I mean that we do not suppose that is contained in the image of , that is, we do not know any relationship between and . I have thought that the continuity of implies the continuity of . But it turns out that doesn't depend on . So I don't know how to proceed. Thanks for your help friends.",X P: X\to X C P X P[C] C P C P C P P I-P Ker (I-P) C,['functional-analysis']
47,Why is this projection of rank 1?,Why is this projection of rank 1?,,"I'm reading the following proof excerpt from a textbook that state the following: Let $E$ be an orthonormal basis of a Hilbert space $H$ .  For $e \in E$ , define $p_e = e \otimes e$ for $e \otimes e: H \longrightarrow H$ given by $(e \otimes e)(z) = \langle z,e \rangle e$ .  Then $p_e$ is a projection of rank $1$ with $p_eK(H)p_e = \mathbb{C}p_e$ with $K(H)$ the collection of compact operators on $H$ . Let $H'$ be another Hilbert space, and suppose that $\varphi: K(H) \longrightarrow K(H')$ is a $*$ isomorphism.  Then $q_e = \varphi(p_e)$ is a projection satisfying $q_eK(H')q_e= \mathbb{C}q_e$ .  It's clear also that $q_e$ is of rank $1$ too. Why is $q_e$ of rank one?  I know that $q_e=q_e\varphi(v)q_e$ for $v$ the rank $1$ operator that sends $x \mapsto \beta e$ .  I.e, $v$ takes an $x \in H$ (which is represented in terms of the orthonormal basis $E$ on $H$ ), to $\beta e$ , where $\beta$ is the coefficient in front of $e$ in the basis representation of $x$ (as then the range of $v$ is $\text{Span}(e)$ and $\langle v(e),e \rangle =1$ , so $p_e=p_evp_e$ ). However, I don't see why this arbitrary $*$ isomorphism sends the rank $1$ operator $v$ to another rank $1$ operator.","I'm reading the following proof excerpt from a textbook that state the following: Let be an orthonormal basis of a Hilbert space .  For , define for given by .  Then is a projection of rank with with the collection of compact operators on . Let be another Hilbert space, and suppose that is a isomorphism.  Then is a projection satisfying .  It's clear also that is of rank too. Why is of rank one?  I know that for the rank operator that sends .  I.e, takes an (which is represented in terms of the orthonormal basis on ), to , where is the coefficient in front of in the basis representation of (as then the range of is and , so ). However, I don't see why this arbitrary isomorphism sends the rank operator to another rank operator.","E H e \in E p_e = e \otimes e e \otimes e: H \longrightarrow H (e \otimes e)(z) = \langle z,e \rangle e p_e 1 p_eK(H)p_e = \mathbb{C}p_e K(H) H H' \varphi: K(H) \longrightarrow K(H') * q_e = \varphi(p_e) q_eK(H')q_e= \mathbb{C}q_e q_e 1 q_e q_e=q_e\varphi(v)q_e v 1 x \mapsto \beta e v x \in H E H \beta e \beta e x v \text{Span}(e) \langle v(e),e \rangle =1 p_e=p_evp_e * 1 v 1","['functional-analysis', 'analysis', 'proof-explanation', 'operator-theory', 'hilbert-spaces']"
48,Is the collection of Gaussian functions $\mathcal F=\{\exp(-ax^2):a\geq0\}$ a basis?,Is the collection of Gaussian functions  a basis?,\mathcal F=\{\exp(-ax^2):a\geq0\},"Is the collection of Gaussian functions $\mathcal F=\{\exp(-ax^2):a\geq0\}$ a basis for the space of all smooth functions on $\mathbb R^+$ ? Seems that this collection is linearly independent. Is this also a basis? EDIT: When I say basis, I am allowing infinite sums from this set, that is, given any smooth function $f$ on $\mathbb R^+$ , do we have a measure $\mu_f$ such that $f(x)=\int_{supp(\mu)} \exp(-ax^2)d\mu_f(a)$ for every $x\in\mathbb R^+$ ? I am not sure what $\mathcal F$ would be called if this happens, is this still called a ""basis""?","Is the collection of Gaussian functions a basis for the space of all smooth functions on ? Seems that this collection is linearly independent. Is this also a basis? EDIT: When I say basis, I am allowing infinite sums from this set, that is, given any smooth function on , do we have a measure such that for every ? I am not sure what would be called if this happens, is this still called a ""basis""?",\mathcal F=\{\exp(-ax^2):a\geq0\} \mathbb R^+ f \mathbb R^+ \mu_f f(x)=\int_{supp(\mu)} \exp(-ax^2)d\mu_f(a) x\in\mathbb R^+ \mathcal F,"['real-analysis', 'functional-analysis', 'analysis']"
49,Predual of disc algebra and $W(\mathbb{T})\neq A(\mathbb{D})$,Predual of disc algebra and,W(\mathbb{T})\neq A(\mathbb{D}),"I want prove that the Wiener algebra , $W(\mathbb{T})$ , does not coincide with the disc algebra $A(\mathbb{D})$ . I know that there are some ways to do this. For example, one smart way is use Rudin-Shapiro sequence, see this post . Note that $W(\mathbb{T})$ is an isometry to $\ell^1$ , with pre-dual $c$ (or $c_0$ , even something else ). However, I never hear story about the pre-dual of disc algebra . Question: Does $A(\mathbb{D})$ has pre-dual? What it is?","I want prove that the Wiener algebra , , does not coincide with the disc algebra . I know that there are some ways to do this. For example, one smart way is use Rudin-Shapiro sequence, see this post . Note that is an isometry to , with pre-dual (or , even something else ). However, I never hear story about the pre-dual of disc algebra . Question: Does has pre-dual? What it is?",W(\mathbb{T}) A(\mathbb{D}) W(\mathbb{T}) \ell^1 c c_0 A(\mathbb{D}),"['functional-analysis', 'banach-spaces', 'banach-algebras', 'dual-spaces']"
50,"Show that $\limsup_{s,\:t\:\to\:\tau}\left\|x(s)-x(t)\right\|_E\ge r$ implies $\left\|\Delta x(\tau)\right\|_E\ge r$",Show that  implies,"\limsup_{s,\:t\:\to\:\tau}\left\|x(s)-x(t)\right\|_E\ge r \left\|\Delta x(\tau)\right\|_E\ge r","Let $E$ be a normed $\mathbb R$ -vector space, and $x:[0,\infty)\to\mathbb R$ be right-continuous. Assume $x$ $$x(t-):=\lim_{s\to t-}x(s)$$ exists for all $t\in O$ and let $$\Delta x(t):=x(t)-x(t-)\;\;\;\text{for }t\ge0.$$ Let $\tau\ge0$ and $r>0$ with $$\ell:=\limsup_{s,\:t\:\to\:\tau}\left\|x(s)-x(t)\right\|_E\ge r\tag1.$$ How can we conclude that $\left\|x(\tau)\right\|_E\ge r$ ? Intuitively, this should be easy to verify, but I'm unable to prove it rigorously. Since we can show that the assumptions imply that $x$ is bounded on each compact interval, we've clearly got $\ell<\infty$ . From this we can deduce that for all $\varepsilon>0$ , there is a $\delta>0$ with $$\left\|x(s)-x(t)\right\|_E<\ell+\varepsilon\tag2$$ for all $s,t\ge0$ with $\max(|s-\tau|,|t-\tau|)<\delta$ . In particular, $$\left\|x(\tau)-x(t)\right\|_E<\ell+\varepsilon\tag3$$ for all $t\in(\tau-\delta,\tau)$ . On the other hand, we have $$\left\|\Delta x(\tau)\right\|_E=\lim_{t\to\tau-}\left\|x(\tau)-x(t)\right\|_E\tag4$$ and hence there is a $\tilde\delta$ with $$\left|\left\|x(\tau)-x(t)\right\|_E-\left\|\Delta x(\tau)\right\|_E\right|<\varepsilon\tag5$$ for all $t\in(\tau-\delta\tilde,\tau)$ . But how can we conclude?","Let be a normed -vector space, and be right-continuous. Assume exists for all and let Let and with How can we conclude that ? Intuitively, this should be easy to verify, but I'm unable to prove it rigorously. Since we can show that the assumptions imply that is bounded on each compact interval, we've clearly got . From this we can deduce that for all , there is a with for all with . In particular, for all . On the other hand, we have and hence there is a with for all . But how can we conclude?","E \mathbb R x:[0,\infty)\to\mathbb R x x(t-):=\lim_{s\to t-}x(s) t\in O \Delta x(t):=x(t)-x(t-)\;\;\;\text{for }t\ge0. \tau\ge0 r>0 \ell:=\limsup_{s,\:t\:\to\:\tau}\left\|x(s)-x(t)\right\|_E\ge r\tag1. \left\|x(\tau)\right\|_E\ge r x \ell<\infty \varepsilon>0 \delta>0 \left\|x(s)-x(t)\right\|_E<\ell+\varepsilon\tag2 s,t\ge0 \max(|s-\tau|,|t-\tau|)<\delta \left\|x(\tau)-x(t)\right\|_E<\ell+\varepsilon\tag3 t\in(\tau-\delta,\tau) \left\|\Delta x(\tau)\right\|_E=\lim_{t\to\tau-}\left\|x(\tau)-x(t)\right\|_E\tag4 \tilde\delta \left|\left\|x(\tau)-x(t)\right\|_E-\left\|\Delta x(\tau)\right\|_E\right|<\varepsilon\tag5 t\in(\tau-\delta\tilde,\tau)","['real-analysis', 'functional-analysis', 'continuity', 'stochastic-analysis']"
51,Unitary representation of $G$ induces representation of $L^1(G)$,Unitary representation of  induces representation of,G L^1(G),"I am reading Davidson's ' $C^*$ algebras by example'. In chapter VII regarding group $C^*$ algebras, he makes the following claim which I do not understand: When $\pi$ is a unitary representation of a Hausdorff, locally compact group $G$ , it induces a representation of $L^1(G)$ by integration: $$\tilde \pi(f)=\int f(t)\pi(t)dt$$ Here, a unitary representation is a representation of $G$ on a subgroup of unitaries in $B(H)$ , where $H$ is some Hilbert space. I do not understand how exactly this gives a representation (and in fact how it is even defined). First of all, if $\pi(t)$ is an operator, how do we integrate over it with respect to the function $f$ ? Doesn't this only makes sense if $\pi(t)\in \mathbb C$ ? And why is the LHS even an operator? What Hilbert space does it act on and what does it do? I'd appreciate any clarification. Thanks in advance!","I am reading Davidson's ' algebras by example'. In chapter VII regarding group algebras, he makes the following claim which I do not understand: When is a unitary representation of a Hausdorff, locally compact group , it induces a representation of by integration: Here, a unitary representation is a representation of on a subgroup of unitaries in , where is some Hilbert space. I do not understand how exactly this gives a representation (and in fact how it is even defined). First of all, if is an operator, how do we integrate over it with respect to the function ? Doesn't this only makes sense if ? And why is the LHS even an operator? What Hilbert space does it act on and what does it do? I'd appreciate any clarification. Thanks in advance!",C^* C^* \pi G L^1(G) \tilde \pi(f)=\int f(t)\pi(t)dt G B(H) H \pi(t) f \pi(t)\in \mathbb C,"['functional-analysis', 'representation-theory', 'operator-algebras', 'c-star-algebras', 'representation-of-algebras']"
52,Bound L^2 norm of gradient by L^infinity norm,Bound L^2 norm of gradient by L^infinity norm,,"For $u\in H^1_{loc}(\mathbb{R}^2)$ a weak solution to $$-div(a\cdot \nabla u) = 0$$ with $a_{ij}$ constant and strongly ellipctic, we showed that $$\int_{B(x_0,s)} |\nabla u|^2 dx \leq \left(\frac{2s}{r}\right)^\alpha \int_{B(x_0,r)} |\nabla u|^2 dx $$ for some constant $\alpha > 0$ . Our goal is now to show a version of Liouvilles theorem i.e. that if in addition $u\in L_\infty(\mathbb{R}^2)$ , $u$ must already be constant. My idea is to bound $\int_{B(x_0,r)} |\nabla u|^2 dx$ somehow and then let $r\to\infty$ . This way we would get for all $x_0$ and $s$ that $u$ is constant on $B(x_0,s)$ etc. The problem is now to bound the integral. I thought to this end we want to show $$||\nabla u ||_{L^2(V)} \leq C$$ for some constant $C$ and all compact $V$ , where I assumed that it would be something like $c\cdot ||u||_\infty$ for some other constant $c$ . But as pointed out in the answers, there are counterexamples. It feels like I‘m mentally blocked (or as we would say in Germany „ich hab ein Brett vorm Kopf“). Thanks for the help!","For a weak solution to with constant and strongly ellipctic, we showed that for some constant . Our goal is now to show a version of Liouvilles theorem i.e. that if in addition , must already be constant. My idea is to bound somehow and then let . This way we would get for all and that is constant on etc. The problem is now to bound the integral. I thought to this end we want to show for some constant and all compact , where I assumed that it would be something like for some other constant . But as pointed out in the answers, there are counterexamples. It feels like I‘m mentally blocked (or as we would say in Germany „ich hab ein Brett vorm Kopf“). Thanks for the help!","u\in H^1_{loc}(\mathbb{R}^2) -div(a\cdot \nabla u) = 0 a_{ij} \int_{B(x_0,s)} |\nabla u|^2 dx \leq \left(\frac{2s}{r}\right)^\alpha \int_{B(x_0,r)} |\nabla u|^2 dx  \alpha > 0 u\in L_\infty(\mathbb{R}^2) u \int_{B(x_0,r)} |\nabla u|^2 dx r\to\infty x_0 s u B(x_0,s) ||\nabla u ||_{L^2(V)} \leq C C V c\cdot ||u||_\infty c","['functional-analysis', 'normed-spaces', 'sobolev-spaces']"
53,Can this set be open in a topological vector space?,Can this set be open in a topological vector space?,,"Let $X$ be a topological vector space, where the topology (as in Rudin's Functional Analysis ) is such that, every singleton is a closed set, the vector space operations are continuous. Now consider the set $S \subset X$ with the following property. $0 \in S$ , for a nonzero $v \in X$ and all $0 < t < a \in \mathbb R$ , we have $tv \notin S$ . Can $S$ be open ? some may argue that the open ball $B_r(0)$ , an open beighborhood, intersects $tv$ and so $0$ is not an interior point of $S$ and therefore $S$ can't be open. But that is cheating, since there may be no metric or norm on the space to tell what is an open ball, I know that $0$ looks like a boundary point but how to show that for a vector topology. If my reasoning is wrong somewhere, please hint! Added: If am I allowed to take the discrete topology, which doesn't seem to be inconsistant with the vector topology above, then perhaps $S$ is open, but only if the field of scalars has this (discrete) topology too, otherwise, e.g. for $\mathbb R$ , it is not going to be the case. Correct me if I'm wrong Added: What are the further conditions on the vector topology such that $S$ is open, if we exclude the (trivial) discrete topology ?","Let be a topological vector space, where the topology (as in Rudin's Functional Analysis ) is such that, every singleton is a closed set, the vector space operations are continuous. Now consider the set with the following property. , for a nonzero and all , we have . Can be open ? some may argue that the open ball , an open beighborhood, intersects and so is not an interior point of and therefore can't be open. But that is cheating, since there may be no metric or norm on the space to tell what is an open ball, I know that looks like a boundary point but how to show that for a vector topology. If my reasoning is wrong somewhere, please hint! Added: If am I allowed to take the discrete topology, which doesn't seem to be inconsistant with the vector topology above, then perhaps is open, but only if the field of scalars has this (discrete) topology too, otherwise, e.g. for , it is not going to be the case. Correct me if I'm wrong Added: What are the further conditions on the vector topology such that is open, if we exclude the (trivial) discrete topology ?",X S \subset X 0 \in S v \in X 0 < t < a \in \mathbb R tv \notin S S B_r(0) tv 0 S S 0 S \mathbb R S,"['general-topology', 'functional-analysis', 'topological-vector-spaces']"
54,Is this a basis for the bounded operators on $ L^2(\mathbb{R}) $?,Is this a basis for the bounded operators on ?, L^2(\mathbb{R}) ,"Let $ L^2=L^2(\mathbb{R}) $ . For every pair $ a,b $ of real numbers define the operator $ U_{a,b} $ on $ L^2 $ sending $ \psi \in L^2 $ to $ U_{a,b}\psi $ defined by the equation $$ [U_{a,b}\psi](x)=e^{ibx}\psi(x+a) $$ Consider the set of operators $$ \mathcal{B}:=\{ U_{a,b}:a,b \in \mathbb{R} \} $$ Is $ \mathcal{B} $ a basis for the space of bounded operators on $ L^2 $ ? They seem linearly independent and it also seems like the span should be a subalgebra at least. But is the closure of the span of $ \mathcal{B} $ all of the bounded operators on $ L^2 $ ?",Let . For every pair of real numbers define the operator on sending to defined by the equation Consider the set of operators Is a basis for the space of bounded operators on ? They seem linearly independent and it also seems like the span should be a subalgebra at least. But is the closure of the span of all of the bounded operators on ?," L^2=L^2(\mathbb{R})   a,b   U_{a,b}   L^2   \psi \in L^2   U_{a,b}\psi  
[U_{a,b}\psi](x)=e^{ibx}\psi(x+a)
 
\mathcal{B}:=\{ U_{a,b}:a,b \in \mathbb{R} \}
  \mathcal{B}   L^2   \mathcal{B}   L^2 ","['functional-analysis', 'operator-theory', 'representation-theory', 'hilbert-spaces', 'operator-algebras']"
55,Counterexample in non-Hilbert space that weak convergence in norm and convergence of norms does not imply strong convergence,Counterexample in non-Hilbert space that weak convergence in norm and convergence of norms does not imply strong convergence,,"See this question: Weak convergence and convergence of norms imply strong convergence in Hilbert space But how can I find a counterexample if we relax the requirement that the space is Hilbert? I mean if we drop reflexivity of Banach spaces, then there should be a counterexample, but I can't think of any yet.","See this question: Weak convergence and convergence of norms imply strong convergence in Hilbert space But how can I find a counterexample if we relax the requirement that the space is Hilbert? I mean if we drop reflexivity of Banach spaces, then there should be a counterexample, but I can't think of any yet.",,"['functional-analysis', 'banach-spaces', 'weak-convergence']"
56,Prove that E is reflexive.,Prove that E is reflexive.,,"QUESTION: Let $E$ be a Banach space where $E'$ is the dual space of $E$ . Assume the $E'$ is separable and suppose that for all neighborhood $V$ of $\sigma(E', E'')$ is there exists a neighborhood of $W\in \sigma(E', E)$ such that $W\subset V$ . Show that $E$ is reflexive. MY ATTEMPT: We have that $E$ is also separable, because $E$ is a Banach space, and $E'$ is separable. Therefore, to show that $E$ is reflexive, we only need to show that $E'$ is reflexive (by another theorem). Now, by Kakutani's theorem, it is enough show that the closure of $B_{E'}$ (the unit ball in $E'$ ) is compact in $\sigma(E', E'')$ . Let $\{V_{\lambda}\}_{\lambda\in \Gamma}$ be an open cover of the ball $\overline{B_{E'}}$ . On the other hand, by Banach-Alaogly-Bourbaki's theorem, $\overline{B_{E'}}$ is compact in $\sigma(E', E)$ . Now, from the statement we can infer that $\{W_{\lambda}\}_{\lambda \in \Gamma}$ is another an open cover of $\overline{B_{E'}}$ , then is there exists $k\in \mathbb{N}$ such that $\overline{B_{E'}}\subset \displaystyle\bigcup_{k=1}^{n}W_{\lambda_k}$ . And because $W_{\lambda_k}\subset V_{\lambda_k}$ (I'm not very sure in how to explain this). Thus, $\overline{B_{E'}}\subset \displaystyle\bigcup_{k=1}^{n}V_{\lambda_k}$ . Therefore $\overline{B_{E'}}$ is compact in $\sigma(E, E'')$ , then by Kakutani's theorem this implies that $E'$ is reflexive, which implies (by other result) that $E$ is itself reflexive. DOUBT: Well, I do not feel that every step above is right. I mean I would like to give more explanations, to provide another proof more step by step. Would you help me with this, please? Thanks in advance. P.S.: I thought maybe it is possible to use Eberlein-Smulian theorem's too. Other idea, using @David Mitra MY SECOND ATTEMPT: Because $E'$ is separable then is there exists a sequence $(x_n)\in E$ such that $\|x_n\|=1$ , $\forall \; n$ and holds that $x_n\rightharpoonup 0$ weakly. (I've proved this using that $E'$ is separable (by definition is there exist a subset $D$ which is contable and dense in $E'$ .)). At the end I've used this result to prove that $\|f_n-f\|\leq \epsilon$ for every $f, f_n\in D$ , $\forall \epsilon>0$ . Thus forall $k>n$ we have that $\|f(x_k)-0\|\longrightarrow 0$ as $m\rightarrow +\infty$ . Therefore, $x_k\rightharpoonup$ weakly. Then, there is $M>0$ , such that $\|x_k\|\leq M$ , i.e., $(x_k)$ is bounded. Hence, by the Eberlein-Smulian theorem this implies that $E$ is reflexive.","QUESTION: Let be a Banach space where is the dual space of . Assume the is separable and suppose that for all neighborhood of is there exists a neighborhood of such that . Show that is reflexive. MY ATTEMPT: We have that is also separable, because is a Banach space, and is separable. Therefore, to show that is reflexive, we only need to show that is reflexive (by another theorem). Now, by Kakutani's theorem, it is enough show that the closure of (the unit ball in ) is compact in . Let be an open cover of the ball . On the other hand, by Banach-Alaogly-Bourbaki's theorem, is compact in . Now, from the statement we can infer that is another an open cover of , then is there exists such that . And because (I'm not very sure in how to explain this). Thus, . Therefore is compact in , then by Kakutani's theorem this implies that is reflexive, which implies (by other result) that is itself reflexive. DOUBT: Well, I do not feel that every step above is right. I mean I would like to give more explanations, to provide another proof more step by step. Would you help me with this, please? Thanks in advance. P.S.: I thought maybe it is possible to use Eberlein-Smulian theorem's too. Other idea, using @David Mitra MY SECOND ATTEMPT: Because is separable then is there exists a sequence such that , and holds that weakly. (I've proved this using that is separable (by definition is there exist a subset which is contable and dense in .)). At the end I've used this result to prove that for every , . Thus forall we have that as . Therefore, weakly. Then, there is , such that , i.e., is bounded. Hence, by the Eberlein-Smulian theorem this implies that is reflexive.","E E' E E' V \sigma(E', E'') W\in \sigma(E', E) W\subset V E E E E' E E' B_{E'} E' \sigma(E', E'') \{V_{\lambda}\}_{\lambda\in \Gamma} \overline{B_{E'}} \overline{B_{E'}} \sigma(E', E) \{W_{\lambda}\}_{\lambda \in \Gamma} \overline{B_{E'}} k\in \mathbb{N} \overline{B_{E'}}\subset \displaystyle\bigcup_{k=1}^{n}W_{\lambda_k} W_{\lambda_k}\subset V_{\lambda_k} \overline{B_{E'}}\subset \displaystyle\bigcup_{k=1}^{n}V_{\lambda_k} \overline{B_{E'}} \sigma(E, E'') E' E E' (x_n)\in E \|x_n\|=1 \forall \; n x_n\rightharpoonup 0 E' D E' \|f_n-f\|\leq \epsilon f, f_n\in D \forall \epsilon>0 k>n \|f(x_k)-0\|\longrightarrow 0 m\rightarrow +\infty x_k\rightharpoonup M>0 \|x_k\|\leq M (x_k) E","['functional-analysis', 'weak-topology']"
57,Solution of elliptic problem is a minimizer of certain functional,Solution of elliptic problem is a minimizer of certain functional,,"Let $f$ be continuously differentiable convex function on $\mathbb{R}$ and $U$ be Lipschitz domain. Suppose $u \in C^2(U) \cap C(\overline{U})$ is a solution to the following problem \begin{cases}  -\Delta u + f'(u)=0  \ \ \ \ \ \ \ \text{ in }  \ \  U, \\ u(x)= 0  \ \ \ \ \ \ \ \text{ in } \ \ \ \partial U, \end{cases} Show that $u$ is a minimizer for the following functional $$ \int_{U} \frac{|\nabla u|^2}{2} + f(u) \ \ dx$$ over all functions that vanish at the boundary. That is, if $v = 0$ on $\partial U$ , then the following hold $$ \int_{U} \frac{|\nabla u|^2}{2}  + f(u) \ \  dx \leq \int_{U} \frac{|\nabla v|^2}{2} + f(v) \ \  dx$$ My attempt: Let $J(u) =\int_{U} \frac{|\nabla u|^2}{2}  + f(u) \ \  dx$ . Suppose $v$ solves the problem and define $w = v-u$ . Then I want to show $J(v) \geq J(u)$ \begin{align} J(v) = J(u + w) &=  \int_{U} \frac{|\nabla u|^2}{2}  + f(u) \ \  dx + \int_{U} \frac{|\nabla w|^2}{2}  + f(w) \ \  dx + \int_U \nabla u \cdot \nabla w \ \ dx\\ &= J(u) + J(w) + a(u,w) \end{align} Now it is clear that $J(w) \geq 0$ . How to deal with the form $a(u,w)$ to conclude the desired inequality? How to relate that to the latter part of the question including the inequality over the defined space of functions?","Let be continuously differentiable convex function on and be Lipschitz domain. Suppose is a solution to the following problem Show that is a minimizer for the following functional over all functions that vanish at the boundary. That is, if on , then the following hold My attempt: Let . Suppose solves the problem and define . Then I want to show Now it is clear that . How to deal with the form to conclude the desired inequality? How to relate that to the latter part of the question including the inequality over the defined space of functions?","f \mathbb{R} U u \in C^2(U) \cap C(\overline{U}) \begin{cases}
 -\Delta u + f'(u)=0  \ \ \ \ \ \ \ \text{ in }  \ \  U, \\ u(x)= 0  \ \ \ \ \ \ \ \text{ in } \ \ \ \partial U,
\end{cases} u  \int_{U} \frac{|\nabla u|^2}{2} + f(u) \ \ dx v = 0 \partial U  \int_{U} \frac{|\nabla u|^2}{2}  + f(u) \ \  dx \leq \int_{U} \frac{|\nabla v|^2}{2} + f(v) \ \  dx J(u) =\int_{U} \frac{|\nabla u|^2}{2}  + f(u) \ \  dx v w = v-u J(v) \geq J(u) \begin{align} J(v) = J(u + w) &=  \int_{U} \frac{|\nabla u|^2}{2}  + f(u) \ \  dx + \int_{U} \frac{|\nabla w|^2}{2}  + f(w) \ \  dx + \int_U \nabla u \cdot \nabla w \ \ dx\\
&= J(u) + J(w) + a(u,w)
\end{align} J(w) \geq 0 a(u,w)","['functional-analysis', 'partial-differential-equations', 'convex-analysis', 'calculus-of-variations']"
58,Is $\Vert A^n \Vert = \Vert A \Vert^n$ for normal operator $A$ on inner product space?,Is  for normal operator  on inner product space?,\Vert A^n \Vert = \Vert A \Vert^n A,"Exercise 7(a) after $\S$ 87. Norm from Paul R. Halmos's ""Finite-Dimensional Vector Spaces"" (second edition) invites a comment on the following assertion. If (linear operator) $A$ is normal, then $\Vert A^n \Vert = \Vert A \Vert^n$ for every positive integer $n$ . For reference, $\S \ 87.$ Norm (from the book) has the following definition for the norm $\Vert \cdot \Vert$ of a linear operator: $\Vert A \Vert = \inf \big\{K: \Vert Ax \Vert \leq K \Vert x \Vert \text{ for all vectors } x \big\}.$ Going by the discussion preceding this exercise (in the book), I assume that the assertion concerns inner product spaces, not the more general normed vector spaces. However, the inner product space, say $\mathcal V$ , of the assertion is not specified to be over the complex (or real) field, and is not said to be finite-dimensional. Also, $\mathcal V$ is not given to be complete. I am able to see why the assertion holds if $\mathcal V$ is finite-dimensional over the complex field. The reason is the spectral theorem for normal operators on such vector spaces. Similarly, I also understand that the assertion would hold in another case: if $A$ is self-adjoint and if $\mathcal V$ is finite-dimensional over the real field. I am not able to imagine what happens in the general case however, and would appreciate a pointer. Thanks.","Exercise 7(a) after 87. Norm from Paul R. Halmos's ""Finite-Dimensional Vector Spaces"" (second edition) invites a comment on the following assertion. If (linear operator) is normal, then for every positive integer . For reference, Norm (from the book) has the following definition for the norm of a linear operator: Going by the discussion preceding this exercise (in the book), I assume that the assertion concerns inner product spaces, not the more general normed vector spaces. However, the inner product space, say , of the assertion is not specified to be over the complex (or real) field, and is not said to be finite-dimensional. Also, is not given to be complete. I am able to see why the assertion holds if is finite-dimensional over the complex field. The reason is the spectral theorem for normal operators on such vector spaces. Similarly, I also understand that the assertion would hold in another case: if is self-adjoint and if is finite-dimensional over the real field. I am not able to imagine what happens in the general case however, and would appreciate a pointer. Thanks.",\S A \Vert A^n \Vert = \Vert A \Vert^n n \S \ 87. \Vert \cdot \Vert \Vert A \Vert = \inf \big\{K: \Vert Ax \Vert \leq K \Vert x \Vert \text{ for all vectors } x \big\}. \mathcal V \mathcal V \mathcal V A \mathcal V,"['linear-algebra', 'functional-analysis', 'vector-spaces', 'linear-transformations', 'operator-theory']"
59,In infinite dimensional vector spaces the complementary of a compact is connected,In infinite dimensional vector spaces the complementary of a compact is connected,,"Let $X$ be an infinite dimensional normed vector space and $K$ a compact subset of $X$ . I want to show that $K^c$ is connected by path. I know that the unity sphere $\mathbb{S} := S(0,1)$ is connected by path and that up to an homeomorphism I can assume $K \subset \mathbb{B} := B(0,1)$ . So I only need to find a path from $x$ to a certain $u \in \mathbb{S}$ , for any $x \in K^c$ . I was suggested to look at the easiest paths, $t \mapsto (1-t)x+tu$ , but I fail to conclude. Any help would be appreciated.","Let be an infinite dimensional normed vector space and a compact subset of . I want to show that is connected by path. I know that the unity sphere is connected by path and that up to an homeomorphism I can assume . So I only need to find a path from to a certain , for any . I was suggested to look at the easiest paths, , but I fail to conclude. Any help would be appreciated.","X K X K^c \mathbb{S} := S(0,1) K \subset \mathbb{B} := B(0,1) x u \in \mathbb{S} x \in K^c t \mapsto (1-t)x+tu","['general-topology', 'functional-analysis', 'compactness', 'normed-spaces', 'path-connected']"
60,"What is the cardinality of $K$, where $L_\infty[0,1]=C(K)$?","What is the cardinality of , where ?","K L_\infty[0,1]=C(K)","By Gelfand representation of (real) C $^*$ -algebras, it is known that $L_\infty[0,1]$ is isometrically isomorphic to $C(K)$ , for some compact Hausdorff $K$ . By looking at the proof, $K$ is actually defined in the following way: $$K=\{\mu\in L_\infty^*:\|\mu\|=\mu(e)=1\text{ and }\mu(fg)=\mu(f)\mu(g)\text{ for all }f,g\in L_\infty\},$$ where $e$ is the unit of the C $^*$ -algebra (that is, in this case the 1-constant function). Moreover, it is proved that $K$ is non-empty since it contains the extreme points of the set $\{\mu\in L_\infty^*:\|\mu\|=\mu(e)=1\}$ . Can we say anything about the cardinality of this set $K$ ? So far I've been able to show the following topological lemma: $\textbf{Lemma:}$ A compact Hausdorff countable space is metrizable. Since $C(K)=L_\infty$ is non-separable, it is known that this implies that $K$ must be non-metrizable. This, combined with the lemma, shows that $K$ is uncountable. Can we do better than this?","By Gelfand representation of (real) C -algebras, it is known that is isometrically isomorphic to , for some compact Hausdorff . By looking at the proof, is actually defined in the following way: where is the unit of the C -algebra (that is, in this case the 1-constant function). Moreover, it is proved that is non-empty since it contains the extreme points of the set . Can we say anything about the cardinality of this set ? So far I've been able to show the following topological lemma: A compact Hausdorff countable space is metrizable. Since is non-separable, it is known that this implies that must be non-metrizable. This, combined with the lemma, shows that is uncountable. Can we do better than this?","^* L_\infty[0,1] C(K) K K K=\{\mu\in L_\infty^*:\|\mu\|=\mu(e)=1\text{ and }\mu(fg)=\mu(f)\mu(g)\text{ for all }f,g\in L_\infty\}, e ^* K \{\mu\in L_\infty^*:\|\mu\|=\mu(e)=1\} K \textbf{Lemma:} C(K)=L_\infty K K","['general-topology', 'functional-analysis', 'banach-spaces', 'gelfand-representation']"
61,"Prove if Hilbert dimension is finite, then the Hilbert space as a vector space has the same dimension","Prove if Hilbert dimension is finite, then the Hilbert space as a vector space has the same dimension",,"This is from Kreyszig's functional analysis text, chapter 3.6 #2. The backward direction is easy and just the Gram Schmidt process on any basis. I am having some trouble on the forward direction. So we start with a totally orthonormal set M such that the closure of the span is the entire space X (by definition of total orthonormal). I need to show that in fact, any element can be expressed as the span so M is in fact the basis. For any any element x in X, we can approximate it as close as we want by linear combinations of M, but I'm not sure how to proceed from here. The Parseval relation was introduced in this chapter, but I don't see any way to use it.","This is from Kreyszig's functional analysis text, chapter 3.6 #2. The backward direction is easy and just the Gram Schmidt process on any basis. I am having some trouble on the forward direction. So we start with a totally orthonormal set M such that the closure of the span is the entire space X (by definition of total orthonormal). I need to show that in fact, any element can be expressed as the span so M is in fact the basis. For any any element x in X, we can approximate it as close as we want by linear combinations of M, but I'm not sure how to proceed from here. The Parseval relation was introduced in this chapter, but I don't see any way to use it.",,['functional-analysis']
62,Positive linear functional $\phi\colon C(X)\to\mathbb{C}$ satisfies $|\phi(f)|\leq\phi(|f|)$,Positive linear functional  satisfies,\phi\colon C(X)\to\mathbb{C} |\phi(f)|\leq\phi(|f|),"Let $X$ be a compact (Hausdorff) space. Let $C(X)$ denote the linear space of continuous complex-valued functions on $X$ . Suppose that $\phi\colon C(X)\to\mathbb{C}$ is a positive linear functional. Thus $\phi(f)\geq0$ whenever $f\geq0$ . I want to prove that $$|\phi(f)|\leq\phi(|f|)$$ for all $f\in C(X)$ . For real-valued $f$ this is easy. Indeed, decompose $f=f_{+}-f_{-}$ , where $f_{+}:=\max(0,f)$ and $f_{-}:=\max(0,-f)$ , and observe that $$|\phi(f)|=|\phi(f_{+})-\phi(f_{-})|\leq\phi(f_{+})+\phi(f_{-})=\phi(|f|).$$ But how do I prove this for complex-valued $f$ ? Also, is there a method that doesn't require proving the real-valued case first?","Let be a compact (Hausdorff) space. Let denote the linear space of continuous complex-valued functions on . Suppose that is a positive linear functional. Thus whenever . I want to prove that for all . For real-valued this is easy. Indeed, decompose , where and , and observe that But how do I prove this for complex-valued ? Also, is there a method that doesn't require proving the real-valued case first?","X C(X) X \phi\colon C(X)\to\mathbb{C} \phi(f)\geq0 f\geq0 |\phi(f)|\leq\phi(|f|) f\in C(X) f f=f_{+}-f_{-} f_{+}:=\max(0,f) f_{-}:=\max(0,-f) |\phi(f)|=|\phi(f_{+})-\phi(f_{-})|\leq\phi(f_{+})+\phi(f_{-})=\phi(|f|). f","['real-analysis', 'functional-analysis', 'linear-transformations', 'operator-theory', 'absolute-value']"
63,Prove that the Fredholm Integral Equation is a contraction,Prove that the Fredholm Integral Equation is a contraction,,"As a part of an exercise I have to prove that the Fredholm Integral Equation is a contraction, I have the following definitions and theorem: Definition . Let $(X,d)$ be a metric space and $G:X \rightarrow X$ . The mapping G is a contraction if $ $ $\exists $ $ 0 \le\theta < 1$ s.t: $$  d(G(x),G(y))\le \theta d(x,y),  \forall  x,y \in X. $$ Definition . Let $ $ $C([a,b])$ be the space of bounded continuos funcions on [a,b]. Theorem (Banch Contraction-Mapping). $ $ Let $(X,d)$ be a complete metric space and $G$ a contraction map of $X$ . Then $\exists!$ fixed point of $G$ in $X$ . Note . We use the supremun norm. Exercise Show that the Fredholm Integral Equation $$ f(x)= \psi(x)+ \lambda \int_{a}^{b}K(x,y)f(y)dy $$ has a unique solution $F \in C([a,b])$ , with $\lambda$ small enough, $\psi \in C([a,b])$ and $K \in (C([a,b]) \times C([a,b]))$ . My attempt: I want to use the Theorem, I know that I have a complete metric space, I still have to prove that it is a contraction. So i define the map $Tf:=f$ , then I have to prove that $ $ $ \exists $ $ 0 \le \theta < 1 $ $ s.t $ $ $ $ d(Tf,T \tilde{f})\le   \theta $ $ d(f, \tilde{f}), \forall f, \tilde{f} \in C([a,b]) $ . $$ d(Tf,T \tilde{f})= \underset{a \le x \le b}{\sup}  | \psi(x)+ \lambda \int_{a}^{b}K(x,y)f(y)dy - \psi(x)- \lambda \int_{a}^{b}K(x,y) \tilde{f}(y)dy | \\ = \lambda \underset{a \le x \le b}{\sup}  | \int_{a}^{b}K(x,y)f(y)dy - \int_{a}^{b}K(x,y) \tilde{f}(y)dy |= \lambda \underset{a \le x \le b}{\sup}  | \int_{a}^{b}K(x,y)(f(y)-\tilde{f}(y))dy | \\ \le \lambda \underset{a \le x \le b}{\sup}  \int_{a}^{b} | K(x,y)|  |f(y)-\tilde{f}(y)|dy= \lambda \int_{a}^{b} \underset{a \le x \le b}{\sup} (| K(x,y)|)  \underset{a \le x \le b}{\sup}(|f(y)-\tilde{f}(y)|)dy \\ = \lambda \int_{a}^{b} \underset{a \le x \le b}{\sup} | K(x,y)| \   d(f(y),\tilde{f}(y))dy. $$ There I'm stuck, I know that $K, f, \tilde{f}$ are bounded but I don't know how to extract $f, \tilde{f}$ from the intregal, since we integrating in function of $y$ . Here a similar question Understanding Fredholm integral equation and to proof it is a contraction on C[a,b] , but the answer does not go through the details Any help or hint will we really appreciated, thank you in advance.","As a part of an exercise I have to prove that the Fredholm Integral Equation is a contraction, I have the following definitions and theorem: Definition . Let be a metric space and . The mapping G is a contraction if s.t: Definition . Let be the space of bounded continuos funcions on [a,b]. Theorem (Banch Contraction-Mapping). Let be a complete metric space and a contraction map of . Then fixed point of in . Note . We use the supremun norm. Exercise Show that the Fredholm Integral Equation has a unique solution , with small enough, and . My attempt: I want to use the Theorem, I know that I have a complete metric space, I still have to prove that it is a contraction. So i define the map , then I have to prove that . There I'm stuck, I know that are bounded but I don't know how to extract from the intregal, since we integrating in function of . Here a similar question Understanding Fredholm integral equation and to proof it is a contraction on C[a,b] , but the answer does not go through the details Any help or hint will we really appreciated, thank you in advance.","(X,d) G:X \rightarrow X   \exists   0 \le\theta < 1 
 d(G(x),G(y))\le \theta d(x,y),  \forall  x,y \in X.
   C([a,b])   (X,d) G X \exists! G X 
f(x)= \psi(x)+ \lambda \int_{a}^{b}K(x,y)f(y)dy
 F \in C([a,b]) \lambda \psi \in C([a,b]) K \in (C([a,b]) \times C([a,b])) Tf:=f    \exists   0 \le \theta < 1   s.t     d(Tf,T \tilde{f})\le 
 \theta   d(f, \tilde{f}), \forall f, \tilde{f} \in C([a,b])  
d(Tf,T \tilde{f})= \underset{a \le x \le b}{\sup}  | \psi(x)+ \lambda \int_{a}^{b}K(x,y)f(y)dy - \psi(x)- \lambda \int_{a}^{b}K(x,y) \tilde{f}(y)dy | \\ = \lambda \underset{a \le x \le b}{\sup}  | \int_{a}^{b}K(x,y)f(y)dy - \int_{a}^{b}K(x,y) \tilde{f}(y)dy |= \lambda \underset{a \le x \le b}{\sup}  | \int_{a}^{b}K(x,y)(f(y)-\tilde{f}(y))dy | \\ \le \lambda \underset{a \le x \le b}{\sup}  \int_{a}^{b} | K(x,y)|  |f(y)-\tilde{f}(y)|dy= \lambda \int_{a}^{b} \underset{a \le x \le b}{\sup} (| K(x,y)|)  \underset{a \le x \le b}{\sup}(|f(y)-\tilde{f}(y)|)dy \\ = \lambda \int_{a}^{b} \underset{a \le x \le b}{\sup} | K(x,y)| \   d(f(y),\tilde{f}(y))dy.
 K, f, \tilde{f} f, \tilde{f} y","['functional-analysis', 'analysis', 'banach-spaces', 'fixed-point-theorems']"
64,On Sum and Product of Two Projections,On Sum and Product of Two Projections,,"The following is Exercise 4 page 40 in Functional Analysis book of Conway : Let $\operatorname{P}$ and $\operatorname{Q}$ be projections. Show: (a) $\operatorname{Ρ+Q}$ is a projection if and only if $\operatorname{ranP} \perp \operatorname{ranQ}$ . If $\operatorname{P+Q}$ is a projection, then $\operatorname{ran(P+Q)} = \operatorname{ranP} + \operatorname{ranQ}$ and $\operatorname{ker(P+Q)} = \operatorname{kerΡ} \cap \operatorname{kerQ}$ . (b) $\operatorname{PQ}$ is a projection if and only if $\operatorname{PQ} = \operatorname{QP}$ . If $\operatorname{PQ}$ is a projection, then $\operatorname{ran(PQ)} = \operatorname{ranP} \cap \operatorname{ranQ}$ and $\operatorname{ker(ΡQ)} = \operatorname{kerΡ} + \operatorname{kerQ}$ . My attempt for (a) : Let $ran Ρ \perp ran Q$ . If $x \in ran Ρ$ then $x \in (ran Q)^{\perp} = \operatorname{ker}(Q)$ where the equality is by def (See Definition. 3.1. of the book). Thus (QP+PQ)(x)=0. If $x \in \operatorname{ker}(Ρ)$ then by symmetry of argument (QP+PQ)(x)=0. Since $H = \operatorname{ker}(Ρ) + ran P$ so QP+PQ = 0 and thus $(P+Q)^2=P+Q$ . To complete the ""if"" part of (a) I have to show that $\operatorname{ker}(Ρ+Q) = (ran (Ρ+Q))^{\perp}$ which I couldn't do. For the ""only if"" part, see here . The answer in that link uses the claim that proving being Hermitian of an operator is enough for being Projection which there is no such discussion in the book! for the second part of (a), if $x \in \operatorname{ker}(Ρ) \cap \operatorname{ker}(Q)$ then obviously $x \in \operatorname{ker}(P+Q)$ ; I don't know how to prove the converse. My attempt for (b) : If PQ=QP then PQ is a projection if I can prove $ker (PQ) = (ran PQ)^{\perp}$ which is not so clear. Projection is defined in the book as follows : 3.1. Definition. An idempotent on H is a bounded linear operator Ε on H such that E^2 = E. A projection is an idempotent Ρ such that $ker Ρ = (ran P)^{\perp}$ . For any other way of proving the statements in the exercise I need to prove them as well i.e. only the definition given is the basic valid one!","The following is Exercise 4 page 40 in Functional Analysis book of Conway : Let and be projections. Show: (a) is a projection if and only if . If is a projection, then and . (b) is a projection if and only if . If is a projection, then and . My attempt for (a) : Let . If then where the equality is by def (See Definition. 3.1. of the book). Thus (QP+PQ)(x)=0. If then by symmetry of argument (QP+PQ)(x)=0. Since so QP+PQ = 0 and thus . To complete the ""if"" part of (a) I have to show that which I couldn't do. For the ""only if"" part, see here . The answer in that link uses the claim that proving being Hermitian of an operator is enough for being Projection which there is no such discussion in the book! for the second part of (a), if then obviously ; I don't know how to prove the converse. My attempt for (b) : If PQ=QP then PQ is a projection if I can prove which is not so clear. Projection is defined in the book as follows : 3.1. Definition. An idempotent on H is a bounded linear operator Ε on H such that E^2 = E. A projection is an idempotent Ρ such that . For any other way of proving the statements in the exercise I need to prove them as well i.e. only the definition given is the basic valid one!",\operatorname{P} \operatorname{Q} \operatorname{Ρ+Q} \operatorname{ranP} \perp \operatorname{ranQ} \operatorname{P+Q} \operatorname{ran(P+Q)} = \operatorname{ranP} + \operatorname{ranQ} \operatorname{ker(P+Q)} = \operatorname{kerΡ} \cap \operatorname{kerQ} \operatorname{PQ} \operatorname{PQ} = \operatorname{QP} \operatorname{PQ} \operatorname{ran(PQ)} = \operatorname{ranP} \cap \operatorname{ranQ} \operatorname{ker(ΡQ)} = \operatorname{kerΡ} + \operatorname{kerQ} ran Ρ \perp ran Q x \in ran Ρ x \in (ran Q)^{\perp} = \operatorname{ker}(Q) x \in \operatorname{ker}(Ρ) H = \operatorname{ker}(Ρ) + ran P (P+Q)^2=P+Q \operatorname{ker}(Ρ+Q) = (ran (Ρ+Q))^{\perp} x \in \operatorname{ker}(Ρ) \cap \operatorname{ker}(Q) x \in \operatorname{ker}(P+Q) ker (PQ) = (ran PQ)^{\perp} ker Ρ = (ran P)^{\perp},['functional-analysis']
65,$\mathcal D$ is the space of compactly supported smooth functions on $\mathbb R^n$. Show $\mathcal D'$ is complete with respect to weak$^*$-topology.,is the space of compactly supported smooth functions on . Show  is complete with respect to weak-topology.,\mathcal D \mathbb R^n \mathcal D' ^*,"The topology on $\mathcal D$ is the locally convex topology induced by seminorms like $\|\partial_\alpha f\|_\infty$ , where $\alpha=(d_1,\ldots,d_n) $ and $\partial_\alpha=\partial_{x_1}^{d_1}\ldots\partial_{x_n}^{d_n}$ . $\mathcal D'$ is its continuous dual space. The weak^ $^*$ topology on $\mathcal D'$ is induced by seminorms like $\|\phi\|_f=|\phi(f)|$ , where $f\in \mathcal D$ . It is easy to define the limit of a Cauchy net on $\mathcal D'$ : $\Phi(f)=\lim_{\lambda}\phi(f)$ . However, I don't know how to show $\Phi$ is continuous, that is, $\Phi(f_\eta)\to 0$ whenever $\|\partial_\alpha f_\eta\|\to 0$ for all $\alpha\in \mathbb N^n$ . Could someone please give me some hints?","The topology on is the locally convex topology induced by seminorms like , where and . is its continuous dual space. The weak^ topology on is induced by seminorms like , where . It is easy to define the limit of a Cauchy net on : . However, I don't know how to show is continuous, that is, whenever for all . Could someone please give me some hints?","\mathcal D \|\partial_\alpha f\|_\infty \alpha=(d_1,\ldots,d_n)  \partial_\alpha=\partial_{x_1}^{d_1}\ldots\partial_{x_n}^{d_n} \mathcal D' ^* \mathcal D' \|\phi\|_f=|\phi(f)| f\in \mathcal D \mathcal D' \Phi(f)=\lim_{\lambda}\phi(f) \Phi \Phi(f_\eta)\to 0 \|\partial_\alpha f_\eta\|\to 0 \alpha\in \mathbb N^n","['functional-analysis', 'fourier-analysis']"
66,Zero is an interior point of a surjective bounded operator with nonempty kernel,Zero is an interior point of a surjective bounded operator with nonempty kernel,,"Let $T$ be a linear bounded operator on a Banach space $X$ over $\mathbb{C}$ , and $T$ is surjective but not injective. Then $0$ is an interior point of the spectrum of $T$ . I came across this question a few days ago. It has been closed, but I want to check my proof of the statement. Proof Preparations: $\ker T := Y$ is a closed subspace of $X$ . We can take a factor $X/Y$ and the respective quotient map $Q$ . It is well-known that $X/Y$ is Banach space w.r.t. the quotient norm $||x + Y|| = \inf_{y \in Y}||x + y||$ . By the inverse mapping theorem $S := TQ$ , which is bijective, has a bounded inverse. Denote $r = 2||S^{-1}|| > 0$ . By the definition of the quotient norm $\forall x \in X$ $\exists x' \in X$ s.t. $Tx' = x$ and $||x'|| \leq r ||x||$ . For any given $x \in X$ we will denote the corresponding $x'$ as $R(x)$ . There are many vectors that fits, but we will assume that only one is chosen for each $x \in X$ . Main part: Fix an arbitrary $\lambda \in \mathbb{C}$ s.t. $|\lambda| \le (3r)^{-1}$ . Fix an arbitrary $x_0 \in Y$ s.t. $||x_0|| = 1$ . Denote $x_n = \lambda^n R^n(x_0)$ , $n \in \mathbb N$ . By the definition of $R$ $||x_n|| \leq (\lambda r)^n \le 3^{-n}$ . Consider an element $w \in X$ defined by the following absolutely convergent series: $$ w = \sum_{n = 0}^\infty (-1)^n x_n. $$ Since $$ \left|\left|\sum_{n = 1}^\infty (-1)^n x_n\right|\right| \leq \frac 12, $$ $w$ is a nonzero vector. Now we observe that $$ (T + \lambda E) w = \sum_{n = 0}^\infty (-1)^n T x_n + \sum_{n = 0}^\infty (-1)^n \lambda x_n = \sum_{n = 1}^\infty (-1)^n \lambda x_{n-1} + \sum_{n = 0}^\infty (-1)^n \lambda x_n = 0. $$ Hence $\ker (T + \lambda E) \neq 0$ , so $-\lambda$ belongs to the spectrum of $T$ (moreover, it's in the point spectrum). Q.E.D.","Let be a linear bounded operator on a Banach space over , and is surjective but not injective. Then is an interior point of the spectrum of . I came across this question a few days ago. It has been closed, but I want to check my proof of the statement. Proof Preparations: is a closed subspace of . We can take a factor and the respective quotient map . It is well-known that is Banach space w.r.t. the quotient norm . By the inverse mapping theorem , which is bijective, has a bounded inverse. Denote . By the definition of the quotient norm s.t. and . For any given we will denote the corresponding as . There are many vectors that fits, but we will assume that only one is chosen for each . Main part: Fix an arbitrary s.t. . Fix an arbitrary s.t. . Denote , . By the definition of . Consider an element defined by the following absolutely convergent series: Since is a nonzero vector. Now we observe that Hence , so belongs to the spectrum of (moreover, it's in the point spectrum). Q.E.D.","T X \mathbb{C} T 0 T \ker T := Y X X/Y Q X/Y ||x + Y|| = \inf_{y \in Y}||x + y|| S := TQ r = 2||S^{-1}|| > 0 \forall x \in X \exists x' \in X Tx' = x ||x'|| \leq r ||x|| x \in X x' R(x) x \in X \lambda \in \mathbb{C} |\lambda| \le (3r)^{-1} x_0 \in Y ||x_0|| = 1 x_n = \lambda^n R^n(x_0) n \in \mathbb N R ||x_n|| \leq (\lambda r)^n \le 3^{-n} w \in X 
w = \sum_{n = 0}^\infty (-1)^n x_n.
 
\left|\left|\sum_{n = 1}^\infty (-1)^n x_n\right|\right| \leq \frac 12,
 w 
(T + \lambda E) w = \sum_{n = 0}^\infty (-1)^n T x_n + \sum_{n = 0}^\infty (-1)^n \lambda x_n = \sum_{n = 1}^\infty (-1)^n \lambda x_{n-1} + \sum_{n = 0}^\infty (-1)^n \lambda x_n = 0.
 \ker (T + \lambda E) \neq 0 -\lambda T","['functional-analysis', 'solution-verification', 'operator-theory', 'spectral-theory']"
67,Non-Hilbert Banach space isomorphic to $\ell_2$,Non-Hilbert Banach space isomorphic to,\ell_2,"I know that $\ell_2$ is the only separable Hilbert space of infinite dimension up to isometric isomorphism, so in particular, any separable Hilbert space of infinite dimension is isomorphic to $\ell_2$ . So my question is, can someone give an example of a Banach space isomorphic to $\ell_2$ but not isometrically isomorphic to it? I know, for what is said above, that this space cannot be a Hilbert space but I can't think of any example.","I know that is the only separable Hilbert space of infinite dimension up to isometric isomorphism, so in particular, any separable Hilbert space of infinite dimension is isomorphic to . So my question is, can someone give an example of a Banach space isomorphic to but not isometrically isomorphic to it? I know, for what is said above, that this space cannot be a Hilbert space but I can't think of any example.",\ell_2 \ell_2 \ell_2,"['functional-analysis', 'hilbert-spaces', 'banach-spaces']"
68,Function which integrates to $0$ against test functions with mean $0$ is constant almost everywhere.,Function which integrates to  against test functions with mean  is constant almost everywhere.,0 0,"Suppose $U$ is a bounded domain in $\mathbb{R}^n$ and $u \in L^1(U)$ has the property that $$\int_{U}u\phi=0 $$ for all $\phi \in C_{c}^{\infty}(U)$ which satisfy $\int \phi = 0$ . I'd like to show that $u = \bar{u}:= \frac{1}{|U|}\int_{U}u$ almost everywhere. Here was my initial approach. We have $$\int(u-\bar{u})^2 = \int u(u-\bar{u}) - \int \bar{u}(u-\bar{u}) = \int u(u-\bar{u}) .$$ Now I'm tempted to approximate $u-\bar{u}$ by smooth compactly supported mollifiers and apply something like the dominated convergence theorem to conclude that the last integral on the line above vanishes, but no straightforward argument is coming to mind. I'd appreciate if someone could help me out here.","Suppose is a bounded domain in and has the property that for all which satisfy . I'd like to show that almost everywhere. Here was my initial approach. We have Now I'm tempted to approximate by smooth compactly supported mollifiers and apply something like the dominated convergence theorem to conclude that the last integral on the line above vanishes, but no straightforward argument is coming to mind. I'd appreciate if someone could help me out here.",U \mathbb{R}^n u \in L^1(U) \int_{U}u\phi=0  \phi \in C_{c}^{\infty}(U) \int \phi = 0 u = \bar{u}:= \frac{1}{|U|}\int_{U}u \int(u-\bar{u})^2 = \int u(u-\bar{u}) - \int \bar{u}(u-\bar{u}) = \int u(u-\bar{u}) . u-\bar{u},"['real-analysis', 'calculus', 'functional-analysis', 'measure-theory', 'distribution-theory']"
69,Existence of infinite subset $S$ of $B_{\ell_2}$ s.t. $\|x-y\| > \sqrt{2}$ for all $x\neq y$ in $S$.,Existence of infinite subset  of  s.t.  for all  in .,S B_{\ell_2} \|x-y\| > \sqrt{2} x\neq y S,"Prove that there exists an infinite subset $S$ of $B_{\ell_2}$ (unit ball of $\ell_2$ ) such that $\|x-y\| > \sqrt{2}$ for all $x\neq y$ in $S$ . Attempt . Subset $S=\{e_n:n\in \mathbb{N}\}$ , where $e_n(k)= 1$ for $n=k$ and $0$ otherwise does not work, since $\|e_n-e_m\|=\sqrt{2}$ for $n\neq m$ . Thanks in advance for the help.","Prove that there exists an infinite subset of (unit ball of ) such that for all in . Attempt . Subset , where for and otherwise does not work, since for . Thanks in advance for the help.",S B_{\ell_2} \ell_2 \|x-y\| > \sqrt{2} x\neq y S S=\{e_n:n\in \mathbb{N}\} e_n(k)= 1 n=k 0 \|e_n-e_m\|=\sqrt{2} n\neq m,"['functional-analysis', 'analysis', 'hilbert-spaces']"
70,"""Asymptotic"" functionals on $C^k(\mathbb{R})$","""Asymptotic"" functionals on",C^k(\mathbb{R}),"Let $C^k(\mathbb{R})$ denote the vector space of $k$ -times continuously differentiable functions $\mathbb{R}\to\mathbb{R}$ (with $k\in\mathbb{N}\cup\{0,\infty\}$ ), and $C^k_c(\mathbb{R})\subset C^k(\mathbb{R})$ denote the subspace of compactly supported functions. Let $D^k(\mathbb{R})$ denote the algebraic dual of $C^k(\mathbb{R})$ , i.e. the set of linear maps $C^k(\mathbb{R})\to\mathbb{R}$ . $D^k(\mathbb{R})$ contains familiar functionals such as $f\mapsto f(x)$ and $f\mapsto\int\psi f$ , but it also contains less familiar objects. In particuar, let $A\subset D^k(\mathbb{R})$ denote the subspace of functionals which vanish on $C_c^k(\mathbb{R})$ , or equivalently the kernel of $\iota^*$ , where $\iota:C^k_c(\mathbb{R})\to C^k(\mathbb{R})$ is the inclusion map. It's straightforward enough to show that $A$ is nonempty on algebraic grounds, but nonetheless difficult to describe the set analytically. My question, then, takes one of two forms: Is there an explicit example of a nonzero element $\lambda\in A$ , ideally defined in such a way that one could in principle compute $\lambda(f)$ for a simply defined (e.g. polynomial) $f$ ? Alternately, is there a reason (set-theoretic or otherwise) that $A$ does not contain any ""easily-constructed"" functionals?","Let denote the vector space of -times continuously differentiable functions (with ), and denote the subspace of compactly supported functions. Let denote the algebraic dual of , i.e. the set of linear maps . contains familiar functionals such as and , but it also contains less familiar objects. In particuar, let denote the subspace of functionals which vanish on , or equivalently the kernel of , where is the inclusion map. It's straightforward enough to show that is nonempty on algebraic grounds, but nonetheless difficult to describe the set analytically. My question, then, takes one of two forms: Is there an explicit example of a nonzero element , ideally defined in such a way that one could in principle compute for a simply defined (e.g. polynomial) ? Alternately, is there a reason (set-theoretic or otherwise) that does not contain any ""easily-constructed"" functionals?","C^k(\mathbb{R}) k \mathbb{R}\to\mathbb{R} k\in\mathbb{N}\cup\{0,\infty\} C^k_c(\mathbb{R})\subset C^k(\mathbb{R}) D^k(\mathbb{R}) C^k(\mathbb{R}) C^k(\mathbb{R})\to\mathbb{R} D^k(\mathbb{R}) f\mapsto f(x) f\mapsto\int\psi f A\subset D^k(\mathbb{R}) C_c^k(\mathbb{R}) \iota^* \iota:C^k_c(\mathbb{R})\to C^k(\mathbb{R}) A \lambda\in A \lambda(f) f A","['linear-algebra', 'functional-analysis', 'set-theory', 'function-spaces']"
71,"Prove that if locally compact group $G$ is discrete, then the group algebra $L^1(G)$ is unital.","Prove that if locally compact group  is discrete, then the group algebra  is unital.",G L^1(G),"I am trying to prove that if $G$ is discrete, then the group algebra $L^1(G)$ is unital. If $G$ is discrete, $\{1\}$ is an open set where 1 is the identity element of $G$ . I am trying to show that the indicator function at $\{1\}$ , $\chi_{\{1\}}$ is the unit element of $L^1(G)$ , but I run into a problem. The convolution operation is for $f\in L^1$ and $\chi_{1}$ is given by: $\int_G f(y)\chi_{\{1\}}(y^{-1}x)\,dy$ . Replacing $y$ with $x$ in the above integral, we get: $\int_G f(x)\chi_{\{1\}}(x^{-1}x)\,dx=\int_G f(x)\,dx$ , because $\chi_{{\1\}}(x^{-1}x)=\chi_{\{1\}})=1$ . So now we have 'isolated' f, but how could we possibly get from $\int_G f(x)\,dx$ to $f$ , as needed? Clearly the integral of $f$ is not equal to $f$ in general. Do we have that somewhere along the line, the integral is no longer over $G$ but over only $\{1\}$ , because indicator function goes zero elsewhere? Then integrating over one element gives you the function itself back? Any help is greatly appreciated. Thanks!","I am trying to prove that if is discrete, then the group algebra is unital. If is discrete, is an open set where 1 is the identity element of . I am trying to show that the indicator function at , is the unit element of , but I run into a problem. The convolution operation is for and is given by: . Replacing with in the above integral, we get: , because . So now we have 'isolated' f, but how could we possibly get from to , as needed? Clearly the integral of is not equal to in general. Do we have that somewhere along the line, the integral is no longer over but over only , because indicator function goes zero elsewhere? Then integrating over one element gives you the function itself back? Any help is greatly appreciated. Thanks!","G L^1(G) G \{1\} G \{1\} \chi_{\{1\}} L^1(G) f\in L^1 \chi_{1} \int_G f(y)\chi_{\{1\}}(y^{-1}x)\,dy y x \int_G f(x)\chi_{\{1\}}(x^{-1}x)\,dx=\int_G f(x)\,dx \chi_{{\1\}}(x^{-1}x)=\chi_{\{1\}})=1 \int_G f(x)\,dx f f f G \{1\}","['functional-analysis', 'measure-theory', 'harmonic-analysis']"
72,"A question regarding least norm element of a closed, convex subset of a Hilbert space","A question regarding least norm element of a closed, convex subset of a Hilbert space",,"Suppose $(V, (\cdot, \cdot))$ is a Hilbert space, $U$ is a nonempty closed convex subset of $V$ , and $g \in U$ is the unique element of $U$ with smallest norm. Prove that $\Re(g, h)\ge \|g\|^2 \ \forall h\in U$ . I was thinking about considering $f=\frac{1}{2}(g+h)\in U$ . So $\|f\|^2 \ge \|g\|^2$ . Unable to get the desired inequality. Any help?","Suppose is a Hilbert space, is a nonempty closed convex subset of , and is the unique element of with smallest norm. Prove that . I was thinking about considering . So . Unable to get the desired inequality. Any help?","(V, (\cdot, \cdot)) U V g \in U U \Re(g, h)\ge \|g\|^2 \ \forall h\in U f=\frac{1}{2}(g+h)\in U \|f\|^2 \ge \|g\|^2","['functional-analysis', 'normed-spaces', 'convex-analysis', 'hilbert-spaces', 'projection']"
73,"For a bounded operator $A$, show that $(fg)(A)=f(A)g(A)$","For a bounded operator , show that",A (fg)(A)=f(A)g(A),"Let $f$ be an analytic function in the neighbourhood of the spectrum $\sigma(A)$ of a bounded operator $A$ . Let $C$ be a contour, counterclockwise around $\sigma(A)$ within the domain of $f$ . Finally let $f(A)$ be defined by $$f(A)=\dfrac{1}{2\pi i}\oint_C f(z) (z-A)^{-1}dz.$$ Now I have to prove that $(fg)(A)=f(A)g(A)$ but I don't know how to start. I do recognize Cauchy's integral and since $f$ is analytic on a neighbourhood of $\sigma(A)$ one could use Cauchy's integral formula but I don't see how this would help.","Let be an analytic function in the neighbourhood of the spectrum of a bounded operator . Let be a contour, counterclockwise around within the domain of . Finally let be defined by Now I have to prove that but I don't know how to start. I do recognize Cauchy's integral and since is analytic on a neighbourhood of one could use Cauchy's integral formula but I don't see how this would help.",f \sigma(A) A C \sigma(A) f f(A) f(A)=\dfrac{1}{2\pi i}\oint_C f(z) (z-A)^{-1}dz. (fg)(A)=f(A)g(A) f \sigma(A),"['functional-analysis', 'operator-theory', 'contour-integration', 'spectral-theory']"
74,Every closed ideal in $C(X)$ is the set of functions that vanish on some closed subset,Every closed ideal in  is the set of functions that vanish on some closed subset,C(X),"This is an exercise from Banach Algebra Techniques in Operator Theory by Douglas My attempt: I've seen a similar argument that shows that every maximal ideal is of the form $I_x = \{ f \in C_0(X) : f(x)= 0\}$ . I tried the same approach, by considering the evaluation map $\phi_x : C_0(X) \rightarrow \mathbb{C}$ , where $\phi_x(f) = f(x)$ for $x \in K$ . Then it seemed like that the same argument wouldn't work, because we are dealing with closed ideals. So I'm not sure how to proceed. Any help will be appreciated! Thank you!","This is an exercise from Banach Algebra Techniques in Operator Theory by Douglas My attempt: I've seen a similar argument that shows that every maximal ideal is of the form . I tried the same approach, by considering the evaluation map , where for . Then it seemed like that the same argument wouldn't work, because we are dealing with closed ideals. So I'm not sure how to proceed. Any help will be appreciated! Thank you!",I_x = \{ f \in C_0(X) : f(x)= 0\} \phi_x : C_0(X) \rightarrow \mathbb{C} \phi_x(f) = f(x) x \in K,"['general-topology', 'functional-analysis', 'operator-algebras', 'c-star-algebras']"
75,$L^1(\mathbb{P}) \neq L^1(\mathbb{Q})$ in general?,in general?,L^1(\mathbb{P}) \neq L^1(\mathbb{Q}),"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and $L^1(\mathbb{P})$ denote the collection of all random variables that are $\mathbb{P}$ -integrable. Now let $\mathbb{Q}$ be an absolutely continuous probability measure w.r.t $\mathbb{P}$ and denote its Radon-Nikodym derivative by $Z$ .  Denote the collection of random variables that are $\mathbb{Q}$ -integrable by $L^1(\mathbb{Q})$ .  We know that $X \in L^1(\mathbb{Q})$ if and only if $ZX \in L^1(\mathbb{P})$ . Is it true that if $Z \notin L^\infty$ , then there exists $X \in L^1(\mathbb{P})$ such that $\mathbb{E}[ZX] = \infty$ ? I am fairly sure this is true, but I am not sure how to prove it.","Let be a probability space and denote the collection of all random variables that are -integrable. Now let be an absolutely continuous probability measure w.r.t and denote its Radon-Nikodym derivative by .  Denote the collection of random variables that are -integrable by .  We know that if and only if . Is it true that if , then there exists such that ? I am fairly sure this is true, but I am not sure how to prove it.","(\Omega,\mathcal{F},\mathbb{P}) L^1(\mathbb{P}) \mathbb{P} \mathbb{Q} \mathbb{P} Z \mathbb{Q} L^1(\mathbb{Q}) X \in L^1(\mathbb{Q}) ZX \in L^1(\mathbb{P}) Z \notin L^\infty X \in L^1(\mathbb{P}) \mathbb{E}[ZX] = \infty","['functional-analysis', 'measure-theory', 'random-variables', 'expected-value']"
76,Continuous and residual spectrum of a multiplication operator on $\ell^p$ in the non-Hilbert case $p\ne2$,Continuous and residual spectrum of a multiplication operator on  in the non-Hilbert case,\ell^p p\ne2,"Let $a\in\ell^\infty$ , $p\in[1,\infty)$ and $$T:\ell^p\to\ell^p\;,\;\;\;x\mapsto ax.$$ It's easy to show that $\sigma_p(T)=\{a_n:n\in\mathbb N\}$ . How can we determine $\sigma_c(T)$ and $\sigma_r(T)$ ? And is there a nice characteriation of $\sigma_p(T')$ ? It really easy to show that $\mathbb C\setminus\overline{\sigma_p(T)}\subseteq\rho(T)$ . But beyond that, I'm only able to answer the question in the case $p=2$ . In that case $T$ is self-adjoint and hence $\sigma_r(T)=\emptyset$ from which we can conclude that $\sigma_c(T)=\overline{\sigma_p(T)}\setminus\sigma_p(T)$ .","Let , and It's easy to show that . How can we determine and ? And is there a nice characteriation of ? It really easy to show that . But beyond that, I'm only able to answer the question in the case . In that case is self-adjoint and hence from which we can conclude that .","a\in\ell^\infty p\in[1,\infty) T:\ell^p\to\ell^p\;,\;\;\;x\mapsto ax. \sigma_p(T)=\{a_n:n\in\mathbb N\} \sigma_c(T) \sigma_r(T) \sigma_p(T') \mathbb C\setminus\overline{\sigma_p(T)}\subseteq\rho(T) p=2 T \sigma_r(T)=\emptyset \sigma_c(T)=\overline{\sigma_p(T)}\setminus\sigma_p(T)","['functional-analysis', 'operator-theory', 'spectral-theory']"
77,"Norm of functional on $C[-1,1]$ defined as $P(f) = f(1)+f(-1)-2f(0)$",Norm of functional on  defined as,"C[-1,1] P(f) = f(1)+f(-1)-2f(0)","I am studying for my final exam and kinda struggling with the following: Calculate the norm of functional on $C[-1,1]$ defined as $P(f) = f(1)+f(-1)-2f(0)$ This seems like one-liner but I am clueless anyway. I appreciate your time.",I am studying for my final exam and kinda struggling with the following: Calculate the norm of functional on defined as This seems like one-liner but I am clueless anyway. I appreciate your time.,"C[-1,1] P(f) = f(1)+f(-1)-2f(0)",['functional-analysis']
78,On deformation of linear combination of linearly independent vectors,On deformation of linear combination of linearly independent vectors,,"Suppose we have a linearly independent set of vectors $\{v_i\}_{i=1}^n \subset H$ where $H$ is a Hilbert space. Let $$ Q_1 = \sum_{i=1}^n v_i $$ Consider $\{q_i\}_{i=1}^n \subset \mathbb{C}$ with $|q_i| < 1$ for any $i$ and set $$ Q_2 = \sum_{i=1}^n q_i v_i $$ Is it true, that $\|Q_2\| \le \|Q_1\|$ ? I thought that it could be prooved somehow by Smith orthogonalization method, but I haven't figured out how. Thank you!","Suppose we have a linearly independent set of vectors where is a Hilbert space. Let Consider with for any and set Is it true, that ? I thought that it could be prooved somehow by Smith orthogonalization method, but I haven't figured out how. Thank you!","\{v_i\}_{i=1}^n \subset H H 
Q_1 = \sum_{i=1}^n v_i
 \{q_i\}_{i=1}^n \subset \mathbb{C} |q_i| < 1 i 
Q_2 = \sum_{i=1}^n q_i v_i
 \|Q_2\| \le \|Q_1\|","['linear-algebra', 'functional-analysis', 'independence']"
79,Some questions regarding the $L^2$ space,Some questions regarding the  space,L^2,"Let $(\Xi,\boldsymbol{\Xi},\mu)$ be a measure space, and let $(\mathbb{R},\mathcal{B}_\mathbb{R})$ be the Borel space associated to $\mathbb{R}$ . Also, let $$\mathcal{L}^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})=\bigg\{f:(\Xi,\boldsymbol{\Xi})\to(\mathbb{R},\mathcal{B}_\mathbb{R})\,\,\Big|\,\int f^2\,\mathrm{d}\mu<\infty\bigg\}$$ be the set of all (real-valued) square-integrable (measurable) functions with respect to (the measure) $\mu$ . Then can we say the following? When the Lebesgue space $L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})$ is viewed as a set, it is defined as the quotient set: $$L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})_\text{set}:=\mathcal{L}^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\,\,/\sim,$$ where $\sim$ is an equivalence relation on $\mathcal{L}^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})$ such that: $$f\sim g\quad:\Leftrightarrow\quad f-g=0\,\text{ $\mu$-almost everywhere.}$$ Is this the definition of $L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})$ as a set? If so, what does ' $\mu$ -almost everywhere' actually mean in the above definition? Some authors seem to imply that (but of course I may be wrong with this interpretation): $$f(\xi)\neq g(\xi)\quad\Rightarrow\quad \mu(\xi)=0$$ when they say that if $f=g$ then $f$ and $g$ differ only on a set of measure zero. Here $\xi\in\Xi$ . However, for this to work, we require that $\{\xi\}$ is an element of the $\sigma$ -algebra $\boldsymbol{\Xi}$ to make sure that $\{\xi\}\mapsto\mu(\xi)$ is well-defined. This therefore imposes a hidden requirement on the definition of $\boldsymbol{\Xi}$ (which I don't like). Or is this the correct interpretation? $$f-g=0\,\text{ $\mu$-almost everywhere}\quad\Leftrightarrow\quad\int (f-g)^2\,\mathrm{d}\mu=0.$$ The reason why we want to define such an equivalence relation $\sim$ on $\mathcal{L}^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})$ is that if we equip $L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})$ with the bilinear map: $$\langle\,\cdot\,,\cdot\,\rangle:L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\times L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\to\mathbb{R}\quad:\Leftrightarrow\quad\langle f,g\rangle=\int fg\,\mathrm{d}\mu,$$ then $\langle\,\cdot\,,\cdot\,\rangle$ qualifies as an inner product on $L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})$ because it satisfies the positive-definite condition of an inner product. Is this the correct motivation? $L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})$ is by definition a vector space over $\mathbb{R}$ , and no further structure is assumed on $L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})_\text{set}$ . If nothing is said, all (equivalence classes of) measurable functions in $L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})$ are always assumed to be maps from $(\Xi,\boldsymbol{\Xi})$ into the Borel measurable space $(\mathbb{R},\mathcal{B}_\mathbb{R})$ , aren't they? (Disclaimer: I am not a mathematician but an engineer studying functional analysis; thus, the notation used here may be non-standard or simply incorrect. If that is the case, please let me know. I would appreciate it very much.) Thank you, Frederick.","Let be a measure space, and let be the Borel space associated to . Also, let be the set of all (real-valued) square-integrable (measurable) functions with respect to (the measure) . Then can we say the following? When the Lebesgue space is viewed as a set, it is defined as the quotient set: where is an equivalence relation on such that: Is this the definition of as a set? If so, what does ' -almost everywhere' actually mean in the above definition? Some authors seem to imply that (but of course I may be wrong with this interpretation): when they say that if then and differ only on a set of measure zero. Here . However, for this to work, we require that is an element of the -algebra to make sure that is well-defined. This therefore imposes a hidden requirement on the definition of (which I don't like). Or is this the correct interpretation? The reason why we want to define such an equivalence relation on is that if we equip with the bilinear map: then qualifies as an inner product on because it satisfies the positive-definite condition of an inner product. Is this the correct motivation? is by definition a vector space over , and no further structure is assumed on . If nothing is said, all (equivalence classes of) measurable functions in are always assumed to be maps from into the Borel measurable space , aren't they? (Disclaimer: I am not a mathematician but an engineer studying functional analysis; thus, the notation used here may be non-standard or simply incorrect. If that is the case, please let me know. I would appreciate it very much.) Thank you, Frederick.","(\Xi,\boldsymbol{\Xi},\mu) (\mathbb{R},\mathcal{B}_\mathbb{R}) \mathbb{R} \mathcal{L}^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})=\bigg\{f:(\Xi,\boldsymbol{\Xi})\to(\mathbb{R},\mathcal{B}_\mathbb{R})\,\,\Big|\,\int f^2\,\mathrm{d}\mu<\infty\bigg\} \mu L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}) L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})_\text{set}:=\mathcal{L}^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\,\,/\sim, \sim \mathcal{L}^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}) f\sim g\quad:\Leftrightarrow\quad f-g=0\,\text{ \mu-almost everywhere.} L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}) \mu f(\xi)\neq g(\xi)\quad\Rightarrow\quad \mu(\xi)=0 f=g f g \xi\in\Xi \{\xi\} \sigma \boldsymbol{\Xi} \{\xi\}\mapsto\mu(\xi) \boldsymbol{\Xi} f-g=0\,\text{ \mu-almost everywhere}\quad\Leftrightarrow\quad\int (f-g)^2\,\mathrm{d}\mu=0. \sim \mathcal{L}^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}) L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}) \langle\,\cdot\,,\cdot\,\rangle:L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\times L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\to\mathbb{R}\quad:\Leftrightarrow\quad\langle f,g\rangle=\int fg\,\mathrm{d}\mu, \langle\,\cdot\,,\cdot\,\rangle L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}) L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}) \mathbb{R} L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})_\text{set} L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}) (\Xi,\boldsymbol{\Xi}) (\mathbb{R},\mathcal{B}_\mathbb{R})","['real-analysis', 'functional-analysis', 'measure-theory', 'hilbert-spaces', 'borel-sets']"
80,"Compactness of $K(S)$, if $K$ is an infinite-dimensional compact operator in Hilbert space","Compactness of , if  is an infinite-dimensional compact operator in Hilbert space",K(S) K,"$H$ is infinite-dimensional Hilbert space. $K: H \rightarrow H$ is infinite-dimensional compact operator. Let $S$ be a unit sphere in H. The task is to proof that $K(S)$ couldn't be compact. I know that: Really we need to proof that $K[S]$ is not closed. If B is unit ball, $[B]$ - closure, then $K([B])$ is also closed(for compact operator in Hilbert space). If $\mathrm{Ker} B$ is empty, i.e. $0 \notin K(S)$ then there is a sequence in $K(S)$ converging to $0$ , so $K(S)$ isn't compact. But I don't understant how to proof noncompactness of $K(S)$ even if one of the basis vectors is mapped to $0$ . On the other side we can try to proof that if $K(S)$ is compact, then $\mathrm{Im}(K)=K(H)$ shuold have finite dimension. It is easy if $K(B)$ contains some ball(like a subspace in $K(H)$ ), but it's far from being true.","is infinite-dimensional Hilbert space. is infinite-dimensional compact operator. Let be a unit sphere in H. The task is to proof that couldn't be compact. I know that: Really we need to proof that is not closed. If B is unit ball, - closure, then is also closed(for compact operator in Hilbert space). If is empty, i.e. then there is a sequence in converging to , so isn't compact. But I don't understant how to proof noncompactness of even if one of the basis vectors is mapped to . On the other side we can try to proof that if is compact, then shuold have finite dimension. It is easy if contains some ball(like a subspace in ), but it's far from being true.",H K: H \rightarrow H S K(S) K[S] [B] K([B]) \mathrm{Ker} B 0 \notin K(S) K(S) 0 K(S) K(S) 0 K(S) \mathrm{Im}(K)=K(H) K(B) K(H),"['functional-analysis', 'hilbert-spaces', 'compact-operators']"
81,"$T_f:L^2[0,1] \to L^2[0,1]$ defined as $T_f=fg$ is bounded and compact only if $f=0$.",defined as  is bounded and compact only if .,"T_f:L^2[0,1] \to L^2[0,1] T_f=fg f=0","I am trying to solve the following problem: Let $f:[0,1] \to \mathbb{C}$ be a continuous function and $T_f:L^2[0,1] \to L^2[0,1]$ be the operator given by $T_f(g)=fg, \; g \in L^2[0,1].$ Prove that $T_f$ is a bounded linear operator on $L^2[0,1]$ and that $T_f$ is compact iff $f=0$ . Now, the linearity of $T_f$ follows by linearity of the usual operations. Indeed $$ T_f(\alpha g_1 + g_2)= f(\alpha g_1 + g_2)= \alpha fg_1 + fg_2= \alpha T_f g_1 + T_f g_2. $$ For boundedness, we have that \begin{align*} \|T_f\|^2_{L^2[0,1]} = \int_{0}^{1} |f|^2|g|^2 &\leq  \int_{0}^{1} |f|^2 \quad (\|g\|\leq 1) \\ &\leq \|f\|^2_{L^2[0,1]}. \end{align*} Then if $f=0$ clearly $T_f$ is compact (being the range just $\{0\}$ ), but I am having trubles showing that if $f\neq 0$ then $T_f$ is not compact. Any help is appreciated.","I am trying to solve the following problem: Let be a continuous function and be the operator given by Prove that is a bounded linear operator on and that is compact iff . Now, the linearity of follows by linearity of the usual operations. Indeed For boundedness, we have that Then if clearly is compact (being the range just ), but I am having trubles showing that if then is not compact. Any help is appreciated.","f:[0,1] \to \mathbb{C} T_f:L^2[0,1] \to L^2[0,1] T_f(g)=fg, \; g \in L^2[0,1]. T_f L^2[0,1] T_f f=0 T_f 
T_f(\alpha g_1 + g_2)= f(\alpha g_1 + g_2)= \alpha fg_1 + fg_2= \alpha T_f g_1 + T_f g_2.
 \begin{align*}
\|T_f\|^2_{L^2[0,1]} = \int_{0}^{1} |f|^2|g|^2 &\leq  \int_{0}^{1} |f|^2 \quad (\|g\|\leq 1) \\
&\leq \|f\|^2_{L^2[0,1]}.
\end{align*} f=0 T_f \{0\} f\neq 0 T_f",['functional-analysis']
82,"Approximating compactly supported $L^2$ functions with Schwartz functions ""from within""?","Approximating compactly supported  functions with Schwartz functions ""from within""?",L^2,"Crossposted from MathOverflow. It is well known that the class of Schwartz functions $\mathcal{S}$ in dense in all $L^p$ spaces therefore for each $f \in L^2$ there exists a sequence of Schwartz functions $(f_k)$ such that $\lVert f - f_k \rVert_{L^2} \to 0$ as $k \to \infty$ . If we suppose further that $f$ has compact support can we find a sequence of Schwartz functions $(f_k)$ such that $\lVert f - f_k \rVert_{L^2} \to 0$ as $k \to \infty$ (as above) and additionally $\operatorname{supp}(f_k) \subseteq \operatorname{supp}(f)$ for all $k$ ? If so, what argument can I appeal to?","Crossposted from MathOverflow. It is well known that the class of Schwartz functions in dense in all spaces therefore for each there exists a sequence of Schwartz functions such that as . If we suppose further that has compact support can we find a sequence of Schwartz functions such that as (as above) and additionally for all ? If so, what argument can I appeal to?",\mathcal{S} L^p f \in L^2 (f_k) \lVert f - f_k \rVert_{L^2} \to 0 k \to \infty f (f_k) \lVert f - f_k \rVert_{L^2} \to 0 k \to \infty \operatorname{supp}(f_k) \subseteq \operatorname{supp}(f) k,"['functional-analysis', 'approximation-theory', 'schwartz-space']"
83,A closed and convex subset of an Hilbert space on which the norm does not attain its maximum,A closed and convex subset of an Hilbert space on which the norm does not attain its maximum,,"I want to prove that the norm $\lvert \lvert \cdot \rvert \rvert _2$ has no maximum on $X=\{x\in \ell^2(k):\sum_{n \in \mathbb{N}} 2^{1/n}\lvert x_n \rvert^2 \le 1\}$ , where $k=\mathbb{R}$ or $\mathbb{C}$ . I have managed to see that this is close and bounded, I can't figure out if this is also convex and I don't know if this would be helpful. I've tried to do some contradiction argument, I have observed is that since $2^{1/n}>1$ , if there is $x \in X$ which attains the maximum for $\lvert \lvert \cdot \rvert \rvert _2$ , then this maximum, say $M$ , must be strictly smaller than $1$ , otherwise $x$ would be outside of $X$ . Now my idea would be that in this case we could add a small $\epsilon$ to some term $x_n$ of $x$ in such a way that $\sum_{n \in \mathbb{N}} 2^{1/n}\lvert x_n \rvert^2$ stays below one, but I can't carry out the computations, even because if $\lvert \lvert x \rvert \rvert _2<1,$ then it does not follow that $\sum_{n \in \mathbb{N}} 2^{1/n}\lvert x_n \rvert^2<1$ , as we can see taking the element $(2^{-1/4}, 0, 0, \ldots)$ .","I want to prove that the norm has no maximum on , where or . I have managed to see that this is close and bounded, I can't figure out if this is also convex and I don't know if this would be helpful. I've tried to do some contradiction argument, I have observed is that since , if there is which attains the maximum for , then this maximum, say , must be strictly smaller than , otherwise would be outside of . Now my idea would be that in this case we could add a small to some term of in such a way that stays below one, but I can't carry out the computations, even because if then it does not follow that , as we can see taking the element .","\lvert \lvert \cdot \rvert \rvert _2 X=\{x\in \ell^2(k):\sum_{n \in \mathbb{N}} 2^{1/n}\lvert x_n \rvert^2 \le 1\} k=\mathbb{R} \mathbb{C} 2^{1/n}>1 x \in X \lvert \lvert \cdot \rvert \rvert _2 M 1 x X \epsilon x_n x \sum_{n \in \mathbb{N}} 2^{1/n}\lvert x_n \rvert^2 \lvert \lvert x \rvert \rvert _2<1, \sum_{n \in \mathbb{N}} 2^{1/n}\lvert x_n \rvert^2<1 (2^{-1/4}, 0, 0, \ldots)","['functional-analysis', 'hilbert-spaces', 'banach-spaces']"
84,Separable C* algebra has a cyclic representation that is isometric.,Separable C* algebra has a cyclic representation that is isometric.,,"I'm studying Conway's Functional Analysis. In chapter 8.5, we learn about GNS representation. Theorem 8.5.17 states that $\mathcal{A}$ is separable then, we can select representation $(\pi, \mathcal{H})$ that $\mathcal{H}$ is separable. And next line, every separable C*-algebra has a cyclic representation that is isometric. I want to prove this, and Conway suggests that $f_n$ is countable weak* dense subset of $S_\mathcal{A}$ (which is state space of $\mathcal{A}$ ), then if we set $f = \sum 2^{-n}f_n$ then $\pi_f$ is an isometry.( $\pi_f$ is from GNS construction) Since GNS Construction suggest that if we make $\pi_f$ , then it is cyclic representation, so I need to prove that $\pi_f$ is isometry. But I cannot get any way to get $\pi_f$ 's norm. if $e_f$ is cyclic vector of $\pi_f$ , $$\|p_f(a) \|^2 \geq \|\pi_f(a) e_f\|^2 = \langle  \pi_f(a^* a) e_f, e_f\rangle = f(a^* a) = \sum 2^{-n}f_n(a^* a)$$ and we know that $\|a\| = \sup\{f(a) : f \in S_\mathcal{A} \}$ for positive element $a$ but I don't know that $\sum 2^{-n}f_n(a^* a) \geq  \|a^* a\| - \epsilon$ . How can i deal with this problem?","I'm studying Conway's Functional Analysis. In chapter 8.5, we learn about GNS representation. Theorem 8.5.17 states that is separable then, we can select representation that is separable. And next line, every separable C*-algebra has a cyclic representation that is isometric. I want to prove this, and Conway suggests that is countable weak* dense subset of (which is state space of ), then if we set then is an isometry.( is from GNS construction) Since GNS Construction suggest that if we make , then it is cyclic representation, so I need to prove that is isometry. But I cannot get any way to get 's norm. if is cyclic vector of , and we know that for positive element but I don't know that . How can i deal with this problem?","\mathcal{A} (\pi, \mathcal{H}) \mathcal{H} f_n S_\mathcal{A} \mathcal{A} f = \sum 2^{-n}f_n \pi_f \pi_f \pi_f \pi_f \pi_f e_f \pi_f \|p_f(a) \|^2 \geq \|\pi_f(a) e_f\|^2 = \langle  \pi_f(a^* a) e_f, e_f\rangle = f(a^* a) = \sum 2^{-n}f_n(a^* a) \|a\| = \sup\{f(a) : f \in S_\mathcal{A} \} a \sum 2^{-n}f_n(a^* a) \geq  \|a^* a\| - \epsilon","['functional-analysis', 'c-star-algebras']"
85,Do we have $u^2 \leq u$ when $\|u \| \leq 1$ in a $C^*$-algebra?,Do we have  when  in a -algebra?,u^2 \leq u \|u \| \leq 1 C^*,"Let $u$ be a positive element in a $C^*$ -algebra $A$ with $\|u \|\le 1$ . Then is it true that $u^2 \leq u$ ? Attempt : This is true in the commutative $C^*$ -subalgebra $C^*(u)$ , since by the Gelfand-Naimark theorem, $C^*(u) \cong C_0(X)$ where $X$ is some locally compact Hausdorff space. Thus, this also holds in $A$ since positivity does not depend on the ambenient $C^*$ -subalgebra. Is this correct?","Let be a positive element in a -algebra with . Then is it true that ? Attempt : This is true in the commutative -subalgebra , since by the Gelfand-Naimark theorem, where is some locally compact Hausdorff space. Thus, this also holds in since positivity does not depend on the ambenient -subalgebra. Is this correct?",u C^* A \|u \|\le 1 u^2 \leq u C^* C^*(u) C^*(u) \cong C_0(X) X A C^*,['functional-analysis']
86,$0\leq a \leq b $ implies $ b^{-1} \leq a^{-1}$ in C*-algebra?,implies  in C*-algebra?,0\leq a \leq b   b^{-1} \leq a^{-1},"I'm studying C*-algebra in Conway's Functional Analysis. Problem is this. $0\leq a \leq b $ , then $ b^{-1} \leq a^{-1}$ in C*-algebra? I tried this problem via this way. 1st trial) Since $  a^{-1} - b^{-1} = a^{-1}(b-a)b^{-1}$ so product of three positive element is positive. But this is false because product of positive element in C*-algebra is not positive. 2nd trial) How about using below Lemma? $a \geq 0$ is equivalent to $a= a^*, ||t-a||\leq t$ for some $t \geq ||a|| $ Then, since $||a^{-1}(b-a)b^{-1}||  \leq ||a^{-1}|| \cdot ||b-a|| \cdot ||b^{-1}||$ so set $t = ||a^{-1}|| \cdot ||b-a|| \cdot ||b^{-1}||$ and try to solve this problem. What I stuck is is $||a||^{-1} = ||a^{-1}||$ ? It is just kind of passing thought, but in generally $a$ is hermitian, then $||a^{2^n}|| = ||a||^{2^n}$ so i think this might be true. Can you help me?","I'm studying C*-algebra in Conway's Functional Analysis. Problem is this. , then in C*-algebra? I tried this problem via this way. 1st trial) Since so product of three positive element is positive. But this is false because product of positive element in C*-algebra is not positive. 2nd trial) How about using below Lemma? is equivalent to for some Then, since so set and try to solve this problem. What I stuck is is ? It is just kind of passing thought, but in generally is hermitian, then so i think this might be true. Can you help me?","0\leq a \leq b   b^{-1} \leq a^{-1}   a^{-1} - b^{-1} = a^{-1}(b-a)b^{-1} a \geq 0 a= a^*, ||t-a||\leq t t \geq ||a||  ||a^{-1}(b-a)b^{-1}||  \leq ||a^{-1}|| \cdot ||b-a|| \cdot ||b^{-1}|| t = ||a^{-1}|| \cdot ||b-a|| \cdot ||b^{-1}|| ||a||^{-1} = ||a^{-1}|| a ||a^{2^n}|| = ||a||^{2^n}",['functional-analysis']
87,Bounded operators on complex Banach space $X$ are commutative exactly when $X$ is one-dimensional?,Bounded operators on complex Banach space  are commutative exactly when  is one-dimensional?,X X,"I am trying to prove that for a Banach space $X$ over $\mathbb{C}$ , dim $(X)=1$ if and only if $\mathfrak{B}(X)$ is commutative. From this StackExchange question ( Bounded linear operator commuting with every compact operators ), we can see that $A \in \mathfrak{B}(X)$ commuting with each $K \in \mathfrak{K}(X)$ (the space of compact operators) means that $A = \lambda I$ for some scalar $\lambda \in \mathbb{C}$ . I can convince myself that the result follows (every bounded operator being commutative means that they commute with compact operators, so they are of the form $\lambda I$ ), but I don't know how to rigorously get to the conclusion that dim $(X)=1$ , let alone how one would show the other direction. Any hint or help is highly appreciated.","I am trying to prove that for a Banach space over , dim if and only if is commutative. From this StackExchange question ( Bounded linear operator commuting with every compact operators ), we can see that commuting with each (the space of compact operators) means that for some scalar . I can convince myself that the result follows (every bounded operator being commutative means that they commute with compact operators, so they are of the form ), but I don't know how to rigorously get to the conclusion that dim , let alone how one would show the other direction. Any hint or help is highly appreciated.",X \mathbb{C} (X)=1 \mathfrak{B}(X) A \in \mathfrak{B}(X) K \in \mathfrak{K}(X) A = \lambda I \lambda \in \mathbb{C} \lambda I (X)=1,"['functional-analysis', 'operator-theory']"
88,Spectrum of a positive operator in $B(H)$.,Spectrum of a positive operator in .,B(H),"We know that for $T\in B(H)$ . If $T$ is positive, then $T$ is self-adjoint and $\sigma(T)\subset R^{+}$ . Do we have the inverse ie: if $T$ is self-adjoint and $\sigma(T)\subset R^{+}$ . $T$ is positive. where $T$ is said to be positive in case $\langle Tx,x\rangle\geq 0$ for all $x\in H$ , $H$ is a Hilbert space. Thank you very much for your help.","We know that for . If is positive, then is self-adjoint and . Do we have the inverse ie: if is self-adjoint and . is positive. where is said to be positive in case for all , is a Hilbert space. Thank you very much for your help.","T\in B(H) T T \sigma(T)\subset R^{+} T \sigma(T)\subset R^{+} T T \langle Tx,x\rangle\geq 0 x\in H H","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'von-neumann-algebras']"
89,Which (non-trace class) operators have a well-defined trace (if any)?,Which (non-trace class) operators have a well-defined trace (if any)?,,"On a Hilbert space $\mathcal{H}$ , it is well known that trace class operators have a finite trace. However, there are operators which are not trace class but have a finite trace, e.g. the unilateral shift . Then, consider a (bounded) operator $A$ such that $$ c=\sum_{n=1}^{\infty}\langle x_n,A x_n\rangle<\infty, $$ for some orthonormal basis $\{x_1,x_2,\ldots\}$ . I'm not sure whether this is enough for the trace of $A$ to be defined in a basis independent way. Namely, $\mathrm{tr}(A)=\sum_{n=1}^{\infty}\langle y_n,A y_n\rangle=c$ for any orthonormal basis $\{y_1,y_2,\ldots\}$ . In the classics von Neumann's book on Mathematical Foundations of Quantum Mecanics, Sec. II.11, he commented this is true (in fact, he did not consider trace class operators) using essentially the following argument: $$ c=\sum_{n=1}^{\infty}\langle x_n,A x_n\rangle=\sum_{n=1}^{\infty}\sum_{m=1}^{\infty}\langle x_n,y_m\rangle \langle y_m, A x_n\rangle=\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}\langle y_m, A x_n\rangle\langle x_n,y_m\rangle=\sum_{m=1}^{\infty}\langle y_m,A y_m\rangle. $$ However, it is not clear to me that the double sum can be switched. Using that $|\langle u,y_m \rangle \langle y_m, v\rangle|\leq \frac12 (|\langle u,y_m \rangle|^2+|\langle v,y_m \rangle|^2)$ it is obtained that $$ \sum_{m=1}^{\infty}\langle x_n,y_n\rangle \langle y_n, A x_n\rangle $$ is absolutely convergent. Is this enough for the summation switch? Thank you in advance. EDIT : As Robert Israel points, $\sum_{n=1}^{\infty}\langle x_n,A x_n\rangle$ must be absolutely convergent. Is it enough?","On a Hilbert space , it is well known that trace class operators have a finite trace. However, there are operators which are not trace class but have a finite trace, e.g. the unilateral shift . Then, consider a (bounded) operator such that for some orthonormal basis . I'm not sure whether this is enough for the trace of to be defined in a basis independent way. Namely, for any orthonormal basis . In the classics von Neumann's book on Mathematical Foundations of Quantum Mecanics, Sec. II.11, he commented this is true (in fact, he did not consider trace class operators) using essentially the following argument: However, it is not clear to me that the double sum can be switched. Using that it is obtained that is absolutely convergent. Is this enough for the summation switch? Thank you in advance. EDIT : As Robert Israel points, must be absolutely convergent. Is it enough?","\mathcal{H} A 
c=\sum_{n=1}^{\infty}\langle x_n,A x_n\rangle<\infty,
 \{x_1,x_2,\ldots\} A \mathrm{tr}(A)=\sum_{n=1}^{\infty}\langle y_n,A y_n\rangle=c \{y_1,y_2,\ldots\} 
c=\sum_{n=1}^{\infty}\langle x_n,A x_n\rangle=\sum_{n=1}^{\infty}\sum_{m=1}^{\infty}\langle x_n,y_m\rangle \langle y_m, A x_n\rangle=\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}\langle y_m, A x_n\rangle\langle x_n,y_m\rangle=\sum_{m=1}^{\infty}\langle y_m,A y_m\rangle.
 |\langle u,y_m \rangle \langle y_m, v\rangle|\leq \frac12 (|\langle u,y_m \rangle|^2+|\langle v,y_m \rangle|^2) 
\sum_{m=1}^{\infty}\langle x_n,y_n\rangle \langle y_n, A x_n\rangle
 \sum_{n=1}^{\infty}\langle x_n,A x_n\rangle","['functional-analysis', 'operator-theory', 'trace']"
90,Product of $L^p$-convergent sequences are Cauchy,Product of -convergent sequences are Cauchy,L^p,"I'm working on showing: If $\|f_n - f\|_p \to 0$ with $1≤p<\infty$ and $h_n \to h$ pointwise with $|h_n|<M$ for all $n$ , then $\{f_nh_n\}$ is Cauchy in $L^p$ I've shown that $\|h_n-h\|_p \to 0$ , but I'm having a hard time showing the product is Cauchy. I tried to manipulate the terms in the norm in additon to using Minkowski's inequality, but it hasn't worked thus far.","I'm working on showing: If with and pointwise with for all , then is Cauchy in I've shown that , but I'm having a hard time showing the product is Cauchy. I tried to manipulate the terms in the norm in additon to using Minkowski's inequality, but it hasn't worked thus far.",\|f_n - f\|_p \to 0 1≤p<\infty h_n \to h |h_n|<M n \{f_nh_n\} L^p \|h_n-h\|_p \to 0,"['real-analysis', 'functional-analysis', 'measure-theory']"
91,Weak maximum principle of strictly elliptic equation with solution in Sobolev space ( Gilberg Trudiger theorem 8.1),Weak maximum principle of strictly elliptic equation with solution in Sobolev space ( Gilberg Trudiger theorem 8.1),,"\begin{equation}\label{eq:81}     Lu=D_i(a^{ij}(x)D_ju+b^i(x)u)+c^i(x)D_iu+d(x)u \end{equation} with \begin{equation}\label{eq:88}     \int_{\Omega}(dv-b^iD_iv)dx\leq 0\qquad \forall v\geq 0,v\in C_0^1(\Omega) \end{equation} Let $u\in W^{1,2}(\Omega)$ satisfy $Lu\geq 0(\leq 0)$ in $\Omega$ . Then \begin{equation}\label{eq:89}     \sup_{\Omega} u\leq \sup_{\partial \Omega}u^+\quad(\inf_{\Omega} u\geq \inf_{\partial \Omega}u^+) \end{equation} Proof: If $u\in W^{1,2}(\Omega)$ and $v\in W_0^{1,2}(\Omega)$ we have $uv\in W_0^{1,1}$ and $D(uv)=vDu+uDv$ . $\mathfrak L(u,v)\leq 0$ $ \int \{(a^{ij}D_ju+b^iu)D_iv-(c^iD_iu+du)v)\}dx\leq 0$ \begin{equation}     \int_{\Omega}\{a^{ij}D_juD_iv-(b^i+c^i)vD_iu\}dx\leq \int_{\Omega}\{duv-b^iD_i(uv)\}\leq 0  \end{equation} for all $v\geq 0$ such that $uv\geq 0$ . last inequality.(Here we used coefficient of u negative). Hence , by coefficient bounds ,we have \begin{equation}\label{eq:810}     \int_{\Omega}a^{ij}D_jD_ivdx\leq 2\lambda\nu\int v|Du|dx \end{equation} for all $v\geq 0$ such that $uv\geq 0$ . In special case $b^i+c^i=0$ , the proof is immediate by taking $v=\max \{u-l,0\}$ where $l=sup_{\partial \Omega}u^+$ . Suppose on contrary , $\sup_{\Omega} u> \sup_{\partial \Omega}u^+$ For general case choose $k$ to satisfy $l\leq k<\sup_{\Omega}u,$ and we set $v=(u-k)^+.$ ( If no such $k$ exists then we are done.\ $v\in W_0^{1,2}(\Omega)$ and by chain rule \begin{align*} Dv = \left\{ \begin{array}{cc}                 Du & \hspace{5mm} u>k\qquad(v\neq 0) \\                 0 & \hspace{5mm} u\leq k\qquad(v=0)\\                 \end{array} \right. \end{align*} Consequently, we obtain above \begin{equation*}         \int_{\Omega}a^{ij}D_jD_ivdx\leq 2\lambda\nu\int_{\Gamma} v|Du|dx\qquad \Gamma=supp (Dv)\subset v \end{equation*} and Hence by Strict ellipticity of $L$ , \begin{equation*}     \int_{\Omega} |Du|^2dx\leq 2\nu\int_{\Gamma} v|Du|dx\leq 2\nu ||v||_{2,\Gamma}||Dv||_{2,\Gamma} \end{equation*} So that \begin{equation*}     ||Dv||_2\leq 2\nu||v||_{2,\Gamma} \end{equation*} By theorem 7.10, $n\geq 3$ \begin{equation*}     ||v||_{2n/(n-2}\leq C||Dv||_2. \end{equation*} Also  by Schwartz's inequality \begin{equation*}     2\nu||v||_{2,\Gamma}\leq C|\Gamma|^{1/n}||v||_{2n/(n-2)}. \end{equation*} So \begin{equation*}     ||v||_{2n/(n-2}\leq C|\Gamma|^{1/n}||v||_{2n/(n-2)}. \end{equation*} where $C=C(n,v)$ so that \begin{equation*}     |\Gamma|\geq C^{-n}>0 \end{equation*} If $n=2$ \ \begin{equation*}     \sup_{\Omega}|u|\leq C|\Omega|^{1/2-1/p}||Du||_p \end{equation*} By replacing $2n/(n-2)$ by any number greater that 2 we get \begin{equation*}     |\Gamma|\geq C^{-n}>0 \end{equation*} As above inequality is independent of $k$ , we can take $k\to \sup_{\Omega}u$ . $u $ attain its supremum in $\Omega$ on set of positive measure, where $Du=0$ . This is contradiction to preceding inequality. I do not understand how to come to contradiction.I understand everything except how contradiction came I don't know. Any Help will be appreciated.","with Let satisfy in . Then Proof: If and we have and . for all such that . last inequality.(Here we used coefficient of u negative). Hence , by coefficient bounds ,we have for all such that . In special case , the proof is immediate by taking where . Suppose on contrary , For general case choose to satisfy and we set ( If no such exists then we are done.\ and by chain rule Consequently, we obtain above and Hence by Strict ellipticity of , So that By theorem 7.10, Also  by Schwartz's inequality So where so that If \ By replacing by any number greater that 2 we get As above inequality is independent of , we can take . attain its supremum in on set of positive measure, where . This is contradiction to preceding inequality. I do not understand how to come to contradiction.I understand everything except how contradiction came I don't know. Any Help will be appreciated.","\begin{equation}\label{eq:81}
    Lu=D_i(a^{ij}(x)D_ju+b^i(x)u)+c^i(x)D_iu+d(x)u
\end{equation} \begin{equation}\label{eq:88}
    \int_{\Omega}(dv-b^iD_iv)dx\leq 0\qquad \forall v\geq 0,v\in C_0^1(\Omega)
\end{equation} u\in W^{1,2}(\Omega) Lu\geq 0(\leq 0) \Omega \begin{equation}\label{eq:89}
    \sup_{\Omega} u\leq \sup_{\partial \Omega}u^+\quad(\inf_{\Omega} u\geq \inf_{\partial \Omega}u^+)
\end{equation} u\in W^{1,2}(\Omega) v\in W_0^{1,2}(\Omega) uv\in W_0^{1,1} D(uv)=vDu+uDv \mathfrak L(u,v)\leq 0 
\int \{(a^{ij}D_ju+b^iu)D_iv-(c^iD_iu+du)v)\}dx\leq 0 \begin{equation}
    \int_{\Omega}\{a^{ij}D_juD_iv-(b^i+c^i)vD_iu\}dx\leq \int_{\Omega}\{duv-b^iD_i(uv)\}\leq 0 
\end{equation} v\geq 0 uv\geq 0 \begin{equation}\label{eq:810}
    \int_{\Omega}a^{ij}D_jD_ivdx\leq 2\lambda\nu\int v|Du|dx
\end{equation} v\geq 0 uv\geq 0 b^i+c^i=0 v=\max \{u-l,0\} l=sup_{\partial \Omega}u^+ \sup_{\Omega} u> \sup_{\partial \Omega}u^+ k l\leq k<\sup_{\Omega}u, v=(u-k)^+. k v\in W_0^{1,2}(\Omega) \begin{align*}
Dv = \left\{ \begin{array}{cc}
                Du & \hspace{5mm} u>k\qquad(v\neq 0) \\
                0 & \hspace{5mm} u\leq k\qquad(v=0)\\
                \end{array} \right.
\end{align*} \begin{equation*}
        \int_{\Omega}a^{ij}D_jD_ivdx\leq 2\lambda\nu\int_{\Gamma} v|Du|dx\qquad \Gamma=supp (Dv)\subset v
\end{equation*} L \begin{equation*}
    \int_{\Omega} |Du|^2dx\leq 2\nu\int_{\Gamma} v|Du|dx\leq 2\nu ||v||_{2,\Gamma}||Dv||_{2,\Gamma}
\end{equation*} \begin{equation*}
    ||Dv||_2\leq 2\nu||v||_{2,\Gamma}
\end{equation*} n\geq 3 \begin{equation*}
    ||v||_{2n/(n-2}\leq C||Dv||_2.
\end{equation*} \begin{equation*}
    2\nu||v||_{2,\Gamma}\leq C|\Gamma|^{1/n}||v||_{2n/(n-2)}.
\end{equation*} \begin{equation*}
    ||v||_{2n/(n-2}\leq C|\Gamma|^{1/n}||v||_{2n/(n-2)}.
\end{equation*} C=C(n,v) \begin{equation*}
    |\Gamma|\geq C^{-n}>0
\end{equation*} n=2 \begin{equation*}
    \sup_{\Omega}|u|\leq C|\Omega|^{1/2-1/p}||Du||_p
\end{equation*} 2n/(n-2) \begin{equation*}
    |\Gamma|\geq C^{-n}>0
\end{equation*} k k\to \sup_{\Omega}u u  \Omega Du=0","['real-analysis', 'functional-analysis', 'partial-differential-equations', 'proof-explanation', 'regularity-theory-of-pdes']"
92,Why does setting y=x work in this proof?,Why does setting y=x work in this proof?,,"The problem in question asks you to show that the non-negativity of a metric follows from the 2nd, 3rd, and 4th metric space axioms i.e. $\textbf{M2}$ $d(x,y) = 0$ iff $x=y$ $\textbf{M3}$ $d(x,y) = d(y,x)$ $\textbf{M4}$ $d(x,y) \leq d(x,z) + d(z,y)$ My (kind of longwinded) proof was the following: We prove by showing that all possible distances on the arbitrary points $x,y,z$ are non-negative. That $d(x,x), d(y,y), d(z,z)$ are non negative is given by $\textbf{M2}$ . For the remainder, let $x=y$ , then using $\textbf{M2}$ , $\textbf{M3}$ , $\textbf{M4}$ we have \begin{equation} \begin{split}     d(x,y)=0 & \leq d(x,z) + d(z,y) \\              & \leq d(x,z) + d(z,x) \\              & \leq d(x,z) + d(x,z) \\              & \leq 2d(x,z) \end{split} \end{equation} dividing both sides by 2 gives \begin{equation}     0 \leq d(x,z) \end{equation} Thus by $\textbf{M3}$ and using the fact that $y=x$ we have that $d(x,z)$ , $d(z,x)$ , $d(y,z)$ , and $d(z,y)$ are all non-negative. QED. I've checked some answers setting and y=x in $\textbf{M4}$ seems to be the right strategy. My question is why does setting y=x work in this case? Doesn't this only prove for the case in which y=x? What about when y doesn't equal x? I've a seen similar strategies used in proofs before and I never quite understood how prooving for a limited set of cases prooved all cases. Many thanks.","The problem in question asks you to show that the non-negativity of a metric follows from the 2nd, 3rd, and 4th metric space axioms i.e. iff My (kind of longwinded) proof was the following: We prove by showing that all possible distances on the arbitrary points are non-negative. That are non negative is given by . For the remainder, let , then using , , we have dividing both sides by 2 gives Thus by and using the fact that we have that , , , and are all non-negative. QED. I've checked some answers setting and y=x in seems to be the right strategy. My question is why does setting y=x work in this case? Doesn't this only prove for the case in which y=x? What about when y doesn't equal x? I've a seen similar strategies used in proofs before and I never quite understood how prooving for a limited set of cases prooved all cases. Many thanks.","\textbf{M2} d(x,y) = 0 x=y \textbf{M3} d(x,y) = d(y,x) \textbf{M4} d(x,y) \leq d(x,z) + d(z,y) x,y,z d(x,x), d(y,y), d(z,z) \textbf{M2} x=y \textbf{M2} \textbf{M3} \textbf{M4} \begin{equation}
\begin{split}
    d(x,y)=0 & \leq d(x,z) + d(z,y) \\
             & \leq d(x,z) + d(z,x) \\
             & \leq d(x,z) + d(x,z) \\
             & \leq 2d(x,z)
\end{split}
\end{equation} \begin{equation}
    0 \leq d(x,z)
\end{equation} \textbf{M3} y=x d(x,z) d(z,x) d(y,z) d(z,y) \textbf{M4}",['functional-analysis']
93,"Give an example of distribution $u \in \mathcal{D}'((0,+\infty)) $ that is not extendible to $\mathbb{R}$",Give an example of distribution  that is not extendible to,"u \in \mathcal{D}'((0,+\infty))  \mathbb{R}","i.e. find a $u \in \mathcal{D}'((0,+\infty))$ , such that for any $v \in \mathcal{D}'(\mathbb{R})$ , $v|_{(0, +\infty)} \neq u$ . In order to find such an example, my question: I tried to prove $e^{1/x^2}$ is an example, i.e. there is a distribution u such that $ u|_{(0, +\infty)} = e^{1/x^2}$ , but I cannot find a contradiction.","i.e. find a , such that for any , . In order to find such an example, my question: I tried to prove is an example, i.e. there is a distribution u such that , but I cannot find a contradiction.","u \in \mathcal{D}'((0,+\infty)) v \in \mathcal{D}'(\mathbb{R}) v|_{(0, +\infty)} \neq u e^{1/x^2}  u|_{(0, +\infty)} = e^{1/x^2}","['functional-analysis', 'partial-differential-equations', 'distribution-theory']"
94,"Brezis section 7.2, theorem 7.3","Brezis section 7.2, theorem 7.3",,"This is from Brezis' Functional Analysis, Sobolev Spaces, and PDEs book. Theorem 7.3 reads: Let $E$ be a Banach space, $F: E \rightarrow E$ a Lipschitz map. If $u_0 \in E$ then there exists a unique solution $u \in C^1([0,\infty); E)$ of the problem $$\begin{cases} \frac{du}{dt}=Fu(t) &\mbox{on } [0, \infty), \\ u(0) = u_0. & \\ \end{cases}$$ The proof defines a Banach space: let $k > 0$ , and set $$ X = \{u \in C([0, \infty); E) \mid \sup_{t \geq 0} e^{-kt} \lVert u(t) \rVert < \infty\}. $$ Then if $u \in X$ , we claim $$ (\Phi u)(t) = u_0 + \int_0^t F(u(s))ds $$ is also an element of $X$ . My question is why? If $F = \mbox{id}_E$ and $u(t) = f(t)u_0$ with $\lVert u_0 \rVert = 1$ and $f(t) \in \mathbb R_{>0}$ , then membership $u \in X$ says $\sup_{t \geq 0} e^{-kt}f(t) < \infty$ while membership $\Phi u \in X$ says $\sup_{t \geq 0} e^{-kt}(1 + \int_0^t f(s)ds) < \infty$ . It seems to me that although $e^{-kt}f(t)$ might be bounded, $e^{-kt}\int_0^t f(s)ds$ might not, since there are functions whose integral grows quicker than itself. On the other hand, I can somewhat reason that this growth is ""polynomial"", in the sense $\int_0^t sds = \frac{t^2}{2}$ grows faster than $t$ but polynomially so, and therefore continues to be controlled by $e^{-kt}$ . Is there any direct proof or intuition for why $u \in X$ implies $\Phi u \in X$ ?","This is from Brezis' Functional Analysis, Sobolev Spaces, and PDEs book. Theorem 7.3 reads: Let be a Banach space, a Lipschitz map. If then there exists a unique solution of the problem The proof defines a Banach space: let , and set Then if , we claim is also an element of . My question is why? If and with and , then membership says while membership says . It seems to me that although might be bounded, might not, since there are functions whose integral grows quicker than itself. On the other hand, I can somewhat reason that this growth is ""polynomial"", in the sense grows faster than but polynomially so, and therefore continues to be controlled by . Is there any direct proof or intuition for why implies ?","E F: E \rightarrow E u_0 \in E u \in C^1([0,\infty); E) \begin{cases} \frac{du}{dt}=Fu(t) &\mbox{on } [0, \infty), \\ u(0) = u_0. & \\ \end{cases} k > 0  X = \{u \in C([0, \infty); E) \mid \sup_{t \geq 0} e^{-kt} \lVert u(t) \rVert < \infty\}.  u \in X  (\Phi u)(t) = u_0 + \int_0^t F(u(s))ds  X F = \mbox{id}_E u(t) = f(t)u_0 \lVert u_0 \rVert = 1 f(t) \in \mathbb R_{>0} u \in X \sup_{t \geq 0} e^{-kt}f(t) < \infty \Phi u \in X \sup_{t \geq 0} e^{-kt}(1 + \int_0^t f(s)ds) < \infty e^{-kt}f(t) e^{-kt}\int_0^t f(s)ds \int_0^t sds = \frac{t^2}{2} t e^{-kt} u \in X \Phi u \in X","['real-analysis', 'functional-analysis', 'analysis']"
95,Problem 7.V Bartle Elements of Integration,Problem 7.V Bartle Elements of Integration,,"$\textbf{Question:}$ Let $(X,\mathcal{F},\mu)$ be an arbitrary measure space. Let $\varphi: \mathbb{R} \rightarrow \mathbb{R}$ be continuous and satisfy for some $K>0$ : $$ \vert \varphi(t) \vert \leq K \vert t \vert, \forall t\in \mathbb{R} \tag{$*$}$$ If $f \in L^p$ , then $\varphi \circ f$ belongs to $L^p$ . Conversely, if $\varphi$ does not satisfy (*), there exists a measure space $(X,\mathcal{F},\mu)$ and a function $f \in L^p$ such that $\varphi \circ f$ does not belong to $L^p$ . $\textbf{My attempt:}$ If $\varphi$ satisfy $(*)$ we have for each $(X,\mathcal{F},\mu)$ and $x\in X$ $$ \vert (\varphi \circ f)(x) \vert = \vert \varphi(f(x)) \vert \leq K \vert f(x) \vert $$ $$ \implies \vert \varphi \circ f \vert^p \leq K^p \vert f \vert^p $$ So $\varphi \circ f \in L^p$ . I can't solve the other statement, help please.","Let be an arbitrary measure space. Let be continuous and satisfy for some : If , then belongs to . Conversely, if does not satisfy (*), there exists a measure space and a function such that does not belong to . If satisfy we have for each and So . I can't solve the other statement, help please.","\textbf{Question:} (X,\mathcal{F},\mu) \varphi: \mathbb{R} \rightarrow \mathbb{R} K>0  \vert \varphi(t) \vert \leq K \vert t \vert, \forall t\in \mathbb{R} \tag{*} f \in L^p \varphi \circ f L^p \varphi (X,\mathcal{F},\mu) f \in L^p \varphi \circ f L^p \textbf{My attempt:} \varphi (*) (X,\mathcal{F},\mu) x\in X  \vert (\varphi \circ f)(x) \vert = \vert \varphi(f(x)) \vert \leq K \vert f(x) \vert   \implies \vert \varphi \circ f \vert^p \leq K^p \vert f \vert^p  \varphi \circ f \in L^p",['real-analysis']
96,Equivalent definitions of Fredholm operators on infinite dimensional Banach spaces,Equivalent definitions of Fredholm operators on infinite dimensional Banach spaces,,"This question is similar to other questions on MSE, but none of them has an answer which satisfies me. Given an infinite dimensional complex Banach space $X$ , $T \in B(H)$ is Fredholm iff the cokernel and the kernel are finite dimensional (if the dimension of the cokernel is finite dimensional, the range is closed, so I have not written this last condition because it is redundant). Now, for Hilbert spaces it can be shown, using decompositions in direct orthogonal sums, that $\dim \operatorname{coker} T < \infty$ is equivalent to $\dim \ker T^* < \infty$ ., where $T^*$ is the adjoint of $T$ . The adjoint can be defined even for general Banach spaces. Moreover, we can define a notion of orthogonal complement in Banach spaces using the dual space $X^*$ . When $X$ is reflexive, we can obtain properties of orthogonality which are similar to Hilbert spaces (when $X$ is not reflexive, some analoguous facts which hold for Hilbert spaces are not anymore valid). So, I would expect that $\dim \operatorname{coker} T < \infty \Leftrightarrow \dim \ker T^* < \infty$ could be true for $X$ reflexive. But what happens for general Banach spaces? A proof as in the case of Hilbert spaces seem to be not anymore possible, but maybe something else could work. So my question is: does this equivalence still hold in general? If the answer is yes, could you please provide some reference with a proof of this fact? EDIT: @s.harp Even though your proof seems correct to me, consider the Toeplitz operator with symbol $(z-1)$ on $H^2$ . The kernel of this operator and the kernel of its adjoint are both trivial, so they have dimension $0$ . This would imply that the dimension of the cokernel is finite, which implies that the range of the operator is closed. However, this Toeplitz operator has a dense - but not closed - range. Maybe this fact depends on the logical axioms used (as, for instance, in the case of Whitehead problem)?","This question is similar to other questions on MSE, but none of them has an answer which satisfies me. Given an infinite dimensional complex Banach space , is Fredholm iff the cokernel and the kernel are finite dimensional (if the dimension of the cokernel is finite dimensional, the range is closed, so I have not written this last condition because it is redundant). Now, for Hilbert spaces it can be shown, using decompositions in direct orthogonal sums, that is equivalent to ., where is the adjoint of . The adjoint can be defined even for general Banach spaces. Moreover, we can define a notion of orthogonal complement in Banach spaces using the dual space . When is reflexive, we can obtain properties of orthogonality which are similar to Hilbert spaces (when is not reflexive, some analoguous facts which hold for Hilbert spaces are not anymore valid). So, I would expect that could be true for reflexive. But what happens for general Banach spaces? A proof as in the case of Hilbert spaces seem to be not anymore possible, but maybe something else could work. So my question is: does this equivalence still hold in general? If the answer is yes, could you please provide some reference with a proof of this fact? EDIT: @s.harp Even though your proof seems correct to me, consider the Toeplitz operator with symbol on . The kernel of this operator and the kernel of its adjoint are both trivial, so they have dimension . This would imply that the dimension of the cokernel is finite, which implies that the range of the operator is closed. However, this Toeplitz operator has a dense - but not closed - range. Maybe this fact depends on the logical axioms used (as, for instance, in the case of Whitehead problem)?",X T \in B(H) \dim \operatorname{coker} T < \infty \dim \ker T^* < \infty T^* T X^* X X \dim \operatorname{coker} T < \infty \Leftrightarrow \dim \ker T^* < \infty X (z-1) H^2 0,"['functional-analysis', 'operator-theory', 'banach-spaces']"
97,schauder basis vs isomorphisms,schauder basis vs isomorphisms,,"My doubt is about a space with schauder basis. If a space has schauder basis so can i say that it has an isometric isomorphism with some space? For an exemple: $c$ has a schauder basis, can i considere another set a dual space who it is isomorphic? I am thinking this because i know that $(c_0)'=l_1$ and can i see something like this to $c_0$ ? ps: I know that every separate space has an isomorphism with some subspace of $l_{\infty}$ . But in this case i think that i can considerate is just trivial isomorphism. plus: I know that $l_1'=l_{\infty}$ and $l_p=l_q'$ , with $\frac{1}{p}+\frac{1}{q}=1$ . Is there another set that can i make this easily?","My doubt is about a space with schauder basis. If a space has schauder basis so can i say that it has an isometric isomorphism with some space? For an exemple: has a schauder basis, can i considere another set a dual space who it is isomorphic? I am thinking this because i know that and can i see something like this to ? ps: I know that every separate space has an isomorphism with some subspace of . But in this case i think that i can considerate is just trivial isomorphism. plus: I know that and , with . Is there another set that can i make this easily?",c (c_0)'=l_1 c_0 l_{\infty} l_1'=l_{\infty} l_p=l_q' \frac{1}{p}+\frac{1}{q}=1,"['functional-analysis', 'schauder-basis']"
98,Equivalence in strong convergence of operators,Equivalence in strong convergence of operators,,"I am trying to see if I have that $(T_n)\in L(X)$ bounded and that $T_nx$ converges to $Tx$ for every $x$ in a dense subset of $X$ a Banach space, then $T_n$ converges strongly to $T$ . Let suppose that $D$ is the dense subset, I was able to see that if $x\in cl D$ then $T_nx$ is a Cauchy sequence so we know that it converges , but I can't see that it converges to $T_x$ . Also I tried seeing by this ' $$||T_nx-T_x||=||T_nx-T_nd_n+T_nd_n-T_x||\leq ||T_n||||x-d_n||+||T_nd_n-T_x||,$$ where $d_k \rightarrow x,$ but I can't seem to prove what I want. Any advice is appreciated.","I am trying to see if I have that bounded and that converges to for every in a dense subset of a Banach space, then converges strongly to . Let suppose that is the dense subset, I was able to see that if then is a Cauchy sequence so we know that it converges , but I can't see that it converges to . Also I tried seeing by this ' where but I can't seem to prove what I want. Any advice is appreciated.","(T_n)\in L(X) T_nx Tx x X T_n T D x\in cl D T_nx T_x ||T_nx-T_x||=||T_nx-T_nd_n+T_nd_n-T_x||\leq ||T_n||||x-d_n||+||T_nd_n-T_x||, d_k \rightarrow x,","['functional-analysis', 'operator-theory', 'banach-spaces']"
99,Representation of a bounded linear operator $T: c \to c$.,Representation of a bounded linear operator .,T: c \to c,"Let $T: c\to c$ be a bounded linear operator, where $c$ is the vector space of convergent real sequences. How can we prove that there exists an infinite matrix $A=(a_{n,k}: n,k\ge 1)$ such that $T(x)=Ax$ for all $x \in c$ ? The proof is very easy replacing $c$ in both places with $c_0=\{x \in c: \lim_n x_n=0\}$ (indeed, in such case, $\{e^i: i\ge 1\}$ is a Schauder basis for $c_0$ , where $e^i \in c$ is the sequence which is constantly equal to $0$ , except $e_i^i=1$ ).","Let be a bounded linear operator, where is the vector space of convergent real sequences. How can we prove that there exists an infinite matrix such that for all ? The proof is very easy replacing in both places with (indeed, in such case, is a Schauder basis for , where is the sequence which is constantly equal to , except ).","T: c\to c c A=(a_{n,k}: n,k\ge 1) T(x)=Ax x \in c c c_0=\{x \in c: \lim_n x_n=0\} \{e^i: i\ge 1\} c_0 e^i \in c 0 e_i^i=1","['functional-analysis', 'riesz-representation-theorem', 'summability-theory']"
