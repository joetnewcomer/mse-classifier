,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Is it true that if $f(x)$ has a linear factor over $\mathbb{F}_p$ for every prime $p$, then $f(x)$ is reducible over $\mathbb{Q}$?","Is it true that if  has a linear factor over  for every prime , then  is reducible over ?",f(x) \mathbb{F}_p p f(x) \mathbb{Q},"We know that $f(x)=x^4+1$ is a polynomial irreducible over $\mathbb{Q}$ but reducible over $\mathbb{F}_p$ for every prime $p$ . My question is: Is it true that if $f(x)$ has a linear factor over $\mathbb{F}_p$ for every prime $p$, then $f(x)$ has a linear factor over $\mathbb{Q}$? Edit: Thanks for @Jyrki Lahtonen's answer, I want to do some modifications: Is it true that if $f(x)$ has a linear factor over $\mathbb{F}_p$ for every prime $p$, then $f(x)$ is reducible over $\mathbb{Q}$? Thanks in advance!","We know that $f(x)=x^4+1$ is a polynomial irreducible over $\mathbb{Q}$ but reducible over $\mathbb{F}_p$ for every prime $p$ . My question is: Is it true that if $f(x)$ has a linear factor over $\mathbb{F}_p$ for every prime $p$, then $f(x)$ has a linear factor over $\mathbb{Q}$? Edit: Thanks for @Jyrki Lahtonen's answer, I want to do some modifications: Is it true that if $f(x)$ has a linear factor over $\mathbb{F}_p$ for every prime $p$, then $f(x)$ is reducible over $\mathbb{Q}$? Thanks in advance!",,"['abstract-algebra', 'number-theory', 'polynomials', 'algebraic-number-theory', 'irreducible-polynomials']"
1,Non-Noetherian ring with a single prime ideal [closed],Non-Noetherian ring with a single prime ideal [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question What are the most simple examples of a commutative ring $R$ satisfying both of the following two properties: 1. $R$ is not Noetherian. 2. $R$ has exactly one prime ideal.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question What are the most simple examples of a commutative ring $R$ satisfying both of the following two properties: 1. $R$ is not Noetherian. 2. $R$ has exactly one prime ideal.",,"['abstract-algebra', 'commutative-algebra']"
2,Relationship between subrings and ideals,Relationship between subrings and ideals,,"I just want to make sure that I understand these two objects correctly. Let $R$ be a ring. A subset $R'\subseteq R$ is a subring provided $R'$ is an additive subgroup that is closed with respect to multiplication. A subset $I\subseteq R$ is an ideal provided $I$ is an additive subgroup such that $rI\subseteq I$ and $Ir\subseteq I$ for all $r\in R$ (where $rI$ and $Ir$ are defined in the ""obvious"" way). Now, in my notes, for the definition of a subring, I didn't specify what I meant by ""with respect to multiplication."" Looking back now, I assume I meant left multiplication. So then, if this is correct, an ideal is a subring that is closed with respect to both left and right multiplication. Is this correct?","I just want to make sure that I understand these two objects correctly. Let $R$ be a ring. A subset $R'\subseteq R$ is a subring provided $R'$ is an additive subgroup that is closed with respect to multiplication. A subset $I\subseteq R$ is an ideal provided $I$ is an additive subgroup such that $rI\subseteq I$ and $Ir\subseteq I$ for all $r\in R$ (where $rI$ and $Ir$ are defined in the ""obvious"" way). Now, in my notes, for the definition of a subring, I didn't specify what I meant by ""with respect to multiplication."" Looking back now, I assume I meant left multiplication. So then, if this is correct, an ideal is a subring that is closed with respect to both left and right multiplication. Is this correct?",,"['abstract-algebra', 'ring-theory']"
3,Is the product of all positive rational numbers equal to one?,Is the product of all positive rational numbers equal to one?,,"I've started reading Pinter's Book of Abstract Algebra , and one of the early exercises calls for a proof that in a finite abelian group $G$, $(a_1a_2a_3a_4...a_n)^2 = e$, if there are any $a_n$ that are their own inverses, and that if no $a_n$ is its own inverse, then $(a_1a_2a_3a_4...a_n) = e$. Since I'm not doing this for a class, I worked out a very informal proof for the second case (no $a_n$ is its own inverse): Since there must be an $a^{-1}$ for each $a$, then $(a_1a_2a_3a_4...a_n)$ can be reduced to so many instances of $(a_1a_1^{-1}a_2a_2^{-1}...a_{n/2}a_{n/2}^{-1})$, which can be simplified to $e^{n/2}$, or just $e$. Is there a particular reason why this holds only for finite abelian groups? If one were to list rational numbers in order, as Cantor demonstrated, would the product of this list tend toward one? Also, would it be fair--albeit relatively meaningless--to say that the group $\mathbb{Q} > 0$ has an odd number of members, as it contains exactly one member that is its own inverse? (full disclosure--this is basically a hobby for me, so apologies in advance for any obvious errors in logic/notation/etc., but please point them out)","I've started reading Pinter's Book of Abstract Algebra , and one of the early exercises calls for a proof that in a finite abelian group $G$, $(a_1a_2a_3a_4...a_n)^2 = e$, if there are any $a_n$ that are their own inverses, and that if no $a_n$ is its own inverse, then $(a_1a_2a_3a_4...a_n) = e$. Since I'm not doing this for a class, I worked out a very informal proof for the second case (no $a_n$ is its own inverse): Since there must be an $a^{-1}$ for each $a$, then $(a_1a_2a_3a_4...a_n)$ can be reduced to so many instances of $(a_1a_1^{-1}a_2a_2^{-1}...a_{n/2}a_{n/2}^{-1})$, which can be simplified to $e^{n/2}$, or just $e$. Is there a particular reason why this holds only for finite abelian groups? If one were to list rational numbers in order, as Cantor demonstrated, would the product of this list tend toward one? Also, would it be fair--albeit relatively meaningless--to say that the group $\mathbb{Q} > 0$ has an odd number of members, as it contains exactly one member that is its own inverse? (full disclosure--this is basically a hobby for me, so apologies in advance for any obvious errors in logic/notation/etc., but please point them out)",,"['abstract-algebra', 'group-theory']"
4,Galois group of the splitting field of the polynomial $x^5 - 2$ over $\mathbb Q$,Galois group of the splitting field of the polynomial  over,x^5 - 2 \mathbb Q,"We know that the splitting field of $x^5 - 2 $ over $\mathbb Q$ is $\mathbb Q(2^{1/5}, \rho)$ , where $\rho$ is a fifth root of unity. Therefore, $\left[\mathbb Q(2^{1/5} , \rho) : \mathbb Q \right] = 20 $ . Let $G$ be the Galois group of $\mathbb Q(2^{1/5} , \rho)$ .  Then $|G| = 20$ . How to find the Galois group $G$ ? Can we generalize to the Galois group of the splitting field of $x^p -2$ over $\mathbb Q$ ?","We know that the splitting field of over is , where is a fifth root of unity. Therefore, . Let be the Galois group of .  Then . How to find the Galois group ? Can we generalize to the Galois group of the splitting field of over ?","x^5 - 2  \mathbb Q \mathbb Q(2^{1/5}, \rho) \rho \left[\mathbb Q(2^{1/5} , \rho) : \mathbb Q \right] = 20  G \mathbb Q(2^{1/5} , \rho) |G| = 20 G x^p -2 \mathbb Q","['abstract-algebra', 'field-theory', 'galois-theory', 'frobenius-groups']"
5,The use of conjugacy class and centralizer?,The use of conjugacy class and centralizer?,,"This is more or less for a conceptual and better-understanding question in group theory and in representation theory: (1) Why are conjugacy class and centralizer important concepts in the group / representation theory? What is the important use of conjugacy class and centralizer of an element $g$ in a group $G$? - (2) How is the case of the conjugacy class and centralizer for an element $g$ in a finite group $G$, different from a continuous group $G'$?","This is more or less for a conceptual and better-understanding question in group theory and in representation theory: (1) Why are conjugacy class and centralizer important concepts in the group / representation theory? What is the important use of conjugacy class and centralizer of an element $g$ in a group $G$? - (2) How is the case of the conjugacy class and centralizer for an element $g$ in a finite group $G$, different from a continuous group $G'$?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'representation-theory']"
6,"What is ""general position"" of hyperplanes?","What is ""general position"" of hyperplanes?",,"A brief question. I was reading some mathematical writing in which the author makes the following statement: Consider $S$ hyperplanes in general position... What is ""general position""? Googling does not return a satisfying answer. Note: I'm not exactly sure how to tag this, so please correct tags as necessary.","A brief question. I was reading some mathematical writing in which the author makes the following statement: Consider $S$ hyperplanes in general position... What is ""general position""? Googling does not return a satisfying answer. Note: I'm not exactly sure how to tag this, so please correct tags as necessary.",,"['abstract-algebra', 'geometry', 'algebraic-geometry']"
7,Real-world uses of Algebraic Structures,Real-world uses of Algebraic Structures,,"I am a Computer science student, and in discrete mathematics, I am learning about algebraic structures. In that I am having concepts like Group,semi-Groups etc... Previously I studied Graphs. I can see a excellent real world application for that. I strongly believe in future I can use many of that in my Coding Algorithms related to Graphics. Could someone tell me real-world application for algebraic structures too...","I am a Computer science student, and in discrete mathematics, I am learning about algebraic structures. In that I am having concepts like Group,semi-Groups etc... Previously I studied Graphs. I can see a excellent real world application for that. I strongly believe in future I can use many of that in my Coding Algorithms related to Graphics. Could someone tell me real-world application for algebraic structures too...",,"['abstract-algebra', 'soft-question', 'big-list', 'applications']"
8,A field of order $32$,A field of order,32,"I was working on this problem from an old qual exam and here is the  question. In particular this is not for homework. True or False: There are no fields of order 32. Justify your answer. Attempt : From general theory I know that any finite field has prime power order and conversely given any prime power there exists a finite field of that order. So of course such fields exist. But now I need to explicitly construct such a field. If I could somehow construct $\mathbb{Z}_2[x]/(p(x))$ where $p(x)$ is a polynomial of degree 5 which is irreducible over $Z_2$ I am done. But wait, how do I come up with a degree 5 polynomial that is irreducible over $Z_2$. My normal methods don't work here because $p(x)$ does not have order 2 or 3. In which case it is easy to check for irreducibility. My question is in these kinds of situations, is there a general way to proceed. Note: I have not learnt Galois' theory or anything like that. Does this problem require more machinery to solve? Please help.","I was working on this problem from an old qual exam and here is the  question. In particular this is not for homework. True or False: There are no fields of order 32. Justify your answer. Attempt : From general theory I know that any finite field has prime power order and conversely given any prime power there exists a finite field of that order. So of course such fields exist. But now I need to explicitly construct such a field. If I could somehow construct $\mathbb{Z}_2[x]/(p(x))$ where $p(x)$ is a polynomial of degree 5 which is irreducible over $Z_2$ I am done. But wait, how do I come up with a degree 5 polynomial that is irreducible over $Z_2$. My normal methods don't work here because $p(x)$ does not have order 2 or 3. In which case it is easy to check for irreducibility. My question is in these kinds of situations, is there a general way to proceed. Note: I have not learnt Galois' theory or anything like that. Does this problem require more machinery to solve? Please help.",,"['abstract-algebra', 'field-theory', 'finite-fields']"
9,"If $[G:H]$ and $[G:K]$ are relatively prime, then $G=HK$","If  and  are relatively prime, then",[G:H] [G:K] G=HK,"I'm struggling to proof that if $H$ and $K$ are subgroups of  finite index of a group $G$ such that $[G:H]$ and $[G:K]$ are relatively prime, then $G=HK$. I don't know why I can't answer it, because this question seems easy. I'm stuck maybe because I've studied so far just Lagrange's theorem and some of its consequences. But I think we don't need much more, because this is the material covered so far by the Hungerford's book. I need help. Thanks.","I'm struggling to proof that if $H$ and $K$ are subgroups of  finite index of a group $G$ such that $[G:H]$ and $[G:K]$ are relatively prime, then $G=HK$. I don't know why I can't answer it, because this question seems easy. I'm stuck maybe because I've studied so far just Lagrange's theorem and some of its consequences. But I think we don't need much more, because this is the material covered so far by the Hungerford's book. I need help. Thanks.",,"['abstract-algebra', 'group-theory']"
10,Is it possible to define a ring as a category?,Is it possible to define a ring as a category?,,"Is it possible to define a ring as a category? For example, a group can be defined as a category with just one object and all morphisms being isomorphisms.","Is it possible to define a ring as a category? For example, a group can be defined as a category with just one object and all morphisms being isomorphisms.",,"['abstract-algebra', 'ring-theory', 'category-theory']"
11,Definition of group action,Definition of group action,,"I'm currently taking a class in abstract algebra, and the textbook we are using is Ted Shifrin's Abstract Algebra: A Geometric Approach. In the chapter on group actions and symmetry, he defines a group actions as follows $$\phi: G \mapsto \operatorname{Perm}(S)$$ where $G$ is a group acting on set $S$. However, most internet sources I've come across define a group action as $$\phi: G \times S \to S$$ There are a few sources that talk about how the two are equivalent, but the explanations are overly brief. Can someone help me reconcile these two definitions?","I'm currently taking a class in abstract algebra, and the textbook we are using is Ted Shifrin's Abstract Algebra: A Geometric Approach. In the chapter on group actions and symmetry, he defines a group actions as follows $$\phi: G \mapsto \operatorname{Perm}(S)$$ where $G$ is a group acting on set $S$. However, most internet sources I've come across define a group action as $$\phi: G \times S \to S$$ There are a few sources that talk about how the two are equivalent, but the explanations are overly brief. Can someone help me reconcile these two definitions?",,"['abstract-algebra', 'group-theory', 'symmetry']"
12,"Where is the name ""coset"" in group theory from?","Where is the name ""coset"" in group theory from?",,"One of the most important application of "" coset "", I think, is to prove the Lagrange's theorem , which was not originally stated in the group theoretic terms. In some textbooks I  have read about abstract algebra, I didn't find any history about ""coset"". Here are my questions : Where is the concept ""coset"" from? And what was it originally used for?","One of the most important application of "" coset "", I think, is to prove the Lagrange's theorem , which was not originally stated in the group theoretic terms. In some textbooks I  have read about abstract algebra, I didn't find any history about ""coset"". Here are my questions : Where is the concept ""coset"" from? And what was it originally used for?",,"['abstract-algebra', 'group-theory']"
13,The confusing nature of direct sum for finite abelian groups,The confusing nature of direct sum for finite abelian groups,,"I would first like to make sure of the following concepts, note that all groups are abelian. Let $A,B$ be subgroups of $G$. (1) Cartesian product (a.k.a. external product): The Cartesian product of subgroups $A$ and $B$ is $A \times B = \left\{ (a,b) \:{:}\: a \in A, b \in B \right\}$ where the operation by components is the group operation. (2) Internal product: The internal product of subgroups $A$ and $B$ is $AB = \left\{ ab \:{:}\: a \in A, b \in B \right\}$. (3) Sum: The sum of subgroups A and B is $A + B = \left\{ a + b \:{:}\: a \in A, b \in B \right\}$. So (2) and (3) are basically the same objects because (2) is used under the multiplicative notation and (3) is used under the additive notation. (4) Direct product: The internal product $AB$ is called a direct product and denoted $A \times B$ (confusingly enough) if $A \cap B = \left\{ 1 \right\}$. (5) Direct sum: The sum $A + B$ is called a direct sum and denoted $A \oplus B$ if $A \cap B = \left\{ 0 \right\}$. So (4) and (5) are basically the same objects because (4) is used under the multiplicative notation and (5) is used under the additive notation. I am aware that (1) and (4) (or (5)) are isomorphic and often used interchangeably. When the direct sum is used in a correct way, it causes no confusion at all such as $\mathbb{Z}_{15} = \left\{ 0,5,10 \right\} \oplus \left\{ 0,3,6,9,12 \right\}$. But when it is used in a rather ambiguous way such as $\mathbb{Z}_2 \oplus \mathbb{Z}_2$, which should be $\left\{ 0+0,0+1,1+0,1+1 \right\} = \left\{ 0,1 \right\}$, which is of order $2$, but I have seen my lecturer saying it is of order $4$, so he must have interpreted it as the Cartesian product owing to the isomorphic nature. I am really not happy with this as the definition of sum and direct sum clearly states otherwise. Could anyone shed some enlightening lights on this issue?","I would first like to make sure of the following concepts, note that all groups are abelian. Let $A,B$ be subgroups of $G$. (1) Cartesian product (a.k.a. external product): The Cartesian product of subgroups $A$ and $B$ is $A \times B = \left\{ (a,b) \:{:}\: a \in A, b \in B \right\}$ where the operation by components is the group operation. (2) Internal product: The internal product of subgroups $A$ and $B$ is $AB = \left\{ ab \:{:}\: a \in A, b \in B \right\}$. (3) Sum: The sum of subgroups A and B is $A + B = \left\{ a + b \:{:}\: a \in A, b \in B \right\}$. So (2) and (3) are basically the same objects because (2) is used under the multiplicative notation and (3) is used under the additive notation. (4) Direct product: The internal product $AB$ is called a direct product and denoted $A \times B$ (confusingly enough) if $A \cap B = \left\{ 1 \right\}$. (5) Direct sum: The sum $A + B$ is called a direct sum and denoted $A \oplus B$ if $A \cap B = \left\{ 0 \right\}$. So (4) and (5) are basically the same objects because (4) is used under the multiplicative notation and (5) is used under the additive notation. I am aware that (1) and (4) (or (5)) are isomorphic and often used interchangeably. When the direct sum is used in a correct way, it causes no confusion at all such as $\mathbb{Z}_{15} = \left\{ 0,5,10 \right\} \oplus \left\{ 0,3,6,9,12 \right\}$. But when it is used in a rather ambiguous way such as $\mathbb{Z}_2 \oplus \mathbb{Z}_2$, which should be $\left\{ 0+0,0+1,1+0,1+1 \right\} = \left\{ 0,1 \right\}$, which is of order $2$, but I have seen my lecturer saying it is of order $4$, so he must have interpreted it as the Cartesian product owing to the isomorphic nature. I am really not happy with this as the definition of sum and direct sum clearly states otherwise. Could anyone shed some enlightening lights on this issue?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
14,Find four groups of order 20 not isomorphic to each other.,Find four groups of order 20 not isomorphic to each other.,,"Find four groups of order 20 not isomorphic to each other and prove why they aren't isomorphic. So far I thought of $\mathbb Z_{20}$, $\mathbb Z_2 \oplus\mathbb Z_{10}$, and $D_{10}$ (dihedral group), but I can't find another one. Would $U(50)$ work? I know it has order 20 and is cyclic but I'm not exactly sure how to move from there. Can someone to point me on the right direction?","Find four groups of order 20 not isomorphic to each other and prove why they aren't isomorphic. So far I thought of $\mathbb Z_{20}$, $\mathbb Z_2 \oplus\mathbb Z_{10}$, and $D_{10}$ (dihedral group), but I can't find another one. Would $U(50)$ work? I know it has order 20 and is cyclic but I'm not exactly sure how to move from there. Can someone to point me on the right direction?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
15,Why $x^{p^n}-x+1$ is irreducible in ${\mathbb{F}_p}$ only when $n=1$ or $n=p=2$,Why  is irreducible in  only when  or,x^{p^n}-x+1 {\mathbb{F}_p} n=1 n=p=2,"I have a question, I think it concerns with field theory. Why the polynomial $$x^{p^n}-x+1$$ is irreducible over ${\mathbb{F}_p}$ only when $n=1$ or $n=p=2$ ? Thanks in advance. It bothers me for several days.","I have a question, I think it concerns with field theory. Why the polynomial is irreducible over only when or ? Thanks in advance. It bothers me for several days.",x^{p^n}-x+1 {\mathbb{F}_p} n=1 n=p=2,"['abstract-algebra', 'polynomials', 'finite-fields', 'irreducible-polynomials']"
16,Software for Galois Theory,Software for Galois Theory,,Background: While studying Group Theory ( Open University M208 ) I had a lot of benefit from the Mathematica Add-on package AbstractAlgebra and later from the GAP software. I am currently self-studying Galois Theory ( using Ian Stewart's Galois Theory  ). Question: Is there a program that calculates the Field Extensions / Galois Group for a ( simple ) polynomial ?,Background: While studying Group Theory ( Open University M208 ) I had a lot of benefit from the Mathematica Add-on package AbstractAlgebra and later from the GAP software. I am currently self-studying Galois Theory ( using Ian Stewart's Galois Theory  ). Question: Is there a program that calculates the Field Extensions / Galois Group for a ( simple ) polynomial ?,,"['abstract-algebra', 'math-software']"
17,Ideals of formal power series ring,Ideals of formal power series ring,,"I need help understanding the following solution for the given problem. The problem is as follows: Given a field $F$, the set of all formal power series $p(t)=a_0+a_1 t+a_2 t^2 + \ldots$ with $a_i \in F$ forms a ring $F[[t]]$. Determine the ideals of the ring. The solution: Let $I$ be an ideal and $p \in I$ such the number $a := \min\{i|a_i \neq 0\}$ is minimal. We claim $I=(t^a).$ First, $p=t^aq$ for some unit $q$, hence $(t^a) \subset I$. Conversely, any $r \in I$ has first nonzero coefficient at degree $\geq a$, hence $t^a s$ for some $s \in F[[t]]$, and so $r \in (t^a)$. My questions: Why the claim $I=(t^a)$? Why does $q$ have to be a unit? What does ""first nonzero coefficient at degree $\geq a$ mean? And I don't understand the last part of the proof!!","I need help understanding the following solution for the given problem. The problem is as follows: Given a field $F$, the set of all formal power series $p(t)=a_0+a_1 t+a_2 t^2 + \ldots$ with $a_i \in F$ forms a ring $F[[t]]$. Determine the ideals of the ring. The solution: Let $I$ be an ideal and $p \in I$ such the number $a := \min\{i|a_i \neq 0\}$ is minimal. We claim $I=(t^a).$ First, $p=t^aq$ for some unit $q$, hence $(t^a) \subset I$. Conversely, any $r \in I$ has first nonzero coefficient at degree $\geq a$, hence $t^a s$ for some $s \in F[[t]]$, and so $r \in (t^a)$. My questions: Why the claim $I=(t^a)$? Why does $q$ have to be a unit? What does ""first nonzero coefficient at degree $\geq a$ mean? And I don't understand the last part of the proof!!",,"['abstract-algebra', 'ring-theory']"
18,"If an element has a unique right inverse, is it invertible?","If an element has a unique right inverse, is it invertible?",,"Suppose $u$ is an element of a ring with a right inverse. I'm trying to understand why the following are equivalent. $u$ has at least two right inverses $u$ is a left zero divisor $u$ is not a unit If $v$ and $w$ are distinct right inverse of $u$, then $u(v-w)=0$, but $v-w\neq 0$, so $u$ is a left zero divisor. It's also clear that if $u$ is a left zero divisor, it cannot be a unit (else I could cancel $u$ from $ub=0$ to see $b=0$). I'm having a heck of a time seeing why $u$ is not a unit implies $u$ has at least two right inverses. I tried the contrapositive, but saw no good approach. What am I missing?","Suppose $u$ is an element of a ring with a right inverse. I'm trying to understand why the following are equivalent. $u$ has at least two right inverses $u$ is a left zero divisor $u$ is not a unit If $v$ and $w$ are distinct right inverse of $u$, then $u(v-w)=0$, but $v-w\neq 0$, so $u$ is a left zero divisor. It's also clear that if $u$ is a left zero divisor, it cannot be a unit (else I could cancel $u$ from $ub=0$ to see $b=0$). I'm having a heck of a time seeing why $u$ is not a unit implies $u$ has at least two right inverses. I tried the contrapositive, but saw no good approach. What am I missing?",,"['abstract-algebra', 'ring-theory']"
19,"Elementary proof that if $A$ is a matrix map from $\mathbb{Z}^m$ to $\mathbb Z^n$, then the map is surjective iff the gcd of maximal minors is $1$","Elementary proof that if  is a matrix map from  to , then the map is surjective iff the gcd of maximal minors is",A \mathbb{Z}^m \mathbb Z^n 1,"I am trying to find an elementary proof that if $\phi$ is a linear map from $\mathbb{Z}^n\rightarrow \mathbb{Z}^m$ represented by an $m \times n$ matrix $A$, then the map is surjective iff the gcd of the determinants of all the $m\times m$ minors of $A$ is $1$. I know that for there to be surjectivity between $\mathbb{Z}^n$ and $\mathbb{Z}^m$ $n$ must be greater than or equal to $ m$ and for there to even be $m \times m$ minors $n$ again must be greater than or equal to $ m$, so I just assume this throughout. I sort of have one direction $\Leftarrow$ i) Greatest Common Divisor =1 implies surjectivity: First observe that the if $ | \mathbb{Z}^m/ Im(M)| < \infty$ then $|\det M| = | \mathbb{Z}^m/ Im(M) |$ otherwise $\det(M) = 0$ where $M$ is an $m\times m$ matrix. We can consider the $n$ columns of $A$ as column vectors $v_1, v_2, \ldots, v_n$. These $n$ column vectors live in $\mathbb{Z}^m$. Let $S'' = \{ v_i\}$ and then let $S'$ be subsets of $S''$ of cardinality $m$ and lastly let $S$ be the elements of $S'$ such that when the $m$ $v_i$ vectors are considered as $m\times m$ matrices, the determinant is not zero, thus $S$ consists of all $m\times m$ minors of $A$ with non-zero determinant (we ignore zeroes since they do not affect gcd). For each $s\in S$ define a map $i_s: \mathbb{Z}^m \rightarrow \mathbb{Z}^n$ that maps the standard basis of  $\mathbb{Z}^m$ to the basis elements $e_k \mathbb{Z}^n$ such that $v_k \in s$. That is, $\phi \circ i_s$ gives the matrix created by the column vectors of  $s$. Let $\Lambda$ be the lattice Im$\phi \supset \sum_{s\in S}$ Im $\phi\circ i_s =\sum_{s \in S} \Lambda_s$. Thus $\forall s \in S$,  $\Lambda_s \subset \Lambda \subset \mathbb{Z}^m$. Thinking in terms of group theory, we have that $\Lambda$ is a subgroup of $\mathbb{Z}^m$ and all the  $\Lambda_s$ are subgroups of $\Lambda$. Thus by Lagrange's Theorem, we have  $|\mathbb{Z}/\Lambda| \Big\vert |\mathbb{Z}^m/\Lambda_s|$ Since $|\mathbb{Z}^m/\Lambda_s|$ are the determininants of the $m\times m$ minors and the definition of the common divisor of several integers is the greatest positive integer dividing all of them. Thus by hypothesis $|\mathbb{Z}/\Lambda| \leq 1$ and so $|\mathbb{Z}/\Lambda| =1$ and we have that Im$A=\Lambda = \mathbb{Z}^m$ so the map is surjective. I was hoping to get a more elementary proof that doesn't rely on the observation that the if $ | \mathbb{Z}^m/ Im(M)| < \infty$ then $|\det M| = | \mathbb{Z}^m/ Im(M) |$ otherwise $\det(M) = 0$ where $M$ is an $m\times m$ matrix or normal forms. Thanks!","I am trying to find an elementary proof that if $\phi$ is a linear map from $\mathbb{Z}^n\rightarrow \mathbb{Z}^m$ represented by an $m \times n$ matrix $A$, then the map is surjective iff the gcd of the determinants of all the $m\times m$ minors of $A$ is $1$. I know that for there to be surjectivity between $\mathbb{Z}^n$ and $\mathbb{Z}^m$ $n$ must be greater than or equal to $ m$ and for there to even be $m \times m$ minors $n$ again must be greater than or equal to $ m$, so I just assume this throughout. I sort of have one direction $\Leftarrow$ i) Greatest Common Divisor =1 implies surjectivity: First observe that the if $ | \mathbb{Z}^m/ Im(M)| < \infty$ then $|\det M| = | \mathbb{Z}^m/ Im(M) |$ otherwise $\det(M) = 0$ where $M$ is an $m\times m$ matrix. We can consider the $n$ columns of $A$ as column vectors $v_1, v_2, \ldots, v_n$. These $n$ column vectors live in $\mathbb{Z}^m$. Let $S'' = \{ v_i\}$ and then let $S'$ be subsets of $S''$ of cardinality $m$ and lastly let $S$ be the elements of $S'$ such that when the $m$ $v_i$ vectors are considered as $m\times m$ matrices, the determinant is not zero, thus $S$ consists of all $m\times m$ minors of $A$ with non-zero determinant (we ignore zeroes since they do not affect gcd). For each $s\in S$ define a map $i_s: \mathbb{Z}^m \rightarrow \mathbb{Z}^n$ that maps the standard basis of  $\mathbb{Z}^m$ to the basis elements $e_k \mathbb{Z}^n$ such that $v_k \in s$. That is, $\phi \circ i_s$ gives the matrix created by the column vectors of  $s$. Let $\Lambda$ be the lattice Im$\phi \supset \sum_{s\in S}$ Im $\phi\circ i_s =\sum_{s \in S} \Lambda_s$. Thus $\forall s \in S$,  $\Lambda_s \subset \Lambda \subset \mathbb{Z}^m$. Thinking in terms of group theory, we have that $\Lambda$ is a subgroup of $\mathbb{Z}^m$ and all the  $\Lambda_s$ are subgroups of $\Lambda$. Thus by Lagrange's Theorem, we have  $|\mathbb{Z}/\Lambda| \Big\vert |\mathbb{Z}^m/\Lambda_s|$ Since $|\mathbb{Z}^m/\Lambda_s|$ are the determininants of the $m\times m$ minors and the definition of the common divisor of several integers is the greatest positive integer dividing all of them. Thus by hypothesis $|\mathbb{Z}/\Lambda| \leq 1$ and so $|\mathbb{Z}/\Lambda| =1$ and we have that Im$A=\Lambda = \mathbb{Z}^m$ so the map is surjective. I was hoping to get a more elementary proof that doesn't rely on the observation that the if $ | \mathbb{Z}^m/ Im(M)| < \infty$ then $|\det M| = | \mathbb{Z}^m/ Im(M) |$ otherwise $\det(M) = 0$ where $M$ is an $m\times m$ matrix or normal forms. Thanks!",,"['abstract-algebra', 'modules', 'determinant', 'integer-lattices']"
20,"""Resultant"" of three polynomials","""Resultant"" of three polynomials",,"The resultant $\operatorname{Res}(f,g)$ of two polynomials over a field $k$ is a polynomial in the coefficients of $f$ and $g$ which enjoys the property of being nonzero if and only if $f$ and $g$ have no common root in an algebraic closure $\overline{k}$ of $k$. Does there exist a similar construction for three polynomials? There seems to be none. I would like to suggest the following conjecture: Conjecture : there does not exist a function $\operatorname{Res}(f,g,h)$ of three polynomials $f,g,h \in k[x]$, which is a polynomial in the coefficients of $f,g,h$, having the property of being zero if and only if the polynomials $f,g,h$ have a common root in an algebraic closure $\overline{k}$ of $k$.","The resultant $\operatorname{Res}(f,g)$ of two polynomials over a field $k$ is a polynomial in the coefficients of $f$ and $g$ which enjoys the property of being nonzero if and only if $f$ and $g$ have no common root in an algebraic closure $\overline{k}$ of $k$. Does there exist a similar construction for three polynomials? There seems to be none. I would like to suggest the following conjecture: Conjecture : there does not exist a function $\operatorname{Res}(f,g,h)$ of three polynomials $f,g,h \in k[x]$, which is a polynomial in the coefficients of $f,g,h$, having the property of being zero if and only if the polynomials $f,g,h$ have a common root in an algebraic closure $\overline{k}$ of $k$.",,"['abstract-algebra', 'polynomials']"
21,"If every commutator is idempotent, then the ring is commutative","If every commutator is idempotent, then the ring is commutative",,"Let $R$ be a ring and for $x,y\!\in\!R$, define the commutator as $[x,y]:=xy-yx$. An $r\!\in\!R$ is idempotent iff $r^2=r$. How can one prove, that if every commutator is idempotent, then the whole ring is commutative, i.e. all commutators are zero?","Let $R$ be a ring and for $x,y\!\in\!R$, define the commutator as $[x,y]:=xy-yx$. An $r\!\in\!R$ is idempotent iff $r^2=r$. How can one prove, that if every commutator is idempotent, then the whole ring is commutative, i.e. all commutators are zero?",,"['abstract-algebra', 'ring-theory']"
22,"A ring with no non-zero nilpotents and $(ab)^2=a^2b^2$ for all $a,b$ must be commutative",A ring with no non-zero nilpotents and  for all  must be commutative,"(ab)^2=a^2b^2 a,b","Given that $R$ is a ring with no non-zero nilpotent elements and has $(ab)^2=a^2b^2$ for all $a,b\in R$, show that $R$ is commutative. I have previously shown that, if $R$ is unital and has $(ab)^2=a^2b^2$ for all $a,b\in R$, then $R$ is commutative. This allows me to restrict attention to non-unital $R$, but I haven't been able to get anywhere with that ""simplification"". The proof in the unital case makes explicit use of the unit element, and it does not seem to suggest anything for this new case. Some of the things I've tried: various element manipulations; looking for some sort of recurrence between powers of a commutator $ab-ba$; studying the set $S=\{(ab-ba)^k\mid k\in\mathbb{N}\}$. This is from Herstein's Topics in Algebra, second edition, problem #25 in the supplementary problems of chapter 3. Any hints would be appreciated. Edit: proof in the unital case If $R$ is unital, evaluate $[a(1+b)]^2$ in two different ways, using the stipulation of the problem, to find $a^2b=aba$. Similarly, $[(1+a)b]^2$ gives $ab^2=bab$. Finally, evaluating $[(1+a)(1+b)]^2$ in two different ways, and canceling terms using those two relations, we end up with $ab=ba$.","Given that $R$ is a ring with no non-zero nilpotent elements and has $(ab)^2=a^2b^2$ for all $a,b\in R$, show that $R$ is commutative. I have previously shown that, if $R$ is unital and has $(ab)^2=a^2b^2$ for all $a,b\in R$, then $R$ is commutative. This allows me to restrict attention to non-unital $R$, but I haven't been able to get anywhere with that ""simplification"". The proof in the unital case makes explicit use of the unit element, and it does not seem to suggest anything for this new case. Some of the things I've tried: various element manipulations; looking for some sort of recurrence between powers of a commutator $ab-ba$; studying the set $S=\{(ab-ba)^k\mid k\in\mathbb{N}\}$. This is from Herstein's Topics in Algebra, second edition, problem #25 in the supplementary problems of chapter 3. Any hints would be appreciated. Edit: proof in the unital case If $R$ is unital, evaluate $[a(1+b)]^2$ in two different ways, using the stipulation of the problem, to find $a^2b=aba$. Similarly, $[(1+a)b]^2$ gives $ab^2=bab$. Finally, evaluating $[(1+a)(1+b)]^2$ in two different ways, and canceling terms using those two relations, we end up with $ab=ba$.",,"['abstract-algebra', 'ring-theory']"
23,Suppose $H$ is the only subgroup of order $o(H)$ in the finite group $G$. Prove that $H$ is a normal subgroup of $G$.,Suppose  is the only subgroup of order  in the finite group . Prove that  is a normal subgroup of .,H o(H) G H G,"Suppose $H$ is the only subgroup of order $o(H)$ in the finite group $G$ . Prove that $H$ is a normal subgroup of $G$ . I've been trying this problem for quite a while but to no avail. What I can't understand is, how do you relate the subgroup being normal to its order? This question is from I.N. Herstein's book Topics in Algebra , page 53, Problem no. 9. This is NOT a homework problem!! I'm studying this book on my own.","Suppose is the only subgroup of order in the finite group . Prove that is a normal subgroup of . I've been trying this problem for quite a while but to no avail. What I can't understand is, how do you relate the subgroup being normal to its order? This question is from I.N. Herstein's book Topics in Algebra , page 53, Problem no. 9. This is NOT a homework problem!! I'm studying this book on my own.",H o(H) G H G,"['abstract-algebra', 'group-theory', 'normal-subgroups']"
24,$\Bbb{Q}$ is not a finitely generated $\Bbb{Z}$-module,is not a finitely generated -module,\Bbb{Q} \Bbb{Z},"I'm trying to show that $\Bbb{Q}$ is not a finitely generated $\Bbb{Z}$-module. Assume to the contrary that $$\Bbb{Q}=\Bbb{Z}\dfrac{a_1}{b_1}+...+\Bbb{Z}\dfrac{a_n}{b_n}$$ where $a_i,b_i\in\Bbb{Z}$. Let lcm$(b_1,...,b_n)=c$ and $d_i=\dfrac{c}{b_i}$. Then $$\Bbb{Q}=\dfrac{d_1a_1}{c}\Bbb{Z}+...+\dfrac{d_na_n}{c}\Bbb{Z}$$ Now let $p$ be a prime that does not divide $c$. Then, there are $x_1,...,x_n\in\Bbb{Z}$ such that $$\dfrac{1}{p}=\dfrac{d_1a_1x_1+...+d_na_nx_n}{c}$$ and hence $p(d_1a_1x_1+...+d_na_nx_n)=c$, which means that $p$ divides $c$, contradiction. That was suspiciously easy. What am I missing?","I'm trying to show that $\Bbb{Q}$ is not a finitely generated $\Bbb{Z}$-module. Assume to the contrary that $$\Bbb{Q}=\Bbb{Z}\dfrac{a_1}{b_1}+...+\Bbb{Z}\dfrac{a_n}{b_n}$$ where $a_i,b_i\in\Bbb{Z}$. Let lcm$(b_1,...,b_n)=c$ and $d_i=\dfrac{c}{b_i}$. Then $$\Bbb{Q}=\dfrac{d_1a_1}{c}\Bbb{Z}+...+\dfrac{d_na_n}{c}\Bbb{Z}$$ Now let $p$ be a prime that does not divide $c$. Then, there are $x_1,...,x_n\in\Bbb{Z}$ such that $$\dfrac{1}{p}=\dfrac{d_1a_1x_1+...+d_na_nx_n}{c}$$ and hence $p(d_1a_1x_1+...+d_na_nx_n)=c$, which means that $p$ divides $c$, contradiction. That was suspiciously easy. What am I missing?",,"['abstract-algebra', 'proof-verification', 'modules', 'abelian-groups']"
25,Adjoint Functor Theorem,Adjoint Functor Theorem,,"The Freyd's Adjoint Theorem states that given a complete locally small category $\mathcal{C}$, a continuous functor $G: \mathcal{C} \to \mathcal{D}$ has a left adjoint if and only if it satisfies a certain condition (which is called a Solution Set Condition in Maclane's book), which is equivalent, under our assumptions, to say that for each $X \in \mathcal{D}$ the category $(X \downarrow G)$ has an initial object. This theorem seems to be central in classical Category Theory, since it allow us to show the existence of a left adjoint for $G$ by checking the given Solution Set Condition. However, this condition seems to be difficult to check, except in some easy cases. Question 1. Is there any fundamental result in which Freyd's Adjoint Theorem plays a crucial role to show the existence of a left adjoint? Question 2 . It is frequently asked (in Maclane's book) to construct a left adjoint functor in some special cases, using Freyd's Adjoint Theorem. However, except these special cases, I do not see how this result allows the explicit construction a left adjoint.","The Freyd's Adjoint Theorem states that given a complete locally small category $\mathcal{C}$, a continuous functor $G: \mathcal{C} \to \mathcal{D}$ has a left adjoint if and only if it satisfies a certain condition (which is called a Solution Set Condition in Maclane's book), which is equivalent, under our assumptions, to say that for each $X \in \mathcal{D}$ the category $(X \downarrow G)$ has an initial object. This theorem seems to be central in classical Category Theory, since it allow us to show the existence of a left adjoint for $G$ by checking the given Solution Set Condition. However, this condition seems to be difficult to check, except in some easy cases. Question 1. Is there any fundamental result in which Freyd's Adjoint Theorem plays a crucial role to show the existence of a left adjoint? Question 2 . It is frequently asked (in Maclane's book) to construct a left adjoint functor in some special cases, using Freyd's Adjoint Theorem. However, except these special cases, I do not see how this result allows the explicit construction a left adjoint.",,"['abstract-algebra', 'category-theory', 'adjoint-functors']"
26,Extensions of degree two are Galois Extensions.,Extensions of degree two are Galois Extensions.,,"This question from Allan Clark's ""Elements of Abstract Algebra"" Show that an extension of degree 2 is Galois except possibly when the characteristic is 2. What is the case when the characteristic is 2? Tips are helpful, a solution is ideal. Thanks.","This question from Allan Clark's ""Elements of Abstract Algebra"" Show that an extension of degree 2 is Galois except possibly when the characteristic is 2. What is the case when the characteristic is 2? Tips are helpful, a solution is ideal. Thanks.",,"['abstract-algebra', 'field-theory', 'galois-theory', 'extension-field']"
27,Is it actually incorrect to say $x/1 = x$?,Is it actually incorrect to say ?,x/1 = x,"The rational numbers $\mathbb{Q}$ are defined as the field of quotients of $\mathbb{Z}$ under the relation $(a, b) \sim (c , d) \iff$ $ad = bc$.  There is an obvious isomorphism between the subring $\{[(a, 1)] : a \in \mathbb{Z}$} and $\mathbb{Z}$ .   So technically we only pair every integer $a$ with $[(a, 1)]$.  They're not equal though.  Am I just making a big deal out of nothing?","The rational numbers $\mathbb{Q}$ are defined as the field of quotients of $\mathbb{Z}$ under the relation $(a, b) \sim (c , d) \iff$ $ad = bc$.  There is an obvious isomorphism between the subring $\{[(a, 1)] : a \in \mathbb{Z}$} and $\mathbb{Z}$ .   So technically we only pair every integer $a$ with $[(a, 1)]$.  They're not equal though.  Am I just making a big deal out of nothing?",,"['abstract-algebra', 'field-theory']"
28,Sums and products of algebraic numbers,Sums and products of algebraic numbers,,"How does one go about proving that the sums and products of two algebraic numbers over a field $F$ (say $a,b\in K$, where $K/F$ is a field extension) is also algebraic? If we call $f_a$ and $f_b$ the min. poly's of $a$ and $b$, then I'm assuming the answer involves such polynomials. Perhaps looking at their roots in splitting fields for both of them? And finding a ""big"" splitting field, constructed from those two other ones? In particular, I'd like a way of explicitly constructing the minimal polynomials $\ f_{ab}$ of $ab$ and $f_{a+b}$ of $a+b$. I read somewhere that $g(x)=\Pi_j\Pi_i (x-\alpha_i\beta_j)$ works for $ab$, where the $\alpha_i$ and $\beta_j$ are the roots of $f_a$ and $f_b$, respectively, but I do not know why $g(x)\in F[x]$.  Similar remarks for $a+b$","How does one go about proving that the sums and products of two algebraic numbers over a field $F$ (say $a,b\in K$, where $K/F$ is a field extension) is also algebraic? If we call $f_a$ and $f_b$ the min. poly's of $a$ and $b$, then I'm assuming the answer involves such polynomials. Perhaps looking at their roots in splitting fields for both of them? And finding a ""big"" splitting field, constructed from those two other ones? In particular, I'd like a way of explicitly constructing the minimal polynomials $\ f_{ab}$ of $ab$ and $f_{a+b}$ of $a+b$. I read somewhere that $g(x)=\Pi_j\Pi_i (x-\alpha_i\beta_j)$ works for $ab$, where the $\alpha_i$ and $\beta_j$ are the roots of $f_a$ and $f_b$, respectively, but I do not know why $g(x)\in F[x]$.  Similar remarks for $a+b$",,"['abstract-algebra', 'field-theory', 'minimal-polynomials']"
29,A reference for ring examples,A reference for ring examples,,"I'm currently reading ""Introduction to Ring Theory"" by Paul Cohn https://www.amazon.com/Introduction-Theory-Springer-Undergraduate-Mathematics/dp/1852332069/ref=sr_1_3?ie=UTF8&qid=1517544148&sr=8-3&keywords=cohn+ring As I'm working through it, I'm realizing I'm really deficient in having examples of various properties at the ready, and it makes it hard to establish a mental picture of what's happening as I read - for instance, a theorem may have the hypotheses ""Let $R$ be a simple ring"" or ""Let $R$ be an Artinian ring"" - and I have difficulty conjuring examples to use as I try to understand what the theorem is saying. This is especially difficult because most of the rings that come to mind are fields or at least commutative, and these cases tend to trivialize many of the theorems in the book. How does one start building up a collection of rings with various properties to use as examples when those properties are invoked? Are there references that exist for this already? EDIT: I've decided to include some of my background - I'm an undergraduate student (nearly graduated) in math, with a relatively heavy algebra background - I've taken 4 semesters of algebra classes, two of which were at the graduate level. I'm familiar with introductory modern algebra, I'm just lacking in the ""canonical example of structure X with property P"" department.","I'm currently reading ""Introduction to Ring Theory"" by Paul Cohn https://www.amazon.com/Introduction-Theory-Springer-Undergraduate-Mathematics/dp/1852332069/ref=sr_1_3?ie=UTF8&qid=1517544148&sr=8-3&keywords=cohn+ring As I'm working through it, I'm realizing I'm really deficient in having examples of various properties at the ready, and it makes it hard to establish a mental picture of what's happening as I read - for instance, a theorem may have the hypotheses ""Let $R$ be a simple ring"" or ""Let $R$ be an Artinian ring"" - and I have difficulty conjuring examples to use as I try to understand what the theorem is saying. This is especially difficult because most of the rings that come to mind are fields or at least commutative, and these cases tend to trivialize many of the theorems in the book. How does one start building up a collection of rings with various properties to use as examples when those properties are invoked? Are there references that exist for this already? EDIT: I've decided to include some of my background - I'm an undergraduate student (nearly graduated) in math, with a relatively heavy algebra background - I've taken 4 semesters of algebra classes, two of which were at the graduate level. I'm familiar with introductory modern algebra, I'm just lacking in the ""canonical example of structure X with property P"" department.",,"['abstract-algebra', 'reference-request', 'ring-theory', 'examples-counterexamples']"
30,Lifting idempotents modulo a nilpotent ideal,Lifting idempotents modulo a nilpotent ideal,,"The problem is this: Suppose $I \subseteq R$ is a nilpotent ideal and there is $r \in R$ with $r \equiv r^2 \pmod I$. Show $r \equiv e \pmod I$ for some $e \in R$ idempotent. I have spent a few hours rolling around in abstracta with no destination. I believe that if I could write down a concrete example of this, the example could guide me through the abstract definitions and show me where to look for an idempotent in $R$. I have looked at 2x2 matrices and could not find any such examples. Might anybody have one?","The problem is this: Suppose $I \subseteq R$ is a nilpotent ideal and there is $r \in R$ with $r \equiv r^2 \pmod I$. Show $r \equiv e \pmod I$ for some $e \in R$ idempotent. I have spent a few hours rolling around in abstracta with no destination. I believe that if I could write down a concrete example of this, the example could guide me through the abstract definitions and show me where to look for an idempotent in $R$. I have looked at 2x2 matrices and could not find any such examples. Might anybody have one?",,"['abstract-algebra', 'ring-theory']"
31,Why should I consider the components $j^2$ and $k^2$ to be $=-1$ in the search for quaternions?,Why should I consider the components  and  to be  in the search for quaternions?,j^2 k^2 =-1,"I'm reading a paper about Hamilton's discovery of quaternions and it explains why he failed in his 'theory of triplets' where he tried to make a vector with $3$ -dimensions, as an analogy to the complex field , where we can see a number as a $2$ -dimensional vector. In this paper, he explains why it is impossible to create a field with $3$ components, that is an extension of the complex field (in other words, it respects addition, and multiplication in the same way...). Here it is As you can see, it goes through all the possibilities and proves that it is impossible. The paper, however, does not explain why $j^2=-1$ . It could be anything! Why $-1$ ?** The article itself is pretty intuitive, but this aspect kills me. Later, in the article, it says that we should instead consider a 4th component called $k$ , such that $k^2=-1$ (also, $i$ and $j$ too). Here is the paper. EDIT : This paper by Rupert Shuttleworth turned out to be extremely helpful (mirrored here on archive.org)","I'm reading a paper about Hamilton's discovery of quaternions and it explains why he failed in his 'theory of triplets' where he tried to make a vector with -dimensions, as an analogy to the complex field , where we can see a number as a -dimensional vector. In this paper, he explains why it is impossible to create a field with components, that is an extension of the complex field (in other words, it respects addition, and multiplication in the same way...). Here it is As you can see, it goes through all the possibilities and proves that it is impossible. The paper, however, does not explain why . It could be anything! Why ?** The article itself is pretty intuitive, but this aspect kills me. Later, in the article, it says that we should instead consider a 4th component called , such that (also, and too). Here is the paper. EDIT : This paper by Rupert Shuttleworth turned out to be extremely helpful (mirrored here on archive.org)",3 2 3 j^2=-1 -1 k k^2=-1 i j,"['abstract-algebra', 'group-theory', 'field-theory', 'quaternions']"
32,Can we rediscover the category of finite (abelian) groups from its morphisms?,Can we rediscover the category of finite (abelian) groups from its morphisms?,,"It was a question on stackexchange approximately a month ago if in the category $(grp)^{fin}$ $|Hom(H,G_1)|= |Hom(H,G_2)|$ for all $H \Rightarrow G_1 \cong G_2$. Link to the previous question. So lately I thought a bit about quite a related question. Assume we are given the category of finite groups (or easier case: finite abelian groups), but with the names of all objects covered (i.e. we don't know which object is which). Can we rediscover the objects by knowing a) only the cardinality of all the $Hom$-Sets associated to the objects b) the categorical structure (i.e. we know the $Hom$-Sets and how morphisms compose with each other) In the Situation b) (which is of course more difficult than a) ), I am quite optimistic this is possible at least for abelian finite groups (something like let $A$ be such that there are no epis $A \rightarrow B$ for $0 \neq B \neq A$, then $A$ is cyclic of prime order. But then $A= \mathbb{Z}/(|Hom(A,A)|)\mathbb{Z}$. Now by induction we should be able to rediscover higher order cyclic groups and as we know the categorial structure, we should also know coproducts) However, the case that is closer to the link above is situation a) and I have absolutely no idea whether this could be possible or not. (For example we can obviously rediscover $0$ and $\mathbb{Z}/2\mathbb{Z}$, but I don't see how to move on) Maybe I should also note that of course the situation is quite different than in the original question: now we know a lot ""more"" $Hom$-sets, but we don't a priori know which objects they arise from. Any input is welcome.","It was a question on stackexchange approximately a month ago if in the category $(grp)^{fin}$ $|Hom(H,G_1)|= |Hom(H,G_2)|$ for all $H \Rightarrow G_1 \cong G_2$. Link to the previous question. So lately I thought a bit about quite a related question. Assume we are given the category of finite groups (or easier case: finite abelian groups), but with the names of all objects covered (i.e. we don't know which object is which). Can we rediscover the objects by knowing a) only the cardinality of all the $Hom$-Sets associated to the objects b) the categorical structure (i.e. we know the $Hom$-Sets and how morphisms compose with each other) In the Situation b) (which is of course more difficult than a) ), I am quite optimistic this is possible at least for abelian finite groups (something like let $A$ be such that there are no epis $A \rightarrow B$ for $0 \neq B \neq A$, then $A$ is cyclic of prime order. But then $A= \mathbb{Z}/(|Hom(A,A)|)\mathbb{Z}$. Now by induction we should be able to rediscover higher order cyclic groups and as we know the categorial structure, we should also know coproducts) However, the case that is closer to the link above is situation a) and I have absolutely no idea whether this could be possible or not. (For example we can obviously rediscover $0$ and $\mathbb{Z}/2\mathbb{Z}$, but I don't see how to move on) Maybe I should also note that of course the situation is quite different than in the original question: now we know a lot ""more"" $Hom$-sets, but we don't a priori know which objects they arise from. Any input is welcome.",,"['abstract-algebra', 'group-theory', 'category-theory']"
33,What's the meaning of $\succ$ operator?,What's the meaning of  operator?,\succ,"What is the meaning of $\succ $ symbol? I have an snippet which includes this operator: (Article is about choice theory) ""a complete and transitive preference $\succ$ over X"" (Maybe very preliminary question but interestingly there is no explanation in the internet about this symbol) Note that $\succ$ is Unicode character U+227B .","What is the meaning of symbol? I have an snippet which includes this operator: (Article is about choice theory) ""a complete and transitive preference over X"" (Maybe very preliminary question but interestingly there is no explanation in the internet about this symbol) Note that is Unicode character U+227B .",\succ  \succ \succ,"['abstract-algebra', 'notation', 'order-theory']"
34,"If $p$ is an odd prime, does every Sylow $p$-subgroup contain an element not in any other Sylow $p$-subgroup?","If  is an odd prime, does every Sylow -subgroup contain an element not in any other Sylow -subgroup?",p p p,"Suppose that $p$ is an odd prime. Does every Sylow $p$-subgroup of a finite group contain an element that is not contained in any other Sylow $p$-subgroup? Or does there exist a group $G$ with Sylow $p$-subgroups $P, P_1, \ldots, P_s$ such that $P$ is contained in $P_1 \cup \ldots \cup P_s$? One immediate observation here is that if a Sylow $p$-subgroup contains an element that is not contained in any other Sylow $p$-subgroup, then the same is true for every other Sylow $p$-subgroup since they are conjugate. Hence we only need to check the statement for one Sylow $p$-subgroup. I've tried different approaches to this problem but I don't think I have found out anything useful so far. Some special cases where the statement is true is when there are $\leq p + 1$ Sylow $p$-subgroups, or when the Sylow $p$-subgroups are cyclic. The reason I am assuming that $p$ is odd because there are counterexamples when $p = 2$. One example is given by $\operatorname{PSL}(2,11)$, where every element of a Sylow $2$-subgroup is contained in at least two Sylow $2$-subgroups. Plenty of more examples can be found with GAP, the smallest example seems to be of order $108$. I have checked all groups of order $\leq 1000$ except for those of orders $576$ and $864$. All the examples I've found so far are given by $2$-sylow subgroups.","Suppose that $p$ is an odd prime. Does every Sylow $p$-subgroup of a finite group contain an element that is not contained in any other Sylow $p$-subgroup? Or does there exist a group $G$ with Sylow $p$-subgroups $P, P_1, \ldots, P_s$ such that $P$ is contained in $P_1 \cup \ldots \cup P_s$? One immediate observation here is that if a Sylow $p$-subgroup contains an element that is not contained in any other Sylow $p$-subgroup, then the same is true for every other Sylow $p$-subgroup since they are conjugate. Hence we only need to check the statement for one Sylow $p$-subgroup. I've tried different approaches to this problem but I don't think I have found out anything useful so far. Some special cases where the statement is true is when there are $\leq p + 1$ Sylow $p$-subgroups, or when the Sylow $p$-subgroups are cyclic. The reason I am assuming that $p$ is odd because there are counterexamples when $p = 2$. One example is given by $\operatorname{PSL}(2,11)$, where every element of a Sylow $2$-subgroup is contained in at least two Sylow $2$-subgroups. Plenty of more examples can be found with GAP, the smallest example seems to be of order $108$. I have checked all groups of order $\leq 1000$ except for those of orders $576$ and $864$. All the examples I've found so far are given by $2$-sylow subgroups.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
35,"If $I+J=R$, where $R$ is a commutative rng, prove that $IJ=I\cap J$.","If , where  is a commutative rng, prove that .",I+J=R R IJ=I\cap J,"So I basically have to prove what is on the title. Given $R$ a commutative rng (a ring that might not contain a $1$ ), with the property that $I+J=R$ , (where $I$ and $J$ are ideals) we have to prove that $IJ=I\cap J$ . One inclusion is easy. If $x\in IJ$ , then $x=\sum a_ib_i$ where $a_i\in I$ and $b_i\in J$ . Thus for any fixed $i$ , we have that since $a_i\in I$ , we have that $a_ib_i\in I$ , and the same argument shows that $a_ib_i\in J$ , thus $\sum a_ib_i\in I$ and $\sum a_ib_i\in J$ , this means that $x=\sum a_ib_i\in I\cap J$ , and thus $IJ\subset I\cap J$ . I am having troubles proving the other inclusion. Any comments? Thanks","So I basically have to prove what is on the title. Given a commutative rng (a ring that might not contain a ), with the property that , (where and are ideals) we have to prove that . One inclusion is easy. If , then where and . Thus for any fixed , we have that since , we have that , and the same argument shows that , thus and , this means that , and thus . I am having troubles proving the other inclusion. Any comments? Thanks",R 1 I+J=R I J IJ=I\cap J x\in IJ x=\sum a_ib_i a_i\in I b_i\in J i a_i\in I a_ib_i\in I a_ib_i\in J \sum a_ib_i\in I \sum a_ib_i\in J x=\sum a_ib_i\in I\cap J IJ\subset I\cap J,"['abstract-algebra', 'ideals', 'rngs']"
36,Order of some quotient ring of Gaussian integers [duplicate],Order of some quotient ring of Gaussian integers [duplicate],,"This question already has answers here : Quotient ring of Gaussian integers (7 answers) Closed 11 years ago . I'm trying to get through a proof of Gauss' that certain primes can be written as the sum of two squares. An assumption is that the order of $\mathbb{Z}[i]/(a+bi)$ is $a^2+b^2$. I get that $(a+bi)(a-bi)=a^2+b^2$, so this places a bound on the order of integers with no imaginary part. But since $b$ isn't a unit, it doesn't seem like this finishes the proof. Any hints?","This question already has answers here : Quotient ring of Gaussian integers (7 answers) Closed 11 years ago . I'm trying to get through a proof of Gauss' that certain primes can be written as the sum of two squares. An assumption is that the order of $\mathbb{Z}[i]/(a+bi)$ is $a^2+b^2$. I get that $(a+bi)(a-bi)=a^2+b^2$, so this places a bound on the order of integers with no imaginary part. But since $b$ isn't a unit, it doesn't seem like this finishes the proof. Any hints?",,"['abstract-algebra', 'ring-theory']"
37,What's the automorphism group of the real and complex numbers and the quaternions?,What's the automorphism group of the real and complex numbers and the quaternions?,,"According to Wikipedia the automorphism group of the octonions is the exceptional group $G_2$. Are there analogous groups for the real numbers, the complex numbers and the quaternions?","According to Wikipedia the automorphism group of the octonions is the exceptional group $G_2$. Are there analogous groups for the real numbers, the complex numbers and the quaternions?",,"['abstract-algebra', 'group-theory']"
38,How to find the degree of a field extension,How to find the degree of a field extension,,"I don't quite understand how to find the degree of a field extension. First, what does the notation [R:K] mean exactly? If I had, for example, to find the degree of $\mathbb Q (\sqrt7)$ over $\mathbb Q$, how would I go about it? And how would it be different from, say, $\mathbb C (\sqrt7)$ over $\mathbb C$? Would it involve finding the minimal polynomial? In the case of $\mathbb Q (\sqrt7)$, I find the minimal polynomial to be $x^2-7$ which is of degree 2, so would this be the value of $[\mathbb Q (\sqrt7):\mathbb Q]$? In $\mathbb C $, this polynomial is reducible, so I assume somehow it would need to be reduced to find the minimal polynomial. (I am guessing since $x^2-7=(x^2+1)-8=i-8$ this is the polynomial in $\mathbb C$) Would the degree of this be the degree of$[\mathbb C (\sqrt7):\mathbb C]$?","I don't quite understand how to find the degree of a field extension. First, what does the notation [R:K] mean exactly? If I had, for example, to find the degree of $\mathbb Q (\sqrt7)$ over $\mathbb Q$, how would I go about it? And how would it be different from, say, $\mathbb C (\sqrt7)$ over $\mathbb C$? Would it involve finding the minimal polynomial? In the case of $\mathbb Q (\sqrt7)$, I find the minimal polynomial to be $x^2-7$ which is of degree 2, so would this be the value of $[\mathbb Q (\sqrt7):\mathbb Q]$? In $\mathbb C $, this polynomial is reducible, so I assume somehow it would need to be reduced to find the minimal polynomial. (I am guessing since $x^2-7=(x^2+1)-8=i-8$ this is the polynomial in $\mathbb C$) Would the degree of this be the degree of$[\mathbb C (\sqrt7):\mathbb C]$?",,"['abstract-algebra', 'field-theory', 'definition', 'extension-field']"
39,Abstract algebra book with real life applications,Abstract algebra book with real life applications,,"Is there an abstract algebra book that emphasizes the applications to ""real world"" problems? Update: By real world, I mean mostly related to physics or other sciences. But references to coding theory or cryptography are also welcome.","Is there an abstract algebra book that emphasizes the applications to ""real world"" problems? Update: By real world, I mean mostly related to physics or other sciences. But references to coding theory or cryptography are also welcome.",,"['abstract-algebra', 'reference-request', 'soft-question', 'big-list', 'applications']"
40,Localization does not commute canonically with infinite direct products,Localization does not commute canonically with infinite direct products,,"Let $S=\mathbb{Z}-\{0\}$. Show the existence or nonexistence of isomorphism between $S^{-1}\prod_{1}^{\infty}\mathbb{Z}_{i}$ and $\prod_{1}^{\infty}\mathbb{Q}_{i}$ as $\mathbb{Q}$-vector spaces. (Here $\mathbb Z_i=\mathbb Z$ and $\mathbb Q_i=\mathbb Q$ for all $i\ge 1$.) This is an example used to show that the localization does not commute with infinite products under the natural (canonical) homomorphism . I read this from a lecture note by Ravi Vakil. I think we still need to show these two are really not isomorphic as $\mathbb{Q}$-vector spaces. I tried to follow the hint to consider the element $(1,\frac{1}{2},\frac{1}{3},...,\frac{1}{n},...)$ but failed. To user26857: I want a proof of the existence or nonexistence of isomorphism between these two vector spaces. If I get it right, your solution reduced the problem to the existence of basis of these two vector spaces. And in your sense, a basis  is a subset $B$ (of the vector space $V$) such that every finite subset of $B$ is a linearly independent set and any vector in $V$ can be expressed as a finite sum of the elements in $B$. If this is what you mean, can you show the existence of such basis? Thank you! To Ragib Zaman: Your example is a better one. Thanks!","Let $S=\mathbb{Z}-\{0\}$. Show the existence or nonexistence of isomorphism between $S^{-1}\prod_{1}^{\infty}\mathbb{Z}_{i}$ and $\prod_{1}^{\infty}\mathbb{Q}_{i}$ as $\mathbb{Q}$-vector spaces. (Here $\mathbb Z_i=\mathbb Z$ and $\mathbb Q_i=\mathbb Q$ for all $i\ge 1$.) This is an example used to show that the localization does not commute with infinite products under the natural (canonical) homomorphism . I read this from a lecture note by Ravi Vakil. I think we still need to show these two are really not isomorphic as $\mathbb{Q}$-vector spaces. I tried to follow the hint to consider the element $(1,\frac{1}{2},\frac{1}{3},...,\frac{1}{n},...)$ but failed. To user26857: I want a proof of the existence or nonexistence of isomorphism between these two vector spaces. If I get it right, your solution reduced the problem to the existence of basis of these two vector spaces. And in your sense, a basis  is a subset $B$ (of the vector space $V$) such that every finite subset of $B$ is a linearly independent set and any vector in $V$ can be expressed as a finite sum of the elements in $B$. If this is what you mean, can you show the existence of such basis? Thank you! To Ragib Zaman: Your example is a better one. Thanks!",,"['abstract-algebra', 'commutative-algebra', 'vector-spaces']"
41,The Maximum possible order for an element $S_n$ [duplicate],The Maximum possible order for an element  [duplicate],S_n,"This question already has answers here : Maximal order of an element in a symmetric group (3 answers) Closed 6 years ago . Given the following groups, what is the maximum possible order for an element for (a) $S_5$ (b) $S_6$ (c) $S_7$ (d) $S_{10}$ (e) $S_{15}$ My book justifies the answer as (a) The greatest order is $6$ and comes from a product of disjoint cycles of length 2 and 3 (b) The greatest order is $6$ and comes from a cycle of length $6$ The other answers were justified exactly the same way, that is (c) 12, (d) 30, (e) 105 I do not understand how in (a) we even got the number ""6"" from $S_5$ and what disjoint cycles they are referring to. Could someone at least justify one for me?","This question already has answers here : Maximal order of an element in a symmetric group (3 answers) Closed 6 years ago . Given the following groups, what is the maximum possible order for an element for (a) $S_5$ (b) $S_6$ (c) $S_7$ (d) $S_{10}$ (e) $S_{15}$ My book justifies the answer as (a) The greatest order is $6$ and comes from a product of disjoint cycles of length 2 and 3 (b) The greatest order is $6$ and comes from a cycle of length $6$ The other answers were justified exactly the same way, that is (c) 12, (d) 30, (e) 105 I do not understand how in (a) we even got the number ""6"" from $S_5$ and what disjoint cycles they are referring to. Could someone at least justify one for me?",,['abstract-algebra']
42,"Is this ""coincidence"" about representations of the Monster actually a coincidence?","Is this ""coincidence"" about representations of the Monster actually a coincidence?",,"I know that the Monster simple group's lowest dimension faithful representation (which is in characteristic $2$ ) has dimension $196882$ and that its lowest dimension faithful representation in characteristic $0$ has dimension $196883$ . Is there any simple explanation for the fact the dimension of the lowest dimension faithful representation has dimension one less than lowest dimension faithful representation in characteristic $0$ ? Are these reasons also valid for other simple groups, like $A_5$ and the Baby Monster groups? Are there representations of dimension $196882$ in other characteristics?","I know that the Monster simple group's lowest dimension faithful representation (which is in characteristic ) has dimension and that its lowest dimension faithful representation in characteristic has dimension . Is there any simple explanation for the fact the dimension of the lowest dimension faithful representation has dimension one less than lowest dimension faithful representation in characteristic ? Are these reasons also valid for other simple groups, like and the Baby Monster groups? Are there representations of dimension in other characteristics?",2 196882 0 196883 0 A_5 196882,"['abstract-algebra', 'group-theory', 'soft-question', 'simple-groups', 'sporadic-groups']"
43,Looking for a Better Way to Think About Polynomial Rings,Looking for a Better Way to Think About Polynomial Rings,,"Given a commutative ring $R$, the polynomial ring in one variable $R[x]$ can be defined as the set of all the formal expressions $a_0+a_1x+\cdots+a_nx^n$ with 'obvious' rules of addition and multiplication. What exactly do we mean by a 'variable' here is not very clear though. My main question is the following: Qustion 1. Does it mean anything to say that $ax=xa$ in $R[x]$ for all $a\in R$? When we talk about multivariable polynomial rings, this approach becomes cumbersome. Even when talking about $R[x, y]$, the multilpication seems rather artificial. Further, we also have an isomorphism $R[x][y]\cong R[x, y]$. This is making me a bit uncomfortable: Question 2. In $R[x][y]$, it seems a bit odd to write $xy=yx$ (See Question 1) but we do certainly want to write this. I know these questions are rather vague. So finally I can ask this: Is there a better way to think about polynomial rings? Also, can we intrinsically define what a variable is? Thanks.","Given a commutative ring $R$, the polynomial ring in one variable $R[x]$ can be defined as the set of all the formal expressions $a_0+a_1x+\cdots+a_nx^n$ with 'obvious' rules of addition and multiplication. What exactly do we mean by a 'variable' here is not very clear though. My main question is the following: Qustion 1. Does it mean anything to say that $ax=xa$ in $R[x]$ for all $a\in R$? When we talk about multivariable polynomial rings, this approach becomes cumbersome. Even when talking about $R[x, y]$, the multilpication seems rather artificial. Further, we also have an isomorphism $R[x][y]\cong R[x, y]$. This is making me a bit uncomfortable: Question 2. In $R[x][y]$, it seems a bit odd to write $xy=yx$ (See Question 1) but we do certainly want to write this. I know these questions are rather vague. So finally I can ask this: Is there a better way to think about polynomial rings? Also, can we intrinsically define what a variable is? Thanks.",,"['abstract-algebra', 'polynomials', 'ring-theory']"
44,How do I show a mapping is a homomorphism?,How do I show a mapping is a homomorphism?,,"I don't want to make this question too broad, or non-specific.  I'll will discuss a simple situation so we can all share a common context, but my question is less about this particular group, and more about the strategy of showing that a particular mapping you're interested in is a valid homomorphism. Let $G$ be a group, and let a non-identity $(\ne 1)$ element $a \in G$ be such that $a^2=1$.  Then $K:=\left\{ 1, a \right\} \lt G$.  I don't see right away that $K \lhd G$, so I want to find a homomorphism with kernel $K$. If we were to show that $K$ is normal, we would need $gK = Kg$ $\forall g \in G$, but since $g1 = 1g$, this would imply we need $ga = ag$ $\forall g \in G$.  (I point this out because I'll refer back to it later.  I'm willing to hear arguments about $K$ being normal, but that's not the point of this question.) Defining a mapping $\phi:G \rightarrow G$ such that $\phi(a)=1$ (and necessarily $\phi(1) = 1$) would certainly put $a$ in the kernel if $\phi$ is indeed a homomorphism as we'd like.  But how would I clearly show that this is a homomorphism, with exactly $K$ as its kernel?  Surely I can't just note that $\phi(ag) = \phi(a)\phi(g) = \phi(g) = \phi(g)\phi(a)=\phi(ga)$.  This would depend on $\phi$ being a homomorphism, and would be an example of assuming the conclusion.  If $\phi$ were a homomorphism and well defined, this would show ... well, I guess it would not show that $ag = ga$, but it would show that $ag$ and $ga$ are both members of the same equivalence class in the quotient group formed by modding $K$ out of $G$. I freely admit that my background is strong in analysis and weak in algebra.  When I watch an algebraist at work, everything looks quick and simple and leaves the impression that I'm watching magic, as if we could prove anything we want to, which clearly isn't so. So I suppose my clear, narrowly focussed question is this: What is the list of criteria that one must show to prove that a particular mapping is a well defined homomorphism, and as an example how would they be used to show that this is (or is not) a homomorphism?","I don't want to make this question too broad, or non-specific.  I'll will discuss a simple situation so we can all share a common context, but my question is less about this particular group, and more about the strategy of showing that a particular mapping you're interested in is a valid homomorphism. Let $G$ be a group, and let a non-identity $(\ne 1)$ element $a \in G$ be such that $a^2=1$.  Then $K:=\left\{ 1, a \right\} \lt G$.  I don't see right away that $K \lhd G$, so I want to find a homomorphism with kernel $K$. If we were to show that $K$ is normal, we would need $gK = Kg$ $\forall g \in G$, but since $g1 = 1g$, this would imply we need $ga = ag$ $\forall g \in G$.  (I point this out because I'll refer back to it later.  I'm willing to hear arguments about $K$ being normal, but that's not the point of this question.) Defining a mapping $\phi:G \rightarrow G$ such that $\phi(a)=1$ (and necessarily $\phi(1) = 1$) would certainly put $a$ in the kernel if $\phi$ is indeed a homomorphism as we'd like.  But how would I clearly show that this is a homomorphism, with exactly $K$ as its kernel?  Surely I can't just note that $\phi(ag) = \phi(a)\phi(g) = \phi(g) = \phi(g)\phi(a)=\phi(ga)$.  This would depend on $\phi$ being a homomorphism, and would be an example of assuming the conclusion.  If $\phi$ were a homomorphism and well defined, this would show ... well, I guess it would not show that $ag = ga$, but it would show that $ag$ and $ga$ are both members of the same equivalence class in the quotient group formed by modding $K$ out of $G$. I freely admit that my background is strong in analysis and weak in algebra.  When I watch an algebraist at work, everything looks quick and simple and leaves the impression that I'm watching magic, as if we could prove anything we want to, which clearly isn't so. So I suppose my clear, narrowly focussed question is this: What is the list of criteria that one must show to prove that a particular mapping is a well defined homomorphism, and as an example how would they be used to show that this is (or is not) a homomorphism?",,"['group-theory', 'abstract-algebra', 'normal-subgroups']"
45,"Difference between ""space"" and ""algebraic structure""","Difference between ""space"" and ""algebraic structure""",,"What is the difference between a ""space"" and an ""algebraic structure""? For example, metric spaces and vector spaces are both spaces and algebraic structures. Is a group a space? Is a manifold a space or an algebraic structure, both or neither?","What is the difference between a ""space"" and an ""algebraic structure""? For example, metric spaces and vector spaces are both spaces and algebraic structures. Is a group a space? Is a manifold a space or an algebraic structure, both or neither?",,"['abstract-algebra', 'terminology']"
46,Derivations of Polynomial Algebra,Derivations of Polynomial Algebra,,"Let $A=\mathbb{F}_p[x,y]$, the commutative polynomial algebra on two variables over the finite field $\mathbb{F}_p$. Define a derivation on an algebra as a map which satisfies the Leibniz rule, ie if $d$ is a derivation then $$d(ab)=ad(b)+bd(a)$$ Let $Der(A)$ be the $\mathbb{F}_p$-module (algebra?) of derivations of $A$. I'm interested in  knowing what $Der(A)$ is. First of all, I'm not sure exactly how complicated the algebraic structure it carries is. I know that it's at least a $\mathbb{F}_p$-module. But is it an algebra? I suspect no, but I can't nail down a reason why. Is it a module over a bigger ring? $\mathbb{F}_p[x,y]$ seems like it might be a good choice- but again, I'm not very sure of this. Finally, what's an explicit description of elements of $Der(A)$? Is it just linear combinations of $\frac{d}{dx}$ and $\frac{d}{dy}$? I apologize if this is a bit overly broad, but I'm encountering derivations over finite fields for the first time, and I'd like to really understand what's going on.","Let $A=\mathbb{F}_p[x,y]$, the commutative polynomial algebra on two variables over the finite field $\mathbb{F}_p$. Define a derivation on an algebra as a map which satisfies the Leibniz rule, ie if $d$ is a derivation then $$d(ab)=ad(b)+bd(a)$$ Let $Der(A)$ be the $\mathbb{F}_p$-module (algebra?) of derivations of $A$. I'm interested in  knowing what $Der(A)$ is. First of all, I'm not sure exactly how complicated the algebraic structure it carries is. I know that it's at least a $\mathbb{F}_p$-module. But is it an algebra? I suspect no, but I can't nail down a reason why. Is it a module over a bigger ring? $\mathbb{F}_p[x,y]$ seems like it might be a good choice- but again, I'm not very sure of this. Finally, what's an explicit description of elements of $Der(A)$? Is it just linear combinations of $\frac{d}{dx}$ and $\frac{d}{dy}$? I apologize if this is a bit overly broad, but I'm encountering derivations over finite fields for the first time, and I'd like to really understand what's going on.",,"['abstract-algebra', 'finite-fields']"
47,Localization at a prime ideal is a reduced ring,Localization at a prime ideal is a reduced ring,,"Here is the question that I came up with, which I am having trouble proving or disproving: Let $A$ be a ring (commutative). Let $p \in Spec(A)$ such that $A_p$ is reduced. Then there exists an open neighborhood of $U \subset Spec(A)$ containing $p$ such that $\forall q \in U$, $A_q$ is reduced. Here is some background to my question: I am basically trying to prove that if the stalks at all closed points of a quasicompact scheme are reduced rings, then the scheme is reduced. Since the closure of every point of a quasicompact scheme contains a closed point of that scheme, proving the above commutative algebra statement (if it is true) will yield a proof of this statement about reducedness of quasicompact schemes. If the statement in bold is true, then I guess the neighborhood $Spec(A)-V(A-p)$ should suffice (this is just a guess), but I am running into some problems trying to use this neighborhood to show that the localization at every point of $Spec(A)-V(A-p)$ gives me a reduced ring. So there might be some other neighborhood of $p$ that I am missing, or the statement in bold is not true. Either way, some help would be appreciated (if the statement in bold is true, then I would appreciate hints and not complete answers).","Here is the question that I came up with, which I am having trouble proving or disproving: Let $A$ be a ring (commutative). Let $p \in Spec(A)$ such that $A_p$ is reduced. Then there exists an open neighborhood of $U \subset Spec(A)$ containing $p$ such that $\forall q \in U$, $A_q$ is reduced. Here is some background to my question: I am basically trying to prove that if the stalks at all closed points of a quasicompact scheme are reduced rings, then the scheme is reduced. Since the closure of every point of a quasicompact scheme contains a closed point of that scheme, proving the above commutative algebra statement (if it is true) will yield a proof of this statement about reducedness of quasicompact schemes. If the statement in bold is true, then I guess the neighborhood $Spec(A)-V(A-p)$ should suffice (this is just a guess), but I am running into some problems trying to use this neighborhood to show that the localization at every point of $Spec(A)-V(A-p)$ gives me a reduced ring. So there might be some other neighborhood of $p$ that I am missing, or the statement in bold is not true. Either way, some help would be appreciated (if the statement in bold is true, then I would appreciate hints and not complete answers).",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
48,Order of the Rubik's cube group,Order of the Rubik's cube group,,"Associated to the Rubik's cube is a group as described in this Wikipedia article : $G = \langle F, B, U, L, D, R\rangle$. For example, the element $F$ corresponds to rotating the front face clockwise by $90$ degrees. According to the article the order of the group is: $2^{27} 3^{14} 5^3 7^2 11$. I have come across several places (for example here ) where this order has been found by just counting various ways to arrange edges and such. Is there a nice way to compute the order by appealing to more ""group theoretic"" tools?","Associated to the Rubik's cube is a group as described in this Wikipedia article : $G = \langle F, B, U, L, D, R\rangle$. For example, the element $F$ corresponds to rotating the front face clockwise by $90$ degrees. According to the article the order of the group is: $2^{27} 3^{14} 5^3 7^2 11$. I have come across several places (for example here ) where this order has been found by just counting various ways to arrange edges and such. Is there a nice way to compute the order by appealing to more ""group theoretic"" tools?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'rubiks-cube']"
49,"What is $\operatorname{Hom}_\mathbb{Z}(\mathbb{Q}/\mathbb{Z},\mathbb{Q}/\mathbb{Z})$?",What is ?,"\operatorname{Hom}_\mathbb{Z}(\mathbb{Q}/\mathbb{Z},\mathbb{Q}/\mathbb{Z})","Is $\operatorname{Hom}_\mathbb{Z}(\mathbb{Q}/\mathbb{Z},\mathbb{Q}/\mathbb{Z})$ isomorphic to any ""known"" group? I suppose what I mean is, is it isomorphic to a group that isn't a Hom group? If such an isomorphism is known, is there a reference which sketches it out? I know $\mathbb{Q}/\mathbb{Z}=\bigoplus_p\mathbb{Z}_{p^\infty}$, but using the various properties to pull direct sums out doesn't seem fruitful. My motivation is that I know $\operatorname{Ext}^0_\mathbb{Z}(A,B)$ is naturally isomorphic to $\operatorname{Hom}_\mathbb{Z}(A,B)$, and pairs like $\operatorname{Hom}(\mathbb{Z},\mathbb{Z})$, $\operatorname{Hom}(\mathbb{Q},\mathbb{Q})$, etc.,  come up frequently in algebraic topology/basic examples in homological algebra. Since $\mathbb{Q}/\mathbb{Z}$ shows up commonly in topology, I'm curious about that case as well.","Is $\operatorname{Hom}_\mathbb{Z}(\mathbb{Q}/\mathbb{Z},\mathbb{Q}/\mathbb{Z})$ isomorphic to any ""known"" group? I suppose what I mean is, is it isomorphic to a group that isn't a Hom group? If such an isomorphism is known, is there a reference which sketches it out? I know $\mathbb{Q}/\mathbb{Z}=\bigoplus_p\mathbb{Z}_{p^\infty}$, but using the various properties to pull direct sums out doesn't seem fruitful. My motivation is that I know $\operatorname{Ext}^0_\mathbb{Z}(A,B)$ is naturally isomorphic to $\operatorname{Hom}_\mathbb{Z}(A,B)$, and pairs like $\operatorname{Hom}(\mathbb{Z},\mathbb{Z})$, $\operatorname{Hom}(\mathbb{Q},\mathbb{Q})$, etc.,  come up frequently in algebraic topology/basic examples in homological algebra. Since $\mathbb{Q}/\mathbb{Z}$ shows up commonly in topology, I'm curious about that case as well.",,"['abstract-algebra', 'reference-request', 'homological-algebra']"
50,On proving every ideal of $\mathbb{Z}_n$ is principal,On proving every ideal of  is principal,\mathbb{Z}_n,"I was working on a problem in Robert Ash's Abstract Algebra , and didn't follow part of the solution. The problem states Let $R$ be the ring of $\mathbb{Z}_n$ of integers modulo $n$, where $n$ may be prime or composite. Show that every ideal of $R$ is principal. His provided solutions goes as Since an ideal $I$ is a finite set in this case, it must have a finite set of generators $x_1,\ldots, x_k$. Let $d$ be the greatest common divisor of the $x_i$. Every element of $I$ is of the form $a_1x_1+\cdots+a_kx_k$, and hence a multiple of $d$. Thus $I\subseteq (d)$. But $d\in I$, because there are integers $a_i$ such that $\sum_{i=1}^k a_ix_i=d$. Consequently, $(d)\subseteq I$. Why is ""there are integers $a_i$ such that $\sum_i a_ix_i=d$ "" obvious? I don't see this automatically, and would appreciate an explanation. Also, does the proof using the division algorithm fall apart here? When solving it without looking at the answer, I said take $n$ to be the least congruence class in an ideal $I$, then for any $m\in I$, $m=qn+r$ for $0\leq r\lt n$, so $m-qn\in I$ as well, so $r\equiv 0$. So $I=(n)$. Does this not work, or did Ash just provide a different proof? Thank you.","I was working on a problem in Robert Ash's Abstract Algebra , and didn't follow part of the solution. The problem states Let $R$ be the ring of $\mathbb{Z}_n$ of integers modulo $n$, where $n$ may be prime or composite. Show that every ideal of $R$ is principal. His provided solutions goes as Since an ideal $I$ is a finite set in this case, it must have a finite set of generators $x_1,\ldots, x_k$. Let $d$ be the greatest common divisor of the $x_i$. Every element of $I$ is of the form $a_1x_1+\cdots+a_kx_k$, and hence a multiple of $d$. Thus $I\subseteq (d)$. But $d\in I$, because there are integers $a_i$ such that $\sum_{i=1}^k a_ix_i=d$. Consequently, $(d)\subseteq I$. Why is ""there are integers $a_i$ such that $\sum_i a_ix_i=d$ "" obvious? I don't see this automatically, and would appreciate an explanation. Also, does the proof using the division algorithm fall apart here? When solving it without looking at the answer, I said take $n$ to be the least congruence class in an ideal $I$, then for any $m\in I$, $m=qn+r$ for $0\leq r\lt n$, so $m-qn\in I$ as well, so $r\equiv 0$. So $I=(n)$. Does this not work, or did Ash just provide a different proof? Thank you.",,"['abstract-algebra', 'ideals']"
51,Explicit computation of a Galois group,Explicit computation of a Galois group,,"Let $E$ be the splitting field of $x^6-2$ over $\mathbb{Q}$. Show that $Gal(E/\mathbb{Q})\cong D_6$, the dihedral group of the regular hexagon. I've shown that $E=\mathbb{Q}(\zeta_6, \sqrt[6]{2})$, where $\zeta_6$ is a (fixed) primitive sixth root of unity, and thus that $[E:\mathbb{Q}]=12$. I'm getting a little mixed up working out the automorphisms, though. I know the Galois group is determined by the action on the generators $\zeta_6$ and $\sqrt[n]{2}$. So then the possibilities appear to be: \begin{align*}\sqrt[6]{2}&\mapsto\zeta_6^n\sqrt[6]{2}\;\;\;\mbox{ for } n=0,1,\ldots ,5 \\ \zeta_6&\mapsto \zeta_6^j\;\;\;\;\;\;\;\;\mbox{ for } j=1,5\,.\end{align*} Does this make sense? Something doesn't quite feel right, but I'm not sure where the issue might be. I know that in some sense the generators are ""independent"", because I definitely can't get one generator from the other. (For example, it'd be different if we had fourth roots of unity because we could get $\sqrt{2}$ from both generators.) Any help is appreciated","Let $E$ be the splitting field of $x^6-2$ over $\mathbb{Q}$. Show that $Gal(E/\mathbb{Q})\cong D_6$, the dihedral group of the regular hexagon. I've shown that $E=\mathbb{Q}(\zeta_6, \sqrt[6]{2})$, where $\zeta_6$ is a (fixed) primitive sixth root of unity, and thus that $[E:\mathbb{Q}]=12$. I'm getting a little mixed up working out the automorphisms, though. I know the Galois group is determined by the action on the generators $\zeta_6$ and $\sqrt[n]{2}$. So then the possibilities appear to be: \begin{align*}\sqrt[6]{2}&\mapsto\zeta_6^n\sqrt[6]{2}\;\;\;\mbox{ for } n=0,1,\ldots ,5 \\ \zeta_6&\mapsto \zeta_6^j\;\;\;\;\;\;\;\;\mbox{ for } j=1,5\,.\end{align*} Does this make sense? Something doesn't quite feel right, but I'm not sure where the issue might be. I know that in some sense the generators are ""independent"", because I definitely can't get one generator from the other. (For example, it'd be different if we had fourth roots of unity because we could get $\sqrt{2}$ from both generators.) Any help is appreciated",,"['abstract-algebra', 'galois-theory']"
52,Lawvere theories with two generic objects,Lawvere theories with two generic objects,,"What is the simplest example of a category with finite products and two objects $X,Y$ such that $X$ and $Y$ are not isomorphic, $X$ is isomorphic to $Y^n$ for some $n \in \mathbb{N}$ , $Y$ is isomorphic to $X^m$ for some $m \in \mathbb{N}$ ? This should demonstrate that the generic object of a Lawvere theory is not uniquely determined. Rather, it shows that the correct definition of a Lawvere theory is a pair $(\mathcal{L},X)$ consisting of a category with finite products and an object $X \in \mathcal{L}$ such that every object of $ \mathcal{L}$ is isomorphic to some $X^n$ . It is not enough to state the existence of such an object as a property. I am not sure if this answers the question (does it?), but in any case there must be simpler examples (since here any category can be chosen). Edit. In fact, a theorem of Ketonen implies that there are boolean algebras $A$ such that $A \cong A^4$ and $A \not\cong A^2$ , and then $X := A$ and $Y := X^2$ are a counterexample. I am looking for an answer which either explains this algebra $A$ in a self-contained way and gives a proof of $A \not\cong A^2$ and $A \cong A^4$ , or (perhaps even) better gives an example in a more elementary category.","What is the simplest example of a category with finite products and two objects such that and are not isomorphic, is isomorphic to for some , is isomorphic to for some ? This should demonstrate that the generic object of a Lawvere theory is not uniquely determined. Rather, it shows that the correct definition of a Lawvere theory is a pair consisting of a category with finite products and an object such that every object of is isomorphic to some . It is not enough to state the existence of such an object as a property. I am not sure if this answers the question (does it?), but in any case there must be simpler examples (since here any category can be chosen). Edit. In fact, a theorem of Ketonen implies that there are boolean algebras such that and , and then and are a counterexample. I am looking for an answer which either explains this algebra in a self-contained way and gives a proof of and , or (perhaps even) better gives an example in a more elementary category.","X,Y X Y X Y^n n \in \mathbb{N} Y X^m m \in \mathbb{N} (\mathcal{L},X) X \in \mathcal{L}  \mathcal{L} X^n A A \cong A^4 A \not\cong A^2 X := A Y := X^2 A A \not\cong A^2 A \cong A^4","['abstract-algebra', 'category-theory', 'examples-counterexamples']"
53,When are two direct products of groups isomorphic?,When are two direct products of groups isomorphic?,,"I was thinking about the following problem: Suppose that $G_1 \cong G_2$ are isomorphic groups. Under what conditions on the groups $H_1,H_2$ will we have $$G_1 \times H_1 \cong G_2 \times H_2 ?$$ Obviously, in the finite case we must have $|H_1|=|H_2|$. Also, it is easy to see that $H_1 \cong H_2$ is sufficient. Is it necessary as well? Thank you!","I was thinking about the following problem: Suppose that $G_1 \cong G_2$ are isomorphic groups. Under what conditions on the groups $H_1,H_2$ will we have $$G_1 \times H_1 \cong G_2 \times H_2 ?$$ Obviously, in the finite case we must have $|H_1|=|H_2|$. Also, it is easy to see that $H_1 \cong H_2$ is sufficient. Is it necessary as well? Thank you!",,"['abstract-algebra', 'group-theory', 'group-isomorphism']"
54,Definition of a monoid: clarification needed,Definition of a monoid: clarification needed,,"I'm only in high school, so excuse my lack of familiarity with most of these terms! A monoid is defined as ""an algebraic structure with a single associative binary operation and identity element."" A binary operation, to my understanding, is something like addition, subtraction, multiplication, division i.e. it involves 2 members of a set, a single operation, and the resulting third member within that set. And an identity element is a special type of element of a set, with respect to a binary operation on that set, which leaves other elements unchanged when combined with things. Examples are ""$0$"" as an additive identity and ""$1$"" as a multiplicative identity. How does this definition correspond to a category with a single object? What are some examples of monoids?","I'm only in high school, so excuse my lack of familiarity with most of these terms! A monoid is defined as ""an algebraic structure with a single associative binary operation and identity element."" A binary operation, to my understanding, is something like addition, subtraction, multiplication, division i.e. it involves 2 members of a set, a single operation, and the resulting third member within that set. And an identity element is a special type of element of a set, with respect to a binary operation on that set, which leaves other elements unchanged when combined with things. Examples are ""$0$"" as an additive identity and ""$1$"" as a multiplicative identity. How does this definition correspond to a category with a single object? What are some examples of monoids?",,"['abstract-algebra', 'category-theory', 'definition', 'monoid']"
55,Let $R$ be a finite commutative ring. Show that an ideal is maximal if and only if it is prime.,Let  be a finite commutative ring. Show that an ideal is maximal if and only if it is prime.,R,Let $R$ be a finite commutative ring. Show that an ideal is maximal if and only if it is prime. My attempt: Let $I$ be an ideal of $R$. Then we have $I$ is maximal $\Leftrightarrow$ $R/I$ is a finite field $\Leftrightarrow$ $R/I$ is a finite integral domain $\Leftrightarrow$ $I$ is a prime ideal. Is my proof valid ?,Let $R$ be a finite commutative ring. Show that an ideal is maximal if and only if it is prime. My attempt: Let $I$ be an ideal of $R$. Then we have $I$ is maximal $\Leftrightarrow$ $R/I$ is a finite field $\Leftrightarrow$ $R/I$ is a finite integral domain $\Leftrightarrow$ $I$ is a prime ideal. Is my proof valid ?,,"['abstract-algebra', 'ring-theory', 'ideals', 'finite-rings']"
56,Approximation Lemma in Serre's Local Fields,Approximation Lemma in Serre's Local Fields,,"Let $A$ be a Dedekind domain, and let $K$ be its field of fractions. In Serre's Local Fields , the following Lemma is stated. Approximation Lemma Let $k$ be a positive integer. For every $i$, $1\leq i \leq k$, let $\mathfrak p_i$ be prime ideals of $A$, $x_i$ elements of $K$, and $n_i$ integers. Then there exists an $x\in L$ such that $v_{\mathfrak p_i}(x - x_i)\geq n_i$ for all $i$, and $v_{\mathfrak q} \geq 0$ for $\mathfrak q \neq \mathfrak p_1,\ldots, \mathfrak p_k$. To get a better feel for this I would like to be able to actually find the $x$ stated in Lemma. I have tried to follow the proof to do this, and there is one crucial step that I don't understand at all. At the start, after assuming that the $x_i$ are in $A$, it is stated that ""by linearity, one may assume that $x_2 = \ldots = x_k = 0$"". I don't see why we can assume this, and I don't even know what is meant by linearity here. Any suggestion as to what it means in the proof, or alternative (preferably constructive) proofs would be much appreciated. As a further, related question, this lemma is often stated as showing that we can find an element that is in one collection of ideals, and not in some other ideal (for example, the proof of proposition 19). I don't see how the Lemma controls an element NOT being in an ideal - it has no control over how high the valuation at an ideal is. Any hints about this would be appreciated too.","Let $A$ be a Dedekind domain, and let $K$ be its field of fractions. In Serre's Local Fields , the following Lemma is stated. Approximation Lemma Let $k$ be a positive integer. For every $i$, $1\leq i \leq k$, let $\mathfrak p_i$ be prime ideals of $A$, $x_i$ elements of $K$, and $n_i$ integers. Then there exists an $x\in L$ such that $v_{\mathfrak p_i}(x - x_i)\geq n_i$ for all $i$, and $v_{\mathfrak q} \geq 0$ for $\mathfrak q \neq \mathfrak p_1,\ldots, \mathfrak p_k$. To get a better feel for this I would like to be able to actually find the $x$ stated in Lemma. I have tried to follow the proof to do this, and there is one crucial step that I don't understand at all. At the start, after assuming that the $x_i$ are in $A$, it is stated that ""by linearity, one may assume that $x_2 = \ldots = x_k = 0$"". I don't see why we can assume this, and I don't even know what is meant by linearity here. Any suggestion as to what it means in the proof, or alternative (preferably constructive) proofs would be much appreciated. As a further, related question, this lemma is often stated as showing that we can find an element that is in one collection of ideals, and not in some other ideal (for example, the proof of proposition 19). I don't see how the Lemma controls an element NOT being in an ideal - it has no control over how high the valuation at an ideal is. Any hints about this would be appreciated too.",,"['abstract-algebra', 'commutative-algebra', 'algebraic-number-theory']"
57,What does it mean to tensor with $\mathbb{Q}$?,What does it mean to tensor with ?,\mathbb{Q},"At our algebraic geometry seminar I often hear that something is 'tensored with $\mathbb{Q}$', e.g. a ring of endomorphisms. This phrase seems to have some intuitive meaning that I don't know. What does 'tensoring with $\mathbb{Q}$' mean?","At our algebraic geometry seminar I often hear that something is 'tensored with $\mathbb{Q}$', e.g. a ring of endomorphisms. This phrase seems to have some intuitive meaning that I don't know. What does 'tensoring with $\mathbb{Q}$' mean?",,"['abstract-algebra', 'tensor-products']"
58,"Is $\text{Hom}(\prod_p \Bbb Z/p\Bbb Z, \Bbb Q) = 0$ possible without choice?",Is  possible without choice?,"\text{Hom}(\prod_p \Bbb Z/p\Bbb Z, \Bbb Q) = 0","That divisible abelian groups are precisely the injective groups is equivalent to choice ; indeed, there are some models of ZF with no injective groups at all. Now, given that $\Bbb Q$ is injective, one immediately has that $\text{Hom}(\prod_p \Bbb Z/p\Bbb Z, \Bbb Q)$ is nontrivial (pick an element of infinite order in the former group; then the definition of injective gives a nonzero map to $\Bbb Q$ factoring the inclusion $\Bbb Z \hookrightarrow \Bbb Q$.) Now, assuming that $\Bbb Q$ is not injective does not obviously prove that $\text{Hom}(\prod_p \Bbb Z/p\Bbb Z, \Bbb Q)$ is trivial, whence: is there a model of ZF in which this is true?","That divisible abelian groups are precisely the injective groups is equivalent to choice ; indeed, there are some models of ZF with no injective groups at all. Now, given that $\Bbb Q$ is injective, one immediately has that $\text{Hom}(\prod_p \Bbb Z/p\Bbb Z, \Bbb Q)$ is nontrivial (pick an element of infinite order in the former group; then the definition of injective gives a nonzero map to $\Bbb Q$ factoring the inclusion $\Bbb Z \hookrightarrow \Bbb Q$.) Now, assuming that $\Bbb Q$ is not injective does not obviously prove that $\text{Hom}(\prod_p \Bbb Z/p\Bbb Z, \Bbb Q)$ is trivial, whence: is there a model of ZF in which this is true?",,['abstract-algebra']
59,"How do the definitions of ""irreducible"" and ""prime"" elements differ?","How do the definitions of ""irreducible"" and ""prime"" elements differ?",,"In my commutative algebra lecture notes it says: A non-zero element $p$ of a ring $R$ which is not a unit of $R$ is called a prime element if $p=ab$ implies $a$ is a unit or $b$ is a unit. Is this not the definition of an irreducible element?? Everywhere else I've read that a non-zero, non-unit element $p$ is a prime element if $p|ab $ implies $p|a$ or $p|b$ Thanks :)","In my commutative algebra lecture notes it says: A non-zero element $p$ of a ring $R$ which is not a unit of $R$ is called a prime element if $p=ab$ implies $a$ is a unit or $b$ is a unit. Is this not the definition of an irreducible element?? Everywhere else I've read that a non-zero, non-unit element $p$ is a prime element if $p|ab $ implies $p|a$ or $p|b$ Thanks :)",,"['abstract-algebra', 'ring-theory']"
60,The difference between vector space and group,The difference between vector space and group,,"When comparing the difference between the definition of vector space, I see that the main job is that vector space defines a scalar product while the group not, so here list two of my questions? 1.Why we need to define a scalar product for a vector space? Physical sense or some insight behind it? 2.One truly nice thing for vector space is that we represent the element with basis, so what we do with elements in vector space is just with basis,so why we can't do the same thing for group? I think the question may be a little silly, but I need a question.","When comparing the difference between the definition of vector space, I see that the main job is that vector space defines a scalar product while the group not, so here list two of my questions? 1.Why we need to define a scalar product for a vector space? Physical sense or some insight behind it? 2.One truly nice thing for vector space is that we represent the element with basis, so what we do with elements in vector space is just with basis,so why we can't do the same thing for group? I think the question may be a little silly, but I need a question.",,"['abstract-algebra', 'group-theory', 'vector-spaces']"
61,"Embeddings $A  B  A$, but $A \not\cong B$?","Embeddings , but ?",A  B  A A \not\cong B,"Are there any nice examples of structures (groups, modules, rings, fields) $A$ and $B$ such that there are embeddings $A  B  A$ while $A \not\cong B$? I would especially like to see an example for modules $A$, $B$. Or is it even true that the existence of such embeddings implies $A \cong B$? Background: Im correcting exercises and I wanted to give a counterexample to a failing argument. (Well, Im not certain it fails, but Im pretty sure it does and its not sufficiently justified at least.)","Are there any nice examples of structures (groups, modules, rings, fields) $A$ and $B$ such that there are embeddings $A  B  A$ while $A \not\cong B$? I would especially like to see an example for modules $A$, $B$. Or is it even true that the existence of such embeddings implies $A \cong B$? Background: Im correcting exercises and I wanted to give a counterexample to a failing argument. (Well, Im not certain it fails, but Im pretty sure it does and its not sufficiently justified at least.)",,"['abstract-algebra', 'modules', 'universal-algebra']"
62,"If $\phi: G \to H$ is an isomorphism, prove that $G$ is abelian if and only if $H$ is abelian","If  is an isomorphism, prove that  is abelian if and only if  is abelian",\phi: G \to H G H,"I would like to know if my proof is correct. Specifically, I would like you to check that surjectivity is needed for proving the first part and injectivity is needed for proving the second part. Problem If $\phi: G \to H$ is an isomorphism, prove that $G$ is abelian if and only if $H$ is abelian. Solution Let $\phi: G \to H$ be an isomorphism. If $G$ is abelian, we have $xy = yx$, for any $x,y \in G$. Consider any two element in $H$, say $c$ and $d$. Since $\phi$ is an isomorphism (more specifically a surjection), we have $c = \phi(a)$ and $d=\phi(b)$ for some $a,b \in G$. Hence, $$cd = \phi(a)\phi(b) = \phi(ab) = \phi(ba) = \phi(b)\phi(a) = dc$$ This means $H$ is also abelian. If $H$ is abelian, we have $xy = yx$, for any $x,y \in H$. Now consider two elements in $G$, say $a$ and $b$. Since $\phi$ is a mapping, we have $c=\phi(a)$ and $d=\phi(b)$ for some $c,d \in H$. Hence, $$\phi(ab) = \phi(a)\phi(b) = cd = dc = \phi(b) \phi(a) = \phi(ba)$$ Since $\phi$ is an isomorphism (more specifically injective), we have $ab = ba$. This means $G$ is also abelian. Thanks","I would like to know if my proof is correct. Specifically, I would like you to check that surjectivity is needed for proving the first part and injectivity is needed for proving the second part. Problem If $\phi: G \to H$ is an isomorphism, prove that $G$ is abelian if and only if $H$ is abelian. Solution Let $\phi: G \to H$ be an isomorphism. If $G$ is abelian, we have $xy = yx$, for any $x,y \in G$. Consider any two element in $H$, say $c$ and $d$. Since $\phi$ is an isomorphism (more specifically a surjection), we have $c = \phi(a)$ and $d=\phi(b)$ for some $a,b \in G$. Hence, $$cd = \phi(a)\phi(b) = \phi(ab) = \phi(ba) = \phi(b)\phi(a) = dc$$ This means $H$ is also abelian. If $H$ is abelian, we have $xy = yx$, for any $x,y \in H$. Now consider two elements in $G$, say $a$ and $b$. Since $\phi$ is a mapping, we have $c=\phi(a)$ and $d=\phi(b)$ for some $c,d \in H$. Hence, $$\phi(ab) = \phi(a)\phi(b) = cd = dc = \phi(b) \phi(a) = \phi(ba)$$ Since $\phi$ is an isomorphism (more specifically injective), we have $ab = ba$. This means $G$ is also abelian. Thanks",,"['abstract-algebra', 'group-theory', 'proof-verification']"
63,Simple module is isomorphic to $R/M$ where $M$ is a maximal ideal,Simple module is isomorphic to  where  is a maximal ideal,R/M M,"In Michael Artin's Algebra textbook page 484 Chapter 12 Exercise 1.6: A module is called simple if it is not the zero module and if it has no proper submodule. (a) Prove that any simple module is isomorphic to R/M, where M is a maximal ideal. My questions are: Is $R/M$ a left module over $R$? or over itself $R/M$? When we defined a module $N$ we defined a map $R\times N\to N$ where $R$ is a ring and $N$ is an Abelian group. Now let the ring $R$ be $M$ as given in question, where $M$ is a maximal ideal of $R$. So the map becomes  $M\times N\to N$. As far as I know, there no equivalent notion of ideal in module. The reason I said that is because from the definition of quotient module $V/W$, $W$ is just a submodule of $V$, not an ""ideal"" submodule of $V$. Is my reasoning correct? If my reasoning in 2. above is wrong, then how can we interpret a maximal ideal in a language of module? Is there a definition of maximal ideal in module distinct to definition of a maximal ideal in ring? To prove the question, I consulted other sources in the internet. There is a proof that says ""Any submodule of $R/M$ is an ideal, since it would be an additive group that is closed under multiplication by elements of $R$ and therefore $R/M$."" Since I am still not clear of the definition of ideal in module, I am confused by the meaning of the above statement, especially what does it mean by ""closed under multiplication by elements of R and therefore $R/M$""? Thank you very much for any helps. I really appreciate it.","In Michael Artin's Algebra textbook page 484 Chapter 12 Exercise 1.6: A module is called simple if it is not the zero module and if it has no proper submodule. (a) Prove that any simple module is isomorphic to R/M, where M is a maximal ideal. My questions are: Is $R/M$ a left module over $R$? or over itself $R/M$? When we defined a module $N$ we defined a map $R\times N\to N$ where $R$ is a ring and $N$ is an Abelian group. Now let the ring $R$ be $M$ as given in question, where $M$ is a maximal ideal of $R$. So the map becomes  $M\times N\to N$. As far as I know, there no equivalent notion of ideal in module. The reason I said that is because from the definition of quotient module $V/W$, $W$ is just a submodule of $V$, not an ""ideal"" submodule of $V$. Is my reasoning correct? If my reasoning in 2. above is wrong, then how can we interpret a maximal ideal in a language of module? Is there a definition of maximal ideal in module distinct to definition of a maximal ideal in ring? To prove the question, I consulted other sources in the internet. There is a proof that says ""Any submodule of $R/M$ is an ideal, since it would be an additive group that is closed under multiplication by elements of $R$ and therefore $R/M$."" Since I am still not clear of the definition of ideal in module, I am confused by the meaning of the above statement, especially what does it mean by ""closed under multiplication by elements of R and therefore $R/M$""? Thank you very much for any helps. I really appreciate it.",,"['abstract-algebra', 'modules']"
64,"Elementary proof of $\mathbb{Q}(\zeta_n)\cap \mathbb{Q}(\zeta_m)=\mathbb{Q}$ when $\gcd(n,m)=1$.",Elementary proof of  when .,"\mathbb{Q}(\zeta_n)\cap \mathbb{Q}(\zeta_m)=\mathbb{Q} \gcd(n,m)=1","In an answer to another question I used the fact that $\mathbb{Q}(\zeta_m)\subseteq \mathbb{Q}(\zeta_n)$ if and only if $m$ divides $n$ (here $\zeta_n$ stands for a primitive $n$th root of unity, Edit: and neither $m$ nor $n$ is  twice an odd number; see KCd comments below). More generally, one can show that $\mathbb{Q}(\zeta_n)\cap \mathbb{Q}(\zeta_m)=\mathbb{Q}$ when $\gcd(n,m)=1$. The only proof of this fact that comes to mind uses facts about discriminants of cyclotomic extensions, and the fact that every non-trivial number field extension over $\mathbb{Q}$ ramifies at least at one prime (see, for instance, Washington, ""Introduction to Cyclotomic Fields"", Chapter 2, Proposition 2.4). Since the original question that I was trying to answer was somewhat elementary, I was left wondering if there are more elementary proofs of the fact  $$\mathbb{Q}(\zeta_n)\cap \mathbb{Q}(\zeta_m)=\mathbb{Q}, \text{ when } \gcd(n,m)=1. $$  By ""elementary proof"" here I mean some proof that does not involve algebraic number theory results about discriminants, or ramification of primes in rings of integers of number fields. Can anyone think of an elementary proof? Thanks!","In an answer to another question I used the fact that $\mathbb{Q}(\zeta_m)\subseteq \mathbb{Q}(\zeta_n)$ if and only if $m$ divides $n$ (here $\zeta_n$ stands for a primitive $n$th root of unity, Edit: and neither $m$ nor $n$ is  twice an odd number; see KCd comments below). More generally, one can show that $\mathbb{Q}(\zeta_n)\cap \mathbb{Q}(\zeta_m)=\mathbb{Q}$ when $\gcd(n,m)=1$. The only proof of this fact that comes to mind uses facts about discriminants of cyclotomic extensions, and the fact that every non-trivial number field extension over $\mathbb{Q}$ ramifies at least at one prime (see, for instance, Washington, ""Introduction to Cyclotomic Fields"", Chapter 2, Proposition 2.4). Since the original question that I was trying to answer was somewhat elementary, I was left wondering if there are more elementary proofs of the fact  $$\mathbb{Q}(\zeta_n)\cap \mathbb{Q}(\zeta_m)=\mathbb{Q}, \text{ when } \gcd(n,m)=1. $$  By ""elementary proof"" here I mean some proof that does not involve algebraic number theory results about discriminants, or ramification of primes in rings of integers of number fields. Can anyone think of an elementary proof? Thanks!",,"['abstract-algebra', 'field-theory', 'algebraic-number-theory', 'cyclotomic-fields']"
65,Characterizations of the $p$-Prfer group,Characterizations of the -Prfer group,p,"I'm an undergrad student fairly keen on algebra. Over the different algebra courses I've taken, I've often encountered the so-called $p$-Prfer group on exercises but somehow never got around to them. Now I'm trying to take care of that, but there are some statements I've seen about this group which I don't know how to prove (maybe because I lack some more background in group theory, especially in the study of infinite abelian groups?) Definition A $p$-group is a $p$-Prfer group if it is isomorphic to $$C_{p^\infty}=\{e^{\frac{2k\pi i}{p^n}}:k\in \mathbb{Z}, n\in\mathbb{Z}^+\} \subset (\mathbb{C}^\times, \cdot)$$ What I'm having trouble to prove is: The following are $p$-Prfer groups: 1) An infinite $p$-group whose subgroups are totally ordered by inclusion, 2) An infinite $p$-group such that every finite subset generates a cyclic group, 3) An infinite abelian $p$-group such that $G$ is isomorphic to every proper quotient, 4) An infinite abelian $p$-group such that every subgroup is finite Just for the record, what I (think I) could prove was that the following are $p$-Prfer groups: 5) An injective envelope of $C_{p^n}$, for any $n\geq 1$, 6) A Sylow $p$-subgroup of $\frac{\mathbb{Q}}{\mathbb{Z}}$, 7) The direct limit of $0\subset C_p \subset C_{p^2}\subset ...$ Here $C_{p^n}$ denotes a cyclic group of order $p^n$. Any other characterizations of the $p$-Prfer group are welcome.","I'm an undergrad student fairly keen on algebra. Over the different algebra courses I've taken, I've often encountered the so-called $p$-Prfer group on exercises but somehow never got around to them. Now I'm trying to take care of that, but there are some statements I've seen about this group which I don't know how to prove (maybe because I lack some more background in group theory, especially in the study of infinite abelian groups?) Definition A $p$-group is a $p$-Prfer group if it is isomorphic to $$C_{p^\infty}=\{e^{\frac{2k\pi i}{p^n}}:k\in \mathbb{Z}, n\in\mathbb{Z}^+\} \subset (\mathbb{C}^\times, \cdot)$$ What I'm having trouble to prove is: The following are $p$-Prfer groups: 1) An infinite $p$-group whose subgroups are totally ordered by inclusion, 2) An infinite $p$-group such that every finite subset generates a cyclic group, 3) An infinite abelian $p$-group such that $G$ is isomorphic to every proper quotient, 4) An infinite abelian $p$-group such that every subgroup is finite Just for the record, what I (think I) could prove was that the following are $p$-Prfer groups: 5) An injective envelope of $C_{p^n}$, for any $n\geq 1$, 6) A Sylow $p$-subgroup of $\frac{\mathbb{Q}}{\mathbb{Z}}$, 7) The direct limit of $0\subset C_p \subset C_{p^2}\subset ...$ Here $C_{p^n}$ denotes a cyclic group of order $p^n$. Any other characterizations of the $p$-Prfer group are welcome.",,"['abstract-algebra', 'group-theory', 'p-groups']"
66,Must large (infinite) groups have large automorphism groups?,Must large (infinite) groups have large automorphism groups?,,"For every cardinal $\kappa$ , is there a cardinal $\lambda$ such that for all groups $G$ with $|G| > \lambda$ , we have $|\mathrm{Aut}(G)| > \kappa$ ? I believe a similar result holds for finite groups (see Groups with given automorphism groups ), but I'm wondering about the infinite case. If this fails, how badly does it fail? Are there arbitrarily large groups with finite automorphism group?","For every cardinal , is there a cardinal such that for all groups with , we have ? I believe a similar result holds for finite groups (see Groups with given automorphism groups ), but I'm wondering about the infinite case. If this fails, how badly does it fail? Are there arbitrarily large groups with finite automorphism group?",\kappa \lambda G |G| > \lambda |\mathrm{Aut}(G)| > \kappa,"['abstract-algebra', 'group-theory', 'cardinals', 'automorphism-group']"
67,Does there exist a ring which is not a principal ideal ring and which has exactly six different ideals?,Does there exist a ring which is not a principal ideal ring and which has exactly six different ideals?,,"Does there exist a ring which is not a principal ideal ring and which has exactly six different ideals? (For me a ring is commutative with a unit element.) I can show that any ring having at most five ideals is a principal ideal ring. EDIT: The proof goes as follows, it is not so hard. Suppose that $R$ is a ring which is not principal and which has at most five ideals. Then there must exist a proper ideal of the form $(\alpha,\beta)$ in $R$ which is not principal. Then $(0), (\alpha),(\beta),(\alpha, \beta), R$ must be the five different ideals of $R$. But what about $(\alpha + \beta)$? It cannot be $(0)$ or $(\alpha,\beta)$ or $R$. Say that it is $(\alpha)$. Then we get that $\alpha \mid \beta$, hence $(\alpha,\beta) = (\alpha)$, contradiction! Similarly, it cannot be $(\beta)$. Hence we are done.","Does there exist a ring which is not a principal ideal ring and which has exactly six different ideals? (For me a ring is commutative with a unit element.) I can show that any ring having at most five ideals is a principal ideal ring. EDIT: The proof goes as follows, it is not so hard. Suppose that $R$ is a ring which is not principal and which has at most five ideals. Then there must exist a proper ideal of the form $(\alpha,\beta)$ in $R$ which is not principal. Then $(0), (\alpha),(\beta),(\alpha, \beta), R$ must be the five different ideals of $R$. But what about $(\alpha + \beta)$? It cannot be $(0)$ or $(\alpha,\beta)$ or $R$. Say that it is $(\alpha)$. Then we get that $\alpha \mid \beta$, hence $(\alpha,\beta) = (\alpha)$, contradiction! Similarly, it cannot be $(\beta)$. Hence we are done.",,"['abstract-algebra', 'ring-theory', 'ideals', 'examples-counterexamples', 'principal-ideal-domains']"
68,Adjointness of Hom and Tensor,Adjointness of Hom and Tensor,,"Could someone provide me a link to the proof of the adjointness of Hom and Tensor. I did an extensive google search but could not find anything self contained that presented the proof in full generality (or at least the generality I know).  Let $R\to S$ be a ring homomorphism, let $M,N$ be $S$-modules and $Q$ an $R$-module. Then, we have  $$\textrm{Hom}_R(M\otimes_S N,Q) \cong \textrm{Hom}_S(M,\textrm{Hom}_R(N,Q)$$","Could someone provide me a link to the proof of the adjointness of Hom and Tensor. I did an extensive google search but could not find anything self contained that presented the proof in full generality (or at least the generality I know).  Let $R\to S$ be a ring homomorphism, let $M,N$ be $S$-modules and $Q$ an $R$-module. Then, we have  $$\textrm{Hom}_R(M\otimes_S N,Q) \cong \textrm{Hom}_S(M,\textrm{Hom}_R(N,Q)$$",,"['abstract-algebra', 'commutative-algebra', 'category-theory', 'tensor-products']"
69,Finite quotient ring of $\mathbb Z[X]$,Finite quotient ring of,\mathbb Z[X],"Since userxxxxx (I don't remember the numbers) deleted his own question which I find interesting, let me repost it: Let $f,g\in\mathbb Z[X]$ with $\mathrm{gcd}(f,g)=1$. Prove that the ring $\mathbb Z[X]/(f,g)$ is finite.","Since userxxxxx (I don't remember the numbers) deleted his own question which I find interesting, let me repost it: Let $f,g\in\mathbb Z[X]$ with $\mathrm{gcd}(f,g)=1$. Prove that the ring $\mathbb Z[X]/(f,g)$ is finite.",,"['abstract-algebra', 'commutative-algebra']"
70,The group of additive sequences of integers,The group of additive sequences of integers,,"Let $G$ be the additive group of the sequences $(a_n)_{n\ge 1} \subset \mathbb{Z}$ and let $f:G \to \mathbb{Z}$ be a group homomorphism. We denote by $e_i$ the sequence $(0,0,...,0,1,0,0...)$ (we just have a $1$ on the $i$ -th position, everything else is zero). Show that the set $\{i\ge 1 | f(e_i) \ne 0\}$ is finite. I thought that I should consider the set of sequences of finite support i.e. the subgroup generated by the $e_i$ s. Let's denote it by $H$ . We have that $f(H)$ is a subgroup of $\mathbb{Z}$ , so $f(H)=m\mathbb{Z}$ for some integer $m$ . We also have that $f(G)=n\mathbb{Z}$ for some positive integer $n$ . But I don't know how to proceed any further. I think that we should aim for a contradiction. I can only think about something having to do with divisibility, but I don't know.","Let be the additive group of the sequences and let be a group homomorphism. We denote by the sequence (we just have a on the -th position, everything else is zero). Show that the set is finite. I thought that I should consider the set of sequences of finite support i.e. the subgroup generated by the s. Let's denote it by . We have that is a subgroup of , so for some integer . We also have that for some positive integer . But I don't know how to proceed any further. I think that we should aim for a contradiction. I can only think about something having to do with divisibility, but I don't know.","G (a_n)_{n\ge 1} \subset \mathbb{Z} f:G \to \mathbb{Z} e_i (0,0,...,0,1,0,0...) 1 i \{i\ge 1 | f(e_i) \ne 0\} e_i H f(H) \mathbb{Z} f(H)=m\mathbb{Z} m f(G)=n\mathbb{Z} n","['abstract-algebra', 'group-theory', 'group-homomorphism']"
71,Discriminant of $\Bbb Q(\sqrt[3]{2})$,Discriminant of,\Bbb Q(\sqrt[3]{2}),"I want to understand a way of computing the discriminant of the number field $K=\mathbb{Q}(\sqrt[3]{2})$. The degree of $K|\mathbb{Q}$ is $n=3$ and we have $3=1+2\cdot 1$, so there are one real and two complex embeddings. Now my teacher concludes that the absolute value of the discriminant is equal to $2^2\cdot 3^3$. Why that?","I want to understand a way of computing the discriminant of the number field $K=\mathbb{Q}(\sqrt[3]{2})$. The degree of $K|\mathbb{Q}$ is $n=3$ and we have $3=1+2\cdot 1$, so there are one real and two complex embeddings. Now my teacher concludes that the absolute value of the discriminant is equal to $2^2\cdot 3^3$. Why that?",,['abstract-algebra']
72,Algebraic interpretation of Lyapunov functions,Algebraic interpretation of Lyapunov functions,,"I have recently learned the method of Lyapunov functions to rule out periodic solutions in two-dimensional nonlinear systems. My understanding is that there is some Lyapunov function for any nonlinear 2D system with no closed orbits, and basically that these functions always asymptotically converge to some fixed point. The usual assumption of their form is something like $ax^2+by^2$, which is I guess convenient because both terms are always positive for positive coefficients, but I am wondering how this relates (if at all) to the idea of norm. Is there an algebraic interpretation of such functions in 2D systems that might provide more insight into what is going on, or alternatively help someone have some better intuition about how to construct these guys? (Aside from being told to find one in a problem set, what about a 2D system might make you think there could be a Lyapunov function?)","I have recently learned the method of Lyapunov functions to rule out periodic solutions in two-dimensional nonlinear systems. My understanding is that there is some Lyapunov function for any nonlinear 2D system with no closed orbits, and basically that these functions always asymptotically converge to some fixed point. The usual assumption of their form is something like $ax^2+by^2$, which is I guess convenient because both terms are always positive for positive coefficients, but I am wondering how this relates (if at all) to the idea of norm. Is there an algebraic interpretation of such functions in 2D systems that might provide more insight into what is going on, or alternatively help someone have some better intuition about how to construct these guys? (Aside from being told to find one in a problem set, what about a 2D system might make you think there could be a Lyapunov function?)",,"['abstract-algebra', 'ordinary-differential-equations']"
73,Ring of Polynomials is a Principal Ideal Ring implies Coefficient Ring is a Field?,Ring of Polynomials is a Principal Ideal Ring implies Coefficient Ring is a Field?,,"I read this proof that if $D$ is an integral domain and $D[X]$ is a principal ideal domain, then $D$ is a field. My question is if the requirements can be relaxed a bit, namely: Is it true that if $D$ is a commutative unitary ring and $D[x]$ is a principal ideal ring (this allows zero-divisors), then $D$ is a field? I would be very pleased if anyone could give me a counter-example or could sketch a proof, certainly the linked proof would completely break down in this case as one could not use the properties of degree.","I read this proof that if $D$ is an integral domain and $D[X]$ is a principal ideal domain, then $D$ is a field. My question is if the requirements can be relaxed a bit, namely: Is it true that if $D$ is a commutative unitary ring and $D[x]$ is a principal ideal ring (this allows zero-divisors), then $D$ is a field? I would be very pleased if anyone could give me a counter-example or could sketch a proof, certainly the linked proof would completely break down in this case as one could not use the properties of degree.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'principal-ideal-domains']"
74,How many non-isomorphic binary structures on the set of $n$ elements?,How many non-isomorphic binary structures on the set of  elements?,n,"This question is originated from Fraleigh's Abstract Algebra, Ex3.34 . The exercise is for the case of $n=2$. The answer is 10, and the below is my solution about it. Let the set be $\{{ a,b \}}$. If we let $f$ be the non-identity isomorphism($f(a)=b, f(b)=a$), then 4 binary structures are invariant under $f$: If you set $a*a$ and $a*b$ then the rest are determined since $f(a)*f(a)=b*b$ and $f(a)*f(b)=b*a$. So the number of non-isomorphic binary structures is $4+ \frac {16-4} 2 = 10$. Is there any generalization of this on $n$ elements? It seems a little complicated for me. I tried to find something on google, but I can't find out.","This question is originated from Fraleigh's Abstract Algebra, Ex3.34 . The exercise is for the case of $n=2$. The answer is 10, and the below is my solution about it. Let the set be $\{{ a,b \}}$. If we let $f$ be the non-identity isomorphism($f(a)=b, f(b)=a$), then 4 binary structures are invariant under $f$: If you set $a*a$ and $a*b$ then the rest are determined since $f(a)*f(a)=b*b$ and $f(a)*f(b)=b*a$. So the number of non-isomorphic binary structures is $4+ \frac {16-4} 2 = 10$. Is there any generalization of this on $n$ elements? It seems a little complicated for me. I tried to find something on google, but I can't find out.",,"['combinatorics', 'abstract-algebra', 'group-theory']"
75,Group theoretic solution to an IMO problem,Group theoretic solution to an IMO problem,,"Is there a (strictly) group theoretic interpretation (and possibly a solution) to this problem (taken from the 27th IMO)? ""To each vertex of a regular pentagon an integer is assigned in such a way that the sum of all five numbers is positive. If three consecutive vertices are assigned the numbers $x,y,z$ respectively, and $y <0$, then the following operation is allowed: the numbers $x,y,z$ are replaced by $x+y$, $-y$, $z+y$, respectively. Such an operation is performed repeatedly as long as at least one of the five numbers is negative. Determine whether this procedure necessarily comes to an end after a finite number of steps"".","Is there a (strictly) group theoretic interpretation (and possibly a solution) to this problem (taken from the 27th IMO)? ""To each vertex of a regular pentagon an integer is assigned in such a way that the sum of all five numbers is positive. If three consecutive vertices are assigned the numbers $x,y,z$ respectively, and $y <0$, then the following operation is allowed: the numbers $x,y,z$ are replaced by $x+y$, $-y$, $z+y$, respectively. Such an operation is performed repeatedly as long as at least one of the five numbers is negative. Determine whether this procedure necessarily comes to an end after a finite number of steps"".",,"['abstract-algebra', 'group-theory', 'representation-theory', 'contest-math']"
76,How many different elements can we obtain by multiplying all element in a group?,How many different elements can we obtain by multiplying all element in a group?,,"Let $G$ be a finite group. How many different elements can we obtain by multiplying all element in a group? Of course, if $G$ is abelian the answer is one but when G is non-abelian, changing the order of the multiplication may produce new elements. My second question is actually related to my attempt to solve the first one. Let $S$ be set of all elements produced by multiplying all elements in $G$. Then, it is easy to show that $Aut(G)$ acts on $S$ naturally. I wonder whether this can be transitive.","Let $G$ be a finite group. How many different elements can we obtain by multiplying all element in a group? Of course, if $G$ is abelian the answer is one but when G is non-abelian, changing the order of the multiplication may produce new elements. My second question is actually related to my attempt to solve the first one. Let $S$ be set of all elements produced by multiplying all elements in $G$. Then, it is easy to show that $Aut(G)$ acts on $S$ naturally. I wonder whether this can be transitive.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
77,"""Graded free"" is stronger than ""graded and free""?","""Graded free"" is stronger than ""graded and free""?",,"This topic suggested me the following question: If $R$ is a commutative graded ring and $F$ a graded $R$-module which is free, then can we conclude that $F$ has a homogeneous basis (that is, a basis consisting of homogeneous elements)? In general the answer is negative, and such an example can be found in Nastasescu, Van Oystaeyen, Methods of Graded Rings , page 21. But their example is not quite usual, and I'd like to know if however the property holds for positively graded $K$-algebras, for example. If not, then maybe someone can provide a generic example when the property holds.","This topic suggested me the following question: If $R$ is a commutative graded ring and $F$ a graded $R$-module which is free, then can we conclude that $F$ has a homogeneous basis (that is, a basis consisting of homogeneous elements)? In general the answer is negative, and such an example can be found in Nastasescu, Van Oystaeyen, Methods of Graded Rings , page 21. But their example is not quite usual, and I'd like to know if however the property holds for positively graded $K$-algebras, for example. If not, then maybe someone can provide a generic example when the property holds.",,"['abstract-algebra', 'commutative-algebra']"
78,How many subgroups does $\mathbb{Z}_6 \times\mathbb{Z}_6 \times\mathbb{Z}_6 \times\mathbb{Z}_6 $ have?,How many subgroups does  have?,\mathbb{Z}_6 \times\mathbb{Z}_6 \times\mathbb{Z}_6 \times\mathbb{Z}_6 ,"How many subgroups does $H = \mathbb{Z}_6 \times\mathbb{Z}_6 \times\mathbb{Z}_6 \times\mathbb{Z}_6 $ have? $\mathbb{Z}_6$ has 4 subgroups (including itself), so the answer is at least $4^4$. But, not all subgroups of $H$ are products of subgroups of $\mathbb{Z}_6$, for example the group generated by $(1,1,1,1)$ is not. Any ideas how to count this type of groups in a simple way?","How many subgroups does $H = \mathbb{Z}_6 \times\mathbb{Z}_6 \times\mathbb{Z}_6 \times\mathbb{Z}_6 $ have? $\mathbb{Z}_6$ has 4 subgroups (including itself), so the answer is at least $4^4$. But, not all subgroups of $H$ are products of subgroups of $\mathbb{Z}_6$, for example the group generated by $(1,1,1,1)$ is not. Any ideas how to count this type of groups in a simple way?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
79,Does $gHg^{-1}\subseteq H$ imply $gHg^{-1}= H$? [duplicate],Does  imply ? [duplicate],gHg^{-1}\subseteq H gHg^{-1}= H,"This question already has answers here : Conjugate subgroup strictly contained in the initial subgroup? (4 answers) Closed 9 years ago . Let $G$ be a group, $H<G$ a subgroup and $g$ an element of $G$. Let $\lambda_g$ denote the inner automorphism which maps $x$ to $gxg^{-1}$. I wonder if $H$ can be mapped to a proper subgroup of itself, i.e.  $\lambda_g(H)\subset H$. I tried to approach this problem topologically. Since every group is the fundamental group of a connected CW-complex of dimension 2, let $(X,x_0)$ be such a space for $G$. Since $X$ is (locally) path-connected and semi-locally simply-connected, there exists a (locally) path-connected covering space $(\widetilde X,\widetilde x_0)$, such that $p_*(\pi_1(\widetilde X,\widetilde x_0))=H$. The element $g$ corresponds to $[\gamma]\in\pi_1(X,x_0))$, and its lift at $\widetilde x_0$ is a path ending at $\widetilde x_1$. By hypothesis, $H\subseteq g^{-1}Hg$, which leads to the existence of a unique lift $f:\pi_1(\widetilde X,\widetilde x_0)\to\pi_1(\widetilde X,\widetilde x_1)$ such that $p=p\circ f$. This lift turns out to be a surjective covering map itself, and it is a homeomorphism iff $H=g^{-1}Hg$. I was unsuccessful in showing the injectivity. If $x_1$ and $x_2$ have the same image under $f$, then $x_1$, $x_2$, and $f(x_1)=f(x_2)$ are all in the same fiber. I took $\lambda$ to be a path from $x_1$ to $x_2$. I have been playing around with $\lambda$, $p\lambda$, and $f\lambda$, but got nowhere. Of course, there could also be a direct algebraic proof. On the other hand, if the statement is not true then someone maybe knows of a counterexample.","This question already has answers here : Conjugate subgroup strictly contained in the initial subgroup? (4 answers) Closed 9 years ago . Let $G$ be a group, $H<G$ a subgroup and $g$ an element of $G$. Let $\lambda_g$ denote the inner automorphism which maps $x$ to $gxg^{-1}$. I wonder if $H$ can be mapped to a proper subgroup of itself, i.e.  $\lambda_g(H)\subset H$. I tried to approach this problem topologically. Since every group is the fundamental group of a connected CW-complex of dimension 2, let $(X,x_0)$ be such a space for $G$. Since $X$ is (locally) path-connected and semi-locally simply-connected, there exists a (locally) path-connected covering space $(\widetilde X,\widetilde x_0)$, such that $p_*(\pi_1(\widetilde X,\widetilde x_0))=H$. The element $g$ corresponds to $[\gamma]\in\pi_1(X,x_0))$, and its lift at $\widetilde x_0$ is a path ending at $\widetilde x_1$. By hypothesis, $H\subseteq g^{-1}Hg$, which leads to the existence of a unique lift $f:\pi_1(\widetilde X,\widetilde x_0)\to\pi_1(\widetilde X,\widetilde x_1)$ such that $p=p\circ f$. This lift turns out to be a surjective covering map itself, and it is a homeomorphism iff $H=g^{-1}Hg$. I was unsuccessful in showing the injectivity. If $x_1$ and $x_2$ have the same image under $f$, then $x_1$, $x_2$, and $f(x_1)=f(x_2)$ are all in the same fiber. I took $\lambda$ to be a path from $x_1$ to $x_2$. I have been playing around with $\lambda$, $p\lambda$, and $f\lambda$, but got nowhere. Of course, there could also be a direct algebraic proof. On the other hand, if the statement is not true then someone maybe knows of a counterexample.",,"['abstract-algebra', 'group-theory', 'algebraic-topology', 'covering-spaces', 'fundamental-groups']"
80,Universal property of $N\rtimes K$,Universal property of,N\rtimes K,"Given groups $N$ and $K$, if $K$ acts on $N$ by \begin{equation} K\xrightarrow{\theta}\operatorname{Aut_{Grp}}(N), \end{equation} then we can define a group $N\rtimes_{\theta}K$ whose elements are like in $N\times K$ but the multiplication is defined by \begin{equation} (n,k)(n',k')=(n\theta_{k}(n'),kk') \end{equation} where $\theta_k\in \operatorname{Aut_{Grp}}(N)$ is the image of $k$ under $\theta$. This semidirect product is very useful in studying structures of finite groups, especially it solves the extension problem \begin{equation} 1\longrightarrow N\longrightarrow N\rtimes_{\theta} K\longrightarrow K\longrightarrow 1. \end{equation} But I am wondering whether this can be defined using universal properties? In the abelian case $N\rtimes K$ is just $N\times K$ so we have the universal property of products, but what about the nonabelian case? Thanks!","Given groups $N$ and $K$, if $K$ acts on $N$ by \begin{equation} K\xrightarrow{\theta}\operatorname{Aut_{Grp}}(N), \end{equation} then we can define a group $N\rtimes_{\theta}K$ whose elements are like in $N\times K$ but the multiplication is defined by \begin{equation} (n,k)(n',k')=(n\theta_{k}(n'),kk') \end{equation} where $\theta_k\in \operatorname{Aut_{Grp}}(N)$ is the image of $k$ under $\theta$. This semidirect product is very useful in studying structures of finite groups, especially it solves the extension problem \begin{equation} 1\longrightarrow N\longrightarrow N\rtimes_{\theta} K\longrightarrow K\longrightarrow 1. \end{equation} But I am wondering whether this can be defined using universal properties? In the abelian case $N\rtimes K$ is just $N\times K$ so we have the universal property of products, but what about the nonabelian case? Thanks!",,"['abstract-algebra', 'group-theory', 'category-theory', 'semidirect-product', 'universal-property']"
81,Transcendental Galois Theory,Transcendental Galois Theory,,"Is there a good reference on transcendental Galois Theory? More precisely, if $K/k$ admits a separating transcendence basis (or maybe if it is a separably generated extension) it seems to me that many of the usual theorems of Galois theory go through.  Moreover, the group $\text{Aut}(K/k)$ seems to have additional structure; namely it should be an algebraic group over $k$ . For example, it seems to me that $k(x_1, ..., x_n)/k$ has automorphism group $GL_n(k)$ .  (EDIT:  As Qiaochu Yuan points out, this is incorrect; the automorphism group at least must contain $PGL_{n+1}(k)$ , acting via its action on the function field of $\mathbb{P}_k^n$ .)  This sort of thing must be well-studied; if so, what are the standard references on the subject? I have seen Pete L. Clark's excellent (rough) notes on related subjects here but they seem not to address quite these sorts of questions.","Is there a good reference on transcendental Galois Theory? More precisely, if admits a separating transcendence basis (or maybe if it is a separably generated extension) it seems to me that many of the usual theorems of Galois theory go through.  Moreover, the group seems to have additional structure; namely it should be an algebraic group over . For example, it seems to me that has automorphism group .  (EDIT:  As Qiaochu Yuan points out, this is incorrect; the automorphism group at least must contain , acting via its action on the function field of .)  This sort of thing must be well-studied; if so, what are the standard references on the subject? I have seen Pete L. Clark's excellent (rough) notes on related subjects here but they seem not to address quite these sorts of questions.","K/k \text{Aut}(K/k) k k(x_1, ..., x_n)/k GL_n(k) PGL_{n+1}(k) \mathbb{P}_k^n","['abstract-algebra', 'reference-request', 'galois-theory', 'algebraic-groups']"
82,Is there a name for this algebraic structure in which $a \cdot (b + c) = (a \cdot b) \cdot c$?,Is there a name for this algebraic structure in which ?,a \cdot (b + c) = (a \cdot b) \cdot c,"Today I was toying around with reflecting points over other points, which I expanded to reflecting lists of points over other lists of points.  In the process, I found an interesting yet somewhat bizarre algebraic structure to describe what I was doing, and I would like to know if there exists a name for it or if similar structures have been studied previously. What follows is a description of the ""observed properties"" of this algebraic structure.  I'm not currently certain which properties should be considered axioms and which are derived from others. Let $(R, +, \cdot )$ be a set $R$ with two binary operations. Furthermore, each element of this set belongs to one of two possible ""types."" Each element of the first type (to be indicated with a subscript $_0$ such as $a_0$) represents a ""translation,"" while each element of the second type ($a_1$) represents a ""reflection.""  If a subscript is not provided then the relation should hold regardless of the type. Addition acts as a ""list-like"" operator, based on how it interacts with multiplication (described later).  It is associative but not commutative. $$(a + b) + c = a + (b + c)$$ When two elements are added, their types xor together. $$a_x + b_y = c_{x \oplus y}$$ Any element added to its negation (additive inverse) results in the identity. $$a + -a = I_0$$ $$a + I_0 = I_0 + a = a$$ Any type-$1$ element is its own negation, as is the identity, but all other type-$0$ elements do not equal their negation. $$a_1 = -a_1$$ $$I_0 = -I_0$$ Swapping the order of operands require that you negate both operands and the expression.  The negation does not ""distribute"" over addition. $$a + b = -(-b + -a)$$ I believe, but am not entirely certain, that $(R, +)$ qualifies as a group. The multiplication operation represents the translation/reflection of one element by/over another: reflection of $a_1$ over $b_1$ $$a_1 \cdot b_1 = c_1$$ $$a_1 \cdot a_1 = a_1$$ translation of $a_1$ by $b_0$ $$a_1 \cdot b_0 = c_1$$ reflection of $a_0$ over $b_1$ $$a_0 \cdot b_1 = -a_0$$ translation of $a_0$ by $b_0$ $$a_0 \cdot b_0 = a_0$$ The identity plays a special role here as well: $$a \cdot I_0 = a$$ $$I_0 \cdot a = I_0$$ Multiplication is a non-associative, non-commutative, yet flexible operation, meaning that the following always holds: $$(a \cdot b) \cdot a = a \cdot (b \cdot a)$$ Furthermore, $$(a \cdot b) \cdot -a = (a \cdot b) \cdot a = a \cdot (b \cdot a) = a \cdot (b \cdot -a)$$ My somewhat bizarre addition operation was constructed to give multiplication of property of ""folding over"" addition from the left. That is, $$a \cdot (b + c) = (a \cdot b) \cdot c$$ $$a \cdot (b + c + d + \ldots + y + z) = a \cdot b \cdot c \cdot d \cdot \ldots  \cdot y \cdot z$$ I call this ""folding"" based on programming terminology, and I think this property is one of the more interesting ones.  It follows from the above that there is no concept of left(?) division: $$a \cdot (b + a) = (a \cdot b) \cdot a = a \cdot (b \cdot a)$$ $$(b + a) \ne (b \cdot a)$$ $$a_0 \cdot b_0 = a_0 = a_0 \cdot c_0$$ $$b_0 \ne c_0$$ Multiplication also distributes right, similar to the concept of ""mapping"" in programming. $$(b + c) \cdot a = (b \cdot a) + (c \cdot a)$$ Negating the first argument of a multiplication expression is equivalent to negating the whole expression. $$-a \cdot b = -(a \cdot b)$$ There also also some other useful equations to relate addition, multiplication, and negation: $$-a + b + a = b \cdot a$$ $$a \cdot b = c \leftrightarrow c \cdot -b = a$$ $$a_0 \cdot b = a_0 \cdot -b$$ Again, I am not entirely confident on the self-consistency of these relationships.  I don't have a real axiomatization yet.  With the properties above I've been able to ""prove"" some simple equivalences such as $$c_x \cdot (c_x \cdot a_1) \cdot b_x = c_x \cdot (b_x \cdot a_1 \cdot c_x)$$ which corresponds to this diagram (which uses ""r"" for ""reflection"" instead of ""$\cdot$""): Have similar algebraic structures been named/studied before?  I am particularly interested in structures that obey $a \cdot (b + c) = (a \cdot b) \cdot c$.  If possible, I would also like to find ways to reduce the role of ""typing"" in the properties listed above.","Today I was toying around with reflecting points over other points, which I expanded to reflecting lists of points over other lists of points.  In the process, I found an interesting yet somewhat bizarre algebraic structure to describe what I was doing, and I would like to know if there exists a name for it or if similar structures have been studied previously. What follows is a description of the ""observed properties"" of this algebraic structure.  I'm not currently certain which properties should be considered axioms and which are derived from others. Let $(R, +, \cdot )$ be a set $R$ with two binary operations. Furthermore, each element of this set belongs to one of two possible ""types."" Each element of the first type (to be indicated with a subscript $_0$ such as $a_0$) represents a ""translation,"" while each element of the second type ($a_1$) represents a ""reflection.""  If a subscript is not provided then the relation should hold regardless of the type. Addition acts as a ""list-like"" operator, based on how it interacts with multiplication (described later).  It is associative but not commutative. $$(a + b) + c = a + (b + c)$$ When two elements are added, their types xor together. $$a_x + b_y = c_{x \oplus y}$$ Any element added to its negation (additive inverse) results in the identity. $$a + -a = I_0$$ $$a + I_0 = I_0 + a = a$$ Any type-$1$ element is its own negation, as is the identity, but all other type-$0$ elements do not equal their negation. $$a_1 = -a_1$$ $$I_0 = -I_0$$ Swapping the order of operands require that you negate both operands and the expression.  The negation does not ""distribute"" over addition. $$a + b = -(-b + -a)$$ I believe, but am not entirely certain, that $(R, +)$ qualifies as a group. The multiplication operation represents the translation/reflection of one element by/over another: reflection of $a_1$ over $b_1$ $$a_1 \cdot b_1 = c_1$$ $$a_1 \cdot a_1 = a_1$$ translation of $a_1$ by $b_0$ $$a_1 \cdot b_0 = c_1$$ reflection of $a_0$ over $b_1$ $$a_0 \cdot b_1 = -a_0$$ translation of $a_0$ by $b_0$ $$a_0 \cdot b_0 = a_0$$ The identity plays a special role here as well: $$a \cdot I_0 = a$$ $$I_0 \cdot a = I_0$$ Multiplication is a non-associative, non-commutative, yet flexible operation, meaning that the following always holds: $$(a \cdot b) \cdot a = a \cdot (b \cdot a)$$ Furthermore, $$(a \cdot b) \cdot -a = (a \cdot b) \cdot a = a \cdot (b \cdot a) = a \cdot (b \cdot -a)$$ My somewhat bizarre addition operation was constructed to give multiplication of property of ""folding over"" addition from the left. That is, $$a \cdot (b + c) = (a \cdot b) \cdot c$$ $$a \cdot (b + c + d + \ldots + y + z) = a \cdot b \cdot c \cdot d \cdot \ldots  \cdot y \cdot z$$ I call this ""folding"" based on programming terminology, and I think this property is one of the more interesting ones.  It follows from the above that there is no concept of left(?) division: $$a \cdot (b + a) = (a \cdot b) \cdot a = a \cdot (b \cdot a)$$ $$(b + a) \ne (b \cdot a)$$ $$a_0 \cdot b_0 = a_0 = a_0 \cdot c_0$$ $$b_0 \ne c_0$$ Multiplication also distributes right, similar to the concept of ""mapping"" in programming. $$(b + c) \cdot a = (b \cdot a) + (c \cdot a)$$ Negating the first argument of a multiplication expression is equivalent to negating the whole expression. $$-a \cdot b = -(a \cdot b)$$ There also also some other useful equations to relate addition, multiplication, and negation: $$-a + b + a = b \cdot a$$ $$a \cdot b = c \leftrightarrow c \cdot -b = a$$ $$a_0 \cdot b = a_0 \cdot -b$$ Again, I am not entirely confident on the self-consistency of these relationships.  I don't have a real axiomatization yet.  With the properties above I've been able to ""prove"" some simple equivalences such as $$c_x \cdot (c_x \cdot a_1) \cdot b_x = c_x \cdot (b_x \cdot a_1 \cdot c_x)$$ which corresponds to this diagram (which uses ""r"" for ""reflection"" instead of ""$\cdot$""): Have similar algebraic structures been named/studied before?  I am particularly interested in structures that obey $a \cdot (b + c) = (a \cdot b) \cdot c$.  If possible, I would also like to find ways to reduce the role of ""typing"" in the properties listed above.",,"['abstract-algebra', 'terminology']"
83,Is $\bar{\mathbb{Q}}(x)\cap \mathbb{Q}((x))=\mathbb{Q}(x)$? [unsolved (even though we earlier thought it was)],Is ? [unsolved (even though we earlier thought it was)],\bar{\mathbb{Q}}(x)\cap \mathbb{Q}((x))=\mathbb{Q}(x),"Fix the algebraic closure of $\mathbb{Q}((x))$ for this question to make sense. I know that $\mathbb{Q}((x)) \cap \overline{\mathbb{Q}(x)}$ has elements that are not in $\mathbb{Q}(x)$ (in analogy to the ""algebraic p-adics""). So I wondered, if we intersect with something even smaller, $\bar{\mathbb{Q}}(x)$, would then the result be $\mathbb{Q}(x)$? More neatly, does $\bar{\mathbb{Q}}(x)\cap \mathbb{Q}((x))=\mathbb{Q}(x)$?","Fix the algebraic closure of $\mathbb{Q}((x))$ for this question to make sense. I know that $\mathbb{Q}((x)) \cap \overline{\mathbb{Q}(x)}$ has elements that are not in $\mathbb{Q}(x)$ (in analogy to the ""algebraic p-adics""). So I wondered, if we intersect with something even smaller, $\bar{\mathbb{Q}}(x)$, would then the result be $\mathbb{Q}(x)$? More neatly, does $\bar{\mathbb{Q}}(x)\cap \mathbb{Q}((x))=\mathbb{Q}(x)$?",,"['abstract-algebra', 'number-theory', 'field-theory']"
84,The field of fractions of a field $F$ is isomorphic to $F$,The field of fractions of a field  is isomorphic to,F F,"Let $F$ be a field and let $\newcommand{\Fract}{\operatorname{Fract}}$ $\Fract(F)$ be the field of fractions of $F$; that is, $\Fract(F)= \{ {a \over b } \mid a \in F , b \in F \setminus \{ 0 \} \}$. I want to show that these two fields are isomorphic. I suggest this map $$  F \to \Fract(F) \ ; \ a \mapsto {a\over a^{-1}} ,$$ for $a \neq 0$ and $0 \mapsto 0$, but this is not injective as $a$ and $-a$ map to the same image. I was thinking about the map  $ \Fract(F) \rightarrow F ;\; a/b\mapsto ab^{-1}$ and this is clearly injective. It is also surjective as $a/1 \mapsto a$. Is this the desired isomorphism?","Let $F$ be a field and let $\newcommand{\Fract}{\operatorname{Fract}}$ $\Fract(F)$ be the field of fractions of $F$; that is, $\Fract(F)= \{ {a \over b } \mid a \in F , b \in F \setminus \{ 0 \} \}$. I want to show that these two fields are isomorphic. I suggest this map $$  F \to \Fract(F) \ ; \ a \mapsto {a\over a^{-1}} ,$$ for $a \neq 0$ and $0 \mapsto 0$, but this is not injective as $a$ and $-a$ map to the same image. I was thinking about the map  $ \Fract(F) \rightarrow F ;\; a/b\mapsto ab^{-1}$ and this is clearly injective. It is also surjective as $a/1 \mapsto a$. Is this the desired isomorphism?",,"['abstract-algebra', 'field-theory']"
85,Augmentation ideal of the group ring,Augmentation ideal of the group ring,,"Let $G$ be a group and $I_G$ be the augmentation ideal of the group ring $\mathbb{Z}G$, i.e. $I_G$ consists of formal linear combinations $\sum n_i g_i$ ($n_i\in\mathbb{Z}$, $g_i\in G$) such that $\sum n_i=0$. Is there a characterization of the groups $G$ for which $\bigcap_k I_G^k=\{0\}$?","Let $G$ be a group and $I_G$ be the augmentation ideal of the group ring $\mathbb{Z}G$, i.e. $I_G$ consists of formal linear combinations $\sum n_i g_i$ ($n_i\in\mathbb{Z}$, $g_i\in G$) such that $\sum n_i=0$. Is there a characterization of the groups $G$ for which $\bigcap_k I_G^k=\{0\}$?",,"['abstract-algebra', 'group-theory', 'group-rings']"
86,Proofs of the structure theorem for finitely generated modules over a PID,Proofs of the structure theorem for finitely generated modules over a PID,,"I'm looking for different proofs (references or sketch of main ideas) of the structure theorem for finitely generated modules over a PID. If possible, a comparison in terms of clarity, elegance or usefulness would be appreciated.","I'm looking for different proofs (references or sketch of main ideas) of the structure theorem for finitely generated modules over a PID. If possible, a comparison in terms of clarity, elegance or usefulness would be appreciated.",,"['abstract-algebra', 'modules', 'principal-ideal-domains']"
87,Order of element equal to least common multiple [duplicate],Order of element equal to least common multiple [duplicate],,"This question already has answers here : Order of elements is lcm-closed in abelian groups (6 answers) Closed 8 years ago . Let $G$ be a group, and $a,b\in G$. Suppose $\operatorname{ord}(a)=m, \operatorname{ord}(b)=n$, and that $ab=ba$. Prove that there is an element $c\in G$ such that $\operatorname{ord}(c)=\operatorname{lcm}(m,n)$. Let $A=\operatorname{lcm}(m,n)$. I consider $(ab)^A=a^Ab^A=1$, so the order of $ab$ divides $A$. What can we do to find an element with order exactly $A$?","This question already has answers here : Order of elements is lcm-closed in abelian groups (6 answers) Closed 8 years ago . Let $G$ be a group, and $a,b\in G$. Suppose $\operatorname{ord}(a)=m, \operatorname{ord}(b)=n$, and that $ab=ba$. Prove that there is an element $c\in G$ such that $\operatorname{ord}(c)=\operatorname{lcm}(m,n)$. Let $A=\operatorname{lcm}(m,n)$. I consider $(ab)^A=a^Ab^A=1$, so the order of $ab$ divides $A$. What can we do to find an element with order exactly $A$?",,"['abstract-algebra', 'group-theory']"
88,"Isomorphism between quotient rings of $K[X,Y]$",Isomorphism between quotient rings of,"K[X,Y]","Let $K$ be a field of characteristic $0$ and $m,n\in\mathbb Z$, $m,n\ge 1$. Prove that $$K[X,Y]/(X^2-Y^m)\simeq K[X,Y]/(X^2-Y^n)$$ if and only if $m=n$. (Related to Isomorphism between quotient rings of $\mathbb{Z}[x,y]$ .) Remarks. 1) The isomorphism can be considered identity on $K$. 2) I didn't assume that $K$ is algebraically closed (although it's more or less obvious that we can) since I expect the eventual solutions will give some explanations that one can do it. One can also assume $K=\mathbb C$ if this helps. 3) Geometric arguments are welcome, but I'm really looking for an elementary solution.","Let $K$ be a field of characteristic $0$ and $m,n\in\mathbb Z$, $m,n\ge 1$. Prove that $$K[X,Y]/(X^2-Y^m)\simeq K[X,Y]/(X^2-Y^n)$$ if and only if $m=n$. (Related to Isomorphism between quotient rings of $\mathbb{Z}[x,y]$ .) Remarks. 1) The isomorphism can be considered identity on $K$. 2) I didn't assume that $K$ is algebraically closed (although it's more or less obvious that we can) since I expect the eventual solutions will give some explanations that one can do it. One can also assume $K=\mathbb C$ if this helps. 3) Geometric arguments are welcome, but I'm really looking for an elementary solution.",,['abstract-algebra']
89,"If $f\in \mathbb{Z}[X]$ has the property that $|f(x)|<1, \forall x\in (-2, 2)$, then prove that $f=0$.","If  has the property that , then prove that .","f\in \mathbb{Z}[X] |f(x)|<1, \forall x\in (-2, 2) f=0","Let $f\in \mathbb{Z}[X]$ such that $|f(x)|<1, \forall x\in (-2, 2)$ . Prove that $f=0$ . I couldn't make too much progress on this problem. I tried considering $f=a_nX^n+a_{n-1}X^{n-1}+...+a_1X+a_0$ and by setting $x=0$ in the hypothesis I got that $|a_0|<1$ and this doesn't look useful. Then I thought about looking at $f$ 's degree, but I couldn't make any observations on this. I believe that the key of the problem should be that the polynomial's coefficients are integers, but I don't know how to use that. Apart from the Rational Root Theorem (which doesn't seem useful here) I don't have in mind other results regarding polynomials with integer coefficients.","Let such that . Prove that . I couldn't make too much progress on this problem. I tried considering and by setting in the hypothesis I got that and this doesn't look useful. Then I thought about looking at 's degree, but I couldn't make any observations on this. I believe that the key of the problem should be that the polynomial's coefficients are integers, but I don't know how to use that. Apart from the Rational Root Theorem (which doesn't seem useful here) I don't have in mind other results regarding polynomials with integer coefficients.","f\in \mathbb{Z}[X] |f(x)|<1, \forall x\in (-2, 2) f=0 f=a_nX^n+a_{n-1}X^{n-1}+...+a_1X+a_0 x=0 |a_0|<1 f","['abstract-algebra', 'polynomials']"
90,Number of finite extensions of $p$-adic number field of given degree $n$,Number of finite extensions of -adic number field of given degree,p n,"Let $p$ be a prime number, $\mathbb{Q}_p$ the $p$-adic number field. We fix an algebraic closure $\Omega$ of $\mathbb{Q}_p$. Any algebraic extension of $\mathbb{Q}_p$ is assumed to be a subfield of $\Omega$. Let $n$ be a positive rational integer. Is the number of finite extensions of $\mathbb{Q}_p$ of degree $n$ finite?   If yes, is there an algorithm to construct all of them? The motivation is as follows. Let $p$ be an odd prime number. I came up with the following result using Hensel's lemma. The number of quadratic extensions of $\mathbb{Q}_p$ is $3$.   They are $\mathbb{Q}_p(\sqrt a)$, $\mathbb{Q}_p(\sqrt{ap})$, $\mathbb{Q}_p(\sqrt p)$,   where $a$ is a quadratic non-residue rational integer mod $p$. $\mathbb{Q}_p(\sqrt a)$ (resp. $\mathbb{Q}_p(\sqrt{ap})$) does not depend on the choice of $a$.","Let $p$ be a prime number, $\mathbb{Q}_p$ the $p$-adic number field. We fix an algebraic closure $\Omega$ of $\mathbb{Q}_p$. Any algebraic extension of $\mathbb{Q}_p$ is assumed to be a subfield of $\Omega$. Let $n$ be a positive rational integer. Is the number of finite extensions of $\mathbb{Q}_p$ of degree $n$ finite?   If yes, is there an algorithm to construct all of them? The motivation is as follows. Let $p$ be an odd prime number. I came up with the following result using Hensel's lemma. The number of quadratic extensions of $\mathbb{Q}_p$ is $3$.   They are $\mathbb{Q}_p(\sqrt a)$, $\mathbb{Q}_p(\sqrt{ap})$, $\mathbb{Q}_p(\sqrt p)$,   where $a$ is a quadratic non-residue rational integer mod $p$. $\mathbb{Q}_p(\sqrt a)$ (resp. $\mathbb{Q}_p(\sqrt{ap})$) does not depend on the choice of $a$.",,"['abstract-algebra', 'algebraic-number-theory']"
91,The homophonic group: a mathematical diversion,The homophonic group: a mathematical diversion,,"By definition, English words have the same pronunciation if their phonetic spellings in the dictionary are the same. The homophonic group $H$ is generated by the letters of the alphabet, subject to the following relations: English words with the same pronunciation represent equal elements of the group. Thus $be = bee$, and since $H$ is a group, we can conclude that $e = 1$ (why?). Try to determine the group $H$. Is it satisfied if I select some special words and use the relations on pronunciation to prove that every letter in the alphabet equal to $1$ so that $H$ is the trivial group?","By definition, English words have the same pronunciation if their phonetic spellings in the dictionary are the same. The homophonic group $H$ is generated by the letters of the alphabet, subject to the following relations: English words with the same pronunciation represent equal elements of the group. Thus $be = bee$, and since $H$ is a group, we can conclude that $e = 1$ (why?). Try to determine the group $H$. Is it satisfied if I select some special words and use the relations on pronunciation to prove that every letter in the alphabet equal to $1$ so that $H$ is the trivial group?",,"['abstract-algebra', 'group-theory', 'free-groups', 'gap']"
92,When is $X_1^{a_1} \cdots X_n^{a_n}-1$ irreducible?,When is  irreducible?,X_1^{a_1} \cdots X_n^{a_n}-1,"Let $F$ be a field, and $a_1, ... , a_n \geq 1$ integers. When is the polynomial $$f = X_1^{a_1} \cdots X_n^{a_n}-1$$  irreducible in $F[X_1, ... ,X_n]$? I believe this should be the case if and only if $d = \gcd(a_1, ... , a_n) = 1$.  At least for $F = \mathbb{C}$, the examples I've computed indicate this to be true. If $d > 1$, then $f$ is not irreducible, since $$f = (X_1^{a_1/d} \cdots X_n^{a_n/d} - 1)[\sum\limits_{i=0}^{d-1} (X_1^{a_1/d} \cdots X_n^{a_n/d})^i]$$ I haven't been able to show the converse yet.","Let $F$ be a field, and $a_1, ... , a_n \geq 1$ integers. When is the polynomial $$f = X_1^{a_1} \cdots X_n^{a_n}-1$$  irreducible in $F[X_1, ... ,X_n]$? I believe this should be the case if and only if $d = \gcd(a_1, ... , a_n) = 1$.  At least for $F = \mathbb{C}$, the examples I've computed indicate this to be true. If $d > 1$, then $f$ is not irreducible, since $$f = (X_1^{a_1/d} \cdots X_n^{a_n/d} - 1)[\sum\limits_{i=0}^{d-1} (X_1^{a_1/d} \cdots X_n^{a_n/d})^i]$$ I haven't been able to show the converse yet.",,"['abstract-algebra', 'polynomials', 'commutative-algebra', 'irreducible-polynomials']"
93,$\operatorname{Aut}(G)\cong \Bbb{Z}/8\Bbb{Z}$,,\operatorname{Aut}(G)\cong \Bbb{Z}/8\Bbb{Z},"I am looking for a group $G$ such that $\operatorname{Aut}(G)\cong \Bbb{Z}/8\Bbb{Z}$ . Obviously $\operatorname{Aut}(\Bbb{Z}_n)\ncong \Bbb{Z}/8\Bbb{Z}$ for any $n$ . Also $\operatorname{Aut}(D_4)\cong D_4$ , neither symmetric/alternating groups are of any help here. May be there is no group for which $\operatorname{Aut}(G)\cong \Bbb{Z}/8\Bbb{Z}$ , this also raises a question can any finite/finitely  generated (why not infinite) group can be generated as an automorphism group of some $G$ Update- It is clear now that $G$ has to be abelian, and no finite abelian satisfy it. Also I found a paper from 1957 by H. de Vries and A.B. de Miranda which says $C_8$ does not occur as Aut group of any torsion-free abelian group. So this settles the question.","I am looking for a group such that . Obviously for any . Also , neither symmetric/alternating groups are of any help here. May be there is no group for which , this also raises a question can any finite/finitely  generated (why not infinite) group can be generated as an automorphism group of some Update- It is clear now that has to be abelian, and no finite abelian satisfy it. Also I found a paper from 1957 by H. de Vries and A.B. de Miranda which says does not occur as Aut group of any torsion-free abelian group. So this settles the question.",G \operatorname{Aut}(G)\cong \Bbb{Z}/8\Bbb{Z} \operatorname{Aut}(\Bbb{Z}_n)\ncong \Bbb{Z}/8\Bbb{Z} n \operatorname{Aut}(D_4)\cong D_4 \operatorname{Aut}(G)\cong \Bbb{Z}/8\Bbb{Z} G G C_8,"['abstract-algebra', 'group-theory', 'examples-counterexamples', 'abelian-groups', 'automorphism-group']"
94,What are the primary disadvantages of Dummit and Foote's abstract algebra text (3rd ed.)?,What are the primary disadvantages of Dummit and Foote's abstract algebra text (3rd ed.)?,,"I have done a fair amount of research concerning which abstract algebra book to ""settle down into""; that is, I wanted to pick an algebra text and really commit to it as my ""primary text,"" more or less, and I have chosen Dummit and Foote's 3rd edition of Abstract Algebra . My goal is to obtain a solid foundation in algebra at the beginning graduate level (I am self-learning). I have gone through a fair amount of John Durbin's Modern Algebra (6th ed.), but I know this is more of a ""warm-up text."" I have heard of algebra books by Herstein, Artin, etc., but I am no longer interested in a comparative analysis. What are the chief drawbacks of using Dummit and Foote's text as my primary algebra text? I know it has been criticized for being somewhat bland, but that it has a ton of excellent problems and examples and is fairly encyclopedic. I am more interested in mathematical drawbacks. Do they leave out any important topics in modern algebra? Does the book have extensive errata? Basically, what are the downsides of using this text? Preferably, I'd like to hear from people who have used this text before and have some background in abstract algebra who can look at my question from a more retrospective outlook.","I have done a fair amount of research concerning which abstract algebra book to ""settle down into""; that is, I wanted to pick an algebra text and really commit to it as my ""primary text,"" more or less, and I have chosen Dummit and Foote's 3rd edition of Abstract Algebra . My goal is to obtain a solid foundation in algebra at the beginning graduate level (I am self-learning). I have gone through a fair amount of John Durbin's Modern Algebra (6th ed.), but I know this is more of a ""warm-up text."" I have heard of algebra books by Herstein, Artin, etc., but I am no longer interested in a comparative analysis. What are the chief drawbacks of using Dummit and Foote's text as my primary algebra text? I know it has been criticized for being somewhat bland, but that it has a ton of excellent problems and examples and is fairly encyclopedic. I am more interested in mathematical drawbacks. Do they leave out any important topics in modern algebra? Does the book have extensive errata? Basically, what are the downsides of using this text? Preferably, I'd like to hear from people who have used this text before and have some background in abstract algebra who can look at my question from a more retrospective outlook.",,"['abstract-algebra', 'soft-question', 'self-learning', 'education']"
95,Prerequisites for Differential Galois theory,Prerequisites for Differential Galois theory,,"I would like to know the prerequisites for Differential Galois theory. I have taken Rings, Fields, Groups, Galois theory, and Algebraic Geometry + Commutative Algebra. Looking at the wikipedia page , I have never studied Lie groups. Is it at all possible to pick it up while I study Differential Galois theory?","I would like to know the prerequisites for Differential Galois theory. I have taken Rings, Fields, Groups, Galois theory, and Algebraic Geometry + Commutative Algebra. Looking at the wikipedia page , I have never studied Lie groups. Is it at all possible to pick it up while I study Differential Galois theory?",,"['abstract-algebra', 'galois-theory', 'differential-algebra']"
96,What nice properties does exponentiation have?,What nice properties does exponentiation have?,,"Exponentiation of course satisfies a number of nontrivial identities: $x^{y+z}=x^yx^z$ $(x^y)^z=x^{yz}$ $x^0=1$, $x^1=x$ However, these identities all involve functions other than exponentiation (I'm thinking of $0$ and $1$ as nullary functions, here). My question is what identities hold of exponentiation alone . That is: What is the equational theory of $(\mathbb{N}, exp)$? To be clear, I mean ""identity"" in the strict, universal-algebraic sense: one term equals another term, where each term is built from variables and exponentiation alone. Also, an identity has to hold on all of $\mathbb{N}$: identities which hold only on, say, numbers divisible by $17$ don't count. A related question: Is that theory axiomatized by finitely many equations? Note: A previous version of this question asked whether there were any nontrivial identities at all. This was extremely silly of me, as pointed out almost immediately by Stefan Perko below: $(x^y)^z=(x^z)^y$.","Exponentiation of course satisfies a number of nontrivial identities: $x^{y+z}=x^yx^z$ $(x^y)^z=x^{yz}$ $x^0=1$, $x^1=x$ However, these identities all involve functions other than exponentiation (I'm thinking of $0$ and $1$ as nullary functions, here). My question is what identities hold of exponentiation alone . That is: What is the equational theory of $(\mathbb{N}, exp)$? To be clear, I mean ""identity"" in the strict, universal-algebraic sense: one term equals another term, where each term is built from variables and exponentiation alone. Also, an identity has to hold on all of $\mathbb{N}$: identities which hold only on, say, numbers divisible by $17$ don't count. A related question: Is that theory axiomatized by finitely many equations? Note: A previous version of this question asked whether there were any nontrivial identities at all. This was extremely silly of me, as pointed out almost immediately by Stefan Perko below: $(x^y)^z=(x^z)^y$.",,"['abstract-algebra', 'logic', 'exponentiation', 'universal-algebra']"
97,Algebraic fixed point theorem,Algebraic fixed point theorem,,"I was wondering if there are some ""algebraic"" fixed point theorems, in group theory. More precisely, given a group $G$ and a group morphism $f : G \to G$, what conditions on $G$ and $f$ should we demand, so that $f$ has a non-trivial fixed point (i.e. $\exists x \neq 1_G, f(x)=x$) ? Here are my thoughts : This  non-trivial fixed point condition  is sometimes a strong condition. For instance, if $G = \mathbb Z$, then the only $f \in \text{Hom}(G,G)$ to have a non-trivial fixed point is the identity. The set of fixed point $\{y \in G \mid f(y)=y\}$ is a subgroup of $G$. Let $G = \mathbb Z / n\mathbb Z$. Assume that $n=ab$ with $a,b>1$. If $f([1]_n) = [a+1]_n$, then $f$ has a non trivial fixed point, namely $x=[b]_n$. This question may be artificial ; I don't know if a morphism with a non trivial fixed point can be useful in other contexts... I don't see a natural way to turn this problem into a  group action  problem (to get some results about fixed points). I tried $G \curvearrowright \text{Im}(f)$ by defining $g \bullet f(x) := f(g)f(x) = f(gx)$, but this doesn't seem to help... Thank you in advance !","I was wondering if there are some ""algebraic"" fixed point theorems, in group theory. More precisely, given a group $G$ and a group morphism $f : G \to G$, what conditions on $G$ and $f$ should we demand, so that $f$ has a non-trivial fixed point (i.e. $\exists x \neq 1_G, f(x)=x$) ? Here are my thoughts : This  non-trivial fixed point condition  is sometimes a strong condition. For instance, if $G = \mathbb Z$, then the only $f \in \text{Hom}(G,G)$ to have a non-trivial fixed point is the identity. The set of fixed point $\{y \in G \mid f(y)=y\}$ is a subgroup of $G$. Let $G = \mathbb Z / n\mathbb Z$. Assume that $n=ab$ with $a,b>1$. If $f([1]_n) = [a+1]_n$, then $f$ has a non trivial fixed point, namely $x=[b]_n$. This question may be artificial ; I don't know if a morphism with a non trivial fixed point can be useful in other contexts... I don't see a natural way to turn this problem into a  group action  problem (to get some results about fixed points). I tried $G \curvearrowright \text{Im}(f)$ by defining $g \bullet f(x) := f(g)f(x) = f(gx)$, but this doesn't seem to help... Thank you in advance !",,"['abstract-algebra', 'group-theory', 'fixed-point-theorems']"
98,"What is ""Field with One Element""?","What is ""Field with One Element""?",,"I was reading the Wikipedia article about The Field with One Element and I came across the following quotes: ""... $F_1$ refers to the idea that there should be a way to replace sets and operations, the traditional building blocks for abstract algebra, with other, more flexible objects."" ""most proposed theories of $F_1$ replace abstract algebra entirely"" I wonder what would the definitions of Algebraic Structures like fields, vector spaces, groups, rings..etc look like if The Field with One Element does exist? is ""The Field with One Element"" itself, if does exist, an Algebraic Structure?","I was reading the Wikipedia article about The Field with One Element and I came across the following quotes: ""... refers to the idea that there should be a way to replace sets and operations, the traditional building blocks for abstract algebra, with other, more flexible objects."" ""most proposed theories of replace abstract algebra entirely"" I wonder what would the definitions of Algebraic Structures like fields, vector spaces, groups, rings..etc look like if The Field with One Element does exist? is ""The Field with One Element"" itself, if does exist, an Algebraic Structure?",F_1 F_1,"['abstract-algebra', 'soft-question']"
99,Galois group of the quintic polynomial $X^5+X+1$,Galois group of the quintic polynomial,X^5+X+1,"I'm trying to find the Galois group of the polynomial $p(X)= X^5+X+1$ over $\mathbb Q$. First, one notes that, if $\omega$ is a primitive cubic root of unity, then it is a root of $p(X)$. So, $X^2+X+1$ is a factor of $p(X)$. We have the following factorisation: \begin{equation} p(X) = (X^2+X+1)(X^3-X^2+1). \end{equation} Now, the derivative of $p(X)$ is $p'(X) = X^4+1$, which is always positive. Hence, $p(X)$ has only one real root, which is a root $\alpha$ of $X^3-X^2+1$. Let me denote by $\eta$ and $\overline{\eta}$ the other two complex roots of $X^3-X^2+1$. Then, a splitting field of $p(X)$ over $\mathbb Q$ is clearly given by \begin{equation} K = \mathbb Q(\alpha, \omega, \eta). \end{equation} Next, I have to compute the degree $[K : \mathbb Q]$ of the extension. It is simple to prove that $[\mathbb Q(\alpha, \eta) : \mathbb Q] = 6$: in fact, $\mathbb Q(\alpha, \eta)$ is a splitting field of $X^3-X^2+1$ over $\mathbb Q$, and this polynomial has only one real root. So, I try to compute as follows: \begin{equation} [K : \mathbb Q] = [K : \mathbb Q(\alpha,\eta)][\mathbb Q(\alpha, \eta) : \mathbb Q]. \end{equation} Here comes my problem: clearly, the degree $[K : \mathbb Q(\alpha,\eta)]$ is $1$ or $2$. The point is to understand whether $\omega \in \mathbb Q(\alpha, \eta)$ or not, and I'm unable to give an answer. I think that actually $[K : \mathbb Q(\alpha,\eta)] = 2$, and that eventually one can prove that the Galois group $\mathrm{Gal}(K | \mathbb Q)$ is isomorphic to $S_3 \times C_2$. How can I prove this?","I'm trying to find the Galois group of the polynomial $p(X)= X^5+X+1$ over $\mathbb Q$. First, one notes that, if $\omega$ is a primitive cubic root of unity, then it is a root of $p(X)$. So, $X^2+X+1$ is a factor of $p(X)$. We have the following factorisation: \begin{equation} p(X) = (X^2+X+1)(X^3-X^2+1). \end{equation} Now, the derivative of $p(X)$ is $p'(X) = X^4+1$, which is always positive. Hence, $p(X)$ has only one real root, which is a root $\alpha$ of $X^3-X^2+1$. Let me denote by $\eta$ and $\overline{\eta}$ the other two complex roots of $X^3-X^2+1$. Then, a splitting field of $p(X)$ over $\mathbb Q$ is clearly given by \begin{equation} K = \mathbb Q(\alpha, \omega, \eta). \end{equation} Next, I have to compute the degree $[K : \mathbb Q]$ of the extension. It is simple to prove that $[\mathbb Q(\alpha, \eta) : \mathbb Q] = 6$: in fact, $\mathbb Q(\alpha, \eta)$ is a splitting field of $X^3-X^2+1$ over $\mathbb Q$, and this polynomial has only one real root. So, I try to compute as follows: \begin{equation} [K : \mathbb Q] = [K : \mathbb Q(\alpha,\eta)][\mathbb Q(\alpha, \eta) : \mathbb Q]. \end{equation} Here comes my problem: clearly, the degree $[K : \mathbb Q(\alpha,\eta)]$ is $1$ or $2$. The point is to understand whether $\omega \in \mathbb Q(\alpha, \eta)$ or not, and I'm unable to give an answer. I think that actually $[K : \mathbb Q(\alpha,\eta)] = 2$, and that eventually one can prove that the Galois group $\mathrm{Gal}(K | \mathbb Q)$ is isomorphic to $S_3 \times C_2$. How can I prove this?",,"['abstract-algebra', 'polynomials', 'galois-theory']"
