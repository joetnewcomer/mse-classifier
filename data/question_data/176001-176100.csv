,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is there a counterexample to the claim that if $\mathbf y\cdot\mathbf y=1$ and $\mathbf x\cdot\mathbf y=c$ then $\mathbf x=c\mathbf y$?,Is there a counterexample to the claim that if  and  then ?,\mathbf y\cdot\mathbf y=1 \mathbf x\cdot\mathbf y=c \mathbf x=c\mathbf y,"Let $x,y$ be arbitrary vectors where $\mathbf{y} \cdot \mathbf{y} = 1$ and $c$ be a real valued scalar. If $\mathbf{x} \cdot \mathbf{y} = c = c (\mathbf{y} \cdot \mathbf{y} ) = (c \mathbf{y} ) \cdot \mathbf{y} $, then $\mathbf{x} = c \mathbf{y}$ Is this true? Feels like a sloppy conclusion no?","Let $x,y$ be arbitrary vectors where $\mathbf{y} \cdot \mathbf{y} = 1$ and $c$ be a real valued scalar. If $\mathbf{x} \cdot \mathbf{y} = c = c (\mathbf{y} \cdot \mathbf{y} ) = (c \mathbf{y} ) \cdot \mathbf{y} $, then $\mathbf{x} = c \mathbf{y}$ Is this true? Feels like a sloppy conclusion no?",,"['linear-algebra', 'multivariable-calculus', 'vector-analysis']"
1,Is curl of a given vector always perpendicular to the given vector field?,Is curl of a given vector always perpendicular to the given vector field?,,As we know cross product of any two vectors yields a vector perpendicular to plane containing both the vectors so is it same for the vector operator del crossed with a vector  ∇ × F (curl of vector field F). if not why?,As we know cross product of any two vectors yields a vector perpendicular to plane containing both the vectors so is it same for the vector operator del crossed with a vector  ∇ × F (curl of vector field F). if not why?,,"['multivariable-calculus', 'vectors', 'vector-analysis']"
2,Evaluate $\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx$ using a double integral,Evaluate  using a double integral,\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx,"I was given the following problem: Evaluate the following integrate using a double integral: $\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx$. The professor told us off the bat the answer was $\ln(2)$. He wants us to show our work and prove this is true. My attempt is below. $I(x)$=$\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx$ = $\int_0^{\infty}\frac{e^{-y}-e^{-2y}}{y}dy$ =$I(y)$. Thus I can say $=I(x)=\sqrt{I(x)I(y)}$ \begin{eqnarray} \int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx &=&\sqrt{\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx\int_0^{\infty}\frac{e^{-y}-e^{-2y}}{y}dy}\\ & = & \sqrt{\int_0^{\infty}\int_0^{\infty}\frac{(e^{-x}-e^{-2x})(e^{-y}-e^{-2y})}{xy}dxdy} \end{eqnarray} This is where things get a little nasty. I can decided to make a change of variables. Letting $x=r\cos{\theta}$, $y=r\sin{\theta}$, thus $dA=dxdy=rdrd\theta$ by the Jacobian. Thus: \begin{eqnarray} \int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx & = & \sqrt{\int_0^{2\pi}\int_0^{\infty}\frac{(e^{-r\cos{\theta}}-e^{-2r\cos{\theta}})(e^{-r\sin{\theta}}-e^{-2r\sin{\theta}})}{r^2\cos{\theta}\sin{\theta}}rdrd\theta}\\ & = & \sqrt{\int_0^{2\pi}\int_0^{\infty}\frac{(e^{-r(\cos{\theta}+\sin{\theta})}-e^{-r(2\cos{\theta}+\sin{\theta})}-e^{-r(\cos{\theta}+2\sin{\theta})}-e^{-2r(\cos{\theta}+\sin{\theta})}}{r\cos{\theta}\sin{\theta}}drd\theta} \end{eqnarray} This is where I am stuck. From here I did a lot of trial and error trying to solve for the problem. From changing the order of integration, integration by parts, and subsitution. Is there something I am missing? Maybe a trig identity that will help simplify the expression. Thank You for your time and I greatly appreciate any feedback you give me.","I was given the following problem: Evaluate the following integrate using a double integral: $\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx$. The professor told us off the bat the answer was $\ln(2)$. He wants us to show our work and prove this is true. My attempt is below. $I(x)$=$\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx$ = $\int_0^{\infty}\frac{e^{-y}-e^{-2y}}{y}dy$ =$I(y)$. Thus I can say $=I(x)=\sqrt{I(x)I(y)}$ \begin{eqnarray} \int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx &=&\sqrt{\int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx\int_0^{\infty}\frac{e^{-y}-e^{-2y}}{y}dy}\\ & = & \sqrt{\int_0^{\infty}\int_0^{\infty}\frac{(e^{-x}-e^{-2x})(e^{-y}-e^{-2y})}{xy}dxdy} \end{eqnarray} This is where things get a little nasty. I can decided to make a change of variables. Letting $x=r\cos{\theta}$, $y=r\sin{\theta}$, thus $dA=dxdy=rdrd\theta$ by the Jacobian. Thus: \begin{eqnarray} \int_0^{\infty}\frac{e^{-x}-e^{-2x}}{x}dx & = & \sqrt{\int_0^{2\pi}\int_0^{\infty}\frac{(e^{-r\cos{\theta}}-e^{-2r\cos{\theta}})(e^{-r\sin{\theta}}-e^{-2r\sin{\theta}})}{r^2\cos{\theta}\sin{\theta}}rdrd\theta}\\ & = & \sqrt{\int_0^{2\pi}\int_0^{\infty}\frac{(e^{-r(\cos{\theta}+\sin{\theta})}-e^{-r(2\cos{\theta}+\sin{\theta})}-e^{-r(\cos{\theta}+2\sin{\theta})}-e^{-2r(\cos{\theta}+\sin{\theta})}}{r\cos{\theta}\sin{\theta}}drd\theta} \end{eqnarray} This is where I am stuck. From here I did a lot of trial and error trying to solve for the problem. From changing the order of integration, integration by parts, and subsitution. Is there something I am missing? Maybe a trig identity that will help simplify the expression. Thank You for your time and I greatly appreciate any feedback you give me.",,"['calculus', 'multivariable-calculus', 'trigonometry']"
3,Find $\frac{\partial z}{\partial x}$ if $xy+yz+zx = 1$,Find  if,\frac{\partial z}{\partial x} xy+yz+zx = 1,"Find $\frac{\partial z}{\partial x}$ if $xy+yz+zx = 1$ I don't understand this question at first. It looks like $x,y,z $ are dependent. So we proceed differentiation partially wrt x: $$xy_x +y + y_x z + z_x y + z_x x+z=0$$ This gives $$z_x = \frac{-z-y-y_xz-xy_x}{x+y}$$ But given answer is $\frac{-z-y}{x+y}$, meaning that they take $y_x = 0$, saying that $y$ and $x$ independent. But how this makes sense, then why not take $z$ and $x$ also dependent and say $z_x = 0$ ? Please tell me the reasoning! I think that they mean to say treat $y$ as constant when finding $z_x$","Find $\frac{\partial z}{\partial x}$ if $xy+yz+zx = 1$ I don't understand this question at first. It looks like $x,y,z $ are dependent. So we proceed differentiation partially wrt x: $$xy_x +y + y_x z + z_x y + z_x x+z=0$$ This gives $$z_x = \frac{-z-y-y_xz-xy_x}{x+y}$$ But given answer is $\frac{-z-y}{x+y}$, meaning that they take $y_x = 0$, saying that $y$ and $x$ independent. But how this makes sense, then why not take $z$ and $x$ also dependent and say $z_x = 0$ ? Please tell me the reasoning! I think that they mean to say treat $y$ as constant when finding $z_x$",,"['multivariable-calculus', 'partial-derivative']"
4,"How do I calculate a double integral like $\iint_\mathbf{D}e^{\frac{x-y}{x+y}}dx\,dy$?",How do I calculate a double integral like ?,"\iint_\mathbf{D}e^{\frac{x-y}{x+y}}dx\,dy","The Problem is to integrate the following double integral $\displaystyle\iint_\mathbf{D}\exp\left(\frac{x-y}{x+y}\right) dx\, dy$ using the technique of transformation of variables ( $u$ and $v$ ). There is a given $D$ with $D:= \{(x,y):\ x\geq 0,\ y \geq 0,\ x+y \leq 1\}$ My Approach: wasn't quite successful at all. I am quite familar with calculus, but i am stuck at multiple integrals. I thought about the following transformation: $u = x-y$ and $v = x+y$ But i don't know the next step. Another suggestion: i thought about the integration of the e-Function. I have in mind that $\int e^x dx = e^x$ . So maybe: $$\iint_\mathbf{D} \exp\left(\frac{x-y}{x+y}\right) dx\ dy = \exp\left(\frac{x-y}{x+y}\right) ?$$","The Problem is to integrate the following double integral using the technique of transformation of variables ( and ). There is a given with My Approach: wasn't quite successful at all. I am quite familar with calculus, but i am stuck at multiple integrals. I thought about the following transformation: and But i don't know the next step. Another suggestion: i thought about the integration of the e-Function. I have in mind that . So maybe:","\displaystyle\iint_\mathbf{D}\exp\left(\frac{x-y}{x+y}\right) dx\, dy u v D D:= \{(x,y):\ x\geq 0,\ y \geq 0,\ x+y \leq 1\} u = x-y v = x+y \int e^x dx = e^x \iint_\mathbf{D} \exp\left(\frac{x-y}{x+y}\right) dx\ dy = \exp\left(\frac{x-y}{x+y}\right) ?","['integration', 'multivariable-calculus', 'multiple-integral']"
5,"Proving that $\iint\frac{x-y}{(x+y)^3}\,dx\,dy$ does not exist over $0 \leq x \leq 1 , 0 \leq y \leq 1$",Proving that  does not exist over,"\iint\frac{x-y}{(x+y)^3}\,dx\,dy 0 \leq x \leq 1 , 0 \leq y \leq 1","To prove that double integral does not exist: $$\iint\frac{x-y}{(x+y)^2}\,dx\,dy$$ over region $0 \leq x \leq 1 , 0 \leq y \leq 1$ . I put $x - y = u$ and $x+y = v$ and I got integral as $$\iint \frac{u}{v^3}\,du\,dv$$ Limits of $u$ are from $2-v \leq u\leq v-2$ and $v$ are from $0$ to $1$ . I am not sure about my new limits and how to prove it further. EDIT : The correct expression is $\iint\frac{x-y}{(x+y)^3}\,dx\,dy$",To prove that double integral does not exist: over region . I put and and I got integral as Limits of are from and are from to . I am not sure about my new limits and how to prove it further. EDIT : The correct expression is,"\iint\frac{x-y}{(x+y)^2}\,dx\,dy 0 \leq x \leq 1 , 0 \leq y \leq 1 x - y = u x+y = v \iint \frac{u}{v^3}\,du\,dv u 2-v \leq u\leq v-2 v 0 1 \iint\frac{x-y}{(x+y)^3}\,dx\,dy","['multivariable-calculus', 'multiple-integral']"
6,Prove or disprove this calculus limit result by geometric approach,Prove or disprove this calculus limit result by geometric approach,,"my question is: Could we prove the this conversion of variable work by my formula on the bottom? $$\iint_R f(r,\theta) \ dxdy = \int_a^b \int_0^{r(\theta)} f(r,\theta) r (dr)\ d\theta$$ as $d r$ and $d \theta$ approach $0$. Prove or disprove that: $$((r+\Delta r) \cos(a +\Delta \theta) -r \cos a) \cdot ((r+\Delta r) \sin(a + \Delta \theta) -r \sin a) / (r \;\Delta \theta \; \Delta r)=1 .$$ where the variable represent as in this graph : as $\Delta r $ and $\Delta \theta$ approach $0$ This question is inspired from $dx\;dy=r \;dr \;d \theta$.","my question is: Could we prove the this conversion of variable work by my formula on the bottom? $$\iint_R f(r,\theta) \ dxdy = \int_a^b \int_0^{r(\theta)} f(r,\theta) r (dr)\ d\theta$$ as $d r$ and $d \theta$ approach $0$. Prove or disprove that: $$((r+\Delta r) \cos(a +\Delta \theta) -r \cos a) \cdot ((r+\Delta r) \sin(a + \Delta \theta) -r \sin a) / (r \;\Delta \theta \; \Delta r)=1 .$$ where the variable represent as in this graph : as $\Delta r $ and $\Delta \theta$ approach $0$ This question is inspired from $dx\;dy=r \;dr \;d \theta$.",,['multivariable-calculus']
7,Reference Request: Differentials of Operators,Reference Request: Differentials of Operators,,"Consider, for example, the map $f: \mathbb{R}^{n \times n} \rightarrow \mathbb{R}^{n \times n}, f(A) = A^2.$ Then its differential is $df(A)(T) = AT+TA$ . I would like a reference that states what this differential means and then how to obtain such results, but not necessarily in a completely rigorous way. I also understand that differentials can be defined and manipulated in the usual way for functionals (e.g. for the Lagrangian, leading to the Euler-Lagrange equations) and I'd like to see this done without developing the whole machinery of variational calculus. In short, I'm looking for a clear treatment of differentials of operator-valued functions. I've tried looking up books on matrix calculus,  calculus on normed vector spaces and variational calculus but haven't found anything suitable (the closest option was Cartan's Differential Calculus , but I'd like something more concrete). Where do people learn this sort of thing?","Consider, for example, the map Then its differential is . I would like a reference that states what this differential means and then how to obtain such results, but not necessarily in a completely rigorous way. I also understand that differentials can be defined and manipulated in the usual way for functionals (e.g. for the Lagrangian, leading to the Euler-Lagrange equations) and I'd like to see this done without developing the whole machinery of variational calculus. In short, I'm looking for a clear treatment of differentials of operator-valued functions. I've tried looking up books on matrix calculus,  calculus on normed vector spaces and variational calculus but haven't found anything suitable (the closest option was Cartan's Differential Calculus , but I'd like something more concrete). Where do people learn this sort of thing?","f: \mathbb{R}^{n \times n} \rightarrow \mathbb{R}^{n \times n}, f(A) = A^2. df(A)(T) = AT+TA","['real-analysis', 'linear-algebra']"
8,Evaluation of a particular type of integral involving logs and trigonometric function,Evaluation of a particular type of integral involving logs and trigonometric function,,Is there any closed form for  $$ \int _0 ^{\infty}\int _0 ^{\infty}\int _0 ^{\infty} \log(x)\log(y)\log(z)\cos(x^2+y^2+z^2)dzdydx$$ if yes then how to prove it?,Is there any closed form for  $$ \int _0 ^{\infty}\int _0 ^{\infty}\int _0 ^{\infty} \log(x)\log(y)\log(z)\cos(x^2+y^2+z^2)dzdydx$$ if yes then how to prove it?,,"['integration', 'multivariable-calculus', 'definite-integrals', 'improper-integrals']"
9,"Example of a function $f:\mathbb{R}^2\to\mathbb{R}$ not differentiable at $(0,0)$, but has a directional derivative at $(0,0)$ in all directions","Example of a function  not differentiable at , but has a directional derivative at  in all directions","f:\mathbb{R}^2\to\mathbb{R} (0,0) (0,0)","Give an example of a function $f:\mathbb{R}^2\to\mathbb{R}$ such that $f'_u(0,0)$ exists in all directions $\|u\| = 1$, but $f$ is not differentiable at $(0,0)$. You have to show that your example satisfy the above requirement.","Give an example of a function $f:\mathbb{R}^2\to\mathbb{R}$ such that $f'_u(0,0)$ exists in all directions $\|u\| = 1$, but $f$ is not differentiable at $(0,0)$. You have to show that your example satisfy the above requirement.",,"['real-analysis', 'multivariable-calculus']"
10,How can I find $\int_{\sqrt2/2}^{1}\int_{\sqrt{1-x^2}}^{x}\frac{1}{\sqrt{x^2+y^2}}dydx$?,How can I find ?,\int_{\sqrt2/2}^{1}\int_{\sqrt{1-x^2}}^{x}\frac{1}{\sqrt{x^2+y^2}}dydx,"My question is ; How can I solve the following integral question? $\displaystyle \int_{\sqrt2/2}^{1}\int_{\sqrt{1-x^2}}^{x}\frac{1}{\sqrt{x^2+y^2}}dydx$ Thanks in advance,","My question is ; How can I solve the following integral question? $\displaystyle \int_{\sqrt2/2}^{1}\int_{\sqrt{1-x^2}}^{x}\frac{1}{\sqrt{x^2+y^2}}dydx$ Thanks in advance,",,"['integration', 'multivariable-calculus']"
11,Why is differentiability defined on multivariable functions this way?,Why is differentiability defined on multivariable functions this way?,,"I am told that a function $f:\mathbb{R}^{n}\to \mathbb{R}$ is differentiable at a point $\mathbf{x}=(x_1,x_2,...,x_n)$ if $\Delta f$ is of form $$\sum_{i}^{n}\frac{\partial f}{\partial x_i}\Delta x_i+\sum_{i}^{n} \epsilon_i \Delta x_i$$ Where $$\lim_{\mathbf{\Delta x}\to \mathbf{0}}\epsilon_{i}=0$$ for every $1\leq i\leq n$ . It seems arduous to me to use such a definition. Why don't mathematicians define differentiability by the existence of partial derivatives, which seems natural? Now, I am aware that I can define things how I want to, but my goal is to understand why it is commonly defined this way. Are there some underlying properties that make this definition superior?","I am told that a function is differentiable at a point if is of form Where for every . It seems arduous to me to use such a definition. Why don't mathematicians define differentiability by the existence of partial derivatives, which seems natural? Now, I am aware that I can define things how I want to, but my goal is to understand why it is commonly defined this way. Are there some underlying properties that make this definition superior?","f:\mathbb{R}^{n}\to \mathbb{R} \mathbf{x}=(x_1,x_2,...,x_n) \Delta f \sum_{i}^{n}\frac{\partial f}{\partial x_i}\Delta x_i+\sum_{i}^{n} \epsilon_i \Delta x_i \lim_{\mathbf{\Delta x}\to \mathbf{0}}\epsilon_{i}=0 1\leq i\leq n","['calculus', 'multivariable-calculus']"
12,Fake proof of differentiability,Fake proof of differentiability,,"It's a theorem that if $f\colon U\subset\Bbb R^n\to \Bbb R^m$ has the property that each of the partial derivatives $\partial_if_j$ exist and are continuous $p\in U$ , then $f$ is differentiable at $p$ . When I was trying to prove this, I came up with the following ""proof"" which doesn't use the  continuity hypothesis. Can someone tell me what's wrong with this proof? Since $f_j$ is differentiable at $p$ , we can write $$ f_j(p+v) = f_j(p) + \sum_i \partial_if_j(p)v_i + R_j(v), $$ where $|R_j(v)|/|v| \to 0$ as $v\to 0$ . Hence, we can write \begin{align*} f(p+v) &= f(p) + \big(\sum_i \partial_if_1(p)v_i + R_1(v),\dots,\sum_i \partial_if_m(p)v_i + R_m(v)\big) \\ &= f(p) + \sum_j\big(\sum_i\partial_if_j(p)v_i\big)e_j + R_j(v)e_j \\ &= f(p) + [Df_p][v] + (R_1,\dots,R_m)(v), \end{align*} where $[Df_p] = [\partial_if_j(p)]$ is the usual Jacobian  matrix, and $[v]$ is the column vector $[v_1\ \dotsb\ v_n]^T$ . Now, $$ \frac{|(R_1,\dots,R_m)(v)|^2}{|v|^2} = \frac{R_1(v)^2 + \dots + R_m(v)^2}{|v|^2} \to 0, $$ where the last expression goes to $0$ as $v\to 0$ since it is a sum of finitely many terms, each of which goes to $0$ . Hence we have written $f(p+v)$ as a sum of a constant term, a linear part, and a sublinear piece, so $f$ is differentiable at $p$ . At no point did I explicitly use the continuity hypothesis, so what exactly is wrong with this proof? Best.","It's a theorem that if has the property that each of the partial derivatives exist and are continuous , then is differentiable at . When I was trying to prove this, I came up with the following ""proof"" which doesn't use the  continuity hypothesis. Can someone tell me what's wrong with this proof? Since is differentiable at , we can write where as . Hence, we can write where is the usual Jacobian  matrix, and is the column vector . Now, where the last expression goes to as since it is a sum of finitely many terms, each of which goes to . Hence we have written as a sum of a constant term, a linear part, and a sublinear piece, so is differentiable at . At no point did I explicitly use the continuity hypothesis, so what exactly is wrong with this proof? Best.","f\colon U\subset\Bbb R^n\to \Bbb R^m \partial_if_j p\in U f p f_j p 
f_j(p+v) = f_j(p) + \sum_i \partial_if_j(p)v_i + R_j(v),
 |R_j(v)|/|v| \to 0 v\to 0 \begin{align*}
f(p+v) &= f(p) + \big(\sum_i \partial_if_1(p)v_i + R_1(v),\dots,\sum_i \partial_if_m(p)v_i + R_m(v)\big) \\
&= f(p) + \sum_j\big(\sum_i\partial_if_j(p)v_i\big)e_j + R_j(v)e_j \\
&= f(p) + [Df_p][v] + (R_1,\dots,R_m)(v),
\end{align*} [Df_p] = [\partial_if_j(p)] [v] [v_1\ \dotsb\ v_n]^T 
\frac{|(R_1,\dots,R_m)(v)|^2}{|v|^2} = \frac{R_1(v)^2 + \dots + R_m(v)^2}{|v|^2} \to 0,
 0 v\to 0 0 f(p+v) f p","['real-analysis', 'multivariable-calculus', 'derivatives', 'proof-verification']"
13,Lagrange multiplier plus or minus,Lagrange multiplier plus or minus,,"I am working through different tutorials about Lagrange multiplier and came upon a problem. It seems like that there's different ways to solve. You have a given equation $f(x,y)$ and a constraint $g(x,y)$. A few tutorials then start to set the derivatives respect to $x$ and $y$ of $\lambda\,g(x,y)$ and $f(x,y)$ equal to each other and start solving for variables: $$f(x,y)= \lambda\,g(x,y) \tag{1}$$ or use a form of $$F(x,y,\lambda)=f(x,y)  - \lambda \,g(x,y)\tag2$$ which is basically the same since you can subtract the right hand side of $(1)$ and derive $(2)$. Other tutorials use a form of $$F(x,y,\lambda)= f(x,y) + \lambda\,g(x,y)\tag3$$ So the main difference is the minus and the plus in their form and I am not sure which one to use. I have found multiple examples for both, so it's not a single mistake by one of the tutors. So which one is the correct one: $(2)$ or $(3)$? sources for $(1)$, $(2)$: A , B sources for $(3)$: C , D","I am working through different tutorials about Lagrange multiplier and came upon a problem. It seems like that there's different ways to solve. You have a given equation $f(x,y)$ and a constraint $g(x,y)$. A few tutorials then start to set the derivatives respect to $x$ and $y$ of $\lambda\,g(x,y)$ and $f(x,y)$ equal to each other and start solving for variables: $$f(x,y)= \lambda\,g(x,y) \tag{1}$$ or use a form of $$F(x,y,\lambda)=f(x,y)  - \lambda \,g(x,y)\tag2$$ which is basically the same since you can subtract the right hand side of $(1)$ and derive $(2)$. Other tutorials use a form of $$F(x,y,\lambda)= f(x,y) + \lambda\,g(x,y)\tag3$$ So the main difference is the minus and the plus in their form and I am not sure which one to use. I have found multiple examples for both, so it's not a single mistake by one of the tutors. So which one is the correct one: $(2)$ or $(3)$? sources for $(1)$, $(2)$: A , B sources for $(3)$: C , D",,"['multivariable-calculus', 'lagrange-multiplier', 'maxima-minima']"
14,Trouble with double integration,Trouble with double integration,,"I'm simply trying to compute the following double integral: $$ \int_1^4\int_0^3\ (\ x\ +\ 2y\ )\ dx\ dy $$ And here are my steps: $$ \int_1^4\ \left.(\ \frac{1}{2}x^2\ +\ 2xy\ )\right|_0^3\ dy $$ $$ \int_1^4\ (\ \frac{9}{2}\ +\ 6y\ )\ dy $$ $$ \frac{9}{2}\ +\ 6\int_1^4\ y\ dy $$ $$ \frac{9}{2}\ +\ 6\ \frac{1}{2}\left.(\ y^2\ )\right|_1^4 $$ $$ \frac{9}{2}\ +\ 3(\ 16\ -\ 1\ ) $$ $$ \frac{9}{2}\ +\ 3(\ 15\ ) $$ $$ \frac{9}{2}\ +\ 45 $$ $$ \frac{9\ + 90}{2} $$ $$ \frac{99}{2} $$ The answer according to my book is 117 / 2, however. $$ \int_1^4\int_0^3\ (\ x\ +\ 2y\ )\ dx\ dy\ =\ \frac{117}{2} $$ What am I doing wrong?","I'm simply trying to compute the following double integral: $$ \int_1^4\int_0^3\ (\ x\ +\ 2y\ )\ dx\ dy $$ And here are my steps: $$ \int_1^4\ \left.(\ \frac{1}{2}x^2\ +\ 2xy\ )\right|_0^3\ dy $$ $$ \int_1^4\ (\ \frac{9}{2}\ +\ 6y\ )\ dy $$ $$ \frac{9}{2}\ +\ 6\int_1^4\ y\ dy $$ $$ \frac{9}{2}\ +\ 6\ \frac{1}{2}\left.(\ y^2\ )\right|_1^4 $$ $$ \frac{9}{2}\ +\ 3(\ 16\ -\ 1\ ) $$ $$ \frac{9}{2}\ +\ 3(\ 15\ ) $$ $$ \frac{9}{2}\ +\ 45 $$ $$ \frac{9\ + 90}{2} $$ $$ \frac{99}{2} $$ The answer according to my book is 117 / 2, however. $$ \int_1^4\int_0^3\ (\ x\ +\ 2y\ )\ dx\ dy\ =\ \frac{117}{2} $$ What am I doing wrong?",,"['multivariable-calculus', 'multiple-integral']"
15,What is the normal vector to the plane ax+by+cz=d?,What is the normal vector to the plane ax+by+cz=d?,,"If d=0, then we obviously see that the equation is the Euclidean inner product with (a,b,c) and (x,y,z) that equals zero - and so (a,b,c) is the normal vector to the plane. What if $d \ne 0$? Then I don't have the same intuitive way of finding the normal - the ""inner product"" wouldn't be 0, and we couldn't conclude the orthogonality of the vectors. Thanks,","If d=0, then we obviously see that the equation is the Euclidean inner product with (a,b,c) and (x,y,z) that equals zero - and so (a,b,c) is the normal vector to the plane. What if $d \ne 0$? Then I don't have the same intuitive way of finding the normal - the ""inner product"" wouldn't be 0, and we couldn't conclude the orthogonality of the vectors. Thanks,",,"['calculus', 'multivariable-calculus', 'vector-analysis']"
16,Differentiable implies continuous - in more dimensions?,Differentiable implies continuous - in more dimensions?,,"I know that ""differentiable of function f in $x_0$ implies continuous of function f in $x_0$"". Can I use the same proof to show that it is valid for a function $f: M \to \mathbb{R}^m$ with $M \subseteq \mathbb{R}^n$ ? Since the definition of ""differentiable"" in ""one-dimensional"" is different from the definition of ""differentiable"" in ""more-dimensional"" i am not sure.","I know that ""differentiable of function f in $x_0$ implies continuous of function f in $x_0$"". Can I use the same proof to show that it is valid for a function $f: M \to \mathbb{R}^m$ with $M \subseteq \mathbb{R}^n$ ? Since the definition of ""differentiable"" in ""one-dimensional"" is different from the definition of ""differentiable"" in ""more-dimensional"" i am not sure.",,"['multivariable-calculus', 'derivatives', 'continuity']"
17,Line Integrals and Surface Integrals,Line Integrals and Surface Integrals,,"Can someone please explain what surface integrals and line integrals are measuring? Is a line integral the arc length along a surface, and a surface integral is the surface area? Also, why is a line integral equal to $0$ on a conservative closed path? Thank you!","Can someone please explain what surface integrals and line integrals are measuring? Is a line integral the arc length along a surface, and a surface integral is the surface area? Also, why is a line integral equal to $0$ on a conservative closed path? Thank you!",,"['multivariable-calculus', 'intuition']"
18,Double integral: $\int_{y=0}^1\int_{x=y}^1 e^{\large x^2}\ dx\ dy$,Double integral:,\int_{y=0}^1\int_{x=y}^1 e^{\large x^2}\ dx\ dy,Could someone help me with this question? I am stuck on it. Compute the following double integral: $$\int_{y=0}^1\int_{x=y}^1 e^{\large x^2}\ dx\ dy.$$ How to compute the integral when the inner integral is a form of error function? Thanks in advance for your help.,Could someone help me with this question? I am stuck on it. Compute the following double integral: $$\int_{y=0}^1\int_{x=y}^1 e^{\large x^2}\ dx\ dy.$$ How to compute the integral when the inner integral is a form of error function? Thanks in advance for your help.,,"['calculus', 'integration']"
19,"If $f: [0,1]\rightarrow \mathbb{R}$ is continuous function positive",If  is continuous function positive,"f: [0,1]\rightarrow \mathbb{R}","If $f: [0,1]\rightarrow \mathbb{R}$ is continuous function positive, so $$\int_{0}^{1} \frac{f(x)}{f(x)+f(1-x)}dx=\frac{1}{2}$$??? all examples that I tested have worked.","If $f: [0,1]\rightarrow \mathbb{R}$ is continuous function positive, so $$\int_{0}^{1} \frac{f(x)}{f(x)+f(1-x)}dx=\frac{1}{2}$$??? all examples that I tested have worked.",,"['calculus', 'real-analysis', 'multivariable-calculus']"
20,"Evaluate the triple integral, tetrahedron","Evaluate the triple integral, tetrahedron",,"$$\iiint_E x^2dV, \text{where E is the solid tetrahedron with vertices }(0,0,0), (1,0,0), (0,1,0), \text{and (0,0,1)}$$ I need some assistance on setting up the limits. If someone could help me learn how to set up my limits of integration, that would be great. I should be able to integrate it just fine.","$$\iiint_E x^2dV, \text{where E is the solid tetrahedron with vertices }(0,0,0), (1,0,0), (0,1,0), \text{and (0,0,1)}$$ I need some assistance on setting up the limits. If someone could help me learn how to set up my limits of integration, that would be great. I should be able to integrate it just fine.",,"['multivariable-calculus', 'integration']"
21,$f(U)=U$ but $f$ is not injective.,but  is not injective.,f(U)=U f,"I was given this exercise: Let $U=\{(x,y): 1<x^2+y^2<2\}$ and $f:U\rightarrow \mathbb {R^2}$ defined by: $$f(x,y)=\left(\frac {x^2-y^2}{r},\frac {2xy}{r}\right)$$ where $r=\sqrt {x^2+y^2}$. Then I have to show that $f(U)=U$ but $f$ is not injective... Think that polar coordinates might help.. but how? I'm kind stuck. Thanks for any help!","I was given this exercise: Let $U=\{(x,y): 1<x^2+y^2<2\}$ and $f:U\rightarrow \mathbb {R^2}$ defined by: $$f(x,y)=\left(\frac {x^2-y^2}{r},\frac {2xy}{r}\right)$$ where $r=\sqrt {x^2+y^2}$. Then I have to show that $f(U)=U$ but $f$ is not injective... Think that polar coordinates might help.. but how? I'm kind stuck. Thanks for any help!",,['multivariable-calculus']
22,"Showing that $ \frac{x\sin(y)-y\sin(x)}{x^2+y^2}\rightarrow_{(x,y)\to (0,0)}0$",Showing that," \frac{x\sin(y)-y\sin(x)}{x^2+y^2}\rightarrow_{(x,y)\to (0,0)}0","I would like to show that: $$ \frac{x\sin(y)-y\sin(x)}{x^2+y^2}\rightarrow_{(x,y)\to (0,0)}0$$ $$ \left| \frac{x\sin(y)-y\sin(x)}{x^2+y^2} \right| \leq \frac{2\vert xy \vert}{x^2+y^2} \leq 1$$ which is not sharp enough, obviously. How can I efficiently ""dominate"" the quantity $ \vert x\sin(y)-y\sin(x)\vert$ ?","I would like to show that: $$ \frac{x\sin(y)-y\sin(x)}{x^2+y^2}\rightarrow_{(x,y)\to (0,0)}0$$ $$ \left| \frac{x\sin(y)-y\sin(x)}{x^2+y^2} \right| \leq \frac{2\vert xy \vert}{x^2+y^2} \leq 1$$ which is not sharp enough, obviously. How can I efficiently ""dominate"" the quantity $ \vert x\sin(y)-y\sin(x)\vert$ ?",,"['real-analysis', 'multivariable-calculus']"
23,"For vectors in three-dimensional space, if $a \cdot b$ and $a \cdot c$ are equal, and $a \times b$ and $a \times c$ are equal, are b and c equal?","For vectors in three-dimensional space, if  and  are equal, and  and  are equal, are b and c equal?",a \cdot b a \cdot c a \times b a \times c,"For vectors in three-dimensional space, if $a \cdot b$ and $a \cdot c$ are equal, and $a \times b$ and $a \times c$ are equal, are b and c equal? I tried looking for counter-examples or using coordinate-by-coordinate proofs, but that didn't get me anywhere.","For vectors in three-dimensional space, if $a \cdot b$ and $a \cdot c$ are equal, and $a \times b$ and $a \times c$ are equal, are b and c equal? I tried looking for counter-examples or using coordinate-by-coordinate proofs, but that didn't get me anywhere.",,['multivariable-calculus']
24,Why is the derivative of $x^x$ not $\ln(x)(x^x)$?,Why is the derivative of  not ?,x^x \ln(x)(x^x),To do this I did $u=x$ and $\frac{dy}{du}=\ln(u)u^x$ and $\frac{du}{dx}=1$ and used the chain rule to get $\ln(x)(x^x)$ . A teacher explained that if $f(x)=\exp(g(x))$ then $f'(x)=g'(x)\exp(g(x))$ and used $\exp(\ln(x)x)$ . However I do not understand why my method of using the chain rule is incorrect and I do not understand the previous rule either. I have also seen a method using multivariable calculus that I do not understand either.,To do this I did and and and used the chain rule to get . A teacher explained that if then and used . However I do not understand why my method of using the chain rule is incorrect and I do not understand the previous rule either. I have also seen a method using multivariable calculus that I do not understand either.,u=x \frac{dy}{du}=\ln(u)u^x \frac{du}{dx}=1 \ln(x)(x^x) f(x)=\exp(g(x)) f'(x)=g'(x)\exp(g(x)) \exp(\ln(x)x),"['calculus', 'multivariable-calculus']"
25,Inequality $\sum_{k=1}^{n} \frac{\log(a_k)}{1+a_{k}^{2}} \leqslant 0$,Inequality,\sum_{k=1}^{n} \frac{\log(a_k)}{1+a_{k}^{2}} \leqslant 0,"Let $a_1,a_2,...,a_n$ be positive real numbers such that $a_1 \cdot a_2 \cdot ... \cdot a_n=1$ . Prove that $\sum_{k=1}^{n} \frac{\log(a_k)}{1+a_{k}^{2}} \leqslant 0$ . I tried using Jensen inequality, but function is not concave for all positive real number and I'm stuck. Any help will be greatly appreciated.","Let be positive real numbers such that . Prove that . I tried using Jensen inequality, but function is not concave for all positive real number and I'm stuck. Any help will be greatly appreciated.","a_1,a_2,...,a_n a_1 \cdot a_2 \cdot ... \cdot a_n=1 \sum_{k=1}^{n} \frac{\log(a_k)}{1+a_{k}^{2}} \leqslant 0","['real-analysis', 'multivariable-calculus']"
26,"Show that $\lim_{(x,y) \to (0,0)} {\frac{x\sin y - y\sin x}{x^2 +y^2}}$ does not exist",Show that  does not exist,"\lim_{(x,y) \to (0,0)} {\frac{x\sin y - y\sin x}{x^2 +y^2}}","Show that $\lim_{(x,y) \to (0,0)} {\frac{x\sin y - y\sin x}{x^2 +y^2}}$ does not exist I did use Wolfram Alpha and it says this limit does not exist. I'm trying to prove this with sequential definition of multivariable function. So basically, I have to find two sequences $(u_k)$ and $(v_k)$ such that they approach $(0,0)$ but the two sequences $f(u_k)$ and $f(v_k)$ approach two different limits. I tried various things but nothing works out. Could you give me some hint about this problem? Thank you in advance!","Show that does not exist I did use Wolfram Alpha and it says this limit does not exist. I'm trying to prove this with sequential definition of multivariable function. So basically, I have to find two sequences and such that they approach but the two sequences and approach two different limits. I tried various things but nothing works out. Could you give me some hint about this problem? Thank you in advance!","\lim_{(x,y) \to (0,0)} {\frac{x\sin y - y\sin x}{x^2 +y^2}} (u_k) (v_k) (0,0) f(u_k) f(v_k)",['multivariable-calculus']
27,"Does $A(x, m) = 1 - A(m, x)$ imply some symmetry in partial derivatives?",Does  imply some symmetry in partial derivatives?,"A(x, m) = 1 - A(m, x)","This is a self-made problem. I have a function $A$ of variables $x, m \geq 0$ . A satisfies the following symmetry: $$A(x, m) = 1 - A(m, x)$$ Is there an equation that relates the partial derivative of $A$ wrt the first argument to the partial derivative of $A$ with respect to the second argument? It seems like there should be something straightforward but I'm not sure how to deduce it. Thank you!",This is a self-made problem. I have a function of variables . A satisfies the following symmetry: Is there an equation that relates the partial derivative of wrt the first argument to the partial derivative of with respect to the second argument? It seems like there should be something straightforward but I'm not sure how to deduce it. Thank you!,"A x, m \geq 0 A(x, m) = 1 - A(m, x) A A","['calculus', 'multivariable-calculus', 'derivatives', 'partial-derivative', 'symmetry']"
28,How to derive or logically explain the formula for curl?,How to derive or logically explain the formula for curl?,,"Most books state that the formula for curl of a vector field is given by $\nabla \times \vec{V}$ where $\vec{V}$ is a differentiable vector field. Also, they state that: ""The curl of a vector field measures the tendency for the vector field to swirl around"". But, none of them state the derivation of the formula. In other words : ""How can we derive the formula for the quantity which measures the tendency for the vector field to swirl around"" ?","Most books state that the formula for curl of a vector field is given by $\nabla \times \vec{V}$ where $\vec{V}$ is a differentiable vector field. Also, they state that: ""The curl of a vector field measures the tendency for the vector field to swirl around"". But, none of them state the derivation of the formula. In other words : ""How can we derive the formula for the quantity which measures the tendency for the vector field to swirl around"" ?",,['multivariable-calculus']
29,"Find the minimum and maximum of the following function: $f(x,y) = x^2+y^2-x+1/4$",Find the minimum and maximum of the following function:,"f(x,y) = x^2+y^2-x+1/4","I've been asked to find the minimum and maximum of the following function: $f(x,y) = x^2+y^2-x+1/4$ On the region or restriction defined as: $D$={${(x,y)\in\mathbb{R}^2:x^2+y^2\leq1;  x+y\leq0}$} First, I observed that $f$ is continuos, and after I did the graph of the region where I will study the function, to check geometrically that the intersection of the two conditions I have defined, is closed and bounded, factor which assure that exist extrems because of the extreme value theorem. Then, I studied the interior of the region with $\nabla f(x,y)=(0,0)$ and I get the critical point $(1/2,0)$ And now I'm having problems to could study the borders of the region. I parametrized one of them through the following curve: $\sigma (t)=(t,-t)$ and then, I compose $f$ with it, $f$$\circ$$\sigma(t)$$= 2t^2-t+1/4$. Once I did this, I get from the ($f$$\circ$$\sigma)'(t)=0$ the critical point $(1/4,-1/4)$. But, I don't know how to parametrize the rest, that is the border of a half part of the unitary circle. Any idea?","I've been asked to find the minimum and maximum of the following function: $f(x,y) = x^2+y^2-x+1/4$ On the region or restriction defined as: $D$={${(x,y)\in\mathbb{R}^2:x^2+y^2\leq1;  x+y\leq0}$} First, I observed that $f$ is continuos, and after I did the graph of the region where I will study the function, to check geometrically that the intersection of the two conditions I have defined, is closed and bounded, factor which assure that exist extrems because of the extreme value theorem. Then, I studied the interior of the region with $\nabla f(x,y)=(0,0)$ and I get the critical point $(1/2,0)$ And now I'm having problems to could study the borders of the region. I parametrized one of them through the following curve: $\sigma (t)=(t,-t)$ and then, I compose $f$ with it, $f$$\circ$$\sigma(t)$$= 2t^2-t+1/4$. Once I did this, I get from the ($f$$\circ$$\sigma)'(t)=0$ the critical point $(1/4,-1/4)$. But, I don't know how to parametrize the rest, that is the border of a half part of the unitary circle. Any idea?",,['multivariable-calculus']
30,"Continuity of $\frac{x^3y^2}{x^4+y^4}$ at $(0,0)$? [duplicate]",Continuity of  at ? [duplicate],"\frac{x^3y^2}{x^4+y^4} (0,0)","This question already has answers here : Multivariable Delta Epsilon Proof $\lim_{(x,y)\to(0,0)}\frac{x^3y^2}{x^4+y^4}$ --- looking for a hint (2 answers) Closed 7 years ago . Suppose a function $f$ is defined as follows: $$f(x,y)=\begin{cases} \frac{x^3y^2}{x^4+y^4}&\text{ when }(x,y)\neq(0,0),\\0 & \text{ when }(x,y)=(0,0).\end{cases}$$ Is this function continuous at $(0,0)$? How is this shown? I've tried considering limits for different $y=g(x)$ functions and I am unable to find a counterexample. But I do not see how to prove continuity in general.","This question already has answers here : Multivariable Delta Epsilon Proof $\lim_{(x,y)\to(0,0)}\frac{x^3y^2}{x^4+y^4}$ --- looking for a hint (2 answers) Closed 7 years ago . Suppose a function $f$ is defined as follows: $$f(x,y)=\begin{cases} \frac{x^3y^2}{x^4+y^4}&\text{ when }(x,y)\neq(0,0),\\0 & \text{ when }(x,y)=(0,0).\end{cases}$$ Is this function continuous at $(0,0)$? How is this shown? I've tried considering limits for different $y=g(x)$ functions and I am unable to find a counterexample. But I do not see how to prove continuity in general.",,"['real-analysis', 'multivariable-calculus', 'continuity']"
31,Volume enclosed by $(x^2+y^2+z^2)^2=x$,Volume enclosed by,(x^2+y^2+z^2)^2=x,"I need to calculate the volume of solid enclosed by the surface $(x^2+y^2+z^2)^2=x$, using only spherical coordinates. My attempt: by changing coordinates to spherical: $x=r\sin\phi\cos\theta~,~y=r\sin\phi\sin\theta~,~z=r\cos\phi$ we obtain the Jacobian $J=r^2\sin\phi$. When $\phi$ and $\theta$ are fixed, $r$ varies from $0$ to $\sqrt[3]{\sin\phi\cos\theta}$ (because $r^4=r\sin\phi\cos\theta$). Keeping $\theta$ fixed, we let $\phi$ vary from $0$ to $\pi$. Thus the volume equals: $$V=\int\limits_{0}^{\pi}\int\limits_{0}^{\pi}\int\limits_{0}^{\sqrt[3]{\sin\phi\cos\theta}}r^2\sin\phi ~dr ~d\phi ~d\theta=0$$ Which is obviously wrong. What am I doing wrong?","I need to calculate the volume of solid enclosed by the surface $(x^2+y^2+z^2)^2=x$, using only spherical coordinates. My attempt: by changing coordinates to spherical: $x=r\sin\phi\cos\theta~,~y=r\sin\phi\sin\theta~,~z=r\cos\phi$ we obtain the Jacobian $J=r^2\sin\phi$. When $\phi$ and $\theta$ are fixed, $r$ varies from $0$ to $\sqrt[3]{\sin\phi\cos\theta}$ (because $r^4=r\sin\phi\cos\theta$). Keeping $\theta$ fixed, we let $\phi$ vary from $0$ to $\pi$. Thus the volume equals: $$V=\int\limits_{0}^{\pi}\int\limits_{0}^{\pi}\int\limits_{0}^{\sqrt[3]{\sin\phi\cos\theta}}r^2\sin\phi ~dr ~d\phi ~d\theta=0$$ Which is obviously wrong. What am I doing wrong?",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'volume']"
32,Divergence of laplacian,Divergence of laplacian,,"It seems to me that, in some derivations on fluid dynamic books I am reading, the identity $$\nabla \cdot (\nabla^2 u) = 0 $$ where $u$ is a vector field, is used. Does this identity exist? Is it true?","It seems to me that, in some derivations on fluid dynamic books I am reading, the identity $$\nabla \cdot (\nabla^2 u) = 0 $$ where $u$ is a vector field, is used. Does this identity exist? Is it true?",,"['multivariable-calculus', 'vectors']"
33,Solve for the gradient of $\log \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi)$,Solve for the gradient of,\log \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi),"This is a standard problem in convex optimization with well known solution but I cannot seem to follow the procedure given in Boyd's CVX book pg 643 Suppose I am given $f(x) = \log \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi)$, $f: R^n \to R$, I need to find the gradient Then, by the chain rule: $Df(x) = Dg(h(x))Dh(x)= D(\log \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi))D( \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi))$ $Df(x) = \dfrac{1}{\sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi)} [?? \text{what is } D( \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi))??] $ I would really appreciate if someone can show me how you would get a closed form of the expression $D( \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi))$. The final solution is $\nabla f(x) = \dfrac{1}{1^Tz}A^Tz$, where $z_i = \exp(a_i^Tx + b_i)$","This is a standard problem in convex optimization with well known solution but I cannot seem to follow the procedure given in Boyd's CVX book pg 643 Suppose I am given $f(x) = \log \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi)$, $f: R^n \to R$, I need to find the gradient Then, by the chain rule: $Df(x) = Dg(h(x))Dh(x)= D(\log \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi))D( \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi))$ $Df(x) = \dfrac{1}{\sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi)} [?? \text{what is } D( \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi))??] $ I would really appreciate if someone can show me how you would get a closed form of the expression $D( \sum\limits_{i = 1}^{m} \exp(a_i^Tx + bi))$. The final solution is $\nabla f(x) = \dfrac{1}{1^Tz}A^Tz$, where $z_i = \exp(a_i^Tx + b_i)$",,"['multivariable-calculus', 'convex-analysis', 'convex-optimization', 'vector-analysis', 'matrix-calculus']"
34,One Step Forward from Gaussian Integral,One Step Forward from Gaussian Integral,,"Now to solve the integral $ \int_0^\infty e^{-x^2} \, dx $ has become a simple task for us. But how can we solve this integral: $$\int_0^\infty e^{-x^3} \, dx $$","Now to solve the integral $ \int_0^\infty e^{-x^2} \, dx $ has become a simple task for us. But how can we solve this integral: $$\int_0^\infty e^{-x^3} \, dx $$",,"['calculus', 'integration', 'multivariable-calculus', 'improper-integrals']"
35,Remembering the definition of the Jacobian: any tips?,Remembering the definition of the Jacobian: any tips?,,I find it impossible to remember that the Jacobian  of $f: \mathbb R^n \to \mathbb R^m$ is $$ \begin{pmatrix} {\partial f_1 \over \partial x_1} & {\partial f_1 \over \partial x_2} & \dots & {\partial f_1 \over \partial x_n} \\ \vdots & \dots & \vdots & \vdots\\ {\partial f_m \over \partial x_1} & \dots & \dots & {\partial f_m \over \partial x_n} \end{pmatrix}$$ and not $$ \begin{pmatrix} {\partial f_1 \over \partial x_1} & {\partial f_2 \over \partial x_1} & \dots & {\partial f_m \over \partial x_1} \\ \vdots & \dots & \vdots & \vdots\\ {\partial f_1 \over \partial x_n} & \dots & \dots & {\partial f_m \over \partial x_n} \end{pmatrix}$$ How to memorise this? Is there any reason why it's defined the first   way and not the other?,I find it impossible to remember that the Jacobian  of $f: \mathbb R^n \to \mathbb R^m$ is $$ \begin{pmatrix} {\partial f_1 \over \partial x_1} & {\partial f_1 \over \partial x_2} & \dots & {\partial f_1 \over \partial x_n} \\ \vdots & \dots & \vdots & \vdots\\ {\partial f_m \over \partial x_1} & \dots & \dots & {\partial f_m \over \partial x_n} \end{pmatrix}$$ and not $$ \begin{pmatrix} {\partial f_1 \over \partial x_1} & {\partial f_2 \over \partial x_1} & \dots & {\partial f_m \over \partial x_1} \\ \vdots & \dots & \vdots & \vdots\\ {\partial f_1 \over \partial x_n} & \dots & \dots & {\partial f_m \over \partial x_n} \end{pmatrix}$$ How to memorise this? Is there any reason why it's defined the first   way and not the other?,,"['linear-algebra', 'multivariable-calculus']"
36,Convexity of $\sqrt{x^2+y^2}$,Convexity of,\sqrt{x^2+y^2},"I am to prove that $\sqrt{x^2+y^2}$ is convex for $x,y>0$. Intuitively, if I look at the derivatives, $\frac{x}{\sqrt{x^2+y^2}}$, $\frac{y}{\sqrt{x^2+y^2}}$, they are increasing in every positive direction. However, that isn't a very formal argument (or even correct?) Of course, one could compute the Hessian, but that seems like a pain and since this is a minor subquestion from an optimisation exam I am preparing for, there must be a simpler way. I thought about looking at it as a composite function, however the lemmas known to me require the outer function to be convex. Thank you for help.","I am to prove that $\sqrt{x^2+y^2}$ is convex for $x,y>0$. Intuitively, if I look at the derivatives, $\frac{x}{\sqrt{x^2+y^2}}$, $\frac{y}{\sqrt{x^2+y^2}}$, they are increasing in every positive direction. However, that isn't a very formal argument (or even correct?) Of course, one could compute the Hessian, but that seems like a pain and since this is a minor subquestion from an optimisation exam I am preparing for, there must be a simpler way. I thought about looking at it as a composite function, however the lemmas known to me require the outer function to be convex. Thank you for help.",,['multivariable-calculus']
37,"$r=(x,y,z)$ prove that $\mathrm{curl}\; r = 0$",prove that,"r=(x,y,z) \mathrm{curl}\; r = 0","Example $\bf 84\,\,\,$ Let $\,\mathbf r=(x,y,z)$ and $r=|\!\,\mathbf r|=\sqrt{x^2+y^2+z^2}$. Then $$\operatorname{div}\mathbf r= \dfrac{\partial x}{\partial x} + \dfrac{\partial y}{\partial y} + \dfrac{\partial z}{\partial z} =3; \\ \operatorname{curl}\mathbf r= \left|\begin{matrix} \mathbf i & \mathbf j & \mathbf k \\ \tfrac{\partial}{\partial x} & \tfrac{\partial}{\partial y} & \tfrac\partial{\partial z}\\ x & y & z  \end{matrix}\right|=\rlap{\rlap{0}\rlap00}0.$$ I fail to see how this equals zero Is $\tfrac{dz}{dy} - \tfrac{dy}{dz} = 0$ and same for other terms too? Thanks","Example $\bf 84\,\,\,$ Let $\,\mathbf r=(x,y,z)$ and $r=|\!\,\mathbf r|=\sqrt{x^2+y^2+z^2}$. Then $$\operatorname{div}\mathbf r= \dfrac{\partial x}{\partial x} + \dfrac{\partial y}{\partial y} + \dfrac{\partial z}{\partial z} =3; \\ \operatorname{curl}\mathbf r= \left|\begin{matrix} \mathbf i & \mathbf j & \mathbf k \\ \tfrac{\partial}{\partial x} & \tfrac{\partial}{\partial y} & \tfrac\partial{\partial z}\\ x & y & z  \end{matrix}\right|=\rlap{\rlap{0}\rlap00}0.$$ I fail to see how this equals zero Is $\tfrac{dz}{dy} - \tfrac{dy}{dz} = 0$ and same for other terms too? Thanks",,"['calculus', 'multivariable-calculus']"
38,What does δA mean in differentiation?,What does δA mean in differentiation?,,"To be more specific, I met this when doing analytical mechanics involving the principle of least action:","To be more specific, I met this when doing analytical mechanics involving the principle of least action:",,"['calculus', 'multivariable-calculus', 'physics', 'partial-derivative']"
39,Evaluating a double integral: $\iint \exp(\sqrt{x^2+y^2})\:dx\:dy$?,Evaluating a double integral: ?,\iint \exp(\sqrt{x^2+y^2})\:dx\:dy,How to evaluate the following integral? $$\iint \exp\left(\sqrt{x^2+y^2} \right)\:dx\:dy$$ I'm trying to integrate this using substitution and integration by parts but I keep getting stuck.,How to evaluate the following integral? $$\iint \exp\left(\sqrt{x^2+y^2} \right)\:dx\:dy$$ I'm trying to integrate this using substitution and integration by parts but I keep getting stuck.,,"['integration', 'multivariable-calculus']"
40,Evaluating double integral on different domains $D$ [closed],Evaluating double integral on different domains  [closed],D,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question $$\iint\limits_{D} \left(x^2+y^2\right)\mathrm{d}x \mathrm{d}y$$ where $D$ is given each time by $D=x^2-y^2=1,\hspace{0.5cm} x^2-y^2=9,\hspace{0.5cm} xy=2,\hspace{0.5cm} xy=4$ I try to use Polar coordinate transformation \begin{cases}    x &= \rho \cos \theta  \\    y &= \rho \sin \theta \end{cases} but I don’t know how to find the range of $\rho$ and $\theta$","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question where is given each time by I try to use Polar coordinate transformation but I don’t know how to find the range of and","\iint\limits_{D} \left(x^2+y^2\right)\mathrm{d}x \mathrm{d}y D D=x^2-y^2=1,\hspace{0.5cm} x^2-y^2=9,\hspace{0.5cm} xy=2,\hspace{0.5cm} xy=4 \begin{cases}
   x &= \rho \cos \theta  \\
   y &= \rho \sin \theta
\end{cases} \rho \theta","['integration', 'multivariable-calculus']"
41,$dxdy=rdrd\theta$,,dxdy=rdrd\theta,"I'm trying to show that $dx\,dy=r\,dr\,d\theta$ using differentials. $x=r\cos(\theta)$ and $y=r\sin(\theta)$ thus $dx=\cos(\theta)dr-r\sin(\theta)d\theta$ and $dy=\sin(\theta)dr+r\cos(\theta)d\theta$ $\begin{align}dx\,dy&=(\cos(\theta)dr-r\sin(\theta)d\theta)(\sin(\theta)dr+r\cos(\theta)d\theta)\\& =\cos(\theta)\sin(\theta) dr^2+r\cos^2(\theta)drd\theta-r\sin^2(\theta)d\theta dr-r^2\cos(\theta)\sin(\theta)d\theta^2\\&=\cos(\theta)\sin(\theta) dr^2-r^2\cos(\theta)\sin(\theta)d\theta^2+rdrd\theta(1-\sin(\theta)^2-\sin(\theta)^2)\end{align}$ If my calculations are correct, $\cos(\theta)\sin(\theta) dr^2-r^2\cos(\theta)\sin(\theta)d\theta^2-2 \sin(\theta)^2rdrd\theta=0$ but how am I suppose to show that?","I'm trying to show that using differentials. and thus and If my calculations are correct, but how am I suppose to show that?","dx\,dy=r\,dr\,d\theta x=r\cos(\theta) y=r\sin(\theta) dx=\cos(\theta)dr-r\sin(\theta)d\theta dy=\sin(\theta)dr+r\cos(\theta)d\theta \begin{align}dx\,dy&=(\cos(\theta)dr-r\sin(\theta)d\theta)(\sin(\theta)dr+r\cos(\theta)d\theta)\\&
=\cos(\theta)\sin(\theta)
dr^2+r\cos^2(\theta)drd\theta-r\sin^2(\theta)d\theta dr-r^2\cos(\theta)\sin(\theta)d\theta^2\\&=\cos(\theta)\sin(\theta)
dr^2-r^2\cos(\theta)\sin(\theta)d\theta^2+rdrd\theta(1-\sin(\theta)^2-\sin(\theta)^2)\end{align} \cos(\theta)\sin(\theta)
dr^2-r^2\cos(\theta)\sin(\theta)d\theta^2-2 \sin(\theta)^2rdrd\theta=0","['calculus', 'multivariable-calculus', 'trigonometry']"
42,"""go / goes to"" $(x \to y)$ vs. ""maps to"" $(x \mapsto y)$","""go / goes to""  vs. ""maps to""",(x \to y) (x \mapsto y),"Is there a convention for determining when to use $\to$ vs when to use $\mapsto$ ? Or is there some flexibility between the two? I have only ever seen $\to$ used within the notation for limits (ie I have never seen anything like $\lim_{x {\color{red}\mapsto} a^+}\limits f(x)$ ) - which makes sense to me. However, I have seen both symbols used for reassignment of a variable -- eg if a question is posed in terms of variables that may shroud the (otherwise familiar) structure of an equation to new initiates: Ex 1: to help a student familiar with spherical coordinates recognize that $\vec{r} = \left< 5\sin u \cos t, 5 \sin u \sin t, 5\cos u \right>$ for $u \in [0,\pi]$ , $t \in [0, 2\pi]$ is the equation of a sphere in polar coordinates by re-writing the expression in terms of the more familiar spherical coordinates $\phi$ and $\theta$ , I've seen both ""let $u \to \phi$ and $t \to \theta$ "" as well as ""let $u \mapsto \phi$ and $t \mapsto \theta$ ."" Ex 2: when making a substitution (e.g. during integration) I've seen ""let $u = x^2$ ,"" as well as ""let $u \mapsto x^2$ ,"" as well as "" $x \mapsto x^2$ ."" I realize that there are hardly any universal conventions; so am equally interested in the reasoning for any specific one (i.e. if you really think they should never be interchanged, I'd love to know why ). Context / Motivation: Most of my (post-secondary) math education has been informal -- a haphazard dipping into many different textbooks; course notes from different universities; online course etc. to complement the basic education I received in applied math during my physics undergraduate degree -- and so I've encountered many different uses of notation. It hasn't been a stumbling block for my understanding (at least, not that I'm aware of), but it feels like high time for me to look into these details. Thanks in advance for your time and help.","Is there a convention for determining when to use vs when to use ? Or is there some flexibility between the two? I have only ever seen used within the notation for limits (ie I have never seen anything like ) - which makes sense to me. However, I have seen both symbols used for reassignment of a variable -- eg if a question is posed in terms of variables that may shroud the (otherwise familiar) structure of an equation to new initiates: Ex 1: to help a student familiar with spherical coordinates recognize that for , is the equation of a sphere in polar coordinates by re-writing the expression in terms of the more familiar spherical coordinates and , I've seen both ""let and "" as well as ""let and ."" Ex 2: when making a substitution (e.g. during integration) I've seen ""let ,"" as well as ""let ,"" as well as "" ."" I realize that there are hardly any universal conventions; so am equally interested in the reasoning for any specific one (i.e. if you really think they should never be interchanged, I'd love to know why ). Context / Motivation: Most of my (post-secondary) math education has been informal -- a haphazard dipping into many different textbooks; course notes from different universities; online course etc. to complement the basic education I received in applied math during my physics undergraduate degree -- and so I've encountered many different uses of notation. It hasn't been a stumbling block for my understanding (at least, not that I'm aware of), but it feels like high time for me to look into these details. Thanks in advance for your time and help.","\to \mapsto \to \lim_{x {\color{red}\mapsto} a^+}\limits f(x) \vec{r} = \left< 5\sin u \cos t, 5 \sin u \sin t, 5\cos u \right> u \in [0,\pi] t \in [0, 2\pi] \phi \theta u \to \phi t \to \theta u \mapsto \phi t \mapsto \theta u = x^2 u \mapsto x^2 x \mapsto x^2","['multivariable-calculus', 'notation', 'convention']"
43,Computing volume inside a ball and outside a cylinder,Computing volume inside a ball and outside a cylinder,,I try to calculate the volume inside the ball $\ x^2 + y^2 + z ^2 = 4 $ the outside the cylinder $\ x^2+y^2=2x $ using double integral.  Since the shape is symmetric I chose $\ z = 0 $ as bottom limit and the ball is the upper limit. I try to convert to polar form and so I get $$\ x^2 + y^2 + z ^2 = 4 \Rightarrow z = \sqrt{4-r^2} \\x^2 + y^2 = 2x \Rightarrow r = 2 \cos \theta $$ therefore the integral should be $$\ 4 \cdot \int_0^{\pi/2} \int_0^{2\cos\theta} (\sqrt{4-r^2}) \ r \ dr \ d \theta$$ but this integral is way to messy for me to calculate. I mean first step of calculating integral for $\ r $ is okay but then the value I get and calculating integral of $\ \theta $ is beyond me and I believe it is beyond the scope of the course. I guess I'm missing something in the process here?,I try to calculate the volume inside the ball the outside the cylinder using double integral.  Since the shape is symmetric I chose as bottom limit and the ball is the upper limit. I try to convert to polar form and so I get therefore the integral should be but this integral is way to messy for me to calculate. I mean first step of calculating integral for is okay but then the value I get and calculating integral of is beyond me and I believe it is beyond the scope of the course. I guess I'm missing something in the process here?,\ x^2 + y^2 + z ^2 = 4  \ x^2+y^2=2x  \ z = 0  \ x^2 + y^2 + z ^2 = 4 \Rightarrow z = \sqrt{4-r^2} \\x^2 + y^2 = 2x \Rightarrow r = 2 \cos \theta  \ 4 \cdot \int_0^{\pi/2} \int_0^{2\cos\theta} (\sqrt{4-r^2}) \ r \ dr \ d \theta \ r  \ \theta ,"['multivariable-calculus', 'analytic-geometry', 'volume', 'multiple-integral']"
44,Proving that $\iint_{B_2(0)}e^{(x^2+y^2)^2}dA\leq e(1+3e^{15})\pi$,Proving that,\iint_{B_2(0)}e^{(x^2+y^2)^2}dA\leq e(1+3e^{15})\pi,"Show that $$\iint_{B_2(0)}e^{(x^2+y^2)^2}dA\leq e(1+3e^{15})\pi$$ [Hint: If you cannot get the desired estimate directly, try using domain decomposition.] I am having trouble with this problem. I understand that using polar coordinates, $$\iint_D{e^{x^2+y^2}dA}=\pi(e-1)$$ where $D$ is the unit disk of radius one, because it becomes $$\int_0^{2\pi}\int_0^1{re^{r^2}dr \ d\theta}=\pi(e-1)$$ So, in the problem above, does this simply become $$\int_0^{2\pi}\int_0^1{re^{{r^2}^2}dr \ d\theta}=\pi(e-1)$$ $$\Rightarrow\int_0^{2\pi}\int_0^1{re^{r^4}dr \ d\theta}=\pi(e-1)?$$ If not, what is it? How would one then prove the inequality?","Show that [Hint: If you cannot get the desired estimate directly, try using domain decomposition.] I am having trouble with this problem. I understand that using polar coordinates, where is the unit disk of radius one, because it becomes So, in the problem above, does this simply become If not, what is it? How would one then prove the inequality?",\iint_{B_2(0)}e^{(x^2+y^2)^2}dA\leq e(1+3e^{15})\pi \iint_D{e^{x^2+y^2}dA}=\pi(e-1) D \int_0^{2\pi}\int_0^1{re^{r^2}dr \ d\theta}=\pi(e-1) \int_0^{2\pi}\int_0^1{re^{{r^2}^2}dr \ d\theta}=\pi(e-1) \Rightarrow\int_0^{2\pi}\int_0^1{re^{r^4}dr \ d\theta}=\pi(e-1)?,"['integration', 'multivariable-calculus', 'definite-integrals', 'polar-coordinates']"
45,Find the max of $x_1 x_2 \cdots x_m$ when $x_1^2+x_2^2+ \cdots + x_m^2=1$,Find the max of  when,x_1 x_2 \cdots x_m x_1^2+x_2^2+ \cdots + x_m^2=1,"Find the max of a function $$f(x_1, x_2,...,x_m)=x_1 x_2 \cdots x_m$$ when $x_1^2+x_2^2+ \cdots +x_m^2=1$ I am looking for unique solutions. So far I've tried two different ways. One of them was with Lagrange multiplier but there seem to be quite too many variables and I couldn't express $x_1,...,x_m$ separately. The second one solution is with the Inequality of arithmetic and geometric means. $$\frac{x_1^2+...+x_m^2}{m}\ge \sqrt[m]{x_1^2 \cdots x_m^2} \implies \frac{1}{m} \ge \sqrt[m]{x_1^2 \cdots x_m^2}=(x_1 \cdots x_m)^{\frac{2}{m}} \implies $$ $$x_1 \cdots x_m \le \frac{1}{m^{\frac{m}{2}}}$$ So we can assume that $$\max f(x_1, x_2,...,x_m)=\frac{1}{m^{\frac{m}{2}}} \quad \forall x_i=\frac{1}{\sqrt m}, \quad i=1,2,...,m.$$ I'd love to know if somebody solved this exercise with Langrange multiplier or in other way. Thanks in advance!",Find the max of a function when I am looking for unique solutions. So far I've tried two different ways. One of them was with Lagrange multiplier but there seem to be quite too many variables and I couldn't express separately. The second one solution is with the Inequality of arithmetic and geometric means. So we can assume that I'd love to know if somebody solved this exercise with Langrange multiplier or in other way. Thanks in advance!,"f(x_1, x_2,...,x_m)=x_1 x_2 \cdots x_m x_1^2+x_2^2+ \cdots +x_m^2=1 x_1,...,x_m \frac{x_1^2+...+x_m^2}{m}\ge \sqrt[m]{x_1^2 \cdots x_m^2} \implies \frac{1}{m} \ge \sqrt[m]{x_1^2 \cdots x_m^2}=(x_1 \cdots x_m)^{\frac{2}{m}} \implies  x_1 \cdots x_m \le \frac{1}{m^{\frac{m}{2}}} \max f(x_1, x_2,...,x_m)=\frac{1}{m^{\frac{m}{2}}} \quad \forall x_i=\frac{1}{\sqrt m}, \quad i=1,2,...,m.","['multivariable-calculus', 'optimization', 'lagrange-multiplier', 'maxima-minima']"
46,Use the spherical coordinates to compute the integral $\int\limits_{B} z^2 dx dy dz$ where B is defined by $1\leq x^2 + y^2 + z^2 \leq 4$,Use the spherical coordinates to compute the integral  where B is defined by,\int\limits_{B} z^2 dx dy dz 1\leq x^2 + y^2 + z^2 \leq 4,", however the answer I got to is different than the answer sheet. The answer sheet says that it should be $\frac{62}{15}$ Am I making some mistake or is the answer sheet incorrect?",", however the answer I got to is different than the answer sheet. The answer sheet says that it should be Am I making some mistake or is the answer sheet incorrect?",\frac{62}{15},"['calculus', 'multivariable-calculus', 'substitution', 'spherical-coordinates', 'change-of-variable']"
47,How to get the interval after change of variables?,How to get the interval after change of variables?,,"Let $D$ be the region bounded by $x+y = 1$, $x= 0$, $y = 0$. Use the result of Exercise 19 to show that $$\iint_D\cos\bigg(\frac{x-y}{x+y}\bigg)~dx~dy = \frac{\sin 1}{2} $$   and graph $D$ on an $xy$ plane and a $uv$ plane, with $u = x-y$ and $v = x+y$. I got the Jacobian determinant is $\dfrac{1}{2}$, but how do I get the limits of integration for $u$ and $v$?","Let $D$ be the region bounded by $x+y = 1$, $x= 0$, $y = 0$. Use the result of Exercise 19 to show that $$\iint_D\cos\bigg(\frac{x-y}{x+y}\bigg)~dx~dy = \frac{\sin 1}{2} $$   and graph $D$ on an $xy$ plane and a $uv$ plane, with $u = x-y$ and $v = x+y$. I got the Jacobian determinant is $\dfrac{1}{2}$, but how do I get the limits of integration for $u$ and $v$?",,"['calculus', 'multivariable-calculus', 'change-of-variable']"
48,What properties of this complex function can be deduced?,What properties of this complex function can be deduced?,,"Let $\Phi(x,y)$ be a complex function of $x, y \in \mathbb{R}$ . Given that $$\int_{-\infty}^{+\infty} \Phi^*(x,y) \frac{\partial}{\partial x} \Phi(x,y) \,dx$$ is purely imaginary: What properties of the complex function $\Phi(x,y)$ can be deduced?","Let $\Phi(x,y)$ be a complex function of $x, y \in \mathbb{R}$ . Given that $$\int_{-\infty}^{+\infty} \Phi^*(x,y) \frac{\partial}{\partial x} \Phi(x,y) \,dx$$ is purely imaginary: What properties of the complex function $\Phi(x,y)$ can be deduced?",,"['multivariable-calculus', 'definite-integrals', 'complex-numbers', 'partial-derivative']"
49,"A curve $(t,t^2,t^3,\ldots,t^n) \in\mathbb R^n$ is not contained in any hyperplane",A curve  is not contained in any hyperplane,"(t,t^2,t^3,\ldots,t^n) \in\mathbb R^n","Let $C$ the curve given by $\gamma:\mathbb R\to\mathbb R^n$, $\gamma(t)=(t,t^2,t^3,\ldots,t^n)$. Show that $C$ is contained in no hyperplane. 2.Find the tangent line and osculating plane at $(0,0,\ldots,0)$. For (1) my idea is to find the curvature of $\gamma$. We have, $$\gamma'(t)=(1,2t,3t^2,...,nt^{n-1})\quad \gamma''(t)=(0,2,6t,...,n(n-1)t^{n-2}).$$ Then $k(t)=||\gamma''(t)||=\sqrt[]{4+36t^2+\cdots+(n(n-1)t^{n-2})^2}>0$ so it is not contained in any hyperplane. Is it ok? If so, is there another way to solve this without using curvature? To get the tangent line and osculating plane, I just take the binormal vector $B(t)=\gamma'(t)\times \gamma''(t)$ and them i get the plane. Is it ok? Thanks for your help.","Let $C$ the curve given by $\gamma:\mathbb R\to\mathbb R^n$, $\gamma(t)=(t,t^2,t^3,\ldots,t^n)$. Show that $C$ is contained in no hyperplane. 2.Find the tangent line and osculating plane at $(0,0,\ldots,0)$. For (1) my idea is to find the curvature of $\gamma$. We have, $$\gamma'(t)=(1,2t,3t^2,...,nt^{n-1})\quad \gamma''(t)=(0,2,6t,...,n(n-1)t^{n-2}).$$ Then $k(t)=||\gamma''(t)||=\sqrt[]{4+36t^2+\cdots+(n(n-1)t^{n-2})^2}>0$ so it is not contained in any hyperplane. Is it ok? If so, is there another way to solve this without using curvature? To get the tangent line and osculating plane, I just take the binormal vector $B(t)=\gamma'(t)\times \gamma''(t)$ and them i get the plane. Is it ok? Thanks for your help.",,"['multivariable-calculus', 'differential-geometry', 'vector-analysis']"
50,Clarification on Implicit Derivatives steps,Clarification on Implicit Derivatives steps,,"I have been attempting to wrap my head around this problem for a couple days now. I've attempted numerous different iterations to try and find how the answer is derived, but I just don't see the connection. Any help on this matter would be greatly appreciated. Thanks. Question : $$3x^5-5y^3 = 5x^2+3y^5\text{.   Find  }\frac{\mathrm{d}y}{\mathrm{d}x}$$ Book's answer : $$\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{x(3x^3-2)}{3y^2(y^2+1)}$$ If you could show the steps to get said answer, that would be most helpful. Thanks.","I have been attempting to wrap my head around this problem for a couple days now. I've attempted numerous different iterations to try and find how the answer is derived, but I just don't see the connection. Any help on this matter would be greatly appreciated. Thanks. Question : $$3x^5-5y^3 = 5x^2+3y^5\text{.   Find  }\frac{\mathrm{d}y}{\mathrm{d}x}$$ Book's answer : $$\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{x(3x^3-2)}{3y^2(y^2+1)}$$ If you could show the steps to get said answer, that would be most helpful. Thanks.",,"['calculus', 'multivariable-calculus', 'derivatives', 'implicit-differentiation']"
51,interval of convergence of $\sum n \exp (-x \sqrt n)$,interval of convergence of,\sum n \exp (-x \sqrt n),"$$\sum^{\infty}_{n=1} n \exp (-x \sqrt n)$$ How to find the interval of convergence? Obviously, 0 is not in the interval because the series becomes divergent. could you help me?","$$\sum^{\infty}_{n=1} n \exp (-x \sqrt n)$$ How to find the interval of convergence? Obviously, 0 is not in the interval because the series becomes divergent. could you help me?",,"['sequences-and-series', 'multivariable-calculus']"
52,Derivative of $\|x\|$,Derivative of,\|x\|,"$f:\mathbb{R}^n\rightarrow\mathbb{R}$ is a map $f(x)=\langle x,x\rangle$, $g:\mathbb{R}\rightarrow\mathbb{R}$ is a map $g(x)=\sqrt{x}$, so the composition $h:=g\circ f:\mathbb{R}^n\rightarrow\mathbb{R}$ is a map $x\mapsto \|x\|$, I want the derivative of $h$ at $a$, according to chain rule it should be $D(g(f(a)))\circ D f(a)$,could any one tell me now next steps?","$f:\mathbb{R}^n\rightarrow\mathbb{R}$ is a map $f(x)=\langle x,x\rangle$, $g:\mathbb{R}\rightarrow\mathbb{R}$ is a map $g(x)=\sqrt{x}$, so the composition $h:=g\circ f:\mathbb{R}^n\rightarrow\mathbb{R}$ is a map $x\mapsto \|x\|$, I want the derivative of $h$ at $a$, according to chain rule it should be $D(g(f(a)))\circ D f(a)$,could any one tell me now next steps?",,"['multivariable-calculus', 'derivatives']"
53,"Differentiable $\mathbf{f}:\Bbb R \to \Bbb R^3$, $|\mathbf{f}(t)| = 1$ implies $\mathbf{f}(t)\cdot\mathbf{f}'(t) = 0$","Differentiable ,  implies",\mathbf{f}:\Bbb R \to \Bbb R^3 |\mathbf{f}(t)| = 1 \mathbf{f}(t)\cdot\mathbf{f}'(t) = 0,"This question comes from Rudin's PMA problem 9.13. For a differentiable function $\mathbf{f} : \Bbb R \to \Bbb R^3$ and $|\mathbf{f}(t)|=1$ for all $t$, I want to prove that $\mathbf{f}(t)\cdot\mathbf{f}'(t) = 0$. Notionally, this makes sense to me. $|\mathbf{f}(t)|=1$ means that $\mathbf{f}(t)$ describes a curve on the unit sphere in $\Bbb R^3$. Of course, the tangent to this curve at any point will lie in the tangent plane to that point on the unit sphere, which is normal to the vector from the origin to that point. Therefore, by orthogonality, the dot product will be zero. However, I am struggling to prove it rigorously using the definition of derivatives. I have $$\mathbf{f}(t)\cdot\mathbf{f}'(t) = \lim_{h\to 0} \frac{1}{h} \left(\mathbf{f}(t) \cdot \left(\mathbf{f}(t+h)-\mathbf{f}(t)\right)\right)$$ by applying properties of limits, etc., but this seems to bring me right back in a circle (no pun intended). I also know that $|\mathbf{f}(t)| = 1$ means that $\mathbf{f}(t)\cdot\mathbf{f}(t) = 1$. I'm just not sure how to proceed from here. I want to argue that the numerator of the limit must be zero, but I can't; evaluation of the limit just brings me back to $\mathbf{f}\cdot\mathbf{f}'$. This is a homework problem, so please just provide a nudge in the right direction. Edit: I also don't ""know"" that $\mathbf{a \cdot b} = |\mathbf{a}||\mathbf{b}|\cos \theta$. I suppose I could prove it, but I feel as if that's avoiding the intent of the question.","This question comes from Rudin's PMA problem 9.13. For a differentiable function $\mathbf{f} : \Bbb R \to \Bbb R^3$ and $|\mathbf{f}(t)|=1$ for all $t$, I want to prove that $\mathbf{f}(t)\cdot\mathbf{f}'(t) = 0$. Notionally, this makes sense to me. $|\mathbf{f}(t)|=1$ means that $\mathbf{f}(t)$ describes a curve on the unit sphere in $\Bbb R^3$. Of course, the tangent to this curve at any point will lie in the tangent plane to that point on the unit sphere, which is normal to the vector from the origin to that point. Therefore, by orthogonality, the dot product will be zero. However, I am struggling to prove it rigorously using the definition of derivatives. I have $$\mathbf{f}(t)\cdot\mathbf{f}'(t) = \lim_{h\to 0} \frac{1}{h} \left(\mathbf{f}(t) \cdot \left(\mathbf{f}(t+h)-\mathbf{f}(t)\right)\right)$$ by applying properties of limits, etc., but this seems to bring me right back in a circle (no pun intended). I also know that $|\mathbf{f}(t)| = 1$ means that $\mathbf{f}(t)\cdot\mathbf{f}(t) = 1$. I'm just not sure how to proceed from here. I want to argue that the numerator of the limit must be zero, but I can't; evaluation of the limit just brings me back to $\mathbf{f}\cdot\mathbf{f}'$. This is a homework problem, so please just provide a nudge in the right direction. Edit: I also don't ""know"" that $\mathbf{a \cdot b} = |\mathbf{a}||\mathbf{b}|\cos \theta$. I suppose I could prove it, but I feel as if that's avoiding the intent of the question.",,"['real-analysis', 'multivariable-calculus', 'derivatives']"
54,Application of Lagrange Multiplier?,Application of Lagrange Multiplier?,,"Let $M$ and $m$ denote resp. the max and min values of the func. $f(x,y,z) = xyz $ over the region defined by the interior and boundary of the sphere $x^2 + y^2 + z^2 = 3$. What is the value of $M + m$? I tried using the method of lagrange multiplier to find $M$ and $m$, but I am having trouble solving the four equations in the four unknowns that are derived from it. I am doubting if Lagrange multipliers is the appropriate method.","Let $M$ and $m$ denote resp. the max and min values of the func. $f(x,y,z) = xyz $ over the region defined by the interior and boundary of the sphere $x^2 + y^2 + z^2 = 3$. What is the value of $M + m$? I tried using the method of lagrange multiplier to find $M$ and $m$, but I am having trouble solving the four equations in the four unknowns that are derived from it. I am doubting if Lagrange multipliers is the appropriate method.",,"['multivariable-calculus', 'optimization']"
55,"Two different characterization of ""differentiable function""","Two different characterization of ""differentiable function""",,"In a calculus class we were given the following definition of ""differentiable function"" (working with 2 variables): Definition : Let $A \in \mathbb{R^2}$, and $f : A \to \mathbb{R}$. We say that $f$ is differentiable in $(x_0, y_0) \in A$ if the graph of $f$ admits a tanget plane at $(x_0, y_0, f(x_0, y_0))$. Then the teacher gave us the following equivalent characterization: Proposition : $f$ is differentiable in $(x_0, y_0)$ iff 1) $f$ admits partial derivatives in $(x_0, y_0)$ 2) the following holds: $$ \lim_{(x,y) \to (x_0, y_0)} \frac{f(x,y) - f(x_0,y_0) - A(x-x_0) - B(y-y_0)}{\sqrt{(x-x_0)^2 + (y-y_0)^2}} = 0 $$ where  $$A = \frac{\partial f}{\partial x}(x_0,y_0)$$ $$B = \frac{\partial f}{\partial y}(x_0,y_0)$$ i.e. the partial derivatives evaluated in $(x_0,y_0)$ Unluckily, I was not able to find any reference about this. So here's my questions: I got it right? Are the two definitions equivalents? How to prove that the limit is zero iff the function admits a tangent plane? Isn't (2) quite obvious? If a tangent plane at $P$ exists, its equation has to be $$f(x,y) = f(P) - \frac{\partial f}{\partial x}(P)(x-x_P) - \frac{\partial f}{\partial y}(P)(y-y_P)$$ follow that the numerator of the limit is zero. So what's the point of the denominator? Couldn't one use anything else for the denominator? Am I missing something? Is (2) noteworthy? EDIT : As noted below, my ""it's obvious from eq. of tangent plane"" approach is, in fact, wrong.","In a calculus class we were given the following definition of ""differentiable function"" (working with 2 variables): Definition : Let $A \in \mathbb{R^2}$, and $f : A \to \mathbb{R}$. We say that $f$ is differentiable in $(x_0, y_0) \in A$ if the graph of $f$ admits a tanget plane at $(x_0, y_0, f(x_0, y_0))$. Then the teacher gave us the following equivalent characterization: Proposition : $f$ is differentiable in $(x_0, y_0)$ iff 1) $f$ admits partial derivatives in $(x_0, y_0)$ 2) the following holds: $$ \lim_{(x,y) \to (x_0, y_0)} \frac{f(x,y) - f(x_0,y_0) - A(x-x_0) - B(y-y_0)}{\sqrt{(x-x_0)^2 + (y-y_0)^2}} = 0 $$ where  $$A = \frac{\partial f}{\partial x}(x_0,y_0)$$ $$B = \frac{\partial f}{\partial y}(x_0,y_0)$$ i.e. the partial derivatives evaluated in $(x_0,y_0)$ Unluckily, I was not able to find any reference about this. So here's my questions: I got it right? Are the two definitions equivalents? How to prove that the limit is zero iff the function admits a tangent plane? Isn't (2) quite obvious? If a tangent plane at $P$ exists, its equation has to be $$f(x,y) = f(P) - \frac{\partial f}{\partial x}(P)(x-x_P) - \frac{\partial f}{\partial y}(P)(y-y_P)$$ follow that the numerator of the limit is zero. So what's the point of the denominator? Couldn't one use anything else for the denominator? Am I missing something? Is (2) noteworthy? EDIT : As noted below, my ""it's obvious from eq. of tangent plane"" approach is, in fact, wrong.",,"['calculus', 'multivariable-calculus']"
56,Derivative of Multi Variable Equation for Diablo 3 Damage Equation,Derivative of Multi Variable Equation for Diablo 3 Damage Equation,,"It has been years since I took calculus and I am trying to figure out if it is possible to calculate the derivative of a mutli variable equation and what the result would be. This equation is from the video game Diablo 3 that represents your damage based on your critical chance and critical damage. I am trying to determine where are the optimal points (or best bang for buck stat) by using derivatives. x = critical chance, y = critical damage, z = damage output Equation: $z = 1 + xy$","It has been years since I took calculus and I am trying to figure out if it is possible to calculate the derivative of a mutli variable equation and what the result would be. This equation is from the video game Diablo 3 that represents your damage based on your critical chance and critical damage. I am trying to determine where are the optimal points (or best bang for buck stat) by using derivatives. x = critical chance, y = critical damage, z = damage output Equation: $z = 1 + xy$",,"['multivariable-calculus', 'derivatives']"
57,"Calculating Volume of ""fat sphere"" defined by $x^8+y^8+z^8 = 64$","Calculating Volume of ""fat sphere"" defined by",x^8+y^8+z^8 = 64,"A young friend of mine had a homework problem involving a surface integral over the surface of the equation $x^8+y^8+z^8=64$ .  The homework problem was solvable using the divergence theorem, but he was curious how to calculate the volume of the bounded complementary component of this surface using triple integrals and I don't remember enough of these tricks to figure it out. Is there a nice formula for calculating volumes of these 'fat spheres' defined by $x^{2n}+y^{2n}+z^{2n} = a$ ? We tried spherical coordinates but the mess was prodigious.","A young friend of mine had a homework problem involving a surface integral over the surface of the equation .  The homework problem was solvable using the divergence theorem, but he was curious how to calculate the volume of the bounded complementary component of this surface using triple integrals and I don't remember enough of these tricks to figure it out. Is there a nice formula for calculating volumes of these 'fat spheres' defined by ? We tried spherical coordinates but the mess was prodigious.",x^8+y^8+z^8=64 x^{2n}+y^{2n}+z^{2n} = a,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'volume']"
58,How do I know if these two integrals are the same?,How do I know if these two integrals are the same?,,"I need to find out if it is true or false that these integrals are the same $$\int_{0}^{1}\int_{0}^{1}\int_{0}^{1-x^2} f(x,y,z)dz dy dx $$ $$\int_{0}^{1}\int_{0}^{1}\int_{-\sqrt{1-z}}^{\sqrt{1-z}}f(x,y,z) dx dy dz$$ I know that $0\leq z\leq 1-x^2$ From just the $z\leq 1-x^2$ part, I know that $-\sqrt{1-z}\leq x \leq \sqrt{1-z}$ But I'm not sure where the bounds for z would come from i.e. how does the second integral shown have 0 and 1 as the limits of integration for z? Also, isn't it technically that $0\leq z \leq 1-x^2 \implies$ $x^2 \leq z+x^2 \leq 1 $ $x^2-z\leq x^2 \leq 1-z$ $\pm\sqrt{x^2-z}\leq x \leq \pm \sqrt{1-z}$ Do I just ignore the left side of the equation?","I need to find out if it is true or false that these integrals are the same I know that From just the part, I know that But I'm not sure where the bounds for z would come from i.e. how does the second integral shown have 0 and 1 as the limits of integration for z? Also, isn't it technically that Do I just ignore the left side of the equation?","\int_{0}^{1}\int_{0}^{1}\int_{0}^{1-x^2} f(x,y,z)dz dy dx  \int_{0}^{1}\int_{0}^{1}\int_{-\sqrt{1-z}}^{\sqrt{1-z}}f(x,y,z) dx dy dz 0\leq z\leq 1-x^2 z\leq 1-x^2 -\sqrt{1-z}\leq x \leq \sqrt{1-z} 0\leq z \leq 1-x^2 \implies x^2 \leq z+x^2 \leq 1  x^2-z\leq x^2 \leq 1-z \pm\sqrt{x^2-z}\leq x \leq \pm \sqrt{1-z}","['multivariable-calculus', 'multiple-integral']"
59,"Continuity of $x^2y^2/(x^2+xy+y^2)$ at $(0,0)$",Continuity of  at,"x^2y^2/(x^2+xy+y^2) (0,0)","I want to check whether the function $f(x,y)=\frac{x^2y^2}{x^2+xy+y^2}$ with $f(0,0)=0$ is continuous at $(0,0)$ . But due to term $xy$ in addition to squares in the denominator, I am unable to proceed. Can one give some hint for it? I tried to find partial derivatives. Both partial derivatives are $0$ on $x$ as well as $y$ axis. But at other points, we get as: $f_x=\frac{x^2y^3+2xy^4}{(x^2+xy+y^2)^2}$ ; I couldn't get any direction to see whether this partial derivative w.r.t. $x$ is bounded near $(0,0)$ .","I want to check whether the function with is continuous at . But due to term in addition to squares in the denominator, I am unable to proceed. Can one give some hint for it? I tried to find partial derivatives. Both partial derivatives are on as well as axis. But at other points, we get as: ; I couldn't get any direction to see whether this partial derivative w.r.t. is bounded near .","f(x,y)=\frac{x^2y^2}{x^2+xy+y^2} f(0,0)=0 (0,0) xy 0 x y f_x=\frac{x^2y^3+2xy^4}{(x^2+xy+y^2)^2} x (0,0)","['real-analysis', 'calculus', 'multivariable-calculus', 'derivatives']"
60,"〈b, a, b〉 and 〈a, b, a〉: For what non zero values of a and b are these two vectors parallel?","〈b, a, b〉 and 〈a, b, a〉: For what non zero values of a and b are these two vectors parallel?",,"Looking for a hint on how to solve this problem. I know for the vectors to be parallel, the cross product must equal the zero vector, but I'm unsure on how to use that information to solve for values. $\langle b, a, b\rangle \times\langle a, b, a\rangle$ . For what non zero values of $a$ and $b$ are these two vectors parallel?","Looking for a hint on how to solve this problem. I know for the vectors to be parallel, the cross product must equal the zero vector, but I'm unsure on how to use that information to solve for values. . For what non zero values of and are these two vectors parallel?","\langle b, a, b\rangle \times\langle a, b, a\rangle a b","['calculus', 'multivariable-calculus', 'vectors']"
61,Derivative of quadratic form for matrices and vectors,Derivative of quadratic form for matrices and vectors,,"I'm not very familiar with multivariable calculus as it relates to matrices. Could someone explain, in detail, why $$\frac{\partial}{\partial x} \left[ x^T A x \right] = (A + A^T)x$$ In the case of a symmetric matrix and $$\frac{\partial}{\partial x} \left[ x^T A x \right] = 2Ax$$ if the matrix is not symmetric. I'm mainly confused about how we even arrive at the first derivative. However, I understand how the first derivative simplifies to the second in the case that A is symmetric.","I'm not very familiar with multivariable calculus as it relates to matrices. Could someone explain, in detail, why In the case of a symmetric matrix and if the matrix is not symmetric. I'm mainly confused about how we even arrive at the first derivative. However, I understand how the first derivative simplifies to the second in the case that A is symmetric.",\frac{\partial}{\partial x} \left[ x^T A x \right] = (A + A^T)x \frac{\partial}{\partial x} \left[ x^T A x \right] = 2Ax,"['multivariable-calculus', 'partial-derivative', 'matrix-calculus', 'machine-learning']"
62,Is log x + log y monotonically increasing with respect to x + y? [closed],Is log x + log y monotonically increasing with respect to x + y? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question We know $\log x + \log y = \log(xy)$ which is a monotonically increasing function with respect to the product $xy$ . I am wondering if $\log x + \log y$ is still a monotonically increasing function of the sum $x+y$ ?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question We know which is a monotonically increasing function with respect to the product . I am wondering if is still a monotonically increasing function of the sum ?",\log x + \log y = \log(xy) xy \log x + \log y x+y,"['calculus', 'multivariable-calculus', 'logarithms', 'monotone-functions']"
63,Why do we need to determine the definiteness of the Hessian to decide what a critical point is?,Why do we need to determine the definiteness of the Hessian to decide what a critical point is?,,"In univariate calculus, if we know that $f'(c)=0$ , we can determine if the function $f$ has a minimum at $c$ by checking that $f''(c) > 0$ . The multivariate analogue of the second derivative is the Hessian matrix. I now learned that to decide between extreme and saddle points in this case, it has to be checked whether the Hessian is positive definite, negative definite or indefinite. This can be achieved by checking its eigenvalues. I have several questions regarding this: Why is it not sufficient to check the sign of the values in the Hessian, but we need to check for definiteness? Does the definiteness just make sure some convexity or concavity properties check out, or is there a more meaningful interpretation of that? How do the eigenvalues of a matrix tell us its definiteness? Addendum: What do the off-diagonal entries in the Hessian even mean? How the slope in a certain dimension changes by making changes in a different dimension?","In univariate calculus, if we know that , we can determine if the function has a minimum at by checking that . The multivariate analogue of the second derivative is the Hessian matrix. I now learned that to decide between extreme and saddle points in this case, it has to be checked whether the Hessian is positive definite, negative definite or indefinite. This can be achieved by checking its eigenvalues. I have several questions regarding this: Why is it not sufficient to check the sign of the values in the Hessian, but we need to check for definiteness? Does the definiteness just make sure some convexity or concavity properties check out, or is there a more meaningful interpretation of that? How do the eigenvalues of a matrix tell us its definiteness? Addendum: What do the off-diagonal entries in the Hessian even mean? How the slope in a certain dimension changes by making changes in a different dimension?",f'(c)=0 f c f''(c) > 0,"['calculus', 'multivariable-calculus', 'optimization', 'maxima-minima', 'hessian-matrix']"
64,Multiple logarithmic integral [closed],Multiple logarithmic integral [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question How would one go to prove that $$\int_{0}^{1} \int_{0}^{1} \int_{0}^{1} \frac{\mathrm{d}(x, y,z)}{ \ln x + \ln y + \ln z} = - \frac{1}{2}$$ I'm not good handling multivariable integrals and nothing pops up in my head. Note: It should be noted that for two variables or one variable the integral diverges.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question How would one go to prove that $$\int_{0}^{1} \int_{0}^{1} \int_{0}^{1} \frac{\mathrm{d}(x, y,z)}{ \ln x + \ln y + \ln z} = - \frac{1}{2}$$ I'm not good handling multivariable integrals and nothing pops up in my head. Note: It should be noted that for two variables or one variable the integral diverges.",,"['integration', 'multivariable-calculus']"
65,Find the maximum value of given expression,Find the maximum value of given expression,,"$$ x+2y+3z = 15 $$ Find the maximum value of $$ 6(1+x)yz + x(2y+3z) $$ I substituted $2y+3z=15-x$ And tried to use AM GM to find maximum value of $xyz$ but they don't occur at same value. I know that this is not the right way to do it but I don't have any idea on how to do these type of questions. How do I proceed? Edit Do note that $x,y,z$ are positive real numbers.","$$ x+2y+3z = 15 $$ Find the maximum value of $$ 6(1+x)yz + x(2y+3z) $$ I substituted $2y+3z=15-x$ And tried to use AM GM to find maximum value of $xyz$ but they don't occur at same value. I know that this is not the right way to do it but I don't have any idea on how to do these type of questions. How do I proceed? Edit Do note that $x,y,z$ are positive real numbers.",,"['multivariable-calculus', 'optimization', 'maxima-minima', 'substitution', 'a.m.-g.m.-inequality']"
66,How does this version of the multivariable chain rule work?,How does this version of the multivariable chain rule work?,,"In my calculus book, it gives these formulas and states them as versions of the multivariable chain rule. I do not see how they make sense as if I cancel out the partial x’s, I get 1 = 2. Can someone explain this and tell me how these formulas work? $\partial f/\partial v = \partial f/\partial x \cdot  dx/dv + \partial f/\partial y \cdot dy/dv$ $\partial f/\partial u = \partial f/\partial x \cdot dx/du + \partial f/\partial y \cdot dy/du$ Note: These formulas are for partial derivatives of functions of form $f(x(u,v),y(u,v))$. Also please try to explain intuitively and not too rigourously.","In my calculus book, it gives these formulas and states them as versions of the multivariable chain rule. I do not see how they make sense as if I cancel out the partial x’s, I get 1 = 2. Can someone explain this and tell me how these formulas work? $\partial f/\partial v = \partial f/\partial x \cdot  dx/dv + \partial f/\partial y \cdot dy/dv$ $\partial f/\partial u = \partial f/\partial x \cdot dx/du + \partial f/\partial y \cdot dy/du$ Note: These formulas are for partial derivatives of functions of form $f(x(u,v),y(u,v))$. Also please try to explain intuitively and not too rigourously.",,"['multivariable-calculus', 'partial-derivative', 'chain-rule']"
67,A paradox in differential calculus,A paradox in differential calculus,,"Say I have a function $f=f(x,y)$ where $x,y$ are independent variables. Now, it is given that $p=x+y$. It can be shown that, since $x,y$ are independent, we get $$\frac{\partial p}{\partial x}=\frac{\partial x}{\partial x}+\frac{\partial y}{\partial x} \implies \frac{\partial p}{\partial x}=1+0 \implies \frac{\partial x}{\partial p}=1$$ and similarly $$\frac{\partial p}{\partial y}=\frac{\partial x}{\partial y}+\frac{\partial y}{\partial y} \implies \frac{\partial p}{\partial y}=0+1 \implies \frac{\partial y}{\partial p}=1$$ Now I can write that $$\frac{\partial f}{\partial p}=\frac{\partial f}{\partial x}\cdot\frac{\partial x}{\partial p}+\frac{\partial f}{\partial y}\cdot\frac{\partial y}{\partial p}$$ And using the above values, we get that $$\frac{\partial f}{\partial p}=\frac{\partial f}{\partial x}\cdot1+\frac{\partial f}{\partial y}\cdot1=\frac{\partial f}{\partial x}+\frac{\partial f}{\partial y}  \tag1$$ So if I replace $f$ by $p$ in $(1)$, which is quite valid since, like $f$, $p$ is also a function in $x,y$, we get that  $$\frac{\partial p}{\partial p}=\frac{\partial p}{\partial x}+\frac{\partial p}{\partial y} \implies \large\color{red}{1=2}$$ How is this possible? Where is the error? Can someone point it out for me? Addendum as per Surb's answer and comments : If, as Surb concludes, for $x,y$ being independent, $\frac{\partial x}{\partial p}=\frac{\partial y}{\partial p}=0$, so I will get $\frac{\partial f}{\partial p}=0$ for all $f=f(x,y)$. But this is not true at all. How about $f=p^2=(x+y)^2$? So where is the mistake?","Say I have a function $f=f(x,y)$ where $x,y$ are independent variables. Now, it is given that $p=x+y$. It can be shown that, since $x,y$ are independent, we get $$\frac{\partial p}{\partial x}=\frac{\partial x}{\partial x}+\frac{\partial y}{\partial x} \implies \frac{\partial p}{\partial x}=1+0 \implies \frac{\partial x}{\partial p}=1$$ and similarly $$\frac{\partial p}{\partial y}=\frac{\partial x}{\partial y}+\frac{\partial y}{\partial y} \implies \frac{\partial p}{\partial y}=0+1 \implies \frac{\partial y}{\partial p}=1$$ Now I can write that $$\frac{\partial f}{\partial p}=\frac{\partial f}{\partial x}\cdot\frac{\partial x}{\partial p}+\frac{\partial f}{\partial y}\cdot\frac{\partial y}{\partial p}$$ And using the above values, we get that $$\frac{\partial f}{\partial p}=\frac{\partial f}{\partial x}\cdot1+\frac{\partial f}{\partial y}\cdot1=\frac{\partial f}{\partial x}+\frac{\partial f}{\partial y}  \tag1$$ So if I replace $f$ by $p$ in $(1)$, which is quite valid since, like $f$, $p$ is also a function in $x,y$, we get that  $$\frac{\partial p}{\partial p}=\frac{\partial p}{\partial x}+\frac{\partial p}{\partial y} \implies \large\color{red}{1=2}$$ How is this possible? Where is the error? Can someone point it out for me? Addendum as per Surb's answer and comments : If, as Surb concludes, for $x,y$ being independent, $\frac{\partial x}{\partial p}=\frac{\partial y}{\partial p}=0$, so I will get $\frac{\partial f}{\partial p}=0$ for all $f=f(x,y)$. But this is not true at all. How about $f=p^2=(x+y)^2$? So where is the mistake?",,"['calculus', 'multivariable-calculus', 'fake-proofs', 'differential', 'paradoxes']"
68,"Differentiation under the integral sign for $\int_{0}^{1}\frac{\arctan x}{x\sqrt{1-x^2}}\,dx$",Differentiation under the integral sign for,"\int_{0}^{1}\frac{\arctan x}{x\sqrt{1-x^2}}\,dx",Hello I have a problem that is: $$\int_0^1\frac{\arctan(x)}{x\sqrt{1-x^2}}dx$$ I try use the following integral $$ \int_0^1\frac{dy}{1+x^2y^2}= \frac{\arctan(x)}{x}$$ My question: if I can do $$\frac{\arctan(x)}{x\sqrt{1-x^2}}= \int_0^1\frac{dy}{(1+x^2y^2)(\sqrt{1-x^2})}$$ and solve but I note that the integral is more difficult. Any comment or any help will be well received. Thanks.,Hello I have a problem that is: $$\int_0^1\frac{\arctan(x)}{x\sqrt{1-x^2}}dx$$ I try use the following integral $$ \int_0^1\frac{dy}{1+x^2y^2}= \frac{\arctan(x)}{x}$$ My question: if I can do $$\frac{\arctan(x)}{x\sqrt{1-x^2}}= \int_0^1\frac{dy}{(1+x^2y^2)(\sqrt{1-x^2})}$$ and solve but I note that the integral is more difficult. Any comment or any help will be well received. Thanks.,,"['calculus', 'real-analysis', 'integration', 'multivariable-calculus', 'definite-integrals']"
69,A high-level reason that $u \cdot (v \times w) = (u \times v) \cdot w$?,A high-level reason that ?,u \cdot (v \times w) = (u \times v) \cdot w,"I can do the algebra to show that for $u, v, w \in \mathbb{R}^3$, this identity is true: $$u \cdot (v \times w) = (u \times v) \cdot w$$ But is there a more high-level reason? I didn't expect the cross and dot product to be connected in this surprising way.","I can do the algebra to show that for $u, v, w \in \mathbb{R}^3$, this identity is true: $$u \cdot (v \times w) = (u \times v) \cdot w$$ But is there a more high-level reason? I didn't expect the cross and dot product to be connected in this surprising way.",,"['multivariable-calculus', 'vectors', 'cross-product']"
70,Finding the area enclosed by a curve without usual 1-D explicit integration.,Finding the area enclosed by a curve without usual 1-D explicit integration.,,"I am trying to find the area enclosed by the curve $$x^4 + y^4 = 4xy$$ in the first quadrant. Solving the roots of a quartic polynomial $y$ does not seem to be an efficient way to approach this. I am considering simplifying the problem converting to polar coordinates in the equation that defines the curve, or perhaps define the curve as a parametric function (in terms of some parameter $t$) and then use Green's Theorem. Any guidance regarding this idea or another technique is appreciated.","I am trying to find the area enclosed by the curve $$x^4 + y^4 = 4xy$$ in the first quadrant. Solving the roots of a quartic polynomial $y$ does not seem to be an efficient way to approach this. I am considering simplifying the problem converting to polar coordinates in the equation that defines the curve, or perhaps define the curve as a parametric function (in terms of some parameter $t$) and then use Green's Theorem. Any guidance regarding this idea or another technique is appreciated.",,['multivariable-calculus']
71,Is $f$ bijective on$\mathbb{R}^2$?,Is  bijective on?,f \mathbb{R}^2,"Let $f(x,y)=(x^2-y^2,2xy)$ a function from $\mathbb{R}^2\to\mathbb{R}^2$. Study if $f$ does have an inverse in whole $\mathbb{R}^2$? My approach: Since $\det(Df(x,y))=(2x)(2x)-(-2y)(2y)=4x^2+4y^2\neq 0$ for $x,y\neq 0$ then $f$ is locally invertible, for any $(x,y)\neq (0,0)$. But how can I know if this inverse function is the same for all the points in $\mathbb{R}^2$? Thanks!","Let $f(x,y)=(x^2-y^2,2xy)$ a function from $\mathbb{R}^2\to\mathbb{R}^2$. Study if $f$ does have an inverse in whole $\mathbb{R}^2$? My approach: Since $\det(Df(x,y))=(2x)(2x)-(-2y)(2y)=4x^2+4y^2\neq 0$ for $x,y\neq 0$ then $f$ is locally invertible, for any $(x,y)\neq (0,0)$. But how can I know if this inverse function is the same for all the points in $\mathbb{R}^2$? Thanks!",,['multivariable-calculus']
72,The projection of a vector value function onto the xz-plane.,The projection of a vector value function onto the xz-plane.,,"Okay, so I missed CalcIII today and I'm struggling a bit here. $r(t) = (\sin t,\cos t,7\sin t + 4\cos 2t)$ Find the projection of $r(t)$ onto the xz-plane for $−1 \leq x \leq 1$ Answer as an equation using the variables $x$, $y$, and $z$. P.S. I clepped CalcI and II.... in 2010. Haven't done much since then so I'm just a little out of practice, need to kick my brain back into gear.","Okay, so I missed CalcIII today and I'm struggling a bit here. $r(t) = (\sin t,\cos t,7\sin t + 4\cos 2t)$ Find the projection of $r(t)$ onto the xz-plane for $−1 \leq x \leq 1$ Answer as an equation using the variables $x$, $y$, and $z$. P.S. I clepped CalcI and II.... in 2010. Haven't done much since then so I'm just a little out of practice, need to kick my brain back into gear.",,['multivariable-calculus']
73,Verifying Stokes' Theorem,Verifying Stokes' Theorem,,"Verify Stokes' Theorem for the given vector field $f(x, y, z)$ and surface $\Sigma$. $$f(x, y, z) = 2y \textbf{i} - x \textbf{j} + z \textbf{k}; \quad \Sigma : x^2 + y^2 + z^2 = 1, z \ge 0$$ This was the solution given. I understand the line integral part, but not the surface integral. Could someone explain each of the steps? Also, the previous answers to the question said to parameterize in spherical coordinates, but this doesn't. Could someone explain that alternate solution as well? Thank you.","Verify Stokes' Theorem for the given vector field $f(x, y, z)$ and surface $\Sigma$. $$f(x, y, z) = 2y \textbf{i} - x \textbf{j} + z \textbf{k}; \quad \Sigma : x^2 + y^2 + z^2 = 1, z \ge 0$$ This was the solution given. I understand the line integral part, but not the surface integral. Could someone explain each of the steps? Also, the previous answers to the question said to parameterize in spherical coordinates, but this doesn't. Could someone explain that alternate solution as well? Thank you.",,['multivariable-calculus']
74,"$f(x,y)=\frac{x^3}{x^2+y^2}$ is not differentiable at $(0,0)$",is not differentiable at,"f(x,y)=\frac{x^3}{x^2+y^2} (0,0)","Define $f(x,y)=\frac{x^3}{x^2+y^2}$ if $(x,y)\neq(0,0)$ and $f(x,y)=0$ for $(x,y)=(0,0)$   Show that it is not differentiable at $(0,0)$ I figured out that both $f_x$ and $f_y$ exists and are discontinuous at $(0,0)$  but can't say anything about differentiability of $f(x,y)$ at $(0,0)$ and also $f(x,y)$ looks like a continuous function!","Define $f(x,y)=\frac{x^3}{x^2+y^2}$ if $(x,y)\neq(0,0)$ and $f(x,y)=0$ for $(x,y)=(0,0)$   Show that it is not differentiable at $(0,0)$ I figured out that both $f_x$ and $f_y$ exists and are discontinuous at $(0,0)$  but can't say anything about differentiability of $f(x,y)$ at $(0,0)$ and also $f(x,y)$ looks like a continuous function!",,"['functions', 'multivariable-calculus', 'continuity', 'partial-derivative']"
75,Incomplete vector field,Incomplete vector field,,"Is there a way I can tell if a vector field on a manifold or just $\mathbb{R}^n$ is incomplete simply by just looking at its formula.  For instance on $\mathbb{R}$, $\displaystyle X= (x^2+1) \frac{\partial}{\partial x}$, is incomplete as it shoots off to infinity in finite time as evidenced by its flow $F=\tan(t-C)$.  Should I be able to see that X was going to be incomplete without computing $F$?","Is there a way I can tell if a vector field on a manifold or just $\mathbb{R}^n$ is incomplete simply by just looking at its formula.  For instance on $\mathbb{R}$, $\displaystyle X= (x^2+1) \frac{\partial}{\partial x}$, is incomplete as it shoots off to infinity in finite time as evidenced by its flow $F=\tan(t-C)$.  Should I be able to see that X was going to be incomplete without computing $F$?",,['differential-geometry']
76,epsilon delta proof for 2 variable limit,epsilon delta proof for 2 variable limit,,"Hey I need to show that $$\lim_{(x,y)\to(0,0)}  {xy \over \sqrt{x^2 + y^2}} = 0.$$ I'm not sure how to start manipulating this as I haven't gotten anything useful yet. Some help to get me going would be nice. Thanks","Hey I need to show that $$\lim_{(x,y)\to(0,0)}  {xy \over \sqrt{x^2 + y^2}} = 0.$$ I'm not sure how to start manipulating this as I haven't gotten anything useful yet. Some help to get me going would be nice. Thanks",,"['calculus', 'multivariable-calculus']"
77,What volume does $2x \le x^2+y^2+z^2 \le 4x$ represent?,What volume does  represent?,2x \le x^2+y^2+z^2 \le 4x,"I'm evaluating $\iiint_V f(x,y,z) dV$ where V is defined by $$2x \le x^2+y^2+z^2 \le 4x $$ To simplify things I swapped x and z, and moved to spherical coordinates: $$ 0 \le \theta \le 2\pi, 2 \cos \phi \le \rho \le 4 \cos \phi$$ and as the last condition implies $ 4 \cos \phi \ge \rho \ge 0$, I added $0 \le \phi \le \pi/2$ The point is: I have no idea if this parametrization is correct, because I can't figure what that disequations represents. From the spherical parametrization it looks like some paraboloid but I'm confused. Could you help in this? And how do I approach such ""confused"" situations? thanks.","I'm evaluating $\iiint_V f(x,y,z) dV$ where V is defined by $$2x \le x^2+y^2+z^2 \le 4x $$ To simplify things I swapped x and z, and moved to spherical coordinates: $$ 0 \le \theta \le 2\pi, 2 \cos \phi \le \rho \le 4 \cos \phi$$ and as the last condition implies $ 4 \cos \phi \ge \rho \ge 0$, I added $0 \le \phi \le \pi/2$ The point is: I have no idea if this parametrization is correct, because I can't figure what that disequations represents. From the spherical parametrization it looks like some paraboloid but I'm confused. Could you help in this? And how do I approach such ""confused"" situations? thanks.",,"['multivariable-calculus', 'analytic-geometry']"
78,Mean Value Theorem for a Multivariate Function $\mathbb{R}^2 \to \mathbb{R}$,Mean Value Theorem for a Multivariate Function,\mathbb{R}^2 \to \mathbb{R},"I am reviewing masters exams and can't recall the multivariable calculus one needs to prove that this is true. A reference would suffice. Thank you! Suppose $x_1,x_2,x_3 \in \mathbb{R}^2$ are three points in the plane that do not lie on a line, and denote by $T$ the closed triangle with vertices $x_1,x_2,x_3$ . Suppose $f : T \to \mathbb{R}$ is a continuous function which is differentiable on the interior of $T$ and which vanishes on the boundary of $T$ . Prove that there exists a point $x$ in the interior of $T$ such that the tangent plane to the graph of $f$ at the point $x$ is horizontal. EDIT: I've been looking through the Wikipedia links, and I understand that for every line there is a point where the derivative must be zero, but I don't see how to the prove the existence of a point where the derivative along every line must be zero. So I may need to be walked through this a little more, if you have time.","I am reviewing masters exams and can't recall the multivariable calculus one needs to prove that this is true. A reference would suffice. Thank you! Suppose are three points in the plane that do not lie on a line, and denote by the closed triangle with vertices . Suppose is a continuous function which is differentiable on the interior of and which vanishes on the boundary of . Prove that there exists a point in the interior of such that the tangent plane to the graph of at the point is horizontal. EDIT: I've been looking through the Wikipedia links, and I understand that for every line there is a point where the derivative must be zero, but I don't see how to the prove the existence of a point where the derivative along every line must be zero. So I may need to be walked through this a little more, if you have time.","x_1,x_2,x_3 \in \mathbb{R}^2 T x_1,x_2,x_3 f : T \to \mathbb{R} T T x T f x","['calculus', 'multivariable-calculus']"
79,About the continuity of the partial derivative,About the continuity of the partial derivative,,"I'm trying to study if the following function has continuous partial derivatives at the origin: $$f(x, y) = \begin{cases}\frac{x^4y^3}{x^8 + y^4} & (x, y) \neq (0, 0) \\\\ \quad 0 & (x, y) = (0, 0)\end{cases}$$ I proved $f$ is continuous at the origin, and I also proved its partial derivatives exist at the origin. Now to show the continuity of $f'_x$ at $(0, 0)$ here is what I did: $$\frac{\partial f}{\partial x} = \frac{4x^3y^3(y^4 - x^8)}{(x^8 + y^4)^2}$$ Having observed it goes to zero along various paths, I did: $$\bigg|\frac{4x^3y^3(y^4 - x^8)}{(x^8 + y^4)^2}\bigg| \leq \frac{4x^2y^2|x| |y| (x^8 + y^4)}{(x^8+y^4)^2} \leq \frac{4x^2y^2|x| |y|}{y^4} = \frac{4x^2|x|}{|y|}$$ But now I am stuck. If for example I say $y = x^4$ , this reduces to $\frac{4}{|x|}$ which does not goes to zero. But the notes say the partial derivatives are continuous (without any proof...) Any help? Thank you! Notice We cannot use polar coordinates. We are demanded to find a distance function to make an upper bound to the function we have, in order to conclude it goes to $0$ as $(x, y) \to (0, 0)$ .","I'm trying to study if the following function has continuous partial derivatives at the origin: I proved is continuous at the origin, and I also proved its partial derivatives exist at the origin. Now to show the continuity of at here is what I did: Having observed it goes to zero along various paths, I did: But now I am stuck. If for example I say , this reduces to which does not goes to zero. But the notes say the partial derivatives are continuous (without any proof...) Any help? Thank you! Notice We cannot use polar coordinates. We are demanded to find a distance function to make an upper bound to the function we have, in order to conclude it goes to as .","f(x, y) = \begin{cases}\frac{x^4y^3}{x^8 + y^4} & (x, y) \neq (0, 0) \\\\ \quad 0 & (x, y) = (0, 0)\end{cases} f f'_x (0, 0) \frac{\partial f}{\partial x} = \frac{4x^3y^3(y^4 - x^8)}{(x^8 + y^4)^2} \bigg|\frac{4x^3y^3(y^4 - x^8)}{(x^8 + y^4)^2}\bigg| \leq \frac{4x^2y^2|x| |y| (x^8 + y^4)}{(x^8+y^4)^2} \leq \frac{4x^2y^2|x| |y|}{y^4} = \frac{4x^2|x|}{|y|} y = x^4 \frac{4}{|x|} 0 (x, y) \to (0, 0)","['multivariable-calculus', 'continuity', 'partial-derivative']"
80,Integrating $e^{-(x^2+y^2+z^2)/a^2}$ over $\mathbb{R}^3$,Integrating  over,e^{-(x^2+y^2+z^2)/a^2} \mathbb{R}^3,"I want to compute the following integral $$ \int_{\mathbb{R}^3}e^{-(x^2+y^2+z^2)/a^2}\,dxdydz $$ and I thought that using spherical coordinates could make it easier, since $r^2=x^2+y^2+z^2$ . With this in mind, I tried $$ \int_{\mathbb{R}^3}e^{-(x^2+y^2+z^2)/a^2}\,dxdydz=\int_0^\infty\int_0^{2\pi}\int_0^\pi r^2\sin \theta \,d\theta d\phi dr=4\pi\int_0^\infty r^2e^{-r^2/a^2}\,dr $$ but I am stuck. Any ideas? Should I simply try to integrate it in cartesian coordinates?","I want to compute the following integral and I thought that using spherical coordinates could make it easier, since . With this in mind, I tried but I am stuck. Any ideas? Should I simply try to integrate it in cartesian coordinates?","
\int_{\mathbb{R}^3}e^{-(x^2+y^2+z^2)/a^2}\,dxdydz
 r^2=x^2+y^2+z^2 
\int_{\mathbb{R}^3}e^{-(x^2+y^2+z^2)/a^2}\,dxdydz=\int_0^\infty\int_0^{2\pi}\int_0^\pi r^2\sin \theta \,d\theta d\phi dr=4\pi\int_0^\infty r^2e^{-r^2/a^2}\,dr
","['integration', 'multivariable-calculus', 'spherical-coordinates']"
81,"Substitution in double integrals. When can I substitute the same way as in one-variable integrals, and when do I need to use the jacobian?","Substitution in double integrals. When can I substitute the same way as in one-variable integrals, and when do I need to use the jacobian?",,"I'm just learning (multivariable) calculus and tried solve the following double integral: $$\int_0^2 \int_0^1 x y e^{x y^2} d y d x$$ I approached it initially using traditional u-substitution similar to one-dimensional integrals. Surprisingly, it yielded the correct result, but as I delved deeper into my textbook, I discovered a more rigorous method involving the Jacobian in multivariable integrals. So my question is: When does traditional u-substitution work in multiple-dimensional integrals, and when do I need to use the more rigorous approach with the Jacobian? Below I have explained my initial approach to solving the integral and the more rigorous approach using the Jacobian. My initial attempt: $$ \int_0^2 \int_0^1 x y e^{x y^2} d y d x $$ I would then make u-substitution like this, where I treat x as a constant: $u=xy^2$ , $\frac{du}{dy}=2xy \implies du=2xy\;dy$ (I now realise this is wrong, since this is not the total derivative, but the partial derivative $\partial u/\partial y$ ). $$ =\int_0^2 \int_0^1 \frac{1}{2} e^{ \overbrace{x y^2}^{u}} \underbrace{2x y \;d y}_{du} \; d x = \int_0^2 \int_0^x \frac{1}{2}e^u \;du \;dx = =\frac{1}{2} \int_0^2\left[e^u\right]_0^x d x=\frac{1}{2} \int_0^2\left(e^x-e^0\right) d x=\frac{1}{2}\left[e^x-x\right]_0^2 $$ $$=\frac{e^2-3}{2}$$ Now this gives the correct result, even though the way I'm doing substitution seems to be inconsistent with how my book treats substitution of multivariable integrals. Why does this work? Was it a coincidence that it worked, or can I always make u-substitution like this in multivariable integrals? How my book treats substitution in multivariable integrals: Substitution in my book is presented as: $$ \iint_R f(x, y) d x d y=\iint_G f(g(u, v), h(u, v))\left|\frac{\partial(x, y)}{\partial(u, v)}\right| d u d v . $$ With the Jacobian determinant or Jacobian of the coordinate transformation $x=g(u, v), y=h(u, v)$ defined as $$ J(u, v)=\left|\begin{array}{ll} \frac{\partial x}{\partial u} & \frac{\partial x}{\partial v} \\ \frac{\partial y}{\partial u} & \frac{\partial y}{\partial v} \end{array}\right|=\frac{\partial x}{\partial u} \frac{\partial y}{\partial v}-\frac{\partial y}{\partial u} \frac{\partial x}{\partial v} . $$ The Jacobian can also be denoted by $$ J(u, v)=\frac{\partial(x, y)}{\partial(u, v)} $$ How I should solve it rigorously So I imagine that in my case if I want to make proper substitution with, I should write the above equation as: $$ \iint_R f(g(x, y), h(x, y))\left|\frac{\partial(u, v)}{\partial(x, y)}\right| d x d y=\iint_G f(u, v) d u d v $$ If I choose $u=xy^2$ and $v=xy$ , then I get: $$ \left|\frac{\partial(u, v)}{\partial(x, y)}\right|=\left|\left|\begin{array}{ll} \frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{array}\right|\right|=\left|\left|\begin{array}{ll} y^2 & 2 x y \\ y^{x^2} & x \end{array}\right|\right|=|y^2 x-2 x y^2|=x y^2 $$ Since $x\geq 0$ on the interval we are considering in the integral. So I could rewrite the integral: $$ \int_0^2 \int_0^1 x y e^{x y^2} d y d x =\int_0^2 \int_0^1\frac{\overbrace{xy^2}^{\left|\frac{\partial(u, v)}{\partial(x, y)}\right|}}{\underbrace{xy^2}_{u}} \underbrace{x y}_{v} e^{\overbrace{x y^2}^{u}} d y d x  =\begin{cases}     \int_0^2 \int_{v^2/2}^{2v} \frac{v}{u} e^u d u d v \\     \int_0^2 \int_{u}^{\sqrt{2u}} \frac{v}{u} e^u d v d u \\   \end{cases} $$ Where the integration boundaries come from sketching the domain transformation from the cartesian coordinate system y(x) (enclosed rectangle) to the new domain $u(v)$ or $v(u)$ (new enclosed shapes) by using the above definitions for $u$ , $v$ . $u(v)=v^2/x = vy$ or $v(u)=u/y=\sqrt{ux}$ The second integral is solvable analytically and leads to the same result as the initial approach: $$=\int_0^2 \int_{u}^{\sqrt{2u}} \frac{v}{u} e^u d v d u=\int_0^2\left[\frac{1}{2} v^2\right]_u^{\sqrt{2u}} \frac{e^u}{u} d u = \int_0^2\left(u-\frac{u^2}{2}\right) \frac{e^u}{u} d u =\int_0^2\left(e^u-\frac{1}{2} u e^u\right) d u $$ $$\underbrace{=}_{\text{partial integration}}e^2-e^0-\frac{1}{2}\left(\left[u e^u\right]_0^2-\int_0^2 e^u d u\right)=\frac{e^2-3}{2}$$ But as you can tell, it is much more work using the rigorous method and I obtain the same result anyhow. How can I in general tell if it works correctly to use the initial dummy approach, and when do I need to use the rigorous approach with the Jacobian? What also seems to be an issue, is that substitution in multivariable integrals is not in our curriculum. So it's only something I figured myself by reading outside our curriculum.","I'm just learning (multivariable) calculus and tried solve the following double integral: I approached it initially using traditional u-substitution similar to one-dimensional integrals. Surprisingly, it yielded the correct result, but as I delved deeper into my textbook, I discovered a more rigorous method involving the Jacobian in multivariable integrals. So my question is: When does traditional u-substitution work in multiple-dimensional integrals, and when do I need to use the more rigorous approach with the Jacobian? Below I have explained my initial approach to solving the integral and the more rigorous approach using the Jacobian. My initial attempt: I would then make u-substitution like this, where I treat x as a constant: , (I now realise this is wrong, since this is not the total derivative, but the partial derivative ). Now this gives the correct result, even though the way I'm doing substitution seems to be inconsistent with how my book treats substitution of multivariable integrals. Why does this work? Was it a coincidence that it worked, or can I always make u-substitution like this in multivariable integrals? How my book treats substitution in multivariable integrals: Substitution in my book is presented as: With the Jacobian determinant or Jacobian of the coordinate transformation defined as The Jacobian can also be denoted by How I should solve it rigorously So I imagine that in my case if I want to make proper substitution with, I should write the above equation as: If I choose and , then I get: Since on the interval we are considering in the integral. So I could rewrite the integral: Where the integration boundaries come from sketching the domain transformation from the cartesian coordinate system y(x) (enclosed rectangle) to the new domain or (new enclosed shapes) by using the above definitions for , . or The second integral is solvable analytically and leads to the same result as the initial approach: But as you can tell, it is much more work using the rigorous method and I obtain the same result anyhow. How can I in general tell if it works correctly to use the initial dummy approach, and when do I need to use the rigorous approach with the Jacobian? What also seems to be an issue, is that substitution in multivariable integrals is not in our curriculum. So it's only something I figured myself by reading outside our curriculum.","\int_0^2 \int_0^1 x y e^{x y^2} d y d x 
\int_0^2 \int_0^1 x y e^{x y^2} d y d x
 u=xy^2 \frac{du}{dy}=2xy \implies du=2xy\;dy \partial u/\partial y 
=\int_0^2 \int_0^1 \frac{1}{2} e^{ \overbrace{x y^2}^{u}} \underbrace{2x y \;d y}_{du} \; d x = \int_0^2 \int_0^x \frac{1}{2}e^u \;du \;dx = =\frac{1}{2} \int_0^2\left[e^u\right]_0^x d x=\frac{1}{2} \int_0^2\left(e^x-e^0\right) d x=\frac{1}{2}\left[e^x-x\right]_0^2
 =\frac{e^2-3}{2} 
\iint_R f(x, y) d x d y=\iint_G f(g(u, v), h(u, v))\left|\frac{\partial(x, y)}{\partial(u, v)}\right| d u d v .
 x=g(u, v), y=h(u, v) 
J(u, v)=\left|\begin{array}{ll}
\frac{\partial x}{\partial u} & \frac{\partial x}{\partial v} \\
\frac{\partial y}{\partial u} & \frac{\partial y}{\partial v}
\end{array}\right|=\frac{\partial x}{\partial u} \frac{\partial y}{\partial v}-\frac{\partial y}{\partial u} \frac{\partial x}{\partial v} .
 
J(u, v)=\frac{\partial(x, y)}{\partial(u, v)}
 
\iint_R f(g(x, y), h(x, y))\left|\frac{\partial(u, v)}{\partial(x, y)}\right| d x d y=\iint_G f(u, v) d u d v
 u=xy^2 v=xy 
\left|\frac{\partial(u, v)}{\partial(x, y)}\right|=\left|\left|\begin{array}{ll}
\frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\
\frac{\partial v}{\partial x} & \frac{\partial v}{\partial y}
\end{array}\right|\right|=\left|\left|\begin{array}{ll}
y^2 & 2 x y \\
y^{x^2} & x
\end{array}\right|\right|=|y^2 x-2 x y^2|=x y^2
 x\geq 0 
\int_0^2 \int_0^1 x y e^{x y^2} d y d x =\int_0^2 \int_0^1\frac{\overbrace{xy^2}^{\left|\frac{\partial(u, v)}{\partial(x, y)}\right|}}{\underbrace{xy^2}_{u}} \underbrace{x y}_{v} e^{\overbrace{x y^2}^{u}} d y d x  =\begin{cases}
    \int_0^2 \int_{v^2/2}^{2v} \frac{v}{u} e^u d u d v \\
    \int_0^2 \int_{u}^{\sqrt{2u}} \frac{v}{u} e^u d v d u \\
  \end{cases}
 u(v) v(u) u v u(v)=v^2/x = vy v(u)=u/y=\sqrt{ux} =\int_0^2 \int_{u}^{\sqrt{2u}} \frac{v}{u} e^u d v d u=\int_0^2\left[\frac{1}{2} v^2\right]_u^{\sqrt{2u}} \frac{e^u}{u} d u = \int_0^2\left(u-\frac{u^2}{2}\right) \frac{e^u}{u} d u =\int_0^2\left(e^u-\frac{1}{2} u e^u\right) d u  \underbrace{=}_{\text{partial integration}}e^2-e^0-\frac{1}{2}\left(\left[u e^u\right]_0^2-\int_0^2 e^u d u\right)=\frac{e^2-3}{2}","['calculus', 'multivariable-calculus', 'substitution', 'multiple-integral', 'jacobian']"
82,Area of $x^{10}+y^{10}\leq 1$,Area of,x^{10}+y^{10}\leq 1,"Whilst looking at someone's vector calculus problem, they mentioned that, making use of Green's Theorem, they had to express the line integral of the boundary of $x^{10}+y^{10}\leq 1$ in terms of its area. The thing is they gave you the area as computed with Mathematica to be $4\Gamma^2(11/10)/\Gamma(6/5)\approx 3.943.$ And I was wondering how you'd prove this: $$\mathcal{A}=\iint_{x^{10}+y^{10}\leq1}dydx=2\int_{-1}^1\sqrt[10]{1-x^{10}}dx=\dfrac{4\Gamma^2(11/10)}{\Gamma(6/5)}.$$","Whilst looking at someone's vector calculus problem, they mentioned that, making use of Green's Theorem, they had to express the line integral of the boundary of in terms of its area. The thing is they gave you the area as computed with Mathematica to be And I was wondering how you'd prove this:",x^{10}+y^{10}\leq 1 4\Gamma^2(11/10)/\Gamma(6/5)\approx 3.943. \mathcal{A}=\iint_{x^{10}+y^{10}\leq1}dydx=2\int_{-1}^1\sqrt[10]{1-x^{10}}dx=\dfrac{4\Gamma^2(11/10)}{\Gamma(6/5)}.,"['calculus', 'integration', 'multivariable-calculus', 'area']"
83,Is function application itself a function?,Is function application itself a function?,,Is function application itself a function? So given a function $f$ and an element $x$ we can define the function that takes $f$ and it's element $x$ to the value of $f$ at $x$ ?,Is function application itself a function? So given a function and an element we can define the function that takes and it's element to the value of at ?,f x f x f x,"['calculus', 'multivariable-calculus', 'functions', 'notation']"
84,Help me understand easy (not for me) concepts in volume integral,Help me understand easy (not for me) concepts in volume integral,,"Keep looking at the page for an hour. Still not sure how I can get the sloping surface of $x+y+z=1$ and integration ranges for $x, y, z$ . and why their range is different too. The book keeps throwing things at me without much explanation. Help me.",Keep looking at the page for an hour. Still not sure how I can get the sloping surface of and integration ranges for . and why their range is different too. The book keeps throwing things at me without much explanation. Help me.,"x+y+z=1 x, y, z",['integration']
85,Can we take the exponential function of a vector?,Can we take the exponential function of a vector?,,"Main question: If $x=(x_1,x_2)\in \mathbb R^2$ , can we have the exponential function of the vector, i.e. $$ e^{i \pi x}=e^{i \pi (x_1,x_2)} \quad? \tag 1 $$ Follow-up question: Can we in some way ""split"" $e^{i \pi (x_1,x_2)}$ ? I'm thinking of the rule the $e^{ia}e^{ib}=e^{i(a+b)}$ , where $a,b\in \mathbb R$ . A test, if we use the standard basis and write the vector as $$ x=(x_1,x_2)=\hat e_1 x_1+\hat e_2x_2 \tag 2 $$ Can we now write $(1)$ as \begin{align} e^{i \pi (x_1,x_2)} &= e^{i \pi (\hat e_1 x_1+\hat e_2x_2)}  \tag 3\\ &= e^{i \pi (\hat e_1 x_1)} e^{i \pi (\hat e_2 x_2)} \quad? \tag 4 \end{align} Is this legitimate?","Main question: If , can we have the exponential function of the vector, i.e. Follow-up question: Can we in some way ""split"" ? I'm thinking of the rule the , where . A test, if we use the standard basis and write the vector as Can we now write as Is this legitimate?","x=(x_1,x_2)\in \mathbb R^2 
e^{i \pi x}=e^{i \pi (x_1,x_2)} \quad? \tag 1
 e^{i \pi (x_1,x_2)} e^{ia}e^{ib}=e^{i(a+b)} a,b\in \mathbb R 
x=(x_1,x_2)=\hat e_1 x_1+\hat e_2x_2 \tag 2
 (1) \begin{align}
e^{i \pi (x_1,x_2)} &=
e^{i \pi (\hat e_1 x_1+\hat e_2x_2)}  \tag 3\\
&=
e^{i \pi (\hat e_1 x_1)}
e^{i \pi (\hat e_2 x_2)}
\quad? \tag 4
\end{align}","['linear-algebra', 'multivariable-calculus', 'functions', 'vectors']"
86,What is the inverse/opposite of a double integral?,What is the inverse/opposite of a double integral?,,"I am currently taking Calc 3 and we just finished our unit on double/triple integrals. I started thinking about a problem back from AP Physics (where my teacher did an impressive amount of hand waving to somehow avoid directly explaining vector calculus when discussing Maxwell's equations, leading to me spending an entire semester confused about what the heck flux was supposed to be or why it should matter), which basically boils down to $\iiint_D{F(x, y, z)}{dV}=Q(D)$ . In Calc 1 and 2, if you have an equation of the form $\int{f(x)}{dx}=g(x)$ , then you can take the ""inverse integral"" (i.e. derivative with respect to x) of both sides, which gives $f(x)=\frac{d}{dx}g(x)$ . However, I cannot seem to figure out what the analogue of this would be for a double or triple integral. What is the opposite/inverse operation for a double or triple integral over some domain $D$ ?","I am currently taking Calc 3 and we just finished our unit on double/triple integrals. I started thinking about a problem back from AP Physics (where my teacher did an impressive amount of hand waving to somehow avoid directly explaining vector calculus when discussing Maxwell's equations, leading to me spending an entire semester confused about what the heck flux was supposed to be or why it should matter), which basically boils down to . In Calc 1 and 2, if you have an equation of the form , then you can take the ""inverse integral"" (i.e. derivative with respect to x) of both sides, which gives . However, I cannot seem to figure out what the analogue of this would be for a double or triple integral. What is the opposite/inverse operation for a double or triple integral over some domain ?","\iiint_D{F(x, y, z)}{dV}=Q(D) \int{f(x)}{dx}=g(x) f(x)=\frac{d}{dx}g(x) D",['multivariable-calculus']
87,Maximize $\boxed{\mathbf{x}+\mathbf{y}}$ subject to the condition that $2 x^{2}+3 y^{2} \leq 1$,Maximize  subject to the condition that,\boxed{\mathbf{x}+\mathbf{y}} 2 x^{2}+3 y^{2} \leq 1,"Maximize $\mathbf{x}+\mathbf{y}$ subject to the condition that $2 x^{2}+3 y^{2} \leq 1$ My approach $\frac{x^{2}}{1 / 2}+\frac{y^{2}}{1 / 3} \leq 1$ Let $z=x+y$ $\mathrm{Now}, 4 \mathrm{x}+6 \mathrm{y} \frac{d y}{d x}=0 \Rightarrow \frac{d y}{d x}=-\frac{2 x}{3 y}$ $2 x^{2}+3 y^{2}=1$ What to do next? Any suggestion or Hint would be greatly appreciated!",Maximize subject to the condition that My approach Let What to do next? Any suggestion or Hint would be greatly appreciated!,"\mathbf{x}+\mathbf{y} 2 x^{2}+3 y^{2} \leq 1 \frac{x^{2}}{1 / 2}+\frac{y^{2}}{1 / 3} \leq 1 z=x+y \mathrm{Now}, 4 \mathrm{x}+6 \mathrm{y} \frac{d y}{d x}=0 \Rightarrow \frac{d y}{d x}=-\frac{2 x}{3 y} 2 x^{2}+3 y^{2}=1","['calculus', 'multivariable-calculus']"
88,Calculating the determinant of the Hessian of a function,Calculating the determinant of the Hessian of a function,,"Suppose one is given a function \begin{equation} f(x_1,\dots,x_n) = g\bigg(x_1,\bigg(\sum_{i=2}^n x_i^2\bigg)^{1/2}\bigg), \end{equation} and denote \begin{equation} t:=x_1 \quad \text{and}\quad r:= \bigg(\sum_{i=2}^n x_i^2\bigg)^{1/2}. \end{equation} I am told that the determinant of the Hessian of $f$ is given by \begin{equation} \det D^2f = (g_{tt}g_{rr}-g_{tr}^2)\bigg(\frac{g_r}{r}\bigg)^{n-2}, \end{equation} and it seems there must be an easy way to see this, but I cannot work it out. I have tried to derive this by computing the Hessian: the first partial derivatives are given by \begin{align} \frac{\partial f}{\partial x_i} & = \frac{\partial g}{\partial t}\frac{\partial t}{\partial x_i} + \frac{\partial g}{\partial r}\frac{\partial r}{\partial x_i} = \begin{cases}g_t & \text{if } i=1 \\ g_r\frac{x_i}{r} & \text{if } i\not=1 \end{cases} \end{align} and then the second partial derivatives are given by \begin{equation} \frac{\partial^2 f}{\partial x_i\partial x_j} = \begin{cases}g_{tt} & \text{if } i=j=1 \\ g_{tr}\frac{x_j}{r} & \text{if }i=1, j\not=1 \\ g_{tr}\frac{x_i}{r} & \text{if }i\not=1, j=1 \\ g_{rr}\frac{x_i x_j}{r^2} + g_r\frac{\delta_{ij}}{r} - g_r\frac{x_ix_j}{r^2} & \text{if }i\not=1, j\not=1.  \end{cases} \end{equation} I was hoping the Hessian would be of a nice form (block diagonal or something) so I could compute the determinant easily, but this doesn't seem to be the case, unless I've calculated something wrong. Any help would be much appreciated! Thanks","Suppose one is given a function and denote I am told that the determinant of the Hessian of is given by and it seems there must be an easy way to see this, but I cannot work it out. I have tried to derive this by computing the Hessian: the first partial derivatives are given by and then the second partial derivatives are given by I was hoping the Hessian would be of a nice form (block diagonal or something) so I could compute the determinant easily, but this doesn't seem to be the case, unless I've calculated something wrong. Any help would be much appreciated! Thanks","\begin{equation}
f(x_1,\dots,x_n) = g\bigg(x_1,\bigg(\sum_{i=2}^n x_i^2\bigg)^{1/2}\bigg),
\end{equation} \begin{equation}
t:=x_1 \quad \text{and}\quad r:= \bigg(\sum_{i=2}^n x_i^2\bigg)^{1/2}.
\end{equation} f \begin{equation}
\det D^2f = (g_{tt}g_{rr}-g_{tr}^2)\bigg(\frac{g_r}{r}\bigg)^{n-2},
\end{equation} \begin{align}
\frac{\partial f}{\partial x_i} & = \frac{\partial g}{\partial t}\frac{\partial t}{\partial x_i} + \frac{\partial g}{\partial r}\frac{\partial r}{\partial x_i} = \begin{cases}g_t & \text{if } i=1 \\
g_r\frac{x_i}{r} & \text{if } i\not=1
\end{cases}
\end{align} \begin{equation}
\frac{\partial^2 f}{\partial x_i\partial x_j} = \begin{cases}g_{tt} & \text{if } i=j=1 \\
g_{tr}\frac{x_j}{r} & \text{if }i=1, j\not=1 \\
g_{tr}\frac{x_i}{r} & \text{if }i\not=1, j=1 \\
g_{rr}\frac{x_i x_j}{r^2} + g_r\frac{\delta_{ij}}{r} - g_r\frac{x_ix_j}{r^2} & \text{if }i\not=1, j\not=1. 
\end{cases}
\end{equation}","['multivariable-calculus', 'partial-derivative', 'vector-analysis']"
89,Verify if the following set is open or not,Verify if the following set is open or not,,"Let's consider the set $X := \{(x,\,0,\,0)\in \mathbb{R^{3}}: 0 < x < 1\}$ . Under the usual topology of $\mathbb{R^3}$ , is this set open? My guess it is not, if we sketch it, but how can one analytically prove this, in terms of open balls and? Thanks in advance!","Let's consider the set . Under the usual topology of , is this set open? My guess it is not, if we sketch it, but how can one analytically prove this, in terms of open balls and? Thanks in advance!","X := \{(x,\,0,\,0)\in \mathbb{R^{3}}: 0 < x < 1\} \mathbb{R^3}","['real-analysis', 'calculus', 'general-topology', 'multivariable-calculus', 'metric-spaces']"
90,"$x =r\cos \theta$ and $y = r\sin\theta$, determine $\frac{\partial r}{\partial x}$ and $\frac{\partial \theta}{\partial x}$","and , determine  and",x =r\cos \theta y = r\sin\theta \frac{\partial r}{\partial x} \frac{\partial \theta}{\partial x},"Given that $x =r\cos \theta$ and $y = r\sin\theta$ , determine $\frac{\partial r}{\partial x}$ and $\frac{\partial \theta}{\partial x}$ Attempt: I thought I'd calculate $\frac{\partial x}{\partial r}$ , treat it as a fraction and say $\frac{\partial r}{\partial x} = 1/\frac{\partial x}{\partial r}$ , however that doesn't work. Then I thought I'd set $r = \frac{x}{\cos \theta}$ and differentiate about $x$ , but this path leads to the same result above. I'm not sure how $y = r\sin \theta$ comes into play here. Official Answer: $$ \frac{\partial r}{\partial x} = \cos \theta, \quad \frac{\partial \theta}{\partial x} = \frac{- \sin\theta }{r}$$","Given that and , determine and Attempt: I thought I'd calculate , treat it as a fraction and say , however that doesn't work. Then I thought I'd set and differentiate about , but this path leads to the same result above. I'm not sure how comes into play here. Official Answer:","x =r\cos \theta y = r\sin\theta \frac{\partial r}{\partial x} \frac{\partial \theta}{\partial x} \frac{\partial x}{\partial r} \frac{\partial r}{\partial x} = 1/\frac{\partial x}{\partial r} r = \frac{x}{\cos \theta} x y = r\sin \theta  \frac{\partial r}{\partial x} = \cos \theta, \quad \frac{\partial \theta}{\partial x} = \frac{- \sin\theta }{r}","['multivariable-calculus', 'partial-derivative']"
91,Composition of multivariate functions.,Composition of multivariate functions.,,"How can I understand a theorem about the composition of two functions: $g = \gamma: I \subset \mathbb{R} \rightarrow \mathbb{R}^m$ $f: \mathbb{R}^m \rightarrow \mathbb{R}$ if it looks like this: $d(f \circ \gamma)(t_0) = df(\gamma(t_0))d\gamma(t_0)=\langle\nabla f(\gamma(t_0)), \gamma^{\prime}(t_0)\rangle$ Isn't $d(f \circ \gamma)(t_0)$ just another way to write $df(\gamma(t_0))$ ? How can I understand this notation?",How can I understand a theorem about the composition of two functions: if it looks like this: Isn't just another way to write ? How can I understand this notation?,"g = \gamma: I \subset \mathbb{R} \rightarrow \mathbb{R}^m f: \mathbb{R}^m \rightarrow \mathbb{R} d(f \circ \gamma)(t_0) = df(\gamma(t_0))d\gamma(t_0)=\langle\nabla f(\gamma(t_0)), \gamma^{\prime}(t_0)\rangle d(f \circ \gamma)(t_0) df(\gamma(t_0))","['real-analysis', 'calculus', 'multivariable-calculus', 'parametric']"
92,How do I find the volume of a parallelepiped given 4 vertices?,How do I find the volume of a parallelepiped given 4 vertices?,,"""Find the volume of the parallelepiped by four vertices: $(0,1,0), (2,2,2), (0,3,0),$ and $(3,1,2)$ . I know the formula to find this volume is: $|\vec{a} \circ(\vec{b}\times \vec{c})|$ , and I know how to carry out the computation to get the actual value. What I need to know is the process of how I set up the values of the vectors $\vec{a},\vec{b},$ and $\vec{c}$ using the given points?","""Find the volume of the parallelepiped by four vertices: and . I know the formula to find this volume is: , and I know how to carry out the computation to get the actual value. What I need to know is the process of how I set up the values of the vectors and using the given points?","(0,1,0), (2,2,2), (0,3,0), (3,1,2) |\vec{a} \circ(\vec{b}\times \vec{c})| \vec{a},\vec{b}, \vec{c}","['calculus', 'multivariable-calculus', 'volume']"
93,How to evaluate the integrals in the cylindrical coordinates,How to evaluate the integrals in the cylindrical coordinates,,"Evaluate the following integral in cylindrical coordinates $$\int^{1}_{-1}\int^{\sqrt{1-x^2}}_{0}\int^{2}_{0}\dfrac{1}{1+x^2+y^2}dzdydx$$ My try: I first took the boundaries as $$-1\le x\le1\\0\le y\le\sqrt{1-x^2}\\0\le z\le2$$ and I know the formula that $$D=\{(r,\theta,z):g(\theta)\le r\le h(\theta),\alpha\le\theta\le\beta,G(x,y)\le z\le H(x,y)\}$$ $$\int^{}_{}\int^{}_{D}\int^{}_{}f(r,\theta,z)dV=\int^{\beta}_{\alpha}\int^{h(\theta)}_{g(\theta)}\int^{H(r\cos\alpha,r\sin\theta)}_{G(r\cos\theta,r\sin\theta)}f(r,\theta,z)dzdrd\theta$$ But how to apply this formula and change the boundaries of the integrals? Can anyone please explain this.",Evaluate the following integral in cylindrical coordinates My try: I first took the boundaries as and I know the formula that But how to apply this formula and change the boundaries of the integrals? Can anyone please explain this.,"\int^{1}_{-1}\int^{\sqrt{1-x^2}}_{0}\int^{2}_{0}\dfrac{1}{1+x^2+y^2}dzdydx -1\le x\le1\\0\le y\le\sqrt{1-x^2}\\0\le z\le2 D=\{(r,\theta,z):g(\theta)\le r\le h(\theta),\alpha\le\theta\le\beta,G(x,y)\le z\le H(x,y)\} \int^{}_{}\int^{}_{D}\int^{}_{}f(r,\theta,z)dV=\int^{\beta}_{\alpha}\int^{h(\theta)}_{g(\theta)}\int^{H(r\cos\alpha,r\sin\theta)}_{G(r\cos\theta,r\sin\theta)}f(r,\theta,z)dzdrd\theta","['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'cylindrical-coordinates']"
94,Is there a Continuous Function mapping $\ S_1\ $ onto $\ S_2\ $,Is there a Continuous Function mapping  onto,\ S_1\  \ S_2\ ,"Let   $$ S_1=\{(x,y)\in\mathbb{R^2}:1<x^2+y^2<2\} $$   $$ S_2=\{(x,y)\in\mathbb{R^2}:2x^2<x^2+y^2<4\} $$   Is there a continuous function $f$ mapping $\ S_1\ $ onto $\ S_2\ $? I believe that there is no function $f$ that maps $\ S_1\ $ onto $\ S_2\ $. My reason for this is that while $S_1$ is path connected, $S_2$ is not path connected and $S_1\cap S_2$ is also not path connected. Hence you cannot map $S_1$ onto $S_2$. Is this logic correct? How can I build on this explanation?","Let   $$ S_1=\{(x,y)\in\mathbb{R^2}:1<x^2+y^2<2\} $$   $$ S_2=\{(x,y)\in\mathbb{R^2}:2x^2<x^2+y^2<4\} $$   Is there a continuous function $f$ mapping $\ S_1\ $ onto $\ S_2\ $? I believe that there is no function $f$ that maps $\ S_1\ $ onto $\ S_2\ $. My reason for this is that while $S_1$ is path connected, $S_2$ is not path connected and $S_1\cap S_2$ is also not path connected. Hence you cannot map $S_1$ onto $S_2$. Is this logic correct? How can I build on this explanation?",,"['general-topology', 'multivariable-calculus']"
95,Is the gradient a surface normal vector or does it point in the direction of maximum increase of f,Is the gradient a surface normal vector or does it point in the direction of maximum increase of f,,"I'm having some trouble trying to visualize and physically understand what's happening with the gradient.  I understand that the following is true: The gradient of f (grad(f)) points in the direction of maximum increase of f However, later on, we are told that a gradient of a surface f (grad(f)) gives us the surface normal vector (i.e pointing away). How can that be? From the first statement, I thought that the gradient must be pointing in the direction of maximum increase of f - surely the direction of maximum increase of f should be a vector pointing in some direction on f itself. How can it be pointing outward as a surface normal vector?","I'm having some trouble trying to visualize and physically understand what's happening with the gradient.  I understand that the following is true: The gradient of f (grad(f)) points in the direction of maximum increase of f However, later on, we are told that a gradient of a surface f (grad(f)) gives us the surface normal vector (i.e pointing away). How can that be? From the first statement, I thought that the gradient must be pointing in the direction of maximum increase of f - surely the direction of maximum increase of f should be a vector pointing in some direction on f itself. How can it be pointing outward as a surface normal vector?",,['multivariable-calculus']
96,Why $\frac{\partial}{\partial\alpha}f(\mathbf{x} + \alpha\mathbf{u})$ evaluates to $\mathbf{u}^T\nabla_{\mathbf{x}}f(\mathbf{x})$,Why  evaluates to,\frac{\partial}{\partial\alpha}f(\mathbf{x} + \alpha\mathbf{u}) \mathbf{u}^T\nabla_{\mathbf{x}}f(\mathbf{x}),"In Deep Learning (page 85) it is stated that: Using the chain rule, we can see that $\frac{\partial}{\partial\alpha}f(\mathbf{x} + \alpha\mathbf{u})$ evaluates to $\mathbf{u}^T\nabla_{\mathbf{x}}f(\mathbf{x})$ when $\alpha=0$. While I think to have understood that $\frac{\partial}{\partial\alpha}f(\mathbf{x} + \alpha\mathbf{u})$ is the directional derivative of $f(\mathbf{x})$ in the direction of $\mathbf{u}$, I still miss how to do the derivation using the chain rule. Also, does $\alpha=0$ mean that we are taking an infinitesimal step in the direction of $\mathbf{u}$?","In Deep Learning (page 85) it is stated that: Using the chain rule, we can see that $\frac{\partial}{\partial\alpha}f(\mathbf{x} + \alpha\mathbf{u})$ evaluates to $\mathbf{u}^T\nabla_{\mathbf{x}}f(\mathbf{x})$ when $\alpha=0$. While I think to have understood that $\frac{\partial}{\partial\alpha}f(\mathbf{x} + \alpha\mathbf{u})$ is the directional derivative of $f(\mathbf{x})$ in the direction of $\mathbf{u}$, I still miss how to do the derivation using the chain rule. Also, does $\alpha=0$ mean that we are taking an infinitesimal step in the direction of $\mathbf{u}$?",,"['multivariable-calculus', 'vector-analysis']"
97,Minimum distance between curves,Minimum distance between curves,,"We define $$f: \mathbb{R} \to \mathbb{R^3}, f(x)=\begin{pmatrix} cos(\pi \cdot x) \\ sin(\pi\cdot x) \\ 1-x^2 \end{pmatrix}$$ Problem: Calculate the minimum distance to the point of orign My ideas: The distance is definded by: $$d(x)=\sqrt{|(cos(π⋅x)-0)^2|+|(sin(π⋅x)-0)^2|+|((1-x^2)-0)^2}|$$ $$d(x)=\sqrt{|(cos(π⋅x))^2|+|(sin(π⋅x))^2|+|(1-x^2)^2}|$$ The minimum distance is the extrema of the first derivation, so I have to calculate $$d'(x)=0$$ As solution I get x=-1 or x=0 or x=1 (Wolfram Alpha) But I'm not actually sure absout the solution and I don't know how to solve it without calculator. Thanks in advance!","We define $$f: \mathbb{R} \to \mathbb{R^3}, f(x)=\begin{pmatrix} cos(\pi \cdot x) \\ sin(\pi\cdot x) \\ 1-x^2 \end{pmatrix}$$ Problem: Calculate the minimum distance to the point of orign My ideas: The distance is definded by: $$d(x)=\sqrt{|(cos(π⋅x)-0)^2|+|(sin(π⋅x)-0)^2|+|((1-x^2)-0)^2}|$$ $$d(x)=\sqrt{|(cos(π⋅x))^2|+|(sin(π⋅x))^2|+|(1-x^2)^2}|$$ The minimum distance is the extrema of the first derivation, so I have to calculate $$d'(x)=0$$ As solution I get x=-1 or x=0 or x=1 (Wolfram Alpha) But I'm not actually sure absout the solution and I don't know how to solve it without calculator. Thanks in advance!",,"['calculus', 'multivariable-calculus', 'curves']"
98,Find inverse of multivariable function,Find inverse of multivariable function,,"How do I find the inverse of $f(x_{1}, x_{2}, x_{3}) = ( \frac{ x_{1} }{1 + x_{1} + x_{2} + x_{3}} , \frac{ x_{2} }{1 + x_{1} + x_{2} + x_{3}} , \frac{ x_{3} }{1 + x_{1} + x_{2} + x_{3}})$ I already managed to prove that the function is inyective but I have no clue on how to find the inverse. Any help is very appreciated.","How do I find the inverse of $f(x_{1}, x_{2}, x_{3}) = ( \frac{ x_{1} }{1 + x_{1} + x_{2} + x_{3}} , \frac{ x_{2} }{1 + x_{1} + x_{2} + x_{3}} , \frac{ x_{3} }{1 + x_{1} + x_{2} + x_{3}})$ I already managed to prove that the function is inyective but I have no clue on how to find the inverse. Any help is very appreciated.",,['multivariable-calculus']
99,Hessian matrix in spherical coordinates,Hessian matrix in spherical coordinates,,"This seems like a straightfoward question but I cannot find the answer anywhere. I need to implement the Hessian matrix of a real scalar function f (an Hamiltonian, to be specific) in spherical coordinates (1,$\theta$,$\phi$) on the unit sphere and evaluate it at a turning point where the first derivatives vanish ($\frac{\partial f}{\partial \theta} =\frac{\partial f}{\partial \phi}=0 $). My first try was $$ H= \begin{pmatrix}     \frac{\partial^2 f}{\partial \theta^2} &  \frac{\partial^2 f}{\partial \theta \partial \phi} \\     \frac{\partial^2 f}{\partial \theta \partial \phi} &  \frac{\partial^2 f}{\partial \phi^2}    \end{pmatrix}, $$ which is what I found in many (physics) papers where $\theta$ is conveniently set to $\frac{\pi}{2}$. However, what I observed numerically is that because the elementary displacement on the sphere $\delta \vec{m}$ caused by a variation d$\phi$ depends on $\theta$, this is valid at the equator and then gradually breaks down closer to the poles because the  $\frac{\partial^2 f}{\partial \phi^2}$ and $\frac{\partial^2 f}{\partial \theta \partial \phi}$ terms tend to $0$ when they shouldn't. This problem is corrected in the spherical gradient by the $\frac{1}{\sin \theta}$ factor on the $\hat{e}_{\phi}$ component, ie: $$ \nabla f = \frac{\partial f}{\partial \theta}\hat{e}_{\theta}+\frac{1}{sin \theta} \frac{\partial f}{\partial \phi}\hat{e}_{\phi}.$$ From various sources (incl. wikipedia ), the Hessian is sometimes defined as the Jacobian of the gradient,  which in spherical coordinates would be $H=J(\nabla f)= \big[ \frac{\partial \nabla f}{\partial \theta} ,\frac{\partial \nabla f}{\partial \phi} \big]$. If I apply this at a turning point where the first derivatives vanish, I end up with $$ H= \begin{pmatrix}     \frac{\partial^2 f}{\partial \theta^2} &  \frac{\partial^2 f}{\partial \theta \partial \phi} \\    \frac{1}{\sin \theta}  \frac{\partial^2 f}{\partial \theta \partial \phi} &  \frac{1}{\sin \theta} \frac{\partial^2 f}{\partial \phi^2}    \end{pmatrix}. $$ This is not symmetric anymore, which bothers me because in every book I looked, it says the Hessian is symmetric as long as the mix derivatives commute. Does this mean this definition does not apply in spherical coordinates? Is there a more general definition I can use? Additionally, I found this post which defines $H=\nabla \nabla^T$. This yields $$ H= \begin{pmatrix}     \frac{\partial^2 f}{\partial \theta^2} & \frac{1}{\sin \theta} \frac{\partial^2 f}{\partial \theta \partial \phi} \\    \frac{1}{\sin \theta}  \frac{\partial^2 f}{\partial \theta \partial \phi} &  \frac{1}{\sin^2 \theta} \frac{\partial^2 f}{\partial \phi^2}    \end{pmatrix} $$ which is a lot more intuitive, but it clashes with the previous Jacobian of the gradient definition Any help/clarifications or suggestions greatly appreciated.","This seems like a straightfoward question but I cannot find the answer anywhere. I need to implement the Hessian matrix of a real scalar function f (an Hamiltonian, to be specific) in spherical coordinates (1,$\theta$,$\phi$) on the unit sphere and evaluate it at a turning point where the first derivatives vanish ($\frac{\partial f}{\partial \theta} =\frac{\partial f}{\partial \phi}=0 $). My first try was $$ H= \begin{pmatrix}     \frac{\partial^2 f}{\partial \theta^2} &  \frac{\partial^2 f}{\partial \theta \partial \phi} \\     \frac{\partial^2 f}{\partial \theta \partial \phi} &  \frac{\partial^2 f}{\partial \phi^2}    \end{pmatrix}, $$ which is what I found in many (physics) papers where $\theta$ is conveniently set to $\frac{\pi}{2}$. However, what I observed numerically is that because the elementary displacement on the sphere $\delta \vec{m}$ caused by a variation d$\phi$ depends on $\theta$, this is valid at the equator and then gradually breaks down closer to the poles because the  $\frac{\partial^2 f}{\partial \phi^2}$ and $\frac{\partial^2 f}{\partial \theta \partial \phi}$ terms tend to $0$ when they shouldn't. This problem is corrected in the spherical gradient by the $\frac{1}{\sin \theta}$ factor on the $\hat{e}_{\phi}$ component, ie: $$ \nabla f = \frac{\partial f}{\partial \theta}\hat{e}_{\theta}+\frac{1}{sin \theta} \frac{\partial f}{\partial \phi}\hat{e}_{\phi}.$$ From various sources (incl. wikipedia ), the Hessian is sometimes defined as the Jacobian of the gradient,  which in spherical coordinates would be $H=J(\nabla f)= \big[ \frac{\partial \nabla f}{\partial \theta} ,\frac{\partial \nabla f}{\partial \phi} \big]$. If I apply this at a turning point where the first derivatives vanish, I end up with $$ H= \begin{pmatrix}     \frac{\partial^2 f}{\partial \theta^2} &  \frac{\partial^2 f}{\partial \theta \partial \phi} \\    \frac{1}{\sin \theta}  \frac{\partial^2 f}{\partial \theta \partial \phi} &  \frac{1}{\sin \theta} \frac{\partial^2 f}{\partial \phi^2}    \end{pmatrix}. $$ This is not symmetric anymore, which bothers me because in every book I looked, it says the Hessian is symmetric as long as the mix derivatives commute. Does this mean this definition does not apply in spherical coordinates? Is there a more general definition I can use? Additionally, I found this post which defines $H=\nabla \nabla^T$. This yields $$ H= \begin{pmatrix}     \frac{\partial^2 f}{\partial \theta^2} & \frac{1}{\sin \theta} \frac{\partial^2 f}{\partial \theta \partial \phi} \\    \frac{1}{\sin \theta}  \frac{\partial^2 f}{\partial \theta \partial \phi} &  \frac{1}{\sin^2 \theta} \frac{\partial^2 f}{\partial \phi^2}    \end{pmatrix} $$ which is a lot more intuitive, but it clashes with the previous Jacobian of the gradient definition Any help/clarifications or suggestions greatly appreciated.",,"['multivariable-calculus', 'vector-analysis', 'spherical-coordinates', 'hessian-matrix']"
