,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Breaking a contour integral into 3 separate contours?,Breaking a contour integral into 3 separate contours?,,"We can try to integrate the following function around a counter-clockwise circular contour: $$\frac{x^3}{(x-1)(x-2)(x-3)}$$ Can someone show how to use the Cauchy–Goursat theorem (explained here and here ) to break this apart into 3 separate contours? In other words, I'd like to take $$\int_c{\frac{x^3}{(x-1)(x-2)(x-3)}}$$ and get $$\int_{C_1}{f_1(x)} + \int_{C_2}{f_2(x)} + \int_{C_3}{f_3(x)}$$ I'm hoping for a pretty thorough explanation with at least one of the contours.  I just want to be certain I have the idea perfected.","We can try to integrate the following function around a counter-clockwise circular contour: $$\frac{x^3}{(x-1)(x-2)(x-3)}$$ Can someone show how to use the Cauchy–Goursat theorem (explained here and here ) to break this apart into 3 separate contours? In other words, I'd like to take $$\int_c{\frac{x^3}{(x-1)(x-2)(x-3)}}$$ and get $$\int_{C_1}{f_1(x)} + \int_{C_2}{f_2(x)} + \int_{C_3}{f_3(x)}$$ I'm hoping for a pretty thorough explanation with at least one of the contours.  I just want to be certain I have the idea perfected.",,"['complex-analysis', 'integration']"
1,is $f$ analytic inside $C?$,is  analytic inside,f C?,"If $$f(z_0)=\dfrac{1}{2\pi i}\int_C\dfrac{f(z)}{z-z_0}dz$$ for all point $z_0$ inside $C,$ is $f$ analytic inside $C?~(C:$ simple closed contour$)$","If $$f(z_0)=\dfrac{1}{2\pi i}\int_C\dfrac{f(z)}{z-z_0}dz$$ for all point $z_0$ inside $C,$ is $f$ analytic inside $C?~(C:$ simple closed contour$)$",,['complex-analysis']
2,Contour Integration - my solution for real integral is complex?,Contour Integration - my solution for real integral is complex?,,"So I've had a crack at this contour integration question and have somehow managed to get a complex solution for a real integral... I've gone through my working a number of times but can't seem to find the mistake, so was hoping someone here could help. Evaluate the integral $$ I=\int^\pi_{-\pi} \frac{\,d\theta}{a+b\cos\theta+c\sin\theta} $$ where $a$, $b$, $c$ are real positive constants such that $a^2>b^2+c^2>0$ My Attempt: Consider the complex function $$f(z)=\frac{1}{az+\frac{1}{2}b(z^2+1)+\frac{1}{2i}c(z^2-1)}$$ This has simple poles when denominator equals zero, i.e. at $z=z_1$ and $z=z_2$, where $$z_1=\frac{-a+\sqrt{a^2-(b^2+c^2)}}{b-ic} \ \text{and}\ \ z_2=\frac{-a-\sqrt{a^2-(b^2+c^2)}}{b-ic}$$ by the quadratic formula. See that $|z_2|>|z_1|\,\,\,\,\,\,(*)$. Note that $|z_1||z_2|=|z_1 z_2|=\left|\frac{b^2+c^2}{(b-ic)^2}\right|=1$ Referring back to $(*)$ we see that $|z_1|<1$ and $|z_2|>1$. $\text{Res}[f(z), z_1]=lim_{z\to z_1}[(z-z_1)f(z)]=\frac{1}{z_1-z_2}=\frac{b-ic}{2 \sqrt{a^2-b^2-c^2}}$ Since $z_1$ is the only pole enclosed by the contour $|z|=1$, by the residue theorem: $$\oint_{|z|=1}f(z)dz=2\pi i \text{Res}[f(z), z_1]\,\,\,\,\,\,(**)$$ Along the contour $|z|=1$, we can write $z=e^{i\theta}$ $dz=ie^{i\theta}d\theta$ with $\theta$ in $[-\pi,\pi]$ Then $$\oint_{|z|=1}f(z)dz=\int^\pi_{-\pi}\frac{ie^{i\theta}}{ae^{i\theta}+\frac{1}{2}b(e^{2i\theta}+1)+\frac{1}{2i}c(e^{2i\theta}-1)}d\theta$$ $$=i\int^\pi_{-\pi}\frac{1}{a+\frac{1}{2}b(e^{i\theta}+e^{-i\theta})+\frac{1}{2i}c(e^{i\theta}-e^{-i\theta})}d\theta=iI$$ Returning to $(**)$, we see that $$I=2\pi\text{Res}[f(z), z_1]=\frac{b-ic}{\sqrt{a^2-b^2-c^2}}\pi$$ Why is my result complex? I'd appreciate it if someone could point out where I went wrong.","So I've had a crack at this contour integration question and have somehow managed to get a complex solution for a real integral... I've gone through my working a number of times but can't seem to find the mistake, so was hoping someone here could help. Evaluate the integral $$ I=\int^\pi_{-\pi} \frac{\,d\theta}{a+b\cos\theta+c\sin\theta} $$ where $a$, $b$, $c$ are real positive constants such that $a^2>b^2+c^2>0$ My Attempt: Consider the complex function $$f(z)=\frac{1}{az+\frac{1}{2}b(z^2+1)+\frac{1}{2i}c(z^2-1)}$$ This has simple poles when denominator equals zero, i.e. at $z=z_1$ and $z=z_2$, where $$z_1=\frac{-a+\sqrt{a^2-(b^2+c^2)}}{b-ic} \ \text{and}\ \ z_2=\frac{-a-\sqrt{a^2-(b^2+c^2)}}{b-ic}$$ by the quadratic formula. See that $|z_2|>|z_1|\,\,\,\,\,\,(*)$. Note that $|z_1||z_2|=|z_1 z_2|=\left|\frac{b^2+c^2}{(b-ic)^2}\right|=1$ Referring back to $(*)$ we see that $|z_1|<1$ and $|z_2|>1$. $\text{Res}[f(z), z_1]=lim_{z\to z_1}[(z-z_1)f(z)]=\frac{1}{z_1-z_2}=\frac{b-ic}{2 \sqrt{a^2-b^2-c^2}}$ Since $z_1$ is the only pole enclosed by the contour $|z|=1$, by the residue theorem: $$\oint_{|z|=1}f(z)dz=2\pi i \text{Res}[f(z), z_1]\,\,\,\,\,\,(**)$$ Along the contour $|z|=1$, we can write $z=e^{i\theta}$ $dz=ie^{i\theta}d\theta$ with $\theta$ in $[-\pi,\pi]$ Then $$\oint_{|z|=1}f(z)dz=\int^\pi_{-\pi}\frac{ie^{i\theta}}{ae^{i\theta}+\frac{1}{2}b(e^{2i\theta}+1)+\frac{1}{2i}c(e^{2i\theta}-1)}d\theta$$ $$=i\int^\pi_{-\pi}\frac{1}{a+\frac{1}{2}b(e^{i\theta}+e^{-i\theta})+\frac{1}{2i}c(e^{i\theta}-e^{-i\theta})}d\theta=iI$$ Returning to $(**)$, we see that $$I=2\pi\text{Res}[f(z), z_1]=\frac{b-ic}{\sqrt{a^2-b^2-c^2}}\pi$$ Why is my result complex? I'd appreciate it if someone could point out where I went wrong.",,['complex-analysis']
3,A problem related to the Casorati–Weierstrass theorem,A problem related to the Casorati–Weierstrass theorem,,"This is an exercise problem from Complex Analysis by Joseph Bak and Donald J. Newman. Suppose $f$ has an isolated singularity at $z_0$. Show that $z_0$ is an essential singularity if and only if there exist sequences $\{\alpha_n\}$ and $\{\beta_n\}$ with $$ \alpha_n \to z_0, \quad \beta_n \to z_0,\qquad\text{ and }\qquad f (\alpha_n) \to 0, \quad f (\beta_n) \to \infty.$$ I know Casorati–Weierstrass' theorem or Picard's theorem should guarantee that if $f$ has an essential singularity, then such suitable sequences should exist such that $f$ can approach any value, which we can set to be $0$ or $\infty$. I, however, am not sure how to prove the converse. I'm wondering if anyone can offer a hint. Thanks.","This is an exercise problem from Complex Analysis by Joseph Bak and Donald J. Newman. Suppose $f$ has an isolated singularity at $z_0$. Show that $z_0$ is an essential singularity if and only if there exist sequences $\{\alpha_n\}$ and $\{\beta_n\}$ with $$ \alpha_n \to z_0, \quad \beta_n \to z_0,\qquad\text{ and }\qquad f (\alpha_n) \to 0, \quad f (\beta_n) \to \infty.$$ I know Casorati–Weierstrass' theorem or Picard's theorem should guarantee that if $f$ has an essential singularity, then such suitable sequences should exist such that $f$ can approach any value, which we can set to be $0$ or $\infty$. I, however, am not sure how to prove the converse. I'm wondering if anyone can offer a hint. Thanks.",,['complex-analysis']
4,Help with unknown notation,Help with unknown notation,,"In Ahlfors' Complex Analysis, page 19 it says (in relation with the Riemann sphere): ""writing $z=x+iy$, we can verify that: $$x:y:-1=x_1:x_2:x_3-1, $$ and this means that the points $(x,y,0),(x_1,x_2,x_3)$ and $(0,0,1)$ are in a straight line."" My question is: what do the colon mean? And how does it follow that the points lie on a line? Thank you.","In Ahlfors' Complex Analysis, page 19 it says (in relation with the Riemann sphere): ""writing $z=x+iy$, we can verify that: $$x:y:-1=x_1:x_2:x_3-1, $$ and this means that the points $(x,y,0),(x_1,x_2,x_3)$ and $(0,0,1)$ are in a straight line."" My question is: what do the colon mean? And how does it follow that the points lie on a line? Thank you.",,"['geometry', 'complex-analysis', 'notation', 'complex-geometry']"
5,Is $\cot(z)-\frac1z$ bounded on a given circle?,Is  bounded on a given circle?,\cot(z)-\frac1z,I am getting stuck with the problem given from the book Schaum's outlines p.240 Q.110 Given $f(z)=\cot(z)-\frac1z$ where $z$ lies on a circle of radius $R=(N+\frac12)\pi$ and centered at the origin. Prove that $|f(z)|\le M$ where $M$ is independent of $N$.,I am getting stuck with the problem given from the book Schaum's outlines p.240 Q.110 Given $f(z)=\cot(z)-\frac1z$ where $z$ lies on a circle of radius $R=(N+\frac12)\pi$ and centered at the origin. Prove that $|f(z)|\le M$ where $M$ is independent of $N$.,,['complex-analysis']
6,Real Pole Residue theorem,Real Pole Residue theorem,,"I've been studying the residue theorem and I've been having a problem understanding the following result seen here (Eq.7.39) which states : Given a regular function on the real axis, $g$, then $$\lim_{\epsilon \to 0}~\int_{-\infty}^{+\infty}\frac{g(x)}{x-x_0\mp i\epsilon}dx=PV\int_{-\infty}^{+\infty}\frac{g(x)}{x-x_0}dx \pm i\pi g(x_0)$$ where $x_0\in\mathbb R$. What I don't understand is the factor $ i\pi g(x_0)$ instead of  $ 2i\pi g(x_0)$. Also, why $g(x_0)\equiv \operatorname{Res}(g(x),x=x_0)$ instead of $\operatorname{Res}(g(x),x=x_0\pm i\epsilon)$ in that same term? Can anyone help me?","I've been studying the residue theorem and I've been having a problem understanding the following result seen here (Eq.7.39) which states : Given a regular function on the real axis, $g$, then $$\lim_{\epsilon \to 0}~\int_{-\infty}^{+\infty}\frac{g(x)}{x-x_0\mp i\epsilon}dx=PV\int_{-\infty}^{+\infty}\frac{g(x)}{x-x_0}dx \pm i\pi g(x_0)$$ where $x_0\in\mathbb R$. What I don't understand is the factor $ i\pi g(x_0)$ instead of  $ 2i\pi g(x_0)$. Also, why $g(x_0)\equiv \operatorname{Res}(g(x),x=x_0)$ instead of $\operatorname{Res}(g(x),x=x_0\pm i\epsilon)$ in that same term? Can anyone help me?",,"['complex-analysis', 'residue-calculus']"
7,A problem on Residue Theorem,A problem on Residue Theorem,,"Today I had a problem in my test which said Calculate $\int_C \dfrac{z}{z^2 + 1}$ where C is circle $|z+\dfrac{1}{z}|= 2$. Now, clearly this was a misprint since C is not a circle. I tried to find the 'curve' C, by converting to Cartesian, but I found that C is set of isolated points in the complex plane. During test, I could only find two points which satisfy the curve, $z=1 $ and $z= -1$. However, I came home and searched on wolfram alpha that the 'curve' is actually set of 6 isolated points. So my question is, since the poles of the function to be integrated i.e. $\dfrac{z}{z^2+1}$ are 'outside' the curve i.e. $\pm i$ do not satisfy the 'curve', is the value of integral by residue theorem $0$? If yes or no, what are the explanations?","Today I had a problem in my test which said Calculate $\int_C \dfrac{z}{z^2 + 1}$ where C is circle $|z+\dfrac{1}{z}|= 2$. Now, clearly this was a misprint since C is not a circle. I tried to find the 'curve' C, by converting to Cartesian, but I found that C is set of isolated points in the complex plane. During test, I could only find two points which satisfy the curve, $z=1 $ and $z= -1$. However, I came home and searched on wolfram alpha that the 'curve' is actually set of 6 isolated points. So my question is, since the poles of the function to be integrated i.e. $\dfrac{z}{z^2+1}$ are 'outside' the curve i.e. $\pm i$ do not satisfy the 'curve', is the value of integral by residue theorem $0$? If yes or no, what are the explanations?",,"['complex-analysis', 'plane-curves', 'residue-calculus']"
8,Integrating $ z^{a-1}(z+z^{-1})^{b}$ on the complex plane,Integrating  on the complex plane, z^{a-1}(z+z^{-1})^{b},"For $a>b>-1$, I want to evaluate $$\int_{C} z^{a-1} \left(z + z^{-1}\right)^{b} \, dz$$ where $C$ is the right half of the circle $|z|=1$ traversed counterclockwise. So I closed the contour with the vertical line segment $[-i, i]$ (indented at $z=i$, $z=0$, and $z=-i$). Under the restriction mentioned above, I get $\begin{align} \int_{C}z^{a-1}\left( z+z^{-1}\right)^{b} \, dz &= \int_{-1}^{1}(it)^{a-1}\left( it+(it)^{-1}\right)^{b} \, i \, dt \\ &=\int_{-1}^{1}(it)^{a-1}\left(\frac{1-t^{2}}{it}\right)^{b} \, i \, dt \\ &= \require{cancel} \cancel{i} \ i^{a-b}\int_{-1}^{1}t^{a-b-1}\left(1-t^{2}\right)^{b} \, dt \\ &=\cancel{i} \left[\cos\left(\frac{\pi(a-b)}{2}\right)+i\sin\left(\frac{\pi(a-b)}{2}\right)\right]\int_{-1}^{1}t^{a-b-1}\left(1-t^{2}\right)^{b} \, dt. \end{align}$ But the book says that it should be $$ 2i \sin\left(\frac{\pi(a-b)}{2}\right)\int_{0}^{1}t^{a-b-1}\left(1-t^{2}\right)^{b}\ dt.$$ How do we get that?","For $a>b>-1$, I want to evaluate $$\int_{C} z^{a-1} \left(z + z^{-1}\right)^{b} \, dz$$ where $C$ is the right half of the circle $|z|=1$ traversed counterclockwise. So I closed the contour with the vertical line segment $[-i, i]$ (indented at $z=i$, $z=0$, and $z=-i$). Under the restriction mentioned above, I get $\begin{align} \int_{C}z^{a-1}\left( z+z^{-1}\right)^{b} \, dz &= \int_{-1}^{1}(it)^{a-1}\left( it+(it)^{-1}\right)^{b} \, i \, dt \\ &=\int_{-1}^{1}(it)^{a-1}\left(\frac{1-t^{2}}{it}\right)^{b} \, i \, dt \\ &= \require{cancel} \cancel{i} \ i^{a-b}\int_{-1}^{1}t^{a-b-1}\left(1-t^{2}\right)^{b} \, dt \\ &=\cancel{i} \left[\cos\left(\frac{\pi(a-b)}{2}\right)+i\sin\left(\frac{\pi(a-b)}{2}\right)\right]\int_{-1}^{1}t^{a-b-1}\left(1-t^{2}\right)^{b} \, dt. \end{align}$ But the book says that it should be $$ 2i \sin\left(\frac{\pi(a-b)}{2}\right)\int_{0}^{1}t^{a-b-1}\left(1-t^{2}\right)^{b}\ dt.$$ How do we get that?",,"['complex-analysis', 'contour-integration']"
9,Real part of holomorphic function cannot have a maximum,Real part of holomorphic function cannot have a maximum,,"I am trying to prove that if $f$ is a holomorphic function from a domain $U$ to $\mathbb{C}$, and the real part has an interior local maximum at a point $a$ in $U$, then $f$ is a constant. I am new to complex analysis, but I was thinking maybe I need to use some variant of the local maximum principle? Thanks.","I am trying to prove that if $f$ is a holomorphic function from a domain $U$ to $\mathbb{C}$, and the real part has an interior local maximum at a point $a$ in $U$, then $f$ is a constant. I am new to complex analysis, but I was thinking maybe I need to use some variant of the local maximum principle? Thanks.",,[]
10,Harmonic Conjugates,Harmonic Conjugates,,"In Gamelin it is stated that ""[t]he basis for application of Green's theorem to harmonic functions is the following important observation. Lemma. If $u(x, y)$ is harmonic, then the differential $\hspace{2in} -\frac{\partial u}{\partial y}$d$x + \frac{\partial u}{\partial x}$d$y$ is closed. "" What does Gamelin mean by ""closed"" here? I found a definition of ""closed surface"" in the ""Dictionary of Analysis, Calculus, and Differential Equations,"" which states that a closed surface is ""[a] surface that has no boundary curves [and] can be characterized as a connected compact metric space in which every point has a neighborhood that is homeomorphic with the interior of a circle."" The former part seems to connect with a discussion at Paul's Online Math Notes: $\hspace{2in}$ , where it is mentioned that ""[a]round the edge of [the above] surface we have a curve C.  This curve is called the boundary curve."" Also, just by considering the function $u(x, y) = x^2 - y^2$ the defined differential, say d$g$ for instance, produces $g(x, y) = 4xy + C$: $\hspace{2in}$ , which appears to have no boundary curve, but, perhaps, I have the notion mixed up. OK, now I see that the author just meant ""closed differential form."" $\hspace{2in}$ Thank you Gerry Myerson and Christopher A. Wong for pointing this out (see below).","In Gamelin it is stated that ""[t]he basis for application of Green's theorem to harmonic functions is the following important observation. Lemma. If $u(x, y)$ is harmonic, then the differential $\hspace{2in} -\frac{\partial u}{\partial y}$d$x + \frac{\partial u}{\partial x}$d$y$ is closed. "" What does Gamelin mean by ""closed"" here? I found a definition of ""closed surface"" in the ""Dictionary of Analysis, Calculus, and Differential Equations,"" which states that a closed surface is ""[a] surface that has no boundary curves [and] can be characterized as a connected compact metric space in which every point has a neighborhood that is homeomorphic with the interior of a circle."" The former part seems to connect with a discussion at Paul's Online Math Notes: $\hspace{2in}$ , where it is mentioned that ""[a]round the edge of [the above] surface we have a curve C.  This curve is called the boundary curve."" Also, just by considering the function $u(x, y) = x^2 - y^2$ the defined differential, say d$g$ for instance, produces $g(x, y) = 4xy + C$: $\hspace{2in}$ , which appears to have no boundary curve, but, perhaps, I have the notion mixed up. OK, now I see that the author just meant ""closed differential form."" $\hspace{2in}$ Thank you Gerry Myerson and Christopher A. Wong for pointing this out (see below).",,['complex-analysis']
11,Complex Integration : $\int_1^{1+i}\frac{1}{1+z^2}dz$,Complex Integration :,\int_1^{1+i}\frac{1}{1+z^2}dz,"Integrate alonf the line segment from $z=1$ to $z=1+i$ :   $$\int_1^{1+i}\frac{1}{1+z^2}dz$$ If I integrate, it is just the identity $tan^{-1}z$, but the answer to this question is $$\frac{\pi}{4}-\frac{1}{2}\arctan2+\frac{i}{4}\log5$$ which I don't understand how they got?","Integrate alonf the line segment from $z=1$ to $z=1+i$ :   $$\int_1^{1+i}\frac{1}{1+z^2}dz$$ If I integrate, it is just the identity $tan^{-1}z$, but the answer to this question is $$\frac{\pi}{4}-\frac{1}{2}\arctan2+\frac{i}{4}\log5$$ which I don't understand how they got?",,"['complex-analysis', 'contour-integration']"
12,"Calculating $\int_{-\infty}^{\infty}\frac{\sin(ax)}{x}\, dx$ using complex analysis",Calculating  using complex analysis,"\int_{-\infty}^{\infty}\frac{\sin(ax)}{x}\, dx","I am going over my complex analysis lecture notes and there is an example about calculating $$\int_{-\infty}^{\infty}\frac{\sin(ax)}{x}\, dx$$ that I don't understand. The solution in the notes starts like this: Denote $C$ as the path from$-R$ to $R$ on the $x$-axis (where $R>0$ is real). Denote $C_{R}$ as the semi-circle (anti-clockwise) that goes from $R$ to $-R$. $$\int_{-R}^{R}\frac{\sin(az)}{z}\, dz=\int_{C}\frac{\sin(az)}{z}\, dz=\int_{C}\frac{e^{aiz}-e^{-aiz}}{2iz}=\frac{1}{2i}(\int_{C}\frac{e^{iaz}}{z}\, dz-\int_{C}\frac{e^{-aiz}}{z}\, dz)$$ Assume $a>0$: $$e^{iaz}=e^{iaRe^{i\theta}}=e^{iaR\cos(\theta)}-e^{-iaR\sin(\theta)}$$ Thus $$\int_{C}\frac{e^{iaz}}{z}\, dz+\int_{C_{R}}\frac{e^{iaz}}{z}\, dz=2\pi iRes_{z=0}\left(\frac{e^{iaz}}{z}\right)=2\pi i$$ The next part claims that for $R\to\infty$:$\int_{C}\frac{e^{iaz}}{z}\, dz=2\pi i$ (I understand this part) From here don't understand what going on in the notes, the sentences claim that $$\int_{C}\frac{e^{-iaz}}{z}\, dz+\int_{C_{R}}\frac{-e^{iaz}}{z}\, dz=0$$ but I think that in a similar manner that sum is $2\pi iRes_{z=0}(\frac{e^{-iaz}}{z})$ which I believe to be $2\pi i\neq0$. The next two sentences afterward say that $\lim_{R\to\infty}\int_{C}\frac{\sin(az)}{z}\, dz=\frac{1}{2i}\cdot2\pi i=\pi$ and that $$\int_{-\infty}^{\infty}\frac{\sin(ax)}{x}\, dx=\pi$$ Can someone please help me understand the part about the sum $$\int_{C}\frac{e^{-iaz}}{z}\, dz+\int_{C_{R}}\frac{-e^{iaz}}{z}\, dz$$ ? I believe that there is a mistake here, I would also appreciate help understanding the last two claims: $$\lim_{R\to\infty}\int_{C}\frac{\sin(az)}{z}\, dz=\pi$$ and that $$\int_{-\infty}^{\infty}\frac{\sin(ax)}{x}\, dx=\pi$$ EDIT: I read this couple more times, I now think that there is problem with the part after ""assume $a>0$"": $$e^{iaz}=e^{iaRe^{i\theta}}=e^{iaR\cos(\theta)}-e^{-iaR\sin(\theta)}$$ I think that the minus at the end should be $\cdot$ and that this is a typo in the notes, but I also think there should not be an $i$ in $e^{-iaR\sin(\theta)}$","I am going over my complex analysis lecture notes and there is an example about calculating $$\int_{-\infty}^{\infty}\frac{\sin(ax)}{x}\, dx$$ that I don't understand. The solution in the notes starts like this: Denote $C$ as the path from$-R$ to $R$ on the $x$-axis (where $R>0$ is real). Denote $C_{R}$ as the semi-circle (anti-clockwise) that goes from $R$ to $-R$. $$\int_{-R}^{R}\frac{\sin(az)}{z}\, dz=\int_{C}\frac{\sin(az)}{z}\, dz=\int_{C}\frac{e^{aiz}-e^{-aiz}}{2iz}=\frac{1}{2i}(\int_{C}\frac{e^{iaz}}{z}\, dz-\int_{C}\frac{e^{-aiz}}{z}\, dz)$$ Assume $a>0$: $$e^{iaz}=e^{iaRe^{i\theta}}=e^{iaR\cos(\theta)}-e^{-iaR\sin(\theta)}$$ Thus $$\int_{C}\frac{e^{iaz}}{z}\, dz+\int_{C_{R}}\frac{e^{iaz}}{z}\, dz=2\pi iRes_{z=0}\left(\frac{e^{iaz}}{z}\right)=2\pi i$$ The next part claims that for $R\to\infty$:$\int_{C}\frac{e^{iaz}}{z}\, dz=2\pi i$ (I understand this part) From here don't understand what going on in the notes, the sentences claim that $$\int_{C}\frac{e^{-iaz}}{z}\, dz+\int_{C_{R}}\frac{-e^{iaz}}{z}\, dz=0$$ but I think that in a similar manner that sum is $2\pi iRes_{z=0}(\frac{e^{-iaz}}{z})$ which I believe to be $2\pi i\neq0$. The next two sentences afterward say that $\lim_{R\to\infty}\int_{C}\frac{\sin(az)}{z}\, dz=\frac{1}{2i}\cdot2\pi i=\pi$ and that $$\int_{-\infty}^{\infty}\frac{\sin(ax)}{x}\, dx=\pi$$ Can someone please help me understand the part about the sum $$\int_{C}\frac{e^{-iaz}}{z}\, dz+\int_{C_{R}}\frac{-e^{iaz}}{z}\, dz$$ ? I believe that there is a mistake here, I would also appreciate help understanding the last two claims: $$\lim_{R\to\infty}\int_{C}\frac{\sin(az)}{z}\, dz=\pi$$ and that $$\int_{-\infty}^{\infty}\frac{\sin(ax)}{x}\, dx=\pi$$ EDIT: I read this couple more times, I now think that there is problem with the part after ""assume $a>0$"": $$e^{iaz}=e^{iaRe^{i\theta}}=e^{iaR\cos(\theta)}-e^{-iaR\sin(\theta)}$$ I think that the minus at the end should be $\cdot$ and that this is a typo in the notes, but I also think there should not be an $i$ in $e^{-iaR\sin(\theta)}$",,"['complex-analysis', 'improper-integrals']"
13,How to evaluate $\xi(0)$?,How to evaluate ?,\xi(0),"How do I evaluate $\xi(0)$ for the Riemann xi function? I know $\xi(0) = \xi(1)$ and $\xi(0) = \tfrac{1}{2} \cdot 0 \cdot (-1) \cdot \Gamma(0) \cdot \zeta(0)$ $\xi(1) = \tfrac{1}{2} \cdot 1 \cdot 0 \cdot \Gamma(\tfrac{1}{2}) \cdot \zeta(1)$ and $\zeta(0) = -\frac{1}{2}$, $\Gamma(\tfrac{1}{2}) = \sqrt{2\pi}$ but $\Gamma(0) = \infty$ and $\zeta(1) = \infty$ so I don't know how to evaluate it.","How do I evaluate $\xi(0)$ for the Riemann xi function? I know $\xi(0) = \xi(1)$ and $\xi(0) = \tfrac{1}{2} \cdot 0 \cdot (-1) \cdot \Gamma(0) \cdot \zeta(0)$ $\xi(1) = \tfrac{1}{2} \cdot 1 \cdot 0 \cdot \Gamma(\tfrac{1}{2}) \cdot \zeta(1)$ and $\zeta(0) = -\frac{1}{2}$, $\Gamma(\tfrac{1}{2}) = \sqrt{2\pi}$ but $\Gamma(0) = \infty$ and $\zeta(1) = \infty$ so I don't know how to evaluate it.",,['complex-analysis']
14,Holomorphic functions on unit disc,Holomorphic functions on unit disc,,"Let $f,g$ be holomorphic on $\mathbb{D}:=\lbrace z\in\mathbb{C}:|z|<1\rbrace$, $f\neq0,g\neq0$, such that $$\frac{f^{\prime}}{f}(\frac{1}{n})=\frac{g^{\prime}}{g}(\frac{1}{n}) $$ for all natural $n\geq1$. Does it imply that $f=Cg$, where $C$ is some constant? Let $A:=\lbrace\frac{1}{n}:n\geq1\rbrace$ and $h:=\frac{f^{\prime}}{f}-\frac{g^{\prime}}{g}$. Now, $h$ is holomprphic on $\mathbb{D}$ and disappears on a subset of $\mathbb{D}$ which has a limit point. Thus $h=0$, so $\frac{f^{\prime}}{f}=\frac{g^{\prime}}{g}$ on $\mathbb{D}$. Could someone help with the next steps? Or maybe $f$ doesn't have to be in the form described above?","Let $f,g$ be holomorphic on $\mathbb{D}:=\lbrace z\in\mathbb{C}:|z|<1\rbrace$, $f\neq0,g\neq0$, such that $$\frac{f^{\prime}}{f}(\frac{1}{n})=\frac{g^{\prime}}{g}(\frac{1}{n}) $$ for all natural $n\geq1$. Does it imply that $f=Cg$, where $C$ is some constant? Let $A:=\lbrace\frac{1}{n}:n\geq1\rbrace$ and $h:=\frac{f^{\prime}}{f}-\frac{g^{\prime}}{g}$. Now, $h$ is holomprphic on $\mathbb{D}$ and disappears on a subset of $\mathbb{D}$ which has a limit point. Thus $h=0$, so $\frac{f^{\prime}}{f}=\frac{g^{\prime}}{g}$ on $\mathbb{D}$. Could someone help with the next steps? Or maybe $f$ doesn't have to be in the form described above?",,['complex-analysis']
15,Lagrange inversion formula proof [duplicate],Lagrange inversion formula proof [duplicate],,"This question already has answers here : Closed 11 years ago . Possible Duplicate: Proving theorem connecting the inverse of a holomorphic function to a contour integral of the function. I saw this theorem in some lecture notes, but I have not been able to find a proof. Let $f:\Omega \to \Bbb C$ be holomorphic with $f(0)=0 $ and $ f'(0)\neq0 $. Assume that $U \subset \Omega $ is a sufficiently small neighborhood of $0$ so that $f$ has a holomorphic inverse on $U$. Choose $r>0$ so small that $\bar B(0,r) \subset U$, further let $\omega \in f(B(0,r))$. Then the following formula holds: $$ f^{-1}(\omega) = \frac{1}{2\pi i} \oint_{|z|=r}\ \frac{f'(z)z}{f(z)-\omega}\, dz $$ A proof or a link to a proof would be very much appreciated.","This question already has answers here : Closed 11 years ago . Possible Duplicate: Proving theorem connecting the inverse of a holomorphic function to a contour integral of the function. I saw this theorem in some lecture notes, but I have not been able to find a proof. Let $f:\Omega \to \Bbb C$ be holomorphic with $f(0)=0 $ and $ f'(0)\neq0 $. Assume that $U \subset \Omega $ is a sufficiently small neighborhood of $0$ so that $f$ has a holomorphic inverse on $U$. Choose $r>0$ so small that $\bar B(0,r) \subset U$, further let $\omega \in f(B(0,r))$. Then the following formula holds: $$ f^{-1}(\omega) = \frac{1}{2\pi i} \oint_{|z|=r}\ \frac{f'(z)z}{f(z)-\omega}\, dz $$ A proof or a link to a proof would be very much appreciated.",,['complex-analysis']
16,Estimating the integrated Tchebychev function and calculating its error,Estimating the integrated Tchebychev function and calculating its error,,"I would like to understand how to derive (2) from (1) below. Problem :    If $\psi_1$ is the integrated Tchebychev function below   $$\psi_1(x)=\frac{1}{2\pi i} \int_{c-i\infty}^{c+i\infty}\frac{x^{s+1}}{s(s+1)} \left(\frac{-\zeta '(s)}{\zeta(s)}\right) \, ds \tag 1$$   where $c$ > 1, then   $$\psi_1(x)=\frac{x^2}{2}-\sum_\rho\frac{x^{\rho+1}}{\rho(\rho+1)}-E(x)\quad(2)$$   where the sum is taken over all zeros of zeta function in the critical strip. Which error term will be   $$E(x)=c_1x+c_0+\sum_{k=1}^{\infty}\frac{x^{1-2k}}{2k(2k-1)}$$   where $c_1=\frac{\zeta '(0)}{\zeta(0)}$ and $c_0=\frac{\zeta '(-1)}{\zeta(-1)}$.","I would like to understand how to derive (2) from (1) below. Problem :    If $\psi_1$ is the integrated Tchebychev function below   $$\psi_1(x)=\frac{1}{2\pi i} \int_{c-i\infty}^{c+i\infty}\frac{x^{s+1}}{s(s+1)} \left(\frac{-\zeta '(s)}{\zeta(s)}\right) \, ds \tag 1$$   where $c$ > 1, then   $$\psi_1(x)=\frac{x^2}{2}-\sum_\rho\frac{x^{\rho+1}}{\rho(\rho+1)}-E(x)\quad(2)$$   where the sum is taken over all zeros of zeta function in the critical strip. Which error term will be   $$E(x)=c_1x+c_0+\sum_{k=1}^{\infty}\frac{x^{1-2k}}{2k(2k-1)}$$   where $c_1=\frac{\zeta '(0)}{\zeta(0)}$ and $c_0=\frac{\zeta '(-1)}{\zeta(-1)}$.",,"['complex-analysis', 'riemann-zeta', 'zeta-functions']"
17,a problem relate to analytic function,a problem relate to analytic function,,"Suppose $f$ is an analytic function on $|z|\leq 1$ with $f(0)=0$, and let $|f(z)|$ have a maximum for $|z|\leq 1$ at 1, show that $f'(1)\neq 0$ unless $f$ is a constant. Remarks: 1, At first attempt, I tried to construct some function related to $f$, and then try to use Schwarz's lemma, but I got stuck; now I guess there exists an direction from $1$ such that the modulus locally increase. 2, To be precise, when applying Schwarz's lemma to $\frac{f}{|f(1)|}$, I got stuck because 1 is not in the open disk.","Suppose $f$ is an analytic function on $|z|\leq 1$ with $f(0)=0$, and let $|f(z)|$ have a maximum for $|z|\leq 1$ at 1, show that $f'(1)\neq 0$ unless $f$ is a constant. Remarks: 1, At first attempt, I tried to construct some function related to $f$, and then try to use Schwarz's lemma, but I got stuck; now I guess there exists an direction from $1$ such that the modulus locally increase. 2, To be precise, when applying Schwarz's lemma to $\frac{f}{|f(1)|}$, I got stuck because 1 is not in the open disk.",,"['complex-analysis', 'analysis']"
18,boundedness of harmonic conjugates,boundedness of harmonic conjugates,,Let $u$ be an harmonic function in the open simply connected set $U$. Then $u$ has a harmonic conjugate $v$ in $U$ (i.e. $f=u+iv$ is analytic on $U$). Suppose $u$ bounded in $U$. Can I say that $v$ is also bounded?,Let $u$ be an harmonic function in the open simply connected set $U$. Then $u$ has a harmonic conjugate $v$ in $U$ (i.e. $f=u+iv$ is analytic on $U$). Suppose $u$ bounded in $U$. Can I say that $v$ is also bounded?,,['complex-analysis']
19,"Evaluate $ \ \int_{- \infty}^{\infty} \frac{x e^{2ix}}{x^2 - 1}\,dx \ $ using given contour",Evaluate  using given contour," \ \int_{- \infty}^{\infty} \frac{x e^{2ix}}{x^2 - 1}\,dx \ ","The question is: Evaluate  $\displaystyle \ \int_{- \infty}^{\infty} \frac{x e^{2ix}}{x^2 - 1}\,dx \ $ using the contour below. (Explain what happens on each part of the contour.) First of all, isn't this a bad choice of contour? (Since it branch cuts between the 2 singularities) If we have to do it this way. Do we have to do it in 6 parts: The upper curve CR The lower left line segment The lower right line segment The center line segment The 2 arcs around the singularities: Cr1 and Cr2 This seems to be a very complicated situation. How do I do each of these steps? Is it residue theorem I have to use? How do I apply it in this situation? I have spent an hour reading about this but didn't get it. I have very limited time to burn on this specific kind of problem. So helps are appreciated, either an answer with steps or intuitive hints are appreciated. Thanks.","The question is: Evaluate  $\displaystyle \ \int_{- \infty}^{\infty} \frac{x e^{2ix}}{x^2 - 1}\,dx \ $ using the contour below. (Explain what happens on each part of the contour.) First of all, isn't this a bad choice of contour? (Since it branch cuts between the 2 singularities) If we have to do it this way. Do we have to do it in 6 parts: The upper curve CR The lower left line segment The lower right line segment The center line segment The 2 arcs around the singularities: Cr1 and Cr2 This seems to be a very complicated situation. How do I do each of these steps? Is it residue theorem I have to use? How do I apply it in this situation? I have spent an hour reading about this but didn't get it. I have very limited time to burn on this specific kind of problem. So helps are appreciated, either an answer with steps or intuitive hints are appreciated. Thanks.",,"['calculus', 'complex-analysis']"
20,branch points of arcsin,branch points of arcsin,,"From the definition given by wikipedia and Cauchy's theorem i can find the branch points of $\arcsin$ through its derivative $\displaystyle\frac{1}{\sqrt{1-x^2}}$ Are -1 and 1 simple pole of this expression ? (i'm a bit confused because of the fractional power) Also, there is also a branch point at infinity. How do i find this branch point ? what are the order of all the branch points of arcsin ? From wikipedia, i know that simple pole of derivative means logarithmic branch point, so there is no order if -1 and 1 are simple pole of $\displaystyle\frac{1}{\sqrt{1-x^2}}$ ?","From the definition given by wikipedia and Cauchy's theorem i can find the branch points of $\arcsin$ through its derivative $\displaystyle\frac{1}{\sqrt{1-x^2}}$ Are -1 and 1 simple pole of this expression ? (i'm a bit confused because of the fractional power) Also, there is also a branch point at infinity. How do i find this branch point ? what are the order of all the branch points of arcsin ? From wikipedia, i know that simple pole of derivative means logarithmic branch point, so there is no order if -1 and 1 are simple pole of $\displaystyle\frac{1}{\sqrt{1-x^2}}$ ?",,['complex-analysis']
21,Complex analysis integration with residues.,Complex analysis integration with residues.,,"I have to show that $$\int_{0}^{2\pi}\frac{d\theta}{(a^{2}\cos^{2}\theta+b^{2}\sin^{2}\theta)^{2}} =\frac{ \pi(a^{2}+b^{2})}{a^{3}b^{3}}$$ where $a,b>0$. I have tried using double angle formulas and Euler's trig identities to simplify this in order to use either residues or Cauchy's integral formula, but everything I have tried has made it messier and messier. Either I'm trying to simplify some things too early or something, but any help or tips would be much appreciated. Okay, I made the substitutions, and right now just focusing on the denominator, I got to $$(a^{2}(z+z^{-1})^2-b^{2}(z-z^{-1})^2)^2$$ (i took out the common factor of 4 that I got). Then here is where I'm stuck. It looks like I have a difference of 2 perfect squares, so I then wrote $$((a(z+z^{-1})-b(z+z^{-1}))(a(z+z^{-1})+b(z+z^{-1})))^2$$ which I then wrote as $$(a(z+z^{-1})-b(z+z^{-1}))^2(a(z+z^{-1})+b(z+z^{-1}))^2$$ If I did it right, which I hope I did, Now I'm not sure where to go from here into getting a rational function.","I have to show that $$\int_{0}^{2\pi}\frac{d\theta}{(a^{2}\cos^{2}\theta+b^{2}\sin^{2}\theta)^{2}} =\frac{ \pi(a^{2}+b^{2})}{a^{3}b^{3}}$$ where $a,b>0$. I have tried using double angle formulas and Euler's trig identities to simplify this in order to use either residues or Cauchy's integral formula, but everything I have tried has made it messier and messier. Either I'm trying to simplify some things too early or something, but any help or tips would be much appreciated. Okay, I made the substitutions, and right now just focusing on the denominator, I got to $$(a^{2}(z+z^{-1})^2-b^{2}(z-z^{-1})^2)^2$$ (i took out the common factor of 4 that I got). Then here is where I'm stuck. It looks like I have a difference of 2 perfect squares, so I then wrote $$((a(z+z^{-1})-b(z+z^{-1}))(a(z+z^{-1})+b(z+z^{-1})))^2$$ which I then wrote as $$(a(z+z^{-1})-b(z+z^{-1}))^2(a(z+z^{-1})+b(z+z^{-1}))^2$$ If I did it right, which I hope I did, Now I'm not sure where to go from here into getting a rational function.",,"['complex-analysis', 'residue-calculus', 'complex-integration']"
22,$\{z\in C:|z| = |\operatorname{re}(z)| +|\operatorname{im}(z)|\}$ open or closed [duplicate],open or closed [duplicate],\{z\in C:|z| = |\operatorname{re}(z)| +|\operatorname{im}(z)|\},"This question already has an answer here : Closed 11 years ago . Possible Duplicate: Proving that a complex set in open/closed/neither and bounded/not bounded I think $\{z\in C:|z| = |\operatorname{re}(z)| +|\operatorname{im}(z)|\}$ is closed. But I have no idea how to show it since you have to take an element of the set (which lies on the axes) and take a neighbourhood around that (not all of the ball is within the set so it's not open). But when you do the complement, not all of everything outside of the axes includes the ball (as some of the ball is on the axes). This would make it neither open nor closed but I'm sure it's closed! Can someone help me please? It's definitely not bounded because no closed ball can cover all of the axes as they go on to infinity and beyond. Right?","This question already has an answer here : Closed 11 years ago . Possible Duplicate: Proving that a complex set in open/closed/neither and bounded/not bounded I think $\{z\in C:|z| = |\operatorname{re}(z)| +|\operatorname{im}(z)|\}$ is closed. But I have no idea how to show it since you have to take an element of the set (which lies on the axes) and take a neighbourhood around that (not all of the ball is within the set so it's not open). But when you do the complement, not all of everything outside of the axes includes the ball (as some of the ball is on the axes). This would make it neither open nor closed but I'm sure it's closed! Can someone help me please? It's definitely not bounded because no closed ball can cover all of the axes as they go on to infinity and beyond. Right?",,"['general-topology', 'complex-analysis', 'bounded-variation']"
23,"What are the analytic isomorphisms of $\Omega = \mathbb{C} \setminus \{p_1,\ldots,p_n\}$?",What are the analytic isomorphisms of ?,"\Omega = \mathbb{C} \setminus \{p_1,\ldots,p_n\}","By an analytic isomorphism of $\Omega$, I mean an analytic function $\Omega \to \Omega$, with an analytic inverse.","By an analytic isomorphism of $\Omega$, I mean an analytic function $\Omega \to \Omega$, with an analytic inverse.",,"['complex-analysis', 'analyticity']"
24,Find all holomorphic functions $f$ such that $f(0) = 0$ and $f(f(z)) = z$ near $0$,Find all holomorphic functions  such that  and  near,f f(0) = 0 f(f(z)) = z 0,"Using power series, I have to find all holomorphic functions $f$ such that $f(0) = 0$ and $f(f(z)) = z$ near $0$. If I'm not mistaken, $f(0)=0$ restricts the power series to a form $\sum_n a_n z^n$ but now I have no idea how to proceed. If I just plug in, I get $$\sum_n a_n \left( \sum_k a_k z^k \right)^n = z$$ for $z$ near $0$, but what next? Thank you very much for any hints.","Using power series, I have to find all holomorphic functions $f$ such that $f(0) = 0$ and $f(f(z)) = z$ near $0$. If I'm not mistaken, $f(0)=0$ restricts the power series to a form $\sum_n a_n z^n$ but now I have no idea how to proceed. If I just plug in, I get $$\sum_n a_n \left( \sum_k a_k z^k \right)^n = z$$ for $z$ near $0$, but what next? Thank you very much for any hints.",,['complex-analysis']
25,Derivative of the Selberg $\zeta$-function,Derivative of the Selberg -function,\zeta,"I want to compute the derivative of the Selberg $\zeta$-function: $$ \mathcal{Z}(s)=\prod_{\gamma \; \text{primitive}} \prod_{n=0}^\infty (1-e^{-l(\gamma)(n+s)}); \qquad \Re(s)>1.$$ Where $\gamma$ are primitive closed geodesics on a given manifold and $l(\gamma)$ is their lenght. We can assume $s\in \mathbb{R}$. Observe that the given expression is justified by: $l(\gamma^n)= n l(\gamma)$. A couple of reliable articles ( Lou's ""On the zeros of the derivative of the Selberg Zeta function"" page 1143 for the statement and page 1141 for its definition of $\mathcal{Z}(s)$, and D'Hoker&Phong's ""The geometry of String Perturbation theory , implicitly in the last passage of page 1005), and  give, more or less explicitly, the following formula for the logarithmic derivative: $$ \frac{\frac{d}{ds}\mathcal{Z}(s)}{\mathcal{Z}(s)} = \sum_{\gamma \; \text{primitive}} \sum_{n=1}^\infty\frac{l(\gamma) e^{-l(\gamma)ns}}{1-e^{-l(\gamma)n}}.$$ But my computation seems to give a slightly different result. Indeed, first we observe: $$ \frac{d}{dx} \left(\prod_{n=0}^\infty f_n(x)\right)= \left(\prod_{n=0}^\infty f_n(x)\right)\left(\sum_{n=0}^\infty \frac{\frac{d}{dx}f_n(x)}{f_n(x)}\right).$$ Is it true? Wikipedia confirms it only in the finite case. Then, applying it to $ \mathcal{Z}(s)$, I deduce: $$ \frac{\frac{d}{ds}\mathcal{Z}(s)}{\mathcal{Z}(s)} = \sum_{\gamma \; \text{primitive}} \sum_{n=0}^\infty\frac{l(\gamma) e^{-l(\gamma)(n+s)}}{1-e^{-l(\gamma)(n+s)}}.$$ This expression seems to be close to the claimed one but I couldn't   prove they are the same. So I guess I'm doing something wrong in the   computation. Do you know how to do it? Thank you very much!","I want to compute the derivative of the Selberg $\zeta$-function: $$ \mathcal{Z}(s)=\prod_{\gamma \; \text{primitive}} \prod_{n=0}^\infty (1-e^{-l(\gamma)(n+s)}); \qquad \Re(s)>1.$$ Where $\gamma$ are primitive closed geodesics on a given manifold and $l(\gamma)$ is their lenght. We can assume $s\in \mathbb{R}$. Observe that the given expression is justified by: $l(\gamma^n)= n l(\gamma)$. A couple of reliable articles ( Lou's ""On the zeros of the derivative of the Selberg Zeta function"" page 1143 for the statement and page 1141 for its definition of $\mathcal{Z}(s)$, and D'Hoker&Phong's ""The geometry of String Perturbation theory , implicitly in the last passage of page 1005), and  give, more or less explicitly, the following formula for the logarithmic derivative: $$ \frac{\frac{d}{ds}\mathcal{Z}(s)}{\mathcal{Z}(s)} = \sum_{\gamma \; \text{primitive}} \sum_{n=1}^\infty\frac{l(\gamma) e^{-l(\gamma)ns}}{1-e^{-l(\gamma)n}}.$$ But my computation seems to give a slightly different result. Indeed, first we observe: $$ \frac{d}{dx} \left(\prod_{n=0}^\infty f_n(x)\right)= \left(\prod_{n=0}^\infty f_n(x)\right)\left(\sum_{n=0}^\infty \frac{\frac{d}{dx}f_n(x)}{f_n(x)}\right).$$ Is it true? Wikipedia confirms it only in the finite case. Then, applying it to $ \mathcal{Z}(s)$, I deduce: $$ \frac{\frac{d}{ds}\mathcal{Z}(s)}{\mathcal{Z}(s)} = \sum_{\gamma \; \text{primitive}} \sum_{n=0}^\infty\frac{l(\gamma) e^{-l(\gamma)(n+s)}}{1-e^{-l(\gamma)(n+s)}}.$$ This expression seems to be close to the claimed one but I couldn't   prove they are the same. So I guess I'm doing something wrong in the   computation. Do you know how to do it? Thank you very much!",,"['real-analysis', 'complex-analysis', 'derivatives', 'zeta-functions']"
26,Singularity at z=infinity?,Singularity at z=infinity?,,Let $f(z)= \dfrac 1 {e^{1/z}+1}$. Does this have a removable singularity at $z=\infty$? I found that all the singulairties (other than $\infty$) are bounded. So $z=\infty$ is a isolated singularity of $f(z)$. But does $f(1/z)=\dfrac 1 {e^{1/(1/z)}+1}=\dfrac 1 {e^{z}+1}$ have removable singularity at $z=0$ because just it has $z$ in the denominator?,Let $f(z)= \dfrac 1 {e^{1/z}+1}$. Does this have a removable singularity at $z=\infty$? I found that all the singulairties (other than $\infty$) are bounded. So $z=\infty$ is a isolated singularity of $f(z)$. But does $f(1/z)=\dfrac 1 {e^{1/(1/z)}+1}=\dfrac 1 {e^{z}+1}$ have removable singularity at $z=0$ because just it has $z$ in the denominator?,,['complex-analysis']
27,Convergence complex integral,Convergence complex integral,,"Does this integral converge $$\lim_{R \to \infty}\int_{\frac{\pi}{2}}^{\pi}\frac{e^{Rte^{i\theta}}}{\sqrt{Re^{i\theta}+1}}\cdot iRe^{i\theta}d\theta$$ where t is a positive integer? If the integral diverges, how can I prove this? p.s. This integral is part of a larger contour integral to calculate $$\int_{a-i\infty}^{a+i\infty} \frac{e^{zt}}{\sqrt{1+z}} dz$$ I know that $$\lim_{R \to \infty}\int_{\frac{\pi}{2}}^{\pi}\frac{e^{Rte^{i\theta}}}{\sqrt{Re^{i\theta}+1}}\cdot iRe^{i\theta}d\theta + \int_{-\pi}^{\frac{-\pi}{2}}\frac{e^{Rte^{i\theta}}}{\sqrt{Re^{i\theta}+1}}\cdot iRe^{i\theta}d\theta=0$$","Does this integral converge $$\lim_{R \to \infty}\int_{\frac{\pi}{2}}^{\pi}\frac{e^{Rte^{i\theta}}}{\sqrt{Re^{i\theta}+1}}\cdot iRe^{i\theta}d\theta$$ where t is a positive integer? If the integral diverges, how can I prove this? p.s. This integral is part of a larger contour integral to calculate $$\int_{a-i\infty}^{a+i\infty} \frac{e^{zt}}{\sqrt{1+z}} dz$$ I know that $$\lim_{R \to \infty}\int_{\frac{\pi}{2}}^{\pi}\frac{e^{Rte^{i\theta}}}{\sqrt{Re^{i\theta}+1}}\cdot iRe^{i\theta}d\theta + \int_{-\pi}^{\frac{-\pi}{2}}\frac{e^{Rte^{i\theta}}}{\sqrt{Re^{i\theta}+1}}\cdot iRe^{i\theta}d\theta=0$$",,"['complex-analysis', 'integration']"
28,Existence of Analytic Functions Based of f(1/n),Existence of Analytic Functions Based of f(1/n),,"I have the following question, and I don't even know where to begin: Do functions $f$ or $g$ exist which are analytic at the point $z=0$ and satisfy the conditions: $f(\frac{1}{n})=f(\frac{-1}{n})=\frac{1}{n^2}$, and $g(\frac{1}{n})=g(\frac{-1}{n})=\frac{1}{n^3}$?","I have the following question, and I don't even know where to begin: Do functions $f$ or $g$ exist which are analytic at the point $z=0$ and satisfy the conditions: $f(\frac{1}{n})=f(\frac{-1}{n})=\frac{1}{n^2}$, and $g(\frac{1}{n})=g(\frac{-1}{n})=\frac{1}{n^3}$?",,['complex-analysis']
29,does there exist an analytic function such that,does there exist an analytic function such that,,If $f$ is analytic in a nbd $\Delta_{\delta}$ of $0$ and $f(z)=-f(-z)\forall z\in\Delta_{\delta} $ Then there exist an analytic function $g\in \Delta_{\delta}$ such that $f(z)=zg(z^2)\forall z\in \Delta_{\delta}$,If $f$ is analytic in a nbd $\Delta_{\delta}$ of $0$ and $f(z)=-f(-z)\forall z\in\Delta_{\delta} $ Then there exist an analytic function $g\in \Delta_{\delta}$ such that $f(z)=zg(z^2)\forall z\in \Delta_{\delta}$,,['complex-analysis']
30,there exist analytic function with $f(\frac{i^n}{n})=-1/n^2$,there exist analytic function with,f(\frac{i^n}{n})=-1/n^2,"Does there exist analytic function with $f(\frac{i^n}{n})=\frac{-1}{n^2} \forall n\ge 2$, well I guess Yes, beacuse $g(z)=f(z)+z^2$ has zero set $\{-\frac{i}{n}: n \text{ odd}\}$ which has limit point zero, hence $f(z)=-z^2$ Is my answer is correct?","Does there exist analytic function with $f(\frac{i^n}{n})=\frac{-1}{n^2} \forall n\ge 2$, well I guess Yes, beacuse $g(z)=f(z)+z^2$ has zero set $\{-\frac{i}{n}: n \text{ odd}\}$ which has limit point zero, hence $f(z)=-z^2$ Is my answer is correct?",,['complex-analysis']
31,Complex Calculus - Cauchy integral Formule,Complex Calculus - Cauchy integral Formule,,"I could not prove below theorem. can you help me ? Thm : let $f(z)$ be analytic in $|z|<1$ with $f(0)=0$ and $\left|f(z)\right|\le 1$ for all $z$, $|z|<1$. prove that $\left|f''(0)\right|\le2$ Thanks","I could not prove below theorem. can you help me ? Thm : let $f(z)$ be analytic in $|z|<1$ with $f(0)=0$ and $\left|f(z)\right|\le 1$ for all $z$, $|z|<1$. prove that $\left|f''(0)\right|\le2$ Thanks",,['complex-analysis']
32,Connected Reinhardt Domain which is not complete,Connected Reinhardt Domain which is not complete,,"Can i have an example of connected Reinhardt domain in $C^n$ which contains zero.  But it is not complete. Complete means: For $w= (w_1,..w_n)\in D$, if $z$ is such that $|z_j|\leq |w_j$ for all $j$ implies $z\in D$.","Can i have an example of connected Reinhardt domain in $C^n$ which contains zero.  But it is not complete. Complete means: For $w= (w_1,..w_n)\in D$, if $z$ is such that $|z_j|\leq |w_j$ for all $j$ implies $z\in D$.",,"['complex-analysis', 'complex-geometry', 'several-complex-variables']"
33,What does it mean for a function to be bounded near $\infty$?,What does it mean for a function to be bounded near ?,\infty,Suppose $f(z)$ is some analytic function which is bounded near $0$. Then $f(1/z)$ is bounded near $\infty$. What exactly does that last statement mean practically? Does it mean $|f(1/z)|$ is bounded somehow?,Suppose $f(z)$ is some analytic function which is bounded near $0$. Then $f(1/z)$ is bounded near $\infty$. What exactly does that last statement mean practically? Does it mean $|f(1/z)|$ is bounded somehow?,,"['complex-analysis', 'terminology']"
34,Formula for Legendre polynomials by use of Cauchy's Integral Formula (From _Visual Complex Analysis_),Formula for Legendre polynomials by use of Cauchy's Integral Formula (From _Visual Complex Analysis_),,"I decided to look through Tristan Needham's Complex Analysis book since it's usually mentioned with great praise. Just doing some exercises, I got stuck on #4 of Chapter 9). Here $P_n(z)$ denotes the $n$-th Legendre polynomial. I've been able to derive that $$ P_n(z)=\frac{1}{2\pi i}\int_K\frac{(Z^2-1)^n}{2^n(Z-z)^{n+1}}dZ $$ for $K$ any simple loop around $z$. Then the book says by taking $K$ to be a circle of radius $\sqrt{|z^2-1|}$ centered at $z$,  $$ P_n(z)=\frac{1}{\pi}\int_0^\pi(z+\sqrt{z^2-1}\cos t)^n dt. $$ I tried to rewrite the RHS of the original equation by reparametrizing $Z=z+\sqrt{|z^2-1|}e^{it}$. However, upon rewriting in terms of the standard substitutions, the integral becomes unmanageable. I have $dZ=i\sqrt{|z^2-1|}e^{it}dt$, $Z^2-1=z^2+2z\sqrt{|z^2-1|}e^{it}+|z^2-1|e^{2it}-1$, $(Z-z)=\sqrt{|z^2-1|}e^{it}$. Substituting in, $$ \frac{1}{2^{n+1}\pi i}\int_0^{2\pi}\left(\frac{Z^2-1}{Z-z}\right)^2\frac{i\sqrt{|z^2-1|}e^{it}dt}{\sqrt{|z^2-1|}e^{it}} $$ which simplifies to $$ \frac{1}{2^{n+1}\pi}\int_0^{2\pi}\left(\frac{z^2-1}{\sqrt{|z^2-1|}e^{it}}+2z+\sqrt{|z^2-1|}e^{it}\right)^n dt. $$ Is there a way to put this into the final desired form? Thanks.","I decided to look through Tristan Needham's Complex Analysis book since it's usually mentioned with great praise. Just doing some exercises, I got stuck on #4 of Chapter 9). Here $P_n(z)$ denotes the $n$-th Legendre polynomial. I've been able to derive that $$ P_n(z)=\frac{1}{2\pi i}\int_K\frac{(Z^2-1)^n}{2^n(Z-z)^{n+1}}dZ $$ for $K$ any simple loop around $z$. Then the book says by taking $K$ to be a circle of radius $\sqrt{|z^2-1|}$ centered at $z$,  $$ P_n(z)=\frac{1}{\pi}\int_0^\pi(z+\sqrt{z^2-1}\cos t)^n dt. $$ I tried to rewrite the RHS of the original equation by reparametrizing $Z=z+\sqrt{|z^2-1|}e^{it}$. However, upon rewriting in terms of the standard substitutions, the integral becomes unmanageable. I have $dZ=i\sqrt{|z^2-1|}e^{it}dt$, $Z^2-1=z^2+2z\sqrt{|z^2-1|}e^{it}+|z^2-1|e^{2it}-1$, $(Z-z)=\sqrt{|z^2-1|}e^{it}$. Substituting in, $$ \frac{1}{2^{n+1}\pi i}\int_0^{2\pi}\left(\frac{Z^2-1}{Z-z}\right)^2\frac{i\sqrt{|z^2-1|}e^{it}dt}{\sqrt{|z^2-1|}e^{it}} $$ which simplifies to $$ \frac{1}{2^{n+1}\pi}\int_0^{2\pi}\left(\frac{z^2-1}{\sqrt{|z^2-1|}e^{it}}+2z+\sqrt{|z^2-1|}e^{it}\right)^n dt. $$ Is there a way to put this into the final desired form? Thanks.",,"['complex-analysis', 'polynomials']"
35,Definition of an algebraic singularity,Definition of an algebraic singularity,,"I'm reading text about generating functions and how to reveal their asymptotic behaviour by means of analysing their singularities. In this context the term ""algebraic singularity"" or in German ""algebraische Singularität"" is used. An example is given: $p(x)=\frac{1-\sqrt{1-4x}}{2}$. It's clear to me what a singularity is, but I can't find what they mean with algebaic in this context. Edit: Is this term used as synonym for essential singularities, i.e. singularities not being poles?","I'm reading text about generating functions and how to reveal their asymptotic behaviour by means of analysing their singularities. In this context the term ""algebraic singularity"" or in German ""algebraische Singularität"" is used. An example is given: $p(x)=\frac{1-\sqrt{1-4x}}{2}$. It's clear to me what a singularity is, but I can't find what they mean with algebaic in this context. Edit: Is this term used as synonym for essential singularities, i.e. singularities not being poles?",,"['complex-analysis', 'generating-functions']"
36,Absolute Convergence of an Infinite Product based on Weierstrass's Factor Theorem,Absolute Convergence of an Infinite Product based on Weierstrass's Factor Theorem,,I am trying to show that $\left\{ \left( 1-\dfrac {z} {\pi }\right) e^{\left( \dfrac {z} {\pi }\right) }\right\} \left\{ \left( 1+\dfrac {z} {\pi }\right) e^{\left( -\dfrac {z} {\pi }\right) }\right\}   \left\{ \left( 1-\dfrac {z} {2\pi }\right) e^{\left( \dfrac {z} {2\pi }\right) }\right\} \left\{ \left( 1+\dfrac {z} {2\pi }\right) e^{\left( -\dfrac {z} {2\pi }\right) }\right\}\ldots $ Converges absolutely. So the general term is of the form $\left( 1\pm \dfrac {z} {m\pi }\right) e^{\pm \dfrac {z} {m\pi }}$ I think it's the $e^{\pm \dfrac {z} {m\pi }}$ which is giving me grief. Any help would be much appreciated. Edit: Is multiplying the $2m -1 $ and the $2m$ terms and canceling out the $e^{\pm \dfrac {z} {m\pi }}$ parts and $\left( 1^2\ - (\dfrac {z} {m\pi })^2\right)$ terms be allowed or would that run the risk of altering the value of the product ?,I am trying to show that $\left\{ \left( 1-\dfrac {z} {\pi }\right) e^{\left( \dfrac {z} {\pi }\right) }\right\} \left\{ \left( 1+\dfrac {z} {\pi }\right) e^{\left( -\dfrac {z} {\pi }\right) }\right\}   \left\{ \left( 1-\dfrac {z} {2\pi }\right) e^{\left( \dfrac {z} {2\pi }\right) }\right\} \left\{ \left( 1+\dfrac {z} {2\pi }\right) e^{\left( -\dfrac {z} {2\pi }\right) }\right\}\ldots $ Converges absolutely. So the general term is of the form $\left( 1\pm \dfrac {z} {m\pi }\right) e^{\pm \dfrac {z} {m\pi }}$ I think it's the $e^{\pm \dfrac {z} {m\pi }}$ which is giving me grief. Any help would be much appreciated. Edit: Is multiplying the $2m -1 $ and the $2m$ terms and canceling out the $e^{\pm \dfrac {z} {m\pi }}$ parts and $\left( 1^2\ - (\dfrac {z} {m\pi })^2\right)$ terms be allowed or would that run the risk of altering the value of the product ?,,"['sequences-and-series', 'complex-analysis', 'convergence-divergence']"
37,Initial guesses for complex Newton method,Initial guesses for complex Newton method,,"For the iterative method $$z_{n+1} = z_n - \frac{f(z_n)}{f'(z_n)}\hspace{2cm}(*)$$ where $f:U \to \mathbb{C}$ and $U$ is an open subset of $\mathbb{C}$. I know that for stationary points ($f'(z)=0$) and points which enter a cycle, the method will not converge. But are there some sufficient features of an initial guess $z_0 \in U$ so the method converges? I don't want to write that (*) ""will converge with luck"". Thanks for your help!","For the iterative method $$z_{n+1} = z_n - \frac{f(z_n)}{f'(z_n)}\hspace{2cm}(*)$$ where $f:U \to \mathbb{C}$ and $U$ is an open subset of $\mathbb{C}$. I know that for stationary points ($f'(z)=0$) and points which enter a cycle, the method will not converge. But are there some sufficient features of an initial guess $z_0 \in U$ so the method converges? I don't want to write that (*) ""will converge with luck"". Thanks for your help!",,['complex-analysis']
38,Radius of convergence composite function,Radius of convergence composite function,,"If the Taylor series of 2 complex functions $f,g$ have radii of convergence $r_f, r_g$ respectively, does it follow that the radius of convergence of their composition has radius of convergence equal to $\min\{r_f, r_g\}$?","If the Taylor series of 2 complex functions $f,g$ have radii of convergence $r_f, r_g$ respectively, does it follow that the radius of convergence of their composition has radius of convergence equal to $\min\{r_f, r_g\}$?",,"['analysis', 'complex-analysis', 'power-series']"
39,Möbius transform which completely preserves circles (how to map a circle?),Möbius transform which completely preserves circles (how to map a circle?),,"(remmert theory of complex function) I am trying to solve this exercise, however it seems impossible because I don't know how to map a circle, and I will be very thankful if somebody points out to me: Given a Circle $C$, is it possible to show that for $a_{1},b_{1}\in \mathbb{C}\backslash C $ there exists a Möbius transformation $$M(z)= \frac{az+b}{cz+d}$$ which fulfills: $$M(C)=C ; M(a_{1})=b_{1}$$ So we can write conditions: $M(a)=b \Rightarrow aa_{1}+b= b(ca_{1}+d)$ How does one map a circle? I thought that a circle in $\mathbb{C}$ needs 3 points to be uniquely determined , so we can put: $z_{1},z_{2},z_{3} \in C$ and the condition is the same as for the a to b mapping: $$az_{k}+b=z_{k}(cz_{k}+d), k=1,2,3 \in \mathbb{N}$$ It seems that there isn't much more one can do with this approach, so I think it is not the right one. What is the right approach?","(remmert theory of complex function) I am trying to solve this exercise, however it seems impossible because I don't know how to map a circle, and I will be very thankful if somebody points out to me: Given a Circle $C$, is it possible to show that for $a_{1},b_{1}\in \mathbb{C}\backslash C $ there exists a Möbius transformation $$M(z)= \frac{az+b}{cz+d}$$ which fulfills: $$M(C)=C ; M(a_{1})=b_{1}$$ So we can write conditions: $M(a)=b \Rightarrow aa_{1}+b= b(ca_{1}+d)$ How does one map a circle? I thought that a circle in $\mathbb{C}$ needs 3 points to be uniquely determined , so we can put: $z_{1},z_{2},z_{3} \in C$ and the condition is the same as for the a to b mapping: $$az_{k}+b=z_{k}(cz_{k}+d), k=1,2,3 \in \mathbb{N}$$ It seems that there isn't much more one can do with this approach, so I think it is not the right one. What is the right approach?",,"['analysis', 'complex-analysis']"
40,When do three points determine the same orientation?,When do three points determine the same orientation?,,"I'm trying to understand the following claim: If $z_1,z_2,z_3,z_4$ are points (as complex numbers) on a circle, then $z_1,z_3,z_4$ and $z_2,z_3,z_4$ determine the same orientation iff $CR(z_1,z_2,z_3,z_4)>0$. Why is this? This was the explanation I tried to explain to myself, but I don't know if it's fully correct, since I make a lot of assumptions to simplify the work. Since the cross ratio is invariant under transformation, we can assume that $z_1,z_2,z_3,z_4$ lie on the real axis. Moreover, we can use a transformation to assume that $z_2=0$, $z_3=1$, and $z_4=2$. Now  $$ (z_1,z_2,z_3,z_4)=\frac{2(z_1-z_3)}{z_1-z_4} $$ and so $(z_1,z_2,z_3,z_4)>0$ if any only if $\frac{z_1-z_3}{z_1-z_4}>0$. Now note that for any $z$, $$ (z,z_1,z_3,z_4)=\frac{(z_1-z_4)z-(z_1-z_4)}{(z_1-z_3)z-2(z_1-z_3)} $$ and $$ (z,z_2,z_3,z_4)=\frac{2z-2}{z-2}. $$ So the determinant of the first transformation is $-(z_1-z_3)(z_1-z_4)$, and that of the latter is $-2$. But $\frac{z_1-1}{z_1-2}>0$ when numerator and denominator have the same sign, that is, either when $z_1>z_3$ and $z_1>z_4$, or when $z_1<z_3$ or $z_1<z_4$, and in either case the determinant is negative. It follows that $\Im(z,z_1,z_3,z_4)$ and $\Im(z,z_2,z_3,z_4)$ always have the same sign, and thus determine the same orientation. Thanks.","I'm trying to understand the following claim: If $z_1,z_2,z_3,z_4$ are points (as complex numbers) on a circle, then $z_1,z_3,z_4$ and $z_2,z_3,z_4$ determine the same orientation iff $CR(z_1,z_2,z_3,z_4)>0$. Why is this? This was the explanation I tried to explain to myself, but I don't know if it's fully correct, since I make a lot of assumptions to simplify the work. Since the cross ratio is invariant under transformation, we can assume that $z_1,z_2,z_3,z_4$ lie on the real axis. Moreover, we can use a transformation to assume that $z_2=0$, $z_3=1$, and $z_4=2$. Now  $$ (z_1,z_2,z_3,z_4)=\frac{2(z_1-z_3)}{z_1-z_4} $$ and so $(z_1,z_2,z_3,z_4)>0$ if any only if $\frac{z_1-z_3}{z_1-z_4}>0$. Now note that for any $z$, $$ (z,z_1,z_3,z_4)=\frac{(z_1-z_4)z-(z_1-z_4)}{(z_1-z_3)z-2(z_1-z_3)} $$ and $$ (z,z_2,z_3,z_4)=\frac{2z-2}{z-2}. $$ So the determinant of the first transformation is $-(z_1-z_3)(z_1-z_4)$, and that of the latter is $-2$. But $\frac{z_1-1}{z_1-2}>0$ when numerator and denominator have the same sign, that is, either when $z_1>z_3$ and $z_1>z_4$, or when $z_1<z_3$ or $z_1<z_4$, and in either case the determinant is negative. It follows that $\Im(z,z_1,z_3,z_4)$ and $\Im(z,z_2,z_3,z_4)$ always have the same sign, and thus determine the same orientation. Thanks.",,"['complex-analysis', 'transformational-geometry']"
41,How do the Laplace s-domain and the complex frequency domain differ?,How do the Laplace s-domain and the complex frequency domain differ?,,"In systems theory and signal processing, we often transform expressions based in the Laplace $s$-domain into the complex frequency domain with $j\omega$ (engineering notation for the angular frequency on the imaginary axis): $s \leftrightarrow j\omega$. I have always been told I can easily transform expressions between the two, but that I shouldn't simply equate them. So far, I always simply considered the Laplace $s$ as a 'sort of frequency or pulsation'. Is this correct? What exactly is the difference in meaning between these two domains? PS: Feel free to (re)tag, as I am not familiar with this particular forum's tags.","In systems theory and signal processing, we often transform expressions based in the Laplace $s$-domain into the complex frequency domain with $j\omega$ (engineering notation for the angular frequency on the imaginary axis): $s \leftrightarrow j\omega$. I have always been told I can easily transform expressions between the two, but that I shouldn't simply equate them. So far, I always simply considered the Laplace $s$ as a 'sort of frequency or pulsation'. Is this correct? What exactly is the difference in meaning between these two domains? PS: Feel free to (re)tag, as I am not familiar with this particular forum's tags.",,['complex-analysis']
42,Conformal map from the intersection of two disks to the unit disc,Conformal map from the intersection of two disks to the unit disc,,"I'm working through past papers for a Complex Analysis class I'm taking and have come across the following problem on conformal maps: Let $\lambda=\frac{1}{2}(1+i \sqrt3)$ and $R$ be the region $$r=\{z \in \mathbb{C} : |z-\lambda|<1 \text{ and } |z-\bar{\lambda}|<1 \}$$ Determine the image of $R$ under the Möbius Transformation $$f(z)=\frac{z}{1-z}$$ and hence find a holomorphic bijection $h$ from $R$ to the unit disc $\mathbb{D}= \{z \in \mathbb{C} : |z|<1 \}$ Thoughts I'm not very comfortable with mapping lens-shaped regions. I think it's significant that as $1$ lies inside $R$, and this is clearly mapping to $\infty$ by $f$ in the extended complex plane, and $0$ is mapped to itself, perhaps this will be the UHP or something similar, though I'm really not sure. Any help would be very appreciated. Best, MM.","I'm working through past papers for a Complex Analysis class I'm taking and have come across the following problem on conformal maps: Let $\lambda=\frac{1}{2}(1+i \sqrt3)$ and $R$ be the region $$r=\{z \in \mathbb{C} : |z-\lambda|<1 \text{ and } |z-\bar{\lambda}|<1 \}$$ Determine the image of $R$ under the Möbius Transformation $$f(z)=\frac{z}{1-z}$$ and hence find a holomorphic bijection $h$ from $R$ to the unit disc $\mathbb{D}= \{z \in \mathbb{C} : |z|<1 \}$ Thoughts I'm not very comfortable with mapping lens-shaped regions. I think it's significant that as $1$ lies inside $R$, and this is clearly mapping to $\infty$ by $f$ in the extended complex plane, and $0$ is mapped to itself, perhaps this will be the UHP or something similar, though I'm really not sure. Any help would be very appreciated. Best, MM.",,"['complex-analysis', 'conformal-geometry']"
43,What is the sum of the series $\sum \limits_{k=0}^\infty q^{2^k}$ if $|q|\lt1$,What is the sum of the series  if,\sum \limits_{k=0}^\infty q^{2^k} |q|\lt1,I wonder if anybody knows how to calculate the series below? $\sum \limits_{k=0}^\infty q^{2^k}$ if $|q|\lt1$? Thanks a lot for answers.,I wonder if anybody knows how to calculate the series below? $\sum \limits_{k=0}^\infty q^{2^k}$ if $|q|\lt1$? Thanks a lot for answers.,,"['sequences-and-series', 'complex-analysis']"
44,Find $\sup\limits_{f \in F}|f(2i)|$,Find,\sup\limits_{f \in F}|f(2i)|,May you help me with this question: Let $F$ a familiy of analytic functions at $H=\{z:\mathrm{Im}z>0\}$ that satisfies $f(i)=0$ and $|f(z)|\leq 1$. I want to find $\sup\limits_{f \in F}|f(2i)|$. I think that the solution is based on Möbius transformation. Thank you.,May you help me with this question: Let $F$ a familiy of analytic functions at $H=\{z:\mathrm{Im}z>0\}$ that satisfies $f(i)=0$ and $|f(z)|\leq 1$. I want to find $\sup\limits_{f \in F}|f(2i)|$. I think that the solution is based on Möbius transformation. Thank you.,,['complex-analysis']
45,Approximation with complex polynomials on $S^1$ - can it be done?,Approximation with complex polynomials on  - can it be done?,S^1,"Can one uniformly approximate a function 'similar' to identity on $S^1$ with complex polynomials? I mean a function like: $f(z)=z \cdot (1+h \cdot \sin(m\cdot Arg(z)))$, for $|h| < 1,\ m \in \mathbb{N}$. What I actually have is a function (actually I have a sequence of them but that is another story) like the following one (or a smooth version of it): $f(z)=z \cdot (1+ h \cdot wave(Arg(z)))$, where $wave(\phi)=[\phi^{-1} \in [\pi,k\pi]] \cdot \sin(\frac{1}{\phi})$, $[p]$ is $1$ if $p$ is true and $0$ otherwise and $k \in \mathbb{N_+}$. Can anyone tell me if there are any theorems saying that this approximation can be done or not? It looks similarly to Fourier series. What actually needs to be done is approximating $wave(Arg(z))$. However I need $z^{-n}$ to use Fourier series theory and I have only polynomials. $z^{-n}$ can not be approximated on the whole $S^1$ with polynomials. If I was able to extend the function to the whole 'unit+$\varepsilon$' disk in a holomorphic way I would be able to use Taylor series for this function, but I don't know if such an extending can be done, since the intuitive way with going orthogonally from the $f(S^1)$ when one goes orthogonally from the $S^1$ leads nowhere. My question comes from a bigger problem and what I actually need to solve it is: make such an approximation $w$ of $f$, that: $w(S^1) \subseteq{} \lbrace z \in \mathbb{C}: dist(z,f(S^1))< \delta \rbrace$ $|z-w(z)| < \varepsilon(h)$ where $\delta$ is some unknown constant depending on $f$. We may choose as $\varepsilon$   any function that is is continuous at zero and $\varepsilon(0)=0$. This one looks more complicated but is weaker than the previous one. If anyone could help me with that I would be really grateful.","Can one uniformly approximate a function 'similar' to identity on $S^1$ with complex polynomials? I mean a function like: $f(z)=z \cdot (1+h \cdot \sin(m\cdot Arg(z)))$, for $|h| < 1,\ m \in \mathbb{N}$. What I actually have is a function (actually I have a sequence of them but that is another story) like the following one (or a smooth version of it): $f(z)=z \cdot (1+ h \cdot wave(Arg(z)))$, where $wave(\phi)=[\phi^{-1} \in [\pi,k\pi]] \cdot \sin(\frac{1}{\phi})$, $[p]$ is $1$ if $p$ is true and $0$ otherwise and $k \in \mathbb{N_+}$. Can anyone tell me if there are any theorems saying that this approximation can be done or not? It looks similarly to Fourier series. What actually needs to be done is approximating $wave(Arg(z))$. However I need $z^{-n}$ to use Fourier series theory and I have only polynomials. $z^{-n}$ can not be approximated on the whole $S^1$ with polynomials. If I was able to extend the function to the whole 'unit+$\varepsilon$' disk in a holomorphic way I would be able to use Taylor series for this function, but I don't know if such an extending can be done, since the intuitive way with going orthogonally from the $f(S^1)$ when one goes orthogonally from the $S^1$ leads nowhere. My question comes from a bigger problem and what I actually need to solve it is: make such an approximation $w$ of $f$, that: $w(S^1) \subseteq{} \lbrace z \in \mathbb{C}: dist(z,f(S^1))< \delta \rbrace$ $|z-w(z)| < \varepsilon(h)$ where $\delta$ is some unknown constant depending on $f$. We may choose as $\varepsilon$   any function that is is continuous at zero and $\varepsilon(0)=0$. This one looks more complicated but is weaker than the previous one. If anyone could help me with that I would be really grateful.",,"['complex-analysis', 'fourier-analysis', 'approximation']"
46,Extending the cube root function to $\mathbb{C}$,Extending the cube root function to,\mathbb{C},"On $\mathbb{R}$, the cube-root function (call it $f(x)$) is a well-defined single-valued function which is $C^\infty$ except at the origin.  ($f(27)=3$, $f(-27)=-3$, etc.) The complex cube root (call it $u(z)$) is triple-valued with branch points at $0$ and $\infty$, so any continuous single-valued branch requires us to exclude some curve connecting $0$ and $\infty$ from the domain.  The origin-centered circle $C_R$ of radius $R$ is thus mapped by $u$ (minus a point excluded from the domain) to an arc subtending an angle of $2\pi/3$ at the origin. It seems to me on geometrical grounds that this means no choice of domain for $u$ can make it restrict to $f$ on the real axis. The image of $C_R\cap \mathbb{R}$ under $f$ includes both $\sqrt[3]{R}$ and $-\sqrt[3]{R}$, but $u$ maps the whole of $C_R$, minus the excluded point, to an arc subtending an angle of less than $\pi$, which thus can't contain both a real number and its negative. Do you agree?  Is it safe to say that the real cube root function (even excluding the origin) has no continuous analytic extension to (any connected region in) $\mathbb{C}$?  If not, how should this statement be qualified?","On $\mathbb{R}$, the cube-root function (call it $f(x)$) is a well-defined single-valued function which is $C^\infty$ except at the origin.  ($f(27)=3$, $f(-27)=-3$, etc.) The complex cube root (call it $u(z)$) is triple-valued with branch points at $0$ and $\infty$, so any continuous single-valued branch requires us to exclude some curve connecting $0$ and $\infty$ from the domain.  The origin-centered circle $C_R$ of radius $R$ is thus mapped by $u$ (minus a point excluded from the domain) to an arc subtending an angle of $2\pi/3$ at the origin. It seems to me on geometrical grounds that this means no choice of domain for $u$ can make it restrict to $f$ on the real axis. The image of $C_R\cap \mathbb{R}$ under $f$ includes both $\sqrt[3]{R}$ and $-\sqrt[3]{R}$, but $u$ maps the whole of $C_R$, minus the excluded point, to an arc subtending an angle of less than $\pi$, which thus can't contain both a real number and its negative. Do you agree?  Is it safe to say that the real cube root function (even excluding the origin) has no continuous analytic extension to (any connected region in) $\mathbb{C}$?  If not, how should this statement be qualified?",,"['complex-analysis', 'functions']"
47,Computing an integral where the poles of the integrand are the roots of unity,Computing an integral where the poles of the integrand are the roots of unity,,I am trying to compute the following integral: $$\int_0^{2\pi} \frac{y}{y^n-1} dy$$ I've tried to decompose $y^n-1$ into $(y-1)(y-e^{i\theta})(y-e^{i2\theta})...(y-e^{i(n-1)\theta})$ but I don't know what to do with this factorization. I've read some others similar questions with the answers but I don't know if the same methods apply.,I am trying to compute the following integral: $$\int_0^{2\pi} \frac{y}{y^n-1} dy$$ I've tried to decompose $y^n-1$ into $(y-1)(y-e^{i\theta})(y-e^{i2\theta})...(y-e^{i(n-1)\theta})$ but I don't know what to do with this factorization. I've read some others similar questions with the answers but I don't know if the same methods apply.,,"['complex-analysis', 'definite-integrals']"
48,Residue of $f(z) = \frac{z-2}{z^2}\sin(\frac{1}{1-z})$ at $z = 1$,Residue of  at,f(z) = \frac{z-2}{z^2}\sin(\frac{1}{1-z}) z = 1,"Given the complex function $f(z) = \frac{z-2}{z^2}\sin(\frac{1}{1-z})$, how can we calculate the residue at the essential singularity at $z = 1$?","Given the complex function $f(z) = \frac{z-2}{z^2}\sin(\frac{1}{1-z})$, how can we calculate the residue at the essential singularity at $z = 1$?",,['complex-analysis']
49,Conformal mapping of a doubly connected domain onto an annulus,Conformal mapping of a doubly connected domain onto an annulus,,"It is a well known theorem that any doubly connected domain can be conformally mapped onto an annulus. Consider the simpler version : Suppose $D$ is a bounded domain whose boundary is two non-intersecting circles. Then $D$ can be conformally mapped onto an annulus. I believe that the proof of this should be easier, that the conformal map would be just a linear fractional transformation. However, I'm having trouble constructing it. Could someone help? Thank you","It is a well known theorem that any doubly connected domain can be conformally mapped onto an annulus. Consider the simpler version : Suppose $D$ is a bounded domain whose boundary is two non-intersecting circles. Then $D$ can be conformally mapped onto an annulus. I believe that the proof of this should be easier, that the conformal map would be just a linear fractional transformation. However, I'm having trouble constructing it. Could someone help? Thank you",,[]
50,Open sets on a surface with locally connected boundary,Open sets on a surface with locally connected boundary,,"Let $\Sigma$ be a surface and $\Omega$ be an open subset of $\Sigma$ . Suppose that $\Omega$ is homeomorphic to the open unit disk $\mathbb{D}$ and is relatively compact in $\Sigma$ . I'm interested in the 'boundary behaviour' of maps $\varphi:\mathbb{D}\to\Omega$ when $\partial\Omega$ is locally connected. When $\Sigma$ is the complex plane or the Riemann sphere, then the Caratheodory-Torhorst Theorem can be used to show that there exists a homeomorphism $\varphi:\mathbb{D}\to\Omega$ which can be continuously extended to $\overline{\varphi}:\overline{\mathbb{D}}\to\overline{\Omega}$ , where the bar denotes closure in its respective space. (Here, the map $\overline{\varphi}$ need not be a homeomorphism.) I want to know whether this is true on general surfaces. If $\partial\Omega$ , the boundary of $\Omega$ , is locally connected, does there exist a homeomorphism $\varphi:\mathbb{D}\to\Omega$ which can be continuously extended to $\overline{\varphi}:\overline{\mathbb{D}}\to\overline{\Omega}$ ? If this is not true in general, when can we guarantee the existence of such $\varphi$ and $\overline{\varphi}$ ?","Let be a surface and be an open subset of . Suppose that is homeomorphic to the open unit disk and is relatively compact in . I'm interested in the 'boundary behaviour' of maps when is locally connected. When is the complex plane or the Riemann sphere, then the Caratheodory-Torhorst Theorem can be used to show that there exists a homeomorphism which can be continuously extended to , where the bar denotes closure in its respective space. (Here, the map need not be a homeomorphism.) I want to know whether this is true on general surfaces. If , the boundary of , is locally connected, does there exist a homeomorphism which can be continuously extended to ? If this is not true in general, when can we guarantee the existence of such and ?",\Sigma \Omega \Sigma \Omega \mathbb{D} \Sigma \varphi:\mathbb{D}\to\Omega \partial\Omega \Sigma \varphi:\mathbb{D}\to\Omega \overline{\varphi}:\overline{\mathbb{D}}\to\overline{\Omega} \overline{\varphi} \partial\Omega \Omega \varphi:\mathbb{D}\to\Omega \overline{\varphi}:\overline{\mathbb{D}}\to\overline{\Omega} \varphi \overline{\varphi},"['complex-analysis', 'surfaces', 'riemann-surfaces', 'geometric-topology', 'low-dimensional-topology']"
51,Find all holomorphic functions $f=u+iv$ such that $g=u^2+iv^2$ is holomorphic,Find all holomorphic functions  such that  is holomorphic,f=u+iv g=u^2+iv^2,"Let $\Omega\subset \mathbb{C}$ be a complex region. Find all holomorphic functions $f=u+iv$ in $\Omega$ such that $g=u^2+iv^2$ also be holomorphic in $\Omega$ . My attempt: We know that Cauchy-Riemann equations for $f$ and $g$ must be satisfied in $\Omega$ , i.e. \begin{equation}\label{eq:CR-1} 		\Biggl\{ 		\begin{aligned} 			u_x&=v_y,\\ 			u_y&=-v_x, 		\end{aligned} 	\end{equation} and, \begin{equation}\label{eq:CR-2} 		\Biggl\{ 		\begin{aligned} 			2uu_x&=2vv_y\\ 			2uu_y&=-2vv_x 		\end{aligned} 		\, \Longleftrightarrow \, \Biggl\{ 		\begin{aligned} 			uu_x&=vv_y\\ 			uu_y&=-vv_x 		\end{aligned} 	\end{equation} From which we get \begin{equation}\label{eq:CR-3} 			\Biggl\{ 		\begin{aligned} 			uu_x&=vu_x\\ 			uu_y&=vu_y. 		\end{aligned} 			\, \Longleftrightarrow \, 		\Biggl\{ 	\begin{aligned} 		(u-v)u_x&=0\\ 		(u-v)u_y&=0 	\end{aligned} \end{equation} I'm stuck in the last part because if I assume $u\neq v$ , for all $z\in \Omega$ then I get that $f$ must be constant. Same case if I assume that $u=v$ , for all $z\in \Omega$ . But, what happens for example if $u\neq v$ for some $z\in \Omega$ and at the same time $u=v$ for other values in $\Omega$ , or maybe this case is not possible?","Let be a complex region. Find all holomorphic functions in such that also be holomorphic in . My attempt: We know that Cauchy-Riemann equations for and must be satisfied in , i.e. and, From which we get I'm stuck in the last part because if I assume , for all then I get that must be constant. Same case if I assume that , for all . But, what happens for example if for some and at the same time for other values in , or maybe this case is not possible?","\Omega\subset \mathbb{C} f=u+iv \Omega g=u^2+iv^2 \Omega f g \Omega \begin{equation}\label{eq:CR-1}
		\Biggl\{
		\begin{aligned}
			u_x&=v_y,\\
			u_y&=-v_x,
		\end{aligned}
	\end{equation} \begin{equation}\label{eq:CR-2}
		\Biggl\{
		\begin{aligned}
			2uu_x&=2vv_y\\
			2uu_y&=-2vv_x
		\end{aligned}
		\, \Longleftrightarrow \, \Biggl\{
		\begin{aligned}
			uu_x&=vv_y\\
			uu_y&=-vv_x
		\end{aligned}
	\end{equation} \begin{equation}\label{eq:CR-3}
			\Biggl\{
		\begin{aligned}
			uu_x&=vu_x\\
			uu_y&=vu_y.
		\end{aligned}
			\, \Longleftrightarrow \,
		\Biggl\{
	\begin{aligned}
		(u-v)u_x&=0\\
		(u-v)u_y&=0
	\end{aligned}
\end{equation} u\neq v z\in \Omega f u=v z\in \Omega u\neq v z\in \Omega u=v \Omega",['complex-analysis']
52,Proving $I(E(\Bbb C))=\left< y^2-x^3-ax-b\right>$,Proving,I(E(\Bbb C))=\left< y^2-x^3-ax-b\right>,"Let $E/\Bbb C : y^2=x^3+ax+b$ be an elliptic curve over $\Bbb C$ . Let $$E(\Bbb C)=\{(x,y)\in\Bbb C^2:y^2=x^3+ax+b\}$$ be the affine variety generated by $E$ . Finally, let $$I(E(\Bbb C))=\{f(x,y)\in\Bbb C[x,y]: f(p)=0,\, \forall p\in E(\Bbb C)\}.$$ I am trying to show that $I(E(\Bbb C))=I_E$ is the ideal generated by $E$ , that is, $$I_E=\left< y^2-x^3-ax-b\right>\subset\Bbb C[x,y].$$ My attempt so far has been the following. Suppose $f\in\Bbb C[x,y]$ . Then we can divide by $y^2-x^3-ax-b$ and get $$f(x,y)=q(x,y)(y^2-x^3-ax-b)+r(x,y),$$ where the total degree of $r\in\Bbb C[x,y]$ is less than $3$ . Suppose then, that $f$ vanishes on $E(\Bbb C)$ . That is, $f\in I_E$ . From the uniformalization theorem, there is a lattice $L\subset \Bbb C$ such that $a=-15G_4(L),$ and $b=-35G_6(L)$ , where $G_4,G_6$ are Eisenstein series corresponding to $L$ . Because of this, the point $(\wp(z,L),\tfrac12\wp'(z,L))$ is in $E(\Bbb C)$ for all $z\in\Bbb C$ . Here, $\wp(z,L)$ is the Weierstrass Elliptic function corresponding to the lattice $L$ . Thus, $$0=f(\wp,\tfrac12\wp')=q(\wp,\tfrac12\wp')(\tfrac14\wp'^2-\wp^3-a\wp-b)+r(\wp,\tfrac12\wp').$$ Due to the differential equation $$\frac14\wp'(z,L)^2=\wp(z,L)^3-15G_4(L)\wp(z,L)-35G_6(L),$$ we then have that $$r(\wp,\tfrac12\wp')=0.$$ All I need to show now is that $r(x,y)$ is identically equal to $0$ , but I am not quite sure how. One thing I considered is to write $$r(x,y)=\beta_1x^2+\beta_2xy+\beta_3y^2+\beta_3x+\beta_5y+\beta_6,$$ so that $$\begin{align} r(\wp,\tfrac12\wp')&=\beta_1\wp^2+\tfrac12\beta_2\wp\wp'+\tfrac14\beta_3\wp'^2+\beta_4\wp+\tfrac12\beta_5\wp'+\beta_6\\ &=\beta_1\wp^2+\tfrac12\beta_2\wp\wp'+\beta_3(\wp^3+a\wp+b)+\beta_4\wp+\tfrac12\beta_5\wp'+\beta_6\\ &=\beta_3\wp^3+\beta_1\wp^2+(a\beta_3+\beta_4)\wp+\tfrac12(\beta_2\wp+\beta_5)\wp'+\beta_6+b\beta_3\\ &= 0. \end{align}$$ Then using the expansion $$\wp(z,L)=\frac1{z^2}+\sum_{n\ge1}(2n+1)G_{2n+2}(L)z^{2n},$$ the expansion of $\beta_3\wp^3+\beta_1\wp^2+(a\beta_3+\beta_4)\wp$ would only contain even powers of $z$ , while the expansion of $\tfrac12(\beta_2\wp+\beta_5)\wp'$ would only contain odd powers of $z$ , making the coefficient of $z^n$ of $r(\wp,\tfrac12\wp')$ be $0$ for all $n\ne0$ , and the constant term of $r(\wp,\tfrac12\wp')$ equal to $-\beta_6-b\beta_3$ . I was hoping that this would then imply that $r(x,y)\equiv 0$ , but I am not exactly sure if that works. Is there a way to show that $r\equiv 0$ from here? Or perhaps an easier way to show that $f\in\left<y^2-x^3-ax-b\right>$ ? Thanks. Edit for context: I encountered this problem by looking through my old notes from my undergrad algebraic geometry class. I was wondering how I could apply what I learned from the class to elliptic curves.","Let be an elliptic curve over . Let be the affine variety generated by . Finally, let I am trying to show that is the ideal generated by , that is, My attempt so far has been the following. Suppose . Then we can divide by and get where the total degree of is less than . Suppose then, that vanishes on . That is, . From the uniformalization theorem, there is a lattice such that and , where are Eisenstein series corresponding to . Because of this, the point is in for all . Here, is the Weierstrass Elliptic function corresponding to the lattice . Thus, Due to the differential equation we then have that All I need to show now is that is identically equal to , but I am not quite sure how. One thing I considered is to write so that Then using the expansion the expansion of would only contain even powers of , while the expansion of would only contain odd powers of , making the coefficient of of be for all , and the constant term of equal to . I was hoping that this would then imply that , but I am not exactly sure if that works. Is there a way to show that from here? Or perhaps an easier way to show that ? Thanks. Edit for context: I encountered this problem by looking through my old notes from my undergrad algebraic geometry class. I was wondering how I could apply what I learned from the class to elliptic curves.","E/\Bbb C : y^2=x^3+ax+b \Bbb C E(\Bbb C)=\{(x,y)\in\Bbb C^2:y^2=x^3+ax+b\} E I(E(\Bbb C))=\{f(x,y)\in\Bbb C[x,y]: f(p)=0,\, \forall p\in E(\Bbb C)\}. I(E(\Bbb C))=I_E E I_E=\left< y^2-x^3-ax-b\right>\subset\Bbb C[x,y]. f\in\Bbb C[x,y] y^2-x^3-ax-b f(x,y)=q(x,y)(y^2-x^3-ax-b)+r(x,y), r\in\Bbb C[x,y] 3 f E(\Bbb C) f\in I_E L\subset \Bbb C a=-15G_4(L), b=-35G_6(L) G_4,G_6 L (\wp(z,L),\tfrac12\wp'(z,L)) E(\Bbb C) z\in\Bbb C \wp(z,L) L 0=f(\wp,\tfrac12\wp')=q(\wp,\tfrac12\wp')(\tfrac14\wp'^2-\wp^3-a\wp-b)+r(\wp,\tfrac12\wp'). \frac14\wp'(z,L)^2=\wp(z,L)^3-15G_4(L)\wp(z,L)-35G_6(L), r(\wp,\tfrac12\wp')=0. r(x,y) 0 r(x,y)=\beta_1x^2+\beta_2xy+\beta_3y^2+\beta_3x+\beta_5y+\beta_6, \begin{align}
r(\wp,\tfrac12\wp')&=\beta_1\wp^2+\tfrac12\beta_2\wp\wp'+\tfrac14\beta_3\wp'^2+\beta_4\wp+\tfrac12\beta_5\wp'+\beta_6\\
&=\beta_1\wp^2+\tfrac12\beta_2\wp\wp'+\beta_3(\wp^3+a\wp+b)+\beta_4\wp+\tfrac12\beta_5\wp'+\beta_6\\
&=\beta_3\wp^3+\beta_1\wp^2+(a\beta_3+\beta_4)\wp+\tfrac12(\beta_2\wp+\beta_5)\wp'+\beta_6+b\beta_3\\
&= 0.
\end{align} \wp(z,L)=\frac1{z^2}+\sum_{n\ge1}(2n+1)G_{2n+2}(L)z^{2n}, \beta_3\wp^3+\beta_1\wp^2+(a\beta_3+\beta_4)\wp z \tfrac12(\beta_2\wp+\beta_5)\wp' z z^n r(\wp,\tfrac12\wp') 0 n\ne0 r(\wp,\tfrac12\wp') -\beta_6-b\beta_3 r(x,y)\equiv 0 r\equiv 0 f\in\left<y^2-x^3-ax-b\right>","['complex-analysis', 'algebraic-geometry', 'ideals', 'elliptic-curves']"
53,"Stein and Shakarchi, Complex Analysis, Chapter 2 Example 2","Stein and Shakarchi, Complex Analysis, Chapter 2 Example 2",,"I'm reading through Stein and Shakarchi's Complex Analysis textbook, but I'm a bit confused by their proof that $$ \int_{0}^{\infty} \frac{1-\cos(x)}{x^2} dx = \frac{\pi}{2}$$ They consider the function $f(z) = \frac{1-e^{iz}}{z^2}$ and an indented semicircle as their contour The part where I'm confused is the integral of $f(z)$ over $\gamma_{\epsilon}^+$ . The way they evaluate this integral is by first noting that $$ f(z) = \frac{-iz}{z^2} + E(z) $$ where $E(z)$ is bounded as $z\rightarrow 0$ . I'm fine with the rest of the proof but I'm puzzled by $E(z)$ . My question: How is this function bounded as $z \rightarrow 0$ ? It seems like $E(z)$ would just be $$ E(z) = \frac{1+iz+e^{iz}}{z^2}$$ Is it because we're integrating over $\gamma_{\epsilon}^+$ and so $|z| = \epsilon$ and so $$ \left| E(z) \right| = \left| \frac{1}{z} + \frac{i}{z} + \frac{e^{iz}}{z^2} \right| \leq \left|\frac{1}{z} \right| + \left| \frac{i}{z} \right| + \left| \frac{e^{iz}}{z^2} \right| = \frac{1}{\epsilon} + \frac{1}{\epsilon^2} + \frac{1}{\epsilon^2} $$ ?","I'm reading through Stein and Shakarchi's Complex Analysis textbook, but I'm a bit confused by their proof that They consider the function and an indented semicircle as their contour The part where I'm confused is the integral of over . The way they evaluate this integral is by first noting that where is bounded as . I'm fine with the rest of the proof but I'm puzzled by . My question: How is this function bounded as ? It seems like would just be Is it because we're integrating over and so and so ?", \int_{0}^{\infty} \frac{1-\cos(x)}{x^2} dx = \frac{\pi}{2} f(z) = \frac{1-e^{iz}}{z^2} f(z) \gamma_{\epsilon}^+  f(z) = \frac{-iz}{z^2} + E(z)  E(z) z\rightarrow 0 E(z) z \rightarrow 0 E(z)  E(z) = \frac{1+iz+e^{iz}}{z^2} \gamma_{\epsilon}^+ |z| = \epsilon  \left| E(z) \right| = \left| \frac{1}{z} + \frac{i}{z} + \frac{e^{iz}}{z^2} \right| \leq \left|\frac{1}{z} \right| + \left| \frac{i}{z} \right| + \left| \frac{e^{iz}}{z^2} \right| = \frac{1}{\epsilon} + \frac{1}{\epsilon^2} + \frac{1}{\epsilon^2} ,"['complex-analysis', 'proof-explanation']"
54,the infinite series $\sum z^n$ for $z \in \mathbb{C}$ does not converge uniformly on $|z| <1$,the infinite series  for  does not converge uniformly on,\sum z^n z \in \mathbb{C} |z| <1,"The series $\sum_{n=0}^{\infty} z^n$ does not converge uniformly on $D(0,1) = \{ z \in \mathbb{C} : |z|<1 \}$ . Here is my attempt: Suppose to the contrary that the series $\sum_{n=0}^{\infty} z^n$ converges uniformly on $D(0,1)$ . Since uniform convergence implies pointwise convergence, the series converges to \begin{equation*}     \sum_{n=0}^{\infty} z^n = \frac{1}{1-z} \end{equation*} for all $z \in D(0, 1)$ . Choose $z = 1 - \frac{1}{k}$ for $k \in \mathbb{N}$ so that $z \in D(0, 1)$ . Then, we have \begin{equation*}     \sum_{n=0}^{\infty} \left(1 - \frac{1}{k}\right)^n = \frac{1}{1 - \left(1 - \frac{1}{k}\right)} = k. \end{equation*} However, the series $\sum_{n=0}^{\infty} \left(1 - \frac{1}{k}\right)^n$ diverges as $k \to \infty$ . This is a contradiction. Now I know that I have to use the supremum norm, but why the attempt does not work? Although the sequence converges to $1$ , I thought that it still lives in $D(0,1)$ . Edit: I changed the summation from $\sum_{n=0}^{\infty}\left(1-\frac{1}{n}\right)^n$ to $\sum_{n=0}^{\infty}\left(1-\frac{1}{k}\right)^n$ .","The series does not converge uniformly on . Here is my attempt: Suppose to the contrary that the series converges uniformly on . Since uniform convergence implies pointwise convergence, the series converges to for all . Choose for so that . Then, we have However, the series diverges as . This is a contradiction. Now I know that I have to use the supremum norm, but why the attempt does not work? Although the sequence converges to , I thought that it still lives in . Edit: I changed the summation from to .","\sum_{n=0}^{\infty} z^n D(0,1) = \{ z \in \mathbb{C} : |z|<1 \} \sum_{n=0}^{\infty} z^n D(0,1) \begin{equation*}
    \sum_{n=0}^{\infty} z^n = \frac{1}{1-z}
\end{equation*} z \in D(0, 1) z = 1 - \frac{1}{k} k \in \mathbb{N} z \in D(0, 1) \begin{equation*}
    \sum_{n=0}^{\infty} \left(1 - \frac{1}{k}\right)^n = \frac{1}{1 - \left(1 - \frac{1}{k}\right)} = k.
\end{equation*} \sum_{n=0}^{\infty} \left(1 - \frac{1}{k}\right)^n k \to \infty 1 D(0,1) \sum_{n=0}^{\infty}\left(1-\frac{1}{n}\right)^n \sum_{n=0}^{\infty}\left(1-\frac{1}{k}\right)^n","['sequences-and-series', 'complex-analysis', 'uniform-convergence']"
55,A uniform (non-asymptotic) upper bound for Hermite polynomials in the complex plane,A uniform (non-asymptotic) upper bound for Hermite polynomials in the complex plane,,"In a paper dating back to 1990, Eijndhoven and Meyers [1] mention the following ""elementary"" upper bound for Hermite polynomials on the whole complex plane: $$ \forall z \in \mathbb{C}, \forall n\in\mathbb{N},\;\; |H_n(z)| \leq 2^{\frac{n}{2}} \,\sqrt{n!}\; e^{\sqrt{2n}|z|}$$ They did not give the proof of this very useful inequality. They only gave a hint, which was to use the well-known, explicit polynomial sum -- a nice piece of advice that left me stranded. Strange as it may seem, I have not found it anywhere in reference books (Bateman, NIST, Gradshtein, Prudnikov and alii etc.). The inequality plays an important part in the other proofs of the paper. Any idea of how to  cleanly derive it? I have a partial proof by induction that unfortunately only works in the complex plane outside of the disk of radius $\sqrt{\frac{n+1}{2}}$ , what I am looking for is a proof valid in the whole complex plane. Also, there exist better bounds on the real and imaginary lines, so partial answers limited to these lines will not do. (Historical edit) For low to moderate values of $n$ , this ""elementary"" upper bound is way better than it looks, at least for high real parts and low imaginary parts. The best uniform inequality in the complex plane  I know of was given by P. Rusev in a paper of the Bulgarian academy of sciences [2]: $$|H_n(z)| \leq (2e/\pi)^\frac{1}{4}(\Gamma(2n+1))^\frac{1}{2} (2n+1)^{-n/2-1/4} e^\frac{n}{2} e^{x^2}\cosh((2n+1)^\frac{1}{2}y), \text { where } z=x+iy$$ It is surprising to see that this ""non elementary"" estimate is in $e^{x^2}$ while the elementary one is only (asymptotically for $y$ fixed) in $e^{|x|}$ . Rusev's bound is not much better for high imaginary parts and low real parts either. It may be better for higher values of $n$ and bounded $x$ . Apparently the author did not know of Eijndhoven and Meyers' formula given 10 years earlier. [1] Eijndhoven,S.J.L.  and Meyers, J.L.H. ""New Orthogonality Relations for the Hermite Polynomials and Related Hilbert Spaces"", JOURNAL OF MATHEMATICAL ANALYSIS AND APPLICATIONS 146, 89-98 (1990), eq. 1.2 p. 90 [2] P. Rusev ""An Inequality for Hermite's Polynomials in the Complex Plane"", Dokladi na b'lgarckata akademia na naukite/Comptes rendus de l'Académie bulgare des Sciences, 53,10 (2000).","In a paper dating back to 1990, Eijndhoven and Meyers [1] mention the following ""elementary"" upper bound for Hermite polynomials on the whole complex plane: They did not give the proof of this very useful inequality. They only gave a hint, which was to use the well-known, explicit polynomial sum -- a nice piece of advice that left me stranded. Strange as it may seem, I have not found it anywhere in reference books (Bateman, NIST, Gradshtein, Prudnikov and alii etc.). The inequality plays an important part in the other proofs of the paper. Any idea of how to  cleanly derive it? I have a partial proof by induction that unfortunately only works in the complex plane outside of the disk of radius , what I am looking for is a proof valid in the whole complex plane. Also, there exist better bounds on the real and imaginary lines, so partial answers limited to these lines will not do. (Historical edit) For low to moderate values of , this ""elementary"" upper bound is way better than it looks, at least for high real parts and low imaginary parts. The best uniform inequality in the complex plane  I know of was given by P. Rusev in a paper of the Bulgarian academy of sciences [2]: It is surprising to see that this ""non elementary"" estimate is in while the elementary one is only (asymptotically for fixed) in . Rusev's bound is not much better for high imaginary parts and low real parts either. It may be better for higher values of and bounded . Apparently the author did not know of Eijndhoven and Meyers' formula given 10 years earlier. [1] Eijndhoven,S.J.L.  and Meyers, J.L.H. ""New Orthogonality Relations for the Hermite Polynomials and Related Hilbert Spaces"", JOURNAL OF MATHEMATICAL ANALYSIS AND APPLICATIONS 146, 89-98 (1990), eq. 1.2 p. 90 [2] P. Rusev ""An Inequality for Hermite's Polynomials in the Complex Plane"", Dokladi na b'lgarckata akademia na naukite/Comptes rendus de l'Académie bulgare des Sciences, 53,10 (2000)."," \forall z \in \mathbb{C}, \forall n\in\mathbb{N},\;\; |H_n(z)| \leq 2^{\frac{n}{2}} \,\sqrt{n!}\; e^{\sqrt{2n}|z|} \sqrt{\frac{n+1}{2}} n |H_n(z)| \leq (2e/\pi)^\frac{1}{4}(\Gamma(2n+1))^\frac{1}{2} (2n+1)^{-n/2-1/4} e^\frac{n}{2} e^{x^2}\cosh((2n+1)^\frac{1}{2}y), \text { where } z=x+iy e^{x^2} y e^{|x|} n x","['complex-analysis', 'upper-lower-bounds', 'orthogonal-polynomials', 'hermite-polynomials']"
56,How would you compute $\int_0^\infty{\frac{dx}{x^{\frac{2}{5}} (x^2 + 1)^2 }}$.,How would you compute .,\int_0^\infty{\frac{dx}{x^{\frac{2}{5}} (x^2 + 1)^2 }},"Given the following integral, how would you solve it? $$ \int_0^\infty{\frac{dx}{x^{\frac{2}{5}} (x^2 + 1)^2 }} $$ because $f(x)$ is an even function: $$ \int_{-\infty}^\infty{\frac{dx}{2x^{\frac{2}{5}} (x^2 + 1)^2 }} $$ By Residue integration, we have: $$ \int_\Gamma f(z)dz = 2 \pi i \sum \text{Res} \{f, z_i \} $$ The countour $\Gamma$ is: $$ \Gamma = [\varepsilon, R] \cup\gamma_{R}(0, \pi) \cup [-R, -\varepsilon] \cup \gamma_\varepsilon (-\pi, 0) $$ where: $$ \gamma_r(a, b): \; z =  re^{it} \; \; \; \; t\in (a, b) $$ hence: $$ \text{Res} \{f, z = 0 \} = \lim_{z \to 0} \; \; (z - 0) \frac{1}{2z^{\frac{2}{5}} (z^2 + 1)^2 } = 0. $$ $$ \text{Res} \{f, z = i \} = \lim_{z \to i} \; \; \frac{d}{dz} \left[(z - i)^2\frac{1}{2z^{\frac{2}{5}} (z^2 + 1)^2 } \right] = -\frac{7}{40}e^{3i \pi / 10} $$ $$ \int_\Gamma f(z)dz = -\frac{7 i \pi}{20}e^{3i \pi / 10} $$ Now, splitting the integrals: $$ \int_\Gamma f(z)dz = \int_{\gamma_R} f(z)dz + \int_{\gamma_\varepsilon} f(z)dz + \int_{-R}^{-\varepsilon} f(z) dz + \int^{R}_{\varepsilon} f(z) dz $$ $$ \int_{\gamma_\varepsilon} f(z)dz = \pi i \text{Res} \{f, z = 0 \} = 0 $$ performing the limit where $R \to \infty$ and $\varepsilon \to 0$ : $$ \int_\Gamma f(z)dz  = \int_{-\infty}^{\infty} f(z)dz =  -\frac{7 i \pi}{20}e^{3i \pi / 10} $$ But this is clearly wrong. I'm doing it right? How should I solve the integral with residues?","Given the following integral, how would you solve it? because is an even function: By Residue integration, we have: The countour is: where: hence: Now, splitting the integrals: performing the limit where and : But this is clearly wrong. I'm doing it right? How should I solve the integral with residues?","
\int_0^\infty{\frac{dx}{x^{\frac{2}{5}} (x^2 + 1)^2 }}
 f(x) 
\int_{-\infty}^\infty{\frac{dx}{2x^{\frac{2}{5}} (x^2 + 1)^2 }}
 
\int_\Gamma f(z)dz = 2 \pi i \sum \text{Res} \{f, z_i \}
 \Gamma 
\Gamma = [\varepsilon, R] \cup\gamma_{R}(0, \pi) \cup [-R, -\varepsilon] \cup \gamma_\varepsilon (-\pi, 0)
 
\gamma_r(a, b): \; z =  re^{it} \; \; \; \; t\in (a, b)
 
\text{Res} \{f, z = 0 \} = \lim_{z \to 0} \; \; (z - 0) \frac{1}{2z^{\frac{2}{5}} (z^2 + 1)^2 } = 0.
 
\text{Res} \{f, z = i \} = \lim_{z \to i} \; \; \frac{d}{dz} \left[(z - i)^2\frac{1}{2z^{\frac{2}{5}} (z^2 + 1)^2 } \right] = -\frac{7}{40}e^{3i \pi / 10}
 
\int_\Gamma f(z)dz = -\frac{7 i \pi}{20}e^{3i \pi / 10}
 
\int_\Gamma f(z)dz = \int_{\gamma_R} f(z)dz + \int_{\gamma_\varepsilon} f(z)dz + \int_{-R}^{-\varepsilon} f(z) dz + \int^{R}_{\varepsilon} f(z) dz
 
\int_{\gamma_\varepsilon} f(z)dz = \pi i \text{Res} \{f, z = 0 \} = 0
 R \to \infty \varepsilon \to 0 
\int_\Gamma f(z)dz  = \int_{-\infty}^{\infty} f(z)dz =  -\frac{7 i \pi}{20}e^{3i \pi / 10}
","['calculus', 'probability', 'complex-analysis', 'definite-integrals', 'stochastic-processes']"
57,Extending a holomorphic function on $\mathbb{C}\backslash K$ to an entire function,Extending a holomorphic function on  to an entire function,\mathbb{C}\backslash K,"Consider a compact set $K\subset \mathbb{R}$ with positive measure (i.e. $\mu(K)>0$ ), and for $z\in\mathbb{C}\backslash K$ , define the holomorphic function $f$ on $\mathbb{C}\backslash K$ by \begin{equation} f(z):=\int_K \frac{dt}{t-z}. \end{equation} Now the question is can $f$ be extended to an entire function ? Clearly $f(z)\to 0$ as $z\to \infty$ in every direction, and I'm not familiar with entire functions of this kind, this seems to me a realy pointless question :(","Consider a compact set with positive measure (i.e. ), and for , define the holomorphic function on by Now the question is can be extended to an entire function ? Clearly as in every direction, and I'm not familiar with entire functions of this kind, this seems to me a realy pointless question :(","K\subset \mathbb{R} \mu(K)>0 z\in\mathbb{C}\backslash K f \mathbb{C}\backslash K \begin{equation}
f(z):=\int_K \frac{dt}{t-z}.
\end{equation} f f(z)\to 0 z\to \infty","['complex-analysis', 'entire-functions', 'analytic-continuation']"
58,Non-polynomial entire function with finitely many zeros tends to zero on circles,Non-polynomial entire function with finitely many zeros tends to zero on circles,,"Suppose $f$ is entire with finitely many zeros. Assume $f$ is not a polynomial. Let $m(r) = \inf_{|z| = r} |f(z)|$ . I want to show that $$\lim_{r \rightarrow \infty} m(r) =0.$$ I want to note that a previous problem required me to prove that the function $M_f(r) = \sup_{|z|=r} |f(z)|$ is a non-decreasing function of $r$ (should be true for any entire function). A hint I was given for this problem was to factor out the zeros to obtain a non-vanishing entire function $g$ . Then supposing that $m(r)$ does not go to zero, I should try to estimate $m(r)$ using $M_{1/g}(r)$ and show that $1/g$ is a polynomial. My current progress so far is that I can write $f(z) = g(z) \prod_{i=1}^k (z-z_i)^k$ where $z_1, \ldots, z_k$ are the finitely many zeros of $f$ , the $k_i$ are the respective orders of the zeros, and $g(z)$ is entire and non-vanishing. Then analyzing $M_{1/g}(r)$ , we have for large enough $r$ so that $f(z) \neq 0$ , $$ M_{1/g}(r) = \sup_{|z|=r} \frac{1}{|g(z)|} = \sup_{|z|=r} \frac{\prod_{i=1}^k |z-z_i|^k}{|f(z)|} \leq  \frac{\sup_{|z|=r}\prod_{i=1}^k |z-z_i|^k}{\inf_{|z|=r}|f(z)|} = \frac{\sup_{|z|=r}\prod_{i=1}^k |z-z_i|^k}{m(r)}. $$ So rearranging gives us $$ m(r) \leq \frac{\sup_{|z|=r}\prod_{i=1}^k |z-z_i|^k}{M_{1/g}(r)}. $$ From here, I'm not sure how to make use the assumption that $m(r)$ does not go to zero and how to show $1/g$ is a polynomial. Furthermore, I'm not sure how that leads to contradiction. I would appreciate any hints.","Suppose is entire with finitely many zeros. Assume is not a polynomial. Let . I want to show that I want to note that a previous problem required me to prove that the function is a non-decreasing function of (should be true for any entire function). A hint I was given for this problem was to factor out the zeros to obtain a non-vanishing entire function . Then supposing that does not go to zero, I should try to estimate using and show that is a polynomial. My current progress so far is that I can write where are the finitely many zeros of , the are the respective orders of the zeros, and is entire and non-vanishing. Then analyzing , we have for large enough so that , So rearranging gives us From here, I'm not sure how to make use the assumption that does not go to zero and how to show is a polynomial. Furthermore, I'm not sure how that leads to contradiction. I would appreciate any hints.","f f m(r) = \inf_{|z| = r} |f(z)| \lim_{r \rightarrow \infty} m(r) =0. M_f(r) = \sup_{|z|=r} |f(z)| r g m(r) m(r) M_{1/g}(r) 1/g f(z) = g(z) \prod_{i=1}^k (z-z_i)^k z_1, \ldots, z_k f k_i g(z) M_{1/g}(r) r f(z) \neq 0  M_{1/g}(r) = \sup_{|z|=r} \frac{1}{|g(z)|} = \sup_{|z|=r} \frac{\prod_{i=1}^k |z-z_i|^k}{|f(z)|} \leq  \frac{\sup_{|z|=r}\prod_{i=1}^k |z-z_i|^k}{\inf_{|z|=r}|f(z)|} = \frac{\sup_{|z|=r}\prod_{i=1}^k |z-z_i|^k}{m(r)}.   m(r) \leq \frac{\sup_{|z|=r}\prod_{i=1}^k |z-z_i|^k}{M_{1/g}(r)}.  m(r) 1/g","['complex-analysis', 'entire-functions']"
59,An automorphic function with no poles is constant.,An automorphic function with no poles is constant.,,"Daniel Bump calls $f$ an automorphic function if it satisfies the formula $$f\left(\frac{az+b}{cz+d}\right)=f(z)$$ where $\begin{pmatrix} a&b\\ c&d \end{pmatrix}\in\mathrm{SL}(2,\mathbb{Z})$ in his Automorphic Forms and Representations . Now I want to verify that an automorphic function with no poles is constant . Bump claims it follows from the maximum modulus principle, but how to explain this in more detail? Should I try to show that $|f(x)|$ has a maximum in $U$ and how to demonstrate it?","Daniel Bump calls an automorphic function if it satisfies the formula where in his Automorphic Forms and Representations . Now I want to verify that an automorphic function with no poles is constant . Bump claims it follows from the maximum modulus principle, but how to explain this in more detail? Should I try to show that has a maximum in and how to demonstrate it?","f f\left(\frac{az+b}{cz+d}\right)=f(z) \begin{pmatrix}
a&b\\
c&d
\end{pmatrix}\in\mathrm{SL}(2,\mathbb{Z}) |f(x)| U","['complex-analysis', 'analytic-number-theory', 'modular-forms', 'meromorphic-functions', 'automorphic-forms']"
60,Basic contour integral of $\frac{\sin z}{z - i}$,Basic contour integral of,\frac{\sin z}{z - i},"I'm trying to evaluate a basic contour integral, but am getting an incorrect factor of 2 in my answer. Evaluating $$\int_{-\infty}^{\infty} \frac{\sin z}{z - i} = \Im \left( \int_{-\infty}^{\infty} \frac{e^{i z}}{z - i} \right) \, ,$$ I express this as a closed semi-circular contour of radius $R$ in the upper-half plane and take $\lim R \to \infty$ . By Jordan's lemma, the integral over the arc contour vanishes and we can evaluate the integral by the residue theorem $$\int_{-\infty}^{\infty} \frac{\sin z}{z - i} = \Im \left( 2 \pi i \, \left. \mathrm{Res}\left(  \frac{e^{i z}}{z - i} \right) \right|_{z = i} \right) = \frac{2 \pi}{e} \, ,$$ while the correct answer is $\pi / e$ . I've stared at this for a bit and still cannot see what I've done wrong. Can anyone quickly point out how the factor of 2 cancels?","I'm trying to evaluate a basic contour integral, but am getting an incorrect factor of 2 in my answer. Evaluating I express this as a closed semi-circular contour of radius in the upper-half plane and take . By Jordan's lemma, the integral over the arc contour vanishes and we can evaluate the integral by the residue theorem while the correct answer is . I've stared at this for a bit and still cannot see what I've done wrong. Can anyone quickly point out how the factor of 2 cancels?","\int_{-\infty}^{\infty} \frac{\sin z}{z - i} = \Im \left( \int_{-\infty}^{\infty} \frac{e^{i z}}{z - i} \right) \, , R \lim R \to \infty \int_{-\infty}^{\infty} \frac{\sin z}{z - i} = \Im \left( 2 \pi i \, \left. \mathrm{Res}\left( 
\frac{e^{i z}}{z - i} \right) \right|_{z = i} \right) = \frac{2 \pi}{e} \, , \pi / e","['complex-analysis', 'contour-integration']"
61,Proving $\sum_{k=1}^{n-1} \cos\left(\frac{2\pi k}{n}\right)=-1$,Proving,\sum_{k=1}^{n-1} \cos\left(\frac{2\pi k}{n}\right)=-1,"I am currently trying to prove $$\sum_{k=1}^{n-1} \cos\left(\frac{2\pi k}{n}\right)=-1$$ My current attempt goes as follows $$\sum_{k=1}^{n-1} \cos\left(\frac{2\pi k}{n}\right)=\Re\left(\sum_{k=1}^{n-1} e^\frac{2\pi k i}{n}\right)$$ Here is where some of my confusion is, I'm not sure which geometric series to use, I have tried $$\sum_{k=1}^{n-1} z^{k} = \frac{z-z^n}{1-z}$$ but I have no clue if this is correct or where the $-1$ would come from. Can someone please show me the correct direction?","I am currently trying to prove My current attempt goes as follows Here is where some of my confusion is, I'm not sure which geometric series to use, I have tried but I have no clue if this is correct or where the would come from. Can someone please show me the correct direction?",\sum_{k=1}^{n-1} \cos\left(\frac{2\pi k}{n}\right)=-1 \sum_{k=1}^{n-1} \cos\left(\frac{2\pi k}{n}\right)=\Re\left(\sum_{k=1}^{n-1} e^\frac{2\pi k i}{n}\right) \sum_{k=1}^{n-1} z^{k} = \frac{z-z^n}{1-z} -1,"['sequences-and-series', 'complex-analysis']"
62,Complex analysis exercise: prove that $f$ is constant given an inequality [duplicate],Complex analysis exercise: prove that  is constant given an inequality [duplicate],f,"This question already has an answer here : How can i prove that this function is bounded in order to apply Liouville's theorem? (1 answer) Closed 10 months ago . I am studying complex analysis and I came upon this exercise: If $f$ is a holomorphic function in $\mathbb{C}$ and for every $z\in\mathbb{C}$ we have $|f(z)|\leq\sqrt{|z|+2}$ then show that $f$ is a constant function. Any ideas for solving this problem? I tried with Liouville's theorem, but I think that it isn't the right way to solve this.","This question already has an answer here : How can i prove that this function is bounded in order to apply Liouville's theorem? (1 answer) Closed 10 months ago . I am studying complex analysis and I came upon this exercise: If is a holomorphic function in and for every we have then show that is a constant function. Any ideas for solving this problem? I tried with Liouville's theorem, but I think that it isn't the right way to solve this.",f \mathbb{C} z\in\mathbb{C} |f(z)|\leq\sqrt{|z|+2} f,"['complex-analysis', 'analysis']"
63,Establishing Analyticity of Function f,Establishing Analyticity of Function f,,"G is a domain in the complex plane. Consider the function $f: G \rightarrow \mathbb{C}$ , which is both complex and continuous within G. Additionally, we have the relation $e^{f(z)} = z$ . I know that inorder to show that f is analytic I need to show the following: 1. Show that G is an open set (This is inherently true as G is a domain). 2. Confirm that f is differentiable within G. It's worth noting that the function $e^x$ exhibits both continuity and differentiability within G. Given that f(z) is continuous across G, we can deduce the continuity of $e^{f(z)}$ within G. I'm seeking your assistance in establishing a connection between these points to demonstrate that f is analytic.","G is a domain in the complex plane. Consider the function , which is both complex and continuous within G. Additionally, we have the relation . I know that inorder to show that f is analytic I need to show the following: 1. Show that G is an open set (This is inherently true as G is a domain). 2. Confirm that f is differentiable within G. It's worth noting that the function exhibits both continuity and differentiability within G. Given that f(z) is continuous across G, we can deduce the continuity of within G. I'm seeking your assistance in establishing a connection between these points to demonstrate that f is analytic.",f: G \rightarrow \mathbb{C} e^{f(z)} = z e^x e^{f(z)},['complex-analysis']
64,Connected components of conformal image of boundary,Connected components of conformal image of boundary,,"Let $f : G \rightarrow \mathbb{D}$ be a biholomorphism (a holomorphic map with holomorphic inverse), and suppose $G$ is a bounded open subset of the plane. Let $C$ be a compact connected subset of the boundary $\partial G$ , and consider the set: $I =  \{y \in \partial \mathbb{D} : \exists (x_n)_{n=1}^{\infty} \subset G, d(x_n, C ) \rightarrow 0, y = \lim_{n} f(x_n) \}$ Is $I$ necessarily of finite connectivity? That is, does $I$ necessarily have at most finitely many connected components? It may be worth noting the image will most certainly NOT be connected. For example, take $G$ to be a slit disk, and $C$ a small compact connected interval below the tip of the slit. Then the image of $C$ under the map $f$ will correspond to two connected components of the boundary of the unit disk.","Let be a biholomorphism (a holomorphic map with holomorphic inverse), and suppose is a bounded open subset of the plane. Let be a compact connected subset of the boundary , and consider the set: Is necessarily of finite connectivity? That is, does necessarily have at most finitely many connected components? It may be worth noting the image will most certainly NOT be connected. For example, take to be a slit disk, and a small compact connected interval below the tip of the slit. Then the image of under the map will correspond to two connected components of the boundary of the unit disk.","f : G \rightarrow \mathbb{D} G C \partial G I =  \{y \in \partial \mathbb{D} : \exists (x_n)_{n=1}^{\infty} \subset G, d(x_n, C ) \rightarrow 0, y = \lim_{n} f(x_n) \} I I G C C f","['complex-analysis', 'analysis', 'connectedness', 'plane-geometry', 'conformal-geometry']"
65,How to evaluate $\int_{0}^{\frac{\pi}{2}} \frac{d\theta}{2+\sin(\theta)}$ using Cauchy's integral theorem even tho it isn't from 0 to 2pi?,How to evaluate  using Cauchy's integral theorem even tho it isn't from 0 to 2pi?,\int_{0}^{\frac{\pi}{2}} \frac{d\theta}{2+\sin(\theta)},"Evaluate using Cauchy's integral theorem $$\int_{0}^{\frac{\pi}{2}} \frac{d\theta}{2+\sin(\theta)}.$$ I understand the idea is to use $\sin(\theta) = \frac{z-z^{-1}}{2i}$ and $z = e^{i\theta}$ to convert into the  complex plane and simplified to: $$2\oint_C{\frac{dz}{z^{2}+4zi-1}}$$ which after plugging into the quadratic equation yields the singularities $i(\sqrt{3}-2),  -i(\sqrt{3}+2)$ applying Cauchy's Integral Theorem $$2\oint_C{\frac{dz}{z^{2}+4zi-1}} = 2\pi{i}\sum_{k_i}{\operatorname{Res}(f(z);k_i)}$$ where $k_i =$ all singularities. My expectation is that $2\pi{i}\sum_{k_i}{\operatorname{Res}(f(z);k_i)} = \frac{2\pi}{\sqrt{3}}$ If I realize that Cauchy's is applied over $\int_{0}^{2\pi}$ but my original integral was only over $\int_{0}^{\frac{\pi}{2}}$ I also put a $\frac{1}{4}$ conversion factor on the integral to change the bounds, which would yield $\frac{\pi}{2\sqrt{3}}$ . This is what I assumed the answer to be from what I understand about this process. However it seems the true result: $$\int_{0}^{\frac{\pi}{2}} \frac{1}{2+\sin(\theta)} = \frac{\pi}{3\sqrt{3}}$$ obviously $\frac{\pi}{2\sqrt{3}}$ and $\frac{\pi}{3\sqrt{3}}$ are different by a factor of $\frac{2}{3}$ . I then solved the problem also using the form $$\oint_C{\frac{f(z)dz}{(z-z_0)^{n+1}}} = \frac{2\pi{i}}{n!}\cdot f^{(n)}(z_0)$$ to check my result, however this also resulted in the same thing I got the other way, i.e. the wrong answer. After testing everything I have not been able to figure out what it could be unless when converting the integrals from $\int_{0}^{\frac{\pi}{2}}$ to a contour over $\oint_C$ . You can't actually just adjust the range as I did. And I should be getting a factor of $\frac16$ instead of $\frac14$ . But I can't figure out why. Please help. Thank you in advance!","Evaluate using Cauchy's integral theorem I understand the idea is to use and to convert into the  complex plane and simplified to: which after plugging into the quadratic equation yields the singularities applying Cauchy's Integral Theorem where all singularities. My expectation is that If I realize that Cauchy's is applied over but my original integral was only over I also put a conversion factor on the integral to change the bounds, which would yield . This is what I assumed the answer to be from what I understand about this process. However it seems the true result: obviously and are different by a factor of . I then solved the problem also using the form to check my result, however this also resulted in the same thing I got the other way, i.e. the wrong answer. After testing everything I have not been able to figure out what it could be unless when converting the integrals from to a contour over . You can't actually just adjust the range as I did. And I should be getting a factor of instead of . But I can't figure out why. Please help. Thank you in advance!","\int_{0}^{\frac{\pi}{2}} \frac{d\theta}{2+\sin(\theta)}. \sin(\theta) = \frac{z-z^{-1}}{2i} z = e^{i\theta} 2\oint_C{\frac{dz}{z^{2}+4zi-1}} i(\sqrt{3}-2), 
-i(\sqrt{3}+2) 2\oint_C{\frac{dz}{z^{2}+4zi-1}} = 2\pi{i}\sum_{k_i}{\operatorname{Res}(f(z);k_i)} k_i = 2\pi{i}\sum_{k_i}{\operatorname{Res}(f(z);k_i)} = \frac{2\pi}{\sqrt{3}} \int_{0}^{2\pi} \int_{0}^{\frac{\pi}{2}} \frac{1}{4} \frac{\pi}{2\sqrt{3}} \int_{0}^{\frac{\pi}{2}} \frac{1}{2+\sin(\theta)} = \frac{\pi}{3\sqrt{3}} \frac{\pi}{2\sqrt{3}} \frac{\pi}{3\sqrt{3}} \frac{2}{3} \oint_C{\frac{f(z)dz}{(z-z_0)^{n+1}}} = \frac{2\pi{i}}{n!}\cdot f^{(n)}(z_0) \int_{0}^{\frac{\pi}{2}} \oint_C \frac16 \frac14","['complex-analysis', 'cauchy-integral-formula']"
66,Does $\sum_{n=0}^{\infty}|f_n| r^n \leq C \|f\|_{L^{\infty}(|z| \leq r)}$ when $f(z)$ is holomorphic?,Does  when  is holomorphic?,\sum_{n=0}^{\infty}|f_n| r^n \leq C \|f\|_{L^{\infty}(|z| \leq r)} f(z),"Let $$f(z) = \sum_{n=0}^{\infty}f_nz^n$$ be holomorphic on $|z| < R$ and let $0 < r < R$ . I'm wondering if there exists some universal constant $C > 0$ (i.e. independent of $r,R,f$ ) for which $$\sum_{n=0}^{\infty} |f_n| r^n \leq C \|f\|_{L^{\infty}(|z| \leq r)}$$ I'm aware of similar, but different results Cauchy's inequality : $|f_n|r^n \leq \|f\|_{L^{\infty}(|z| \leq r)}$ for all $n \geq 0$ Parseval's identity : $\sum_{n=0}^{\infty} |f_n|^2 r^{2n} = \frac{1}{2\pi}\int_0^{2\pi} |f(re^{i\theta})|^2 d\theta$ which implies $$\left( \sum_{n=0}^{\infty} |f_n|^2 r^{2n} \right)^{\frac{1}{2}} \leq \|f\|_{L^{\infty}(|z| \leq r)}$$ Hadamard Multiplication Theorem Hardy's inequality","Let be holomorphic on and let . I'm wondering if there exists some universal constant (i.e. independent of ) for which I'm aware of similar, but different results Cauchy's inequality : for all Parseval's identity : which implies Hadamard Multiplication Theorem Hardy's inequality","f(z) = \sum_{n=0}^{\infty}f_nz^n |z| < R 0 < r < R C > 0 r,R,f \sum_{n=0}^{\infty} |f_n| r^n \leq C \|f\|_{L^{\infty}(|z| \leq r)} |f_n|r^n \leq \|f\|_{L^{\infty}(|z| \leq r)} n \geq 0 \sum_{n=0}^{\infty} |f_n|^2 r^{2n} = \frac{1}{2\pi}\int_0^{2\pi} |f(re^{i\theta})|^2 d\theta \left( \sum_{n=0}^{\infty} |f_n|^2 r^{2n} \right)^{\frac{1}{2}} \leq \|f\|_{L^{\infty}(|z| \leq r)}","['complex-analysis', 'upper-lower-bounds']"
67,Analysing an integral asymptotically,Analysing an integral asymptotically,,"Let $A$ be a constant, say larger than $1/2$ . I am interested in the integral $$I_s = \int_0^\infty (A+\varepsilon+\nu^2)^{-s} e^{ix\nu} d\nu$$ where $s$ is a complex variable, ultimately with fixed real part ( $\Re(s) = 2+\delta$ ). Option 1, moving contour By moving the integration line until $\Im \nu = A$ , for which everything in holomorphic, we are led to consider the integral $$I_s = e^{-Ax}\int_0^\infty (\varepsilon + 2iAt + t^2)^{-s} e^{ixt} dt$$ and I do want to see this exponential decay. However, this integral does not converge absolutely (the integrand absolute value is about $t^{\Re(s)}$ ). Question 1. Is this integral convergent? How does it depend on $s$ and on $x$ ? Option 2, obtaining an explicit formula The original integral is a Basset integral for the $K$ -Bessel function (given e.g. here ) which states that it looks like $$K_{s}(zx) \frac{x^{s}}{z^s\Gamma(s)}$$ where $z^2 = A+\varepsilon$ Question 2. Knowing that $\Re(s) = 2 + \delta$ for a small $\delta>0$ , how does this depend upon $s$ (when its imaginary part grows)? How does it depend upon $x$ ? It looks like it blows up vertically in $s$ , since the $\Gamma$ function does by Stirling formula.","Let be a constant, say larger than . I am interested in the integral where is a complex variable, ultimately with fixed real part ( ). Option 1, moving contour By moving the integration line until , for which everything in holomorphic, we are led to consider the integral and I do want to see this exponential decay. However, this integral does not converge absolutely (the integrand absolute value is about ). Question 1. Is this integral convergent? How does it depend on and on ? Option 2, obtaining an explicit formula The original integral is a Basset integral for the -Bessel function (given e.g. here ) which states that it looks like where Question 2. Knowing that for a small , how does this depend upon (when its imaginary part grows)? How does it depend upon ? It looks like it blows up vertically in , since the function does by Stirling formula.",A 1/2 I_s = \int_0^\infty (A+\varepsilon+\nu^2)^{-s} e^{ix\nu} d\nu s \Re(s) = 2+\delta \Im \nu = A I_s = e^{-Ax}\int_0^\infty (\varepsilon + 2iAt + t^2)^{-s} e^{ixt} dt t^{\Re(s)} s x K K_{s}(zx) \frac{x^{s}}{z^s\Gamma(s)} z^2 = A+\varepsilon \Re(s) = 2 + \delta \delta>0 s x s \Gamma,"['integration', 'complex-analysis', 'analysis', 'contour-integration', 'mellin-transform']"
68,Dimension of a space of holomorphic functions,Dimension of a space of holomorphic functions,,"I would like to solve the following: for $r$ a positive real number, determine the dimension of the following vector space over $\mathbb{C}$ in terms of $r$ : $$[\text{holomorphic } f:\mathbb{C}\rightarrow\mathbb{C}\text{ where } f<\infty].$$ My idea is to show that all such holomorphic functions are really nice in some way, like polynomials. I've tried playing around with the power series expansion and showing this directly, but I'm not making much progress. Is this the right idea? Any help is appreciated.","I would like to solve the following: for a positive real number, determine the dimension of the following vector space over in terms of : My idea is to show that all such holomorphic functions are really nice in some way, like polynomials. I've tried playing around with the power series expansion and showing this directly, but I'm not making much progress. Is this the right idea? Any help is appreciated.",r \mathbb{C} r [\text{holomorphic } f:\mathbb{C}\rightarrow\mathbb{C}\text{ where } f<\infty].,[]
69,Integral related to binomial coefficient $\frac{1}{2\pi}\int_{-\pi}^{\pi}\frac{(1+e^{ix})^n}{e^{ixk}}~dx$,Integral related to binomial coefficient,\frac{1}{2\pi}\int_{-\pi}^{\pi}\frac{(1+e^{ix})^n}{e^{ixk}}~dx,"I want to show that $$\frac{1}{2\pi}\int_{-\pi}^{\pi}\frac{(1+e^{ix})^n}{e^{ixk}}~dx={n\choose k}$$ My attempts were very poor, since I'm not an expert in contour integration.I thought that, in order to have factorials on the right, the integral could be reduced to a Beta function, but substituting $t=e^{ix}$ doesn't work because of the bounds $-\pi,\pi$ . I am wondering if anyone could give me a shove in the right direction.","I want to show that My attempts were very poor, since I'm not an expert in contour integration.I thought that, in order to have factorials on the right, the integral could be reduced to a Beta function, but substituting doesn't work because of the bounds . I am wondering if anyone could give me a shove in the right direction.","\frac{1}{2\pi}\int_{-\pi}^{\pi}\frac{(1+e^{ix})^n}{e^{ixk}}~dx={n\choose k} t=e^{ix} -\pi,\pi","['integration', 'complex-analysis', 'definite-integrals', 'contour-integration', 'residue-calculus']"
70,Compute residues for $\int_{-\infty}^{\infty} \frac{x \sin x}{1+x^4}dx$,Compute residues for,\int_{-\infty}^{\infty} \frac{x \sin x}{1+x^4}dx,"I am trying to compute $$\int_{-\infty}^{\infty} \frac{x \sin x}{1+x^4}dx$$ This question has been asked here , but the asker and answerer skip over the calculation of the residues. Define the curve $\gamma$ to be the semicircle in the top half plane with radius $R$ and straight edge on the real axis from $-R$ to $R$ . Then by the residue theorem and Jordan's lemma, taking $R \to \infty$ , I know that $$\int_{-\infty}^{\infty} \frac{z e^{iz}}{1+z^4}dz = \oint_{\gamma} \frac{ze^{iz}}{1+z^4} dz = 2 \pi i \sum_{\alpha \text{ roots of } 1+z^4, \Im(\alpha)>0} \text{Res}\left(\frac{z e^{iz}}{1+z^4}, \alpha \right)$$ The relevant roots are $\alpha=e^{\frac{\pi i}{4}}, e^{\frac{3 \pi i}{4}}$ . How can I go about calculating these residues? I know that it's the coefficient of $z^{-1}$ the Laurent series at $\alpha$ , or also $\frac{1}{2 \pi i} \oint_{\partial D(\alpha, r)} \frac{z e^{iz}}{1+z^4} dz$ . I'm struggling to calculate either of these. What do I do?","I am trying to compute This question has been asked here , but the asker and answerer skip over the calculation of the residues. Define the curve to be the semicircle in the top half plane with radius and straight edge on the real axis from to . Then by the residue theorem and Jordan's lemma, taking , I know that The relevant roots are . How can I go about calculating these residues? I know that it's the coefficient of the Laurent series at , or also . I'm struggling to calculate either of these. What do I do?","\int_{-\infty}^{\infty} \frac{x \sin x}{1+x^4}dx \gamma R -R R R \to \infty \int_{-\infty}^{\infty} \frac{z e^{iz}}{1+z^4}dz = \oint_{\gamma} \frac{ze^{iz}}{1+z^4} dz = 2 \pi i \sum_{\alpha \text{ roots of } 1+z^4, \Im(\alpha)>0} \text{Res}\left(\frac{z e^{iz}}{1+z^4}, \alpha \right) \alpha=e^{\frac{\pi i}{4}}, e^{\frac{3 \pi i}{4}} z^{-1} \alpha \frac{1}{2 \pi i} \oint_{\partial D(\alpha, r)} \frac{z e^{iz}}{1+z^4} dz","['integration', 'complex-analysis', 'analysis', 'improper-integrals', 'contour-integration']"
71,How to perform the parameterization of the following figure?,How to perform the parameterization of the following figure?,,"This topic has been a bit tedious for me but in my attempt I found a possible complex function that represents this trajectory is: z(t) = (2i - 4i t) u(t) + (2r t) u(t-1/2) + (-2ir + (2r-ir) (t-1)) u(t-1) Where u(t) is the Heaviside unit step function. This complex function is divided into two parts to represent the two curves of the trajectory: The first part (2i - 4i t) u(t) + (2r t) u(t-1/2) represents the curve that starts from the negative ""Y"" axis at the point "" $-2ir$ "", goes to the axis ""X"" at the "" $2r$ "" point and then goes to the positive y axis at the ""2ir"" point. The Heaviside unit step function is used to ensure that the first part of the function is only evaluated on the interval [0, 1] . The second part (-2ir + (2r-ir) (t-1)) u(t-1) represents the smallest curve that starts at the point ""ir"", goes to the ""X"" axis at the point "" $r$ "" and goes to the negative ""Y"" axis at the ""-ir"" point. The Heaviside unit step function is used to ensure that the second part of the function is only evaluated on the interval [1, 2] . The arrow that connects the end point of the second curve with the initial point of the first curve is represented by the discontinuity in the function at $t=1$ . I don't know if the above is a valid or correct answer, I appreciate everything you can correct.","This topic has been a bit tedious for me but in my attempt I found a possible complex function that represents this trajectory is: z(t) = (2i - 4i t) u(t) + (2r t) u(t-1/2) + (-2ir + (2r-ir) (t-1)) u(t-1) Where u(t) is the Heaviside unit step function. This complex function is divided into two parts to represent the two curves of the trajectory: The first part (2i - 4i t) u(t) + (2r t) u(t-1/2) represents the curve that starts from the negative ""Y"" axis at the point "" "", goes to the axis ""X"" at the "" "" point and then goes to the positive y axis at the ""2ir"" point. The Heaviside unit step function is used to ensure that the first part of the function is only evaluated on the interval [0, 1] . The second part (-2ir + (2r-ir) (t-1)) u(t-1) represents the smallest curve that starts at the point ""ir"", goes to the ""X"" axis at the point "" "" and goes to the negative ""Y"" axis at the ""-ir"" point. The Heaviside unit step function is used to ensure that the second part of the function is only evaluated on the interval [1, 2] . The arrow that connects the end point of the second curve with the initial point of the first curve is represented by the discontinuity in the function at . I don't know if the above is a valid or correct answer, I appreciate everything you can correct.",-2ir 2r r t=1,['complex-analysis']
72,How to find residue at $z=0$ for $f(z) = \frac{e^{1/z}}{z+a}$,How to find residue at  for,z=0 f(z) = \frac{e^{1/z}}{z+a},"Let $a \in \mathbb C$ be a complex number, and consider the function $$ f(z) = \frac{e^{1/z}}{z+a}$$ Compute the residues of $f(z)$ at each of its singularities. So I know there are singularities at $z=0$ and $z=-a$ , and I know $\text{Res}(f(z), z_0) = g(z_0) / h'(z_0)$ can be used for the singularity at $z=-a$ to find the residue to be $e^{-1/a}$ , but am not sure how to compute the residue at $z=0$ . Any help would be appreciated.","Let be a complex number, and consider the function Compute the residues of at each of its singularities. So I know there are singularities at and , and I know can be used for the singularity at to find the residue to be , but am not sure how to compute the residue at . Any help would be appreciated.","a \in \mathbb C  f(z) = \frac{e^{1/z}}{z+a} f(z) z=0 z=-a \text{Res}(f(z), z_0) = g(z_0) / h'(z_0) z=-a e^{-1/a} z=0","['complex-analysis', 'residue-calculus', 'singularity']"
73,Prove that the any Riemann surface of genus zero is isomorphic to the Riemann sphere,Prove that the any Riemann surface of genus zero is isomorphic to the Riemann sphere,,"Let $X$ be a compact Riemann surface, and suppose that there exists a meromorphic function $f$ on $X$ with one simple pole and no other poles. Show that $f$ is an isomorphism between $X$ and the Riemann sphere. Using this, prove that the any Riemann surface of genus zero is isomorphic to the Riemann sphere. Let $(f) = (P) - (Q)$ . Since the degree of $f$ is zero, it must be that $P \neq Q$ . I am not sure how I can prove that $f$ is surjective, other than the general instruction that I can use the Riemann-Roch theorem. I know that the sum of the divisor of any meromorphic function is equal to zero, and that for any divisor $K$ of $X$ , the degree of $K$ is equal to $2g - 2$ where $g$ is the genus. EDIT: Thanks to @DJ Dowd, I proved the second part: let $Q$ be any point in $X$ . Then $\dim L((Q)) \geq 2$ by Riemann Roch, so that there exists a nonconstant function $f \in L((Q))$ and it can be shown that $f$ can have only one simple zero and no other poles by using the fact that the degree of $f$ is zero. It remains to prove the first part. Because the function $f - c$ has a simple zero at $c = f(R)$ for arbitrary $R \in X$ , we have injectivity. Thus it remains to prove surjectivity.","Let be a compact Riemann surface, and suppose that there exists a meromorphic function on with one simple pole and no other poles. Show that is an isomorphism between and the Riemann sphere. Using this, prove that the any Riemann surface of genus zero is isomorphic to the Riemann sphere. Let . Since the degree of is zero, it must be that . I am not sure how I can prove that is surjective, other than the general instruction that I can use the Riemann-Roch theorem. I know that the sum of the divisor of any meromorphic function is equal to zero, and that for any divisor of , the degree of is equal to where is the genus. EDIT: Thanks to @DJ Dowd, I proved the second part: let be any point in . Then by Riemann Roch, so that there exists a nonconstant function and it can be shown that can have only one simple zero and no other poles by using the fact that the degree of is zero. It remains to prove the first part. Because the function has a simple zero at for arbitrary , we have injectivity. Thus it remains to prove surjectivity.",X f X f X (f) = (P) - (Q) f P \neq Q f K X K 2g - 2 g Q X \dim L((Q)) \geq 2 f \in L((Q)) f f f - c c = f(R) R \in X,"['complex-analysis', 'algebraic-geometry', 'riemann-surfaces', 'meromorphic-functions']"
74,Why is the Eisenstein series $G_2$ a quasimodular form?,Why is the Eisenstein series  a quasimodular form?,G_2,"For even $k \geq 4$ , the Eisenstein series \begin{align*} G_k(\tau) &=  \sum_{(n, m)\in \mathbb{Z}^2} \frac{1}{(m + n\tau)^k} \end{align*} (omitting the term $(n, m) = (0, 0)$ ) is a modular form of weight $k$ for $\Gamma = SL_2(\mathbb{Z})$ , and in fact the ring of modular forms of $\Gamma$ is just $\mathbb{C}[E_4, E_6]$ . The usual proof involving rearranging the double series over $n$ and $m$ , which fails to converge compactly for the case $k = 2$ . Still, $G_2$ is reasonably close to a modular form; it satisfies $G_2(-1/\tau) = \tau^2 G_2(\tau) + \alpha \tau$ for some constant $\alpha\not = 0$ , and the graded ring $M_* = \mathbb{C}[G_2, G_4, G_6]$ is closed under the operator $D \vert M_k = \frac{1}{2\pi i} \frac{d}{dq} + \beta k$ for some constant $\beta$ . All this is easy enough to prove directly, but is there some deeper reason why $G_2$ is a quasimodular form? That is, why is $G_2$ still very close to being a modular form despite the bad behavior of the series above for $k = 2$ ; or, conversely, why doesn't $\Gamma$ have any modular forms of weight $2$ despite having a reasonable candidate in $G_2$ ?","For even , the Eisenstein series (omitting the term ) is a modular form of weight for , and in fact the ring of modular forms of is just . The usual proof involving rearranging the double series over and , which fails to converge compactly for the case . Still, is reasonably close to a modular form; it satisfies for some constant , and the graded ring is closed under the operator for some constant . All this is easy enough to prove directly, but is there some deeper reason why is a quasimodular form? That is, why is still very close to being a modular form despite the bad behavior of the series above for ; or, conversely, why doesn't have any modular forms of weight despite having a reasonable candidate in ?","k \geq 4 \begin{align*}
G_k(\tau) &=  \sum_{(n, m)\in \mathbb{Z}^2} \frac{1}{(m + n\tau)^k}
\end{align*} (n, m) = (0, 0) k \Gamma = SL_2(\mathbb{Z}) \Gamma \mathbb{C}[E_4, E_6] n m k = 2 G_2 G_2(-1/\tau) = \tau^2 G_2(\tau) + \alpha \tau \alpha\not = 0 M_* = \mathbb{C}[G_2, G_4, G_6] D \vert M_k = \frac{1}{2\pi i} \frac{d}{dq} + \beta k \beta G_2 G_2 k = 2 \Gamma 2 G_2","['complex-analysis', 'analytic-number-theory', 'modular-forms']"
75,Hoffman - Definition of Blaschke product,Hoffman - Definition of Blaschke product,,"I am self-studying Banach Spaces of Analytic Functions by Hoffman. I have a question regarding the following theorem: According to the author, the set $K$ formed as in the theorem is compact. I do not see how. If we consider the $\alpha_n = 1/n$ for each $n \in \mathbb N$ then the Blaschke product makes sense because the $\prod_{n=1}^{\infty} 1/n = 0$ . However, the set $K$ formed out is $K=\mathbb N$ which is not compact. Is the author mistaken or am I doing something wrong?","I am self-studying Banach Spaces of Analytic Functions by Hoffman. I have a question regarding the following theorem: According to the author, the set formed as in the theorem is compact. I do not see how. If we consider the for each then the Blaschke product makes sense because the . However, the set formed out is which is not compact. Is the author mistaken or am I doing something wrong?",K \alpha_n = 1/n n \in \mathbb N \prod_{n=1}^{\infty} 1/n = 0 K K=\mathbb N,"['complex-analysis', 'hardy-spaces']"
76,Triply transitive action on upper half plane,Triply transitive action on upper half plane,,"I am calculating the area of a triangle in the upper half  plane. Consider the following triangle in the upper half plane with the Poincare metric. Can I transform this triangle to the following triangle via an element of $PSL(2, \mathbb{R})$ ? I have the above doubt. I think I can do this because $PSL(2, \mathbb{R})$ triple transitively on boundary of the upper half plane, which is $\Bbb R \cup \{ \infty \}$ . Am I correct?","I am calculating the area of a triangle in the upper half  plane. Consider the following triangle in the upper half plane with the Poincare metric. Can I transform this triangle to the following triangle via an element of ? I have the above doubt. I think I can do this because triple transitively on boundary of the upper half plane, which is . Am I correct?","PSL(2, \mathbb{R}) PSL(2, \mathbb{R}) \Bbb R \cup \{ \infty \}","['complex-analysis', 'solution-verification', 'hyperbolic-geometry']"
77,Use of Fubini's Theorem in Papa Rudin's Holomorphic Fourier Transforms,Use of Fubini's Theorem in Papa Rudin's Holomorphic Fourier Transforms,,"I am starting to read on chapter 19, Holomorphic Fourier Transforms from Real and Complex Analysis by Walter Rudin. In the first page of that chapter I came across the function $$f(z) = \int_0^\infty F(t)e^{itz} dt$$ where $z\in \mathbb{C}$ is in the upper half plane, $F\in L^2(\mathbb{R})$ and $F$ vanishes on $(-\infty, 0)$ . I want to prove that $f$ is analytic. I proved that $f$ is continuous in $\mathbb{C}$ . To prove that it is holomorphic, the author hints to use Morera's theorem, for which I have to show that for any closed path $\gamma$ in $\mathbb{C}$ , the integral $$\int_\gamma f(z) dz =0$$ My course of proof is to show \begin{align*}     \int_\gamma f(z)\ dz &= \int_\gamma \int_0^\infty F(t) e^{2\pi i t z} \ dt \ dz \\     & = \int_0^\infty F(t) \int_\gamma e^{2\pi itz} \ dz \ dt \\     & = \int_0^\infty F(t) \cdot 0 \ dt \\     & = 0   \end{align*} But I can't see how the use of Fubini's theorem is justified in the change of order of integration.","I am starting to read on chapter 19, Holomorphic Fourier Transforms from Real and Complex Analysis by Walter Rudin. In the first page of that chapter I came across the function where is in the upper half plane, and vanishes on . I want to prove that is analytic. I proved that is continuous in . To prove that it is holomorphic, the author hints to use Morera's theorem, for which I have to show that for any closed path in , the integral My course of proof is to show But I can't see how the use of Fubini's theorem is justified in the change of order of integration.","f(z) = \int_0^\infty F(t)e^{itz} dt z\in \mathbb{C} F\in L^2(\mathbb{R}) F (-\infty, 0) f f \mathbb{C} \gamma \mathbb{C} \int_\gamma f(z) dz =0 \begin{align*}
    \int_\gamma f(z)\ dz &= \int_\gamma \int_0^\infty F(t) e^{2\pi i t z} \ dt \ dz \\
    & = \int_0^\infty F(t) \int_\gamma e^{2\pi itz} \ dz \ dt \\
    & = \int_0^\infty F(t) \cdot 0 \ dt \\
    & = 0
  \end{align*}","['real-analysis', 'complex-analysis', 'measure-theory', 'fourier-analysis', 'fourier-transform']"
78,"Expand $\cos^a x$ in terms of $\cos kx$, $\sin mx$","Expand  in terms of ,",\cos^a x \cos kx \sin mx,"If $a\geq 0$ , expand $\cos^a x$ in terms of $\cos kx$ , $\sin mx$ $$\cos^a x=\left(\frac{e^{ix}+e^{-ix}}2\right)^a$$ Since $a$ is a non negative real number, so by General Binomial theorem $$\cos^a x=\frac1{2^a}\sum_{k=0}^\infty\binom ake^{ikx}e^{-i(a-k)x}$$ where $\binom ak=a(a-1)(a-2)...(a-k+1)$ $$\cos^a x=\frac1{2^a}\sum_{k=0}^\infty\binom ake^{i(2k-a)x}$$ Any help would be appreciated.","If , expand in terms of , Since is a non negative real number, so by General Binomial theorem where Any help would be appreciated.",a\geq 0 \cos^a x \cos kx \sin mx \cos^a x=\left(\frac{e^{ix}+e^{-ix}}2\right)^a a \cos^a x=\frac1{2^a}\sum_{k=0}^\infty\binom ake^{ikx}e^{-i(a-k)x} \binom ak=a(a-1)(a-2)...(a-k+1) \cos^a x=\frac1{2^a}\sum_{k=0}^\infty\binom ake^{i(2k-a)x},"['real-analysis', 'complex-analysis', 'trigonometry', 'complex-numbers', 'binomial-theorem']"
79,Uniqueness of trigonometric functions from functional equation,Uniqueness of trigonometric functions from functional equation,,"Take the functional equation $$f(x+y)=f(x)f(y).$$ This is a variation on the Cauchy equation, and we know that it has a unique continuous solution over the real numbers $$f(x)=e^{\alpha x}.$$ We then look at the pair of equations $$u(x+y)=u(x)u(y)-v(x)v(y),$$ $$v(x+y)=v(x)u(y)+u(x)v(y).$$ Moving over to complex numbers and setting $f(z)=u(z)+iv(z)$ , this becomes the exponential equation above. Fixing that $u,v$ are real for real arguments fixes the trigonometric functions, $$u(x)=e^{\alpha x}\cos\beta x,\quad v(x)=e^{\alpha x}\sin\beta x$$ as defined via complex exponentials. Further specifying a bounded image gives us what we need. So the trig functions must be the only continuous bounded solutions to the pair of equations above. Specifying that it's just bounded is probably enough, actually, given the Cauchy-ness involved. Can this uniqueness be established by working solely over the reals? Preferably just by elementary methods. It doesn't need to be established that $\cos x=\Re e^{ix}$ , for example. EDIT: A possible direction assuming continuity could be the following. As pointed out by an answer below, we can focus only on solutions for which $u^2+v^2=1$ . With that in mind, what would be interesting to show is that given two nontrivial continuous solutions $(u_1,v_1)$ and $(u_2,v_2)$ , we must have $$u_2(x)=u_1(\alpha x),$$ $$v_2(x)=v_1(\alpha x),$$ where $$\alpha=\lim_{x\rightarrow0}\frac{v_2(x)}{v_1(x)},$$ provided of course that we can show this limit exists.","Take the functional equation This is a variation on the Cauchy equation, and we know that it has a unique continuous solution over the real numbers We then look at the pair of equations Moving over to complex numbers and setting , this becomes the exponential equation above. Fixing that are real for real arguments fixes the trigonometric functions, as defined via complex exponentials. Further specifying a bounded image gives us what we need. So the trig functions must be the only continuous bounded solutions to the pair of equations above. Specifying that it's just bounded is probably enough, actually, given the Cauchy-ness involved. Can this uniqueness be established by working solely over the reals? Preferably just by elementary methods. It doesn't need to be established that , for example. EDIT: A possible direction assuming continuity could be the following. As pointed out by an answer below, we can focus only on solutions for which . With that in mind, what would be interesting to show is that given two nontrivial continuous solutions and , we must have where provided of course that we can show this limit exists.","f(x+y)=f(x)f(y). f(x)=e^{\alpha x}. u(x+y)=u(x)u(y)-v(x)v(y), v(x+y)=v(x)u(y)+u(x)v(y). f(z)=u(z)+iv(z) u,v u(x)=e^{\alpha x}\cos\beta x,\quad v(x)=e^{\alpha x}\sin\beta x \cos x=\Re e^{ix} u^2+v^2=1 (u_1,v_1) (u_2,v_2) u_2(x)=u_1(\alpha x), v_2(x)=v_1(\alpha x), \alpha=\lim_{x\rightarrow0}\frac{v_2(x)}{v_1(x)},","['real-analysis', 'complex-analysis', 'functional-equations']"
80,"Ash & Novinger - Complex Variables - Defining a continuous argument, walking around the unit circle","Ash & Novinger - Complex Variables - Defining a continuous argument, walking around the unit circle",,"I am self studying Ash & Novinger's Complex Variables. Before I present my question, here's a definition: Let $S \subset \mathbb C$ and $f : S \to \mathbb C \setminus \{ 0 \}$ be continuous. A function $\theta : S \to \mathbb R$ is said to be a continuous argument of $f$ if $\theta$ is continuous on $S$ and $f(s)=\lvert f(s) \rvert e^{i\theta (s)}$ for each $s \in S$ . In Example 3.1.5 (c) , the authors claim that $f : \{ z : \lvert z \rvert =1 \} \to \mathbb C$ does not have a continuous argument. They initially present a very handwavy argument and postpone its proof after they develop the necessary tools to prove it. Here's how the ""handwavy proof"" goes: The intuition underlying the above example is that if we walk entirely around the unit circle, a continuous argument of $z$ must change by $2\pi$ . Thus the argument of $z$ must abruptly jump by $2\pi$ at the end of the trip, which contradicts continuity. Since this is handwavy, I accept it. Later, they go on to prove that: If $\gamma : [a,b] \to \mathbb C \setminus \{ 0 \}$ is continuous, then $\gamma$ has a continuous argument. I read the proof of this, it seems perfectly fine. In particular if I consider $\gamma : [0, 2\pi] \to \mathbb C$ given by $\gamma(t)=e^{it}$ is a ""zerofree"" continuous function and by the above theorem has a continuous argument. This seems a little counterintuitive to me. The images of $f$ and $\gamma$ are the same. How does the ""handwavy"" walking around the unit circle fail in this case?","I am self studying Ash & Novinger's Complex Variables. Before I present my question, here's a definition: Let and be continuous. A function is said to be a continuous argument of if is continuous on and for each . In Example 3.1.5 (c) , the authors claim that does not have a continuous argument. They initially present a very handwavy argument and postpone its proof after they develop the necessary tools to prove it. Here's how the ""handwavy proof"" goes: The intuition underlying the above example is that if we walk entirely around the unit circle, a continuous argument of must change by . Thus the argument of must abruptly jump by at the end of the trip, which contradicts continuity. Since this is handwavy, I accept it. Later, they go on to prove that: If is continuous, then has a continuous argument. I read the proof of this, it seems perfectly fine. In particular if I consider given by is a ""zerofree"" continuous function and by the above theorem has a continuous argument. This seems a little counterintuitive to me. The images of and are the same. How does the ""handwavy"" walking around the unit circle fail in this case?","S \subset \mathbb C f : S \to \mathbb C \setminus \{ 0 \} \theta : S \to \mathbb R f \theta S f(s)=\lvert f(s) \rvert e^{i\theta (s)} s \in S f : \{ z : \lvert z \rvert =1 \} \to \mathbb C z 2\pi z 2\pi \gamma : [a,b] \to \mathbb C \setminus \{ 0 \} \gamma \gamma : [0, 2\pi] \to \mathbb C \gamma(t)=e^{it} f \gamma",['complex-analysis']
81,Extending holomorphic function on punctured plane to Riemann sphere,Extending holomorphic function on punctured plane to Riemann sphere,,"I have a holomorphic function $f: \mathbb{C} \setminus \{0\} \rightarrow \mathbb{C}$ , and I wish to extend $f$ to a holomorphic function $\tilde{f}: \widehat{\mathbb{C} \setminus \{0\} } \rightarrow \hat{\mathbb{C}}$ where $\widehat{\mathbb{C} \setminus \{0\} }$ is homeomorphic to the Riemann sphere by adding two points at infinity. I believe that it suffices to determine where these two points at infinity go, so it seems that I should map both of them to $\infty$ in $\hat{\mathbb{C}}$ . (In the more specific context of the problem I'm working on, I also have to show that $\tilde{f}$ is a double branched cover.) However, I'm struggling to show that $\tilde{f}$ is holomorphic that at these two points at infinity. I've tried computing the derivative directly by definition, but I'm running to issues involving arithmetic with $\infty$ . Please let me know in the comments if you need the complete context of the problem in case this is not enough information.","I have a holomorphic function , and I wish to extend to a holomorphic function where is homeomorphic to the Riemann sphere by adding two points at infinity. I believe that it suffices to determine where these two points at infinity go, so it seems that I should map both of them to in . (In the more specific context of the problem I'm working on, I also have to show that is a double branched cover.) However, I'm struggling to show that is holomorphic that at these two points at infinity. I've tried computing the derivative directly by definition, but I'm running to issues involving arithmetic with . Please let me know in the comments if you need the complete context of the problem in case this is not enough information.",f: \mathbb{C} \setminus \{0\} \rightarrow \mathbb{C} f \tilde{f}: \widehat{\mathbb{C} \setminus \{0\} } \rightarrow \hat{\mathbb{C}} \widehat{\mathbb{C} \setminus \{0\} } \infty \hat{\mathbb{C}} \tilde{f} \tilde{f} \infty,['complex-analysis']
82,"Ash & Novinger - Complex Variables - Exercise 2.4.1, possibly dealing with identity theorem","Ash & Novinger - Complex Variables - Exercise 2.4.1, possibly dealing with identity theorem",,"I am self-studying Ash & Novinger's Complex Variables. In Exercise 2.4.1 (Page 26) the authors ask the following exercise: Give an example of nonconstant, analytic function $f$ on a region $\Omega$ such that $f$ has a limit point of zeroes at a point outside $\Omega$ . It is immediate to see that the function $f: \mathbb C \setminus \{ 0 \} \to \mathbb C$ given by $f(z)=\sin (\frac{\pi}{z})$ has zeros at $1/k$ for each $k \in \mathbb N$ . However, the limit of the sequence whose terms are $1/k$ is $0$ does not belong to the domain. But, I think the authors are trying to illustrate something here. Does it have something to do with the identity theorem? In this case the zero set of $f$ consists elements of the form $1/k$ where $k \in \mathbb Z \setminus \{ 0 \}$ . So the zero set of $f$ does not contain any limit points of $\mathbb C \setminus \{ 0 \}$ . But then the identity theorem has nothing to do here. What exactly are the authors trying to illustrate here?","I am self-studying Ash & Novinger's Complex Variables. In Exercise 2.4.1 (Page 26) the authors ask the following exercise: Give an example of nonconstant, analytic function on a region such that has a limit point of zeroes at a point outside . It is immediate to see that the function given by has zeros at for each . However, the limit of the sequence whose terms are is does not belong to the domain. But, I think the authors are trying to illustrate something here. Does it have something to do with the identity theorem? In this case the zero set of consists elements of the form where . So the zero set of does not contain any limit points of . But then the identity theorem has nothing to do here. What exactly are the authors trying to illustrate here?",f \Omega f \Omega f: \mathbb C \setminus \{ 0 \} \to \mathbb C f(z)=\sin (\frac{\pi}{z}) 1/k k \in \mathbb N 1/k 0 f 1/k k \in \mathbb Z \setminus \{ 0 \} f \mathbb C \setminus \{ 0 \},['complex-analysis']
83,Trying to do integration using residue theorem,Trying to do integration using residue theorem,,"prove using residue theorem $$\int_{0}^{2\pi}\frac{\cos2\theta}{5+4\cos\theta}d\theta={\pi}/6$$ I tried by using $$z=e^{i\theta}$$ now $$\cos\theta=\frac{e^{i\theta}+e^{-i\theta}}{2}=\frac{z+z^{-1}}{2}$$ $$dz=izd\theta$$ $$\int_{0}^{2\pi}\frac{\cos2\theta}{5+4\cos\theta}d\theta=\int_{0}^{2\pi}\frac{2\cos^2\theta-1}{5+4\cos\theta}d\theta=\int_{|z|=1}\frac{(z^4+1)dz}{2iz^2(2z+1)(z+2)}$$ Now poles occur at $$z=0, -1/2, -2$$ rejecting $$z=-2,$$ as $$ |z|=2>1$$ Now $$Res_{z=-1/2}=\frac{(-1/2)^4+1)}{2i(-1/2)^2(-1/2+2)}=17/12i$$ Pole at z=0 is  of order 2 $$Res_{z=0}=\lim_{z \to 0} \frac{d}{dz}(\frac{(z^4+1)}{2i(2z+1)(z+2)})=-5/8i$$ $$\int_{0}^{2\pi}\frac{\cos2\theta}{5+4\cos\theta}d\theta={2\pi}i(Res_{z=-1/2}+Res_{z=0})=19{\pi}/12$$ But the answer is $${\pi}/6$$ I tried many times, but i get the same answer","prove using residue theorem I tried by using now Now poles occur at rejecting as Now Pole at z=0 is  of order 2 But the answer is I tried many times, but i get the same answer","\int_{0}^{2\pi}\frac{\cos2\theta}{5+4\cos\theta}d\theta={\pi}/6 z=e^{i\theta} \cos\theta=\frac{e^{i\theta}+e^{-i\theta}}{2}=\frac{z+z^{-1}}{2} dz=izd\theta \int_{0}^{2\pi}\frac{\cos2\theta}{5+4\cos\theta}d\theta=\int_{0}^{2\pi}\frac{2\cos^2\theta-1}{5+4\cos\theta}d\theta=\int_{|z|=1}\frac{(z^4+1)dz}{2iz^2(2z+1)(z+2)} z=0, -1/2, -2 z=-2,  |z|=2>1 Res_{z=-1/2}=\frac{(-1/2)^4+1)}{2i(-1/2)^2(-1/2+2)}=17/12i Res_{z=0}=\lim_{z \to 0} \frac{d}{dz}(\frac{(z^4+1)}{2i(2z+1)(z+2)})=-5/8i \int_{0}^{2\pi}\frac{\cos2\theta}{5+4\cos\theta}d\theta={2\pi}i(Res_{z=-1/2}+Res_{z=0})=19{\pi}/12 {\pi}/6","['complex-analysis', 'definite-integrals', 'residue-calculus']"
84,Imaginary part of dilogarithm,Imaginary part of dilogarithm,,"I have evaluated a certain real-valued, finite integral with no general elementary solution, but which I have been able to prove equals the imaginary part of some dilogarithms and can write in the form $\Im{\left(\operatorname{Li_2}\left(r\cdot e^{i\theta}\right)\right)}=\tfrac{1}{2i}\left({\operatorname{Li_2}\left(r\cdot e^{i\theta}\right)}-{\operatorname{Li_2}\left(r\cdot e^{-i\theta}\right)}\right)$ similar to the integral in this question and where we can assume $r≥0$ and $0<\theta<\pi$ . Since the input variables are real-valued and the answer is real-valued, I'd prefer a solution that avoids intermediate complex notation while at the same time keeping the underlying integral/series implicit.  I'm aware of some ""trivial"" solutions: $\lim\limits_{\theta \to 0^+}\Im{\left(\operatorname{Li_2}\left(r\cdot e^{i\theta}\right)\right)}=\begin{cases}0 & \text{if } r≤1\\ \pi\log{(r)} & \text{if } r>1\end{cases}$ $\Im{\left(\operatorname{Li_2}\left(r\cdot e^{i\pi/2}\right)\right)}=\operatorname{Ti_2}\left(r\right)$ $\Im{\left(\operatorname{Li_2}\left(1\cdot e^{i\theta}\right)\right)}=\operatorname{Cl_2}\left(\theta\right)$ Is it possible to separate $r$ and $\theta$ more generically?  That is to say, I prefer to write the solution in terms like the inverse tangent integral $\operatorname{Ti_2}\left(r\right)$ or the Clausen function $\operatorname{Cl_2}\left(\theta\right)$ where the arguments stay real-valued.  It is also acceptable to use other related functions such as the trigamma function, zeta functions, or even the original dilogarithm with real argument, as long as you don't get more abstract like hypergeometric functions. If not generically, are there particular values of $\theta$ where this is possible such as at angles that are rational numbers times $\pi$ ? $\theta=\pi/3$ or $2\pi/5$ or $\pi/4$ for instance?  I suppose this is my main goal, to get a function of $r$ for certain fixed $\theta$ other than $0$ and $\pi/2$ . If it helps, you can restrict your answer to $0≤r≤1$ or smaller and $0<\theta<\pi/2$ .  Can you extend your answer to $\left|\Re{\left(r\cdot e^{i\theta}\right)}\right|≤1$ ?  Can you extend it all the way to $0≤r≤2$ or more? See also a related question about the real part .","I have evaluated a certain real-valued, finite integral with no general elementary solution, but which I have been able to prove equals the imaginary part of some dilogarithms and can write in the form similar to the integral in this question and where we can assume and . Since the input variables are real-valued and the answer is real-valued, I'd prefer a solution that avoids intermediate complex notation while at the same time keeping the underlying integral/series implicit.  I'm aware of some ""trivial"" solutions: Is it possible to separate and more generically?  That is to say, I prefer to write the solution in terms like the inverse tangent integral or the Clausen function where the arguments stay real-valued.  It is also acceptable to use other related functions such as the trigamma function, zeta functions, or even the original dilogarithm with real argument, as long as you don't get more abstract like hypergeometric functions. If not generically, are there particular values of where this is possible such as at angles that are rational numbers times ? or or for instance?  I suppose this is my main goal, to get a function of for certain fixed other than and . If it helps, you can restrict your answer to or smaller and .  Can you extend your answer to ?  Can you extend it all the way to or more? See also a related question about the real part .",\Im{\left(\operatorname{Li_2}\left(r\cdot e^{i\theta}\right)\right)}=\tfrac{1}{2i}\left({\operatorname{Li_2}\left(r\cdot e^{i\theta}\right)}-{\operatorname{Li_2}\left(r\cdot e^{-i\theta}\right)}\right) r≥0 0<\theta<\pi \lim\limits_{\theta \to 0^+}\Im{\left(\operatorname{Li_2}\left(r\cdot e^{i\theta}\right)\right)}=\begin{cases}0 & \text{if } r≤1\\ \pi\log{(r)} & \text{if } r>1\end{cases} \Im{\left(\operatorname{Li_2}\left(r\cdot e^{i\pi/2}\right)\right)}=\operatorname{Ti_2}\left(r\right) \Im{\left(\operatorname{Li_2}\left(1\cdot e^{i\theta}\right)\right)}=\operatorname{Cl_2}\left(\theta\right) r \theta \operatorname{Ti_2}\left(r\right) \operatorname{Cl_2}\left(\theta\right) \theta \pi \theta=\pi/3 2\pi/5 \pi/4 r \theta 0 \pi/2 0≤r≤1 0<\theta<\pi/2 \left|\Re{\left(r\cdot e^{i\theta}\right)}\right|≤1 0≤r≤2,"['complex-analysis', 'closed-form', 'polylogarithm']"
85,"If we have an open set $S$ and multiply every element of $S$ by a fixed complex number $z_{0}$, is the resultant set open?","If we have an open set  and multiply every element of  by a fixed complex number , is the resultant set open?",S S z_{0},"Suppose S in a complex open set with elements $s \in \mathbb{C}$ , if we multiply all elements by a fixed complex number $z_0$ , will the resultant set be open as well? My intuition says yes, as multiplying a given open set geometrically has the effect of rotating and stretching the area defined by the set, so this new area should also be open. I am just not sure how I would go about proving it. Any help would be appreciated. EDIT: As some have pointed out the constraint on $z_0$ is that it is non-zero.","Suppose S in a complex open set with elements , if we multiply all elements by a fixed complex number , will the resultant set be open as well? My intuition says yes, as multiplying a given open set geometrically has the effect of rotating and stretching the area defined by the set, so this new area should also be open. I am just not sure how I would go about proving it. Any help would be appreciated. EDIT: As some have pointed out the constraint on is that it is non-zero.",s \in \mathbb{C} z_0 z_0,['complex-analysis']
86,Degree of a polynomial injective on complex upper half plane,Degree of a polynomial injective on complex upper half plane,,"I'm trying to solve the following problem. Any polynomial function injective on the upper half plane has degree less than or equal to 2. This seems intuitively true, since polynomial of degree $n$ will approximately be an $n$ fold covering map. However I have no idea how to prove it explictely. I tried to show that polynomial of degree > 2 is not injective by finding two points having the same value, but it didn't work well. Any idea for this one?","I'm trying to solve the following problem. Any polynomial function injective on the upper half plane has degree less than or equal to 2. This seems intuitively true, since polynomial of degree will approximately be an fold covering map. However I have no idea how to prove it explictely. I tried to show that polynomial of degree > 2 is not injective by finding two points having the same value, but it didn't work well. Any idea for this one?",n n,['complex-analysis']
87,Prove/Disprove $f(z)=0$ if and only if $z=0$ for a power series $f$ about the centre $0$ having radius of convergence $2$,Prove/Disprove  if and only if  for a power series  about the centre  having radius of convergence,f(z)=0 z=0 f 0 2,"Q. Let $f(z)$ be a power-series (with complex coefficients) centred at $0 \in \mathbb{C}$ and with a radius of convergence $2$ . Suppose that $f(0)=0$ . Choose the correct statement(s) from below: (A) $f^{-1}(0)=\{0\}$ (B) If $f$ is a non-constant function on $\{z \in \Bbb C~:~|z|<2\}$ , then $f^{-1}(0)=\{0\}$ ; (C) If $f$ is a non-constant function, then for all $\zeta \in \Bbb C$ with sufficiently small $|\zeta|$ , the equation $f(z)=\zeta$ has a solution; (D) $\int_\gamma f^{(n)}(z) d z=0$ for every $n \geq 1$ , where $\gamma$ is a unit circle centred at $0$ , oriented clockwise, and $f^{(n)}$ is the $n^{\text{th}}$ derivative of $f(z)$ . How can I confirm $f(z)=0$ if and only if $z=0$ , in the geometric series $\sum_{n=1}^\infty 2^{-n}z^n$ , I got first option is true, but how to generalize. Option D says all the coefficients of the terms is zero, I feel it is impossible.","Q. Let be a power-series (with complex coefficients) centred at and with a radius of convergence . Suppose that . Choose the correct statement(s) from below: (A) (B) If is a non-constant function on , then ; (C) If is a non-constant function, then for all with sufficiently small , the equation has a solution; (D) for every , where is a unit circle centred at , oriented clockwise, and is the derivative of . How can I confirm if and only if , in the geometric series , I got first option is true, but how to generalize. Option D says all the coefficients of the terms is zero, I feel it is impossible.",f(z) 0 \in \mathbb{C} 2 f(0)=0 f^{-1}(0)=\{0\} f \{z \in \Bbb C~:~|z|<2\} f^{-1}(0)=\{0\} f \zeta \in \Bbb C |\zeta| f(z)=\zeta \int_\gamma f^{(n)}(z) d z=0 n \geq 1 \gamma 0 f^{(n)} n^{\text{th}} f(z) f(z)=0 z=0 \sum_{n=1}^\infty 2^{-n}z^n,"['real-analysis', 'complex-analysis']"
88,Why is the derivative of the real absolute squared different to complex absolute squared,Why is the derivative of the real absolute squared different to complex absolute squared,,"I know that for $x \in \mathbb{R}$ there is $$ \frac{\mathrm{d}}{\mathrm{d}x} |x|^2 = 2|x| \frac{\mathrm{d}}{\mathrm{d}x} |x| = 2|x| \frac{x}{|x|} = 2x $$ Which makes sense because $|x|^2 = x^2$ , but for $z\in\mathbb{C}$ there is $$ \frac{\partial}{\partial z} |z|^2 = \frac{\partial}{\partial z} (z\overline{z}) = \frac{\partial z}{\partial z} \overline{z} + \frac{\partial\overline{z}}{\partial z}z = \overline{z} $$ Both makes sense on their own but shouldn’t they agree on the real part? Why are these two different? This leads to the second part: which one should I use for $$ \frac{\partial}{\partial f_j} |\langle f_j,f_k \rangle|^2$$ Or does it depend on whether the inner product space is complex or real?","I know that for there is Which makes sense because , but for there is Both makes sense on their own but shouldn’t they agree on the real part? Why are these two different? This leads to the second part: which one should I use for Or does it depend on whether the inner product space is complex or real?","x \in \mathbb{R}  \frac{\mathrm{d}}{\mathrm{d}x} |x|^2 = 2|x| \frac{\mathrm{d}}{\mathrm{d}x} |x| = 2|x| \frac{x}{|x|} = 2x  |x|^2 = x^2 z\in\mathbb{C}  \frac{\partial}{\partial z} |z|^2 = \frac{\partial}{\partial z} (z\overline{z}) = \frac{\partial z}{\partial z} \overline{z} + \frac{\partial\overline{z}}{\partial z}z = \overline{z}   \frac{\partial}{\partial f_j} |\langle f_j,f_k \rangle|^2","['calculus', 'complex-analysis', 'inner-products', 'absolute-value']"
89,Cauchy principal value: methods,Cauchy principal value: methods,,"I don't understand yet the logic in the Cauchy Principale Value (P.V.) calculations. Let the resideu theorem: $$\color{red}{\oint_Cf(z) \ dz = 2\pi i \sum_{k=1}^n \underset{z=z_k}{Res}\{f(z)\}}$$ (we supposed that $C$ was a ""nice"" closed curb and $f(z)$ analytical $\forall z \in \mathrm{int} \ C$ except in $z_k$ ( $1 \le k \le n$ )) I've got 2 poorly justified examples in my exercice book (forgive me for non-mathjaxing all of that follows) : Apparently, the corrector found a nice closed curb, but don't want to share how he did it. Usually, when $f(z)$ is pair, we can define such a $C$ curb: but it doesn't explain why the 2 factor is missing in the answer . Why $\pi i$ instead of $2\pi i$ ? Second example: $$P.V. \int_{-\infty}^{+\infty} \frac{\exp(-4ix)}{(x+i)^2} \ dx$$ Here, we have a reversed cup (why reversed ?) $\gamma (R)$ with the segment $C(R)$ : Again, I don't understand what has been done. Is there a general methode I can understand to solve those 2 exercices ? EDIT : corrected one error pointed out in the comments ( $(x+i)^2$ instead of $(x+1)^2$ )","I don't understand yet the logic in the Cauchy Principale Value (P.V.) calculations. Let the resideu theorem: (we supposed that was a ""nice"" closed curb and analytical except in ( )) I've got 2 poorly justified examples in my exercice book (forgive me for non-mathjaxing all of that follows) : Apparently, the corrector found a nice closed curb, but don't want to share how he did it. Usually, when is pair, we can define such a curb: but it doesn't explain why the 2 factor is missing in the answer . Why instead of ? Second example: Here, we have a reversed cup (why reversed ?) with the segment : Again, I don't understand what has been done. Is there a general methode I can understand to solve those 2 exercices ? EDIT : corrected one error pointed out in the comments ( instead of )",\color{red}{\oint_Cf(z) \ dz = 2\pi i \sum_{k=1}^n \underset{z=z_k}{Res}\{f(z)\}} C f(z) \forall z \in \mathrm{int} \ C z_k 1 \le k \le n f(z) C \pi i 2\pi i P.V. \int_{-\infty}^{+\infty} \frac{\exp(-4ix)}{(x+i)^2} \ dx \gamma (R) C(R) (x+i)^2 (x+1)^2,"['integration', 'complex-analysis']"
90,"Laplace transforms of Appell functions F1, F2, F3, F4 relative to one of the two variables","Laplace transforms of Appell functions F1, F2, F3, F4 relative to one of the two variables",,"Appell's two-variable functions $F_1, F_2, F_3$ and $F_4$ are known to have numerous uses in applied mathematics, notably mathematical Physics. I am looking for generalized Laplace transforms (if they exist) of these functions relative to one of the two variables (I found at least two references that give some of them relative to a linear combination of the two variables). In more formal words, the question is about finding closed forms for: $$ I_1 = \int_0^\infty x^\alpha e^{-s \, x} F_{1}(a, b, c, d; x, y) \, dx$$ $$ I_2 = \int_0^\infty x^\alpha e^{-s \, x} F_{2}(a, b, c, d, e; x, y) \, dx$$ $$ I_3 = \int_0^\infty x^\alpha e^{-s \, x} F_{3}(a, b, c, d, e; x, y) \, dx$$ $$ I_4 = \int_0^\infty x^\alpha e^{-s \, x} F_{4}(a, b, c, d; x, y) \, dx,$$ where $\alpha, s, a, b, c, d, e$ are the parameters and $x, y$ the variables. The only reliable hint I could find is in Harold Exton's handbook ([2]), where Exton gives a method for finding the Laplace transform of $F_1$ using Mellin-Barnes integral representations of $F_1$ . Unfortunately, he did not complete the argument: ""page 99: (...) We make use of the double Barnes integral for the Appell function F1 given by Appell and Kampé de Fériet (1926p page 40. This is $$F_1(a,b,b',c;x,y) = \frac{\Gamma(c)}{(2 \pi i)^2 \Gamma(a) \Gamma(b) \Gamma(b')} \int_{-i \infty}^{i \infty}\int_{-i \infty}^{i \infty} \frac{\Gamma(a+u+v)\Gamma(b+u)\Gamma(b'+v)\Gamma(-u)\Gamma(-v)(-x)^u (-y )^v}{\Gamma(c+u+v)} \, du \, dv$$ (5.2.4.26) Some indication is now given as to the evaluation of the Laplace integral of the function $F_1$ [Exton proceeds, interchanging the order of integration and evaluating the inner integral as a gamma function, which gives:] $$P = \frac{(2 \pi i)^2 \Gamma(c) \Gamma(d) \Gamma(d')}{\Gamma(f)} \int_0^{\infty} e^{-s\, t} t^{a-1} F_1(c, d, d', f; xt, yt) \, dt \, \\=  \frac{\Gamma(a)}{s^a} \ \int_{-i \infty}^{i \infty}\int_{-i \infty}^{i \infty} \frac{\Gamma(c+u+v) \Gamma(a+u+v) \Gamma(d+u) \Gamma(d'+v) \Gamma(-u) \Gamma(-v) (-x)^u (-y )^v}{\Gamma(f+u+v)} (-\frac{x}{s})^u (-\frac{y}{s})^v\, du \, dv$$ (5.2.4.28) In order to obtain a representation of this last result in terms of convergent series, the above integral may be written as an integral of Barnes type of a [Meijer] G-function of one variable. Some rather lengthy manipulation eventually leads to the sum of six double hypergeometric series of higher order with argument $s/x$ and $s/y$ . Exton did not give the six series alluded to but only special cases of interest expressed using Kampé de Feriet functions or generalized hypergeometric functions of one variable. He also only considered the case in which both function variables $x$ and $y$ are linked to the Laplace transform by the same integration variable $t$ , but his method is obviously valid if only one variable is linked (so with no $t$ as a multiplier of $y$ in $F_1(c, d, d', f; xt, y)$ for example). The method looks fine and I have looked around for whether there is any paper giving the forms (probably in Meijer-G representations), without success so far. In any case, series representations should not be used, except for heuristic hints: their domain of convergence is too limited for the Laplace transforms to be defined. But Euler-type integral representations and, as in Exton's book, Mellin-Barnes integral representations could be considered (as analytic continuations giving meaning to the Laplace transforms) or possibly expressions as a series of Gauss hypergeometric functions, since these can have Laplace transforms (see here ). Again, these may well have been published, but I failed to find anything that neatly answers the question. [2]: Exton, Harold , Handbook of hypergeometric integrals. Theory, applications, tables, computer programs, Mathematics & its Applications. Chichester: Ellis Horwood Limited Publishers. 316 p. (1978). ZBL0377.33001 .","Appell's two-variable functions and are known to have numerous uses in applied mathematics, notably mathematical Physics. I am looking for generalized Laplace transforms (if they exist) of these functions relative to one of the two variables (I found at least two references that give some of them relative to a linear combination of the two variables). In more formal words, the question is about finding closed forms for: where are the parameters and the variables. The only reliable hint I could find is in Harold Exton's handbook ([2]), where Exton gives a method for finding the Laplace transform of using Mellin-Barnes integral representations of . Unfortunately, he did not complete the argument: ""page 99: (...) We make use of the double Barnes integral for the Appell function F1 given by Appell and Kampé de Fériet (1926p page 40. This is (5.2.4.26) Some indication is now given as to the evaluation of the Laplace integral of the function [Exton proceeds, interchanging the order of integration and evaluating the inner integral as a gamma function, which gives:] (5.2.4.28) In order to obtain a representation of this last result in terms of convergent series, the above integral may be written as an integral of Barnes type of a [Meijer] G-function of one variable. Some rather lengthy manipulation eventually leads to the sum of six double hypergeometric series of higher order with argument and . Exton did not give the six series alluded to but only special cases of interest expressed using Kampé de Feriet functions or generalized hypergeometric functions of one variable. He also only considered the case in which both function variables and are linked to the Laplace transform by the same integration variable , but his method is obviously valid if only one variable is linked (so with no as a multiplier of in for example). The method looks fine and I have looked around for whether there is any paper giving the forms (probably in Meijer-G representations), without success so far. In any case, series representations should not be used, except for heuristic hints: their domain of convergence is too limited for the Laplace transforms to be defined. But Euler-type integral representations and, as in Exton's book, Mellin-Barnes integral representations could be considered (as analytic continuations giving meaning to the Laplace transforms) or possibly expressions as a series of Gauss hypergeometric functions, since these can have Laplace transforms (see here ). Again, these may well have been published, but I failed to find anything that neatly answers the question. [2]: Exton, Harold , Handbook of hypergeometric integrals. Theory, applications, tables, computer programs, Mathematics & its Applications. Chichester: Ellis Horwood Limited Publishers. 316 p. (1978). ZBL0377.33001 .","F_1, F_2, F_3 F_4  I_1 = \int_0^\infty x^\alpha e^{-s \, x} F_{1}(a, b, c, d; x, y) \, dx  I_2 = \int_0^\infty x^\alpha e^{-s \, x} F_{2}(a, b, c, d, e; x, y) \, dx  I_3 = \int_0^\infty x^\alpha e^{-s \, x} F_{3}(a, b, c, d, e; x, y) \, dx  I_4 = \int_0^\infty x^\alpha e^{-s \, x} F_{4}(a, b, c, d; x, y) \, dx, \alpha, s, a, b, c, d, e x, y F_1 F_1 F_1(a,b,b',c;x,y) = \frac{\Gamma(c)}{(2 \pi i)^2 \Gamma(a) \Gamma(b) \Gamma(b')} \int_{-i \infty}^{i \infty}\int_{-i \infty}^{i \infty} \frac{\Gamma(a+u+v)\Gamma(b+u)\Gamma(b'+v)\Gamma(-u)\Gamma(-v)(-x)^u (-y )^v}{\Gamma(c+u+v)} \, du \, dv F_1 P = \frac{(2 \pi i)^2 \Gamma(c) \Gamma(d) \Gamma(d')}{\Gamma(f)} \int_0^{\infty} e^{-s\, t} t^{a-1} F_1(c, d, d', f; xt, yt) \, dt \, \\=  \frac{\Gamma(a)}{s^a} \ \int_{-i \infty}^{i \infty}\int_{-i \infty}^{i \infty} \frac{\Gamma(c+u+v) \Gamma(a+u+v) \Gamma(d+u) \Gamma(d'+v) \Gamma(-u) \Gamma(-v) (-x)^u (-y )^v}{\Gamma(f+u+v)} (-\frac{x}{s})^u (-\frac{y}{s})^v\, du \, dv s/x s/y x y t t y F_1(c, d, d', f; xt, y)","['complex-analysis', 'laplace-transform', 'hypergeometric-function']"
91,Find all analytic functions $f: \mathbb{C} \backslash\{3\} \rightarrow \mathbb{C}$ such that $|f(z)| \leq \frac{\left|(z-2)^{2}\right|}{|z-3|}$,Find all analytic functions  such that,f: \mathbb{C} \backslash\{3\} \rightarrow \mathbb{C} |f(z)| \leq \frac{\left|(z-2)^{2}\right|}{|z-3|},"This is a question on one of my homework sheets for a complex function theory module on my maths MSc. I believe I need to use the Laurent series for $f(z)$ around 3 here, so I wrote $f(z)$ as: $$f\left(z\right)\ =\ \sum_{n=-\infty}^{\infty}a_n\left(z-3\right)^n$$ And then I used the integral representation of the coefficients: $$a_n=\frac{1}{2\pi i}\int_{S_p^+\left(3\right)}^{ }\frac{f\left(z\right)}{\left(z-3\right)^{n+1}}dz$$ So this would mean that we have: $$f\left(z\right)\ =\ \left|\sum_{n=-\infty}^{\infty}\left(\frac{1}{2\pi i}\int_{S_p^+\left(3\right)}^{ }\frac{f\left(z\right)}{\left(z-3\right)^{n+1}}dz\right)z^n\right|\le\frac{\left|\left(z-2\right)^2\right|}{\left|z-3\right|}$$ I somehow need to determine how many coefficients of the Laurent series are nonzero, but I'm kind of stuck on where to go next. I noticed that by Cauchy's nth Derivative Formula that, since $$f^n\left(3\right)=\frac{n!}{2\pi i}\int_{S_p^+\left(3\right)}^{ }\frac{f\left(z\right)}{\left(z-3\right)^{n+1}}dz$$ I guess that means we could write $a_n=\frac{f^n\left(3\right)}{n!}$ , but I don't know if that's helpful here.","This is a question on one of my homework sheets for a complex function theory module on my maths MSc. I believe I need to use the Laurent series for around 3 here, so I wrote as: And then I used the integral representation of the coefficients: So this would mean that we have: I somehow need to determine how many coefficients of the Laurent series are nonzero, but I'm kind of stuck on where to go next. I noticed that by Cauchy's nth Derivative Formula that, since I guess that means we could write , but I don't know if that's helpful here.",f(z) f(z) f\left(z\right)\ =\ \sum_{n=-\infty}^{\infty}a_n\left(z-3\right)^n a_n=\frac{1}{2\pi i}\int_{S_p^+\left(3\right)}^{ }\frac{f\left(z\right)}{\left(z-3\right)^{n+1}}dz f\left(z\right)\ =\ \left|\sum_{n=-\infty}^{\infty}\left(\frac{1}{2\pi i}\int_{S_p^+\left(3\right)}^{ }\frac{f\left(z\right)}{\left(z-3\right)^{n+1}}dz\right)z^n\right|\le\frac{\left|\left(z-2\right)^2\right|}{\left|z-3\right|} f^n\left(3\right)=\frac{n!}{2\pi i}\int_{S_p^+\left(3\right)}^{ }\frac{f\left(z\right)}{\left(z-3\right)^{n+1}}dz a_n=\frac{f^n\left(3\right)}{n!},"['complex-analysis', 'complex-integration', 'laurent-series', 'analytic-functions']"
92,How to take a Fourier transform of a $\text{sinc}$ function in the complex plane.,How to take a Fourier transform of a  function in the complex plane.,\text{sinc},"Full disclosure: This is technically a ""homework"" question but not really. What I mean is that my professor gave us free reign to use Mathematica to simply get the answer to the integral but I am trying to go the extra mile and understand the full derivation, but I'm stuck. The problem is solving the Laplace equation for a finite strip. The solution which I've already derived is: $$V(x,y)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{2\sin{k}}{k}e^{ikx}e^{-|k|y}dk\tag{1}$$ He asks us to try to solve this integral by hand (and if we can't, to feel free to simply use Mathematica to get the answer) which I've been working on for a couple of hours. I've gotten as far as changing the integral to: $$V(x,y)=2\int_{0}^{\infty}dk\frac{\sin{k}}{k}e^{ikz}-2\int_{0}^{-\infty}dk\frac{\sin{k}}{k}e^{ikz^*}\tag{2}$$ Where $z\equiv(x+iy)$ . This is something like the Fourier transform that takes $\text{sinc}(k)\rightarrow\tilde{\text{sinc}}(z)$ but I've never evaluated a Fourier transform in the complex plane. I know I'm on the right track as the correct answer is: $$V(x,y)=-\frac{2}{\pi}\Im(\text{arctanh}(z^{-1}))\tag{3}$$ But I'm nevertheless stuck and would appreciate a hint or a nudge in the correct direction so that I see how to proceed. I have an inkling that the answer involves expressing $z^{-1}$ as $z^{-1}=\frac{d}{dz}\ln{z}$ and then evaluating the integral until you get something like $\frac{1}{z^*}-\frac{1}{z}$ and expressing that as $\frac{d}{dz}(\ln(z^*)-\ln(z))=\frac{d}{dz}\ln{\frac{z^*}{z}}$ which is closely related to arctan functions as discussed here but I don't quite see how to get there.","Full disclosure: This is technically a ""homework"" question but not really. What I mean is that my professor gave us free reign to use Mathematica to simply get the answer to the integral but I am trying to go the extra mile and understand the full derivation, but I'm stuck. The problem is solving the Laplace equation for a finite strip. The solution which I've already derived is: He asks us to try to solve this integral by hand (and if we can't, to feel free to simply use Mathematica to get the answer) which I've been working on for a couple of hours. I've gotten as far as changing the integral to: Where . This is something like the Fourier transform that takes but I've never evaluated a Fourier transform in the complex plane. I know I'm on the right track as the correct answer is: But I'm nevertheless stuck and would appreciate a hint or a nudge in the correct direction so that I see how to proceed. I have an inkling that the answer involves expressing as and then evaluating the integral until you get something like and expressing that as which is closely related to arctan functions as discussed here but I don't quite see how to get there.","V(x,y)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{2\sin{k}}{k}e^{ikx}e^{-|k|y}dk\tag{1} V(x,y)=2\int_{0}^{\infty}dk\frac{\sin{k}}{k}e^{ikz}-2\int_{0}^{-\infty}dk\frac{\sin{k}}{k}e^{ikz^*}\tag{2} z\equiv(x+iy) \text{sinc}(k)\rightarrow\tilde{\text{sinc}}(z) V(x,y)=-\frac{2}{\pi}\Im(\text{arctanh}(z^{-1}))\tag{3} z^{-1} z^{-1}=\frac{d}{dz}\ln{z} \frac{1}{z^*}-\frac{1}{z} \frac{d}{dz}(\ln(z^*)-\ln(z))=\frac{d}{dz}\ln{\frac{z^*}{z}}","['complex-analysis', 'ordinary-differential-equations', 'fourier-transform']"
93,complex analysis/ integral: $\int_0^\infty \frac{1-\cos x }{x^2}dx$,complex analysis/ integral:,\int_0^\infty \frac{1-\cos x }{x^2}dx,"I have a question about an example in Stein/Shakarchi. Actually there is another thread here on SE Integrating $\int_0^\infty \frac{1-\cos x }{x^2}dx$ via contour integral. Regarding the integral $\int_0^\infty \frac{1-\cos x }{x^2}dx$ , I understand the indented semicircle contour, the division into 4 integrals, I also understand it until letting $R \rightarrow \infty$ and then applying ML estimation. However afterwards, I can not follow it anymore, where did the integrals of the two horizontal lines go? Do they cancel each other out (if yes, how can I see it?) and why do they write $f(z)$ as $f(z)=\frac{-i z}{z^2} + E(z)$ ? It would be really kind if someone could explain these last steps to me","I have a question about an example in Stein/Shakarchi. Actually there is another thread here on SE Integrating $\int_0^\infty \frac{1-\cos x }{x^2}dx$ via contour integral. Regarding the integral , I understand the indented semicircle contour, the division into 4 integrals, I also understand it until letting and then applying ML estimation. However afterwards, I can not follow it anymore, where did the integrals of the two horizontal lines go? Do they cancel each other out (if yes, how can I see it?) and why do they write as ? It would be really kind if someone could explain these last steps to me",\int_0^\infty \frac{1-\cos x }{x^2}dx R \rightarrow \infty f(z) f(z)=\frac{-i z}{z^2} + E(z),"['complex-analysis', 'contour-integration']"
94,"Palka, An Introduction to Complex Analysis pp. 97-98, drawing a connection between differentiability in the real sense and complex differentiability","Palka, An Introduction to Complex Analysis pp. 97-98, drawing a connection between differentiability in the real sense and complex differentiability",,"The book in question is An Introduction to Complex Function Thoery by Bruce Palka. Palka defines differentiability in the real sense as that a continuous function $f:A\to \mathbb{C}$ is differentiable at $z = x + iy$ in the real sense at $z_0 \in A$ if there exists complex numbers $c, d \in \mathbb{C}$ such that $f(z) = f(z_0) + c(z - z_0) + d(\overline{z} - \overline{z_0}) + E(z)$ where $E(z) \to 0$ as $z \to z_0$ . Palka's definition of complex differentiability is that (assume the same function $f$ ) $f$ has a complex derivative at $z_0 \in A$ if the limit $\lim_{z\to z_0}\frac{f(z) - f(z_0)}{z - z_0}$ exists. Palka discusses the general philosophy between these two notions in pages 97-98 by noting that the derivative of $f$ is in the real sense the matrix $\begin{bmatrix}\alpha & \beta\\ \gamma & \delta\end{bmatrix}$ with $\alpha = u_x, \beta = u_y, \gamma = v_x, \delta = v_y$ when $f = u + iv$ giving the $f$ the linear approximation form  at $z_0$ as $$f(z) = f(z_0) + \begin{bmatrix}\alpha & \beta\\\ \gamma & \delta\end{bmatrix}\begin{bmatrix}x - x_0\\\ y - y_0\end{bmatrix} + E(z)$$ when a complex number $z$ is viewed as a two dimensional vector. Then Palka states (without any computation) that the $c$ and $d$ w.r.t. the elements of the said matrix are $c = \frac{1}{2}\left(\alpha + \delta + i\left(\gamma - \beta\right)\right)$ and $d = \frac{1}{2}\left(\alpha - \delta + i\left(\gamma + \beta\right)\right)$ when $x = \frac{z + \overline{z}}{2} , y = \frac{z - \overline{z}}{2i}$ . Unfortunately I cannot seem to be able to derive these same equalities. Namely after applying the matrix to the vector $\begin{bmatrix}x - x_0\\\ y - y_0\end{bmatrix}$ and substituting the form of $x, x_0, y, y_0$ , we get $$\frac{1}{2}\begin{bmatrix}(z - z_0)(\alpha - i\beta) + (\overline{z} - \overline{z}_0)(\alpha + i\beta)\\\ (z - z_0)(\gamma - i\delta) + (\overline{z} - \overline{z}_0)(\gamma + i\delta)\end{bmatrix}$$ and I can't see any clear connection between $c$ and $d$ from this. What should I do? Thanks!","The book in question is An Introduction to Complex Function Thoery by Bruce Palka. Palka defines differentiability in the real sense as that a continuous function is differentiable at in the real sense at if there exists complex numbers such that where as . Palka's definition of complex differentiability is that (assume the same function ) has a complex derivative at if the limit exists. Palka discusses the general philosophy between these two notions in pages 97-98 by noting that the derivative of is in the real sense the matrix with when giving the the linear approximation form  at as when a complex number is viewed as a two dimensional vector. Then Palka states (without any computation) that the and w.r.t. the elements of the said matrix are and when . Unfortunately I cannot seem to be able to derive these same equalities. Namely after applying the matrix to the vector and substituting the form of , we get and I can't see any clear connection between and from this. What should I do? Thanks!","f:A\to \mathbb{C} z = x + iy z_0 \in A c, d \in \mathbb{C} f(z) = f(z_0) + c(z - z_0) + d(\overline{z} - \overline{z_0}) + E(z) E(z) \to 0 z \to z_0 f f z_0 \in A \lim_{z\to z_0}\frac{f(z) - f(z_0)}{z - z_0} f \begin{bmatrix}\alpha & \beta\\ \gamma & \delta\end{bmatrix} \alpha = u_x, \beta = u_y, \gamma = v_x, \delta = v_y f = u + iv f z_0 f(z) = f(z_0) + \begin{bmatrix}\alpha & \beta\\\ \gamma & \delta\end{bmatrix}\begin{bmatrix}x - x_0\\\ y - y_0\end{bmatrix} + E(z) z c d c = \frac{1}{2}\left(\alpha + \delta + i\left(\gamma - \beta\right)\right) d = \frac{1}{2}\left(\alpha - \delta + i\left(\gamma + \beta\right)\right) x = \frac{z + \overline{z}}{2} , y = \frac{z - \overline{z}}{2i} \begin{bmatrix}x - x_0\\\ y - y_0\end{bmatrix} x, x_0, y, y_0 \frac{1}{2}\begin{bmatrix}(z - z_0)(\alpha - i\beta) + (\overline{z} - \overline{z}_0)(\alpha + i\beta)\\\ (z - z_0)(\gamma - i\delta) + (\overline{z} - \overline{z}_0)(\gamma + i\delta)\end{bmatrix} c d",['complex-analysis']
95,solutions in upper half plane for polynomial-argument theorem,solutions in upper half plane for polynomial-argument theorem,,"Given $P(z)=z^5-12z^2+14$ , prove that there exist 2 solutions to $P(z)=0 $ in $\{Im(z)\ge 0 \}$ I tried using the argument theorem that states $\oint_{\gamma}\frac{p'\left(z\right)}{p\left(z\right)}dz=2\pi i\left(N-P\right) $ . Obviously $P=0 $ because it is a polynomial, I need to prove that $N=2$ . I looked at $$ \begin{cases} \gamma_{1}=t, & t\in\left[-R,R\right]\\ \gamma_{2}=Re^{it} & t\in\left[0,\pi\right] \end{cases} $$ and $\gamma =\gamma_1 \cup \gamma_2 $ . This made the 2 integrals $$ \oint_{\gamma}\frac{p'\left(z\right)}{p\left(z\right)}dz=\int\limits _{-R}^{R}\frac{5t^{4}-24t}{t^{5}-12t^{2}+14}dt+\int\limits _{0}^{\pi}\frac{R^{4}e^{4it}-24Re^{it}}{R^{5}e^{5it}-12R^{2}e^{2it}+14}\cdot iRe^{it}dt $$ $$ \int\limits _{-R}^{R}\frac{5t^{4}-24t}{t^{5}-12t^{2}+14}dt=\ln\left|\frac{R^{5}-12R^{2}+14}{-R^{5}-12R^{2}+14}\right|\xrightarrow{R\to\infty}0 $$ The problem is evaluating $$ \int\limits _{0}^{\pi}\frac{5R^{4}e^{4it}-24Re^{it}}{R^{5}e^{5it}-12R^{2}e^{2it}+14}\cdot iRe^{it}dt\approx\int\limits _{0}^{\pi}\frac{5iR^{5}e^{5it}}{R^{5}e^{5it}}\cdot dt=5\pi i $$ . I used a very loose approximation because I have no idea how to actually integrate that, and this gives me $N=2.5 $ , which I think is wrong,I need to get an integer. Where did I go wrong?","Given , prove that there exist 2 solutions to in I tried using the argument theorem that states . Obviously because it is a polynomial, I need to prove that . I looked at and . This made the 2 integrals The problem is evaluating . I used a very loose approximation because I have no idea how to actually integrate that, and this gives me , which I think is wrong,I need to get an integer. Where did I go wrong?","P(z)=z^5-12z^2+14 P(z)=0  \{Im(z)\ge 0 \} \oint_{\gamma}\frac{p'\left(z\right)}{p\left(z\right)}dz=2\pi i\left(N-P\right)  P=0  N=2  \begin{cases}
\gamma_{1}=t, & t\in\left[-R,R\right]\\
\gamma_{2}=Re^{it} & t\in\left[0,\pi\right]
\end{cases}  \gamma =\gamma_1 \cup \gamma_2   \oint_{\gamma}\frac{p'\left(z\right)}{p\left(z\right)}dz=\int\limits _{-R}^{R}\frac{5t^{4}-24t}{t^{5}-12t^{2}+14}dt+\int\limits _{0}^{\pi}\frac{R^{4}e^{4it}-24Re^{it}}{R^{5}e^{5it}-12R^{2}e^{2it}+14}\cdot iRe^{it}dt   \int\limits _{-R}^{R}\frac{5t^{4}-24t}{t^{5}-12t^{2}+14}dt=\ln\left|\frac{R^{5}-12R^{2}+14}{-R^{5}-12R^{2}+14}\right|\xrightarrow{R\to\infty}0   \int\limits _{0}^{\pi}\frac{5R^{4}e^{4it}-24Re^{it}}{R^{5}e^{5it}-12R^{2}e^{2it}+14}\cdot iRe^{it}dt\approx\int\limits _{0}^{\pi}\frac{5iR^{5}e^{5it}}{R^{5}e^{5it}}\cdot dt=5\pi i  N=2.5 ",['complex-analysis']
96,Finding conformal map from a region with a slit to upper half plane,Finding conformal map from a region with a slit to upper half plane,,"Find a conformal map from $F=\{z=x+iy\in\mathbb{C}:-\pi<y<\pi\}\setminus(-\infty,0]$ to the upper half plane $\mathbb{H}=\{z=x+iy\in\mathbb{C}:y>0\}$ To be honest, I never dealt with strips with slits before so I don't really have an idea where to start. The first idea that came to mind is maybe use the logarithm function (since its' principal branch is when we take $\mathbb{C}\setminus(-\infty,0]$ . Other than that I don't know how to continue. What is the general way to think on such questions?","Find a conformal map from to the upper half plane To be honest, I never dealt with strips with slits before so I don't really have an idea where to start. The first idea that came to mind is maybe use the logarithm function (since its' principal branch is when we take . Other than that I don't know how to continue. What is the general way to think on such questions?","F=\{z=x+iy\in\mathbb{C}:-\pi<y<\pi\}\setminus(-\infty,0] \mathbb{H}=\{z=x+iy\in\mathbb{C}:y>0\} \mathbb{C}\setminus(-\infty,0]","['complex-analysis', 'analysis', 'conformal-geometry', 'mobius-transformation']"
97,"If $f(z)=\overline{f(\overline z)}$ for a holomorphic $f$, is the same true for its derivative?","If  for a holomorphic , is the same true for its derivative?",f(z)=\overline{f(\overline z)} f,"Suppose that $f : \mathbb C \to \mathbb C$ is an entire function which satisfies the relation $$ f(z)=\overline{f(\overline z)} $$ for every $z \in \mathbb C$ . I'm wondering if the same is true for its complex derivative, i.e. so we have $f'(z)=\overline{f'(\overline z)}$ ?","Suppose that is an entire function which satisfies the relation for every . I'm wondering if the same is true for its complex derivative, i.e. so we have ?","f : \mathbb C \to \mathbb C 
f(z)=\overline{f(\overline z)}
 z \in \mathbb C f'(z)=\overline{f'(\overline z)}",['complex-analysis']
98,Define the domain in which $f(z)=z\cdot \text{Im} (z)$ is differentiable and calculate its derivative.,Define the domain in which  is differentiable and calculate its derivative.,f(z)=z\cdot \text{Im} (z),"Define the domain in which the below function is differentiable and calculate its derivative: $$f(z)=z\cdot \text{Im} (z)$$ I tried checking the analyticity of the function by definining $z=x+iy$ , I get $$f(z)=(x+iy)y$$ but by the Cauchy-Riemann equations, it is not an analytic function: $$ \dfrac{\partial u(x,y)}{\partial x} = \dfrac{\partial(xy)}{\partial x} = y \neq \dfrac{\partial v(x,y)}{\partial y} = \dfrac{\partial (y^{2})}{y} = 2y$$ In which $$Re(f(z)) = u(x,y)$$ and $$Im(f(z)) = v(x,y)$$","Define the domain in which the below function is differentiable and calculate its derivative: I tried checking the analyticity of the function by definining , I get but by the Cauchy-Riemann equations, it is not an analytic function: In which and","f(z)=z\cdot \text{Im} (z) z=x+iy f(z)=(x+iy)y  \dfrac{\partial u(x,y)}{\partial x} = \dfrac{\partial(xy)}{\partial x} = y \neq \dfrac{\partial v(x,y)}{\partial y} = \dfrac{\partial (y^{2})}{y} = 2y Re(f(z)) = u(x,y) Im(f(z)) = v(x,y)","['complex-analysis', 'derivatives', 'complex-numbers']"
99,Estimation of $\lvert f' \rvert$ via Cauchy-integral formula,Estimation of  via Cauchy-integral formula,\lvert f' \rvert,"I am asked to prove that if $f: \mathbb{C} \rightarrow \mathbb{C}$ is entire and $\lvert f(z) \rvert \leq 1$ on $\overline{B_1(0)}$ , then $\lvert f'(z) \rvert \leq 4$ on $\overline{B_\frac{1}{2}(0)}$ . What I did is to choose any $z \in \overline{B_\frac{1}{2}(0)}$ . I then easily observed that $\overline{B_\frac{1}{2}(z)} \subseteq \overline{B_1(0)}$ . Then: $$ \lvert f'(z) \rvert = \left \lvert \frac{1}{2\pi i} \oint_{\partial K_\frac{1}{2}(z)} \frac{f(w)}{(w-z)^2}~\mathrm{d}w\right \rvert \leq \frac{1}{2\pi} \oint_{\partial K_\frac{1}{2}(z)} \frac{\overbrace{\lvert f(w) \rvert}^{\leq 1}}{\underbrace{\lvert w-z\rvert^2}_{=\frac{1}{4}}}~\mathrm{d}w \leq 2 $$ So I got an even better estimate... . Do you know if I made a mistake? Thank you. I am also personally interested in what is the sharpest estimation of this kind. I know that $\lvert f' \rvert = 1$ is possible e.g. for $f(z) = z^2$ .","I am asked to prove that if is entire and on , then on . What I did is to choose any . I then easily observed that . Then: So I got an even better estimate... . Do you know if I made a mistake? Thank you. I am also personally interested in what is the sharpest estimation of this kind. I know that is possible e.g. for .","f: \mathbb{C} \rightarrow \mathbb{C} \lvert f(z) \rvert \leq 1 \overline{B_1(0)} \lvert f'(z) \rvert \leq 4 \overline{B_\frac{1}{2}(0)} z \in \overline{B_\frac{1}{2}(0)} \overline{B_\frac{1}{2}(z)} \subseteq \overline{B_1(0)} 
\lvert f'(z) \rvert = \left \lvert \frac{1}{2\pi i} \oint_{\partial K_\frac{1}{2}(z)} \frac{f(w)}{(w-z)^2}~\mathrm{d}w\right \rvert \leq \frac{1}{2\pi} \oint_{\partial K_\frac{1}{2}(z)} \frac{\overbrace{\lvert f(w) \rvert}^{\leq 1}}{\underbrace{\lvert w-z\rvert^2}_{=\frac{1}{4}}}~\mathrm{d}w \leq 2
 \lvert f' \rvert = 1 f(z) = z^2","['integration', 'complex-analysis', 'inequality', 'cauchy-integral-formula']"
