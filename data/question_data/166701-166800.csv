,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is standard deviation additive?,Is standard deviation additive?,,"I am helping someone study for a statistics exam. I am quite good at most other math classes but it's been a while since I studied statistics. I am stuck on one of the exercise problems that we worked on. Exercise: This is a paraphrase of the exercise: A mason lays a row of cement blocks with a layer of motar. Each row (bricks and mortar) has a mean height of 8 inches with standard deviation 0.1 inches. What is the probability that a wall built from 4 rows of cement blocks differs from 32 inches by more than a half-inch? Assume that the height of each row is independent and distributed normally. What I can do: I know that I need to find the mean $\mu_{wall}$ and standard deviation $\sigma_{wall}$ for the wall made from four rows of cement blocks. I'm given that the mean $\mu_{row}$ and standard deviation $\sigma_{row}$ of one row of blocks are $\mu_{row} = 8$ and $\sigma_{row} = 0.1$. So for $n = 4$ rows, we have $\mu_{walls} = n \mu_{row} = 4 \cdot 8 = 32$. Question: How do I calculate $\sigma_{wall}$ knowing that $\sigma_{row} = 0.1$? My first guess would be to simply multiply by 4, but I'm not sure that is correct. Once I have the standard deviation, doing a Z test is easy.","I am helping someone study for a statistics exam. I am quite good at most other math classes but it's been a while since I studied statistics. I am stuck on one of the exercise problems that we worked on. Exercise: This is a paraphrase of the exercise: A mason lays a row of cement blocks with a layer of motar. Each row (bricks and mortar) has a mean height of 8 inches with standard deviation 0.1 inches. What is the probability that a wall built from 4 rows of cement blocks differs from 32 inches by more than a half-inch? Assume that the height of each row is independent and distributed normally. What I can do: I know that I need to find the mean $\mu_{wall}$ and standard deviation $\sigma_{wall}$ for the wall made from four rows of cement blocks. I'm given that the mean $\mu_{row}$ and standard deviation $\sigma_{row}$ of one row of blocks are $\mu_{row} = 8$ and $\sigma_{row} = 0.1$. So for $n = 4$ rows, we have $\mu_{walls} = n \mu_{row} = 4 \cdot 8 = 32$. Question: How do I calculate $\sigma_{wall}$ knowing that $\sigma_{row} = 0.1$? My first guess would be to simply multiply by 4, but I'm not sure that is correct. Once I have the standard deviation, doing a Z test is easy.",,"['statistics', 'standard-deviation']"
1,"Normal Distribution, The ""Y"" Value","Normal Distribution, The ""Y"" Value",,"Guys I am having trouble with the standard normal distribution. http://www.regentsprep.org/Regents/math/algtrig/ATS2/NormalLesson.htm We know the X values run from approx $-\infty$ to $+\infty$ but what are the y values?? The normal distribution takes two parameters $\mathcal{N}(\mu, \sigma^2)$ but what is the range of y? $y>0$ obviously and the ""y"" will depend on the mean and variance you picked as $y=\frac{\exp(-z^2)}{\sqrt{2\pi\sigma^2}}$. But I have trouble understanding what it means. If I take the S&P500 and I difference the series (SPX-SPX(-1)) the histogram of the returns will have an approximate normal distributions and will list out the number of times I have a return of -1%,-.5%,0%,.5%, 1% , etc throughout the history. So is the ""y"" of the normal distribution the number of times I have had that x as a value? Should I think of the normal distribution in practical terms the number of times that one point event has occurred? I look at some normal distributions and the Y ranges from 0-4, others I see the y ranging from 0 to 1, as a probability should. I know the area underneath the curve should sum to 1 but shouldnt the y values always be less than 1? https://statistics.laerd.com/statistical-guides/standard-score.php Thanks guys!","Guys I am having trouble with the standard normal distribution. http://www.regentsprep.org/Regents/math/algtrig/ATS2/NormalLesson.htm We know the X values run from approx $-\infty$ to $+\infty$ but what are the y values?? The normal distribution takes two parameters $\mathcal{N}(\mu, \sigma^2)$ but what is the range of y? $y>0$ obviously and the ""y"" will depend on the mean and variance you picked as $y=\frac{\exp(-z^2)}{\sqrt{2\pi\sigma^2}}$. But I have trouble understanding what it means. If I take the S&P500 and I difference the series (SPX-SPX(-1)) the histogram of the returns will have an approximate normal distributions and will list out the number of times I have a return of -1%,-.5%,0%,.5%, 1% , etc throughout the history. So is the ""y"" of the normal distribution the number of times I have had that x as a value? Should I think of the normal distribution in practical terms the number of times that one point event has occurred? I look at some normal distributions and the Y ranges from 0-4, others I see the y ranging from 0 to 1, as a probability should. I know the area underneath the curve should sum to 1 but shouldnt the y values always be less than 1? https://statistics.laerd.com/statistical-guides/standard-score.php Thanks guys!",,"['statistics', 'normal-distribution']"
2,What is a sufficient statistic?,What is a sufficient statistic?,,"I am trying to understand the definition of a sufficient statistic and trying to make conceptual sense of it. Wikipedia says $$Pr(X=x|T(X)=t,\theta) = Pr(X=x|T(X)=t)$$ Exactly how am I suppose to make sense of probability with $\theta$? Probability makes sense for $X$ because it is a function (a random variable) defined on a probability space. As far as I can tell $\theta$ has no sense of being defined on that probability space so how can a conditional make sense?","I am trying to understand the definition of a sufficient statistic and trying to make conceptual sense of it. Wikipedia says $$Pr(X=x|T(X)=t,\theta) = Pr(X=x|T(X)=t)$$ Exactly how am I suppose to make sense of probability with $\theta$? Probability makes sense for $X$ because it is a function (a random variable) defined on a probability space. As far as I can tell $\theta$ has no sense of being defined on that probability space so how can a conditional make sense?",,['statistics']
3,Is there a difference between rejecting a null hypothesis and not accepting a null hypothesis?,Is there a difference between rejecting a null hypothesis and not accepting a null hypothesis?,,"I understand that we never say that the null hypothesis is accepted, instead we say that the null hypothesis is not rejected since we can never prove an effect does not exist through empirical evidence. But does the opposite hold? Is there a difference between rejecting the null hypothesis and not accepting the null hypothesis? In the same sense, how can we prove that an effect does exist? Surely we can only show that there is a low probability, say at 1% significance level, that an effect does not exist and thus we can only not accept it?","I understand that we never say that the null hypothesis is accepted, instead we say that the null hypothesis is not rejected since we can never prove an effect does not exist through empirical evidence. But does the opposite hold? Is there a difference between rejecting the null hypothesis and not accepting the null hypothesis? In the same sense, how can we prove that an effect does exist? Surely we can only show that there is a low probability, say at 1% significance level, that an effect does not exist and thus we can only not accept it?",,"['statistics', 'statistical-inference', 'hypothesis-testing']"
4,How determine the distribution of $S_{n-1}^{2}$? [duplicate],How determine the distribution of ? [duplicate],S_{n-1}^{2},"This question already has answers here : Proof of $\frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}$ (5 answers) Closed 3 years ago . If $ X_1,\dots,X_n $ is a random sample with $X_i \sim N(\mu,\sigma^2) $ , how determinate the distribution of $S_{n-1}^2 = \frac{1}{n-1} \sum \limits_{i=1}^n (X_i - \bar{X})^2 $ ? I tried to apply the method of moments as follow: $S_{n-1}^2 = \frac{1}{n-1} \sum \limits_{i=1}^n (X_i - \bar{X})^2 = \frac{1}{n-1} \sum \limits_{i=1}^n X_i^2 - \frac{n}{n-1} \bar{X}^2 $ $$ M_{S_{n-1}^2 }(t) = E[ e^{t ( \frac{1}{n-1} \sum \limits_{i=1}^n X_i^2 - \frac{n}{n-1} \bar{X}^2 ) } ] =  E[ e^{t ( \frac{1}{n-1} \sum \limits_{i=1}^n X_i^2)} e^{t(- \frac{n}{n-1} \bar{X}^2 ) } ] = E[ e^{t ( \frac{1}{n-1} \sum \limits_{i=1}^n X_i^2)} e^{(-t \frac{n}{n-1} \bar{X}^2 ) } ] $$ $$= E[ e^{t ( \frac{1}{n-1} \sum \limits_{i=1}^n X_i^2)}] E[e^{(-t \frac{n}{n-1} \bar{X}^2 ) } ] = \prod_{i=1}^n E[ e^{t ( \frac{1}{n-1} X_i^2)}] E[e^{(-t \frac{n}{n-1} \bar{X}^2 ) } ]$$ But in this point I'm lose. Should I apply the following? $$ X_i \sim N( \mu,\sigma^2 ) \Rightarrow X_i = \sigma Z + \mu  $$ $$ Y = (\sigma Z+ \mu )^2 \Rightarrow M_Y(t) = \frac{1}{\sqrt{1-2t\sigma^2}} \exp\left(  \dfrac{\mu^2t}{1-2t\sigma^2}\right) , \ \text{if } \ 2\operatorname{Re}(t\sigma^2) < 1$$ Or isn't this the simplest way to determinate $S_{n-1}^2$ ?","This question already has answers here : Proof of $\frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}$ (5 answers) Closed 3 years ago . If is a random sample with , how determinate the distribution of ? I tried to apply the method of moments as follow: But in this point I'm lose. Should I apply the following? Or isn't this the simplest way to determinate ?"," X_1,\dots,X_n  X_i \sim N(\mu,\sigma^2)  S_{n-1}^2 = \frac{1}{n-1} \sum \limits_{i=1}^n (X_i - \bar{X})^2  S_{n-1}^2 = \frac{1}{n-1} \sum \limits_{i=1}^n (X_i - \bar{X})^2 = \frac{1}{n-1} \sum \limits_{i=1}^n X_i^2 - \frac{n}{n-1} \bar{X}^2   M_{S_{n-1}^2 }(t) = E[ e^{t ( \frac{1}{n-1} \sum \limits_{i=1}^n X_i^2 - \frac{n}{n-1} \bar{X}^2 ) } ] =  E[ e^{t ( \frac{1}{n-1} \sum \limits_{i=1}^n X_i^2)} e^{t(- \frac{n}{n-1} \bar{X}^2 ) } ] = E[ e^{t ( \frac{1}{n-1} \sum \limits_{i=1}^n X_i^2)} e^{(-t \frac{n}{n-1} \bar{X}^2 ) } ]  = E[ e^{t ( \frac{1}{n-1} \sum \limits_{i=1}^n X_i^2)}] E[e^{(-t \frac{n}{n-1} \bar{X}^2 ) } ] = \prod_{i=1}^n E[ e^{t ( \frac{1}{n-1} X_i^2)}] E[e^{(-t \frac{n}{n-1} \bar{X}^2 ) } ]  X_i \sim N( \mu,\sigma^2 ) \Rightarrow X_i = \sigma Z + \mu    Y = (\sigma Z+ \mu )^2 \Rightarrow M_Y(t) = \frac{1}{\sqrt{1-2t\sigma^2}} \exp\left(  \dfrac{\mu^2t}{1-2t\sigma^2}\right) , \ \text{if } \ 2\operatorname{Re}(t\sigma^2) < 1 S_{n-1}^2","['statistics', 'probability-distributions']"
5,What is the simplest example of a non-exchangeable sequence of random variables?,What is the simplest example of a non-exchangeable sequence of random variables?,,"I read the wiki article on exchangeability which contained examples, but not negative examples. Can you please provide the simplest negative example of exchangeable random variables? Also, I know that: $P(x_1, x_2) = P(x_1 | x_2) P(x_2) = P(x_2 | x_1) P(x_1)$ I thought this is always true, but now I think it is invalid for cases of non-exchangeable random variables, but I cannot see examples.","I read the wiki article on exchangeability which contained examples, but not negative examples. Can you please provide the simplest negative example of exchangeable random variables? Also, I know that: I thought this is always true, but now I think it is invalid for cases of non-exchangeable random variables, but I cannot see examples.","P(x_1, x_2) = P(x_1 | x_2) P(x_2) = P(x_2 | x_1) P(x_1)","['statistics', 'probability-distributions', 'random-variables']"
6,How to calculate standard deviation?,How to calculate standard deviation?,,"x(i) | freq. 8 | 11 10 | 9 12 | 13 14 | 24 16 | 16 18 | 10 20 | 15 The formula for standard deviation is $\sigma = \sqrt{\frac{\Sigma|x-\bar{x}|^2}{n}}$ . It would be easy with a graphing calculator, but I only have TI-30XA scientific calculator that can't do much. Can someone teach me a faster way to calculate the standard deviation by hand?","x(i) | freq. 8 | 11 10 | 9 12 | 13 14 | 24 16 | 16 18 | 10 20 | 15 The formula for standard deviation is . It would be easy with a graphing calculator, but I only have TI-30XA scientific calculator that can't do much. Can someone teach me a faster way to calculate the standard deviation by hand?",\sigma = \sqrt{\frac{\Sigma|x-\bar{x}|^2}{n}},['statistics']
7,Asymptotics of inverse of normal CDF,Asymptotics of inverse of normal CDF,,"Let $\Phi(x)$ denote the cdf of the standard normal distribution.  What are the asymptotics of $\Phi^{-1}(p)$ , as $p \to 1$ ?  In particular, is there an asymptotic expression for $\Phi^{-1}(1-x)$ , as $x \to 0$ ?  A first-order approximation would be fine.","Let denote the cdf of the standard normal distribution.  What are the asymptotics of , as ?  In particular, is there an asymptotic expression for , as ?  A first-order approximation would be fine.",\Phi(x) \Phi^{-1}(p) p \to 1 \Phi^{-1}(1-x) x \to 0,"['real-analysis', 'statistics', 'probability-distributions', 'asymptotics', 'normal-distribution']"
8,One tailed confidence interval $1 - 2\alpha $ rationale,One tailed confidence interval  rationale,1 - 2\alpha ,"In my statistics textbook, I’ve noticed a pattern that is clear but the rationale for which isn’t explained: When constructing a one tailed confidence interval, the confidence level is equal to $ 1 - 2\alpha $. I can apply this idea, but can someone please explain to me the rationale? Why is $ 1 - 2\alpha $ the confidence level for a one tailed test when a two tailed test is $1 - \alpha $? I should add that my understanding is that a one tailed confidence interval should have confidence level equal to $1 - \alpha $ because each tail in a two tailed confidence interval has area $1 - \alpha/2 $. This is what I cannot reconcile. Edit: This table is referenced repeatedly in the book but no justification I can find is given. The book is “Essentials of Statistics,” 5th edition, Triola, Mario F. Edit: I’ve included some reference photos from two sections of the book. The first two photos below are from a general section on confidence intervals where only two tailed intervals are discussed. The following two photos are from a section on chi-squares tests. I can not reconcile the statements regarding confidence level in the next photo from the statement about alpha in the final photo:","In my statistics textbook, I’ve noticed a pattern that is clear but the rationale for which isn’t explained: When constructing a one tailed confidence interval, the confidence level is equal to $ 1 - 2\alpha $. I can apply this idea, but can someone please explain to me the rationale? Why is $ 1 - 2\alpha $ the confidence level for a one tailed test when a two tailed test is $1 - \alpha $? I should add that my understanding is that a one tailed confidence interval should have confidence level equal to $1 - \alpha $ because each tail in a two tailed confidence interval has area $1 - \alpha/2 $. This is what I cannot reconcile. Edit: This table is referenced repeatedly in the book but no justification I can find is given. The book is “Essentials of Statistics,” 5th edition, Triola, Mario F. Edit: I’ve included some reference photos from two sections of the book. The first two photos below are from a general section on confidence intervals where only two tailed intervals are discussed. The following two photos are from a section on chi-squares tests. I can not reconcile the statements regarding confidence level in the next photo from the statement about alpha in the final photo:",,"['statistics', 'confidence-interval']"
9,"What is the meaning of ""expected value of an estimator""?","What is the meaning of ""expected value of an estimator""?",,"I am studying statistics and i am having trouble understanding some proofs because i don't quite understand what the concept of ""expected value of an estimator"" means and what is the difference with the value of the esimator itself. Say i got a sample and I take the variance v of that sample. That variance v is my estimator. What is the meaning of the expected value of the variance? Thanks a lot!","I am studying statistics and i am having trouble understanding some proofs because i don't quite understand what the concept of ""expected value of an estimator"" means and what is the difference with the value of the esimator itself. Say i got a sample and I take the variance v of that sample. That variance v is my estimator. What is the meaning of the expected value of the variance? Thanks a lot!",,"['statistics', 'descriptive-statistics']"
10,Expected Value for $n$ values,Expected Value for  values,n,"I've been thinking about this for a while and I can't seem to figure it out.  In a class, a teacher will call a student to answer a questions and the number of questions $n$ is equal to the number of students. A question is asked to one student at random. Using linearity of expectation, if there are $n$ students and $n$ questions, what is the expected number of students that don't get called? I decided to try it out with $n=2$. Using $1$ = called, and $0$=not called, there are 4 possibilities $(11, 10, 01, 00)$. Then, we would have to multiply the probability with the value. Now, I am totally lost. There is a probability of $1/4$ is for $00$, and $1/4$ for both $01$ and $10$ each. Then is the expected value just $3/4$? And how would I apply it to $n$ cases, instead of just $n=2$?","I've been thinking about this for a while and I can't seem to figure it out.  In a class, a teacher will call a student to answer a questions and the number of questions $n$ is equal to the number of students. A question is asked to one student at random. Using linearity of expectation, if there are $n$ students and $n$ questions, what is the expected number of students that don't get called? I decided to try it out with $n=2$. Using $1$ = called, and $0$=not called, there are 4 possibilities $(11, 10, 01, 00)$. Then, we would have to multiply the probability with the value. Now, I am totally lost. There is a probability of $1/4$ is for $00$, and $1/4$ for both $01$ and $10$ each. Then is the expected value just $3/4$? And how would I apply it to $n$ cases, instead of just $n=2$?",,"['statistics', 'discrete-mathematics', 'expectation']"
11,How should I calculate a rolling autocorrelation?,How should I calculate a rolling autocorrelation?,,"I have an array of data $ \mathbf{y} \in \mathbb{R}^n $, and I need to calculate the lag-1 autocorrelation between sections of this array 7 elements long. For all intents and purposes, we can imagine reshaping this array into a $ n/7 \times 7$ matrix, and then taking the autocorrelation between each row of the matrix. Here is my gripe:  I'm unsure how to compute the AC.  On one hand I could use the following formula $$ r = \dfrac{  \sum_{j=1}^{7} (\mathbf{y}_{i,j}- \bar{\mathbf{y}})(\mathbf{y}_{i+1,j}- \bar{\mathbf{y}}) }{\left(\sum_{i=1}^{7}(\mathbf{y_{i,j} - \bar{\mathbf{y}}})^2\right)^{0.5} \left( \sum_{i=1}^{7}(\mathbf{y_{i+1,j} - \bar{\mathbf{y}}})^2 \right)^{0.5} } $$ Here, $ \bar{\mathbf{y}}$ is the mean of the entire vector, and not the row.  I do this because each row from the matrix comes from the same signal.  This would require me to write my own function, which is not out of the realm of possibility, I just trust built in functions from stat toolkits a little more than my own understanding. The other option is to use a built in function, but I am unsure if the function will calculate the mean of each row and use that in the calculation.  Like I've said before, since each row comes from the same signal, the mean used in the calculation should be the mean of the entire signal and not just the row. Thoughts are appreciated on the issue.  I'm writing this in python if that is salient. So how should I go about computing this?","I have an array of data $ \mathbf{y} \in \mathbb{R}^n $, and I need to calculate the lag-1 autocorrelation between sections of this array 7 elements long. For all intents and purposes, we can imagine reshaping this array into a $ n/7 \times 7$ matrix, and then taking the autocorrelation between each row of the matrix. Here is my gripe:  I'm unsure how to compute the AC.  On one hand I could use the following formula $$ r = \dfrac{  \sum_{j=1}^{7} (\mathbf{y}_{i,j}- \bar{\mathbf{y}})(\mathbf{y}_{i+1,j}- \bar{\mathbf{y}}) }{\left(\sum_{i=1}^{7}(\mathbf{y_{i,j} - \bar{\mathbf{y}}})^2\right)^{0.5} \left( \sum_{i=1}^{7}(\mathbf{y_{i+1,j} - \bar{\mathbf{y}}})^2 \right)^{0.5} } $$ Here, $ \bar{\mathbf{y}}$ is the mean of the entire vector, and not the row.  I do this because each row from the matrix comes from the same signal.  This would require me to write my own function, which is not out of the realm of possibility, I just trust built in functions from stat toolkits a little more than my own understanding. The other option is to use a built in function, but I am unsure if the function will calculate the mean of each row and use that in the calculation.  Like I've said before, since each row comes from the same signal, the mean used in the calculation should be the mean of the entire signal and not just the row. Thoughts are appreciated on the issue.  I'm writing this in python if that is salient. So how should I go about computing this?",,"['statistics', 'signal-processing', 'correlation']"
12,Why is Wolfram giving me a different answer for standard deviation?,Why is Wolfram giving me a different answer for standard deviation?,,"I have the following set of data: Raw Scores   x-x̄        (x-x̄)² -----------------------------  7           -6            36  8           -5            25 10           -3             9 14            1             1 26           13           169 ----------------------------- 65            0           240 ----------------------------- From the raw scores we know that : $$ n=5 $$ and ∴ the mean, $$ x̄ = \frac{\sum}{n}  = \frac{65}{5}   =    13 $$ I then proceeded to complete the table above filling in $$ x-x̄ $$ & $$ (x-x̄ )² $$ I am now required to calculate the standard deviation & have the following  eqation. $$ \sigma = \sqrt{\frac{\sum(x_i-\overline{x})^2}{n}} = \sqrt{\frac{240}{5}} = 4 \sqrt{15} $$ However when I submit my data to wolfram and query standard deviatioin it returns the answer $$2\sqrt{15}$$ Maybe this is out of the scope of my learning but being curious I opened the step by step answer and I see that wolfram calculates the standard deviation by $$ \sigma = \sqrt{\frac{\sum(x_i-\overline{x})^2}{n-1}} $$ My textbook accessible here and another textbook my teacher printed out have the eqation    , I find it hard to believe that My teacher and 2 other textbooks can be wrong however Im pretty sure the developers at wolfram couldn't have got it wrong either. What am I missing?","I have the following set of data: Raw Scores   x-x̄        (x-x̄)² -----------------------------  7           -6            36  8           -5            25 10           -3             9 14            1             1 26           13           169 ----------------------------- 65            0           240 ----------------------------- From the raw scores we know that : $$ n=5 $$ and ∴ the mean, $$ x̄ = \frac{\sum}{n}  = \frac{65}{5}   =    13 $$ I then proceeded to complete the table above filling in $$ x-x̄ $$ & $$ (x-x̄ )² $$ I am now required to calculate the standard deviation & have the following  eqation. $$ \sigma = \sqrt{\frac{\sum(x_i-\overline{x})^2}{n}} = \sqrt{\frac{240}{5}} = 4 \sqrt{15} $$ However when I submit my data to wolfram and query standard deviatioin it returns the answer $$2\sqrt{15}$$ Maybe this is out of the scope of my learning but being curious I opened the step by step answer and I see that wolfram calculates the standard deviation by $$ \sigma = \sqrt{\frac{\sum(x_i-\overline{x})^2}{n-1}} $$ My textbook accessible here and another textbook my teacher printed out have the eqation    , I find it hard to believe that My teacher and 2 other textbooks can be wrong however Im pretty sure the developers at wolfram couldn't have got it wrong either. What am I missing?",,['statistics']
13,How do I know if a sufficient statistic is also complete?,How do I know if a sufficient statistic is also complete?,,"For example, for an i.i.d. sample of random variables $X_i$ distributed according to a normal distribution, I found a sufficient statistic—the sample mean. How do I know if this is also complete? Thank you.","For example, for an i.i.d. sample of random variables $X_i$ distributed according to a normal distribution, I found a sufficient statistic—the sample mean. How do I know if this is also complete? Thank you.",,"['statistics', 'normal-distribution', 'statistical-inference']"
14,computing the bias and standard error of a uniform distribution with unknown upper limit?,computing the bias and standard error of a uniform distribution with unknown upper limit?,,"Let $X_1, \ldots, X_n \sim \mathrm{Uniform}(0,T)$ and $T^\wedge = \max\{X_1, \ldots, X_n\}$, which is the estimator of $T$.  What is the bias and se of this estimator? If $n=1$, then the calculating the bias and standard error are straight forward ($\text{bias}=-T/2$, and $\text{se}=\sqrt{T^2/12}$. But I'm not sure how to go for it when we have $n$ samples as in this problem?!","Let $X_1, \ldots, X_n \sim \mathrm{Uniform}(0,T)$ and $T^\wedge = \max\{X_1, \ldots, X_n\}$, which is the estimator of $T$.  What is the bias and se of this estimator? If $n=1$, then the calculating the bias and standard error are straight forward ($\text{bias}=-T/2$, and $\text{se}=\sqrt{T^2/12}$. But I'm not sure how to go for it when we have $n$ samples as in this problem?!",,"['statistics', 'statistical-inference']"
15,Closed form for coefficients in Multiple Regression model,Closed form for coefficients in Multiple Regression model,,"I want to find $\hat{\beta}$ in ordinary least squares s.t. $\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X_1 + \cdots + \hat{\beta}_n X_n $. I know the way to do this is through the normal equation using matrix algebra, but I have never seen a nice closed form solution for each $\hat{\beta}_i$. I'm thinking as a generalization of the simple linear regression case, $$ \hat{\beta}_i = \frac{ Cov(X_i, Y) }{Var(X_i) },$$ where $ Y = \beta_0 + \beta_1 X_1 + \cdots + \beta_n X_n + \epsilon_i $. Is my conjecture for the form of the regression coefficients true? And what would $\hat{\beta_0}$ be?","I want to find $\hat{\beta}$ in ordinary least squares s.t. $\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X_1 + \cdots + \hat{\beta}_n X_n $. I know the way to do this is through the normal equation using matrix algebra, but I have never seen a nice closed form solution for each $\hat{\beta}_i$. I'm thinking as a generalization of the simple linear regression case, $$ \hat{\beta}_i = \frac{ Cov(X_i, Y) }{Var(X_i) },$$ where $ Y = \beta_0 + \beta_1 X_1 + \cdots + \beta_n X_n + \epsilon_i $. Is my conjecture for the form of the regression coefficients true? And what would $\hat{\beta_0}$ be?",,"['statistics', 'regression']"
16,"What is the definition of a ""predictable process""?","What is the definition of a ""predictable process""?",,"I am reading a book on financial mathematics, and frequently encounter the phrase ""predictable process"", which I haven't seen definition of, and cannot find the definition online. At first I thought that this was referring to a process which is known exactly at $t = 0$, but that is not the case, because then I see decomposition of an $(\mathcal F_t)_{t\in\mathbb N}$-adapted process $(X_t)$ into a martingale process $(M_t)$ and a predictable process $(A_t)$ where $$ \begin{eqnarray} M_0 = 0, &\hspace{10mm} &\Delta M_t = M_t - M_{t-1} = X_t - E(X_t|\mathcal F_{t-1}) \\ A_0 = 0, &\hspace{10mm} &\Delta A_t = A_t - A_{t-1} = E(X_t|\mathcal F_{t-1}) - X_{t-1} \end{eqnarray} $$ so it seems like $A_t$ can only be predicted at $t-1$.  Is that what a ""predictable process"" is?","I am reading a book on financial mathematics, and frequently encounter the phrase ""predictable process"", which I haven't seen definition of, and cannot find the definition online. At first I thought that this was referring to a process which is known exactly at $t = 0$, but that is not the case, because then I see decomposition of an $(\mathcal F_t)_{t\in\mathbb N}$-adapted process $(X_t)$ into a martingale process $(M_t)$ and a predictable process $(A_t)$ where $$ \begin{eqnarray} M_0 = 0, &\hspace{10mm} &\Delta M_t = M_t - M_{t-1} = X_t - E(X_t|\mathcal F_{t-1}) \\ A_0 = 0, &\hspace{10mm} &\Delta A_t = A_t - A_{t-1} = E(X_t|\mathcal F_{t-1}) - X_{t-1} \end{eqnarray} $$ so it seems like $A_t$ can only be predicted at $t-1$.  Is that what a ""predictable process"" is?",,"['statistics', 'stochastic-processes', 'finance']"
17,"Given a set of numbers, what mathematical name is given to the most frequent number","Given a set of numbers, what mathematical name is given to the most frequent number",,"Assume a set of numbers {0,1,2,3,4,4,4,4,4,5,6,7,8,9} What mathematical name is given to the number that most frequently occurs? For example, if I was to count the number of occurrences for each number in the above set, I would note every number occurring once except 4 which occurs 5 times. Thanks","Assume a set of numbers {0,1,2,3,4,4,4,4,4,5,6,7,8,9} What mathematical name is given to the number that most frequently occurs? For example, if I was to count the number of occurrences for each number in the above set, I would note every number occurring once except 4 which occurs 5 times. Thanks",,"['statistics', 'terminology', 'mathematica']"
18,Sum of normal random variables being not normal,Sum of normal random variables being not normal,,"If X and Y are identically distributed as $N(0,1)$ (but not independent) with covariance $cov(X, Y)=\frac{1}{2}$ (and these are the only constraints). Is it possible to construct X and Y such that X+Y is not normally distributed?",If X and Y are identically distributed as (but not independent) with covariance (and these are the only constraints). Is it possible to construct X and Y such that X+Y is not normally distributed?,"N(0,1) cov(X, Y)=\frac{1}{2}","['statistics', 'normal-distribution']"
19,What is a 100th percentile?,What is a 100th percentile?,,"I am really confused behind the mathematical meaning of a 100th percentile. What does that mean mathematically? Does it mean that a data point in a sample space is greater in some metric and that is also greater than itself? That makes no sense. AFAIK, there can be no such thing as the 100th percentile, because the maximum data point considered is still part of the sample space. For example, when a student scores the highest marks, he/she can be the 99.999th percentile, but what is the meaning of 100th percentile ?","I am really confused behind the mathematical meaning of a 100th percentile. What does that mean mathematically? Does it mean that a data point in a sample space is greater in some metric and that is also greater than itself? That makes no sense. AFAIK, there can be no such thing as the 100th percentile, because the maximum data point considered is still part of the sample space. For example, when a student scores the highest marks, he/she can be the 99.999th percentile, but what is the meaning of 100th percentile ?",,['statistics']
20,Alterative Sum of Squared Error formula proof,Alterative Sum of Squared Error formula proof,,"The well-known formula of calculating Sum of Squared Error for a cluster is this: SSE formula where ""c"" is the mean and ""x"" is the value of an observation. But this formula also brings the same result: Alternative SSE formula where ""m"" is the number of the observations and ""y"" takes in every iteration, values of the observations. For example, if we have {3, 7, 8} , our mean ""c"" = 6 and: Using the usual formula: (6-3)² + (6-7)² + (6-8)² = 14 Using the alternative formula: [ 1∕(2*3) ] × [ (3-3)² + (3-7)² + (3-8)² + (7-3)² + (7-7)² + (7-8)² + (8-3)² + (8-7)² + (8-8)²] = 14 Starting from the first formula, I 'm trying to prove the alternative, but I 'm lost. Can someone help me with the proof?","The well-known formula of calculating Sum of Squared Error for a cluster is this: SSE formula where ""c"" is the mean and ""x"" is the value of an observation. But this formula also brings the same result: Alternative SSE formula where ""m"" is the number of the observations and ""y"" takes in every iteration, values of the observations. For example, if we have {3, 7, 8} , our mean ""c"" = 6 and: Using the usual formula: (6-3)² + (6-7)² + (6-8)² = 14 Using the alternative formula: [ 1∕(2*3) ] × [ (3-3)² + (3-7)² + (3-8)² + (7-3)² + (7-7)² + (7-8)² + (8-3)² + (8-7)² + (8-8)²] = 14 Starting from the first formula, I 'm trying to prove the alternative, but I 'm lost. Can someone help me with the proof?",,['statistics']
21,Basic Statistical Values,Basic Statistical Values,,"I wanted to make my own problem and solve it to learn some new stuff -- Let's say we have some type of standardized test, where a rough data curve depicts $P(x)=x^2e^{-\frac{x}{14}}$ which is the number of people who got that score. Now, we have $\displaystyle \int_0^{100}P(x)\,dx = 5342.0$ approximately. So, we scale our probabilities so we have $\displaystyle p(x)=\frac{1}{5342}x^2e^{-\frac{x}{14}}$. Then, to get the mean, we evaluate $\displaystyle \int_0^{100}xp(x)\,dx$, right? I don't think we have to divide by $100$ because it's a weighted average and we have $p(x)$ being the weight of $x$. This would give us $39.928$, which kind of makes sense from the graph! Then, I think that variance would be $\displaystyle \int_0^{100}(x-39.928)^2p(x)\,dx=434.55$ Then, standard deviation would equal to $\sqrt{434.55}=\boxed{20.84}$ Are all my steps correct? What can I do with a standard deviation? Does the $68-95-99.7$ rule apply? UPDATE I now let $X$ range from $0$ to $+\infty$, and the results are really nice! We have the density $p(x)=\displaystyle \frac{1}{5488}x^2e^{-\frac{x}{14}}$ We have mean $42$. We have variance $588$. We have standard deviation $\sqrt{588}$.","I wanted to make my own problem and solve it to learn some new stuff -- Let's say we have some type of standardized test, where a rough data curve depicts $P(x)=x^2e^{-\frac{x}{14}}$ which is the number of people who got that score. Now, we have $\displaystyle \int_0^{100}P(x)\,dx = 5342.0$ approximately. So, we scale our probabilities so we have $\displaystyle p(x)=\frac{1}{5342}x^2e^{-\frac{x}{14}}$. Then, to get the mean, we evaluate $\displaystyle \int_0^{100}xp(x)\,dx$, right? I don't think we have to divide by $100$ because it's a weighted average and we have $p(x)$ being the weight of $x$. This would give us $39.928$, which kind of makes sense from the graph! Then, I think that variance would be $\displaystyle \int_0^{100}(x-39.928)^2p(x)\,dx=434.55$ Then, standard deviation would equal to $\sqrt{434.55}=\boxed{20.84}$ Are all my steps correct? What can I do with a standard deviation? Does the $68-95-99.7$ rule apply? UPDATE I now let $X$ range from $0$ to $+\infty$, and the results are really nice! We have the density $p(x)=\displaystyle \frac{1}{5488}x^2e^{-\frac{x}{14}}$ We have mean $42$. We have variance $588$. We have standard deviation $\sqrt{588}$.",,['statistics']
22,Variance Estimate in linear regression,Variance Estimate in linear regression,,"In a linear regression, $y=X\beta+\epsilon$, where $\epsilon\sim N(0, \sigma^2)$, $X\sim R^{N \times (p+1)}$. Assume the observations $y_i$ are uncorrelated and have constant variance $\sigma^2$, and that the $x_i$ are fixed. Then $\hat{\beta} = (X^T X)^{-1} X^T y$. One estimate the variance $\sigma^2$ by $\hat{\sigma}^2 = \frac{1}{N-p-1}\sum_{i=1}^N (y_i-\hat{y}_i)^2$. How to prove $E(\hat{\sigma}^2) = \sigma^2$? and why $\hat{\beta}\sim N(\beta, (X^T X)^{-1}\sigma^2)$ ? I know how to get the mean and variance of $\hat{\beta}$, but why it follows a normal distribution?","In a linear regression, $y=X\beta+\epsilon$, where $\epsilon\sim N(0, \sigma^2)$, $X\sim R^{N \times (p+1)}$. Assume the observations $y_i$ are uncorrelated and have constant variance $\sigma^2$, and that the $x_i$ are fixed. Then $\hat{\beta} = (X^T X)^{-1} X^T y$. One estimate the variance $\sigma^2$ by $\hat{\sigma}^2 = \frac{1}{N-p-1}\sum_{i=1}^N (y_i-\hat{y}_i)^2$. How to prove $E(\hat{\sigma}^2) = \sigma^2$? and why $\hat{\beta}\sim N(\beta, (X^T X)^{-1}\sigma^2)$ ? I know how to get the mean and variance of $\hat{\beta}$, but why it follows a normal distribution?",,"['statistics', 'machine-learning', 'linear-regression']"
23,How do I rate smoothness of discretely sampled data? (Picture!!!),How do I rate smoothness of discretely sampled data? (Picture!!!),,"In the sense that the following curves pictured in order will be rated 98%, 80%, 40%, 5% smooth approximating by eye. My ideas: (1) If the curves all follow some general shape like a polynomial curve then do curve fitting and calculate the total ""distance from the curve"" of the data. (2) Count the number of times a slope line between two datapoints intersects the data lines (line segments between data points) and divide by the number of data samples. Your ideas?","In the sense that the following curves pictured in order will be rated 98%, 80%, 40%, 5% smooth approximating by eye. My ideas: (1) If the curves all follow some general shape like a polynomial curve then do curve fitting and calculate the total ""distance from the curve"" of the data. (2) Count the number of times a slope line between two datapoints intersects the data lines (line segments between data points) and divide by the number of data samples. Your ideas?",,"['statistics', 'metric-spaces', 'graphing-functions', 'curvature']"
24,"Meaning of ""Percent increase""","Meaning of ""Percent increase""",,"When someone uses the phrase ""percent increase"" what does that mean? For example, if something took $4$ seconds before and now it takes $1$ second, would that be a $400$ % increase?","When someone uses the phrase ""percent increase"" what does that mean? For example, if something took seconds before and now it takes second, would that be a % increase?",4 1 400,"['statistics', 'percentages']"
25,Variance of a MLE $\sigma^2$ estimator; how to calculate,Variance of a MLE  estimator; how to calculate,\sigma^2,"Let $X_1, X_2,...,X_n$ be an i.i.d. random sample from $N(0, \sigma^{2})$. a. Find the variance of $\hat{\sigma}^{2}_{MLE}$ So I found $\hat{\sigma}^{2}_{MLE}$ by taking the derivative of the log of the normal pdf function, but from there I am not sure how to proceed. $\hat{\sigma}^{2}_{MLE}$ comes out to $\frac{\sum_{i=1}^n X_i^{2}}{n}$. From there, would I do $\text{var}\left(\frac{\sum_{i=1}^n X_i^{2}}{n}\right)$ ? How do I compute this? Thanks!","Let $X_1, X_2,...,X_n$ be an i.i.d. random sample from $N(0, \sigma^{2})$. a. Find the variance of $\hat{\sigma}^{2}_{MLE}$ So I found $\hat{\sigma}^{2}_{MLE}$ by taking the derivative of the log of the normal pdf function, but from there I am not sure how to proceed. $\hat{\sigma}^{2}_{MLE}$ comes out to $\frac{\sum_{i=1}^n X_i^{2}}{n}$. From there, would I do $\text{var}\left(\frac{\sum_{i=1}^n X_i^{2}}{n}\right)$ ? How do I compute this? Thanks!",,['statistics']
26,Why do p-values include the probability of obtaining more extreme values than the test statistic?,Why do p-values include the probability of obtaining more extreme values than the test statistic?,,"p -value is defined as ""the probability of obtaining a test statistic at least as extreme as the one that was actually observed, assuming that the null hypothesis is true"" . Why are all values more favourable to the alternative hypothesis than the one observed are considered when finding the p -value. Is there some intuitive explanation for this? (From a practical viewpoint, I do realize that in the case of a continuous random variable that the probability of getting some exact value is 0, and so it's impossible to consider the probability associated with the exact value of the test statistic.) The only attempt to answer this question I found was this PDF which equates p-values to Type I error rates. However, the Wikipedia p-value page also states that ""The p-value should not be confused with the Type I error rate [false positive rate] α in the Neyman–Pearson approach."" so I'm not sure how useful of an explanation that is.","p -value is defined as ""the probability of obtaining a test statistic at least as extreme as the one that was actually observed, assuming that the null hypothesis is true"" . Why are all values more favourable to the alternative hypothesis than the one observed are considered when finding the p -value. Is there some intuitive explanation for this? (From a practical viewpoint, I do realize that in the case of a continuous random variable that the probability of getting some exact value is 0, and so it's impossible to consider the probability associated with the exact value of the test statistic.) The only attempt to answer this question I found was this PDF which equates p-values to Type I error rates. However, the Wikipedia p-value page also states that ""The p-value should not be confused with the Type I error rate [false positive rate] α in the Neyman–Pearson approach."" so I'm not sure how useful of an explanation that is.",,['statistics']
27,Determining a confidence interval for $\sigma$ from a Rayleigh distribution,Determining a confidence interval for  from a Rayleigh distribution,\sigma,"Hello stackexchangers, Suppose we have $n$ Rayleigh distributions defined by $$f_X(x)=\frac{x}{\sigma^2}e^{-x^2/2\sigma^2}.$$ How would you go about determining an approximative confidence interval for $\sigma$? I got this problem from a dear friend, and he suggested that I use the method of least-squares on $\sigma$. Guided by his wisdom, I found the least-squares prediction to be $$\sigma^*=\bar{x}\sqrt{\frac{2}{\pi}},$$ where $\bar{x}$ is the mean value, but I am completely lost as to how to proceed. Any hints would be greatly appreciated. Your Mayor, Ron Ford","Hello stackexchangers, Suppose we have $n$ Rayleigh distributions defined by $$f_X(x)=\frac{x}{\sigma^2}e^{-x^2/2\sigma^2}.$$ How would you go about determining an approximative confidence interval for $\sigma$? I got this problem from a dear friend, and he suggested that I use the method of least-squares on $\sigma$. Guided by his wisdom, I found the least-squares prediction to be $$\sigma^*=\bar{x}\sqrt{\frac{2}{\pi}},$$ where $\bar{x}$ is the mean value, but I am completely lost as to how to proceed. Any hints would be greatly appreciated. Your Mayor, Ron Ford",,"['statistics', 'probability-distributions']"
28,Proof of Covariance,Proof of Covariance,,"I am dealing extremely often with the covariance during my statistics classes. However, the only proof I have found so far is  that. My question is, how to deal with the double integral of the covariance or is there another proof for the covariance? \begin{align}\text{Cov}(X,Y)& = \mathbb{E}(X- \mathbb{E}(X))(Y- \mathbb{E}(Y))\\ &= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\;(x- \mathbb{E}(X))(y- \mathbb{E}(Y))f(x,y)dx\;dy\\&= \mathbb{E}(XY)- \mathbb{E}(X)\mathbb{E}(Y)\; .\end{align} UPDATE Could that also be true? \begin{align}\text{Cov}(X,Y)&=\mathbb{E}(XY -X\mathbb{E}Y -Y\mathbb{E}X + \mathbb{E}X\mathbb{E}Y)\\&=\mathbb{E}(XY)- \mathbb{E}X\mathbb{E}Y -\mathbb{E}Y\mathbb{E}X + \mathbb{E}X \mathbb{E}Y\\&= \mathbb{E}(XY)- \mathbb{E}X \mathbb{E}Y \; . \end{align}","I am dealing extremely often with the covariance during my statistics classes. However, the only proof I have found so far is  that. My question is, how to deal with the double integral of the covariance or is there another proof for the covariance? \begin{align}\text{Cov}(X,Y)& = \mathbb{E}(X- \mathbb{E}(X))(Y- \mathbb{E}(Y))\\ &= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\;(x- \mathbb{E}(X))(y- \mathbb{E}(Y))f(x,y)dx\;dy\\&= \mathbb{E}(XY)- \mathbb{E}(X)\mathbb{E}(Y)\; .\end{align} UPDATE Could that also be true? \begin{align}\text{Cov}(X,Y)&=\mathbb{E}(XY -X\mathbb{E}Y -Y\mathbb{E}X + \mathbb{E}X\mathbb{E}Y)\\&=\mathbb{E}(XY)- \mathbb{E}X\mathbb{E}Y -\mathbb{E}Y\mathbb{E}X + \mathbb{E}X \mathbb{E}Y\\&= \mathbb{E}(XY)- \mathbb{E}X \mathbb{E}Y \; . \end{align}",,"['statistics', 'integration']"
29,Are coordinate projections in the Skorokhod space continuous?,Are coordinate projections in the Skorokhod space continuous?,,"I was wondering whether coordinate projections in the Skorokhod space $D[0,1]$ are actually continuous (and, if so, how can this be proven)? many thanks for any comments/ideas. cheers!","I was wondering whether coordinate projections in the Skorokhod space $D[0,1]$ are actually continuous (and, if so, how can this be proven)? many thanks for any comments/ideas. cheers!",,"['statistics', 'stochastic-processes', 'stochastic-calculus']"
30,Show a statistic is not sufficient,Show a statistic is not sufficient,,"Let $T$ be a sufficient statistic. Suppose $f(T)$ is not a one-to-one function of $T$. Show $f(T)$ is not a sufficient statistic. I think this should be proved by contradiction. Since $f$ is not one-to-one, $\exists t_1 \ne t_2 \ni g(t_1)=g(t_2)$. I sough a contradiction in the factorization theorem by writing $f_\theta(x)=h(x)g_\theta(f^{-1}\circ f(T(X)))$. But, I didn't succeed. I tried from the definition of a sufficient statistic, but I don't see a way there too. I think, the proof can be done without specifying a distribution for the sample. If that's not the case, we may assume, the sample comes from a $\operatorname{Bernouilli}(\theta)$.","Let $T$ be a sufficient statistic. Suppose $f(T)$ is not a one-to-one function of $T$. Show $f(T)$ is not a sufficient statistic. I think this should be proved by contradiction. Since $f$ is not one-to-one, $\exists t_1 \ne t_2 \ni g(t_1)=g(t_2)$. I sough a contradiction in the factorization theorem by writing $f_\theta(x)=h(x)g_\theta(f^{-1}\circ f(T(X)))$. But, I didn't succeed. I tried from the definition of a sufficient statistic, but I don't see a way there too. I think, the proof can be done without specifying a distribution for the sample. If that's not the case, we may assume, the sample comes from a $\operatorname{Bernouilli}(\theta)$.",,[]
31,How can I find the median of this frequency distribution,How can I find the median of this frequency distribution,,"How can we find out the median of a frequency distribution table?In fact, if you use a particular formula,it will be very kind of you to prove it(That's what I am really looking forward to) Thank you. Class boundary 60-70  70-80      80-90   90-100 Frequency         4        5       6          7 The respective frequencies are 4,5,6 and 7.","How can we find out the median of a frequency distribution table?In fact, if you use a particular formula,it will be very kind of you to prove it(That's what I am really looking forward to) Thank you. Class boundary 60-70  70-80      80-90   90-100 Frequency         4        5       6          7 The respective frequencies are 4,5,6 and 7.",,['statistics']
32,"Formulas or approximations for $\mathbb{E}\left( \frac{X}{\|X\|} \right)$ or $\mathbb{E}\left( \frac{X}{\|X\|^2} \right) $, $X\sim N(\mu, Id)$?","Formulas or approximations for  or , ?","\mathbb{E}\left( \frac{X}{\|X\|} \right) \mathbb{E}\left( \frac{X}{\|X\|^2} \right)  X\sim N(\mu, Id)","I want to compute or approximate the following expected values with some analytic expression: $\mathbb{E}\left( \frac{X}{\|X\|} \right)$ and $\mathbb{E}\left( \frac{X}{\|X\|^2} \right) $ , where $X \in \mathbb{R}^n$ is a multivariate isotropic, non-centered gaussian $X\sim N(\mu, Id)$ . For a general $X\sim N(\mu, \Sigma)$ Gaussian, the variable $\frac{X}{\|X\|}$ is called the general projected normal distribution. This is a complicated distribution, whose moments don't seem to have closed form formulas. However, for the simpler case where the covariance is the identity matrix, I wondered whether there's a way to obtain or approximate these expected values. This question comes close to what I need, asking for the expectation $\mathbb{E} \left( \frac{1}{1+\|X\|^2} \right)$ and someone posted an approximation. This other question asks for the second expectation, but asks specifically for the expectation formula, while I'm asking if there's some reasonable approximation. Edit: Cross posted in CV here","I want to compute or approximate the following expected values with some analytic expression: and , where is a multivariate isotropic, non-centered gaussian . For a general Gaussian, the variable is called the general projected normal distribution. This is a complicated distribution, whose moments don't seem to have closed form formulas. However, for the simpler case where the covariance is the identity matrix, I wondered whether there's a way to obtain or approximate these expected values. This question comes close to what I need, asking for the expectation and someone posted an approximation. This other question asks for the second expectation, but asks specifically for the expectation formula, while I'm asking if there's some reasonable approximation. Edit: Cross posted in CV here","\mathbb{E}\left( \frac{X}{\|X\|} \right) \mathbb{E}\left( \frac{X}{\|X\|^2} \right)  X \in \mathbb{R}^n X\sim N(\mu, Id) X\sim N(\mu, \Sigma) \frac{X}{\|X\|} \mathbb{E} \left( \frac{1}{1+\|X\|^2} \right)","['statistics', 'probability-distributions', 'moment-generating-functions']"
33,Prove consistency of MLE,Prove consistency of MLE,,"Let be $(X_1,Y_1),...,(X_n,Y_n)$ n independent couples of random variables where $X_i\sim{Binom(10,\theta)}$ and $Y_i|X_i=x_i\sim{Pois(\lambda{(1+x_i)})}$ . I found the MLE for $\lambda$ , which is: $$ \hat{\lambda}={\sum_{i=1}^n{Y_i}\over{n+\sum_{i=1}^n{X_i}}}. $$ How can I prove that it is a consistent estimator for $\lambda$ ?","Let be n independent couples of random variables where and . I found the MLE for , which is: How can I prove that it is a consistent estimator for ?","(X_1,Y_1),...,(X_n,Y_n) X_i\sim{Binom(10,\theta)} Y_i|X_i=x_i\sim{Pois(\lambda{(1+x_i)})} \lambda 
\hat{\lambda}={\sum_{i=1}^n{Y_i}\over{n+\sum_{i=1}^n{X_i}}}.
 \lambda","['statistics', 'statistical-inference', 'maximum-likelihood']"
34,Asymmetric confidence intervals,Asymmetric confidence intervals,,"Suppose we have iid data $X_i$ with known variance $\sigma^2$ , and wish to write an asymptotic $1-\alpha $ coverage CI for the population mean $\mu$ . CLT implies that if $z_q$ represents the $q$ quantile of a standard normal, $$z_{\alpha/2}=-z_{1-\alpha/2}\leq \frac{\bar X-\mu}{\sigma/\sqrt  n}\leq z_{1-\alpha/2}$$ occurs (asymptotically) with probability $1-\alpha$ and thus implies a CI for $\mu$ of $\bar X\pm z_{1-\alpha/2}\frac{\sigma}{\sqrt n}.$ Any particular reason we take symmetric bounds, or is this just a matter of simplicity? For instance, it seems to me we could have also used $$ z_{q_1}\leq \frac{\bar X-\mu}{\sigma/\sqrt  n}\leq z_{q_2}$$ for any $q_2-q_1=1-\alpha.$ Update: By ""symmetric,"" I mean using $q_2=1-q_1.$","Suppose we have iid data with known variance , and wish to write an asymptotic coverage CI for the population mean . CLT implies that if represents the quantile of a standard normal, occurs (asymptotically) with probability and thus implies a CI for of Any particular reason we take symmetric bounds, or is this just a matter of simplicity? For instance, it seems to me we could have also used for any Update: By ""symmetric,"" I mean using",X_i \sigma^2 1-\alpha  \mu z_q q z_{\alpha/2}=-z_{1-\alpha/2}\leq \frac{\bar X-\mu}{\sigma/\sqrt  n}\leq z_{1-\alpha/2} 1-\alpha \mu \bar X\pm z_{1-\alpha/2}\frac{\sigma}{\sqrt n}.  z_{q_1}\leq \frac{\bar X-\mu}{\sigma/\sqrt  n}\leq z_{q_2} q_2-q_1=1-\alpha. q_2=1-q_1.,"['statistics', 'statistical-inference', 'confidence-interval']"
35,Meaning of linearity in statistics vs linearity in linear algebra,Meaning of linearity in statistics vs linearity in linear algebra,,"I've noticed that in Statistics, when the topic of ""linearity"" comes up, what is usually meant is that a fit can be made with a function of the form $\mathbb{R} \mapsto \mathbb{R}: y(x)= mx+q$ Now in linear algebra this is obviously not true (equations of the form y=mx+q are not necessarily linear). Am i mistaking something or is this just a point where statisticans and mathematicians use the same words for different things?","I've noticed that in Statistics, when the topic of ""linearity"" comes up, what is usually meant is that a fit can be made with a function of the form Now in linear algebra this is obviously not true (equations of the form y=mx+q are not necessarily linear). Am i mistaking something or is this just a point where statisticans and mathematicians use the same words for different things?",\mathbb{R} \mapsto \mathbb{R}: y(x)= mx+q,"['linear-algebra', 'statistics']"
36,2 values expected value problem,2 values expected value problem,,"A bank account has 1000 dollars and get's a 5% interest daily. Every day the account has $0.405$ probability to lose $20$ dollars. What's the mean of the amount of money in the acount after 2 days? I thought about calculating $((1000-20*0.405)*1.05-20*0.405)*1.05$ But I think it might be wrong because the probabiltity changes depending on the previous day. I mean that the probability to lose in both days is $0.405^2$ , one day lose and the other no lose would be $0.405*(1-0.405)$ to my understaing, so I would need to take it into acount somehow but don't know how. thank you.","A bank account has 1000 dollars and get's a 5% interest daily. Every day the account has probability to lose dollars. What's the mean of the amount of money in the acount after 2 days? I thought about calculating But I think it might be wrong because the probabiltity changes depending on the previous day. I mean that the probability to lose in both days is , one day lose and the other no lose would be to my understaing, so I would need to take it into acount somehow but don't know how. thank you.",0.405 20 ((1000-20*0.405)*1.05-20*0.405)*1.05 0.405^2 0.405*(1-0.405),['statistics']
37,What is the median of an empty set?,What is the median of an empty set?,,The median of a singleton set is the element itself. The median of a set with two elements is the average of the elements. What should a machine return when required the median of an empty set?,The median of a singleton set is the element itself. The median of a set with two elements is the average of the elements. What should a machine return when required the median of an empty set?,,['statistics']
38,Probability of nth draw being same value,Probability of nth draw being same value,,"Disclaimer at the beginning: this does relate to a homework problem, but is not the actual homework problem itself. Consider a series of numbers, $1, 2,...,n$ . We select one value at a time at random from this sequence (with replacement) until we select a value that has already been selected before. Let $D_n$ be the draw on which we select a value that has been selected before. $D_n$ clearly only takes on values from $2$ to $n+1$ . Now, the homework problem asks us to show that (but this is not what I'm asking about): $$\lim_{n \to \infty}P\{\frac{D_n}{\sqrt{n}}>x\}=e^{\frac{-x^2}{2}}$$ However, what I'm curious to know about is the probability $P\{D_n=t\}$ . In my calculation, there are $n^{n+1}$ possible ways of making $n+1$ draws of n values. And, there are $$n(n-1)(n-2)...(n-t+1)\binom{n-1}{1}(n^{n-t+1})=\frac{n!(n-1)(n^{n-t+1})}{(n-t+1)!}$$ ways of having exactly two values in t draws be equal. So, then the $P\{D_n=t\}$ : $$P\{D_n=t\}=\frac{n!(n-1)(n^{n-t+1})}{(n-t+1)!}*\frac{1}{n^{n+1}}$$ $$=\frac{n!(n-1)(n^{-t})}{(n-t+1)!}$$ However, I know this must be wrong because as $n \to \infty$ , this is (according to Mathematica), unbounded. Where am I going wrong?","Disclaimer at the beginning: this does relate to a homework problem, but is not the actual homework problem itself. Consider a series of numbers, . We select one value at a time at random from this sequence (with replacement) until we select a value that has already been selected before. Let be the draw on which we select a value that has been selected before. clearly only takes on values from to . Now, the homework problem asks us to show that (but this is not what I'm asking about): However, what I'm curious to know about is the probability . In my calculation, there are possible ways of making draws of n values. And, there are ways of having exactly two values in t draws be equal. So, then the : However, I know this must be wrong because as , this is (according to Mathematica), unbounded. Where am I going wrong?","1, 2,...,n D_n D_n 2 n+1 \lim_{n \to \infty}P\{\frac{D_n}{\sqrt{n}}>x\}=e^{\frac{-x^2}{2}} P\{D_n=t\} n^{n+1} n+1 n(n-1)(n-2)...(n-t+1)\binom{n-1}{1}(n^{n-t+1})=\frac{n!(n-1)(n^{n-t+1})}{(n-t+1)!} P\{D_n=t\} P\{D_n=t\}=\frac{n!(n-1)(n^{n-t+1})}{(n-t+1)!}*\frac{1}{n^{n+1}} =\frac{n!(n-1)(n^{-t})}{(n-t+1)!} n \to \infty","['statistics', 'permutations']"
39,Minimum mean squared error of an estimator of the variance of the normal distribution [duplicate],Minimum mean squared error of an estimator of the variance of the normal distribution [duplicate],,"This question already has an answer here : Variance with minimal MSE in normal distribution (1 answer) Closed 4 years ago . I am trying to find the estimator of the variance $\sigma^2$ of a normal distribution with the minimum mean square error. From reading up, I know the unbiased estimator of the variance of a Guassian is  $\frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2$ and that the estimator I am looking for is a scaled version of this unbiased estimator. The question is from a problem sheet from the last academic year. The specific question is: Let $X_1, \dots, X_n$ be a simple random sample from a normal distribution with unknown mean $\mu$ and variance $\sigma^2$. Consider estimators of $\sigma^2$ of the form $k \sum_{i=1}^{n}(X_i - \bar{X})^2$ and find the value of $k$ that minimises the mean square error. What is the efficiency of the usual unbiased estimator relative to this estimator, if the relative efficiency is defined as the ratio of the mean squared error? For the first part, I think I am meant to rewrite the MSE of the estimator as an expectation and then take derivatives with respect to $k$. This is what I have so far: $$ \begin{align} MSE(\hat{\theta}) &= \mathbb{E} \left[ (\hat{\theta} - \theta)^2 \right] \\ &= \mathbb{E} \left[ \left(k \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X})^2 - \sigma^2 \right)^2 \right] \\ &= \mathbb{E} \left[ \left(k \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X} )^2 \right)^2 - 2 \left( k \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X})^2 \right) \sigma^2 + \sigma^4 \right]  \end{align} $$ But however else I continue from here, I can't find a way that gets me to $ k = \frac{1}{n + 1}$, which the Wikipedia article linked to below suggests is the answer. For the second part, I think I can use the MSE of the unbiased estimator given in the Wikipedia article to find the efficiency, although it would be really helpful to see the steps that one takes to calculate this MSE, as in the article it is just stated. My question is linked to this one , although less advanced. The Wikipedia article on the MSE linked to in the question above is also relevant, although there they also calculate $ \mathbb{E} [S^4_{n-1}]$, which I'm not sure about.","This question already has an answer here : Variance with minimal MSE in normal distribution (1 answer) Closed 4 years ago . I am trying to find the estimator of the variance $\sigma^2$ of a normal distribution with the minimum mean square error. From reading up, I know the unbiased estimator of the variance of a Guassian is  $\frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2$ and that the estimator I am looking for is a scaled version of this unbiased estimator. The question is from a problem sheet from the last academic year. The specific question is: Let $X_1, \dots, X_n$ be a simple random sample from a normal distribution with unknown mean $\mu$ and variance $\sigma^2$. Consider estimators of $\sigma^2$ of the form $k \sum_{i=1}^{n}(X_i - \bar{X})^2$ and find the value of $k$ that minimises the mean square error. What is the efficiency of the usual unbiased estimator relative to this estimator, if the relative efficiency is defined as the ratio of the mean squared error? For the first part, I think I am meant to rewrite the MSE of the estimator as an expectation and then take derivatives with respect to $k$. This is what I have so far: $$ \begin{align} MSE(\hat{\theta}) &= \mathbb{E} \left[ (\hat{\theta} - \theta)^2 \right] \\ &= \mathbb{E} \left[ \left(k \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X})^2 - \sigma^2 \right)^2 \right] \\ &= \mathbb{E} \left[ \left(k \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X} )^2 \right)^2 - 2 \left( k \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X})^2 \right) \sigma^2 + \sigma^4 \right]  \end{align} $$ But however else I continue from here, I can't find a way that gets me to $ k = \frac{1}{n + 1}$, which the Wikipedia article linked to below suggests is the answer. For the second part, I think I can use the MSE of the unbiased estimator given in the Wikipedia article to find the efficiency, although it would be really helpful to see the steps that one takes to calculate this MSE, as in the article it is just stated. My question is linked to this one , although less advanced. The Wikipedia article on the MSE linked to in the question above is also relevant, although there they also calculate $ \mathbb{E} [S^4_{n-1}]$, which I'm not sure about.",,"['statistics', 'normal-distribution', 'variance', 'parameter-estimation', 'mean-square-error']"
40,Statistical error associated with a bin count,Statistical error associated with a bin count,,"I have a collection of data points. I have computed the histogram of this data to create the empirical distribution. How can estimated the error in the value at each bin. Based on the the total number of data points and the counts at each bin. The data comes from chemical random reactions, between two states. The total number of events may vary according to the lifetime of chemicals used, but considerable big >>5000 data points. The number of bins used is 100 and of homogeneous width.  The intention of estimate the error is to propagate this error trough an equation that depends on the distribution of the process and therefore estimate the error of the quantity computed from this histogram.","I have a collection of data points. I have computed the histogram of this data to create the empirical distribution. How can estimated the error in the value at each bin. Based on the the total number of data points and the counts at each bin. The data comes from chemical random reactions, between two states. The total number of events may vary according to the lifetime of chemicals used, but considerable big >>5000 data points. The number of bins used is 100 and of homogeneous width.  The intention of estimate the error is to propagate this error trough an equation that depends on the distribution of the process and therefore estimate the error of the quantity computed from this histogram.",,"['statistics', 'error-propagation', 'standard-error']"
41,Difference between sufficient and non sufficient statistics,Difference between sufficient and non sufficient statistics,,"I have a few questions here. Could someone please give me (in plain English, avoiding as much statistical jargon as possible and resorting to examples one might understand with a only a basic knowledge of statistics and/or mathematics whenever possible) an example of a non sufficient statistic, and go on to explain why it isn't sufficient? When we say ""sufficient,"" what does that mean? Sufficient for... what exactly? Why is it so important? What makes a sufficient statistic sufficient?","I have a few questions here. Could someone please give me (in plain English, avoiding as much statistical jargon as possible and resorting to examples one might understand with a only a basic knowledge of statistics and/or mathematics whenever possible) an example of a non sufficient statistic, and go on to explain why it isn't sufficient? When we say ""sufficient,"" what does that mean? Sufficient for... what exactly? Why is it so important? What makes a sufficient statistic sufficient?",,"['statistics', 'statistical-inference']"
42,Orthogonality of random vectors and the inner product,Orthogonality of random vectors and the inner product,,"An acclaimed answer to the question What does orthogonal mean in statistics? is beautifully stripped down to $$\mathbb E[\mathbf {XY^*}]=0$$ I am not familiar with the operations involved, not just because of the inclusion of complex numbers, but most important, because I don't see the use of the inner product in this context. In this post : The vector space $\mathscr L_2$ of real-valued random variables on $(\Omega,\mathscr F,\mathbb P)$ (modulo equivalence of course) with finite   second moment is special, because it's the only one in which the norm   corresponds to an inner product. If $X$ and $Y$ are random variables   in $\mathscr L_2$, we define the inner product of $X$ and $Y$ by $⟨X,Y⟩=\mathbb E[XY]$ In relations to the comments below I find this quote on Wikipedia : For real random variables $X$ and $Y$, the expected value of their   product $\displaystyle \langle X,Y\rangle :=\operatorname {E} (XY)$ is   an inner product. This definition of expectation as inner product can   be extended to random vectors as well. The actual hurdle: Now, this inner product is not the dot product of two vectors, is it? If the idea is to multiply the elements of two random vectors $X$ and $Y$ and then perform the inner product of this multiplication vector with itself, we'd be getting $[XY]^2$ - more like a norm... I think there is more to inner product, included in the quotes I pasted above, and requiring knowledge of abstract algebra. This probably includes the concept of the vector space $\mathscr L_2$. What I got so far: Since, \begin{align} Cov[X,Y]=&E[(X−E[X])\cdot(Y−E[Y])]\\ &=E[X\cdot Y]−E[X\cdot E[Y]]−E[E[X]\cdot Y]+E[E[X]\cdot E[Y]]\\ &=E[X\cdot Y]−E[X]\cdot E[Y] \end{align} ​ and consequently, $$E[XY]=Cov[X,Y]+E[X]\cdot E[Y],$$ real-valued random variables $X$ and $Y$ are uncorrelated (different from independent) if and only if the centered variables $X-E(X)$ and $Y-E(Y)$ are orthogonal : $E[XY]=0.$","An acclaimed answer to the question What does orthogonal mean in statistics? is beautifully stripped down to $$\mathbb E[\mathbf {XY^*}]=0$$ I am not familiar with the operations involved, not just because of the inclusion of complex numbers, but most important, because I don't see the use of the inner product in this context. In this post : The vector space $\mathscr L_2$ of real-valued random variables on $(\Omega,\mathscr F,\mathbb P)$ (modulo equivalence of course) with finite   second moment is special, because it's the only one in which the norm   corresponds to an inner product. If $X$ and $Y$ are random variables   in $\mathscr L_2$, we define the inner product of $X$ and $Y$ by $⟨X,Y⟩=\mathbb E[XY]$ In relations to the comments below I find this quote on Wikipedia : For real random variables $X$ and $Y$, the expected value of their   product $\displaystyle \langle X,Y\rangle :=\operatorname {E} (XY)$ is   an inner product. This definition of expectation as inner product can   be extended to random vectors as well. The actual hurdle: Now, this inner product is not the dot product of two vectors, is it? If the idea is to multiply the elements of two random vectors $X$ and $Y$ and then perform the inner product of this multiplication vector with itself, we'd be getting $[XY]^2$ - more like a norm... I think there is more to inner product, included in the quotes I pasted above, and requiring knowledge of abstract algebra. This probably includes the concept of the vector space $\mathscr L_2$. What I got so far: Since, \begin{align} Cov[X,Y]=&E[(X−E[X])\cdot(Y−E[Y])]\\ &=E[X\cdot Y]−E[X\cdot E[Y]]−E[E[X]\cdot Y]+E[E[X]\cdot E[Y]]\\ &=E[X\cdot Y]−E[X]\cdot E[Y] \end{align} ​ and consequently, $$E[XY]=Cov[X,Y]+E[X]\cdot E[Y],$$ real-valued random variables $X$ and $Y$ are uncorrelated (different from independent) if and only if the centered variables $X-E(X)$ and $Y-E(Y)$ are orthogonal : $E[XY]=0.$",,"['statistics', 'complex-numbers', 'vectors']"
43,5 number summary vs mean and standard deviation,5 number summary vs mean and standard deviation,,Hello i have a few numbers and i want to describe them using the best tool for this case: Either the 5-number summary or the mean and the standard deviation .But since i am statistics newbie i dont know when 5NS is better than mean and SD.In this specific case we have the following numbers: 130 125 107 97 96 94 86 83 82 81 58 55 54 52 48 47 45 45 42 41 39 39 39 38 36 35 34 5NS give us : Minimum.   1st Quartile.   Median.     3rd Quartile.      Maximum.       34.0      40.0          52.0          84.5            130.0 and mean with standard deviaton give us: mean=64 and standard devation = 26.19 Which one is better to describe our data in this case and when is 5NS better to use than Mean and SD??,Hello i have a few numbers and i want to describe them using the best tool for this case: Either the 5-number summary or the mean and the standard deviation .But since i am statistics newbie i dont know when 5NS is better than mean and SD.In this specific case we have the following numbers: 130 125 107 97 96 94 86 83 82 81 58 55 54 52 48 47 45 45 42 41 39 39 39 38 36 35 34 5NS give us : Minimum.   1st Quartile.   Median.     3rd Quartile.      Maximum.       34.0      40.0          52.0          84.5            130.0 and mean with standard deviaton give us: mean=64 and standard devation = 26.19 Which one is better to describe our data in this case and when is 5NS better to use than Mean and SD??,,"['statistics', 'standard-deviation', 'means']"
44,Populations and Sample Spaces,Populations and Sample Spaces,,"I have been reading the book ""Introduction To Statistics, A Customised Edition of Statistics For Business and Economics"" by P. Newbold et al. As I understand their statement of classical probability: ... Classical probability is the propertion of times that an event will occur assuming that all outcomes in are sample space a equally likely to occur... So as I understand it, we assume each outcome is equally likely, so for, say a die roll my sample space, the set of all possible outcomes of a random experiment, is {1, 2, 3, 4, 5, 6} . Ie. $$    P(A)=\frac{number\ of\ outcomes\ relevant\ to\ event\ A}{total\ number\ of\ outcomes} = \frac{N_A}{N} $$ My first question had been: Is it correct to say that we have to assume each outcome is equally likely? My thinking had been this: So if I want the probability I roll a 6, for example, the number of relevant outputs is len({6}) = 1 and the total number of outcomes is len({1,2,3,4,5,6}) = 6 , so I would say P(6) is 1/6. But what if my dice is unfair. How can I represent this in classical probability? The number of outcomes remain the same... what tools does classic probability have to allow for this? Or is this where relative frequency probability is required? The reason I was asking is that I couldn't see how we could, using classical probability, model a biased dice for example. I think now that it can't and that to  model events of unequal probability we need relative frequency probability. All I was asking for was confirmation that my thinking on this was correct. It seems there has been quite dome disagreement on it, but above is a verbatim quote from the book. So... given this, the book also makes the following definitions: Sample Space = The set of all possible basic outcomes from a random experiment. Population = The complete set of items or ""events"" of interest. Size is very large, denoted N, possibly infinite. So my next question had been, Is the ""sample space"" in this case (for classical probability) also the population? . Still not sure if sample space is the same as population: I have understood ""sample space"" as ""the set of all possible basic outcomes from a random experiment."" I have understood population as ""the complete set of items or ""events"" of interest""... so surely all possible results of an experiment must be the complete set of items of interest, so the two terms are equivalent? This seems wrong to me, but I don't have a grasp as to why? In fact even in relative frequency probability, how do these two terms really differ.","I have been reading the book ""Introduction To Statistics, A Customised Edition of Statistics For Business and Economics"" by P. Newbold et al. As I understand their statement of classical probability: ... Classical probability is the propertion of times that an event will occur assuming that all outcomes in are sample space a equally likely to occur... So as I understand it, we assume each outcome is equally likely, so for, say a die roll my sample space, the set of all possible outcomes of a random experiment, is {1, 2, 3, 4, 5, 6} . Ie. $$    P(A)=\frac{number\ of\ outcomes\ relevant\ to\ event\ A}{total\ number\ of\ outcomes} = \frac{N_A}{N} $$ My first question had been: Is it correct to say that we have to assume each outcome is equally likely? My thinking had been this: So if I want the probability I roll a 6, for example, the number of relevant outputs is len({6}) = 1 and the total number of outcomes is len({1,2,3,4,5,6}) = 6 , so I would say P(6) is 1/6. But what if my dice is unfair. How can I represent this in classical probability? The number of outcomes remain the same... what tools does classic probability have to allow for this? Or is this where relative frequency probability is required? The reason I was asking is that I couldn't see how we could, using classical probability, model a biased dice for example. I think now that it can't and that to  model events of unequal probability we need relative frequency probability. All I was asking for was confirmation that my thinking on this was correct. It seems there has been quite dome disagreement on it, but above is a verbatim quote from the book. So... given this, the book also makes the following definitions: Sample Space = The set of all possible basic outcomes from a random experiment. Population = The complete set of items or ""events"" of interest. Size is very large, denoted N, possibly infinite. So my next question had been, Is the ""sample space"" in this case (for classical probability) also the population? . Still not sure if sample space is the same as population: I have understood ""sample space"" as ""the set of all possible basic outcomes from a random experiment."" I have understood population as ""the complete set of items or ""events"" of interest""... so surely all possible results of an experiment must be the complete set of items of interest, so the two terms are equivalent? This seems wrong to me, but I don't have a grasp as to why? In fact even in relative frequency probability, how do these two terms really differ.",,['statistics']
45,"Why is the ""wrong"" interpretation of confidence intervals still seemingly correct?","Why is the ""wrong"" interpretation of confidence intervals still seemingly correct?",,"According to online sources, if you are operating at 95% confidence, it means if you repeated a sampling process many times and then looked at the 95% confidence intervals over all the results, 95% of the time the brackets would contain the true population mean. But then they say that it is NOT the same as saying ""you can be 95% confident that the intervals you computed contain the population mean."" Isn't it, though? For instance I do my first experiment and get a 95% confidence interval. Then a second. Third, fourth, ..., 100th. 95 of those intervals should contain the population mean. Is this correct so far? If so, then why isn't it the same as me saying, from the moment I did the very first test, ""this particular interval has a 95% chance at being one of the intervals that contain the true population mean""?","According to online sources, if you are operating at 95% confidence, it means if you repeated a sampling process many times and then looked at the 95% confidence intervals over all the results, 95% of the time the brackets would contain the true population mean. But then they say that it is NOT the same as saying ""you can be 95% confident that the intervals you computed contain the population mean."" Isn't it, though? For instance I do my first experiment and get a 95% confidence interval. Then a second. Third, fourth, ..., 100th. 95 of those intervals should contain the population mean. Is this correct so far? If so, then why isn't it the same as me saying, from the moment I did the very first test, ""this particular interval has a 95% chance at being one of the intervals that contain the true population mean""?",,['statistics']
46,Lacking in the Intuition behind the Logistic Regression Cost and Update Functions,Lacking in the Intuition behind the Logistic Regression Cost and Update Functions,,"I am lacking in intuition about the logistic regression cost and update functions. For example, in the cost function of where why is log used. Is it just to make computations easier? Could log not be used and still work the same? Since likelihood is the inverse of probrability couldn't the inverse of the sigmoid function be used instead? Also, is there any reason other than a coincidence, that the derivative of both the logistic and linear regression is the cost function times $x^(i)$ ?","I am lacking in intuition about the logistic regression cost and update functions. For example, in the cost function of where why is log used. Is it just to make computations easier? Could log not be used and still work the same? Since likelihood is the inverse of probrability couldn't the inverse of the sigmoid function be used instead? Also, is there any reason other than a coincidence, that the derivative of both the logistic and linear regression is the cost function times ?",x^(i),"['calculus', 'linear-algebra', 'statistics', 'machine-learning']"
47,"If $Y=X\beta+\epsilon$, prove that the least square estimator $\hat\beta$ is independent of $Y-X\hat{\beta}$","If , prove that the least square estimator  is independent of",Y=X\beta+\epsilon \hat\beta Y-X\hat{\beta},"Let $Y=X\beta+\epsilon$, where $Y$ is an $n$ by $1$ vector, $X$ is an $n$ by $p$ matrix with full rank and $\epsilon$ is an $n$ by 1 vector of random errors independently and normally distribution with mean vector $0$ and variance-covariance matrix $\Sigma=\sigma^2 I$, with $0$ being an $n$ by $1$ vector of zeros and $I$ being the $n$ by $n$ identity matrix. Prove the least square estimator $\hat{\beta}$ and $Y-X\hat{\beta}$ are independent vectors. I already get $\hat{\beta}=(X^TX)^{-1}X^{T}Y$. But I tried to prove independence, but I cannot.","Let $Y=X\beta+\epsilon$, where $Y$ is an $n$ by $1$ vector, $X$ is an $n$ by $p$ matrix with full rank and $\epsilon$ is an $n$ by 1 vector of random errors independently and normally distribution with mean vector $0$ and variance-covariance matrix $\Sigma=\sigma^2 I$, with $0$ being an $n$ by $1$ vector of zeros and $I$ being the $n$ by $n$ identity matrix. Prove the least square estimator $\hat{\beta}$ and $Y-X\hat{\beta}$ are independent vectors. I already get $\hat{\beta}=(X^TX)^{-1}X^{T}Y$. But I tried to prove independence, but I cannot.",,"['linear-algebra', 'statistics', 'normal-distribution', 'linear-regression']"
48,"Continuous time markov chains, is this step by step example correct","Continuous time markov chains, is this step by step example correct",,"I have some questions regarding CTMC... and most importantly whether the step-by-step example I provide below is correct. My main sources about CTMC are: ( [1] , and [2] ). Let's assume 3 possible states $S = {1, 2, 3}$. There are the following data instances $D = {d_1, d_2, d_3, d_4}$ from which I want to model as a CTMC. In parenthesis the time spent at the state before transiting to the next. $ d_1 = 1(3min) \rightarrow 2(3min) \rightarrow 3\\ d_2 = 1(8min) \rightarrow 2(12min) \rightarrow 3\\ d_3 = 1(2min) \rightarrow 3\\ d_4 = 2(2min) \rightarrow 3 $ The main question(s) I want to ask and answer from the CTMC is: Problem: What is the probability of transiting from state $i$ to state $j$ given that $s$ time has elapsed since entering state $i$? So to form the CTMC I start with the embedded transition matrix for $D$ which is: $ p_{ij} = \begin{bmatrix} 0 & 2/3 & 1/3 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \end{bmatrix} $ Now the next step is to calculate the rates. From [1, p3] it says that ""Each time state i is visited, the chain spends, on average, $E(Hi) = 1/a_i$ units of time there before moving on"" . From what I understand $a_i$ is the set of rates for state $i$, also denoted in other texts as $\lambda_i$ or $v_i$, for example an operator receives 2 calls in an hour, hence $a_i = 1$ call in half an hour. However, I am not sure how to calculate this from the above data $D$. But, I can calculate the average time spent at each state and then from the above equation, solving for $a_i = 1 / E(H_i)$ I can obtain these rates... $E(H_i) = \begin{bmatrix}4.33 & 5.66 & 0 \end{bmatrix}$, denoting with 0 the terminal (consume) state. Hence, $a_i = \begin{bmatrix}0.23 & 0.18 & 0 \end{bmatrix}$, again 0 is for consume state. Q1: Is this valid? Q2: Given that in this way I assume that the probability distribution of time spent is an exponential distribution, I lose the true variance of the actual distribution as the variance of the exponential distribution is the same as the mean... Is this OK? Is there any other way? Q3: How can terminal/consume states be represented? Again from [1, p3] I can now compute the transition rate matrix (infinitesimal generator) $Q$: $Q_{ij} = -a_i$, if $i==j$ $Q_{ij} = a_i * p_{ij}$, if $i != j$ $ Q = \begin{bmatrix} -0.23 & 0.15 & 0.08\\ 0 & -0.18 & 0.18\\ 0 & 0 & 0 \end{bmatrix} $ Q4: Although [1, p3] states that $Q_{ii} = -a_i$, [2, p227] says that $Q_{ii} = 0$. Which one is correct then? Now that we know $Q$, from [1, p2] I can calculate $P_{ij}(t)$ as follows: $P_{ij}(t) = e^{Qt}$ (from what I read there are a number of ways to compute that and I can use a numerical software that implements them) Q5: I assume $t = s$, ie the elapsed time since entering state $i$ Q6: Why do I need to calculate the complete matrix $P_{ij}(t)$ if I am interested in one particular ${ij}$. Is there any way to calculate that. Q7: I read in [2, p.228] that if the process can be modelled as a Poisson process then the solution is: $P_{ij}(t) = \dfrac{(\lambda_i t)^k}{k!}e^{-\lambda_i t}$, where $k$ is the number of events in an interval of length t, which in my case above is $1$. Can I assume that the above process is a Poisson process? Q8: And lastly is everything I have explained in the above step-by-step example correct? Thank you the most for your time reading this and if you can provide any answers to my questions.","I have some questions regarding CTMC... and most importantly whether the step-by-step example I provide below is correct. My main sources about CTMC are: ( [1] , and [2] ). Let's assume 3 possible states $S = {1, 2, 3}$. There are the following data instances $D = {d_1, d_2, d_3, d_4}$ from which I want to model as a CTMC. In parenthesis the time spent at the state before transiting to the next. $ d_1 = 1(3min) \rightarrow 2(3min) \rightarrow 3\\ d_2 = 1(8min) \rightarrow 2(12min) \rightarrow 3\\ d_3 = 1(2min) \rightarrow 3\\ d_4 = 2(2min) \rightarrow 3 $ The main question(s) I want to ask and answer from the CTMC is: Problem: What is the probability of transiting from state $i$ to state $j$ given that $s$ time has elapsed since entering state $i$? So to form the CTMC I start with the embedded transition matrix for $D$ which is: $ p_{ij} = \begin{bmatrix} 0 & 2/3 & 1/3 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \end{bmatrix} $ Now the next step is to calculate the rates. From [1, p3] it says that ""Each time state i is visited, the chain spends, on average, $E(Hi) = 1/a_i$ units of time there before moving on"" . From what I understand $a_i$ is the set of rates for state $i$, also denoted in other texts as $\lambda_i$ or $v_i$, for example an operator receives 2 calls in an hour, hence $a_i = 1$ call in half an hour. However, I am not sure how to calculate this from the above data $D$. But, I can calculate the average time spent at each state and then from the above equation, solving for $a_i = 1 / E(H_i)$ I can obtain these rates... $E(H_i) = \begin{bmatrix}4.33 & 5.66 & 0 \end{bmatrix}$, denoting with 0 the terminal (consume) state. Hence, $a_i = \begin{bmatrix}0.23 & 0.18 & 0 \end{bmatrix}$, again 0 is for consume state. Q1: Is this valid? Q2: Given that in this way I assume that the probability distribution of time spent is an exponential distribution, I lose the true variance of the actual distribution as the variance of the exponential distribution is the same as the mean... Is this OK? Is there any other way? Q3: How can terminal/consume states be represented? Again from [1, p3] I can now compute the transition rate matrix (infinitesimal generator) $Q$: $Q_{ij} = -a_i$, if $i==j$ $Q_{ij} = a_i * p_{ij}$, if $i != j$ $ Q = \begin{bmatrix} -0.23 & 0.15 & 0.08\\ 0 & -0.18 & 0.18\\ 0 & 0 & 0 \end{bmatrix} $ Q4: Although [1, p3] states that $Q_{ii} = -a_i$, [2, p227] says that $Q_{ii} = 0$. Which one is correct then? Now that we know $Q$, from [1, p2] I can calculate $P_{ij}(t)$ as follows: $P_{ij}(t) = e^{Qt}$ (from what I read there are a number of ways to compute that and I can use a numerical software that implements them) Q5: I assume $t = s$, ie the elapsed time since entering state $i$ Q6: Why do I need to calculate the complete matrix $P_{ij}(t)$ if I am interested in one particular ${ij}$. Is there any way to calculate that. Q7: I read in [2, p.228] that if the process can be modelled as a Poisson process then the solution is: $P_{ij}(t) = \dfrac{(\lambda_i t)^k}{k!}e^{-\lambda_i t}$, where $k$ is the number of events in an interval of length t, which in my case above is $1$. Can I assume that the above process is a Poisson process? Q8: And lastly is everything I have explained in the above step-by-step example correct? Thank you the most for your time reading this and if you can provide any answers to my questions.",,"['statistics', 'markov-chains', 'markov-process']"
49,Exponential of Squared Brownian Motion,Exponential of Squared Brownian Motion,,"Long time lurker, first time posting! Have a problem, that looks familiar but I can't put my finger on it. Need to calculate  $\mathbb{E} [\exp(aW_T^2)|F_t]$ where $W_t$ is an $F_t$ adapted standard Brownian motion and $t \leq T$. Any help on exponentials of squared Brownian motion is very appreciated!","Long time lurker, first time posting! Have a problem, that looks familiar but I can't put my finger on it. Need to calculate  $\mathbb{E} [\exp(aW_T^2)|F_t]$ where $W_t$ is an $F_t$ adapted standard Brownian motion and $t \leq T$. Any help on exponentials of squared Brownian motion is very appreciated!",,"['statistics', 'probability-distributions', 'stochastic-processes', 'conditional-probability']"
50,Proving conditional independence,Proving conditional independence,,"I have the following problem: Three random variables have the following joint distribution: $$ P(X,Y,Z) = P(X)P(Y|X)P(Z|Y) $$ Show that $X$ and $Z$ are conditionally independent given $Y$. The solution that I have been given is: $$ P(X)P(Y|X)P(Z|Y) = \frac{P(X)P(Y|X)P(Z|Y)}{P(Y)} = \frac{P(X,Y)}{P(Y)}P(Z|Y) = P(X|Y)P(Z|Y) $$ But no explanation was given for how each of these steps where reached - is anyone able to elaborate on this?","I have the following problem: Three random variables have the following joint distribution: $$ P(X,Y,Z) = P(X)P(Y|X)P(Z|Y) $$ Show that $X$ and $Z$ are conditionally independent given $Y$. The solution that I have been given is: $$ P(X)P(Y|X)P(Z|Y) = \frac{P(X)P(Y|X)P(Z|Y)}{P(Y)} = \frac{P(X,Y)}{P(Y)}P(Z|Y) = P(X|Y)P(Z|Y) $$ But no explanation was given for how each of these steps where reached - is anyone able to elaborate on this?",,"['statistics', 'conditional-probability']"
51,How to weight three different variables to create a ranking,How to weight three different variables to create a ranking,,"I have data on the graduation rate, tuition, and average student income (a measure of accessibility) for about $7,000$ colleges and universities in the U.S., and I'm trying to compose an interactive in which people can manipulate the importance of these three variables to create a ranking. Users drag three sliders to emphasize or deemphasize the importance of the variables: I've standardized the variables through the usual means so that each value is the number of standard deviations from the mean. Each variable also has a weight assigned by the sliders, which add to 1. One user might give $50\%$ weight to graduation rate and $25\%$ to the other two; another might give $33\%$ to all three, and so forth. My first instinct was to just multiply the weight by the standardized value and add them together for each school's score. But this seems to overly reward outliers in one area, when the goal is to surface schools that perform well over all. Graduation rate is negatively correlated with accessibility and positively correlated to cost, FWIW. Is there an accepted way to weight multivariate systems like this in a better way?","I have data on the graduation rate, tuition, and average student income (a measure of accessibility) for about colleges and universities in the U.S., and I'm trying to compose an interactive in which people can manipulate the importance of these three variables to create a ranking. Users drag three sliders to emphasize or deemphasize the importance of the variables: I've standardized the variables through the usual means so that each value is the number of standard deviations from the mean. Each variable also has a weight assigned by the sliders, which add to 1. One user might give weight to graduation rate and to the other two; another might give to all three, and so forth. My first instinct was to just multiply the weight by the standardized value and add them together for each school's score. But this seems to overly reward outliers in one area, when the goal is to surface schools that perform well over all. Graduation rate is negatively correlated with accessibility and positively correlated to cost, FWIW. Is there an accepted way to weight multivariate systems like this in a better way?","7,000 50\% 25\% 33\%","['statistics', 'standard-deviation']"
52,Transition from parametric to nonparametric statistics: what is $\Theta$?,Transition from parametric to nonparametric statistics: what is ?,\Theta,"During my first statistics course I learned that a statistical model is a collection of probability measures $\mathcal{P}$, where we can index each measure by a 'parameter' $\theta$ such that $\mathcal{P} = \{P_\theta\,\,|\,\,\theta\in\Theta\}$. My first question is: What exactly is $\Theta$? I am now working on a project concerning nonparametric statistics where $\Theta$ is always an (infinite dimensional) vector space. However, when we look at the parametric normal family $\{N(\mu,\sigma^2)\,\,|(\mu,\sigma)\in\Theta = \mathbb{R}\times(0,\infty)\}$, then clearly $\Theta$ is no vector space. A possible answer that I thought of was that $\Theta$ is in general a metric space (although maybe just a set is enough?), but then how do we mark the transistion between a parametric model and non parametric model. To only separate when $\Theta$ is an infinite dimensional vector space produces strange cases. For example: when we consider an infinite dimensional vector space, but interpret it as just a metric space, do we suddenly deal with a parametric model? That seems odd... My second question: What exactly separates parametric and nonparametric models when we look at $\Theta$. Thank you!","During my first statistics course I learned that a statistical model is a collection of probability measures $\mathcal{P}$, where we can index each measure by a 'parameter' $\theta$ such that $\mathcal{P} = \{P_\theta\,\,|\,\,\theta\in\Theta\}$. My first question is: What exactly is $\Theta$? I am now working on a project concerning nonparametric statistics where $\Theta$ is always an (infinite dimensional) vector space. However, when we look at the parametric normal family $\{N(\mu,\sigma^2)\,\,|(\mu,\sigma)\in\Theta = \mathbb{R}\times(0,\infty)\}$, then clearly $\Theta$ is no vector space. A possible answer that I thought of was that $\Theta$ is in general a metric space (although maybe just a set is enough?), but then how do we mark the transistion between a parametric model and non parametric model. To only separate when $\Theta$ is an infinite dimensional vector space produces strange cases. For example: when we consider an infinite dimensional vector space, but interpret it as just a metric space, do we suddenly deal with a parametric model? That seems odd... My second question: What exactly separates parametric and nonparametric models when we look at $\Theta$. Thank you!",,['statistics']
53,Find a transformation such that the Fisher Information is constant in terms of the parameter.,Find a transformation such that the Fisher Information is constant in terms of the parameter.,,"Say you have a Gamma distribution with parameters $\alpha$ known and $\theta$ unknown. Find a transformation of $\theta$, $\eta=g(\theta)$ such that ${\cal I} (\eta)$, the Fisher Information, is constant in terms of $\eta$. My problem is that the only way I can do this is by trial and error. At the moment I haven't been able to come up with any transformations that make this work. Is there a method that this can be done?","Say you have a Gamma distribution with parameters $\alpha$ known and $\theta$ unknown. Find a transformation of $\theta$, $\eta=g(\theta)$ such that ${\cal I} (\eta)$, the Fisher Information, is constant in terms of $\eta$. My problem is that the only way I can do this is by trial and error. At the moment I haven't been able to come up with any transformations that make this work. Is there a method that this can be done?",,['statistics']
54,The relationship between fisher information and EM algorithm?,The relationship between fisher information and EM algorithm?,,"I wonder what is the relationship between fisher information and EM algorithm? When I read papers about EM algorithm, people sometimes discussed about fisher information, and there are algorithms which would combine fisher scoring method and EM algorithm together. However, I couldn't find materials clearly illustrate how fisher information is related to EM algorithm and what role it is playing ? Could anyone help me understand if there is any connection? Thanks.","I wonder what is the relationship between fisher information and EM algorithm? When I read papers about EM algorithm, people sometimes discussed about fisher information, and there are algorithms which would combine fisher scoring method and EM algorithm together. However, I couldn't find materials clearly illustrate how fisher information is related to EM algorithm and what role it is playing ? Could anyone help me understand if there is any connection? Thanks.",,"['linear-algebra', 'statistics', 'algorithms', 'optimization']"
55,Find UMVUE in a uniform distribution setting,Find UMVUE in a uniform distribution setting,,"Let $X_1, ..., X_n$ be independent and uniformly distributed on $(\theta_1-\theta_2,\theta_1+\theta_2)$ for $\theta_1 \in \mathbb{R}$ , $\theta_2>0$ . Find UMVUEs for a) $\theta_1$ and $\theta_2$ , b) $\theta_1/\theta_2$ . Naturally, I would like to use the Lehmann-Scheffé theorem that says: If $V$ is a complete, sufficient statistic for $\theta$ and $\mathbb{E}_\theta[g(V)]=h(\theta)$ holds. Then $g(V)$ is an UMVUE for $h(\theta)$ . So first, I have to find such a statistic for any of my $\theta$ s. In the lecture we learned that $(X_{(1)}, X_{(n)})$ sufficient for $(a,b)$ if the $X_i$ are uniform on $(a,b)$ (where $X_{(1)}<...<X_{(n)}$ is the order statistic for $X_1, ..., X_n$ ). So it follows that in my setting $(X_{(1)}, X_{(n)})$ is sufficient for $(\theta_1-\theta_2,\theta_1+\theta_2)$ ? But looking at the proof, $(X_{(1)}, X_{(n)})$ is already a sufficient statistic for $(\theta_1, \theta_2)$ , too, right? So I have to check for completeness and thus show that for all functions $g$ mapping from the range of $V$ to $\mathbb{R}$ from $\mathbb{E}_\theta[g(X_{(1)}, X_{(n)})]=0$ for all $\theta=(\theta_1, \theta_2)$ follows $\mathbb{P}_\theta(g(X_{(1)}, X_{(n)})=1)=1$ $\mathbb{P}_\theta$ -almost-surely. Here I'm stuck: How can I show that?","Let be independent and uniformly distributed on for , . Find UMVUEs for a) and , b) . Naturally, I would like to use the Lehmann-Scheffé theorem that says: If is a complete, sufficient statistic for and holds. Then is an UMVUE for . So first, I have to find such a statistic for any of my s. In the lecture we learned that sufficient for if the are uniform on (where is the order statistic for ). So it follows that in my setting is sufficient for ? But looking at the proof, is already a sufficient statistic for , too, right? So I have to check for completeness and thus show that for all functions mapping from the range of to from for all follows -almost-surely. Here I'm stuck: How can I show that?","X_1, ..., X_n (\theta_1-\theta_2,\theta_1+\theta_2) \theta_1 \in \mathbb{R} \theta_2>0 \theta_1 \theta_2 \theta_1/\theta_2 V \theta \mathbb{E}_\theta[g(V)]=h(\theta) g(V) h(\theta) \theta (X_{(1)}, X_{(n)}) (a,b) X_i (a,b) X_{(1)}<...<X_{(n)} X_1, ..., X_n (X_{(1)}, X_{(n)}) (\theta_1-\theta_2,\theta_1+\theta_2) (X_{(1)}, X_{(n)}) (\theta_1, \theta_2) g V \mathbb{R} \mathbb{E}_\theta[g(X_{(1)}, X_{(n)})]=0 \theta=(\theta_1, \theta_2) \mathbb{P}_\theta(g(X_{(1)}, X_{(n)})=1)=1 \mathbb{P}_\theta","['statistics', 'statistical-inference', 'uniform-distribution', 'parameter-estimation']"
56,What is WHSSETIT?,What is WHSSETIT?,,I am working through a 7 step statistical procedure for hypothesis testing. Step 7 has a field marked WHSSETIT? . What does this acronym stand for and what is the expected response?,I am working through a 7 step statistical procedure for hypothesis testing. Step 7 has a field marked WHSSETIT? . What does this acronym stand for and what is the expected response?,,"['statistics', 'terminology']"
57,Mode for unique numbers,Mode for unique numbers,,I'm trying to construct a rough statistical software and I'm confused about the following: What is the mode if all numbers are unique? What is the mode if 2 numbers have same (highest) frequency? What I feel: Should output nothing. Should output the average of the 2. Just as reference: a = [1 2 3 4 5] mode(a) %Prints 1 a = [2 2 3 3] mode(a) %Prints 2 in Octave But I'm not sure how it's supposed to be done.,I'm trying to construct a rough statistical software and I'm confused about the following: What is the mode if all numbers are unique? What is the mode if 2 numbers have same (highest) frequency? What I feel: Should output nothing. Should output the average of the 2. Just as reference: a = [1 2 3 4 5] mode(a) %Prints 1 a = [2 2 3 3] mode(a) %Prints 2 in Octave But I'm not sure how it's supposed to be done.,,['statistics']
58,Closed form of integral of $\operatorname{erfc} \log t$,Closed form of integral of,\operatorname{erfc} \log t,Is there any closed form expression for the following integral? $$ \int\limits_t^\infty \left(1- \operatorname{erf}(\log x) \right )dx $$ or equivalently: $$ \int\limits_t^\infty \operatorname{erfc}(\log x ) dx $$ I just wish to know if there is any way I can do better than sampling the values at particular points and calculating the area under the curve numerically. Any help is appreciated. Thanks.,Is there any closed form expression for the following integral? $$ \int\limits_t^\infty \left(1- \operatorname{erf}(\log x) \right )dx $$ or equivalently: $$ \int\limits_t^\infty \operatorname{erfc}(\log x ) dx $$ I just wish to know if there is any way I can do better than sampling the values at particular points and calculating the area under the curve numerically. Any help is appreciated. Thanks.,,"['statistics', 'integration', 'special-functions', 'definite-integrals', 'closed-form']"
59,finding variance from a piecewise function,finding variance from a piecewise function,,"How do you calculate the variance of a piecewise function? For example, what would be the variance of the probability density function $f_x(x)= \frac{3}{4}, 0\leq x\leq 1; \frac{1}{4}, 2\leq x \leq 3; 0$ otherwise?","How do you calculate the variance of a piecewise function? For example, what would be the variance of the probability density function $f_x(x)= \frac{3}{4}, 0\leq x\leq 1; \frac{1}{4}, 2\leq x \leq 3; 0$ otherwise?",,"['statistics', 'probability-distributions', 'descriptive-statistics']"
60,Fitting a sine wave of known frequency through three points,Fitting a sine wave of known frequency through three points,,"We have a computationally expensive function of a large set of data and an angle, that is known to result in a sine wave: $$ f(\text{data}, \theta) \approx a \sin (\theta + b) + c$$ We want to find the constants $a$, $b$, and $c$, executing the function as few times as possible.","We have a computationally expensive function of a large set of data and an angle, that is known to result in a sine wave: $$ f(\text{data}, \theta) \approx a \sin (\theta + b) + c$$ We want to find the constants $a$, $b$, and $c$, executing the function as few times as possible.",,['statistics']
61,How does one handle ties in Order Statistics and Rank-Order Statistics?,How does one handle ties in Order Statistics and Rank-Order Statistics?,,"I'm preparing to calculate a data set's Mean Difference (equation given in the image below), but am having trouble understanding what I'm supposed to do when duplicate values are involved. My data consists of a large collection of integers which all have values in the set [0,5]. With such a small value set, ties are inevitable. However, I can't seem to find any resources that take this in to consideration. They all assume the probability of ties is 0 and continue with the material. Let's create a small example data set (bounded within the set of values that my actual data is): [0, 3, 2, 5, 4, 4, 5, 1, 3, 5] How would one go about dealing with duplicates when calculating Order Statistic and Rank-Order Statistics?","I'm preparing to calculate a data set's Mean Difference (equation given in the image below), but am having trouble understanding what I'm supposed to do when duplicate values are involved. My data consists of a large collection of integers which all have values in the set [0,5]. With such a small value set, ties are inevitable. However, I can't seem to find any resources that take this in to consideration. They all assume the probability of ties is 0 and continue with the material. Let's create a small example data set (bounded within the set of values that my actual data is): [0, 3, 2, 5, 4, 4, 5, 1, 3, 5] How would one go about dealing with duplicates when calculating Order Statistic and Rank-Order Statistics?",,"['statistics', 'order-statistics']"
62,Range of coefficient of Skewness,Range of coefficient of Skewness,,Prove that Pearson's second measure of Skewness that is Skewness = 3(Mean - Median)/Standard deviation lies between -3 and +3,Prove that Pearson's second measure of Skewness that is Skewness = 3(Mean - Median)/Standard deviation lies between -3 and +3,,['statistics']
63,Single number to represent a ratio?,Single number to represent a ratio?,,"There's probably a very simple answer to this, but I can't put my finger on it. I have two numbers.  I want one to be large, and the other to be small.  I'd like to identify these with a single value. For instance (hypothetical example follows), students should have high test scores and low absence rates.  Therefore, a student with a test score of 100 and an absence rate of 0 is the ideal student. For the purpose of this example, the absence rate is the more important number. We'd rather have a student with a test score of 50 and has an absence rate of 1 than a student with a test score of 100 and an absence rate of 2.  In other words, it's most important that the small number is actually small. So taking test score / absence rate won't work.  Because in the aforementioned example, it scores both students equally.  Additionally, a student with perfect attendance throws a divide-by-zero error. Any suggestions? Is there actually a simple answer?  I apologize if the question is too elementary for this site. Thanks! P.S. I couldn't identify an appropriate tag, so please re-tag if you can think of a better one. EDIT: Reading through my question, I see that it could depend on how much more important the small number is than the big number.  Really, I'm not concerned with the particulars.  A general answer is all I need to craft a solution to my specific problem.","There's probably a very simple answer to this, but I can't put my finger on it. I have two numbers.  I want one to be large, and the other to be small.  I'd like to identify these with a single value. For instance (hypothetical example follows), students should have high test scores and low absence rates.  Therefore, a student with a test score of 100 and an absence rate of 0 is the ideal student. For the purpose of this example, the absence rate is the more important number. We'd rather have a student with a test score of 50 and has an absence rate of 1 than a student with a test score of 100 and an absence rate of 2.  In other words, it's most important that the small number is actually small. So taking test score / absence rate won't work.  Because in the aforementioned example, it scores both students equally.  Additionally, a student with perfect attendance throws a divide-by-zero error. Any suggestions? Is there actually a simple answer?  I apologize if the question is too elementary for this site. Thanks! P.S. I couldn't identify an appropriate tag, so please re-tag if you can think of a better one. EDIT: Reading through my question, I see that it could depend on how much more important the small number is than the big number.  Really, I'm not concerned with the particulars.  A general answer is all I need to craft a solution to my specific problem.",,"['statistics', 'soft-question']"
64,"Showing that $X_{1:n}$ is sufficient for $\eta$, by factorization","Showing that  is sufficient for , by factorization",X_{1:n} \eta,"I'm asked to show that $X_{1:n}$ (the minimum order statistic) is sufficient for $\eta$, in the case of a random sample $(X_1, ... , X_n)$ where $X_i\sim EXP(1,\eta$) (this is the two-parameter exponential distribution $EXP(\theta,\eta):$ $(1/\theta)\exp(-(x-\eta)/\theta)$, $x>\eta$; in this case $\theta=1$), by using the ""factorization method"", that is, writing $f(x_1,...,x_n;\eta)$ as $g(s,\eta)h(x_1,...,x_n)$, where $S$ is the statistic ($X_{1:n}$, in this case), $g(s;\eta)$ does not depend on $x_1,...,x_n$ except through $s$, and $h(x_1,...,x_n)$ does not involve $\theta$. I have $f(x_1,...,x_n;\eta)=\exp(n\eta)\exp(-\sum_{i=1}^n x_i)$. The sum in the exponential is the same as $\sum_{i=1}^n x_{i:n}$, but I need an expression that involves $x_{1:n}$ in one factor and the $x_i$'s in the other. I don't know how to do this. I know there are formulas for joint pdf's of any set of order statistics (quite lengthy), but I really don't know how to proceed. Thank you.","I'm asked to show that $X_{1:n}$ (the minimum order statistic) is sufficient for $\eta$, in the case of a random sample $(X_1, ... , X_n)$ where $X_i\sim EXP(1,\eta$) (this is the two-parameter exponential distribution $EXP(\theta,\eta):$ $(1/\theta)\exp(-(x-\eta)/\theta)$, $x>\eta$; in this case $\theta=1$), by using the ""factorization method"", that is, writing $f(x_1,...,x_n;\eta)$ as $g(s,\eta)h(x_1,...,x_n)$, where $S$ is the statistic ($X_{1:n}$, in this case), $g(s;\eta)$ does not depend on $x_1,...,x_n$ except through $s$, and $h(x_1,...,x_n)$ does not involve $\theta$. I have $f(x_1,...,x_n;\eta)=\exp(n\eta)\exp(-\sum_{i=1}^n x_i)$. The sum in the exponential is the same as $\sum_{i=1}^n x_{i:n}$, but I need an expression that involves $x_{1:n}$ in one factor and the $x_i$'s in the other. I don't know how to do this. I know there are formulas for joint pdf's of any set of order statistics (quite lengthy), but I really don't know how to proceed. Thank you.",,"['statistics', 'parameter-estimation']"
65,A variation on the $F$-distribution,A variation on the -distribution,F,"If I have $\frac{X/n_1}{Y/n_2}$ where $X$ and $Y$ are independent chi-squared random variables, with degrees of freedom $n_1$ and $n_2$, respectively, then the distribution of this ratio is given by the $F$-distribution. If I have, instead, $\frac{X}{Y + k}$ where $k$ is a constant, what would the distribution be?","If I have $\frac{X/n_1}{Y/n_2}$ where $X$ and $Y$ are independent chi-squared random variables, with degrees of freedom $n_1$ and $n_2$, respectively, then the distribution of this ratio is given by the $F$-distribution. If I have, instead, $\frac{X}{Y + k}$ where $k$ is a constant, what would the distribution be?",,"['statistics', 'probability-distributions']"
66,What distribution does the height of both men and women follow?,What distribution does the height of both men and women follow?,,"It is often said that the height of men and that of women follow normal distribution with different means and variances. As graphs suggest, it appears true. Then, what is the whole distribution of both men and women? Is it normal distribution or other distribution? (I'm asking a distribution the height of randomly chosen people follow, including both men and women.) I thought it is related to the reproductive property of the normal distribution, but it appears slightly different.","It is often said that the height of men and that of women follow normal distribution with different means and variances. As graphs suggest, it appears true. Then, what is the whole distribution of both men and women? Is it normal distribution or other distribution? (I'm asking a distribution the height of randomly chosen people follow, including both men and women.) I thought it is related to the reproductive property of the normal distribution, but it appears slightly different.",,"['statistics', 'normal-distribution', 'variance', 'means']"
67,Question about only centering a matrix once in the covariance matrix,Question about only centering a matrix once in the covariance matrix,,"From probability, we have $$\Sigma_x = \frac{\left(HX\right)^T\left(HX\right)}{N}$$ Where $\Sigma_X$ is the covariance matrix for a data matrix $X$ . $X$ is constructed by putting all the datapoints in rows, so the first row is the first datapoint, the second row is the second collected data point and so forth. $H$ is the centering matrix $I - \frac{11^T}{N}$ Simplifying $\Sigma_X$ , $$\frac{\left(HX\right)^T\left(HX\right)}{N} = \frac{X^TH^T H X }{N} = \frac{X^T H ^2 X}{N} = \frac{X^THX}{N}$$ This both makes sense and doesn't make sense. At first glance, centering a matrix once and then doing so again does nothing the second time around. Matrix $H$ is idempotent. As a result when we lose the squared above the H, I'm okay with that. However digging a little deeper, it doesn't make sense that only one of my data matrices is centered when I should have two centered data matrices to properly compute covariance. Going to the 1D case, $$E[(X - \mu_{x})^2]  \neq E[X(X - \mu_{x})]$$ Here it doesn't make sense for only one of my $X$ random variables to be centered while the other one isn't.","From probability, we have Where is the covariance matrix for a data matrix . is constructed by putting all the datapoints in rows, so the first row is the first datapoint, the second row is the second collected data point and so forth. is the centering matrix Simplifying , This both makes sense and doesn't make sense. At first glance, centering a matrix once and then doing so again does nothing the second time around. Matrix is idempotent. As a result when we lose the squared above the H, I'm okay with that. However digging a little deeper, it doesn't make sense that only one of my data matrices is centered when I should have two centered data matrices to properly compute covariance. Going to the 1D case, Here it doesn't make sense for only one of my random variables to be centered while the other one isn't.",\Sigma_x = \frac{\left(HX\right)^T\left(HX\right)}{N} \Sigma_X X X H I - \frac{11^T}{N} \Sigma_X \frac{\left(HX\right)^T\left(HX\right)}{N} = \frac{X^TH^T H X }{N} = \frac{X^T H ^2 X}{N} = \frac{X^THX}{N} H E[(X - \mu_{x})^2]  \neq E[X(X - \mu_{x})] X,"['linear-algebra', 'statistics', 'expected-value', 'variance', 'covariance']"
68,Finding the UMVUE for $g(\lambda) = \lambda \cdot \exp(-\lambda)$,Finding the UMVUE for,g(\lambda) = \lambda \cdot \exp(-\lambda),"Given the random sample $X_1, \ldots, X_n$ of the random variable $X \sim \textrm{Poisson}(\lambda)$ , find the UMVUE for $g(\lambda) = \lambda \exp(-\lambda)$ . We know through the exponential family that $\sum X_i$ is a sufficient and complete statistic for $\lambda$ . Define $W(X)$ as $$ W(X) = \begin{cases}  1, & \text{if $X_1 = 1$} &&  \\ 0, & \text{otherwise}  \end{cases} $$ Then $$ E[W(X)] = \sum_{w = 0}^{\infty} w P(W = w) = 1 \cdot P(X_1 = 1) = \lambda e^{-\lambda}  $$ Using Lehmann-Scheffé $$ T^{*}(X) = E[W(X) | T(X)] = \sum w P(W(X) = w  |  T(X) = t ) = P(X_1 = 1 | \sum_{i = 1}^{n} X_i )$$ we obtain $$ \lambda \left(\frac{n-1}{n} \right)^{\sum_{i = 1}^{n} X_i} $$ Is the above reasoning correct?","Given the random sample of the random variable , find the UMVUE for . We know through the exponential family that is a sufficient and complete statistic for . Define as Then Using Lehmann-Scheffé we obtain Is the above reasoning correct?","X_1, \ldots, X_n X \sim \textrm{Poisson}(\lambda) g(\lambda) = \lambda \exp(-\lambda) \sum X_i \lambda W(X) 
W(X) =
\begin{cases} 
1, & \text{if X_1 = 1} &&  \\
0, & \text{otherwise} 
\end{cases}
  E[W(X)] = \sum_{w = 0}^{\infty} w P(W = w) = 1 \cdot P(X_1 = 1) = \lambda e^{-\lambda}    T^{*}(X) = E[W(X) | T(X)] = \sum w P(W(X) = w  |  T(X) = t ) = P(X_1 = 1 | \sum_{i = 1}^{n} X_i )  \lambda \left(\frac{n-1}{n} \right)^{\sum_{i = 1}^{n} X_i} ","['statistics', 'statistical-inference']"
69,Choosing Coins To Flip,Choosing Coins To Flip,,"Suppose I have two coins, and I don't know what the probability of getting a heads is with either coin. I flip one 60 times, and get heads 36 times. I flip another 20 times, and get heads 18 times. Which coin should I flip next for the highest probability of getting a heads? And how do I answer this more generally (changing # of flips, heads, and increasing the # of coins and ranking them)? I tried solving this problem using the Maximum Likelihood Estimation function for the Binomial Distribution, but it doesn't behave in a way that I found useful. Edit: The most extreme example would be to consider I have hundreds of coins, some have only been flipped once, and some have been flipped hundreds of times. How do I rank the coins in order to decide which ones would give me the greatest chance of picking heads? The practical situation I'm looking at actually resembles this situation, after some abstraction!","Suppose I have two coins, and I don't know what the probability of getting a heads is with either coin. I flip one 60 times, and get heads 36 times. I flip another 20 times, and get heads 18 times. Which coin should I flip next for the highest probability of getting a heads? And how do I answer this more generally (changing # of flips, heads, and increasing the # of coins and ranking them)? I tried solving this problem using the Maximum Likelihood Estimation function for the Binomial Distribution, but it doesn't behave in a way that I found useful. Edit: The most extreme example would be to consider I have hundreds of coins, some have only been flipped once, and some have been flipped hundreds of times. How do I rank the coins in order to decide which ones would give me the greatest chance of picking heads? The practical situation I'm looking at actually resembles this situation, after some abstraction!",,"['statistics', 'binomial-distribution']"
70,"Find sufficient and complete statistic: Uniform distribution, $\theta \geq 1$","Find sufficient and complete statistic: Uniform distribution,",\theta \geq 1,"Take a random sample $X_1,X_2, \dots X_n$ from the distribution f $(x;\theta)=\frac{1}{\theta}$ for $0 \leq x \leq \theta$ , where $\theta \geq 1$ (pay attention!). I need to find an efficient estimator (in terms of MSE). I've managed to check if $\max(1, X_{(n)})$ is sufficient and complete. But I can't transform it to get an unbiased estimator. So, my questions are: Could you suggest a suitable transformation? If not, could you find another sufficient and complete estimator?","Take a random sample from the distribution f for , where (pay attention!). I need to find an efficient estimator (in terms of MSE). I've managed to check if is sufficient and complete. But I can't transform it to get an unbiased estimator. So, my questions are: Could you suggest a suitable transformation? If not, could you find another sufficient and complete estimator?","X_1,X_2, \dots X_n (x;\theta)=\frac{1}{\theta} 0 \leq x \leq \theta \theta \geq 1 \max(1, X_{(n)})","['statistics', 'uniform-distribution']"
71,Comparison of bird diet at two different nests,Comparison of bird diet at two different nests,,"I have a list with the different prey types and quantities that birds at Nest $1$ gave to their fledglings. I also have the same information for another nest of the same bird species. Suppose I have NEST 1 Mammals: 500 Arthropods: 200 Birds: 20  NEST 2 Mammals: 180 Arthropods: 50 Birds: 3 Can I use the Chi-squared test to demonstrate the diets are actually very similar (or maybe not similar)? Of course, my actual data is more complex, with more classes (to family level).","I have a list with the different prey types and quantities that birds at Nest gave to their fledglings. I also have the same information for another nest of the same bird species. Suppose I have NEST 1 Mammals: 500 Arthropods: 200 Birds: 20  NEST 2 Mammals: 180 Arthropods: 50 Birds: 3 Can I use the Chi-squared test to demonstrate the diets are actually very similar (or maybe not similar)? Of course, my actual data is more complex, with more classes (to family level).",1,"['statistics', 'biology', 'chi-squared']"
72,Need clear and simple clarification on the difference between accuracy and precision,Need clear and simple clarification on the difference between accuracy and precision,,"Could someone suggest a better explanation of the difference between ""accuracy and precision concept"" other than this very common approach which is not clear to me. EDIT For example: Why is picture in top rights corner is ""precise""? Is it because the dots are within the outer circle? Or is it because the dots are clustered together? What about the distance between the clustered dots center and the radius of the inner circle, this could be huge, would it still be precise? Thank you.","Could someone suggest a better explanation of the difference between ""accuracy and precision concept"" other than this very common approach which is not clear to me. EDIT For example: Why is picture in top rights corner is ""precise""? Is it because the dots are within the outer circle? Or is it because the dots are clustered together? What about the distance between the clustered dots center and the radius of the inner circle, this could be huge, would it still be precise? Thank you.",,"['statistics', 'terminology']"
73,Typo in introductory statistics book,Typo in introductory statistics book,,Mistake in book. This is an example from an indtroduction to the central limit theorem written by a professor at my university. Is this a typo?,Mistake in book. This is an example from an indtroduction to the central limit theorem written by a professor at my university. Is this a typo?,,['statistics']
74,Two generators of random points in a disk,Two generators of random points in a disk,,"I have two ways to generate points in a disk: The first is: $ a, b \sim U[0, 1].  $ Point is generating the next way: $(a \cos(2\pi b), a \sin(2 \pi b))$ . The second is: $a, b \sim U[-1, 1]$ and point generating only if $a^2 + b^2 \le 1$ . Suppose I've given points already distributed. I want to derive by what method (first or second) it was produced. By the way graph of this two method is: It's easy to see, that for the first method points are more 'squeezed' to zero than for the second method. My approach: is very clumsy. I'm finding probability that points are more concentrated to the center in first method, i.e. I'm finding $\mathbb{P}(-0.2 < x < 0.2)$ for each method. I'm doing it using Cumulative Distribution Function estimation: $$ \tilde F(t)=\frac{1}{n + 1} \left(\frac{1}{2}  + \sum_{i: x_i < t} 1  \right) $$ For the first it is near the $0.4$ , while for the second it is more near the $0.25.$ Any ideas how to solve it more mathematical way?","I have two ways to generate points in a disk: The first is: Point is generating the next way: . The second is: and point generating only if . Suppose I've given points already distributed. I want to derive by what method (first or second) it was produced. By the way graph of this two method is: It's easy to see, that for the first method points are more 'squeezed' to zero than for the second method. My approach: is very clumsy. I'm finding probability that points are more concentrated to the center in first method, i.e. I'm finding for each method. I'm doing it using Cumulative Distribution Function estimation: For the first it is near the , while for the second it is more near the Any ideas how to solve it more mathematical way?","
a, b \sim U[0, 1]. 
 (a \cos(2\pi b), a \sin(2 \pi b)) a, b \sim U[-1, 1] a^2 + b^2 \le 1 \mathbb{P}(-0.2 < x < 0.2)  \tilde F(t)=\frac{1}{n + 1} \left(\frac{1}{2}  + \sum_{i: x_i < t} 1  \right)  0.4 0.25.","['statistics', 'statistical-inference', 'hypothesis-testing']"
75,"Showing $X_{(n)}$ is not complete for $\theta \in [1,\infty)$ when $X_i$'s are i.i.d $\text{Unif}(0,\theta)$",Showing  is not complete for  when 's are i.i.d,"X_{(n)} \theta \in [1,\infty) X_i \text{Unif}(0,\theta)","I am trying to show that the order statistic $X_{(n)}$ for a set of RV $\{X_i\}_{1}^{n}$ where $X_i\overset{iid}\sim \text{Unif}(0,\theta)$ is complete when $\theta \in (0,\infty)$ but not when $\theta \in [1,\infty)$ . By completeness $E[g(X_{(n)})]=0$ iff $g(X_{(n)})=0$ a.e. $X_{(n)}\sim n\theta^{-n}X_{(n)}^{n-1}$ then if $$E[g(X_{(n)})]=\int_{0}^{\theta}g(X_{(n)})n\theta^{-n}X_{(n)}^{n-1}dX_{(n)}=0$$ this implies $$g(\theta)=0, \forall \theta \in(0,\infty)$$ Since for any $X_{(n)}$ there exists a $\theta=X_{(n)}$ one can conclude $g(X_{(n)})=0$ when the parameter space is restricted to $\theta \in [1,\infty)$ then by the statement above one can conclude $$g(\theta)=0, \forall \theta \in [1,\infty)$$ not guaranteeing that $g(X_{(n)})=0$ for $X_{(n)}\in(0,1)$ I am having trouble using this to justify non completeness.",I am trying to show that the order statistic for a set of RV where is complete when but not when . By completeness iff a.e. then if this implies Since for any there exists a one can conclude when the parameter space is restricted to then by the statement above one can conclude not guaranteeing that for I am having trouble using this to justify non completeness.,"X_{(n)} \{X_i\}_{1}^{n} X_i\overset{iid}\sim \text{Unif}(0,\theta) \theta \in (0,\infty) \theta \in [1,\infty) E[g(X_{(n)})]=0 g(X_{(n)})=0 X_{(n)}\sim n\theta^{-n}X_{(n)}^{n-1} E[g(X_{(n)})]=\int_{0}^{\theta}g(X_{(n)})n\theta^{-n}X_{(n)}^{n-1}dX_{(n)}=0 g(\theta)=0, \forall \theta \in(0,\infty) X_{(n)} \theta=X_{(n)} g(X_{(n)})=0 \theta \in [1,\infty) g(\theta)=0, \forall \theta \in [1,\infty) g(X_{(n)})=0 X_{(n)}\in(0,1)","['statistics', 'statistical-inference', 'uniform-distribution']"
76,Full Rank Exponential Families,Full Rank Exponential Families,,I am trying to better understand the importance of full rank exponential families of distributions i.e. a family of populations dominated by a $\sigma$ -finite measure such that the radon-nykodym derivative can be written as $$ f_\theta(x)=h(x)e^{\eta(\theta)^tT(x)-\zeta(\theta)} $$ I am trying to understand why the statistic $T(x)$ is minimally sufficient only when the family of populations $f_\theta$ is of full rank i.e that there exists an open set within the parameter space of our family of populations. What happens if full rank is not satisfied?,I am trying to better understand the importance of full rank exponential families of distributions i.e. a family of populations dominated by a -finite measure such that the radon-nykodym derivative can be written as I am trying to understand why the statistic is minimally sufficient only when the family of populations is of full rank i.e that there exists an open set within the parameter space of our family of populations. What happens if full rank is not satisfied?,\sigma  f_\theta(x)=h(x)e^{\eta(\theta)^tT(x)-\zeta(\theta)}  T(x) f_\theta,"['statistics', 'statistical-inference', 'exponential-distribution', 'sufficient-statistics']"
77,Portfolio optimization,Portfolio optimization,,"I prepare Markowitz optimization model for 4 different local companies with Excel functions and Solver. And I get confusing result for me, maybe somebody will explain it. So, from historic information I calculated daily returns and from that daily returns I calculated arithmetic and geometric means. And for just one company I get a huge difference between AVERAGE and GEOMEAN means. Arithmetic mean: 0.145 and geometric mean: -0.00171. So, in result this company has the highest arithmetic mean and the lowest geometric mean of all 4 companies. I get that the model invests the lower percentage of cash to this company. Is everything fine with this result?","I prepare Markowitz optimization model for 4 different local companies with Excel functions and Solver. And I get confusing result for me, maybe somebody will explain it. So, from historic information I calculated daily returns and from that daily returns I calculated arithmetic and geometric means. And for just one company I get a huge difference between AVERAGE and GEOMEAN means. Arithmetic mean: 0.145 and geometric mean: -0.00171. So, in result this company has the highest arithmetic mean and the lowest geometric mean of all 4 companies. I get that the model invests the lower percentage of cash to this company. Is everything fine with this result?",,"['statistics', 'optimization', 'finance', 'mathematical-modeling', 'quadratic-programming']"
78,Is there an accepted term for the opposite of mode in statistics?,Is there an accepted term for the opposite of mode in statistics?,,"In descriptive statistics, there are terms for all sorts of things.  The mean, median, and mode for a set of data are each three very frequently thrown around examples. The mode in particular is defined as the result that has occurred the most frequently. Is there a name for the opposite of this?  Is there a name for the result which has occurred the least frequently ( but still a nonzero number of times )? If I were to guess at a name or come up with one myself, perhaps a name like "" anti-mode "" might be appropriate, but I was wondering if there was an already accepted name.","In descriptive statistics, there are terms for all sorts of things.  The mean, median, and mode for a set of data are each three very frequently thrown around examples. The mode in particular is defined as the result that has occurred the most frequently. Is there a name for the opposite of this?  Is there a name for the result which has occurred the least frequently ( but still a nonzero number of times )? If I were to guess at a name or come up with one myself, perhaps a name like "" anti-mode "" might be appropriate, but I was wondering if there was an already accepted name.",,"['statistics', 'terminology', 'descriptive-statistics']"
79,marginal likelihood in variational bayes,marginal likelihood in variational bayes,,"In this paper, https://arxiv.org/abs/1312.6114 I have some questions regarding equation 1 and 2 equation one starts with The marginal likelihood is composed of a sum over the marginal lieklihoods of individual datapoints $\log p_\theta(x^{(1)}, ..., x^{(n)}) = \sum_{i=1}^N \log p_\theta(x^{(i)})$ which can be rewritten as... $$ \log p_\theta(x^{(i)}) = D_{KL}(q_\phi(z|x^{(i)}) || p_\theta(z|x^{(i)}))+ \mathcal{L} (\theta, \phi; x^{(i)}) $$ How is this the same as marginal likelihood . I've been looking at this equation for quite some time and I can't reason through it like I can with standard marginal likelihood. The only thing I have been able to deduce from it (I think) is that the two terms on the RHS of the equation will be negatively correlated because as the divergence gets smaller, the likelihood of them both goes up and vice versa, correct? In the second equation, the author makes a statement about the likelihood and I also don't see how that came about... $$ \log p_\theta(x^{(i)}) \ge \mathcal{L}(\theta, \phi; x^{(i)}) = \mathbb{E}_{q_\phi(z|x^{(i)})} \big[ -\log q_\phi(z|x) + \log p_\theta(x,z) \big] $$ Why is this equal to the joint likelihood of $\theta$ and $\phi$ ? Why is the input to $q_\theta$ different (joint) than that of $q_\phi$ which is conditional?","In this paper, https://arxiv.org/abs/1312.6114 I have some questions regarding equation 1 and 2 equation one starts with The marginal likelihood is composed of a sum over the marginal lieklihoods of individual datapoints which can be rewritten as... How is this the same as marginal likelihood . I've been looking at this equation for quite some time and I can't reason through it like I can with standard marginal likelihood. The only thing I have been able to deduce from it (I think) is that the two terms on the RHS of the equation will be negatively correlated because as the divergence gets smaller, the likelihood of them both goes up and vice versa, correct? In the second equation, the author makes a statement about the likelihood and I also don't see how that came about... Why is this equal to the joint likelihood of and ? Why is the input to different (joint) than that of which is conditional?","\log p_\theta(x^{(1)}, ..., x^{(n)}) = \sum_{i=1}^N \log p_\theta(x^{(i)}) 
\log p_\theta(x^{(i)}) = D_{KL}(q_\phi(z|x^{(i)}) || p_\theta(z|x^{(i)}))+ \mathcal{L} (\theta, \phi; x^{(i)})
 
\log p_\theta(x^{(i)}) \ge \mathcal{L}(\theta, \phi; x^{(i)}) = \mathbb{E}_{q_\phi(z|x^{(i)})} \big[ -\log q_\phi(z|x) + \log p_\theta(x,z) \big]
 \theta \phi q_\theta q_\phi","['statistics', 'statistical-inference', 'machine-learning', 'bayesian', 'bayes-theorem']"
80,"What is the difference between a response, output, hidden and latent variables in modeling?","What is the difference between a response, output, hidden and latent variables in modeling?",,"I'm a learner of machine learning and statistics and I have some experience with both of the subjects. However, until this day it has not yet been fully revealed to me what is the fundamental difference between the four following variables: Response variable Output variable Hidden variable Latent variable To my knowledge, in data analysis our task in general is to find the functional relationship between explanatory observed data $x$ and the variable of interest $y$ . That is, in general our goal in many modeling applications is to find a function $f$ such that: $$f(x)=y,$$ using some data set $D={(x_1,y_1), (x_2,y_2), ..., (x_n, y_n)}$ . I think the ""response"" and ""output"" variables are synonyms and generally refer to the $y$ variable. But what about ""hidden"" and ""latent"" variables? What do they refer to? Are they also synonyms for $y$ or do they refer to the parameters of $f$ ? Concrete and simple examples would be both sufficient and excellent answers, thank you! UPDATE: As requested, I will also add the following into the list of variables to be explained: independent variable dependent variable confound variable","I'm a learner of machine learning and statistics and I have some experience with both of the subjects. However, until this day it has not yet been fully revealed to me what is the fundamental difference between the four following variables: Response variable Output variable Hidden variable Latent variable To my knowledge, in data analysis our task in general is to find the functional relationship between explanatory observed data and the variable of interest . That is, in general our goal in many modeling applications is to find a function such that: using some data set . I think the ""response"" and ""output"" variables are synonyms and generally refer to the variable. But what about ""hidden"" and ""latent"" variables? What do they refer to? Are they also synonyms for or do they refer to the parameters of ? Concrete and simple examples would be both sufficient and excellent answers, thank you! UPDATE: As requested, I will also add the following into the list of variables to be explained: independent variable dependent variable confound variable","x y f f(x)=y, D={(x_1,y_1), (x_2,y_2), ..., (x_n, y_n)} y y f","['statistics', 'mathematical-modeling', 'data-analysis']"
81,"The ""correct"" standard deviation","The ""correct"" standard deviation",,"This may end up being a question more about scientific best practice than anything else, but I think this is the right community to ask it in to get the insight I'm looking for. Say I have two little square widgets made out of a material that shrinks when it gets wet.  I want to know by how much.  I measure the length of the widgets along two lines each (because they're not shaped perfectly and my measurement technique isn't perfect), before and after soaking them with water.  I come back with data that looks like this: Widget  Measurement  Before  After  Shrinkage 1       1            1.898   1.722  0.176 1       2            1.904   1.737  0.167 2       1            2.003   1.763  0.240 2       2            2.029   1.843  0.186 Now, I can calculate the overall mean without worrying too much in this case, since the mean of two means is the same as the mean of all the points that went in as long as each mean has the same number of samples, which in this case they do.  So: avg(0.176,0.167,0.240,0.186) = 0.192 = avg(avg(0.176,0.167),avg(0.240,0.186)) However, this type of relation is not true for the standard deviation.  There are several approaches that immediately present themselves to me as options for finding an overall standard deviation for this dataset: Use all of the data at once: sd(0.176,0.167,0.240,0.186) = 0.033 Get a standard deviation for each widget, and average them: avg(sd(0.176,0.167),sd(0.240,0.186)) = 0.022 Get the average for each widget, and take the standard deviation of the two: sd(avg(0.176,0.167),avg(0.240,0.186)) = 0.029 Now, maybe it's just confusion on my part as to the meaning of a standard deviation, but I don't know which approach would be correct to use here (for the purpose of, for example, putting error bars on a graph).  Intuitively I'm drawn to the first method, because it seems to incorporate the most information about the data in the actual standard deviation calculation.  I'm wary, though, that doing this could be be implicitly making some assumption about the structure of the data, such as homogeneity , which may not actually hold. What approach is generally regarded as correct , and what assumptions about the structure of the data does it imply?  Is there another, more correct method (or another method that makes fewer assumptions) which I failed to list?","This may end up being a question more about scientific best practice than anything else, but I think this is the right community to ask it in to get the insight I'm looking for. Say I have two little square widgets made out of a material that shrinks when it gets wet.  I want to know by how much.  I measure the length of the widgets along two lines each (because they're not shaped perfectly and my measurement technique isn't perfect), before and after soaking them with water.  I come back with data that looks like this: Widget  Measurement  Before  After  Shrinkage 1       1            1.898   1.722  0.176 1       2            1.904   1.737  0.167 2       1            2.003   1.763  0.240 2       2            2.029   1.843  0.186 Now, I can calculate the overall mean without worrying too much in this case, since the mean of two means is the same as the mean of all the points that went in as long as each mean has the same number of samples, which in this case they do.  So: avg(0.176,0.167,0.240,0.186) = 0.192 = avg(avg(0.176,0.167),avg(0.240,0.186)) However, this type of relation is not true for the standard deviation.  There are several approaches that immediately present themselves to me as options for finding an overall standard deviation for this dataset: Use all of the data at once: sd(0.176,0.167,0.240,0.186) = 0.033 Get a standard deviation for each widget, and average them: avg(sd(0.176,0.167),sd(0.240,0.186)) = 0.022 Get the average for each widget, and take the standard deviation of the two: sd(avg(0.176,0.167),avg(0.240,0.186)) = 0.029 Now, maybe it's just confusion on my part as to the meaning of a standard deviation, but I don't know which approach would be correct to use here (for the purpose of, for example, putting error bars on a graph).  Intuitively I'm drawn to the first method, because it seems to incorporate the most information about the data in the actual standard deviation calculation.  I'm wary, though, that doing this could be be implicitly making some assumption about the structure of the data, such as homogeneity , which may not actually hold. What approach is generally regarded as correct , and what assumptions about the structure of the data does it imply?  Is there another, more correct method (or another method that makes fewer assumptions) which I failed to list?",,"['statistics', 'philosophy', 'descriptive-statistics']"
82,Kelly Criterion for a finite number of bets,Kelly Criterion for a finite number of bets,,"I am not a mathematician but I have read extensively about the Kelly Criterion and understood it well (I think at least). Kelly criterion allows you find out the fraction f* of your bankroll that you should bet if the odds of a bet and the probability of its success are known such as to maximize the logarithmic growth rate of your account. For reference, the formula and derivation can be found on the wiki . However, in real life this is hardly ever the case that a bet (even if it had positive expectancy) is available to us infinitely. So let us say there was a limit on the number of a times you could make a bet. How can the Kelly formula be adjusted so that one could find the optimum fraction of bankroll to bet assuming there was a limit to the number of bets allowed. For example, let's say a casino offered you a bet that for every \$1 you bet, 60% of the times you would win \$1 in addition to the 1$ bet and 40% of the time you would lose the \$1. So according to the Kelly formula you would want to bet: f* = (0.6 * 1 - 0.4) / 1 = 0.2 20% of your bankroll. However, let us say I added an additional criteria that you are only allowed 10 bets or maybe even less (like 2 bets?) How can I extend the Kelly formula to calculate the optimum fraction of bank roll to bet when this new constraint is added. Thanks in advance! Cheers!","I am not a mathematician but I have read extensively about the Kelly Criterion and understood it well (I think at least). Kelly criterion allows you find out the fraction f* of your bankroll that you should bet if the odds of a bet and the probability of its success are known such as to maximize the logarithmic growth rate of your account. For reference, the formula and derivation can be found on the wiki . However, in real life this is hardly ever the case that a bet (even if it had positive expectancy) is available to us infinitely. So let us say there was a limit on the number of a times you could make a bet. How can the Kelly formula be adjusted so that one could find the optimum fraction of bankroll to bet assuming there was a limit to the number of bets allowed. For example, let's say a casino offered you a bet that for every \$1 you bet, 60% of the times you would win \$1 in addition to the 1$ bet and 40% of the time you would lose the \$1. So according to the Kelly formula you would want to bet: f* = (0.6 * 1 - 0.4) / 1 = 0.2 20% of your bankroll. However, let us say I added an additional criteria that you are only allowed 10 bets or maybe even less (like 2 bets?) How can I extend the Kelly formula to calculate the optimum fraction of bank roll to bet when this new constraint is added. Thanks in advance! Cheers!",,"['statistics', 'gambling']"
83,"What is an estimator for the ""number of trials"" given observed successes and the success probability?","What is an estimator for the ""number of trials"" given observed successes and the success probability?",,"The binomial distribution with $n$ trials, $k$ successes and success probability $p$ is given by $$P(k;n,p) = \binom{n}{k} p^k (1-p)^{(n-k)}, \quad k \in \{0,...,n\}$$ Suppose that we observe $k$ successes and know $p$ but we do not know $n$ . Observe that now $k$ and $p$ are fixed whereas $n$ is stochastic. So if $k=6$ and $p=0.4$ , $$P(k=6; n ,p=0.4) = \binom{n}{6} 0.4^6 (0.6)^{(n-6)}, \quad n \in \{6,...,\infty\}.$$ This is however (remark by @Xiaomi) not a valid probability function as it does not sum to one over its suppoer. Is there a probability mass function for $n$ ?  What is a useful (unbiased, consistent) estimator for its parameter $n$ ?","The binomial distribution with trials, successes and success probability is given by Suppose that we observe successes and know but we do not know . Observe that now and are fixed whereas is stochastic. So if and , This is however (remark by @Xiaomi) not a valid probability function as it does not sum to one over its suppoer. Is there a probability mass function for ?  What is a useful (unbiased, consistent) estimator for its parameter ?","n k p P(k;n,p) = \binom{n}{k} p^k (1-p)^{(n-k)}, \quad k \in \{0,...,n\} k p n k p n k=6 p=0.4 P(k=6; n ,p=0.4) = \binom{n}{6} 0.4^6 (0.6)^{(n-6)}, \quad n \in \{6,...,\infty\}. n n","['statistics', 'binomial-distribution', 'parameter-estimation']"
84,A measure similar to variance that's always between 0 and 1?,A measure similar to variance that's always between 0 and 1?,,"Consider the following histogram, obtained from around 1000 measures of distance. As you can observe, most of the data appears near the mean arond the value 5-10. I also have some isolated samples far away at values 100, 160. 1) Is there any statistical measure I can use to detect when this happens? Sometimes there are no outliers and I'm trying to detect such cases. I was thinking of thresholding variance, but I'm looking for a measure with a value in a fixed interval (e.g. always 0 to 1). 2) I'm trying to get an interval like the one in red that only includes the measures around the mean. I'm looking for a method that works for different histograms with a similar shape (number of readings and values can vary, but shape is always similar). Could you suggest me a method?","Consider the following histogram, obtained from around 1000 measures of distance. As you can observe, most of the data appears near the mean arond the value 5-10. I also have some isolated samples far away at values 100, 160. 1) Is there any statistical measure I can use to detect when this happens? Sometimes there are no outliers and I'm trying to detect such cases. I was thinking of thresholding variance, but I'm looking for a measure with a value in a fixed interval (e.g. always 0 to 1). 2) I'm trying to get an interval like the one in red that only includes the measures around the mean. I'm looking for a method that works for different histograms with a similar shape (number of readings and values can vary, but shape is always similar). Could you suggest me a method?",,"['statistics', 'standard-deviation', 'variance']"
85,Show that the statistic $T(X)$ is complete.,Show that the statistic  is complete.,T(X),"Exercise: Let $X_1,\ldots,X_n$ be a sample from the distribution with density $$f(x|\theta) = \dfrac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)$$ w.r.t. the Lebesgue measure. Show that the statistic $T(X) = \max(X_1,\ldots,X_n)$ is complete. What I've tried: I know that a statistic $T$ is said to be complete for $\theta\in\Omega$ if for any Borel function $f$, $\operatorname{E}_\theta f(T) = 0$ for all $P_\theta \in \Omega$, implies that $f(T)=0$, $P_\theta$-a.s. for all $\theta$. So what I want to do is take $\operatorname{E}_\theta f(T)$ and show that this is only equal to zero when $f(T) = 0$. If I'm correct, that means that I need to show that $$\displaystyle\int f(T(X))\dfrac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)dx = 0$$ implies $f(T(X)) = 0$. I'm not sure how to proceed from here though. Question: How do I solve this exercise? Thanks in advance!","Exercise: Let $X_1,\ldots,X_n$ be a sample from the distribution with density $$f(x|\theta) = \dfrac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)$$ w.r.t. the Lebesgue measure. Show that the statistic $T(X) = \max(X_1,\ldots,X_n)$ is complete. What I've tried: I know that a statistic $T$ is said to be complete for $\theta\in\Omega$ if for any Borel function $f$, $\operatorname{E}_\theta f(T) = 0$ for all $P_\theta \in \Omega$, implies that $f(T)=0$, $P_\theta$-a.s. for all $\theta$. So what I want to do is take $\operatorname{E}_\theta f(T)$ and show that this is only equal to zero when $f(T) = 0$. If I'm correct, that means that I need to show that $$\displaystyle\int f(T(X))\dfrac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)dx = 0$$ implies $f(T(X)) = 0$. I'm not sure how to proceed from here though. Question: How do I solve this exercise? Thanks in advance!",,"['statistics', 'probability-distributions', 'statistical-inference']"
86,"In linear regression, why is the hat matrix idempotent, symmetric, and p.s.d.?","In linear regression, why is the hat matrix idempotent, symmetric, and p.s.d.?",,"In linear regression,    $$y = X \beta + \epsilon$$ where $y$ is a $n \times 1$ vector of observations for the response variable, $X = (x_{1}^{T}, ..., x_{n}^{T}), x_{i} \in \mathbb{R}^p. i =1,...,n$ is a data matrix of $p$ explanatory variables, and $\epsilon$ is a vector of errors. Further, assume that $\mathbb{E}[\epsilon_i] = 0$ and $var(\epsilon_i) = \sigma^2, i=1,...n$ The least-squares estimate, $$\hat{\beta} = (X^{T}X)^{-1}X^{T}y$$ The least-squares estimators are the fitted values, $$\hat{y} = X \hat{\beta} = X(X^{T}X)^{-1}X^{T}y = X C^{-1}X^{T}y = Py$$ $P$ is a projection matrix. It is has the following properties: idempotent, meaning P*P = P symmetric positive semi-definite For property 1, what's the intuition behind this? How can you take some matrix do transformation, inverse and multiplication, then, you get idempotent. It's an important concept. But, it's hard to follow through the math to get an intuition. Why will we get property 2 and property 3, How am I supposed to think about this?","In linear regression,    $$y = X \beta + \epsilon$$ where $y$ is a $n \times 1$ vector of observations for the response variable, $X = (x_{1}^{T}, ..., x_{n}^{T}), x_{i} \in \mathbb{R}^p. i =1,...,n$ is a data matrix of $p$ explanatory variables, and $\epsilon$ is a vector of errors. Further, assume that $\mathbb{E}[\epsilon_i] = 0$ and $var(\epsilon_i) = \sigma^2, i=1,...n$ The least-squares estimate, $$\hat{\beta} = (X^{T}X)^{-1}X^{T}y$$ The least-squares estimators are the fitted values, $$\hat{y} = X \hat{\beta} = X(X^{T}X)^{-1}X^{T}y = X C^{-1}X^{T}y = Py$$ $P$ is a projection matrix. It is has the following properties: idempotent, meaning P*P = P symmetric positive semi-definite For property 1, what's the intuition behind this? How can you take some matrix do transformation, inverse and multiplication, then, you get idempotent. It's an important concept. But, it's hard to follow through the math to get an intuition. Why will we get property 2 and property 3, How am I supposed to think about this?",,"['linear-algebra', 'statistics', 'regression', 'linear-regression']"
87,Is there an analogous Gibbs phenomena to approximating sinusoidal but with polynomial terms?,Is there an analogous Gibbs phenomena to approximating sinusoidal but with polynomial terms?,,"I was trying to approximate a sine curve with a finite number of polynomials terms using linear regression (or the pseudo-inverse). I construct a Vandermonde matrix (or a Kernel polynomial feature matrix) and then solve the linear system (usually using the pseudo-inverse): $$ y = \Phi(x)w$$ then I try to visualize the solution. For low degree polynomials the approximation seems fine but eventually when the degree of the polynomial is pretty high, there is a weird funky bit at the edge: This reminded me of Gibbs phenomenon where at discontinuities there seems to be high oscillations near the jump. I know that Gibbs phenomena happens with a finite sum of Fourier series. However, this empirical observation really made me wonder. Is this the reason the edge of the approximation looks strange? Also from a statistics/machine learning point of view it seems clear that if the solution is not regularized, then a high complexity model should overfit to noise. However, in this model there is no noise. Therefore, I was not quite sure what was going on and was wondering what it was. Thus, my question is, is there a Gibbs phenomena for approximating sinusoidal with a finite number of polynomial terms? If yes, then what is it and what are its details? Another observation that I found odd is that the high oscillation/jump only happened at the right discontinuity. I am not sure why that is but I thought it was quite puzzling.","I was trying to approximate a sine curve with a finite number of polynomials terms using linear regression (or the pseudo-inverse). I construct a Vandermonde matrix (or a Kernel polynomial feature matrix) and then solve the linear system (usually using the pseudo-inverse): $$ y = \Phi(x)w$$ then I try to visualize the solution. For low degree polynomials the approximation seems fine but eventually when the degree of the polynomial is pretty high, there is a weird funky bit at the edge: This reminded me of Gibbs phenomenon where at discontinuities there seems to be high oscillations near the jump. I know that Gibbs phenomena happens with a finite sum of Fourier series. However, this empirical observation really made me wonder. Is this the reason the edge of the approximation looks strange? Also from a statistics/machine learning point of view it seems clear that if the solution is not regularized, then a high complexity model should overfit to noise. However, in this model there is no noise. Therefore, I was not quite sure what was going on and was wondering what it was. Thus, my question is, is there a Gibbs phenomena for approximating sinusoidal with a finite number of polynomial terms? If yes, then what is it and what are its details? Another observation that I found odd is that the high oscillation/jump only happened at the right discontinuity. I am not sure why that is but I thought it was quite puzzling.",,"['statistics', 'polynomials', 'fourier-analysis', 'fourier-series', 'machine-learning']"
88,Dividing Variance by $n$,Dividing Variance by,n,"This sample follows a Normal Distribution with Mean $= 280 / 20 = 14$, and Variance $= (3977.57 / 20) - 14^2 = 2.88$. To find the unbiased variance, we can divide it by $19$ to get $3.03$. However, in the following question: I used $\displaystyle\int\frac{3x^3 + 2x^2}{10} \, dx$ and $\displaystyle\int \frac{3x^4 + 2x^4}{10}\,dx - \text{mean}^2$ to get the mean and variance that the sample follows. The answer gives the variance as $\displaystyle\int \frac{3x^4 + 2x^4}{10}\, dx - \text{mean}^2$ divided by $n$. I understand that this is the definition given by the Central Limit Theorem. What I don't understand is why we don't divide by $n$ in the first example if we do in this case. Is it because we only divide by $n$ when using the central limit theorem, and the first example had only 20 samples taken, meaning that the central limit theorem could not be used? In this way, does it depend on the size of $n$? Any help will be greatly appreciated, thanks in advance.","This sample follows a Normal Distribution with Mean $= 280 / 20 = 14$, and Variance $= (3977.57 / 20) - 14^2 = 2.88$. To find the unbiased variance, we can divide it by $19$ to get $3.03$. However, in the following question: I used $\displaystyle\int\frac{3x^3 + 2x^2}{10} \, dx$ and $\displaystyle\int \frac{3x^4 + 2x^4}{10}\,dx - \text{mean}^2$ to get the mean and variance that the sample follows. The answer gives the variance as $\displaystyle\int \frac{3x^4 + 2x^4}{10}\, dx - \text{mean}^2$ divided by $n$. I understand that this is the definition given by the Central Limit Theorem. What I don't understand is why we don't divide by $n$ in the first example if we do in this case. Is it because we only divide by $n$ when using the central limit theorem, and the first example had only 20 samples taken, meaning that the central limit theorem could not be used? In this way, does it depend on the size of $n$? Any help will be greatly appreciated, thanks in advance.",,['statistics']
89,Variance of Beta in the Normal Linear Regression Model,Variance of Beta in the Normal Linear Regression Model,,"Let $Y_1, Y_2, \ldots, Y_n$ represent response variables and let $x_1, x_2,\ldots, x_n$ be the associated explanatory variables. In the normal linear regression model, it's assumed that: $$Y_i \sim N(\alpha + \beta x_i, \sigma^2).$$ The maximum likelihood estimate for $\beta$ is $\hat \beta = \frac{S_{XY}}{S_{XX}}$ where $S_{XY} = \sum_{i=1}^{n} (x_i - \bar x )(Y_i - \bar Y)$ and $S_{XX} = \sum_{i=1}^{n} (x_i - \bar x )^2$. Clearly $\hat \beta$ is a normally distributed random variable (being a linear combination of normal random variables). I'm trying to show that it's variance is $\frac{\sigma^2}{S_{XX}}$ - but am really struggling. I would really appreciate any pointers, hints, or solutions. Thanks, Jack","Let $Y_1, Y_2, \ldots, Y_n$ represent response variables and let $x_1, x_2,\ldots, x_n$ be the associated explanatory variables. In the normal linear regression model, it's assumed that: $$Y_i \sim N(\alpha + \beta x_i, \sigma^2).$$ The maximum likelihood estimate for $\beta$ is $\hat \beta = \frac{S_{XY}}{S_{XX}}$ where $S_{XY} = \sum_{i=1}^{n} (x_i - \bar x )(Y_i - \bar Y)$ and $S_{XX} = \sum_{i=1}^{n} (x_i - \bar x )^2$. Clearly $\hat \beta$ is a normally distributed random variable (being a linear combination of normal random variables). I'm trying to show that it's variance is $\frac{\sigma^2}{S_{XX}}$ - but am really struggling. I would really appreciate any pointers, hints, or solutions. Thanks, Jack",,"['statistics', 'statistical-inference', 'regression', 'linear-regression']"
90,Motivation Of Correlation Coefficient Formula,Motivation Of Correlation Coefficient Formula,,"Definitions correlation coefficient $= r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2\sum_{i=1}^{n}(y_i - \bar{y})^2}}$ My Question What is the motivation of this formula? It's supposed to measure linear relationships on bivariate data, but I don't understand why it would do that as defined. For example, Riemann integrals are said to measure area under a curve, and that makes sense because $\sum f(x_i)\Delta x$ is adding areas of rectangles under the curve $f(x)$ approximating its area more and more as we take more samples. Does such an intuition exist for the correlation coefficient? What is it? My background in statistics is nothing but a bit of discrete probability. I know histograms, data plots, mean, median, range, variance, standard deviation, box plots and scatter plots at this point (from reading the first weeks material on an introductory statistics class). My Research All of the ""Questions that may already have your answer"" seemed to either be asking about what the formula said mathematically or asked questions that were more advanced than my knowledge.","Definitions correlation coefficient $= r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2\sum_{i=1}^{n}(y_i - \bar{y})^2}}$ My Question What is the motivation of this formula? It's supposed to measure linear relationships on bivariate data, but I don't understand why it would do that as defined. For example, Riemann integrals are said to measure area under a curve, and that makes sense because $\sum f(x_i)\Delta x$ is adding areas of rectangles under the curve $f(x)$ approximating its area more and more as we take more samples. Does such an intuition exist for the correlation coefficient? What is it? My background in statistics is nothing but a bit of discrete probability. I know histograms, data plots, mean, median, range, variance, standard deviation, box plots and scatter plots at this point (from reading the first weeks material on an introductory statistics class). My Research All of the ""Questions that may already have your answer"" seemed to either be asking about what the formula said mathematically or asked questions that were more advanced than my knowledge.",,['statistics']
91,Find value in standard normal distribution equation,Find value in standard normal distribution equation,,"I'm given the following equation: $P(X<b)=0.05$ and $X \sim N(-1, 4)$. Now I have to find the value of b in this equation. First, I convert $P(X<b)$ to be using the standard normal distribution. This gives $P(Z<\frac{b - \mu} \sigma) = 0.05$ or $P(Z<\frac{b + 1} 2)=0.05$. By looking into a table with all values for $\phi(z)$, I found out that $\frac{b + 1} 2 = -3.29$ or $b = -7.58$. The solution that was given by the teacher is $-4.29$. I don't know what I did wrong?","I'm given the following equation: $P(X<b)=0.05$ and $X \sim N(-1, 4)$. Now I have to find the value of b in this equation. First, I convert $P(X<b)$ to be using the standard normal distribution. This gives $P(Z<\frac{b - \mu} \sigma) = 0.05$ or $P(Z<\frac{b + 1} 2)=0.05$. By looking into a table with all values for $\phi(z)$, I found out that $\frac{b + 1} 2 = -3.29$ or $b = -7.58$. The solution that was given by the teacher is $-4.29$. I don't know what I did wrong?",,"['statistics', 'normal-distribution']"
92,Stochastic Gradient Descent (SGD) algorithm explanation,Stochastic Gradient Descent (SGD) algorithm explanation,,I am new to machine learning and am currently trying to understand the Stochastic Gradient Descent (SGD) algorithm.  $$ w := w - \eta\nabla Q_i(w) $$ As I understand it so far $Q_i(w)$ is what is going to be estimated - $i$ being the current dataset under observation. Can anyone help break down what the equation means? Thank you,I am new to machine learning and am currently trying to understand the Stochastic Gradient Descent (SGD) algorithm.  $$ w := w - \eta\nabla Q_i(w) $$ As I understand it so far $Q_i(w)$ is what is going to be estimated - $i$ being the current dataset under observation. Can anyone help break down what the equation means? Thank you,,"['statistics', 'optimization', 'machine-learning', 'gradient-descent']"
93,Autocovariance function in $AR(1)$ process,Autocovariance function in  process,AR(1),"Let a autoregressive process $AR(1)$ given by $$x_t=\sum_{j=0}^\infty \phi^jw_{t-j}$$ where $|\phi|<1$ and $w_{t-j}$ is i.i.d a white noise with mean 0 and variance $\sigma^2$. The autocovariance function is $$\gamma(h)=cov(x_{t+h},x_t)=E\Big[\Big(\sum_{j=0}^\infty \phi^jw_{t+h-j}\Big)\Big(\sum_{k=0}^\infty \phi^k w_{t-k}\Big)\Big]$$ $$=E[(w_{t+h}+\dots+\phi^hw_t+\phi^{h+1}w_{t-1}+\dots)(w_t+\phi w_{t-1}+\phi^2 w_{t-2}+\dots)\qquad\textbf{(1)}$$ $$=\sigma^2\sum_{j=0}^\infty \phi^{h+j}\phi^j=\sigma^2\phi^h\sum_{j=0}^\infty \phi^{2j}=\frac{\sigma_2\phi^h}{1-\phi^2},\qquad h\geq 0$$ I know that last equality is the power series representation of that sum, but I'm having hard time to understand how they get $$\sigma^2\sum_{j=0}^\infty \phi^{h+j}\phi^j$$ from $\textbf{(1)}$. I know that they are using $$E[w_{j}w_{k}]=E[w_t^2]=Var(w_t)=\sigma^2$$ in the expectations, but I don't understood how to get the exponents in $\phi$ Anyone can help me?","Let a autoregressive process $AR(1)$ given by $$x_t=\sum_{j=0}^\infty \phi^jw_{t-j}$$ where $|\phi|<1$ and $w_{t-j}$ is i.i.d a white noise with mean 0 and variance $\sigma^2$. The autocovariance function is $$\gamma(h)=cov(x_{t+h},x_t)=E\Big[\Big(\sum_{j=0}^\infty \phi^jw_{t+h-j}\Big)\Big(\sum_{k=0}^\infty \phi^k w_{t-k}\Big)\Big]$$ $$=E[(w_{t+h}+\dots+\phi^hw_t+\phi^{h+1}w_{t-1}+\dots)(w_t+\phi w_{t-1}+\phi^2 w_{t-2}+\dots)\qquad\textbf{(1)}$$ $$=\sigma^2\sum_{j=0}^\infty \phi^{h+j}\phi^j=\sigma^2\phi^h\sum_{j=0}^\infty \phi^{2j}=\frac{\sigma_2\phi^h}{1-\phi^2},\qquad h\geq 0$$ I know that last equality is the power series representation of that sum, but I'm having hard time to understand how they get $$\sigma^2\sum_{j=0}^\infty \phi^{h+j}\phi^j$$ from $\textbf{(1)}$. I know that they are using $$E[w_{j}w_{k}]=E[w_t^2]=Var(w_t)=\sigma^2$$ in the expectations, but I don't understood how to get the exponents in $\phi$ Anyone can help me?",,"['statistics', 'stochastic-processes', 'self-learning', 'time-series']"
94,Quotient of two Gaussian densities,Quotient of two Gaussian densities,,"The matrix cookbook contains formulas for the product of two multivariate Gaussians, but doesn't appear to contain formulas for the quotient of two Gaussians. $$ \frac{\mathcal{N}(\mathbf{m}_1, \Sigma_1)}{\mathcal{N}(\mathbf{m}_2, \Sigma_2)} = ~?? $$ Note that I'm not looking for the quotient of two random variables ( answered here ), I just care about the quotient of two PDFs. Context: I'm trying to derive factor analysis from Roweis and Ghahramani (1999) . They apply Bayes rule: $$ p(\mathbf{x} \mid \mathbf{y}) = \frac{p(\mathbf{y} \mid \mathbf{x}) p(\mathbf{x})}{p(\mathbf{y})} \\ =\frac{\mathcal{N}(C\mathbf{x}, R)\mathcal{N}(0, I)}{\mathcal{N}(0,CC^T + R)} \\ = \frac{\mathcal{N}((R^{-1} + I)^{-1} (R^{-1} C \mathbf{x}), (R^{-1} + I)^{-1})}{\mathcal{N}(0,CC^T + R)} \\ \vdots \\ ??? \\ \vdots \\ = \mathcal{N}(\boldsymbol{\beta} \mathbf{y}, I - \boldsymbol{\beta} C), \quad \boldsymbol{\beta} = C^T (C C^T + R)^{-1} $$ I used the matrix cookbook for the third equality. R is a covariance matrix without any special assumptions at this point in the paper.","The matrix cookbook contains formulas for the product of two multivariate Gaussians, but doesn't appear to contain formulas for the quotient of two Gaussians. $$ \frac{\mathcal{N}(\mathbf{m}_1, \Sigma_1)}{\mathcal{N}(\mathbf{m}_2, \Sigma_2)} = ~?? $$ Note that I'm not looking for the quotient of two random variables ( answered here ), I just care about the quotient of two PDFs. Context: I'm trying to derive factor analysis from Roweis and Ghahramani (1999) . They apply Bayes rule: $$ p(\mathbf{x} \mid \mathbf{y}) = \frac{p(\mathbf{y} \mid \mathbf{x}) p(\mathbf{x})}{p(\mathbf{y})} \\ =\frac{\mathcal{N}(C\mathbf{x}, R)\mathcal{N}(0, I)}{\mathcal{N}(0,CC^T + R)} \\ = \frac{\mathcal{N}((R^{-1} + I)^{-1} (R^{-1} C \mathbf{x}), (R^{-1} + I)^{-1})}{\mathcal{N}(0,CC^T + R)} \\ \vdots \\ ??? \\ \vdots \\ = \mathcal{N}(\boldsymbol{\beta} \mathbf{y}, I - \boldsymbol{\beta} C), \quad \boldsymbol{\beta} = C^T (C C^T + R)^{-1} $$ I used the matrix cookbook for the third equality. R is a covariance matrix without any special assumptions at this point in the paper.",,"['statistics', 'normal-distribution']"
95,How to derive Population Variance formula?,How to derive Population Variance formula?,,"There's a formula of variance on wikipedia , but I'm confused with the last equality. How does it come out? $$\sigma^2 = \frac{1}{N} \sum_{i=1}^N (x_i-\mu)^2 = \left(\frac{1}{N}\sum_{i=1}^N x_i^2\right)-\mu^2 = \frac{1}{N^2} \sum_{i<j} \left(x_i-x_j\right)^2$$","There's a formula of variance on wikipedia , but I'm confused with the last equality. How does it come out? $$\sigma^2 = \frac{1}{N} \sum_{i=1}^N (x_i-\mu)^2 = \left(\frac{1}{N}\sum_{i=1}^N x_i^2\right)-\mu^2 = \frac{1}{N^2} \sum_{i<j} \left(x_i-x_j\right)^2$$",,['statistics']
96,Median of Medians,Median of Medians,,"Given a set A with median A m = 10 and set B with median B m = 20 is it true that the median of the combined set C is $10 \le$ C m $\le 20$ ? My first thought was that this wasn't true so I tried to find a counter example but I wasnt able to so I am assuming that it likely is true but I havent been able to find any theorem or other proof for this. Ideally I would like to know if this is true for the general case not just 10,20 I just chose these numbers while trying to find a counter example. Any help would be greatly appreciated.","Given a set A with median A m = 10 and set B with median B m = 20 is it true that the median of the combined set C is $10 \le$ C m $\le 20$ ? My first thought was that this wasn't true so I tried to find a counter example but I wasnt able to so I am assuming that it likely is true but I havent been able to find any theorem or other proof for this. Ideally I would like to know if this is true for the general case not just 10,20 I just chose these numbers while trying to find a counter example. Any help would be greatly appreciated.",,"['statistics', 'data-analysis', 'median']"
97,The relationship between sample variance and proportion variance?,The relationship between sample variance and proportion variance?,,"I'm trying to see the relationship between the sample variance equation $\sum(X_i- \bar X)^2/(n-1)$ and the variance estimate, $\bar X(1-\bar X),$ in case of binary samples. I wonder if the outputs are the same, or if not, what is the relationship between the two?? I'm trying to prove their relationship but it's quite challenging to me.. Please help! Sigma(Xi-Xbar)/(n-1) Xbar(1-Xbar)","I'm trying to see the relationship between the sample variance equation $\sum(X_i- \bar X)^2/(n-1)$ and the variance estimate, $\bar X(1-\bar X),$ in case of binary samples. I wonder if the outputs are the same, or if not, what is the relationship between the two?? I'm trying to prove their relationship but it's quite challenging to me.. Please help! Sigma(Xi-Xbar)/(n-1) Xbar(1-Xbar)",,"['statistics', 'variance']"
98,Integration of Exponential,Integration of Exponential,,"I am trying to integrate this function $f(x)=e^{-c/x}$. $$\int_{a}^b e^{-c/x} dx \\$$ where $c$ is just a constant and $0<a<b$. But $u$ subsititution leads to me to an integration by parts which leads to another integration by parts that keeps going. Is there a closed form solution to this integral?? I appreciate any help. Thank you. Update: I derived this function from a conditional pdf. $f(y|x)=x^{-1}e^{-y/x}$ and $f(x)=x$ on $[0,\sqrt{2}]$. By using Bayes Theorem you get a joint pdf $f(x,y)=e^{-y/x}$. Now using the joint pdf I am trying to solve for partial pdf $f_y(y)$. In the problem above I generalize it to $[a,b]$ and $y=c$.","I am trying to integrate this function $f(x)=e^{-c/x}$. $$\int_{a}^b e^{-c/x} dx \\$$ where $c$ is just a constant and $0<a<b$. But $u$ subsititution leads to me to an integration by parts which leads to another integration by parts that keeps going. Is there a closed form solution to this integral?? I appreciate any help. Thank you. Update: I derived this function from a conditional pdf. $f(y|x)=x^{-1}e^{-y/x}$ and $f(x)=x$ on $[0,\sqrt{2}]$. By using Bayes Theorem you get a joint pdf $f(x,y)=e^{-y/x}$. Now using the joint pdf I am trying to solve for partial pdf $f_y(y)$. In the problem above I generalize it to $[a,b]$ and $y=c$.",,"['integration', 'statistics']"
99,How to prove that $\hat\sigma^2$ has $\chi^2_{n-p}$ distribution (linear regression),How to prove that  has  distribution (linear regression),\hat\sigma^2 \chi^2_{n-p},"Consider the linear regression model: $$Y_i=r(x_i)+\varepsilon_i\equiv\sum_{j = 1}^p x_{ij} \beta _j + \varepsilon _i,\quad i=1,\ldots,n.$$ where $x_1,\ldots,x_n\in \mathbb{R}^p$ are fixed, $E(\varepsilon_i)=0$,  $\operatorname{Var}(\varepsilon_i)=\sigma^2$. Denote $Y=(Y_1,\ldots,Y_n)^T$, $\beta=(\beta_1,\ldots,\beta_p)^T$, $X=(x_{ij})_{n\times p}$. As is known, $\hat \beta  = \arg\min\limits_{\beta  \in \mathbb{R}^p} (Y - X\beta)^T (Y - X\beta)=(X^TX)^{-1}X^TY$ if the matrix $X^TX$ is invertible, and so an estimator of $r(x)$ at $x=(x_1,\ldots,x_p)\in\mathbb{R}^p$ is given by $\hat r_n(x)=x^T\hat\beta$. Let $$\hat{\sigma}^2 = \frac{1}{\sigma^2}\sum_{i = 1}^n (Y_i - {\hat r}_n (x_i))^2.$$ I am stucking the problem: $\hat\sigma^2$ has $\chi^2_{n-p}$ distribution. How to prove the statement?","Consider the linear regression model: $$Y_i=r(x_i)+\varepsilon_i\equiv\sum_{j = 1}^p x_{ij} \beta _j + \varepsilon _i,\quad i=1,\ldots,n.$$ where $x_1,\ldots,x_n\in \mathbb{R}^p$ are fixed, $E(\varepsilon_i)=0$,  $\operatorname{Var}(\varepsilon_i)=\sigma^2$. Denote $Y=(Y_1,\ldots,Y_n)^T$, $\beta=(\beta_1,\ldots,\beta_p)^T$, $X=(x_{ij})_{n\times p}$. As is known, $\hat \beta  = \arg\min\limits_{\beta  \in \mathbb{R}^p} (Y - X\beta)^T (Y - X\beta)=(X^TX)^{-1}X^TY$ if the matrix $X^TX$ is invertible, and so an estimator of $r(x)$ at $x=(x_1,\ldots,x_p)\in\mathbb{R}^p$ is given by $\hat r_n(x)=x^T\hat\beta$. Let $$\hat{\sigma}^2 = \frac{1}{\sigma^2}\sum_{i = 1}^n (Y_i - {\hat r}_n (x_i))^2.$$ I am stucking the problem: $\hat\sigma^2$ has $\chi^2_{n-p}$ distribution. How to prove the statement?",,"['statistics', 'statistical-inference']"
