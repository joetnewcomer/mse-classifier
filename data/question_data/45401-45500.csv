,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,$\mathbb{Z} _{29}$ is a field. True or False.,is a field. True or False.,\mathbb{Z} _{29},"My answer was True and this is my argument: Since $\mathbb{Z}_{n}$ has got $2$ operations plus the other properties of a ring, I figured that it is indeed a ring. On the other hand, since $\mathbb{Z}_{n}$ is abelian (commutative) and has the multiplicative identity $1$, It can be concluded that it is a $Commutative$ Ring with an $identity$, hence implies that it is a Field. I've also read a theorem which states that: ""Every finite integral domain is a field."" Is my argument acceptable and can I also use the above theorem as an argument? Your help would be really appreciated.","My answer was True and this is my argument: Since $\mathbb{Z}_{n}$ has got $2$ operations plus the other properties of a ring, I figured that it is indeed a ring. On the other hand, since $\mathbb{Z}_{n}$ is abelian (commutative) and has the multiplicative identity $1$, It can be concluded that it is a $Commutative$ Ring with an $identity$, hence implies that it is a Field. I've also read a theorem which states that: ""Every finite integral domain is a field."" Is my argument acceptable and can I also use the above theorem as an argument? Your help would be really appreciated.",,"['abstract-algebra', 'ring-theory']"
1,Are there homomorphisms of group algebras that don't come from a group homomorphism?,Are there homomorphisms of group algebras that don't come from a group homomorphism?,,"Given a finite group $G$, one can define the group algebra $\mathbb{C}[G]$ as the algebra having the elements of $G$ as a basis, with the multiplication of $G$. Clearly, any group homomorphism induces an algebra homomorphism on the group algebras. I'm wondering whether one can prove that any algebra homomorphism of two group algebras must always come from a homomorphism of groups.","Given a finite group $G$, one can define the group algebra $\mathbb{C}[G]$ as the algebra having the elements of $G$ as a basis, with the multiplication of $G$. Clearly, any group homomorphism induces an algebra homomorphism on the group algebras. I'm wondering whether one can prove that any algebra homomorphism of two group algebras must always come from a homomorphism of groups.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'group-rings']"
2,Examples of loops which have two-sided inverses.,Examples of loops which have two-sided inverses.,,Are there any neat examples of non-associative loops such that for each element a in the loop there exists $a^{-1}$ so that $a*a^{-1}=1=a^{-1}*a$.  Even cooler would be a commutative loop. Also: are there commutative finite loops?,Are there any neat examples of non-associative loops such that for each element a in the loop there exists $a^{-1}$ so that $a*a^{-1}=1=a^{-1}*a$.  Even cooler would be a commutative loop. Also: are there commutative finite loops?,,"['abstract-algebra', 'reference-request', 'examples-counterexamples', 'abelian-groups', 'grouplike-elements']"
3,Construct a finite field of order 27,Construct a finite field of order 27,,"So some of my thoughts for constructing a finite field of order 27 are making me think of a field with $p^n$ elements, where $p = 3$ and $n = 3$ such that we want a cubic polynomial in $\mathbb{F}_3[X]$ that does not factor. Could this be thought of as looking for a cubic polynomial in $\mathbb{F}_3[X]$ with no roots in $\mathbb{F}_3$? Could this polynomial work: $x^3 + 2x^2 + 1$ ?","So some of my thoughts for constructing a finite field of order 27 are making me think of a field with $p^n$ elements, where $p = 3$ and $n = 3$ such that we want a cubic polynomial in $\mathbb{F}_3[X]$ that does not factor. Could this be thought of as looking for a cubic polynomial in $\mathbb{F}_3[X]$ with no roots in $\mathbb{F}_3$? Could this polynomial work: $x^3 + 2x^2 + 1$ ?",,['abstract-algebra']
4,If $\alpha$ and $\beta$ are algebraic integers then any solution to $x^2+\alpha x + \beta = 0$ is also an algebraic integer.,If  and  are algebraic integers then any solution to  is also an algebraic integer.,\alpha \beta x^2+\alpha x + \beta = 0,An algebraic integer is a complex number that is a root of a monic polynomial with coefficients in $\mathbb{Z}$. Let $\alpha$ and $\beta$ be algebraic integers. Then any solution to $x^2+\alpha x + \beta = 0$ is also an algebraic integer. What we have so far is that $2x+\alpha$ is an algebraic integer but since the set of algebraic integers is a ring I can't divide by 2 so I can't have an algebraic integer and also the polynomial wouldn't be monic. I appreciate the help.,An algebraic integer is a complex number that is a root of a monic polynomial with coefficients in $\mathbb{Z}$. Let $\alpha$ and $\beta$ be algebraic integers. Then any solution to $x^2+\alpha x + \beta = 0$ is also an algebraic integer. What we have so far is that $2x+\alpha$ is an algebraic integer but since the set of algebraic integers is a ring I can't divide by 2 so I can't have an algebraic integer and also the polynomial wouldn't be monic. I appreciate the help.,,"['abstract-algebra', 'number-theory', 'algebraic-number-theory']"
5,"free subgroups of $SL(2,\mathbb{R})$",free subgroups of,"SL(2,\mathbb{R})","In the example section of the wikipedia article on the the Ping Pong lemma , you can see how to construct a free subgroup of $SL(2,\mathbb{R})$ with two generators  $$ a_1 = \begin{pmatrix} 1 & 2 \\ 0 & 1 \end{pmatrix},  \ \ \ \ \ a_2 =  \begin{pmatrix} 1 & 0 \\ 2 & 1 \end{pmatrix}. $$ Is it possible to construct free subgroups of $SL(2,\mathbb{R})$ with an arbitrary number of generators in a similar way (using the Ping Pong lemma)? Do such subgroups even exist? Sorry if this is a stupid question, I'm a noob at group theory.","In the example section of the wikipedia article on the the Ping Pong lemma , you can see how to construct a free subgroup of $SL(2,\mathbb{R})$ with two generators  $$ a_1 = \begin{pmatrix} 1 & 2 \\ 0 & 1 \end{pmatrix},  \ \ \ \ \ a_2 =  \begin{pmatrix} 1 & 0 \\ 2 & 1 \end{pmatrix}. $$ Is it possible to construct free subgroups of $SL(2,\mathbb{R})$ with an arbitrary number of generators in a similar way (using the Ping Pong lemma)? Do such subgroups even exist? Sorry if this is a stupid question, I'm a noob at group theory.",,"['abstract-algebra', 'lie-groups', 'geometric-group-theory']"
6,Is $\mathbb Z/p\mathbb Z$ a subfield of every finite field?,Is  a subfield of every finite field?,\mathbb Z/p\mathbb Z,"I translate this from a German book: ""For every finite field  $K$ there exists a prime number $p$ such that $\mathbb Z/p\mathbb Z$ is a subfield of $K$"" But how is this possible? For example the field $K = \{0,1\}$ contains integers but $\mathbb Z/p\mathbb Z$ contains equivalence classes. To be a subfield it would also have to be a subset of $K$.","I translate this from a German book: ""For every finite field  $K$ there exists a prime number $p$ such that $\mathbb Z/p\mathbb Z$ is a subfield of $K$"" But how is this possible? For example the field $K = \{0,1\}$ contains integers but $\mathbb Z/p\mathbb Z$ contains equivalence classes. To be a subfield it would also have to be a subset of $K$.",,['abstract-algebra']
7,"Example of ""ring"" without the distributive property?","Example of ""ring"" without the distributive property?",,"Can anyone give an example of an ""non-artificial"" algebraic structure that fails to be a ring only because of a lack of one- and two-sided distributive property?","Can anyone give an example of an ""non-artificial"" algebraic structure that fails to be a ring only because of a lack of one- and two-sided distributive property?",,"['abstract-algebra', 'ring-theory']"
8,"Define the dual group $\hat G$ as the set of all homs. from $G$ to $\Bbb C^*$, with pointwise multiplication. Show $\hat G$ is an abelian group.","Define the dual group  as the set of all homs. from  to , with pointwise multiplication. Show  is an abelian group.",\hat G G \Bbb C^* \hat G,"I don't really understand the nature of $\hat G$ as described in this question: For any group $G$ , define its dual group $\hat G$ to be the set of all homomorphisms from $G$ into $\mathbb{C}^*$ , together with the binary operation of pointwise multiplication of functions. Show that this binary operation makes $\hat G$ into an abelian group. I understand that any element of finite order would have to be mapped into some element of $\mathbb{C}^*$ that's of the same order, which means $x \in \mathbb{C}^*$ such that $x^a = 1$ , but I don't know what those elements look like other than the obvious ( $i, -1, -i$ and $1$ ). To emphasize my ignorance, to me the set of all homomorphisms from an arbitrary group into an uncountably infinite set seems like a really general set that would be difficult to analyze.","I don't really understand the nature of as described in this question: For any group , define its dual group to be the set of all homomorphisms from into , together with the binary operation of pointwise multiplication of functions. Show that this binary operation makes into an abelian group. I understand that any element of finite order would have to be mapped into some element of that's of the same order, which means such that , but I don't know what those elements look like other than the obvious ( and ). To emphasize my ignorance, to me the set of all homomorphisms from an arbitrary group into an uncountably infinite set seems like a really general set that would be difficult to analyze.","\hat G G \hat G G \mathbb{C}^* \hat G \mathbb{C}^* x \in \mathbb{C}^* x^a = 1 i, -1, -i 1","['abstract-algebra', 'group-theory', 'complex-numbers', 'abelian-groups', 'group-homomorphism']"
9,"Prove $(a^m)^n=a^{mn}$ for all $a\in G$ and $m,n\in\mathbb{Z}$",Prove  for all  and,"(a^m)^n=a^{mn} a\in G m,n\in\mathbb{Z}","I have to prove  $(a^m)^n=a^{mn}$ for all $a\in G$ and $m,n\in\mathbb{Z}$ where $G$ is a group. Is it enough to just expand $(a^m)^n=(a^m***a^m)$- $n$ times. And then from here we can expand it a bit more to there there are $mn$ amount of $a's$? Or do I need to break it up into cases. I felt if I did I'll have atleast 3 cases and a few subcases. As of right now I have two cases one where $m=n=0$ and the other where $a,b\neq 0$. Here is what I have so far. New proof #2 Case 1: Let $m>0$ and $n>0$ We will proceed by induction. We fix m and induct on n.    Base case: Let n=1. We see that $a^m=a^m$.    Inductive case: Suppose that $(a^m)^k=a^{mk}$ We shall prove $(a^m)^{k+1}=a^{m(k+1)}$.   It follows immediately from assumption that $(a^m)^{k+1}=a^{m(k+1)}$. Case 2: $m=n=0$. It is immediately obvious that  $(a^m)^n=a^{mn}$ Case 3: $m<0$ and $n<0$.  Let $m=-t$ and $n=-r$ where $t,r>0$. Then $(a^m)^n=(a^{-t})^{-r})=(a^{-1})^t)^r)^{-1}=(a^{-1})^{rt})^{-1}=(a^{-nt})^{-1}=(a^{nt})^{-1}=a^{n*(-1)t}=a^{mn}$","I have to prove  $(a^m)^n=a^{mn}$ for all $a\in G$ and $m,n\in\mathbb{Z}$ where $G$ is a group. Is it enough to just expand $(a^m)^n=(a^m***a^m)$- $n$ times. And then from here we can expand it a bit more to there there are $mn$ amount of $a's$? Or do I need to break it up into cases. I felt if I did I'll have atleast 3 cases and a few subcases. As of right now I have two cases one where $m=n=0$ and the other where $a,b\neq 0$. Here is what I have so far. New proof #2 Case 1: Let $m>0$ and $n>0$ We will proceed by induction. We fix m and induct on n.    Base case: Let n=1. We see that $a^m=a^m$.    Inductive case: Suppose that $(a^m)^k=a^{mk}$ We shall prove $(a^m)^{k+1}=a^{m(k+1)}$.   It follows immediately from assumption that $(a^m)^{k+1}=a^{m(k+1)}$. Case 2: $m=n=0$. It is immediately obvious that  $(a^m)^n=a^{mn}$ Case 3: $m<0$ and $n<0$.  Let $m=-t$ and $n=-r$ where $t,r>0$. Then $(a^m)^n=(a^{-t})^{-r})=(a^{-1})^t)^r)^{-1}=(a^{-1})^{rt})^{-1}=(a^{-nt})^{-1}=(a^{nt})^{-1}=a^{n*(-1)t}=a^{mn}$",,['abstract-algebra']
10,subgroup definition,subgroup definition,,"$H \subseteq \text{group  } G $, $H$ is not empty. If for any $a,b \in H$, we have $a^{-1}b^{-1} \in H$ , is it possible to deduce that $H$ is a subgroup of $G$ ? I feel like this is not necessarily true because the identity can't be proven to be in $H$, but I can't find an counterexample.","$H \subseteq \text{group  } G $, $H$ is not empty. If for any $a,b \in H$, we have $a^{-1}b^{-1} \in H$ , is it possible to deduce that $H$ is a subgroup of $G$ ? I feel like this is not necessarily true because the identity can't be proven to be in $H$, but I can't find an counterexample.",,"['abstract-algebra', 'group-theory']"
11,"Every field contains an isomorphic copy of the prime field $\mathbb{Q}$ if char $= 0$, and $\mathbb{Z}_p$ if char $= p$","Every field contains an isomorphic copy of the prime field  if char , and  if char",\mathbb{Q} = 0 \mathbb{Z}_p = p,"Every field contains an isomorphic copy of the prime field $\mathbb{Q}$ if char $= 0$, and $\mathbb{Z}_p$ if char $= p$. Could you help me prove this theorem? My professor introduced this theorem during the lecture but didn't prove it.","Every field contains an isomorphic copy of the prime field $\mathbb{Q}$ if char $= 0$, and $\mathbb{Z}_p$ if char $= p$. Could you help me prove this theorem? My professor introduced this theorem during the lecture but didn't prove it.",,"['abstract-algebra', 'field-theory']"
12,"Can I derive $i^2 \neq 1$ from a presentation $\langle i, j \mid i^4 = j^4 = 1, ij = j^3 i\rangle$ of Quaternion group $Q$?",Can I derive  from a presentation  of Quaternion group ?,"i^2 \neq 1 \langle i, j \mid i^4 = j^4 = 1, ij = j^3 i\rangle Q","(This question is related to the previous post I've posted few hours ago: (Dummit's AA, 1.5, P3) Are these presentations of the Quarternion group equivalent? ) I was trying to prove that the presentation $$\langle i, j \mid i^4 = j^4 = 1, ij = j^3 i\rangle $$ generates Quaternion group. The only thing that I couldn't derive was that $i^2 \neq 1$. I tried to derive a contradiction from the supposition $i^2 =1$ but this didn't give me a contradiction (at least not yet) but rather it brought me to an Abelian group that consists of 4 elements with every element other than 1 having order 2. I'm not sure where I'm wrong. Does indeed the above presentation generate an Abelian group with its order 4? (I think this can't happen according to the previous post!!) Or $i^2 = 1$ is a indeed contradictory? If the latter is the case, would you please show me the derivation?","(This question is related to the previous post I've posted few hours ago: (Dummit's AA, 1.5, P3) Are these presentations of the Quarternion group equivalent? ) I was trying to prove that the presentation $$\langle i, j \mid i^4 = j^4 = 1, ij = j^3 i\rangle $$ generates Quaternion group. The only thing that I couldn't derive was that $i^2 \neq 1$. I tried to derive a contradiction from the supposition $i^2 =1$ but this didn't give me a contradiction (at least not yet) but rather it brought me to an Abelian group that consists of 4 elements with every element other than 1 having order 2. I'm not sure where I'm wrong. Does indeed the above presentation generate an Abelian group with its order 4? (I think this can't happen according to the previous post!!) Or $i^2 = 1$ is a indeed contradictory? If the latter is the case, would you please show me the derivation?",,['abstract-algebra']
13,Does every category have a functor?,Does every category have a functor?,,"Is there any one (or more) categories that doesn't have a functor? Functors go between categories, so is there any category that only has an identity functor but no other functor that maps it to another category?","Is there any one (or more) categories that doesn't have a functor? Functors go between categories, so is there any category that only has an identity functor but no other functor that maps it to another category?",,"['category-theory', 'abstract-algebra']"
14,Homomorphisms between $ \mathbb{Z} $ modules.,Homomorphisms between  modules., \mathbb{Z} ,"Calculate $\newcommand\Hom{\operatorname{Hom}}\Hom(\mathbb Z \oplus \mathbb Z_{p^\infty},\mathbb Z \oplus \mathbb Z_{p^\infty})$. Where $ \mathbb Z_{p^\infty}= \bigcup_{k=1}^{\infty}\bar{\langle\frac1{p^k}\rangle}$ for $p$ prime. As $\mathbb Z$ and  $\mathbb Z_{p^\infty}$ are $\mathbb Z$-modules then applying the theorem $\Hom_A ( \bigoplus_{i \in I} M_i, \prod_{j \in J} N_j ) \cong\prod_{(i,j) \in I \times J} \Hom(M_i,N_j)$ because for finite indices have $\bigoplus_{i=1}^{n}M_i = \prod_{i=1}^n M_1$. Then the problem reduces to find those $\Hom$ where $$ \Hom(\mathbb{Z}, \mathbb{Z}) \cong \mathbb{Z} $$ $$ \Hom(\mathbb{Z},\mathbb{Z}_{p^\infty}) \cong \mathbb{Z}_{p^\infty}$$  but  $\Hom(\mathbb{Z}_{p^\infty},\mathbb{Z})$ and  $\Hom(\mathbb{Z}_{p^\infty},\mathbb{Z}_{p^\infty})$ not how to calculate them.","Calculate $\newcommand\Hom{\operatorname{Hom}}\Hom(\mathbb Z \oplus \mathbb Z_{p^\infty},\mathbb Z \oplus \mathbb Z_{p^\infty})$. Where $ \mathbb Z_{p^\infty}= \bigcup_{k=1}^{\infty}\bar{\langle\frac1{p^k}\rangle}$ for $p$ prime. As $\mathbb Z$ and  $\mathbb Z_{p^\infty}$ are $\mathbb Z$-modules then applying the theorem $\Hom_A ( \bigoplus_{i \in I} M_i, \prod_{j \in J} N_j ) \cong\prod_{(i,j) \in I \times J} \Hom(M_i,N_j)$ because for finite indices have $\bigoplus_{i=1}^{n}M_i = \prod_{i=1}^n M_1$. Then the problem reduces to find those $\Hom$ where $$ \Hom(\mathbb{Z}, \mathbb{Z}) \cong \mathbb{Z} $$ $$ \Hom(\mathbb{Z},\mathbb{Z}_{p^\infty}) \cong \mathbb{Z}_{p^\infty}$$  but  $\Hom(\mathbb{Z}_{p^\infty},\mathbb{Z})$ and  $\Hom(\mathbb{Z}_{p^\infty},\mathbb{Z}_{p^\infty})$ not how to calculate them.",,"['abstract-algebra', 'group-theory', 'modules']"
15,GCD in a subring is GCD in a bigger ring?,GCD in a subring is GCD in a bigger ring?,,"Let $R$ be a UFD which is a subring of an integral domain $S$. If $r_1$ and $r_2$ are two nonzero elements of $R$ with GCD $d$, is it true that $d$ is also a GCD of $r_1$ and $r_2$ in $S$? I know this is true if $R$ is a PID.","Let $R$ be a UFD which is a subring of an integral domain $S$. If $r_1$ and $r_2$ are two nonzero elements of $R$ with GCD $d$, is it true that $d$ is also a GCD of $r_1$ and $r_2$ in $S$? I know this is true if $R$ is a PID.",,"['abstract-algebra', 'ring-theory', 'divisibility', 'unique-factorization-domains']"
16,Classifying groups of order 90.,Classifying groups of order 90.,,"Since $3\cdot 3\cdot 2\cdot 5=90$, we know that we have a $3$-Sylow subgroup $P_3$ of order $9$, a $2$-sylow subgroup $P_2$ of order $2$, a $ 5$-Sylow subgroup $P_5$ of order $5$. I know that $P_5 \cong Z_5$ and $P_2 \cong Z_2$, right? But I'm not sure what $P_3$ is isomorphic to, because we cannot necessarily conclude that it is cyclic...since it might have $4$ different elements of order $3$. So when I'm looking at the different cases for the semidirect products (for example if I look at the case when all of the sylow subgroups are normal), I will just say $G \cong P_3 \times Z_{10}$, right? I am just asking to make sure if I'm doing it correctly (for this specific case). Thanks in advance","Since $3\cdot 3\cdot 2\cdot 5=90$, we know that we have a $3$-Sylow subgroup $P_3$ of order $9$, a $2$-sylow subgroup $P_2$ of order $2$, a $ 5$-Sylow subgroup $P_5$ of order $5$. I know that $P_5 \cong Z_5$ and $P_2 \cong Z_2$, right? But I'm not sure what $P_3$ is isomorphic to, because we cannot necessarily conclude that it is cyclic...since it might have $4$ different elements of order $3$. So when I'm looking at the different cases for the semidirect products (for example if I look at the case when all of the sylow subgroups are normal), I will just say $G \cong P_3 \times Z_{10}$, right? I am just asking to make sure if I'm doing it correctly (for this specific case). Thanks in advance",,"['abstract-algebra', 'group-theory']"
17,Find $(1-ba)^{-1}$ when $c=(1-ab)^{-1} $ in ring $R$.,Find  when  in ring .,(1-ba)^{-1} c=(1-ab)^{-1}  R,"For $R$ is a ring has identity element. $a,b\in R$ and  $c=(1-ab)^{-1}$ . Find $(1-ba)^{-1}$.","For $R$ is a ring has identity element. $a,b\in R$ and  $c=(1-ab)^{-1}$ . Find $(1-ba)^{-1}$.",,"['abstract-algebra', 'ring-theory']"
18,$I[X]$ is a prime ideal in $R[X]$ iff I is a prime ideal in $R$,is a prime ideal in  iff I is a prime ideal in,I[X] R[X] R,Let $R$ be a commutative ring (not necessarily unital). Let I be an ideal of R. Show that $I[X]$ is a prime ideal in $R[X]$ iff  I is a prime ideal in $R$. I have attempted to use the facts: I is prime iff $R/I$ is an ID. I is maximal iff $R/I$ is a field. But both require $R$ to be a commutative unital ring. I thought constructing an isomorphism might work but not entirely sure. A more detailed explanation is very much appreciated. Thanks.,Let $R$ be a commutative ring (not necessarily unital). Let I be an ideal of R. Show that $I[X]$ is a prime ideal in $R[X]$ iff  I is a prime ideal in $R$. I have attempted to use the facts: I is prime iff $R/I$ is an ID. I is maximal iff $R/I$ is a field. But both require $R$ to be a commutative unital ring. I thought constructing an isomorphism might work but not entirely sure. A more detailed explanation is very much appreciated. Thanks.,,['abstract-algebra']
19,Prove that there exist no element of order 18 in $S_9$,Prove that there exist no element of order 18 in,S_9,"Prove that there exist no element of order 18 in $S_9$. How do I prove this ? I think the idea is that elements of the form: $(123456)(789)$ have order 6 as $\text{lcm}(6,3)=6$. Elements of the form $(123456789)(10\,11)$ surely don't exist in $S_9$. And I don't see any other ways to get to order 18. How do I prove this rigoursly ?","Prove that there exist no element of order 18 in $S_9$. How do I prove this ? I think the idea is that elements of the form: $(123456)(789)$ have order 6 as $\text{lcm}(6,3)=6$. Elements of the form $(123456789)(10\,11)$ surely don't exist in $S_9$. And I don't see any other ways to get to order 18. How do I prove this rigoursly ?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
20,Where do I use the fact that $F$ is algebraically closed in this proof?,Where do I use the fact that  is algebraically closed in this proof?,F,"I have to do the following. Let $F$ be an algebraically closed field. $I\in F[X_1,...,X_n]$ an ideal. Denote by $S(I)$ the subset in $F^n$ consisting of all $n$-tuples $(a_1,...,a_n)\in F^n$ such that $f(a_1,...,a_n)=0$ for all $f\in I$. A subset $S\subset F^n$ is called closed if there exists an ideal $I$ (of $F[X_1,...,X_n]$ such that $S=S(I)$. Prove that the union of any two closed sets is closed. Here is my attempt: First: I claim that if $S$ is closed then I can find an $I$ such that it is generated by one element and $S(I)=S$. Proof: By definition of closed we know there is a $J$ such that $S=S(J)$. Since our ring is Noetherian we know that $J$ is f.g. so $J=\langle f_1,..,f_k\rangle$. Let $h=\gcd(f_i)$. I claim that $I=\langle h\rangle $ works. If $(a_1,..,a_n)\in S$, then $f_i(a_1,..,a_n)=0$. Since $h=\sum \alpha_i f_i$ (Bezout), we just plug in $(a_1,...,a_n)$ at both sides and obtain that $h(a_1,...,a_n)=0$, so indeed $(a_1,...,a_n)\in S(I)$. For the reverse inclusion if $(a_1,..,a_n)\in S(I)$, then $h(a_1,...,a_n)=0$. As $h\mid f_i$, we have that $f_i(a_1,...,a_n)=0$, so $(a_1,...,a_n)\in S(J)$. Now using this fact, I will solve the question: Let $S_1$ and $S_2$ be closed with $I_1=\langle f\rangle$ and $I_2=\langle g\rangle$  such that $S_1=S(I_1)$, and $S_2=S(I_2)$. Then let $h=$lcm$ (f,g)$. Then we have that $S(\langle h\rangle)$ works. If $(a_1,...,a_n)\in S_1\cup S_2$, then either $f(a_1,...,a_n)$ or $g(a_1,...a_n)=0$ (wlog say the first case happens). Then since $f\mid h$ then $(a_1,...,a_n)\in S(\langle h\rangle)$. For the other inclusion just note that if $h(a_1,...,a_n)=0$ then eithe $f(a_1,...,a_n)=0$ or $g(a_1,...,a_n)=0$ (because otherwise we would have $fg(a_1,....,a_n)\neq 0$ and since $h\mid fg$ we would get a contradiction here) so we have that either $(a_1,...,a_n)\in S_1$ or $(a_1,...,a_n)\in S_2$. Question: Where do I need the algebraic closure here?","I have to do the following. Let $F$ be an algebraically closed field. $I\in F[X_1,...,X_n]$ an ideal. Denote by $S(I)$ the subset in $F^n$ consisting of all $n$-tuples $(a_1,...,a_n)\in F^n$ such that $f(a_1,...,a_n)=0$ for all $f\in I$. A subset $S\subset F^n$ is called closed if there exists an ideal $I$ (of $F[X_1,...,X_n]$ such that $S=S(I)$. Prove that the union of any two closed sets is closed. Here is my attempt: First: I claim that if $S$ is closed then I can find an $I$ such that it is generated by one element and $S(I)=S$. Proof: By definition of closed we know there is a $J$ such that $S=S(J)$. Since our ring is Noetherian we know that $J$ is f.g. so $J=\langle f_1,..,f_k\rangle$. Let $h=\gcd(f_i)$. I claim that $I=\langle h\rangle $ works. If $(a_1,..,a_n)\in S$, then $f_i(a_1,..,a_n)=0$. Since $h=\sum \alpha_i f_i$ (Bezout), we just plug in $(a_1,...,a_n)$ at both sides and obtain that $h(a_1,...,a_n)=0$, so indeed $(a_1,...,a_n)\in S(I)$. For the reverse inclusion if $(a_1,..,a_n)\in S(I)$, then $h(a_1,...,a_n)=0$. As $h\mid f_i$, we have that $f_i(a_1,...,a_n)=0$, so $(a_1,...,a_n)\in S(J)$. Now using this fact, I will solve the question: Let $S_1$ and $S_2$ be closed with $I_1=\langle f\rangle$ and $I_2=\langle g\rangle$  such that $S_1=S(I_1)$, and $S_2=S(I_2)$. Then let $h=$lcm$ (f,g)$. Then we have that $S(\langle h\rangle)$ works. If $(a_1,...,a_n)\in S_1\cup S_2$, then either $f(a_1,...,a_n)$ or $g(a_1,...a_n)=0$ (wlog say the first case happens). Then since $f\mid h$ then $(a_1,...,a_n)\in S(\langle h\rangle)$. For the other inclusion just note that if $h(a_1,...,a_n)=0$ then eithe $f(a_1,...,a_n)=0$ or $g(a_1,...,a_n)=0$ (because otherwise we would have $fg(a_1,....,a_n)\neq 0$ and since $h\mid fg$ we would get a contradiction here) so we have that either $(a_1,...,a_n)\in S_1$ or $(a_1,...,a_n)\in S_2$. Question: Where do I need the algebraic closure here?",,"['abstract-algebra', 'algebraic-geometry', 'ring-theory', 'field-theory', 'ideals']"
21,Field extensions that are not normal,Field extensions that are not normal,,"I am trying to come up with field extensions $M : L : K$ such that none of the three extensions $M:L, L:K, M:K$ are normal. So far, I have tried letting $K = \mathbb{Q}, L = \mathbb{Q}(\sqrt[3]{2})$. I know that $L$ is not normal over $K$  since $x^3 - 2$ is an irreducible polynomial over $K$ with a root in $L$ but does not split in $L$, due to having complex roots. Now I am not sure what a suitable choice of $M$ would be. I am using $M = \mathbb{Q}(\sqrt[3]{2},\sqrt{2})$, which is not normal over $K$ again by using $x^3 - 2$ as the non-splitting irreducible polynomial over $K$. To show that $M$ is not normal over $L$, I am trying to use the polynomial $x^6 - 32$: it has a root $\sqrt[6]{32} = \sqrt[3]{2} \cdot \sqrt{2}$ in $M$, and does not split in $M$ since it has complex roots, but how can we show this polynomial is irreducible over $L$, if indeed it is irreducible?","I am trying to come up with field extensions $M : L : K$ such that none of the three extensions $M:L, L:K, M:K$ are normal. So far, I have tried letting $K = \mathbb{Q}, L = \mathbb{Q}(\sqrt[3]{2})$. I know that $L$ is not normal over $K$  since $x^3 - 2$ is an irreducible polynomial over $K$ with a root in $L$ but does not split in $L$, due to having complex roots. Now I am not sure what a suitable choice of $M$ would be. I am using $M = \mathbb{Q}(\sqrt[3]{2},\sqrt{2})$, which is not normal over $K$ again by using $x^3 - 2$ as the non-splitting irreducible polynomial over $K$. To show that $M$ is not normal over $L$, I am trying to use the polynomial $x^6 - 32$: it has a root $\sqrt[6]{32} = \sqrt[3]{2} \cdot \sqrt{2}$ in $M$, and does not split in $M$ since it has complex roots, but how can we show this polynomial is irreducible over $L$, if indeed it is irreducible?",,"['abstract-algebra', 'field-theory', 'extension-field']"
22,Show that a nonempty set of integers that is closed under subtraction must also be closed under addition,Show that a nonempty set of integers that is closed under subtraction must also be closed under addition,,"So this is what I have so far: Let X be a nonempty set of integers Let $a,b\in X$ and we need to show that $a+b\in X$ Because $b\in X$ and X is closed under subtraction, than $b-b\in X$ Once again, by closure under subtraction $b-(b-b)\in X$ Since $a\in X$ as well, by closure under subtraction, $a-[(b-b)-b]\in X$ $a-[(b-b)-b]=a-(b-2b)=a-(-b)=a+b$ $\therefore a+b\in X$ But how would I show that the empty set is closed under addition as well?","So this is what I have so far: Let X be a nonempty set of integers Let $a,b\in X$ and we need to show that $a+b\in X$ Because $b\in X$ and X is closed under subtraction, than $b-b\in X$ Once again, by closure under subtraction $b-(b-b)\in X$ Since $a\in X$ as well, by closure under subtraction, $a-[(b-b)-b]\in X$ $a-[(b-b)-b]=a-(b-2b)=a-(-b)=a+b$ $\therefore a+b\in X$ But how would I show that the empty set is closed under addition as well?",,"['abstract-algebra', 'number-theory']"
23,Projective indecomposables versus general indecomposables,Projective indecomposables versus general indecomposables,,"Given a finite dimensional algebra, what is the exact relation between the indecomposable projective modules, and a general indecomposable module? In the case of an oriented quiver without cycles for example, it is easy to find the simples, and the indecomposable projectives. What does this tell us about a general indecomposable module? I guess the main question is, to understand the complete representation theory of a finite dimensional algebra (or let's say a quiver), what else do we need besides the simples and the projective indecomposables?","Given a finite dimensional algebra, what is the exact relation between the indecomposable projective modules, and a general indecomposable module? In the case of an oriented quiver without cycles for example, it is easy to find the simples, and the indecomposable projectives. What does this tell us about a general indecomposable module? I guess the main question is, to understand the complete representation theory of a finite dimensional algebra (or let's say a quiver), what else do we need besides the simples and the projective indecomposables?",,"['abstract-algebra', 'representation-theory', 'quiver']"
24,$S_4/V_4$ isomorphic to $S_3$ - Understanding Attached Tables,isomorphic to  - Understanding Attached Tables,S_4/V_4 S_3,"I think I see $ S_4/V_4 \cong S_3 $ from the first table beneath marked in the green. I just ignore $ V_4 $ and think of it as mapped away by the bijection $ f^{-1} $ where $ f(s) = s V_4 \iff f^{-1}(\sigma V_4) = s \in S_3 $ But why do they compute only $\{S_3\}V_4 $ ? By definition, $ S_4/V_4 = \{sV_4 : s \in S_4\} $ . Where are the rest of the elements in $ S_4/V_4 $ like $(2, 1, 3, 4)V_4, (2, 1, 4, 3)V_4, (2, 3, 1, 4)V_4 $ etc...? I don't see ""The rows are the cosets of $V_4 $ in $S_4$ ."" Can someone show me this please? For instance, the third row of the table marked in the blue consists of $(1, 4, 3, 2), (1, 3, 2, 4) \notin V_4 $ . I can't see $ S_4/V_4 \cong S_3 $ from the second table. Can someone explain it please?  Thank you.","I think I see from the first table beneath marked in the green. I just ignore and think of it as mapped away by the bijection where But why do they compute only ? By definition, . Where are the rest of the elements in like etc...? I don't see ""The rows are the cosets of in ."" Can someone show me this please? For instance, the third row of the table marked in the blue consists of . I can't see from the second table. Can someone explain it please?  Thank you."," S_4/V_4 \cong S_3   V_4   f^{-1}   f(s) = s V_4 \iff f^{-1}(\sigma V_4) = s \in S_3  \{S_3\}V_4   S_4/V_4 = \{sV_4 : s \in S_4\}   S_4/V_4  (2, 1, 3, 4)V_4, (2, 1, 4, 3)V_4, (2, 3, 1, 4)V_4  V_4  S_4 (1, 4, 3, 2), (1, 3, 2, 4) \notin V_4   S_4/V_4 \cong S_3 ","['abstract-algebra', 'group-theory']"
25,"Ideals in $C[0,1]$",Ideals in,"C[0,1]","Let $C[0,1]$ be the ring of continuous real-valued functions on $[0,1]$, with addition and multiplication defined pointwise.    For any subset $S$ of $C[0,1]$ let $Z(S)=\{f\in C[0,1]: f(x)=0 \text{ for all }x\in S\}$. Then which of the following statements are true? (a) If $Z(S)$ is an ideal in $C[0,1]$ then $S$ is closed in $[0,1]$. (b) If $Z(S)$ is a maximal ideal then $S$ has only one point. (c) If $S$ has only one point then $Z(S)$ is a maximal ideal. (a) Not necessary: if I take $S=(1/2,1/3)$ still $Z(S)$ is an ideal. (b) I know that maximal ideals in $C[0,1]$ come in this way (I don't know the proof rigorously), i.e. $C_a=\{f\in C[0,1]:f(a)=0\}$ so $S$ may be finite or countable set? So I guess $(b)$ is a true statement and for the same reason $(c)$ is also true. But I will be happy if someone can explain me a bit about (b) and (c). Thank you.","Let $C[0,1]$ be the ring of continuous real-valued functions on $[0,1]$, with addition and multiplication defined pointwise.    For any subset $S$ of $C[0,1]$ let $Z(S)=\{f\in C[0,1]: f(x)=0 \text{ for all }x\in S\}$. Then which of the following statements are true? (a) If $Z(S)$ is an ideal in $C[0,1]$ then $S$ is closed in $[0,1]$. (b) If $Z(S)$ is a maximal ideal then $S$ has only one point. (c) If $S$ has only one point then $Z(S)$ is a maximal ideal. (a) Not necessary: if I take $S=(1/2,1/3)$ still $Z(S)$ is an ideal. (b) I know that maximal ideals in $C[0,1]$ come in this way (I don't know the proof rigorously), i.e. $C_a=\{f\in C[0,1]:f(a)=0\}$ so $S$ may be finite or countable set? So I guess $(b)$ is a true statement and for the same reason $(c)$ is also true. But I will be happy if someone can explain me a bit about (b) and (c). Thank you.",,"['abstract-algebra', 'ring-theory', 'ideals']"
26,A domain is a field if it has a common multiple $\!\neq\! 0$ of all elements $\!\neq\! 0$,A domain is a field if it has a common multiple  of all elements,\!\neq\! 0 \!\neq\! 0,"Let $D$ be a domain which is not a field. If there exists $b \in D - \{0\}$ such that for all $a \in D - \{0\}$, $a|b$, then is it true that $b = 0$? This is certainly true if one has a UFD with infinitely many irreducibles (that are not associates) or a Jacobson domain which is not a field (or more generally a domain where the intersection of all non-zero prime ideals is the zero ideal), but I can't seem to be able to prove this for a domain in general or find a counterexample. If this statement is false for an arbitrary domain, then is there some additional weak hypothesis on the domain which makes the above statement true? I was actually trying to answer a question asked yesterday on MSE, which was the following: If $D$ is a domain which is not a field and $Q = Frac(D)$, then $Hom_D(Q,D) = \{0\}$ . Note that if $\varphi$ is any such $D$-linear map, then for all $a \in D- \{0\}$, $a\varphi(1/a) = \varphi(a/a) = \varphi(1)$. Thus, I get for all $a \in D - \{0\}$, $a|\varphi(1)$, and I want to conclude that $\varphi(1) = 0$, but cannot.","Let $D$ be a domain which is not a field. If there exists $b \in D - \{0\}$ such that for all $a \in D - \{0\}$, $a|b$, then is it true that $b = 0$? This is certainly true if one has a UFD with infinitely many irreducibles (that are not associates) or a Jacobson domain which is not a field (or more generally a domain where the intersection of all non-zero prime ideals is the zero ideal), but I can't seem to be able to prove this for a domain in general or find a counterexample. If this statement is false for an arbitrary domain, then is there some additional weak hypothesis on the domain which makes the above statement true? I was actually trying to answer a question asked yesterday on MSE, which was the following: If $D$ is a domain which is not a field and $Q = Frac(D)$, then $Hom_D(Q,D) = \{0\}$ . Note that if $\varphi$ is any such $D$-linear map, then for all $a \in D- \{0\}$, $a\varphi(1/a) = \varphi(a/a) = \varphi(1)$. Thus, I get for all $a \in D - \{0\}$, $a|\varphi(1)$, and I want to conclude that $\varphi(1) = 0$, but cannot.",,"['abstract-algebra', 'commutative-algebra']"
27,why the addition operation of a ring need to be commutative?,why the addition operation of a ring need to be commutative?,,The definition of a ring requires the addition operation to be commutative. But why it has to be?,The definition of a ring requires the addition operation to be commutative. But why it has to be?,,"['abstract-algebra', 'ring-theory']"
28,"An overring of a polynomial ring, noetherian or not?","An overring of a polynomial ring, noetherian or not?",,"Let $S$ be a commutative domain and let $k$ be a subfield of $S$. Let $R:=k[x,y] \subseteq S$ be the polynomial ring in two variables $x,y$ and suppose that for every $s \in S$ there exists some $0 \neq r \in k[x]$ such that $rs \in R$, i.e. $S \subseteq (k[x] \setminus \{0\})^{-1}R$. My question: does $S$ have to be noetherian? Thanks","Let $S$ be a commutative domain and let $k$ be a subfield of $S$. Let $R:=k[x,y] \subseteq S$ be the polynomial ring in two variables $x,y$ and suppose that for every $s \in S$ there exists some $0 \neq r \in k[x]$ such that $rs \in R$, i.e. $S \subseteq (k[x] \setminus \{0\})^{-1}R$. My question: does $S$ have to be noetherian? Thanks",,"['abstract-algebra', 'commutative-algebra']"
29,Existence of normal subgroups for a group of order $36$,Existence of normal subgroups for a group of order,36,Prove that a group of order 36 must have a normal subgroup of order 3 or 9. Let n2 be the number of 2-Sylow subgroups of G (with |G|=36). Then n must be 1 or 3.  Let n3 be the number of 3-Sylow subgroups of G. then n3=1 or n3=4 if n3=1 we have 1 3-sylow group of order 9. and it is also a normal group(from sylow theorem ) if n2=1 there is normal group of order 4 but I cant show normal group of order 3.,Prove that a group of order 36 must have a normal subgroup of order 3 or 9. Let n2 be the number of 2-Sylow subgroups of G (with |G|=36). Then n must be 1 or 3.  Let n3 be the number of 3-Sylow subgroups of G. then n3=1 or n3=4 if n3=1 we have 1 3-sylow group of order 9. and it is also a normal group(from sylow theorem ) if n2=1 there is normal group of order 4 but I cant show normal group of order 3.,,"['abstract-algebra', 'finite-groups']"
30,What is the meaning of $K/F$ is a cyclic extension?,What is the meaning of  is a cyclic extension?,K/F,"I have it that $K/F$ is a (finite) field extension, what is the definition of when $K/F$ is called cyclic ? I heard it while I studied Galois theory and it was defined as $K/F$ is called cyclic if $Gal(K/F)$ is a cyclic group where the notation $Gal$ means that $K/F$ is also Galois. Does, in general, it means $Aut(K/F)$ is cyclic, without the requirement that the extension is Galois ? (how it is defined in the literature/what is the convention ?)","I have it that $K/F$ is a (finite) field extension, what is the definition of when $K/F$ is called cyclic ? I heard it while I studied Galois theory and it was defined as $K/F$ is called cyclic if $Gal(K/F)$ is a cyclic group where the notation $Gal$ means that $K/F$ is also Galois. Does, in general, it means $Aut(K/F)$ is cyclic, without the requirement that the extension is Galois ? (how it is defined in the literature/what is the convention ?)",,"['abstract-algebra', 'terminology', 'field-theory', 'galois-theory', 'definition']"
31,The Number of Sylow Subgroups,The Number of Sylow Subgroups,,"We've been studying Sylow $p$-subgroups, and I've come across this problem. Let $H$ be a subgroup of $G$, and suppose $G$ is finite. Then, $n_p (H) \leq n_p (G)$, where $n_p$ denotes the number of Sylow $p$-subgroups of a group. I am having trouble figuring this one out, and I was wondering if anyone could help? Thank you.","We've been studying Sylow $p$-subgroups, and I've come across this problem. Let $H$ be a subgroup of $G$, and suppose $G$ is finite. Then, $n_p (H) \leq n_p (G)$, where $n_p$ denotes the number of Sylow $p$-subgroups of a group. I am having trouble figuring this one out, and I was wondering if anyone could help? Thank you.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
32,Does a linear operator obeying Leibniz rule imply it is a differential operator?,Does a linear operator obeying Leibniz rule imply it is a differential operator?,,"At the moment I'm studying manifolds and in the definition of tangent space, the notion of derivation was used in the material I'm reading. I asked here about the matter and it was told me that it's not necessary to have a complete background in abstract algebra to proceed but instead just understand the definition of a derivation. If I understood well a derivation is a way to extract the main properties of a differential operator: linearity and obeying the product rule. This line of thought leads me to a doubt: every differential operator should obey the product rule, but if a operator is linear and obey the product rule is possible to conclude it's a differential operator (it can calculate rates of change, be used to construct the taylor approximation to the function and every other properties we expect from a derivative)?","At the moment I'm studying manifolds and in the definition of tangent space, the notion of derivation was used in the material I'm reading. I asked here about the matter and it was told me that it's not necessary to have a complete background in abstract algebra to proceed but instead just understand the definition of a derivation. If I understood well a derivation is a way to extract the main properties of a differential operator: linearity and obeying the product rule. This line of thought leads me to a doubt: every differential operator should obey the product rule, but if a operator is linear and obey the product rule is possible to conclude it's a differential operator (it can calculate rates of change, be used to construct the taylor approximation to the function and every other properties we expect from a derivative)?",,"['abstract-algebra', 'manifolds']"
33,Two Lie groups which are isomorphic but not homeomorphic,Two Lie groups which are isomorphic but not homeomorphic,,"I am looking for an example of two Lie groups which are isomorphic as groups but not homeomorphic as topological spaces. Or, even more interestingly, a proof that two such groups cannot exist. Does anyone have an example or a proof?","I am looking for an example of two Lie groups which are isomorphic as groups but not homeomorphic as topological spaces. Or, even more interestingly, a proof that two such groups cannot exist. Does anyone have an example or a proof?",,"['abstract-algebra', 'lie-groups', 'topological-groups']"
34,Why is $\mathbb{Z}_2 \ast \mathbb{Z}_2$ not a free group?,Why is  not a free group?,\mathbb{Z}_2 \ast \mathbb{Z}_2,"I recently start reading Hatcher's book for self-study. On page $46$ it gives such an example that is a free product and not a free group. I don't quite understand the explanation given in the book. Should I show that any subset of $\mathbb{Z}_2\ast\mathbb{Z}_2$ cannot be the basis for a free group? Secondly, what is the relationship between free abelian groups and free groups?","I recently start reading Hatcher's book for self-study. On page $46$ it gives such an example that is a free product and not a free group. I don't quite understand the explanation given in the book. Should I show that any subset of $\mathbb{Z}_2\ast\mathbb{Z}_2$ cannot be the basis for a free group? Secondly, what is the relationship between free abelian groups and free groups?",,"['abstract-algebra', 'commutative-algebra', 'algebraic-topology']"
35,Quotient of a free $\mathbb{Z}$-module,Quotient of a free -module,\mathbb{Z},"I'm trying to find the quotient of a free $\mathbb{Z}$-module, but somehow I don't really find the right procedure on how to get the right quotient (nor have I found any sources). I've read What does it mean here to describe the structure of this quotient module? already, but I didn't manage to reproduce the second matrix from that specific post. In my specific example I have $\mathbb{Z}^3$ as a left-$\mathbb{Z}$ module. Lets call the generators $e_1, e_2, e_3$. My submodule is given by $$K:=\operatorname{span}_{\mathbb{Z}}\left<i_1:=\left(\matrix{0\\-2\\1}\right), i_2:=\left(\matrix{-2\\0\\1}\right)\right>$$ My idea to get the quotient module $\mathbb{Z}^3/K$ thus far was to use the equalities $$i_1 = -2e_2+e_3\\ i_2 = -2e_1+e_3 $$ Which yields (for $z_1,z_2,z_3,l_1,l_2\in\mathbb{Z}$): $$ z_1e_1+z_2e_2+z_3e_3 \equiv z_1e_1+z_2e_2+z_3e_3+l_1i_1+l_2i_2\\  = z_1e_1+z_2e_2+z_3e_3+l_1(-2e_2+e_3)+l_2(-2e_1+e_3)\\  = (z_1-2l_1)e_1 + (z_2-2l_2)e_2 + (z_3+l_1+l_2)e_3$$ So for $z_1$ even, the first summand should be identical to zero. For $z_1$ uneven it should be identical to one. Same goes for $z_2$ and the second summand, whereas the third summand should be identical to zero in any case (though i'm not really sure about how to deal with that one, since I've already fixed $l_1$ and $l_2$). Hence I'd say my quotient should be $\mathbb{Z}_2^2$. However, letting sage do the calculations, it claims that the result should be $\mathbb{Z}\oplus\mathbb{Z}_2$ So my question is: Is my result wrong? If so: Where's my mistake and is there a better way to do it?","I'm trying to find the quotient of a free $\mathbb{Z}$-module, but somehow I don't really find the right procedure on how to get the right quotient (nor have I found any sources). I've read What does it mean here to describe the structure of this quotient module? already, but I didn't manage to reproduce the second matrix from that specific post. In my specific example I have $\mathbb{Z}^3$ as a left-$\mathbb{Z}$ module. Lets call the generators $e_1, e_2, e_3$. My submodule is given by $$K:=\operatorname{span}_{\mathbb{Z}}\left<i_1:=\left(\matrix{0\\-2\\1}\right), i_2:=\left(\matrix{-2\\0\\1}\right)\right>$$ My idea to get the quotient module $\mathbb{Z}^3/K$ thus far was to use the equalities $$i_1 = -2e_2+e_3\\ i_2 = -2e_1+e_3 $$ Which yields (for $z_1,z_2,z_3,l_1,l_2\in\mathbb{Z}$): $$ z_1e_1+z_2e_2+z_3e_3 \equiv z_1e_1+z_2e_2+z_3e_3+l_1i_1+l_2i_2\\  = z_1e_1+z_2e_2+z_3e_3+l_1(-2e_2+e_3)+l_2(-2e_1+e_3)\\  = (z_1-2l_1)e_1 + (z_2-2l_2)e_2 + (z_3+l_1+l_2)e_3$$ So for $z_1$ even, the first summand should be identical to zero. For $z_1$ uneven it should be identical to one. Same goes for $z_2$ and the second summand, whereas the third summand should be identical to zero in any case (though i'm not really sure about how to deal with that one, since I've already fixed $l_1$ and $l_2$). Hence I'd say my quotient should be $\mathbb{Z}_2^2$. However, letting sage do the calculations, it claims that the result should be $\mathbb{Z}\oplus\mathbb{Z}_2$ So my question is: Is my result wrong? If so: Where's my mistake and is there a better way to do it?",,"['abstract-algebra', 'modules']"
36,A question about Euclidean Domain,A question about Euclidean Domain,,"This is a problem from Aluffi's book, chapter V 2.17. ""Let $R$ be a Euclidean Domain that is not a field. Prove that there exists a nonzero, nonunit element $c$ in $R$ such that $\forall a \in R$, $\exists q$, $r \in R$ with $a = qc + r$, and either $r = 0$ or $r$ a unit."" Ok, I know that if $c\mid a$ then $r=0$, but if $c\nmid a$, not sure about what to do. I took the classic Euclidean Domain $\mathbb{Z}$ as example, and in $\mathbb{Z}$ I know that $c = 2$ ( also $-2$). Then I tried to generalize this. I did $c = unit + unit$, but this didn't help and exercise 2.18 showed me that $c$ is not always $unit+unit$. I'm out of ideas, need some help. Thanks.","This is a problem from Aluffi's book, chapter V 2.17. ""Let $R$ be a Euclidean Domain that is not a field. Prove that there exists a nonzero, nonunit element $c$ in $R$ such that $\forall a \in R$, $\exists q$, $r \in R$ with $a = qc + r$, and either $r = 0$ or $r$ a unit."" Ok, I know that if $c\mid a$ then $r=0$, but if $c\nmid a$, not sure about what to do. I took the classic Euclidean Domain $\mathbb{Z}$ as example, and in $\mathbb{Z}$ I know that $c = 2$ ( also $-2$). Then I tried to generalize this. I did $c = unit + unit$, but this didn't help and exercise 2.18 showed me that $c$ is not always $unit+unit$. I'm out of ideas, need some help. Thanks.",,"['abstract-algebra', 'ring-theory', 'euclidean-domain']"
37,Exhibiting a special subgroup whose involutions are all conjugate to a given involution?,Exhibiting a special subgroup whose involutions are all conjugate to a given involution?,,"I'm trying to work through a sketch proof attributed to Walter Feit on characterizing $S_5$. Suppose $G$ is a finite group with exactly two conjugacy classes of involutions, with $u_1$ and $u_2$ being representatives. Suppose $C_1=C(u_1)\simeq \langle u_1\rangle\times S_3$ and $C_2=C(u_2)$ be a dihedral group of order $8$. The eventual result is that $G\simeq S_5$. Also, $C(u)$ denotes the centralizer of $u$ in $G$. I'm trying to deduce that $|S_2|=0$ or $4$, where $S_i$ is the set of pairs $(x,y)$ with $x$ conjugate to $u_1$, $y$ conjugate to $u_2$, and $(xy)^n=u_i$ for some $n$, and that $C_2$ then has a noncyclic subgroup $V$ such that all involutions in $V$ are conjugate to $u_2$ in $G$. This is part of exercise 10 of page 83, Jacobson's Basic Algebra I. Thanks for any help. My sparse thoughts: I know a few facts I think are useful (proofs are linked in the numbers to the left hand side): 1. If $c_i=|C(u_i)|$ and $s_i=|S_i|$, then $|G|=c_1s_2+c_2s_1$. 2. $C_2$ is a Sylow $2$-subgroup, and I observe from this that one can assume $u_1\in C_2$ by taking a conjugate. 3. There are $3$ classes of involutions in $C_2$, and if $x$ is an involution distinct from $u_2$, then $x$ is conjugate to $xu_2$ in $C_2$. I'm lost on how to use this info on the involutions in $C_2$ to count the size of $S_2$. Identifying $C_2$ with $D_8=\langle r,s\mid r^4=s^2=1,\; sr=r^3s\rangle$ and $r^2$ with $u_2$, I know that the two noncyclic subgroups of order $4$ are $\{1,s,r^2,r^2s\}$ and $\{1,rs,r^2,r^3s\}$. I consider the intersection $C:=C_1\cap C_2$. This is a subgroup with order dividing $8$ and $12$, but since I already know $1,u_1,u_2\in C$, then $|C|=4$. I think this might be the desired subgroup $V$. I'm not sure what action of $C_1$ on $u_2$ to consider, since I don't know if left multiplication or conjugation will send $u_2$ back into $C_2$.","I'm trying to work through a sketch proof attributed to Walter Feit on characterizing $S_5$. Suppose $G$ is a finite group with exactly two conjugacy classes of involutions, with $u_1$ and $u_2$ being representatives. Suppose $C_1=C(u_1)\simeq \langle u_1\rangle\times S_3$ and $C_2=C(u_2)$ be a dihedral group of order $8$. The eventual result is that $G\simeq S_5$. Also, $C(u)$ denotes the centralizer of $u$ in $G$. I'm trying to deduce that $|S_2|=0$ or $4$, where $S_i$ is the set of pairs $(x,y)$ with $x$ conjugate to $u_1$, $y$ conjugate to $u_2$, and $(xy)^n=u_i$ for some $n$, and that $C_2$ then has a noncyclic subgroup $V$ such that all involutions in $V$ are conjugate to $u_2$ in $G$. This is part of exercise 10 of page 83, Jacobson's Basic Algebra I. Thanks for any help. My sparse thoughts: I know a few facts I think are useful (proofs are linked in the numbers to the left hand side): 1. If $c_i=|C(u_i)|$ and $s_i=|S_i|$, then $|G|=c_1s_2+c_2s_1$. 2. $C_2$ is a Sylow $2$-subgroup, and I observe from this that one can assume $u_1\in C_2$ by taking a conjugate. 3. There are $3$ classes of involutions in $C_2$, and if $x$ is an involution distinct from $u_2$, then $x$ is conjugate to $xu_2$ in $C_2$. I'm lost on how to use this info on the involutions in $C_2$ to count the size of $S_2$. Identifying $C_2$ with $D_8=\langle r,s\mid r^4=s^2=1,\; sr=r^3s\rangle$ and $r^2$ with $u_2$, I know that the two noncyclic subgroups of order $4$ are $\{1,s,r^2,r^2s\}$ and $\{1,rs,r^2,r^3s\}$. I consider the intersection $C:=C_1\cap C_2$. This is a subgroup with order dividing $8$ and $12$, but since I already know $1,u_1,u_2\in C$, then $|C|=4$. I think this might be the desired subgroup $V$. I'm not sure what action of $C_1$ on $u_2$ to consider, since I don't know if left multiplication or conjugation will send $u_2$ back into $C_2$.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
38,How to show that $M_B = B \otimes_{A} M$ is a $B$-module?,How to show that  is a -module?,M_B = B \otimes_{A} M B,"Let $A,B$ be commutative rings with identity. Let $f:A \rightarrow B$ be a ring homomorphism and let $M$ be an $A$-module. Since $B$ can be viewed as an $A$-module with the operation $A \times B \rightarrow B$ given by $(\alpha,b) \mapsto f(\alpha)b$, we can define the $A$-module $M_B = B \otimes_{A} M$. How can i show that $M_B$ is also a $B$-module with action such that $(b',b \otimes_{A} x) \mapsto (b'b \otimes_A x)$? Added:  In order to show that $M_B$ is a $B$-module, we need to construct a ring homomorphism $B \rightarrow End(M_B)$. How can we do that?","Let $A,B$ be commutative rings with identity. Let $f:A \rightarrow B$ be a ring homomorphism and let $M$ be an $A$-module. Since $B$ can be viewed as an $A$-module with the operation $A \times B \rightarrow B$ given by $(\alpha,b) \mapsto f(\alpha)b$, we can define the $A$-module $M_B = B \otimes_{A} M$. How can i show that $M_B$ is also a $B$-module with action such that $(b',b \otimes_{A} x) \mapsto (b'b \otimes_A x)$? Added:  In order to show that $M_B$ is a $B$-module, we need to construct a ring homomorphism $B \rightarrow End(M_B)$. How can we do that?",,"['abstract-algebra', 'commutative-algebra', 'tensor-products']"
39,Using $\mathbb{Z}/4\mathbb{Z}$ to construct a counterexample to submodules of free modules being free,Using  to construct a counterexample to submodules of free modules being free,\mathbb{Z}/4\mathbb{Z},Is it possible to use the ring $R = \mathbb{Z}/4\mathbb{Z}$ to construct a counter-example that submodules of free modules are not necessarily free? Thanks a lot.,Is it possible to use the ring $R = \mathbb{Z}/4\mathbb{Z}$ to construct a counter-example that submodules of free modules are not necessarily free? Thanks a lot.,,"['abstract-algebra', 'modules']"
40,When are $R$-mod and $R$-mod-$R$ equivalent?,When are -mod and -mod- equivalent?,R R R,Let $R$ be a commutative ring with 1. Under what conditions are $R$-mod (the category of $R$-modules) and $R$-mod-$R$ (the category of $R$-$R$ bimodules) equivalent as categories?,Let $R$ be a commutative ring with 1. Under what conditions are $R$-mod (the category of $R$-modules) and $R$-mod-$R$ (the category of $R$-$R$ bimodules) equivalent as categories?,,"['abstract-algebra', 'category-theory', 'modules']"
41,Product of a principal proper ideal by itself,Product of a principal proper ideal by itself,,"Let $P$ be a principal proper ideal in an integral domain. Is it $P^2 \subset P$ in general? If yes, how to prove it? For example, if you look at the ideal $(3)=3\mathbb{Z}$ in $\mathbb{Z}$, it is quite simple to show that $3$ is not in $(3)^2$, but how to prove a similar property in a more general context? Now suppose that we have a Dedekind domain. If $P$ is a principal prime ideal, does $P^2 \neq P$ (and so $P^2 \subset P$) follow from the fact that there is a sort of unique factorization of proper ideals in terms of prime ideals?","Let $P$ be a principal proper ideal in an integral domain. Is it $P^2 \subset P$ in general? If yes, how to prove it? For example, if you look at the ideal $(3)=3\mathbb{Z}$ in $\mathbb{Z}$, it is quite simple to show that $3$ is not in $(3)^2$, but how to prove a similar property in a more general context? Now suppose that we have a Dedekind domain. If $P$ is a principal prime ideal, does $P^2 \neq P$ (and so $P^2 \subset P$) follow from the fact that there is a sort of unique factorization of proper ideals in terms of prime ideals?",,"['abstract-algebra', 'ring-theory', 'ideals']"
42,reducing $x^4+1$ in $\mathbb{Z}_p[x]$ [duplicate],reducing  in  [duplicate],x^4+1 \mathbb{Z}_p[x],"This question already has answers here : Closed 12 years ago . Possible Duplicate: reducible polynomial modulo every prime Ok so we have to prove the following: If $R=\mathbb{Z}_p$ for $p$ a prime, then, $x^4+1$ is reducible over $R[x]$. This is are my ideas (please let me know if there is an easier way to tackle this problem): First if $p=2$ then we know that $x+1$ is a factor since $1^4+1=0$ and it follows that $x-1=x+1$ is a factor. Hence from now on let us assume $p$ is odd. First if $x^4+1=(x^2+ax+b)(x^2+cx+d)$, I have that the leading coefficients in the factors is $1$ since I can always force this, and now I obtain the following: $bd=1$ $ad+bc=0$ $d+ac+b=0$ $a+c=0$ Where the above are obtained by multiplying out the factors and setting the coefficients for the value they ought to be. However, we can use the last equation and plug in the second equation, to obtain $a(b-d)=0$ and since $\mathbb{Z}_p$ is a field, then we know it has no zero divisors. If $a=0$ then we have that $b=-d$ and hence $-d^2=1$, which means that $d^2=-1$. By using quadratic residues (here is where I worry since my class has not cover that) we have that if $p\equiv 1\pmod{4}$ then we know that (The Legendre Symbol) $(\frac{a}{p})=\bar{a}^{(p-1)/2}$, using $a=-1$, we have that $(\frac{a}{p})=1$, so $-1$ is not a quadratic residue, i.e., it is a square., hence $x^4+1=(x^4-(-1))=(x^2-d)(x^2+d)$ I am stuck in the case when $p\equiv 3\pmod{4}$. Any help, comments, hints, or thoughts would be appreciated!","This question already has answers here : Closed 12 years ago . Possible Duplicate: reducible polynomial modulo every prime Ok so we have to prove the following: If $R=\mathbb{Z}_p$ for $p$ a prime, then, $x^4+1$ is reducible over $R[x]$. This is are my ideas (please let me know if there is an easier way to tackle this problem): First if $p=2$ then we know that $x+1$ is a factor since $1^4+1=0$ and it follows that $x-1=x+1$ is a factor. Hence from now on let us assume $p$ is odd. First if $x^4+1=(x^2+ax+b)(x^2+cx+d)$, I have that the leading coefficients in the factors is $1$ since I can always force this, and now I obtain the following: $bd=1$ $ad+bc=0$ $d+ac+b=0$ $a+c=0$ Where the above are obtained by multiplying out the factors and setting the coefficients for the value they ought to be. However, we can use the last equation and plug in the second equation, to obtain $a(b-d)=0$ and since $\mathbb{Z}_p$ is a field, then we know it has no zero divisors. If $a=0$ then we have that $b=-d$ and hence $-d^2=1$, which means that $d^2=-1$. By using quadratic residues (here is where I worry since my class has not cover that) we have that if $p\equiv 1\pmod{4}$ then we know that (The Legendre Symbol) $(\frac{a}{p})=\bar{a}^{(p-1)/2}$, using $a=-1$, we have that $(\frac{a}{p})=1$, so $-1$ is not a quadratic residue, i.e., it is a square., hence $x^4+1=(x^4-(-1))=(x^2-d)(x^2+d)$ I am stuck in the case when $p\equiv 3\pmod{4}$. Any help, comments, hints, or thoughts would be appreciated!",,['abstract-algebra']
43,"Let $A$ be a symmetric subset of a group $G$ such that $A$ contains the identity, and $A$ is covered by some translation. Is then $A$ a subgroup?","Let  be a symmetric subset of a group  such that  contains the identity, and  is covered by some translation. Is then  a subgroup?",A G A A A,"Let $G$ be a multiplicative group and $A\subseteq G$ such that 1) $\forall a\in A, a^{-1}\in A$ 2) $1\in A$ 3) $AA \subseteq gA$ for some $g\in G$ Can we say that $A$ is a subgroup? One can immediately show that $g\in A$ and that we have $g^{-1}A \subseteq A \subseteq gA$ but I believe you must use the symmetry property of $A$ (1) again to conclude that it is a subgroup (if it is).","Let $G$ be a multiplicative group and $A\subseteq G$ such that 1) $\forall a\in A, a^{-1}\in A$ 2) $1\in A$ 3) $AA \subseteq gA$ for some $g\in G$ Can we say that $A$ is a subgroup? One can immediately show that $g\in A$ and that we have $g^{-1}A \subseteq A \subseteq gA$ but I believe you must use the symmetry property of $A$ (1) again to conclude that it is a subgroup (if it is).",,"['abstract-algebra', 'group-theory']"
44,Motivation Behind Tschirnhaus Transformation and Cardano's Formula,Motivation Behind Tschirnhaus Transformation and Cardano's Formula,,"I have a general question about the cubic equation: Let $a,b,c \in \mathbb{C}$ with $a \neq 0$. The general cubic equation is $t^3+at^{2}+bt+c = 0$. To get Cardano's Formula, we first transform the equation so that $a= 0$ (i.e. $t^3+bt+c = 0$). Then we reduce this to a quadratic that we can solve. What is the motivation behind the transformations that reduce $t^3+at^2+bt+c = 0$ to $t^3+bt+c = 0$? In particular, if we let $y = t+ \frac{a}{3}$, then $t = y-\frac{a}{3}$ which cancels the $at^2$ term. This is called a Tschirnhaus transformation . We are left with an equation of the form $$y^3+py+q = 0$$ But how do we know what transformations to use to get Cardano's Formula, where $$p = \frac{a^2-2a^3+3b}{3}\quad\mathrm{and}\quad q = \frac{2a^3-9ab+27c}{27}\quad ?$$ Finally if we let $y = \sqrt[3]{u}+ \sqrt[3]{v}$ we eventually get a quadratic which leads to Cardano's Formula.","I have a general question about the cubic equation: Let $a,b,c \in \mathbb{C}$ with $a \neq 0$. The general cubic equation is $t^3+at^{2}+bt+c = 0$. To get Cardano's Formula, we first transform the equation so that $a= 0$ (i.e. $t^3+bt+c = 0$). Then we reduce this to a quadratic that we can solve. What is the motivation behind the transformations that reduce $t^3+at^2+bt+c = 0$ to $t^3+bt+c = 0$? In particular, if we let $y = t+ \frac{a}{3}$, then $t = y-\frac{a}{3}$ which cancels the $at^2$ term. This is called a Tschirnhaus transformation . We are left with an equation of the form $$y^3+py+q = 0$$ But how do we know what transformations to use to get Cardano's Formula, where $$p = \frac{a^2-2a^3+3b}{3}\quad\mathrm{and}\quad q = \frac{2a^3-9ab+27c}{27}\quad ?$$ Finally if we let $y = \sqrt[3]{u}+ \sqrt[3]{v}$ we eventually get a quadratic which leads to Cardano's Formula.",,"['abstract-algebra', 'soft-question', 'polynomials']"
45,"Is $\mathbb{R}(X+Y)\subseteq\mathbb{R}(X,Y)$ a purely transcendental extension?",Is  a purely transcendental extension?,"\mathbb{R}(X+Y)\subseteq\mathbb{R}(X,Y)","Is there a nice, short and elementary argument that the field extension $\mathbb{R}(X+Y)\subseteq\mathbb{R}(X,Y)$ is purely transcendental? Obviously, $\mbox{tr deg}_{\mathbb{R}(X+Y)}\mathbb{R}(X,Y)\le1$, because $\mathbb{R}(X+Y)\subseteq\mathbb{R}(X+Y,Y)=\mathbb{R}(X,Y)$, so it is left to show that $Y$ is not algebraic over $\mathbb{R}(X+Y)$. I don't see any nice proofs of this fact, only some brute force methods of summing degrees of powers of $Y$ in polynomials from $\mathbb{R}(X+Y)[\mathbb{X}]$. Similar question concerns the transcendence degree of the extension $\mathbb{R}(X^2+Y^2)\subseteq\mathbb{R}(X,Y)$. This extension is not purely transcendal (an easy proof using automorphisms from Galois group). $X$ is algebraic over $\mathbb{R}(X^2)$, so again $\mbox{tr deg}_{\mathbb{R}(X^2+Y^2)}\mathbb{R}(X,Y)\le1$, because $\mathbb{R}(X^2+Y^2)\subseteq\mathbb{R}(X^2+Y^2,Y)=\mathbb{R}(X^2,Y)\subseteq\mathbb{R}(X,Y)$. But how to show that $Y$ is not algebraic over $\mathbb{R}(X^2+Y^2)$? I don't know algebraic geometry, thus please don't use it in your answer.","Is there a nice, short and elementary argument that the field extension $\mathbb{R}(X+Y)\subseteq\mathbb{R}(X,Y)$ is purely transcendental? Obviously, $\mbox{tr deg}_{\mathbb{R}(X+Y)}\mathbb{R}(X,Y)\le1$, because $\mathbb{R}(X+Y)\subseteq\mathbb{R}(X+Y,Y)=\mathbb{R}(X,Y)$, so it is left to show that $Y$ is not algebraic over $\mathbb{R}(X+Y)$. I don't see any nice proofs of this fact, only some brute force methods of summing degrees of powers of $Y$ in polynomials from $\mathbb{R}(X+Y)[\mathbb{X}]$. Similar question concerns the transcendence degree of the extension $\mathbb{R}(X^2+Y^2)\subseteq\mathbb{R}(X,Y)$. This extension is not purely transcendal (an easy proof using automorphisms from Galois group). $X$ is algebraic over $\mathbb{R}(X^2)$, so again $\mbox{tr deg}_{\mathbb{R}(X^2+Y^2)}\mathbb{R}(X,Y)\le1$, because $\mathbb{R}(X^2+Y^2)\subseteq\mathbb{R}(X^2+Y^2,Y)=\mathbb{R}(X^2,Y)\subseteq\mathbb{R}(X,Y)$. But how to show that $Y$ is not algebraic over $\mathbb{R}(X^2+Y^2)$? I don't know algebraic geometry, thus please don't use it in your answer.",,"['abstract-algebra', 'field-theory']"
46,Rings of matrices,Rings of matrices,,Let $ A\in {\mathbb{F} }^{n\times n} $ be a fixed matrix. The set of all matrices that commute with A forms a subring of ${\mathbb{F} }^{n\times n}$. Is any subring of ${\mathbb{F} }^{n\times n }$ (which contains the identity) of the above form? Thanks.,Let $ A\in {\mathbb{F} }^{n\times n} $ be a fixed matrix. The set of all matrices that commute with A forms a subring of ${\mathbb{F} }^{n\times n}$. Is any subring of ${\mathbb{F} }^{n\times n }$ (which contains the identity) of the above form? Thanks.,,"['abstract-algebra', 'matrices', 'ring-theory']"
47,"If $g^3 = e$ for all $g \in G$, then $hgh^{-1}$ and $g$ commute for all $h,g \in G$.","If  for all , then  and  commute for all .","g^3 = e g \in G hgh^{-1} g h,g \in G","This is an exercise from a lecture on Introduction to group theory and it is given in the introductory part so I am not sure what methods to use to prove this. It is given right after an exercise that if $g^2=e$ for all $g \in G$ then $G$ is abelian, so I assume this problem can be solved with similar basic algebraic manipulations but I have got stuck on it. Suppose that $g^3 = e$ for all $g \in G$ for a group $G$ . Then show that $hgh^{-1}$ and $g$ commute for all $h,g \in G$ . I've been thinking about this problem for a while but I can't figure out a way to show this. I would greatly appreciate any help.","This is an exercise from a lecture on Introduction to group theory and it is given in the introductory part so I am not sure what methods to use to prove this. It is given right after an exercise that if for all then is abelian, so I assume this problem can be solved with similar basic algebraic manipulations but I have got stuck on it. Suppose that for all for a group . Then show that and commute for all . I've been thinking about this problem for a while but I can't figure out a way to show this. I would greatly appreciate any help.","g^2=e g \in G G g^3 = e g \in G G hgh^{-1} g h,g \in G","['abstract-algebra', 'group-theory']"
48,The unit circle of a field has an injective homomorphism to the group of units.,The unit circle of a field has an injective homomorphism to the group of units.,,"Let $K$ be a field with characteristic more than 2, and containing an element $i\in K$ such that $i^2=-1$ . Define the unit circle of $K$ to be the set $U.C. = \{(x,y)\in K^2:x^2+y^2=1\}$ .  Define $\varphi: U.C.\to K^\times$ by $$ \varphi(x,y) = x+iy $$ . Show that $\varphi$ is injective. My work so far: I've already shown that $\varphi$ is a homomorphism.  In order to prove injectivity we let $w,x,y,z\in K$ such that $w^2+x^2=1=y^2+z^2$ , and need to show that $\varphi(w,x) = \varphi(y,z)$ implies that $(w,x)=(y,z)$ .  Of course the assumption is the same as $$ w+ix = y+iz $$ but we can't use the usual manipulation of complex numbers.  We can obtain $$ w-y = i(z-x) $$ which implies $$ w^2-2wy + y^2 = -(z^2-2xz+x^2) $$ which implies $$ 2-2wy = 2xz $$ and then $$ 1 = wy+xz $$ This looks like Bezout's identity and therefore implies a few statements about GCDs.  However, none of them implies the equality $w=y$ as far as I can tell. Here are the things I know about fields, which seem even possibly relevant: Every ideal in $K[x]$ is principal. A commutative ring with identity is a field if and only if it has only two ideals. An injective homomorphism from an integral domain to a field always extends to an injective homomorphism from its ring of fractions to the same field.","Let be a field with characteristic more than 2, and containing an element such that . Define the unit circle of to be the set .  Define by . Show that is injective. My work so far: I've already shown that is a homomorphism.  In order to prove injectivity we let such that , and need to show that implies that .  Of course the assumption is the same as but we can't use the usual manipulation of complex numbers.  We can obtain which implies which implies and then This looks like Bezout's identity and therefore implies a few statements about GCDs.  However, none of them implies the equality as far as I can tell. Here are the things I know about fields, which seem even possibly relevant: Every ideal in is principal. A commutative ring with identity is a field if and only if it has only two ideals. An injective homomorphism from an integral domain to a field always extends to an injective homomorphism from its ring of fractions to the same field.","K i\in K i^2=-1 K U.C. = \{(x,y)\in K^2:x^2+y^2=1\} \varphi: U.C.\to K^\times  \varphi(x,y) = x+iy  \varphi \varphi w,x,y,z\in K w^2+x^2=1=y^2+z^2 \varphi(w,x) = \varphi(y,z) (w,x)=(y,z)  w+ix = y+iz   w-y = i(z-x)   w^2-2wy + y^2 = -(z^2-2xz+x^2)   2-2wy = 2xz   1 = wy+xz  w=y K[x]","['abstract-algebra', 'ring-theory', 'group-homomorphism']"
49,Do functions over a ring have an odd and an even part?,Do functions over a ring have an odd and an even part?,,"All functions $f(x):\mathbb{R}\to\mathbb{R}$ can be decomposed into an even and an odd part $f(x)=E(x)+O(x)$ . The proof I see here , and on Wikipedia requires $2$ to have an inverse, however I want to know if this property is true of functions in a ring. For a ring $R$ for every function $f(x):R\to R$ , can I find even and odd functions $E(x)$ and $O(x)$ such that $f(x)=E(x)+O(x)$ ? Using a similar method to the ordinary proof I can find that $2E(x)$ and $2O(x)$ are defined uniquely by $f$ , but this only shows that $2f$ has a decomposition into an even and an odd part. Because $2$ does not necessarily have an inverse, I'm not certain how to solve this. I think that a decomposition seems possible, but it would not necessarily be unique?","All functions can be decomposed into an even and an odd part . The proof I see here , and on Wikipedia requires to have an inverse, however I want to know if this property is true of functions in a ring. For a ring for every function , can I find even and odd functions and such that ? Using a similar method to the ordinary proof I can find that and are defined uniquely by , but this only shows that has a decomposition into an even and an odd part. Because does not necessarily have an inverse, I'm not certain how to solve this. I think that a decomposition seems possible, but it would not necessarily be unique?",f(x):\mathbb{R}\to\mathbb{R} f(x)=E(x)+O(x) 2 R f(x):R\to R E(x) O(x) f(x)=E(x)+O(x) 2E(x) 2O(x) f 2f 2,"['abstract-algebra', 'ring-theory', 'even-and-odd-functions']"
50,Question regarding the equivalence of two relations in a finite group given a subgroup,Question regarding the equivalence of two relations in a finite group given a subgroup,,"Let $(G, \cdot)$ be a group and $H$ a finite subgroup of $G$ (i.e. $H \leq G, \lvert H \rvert = n \in \mathbb{N}^*)$ . Prove the following two relations are equivalent ( $e$ is the identity element): $\forall x, y \in G-H, x \neq y \implies xy \neq yx;$ $(H, \cdot)$ is abelian, $\lvert G \rvert=2\lvert H \rvert, |Z(G)| = 1;$ I first assumed 2) then proved 1). $$\begin{align*} x \in G-H &\implies xh \in G-H, \forall h \in H.\\  xh_1=xh_2 &\implies h_1=h_2, \forall h_1, h_2 \in H.\\\  |G-H|=|H| &\implies G-H= \{ xh \mid h \in H \} \end{align*}$$ Now we have $$\begin{align*} (xh_1)(xh_2)=(xh_2)(xh_1) &\implies h_2^{-1}h_1xh_2h_1^{-1}=e\\ &\implies (h_2^{-1}h_1)x(h_2^{-1}h_1)^{-1}=e. \end{align*}$$ $(h_2^{-1}h_1)^{-1}=h_1^{-1}h_2=h_2h_1^{-1}$ because $(H, \cdot)$ is abelian. $gxg^{-1}=e$ has one solution, namely $x=e$ , when $g \in G$ . I did not use the fact that $Z(G)$ is trivial here and I have no idea how to prove 2) assuming 1). Is the question wrong or did I do a mistake?","Let be a group and a finite subgroup of (i.e. . Prove the following two relations are equivalent ( is the identity element): is abelian, I first assumed 2) then proved 1). Now we have because is abelian. has one solution, namely , when . I did not use the fact that is trivial here and I have no idea how to prove 2) assuming 1). Is the question wrong or did I do a mistake?","(G, \cdot) H G H \leq G, \lvert H \rvert = n \in \mathbb{N}^*) e \forall x, y \in G-H, x \neq y \implies xy \neq yx; (H, \cdot) \lvert G \rvert=2\lvert H \rvert, |Z(G)| = 1; \begin{align*}
x \in G-H &\implies xh \in G-H, \forall h \in H.\\
 xh_1=xh_2 &\implies h_1=h_2, \forall h_1, h_2 \in H.\\\
 |G-H|=|H| &\implies G-H= \{ xh \mid h \in H \}
\end{align*} \begin{align*}
(xh_1)(xh_2)=(xh_2)(xh_1) &\implies h_2^{-1}h_1xh_2h_1^{-1}=e\\ &\implies (h_2^{-1}h_1)x(h_2^{-1}h_1)^{-1}=e.
\end{align*} (h_2^{-1}h_1)^{-1}=h_1^{-1}h_2=h_2h_1^{-1} (H, \cdot) gxg^{-1}=e x=e g \in G Z(G)","['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
51,"A finite group of order $mn$ with $m,n$ relatively prime, together with subgroups of orders $m, n$.","A finite group of order  with  relatively prime, together with subgroups of orders .","mn m,n m, n","Let $G$ be a finite group of order $mn$ with $(m,n) = 1$ . Assume that there exist subgroups $M,N$ of $G$ of orders $m$ and $n$ , respectively. Prove that $G$ is isomorphic to a subgroup of the symmetric group $S_{m+n}$ . It is easy to notice that $M\cap N = \{e\}$ since $m,n$ relatively prime, thus, $|MN|=\frac{|M||N|}{|M\cap N|} = mn$ . Hence, $G = MN = NM$ . To prove that $G$ is isomorphic to a subgroup of the symmetric group $S_{m+n}$ , I think I should construct a group action (G acting on some set of order m+n). And the set I think of is $A = M \cup N$ where identities in $M$ and $N$ respectively should be viewed as two different elements. Hence $|A| = m+n$ . If elements in $M$ commute with those in $N$ , I can define a group action $hk \cdot a = ha$ if $a \in M$ or $ka$ if $a \in N$ . (Here, $h \in M, k \in N$ , and $hk$ represents an element in $G$ ). However, I do not know how to prove the case where elements in $M$ do not commute with those in $N$ .","Let be a finite group of order with . Assume that there exist subgroups of of orders and , respectively. Prove that is isomorphic to a subgroup of the symmetric group . It is easy to notice that since relatively prime, thus, . Hence, . To prove that is isomorphic to a subgroup of the symmetric group , I think I should construct a group action (G acting on some set of order m+n). And the set I think of is where identities in and respectively should be viewed as two different elements. Hence . If elements in commute with those in , I can define a group action if or if . (Here, , and represents an element in ). However, I do not know how to prove the case where elements in do not commute with those in .","G mn (m,n) = 1 M,N G m n G S_{m+n} M\cap N = \{e\} m,n |MN|=\frac{|M||N|}{|M\cap N|} = mn G = MN = NM G S_{m+n} A = M \cup N M N |A| = m+n M N hk \cdot a = ha a \in M ka a \in N h \in M, k \in N hk G M N","['abstract-algebra', 'group-theory', 'group-actions', 'symmetric-groups', 'group-isomorphism']"
52,Non-trivial intersection of two cyclic groups,Non-trivial intersection of two cyclic groups,,"Consider the additive group $(\mathbb{Q},+)$ and let $p,q\in\mathbb{Q}\setminus\{0\}$ . Show that for the cyclic groups $\langle p\rangle$ and $\langle q\rangle$ , we have that $$ \langle p\rangle\cap\langle q\rangle\neq\{0\}.\tag{1} $$ I think I am only missing the very last step. I know that there exist $k,\ell\in\mathbb{Z}$ with $k,\ell\neq 0$ such that $$ kp=\ell q.\tag{2} $$ What I am missing is the reason why this implies $(1)$ . I only see that $(2)$ implies $p=\frac{\ell}{k}q$ and $q=\frac{k}{\ell}p$ , respectively. Hence, I get $$ \langle p\rangle = \{p^n: n\in\mathbb{Z}\}=\left\{\left(\frac{\ell}{k}\right)^n q^n: n\in\mathbb{Z}\right\},\qquad\langle q\rangle=\{q^n: n\in\mathbb{Z}\}=\left\{\left(\frac{k}{\ell}\right)^n p^n: n\in\mathbb{Z}\right\} $$","Consider the additive group and let . Show that for the cyclic groups and , we have that I think I am only missing the very last step. I know that there exist with such that What I am missing is the reason why this implies . I only see that implies and , respectively. Hence, I get","(\mathbb{Q},+) p,q\in\mathbb{Q}\setminus\{0\} \langle p\rangle \langle q\rangle 
\langle p\rangle\cap\langle q\rangle\neq\{0\}.\tag{1}
 k,\ell\in\mathbb{Z} k,\ell\neq 0 
kp=\ell q.\tag{2}
 (1) (2) p=\frac{\ell}{k}q q=\frac{k}{\ell}p 
\langle p\rangle = \{p^n: n\in\mathbb{Z}\}=\left\{\left(\frac{\ell}{k}\right)^n q^n: n\in\mathbb{Z}\right\},\qquad\langle q\rangle=\{q^n: n\in\mathbb{Z}\}=\left\{\left(\frac{k}{\ell}\right)^n p^n: n\in\mathbb{Z}\right\}
","['abstract-algebra', 'group-theory', 'cyclic-groups', 'rational-numbers']"
53,How Zorn's lemma is used here?,How Zorn's lemma is used here?,,"I am studying the following theorem in Advanced modern algebra/ Joseph J. Rotman. - Third edition,(Graduate studies in mathematics ; volume 165), A left $R$ module $M$ over a ring $R$ is semisimple if and only if every submodule of $M$ is a direct summand. I have not understood how Zorn's lemma is used in the converse part of the theorem : By Zorn's lemma, there is a family $(S_j)_{j \in I}$ of simple sub-modules of $M$ maximal such that the sub-module $U$ they generate is their direct sum: $U = \oplus_{j \in I} S_j.$ I have taken (I hope this is a right direction) $$F = \{ (S_j)_{j \in I}  : \text{The submodule generated by }(S_j)_{j \in I} \text{ is their direct sum where each $S_j$ are simple}\}$$ The previous part of the argument tells : Every non-zero sub-module $B$ contains a simple summand. This implies that $M$ contains a simple summand and consequently $F$ is nonempty. But somehow I am not able to show rigorously that every chain has an upper bound. Any help is appreciated.","I am studying the following theorem in Advanced modern algebra/ Joseph J. Rotman. - Third edition,(Graduate studies in mathematics ; volume 165), A left module over a ring is semisimple if and only if every submodule of is a direct summand. I have not understood how Zorn's lemma is used in the converse part of the theorem : By Zorn's lemma, there is a family of simple sub-modules of maximal such that the sub-module they generate is their direct sum: I have taken (I hope this is a right direction) The previous part of the argument tells : Every non-zero sub-module contains a simple summand. This implies that contains a simple summand and consequently is nonempty. But somehow I am not able to show rigorously that every chain has an upper bound. Any help is appreciated.",R M R M (S_j)_{j \in I} M U U = \oplus_{j \in I} S_j. F = \{ (S_j)_{j \in I}  : \text{The submodule generated by }(S_j)_{j \in I} \text{ is their direct sum where each S_j are simple}\} B M F,"['abstract-algebra', 'modules', 'axiom-of-choice', 'semi-simple-rings']"
54,Certain Galois extension over $\mathbb{Q}$ not contain $\sqrt[4]{2}$,Certain Galois extension over  not contain,\mathbb{Q} \sqrt[4]{2},"I want to show that $\sqrt[4]{2}$ is not contained in any field $K$ that is Galois over $\mathbb{Q}$ with $G(K/\mathbb{Q}) \cong S_n$ , for any positive integer $n$ . The statement is obvisouly true when $n = 1,2,3$ . Indeed, if $n \leqslant 3$ and $\sqrt[4]{2} \in K$ , then $x^4 - 2$ splits completely in $K$ . Hence, $K$ contains $\mathbb{Q}(\sqrt[4]{2},i)$ , which implies $8 \mid n!$ , a contradiction. However, I have no idea how to prove this for $n \geqslant 4$ . I also know that the condition $G(K/\mathbb{Q}) \cong S_n$ implies $K$ is the splitting field of some irreducible polynomial $f$ over $Q$ . But I don't know whether this fact is useful here.","I want to show that is not contained in any field that is Galois over with , for any positive integer . The statement is obvisouly true when . Indeed, if and , then splits completely in . Hence, contains , which implies , a contradiction. However, I have no idea how to prove this for . I also know that the condition implies is the splitting field of some irreducible polynomial over . But I don't know whether this fact is useful here.","\sqrt[4]{2} K \mathbb{Q} G(K/\mathbb{Q}) \cong S_n n n = 1,2,3 n \leqslant 3 \sqrt[4]{2} \in K x^4 - 2 K K \mathbb{Q}(\sqrt[4]{2},i) 8 \mid n! n \geqslant 4 G(K/\mathbb{Q}) \cong S_n K f Q","['abstract-algebra', 'galois-theory']"
55,$\sqrt[3]{10-x}+\sqrt[3]{30-x}=\sqrt[3]{15-x}+\sqrt[3]{25-x}$,,\sqrt[3]{10-x}+\sqrt[3]{30-x}=\sqrt[3]{15-x}+\sqrt[3]{25-x},I just happened to find a problem and an elegant solution. The question asks us to solve the following equation $$\sqrt[3]{10-x}+\sqrt[3]{30-x}=\sqrt[3]{15-x}+\sqrt[3]{25-x}$$ I am answering this question below but I would love if you can also share a different solution. P.S: I composed this problem by myself. I do not know if this problem is available anywhere. I would love to get some feedback about the same. It motivates me to create problems and discuss with others.,I just happened to find a problem and an elegant solution. The question asks us to solve the following equation I am answering this question below but I would love if you can also share a different solution. P.S: I composed this problem by myself. I do not know if this problem is available anywhere. I would love to get some feedback about the same. It motivates me to create problems and discuss with others.,\sqrt[3]{10-x}+\sqrt[3]{30-x}=\sqrt[3]{15-x}+\sqrt[3]{25-x},"['abstract-algebra', 'functions', 'systems-of-equations', 'elementary-functions']"
56,Can the field of Laurent series be made into an Archimedean ordered field?,Can the field of Laurent series be made into an Archimedean ordered field?,,"In today's analysis class, my professor introduced the field of formal Laurent series $\Bbb R((x))$ . He also talked about the dictionary order on $\Bbb R((x))$ and why it is not an Archimedean ordered field. One natural question arises: Can $\Bbb R((x))$ be made into an Archimedean ordered field? My professor answered that there are uncountably orders on $\Bbb R((x))$ , but none that he knows of make it an Archimedean field. Since we know that every Archimedean field can be embedded into the real number and conversely, every subfield of $\Bbb R$ is Archimedean, the question transforms into: Can $\Bbb R((x))$ (as a field) be embedded into $\Bbb R$ ? The new formulation doesn't seem easier, but it makes the problem a purely algebraic one. Thanks for nombre's answer, $\Bbb R((x))$ cannot be embedded into $\Bbb R$ for the simple reason that it contains a copy of $\Bbb R$ . Now I wonder if $\Bbb Q((x))$ embeds into $\Bbb R$ .","In today's analysis class, my professor introduced the field of formal Laurent series . He also talked about the dictionary order on and why it is not an Archimedean ordered field. One natural question arises: Can be made into an Archimedean ordered field? My professor answered that there are uncountably orders on , but none that he knows of make it an Archimedean field. Since we know that every Archimedean field can be embedded into the real number and conversely, every subfield of is Archimedean, the question transforms into: Can (as a field) be embedded into ? The new formulation doesn't seem easier, but it makes the problem a purely algebraic one. Thanks for nombre's answer, cannot be embedded into for the simple reason that it contains a copy of . Now I wonder if embeds into .",\Bbb R((x)) \Bbb R((x)) \Bbb R((x)) \Bbb R((x)) \Bbb R \Bbb R((x)) \Bbb R \Bbb R((x)) \Bbb R \Bbb R \Bbb Q((x)) \Bbb R,"['abstract-algebra', 'laurent-series', 'formal-power-series', 'ordered-fields']"
57,"Proving Schur-Zassenhaus Theorem, with added assumption that $G/H$ is cyclic","Proving Schur-Zassenhaus Theorem, with added assumption that  is cyclic",G/H,"Schur-Zassenhaus Theorem: If there exists normal Hall-subgroup $H$ of finite group $G$ , then there exists complement $K$ of $H$ in $G$ . So if $\exists$ H $\unlhd$ G s.t. |H| is coprime to [G:H] then $\exists K \le G$ s.t. $ G = HK \cong H \rtimes K $ All proofs of this theorem use group cohomology or Burnside's arguments in conjunction with commutator subgroups of the Sylow $p$ -subgroups. My question is, if we assume $G/H$ is cyclic can we somehow take out some of the heavier machinery in the proof? Like somehow showing that $H$ is abelian would be real nice. Then the induction is pretty ok without the use of cohomology. I'm not sure what knowing $K$ is abelian implies.","Schur-Zassenhaus Theorem: If there exists normal Hall-subgroup of finite group , then there exists complement of in . So if H G s.t. |H| is coprime to [G:H] then s.t. All proofs of this theorem use group cohomology or Burnside's arguments in conjunction with commutator subgroups of the Sylow -subgroups. My question is, if we assume is cyclic can we somehow take out some of the heavier machinery in the proof? Like somehow showing that is abelian would be real nice. Then the induction is pretty ok without the use of cohomology. I'm not sure what knowing is abelian implies.",H G K H G \exists \unlhd \exists K \le G  G = HK \cong H \rtimes K  p G/H H K,"['abstract-algebra', 'group-theory', 'cyclic-groups', 'group-cohomology']"
58,When is the centralizer of a subgroup equal to the subgroup itself?,When is the centralizer of a subgroup equal to the subgroup itself?,,"I am going through a proof of the proposition Assume $G$ is a group of order $pq$ , where $p$ and $q$ are primes with $p\le q$ and $p$ does not divide $q-1$ . Then $G$ is abelian. in Abstract Algbra by Dummit and Foote, and I am stuck at one step. The relevant assumptions are: $Z(G)=1$ (the center of $G$ is the trivial subgroup), $G$ has an element $x$ of order $q$ , and $H=\langle x\rangle$ . At this point the author concludes that $C_G(H)=H$ , ( $C_G(H)$ represents the centralizer of $H$ in $G$ ) but I cannot see why. I can see $H\subset C_G(H)$ . Also $C_G(H)=C_G(x)$ . But how to proceed? In particular, I do not know how the condition $Z(G)=1$ is relevant here. Any help is appreciated. If you believe more information is needed in the context, I can provide it.","I am going through a proof of the proposition Assume is a group of order , where and are primes with and does not divide . Then is abelian. in Abstract Algbra by Dummit and Foote, and I am stuck at one step. The relevant assumptions are: (the center of is the trivial subgroup), has an element of order , and . At this point the author concludes that , ( represents the centralizer of in ) but I cannot see why. I can see . Also . But how to proceed? In particular, I do not know how the condition is relevant here. Any help is appreciated. If you believe more information is needed in the context, I can provide it.",G pq p q p\le q p q-1 G Z(G)=1 G G x q H=\langle x\rangle C_G(H)=H C_G(H) H G H\subset C_G(H) C_G(H)=C_G(x) Z(G)=1,"['abstract-algebra', 'group-theory']"
59,A group orbit/Burnside's lemma question,A group orbit/Burnside's lemma question,,"Consider a set $X$ of $9$ dots arranged in a $3 \times 3$ grid. Let $H$ be the group generated by the permutations on the rows of $X$ and by the permutations on the columns of $X$ . I am asked: How many elements are in $H$ ? What cycle types appear in $H$ ? How many elements in $H$ belong to each cycle type? If the $9$ elements in $X$ are colored $3$ each red, white and blue, how many ways can we color $X$ , where two colorings are the same if we can move from one coloring to another through operations in $H$ ? I have only a few ideas: The group $H$ will be something like $S_3 \times S_3$ , because we can permute rows and columns, so that should give me 36 elements in $H$ . This clearly looks like I'm supposed to apply Burnside's Lemma. The group acting  will be $H$ . But I'm not too sure about the rest. I need to count the number of fixed points for every element in $H$ . Thanks.","Consider a set of dots arranged in a grid. Let be the group generated by the permutations on the rows of and by the permutations on the columns of . I am asked: How many elements are in ? What cycle types appear in ? How many elements in belong to each cycle type? If the elements in are colored each red, white and blue, how many ways can we color , where two colorings are the same if we can move from one coloring to another through operations in ? I have only a few ideas: The group will be something like , because we can permute rows and columns, so that should give me 36 elements in . This clearly looks like I'm supposed to apply Burnside's Lemma. The group acting  will be . But I'm not too sure about the rest. I need to count the number of fixed points for every element in . Thanks.",X 9 3 \times 3 H X X H H H 9 X 3 X H H S_3 \times S_3 H H H,"['abstract-algebra', 'group-theory', 'group-actions']"
60,Structure Theorem for non-abelian finite groups or rings,Structure Theorem for non-abelian finite groups or rings,,"How many structure theorems do we have in Abstract Algebra for finite algebraic structures? I know some of the following theorems: If $G$ is a finite abelian group, then $G$ is a product cyclic groups of prime power order. If $R$ is a finite commutative ring, then $R$ is Artinian and hence a direct product of local rings. I am wondering if there are other structure theorems for finite algebraic structures. Is it possible to write a non-commutative or a non-abelian group in this way? Why are the theorems available for abelian cases but not for non-abelian ones? If someone can please help me find some references where I can get structure theorems for non-commutative or a non-abelian group/rings, I will be thankful. Please help.","How many structure theorems do we have in Abstract Algebra for finite algebraic structures? I know some of the following theorems: If is a finite abelian group, then is a product cyclic groups of prime power order. If is a finite commutative ring, then is Artinian and hence a direct product of local rings. I am wondering if there are other structure theorems for finite algebraic structures. Is it possible to write a non-commutative or a non-abelian group in this way? Why are the theorems available for abelian cases but not for non-abelian ones? If someone can please help me find some references where I can get structure theorems for non-commutative or a non-abelian group/rings, I will be thankful. Please help.",G G R R,"['abstract-algebra', 'group-theory', 'ring-theory', 'finite-groups', 'finite-rings']"
61,Exercise III.5.10 in Grillet's Abstract Algebra,Exercise III.5.10 in Grillet's Abstract Algebra,,"Let $R$ be commutative, with characteristic either $0$ or greater than $m$ . Show that a root $r$ of $A \in R[X]$ has multiplicity $m$ if and only if $A^{(k)}(r)=0$ for all $k<m$ and $A^{m}(r) \neq 0$ . Show that the hypothesis about the characteristic of $R$ cannot be omitted from this result. By definition of multiplicity $A(x)=(x-r)^{m}B(x)$ , where $B(r) \neq 0$ . It's easy to see, that $A^{k}(r)=0$ for all $k<m$ and $A^{m}(r)=m!B(r)$ . But why $m!B(r) \neq 0$ ? Shouldn't $R$ necessarily be a domain?","Let be commutative, with characteristic either or greater than . Show that a root of has multiplicity if and only if for all and . Show that the hypothesis about the characteristic of cannot be omitted from this result. By definition of multiplicity , where . It's easy to see, that for all and . But why ? Shouldn't necessarily be a domain?",R 0 m r A \in R[X] m A^{(k)}(r)=0 k<m A^{m}(r) \neq 0 R A(x)=(x-r)^{m}B(x) B(r) \neq 0 A^{k}(r)=0 k<m A^{m}(r)=m!B(r) m!B(r) \neq 0 R,"['abstract-algebra', 'polynomial-rings']"
62,Minimal polynomials and Galois extensions,Minimal polynomials and Galois extensions,,"I'm back again with a question, but this time I am only curious about one thing. Here's how it goes: Let $K$ be a Galois extension of a field $F$ . By the theorem of the primitive element, we know that $K = F(\alpha_1)$ for some $\alpha_1 \in K.$ Suppose that $f(X)$ is the minimal polynomial of $\alpha_1$ over $F$ . Now $K$ is the splitting field for $f(X)$ as $K$ is separable and normal. We also know that $F(\alpha_1, \alpha_2, \ldots, \alpha_n)$ for the distinct roots $\alpha_i$ of $f(X)$ is a splitting field for $f(X)$ . This means that $F(\alpha_1, \alpha_2, \ldots, \alpha_n) = F(\alpha_1)$ . Since $f(X)$ has $n = deg f(X)$ distinct roots it must be the case that all roots of $f(X)$ are linear combinations of $\alpha_1$ . This also means that $F(\alpha_k) = F(\alpha_d)$ for some $k, d \leq n$ . However, I am not sure if my arguments are correct. I am also quite afraid of drawing my own conclusions as I am currently self-studying Galois theory with basically no prior knowledge of algebra. I hope that someone can correct me if I am wrong!","I'm back again with a question, but this time I am only curious about one thing. Here's how it goes: Let be a Galois extension of a field . By the theorem of the primitive element, we know that for some Suppose that is the minimal polynomial of over . Now is the splitting field for as is separable and normal. We also know that for the distinct roots of is a splitting field for . This means that . Since has distinct roots it must be the case that all roots of are linear combinations of . This also means that for some . However, I am not sure if my arguments are correct. I am also quite afraid of drawing my own conclusions as I am currently self-studying Galois theory with basically no prior knowledge of algebra. I hope that someone can correct me if I am wrong!","K F K = F(\alpha_1) \alpha_1 \in K. f(X) \alpha_1 F K f(X) K F(\alpha_1, \alpha_2, \ldots, \alpha_n) \alpha_i f(X) f(X) F(\alpha_1, \alpha_2, \ldots, \alpha_n) = F(\alpha_1) f(X) n = deg f(X) f(X) \alpha_1 F(\alpha_k) = F(\alpha_d) k, d \leq n","['abstract-algebra', 'galois-theory', 'minimal-polynomials']"
63,Suppose $G$ is a finite simple group whose order is divisible by $p^2$. Show there is no subgroup with index $p$.,Suppose  is a finite simple group whose order is divisible by . Show there is no subgroup with index .,G p^2 p,"Suppose $G$ is a finite simple group such that $p^2$ divides $|G|$ for some prime $p$ . Show there is no subgroup of $G$ of index $p$ . We can write the order of $G$ as $|G|=p^2m$ . I want to use the third Sylow theorem, but there is no restriction that $p$ does not divide $m$ . So, I rewrote the order as $|G|=p^nm_1$ where $n\geq2$ and $p$ does not divide $m_1$ . But, I don't know how to convert this into a proof showing the index of a subgroup can't be $p$ .","Suppose is a finite simple group such that divides for some prime . Show there is no subgroup of of index . We can write the order of as . I want to use the third Sylow theorem, but there is no restriction that does not divide . So, I rewrote the order as where and does not divide . But, I don't know how to convert this into a proof showing the index of a subgroup can't be .",G p^2 |G| p G p G |G|=p^2m p m |G|=p^nm_1 n\geq2 p m_1 p,"['abstract-algebra', 'group-theory', 'finite-groups', 'simple-groups']"
64,"In the ring $\mathbb{Z}_p$, $p$ is prime, $(a+b)^p=a^p+b^p$ proof? [duplicate]","In the ring ,  is prime,  proof? [duplicate]",\mathbb{Z}_p p (a+b)^p=a^p+b^p,"This question already has answers here : A freshman's dream (2 answers) Which fields satisfy the Freshman's Dream? (1 answer) Closed 3 years ago . In the ring, $\mathbb{Z}_p$ , $p$ a prime , prove that $(a+b)^p=a^p+b^p$ . The hint that is given to us says that the binomial expansion works in commutative rings, but I think I used something much more simple? I said that $\mathbb{Z}_p$ of prime order is cyclic, so $\langle x\rangle = \mathbb{Z}_p$ is generated by $x$ . So therefore $x^p \bmod p = x$ . Thus in $\mathbb{Z}_p,(a+b)^p = a+b = a^p +b^p$ The only thing I am unsure of is if I have to prove that $x^p \bmod p = x$ , and then if I can apply it to $(a+b)^p$ . If this way is super is super goofy and, even if it works somehow, requires a lot of proof, then how might I get started on the binomial theorem? Thanks team.","This question already has answers here : A freshman's dream (2 answers) Which fields satisfy the Freshman's Dream? (1 answer) Closed 3 years ago . In the ring, , a prime , prove that . The hint that is given to us says that the binomial expansion works in commutative rings, but I think I used something much more simple? I said that of prime order is cyclic, so is generated by . So therefore . Thus in The only thing I am unsure of is if I have to prove that , and then if I can apply it to . If this way is super is super goofy and, even if it works somehow, requires a lot of proof, then how might I get started on the binomial theorem? Thanks team.","\mathbb{Z}_p p (a+b)^p=a^p+b^p \mathbb{Z}_p \langle x\rangle = \mathbb{Z}_p x x^p \bmod p = x \mathbb{Z}_p,(a+b)^p = a+b = a^p +b^p x^p \bmod p = x (a+b)^p","['abstract-algebra', 'ring-theory', 'binomial-theorem', 'cyclic-groups']"
65,"Proof that transpositions generate $S_n$, and proof that $\#(S_n) = n!$ (Lang's Algebra p. 13)","Proof that transpositions generate , and proof that  (Lang's Algebra p. 13)",S_n \#(S_n) = n!,"I am trying to unpack Lang's proofs and verify that I'm correctly filling in the details. Excerpt: My attempt: To prove that the transpositions generate $S_n$ , we proceed by induction on $n$ . When $n = 1$ we can use the identity map to generate $S_1$ . Assume the result is true for $S_{n - 1}$ . Consider $\sigma \in S_n$ and assume that $\sigma(n) = k \neq n$ , otherwise we could think of $\sigma$ as a product of transpositions in $S_{n - 1}$ and tack on $\tau (n) = n$ for all the transpositions. Take transposition $\tau \in S_n$ that interchanges $k$ and $n$ . Then $\tau \sigma$ leaves $n$ fixed and can therefore be written as $\tau \sigma = \tau_m \tau_{m - 1} \dots \tau_1$ where all the transpositions on the right-hand side are extensions of transpositions in $S_{n - 1}$ that leave $n$ fixed. Multiply by $\tau$ on the left to see that $\sigma = \tau \tau_m \tau_{m - 1} \dots \tau_1$ as desired. To prove that $\#(S_n) = n!$ we again use induction on $n$ . The base case is clear. Assume that $\# (S_{n - 1}) = (n - 1)!$ . The subgroup $H$ of $S_n$ that leaves $n$ fixed is isomorphic to $S_{n - 1}$ because the elements of $S_{n - 1}$ are the same as those of $H$ , except that they are restricted to $\{ 1, \dots n - 1 \}$ . The elements $\sigma_1, \dots, \sigma_n$ as described are coset representatives (of distinct cosets) of $H$ in $S_n$ . The argument $\sigma_i h_1 = \sigma_j h_2 \Rightarrow \sigma_i = \sigma_j h_2 h_1^{-1} \Rightarrow \sigma_i H = \sigma_j h_2 h_1^{-1} H \Rightarrow \sigma_i H = \sigma_j H$ shows that two such cosets are either disjoint or equal. Question: Unfortunately I cannot quite put my finger on why $\bigcup_{i = 1}^n \sigma_i H = S_n$ . If I consider $\sigma \in S_n$ such that $\sigma (n) = k$ , then I feel like I need to show that $\sigma \in \sigma_k H$ , but I don't see how to do this. Why is this ""immediately verified""? Once I've shown this, I see that Lagrange's theorem gets us $(S_n : 1) = n(n - 1)!$ as desired. I appreciate any help.","I am trying to unpack Lang's proofs and verify that I'm correctly filling in the details. Excerpt: My attempt: To prove that the transpositions generate , we proceed by induction on . When we can use the identity map to generate . Assume the result is true for . Consider and assume that , otherwise we could think of as a product of transpositions in and tack on for all the transpositions. Take transposition that interchanges and . Then leaves fixed and can therefore be written as where all the transpositions on the right-hand side are extensions of transpositions in that leave fixed. Multiply by on the left to see that as desired. To prove that we again use induction on . The base case is clear. Assume that . The subgroup of that leaves fixed is isomorphic to because the elements of are the same as those of , except that they are restricted to . The elements as described are coset representatives (of distinct cosets) of in . The argument shows that two such cosets are either disjoint or equal. Question: Unfortunately I cannot quite put my finger on why . If I consider such that , then I feel like I need to show that , but I don't see how to do this. Why is this ""immediately verified""? Once I've shown this, I see that Lagrange's theorem gets us as desired. I appreciate any help.","S_n n n = 1 S_1 S_{n - 1} \sigma \in S_n \sigma(n) = k \neq n \sigma S_{n - 1} \tau (n) = n \tau \in S_n k n \tau \sigma n \tau \sigma = \tau_m \tau_{m - 1} \dots \tau_1 S_{n - 1} n \tau \sigma = \tau \tau_m \tau_{m - 1} \dots \tau_1 \#(S_n) = n! n \# (S_{n - 1}) = (n - 1)! H S_n n S_{n - 1} S_{n - 1} H \{ 1, \dots n - 1 \} \sigma_1, \dots, \sigma_n H S_n \sigma_i h_1 = \sigma_j h_2 \Rightarrow \sigma_i = \sigma_j h_2 h_1^{-1} \Rightarrow \sigma_i H = \sigma_j h_2 h_1^{-1} H \Rightarrow \sigma_i H = \sigma_j H \bigcup_{i = 1}^n \sigma_i H = S_n \sigma \in S_n \sigma (n) = k \sigma \in \sigma_k H (S_n : 1) = n(n - 1)!","['abstract-algebra', 'group-theory', 'permutations', 'symmetric-groups']"
66,The set of continuous functions vanishing at $c$ is not the principal ideal generated by $x-c$,The set of continuous functions vanishing at  is not the principal ideal generated by,c x-c,"Let $R = \mathcal C([0,1], \mathbb R)$ and $M_c = \{f \in R \mid  f(c) = 0\}$ . I would like to show that: a. $M_c \neq M_b$ if $b \neq c$ ; b. $M_c$ is not the principal ideal generated by $x-c$ ; c. $M_c$ is not finitely generated. For a. I think its clear that if $f(x)=x-c$ then $ f \in M_c $ and $f \in M_b$ iff $b=c$ . b. is trickier. I'm thinking about something like $f=|x-c|$ because then if $f=g(x-c)$ then $g=|x-c|/(x-c)$ and then $g \notin R$ . This doesn't feel good enough. How can I make this precise or am I even on the right track? EDIT; Suppose $c \neq 1$ . Let $f(x)=(x-c)^{1/2}\chi_{x > c}$ . Clearly $f \in M_c$ . Suppose $(x-c)$ divides $f$ Then $f= g(x-c)$ for some $g \in \mathcal{R}$ . I want to go for $g \notin \mathcal{R}$ but I'm pretty sure I cannot say $g=\frac{f}{x-c}$ because $x-c$ is not a unit...so I'm stuck here. EDIT2; Ok I think I have it.  Suppose $x>c$ . If we calculate: $$|g(x)-g(c)|=|\frac{f(x)}{x-c}-g(c)|\geq|x-c|^{-1/2}-|g(c)| \geq 1 - |g(c)|$$ So $g$ has no right limit as $x \rightarrow c$ and therefore $g \notin R$",Let and . I would like to show that: a. if ; b. is not the principal ideal generated by ; c. is not finitely generated. For a. I think its clear that if then and iff . b. is trickier. I'm thinking about something like because then if then and then . This doesn't feel good enough. How can I make this precise or am I even on the right track? EDIT; Suppose . Let . Clearly . Suppose divides Then for some . I want to go for but I'm pretty sure I cannot say because is not a unit...so I'm stuck here. EDIT2; Ok I think I have it.  Suppose . If we calculate: So has no right limit as and therefore,"R = \mathcal C([0,1], \mathbb R) M_c = \{f \in R \mid  f(c) = 0\} M_c \neq M_b b \neq c M_c x-c M_c f(x)=x-c  f \in M_c  f \in M_b b=c f=|x-c| f=g(x-c) g=|x-c|/(x-c) g \notin R c \neq 1 f(x)=(x-c)^{1/2}\chi_{x > c} f \in M_c (x-c) f f= g(x-c) g \in \mathcal{R} g \notin \mathcal{R} g=\frac{f}{x-c} x-c x>c |g(x)-g(c)|=|\frac{f(x)}{x-c}-g(c)|\geq|x-c|^{-1/2}-|g(c)| \geq 1 - |g(c)| g x \rightarrow c g \notin R","['abstract-algebra', 'ring-theory']"
67,Are finitely generated modules over a commutative ring always a direct sum of cyclic submodules?,Are finitely generated modules over a commutative ring always a direct sum of cyclic submodules?,,"Let's first motivate my question by looking at a finitely generated $k$ -algebra $A$ over a field $k$ . Then $A$ in general does not have the form $k[a_1,a_2,\ldots,a_n]$ where $\{a_1,a_2,\ldots,a_n\}$ is a generating set for $A$ . For example consider the two-dimensional irreducible representation $V$ of the quarternion group $Q_8$ , then the ring of invariants is finitely generated by Hilbert's finiteness theorem, but  the algebra of invariants, which is a subalgebra of a polynomial algebra in two variables holds the form $$ \mathbb{C}[V]^{Q_8} = \dfrac{\mathbb{C}[f,g,h]}{(h^2-f^2g+4g^3)},$$ where $f$ and $g$ are invariant polynomials of degree 4, and $h$ is of degree 6. The reason is that the generating polynomials are not algebraically independent. Now consider a commutative ring $R$ , and $M$ a finitely generating $R$ -module, and $\{m_1,m_2,\ldots,m_n\}$ a generating set for $M$ , I want to know whether it is true that $M$ holds the form $$ M = \bigoplus_{i=1}^n Rm_i$$ I think this is not true, but this is true if and only if $M$ is a finitely generated $\textit{free}$ module over $R$ . Can someone enlighten me?","Let's first motivate my question by looking at a finitely generated -algebra over a field . Then in general does not have the form where is a generating set for . For example consider the two-dimensional irreducible representation of the quarternion group , then the ring of invariants is finitely generated by Hilbert's finiteness theorem, but  the algebra of invariants, which is a subalgebra of a polynomial algebra in two variables holds the form where and are invariant polynomials of degree 4, and is of degree 6. The reason is that the generating polynomials are not algebraically independent. Now consider a commutative ring , and a finitely generating -module, and a generating set for , I want to know whether it is true that holds the form I think this is not true, but this is true if and only if is a finitely generated module over . Can someone enlighten me?","k A k A k[a_1,a_2,\ldots,a_n] \{a_1,a_2,\ldots,a_n\} A V Q_8  \mathbb{C}[V]^{Q_8} = \dfrac{\mathbb{C}[f,g,h]}{(h^2-f^2g+4g^3)}, f g h R M R \{m_1,m_2,\ldots,m_n\} M M  M = \bigoplus_{i=1}^n Rm_i M \textit{free} R","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'modules']"
68,formula for the $k$th coefficient of a polynomial plugged into itself $n$ times,formula for the th coefficient of a polynomial plugged into itself  times,k n,"If a polynomial with coefficients $a_k$ is plugged into itself $n$ times, this will result in another polynomial with polynomial coefficients $b_k$ . Find an explicit formula for $b_k$ given $a_k$ , and $n$ . For example, $f(x)$ is a polynomial with the following coefficients $a_0=1$ , $a_1=2$ , and $a_2=3$ . All other coefficients $a_m$ where $m>2$ are zero. This will result in the following polynomial. $$ f(t) = 1 + 2x + 3x^2 $$ We want to find the polynomial coefficients of this polynomial after it is plugged into itself 1 time, thus $n=1$ . $$ f(f(t)) = 1 + 2(1 + 2x + 3x^2) + 3(1 + 2x + 3x^2)^2 $$ $$ f(f(t)) = 6 + 16 x + 36 x^2 + 36 x^3 + 27 x^4 $$ Thus $b_0=6$ , $b_1=16$ , $b_2=36$ , and so on. So, in summary, if a polynomial with polynomial coefficients $a_k$ plugged into itself $n$ times, what are the coefficients of the resulting polynomial $b_k$ ?","If a polynomial with coefficients is plugged into itself times, this will result in another polynomial with polynomial coefficients . Find an explicit formula for given , and . For example, is a polynomial with the following coefficients , , and . All other coefficients where are zero. This will result in the following polynomial. We want to find the polynomial coefficients of this polynomial after it is plugged into itself 1 time, thus . Thus , , , and so on. So, in summary, if a polynomial with polynomial coefficients plugged into itself times, what are the coefficients of the resulting polynomial ?","a_k n b_k b_k a_k n f(x) a_0=1 a_1=2 a_2=3 a_m m>2 
f(t) = 1 + 2x + 3x^2
 n=1 
f(f(t)) = 1 + 2(1 + 2x + 3x^2) + 3(1 + 2x + 3x^2)^2
 
f(f(t)) = 6 + 16 x + 36 x^2 + 36 x^3 + 27 x^4
 b_0=6 b_1=16 b_2=36 a_k n b_k","['real-analysis', 'abstract-algebra', 'number-theory', 'polynomials']"
69,What is internal direct sum or internal direct product in Dummit and Foote?,What is internal direct sum or internal direct product in Dummit and Foote?,,"I refer to Dummit and Foote Chapter 10.3 specifically pages 351 , 353 , 354 , 356 and 357 . Does Exercise 10.3.21 on pages 357 (By the way, there's some errata here. Condition (iii) should be $i_1,...,i_k$ ) define a notion of internal direct sum (of unital $R$ -submodules of a unital $R$ -module over a unital, but not necessarily commutative, ring $R$ )? I think this is an internal direct sum for an infinite or a finite index set that generalises the notion of internal direct sum for a finite index set given in page 354 . Do we have a notion of ' internal direct product '? For the finite case, I believe this is the ' $N_1 + ... + N_k$ ' part of Proposition 10.5 in page 353 . For the finite or infinite case, I believe this is the 'the (unital $R$ -)submodule of $M$ generated by (the union of) all the $N_i$ 's' part of Condition (i) of Exercise 10.3.21 because ' $N_1 + ... + N_k$ ' in Proposition 10.5 is actually equal to (see page 351 ) the (unital $R$ -) 'submodule of $M$ generated by (the union of) all the $N_i$ 's' such that Condition (i) generalises the '(1)' in Proposition 10.5. Therefore : I think of internal direct product of $N_i$ 's of $M$ as $\sum_{i \in I} N_i = R\{\bigcup_{i \in I} N_i\}$ , which like external direct product and external direct sum, is always defined. And then I think of internal direct sum as not always defined but, whenever defined, as equal to internal direct product. Possibly relevant: 'Semidirect product'. This wikipedia page: https://en.wikipedia.org/wiki/Direct_sum_of_groups#Generalization_to_sums_over_infinite_sets Context: I'm trying to understand the direct sum parts of graded rings and graded ideals in later in Chapter 11.5 . I'm hoping these can be internal instead of just external. I ask more here . Edit 1: Thank you for the upvotes or views. I feel like all the hours I spent trying to understand this seemingly minor thing was really worth it. Edit 2: For (not necessarily Abelian) groups: Internal direct product/sum in groups: Is join and independent equivalent to unique expression?","I refer to Dummit and Foote Chapter 10.3 specifically pages 351 , 353 , 354 , 356 and 357 . Does Exercise 10.3.21 on pages 357 (By the way, there's some errata here. Condition (iii) should be ) define a notion of internal direct sum (of unital -submodules of a unital -module over a unital, but not necessarily commutative, ring )? I think this is an internal direct sum for an infinite or a finite index set that generalises the notion of internal direct sum for a finite index set given in page 354 . Do we have a notion of ' internal direct product '? For the finite case, I believe this is the ' ' part of Proposition 10.5 in page 353 . For the finite or infinite case, I believe this is the 'the (unital -)submodule of generated by (the union of) all the 's' part of Condition (i) of Exercise 10.3.21 because ' ' in Proposition 10.5 is actually equal to (see page 351 ) the (unital -) 'submodule of generated by (the union of) all the 's' such that Condition (i) generalises the '(1)' in Proposition 10.5. Therefore : I think of internal direct product of 's of as , which like external direct product and external direct sum, is always defined. And then I think of internal direct sum as not always defined but, whenever defined, as equal to internal direct product. Possibly relevant: 'Semidirect product'. This wikipedia page: https://en.wikipedia.org/wiki/Direct_sum_of_groups#Generalization_to_sums_over_infinite_sets Context: I'm trying to understand the direct sum parts of graded rings and graded ideals in later in Chapter 11.5 . I'm hoping these can be internal instead of just external. I ask more here . Edit 1: Thank you for the upvotes or views. I feel like all the hours I spent trying to understand this seemingly minor thing was really worth it. Edit 2: For (not necessarily Abelian) groups: Internal direct product/sum in groups: Is join and independent equivalent to unique expression?","i_1,...,i_k R R R N_1 + ... + N_k R M N_i N_1 + ... + N_k R M N_i N_i M \sum_{i \in I} N_i = R\{\bigcup_{i \in I} N_i\}","['abstract-algebra', 'modules', 'direct-sum', 'direct-product', 'graded-rings']"
70,Semisimple Lie algebra and Jacobson radical,Semisimple Lie algebra and Jacobson radical,,"In the theory of Lie algebras, the radical $\mathrm{rad} (\mathfrak{g})$ of a Lie algebra $\mathfrak{g}$ is defined to be a (the) maximal solvable ideal of $\mathfrak{g}$ , and the Lie algebra $\mathfrak{g}$ is said to be semisimple if $\mathrm{rad} (\mathfrak{g}) = 0$ . On the other hand, in the theory of associative algebras, the Jacobson radical $\mathrm{rad} (A)$ of an algebra $A$ is the intersection of all maximal (left) ideal of $A$ , and the algebra $A$ is semisimple if $A$ is artinian and $\mathrm{rad} (A) = 0$ . (A semisimple algebra is a semisimple module (direct sum of simple modules) over itself.) Then, there rises two questions to me: Is the universal enveloping algebra $U (\mathfrak{g})$ artinian? Do this two kinds of semisimplicity coincide; that is, $\mathfrak{g}$ is semisimple iff $U (\mathfrak{g})$ is semisimple? If not, under which circumstances can we deduce the equivalence of semisimplicity?","In the theory of Lie algebras, the radical of a Lie algebra is defined to be a (the) maximal solvable ideal of , and the Lie algebra is said to be semisimple if . On the other hand, in the theory of associative algebras, the Jacobson radical of an algebra is the intersection of all maximal (left) ideal of , and the algebra is semisimple if is artinian and . (A semisimple algebra is a semisimple module (direct sum of simple modules) over itself.) Then, there rises two questions to me: Is the universal enveloping algebra artinian? Do this two kinds of semisimplicity coincide; that is, is semisimple iff is semisimple? If not, under which circumstances can we deduce the equivalence of semisimplicity?",\mathrm{rad} (\mathfrak{g}) \mathfrak{g} \mathfrak{g} \mathfrak{g} \mathrm{rad} (\mathfrak{g}) = 0 \mathrm{rad} (A) A A A A \mathrm{rad} (A) = 0 U (\mathfrak{g}) \mathfrak{g} U (\mathfrak{g}),"['abstract-algebra', 'representation-theory', 'lie-algebras', 'semisimple-lie-algebras']"
71,Irreducible element iff prime norm in Gaussian integers?,Irreducible element iff prime norm in Gaussian integers?,,"I am trying to prove the following: Let $R=\mathbb{Z}[i]$ , $a, b \in \mathbb{Z}, ab \neq 0$ . Show that $a+bi$ is an irreducible element in $R$ if and only if $a^2 + b^2  \mathbb{Z}$ is prime. Since $R$ is a Euclidean domain, irreducible elements are prime. I think this is relevant, but am stuck on where to go from here.","I am trying to prove the following: Let , . Show that is an irreducible element in if and only if is prime. Since is a Euclidean domain, irreducible elements are prime. I think this is relevant, but am stuck on where to go from here.","R=\mathbb{Z}[i] a, b \in \mathbb{Z}, ab \neq 0 a+bi R a^2 + b^2  \mathbb{Z} R",['abstract-algebra']
72,The set $5^{-\infty}\mathbb{Z}$ is a colimit,The set  is a colimit,5^{-\infty}\mathbb{Z},"I am trying to understand why the set of rational numbers whose denominators are powers of $5$ , $5^{-\infty}\mathbb{Z}$ , is a colimit. Specifically, why is $5^{-\infty}\mathbb{Z}$ the colimit of the diagram $$\mathbb{Z}\longrightarrow5^{-1}\mathbb{Z}\longrightarrow5^{-2}\mathbb{Z}\longrightarrow\cdots$$ I'm not sure what the maps to $5^{-\infty}\mathbb{Z}$ are. They can't be inclusion, or else we won't get commutativity. What am I missing? I imagine the arrows above are given by division by $5$ , and maybe the maps to the limit are multiplication by $5$ ?","I am trying to understand why the set of rational numbers whose denominators are powers of , , is a colimit. Specifically, why is the colimit of the diagram I'm not sure what the maps to are. They can't be inclusion, or else we won't get commutativity. What am I missing? I imagine the arrows above are given by division by , and maybe the maps to the limit are multiplication by ?",5 5^{-\infty}\mathbb{Z} 5^{-\infty}\mathbb{Z} \mathbb{Z}\longrightarrow5^{-1}\mathbb{Z}\longrightarrow5^{-2}\mathbb{Z}\longrightarrow\cdots 5^{-\infty}\mathbb{Z} 5 5,"['abstract-algebra', 'category-theory', 'limits-colimits']"
73,Can $\mathbb{Q}(u)$ be of degree 2 over $\mathbb{Q} (u^3)$?,Can  be of degree 2 over ?,\mathbb{Q}(u) \mathbb{Q} (u^3),"I came across the following question - Let $u$ be algebraic over $\mathbb Q$ of degree which is not divisible by $3$ . Does necessarily $\mathbb Q(u)=\mathbb Q(u^3)$ ? What I have so far: Since $x^3-u^3$ is reducible over $\mathbb Q$ with $u$ as a root, then the dimension of $\mathbb Q(u)$ over $\mathbb Q(u^3)$ is at most $3$ . From the dimension theorem: $[\mathbb Q(u):\mathbb Q]=[\mathbb Q(u):\mathbb Q(u^3)]\cdot [\mathbb Q(u^3):\mathbb Q]$ The LHS is not divisible by $3$ , and so since $[\mathbb Q(u):\mathbb Q(u^3)]$ is either $1$ or $2$ , and cannot be $3$ . If it is $1$ , then we know that the two fields are equal. But I'm not sure why it can't be $2$ . and can't come up with a counter example which fits the problem. Can anyone help me with proving that the two fields are equal, or coming up with a counter example? Thanks in advance.","I came across the following question - Let be algebraic over of degree which is not divisible by . Does necessarily ? What I have so far: Since is reducible over with as a root, then the dimension of over is at most . From the dimension theorem: The LHS is not divisible by , and so since is either or , and cannot be . If it is , then we know that the two fields are equal. But I'm not sure why it can't be . and can't come up with a counter example which fits the problem. Can anyone help me with proving that the two fields are equal, or coming up with a counter example? Thanks in advance.",u \mathbb Q 3 \mathbb Q(u)=\mathbb Q(u^3) x^3-u^3 \mathbb Q u \mathbb Q(u) \mathbb Q(u^3) 3 [\mathbb Q(u):\mathbb Q]=[\mathbb Q(u):\mathbb Q(u^3)]\cdot [\mathbb Q(u^3):\mathbb Q] 3 [\mathbb Q(u):\mathbb Q(u^3)] 1 2 3 1 2,"['abstract-algebra', 'ring-theory', 'field-theory', 'galois-theory', 'splitting-field']"
74,Representation over a finite field,Representation over a finite field,,"Are there any two inequivalent and irreducible $F$ -representations of a finite group $G$ (where $F$ is a field of positive characteristic) having the same characters? I can surely find an example in which the representations are not both irreducible, but I thought it would be nice to find an example in which both are irreducible.","Are there any two inequivalent and irreducible -representations of a finite group (where is a field of positive characteristic) having the same characters? I can surely find an example in which the representations are not both irreducible, but I thought it would be nice to find an example in which both are irreducible.",F G F,"['abstract-algebra', 'group-theory', 'finite-groups', 'representation-theory']"
75,Solve the Diophantine Equation $x^2 + 7 = y^5$.,Solve the Diophantine Equation .,x^2 + 7 = y^5,"This is a duplicate question of Find integers solutions of $x^2+7=y^5$ , however there was no full answer. The solutions $(\pm5, 2)$ and $(\pm 181, 8)$ have been found. The usual strategy for such a question is to work inside the ring of integers of $\mathbb{Q}(\sqrt{-7})$ , which is $\mathcal{O} = \mathbb{Z}[ \frac{1+\sqrt{-7}}{2}]$ . It turns out that this is a unique factorisation domain (which one can figure out by calculating its Class group). So it is natural to factor the equation as $(x - \sqrt{-7})(x+\sqrt{-7}) = y^5$ . If we assume that $x-\sqrt{-7}$ and $x+\sqrt{-7}$ are coprime, we find that $x+\sqrt{-7} = \beta^5$ for a certain $\beta = a + b\frac{1+\sqrt{-7}}{2}\in \mathbb{Z}[\frac{1+\sqrt{-7}}{2}]$ . Writing $c= 2a+b$ and expanding the fifth power, this gives the system of equations $$ c^5 -70 c^3 b^2 + 245 c^4 b = 32 x, $$ $$ 5 c^4 b -70 c^2 b^3 + 49 b^5 = 32. $$ Now with enough patience, one can show that this system has no solutions with $b \equiv c \pmod{2}$ . However this contradicts the solutions that we have found. And indeed there's no reason for $x \pm \sqrt{-7}$ to be coprime when $x$ is odd. What is the approach to solve the remaining case of this diophantine equation? One approach that I have tried is that the coprime condition holds inside the ring $\cal{O}[\frac{1}{2}]$ . This gives the equation $x + \sqrt{-7} = (a+b\sqrt{-7})^5$ with $a,b \in \mathbb{Z}[\frac{1}{2}]$ , which I am unable to solve.","This is a duplicate question of Find integers solutions of $x^2+7=y^5$ , however there was no full answer. The solutions and have been found. The usual strategy for such a question is to work inside the ring of integers of , which is . It turns out that this is a unique factorisation domain (which one can figure out by calculating its Class group). So it is natural to factor the equation as . If we assume that and are coprime, we find that for a certain . Writing and expanding the fifth power, this gives the system of equations Now with enough patience, one can show that this system has no solutions with . However this contradicts the solutions that we have found. And indeed there's no reason for to be coprime when is odd. What is the approach to solve the remaining case of this diophantine equation? One approach that I have tried is that the coprime condition holds inside the ring . This gives the equation with , which I am unable to solve.","(\pm5, 2) (\pm 181, 8) \mathbb{Q}(\sqrt{-7}) \mathcal{O} = \mathbb{Z}[ \frac{1+\sqrt{-7}}{2}] (x - \sqrt{-7})(x+\sqrt{-7}) = y^5 x-\sqrt{-7} x+\sqrt{-7} x+\sqrt{-7} = \beta^5 \beta = a + b\frac{1+\sqrt{-7}}{2}\in \mathbb{Z}[\frac{1+\sqrt{-7}}{2}] c= 2a+b  c^5 -70 c^3 b^2 + 245 c^4 b = 32 x,   5 c^4 b -70 c^2 b^3 + 49 b^5 = 32.  b \equiv c \pmod{2} x \pm \sqrt{-7} x \cal{O}[\frac{1}{2}] x + \sqrt{-7} = (a+b\sqrt{-7})^5 a,b \in \mathbb{Z}[\frac{1}{2}]","['abstract-algebra', 'number-theory', 'algebraic-number-theory', 'diophantine-equations']"
76,For which $n$ can the plane with $n$ points removed be equipped with a Lie group structure?,For which  can the plane with  points removed be equipped with a Lie group structure?,n n,"Let $X=\mathbb{R}^2-\{p_1, p_2,..., p_n\}$ , then if $n=0$ then clearly $X=\mathbb{R}^2$ is a Lie group under addition. If $n=1$ , then $X=\mathbb{R}^2-\{p_1\}$ is isomorphic to $\mathbb{C}\setminus\{0\}$ which has a Lie group structure under multiplication. But I don't know how to proceed in the case in which $n>1$ . I have thought of using that the tangent bundle of a Lie group is trivial but I don't know how to do this. I would appreciate any help or suggestions. Thank you.","Let , then if then clearly is a Lie group under addition. If , then is isomorphic to which has a Lie group structure under multiplication. But I don't know how to proceed in the case in which . I have thought of using that the tangent bundle of a Lie group is trivial but I don't know how to do this. I would appreciate any help or suggestions. Thank you.","X=\mathbb{R}^2-\{p_1, p_2,..., p_n\} n=0 X=\mathbb{R}^2 n=1 X=\mathbb{R}^2-\{p_1\} \mathbb{C}\setminus\{0\} n>1","['abstract-algebra', 'differential-geometry', 'lie-groups', 'lie-algebras', 'vector-bundles']"
77,Counterexample with finite index,Counterexample with finite index,,"I'm on a three part question, and have got stuck on the last part. The full question is: Let $G$ be a group and $H$ a finite index subgroup of $G$ . (a) If $g \in G$ show that there is a smallest positive integer $k$ such that $g^{k} \in H.$ Show that $k$ divides every integer $m$ such that $g^{m} \in H$ . (b) If $H$ is normal in $G$ show that $k$ divides $[G:H]$ . (c) Produce a counterexample to the claim that for all subgroups $H$ we have $k$ dividing $[G:H]$ I'm working on part (c). From part (b), I can see that I need $H$ to not be a normal subgroup, but I'm having a hard time coming up with a counterexample. Any help would be appreciated.","I'm on a three part question, and have got stuck on the last part. The full question is: Let be a group and a finite index subgroup of . (a) If show that there is a smallest positive integer such that Show that divides every integer such that . (b) If is normal in show that divides . (c) Produce a counterexample to the claim that for all subgroups we have dividing I'm working on part (c). From part (b), I can see that I need to not be a normal subgroup, but I'm having a hard time coming up with a counterexample. Any help would be appreciated.",G H G g \in G k g^{k} \in H. k m g^{m} \in H H G k [G:H] H k [G:H] H,"['abstract-algebra', 'group-theory', 'examples-counterexamples']"
78,Injective map of abelian group and product of cyclic quotients,Injective map of abelian group and product of cyclic quotients,,Let $A$ be an abelian group. We have a map from $A \to \prod{(A/I)}$ where $A/I$ varies over the cyclic quotients of $A$ . This map is given by sending $x$ to $\prod (x \text{ mod } I)$ . Is this map injective?,Let be an abelian group. We have a map from where varies over the cyclic quotients of . This map is given by sending to . Is this map injective?,A A \to \prod{(A/I)} A/I A x \prod (x \text{ mod } I),"['abstract-algebra', 'group-theory']"
79,The Kernel of a Homomorphism,The Kernel of a Homomorphism,,""" The kernel is important because it controls the entire homomorphism. It tells us not only which elements of G are mapped to the identity in G', but also which pairs of elements have the same image in G'.  "" (Taken from Algebra by Artin.) How does the kernel tell us which pairs of elements have the same image in G'? What I tried: let $f$ be a homomorphism such that $f(a) = f(b) = c$ . $c$ is in $G'$ , so it has an inverse $c^{-1}$ . So then, $c^{-1}f(a) = c^{-1}f(b) = cc^{-1} = 1$ . But, this is tedious to compute, and I didn't use the kernel to do it.",""" The kernel is important because it controls the entire homomorphism. It tells us not only which elements of G are mapped to the identity in G', but also which pairs of elements have the same image in G'.  "" (Taken from Algebra by Artin.) How does the kernel tell us which pairs of elements have the same image in G'? What I tried: let be a homomorphism such that . is in , so it has an inverse . So then, . But, this is tedious to compute, and I didn't use the kernel to do it.",f f(a) = f(b) = c c G' c^{-1} c^{-1}f(a) = c^{-1}f(b) = cc^{-1} = 1,"['abstract-algebra', 'group-theory', 'group-homomorphism']"
80,Similarity between Axiomatic Set Theory and Modern Algebra,Similarity between Axiomatic Set Theory and Modern Algebra,,"Continuum Hypothesis(CH) is independent of ZFC Axioms, which means there exist models of ZFC where CH is true, and models where CH is false. Can I say something similar for groups? Something like the following: The statement $\forall a\forall b[a,b\in G\Rightarrow ab=ba]$ (i.e. any two elements commute) is independent of the axioms of a group because there are examples of groups where this is true (Abelian groups), and groups where this is false. By ""axioms of a group"", I mean things we have in the definition of a group (associativity, the existence of an identity, etc). A group is a set, so set theory axioms are included here as well. Can I say $\forall a\forall b[ab=ba]$ is independent of group axioms, and can I refer to an example of a group (e.g. $\mathbb Z_n$ ) a model of group axioms? This might be a strange question, but it is important. The meaning of ""independence of CH"" and the concept of Model is very difficult for a learner to understand; the fact that a group can be either Abelian or not can be easily understood. So are they really the same thing according to my interpretation above? If they are not exactly the same, then how are they different? PS: there are a lot of cross-overs between set theory and Algebra. For example, boolean algebra. I do find some very general discussion on the topic, for example here , but none of them go into such details.","Continuum Hypothesis(CH) is independent of ZFC Axioms, which means there exist models of ZFC where CH is true, and models where CH is false. Can I say something similar for groups? Something like the following: The statement (i.e. any two elements commute) is independent of the axioms of a group because there are examples of groups where this is true (Abelian groups), and groups where this is false. By ""axioms of a group"", I mean things we have in the definition of a group (associativity, the existence of an identity, etc). A group is a set, so set theory axioms are included here as well. Can I say is independent of group axioms, and can I refer to an example of a group (e.g. ) a model of group axioms? This might be a strange question, but it is important. The meaning of ""independence of CH"" and the concept of Model is very difficult for a learner to understand; the fact that a group can be either Abelian or not can be easily understood. So are they really the same thing according to my interpretation above? If they are not exactly the same, then how are they different? PS: there are a lot of cross-overs between set theory and Algebra. For example, boolean algebra. I do find some very general discussion on the topic, for example here , but none of them go into such details.","\forall a\forall b[a,b\in G\Rightarrow ab=ba] \forall a\forall b[ab=ba] \mathbb Z_n","['abstract-algebra', 'group-theory', 'model-theory']"
81,"Prove $(y-x^2)$ is a prime ideal in $\mathbb{R}[x,y]$, but not maximal.","Prove  is a prime ideal in , but not maximal.","(y-x^2) \mathbb{R}[x,y]","My guess is to use the fact that when we take the quotient, $\mathbb{R}[x,y]/(y-x^2)$ , this will become an integral domain but not a field. I am not sure how to take the quotient, though. I am also unfamiliar with the ring of polynomials of two variables. As a set, can I write $\mathbb{R}[x,y] = \{a + bx + cy + dxy + ex^2+fy^2+...| a,b,c,d,e,f,...\in \mathbb{R}\}$ ? And would it be correct if I assume that in the quotient, $y = x^2$ ? If my above two guesses are correct, then I would assume that the quotient becomes $\mathbb{R}[x]$ , since all the $y$ terms can be turned into $x^2$ . But isn't this ring an integral domain, since there are no zero divisors, but not a field, since not every real polynomial has an inverse?","My guess is to use the fact that when we take the quotient, , this will become an integral domain but not a field. I am not sure how to take the quotient, though. I am also unfamiliar with the ring of polynomials of two variables. As a set, can I write ? And would it be correct if I assume that in the quotient, ? If my above two guesses are correct, then I would assume that the quotient becomes , since all the terms can be turned into . But isn't this ring an integral domain, since there are no zero divisors, but not a field, since not every real polynomial has an inverse?","\mathbb{R}[x,y]/(y-x^2) \mathbb{R}[x,y] = \{a + bx + cy + dxy + ex^2+fy^2+...| a,b,c,d,e,f,...\in \mathbb{R}\} y = x^2 \mathbb{R}[x] y x^2","['abstract-algebra', 'ring-theory', 'ideals', 'maximal-and-prime-ideals']"
82,The group algebra is not semisimple if characteristic divides group order.,The group algebra is not semisimple if characteristic divides group order.,,"I'm studying a proof that if a prime $p$ has $p\mid |G|$ and $k$ is a field of characteristic $p$ , then the group algebra $kG$ is not semisimple. My issue is that there is an assertion in the first line that I don't understand - given this assertion, I am fine with the rest of the proof. The proof goes like this: If $kG$ were semisimple, the trivial module $k$ would appear exactly once as a summand in a decomposition of $kG$ into simple $kG$ modules. This must be something special about the group algebra, because e.g. $k\oplus k$ doesn't satisfy this and is semisimple, but I don't know where this comes from. By the Artin-Wedderburn theorem, any composition series of $kG$ has exactly one factor isomorphic to $k$ . The augmentation ideal $\Sigma$ (the kernel of the augmentation map sending each group element to 1) has $kG/\Sigma\cong k$ . $\sigma=\sum_{g\in G}g$ lies in the augmentation ideal since $k$ is of characteristic $p$ . So, $k\sigma$ is a submodule of $kG$ contained in the augmentation ideal. Refining $kG\supset \Sigma \supset k\sigma\supset 0$ to a composition series will give at least two factors isomorphic to the trivial module, a contradiction. I understand how, assuming (1), the proof works, and I'm sure I'm missing something blatantly obvious. Why is (1) true?","I'm studying a proof that if a prime has and is a field of characteristic , then the group algebra is not semisimple. My issue is that there is an assertion in the first line that I don't understand - given this assertion, I am fine with the rest of the proof. The proof goes like this: If were semisimple, the trivial module would appear exactly once as a summand in a decomposition of into simple modules. This must be something special about the group algebra, because e.g. doesn't satisfy this and is semisimple, but I don't know where this comes from. By the Artin-Wedderburn theorem, any composition series of has exactly one factor isomorphic to . The augmentation ideal (the kernel of the augmentation map sending each group element to 1) has . lies in the augmentation ideal since is of characteristic . So, is a submodule of contained in the augmentation ideal. Refining to a composition series will give at least two factors isomorphic to the trivial module, a contradiction. I understand how, assuming (1), the proof works, and I'm sure I'm missing something blatantly obvious. Why is (1) true?",p p\mid |G| k p kG kG k kG kG k\oplus k kG k \Sigma kG/\Sigma\cong k \sigma=\sum_{g\in G}g k p k\sigma kG kG\supset \Sigma \supset k\sigma\supset 0,"['abstract-algebra', 'modules', 'representation-theory', 'positive-characteristic']"
83,How to understand / imagine what is a line bundle,How to understand / imagine what is a line bundle,,"Wikipedia says: In mathematics, a line bundle expresses the concept of a line that   varies from point to point of a space. For example a curve in the   plane having a tangent line at each point determines a varying line:   the tangent bundle is a way of organising these. More formally, in   algebraic topology and differential topology a line bundle is defined   as a vector bundle of rank 1. Line bundles are specified by choosing a one-dimensional vector space for each point of the space in a continuous manner. But I do not understand it clear. I have been reading several definitions but I do not manage to understand it. Any help?","Wikipedia says: In mathematics, a line bundle expresses the concept of a line that   varies from point to point of a space. For example a curve in the   plane having a tangent line at each point determines a varying line:   the tangent bundle is a way of organising these. More formally, in   algebraic topology and differential topology a line bundle is defined   as a vector bundle of rank 1. Line bundles are specified by choosing a one-dimensional vector space for each point of the space in a continuous manner. But I do not understand it clear. I have been reading several definitions but I do not manage to understand it. Any help?",,"['abstract-algebra', 'algebraic-geometry', 'vector-bundles', 'fiber-bundles']"
84,Is there a tensor product of $G$-sets?,Is there a tensor product of -sets?,G,"We can take the tensor product of two vector spaces, and the tensor product of two modules.  I'm wondering if the same can be done for group actions. Let $G$ be a group which acts on two sets $X$ and $Y$ .  My question is there a definition for the tensor product of $X$ and $Y$ ? If so, what kind of object will it be?  The tensor product of modules need not be a module, it can just be an abelian group.  Similarly, is it possible that the tensor product of $X$ and $Y$ can just be a group rather than another $G$ -set?","We can take the tensor product of two vector spaces, and the tensor product of two modules.  I'm wondering if the same can be done for group actions. Let be a group which acts on two sets and .  My question is there a definition for the tensor product of and ? If so, what kind of object will it be?  The tensor product of modules need not be a module, it can just be an abelian group.  Similarly, is it possible that the tensor product of and can just be a group rather than another -set?",G X Y X Y X Y G,"['abstract-algebra', 'group-theory', 'modules', 'tensor-products', 'group-actions']"
85,How to prove that $\mathbb{Z}[X]/g\mathbb{Z}[X]$ is not a field? [duplicate],How to prove that  is not a field? [duplicate],\mathbb{Z}[X]/g\mathbb{Z}[X],"This question already has answers here : Nonconstant polynomials do not generate maximal ideals in $\mathbb Z[x]$ (4 answers) Closed 5 years ago . How to prove that $\mathbb{Z}[X]/g\mathbb{Z}[X]$ is not a field, where $g$ is a non constant polynomial in $\mathbb{Z}[X]$ ? (The key is to show that $f : \mathbb{Z}[X]/g\mathbb{Z}[X] \to \mathbb{Z}/p\mathbb{Z}$ is not injective.) edit 1: Now I'm trying to find the characteristic of the given ring. Consider the map: $g: \mathbb{Z} \to \mathbb{Z}[X]/g\mathbb{Z}[X]$ , where $m \mapsto 1 + 1 + \cdots + 1 $ (m times). Since the $\ker f$ is an ideal of $\mathbb{Z}$ , it has to be of the form $n\mathbb{Z}$ , where $n$ is the characteristic. So I guess the characteristic is $0$ ...no? edit 2: Thank you for all the replies below! I looked through the answer but it's a little advanced for me... I figured it out eventually using some more basic ideas and I'll put it here when I get some time...Thanks again! edit 3: My solution: Step 1: Prove there is a $a \in \mathbb{Z}$ such that $g(a) \neq 0, \pm 1$ and let $p$ be a prime number that divides $g(a)$ . Suppose $g(X) = \sum_{i = 1}^na_iX^i$ , then $g(X) = 0$ has at most $n$ integer solutions, $p(X) = g(X) -1 = 0$ has at most $n$ integer solutions, and so is $q(X) = g(X)+1 = 0$ . There are at most $3n$ integers that satisfy $g(a) = 0,\pm1$ , but $\mathbb{Z}$ is infinite, so there has to be a $a \in \mathbb{Z}$ such that $g(a) \neq 0, \pm 1$ . Step 2: Prove that there is a unique well-defined surjective morphism of rings $f: \mathbb{Z}[X] \to \mathbb{Z}/p\mathbb{Z}$ sending $X$ to $a$ mod $p$ and that it yields a homomorphism of rings $\phi: \mathbb{Z}[X]/g\mathbb{Z}[X] \to \mathbb{Z}/p\mathbb{Z}$ . Observe that $g\mathbb{Z}[X]$ is in the kernel, so the map factor through $\mathbb{Z}[X]/g\mathbb{Z}[X]$ . Step 3: Show that the resulting map is not injective. Note that the map $\phi$ is injective if and only if $\ker f = g\mathbb{Z}[X]$ , but actually $g\mathbb{Z}[X] \subset \ker f$ . Alternatively, according to my prof, if the map was injective, $\mathbb{Z}[X]/g\mathbb{Z}[X]$ would identify with a subring of $\mathbb{Z}/p\mathbb{Z}$ so it would have characteristic $p$ , contradiction! Step 4: We use that if $g: K \to A$ where $K$ is a field, then $g$ is either injective or the zero map. Since the above map is not a zero map and we proved that it's not injective, $\mathbb{Z}[X]/g\mathbb{Z}[X]$ can't be a field.","This question already has answers here : Nonconstant polynomials do not generate maximal ideals in $\mathbb Z[x]$ (4 answers) Closed 5 years ago . How to prove that is not a field, where is a non constant polynomial in ? (The key is to show that is not injective.) edit 1: Now I'm trying to find the characteristic of the given ring. Consider the map: , where (m times). Since the is an ideal of , it has to be of the form , where is the characteristic. So I guess the characteristic is ...no? edit 2: Thank you for all the replies below! I looked through the answer but it's a little advanced for me... I figured it out eventually using some more basic ideas and I'll put it here when I get some time...Thanks again! edit 3: My solution: Step 1: Prove there is a such that and let be a prime number that divides . Suppose , then has at most integer solutions, has at most integer solutions, and so is . There are at most integers that satisfy , but is infinite, so there has to be a such that . Step 2: Prove that there is a unique well-defined surjective morphism of rings sending to mod and that it yields a homomorphism of rings . Observe that is in the kernel, so the map factor through . Step 3: Show that the resulting map is not injective. Note that the map is injective if and only if , but actually . Alternatively, according to my prof, if the map was injective, would identify with a subring of so it would have characteristic , contradiction! Step 4: We use that if where is a field, then is either injective or the zero map. Since the above map is not a zero map and we proved that it's not injective, can't be a field.","\mathbb{Z}[X]/g\mathbb{Z}[X] g \mathbb{Z}[X] f : \mathbb{Z}[X]/g\mathbb{Z}[X] \to \mathbb{Z}/p\mathbb{Z} g: \mathbb{Z} \to \mathbb{Z}[X]/g\mathbb{Z}[X] m \mapsto 1 + 1 + \cdots + 1  \ker f \mathbb{Z} n\mathbb{Z} n 0 a \in \mathbb{Z} g(a) \neq 0, \pm 1 p g(a) g(X) = \sum_{i = 1}^na_iX^i g(X) = 0 n p(X) = g(X) -1 = 0 n q(X) = g(X)+1 = 0 3n g(a) = 0,\pm1 \mathbb{Z} a \in \mathbb{Z} g(a) \neq 0, \pm 1 f: \mathbb{Z}[X] \to \mathbb{Z}/p\mathbb{Z} X a p \phi: \mathbb{Z}[X]/g\mathbb{Z}[X] \to \mathbb{Z}/p\mathbb{Z} g\mathbb{Z}[X] \mathbb{Z}[X]/g\mathbb{Z}[X] \phi \ker f = g\mathbb{Z}[X] g\mathbb{Z}[X] \subset \ker f \mathbb{Z}[X]/g\mathbb{Z}[X] \mathbb{Z}/p\mathbb{Z} p g: K \to A K g \mathbb{Z}[X]/g\mathbb{Z}[X]","['abstract-algebra', 'maximal-and-prime-ideals']"
86,"$x \mapsto x^n $ is a automorphism of group $G$, show that for all $x$ in $G$, $x^{n-1} \in Z(G)$.","is a automorphism of group , show that for all  in , .",x \mapsto x^n  G x G x^{n-1} \in Z(G),"If $x \mapsto x^n $ is a automorphism of group $G$ , show that for all $x$ in $G$ , $x^{n-1} \in Z(G)$ . This mean $G=\{x^n:x \in G\}$ and $x^n=e$ if and only if $x= e$ . Now let $y\in G$ . I Want to show that $$yx^{n-1}=x^{n-1}y.$$ We know that $y$ is $n^{\text {th}}$ power of some element of $G$ , but how to proceed from here? Any hint is appreciated. Thanks in Advance.","If is a automorphism of group , show that for all in , . This mean and if and only if . Now let . I Want to show that We know that is power of some element of , but how to proceed from here? Any hint is appreciated. Thanks in Advance.",x \mapsto x^n  G x G x^{n-1} \in Z(G) G=\{x^n:x \in G\} x^n=e x= e y\in G yx^{n-1}=x^{n-1}y. y n^{\text {th}} G,"['abstract-algebra', 'group-theory', 'group-homomorphism']"
87,"Show that $\mathbb{Q}(\sqrt{3},\sqrt[4]{3}, \sqrt[8]{3},...)$ is algebraic over $\mathbb{Q}$ but not a finite extension.",Show that  is algebraic over  but not a finite extension.,"\mathbb{Q}(\sqrt{3},\sqrt[4]{3}, \sqrt[8]{3},...) \mathbb{Q}","Show that $\mathbb{Q}(\sqrt{3},\sqrt[4]{3}, \sqrt[8]{3},...)$ is algebraic over $\mathbb{Q}$ but not a finite extension. I think for the algebraic part, since for every simple extension, each of those elements can be adjoined and each of these simple extensions has a minimal polynomial that cannot be reduced in $\mathbb{Q}$ . For example, the simple extension $\mathbb{Q}(\sqrt{3}, \sqrt[4]{3})(\sqrt[8]{3})$ has minimal polynomial $x^{8}-3$ . And since each simple extension has an increasingly large degree, the degree of the simple extensions over the previous extension gets larger for each attachment. But I am not sure how to express this formally... For the infinite degree part, I was thinking because the set $\left \{\sqrt{3},\sqrt[4]{3}, \sqrt[8]{3},...\right \}$ is linearly independent?","Show that is algebraic over but not a finite extension. I think for the algebraic part, since for every simple extension, each of those elements can be adjoined and each of these simple extensions has a minimal polynomial that cannot be reduced in . For example, the simple extension has minimal polynomial . And since each simple extension has an increasingly large degree, the degree of the simple extensions over the previous extension gets larger for each attachment. But I am not sure how to express this formally... For the infinite degree part, I was thinking because the set is linearly independent?","\mathbb{Q}(\sqrt{3},\sqrt[4]{3}, \sqrt[8]{3},...) \mathbb{Q} \mathbb{Q} \mathbb{Q}(\sqrt{3}, \sqrt[4]{3})(\sqrt[8]{3}) x^{8}-3 \left \{\sqrt{3},\sqrt[4]{3}, \sqrt[8]{3},...\right \}",['abstract-algebra']
88,Fundamental Theorem of Algebra for Two Variables,Fundamental Theorem of Algebra for Two Variables,,"Is there an extension for the Fundamental Theorem of Algebra for Two or more variables, such in case of polynomials systems: $ \begin{cases} f(x, y) = 0 \\ g(x, y) = 0 \end{cases} $ For single-variable polynomials, the Theorem states that nth-degree polynomials implies n complex roots. And about two or more variables, there is such extension? Perhaps a sum of degrees or the max number of degrees of the variables?","Is there an extension for the Fundamental Theorem of Algebra for Two or more variables, such in case of polynomials systems: $ \begin{cases} f(x, y) = 0 \\ g(x, y) = 0 \end{cases} $ For single-variable polynomials, the Theorem states that nth-degree polynomials implies n complex roots. And about two or more variables, there is such extension? Perhaps a sum of degrees or the max number of degrees of the variables?",,['abstract-algebra']
89,Calculating the degree of some extension of $\mathbb{Q}_3$,Calculating the degree of some extension of,\mathbb{Q}_3,"Let $p=3$ and $\zeta$ be a cube root of unity not equal $1$. Consider the field of $3$-adic numbers $\mathbb{Q}_3$. At the beginning of section 5.4 of Fernando Gouvea's book $p$-adic numbers - An Introduction , he states that the field $\mathbb{Q}_3(\sqrt{2},\zeta)$ is an extension of degree $4$. Furthermore, the fields $\mathbb{Q}_3(\sqrt{2})$ and $\mathbb{Q}_3(\zeta)$ are both extensions of degree $2$. Now I would like to understand why this is true. I understand why we have $[\mathbb{Q}_3(\sqrt{2}):\mathbb{Q}_3]=2$. This is true because $f = x^2-2$ is irreducible over $\mathbb{Q}_3$, as 2 is a quadratic nonresidue, so we can apply Eisenstein's criterion. This means that $f$ is the minimal polynomial of $\sqrt{2}$ which has degree $2$. Therefore, the claim holds. I am also really sure about the fact that $[\mathbb{Q}_3(\zeta):\mathbb{Q}_3]=2$ is true. As $\zeta$ is a cubic root of unity, the minimal polynomial of $\zeta$ divides $x^3 - 1$ which has $1$ as a root, so it is obviously not irreducible. If we divide $x^3 - 1$ by $x-1$, then we obtain the polynomial $g=x^2+x+1$. This must mean that $g$ is the minimal polynomial of $\zeta$ if the degree of the extension is really $2$. But I do not know how to show why $g$ is irreducible over $\mathbb{Q}_3$. To show that $[\mathbb{Q}_3(\zeta,\sqrt{2}):\mathbb{Q}_3] = 4$, we only have to show either $\zeta \not\in \mathbb{Q}_3(\sqrt{2})$ or $\sqrt{2} \not\in \mathbb{Q}_3(\zeta)$, so we can apply the tower law. For instance, we assume $\zeta \in \mathbb{Q}_3(\sqrt{2})$. Then there exist coefficients $c_1,c_2 \in \mathbb{Q}_3$ such that $\zeta = c_1 + c_2 \sqrt{2}$ because we know that $\mathbb{Q}_3(\sqrt{2})$ is a vector space of $\mathbb{Q}_3$ of dimension $2$ with basis $\{1,\sqrt{2}\}$. Then $$ 0 = \zeta^2 + \zeta + 1 = (c_1^2 + 2c_2^2+c_1+1) + (2c_1c_2+c_2)\sqrt{2}  $$ and therefore $c_1^2 + 2c_2^2+c_1+1=0$ and $2c_1c_2+c_2=0$. But this looks like a really difficult system of equations to solve, as I know nothing about $c_1$ and $c_2$. Could you please help me with this problem? Thank you in advance!","Let $p=3$ and $\zeta$ be a cube root of unity not equal $1$. Consider the field of $3$-adic numbers $\mathbb{Q}_3$. At the beginning of section 5.4 of Fernando Gouvea's book $p$-adic numbers - An Introduction , he states that the field $\mathbb{Q}_3(\sqrt{2},\zeta)$ is an extension of degree $4$. Furthermore, the fields $\mathbb{Q}_3(\sqrt{2})$ and $\mathbb{Q}_3(\zeta)$ are both extensions of degree $2$. Now I would like to understand why this is true. I understand why we have $[\mathbb{Q}_3(\sqrt{2}):\mathbb{Q}_3]=2$. This is true because $f = x^2-2$ is irreducible over $\mathbb{Q}_3$, as 2 is a quadratic nonresidue, so we can apply Eisenstein's criterion. This means that $f$ is the minimal polynomial of $\sqrt{2}$ which has degree $2$. Therefore, the claim holds. I am also really sure about the fact that $[\mathbb{Q}_3(\zeta):\mathbb{Q}_3]=2$ is true. As $\zeta$ is a cubic root of unity, the minimal polynomial of $\zeta$ divides $x^3 - 1$ which has $1$ as a root, so it is obviously not irreducible. If we divide $x^3 - 1$ by $x-1$, then we obtain the polynomial $g=x^2+x+1$. This must mean that $g$ is the minimal polynomial of $\zeta$ if the degree of the extension is really $2$. But I do not know how to show why $g$ is irreducible over $\mathbb{Q}_3$. To show that $[\mathbb{Q}_3(\zeta,\sqrt{2}):\mathbb{Q}_3] = 4$, we only have to show either $\zeta \not\in \mathbb{Q}_3(\sqrt{2})$ or $\sqrt{2} \not\in \mathbb{Q}_3(\zeta)$, so we can apply the tower law. For instance, we assume $\zeta \in \mathbb{Q}_3(\sqrt{2})$. Then there exist coefficients $c_1,c_2 \in \mathbb{Q}_3$ such that $\zeta = c_1 + c_2 \sqrt{2}$ because we know that $\mathbb{Q}_3(\sqrt{2})$ is a vector space of $\mathbb{Q}_3$ of dimension $2$ with basis $\{1,\sqrt{2}\}$. Then $$ 0 = \zeta^2 + \zeta + 1 = (c_1^2 + 2c_2^2+c_1+1) + (2c_1c_2+c_2)\sqrt{2}  $$ and therefore $c_1^2 + 2c_2^2+c_1+1=0$ and $2c_1c_2+c_2=0$. But this looks like a really difficult system of equations to solve, as I know nothing about $c_1$ and $c_2$. Could you please help me with this problem? Thank you in advance!",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory', 'extension-field', 'p-adic-number-theory']"
90,Show that the field of fractions of $\mathbb{Z}[[x]]$ is properly contained in $\Bbb Q((x))$,Show that the field of fractions of  is properly contained in,\mathbb{Z}[[x]] \Bbb Q((x)),"I've been working on this for a while but I don't know how to proceed. Here it's what I've done: Clearly, my goal is to show that every element of the field of fractions is in $\Bbb Q((x))$ and to show that there exist an element of $\Bbb Q((x))$ that is not an element of the field of fractions. The problem suggests considering the series expansion for $e^x$ so that's what I did. I guess that that's the hint because $e^x$ is the element in $\mathbb{Q}((x))$ that is not in $\text{Frac}(\mathbb{Z}[[x]])$ I'm looking for. So  $$e^x=\displaystyle \sum_{n=0}^\infty \frac{x^n}{n!}$$ Since $n!\in\mathbb{N}$ then $\frac{1}{n!}\in \mathbb{Q}$ and $e^x\in \mathbb{Q}((x))$ Now, this is where I can't go further. I've tried assuming that $e^x\in \text{Frac}(\mathbb{Z}[[x]])$ and using that it must be a unit to achieve a contradiction but I don't know how to do so. Any hints? Thanks in advance","I've been working on this for a while but I don't know how to proceed. Here it's what I've done: Clearly, my goal is to show that every element of the field of fractions is in $\Bbb Q((x))$ and to show that there exist an element of $\Bbb Q((x))$ that is not an element of the field of fractions. The problem suggests considering the series expansion for $e^x$ so that's what I did. I guess that that's the hint because $e^x$ is the element in $\mathbb{Q}((x))$ that is not in $\text{Frac}(\mathbb{Z}[[x]])$ I'm looking for. So  $$e^x=\displaystyle \sum_{n=0}^\infty \frac{x^n}{n!}$$ Since $n!\in\mathbb{N}$ then $\frac{1}{n!}\in \mathbb{Q}$ and $e^x\in \mathbb{Q}((x))$ Now, this is where I can't go further. I've tried assuming that $e^x\in \text{Frac}(\mathbb{Z}[[x]])$ and using that it must be a unit to achieve a contradiction but I don't know how to do so. Any hints? Thanks in advance",,"['abstract-algebra', 'field-theory', 'power-series', 'laurent-series']"
91,"Meaning of ""up to associates"" in unique prime factorization","Meaning of ""up to associates"" in unique prime factorization",,"We know that the Euclidean Domain has the property of Unique Factorization. More precisely, every nonzero element in a Euclidean ring $R$ can be uniquely written (up to associates) as a product of prime elements or is a unit in $R$. The word ""up to associates"" confusing me a bit. P.S. Let's consider the example in the euclidean domain $\mathbb{Z}[i]$ and consider the following prime factorizations such as: $$(2+i)(1+i) \quad\text{and} \quad (-1+2i)(1-i)$$ Note that $2+i\sim -1+2i$ and $1+i\sim 1-i$. Can anyone explain me the meaning of the phrase ""up to associates"" in the above example, please?","We know that the Euclidean Domain has the property of Unique Factorization. More precisely, every nonzero element in a Euclidean ring $R$ can be uniquely written (up to associates) as a product of prime elements or is a unit in $R$. The word ""up to associates"" confusing me a bit. P.S. Let's consider the example in the euclidean domain $\mathbb{Z}[i]$ and consider the following prime factorizations such as: $$(2+i)(1+i) \quad\text{and} \quad (-1+2i)(1-i)$$ Note that $2+i\sim -1+2i$ and $1+i\sim 1-i$. Can anyone explain me the meaning of the phrase ""up to associates"" in the above example, please?",,"['abstract-algebra', 'gaussian-integers']"
92,Field isomorphic to a transcendental extension of itself,Field isomorphic to a transcendental extension of itself,,"Let $k$ be any field and $K:=k(X_1,X_2,\dots)$ be the field of rational functions over $k$ in countably many variables. Now $K$ has the interesting property that it is isomorphic to a transcendental extension of itself namely $K\cong K(X)$. Are there any other examples of this phenomenon or is the following true? When $K$ is a field that is isomorphic to a transcendental extension of itself, then there is some field $k$ s.t. $K\cong k(X_1,X_2,\dots)$.","Let $k$ be any field and $K:=k(X_1,X_2,\dots)$ be the field of rational functions over $k$ in countably many variables. Now $K$ has the interesting property that it is isomorphic to a transcendental extension of itself namely $K\cong K(X)$. Are there any other examples of this phenomenon or is the following true? When $K$ is a field that is isomorphic to a transcendental extension of itself, then there is some field $k$ s.t. $K\cong k(X_1,X_2,\dots)$.",,"['abstract-algebra', 'field-theory']"
93,How can one go about counting the amount of abelian groups of a fixed order?,How can one go about counting the amount of abelian groups of a fixed order?,,"Let $n \in \mathbb{N}$ and let $$ n = p_1^{a_1} \cdots p_r^{a_r}  $$ be its factorization into primes. My intention is to count how many abelian groups $G$ of order $n$ are there. What follows are my thoughts about this question, which surely are quite rudimentary. By the structure theorem, we have that: $$ G \simeq \bigoplus_{i = 1}^r \bigoplus_{j = 1}^{m_i} \mathbb{Z}/(p_i^{s_{i,j}})  $$ with $s_{i,1} \leq \dots \leq s_{i,m_i}$ for each $i$ and thus, the cardinals of these two groups must coincide: $$ n = \prod_{i = 1}^r \prod_{j = 1}^{m_i} p_i^{s_{i,j}} = \prod_{i = 1}^r p_i^{\sum_{j = 1}^{m_i}s_{i,j}} $$ Therefore, by the uniqueness of prime factorization, $$ s_{i,1} + \dots + s_{i,m_i} = a_i \quad (\forall i\in [r])  $$ The question then turns into a combinatorial one, that is, how many combinations of non-negative, non-decreasing integers are there such that: $$ s_{i,1} + \dots + s_{i,m_i} = a_i \quad (\forall i\in [r])  $$ Since the problem is independent for each prime, we can tackle each of these independently. Moreover, we can count the amount of tuples of non negative numbers $(s_1, \dots, s_{a_i})$ in increasing order such that $\sum_{j = 1}^{a_i}s_j = a_i$; that is, we can fix a size for the amount of numbers, since the smallest possible case is to have exactly $a_i$ ones. Having done this, we have as many combinations as the $a_i$-th coefficient of the following generating function $$ f_i = \prod_{j = 1}^{a_i}(1-X^j)^{-1} = \left(\sum_{k \geq 0}X^k\right) \dots \left(\sum_{k \geq 0}X^{ka_i}\right) $$ by corresponding solutions to $x_1 + 2x_2 + \dots + a_ix_{a_i} = a_i$ with tuples by taking: $$ s_{a_i-q} = \sum_{k = q}^{a_i}x_k $$ that is, we would have $[f_i]_{a_i}$ possible solutions, giving a total of $$ [f_1]_{a_1} \cdots [f_r]_{a_r} $$ possible abelian groups of order $n$. I'd really appreciate if you could comment on whether this approach is correct or not and if so, how could one get a more explicit answer, since this one is rather unsatisfactory.","Let $n \in \mathbb{N}$ and let $$ n = p_1^{a_1} \cdots p_r^{a_r}  $$ be its factorization into primes. My intention is to count how many abelian groups $G$ of order $n$ are there. What follows are my thoughts about this question, which surely are quite rudimentary. By the structure theorem, we have that: $$ G \simeq \bigoplus_{i = 1}^r \bigoplus_{j = 1}^{m_i} \mathbb{Z}/(p_i^{s_{i,j}})  $$ with $s_{i,1} \leq \dots \leq s_{i,m_i}$ for each $i$ and thus, the cardinals of these two groups must coincide: $$ n = \prod_{i = 1}^r \prod_{j = 1}^{m_i} p_i^{s_{i,j}} = \prod_{i = 1}^r p_i^{\sum_{j = 1}^{m_i}s_{i,j}} $$ Therefore, by the uniqueness of prime factorization, $$ s_{i,1} + \dots + s_{i,m_i} = a_i \quad (\forall i\in [r])  $$ The question then turns into a combinatorial one, that is, how many combinations of non-negative, non-decreasing integers are there such that: $$ s_{i,1} + \dots + s_{i,m_i} = a_i \quad (\forall i\in [r])  $$ Since the problem is independent for each prime, we can tackle each of these independently. Moreover, we can count the amount of tuples of non negative numbers $(s_1, \dots, s_{a_i})$ in increasing order such that $\sum_{j = 1}^{a_i}s_j = a_i$; that is, we can fix a size for the amount of numbers, since the smallest possible case is to have exactly $a_i$ ones. Having done this, we have as many combinations as the $a_i$-th coefficient of the following generating function $$ f_i = \prod_{j = 1}^{a_i}(1-X^j)^{-1} = \left(\sum_{k \geq 0}X^k\right) \dots \left(\sum_{k \geq 0}X^{ka_i}\right) $$ by corresponding solutions to $x_1 + 2x_2 + \dots + a_ix_{a_i} = a_i$ with tuples by taking: $$ s_{a_i-q} = \sum_{k = q}^{a_i}x_k $$ that is, we would have $[f_i]_{a_i}$ possible solutions, giving a total of $$ [f_1]_{a_1} \cdots [f_r]_{a_r} $$ possible abelian groups of order $n$. I'd really appreciate if you could comment on whether this approach is correct or not and if so, how could one get a more explicit answer, since this one is rather unsatisfactory.",,"['abstract-algebra', 'combinatorics', 'abelian-groups']"
94,Why are 'finite morphisms' important in algebraic geometry? And what does a module of finite type mean?,Why are 'finite morphisms' important in algebraic geometry? And what does a module of finite type mean?,,"Linear transformations, Group, ring, $k$-algebra morphisms and many other types of morphisms that appear throughout mathematics are more or less obvious in the sense that we can clearly see why they are defined the way they are. Then we have continuous maps as morphisms in the category $\mathrm{Top}$ that look tricky in the way they're defined, but we don't mind them a lot because we have seen them long before we learned about morphisms and they are familiar to us. However, I have been struggling to understand why we need to define 'finite morphisms' in algebraic geometry. What do they help us achieve? What properties do they preserve? Why are they interesting? We already have a notion of morphism between algebraic varieties seen as 'spaces with functions' which seems quite natural and reasonable to me as it is. Why do we need another type of morphism between algebraic varieties? And more importantly, what does it mean for a $B$-module $A$ to be of finite type? Is it related to the concept of a finite morphism?","Linear transformations, Group, ring, $k$-algebra morphisms and many other types of morphisms that appear throughout mathematics are more or less obvious in the sense that we can clearly see why they are defined the way they are. Then we have continuous maps as morphisms in the category $\mathrm{Top}$ that look tricky in the way they're defined, but we don't mind them a lot because we have seen them long before we learned about morphisms and they are familiar to us. However, I have been struggling to understand why we need to define 'finite morphisms' in algebraic geometry. What do they help us achieve? What properties do they preserve? Why are they interesting? We already have a notion of morphism between algebraic varieties seen as 'spaces with functions' which seems quite natural and reasonable to me as it is. Why do we need another type of morphism between algebraic varieties? And more importantly, what does it mean for a $B$-module $A$ to be of finite type? Is it related to the concept of a finite morphism?",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'category-theory', 'morphism']"
95,How do we know that automorphisms on polynomials have a polynomial like form?,How do we know that automorphisms on polynomials have a polynomial like form?,,"Let $F$ be a field and $\sigma:F[x]\to F[x]$ be automorphism, $\sigma(a) = a$ for all $a\in F$. I'm supposed to show that $\sigma(f(x)) = f(ax+b)$ for some $a\not = 0$ and $b$ in $F$. Now I've got a solution that my professor gave me that seems to assume that the automorphism must have the form $\sigma(f(x)) = f(p(x))$ for some $p(x)\in F[x]$. So my question is how does $\sigma$ being an automorphism on $F[x]$ and $\sigma(a) = a$ for all $a\in F$ give us that $\sigma(f(x) = f(p(x))$ for some $p(x)\in F[x]$, why can't there be some weirder looking automorphism? I've looked at Automorphisms of $F[x]$ , however the only solution seems to make the same assumption that my professor makes.","Let $F$ be a field and $\sigma:F[x]\to F[x]$ be automorphism, $\sigma(a) = a$ for all $a\in F$. I'm supposed to show that $\sigma(f(x)) = f(ax+b)$ for some $a\not = 0$ and $b$ in $F$. Now I've got a solution that my professor gave me that seems to assume that the automorphism must have the form $\sigma(f(x)) = f(p(x))$ for some $p(x)\in F[x]$. So my question is how does $\sigma$ being an automorphism on $F[x]$ and $\sigma(a) = a$ for all $a\in F$ give us that $\sigma(f(x) = f(p(x))$ for some $p(x)\in F[x]$, why can't there be some weirder looking automorphism? I've looked at Automorphisms of $F[x]$ , however the only solution seems to make the same assumption that my professor makes.",,"['abstract-algebra', 'polynomial-rings']"
96,Forming a group from the product of two other groups?,Forming a group from the product of two other groups?,,"So I was talking to someone and they said if you have two groups $K_s$ and $K_t$ and a homomorphism $K_sAut(K_t)$, you can form what's called their semi direct product The idea being that each group embeds as a subgroup of the semi direct product and then you can think about multiplying their elements together... So let's say you have a group called $ K_s $ and another group called $ K_t $ and want to form a new group $ K_I = K_s \times K_t $. Can someone explain this concept of forming a group from the product of two other groups?","So I was talking to someone and they said if you have two groups $K_s$ and $K_t$ and a homomorphism $K_sAut(K_t)$, you can form what's called their semi direct product The idea being that each group embeds as a subgroup of the semi direct product and then you can think about multiplying their elements together... So let's say you have a group called $ K_s $ and another group called $ K_t $ and want to form a new group $ K_I = K_s \times K_t $. Can someone explain this concept of forming a group from the product of two other groups?",,"['abstract-algebra', 'group-theory']"
97,Does there exist an infinite nilpotent group with finite center?,Does there exist an infinite nilpotent group with finite center?,,"Does there exist an infinite nilpotent group with finite center? I failed to prove that it does not, but any examples of such groups do not come to my mind either. Any help will be appreciated.","Does there exist an infinite nilpotent group with finite center? I failed to prove that it does not, but any examples of such groups do not come to my mind either. Any help will be appreciated.",,"['abstract-algebra', 'group-theory']"
98,Smallest variety containing $\mathbb{Z}$,Smallest variety containing,\mathbb{Z},"I've been told that the answer is all abelian groups, but I don't see how. I know that the class of all nilpotent groups of degree 1 is a group variety and that a group being nilpotent of degree 1 is equivalent to that group being abelian so the class of all abeliani groups is indeed a variety.  I also know that the integers are a group when considered with addition as the operation and that a class of algebraic structures of the same signature is a variety if and only if it is closed under the taking of homomorphic images, subalgebras and (direct) products, but I'm not quite sure how to use this here or if this is even the way to go about this. I think that the main structure of this proof should be to show that $\mathbb{Z}$ is contained inside the variety of all abelian groups and then show that its the smallest one that could possibly contain $\mathbb{Z}$.  I know that in the class of abelian groups, the language is $(+, 0, \frac{1}{})$ and the identities are  $$(x+y)+z = x + (y+z),$$  $$x+y = y+x,$$  $$x + 0=x,$$  $$x+(-x) = 0,$$  all of which obviously hold on $\mathbb{Z}$.  Is that enough to say that the class of abelian groups contains $\mathbb{Z}$? How would I show nothing smaller could contain $\mathbb{Z}$?","I've been told that the answer is all abelian groups, but I don't see how. I know that the class of all nilpotent groups of degree 1 is a group variety and that a group being nilpotent of degree 1 is equivalent to that group being abelian so the class of all abeliani groups is indeed a variety.  I also know that the integers are a group when considered with addition as the operation and that a class of algebraic structures of the same signature is a variety if and only if it is closed under the taking of homomorphic images, subalgebras and (direct) products, but I'm not quite sure how to use this here or if this is even the way to go about this. I think that the main structure of this proof should be to show that $\mathbb{Z}$ is contained inside the variety of all abelian groups and then show that its the smallest one that could possibly contain $\mathbb{Z}$.  I know that in the class of abelian groups, the language is $(+, 0, \frac{1}{})$ and the identities are  $$(x+y)+z = x + (y+z),$$  $$x+y = y+x,$$  $$x + 0=x,$$  $$x+(-x) = 0,$$  all of which obviously hold on $\mathbb{Z}$.  Is that enough to say that the class of abelian groups contains $\mathbb{Z}$? How would I show nothing smaller could contain $\mathbb{Z}$?",,"['abstract-algebra', 'universal-algebra']"
99,"Let $\sigma \in\operatorname{Aut}(K)$ have infinite order and $F = \mathcal{F}(\sigma)$. Show that if $K/F$ is algebraic, then $K$ is normal over $F$.","Let  have infinite order and . Show that if  is algebraic, then  is normal over .",\sigma \in\operatorname{Aut}(K) F = \mathcal{F}(\sigma) K/F K F,"Let $K$ be a field, and suppose that $\sigma \in\operatorname{Aut}(K)$ has infinite order. Let $F$ be the fixed field of $\sigma$ . If $K/F$ is algebraic, show that $K$ is normal over $F$ . I have to use Definition. If $K$ is a field extension of $F$ , then $K$ is normal over $F$ if $K$ is splitting field of a set of polynomials over $F$ Criteria for normality: Proposition. If $K$ is algebraic over $F$ , then the following statements are equivalent: The field $K$ is normal over $F$ 2. If $M$ is an algebraic closure of $K$ and if $\tau: K \to M$ is an $F$ -homomorphism, then $\tau(K)=K$ . 3. If $F \subset L \subset K \subset N$ are fields and if $\sigma: L \to N$ is an $F$ -homomorphism, then $\sigma(L) \subset K$ , and there is a $\tau \in\operatorname{Gal}(K/F)$ with $\tau|_{L} = \sigma$ 4. For any irreducible $f(x) \in F[x]$ , if $f$ has a root in $K$ , then $f$ splits over $K$ . I'm not sure what to do, I'm trying to use the statement 2. We know that $\mathcal{F}(\sigma) = F$ , so $\sigma(F) = F$ . Let $M$ be an algebraic closure of $K$ . We know that $\sigma$ is an $F$ -automorphism, in particular, $\sigma$ is an $F$ -homomorphism... $\sigma: K \to M$ would not it be a $F$ -homomorphism? Seems very simple, I imagine I'm not seeing something, because I didn't use the hypothesis $\sigma$ has infinite order. Thanks for the help!","Let be a field, and suppose that has infinite order. Let be the fixed field of . If is algebraic, show that is normal over . I have to use Definition. If is a field extension of , then is normal over if is splitting field of a set of polynomials over Criteria for normality: Proposition. If is algebraic over , then the following statements are equivalent: The field is normal over 2. If is an algebraic closure of and if is an -homomorphism, then . 3. If are fields and if is an -homomorphism, then , and there is a with 4. For any irreducible , if has a root in , then splits over . I'm not sure what to do, I'm trying to use the statement 2. We know that , so . Let be an algebraic closure of . We know that is an -automorphism, in particular, is an -homomorphism... would not it be a -homomorphism? Seems very simple, I imagine I'm not seeing something, because I didn't use the hypothesis has infinite order. Thanks for the help!",K \sigma \in\operatorname{Aut}(K) F \sigma K/F K F K F K F K F K F K F M K \tau: K \to M F \tau(K)=K F \subset L \subset K \subset N \sigma: L \to N F \sigma(L) \subset K \tau \in\operatorname{Gal}(K/F) \tau|_{L} = \sigma f(x) \in F[x] f K f K \mathcal{F}(\sigma) = F \sigma(F) = F M K \sigma F \sigma F \sigma: K \to M F \sigma,"['abstract-algebra', 'field-theory', 'galois-theory', 'extension-field']"
