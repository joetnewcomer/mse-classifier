,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Confusion about implicit differentiation.,Confusion about implicit differentiation.,,"I want to implicitly differentiate $Ax^2 + By^2 + Cxy + Dx + Ey + F = 0$. This is not an exceedingly difficult task, and when I solved it I got $$ y' = -\frac{2Ax + Cy + D}{2By + Cx + E} $$ But my confusion comes from the fact that in this answer by frogeyedpeas, he says it is equal to $$ -\frac{2Ax + D}{2By + Cx + E}. $$ The confusion comes from the $Cxy$ term. The product rule says that $$\frac{d}{dx}Cxy = C(\frac{d}{dx}x\cdot y + x \cdot \frac{d}{dx}y) = C(y + xy'),$$ and wolfram alpha can verify this (just input $xy = 1$). Did frogeyedpeas accidentally make a mistake, or is there something I'm missing that makes this scenario different? EDIT: Finally it's all correct, I copied correctly and the coefficients are fixed. Thanks to everyone who pointed out the errors!","I want to implicitly differentiate $Ax^2 + By^2 + Cxy + Dx + Ey + F = 0$. This is not an exceedingly difficult task, and when I solved it I got $$ y' = -\frac{2Ax + Cy + D}{2By + Cx + E} $$ But my confusion comes from the fact that in this answer by frogeyedpeas, he says it is equal to $$ -\frac{2Ax + D}{2By + Cx + E}. $$ The confusion comes from the $Cxy$ term. The product rule says that $$\frac{d}{dx}Cxy = C(\frac{d}{dx}x\cdot y + x \cdot \frac{d}{dx}y) = C(y + xy'),$$ and wolfram alpha can verify this (just input $xy = 1$). Did frogeyedpeas accidentally make a mistake, or is there something I'm missing that makes this scenario different? EDIT: Finally it's all correct, I copied correctly and the coefficients are fixed. Thanks to everyone who pointed out the errors!",,"['derivatives', 'implicit-differentiation']"
1,Finding the derivative using the definition?,Finding the derivative using the definition?,,"Calculate the derivate of the given function directly from the definition of derivative, and express the result using differentials $$\lim_{h\to 0} \frac{f(x+h)-f(x)}{h}$$ when $f(x)= 1/\sqrt{1+x^2}$ any tips/solutions on how to get started on this one? I am able to do more basic problems, but not with root etc! thanks for tips/advice/solutions!","Calculate the derivate of the given function directly from the definition of derivative, and express the result using differentials $$\lim_{h\to 0} \frac{f(x+h)-f(x)}{h}$$ when $f(x)= 1/\sqrt{1+x^2}$ any tips/solutions on how to get started on this one? I am able to do more basic problems, but not with root etc! thanks for tips/advice/solutions!",,"['calculus', 'algebra-precalculus', 'derivatives']"
2,Can you factor before finding derivative?,Can you factor before finding derivative?,,Say the function is $y=\frac{x^2-1}{x-1}$ Can you factor functions before finding the derivative or does that not work?,Say the function is $y=\frac{x^2-1}{x-1}$ Can you factor functions before finding the derivative or does that not work?,,"['calculus', 'derivatives']"
3,How to determine if it is l'Hopital's or not?,How to determine if it is l'Hopital's or not?,,"I got a lot of limits questions that I am able to find there limits, but I do not know if they meet the qualification to be l'Hopital's or not. SO how to know that ? For example: Q1) $ \lim_{t \rightarrow \infty} \dfrac{(\ln t )^ 2}{t}$ I would say yes, infinity/infinity Q2) $ \lim_{y \rightarrow 0} \dfrac{2y}{y^2}$ I would say yes 0/0 Q3) $ \lim_{x \rightarrow \infty} \dfrac{e^{−x}}{ 1 + \ln x }$ I would say no, 0/number Q4) $\lim_{\theta \rightarrow 0} \dfrac{\arctan \theta}{7\theta}$ I would say yes, 0/0 Q5) $\lim_{x \rightarrow 0+ } \dfrac{\cot x}{\ln x}$ I don't know if the 0+ would make a difference of the 0. But The answer would be no because 0/undefined So bottom line is there any rules to know if it is l'Hospital's or not? I just feel that 0/0 and infinity/infinity are the ones that can determine. BUt is there any other forms ? such as 0/1 or 1/0 or infinity/0 ?","I got a lot of limits questions that I am able to find there limits, but I do not know if they meet the qualification to be l'Hopital's or not. SO how to know that ? For example: Q1) $ \lim_{t \rightarrow \infty} \dfrac{(\ln t )^ 2}{t}$ I would say yes, infinity/infinity Q2) $ \lim_{y \rightarrow 0} \dfrac{2y}{y^2}$ I would say yes 0/0 Q3) $ \lim_{x \rightarrow \infty} \dfrac{e^{−x}}{ 1 + \ln x }$ I would say no, 0/number Q4) $\lim_{\theta \rightarrow 0} \dfrac{\arctan \theta}{7\theta}$ I would say yes, 0/0 Q5) $\lim_{x \rightarrow 0+ } \dfrac{\cot x}{\ln x}$ I don't know if the 0+ would make a difference of the 0. But The answer would be no because 0/undefined So bottom line is there any rules to know if it is l'Hospital's or not? I just feel that 0/0 and infinity/infinity are the ones that can determine. BUt is there any other forms ? such as 0/1 or 1/0 or infinity/0 ?",,"['calculus', 'derivatives']"
4,Values of $6 + \int_a^x \frac{f(t)}{t^2} dt = 2 \sqrt{x}$,Values of,6 + \int_a^x \frac{f(t)}{t^2} dt = 2 \sqrt{x},"Let $f$ and $a$ such that $6 + \int_a^x \frac{f(t)}{t^2} dt = 2 \sqrt{x}$. I need to find the values of $f$ and $a$ that satisfies this condition. For this i tried: $F(x) = 6 + \int_a^x \frac{f(t)}{t^2} dt = 2 \sqrt{x}$ then $F´(x) = \frac{f(x)}{x^2} = \frac{1}{\sqrt{x}}$ since $ \frac{d}{dx} \int_a^x \frac{f(t)}{t^2} dt = \frac{f(x)}{x^2}$ and here i stuck , how can i conclude in get de values of $f$ and $a$ please some healp, thanxs for your time.","Let $f$ and $a$ such that $6 + \int_a^x \frac{f(t)}{t^2} dt = 2 \sqrt{x}$. I need to find the values of $f$ and $a$ that satisfies this condition. For this i tried: $F(x) = 6 + \int_a^x \frac{f(t)}{t^2} dt = 2 \sqrt{x}$ then $F´(x) = \frac{f(x)}{x^2} = \frac{1}{\sqrt{x}}$ since $ \frac{d}{dx} \int_a^x \frac{f(t)}{t^2} dt = \frac{f(x)}{x^2}$ and here i stuck , how can i conclude in get de values of $f$ and $a$ please some healp, thanxs for your time.",,"['calculus', 'real-analysis', 'algebra-precalculus', 'derivatives']"
5,Find the equation of the tangent line,Find the equation of the tangent line,,Find the equation of the line tangent to $f(x) = \tan x$ at $x = \frac{\pi}{4}$. I'm trying to incorporate the slope point formula using $f'(x) = \sec^2 x$ but I'm nowhere near!,Find the equation of the line tangent to $f(x) = \tan x$ at $x = \frac{\pi}{4}$. I'm trying to incorporate the slope point formula using $f'(x) = \sec^2 x$ but I'm nowhere near!,,"['calculus', 'derivatives']"
6,Does uniform convergence of $f$ imply convergence of derivatives?,Does uniform convergence of  imply convergence of derivatives?,f,"Let $X$ denote the collection of all differentiable functions $f : [0, 1] \rightarrow \Bbb R$, such that $f(0)=0$ and $f'$ is continuous. Let $\{f_n\}$ be a Cauchy sequence. By Cauchy criterion for uniform convergence, $f_n$ converges uniformly to some $f$. Does that imply that $f'_n \rightarrow f'$ uniformly?","Let $X$ denote the collection of all differentiable functions $f : [0, 1] \rightarrow \Bbb R$, such that $f(0)=0$ and $f'$ is continuous. Let $\{f_n\}$ be a Cauchy sequence. By Cauchy criterion for uniform convergence, $f_n$ converges uniformly to some $f$. Does that imply that $f'_n \rightarrow f'$ uniformly?",,"['real-analysis', 'derivatives', 'convergence-divergence', 'uniform-convergence']"
7,What is defined by rate of change at a single point?,What is defined by rate of change at a single point?,,"Rate of change measures how fast a process is going when it moves from one point to another. It measures the change of, say, $Y$ when $X$ moves from $X$ to $X + \Delta X$. But my problem arises when rate of change is concerned at only a single point; the mathematical tool to solve this is to use derivative at that point provided the graph is continuous. I am unable to understand the rate of change concept at a single point; I have always connected the rate of change with two points. So what is the rate of change concept at a single point? Let a spherical balloon have a variable radius & the rate of change of volume w.r.t radius when radius is $7$ unit is $196\pi$. What is the meaning of this statement when it mentions the rate of change at a single point i.e. at $r=7$? Thanks for your help.","Rate of change measures how fast a process is going when it moves from one point to another. It measures the change of, say, $Y$ when $X$ moves from $X$ to $X + \Delta X$. But my problem arises when rate of change is concerned at only a single point; the mathematical tool to solve this is to use derivative at that point provided the graph is continuous. I am unable to understand the rate of change concept at a single point; I have always connected the rate of change with two points. So what is the rate of change concept at a single point? Let a spherical balloon have a variable radius & the rate of change of volume w.r.t radius when radius is $7$ unit is $196\pi$. What is the meaning of this statement when it mentions the rate of change at a single point i.e. at $r=7$? Thanks for your help.",,['calculus']
8,Find the Taylor series of $f(x) = e ^{- 1 / x^2}$,Find the Taylor series of,f(x) = e ^{- 1 / x^2},"Find the Taylor series about 0, the function defined as: $f(x) = e ^{- 1 / x^2}$ if $x \ne 0$ and $f(x) = 0$ if $x=0$ and What can i conclude of the resulting? First i note that the function f is even then i calculate the derivatives:  $$f'(x) = e ^{- 1 / x^2} (2 / x^3)^2$$ $$f'(x) = e ^{- 1 / x^2} (2 / x^3)^2 + e ^{- 1 / x^2} (- 6/ x^4) $$ but when when i analyzed the derivative in $x=0$ : $\lim\limits_{x\rightarrow 0} \frac{f(x) - f(0)}{x-0} = \lim\limits_{x\rightarrow 0} \frac{e ^{- 1 / x^2}}{x} $ and this is and indeterminate  $\frac{0}{0}$ then for l'hopital: $\lim\limits_{x\rightarrow 0} \frac{(e {^{- 1 /x^{2}}})'}{x'}  = \lim\limits_{x\rightarrow 0} \frac{(e {^{- 1 /x^{2}}})( \frac{2}{x^3})}{1} $ but i stuck here how can i get the taylor series if i can't find the derivative in this point, please help me.","Find the Taylor series about 0, the function defined as: $f(x) = e ^{- 1 / x^2}$ if $x \ne 0$ and $f(x) = 0$ if $x=0$ and What can i conclude of the resulting? First i note that the function f is even then i calculate the derivatives:  $$f'(x) = e ^{- 1 / x^2} (2 / x^3)^2$$ $$f'(x) = e ^{- 1 / x^2} (2 / x^3)^2 + e ^{- 1 / x^2} (- 6/ x^4) $$ but when when i analyzed the derivative in $x=0$ : $\lim\limits_{x\rightarrow 0} \frac{f(x) - f(0)}{x-0} = \lim\limits_{x\rightarrow 0} \frac{e ^{- 1 / x^2}}{x} $ and this is and indeterminate  $\frac{0}{0}$ then for l'hopital: $\lim\limits_{x\rightarrow 0} \frac{(e {^{- 1 /x^{2}}})'}{x'}  = \lim\limits_{x\rightarrow 0} \frac{(e {^{- 1 /x^{2}}})( \frac{2}{x^3})}{1} $ but i stuck here how can i get the taylor series if i can't find the derivative in this point, please help me.",,"['calculus', 'derivatives', 'taylor-expansion']"
9,Solve $\lim_{x\to0}{\frac{x^2\cdot\sin\frac{1}{x}}{\sin x}}$,Solve,\lim_{x\to0}{\frac{x^2\cdot\sin\frac{1}{x}}{\sin x}},"Find the limit: $$\lim_{x\to0}{\frac{x^2\cdot\sin\frac{1}{x}}{\sin x}}$$ After treating it with l'Hopital rule, we get: $$\lim_{x\to0}{\frac{2x\cdot\sin \frac{1}{x}-\cos\frac{1}{x}}{\cos x}}$$ Now, the numerator of fraction doesn't have a limit, so I can't use l'Hopital rule again. What to do? I can split it into two fractions, but I'm not sure how would it help: $$\lim_{x\to0}{\frac{2x\cdot\sin \frac{1}{x}}{\cos x}} - \lim_{x\to0}{\frac{\cos\frac{1}{x}}{\cos x}}$$","Find the limit: $$\lim_{x\to0}{\frac{x^2\cdot\sin\frac{1}{x}}{\sin x}}$$ After treating it with l'Hopital rule, we get: $$\lim_{x\to0}{\frac{2x\cdot\sin \frac{1}{x}-\cos\frac{1}{x}}{\cos x}}$$ Now, the numerator of fraction doesn't have a limit, so I can't use l'Hopital rule again. What to do? I can split it into two fractions, but I'm not sure how would it help: $$\lim_{x\to0}{\frac{2x\cdot\sin \frac{1}{x}}{\cos x}} - \lim_{x\to0}{\frac{\cos\frac{1}{x}}{\cos x}}$$",,['derivatives']
10,Find constants $a$ and $b$ such that $ \lim_{x \to 0} \frac{1}{bx-\sin x} \int^x_0 \frac{t^2dt}{ \sqrt{a+t}}=1$,Find constants  and  such that,a b  \lim_{x \to 0} \frac{1}{bx-\sin x} \int^x_0 \frac{t^2dt}{ \sqrt{a+t}}=1,"Find constants $a$ and $b$ such that $$ \lim_{x \to 0} \frac{1}{bx-\sin x} \int^x_0 \frac{t^2dt}{ \sqrt{a+t}}=1$$ First,$a$ should be positive to make sure the limit is meaningful as $x \to 0^-$ . Then I check the limit of the numerator,say $- \frac{a}{2}<x<0$. For t in the interval(x,0), there's  $\frac{1}{\sqrt{a+t}}<M$, where $M>0$,so $$| \int^x_0 \frac{t^2dt}{ \sqrt{a+t}} | <M |\int^x_0t^2dt| =M \frac{-x^3}{3},$$ by using the sandwich theorem I get $\lim_{x \to 0^-} \int^x_0 \frac{t^2dt}{ \sqrt{a+t}} =0$,thing should be the same when $x>0$ . So the limit is the form $0/0$ . Apply L'Hopital's rule twice I get  $$\begin{align} \lim_{x \to 0} \frac{1}{bx-\sin x} \int^x_0 \frac{t^2dt}{ \sqrt{a+t}}  &= \lim_{x \to 0} \frac{x^2}{ \sqrt{a+x}(bx-\sin x)} \\ &= \lim_{x \to 0} \frac{2x} { \frac{bx-\sin x}{2 \sqrt{a+x}}+ \sqrt{a+x}  (b- \cos x)} \\ &= \lim_{x \to 0} \frac{4x \sqrt{a+x}}{3bx+2ab-2(a+x)\cos x -\sin x} \end{align}$$Now the limit becomes $ \frac{0}{2ab-2a}$,so $2a(b-1)=0$ and $b=1$ cause $a$ is positive. Apply L'Hopital's rule again $$\begin{align}  \lim_{x \to 0} \frac{4x \sqrt{a+x}}{3x+2a-2(a+x)\cos x -\sin x} &= \lim_{x \to 0} \frac{4( \sqrt{a+x} + \frac{x}{2 \sqrt{a+x}})}{3+2a \sin x- 2 \cos x  + 2 x \sin x - \cos x} \\ & =  \lim_{x \to 0} \frac{2(2a+3x)}{\sqrt{a+x} (3-3 \cos x  + 2a \sin x + 2x \sin x )}  \\ &= \frac{4a}{\sqrt{a}  0}  \quad ?!\end{align}$$ and I fail to solve it. Thanks in advance.","Find constants $a$ and $b$ such that $$ \lim_{x \to 0} \frac{1}{bx-\sin x} \int^x_0 \frac{t^2dt}{ \sqrt{a+t}}=1$$ First,$a$ should be positive to make sure the limit is meaningful as $x \to 0^-$ . Then I check the limit of the numerator,say $- \frac{a}{2}<x<0$. For t in the interval(x,0), there's  $\frac{1}{\sqrt{a+t}}<M$, where $M>0$,so $$| \int^x_0 \frac{t^2dt}{ \sqrt{a+t}} | <M |\int^x_0t^2dt| =M \frac{-x^3}{3},$$ by using the sandwich theorem I get $\lim_{x \to 0^-} \int^x_0 \frac{t^2dt}{ \sqrt{a+t}} =0$,thing should be the same when $x>0$ . So the limit is the form $0/0$ . Apply L'Hopital's rule twice I get  $$\begin{align} \lim_{x \to 0} \frac{1}{bx-\sin x} \int^x_0 \frac{t^2dt}{ \sqrt{a+t}}  &= \lim_{x \to 0} \frac{x^2}{ \sqrt{a+x}(bx-\sin x)} \\ &= \lim_{x \to 0} \frac{2x} { \frac{bx-\sin x}{2 \sqrt{a+x}}+ \sqrt{a+x}  (b- \cos x)} \\ &= \lim_{x \to 0} \frac{4x \sqrt{a+x}}{3bx+2ab-2(a+x)\cos x -\sin x} \end{align}$$Now the limit becomes $ \frac{0}{2ab-2a}$,so $2a(b-1)=0$ and $b=1$ cause $a$ is positive. Apply L'Hopital's rule again $$\begin{align}  \lim_{x \to 0} \frac{4x \sqrt{a+x}}{3x+2a-2(a+x)\cos x -\sin x} &= \lim_{x \to 0} \frac{4( \sqrt{a+x} + \frac{x}{2 \sqrt{a+x}})}{3+2a \sin x- 2 \cos x  + 2 x \sin x - \cos x} \\ & =  \lim_{x \to 0} \frac{2(2a+3x)}{\sqrt{a+x} (3-3 \cos x  + 2a \sin x + 2x \sin x )}  \\ &= \frac{4a}{\sqrt{a}  0}  \quad ?!\end{align}$$ and I fail to solve it. Thanks in advance.",,"['calculus', 'integration', 'limits', 'derivatives']"
11,Differentiation problem: Finding $f'(x)$,Differentiation problem: Finding,f'(x),"Let $$f(x) = \sqrt{x + \sqrt{0 + \sqrt{x + \sqrt{0 + \sqrt{x + \dots}}}}} \,.$$ If $f(a) = 4$, then find $f'(a)$. For this question, I really get stuck. Would anyone mind telling me how to obtain $f'(a)$?","Let $$f(x) = \sqrt{x + \sqrt{0 + \sqrt{x + \sqrt{0 + \sqrt{x + \dots}}}}} \,.$$ If $f(a) = 4$, then find $f'(a)$. For this question, I really get stuck. Would anyone mind telling me how to obtain $f'(a)$?",,"['calculus', 'sequences-and-series', 'derivatives']"
12,Find greatest value of $y(x) = (0.9^x)(300x + 650)$,Find greatest value of,y(x) = (0.9^x)(300x + 650),"Question and attempt $y(x) = (0.9^x)(300x + 650)$ Estimate at what x value that y reaches its maximum value The only way I could think of would be to use derivatives, so I tried it: $y'(x) = (0.9^x)' \times (300x + 650) + 0.9^x \times (300x + 650)'$ $=$ [$\ln(0.9) \times 0.9^x \times 1$] $\times  (300x + 650) + 0.9^x \times 300$ So then I subbed in 0 to find where the turning point is: $y(0) =\ln0.9 \times 0.9^0 \times (300(0) + 650) + 0.9^0 \times 300$ $=\ln0.9 \times 650 + 300$ ~ $231.51$ The problem is that $231.51$ is not the correct answer. The real answer This is a table of values of the answer (see that it increases up to in between x = 7 and 8, then decreases): x = 5: 1269.5535 x = 6: 1302.03045 x = 7: 1315.316475 x = 8: 1312.9249905 x = 9: 1297.85863815 Here is what the graph actually looks like (which tells me there is a turning point): And here is the picture of the vertex: So the x value at which the y value is at its maximum value is $7.3$ I'd like to know where I went wrong with the derivative idea, but I still would encourage answers describing any other way to solve the problem.","Question and attempt $y(x) = (0.9^x)(300x + 650)$ Estimate at what x value that y reaches its maximum value The only way I could think of would be to use derivatives, so I tried it: $y'(x) = (0.9^x)' \times (300x + 650) + 0.9^x \times (300x + 650)'$ $=$ [$\ln(0.9) \times 0.9^x \times 1$] $\times  (300x + 650) + 0.9^x \times 300$ So then I subbed in 0 to find where the turning point is: $y(0) =\ln0.9 \times 0.9^0 \times (300(0) + 650) + 0.9^0 \times 300$ $=\ln0.9 \times 650 + 300$ ~ $231.51$ The problem is that $231.51$ is not the correct answer. The real answer This is a table of values of the answer (see that it increases up to in between x = 7 and 8, then decreases): x = 5: 1269.5535 x = 6: 1302.03045 x = 7: 1315.316475 x = 8: 1312.9249905 x = 9: 1297.85863815 Here is what the graph actually looks like (which tells me there is a turning point): And here is the picture of the vertex: So the x value at which the y value is at its maximum value is $7.3$ I'd like to know where I went wrong with the derivative idea, but I still would encourage answers describing any other way to solve the problem.",,"['calculus', 'derivatives']"
13,Finding the nth derivative of $y=e^{ax+b}$,Finding the nth derivative of,y=e^{ax+b},How to find the $n$-th derivative of $y=e^{ax+b}$ Please provide an explanation of the steps. Thanks.,How to find the $n$-th derivative of $y=e^{ax+b}$ Please provide an explanation of the steps. Thanks.,,"['calculus', 'derivatives']"
14,Finding derivative at a point in a set,Finding derivative at a point in a set,,"If I have a few values for f(x), i.e. {(0,1), (2, 3), (5, 6)}, is there a way to calculate the derivative at, say f(6), without interpolation?","If I have a few values for f(x), i.e. {(0,1), (2, 3), (5, 6)}, is there a way to calculate the derivative at, say f(6), without interpolation?",,"['calculus', 'derivatives']"
15,shortest distant of curve from origin,shortest distant of curve from origin,,"what'd be shortest distance of curve from origin(0,0) function is $$ y=\frac{e^x+ e^{-x}}{2} $$  I tried taking some x and y points on curve then using distance formula finding distant then i found differential coefficient and equated to zero $$ dS/dx =0 $$  but did't got my answer","what'd be shortest distance of curve from origin(0,0) function is $$ y=\frac{e^x+ e^{-x}}{2} $$  I tried taking some x and y points on curve then using distance formula finding distant then i found differential coefficient and equated to zero $$ dS/dx =0 $$  but did't got my answer",,"['differential-geometry', 'derivatives']"
16,How to evaluate the derivative$\frac{d}{dx}\left(\ln\sqrt{\frac{4+x²}{4-x²}}\right)$?,How to evaluate the derivative?,\frac{d}{dx}\left(\ln\sqrt{\frac{4+x²}{4-x²}}\right),How can I evaluate this derivative?: $$\frac{d}{dx}\left(\ln\sqrt{\frac{4+x^2}{4-x^2}}\right)$$ Thank you.,How can I evaluate this derivative?: $$\frac{d}{dx}\left(\ln\sqrt{\frac{4+x^2}{4-x^2}}\right)$$ Thank you.,,"['calculus', 'derivatives']"
17,derive using the chain rule,derive using the chain rule,,"Given the polinomyal $f(x)=\frac{x^3}{(4-x^2)^3}$ find $f'(x)$ So, If I try to derive this, first I must to apply the chain rule in the denominator and then derive of the division (...) $$f'(x)=\frac{x^3}{3(4-x^2)^2(-2)} = \frac{x^3}{-6(4-x^2)^2}$$ (...)? Or there is another way to do this?","Given the polinomyal $f(x)=\frac{x^3}{(4-x^2)^3}$ find $f'(x)$ So, If I try to derive this, first I must to apply the chain rule in the denominator and then derive of the division (...) $$f'(x)=\frac{x^3}{3(4-x^2)^2(-2)} = \frac{x^3}{-6(4-x^2)^2}$$ (...)? Or there is another way to do this?",,"['calculus', 'derivatives']"
18,$e^{\large\frac{-t}{5}}(1-\frac{t}{5})=0$ solve for t,solve for t,e^{\large\frac{-t}{5}}(1-\frac{t}{5})=0,"I'm given the following equation an i have to solve for $""t""$ This is actually the derivative of a function, set equal to zero: $$f'(t) = e^\frac{-t}{5}(1-\frac{t}{5})=0$$ I will admit im just stuck and im looking for how to solve this efficiently. steps $1,\;2$ - rewrote the equation and distributed: $$\frac{1}{e^\frac{t}{5}}(1-\frac{t}{5}) \iff \frac{1-\frac{t}{5}}{e^\frac{t}{5}} $$ steps $3, \;4$ - common denominator of 5,  multiply by reciprocal of denominator: $$ \frac{\frac{5-t}{5}}{e^\frac{t}{5}}\iff\frac{\frac{5-t}{5}}*\frac{1}{e^\frac{t}{5}}  = \frac{5-t}{5e^\frac{t}{5}}  $$ step 5, set  this is where I,m stuck: $$f'(t) = \frac{5-t}{5e^\frac{t}{5}}=0$$ How do i go from here? And am I even doing this correctly? Any help would be greatly appreciated. Miguel","I'm given the following equation an i have to solve for $""t""$ This is actually the derivative of a function, set equal to zero: $$f'(t) = e^\frac{-t}{5}(1-\frac{t}{5})=0$$ I will admit im just stuck and im looking for how to solve this efficiently. steps $1,\;2$ - rewrote the equation and distributed: $$\frac{1}{e^\frac{t}{5}}(1-\frac{t}{5}) \iff \frac{1-\frac{t}{5}}{e^\frac{t}{5}} $$ steps $3, \;4$ - common denominator of 5,  multiply by reciprocal of denominator: $$ \frac{\frac{5-t}{5}}{e^\frac{t}{5}}\iff\frac{\frac{5-t}{5}}*\frac{1}{e^\frac{t}{5}}  = \frac{5-t}{5e^\frac{t}{5}}  $$ step 5, set  this is where I,m stuck: $$f'(t) = \frac{5-t}{5e^\frac{t}{5}}=0$$ How do i go from here? And am I even doing this correctly? Any help would be greatly appreciated. Miguel",,"['calculus', 'derivatives']"
19,Derivative of an integral,Derivative of an integral,,"I would like some guidance on how to solve these type of problems. Find $h'(x)$ if $$h(x) = \int\limits_{\cos(x)}^x \mathrm{e}^{t^2} \, dt$$ Mathematica says $h'(x) = e^{x^2} - e^{\cos^2(x)} ( - \sin x )$","I would like some guidance on how to solve these type of problems. Find $h'(x)$ if $$h(x) = \int\limits_{\cos(x)}^x \mathrm{e}^{t^2} \, dt$$ Mathematica says $h'(x) = e^{x^2} - e^{\cos^2(x)} ( - \sin x )$",,"['integration', 'derivatives']"
20,How do I find the derivative of $2e^{-x}+e^{5x}$,How do I find the derivative of,2e^{-x}+e^{5x},$$2e^{-x}+e^{5x}$$ Here is what I have tried: $$2e^{-x}+e^{5x}$$ $$\frac{2}{e^x}+e^{5x}$$ $$\left(\frac{2}{e^x}\right)'+(e^{5x})'$$ $$\left(\frac{2}{e^x}\right)' = \frac{-2e^x}{e^{2x}}$$ $$(e^{5x})'=5xe^{5x}$$ So the answer I got was $$\frac{-2e^x}{e^{2x}}+5xe^{5x}$$ I checked my answer online and it said that it was incorrect but I am sure I have done the steps correctly. Did I approach this problem correctly?,$$2e^{-x}+e^{5x}$$ Here is what I have tried: $$2e^{-x}+e^{5x}$$ $$\frac{2}{e^x}+e^{5x}$$ $$\left(\frac{2}{e^x}\right)'+(e^{5x})'$$ $$\left(\frac{2}{e^x}\right)' = \frac{-2e^x}{e^{2x}}$$ $$(e^{5x})'=5xe^{5x}$$ So the answer I got was $$\frac{-2e^x}{e^{2x}}+5xe^{5x}$$ I checked my answer online and it said that it was incorrect but I am sure I have done the steps correctly. Did I approach this problem correctly?,,"['calculus', 'derivatives']"
21,Inverse of $e^{-x^2/2} + 2x$,Inverse of,e^{-x^2/2} + 2x,I would like to find the inverse of $$f(x) = e^{-x^2/2} +  2x.$$ The reason I need to find the inverse is to evaluate the derivative of the inverse at $x=1$. I realise I can do that without actually finding the inverse of $f$ since $f(0)= 1$ if and only if $f^{-1}(1) =0$. Yet I'd appreciate it if someone could help me find the inverse of $f$.,I would like to find the inverse of $$f(x) = e^{-x^2/2} +  2x.$$ The reason I need to find the inverse is to evaluate the derivative of the inverse at $x=1$. I realise I can do that without actually finding the inverse of $f$ since $f(0)= 1$ if and only if $f^{-1}(1) =0$. Yet I'd appreciate it if someone could help me find the inverse of $f$.,,"['calculus', 'derivatives']"
22,Can we use integration to simulate a derivative?,Can we use integration to simulate a derivative?,,"If we suppose that we have the problem of finding the derivative for some function, say $f(x)$ at a point $p$, can we use an integral to calculate it? My incomplete idea is that we can take an integral: $$\int_a^p{f(x) dx}$$ which gives us the area under the function $f(x)$.  We then divide the area by the $x$ distance, which gives us the average slope of $f(x)$: $$\frac{\int_a^p{f(x) dx}}{p-a}$$ We then take the limit as $a$ approaches $p$ to find the slope at that point: $$\lim_{a \to p}{\frac{\int_a^p{f(x) dx}}{p-a}}$$ Is this correct?  If not, how could we similarly simulate a derviate using an integral? I am also interested in finding the function of the derivative using an integral (at all points, instead of just one).","If we suppose that we have the problem of finding the derivative for some function, say $f(x)$ at a point $p$, can we use an integral to calculate it? My incomplete idea is that we can take an integral: $$\int_a^p{f(x) dx}$$ which gives us the area under the function $f(x)$.  We then divide the area by the $x$ distance, which gives us the average slope of $f(x)$: $$\frac{\int_a^p{f(x) dx}}{p-a}$$ We then take the limit as $a$ approaches $p$ to find the slope at that point: $$\lim_{a \to p}{\frac{\int_a^p{f(x) dx}}{p-a}}$$ Is this correct?  If not, how could we similarly simulate a derviate using an integral? I am also interested in finding the function of the derivative using an integral (at all points, instead of just one).",,"['integration', 'derivatives']"
23,Why is the derivative of $\frac{|x|}{x}$ equal to $\emptyset$ at $x=0$?,Why is the derivative of  equal to  at ?,\frac{|x|}{x} \emptyset x=0,"I got a bit of a confusion here. If $\varphi(x)=\frac{|x|}{x}$, then  $$ \varphi(x) = \left.\Bigg\{ \begin{array}{cc} 1 &if \ x>0\\ \emptyset & if \ x=0\\ -1 & if \ x <0 \end{array} \right. $$ and then $$ \varphi'(x) = \left.\Bigg\{ \begin{array}{cc} 0 &if \ x>0 \cup x<0\\ \emptyset & if \ x=0 \end{array} \right. $$ The derivative at $0$ is nevertheless also $0$. Why? My only suspicion is that $\varphi(x)$ is actually somehow defined at $x=0$, although I do not see how: there should be an indeterminate form $\frac{0}{0}$. Some form of L'Hospital's rule?","I got a bit of a confusion here. If $\varphi(x)=\frac{|x|}{x}$, then  $$ \varphi(x) = \left.\Bigg\{ \begin{array}{cc} 1 &if \ x>0\\ \emptyset & if \ x=0\\ -1 & if \ x <0 \end{array} \right. $$ and then $$ \varphi'(x) = \left.\Bigg\{ \begin{array}{cc} 0 &if \ x>0 \cup x<0\\ \emptyset & if \ x=0 \end{array} \right. $$ The derivative at $0$ is nevertheless also $0$. Why? My only suspicion is that $\varphi(x)$ is actually somehow defined at $x=0$, although I do not see how: there should be an indeterminate form $\frac{0}{0}$. Some form of L'Hospital's rule?",,"['calculus', 'real-analysis', 'derivatives', 'absolute-value']"
24,Find $\frac{d}{dx}(\cos x)$,Find,\frac{d}{dx}(\cos x),Find $\dfrac{d}{dx}(\cos x)$ I know the answer is $-\sin x$ only by process of elimination. I can find solution graphically but I need to know algebraically. Here is my proof so far. $\begin{align*} \dfrac{d}{dx}\cos x=\lim_{h\to 0}\dfrac{\cos (x+h)-\cos x}{h} &=\lim_{h\to 0}\dfrac{\cos x\cos h-\sin x\sin h-\cos x}{h} \end{align*}$ And that's where I end up and I have no clue where to go from here. Can someone please give me the next step but not the complete answer.,Find $\dfrac{d}{dx}(\cos x)$ I know the answer is $-\sin x$ only by process of elimination. I can find solution graphically but I need to know algebraically. Here is my proof so far. $\begin{align*} \dfrac{d}{dx}\cos x=\lim_{h\to 0}\dfrac{\cos (x+h)-\cos x}{h} &=\lim_{h\to 0}\dfrac{\cos x\cos h-\sin x\sin h-\cos x}{h} \end{align*}$ And that's where I end up and I have no clue where to go from here. Can someone please give me the next step but not the complete answer.,,"['calculus', 'trigonometry', 'derivatives']"
25,Evaluate $\frac{d}{dx}ⁿx$.,Evaluate .,\frac{d}{dx}ⁿx,"Evaluate $\frac{d}{dx}ⁿx$ which $ⁿx=x^{x^{x^{...}}}$, total $n$ $x$'s. I have tried to observe when $n=1,2,3,4,5$, but it's difficult to see the pattern. Can anyone get it? Thank you.","Evaluate $\frac{d}{dx}ⁿx$ which $ⁿx=x^{x^{x^{...}}}$, total $n$ $x$'s. I have tried to observe when $n=1,2,3,4,5$, but it's difficult to see the pattern. Can anyone get it? Thank you.",,"['calculus', 'derivatives']"
26,Finding $f'(x)$ when $f(x)=\int^1_0 e^{xy+y^2}dy$,Finding  when,f'(x) f(x)=\int^1_0 e^{xy+y^2}dy,"If $f(x) = \int^1_0 e^{xy+y^2}dy$, find $f'(0)$. I understand that this is function defined by an integral, and $e^{y^{2}}$ does not integrate into an elementary function. So, I will need to take $f'(x)$ which yields: $$\int^1_0 ye^{xy+y^2}dy$$ I am trying to integrate this, but I am failing. I take it I should use integration by parts, but I can't because I still have $e^{y^2}$ term. Any help?","If $f(x) = \int^1_0 e^{xy+y^2}dy$, find $f'(0)$. I understand that this is function defined by an integral, and $e^{y^{2}}$ does not integrate into an elementary function. So, I will need to take $f'(x)$ which yields: $$\int^1_0 ye^{xy+y^2}dy$$ I am trying to integrate this, but I am failing. I take it I should use integration by parts, but I can't because I still have $e^{y^2}$ term. Any help?",,"['calculus', 'integration', 'derivatives']"
27,Uniform convergence and differentiation,Uniform convergence and differentiation,,"How does one show that given that $g\in C^1(a,b)$, the sequence of functions  $$ g_n=n\left(g\left(x+{1\over n}\right)-g(x)\right) $$  converges uniformly on all closed intervals in $(a,b)$? I assume the limit function is $g'(x)$.","How does one show that given that $g\in C^1(a,b)$, the sequence of functions  $$ g_n=n\left(g\left(x+{1\over n}\right)-g(x)\right) $$  converges uniformly on all closed intervals in $(a,b)$? I assume the limit function is $g'(x)$.",,"['real-analysis', 'sequences-and-series', 'analysis', 'derivatives', 'uniform-convergence']"
28,Higher derivatives of an exponential function,Higher derivatives of an exponential function,,"Let $$p_n(x)e^{-x^2}$$ be the $n$th derivative of $$e^{-x^2}.$$ Find a formula for $p_n(x)$. We have $p_1(x)=-2x, p_2(x)=4x^2-2$, etc. But what is the general formula for $p_n$?","Let $$p_n(x)e^{-x^2}$$ be the $n$th derivative of $$e^{-x^2}.$$ Find a formula for $p_n(x)$. We have $p_1(x)=-2x, p_2(x)=4x^2-2$, etc. But what is the general formula for $p_n$?",,"['calculus', 'real-analysis', 'derivatives']"
29,$| |x + y|^p - |x|^p | \leq \epsilon |x|^p + C |y|^p$,,| |x + y|^p - |x|^p | \leq \epsilon |x|^p + C |y|^p,"I want to demonstrate that: Let $1 < p < \infty$ ; for any $\epsilon > 0$ , there exists $C = C(\epsilon) \geq 1$ such that for all $x, y \in \mathbb{R}$ , we have $$ | |x + y|^p - |x|^p | \leq \epsilon |x|^p + C |y|^p.$$ I encountered this question while reading an article by Brézis, where, under certain conditions, $$\lim_n \, ( ||f_n||_p^p - ||f_n - f||_p^p ) = ||f||_p^p.$$ However, the inequality above was simply stated, and I'm struggling to understand why it holds. My thoughts are that it might be derived from some inequalities involving the derivatives of monotone functions. Thank you for any insights.","I want to demonstrate that: Let ; for any , there exists such that for all , we have I encountered this question while reading an article by Brézis, where, under certain conditions, However, the inequality above was simply stated, and I'm struggling to understand why it holds. My thoughts are that it might be derived from some inequalities involving the derivatives of monotone functions. Thank you for any insights.","1 < p < \infty \epsilon > 0 C = C(\epsilon) \geq 1 x, y \in \mathbb{R}  | |x + y|^p - |x|^p | \leq \epsilon |x|^p + C |y|^p. \lim_n \, ( ||f_n||_p^p - ||f_n - f||_p^p ) = ||f||_p^p.","['real-analysis', 'calculus', 'derivatives', 'lp-spaces', 'real-numbers']"
30,Chain rule and differentiability of $|x|^2$,Chain rule and differentiability of,|x|^2,"Going through Thomas Calculus, question 90 in the chapter on Chain Rule: Suppose that $f(x) =x^{2}$ and $g(x) =|x|$ . Then the composites $$ ( f\circ g)( x) =|x|^{2} =x^{2} \ \ \ \ \ \ and\ \ \ \ \ ( g\circ f)( x) =|x^{2} |=x^{2} $$ are both differentiable at $x=0$ even though $g$ itself is not differentiable at $x=0$ . Does this contradict the Chain Rule? I understand that $|x^{2}|$ is differentiable at $x=0$ because the inner function is differentiable. And the outer function receives only non-negative values, so it also turns out to be differentiable. But I don't believe that $f\circ g$ is differentiable. While the expression $|x|^{2}$ can be simplified to $x^{2}$ , these are in fact different functions. And because the inner $g$ isn't differentiable at $x=0$ , the whole composition isn't differentiable at this point. But strictly speaking the question itself doesn't sound correct - it says the composites are both differentiable. But what the author meant is the 3d function $c(x)=x^{2}$ is differentiable. Composites and $c(x)$ are not the same function - they just happen to give the same result. Do I understand the solution correctly? Is the question posed incorrectly?","Going through Thomas Calculus, question 90 in the chapter on Chain Rule: Suppose that and . Then the composites are both differentiable at even though itself is not differentiable at . Does this contradict the Chain Rule? I understand that is differentiable at because the inner function is differentiable. And the outer function receives only non-negative values, so it also turns out to be differentiable. But I don't believe that is differentiable. While the expression can be simplified to , these are in fact different functions. And because the inner isn't differentiable at , the whole composition isn't differentiable at this point. But strictly speaking the question itself doesn't sound correct - it says the composites are both differentiable. But what the author meant is the 3d function is differentiable. Composites and are not the same function - they just happen to give the same result. Do I understand the solution correctly? Is the question posed incorrectly?","f(x) =x^{2} g(x) =|x| 
( f\circ g)( x) =|x|^{2} =x^{2} \ \ \ \ \ \ and\ \ \ \ \ ( g\circ f)( x) =|x^{2} |=x^{2}
 x=0 g x=0 |x^{2}| x=0 f\circ g |x|^{2} x^{2} g x=0 c(x)=x^{2} c(x)","['derivatives', 'chain-rule']"
31,Differentiation: what rule am I missing here?,Differentiation: what rule am I missing here?,,"I am trying to differentiate the below with respect to c: $\left(\frac{a-b}{c-b}\right)^d$ , however I get an answer different to what Mathematica (and other sources) is telling me, which is $-\frac{(a-b)\left(\frac{a-b}{c-b}\right)^{d-1}d}{(c-b)^2}$ The way I'm approaching it is: $\left(\frac{a-b}{c-b}\right)^d = \frac{(a-b)^d}{(c-b)^d} = (a-b)^d*(c-b)^{-d}$ , then I treat $(a-b)^d$ as a constant and differentiate the $(c-b)^{-d}$ term which gives me: $(a-b)^d * -d(c-b)^{-d-1} = \frac{-d(a-b)^d}{(c-b)^{d-1}}$ . I can't work out what rule or a method I'm missing here unfortunately so I would be very grateful for any advice or pointers on that. Thanks for reading!","I am trying to differentiate the below with respect to c: , however I get an answer different to what Mathematica (and other sources) is telling me, which is The way I'm approaching it is: , then I treat as a constant and differentiate the term which gives me: . I can't work out what rule or a method I'm missing here unfortunately so I would be very grateful for any advice or pointers on that. Thanks for reading!",\left(\frac{a-b}{c-b}\right)^d -\frac{(a-b)\left(\frac{a-b}{c-b}\right)^{d-1}d}{(c-b)^2} \left(\frac{a-b}{c-b}\right)^d = \frac{(a-b)^d}{(c-b)^d} = (a-b)^d*(c-b)^{-d} (a-b)^d (c-b)^{-d} (a-b)^d * -d(c-b)^{-d-1} = \frac{-d(a-b)^d}{(c-b)^{d-1}},['derivatives']
32,How do I take $\dfrac d{dx}W(x+\ln|x+2|+c)$?,How do I take ?,\dfrac d{dx}W(x+\ln|x+2|+c),"So 4 days ago, I asked this question on how to solve the differential equation $$(xy+2y+x+2)y'=e^{-y}(x+3)$$ which I was able to solve, with the solution being $$W(x+\ln|x+2|+b),b=c_0-c_1$$ where $W(z)$ is Lambert's $W$ function, however I don't know how to verify this answer. Sure, as @Moo mentioned, all I have to do is plug in $W(x+\ln|x+2|+b)$ into the original equation, but that involves taking $\frac d{dx}W(x+\ln|x+2|+b)$ , which I don't know how to do. So my question is: How do I go about taking $\frac d{dx}W(x+\ln|x+2|+b)$ , where $W(z)$ is Lambert's $W$ function, also known as the product log function?","So 4 days ago, I asked this question on how to solve the differential equation which I was able to solve, with the solution being where is Lambert's function, however I don't know how to verify this answer. Sure, as @Moo mentioned, all I have to do is plug in into the original equation, but that involves taking , which I don't know how to do. So my question is: How do I go about taking , where is Lambert's function, also known as the product log function?","(xy+2y+x+2)y'=e^{-y}(x+3) W(x+\ln|x+2|+b),b=c_0-c_1 W(z) W W(x+\ln|x+2|+b) \frac d{dx}W(x+\ln|x+2|+b) \frac d{dx}W(x+\ln|x+2|+b) W(z) W","['calculus', 'derivatives']"
33,"If $f(x)=x^4+4x^3+26$, then find the number of solutions of $f(f(f(f(x))))=26$ is ____","If , then find the number of solutions of  is ____",f(x)=x^4+4x^3+26 f(f(f(f(x))))=26,"If $f(x)=x^4+4x^3+26$ , then find the number of solutions of $f(f(f(f(x))))=26$ is ____ My approach is as follows: $f'(x)=4x^3+12x^2=4x^2(x+3)$ $f''(x)=12x^2+24x=12x(x+2)$ At $x=-3$ it is minimum as the value of $f'(x)$ changes from negative to positive then $f(-3)=(-3)^4+4(-3)^3+26=-1$ , therefore the range of $f(x)$ is $[-1,\infty)$ .","If , then find the number of solutions of is ____ My approach is as follows: At it is minimum as the value of changes from negative to positive then , therefore the range of is .","f(x)=x^4+4x^3+26 f(f(f(f(x))))=26 f'(x)=4x^3+12x^2=4x^2(x+3) f''(x)=12x^2+24x=12x(x+2) x=-3 f'(x) f(-3)=(-3)^4+4(-3)^3+26=-1 f(x) [-1,\infty)","['calculus', 'derivatives']"
34,Gradient of $C \mapsto\frac{1}{2}\left\lVert CA - BC \right\rVert_F^2$,Gradient of,C \mapsto\frac{1}{2}\left\lVert CA - BC \right\rVert_F^2,"Given the matrices $A \in \mathbb{R}^{n \times n}$ and $B \in \mathbb{R}^{m \times m}$ , let the scalar field $f : \mathbb{R}^{m \times n} \to \mathbb{R}$ be defined by $$ f(C) := \frac{1}{2}\left\lVert CA - BC \right\rVert_F^2 $$ What is the gradient $\nabla f$ ? I am trying to differentiate this function w.r.t. to $C$ but I cannot find a way to manipulate the expression that would enable me to do so. I've also tried a definition of derivative adapted in this case but I don't endup with something useful at first glance. I endup with a linear map $df(C)$ defined by the expression $$ df(C)E = \text{trace} \left\{ (CA -BC)^T (EA - BE)\right\} = \left\langle CA -BC,EA-BE\right\rangle $$ which then leads to me to $$ df(C) = \left\langle AA^TC^T - AC^TB^T - A^TC^TB + C^TB^TB, \cdot \right\rangle $$ Is this expression correct?","Given the matrices and , let the scalar field be defined by What is the gradient ? I am trying to differentiate this function w.r.t. to but I cannot find a way to manipulate the expression that would enable me to do so. I've also tried a definition of derivative adapted in this case but I don't endup with something useful at first glance. I endup with a linear map defined by the expression which then leads to me to Is this expression correct?","A \in \mathbb{R}^{n \times n} B \in \mathbb{R}^{m \times m} f : \mathbb{R}^{m \times n} \to \mathbb{R}  f(C) := \frac{1}{2}\left\lVert CA - BC \right\rVert_F^2  \nabla f C df(C) 
df(C)E = \text{trace} \left\{ (CA -BC)^T (EA - BE)\right\} = \left\langle CA -BC,EA-BE\right\rangle
 
df(C) = \left\langle AA^TC^T - AC^TB^T - A^TC^TB + C^TB^TB, \cdot \right\rangle
","['matrices', 'derivatives', 'matrix-calculus', 'scalar-fields']"
35,Where am I going wrong with using the chain rule to compute the derivative of this composite function?,Where am I going wrong with using the chain rule to compute the derivative of this composite function?,,"Let $g$ be a function of $y_1$ and $y_2$ ; $g = f(y_1, y_2) = y_1 \times y_2$ . And further let $y_1 = x^2$ and $y_2 = 3\sin(x)$ Therefore $g = 3x^2 \sin(x)$ . The derivative with respect to $x$ then becomes $\frac{dg}{dx} = 6x\sin(x) + 3x^2 \cos(x)$ . Now I would like to compute the same derivative using the chain rule. So $\frac{dg}{dx} = \frac{1}{2}\frac{dg}{dx} + \frac{1}{2}\frac{dg}{dx} = \frac{1}{2}\frac{dg}{dx}\frac{dy_1}{dy_1} + \frac{1}{2}\frac{dg}{dx}\frac{dy_2}{dy_2} =  \frac{1}{2}\frac{dg}{dy_1}\frac{dy_1}{dx} + \frac{1}{2}\frac{dg}{dy_2}\frac{dy_2}{dx} = \frac{1}{2}y_2 \times 2x + \frac{1}{2} y_1 \times 3\cos(x) = 3x\sin(x) + \frac{3}{2}x^2\cos(x) $ Which is off by the factor $\frac{1}{2}$ . The algebra breaks down at some point here. Can anyone see where am going wrong?",Let be a function of and ; . And further let and Therefore . The derivative with respect to then becomes . Now I would like to compute the same derivative using the chain rule. So Which is off by the factor . The algebra breaks down at some point here. Can anyone see where am going wrong?,"g y_1 y_2 g = f(y_1, y_2) = y_1 \times y_2 y_1 = x^2 y_2 = 3\sin(x) g = 3x^2 \sin(x) x \frac{dg}{dx} = 6x\sin(x) + 3x^2 \cos(x) \frac{dg}{dx} = \frac{1}{2}\frac{dg}{dx} + \frac{1}{2}\frac{dg}{dx} = \frac{1}{2}\frac{dg}{dx}\frac{dy_1}{dy_1} + \frac{1}{2}\frac{dg}{dx}\frac{dy_2}{dy_2} = 
\frac{1}{2}\frac{dg}{dy_1}\frac{dy_1}{dx} + \frac{1}{2}\frac{dg}{dy_2}\frac{dy_2}{dx}
= \frac{1}{2}y_2 \times 2x + \frac{1}{2} y_1 \times 3\cos(x) = 3x\sin(x) + \frac{3}{2}x^2\cos(x)
 \frac{1}{2}","['derivatives', 'chain-rule']"
36,How to find out all the points where a function is not differentiable?,How to find out all the points where a function is not differentiable?,,"I came across a question wherein I was asked to find out where all the function $\left|x^2 - 5x+ 6\right|$ is differentiable. I plotted the graph of the function and I was able to find out that the above function isn't differentiable at $2$ and $3$ . Now without plotting the graph of the same, how can I find out the points where the above function isn't differentiable (or any other function).","I came across a question wherein I was asked to find out where all the function is differentiable. I plotted the graph of the function and I was able to find out that the above function isn't differentiable at and . Now without plotting the graph of the same, how can I find out the points where the above function isn't differentiable (or any other function).",\left|x^2 - 5x+ 6\right| 2 3,"['calculus', 'derivatives']"
37,Finding the derivative of $y = x^{(x+1)(x+2)(x+3)(x+4)\ldots(x+n)}$. [closed],Finding the derivative of . [closed],y = x^{(x+1)(x+2)(x+3)(x+4)\ldots(x+n)},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question I'm trying to find the derivative of this function with respect to $x$ : $$y = x^{(x+1)(x+2)(x+3)(x+4)\ldots(x+n)}$$ I was thinking about using $\ln$ to solve this, but I'm not sure if that's the right way to go about it. Any ideas or suggestions would be greatly appreciated. Thanks for your help!","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question I'm trying to find the derivative of this function with respect to : I was thinking about using to solve this, but I'm not sure if that's the right way to go about it. Any ideas or suggestions would be greatly appreciated. Thanks for your help!",x y = x^{(x+1)(x+2)(x+3)(x+4)\ldots(x+n)} \ln,"['calculus', 'derivatives', 'products']"
38,Why can't I use the form $\frac1{x^2+1}$ from the derivative of $\arctan(x)$ to convert the integral form in this situation?,Why can't I use the form  from the derivative of  to convert the integral form in this situation?,\frac1{x^2+1} \arctan(x),"In the question that solves the integral $\displaystyle\int\frac1{6x^2 + 36x + 78} \,\mathrm{d}x$ , I first tried to solve it by changing the denominator in a form of $\dfrac1{x^2 + 1}$ to apply $\;\arctan(x)$ . $\dfrac1{6\!\cdot\!\left(x^2 + 6x + 13\right)}=\dfrac16\!\cdot\!\dfrac1{(x + 3)^2 + 2^2}$ Now, in order to make it in a form of $\;\dfrac1{x^2 + 1}\;,\;$ I divide everything by $\,2^2$ : $=\dfrac16\!\cdot\!\dfrac1{\left(\frac{x+3}2\right)^2+1}\!\cdot\!\dfrac1{2^2} =\dfrac1{24}\!\cdot\!\dfrac1{\left(\frac{x+3}2\right)^2+1}$ Then assume that $\;u=\dfrac{x+3}2\;,\;$ I thought I can apply arctan to get rid of the integral form: $\dfrac1{24}\!\cdot\!\arctan\left(\dfrac{x+3}2\right)+c\;.$ But the correct answer is $\;\dfrac1{12}\!\cdot\!\arctan\left(\dfrac{x+3}2\right) + c\;,\;$ not $\;\dfrac1{24}\,.$ The answer also explained to use $\;\dfrac1{x^2 + k^2} = \left[\dfrac1k\!\cdot\!\arctan\left(\dfrac xk\right)\right]’$ (derivative), but I wonder why I cannot use the form of $\;\dfrac1{x^2 + 1}\;,\;$ which is the only equation I have known.","In the question that solves the integral , I first tried to solve it by changing the denominator in a form of to apply . Now, in order to make it in a form of I divide everything by : Then assume that I thought I can apply arctan to get rid of the integral form: But the correct answer is not The answer also explained to use (derivative), but I wonder why I cannot use the form of which is the only equation I have known.","\displaystyle\int\frac1{6x^2 + 36x + 78} \,\mathrm{d}x \dfrac1{x^2 + 1} \;\arctan(x) \dfrac1{6\!\cdot\!\left(x^2 + 6x + 13\right)}=\dfrac16\!\cdot\!\dfrac1{(x + 3)^2 + 2^2} \;\dfrac1{x^2 + 1}\;,\; \,2^2 =\dfrac16\!\cdot\!\dfrac1{\left(\frac{x+3}2\right)^2+1}\!\cdot\!\dfrac1{2^2}
=\dfrac1{24}\!\cdot\!\dfrac1{\left(\frac{x+3}2\right)^2+1} \;u=\dfrac{x+3}2\;,\; \dfrac1{24}\!\cdot\!\arctan\left(\dfrac{x+3}2\right)+c\;. \;\dfrac1{12}\!\cdot\!\arctan\left(\dfrac{x+3}2\right) + c\;,\; \;\dfrac1{24}\,. \;\dfrac1{x^2 + k^2} = \left[\dfrac1k\!\cdot\!\arctan\left(\dfrac xk\right)\right]’ \;\dfrac1{x^2 + 1}\;,\;","['integration', 'derivatives', 'trigonometry']"
39,Find the derivative of $y=\ln^3(3-x+x^2)$,Find the derivative of,y=\ln^3(3-x+x^2),"Find the derivative of $$y=\ln^3(3-x+x^2)$$ We have to use the chain rule, but I am not sure how to think about it when we have more complex functions as in this problem. We can rewrite the function as $$y=\left[\ln(3-x+x^2)\right]^3,$$ so the outermost function is $g(x)=x^3$ , right? And its derivative is $g'(x)=3x^2$ . Then we have $t(x)=\ln(3-x+x^2)$ and $t'(x)=\dfrac{1}{3-x+x^2}(3-x+x^2)^{'}$ and finally $v(x)=(3-x+x^2)$ with $v'(x)=2x-1$ . How do we use that in order to find $y'$ ? I would be grateful if you explained it in detail.","Find the derivative of We have to use the chain rule, but I am not sure how to think about it when we have more complex functions as in this problem. We can rewrite the function as so the outermost function is , right? And its derivative is . Then we have and and finally with . How do we use that in order to find ? I would be grateful if you explained it in detail.","y=\ln^3(3-x+x^2) y=\left[\ln(3-x+x^2)\right]^3, g(x)=x^3 g'(x)=3x^2 t(x)=\ln(3-x+x^2) t'(x)=\dfrac{1}{3-x+x^2}(3-x+x^2)^{'} v(x)=(3-x+x^2) v'(x)=2x-1 y'","['calculus', 'derivatives']"
40,Gradient of ${\bf x}^\top {\bf A}^{1/2} {\bf x}$ with respect to $\bf A$,Gradient of  with respect to,{\bf x}^\top {\bf A}^{1/2} {\bf x} \bf A,"How to calculate the gradient $\nabla_{\bf A} \left( {\bf x}^\top {\bf A}^{1/2} {\bf x} \right)$ , where $\bf x$ is $N \times 1$ column vector and $\bf A$ is $N \times N$ symmetric positive matrix? The difficulty is that there is ${\bf x}^\top {\bf A}^{1/2} {\bf x}$ rather than ${\bf x}^\top {\bf A} {\bf x}$ . Motivation I want to calculate the gradient of the vector Gaussian distribution $\mathcal{N} \left( \mathbf{y} \mid \mathbf{A}^{\frac{1}{2}}\mathbf{x}, \mathbf{I} \right)$ w.r.t. $\mathbf{A}$ , where $\mathbf{I}$ is an identity matrix, and $$ \mathcal{N} \left( \mathbf{y} \mid \mathbf{A}^{\frac{1}{2}},\mathbf{I} \right) = (2\pi)^{-\frac{N}{2}} \exp \left( -\left\|\mathbf{y}-\mathbf{A}^{\frac{1}{2}}\mathbf{x} \right\|_2^2 \right) $$ where $\|\cdot\|_2$ denotes the $\ell_2$ norm. Its difficulty is to calculate the term $$\nabla_{\mathbf{A}} \left( \mathbf{y}^T\mathbf{A}^{\frac{1}{2}}\mathbf{x} \right)$$ This term can be similarly solved by $\nabla_{\mathbf{A}}\left( \mathbf{x}^T\mathbf{A}^{\frac{1}{2}}\mathbf{x} \right)$ . And I believe this term exists.","How to calculate the gradient , where is column vector and is symmetric positive matrix? The difficulty is that there is rather than . Motivation I want to calculate the gradient of the vector Gaussian distribution w.r.t. , where is an identity matrix, and where denotes the norm. Its difficulty is to calculate the term This term can be similarly solved by . And I believe this term exists.","\nabla_{\bf A} \left( {\bf x}^\top {\bf A}^{1/2} {\bf x} \right) \bf x N \times 1 \bf A N \times N {\bf x}^\top {\bf A}^{1/2} {\bf x} {\bf x}^\top {\bf A} {\bf x} \mathcal{N} \left( \mathbf{y} \mid \mathbf{A}^{\frac{1}{2}}\mathbf{x}, \mathbf{I} \right) \mathbf{A} \mathbf{I}  \mathcal{N} \left( \mathbf{y} \mid \mathbf{A}^{\frac{1}{2}},\mathbf{I} \right) = (2\pi)^{-\frac{N}{2}} \exp \left( -\left\|\mathbf{y}-\mathbf{A}^{\frac{1}{2}}\mathbf{x} \right\|_2^2 \right)  \|\cdot\|_2 \ell_2 \nabla_{\mathbf{A}} \left( \mathbf{y}^T\mathbf{A}^{\frac{1}{2}}\mathbf{x} \right) \nabla_{\mathbf{A}}\left( \mathbf{x}^T\mathbf{A}^{\frac{1}{2}}\mathbf{x} \right)","['matrices', 'derivatives', 'normal-distribution', 'matrix-calculus', 'scalar-fields']"
41,Differentiability at the limit of non-differentiable points,Differentiability at the limit of non-differentiable points,,"Let $f : \mathbb{R} \to \mathbb{R}$ be a continuous function. Suppose there exists a sequence $(x_n)_{n \ge 1} \subseteq \mathbb{R}$ such that: there exists $x_\infty \in \mathbb{R}$ such that $x_n \to x_\infty$ as $n \to \infty$ $f$ is not differentiable at each point $x_n$ Do we know that $f$ cannot then be differentiable at $x_\infty$ ? I suspect it is impossible for $f$ to be differentiable at $x_\infty$ but I have not been able to prove this myself. I have tried approximating the Newton quotients at $x_\infty$ by those at $x_n$ , making use of continuity, but to no avail. I have also not found this result anywhere online. Hints towards the proof of this result or counter-examples would be greatly appreciated. Of course, after posting, I realized that this question may be stated more succinctly. For $f \in C(\mathbb{R})$ , is the set $$A := \{x \in \mathbb{R}\ |\ f'(x) \text{ does not exist}\}$$ closed?","Let be a continuous function. Suppose there exists a sequence such that: there exists such that as is not differentiable at each point Do we know that cannot then be differentiable at ? I suspect it is impossible for to be differentiable at but I have not been able to prove this myself. I have tried approximating the Newton quotients at by those at , making use of continuity, but to no avail. I have also not found this result anywhere online. Hints towards the proof of this result or counter-examples would be greatly appreciated. Of course, after posting, I realized that this question may be stated more succinctly. For , is the set closed?",f : \mathbb{R} \to \mathbb{R} (x_n)_{n \ge 1} \subseteq \mathbb{R} x_\infty \in \mathbb{R} x_n \to x_\infty n \to \infty f x_n f x_\infty f x_\infty x_\infty x_n f \in C(\mathbb{R}) A := \{x \in \mathbb{R}\ |\ f'(x) \text{ does not exist}\},"['real-analysis', 'calculus', 'derivatives', 'continuity']"
42,Prove $ (\tan(x))^{'} = \frac{1}{\cos^2(x)} $ [duplicate],Prove  [duplicate], (\tan(x))^{'} = \frac{1}{\cos^2(x)} ,"This question already has answers here : Proving $\frac{\mathrm d}{\mathrm dx}(\tan x)=\sec ^2x$ (3 answers) Closed 1 year ago . I want to prove $\displaystyle (\tan (x))'=\frac{1}{\cos^2(x)} $ using the definition of the derivative. So I started with the following: \begin{align*}\lim \limits _{h\to 0}\frac{\tan (x+h)-\tan (x)}{h} & =\lim \limits _{h\to 0}\frac{\sin (x+h-x)}{\cos (x+h)\cos (x)} \\ & =\lim \limits _{h\to 0}\frac{\sin (h)}{\cos (x+h)\cos (x)}. \end{align*} But the problem is that $\lim \limits _{h\to 0}\sin (h)=0\neq 1$ . Can you give me a hint on how to solve this? I know there are other identities for tan(x + h) - tan(x), but I want to solve this problem using the on I wrote in the solution.","This question already has answers here : Proving $\frac{\mathrm d}{\mathrm dx}(\tan x)=\sec ^2x$ (3 answers) Closed 1 year ago . I want to prove using the definition of the derivative. So I started with the following: But the problem is that . Can you give me a hint on how to solve this? I know there are other identities for tan(x + h) - tan(x), but I want to solve this problem using the on I wrote in the solution.","\displaystyle (\tan (x))'=\frac{1}{\cos^2(x)}  \begin{align*}\lim \limits _{h\to 0}\frac{\tan (x+h)-\tan (x)}{h} & =\lim \limits _{h\to 0}\frac{\sin (x+h-x)}{\cos (x+h)\cos (x)} \\
& =\lim \limits _{h\to 0}\frac{\sin (h)}{\cos (x+h)\cos (x)}.
\end{align*} \lim \limits _{h\to 0}\sin (h)=0\neq 1","['real-analysis', 'calculus', 'derivatives']"
43,Baby Rudin Theorem 5.5 (Chain rule): What's wrong with the obvious proof?,Baby Rudin Theorem 5.5 (Chain rule): What's wrong with the obvious proof?,,"In Theorem 5.5, Rudin proves the chain rule, but does so in a somewhat different fashion than expected. It seems we can prove the chain rule more easily. Theorem: Suppose $f:[a,b]\to\mathbb{R}$ is continuous  on $[a,b]$ and $g:I\to\mathbb{R}$ where $I$ is an interval that contains the range of $f$ and $g$ is continuous at $f(x)$ . Then if we define $h(t)=g(f(t))$ , $t\in[a,b]$ , then $h'(x)=g'(f(x))f'(x)$ . Proof: If we write down $g'(f(x))f'(x)$ , it looks like we're done if we can just express $g'$ in terms of the same limits as $f'$ , i.e., $\lim_{t\to x} g(f(t))=\lim_{y\to f(x)} g(y)$ . Showing this seems equivalent to Theorem 4.7, that $h$ is continuous at $x$ , but I'll write it for the sake of completeness: $\lim_{y\to f(x)}g(y)=g(f(x)),$ so $\forall \epsilon>0 \exists\delta>0$ st $\forall y\in I$ st $d(y,f(x))<\delta, d(g(y),g(f(x)))<\epsilon$ . Since $f$ is continuous at $x$ , $\exists \eta>0$ st $\forall t\in[a,b]$ st $d(t,x)<\eta,$ $d(f(t),f(x))<\delta$ ,which means $d(g(f(t)),g(f(x)))<\epsilon$ . So then $\lim_{t\to x} g(f(t)) = \lim_{y\to f(x)}g(y)$ . Then we have $g'(f(x))*f'(x) = \lim_{y\to f(x)}\frac{g(y)-g(f(x))}{y-f(x)}*\lim_{t\to x}\frac{f(t)-f(x)}{t-x}$ $=\lim_{t\to x}\frac{g(f(t))-g(f(x))}{f(t)-f(x)}*\lim_{t\to x}\frac{f(t)-f(x)}{t-x}$ $=\lim_{t\to x}\frac{g(f(t))-g(f(x))}{t-x} = h'(x)$ . Is there an issue to this approach I'm not seeing?","In Theorem 5.5, Rudin proves the chain rule, but does so in a somewhat different fashion than expected. It seems we can prove the chain rule more easily. Theorem: Suppose is continuous  on and where is an interval that contains the range of and is continuous at . Then if we define , , then . Proof: If we write down , it looks like we're done if we can just express in terms of the same limits as , i.e., . Showing this seems equivalent to Theorem 4.7, that is continuous at , but I'll write it for the sake of completeness: so st st . Since is continuous at , st st ,which means . So then . Then we have . Is there an issue to this approach I'm not seeing?","f:[a,b]\to\mathbb{R} [a,b] g:I\to\mathbb{R} I f g f(x) h(t)=g(f(t)) t\in[a,b] h'(x)=g'(f(x))f'(x) g'(f(x))f'(x) g' f' \lim_{t\to x} g(f(t))=\lim_{y\to f(x)} g(y) h x \lim_{y\to f(x)}g(y)=g(f(x)), \forall \epsilon>0 \exists\delta>0 \forall y\in I d(y,f(x))<\delta, d(g(y),g(f(x)))<\epsilon f x \exists \eta>0 \forall t\in[a,b] d(t,x)<\eta, d(f(t),f(x))<\delta d(g(f(t)),g(f(x)))<\epsilon \lim_{t\to x} g(f(t)) = \lim_{y\to f(x)}g(y) g'(f(x))*f'(x) = \lim_{y\to f(x)}\frac{g(y)-g(f(x))}{y-f(x)}*\lim_{t\to x}\frac{f(t)-f(x)}{t-x} =\lim_{t\to x}\frac{g(f(t))-g(f(x))}{f(t)-f(x)}*\lim_{t\to x}\frac{f(t)-f(x)}{t-x} =\lim_{t\to x}\frac{g(f(t))-g(f(x))}{t-x} = h'(x)","['real-analysis', 'calculus', 'derivatives']"
44,Representation of $n$-th derivative. [closed],Representation of -th derivative. [closed],n,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question The derivative of a function $y = f(x)$ with respect to $x$ is represented as $\frac{dy}{dx}$ The second derivative is represented as $\frac{d^2y}{dx^2}$ and so on. Why is it used like this?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question The derivative of a function with respect to is represented as The second derivative is represented as and so on. Why is it used like this?",y = f(x) x \frac{dy}{dx} \frac{d^2y}{dx^2},"['derivatives', 'notation']"
45,Finding the function for a sequence using differences,Finding the function for a sequence using differences,,"I am trying to find a function generating/suitable for the following sequence: ${2,6,12,20,30,42,56...}$ The first order differences are: $4, 6, 8, 10, 12, 14...$ and the second order differences are: $2, 2, 2, 2, 2, 2...$ this means that: $y''= 2 \implies y' = 2\cdot x + c$ and we can see that for $c = 2$ we can get the correct numbers i.e. the first order differences (replacing starting from $x = 1$ ). So $y' = 2\cdot x + 2$ This means that $y = x^2 + 2\cdot x + c$ But I can't find any value of $c$ that would give the original sequence. Now I see that $y'$ could also be $y' = 2\cdot x + 4$ as it gives the correct numbers if we replace starting from $x = 0$ but then we have $y = x^2 + 4\cdot x + c$ and I again can't find any $c$ that matches the original sequence. What am I doing wrong here?",I am trying to find a function generating/suitable for the following sequence: The first order differences are: and the second order differences are: this means that: and we can see that for we can get the correct numbers i.e. the first order differences (replacing starting from ). So This means that But I can't find any value of that would give the original sequence. Now I see that could also be as it gives the correct numbers if we replace starting from but then we have and I again can't find any that matches the original sequence. What am I doing wrong here?,"{2,6,12,20,30,42,56...} 4, 6, 8, 10, 12, 14... 2, 2, 2, 2, 2, 2... y''= 2 \implies y' = 2\cdot x + c c = 2 x = 1 y' = 2\cdot x + 2 y = x^2 + 2\cdot x + c c y' y' = 2\cdot x + 4 x = 0 y = x^2 + 4\cdot x + c c","['calculus', 'sequences-and-series', 'derivatives']"
46,"$\forall x\in \mathbb{R}, |f'(x)| \leqslant C |f(x)|$ implies $f=0$",implies,"\forall x\in \mathbb{R}, |f'(x)| \leqslant C |f(x)| f=0","Question Let $f\in \mathcal{C}^1$ a function such that $f(0)=0$ and $\forall x\in \mathbb{R}, |f'(x)| \leqslant C |f(x)|$ . Prove that $f=0$ My attempt If there exists $a$ such that $f(a)\neq 0$ , then in a neighborhood of $a$ we can write $-c \le \frac{f'}{f} \le c$ and we can integrate between $a$ and $x$ in this neighborhood : $-c(x-a) \le \ln(f(x)) - \ln(f(a)) \le c(x-a)$ so $\exp(-c(x-a)) \le \frac{f(x)}{f(a)} \le \exp(c(x-a)) (*)$ . Without loosing generality we can suppose $a>0$ . Let $b = \max \{ a > x \ge 0, f(x)=0\}$ (exists since $f(0)=0$ ). Then when $x\rightarrow b$ we get in $(*)$ : $\exp(-c(b-a)) \le 0$ . This is impossible. So we get the result. First I'm not sure of my proof. Then I think there might be other proofs, and surely easier ones. Could someone help ?","Question Let a function such that and . Prove that My attempt If there exists such that , then in a neighborhood of we can write and we can integrate between and in this neighborhood : so . Without loosing generality we can suppose . Let (exists since ). Then when we get in : . This is impossible. So we get the result. First I'm not sure of my proof. Then I think there might be other proofs, and surely easier ones. Could someone help ?","f\in \mathcal{C}^1 f(0)=0 \forall x\in \mathbb{R}, |f'(x)| \leqslant C |f(x)| f=0 a f(a)\neq 0 a -c \le \frac{f'}{f} \le c a x -c(x-a) \le \ln(f(x)) - \ln(f(a)) \le c(x-a) \exp(-c(x-a)) \le \frac{f(x)}{f(a)} \le \exp(c(x-a)) (*) a>0 b = \max \{ a > x \ge 0, f(x)=0\} f(0)=0 x\rightarrow b (*) \exp(-c(b-a)) \le 0","['real-analysis', 'integration', 'analysis', 'derivatives', 'roots']"
47,"Is there any closed form for the integral $\int_{0}^{\infty} \frac{\ln ^{n} x}{1+x^{2}} d x$, where $n\in \mathbb N?$","Is there any closed form for the integral , where",\int_{0}^{\infty} \frac{\ln ^{n} x}{1+x^{2}} d x n\in \mathbb N?,"Latest Edit Thanks to @Claude Leibovici and @Gary for giving us the closed form of the integral. Using MA , we have $$\frac{d^{ n}}{d{x}^{n}}\left(\sec x\right)= \sum_{k=0}^{\infty} \frac{(-1)^{k}}{(2 k-n) !} E_{2 k} x^{2 k-n} $$ $$ \begin{aligned} \int_{0}^{\infty} \frac{\ln ^{2 n} x}{1+x^{2}} d x=&\left.\frac{\pi}{2} \frac{\partial^{2 n}}{\partial{a}^{2 n}}\left(\sec \left(\frac{a \pi}{2}\right)\right)\right|_{a=0} \\ =&\left.\left(\frac{\pi}{2}\right)^{2 n+1} \sum_{k=0}^{\infty} \frac{(-1)^{k}}{(2 k-2 n) !} E_{2 k} \left(\frac{a\pi}{2} \right) ^{2 k-2 n}\right|_{a=0} \\ =&\left(\frac{\pi}{2}\right)^{2 n+1}(-1)^{n} E_{2 n} \\ =&\left(\frac{\pi}{2}\right)^{2 n+1}\left|E_{2 n}\right| \end{aligned} $$ where $E_{2 k}$ is an Euler number . For example, $$ \begin{aligned} \int_{0}^{\infty} \frac{\ln ^{20} x}{1+x^{2}} d x &=\frac{\pi^{21}}{2^{21}}|E _{10}| =\frac{370371188237525 \pi^{21}}{2097152}, \end{aligned} $$ checked by MA . Noting that $$ \begin{aligned} \int_{0}^{\infty} \frac{\ln^{2n-1}x}{1+x^2} d x &=\int_{0}^{\infty} \frac{\ln \left(\frac{1}{x}\right)}{1+\frac{1}{x^{2}}} \cdot \frac{d x}{x^{2}} =-\int_{0}^{\infty} \frac{\ln ^{2 n-1} x}{x^{2}+1} d x, \end{aligned} $$ we have $$ I_{2n-1}=\int_{0}^{\infty} \frac{\ln ^{2 n-1} x}{1+x^{2}} d x=0 $$ How about $$I_{2n}=\int_{0}^{\infty} \frac{\ln ^{2 n} x}{1+x^{2}} d x?$$ I like to switch the integration problem to a differentiation problem by defining a new integral. $$ J(a):=\int_{0}^{\infty} \frac{x^{a}}{1+x^{2}} d x $$ Then $$ I_{k}=J^{(k)}(0) $$ By my post $$\int_{0}^{\infty} \frac{x^{r}}{x^{m}+1} d x=\frac{\pi}{m} \csc \frac{(r+1) \pi}{m},$$ we have $$ J(a)=\frac{\pi}{2} \csc \frac{(a+1) \pi}{2}=\frac{\pi}{2} \sec \left(\frac{a \pi}{2}\right) $$ Then $$ \begin{aligned} \int_{0}^{\infty} \frac{\ln ^{2n} x}{1+x^{2}} d x &=\left.\int_{0}^{\infty} \frac{1}{1+x^{2}} \frac{\partial^{2n}}{\partial a^{2n}}\left(x^{a}\right) d x\right|_{a=0} \\ &=\boxed{\frac{\pi}{2} \frac{d^{2n}}{d a^{2n}}\left[\left.\sec \left(\frac{a \pi}{2}\right) \right]\right|_{a=0}} \end{aligned} $$ For examples, $$ \begin{aligned} I_{2}&=\left.\frac{\pi}{2} \cdot \frac{d^{2}}{d a^{2}} \sec \left(\frac{a \pi}{2}\right)\right|_{a=0}=\frac{\pi^{3}}{8} \\ I_{4}&=\left.\frac{\pi}{2} \cdot \frac{d^{4}}{d a^{4}} \sec \left(\frac{a \pi}{2}\right)\right|_{a=0}=\frac{5 \pi^{5}}{32}\\ &\qquad \vdots \end{aligned} $$ Alternative method (By reduction formula) Applying Leibniz’s Rule and differentiating the following equation w.r.t $a$ by $n$ times $$ J(a) \cos \frac{a \pi}{2}=\frac{\pi}{2} , $$ we have $$ \sum_{k=0}^{2 n}\left(\begin{array}{c} 2 n \\ k \end{array}\right) \left[\cos \left(\frac{a \pi}{2}\right)\right]^{(2 n-k)}  J^{(k)}(a)=0 $$ Putting $a=0$ yields $$ \sum_{k=0}^{2 n}\left(\begin{array}{c} 2 n \\ k \end{array}\right) \left(\frac{\pi}{2}\right)^{2 n-k}\cos \left(\frac{(2 n-k) \pi}{2}\right)I_{k}=0 $$ Since $I_{2k-1}=0,$ we have found a reduction formula relating $I_{2k}$ . $$ \boxed{\sum_{k=0}^{n}\left(\begin{array}{l} 2 n \\ 2 k \end{array}\right)\left(\frac{\pi^{2}}{4}\right)^{n-k} \cos (n-k) \pi I_{2 k}=0} $$ For example, $$ \begin{aligned} \left(\begin{array}{l} 4 \\ 0 \end{array}\right)\left(\frac{\pi^{2}}{4}\right)^{2} I_{0}+\left(\begin{array}{l} 4 \\ 2 \end{array}\right)\left(\frac{\pi^{2}}{4}\right)  I_{2}+\left(\begin{array}{l} 4 \\ 4 \end{array}\right) I_{4}=0 . \\ \frac{\pi^{4}}{16} \cdot \frac{\pi}{2}-6 \cdot \frac{\pi^{2}}{4}\left(\frac{\pi^{3}}{8}\right)+I_{4}=0 \\ I_{4}=-\frac{\pi^{5}}{32}+\frac{6 \pi^{5}}{3 \cdot 2}=\frac{5 \pi^{5}}{32} \end{aligned} $$ checked by WA . My Question Is there any formula for the $n^{th}$ derivative of $\sec x$ ? Your opinions and alternative solutions are highly appreciated.","Latest Edit Thanks to @Claude Leibovici and @Gary for giving us the closed form of the integral. Using MA , we have where is an Euler number . For example, checked by MA . Noting that we have How about I like to switch the integration problem to a differentiation problem by defining a new integral. Then By my post we have Then For examples, Alternative method (By reduction formula) Applying Leibniz’s Rule and differentiating the following equation w.r.t by times we have Putting yields Since we have found a reduction formula relating . For example, checked by WA . My Question Is there any formula for the derivative of ? Your opinions and alternative solutions are highly appreciated.","\frac{d^{ n}}{d{x}^{n}}\left(\sec x\right)= \sum_{k=0}^{\infty} \frac{(-1)^{k}}{(2 k-n) !} E_{2 k} x^{2 k-n}  
\begin{aligned}
\int_{0}^{\infty} \frac{\ln ^{2 n} x}{1+x^{2}} d x=&\left.\frac{\pi}{2} \frac{\partial^{2 n}}{\partial{a}^{2 n}}\left(\sec \left(\frac{a \pi}{2}\right)\right)\right|_{a=0} \\
=&\left.\left(\frac{\pi}{2}\right)^{2 n+1} \sum_{k=0}^{\infty} \frac{(-1)^{k}}{(2 k-2 n) !} E_{2 k} \left(\frac{a\pi}{2} \right) ^{2 k-2 n}\right|_{a=0} \\
=&\left(\frac{\pi}{2}\right)^{2 n+1}(-1)^{n} E_{2 n} \\
=&\left(\frac{\pi}{2}\right)^{2 n+1}\left|E_{2 n}\right|
\end{aligned}
 E_{2 k} 
\begin{aligned}
\int_{0}^{\infty} \frac{\ln ^{20} x}{1+x^{2}} d x &=\frac{\pi^{21}}{2^{21}}|E _{10}| =\frac{370371188237525 \pi^{21}}{2097152},
\end{aligned}
 
\begin{aligned}
\int_{0}^{\infty} \frac{\ln^{2n-1}x}{1+x^2} d x &=\int_{0}^{\infty} \frac{\ln \left(\frac{1}{x}\right)}{1+\frac{1}{x^{2}}} \cdot \frac{d x}{x^{2}} =-\int_{0}^{\infty} \frac{\ln ^{2 n-1} x}{x^{2}+1} d x,
\end{aligned}
 
I_{2n-1}=\int_{0}^{\infty} \frac{\ln ^{2 n-1} x}{1+x^{2}} d x=0
 I_{2n}=\int_{0}^{\infty} \frac{\ln ^{2 n} x}{1+x^{2}} d x? 
J(a):=\int_{0}^{\infty} \frac{x^{a}}{1+x^{2}} d x
 
I_{k}=J^{(k)}(0)
 \int_{0}^{\infty} \frac{x^{r}}{x^{m}+1} d x=\frac{\pi}{m} \csc \frac{(r+1) \pi}{m}, 
J(a)=\frac{\pi}{2} \csc \frac{(a+1) \pi}{2}=\frac{\pi}{2} \sec \left(\frac{a \pi}{2}\right)
 
\begin{aligned}
\int_{0}^{\infty} \frac{\ln ^{2n} x}{1+x^{2}} d x &=\left.\int_{0}^{\infty} \frac{1}{1+x^{2}} \frac{\partial^{2n}}{\partial a^{2n}}\left(x^{a}\right) d x\right|_{a=0} \\
&=\boxed{\frac{\pi}{2} \frac{d^{2n}}{d a^{2n}}\left[\left.\sec \left(\frac{a \pi}{2}\right) \right]\right|_{a=0}}
\end{aligned}
 
\begin{aligned}
I_{2}&=\left.\frac{\pi}{2} \cdot \frac{d^{2}}{d a^{2}} \sec \left(\frac{a \pi}{2}\right)\right|_{a=0}=\frac{\pi^{3}}{8} \\
I_{4}&=\left.\frac{\pi}{2} \cdot \frac{d^{4}}{d a^{4}} \sec \left(\frac{a \pi}{2}\right)\right|_{a=0}=\frac{5 \pi^{5}}{32}\\ &\qquad \vdots
\end{aligned}
 a n 
J(a) \cos \frac{a \pi}{2}=\frac{\pi}{2} ,
 
\sum_{k=0}^{2 n}\left(\begin{array}{c}
2 n \\
k
\end{array}\right) \left[\cos \left(\frac{a \pi}{2}\right)\right]^{(2 n-k)}  J^{(k)}(a)=0
 a=0 
\sum_{k=0}^{2 n}\left(\begin{array}{c}
2 n \\
k
\end{array}\right) \left(\frac{\pi}{2}\right)^{2 n-k}\cos \left(\frac{(2 n-k) \pi}{2}\right)I_{k}=0
 I_{2k-1}=0, I_{2k} 
\boxed{\sum_{k=0}^{n}\left(\begin{array}{l}
2 n \\
2 k
\end{array}\right)\left(\frac{\pi^{2}}{4}\right)^{n-k} \cos (n-k) \pi I_{2 k}=0}
 
\begin{aligned}
\left(\begin{array}{l}
4 \\
0
\end{array}\right)\left(\frac{\pi^{2}}{4}\right)^{2} I_{0}+\left(\begin{array}{l}
4 \\
2
\end{array}\right)\left(\frac{\pi^{2}}{4}\right)  I_{2}+\left(\begin{array}{l}
4 \\
4
\end{array}\right) I_{4}=0 . \\
\frac{\pi^{4}}{16} \cdot \frac{\pi}{2}-6 \cdot \frac{\pi^{2}}{4}\left(\frac{\pi^{3}}{8}\right)+I_{4}=0 \\
I_{4}=-\frac{\pi^{5}}{32}+\frac{6 \pi^{5}}{3 \cdot 2}=\frac{5 \pi^{5}}{32}
\end{aligned}
 n^{th} \sec x","['calculus', 'integration', 'derivatives']"
48,Proving a function has a local minimum,Proving a function has a local minimum,,"If $f(x)=2x^2+x^2\sin(1/x)$ for $x ≠ 0$ and $f(0)=0$ , how can I prove $f(x)$ has a local minumum when $x= 0$ and (Df)(0)=0? I'm thinking the first step is proving $(Df)(0)=0$ with $$\lim_{x\to 0}(Df)=\lim_{x\to 0}(4x+2x\sin(1/x)-\cos(1/x))=0$$ But here I get stuck because I can't say anything about what happens to $\cos(1/x)$ .","If for and , how can I prove has a local minumum when and (Df)(0)=0? I'm thinking the first step is proving with But here I get stuck because I can't say anything about what happens to .",f(x)=2x^2+x^2\sin(1/x) x ≠ 0 f(0)=0 f(x) x= 0 (Df)(0)=0 \lim_{x\to 0}(Df)=\lim_{x\to 0}(4x+2x\sin(1/x)-\cos(1/x))=0 \cos(1/x),"['calculus', 'derivatives', 'maxima-minima']"
49,Derivative of floor function using epsilon/delta,Derivative of floor function using epsilon/delta,,"For every $x\in\mathbb{R}$ , let $[x]$ denote the floor of $x$ . I read that the derivative of $[x]$ over non-integers is zero, and now I want to show it using epsilon/delta, i.e. show $$0=\lim_{x\rightarrow a}\frac{[x]-[a]}{x-a}$$ for all nonintegers $a$ . Let $\epsilon>0$ . There exists $\delta>0$ such that $0<|x-a|<\delta$ implies $|[x]-[a]|<\epsilon$ . If I can get $|x-a|>1$ , then we are done. But I am not able to make $|x-a|>1$ . So maybe going through this way is not right. In fact, if I can show that $$\frac{|[x]-[a]|}{|x-a|}\leq C$$ for some constant $C$ , I'll be done. What should be my delta?","For every , let denote the floor of . I read that the derivative of over non-integers is zero, and now I want to show it using epsilon/delta, i.e. show for all nonintegers . Let . There exists such that implies . If I can get , then we are done. But I am not able to make . So maybe going through this way is not right. In fact, if I can show that for some constant , I'll be done. What should be my delta?",x\in\mathbb{R} [x] x [x] 0=\lim_{x\rightarrow a}\frac{[x]-[a]}{x-a} a \epsilon>0 \delta>0 0<|x-a|<\delta |[x]-[a]|<\epsilon |x-a|>1 |x-a|>1 \frac{|[x]-[a]|}{|x-a|}\leq C C,"['real-analysis', 'derivatives', 'continuity', 'epsilon-delta', 'ceiling-and-floor-functions']"
50,"If $f(\frac{x}{y})=\frac{f(x)}{f(y)}$ for all $x,y \in \Bbb R$ , $y \neq 0$ and $f'(x)$ exist for all all $x$ , $f(2)=4$, Then $f(5)$ is?","If  for all  ,  and  exist for all all  , , Then  is?","f(\frac{x}{y})=\frac{f(x)}{f(y)} x,y \in \Bbb R y \neq 0 f'(x) x f(2)=4 f(5)","If $f\left(\frac{x}{y}\right)=\frac{f(x)}{f(y)}$ for all $x,y \in \Bbb R$ , $y \neq 0$ and $f'(x)$ exist for all $x$ , $f(2)=4$ ,  Then $f(5)$ is? I am solving this question using my teacher's method which is as follows My Approach: Differentiate with respect to $x$ assuming $y$ to be constant $f'\left(\frac{x}{y}\right) \cdot \frac{1}{y}=\frac{f'(x)}{f(y)}$ But i am not sure how to processed further using this method to get the result because i am not given any derivative. I know definition method to solve this question Here is the question which has been solved using direct differentiation Let $f:\mathbb{R \rightarrow R}$ satisfies $f(x)+f(y)= f \biggl(\frac{x+y}{1-xy}\biggl)$ and $f'(0)=5$. Then find $f(x)$ P.S.:- I've solved many question using direct differentiation method but I am not getting above question","If for all , and exist for all , ,  Then is? I am solving this question using my teacher's method which is as follows My Approach: Differentiate with respect to assuming to be constant But i am not sure how to processed further using this method to get the result because i am not given any derivative. I know definition method to solve this question Here is the question which has been solved using direct differentiation Let $f:\mathbb{R \rightarrow R}$ satisfies $f(x)+f(y)= f \biggl(\frac{x+y}{1-xy}\biggl)$ and $f'(0)=5$. Then find $f(x)$ P.S.:- I've solved many question using direct differentiation method but I am not getting above question","f\left(\frac{x}{y}\right)=\frac{f(x)}{f(y)} x,y \in \Bbb R y \neq 0 f'(x) x f(2)=4 f(5) x y f'\left(\frac{x}{y}\right) \cdot \frac{1}{y}=\frac{f'(x)}{f(y)}","['limits', 'derivatives']"
51,Is there an intuitive way to think about the product rule for derivatives?,Is there an intuitive way to think about the product rule for derivatives?,,"$\frac{d}{dx}(f(x)g(x)) = f'(x)g(x) + f(x)g'(x)$ Is there a reason why this makes sense? I mean really, if you break things down in terms of slopes of tangent lines and what not, there is a lot going on here. Is there some geometric intuition going on behind this that I've been blind to all of these years? Thanks in advance","Is there a reason why this makes sense? I mean really, if you break things down in terms of slopes of tangent lines and what not, there is a lot going on here. Is there some geometric intuition going on behind this that I've been blind to all of these years? Thanks in advance",\frac{d}{dx}(f(x)g(x)) = f'(x)g(x) + f(x)g'(x),['calculus']
52,Issue with getting the derivative of an integral,Issue with getting the derivative of an integral,,"I'm trying to find the derivative of the following integral: $\int_{\cos(x)}^{1} \sqrt{1-t^2} dt$ My steps are: $\frac{d}{dx} \left( \int_{\cos(x)}^{1} \sqrt{1-t^2} dt \right) = -\frac{d}{dx} \left( \int_{1}^{\cos(x)} \sqrt{1-t^2} dt \right) = -\sqrt{1-\cos^2(x)} \frac{d}{dx}\left( \cos(x) \right) = -\sqrt{1-\cos^2(x)} \cdot -\sin(x) = \sin^2(x) $ However, the book says the right answer is $ \lvert \sin(x) \rvert \sin(x) $ What am I missing here?","I'm trying to find the derivative of the following integral: My steps are: However, the book says the right answer is What am I missing here?",\int_{\cos(x)}^{1} \sqrt{1-t^2} dt \frac{d}{dx} \left( \int_{\cos(x)}^{1} \sqrt{1-t^2} dt \right) = -\frac{d}{dx} \left( \int_{1}^{\cos(x)} \sqrt{1-t^2} dt \right) = -\sqrt{1-\cos^2(x)} \frac{d}{dx}\left( \cos(x) \right) = -\sqrt{1-\cos^2(x)} \cdot -\sin(x) = \sin^2(x)   \lvert \sin(x) \rvert \sin(x) ,"['calculus', 'derivatives', 'trigonometry']"
53,Find the maximum and minimum of a multivariable function on a circle,Find the maximum and minimum of a multivariable function on a circle,,"This question is a continuation from a previous question I recently asked: Stationary points of a multivariable function I now have to find the maximum and minimum values of my function on the circle: $x^2 +y^2 = 4$ I'll repeat what I have so you don't have to keep checking back to my previous post: The function: $f(x,y) = (x^2+2y^2)e^{-x^2-y^2}$ The partial derivatives: $f_x = (-2x(x^2+2y^2)+2x)e^{-x^2-y^2}$ , $f_y=(-2y(x^2+2y^2)+4y)e^{-x^2-y^2}$ From here I set up my Lagrange equations (Since I know that that $\nabla f = \lambda \nabla g$ where $g$ is the function of the given circle): (I also know that $e^{-x^2-y^2}$ simply becomes $e^{-4}$ since $x^2 +y^2 =4$ ) $$(-2x(x^2+2y^2)+2x)e^{-4} = 2\lambda x \space (1)$$ $$(-2y(x^2+2y^2)+4y)e^{-4} = 2\lambda y \space (2)$$ $$x^2+y^2 = 4 \space (3)$$ From here I wasn't entirely sure what to do but I tried dividing both sides of $(1)$ by $2x$ to get: $-e^{-4}(x^2+2y^2)+e^{-4} = \lambda$ , and similarly divide both sides of $(2)$ by $2y$ to get: $-e^{-4}(x^2+2y^2)+2e^{-4} = \lambda$ So my new Lagrange equations would be: $$-e^{-4}(x^2+2y^2)+e^{-4} = \lambda \space (4)$$ $$-e^{-4}(x^2+2y^2)+2e^{-4} = \lambda \space (5)$$ $$x^2 +y^2 = 4 \space (3)$$ I'm not even sure if what I did is correct and even so I'm not sure where I would go from here, equating $(4)$ and $(5)$ wouldn't help (At least I don't think it will) and so I'm quite confused on where to go from here or where I've made a mistake. If anyone can guide me in the right direction or show me a better method it would really help, thanks in advance","This question is a continuation from a previous question I recently asked: Stationary points of a multivariable function I now have to find the maximum and minimum values of my function on the circle: I'll repeat what I have so you don't have to keep checking back to my previous post: The function: The partial derivatives: , From here I set up my Lagrange equations (Since I know that that where is the function of the given circle): (I also know that simply becomes since ) From here I wasn't entirely sure what to do but I tried dividing both sides of by to get: , and similarly divide both sides of by to get: So my new Lagrange equations would be: I'm not even sure if what I did is correct and even so I'm not sure where I would go from here, equating and wouldn't help (At least I don't think it will) and so I'm quite confused on where to go from here or where I've made a mistake. If anyone can guide me in the right direction or show me a better method it would really help, thanks in advance","x^2 +y^2 = 4 f(x,y) = (x^2+2y^2)e^{-x^2-y^2} f_x = (-2x(x^2+2y^2)+2x)e^{-x^2-y^2} f_y=(-2y(x^2+2y^2)+4y)e^{-x^2-y^2} \nabla f = \lambda \nabla g g e^{-x^2-y^2} e^{-4} x^2 +y^2 =4 (-2x(x^2+2y^2)+2x)e^{-4} = 2\lambda x \space (1) (-2y(x^2+2y^2)+4y)e^{-4} = 2\lambda y \space (2) x^2+y^2 = 4 \space (3) (1) 2x -e^{-4}(x^2+2y^2)+e^{-4} = \lambda (2) 2y -e^{-4}(x^2+2y^2)+2e^{-4} = \lambda -e^{-4}(x^2+2y^2)+e^{-4} = \lambda \space (4) -e^{-4}(x^2+2y^2)+2e^{-4} = \lambda \space (5) x^2 +y^2 = 4 \space (3) (4) (5)","['derivatives', 'systems-of-equations', 'maxima-minima', 'stationary-point']"
54,Problem based on mean value theorem and intermediate value theorem,Problem based on mean value theorem and intermediate value theorem,,"Let $f:[0,8]\rightarrow R$ be a differentiable function such that $f(0)=0, f(4)=1$ and $f(8)=1$ , then there exists some $c \in (0,8)$ where $f'(c)=1/12$ We need to ascertain whether it is always true? My approach using LMVT in [0,4] we can say there exists $c_1 \in (0,4)$ such that $f'(c_1)=\frac{1}{4}$ and using LMVT in [4,8] we can say there exists $c_2 \in (4,8)$ such that $f'(c_2)=0.$ Since $\frac{1}{12} \in (0,\frac{1}{4})$ using IVT we can say the statement is true. However, in the book answer is given statement is not always true. Please verify.","Let be a differentiable function such that and , then there exists some where We need to ascertain whether it is always true? My approach using LMVT in [0,4] we can say there exists such that and using LMVT in [4,8] we can say there exists such that Since using IVT we can say the statement is true. However, in the book answer is given statement is not always true. Please verify.","f:[0,8]\rightarrow R f(0)=0, f(4)=1 f(8)=1 c \in (0,8) f'(c)=1/12 c_1 \in (0,4) f'(c_1)=\frac{1}{4} c_2 \in (4,8) f'(c_2)=0. \frac{1}{12} \in (0,\frac{1}{4})","['calculus', 'derivatives']"
55,What functions satisfy $D^* f = Df$?,What functions satisfy ?,D^* f = Df,I came across one exercise that I found pretty interesting. The problem gave us a new definition of derivate $D^*f(x) = \lim_{h \to 0} \frac{f^2(x + h) - f^2(x)}{h}$ . It asks us for what functions does $D^*f = Df$ . I know that $D^*f = 2fDf$ but I am not sure what functions satisfies $D^*f = Df$ except constant functions. Any idea for other non-trivial possibilities?,I came across one exercise that I found pretty interesting. The problem gave us a new definition of derivate . It asks us for what functions does . I know that but I am not sure what functions satisfies except constant functions. Any idea for other non-trivial possibilities?,D^*f(x) = \lim_{h \to 0} \frac{f^2(x + h) - f^2(x)}{h} D^*f = Df D^*f = 2fDf D^*f = Df,['derivatives']
56,If $P(x)$ be a real polynomial such that $\lvert P(x)\rvert$ is also a polynomial then what can we conclude about $P(x)$?,If  be a real polynomial such that  is also a polynomial then what can we conclude about ?,P(x) \lvert P(x)\rvert P(x),"My thinking is this:- If it is a constant polynomial then it is trivial. If it has degree $\geq 1$ . Then the polynomial must be differentiable. Now for it to be differentiable it should lie totally on the upper half of the $xy-$ plane or the lower half . Well it can have roots,but we will consider to lie on the upper half or lower half regardless. Considering geometrically, if the curve had a portion in the lower half and a portion on the upper half...then the function $\lvert P(x)\rvert$ would become non-differentiable at the root on account of it having ""sharp edges"" there. Is my thinking correct? Did I miss anything? Can I conclude anything else?. Any help is appreciated.","My thinking is this:- If it is a constant polynomial then it is trivial. If it has degree . Then the polynomial must be differentiable. Now for it to be differentiable it should lie totally on the upper half of the plane or the lower half . Well it can have roots,but we will consider to lie on the upper half or lower half regardless. Considering geometrically, if the curve had a portion in the lower half and a portion on the upper half...then the function would become non-differentiable at the root on account of it having ""sharp edges"" there. Is my thinking correct? Did I miss anything? Can I conclude anything else?. Any help is appreciated.",\geq 1 xy- \lvert P(x)\rvert,"['real-analysis', 'derivatives', 'polynomials']"
57,How to evaluate $\frac{\partial}{\partial x}\Gamma(f(x))$?,How to evaluate ?,\frac{\partial}{\partial x}\Gamma(f(x)),"If my math is correct: $$\Gamma(f(x))=\displaystyle \int_0^\infty e^{-t}t^{f(x)-1}dt$$ $$\frac{\partial}{\partial x}\Gamma(f(x))=\displaystyle \int_0^\infty e^{-t}f^\prime (x)\textrm{ln}(t)t^{f(x)-1}dt$$ $$=f^\prime (x)\displaystyle \int_0^\infty e^{-t}\textrm{ln}(t)t^{f(x)-1}dt$$ But here I get stuck. The integral is tantalizingly close to the definition of $\Gamma(f(x))$ , except for the $\textrm{ln}(t)$ term. I've tried integration by parts to resolve the integral but no luck so far. I'm hoping to find a formula for $\frac{\partial}{\partial x}\Gamma(f(x))$ that can be expressed from the terms: $\Gamma(f(x))$ , $\Gamma^\prime(x)$ , or $\Gamma(x)$ and therefore can be calculated in the R program I'm running.","If my math is correct: But here I get stuck. The integral is tantalizingly close to the definition of , except for the term. I've tried integration by parts to resolve the integral but no luck so far. I'm hoping to find a formula for that can be expressed from the terms: , , or and therefore can be calculated in the R program I'm running.",\Gamma(f(x))=\displaystyle \int_0^\infty e^{-t}t^{f(x)-1}dt \frac{\partial}{\partial x}\Gamma(f(x))=\displaystyle \int_0^\infty e^{-t}f^\prime (x)\textrm{ln}(t)t^{f(x)-1}dt =f^\prime (x)\displaystyle \int_0^\infty e^{-t}\textrm{ln}(t)t^{f(x)-1}dt \Gamma(f(x)) \textrm{ln}(t) \frac{\partial}{\partial x}\Gamma(f(x)) \Gamma(f(x)) \Gamma^\prime(x) \Gamma(x),"['integration', 'derivatives', 'gamma-function']"
58,Systematic procedure for calculating derivatives involving Dirac delta terms,Systematic procedure for calculating derivatives involving Dirac delta terms,,"As we know , $\nabla \cdot (\hat{r}/r^2) = 4\pi \delta^3(\vec{r})$ . This particular instance is easily justified by appealing to the divergence theorem, but there are also more complicated examples such as this one . My question is actually inspired by a post over at physics SE ( link ) where it seems that a delta function term has been left unaccounted for somehow, but I'm not sure where. In general, derivatives are easy to calculate systematically using the chain rule, product rule, etc. but it seems that when the result contains Dirac delta terms, some ad hoc method is used to derive them. Is there a systematic way to do it?","As we know , . This particular instance is easily justified by appealing to the divergence theorem, but there are also more complicated examples such as this one . My question is actually inspired by a post over at physics SE ( link ) where it seems that a delta function term has been left unaccounted for somehow, but I'm not sure where. In general, derivatives are easy to calculate systematically using the chain rule, product rule, etc. but it seems that when the result contains Dirac delta terms, some ad hoc method is used to derive them. Is there a systematic way to do it?",\nabla \cdot (\hat{r}/r^2) = 4\pi \delta^3(\vec{r}),"['derivatives', 'dirac-delta']"
59,Use Implicit Differentiation to find $\frac{d^2y}{dx^2}$?,Use Implicit Differentiation to find ?,\frac{d^2y}{dx^2},"Given a system of equation, \begin{align*} x &= t^2 + 2t \\ y &= 3t^4 + 4t^3 \end{align*} I want to find $\frac{d^2 y}{dx^2}$ at $(x,y) = (8, 80)$ . Then, $\partial_x(y) = \frac{d y}{dt} \frac{dt}{dx}$ . By chain rule, \begin{align*} \partial_x^2(y) &= \partial_x \left(\frac{d y}{dt}\right)\frac{dt}{dx} + \frac{dy}{dt} \partial_x \left(\frac{dt}{dx}\right) \\ &= \frac{d^2 y}{dt^2}\left(\frac{dt}{dx}\right)^2 + \frac{dy}{dt}\frac{d^2t}{dx^2} \end{align*} Here, how do I find $\frac{d^2 t}{dx^2}$ ?","Given a system of equation, I want to find at . Then, . By chain rule, Here, how do I find ?","\begin{align*}
x &= t^2 + 2t \\
y &= 3t^4 + 4t^3
\end{align*} \frac{d^2 y}{dx^2} (x,y) = (8, 80) \partial_x(y) = \frac{d y}{dt} \frac{dt}{dx} \begin{align*}
\partial_x^2(y) &= \partial_x \left(\frac{d y}{dt}\right)\frac{dt}{dx} + \frac{dy}{dt} \partial_x \left(\frac{dt}{dx}\right) \\
&= \frac{d^2 y}{dt^2}\left(\frac{dt}{dx}\right)^2 + \frac{dy}{dt}\frac{d^2t}{dx^2}
\end{align*} \frac{d^2 t}{dx^2}","['calculus', 'derivatives', 'implicit-differentiation']"
60,What does the notation $f^*(x)$ mean?,What does the notation  mean?,f^*(x),I'm doing an assignment for my calculus course. I don't need help with the question. But I've never come across that notation $f^*(x)\;.\;$ See the following picture : I can't find anything in my book about it. Is it just an arbitrary use of a symbol ?,I'm doing an assignment for my calculus course. I don't need help with the question. But I've never come across that notation See the following picture : I can't find anything in my book about it. Is it just an arbitrary use of a symbol ?,f^*(x)\;.\;,"['calculus', 'derivatives', 'notation']"
61,Infinite fraction's derivative [closed],Infinite fraction's derivative [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question $f(x)=x+\dfrac{1}{x+\dfrac{1}{x+\dfrac{1}{x+\ldots}}}$ $f'\left(\dfrac{3}{2}\right)=?$ I tried to make equation like $y^2=xy+1$ but I can't made it clearly.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I tried to make equation like but I can't made it clearly.",f(x)=x+\dfrac{1}{x+\dfrac{1}{x+\dfrac{1}{x+\ldots}}} f'\left(\dfrac{3}{2}\right)=? y^2=xy+1,"['calculus', 'derivatives', 'continued-fractions']"
62,If x =-1 for the derivative of ln(x)=1/x does that imply that ln(-1) = -1?,If x =-1 for the derivative of ln(x)=1/x does that imply that ln(-1) = -1?,,"I wanted to find the solution of x for y=ln(x)-1/x=0 and my first intuition was to rearrange the equation to ln(x)=1/x and find the first derivative of the equation which gave me 1/x=-x^-2. I rearranged this equation to get x and it got me to x=-1. this made me ask if x=-1, does that imply that ln(-1)=-1? I understand that there are other ways to find x which is true for the equation. but I don't understand why this doesn't work and why ln(-1) is not equal to -1 even when x=-1. Does anybody have any ideas as to why this is?","I wanted to find the solution of x for y=ln(x)-1/x=0 and my first intuition was to rearrange the equation to ln(x)=1/x and find the first derivative of the equation which gave me 1/x=-x^-2. I rearranged this equation to get x and it got me to x=-1. this made me ask if x=-1, does that imply that ln(-1)=-1? I understand that there are other ways to find x which is true for the equation. but I don't understand why this doesn't work and why ln(-1) is not equal to -1 even when x=-1. Does anybody have any ideas as to why this is?",,"['calculus', 'derivatives', 'logarithms']"
63,Differentiate $x^{a^x}$ without logarithmic differentiation?,Differentiate  without logarithmic differentiation?,x^{a^x},"Problem. Compute $\frac{d}{dx} x^{a^x}$ . Method 1: Logarithmic Differentiation (Correct): \begin{align*} y&= x^{a^x} \\ \ln(y)&=a^x \cdot \ln(x) \\ \frac{1}{y} \frac{dy}{dx} &=a^x \frac{1}{x} + \ln(x) \ln(a) a^x \\ \frac{dy}{dx} &= y\left(\frac{1}{x} a^x + \ln(a) \ln(x) a^x\right) \\ \frac{dy}{dx} &= x^{a^x}\left(\frac{1}{x} a^x + \ln(a) \ln(x) a^x\right) \\ \frac{dy}{dx} &= a^x x^{a^x}\left(\frac{1}{x} + \ln(a) \ln(x)\right) \\ \frac{dy}{dx} &= a^x x^{a^x-1}\left(1 + x\ln(a) \ln(x) \right) \\ \end{align*} Method 2: Chain Rule (Incorrect): \begin{align*} y&= x^{a^x} \\ \frac{dy}{dx} &= a^x x^{a^x-1} \cdot \left[\ln(a) \cdot a^x\right] \end{align*} Method 2 is incorrect because it $x^{a^x}$ is not a power function, so we cannot apply power rule (thanks @Alann_Rosas and @Parcly_Taxel). My Question: Can Ninad Munshi's answer here be adopted to correct method 2 without the use of logarithmic differentiation? What is the name (and/or proof) of this generalized version of chain rule? Thank you!","Problem. Compute . Method 1: Logarithmic Differentiation (Correct): Method 2: Chain Rule (Incorrect): Method 2 is incorrect because it is not a power function, so we cannot apply power rule (thanks @Alann_Rosas and @Parcly_Taxel). My Question: Can Ninad Munshi's answer here be adopted to correct method 2 without the use of logarithmic differentiation? What is the name (and/or proof) of this generalized version of chain rule? Thank you!","\frac{d}{dx} x^{a^x} \begin{align*}
y&= x^{a^x} \\
\ln(y)&=a^x \cdot \ln(x) \\
\frac{1}{y} \frac{dy}{dx} &=a^x \frac{1}{x} + \ln(x) \ln(a) a^x \\
\frac{dy}{dx} &= y\left(\frac{1}{x} a^x + \ln(a) \ln(x) a^x\right) \\
\frac{dy}{dx} &= x^{a^x}\left(\frac{1}{x} a^x + \ln(a) \ln(x) a^x\right) \\
\frac{dy}{dx} &= a^x x^{a^x}\left(\frac{1}{x} + \ln(a) \ln(x)\right) \\
\frac{dy}{dx} &= a^x x^{a^x-1}\left(1 + x\ln(a) \ln(x) \right) \\
\end{align*} \begin{align*}
y&= x^{a^x} \\
\frac{dy}{dx} &= a^x x^{a^x-1} \cdot \left[\ln(a) \cdot a^x\right]
\end{align*} x^{a^x}","['calculus', 'derivatives', 'logarithms', 'exponential-function', 'chain-rule']"
64,Proving differentiability and calculating the differential of $A \mapsto A^2$ [closed],Proving differentiability and calculating the differential of  [closed],A \mapsto A^2,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let $$\begin{aligned} f : M_n(\Bbb R) &\to M_n(\Bbb R)\\ A  &\mapsto A^2 \end{aligned}$$ Prove that $f$ is differentiable and calculate its differential. Any hints on how to prove that? I don't think $f$ is linear so any theorems I can use?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let Prove that is differentiable and calculate its differential. Any hints on how to prove that? I don't think is linear so any theorems I can use?",\begin{aligned} f : M_n(\Bbb R) &\to M_n(\Bbb R)\\ A  &\mapsto A^2 \end{aligned} f f,"['matrices', 'derivatives', 'matrix-calculus']"
65,Why doesn't $f(x) = x^2$ generate a counter-example to $f(-x) = -f'(x)$?,Why doesn't  generate a counter-example to ?,f(x) = x^2 f(-x) = -f'(x),"According to the chain rule, the derivative of $f(-x) = -f'(x)$ , since $$ \frac{d}{dx}(f(-x)) = \frac{df(u)}{du} \frac{du}{dx} = f'(-x)*-1 = -f'(-x) $$ where $u = -x$ .  But doesn't the case of $f(x) = (x)^2$ generate a counter-example to this? $$ f'(-x) = \frac{d}{dx}(-x)^2 = \frac{d}{dx}x^2 = 2x \ne -(2x) = -f'(-x) $$","According to the chain rule, the derivative of , since where .  But doesn't the case of generate a counter-example to this?","f(-x) = -f'(x) 
\frac{d}{dx}(f(-x)) = \frac{df(u)}{du} \frac{du}{dx} = f'(-x)*-1 = -f'(-x)
 u = -x f(x) = (x)^2 
f'(-x) = \frac{d}{dx}(-x)^2 = \frac{d}{dx}x^2 = 2x \ne -(2x) = -f'(-x)
","['derivatives', 'chain-rule']"
66,Change from differentiation wrt to matrix to wrt to inverse of matrix for symmetric matrices,Change from differentiation wrt to matrix to wrt to inverse of matrix for symmetric matrices,,"For the rule below: $$ \frac{\partial J}{\partial \mathbf{A}}= -\mathbf{A}^{-T} \frac{\partial J}{\partial \mathbf{W}} \mathbf{A}^{-T}  $$ where $\mathbf{A}$ is an invertible square matrix, $\mathbf{W}$ is the inverse of $\mathbf{A}$ , and J is a function (see end of section 2.2 in matrix cookbook https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf ) Does this rule hold if $\mathbf{A}$ is a symmetric matrix?","For the rule below: where is an invertible square matrix, is the inverse of , and J is a function (see end of section 2.2 in matrix cookbook https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf ) Does this rule hold if is a symmetric matrix?","
\frac{\partial J}{\partial \mathbf{A}}= -\mathbf{A}^{-T} \frac{\partial J}{\partial \mathbf{W}} \mathbf{A}^{-T} 
 \mathbf{A} \mathbf{W} \mathbf{A} \mathbf{A}","['derivatives', 'matrix-calculus', 'symmetric-matrices']"
67,"prove that $3x - x^3 < 2 \cdot \sin(\pi/2 \cdot x)$ $\forall x \in (0, 1)$",prove that,"3x - x^3 < 2 \cdot \sin(\pi/2 \cdot x) \forall x \in (0, 1)","I faced problems of such kind before and usually I would just chech that on the ends of segment values of compared functions are equal and then find their derivatives and make sure that derivative of one function is always greater on some interval or segment. However, in this case it just didn't work. I found derivative but on some interval $A \subset (0, 1)$ one is greater than the other and on another interval $B \subset (0, 1)$ everything is vice versa. Do you have any other meaningful approaches to this problem?","I faced problems of such kind before and usually I would just chech that on the ends of segment values of compared functions are equal and then find their derivatives and make sure that derivative of one function is always greater on some interval or segment. However, in this case it just didn't work. I found derivative but on some interval one is greater than the other and on another interval everything is vice versa. Do you have any other meaningful approaches to this problem?","A \subset (0, 1) B \subset (0, 1)","['calculus', 'derivatives', 'inequality']"
68,Why does replacing dx and dy with finite values yield this result?,Why does replacing dx and dy with finite values yield this result?,,"Consider the change in the function $f(x)=x^2$ at $x=1$ when $x$ is changed by some value $\Delta x$ . $$ \Delta y = f(x+\Delta x)-f(x)\\ \to \Delta y = (1+\Delta x)^2-1^2 $$ Let's set this value $\Delta x$ to $0.1$ . Then $$ \Delta y = (1+0.1)^2-1^2=0.21 $$ Now let's consider this change in the function utilizing its derivative. $$ \frac{dy}{dx}=2x\\ dy=2x(dx) $$ Let's replace the infinitesimal differences $dx$ and $dy$ with a finite difference (is this valid?). $$ \Delta y = 2x(\Delta x) $$ Again, let's set $\Delta x$ to 0.1. $$ \Delta y = 2x(0.1)\\ \to\Delta y=2(1)(0.1) = 0.2 $$ Why does $\Delta y$ end up being different than it was previously? I would think that since we're replacing $dx$ with a finite difference, $dy$ would be the same as $\Delta y$ in #1. There must be a flaw in my thinking somewhere. Edit: Thanks for the answers. Here's the justification I worked out. $$ \frac{\Delta y}{\Delta x} = \frac{(x + \Delta x)^2 - x^2}{\Delta x}\\ \frac{\Delta y}{\Delta x}=\frac{x^2+2x\Delta x + (\Delta x)^2 - x^2}{\Delta x}\\ \frac{\Delta y}{\Delta x}= 2x+\Delta x\\ \to\Delta y = \Delta x(2x + \Delta x)\\ $$ As $\frac{\Delta y}{\Delta x}$ approximates $\frac{dy}{dx}$ with smaller and smaller values of $\Delta x$ , a remainder term is always present. Since $x^2$ is exponential, $\Delta y$ must be greater than multiplying the current growth rate, $f'(x)$ by $\Delta x$ . Using 0.1 for $\Delta x$ gives us $$ \Delta y = 0.1(2(1) + 0.1) = 0.21  $$ the same value calculated in #1.","Consider the change in the function at when is changed by some value . Let's set this value to . Then Now let's consider this change in the function utilizing its derivative. Let's replace the infinitesimal differences and with a finite difference (is this valid?). Again, let's set to 0.1. Why does end up being different than it was previously? I would think that since we're replacing with a finite difference, would be the same as in #1. There must be a flaw in my thinking somewhere. Edit: Thanks for the answers. Here's the justification I worked out. As approximates with smaller and smaller values of , a remainder term is always present. Since is exponential, must be greater than multiplying the current growth rate, by . Using 0.1 for gives us the same value calculated in #1.","f(x)=x^2 x=1 x \Delta x 
\Delta y = f(x+\Delta x)-f(x)\\
\to \Delta y = (1+\Delta x)^2-1^2
 \Delta x 0.1 
\Delta y = (1+0.1)^2-1^2=0.21
 
\frac{dy}{dx}=2x\\
dy=2x(dx)
 dx dy 
\Delta y = 2x(\Delta x)
 \Delta x 
\Delta y = 2x(0.1)\\
\to\Delta y=2(1)(0.1) = 0.2
 \Delta y dx dy \Delta y 
\frac{\Delta y}{\Delta x} = \frac{(x + \Delta x)^2 - x^2}{\Delta x}\\
\frac{\Delta y}{\Delta x}=\frac{x^2+2x\Delta x + (\Delta x)^2 - x^2}{\Delta x}\\
\frac{\Delta y}{\Delta x}= 2x+\Delta x\\
\to\Delta y = \Delta x(2x + \Delta x)\\
 \frac{\Delta y}{\Delta x} \frac{dy}{dx} \Delta x x^2 \Delta y f'(x) \Delta x \Delta x 
\Delta y = 0.1(2(1) + 0.1) = 0.21 
","['calculus', 'derivatives']"
69,Moving exterior differential/derivative inside a wedge product,Moving exterior differential/derivative inside a wedge product,,"Assumptions : Let $M$ be smooth $m$ -manifold. (If needed: Let $M$ be orientable and then oriented. Let $M$ be compact. Let $(M,g)$ be a Riemannian manifold.) Let $\Omega^jM$ be the set of smooth $k$ -forms on $M$ , for $j=0, 1, ..., m$ . Let $d_j: \Omega^jM \to \Omega^{j+1}M$ be exterior differential / derivative on $\Omega^jM$ (based on $d: \Omega(M) \to \Omega(M)$ , with $\Omega(M)$ $:= \bigoplus_{j=0}^{m} \Omega^jM$ ). Let $k \in \{0, 1, ..., m\}$ . Let $(\alpha, \gamma) \in \Omega^kM \times \Omega^{m-(k+1)}M$ . Observations : $d_k \alpha \wedge \gamma$ is a smooth top form (aka smooth $m$ -form) $(-1)^{1+k^2} \alpha \wedge d_{m-(k+1)}\gamma$ is a smooth top form (aka smooth $m$ -form) Question 1 : Assuming the above observations are correct, are they equal? Question 2 : In general, can we just move exterior differential/derivative through wedge products and just multiply $(-1)^{\text{something}}$ ? Question 3 : In anything above, are we assuming any additional things on $M$ like orientable/oriented/compact/Riemannian? Question 4 : If no to question 1, then do each of the 2 forms at least have equal integrals, i.e. the values we get when we plug each into $\int_M$ are equal? Here, we now suppose $M$ is orientable and then oriented and I guess compact (otherwise I guess we have to assume the forms have compact support or something). Context : This comes from some definitions and propositions leading to Hodge decomposition theorem, including the definition of Hodge star operator, but I'm trying to see if I understand the non-Hodge parts correctly. ( $\gamma$ is actually the image of some $\beta \in \Omega^{k+1}M$ under the Hodge-star operator.)","Assumptions : Let be smooth -manifold. (If needed: Let be orientable and then oriented. Let be compact. Let be a Riemannian manifold.) Let be the set of smooth -forms on , for . Let be exterior differential / derivative on (based on , with ). Let . Let . Observations : is a smooth top form (aka smooth -form) is a smooth top form (aka smooth -form) Question 1 : Assuming the above observations are correct, are they equal? Question 2 : In general, can we just move exterior differential/derivative through wedge products and just multiply ? Question 3 : In anything above, are we assuming any additional things on like orientable/oriented/compact/Riemannian? Question 4 : If no to question 1, then do each of the 2 forms at least have equal integrals, i.e. the values we get when we plug each into are equal? Here, we now suppose is orientable and then oriented and I guess compact (otherwise I guess we have to assume the forms have compact support or something). Context : This comes from some definitions and propositions leading to Hodge decomposition theorem, including the definition of Hodge star operator, but I'm trying to see if I understand the non-Hodge parts correctly. ( is actually the image of some under the Hodge-star operator.)","M m M M (M,g) \Omega^jM k M j=0, 1, ..., m d_j: \Omega^jM \to \Omega^{j+1}M \Omega^jM d: \Omega(M) \to \Omega(M) \Omega(M) := \bigoplus_{j=0}^{m} \Omega^jM k \in \{0, 1, ..., m\} (\alpha, \gamma) \in \Omega^kM \times \Omega^{m-(k+1)}M d_k \alpha \wedge \gamma m (-1)^{1+k^2} \alpha \wedge d_{m-(k+1)}\gamma m (-1)^{\text{something}} M \int_M M \gamma \beta \in \Omega^{k+1}M","['derivatives', 'differential-geometry', 'riemannian-geometry', 'differential-forms', 'exterior-algebra']"
70,Why is $\frac{d}{dt}[\frac{1}{y}] = \frac{d}{dt}[\cos{x}]$ result in an application of the chain rule in related functions?,Why is  result in an application of the chain rule in related functions?,\frac{d}{dt}[\frac{1}{y}] = \frac{d}{dt}[\cos{x}],"Why does the below step result in a chain rule? Intuitively, I would just differentiate it against y and x resulting in $-y^{-2} = -\sin{x}$ . Khan Acad mentioned something about relating y = y(t) and x = x(t), but my brain is struggling to comprehend why it can just be related like this... (Though I could just be getting it completely wrong)","Why does the below step result in a chain rule? Intuitively, I would just differentiate it against y and x resulting in . Khan Acad mentioned something about relating y = y(t) and x = x(t), but my brain is struggling to comprehend why it can just be related like this... (Though I could just be getting it completely wrong)",-y^{-2} = -\sin{x},"['calculus', 'derivatives', 'related-rates']"
71,How to take the derivative of the following expression,How to take the derivative of the following expression,,"I am taking macro course this Fall and my calculus is quite rusty. So in the lecture notes they derive the following: $$ \begin{split} MPL&=\frac{dY}{dL}\\&=\frac{d(ALf(k))}{dL}\\&=Af(k)+ALf′(k)(−K)/(L^2A)\\&=A(f(k)−kf′(k))\\&=w \end{split} $$ Specifically, I don't quite understand how they got $Af(k) + ALf'(k) (-K)/(L^2A)$ from $d(ALf(k))/dL?$ Let me also clarify that k = K/AL Honestly, I am stuck at this point and guess will be doing a lot of differentiation like this during the entire course. Would really appreciate if someone could clarify the differentiation part.","I am taking macro course this Fall and my calculus is quite rusty. So in the lecture notes they derive the following: Specifically, I don't quite understand how they got from Let me also clarify that k = K/AL Honestly, I am stuck at this point and guess will be doing a lot of differentiation like this during the entire course. Would really appreciate if someone could clarify the differentiation part.","
\begin{split}
MPL&=\frac{dY}{dL}\\&=\frac{d(ALf(k))}{dL}\\&=Af(k)+ALf′(k)(−K)/(L^2A)\\&=A(f(k)−kf′(k))\\&=w
\end{split}
 Af(k) + ALf'(k) (-K)/(L^2A) d(ALf(k))/dL?",['derivatives']
72,Simplifying the derivative of $\sin(\cos^2 x)\cos(\sin^2 x)$,Simplifying the derivative of,\sin(\cos^2 x)\cos(\sin^2 x),"Differentiating the term $$\sin(\cos^2 x)\cos(\sin^2 x)$$ leads me through the chain and product rule to $$-\sin(2x)\cos(\cos^2 x)\cos(\sin^2 x)+(-\sin(\sin^2 x)\sin(2x)\sin(\cos^2 x))$$ where the derivative of $\sin^2 x$ equals to $$\frac{d}{dx} \sin^2 x = 2\sin x \frac{d}{dx} \sin x = 2\sin x \cos x = \sin 2x$$ and $\frac{d}{dx} cos^2 x$ to $-\sin 2x$ respectively. Through factorization, I can then simplify the term to $$-\sin 2x\ (\cos(\cos^2 x)\cos(\sin^2 x) + \sin(\sin^2 x)\sin(\cos^2 x))$$ The problem starts here where I fail to find a simplification for the second factor which, according to Wolfram Mathematica, should lead to $\cos(\cos 2x)$ and ultimately to $$-\sin(2x)\cos(\cos 2x)$$ How and which trigonometric identities could I apply to get to that? Is my approach right?","Differentiating the term leads me through the chain and product rule to where the derivative of equals to and to respectively. Through factorization, I can then simplify the term to The problem starts here where I fail to find a simplification for the second factor which, according to Wolfram Mathematica, should lead to and ultimately to How and which trigonometric identities could I apply to get to that? Is my approach right?",\sin(\cos^2 x)\cos(\sin^2 x) -\sin(2x)\cos(\cos^2 x)\cos(\sin^2 x)+(-\sin(\sin^2 x)\sin(2x)\sin(\cos^2 x)) \sin^2 x \frac{d}{dx} \sin^2 x = 2\sin x \frac{d}{dx} \sin x = 2\sin x \cos x = \sin 2x \frac{d}{dx} cos^2 x -\sin 2x -\sin 2x\ (\cos(\cos^2 x)\cos(\sin^2 x) + \sin(\sin^2 x)\sin(\cos^2 x)) \cos(\cos 2x) -\sin(2x)\cos(\cos 2x),"['derivatives', 'trigonometry']"
73,Derivative of limited convolution,Derivative of limited convolution,,"If I take infinite convolution, I know that its derivative is the convolution between one term and other term's derivative. However, I am interested on derivative of $$\dfrac {d}{dt}\int_0^t f (t) g (t-a) da$$ i.e. in terms of limited convolution . Many thanks in advance! ====== EDIT: Please review comments on answer","If I take infinite convolution, I know that its derivative is the convolution between one term and other term's derivative. However, I am interested on derivative of i.e. in terms of limited convolution . Many thanks in advance! ====== EDIT: Please review comments on answer",\dfrac {d}{dt}\int_0^t f (t) g (t-a) da,"['derivatives', 'definite-integrals', 'convolution']"
74,"Prove that if $f$ is differentiable at $c$ (i.e., $\lim_{x\to c} {f(x)-f(c)\over x-c}$ exists), then $f'(c) = \lim_{h\to 0}{f(c+h)-f(c)\over h}.$","Prove that if  is differentiable at  (i.e.,  exists), then",f c \lim_{x\to c} {f(x)-f(c)\over x-c} f'(c) = \lim_{h\to 0}{f(c+h)-f(c)\over h}.,"Prove that if $f$ is differentiable at $c$ , then $f'(c) = \lim_{h\to 0}{f(c+h)-f(c)\over h}$ . I did this: If f is differentiable at $c$ , then it's continuous at $c$ , which implies, $\lim_{x\to c}$ $f(x)=f(c)$ if only if $\lim_{h\to 0}$ $f(c+h)-f(c)=0$ . Then dividing by $h$ , $$\lim_{h\to 0}{f(c+h)-f(c)\over h}=f'(c).$$ I don't know if this is correct, I feel it's kind of arbitrary. Edit: The definition of derivative is as follows- If $f$ is differentiable at a point a then the following limit exists: $\lim_{x\to a} {f(x)-f(a)\over x-a}$ .","Prove that if is differentiable at , then . I did this: If f is differentiable at , then it's continuous at , which implies, if only if . Then dividing by , I don't know if this is correct, I feel it's kind of arbitrary. Edit: The definition of derivative is as follows- If is differentiable at a point a then the following limit exists: .",f c f'(c) = \lim_{h\to 0}{f(c+h)-f(c)\over h} c c \lim_{x\to c} f(x)=f(c) \lim_{h\to 0} f(c+h)-f(c)=0 h \lim_{h\to 0}{f(c+h)-f(c)\over h}=f'(c). f \lim_{x\to a} {f(x)-f(a)\over x-a},"['real-analysis', 'calculus', 'derivatives']"
75,"Is the definition of ""limit of function"" incomplete?","Is the definition of ""limit of function"" incomplete?",,"On Wikipedia the definition of limit of a function $f$ such that it assigns an output $f(x)$ to every input $x$ is given as follows: We say that the function has a limit $L$ at an input $p$ , if $f(x)$ gets closer and closer to $L$ as $x$ moves closer and closer to $p$ . But I have a problem with it; If $L$ (for concrete example say $5$ ) is chosen as limit of the function then can't $L-0.1$ ( $4.9$ ) or $L-1$ ( $4$ ) or $L+1$ ( $6$ ) also be chosen as limit? Let me explain what I mean. If value of ""input"" is made to approach $p$ then, as given, the output will also approach $L$ , and also $L-0.1$ , $L-1$ ..... so what makes us choose only $L$ as the ""limit""? There is no special, explicit property, seems to be, mentioned which allows us to choose $L$ as the only ""limit"" and disregard other values(or does it?) like the fix difference between output, for given input, and the limit .","On Wikipedia the definition of limit of a function such that it assigns an output to every input is given as follows: We say that the function has a limit at an input , if gets closer and closer to as moves closer and closer to . But I have a problem with it; If (for concrete example say ) is chosen as limit of the function then can't ( ) or ( ) or ( ) also be chosen as limit? Let me explain what I mean. If value of ""input"" is made to approach then, as given, the output will also approach , and also , ..... so what makes us choose only as the ""limit""? There is no special, explicit property, seems to be, mentioned which allows us to choose as the only ""limit"" and disregard other values(or does it?) like the fix difference between output, for given input, and the limit .",f f(x) x L p f(x) L x p L 5 L-0.1 4.9 L-1 4 L+1 6 p L L-0.1 L-1 L L,['calculus']
76,"Is $\frac{f'}{f}$ bounded for $f$ convex, $f>c$?","Is  bounded for  convex, ?",\frac{f'}{f} f f>c,"Let $c>0$ , $f\colon \mathbb{R} \to [c,\infty)$ be differentiable and convex. Do we have $$ \left\|\frac{f'}{f}\right\|_{\infty} < \infty ?$$ This seems to be true in simple examples, but I am not sure whether this is true in general, so I would appreciate some hint or a counterexample.","Let , be differentiable and convex. Do we have This seems to be true in simple examples, but I am not sure whether this is true in general, so I would appreciate some hint or a counterexample.","c>0 f\colon \mathbb{R} \to [c,\infty)  \left\|\frac{f'}{f}\right\|_{\infty} < \infty ?","['real-analysis', 'derivatives', 'convex-analysis']"
77,Finding derivative of integral?,Finding derivative of integral?,,How may I calculate derivative for the following function? $$I_n(x)=\int_{a}^{x} (x-t)^{n}f(t)dt$$ Note : I'm given that $f$ is continuous,How may I calculate derivative for the following function? Note : I'm given that is continuous,I_n(x)=\int_{a}^{x} (x-t)^{n}f(t)dt f,"['calculus', 'integration', 'derivatives']"
78,Is Rolle's Theorem true when the function..,Is Rolle's Theorem true when the function..,,"Is Rolle's Theorem true when the function is not continuous at the end points? Suppose we define a function $f(x)=x$ for $0<x\leq 1$ and define $f(0)=1$ then it satisfies all the conditions of above theorem, except continuity at $x=0$ . Is Rolle's Theorem true in such cases?","Is Rolle's Theorem true when the function is not continuous at the end points? Suppose we define a function for and define then it satisfies all the conditions of above theorem, except continuity at . Is Rolle's Theorem true in such cases?",f(x)=x 0<x\leq 1 f(0)=1 x=0,"['calculus', 'derivatives', 'rolles-theorem']"
79,"True or false: $\frac{\mathrm d}{\mathrm dx}(\int _2^{\:e^x}\:\ln t \,dt)=x-\ln 2$. Support with a proof",True or false: . Support with a proof,"\frac{\mathrm d}{\mathrm dx}(\int _2^{\:e^x}\:\ln t \,dt)=x-\ln 2","True or false: $\frac{d}{dx}(\int _2^{\:e^x}\:\ln t \,dt)=x-\ln 2$ . Support with a proof I think it is false. I used the Fundamental Theorem of Calculus: $$\int _2^{\:e^x}\:\ln t\,dt\:=\:\int _0^{e^x}\ln t\:-\:\int _0^2\ln t\,dt$$ The second integral $\frac{d}{dx}\left(\int _0^2\ln t\right)dt=\ln 2$ The first integral $\frac{d}{dx}\left(\int _0^{e^x}\ln t\:\right)=\frac{d\left(e^x\right)}{dx}\frac{d}{d\left(e^x\right)}\int _0^{e^x}\ln t\:=e^xx$ Combining the terms $$\frac{d}{dx}\left(\int _2^{\:e^x}\:\ln t\,dt\:\right)=e^xx-\ln 2,$$ I saw the solution of the same question on a website , and its answer is different from mine. Is my solution wrong?","True or false: . Support with a proof I think it is false. I used the Fundamental Theorem of Calculus: The second integral The first integral Combining the terms I saw the solution of the same question on a website , and its answer is different from mine. Is my solution wrong?","\frac{d}{dx}(\int _2^{\:e^x}\:\ln t \,dt)=x-\ln 2 \int _2^{\:e^x}\:\ln t\,dt\:=\:\int _0^{e^x}\ln t\:-\:\int _0^2\ln t\,dt \frac{d}{dx}\left(\int _0^2\ln t\right)dt=\ln 2 \frac{d}{dx}\left(\int _0^{e^x}\ln t\:\right)=\frac{d\left(e^x\right)}{dx}\frac{d}{d\left(e^x\right)}\int _0^{e^x}\ln t\:=e^xx \frac{d}{dx}\left(\int _2^{\:e^x}\:\ln t\,dt\:\right)=e^xx-\ln 2,","['calculus', 'integration', 'derivatives', 'solution-verification']"
80,Do smooth and $L^1$ functions vanish at infinity?,Do smooth and  functions vanish at infinity?,L^1,"Sometimes when proving some estimates on a smooth solution of a PDE over the whole space domain, one integrates over space terms like $\partial_x u$ , and those terms vanish for some reason. Since we are working on the whole space and no boundary conditions are prescribed, my guess was that the reason was that $u \in L^1 \cap C^1$ , hence $\lim_{|x| \to +\infty} u(x) = 0$ and then $\int_{-\infty}^{+\infty} \partial_x u \, dx = \left[u(x)\right]_{-\infty}^{+\infty} = 0$ basically. However, I failed to prove such a statement and don't even know if it is true. I know that there are $L^1$ functions that do not vanish at infinity, and that aren't even bounded, but I couldn't think of any function that would be smooth as well, let's say $C^1$ . I thought that if $u$ is $C^1$ then you can't have peaks as stiff as you want, so you can't imagine peaks which mass would tend to zero ... but I failed to make this rigorous. Does anybody have a clue on that?","Sometimes when proving some estimates on a smooth solution of a PDE over the whole space domain, one integrates over space terms like , and those terms vanish for some reason. Since we are working on the whole space and no boundary conditions are prescribed, my guess was that the reason was that , hence and then basically. However, I failed to prove such a statement and don't even know if it is true. I know that there are functions that do not vanish at infinity, and that aren't even bounded, but I couldn't think of any function that would be smooth as well, let's say . I thought that if is then you can't have peaks as stiff as you want, so you can't imagine peaks which mass would tend to zero ... but I failed to make this rigorous. Does anybody have a clue on that?","\partial_x u u \in L^1 \cap C^1 \lim_{|x| \to +\infty} u(x) = 0 \int_{-\infty}^{+\infty} \partial_x u \, dx = \left[u(x)\right]_{-\infty}^{+\infty} = 0 L^1 C^1 u C^1","['integration', 'derivatives', 'lebesgue-integral', 'partial-differential-equations']"
81,"Prove or disprove: if $f:(0,1)\to\mathbb{R}$ is twice differentiable and $f$ and $f'$ are bounded then $f''$ is bounded.",Prove or disprove: if  is twice differentiable and  and  are bounded then  is bounded.,"f:(0,1)\to\mathbb{R} f f' f''","I believe this is not true and I wonder if this is a correct counterexample: Define $F: [0,1] \to \mathbb{R}$ by $F(0)=0$ and $F(x)=\sin (1/x)$ elsewhere. Then define $f(x)=\int_{0}^{x} F$ . Then $f$ is differentiable and bounded on $(0,1)$ and $f'(x)=\sin (1/x)$ . On the other hand, $f''(x)=-(1/x^2) \cos (1/x)$ . Is this counterexample correct and or is there any flaw in my reasoning? Is there a function $f$ not defined in terms of integrals which does not satisfy the given property?","I believe this is not true and I wonder if this is a correct counterexample: Define by and elsewhere. Then define . Then is differentiable and bounded on and . On the other hand, . Is this counterexample correct and or is there any flaw in my reasoning? Is there a function not defined in terms of integrals which does not satisfy the given property?","F: [0,1] \to \mathbb{R} F(0)=0 F(x)=\sin (1/x) f(x)=\int_{0}^{x} F f (0,1) f'(x)=\sin (1/x) f''(x)=-(1/x^2) \cos (1/x) f","['real-analysis', 'derivatives']"
82,How to find the derivative of $\sqrt{x+2} -x$ using limit definition?,How to find the derivative of  using limit definition?,\sqrt{x+2} -x,"So the function is $f(x) = \sqrt{x+2} -x$ , and I keep hitting dead ends trying to solve it using the definition of derivative. If anyone can help, it would be greatly appreciated!","So the function is , and I keep hitting dead ends trying to solve it using the definition of derivative. If anyone can help, it would be greatly appreciated!",f(x) = \sqrt{x+2} -x,['derivatives']
83,What is the inverse of the *divergence* operator?,What is the inverse of the *divergence* operator?,,The inverse of derivation is integral. But what is the inverse of the divergence operator ? Doest it exist ?,The inverse of derivation is integral. But what is the inverse of the divergence operator ? Doest it exist ?,,"['integration', 'derivatives', 'mathematical-physics']"
84,"Proving that if f' is bounded in the fixed point, then f' is bounded on some interval","Proving that if f' is bounded in the fixed point, then f' is bounded on some interval",,"I have a question related to the Problem 10 in Exercises 1.7  (p. 35) in the book ""Discrete chaos"" , Saber Elaydi. The Problem is: ""Assume that $f$ is continuously differentiable at $x^*$ . Show that if $|f'(x^*)| <1$ , for a fixed point $x^*$ of $f$ , then there exists an interval $I= (x^* -\delta, x^*+\delta)$ such that $|f'(x)| \leq M <1$ for all $x \in I$ and for some constant $M $ . "" My attempt was: $f$ is  continuously differentiable at $x^*$ , so it is continuous at $x^*$ , so for all $ \epsilon > 0$ $\exists  \delta > 0  $ such that $ |x- x^* |< \delta \implies  |f(x) - f(x^*) |< \epsilon $ . I wanted to prove that on the interval $(x^*-\delta, x^*+\delta)  $ holds: $|f'(x)| \leq M <1$ , for some $M$ . We can write $|f'(x)| $ as: $|f'(x)| = | f'(x) - f'(x^*) + f'(x^*) | \leq | f'(x) - f'(x^*)| + |f'(x^*) | \leq \epsilon + 1$ , where $x \in (x^*-\delta, x^*+\delta)  $ Now I don't know what to do, can someone help me? Thanks in advance.","I have a question related to the Problem 10 in Exercises 1.7  (p. 35) in the book ""Discrete chaos"" , Saber Elaydi. The Problem is: ""Assume that is continuously differentiable at . Show that if , for a fixed point of , then there exists an interval such that for all and for some constant . "" My attempt was: is  continuously differentiable at , so it is continuous at , so for all such that . I wanted to prove that on the interval holds: , for some . We can write as: , where Now I don't know what to do, can someone help me? Thanks in advance.","f x^* |f'(x^*)| <1 x^* f I= (x^* -\delta, x^*+\delta) |f'(x)| \leq M <1 x \in I M  f x^* x^*  \epsilon > 0 \exists  \delta > 0    |x- x^* |< \delta \implies  |f(x) - f(x^*) |< \epsilon  (x^*-\delta, x^*+\delta)   |f'(x)| \leq M <1 M |f'(x)|  |f'(x)| = | f'(x) - f'(x^*) + f'(x^*) | \leq | f'(x) - f'(x^*)| + |f'(x^*) | \leq \epsilon + 1 x \in (x^*-\delta, x^*+\delta)  ","['calculus', 'derivatives', 'fixed-points']"
85,"Determine whether $f(x,y)=\sqrt{|xy|}$ and/or $g(x,y)=e^{|x|^3y}$ are differentiable at the point $(0, 0)$.",Determine whether  and/or  are differentiable at the point .,"f(x,y)=\sqrt{|xy|} g(x,y)=e^{|x|^3y} (0, 0)","Determine whether $$f(x,y)=\sqrt{|xy|}$$ and/or $$g(x,y)=e^{|x|^3y}$$ are differentiable at the point $(0, 0)$ . Also, find its total derivative if it exists at (0, 0); if not, prove that it is not differentiable at $(0, 0)$ . My approach: For $f(x,y)$ , I got it is not differentiable because the limit tends to $1$ and $-1$ . But I am not sure about $g(x,y)$ .","Determine whether and/or are differentiable at the point . Also, find its total derivative if it exists at (0, 0); if not, prove that it is not differentiable at . My approach: For , I got it is not differentiable because the limit tends to and . But I am not sure about .","f(x,y)=\sqrt{|xy|} g(x,y)=e^{|x|^3y} (0, 0) (0, 0) f(x,y) 1 -1 g(x,y)","['derivatives', 'bivariate-distributions']"
86,"Is this Function Differentiable? $f(x) = \begin{cases} x^2-4x+5, & \text{if } x\neq 0\\ 3x+5, & \text{if } x=0 \end{cases}$",Is this Function Differentiable?,"f(x) = \begin{cases} x^2-4x+5, & \text{if } x\neq 0\\ 3x+5, & \text{if } x=0 \end{cases}","$$f(x) = \begin{cases} x^2-4x+5,  & \text{if $x\neq0$ } \\ 3x+5, & \text{if $x=0$ } \end{cases}$$ Can we Present this function as a Differentiable Function whose Derivate Function is Not Continues? I Suppose the Derivate Function would be: $$f'(x) = \begin{cases} 2x-4,  & \text{if $x\neq0$ } \\ 3, & \text{if $x=0$ } \end{cases}$$ Am I Right? And is this function basically differentiable? Thanks in Advance.",Can we Present this function as a Differentiable Function whose Derivate Function is Not Continues? I Suppose the Derivate Function would be: Am I Right? And is this function basically differentiable? Thanks in Advance.,"f(x) = \begin{cases} x^2-4x+5,  & \text{if x\neq0 } \\ 3x+5, & \text{if x=0 } \end{cases} f'(x) = \begin{cases} 2x-4,  & \text{if x\neq0 } \\ 3, & \text{if x=0 } \end{cases}",['derivatives']
87,Derivative of Square Root of Matrix with respect to a Scalar,Derivative of Square Root of Matrix with respect to a Scalar,,"Let $X(\Omega)$ be a positive-semi-definite matrix which is a function of a set of parameters $\Omega$ . I am interested in both cases where the matrix is real, or is Hermitian. What is the derivative of the square root of this matrix with respect to an individual parameter $\Omega_i$ , i.e $ {\partial_{\Omega_i}\sqrt{X(\Omega)}} $ ?  Can this derivative be reduced to a form in terms of ${\partial_{\Omega_i}X(\Omega)}$ ?","Let be a positive-semi-definite matrix which is a function of a set of parameters . I am interested in both cases where the matrix is real, or is Hermitian. What is the derivative of the square root of this matrix with respect to an individual parameter , i.e ?  Can this derivative be reduced to a form in terms of ?","X(\Omega) \Omega \Omega_i 
{\partial_{\Omega_i}\sqrt{X(\Omega)}}
 {\partial_{\Omega_i}X(\Omega)}","['matrices', 'derivatives', 'matrix-equations', 'matrix-calculus']"
88,"How to show that ""whenever $v \ne 0$"", $m\frac{dv}{dt} = -kx$","How to show that ""whenever "",",v \ne 0 m\frac{dv}{dt} = -kx,"A particle of constant mass m moves along the $x$ -axis. Its velocity $v$ and position $x$ satisfy the equation: $\frac{m}{2}(v^2 - v_0^2) = \frac{k}{2}(x_0^2 - x^2)$ where $K$ , $Y_0$ , and $X_0$ are constants. Show that whenever $v \ne 0$ , $m\frac{dv}{dt} = -kx$ . My reasoning is this: we can treat the $x$ as $S$ and it's a function of $t$ . Then the $v$ becomes a function of $x$ . If we differentiate both sides of the equation according to the implicit differentiation rules, we'll get: $$ \frac{m}{2}(2vv') = \frac{k}{2}(-2x) \\ mvv' = -kx $$ If this is correct, the only case where $m\frac{dv}{dt} = -kx$ is when $V=1$ , not ""whenever $v \ne 0$ "". So I'm stuck here. Could, please, someone explain what is wrong here?","A particle of constant mass m moves along the -axis. Its velocity and position satisfy the equation: where , , and are constants. Show that whenever , . My reasoning is this: we can treat the as and it's a function of . Then the becomes a function of . If we differentiate both sides of the equation according to the implicit differentiation rules, we'll get: If this is correct, the only case where is when , not ""whenever "". So I'm stuck here. Could, please, someone explain what is wrong here?","x v x \frac{m}{2}(v^2 - v_0^2) = \frac{k}{2}(x_0^2 - x^2) K Y_0 X_0 v \ne 0 m\frac{dv}{dt} = -kx x S t v x 
\frac{m}{2}(2vv') = \frac{k}{2}(-2x) \\
mvv' = -kx
 m\frac{dv}{dt} = -kx V=1 v \ne 0","['calculus', 'derivatives', 'implicit-differentiation']"
89,Derivative of $\log(r)$ with respect to $x$,Derivative of  with respect to,\log(r) x,"$r$ is a polar radius coordinate, $x$ is a horisontal cartesian coordinate. Going one way, i get: $\log(r)_x=\log(\sqrt{z\bar{z}})_x$ = $\frac{ (\sqrt{z\bar{z}})_x }{ \sqrt{z\bar{z}}}= \frac{0.5((\bar{z})_xz+ \bar{z}z_x) }{ \bar{z}z } = \frac{x}{r^2} $ . This is correct. But going other way, i get: $\log(r)_x=\log(r)_rr_x= \frac{r_x}{r}= \frac{1}{r} $ , since $x=re^{i0}=r$ in polar coordinates. My question is, why is the second way wrong, and are there any easier methods to arrive at $\log(r)_x= \frac{x}{r^2}$ , without using complex numbers perhaps?","is a polar radius coordinate, is a horisontal cartesian coordinate. Going one way, i get: = . This is correct. But going other way, i get: , since in polar coordinates. My question is, why is the second way wrong, and are there any easier methods to arrive at , without using complex numbers perhaps?",r x \log(r)_x=\log(\sqrt{z\bar{z}})_x \frac{ (\sqrt{z\bar{z}})_x }{ \sqrt{z\bar{z}}}= \frac{0.5((\bar{z})_xz+ \bar{z}z_x) }{ \bar{z}z } = \frac{x}{r^2}  \log(r)_x=\log(r)_rr_x= \frac{r_x}{r}= \frac{1}{r}  x=re^{i0}=r \log(r)_x= \frac{x}{r^2},"['complex-analysis', 'derivatives', 'coordinate-systems', 'polar-coordinates', 'implicit-differentiation']"
90,Derivative of Inverse Function on Banach Space,Derivative of Inverse Function on Banach Space,,"During the semester, I ran into a problem that dealt with finding the derivative of the inverse function on a Banach space (where $V$ , the vector space is a Banach algebra and the field $F = R$ or $C$ ). I had managed to show that the set of invertible elements of the Banach algebra was open, and then I needed to find the derivative of $f(x) = x^{-1}$ where $f : GL(V) \to GL(V)$ . Here is what I have thought so far: So the derivative satisfies $\lim_{h \to 0} |\frac{(x+h)^{-1} - x^{-1} - \lambda(h)}{|h|}|$ . We have that $(x+h)^{-1} - x^{-1} = x^{-1}((e + x^{-1}h)^{-1} - 1) = x^{-1}(\sum_{j=0}^{\infty} (x^{-1}h)^{j} - 1) = x^{-1}(\sum_{j=1}^{\infty} (x^{-1}h)^{j})$ . This is as far as I have been able to get. Any hints or helps would be greatly appreciated. Working off the hint from Thomas Shelby: We show that $f$ is continuous on $GL(V)$ . Given some $x \in GL(V)$ (let $B(x, h) \subseteq GL(V)$ and an $\epsilon > 0$ we have two cases. If $||x||\epsilon \geq 1$ then choose $\delta = \min(1, h)$ else choose $\delta = \min(\frac{||x||^2\epsilon}{2(1-||x||\epsilon)}, h)$ . Then we have for $y$ such that $||x - y|| < \delta$ that $|f(x) - f(y)|| = ||x^{-1}(y-x)y^{-1}|| = ||x^{-1}||*||y^{-1}||*||x-y|| = \frac{||x-y||}{||x||*||y||}$ and since $||y|| \leq ||x - y|| + ||x||$ by triangle inequality we have that this is less than or equal to $\frac{\delta}{||x||(||x|| + \delta)} < \frac{\frac{||x||^2\epsilon}{1-||x||\epsilon}}{\frac{||x||^2}{1-||x||\epsilon}} = \epsilon$ . To conclude then we note that as Thomas Shelby wrote, $||\frac{(x+h)^{-1} - x^{-1} + x^{-1}hx}{||h||}|| = \frac{||(x+h)^{-1} - x^{-1}||*||h||*||x^{-1}||}{||h||} = ||(x+h)^{-1} - x^{-1}||*||x^{-1}||$ which goes to $0$ as $h \to 0$ by continuity of $f$ .","During the semester, I ran into a problem that dealt with finding the derivative of the inverse function on a Banach space (where , the vector space is a Banach algebra and the field or ). I had managed to show that the set of invertible elements of the Banach algebra was open, and then I needed to find the derivative of where . Here is what I have thought so far: So the derivative satisfies . We have that . This is as far as I have been able to get. Any hints or helps would be greatly appreciated. Working off the hint from Thomas Shelby: We show that is continuous on . Given some (let and an we have two cases. If then choose else choose . Then we have for such that that and since by triangle inequality we have that this is less than or equal to . To conclude then we note that as Thomas Shelby wrote, which goes to as by continuity of .","V F = R C f(x) = x^{-1} f : GL(V) \to GL(V) \lim_{h \to 0} |\frac{(x+h)^{-1} - x^{-1} - \lambda(h)}{|h|}| (x+h)^{-1} - x^{-1} = x^{-1}((e + x^{-1}h)^{-1} - 1) = x^{-1}(\sum_{j=0}^{\infty} (x^{-1}h)^{j} - 1) = x^{-1}(\sum_{j=1}^{\infty} (x^{-1}h)^{j}) f GL(V) x \in GL(V) B(x, h) \subseteq GL(V) \epsilon > 0 ||x||\epsilon \geq 1 \delta = \min(1, h) \delta = \min(\frac{||x||^2\epsilon}{2(1-||x||\epsilon)}, h) y ||x - y|| < \delta |f(x) - f(y)|| = ||x^{-1}(y-x)y^{-1}|| = ||x^{-1}||*||y^{-1}||*||x-y|| = \frac{||x-y||}{||x||*||y||} ||y|| \leq ||x - y|| + ||x|| \frac{\delta}{||x||(||x|| + \delta)} < \frac{\frac{||x||^2\epsilon}{1-||x||\epsilon}}{\frac{||x||^2}{1-||x||\epsilon}} = \epsilon ||\frac{(x+h)^{-1} - x^{-1} + x^{-1}hx}{||h||}|| = \frac{||(x+h)^{-1} - x^{-1}||*||h||*||x^{-1}||}{||h||} = ||(x+h)^{-1} - x^{-1}||*||x^{-1}|| 0 h \to 0 f","['derivatives', 'banach-spaces']"
91,Why is $\left(\frac{\partial}{\partial x_i}\right)f = \left(\frac{\partial f}{\partial x_i}\right)$,Why is,\left(\frac{\partial}{\partial x_i}\right)f = \left(\frac{\partial f}{\partial x_i}\right),"i'm currently reading An Introduction to Morse Theory by Yukio Matsumoto and on p.62 it says A vector field itself is sort of a differential operator, since it   assigns to each point a ""tangent vector"" which is a differential   operation. Let us differentiate $f$ with respect to the gradient   vector field $X_f$ : $$X_f \cdot f = \left(\sum_{i=1}^m \frac{\partial f}{\partial x_i}  \frac{\partial}{\partial x_i}\right)\cdot f = \sum_{i=1}^m \left(  \frac{\partial f}{\partial x_i}\right)^2 \ge 0$$ I would love to understand why $$ \left(\frac{\partial}{\partial x_i}\right)\cdot f =  \left(  \frac{\partial f}{\partial x_i}\right)$$ Could anyone help me on this? Thank you very much.","i'm currently reading An Introduction to Morse Theory by Yukio Matsumoto and on p.62 it says A vector field itself is sort of a differential operator, since it   assigns to each point a ""tangent vector"" which is a differential   operation. Let us differentiate with respect to the gradient   vector field : I would love to understand why Could anyone help me on this? Thank you very much.","f X_f X_f \cdot f = \left(\sum_{i=1}^m \frac{\partial f}{\partial x_i}
 \frac{\partial}{\partial x_i}\right)\cdot f = \sum_{i=1}^m \left(
 \frac{\partial f}{\partial x_i}\right)^2 \ge 0  \left(\frac{\partial}{\partial x_i}\right)\cdot f =  \left(
 \frac{\partial f}{\partial x_i}\right)","['real-analysis', 'calculus', 'derivatives', 'partial-derivative', 'differential-operators']"
92,Is a continuous real-valued function with an almost everywhere continuous derivative necessarily differentiable on $\mathbb{R}$? [duplicate],Is a continuous real-valued function with an almost everywhere continuous derivative necessarily differentiable on ? [duplicate],\mathbb{R},"This question already has answers here : If a derivative of a continuous function has a limit, must it agree with that limit? [duplicate] (2 answers) Closed 4 years ago . Setting: Let $a\in \mathbb{R}$ , and let $f$ be a function which is continuous on $\mathbb{R}$ , differentiable on $(\infty,a)\cup (a,\infty)$ , and has the property that $\lim_{x\to a^{-}}f'(x) = \lim_{x\to a^{+}}f'(x) = L$ for some $L\in\mathbb{R}$ . Question: Does it automatically follow that $f$ is differentiable at $a\in \mathbb{R}$ ? My intuition wants to say yes since we are placing such strong conditions on $f$ , and if I were going to try to prove this I would pursue the following logic: Argument: \begin{align*} f'(a) &= \lim_{h\to 0}\frac{f(a+h) - f(a)}{h}\\ &= \lim_{h\to 0}\left[\lim_{x\to a^{-}}\frac{f(x+h) - f(x)}{h}\right]\text{using continuity of} f \text{at }a\\ &= \color{red}{\lim_{x\to a^{-}}\left[\lim_{h\to 0}\frac{f(x+h) - f(x)}{h}\right]}\\ &= \lim_{x\to a^{-}}f'(x)\\ &= L \end{align*} or using essentially the same argument from the other side..... \begin{align*} f'(a) &= \lim_{h\to 0}\frac{f(a+h) - f(a)}{h}\\ &= \lim_{h\to 0}\left[\lim_{x\to a^{+}}\frac{f(x+h) - f(x)}{h}\right]\text{using continuity of} f \text{at }a\\ &= \color{blue}{\lim_{x\to a^{+}}\left[\lim_{h\to 0}\frac{f(x+h) - f(x)}{h}\right]}\\ &= \lim_{x\to a^{+}}f'(x)\\ &= L \end{align*} But the steps that I've outlined in red and blue correspond to geniune gaps in my argument.  We cannot always interchange such limits without caution, but perhaps due to the strong assumptions on $f$ we can in this case. Is there an example of a function $f$ (of course, satisfying the conditions give above) for which this logic fails? If not, how can I fix my argument?","This question already has answers here : If a derivative of a continuous function has a limit, must it agree with that limit? [duplicate] (2 answers) Closed 4 years ago . Setting: Let , and let be a function which is continuous on , differentiable on , and has the property that for some . Question: Does it automatically follow that is differentiable at ? My intuition wants to say yes since we are placing such strong conditions on , and if I were going to try to prove this I would pursue the following logic: Argument: or using essentially the same argument from the other side..... But the steps that I've outlined in red and blue correspond to geniune gaps in my argument.  We cannot always interchange such limits without caution, but perhaps due to the strong assumptions on we can in this case. Is there an example of a function (of course, satisfying the conditions give above) for which this logic fails? If not, how can I fix my argument?","a\in \mathbb{R} f \mathbb{R} (\infty,a)\cup (a,\infty) \lim_{x\to a^{-}}f'(x) = \lim_{x\to a^{+}}f'(x) = L L\in\mathbb{R} f a\in \mathbb{R} f \begin{align*}
f'(a) &= \lim_{h\to 0}\frac{f(a+h) - f(a)}{h}\\
&= \lim_{h\to 0}\left[\lim_{x\to a^{-}}\frac{f(x+h) - f(x)}{h}\right]\text{using continuity of} f \text{at }a\\
&= \color{red}{\lim_{x\to a^{-}}\left[\lim_{h\to 0}\frac{f(x+h) - f(x)}{h}\right]}\\
&= \lim_{x\to a^{-}}f'(x)\\
&= L
\end{align*} \begin{align*}
f'(a) &= \lim_{h\to 0}\frac{f(a+h) - f(a)}{h}\\
&= \lim_{h\to 0}\left[\lim_{x\to a^{+}}\frac{f(x+h) - f(x)}{h}\right]\text{using continuity of} f \text{at }a\\
&= \color{blue}{\lim_{x\to a^{+}}\left[\lim_{h\to 0}\frac{f(x+h) - f(x)}{h}\right]}\\
&= \lim_{x\to a^{+}}f'(x)\\
&= L
\end{align*} f f","['calculus', 'derivatives']"
93,Matrix derivative of $\hat{G}\ln \hat{G}$ where $\hat{G}$ is a diagonalizable matrix?,Matrix derivative of  where  is a diagonalizable matrix?,\hat{G}\ln \hat{G} \hat{G},"Let $\hat{G}$ be a $n\times n$ matrix that is diagonalizable $\hat{D}=P^{-1}\hat{G} P$ . What is the matrix-by-matrix derivative: $$ \frac{\partial }{\partial \hat{G}} \hat{G}\ln \hat{G} $$ My intuition would be to proceed as follows: $$ \begin{align} \frac{\partial }{\partial \hat{G}} \hat{G}\ln \hat{G}&=\left( \frac{\partial }{\partial \hat{G}} \hat{G} \right)\ln \hat{G}+\hat{G}\frac{\partial }{\partial \hat{G}} \ln \hat{G}\\ &=\ln \hat{G}+\hat{G}\frac{\partial }{\partial \hat{G}} P^{-1} \ln \hat{D} P\\ &=\ln \hat{G}+ \left[ \hat{G} \left( \frac{\partial }{\partial \hat{G}} P^{-1} \right) \ln \hat{D} P \right] + \left[\hat{G} P^{-1} \left( \frac{\partial }{\partial \hat{G}}   \ln \hat{D} \right) P \right]+ \left[\hat{G} P^{-1} \ln \hat{D} \frac{\partial }{\partial \hat{G}}   P \right] \end{align} $$ What can I simplyfy from there? Can $\left( \frac{\partial }{\partial \hat{G}} P^{-1} \right)$ or $\left( \frac{\partial }{\partial \hat{G}} P \right)$ be made equal to $0$ ? What about the middle term $P^{-1} \left( \frac{\partial }{\partial \hat{G}}   \ln \hat{D} \right) P$ ? $$ P^{-1} \left( \frac{\partial }{\partial \hat{G}}   \ln \hat{D} \right) P=P^{-1} \left( \frac{1}{\hat{D}} \frac{\partial \hat{D}}{\partial \hat{G}} \right) P $$ I imagine that because $\hat{G}$ is diagonalizable, eventually $$ \frac{\partial }{\partial \hat{G}} \hat{G}\ln \hat{G} \to \ln \hat{G} +1 $$ but I cannot seem to get there.","Let be a matrix that is diagonalizable . What is the matrix-by-matrix derivative: My intuition would be to proceed as follows: What can I simplyfy from there? Can or be made equal to ? What about the middle term ? I imagine that because is diagonalizable, eventually but I cannot seem to get there.","\hat{G} n\times n \hat{D}=P^{-1}\hat{G} P 
\frac{\partial }{\partial \hat{G}} \hat{G}\ln \hat{G}
 
\begin{align}
\frac{\partial }{\partial \hat{G}} \hat{G}\ln \hat{G}&=\left( \frac{\partial }{\partial \hat{G}} \hat{G} \right)\ln \hat{G}+\hat{G}\frac{\partial }{\partial \hat{G}} \ln \hat{G}\\
&=\ln \hat{G}+\hat{G}\frac{\partial }{\partial \hat{G}} P^{-1} \ln \hat{D} P\\
&=\ln \hat{G}+ \left[ \hat{G} \left( \frac{\partial }{\partial \hat{G}} P^{-1} \right) \ln \hat{D} P \right] + \left[\hat{G} P^{-1} \left( \frac{\partial }{\partial \hat{G}}   \ln \hat{D} \right) P \right]+ \left[\hat{G} P^{-1} \ln \hat{D} \frac{\partial }{\partial \hat{G}}   P \right]
\end{align}
 \left( \frac{\partial }{\partial \hat{G}} P^{-1} \right) \left( \frac{\partial }{\partial \hat{G}} P \right) 0 P^{-1} \left( \frac{\partial }{\partial \hat{G}}   \ln \hat{D} \right) P 
P^{-1} \left( \frac{\partial }{\partial \hat{G}}   \ln \hat{D} \right) P=P^{-1} \left( \frac{1}{\hat{D}} \frac{\partial \hat{D}}{\partial \hat{G}} \right) P
 \hat{G} 
\frac{\partial }{\partial \hat{G}} \hat{G}\ln \hat{G} \to \ln \hat{G} +1
","['matrices', 'derivatives']"
94,Relation of Determinant and trace of a matrix concerning derivative,Relation of Determinant and trace of a matrix concerning derivative,,"If there is a function $F(t) = det(I_{n} + tA)$ where $A$ is an $n \times n$ matrix, $t$ is an arbitrary real number, and $I_{n}$ is $n \times n$ identity matrix, is it true that the derivative of $F(t)$ at $t = 0$ is equal to the trace of $A$ ? That is, $F'(0) = Tr(A)$ I currently know that the trace is the sum of the diagonal entries of a matrix but I am not sure how I should go about differentiating the right hand side. Is there a general formula for finding determinant that I could possibly differentiate? It seems like there is something called 'big formula for determinant' but I am not sure how that can be used for this problem. Any help would be appreciated.","If there is a function where is an matrix, is an arbitrary real number, and is identity matrix, is it true that the derivative of at is equal to the trace of ? That is, I currently know that the trace is the sum of the diagonal entries of a matrix but I am not sure how I should go about differentiating the right hand side. Is there a general formula for finding determinant that I could possibly differentiate? It seems like there is something called 'big formula for determinant' but I am not sure how that can be used for this problem. Any help would be appreciated.",F(t) = det(I_{n} + tA) A n \times n t I_{n} n \times n F(t) t = 0 A F'(0) = Tr(A),"['linear-algebra', 'derivatives']"
95,Why are there apparently multiple general anti-derivatives for $f(x) = 1/x$? [duplicate],Why are there apparently multiple general anti-derivatives for ? [duplicate],f(x) = 1/x,"This question already has answers here : Two different solutions to integral (3 answers) Closed 4 years ago . So I've learned that the general anti-derivative of $f(x)=1/x$ is: $\ln|x|+C$ But it is also true, according to Wolfram Alpha, that the derivative of $\ln(2x)$ is also $1/x$ . So what gives? How can these facts both be true? Why isn't $\ln(2x) + C$ also an anti-derivative of $1/x$ ? Is there something about the definition of anti-differentiation that I'm missing? NOTE: I am in high school Calculus, and we have not yet covered integration. That being said, I have some limited familiarity with the notation for indefinite integrals (which I understand to be the same as anti-derivatives?), so as long as you're careful to explain things and use precise language, I suppose I'm fine with using integrals in any answers.","This question already has answers here : Two different solutions to integral (3 answers) Closed 4 years ago . So I've learned that the general anti-derivative of is: But it is also true, according to Wolfram Alpha, that the derivative of is also . So what gives? How can these facts both be true? Why isn't also an anti-derivative of ? Is there something about the definition of anti-differentiation that I'm missing? NOTE: I am in high school Calculus, and we have not yet covered integration. That being said, I have some limited familiarity with the notation for indefinite integrals (which I understand to be the same as anti-derivatives?), so as long as you're careful to explain things and use precise language, I suppose I'm fine with using integrals in any answers.",f(x)=1/x \ln|x|+C \ln(2x) 1/x \ln(2x) + C 1/x,"['calculus', 'integration', 'derivatives']"
96,Numerical derivative at order 3,Numerical derivative at order 3,,"I'd like to find the formula for the 3rd order numerical derivative in order to further implement a Python function for a time series (Python only have a function from scipy which takes an unknown variable). In order to demonstrate and calculate the general formula I just took the 2 main formulas : $$f'(x) = \frac{f(x+h) - f(x-h)}{2h}$$ $$f''(x) = \frac{f(x+h) - 2f(x) + f(x+h)}{h^2}$$ then I made the following hypothesis that : $$ f'''(x) = \frac{f''(x+h) - f''(x-h)}{2h}$$ where, $$ f''(x+h) = \frac{f(x+h+h)-2f(x+h)+f(x+h-h)}{2h}$$ $$ = \frac{f(x+2h)-2f(x+h)+f(x)}{2h}$$ and same calculation for the other, $$ f''(x-h) = \frac{f(x-2h)-2f(x-h) + f(x)}{2h}$$ which gives me at the end : $$f'''(x) = \frac{f(x+2h) + 2h(f(x-h) - f(x+h))-f(x-2h)}{4h^2}$$ But I just can't find anywhere if my calculation is right or not, Is my result good ? What about the calculation method ? I'm doubting as I'm not studying at school anymore I don't have a teacher to correct me.","I'd like to find the formula for the 3rd order numerical derivative in order to further implement a Python function for a time series (Python only have a function from scipy which takes an unknown variable). In order to demonstrate and calculate the general formula I just took the 2 main formulas : then I made the following hypothesis that : where, and same calculation for the other, which gives me at the end : But I just can't find anywhere if my calculation is right or not, Is my result good ? What about the calculation method ? I'm doubting as I'm not studying at school anymore I don't have a teacher to correct me.",f'(x) = \frac{f(x+h) - f(x-h)}{2h} f''(x) = \frac{f(x+h) - 2f(x) + f(x+h)}{h^2}  f'''(x) = \frac{f''(x+h) - f''(x-h)}{2h}  f''(x+h) = \frac{f(x+h+h)-2f(x+h)+f(x+h-h)}{2h}  = \frac{f(x+2h)-2f(x+h)+f(x)}{2h}  f''(x-h) = \frac{f(x-2h)-2f(x-h) + f(x)}{2h} f'''(x) = \frac{f(x+2h) + 2h(f(x-h) - f(x+h))-f(x-2h)}{4h^2},"['derivatives', 'numerical-methods', 'numerical-calculus']"
97,"If $f:S_1\rightarrow S_2, C^{\infty}$ is invertible and $f^{-1}$ is differentiable, so $f^{-1}$ is $C^{\infty}$","If  is invertible and  is differentiable, so  is","f:S_1\rightarrow S_2, C^{\infty} f^{-1} f^{-1} C^{\infty}","I am trying to follow some notes of classes and the professor wrote. It is a result for differentiable applications between surfaces. If $f:S_1\rightarrow S_2, C^{\infty}$ is invertible and $f^{-1}$ is differentiable, so $f^{-1}$ is $C^{\infty}$ . Proof: If $g=f^{-1}$ , so $g ~\circ~f=I $ and $dg_{f(p)}\circ df_p=I$ . Then, $dg_{f(p)}=(df_p)^{-1}=Inv~\circ df_p$ . Therefore, $g$ is $C^{\infty}$ . I could follow the steps, but do not get how obtain the conclusion ""therefore..."". Many thanks.","I am trying to follow some notes of classes and the professor wrote. It is a result for differentiable applications between surfaces. If is invertible and is differentiable, so is . Proof: If , so and . Then, . Therefore, is . I could follow the steps, but do not get how obtain the conclusion ""therefore..."". Many thanks.","f:S_1\rightarrow S_2, C^{\infty} f^{-1} f^{-1} C^{\infty} g=f^{-1} g ~\circ~f=I  dg_{f(p)}\circ df_p=I dg_{f(p)}=(df_p)^{-1}=Inv~\circ df_p g C^{\infty}","['derivatives', 'differential-geometry']"
98,What is the derivative for the function $f(x) = \sin^2(x)\sin(x^2)?$,What is the derivative for the function,f(x) = \sin^2(x)\sin(x^2)?,"I understand the process of the product rule and chain rule etc. My answer led to $[\sin^2(x)\cos(x^2)(2x)] + \sin(x^2)(2\sin x \cos x).$ According to my solutions manual this is so far correct, however the final answer reads $2\sin(x)[x\cos(x^2)+\cos(x)\sin(x^2)].$ I assume this is some algebraic manipulation with maybe trig identities however I have no idea how. I'd appreciate if someone explained how to arrive at that answer, thank you!","I understand the process of the product rule and chain rule etc. My answer led to According to my solutions manual this is so far correct, however the final answer reads I assume this is some algebraic manipulation with maybe trig identities however I have no idea how. I'd appreciate if someone explained how to arrive at that answer, thank you!",[\sin^2(x)\cos(x^2)(2x)] + \sin(x^2)(2\sin x \cos x). 2\sin(x)[x\cos(x^2)+\cos(x)\sin(x^2)].,"['calculus', 'derivatives']"
99,Differentiability of $\log|x|$,Differentiability of,\log|x|,It is known that $$\dfrac{d}{dx}\log f(x) = \dfrac{1}{f(x)} f'(x)$$ but how does it is not applicable for $\log |x|$ as $|x|$ is not differentiable?,It is known that but how does it is not applicable for as is not differentiable?,\dfrac{d}{dx}\log f(x) = \dfrac{1}{f(x)} f'(x) \log |x| |x|,"['derivatives', 'logarithms']"
