,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Nonparametric changepoint detection for point process,Nonparametric changepoint detection for point process,,"This is a replication of a question I've recently asked on Cross Validated. It hasn't received an answer or much attention, so I've posted it here. I have a family of point processes representing neural firing data. In each of these point processes, there is a marked pause in events beginning and ending at around the same time. I would like to measure the length of this pause. The model generating this data seems quite complicated and, so far, it has resisted fitting to any elementary distributions. This makes changepoint detection difficult. I've developed a non-statistical method inspired by Canny edge detection, though it doesn't work as well as I'd like. Are there known methods for detecting changepoints in general, nonstationary point processes?","This is a replication of a question I've recently asked on Cross Validated. It hasn't received an answer or much attention, so I've posted it here. I have a family of point processes representing neural firing data. In each of these point processes, there is a marked pause in events beginning and ending at around the same time. I would like to measure the length of this pause. The model generating this data seems quite complicated and, so far, it has resisted fitting to any elementary distributions. This makes changepoint detection difficult. I've developed a non-statistical method inspired by Canny edge detection, though it doesn't work as well as I'd like. Are there known methods for detecting changepoints in general, nonstationary point processes?",,"['statistics', 'stochastic-processes', 'signal-processing']"
1,Confidence and proportion,Confidence and proportion,,"You wish to estimate,with $99\%$ confidence, the proportion of Canadian drivers who want the speed limit raised to $130$ kph. Your estimate must be accurate to within $5\%$. How many drivers must you survey,if your initial estimate of the proportion is $0.60$? I know that $99\%$ is $2.575$ but i dont know how to set up the problem. I don't think that $130$ kph even has anything to do with the problem. I think i am over thinking this question.","You wish to estimate,with $99\%$ confidence, the proportion of Canadian drivers who want the speed limit raised to $130$ kph. Your estimate must be accurate to within $5\%$. How many drivers must you survey,if your initial estimate of the proportion is $0.60$? I know that $99\%$ is $2.575$ but i dont know how to set up the problem. I don't think that $130$ kph even has anything to do with the problem. I think i am over thinking this question.",,['statistics']
2,Sum of waves with random phase and amplitudes as random sum of cosines,Sum of waves with random phase and amplitudes as random sum of cosines,,"I need to derive the average and variance of the amplitude of a sum of waves with the form: $$ \sum_{k=1}^N e^{j\delta_k} A_k $$ where  $$A_k = \sum_{i=1}^N \cos(\phi_k - \phi_i)$$ The random variables $\delta$ and $\phi$ are independent and uniformly distributed. $\phi$ between $-\pi$ and $\pi$ and $\delta$ between an arbitrary constant $-\omega/2$ and $\omega/2$. Also, I can consider $N$ arbitrarily large. Any suggestions? Thanks for any help.","I need to derive the average and variance of the amplitude of a sum of waves with the form: $$ \sum_{k=1}^N e^{j\delta_k} A_k $$ where  $$A_k = \sum_{i=1}^N \cos(\phi_k - \phi_i)$$ The random variables $\delta$ and $\phi$ are independent and uniformly distributed. $\phi$ between $-\pi$ and $\pi$ and $\delta$ between an arbitrary constant $-\omega/2$ and $\omega/2$. Also, I can consider $N$ arbitrarily large. Any suggestions? Thanks for any help.",,"['probability', 'statistics']"
3,How will law of large number changes if we have Indepedent but not identically distributed?,How will law of large number changes if we have Indepedent but not identically distributed?,,How will law of large number changes if we have Indepedent but not identically distributed ?,How will law of large number changes if we have Indepedent but not identically distributed ?,,"['probability', 'statistics']"
4,Sampling with no duplicates,Sampling with no duplicates,,"I am sampling a population of unknown size and unknown distribution. The sample will be taken over distinct time intervals, but I have to reject any duplicates in the given time interval. The sample sizes over each time interval will vary in size. The sample will then be combined to form the population sample. My goal is to estimate the size of the population. Example: Time period 1) $\{x_1,x_4,x_8,x_8,x_8\}$ reject fourth and fifth observation and I am left with $\{x_1,x_4,x_8\}$ as my sample in time period 1. Time period 2) $\{ x_{10}, x_1, x_7,x_3, x_8, x_{10}, x_{11}, x_7 \}$, reject sixth and eight observations and I am left with $\{ x_{10}, x_1, x_7,x_3, x_8, x_{11} \}$ as my sample in time period 2. I now combine my sample from time periods 1 and 2 to get $\{x_1, x_2, x_3, x_4, x_7, x_8, x_8, x_{10}, x_{11} \}$ My question concerns the process that I am following. It appears to be selection bias. What can I do to address it? Is there some way to weight the samples with multiple duplicates more heavily when I make my estimation. Are there any other issues I should be aware of?","I am sampling a population of unknown size and unknown distribution. The sample will be taken over distinct time intervals, but I have to reject any duplicates in the given time interval. The sample sizes over each time interval will vary in size. The sample will then be combined to form the population sample. My goal is to estimate the size of the population. Example: Time period 1) $\{x_1,x_4,x_8,x_8,x_8\}$ reject fourth and fifth observation and I am left with $\{x_1,x_4,x_8\}$ as my sample in time period 1. Time period 2) $\{ x_{10}, x_1, x_7,x_3, x_8, x_{10}, x_{11}, x_7 \}$, reject sixth and eight observations and I am left with $\{ x_{10}, x_1, x_7,x_3, x_8, x_{11} \}$ as my sample in time period 2. I now combine my sample from time periods 1 and 2 to get $\{x_1, x_2, x_3, x_4, x_7, x_8, x_8, x_{10}, x_{11} \}$ My question concerns the process that I am following. It appears to be selection bias. What can I do to address it? Is there some way to weight the samples with multiple duplicates more heavily when I make my estimation. Are there any other issues I should be aware of?",,"['probability', 'statistics', 'estimation', 'sampling']"
5,Rao-Blackwell Theorem corollary,Rao-Blackwell Theorem corollary,,"I have as corollary to the Rao-Blackwell theorem: If a minimum variance unbiased estimator $\hat \theta$ for $\theta$ exists, there is a function $\hat \theta_T$ of the minimal sufficient statistic $T$ for $\theta$ which is a minimum variance unbiased estimator. Do we need $T$ to be minimal sufficient though? It seems to me that just being sufficient is enough, but whenever my lecturer used this result in practice he showed that the $T$ wasn't just sufficient, but minimal sufficient.","I have as corollary to the Rao-Blackwell theorem: If a minimum variance unbiased estimator $\hat \theta$ for $\theta$ exists, there is a function $\hat \theta_T$ of the minimal sufficient statistic $T$ for $\theta$ which is a minimum variance unbiased estimator. Do we need $T$ to be minimal sufficient though? It seems to me that just being sufficient is enough, but whenever my lecturer used this result in practice he showed that the $T$ wasn't just sufficient, but minimal sufficient.",,['statistics']
6,How do I calculate if a line on a graph is generally far away from another line?,How do I calculate if a line on a graph is generally far away from another line?,,disclaimer : I'm (evidently) not a mathematician/statistician and a total n00b so if this question is too basic for the community let me know! Also excuse any misuse of terminology! Say I have two lines on a graph: Visually I can see that generally the grey line is lower than the red line. But how can I say this mathematically so that it results in a true or false? Standard Deviation If I apply standard deviation on the red line I can easily see if any points in the grey bar deviate from the range of the red. But how can I say that this generally happens for all the points? Is it about taking the average value of the grey line and seeing if that average value is within or outside the standard deviation of the red line?,disclaimer : I'm (evidently) not a mathematician/statistician and a total n00b so if this question is too basic for the community let me know! Also excuse any misuse of terminology! Say I have two lines on a graph: Visually I can see that generally the grey line is lower than the red line. But how can I say this mathematically so that it results in a true or false? Standard Deviation If I apply standard deviation on the red line I can easily see if any points in the grey bar deviate from the range of the red. But how can I say that this generally happens for all the points? Is it about taking the average value of the grey line and seeing if that average value is within or outside the standard deviation of the red line?,,"['statistics', 'standard-deviation']"
7,How to calculate Fisher Information (FI) matrix for Multivariate Normal Distribution (MN),How to calculate Fisher Information (FI) matrix for Multivariate Normal Distribution (MN),,"Below is the gradient (score) of the MN log likelihood function L for n=1 observation. I originally attempted to calculate the Hessian matrix  but ran into difficulty calculating 2nd order derivatives wrt μ and Σ,  to obtain FI = -E(Hessian). MLEs for μ and Σ can be derived from these equations $dL/du = Σ^{-1}(X−u)   \quad,\quad   dL/dΣ = −(1/2)Σ^{-1} + (1/2)Σ^{-1} (X−μ)(X−μ)′\ Σ^{-1}$ Alternatively, I calculated the expectation of the outer product of the gradient vector for the MN FI matrix as | Σ^-1    0    |               FI = n |              |                      | 0   1/2 Σ^-2 | under assumptions of  E(X-μ)=0,   E(X-μ)${^2}$ = E[(X-μ)(X-μ)']= Σ and [E(X-μ)(X-μ)']${^2}$ = E(X-u)${^4}$ = 3Σ${^2}$. I think... this looks like the multivariate analog to the well known univariate normal distribution information matrix below, where Q${^2}$ is scalar variance parameter, E(x-μ)=0, E(x-μ)${^2}$ = E[(x-μ)(x-μ)]= Q${^2}$  and E(x-μ)${^4}$ = 3Q${^4}$ (kurtosis) | Q^-2    0    |               FI = n |              |                      | 0   1/2 Q^-4 | QUESTION: Can one infer a MN kurtosis of  E(X-u)${^4}$ = 3Σ${^2}$ from the well known UN kurtosis of  E(x-μ)${^4}$ = 3Q${^4}$ for this MN FI matrix derivation ??? The E(X-u)${^4}$ is needed for the [E(dL/dΣ)]${^2}$ element in outer product of gradient. Any thoughts or comments please, Thank you","Below is the gradient (score) of the MN log likelihood function L for n=1 observation. I originally attempted to calculate the Hessian matrix  but ran into difficulty calculating 2nd order derivatives wrt μ and Σ,  to obtain FI = -E(Hessian). MLEs for μ and Σ can be derived from these equations $dL/du = Σ^{-1}(X−u)   \quad,\quad   dL/dΣ = −(1/2)Σ^{-1} + (1/2)Σ^{-1} (X−μ)(X−μ)′\ Σ^{-1}$ Alternatively, I calculated the expectation of the outer product of the gradient vector for the MN FI matrix as | Σ^-1    0    |               FI = n |              |                      | 0   1/2 Σ^-2 | under assumptions of  E(X-μ)=0,   E(X-μ)${^2}$ = E[(X-μ)(X-μ)']= Σ and [E(X-μ)(X-μ)']${^2}$ = E(X-u)${^4}$ = 3Σ${^2}$. I think... this looks like the multivariate analog to the well known univariate normal distribution information matrix below, where Q${^2}$ is scalar variance parameter, E(x-μ)=0, E(x-μ)${^2}$ = E[(x-μ)(x-μ)]= Q${^2}$  and E(x-μ)${^4}$ = 3Q${^4}$ (kurtosis) | Q^-2    0    |               FI = n |              |                      | 0   1/2 Q^-4 | QUESTION: Can one infer a MN kurtosis of  E(X-u)${^4}$ = 3Σ${^2}$ from the well known UN kurtosis of  E(x-μ)${^4}$ = 3Q${^4}$ for this MN FI matrix derivation ??? The E(X-u)${^4}$ is needed for the [E(dL/dΣ)]${^2}$ element in outer product of gradient. Any thoughts or comments please, Thank you",,"['statistics', 'derivatives', 'probability-distributions', 'matrix-calculus', 'parameter-estimation']"
8,How to use Hoeffding Inequality?,How to use Hoeffding Inequality?,,"I am new to Hoeffding Inequality and can someone kindly explain to me how to use it? I need to solve the following problem. If $\mu = 0.9$, use Hoeffding Inequality to bound the probability that a sample of 10 marbles will have $k \leq 0.1$. $\mu$ refers to the probability of red marbles in a bin of red and green marbles and $k$ refers to the fraction of red marbles within the sample Hoeffding Inequality is given as $P(|k - \mu| > \epsilon) \leq 2e^{-2\epsilon^2 N}$ for any $\epsilon > 0$. I can't relate binomial distribution to Hoeffding Inequality.","I am new to Hoeffding Inequality and can someone kindly explain to me how to use it? I need to solve the following problem. If $\mu = 0.9$, use Hoeffding Inequality to bound the probability that a sample of 10 marbles will have $k \leq 0.1$. $\mu$ refers to the probability of red marbles in a bin of red and green marbles and $k$ refers to the fraction of red marbles within the sample Hoeffding Inequality is given as $P(|k - \mu| > \epsilon) \leq 2e^{-2\epsilon^2 N}$ for any $\epsilon > 0$. I can't relate binomial distribution to Hoeffding Inequality.",,"['statistics', 'machine-learning']"
9,Hypothesis Testing Confusion - Laboratory Mice,Hypothesis Testing Confusion - Laboratory Mice,,"I've slowly been building up some confidence on these types of problems but after the easy plug-n-chug I get very confused on what to do. There is a solution I found online for this question (number 1, solution 1) but I get confused on the very last step, where they say .046 > .05. The question is: A colony of laboratory mice consists of several thousand mice. The average weight of all the mice is 32 grams with a standard deviation of 4 grams. A laboratory assistant was asked by a scientist to select 25 mice for an experiment. However, before performing the experiment, the scientist decided to weigh the mice as an indicator of whether the assistants selection constituted a random sample or whether it was made with some unconscious bias (perhaps the mice selected were the ones that were slowest in avoiding the assistant, which might indicate some inferiority about this group). If the sample mean of the 25 mice was 30.4, would this be significant evidence, at the 5 percent level of significance, against the hypothesis that the selection constituted a random sample? My steps were: Ho = mu-not is 32 grams (selection is random) H1 = mu is not 32 grams (selection is not random) standard deviation is 4 grams n = 25 mice x-bar (sample mean) = 30.4 Confidence Interval is 95% (level of significance is .05) All I really did was find the p-value using: (x-bar - mu) / (std dev / sqrt(n)) p-value: |30.4 - 32| / (4/5) = 2 The probability of rejecting Ho = (Z > 2) Value based on the confidence interval would be the level of significance divided by 2 since this is a two-sided confidence interval. Looking this up in a z-table I got 1.96. However, I don't know where to go from here especially since the solutions page has .046 < .05, which I'm not sure how to get. Can someone please explain this?","I've slowly been building up some confidence on these types of problems but after the easy plug-n-chug I get very confused on what to do. There is a solution I found online for this question (number 1, solution 1) but I get confused on the very last step, where they say .046 > .05. The question is: A colony of laboratory mice consists of several thousand mice. The average weight of all the mice is 32 grams with a standard deviation of 4 grams. A laboratory assistant was asked by a scientist to select 25 mice for an experiment. However, before performing the experiment, the scientist decided to weigh the mice as an indicator of whether the assistants selection constituted a random sample or whether it was made with some unconscious bias (perhaps the mice selected were the ones that were slowest in avoiding the assistant, which might indicate some inferiority about this group). If the sample mean of the 25 mice was 30.4, would this be significant evidence, at the 5 percent level of significance, against the hypothesis that the selection constituted a random sample? My steps were: Ho = mu-not is 32 grams (selection is random) H1 = mu is not 32 grams (selection is not random) standard deviation is 4 grams n = 25 mice x-bar (sample mean) = 30.4 Confidence Interval is 95% (level of significance is .05) All I really did was find the p-value using: (x-bar - mu) / (std dev / sqrt(n)) p-value: |30.4 - 32| / (4/5) = 2 The probability of rejecting Ho = (Z > 2) Value based on the confidence interval would be the level of significance divided by 2 since this is a two-sided confidence interval. Looking this up in a z-table I got 1.96. However, I don't know where to go from here especially since the solutions page has .046 < .05, which I'm not sure how to get. Can someone please explain this?",,"['statistics', 'hypothesis-testing']"
10,What is the moment generating function of Dirichlet distribution?,What is the moment generating function of Dirichlet distribution?,,"I want to find the moment generating function (or the Laplace transform) of the Dirichlet distribution. I know the moments can be found using the gamma functions as follows  :$$E\left[\prod_{i=1}^K x_i^{\beta_i}\right]=\frac{B\left(\boldsymbol{\alpha}+\boldsymbol{\beta}\right)}{B\left(\boldsymbol{\alpha}\right)}=\frac{\Gamma\left(\sum_{i=1}^{n}\alpha_{i}\right)}{\Gamma\left(\sum_{i=1}^{n}\alpha_{i}+\beta_{i}\right)}\times\prod_{i=1}^{n}\frac{\Gamma\left(\alpha_{i}+\beta_{i}\right)}{\Gamma\left(\alpha_{i}\right)},$$ but what I am really interested in is the functional form of the MGF (or the Laplace transform) so that it can be used to find other sampling distributions thereof or any other transformation of the Dirichlet also.","I want to find the moment generating function (or the Laplace transform) of the Dirichlet distribution. I know the moments can be found using the gamma functions as follows  :$$E\left[\prod_{i=1}^K x_i^{\beta_i}\right]=\frac{B\left(\boldsymbol{\alpha}+\boldsymbol{\beta}\right)}{B\left(\boldsymbol{\alpha}\right)}=\frac{\Gamma\left(\sum_{i=1}^{n}\alpha_{i}\right)}{\Gamma\left(\sum_{i=1}^{n}\alpha_{i}+\beta_{i}\right)}\times\prod_{i=1}^{n}\frac{\Gamma\left(\alpha_{i}+\beta_{i}\right)}{\Gamma\left(\alpha_{i}\right)},$$ but what I am really interested in is the functional form of the MGF (or the Laplace transform) so that it can be used to find other sampling distributions thereof or any other transformation of the Dirichlet also.",,"['probability', 'statistics']"
11,multinomial hypothesis testing,multinomial hypothesis testing,,"Suppose we have data $(X_1, X_2, X_3)$ (I'll refer the categories as 1, 2, 3) that has a multinomial distribution with parameters $n$ and $(p_1, p_2, p_3)$ and we want to test the hypothesis that $p_1>p_2>p_3$.  I am trying to figure out an exact testing procedure for this. One idea I had would be to first condition $X_3$ on $X_1$ i.e. see how many times 3 was realized when the options were 3 and 2 only.  According to the hypothesis, this should be less than 1/2 and we could construct a simple binomial test for this since $X_3|X_1$ has a binomial distribution with parameters $n-X_1$ and $\frac{p_3}{p_2+p_3}$ and reject if the realization of 3 exceeded some critical value $k$. Secondly, we could perform a similar test for $X_2|X_3$ and if the hypothesis is true we should see 2 chosen less than half the time when the options are only 1 or 2.  A similar binomial test would work for testing this.  Overall, we could reject the original hypothesis if either of these tests reject. However, controlling size seems difficult to me in this case since the tests are not independent (at least they obviously seem to not be). Is there a better approach to testing this hypothesis?  I have considered confidence intervals for the $p$'s, but not sure if I should use two-side or one-sided.  I have seen procedures for confidence intervals for $p_i-p_j$ for $i\neq j$, but these rely on asymptotic approximations. Anyway, any help or suggestions or references would be greatly appreciated.","Suppose we have data $(X_1, X_2, X_3)$ (I'll refer the categories as 1, 2, 3) that has a multinomial distribution with parameters $n$ and $(p_1, p_2, p_3)$ and we want to test the hypothesis that $p_1>p_2>p_3$.  I am trying to figure out an exact testing procedure for this. One idea I had would be to first condition $X_3$ on $X_1$ i.e. see how many times 3 was realized when the options were 3 and 2 only.  According to the hypothesis, this should be less than 1/2 and we could construct a simple binomial test for this since $X_3|X_1$ has a binomial distribution with parameters $n-X_1$ and $\frac{p_3}{p_2+p_3}$ and reject if the realization of 3 exceeded some critical value $k$. Secondly, we could perform a similar test for $X_2|X_3$ and if the hypothesis is true we should see 2 chosen less than half the time when the options are only 1 or 2.  A similar binomial test would work for testing this.  Overall, we could reject the original hypothesis if either of these tests reject. However, controlling size seems difficult to me in this case since the tests are not independent (at least they obviously seem to not be). Is there a better approach to testing this hypothesis?  I have considered confidence intervals for the $p$'s, but not sure if I should use two-side or one-sided.  I have seen procedures for confidence intervals for $p_i-p_j$ for $i\neq j$, but these rely on asymptotic approximations. Anyway, any help or suggestions or references would be greatly appreciated.",,['probability']
12,Hoeffding’s inequality extension,Hoeffding’s inequality extension,,"In Hoeffding’s inequality we assume that the random variables $X_i$ ,$i=1,..,n$ are i.i.d. and bounded . Is there any extension to Hoeffding’s inequality  for the case that $X_i$ are identically disributed but not independent? Thanks","In Hoeffding’s inequality we assume that the random variables $X_i$ ,$i=1,..,n$ are i.i.d. and bounded . Is there any extension to Hoeffding’s inequality  for the case that $X_i$ are identically disributed but not independent? Thanks",,"['probability', 'probability-theory', 'statistics', 'machine-learning']"
13,Steve Nash’s expected value from his one-and-one free throw situation is 1.72 points. What is his free-throw percentage?,Steve Nash’s expected value from his one-and-one free throw situation is 1.72 points. What is his free-throw percentage?,,"The one-on-one free throw situation works like this - for the first throw, if you make it, you get to do it again. If you miss, you don't get another chance. If you make it the second time, you get two points total. If Steve Nash's expected value is 1.72 points on average, what is his free throw percentage (number of times he makes the basket)? Please do not research this on the internet as Steve Nash just retired with the highest free throw percentage, so the answer would be on the internet.","The one-on-one free throw situation works like this - for the first throw, if you make it, you get to do it again. If you miss, you don't get another chance. If you make it the second time, you get two points total. If Steve Nash's expected value is 1.72 points on average, what is his free throw percentage (number of times he makes the basket)? Please do not research this on the internet as Steve Nash just retired with the highest free throw percentage, so the answer would be on the internet.",,"['probability', 'statistics', 'quadratics']"
14,Maximum density linear combination chi squares,Maximum density linear combination chi squares,,"I have a positive linear combination of chi square variables  \begin{equation*}  X=\sum_{i=1}^k \lambda_i \chi^2(r_i)  \end{equation*} the degrees of freedom satisfy $r_i>1$. I need an upperbound of the maximum density of $X$. I searched for results on the maximum of convolution functions etc. It is also important to know that the closed form expression of density of $X$ is not known (and may not exist). I have bounds of the density of $\chi^2(r_i)$ when $r_i>1$,  namely $1$.","I have a positive linear combination of chi square variables  \begin{equation*}  X=\sum_{i=1}^k \lambda_i \chi^2(r_i)  \end{equation*} the degrees of freedom satisfy $r_i>1$. I need an upperbound of the maximum density of $X$. I searched for results on the maximum of convolution functions etc. It is also important to know that the closed form expression of density of $X$ is not known (and may not exist). I have bounds of the density of $\chi^2(r_i)$ when $r_i>1$,  namely $1$.",,"['statistics', 'inequality', 'exponential-function']"
15,Probability of co-occurence,Probability of co-occurence,,"Of total $N$ people, $m$ people are good at mathematics and $c$ people are good at computer science. What is the expected number of people good at both mathematics and computer science? Or what is the probability that $r$ people are good at both mathematics and computer science.  The formula I have derived is $$P(r)= C(N,r)*C(N-r , m-r) * C(N-m, c-r) / ( C(N,m) * C(N,n))  $$ $N$=Total people $m$=number of people good at math $c$=number of people good at computer $r$= number of people good at both But it contains $n!$, $p!$, $c!$ etc which is difficult to compute for large values (my real problem has large values for all of these). I am looking for a neat workable formula, I am hoping it exist since it is such a basic problem. Note: I am interested in the case where peoples are fixed and get used up. So it's basically like pushing peoples around in a given number of position.","Of total $N$ people, $m$ people are good at mathematics and $c$ people are good at computer science. What is the expected number of people good at both mathematics and computer science? Or what is the probability that $r$ people are good at both mathematics and computer science.  The formula I have derived is $$P(r)= C(N,r)*C(N-r , m-r) * C(N-m, c-r) / ( C(N,m) * C(N,n))  $$ $N$=Total people $m$=number of people good at math $c$=number of people good at computer $r$= number of people good at both But it contains $n!$, $p!$, $c!$ etc which is difficult to compute for large values (my real problem has large values for all of these). I am looking for a neat workable formula, I am hoping it exist since it is such a basic problem. Note: I am interested in the case where peoples are fixed and get used up. So it's basically like pushing peoples around in a given number of position.",,"['probability', 'statistics']"
16,Integration of gaussian divided by square root of -log(1-x) - does the Meijer G function help me?,Integration of gaussian divided by square root of -log(1-x) - does the Meijer G function help me?,,"After some modelling of my data I came to the following integral: $$ \int_0^{1}\dfrac{exp{\left(-\dfrac{\left(x-\mu\right)^2}{2\,\sigma^2}\right)}}{\sqrt{-\log{(1-x)}}} $$ I cannot solve it, and neither can mathematica, maxima or sympy. I would like to know how to solve such integrals in general and I will pursue any pointers. I know that often such integrals can be solved by expressing the function in forms of a confluent hypergeometric function or something even more general, like the meijer G function, but I do not know how to do that. I want to calculate this integral because I want to optimize the likelihood of the measurements, modelled as gaussian distributions, given the distribution. The overall distribution arises as the distribution of function values of a gaussian distribution where the values of x are randomly distributed. Note that the distribution itself can be integrated: $$ \dfrac{d\,\mathrm{erf}\left({\sqrt{-\log{\left(1-x\right)}}}\right)}{dx} = \dfrac{1}{\sqrt{-log\left(1-x\right)}} $$","After some modelling of my data I came to the following integral: $$ \int_0^{1}\dfrac{exp{\left(-\dfrac{\left(x-\mu\right)^2}{2\,\sigma^2}\right)}}{\sqrt{-\log{(1-x)}}} $$ I cannot solve it, and neither can mathematica, maxima or sympy. I would like to know how to solve such integrals in general and I will pursue any pointers. I know that often such integrals can be solved by expressing the function in forms of a confluent hypergeometric function or something even more general, like the meijer G function, but I do not know how to do that. I want to calculate this integral because I want to optimize the likelihood of the measurements, modelled as gaussian distributions, given the distribution. The overall distribution arises as the distribution of function values of a gaussian distribution where the values of x are randomly distributed. Note that the distribution itself can be integrated: $$ \dfrac{d\,\mathrm{erf}\left({\sqrt{-\log{\left(1-x\right)}}}\right)}{dx} = \dfrac{1}{\sqrt{-log\left(1-x\right)}} $$",,"['calculus', 'integration', 'statistics', 'probability-distributions', 'maxima-software']"
17,In Bayesian Statistic how do you usually find out what is the distribution of the unknown?,In Bayesian Statistic how do you usually find out what is the distribution of the unknown?,,"To estimate the posterior we have $$p(\theta|x) = \frac{p(\theta)*p(x|\theta)}{\sum p(\theta ')*p(x|\theta ')}$$ $x$ is usually the experimentally sampled data, and $\theta$ is the model, but both $p(x|\theta)$ and $p(\theta)$ is unknown, how do you usually measure those two quantities?","To estimate the posterior we have $$p(\theta|x) = \frac{p(\theta)*p(x|\theta)}{\sum p(\theta ')*p(x|\theta ')}$$ $x$ is usually the experimentally sampled data, and $\theta$ is the model, but both $p(x|\theta)$ and $p(\theta)$ is unknown, how do you usually measure those two quantities?",,"['statistics', 'statistical-inference', 'bayesian', 'bayes-theorem']"
18,make the mean of 2 data sets the same,make the mean of 2 data sets the same,,"I am in the process of computing my student's final scores and for some reason I couldn't figure this step out: If I have 2 data sets of scores in the range [0,40] but one data set has a different mean than the other, how can I make the mean the same for both data sets such that: Those who got a 40 will still get a 40 and The new scores will still be in the [0,40] range?","I am in the process of computing my student's final scores and for some reason I couldn't figure this step out: If I have 2 data sets of scores in the range [0,40] but one data set has a different mean than the other, how can I make the mean the same for both data sets such that: Those who got a 40 will still get a 40 and The new scores will still be in the [0,40] range?",,"['statistics', 'data-analysis']"
19,Does Bivariate Normal have a monotone likelihood ratio?,Does Bivariate Normal have a monotone likelihood ratio?,,"In general, with all parameters unknown I think the answer to this question is no. I think this because in this instance we would have a curved multivariate exponential family. Is this reasoning correct? Now, suppose the only unknown parameters are the correlation, $\rho$, and one of the means, $\mu_1$, then in this (or any other) particular instance does the bivariate normal distribution have a monotone likelihood ratio?","In general, with all parameters unknown I think the answer to this question is no. I think this because in this instance we would have a curved multivariate exponential family. Is this reasoning correct? Now, suppose the only unknown parameters are the correlation, $\rho$, and one of the means, $\mu_1$, then in this (or any other) particular instance does the bivariate normal distribution have a monotone likelihood ratio?",,"['probability', 'statistics', 'normal-distribution', 'bivariate-distributions']"
20,uncertainty of slope.,uncertainty of slope.,,"i have a graph that i fitted a line on it using least squares fit. Now i want to calculate the uncertainty of slope. i calculated the standard error of slope and now i have this question: the uncertainty of slope is ""slope ± standard error"" or it is the confidence interval???! please help me. i really need the answer. i searched in many books but unfortunately i couldn't find the answer.","i have a graph that i fitted a line on it using least squares fit. Now i want to calculate the uncertainty of slope. i calculated the standard error of slope and now i have this question: the uncertainty of slope is ""slope ± standard error"" or it is the confidence interval???! please help me. i really need the answer. i searched in many books but unfortunately i couldn't find the answer.",,['statistics']
21,One tailed or two tailed,One tailed or two tailed,,"Ok so this the question: An administrator at a medium-sized hospital tells the board of directors that, among patients received at the Emergency room and eventually admitted to a ward, the average length of time between arriving at Emergency and being admitted to the ward is 4 hours and 15 minutes. One of the board members believes this figure is an underestimate and checks the records for a sample of 25 patients. The sample mean is 6 hours and 30 minutes. Assuming that the population standard deviation is 3 hours, and that the length of time spent in Emergency is normally distributed, use the sample data to determine whether there is sufficient evidence at the 5% level of significance to assert that the administrator's claim is an underestimate. The first scenario is that that for the null hypothesis the mean is equals to 4hrs 15mins. For the alternative hypothesis the mean is not equals to 4hrs 15mins. So it could be less or more. However the question says that one the board memeber thinks that it might be an UNDERESTIMATE so that means the alternative hypothesis must be higher than 4hrs 15 mins? Right? So that opens the possibility to a another scenario which is: In the null hypothesis the mean is equals to or less than 4hrs 15mins. And in the alternative hypothesis the mean is greater than 4hrs 15mins. So the first scenario is a two tailed test and the second scenario is one tailed test. The question asks me whether it is a one tailed test or two tailed, and there is only one correct answer. But I am not sure which one is correct. From my perspective both make sense. If someone could give me the correct answer and explain it to me it would help me out a lot.","Ok so this the question: An administrator at a medium-sized hospital tells the board of directors that, among patients received at the Emergency room and eventually admitted to a ward, the average length of time between arriving at Emergency and being admitted to the ward is 4 hours and 15 minutes. One of the board members believes this figure is an underestimate and checks the records for a sample of 25 patients. The sample mean is 6 hours and 30 minutes. Assuming that the population standard deviation is 3 hours, and that the length of time spent in Emergency is normally distributed, use the sample data to determine whether there is sufficient evidence at the 5% level of significance to assert that the administrator's claim is an underestimate. The first scenario is that that for the null hypothesis the mean is equals to 4hrs 15mins. For the alternative hypothesis the mean is not equals to 4hrs 15mins. So it could be less or more. However the question says that one the board memeber thinks that it might be an UNDERESTIMATE so that means the alternative hypothesis must be higher than 4hrs 15 mins? Right? So that opens the possibility to a another scenario which is: In the null hypothesis the mean is equals to or less than 4hrs 15mins. And in the alternative hypothesis the mean is greater than 4hrs 15mins. So the first scenario is a two tailed test and the second scenario is one tailed test. The question asks me whether it is a one tailed test or two tailed, and there is only one correct answer. But I am not sure which one is correct. From my perspective both make sense. If someone could give me the correct answer and explain it to me it would help me out a lot.",,['statistics']
22,Why does the probability of a bivariate Poisson distribution behaves like this? (see example),Why does the probability of a bivariate Poisson distribution behaves like this? (see example),,"I am a beginner in working with statistics and I wanted to generate a bivariate Poisson distribution $(X_1, X_2)$ and to do so, I did according to the indication found on wikipedia (bottom of the page, http://en.wikipedia.org/wiki/Poisson_distribution ), therefore, I have generated three independent random variables which have a Poisson distribution $(Y_1, Y_2, Y_3)$, with means $\lambda_1 = \lambda_2 = \lambda_3 = 2$. Provided I have set: $X_1 = Y_1 + Y_3$ $X_2 = Y_2 + Y_3$ Then, $X_1$ ~ Poisson($2+2$) = Poisson($4$) $X_2$ ~ Poisson($2+2$) = Poisson($4$) In order to compute the bivariate probability I use the formula found on wikipedia (bottom of the page, http://en.wikipedia.org/wiki/Poisson_distribution ). When I try to compute the following probabilities (both in Matlab - set the format short - and on the paper), I obtain: $P(X_1 = 4, X_2 = 4) = 0.0446$ $P(X_1 = 3, X_2 = 3) = 0.0474$ Basically, it indicates that $P(X_1 = 4, X_2 = 4) < P (X_1 = 3, X_2 = 3)$, which seems completely counterintuitive, since the mean for both random variables $X_1$ and $X_2$ is $4$. Initially, I have doubted my Matlab code and my calculation skills, but I tested it thouroughly and I obtain the same results. Is there any potential explanation for this or I am simply wrong in performing my calculations? Thank you all.","I am a beginner in working with statistics and I wanted to generate a bivariate Poisson distribution $(X_1, X_2)$ and to do so, I did according to the indication found on wikipedia (bottom of the page, http://en.wikipedia.org/wiki/Poisson_distribution ), therefore, I have generated three independent random variables which have a Poisson distribution $(Y_1, Y_2, Y_3)$, with means $\lambda_1 = \lambda_2 = \lambda_3 = 2$. Provided I have set: $X_1 = Y_1 + Y_3$ $X_2 = Y_2 + Y_3$ Then, $X_1$ ~ Poisson($2+2$) = Poisson($4$) $X_2$ ~ Poisson($2+2$) = Poisson($4$) In order to compute the bivariate probability I use the formula found on wikipedia (bottom of the page, http://en.wikipedia.org/wiki/Poisson_distribution ). When I try to compute the following probabilities (both in Matlab - set the format short - and on the paper), I obtain: $P(X_1 = 4, X_2 = 4) = 0.0446$ $P(X_1 = 3, X_2 = 3) = 0.0474$ Basically, it indicates that $P(X_1 = 4, X_2 = 4) < P (X_1 = 3, X_2 = 3)$, which seems completely counterintuitive, since the mean for both random variables $X_1$ and $X_2$ is $4$. Initially, I have doubted my Matlab code and my calculation skills, but I tested it thouroughly and I obtain the same results. Is there any potential explanation for this or I am simply wrong in performing my calculations? Thank you all.",,"['statistics', 'poisson-distribution', 'bivariate-distributions']"
23,a variant of MLE of a normal distribution,a variant of MLE of a normal distribution,,"It is well-known that if we have ""n"" sample observations from normal distribution with unknown mean, then the sample mean would be the MLE for the mean of the normal distribution. However, let's assume that before we collect our sample, somebody has already collected ""n"" sample observations, and the only information we get from that guy is that all the ""n"" sample observations were smaller or equal to A for some real number A. Is there any way we could somehow use ""n"" and ""A"" into MLE for the mean when we collect our sample? Any input would be greatly appreciated. I'm just curious.","It is well-known that if we have ""n"" sample observations from normal distribution with unknown mean, then the sample mean would be the MLE for the mean of the normal distribution. However, let's assume that before we collect our sample, somebody has already collected ""n"" sample observations, and the only information we get from that guy is that all the ""n"" sample observations were smaller or equal to A for some real number A. Is there any way we could somehow use ""n"" and ""A"" into MLE for the mean when we collect our sample? Any input would be greatly appreciated. I'm just curious.",,"['probability', 'statistics', 'bayesian']"
24,how to prove this function is a probability measure in $U_B$,how to prove this function is a probability measure in,U_B,"Let $(\Omega, U, P)$ be a probability space. and $B\in U$, $P(B)\gt 0$ $U_B =\{A: A=B\cap C, C\in U\}$ its class in $\Omega$ is a $\sigma$-algebra and $P_B : U_B \to \Bbb R$ $A \to P_B(A)=\frac{P(A)}{P(B)}$ how to prove this function is a measurable space in $U_B$ What I know that is the following; measurable space is defined as $U$ be a $\sigma$-algebra in $\Omega$ $P: U  \to [0,1]$ $A \to P(A)$ i)  $\forall A \in U$, $P(A) \ge 0$ ii) $P(\Omega)=1$ iii)$A_i \cap A_j = \emptyset$ $P(\bigcup_{n=1}^\infty A_n)=\sum^\infty_{n=1)} P(A_n)$ Thank you for helping :)","Let $(\Omega, U, P)$ be a probability space. and $B\in U$, $P(B)\gt 0$ $U_B =\{A: A=B\cap C, C\in U\}$ its class in $\Omega$ is a $\sigma$-algebra and $P_B : U_B \to \Bbb R$ $A \to P_B(A)=\frac{P(A)}{P(B)}$ how to prove this function is a measurable space in $U_B$ What I know that is the following; measurable space is defined as $U$ be a $\sigma$-algebra in $\Omega$ $P: U  \to [0,1]$ $A \to P(A)$ i)  $\forall A \in U$, $P(A) \ge 0$ ii) $P(\Omega)=1$ iii)$A_i \cap A_j = \emptyset$ $P(\bigcup_{n=1}^\infty A_n)=\sum^\infty_{n=1)} P(A_n)$ Thank you for helping :)",,"['probability', 'probability-theory', 'statistics', 'stochastic-processes']"
25,"Is an ARMA(p,0) process invertible?","Is an ARMA(p,0) process invertible?",,"Consider an ARMA(2,0) process. Is the process invertible? $(1-\phi_1L - \phi_2L^2)X_t = u_t$ I understand that for the process to be invertible, I must assess the root of on the MA side of the equation, however in this case it doesn't exist. Would the process still be invertible or not? Would the answer be true for an ARMA(p,0) model?","Consider an ARMA(2,0) process. Is the process invertible? $(1-\phi_1L - \phi_2L^2)X_t = u_t$ I understand that for the process to be invertible, I must assess the root of on the MA side of the equation, however in this case it doesn't exist. Would the process still be invertible or not? Would the answer be true for an ARMA(p,0) model?",,"['statistics', 'time-series']"
26,Expectation subscript notation,Expectation subscript notation,,"http://www.stat.cmu.edu/~larry/=stat705/Lecture8.pdf At the bottom of page 1 in this pdf, they say the expectation is taken over theta, but I don't understand why the expectation isn't over X when the integration is over x. I thought it might be a mistake but it seems the same everywhere else so it must be correct.","http://www.stat.cmu.edu/~larry/=stat705/Lecture8.pdf At the bottom of page 1 in this pdf, they say the expectation is taken over theta, but I don't understand why the expectation isn't over X when the integration is over x. I thought it might be a mistake but it seems the same everywhere else so it must be correct.",,"['probability', 'statistics']"
27,Invariance of MLE [closed],Invariance of MLE [closed],,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question Random sample has pdf:$f(x|\theta)$ Then the MLE of $\theta$ is  $$\hat{\theta}=\arg\max_{ \theta}\sum_{i=1}^n\log f(x_i|\theta)$$ $\tau=g(\theta)$ My question is why $\tau$ 's MLE is  $$\hat{\tau}=\arg \max_\tau\left[\max_{\theta\in g^{-1}(\tau)}\sum_{i=1}^n\log f(x_i|\theta) \right]$$,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question Random sample has pdf:$f(x|\theta)$ Then the MLE of $\theta$ is  $$\hat{\theta}=\arg\max_{ \theta}\sum_{i=1}^n\log f(x_i|\theta)$$ $\tau=g(\theta)$ My question is why $\tau$ 's MLE is  $$\hat{\tau}=\arg \max_\tau\left[\max_{\theta\in g^{-1}(\tau)}\sum_{i=1}^n\log f(x_i|\theta) \right]$$,,['statistics']
28,Double Integral of an Exponential Function with an Absolute Value in the Numerator of the Exponent,Double Integral of an Exponential Function with an Absolute Value in the Numerator of the Exponent,,"This is a question related to statistics, but my major concern relates to the setup and evaluation of integrals. So I decided this question was better suited for Mathematics Exchange than CV. I know the following... $ E[S(x)]=\mu , \\ Var[S(x)]= \sigma^{2} , \\ \rho(h)= \mathrm{e}^{\left(-\tfrac{h}{\phi} \right)} , \\ R(x)=(2\theta)^{-1} \int\limits_{x-\theta}^{x+\theta} S(u) \, du , \\ \implies Cov \left[ S(u), S(v) \right] = \gamma(h) =\sigma^{2} \mathrm{exp} \left\{-\frac{|h|}{\phi} \right\} = \sigma^{2} \mathrm{exp} \left\{-\frac{| u-v|}{\phi} \right\}.$ I also know, $E[R(x)]= (2\theta)^{-1} \mu \ (2\theta) = \mu.$ What I want to know is $Cov[R(x), R(y)]$. Here is what I have so far... $$ \begin{align} Cov \left[R(x), R(y) \right] &=Cov \left[(2\theta)^{-1} \int\limits_{x-\theta}^{x+\theta} S(u) \, du, \ (2\theta)^{-1} \int\limits_{y-\theta}^{y+\theta} S(v) \, dv \right] \\ &= (2\theta)^{-2} \ Cov \left[ \ \int\limits_{x-\theta}^{x+\theta} S(u) \, du, \ \int\limits_{y-\theta}^{y+\theta} S(v) \, dv \right] \\ &= (2\theta)^{-2} \int\limits_{x-\theta}^{x+\theta} \int\limits_{y-\theta}^{y+\theta} \ Cov \left[ S(u), S(v) \right] \ du \ dv \\ &= (2\theta)^{-2} \int\limits_{x-\theta}^{x+\theta} \int\limits_{y-\theta}^{y+\theta} \sigma^{2} \mathrm{exp} \left\{-\tfrac{| u-v|}{\phi} \right\} \ du \ dv \\ &= (2\theta)^{-2} \ \sigma^{2} \int\limits_{x-\theta}^{x+\theta} \int\limits_{y-\theta}^{y+\theta} \mathrm{exp} \left\{-\tfrac{| u-v|}{\phi} \right\} \ du \ dv \end{align}  $$ Here, I am having trouble understanding how to properly set up this integral. I have been told this is what it should look like... $$ (2\theta)^{-2} \ \sigma^{2} \int\limits_{x-\theta}^{x+\theta} \int\limits_{v}^{y+\theta} \mathrm{exp} \left\{-\frac{(u-v)}{\phi} \right\} \ du \ dv + (2\theta)^{-2} \ \sigma^{2} \int\limits_{y-\theta}^{y+\theta} \int\limits_{u}^{x+\theta} \mathrm{exp} \left\{-\frac{(v-u)}{\phi} \right\} \ dv \ du $$ I have a few questions. What is the intuition regarding splitting the two integrals into two double integrals? How do you deiced on the bounds and order of the integration? Why is the order of $u$ and $v$ in the exponent changed? And how would I go about integrating the following... $$\int\limits_{x-\theta}^{x+\theta} \int\limits_{v}^{y+\theta} \mathrm{exp} \left\{-\frac{(u-v)}{\phi} \right\} \ du \ dv$$ Thanks for the help!","This is a question related to statistics, but my major concern relates to the setup and evaluation of integrals. So I decided this question was better suited for Mathematics Exchange than CV. I know the following... $ E[S(x)]=\mu , \\ Var[S(x)]= \sigma^{2} , \\ \rho(h)= \mathrm{e}^{\left(-\tfrac{h}{\phi} \right)} , \\ R(x)=(2\theta)^{-1} \int\limits_{x-\theta}^{x+\theta} S(u) \, du , \\ \implies Cov \left[ S(u), S(v) \right] = \gamma(h) =\sigma^{2} \mathrm{exp} \left\{-\frac{|h|}{\phi} \right\} = \sigma^{2} \mathrm{exp} \left\{-\frac{| u-v|}{\phi} \right\}.$ I also know, $E[R(x)]= (2\theta)^{-1} \mu \ (2\theta) = \mu.$ What I want to know is $Cov[R(x), R(y)]$. Here is what I have so far... $$ \begin{align} Cov \left[R(x), R(y) \right] &=Cov \left[(2\theta)^{-1} \int\limits_{x-\theta}^{x+\theta} S(u) \, du, \ (2\theta)^{-1} \int\limits_{y-\theta}^{y+\theta} S(v) \, dv \right] \\ &= (2\theta)^{-2} \ Cov \left[ \ \int\limits_{x-\theta}^{x+\theta} S(u) \, du, \ \int\limits_{y-\theta}^{y+\theta} S(v) \, dv \right] \\ &= (2\theta)^{-2} \int\limits_{x-\theta}^{x+\theta} \int\limits_{y-\theta}^{y+\theta} \ Cov \left[ S(u), S(v) \right] \ du \ dv \\ &= (2\theta)^{-2} \int\limits_{x-\theta}^{x+\theta} \int\limits_{y-\theta}^{y+\theta} \sigma^{2} \mathrm{exp} \left\{-\tfrac{| u-v|}{\phi} \right\} \ du \ dv \\ &= (2\theta)^{-2} \ \sigma^{2} \int\limits_{x-\theta}^{x+\theta} \int\limits_{y-\theta}^{y+\theta} \mathrm{exp} \left\{-\tfrac{| u-v|}{\phi} \right\} \ du \ dv \end{align}  $$ Here, I am having trouble understanding how to properly set up this integral. I have been told this is what it should look like... $$ (2\theta)^{-2} \ \sigma^{2} \int\limits_{x-\theta}^{x+\theta} \int\limits_{v}^{y+\theta} \mathrm{exp} \left\{-\frac{(u-v)}{\phi} \right\} \ du \ dv + (2\theta)^{-2} \ \sigma^{2} \int\limits_{y-\theta}^{y+\theta} \int\limits_{u}^{x+\theta} \mathrm{exp} \left\{-\frac{(v-u)}{\phi} \right\} \ dv \ du $$ I have a few questions. What is the intuition regarding splitting the two integrals into two double integrals? How do you deiced on the bounds and order of the integration? Why is the order of $u$ and $v$ in the exponent changed? And how would I go about integrating the following... $$\int\limits_{x-\theta}^{x+\theta} \int\limits_{v}^{y+\theta} \mathrm{exp} \left\{-\frac{(u-v)}{\phi} \right\} \ du \ dv$$ Thanks for the help!",,"['calculus', 'integration', 'statistics', 'definite-integrals', 'self-learning']"
29,Probability - Poisson arrival of rain,Probability - Poisson arrival of rain,,"I'm trying to solve this Poisson problem. A rain shower lasts 10 minutes and in that time deposits $10^6$ raindrops over 100 $m^2$. a) What is the probability of at least one drop landing in 1 $cm^2$ b)On average, how much time elapses before a raindrop hits the 1 $cm^2$ area. I understand the first part, the intensity is 1 drop/$cm^2$ so the probability is of at least one is $P(x\ge1)=1-\frac{(1^0)e^{-1}}{0!}=0.632$ But I'm not sure about the second part. I don't see how the number of drops, the time interval, and the two areas relate to each other to appear in a Poisson proccess. Particularly since I'm apparently not trying to find the probability of no drops after some amount of time.","I'm trying to solve this Poisson problem. A rain shower lasts 10 minutes and in that time deposits $10^6$ raindrops over 100 $m^2$. a) What is the probability of at least one drop landing in 1 $cm^2$ b)On average, how much time elapses before a raindrop hits the 1 $cm^2$ area. I understand the first part, the intensity is 1 drop/$cm^2$ so the probability is of at least one is $P(x\ge1)=1-\frac{(1^0)e^{-1}}{0!}=0.632$ But I'm not sure about the second part. I don't see how the number of drops, the time interval, and the two areas relate to each other to appear in a Poisson proccess. Particularly since I'm apparently not trying to find the probability of no drops after some amount of time.",,"['probability', 'statistics', 'poisson-distribution']"
30,"Let $X_1,\ldots,X_n$ i.i.d. negative binomial. Find the best unbiased estimator for $P(X\le3)$",Let  i.i.d. negative binomial. Find the best unbiased estimator for,"X_1,\ldots,X_n P(X\le3)","I am not sure where I should even start with this problems. I know that the sum of negative binomial random variables is itself a negative binomial random variable. I am sure that I can show that the sum is also a sufficient and complete statistic. However, beyond this point I am not sure where to go with finding the ""best"" unbiased estimator. Any suggestions would be greatly appretiated","I am not sure where I should even start with this problems. I know that the sum of negative binomial random variables is itself a negative binomial random variable. I am sure that I can show that the sum is also a sufficient and complete statistic. However, beyond this point I am not sure where to go with finding the ""best"" unbiased estimator. Any suggestions would be greatly appretiated",,['statistics']
31,How sample size affects confidence interval.,How sample size affects confidence interval.,,"Suppose the weight of n primary one students has sample mean of 20KG. If n = 40, a certain percentage of confidence interval for the population mean is (15.5,24.5). Find the confidence interval if we decrease the sample size to 30. Am I doing it right this way? Method 1 Given margin error = $\frac{\sigma}{\sqrt n}$ It means if sample size is quadrupled, margin error will be halved. Since $n = 40, 0.75n = 30$ Margin error now is $4.5$ New margin error = $\frac{4.5}{\sqrt {0.75}}$ = $3\sqrt 3$ Therefore, new interval = $20-3\sqrt 3$ to $20+3\sqrt3$ = $14.804 to 25.196$ Method 2 I solve for $\sigma$ first. Given margin error = $\frac{\sigma}{\sqrt n}$ = $4.5$ and $n = 40$ $\sigma = 4.5\sqrt{40}$ Sub new $n$ to find new margin error New margin error = $\frac{4.5\sqrt{40}}{\sqrt{30}}$ = $3\sqrt 3$ Which turns out the be the same. But I have one question for this method. Wouldn't the sample deviation, $\sigma$ changes whenever our sample size changes(which means sampled data will be different)? Why can I still use method 2 which assumed $\sigma$ remained unchanged?","Suppose the weight of n primary one students has sample mean of 20KG. If n = 40, a certain percentage of confidence interval for the population mean is (15.5,24.5). Find the confidence interval if we decrease the sample size to 30. Am I doing it right this way? Method 1 Given margin error = $\frac{\sigma}{\sqrt n}$ It means if sample size is quadrupled, margin error will be halved. Since $n = 40, 0.75n = 30$ Margin error now is $4.5$ New margin error = $\frac{4.5}{\sqrt {0.75}}$ = $3\sqrt 3$ Therefore, new interval = $20-3\sqrt 3$ to $20+3\sqrt3$ = $14.804 to 25.196$ Method 2 I solve for $\sigma$ first. Given margin error = $\frac{\sigma}{\sqrt n}$ = $4.5$ and $n = 40$ $\sigma = 4.5\sqrt{40}$ Sub new $n$ to find new margin error New margin error = $\frac{4.5\sqrt{40}}{\sqrt{30}}$ = $3\sqrt 3$ Which turns out the be the same. But I have one question for this method. Wouldn't the sample deviation, $\sigma$ changes whenever our sample size changes(which means sampled data will be different)? Why can I still use method 2 which assumed $\sigma$ remained unchanged?",,"['statistics', 'statistical-inference', 'sampling']"
32,How to prove / disprove these conditional probability statements?,How to prove / disprove these conditional probability statements?,,"I was browsing a well known technology board and someone posted a pretty standard question about conditional probabilities. As this happens to be the current subject of my lectures (just starting), I decided to take a swing at them and it turns out I have no idea what I'm doing, or what kind of proof (contradiction?) I should be using in these kinds of questions. I can show these are correct/incorrect with arbitrary numbers, but I have a gut feeling there are more succinct ways of showing truth. If P(a|b,c) = P(a), then P(b|c) = P(b) I get the feeling that this one is wrong, only because we can't assume c has no bearing on b with only the information that neither affects a. From my limited knowledge of conditional probability, I'm reading the first statement that a is independent from both b and c. I did this, where I assumed the implication was true, and got a contradiction. Nevermind, I made the assumption that P(a|b,c) = P(a) ==> P(a|b) = P(a) and P(a|c) = P(a), and I apparently can't do that? If P(a | b) = P(a), then P(a | b, c) = P(a | c) I believe this one is true, because if a and b are independent, then the probability of a, given two conditions - one of which doesn't affect it, and one that might - should just be the probability of a given the other condition (c). I also tried proving this one, but I kept going in a circle. I've tried contradiction approaches, but I'm not familiar enough with conditional probability to say something is for sure a contradiction (For example, before I realized the incorrect assumption I made on the first one, I assumed the second part was true and arrived at P(b|a,c) = P(b|c), which looks false, but because of the stuff about independence I can't be certain). Most of my 'technique' has revolved around using the definitions P(a|b) = P(a,b)/p(b) (expanded to) P(a|b,c) = P(a,b,c)/P(b,c) P(a,b) = P(a|b)P(b) = P(b|a)P(a) Any help is appreciated, especially if you focus on the ""why"" of choosing a certain proof.","I was browsing a well known technology board and someone posted a pretty standard question about conditional probabilities. As this happens to be the current subject of my lectures (just starting), I decided to take a swing at them and it turns out I have no idea what I'm doing, or what kind of proof (contradiction?) I should be using in these kinds of questions. I can show these are correct/incorrect with arbitrary numbers, but I have a gut feeling there are more succinct ways of showing truth. If P(a|b,c) = P(a), then P(b|c) = P(b) I get the feeling that this one is wrong, only because we can't assume c has no bearing on b with only the information that neither affects a. From my limited knowledge of conditional probability, I'm reading the first statement that a is independent from both b and c. I did this, where I assumed the implication was true, and got a contradiction. Nevermind, I made the assumption that P(a|b,c) = P(a) ==> P(a|b) = P(a) and P(a|c) = P(a), and I apparently can't do that? If P(a | b) = P(a), then P(a | b, c) = P(a | c) I believe this one is true, because if a and b are independent, then the probability of a, given two conditions - one of which doesn't affect it, and one that might - should just be the probability of a given the other condition (c). I also tried proving this one, but I kept going in a circle. I've tried contradiction approaches, but I'm not familiar enough with conditional probability to say something is for sure a contradiction (For example, before I realized the incorrect assumption I made on the first one, I assumed the second part was true and arrived at P(b|a,c) = P(b|c), which looks false, but because of the stuff about independence I can't be certain). Most of my 'technique' has revolved around using the definitions P(a|b) = P(a,b)/p(b) (expanded to) P(a|b,c) = P(a,b,c)/P(b,c) P(a,b) = P(a|b)P(b) = P(b|a)P(a) Any help is appreciated, especially if you focus on the ""why"" of choosing a certain proof.",,"['probability', 'statistics']"
33,Statistics - Estimation problem,Statistics - Estimation problem,,"I am struggling with a statistics problem that seems quite easy but don't know what to do. In a factory a product is given to two experts - X and Y. They have to independently test the product and find defects, if any. Expert A found 11 defects and expert Y found 15. After comparison it is known that 8 of the defects are found by both of them. Find an estimation of the number of defects in the product. The first thing that comes in mind is the mean value - 13. However, I don't know how to use the '8 defects in common' information. Any suggestions?","I am struggling with a statistics problem that seems quite easy but don't know what to do. In a factory a product is given to two experts - X and Y. They have to independently test the product and find defects, if any. Expert A found 11 defects and expert Y found 15. After comparison it is known that 8 of the defects are found by both of them. Find an estimation of the number of defects in the product. The first thing that comes in mind is the mean value - 13. However, I don't know how to use the '8 defects in common' information. Any suggestions?",,"['statistics', 'estimation']"
34,Multivariate Delta Method,Multivariate Delta Method,,"If I have a $\sqrt{N}$ asymptotic normal estimator (call it $\boldsymbol{\theta}$, possibly a vector). Say I want to find the asymptotic distribution of $g(\boldsymbol{\theta})$ and suppose $g'(\boldsymbol{\theta})=0$ (assume $g(\cdot)$ real valued). How would the second order delta method derivation go along in this case? Can easily argue that the quadratic form in the Taylor expansion is asymptotically chi-square? In the univariate case this is trivial, but in the multivariate case there is dependency issues which does not seem obvious. Also, would the estimator converge at $\sqrt{N}$ speed? Thanks.","If I have a $\sqrt{N}$ asymptotic normal estimator (call it $\boldsymbol{\theta}$, possibly a vector). Say I want to find the asymptotic distribution of $g(\boldsymbol{\theta})$ and suppose $g'(\boldsymbol{\theta})=0$ (assume $g(\cdot)$ real valued). How would the second order delta method derivation go along in this case? Can easily argue that the quadratic form in the Taylor expansion is asymptotically chi-square? In the univariate case this is trivial, but in the multivariate case there is dependency issues which does not seem obvious. Also, would the estimator converge at $\sqrt{N}$ speed? Thanks.",,"['statistics', 'convergence-divergence', 'asymptotics']"
35,Marginal Distribution of the sum of Bernoulli rv,Marginal Distribution of the sum of Bernoulli rv,,"consider the conditional on probabilities $p_1, \ldots, p_n$, with independent Bernoulli random variables $Y_1, ..., Y_n$ given that  $P(Y_i = 1\mid p_1, \ldots, p_n) = p_i, \  P(Y_i = 0\mid p_1, \ldots, p_n) = 1 − p_i$  for  $i = 1, \ldots, n$. if each $p_i$ is a random draw from a distribution with mean $p$. we are looking for the distribution of $X = Y_1 + \cdots + Y_n$. I am thinking that $X$ follows a bin. distribution. Am I wrong?","consider the conditional on probabilities $p_1, \ldots, p_n$, with independent Bernoulli random variables $Y_1, ..., Y_n$ given that  $P(Y_i = 1\mid p_1, \ldots, p_n) = p_i, \  P(Y_i = 0\mid p_1, \ldots, p_n) = 1 − p_i$  for  $i = 1, \ldots, n$. if each $p_i$ is a random draw from a distribution with mean $p$. we are looking for the distribution of $X = Y_1 + \cdots + Y_n$. I am thinking that $X$ follows a bin. distribution. Am I wrong?",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
36,Continuous Percentage,Continuous Percentage,,"This is probably super easy for the experts here (I need to retake and practice a lot of math courses, its been a while). Suppose I have a shared bank account with N number of people. Anyone can add some amount to the account. Each person that adds money to the account needs to have a cumulative percentage that represents how much of the total balance they can lay claim to. So if 10 people add 10 dollars each, each person would own 10 percent of the account. If an 11th person comes in and adds 100 dollars, then the 11th person would own 50 percent of the account. However, the original percentages for the first 10 people are off now, since they would not own 10 percent of the total 200 dollars. Now everyones percentages would not be correct if you multiplied them times the total account value. Other scenarios like, let's say a wealthy benefactor gives 250 dollars to the account and then the government comes in an takes 30 dollars from the entire account. This further confuses all the percentages Is there anyway to keep a running percentage that each person owns without updating each ownage percentage for each person, everytime the account is changed ? If you removed the 50% first, then did the lesser amounts it should work but is that the only way ?","This is probably super easy for the experts here (I need to retake and practice a lot of math courses, its been a while). Suppose I have a shared bank account with N number of people. Anyone can add some amount to the account. Each person that adds money to the account needs to have a cumulative percentage that represents how much of the total balance they can lay claim to. So if 10 people add 10 dollars each, each person would own 10 percent of the account. If an 11th person comes in and adds 100 dollars, then the 11th person would own 50 percent of the account. However, the original percentages for the first 10 people are off now, since they would not own 10 percent of the total 200 dollars. Now everyones percentages would not be correct if you multiplied them times the total account value. Other scenarios like, let's say a wealthy benefactor gives 250 dollars to the account and then the government comes in an takes 30 dollars from the entire account. This further confuses all the percentages Is there anyway to keep a running percentage that each person owns without updating each ownage percentage for each person, everytime the account is changed ? If you removed the 50% first, then did the lesser amounts it should work but is that the only way ?",,"['calculus', 'algebra-precalculus', 'statistics']"
37,Properties of eigenvectors of a sample covariance matrix?,Properties of eigenvectors of a sample covariance matrix?,,"My apology if the question is not appropriate. For me Eigenvectors are quite a mystery. Does it have any property that we can relate to the matrix it came from? By property I mean something like the sum of its elements, relation between real and imaginary part of the element, etc. My specific interest is: consider a sample covariance matrix $A$ which is positive definite Hermitian matrix. Further,the sample covariance matrix is of size $N$ by $N$ and derived from an $N$ sensor system receiving band limited-signal over time. Are there any specific properties of the eigenvectors of $A$? If there are any, how we can even formulate the problem? That Eigenvalues are variances and Eigenvectors are corresponding directions is a known property, but is there anything else?","My apology if the question is not appropriate. For me Eigenvectors are quite a mystery. Does it have any property that we can relate to the matrix it came from? By property I mean something like the sum of its elements, relation between real and imaginary part of the element, etc. My specific interest is: consider a sample covariance matrix $A$ which is positive definite Hermitian matrix. Further,the sample covariance matrix is of size $N$ by $N$ and derived from an $N$ sensor system receiving band limited-signal over time. Are there any specific properties of the eigenvectors of $A$? If there are any, how we can even formulate the problem? That Eigenvalues are variances and Eigenvectors are corresponding directions is a known property, but is there anything else?",,"['real-analysis', 'linear-algebra', 'probability', 'statistics', 'signal-processing']"
38,Some statistical (learning) issues,Some statistical (learning) issues,,"im reading about statistical learning ( Trevor Hastie, Robert Tibshirani, Jerome Friedman The elements of statistical learning ) and for some reason it seems to be trivial that $E[XX^T]$ is non-singular (with $X \in \mathbb{R}^P$ a random real valued vector) but I dont really think its that easy, am i missing something here?","im reading about statistical learning ( Trevor Hastie, Robert Tibshirani, Jerome Friedman The elements of statistical learning ) and for some reason it seems to be trivial that $E[XX^T]$ is non-singular (with $X \in \mathbb{R}^P$ a random real valued vector) but I dont really think its that easy, am i missing something here?",,"['matrices', 'statistics']"
39,Average Cost of Obtaining in game Item,Average Cost of Obtaining in game Item,,"I know this will sound like a trivial maths problem, but recently I've been playing a game in which you can pay 5 in game gems to get a Rare (R), Super Rare (SR), and Ultra Rare (UR) characters randomly. And the probability of getting said characters are 90%, 9%, and 1% respectively. What I have calculated thus far is that each character is worth approximately 5.5, 55, and 500 gems respectively by doing the following calculation: Average Cost = Cost of Rolling/Probability But I have no proof that this is correct or incorrect. I thought it had something to do with expected value as taught in school, but something seems off about it. To further complicate things, you can spend 50 gems to roll 11 times. And on top of that, occasionally you can roll spend 50 gems to roll 11 times with 1 guaranteed SR. What would then be the expected average cost for each respective rarity? Probability has always been interesting to me, but definitely not my strong suit.","I know this will sound like a trivial maths problem, but recently I've been playing a game in which you can pay 5 in game gems to get a Rare (R), Super Rare (SR), and Ultra Rare (UR) characters randomly. And the probability of getting said characters are 90%, 9%, and 1% respectively. What I have calculated thus far is that each character is worth approximately 5.5, 55, and 500 gems respectively by doing the following calculation: Average Cost = Cost of Rolling/Probability But I have no proof that this is correct or incorrect. I thought it had something to do with expected value as taught in school, but something seems off about it. To further complicate things, you can spend 50 gems to roll 11 times. And on top of that, occasionally you can roll spend 50 gems to roll 11 times with 1 guaranteed SR. What would then be the expected average cost for each respective rarity? Probability has always been interesting to me, but definitely not my strong suit.",,"['probability', 'statistics', 'economics']"
40,Can a mixture of normals be a constant?,Can a mixture of normals be a constant?,,"Q . Can a mixture of a finite number of 2-dimensional normal distributions,   with different means and covariances, sum to a constant within some   bounded region of the plane? I believe the answer is No , in any dimension, but I have not proved that, and I hold out some hope that a clever mixture would magically sum to a constant... I would also be interested if the answer is Yes for any of the commonly used probability distributions: Poisson, gamma, etc.","Q . Can a mixture of a finite number of 2-dimensional normal distributions,   with different means and covariances, sum to a constant within some   bounded region of the plane? I believe the answer is No , in any dimension, but I have not proved that, and I hold out some hope that a clever mixture would magically sum to a constant... I would also be interested if the answer is Yes for any of the commonly used probability distributions: Poisson, gamma, etc.",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
41,Fisher Expected Information for a Gaussian Process model,Fisher Expected Information for a Gaussian Process model,,"Suppose I have a two dimensional Gaussian process model (GP), defined by a squared exponential correlation function s.t:  $$R(x_{i},x_{j}) = \exp\left(-\frac{|x_{i} - x_{j}|^2}{2}\right).$$ I am trying to evaluate Fisher Expected Information for the GP model, defined by: $$I(\theta) = E\left[\left(\frac{\partial \log f(x;\theta)}{d \theta}\right)^2\right].$$","Suppose I have a two dimensional Gaussian process model (GP), defined by a squared exponential correlation function s.t:  $$R(x_{i},x_{j}) = \exp\left(-\frac{|x_{i} - x_{j}|^2}{2}\right).$$ I am trying to evaluate Fisher Expected Information for the GP model, defined by: $$I(\theta) = E\left[\left(\frac{\partial \log f(x;\theta)}{d \theta}\right)^2\right].$$",,"['statistics', 'statistical-inference', 'information-theory', 'machine-learning', 'parameter-estimation']"
42,Principal component analysis - covariance matrix,Principal component analysis - covariance matrix,,"I know that PCA is about rotating the axes of coordinate system so that the covariance matrix of data is diagonal. It means we want to have as much variance in measurement of one type as possible and as little covariance between measurements of different types as possible. $P$ is a matrix whose rows are the new basis vectors. As it turns out below, it's best to take eigenvectors of our original covariance matrix (expressed in original basis) as the new basis. First, the most important question: 1) the $i^{th}$ diagonal value of $C_{y}$ is the variance of $X$ along $p_i$. Could you explain why? Are they equal to eigenvalues of the corresponding eigenvectors? Why? 2) Can we always rotate the data points so that covariance matrix of the data is diagonal? It's quite surprising for me that this matrix always exists. 3) PCA is about minimizing redundancy and maximizing variance of measurements of the same type. OK, we can obtain a diagonal covariance matrix - it means all terms of the matrix not on its diagonal are zero, so we minimized them (thus PCA eliminates redundancy completely). But how does it maximize the variance (terms on diagonal)? We don't do anything to maximize them actually... Source","I know that PCA is about rotating the axes of coordinate system so that the covariance matrix of data is diagonal. It means we want to have as much variance in measurement of one type as possible and as little covariance between measurements of different types as possible. $P$ is a matrix whose rows are the new basis vectors. As it turns out below, it's best to take eigenvectors of our original covariance matrix (expressed in original basis) as the new basis. First, the most important question: 1) the $i^{th}$ diagonal value of $C_{y}$ is the variance of $X$ along $p_i$. Could you explain why? Are they equal to eigenvalues of the corresponding eigenvectors? Why? 2) Can we always rotate the data points so that covariance matrix of the data is diagonal? It's quite surprising for me that this matrix always exists. 3) PCA is about minimizing redundancy and maximizing variance of measurements of the same type. OK, we can obtain a diagonal covariance matrix - it means all terms of the matrix not on its diagonal are zero, so we minimized them (thus PCA eliminates redundancy completely). But how does it maximize the variance (terms on diagonal)? We don't do anything to maximize them actually... Source",,"['linear-algebra', 'statistics']"
43,P-value - test at $5 \%$ if there is significant difference in fuel consumption between the two petrol grades?,P-value - test at  if there is significant difference in fuel consumption between the two petrol grades?,5 \%,"A car owners want to investigate if gasoline consumption of his car   depends on the fuel octane number. He therefore intend to   ""premium"" and ""regular"" at random and computes each time the average   fuel consumption . After some time , he has received the following   values ​: $$(P) Premium: 0.87, 0.93, 0.82, 0.95, 0.86, 0.88, 0.84, 0.91, 0.86, 0.92, 0.89, 0.90$$ $$(R) Regular: 0.88, 0.96, 0.92, 0.94, 0.93, 0.90, 0.95, 0.92, 0.89, 0.94, 0.97$$    Test at $5 \%$ if there is no significant difference in fuel consumption between the two petrol grades. My attempt: We want to compare the two samples $P$ from X and $R$ from Y, which comprising $n_1$=12 and $n_2=11$ respectively. From the exercis we can see that we want to test the null hypothesis $$H_0: \ the \ fuel\ consumption \ of \ his \ car \ does \ not \ depends \ on \ the \ gasoline $$ against the alternatively hypothesis $$H_1: \ the \ fuel\ consumption \ of \ his \ car \ does \ depends \ on \ the \ gasoline$$ The alternatively is 2-sided hypothesis. I did start with arrange all the observations in order of magnitude and did get $$R_1= sum \ of \ ranks \ of \ sample 1 = 103.5$$ $$R_2= sum \ of \ ranks \ of \ sample 2 = 172.5$$ there we have 7 groups of doublets and 1 group of triplets. I know that the rank sum i should use is the one for the sample is at least, which is $R_2$. Furthemore i know that i can approximate $R_2$ with normalapproximation because $n_1>10 \ and \ n_2>10$. I do not know what to do now . What probabilty should i calculate? I know that i can standardize it to $N(0,1)$ and use the table, but I always get wrong answers. EDIT: The expected value for the normal approximation is 132 and the variance for the approximation is $\frac{24167}{91}$. When standardizing i get that $$Z=\frac{R_2-E(R_2)}{D(R_2)} \sim approx N(0,1)$$  What should I do now?","A car owners want to investigate if gasoline consumption of his car   depends on the fuel octane number. He therefore intend to   ""premium"" and ""regular"" at random and computes each time the average   fuel consumption . After some time , he has received the following   values ​: $$(P) Premium: 0.87, 0.93, 0.82, 0.95, 0.86, 0.88, 0.84, 0.91, 0.86, 0.92, 0.89, 0.90$$ $$(R) Regular: 0.88, 0.96, 0.92, 0.94, 0.93, 0.90, 0.95, 0.92, 0.89, 0.94, 0.97$$    Test at $5 \%$ if there is no significant difference in fuel consumption between the two petrol grades. My attempt: We want to compare the two samples $P$ from X and $R$ from Y, which comprising $n_1$=12 and $n_2=11$ respectively. From the exercis we can see that we want to test the null hypothesis $$H_0: \ the \ fuel\ consumption \ of \ his \ car \ does \ not \ depends \ on \ the \ gasoline $$ against the alternatively hypothesis $$H_1: \ the \ fuel\ consumption \ of \ his \ car \ does \ depends \ on \ the \ gasoline$$ The alternatively is 2-sided hypothesis. I did start with arrange all the observations in order of magnitude and did get $$R_1= sum \ of \ ranks \ of \ sample 1 = 103.5$$ $$R_2= sum \ of \ ranks \ of \ sample 2 = 172.5$$ there we have 7 groups of doublets and 1 group of triplets. I know that the rank sum i should use is the one for the sample is at least, which is $R_2$. Furthemore i know that i can approximate $R_2$ with normalapproximation because $n_1>10 \ and \ n_2>10$. I do not know what to do now . What probabilty should i calculate? I know that i can standardize it to $N(0,1)$ and use the table, but I always get wrong answers. EDIT: The expected value for the normal approximation is 132 and the variance for the approximation is $\frac{24167}{91}$. When standardizing i get that $$Z=\frac{R_2-E(R_2)}{D(R_2)} \sim approx N(0,1)$$  What should I do now?",,"['statistics', 'statistical-inference', 'order-statistics', 'hypothesis-testing', 'descriptive-statistics']"
44,Reducing eigenvalues of symmetric PSD matrix towards 0: effect on ratios of original matrix elements?,Reducing eigenvalues of symmetric PSD matrix towards 0: effect on ratios of original matrix elements?,,"Let $\boldsymbol{S}$ be $k \times k$ positive semi-definite real symmetric matrix with eigen decomposition $\boldsymbol{S} = \boldsymbol{X} \boldsymbol{\Lambda} \boldsymbol{X}'$ ($\boldsymbol{\Lambda}$ diagonal, $\boldsymbol{X}$ orthonormal matrix of eigenvectors). Assume that we reduce each eigenvalue $\lambda_i$ by $\psi_i \in [0, \lambda_i]$, for $i = 1, \ldots, k$ with $\lambda_i$ sorted so that $\lambda_i \ge \lambda_{i+1}$. Define our ratio of interest $r_{ij}^\psi$ in terms of elements of the new matrix $\boldsymbol{S}^{\psi}$: $$ r_{ij}^\psi = \frac{s_{ij}^\psi}{\sqrt{s_{ii}^\psi}\sqrt{s_{jj}^\psi}} = \frac{\sum_{l=1}^k x_{il} x_{jl} (\lambda_l - \psi_l)}{\sqrt{\sum_{l=1}^k x_{il}^2 (\lambda_l - \psi_l)} \sqrt{\sum_{l=1}^k x_{jl}^2 (\lambda_l - \psi_l)}}. $$ How does $r_{ij}^\psi$ change as $\psi_i$ grows? In particular, I am interested in the case when $\psi_i \ge \psi_{i+1}$ for $i = 1, \ldots, k$. Initially my numerical experiments delivered an increase in absolute value, but now I have found the cases that yield a decrease instead. I can formulate a counterexample for some subset of parameter values using the fact that columns of $\boldsymbol{X}$ are length one and orthogonal to each other (e.g., when $\lambda_k \approx 0$), so strictly speaking I'm done; but I wonder if it can be shown more generally and elegantly. (If $r_{ij}^\psi$ is thought as a correlation coefficient, then this problem has direct relation to statistics.)","Let $\boldsymbol{S}$ be $k \times k$ positive semi-definite real symmetric matrix with eigen decomposition $\boldsymbol{S} = \boldsymbol{X} \boldsymbol{\Lambda} \boldsymbol{X}'$ ($\boldsymbol{\Lambda}$ diagonal, $\boldsymbol{X}$ orthonormal matrix of eigenvectors). Assume that we reduce each eigenvalue $\lambda_i$ by $\psi_i \in [0, \lambda_i]$, for $i = 1, \ldots, k$ with $\lambda_i$ sorted so that $\lambda_i \ge \lambda_{i+1}$. Define our ratio of interest $r_{ij}^\psi$ in terms of elements of the new matrix $\boldsymbol{S}^{\psi}$: $$ r_{ij}^\psi = \frac{s_{ij}^\psi}{\sqrt{s_{ii}^\psi}\sqrt{s_{jj}^\psi}} = \frac{\sum_{l=1}^k x_{il} x_{jl} (\lambda_l - \psi_l)}{\sqrt{\sum_{l=1}^k x_{il}^2 (\lambda_l - \psi_l)} \sqrt{\sum_{l=1}^k x_{jl}^2 (\lambda_l - \psi_l)}}. $$ How does $r_{ij}^\psi$ change as $\psi_i$ grows? In particular, I am interested in the case when $\psi_i \ge \psi_{i+1}$ for $i = 1, \ldots, k$. Initially my numerical experiments delivered an increase in absolute value, but now I have found the cases that yield a decrease instead. I can formulate a counterexample for some subset of parameter values using the fact that columns of $\boldsymbol{X}$ are length one and orthogonal to each other (e.g., when $\lambda_k \approx 0$), so strictly speaking I'm done; but I wonder if it can be shown more generally and elegantly. (If $r_{ij}^\psi$ is thought as a correlation coefficient, then this problem has direct relation to statistics.)",,"['linear-algebra', 'statistics', 'eigenvalues-eigenvectors']"
45,Finding P value,Finding P value,,"I have these observations $(2,3.2,3.8,2.5,3.3,2.8,3.0,3.4)$ from $X \sim N(\mu,\sigma^2)$ and i want to calculate the $P$-value testing $H_0: \mu =3.2$ against $H_1 \neq 3.2$ with $\sigma = 0.6$ should i calculate $P r(X > 3.3) $ and $Pr( X < 3)$ and add these togheter ? I tried it using that  $X = Y\sigma + \mu  \sim N(0,1)$ but the answer don't seem to be right according to the solution which is $P = 0.347$ Anyone can tell me what Iam doing wrong?","I have these observations $(2,3.2,3.8,2.5,3.3,2.8,3.0,3.4)$ from $X \sim N(\mu,\sigma^2)$ and i want to calculate the $P$-value testing $H_0: \mu =3.2$ against $H_1 \neq 3.2$ with $\sigma = 0.6$ should i calculate $P r(X > 3.3) $ and $Pr( X < 3)$ and add these togheter ? I tried it using that  $X = Y\sigma + \mu  \sim N(0,1)$ but the answer don't seem to be right according to the solution which is $P = 0.347$ Anyone can tell me what Iam doing wrong?",,"['probability', 'statistics', 'statistical-inference']"
46,sample size calculator for a poisson distribution?,sample size calculator for a poisson distribution?,,"This question is related to research for Alzheimer's disease. I am a Professor of Neuroscience: while I know how to make genetically modified mice, I have limited knowledge of the underlying statistics. Transgenic mice overexpressing the A-beta protein develop in average ca. 8'000 ""plaques"" in their brains. The plaques are a surrogate marker of the intellectual deterioration occurring in Alzheimer's disease. I have a method that allows me to count all plaques present in the brain of a mouse (which is a technical feat, believe me!). Now, I am testing a few treatment options. Specifically, I wish to find out if my treatment reduces significantly the number of plaques. I do not know the inter-individual variability of this number yet, but I will find out soon. Let's assume it's 5% S.E.M. The goal is to reduce the plaque load by at least 40%. How can I use a calculator, or a python or R script, to estimate how many mice I need to have in the treated and control groups in order to establish non-futility of the treatment with a 5% or 1% (or 0.1%) confidence?","This question is related to research for Alzheimer's disease. I am a Professor of Neuroscience: while I know how to make genetically modified mice, I have limited knowledge of the underlying statistics. Transgenic mice overexpressing the A-beta protein develop in average ca. 8'000 ""plaques"" in their brains. The plaques are a surrogate marker of the intellectual deterioration occurring in Alzheimer's disease. I have a method that allows me to count all plaques present in the brain of a mouse (which is a technical feat, believe me!). Now, I am testing a few treatment options. Specifically, I wish to find out if my treatment reduces significantly the number of plaques. I do not know the inter-individual variability of this number yet, but I will find out soon. Let's assume it's 5% S.E.M. The goal is to reduce the plaque load by at least 40%. How can I use a calculator, or a python or R script, to estimate how many mice I need to have in the treated and control groups in order to establish non-futility of the treatment with a 5% or 1% (or 0.1%) confidence?",,"['statistics', 'poisson-distribution']"
47,minimizing mean square error with type 1 and 2 error weights,minimizing mean square error with type 1 and 2 error weights,,"Suppose we have a random variable $X$ with a pmf that puts strictly positive probability only on integer values $0,1,2,\dots,n$. The objective is to choose a $z\in\mathbb{Z}$ that minimizes $$c\sum_{i=0}^z (z-i)^2 \Pr(X=i)+ \sum_{i=z+1}^n (z-i)^2 \Pr(X=i). $$ When $c=1$, it is obvious that $z^* = \mathbb{E}X$. However, I'm not sure how to proceed for a general $c>0$. Using calculus doesn't work well with the sums (and we really are optimizing over a discrete domain). My thinking is to choose the maximum $z$ that satisfies $$\sum_{j=0}^{n-z-1}(1+2j)\Pr(X=z+1+j) > c\sum_{j=0}^{z}(2z+1-2j)\Pr(X=j),$$ but I'm not sure that this can be reduced to solve explicitly for $z$. Any suggestions?","Suppose we have a random variable $X$ with a pmf that puts strictly positive probability only on integer values $0,1,2,\dots,n$. The objective is to choose a $z\in\mathbb{Z}$ that minimizes $$c\sum_{i=0}^z (z-i)^2 \Pr(X=i)+ \sum_{i=z+1}^n (z-i)^2 \Pr(X=i). $$ When $c=1$, it is obvious that $z^* = \mathbb{E}X$. However, I'm not sure how to proceed for a general $c>0$. Using calculus doesn't work well with the sums (and we really are optimizing over a discrete domain). My thinking is to choose the maximum $z$ that satisfies $$\sum_{j=0}^{n-z-1}(1+2j)\Pr(X=z+1+j) > c\sum_{j=0}^{z}(2z+1-2j)\Pr(X=j),$$ but I'm not sure that this can be reduced to solve explicitly for $z$. Any suggestions?",,"['statistics', 'optimization', 'mean-square-error']"
48,Why we won't add +1 to N while calculating quartiles for continuous series?,Why we won't add +1 to N while calculating quartiles for continuous series?,,"I am been using interpolation formula for calculating quartiles of data in continuous series. My question is Why we write (N+1)/4 & 3(N+1)/4 for Q1 & Q3 while calculating quartiles for individual & discrete series. But N/4 and 3N/4 without +1 for calculating Q1 & Q3 in continuous series. I google for its derivation and essence but couldn't come to the point. So, provide the logic for not using +1 in continuous series quartiles calculation.","I am been using interpolation formula for calculating quartiles of data in continuous series. My question is Why we write (N+1)/4 & 3(N+1)/4 for Q1 & Q3 while calculating quartiles for individual & discrete series. But N/4 and 3N/4 without +1 for calculating Q1 & Q3 in continuous series. I google for its derivation and essence but couldn't come to the point. So, provide the logic for not using +1 in continuous series quartiles calculation.",,"['statistics', 'discrete-mathematics']"
49,Find moment generating function,Find moment generating function,,"I want to find the moment generating function $M(t)$ for distribution $$ f(x) =e^{-(ax)^{2}}*(1-e^{-(ax)^{2}})^{b-1}*[-log(1-e^{-(ax)^{2}})]^{r-1} $$ $$ M(t):=E(tX) = \int_0^\infty e^{tx}*f(x)dx \,. $$ But I have a problem.","I want to find the moment generating function $M(t)$ for distribution $$ f(x) =e^{-(ax)^{2}}*(1-e^{-(ax)^{2}})^{b-1}*[-log(1-e^{-(ax)^{2}})]^{r-1} $$ $$ M(t):=E(tX) = \int_0^\infty e^{tx}*f(x)dx \,. $$ But I have a problem.",,['statistics']
50,"confidence intervals for 20 different parameters - distribution, probabilit and most probable value.","confidence intervals for 20 different parameters - distribution, probabilit and most probable value.",,"I need help with the subexercise (c) in the following exercise. A researcher is planning a study where she must calculate confidence   intervals for 20 different parameters. The intervals are independent of   each other and all have 95% confidence . Let N be the number of   intervals that is containing it's parameter. ( a) Wat is the distribution of N ? ( b) What is the probability that all   the intervals that is containing its parameter? ( c ) What is the most probable value of N   ? Solution : (a): $N$~$bin(20,1-α)=bin(20,0.95)$. I did get this by just using the definition/prove of binomial distribution. n=20 because we have 20 parameters which gives us 20 intervals. (b): using probability function for binomial distribution with k=20. my question is if following is right (c): The most probable value of N is the espected value of N, i.e $E(N)=np=20*0.95=19$. Hence the most proabable value is $N=19$","I need help with the subexercise (c) in the following exercise. A researcher is planning a study where she must calculate confidence   intervals for 20 different parameters. The intervals are independent of   each other and all have 95% confidence . Let N be the number of   intervals that is containing it's parameter. ( a) Wat is the distribution of N ? ( b) What is the probability that all   the intervals that is containing its parameter? ( c ) What is the most probable value of N   ? Solution : (a): $N$~$bin(20,1-α)=bin(20,0.95)$. I did get this by just using the definition/prove of binomial distribution. n=20 because we have 20 parameters which gives us 20 intervals. (b): using probability function for binomial distribution with k=20. my question is if following is right (c): The most probable value of N is the espected value of N, i.e $E(N)=np=20*0.95=19$. Hence the most proabable value is $N=19$",,"['probability', 'statistics', 'statistical-inference', 'descriptive-statistics']"
51,Bounding the density of random variable,Bounding the density of random variable,,"This is a followup to the question in Bounding the Density of the Maximum of N Random Variables I have a random variable, X, whose cdf is bounded as below: $ \Pr \{X \le x \} \le  \underset{i}{\prod} \Pr\left\{\xi_i \le x\right\} $, How do I bound the density  of $X$ ? Can it be written as $f_X \le \sum_i f_{\xi_i} \prod_{j \ne i} \Pr\left\{\xi_j \le x\right\}$. I am trying to write a proof for the above. Any  hints ?","This is a followup to the question in Bounding the Density of the Maximum of N Random Variables I have a random variable, X, whose cdf is bounded as below: $ \Pr \{X \le x \} \le  \underset{i}{\prod} \Pr\left\{\xi_i \le x\right\} $, How do I bound the density  of $X$ ? Can it be written as $f_X \le \sum_i f_{\xi_i} \prod_{j \ne i} \Pr\left\{\xi_j \le x\right\}$. I am trying to write a proof for the above. Any  hints ?",,"['probability', 'statistics', 'probability-theory', 'order-statistics']"
52,Random numbers generator,Random numbers generator,,"If I know how to generate random numbers from Gaussian distribution (using Box-Muller method), how can I generate random numbers from distribution with pdf $\frac{x+e^{-x^2/2}}{\text{erf}{(1/\sqrt{2})}\sqrt{2\pi}}$ on interval $[-1,1]$? I have to create generator of such numbers in Matlab but I can't figure out what is a procedure to generate them.","If I know how to generate random numbers from Gaussian distribution (using Box-Muller method), how can I generate random numbers from distribution with pdf $\frac{x+e^{-x^2/2}}{\text{erf}{(1/\sqrt{2})}\sqrt{2\pi}}$ on interval $[-1,1]$? I have to create generator of such numbers in Matlab but I can't figure out what is a procedure to generate them.",,"['statistics', 'probability-distributions', 'normal-distribution', 'monte-carlo']"
53,What is the probability of $X <Y <Z$?,What is the probability of ?,X <Y <Z,"I have been trying to derive the probability $Pr[X<Y<Z]$, where $X$, $Y$, and $Z$ are independent and follow exponential distribution with parameters $\lambda_x$, $\lambda_y$, and $\lambda_z$, respectively. What I did is as follows: $\Pr \left[ {X < Y < Z} \right] = \Pr \left[ {X < Y,Y < Z} \right]\\  = \int\limits_0^\infty  {\Pr \left[ {X < y,Z > y} \right]{f_Y}(y)dy} \\  = \int\limits_0^\infty  {\Pr \left[ {X < y} \right]\Pr \left[ {Z > y} \right]{f_Y}\left( y \right)dy}$ Is it right or wrong? If it is wrong, how can we solve this problem? Thank you very much.","I have been trying to derive the probability $Pr[X<Y<Z]$, where $X$, $Y$, and $Z$ are independent and follow exponential distribution with parameters $\lambda_x$, $\lambda_y$, and $\lambda_z$, respectively. What I did is as follows: $\Pr \left[ {X < Y < Z} \right] = \Pr \left[ {X < Y,Y < Z} \right]\\  = \int\limits_0^\infty  {\Pr \left[ {X < y,Z > y} \right]{f_Y}(y)dy} \\  = \int\limits_0^\infty  {\Pr \left[ {X < y} \right]\Pr \left[ {Z > y} \right]{f_Y}\left( y \right)dy}$ Is it right or wrong? If it is wrong, how can we solve this problem? Thank you very much.",,['statistics']
54,Distribution of maximum of correlated Gaussians,Distribution of maximum of correlated Gaussians,,"Let $X_1,X_2,...,X_n$ be iid standard Gaussian random variables. Consider the set of random variables $M =\left\{\left( X_i-X_j\right) :i,j = \left\{1,2,\dots,n\right\} \& i\ne j\right\}$. I am trying to find a closed form expression for the cdf or an analytical expression on the upper bound of the cdf of the maximum of $M$. How do I take care of the correlation between the variables in $M$? Is there any asymptotic results as $n \rightarrow \infty$ ?","Let $X_1,X_2,...,X_n$ be iid standard Gaussian random variables. Consider the set of random variables $M =\left\{\left( X_i-X_j\right) :i,j = \left\{1,2,\dots,n\right\} \& i\ne j\right\}$. I am trying to find a closed form expression for the cdf or an analytical expression on the upper bound of the cdf of the maximum of $M$. How do I take care of the correlation between the variables in $M$? Is there any asymptotic results as $n \rightarrow \infty$ ?",,"['probability', 'statistics', 'probability-theory', 'order-statistics']"
55,"How to show that this estimator is unbiased, and find its variance","How to show that this estimator is unbiased, and find its variance",,"Suppose I'm trying to estimate $\mathbb{E}[\phi(X)]$ where $X$ is an $N(0,\sigma^2)$ r.v. by using the estimator $$\theta = \frac{1}{n \sigma} \sum_{i=1}^n \exp(-Y_i^2(1/2\sigma^2 - 1/2))\phi(Y_i)$$ where $Y_i$ are i.i.d $N(0,1)$ r.v.'s and $\phi$ is s.t. $\phi(X)$ has finite mean and variance. How do I show that this is unbiased? I've currently tried manipulating the thing inside the sum to try and get something that resembles a normal pdf which integrates to 1, but there's a couple of things missing that means this doesn't work. Hints much appreciated","Suppose I'm trying to estimate $\mathbb{E}[\phi(X)]$ where $X$ is an $N(0,\sigma^2)$ r.v. by using the estimator $$\theta = \frac{1}{n \sigma} \sum_{i=1}^n \exp(-Y_i^2(1/2\sigma^2 - 1/2))\phi(Y_i)$$ where $Y_i$ are i.i.d $N(0,1)$ r.v.'s and $\phi$ is s.t. $\phi(X)$ has finite mean and variance. How do I show that this is unbiased? I've currently tried manipulating the thing inside the sum to try and get something that resembles a normal pdf which integrates to 1, but there's a couple of things missing that means this doesn't work. Hints much appreciated",,"['probability', 'statistics', 'probability-theory']"
56,Application of change of variable to the density of an exponential family?,Application of change of variable to the density of an exponential family?,,"Suppose we have an exponential model that admits a canonical parametrization so that its densities can be written as $$ l(y;\theta)=C(\theta)\exp\left[\theta^*T(y)+\sum_{i=1}^{p-1}\lambda_iS_i(y)\right]\tag{$*$} $$ where $\theta^*,T(y)\in\mathbb{R}$ and $\theta=(\theta^*,\lambda_1,\ldots,\lambda_{p-1})'$. Let $S=(S_1,\ldots,S_{p-1})'$. My text then claims: The statistic $(T,S')'$ is sufficient for $\theta$. Thus, we can consider the model induced by this statistic. The probability distributions of the induced model have densities of the form   $$ l(t,s;\theta)=\hat{C}(\theta)\exp\left[\theta^*t+\sum_{i=1}^{p-1}\lambda_is_i\right]\tag{$**$}. $$ I understand the claim about sufficiency but where does ($*$$*$) come from? I thought about using a change of variable formula (assuming that the conditions for its application are satisfied). But there would always be an extra term involving $t,s$ that I didn't know how to get rid of. Thank you very much.","Suppose we have an exponential model that admits a canonical parametrization so that its densities can be written as $$ l(y;\theta)=C(\theta)\exp\left[\theta^*T(y)+\sum_{i=1}^{p-1}\lambda_iS_i(y)\right]\tag{$*$} $$ where $\theta^*,T(y)\in\mathbb{R}$ and $\theta=(\theta^*,\lambda_1,\ldots,\lambda_{p-1})'$. Let $S=(S_1,\ldots,S_{p-1})'$. My text then claims: The statistic $(T,S')'$ is sufficient for $\theta$. Thus, we can consider the model induced by this statistic. The probability distributions of the induced model have densities of the form   $$ l(t,s;\theta)=\hat{C}(\theta)\exp\left[\theta^*t+\sum_{i=1}^{p-1}\lambda_is_i\right]\tag{$**$}. $$ I understand the claim about sufficiency but where does ($*$$*$) come from? I thought about using a change of variable formula (assuming that the conditions for its application are satisfied). But there would always be an extra term involving $t,s$ that I didn't know how to get rid of. Thank you very much.",,"['statistics', 'probability-theory']"
57,Bound for variance of maximum of normal random variables,Bound for variance of maximum of normal random variables,,"Suppose that $(X_1,\ldots,X_n)=\mathbf{X}\sim N(\mathbf{0},\Sigma)$ is an $n$-dimensional normal random vector. I want to show the bound $$ \text{Var}\left(\max_{i\leq n} X_i\right)\leq \max_{i\leq n} \text{Var}(X_i)$$ How do I even begin showing this type of bound?","Suppose that $(X_1,\ldots,X_n)=\mathbf{X}\sim N(\mathbf{0},\Sigma)$ is an $n$-dimensional normal random vector. I want to show the bound $$ \text{Var}\left(\max_{i\leq n} X_i\right)\leq \max_{i\leq n} \text{Var}(X_i)$$ How do I even begin showing this type of bound?",,"['probability', 'statistics', 'probability-theory', 'inequality']"
58,Definition of Standard Deviation,Definition of Standard Deviation,,"We note that given a probability distribution function $P$ over a space $U$ the expected value of a function of the elements in U: $$ E(f(x)) = \int_{U} f(x)P(x) $$ We thus consider the mean as the expected value of the numbers that is: $$ E(x) = \int_{U} x P(x) $$ Now we consider ""standard deviation"" to be the expected difference between a variable from the mean that is $$ Std(x) = E(|x - E(x)|)  = E\left(\sqrt{(x - E(x))^2}\right) $$ Yet Standard deviation is always measured as: $$ \sqrt{E((x - E(x)^2)} $$ The latter formula doesn't make sense to me. Can someone explain why mine is wrong and hte latter is corret?","We note that given a probability distribution function $P$ over a space $U$ the expected value of a function of the elements in U: $$ E(f(x)) = \int_{U} f(x)P(x) $$ We thus consider the mean as the expected value of the numbers that is: $$ E(x) = \int_{U} x P(x) $$ Now we consider ""standard deviation"" to be the expected difference between a variable from the mean that is $$ Std(x) = E(|x - E(x)|)  = E\left(\sqrt{(x - E(x))^2}\right) $$ Yet Standard deviation is always measured as: $$ \sqrt{E((x - E(x)^2)} $$ The latter formula doesn't make sense to me. Can someone explain why mine is wrong and hte latter is corret?",,"['probability', 'statistics', 'probability-distributions', 'expectation', 'standard-deviation']"
59,Motivation behind standard deviation?,Motivation behind standard deviation?,,"Let's take the numbers 0-10.  Their mean is 5, and the individual deviations from 5 are -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5 And so the average (magnitude of) deviation from the mean is $30/11 \approx 2.72$. However, this is not the standard deviation.  The standard deviation is $\sqrt{10} \approx 3.16$. The first mean-deviation is a simpler and by far more intuitive definition of the ""standard-deviation"" , so I'm sure it's the first definition statisticians worked with.  However, for some reason they decided to adopt the second definition instead.  What is the reasoning behind that decision?","Let's take the numbers 0-10.  Their mean is 5, and the individual deviations from 5 are -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5 And so the average (magnitude of) deviation from the mean is $30/11 \approx 2.72$. However, this is not the standard deviation.  The standard deviation is $\sqrt{10} \approx 3.16$. The first mean-deviation is a simpler and by far more intuitive definition of the ""standard-deviation"" , so I'm sure it's the first definition statisticians worked with.  However, for some reason they decided to adopt the second definition instead.  What is the reasoning behind that decision?",,"['intuition', 'statistics', 'standard-deviation']"
60,Help with a cumulative distribution function question.,Help with a cumulative distribution function question.,,This is a question I want to solve: The random variable $X$ has cdf: $$ F_X(x) = \begin{cases} \begin{align} &0 &&x <0\\ &0.5 + c\sin^2\left(\frac{\pi x}{2}\right) &0 \leq\; &x \leq 1\\ &1 &&x>1 \end{align} \end{cases} $$ (a) What values can $c$ assume? (b) Plot the cdf. (c) Find $P[X > 0]$. I assume that $x$ is between $0$ and $1$ so $$ 0.5 + c \sin^2(\pi\times x/2) = 0 $$ then $x=1$ and $$ c \sin^2(\pi\times 1/2) = -0.5 $$ since $c = -0.5$ Is that correct and I need help with the nother parts please.,This is a question I want to solve: The random variable $X$ has cdf: $$ F_X(x) = \begin{cases} \begin{align} &0 &&x <0\\ &0.5 + c\sin^2\left(\frac{\pi x}{2}\right) &0 \leq\; &x \leq 1\\ &1 &&x>1 \end{align} \end{cases} $$ (a) What values can $c$ assume? (b) Plot the cdf. (c) Find $P[X > 0]$. I assume that $x$ is between $0$ and $1$ so $$ 0.5 + c \sin^2(\pi\times x/2) = 0 $$ then $x=1$ and $$ c \sin^2(\pi\times 1/2) = -0.5 $$ since $c = -0.5$ Is that correct and I need help with the nother parts please.,,"['probability', 'statistics']"
61,Proving the sample variance has a chi squared critical value,Proving the sample variance has a chi squared critical value,,"Let $X_1, . . . , X_n$ be independent normal observations with means $µ = 0$ and variances $σ^2$. For testing the null hypothesis $H_0 : σ^2 = 1$ versus the alternative $H_a : σ^2 > 1$ show that the likelihood ratio test is $$\dfrac{1}{n}\sum_{i=1}^{n} x_i^2>\dfrac{k}{n}$$ where the critical value $k$ is the $\alpha$ critical value for the $\chi^2_n$ distribution. You can use the fact that $$\hat{\sigma^2}=\dfrac{1}{n}\sum_{i=1}^{n} x_i^2$$ Basically I found the likelihood ratio which I got was $$T=2[\dfrac{-n}{2}ln(\hat{\sigma^2})-\dfrac{n}{2}+\dfrac{1}{2}\sum_{i=1}^{n} x_i^2]$$ Let $k\in\mathbb{R}$ such that  $$T=2[\dfrac{-n}{2}ln(\hat{\sigma^2})-\dfrac{n}{2}+\dfrac{1}{2}\sum_{i=1}^{n} x_i^2]>k\geq 0$$ since we know $T\geq 0$. From here I get $$\dfrac{1}{n}\sum_{i=1}^nx_i^2-ln(\hat{\sigma^2})-1>\dfrac{k}{n}$$. The only way I can establish this relationship is by seeing that since $T\geq 0$ then it follows that $$\dfrac{1}{n}\sum_{i=1}^nx_i^2>ln(\hat{\sigma^2})+1\implies\dfrac{1}{n}\sum_{i=1}^nx_i^2>\dfrac{k}{n}\implies \sum_{i=1}^nx_i^2>k $$. Now under the null hypothesis it follows $X_1,..,X_n$~$N(0,1)$ and iid (Cochrans Theorem). Therefore it follows $\sum_{i=1}^nx_i^2$~$\chi_n^2$. We can let $k=\chi_{\alpha,n}^2$ for any specified $\alpha$. Would this be correct? Thanks. This was the only way I could see doing this problem.","Let $X_1, . . . , X_n$ be independent normal observations with means $µ = 0$ and variances $σ^2$. For testing the null hypothesis $H_0 : σ^2 = 1$ versus the alternative $H_a : σ^2 > 1$ show that the likelihood ratio test is $$\dfrac{1}{n}\sum_{i=1}^{n} x_i^2>\dfrac{k}{n}$$ where the critical value $k$ is the $\alpha$ critical value for the $\chi^2_n$ distribution. You can use the fact that $$\hat{\sigma^2}=\dfrac{1}{n}\sum_{i=1}^{n} x_i^2$$ Basically I found the likelihood ratio which I got was $$T=2[\dfrac{-n}{2}ln(\hat{\sigma^2})-\dfrac{n}{2}+\dfrac{1}{2}\sum_{i=1}^{n} x_i^2]$$ Let $k\in\mathbb{R}$ such that  $$T=2[\dfrac{-n}{2}ln(\hat{\sigma^2})-\dfrac{n}{2}+\dfrac{1}{2}\sum_{i=1}^{n} x_i^2]>k\geq 0$$ since we know $T\geq 0$. From here I get $$\dfrac{1}{n}\sum_{i=1}^nx_i^2-ln(\hat{\sigma^2})-1>\dfrac{k}{n}$$. The only way I can establish this relationship is by seeing that since $T\geq 0$ then it follows that $$\dfrac{1}{n}\sum_{i=1}^nx_i^2>ln(\hat{\sigma^2})+1\implies\dfrac{1}{n}\sum_{i=1}^nx_i^2>\dfrac{k}{n}\implies \sum_{i=1}^nx_i^2>k $$. Now under the null hypothesis it follows $X_1,..,X_n$~$N(0,1)$ and iid (Cochrans Theorem). Therefore it follows $\sum_{i=1}^nx_i^2$~$\chi_n^2$. We can let $k=\chi_{\alpha,n}^2$ for any specified $\alpha$. Would this be correct? Thanks. This was the only way I could see doing this problem.",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'proof-verification']"
62,Is AR(p) strictly stationar?,Is AR(p) strictly stationar?,,"Good evening. Is it true that model AR(p) is a strictly stacionar random sequence? Model AR(p) is given by $X_{t} = \varphi_{1} X_{t-1} + \ldots + \varphi_{p} X_{t-p} + Y_{t}$ where $\{Y_{t}\}_{t \in {Z}}$ is white noise and strict stacionarity means that all finite-dimensional distributions are invariant with respect to shift. If so, can you prove it?","Good evening. Is it true that model AR(p) is a strictly stacionar random sequence? Model AR(p) is given by $X_{t} = \varphi_{1} X_{t-1} + \ldots + \varphi_{p} X_{t-p} + Y_{t}$ where $\{Y_{t}\}_{t \in {Z}}$ is white noise and strict stacionarity means that all finite-dimensional distributions are invariant with respect to shift. If so, can you prove it?",,"['statistics', 'random-variables']"
63,Finding conditional expectation from system of equations,Finding conditional expectation from system of equations,,"I have three equations: $$X_m = \beta_0 + \beta_1 \cdot X_I + \varepsilon_{BL}$$ $$W_M = X_M + \varepsilon_{MBL}$$ $$W_I = \gamma_0 + \gamma_1 \cdot X_I + \varepsilon_{RDI}$$ The $\varepsilon$'s are normally distributed with mean 0, variance $\sigma^2$. I need to find E[$X_I\mid W_I$] and E[$X_I\mid W_I,W_M$]. The first is straightforward because I have an equation that relates $X_I$ and $W_I$, but how do find the latter expectation?","I have three equations: $$X_m = \beta_0 + \beta_1 \cdot X_I + \varepsilon_{BL}$$ $$W_M = X_M + \varepsilon_{MBL}$$ $$W_I = \gamma_0 + \gamma_1 \cdot X_I + \varepsilon_{RDI}$$ The $\varepsilon$'s are normally distributed with mean 0, variance $\sigma^2$. I need to find E[$X_I\mid W_I$] and E[$X_I\mid W_I,W_M$]. The first is straightforward because I have an equation that relates $X_I$ and $W_I$, but how do find the latter expectation?",,"['statistics', 'conditional-expectation']"
64,extended PCA (tangled matrices),extended PCA (tangled matrices),,"Given an $m$ by $n$ matrix $A$ and the constant $r$, the principal component analysis allows us to find matrices $W$ and $H$ so that the $WH$ gives a lower rank approximation of $A$. In other words, $A_{m\times n} \cong W_{m\times r}H_{r\times n}$ where $W$ is an $m$ by $r$ matrix and $H$ is an $r$ by $n$ matrix such that $|A-WH|^2$ is minimized. ($r$ is smaller than $m$ and $n$) Now we have a different but related problem, which I was wondering if it can be solved in similar way. Instead of one matrix A, we are given two matrices $A_{m\times n}$ and $B_{m\times p}$ and the constants $r$ and $\lambda$. We want to find three matrices $W_{m\times r}$,$H_{r\times n}$ and $G_{r\times p}$ such that $A \cong WH$ $B \cong WG$ The objective function that we want to minimize is: $C = |A-WH|^2+ \lambda .  |B-WG|^2$ How can we find the optimal $W$,$H$ and $G$ matrices?","Given an $m$ by $n$ matrix $A$ and the constant $r$, the principal component analysis allows us to find matrices $W$ and $H$ so that the $WH$ gives a lower rank approximation of $A$. In other words, $A_{m\times n} \cong W_{m\times r}H_{r\times n}$ where $W$ is an $m$ by $r$ matrix and $H$ is an $r$ by $n$ matrix such that $|A-WH|^2$ is minimized. ($r$ is smaller than $m$ and $n$) Now we have a different but related problem, which I was wondering if it can be solved in similar way. Instead of one matrix A, we are given two matrices $A_{m\times n}$ and $B_{m\times p}$ and the constants $r$ and $\lambda$. We want to find three matrices $W_{m\times r}$,$H_{r\times n}$ and $G_{r\times p}$ such that $A \cong WH$ $B \cong WG$ The objective function that we want to minimize is: $C = |A-WH|^2+ \lambda .  |B-WG|^2$ How can we find the optimal $W$,$H$ and $G$ matrices?",,"['linear-algebra', 'matrices', 'statistics', 'eigenvalues-eigenvectors']"
65,"Urn with marbles, unknown number of colors","Urn with marbles, unknown number of colors",,"When I started with this calculation I thought this was going to be a flashback from school decades ago but now after searching I'm confused if I'm over thinking it or if it's not as trivial as I thought - please point me in the right direction if I am. Assume an urn with N=1000 total marbles. After pulling 70 without replacement, 11 different colors were drawn with different frequencies. based on only these values, can I calculate the probability there are k colors? I know 10 < k < 942 but how do I calculate the p for let's say k= 50 or what range the p would be less than 0.05? Thank you!","When I started with this calculation I thought this was going to be a flashback from school decades ago but now after searching I'm confused if I'm over thinking it or if it's not as trivial as I thought - please point me in the right direction if I am. Assume an urn with N=1000 total marbles. After pulling 70 without replacement, 11 different colors were drawn with different frequencies. based on only these values, can I calculate the probability there are k colors? I know 10 < k < 942 but how do I calculate the p for let's say k= 50 or what range the p would be less than 0.05? Thank you!",,"['statistics', 'sampling']"
66,How to calculate probability of users generating distributed events reaching n events per 15 minutes?,How to calculate probability of users generating distributed events reaching n events per 15 minutes?,,We have games & apps that connect to services such as Facebook and Twitter to fetch information. These services have various rate-limit caps that you cannot exceed - typically based on a 15 minute window of time. If we exceed this rate - the service blocks for a while. This makes my users sad. For a concrete example - you can only fetch a users tweets about 300 times per 15 minute window. I would like to estimate how many users it might take before I could reasonably expect to hit this quota of 300 events in any given 15 minute window. This is so I can look ahead from our usage trends and maybe cache this data or pool it or whatever. Assumptions: A user can be expected to use the app for 5 minutes then quit There is a 1/5 any given user will access this twitter feed during a session (based on actual usage) I would restrict this usage to daylight hours (Not yet concerned about lower levels of - users at night - most of our gamers are in the US mainland and not night owls) I assume usage is evenly spread across this time. I see it is connected to questions such as this: ( How to calculate the probability of two events happening within a certain time period using exponential distribution ) but I can't quite connect the dots :) Thanks for any input!,We have games & apps that connect to services such as Facebook and Twitter to fetch information. These services have various rate-limit caps that you cannot exceed - typically based on a 15 minute window of time. If we exceed this rate - the service blocks for a while. This makes my users sad. For a concrete example - you can only fetch a users tweets about 300 times per 15 minute window. I would like to estimate how many users it might take before I could reasonably expect to hit this quota of 300 events in any given 15 minute window. This is so I can look ahead from our usage trends and maybe cache this data or pool it or whatever. Assumptions: A user can be expected to use the app for 5 minutes then quit There is a 1/5 any given user will access this twitter feed during a session (based on actual usage) I would restrict this usage to daylight hours (Not yet concerned about lower levels of - users at night - most of our gamers are in the US mainland and not night owls) I assume usage is evenly spread across this time. I see it is connected to questions such as this: ( How to calculate the probability of two events happening within a certain time period using exponential distribution ) but I can't quite connect the dots :) Thanks for any input!,,"['probability', 'statistics', 'probability-distributions']"
67,Indicator function property,Indicator function property,,"The indicator function for a probability event $A \subset \Omega$ is given by $ \mathbf{1}_A(x) =\begin{cases} 1 & \text{if }x \in A \\ 0 & \text{if }x \notin A. \end{cases}$ Consider $N$ dependent events $A_1 \leq a,A_2 \leq a,\cdots,A_N \leq a \subset \Omega.$ Now, we want to evaluate the probability $ \Pr \{A_1 \leq a,A_2 \leq a,\cdots,A_N \leq a\}$, which can be written in terms of the indicator functions as $\Pr \{A_1 \leq a,A_2 \leq a,\cdots,A_N \leq a\} = E \left[ \mathbf{1}_{A_1 \leq a,A_2 \leq a,\cdots,A_N \leq a}\right].$ How to arrive at the next step in terms of covariance of the indicator random variables? Example: Consider the 2 events case. Then, $$\begin{align} \Pr \{A_1 \leq a,A_2 \leq a\} &= E \left[ \mathbf{1}_{A_1 \leq a,A_2 \leq a}\right]\\ &=E \left[ \mathbf{1}_{A_1 \leq a} \mathbf{1}_{A_2 \leq a}\right]\\ &=E \left[ \mathbf{1}_{A_1 \leq a} \right] E \left[ \mathbf{1}_{A_2 \leq a}\right]+\operatorname{Cov}\left(\mathbf{1}_{A_1 \leq a},\mathbf{1}_{A_2 \leq a} \right)\end{align}$$","The indicator function for a probability event $A \subset \Omega$ is given by $ \mathbf{1}_A(x) =\begin{cases} 1 & \text{if }x \in A \\ 0 & \text{if }x \notin A. \end{cases}$ Consider $N$ dependent events $A_1 \leq a,A_2 \leq a,\cdots,A_N \leq a \subset \Omega.$ Now, we want to evaluate the probability $ \Pr \{A_1 \leq a,A_2 \leq a,\cdots,A_N \leq a\}$, which can be written in terms of the indicator functions as $\Pr \{A_1 \leq a,A_2 \leq a,\cdots,A_N \leq a\} = E \left[ \mathbf{1}_{A_1 \leq a,A_2 \leq a,\cdots,A_N \leq a}\right].$ How to arrive at the next step in terms of covariance of the indicator random variables? Example: Consider the 2 events case. Then, $$\begin{align} \Pr \{A_1 \leq a,A_2 \leq a\} &= E \left[ \mathbf{1}_{A_1 \leq a,A_2 \leq a}\right]\\ &=E \left[ \mathbf{1}_{A_1 \leq a} \mathbf{1}_{A_2 \leq a}\right]\\ &=E \left[ \mathbf{1}_{A_1 \leq a} \right] E \left[ \mathbf{1}_{A_2 \leq a}\right]+\operatorname{Cov}\left(\mathbf{1}_{A_1 \leq a},\mathbf{1}_{A_2 \leq a} \right)\end{align}$$",,"['probability', 'statistics']"
68,Summation of binomial number of poisson random variables,Summation of binomial number of poisson random variables,,"Z is summation of K random variables that each has Poisson distribution with different means. But, K is a Binomial random with parameters of n and p . I was wondering what is the distribution of Z?","Z is summation of K random variables that each has Poisson distribution with different means. But, K is a Binomial random with parameters of n and p . I was wondering what is the distribution of Z?",,"['probability', 'statistics', 'probability-distributions', 'stochastic-processes', 'random-variables']"
69,A math proof within a question about homogeneous Poisson process,A math proof within a question about homogeneous Poisson process,,"We know that a homogeneous Poisson process is a process with a constant intensity $\lambda$ . That is, for any time interval $[t, t+\Delta t]$ , $P\left \{ k \text{ events in } [t, t+\Delta t] \right \}=\frac{\exp(-\lambda \, \Delta t)(\lambda \, \Delta t)^k}{k!}$ . And therefore, event count in $[0, T]$ follows a Poisson distribution with rate $\lambda T$ . That is, $P\left \{ N(T)=k\right \}=\frac{\exp(-\lambda T)(\lambda T)^k}{k!}$ . ( $N$ is the count.) The problem is: Prove that the following simulation generates a homogeneous Poisson process with rate $\lambda$ on $[0, T]$ : Step 1: Sample $m$ from Poisson distribution with mean $\lambda T$ . Step 2: Sample $s_1, \cdots,s_m$ i.i.d. from uniform $[0, T]$ . That is , demonstrate that for any time interval $[t, t+\Delta t]$ in $[0,T]$ , $P\left \{ k \text{ events in } [t, t+\Delta t] \right \}=\frac{\exp(-\lambda \, \Delta t)(\lambda \, \Delta t)^k}{k!}$ . Now we look at the problem, we have Given $m$ events in $[0,T]$ , \begin{align} & P\left \{ k \text{ events in } [t, t+\Delta t] \right \}\\ = {} & \sum^\infty_{m=k} P\left \{ k \text{ events in } [t, t+\Delta t],m \;\text{events in}\; [0,T]\right \}\\ = {} & \sum^\infty_{m=k} P\left\{ k \text{ events in } [t, t+\Delta t] \mid m \text{ events in } [0,T]\right \}\cdot P\left \{ m \text{ events in } [0,T] \right \}\\ = {} & \sum_{m=k}^\infty \binom{m}{k}\left(\frac{\Delta t}{T}\right)^k \left(\frac{T-\Delta t}{T}\right)^{m-k} \cdot \frac{\exp(-\lambda T)(\lambda T)^m}{m!} \end{align} So in order to prove the result, we should have $$\sum_{m=k}^\infty\binom{m}{k} \left(\frac{\Delta t}{T}\right)^k \left(\frac{T-\Delta t}{T}\right)^{m-k} \cdot \frac{\exp(-\lambda T)(\lambda T)^m}{m!}=\frac{\exp(-\lambda \,\Delta t)(\lambda \,\Delta t)^k}{k!} \tag{$*$} $$ and this should hold. But my question is how to derive $(*)$ mathematically? How to show the two sides are equal in $(*)$ ? Can you show it? Thanks in advance.","We know that a homogeneous Poisson process is a process with a constant intensity . That is, for any time interval , . And therefore, event count in follows a Poisson distribution with rate . That is, . ( is the count.) The problem is: Prove that the following simulation generates a homogeneous Poisson process with rate on : Step 1: Sample from Poisson distribution with mean . Step 2: Sample i.i.d. from uniform . That is , demonstrate that for any time interval in , . Now we look at the problem, we have Given events in , So in order to prove the result, we should have and this should hold. But my question is how to derive mathematically? How to show the two sides are equal in ? Can you show it? Thanks in advance.","\lambda [t, t+\Delta t] P\left \{ k \text{ events in } [t, t+\Delta t] \right \}=\frac{\exp(-\lambda \, \Delta t)(\lambda \, \Delta t)^k}{k!} [0, T] \lambda T P\left \{ N(T)=k\right \}=\frac{\exp(-\lambda T)(\lambda T)^k}{k!} N \lambda [0, T] m \lambda T s_1, \cdots,s_m [0, T] [t, t+\Delta t] [0,T] P\left \{ k \text{ events in } [t, t+\Delta t] \right \}=\frac{\exp(-\lambda \, \Delta t)(\lambda \, \Delta t)^k}{k!} m [0,T] \begin{align}
& P\left \{ k \text{ events in } [t, t+\Delta t] \right \}\\
= {} & \sum^\infty_{m=k} P\left \{ k \text{ events in } [t, t+\Delta t],m \;\text{events in}\; [0,T]\right \}\\
= {} & \sum^\infty_{m=k} P\left\{ k \text{ events in } [t, t+\Delta t] \mid m \text{ events in } [0,T]\right \}\cdot P\left \{ m \text{ events in } [0,T] \right \}\\
= {} & \sum_{m=k}^\infty \binom{m}{k}\left(\frac{\Delta t}{T}\right)^k \left(\frac{T-\Delta t}{T}\right)^{m-k} \cdot \frac{\exp(-\lambda T)(\lambda T)^m}{m!}
\end{align} \sum_{m=k}^\infty\binom{m}{k} \left(\frac{\Delta t}{T}\right)^k \left(\frac{T-\Delta t}{T}\right)^{m-k} \cdot \frac{\exp(-\lambda T)(\lambda T)^m}{m!}=\frac{\exp(-\lambda \,\Delta t)(\lambda \,\Delta t)^k}{k!} \tag{*}  (*) (*)","['statistics', 'stochastic-processes', 'self-learning', 'poisson-distribution']"
70,Variance of event counting,Variance of event counting,,"I have this question (not homework, review problem for qualifying exam), tried approaching it a couple of ways (unsuccessfully). Any recommendations? Let $X_1,..,X_n$ be i.i.d continuous rvs. A record is said to occur at time $k$ if $X_k > X_i$ for all $i = 1,...,k-1$. Let $N$ denote the number of records. Find the variance of $N$.","I have this question (not homework, review problem for qualifying exam), tried approaching it a couple of ways (unsuccessfully). Any recommendations? Let $X_1,..,X_n$ be i.i.d continuous rvs. A record is said to occur at time $k$ if $X_k > X_i$ for all $i = 1,...,k-1$. Let $N$ denote the number of records. Find the variance of $N$.",,"['probability', 'statistics', 'order-statistics']"
71,How much data do I need to gather?,How much data do I need to gather?,,"I'm studying a manufacturing process that produces widgets, with a number of machines that breakdown or jam occasionally. I want to figure out how many hours of studying I need to do, in order to be confident in knowing what the biggest causes of downtime are. I will then make changes to the machines that are causing the most problems, and continue to study the process. I then want to determine how much better the process is. How should I go about this? It seems like it should be easy, but I don't know where to start, thanks in advance! Update #1 I think I need to start with some bounds for the problem, such as a confidence level, and population size. I'm not sure why it is the case, but people seem happy with 95% confidence. I think that the population is unknown / infinite, as it is time. So, how does my desired confidence level (95%) translate into a sample size (number of hours)?","I'm studying a manufacturing process that produces widgets, with a number of machines that breakdown or jam occasionally. I want to figure out how many hours of studying I need to do, in order to be confident in knowing what the biggest causes of downtime are. I will then make changes to the machines that are causing the most problems, and continue to study the process. I then want to determine how much better the process is. How should I go about this? It seems like it should be easy, but I don't know where to start, thanks in advance! Update #1 I think I need to start with some bounds for the problem, such as a confidence level, and population size. I'm not sure why it is the case, but people seem happy with 95% confidence. I think that the population is unknown / infinite, as it is time. So, how does my desired confidence level (95%) translate into a sample size (number of hours)?",,['statistics']
72,Expected value of an exponential of a gaussian random variable,Expected value of an exponential of a gaussian random variable,,"$$E (Y_t)=E(e^{X_t}) = E(e^{N(X_0e^{at};\frac{b^2}{2a}(e^{2at}-1)}) =\text{ ?}$$ Knowning that $$X_t \sim N\left[X_0e^{at};\frac{b^2}{2a}(e^{2at}-1)\right]$$ $$X_t= aX_t \, dt+b \, dB_t$$ The processes are standard brownian motions. Thank you","$$E (Y_t)=E(e^{X_t}) = E(e^{N(X_0e^{at};\frac{b^2}{2a}(e^{2at}-1)}) =\text{ ?}$$ Knowning that $$X_t \sim N\left[X_0e^{at};\frac{b^2}{2a}(e^{2at}-1)\right]$$ $$X_t= aX_t \, dt+b \, dB_t$$ The processes are standard brownian motions. Thank you",,"['statistics', 'stochastic-processes']"
73,How to parameterize some emprical data,How to parameterize some emprical data,,"I would like to describe a bunch of data that I have collected as a function of two variables.  The data is phytoplankton absorption in my local area that has changed in concentration.  The data looks similar to this image. Phytoplankton will vary in absorption greatly around 440 (nm) and 665 (nm)  [Actually it is more complicated than that but for my purposes it is fine.] The total absorption will increase with concentration.  It will increase non-linearly as their are shading effects and chlorophyll packaging effects. I was thinking that it may be possible to come up with a two component empirical model, possibly? based around a basis vector (or the mean value of lots of measurements) and somehow describing the variance around 440 and 665 nm to scale the total absorption. I don't really know where to start looking. These so called 'bio-optical' models are comon for CDOM and Particle scattering but they are much simpler to describe by fitting curves to their much simpler shapes. Any help regards to what books to read or what to begin searching would be appreciated.  I am not a mathematician, so I am not great at this stuff but I did do Vector calc and linear algebra at uni. [EDIT]  sorry lack of axis.  X axis is wavelength in nm 440 and 665 are the two peaks.","I would like to describe a bunch of data that I have collected as a function of two variables.  The data is phytoplankton absorption in my local area that has changed in concentration.  The data looks similar to this image. Phytoplankton will vary in absorption greatly around 440 (nm) and 665 (nm)  [Actually it is more complicated than that but for my purposes it is fine.] The total absorption will increase with concentration.  It will increase non-linearly as their are shading effects and chlorophyll packaging effects. I was thinking that it may be possible to come up with a two component empirical model, possibly? based around a basis vector (or the mean value of lots of measurements) and somehow describing the variance around 440 and 665 nm to scale the total absorption. I don't really know where to start looking. These so called 'bio-optical' models are comon for CDOM and Particle scattering but they are much simpler to describe by fitting curves to their much simpler shapes. Any help regards to what books to read or what to begin searching would be appreciated.  I am not a mathematician, so I am not great at this stuff but I did do Vector calc and linear algebra at uni. [EDIT]  sorry lack of axis.  X axis is wavelength in nm 440 and 665 are the two peaks.",,"['statistics', 'statistical-inference']"
74,Obtain distribution of mid-range in uniform,Obtain distribution of mid-range in uniform,,"I want to obtain distribution of mid-range, $(x_{(1)} + x_{(n)})/2$, of an uniform(a, b) random variable.  One can use the following transformation. $M = \frac{X_{(1)} + X_{(n)}}{2}$ and $W = \frac{X_{(n)} - X_{(1)}}{2}$ clearly $X_{(1)} = M-W$, $X_{(n)} = M + W$ and the jacobian is 2. The joint distribution of $m, w$ is $f(m, w) = 2^{n-1}n(n-1)w^{n-2}/(b-a)^n$. Now i want to integrating with respect to $w$ to find distribution of mid-range. But i cannot determine the limit of $w$.  How should determine the limit of that?","I want to obtain distribution of mid-range, $(x_{(1)} + x_{(n)})/2$, of an uniform(a, b) random variable.  One can use the following transformation. $M = \frac{X_{(1)} + X_{(n)}}{2}$ and $W = \frac{X_{(n)} - X_{(1)}}{2}$ clearly $X_{(1)} = M-W$, $X_{(n)} = M + W$ and the jacobian is 2. The joint distribution of $m, w$ is $f(m, w) = 2^{n-1}n(n-1)w^{n-2}/(b-a)^n$. Now i want to integrating with respect to $w$ to find distribution of mid-range. But i cannot determine the limit of $w$.  How should determine the limit of that?",,"['integration', 'statistics', 'education', 'uniform-distribution', 'order-statistics']"
75,iid and correlated order statistics - A comparison,iid and correlated order statistics - A comparison,,"This is an extension of my previous question from the post iid and correlated order statistics a comparison Consider the two random variables $X_1$ and $X_2$ defined via non-negative random variables $Y_1$ and $Y_2$ as $ X_1=\min(Y_1,Y_2)\\$  where $Y_1$ and $Y_2$ are i.i.d  and $ X_2=\min(Y_1,Y_2)$  - where $Y_1$ and $Y_2$ are correlated. The question is can we say $X_1 \leq X_2$ always? How to prove it?","This is an extension of my previous question from the post iid and correlated order statistics a comparison Consider the two random variables $X_1$ and $X_2$ defined via non-negative random variables $Y_1$ and $Y_2$ as $ X_1=\min(Y_1,Y_2)\\$  where $Y_1$ and $Y_2$ are i.i.d  and $ X_2=\min(Y_1,Y_2)$  - where $Y_1$ and $Y_2$ are correlated. The question is can we say $X_1 \leq X_2$ always? How to prove it?",,"['probability', 'statistics', 'order-statistics', 'independence']"
76,"Rigorously, what is the goal of (machine/statistical) Learning and why is that the goal?","Rigorously, what is the goal of (machine/statistical) Learning and why is that the goal?",,"After some time doing machine learning and statistical learning theory, I decided to return to my foundations and make sure that the goal of what I am doing makes sense. First let me define $I(f)$ as the generalization error $I(f) = \int_{x,y} V(f(x),y) d\rho(x,y)$ and $V(f(x),y)$ as the cost function. Also, let $f_S$ be the output of a learning algorithm $A$ given some data, i.e. $f_S = A(S)$. One way to characterize the goal of learning is as follows: $$\inf_{f \in F} I(f)$$ given only a finite training set $S$ sampled from the distribution that generated the data $\rho(x,y)$. Where $F$ is the space of functions where the integral is well defined (things are measurable and good etc etc, not necessarily Hilbert spaces). Technically, if the inf could be achieved, then that would be the best of the best. The optimum of the optimum. Possibly not feasible to compute but mathematically it makes sense. Another way of saying this is, minimizing the expected error given only the training data is the goal of learning. Since we probably can't achieve the above infimum (minimization), we need a way to quantify the quality of our solution $f_S$. One possibility could be: $$\inf_{f_s \in \mathcal{H}} \left\{ I(f_S) - \inf_{f \in F} I(f) \right\} $$ i.e. trying to have a $f_S$ as close to the best as possible. However, I was considering a different way of characterizing what exactly it means to learn and I was wondering if it made sense or if they were equivalent or maybe one is stronger than the other. Consider minimizing the infinity norm between the algorithms output function $f_S = A(S)$ (where $A$ is the learning algorithm and $S$ is the training set) and the best function $f^* = \operatorname{arginf}\limits_{f \in F} I(f)$, i.e. consider: $$ \inf_{f \in \mathcal{H}} \left\{ \sup_{x \in \mathcal{X}} |f_S(x) - f^*(x)| \right\}$$ would trying to minimize $\sup_{x \in \mathcal{X}} |f_S(x) - f^*(x)|$ make sense as a goal for learning? I was told that, that goal was ""too strong"". What does it mean to strong? Is it in a mathematical sense? Like, minimizing the above implies minimizing $I(f_S) - \inf_{f \in F} I(f)$? Intuitively it seems to me that indeed the above implies minimizing $I(f_S) - \inf_{f \in F} I(f)$. Why? Because $\inf_{f \in \mathcal{H}} \left\{ \sup_{x \in \mathcal{X}} |f_S(x) - f^*(x)| \right\}$ means to minimize the difference between $f_S$ (output of learning algorithm) and the optimum $f^*$. This means that if the largest difference is minimized for all $x$, then $f_S$ and $f^*$ are basically the same (or approximately the same). Hence, they should have the same average cost over the whole data space. i.e. $$I(f_S) - \inf_{f \in F} I(f) \approx 0$$ Maybe is way to strong and we only need them to be similar for data samples $(x,y)$ that are actually possible to sample, so maybe: $$ \inf_{f \in \mathcal{H}} \left\{ \sup_{x \in \operatorname{support}(\rho)} |f_S(x) - f^*(x)| \right\}$$ Would this make more sense? Or are both definitions still unreasonable quantities to try to optimize in learning? Why would minimizing: $$ I(f_S) - \inf_{f \in F} I(f)$$ be a much better goal? Also, after thinking about it more, maybe we would like to take into account the relative weights or relative frequencies of what points are sampled and instead redefine the quantity I suggested and minimize it: $$ \int_{x} |f_S(x) - f^*(x) | d\rho(x)$$ maybe choosing an $f_S$ that achieves the above minimum is a good choice. However, I've never even seen this discussed anywhere. Is the above a bad quantity to consider? What is the difference with minimizing $I(f_S) - \inf_{f \in F} I(f)$ and $ \int_{x,y} |f_S(x) - f^*(x) | d\rho(x,y)$? What are the pros and cons of one and the other? Why is $I(f_S) - \inf_{f \in F} I(f)$ is probably better?","After some time doing machine learning and statistical learning theory, I decided to return to my foundations and make sure that the goal of what I am doing makes sense. First let me define $I(f)$ as the generalization error $I(f) = \int_{x,y} V(f(x),y) d\rho(x,y)$ and $V(f(x),y)$ as the cost function. Also, let $f_S$ be the output of a learning algorithm $A$ given some data, i.e. $f_S = A(S)$. One way to characterize the goal of learning is as follows: $$\inf_{f \in F} I(f)$$ given only a finite training set $S$ sampled from the distribution that generated the data $\rho(x,y)$. Where $F$ is the space of functions where the integral is well defined (things are measurable and good etc etc, not necessarily Hilbert spaces). Technically, if the inf could be achieved, then that would be the best of the best. The optimum of the optimum. Possibly not feasible to compute but mathematically it makes sense. Another way of saying this is, minimizing the expected error given only the training data is the goal of learning. Since we probably can't achieve the above infimum (minimization), we need a way to quantify the quality of our solution $f_S$. One possibility could be: $$\inf_{f_s \in \mathcal{H}} \left\{ I(f_S) - \inf_{f \in F} I(f) \right\} $$ i.e. trying to have a $f_S$ as close to the best as possible. However, I was considering a different way of characterizing what exactly it means to learn and I was wondering if it made sense or if they were equivalent or maybe one is stronger than the other. Consider minimizing the infinity norm between the algorithms output function $f_S = A(S)$ (where $A$ is the learning algorithm and $S$ is the training set) and the best function $f^* = \operatorname{arginf}\limits_{f \in F} I(f)$, i.e. consider: $$ \inf_{f \in \mathcal{H}} \left\{ \sup_{x \in \mathcal{X}} |f_S(x) - f^*(x)| \right\}$$ would trying to minimize $\sup_{x \in \mathcal{X}} |f_S(x) - f^*(x)|$ make sense as a goal for learning? I was told that, that goal was ""too strong"". What does it mean to strong? Is it in a mathematical sense? Like, minimizing the above implies minimizing $I(f_S) - \inf_{f \in F} I(f)$? Intuitively it seems to me that indeed the above implies minimizing $I(f_S) - \inf_{f \in F} I(f)$. Why? Because $\inf_{f \in \mathcal{H}} \left\{ \sup_{x \in \mathcal{X}} |f_S(x) - f^*(x)| \right\}$ means to minimize the difference between $f_S$ (output of learning algorithm) and the optimum $f^*$. This means that if the largest difference is minimized for all $x$, then $f_S$ and $f^*$ are basically the same (or approximately the same). Hence, they should have the same average cost over the whole data space. i.e. $$I(f_S) - \inf_{f \in F} I(f) \approx 0$$ Maybe is way to strong and we only need them to be similar for data samples $(x,y)$ that are actually possible to sample, so maybe: $$ \inf_{f \in \mathcal{H}} \left\{ \sup_{x \in \operatorname{support}(\rho)} |f_S(x) - f^*(x)| \right\}$$ Would this make more sense? Or are both definitions still unreasonable quantities to try to optimize in learning? Why would minimizing: $$ I(f_S) - \inf_{f \in F} I(f)$$ be a much better goal? Also, after thinking about it more, maybe we would like to take into account the relative weights or relative frequencies of what points are sampled and instead redefine the quantity I suggested and minimize it: $$ \int_{x} |f_S(x) - f^*(x) | d\rho(x)$$ maybe choosing an $f_S$ that achieves the above minimum is a good choice. However, I've never even seen this discussed anywhere. Is the above a bad quantity to consider? What is the difference with minimizing $I(f_S) - \inf_{f \in F} I(f)$ and $ \int_{x,y} |f_S(x) - f^*(x) | d\rho(x,y)$? What are the pros and cons of one and the other? Why is $I(f_S) - \inf_{f \in F} I(f)$ is probably better?",,"['statistics', 'probability-theory', 'machine-learning']"
77,Formula to generate a grade,Formula to generate a grade,,"I hope this question is appropriate for this site, if not sorry in advanced. I'm trying to come up with a formula to generate a grade, which will take into consideration the diffculty level of the questions. The person taking this quiz can determine the diffculty of the questions so I want the result to give more credit to the harder questions, because if someone answered 8/8 questions correctly in level 8, it's much harder than answering 8/8 correctly in level 1. Each one is asked X questions in 1-8 levels, but not necessarily all of them. For example lets say X was 60 and these are the results: 5/9 - level1 4/9 - level2 3/8 - level3 3/7 - level4 4/8 - level5 0/0 - level6 2/10 - level7 1/9 - level8 Does anyone have an idea for such a formula?","I hope this question is appropriate for this site, if not sorry in advanced. I'm trying to come up with a formula to generate a grade, which will take into consideration the diffculty level of the questions. The person taking this quiz can determine the diffculty of the questions so I want the result to give more credit to the harder questions, because if someone answered 8/8 questions correctly in level 8, it's much harder than answering 8/8 correctly in level 1. Each one is asked X questions in 1-8 levels, but not necessarily all of them. For example lets say X was 60 and these are the results: 5/9 - level1 4/9 - level2 3/8 - level3 3/7 - level4 4/8 - level5 0/0 - level6 2/10 - level7 1/9 - level8 Does anyone have an idea for such a formula?",,['statistics']
78,Probability of Big Leads in CoinTossing Game Evaporating,Probability of Big Leads in CoinTossing Game Evaporating,,"In a Coin Tossing game, how is the probability of a lead change affected by the size of the lead that one side has - taking into account the number of coin flips remaining in the game? I have asked for help at Statcrunch.com, Hyperstats.com and Wolfram.com without success. Given a lead at the Halfway Point in a Coin-tossing game of 20, 100, or 1,000 flips, Feller said that the probability of their being no further Lead Changes was roughly 50%. I have been trying to explore out how the Probability of a Lead Change is affected by the size of the Lead. So, I manually conducted 20 flip coin games, and collected a sample of 50 games where there was no lead change. I looked at 39 Leads which had reached a height of 5, and found that 43% finished the game at a higher level than 5, 33% finished at exactly 5, and 23% finished at a lower level than 5. However, this does not really give me what I want, because I did not record the size of leads in all the other games where there one or more lead changes. I would like to be able to make a probability statement about the chance of a lead of Size X evaporating into a Lead Change with N number of Coin Flips remaining in a game. I thought, ""Simple. For lead size of 5, just find out the probability of 6 or more heads occurring in a sample of N coinflips.  There are all sorts of calculators for that."" However, those calculators fail to take into account whether there were any lead changes during the samples of games of N size that are generated. So, for example, starting at a Lead of 5 Heads, the next 6 flips might be Tails, which would cause the lead to evaporate and a Lead Change to occur. But, the overall number of Heads in the next 20 flips might end end up equal to the number of Tails due to Lead Changes... So, I cannot just use the probability of tossing 13 Tails and 7 Tails in a sample of 20 to figure out the probability of a Lead Size of 5 disappearing given 20 more flips. I really do not have the time, nor the patience, to do any more manual coin flip experiments and I lack the programming skills to write some simulations to answer my questions. In basic terms, I want to know when the optimum time is to follow the advice ""Quit while you are ahead."" Does not the size of your lead affect the optimum time to quit, given N number of flips remaining in your game? What is the Probability that you will lose your lead versus increase your lead, depending upon the Size of your Lead and the number of flips remaining?","In a Coin Tossing game, how is the probability of a lead change affected by the size of the lead that one side has - taking into account the number of coin flips remaining in the game? I have asked for help at Statcrunch.com, Hyperstats.com and Wolfram.com without success. Given a lead at the Halfway Point in a Coin-tossing game of 20, 100, or 1,000 flips, Feller said that the probability of their being no further Lead Changes was roughly 50%. I have been trying to explore out how the Probability of a Lead Change is affected by the size of the Lead. So, I manually conducted 20 flip coin games, and collected a sample of 50 games where there was no lead change. I looked at 39 Leads which had reached a height of 5, and found that 43% finished the game at a higher level than 5, 33% finished at exactly 5, and 23% finished at a lower level than 5. However, this does not really give me what I want, because I did not record the size of leads in all the other games where there one or more lead changes. I would like to be able to make a probability statement about the chance of a lead of Size X evaporating into a Lead Change with N number of Coin Flips remaining in a game. I thought, ""Simple. For lead size of 5, just find out the probability of 6 or more heads occurring in a sample of N coinflips.  There are all sorts of calculators for that."" However, those calculators fail to take into account whether there were any lead changes during the samples of games of N size that are generated. So, for example, starting at a Lead of 5 Heads, the next 6 flips might be Tails, which would cause the lead to evaporate and a Lead Change to occur. But, the overall number of Heads in the next 20 flips might end end up equal to the number of Tails due to Lead Changes... So, I cannot just use the probability of tossing 13 Tails and 7 Tails in a sample of 20 to figure out the probability of a Lead Size of 5 disappearing given 20 more flips. I really do not have the time, nor the patience, to do any more manual coin flip experiments and I lack the programming skills to write some simulations to answer my questions. In basic terms, I want to know when the optimum time is to follow the advice ""Quit while you are ahead."" Does not the size of your lead affect the optimum time to quit, given N number of flips remaining in your game? What is the Probability that you will lose your lead versus increase your lead, depending upon the Size of your Lead and the number of flips remaining?",,['statistics']
79,Intuitive explanation of “unit root” sought,Intuitive explanation of “unit root” sought,,"I am struggling to get my head around the concept of ""unit root"" in relation to time series. And it would be a great help if someone could give me a two or three sentence intuitive explanation of the concept. As an example of the kind of thing I am after, earlier on I also wanted to find the meaning of ""hurst exponent""... and it was a great help to find out that it was simply ""a measure of the smoothness (as opposed to crinklyness) of the time series"" - see image below. EDIT: Alternatively, a pointer to an online explanation would be good, so long as it includes a good helping of "" Tell them what you are going to tell them "".","I am struggling to get my head around the concept of ""unit root"" in relation to time series. And it would be a great help if someone could give me a two or three sentence intuitive explanation of the concept. As an example of the kind of thing I am after, earlier on I also wanted to find the meaning of ""hurst exponent""... and it was a great help to find out that it was simply ""a measure of the smoothness (as opposed to crinklyness) of the time series"" - see image below. EDIT: Alternatively, a pointer to an online explanation would be good, so long as it includes a good helping of "" Tell them what you are going to tell them "".",,"['statistics', 'time-series']"
80,Grading system with multiple judges,Grading system with multiple judges,,"This is a practical question, I'm not sure if it's on-topic here. So sorry if it's not. There is a competition where judges decide the score competitors by summing their performance mark in several aspects, and different competitors might be graded by different sets of judges. E.g. There are competitors A,B and Judges 1~3. A is graded by J1 and J2, B is graded by J1 and J3. But the judges is not professionally trained so the cardinal value of the score might not be comparable with each other. For example, J1 might prefer to give a score between 2~4, J2 between 1~5, and J3 between 3~5. How should I adjust the scores so that the average score reflect the truth strength of the competitors? My thoughts: (1) Naive ranking: If J1 grades $n_1$ competitors, then the $k$-th highest scorer gets $k/n_1$ points (2) Normalized ranking: Normalize $\{k/n_1\}$. (3) Normalized score: Normalize the score given by each judge. But they have their advantages and disadvantages. So I would like to ask, what kind of method is most frequently used (I didn't go for ""optimal"", because it's hard to define which method is better)? Thanks!","This is a practical question, I'm not sure if it's on-topic here. So sorry if it's not. There is a competition where judges decide the score competitors by summing their performance mark in several aspects, and different competitors might be graded by different sets of judges. E.g. There are competitors A,B and Judges 1~3. A is graded by J1 and J2, B is graded by J1 and J3. But the judges is not professionally trained so the cardinal value of the score might not be comparable with each other. For example, J1 might prefer to give a score between 2~4, J2 between 1~5, and J3 between 3~5. How should I adjust the scores so that the average score reflect the truth strength of the competitors? My thoughts: (1) Naive ranking: If J1 grades $n_1$ competitors, then the $k$-th highest scorer gets $k/n_1$ points (2) Normalized ranking: Normalize $\{k/n_1\}$. (3) Normalized score: Normalize the score given by each judge. But they have their advantages and disadvantages. So I would like to ask, what kind of method is most frequently used (I didn't go for ""optimal"", because it's hard to define which method is better)? Thanks!",,['statistics']
81,Distinguishable balls in distinguishable boxes?,Distinguishable balls in distinguishable boxes?,,"Suppose I have $n$ distinguishable balls and $N$ distinguishable boxes. A particular configuration of this 'system' is such that there are $k$ particles in a box, b, where $1\lt b \lt N$ (i.e. the boxes are numbered). The ordering of balls in a particular box does not matter. The number of ways of realising a particular configuration is: $$n! \prod_{k=1}^{N}\frac{1}{k!}$$ I'm struggling to show that the above is true. My current thoughts (though they are wrong) are: ways of producing particular configuration = (ways of choosing $k$ balls from $n$ balls) x (ways of choosing 1 box from $N$ boxes) x (ways of choosing $n-k$ balls from $n$ balls) x (ways of choosing $N-1$ boxes from $N$ boxes) = $$nC_k \times NC_1 \times nC_{n-k} \times NC_{N-1} $$ Would anyone be willing to help me figure this out? I was asked: The statement is not clear to me. Isn't your description of a valid configuration equivalent of saying : ""put n balls in N boxes such that (at least) one box has exactly k balls"" ? - Yes, this is what I mean.","Suppose I have $n$ distinguishable balls and $N$ distinguishable boxes. A particular configuration of this 'system' is such that there are $k$ particles in a box, b, where $1\lt b \lt N$ (i.e. the boxes are numbered). The ordering of balls in a particular box does not matter. The number of ways of realising a particular configuration is: $$n! \prod_{k=1}^{N}\frac{1}{k!}$$ I'm struggling to show that the above is true. My current thoughts (though they are wrong) are: ways of producing particular configuration = (ways of choosing $k$ balls from $n$ balls) x (ways of choosing 1 box from $N$ boxes) x (ways of choosing $n-k$ balls from $n$ balls) x (ways of choosing $N-1$ boxes from $N$ boxes) = $$nC_k \times NC_1 \times nC_{n-k} \times NC_{N-1} $$ Would anyone be willing to help me figure this out? I was asked: The statement is not clear to me. Isn't your description of a valid configuration equivalent of saying : ""put n balls in N boxes such that (at least) one box has exactly k balls"" ? - Yes, this is what I mean.",,"['combinatorics', 'statistics', 'permutations', 'combinations']"
82,How to estimate the variance of several populations when every population mean and variance is different?,How to estimate the variance of several populations when every population mean and variance is different?,,"I'm currently using the Pooled Variance method, but in my case I cannot assume that every population variance is the same. Is there a method for these cases ?","I'm currently using the Pooled Variance method, but in my case I cannot assume that every population variance is the same. Is there a method for these cases ?",,"['statistics', 'statistical-inference', 'standard-deviation']"
83,Stuck on an integral of form $\int\exp(-\frac{\alpha}{m^2} - \beta m)\frac{dm}{m}$. Any ideas?,Stuck on an integral of form . Any ideas?,\int\exp(-\frac{\alpha}{m^2} - \beta m)\frac{dm}{m},"My statistical model involves the multiplication of a scalar random variable $X|X \geq 0 \sim 2\mathcal{N}(x;0,\sigma^2)\ \mathbb{I} \ [x \in \mathcal{R}_+]$, or a gaussian variable that must be strictly above zero, and and scalar exponentially distributed magnitude $M \sim \exp(m;\lambda)$. I would like to find the distribution of $C =M\cdot X$ which is clearly still positive. So far I have that: $f_C(c) = \int_0^{\infty}f_{X|M}(\frac{c}{M}|M = m)f_M(m)\frac{dm}{m}$ $\ \ \ \ \ \ \ \ \ \ = \int_0^{\infty}f_{X}(\frac{c}{m})f_M(m)\frac{dm}{m}$ $\ \ \ \ \ \ \ \ \ \ = \sqrt{\frac{2}\pi} \frac{\lambda}{\sigma}\int_0^{\infty}\exp \left({-\frac{1}{2}\left(\frac{c}{\sigma m}\right)^2} \right) \cdot \exp \left(- \lambda m\right) \frac{dm}{m}$ I haven't really founding a promising direction to pursue to integrate this. Part of what makes it difficult is the integration of the form $\int\exp(-\frac{\alpha}{m^2} - \beta m)\frac{dm}{m}$ and everything I try seems fruitless. I've considered modifying the $M$ distribution, but the exponential seems reasonable for my application. It's modelling something physical (diffusion of a single particle), but the magnitude $M$ is not determined by some well-defined rigourous process so it's quite possible the $M$ distribution has nothing to do with physics inherently. But I thought I could change the magnitude to the form $\sim \frac{1}{Z}e^{(k_bT)^{-1}U(m)}$ or even $\sim \frac{1}{Z}e^{-(k_bT)^{-1}U(m,x)} $ for some $U(\cdots)$'s if necessary, but I'm not sure if either of those would be physically justifiable. Any ideas? EDIT: for clarity.","My statistical model involves the multiplication of a scalar random variable $X|X \geq 0 \sim 2\mathcal{N}(x;0,\sigma^2)\ \mathbb{I} \ [x \in \mathcal{R}_+]$, or a gaussian variable that must be strictly above zero, and and scalar exponentially distributed magnitude $M \sim \exp(m;\lambda)$. I would like to find the distribution of $C =M\cdot X$ which is clearly still positive. So far I have that: $f_C(c) = \int_0^{\infty}f_{X|M}(\frac{c}{M}|M = m)f_M(m)\frac{dm}{m}$ $\ \ \ \ \ \ \ \ \ \ = \int_0^{\infty}f_{X}(\frac{c}{m})f_M(m)\frac{dm}{m}$ $\ \ \ \ \ \ \ \ \ \ = \sqrt{\frac{2}\pi} \frac{\lambda}{\sigma}\int_0^{\infty}\exp \left({-\frac{1}{2}\left(\frac{c}{\sigma m}\right)^2} \right) \cdot \exp \left(- \lambda m\right) \frac{dm}{m}$ I haven't really founding a promising direction to pursue to integrate this. Part of what makes it difficult is the integration of the form $\int\exp(-\frac{\alpha}{m^2} - \beta m)\frac{dm}{m}$ and everything I try seems fruitless. I've considered modifying the $M$ distribution, but the exponential seems reasonable for my application. It's modelling something physical (diffusion of a single particle), but the magnitude $M$ is not determined by some well-defined rigourous process so it's quite possible the $M$ distribution has nothing to do with physics inherently. But I thought I could change the magnitude to the form $\sim \frac{1}{Z}e^{(k_bT)^{-1}U(m)}$ or even $\sim \frac{1}{Z}e^{-(k_bT)^{-1}U(m,x)} $ for some $U(\cdots)$'s if necessary, but I'm not sure if either of those would be physically justifiable. Any ideas? EDIT: for clarity.",,"['probability', 'integration', 'statistics', 'definite-integrals', 'improper-integrals']"
84,"Notation $x^n=(x_1,\dotsc,x_n)$",Notation,"x^n=(x_1,\dotsc,x_n)","In a book on statistics I saw the notation $x^n=(x_1,\dotsc,x_n)$ and wondering how common this is in measure theory/statistics. More precisely it is about a probability space $(\mathbb{H},\mathcal{H},P) = (\times_{i=1}^\infty\mathbb{H}_i,\otimes_{i=1}^\infty\mathcal{H}_i,\otimes_{i=1}^\infty P_i)$ and $x=(x_1,x_2,...) \in \mathbb{H}$. The random variables $X_i: \mathbb{H} \to \mathbb{H}_i$ are defined as $X_i(x) = x_i$. Now $X^n := (X_1,\dotsc,X_n)$ and $X^n(x) = x^n=(x_1,\dotsc,x_n)$. Can this notation be used in a publication in statistics?","In a book on statistics I saw the notation $x^n=(x_1,\dotsc,x_n)$ and wondering how common this is in measure theory/statistics. More precisely it is about a probability space $(\mathbb{H},\mathcal{H},P) = (\times_{i=1}^\infty\mathbb{H}_i,\otimes_{i=1}^\infty\mathcal{H}_i,\otimes_{i=1}^\infty P_i)$ and $x=(x_1,x_2,...) \in \mathbb{H}$. The random variables $X_i: \mathbb{H} \to \mathbb{H}_i$ are defined as $X_i(x) = x_i$. Now $X^n := (X_1,\dotsc,X_n)$ and $X^n(x) = x^n=(x_1,\dotsc,x_n)$. Can this notation be used in a publication in statistics?",,"['statistics', 'measure-theory', 'notation']"
85,Is there a name for expressions that are invariant under the exchange of raw moments and cumulants?,Is there a name for expressions that are invariant under the exchange of raw moments and cumulants?,,"I'm interested in expressions that are invariant under the exchange of raw moments and cumulants. This is trivially true of all expressions written only in terms of first order moments but nontrivial expressions exist for higher orders. A couple of examples are as follows: $\kappa _{2,0}\kappa_{0,1}{}^2-\kappa _{0,2} \kappa    _{1,0}{}^2=\mu'_{2,0}\mu'_{0,1}{}^2-\mu'_{0,2} \mu'_{1,0}{}^2$ $\kappa _{2,0}\kappa_{0,1}{}^2+\kappa _{0,2} \kappa    _{1,0}{}^2-2\kappa_{1,1} \kappa_{1,0}\kappa_{0,1}=\mu'_{2,0}\mu'_{0,1}{}^2+\mu'_{0,2}    \mu'_{1,0}{}^2-2\mu'_{1,1} \mu'_{1,0}\mu'_{0,1}$ Does anybody know if these have a specific name or know anything else about them? I'm looking for any material I can find in order to learn more about them. Thanks!","I'm interested in expressions that are invariant under the exchange of raw moments and cumulants. This is trivially true of all expressions written only in terms of first order moments but nontrivial expressions exist for higher orders. A couple of examples are as follows: $\kappa _{2,0}\kappa_{0,1}{}^2-\kappa _{0,2} \kappa    _{1,0}{}^2=\mu'_{2,0}\mu'_{0,1}{}^2-\mu'_{0,2} \mu'_{1,0}{}^2$ $\kappa _{2,0}\kappa_{0,1}{}^2+\kappa _{0,2} \kappa    _{1,0}{}^2-2\kappa_{1,1} \kappa_{1,0}\kappa_{0,1}=\mu'_{2,0}\mu'_{0,1}{}^2+\mu'_{0,2}    \mu'_{1,0}{}^2-2\mu'_{1,1} \mu'_{1,0}\mu'_{0,1}$ Does anybody know if these have a specific name or know anything else about them? I'm looking for any material I can find in order to learn more about them. Thanks!",,"['statistics', 'probability-distributions', 'moment-generating-functions']"
86,Binomial Probablity,Binomial Probablity,,"A multiple choice test has 40 questions. Each question has five possible answers of which one is correct. Assuming that an individual has studied and has a 70% chance of answering a question correctly, what is the expected number of correct answers?","A multiple choice test has 40 questions. Each question has five possible answers of which one is correct. Assuming that an individual has studied and has a 70% chance of answering a question correctly, what is the expected number of correct answers?",,"['probability', 'statistics']"
87,Statistical Test involving the Mean and variance of two samples,Statistical Test involving the Mean and variance of two samples,,"I am doing a hypothesis test two see if two sets X and Y both containing 100 values are both part of a parent set, or are two unique sets. So H0:X and Y are belong to the same parent set    H1:They are from two different set I decided to use a 5% significance level To check this I used a statistical test using the difference in their means, and this result led me to reject H0. I then used a statistical test using the difference in their variance, and this result led me to accept H0. Is there a statistical test I could you use that could detect a differnce in the mean and variances?","I am doing a hypothesis test two see if two sets X and Y both containing 100 values are both part of a parent set, or are two unique sets. So H0:X and Y are belong to the same parent set    H1:They are from two different set I decided to use a 5% significance level To check this I used a statistical test using the difference in their means, and this result led me to reject H0. I then used a statistical test using the difference in their variance, and this result led me to accept H0. Is there a statistical test I could you use that could detect a differnce in the mean and variances?",,"['statistics', 'hypothesis-testing']"
88,Optimal unbiased estimator,Optimal unbiased estimator,,"I have the sample $X_1,\ldots,X_n$ of i.i.d. from $U(\theta - 1/2; \theta +1/2)$ . It is well known that $T = (X_{(1)}; X_{(n)})$ is a sufficient but not complete statistic, because $X_{(n)}-X_{(1)} - (n-1)/(n+1)$ is unbiased estimator of zero. I want to find unbiased estimator of $\theta$ with minimal variance. I have crude unbiased estimator of $\theta$ : $$\hat {\theta} = X_1.$$ From Blackwell-Rao-Kolmogorov theorem estimator $$\hat {\theta}_1 = E\left[X_1\mid X_{(1)} = t_1; X_{(n)} = t_2\right] = \frac{t_1 + t_2}{2}$$ is unbiased and uniformly better than $\hat {\theta} = X_1$ . But because of non-completeless of $T = (X_{(1)}; X_{(n)})$ , this is not the only unbiased estimator as the function of $T$ . Moreover if I iterate the Blackwell-Rao-Kolmogorov theorem with this new estimator $\hat {\theta}_1 =\frac{t_1 + t_2}{2}$ I don't improve it: $$E\left[\frac {X_{(1)} + X_{(n)}}{2}\mid X_{(1)} = t_1; X_{(n)} = t_2\right] = \frac{t_1 + t_2}{2} = \hat {\theta}_1.$$ Is the $\frac {X_{(1)} + X_{(n)}}{2}$ the optimal unbiased estimator of $\theta$ (but not unique)?","I have the sample of i.i.d. from . It is well known that is a sufficient but not complete statistic, because is unbiased estimator of zero. I want to find unbiased estimator of with minimal variance. I have crude unbiased estimator of : From Blackwell-Rao-Kolmogorov theorem estimator is unbiased and uniformly better than . But because of non-completeless of , this is not the only unbiased estimator as the function of . Moreover if I iterate the Blackwell-Rao-Kolmogorov theorem with this new estimator I don't improve it: Is the the optimal unbiased estimator of (but not unique)?","X_1,\ldots,X_n U(\theta - 1/2; \theta +1/2) T = (X_{(1)}; X_{(n)}) X_{(n)}-X_{(1)} - (n-1)/(n+1) \theta \theta \hat {\theta} = X_1. \hat {\theta}_1 = E\left[X_1\mid X_{(1)} = t_1; X_{(n)} = t_2\right] = \frac{t_1 + t_2}{2} \hat {\theta} = X_1 T = (X_{(1)}; X_{(n)}) T \hat {\theta}_1 =\frac{t_1 + t_2}{2} E\left[\frac {X_{(1)} + X_{(n)}}{2}\mid X_{(1)} = t_1; X_{(n)} = t_2\right] = \frac{t_1 + t_2}{2} = \hat {\theta}_1. \frac {X_{(1)} + X_{(n)}}{2} \theta","['statistics', 'statistical-inference', 'uniform-distribution', 'parameter-estimation']"
89,Relative Error $\frac{x-x_0}{x}$,Relative Error,\frac{x-x_0}{x},"According to many definitions I've seen the relative error is defined by $$E = \frac{x-x_0}{x}$$ where $x$ is the ""true"" value. But some people use instead $$\frac{x-x_0}{x_0}. $$ Is this incorrect?","According to many definitions I've seen the relative error is defined by $$E = \frac{x-x_0}{x}$$ where $x$ is the ""true"" value. But some people use instead $$\frac{x-x_0}{x_0}. $$ Is this incorrect?",,"['statistics', 'error-propagation']"
90,probability matching strategy for coin flips,probability matching strategy for coin flips,,"imagine a betting game where we observe $N$ independent coin flips $x_1,...,x_n$ (where each $x_i \in {H,T}$) from the same coin, whose true weight is $\theta$. the task is to predict how many Heads we will get in the next $M$ flips of the same coin. the closer you are to the true number of heads, the higher your payoff will be. as example, the reward may be $r/(abs(Guess_H - True_H) + 1)$ where $Guess_H$ is your guess for number of Heads on next $M$ flips, $True_H$ is actual number of Heads in the next $M$ flips, and $r$ is some value $r > 1$. what is the optimal strategy? how do you show formally which of the two following strategies is better? strategy 1: estimate coin weight $\theta$ from $N$ first flips. if $\theta > 0.5$, predict all Heads for next $M$ flips ($M$ Heads), if $\theta < 0.5$, predict all Tails for next $M$ flips (0 Heads). strategy 2: estimate coin weight $\theta$ from $N$ first flips. predict $\theta*M$ many heads for next $M$ flips. which strategy is better? can this be shown formally? attempt: expected reward for strategy 1 : assume $\theta = 0.75, M = 10$ $E(reward|strategy 1) = Binomial(10; 10, 0.75)*r$ expected reward for strategy 2 : $E(reward|strategy 2) = Binomial(0.75 * 10; 10, 0.75)*r$ this shows that for this case, strategy 2 is better, since: $Binomial(0.75 * 10; 10, 0.75) > Binomial(10; 10, 0.75)$ how can this be shown analytically and in general, not assuming particular values for $M$ and the true $\theta$?","imagine a betting game where we observe $N$ independent coin flips $x_1,...,x_n$ (where each $x_i \in {H,T}$) from the same coin, whose true weight is $\theta$. the task is to predict how many Heads we will get in the next $M$ flips of the same coin. the closer you are to the true number of heads, the higher your payoff will be. as example, the reward may be $r/(abs(Guess_H - True_H) + 1)$ where $Guess_H$ is your guess for number of Heads on next $M$ flips, $True_H$ is actual number of Heads in the next $M$ flips, and $r$ is some value $r > 1$. what is the optimal strategy? how do you show formally which of the two following strategies is better? strategy 1: estimate coin weight $\theta$ from $N$ first flips. if $\theta > 0.5$, predict all Heads for next $M$ flips ($M$ Heads), if $\theta < 0.5$, predict all Tails for next $M$ flips (0 Heads). strategy 2: estimate coin weight $\theta$ from $N$ first flips. predict $\theta*M$ many heads for next $M$ flips. which strategy is better? can this be shown formally? attempt: expected reward for strategy 1 : assume $\theta = 0.75, M = 10$ $E(reward|strategy 1) = Binomial(10; 10, 0.75)*r$ expected reward for strategy 2 : $E(reward|strategy 2) = Binomial(0.75 * 10; 10, 0.75)*r$ this shows that for this case, strategy 2 is better, since: $Binomial(0.75 * 10; 10, 0.75) > Binomial(10; 10, 0.75)$ how can this be shown analytically and in general, not assuming particular values for $M$ and the true $\theta$?",,"['probability', 'statistics', 'probability-theory', 'bayesian', 'decision-theory']"
91,How can I infer order from partially ordered discrete sequences?,How can I infer order from partially ordered discrete sequences?,,"A really interesting problem that I can't stop thinking about! Have run in to this a couple of times but yet to find a smart approach to either solve or frame this problem. This is my try at generalizing it: Assume that we have an application where a user in each session can make one or many actions, each of those actions falls into the categories, say $\{a,b,c,d,e,f,g\}$. In one of the sessions the user makes some kind of 'defining action' that leads to termination of the sequence, in most cases terminating it immediately but there are occasionaly actions even afterwards. Aim: We want to classify users according to which their 'defining' action was Variables $\mathcal{O}$= the order of the actions ( Unknown ) $S$= Session of the action $\mathcal{D}$= binary, '1' indicating the 'defining action' ( Unknown ) $W$= binary, '1' indicating that the 'defining' action was made in this session $A$= Type of action Data We have data for some large amount of $N$ users. Example of data for a user that should be classified as type 'c', where  $W=1$ marked in red: \begin{array}{c|c|c|c}  \hline  \mathcal{O}& S& \mathcal{D}& W & A &\\ \hline  1&1& 0&0&a\\ \hline  2&2& 0&0&e\\ \hline  \color{red}{3} &\color{red}{3} &\color{red}{0}&\color{red}{1}& \color{red}{b}\\ \hline  \color{red}{4} &\color{red}{3} &\color{red}{1}&\color{red}{1}& \color{red}{c}\\ \hline  5&4& 0&0&a\\ \hline  6&5& 0&0&f\\ \hline  \end{array} Problem: We would only need $\mathcal{D}$ together with $A$ to conclude that this user is of category 'c'  but $\mathcal{D}$ is not known explicitly. When there's only one action done in the session where the the determining action was taken $W$ is identically $\mathcal{D}$. This is the fact in most of the cases. Here on the other hand we only know which session the decision was taken so for all we know the user can either be classified as a ' b '- or ' c '- user. Illustrated below In most cases only one action per session is made so $\mathcal{D}=W$ in each case and thus the defining action is known. There is some a set of unknown rules in what sequences of actions can lead to particular defining actions. For example; "" b cannot be the determining action if action a followed by e has been taken'. Those rules are not followed consistently, there's some random variation. And in particular, they are unknown. We assume that the event that some sessions has multiple actions is randomly distributed. How can I approach trying to infer which the defining decision is for each user based upon my observations? Preferrably I'd get some model assigning membership scores/probabilites for each category given data. Why is this interesting? This is a terminating sequence of varying length wich we can only observe as a partially ordered set. Usually one can use domain knowledge/theory to infer this order. When there are no such knowledge one can sometimes use exploratory analysis to figure it out. That is not always possible due to complexity and is inherently biased and timeconsuming. I've run into this when working with large large relational databases where (by design or negligence) some attribute is missing that I need to accurately guess.","A really interesting problem that I can't stop thinking about! Have run in to this a couple of times but yet to find a smart approach to either solve or frame this problem. This is my try at generalizing it: Assume that we have an application where a user in each session can make one or many actions, each of those actions falls into the categories, say $\{a,b,c,d,e,f,g\}$. In one of the sessions the user makes some kind of 'defining action' that leads to termination of the sequence, in most cases terminating it immediately but there are occasionaly actions even afterwards. Aim: We want to classify users according to which their 'defining' action was Variables $\mathcal{O}$= the order of the actions ( Unknown ) $S$= Session of the action $\mathcal{D}$= binary, '1' indicating the 'defining action' ( Unknown ) $W$= binary, '1' indicating that the 'defining' action was made in this session $A$= Type of action Data We have data for some large amount of $N$ users. Example of data for a user that should be classified as type 'c', where  $W=1$ marked in red: \begin{array}{c|c|c|c}  \hline  \mathcal{O}& S& \mathcal{D}& W & A &\\ \hline  1&1& 0&0&a\\ \hline  2&2& 0&0&e\\ \hline  \color{red}{3} &\color{red}{3} &\color{red}{0}&\color{red}{1}& \color{red}{b}\\ \hline  \color{red}{4} &\color{red}{3} &\color{red}{1}&\color{red}{1}& \color{red}{c}\\ \hline  5&4& 0&0&a\\ \hline  6&5& 0&0&f\\ \hline  \end{array} Problem: We would only need $\mathcal{D}$ together with $A$ to conclude that this user is of category 'c'  but $\mathcal{D}$ is not known explicitly. When there's only one action done in the session where the the determining action was taken $W$ is identically $\mathcal{D}$. This is the fact in most of the cases. Here on the other hand we only know which session the decision was taken so for all we know the user can either be classified as a ' b '- or ' c '- user. Illustrated below In most cases only one action per session is made so $\mathcal{D}=W$ in each case and thus the defining action is known. There is some a set of unknown rules in what sequences of actions can lead to particular defining actions. For example; "" b cannot be the determining action if action a followed by e has been taken'. Those rules are not followed consistently, there's some random variation. And in particular, they are unknown. We assume that the event that some sessions has multiple actions is randomly distributed. How can I approach trying to infer which the defining decision is for each user based upon my observations? Preferrably I'd get some model assigning membership scores/probabilites for each category given data. Why is this interesting? This is a terminating sequence of varying length wich we can only observe as a partially ordered set. Usually one can use domain knowledge/theory to infer this order. When there are no such knowledge one can sometimes use exploratory analysis to figure it out. That is not always possible due to complexity and is inherently biased and timeconsuming. I've run into this when working with large large relational databases where (by design or negligence) some attribute is missing that I need to accurately guess.",,"['statistics', 'trees', 'bayesian', 'data-analysis', 'data-mining']"
92,Statistical sample with age ranges. How to extrapolate it using the real age distribution over population.,Statistical sample with age ranges. How to extrapolate it using the real age distribution over population.,,"I have a data set consisting in the classification of the numbers of suicides by age range. I want to figure out if there is or not association between the number of suicides and the age range. But, obviously, if there are more people (in the real population) in the range of (50,60) than in the range (20,30) I will have more suicides in the range (50,60). Therefore, I know I have to consider the population distribution. And I have this data. However, I don't know what is the statistical method to do this. I can divide each cell by the weight this range has in the population, and I will obtain ""the equivalent sample"" with a correct population distribution. However, I want to do inference with this table, for example a Chi Square Test of Independence, and after this artificial change I don't know how to apply this. Can anyone help? I only need some bibliographic source or some idea. I looked for it, but I found nothing. Thanks in advance.","I have a data set consisting in the classification of the numbers of suicides by age range. I want to figure out if there is or not association between the number of suicides and the age range. But, obviously, if there are more people (in the real population) in the range of (50,60) than in the range (20,30) I will have more suicides in the range (50,60). Therefore, I know I have to consider the population distribution. And I have this data. However, I don't know what is the statistical method to do this. I can divide each cell by the weight this range has in the population, and I will obtain ""the equivalent sample"" with a correct population distribution. However, I want to do inference with this table, for example a Chi Square Test of Independence, and after this artificial change I don't know how to apply this. Can anyone help? I only need some bibliographic source or some idea. I looked for it, but I found nothing. Thanks in advance.",,"['statistics', 'statistical-inference']"
93,Estimate of shared variance for n samples of x and y,Estimate of shared variance for n samples of x and y,,"I am performing a t-test on n different samples of both $X_1, X_2,...,X_k$ and $Y_1,Y_2,...,Y_k$. To begin with I want to assume that all 2*n samples have the same variance but that they do not have the same mean. Any advise on how I would best estimate this shared variance? I know that pooled variance works well if I only had one sample of X and Y, is there any way I can expand this to all n samples of X and Y?","I am performing a t-test on n different samples of both $X_1, X_2,...,X_k$ and $Y_1,Y_2,...,Y_k$. To begin with I want to assume that all 2*n samples have the same variance but that they do not have the same mean. Any advise on how I would best estimate this shared variance? I know that pooled variance works well if I only had one sample of X and Y, is there any way I can expand this to all n samples of X and Y?",,"['probability', 'statistics']"
94,What is the transformation that maps a Gaussian distribution to a Beta distribution?,What is the transformation that maps a Gaussian distribution to a Beta distribution?,,"Suppose X is a random variable with Gaussian distribution over domain $\mathbb{R} = (-\infty, +\infty)$, with PDF function $f_X$. And Y is a random variable with Beta distribution over domain $[0,1]$, with PDF function $f_Y$. Seeking a map $T: \mathbb{R} \rightarrow [0,1]$ such that $f_X(x) = f_Y(T(x))$. In words, if X is ""re-distributed"" over [0,1] then it would be a Beta distribution. In other words, $T$ squeezes the domain from $(-\infty, +\infty)$ to [0,1].","Suppose X is a random variable with Gaussian distribution over domain $\mathbb{R} = (-\infty, +\infty)$, with PDF function $f_X$. And Y is a random variable with Beta distribution over domain $[0,1]$, with PDF function $f_Y$. Seeking a map $T: \mathbb{R} \rightarrow [0,1]$ such that $f_X(x) = f_Y(T(x))$. In words, if X is ""re-distributed"" over [0,1] then it would be a Beta distribution. In other words, $T$ squeezes the domain from $(-\infty, +\infty)$ to [0,1].",,"['statistics', 'probability-theory', 'probability-distributions']"
95,How to check $H_0$ hypothesis using Pearson's criteria?,How to check  hypothesis using Pearson's criteria?,H_0,"How to check hypothesis by using Pearson's criteria ( $\chi^2$ test), that $H_0:$ random variable $X$ is normally distributed given that $k=7$ (count of intervals) and $\alpha=0.1 $ (significance level). I do understand how you would have to approach problem where you would have to check simple hypothesis, like, for example, $H_0:$ mean value of pages read by student of computer science faculty per day is greater than or equal 10, given that: $n=50$ (test group members) $\bar{x}=11.7$ $s=1$ Then I would define $H_a$ as: mean value of pages read by student of computer science faculty per day is less than 10. and calculate $$z=\frac{\bar{x}-\mu_0}{\sigma /\sqrt{n}}$$ and look up P-Value from normal curve areas table. Then comparing P-value against $\alpha$ would determine that $H_a$ would be rejected and therefore $H_0$ would be approved. But how do I approach my problem? $$H_0: X\sim N(\mu,\sigma^2)$$ $$H_a: X\nsim N(\mu,\sigma^2)$$","How to check hypothesis by using Pearson's criteria ( $\chi^2$ test), that $H_0:$ random variable $X$ is normally distributed given that $k=7$ (count of intervals) and $\alpha=0.1 $ (significance level). I do understand how you would have to approach problem where you would have to check simple hypothesis, like, for example, $H_0:$ mean value of pages read by student of computer science faculty per day is greater than or equal 10, given that: $n=50$ (test group members) $\bar{x}=11.7$ $s=1$ Then I would define $H_a$ as: mean value of pages read by student of computer science faculty per day is less than 10. and calculate $$z=\frac{\bar{x}-\mu_0}{\sigma /\sqrt{n}}$$ and look up P-Value from normal curve areas table. Then comparing P-value against $\alpha$ would determine that $H_a$ would be rejected and therefore $H_0$ would be approved. But how do I approach my problem? $$H_0: X\sim N(\mu,\sigma^2)$$ $$H_a: X\nsim N(\mu,\sigma^2)$$",,"['statistics', 'self-learning', 'normal-distribution', 'hypothesis-testing']"
96,Help with Linear Transformation of a multivariate normal,Help with Linear Transformation of a multivariate normal,,"Given X ~ $N_2$ ( μ , Σ)$ Find the Distribution of $$         \begin{pmatrix}         X+Y \\         X-Y         \end{pmatrix} $$ Show independence if $Var(X) = Var(Y)$ Attempt: Given proper of Multitvariate Normal Transformations $N_m$ (A μ , $AΣA^t$ ) Using $$     A =            \begin{pmatrix}           1&1 \\                1 &-1         \end{pmatrix}*  \begin{pmatrix}           X \\                Y         \end{pmatrix} =         \begin{pmatrix}         X+Y \\         X-Y         \end{pmatrix}\begin{pmatrix}          1&1 \\                1 &-1         \end{pmatrix} = $$ The general Variance-covariance matrix of a bivariate normal,multiplied by $AΣA^t$ $$     A =            \begin{pmatrix}           1&1 \\                1 &-1         \end{pmatrix}*  \begin{pmatrix}           δ_x^2&δ_{xy} \\                δ_{xy} &δ_y^2         \end{pmatrix} *         \begin{pmatrix}          1&1 \\                1 &-1         \end{pmatrix} = \begin{pmatrix}          4δ&0 \\                0 &0         \end{pmatrix} $$ Given  $δ_{xy} = δ_x^2 = δ_y^2$ My Questions:  i. Do the zeros in the final Variance-Covariance matrix sufficiently show independence? ii. Does $δ_y^2 = 0$ effect the pdf, ie making it degenerate? Where the bivariate pdf is $\frac{1}{2\piδ_yδ_x(1-\rho^2)} e^{\frac{q}{2(1-\rho^2)}}$ $q = [(\frac{x-μ_x}{δ_x})^2 -2\rho(\frac{y-μ_y}{δ_x})(\frac{y-μ_y}{δ_y}) + (\frac{y-μ_y}{δ_y})^2]$ By $AΣA^t$  $\rho = 0$ and $δ_y^2 = 0 $ $q = [(\frac{x-μ_x}{δ_x})^2 + (\frac{y-μ_y}{0})^2]$  which is problematic. I'm not sure where I am going wrong here...","Given X ~ $N_2$ ( μ , Σ)$ Find the Distribution of $$         \begin{pmatrix}         X+Y \\         X-Y         \end{pmatrix} $$ Show independence if $Var(X) = Var(Y)$ Attempt: Given proper of Multitvariate Normal Transformations $N_m$ (A μ , $AΣA^t$ ) Using $$     A =            \begin{pmatrix}           1&1 \\                1 &-1         \end{pmatrix}*  \begin{pmatrix}           X \\                Y         \end{pmatrix} =         \begin{pmatrix}         X+Y \\         X-Y         \end{pmatrix}\begin{pmatrix}          1&1 \\                1 &-1         \end{pmatrix} = $$ The general Variance-covariance matrix of a bivariate normal,multiplied by $AΣA^t$ $$     A =            \begin{pmatrix}           1&1 \\                1 &-1         \end{pmatrix}*  \begin{pmatrix}           δ_x^2&δ_{xy} \\                δ_{xy} &δ_y^2         \end{pmatrix} *         \begin{pmatrix}          1&1 \\                1 &-1         \end{pmatrix} = \begin{pmatrix}          4δ&0 \\                0 &0         \end{pmatrix} $$ Given  $δ_{xy} = δ_x^2 = δ_y^2$ My Questions:  i. Do the zeros in the final Variance-Covariance matrix sufficiently show independence? ii. Does $δ_y^2 = 0$ effect the pdf, ie making it degenerate? Where the bivariate pdf is $\frac{1}{2\piδ_yδ_x(1-\rho^2)} e^{\frac{q}{2(1-\rho^2)}}$ $q = [(\frac{x-μ_x}{δ_x})^2 -2\rho(\frac{y-μ_y}{δ_x})(\frac{y-μ_y}{δ_y}) + (\frac{y-μ_y}{δ_y})^2]$ By $AΣA^t$  $\rho = 0$ and $δ_y^2 = 0 $ $q = [(\frac{x-μ_x}{δ_x})^2 + (\frac{y-μ_y}{0})^2]$  which is problematic. I'm not sure where I am going wrong here...",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
97,Calculating Euclidean dissimilarity for a given cluster with itself,Calculating Euclidean dissimilarity for a given cluster with itself,,"Suppose I have clusters $$A= \{(1,1)^T, (1,2)^T\} $$ $$B=\{(2,3)^T, (3,4)^T\} $$ $$C= \{(4,5)^T, (5,6)^T, (1,2)^T\} $$ I wish to use the Euclidean dissimilarity and Average linkage to calculate a dissimilarity matrix for these clusters. So I use the formula $\frac{1}{|A||B|}\sum_{x\in A}\sum_{y\in B}\sqrt{\sum_{k=1}^{m}(x_{ik} - y_{jk})^2}$ But if I wish to calculate the dissimilarity using this measure between say $A$ and itself, I'm inclined to say from a rudimentary knowledge of metric spaces (and a basic intuition that $A$ should have $0$ dissimilarity with itself) that $d(A,A)=0$ for any $A$. However, using the formula given above I get $d(A,A)=0.5$; $$\frac{1}{4}\left[\sqrt{(1-2)^2 + 0} + \sqrt{(2-1)^2 + 0} \right] = 0.5$$ Can someone reason with me which of the two answers is correct? I feel the conclusion probably hinges on whether $A$ is interpreted as a single entity or as a collection of sets.","Suppose I have clusters $$A= \{(1,1)^T, (1,2)^T\} $$ $$B=\{(2,3)^T, (3,4)^T\} $$ $$C= \{(4,5)^T, (5,6)^T, (1,2)^T\} $$ I wish to use the Euclidean dissimilarity and Average linkage to calculate a dissimilarity matrix for these clusters. So I use the formula $\frac{1}{|A||B|}\sum_{x\in A}\sum_{y\in B}\sqrt{\sum_{k=1}^{m}(x_{ik} - y_{jk})^2}$ But if I wish to calculate the dissimilarity using this measure between say $A$ and itself, I'm inclined to say from a rudimentary knowledge of metric spaces (and a basic intuition that $A$ should have $0$ dissimilarity with itself) that $d(A,A)=0$ for any $A$. However, using the formula given above I get $d(A,A)=0.5$; $$\frac{1}{4}\left[\sqrt{(1-2)^2 + 0} + \sqrt{(2-1)^2 + 0} \right] = 0.5$$ Can someone reason with me which of the two answers is correct? I feel the conclusion probably hinges on whether $A$ is interpreted as a single entity or as a collection of sets.",,"['matrices', 'statistics', 'metric-spaces', 'euclidean-geometry', 'clustering']"
98,"Projection of $\log(x)$ on $(x,x^2)$",Projection of  on,"\log(x) (x,x^2)","For a positive random variable $X$, is it true that $\mathrm{cov}(X,\log(X))>0$ and $\mathrm{cov}(X^2,\log(X))<0$, where $\mathrm{cov}(X,Y)$ denotes the covariance between any $X$ and $Y$? The reason I ask: I am considering a linear regression of $\log(X)$ on $X$ and $X^2$ and I would expect that the coefficients have the above signs based on the concavity of the function $\log(x)$ for $x>0$. In fact, I would not expect the signs of the above covariances to depend on the distribution of $X$. My attempt: I have tried writing $$\log(X)=\log(x_0)+\frac{1}{x_0}(X-x_0)-\frac{1}{2x_1^2}(X-x_0)^2$$ for all $x_0$ and some $x_1$ in $\mathbb R^+$. I end up with expressions for $\mathrm{cov}(X,\log(X))$ and $\mathrm{cov}(X^2,\log(X))$ that depend on the distributional properties $\mathbb VX$, $\mathbb VX^2$ and $\mathrm{cov}(X^2,X)$, where $\mathbb VY$ denotes the variance of a random variable $Y$. I'm not sure if this approach is correct, but it seems to show that the signs of $\mathrm{cov}(X,\log(X))$ and $\mathrm{cov}(X^2,\log(X))$ can be positive or negative depending on the distribution of $X$.","For a positive random variable $X$, is it true that $\mathrm{cov}(X,\log(X))>0$ and $\mathrm{cov}(X^2,\log(X))<0$, where $\mathrm{cov}(X,Y)$ denotes the covariance between any $X$ and $Y$? The reason I ask: I am considering a linear regression of $\log(X)$ on $X$ and $X^2$ and I would expect that the coefficients have the above signs based on the concavity of the function $\log(x)$ for $x>0$. In fact, I would not expect the signs of the above covariances to depend on the distribution of $X$. My attempt: I have tried writing $$\log(X)=\log(x_0)+\frac{1}{x_0}(X-x_0)-\frac{1}{2x_1^2}(X-x_0)^2$$ for all $x_0$ and some $x_1$ in $\mathbb R^+$. I end up with expressions for $\mathrm{cov}(X,\log(X))$ and $\mathrm{cov}(X^2,\log(X))$ that depend on the distributional properties $\mathbb VX$, $\mathbb VX^2$ and $\mathrm{cov}(X^2,X)$, where $\mathbb VY$ denotes the variance of a random variable $Y$. I'm not sure if this approach is correct, but it seems to show that the signs of $\mathrm{cov}(X,\log(X))$ and $\mathrm{cov}(X^2,\log(X))$ can be positive or negative depending on the distribution of $X$.",,"['probability', 'statistics']"
99,Covariance matrix of CAR model,Covariance matrix of CAR model,,"Does anyone know how to obtain the covariance matrix of the conditional autoregressive (CAR) model? The general idea is that a random variable $Y_{i}$ may depend on other values $Y_{j}$ where $j \neq i$.  $Y_{i}$ can be a measurement at location $i$ that is correlated with measurement $Y_{j}$ at location $j$. In a CAR model, these variables follow the conditional mean: $$E(Y_{i}|\text{all }Y_{j\neq i}) = \mu_{i} + \rho\Sigma_{j\neq i}w_{ij}(Y_{j}-\mu_{j})$$ where $\mu_{i}$ is the mean of $Y_{i}$, $w_{ij}$ are weights that determine the influence of location $j$ on $i$ and $\rho$ describes a positive or negative direction. We also know that the conditional variance is: $$Var(Y_{i}|\text{all }Y_{j\neq i})=\sigma^{2}$$ I want to know how to derive the covariance matrix: $$V = (I - \rho W)^{-1}M$$ in which $M$ is a $n\times n$ matrix of conditional variances $(\sigma_{1}^{2},\dots, \sigma_{n}^{2})$ and $W$ is a $n\times n$ matrix of weights $w_{ij}$ with zeros on the diagonal. I'm guessing it should be a somewhat straightforward calculation. Mainly, $$\Sigma_{ij} = cov(Y_{i},Y_{j}) = E[(Y_{i}-E[Y_{i}])(Y_{j}-E[Y_{j}])]$$ However, I can't see how to obtain the first term from this operation. I think and correct me if I'm wrong, $E(Y_{i},Y_{j})$ under this model should be zero. That should simplify the derivation. This is the description I have been reading, in case it may be helpful. The original paper by Besag assumes the existence of such a covariance matrix, but as far as I understand, he doesn't derive it. Any help would be appreciated. UPDATE : There is a very simple way to prove the covariance matrix. If we use the vector of all $Y_{i}$ as $Y$ and define the CAR model in terms of $Y$: $$Y = \rho W Y + M$$ (assuming $\mu_{i}=0$ and with a diagonal $n\times n$ matrix sharing the same $\sigma^{2}$) Then, $$Y = (I - \rho W)^{-1}M$$ and it is quite obvious that a distribution $Y = N(0, (I - \rho W)^{-1}M)$ gives the desired result. However, I'm not quite satisfied with this result since I had to redefine the CAR model, which no longer has the expected value as above.","Does anyone know how to obtain the covariance matrix of the conditional autoregressive (CAR) model? The general idea is that a random variable $Y_{i}$ may depend on other values $Y_{j}$ where $j \neq i$.  $Y_{i}$ can be a measurement at location $i$ that is correlated with measurement $Y_{j}$ at location $j$. In a CAR model, these variables follow the conditional mean: $$E(Y_{i}|\text{all }Y_{j\neq i}) = \mu_{i} + \rho\Sigma_{j\neq i}w_{ij}(Y_{j}-\mu_{j})$$ where $\mu_{i}$ is the mean of $Y_{i}$, $w_{ij}$ are weights that determine the influence of location $j$ on $i$ and $\rho$ describes a positive or negative direction. We also know that the conditional variance is: $$Var(Y_{i}|\text{all }Y_{j\neq i})=\sigma^{2}$$ I want to know how to derive the covariance matrix: $$V = (I - \rho W)^{-1}M$$ in which $M$ is a $n\times n$ matrix of conditional variances $(\sigma_{1}^{2},\dots, \sigma_{n}^{2})$ and $W$ is a $n\times n$ matrix of weights $w_{ij}$ with zeros on the diagonal. I'm guessing it should be a somewhat straightforward calculation. Mainly, $$\Sigma_{ij} = cov(Y_{i},Y_{j}) = E[(Y_{i}-E[Y_{i}])(Y_{j}-E[Y_{j}])]$$ However, I can't see how to obtain the first term from this operation. I think and correct me if I'm wrong, $E(Y_{i},Y_{j})$ under this model should be zero. That should simplify the derivation. This is the description I have been reading, in case it may be helpful. The original paper by Besag assumes the existence of such a covariance matrix, but as far as I understand, he doesn't derive it. Any help would be appreciated. UPDATE : There is a very simple way to prove the covariance matrix. If we use the vector of all $Y_{i}$ as $Y$ and define the CAR model in terms of $Y$: $$Y = \rho W Y + M$$ (assuming $\mu_{i}=0$ and with a diagonal $n\times n$ matrix sharing the same $\sigma^{2}$) Then, $$Y = (I - \rho W)^{-1}M$$ and it is quite obvious that a distribution $Y = N(0, (I - \rho W)^{-1}M)$ gives the desired result. However, I'm not quite satisfied with this result since I had to redefine the CAR model, which no longer has the expected value as above.",,"['statistics', 'covariance', 'conditional-expectation']"
