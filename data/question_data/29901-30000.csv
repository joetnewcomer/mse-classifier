,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Likelihood of circle vs. ellipse vs. parabola vs. hyperbola from $ax^2+bxy+cy^2+dx+ey+f=0$ with coefficients uniformly random in $[-1,1]$",Likelihood of circle vs. ellipse vs. parabola vs. hyperbola from  with coefficients uniformly random in,"ax^2+bxy+cy^2+dx+ey+f=0 [-1,1]","Q . What is the probability that a random quadratic equation describes a circle, an ellipse, a parabola, or a hyperbola? Let's use this definition of a random quadratic: $$a\, x^2 + b\, x y + c\, y^2 + d\, x + e\, y + f = 0 \;$$ where $a,b,c,d,e,f$ are each uniformly random within $[-1,1]$ . For a circle the probability should be $0$ , but I am unclear on the likelihood of ellipse vs. parabola vs. hyperbola. Each conic can be represented as a point in a $5$ -dimensional projective space. So I'm asking for the corresponding portions/volumes within this space. My trigger for this question is a quote from Colin Adams: ""So if we want to understand the geometry of surfaces, it's all about the hyperbolic case."" So I was wondering if hyperbolas dominate even in the plane. (Colin Adams, ""What is ... a Hyperbolic 3-Manifold?"" AMS 65 , no. 5, pp.544-546. PDF download ). Added : Simulations suggest that hyperbolas occur roughly 73% of the time, ellipses 14%, and the remainder have only imaginary solutions.","Q . What is the probability that a random quadratic equation describes a circle, an ellipse, a parabola, or a hyperbola? Let's use this definition of a random quadratic: where are each uniformly random within . For a circle the probability should be , but I am unclear on the likelihood of ellipse vs. parabola vs. hyperbola. Each conic can be represented as a point in a -dimensional projective space. So I'm asking for the corresponding portions/volumes within this space. My trigger for this question is a quote from Colin Adams: ""So if we want to understand the geometry of surfaces, it's all about the hyperbolic case."" So I was wondering if hyperbolas dominate even in the plane. (Colin Adams, ""What is ... a Hyperbolic 3-Manifold?"" AMS 65 , no. 5, pp.544-546. PDF download ). Added : Simulations suggest that hyperbolas occur roughly 73% of the time, ellipses 14%, and the remainder have only imaginary solutions.","a\, x^2 + b\, x y + c\, y^2 + d\, x + e\, y + f = 0 \; a,b,c,d,e,f [-1,1] 0 5","['probability', 'polynomials', 'conic-sections']"
1,Choosing point uniformly on surface of sphere,Choosing point uniformly on surface of sphere,,"I saw the following statement posted by Fermat's Library on Twitter: The way to correctly generate a random point on the surface of a unit sphere is not to pick uniform distributions $\theta$ in $[0,2\pi)$ and $\phi$ in $[0,\pi)$ . Instead, choose $u$ and $v$ from uniform distributions on $[0,1)$ . Then, $\phi = \cos^{-1}(2v-1)$ $\theta = 2\pi u$ I can see why uniformly choosing $\theta$ in $[0,2\pi)$ and $\phi$ in $[0,\pi)$ would lead to points near the poles being more likely to be chosen than points near the equator. But I can't think of an intuitive explanation for why the given solution correctly gives a uniform distribution. Is there a good intuitive explanation for this?","I saw the following statement posted by Fermat's Library on Twitter: The way to correctly generate a random point on the surface of a unit sphere is not to pick uniform distributions in and in . Instead, choose and from uniform distributions on . Then, I can see why uniformly choosing in and in would lead to points near the poles being more likely to be chosen than points near the equator. But I can't think of an intuitive explanation for why the given solution correctly gives a uniform distribution. Is there a good intuitive explanation for this?","\theta [0,2\pi) \phi [0,\pi) u v [0,1) \phi = \cos^{-1}(2v-1) \theta = 2\pi u \theta [0,2\pi) \phi [0,\pi)","['probability', 'geometry', 'polar-coordinates', 'spheres']"
2,Flip $n$ coins on a circle. Assume a coin has been chosen from among those whose neighbors are both heads. What's the probability it is heads?,Flip  coins on a circle. Assume a coin has been chosen from among those whose neighbors are both heads. What's the probability it is heads?,n,"This is a generalization of the problem below (first appeared here ) I am particularly curious to know if there is a closed-form formula to calculate the probability for any $n$ and any probability of heads $p$ . note: One doesn't need to calculate the probability to show that it is not 50-50.  If $n=3$ , the exact probability can be calculated with few computational steps. For larger $n$ , relatively simple algorithms can be used to calculate the probability; some are more efficient than others.","This is a generalization of the problem below (first appeared here ) I am particularly curious to know if there is a closed-form formula to calculate the probability for any and any probability of heads . note: One doesn't need to calculate the probability to show that it is not 50-50.  If , the exact probability can be calculated with few computational steps. For larger , relatively simple algorithms can be used to calculate the probability; some are more efficient than others.",n p n=3 n,"['probability', 'combinatorics', 'puzzle', 'conditional-probability', 'paradoxes']"
3,"Balls with duplicate colors grouped into groups of 5, probability of a group with $\ge 2$ colors","Balls with duplicate colors grouped into groups of 5, probability of a group with  colors",\ge 2,"This arose out of an online game, and both exact answers and approximations would be greatly appreciated. $280$ balls are randomly put into $56$ bins such that all bins contain exactly $5$ balls. Among all $280$ balls, $2$ of them are colored red, $2$ of them green, $2$ of them blue (the rest can be considered uncolored, or any other color). I want to know the probability that, among the $56$ bins of balls, there exists $\ge 1$ bin which satisfies the following condition: the bin contains balls of at least two colors among the colors red, green, and blue. For example, if we use ""O"" to denote a ball that is not colored as red, green, or blue. $\{R, B, O, O,  O\}$ and $\{R,R,G,O,O\}$ are bins that satisfy the condition, while $\{R,R,O,O,O\}$ and $\{B,O,O,O,O\}$ do not. My Attempt I think an exact answer can be arrived (using multinomials), but I could not proceed beyond writing out the denominator. I decided to do a Poisson approximation, where $n = 56$ and $p$ is the probability that, when we randomly sample $5$ balls out of $280$ , the $5$ balls satisfy the condition. I calculated $p$ as follows: $$ 1 - \frac { \binom{274}{5} + \binom{6}{1} \binom{274}{4} + 3 \binom{2}{2} \binom{274}{3} } {\binom{280}{5}} $$ And from then on I used $\lambda = n p$ and used $1 - e^{-\lambda}$ as the final probability that there exists $\ge 1$ bin which satisfies the condition. Is my $p$ correct, or did I count it wrong? Can I use Poisson approximation here? I know that Poisson can be used for weakly dependent events, but I am not sure this qualifies. Edit: The Randomization Process I realized that I probably should have stated the randomization process. The original game was randomized by randomly sampling 5 out of 280 into the first bin, 5 out of the remaining 275 into the second, 5 out of the remaining 270 into the third, and so on.","This arose out of an online game, and both exact answers and approximations would be greatly appreciated. balls are randomly put into bins such that all bins contain exactly balls. Among all balls, of them are colored red, of them green, of them blue (the rest can be considered uncolored, or any other color). I want to know the probability that, among the bins of balls, there exists bin which satisfies the following condition: the bin contains balls of at least two colors among the colors red, green, and blue. For example, if we use ""O"" to denote a ball that is not colored as red, green, or blue. and are bins that satisfy the condition, while and do not. My Attempt I think an exact answer can be arrived (using multinomials), but I could not proceed beyond writing out the denominator. I decided to do a Poisson approximation, where and is the probability that, when we randomly sample balls out of , the balls satisfy the condition. I calculated as follows: And from then on I used and used as the final probability that there exists bin which satisfies the condition. Is my correct, or did I count it wrong? Can I use Poisson approximation here? I know that Poisson can be used for weakly dependent events, but I am not sure this qualifies. Edit: The Randomization Process I realized that I probably should have stated the randomization process. The original game was randomized by randomly sampling 5 out of 280 into the first bin, 5 out of the remaining 275 into the second, 5 out of the remaining 270 into the third, and so on.","280 56 5 280 2 2 2 56 \ge 1 \{R, B, O, O,  O\} \{R,R,G,O,O\} \{R,R,O,O,O\} \{B,O,O,O,O\} n = 56 p 5 280 5 p 
1 - \frac {
\binom{274}{5} + \binom{6}{1} \binom{274}{4} + 3 \binom{2}{2} \binom{274}{3}
} {\binom{280}{5}}
 \lambda = n p 1 - e^{-\lambda} \ge 1 p","['probability', 'combinatorics']"
4,Expected number of coin flips until all cars move to end of array?,Expected number of coin flips until all cars move to end of array?,,"Imagine that we have an array of length $2n$ , where the first $n$ entries are a $C$ (representing a toy car) and the remaining $n$ entries are empty. Additionally, we have $n$ fair coins labeled $1$ through $n$ , where coin $i$ corresponds to car $C_i$ in the array. On each timestep, we flip all $n$ coins. If coin $i$ comes up as heads, then car $C_i$ moves forward in the array by one spot, but only if it is not blocked by another car directly in the slot in front of it. Else, if blocked or the coin comes up tails, car $C_i$ does nothing. The question has two parts: What is the expected number of timesteps until the $n$ - $th$ car reaches the end of the array (reaches slot $2n$ )? What is the expected number of timesteps until all of the $n$ cars have moved from the first $n$ slots of the array to the last $n$ slots? I have worked out part 1 as follows. The expected number of flips for one coin to land as heads is $2$ , and the $n$ - $th$ car has to move $n$ slots to get to the end (and is not blocked by anything ever), so the expected number of timesteps is $2n$ . However, I am lost on the approach to part 2. I reason that it should be on the order $O(n\log n$ ) but do not know how to proceed. I keep running into a long chain of conditional probabilities and wonder if there is a more elegant way I am missing.","Imagine that we have an array of length , where the first entries are a (representing a toy car) and the remaining entries are empty. Additionally, we have fair coins labeled through , where coin corresponds to car in the array. On each timestep, we flip all coins. If coin comes up as heads, then car moves forward in the array by one spot, but only if it is not blocked by another car directly in the slot in front of it. Else, if blocked or the coin comes up tails, car does nothing. The question has two parts: What is the expected number of timesteps until the - car reaches the end of the array (reaches slot )? What is the expected number of timesteps until all of the cars have moved from the first slots of the array to the last slots? I have worked out part 1 as follows. The expected number of flips for one coin to land as heads is , and the - car has to move slots to get to the end (and is not blocked by anything ever), so the expected number of timesteps is . However, I am lost on the approach to part 2. I reason that it should be on the order ) but do not know how to proceed. I keep running into a long chain of conditional probabilities and wonder if there is a more elegant way I am missing.",2n n C n n 1 n i C_i n i C_i C_i n th 2n n n n 2 n th n 2n O(n\log n,"['probability', 'random-variables', 'expected-value']"
5,How to use Kullback-Leibler Divergence if probability distributions have different support?,How to use Kullback-Leibler Divergence if probability distributions have different support?,,"I have two discrete random variables $X$ and $Y$ and their distributions have different support. Assume $X$ and $Y$ can both take on the same number of values. Lets say $X$ takes values in $\{10,13,15,17,19\}$ and $Y$ takes values in $\{12,14,16,18,20\}$. I would like to use the Kullback-Leibler Divergence but it requires that Q dominates P. Is it possible to modify the support of each random variable so that they have the same support? If not, are there any measures of statistical distance that do not require $X$ and $Y$ to have the same support? One solution I have created is to make kernel density estimators with a gaussian kernel using the datasets collected on $X$ and $Y$. Now the densities $\hat{f}(x)$ and $\hat{g}(y)$ have support on $( -\infty, \infty)$ and with suitable bandwidth they are multimodal with modes centered around the support of the original random variables. It remains to be seen how wise or foolish of an idea this is. Note: Since the KL divergence of a finite gaussian mixture does not have a closed form solution, I used monte carlo methods to estimate it.","I have two discrete random variables $X$ and $Y$ and their distributions have different support. Assume $X$ and $Y$ can both take on the same number of values. Lets say $X$ takes values in $\{10,13,15,17,19\}$ and $Y$ takes values in $\{12,14,16,18,20\}$. I would like to use the Kullback-Leibler Divergence but it requires that Q dominates P. Is it possible to modify the support of each random variable so that they have the same support? If not, are there any measures of statistical distance that do not require $X$ and $Y$ to have the same support? One solution I have created is to make kernel density estimators with a gaussian kernel using the datasets collected on $X$ and $Y$. Now the densities $\hat{f}(x)$ and $\hat{g}(y)$ have support on $( -\infty, \infty)$ and with suitable bandwidth they are multimodal with modes centered around the support of the original random variables. It remains to be seen how wise or foolish of an idea this is. Note: Since the KL divergence of a finite gaussian mixture does not have a closed form solution, I used monte carlo methods to estimate it.",,"['probability', 'probability-distributions', 'information-theory']"
6,Question about random walk,Question about random walk,,"Consider $X_1, X_2, X_3$ ... random variables i.i.d. such that  $P(X_i=1)=p$ and  $P(X_i=-1)=1-p$. Consider the random walk $(S_n)_{n\ge 0} $ with $S_0=0$ and for $n\ge 1 $,  $S_n = \displaystyle\sum^{n}_{i=1} X_i$. Let $d=2p-1=E X_i$ be the drift of $S_n $. Assume  that  $d>0.$ Define $T_x= \inf \{n\ge0; S_n=x\} $. I want to prove that   $\displaystyle\sup_{y>0}\{T_y-\frac {2(y-1)}{d}\}$ is finite. It's clear that $T_y $ is finite, because $S_n$ is transient to right, but I can not control the difference. I thought of using the fact that the time the walker needs to go from $0$ to $y$ is of the ordem of $\frac {y}{d}$ since d is intuitively the speed of the random walk. Help?","Consider $X_1, X_2, X_3$ ... random variables i.i.d. such that  $P(X_i=1)=p$ and  $P(X_i=-1)=1-p$. Consider the random walk $(S_n)_{n\ge 0} $ with $S_0=0$ and for $n\ge 1 $,  $S_n = \displaystyle\sum^{n}_{i=1} X_i$. Let $d=2p-1=E X_i$ be the drift of $S_n $. Assume  that  $d>0.$ Define $T_x= \inf \{n\ge0; S_n=x\} $. I want to prove that   $\displaystyle\sup_{y>0}\{T_y-\frac {2(y-1)}{d}\}$ is finite. It's clear that $T_y $ is finite, because $S_n$ is transient to right, but I can not control the difference. I thought of using the fact that the time the walker needs to go from $0$ to $y$ is of the ordem of $\frac {y}{d}$ since d is intuitively the speed of the random walk. Help?",,['probability']
7,Jump Process - Random Walk,Jump Process - Random Walk,,"A 1-D random walker strarting at time $t=0$ and location $x=0$, moves to the right ($x+1$) or the left ($x-1$) according to independent random variables $R_1,R_2,\ldots$ and $L_1,L_2,\ldots$, such that the $k^{\mathrm{th}}$ jump to the right occurs at the time $\sum_{i=1}^{k} R_i$ and the $k^{\mathrm{th}}$ jump to the left occurs at the time $\sum_{i=1}^{k} L_i$. Assume $R_i$s and $L_i$s are samples of the same probability density function $f(x)$. Show that the probability that the location of the random walker remains $x\leq M$ after the first $N$ steps to the right, tends to $1-\delta$, for all $\delta>0$, as $N, M \to\infty$, as long as $M=\mathcal{O}(\sqrt{N})$. My Solution : If $f(x)=\lambda e^{-\lambda x}$, the memorylessness of exponential random variables makes this problem equivalent to a symmetric random walk, then we can find the survival probability of a random walk and use the Brownian motion limit to prove this (see Survival Probability in here ). How about the general $f(x)$? I think we make it equivalent to another Brownian motion, I don't know how to find the parameters of that Brownian motion.","A 1-D random walker strarting at time $t=0$ and location $x=0$, moves to the right ($x+1$) or the left ($x-1$) according to independent random variables $R_1,R_2,\ldots$ and $L_1,L_2,\ldots$, such that the $k^{\mathrm{th}}$ jump to the right occurs at the time $\sum_{i=1}^{k} R_i$ and the $k^{\mathrm{th}}$ jump to the left occurs at the time $\sum_{i=1}^{k} L_i$. Assume $R_i$s and $L_i$s are samples of the same probability density function $f(x)$. Show that the probability that the location of the random walker remains $x\leq M$ after the first $N$ steps to the right, tends to $1-\delta$, for all $\delta>0$, as $N, M \to\infty$, as long as $M=\mathcal{O}(\sqrt{N})$. My Solution : If $f(x)=\lambda e^{-\lambda x}$, the memorylessness of exponential random variables makes this problem equivalent to a symmetric random walk, then we can find the survival probability of a random walk and use the Brownian motion limit to prove this (see Survival Probability in here ). How about the general $f(x)$? I think we make it equivalent to another Brownian motion, I don't know how to find the parameters of that Brownian motion.",,"['probability', 'statistics', 'stochastic-processes', 'brownian-motion', 'random-walk']"
8,"Which outcome is more likely, getting four kings within 2x cards or a specific pair of triples (from a group) within x cards?","Which outcome is more likely, getting four kings within 2x cards or a specific pair of triples (from a group) within x cards?",,"Suppose 2 people (call them A and B) challenge each other to a card game. A fair, well shuffled, standard 52 card deck is used for each hand. Community (shared) cards are drawn one at a time without replacement for each hand.  Player A will win if all four Kings are drawn in a hand.  Player B will have a candidate win if a pair of triples are drawn from the following ranks (2,3,4,5,6,7,8,9,10) in a hand.  Since it is more likely that B will encounter a candidate win before A wins, both players agree that even if B gets a candidate win (let's say for example with 20 cards drawn so let n = the number of cards drawn for B to have the first candidate win of the hand), community cards will continue to be drawn for that hand until either twice as many cards are drawn and there is no win for A, or A has a win before 2n cards are drawn. For example: Let's suppose player B gets a candidate win early in the hand at the 10th drawn card (not likely but good to keep this example short).  The drawn cards could be something like this: 3 5 K 7 5 J K 3 3 5.  Here B has a candidate win with 333 and 555 but the rules of the game state that A has a chance to win by getting the 4 Ks within twice the number of cards drawn when B gets the first candidate win (in this example twice 10 cards = 20 cards).  So for example, if drawn cards 11 thru 15 were 9 2 K Q K, then A would actually win because A's win was in 15 cards and B's candidate win was in 10 cards and 15 is less than double of 10.  In this case, B's candidate win would lose. So there will be a winner every hand. So the question is who will win in the longrun based on the given rules?  How do you compute this mathematically?  That is, how do you determine the average number of cards for each player to get a candidate win and if we apply these rules of the game, who should win in the longrun? For clarification, note that quads of ranks 2,3,4,5,6,7,8,9 and 10 are still considered triples.  So (for example), B can still have a candidate win if cards 2 2 2 3 3 3 3 are drawn somewhere in the hand before seeing quad Ks.  The last card of rank 3 here might be drawn as we are drawing more cards to see if A will have a win within the allowed # of cards.  Also, even if more than a 2 occurrences of triples in ranks 2,3,4,5,6,7,8,9,and 10 show up, that is still considered a candidate win for B.  For clarity, think of the first pair of triples seen (in ranks 2,3,4,5,6,7,8,9,10) as the start of the candidate win for B (taking note of how many cards were drawn up to that point), and as we draw more cards to see if A wins or not, other triples that come up will not nullify the candidate win that B already has. Also, in the rare case where the four Ks appear before player B gets the 2 occurrences of triples, the hand would stop immediately since that is clearly a win for player A. For clarity I should also mention that quads in ranks 2..10 are still considered a candidate win for B such as if cards 2 2 2 2 7 7 7 7 are seen before the 4 Ks are seen.  This is because once a triple in ranks 2..10 is seen, it retains the triple ""status"" (for the purpose of this game), even though it may later turn into a quad during that same hand. Also note that the minumum # of drawn cards for A to win is 4 (KKKK) but the minimum for B to win is 12 (such as 3 5 3 5 3 5 7 K 8 K 9 K).  Even though B has the candidate win at drawn card 6 in this example, we have to allow 12 drawn cards total to ensure there is no win by A within the 12 total cards.","Suppose 2 people (call them A and B) challenge each other to a card game. A fair, well shuffled, standard 52 card deck is used for each hand. Community (shared) cards are drawn one at a time without replacement for each hand.  Player A will win if all four Kings are drawn in a hand.  Player B will have a candidate win if a pair of triples are drawn from the following ranks (2,3,4,5,6,7,8,9,10) in a hand.  Since it is more likely that B will encounter a candidate win before A wins, both players agree that even if B gets a candidate win (let's say for example with 20 cards drawn so let n = the number of cards drawn for B to have the first candidate win of the hand), community cards will continue to be drawn for that hand until either twice as many cards are drawn and there is no win for A, or A has a win before 2n cards are drawn. For example: Let's suppose player B gets a candidate win early in the hand at the 10th drawn card (not likely but good to keep this example short).  The drawn cards could be something like this: 3 5 K 7 5 J K 3 3 5.  Here B has a candidate win with 333 and 555 but the rules of the game state that A has a chance to win by getting the 4 Ks within twice the number of cards drawn when B gets the first candidate win (in this example twice 10 cards = 20 cards).  So for example, if drawn cards 11 thru 15 were 9 2 K Q K, then A would actually win because A's win was in 15 cards and B's candidate win was in 10 cards and 15 is less than double of 10.  In this case, B's candidate win would lose. So there will be a winner every hand. So the question is who will win in the longrun based on the given rules?  How do you compute this mathematically?  That is, how do you determine the average number of cards for each player to get a candidate win and if we apply these rules of the game, who should win in the longrun? For clarification, note that quads of ranks 2,3,4,5,6,7,8,9 and 10 are still considered triples.  So (for example), B can still have a candidate win if cards 2 2 2 3 3 3 3 are drawn somewhere in the hand before seeing quad Ks.  The last card of rank 3 here might be drawn as we are drawing more cards to see if A will have a win within the allowed # of cards.  Also, even if more than a 2 occurrences of triples in ranks 2,3,4,5,6,7,8,9,and 10 show up, that is still considered a candidate win for B.  For clarity, think of the first pair of triples seen (in ranks 2,3,4,5,6,7,8,9,10) as the start of the candidate win for B (taking note of how many cards were drawn up to that point), and as we draw more cards to see if A wins or not, other triples that come up will not nullify the candidate win that B already has. Also, in the rare case where the four Ks appear before player B gets the 2 occurrences of triples, the hand would stop immediately since that is clearly a win for player A. For clarity I should also mention that quads in ranks 2..10 are still considered a candidate win for B such as if cards 2 2 2 2 7 7 7 7 are seen before the 4 Ks are seen.  This is because once a triple in ranks 2..10 is seen, it retains the triple ""status"" (for the purpose of this game), even though it may later turn into a quad during that same hand. Also note that the minumum # of drawn cards for A to win is 4 (KKKK) but the minimum for B to win is 12 (such as 3 5 3 5 3 5 7 K 8 K 9 K).  Even though B has the candidate win at drawn card 6 in this example, we have to allow 12 drawn cards total to ensure there is no win by A within the 12 total cards.",,"['probability', 'card-games']"
9,Sum of random variables at least $\log n$,Sum of random variables at least,\log n,"Let $X_1,\dots,X_n$ be independent random variables in $\{0,1\}$, and $X=X_1+\dots+X_n$. Suppose that $\mathbb{E}[X]=1$. What is the best possible upper bound on $\text{Pr}(X>\log n)$? Using the multiplicative form of Chernoff's bound , we have that $\text{Pr}(X>1+\delta)<\dfrac{e^\delta}{(1+\delta)^{1+\delta}}$ for any $\delta>0$. When $\delta$ is $\log n-1$, then this becomes $\dfrac{e^{\log n-1}}{\log n^{\log n}}$. This is approximately $n^{1-\log\log n}$. Are there examples of random variables $X_1,\dots,X_n$ that shows that this bound resulting from Chernoff is (approximately) tight?","Let $X_1,\dots,X_n$ be independent random variables in $\{0,1\}$, and $X=X_1+\dots+X_n$. Suppose that $\mathbb{E}[X]=1$. What is the best possible upper bound on $\text{Pr}(X>\log n)$? Using the multiplicative form of Chernoff's bound , we have that $\text{Pr}(X>1+\delta)<\dfrac{e^\delta}{(1+\delta)^{1+\delta}}$ for any $\delta>0$. When $\delta$ is $\log n-1$, then this becomes $\dfrac{e^{\log n-1}}{\log n^{\log n}}$. This is approximately $n^{1-\log\log n}$. Are there examples of random variables $X_1,\dots,X_n$ that shows that this bound resulting from Chernoff is (approximately) tight?",,"['probability', 'random-variables', 'expectation']"
10,Measure acting on differential form,Measure acting on differential form,,"In the context of measure theory, given a probability measure $\xi : \mathcal{B}(X) \rightarrow [0,1]$ and a (smooth) function $v:X\rightarrow \mathbb{R}$ where $X\subset \mathbb{R}^n$, we encounter the notation $$ \int_X v(x)\, \xi(dx) $$ What is behind the notation $\xi(dx)$ formally ? Do probability measures act on differential forms ? If so, what is this action formally ?","In the context of measure theory, given a probability measure $\xi : \mathcal{B}(X) \rightarrow [0,1]$ and a (smooth) function $v:X\rightarrow \mathbb{R}$ where $X\subset \mathbb{R}^n$, we encounter the notation $$ \int_X v(x)\, \xi(dx) $$ What is behind the notation $\xi(dx)$ formally ? Do probability measures act on differential forms ? If so, what is this action formally ?",,"['probability', 'integration', 'measure-theory', 'differential-geometry']"
11,"Coupling showing that $\operatorname{Bin}(n,\frac{1}{n+1})$ stochastically dominates $\operatorname{Bin}(n-1,\frac{1}{n})$",Coupling showing that  stochastically dominates,"\operatorname{Bin}(n,\frac{1}{n+1}) \operatorname{Bin}(n-1,\frac{1}{n})","The classical inequality $$ \left(1-\frac{1}{n}\right)^{n-1} > \frac{1}{e} $$ has a probabilistic generalization: the binomial distribution $\operatorname{Bin}(n-1,\frac{1}{n})$ is stochastically dominated by the Poisson distribution $\operatorname{Po}(1)$. A simple coupling proof of this can be found in Klenke and Mattner, Stochastic ordering of classical discrete distributions . They also prove the stronger result that $\operatorname{Bin}(n,\frac{1}{n+1})$ stochastically dominates $\operatorname{Bin}(n-1,\frac{1}{n})$, which generalizes the fact that the sequence $(1-\frac1n)^{n-1}$ is decreasing. Is there a natural coupling that shows that $\operatorname{Bin}(n,\frac{1}{n+1})$ stochastically dominates $\operatorname{Bin}(n-1,\frac{1}{n})$? What I have in mind is an elementary argument that involves a balls-into-bins scenario, but any other simple coupling would be great. (Just to be clear: I already know that there exists some coupling, this follows from the stochastic domination.)","The classical inequality $$ \left(1-\frac{1}{n}\right)^{n-1} > \frac{1}{e} $$ has a probabilistic generalization: the binomial distribution $\operatorname{Bin}(n-1,\frac{1}{n})$ is stochastically dominated by the Poisson distribution $\operatorname{Po}(1)$. A simple coupling proof of this can be found in Klenke and Mattner, Stochastic ordering of classical discrete distributions . They also prove the stronger result that $\operatorname{Bin}(n,\frac{1}{n+1})$ stochastically dominates $\operatorname{Bin}(n-1,\frac{1}{n})$, which generalizes the fact that the sequence $(1-\frac1n)^{n-1}$ is decreasing. Is there a natural coupling that shows that $\operatorname{Bin}(n,\frac{1}{n+1})$ stochastically dominates $\operatorname{Bin}(n-1,\frac{1}{n})$? What I have in mind is an elementary argument that involves a balls-into-bins scenario, but any other simple coupling would be great. (Just to be clear: I already know that there exists some coupling, this follows from the stochastic domination.)",,"['probability', 'binomial-distribution', 'coupling']"
12,Is a linear factor more likely than a quadratic factor?,Is a linear factor more likely than a quadratic factor?,,"I choose a reducible (over $\mathbb Z$) monic polynomial of degree four with integer coefficients, at random. Is it more likely to have  a linear factor or a quadratic factor ? Formal version of the question : let $N>0$, and $$B_N=\lbrace (a,b,c,d) \in [|-N,N|]^4 | X^4+aX^3+bX^2+cX+d \text{ is reducible},\rbrace$$ (so that $|B_N|$ has at most $(2N+1)^4$ elements ; in fact, it is known to have $o(N^4)$ elements, and even $O(N^3)$ if I'm not mistaken). Let $$ \begin{array}{lcl} B_{N,1} &=&\lbrace (a,b,c,d) \in B_N | X^4+aX^3+bX^2+cX+d \text{ has a linear factor}\rbrace, \\ B_{N,2}&=&\lbrace (a,b,c,d) \in B_N | X^4+aX^3+bX^2+cX+d \text{ has a quadratic factor}\rbrace, \end{array}$$ (note that in $B_{N,2}$ the quadratic factor may itself be reducible ; also the intersection $B_{N,1}\cap B_{N,2}$ is nonempty) and $$ p_n=\frac{|B_{N,1}|}{|B_N|}, q_n=\frac{|B_{N,2}|}{|B_N|}  $$ Is anything known about the asymptotic behaviour of $p_n,q_n$ and $\frac{p_n}{q_n}$ ?","I choose a reducible (over $\mathbb Z$) monic polynomial of degree four with integer coefficients, at random. Is it more likely to have  a linear factor or a quadratic factor ? Formal version of the question : let $N>0$, and $$B_N=\lbrace (a,b,c,d) \in [|-N,N|]^4 | X^4+aX^3+bX^2+cX+d \text{ is reducible},\rbrace$$ (so that $|B_N|$ has at most $(2N+1)^4$ elements ; in fact, it is known to have $o(N^4)$ elements, and even $O(N^3)$ if I'm not mistaken). Let $$ \begin{array}{lcl} B_{N,1} &=&\lbrace (a,b,c,d) \in B_N | X^4+aX^3+bX^2+cX+d \text{ has a linear factor}\rbrace, \\ B_{N,2}&=&\lbrace (a,b,c,d) \in B_N | X^4+aX^3+bX^2+cX+d \text{ has a quadratic factor}\rbrace, \end{array}$$ (note that in $B_{N,2}$ the quadratic factor may itself be reducible ; also the intersection $B_{N,1}\cap B_{N,2}$ is nonempty) and $$ p_n=\frac{|B_{N,1}|}{|B_N|}, q_n=\frac{|B_{N,2}|}{|B_N|}  $$ Is anything known about the asymptotic behaviour of $p_n,q_n$ and $\frac{p_n}{q_n}$ ?",,"['probability', 'polynomials']"
13,Select 3 balls from a bag. What is the probability that the third ball is white given that the first two draws result in white balls.,Select 3 balls from a bag. What is the probability that the third ball is white given that the first two draws result in white balls.,,"In detail, a bag has 8 white, $3$ red, $2$ blue balls. One by one balls are drawn from the bag. If the first two draws result in white balls, find the probability that the third ball drawn would be white when the balls are drawn without replacement. I think if the first two draws result in white balls then we are left with $6$ white balls and the probability of drawing a third white ball is $6 \over 11$. Is this line of thinking valid or am I missing something else?","In detail, a bag has 8 white, $3$ red, $2$ blue balls. One by one balls are drawn from the bag. If the first two draws result in white balls, find the probability that the third ball drawn would be white when the balls are drawn without replacement. I think if the first two draws result in white balls then we are left with $6$ white balls and the probability of drawing a third white ball is $6 \over 11$. Is this line of thinking valid or am I missing something else?",,"['probability', 'combinatorics', 'proof-verification', 'combinations']"
14,Expected value and variance of ratio of two sums of two sets of random variables,Expected value and variance of ratio of two sums of two sets of random variables,,"Let $X_1,X_2,\ldots,X_n$ be iid $\operatorname{Gamma}(\alpha,\beta)$ random variables. Suppose that, conditionally on $X_1,X_2,\ldots,X_n$, the random variables $Y_1,Y_2,\ldots,Y_n$ are independent and $Y_{i}\mid X_{i}\sim \operatorname{Gamma}(\alpha,\beta X_i)$. Show that $$E\left(\frac{\bar{Y}}{\bar{X}}\right)=\alpha\beta$$ and $$\operatorname{Var}\left(\frac{\bar{Y}}{\bar{X}}\right)=\alpha\beta^2E\left(\frac{\sum X_i^2}{(\sum X_i)^2}\right).$$ It is a question from a past comprehensive exam. The hint says ""use the iterated expectation and variance formulas"". But I do not see anywhere can use this hint.","Let $X_1,X_2,\ldots,X_n$ be iid $\operatorname{Gamma}(\alpha,\beta)$ random variables. Suppose that, conditionally on $X_1,X_2,\ldots,X_n$, the random variables $Y_1,Y_2,\ldots,Y_n$ are independent and $Y_{i}\mid X_{i}\sim \operatorname{Gamma}(\alpha,\beta X_i)$. Show that $$E\left(\frac{\bar{Y}}{\bar{X}}\right)=\alpha\beta$$ and $$\operatorname{Var}\left(\frac{\bar{Y}}{\bar{X}}\right)=\alpha\beta^2E\left(\frac{\sum X_i^2}{(\sum X_i)^2}\right).$$ It is a question from a past comprehensive exam. The hint says ""use the iterated expectation and variance formulas"". But I do not see anywhere can use this hint.",,"['probability', 'statistics', 'statistical-inference']"
15,Expected travel of random walk in arbitrary game with multiple payouts,Expected travel of random walk in arbitrary game with multiple payouts,,"As explained here , the average distance or 'travel' of a random walk with $N$ coin tosses approaches: $$\sqrt{\dfrac{2N}{\pi}}$$ What a beautiful result - who would've thought $\pi$ was involved! However, what would be the formula to use for an arbitrary paytable? For example, a coin toss has the paytable: 0.5 : -1 0.5 : 1 ...so a 50% chance of both winning or losing a point. After 10,000 coin tosses, the travel on average will be $\sqrt{10000\cdot2/{\pi}} \approx 79.788$. However a dice roll where you need to land a six to win could have the paytable: 0.8333.. : -1 0.1666.. : 5 After 10,000 dice rolls, the travel on average will be about 178. However, I only know that because I used simulation to brute force the result - I don't know the formula. More generally, a paytable could have multiple entries where all the probabilities add up to one: probability1 : payout1 probability2 : payout2 probability3 : payout3 ... ... probabilityN : payoutN Note that the total of the payouts may not necessarily be zero. It could be weighted to produce an unfair game. For example: 0.75 : -1 0.1 : 0.5 0.15 : 4.5 That's an average payout of $-0.025$ with a variance of $3.811875$, and using simulation, I get $\approx 268.8$ 'travel' from 10000 runs. But how would I find this out directly? In other words, how would you find the average 'travel' of such a generalized paytable without resorting to simulation? As a side question, would this figure also be a better indication of risk for such a 'game' compared to the standard deviation of the paytable as defined here ? Here's the code I used for the simulation: http://pastebin.com/985eDTFh It's written in C#, but is otherwise very well self-contained. Most of it is a fast random class, but you can use the default Random class if you prefer. Also, if you're not using C#, don't worry too much about converting the convertCSVtoPayoutTable() function as you can hard code the probability and payout arrays yourself if you prefer.","As explained here , the average distance or 'travel' of a random walk with $N$ coin tosses approaches: $$\sqrt{\dfrac{2N}{\pi}}$$ What a beautiful result - who would've thought $\pi$ was involved! However, what would be the formula to use for an arbitrary paytable? For example, a coin toss has the paytable: 0.5 : -1 0.5 : 1 ...so a 50% chance of both winning or losing a point. After 10,000 coin tosses, the travel on average will be $\sqrt{10000\cdot2/{\pi}} \approx 79.788$. However a dice roll where you need to land a six to win could have the paytable: 0.8333.. : -1 0.1666.. : 5 After 10,000 dice rolls, the travel on average will be about 178. However, I only know that because I used simulation to brute force the result - I don't know the formula. More generally, a paytable could have multiple entries where all the probabilities add up to one: probability1 : payout1 probability2 : payout2 probability3 : payout3 ... ... probabilityN : payoutN Note that the total of the payouts may not necessarily be zero. It could be weighted to produce an unfair game. For example: 0.75 : -1 0.1 : 0.5 0.15 : 4.5 That's an average payout of $-0.025$ with a variance of $3.811875$, and using simulation, I get $\approx 268.8$ 'travel' from 10000 runs. But how would I find this out directly? In other words, how would you find the average 'travel' of such a generalized paytable without resorting to simulation? As a side question, would this figure also be a better indication of risk for such a 'game' compared to the standard deviation of the paytable as defined here ? Here's the code I used for the simulation: http://pastebin.com/985eDTFh It's written in C#, but is otherwise very well self-contained. Most of it is a fast random class, but you can use the default Random class if you prefer. Also, if you're not using C#, don't worry too much about converting the convertCSVtoPayoutTable() function as you can hard code the probability and payout arrays yourself if you prefer.",,"['probability', 'game-theory', 'random-walk', 'simulation']"
16,Digit Code Combination Problem,Digit Code Combination Problem,,"Based on real life experience, I just considered the following combinatorial challenge: In a workplace with currently $n$ employees each employee has its own unique 4-digit code used to pass through certain doors at certain times of day. Tomorrow $r$ new employees will start working there and each must fill in a form suggesting two different 4-digit codes. They have no knowledge of each others codes or the $n$ current employee's codes. When everyone has filed their forms, it is attempted to assign each new employee one of their suggested codes so that all $n+r$ persons working there have unique codes. For simplicity, let us assume that the new employees choose their two different 4-digit suggestions uniformly at random. Then what is the probability $P(n,r)$ that the workplace is unable to assign unique codes to all the new employees?","Based on real life experience, I just considered the following combinatorial challenge: In a workplace with currently $n$ employees each employee has its own unique 4-digit code used to pass through certain doors at certain times of day. Tomorrow $r$ new employees will start working there and each must fill in a form suggesting two different 4-digit codes. They have no knowledge of each others codes or the $n$ current employee's codes. When everyone has filed their forms, it is attempted to assign each new employee one of their suggested codes so that all $n+r$ persons working there have unique codes. For simplicity, let us assume that the new employees choose their two different 4-digit suggestions uniformly at random. Then what is the probability $P(n,r)$ that the workplace is unable to assign unique codes to all the new employees?",,"['probability', 'combinatorics', 'algebra-precalculus', 'recreational-mathematics']"
17,"If $\mathbb{E}[X] = 0$, then $P[X \geq \lambda] \leq \frac{\sigma^2}{\sigma^2 + \lambda^2}$","If , then",\mathbb{E}[X] = 0 P[X \geq \lambda] \leq \frac{\sigma^2}{\sigma^2 + \lambda^2},"Say $X$ is a real random variable, and its expected value is $\mathbb{E}[X] = 0$.  Denote the variance $\operatorname{Var}[X] = \sigma^2$. Show that $P[X \geq \lambda] \leq \frac{\sigma^2}{\sigma^2 + \lambda^2}$ for any $\lambda > 0$. This is an exercise in The Probabilistic Method (Alon & Spencer) in chapter 4, which focuses on the uses of the Chebyshev inequality - so I assume it is useful here but I'm stuck.","Say $X$ is a real random variable, and its expected value is $\mathbb{E}[X] = 0$.  Denote the variance $\operatorname{Var}[X] = \sigma^2$. Show that $P[X \geq \lambda] \leq \frac{\sigma^2}{\sigma^2 + \lambda^2}$ for any $\lambda > 0$. This is an exercise in The Probabilistic Method (Alon & Spencer) in chapter 4, which focuses on the uses of the Chebyshev inequality - so I assume it is useful here but I'm stuck.",,"['probability', 'expectation']"
18,Roll a fair die until a 6 appears for the third time. What is the chance that all six values have occurred?,Roll a fair die until a 6 appears for the third time. What is the chance that all six values have occurred?,,"The question in the title is a homework question that I have been stumped on for some time. My approach thus far was to treat it as an occupancy problem. From class we derived the following formula for the probability of k faces being rolled on an r sided die after n rolls: $$ P(Y = k) = \binom{r}{k} \big (\frac{k}{r}\big )^n \sum_{i=0}^{r}(-1)^i\binom{k}{i}\big(1-\frac{i}{k}\big)^n$$ So what I have done is set k = r = 6 and arrived at: $$ P(Y = 6) = \sum_{i=0}^{6}(-1)^i\binom{6}{i}\big(1-\frac{i}{6}\big)^n$$ However, the problem now is that n is a random integer variable between $3$ and infinity. What I did next was attempt to model the number of rolls as a negative-binomial random variable and then compute the expectation value of the above expression inside of this distribution; however, it produces a very ugly expression which I am pretty sure is still wrong because it does not include the fact that a 6 is guaranteed to be rolled. I basically have run out of ideas and am somewhat stuck on how to proceed. My approach may be a total red herring, so feel free to discard it in any advice you give. Also, this is homework, so please don't list a full solution. Thanks for any help!","The question in the title is a homework question that I have been stumped on for some time. My approach thus far was to treat it as an occupancy problem. From class we derived the following formula for the probability of k faces being rolled on an r sided die after n rolls: $$ P(Y = k) = \binom{r}{k} \big (\frac{k}{r}\big )^n \sum_{i=0}^{r}(-1)^i\binom{k}{i}\big(1-\frac{i}{k}\big)^n$$ So what I have done is set k = r = 6 and arrived at: $$ P(Y = 6) = \sum_{i=0}^{6}(-1)^i\binom{6}{i}\big(1-\frac{i}{6}\big)^n$$ However, the problem now is that n is a random integer variable between $3$ and infinity. What I did next was attempt to model the number of rolls as a negative-binomial random variable and then compute the expectation value of the above expression inside of this distribution; however, it produces a very ugly expression which I am pretty sure is still wrong because it does not include the fact that a 6 is guaranteed to be rolled. I basically have run out of ideas and am somewhat stuck on how to proceed. My approach may be a total red herring, so feel free to discard it in any advice you give. Also, this is homework, so please don't list a full solution. Thanks for any help!",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'dice']"
19,"Is there a statistical interpretation of Green's theorem, Stokes' theorem, or the divergence theorem?","Is there a statistical interpretation of Green's theorem, Stokes' theorem, or the divergence theorem?",,"I'm teaching a class on integration of functions of several variables and vector calculus this semester.  The class is made up most of economics majors and engineering majors, with a smattering of math and physics folks as well.  I taught this class last semester, and I found that a lot of the economics majors were rather bored during the second half.  I was able to motivate multiple integrals by doing some calculations with jointly distributed random variables, but for the vector analysis part of the course the only motivation I could think of was based on physics. So I'm wondering if anybody knows a statistical/probabilistic interpretation of any of the main theorems of vector calculus.  This might require having such an interpretation of div, grad, and curl, and it's not so obvious what it might be.  Anyone have any ideas?","I'm teaching a class on integration of functions of several variables and vector calculus this semester.  The class is made up most of economics majors and engineering majors, with a smattering of math and physics folks as well.  I taught this class last semester, and I found that a lot of the economics majors were rather bored during the second half.  I was able to motivate multiple integrals by doing some calculations with jointly distributed random variables, but for the vector analysis part of the course the only motivation I could think of was based on physics. So I'm wondering if anybody knows a statistical/probabilistic interpretation of any of the main theorems of vector calculus.  This might require having such an interpretation of div, grad, and curl, and it's not so obvious what it might be.  Anyone have any ideas?",,"['probability', 'multivariable-calculus']"
20,Age of Stochasticity?,Age of Stochasticity?,,"Today I came across D. Mumford's 1999 article The Dawning of the Age of Stochasticity , which is quite remarkable even after more than a decade. The title already indicates the theme, but I copy the abstract for the convenience of the reader: For over two millennia, Aristotle's logic has ruled over the thinking of western intellectuals. All precise theories, all scientific models, even models of process of thinking itself, have in principle conformed to the straight-jacket of logic. But from its shady beginnings devising gambling strategies and counting corpses in medieval London, probability theory and statistical interference now emerges as better foundations for scientific models, especially those of the process of thinking and as essential ingredients of theoretical mathematics, even foundation of mathematics itself. We propose that this sea change in our perspective will affect virtually all of mathematics in the next century. In the article he proposes a new approach to mathematical science, putting random variables and stochasticity into foundations of mathematics (rather than building them upon measure theory), especially in theory of differential equations and artificial intelligence. I am wondering how is this program going? I know something about stochastic differential equations from finance, and I know probability theory is fundamental to machine learning and artificial intelligence. However, it seems to me stochasticity is still far from the foundations of mathematics, and much mathematics is still ruled by logic. Of course as an undergraduate maybe I am just too far from the frontier. So can someone tell me how is this program going? Is it really some advantage in this new approach Mumford proposed? Thanks very much!","Today I came across D. Mumford's 1999 article The Dawning of the Age of Stochasticity , which is quite remarkable even after more than a decade. The title already indicates the theme, but I copy the abstract for the convenience of the reader: For over two millennia, Aristotle's logic has ruled over the thinking of western intellectuals. All precise theories, all scientific models, even models of process of thinking itself, have in principle conformed to the straight-jacket of logic. But from its shady beginnings devising gambling strategies and counting corpses in medieval London, probability theory and statistical interference now emerges as better foundations for scientific models, especially those of the process of thinking and as essential ingredients of theoretical mathematics, even foundation of mathematics itself. We propose that this sea change in our perspective will affect virtually all of mathematics in the next century. In the article he proposes a new approach to mathematical science, putting random variables and stochasticity into foundations of mathematics (rather than building them upon measure theory), especially in theory of differential equations and artificial intelligence. I am wondering how is this program going? I know something about stochastic differential equations from finance, and I know probability theory is fundamental to machine learning and artificial intelligence. However, it seems to me stochasticity is still far from the foundations of mathematics, and much mathematics is still ruled by logic. Of course as an undergraduate maybe I am just too far from the frontier. So can someone tell me how is this program going? Is it really some advantage in this new approach Mumford proposed? Thanks very much!",,"['probability', 'soft-question', 'stochastic-processes', 'intuition', 'philosophy']"
21,Probability of two points being split into different partitions.,Probability of two points being split into different partitions.,,"Suppose $x < y \in [0, 1]$ and $U_1, U_2, ...$ are random variables distributed as uniform on $(0, w)$ with $w < 1$. Define $S_n = \sum_{i = 1} ^ n U_i$. We'll say that $(S_i)$ splits $x$ and $y$ if, for some $n$, $x < S_n < y$. I'm interested in what sorts of things could be said about the probability that $x$ and $y$ are split. If it helps, take $w$ to be small and $x, y$ close to $1$ and $|x - y| < w$. I feel that this is quite related to whatever subject studies things like Poisson processes. Obviously, I know that if $|x - y| > w$ then $x$ and $y$ will be split, but beyond that I'm not sure what theory I would look to, and I don't know whether this sort of problem is tractable or not (it might be trivial for all I know). Only guess that I have is that near $|x - y| = w$ the probability should go to $0$ like $1 - \frac{|x - y|}{w}$, and this should be a lower bound for any $|x - y| < w$. I may also be interested in results or pointers for $U_i$ not uniform, but I need it to be the case that for points sufficiently far away the probability of being split is exactly $1$. EDIT : In light of the solution posted by PinkElephant below, I'll reword this as follows. Set $w = 1$ and remove the restriction on $x, y \in [0, 1]$ so that just $x < y \in \mathbb R$. What is the probability that $x$ and $y$ are split for large values of $x, y$ but for $|x - y|$ fixed, i.e. $x, y \to \infty$ but $y - x$ constant. It seems to me that asymptotically things should only depend on $y - x$; for $x, y$ near $0$ it seems as though there is dependence on the fact that we started the sum from $0$ that I think we escape from for large $x, y$. Update : I have a heuristic argument that gives the asymptotic probability of $x$ and $y$ being split as $1 - (1 - |x - y|)^2_+$ where $(a)_+$ denotes $\max\{0, a\}$. The argument is as follows: it should not matter asymptotically where $x$ and $y$ lie, so we can assume $x= k$ for some positive integer $k$. $x$ and $y$ will be split if, for the first value of $S_i$ in the interval $[x, x + 1]$, we have $x \le S_i \le y$. Consider the Markov chain $T_j$ consisting of the fractional parts of those $S_i$ such that $(S_{i - 1}) > (S_i)$, where $(a)$ denotes the fractional part of $a$. The probability that $x$ and $y$ are split should be $P(T \le (y - x))$ where $T$ is drawn from the stationary distribution of the $T_j$. I took a blind guess that the stationary distribution was given by the density $f(t) = 2(1 - t)$, drew a bunch of samples from the Markov chain I described, and verified empirically that $f(t) = 2 (1 - t)$ is the answer I'm supposed to get. If anyone wants to take a stab at verifying that $1 - (1 - |x - y|)_+^2$ is indeed the correct answer asymptotically, it would be much appreciated.","Suppose $x < y \in [0, 1]$ and $U_1, U_2, ...$ are random variables distributed as uniform on $(0, w)$ with $w < 1$. Define $S_n = \sum_{i = 1} ^ n U_i$. We'll say that $(S_i)$ splits $x$ and $y$ if, for some $n$, $x < S_n < y$. I'm interested in what sorts of things could be said about the probability that $x$ and $y$ are split. If it helps, take $w$ to be small and $x, y$ close to $1$ and $|x - y| < w$. I feel that this is quite related to whatever subject studies things like Poisson processes. Obviously, I know that if $|x - y| > w$ then $x$ and $y$ will be split, but beyond that I'm not sure what theory I would look to, and I don't know whether this sort of problem is tractable or not (it might be trivial for all I know). Only guess that I have is that near $|x - y| = w$ the probability should go to $0$ like $1 - \frac{|x - y|}{w}$, and this should be a lower bound for any $|x - y| < w$. I may also be interested in results or pointers for $U_i$ not uniform, but I need it to be the case that for points sufficiently far away the probability of being split is exactly $1$. EDIT : In light of the solution posted by PinkElephant below, I'll reword this as follows. Set $w = 1$ and remove the restriction on $x, y \in [0, 1]$ so that just $x < y \in \mathbb R$. What is the probability that $x$ and $y$ are split for large values of $x, y$ but for $|x - y|$ fixed, i.e. $x, y \to \infty$ but $y - x$ constant. It seems to me that asymptotically things should only depend on $y - x$; for $x, y$ near $0$ it seems as though there is dependence on the fact that we started the sum from $0$ that I think we escape from for large $x, y$. Update : I have a heuristic argument that gives the asymptotic probability of $x$ and $y$ being split as $1 - (1 - |x - y|)^2_+$ where $(a)_+$ denotes $\max\{0, a\}$. The argument is as follows: it should not matter asymptotically where $x$ and $y$ lie, so we can assume $x= k$ for some positive integer $k$. $x$ and $y$ will be split if, for the first value of $S_i$ in the interval $[x, x + 1]$, we have $x \le S_i \le y$. Consider the Markov chain $T_j$ consisting of the fractional parts of those $S_i$ such that $(S_{i - 1}) > (S_i)$, where $(a)$ denotes the fractional part of $a$. The probability that $x$ and $y$ are split should be $P(T \le (y - x))$ where $T$ is drawn from the stationary distribution of the $T_j$. I took a blind guess that the stationary distribution was given by the density $f(t) = 2(1 - t)$, drew a bunch of samples from the Markov chain I described, and verified empirically that $f(t) = 2 (1 - t)$ is the answer I'm supposed to get. If anyone wants to take a stab at verifying that $1 - (1 - |x - y|)_+^2$ is indeed the correct answer asymptotically, it would be much appreciated.",,"['probability', 'stochastic-processes']"
22,Is it possible to find a lower bound of this integral $\displaystyle\int^A_0 (A-x)p(x)\ dx$?,Is it possible to find a lower bound of this integral ?,\displaystyle\int^A_0 (A-x)p(x)\ dx,"Is it possible to find a lower bound of this integral? $\displaystyle\int^A_0 (A-x)p(x)\ dx$. Here $p(x)$ is some probability distribution with known mean and standard deviation and $A$ is a constant. I was trying to simplify this as $A\displaystyle\int^A_0 p(x)\ dx - \displaystyle\int^A_0 xp(x)\ dx $. The lower bound on the first integral can be found using Markov's inequality but how to find the upper bound of the second integral? Also, will this bound be tight?","Is it possible to find a lower bound of this integral? $\displaystyle\int^A_0 (A-x)p(x)\ dx$. Here $p(x)$ is some probability distribution with known mean and standard deviation and $A$ is a constant. I was trying to simplify this as $A\displaystyle\int^A_0 p(x)\ dx - \displaystyle\int^A_0 xp(x)\ dx $. The lower bound on the first integral can be found using Markov's inequality but how to find the upper bound of the second integral? Also, will this bound be tight?",,['probability']
23,Trying to understand the basics of bayesian inference,Trying to understand the basics of bayesian inference,,"This paper gives a somewhat gentle introduction to Bayesian inference: http://www.miketipping.com/papers/met-mlbayes.pdf I got to section 2.3 without much problems but got stuck in understanding that section onwards. It starts by presenting a probabilistic regression framework where the likelihood of all data is given as: $$ p(t|x,w,\sigma^2) = \prod_{n}p\left(t_n|x_n,w,\sigma^2\right) $$ where $t_n=y(x_n;w)+\epsilon_n$ is the 'target' value. Next, given a set of parameters $w$ and a hyperparameter $\alpha$, the prior is given as: $$ p(w|\alpha)=\prod_{m}\left(\frac{\alpha}{2\pi}\right)^{1/2}\exp\left({-\frac{\alpha}{2}w_m^2}\right) $$ I can then compute the posterior $p\left(w|t,\alpha,\sigma^2\right)$. What I don't understand is the following: In the first equation above, how should I interpret the product over the $N$ pairs of data $(t_n,x_n)$? Lets say I get two initial measurements from the real world, is $p\left(t|x,w,\sigma^2\right)$ supposed to give me a single real-valued probability? And how do I account for $w$ since it is not known yet? As far as I got it, $w$ is supposed to be a vector of size $M$ where $w_i$ contains the $i$th estimated value. Now, how can a prior for $w$ have a reference to its own vector elements if I don't know them yet? Shouldn't a prior be an independent distribution such as a Gaussian or Beta? Also, shouldn't a prior be independent of hyperparameters? Figure 4, on the article's page 8 has a plot from the prior and from the posteriors of an example using the $y=\sin(x)$ function with added Gaussian variance 0.2. How could I plot something similar in, say, Octave/Matlab or R? I don't have a strong background in statistics so forgive me if this is too basic. Any help is appreciated. Thanks in advance!","This paper gives a somewhat gentle introduction to Bayesian inference: http://www.miketipping.com/papers/met-mlbayes.pdf I got to section 2.3 without much problems but got stuck in understanding that section onwards. It starts by presenting a probabilistic regression framework where the likelihood of all data is given as: $$ p(t|x,w,\sigma^2) = \prod_{n}p\left(t_n|x_n,w,\sigma^2\right) $$ where $t_n=y(x_n;w)+\epsilon_n$ is the 'target' value. Next, given a set of parameters $w$ and a hyperparameter $\alpha$, the prior is given as: $$ p(w|\alpha)=\prod_{m}\left(\frac{\alpha}{2\pi}\right)^{1/2}\exp\left({-\frac{\alpha}{2}w_m^2}\right) $$ I can then compute the posterior $p\left(w|t,\alpha,\sigma^2\right)$. What I don't understand is the following: In the first equation above, how should I interpret the product over the $N$ pairs of data $(t_n,x_n)$? Lets say I get two initial measurements from the real world, is $p\left(t|x,w,\sigma^2\right)$ supposed to give me a single real-valued probability? And how do I account for $w$ since it is not known yet? As far as I got it, $w$ is supposed to be a vector of size $M$ where $w_i$ contains the $i$th estimated value. Now, how can a prior for $w$ have a reference to its own vector elements if I don't know them yet? Shouldn't a prior be an independent distribution such as a Gaussian or Beta? Also, shouldn't a prior be independent of hyperparameters? Figure 4, on the article's page 8 has a plot from the prior and from the posteriors of an example using the $y=\sin(x)$ function with added Gaussian variance 0.2. How could I plot something similar in, say, Octave/Matlab or R? I don't have a strong background in statistics so forgive me if this is too basic. Any help is appreciated. Thanks in advance!",,"['probability', 'bayesian', 'statistical-inference']"
24,Probability of at least one male and one female sharing the same birthday,Probability of at least one male and one female sharing the same birthday,,"There are $30$ students in a class. The lecturer has noted the birthday (month and day) of each student in the class. Assume that all the students in the class have birthdays that are independent, that there are $365$ days in a year, and that any day is equally likely to be the birthday of a particular student. What is the probability that at least one male and one female student shared the same birthday if: (i) There are $15$ male students and $15$ female students. (ii) There are $10$ male students and $20$ female students. (Note: Shared birthdays between, say, two male students do not count) For (i), since the number of male and female students are equal, we can form $15$ pairs, each consists of $1$ male and $1$ female student. Therefore the number of distinct birthday for a pair is $365^2$ and the required probability is: $P = 1-\frac{{{{365}^2} \times ({{365}^2} - 1) \times ... \times ({{365}^2} - 14)}}{{{{365}^2}}}$ As for part (ii), I haven't figured out how to do it. Any help is appreciated, thanks!","There are $30$ students in a class. The lecturer has noted the birthday (month and day) of each student in the class. Assume that all the students in the class have birthdays that are independent, that there are $365$ days in a year, and that any day is equally likely to be the birthday of a particular student. What is the probability that at least one male and one female student shared the same birthday if: (i) There are $15$ male students and $15$ female students. (ii) There are $10$ male students and $20$ female students. (Note: Shared birthdays between, say, two male students do not count) For (i), since the number of male and female students are equal, we can form $15$ pairs, each consists of $1$ male and $1$ female student. Therefore the number of distinct birthday for a pair is $365^2$ and the required probability is: $P = 1-\frac{{{{365}^2} \times ({{365}^2} - 1) \times ... \times ({{365}^2} - 14)}}{{{{365}^2}}}$ As for part (ii), I haven't figured out how to do it. Any help is appreciated, thanks!",,"['probability', 'birthday']"
25,"How many distinct n-letter ""words"" can be formed from a set of k letters where some of the letters are repeated?","How many distinct n-letter ""words"" can be formed from a set of k letters where some of the letters are repeated?",,"How many distinct n-letter ""words"" can be formed from a set of k letters where some of the letters are repeated? Examples: __ How many 6-letter words can be formed from the letters: ABBCCC? This is elementary. There are 6! arrangements counting repeats. Then we just divide by 2!3! to account for the repeats caused by the 2!3! identical arrangements of the Bs and Cs How many 5-letter words can be formed from the letters: ABBCCC? Excluding A we have $\frac{5!}{2!3!}$ Excluding either B $\frac{5!}{3!}$ Excluding any of the Cs $\frac{5!}{2!2!}$ Then take the sum. How many 4-letter words can be formed from the letters: ABBCCC? At this point I find it difficult to procede without far too many cases. Is there a general approach?","How many distinct n-letter ""words"" can be formed from a set of k letters where some of the letters are repeated? Examples: __ How many 6-letter words can be formed from the letters: ABBCCC? This is elementary. There are 6! arrangements counting repeats. Then we just divide by 2!3! to account for the repeats caused by the 2!3! identical arrangements of the Bs and Cs How many 5-letter words can be formed from the letters: ABBCCC? Excluding A we have $\frac{5!}{2!3!}$ Excluding either B $\frac{5!}{3!}$ Excluding any of the Cs $\frac{5!}{2!2!}$ Then take the sum. How many 4-letter words can be formed from the letters: ABBCCC? At this point I find it difficult to procede without far too many cases. Is there a general approach?",,"['probability', 'combinatorics']"
26,Throwing balls into $b$ buckets: when does some bucket overflow size $s$?,Throwing balls into  buckets: when does some bucket overflow size ?,b s,"Suppose you throw balls one-by-one into $b$ buckets, uniformly at random. At what time does the size of some (any) bucket exceed size $s$? That is, consider the following random process. At each of times $t=1, 2, 3, \dots$, Pick up a ball (from some infinite supply of balls that you have). Assign it to one of $b$ buckets, uniformly at random, and independent of choices made for previous balls. For this random process, let $T = T(s,b)$ be the time such that At time $T-1$ (after the $T-1$th ball was assigned), for each bucket, the number of balls assigned to it was $\le s$. At time $T$ (after the $T$th ball was assigned), there is some bucket for which the number of balls assigned to it is $s + 1$. What can we say about $T$? If we can get the distribution of $T(s,b)$ that would be great, else even knowing its expected value and variance, or even just expected value, would be good. Beyond the obvious fact that $T \le bs+1$ (and therefore $E[T]$ exists), I don't see anything very helpful. The motivation comes from a real-life computer application involving hashing (the numbers of interest are something like $b = 10000$ and $s = 64$).","Suppose you throw balls one-by-one into $b$ buckets, uniformly at random. At what time does the size of some (any) bucket exceed size $s$? That is, consider the following random process. At each of times $t=1, 2, 3, \dots$, Pick up a ball (from some infinite supply of balls that you have). Assign it to one of $b$ buckets, uniformly at random, and independent of choices made for previous balls. For this random process, let $T = T(s,b)$ be the time such that At time $T-1$ (after the $T-1$th ball was assigned), for each bucket, the number of balls assigned to it was $\le s$. At time $T$ (after the $T$th ball was assigned), there is some bucket for which the number of balls assigned to it is $s + 1$. What can we say about $T$? If we can get the distribution of $T(s,b)$ that would be great, else even knowing its expected value and variance, or even just expected value, would be good. Beyond the obvious fact that $T \le bs+1$ (and therefore $E[T]$ exists), I don't see anything very helpful. The motivation comes from a real-life computer application involving hashing (the numbers of interest are something like $b = 10000$ and $s = 64$).",,"['probability', 'combinatorics', 'stochastic-processes', 'discrete-mathematics', 'computer-science']"
27,Expected value of number of edges of a connected graph,Expected value of number of edges of a connected graph,,"There are n vertices. 2 vertices are chosen such that there is no edge between them and add an edge between them. We choose each pair with equal probability. Once we a have a completely connected graph we stop adding edges. Let X be the number of edges before we obtain a connected graph. What is the expected value of X? For example, when number of vertices are 4 case 1:>  3 edges form a triangle, and we need a 4th edge to make the graph completely connected. case 2:> all the 4 nodes are connected by 3 edges. The probability of the case 1 is 4/20 (number of triple of edges that make a triangle divided by number of ways we can choose 3 different edges), and the probability of case 2 is 16/20. So the expected value would be 4/20*4 + 16/20*3 = 3.2 I looked through http://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model to get the answer. However, I did not get a clue. I also looked through http://www.cs.berkeley.edu/~jfc/cs174/lecs/lec9/lec9.pdf there it was shown that expected value is (n-1)*((n-1)st Harmonic number). Using that for n=4 we get 3 * 1.83 = 5.5 But, the answer I am looking for is 3.2. Now, is there a mathematical formula to get the answer directly? Please show me the way. I am a noob in math. Edit1: The number of edges we need to consider is (n-1) to (n-1)(n-2)/2. The minimum number of edges in a connected graph is (n-1). The maximum for this question is (n-1)(n-2)/2 + 1. This is because (n-1) edges can be connected by maximum (n-1)(n-2)/2 edges, and 1 edge to connect to the lonely vertex.","There are n vertices. 2 vertices are chosen such that there is no edge between them and add an edge between them. We choose each pair with equal probability. Once we a have a completely connected graph we stop adding edges. Let X be the number of edges before we obtain a connected graph. What is the expected value of X? For example, when number of vertices are 4 case 1:>  3 edges form a triangle, and we need a 4th edge to make the graph completely connected. case 2:> all the 4 nodes are connected by 3 edges. The probability of the case 1 is 4/20 (number of triple of edges that make a triangle divided by number of ways we can choose 3 different edges), and the probability of case 2 is 16/20. So the expected value would be 4/20*4 + 16/20*3 = 3.2 I looked through http://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model to get the answer. However, I did not get a clue. I also looked through http://www.cs.berkeley.edu/~jfc/cs174/lecs/lec9/lec9.pdf there it was shown that expected value is (n-1)*((n-1)st Harmonic number). Using that for n=4 we get 3 * 1.83 = 5.5 But, the answer I am looking for is 3.2. Now, is there a mathematical formula to get the answer directly? Please show me the way. I am a noob in math. Edit1: The number of edges we need to consider is (n-1) to (n-1)(n-2)/2. The minimum number of edges in a connected graph is (n-1). The maximum for this question is (n-1)(n-2)/2 + 1. This is because (n-1) edges can be connected by maximum (n-1)(n-2)/2 edges, and 1 edge to connect to the lonely vertex.",,"['probability', 'combinatorics', 'graph-theory']"
28,Probability and genetics - Bayes' theorem,Probability and genetics - Bayes' theorem,,"Britney can be homozygous $HH$ or heterozygous $Hh$ with equal probability. Hemophilia is a mostly inherited genetic disorder. A test to detect a dominant allele $h$ , responsible for the disorder, is carried out. The test has $85\%$ reliability in heterozygous women (with $Hh$ genotype), that is, it successfully detects the presence of the allele $h$ in $85\%$ of the cases, while in homozygous women (with $HH$ genotype) it fails to detect $h$ in $1\%$ of the cases. We want to calculate the following probabilities: $P (\text{Britney}\,Hh | \text{test was positive})$ and $P(\text{Britney}\,HH | \text{test was negative})$ I am not sure for the correct interpretation of the question, as I had to translate some terms I am not familiar with. With the little knowledge I have on statistics, I will make an attempt: Prior probability Britney is homozygous or heterozygous $P(ΗΗ)= P(Hh) = 0.5$ $$P(E|Hh)= \text{Probability of a Positive Test Result given Britney is Heterozygous} = 0.85\\ \text{So, we have}\\ P(E|HH)= \text{Probability of a Positive Test Result given Britney is Homozygous} = 0.15$$ We want $$P(HH|E) = \text{Probability of Britney being Heterozygous given the test yields a Positive Result}$$ We also want $$P(Hh|E^c) = \text{Probability of Britney being Homozygous given the test yields a Negative Result}$$ So for a) $$P(HH|E) = {P(E|HH) P(HH) \over P(E)} = {P(E|HH) P(HH) \over P(E|HH)P(HH) + P(E|{Hh}) P({Hh})}$$ and similarly for the second. Are these correct? EDIT: Can you tell me if this is correct? "" $P(E|HH)= \text{Probability of a Positive Test Result given Britney is Homozygous} = 0.15$ "" or is it "" $P(E|HH)= \text{Probability of a Negative Test Result given Britney is Heterozygous} = 0.15$ ""?","Britney can be homozygous or heterozygous with equal probability. Hemophilia is a mostly inherited genetic disorder. A test to detect a dominant allele , responsible for the disorder, is carried out. The test has reliability in heterozygous women (with genotype), that is, it successfully detects the presence of the allele in of the cases, while in homozygous women (with genotype) it fails to detect in of the cases. We want to calculate the following probabilities: and I am not sure for the correct interpretation of the question, as I had to translate some terms I am not familiar with. With the little knowledge I have on statistics, I will make an attempt: Prior probability Britney is homozygous or heterozygous We want We also want So for a) and similarly for the second. Are these correct? EDIT: Can you tell me if this is correct? "" "" or is it "" ""?","HH Hh h 85\% Hh h 85\% HH h 1\% P (\text{Britney}\,Hh | \text{test was positive}) P(\text{Britney}\,HH | \text{test was negative}) P(ΗΗ)= P(Hh) = 0.5 P(E|Hh)= \text{Probability of a Positive Test Result given Britney is Heterozygous} = 0.85\\
\text{So, we have}\\
P(E|HH)= \text{Probability of a Positive Test Result given Britney is Homozygous} = 0.15 P(HH|E) = \text{Probability of Britney being Heterozygous given the test yields a Positive Result} P(Hh|E^c) = \text{Probability of Britney being Homozygous given the test yields a Negative Result} P(HH|E) = {P(E|HH) P(HH) \over P(E)} = {P(E|HH) P(HH) \over P(E|HH)P(HH) + P(E|{Hh}) P({Hh})} P(E|HH)= \text{Probability of a Positive Test Result given Britney is Homozygous} = 0.15 P(E|HH)= \text{Probability of a Negative Test Result given Britney is Heterozygous} = 0.15","['probability', 'statistics']"
29,Expectation of a betting game involving generalized Catalan numbers,Expectation of a betting game involving generalized Catalan numbers,,"I've recently become interested in a type of biased random walk. In the original context, the simplest problem I cannot answer is as follows: Suppose you enter a simple but lousy betting game. The price to enter is \$3, and a fair coin is flipped. If it lands heads you win \$4, otherwise you win nothing. So, each game either increases your wealth by \$1 or decreases it by \$3. If you begin with just \$3 and repeatedly enter the game until you can no longer pay the fee, what is the expected number of games you will play? Actually, I'd like to be able to answer this question for any game where the cost is $m$ , the prize is $m+1$ , and we have any given amount of starting wealth $w$ . This similar question+answer shows that the expectation diverges when $m=1$ for any starting wealth. Another way to phrase the question would be as a random walk. If you consider our position on the number line to be our total wealth after paying the fee, the case $m=w=1$ is a random walk from the origin that ends whenever the position becomes negative. The general case $m$ is a sort of random walk, but really it's more of a ""stumble"", since we either advance one step or reverse $m$ steps. I am interested in the expected length of these $m$ -stumbles. Here is what I know so far: The expected number of games, $g_{m,w}$ , satisfies an easy recurrence relating your starting wealth: $$ g_{m,w}  = 1 + \frac{1}{2}g_{m,w+1} + \frac{1}{2}g_{m,w-m}$$ Which I find has generating function: $$\sum_{w \ge 0} g_{m,w}z^n = \left(\alpha_m - \frac{2z}{1-z}\right)\left(\frac{1}{1 - 2z + z^{m+1}}\right)z^{m}$$ where $\alpha_m = g_{m,m}$ represents the average length of an $m$ -stumble from the origin. The $g$ terms are related to the Fibonacci n-step numbers by $A_{w}\alpha_m - 2B_{w}$ where A is a partial sum of the first $w$ n-step numbers $\sum_{k \le w}F_{k}^{(n)}$ , and B is a double convolution, i.e. the sum of the first $w-1$ partial sums $\sum\sum_{k < w}F^{(n)}_{k}$ . The easiest way to find $g_{m,w}$ given some $g_{m,s}$ that I know of is to use the recurrence directly. I have found the following double sum formula for general $\alpha_m$ : $$\alpha_m = \sum_{n = 0}^{\infty} \sum_{k=1}^{m} k\binom{mn + n + k}{n} / 2^{mn + n + k}$$ which more-or-less follows from the definition of the Fuss-Catalan numbers. Each term represents the contribution to the expectation of games ending at flip number $(m+1)n+k$ . The inner sum does not include the term $k=0$ because it is not possible to lose after flip numbers divisible by $m+1$ . (After flip $n$ your total wealth must be congruent to $n+m \mod{(m+1)}$ , since it increases by exactly $1$ or $-m \equiv +1 \mod{(m+1)}$ each flip, and it begins at $w = m \equiv -1 \mod{(m+1)}$ , so if you haven't already lost your wealth must be at least $m$ meaning you are guaranteed to have enough to pay the fee for these games.) I don't know how to evaluate this sum, but I do know at least one value and have good guesses for others. We know from the linked question $\alpha_1 = \infty$ , but for $m > 1$ , $\alpha_m$ converges. The one value I know is: $$\alpha_2 = \sum_{n=0}^{\infty} \binom{3n+1}{n}/2^{3n+1} + 2\sum_{n=0}^{\infty}\binom{3n+2}{n}/2^{3n+2} = 1 + \sqrt{5}$$ Which is the value Mathematica gives me. I don't how how it arrives at this value, but it appears correct and matches my simulations. Unfortunately, Mathematica chokes on $\alpha_3$ and higher. I guessed that $\alpha_m$ is the root of an $m$ 'th order polynomial, so $\alpha_2 = 1 + \sqrt{5} = (x^2 - 2x - 4)_{+}$ , meaning $\alpha_2$ is the unique positive real root of $x^2 - 2x - 4 = 0$ . A value for $\alpha_3$ would answer the initial problem statement in this question. I find the following guesses match the value of my sum with very high accuracy, to at least 100 digits: $$ \begin{align} \alpha_3 &= (x^3 - 4x - 4)_{+} \\ \alpha_4 &= (3x^4 + 4x^3 - 8x^2 - 24x - 16)_{+} \\ \alpha_5 &= (2x^5 + 5x^4 - 20x^2 - 32x - 16)_{+} \end{align} $$ but even knowing these values I have no idea how to prove them, even for the apparently simple cases of $\alpha_2$ and $\alpha_3$ . Does anyone know how to find $\alpha_3$ or general $\alpha_m$ ?","I've recently become interested in a type of biased random walk. In the original context, the simplest problem I cannot answer is as follows: Suppose you enter a simple but lousy betting game. The price to enter is \$3, and a fair coin is flipped. If it lands heads you win \$4, otherwise you win nothing. So, each game either increases your wealth by \$1 or decreases it by \$3. If you begin with just \$3 and repeatedly enter the game until you can no longer pay the fee, what is the expected number of games you will play? Actually, I'd like to be able to answer this question for any game where the cost is , the prize is , and we have any given amount of starting wealth . This similar question+answer shows that the expectation diverges when for any starting wealth. Another way to phrase the question would be as a random walk. If you consider our position on the number line to be our total wealth after paying the fee, the case is a random walk from the origin that ends whenever the position becomes negative. The general case is a sort of random walk, but really it's more of a ""stumble"", since we either advance one step or reverse steps. I am interested in the expected length of these -stumbles. Here is what I know so far: The expected number of games, , satisfies an easy recurrence relating your starting wealth: Which I find has generating function: where represents the average length of an -stumble from the origin. The terms are related to the Fibonacci n-step numbers by where A is a partial sum of the first n-step numbers , and B is a double convolution, i.e. the sum of the first partial sums . The easiest way to find given some that I know of is to use the recurrence directly. I have found the following double sum formula for general : which more-or-less follows from the definition of the Fuss-Catalan numbers. Each term represents the contribution to the expectation of games ending at flip number . The inner sum does not include the term because it is not possible to lose after flip numbers divisible by . (After flip your total wealth must be congruent to , since it increases by exactly or each flip, and it begins at , so if you haven't already lost your wealth must be at least meaning you are guaranteed to have enough to pay the fee for these games.) I don't know how to evaluate this sum, but I do know at least one value and have good guesses for others. We know from the linked question , but for , converges. The one value I know is: Which is the value Mathematica gives me. I don't how how it arrives at this value, but it appears correct and matches my simulations. Unfortunately, Mathematica chokes on and higher. I guessed that is the root of an 'th order polynomial, so , meaning is the unique positive real root of . A value for would answer the initial problem statement in this question. I find the following guesses match the value of my sum with very high accuracy, to at least 100 digits: but even knowing these values I have no idea how to prove them, even for the apparently simple cases of and . Does anyone know how to find or general ?","m m+1 w m=1 m=w=1 m m m g_{m,w}  g_{m,w}  = 1 + \frac{1}{2}g_{m,w+1} + \frac{1}{2}g_{m,w-m} \sum_{w \ge 0} g_{m,w}z^n = \left(\alpha_m - \frac{2z}{1-z}\right)\left(\frac{1}{1 - 2z + z^{m+1}}\right)z^{m} \alpha_m = g_{m,m} m g A_{w}\alpha_m - 2B_{w} w \sum_{k \le w}F_{k}^{(n)} w-1 \sum\sum_{k < w}F^{(n)}_{k} g_{m,w} g_{m,s} \alpha_m \alpha_m = \sum_{n = 0}^{\infty} \sum_{k=1}^{m} k\binom{mn + n + k}{n} / 2^{mn + n + k} (m+1)n+k k=0 m+1 n n+m \mod{(m+1)} 1 -m \equiv +1 \mod{(m+1)} w = m \equiv -1 \mod{(m+1)} m \alpha_1 = \infty m > 1 \alpha_m \alpha_2 = \sum_{n=0}^{\infty} \binom{3n+1}{n}/2^{3n+1} + 2\sum_{n=0}^{\infty}\binom{3n+2}{n}/2^{3n+2} = 1 + \sqrt{5} \alpha_3 \alpha_m m \alpha_2 = 1 + \sqrt{5} = (x^2 - 2x - 4)_{+} \alpha_2 x^2 - 2x - 4 = 0 \alpha_3 
\begin{align}
\alpha_3 &= (x^3 - 4x - 4)_{+} \\
\alpha_4 &= (3x^4 + 4x^3 - 8x^2 - 24x - 16)_{+} \\
\alpha_5 &= (2x^5 + 5x^4 - 20x^2 - 32x - 16)_{+}
\end{align}
 \alpha_2 \alpha_3 \alpha_3 \alpha_m","['probability', 'discrete-mathematics', 'summation', 'binomial-coefficients', 'catalan-numbers']"
30,Betting game with numbers,Betting game with numbers,,"Someone is challenged to play the following game: there are 36 marbles in an urn. 21 of them are red, 9 are blue and 6 are green. Each red is worth 0 rupees, each blue 100 rupees and each green 1000 rupees. By betting 1000 rupees only once, you must pick as many marbles as you want (obviously without seeing its color), one by one (you draw each marble, look at its color and either stop or continue) and without replacement and you can stop at any time, and you earn the product of the values of the marbles you have picked so far. Assuming that the player plays optimally, what is the average percentage of the average percentage of profit for the game? My understanding is that we must calculate the probability (not) to draw a 0 in a series of consecutive draws from 1 to 36. For the 1st draw, the probability to get a 0 is $P_1 = \frac {21}{36}$ and the game ends, so with probability $P'_1 = \frac {15}{36}$ the player continues (""optimal"" playing refers to this, otherwise if he continues, he will get 0 anyway). Up to now, the player has earned 100 rupees with probability $Pw'_1 = \frac {15*9}{36*15}$ and 1000 rupees with probability $Pww'_1 = \frac {15*6}{36*15}$ . For the 2nd draw, the probability not to get a 0 is $P'_2 = \frac {14}{35}$ and so on. The player will earn again the product of either 100 or 1000 of the first earning, with probability equal to the product of $P'_2$ by $\frac {8}{14}$ or $\frac {5}{14}$ . Can you please help me continue? It is getting really confusing from this point forward! Thank you very much!","Someone is challenged to play the following game: there are 36 marbles in an urn. 21 of them are red, 9 are blue and 6 are green. Each red is worth 0 rupees, each blue 100 rupees and each green 1000 rupees. By betting 1000 rupees only once, you must pick as many marbles as you want (obviously without seeing its color), one by one (you draw each marble, look at its color and either stop or continue) and without replacement and you can stop at any time, and you earn the product of the values of the marbles you have picked so far. Assuming that the player plays optimally, what is the average percentage of the average percentage of profit for the game? My understanding is that we must calculate the probability (not) to draw a 0 in a series of consecutive draws from 1 to 36. For the 1st draw, the probability to get a 0 is and the game ends, so with probability the player continues (""optimal"" playing refers to this, otherwise if he continues, he will get 0 anyway). Up to now, the player has earned 100 rupees with probability and 1000 rupees with probability . For the 2nd draw, the probability not to get a 0 is and so on. The player will earn again the product of either 100 or 1000 of the first earning, with probability equal to the product of by or . Can you please help me continue? It is getting really confusing from this point forward! Thank you very much!",P_1 = \frac {21}{36} P'_1 = \frac {15}{36} Pw'_1 = \frac {15*9}{36*15} Pww'_1 = \frac {15*6}{36*15} P'_2 = \frac {14}{35} P'_2 \frac {8}{14} \frac {5}{14},"['probability', 'gambling']"
31,Dudley's integral inequality: tail bound,Dudley's integral inequality: tail bound,,"This is problem 8.1.7 in Vershynin's High Dimensional Probability book. Let $(X_t)_{t\in T}$ be a random process indexed by a metric space $(T,d)$ with sub-gaussian increments(i.e. $||X_t-X_s||_{\psi_2} \leq Kd(s,t)$ for all $s,t\in T$ ). Then for every $u\geq 0$ , the event $$ \sup_{t,s\in T} |X_t-X_s| \leq CK \left( \int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) \right)$$ with probability $1-2\exp(u^2)$ where $C$ is just some absolute constant. If we assume $T$ is second countable then we may prove it just for the case when $T$ is finite by applying dominated convergence theorem and apply a limit argument. Furthermore, the tail bound is trivially true when $T$ is unbounded so assume $\text{diam}(T)<\infty$ . With these assumptions, lets move on to the issues I'm having proving the result. To prove this result we are given the following hints. Define $\epsilon_k=2^{-k}$ and $T_k$ is an $\epsilon_k$ covering of with cardinality $|T_k|=\mathcal{N}(T,d,\epsilon_k)$ . Then if $t\in T$ we define $\pi_k(t)\in T_k$ to be the closest element in $T_k$ to $t_0$ for some fixed element $t_0$ . In particular we can show that $$\sup_{t\in T} (X_{\pi_k(t)}-X_{\pi_{k-1}(t)}) \leq CK\epsilon_{k-1}(\sqrt{\log|T_k|}+z)$$ with probability at least $1-2\exp(-z^2)$ . So proving this was fairly straight forward. The next hint was to prove a bound for $$ \sup_{t\in T} |X_t-X_{t_0}| \leq CK \left( \int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) \right)$$ using the previous result. We note that we can write $$\int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) = \int_0^{\text{diam}(T)}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon)} + u \right) d\epsilon$$ Since $T$ is finite there exists a $\kappa_0, K_0 \in \mathbb{Z}$ such that $T_{\kappa_0} = \{t_0\}$ and $T_{K_0} = T$ . So we can write $$\int_0^{\text{diam}(T)}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon)} + u \right) d\epsilon \sim \sum_{k\geq{\kappa_0+1}} \epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + u \right) $$ Next we form the chain and note that $\pi_{k_0}(t) = t_0$ and $\pi_{K_0}(t)=t$ so we have $$\sup_{t\in T}|X_t-X_{t_0}|\leq \sum_{k=\kappa_0+1}^{K_0} \sup_{t\in T}|X_{\pi_k(t)}-X_{\pi_{k-1}(t)}|$$ If we let $$\sup_{t\in T}|X_t-X_{t_0}|\geq CK\sum_{k=\kappa_0+1}^{K_0}\epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + z_k \right)$$ be our event $E$ then from a union bound we have $$P(E) \leq 2\sum_{k=\kappa_0+1}^{K_0}\exp(-z_k^2)$$ Vershynin then suggests we choose $z_k=u+\sqrt{k-\kappa_0}$ . If we plug this into our sum we get $$2\sum_{k=\kappa_0+1}^{K_0}\exp(-z_k^2) \leq \exp(-u^2)$$ So, in particular, we have that by another union bound that $$ \sup_{s,t\in T}|X_s-X_{t}|\geq 2CK\sum_{k=\kappa_0+1}^{K_0}\epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + u + \sqrt{k-\kappa_0} \right)$$ Has probability less than $2\exp(-u^2)$ Which is almost a larger event than the original one were proving. My only issue is how to absorb the additional term $\sum_{k=\kappa_0+1}^{K_0} \epsilon_{k-1} \sqrt{k-\kappa_0}$ . If I can deal with that I have what I wanted to prove because $$  2CK\int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) \geq C' 2CK\sum_{k=\kappa_0+1}^{K_0}\epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + u \right)$$","This is problem 8.1.7 in Vershynin's High Dimensional Probability book. Let be a random process indexed by a metric space with sub-gaussian increments(i.e. for all ). Then for every , the event with probability where is just some absolute constant. If we assume is second countable then we may prove it just for the case when is finite by applying dominated convergence theorem and apply a limit argument. Furthermore, the tail bound is trivially true when is unbounded so assume . With these assumptions, lets move on to the issues I'm having proving the result. To prove this result we are given the following hints. Define and is an covering of with cardinality . Then if we define to be the closest element in to for some fixed element . In particular we can show that with probability at least . So proving this was fairly straight forward. The next hint was to prove a bound for using the previous result. We note that we can write Since is finite there exists a such that and . So we can write Next we form the chain and note that and so we have If we let be our event then from a union bound we have Vershynin then suggests we choose . If we plug this into our sum we get So, in particular, we have that by another union bound that Has probability less than Which is almost a larger event than the original one were proving. My only issue is how to absorb the additional term . If I can deal with that I have what I wanted to prove because","(X_t)_{t\in T} (T,d) ||X_t-X_s||_{\psi_2} \leq Kd(s,t) s,t\in T u\geq 0  \sup_{t,s\in T} |X_t-X_s| \leq CK \left( \int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) \right) 1-2\exp(u^2) C T T T \text{diam}(T)<\infty \epsilon_k=2^{-k} T_k \epsilon_k |T_k|=\mathcal{N}(T,d,\epsilon_k) t\in T \pi_k(t)\in T_k T_k t_0 t_0 \sup_{t\in T} (X_{\pi_k(t)}-X_{\pi_{k-1}(t)}) \leq CK\epsilon_{k-1}(\sqrt{\log|T_k|}+z) 1-2\exp(-z^2)  \sup_{t\in T} |X_t-X_{t_0}| \leq CK \left( \int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) \right) \int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) = \int_0^{\text{diam}(T)}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon)} + u \right) d\epsilon T \kappa_0, K_0 \in \mathbb{Z} T_{\kappa_0} = \{t_0\} T_{K_0} = T \int_0^{\text{diam}(T)}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon)} + u \right) d\epsilon \sim \sum_{k\geq{\kappa_0+1}} \epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + u \right)  \pi_{k_0}(t) = t_0 \pi_{K_0}(t)=t \sup_{t\in T}|X_t-X_{t_0}|\leq \sum_{k=\kappa_0+1}^{K_0} \sup_{t\in T}|X_{\pi_k(t)}-X_{\pi_{k-1}(t)}| \sup_{t\in T}|X_t-X_{t_0}|\geq CK\sum_{k=\kappa_0+1}^{K_0}\epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + z_k \right) E P(E) \leq 2\sum_{k=\kappa_0+1}^{K_0}\exp(-z_k^2) z_k=u+\sqrt{k-\kappa_0} 2\sum_{k=\kappa_0+1}^{K_0}\exp(-z_k^2) \leq \exp(-u^2)  \sup_{s,t\in T}|X_s-X_{t}|\geq 2CK\sum_{k=\kappa_0+1}^{K_0}\epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + u + \sqrt{k-\kappa_0} \right) 2\exp(-u^2) \sum_{k=\kappa_0+1}^{K_0} \epsilon_{k-1} \sqrt{k-\kappa_0}   2CK\int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) \geq C' 2CK\sum_{k=\kappa_0+1}^{K_0}\epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + u \right)","['probability', 'probability-theory', 'statistics', 'inequality']"
32,Average queue length with impatient customers,Average queue length with impatient customers,,"Suppose customers join a queue with a poisson arrival rate $m$ . If a customer is not served within a unit of time, she abandons the queue. Customers are served in a first-come-first-served (FCFS) manner. There is a single server, and the service time for each customer is distributed exponentially with mean $\frac{1}{\lambda m}$ , where $\lambda<1$ . I would like to show that the average length of the queue is at least $m-o(m)$ . Any input will be appreciated! P.S. The claim is intuitive, but I have not been able to find a formal proof. I have also run simulations, which confirm that this holds.","Suppose customers join a queue with a poisson arrival rate . If a customer is not served within a unit of time, she abandons the queue. Customers are served in a first-come-first-served (FCFS) manner. There is a single server, and the service time for each customer is distributed exponentially with mean , where . I would like to show that the average length of the queue is at least . Any input will be appreciated! P.S. The claim is intuitive, but I have not been able to find a formal proof. I have also run simulations, which confirm that this holds.",m \frac{1}{\lambda m} \lambda<1 m-o(m),"['probability', 'probability-theory', 'stochastic-processes', 'poisson-process', 'queueing-theory']"
33,"Expected area ""sweeped"" on an infinite Minesweeper board","Expected area ""sweeped"" on an infinite Minesweeper board",,"Given an average density (x/y) of x mines in y squares, is it possible to calculate the expected number of squares you can ""sweep"" (i.e. identify whether there is a mine or not) on an infinitely sized minesweeper game, before you have to guess- i.e. no more squares can be deduced.","Given an average density (x/y) of x mines in y squares, is it possible to calculate the expected number of squares you can ""sweep"" (i.e. identify whether there is a mine or not) on an infinitely sized minesweeper game, before you have to guess- i.e. no more squares can be deduced.",,"['probability', 'recreational-mathematics']"
34,Intersection of random line segments in the plane,Intersection of random line segments in the plane,,"Let a point on the plane be randomly chosen via $(\sqrt{\frac{t}{1-t}}\cos(2\pi\theta),\sqrt{\frac{t}{1-t}}\sin(2\pi\theta))$, where $t$ and $\theta$ are uniformly randomly chosen on $[0,1]$ (equivalently, choose a point uniformly randomly on the surface of the sphere and then project stereographically). Then, what is the probability that two random line segments (determined by their endpoints) will intersect? This is a repost of a subproblem in a previous post that never got answered. Monte Carlo simulation suggests that the answer is precisely $1/5$, but I have no fruitful ideas left how to prove it.","Let a point on the plane be randomly chosen via $(\sqrt{\frac{t}{1-t}}\cos(2\pi\theta),\sqrt{\frac{t}{1-t}}\sin(2\pi\theta))$, where $t$ and $\theta$ are uniformly randomly chosen on $[0,1]$ (equivalently, choose a point uniformly randomly on the surface of the sphere and then project stereographically). Then, what is the probability that two random line segments (determined by their endpoints) will intersect? This is a repost of a subproblem in a previous post that never got answered. Monte Carlo simulation suggests that the answer is precisely $1/5$, but I have no fruitful ideas left how to prove it.",,"['probability', 'geometry', 'geometric-probability', 'stereographic-projections']"
35,Multi-Gaussian Integrals with Heaviside for cosmic connectivity,Multi-Gaussian Integrals with Heaviside for cosmic connectivity,,"Context I would like to  predict the connectivity of the so-called cosmic web in arbitrary dimensions. This is the cosmic web (in a hydrodynamical simulation) The little wiggly things are galaxies (as traced by the gas density) while the inset shows the corresponding light produced by the stars which were born from that gas. The connectivity $\kappa$ is defined as the number of ridges connecting a given maxima  to its surrounding saddles, which in turn therefore corresponds to $2 n_{\rm max}/ n_{\rm saddle}$ where $n_{\rm max}$ and $n_{\rm saddle}$ are  the total number of maxima and saddles in the field. This is how the cosmic web looks like in 3D on larger scales (using a filament tracer algorithm): so the motivation is to predict how many filaments are connected to a given node from first principes. Definitions As a starting point I am restricting myself to a Gaussian random field. For such fields  the connectivity $k^d$ is then simply \begin{equation} \kappa^{d}  =\frac{2n_{\rm saddle}}{n_{\rm max}}= \frac{2 \left\langle   \Theta_{\rm H}(-\{\lambda_{i}\}_{i<d})  \Theta_{\rm H}(\lambda_{d})   \left| \prod  \lambda_i \right| \right\rangle} {\left\langle   \Theta_{\rm H}(-\{\lambda_{i}]\}_{i\leq d})   \left| \prod  \lambda_i \right| \right\rangle}\,, \label{eq:defkapND} \end{equation} where the expectation is to be carried over Gaussian PDFs. Technically  I therefore need to evaluate in arbitrary dimensions integrals such as \begin{equation} \int \cdots \int \prod_{i\le { d}}  d \lambda_i \, G(\{\lambda_i\}) \prod_{i<j} (\lambda_j-\lambda_i)  \, \prod_{i\le d}\Theta_{\rm H}(-\lambda_i) \,,  \label{eq:defQprob} \end{equation} where $\Theta_{\rm H}$ is a Heaviside function and $G(\lambda_i)$ is a multi-Gaussian PDF with variance covariance given by \begin{equation} M_{i,j}= \frac{1}{d (d+2)} \quad {\rm for}\quad i\neq j\\ M_{i,i}= \frac{3}{d (d+2)} \end{equation} For instance for $d=7$ this matrix reads \begin{equation} \left( \begin{array}{cccccc}  \frac{1}{16} & \frac{1}{48} &    \frac{1}{48} & \frac{1}{48} &    \frac{1}{48} & \frac{1}{48} \\  \frac{1}{48} & \frac{1}{16} &    \frac{1}{48} & \frac{1}{48} &    \frac{1}{48} & \frac{1}{48} \\  \frac{1}{48} & \frac{1}{48} &    \frac{1}{16} & \frac{1}{48} &    \frac{1}{48} & \frac{1}{48} \\  \frac{1}{48} & \frac{1}{48} &    \frac{1}{48} & \frac{1}{16} &    \frac{1}{48} & \frac{1}{48} \\  \frac{1}{48} & \frac{1}{48} &    \frac{1}{48} & \frac{1}{48} &    \frac{1}{16} & \frac{1}{48} \\  \frac{1}{48} & \frac{1}{48} &    \frac{1}{48} & \frac{1}{48} &    \frac{1}{48} & \frac{1}{16} \\ \end{array} \right) \end{equation} Questions Is is possible to compute the ratio analytically for $d>3$ ? For instance \begin{equation}\kappa^2=4 \end{equation} for $d=2$ and \begin{equation} \kappa^3=2 \frac{18 \sqrt{2} + 29 \sqrt{3}}{     {-18 \sqrt{2} + 29 \sqrt{3}}} \approx 6.11  \end{equation} for $d=3$ .  It is strikingly close to a cubic face centred lattice, but with some level of impurity to the crystal. Can this ratio be computed numerically for $d>11$ ? So far I have $\kappa^d$ = $4$ , $6.11$ , $8.35$ , $10.73$ , $13.23$ , $15.85$ , $18.7$ , $21.4$ , $24.4$ , $27.4$ for $d=$ $2$ , $3$ , $4$ , $5$ , $6$ , $7$ , $8$ , $9$ , $10$ and $11$ resp. From inspection of $d\le 11$ we conjecture that it is closely approximated  by \begin{equation}  \kappa^d= 2d+\left(\frac{2d-4}{7}\right)^{7/4}.  \end{equation} which suggests that the $d$ cosmic web behaves like a crystal with growing impurity. can the large d asymptote be computed? FYI, this question is linked to that mathematica question and this paper . FYI2: this paper may be relevant to the asymptote ?","Context I would like to  predict the connectivity of the so-called cosmic web in arbitrary dimensions. This is the cosmic web (in a hydrodynamical simulation) The little wiggly things are galaxies (as traced by the gas density) while the inset shows the corresponding light produced by the stars which were born from that gas. The connectivity is defined as the number of ridges connecting a given maxima  to its surrounding saddles, which in turn therefore corresponds to where and are  the total number of maxima and saddles in the field. This is how the cosmic web looks like in 3D on larger scales (using a filament tracer algorithm): so the motivation is to predict how many filaments are connected to a given node from first principes. Definitions As a starting point I am restricting myself to a Gaussian random field. For such fields  the connectivity is then simply where the expectation is to be carried over Gaussian PDFs. Technically  I therefore need to evaluate in arbitrary dimensions integrals such as where is a Heaviside function and is a multi-Gaussian PDF with variance covariance given by For instance for this matrix reads Questions Is is possible to compute the ratio analytically for ? For instance for and for .  It is strikingly close to a cubic face centred lattice, but with some level of impurity to the crystal. Can this ratio be computed numerically for ? So far I have = , , , , , , , , , for , , , , , , , , and resp. From inspection of we conjecture that it is closely approximated  by which suggests that the cosmic web behaves like a crystal with growing impurity. can the large d asymptote be computed? FYI, this question is linked to that mathematica question and this paper . FYI2: this paper may be relevant to the asymptote ?","\kappa 2 n_{\rm max}/ n_{\rm saddle} n_{\rm max} n_{\rm saddle} k^d \begin{equation}
\kappa^{d}  =\frac{2n_{\rm saddle}}{n_{\rm max}}= \frac{2 \left\langle   \Theta_{\rm H}(-\{\lambda_{i}\}_{i<d})  \Theta_{\rm H}(\lambda_{d})   \left| \prod  \lambda_i \right| \right\rangle}
{\left\langle   \Theta_{\rm H}(-\{\lambda_{i}]\}_{i\leq d})   \left| \prod  \lambda_i \right| \right\rangle}\,,
\label{eq:defkapND}
\end{equation} \begin{equation} \int \cdots \int
\prod_{i\le { d}}  d \lambda_i \,
G(\{\lambda_i\}) \prod_{i<j} (\lambda_j-\lambda_i)  \, \prod_{i\le d}\Theta_{\rm H}(-\lambda_i)
\,,  \label{eq:defQprob}
\end{equation} \Theta_{\rm H} G(\lambda_i) \begin{equation}
M_{i,j}= \frac{1}{d (d+2)} \quad {\rm for}\quad i\neq j\\
M_{i,i}= \frac{3}{d (d+2)}
\end{equation} d=7 \begin{equation}
\left(
\begin{array}{cccccc}
 \frac{1}{16} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} \\
 \frac{1}{48} & \frac{1}{16} &
   \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} \\
 \frac{1}{48} & \frac{1}{48} &
   \frac{1}{16} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} \\
 \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{16} &
   \frac{1}{48} & \frac{1}{48} \\
 \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} &
   \frac{1}{16} & \frac{1}{48} \\
 \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{48} &
   \frac{1}{48} & \frac{1}{16} \\
\end{array}
\right)
\end{equation} d>3 \begin{equation}\kappa^2=4
\end{equation} d=2 \begin{equation}
\kappa^3=2 \frac{18 \sqrt{2} + 29 \sqrt{3}}{
    {-18 \sqrt{2} + 29 \sqrt{3}}} \approx 6.11 
\end{equation} d=3 d>11 \kappa^d 4 6.11 8.35 10.73 13.23 15.85 18.7 21.4 24.4 27.4 d= 2 3 4 5 6 7 8 9 10 11 d\le 11 \begin{equation}
 \kappa^d= 2d+\left(\frac{2d-4}{7}\right)^{7/4}.
 \end{equation} d","['probability', 'integration', 'numerical-methods', 'asymptotics', 'conditional-expectation']"
36,Intuitive explanation of Newton - Pepys problem,Intuitive explanation of Newton - Pepys problem,,"Quoting Wikipedia for description of problem: In 1693 Samuel Pepys and Isaac Newton corresponded over a problem posed by Pepys in relation to a wager he planned to make. The problem was: Which of the following three propositions has the greatest chance of success? Six fair dice are tossed independently and at least one “6” appears. Twelve fair dice are tossed independently and at least two “6”s appear. Eighteen fair dice are tossed independently and at least three “6”s appear. Pepys initially thought that outcome C had the highest probability, but Newton correctly concluded that outcome A actually has the highest probability. I know how A has highest probability mathematically. But it feels kind of unintuitive to me. Newton's explanation from Wikipedia Although Newton correctly calculated the odds of each bet, he provided a separate intuitive explanation to Pepys. He imagined that B and C toss their dice in groups of six, and said that A was most favorable because it required a 6 in only one toss, while B and C required a 6 in each of their tosses. This explanation assumes that a group does not produce more than one 6, so it does not actually correspond to the original problem So my question is what is the intuition behind the result?","Quoting Wikipedia for description of problem: In 1693 Samuel Pepys and Isaac Newton corresponded over a problem posed by Pepys in relation to a wager he planned to make. The problem was: Which of the following three propositions has the greatest chance of success? Six fair dice are tossed independently and at least one “6” appears. Twelve fair dice are tossed independently and at least two “6”s appear. Eighteen fair dice are tossed independently and at least three “6”s appear. Pepys initially thought that outcome C had the highest probability, but Newton correctly concluded that outcome A actually has the highest probability. I know how A has highest probability mathematically. But it feels kind of unintuitive to me. Newton's explanation from Wikipedia Although Newton correctly calculated the odds of each bet, he provided a separate intuitive explanation to Pepys. He imagined that B and C toss their dice in groups of six, and said that A was most favorable because it required a 6 in only one toss, while B and C required a 6 in each of their tosses. This explanation assumes that a group does not produce more than one 6, so it does not actually correspond to the original problem So my question is what is the intuition behind the result?",,"['probability', 'probability-distributions']"
37,Expected area of a random $n$-gon,Expected area of a random -gon,n,"Choose $n$ points $\{z_1, \ldots, z_n\}$ from the unit circle $\partial \mathbb{D} = \{z \in \mathbb{C}: |z| = 1\}$ uniformly at random, and let $P_n$ be the convex hull of the $z_i$'s. Let $X_n = area(P_n)$. What can be said about $X_n$? Can $\mathbb{E}X_n$ be computed? It's easy to see that $P_n$ converges to $\mathbb{D}$ pointwise almost surely, so $X_n \to \pi$ a.s. as $n \to \infty$. What is the rate of convergence? It is 'easy' to get a direct computation for $\mathbb{E}X_3$, by writing down a formula for the area of the triangle and integrating directly: for example, you can assume $z_1 = 1$, and that $z_2 = e^{i \theta}, z_3 = e^{i \phi}$ with $\theta < \phi$, and integrate directly. But this is a bit tedious, and especially so for large $n$! Is there an easier way to do this computation? One idea is to rely on order statistics: write $z_k = \exp(i \theta_k)$ for iid uniform variables $\theta_k \in [0,2\pi)$, and let $\{\phi_k\}_{k=1}^n$ be the ordered sequence of the $\theta_k$, i.e. $\phi_1 = \min\{\theta_1, \ldots, \theta_n\}$, $\phi_2 = $ 2nd largest element of $\{\theta_1, \ldots, \theta_n\}$, ... $\phi_n = \max\{\theta_1, \ldots, \theta_n\}$. The distributions of the $\phi$'s can be written down explicitly - though it's a bit messy - and $P_n$ can be divided into $n$ triangles, yielding $X_n = \frac{1}{2} \sum_{k=1}^n \sin(\phi_k - \phi_{k-1})$, with the convention $\phi_0 = \phi_n - 2\pi$. I haven't tried writing down this integral out of fear, but it may be do-able. ( I suspect there is a clever symmetry argument to avoid needing the order statistics. ) Heuristically, if the $z_n$ are 'well-distributed,' the angle distance between adjacent $z_i$'s is roughly $\frac{2\pi}{n}$, so the error between the areas of the disk and $P$ is roughly $n(\frac{\pi}{n} - \frac{1}{2} \sin(\frac{2\pi}{n})) = \frac{4\pi^3}{3} n^{-2} + O(n^{-4})$. Thus we should have $n^2(\pi - \mathbb{E}X_n) \to L \in (0,\infty)$ $\hspace{.5cm} (\star)$ Perhaps this argument can be formalized, and the constant $L$ can be determined. After that, the usual next step is to hope for something like $n^2(\pi - X_n) \to_d Z$ for some random variable $Z$, or a CLT like $\gamma_n (X_n - \mathbb{E}X_n) \to_d N(0,1)$ for some constants $\gamma_n$. Also: what if the $z_k$ are selected uniformly from the unit sphere in $d$-dimensions? I haven't thought much about this, but maybe a statement analogous to $\star$ can be proved. Edit 1: A quick google search revealed this site, which has some additional interesting calculations. In particular, it claims to compute $L$ via the method I suggested, which would answer $\star$.","Choose $n$ points $\{z_1, \ldots, z_n\}$ from the unit circle $\partial \mathbb{D} = \{z \in \mathbb{C}: |z| = 1\}$ uniformly at random, and let $P_n$ be the convex hull of the $z_i$'s. Let $X_n = area(P_n)$. What can be said about $X_n$? Can $\mathbb{E}X_n$ be computed? It's easy to see that $P_n$ converges to $\mathbb{D}$ pointwise almost surely, so $X_n \to \pi$ a.s. as $n \to \infty$. What is the rate of convergence? It is 'easy' to get a direct computation for $\mathbb{E}X_3$, by writing down a formula for the area of the triangle and integrating directly: for example, you can assume $z_1 = 1$, and that $z_2 = e^{i \theta}, z_3 = e^{i \phi}$ with $\theta < \phi$, and integrate directly. But this is a bit tedious, and especially so for large $n$! Is there an easier way to do this computation? One idea is to rely on order statistics: write $z_k = \exp(i \theta_k)$ for iid uniform variables $\theta_k \in [0,2\pi)$, and let $\{\phi_k\}_{k=1}^n$ be the ordered sequence of the $\theta_k$, i.e. $\phi_1 = \min\{\theta_1, \ldots, \theta_n\}$, $\phi_2 = $ 2nd largest element of $\{\theta_1, \ldots, \theta_n\}$, ... $\phi_n = \max\{\theta_1, \ldots, \theta_n\}$. The distributions of the $\phi$'s can be written down explicitly - though it's a bit messy - and $P_n$ can be divided into $n$ triangles, yielding $X_n = \frac{1}{2} \sum_{k=1}^n \sin(\phi_k - \phi_{k-1})$, with the convention $\phi_0 = \phi_n - 2\pi$. I haven't tried writing down this integral out of fear, but it may be do-able. ( I suspect there is a clever symmetry argument to avoid needing the order statistics. ) Heuristically, if the $z_n$ are 'well-distributed,' the angle distance between adjacent $z_i$'s is roughly $\frac{2\pi}{n}$, so the error between the areas of the disk and $P$ is roughly $n(\frac{\pi}{n} - \frac{1}{2} \sin(\frac{2\pi}{n})) = \frac{4\pi^3}{3} n^{-2} + O(n^{-4})$. Thus we should have $n^2(\pi - \mathbb{E}X_n) \to L \in (0,\infty)$ $\hspace{.5cm} (\star)$ Perhaps this argument can be formalized, and the constant $L$ can be determined. After that, the usual next step is to hope for something like $n^2(\pi - X_n) \to_d Z$ for some random variable $Z$, or a CLT like $\gamma_n (X_n - \mathbb{E}X_n) \to_d N(0,1)$ for some constants $\gamma_n$. Also: what if the $z_k$ are selected uniformly from the unit sphere in $d$-dimensions? I haven't thought much about this, but maybe a statement analogous to $\star$ can be proved. Edit 1: A quick google search revealed this site, which has some additional interesting calculations. In particular, it claims to compute $L$ via the method I suggested, which would answer $\star$.",,"['probability', 'random-variables', 'area', 'geometric-probability']"
38,Distribution of $i$th largest entry in multinomial sample,Distribution of th largest entry in multinomial sample,i,"I have a $k$-class multinomial distribution with vector of probabilities $(p_1, p_2, \ldots, p_k)$, from which I draw a size-$N$ sample $(c_1, c_2, \ldots, c_k), \sum\limits_{s=1}^k c_s = N$. Assume for simplicity that $c_j \geq 1$ for all $j$. Next, I sort the sample in descending order by count to obtain $(c_{(1)}, c_{(2)}, \ldots, c_{(k)})$ where $c_{(\ell)} \geq c_{(\ell+1)}$. Are there any research papers or other resources that describe the distribution over $c_{(i)}$, the $i$th largest count in a multinomial sample? For example, the distribution over $c_{(1)}$ is the distribution over the largest count and $c_{(k)}$ is the distribution over the smallest. Or, asked a different way, what is the distribution describing the probability that the $j$th class's count is the $i$th largest in the sample? I've been googling around for a while but haven't really found anything relevant.","I have a $k$-class multinomial distribution with vector of probabilities $(p_1, p_2, \ldots, p_k)$, from which I draw a size-$N$ sample $(c_1, c_2, \ldots, c_k), \sum\limits_{s=1}^k c_s = N$. Assume for simplicity that $c_j \geq 1$ for all $j$. Next, I sort the sample in descending order by count to obtain $(c_{(1)}, c_{(2)}, \ldots, c_{(k)})$ where $c_{(\ell)} \geq c_{(\ell+1)}$. Are there any research papers or other resources that describe the distribution over $c_{(i)}$, the $i$th largest count in a multinomial sample? For example, the distribution over $c_{(1)}$ is the distribution over the largest count and $c_{(k)}$ is the distribution over the smallest. Or, asked a different way, what is the distribution describing the probability that the $j$th class's count is the $i$th largest in the sample? I've been googling around for a while but haven't really found anything relevant.",,"['probability', 'probability-distributions']"
39,The probability for a finite sequence to not include a prime,The probability for a finite sequence to not include a prime,,"Given an integer $x_0$. Randomly select integers $x_{i+1}\in\{1,\dots ,x_i\}$ uniformly distributed to get a sequence  $$x_0\ge x_1\ge\cdots\ge x_{n}=1$$ What is the probability for all of the $x_i$:s, $0<i<n$, to be composites? Erroneous: There is a claim that this probability is $\frac{1}{x_0}$ but my computationally results suggest a far greater probability.","Given an integer $x_0$. Randomly select integers $x_{i+1}\in\{1,\dots ,x_i\}$ uniformly distributed to get a sequence  $$x_0\ge x_1\ge\cdots\ge x_{n}=1$$ What is the probability for all of the $x_i$:s, $0<i<n$, to be composites? Erroneous: There is a claim that this probability is $\frac{1}{x_0}$ but my computationally results suggest a far greater probability.",,"['probability', 'probability-distributions', 'prime-numbers', 'computational-mathematics']"
40,Probability of getting a seat in the train car,Probability of getting a seat in the train car,,"A train has got five train cars, each one with N seats. There are 150 passengers who randomly choose one of the cars. What is the probability that everyone will get a seat? I think that what is asking me is  ""what is the probability that each wagon is chosen by no more than N passengers""? Given a wagon, the probability of having $n<N$ people in it is given by $$p_N=\sum\limits_{n=0}^N \binom{150}{n}0.2^n 0.8^{150-n}$$. I thought of the answer being $p_N^5$.. but I think that the events wagon a is chosen by no more than N passengers wagon b is chosen by no more than N passengers wagon c is chosen by no more than N passengers wagon d is chosen by no more than N passengers wagon e is chosen by no more than N passengers are far from being independent... So what could I do? Thanks a lot","A train has got five train cars, each one with N seats. There are 150 passengers who randomly choose one of the cars. What is the probability that everyone will get a seat? I think that what is asking me is  ""what is the probability that each wagon is chosen by no more than N passengers""? Given a wagon, the probability of having $n<N$ people in it is given by $$p_N=\sum\limits_{n=0}^N \binom{150}{n}0.2^n 0.8^{150-n}$$. I thought of the answer being $p_N^5$.. but I think that the events wagon a is chosen by no more than N passengers wagon b is chosen by no more than N passengers wagon c is chosen by no more than N passengers wagon d is chosen by no more than N passengers wagon e is chosen by no more than N passengers are far from being independent... So what could I do? Thanks a lot",,"['probability', 'probability-theory', 'independence']"
41,Two groups of numbers with close sums,Two groups of numbers with close sums,,"Let $n$ be a positive integer, and independently randomize numbers $x_1,\dots,x_n,y_1,\dots,y_n$ from $(0,1)$ uniformly. Fix a real number $r>0$. Let $p_n$ be the probability that the indices $\{1,\dots,n\}$ can be divided into two groups $A,B$ so that $$\left|\sum_{i\in A}x_i-\sum_{i\in B} x_i\right|<r \text{ and } \left|\sum_{i\in A}y_i-\sum_{i\in B} y_i\right|<r.$$ Is it true that $p_n$ approaches $1$ as $n\rightarrow\infty$? If we only have the $x_i$'s, then this is true by the following method. We can let $n$ be large enough so that there are likely more than $2/r$ numbers that are in $I=[r/2, r]$. We put the numbers one by one into the two groups, starting with those outside $I$, keeping the difference between the two groups less than $1$. Then we put in the numbers in $I$ so that the difference between the two groups is less than $r$.","Let $n$ be a positive integer, and independently randomize numbers $x_1,\dots,x_n,y_1,\dots,y_n$ from $(0,1)$ uniformly. Fix a real number $r>0$. Let $p_n$ be the probability that the indices $\{1,\dots,n\}$ can be divided into two groups $A,B$ so that $$\left|\sum_{i\in A}x_i-\sum_{i\in B} x_i\right|<r \text{ and } \left|\sum_{i\in A}y_i-\sum_{i\in B} y_i\right|<r.$$ Is it true that $p_n$ approaches $1$ as $n\rightarrow\infty$? If we only have the $x_i$'s, then this is true by the following method. We can let $n$ be large enough so that there are likely more than $2/r$ numbers that are in $I=[r/2, r]$. We put the numbers one by one into the two groups, starting with those outside $I$, keeping the difference between the two groups less than $1$. Then we put in the numbers in $I$ so that the difference between the two groups is less than $r$.",,['probability']
42,What is the probability that they have no common prime factor?,What is the probability that they have no common prime factor?,,"I am seeking a simple way to solve the following problem. It is an easy problem, but I don't like the way I solve the problem. I listed two sets of numbers and counted one by one first and then find the probability. It works for this problem. But if the problem changes a little, such as change 9 to 1000, my method will not work. Two different integers are randomly selected from the set of integers greater than 2 and less than 9. What is the probability that they have no common prime factor?","I am seeking a simple way to solve the following problem. It is an easy problem, but I don't like the way I solve the problem. I listed two sets of numbers and counted one by one first and then find the probability. It works for this problem. But if the problem changes a little, such as change 9 to 1000, my method will not work. Two different integers are randomly selected from the set of integers greater than 2 and less than 9. What is the probability that they have no common prime factor?",,['probability']
43,Urn Probability Problem (conditional replacement),Urn Probability Problem (conditional replacement),,"I am working through Parzen and I came across a problem that has completely stumped me. I have an urn which has $M$ black balls and $N$ white balls. Each turn, I reach in and randomly choose one ball without replacement. If the ball is black, I add one white ball to the urn. If the ball is white, I do nothing. I want to know $X$, the expected number of white balls I will have when I drawn all of the black balls and also $Y$, the expected number of draws necessary to have drawn all of the black balls. No approach I can think of helps: indicator variables, re-arrangements, thinking about the event before the last event, recasting $\operatorname{P}(Y = y) = \operatorname{P}(Y>y-1)-\operatorname{P}(Y>y)$, etc. If someone could give me a hint as to how to start, I'd be most appreciative.","I am working through Parzen and I came across a problem that has completely stumped me. I have an urn which has $M$ black balls and $N$ white balls. Each turn, I reach in and randomly choose one ball without replacement. If the ball is black, I add one white ball to the urn. If the ball is white, I do nothing. I want to know $X$, the expected number of white balls I will have when I drawn all of the black balls and also $Y$, the expected number of draws necessary to have drawn all of the black balls. No approach I can think of helps: indicator variables, re-arrangements, thinking about the event before the last event, recasting $\operatorname{P}(Y = y) = \operatorname{P}(Y>y-1)-\operatorname{P}(Y>y)$, etc. If someone could give me a hint as to how to start, I'd be most appreciative.",,"['probability', 'probability-theory', 'discrete-mathematics']"
44,Sum of uniform random variables on simplex,Sum of uniform random variables on simplex,,"Let $X,X'$ be two independent uniform random variables on $n$-dimensional simplex $\Delta_n= \{(x_1,\ldots,x_n):x_i \geq 0, \sum x_i \leq 1\}$. I am trying to find the probability distribution of their sum  $$ Y= X+X' $$ More specifically I am interested in finding the differential entropy of their sum, $h(Y)$. $$ h(Y)= -\int f_Y(y) \log(f_Y(y)) \ dy $$ The convolution integrals are tending to be too messy. I couldn't find any other trick apart from convolution.","Let $X,X'$ be two independent uniform random variables on $n$-dimensional simplex $\Delta_n= \{(x_1,\ldots,x_n):x_i \geq 0, \sum x_i \leq 1\}$. I am trying to find the probability distribution of their sum  $$ Y= X+X' $$ More specifically I am interested in finding the differential entropy of their sum, $h(Y)$. $$ h(Y)= -\int f_Y(y) \log(f_Y(y)) \ dy $$ The convolution integrals are tending to be too messy. I couldn't find any other trick apart from convolution.",,"['probability', 'probability-distributions', 'information-theory']"
45,Market Making Card Bet Game,Market Making Card Bet Game,,"In an interview I received the follow question: We have 3 cards face down, and we give each card in a deck of 52 a numeric score ( A = 1, 2=2, .... , J=11, Q=12, K = 13). The interviewer asked me to find the expected sum of these 3 cards, I approximated that each card has an expected value of (1+2+...+13)/13 = 7, and so the sum is approximately going to be 21 (or adjusted down slightly to 20.5). Then the game begins as follows. You begin with $1000. I will quote a price to play this game, and you are able to either buy x units, or sell me x units, then we turn over the cards and you realize your profit or loss. For example: Lets say you are given a price of 25, clearly this is greater than 21, so I would choose to sell (Short) 10 units at that price. The cards turn out to have a sum of 23, so I make a profit of (25-23)*10 = 20. So my total money now is 1020, and so on. We played several rounds of this, and I was just wondering what is an appropriate strategy for this game? I tended to increase the units I would buy when quoted a very low price, and increase the number I would sell when quoted a very high price (relative to 21), but now that I think about it, is there a more sophisticated way of approaching this problem?","In an interview I received the follow question: We have 3 cards face down, and we give each card in a deck of 52 a numeric score ( A = 1, 2=2, .... , J=11, Q=12, K = 13). The interviewer asked me to find the expected sum of these 3 cards, I approximated that each card has an expected value of (1+2+...+13)/13 = 7, and so the sum is approximately going to be 21 (or adjusted down slightly to 20.5). Then the game begins as follows. You begin with $1000. I will quote a price to play this game, and you are able to either buy x units, or sell me x units, then we turn over the cards and you realize your profit or loss. For example: Lets say you are given a price of 25, clearly this is greater than 21, so I would choose to sell (Short) 10 units at that price. The cards turn out to have a sum of 23, so I make a profit of (25-23)*10 = 20. So my total money now is 1020, and so on. We played several rounds of this, and I was just wondering what is an appropriate strategy for this game? I tended to increase the units I would buy when quoted a very low price, and increase the number I would sell when quoted a very high price (relative to 21), but now that I think about it, is there a more sophisticated way of approaching this problem?",,"['probability', 'puzzle', 'finance']"
46,2D random walk variation,2D random walk variation,,"If a point on a 2D lattice is allowed to take a random walk by taking a unit step either up, down, left or right, there is probability $1$ of reaching any point (including the starting point) as the number of steps approaches infinity. However, if further limiting rules are added, the probability of the point reaching distance $d$ from the startpoint is altered. What is the expected distance $d$ from the startpoint given the following rules: 1)   The point may not ""go back on itself"" (eg, if move #3 is up, move #4 cannot be down) 2)   The random walk finishes if the point ""crashes into"" any previous path it has taken (ie, it cannot take a path it has taken previously)? (Clearly the minimum number of steps is 4.)","If a point on a 2D lattice is allowed to take a random walk by taking a unit step either up, down, left or right, there is probability $1$ of reaching any point (including the starting point) as the number of steps approaches infinity. However, if further limiting rules are added, the probability of the point reaching distance $d$ from the startpoint is altered. What is the expected distance $d$ from the startpoint given the following rules: 1)   The point may not ""go back on itself"" (eg, if move #3 is up, move #4 cannot be down) 2)   The random walk finishes if the point ""crashes into"" any previous path it has taken (ie, it cannot take a path it has taken previously)? (Clearly the minimum number of steps is 4.)",,"['probability', 'markov-chains', 'random-walk']"
47,A Continuous-Time Markov Process Taking All Possible Values,A Continuous-Time Markov Process Taking All Possible Values,,"Let $\mathbb{N}$ be the set of positive integers. For each $n \in \mathbb{N}$ , let $X^{(n)}=\{ X^{(n)}(t): t \geq 0 \}$ be a Markov chain with state-space the two point set $\{0,1\}$ and $Q$ -matrix \begin{equation} Q^{(n)} = \begin{pmatrix} - a_{n} & a_{n}\\ b_{n} & - b_{n}\\ \end{pmatrix} \end{equation} where $a_{n}, b_{n} > 0$ . Assume that $\sum a_{n} = \infty$ and $\sum a_{n}/b_{n} < \infty$ . The transition matrix is $P^{(n)}(t) = \exp(t Q^{(n)})$ . The processes $(X^{(n)}: n \in \mathbb{N})$ are independent and $X^{(n)}(0)=0$ for every $n$ . Each $X^{(n)}$ has right-continuous paths. Consider the process $X = (X^{(n)})$ with values in $\{0,1\}^{\mathbb{N}}$ . This process was introduced by David Blackwell in Another Countable Markov Process with Only Instantaneous States , Ann. Math. Stat., Volume 29 (1958), 313 - 316. His properties are studied e.g. in Kai Lai Chung, Markov Processes with Stationary Transition Probabilities or David Freedman, Markov Chains , or in the guided exercise E4.8 of David Williams, Probability with Martingales . In a note to the last one, the author states that... ... much deeper techniques [can be used to] show that for certain choices of the sequences $(a_{n})$ and $(b_{n})$ , $X$ will almost certainly visit every point in $\{0,1\}^{\mathbb{N}}$ uncountably often within a finite time. Could someone tell me what kind of techinques he refers to? What are the conditions on $(a_{n})$ and $(b_{n})$ ? Is there a general theory which answers this kind of questions? Thank you very much for your help.","Let be the set of positive integers. For each , let be a Markov chain with state-space the two point set and -matrix where . Assume that and . The transition matrix is . The processes are independent and for every . Each has right-continuous paths. Consider the process with values in . This process was introduced by David Blackwell in Another Countable Markov Process with Only Instantaneous States , Ann. Math. Stat., Volume 29 (1958), 313 - 316. His properties are studied e.g. in Kai Lai Chung, Markov Processes with Stationary Transition Probabilities or David Freedman, Markov Chains , or in the guided exercise E4.8 of David Williams, Probability with Martingales . In a note to the last one, the author states that... ... much deeper techniques [can be used to] show that for certain choices of the sequences and , will almost certainly visit every point in uncountably often within a finite time. Could someone tell me what kind of techinques he refers to? What are the conditions on and ? Is there a general theory which answers this kind of questions? Thank you very much for your help.","\mathbb{N} n \in \mathbb{N} X^{(n)}=\{ X^{(n)}(t): t \geq 0 \} \{0,1\} Q \begin{equation}
Q^{(n)} = \begin{pmatrix} - a_{n} & a_{n}\\
b_{n} & - b_{n}\\
\end{pmatrix}
\end{equation} a_{n}, b_{n} > 0 \sum a_{n} = \infty \sum a_{n}/b_{n} < \infty P^{(n)}(t) = \exp(t Q^{(n)}) (X^{(n)}: n \in \mathbb{N}) X^{(n)}(0)=0 n X^{(n)} X = (X^{(n)}) \{0,1\}^{\mathbb{N}} (a_{n}) (b_{n}) X \{0,1\}^{\mathbb{N}} (a_{n}) (b_{n})","['probability', 'stochastic-processes', 'markov-chains', 'markov-process']"
48,lower bound of expectation of stochastic differential equation,lower bound of expectation of stochastic differential equation,,"I'm looking for a lower bound on the expected value of a smooth, non-negative, increasing function $\mathbb{E}f(X_t)$, $f(0)=0$ of the solution to a stochastic differential equation $X_t = x + \int_0^t b(X_s) ds + \int_0^t \sigma(X_s) dw_s$  ($x>0$). I'm aware of many upper bounds based on linear growth and Lipschitz constants, e.g., $\mathbb{E}|X_t|^p \le Ce^{\alpha t}$ or $\mathbb{E}|X_t-X_s|^p \le Cg(|t-s|)$, etc. For a lower bound I've played around with the second moment method, the reverse Markov inequality (like this ), and flipped through Oksendal, K&S, R&Y, and Mao, but I'm stumped. From Markov's inequality and a Girsanov argument I can show that for any $t>0$, $\mathbb{E}f(X_t) \ge P[f(X_t)>1]>0$. However, I'm not aware of any results based on linear growth or Lipschitz constants in a similar manner to the results mentioned above, something like, say, $\mathbb{E}|X_t|^p \ge Cg(t)$ for some decreasing function $g(t)$. Is anyone aware of a result like this?","I'm looking for a lower bound on the expected value of a smooth, non-negative, increasing function $\mathbb{E}f(X_t)$, $f(0)=0$ of the solution to a stochastic differential equation $X_t = x + \int_0^t b(X_s) ds + \int_0^t \sigma(X_s) dw_s$  ($x>0$). I'm aware of many upper bounds based on linear growth and Lipschitz constants, e.g., $\mathbb{E}|X_t|^p \le Ce^{\alpha t}$ or $\mathbb{E}|X_t-X_s|^p \le Cg(|t-s|)$, etc. For a lower bound I've played around with the second moment method, the reverse Markov inequality (like this ), and flipped through Oksendal, K&S, R&Y, and Mao, but I'm stumped. From Markov's inequality and a Girsanov argument I can show that for any $t>0$, $\mathbb{E}f(X_t) \ge P[f(X_t)>1]>0$. However, I'm not aware of any results based on linear growth or Lipschitz constants in a similar manner to the results mentioned above, something like, say, $\mathbb{E}|X_t|^p \ge Cg(t)$ for some decreasing function $g(t)$. Is anyone aware of a result like this?",,"['probability', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
49,"Let $X$ be the number of aces and $Y$ be the number of spades. Show that $X$, $Y$ are uncorrelated.","Let  be the number of aces and  be the number of spades. Show that ,  are uncorrelated.",X Y X Y,"A deck of 52 cards is shuffled, and we deal a bridge of 13 cards. Let $X$ be the number of aces and $Y$ be the number of spades. Show that $X$, $Y$ are uncorrelated. Here is what I did: $Cov(X,Y) = E[XY]-E[X]E[Y]$ uncorrelated means $Cov(X,Y) = 0$, hence  $E[XY]=E[X]E[Y]$ $E[X] =  \sum_{k=0}^{k=4} k \frac{\dbinom{4}{k} \dbinom{48}{13-k}}{\dbinom{52}{13}} $ $E[Y] =  \sum_{k=0}^{k=13} k \frac{\dbinom{13}{k} \dbinom{39}{13-k}}{\dbinom{52}{13}} $ Are the summations above correct? and how do I calculate $E[XY]$?","A deck of 52 cards is shuffled, and we deal a bridge of 13 cards. Let $X$ be the number of aces and $Y$ be the number of spades. Show that $X$, $Y$ are uncorrelated. Here is what I did: $Cov(X,Y) = E[XY]-E[X]E[Y]$ uncorrelated means $Cov(X,Y) = 0$, hence  $E[XY]=E[X]E[Y]$ $E[X] =  \sum_{k=0}^{k=4} k \frac{\dbinom{4}{k} \dbinom{48}{13-k}}{\dbinom{52}{13}} $ $E[Y] =  \sum_{k=0}^{k=13} k \frac{\dbinom{13}{k} \dbinom{39}{13-k}}{\dbinom{52}{13}} $ Are the summations above correct? and how do I calculate $E[XY]$?",,['probability']
50,"A lawn, a flower, a pipe and the neighbours","A lawn, a flower, a pipe and the neighbours",,"You have a square lawn and a precious flower in the centre. You want to make sure you water the flower, and you don't particularly care how much of the lawn you water. To please your aleatory aesthetic sense, you uniformly randomly pick two points on the lawn as end points of an elevated irrigation pipe, which will rotate around its centre and irrigate the circle it covers. You keep picking points until the pipe waters the flower and none of the neighbours' plots. What's the probability for one pick to yield admissible points? Suppose your costs are mainly determined by the material for the pipe; what is its expected length? Suppose your costs are mainly determined by the water used; what's the expected irrigated area? How do these compare to the corresponding values if you just picked two random points without worrying about the flower or the neighbours? The background to this question is that I realized in thinking about this answer that a) calculations can actually be simplified by seemingly complicated conditions like the circle determined by the points being inside the square (the expected length of the segment is easier to determine with that condition than without), and b) some conditions, like the circle being inside the square, reduce the expected length and area, whereas others, like the centre being inside the circle, increase the expected length and area, and it would be interesting to see which of these effects is stronger. I'm hoping that perhaps it's different for the length and the area. Feel free to calculate higher moments. I expect this to be a straightforward calculation with the approach I used in that answer; it's just that the integration limits are slightly complicated by the condition that the centre be in the circle. I'll try to perform the calculation and write an answer if noone else does, but I thought I'd share the problem with you first.","You have a square lawn and a precious flower in the centre. You want to make sure you water the flower, and you don't particularly care how much of the lawn you water. To please your aleatory aesthetic sense, you uniformly randomly pick two points on the lawn as end points of an elevated irrigation pipe, which will rotate around its centre and irrigate the circle it covers. You keep picking points until the pipe waters the flower and none of the neighbours' plots. What's the probability for one pick to yield admissible points? Suppose your costs are mainly determined by the material for the pipe; what is its expected length? Suppose your costs are mainly determined by the water used; what's the expected irrigated area? How do these compare to the corresponding values if you just picked two random points without worrying about the flower or the neighbours? The background to this question is that I realized in thinking about this answer that a) calculations can actually be simplified by seemingly complicated conditions like the circle determined by the points being inside the square (the expected length of the segment is easier to determine with that condition than without), and b) some conditions, like the circle being inside the square, reduce the expected length and area, whereas others, like the centre being inside the circle, increase the expected length and area, and it would be interesting to see which of these effects is stronger. I'm hoping that perhaps it's different for the length and the area. Feel free to calculate higher moments. I expect this to be a straightforward calculation with the approach I used in that answer; it's just that the integration limits are slightly complicated by the condition that the centre be in the circle. I'll try to perform the calculation and write an answer if noone else does, but I thought I'd share the problem with you first.",,"['probability', 'geometric-probability']"
51,Probability a rotation has a small distance to a vector,Probability a rotation has a small distance to a vector,,"Given two binary vectors $V_1$, $V_2$ of length $\ell$, say that the distance between $V_1$ and $V_2$ is the number of positions in the vectors that don't match. So the distance between $001$ and $101$ is $1$.  We also define rotations of $V$ so that if $V$ is $01011$, for example, the five rotations are $01011$, $10110$, $01101$, $110101$ and $10101$. We can therefore index the rotations from $0$ to $\ell-1$ so that index $i$ refers to rotation $i$ and index $0$ refers to the identity rotation. If the vector is chosen uniformly at random and we are given an index $i$, how can I compute the probability that $V$ has distance at most $k$ to rotation $i$?","Given two binary vectors $V_1$, $V_2$ of length $\ell$, say that the distance between $V_1$ and $V_2$ is the number of positions in the vectors that don't match. So the distance between $001$ and $101$ is $1$.  We also define rotations of $V$ so that if $V$ is $01011$, for example, the five rotations are $01011$, $10110$, $01101$, $110101$ and $10101$. We can therefore index the rotations from $0$ to $\ell-1$ so that index $i$ refers to rotation $i$ and index $0$ refers to the identity rotation. If the vector is chosen uniformly at random and we are given an index $i$, how can I compute the probability that $V$ has distance at most $k$ to rotation $i$?",,['probability']
52,Why is the best position for LCR not the last person?,Why is the best position for LCR not the last person?,,"For the uninitiated, LCR is a game in which each player starts with three ""tokens"" and rolls up to three dice (at most as many as tokens they have). Each die has three sides which indicate that nothing happens and one spot apiece for left, center, and right; left and right indicating that they pass one token in that direction and center indicating that a token goes to the ""center,"" where it is removed from the game. The game ends when only one player has any tokens. I was wondering what position would be best, so I created the following Python script to do this for me: from random import *  def LCRRound(players):     global playerset     playerset = [3] * players     while not GameOver():         for player in range(len(playerset)):             for i in range(min(3, playerset[player])):                 Move(player)             if GameOver():                 break     return [playerset.index(p) for p in playerset if p!=0][0] def L(player):     playerset[player]-=1     playerset[player-1]+=1 def C(player):     playerset[player]-=1 def R(player):     playerset[player]-=1     playerset[(player+1)%len(playerset)]+=1 def GameOver():     return playerset.count(0) == len(playerset)-1 def Move(player):     tmp = randrange(6)     if tmp==3:         L(player)     if tmp==4:         C(player)     if tmp==5:         R(player)  for x in range(2, 11):     wins = [0] * x     for y in range(100000 * x):         wins[LCRRound(x)]+=1     print(wins) Which tests for randomly generated games with 2 to 10 players, playing 100,000 games for each player in each set (so 200,000 games for the two player tests, 300,000 for three, and so on up to 1,000,000 games for ten players). This generated the following output (and similar output other times I ran it), with the numbers being the number of times that player one (players are in order of who rolls): [76233, 123767] [91720, 98359, 109921] [95913, 97396, 101796, 104895] [96340, 97629, 99926, 103080, 103025] [96985, 96768, 98607, 101509, 103283, 102848] [97557, 96211, 97613, 100659, 102562, 103595, 101803] [97636, 95984, 96652, 99220, 101364, 103619, 104070, 101455] [98000, 95559, 96338, 97589, 99600, 102966, 104767, 104061, 101120] [97355, 95754, 95876, 97163, 99303, 101537, 103103, 104583, 103943, 101383] For two and three players, the optimal position is last. However, after that, the player who wins the most becomes the second to last and then the third to last (and would presumably continue in this motion as more players are added). This is contrary to what I expected, since I thought the optimal position would be the player immediately before, after, or opposite the starting player, but it is none of these. In face, the second player seems to be the most disfavorable rather than the person who starts. Which leads me to my question: What is the mathematical explanation for what position is the best in LCR?","For the uninitiated, LCR is a game in which each player starts with three ""tokens"" and rolls up to three dice (at most as many as tokens they have). Each die has three sides which indicate that nothing happens and one spot apiece for left, center, and right; left and right indicating that they pass one token in that direction and center indicating that a token goes to the ""center,"" where it is removed from the game. The game ends when only one player has any tokens. I was wondering what position would be best, so I created the following Python script to do this for me: from random import *  def LCRRound(players):     global playerset     playerset = [3] * players     while not GameOver():         for player in range(len(playerset)):             for i in range(min(3, playerset[player])):                 Move(player)             if GameOver():                 break     return [playerset.index(p) for p in playerset if p!=0][0] def L(player):     playerset[player]-=1     playerset[player-1]+=1 def C(player):     playerset[player]-=1 def R(player):     playerset[player]-=1     playerset[(player+1)%len(playerset)]+=1 def GameOver():     return playerset.count(0) == len(playerset)-1 def Move(player):     tmp = randrange(6)     if tmp==3:         L(player)     if tmp==4:         C(player)     if tmp==5:         R(player)  for x in range(2, 11):     wins = [0] * x     for y in range(100000 * x):         wins[LCRRound(x)]+=1     print(wins) Which tests for randomly generated games with 2 to 10 players, playing 100,000 games for each player in each set (so 200,000 games for the two player tests, 300,000 for three, and so on up to 1,000,000 games for ten players). This generated the following output (and similar output other times I ran it), with the numbers being the number of times that player one (players are in order of who rolls): [76233, 123767] [91720, 98359, 109921] [95913, 97396, 101796, 104895] [96340, 97629, 99926, 103080, 103025] [96985, 96768, 98607, 101509, 103283, 102848] [97557, 96211, 97613, 100659, 102562, 103595, 101803] [97636, 95984, 96652, 99220, 101364, 103619, 104070, 101455] [98000, 95559, 96338, 97589, 99600, 102966, 104767, 104061, 101120] [97355, 95754, 95876, 97163, 99303, 101537, 103103, 104583, 103943, 101383] For two and three players, the optimal position is last. However, after that, the player who wins the most becomes the second to last and then the third to last (and would presumably continue in this motion as more players are added). This is contrary to what I expected, since I thought the optimal position would be the player immediately before, after, or opposite the starting player, but it is none of these. In face, the second player seems to be the most disfavorable rather than the person who starts. Which leads me to my question: What is the mathematical explanation for what position is the best in LCR?",,"['probability', 'game-theory', 'dice']"
53,How long until everyone has been in the lead?,How long until everyone has been in the lead?,,"Earlier, I asked a question about a series of competitions: A series of matches are held between n identical competitors. Each is won by one of the n with equal probability (no ties). I'm looking for a probabilistic description of the outcome when looking at the first player to win 1, 2, ... matches. Now I am able to ask my full question. In this scenario, what is the expected time until all players have been in the lead at least once? (Say, with probability at least 1/2 -- though other measures of central tendency are probably fine if they're easier to work with.) For $n=1$ this takes only one match. For $n=2$ this is just a 1-D random walk (essentially, start at 1 and see how many steps you take until you become negative); I find that after 9 matches both players have been in the lead with probability 65/128 > 50%. Even with $n=3$ it gets hard to find an exact answer because of the exponential blow-up (it is at least several hundred). So what I'm really looking for is an asymptotic, since my interests lie in $n$ much larger than 3.","Earlier, I asked a question about a series of competitions: A series of matches are held between n identical competitors. Each is won by one of the n with equal probability (no ties). I'm looking for a probabilistic description of the outcome when looking at the first player to win 1, 2, ... matches. Now I am able to ask my full question. In this scenario, what is the expected time until all players have been in the lead at least once? (Say, with probability at least 1/2 -- though other measures of central tendency are probably fine if they're easier to work with.) For $n=1$ this takes only one match. For $n=2$ this is just a 1-D random walk (essentially, start at 1 and see how many steps you take until you become negative); I find that after 9 matches both players have been in the lead with probability 65/128 > 50%. Even with $n=3$ it gets hard to find an exact answer because of the exponential blow-up (it is at least several hundred). So what I'm really looking for is an asymptotic, since my interests lie in $n$ much larger than 3.",,"['probability', 'random-walk']"
54,Confidence band for Brownian Motion with uniformly distributed hitting position,Confidence band for Brownian Motion with uniformly distributed hitting position,,"Let $(B_t)$ denote the standard Brownian motion on the interval $[0,1]$. For a given confidence level $\alpha \in (0,1)$ a confidence band on $[0,1]$ is any function $u$ with the property that  $$ P(\omega; |B_t(\omega)| < u(t), \quad \forall t\in [0,1])=\alpha. $$ In other words, the probability that a path of the Brownian motion stays within a confidence band is $\alpha$. Additionally the boundary hitting position for those paths leaving the band must be uniformly distributed on $[0,1]$. This condition can be stated using the stopping time  $$\tau(\omega) = \inf [ t \in [0,1], |B_t(\omega)|=u(t) ]. $$ Then $\tau $ is the time of the first hitting, and one asks that $\tau$ is uniformly distributed on $[0,1]$ conditionally on the event that $\tau$ is finite. I am interested in References and links to literature or papers considering this or similar problems Thoughts, ideas, discussion The context of the problem is a rather boring one, so will not state it here. The problem itself seem to be non-trivial and interesting.","Let $(B_t)$ denote the standard Brownian motion on the interval $[0,1]$. For a given confidence level $\alpha \in (0,1)$ a confidence band on $[0,1]$ is any function $u$ with the property that  $$ P(\omega; |B_t(\omega)| < u(t), \quad \forall t\in [0,1])=\alpha. $$ In other words, the probability that a path of the Brownian motion stays within a confidence band is $\alpha$. Additionally the boundary hitting position for those paths leaving the band must be uniformly distributed on $[0,1]$. This condition can be stated using the stopping time  $$\tau(\omega) = \inf [ t \in [0,1], |B_t(\omega)|=u(t) ]. $$ Then $\tau $ is the time of the first hitting, and one asks that $\tau$ is uniformly distributed on $[0,1]$ conditionally on the event that $\tau$ is finite. I am interested in References and links to literature or papers considering this or similar problems Thoughts, ideas, discussion The context of the problem is a rather boring one, so will not state it here. The problem itself seem to be non-trivial and interesting.",,"['probability', 'probability-theory', 'stochastic-processes', 'brownian-motion']"
55,"If $(a,b,c)$ are the sides of a triangle, what is the probability that $ax+by \ge c$?","If  are the sides of a triangle, what is the probability that ?","(a,b,c) ax+by \ge c","Posted in MO since it is unanswered in MSE. Let $(a,b,c)$ be the side of a triangle. In its most general linear form, the triangle inequality can be expressed as: Does $ax + by \ge c$ for fixed $x,y \ge 0$ hold? Trivially the inequality holds if both $x$ and $y$ are $\ge 1$ ; however if one of or both of $x$ and $y$ is non-negative and $\le 1$ then $ax+y \ge c$ is not necessarily true. Assuming that vertices of a triangle are uniformly random on a circle we can ask the probability $P(ax+by \ge c)$ . In this question we found a closed form for the probability $P(a+b \ge cx)$ , $x \ge 1$ . This question is an attempt at generalization of this result. Experimental data show that if $0 \le x,y \le 1$ then, $$ P(ax + by \ge c) = \frac{4}{\pi^2}\chi_2(x) + \frac{4}{\pi^2}\chi_2(y) \tag 1 $$ and if $0 \le x \le 1 \le y$ then, $$ P(ax + by \ge c) = 1 + \frac{4}{\pi^2}\chi_2\left(\frac{x}{y}\right)  - \frac{4}{\pi^2}\chi_2\left(\frac{1}{y}\right)  \tag 2 $$ where $\displaystyle \chi_2(x) = \sum_{k=0}^{\infty} \frac{x^{2k+1}}{(2k+1)^2}, |x| \le 1$ is the Legendre Chi function . Question 1 : Is $(1)$ true? Question 2 : Is $(2)$ true?","Posted in MO since it is unanswered in MSE. Let be the side of a triangle. In its most general linear form, the triangle inequality can be expressed as: Does for fixed hold? Trivially the inequality holds if both and are ; however if one of or both of and is non-negative and then is not necessarily true. Assuming that vertices of a triangle are uniformly random on a circle we can ask the probability . In this question we found a closed form for the probability , . This question is an attempt at generalization of this result. Experimental data show that if then, and if then, where is the Legendre Chi function . Question 1 : Is true? Question 2 : Is true?","(a,b,c) ax + by \ge c x,y \ge 0 x y \ge 1 x y \le 1 ax+y \ge c P(ax+by \ge c) P(a+b \ge cx) x \ge 1 0 \le x,y \le 1 
P(ax + by \ge c) = \frac{4}{\pi^2}\chi_2(x) + \frac{4}{\pi^2}\chi_2(y) \tag 1
 0 \le x \le 1 \le y 
P(ax + by \ge c) = 1 + \frac{4}{\pi^2}\chi_2\left(\frac{x}{y}\right) 
- \frac{4}{\pi^2}\chi_2\left(\frac{1}{y}\right)  \tag 2
 \displaystyle \chi_2(x) = \sum_{k=0}^{\infty} \frac{x^{2k+1}}{(2k+1)^2}, |x| \le 1 (1) (2)","['probability', 'integration', 'geometry', 'inequality', 'summation']"
56,Calculate the speed of the slowest flying machine in Minecraft with probabilities,Calculate the speed of the slowest flying machine in Minecraft with probabilities,,"In Minecraft (sandbox video game made of blocks,written in Java), I have recently created a flying machine (assemble of blocks which moves on its own) and I have trouble calculating its speed, I hope someone can help me. Topic : probabilities Context [vocab and general context]: Minecraft runs on a clock, steping 20 times per second. There are 20 'game ticks' (gt for short) in a second , 72 000 gt per hour. Thunderstorm is a weather in the game and only during this weather, lightning bolts can appear. A chunk is a 16 wide *16 long *256 high piece of the world. The duration of thunderstorms is between 3 600 and 15 600 gt (3 mins to 13 mins) with a pseudorandom uniform distribution [for details it is drawn with java.util.Random.nextInt(int bound = 12000)+3600 ] The duration of 'clear' weather ( time between thunderstorms ) is similarly drawn but with bound of 168000 and added 12000 making it from 12 000 to 180 000 gt . It is assumed that the player don't sleep(=drawn time is the actual time between thunders). During (only) thunder weather, there is a 1/(100 000) chance per gt of a lightning bolt occuring in a chunk. A lighting bolt position in a chunk is randomly selected using a LCG (linear congruential generator) [with parameters $a=3,c=1013904223$ and $m=2^{32}$ for formula $X_{n+1} = (a*X_n + c) \mod m$ ] and can (I think) be associated with a uniform distribution for the coordinates of the position along the two horizontal axis [given basically by ((LCG >> 2) & 15) for one axis and ((LCG >> 2) >> 8 ) & 15 ] and the vertical coordinate is given by the block at the highest position (top-most block vertically). There is then a $\dfrac{1}{100\, 000} * \dfrac{1}{16*16} = \dfrac{1}{25\, 600\, 000} $ chance per gt of a lighting bolt hitting a block (my block is placed to be the highest in its column of blocks) when it is thundering. [these probabilities are independant, therefore multiply them to get the proba of both happening, the target block can only be in 1 chunk at a time] My flying machine need, to progress 1 block forward, 1 lighting bolt hit on 1 block [a piston that reacts to the lightning bolt] and to move 2 blocks forward, it requires 2 lightning bolts, spaced in time by 9 gt and the second lightning bolt (bolt for short) needs to happen at a different coordinate than the previous one (1 block offset in a horizontal direction). The targeted block may have moved to a different chunk (I don't think it changes the results). If the second bolt did not happen at the right place/time, then the flying machine flies back in the other direction with a speed of 10gt per block (as opposed to the 9gt per block of the +X movement). We have these two 'forces' opposing : the random lightning bolts pushing the flying machine forward (let's say in the +X direction) while another circuit pushes the flying machine backwards (-X direction) if bolts are not received at the right time and place. Problem Based on the context, you probably think that the flying machine mostly goes in the -X direction seeing how rare thunderstorms and lightning bolts are (its true !), the problem formulates as follows : What is the probability that this machine travels 30 M(million) blocks in the +X direction ? Resolution attemp : We'll start by seeing a few usefull observations then formulate more clearly then I will describe my attempt. Observations The flying machine is faster in the +X direction (9gt per block) than in the -X direction (10gt per block). There is a lot more time on average where it is not thundering as the average off thunder (no thunderstorms) is 96 000 gt (consecutive)(80 mins) while the average thunderstorm duration is only 9 600 gt(consecutive)(8 mins). The maximum distance traveled during a thunderstorm (+X direction) (15 600gt) is $\frac{15600 }{9} = \frac{5200}{3} \approx 1\, 733.\overline{3}$ blocks while the minimum distance traveled during clear weather (-X direction(dir for short)) is $\frac{12000 }{10} = 1200$ blocks which is less than the maximum +X dir distance, with a maximum overall forward distance of $\frac{5200}{3}-1200=\frac{1600}{3} \approx 533.\overline{3}$ blocks ==> it is possible to overall go forward. For the maximum thunderstorm duration, the given clear weather duration that moves the same distance (but opposite direction) is $\frac{15600 }{9}*10 = \frac{52000}{3} \approx 17333.\overline{3}$ gt (which is an integer in reality). This means that any clear weather duration over this number will result in a total (during a cycle thunder, no thunder) distance in the -X direction no matter the thunderstorm duration. Oppositely, for the maximum clear weather duration, the maximum number of blocks progressed in the -X direction is $\frac{180 000}{10} = 18 \,000$ blocks as, even during a thunderstorm, it is not garanted to go forward at all (no lightning bolts) Mathematical formulation A parameter $F$ (forward) is given initialy by a random uniform distribution (integers) $U(3\, 600,15 \, 600)$ A parameter $B$ (backward) is given initialy  by a random uniform distribution (integers) $U(12\, 000,180 \, 000)$ A parameter $L$ (lightning bolt) is given by a descrete probability $p_L = \dfrac{1}{25\, 600 \, 000}$ A parameter $T$ (thundering) that is true or false (1 or 0) that says when it is thundering A parameter $x_n$ (position from the origin ( $x_0=0$ )) of the flying machine with conditions that $x_n>0,\forall n \in \mathbb{N}$ The pseudo algorithm of the process is described here When T switches from 0 to 1 : draw F When T switches from 1 to 0 : draw B  If T is 1: (thunderstorm)     cycle F number of times:         if cooldown is 0:               draw L (lightning bolt occur ?)         otherwise :              subtract 1 from cooldown         if L is 1 (success):             cooldown is set to 9 gt             x_n is increased by 1             L is to 0         if cooldown is -1 :             x_n is decreased by 1             cooldown is set to 10     set T to 0 once cycle is finished if T is 0 : (clear weather)     x_n is decreased by min(x_n,B/10)     (min to not become negative     set T to 1 The goal is to calculate the time taken on average for x_n to reach 30 000 000. My resolution attempt I tried to bound the minimum time : from the previous observations, we can travel forward (+X dir) as maximum of 533 blocks every thunder and clear weather cycle, so every 27 600 gt. This gives us the shortest time possible with perfect luck of $ \frac{27600}{533}\times 30\, 000 \, 000 = 1 553 470 920$ gt (59.1 years (fast!)) Then I tried to estimate it using gambler's ruin but am not sure at all if I used it corectly. There are 6 480 000 couples (thunder, clear) with a positive amount of ticks (thunder gt-clear gt) out of the 2 016 000 000 couples possible, giving a probability of 0.32142857 % to have a couple with more thunder gt than clear gt. Doing the sum of the values of all the couples (thunder gt-clear gt) gives a value of 7 782 481 200, which I after multiplied it by probability of it beeing positive to give the overal expected value of positive couples : $p =25\, 015\, 118$ . then using this formula I found online, we can calculate the expected nb of gt to have to wait to have 9*30M gt : $ p+ \dfrac{\left(p\right)^{9*30*10^6-1}-1}{p-1}$ Which gives a result of around $10^{(10^{9.3})}$ That is the expected time to wait before the thunder/clear weather cycle give the right conditions to reach the goal with perfect lighting bolts luck. To take into account I use the same formula but swapping the $p$ for the $1/p_L$ (average time between good lighting bolts and with the time calculated above, giving the formula $ \dfrac{1}{p_L}+ \dfrac{\left(\dfrac{1}{p_L}\right)^{10^{(10^{9.3})}-1}-1}{\dfrac{1}{p_L}-1}$ Which gives a result of (around) $10^{(10^{(10^{(9.3)})})}$ gt Which is very slow ! Conclusion I am really not sure about these calculations and would like if anyone could guide me to find the speed of this machine. It is expected to take a lot longer than $7*10^{9*10^7}$ but the upper bound has no estimate. I would gladly answer any questions about details or general questions to help resolve this problem. Thank you for reading !","In Minecraft (sandbox video game made of blocks,written in Java), I have recently created a flying machine (assemble of blocks which moves on its own) and I have trouble calculating its speed, I hope someone can help me. Topic : probabilities Context [vocab and general context]: Minecraft runs on a clock, steping 20 times per second. There are 20 'game ticks' (gt for short) in a second , 72 000 gt per hour. Thunderstorm is a weather in the game and only during this weather, lightning bolts can appear. A chunk is a 16 wide *16 long *256 high piece of the world. The duration of thunderstorms is between 3 600 and 15 600 gt (3 mins to 13 mins) with a pseudorandom uniform distribution [for details it is drawn with java.util.Random.nextInt(int bound = 12000)+3600 ] The duration of 'clear' weather ( time between thunderstorms ) is similarly drawn but with bound of 168000 and added 12000 making it from 12 000 to 180 000 gt . It is assumed that the player don't sleep(=drawn time is the actual time between thunders). During (only) thunder weather, there is a 1/(100 000) chance per gt of a lightning bolt occuring in a chunk. A lighting bolt position in a chunk is randomly selected using a LCG (linear congruential generator) [with parameters and for formula ] and can (I think) be associated with a uniform distribution for the coordinates of the position along the two horizontal axis [given basically by ((LCG >> 2) & 15) for one axis and ((LCG >> 2) >> 8 ) & 15 ] and the vertical coordinate is given by the block at the highest position (top-most block vertically). There is then a chance per gt of a lighting bolt hitting a block (my block is placed to be the highest in its column of blocks) when it is thundering. [these probabilities are independant, therefore multiply them to get the proba of both happening, the target block can only be in 1 chunk at a time] My flying machine need, to progress 1 block forward, 1 lighting bolt hit on 1 block [a piston that reacts to the lightning bolt] and to move 2 blocks forward, it requires 2 lightning bolts, spaced in time by 9 gt and the second lightning bolt (bolt for short) needs to happen at a different coordinate than the previous one (1 block offset in a horizontal direction). The targeted block may have moved to a different chunk (I don't think it changes the results). If the second bolt did not happen at the right place/time, then the flying machine flies back in the other direction with a speed of 10gt per block (as opposed to the 9gt per block of the +X movement). We have these two 'forces' opposing : the random lightning bolts pushing the flying machine forward (let's say in the +X direction) while another circuit pushes the flying machine backwards (-X direction) if bolts are not received at the right time and place. Problem Based on the context, you probably think that the flying machine mostly goes in the -X direction seeing how rare thunderstorms and lightning bolts are (its true !), the problem formulates as follows : What is the probability that this machine travels 30 M(million) blocks in the +X direction ? Resolution attemp : We'll start by seeing a few usefull observations then formulate more clearly then I will describe my attempt. Observations The flying machine is faster in the +X direction (9gt per block) than in the -X direction (10gt per block). There is a lot more time on average where it is not thundering as the average off thunder (no thunderstorms) is 96 000 gt (consecutive)(80 mins) while the average thunderstorm duration is only 9 600 gt(consecutive)(8 mins). The maximum distance traveled during a thunderstorm (+X direction) (15 600gt) is blocks while the minimum distance traveled during clear weather (-X direction(dir for short)) is blocks which is less than the maximum +X dir distance, with a maximum overall forward distance of blocks ==> it is possible to overall go forward. For the maximum thunderstorm duration, the given clear weather duration that moves the same distance (but opposite direction) is gt (which is an integer in reality). This means that any clear weather duration over this number will result in a total (during a cycle thunder, no thunder) distance in the -X direction no matter the thunderstorm duration. Oppositely, for the maximum clear weather duration, the maximum number of blocks progressed in the -X direction is blocks as, even during a thunderstorm, it is not garanted to go forward at all (no lightning bolts) Mathematical formulation A parameter (forward) is given initialy by a random uniform distribution (integers) A parameter (backward) is given initialy  by a random uniform distribution (integers) A parameter (lightning bolt) is given by a descrete probability A parameter (thundering) that is true or false (1 or 0) that says when it is thundering A parameter (position from the origin ( )) of the flying machine with conditions that The pseudo algorithm of the process is described here When T switches from 0 to 1 : draw F When T switches from 1 to 0 : draw B  If T is 1: (thunderstorm)     cycle F number of times:         if cooldown is 0:               draw L (lightning bolt occur ?)         otherwise :              subtract 1 from cooldown         if L is 1 (success):             cooldown is set to 9 gt             x_n is increased by 1             L is to 0         if cooldown is -1 :             x_n is decreased by 1             cooldown is set to 10     set T to 0 once cycle is finished if T is 0 : (clear weather)     x_n is decreased by min(x_n,B/10)     (min to not become negative     set T to 1 The goal is to calculate the time taken on average for x_n to reach 30 000 000. My resolution attempt I tried to bound the minimum time : from the previous observations, we can travel forward (+X dir) as maximum of 533 blocks every thunder and clear weather cycle, so every 27 600 gt. This gives us the shortest time possible with perfect luck of gt (59.1 years (fast!)) Then I tried to estimate it using gambler's ruin but am not sure at all if I used it corectly. There are 6 480 000 couples (thunder, clear) with a positive amount of ticks (thunder gt-clear gt) out of the 2 016 000 000 couples possible, giving a probability of 0.32142857 % to have a couple with more thunder gt than clear gt. Doing the sum of the values of all the couples (thunder gt-clear gt) gives a value of 7 782 481 200, which I after multiplied it by probability of it beeing positive to give the overal expected value of positive couples : . then using this formula I found online, we can calculate the expected nb of gt to have to wait to have 9*30M gt : Which gives a result of around That is the expected time to wait before the thunder/clear weather cycle give the right conditions to reach the goal with perfect lighting bolts luck. To take into account I use the same formula but swapping the for the (average time between good lighting bolts and with the time calculated above, giving the formula Which gives a result of (around) gt Which is very slow ! Conclusion I am really not sure about these calculations and would like if anyone could guide me to find the speed of this machine. It is expected to take a lot longer than but the upper bound has no estimate. I would gladly answer any questions about details or general questions to help resolve this problem. Thank you for reading !","a=3,c=1013904223 m=2^{32} X_{n+1} = (a*X_n + c) \mod m \dfrac{1}{100\, 000} * \dfrac{1}{16*16} = \dfrac{1}{25\, 600\, 000}  \frac{15600 }{9} = \frac{5200}{3} \approx 1\, 733.\overline{3} \frac{12000 }{10} = 1200 \frac{5200}{3}-1200=\frac{1600}{3} \approx 533.\overline{3} \frac{15600 }{9}*10 = \frac{52000}{3} \approx 17333.\overline{3} \frac{180 000}{10} = 18 \,000 F U(3\, 600,15 \, 600) B U(12\, 000,180 \, 000) L p_L = \dfrac{1}{25\, 600 \, 000} T x_n x_0=0 x_n>0,\forall n \in \mathbb{N}  \frac{27600}{533}\times 30\, 000 \, 000 = 1 553 470 920 p =25\, 015\, 118  p+ \dfrac{\left(p\right)^{9*30*10^6-1}-1}{p-1} 10^{(10^{9.3})} p 1/p_L  \dfrac{1}{p_L}+ \dfrac{\left(\dfrac{1}{p_L}\right)^{10^{(10^{9.3})}-1}-1}{\dfrac{1}{p_L}-1} 10^{(10^{(10^{(9.3)})})} 7*10^{9*10^7}",['probability']
57,"The Lévy–Ciesielski construction of a Brownian motion for $t\in \mathbb R$ (and not only $t\in[0,1]$)",The Lévy–Ciesielski construction of a Brownian motion for  (and not only ),"t\in \mathbb R t\in[0,1]","The Lévy–Ciesielski construction of a Brownian motion is based on $$ W(t):=\sum_{k=0}^{\infty} A_k s_k(t) \quad \quad \quad\quad \quad \quad\quad \quad \quad (1) $$ for times $0 \leq t \leq 1$ , where the coefficients $\left\{A_k\right\}_{k=0}^{\infty}$ are independent, $N(0,1)$ random variables defined on some probability space. (see ""Evans, Lawrence C. An introduction to stochastic differential equations. Vol. 82. American Mathematical Soc., 2012."") The function $s_k$ is the $k$ -th Schauder function: $$ s_k(t):=\int_0^t h_k(s) d s \quad(0 \leq t \leq 1) $$ where $k=0,1,2, \ldots$ and the family $\left\{h_k(\cdot)\right\}_{k=0}^{\infty}$ of Haar functions are defined for $0 \leq t \leq 1$ as follows: $$ \begin{gathered} h_0(t):=1 \quad \text { for } 0 \leq t \leq 1 \\ h_1(t):=\left\{\begin{array}{lr} 1 & \text { for } 0 \leq t \leq \frac{1}{2} \\ -1 & \text { for } \frac{1}{2}<t \leq 1 \end{array}\right. \end{gathered} $$ If $2^n \leq k<2^{n+1}, n=1,2, \ldots$ , we set $$ h_k(t):=\left\{\begin{array}{l} 2^{n / 2} \text { for } \frac{k-2^n}{2^n} \leq t \leq \frac{k-2^n+1 / 2}{2^n} \\ -2^{n / 2} \text { for } \frac{k-2^n+1 / 2}{2^n}<t \leq \frac{k-2^n+1}{2^n} \\ 0 \text { otherwise. } \end{array}\right. $$ In Evan's book, I read that: $$ W(t, \omega):=\sum_{k=0}^{\infty} A_k(\omega) s_k(t) \quad(0 \leq t \leq 1) \quad \quad \quad \quad \quad (2)$$ defines a Brownian motion for $0 \leq t \leq 1$ . Probably my question is very naive, but I would like to know if there exists for $W(\cdot)$ and $t\in\mathbb R$ an expression in infinite sum using the Haar system like the (1) and (2). For example, if we let the indices $k$ and $n$ vary over the whole $\mathbb Z$ , can we get an expression of the Brownian motion over $\mathbb R$ ? (For the latter, I think not because otherwise, I would have found it written in some book...)","The Lévy–Ciesielski construction of a Brownian motion is based on for times , where the coefficients are independent, random variables defined on some probability space. (see ""Evans, Lawrence C. An introduction to stochastic differential equations. Vol. 82. American Mathematical Soc., 2012."") The function is the -th Schauder function: where and the family of Haar functions are defined for as follows: If , we set In Evan's book, I read that: defines a Brownian motion for . Probably my question is very naive, but I would like to know if there exists for and an expression in infinite sum using the Haar system like the (1) and (2). For example, if we let the indices and vary over the whole , can we get an expression of the Brownian motion over ? (For the latter, I think not because otherwise, I would have found it written in some book...)","
W(t):=\sum_{k=0}^{\infty} A_k s_k(t) \quad \quad \quad\quad \quad \quad\quad \quad \quad (1)
 0 \leq t \leq 1 \left\{A_k\right\}_{k=0}^{\infty} N(0,1) s_k k 
s_k(t):=\int_0^t h_k(s) d s \quad(0 \leq t \leq 1)
 k=0,1,2, \ldots \left\{h_k(\cdot)\right\}_{k=0}^{\infty} 0 \leq t \leq 1 
\begin{gathered}
h_0(t):=1 \quad \text { for } 0 \leq t \leq 1 \\
h_1(t):=\left\{\begin{array}{lr}
1 & \text { for } 0 \leq t \leq \frac{1}{2} \\
-1 & \text { for } \frac{1}{2}<t \leq 1
\end{array}\right.
\end{gathered}
 2^n \leq k<2^{n+1}, n=1,2, \ldots 
h_k(t):=\left\{\begin{array}{l}
2^{n / 2} \text { for } \frac{k-2^n}{2^n} \leq t \leq \frac{k-2^n+1 / 2}{2^n} \\
-2^{n / 2} \text { for } \frac{k-2^n+1 / 2}{2^n}<t \leq \frac{k-2^n+1}{2^n} \\
0 \text { otherwise. }
\end{array}\right.
 
W(t, \omega):=\sum_{k=0}^{\infty} A_k(\omega) s_k(t) \quad(0 \leq t \leq 1) \quad \quad \quad \quad \quad (2) 0 \leq t \leq 1 W(\cdot) t\in\mathbb R k n \mathbb Z \mathbb R","['probability', 'brownian-motion']"
58,Probability of winning a game guessing $k$ random numbers in sequence with optimal strategy,Probability of winning a game guessing  random numbers in sequence with optimal strategy,k,"We are playing a game as follows, suppose we have $k$ spaces. One at a time, we will pick $k$ random integers from the range $[1,n]$ , without replacement. After selecting a number, we must choose to place it in one of our spaces before selecting the next number. We ""win"" if after selecting our $k$ numbers, our sequence on our spaces is in increasing order. Here is an example of a winning game where $n=10, k=3$ . Initial state: _ _ _ Randomly select $5$ , place in middle slot: _ $5$ _ Randomly select $6$ , place in last slot: _ $5$ $6$ Randomly select $1$ , place in first slot: $1$ $5$ $6$ Note that had the last number been a $7,8,9,10$ instead of $1$ , then we would have lost as none of those values are $<5$ . Clearly, if you are just randomly selecting the slot at every iteration, the probability of winning is $\frac{1}{k!}$ . However, we can do better by having good strategy; why place a $1$ in the last slot when thats an instant loss, for example. Define $P(n,k)$ to be the maximum probability of winning the game given $k$ slots and $n$ random numbers. When we say ""maximum probability"" we mean that whenever we select a random number, we put it in the slot where from there we have the highest probability of winning the game. Edit: I have since realized I need more base cases. $P(n,0)=1$ and $P(j,k)=0$ if $j<k$ . $P(j, j)=1$ We will prove our formula recursively with induction. Notice that in our base case, $P(n, 1)=1$ for all values of $n$ . Assume that for all values of $m<n$ and $j<k$ that $P(m, j)$ provides the maximum probability of winning for $j$ slots with selection $[1,m]$ . We now define the formula for the $n,k$ case. We have $n$ options for what we can pick as our first number, for the sake of argument suppose we selected the number $x\in[1,n]$ . With this first number we can now calculate the probability of winning the $n, k$ case, given our first selected number is $x$ . Notate this as $P(n,k;x)$ [^1]. Since there is a $\frac{1}{n}$ chance of selecting any particular $x$ , we know that $$ P(n,k) = \frac{1}{n}\sum_{x=1}^n P(n,k;x) $$ Now to calculate $P(n,k;x)$ , we must determine the optimal location to place $x$ in the slots. If I was to place $x$ in slot $i$ , I would partition the board into two sections, one of length $i-1$ on the left, and one of length $k-i$ on the right. In order to win, we must select exactly $i-1$ numbers to place on the left that are $<x$ , and exactly $k-i$ numbers on the right that are $>x$ , otherwise we lose as we have placed $x$ in the wrong spot for our selected numbers. The probability of this occuring is $$ \frac{\binom{x-1}{i-1}\binom{n-x}{k-i}}{\binom{n-1}{k-1}} $$ However, just getting the correct numbers is not enough, as we must put them in the correct locations, but these partitioned boards are equivilent to playing the same game twice! So if we get valid numbers (per above) we only need to win the partitioned boards in order to win the game. Since $x-1, n-x < n$ and $i-1, k-i<k$ we can use our inductive hypothesis to say that the probability of winning if we place $x$ in slot $i$ is $$ \frac{\binom{x-1}{i-1}\binom{n-x}{k-i}}{\binom{n-1}{k-1}}P(x-1, i-1)P(n-x, k-i). $$ In order to optimize our strategy, we select the $i$ for which this value is maximized which gives us $$ P(n,k;x)=\max_{1\leq i\leq k}\left[\frac{\binom{x-1}{i-1}\binom{n-x}{k-i}}{\binom{n-1}{k-1}}P(x-1, i-1)P(n-x, k-i)\right] $$ Which means we can sum over all values of $x$ and divide by $n$ to get the value of $P(n,k)$ Q.E.D. This recursive formula was also not too tough to program up, here is a plot of when $n=50$ , notice that the y axis is a log plot so the variations can be seen. Minimal solution is when $k=35$ with $P(50,35)\approx 3.28\cdot 10^{-5}$ $n=50$ "" /> As an aside, has anyone seen this before? I was thinking of writing this into a blog post for my students and if this is a known thing than I'd like to reference a paper on it [^1]: I understand my notation is starting to get a bit garbo while writing this down","We are playing a game as follows, suppose we have spaces. One at a time, we will pick random integers from the range , without replacement. After selecting a number, we must choose to place it in one of our spaces before selecting the next number. We ""win"" if after selecting our numbers, our sequence on our spaces is in increasing order. Here is an example of a winning game where . Initial state: _ _ _ Randomly select , place in middle slot: _ _ Randomly select , place in last slot: _ Randomly select , place in first slot: Note that had the last number been a instead of , then we would have lost as none of those values are . Clearly, if you are just randomly selecting the slot at every iteration, the probability of winning is . However, we can do better by having good strategy; why place a in the last slot when thats an instant loss, for example. Define to be the maximum probability of winning the game given slots and random numbers. When we say ""maximum probability"" we mean that whenever we select a random number, we put it in the slot where from there we have the highest probability of winning the game. Edit: I have since realized I need more base cases. and if . We will prove our formula recursively with induction. Notice that in our base case, for all values of . Assume that for all values of and that provides the maximum probability of winning for slots with selection . We now define the formula for the case. We have options for what we can pick as our first number, for the sake of argument suppose we selected the number . With this first number we can now calculate the probability of winning the case, given our first selected number is . Notate this as [^1]. Since there is a chance of selecting any particular , we know that Now to calculate , we must determine the optimal location to place in the slots. If I was to place in slot , I would partition the board into two sections, one of length on the left, and one of length on the right. In order to win, we must select exactly numbers to place on the left that are , and exactly numbers on the right that are , otherwise we lose as we have placed in the wrong spot for our selected numbers. The probability of this occuring is However, just getting the correct numbers is not enough, as we must put them in the correct locations, but these partitioned boards are equivilent to playing the same game twice! So if we get valid numbers (per above) we only need to win the partitioned boards in order to win the game. Since and we can use our inductive hypothesis to say that the probability of winning if we place in slot is In order to optimize our strategy, we select the for which this value is maximized which gives us Which means we can sum over all values of and divide by to get the value of Q.E.D. This recursive formula was also not too tough to program up, here is a plot of when , notice that the y axis is a log plot so the variations can be seen. Minimal solution is when with $n=50$ "" /> As an aside, has anyone seen this before? I was thinking of writing this into a blog post for my students and if this is a known thing than I'd like to reference a paper on it [^1]: I understand my notation is starting to get a bit garbo while writing this down","k k [1,n] k n=10, k=3 5 5 6 5 6 1 1 5 6 7,8,9,10 1 <5 \frac{1}{k!} 1 P(n,k) k n P(n,0)=1 P(j,k)=0 j<k P(j, j)=1 P(n, 1)=1 n m<n j<k P(m, j) j [1,m] n,k n x\in[1,n] n, k x P(n,k;x) \frac{1}{n} x 
P(n,k) = \frac{1}{n}\sum_{x=1}^n P(n,k;x)
 P(n,k;x) x x i i-1 k-i i-1 <x k-i >x x 
\frac{\binom{x-1}{i-1}\binom{n-x}{k-i}}{\binom{n-1}{k-1}}
 x-1, n-x < n i-1, k-i<k x i 
\frac{\binom{x-1}{i-1}\binom{n-x}{k-i}}{\binom{n-1}{k-1}}P(x-1, i-1)P(n-x, k-i).
 i 
P(n,k;x)=\max_{1\leq i\leq k}\left[\frac{\binom{x-1}{i-1}\binom{n-x}{k-i}}{\binom{n-1}{k-1}}P(x-1, i-1)P(n-x, k-i)\right]
 x n P(n,k) n=50 k=35 P(50,35)\approx 3.28\cdot 10^{-5}","['probability', 'combinatorics', 'solution-verification', 'combinations']"
59,"What is the probability that a random regular expression defines the language of all binary strings $\{0, 1\}^*$?",What is the probability that a random regular expression defines the language of all binary strings ?,"\{0, 1\}^*","Suppose we generate a random regular expression $R$ in the following way: We start with a single meta-symbol $S$ . Then each turn we independently replace all $S$ in our word with $\{0\}$ , $\{1\}$ , $(S \cup S)$ , $SS$ or $S^*$ with equal probability. This process terminates with probability $1$ due to the extinction criterion Galton-Watson branching processes. What is the probability $p$ that $R$ defines the language of all binary strings $\{0, 1\}^*$ ? All I know about this number is that it lies in  in $[\frac{1}{5 \sqrt{5}};\frac{1}{2}]$ . Here $\frac{1}{5 \sqrt{5}}$ is the probability of $R$ containing $(\{0\} \cup \{1\})^*$ or $(\{1\} \cup \{0\})^*$ as a subexpression, derived from the following equation: $x = \frac{2}{5^4} + \frac{1}{5}(5x - 2x^2)$ $2x^2 = \frac{2}{5^3}$ $x = \frac{1}{5 \sqrt{5}}$ And $\frac{1}{2}$ is the probability of $R$ defining an infinite language (which happens iff $R$ contains a Kleene star operator), derived from the following equation: $5y = 1 + 4y - 2y^2$ $2y^2 + y - 1 = 0$ $y = \frac{1}{2}$ However, I have no idea how to find the exact value of $p$ .","Suppose we generate a random regular expression in the following way: We start with a single meta-symbol . Then each turn we independently replace all in our word with , , , or with equal probability. This process terminates with probability due to the extinction criterion Galton-Watson branching processes. What is the probability that defines the language of all binary strings ? All I know about this number is that it lies in  in . Here is the probability of containing or as a subexpression, derived from the following equation: And is the probability of defining an infinite language (which happens iff contains a Kleene star operator), derived from the following equation: However, I have no idea how to find the exact value of .","R S S \{0\} \{1\} (S \cup S) SS S^* 1 p R \{0, 1\}^* [\frac{1}{5 \sqrt{5}};\frac{1}{2}] \frac{1}{5 \sqrt{5}} R (\{0\} \cup \{1\})^* (\{1\} \cup \{0\})^* x = \frac{2}{5^4} + \frac{1}{5}(5x - 2x^2) 2x^2 = \frac{2}{5^3} x = \frac{1}{5 \sqrt{5}} \frac{1}{2} R R 5y = 1 + 4y - 2y^2 2y^2 + y - 1 = 0 y = \frac{1}{2} p","['probability', 'stochastic-processes', 'formal-languages', 'regular-language', 'regular-expressions']"
60,Reference for the Gibbs variational principle/dual characterization of KL,Reference for the Gibbs variational principle/dual characterization of KL,,"Let $P,Q$ be two probability distributions. Then, one has the following dual characterization of their Kullback-Leibler divergence (relative entropy): $$ D(P \,\|\,Q) = \sup_f ( \mathbb{E}_P[f(X)] - \log \mathbb{E}_Q[e^{f(X)}] ) \tag{1} $$ This characterization is sometimes referred to as Gibbs variational principle , or Donsker-Varadhan formula; however, I couldn't track where it was first proven (there is often a reference to a paper of and Donsker Varadhan from 1983, but I couldn't find, in there, where (1) is actually established). Where was (1) established first, specifically? What to cite?","Let be two probability distributions. Then, one has the following dual characterization of their Kullback-Leibler divergence (relative entropy): This characterization is sometimes referred to as Gibbs variational principle , or Donsker-Varadhan formula; however, I couldn't track where it was first proven (there is often a reference to a paper of and Donsker Varadhan from 1983, but I couldn't find, in there, where (1) is actually established). Where was (1) established first, specifically? What to cite?","P,Q 
D(P \,\|\,Q) = \sup_f ( \mathbb{E}_P[f(X)] - \log \mathbb{E}_Q[e^{f(X)}] ) \tag{1}
","['probability', 'reference-request', 'math-history']"
61,Is it true that $\phi(\mu)=\mu F(\mu)^2-\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq 0$?,Is it true that ?,\phi(\mu)=\mu F(\mu)^2-\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq 0,"Consider a random variable $V$ with distribution function $F$ and density function $f$ with support $[\underline{v},\overline{v}]$ , where $0\leq\underline{v}<\overline{v}$ . The mean is $\mu$ . Here $f$ is assumed to be differentiable on its support and log-concave (i.e. $\ln \circ f$ is a concave function). I would like to prove (or disprove) that $$\tag{1}\phi(\mu)=\mu F(\mu)^2-\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq 0$$ for all such probability distributions. I have not been able to find any examples of distributions for which inequality $(1)$ is violated (I have tried the beta and Kumaraswamy distributions on $[0,1]$ with many different combinations of parameters). An example of an $f$ that is not log concave for which $\phi(\mu)<0$ would also be helpful (as I am not entirely sure whether the log-concavity is relevant). Inequality $(1)$ can also be written as (using integration by parts): $$\begin{align}&E[V\mid V\geq \mu]\cdot P(V\geq \mu)+\mu\cdot P[V\leq \mu]-E[\hat{V}\mid \hat{V}\geq \mu]\cdot P(\hat{V}\geq \mu)\\ &=\int_{\mu}^{\overline{v}}vf(v)dv+\mu F(\mu)-\int_{\mu}^{\overline{v}}v\hat{f}(v)dv\\\tag{2} &=\int_{\mu}^{\overline{v}}vf(v)dv+\mu F(\mu)-\int_{\mu}^{\overline{v}}v[2f(v)F(v)]dv\\ &=\int_{\mu}^{\overline{v}}vf(v)[1-2F(v)]dv+\mu F(\mu)\geq 0\end{align} $$ where $\hat{V}$ denotes the random variable that is the maximum of two independent copies of $V$ , $\hat{F}$ given by $\hat{F}(v)=[F(v)]^2$ is its distribution function and $\hat{f}$ given by $\hat{f}(v)=2f(v)F(v)$ is its density function. Some extra details: Let $\phi(x)=g(x)-h(x)$ where $g$ and $h$ are given by $$g(x)=\int_{x}^{\overline{v}}vf(v)dv+\mu F(x),\qquad \text{and} \qquad h(x)=\int_{x}^{\overline{v}}v[2f(v)F(v)]dv$$ Then inequality $(1)$ is $\phi(\mu)\geq 0$ . Denoting the mean of $\hat{F}$ by $\hat{\mu}$ , it is easy to see that: $$\phi(\underline{v})=\mu-\hat{\mu}<0\quad \text{and}\quad  \phi(\overline{v})=\mu>0$$ Also, $\phi$ is strictly increasing: $$\phi'(x)=(\mu-x+2xF(x))f(x)\geq xF(x)f(x)>0,\quad \forall x\in(\underline{v},\overline{v})$$ where the first inequality follows from Markov's inequality. It follows that there exists a unique $\bar{x}\in(\underline{v},\overline{v})$ such that $$\phi(x)\lesseqqgtr0\iff x \lesseqqgtr\bar{x}.$$ Additionally $$g'(x)\gtreqqless0\iff x \lesseqqgtr\mu$$ so that the maximum of $g$ is $g(\mu)$ . Note also that integrating by parts gives $$g(x)=\bar{v}+(\mu-x)F(x)-\int_x^{\overline{v}}F(v)dv\qquad \text{and}\qquad h(x)=\bar{v}-x[F(x)]^2-\int_x^{\overline{v}}[F(v)]^2dv$$ Some facts related to log-concavity: Log-concavity of $f$ implies log-concavity of $F$ and $1-F$ If $f$ is differentiable then log-concavity of $F$ is equivalent to $f^2-Ff'\geq 0$ and log-concavity of $1-F$ is equivalent to $(1-F)f'+f^2\geq 0$ Log-concavity of $F$ implies $F(\mu)\geq \frac{1}{e}$ Products of log-concave functions are log concave. For example $F[1-F]$ is log-concave. -Log-concave densities are (strongly) unimodal A proof that $\phi(\mu)\geq 0$ if $\mu\geq m$ and $\mu\geq \overline{v}/2$ Let $m$ be the median of $F$ . Then $$\phi(m)=\frac{1}{4}(2\mu-m)-\int_m^{\overline{v}}F(v)[1-F(v)]dv\geq \frac{1}{4}(2\mu-\overline{v})$$ where the last inequality follows because the integrand is at most $1/4$ . Since $\phi$ is increasing and $\mu\geq m$ , the result follows. (Note that this result allows us to conclude that $\phi(\mu)\geq 0$ for all symmetric distributions.) A lower bound for $\phi(\mu)$ From Chebyshev's integral inequality : $$\int_{\mu}^{\overline{v}}[F(v)]^2dv\geq \frac{1}{\overline{v}-\mu}\left[\int_{\mu}^{\overline{v}}F(v)dv\right]^2$$ Thus $$-\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq -\frac{1}{\overline{v}-\mu}\int_{\mu}^{\overline{v}}F(v)dv\left(\overline{v}-\mu-\int_{\mu}^{\overline{v}}F(v)dv\right)$$ Since $\int_{\mu}^{\overline{v}}F(v)dv\leq \overline{v}-\mu$ and $$\int_{\mu}^{\overline{v}}F(v)dv=\overline{v}-\mu F(\mu)-\int_{\mu}^{\overline{v}}vf(v)dv$$ we get $$-\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq \mu[1-F(\mu)]-\int_{\mu}^{\overline{v}}vf(v)dv.$$ It follows that $$\begin{align*} \phi(\mu)&\geq\mu F(\mu)^2+\mu[1-F(\mu)]-\int_{\mu}^{\overline{v}}vf(v)dv \\ &=\mu-\int_{\mu}^{\overline{v}}vf(v)dv-\mu F(\mu)[1-F(\mu)]\\ \tag{3} &=\int_{\underline{v}}^{\mu}vf(v)dv-\mu F(\mu)[1-F(\mu)]\\ &=\mu F(\mu)^2-\int_{\underline{v}}^{\mu}F(v)dv \end{align*}$$ The lower bound above seems to be nonnegative for the beta distributions and Kumaraswamy distributions. It is exactly zero for the uniform distribution on $[0,1]$ . A proof that $\phi(\mu)\geq 0$ when $f$ is increasing on $[\underline{v},\mu]$ and $F(\mu)\geq 1/2$ Since $F(\mu)[1-F(\mu)]\leq 1/4$ , the lower bound $(3)$ gives the following sufficient condition for $\phi(\mu)\geq 0$ : $$\int_{\underline{v}}^{\mu}vf(v)dv\geq\frac{1}{4}\mu$$ If $f$ is increasing on $[\underline{v},\mu]$ and $F(\mu)\geq 1/2$ then, $$\int_{\underline{v}}^{\mu}vf(v)dv\geq \frac{\mu+\underline{v}}{2}F(\mu)\geq \frac{1}{4}\mu$$ where the first inequality comes from by Chebyshev's integral inequality.","Consider a random variable with distribution function and density function with support , where . The mean is . Here is assumed to be differentiable on its support and log-concave (i.e. is a concave function). I would like to prove (or disprove) that for all such probability distributions. I have not been able to find any examples of distributions for which inequality is violated (I have tried the beta and Kumaraswamy distributions on with many different combinations of parameters). An example of an that is not log concave for which would also be helpful (as I am not entirely sure whether the log-concavity is relevant). Inequality can also be written as (using integration by parts): where denotes the random variable that is the maximum of two independent copies of , given by is its distribution function and given by is its density function. Some extra details: Let where and are given by Then inequality is . Denoting the mean of by , it is easy to see that: Also, is strictly increasing: where the first inequality follows from Markov's inequality. It follows that there exists a unique such that Additionally so that the maximum of is . Note also that integrating by parts gives Some facts related to log-concavity: Log-concavity of implies log-concavity of and If is differentiable then log-concavity of is equivalent to and log-concavity of is equivalent to Log-concavity of implies Products of log-concave functions are log concave. For example is log-concave. -Log-concave densities are (strongly) unimodal A proof that if and Let be the median of . Then where the last inequality follows because the integrand is at most . Since is increasing and , the result follows. (Note that this result allows us to conclude that for all symmetric distributions.) A lower bound for From Chebyshev's integral inequality : Thus Since and we get It follows that The lower bound above seems to be nonnegative for the beta distributions and Kumaraswamy distributions. It is exactly zero for the uniform distribution on . A proof that when is increasing on and Since , the lower bound gives the following sufficient condition for : If is increasing on and then, where the first inequality comes from by Chebyshev's integral inequality.","V F f [\underline{v},\overline{v}] 0\leq\underline{v}<\overline{v} \mu f \ln \circ f \tag{1}\phi(\mu)=\mu F(\mu)^2-\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq 0 (1) [0,1] f \phi(\mu)<0 (1) \begin{align}&E[V\mid V\geq \mu]\cdot P(V\geq \mu)+\mu\cdot P[V\leq \mu]-E[\hat{V}\mid \hat{V}\geq \mu]\cdot P(\hat{V}\geq \mu)\\
&=\int_{\mu}^{\overline{v}}vf(v)dv+\mu F(\mu)-\int_{\mu}^{\overline{v}}v\hat{f}(v)dv\\\tag{2}
&=\int_{\mu}^{\overline{v}}vf(v)dv+\mu F(\mu)-\int_{\mu}^{\overline{v}}v[2f(v)F(v)]dv\\
&=\int_{\mu}^{\overline{v}}vf(v)[1-2F(v)]dv+\mu F(\mu)\geq 0\end{align}  \hat{V} V \hat{F} \hat{F}(v)=[F(v)]^2 \hat{f} \hat{f}(v)=2f(v)F(v) \phi(x)=g(x)-h(x) g h g(x)=\int_{x}^{\overline{v}}vf(v)dv+\mu F(x),\qquad \text{and} \qquad h(x)=\int_{x}^{\overline{v}}v[2f(v)F(v)]dv (1) \phi(\mu)\geq 0 \hat{F} \hat{\mu} \phi(\underline{v})=\mu-\hat{\mu}<0\quad \text{and}\quad  \phi(\overline{v})=\mu>0 \phi \phi'(x)=(\mu-x+2xF(x))f(x)\geq xF(x)f(x)>0,\quad \forall x\in(\underline{v},\overline{v}) \bar{x}\in(\underline{v},\overline{v}) \phi(x)\lesseqqgtr0\iff x \lesseqqgtr\bar{x}. g'(x)\gtreqqless0\iff x \lesseqqgtr\mu g g(\mu) g(x)=\bar{v}+(\mu-x)F(x)-\int_x^{\overline{v}}F(v)dv\qquad \text{and}\qquad h(x)=\bar{v}-x[F(x)]^2-\int_x^{\overline{v}}[F(v)]^2dv f F 1-F f F f^2-Ff'\geq 0 1-F (1-F)f'+f^2\geq 0 F F(\mu)\geq \frac{1}{e} F[1-F] \phi(\mu)\geq 0 \mu\geq m \mu\geq \overline{v}/2 m F \phi(m)=\frac{1}{4}(2\mu-m)-\int_m^{\overline{v}}F(v)[1-F(v)]dv\geq \frac{1}{4}(2\mu-\overline{v}) 1/4 \phi \mu\geq m \phi(\mu)\geq 0 \phi(\mu) \int_{\mu}^{\overline{v}}[F(v)]^2dv\geq \frac{1}{\overline{v}-\mu}\left[\int_{\mu}^{\overline{v}}F(v)dv\right]^2 -\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq -\frac{1}{\overline{v}-\mu}\int_{\mu}^{\overline{v}}F(v)dv\left(\overline{v}-\mu-\int_{\mu}^{\overline{v}}F(v)dv\right) \int_{\mu}^{\overline{v}}F(v)dv\leq \overline{v}-\mu \int_{\mu}^{\overline{v}}F(v)dv=\overline{v}-\mu F(\mu)-\int_{\mu}^{\overline{v}}vf(v)dv -\int_{\mu}^{\overline{v}}F(v)[1-F(v)]dv\geq \mu[1-F(\mu)]-\int_{\mu}^{\overline{v}}vf(v)dv. \begin{align*}
\phi(\mu)&\geq\mu F(\mu)^2+\mu[1-F(\mu)]-\int_{\mu}^{\overline{v}}vf(v)dv \\
&=\mu-\int_{\mu}^{\overline{v}}vf(v)dv-\mu F(\mu)[1-F(\mu)]\\
\tag{3}
&=\int_{\underline{v}}^{\mu}vf(v)dv-\mu F(\mu)[1-F(\mu)]\\
&=\mu F(\mu)^2-\int_{\underline{v}}^{\mu}F(v)dv
\end{align*} [0,1] \phi(\mu)\geq 0 f [\underline{v},\mu] F(\mu)\geq 1/2 F(\mu)[1-F(\mu)]\leq 1/4 (3) \phi(\mu)\geq 0 \int_{\underline{v}}^{\mu}vf(v)dv\geq\frac{1}{4}\mu f [\underline{v},\mu] F(\mu)\geq 1/2 \int_{\underline{v}}^{\mu}vf(v)dv\geq \frac{\mu+\underline{v}}{2}F(\mu)\geq \frac{1}{4}\mu","['probability', 'inequality', 'probability-distributions', 'integral-inequality']"
62,Are there any solvers to Chance Constrained Programming Problems?,Are there any solvers to Chance Constrained Programming Problems?,,"I'm trying to solve a chance constrained programming (CCP) problem $\min_x f_0(x, \xi), \text{ such that } \mathbb{P} ( f_i(x, \xi) \ge \alpha_i ) \le \epsilon_i, \text{ where } i = 1,2,\cdots, m$ Most of approaches to solve CCP problems are reformulating the chance constraint into some computationally tractable forms. For example, the chance constraint $\mathbb{P}(\xi^\intercal x \ge b) \le \epsilon $ can be rewritten in 3 different ways (not equivalent) assume $\xi$ satisfies a Gaussian distribution $\xi \sim N(\bar{\xi}, \Sigma)$, then $\mathbb{P}(\xi^\intercal x \ge b) \le \epsilon $ is equivalent with $b - \bar{\xi}^\intercal x \ge \Phi^{-1}(1-\epsilon) || \Sigma^{1/2} x ||_2 $. This is a deterministic Second Order Cone Constraint. which is convex and will not cause intractable issues. (Please refer to Stephen Boyd's lecture notes for more details) Using the scenario approach in [1] Calafiore, Giuseppe C., and Marco C. Campi. ""The scenario approach to robust control design."" IEEE Transactions on Automatic Control 51.5 (2006): 742-753. Assume we have many samples $\xi^1, \xi^2,\cdots, \xi^N$ from unknown distribution of $\xi$. The chance constraint  $\mathbb{P}(\xi^\intercal x \ge b) \le \epsilon $ is approximated by \begin{eqnarray} (\xi^1)^\intercal x \ge b\\  (\xi^2)^\intercal x \ge b\\  \vdots\\  (\xi^N)^\intercal x \ge b  \end{eqnarray} which is a set of linear (deterministic) inequalities the convex approximation (Bernstein approximation) in [2] Nemirovski, Arkadi, and Alexander Shapiro. ""Convex approximations of chance constrained programs."" SIAM Journal on Optimization 17.4 (2006): 969-996.  The key idea is to obtain a deterministic optimization problem whose optimal solution is suboptimal to the original CCP problem. I will not write their solutions here since I don't want to scare you away. All these approaches are reformulating the chance constraint into some computationally tractable forms (by which I mean current solvers like gruobi/cplex/mosek could handle). I'm wondering are there any scripts (preferably in Matlab or Python) that could convert a chance constraint into a deterministic form using the methods listed above? Or in the best case, are there any solvers have incorporated the methods above and are able to solve chance constrained programming problems?","I'm trying to solve a chance constrained programming (CCP) problem $\min_x f_0(x, \xi), \text{ such that } \mathbb{P} ( f_i(x, \xi) \ge \alpha_i ) \le \epsilon_i, \text{ where } i = 1,2,\cdots, m$ Most of approaches to solve CCP problems are reformulating the chance constraint into some computationally tractable forms. For example, the chance constraint $\mathbb{P}(\xi^\intercal x \ge b) \le \epsilon $ can be rewritten in 3 different ways (not equivalent) assume $\xi$ satisfies a Gaussian distribution $\xi \sim N(\bar{\xi}, \Sigma)$, then $\mathbb{P}(\xi^\intercal x \ge b) \le \epsilon $ is equivalent with $b - \bar{\xi}^\intercal x \ge \Phi^{-1}(1-\epsilon) || \Sigma^{1/2} x ||_2 $. This is a deterministic Second Order Cone Constraint. which is convex and will not cause intractable issues. (Please refer to Stephen Boyd's lecture notes for more details) Using the scenario approach in [1] Calafiore, Giuseppe C., and Marco C. Campi. ""The scenario approach to robust control design."" IEEE Transactions on Automatic Control 51.5 (2006): 742-753. Assume we have many samples $\xi^1, \xi^2,\cdots, \xi^N$ from unknown distribution of $\xi$. The chance constraint  $\mathbb{P}(\xi^\intercal x \ge b) \le \epsilon $ is approximated by \begin{eqnarray} (\xi^1)^\intercal x \ge b\\  (\xi^2)^\intercal x \ge b\\  \vdots\\  (\xi^N)^\intercal x \ge b  \end{eqnarray} which is a set of linear (deterministic) inequalities the convex approximation (Bernstein approximation) in [2] Nemirovski, Arkadi, and Alexander Shapiro. ""Convex approximations of chance constrained programs."" SIAM Journal on Optimization 17.4 (2006): 969-996.  The key idea is to obtain a deterministic optimization problem whose optimal solution is suboptimal to the original CCP problem. I will not write their solutions here since I don't want to scare you away. All these approaches are reformulating the chance constraint into some computationally tractable forms (by which I mean current solvers like gruobi/cplex/mosek could handle). I'm wondering are there any scripts (preferably in Matlab or Python) that could convert a chance constraint into a deterministic form using the methods listed above? Or in the best case, are there any solvers have incorporated the methods above and are able to solve chance constrained programming problems?",,"['probability', 'optimization', 'algorithms', 'convex-optimization', 'approximation']"
63,empirical quantile function - uniform convergence,empirical quantile function - uniform convergence,,"Let $X_1,...,X_n$ denote independent and identically distributed random variables, with $X_i \sim F$, $1 \leq i \leq n$. Assume $F$ is continuous. Then we know that its generalized inverse (quantile function) $F^{\leftharpoonup}(u):= \inf\{x: \, F(x)>u\}$ exists. If $F_n$ denotes the empirical cumulative distribution function, i.e. $F_n(x)=\frac{1}{n} \sum_{i=1}^n \textbf{1}(X_i \leq x)$, by Glivenko-Cantelli we know $\Vert F_n - F \Vert_\infty \overset{a.s.}{\to}0$. Now, what can we say about $ \Vert {F_n}^{\leftharpoonup}- F^{\leftharpoonup} \Vert_\infty $? Are there conditions under which a.s. uniform convergence can be obtained for the empirical quantile function ${F_n}^{\leftharpoonup}$?","Let $X_1,...,X_n$ denote independent and identically distributed random variables, with $X_i \sim F$, $1 \leq i \leq n$. Assume $F$ is continuous. Then we know that its generalized inverse (quantile function) $F^{\leftharpoonup}(u):= \inf\{x: \, F(x)>u\}$ exists. If $F_n$ denotes the empirical cumulative distribution function, i.e. $F_n(x)=\frac{1}{n} \sum_{i=1}^n \textbf{1}(X_i \leq x)$, by Glivenko-Cantelli we know $\Vert F_n - F \Vert_\infty \overset{a.s.}{\to}0$. Now, what can we say about $ \Vert {F_n}^{\leftharpoonup}- F^{\leftharpoonup} \Vert_\infty $? Are there conditions under which a.s. uniform convergence can be obtained for the empirical quantile function ${F_n}^{\leftharpoonup}$?",,"['probability', 'statistics', 'asymptotics']"
64,What is the probability that the Golden State Warriors will break the NBA regular season record of wins?,What is the probability that the Golden State Warriors will break the NBA regular season record of wins?,,"There are $82$ games in a regular season, and the current record is held by the Chicago Bulls, at 72-10. As of yesterday (March 4th 2016), the GSW season performance stood at 55-5. Assuming they maintain this record or do better,they need to win at least 18 of their next 22 games.  I calculated the probability of them breaking the Bulls' record as ~7.4%, since each game's outcome is a binomial probability, and the probability of them winning so far is 55/60. I used the following code in R: p = 11/12 #55/60, their current record q = 1-p i = c(0:22) (choose(22,18)*(p^18)*(q^4))/sum(choose(22,i)*(p^i)*(q^(22-i))) But if they keep winning, the probability p of their winning a game will keep changing. How can we take that into consideration while calculating the overall probability?","There are $82$ games in a regular season, and the current record is held by the Chicago Bulls, at 72-10. As of yesterday (March 4th 2016), the GSW season performance stood at 55-5. Assuming they maintain this record or do better,they need to win at least 18 of their next 22 games.  I calculated the probability of them breaking the Bulls' record as ~7.4%, since each game's outcome is a binomial probability, and the probability of them winning so far is 55/60. I used the following code in R: p = 11/12 #55/60, their current record q = 1-p i = c(0:22) (choose(22,18)*(p^18)*(q^4))/sum(choose(22,i)*(p^i)*(q^(22-i))) But if they keep winning, the probability p of their winning a game will keep changing. How can we take that into consideration while calculating the overall probability?",,['probability']
65,Conditional expectation involving some complications around exponential random variables,Conditional expectation involving some complications around exponential random variables,,"Here is my problem. Consider four independent exponential distributions $X^A_1$, $X^B_1$, $X^A_2$, $X^B_2$ where $X^A_1$ and $X^B_1$ are $\exp(\lambda_1)$ and $X^A_2$ and $X^B_2$ are $\exp(\lambda_2)$. There is another random variable $\mu$ where $\mu=\mu^G$ when $X_1=X^A_1+X^B_1 < X_2=X^A_2+X^B_2$ and $\mu=\mu^B$ otherwise. In this setup, I'd like to calculate $E[e^{-rX_1}\mu]$. The approach I've taken is use $E[e^{-rX}\mu]=E[e^{-rX}\mu^G|X_1<X_2]P(X_1<X_2)+E[e^{-rX}\mu^B|X_1>X_2]P(X_1>X_2)$, and since $X_1$ and $X_2$ follow gamma distribution with (2,$\lambda_1$) and (2,$\lambda_2$), respectively, I calculated the density function $f_Y(y)$ where $Y=X_1-X_2$. And it is easy to show $$f_{{X_1},Y}(x_1,y)=f_{X_1}(x_1)f_{X_2}(x_1-y),$$ and from this point, I obtained the conditional density $f_{X_1}(x_1|Y=y)$ and tried to calculated the conditional expectation. But, I ended up with having a complicated form in the integrand when calculating the conditional expectation $E[e^{-rX}\mu^G|X_1<X_2]$, and probably I could proceed further, but I'd like to ask you if there is an easier way to get $E[e^{-rX}\mu]$ without calculating all the density functions. Thank you very much!","Here is my problem. Consider four independent exponential distributions $X^A_1$, $X^B_1$, $X^A_2$, $X^B_2$ where $X^A_1$ and $X^B_1$ are $\exp(\lambda_1)$ and $X^A_2$ and $X^B_2$ are $\exp(\lambda_2)$. There is another random variable $\mu$ where $\mu=\mu^G$ when $X_1=X^A_1+X^B_1 < X_2=X^A_2+X^B_2$ and $\mu=\mu^B$ otherwise. In this setup, I'd like to calculate $E[e^{-rX_1}\mu]$. The approach I've taken is use $E[e^{-rX}\mu]=E[e^{-rX}\mu^G|X_1<X_2]P(X_1<X_2)+E[e^{-rX}\mu^B|X_1>X_2]P(X_1>X_2)$, and since $X_1$ and $X_2$ follow gamma distribution with (2,$\lambda_1$) and (2,$\lambda_2$), respectively, I calculated the density function $f_Y(y)$ where $Y=X_1-X_2$. And it is easy to show $$f_{{X_1},Y}(x_1,y)=f_{X_1}(x_1)f_{X_2}(x_1-y),$$ and from this point, I obtained the conditional density $f_{X_1}(x_1|Y=y)$ and tried to calculated the conditional expectation. But, I ended up with having a complicated form in the integrand when calculating the conditional expectation $E[e^{-rX}\mu^G|X_1<X_2]$, and probably I could proceed further, but I'd like to ask you if there is an easier way to get $E[e^{-rX}\mu]$ without calculating all the density functions. Thank you very much!",,"['probability', 'probability-distributions', 'conditional-expectation', 'independence', 'exponential-distribution']"
66,Show rigorously that Pólya urn describes a martingale,Show rigorously that Pólya urn describes a martingale,,"We work with the famous Pólya urn problem. At the beginning one has $r$ red balls and $b$ blue ball in the urn. After each draw we add $t$ balls of the same color in the urn. $(X_n)_{n \in \mathbb N}$ is the share of red balls in the urn after $n$-th draw. I need to show that $(X_n)_{n \in \mathbb N}$ is a martingale rigorously (i.e. using only theorems and without imagination power based on real world experience). I select a filtration $(\mathcal F_n)_{n \in \mathbb N}=\sigma (X_1,...,X_n)$. I need to show that $E(X_{n+1}|\sigma (X_1,...,X_n))=X_n$ $E(X_{n+1}|\sigma (X_1,...,X_n))=E(\frac{lX_n+S}{l+t}|\sigma (X_1,...,X_n))=\frac{lX_n}{l+t}+\frac{E(S|\sigma (X_1,...,X_n))}{l+t}$ where $l$ is the number of balls in the urn after $n$-th draw and $S$ is the number of balls added after $n+1$-th draw (random variable), the last step is possible because $X_n$ is $\sigma (X_1,...,X_n)$ measurable. Further $E(S|\sigma (X_1,...,X_n))=tE(\mathcal I\{$read ball at $n+1$-th draw$\}|\sigma (X_1,...,X_n))$ How do I take it from here? Please note that I saw The Pólya urn model describes a martingale , and I do not consider it rigorous enough.","We work with the famous Pólya urn problem. At the beginning one has $r$ red balls and $b$ blue ball in the urn. After each draw we add $t$ balls of the same color in the urn. $(X_n)_{n \in \mathbb N}$ is the share of red balls in the urn after $n$-th draw. I need to show that $(X_n)_{n \in \mathbb N}$ is a martingale rigorously (i.e. using only theorems and without imagination power based on real world experience). I select a filtration $(\mathcal F_n)_{n \in \mathbb N}=\sigma (X_1,...,X_n)$. I need to show that $E(X_{n+1}|\sigma (X_1,...,X_n))=X_n$ $E(X_{n+1}|\sigma (X_1,...,X_n))=E(\frac{lX_n+S}{l+t}|\sigma (X_1,...,X_n))=\frac{lX_n}{l+t}+\frac{E(S|\sigma (X_1,...,X_n))}{l+t}$ where $l$ is the number of balls in the urn after $n$-th draw and $S$ is the number of balls added after $n+1$-th draw (random variable), the last step is possible because $X_n$ is $\sigma (X_1,...,X_n)$ measurable. Further $E(S|\sigma (X_1,...,X_n))=tE(\mathcal I\{$read ball at $n+1$-th draw$\}|\sigma (X_1,...,X_n))$ How do I take it from here? Please note that I saw The Pólya urn model describes a martingale , and I do not consider it rigorous enough.",,"['probability', 'martingales', 'polya-urn-model']"
67,Why is the supremum a random variable in the Glivenko–Cantelli theorem,Why is the supremum a random variable in the Glivenko–Cantelli theorem,,"According to wikipedia : Assume that $X_1,X_2,\dots$ are independent and identically-distributed random variables in $\mathbb{R}$ with common cumulative distribution function $F(x)$. The empirical distribution function for $X_1,\dots,X_n$ is defined by $$F_n(x)=\frac{1}{n}\sum_{i=1}^n I_{(-\infty,x]}(X_i)$$ where $I_C$ is the indicator function of the set $C$. ... Theorem $$\|F_n - F\|_\infty = \sup_{x\in \mathbb{R}} |F_n(x) - F(x)| {\longrightarrow} 0$$ almost surely. Now why is $\sup_{x\in \mathbb{R}} |F_n(x) - F(x)|$ even a random variable (i.e. that is, it's measurable)? I know the supremum for a countable set of RVs is a random variable, but here it's over an uncountable set $\mathbb{R}$.","According to wikipedia : Assume that $X_1,X_2,\dots$ are independent and identically-distributed random variables in $\mathbb{R}$ with common cumulative distribution function $F(x)$. The empirical distribution function for $X_1,\dots,X_n$ is defined by $$F_n(x)=\frac{1}{n}\sum_{i=1}^n I_{(-\infty,x]}(X_i)$$ where $I_C$ is the indicator function of the set $C$. ... Theorem $$\|F_n - F\|_\infty = \sup_{x\in \mathbb{R}} |F_n(x) - F(x)| {\longrightarrow} 0$$ almost surely. Now why is $\sup_{x\in \mathbb{R}} |F_n(x) - F(x)|$ even a random variable (i.e. that is, it's measurable)? I know the supremum for a countable set of RVs is a random variable, but here it's over an uncountable set $\mathbb{R}$.",,"['probability', 'probability-theory']"
68,Calculating probability of some event using geometric considerations,Calculating probability of some event using geometric considerations,,"I want to estimate exponentially the following probability: Let $\bf{U}\in\mathbb{R}^n$ be a random vector uniformly distributed on the $n$-dimensional hypersphere, centered at the origin with radius $R$, and let $A\in\mathbb{S}_{++}^{n\times n}$ be a positive definite and deterministic matrix. I want to estimate the probability that  $$ \text{Pr}(||\bf{v}-A\bf{U}||^2\approx n\alpha) = ?\ \ \ (1). $$ As example, when $A$ is an identity matrix, we have  $$ \text{Pr}(||\bf{v}-\bf{U}||^2\approx n\alpha) $$  which can be interpreted as the probability that a randomly vector $\bf{U}$ on the hypersphere ($R$) will fall on the hypersphere centered around $\bf{v}$ with radius $\approx\sqrt{n\alpha}$. Equivalently, we want to find the probability that a randomly vector $\bf{U}$ on the hypersphere ($R$) would have some ""correlation"" coefficient (Pearson product), $\beta$, with $\bf{v}$. This probability can be calculated as the fraction between the surface area of the $n-2$ dimensional ""circle"" with radius $R\sin(\gamma)$ (in which $\beta = \cos(\gamma)$), and the $n$ dimensional sphere of radius $R$. It is easily can be shown that as $n\to\infty$ this probability is given by $\exp(n\ln(1-\beta^2)/2)$. When we introduce the matrix $A$, then $\bf{Y} = AU$ lives on the the $n$-dimensional hyper-ellipsoid . Accordingly, we want to find the probability that a randomly vector $\bf{Y}$ on the hyper-ellipsoid will fall on the hypersphere centered around $\bf{v}$ with radius $\approx\sqrt{n\alpha}$. So we need to find the fraction between the surface area of the interaction of this two shapes, and the surface area of the hyper-ellipsoid. Any suggestions how to accomplish that, or, solving the problem in different way? Thank you!","I want to estimate exponentially the following probability: Let $\bf{U}\in\mathbb{R}^n$ be a random vector uniformly distributed on the $n$-dimensional hypersphere, centered at the origin with radius $R$, and let $A\in\mathbb{S}_{++}^{n\times n}$ be a positive definite and deterministic matrix. I want to estimate the probability that  $$ \text{Pr}(||\bf{v}-A\bf{U}||^2\approx n\alpha) = ?\ \ \ (1). $$ As example, when $A$ is an identity matrix, we have  $$ \text{Pr}(||\bf{v}-\bf{U}||^2\approx n\alpha) $$  which can be interpreted as the probability that a randomly vector $\bf{U}$ on the hypersphere ($R$) will fall on the hypersphere centered around $\bf{v}$ with radius $\approx\sqrt{n\alpha}$. Equivalently, we want to find the probability that a randomly vector $\bf{U}$ on the hypersphere ($R$) would have some ""correlation"" coefficient (Pearson product), $\beta$, with $\bf{v}$. This probability can be calculated as the fraction between the surface area of the $n-2$ dimensional ""circle"" with radius $R\sin(\gamma)$ (in which $\beta = \cos(\gamma)$), and the $n$ dimensional sphere of radius $R$. It is easily can be shown that as $n\to\infty$ this probability is given by $\exp(n\ln(1-\beta^2)/2)$. When we introduce the matrix $A$, then $\bf{Y} = AU$ lives on the the $n$-dimensional hyper-ellipsoid . Accordingly, we want to find the probability that a randomly vector $\bf{Y}$ on the hyper-ellipsoid will fall on the hypersphere centered around $\bf{v}$ with radius $\approx\sqrt{n\alpha}$. So we need to find the fraction between the surface area of the interaction of this two shapes, and the surface area of the hyper-ellipsoid. Any suggestions how to accomplish that, or, solving the problem in different way? Thank you!",,"['probability', 'probability-theory', 'probability-distributions']"
69,Selecting cards to form a fair game,Selecting cards to form a fair game,,"Background In an old card game we draw 2 cards from a pile of 2 red and 2 black cards without replacement. If the two cards have the same color (for instance red and red) you win. However, if the cards have opposite color you lose. This is a rich problem, especially if we instead look at the broader problem of drawing $2$ cards from a pile of $(n,m)$ cards, where we now have $n$ red and $m$ blue cards. After sorting out the information one can show that any solution must satisfy $$(n-m)^2 = n + m$$ from which it is not hard to deduce that every solution must be a pair of consecutive triangular numbers. $$(1,3), \ (3,6), \ (6,10), \ (10,15), \ldots$$ In other words we have $$T_2(n) = T_2(n-1) + n, \qquad T(n)=0, n\leq 1$$ Which of course also can be expressed as $T_2(n) = n(n+1)/2$ . So $\bigl(T_2(n), T_2(n+1)\bigl)$ forms every solution. My question is if similar beautiful patterns appear when we increase the number of cards we draw. Main statement Assume we have a pile of $(n,m)$ cards, where $n$ of the cards are red and $m$ are black and we draw $c$ cards from the pile (where $c \leq n + m$ ). Fix $n$ , how do we have to choose $m$ to obtain a fair game? E.g. a game where the probability of drawing a pile of cards of similar colors (red, red ..., red or black, black, ..., black) equals the probability of drawing cards of opposite color (any combination of red and black cards) For $c = 3$ it seems we have to find integer solutions to $$n(n-1)(n-2) + m(m-1)(m-2) = 3mn(n+m-2)$$ and this seems really hard. However, it seems $(1,5,3)$ is a solution. After an extensive computer search it seems $$(1,5), \ (5,20), \ (20,76), \ (76,285), \ (285,1065), \ (1065,3976), \ \ldots$$ Are the first few solutions when drawing three cards. It seems these satisfy $$ 	T_3(u) = 5 T_3(u-1) - 5 T_3(u-2) + T_3(u-3) \ \text{with} \ T_3(1) = 1 \ \text{and} \ T_3(u) = 0 \ \text{if} \ u \leq 0. $$ EDIT: Seems to boiling down to finding all integer pair such that $$     \binom{m}{c}\binom{n}{0} \Bigl/\binom{m+n}{c}\Bigr.      + \binom{m}{0}\binom{n}{c} \Bigl/\binom{m+n}{c}\Bigr. = \frac{1}{2}, $$ Where again $c \in \mathbb{N}_{\geq 2}$ and $c \leq n < m$ . The expression above can be ""simplified"" to $$\prod_{i=0}^{n-1} \frac{m+n-k-i}{m+n-i} + \prod_{i=0}^{m-1} \frac{n+m-k-i}{n+m-i} = \frac{1}{2}$$ and can be quite easily be numerically approximated. However, it does not lead me closer to finding every solution for every $c$ . EDIT 2: While I thought all solutions would be on the form $(a,b)$ , $(b,c)$ , $(c,d), \ldots$ this does not seem to be the case.  In particular for $c = 6$ we $$T_6(1) = (1,11), \qquad T_6(2) = (2,19)$$ interesting! Problems Let $T_c(n)$ be the $n$ 'th solution when drawing $c$ cards. Is it true that $T_c(1) = 2c - 1$ for every $c\geq 2$ ? Is there a general recurrence relation for $T_c(n)$ ? Is there a closed expression for $T_c(n)?$ Given a particular $c$ how can we find all pairs $(n,m)$ that form a fair game?","Background In an old card game we draw 2 cards from a pile of 2 red and 2 black cards without replacement. If the two cards have the same color (for instance red and red) you win. However, if the cards have opposite color you lose. This is a rich problem, especially if we instead look at the broader problem of drawing cards from a pile of cards, where we now have red and blue cards. After sorting out the information one can show that any solution must satisfy from which it is not hard to deduce that every solution must be a pair of consecutive triangular numbers. In other words we have Which of course also can be expressed as . So forms every solution. My question is if similar beautiful patterns appear when we increase the number of cards we draw. Main statement Assume we have a pile of cards, where of the cards are red and are black and we draw cards from the pile (where ). Fix , how do we have to choose to obtain a fair game? E.g. a game where the probability of drawing a pile of cards of similar colors (red, red ..., red or black, black, ..., black) equals the probability of drawing cards of opposite color (any combination of red and black cards) For it seems we have to find integer solutions to and this seems really hard. However, it seems is a solution. After an extensive computer search it seems Are the first few solutions when drawing three cards. It seems these satisfy EDIT: Seems to boiling down to finding all integer pair such that Where again and . The expression above can be ""simplified"" to and can be quite easily be numerically approximated. However, it does not lead me closer to finding every solution for every . EDIT 2: While I thought all solutions would be on the form , , this does not seem to be the case.  In particular for we interesting! Problems Let be the 'th solution when drawing cards. Is it true that for every ? Is there a general recurrence relation for ? Is there a closed expression for Given a particular how can we find all pairs that form a fair game?","2 (n,m) n m (n-m)^2 = n + m (1,3), \ (3,6), \ (6,10), \ (10,15), \ldots T_2(n) = T_2(n-1) + n, \qquad T(n)=0, n\leq 1 T_2(n) = n(n+1)/2 \bigl(T_2(n), T_2(n+1)\bigl) (n,m) n m c c \leq n + m n m c = 3 n(n-1)(n-2) + m(m-1)(m-2) = 3mn(n+m-2) (1,5,3) (1,5), \ (5,20), \ (20,76), \ (76,285), \ (285,1065), \ (1065,3976), \ \ldots 
	T_3(u) = 5 T_3(u-1) - 5 T_3(u-2) + T_3(u-3) \ \text{with} \ T_3(1) = 1 \ \text{and} \ T_3(u) = 0 \ \text{if} \ u \leq 0.
      \binom{m}{c}\binom{n}{0} \Bigl/\binom{m+n}{c}\Bigr. 
    + \binom{m}{0}\binom{n}{c} \Bigl/\binom{m+n}{c}\Bigr. = \frac{1}{2},  c \in \mathbb{N}_{\geq 2} c \leq n < m \prod_{i=0}^{n-1} \frac{m+n-k-i}{m+n-i} + \prod_{i=0}^{m-1} \frac{n+m-k-i}{n+m-i} = \frac{1}{2} c (a,b) (b,c) (c,d), \ldots c = 6 T_6(1) = (1,11), \qquad T_6(2) = (2,19) T_c(n) n c T_c(1) = 2c - 1 c\geq 2 T_c(n) T_c(n)? c (n,m)","['probability', 'combinatorics', 'game-theory', 'card-games', 'fair-division']"
70,roll a dice repeatedly until the sum goes above 63,roll a dice repeatedly until the sum goes above 63,,"I saw this question online but I don't know if my solution is right or not. Here is the original question: Roll a die repeatedly. Say that you stop when the sum goes above 63. What is the probability that the second to last sum value (total) was X. Make a market on this  probability. Ie what is your 90 percent confidence interval. This is my solution: X=63, 6 possible last roll as 1,2,3,4,5,6; X=62, 5 possible last roll as 2,3,4,5,6; X=61, 4 possible last roll as 3,4,5,6; X=60, 3 possible last roll as 4,5,6; X=59, 2 possible last roll as 5,6; X=58, 1 possible last roll as 6. BUT I don't know if it's right to think backward instead of considering the possible second to last value first? i.e. how many possibility to get a 63 regardless of last roll. Thank you very much!","I saw this question online but I don't know if my solution is right or not. Here is the original question: Roll a die repeatedly. Say that you stop when the sum goes above 63. What is the probability that the second to last sum value (total) was X. Make a market on this  probability. Ie what is your 90 percent confidence interval. This is my solution: X=63, 6 possible last roll as 1,2,3,4,5,6; X=62, 5 possible last roll as 2,3,4,5,6; X=61, 4 possible last roll as 3,4,5,6; X=60, 3 possible last roll as 4,5,6; X=59, 2 possible last roll as 5,6; X=58, 1 possible last roll as 6. BUT I don't know if it's right to think backward instead of considering the possible second to last value first? i.e. how many possibility to get a 63 regardless of last roll. Thank you very much!",,"['probability', 'dice']"
71,Probability of picking 4 red balls,Probability of picking 4 red balls,,There are $6$ red balls and $5$ blue balls in a jar. You pick any $4$ balls without looking in  the jar. What is the probability that you would be having $4$ red balls in hand? Note that you're picking up all the $4$ balls in one single attempt and not one-by-one. Also balls of same colour are to be considered as identical.  I tried this and got the answer as $4/11$ which was wrong. I can't figure out what the cases (sample space) would be.,There are $6$ red balls and $5$ blue balls in a jar. You pick any $4$ balls without looking in  the jar. What is the probability that you would be having $4$ red balls in hand? Note that you're picking up all the $4$ balls in one single attempt and not one-by-one. Also balls of same colour are to be considered as identical.  I tried this and got the answer as $4/11$ which was wrong. I can't figure out what the cases (sample space) would be.,,"['probability', 'combinations']"
72,Probability that a coin lands on tails an odd number of times when it is tossed $100$ times [duplicate],Probability that a coin lands on tails an odd number of times when it is tossed  times [duplicate],100,"This question already has answers here : A coin is tossed $n$ times. What is the probability of getting odd number of heads? [duplicate] (5 answers) Closed 10 months ago . The community reviewed whether to reopen this question 4 months ago and left it closed: Original close reason(s) were not resolved A coin is tossed 100 times , Find the probability that tail occurs odd number of times! I do not know the answer, but I tried this, that there are these $4$ possible outcomes in which tossing of a coin $100$ times can unfold. head occurs odd times head occurs even times tail occurs odd times tail occurs even times Getting a head is equally likely as getting a tail, similarly for odd times and even times. Thus, all of these events must have same the probability, i.e. $\dfrac{1}{4}$ . Is this the correct answer? Is there an alternate way of solving this problem? Lets hear it! Remark This question was closed for being a duplicate of A coin is tossed $n$ times. What is the probability of getting odd number of heads? . However, the latter was posted in Nov 17, 2017, hence more than 5 years after this one.","This question already has answers here : A coin is tossed $n$ times. What is the probability of getting odd number of heads? [duplicate] (5 answers) Closed 10 months ago . The community reviewed whether to reopen this question 4 months ago and left it closed: Original close reason(s) were not resolved A coin is tossed 100 times , Find the probability that tail occurs odd number of times! I do not know the answer, but I tried this, that there are these possible outcomes in which tossing of a coin times can unfold. head occurs odd times head occurs even times tail occurs odd times tail occurs even times Getting a head is equally likely as getting a tail, similarly for odd times and even times. Thus, all of these events must have same the probability, i.e. . Is this the correct answer? Is there an alternate way of solving this problem? Lets hear it! Remark This question was closed for being a duplicate of A coin is tossed $n$ times. What is the probability of getting odd number of heads? . However, the latter was posted in Nov 17, 2017, hence more than 5 years after this one.",4 100 \dfrac{1}{4},['probability']
73,WHY are there two kinds of 'possible choice' questions?,WHY are there two kinds of 'possible choice' questions?,,"I am studying for my GED. I was homeschooled, so most of the math topics covered are fairly easy, but there's one which I never went over, and which is giving me some trouble. I understand how to do the problems. The math works out. The trouble is that I don't understand why the process to get the solution is different. I was hoping someone here could explain it in terms I can understand. I'm dealing with what my study guide terms 'counting' questions. They deal with the number of possible choices in a given scenario. Here's a typical question: A DJ has enough time to play four songs. She has seven different songs to choose from. How many different orderings of songs can she choose? This is fairly straightforward. The work looks like $(7)(6)(5)(4)$. I understand why this works. She has seven choices first, then six, and so on. It's the next type of question which I can't figure out: A DJ is choosing four new records for his collection. He has seven available choices. How many different groups of records can he choose? This one starts out like the first one, but there's an additional step. You divide thusly: $\frac{(7)(6)(5)(4)}{(4)(3)(2)(1)}$. I know where the numbers are coming from, and how the math works. But I would like to know why. If I understand the principle, the problem will be much easier. The book explains that this is because 'order does not matter'. That doesn't make any sense, as clearly order doesn't matter in the first problem either. There's no further explanation. I need to understand why there is an additional step, so that I will be able to spot the differences between the two problems on the test. Note: I'm not asking for how to solve the problem, or how the math works. I'm asking why two problems, which, to me, look identical, are solved differently.","I am studying for my GED. I was homeschooled, so most of the math topics covered are fairly easy, but there's one which I never went over, and which is giving me some trouble. I understand how to do the problems. The math works out. The trouble is that I don't understand why the process to get the solution is different. I was hoping someone here could explain it in terms I can understand. I'm dealing with what my study guide terms 'counting' questions. They deal with the number of possible choices in a given scenario. Here's a typical question: A DJ has enough time to play four songs. She has seven different songs to choose from. How many different orderings of songs can she choose? This is fairly straightforward. The work looks like $(7)(6)(5)(4)$. I understand why this works. She has seven choices first, then six, and so on. It's the next type of question which I can't figure out: A DJ is choosing four new records for his collection. He has seven available choices. How many different groups of records can he choose? This one starts out like the first one, but there's an additional step. You divide thusly: $\frac{(7)(6)(5)(4)}{(4)(3)(2)(1)}$. I know where the numbers are coming from, and how the math works. But I would like to know why. If I understand the principle, the problem will be much easier. The book explains that this is because 'order does not matter'. That doesn't make any sense, as clearly order doesn't matter in the first problem either. There's no further explanation. I need to understand why there is an additional step, so that I will be able to spot the differences between the two problems on the test. Note: I'm not asking for how to solve the problem, or how the math works. I'm asking why two problems, which, to me, look identical, are solved differently.",,"['probability', 'permutations', 'combinations']"
74,"Probability that on three rolls of dice, there will be at least one 6 showing up?","Probability that on three rolls of dice, there will be at least one 6 showing up?",,"What is the probability that on three rolls of dice, there will be at least one 6 showing up? Attempt: Since there can be one six or two sixes or three sixes on three rolls, I considered separate cases and added them up. So $(1/6)(5/6)(5/6) + (1/6)(1/6)(5/6) + (1/6)(1/6)(1/6) = 31/216$, but answer is incorrect as per book.  Can anyone suggest where I am wrong ?","What is the probability that on three rolls of dice, there will be at least one 6 showing up? Attempt: Since there can be one six or two sixes or three sixes on three rolls, I considered separate cases and added them up. So $(1/6)(5/6)(5/6) + (1/6)(1/6)(5/6) + (1/6)(1/6)(1/6) = 31/216$, but answer is incorrect as per book.  Can anyone suggest where I am wrong ?",,['probability']
75,Why is my explanation wrong?,Why is my explanation wrong?,,"A class of $30$ students, J. being one of them, has $5$ classes today. What is the chance, that J. will be the chosen student to explain the    homework in at least two classes? What is the chance that someone will be chosen at least twice? My solution is the following: The probability for J. being chosen at least twice is $$\left( \frac{1}{30} \right)^2 \cdot \left( \frac{29}{30} \right)^3 + \left(\frac{1}{30} \right)^3 \cdot \left( \frac{29}{30} \right)^2 + \left( \frac{1}{30} \right)^4 \cdot \left( \frac{29}{30} \right) + \left( \frac{1}{30} \right)^5 \approx 0.104\%$$ The answer for the second question is simply J.'s probability multiplied by the number of students, approcimately $3.12\%$ We had a debate with a fellow student about this explanation, but couldn't convince each other. Is my explanation correct, or if not, where did I make a mistake?","A class of students, J. being one of them, has classes today. What is the chance, that J. will be the chosen student to explain the    homework in at least two classes? What is the chance that someone will be chosen at least twice? My solution is the following: The probability for J. being chosen at least twice is The answer for the second question is simply J.'s probability multiplied by the number of students, approcimately We had a debate with a fellow student about this explanation, but couldn't convince each other. Is my explanation correct, or if not, where did I make a mistake?",30 5 \left( \frac{1}{30} \right)^2 \cdot \left( \frac{29}{30} \right)^3 + \left(\frac{1}{30} \right)^3 \cdot \left( \frac{29}{30} \right)^2 + \left( \frac{1}{30} \right)^4 \cdot \left( \frac{29}{30} \right) + \left( \frac{1}{30} \right)^5 \approx 0.104\% 3.12\%,['probability']
76,pigeonhole principle clarification,pigeonhole principle clarification,,Would the following statement be applicable to the pigeonhole principle? Or can I simply do $100 \times 50 = 5000$? What is least amount of students in a school to guarantee that there are at least 100 students from the same state?,Would the following statement be applicable to the pigeonhole principle? Or can I simply do $100 \times 50 = 5000$? What is least amount of students in a school to guarantee that there are at least 100 students from the same state?,,"['probability', 'combinatorics', 'pigeonhole-principle']"
77,Variance of a sum of IID random variables.,Variance of a sum of IID random variables.,,"Let's say we have a sequence of $n$ IID random variables, $I_i$. Let's define a new random variable which is their sum: $$S = \sum_i I_i$$ To calculate the variance of $S$ we can say - $$V(S) = \sum_i V(I_i) = nV(I_1)$$ Or we can also say that $S$ has the same distribution as $nI_1$ So, we should have $V(S) = V(nI_1) = n^2V(I_1)$. This is of course, in direct contradiction to what we got above. What am I missing?","Let's say we have a sequence of $n$ IID random variables, $I_i$. Let's define a new random variable which is their sum: $$S = \sum_i I_i$$ To calculate the variance of $S$ we can say - $$V(S) = \sum_i V(I_i) = nV(I_1)$$ Or we can also say that $S$ has the same distribution as $nI_1$ So, we should have $V(S) = V(nI_1) = n^2V(I_1)$. This is of course, in direct contradiction to what we got above. What am I missing?",,"['probability', 'random-variables', 'independence', 'variance']"
78,Probability of obtaining a heads on the coin before a 1 or 2 on the die?,Probability of obtaining a heads on the coin before a 1 or 2 on the die?,,"I came across this question recently and can't seem to find the correct approach. Any help would be appreciated! An experiment consists of first tossing an unbiased coin and then rolling a fair die. If we perform this experiment successively, what is the probability of obtaining a heads on the coin before a $1$ or $2$ on the die? $\mathbb P(\textrm{Heads})=\frac12$ $\mathbb P(1,2)=\frac13$ If $A_i$ represents the event that a $1$ or a $2$ is rolled on the $i^{th}$ toss, then I have to find the following: $$\bigcup^{\infty}_{i=1}\mathbb P(A_i).$$ But I am  not sure how to find this and also incorporate the probability of landing on heads before this... Am I approaching this correctly or should I be assigning random variables and working from there?","I came across this question recently and can't seem to find the correct approach. Any help would be appreciated! An experiment consists of first tossing an unbiased coin and then rolling a fair die. If we perform this experiment successively, what is the probability of obtaining a heads on the coin before a or on the die? If represents the event that a or a is rolled on the toss, then I have to find the following: But I am  not sure how to find this and also incorporate the probability of landing on heads before this... Am I approaching this correctly or should I be assigning random variables and working from there?","1 2 \mathbb P(\textrm{Heads})=\frac12 \mathbb P(1,2)=\frac13 A_i 1 2 i^{th} \bigcup^{\infty}_{i=1}\mathbb P(A_i).","['probability', 'dice']"
79,chance on throwing a six with 6 dice,chance on throwing a six with 6 dice,,"The chance to throw a 6 with one die is 1/6 And 6 times 1/6 = 1 So, if I throw with 6 dice, the chance to throw at least 1 six should be 1. But when I throw 6 dice, I sometimes don't throw any 6 at all.. How come?","The chance to throw a 6 with one die is 1/6 And 6 times 1/6 = 1 So, if I throw with 6 dice, the chance to throw at least 1 six should be 1. But when I throw 6 dice, I sometimes don't throw any 6 at all.. How come?",,['probability']
80,The probability that in a game of bridge each of the four players is dealt one ace,The probability that in a game of bridge each of the four players is dealt one ace,,"The question is to show that the probability that each of the four players in a game of bridge receives one ace is $$ \frac{24 \cdot 48! \cdot13^4}{52!}$$ My explanation so far is that there are $4!$ ways to arrange the 4 aces, $48!$ ways to arrange the other cards, and since each arrangement is equally likely we divide by $52!$.  I believe the $13^4$ represents the number of arrangements to distribute 4 aces among 13 cards, but I don't see why we must multiply by this value as well?","The question is to show that the probability that each of the four players in a game of bridge receives one ace is $$ \frac{24 \cdot 48! \cdot13^4}{52!}$$ My explanation so far is that there are $4!$ ways to arrange the 4 aces, $48!$ ways to arrange the other cards, and since each arrangement is equally likely we divide by $52!$.  I believe the $13^4$ represents the number of arrangements to distribute 4 aces among 13 cards, but I don't see why we must multiply by this value as well?",,"['probability', 'combinatorics']"
81,Probability that a random 13-card hand contains at least 3 cards of every suit?,Probability that a random 13-card hand contains at least 3 cards of every suit?,,"A random 13-card hand is dealt from a standard deck of cards. What is the probability   that the hand contains at least 3 cards of every suit? (Introduction to Probability, p.36) My solution: There are $\binom{52}{13}$ possible hands. Because there are 13 cards for the hand, to obtain at least three cards of one suit per hand, we need to have exactly three cards of one suit per hand plus one additional card of any suit, thus $\binom{13}{3}^4 * 4 \binom{10}{1}$ Result: $\frac{40*\binom{13}{3}^4}{\binom{52}{13}} = 0.4214$ However, simulating it in R yields: deck <- rep(1:4, 13) out <- replicate(1e5,{   hand <- sample(deck, size=13, replace=FALSE)   all(table(hand) >= 3) }) mean(out) > 0.14387 Can anybody tell me what is wrong? EDIT I'm afraid, the correct code should be. deck <- rep(1:4, 13) out <- replicate(1e5,{   hand <- sample(deck, size=13, replace=FALSE)   length(table(hand))==4 & all(table(hand) >= 3 ) }) mean(out) > 0.10639","A random 13-card hand is dealt from a standard deck of cards. What is the probability   that the hand contains at least 3 cards of every suit? (Introduction to Probability, p.36) My solution: There are $\binom{52}{13}$ possible hands. Because there are 13 cards for the hand, to obtain at least three cards of one suit per hand, we need to have exactly three cards of one suit per hand plus one additional card of any suit, thus $\binom{13}{3}^4 * 4 \binom{10}{1}$ Result: $\frac{40*\binom{13}{3}^4}{\binom{52}{13}} = 0.4214$ However, simulating it in R yields: deck <- rep(1:4, 13) out <- replicate(1e5,{   hand <- sample(deck, size=13, replace=FALSE)   all(table(hand) >= 3) }) mean(out) > 0.14387 Can anybody tell me what is wrong? EDIT I'm afraid, the correct code should be. deck <- rep(1:4, 13) out <- replicate(1e5,{   hand <- sample(deck, size=13, replace=FALSE)   length(table(hand))==4 & all(table(hand) >= 3 ) }) mean(out) > 0.10639",,"['probability', 'combinatorics', 'card-games']"
82,Find the probability of getting two sixes in $5$ throws of a die.,Find the probability of getting two sixes in  throws of a die.,5,"In an experiment, a fair die is rolled until two sixes are obtained in succession. What is the probability that the experiment will end in the fifth trial? My work: The probability of not getting a $6$ in the first roll is $\frac{5}{6}$ Similarly for the second and third throw. Again the probability of getting a $6$ is fourth roll is $\frac{1}{6}$. So the probability of ending the game in the fifth roll is $\frac{5^3}{6^3}\times\frac{1}{6^2}=\frac{125}{6^5}$. But the answer is not correct. Where is my mistake? Help please.","In an experiment, a fair die is rolled until two sixes are obtained in succession. What is the probability that the experiment will end in the fifth trial? My work: The probability of not getting a $6$ in the first roll is $\frac{5}{6}$ Similarly for the second and third throw. Again the probability of getting a $6$ is fourth roll is $\frac{1}{6}$. So the probability of ending the game in the fifth roll is $\frac{5^3}{6^3}\times\frac{1}{6^2}=\frac{125}{6^5}$. But the answer is not correct. Where is my mistake? Help please.",,"['probability', 'probability-theory']"
83,Probability of $2$ people being together out of a group of $4$.,Probability of  people being together out of a group of .,2 4,There were $2$ people who wanted to be in a group together. Those $2$ people were in a pool of $4$ people. Someone would randomly select $2$ people in a row and those people would be in a group together. The remaining $2$ would also be in a group. What the probability of those $2$ people who wanted to be in the same group actually being in the same group? What I tried Lets assume that the $2$ who want to be together are person A and B respectively and person C and D are the other $2$. The probability of choosing person A and B is $\dfrac 14 \cdot \dfrac 13 = \dfrac 1{12}.$,There were $2$ people who wanted to be in a group together. Those $2$ people were in a pool of $4$ people. Someone would randomly select $2$ people in a row and those people would be in a group together. The remaining $2$ would also be in a group. What the probability of those $2$ people who wanted to be in the same group actually being in the same group? What I tried Lets assume that the $2$ who want to be together are person A and B respectively and person C and D are the other $2$. The probability of choosing person A and B is $\dfrac 14 \cdot \dfrac 13 = \dfrac 1{12}.$,,"['probability', 'combinations']"
84,Probability that sum of independent uniform variables is less than 1,Probability that sum of independent uniform variables is less than 1,,"I would like to determine the probability $\mathbb{P}(X_1+\dots+X_n\leq 1)$, where $X=(X_i)_{1\leq i\leq n}$ is a family of independent uniform random variables on $[0,1]$. My first idea is to do this by induction. The first three base cases are straightforward to determine and give us $\mathbb{P}(X_1\leq 1)=1$, $\mathbb{P}(X_1+X_2\leq 1)=\frac{1}{2}$ and $\mathbb{P}(X_1+X_2+X_3\leq 1)=\frac{1}{6}$, which suggests that $\mathbb{P}(X_1+\dots+X_n\leq 1)=\frac{1}{n!}$. Supposing this is true for a certain arbitrary integer $n$, I am having difficulties establishing the result for $n+1$, i.e. $\mathbb{P}(X_1+\dots+X_n+X_{n+1}\leq 1)=\frac{1}{(n+1)!}$. I believe the starting point should be: $$\mathbb{P}(X_1+\dots+X_n+X_{n+1}\leq 1)=\mathbb{P}(X_1+\dots+X_n\leq 1-X_{n+1}),$$ and then somehow condition on $X_{n+1}$, but I am stuck at this point of the calculation. Any ideas of references to literature or even an alternative direct proof would be greatly appreciated.","I would like to determine the probability $\mathbb{P}(X_1+\dots+X_n\leq 1)$, where $X=(X_i)_{1\leq i\leq n}$ is a family of independent uniform random variables on $[0,1]$. My first idea is to do this by induction. The first three base cases are straightforward to determine and give us $\mathbb{P}(X_1\leq 1)=1$, $\mathbb{P}(X_1+X_2\leq 1)=\frac{1}{2}$ and $\mathbb{P}(X_1+X_2+X_3\leq 1)=\frac{1}{6}$, which suggests that $\mathbb{P}(X_1+\dots+X_n\leq 1)=\frac{1}{n!}$. Supposing this is true for a certain arbitrary integer $n$, I am having difficulties establishing the result for $n+1$, i.e. $\mathbb{P}(X_1+\dots+X_n+X_{n+1}\leq 1)=\frac{1}{(n+1)!}$. I believe the starting point should be: $$\mathbb{P}(X_1+\dots+X_n+X_{n+1}\leq 1)=\mathbb{P}(X_1+\dots+X_n\leq 1-X_{n+1}),$$ and then somehow condition on $X_{n+1}$, but I am stuck at this point of the calculation. Any ideas of references to literature or even an alternative direct proof would be greatly appreciated.",,"['probability', 'probability-theory', 'probability-distributions', 'uniform-distribution']"
85,Intuitive meaning of the probability density function at a point,Intuitive meaning of the probability density function at a point,,"I understand how to integrate probability density functions to find probability within a certain range. However, what I don't understand is what it would mean to set the variable (say $x$ or $y$) to a certain value and evaluate the pdf as you would evaluate any other function. I know this happens when dealing with conditional density functions in a multivariable situation. But I'm a little confused as to what this actually signifies.","I understand how to integrate probability density functions to find probability within a certain range. However, what I don't understand is what it would mean to set the variable (say $x$ or $y$) to a certain value and evaluate the pdf as you would evaluate any other function. I know this happens when dealing with conditional density functions in a multivariable situation. But I'm a little confused as to what this actually signifies.",,"['probability', 'integration', 'statistics', 'continuity']"
86,"Flip a coin until a head comes up. Why is ""infinitely many tails"" an event we need to consider?","Flip a coin until a head comes up. Why is ""infinitely many tails"" an event we need to consider?",,"Suppose we're considering the problem of flipping a coin until ""heads"" comes up.  The sequences H, TH, TTH, TTTH, ... are all part of the sample space we need to consider. But what about the sequence TTT... (infinitely many tails)?  I would think that this ""event"" should be excluded by definition, because our experiment doesn't end until ""heads"" comes up.  Nonetheless, one could imagine a scenario where ""heads"" never comes up. So when should we include TTT... in our sample space, and in doing so, what does that ""buy"" us?","Suppose we're considering the problem of flipping a coin until ""heads"" comes up.  The sequences H, TH, TTH, TTTH, ... are all part of the sample space we need to consider. But what about the sequence TTT... (infinitely many tails)?  I would think that this ""event"" should be excluded by definition, because our experiment doesn't end until ""heads"" comes up.  Nonetheless, one could imagine a scenario where ""heads"" never comes up. So when should we include TTT... in our sample space, and in doing so, what does that ""buy"" us?",,"['probability', 'probability-theory']"
87,Probability of deck of cards such that each person receives one ace,Probability of deck of cards such that each person receives one ace,,"Suppose that a deck of 52 cards containing four aces is shuffled thoroughly and the cards are then distributed among four players so that each player receives 13 cards. Determine the probability that each player will receive one ace. The answer to this is given as$$\frac{13^4}{\binom {52}4}$$ My doubt is the following: The book justifies ${\binom {52}{4}}$ as number of possible different combinations of the four positions in the deck occupied by 4 aces. That sounds like a case of arrangements to me, so shouldn't we think about permutations and not combinations if we are concerned about how the aces are to be arranged in the deck ?. Shouldn't the denominator be ${\binom {52}{13}}$ since you are choosing 13 cards for 4 people.","Suppose that a deck of 52 cards containing four aces is shuffled thoroughly and the cards are then distributed among four players so that each player receives 13 cards. Determine the probability that each player will receive one ace. The answer to this is given as$$\frac{13^4}{\binom {52}4}$$ My doubt is the following: The book justifies ${\binom {52}{4}}$ as number of possible different combinations of the four positions in the deck occupied by 4 aces. That sounds like a case of arrangements to me, so shouldn't we think about permutations and not combinations if we are concerned about how the aces are to be arranged in the deck ?. Shouldn't the denominator be ${\binom {52}{13}}$ since you are choosing 13 cards for 4 people.",,"['probability', 'combinatorics']"
88,Suppose we roll a fair $6$ sided die repeatedly. Find the expected number of rolls required to see $3$ of the same number in succession.,Suppose we roll a fair  sided die repeatedly. Find the expected number of rolls required to see  of the same number in succession.,6 3,"Suppose we roll a fair six sided die repeatedly. Find the expected number of rolls required to see $3$ of the same number in succession From the link below, I learned that $258$ rolls are expected to see 3 sixes appear in succession.  So I'm thinking that for a same (any) number, the rolls expected would be $258/6 = 43$ . But I'm unsure how to show this and whether it really is correct. How many times to roll a die before getting two consecutive sixes?","Suppose we roll a fair six sided die repeatedly. Find the expected number of rolls required to see of the same number in succession From the link below, I learned that rolls are expected to see 3 sixes appear in succession.  So I'm thinking that for a same (any) number, the rolls expected would be . But I'm unsure how to show this and whether it really is correct. How many times to roll a die before getting two consecutive sixes?",3 258 258/6 = 43,"['probability', 'probability-theory']"
89,Find the fraction where the decimal expansion is infinite?,Find the fraction where the decimal expansion is infinite?,,"Find the fraction with integers for the numerator and denominator, where the decimal expansion is $0.11235.....$ The numerator and denominator must be less than $100$. Find the fraction. I believe I can use generating functions here to get $1+x+2x^2+3x^3+5x^4+.....$, but I do not know how to apply it.","Find the fraction with integers for the numerator and denominator, where the decimal expansion is $0.11235.....$ The numerator and denominator must be less than $100$. Find the fraction. I believe I can use generating functions here to get $1+x+2x^2+3x^3+5x^4+.....$, but I do not know how to apply it.",,"['probability', 'power-series', 'generating-functions', 'fractions']"
90,Coin sequence paradox from Martin Gardner's book,Coin sequence paradox from Martin Gardner's book,,"""An event less frequent in the long run is likely to happen before a more frequent event!"" How can I show that THTH is more likely to turn up before HTHH with a probability of 9/14, even though waiting time of THTH is 20 and HTHH, 18! I would be very thankful if you could show me the way of calculating the probability of turning up earlier, and the waiting time. Thank you!","""An event less frequent in the long run is likely to happen before a more frequent event!"" How can I show that THTH is more likely to turn up before HTHH with a probability of 9/14, even though waiting time of THTH is 20 and HTHH, 18! I would be very thankful if you could show me the way of calculating the probability of turning up earlier, and the waiting time. Thank you!",,['probability']
91,Expectation of a die roll summed,Expectation of a die roll summed,,"I know this problem involves conditional probability, but I'm confused as to how to tackle it. Assume a die is rolled over and over, where the total is summed. If the die's roll is $\geq 3$ the game stops and the summed total is read out. What is the expectation of the total? What is the expected number of times the die was rolled?","I know this problem involves conditional probability, but I'm confused as to how to tackle it. Assume a die is rolled over and over, where the total is summed. If the die's roll is $\geq 3$ the game stops and the summed total is read out. What is the expectation of the total? What is the expected number of times the die was rolled?",,"['probability', 'expectation', 'conditional-expectation']"
92,What is the expected number of dice one needs to roll to get any monotonically increasing series of 1 to 6?,What is the expected number of dice one needs to roll to get any monotonically increasing series of 1 to 6?,,"Similar to: ""What is the expected number of dice one needs to roll to get 1,2,3,4,5,6 in order?"" but we allow repeats so 1,1,2,2,3,4,4,4,4,5,5,6 would count. My answer (or simulation) is flawed as I cannot get reasonable agreement. My C++11 simulation code is below. I fear that the 'bug' is more likely to be in my algebra #include <iostream> #include <random>  int main(int argc, char* argv[]) {   int seed = 101;   if ( argc>1 )     seed = atoi(argv[1]);    std::uniform_int_distribution<int> distribution(1,6);   std::mt19937 engine(seed);   auto generator = std::bind(distribution,engine);    int rollForSequenceSum = 0;   int multiples = 1000;   for ( int i=0; i<multiples; ++i )   {     int rollCount = 0;     int nextInSequence = 1;      while ( nextInSequence <= 6 )     {       ++rollCount;       int random = generator();       if ( random == nextInSequence )       {         ++nextInSequence;       }        else if ( random == (nextInSequence-1) )       {         //Do nothing       }        else if ( random == 1 )       {         nextInSequence = 2;       }       else       {         nextInSequence = 1;       }     }     rollForSequenceSum += rollCount;   }   double mean = (double) rollForSequenceSum / (double) multiples;   std::cout << mean << std::endl; }","Similar to: ""What is the expected number of dice one needs to roll to get 1,2,3,4,5,6 in order?"" but we allow repeats so 1,1,2,2,3,4,4,4,4,5,5,6 would count. My answer (or simulation) is flawed as I cannot get reasonable agreement. My C++11 simulation code is below. I fear that the 'bug' is more likely to be in my algebra #include <iostream> #include <random>  int main(int argc, char* argv[]) {   int seed = 101;   if ( argc>1 )     seed = atoi(argv[1]);    std::uniform_int_distribution<int> distribution(1,6);   std::mt19937 engine(seed);   auto generator = std::bind(distribution,engine);    int rollForSequenceSum = 0;   int multiples = 1000;   for ( int i=0; i<multiples; ++i )   {     int rollCount = 0;     int nextInSequence = 1;      while ( nextInSequence <= 6 )     {       ++rollCount;       int random = generator();       if ( random == nextInSequence )       {         ++nextInSequence;       }        else if ( random == (nextInSequence-1) )       {         //Do nothing       }        else if ( random == 1 )       {         nextInSequence = 2;       }       else       {         nextInSequence = 1;       }     }     rollForSequenceSum += rollCount;   }   double mean = (double) rollForSequenceSum / (double) multiples;   std::cout << mean << std::endl; }",,"['probability', 'statistics', 'dice']"
93,A Game in Probability,A Game in Probability,,You and n other players ( $n \ge 1$ ) play a game. Each player chooses a real number between 0 and 1. A referee also chooses a number between 0 and 1. The player who chooses the closest number to the referee's number wins. What should be your choice. Will it depend on $n$ ? Assume that the n players (other than yourself) and the referee choose the numbers uniformly between 0 and 1. Can someone give a sketch of the solution? I've been trying this but unable to produce an answer. Edit:You may ignore two or more players choosing the same number,You and n other players ( ) play a game. Each player chooses a real number between 0 and 1. A referee also chooses a number between 0 and 1. The player who chooses the closest number to the referee's number wins. What should be your choice. Will it depend on ? Assume that the n players (other than yourself) and the referee choose the numbers uniformly between 0 and 1. Can someone give a sketch of the solution? I've been trying this but unable to produce an answer. Edit:You may ignore two or more players choosing the same number,n \ge 1 n,"['probability', 'game-theory']"
94,Finding probability of other child also being a boy [duplicate],Finding probability of other child also being a boy [duplicate],,"This question already has answers here : In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? (21 answers) Closed 10 years ago . A man visits a couple who have two children.One of them, a boy, comes in to the room. Find the probability p that other is also a boy a) 1/3 b) 2/3 c) 1/2 d) 3/4 Correct Ans: a) 1/3 However I am getting answer as 1/2.My solution is as follows. The couple has two children, hence the sample space is as follows. B- Boy G - Girl BB BG GG ( BG and GB mean the same thing as Girl,Boy), but it is already known that one is boy.So the sample space reduces to BB BG So now p is 1/2 Is there some mistake is my approach ?","This question already has answers here : In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? (21 answers) Closed 10 years ago . A man visits a couple who have two children.One of them, a boy, comes in to the room. Find the probability p that other is also a boy a) 1/3 b) 2/3 c) 1/2 d) 3/4 Correct Ans: a) 1/3 However I am getting answer as 1/2.My solution is as follows. The couple has two children, hence the sample space is as follows. B- Boy G - Girl BB BG GG ( BG and GB mean the same thing as Girl,Boy), but it is already known that one is boy.So the sample space reduces to BB BG So now p is 1/2 Is there some mistake is my approach ?",,['probability']
95,Conditional probability,Conditional probability,,"Given the events $A, B$ the conditional probability of $A$ supposing that $B$ happened is: $$P(A | B)=\frac{P(A\cap B )}{P(B)}$$ Can we write that for the Events $A,B,C$, the following is true? $$P(A | B\cap C)=\frac{P(A\cap B\cap C )}{P(B\cap C)}$$ I have couple of problems with the equation above; it doesn't always fit my logical solutions. If it's not true, I'll be happy to hear why. Thank you.","Given the events $A, B$ the conditional probability of $A$ supposing that $B$ happened is: $$P(A | B)=\frac{P(A\cap B )}{P(B)}$$ Can we write that for the Events $A,B,C$, the following is true? $$P(A | B\cap C)=\frac{P(A\cap B\cap C )}{P(B\cap C)}$$ I have couple of problems with the equation above; it doesn't always fit my logical solutions. If it's not true, I'll be happy to hear why. Thank you.",,[]
96,Probability of a two-headed coin given a few sample flips?,Probability of a two-headed coin given a few sample flips?,,"A probability problem was posed to me, and I am terrible at probability. It was first posed to me like this: I have 5 coins. One of them is a   two-headed coin, and the others are   normal coins. I pick a coin, and then   I flip that coin three times; each   time is heads. What is the probability   that the coin is two-headed? My answer was, naturally, 1/5. I am still of the opinion that it's the correct answer to that particular phrasing (do you agree?). But of course I was told this is a wrong answer. After some thought, I came up with the following phrasing which is what was really meant: You are given a coin and told that it   has a 1/5 chance that it is   double-headed, otherwise it is a   normal coin. You are allowed three   flips of the coin. Upon doing these,   you receive three heads. What is the   probability that your coin is   double-headed? Now I have two questions, first of all does that seem like a proper rewording to you? And secondly... What is the answer and the reasoning to reach that answer? I am terrible at probability, and while I can clearly see the problem and maybe spell out the first step or two, I am at a total loss as to how to arrive at an answer. Edit: one more question, actually: is this an instance of the Monty Hall problem ? I obviously see that it is very different, yet it feels somehow similar...","A probability problem was posed to me, and I am terrible at probability. It was first posed to me like this: I have 5 coins. One of them is a   two-headed coin, and the others are   normal coins. I pick a coin, and then   I flip that coin three times; each   time is heads. What is the probability   that the coin is two-headed? My answer was, naturally, 1/5. I am still of the opinion that it's the correct answer to that particular phrasing (do you agree?). But of course I was told this is a wrong answer. After some thought, I came up with the following phrasing which is what was really meant: You are given a coin and told that it   has a 1/5 chance that it is   double-headed, otherwise it is a   normal coin. You are allowed three   flips of the coin. Upon doing these,   you receive three heads. What is the   probability that your coin is   double-headed? Now I have two questions, first of all does that seem like a proper rewording to you? And secondly... What is the answer and the reasoning to reach that answer? I am terrible at probability, and while I can clearly see the problem and maybe spell out the first step or two, I am at a total loss as to how to arrive at an answer. Edit: one more question, actually: is this an instance of the Monty Hall problem ? I obviously see that it is very different, yet it feels somehow similar...",,['probability']
97,"If $X$ is Gaussian, prove that $X-\lfloor X \rfloor \sim U(0,1)$ as its variance becomes large","If  is Gaussian, prove that  as its variance becomes large","X X-\lfloor X \rfloor \sim U(0,1)","I have a normal distributed random variable, $X$ with mean $\mu$ and standard deviation, $\sigma$ . I don't believe it matters, but this distribution was obtained as a result of summing a large number of independent, identically distributed random numbers with finite variance (hence invoking the central limit theorem). It seems intuitive that $X - \lfloor X \rfloor$ should become closer and closer to a uniform random number between $(0,1)$ as the variance of $X$ increases. And in the limit, it should become a uniform random number. Is there a proof for this claim or a refutation of it? Context: this is going to help ""complete"" the accepted answer here: As the variance of a random variable grows, the conditional distribution of it residing in an interval of length $1$ becomes uniform . Larger picture, I'm trying to prove Blackwell's theorem from renewal theory. See here for details: Going ""well into the lifetime"" of a renewal process means the time until the next event will be uniform conditional on inter-arrival?","I have a normal distributed random variable, with mean and standard deviation, . I don't believe it matters, but this distribution was obtained as a result of summing a large number of independent, identically distributed random numbers with finite variance (hence invoking the central limit theorem). It seems intuitive that should become closer and closer to a uniform random number between as the variance of increases. And in the limit, it should become a uniform random number. Is there a proof for this claim or a refutation of it? Context: this is going to help ""complete"" the accepted answer here: As the variance of a random variable grows, the conditional distribution of it residing in an interval of length $1$ becomes uniform . Larger picture, I'm trying to prove Blackwell's theorem from renewal theory. See here for details: Going ""well into the lifetime"" of a renewal process means the time until the next event will be uniform conditional on inter-arrival?","X \mu \sigma X - \lfloor X \rfloor (0,1) X","['probability', 'uniform-distribution', 'central-limit-theorem']"
98,Distribution of a random variable in a coin toss,Distribution of a random variable in a coin toss,,"Amanda tosses a fair coin until she gets $H$ . Let $X$ be the number of these tosses. After that she tosses $X$ fair coins, each one until she gets $H$ . Let $Y_i$ be the number of tosses for the coin $i\in\{1,\dots,X\}$ . Finally, Let $S=Y_1+Y_2+\dots+Y_X$ the total number of tosses (excluding the first $X$ tosses). Prove: $S\sim \mathrm{Geo}\left(\frac14 \right)$ My try: I know that $(S|X=k)\sim \mathrm{NegBin}(k, 1/2)$ as sum of geometric random variables. How can I conclude that $S\sim \mathrm{Geo}(1/4 )$ ?","Amanda tosses a fair coin until she gets . Let be the number of these tosses. After that she tosses fair coins, each one until she gets . Let be the number of tosses for the coin . Finally, Let the total number of tosses (excluding the first tosses). Prove: My try: I know that as sum of geometric random variables. How can I conclude that ?","H X X H Y_i i\in\{1,\dots,X\} S=Y_1+Y_2+\dots+Y_X X S\sim \mathrm{Geo}\left(\frac14 \right) (S|X=k)\sim \mathrm{NegBin}(k, 1/2) S\sim \mathrm{Geo}(1/4 )","['probability', 'probability-distributions', 'negative-binomial']"
99,Probability with unknown variables,Probability with unknown variables,,"An urn contains $10$ red marbles and $10$ black marbles while a second urn contains $25$ red marbles and an unknown number of black marbles. A random marble will be selected from each urn and the probability that both marbles are the same will be determined. A hint was given by the teacher: the probability does NOT depend on the number of unknown marbles. Verify that this is the case. Let's call $N$ the unknown number of marbles. I wrote out all possible ways to select a marble from each urn, selecting a red marble from both urn $1$ and urn $2$, and selecting a black marble from urn $1$ and $2$ and this is what I got: Number of ways to select a marble from each urn: $ \binom{20}{1}\binom{25+N}{1}$ Number of ways to select $1$ red marble from both urn $1$ and urn $2$: $\binom{10}{1}\binom{25}{ 1}$ Number of ways to select $1$ black marble from urn $1$ and urn $2$: $\binom{10}{1}\binom{N}{ 1}$ And this is what I got as my final equation to finding out the probability of selecting the same color marble from each urn: $\dfrac{\binom{10}{1}\binom{25}{ 1}+\binom{10}{1}\binom{N}{ 1}}{\binom{20}{1}\binom{25+N}{1}} $ I am confused on how the probability doesn't depend on the unknown number of black marbles in urn $2$? Any help would be much appreciated, thank you so much! PS: I also searched through stack exchange for a problem similar to this and I couldn't find one. If this question was asked already, then I apologize!","An urn contains $10$ red marbles and $10$ black marbles while a second urn contains $25$ red marbles and an unknown number of black marbles. A random marble will be selected from each urn and the probability that both marbles are the same will be determined. A hint was given by the teacher: the probability does NOT depend on the number of unknown marbles. Verify that this is the case. Let's call $N$ the unknown number of marbles. I wrote out all possible ways to select a marble from each urn, selecting a red marble from both urn $1$ and urn $2$, and selecting a black marble from urn $1$ and $2$ and this is what I got: Number of ways to select a marble from each urn: $ \binom{20}{1}\binom{25+N}{1}$ Number of ways to select $1$ red marble from both urn $1$ and urn $2$: $\binom{10}{1}\binom{25}{ 1}$ Number of ways to select $1$ black marble from urn $1$ and urn $2$: $\binom{10}{1}\binom{N}{ 1}$ And this is what I got as my final equation to finding out the probability of selecting the same color marble from each urn: $\dfrac{\binom{10}{1}\binom{25}{ 1}+\binom{10}{1}\binom{N}{ 1}}{\binom{20}{1}\binom{25+N}{1}} $ I am confused on how the probability doesn't depend on the unknown number of black marbles in urn $2$? Any help would be much appreciated, thank you so much! PS: I also searched through stack exchange for a problem similar to this and I couldn't find one. If this question was asked already, then I apologize!",,"['probability', 'statistics']"
