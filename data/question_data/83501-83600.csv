,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Is the identity map $id: H^2(-\pi,\pi) \to L^2(-\pi,\pi)$ Hilbert-Schmidt?",Is the identity map  Hilbert-Schmidt?,"id: H^2(-\pi,\pi) \to L^2(-\pi,\pi)","Let $H_1, H_2$ be Hilbert spaces. A linear operator $A: H_1 \to H_2$ is Hilbert-Schmidt iff for some orthonormal basis $\lbrace e_n : ~ n \in \mathbb{N} \rbrace$ of $H_1$ the sum $\sum_{n \in \mathbb{N}} \Vert A e_n \Vert^2_{H_2}$ is finite. It is easy to see that if $H_1 = H_2$ the identity operator $id: H_1 \to H_1$ is Hilbert-Schmidt if and only if $H$ is finite-dimensional, since otherwise $\sum_{n \in \mathbb{N}} \Vert e_n \Vert^2_{H_2}= \sum_{n \in \mathbb{N}} \Vert e_n \Vert^2_{H_1}=  \sum_{n \in \mathbb{N}} 1$ clearly diverges. But what if $H_1$ is a real subset of $H_2$? Then the situation changes somehow, because $\Vert \cdot \Vert_{H_1} = \Vert \cdot \Vert_{H_2}$ needs not to hold anymore. More specific: Is the identity map $id: H^2(-\pi,\pi) \to L^2(-\pi,\pi)$ Hilbert-Schmidt? and if not: Is there any chance that $id: H^p(-\pi,\pi) \to L^2(-\pi,\pi)$ is Hilbert-Schmidt for any $p$? EDIT: We equip $L^2$ and $H^2$ with the standard norms $\Vert f \Vert_{L^2}^2 = \int \vert f(x) \vert^2 dx$ and $\Vert f \Vert_{H^2}^2 = \int \vert f(x) \vert^2 dx + \int \vert D f(x) \vert^2 dx + \int \vert D^2f(x) \vert^2 dx$.","Let $H_1, H_2$ be Hilbert spaces. A linear operator $A: H_1 \to H_2$ is Hilbert-Schmidt iff for some orthonormal basis $\lbrace e_n : ~ n \in \mathbb{N} \rbrace$ of $H_1$ the sum $\sum_{n \in \mathbb{N}} \Vert A e_n \Vert^2_{H_2}$ is finite. It is easy to see that if $H_1 = H_2$ the identity operator $id: H_1 \to H_1$ is Hilbert-Schmidt if and only if $H$ is finite-dimensional, since otherwise $\sum_{n \in \mathbb{N}} \Vert e_n \Vert^2_{H_2}= \sum_{n \in \mathbb{N}} \Vert e_n \Vert^2_{H_1}=  \sum_{n \in \mathbb{N}} 1$ clearly diverges. But what if $H_1$ is a real subset of $H_2$? Then the situation changes somehow, because $\Vert \cdot \Vert_{H_1} = \Vert \cdot \Vert_{H_2}$ needs not to hold anymore. More specific: Is the identity map $id: H^2(-\pi,\pi) \to L^2(-\pi,\pi)$ Hilbert-Schmidt? and if not: Is there any chance that $id: H^p(-\pi,\pi) \to L^2(-\pi,\pi)$ is Hilbert-Schmidt for any $p$? EDIT: We equip $L^2$ and $H^2$ with the standard norms $\Vert f \Vert_{L^2}^2 = \int \vert f(x) \vert^2 dx$ and $\Vert f \Vert_{H^2}^2 = \int \vert f(x) \vert^2 dx + \int \vert D f(x) \vert^2 dx + \int \vert D^2f(x) \vert^2 dx$.",,"['functional-analysis', 'hilbert-spaces']"
1,How to solve the functional equation $ f(f(x))=ax^2+bx+c $,How to solve the functional equation, f(f(x))=ax^2+bx+c ,"Find all real numbers $a,b,c\in\mathbb{R}$ for which there exists a function $f:\mathbb{R}\to\mathbb{R}$ such that: $$ f(f(x))=ax^2+bx+c $$ for all $x\in\mathbb{R}$. The only thing I could deduce is: $$ f(ax^2+bx+c)=af(x)^2+bf(x)+c $$ Which doesn't help much. How to tackle the problem?","Find all real numbers $a,b,c\in\mathbb{R}$ for which there exists a function $f:\mathbb{R}\to\mathbb{R}$ such that: $$ f(f(x))=ax^2+bx+c $$ for all $x\in\mathbb{R}$. The only thing I could deduce is: $$ f(ax^2+bx+c)=af(x)^2+bf(x)+c $$ Which doesn't help much. How to tackle the problem?",,"['functional-analysis', 'functions', 'functional-equations']"
2,"$W^{s,p}(\mathbb{R}^{n})$ Is Not Closed Under Multiplication when $s\leq n/p$",Is Not Closed Under Multiplication when,"W^{s,p}(\mathbb{R}^{n}) s\leq n/p","For $s\in\mathbb{R}$, $1<p<\infty$, and $n\geq 1$, define the Sobolev space $W^{s,p}(\mathbb{R}^{n})$ by     $$W^{s,p}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}(\mathbb{R}^{n}) : \|(\langle{\xi}\rangle^{s}\widehat{f})^{\vee}\|_{L^{p}}<\infty\right\}$$, equipped with norm     $$\|f\|_{W^{s,p}}=\|(\langle{\xi}\rangle^{s}\widehat{f})^{\vee}\|_{L^{p}}$$ If $\phi+\sum_{k=1}^{\infty}\psi(2^{-k}\cdot)=1$ is a Littlewood-Paley partition of unity, then we have the equivalence of norms     $$\|f\|_{W^{s,p}}\approx \|P_{\leq 0}f\|_{L^{p}}+\left\|\left(\sum_{k=1}^{\infty}2^{2ks}|P_{k}f|^{2}\right)^{1/2}\right\|_{L^{p}},$$ where $\widehat{P_{\leq 0}f}=\psi\widehat{f}$ and $\widehat{P_{k}f}=\psi(2^{-k})\widehat{f}$. When $sp> n$, one can show that $W^{s,p}$ is closed under pointwise multiplication. More precisely, Theorem. For $n\geq 1$, $1<p<\infty$, and $s>n/p$, $$\|fg\|_{W^{s,p}}\lesssim_{n,p,s}\|f\|_{W^{s,p}}\|g\|_{W^{s,p}},\quad\forall f,g\in W^{s,p}(\mathbb{R}^{n})$$ I want to show that this result is sharp for any $1<p<\infty$, $n\geq 1$, and $0<s\leq n/p$. Specifically, Problem. For all $n\geq 1$, $0<s\leq n/p$, find a function $f\in W^{s,p}(\mathbb{R}^{n})$ such that $f^{2}\notin W^{s,p}(\mathbb{R}^{n})$. The proof of the above theorem with which I am familiar (see Week 4 notes here ) uses the fact that by Sobolev embedding, we can control $\|f\|_{L^{\infty}}$ by $\|f\|_{W^{s,p}}$ and therefore we can control the $L^{\infty}$-norm of the Hardy-Littlewood maximal function of $f$, denoted $Mf$, by $\|f\|_{W^{s,p}}$. I believe for $s<n/p$, I can construct a function $f\in W^{s,p}$ which is not bounded. T. Tao writes that one cannot control the $L^{\infty}$ norm by the $W^{s,p}$ norm also when $s=n/p$, but I couldn't show the endpoint case (Edit 1: See below for proof of endpoint case). Consider functions of the function     $$f_{N}:=N^{-1}\sum_{k=1}^{N}2^{-sk}2^{nk/p}\widehat{\psi}(2^{k}x)$$ where $\psi$ is a nonnegative bump function adapted to the annulus $1\leq|\xi|\leq 2$ and $N\geq 1$ is an integer. Instead of $N^{-1}$, Tao uses $N^{-1/p}$ but I was unable to make that work. I claim that $\|f_{N}\|_{W^{s,p}}\lesssim 1$ (i.e. uniformly in $N$). It's clear from the triangle inequality and dilation invariance that $\|f_{N}\|_{L^{p}}\lesssim 1$. Whence by Young's inequality, $\|P_{\leq 0}f_{N}\|_{L^{p}}\lesssim 1$. By analyzing frequency supports, we see that     $${P_{k}2^{jn/p}\widehat{\psi}(2^{j}\cdot)}=0,\quad |k-j|> 3$$ Whence, $$2^{sk}P_{k}f_{N}=N^{-1}\sum_{j=k-3}^{k+3}P_{k}2^{s(k-j)}2^{jn/p}\widehat{\psi}(2^{j})=N^{-1}\sum_{j=-3}^{3}2^{-sj}P_{k}2^{(k+j)n/p}\widehat{\psi}(2^{j+k})$$ where terms with negative indices are defined to be zero. Thus by nesting of $\ell^{p}$ spaces and the above observations, we have that \begin{align*} \left(\sum_{k=1}^{\infty}|2^{sk}P_{k}f_{N}|^{2}\right)^{1/2}\lesssim_{n,s,p} N^{-1}\sum_{j=1}^{N}\sum_{k=j-3}^{j+3}|P_{k}2^{nj/p}\widehat{\psi}(2^{j})| \end{align*} By triangle inequality, Young's inequality, dilation invariance, we obtain that $$\left\|N^{-1}\sum_{j=1}^{N}\sum_{k=j-3}^{j+3}|P_{k}2^{nj/p}\widehat{\psi}(2^{j})|\right\|_{L^{p}}\lesssim_{n,s}N^{-1}\sum_{j=1}^{N}\|2^{nj/p}\widehat{\psi}(2^{j})\|_{L^{p}}=\|\widehat{\psi}\|_{L^{p}}$$ But since $\widehat{\psi}(0)=\int\psi dx=c>0$, it follows that     $$\|f_{N}\|_{L^{\infty}}\gtrsim N^{-1}\sum_{k=1}^{N}2^{k(n/p-s)}\rightarrow\infty,$$ as $N\rightarrow\infty$, since $s<n/p$. By taking an increasing sequence $N_{k}\rightarrow\infty$ such that $\|f_{N_{k}}\|_{L^{\infty}}$ is suitably large, one can probaby construct a $W^{s,p}$ function of the form $f=\sum_{k}2^{-k}f_{N_{k}}$ such that $\|f\|_{L^{\infty}}=\infty$, but I don't see how to apply this to show what I want. Edit 1: I believe I have figured out how to show the endpoint case $s=n/p$ in the claim that $\|\cdot\|_{W^{s,p}}$ does not control $\|\cdot\|_{L^{\infty}}$. Consider functions of the function     $$f_{N}:=\sum_{k=1}^{N}2^{-sk}2^{nk/p}\widehat{\psi}(2^{k}x)$$ where $\psi$ is a nonnegative bump function adapted to the annulus $1\leq|\xi|\leq 2$ and $N\geq 1$ is an integer. I claim that $\|f_{N}\|_{W^{s,p}}\lesssim_{n,s,p}N^{1/p}$ (i.e. uniformly in $N$). It's clear from the triangle inequality and dilation invariance that $\|f_{N}\|_{L^{p}}\lesssim N^{1/p}$. Whence by Young's inequality, $\|P_{\leq 0}f_{N}\|_{L^{p}}\lesssim N^{1/p}$. By analyzing frequency supports, we see that     $${P_{k}2^{jn/p}\widehat{\psi}(2^{j}\cdot)}=0,\quad |k-j|> 3$$ Whence, $$2^{sk}P_{k}f_{N}=\sum_{j=k-3}^{k+3}P_{k}2^{s(k-j)}2^{jn/p}\widehat{\psi}(2^{j})=\sum_{j=-3}^{3}2^{-sj}P_{k}2^{(k+j)n/p}\widehat{\psi}(2^{j+k})$$ where terms with negative indices are defined to be zero. By the upper Littlewood-Paley inequality, \begin{align*} \left\|\left(\sum_{k=1}^{\infty}2^{2sk}|P_{k}f_{N}|^{2}\right)^{1/2}\right\|_{L^{p}}&\lesssim_{n,s,p}\left\|\left(\sum_{j=1}^{N}2^{2jn/p}|\widehat{\psi}(2^{j}\cdot)|^{2}\right)^{1/2}\right\|_{L^{p}}\\ &\leq\left\|\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}\cdot)|\right\|_{L^{p}} \end{align*} by the nesting property. Since $\widehat{\psi}$ is a Schwartz function adapted to a ball of radius $O(1)$, we have that $$\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}x)|\lesssim_{M}\sum_{j=1}^{N}\dfrac{1}{(1+|2^{j}x|)^{M}}$$ for any $M\geq 0$. So for integer $N-1\geq k\geq 0$, \begin{align*} \int_{2^{-k-1}\leq|x|\leq 2^{-k}}\left|\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}x)|\right|^{p}dx&\lesssim_{M}\int_{2^{-k-1}\leq|x|\leq 2^{-k}}\left|\sum_{j=1}^{k}2^{jn/p}+\sum_{j=k+1}^{N}\dfrac{2^{jn/p}}{(1+|2^{j}x|)^{M}}\right|^{p}dx\\ &\lesssim\int_{2^{-k}\leq|x|\leq 2^{-k-1}}\left|2^{kn/p}+\sum_{j=k+1}^{N}\dfrac{2^{jn/p}}{(1+|2^{j}x|)^{M}}\right|^{p}dx\\ \end{align*} The second term in the integrand is bounded from above by a decreasing, convergent geometric series, provided $M$ is sufficiently large, and is therefore comparable to its first term $\sim 2^{kn/p}$. Whence the above is majorized by \begin{align*} \lesssim\int_{2^{-k-1}\leq|x|\leq 2^{-k}}2^{kn}dx\sim_{n} 1 \end{align*} For $k\leq N$, we the estimate $$\int_{|x|\leq 2^{-N}}\left|\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}x)|\right|^{p}dx\lesssim\int_{|x|\leq 2^{-N}}2^{Nn}dx\sim_{n}1$$ For $|x|\geq 1$, rapid decay gives the estimate \begin{align*} \int_{|x|\geq 1}\left|\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}x)|\right|^{p}dx\lesssim_{M}\int_{|x|\geq 1}\left(\sum_{j=1}^{N}2^{jn/p}|2^{j}x|^{-M}\right)^{p}dx\lesssim_{n,M,p}1, \end{align*} provided $M$ is sufficiently large. Combining the estimates and adding up the pieces of the integral, we conclude that \begin{align*} \int_{\mathbb{R}^{n}}\left|\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}x)|\right|^{p}dx&\lesssim_{n,p} N \end{align*} Taking $p^{th}$ roots completes the proof of the claim.","For $s\in\mathbb{R}$, $1<p<\infty$, and $n\geq 1$, define the Sobolev space $W^{s,p}(\mathbb{R}^{n})$ by     $$W^{s,p}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}(\mathbb{R}^{n}) : \|(\langle{\xi}\rangle^{s}\widehat{f})^{\vee}\|_{L^{p}}<\infty\right\}$$, equipped with norm     $$\|f\|_{W^{s,p}}=\|(\langle{\xi}\rangle^{s}\widehat{f})^{\vee}\|_{L^{p}}$$ If $\phi+\sum_{k=1}^{\infty}\psi(2^{-k}\cdot)=1$ is a Littlewood-Paley partition of unity, then we have the equivalence of norms     $$\|f\|_{W^{s,p}}\approx \|P_{\leq 0}f\|_{L^{p}}+\left\|\left(\sum_{k=1}^{\infty}2^{2ks}|P_{k}f|^{2}\right)^{1/2}\right\|_{L^{p}},$$ where $\widehat{P_{\leq 0}f}=\psi\widehat{f}$ and $\widehat{P_{k}f}=\psi(2^{-k})\widehat{f}$. When $sp> n$, one can show that $W^{s,p}$ is closed under pointwise multiplication. More precisely, Theorem. For $n\geq 1$, $1<p<\infty$, and $s>n/p$, $$\|fg\|_{W^{s,p}}\lesssim_{n,p,s}\|f\|_{W^{s,p}}\|g\|_{W^{s,p}},\quad\forall f,g\in W^{s,p}(\mathbb{R}^{n})$$ I want to show that this result is sharp for any $1<p<\infty$, $n\geq 1$, and $0<s\leq n/p$. Specifically, Problem. For all $n\geq 1$, $0<s\leq n/p$, find a function $f\in W^{s,p}(\mathbb{R}^{n})$ such that $f^{2}\notin W^{s,p}(\mathbb{R}^{n})$. The proof of the above theorem with which I am familiar (see Week 4 notes here ) uses the fact that by Sobolev embedding, we can control $\|f\|_{L^{\infty}}$ by $\|f\|_{W^{s,p}}$ and therefore we can control the $L^{\infty}$-norm of the Hardy-Littlewood maximal function of $f$, denoted $Mf$, by $\|f\|_{W^{s,p}}$. I believe for $s<n/p$, I can construct a function $f\in W^{s,p}$ which is not bounded. T. Tao writes that one cannot control the $L^{\infty}$ norm by the $W^{s,p}$ norm also when $s=n/p$, but I couldn't show the endpoint case (Edit 1: See below for proof of endpoint case). Consider functions of the function     $$f_{N}:=N^{-1}\sum_{k=1}^{N}2^{-sk}2^{nk/p}\widehat{\psi}(2^{k}x)$$ where $\psi$ is a nonnegative bump function adapted to the annulus $1\leq|\xi|\leq 2$ and $N\geq 1$ is an integer. Instead of $N^{-1}$, Tao uses $N^{-1/p}$ but I was unable to make that work. I claim that $\|f_{N}\|_{W^{s,p}}\lesssim 1$ (i.e. uniformly in $N$). It's clear from the triangle inequality and dilation invariance that $\|f_{N}\|_{L^{p}}\lesssim 1$. Whence by Young's inequality, $\|P_{\leq 0}f_{N}\|_{L^{p}}\lesssim 1$. By analyzing frequency supports, we see that     $${P_{k}2^{jn/p}\widehat{\psi}(2^{j}\cdot)}=0,\quad |k-j|> 3$$ Whence, $$2^{sk}P_{k}f_{N}=N^{-1}\sum_{j=k-3}^{k+3}P_{k}2^{s(k-j)}2^{jn/p}\widehat{\psi}(2^{j})=N^{-1}\sum_{j=-3}^{3}2^{-sj}P_{k}2^{(k+j)n/p}\widehat{\psi}(2^{j+k})$$ where terms with negative indices are defined to be zero. Thus by nesting of $\ell^{p}$ spaces and the above observations, we have that \begin{align*} \left(\sum_{k=1}^{\infty}|2^{sk}P_{k}f_{N}|^{2}\right)^{1/2}\lesssim_{n,s,p} N^{-1}\sum_{j=1}^{N}\sum_{k=j-3}^{j+3}|P_{k}2^{nj/p}\widehat{\psi}(2^{j})| \end{align*} By triangle inequality, Young's inequality, dilation invariance, we obtain that $$\left\|N^{-1}\sum_{j=1}^{N}\sum_{k=j-3}^{j+3}|P_{k}2^{nj/p}\widehat{\psi}(2^{j})|\right\|_{L^{p}}\lesssim_{n,s}N^{-1}\sum_{j=1}^{N}\|2^{nj/p}\widehat{\psi}(2^{j})\|_{L^{p}}=\|\widehat{\psi}\|_{L^{p}}$$ But since $\widehat{\psi}(0)=\int\psi dx=c>0$, it follows that     $$\|f_{N}\|_{L^{\infty}}\gtrsim N^{-1}\sum_{k=1}^{N}2^{k(n/p-s)}\rightarrow\infty,$$ as $N\rightarrow\infty$, since $s<n/p$. By taking an increasing sequence $N_{k}\rightarrow\infty$ such that $\|f_{N_{k}}\|_{L^{\infty}}$ is suitably large, one can probaby construct a $W^{s,p}$ function of the form $f=\sum_{k}2^{-k}f_{N_{k}}$ such that $\|f\|_{L^{\infty}}=\infty$, but I don't see how to apply this to show what I want. Edit 1: I believe I have figured out how to show the endpoint case $s=n/p$ in the claim that $\|\cdot\|_{W^{s,p}}$ does not control $\|\cdot\|_{L^{\infty}}$. Consider functions of the function     $$f_{N}:=\sum_{k=1}^{N}2^{-sk}2^{nk/p}\widehat{\psi}(2^{k}x)$$ where $\psi$ is a nonnegative bump function adapted to the annulus $1\leq|\xi|\leq 2$ and $N\geq 1$ is an integer. I claim that $\|f_{N}\|_{W^{s,p}}\lesssim_{n,s,p}N^{1/p}$ (i.e. uniformly in $N$). It's clear from the triangle inequality and dilation invariance that $\|f_{N}\|_{L^{p}}\lesssim N^{1/p}$. Whence by Young's inequality, $\|P_{\leq 0}f_{N}\|_{L^{p}}\lesssim N^{1/p}$. By analyzing frequency supports, we see that     $${P_{k}2^{jn/p}\widehat{\psi}(2^{j}\cdot)}=0,\quad |k-j|> 3$$ Whence, $$2^{sk}P_{k}f_{N}=\sum_{j=k-3}^{k+3}P_{k}2^{s(k-j)}2^{jn/p}\widehat{\psi}(2^{j})=\sum_{j=-3}^{3}2^{-sj}P_{k}2^{(k+j)n/p}\widehat{\psi}(2^{j+k})$$ where terms with negative indices are defined to be zero. By the upper Littlewood-Paley inequality, \begin{align*} \left\|\left(\sum_{k=1}^{\infty}2^{2sk}|P_{k}f_{N}|^{2}\right)^{1/2}\right\|_{L^{p}}&\lesssim_{n,s,p}\left\|\left(\sum_{j=1}^{N}2^{2jn/p}|\widehat{\psi}(2^{j}\cdot)|^{2}\right)^{1/2}\right\|_{L^{p}}\\ &\leq\left\|\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}\cdot)|\right\|_{L^{p}} \end{align*} by the nesting property. Since $\widehat{\psi}$ is a Schwartz function adapted to a ball of radius $O(1)$, we have that $$\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}x)|\lesssim_{M}\sum_{j=1}^{N}\dfrac{1}{(1+|2^{j}x|)^{M}}$$ for any $M\geq 0$. So for integer $N-1\geq k\geq 0$, \begin{align*} \int_{2^{-k-1}\leq|x|\leq 2^{-k}}\left|\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}x)|\right|^{p}dx&\lesssim_{M}\int_{2^{-k-1}\leq|x|\leq 2^{-k}}\left|\sum_{j=1}^{k}2^{jn/p}+\sum_{j=k+1}^{N}\dfrac{2^{jn/p}}{(1+|2^{j}x|)^{M}}\right|^{p}dx\\ &\lesssim\int_{2^{-k}\leq|x|\leq 2^{-k-1}}\left|2^{kn/p}+\sum_{j=k+1}^{N}\dfrac{2^{jn/p}}{(1+|2^{j}x|)^{M}}\right|^{p}dx\\ \end{align*} The second term in the integrand is bounded from above by a decreasing, convergent geometric series, provided $M$ is sufficiently large, and is therefore comparable to its first term $\sim 2^{kn/p}$. Whence the above is majorized by \begin{align*} \lesssim\int_{2^{-k-1}\leq|x|\leq 2^{-k}}2^{kn}dx\sim_{n} 1 \end{align*} For $k\leq N$, we the estimate $$\int_{|x|\leq 2^{-N}}\left|\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}x)|\right|^{p}dx\lesssim\int_{|x|\leq 2^{-N}}2^{Nn}dx\sim_{n}1$$ For $|x|\geq 1$, rapid decay gives the estimate \begin{align*} \int_{|x|\geq 1}\left|\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}x)|\right|^{p}dx\lesssim_{M}\int_{|x|\geq 1}\left(\sum_{j=1}^{N}2^{jn/p}|2^{j}x|^{-M}\right)^{p}dx\lesssim_{n,M,p}1, \end{align*} provided $M$ is sufficiently large. Combining the estimates and adding up the pieces of the integral, we conclude that \begin{align*} \int_{\mathbb{R}^{n}}\left|\sum_{j=1}^{N}2^{jn/p}|\widehat{\psi}(2^{j}x)|\right|^{p}dx&\lesssim_{n,p} N \end{align*} Taking $p^{th}$ roots completes the proof of the claim.",,"['functional-analysis', 'fourier-analysis', 'sobolev-spaces', 'littlewood-paley-theory', 'fractional-sobolev-spaces']"
3,"Given a point $x$ and a closed subspace $Y$ of a normed space, must the distance from $x$ to $Y$ be achieved by some $y\in Y$?","Given a point  and a closed subspace  of a normed space, must the distance from  to  be achieved by some ?",x Y x Y y\in Y,"I think no. And I am looking for examples. I would like a sequence $y_n$ in $Y$ such that $||y_n-x||\rightarrow d(x,Y)$ while $y_n$ do not converge. Can anyone give a proof or an counterexample to this question?","I think no. And I am looking for examples. I would like a sequence $y_n$ in $Y$ such that $||y_n-x||\rightarrow d(x,Y)$ while $y_n$ do not converge. Can anyone give a proof or an counterexample to this question?",,['functional-analysis']
4,What are the Eigenvectors of the curl operator?,What are the Eigenvectors of the curl operator?,,"The curl operator $\vec\nabla\times\mathbb{1}$ can be written as a skew-symmetric 3x3 matrix $$\mathrm{curl} = \begin{pmatrix}0 & -\partial_z & \partial_y \\ \partial_z & 0 & -\partial_x \\ -\partial_y & \partial_x & 0\end{pmatrix}$$ (in Cartesian coordinates). Since $\mathrm{curl}\,\mathrm{grad}=0$ and $\mathrm{div}\,\mathrm{curl}=0$, the Eigenvector 1 to the Eigenvalue 0 is $\vec\nabla$. And by calculating $\det(\mathrm{curl}-\lambda)\stackrel!=0=-\lambda(\lambda^2+\Delta)$ one obtains that the other two Eigenvalues (with opposite signs) both satisfy $\lambda_\pm^2=-\Delta$, i.e. they are the two roots of the negative Laplacian. Since $\mathrm{curl}^2=\mathrm{grad}\,\mathrm{div}-\Delta$, the Eigenvectors $\vec f_\pm$, satisfying $\mathrm{curl}^2\vec f_\pm = -\Delta\vec f_\pm$, they have a constant divergence. More precisely, since they must be orthogonal to $\vec\nabla$ due to the different Eigenvalues, they can be written as $\vec f_\pm = \vec g_\pm\times\vec\nabla$. Since the $\vec f_\pm$ are also orthogonal to each other, one can obtain $$\vec f_\pm = \pm\lambda_\pm^{-1}\,\vec f_\mp\times\vec\nabla$$ where the factor $\pm\lambda_\pm^ {-1}$ was chosen for symmetry and consistency. But what is an analytical (non-recursive) expression for them? You may already have noticed that the $\lambda_\pm$ are Dirac operators , so I wouldn't be too surprised if an answer included spinors and $\partial\!\!/$, even though that is in 4D... In fact, it is most likely that this is the case, since apart from $\vec\nabla$, the vector of $\gamma$ (or Pauli) matrices would not set any preferred direction. 1 In the sense that for any scalar function $s(\vec x)$, $\vec\nabla s$ is an Eigenvector of $\mathrm{curl}$ with Eigenvalue 0, i.e. $\forall s:\mathrm{curl}\vec\nabla s = 0\cdot\vec\nabla s$. It's just like stating $[x_i,\partial_j] = \delta_{ij}$ while this only makes sense when acting on something.","The curl operator $\vec\nabla\times\mathbb{1}$ can be written as a skew-symmetric 3x3 matrix $$\mathrm{curl} = \begin{pmatrix}0 & -\partial_z & \partial_y \\ \partial_z & 0 & -\partial_x \\ -\partial_y & \partial_x & 0\end{pmatrix}$$ (in Cartesian coordinates). Since $\mathrm{curl}\,\mathrm{grad}=0$ and $\mathrm{div}\,\mathrm{curl}=0$, the Eigenvector 1 to the Eigenvalue 0 is $\vec\nabla$. And by calculating $\det(\mathrm{curl}-\lambda)\stackrel!=0=-\lambda(\lambda^2+\Delta)$ one obtains that the other two Eigenvalues (with opposite signs) both satisfy $\lambda_\pm^2=-\Delta$, i.e. they are the two roots of the negative Laplacian. Since $\mathrm{curl}^2=\mathrm{grad}\,\mathrm{div}-\Delta$, the Eigenvectors $\vec f_\pm$, satisfying $\mathrm{curl}^2\vec f_\pm = -\Delta\vec f_\pm$, they have a constant divergence. More precisely, since they must be orthogonal to $\vec\nabla$ due to the different Eigenvalues, they can be written as $\vec f_\pm = \vec g_\pm\times\vec\nabla$. Since the $\vec f_\pm$ are also orthogonal to each other, one can obtain $$\vec f_\pm = \pm\lambda_\pm^{-1}\,\vec f_\mp\times\vec\nabla$$ where the factor $\pm\lambda_\pm^ {-1}$ was chosen for symmetry and consistency. But what is an analytical (non-recursive) expression for them? You may already have noticed that the $\lambda_\pm$ are Dirac operators , so I wouldn't be too surprised if an answer included spinors and $\partial\!\!/$, even though that is in 4D... In fact, it is most likely that this is the case, since apart from $\vec\nabla$, the vector of $\gamma$ (or Pauli) matrices would not set any preferred direction. 1 In the sense that for any scalar function $s(\vec x)$, $\vec\nabla s$ is an Eigenvector of $\mathrm{curl}$ with Eigenvalue 0, i.e. $\forall s:\mathrm{curl}\vec\nabla s = 0\cdot\vec\nabla s$. It's just like stating $[x_i,\partial_j] = \delta_{ij}$ while this only makes sense when acting on something.",,"['functional-analysis', 'operator-theory', 'eigenvalues-eigenvectors']"
5,Matrices with entries in $C^*$-algebra,Matrices with entries in -algebra,C^*,"Let $\mathcal{A}$ be a $C^*$-algebra. Consider vector space of matrices of size $n\times n$ whose entries in $\mathcal{A}$. Denote this vector space $M_{n,n}(\mathcal{A})$. We can define involution on $M_{n,n}(\mathcal{A})$ by equality $$ [a_{ij}]^*=[a_{ji}^*],\qquad\text{where}\quad [a_{ij}]\in M_{n,n}(\mathcal{A}). $$ Thus we have an involutive algebra $M_{n,n}(\mathcal{A})$. It is well known  that there exist at most one norm on $M_{n,n}(\mathcal{A})$ making it a $C^*$-algebra. This norm does exist. Indeed take universal representation $\pi:\mathcal{A}\to\mathcal{B}(H)$ and define linear injective $^*$-homomorphism $$ \Pi:M_{n,n}(\mathcal{A})\to\mathcal{B}\left(\bigoplus\limits_{k=1}^n H\right):[a_{ij}]\mapsto\left((x_1,\ldots,x_n)\mapsto\left(\sum\limits_{j=1}^n\pi(a_{1j})x_j,\ldots,\sum\limits_{j=1}^n\pi(a_{nj})x_j\right)\right) $$ Hence we can define norm on $M_{n,n}(\mathcal{A})$ as $\left\Vert[a_{ij}]\right\Vert_{M_{n,n}(\mathcal{A})}=\Vert\Pi([a_{ij}])\Vert$. At first sight this definition depends on the choice of representation, but in fact it does not. My question This norm on $M_{n,n}(\mathcal{A})$ can be defined internally. Namely $$ \Vert[a_{ij}]\Vert_{M_{n,n}(\mathcal{A})}=\sup\left\Vert\sum\limits_{i=1}^n\sum\limits_{j=1}^n x_i a_{ij}y_j^*\right\Vert $$ where supremum is taken over all tuples $\{x_i\}_{i=1}^n\subset\mathcal{A}$,  $\{y_i\}_{i=1}^n\subset\mathcal{A}$ such that  $\left\Vert\sum\limits_{i=1}^n x_i x_i^*\right\Vert\leq 1$, $\left\Vert\sum\limits_{i=1}^n y_i y_i^*\right\Vert\leq 1$. Is there proof of this fact without usage of structural theorem for $C^*$-algebras, a straightforward proof which can be made by simple checking axioms of $C^*$-algebras? P.S. There is another answer on this question on mathoverflow.net","Let $\mathcal{A}$ be a $C^*$-algebra. Consider vector space of matrices of size $n\times n$ whose entries in $\mathcal{A}$. Denote this vector space $M_{n,n}(\mathcal{A})$. We can define involution on $M_{n,n}(\mathcal{A})$ by equality $$ [a_{ij}]^*=[a_{ji}^*],\qquad\text{where}\quad [a_{ij}]\in M_{n,n}(\mathcal{A}). $$ Thus we have an involutive algebra $M_{n,n}(\mathcal{A})$. It is well known  that there exist at most one norm on $M_{n,n}(\mathcal{A})$ making it a $C^*$-algebra. This norm does exist. Indeed take universal representation $\pi:\mathcal{A}\to\mathcal{B}(H)$ and define linear injective $^*$-homomorphism $$ \Pi:M_{n,n}(\mathcal{A})\to\mathcal{B}\left(\bigoplus\limits_{k=1}^n H\right):[a_{ij}]\mapsto\left((x_1,\ldots,x_n)\mapsto\left(\sum\limits_{j=1}^n\pi(a_{1j})x_j,\ldots,\sum\limits_{j=1}^n\pi(a_{nj})x_j\right)\right) $$ Hence we can define norm on $M_{n,n}(\mathcal{A})$ as $\left\Vert[a_{ij}]\right\Vert_{M_{n,n}(\mathcal{A})}=\Vert\Pi([a_{ij}])\Vert$. At first sight this definition depends on the choice of representation, but in fact it does not. My question This norm on $M_{n,n}(\mathcal{A})$ can be defined internally. Namely $$ \Vert[a_{ij}]\Vert_{M_{n,n}(\mathcal{A})}=\sup\left\Vert\sum\limits_{i=1}^n\sum\limits_{j=1}^n x_i a_{ij}y_j^*\right\Vert $$ where supremum is taken over all tuples $\{x_i\}_{i=1}^n\subset\mathcal{A}$,  $\{y_i\}_{i=1}^n\subset\mathcal{A}$ such that  $\left\Vert\sum\limits_{i=1}^n x_i x_i^*\right\Vert\leq 1$, $\left\Vert\sum\limits_{i=1}^n y_i y_i^*\right\Vert\leq 1$. Is there proof of this fact without usage of structural theorem for $C^*$-algebras, a straightforward proof which can be made by simple checking axioms of $C^*$-algebras? P.S. There is another answer on this question on mathoverflow.net",,"['functional-analysis', 'c-star-algebras', 'operator-algebras']"
6,Is there a connection between duality in linear programming and duality in functional analysis?,Is there a connection between duality in linear programming and duality in functional analysis?,,"In linear programming we optimize a linear function which is constrained by linear inequalities or linear equalities. Under some conditions you can rewrite the problem to the dual problem, so that you can solve another linear programming problem to get your result. In functional analysis the dual of a vector space is the collection of linear functionals from the vector space. Are there any connections between this? Can we write the problems in some way so that they say the same thing? The only connection I have seen is that in functional analysis we have the hahn-banach theorem, which is a theorem about extensions of linear functionals, this is connected to the hahn-banach separation theorem, the separating hyperplane theorem, and this again is connected to farkas lemma, which is used in linear programming. Is there any more connections, or is it just coincidental that both use the word dual? Before I started reading functional analysis I thought the connection would be stronger, since we can prove the separating hyperplane theorem using functional analysis, and this theorem and farkas lemma were a big part of linear programming.","In linear programming we optimize a linear function which is constrained by linear inequalities or linear equalities. Under some conditions you can rewrite the problem to the dual problem, so that you can solve another linear programming problem to get your result. In functional analysis the dual of a vector space is the collection of linear functionals from the vector space. Are there any connections between this? Can we write the problems in some way so that they say the same thing? The only connection I have seen is that in functional analysis we have the hahn-banach theorem, which is a theorem about extensions of linear functionals, this is connected to the hahn-banach separation theorem, the separating hyperplane theorem, and this again is connected to farkas lemma, which is used in linear programming. Is there any more connections, or is it just coincidental that both use the word dual? Before I started reading functional analysis I thought the connection would be stronger, since we can prove the separating hyperplane theorem using functional analysis, and this theorem and farkas lemma were a big part of linear programming.",,"['functional-analysis', 'linear-programming']"
7,Is This Set of Zero Measure?,Is This Set of Zero Measure?,,"Let $(X,\mathscr M,\mu)$ be a measure space and $(Y,\|\cdot\|)$ a separable Banach space with $\{y_n\}_{n=1}^{\infty}$ being a dense subset in it. Suppose that $f:X\to Y$ is a Borel measurable function and $$\int \|f(x)\|\,\mathrm d\mu<+\infty.$$ Suppose also that the sets $(E_{nj})_{n,j=1}^{\infty}$ in $X$ are such that all of them are in $\mathscr M$ and their measures are finite; for any given $j\in\mathbb Z_+$, $(E_{nj})_{n=1}^{\infty}$ are disjoint and their union gives $\{x\in X\,|\,f(x)\neq 0\}$; if $x\in E_{nj}$, then $\|y_n-f(x)\|<1/j\cdot\|y_n\|$. What I want to show is that the set $$\bigcap_{\ell=1}^{\infty}\bigcup_{k=\ell}^{\infty}\bigsqcup_{n=k+1}^{\infty}E_{nk}$$ is of measure zero (the notation $\sqcup$ emphasizes that the union is one of disjoint sets). I'm afraid I cannot use a limiting argument that exploits measures being continuous from above, as the sets $$\bigcup_{k=\ell}^{\infty}\bigsqcup_{n=k+1}^{\infty}E_{nk}$$ may be of infinite measure for all $\ell\in\mathbb Z_+$. In particular, if $\|f(x)\|>0$ for all $x\in X$ and $\mu(X)=+\infty$, then this fear is justified, as $X=\bigcup_{n=1}^{\infty} E_{nk}$ for all $k\in\mathbb Z_+$ by the second assumption above. If it is of any help, we know also that for any $\varepsilon>0$, the following holds: $$Y\setminus\{0\}\subseteq\bigcup_{n=1}^{\infty}\left\{y\in Y\,\big|\,\|y_n-y\|<\varepsilon\|y_n\|\right\}.$$ More generally (it would be enough for my purposes), is it possible to choose a map from $\mathbb Z_+$ to itself $k\mapsto N_k$ such that $$\bigcap_{\ell=1}^{\infty}\bigcup_{k=\ell}^{\infty}\bigsqcup_{n=N_k+1}^{\infty}E_{nk}$$ is of measure zero? Any suggestion will be dearly appreciated.","Let $(X,\mathscr M,\mu)$ be a measure space and $(Y,\|\cdot\|)$ a separable Banach space with $\{y_n\}_{n=1}^{\infty}$ being a dense subset in it. Suppose that $f:X\to Y$ is a Borel measurable function and $$\int \|f(x)\|\,\mathrm d\mu<+\infty.$$ Suppose also that the sets $(E_{nj})_{n,j=1}^{\infty}$ in $X$ are such that all of them are in $\mathscr M$ and their measures are finite; for any given $j\in\mathbb Z_+$, $(E_{nj})_{n=1}^{\infty}$ are disjoint and their union gives $\{x\in X\,|\,f(x)\neq 0\}$; if $x\in E_{nj}$, then $\|y_n-f(x)\|<1/j\cdot\|y_n\|$. What I want to show is that the set $$\bigcap_{\ell=1}^{\infty}\bigcup_{k=\ell}^{\infty}\bigsqcup_{n=k+1}^{\infty}E_{nk}$$ is of measure zero (the notation $\sqcup$ emphasizes that the union is one of disjoint sets). I'm afraid I cannot use a limiting argument that exploits measures being continuous from above, as the sets $$\bigcup_{k=\ell}^{\infty}\bigsqcup_{n=k+1}^{\infty}E_{nk}$$ may be of infinite measure for all $\ell\in\mathbb Z_+$. In particular, if $\|f(x)\|>0$ for all $x\in X$ and $\mu(X)=+\infty$, then this fear is justified, as $X=\bigcup_{n=1}^{\infty} E_{nk}$ for all $k\in\mathbb Z_+$ by the second assumption above. If it is of any help, we know also that for any $\varepsilon>0$, the following holds: $$Y\setminus\{0\}\subseteq\bigcup_{n=1}^{\infty}\left\{y\in Y\,\big|\,\|y_n-y\|<\varepsilon\|y_n\|\right\}.$$ More generally (it would be enough for my purposes), is it possible to choose a map from $\mathbb Z_+$ to itself $k\mapsto N_k$ such that $$\bigcap_{\ell=1}^{\infty}\bigcup_{k=\ell}^{\infty}\bigsqcup_{n=N_k+1}^{\infty}E_{nk}$$ is of measure zero? Any suggestion will be dearly appreciated.",,"['functional-analysis', 'measure-theory']"
8,Understanding the Trace Theorem for Sobolev spaces?,Understanding the Trace Theorem for Sobolev spaces?,,"I'm reading Evans book on PDEs and I'm not sure of the meaning behind the Trace Theorem for Sobolev spaces and what it aims to accomplish. The theorem is as follows: Assume a domain $U$ is bounded and that $\partial U$ is $C^1$. Then there exists a bounded linear operator $$T: W^{1,p}(U) \to L^p(\partial U)$$ such that i) $Tu = u|_{\partial U}$ if $u \in W^{1,p}(U) \cap C(\overline{U}) $ ii) $||Tu||_{L^p(\partial U)} \le C ||u||_{W^{1,p}(U)}$ for each $u \in W^{1,p}(U)$, with $C$ depending only on $p$ and $U$. I get that if $u$ is continuous we have already have a definition of $u$ on the boundary and this leads to i). I don't see what is meant by ii) though. I read it as 'for any $u \in W^{1, p}$, the size of $T$ acting on $u$ in $L^p$ over the boundary $\partial U$ will always be less than or equal to a constant times the size of $u$ in $W^{1, p}$ over the entire domain $U$'. How is this useful, we haven't even given an explicit definition of $T$, we have only made a statement about its size? We are relating norms over different domains ($\partial U$ and $U$), this seems like a meaningless thing to do..so why do we do it? Furthermore, what is the relevance of $||Tu||_{L^p(\partial U)}$ being less than or equal to a constant times $||u||_{W^{1,p}(U)}$? The constant could be arbitrarily large so I don't see the point of making this statement?","I'm reading Evans book on PDEs and I'm not sure of the meaning behind the Trace Theorem for Sobolev spaces and what it aims to accomplish. The theorem is as follows: Assume a domain $U$ is bounded and that $\partial U$ is $C^1$. Then there exists a bounded linear operator $$T: W^{1,p}(U) \to L^p(\partial U)$$ such that i) $Tu = u|_{\partial U}$ if $u \in W^{1,p}(U) \cap C(\overline{U}) $ ii) $||Tu||_{L^p(\partial U)} \le C ||u||_{W^{1,p}(U)}$ for each $u \in W^{1,p}(U)$, with $C$ depending only on $p$ and $U$. I get that if $u$ is continuous we have already have a definition of $u$ on the boundary and this leads to i). I don't see what is meant by ii) though. I read it as 'for any $u \in W^{1, p}$, the size of $T$ acting on $u$ in $L^p$ over the boundary $\partial U$ will always be less than or equal to a constant times the size of $u$ in $W^{1, p}$ over the entire domain $U$'. How is this useful, we haven't even given an explicit definition of $T$, we have only made a statement about its size? We are relating norms over different domains ($\partial U$ and $U$), this seems like a meaningless thing to do..so why do we do it? Furthermore, what is the relevance of $||Tu||_{L^p(\partial U)}$ being less than or equal to a constant times $||u||_{W^{1,p}(U)}$? The constant could be arbitrarily large so I don't see the point of making this statement?",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
9,$5$ questions on the definition of the Gelfand triple,questions on the definition of the Gelfand triple,5,"Let $(H,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a Hilbert space over $\mathbb F\in\left\{\mathbb R,\mathbb C\right\}$ , $\left\|\;\cdot\;\right\|$ be the norm induced by $\langle\;\cdot\;,\;\cdot\;\rangle$ and $\Phi$ be a subspace of $H$ . Question 1 : Why can we find a finer topology $\tau$ on $\Phi$ such that $$\iota:(\Phi,\tau)\to(H,\left\|\;\cdot\;\right\|)\;,\;\;\;x\mapsto x\tag 1$$ is continuous? Question 2 : Why is it no loss to assume that $\Phi$ is dense in $(H,\left\|\;\cdot\;\right\|)$ ? Now, let $$\Phi^\ast\stackrel{\text{def}}=\left\{f:\Phi\to\mathbb F\mid f\text{ is continuous and linear}\right\}\tag 2$$ denote the dual space of $\Phi$ . Then, for all $f\in\Phi^*$ there is exactly one $\phi\in\Phi$ such that $$f\equiv\langle\;\cdot\;,\phi\rangle\tag 3$$ by the Fréchet-Riesz representation theorem . Let me quote from the Wikipedia article about the Gelfand triple : We consider the inclusion of dual spaces $H^\ast$ in $\Phi^\ast$ . The latter, dual to $\Phi$ in its 'test function' topology, is realised as a space of distributions or generalised functions of some sort, and the linear functionals on the subspace $\Phi$ of type $$\phi\mapsto\langle v,\phi\rangle$$ for $v$ in $H$ are faithfully represented as distributions (because we assume $\Phi$ dense). I can't make much sense of this paragraph. Question 3 : In $(1)$ we had considered the inclusion of $\Phi$ in $H$ . Why do we now consider the inclusion of $H^\ast$ in $\Phi^\ast$ ? Moreover, given the definition of the dual space in $(2)$ , we won't have $H^\ast\subseteq\Phi^\ast$ unless $\Phi=H$ . So, what is meant by inclusion here? Question 4 : What do they mean by 'test function' topology ? Is that just a fancy name for $\tau$ ? Question 5 : I have no idea what they mean in the last sentence. I'm not familiar with distributions. Is this somehow related to $(3)$ ? And why do we need the density of $\Phi^\ast$ ?","Let be a Hilbert space over , be the norm induced by and be a subspace of . Question 1 : Why can we find a finer topology on such that is continuous? Question 2 : Why is it no loss to assume that is dense in ? Now, let denote the dual space of . Then, for all there is exactly one such that by the Fréchet-Riesz representation theorem . Let me quote from the Wikipedia article about the Gelfand triple : We consider the inclusion of dual spaces in . The latter, dual to in its 'test function' topology, is realised as a space of distributions or generalised functions of some sort, and the linear functionals on the subspace of type for in are faithfully represented as distributions (because we assume dense). I can't make much sense of this paragraph. Question 3 : In we had considered the inclusion of in . Why do we now consider the inclusion of in ? Moreover, given the definition of the dual space in , we won't have unless . So, what is meant by inclusion here? Question 4 : What do they mean by 'test function' topology ? Is that just a fancy name for ? Question 5 : I have no idea what they mean in the last sentence. I'm not familiar with distributions. Is this somehow related to ? And why do we need the density of ?","(H,\langle\;\cdot\;,\;\cdot\;\rangle) \mathbb F\in\left\{\mathbb R,\mathbb C\right\} \left\|\;\cdot\;\right\| \langle\;\cdot\;,\;\cdot\;\rangle \Phi H \tau \Phi \iota:(\Phi,\tau)\to(H,\left\|\;\cdot\;\right\|)\;,\;\;\;x\mapsto x\tag 1 \Phi (H,\left\|\;\cdot\;\right\|) \Phi^\ast\stackrel{\text{def}}=\left\{f:\Phi\to\mathbb F\mid f\text{ is continuous and linear}\right\}\tag 2 \Phi f\in\Phi^* \phi\in\Phi f\equiv\langle\;\cdot\;,\phi\rangle\tag 3 H^\ast \Phi^\ast \Phi \Phi \phi\mapsto\langle v,\phi\rangle v H \Phi (1) \Phi H H^\ast \Phi^\ast (2) H^\ast\subseteq\Phi^\ast \Phi=H \tau (3) \Phi^\ast","['analysis', 'functional-analysis', 'operator-theory', 'hilbert-spaces', 'distribution-theory']"
10,Radon-Nikodým (write the density as a limit),Radon-Nikodým (write the density as a limit),,"Let $\mu$ be a probability measure and $\nu$ a $\sigma$-finite measure on $(\mathbb{R},\mathcal{B})$ with $\nu\ll\mu$. Show that it is $\mu$-a.s. $$ \lim_{h\to 0}\frac{\nu [x-h,x+h)}{\mu [x-h,x+h)}=\frac{d\nu}{d\mu}(x). $$ I do not have many ideas... Set $f:=\frac{d\nu}{d\mu}$. Then $\nu [x-h,x+h)=\int_{[x-h,x+h)}f\, d\mu$ and $$ \lim_{h\to 0}\frac{\nu [x-h,x+h)}{\mu [x-h,x+h)}=\lim_{h\to 0}\frac{\int_{[x-h,x+h)}f\, d\mu}{\mu [x-h,x+h)}. $$ But that does not really help. Can you help me, please? Miro","Let $\mu$ be a probability measure and $\nu$ a $\sigma$-finite measure on $(\mathbb{R},\mathcal{B})$ with $\nu\ll\mu$. Show that it is $\mu$-a.s. $$ \lim_{h\to 0}\frac{\nu [x-h,x+h)}{\mu [x-h,x+h)}=\frac{d\nu}{d\mu}(x). $$ I do not have many ideas... Set $f:=\frac{d\nu}{d\mu}$. Then $\nu [x-h,x+h)=\int_{[x-h,x+h)}f\, d\mu$ and $$ \lim_{h\to 0}\frac{\nu [x-h,x+h)}{\mu [x-h,x+h)}=\lim_{h\to 0}\frac{\int_{[x-h,x+h)}f\, d\mu}{\mu [x-h,x+h)}. $$ But that does not really help. Can you help me, please? Miro",,"['functional-analysis', 'measure-theory']"
11,Closed unit ball is compact?,Closed unit ball is compact?,,"Let $X$ be a Banach space and let $\operatorname{Lip}_{0}(X)$ be the space of all real-valued Lipschitz functions which vanish at $0$. The space $\operatorname{Lip}_{0}(X)$ is a Banach space when it is equipped with the Lipschitz norm, defined by: $$L(f)=\|f\|_{\operatorname{Lip}}=\sup\left\{\frac{f(x)-f(y)}{\|x-y\|}:\,x,y\in X,\,x\neq y\right\}$$ My goal is to show that the closed unit ball of the space $\operatorname{Lip}_{0}(X)$ is compact for the topology of pointwise convergence. I have try with no success to use Tychonoff theorem or Banach-Alaoglu theorem. I failed because the Banach-Alaoglu theorem concerned the closed unit ball of the dual space with the weak-star topology. Thank for any help.","Let $X$ be a Banach space and let $\operatorname{Lip}_{0}(X)$ be the space of all real-valued Lipschitz functions which vanish at $0$. The space $\operatorname{Lip}_{0}(X)$ is a Banach space when it is equipped with the Lipschitz norm, defined by: $$L(f)=\|f\|_{\operatorname{Lip}}=\sup\left\{\frac{f(x)-f(y)}{\|x-y\|}:\,x,y\in X,\,x\neq y\right\}$$ My goal is to show that the closed unit ball of the space $\operatorname{Lip}_{0}(X)$ is compact for the topology of pointwise convergence. I have try with no success to use Tychonoff theorem or Banach-Alaoglu theorem. I failed because the Banach-Alaoglu theorem concerned the closed unit ball of the dual space with the weak-star topology. Thank for any help.",,['functional-analysis']
12,Closure in the Space of Probability Measures with the Prohorov metric,Closure in the Space of Probability Measures with the Prohorov metric,,"I have seen this result stated countless times: assume the metric space $(\theta,d)$ is separable; then $(\theta,d)$ is complete if and only if the space $(\mathcal{P}(\Theta),\rho)$ (the space of probability measures, taken with the Prohorov metric--which is equivalent to the weak* topology) is complete.  See, for instance, Billingsley, Convergence of Probability Measures (1968), pg 240 W. Whitt, Weak Convergence of Probability Measures on the Function Space $C[0,\infty)$, Annals of Math. Stat 41 (1970), Corollary 2 http://www.math.leidenuniv.nl/~vangaans/jancol1.pdf , Theorem 9.2 But if this result holds (say, for $\Theta = \mathbb{R}$), then $(\mathcal{P}(\Theta),\rho)$ is weak* closed, which is false (see, e.g., milanmerkle.com/documents/radovi/WEACO2a.pdf , Section 5.4; a similar discussion has been had on these boards: Is the set of all probability measures weak*-closed? ) The proof of the first result typically relies on Prohorov's Theorem: take a Cauchy sequence $\{P_{n}\}$, show that the sequence is tight, therefore it is relatively sequentially compact.  But in all the cases mentioned above, the authors use relative sequential compactness to conclude that the sequence must have a convergent subsequence in the space of probability measures (rather than the closure of that space).  This seems to be the error, but the result is stated so ubiquitously that I feel I may be missing something.... UPDATE: I have located another related question: Tightness of a sequence of probability measures and weak convergence of a subsequence In Billingsley's proof (of my result), we take a Cauchy sequence $\{P_{n}\}$ and show that the sequence is tight, which is taken to prove the convergence of a subsequence.  But this result seems incorrect, since tightness is only sufficient to prove the relative compactness of the set of measures in the sequence (by Prohorov's Theorem).","I have seen this result stated countless times: assume the metric space $(\theta,d)$ is separable; then $(\theta,d)$ is complete if and only if the space $(\mathcal{P}(\Theta),\rho)$ (the space of probability measures, taken with the Prohorov metric--which is equivalent to the weak* topology) is complete.  See, for instance, Billingsley, Convergence of Probability Measures (1968), pg 240 W. Whitt, Weak Convergence of Probability Measures on the Function Space $C[0,\infty)$, Annals of Math. Stat 41 (1970), Corollary 2 http://www.math.leidenuniv.nl/~vangaans/jancol1.pdf , Theorem 9.2 But if this result holds (say, for $\Theta = \mathbb{R}$), then $(\mathcal{P}(\Theta),\rho)$ is weak* closed, which is false (see, e.g., milanmerkle.com/documents/radovi/WEACO2a.pdf , Section 5.4; a similar discussion has been had on these boards: Is the set of all probability measures weak*-closed? ) The proof of the first result typically relies on Prohorov's Theorem: take a Cauchy sequence $\{P_{n}\}$, show that the sequence is tight, therefore it is relatively sequentially compact.  But in all the cases mentioned above, the authors use relative sequential compactness to conclude that the sequence must have a convergent subsequence in the space of probability measures (rather than the closure of that space).  This seems to be the error, but the result is stated so ubiquitously that I feel I may be missing something.... UPDATE: I have located another related question: Tightness of a sequence of probability measures and weak convergence of a subsequence In Billingsley's proof (of my result), we take a Cauchy sequence $\{P_{n}\}$ and show that the sequence is tight, which is taken to prove the convergence of a subsequence.  But this result seems incorrect, since tightness is only sufficient to prove the relative compactness of the set of measures in the sequence (by Prohorov's Theorem).",,"['functional-analysis', 'probability-theory']"
13,Motivation/Intuition behind Lorentz spaces,Motivation/Intuition behind Lorentz spaces,,"My current understanding is that the Lorentz spaces $L^{p,q}$ arise naturally as interpolation spaces between $L^1$ and $L^\infty$, but then people often describe them heuristically by saying something along the lines of ""Lorentz spaces provide a finer control than $L^p$ spaces"", and this is where I'm lost - what does that really mean? It certainly seems like a reasonable claim, if only because you now have an extra parameter to tweak, and since $L^{p,p}=L^p$, well the Lorentz spaces are simply a larger class of spaces amongst which your classical $L^p$ spaces live, so sure, they are ""better"" because there's more of them, so I can give more nuanced descriptions, but I don't really understand where the nuance lies, I don't understand what extra control the Lorentz spaces provide you that the usual $L^p$ spaces do not. I feel like my question is very vague overall, so feel free to ask for clarifications. As an example of the type of answer that I think there might be to what I am asking is the following cryptic (to me anyway) comment on the wikipedia page for ""Lorentz spaces"": ""The Lorentz norms provide tighter control over both qualities than the $L^{p}$ norms, by exponentially rescaling the measure in both the range (p) and the domain (q)"". I have no idea what that means, if anyone does, please let me know, but it seems like, after clarification, it would provide a nice intuitive explanation for precisely how Lorentz spaces provide finer control than $L^p$ spaces do.","My current understanding is that the Lorentz spaces $L^{p,q}$ arise naturally as interpolation spaces between $L^1$ and $L^\infty$, but then people often describe them heuristically by saying something along the lines of ""Lorentz spaces provide a finer control than $L^p$ spaces"", and this is where I'm lost - what does that really mean? It certainly seems like a reasonable claim, if only because you now have an extra parameter to tweak, and since $L^{p,p}=L^p$, well the Lorentz spaces are simply a larger class of spaces amongst which your classical $L^p$ spaces live, so sure, they are ""better"" because there's more of them, so I can give more nuanced descriptions, but I don't really understand where the nuance lies, I don't understand what extra control the Lorentz spaces provide you that the usual $L^p$ spaces do not. I feel like my question is very vague overall, so feel free to ask for clarifications. As an example of the type of answer that I think there might be to what I am asking is the following cryptic (to me anyway) comment on the wikipedia page for ""Lorentz spaces"": ""The Lorentz norms provide tighter control over both qualities than the $L^{p}$ norms, by exponentially rescaling the measure in both the range (p) and the domain (q)"". I have no idea what that means, if anyone does, please let me know, but it seems like, after clarification, it would provide a nice intuitive explanation for precisely how Lorentz spaces provide finer control than $L^p$ spaces do.",,"['analysis', 'functional-analysis', 'measure-theory']"
14,"Two definitions of $H^1(\partial\Omega)$, one using charts and one use tangential gradients","Two definitions of , one using charts and one use tangential gradients",H^1(\partial\Omega),"Let $\Omega$ be a bounded Lipschitz domain with boundary $\partial\Omega$. There are two ways to define a space $H^1(\partial\Omega)$: By using charts, we can define $H^1(\partial\Omega)$ to contain functions $u\colon \partial\Omega \to \mathbb{R}$ such that $u\circ g_i \in H^1(D_i)$ for all $i$ where $g_i\colon D_i \subset \mathbb{R}^{n-1} \to \mathbb{R}$ is a chart map. The norm is the obvious norm. We can define a tangential gradient on $\partial\Omega$ as: $$\nabla_S \varphi = \nabla \varphi - (\nabla \varphi \cdot \nu)\nu$$ where $\nu$ is the unit normal vector on $\partial\Omega$ and $\nabla$ is the usual gradient. Here $\varphi$ is smooth. We can get a weak version of the tangential gradient by using the integration by parts formula on surface, let's call the weak tangential gradient $\nabla_T.$ Then we can define $H^1(\partial\Omega)$ as functions $u:\partial\Omega \to \mathbb{R}$ such that $u \in L^2(\partial\Omega)$ and $\nabla_T u \in L^2(\partial\Omega)$, and give it the obvious norm. My question: are these definitions equivalent in some way? Do we have equivalence of norms? The second definition is not very common or popular, why is that?","Let $\Omega$ be a bounded Lipschitz domain with boundary $\partial\Omega$. There are two ways to define a space $H^1(\partial\Omega)$: By using charts, we can define $H^1(\partial\Omega)$ to contain functions $u\colon \partial\Omega \to \mathbb{R}$ such that $u\circ g_i \in H^1(D_i)$ for all $i$ where $g_i\colon D_i \subset \mathbb{R}^{n-1} \to \mathbb{R}$ is a chart map. The norm is the obvious norm. We can define a tangential gradient on $\partial\Omega$ as: $$\nabla_S \varphi = \nabla \varphi - (\nabla \varphi \cdot \nu)\nu$$ where $\nu$ is the unit normal vector on $\partial\Omega$ and $\nabla$ is the usual gradient. Here $\varphi$ is smooth. We can get a weak version of the tangential gradient by using the integration by parts formula on surface, let's call the weak tangential gradient $\nabla_T.$ Then we can define $H^1(\partial\Omega)$ as functions $u:\partial\Omega \to \mathbb{R}$ such that $u \in L^2(\partial\Omega)$ and $\nabla_T u \in L^2(\partial\Omega)$, and give it the obvious norm. My question: are these definitions equivalent in some way? Do we have equivalence of norms? The second definition is not very common or popular, why is that?",,"['functional-analysis', 'differential-geometry', 'partial-differential-equations', 'sobolev-spaces']"
15,"Operator topologies on $L^{\infty}(X,\mu )$",Operator topologies on,"L^{\infty}(X,\mu )","Let $(X,\mu )$ be a measure space.  Then, $L^2(X):=L^2(X,\mu )$ is a Hilbert space in the usual way and we may view $L^{\infty}(X):=L^{\infty}(X,\mu )$ as a subalgebra of bounded operators on $L^2(X)$ via $L^{\infty}(X)\ni f\mapsto M_f$, where $M_f\colon L^2(X)\rightarrow L^2(X)$ is the multiplication operator defined by $[M_f(g)](x):=f(x)g(x)$. Regarding $L^{\infty}(X)$ as an algebra of bounded operators in this way, the question can be stated as How can we describe explicitly convergence in the various operator topologies on $L^{\infty}(X)$? At least one is relatively easy.  For example, $\lambda \mapsto M_{f_{\lambda}}$ converges to $M_f$ in the operator norm topology iff $\lambda \mapsto f_{\lambda}$ converges to $f$ in the $L^{\infty}$ norm.  It seems that convergence in measure corresponds to ultra-weak convergence .  Furthermore, pointwise almost-everywhere convergence can't correspond to any topology .  These are perhaps the three most obvious notions of convergence in $L^{\infty}(X)$, but that leaves many operator topologies unaccounted for.  Perhaps most of them just don't have a very nice description? Update #1 :  It seems as if the weak operator topology corresponds to the weak-$^*$ topology:  $\lambda \mapsto f_{\lambda}\in L^{\infty}(X)$ converges to $f\in L^{\infty}(X)$ in the weak-$^*$ topology iff $\lambda \mapsto \int _Xgf_{\lambda}$ converges to $\int _Xgf$ for all $g\in L^1(X)$, and on the other hand, $\lambda \mapsto M_{f_{\lambda}}$ converges to $M_f$ in the weak operator topology iff $\lambda \mapsto \int _Xgf_{\lambda}h$ converges to $\int  _Xgfh$ for all $g,h\in L^2(X)$.  As $gh\in L^1(X)$ for $g,h\in L^2(X)$, we obtain the $(\Rightarrow )$ direction immediately.  For the $(\Leftarrow )$ write $g=u|g|$ for some Borel function $u$ with $|u|=1$, so that we have $\lambda \mapsto \int _Xgf_{\lambda}=\int _X(u|g|^{1/2})f_{\lambda}|g|^{1/2}$ converges to $\int _X(u|g|^{1/2})f|g|^{1/2}=\int _Xgf$. Update #2 :  I have decided to ask this on mathoverflow .","Let $(X,\mu )$ be a measure space.  Then, $L^2(X):=L^2(X,\mu )$ is a Hilbert space in the usual way and we may view $L^{\infty}(X):=L^{\infty}(X,\mu )$ as a subalgebra of bounded operators on $L^2(X)$ via $L^{\infty}(X)\ni f\mapsto M_f$, where $M_f\colon L^2(X)\rightarrow L^2(X)$ is the multiplication operator defined by $[M_f(g)](x):=f(x)g(x)$. Regarding $L^{\infty}(X)$ as an algebra of bounded operators in this way, the question can be stated as How can we describe explicitly convergence in the various operator topologies on $L^{\infty}(X)$? At least one is relatively easy.  For example, $\lambda \mapsto M_{f_{\lambda}}$ converges to $M_f$ in the operator norm topology iff $\lambda \mapsto f_{\lambda}$ converges to $f$ in the $L^{\infty}$ norm.  It seems that convergence in measure corresponds to ultra-weak convergence .  Furthermore, pointwise almost-everywhere convergence can't correspond to any topology .  These are perhaps the three most obvious notions of convergence in $L^{\infty}(X)$, but that leaves many operator topologies unaccounted for.  Perhaps most of them just don't have a very nice description? Update #1 :  It seems as if the weak operator topology corresponds to the weak-$^*$ topology:  $\lambda \mapsto f_{\lambda}\in L^{\infty}(X)$ converges to $f\in L^{\infty}(X)$ in the weak-$^*$ topology iff $\lambda \mapsto \int _Xgf_{\lambda}$ converges to $\int _Xgf$ for all $g\in L^1(X)$, and on the other hand, $\lambda \mapsto M_{f_{\lambda}}$ converges to $M_f$ in the weak operator topology iff $\lambda \mapsto \int _Xgf_{\lambda}h$ converges to $\int  _Xgfh$ for all $g,h\in L^2(X)$.  As $gh\in L^1(X)$ for $g,h\in L^2(X)$, we obtain the $(\Rightarrow )$ direction immediately.  For the $(\Leftarrow )$ write $g=u|g|$ for some Borel function $u$ with $|u|=1$, so that we have $\lambda \mapsto \int _Xgf_{\lambda}=\int _X(u|g|^{1/2})f_{\lambda}|g|^{1/2}$ converges to $\int _X(u|g|^{1/2})f|g|^{1/2}=\int _Xgf$. Update #2 :  I have decided to ask this on mathoverflow .",,"['functional-analysis', 'measure-theory', 'operator-theory', 'operator-algebras']"
16,Compact embedding in weighted Sobolev spaces,Compact embedding in weighted Sobolev spaces,,"I have a question concerning Sobolev's embedding. Let (for simplicity) $\Omega=\left(  0,1\right)  $. Then it is well known by Rellich's theorem that $H^{1}\left(  \Omega\right)  $ is compactly embedded in $L^{2}\left(  \Omega\right)  $. The situation becomes unclear to me, if I consider a weighted $H^{1}\left(  \Omega\right)  $ space by introducing the norm $\left\Vert u\right\Vert _{1,w}:=\left\Vert u\right\Vert _{L^{2}\left(  \Omega\right)  }+\left\Vert xu^{\prime}\right\Vert _{L^{2}\left(  \Omega\right)  }$ and letting $H_{w}^{1}\left(  \Omega\right) $ be the closure of smooth and compactly support functions in $\Omega$. Question: Is $H_{w}^{1}\left(  \Omega\right)  $ compactly embedded in $L^{2}\left(  \Omega\right)  $ or is the embedding only continuous?","I have a question concerning Sobolev's embedding. Let (for simplicity) $\Omega=\left(  0,1\right)  $. Then it is well known by Rellich's theorem that $H^{1}\left(  \Omega\right)  $ is compactly embedded in $L^{2}\left(  \Omega\right)  $. The situation becomes unclear to me, if I consider a weighted $H^{1}\left(  \Omega\right)  $ space by introducing the norm $\left\Vert u\right\Vert _{1,w}:=\left\Vert u\right\Vert _{L^{2}\left(  \Omega\right)  }+\left\Vert xu^{\prime}\right\Vert _{L^{2}\left(  \Omega\right)  }$ and letting $H_{w}^{1}\left(  \Omega\right) $ be the closure of smooth and compactly support functions in $\Omega$. Question: Is $H_{w}^{1}\left(  \Omega\right)  $ compactly embedded in $L^{2}\left(  \Omega\right)  $ or is the embedding only continuous?",,"['functional-analysis', 'sobolev-spaces']"
17,Non-trivial faces of the closed convex hull of a non-convex closed set with connected complement,Non-trivial faces of the closed convex hull of a non-convex closed set with connected complement,,"I'm trying to prove or disprove a problem, but I'm struggling to make headway. Any help is appreciated. Suppose $X$ is a Hilbert Space, and $C \subseteq X$ is closed, bounded, non-convex, and $X \setminus C$ is connected. Does the boundary of $\operatorname{conv} C$ necessarily contain a line segment? The following are my thoughts on the problem: The connectedness and openness of the complement gives us an open subset of the boundary of $\operatorname{conv} C$ that doesn't intersect $C$. The Bishop-Phelps theorem tells us that support points are dense in the boundary of convex sets, so there must exist support points of $\overline{\operatorname{conv}} C$ that aren't contained in $C$. If we choose one such point, by translation, we can say it is $0$ without loss of generality. If this point is not extreme in $\overline{\operatorname{conv}} C$, then we are done. However, such points can be extreme (e.g. take $C$ to be the standard orthonormal basis in $l^2$, in which case $0$ is such a point). I decided to look at the tangent cone of $\overline{\operatorname{conv}} C$ from the point $0$. I then picked a support point $x$ of this cone, other than $0$, but close enough that we could guarantee that it would not be in $C$. The supporting hyperplane must support the set $\overline{\operatorname{conv}} C$ at $0$. I'm hoping to show that $x \in \overline{\operatorname{conv}} C$. This is where I get stuck. If the functional that supports at $x$ achieves its maximum on $C$, then I get to the result, but this may not be the case. Again, any help is appreciated. Thanks in advance.","I'm trying to prove or disprove a problem, but I'm struggling to make headway. Any help is appreciated. Suppose $X$ is a Hilbert Space, and $C \subseteq X$ is closed, bounded, non-convex, and $X \setminus C$ is connected. Does the boundary of $\operatorname{conv} C$ necessarily contain a line segment? The following are my thoughts on the problem: The connectedness and openness of the complement gives us an open subset of the boundary of $\operatorname{conv} C$ that doesn't intersect $C$. The Bishop-Phelps theorem tells us that support points are dense in the boundary of convex sets, so there must exist support points of $\overline{\operatorname{conv}} C$ that aren't contained in $C$. If we choose one such point, by translation, we can say it is $0$ without loss of generality. If this point is not extreme in $\overline{\operatorname{conv}} C$, then we are done. However, such points can be extreme (e.g. take $C$ to be the standard orthonormal basis in $l^2$, in which case $0$ is such a point). I decided to look at the tangent cone of $\overline{\operatorname{conv}} C$ from the point $0$. I then picked a support point $x$ of this cone, other than $0$, but close enough that we could guarantee that it would not be in $C$. The supporting hyperplane must support the set $\overline{\operatorname{conv}} C$ at $0$. I'm hoping to show that $x \in \overline{\operatorname{conv}} C$. This is where I get stuck. If the functional that supports at $x$ achieves its maximum on $C$, then I get to the result, but this may not be the case. Again, any help is appreciated. Thanks in advance.",,"['functional-analysis', 'convex-analysis', 'hilbert-spaces', 'convex-hulls']"
18,Is every self-adjoint operator bounded?,Is every self-adjoint operator bounded?,,"This is a problem our teacher gave us and I have a feeling he forgot to mention some additional data. Let $H$ be a Hilbert space and $T : H \to H$ a everywhere-defined linear operator such that $T$ is self-adjoint, i.e. $\forall x,y \in H : \langle Tx,y\rangle=\langle x,Ty\rangle$ . Show that $T$ is bounded! Using Cauchy-Schwarz inequality it is clear that if $T$ is idempotent then it's bounded, but with just the information initially provided I don't feel like it's possible to prove the boundedness. Can somebody shed some light on this? Perhaps with a counter-example?","This is a problem our teacher gave us and I have a feeling he forgot to mention some additional data. Let be a Hilbert space and a everywhere-defined linear operator such that is self-adjoint, i.e. . Show that is bounded! Using Cauchy-Schwarz inequality it is clear that if is idempotent then it's bounded, but with just the information initially provided I don't feel like it's possible to prove the boundedness. Can somebody shed some light on this? Perhaps with a counter-example?","H T : H \to H T \forall x,y \in H : \langle Tx,y\rangle=\langle x,Ty\rangle T T","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'self-adjoint-operators']"
19,"Elegant proof that $L^2([a,b])$ is separable",Elegant proof that  is separable,"L^2([a,b])","Is anybody aware of, or can provide at least an outline, of a proof that the Hilbert space of Lebesgue functions square-integrable on the closed real interval [a,b], equipped with the $L^2$ norm, is separable? I've seen an ugly proof involving truncated functions so I'm not desperate, but would really like to use something nice. By the way, if you refer to a particular dense countable subset, could you please explain why it is dense and countable even if you consider it to be a fairly 'high-profile' set? Thanks","Is anybody aware of, or can provide at least an outline, of a proof that the Hilbert space of Lebesgue functions square-integrable on the closed real interval [a,b], equipped with the $L^2$ norm, is separable? I've seen an ugly proof involving truncated functions so I'm not desperate, but would really like to use something nice. By the way, if you refer to a particular dense countable subset, could you please explain why it is dense and countable even if you consider it to be a fairly 'high-profile' set? Thanks",,"['functional-analysis', 'hilbert-spaces']"
20,A Banach space that is not a Hilbert space,A Banach space that is not a Hilbert space,,Can someone give me an example of a Banach space that is not a Hilbert space? I can't think of any because I don't know how to show one space that can not have inner product structure.,Can someone give me an example of a Banach space that is not a Hilbert space? I can't think of any because I don't know how to show one space that can not have inner product structure.,,"['functional-analysis', 'hilbert-spaces', 'banach-spaces', 'normed-spaces', 'inner-products']"
21,T compact if and only if $T^*T$ is compact.,T compact if and only if  is compact.,T^*T,"I have an operator $T \in B(\mathcal{H})$ . I need to prove that T is comapct if and only if $T^*T$ is compact. One way is ok, because if $A$ or $B$ is compact then $AB$ is compact, so I get at once that if $T$ is compact then $T^*T$ is compact. But how do I go the other way? If I assume that $T^*T$ is compact I am not quite sure how to see that $T$ is compact. If I assume for contradiction that $T$ is not compact I must also have that $T^*$ is not compact. If I knew that either $T$ or $T^*$ was invertible it would be ok, because then I could find a bounded subsequence that did not converge. But when I do not have invertibility I am not quite sure how to proceed.","I have an operator . I need to prove that T is comapct if and only if is compact. One way is ok, because if or is compact then is compact, so I get at once that if is compact then is compact. But how do I go the other way? If I assume that is compact I am not quite sure how to see that is compact. If I assume for contradiction that is not compact I must also have that is not compact. If I knew that either or was invertible it would be ok, because then I could find a bounded subsequence that did not converge. But when I do not have invertibility I am not quite sure how to proceed.",T \in B(\mathcal{H}) T^*T A B AB T T^*T T^*T T T T^* T T^*,"['functional-analysis', 'compact-operators', 'adjoint-operators']"
22,An example of non-closed subspace of a Hilbert space?,An example of non-closed subspace of a Hilbert space?,,I am reading a book on Hilbert space. It seems that the author assumes that a linear subspace of a Hilbert space can be non-closed. I cannot think of an example. I am still used to the finite-dimensional case. Can anyone give me an example?,I am reading a book on Hilbert space. It seems that the author assumes that a linear subspace of a Hilbert space can be non-closed. I cannot think of an example. I am still used to the finite-dimensional case. Can anyone give me an example?,,"['functional-analysis', 'hilbert-spaces']"
23,When is the image of a linear operator (between Banach spaces) closed?,When is the image of a linear operator (between Banach spaces) closed?,,Let $T: X \longrightarrow Y$ be a continuous linear map between two Banach spaces. When is $\operatorname{Ran}(T)$ a closed subspace? What theorems are there? Thanks :),Let $T: X \longrightarrow Y$ be a continuous linear map between two Banach spaces. When is $\operatorname{Ran}(T)$ a closed subspace? What theorems are there? Thanks :),,"['functional-analysis', 'operator-theory', 'closed-graph']"
24,$l_1$ equipped with the sup norm is NOT a Banach Space,equipped with the sup norm is NOT a Banach Space,l_1,"Prove that $l_1 = \{ x = (x_k)_{k\in\mathbb{N}}\subset \mathbb{R};\ \sum_{k\in\mathbb{N}}\ |x_k| < +\infty \}$ equipped with the norm $\| x\| = \mathrm{sup}_{k\in\mathbb{N}} |x_k|$ is NOT a Banach Space. I've tried to solve it considering the sequence $x_n = (\frac{1}{k^{1 + 1/n}}),\ \forall n \in \mathbb{N}$ Since $\sum_{k\in\mathbb{N}}\frac{1}{k^{1 + 1/n}} < +\infty$ (because $1+1/n > 1$), $(x_n)_{n\in\mathbb{N}}$ is a sequence in $l_1$. We also have that $x_n \longrightarrow (1/k)_{k\in\mathbb{N}},$ as $n\longrightarrow +\infty$, and this one is not in $l_1$. I would like to prove that $(x_n)_{n\in\mathbb{N}}$ is a Cauchy sequence, but I don't have a clue how to do it.","Prove that $l_1 = \{ x = (x_k)_{k\in\mathbb{N}}\subset \mathbb{R};\ \sum_{k\in\mathbb{N}}\ |x_k| < +\infty \}$ equipped with the norm $\| x\| = \mathrm{sup}_{k\in\mathbb{N}} |x_k|$ is NOT a Banach Space. I've tried to solve it considering the sequence $x_n = (\frac{1}{k^{1 + 1/n}}),\ \forall n \in \mathbb{N}$ Since $\sum_{k\in\mathbb{N}}\frac{1}{k^{1 + 1/n}} < +\infty$ (because $1+1/n > 1$), $(x_n)_{n\in\mathbb{N}}$ is a sequence in $l_1$. We also have that $x_n \longrightarrow (1/k)_{k\in\mathbb{N}},$ as $n\longrightarrow +\infty$, and this one is not in $l_1$. I would like to prove that $(x_n)_{n\in\mathbb{N}}$ is a Cauchy sequence, but I don't have a clue how to do it.",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
25,"On the density of $C[0,1]$ in the space $L^{\infty}[0,1]$",On the density of  in the space,"C[0,1] L^{\infty}[0,1]","It's easy to show $C[0,1]$ is not dense in $L^{\infty}[0,1]$ in the norm topology, but $C[0,1]$ is dense in $L^{\infty}[0,1]$ in the weak*-topology when take $L^{\infty}$ as the dual of $L^{1}$. how to prove it?","It's easy to show $C[0,1]$ is not dense in $L^{\infty}[0,1]$ in the norm topology, but $C[0,1]$ is dense in $L^{\infty}[0,1]$ in the weak*-topology when take $L^{\infty}$ as the dual of $L^{1}$. how to prove it?",,"['functional-analysis', 'banach-spaces']"
26,Give an example of a real function so that every rational is a strict local minimum,Give an example of a real function so that every rational is a strict local minimum,,"Give an example of $f : \mathbb R → [0, \infty) $ so that every $r \in \mathbb Q$ is   a strict local minimum for $f$. Strict local minimum means there is a vicinity $V$ of $r$ such that $f(y) > f(r) ,\ \forall y \in V-\{r\}$ My attempt So far, none. My feeling is there isn't such a function, mainly because of the density of $\mathbb Q$ in $\mathbb R$. Suppose I define $f$ like this: $f(x) = 0$ for $x \in \mathbb Q$ and $f(x) = 1$ for $x \not \in \mathbb Q$. Every rational $r$ does not map to a strict local minimum for $f$ only because of the other rationals present in every vicinity of $r$. So $f$ cannot be constant on $\mathbb Q$, but how to define it is beyond my imagination.","Give an example of $f : \mathbb R → [0, \infty) $ so that every $r \in \mathbb Q$ is   a strict local minimum for $f$. Strict local minimum means there is a vicinity $V$ of $r$ such that $f(y) > f(r) ,\ \forall y \in V-\{r\}$ My attempt So far, none. My feeling is there isn't such a function, mainly because of the density of $\mathbb Q$ in $\mathbb R$. Suppose I define $f$ like this: $f(x) = 0$ for $x \in \mathbb Q$ and $f(x) = 1$ for $x \not \in \mathbb Q$. Every rational $r$ does not map to a strict local minimum for $f$ only because of the other rationals present in every vicinity of $r$. So $f$ cannot be constant on $\mathbb Q$, but how to define it is beyond my imagination.",,['functional-analysis']
27,"Possible flaw in ""proof"" that a sum of two compact operators is compact","Possible flaw in ""proof"" that a sum of two compact operators is compact",,"If X and Y are Banach spaces, and $A: X \to Y$, $B: X \to Y$ are both compact operators, then $A + B$ is compact. A + B is compact if and only if for every bounded sequence $\lbrace x_n \rbrace$ in X, the sequence $\lbrace (A + B) x_n \rbrace$ has a convergent subsequence; certainly both $\lbrace A x_n \rbrace$ and $\lbrace B x_n \rbrace$ each have a convergent subsequence, and I've seen a few proofs that seem to think it straightforward that this implies $\lbrace (A + B) x_n \rbrace$ has one. This doesn't seem quite right to me. The way it appears one should try to make a convergent subsequence is to intersect the indices of the convergent subsequences for A and B individually. So, for example, if $\lbrace A x_{n_j} \rbrace$ and $\lbrace B x_{n_k} \rbrace$, then the idea is to take the set of indices $\lbrace n_m \rbrace := \lbrace n_j \rbrace \cap \lbrace n_k \rbrace$ and say that $\lbrace (A + B) x_{n_m} \rbrace$ converges as a sum of two further subsequences of the convergent subsequences for A and B. But what if that intersection is empty, for example if $\lbrace n_j \rbrace = 1, 3, 5, ...$ and $\lbrace n_k \rbrace = 2, 4, 6, ...$? Instinctively I would say ""if they're disjoint, just pick a different pair"", but how can one be sure that the intersection isn't empty for any chosen pair of convergent subsequences? To be clear, I believe that A + B is compact, it's this form of proof of the fact that seems dubious to me.","If X and Y are Banach spaces, and $A: X \to Y$, $B: X \to Y$ are both compact operators, then $A + B$ is compact. A + B is compact if and only if for every bounded sequence $\lbrace x_n \rbrace$ in X, the sequence $\lbrace (A + B) x_n \rbrace$ has a convergent subsequence; certainly both $\lbrace A x_n \rbrace$ and $\lbrace B x_n \rbrace$ each have a convergent subsequence, and I've seen a few proofs that seem to think it straightforward that this implies $\lbrace (A + B) x_n \rbrace$ has one. This doesn't seem quite right to me. The way it appears one should try to make a convergent subsequence is to intersect the indices of the convergent subsequences for A and B individually. So, for example, if $\lbrace A x_{n_j} \rbrace$ and $\lbrace B x_{n_k} \rbrace$, then the idea is to take the set of indices $\lbrace n_m \rbrace := \lbrace n_j \rbrace \cap \lbrace n_k \rbrace$ and say that $\lbrace (A + B) x_{n_m} \rbrace$ converges as a sum of two further subsequences of the convergent subsequences for A and B. But what if that intersection is empty, for example if $\lbrace n_j \rbrace = 1, 3, 5, ...$ and $\lbrace n_k \rbrace = 2, 4, 6, ...$? Instinctively I would say ""if they're disjoint, just pick a different pair"", but how can one be sure that the intersection isn't empty for any chosen pair of convergent subsequences? To be clear, I believe that A + B is compact, it's this form of proof of the fact that seems dubious to me.",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'compact-operators']"
28,is bounded linear operator necessarily continuous?,is bounded linear operator necessarily continuous?,,"Let $U, V$ be separable Banach spaces. Suppose we have a bounded, linear operator $C : U\to V$ . Questions are the following Shall $C$ be continuous since $V$ is a Banach space? In general, is a bounded linear operator necessarily continuous (I guess the answer is no, but what would be a counter example?) Are things in Banach spaces always continuous?","Let be separable Banach spaces. Suppose we have a bounded, linear operator . Questions are the following Shall be continuous since is a Banach space? In general, is a bounded linear operator necessarily continuous (I guess the answer is no, but what would be a counter example?) Are things in Banach spaces always continuous?","U, V C : U\to V C V","['functional-analysis', 'partial-differential-equations', 'operator-theory', 'banach-spaces']"
29,"Prove that if a linear operator is continuous, then it is bounded.","Prove that if a linear operator is continuous, then it is bounded.",,"I'm trying to prove that if a linear operator is continuous, then it is bounded. Let $T:V\to W$. Let us assume it is continuous. Then for any $\epsilon>0$, $\|T(x-x_0)\|<\epsilon$ if $\|x-x_0\|<\delta$ for some $\delta\in \Bbb{R}$. If $T$ is bounded, then $\sup \frac{\|T(x-x_0)\|}{\|x-x_0\|}$ exists, where $x$ and $x_0$ may be any vectors in $V$ . The proof in my book ""Functional Analaysis"" by Kreyszig (pg.97) proceeds by stating Let $x=x_0+\delta\frac{y}{\|y\|}$, where $y$ is any vector in $V$ Aren't we artificially restricting the possible values of $x$ in comparison with $x_0$? Thanks in advance!","I'm trying to prove that if a linear operator is continuous, then it is bounded. Let $T:V\to W$. Let us assume it is continuous. Then for any $\epsilon>0$, $\|T(x-x_0)\|<\epsilon$ if $\|x-x_0\|<\delta$ for some $\delta\in \Bbb{R}$. If $T$ is bounded, then $\sup \frac{\|T(x-x_0)\|}{\|x-x_0\|}$ exists, where $x$ and $x_0$ may be any vectors in $V$ . The proof in my book ""Functional Analaysis"" by Kreyszig (pg.97) proceeds by stating Let $x=x_0+\delta\frac{y}{\|y\|}$, where $y$ is any vector in $V$ Aren't we artificially restricting the possible values of $x$ in comparison with $x_0$? Thanks in advance!",,[]
30,Why are compact operators 'small'?,Why are compact operators 'small'?,,"I have been hearing different people saying this in different contexts for quite some time but I still don't quite get it. I know that compact operators map bounded sets to totally bounded ones, that the perturbation of a compact operator does not change the index, and that the calkin algebra is an indispensable tool in the study of operators in the sense that 'essentially something' becomes a useful notion. But I still suspect why they are 'small'. Now Connes says they are like 'infinitesimals' in commutative function theory, which makes me even more confused. So I guess I just post this question here and hopefully I can hear some quite good explanations about the reasoning behind this intuition. Thanks!","I have been hearing different people saying this in different contexts for quite some time but I still don't quite get it. I know that compact operators map bounded sets to totally bounded ones, that the perturbation of a compact operator does not change the index, and that the calkin algebra is an indispensable tool in the study of operators in the sense that 'essentially something' becomes a useful notion. But I still suspect why they are 'small'. Now Connes says they are like 'infinitesimals' in commutative function theory, which makes me even more confused. So I guess I just post this question here and hopefully I can hear some quite good explanations about the reasoning behind this intuition. Thanks!",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'banach-algebras']"
31,Is $L^2(\mathbb{R})$ with convolution a Banach Algebra?,Is  with convolution a Banach Algebra?,L^2(\mathbb{R}),"Is $L^2(\mathbb{R})$ a Banach algebra, with convolution? I am pretty sure the answer is no, because I think that $f,g \in L^2(\mathbb{R})$ does not imply that $f*g \in L^2(\mathbb{R})$. However, I can't seem to find a counterexample, or a proof that this is not the case, using Fourier Transform for example. Can someone give a hint? Thank you","Is $L^2(\mathbb{R})$ a Banach algebra, with convolution? I am pretty sure the answer is no, because I think that $f,g \in L^2(\mathbb{R})$ does not imply that $f*g \in L^2(\mathbb{R})$. However, I can't seem to find a counterexample, or a proof that this is not the case, using Fourier Transform for example. Can someone give a hint? Thank you",,"['functional-analysis', 'fourier-analysis']"
32,Schur's Theorem: In $\ell^1$ weak convergence of $x_n$ is the same as convergence in the norm,Schur's Theorem: In  weak convergence of  is the same as convergence in the norm,\ell^1 x_n,"I'm having a really hard time with nearly every part of this proof, any help would be appreciated. Schur's Theorem: In $\ell^1$ weak convergence of $x_n$ is the same as convergence in the norm. Definition : For $x_n \in \ell^1$ convergence in the norm: $$ x_n \to x \iff \|\ x_n - x \|_{\ell^1}  \to 0.$$ Definition : For $x_n \in \ell^1$, weak convergence: $$x_n \rightharpoonup x \iff \phi x_n \to \phi x \hspace{1cm} \forall x_n \in \ell^1 , \space\ \space\ \forall \phi \in \ell^{1*}.$$ This problem is from Muscat's ""Functional Analysis"" text. It breaks Schur's Theorem up into the following parts: 1) If the statement were false there would be unit $x_n = (a_{ni}) \in \ell^1$ such that $x_n \rightharpoonup 0$ Proof: Taking a unit $(a_{ni}) \in \ell^1$ we have that $\sum_{i=1}^{\infty} |a_{ni}| = 1$. Then, for some $\phi \in \ell^{1*}$ we (somehow?) obtain that $\phi x_n \to \phi x = 0$. 2)  For each $n$ there is an $N_n$, such that $\sum_{i=1}^{N_n} |a_{ni}| > \frac{4}{5}$. Proof: Since $(a_{ni})$ is convergent in $\ell^1$ as a unit, we have that  $$\sum_{i=1}^{\infty} |a_{ni}| = 1 \hspace{1cm} \forall n$$ as a requirement for convergent series is that their tail sequence goes to $0$, so that for $\epsilon > 0$ there exists some $N \in \mathbb{N}$ where  $$\sum_{i=N}^{\infty} |a_{ni}| < \epsilon.$$ Hence, it follows that we may find an $N_n$ where  $$\sum_{i=1}^{N_n} |a_{ni}| > \frac{4}{5} \hspace{1cm} \forall n$$ 3) Each coefficient converges to $0$ as $n \to \infty$, so $\forall k , \exists M, n \geq M \Rightarrow \sum_{i < k} |a_{ni} | < \frac{1}{5}$. Proof: Mirroring what we did above in part (2) and choosing $\epsilon = \frac{1}{5}$. 4) A subsequence of $\left\{ x_n \right\}$ exists with    $$\sum_{i < N_n - 1} |a_{ni}| < \dfrac{1}{5} , \sum_{i=N_{n-1}}^{N_n} |a_{ni} | > \dfrac{3}{5}, \sum_{i > N_n} |a_{ni} | < \dfrac{1}{5} .$$ Proof: 5) Let $y := (|a_{ni}| / a_{ni}) \in \ell^{\infty}$ where for each $i$, $n$ is such that $N_{n-1} \leq i < N_n$. Show $|y \cdot x_n | \geq \frac{1}{5}$ to obtain a contradiction. Proof:","I'm having a really hard time with nearly every part of this proof, any help would be appreciated. Schur's Theorem: In $\ell^1$ weak convergence of $x_n$ is the same as convergence in the norm. Definition : For $x_n \in \ell^1$ convergence in the norm: $$ x_n \to x \iff \|\ x_n - x \|_{\ell^1}  \to 0.$$ Definition : For $x_n \in \ell^1$, weak convergence: $$x_n \rightharpoonup x \iff \phi x_n \to \phi x \hspace{1cm} \forall x_n \in \ell^1 , \space\ \space\ \forall \phi \in \ell^{1*}.$$ This problem is from Muscat's ""Functional Analysis"" text. It breaks Schur's Theorem up into the following parts: 1) If the statement were false there would be unit $x_n = (a_{ni}) \in \ell^1$ such that $x_n \rightharpoonup 0$ Proof: Taking a unit $(a_{ni}) \in \ell^1$ we have that $\sum_{i=1}^{\infty} |a_{ni}| = 1$. Then, for some $\phi \in \ell^{1*}$ we (somehow?) obtain that $\phi x_n \to \phi x = 0$. 2)  For each $n$ there is an $N_n$, such that $\sum_{i=1}^{N_n} |a_{ni}| > \frac{4}{5}$. Proof: Since $(a_{ni})$ is convergent in $\ell^1$ as a unit, we have that  $$\sum_{i=1}^{\infty} |a_{ni}| = 1 \hspace{1cm} \forall n$$ as a requirement for convergent series is that their tail sequence goes to $0$, so that for $\epsilon > 0$ there exists some $N \in \mathbb{N}$ where  $$\sum_{i=N}^{\infty} |a_{ni}| < \epsilon.$$ Hence, it follows that we may find an $N_n$ where  $$\sum_{i=1}^{N_n} |a_{ni}| > \frac{4}{5} \hspace{1cm} \forall n$$ 3) Each coefficient converges to $0$ as $n \to \infty$, so $\forall k , \exists M, n \geq M \Rightarrow \sum_{i < k} |a_{ni} | < \frac{1}{5}$. Proof: Mirroring what we did above in part (2) and choosing $\epsilon = \frac{1}{5}$. 4) A subsequence of $\left\{ x_n \right\}$ exists with    $$\sum_{i < N_n - 1} |a_{ni}| < \dfrac{1}{5} , \sum_{i=N_{n-1}}^{N_n} |a_{ni} | > \dfrac{3}{5}, \sum_{i > N_n} |a_{ni} | < \dfrac{1}{5} .$$ Proof: 5) Let $y := (|a_{ni}| / a_{ni}) \in \ell^{\infty}$ where for each $i$, $n$ is such that $N_{n-1} \leq i < N_n$. Show $|y \cdot x_n | \geq \frac{1}{5}$ to obtain a contradiction. Proof:",,"['functional-analysis', 'lp-spaces', 'weak-convergence']"
33,Spectral radius of the Volterra operator,Spectral radius of the Volterra operator,,"The Volterra operator acting on $L^2[0,1]$ is defined by $$A(f)(x)=\int_0^x f(t) dt$$  How can I calculate the spectral radius of $A$ using the spectral radius formula for bounded linear operators: $$\rho(A)=\lim_{n\rightarrow \infty} \|A^n\|^{1/n} \text{?}$$ This was given as an exercise in a book right after introducing the spectral radius formula, so it should be simple exercise, but I don't see immediately how to do the calculations. Any hint is appreciated.","The Volterra operator acting on $L^2[0,1]$ is defined by $$A(f)(x)=\int_0^x f(t) dt$$  How can I calculate the spectral radius of $A$ using the spectral radius formula for bounded linear operators: $$\rho(A)=\lim_{n\rightarrow \infty} \|A^n\|^{1/n} \text{?}$$ This was given as an exercise in a book right after introducing the spectral radius formula, so it should be simple exercise, but I don't see immediately how to do the calculations. Any hint is appreciated.",,"['functional-analysis', 'operator-theory', 'spectral-theory', 'spectral-radius']"
34,How to prove Halmos’s Inequality,How to prove Halmos’s Inequality,,"How to prove Halmos’s Inequality? If $A$ and $B$ are bounded linear operators on a Hilbert space such that $A$, or $B$, commutes with $AB-BA$ then $$\|I-(AB- BA)\|\ge 1.$$ I found it from http://www.staff.vu.edu.au/rgmia/monographs/bullen/Dict-Ineq-Supp-Comb.pdf at page 18.","How to prove Halmos’s Inequality? If $A$ and $B$ are bounded linear operators on a Hilbert space such that $A$, or $B$, commutes with $AB-BA$ then $$\|I-(AB- BA)\|\ge 1.$$ I found it from http://www.staff.vu.edu.au/rgmia/monographs/bullen/Dict-Ineq-Supp-Comb.pdf at page 18.",,"['functional-analysis', 'inequality', 'hilbert-spaces', 'operator-theory', 'banach-algebras']"
35,Is it mathematically problematic to consider the complex space of real(!)-valued functions?,Is it mathematically problematic to consider the complex space of real(!)-valued functions?,,"$L^2(ℝ)$ is obviously a real Hilbert space, and $L^2(ℂ)$ a complex Hilbert space. However it recently occured to me that it might also make sense to consider $L^2(ℝ)$ as a complex vector space, with $$   (μ \cdot f)(x) = μ \cdot f(x) $$ in the usual way for real $μ$, but $$   (iμ \cdot f)(x) = μ \cdot H(f)(x) $$ where $H : L^2(ℝ)\to L^2(ℝ)$ is the Hilbert transform . Why? Well, physicists and engineers seem to be using that space all the time: it's generally understood that there's no such thing as an imaginary, measurable physical quantity, and when we consider “phase rotation by 90°” (i.e. multiplication with $i$) we actually mean that a sinusoidal signal is shifted by a quarter wavelength – precisely what the Hilbert transform does. Can all of this be made rigorous?","$L^2(ℝ)$ is obviously a real Hilbert space, and $L^2(ℂ)$ a complex Hilbert space. However it recently occured to me that it might also make sense to consider $L^2(ℝ)$ as a complex vector space, with $$   (μ \cdot f)(x) = μ \cdot f(x) $$ in the usual way for real $μ$, but $$   (iμ \cdot f)(x) = μ \cdot H(f)(x) $$ where $H : L^2(ℝ)\to L^2(ℝ)$ is the Hilbert transform . Why? Well, physicists and engineers seem to be using that space all the time: it's generally understood that there's no such thing as an imaginary, measurable physical quantity, and when we consider “phase rotation by 90°” (i.e. multiplication with $i$) we actually mean that a sinusoidal signal is shifted by a quarter wavelength – precisely what the Hilbert transform does. Can all of this be made rigorous?",,"['functional-analysis', 'complex-numbers', 'soft-question', 'hilbert-spaces']"
36,C* Algebra textbook recommendation,C* Algebra textbook recommendation,,I have read the first two chapters from Analysis Now and the chapter on C* algebras (chptr 8?).  I'm taking a course on C* algebras in the spring and am currently overwhelmed with the choices. I'd like to get something that isn't too highbrow. Any recommendations from experts or students in the field would be greatly appreciated.,I have read the first two chapters from Analysis Now and the chapter on C* algebras (chptr 8?).  I'm taking a course on C* algebras in the spring and am currently overwhelmed with the choices. I'd like to get something that isn't too highbrow. Any recommendations from experts or students in the field would be greatly appreciated.,,"['analysis', 'functional-analysis', 'reference-request', 'c-star-algebras']"
37,Why do we need to define Lebesgue spaces using equivalence classes?,Why do we need to define Lebesgue spaces using equivalence classes?,,"When we define an $L^{p}$ space for  $1\leq p \leq \infty$, we say elements of this space are equivalence classes of functions which are equal almost everywhere and $$ \int|f|^{p} dx < \infty $$ Why can we not say elements are functions which satisfy $ \int|f|^{p} < \infty $ ? I understand that if $g=f$  a.e. then $ ||f||_{L^{p}} = ||g||_{L^{p}} $ is this the reason for it? EDIT : The reason for asking is because I am studying an optimal control of PDEs course which says we need to be careful when considering the PDE : $ -\Delta y = f $ on $ \Omega  $ $ y=0 $ on $ \partial \Omega  $ ...since we need to define what it means for $ y=0 $ on $\partial\Omega$,  since  $\partial\Omega$ has zero measure.","When we define an $L^{p}$ space for  $1\leq p \leq \infty$, we say elements of this space are equivalence classes of functions which are equal almost everywhere and $$ \int|f|^{p} dx < \infty $$ Why can we not say elements are functions which satisfy $ \int|f|^{p} < \infty $ ? I understand that if $g=f$  a.e. then $ ||f||_{L^{p}} = ||g||_{L^{p}} $ is this the reason for it? EDIT : The reason for asking is because I am studying an optimal control of PDEs course which says we need to be careful when considering the PDE : $ -\Delta y = f $ on $ \Omega  $ $ y=0 $ on $ \partial \Omega  $ ...since we need to define what it means for $ y=0 $ on $\partial\Omega$,  since  $\partial\Omega$ has zero measure.",,"['functional-analysis', 'equivalence-relations', 'almost-everywhere']"
38,"Do there exist closed subspaces  $X$, $Y$ of  Banach space, such that $X+Y$ is not closed?","Do there exist closed subspaces  ,  of  Banach space, such that  is not closed?",X Y X+Y,"I am looking for an example of two closed subspaces of a Banach space, such that their sum is not closed.","I am looking for an example of two closed subspaces of a Banach space, such that their sum is not closed.",,"['functional-analysis', 'banach-spaces']"
39,Is this an inner product on $L^1$?,Is this an inner product on ?,L^1,"I know that $\int f(x) \overline{g(x)} dx$ is an inner product on $L^2$. But is it one on $L^1$? I think it isn't, but I am have had difficulty figuring out which defining property is violated. Thanks in advance for any pointers!","I know that $\int f(x) \overline{g(x)} dx$ is an inner product on $L^2$. But is it one on $L^1$? I think it isn't, but I am have had difficulty figuring out which defining property is violated. Thanks in advance for any pointers!",,[]
40,The spectral radius of normal operator,The spectral radius of normal operator,,"Let $H$ be a Hilbert space and $T$ be linear bounded operator in $H$.  Prove that if $T$ is normal then the spectral radius of $T$, $$r(T)=\|T\|.$$ Is this TRUE?","Let $H$ be a Hilbert space and $T$ be linear bounded operator in $H$.  Prove that if $T$ is normal then the spectral radius of $T$, $$r(T)=\|T\|.$$ Is this TRUE?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory', 'normal-operator']"
41,Coercivity vs boundedness of operator,Coercivity vs boundedness of operator,,The definition of coercivity and boundedness of a linear operator $L$ between two $B$ spaces looks similar: $\lVert Lx\lVert\geq M_1\lVert x\rVert$ and $\lVert Lx\rVert\leq M_2\lVert x\rVert$ for some constants $M_1$ and $M_2$. Thus in order to show the existence of a PDE $Lu=f$ one needs to show that it is coercive. However if my operator $L$ happen to be bounded and $M_2 \leq M_1$? What is the intuition behind those two concepts because they are based on computation of the same quantities and comparing the two?,The definition of coercivity and boundedness of a linear operator $L$ between two $B$ spaces looks similar: $\lVert Lx\lVert\geq M_1\lVert x\rVert$ and $\lVert Lx\rVert\leq M_2\lVert x\rVert$ for some constants $M_1$ and $M_2$. Thus in order to show the existence of a PDE $Lu=f$ one needs to show that it is coercive. However if my operator $L$ happen to be bounded and $M_2 \leq M_1$? What is the intuition behind those two concepts because they are based on computation of the same quantities and comparing the two?,,"['functional-analysis', 'operator-theory', 'normed-spaces']"
42,Spectral measure of the multiplication operator,Spectral measure of the multiplication operator,,"Let $(X,\mathcal B,\mu)$ be a finite measure space and consider the operator $T\colon L^2(X,\mu)\to L^2(X,\mu)$ given by $Tf(x)=\varphi(x)f(x)$ , where $\varphi\colon X\to\mathbb R$ is a bounded measurable function. Is there any possibility to determine the spectral measure explicitly?","Let be a finite measure space and consider the operator given by , where is a bounded measurable function. Is there any possibility to determine the spectral measure explicitly?","(X,\mathcal B,\mu) T\colon L^2(X,\mu)\to L^2(X,\mu) Tf(x)=\varphi(x)f(x) \varphi\colon X\to\mathbb R","['functional-analysis', 'operator-theory', 'spectral-theory']"
43,Can this complete metric space be a Banach space?,Can this complete metric space be a Banach space?,,"Let $(S,d)$ be the space of all sequences in $\mathbb{R}$ with the metric $$d(\mathbf{x},\mathbf{y})=\sum_{i=1}^{\infty}\dfrac{1}{2^i}\dfrac{|\xi_i-\eta_i|}{1+|\xi_i-\eta_i|}$$ where $\mathbf{x}=(\xi_i)$ and $\mathbf{y}=(\eta_i)$ . This is a complete metric space, but the metric does not come from a norm. Therefore the topology of $S$ cannot be defined by a norm. My question is: does there exist any complete norm on the underlying vector space $S$ of all sequences in $\mathbb{R}$ ?","Let be the space of all sequences in with the metric where and . This is a complete metric space, but the metric does not come from a norm. Therefore the topology of cannot be defined by a norm. My question is: does there exist any complete norm on the underlying vector space of all sequences in ?","(S,d) \mathbb{R} d(\mathbf{x},\mathbf{y})=\sum_{i=1}^{\infty}\dfrac{1}{2^i}\dfrac{|\xi_i-\eta_i|}{1+|\xi_i-\eta_i|} \mathbf{x}=(\xi_i) \mathbf{y}=(\eta_i) S S \mathbb{R}","['functional-analysis', 'metric-spaces', 'banach-spaces', 'complete-spaces']"
44,"Are the polynomial functions on $S^1$ dense in $C(S^1,ℂ)$?",Are the polynomial functions on  dense in ?,"S^1 C(S^1,ℂ)","A friend of mine came up with this problem: Let $S^1$ be the unit circle in $ℂ$ and $P$ the space of polynomial functions $S^1 → ℂ$ (with complex coefficients). Is $P$ dense in $C(S^1,ℂ)$? Stone–Weierstraß is not applicable because $P$ is not closed under complex conjugation. We’re wondering if complex conjugation on $S^1$ (= inverting) is a uniform limit of polynomials. We suspect not, but don’t know how to prove it.","A friend of mine came up with this problem: Let $S^1$ be the unit circle in $ℂ$ and $P$ the space of polynomial functions $S^1 → ℂ$ (with complex coefficients). Is $P$ dense in $C(S^1,ℂ)$? Stone–Weierstraß is not applicable because $P$ is not closed under complex conjugation. We’re wondering if complex conjugation on $S^1$ (= inverting) is a uniform limit of polynomials. We suspect not, but don’t know how to prove it.",,['functional-analysis']
45,Open linear subspace of a Hilbert space.,Open linear subspace of a Hilbert space.,,"Does there exist any open linear (vector) subspace of a Hilbert space? I could not think of any example. Actually, I was reading the book by Simmons, there almost in every theorem it assumed that ""If M is a closed linear subspace"".It seemed natural to me to think about subspaces which are not closed. I have an got an example which is not closed: Take the Hilbert space H = L^[0,1], with L^2 norm and the subspace set of all polynomials , it is not closed because it's closure is H and not open can be found here Set of all polynomials on [0, 1/2] is not open in C[0, 1/2] . Then I asked myself an example of  to think of an open set. But I could lead myself nowhere, as I am not familiar with infinite dimensional vector space. Not closed does not necessarily mean open.","Does there exist any open linear (vector) subspace of a Hilbert space? I could not think of any example. Actually, I was reading the book by Simmons, there almost in every theorem it assumed that ""If M is a closed linear subspace"".It seemed natural to me to think about subspaces which are not closed. I have an got an example which is not closed: Take the Hilbert space H = L^[0,1], with L^2 norm and the subspace set of all polynomials , it is not closed because it's closure is H and not open can be found here Set of all polynomials on [0, 1/2] is not open in C[0, 1/2] . Then I asked myself an example of  to think of an open set. But I could lead myself nowhere, as I am not familiar with infinite dimensional vector space. Not closed does not necessarily mean open.",,['functional-analysis']
46,Does existence of the second weak derivative of $f\in L^2$ imply existence of the first?,Does existence of the second weak derivative of  imply existence of the first?,f\in L^2,"Let's consider a function $f\in L^2(\mathbb{R})$ for which the second weak derivative exists and lie in $L^2(\mathbb{R})$, i.e. there exists $f''\in L^2(\mathbb{R})$ such that for all $\varphi\in C_0^\infty(\mathbb{R})$ the following integral equation stands: $$ \int\limits_\mathbb{R}f(x)\varphi''(x)dx=\int\limits_\mathbb{R}f''(x)\varphi(x)dx. $$ My question is, having this can we assume that weak $f'$ also exists in $L^2(\mathbb{R})$? Suppose we found a normal (not generalized) function $g:\mathbb{R}\to\mathbb{C}$ such that for all $\varphi\in C_0^\infty(\mathbb{R})$ $$ \int\limits_\mathbb{R}f(x)\varphi'(x)dx=-\int\limits_\mathbb{R}g(x)\varphi(x)dx. $$ Then $$ \langle -f'', f \rangle_{L^2}=-\int\limits_\mathbb{R}f''(x)f(x)dx=\int\limits_\mathbb{R}g(x)g(x)dx=\|g\|_{L^2}^2 $$ which means, that $g$ is in $L^2(\mathbb{R})$. But what guarantees us the existence of such $g$?","Let's consider a function $f\in L^2(\mathbb{R})$ for which the second weak derivative exists and lie in $L^2(\mathbb{R})$, i.e. there exists $f''\in L^2(\mathbb{R})$ such that for all $\varphi\in C_0^\infty(\mathbb{R})$ the following integral equation stands: $$ \int\limits_\mathbb{R}f(x)\varphi''(x)dx=\int\limits_\mathbb{R}f''(x)\varphi(x)dx. $$ My question is, having this can we assume that weak $f'$ also exists in $L^2(\mathbb{R})$? Suppose we found a normal (not generalized) function $g:\mathbb{R}\to\mathbb{C}$ such that for all $\varphi\in C_0^\infty(\mathbb{R})$ $$ \int\limits_\mathbb{R}f(x)\varphi'(x)dx=-\int\limits_\mathbb{R}g(x)\varphi(x)dx. $$ Then $$ \langle -f'', f \rangle_{L^2}=-\int\limits_\mathbb{R}f''(x)f(x)dx=\int\limits_\mathbb{R}g(x)g(x)dx=\|g\|_{L^2}^2 $$ which means, that $g$ is in $L^2(\mathbb{R})$. But what guarantees us the existence of such $g$?",,"['functional-analysis', 'lebesgue-integral', 'sobolev-spaces', 'weak-derivatives']"
47,Connectedness property of $R^2$,Connectedness property of,R^2,My class teacher proposed this problem which seem very interesting. If we remove countably many open disc from $R^2$. Is the remaining     space still be path connected. I have done the problem for the case when disc are not disjoint and find out that space need not be path connected. But I am wondering what happen if disc are   disjoint.my guess is space should be path connected any help will be appreciated.,My class teacher proposed this problem which seem very interesting. If we remove countably many open disc from $R^2$. Is the remaining     space still be path connected. I have done the problem for the case when disc are not disjoint and find out that space need not be path connected. But I am wondering what happen if disc are   disjoint.my guess is space should be path connected any help will be appreciated.,,"['geometry', 'functional-analysis', 'graph-theory', 'algebraic-topology', 'connectedness']"
48,Fourier transform as a Gelfand transform,Fourier transform as a Gelfand transform,,One question came to my mind while looking at the proof of Gelfand-Naimark theorem. Is Fourier transform a kind of Gelfand transform? Are there any other well-known transforms which are so?,One question came to my mind while looking at the proof of Gelfand-Naimark theorem. Is Fourier transform a kind of Gelfand transform? Are there any other well-known transforms which are so?,,"['functional-analysis', 'fourier-analysis', 'operator-theory', 'banach-algebras']"
49,Why isn't every Hamel basis a Schauder basis?,Why isn't every Hamel basis a Schauder basis?,,"I seem to have tripped on the common Hamel/Schauder confusion. If $X$ is any vector space (not necessarily finite dimension) and $B$ is a linearly independent subset that spans $X$, then $B$ is a Hamel basis for $X$. If there exists a sequence $(e_n)$ such that for every $x \in X$ there exists a unique sequence of scalars $(\alpha_n)$ for which $\lim_{n \to \infty} || x - (\alpha_1e_1 + \cdots + \alpha_ne_n)|| = 0$, then $(e_n)$ is a Schauder basis for $X$. So I'm tempted to think that every Hamel basis is also a Schauder basis; just extened the finite linear combination into an infinite one by adding zero coeeficients. I know I'm wrong, but what am I missing?","I seem to have tripped on the common Hamel/Schauder confusion. If $X$ is any vector space (not necessarily finite dimension) and $B$ is a linearly independent subset that spans $X$, then $B$ is a Hamel basis for $X$. If there exists a sequence $(e_n)$ such that for every $x \in X$ there exists a unique sequence of scalars $(\alpha_n)$ for which $\lim_{n \to \infty} || x - (\alpha_1e_1 + \cdots + \alpha_ne_n)|| = 0$, then $(e_n)$ is a Schauder basis for $X$. So I'm tempted to think that every Hamel basis is also a Schauder basis; just extened the finite linear combination into an infinite one by adding zero coeeficients. I know I'm wrong, but what am I missing?",,"['functional-analysis', 'schauder-basis', 'hamel-basis']"
50,C*-algebras as Banach lattices?,C*-algebras as Banach lattices?,,It seems to be trivial but I am not sure about monotonicity of the norm in the non-commutative case: Is every C*-algebra a Banach lattice with respect to its natural positive cone?,It seems to be trivial but I am not sure about monotonicity of the norm in the non-commutative case: Is every C*-algebra a Banach lattice with respect to its natural positive cone?,,"['functional-analysis', 'banach-spaces', 'c-star-algebras', 'vector-lattices', 'banach-lattices']"
51,Renorming $\mathcal{B}(\mathcal{H})$?,Renorming ?,\mathcal{B}(\mathcal{H}),"Consider the Banach space of all bounded operators $\mathcal{B}(\mathcal{H})$ on a (separable if you wish) Hilbert space $\mathcal{H}$ with the operator norm. Can we renorm this space to a strictly convex one? Recall that a Banach space is strictly convex whenever the unit sphere is the set of extreme points of the closed unit ball. Seemingly, it is well known but I don't know how to prove that. I am interested in the cases $\mathcal{B}(E)$ ($E$ - some infinite dimensional Banach space; excluding  the Argyros-Haydon space $E$ - in that case $\mathcal{B}(E)$ is separable, thus admits such a renorming) or $\mathcal{M}$ - a von Neumann algebra as well.","Consider the Banach space of all bounded operators $\mathcal{B}(\mathcal{H})$ on a (separable if you wish) Hilbert space $\mathcal{H}$ with the operator norm. Can we renorm this space to a strictly convex one? Recall that a Banach space is strictly convex whenever the unit sphere is the set of extreme points of the closed unit ball. Seemingly, it is well known but I don't know how to prove that. I am interested in the cases $\mathcal{B}(E)$ ($E$ - some infinite dimensional Banach space; excluding  the Argyros-Haydon space $E$ - in that case $\mathcal{B}(E)$ is separable, thus admits such a renorming) or $\mathcal{M}$ - a von Neumann algebra as well.",,"['functional-analysis', 'banach-spaces', 'operator-theory', 'operator-algebras', 'von-neumann-algebras']"
52,Comparison of definitions for Functions of Bounded Variation,Comparison of definitions for Functions of Bounded Variation,,"I have been trying to understand the functions of bounded variation and I came across the following definitions Defintion 1: A function $f:\mathbb{R^d} \rightarrow \mathbb{R}$ is of bounded variation iff $$ \begin{split} \operatorname{TV}(f)&:=\int\limits_{\mathbb{R}^{d-1}}\mathcal{TV}(f(\cdot,x_2,\cdots,x_d))dx_2 \cdots dx_m +\cdots +\\ & \quad+\cdots+\int\limits_{\mathbb{R}^{d-1}}\mathcal{TV}(f(x_1, \cdots, x_{d-1},\cdot)) dx_1\cdots dx_{d-1} < \infty. \end{split} $$ where, for $g:\mathbb{R} \rightarrow \mathbb{R} $ $$ \mathcal{TV}(g):=\sup \left\{\sum\limits_{k=1}^N{\left|g(\xi_k)-g(\xi_{k-1})\right|}\right\} $$ and supremum is taken over all $M \geq 1$ and all partitions $\{\xi_1,\xi_2,....,\xi_N\}$ of $\mathbb{R}.$ Defintion 2: A function $f:\mathbb{R^d} \rightarrow \mathbb{R}$ is of bounded variation iff $$ \operatorname{TV}(f)= \sup \left\{\,\int\limits_{\mathbb{R}^m}f \operatorname{div}(\phi): \phi \in C_c^1(\mathbb{R^d})^d, \|\phi\|_{L^{\infty}} \leq 1\, \right\} < \infty. $$ Clearly if $f$ is of bounded variation in the sense of definition 2, it may not be of bounded variation in the sense of definition 1. In this regard, I have the following doubts. If $f$ satisfies definition 1, then do we have $f$ satisfies definition 2? (I felt so but could not prove it rigorously). If  [1] is true then $\operatorname{TV}(f)$ calculated by definition 1 and definition 2 are they equal? If $f$ satisfies definition 2, does there exist a function $g:\mathbb{R}^d \rightarrow \mathbb{R}$ a.e equal to $f$ such that $g$ satisfies definition 1? If so how to prove it? P.S. : I have read somewhere that 3 is true in one dimension and in-fact we can find $g$ which is right continuous. But I could not find the rigorous proof and also I could not find any such result in multi-d.","I have been trying to understand the functions of bounded variation and I came across the following definitions Defintion 1: A function is of bounded variation iff where, for and supremum is taken over all and all partitions of Defintion 2: A function is of bounded variation iff Clearly if is of bounded variation in the sense of definition 2, it may not be of bounded variation in the sense of definition 1. In this regard, I have the following doubts. If satisfies definition 1, then do we have satisfies definition 2? (I felt so but could not prove it rigorously). If  [1] is true then calculated by definition 1 and definition 2 are they equal? If satisfies definition 2, does there exist a function a.e equal to such that satisfies definition 1? If so how to prove it? P.S. : I have read somewhere that 3 is true in one dimension and in-fact we can find which is right continuous. But I could not find the rigorous proof and also I could not find any such result in multi-d.","f:\mathbb{R^d} \rightarrow \mathbb{R} 
\begin{split}
\operatorname{TV}(f)&:=\int\limits_{\mathbb{R}^{d-1}}\mathcal{TV}(f(\cdot,x_2,\cdots,x_d))dx_2 \cdots dx_m +\cdots +\\
& \quad+\cdots+\int\limits_{\mathbb{R}^{d-1}}\mathcal{TV}(f(x_1, \cdots, x_{d-1},\cdot)) dx_1\cdots dx_{d-1} < \infty.
\end{split}
 g:\mathbb{R} \rightarrow \mathbb{R}  
\mathcal{TV}(g):=\sup \left\{\sum\limits_{k=1}^N{\left|g(\xi_k)-g(\xi_{k-1})\right|}\right\}
 M \geq 1 \{\xi_1,\xi_2,....,\xi_N\} \mathbb{R}. f:\mathbb{R^d} \rightarrow \mathbb{R} 
\operatorname{TV}(f)= \sup \left\{\,\int\limits_{\mathbb{R}^m}f \operatorname{div}(\phi): \phi \in C_c^1(\mathbb{R^d})^d, \|\phi\|_{L^{\infty}} \leq 1\, \right\} < \infty.
 f f f \operatorname{TV}(f) f g:\mathbb{R}^d \rightarrow \mathbb{R} f g g","['functional-analysis', 'analysis', 'measure-theory', 'bounded-variation', 'total-variation']"
53,Norm and scalar product of $H_0^1(\Omega)$,Norm and scalar product of,H_0^1(\Omega),"Let $\Omega \subset \mathbb R^n$. The $H^1(\Omega)$ and $H^1_0(\Omega)$ spaces are defined as follows: $$\begin{align} H^1(\Omega) &= \{v \in L^2(\Omega) \mid \nabla v \in {(L^2(\Omega))}^n\}\\ H_0^1(\Omega) &= \overline{\mathcal C^\infty_C(\Omega)}^{{\|\cdot\|}_{H^1(\Omega)}} \end{align}$$ where the derivatives are to be understood in the distributional sense and $$\begin{align} {(u, v)}_{H^1(\Omega)} &= {(u, v)}_{L^2(\Omega)} + \int_\Omega \nabla u \cdot \nabla v\\ {\|v\|}_{H^1(\Omega)}^2 &= {\|v\|}_{L^2(\Omega)}^2 + {\|\:\!|\nabla v|\:\!\|}_{L^2(\Omega)}^2 \end{align}$$ Now, in my notes I have the definitions $$\begin{align} {(u, v)}_{H^1_0(\Omega)} &= \int_\Omega \nabla u \cdot \nabla v \tag{1}\\ {\|u\|}_{H^1_0(\Omega)} &= {\|\:\!|\nabla u|\:\!\|}_{L^2(\Omega)} \end{align}$$ which make $H^1_0(\Omega)$ a Hilbert space. However, in the teacher's notes I see in multiple places statements that contradict $(1)$. For example, they say that if $T \in H^{-1}(\Omega)$ (dual space of $H^1_0(\Omega)$), then by Riesz' representation theorem there exist a $\bar u \in H^1_0(\Omega)$ such that $$\langle T, v \rangle = \int_\Omega (\bar uv + \nabla \bar u \cdot \nabla v),\qquad \forall v \in H^1_0(\Omega)$$ which takes me by surprise since it's using ${(\cdot,\cdot)}_{H^1(\Omega)}$ instead of $(1)$. In another instance, I see $$a(u, v) = \int_0^1 u'v' + \int_0^1 uv \color{red}{=} {(u, v)}_{H^1_0(0, 1)}$$ which does the same thing. My question is, does it make sense to identify the scalar product of $H^1_0(\Omega)$ with the scalar product of $H^1(\Omega)$?","Let $\Omega \subset \mathbb R^n$. The $H^1(\Omega)$ and $H^1_0(\Omega)$ spaces are defined as follows: $$\begin{align} H^1(\Omega) &= \{v \in L^2(\Omega) \mid \nabla v \in {(L^2(\Omega))}^n\}\\ H_0^1(\Omega) &= \overline{\mathcal C^\infty_C(\Omega)}^{{\|\cdot\|}_{H^1(\Omega)}} \end{align}$$ where the derivatives are to be understood in the distributional sense and $$\begin{align} {(u, v)}_{H^1(\Omega)} &= {(u, v)}_{L^2(\Omega)} + \int_\Omega \nabla u \cdot \nabla v\\ {\|v\|}_{H^1(\Omega)}^2 &= {\|v\|}_{L^2(\Omega)}^2 + {\|\:\!|\nabla v|\:\!\|}_{L^2(\Omega)}^2 \end{align}$$ Now, in my notes I have the definitions $$\begin{align} {(u, v)}_{H^1_0(\Omega)} &= \int_\Omega \nabla u \cdot \nabla v \tag{1}\\ {\|u\|}_{H^1_0(\Omega)} &= {\|\:\!|\nabla u|\:\!\|}_{L^2(\Omega)} \end{align}$$ which make $H^1_0(\Omega)$ a Hilbert space. However, in the teacher's notes I see in multiple places statements that contradict $(1)$. For example, they say that if $T \in H^{-1}(\Omega)$ (dual space of $H^1_0(\Omega)$), then by Riesz' representation theorem there exist a $\bar u \in H^1_0(\Omega)$ such that $$\langle T, v \rangle = \int_\Omega (\bar uv + \nabla \bar u \cdot \nabla v),\qquad \forall v \in H^1_0(\Omega)$$ which takes me by surprise since it's using ${(\cdot,\cdot)}_{H^1(\Omega)}$ instead of $(1)$. In another instance, I see $$a(u, v) = \int_0^1 u'v' + \int_0^1 uv \color{red}{=} {(u, v)}_{H^1_0(0, 1)}$$ which does the same thing. My question is, does it make sense to identify the scalar product of $H^1_0(\Omega)$ with the scalar product of $H^1(\Omega)$?",,"['functional-analysis', 'sobolev-spaces']"
54,"Correspondence between maximal ideals and multiplicative functionals of a non unital, commutative Banach algebra.","Correspondence between maximal ideals and multiplicative functionals of a non unital, commutative Banach algebra.",,"Let $\mathcal{A}$ be a non (necessarily) unital commutative Banach algebra, and let  $$ M_{\mathcal{A}} = \{ \phi:\mathcal{A} \to \mathbb{C} : \phi \mbox{ is multiplicative and not trivial}\} $$ and $$ \mathrm{Max}(\mathcal{A})=\{ I \lhd \mathcal{A} : I \mbox{ maximal} \}.$$ If $\mathcal{A}$ is unital, it is well known that there is a bijection between $M_{\mathcal{A}}$ and  $\mathrm{Max}(\mathcal{A})$ sending each functional to its kernel (the inverse is given by the quotient and the Gelfand-Mazur theorem). My question is, is this still a bijection in the non-unital case? I'm aware that if $\mathcal{A}$ is a commutative C*-algebra it is still a bijection. Also that the restriction gives a bijection from $M_{\tilde{\mathcal{A}}} \setminus \{ \pi:\tilde{\mathcal{A}} \to \mathbb{C} \}$ to $M_{\mathcal{A}}$; but this fact don't seem enough to conclude the result. I haven't been able to find a source for this. Thanks in advance.","Let $\mathcal{A}$ be a non (necessarily) unital commutative Banach algebra, and let  $$ M_{\mathcal{A}} = \{ \phi:\mathcal{A} \to \mathbb{C} : \phi \mbox{ is multiplicative and not trivial}\} $$ and $$ \mathrm{Max}(\mathcal{A})=\{ I \lhd \mathcal{A} : I \mbox{ maximal} \}.$$ If $\mathcal{A}$ is unital, it is well known that there is a bijection between $M_{\mathcal{A}}$ and  $\mathrm{Max}(\mathcal{A})$ sending each functional to its kernel (the inverse is given by the quotient and the Gelfand-Mazur theorem). My question is, is this still a bijection in the non-unital case? I'm aware that if $\mathcal{A}$ is a commutative C*-algebra it is still a bijection. Also that the restriction gives a bijection from $M_{\tilde{\mathcal{A}}} \setminus \{ \pi:\tilde{\mathcal{A}} \to \mathbb{C} \}$ to $M_{\mathcal{A}}$; but this fact don't seem enough to conclude the result. I haven't been able to find a source for this. Thanks in advance.",,"['functional-analysis', 'operator-algebras', 'banach-algebras']"
55,How does the method of Lagrange multipliers fail (in classical field theories with local constraints)?,How does the method of Lagrange multipliers fail (in classical field theories with local constraints)?,,"The method of Lagrange multipliers is used to find the extrema of $f(x)$ subject to the constraints $\vec g(x)=0$, where  $x=(x_1,\dots,x_n)$ and $\vec g=(g_1,\dots,g_m)$ for $m \leq n$. Although many textbooks get the final equations by arguing that at an extrema, the variation of $f(x)$  must be orthogonal to the surface $g(x)=0$, the ""simpler"" approach (and that which is commonly seen in field theory / optimizing functionals) is to construct the Lagrange function $$ L(x,\lambda) = f(x) + \vec\lambda\cdot\vec g(x) $$ and varying w.r.t. $x$ and $\lambda$ to get the vector equations $$ \begin{align}   &x:&              0 &= \nabla f(x) + \sum_i \lambda_i \nabla g_i(x) \,, \\   &\vec \lambda:&   0 &= \vec g(x) \ . \end{align} $$ The method only works if the extremal point is a regular point of the constraint surface, i.e. if $\mathrm{rnk}(\nabla\vec g) = m$. What is the best way of understanding what goes wrong when the extrema is not a regular point of the constraint? And, most importantly to me, how does this generalize to field theories (i.e. optimizing functionals) with local constraints ? What is the equivalent regularity condition for constraints in field theory? Instructive examples are more than welcome.","The method of Lagrange multipliers is used to find the extrema of $f(x)$ subject to the constraints $\vec g(x)=0$, where  $x=(x_1,\dots,x_n)$ and $\vec g=(g_1,\dots,g_m)$ for $m \leq n$. Although many textbooks get the final equations by arguing that at an extrema, the variation of $f(x)$  must be orthogonal to the surface $g(x)=0$, the ""simpler"" approach (and that which is commonly seen in field theory / optimizing functionals) is to construct the Lagrange function $$ L(x,\lambda) = f(x) + \vec\lambda\cdot\vec g(x) $$ and varying w.r.t. $x$ and $\lambda$ to get the vector equations $$ \begin{align}   &x:&              0 &= \nabla f(x) + \sum_i \lambda_i \nabla g_i(x) \,, \\   &\vec \lambda:&   0 &= \vec g(x) \ . \end{align} $$ The method only works if the extremal point is a regular point of the constraint surface, i.e. if $\mathrm{rnk}(\nabla\vec g) = m$. What is the best way of understanding what goes wrong when the extrema is not a regular point of the constraint? And, most importantly to me, how does this generalize to field theories (i.e. optimizing functionals) with local constraints ? What is the equivalent regularity condition for constraints in field theory? Instructive examples are more than welcome.",,"['functional-analysis', 'optimization', 'multivariable-calculus', 'examples-counterexamples']"
56,Advanced book on partial differential equations,Advanced book on partial differential equations,,"I am looking for an advanced book on partial differential equations that makes use of functional analysis as much as possible. All the books I have looked in so far either shy away from functional analysis and try to avoid even basic concepts, or present results from functional analysis I know anyway just to discuss some very basic applications to partial differential equations (say, semigroup theory applied to the heat equation). The book I am looking for should use functional analysis instead of hard analysis whenever possible (I am well aware of the fact that the theory of partial differential equations is not merely an application of functional analysis), go into some advanced topics that are relevant for research, and not spend too much space on covering the results of functional analysis itself - I have my references for that. The background is that I am interested in operator equations that are not partial differential equations, yet methods from pde are often helpful. If it is relevant, I am mostly interested in elliptic and parabolic equations, although I don't want to limit the focus.","I am looking for an advanced book on partial differential equations that makes use of functional analysis as much as possible. All the books I have looked in so far either shy away from functional analysis and try to avoid even basic concepts, or present results from functional analysis I know anyway just to discuss some very basic applications to partial differential equations (say, semigroup theory applied to the heat equation). The book I am looking for should use functional analysis instead of hard analysis whenever possible (I am well aware of the fact that the theory of partial differential equations is not merely an application of functional analysis), go into some advanced topics that are relevant for research, and not spend too much space on covering the results of functional analysis itself - I have my references for that. The background is that I am interested in operator equations that are not partial differential equations, yet methods from pde are often helpful. If it is relevant, I am mostly interested in elliptic and parabolic equations, although I don't want to limit the focus.",,"['functional-analysis', 'partial-differential-equations', 'book-recommendation']"
57,An application of J.-L. Lion's Lemma,An application of J.-L. Lion's Lemma,,"Let $X,Y$ and $Z$ be three Banach spaces with norms $\|\cdot\|_X$, $\|\cdot\|_Y$,$\|\cdot\|_Z$. Assume that $X\subset Y$ with compact ""injection"" and that $Y\subset Z$ with continuous injection. Then $$\forall\epsilon>0, \exists  C_{\epsilon}\geq0  $$ Satisfying $$\|u\|_Y\leq \epsilon \|u\|_X+C_{\epsilon}\|u\|_Z \ \ \forall u \in X.$$ My question are I) Where can I find a proof of this result? II) As a consequence of that how to prove $$\max_{[0,1]}|u|\leq \epsilon\max_{[0,1]}|u'|+C_{\epsilon}\|u\|_{L^1{[0,1]}} \forall \in C^1({[0,1]})?$$","Let $X,Y$ and $Z$ be three Banach spaces with norms $\|\cdot\|_X$, $\|\cdot\|_Y$,$\|\cdot\|_Z$. Assume that $X\subset Y$ with compact ""injection"" and that $Y\subset Z$ with continuous injection. Then $$\forall\epsilon>0, \exists  C_{\epsilon}\geq0  $$ Satisfying $$\|u\|_Y\leq \epsilon \|u\|_X+C_{\epsilon}\|u\|_Z \ \ \forall u \in X.$$ My question are I) Where can I find a proof of this result? II) As a consequence of that how to prove $$\max_{[0,1]}|u|\leq \epsilon\max_{[0,1]}|u'|+C_{\epsilon}\|u\|_{L^1{[0,1]}} \forall \in C^1({[0,1]})?$$",,"['functional-analysis', 'banach-spaces']"
58,Besov spaces---concrete description of spatial inhomogeneity,Besov spaces---concrete description of spatial inhomogeneity,,"Some very pedestrian questions about Besov spaces. Just to fix notation: 1.Let $f \in \mathcal{S}'$, the space of tempered distributions. 2.$\Psi, \{ \Phi_n \}_{n \geq 0} \subset \mathcal{S}$ such that their Fourier transforms $\hat{\Psi}, \{ \hat{\Phi}_n \}$ form a partition of unity subordinate to the cover $A_0 = (-1, 1)$, $ A_n = \{2^{n-1} < |\xi| < 2^{n+1} \}$. 3.So $f = \Psi * f + \sum_{n \geq 0} \Phi_n * f$ in $ \mathcal{S}'$. 4.Say (my impression) $f$ lies in the inhomogeneous Besov space $B^{\alpha}_{p,q}$ if $$ \| \Psi * f\|_p + (\sum_{n \geq 0} (2^{n \alpha} \|\Phi_n * f\|_p)^q)^{\frac{1}{q}} < \infty. $$ Questions What exactly does the indices signify in terms of smoothness properties of the function? How does the frequency content of $f$ in the dyadic frequency bands, as summarized by the Besov norm, reflect its regularity properties? For example, if I want to find $f \in L^2(\mathbb{R})$ that's $\beta$-times differentiable in the Sobolev sense, I can just look for the condition $$ \| \hat{f}(\xi) \xi^{\beta} \|_2 < \infty $$ What would be a corresponding statement for $B^{\alpha}_{p,q}$ for, say, a piecewise constant function? What if different pieces have different degrees of smoothness?","Some very pedestrian questions about Besov spaces. Just to fix notation: 1.Let $f \in \mathcal{S}'$, the space of tempered distributions. 2.$\Psi, \{ \Phi_n \}_{n \geq 0} \subset \mathcal{S}$ such that their Fourier transforms $\hat{\Psi}, \{ \hat{\Phi}_n \}$ form a partition of unity subordinate to the cover $A_0 = (-1, 1)$, $ A_n = \{2^{n-1} < |\xi| < 2^{n+1} \}$. 3.So $f = \Psi * f + \sum_{n \geq 0} \Phi_n * f$ in $ \mathcal{S}'$. 4.Say (my impression) $f$ lies in the inhomogeneous Besov space $B^{\alpha}_{p,q}$ if $$ \| \Psi * f\|_p + (\sum_{n \geq 0} (2^{n \alpha} \|\Phi_n * f\|_p)^q)^{\frac{1}{q}} < \infty. $$ Questions What exactly does the indices signify in terms of smoothness properties of the function? How does the frequency content of $f$ in the dyadic frequency bands, as summarized by the Besov norm, reflect its regularity properties? For example, if I want to find $f \in L^2(\mathbb{R})$ that's $\beta$-times differentiable in the Sobolev sense, I can just look for the condition $$ \| \hat{f}(\xi) \xi^{\beta} \|_2 < \infty $$ What would be a corresponding statement for $B^{\alpha}_{p,q}$ for, say, a piecewise constant function? What if different pieces have different degrees of smoothness?",,"['functional-analysis', 'reference-request', 'sobolev-spaces', 'harmonic-analysis', 'besov-space']"
59,Continuity of scalar product,Continuity of scalar product,,"In a Hilbert space $H$ with inner product and associated norm, why would if $\|x-x_n\| \longrightarrow 0$ and $\|y-y_n\| \longrightarrow 0$ also $\langle x_n,y_n\rangle \longrightarrow\langle x,y\rangle$? I understand that by Cauchy-Schwarz $\lvert\langle x-x_n,y-y_n\rangle\rvert \leq \|x-x_n\|\cdot\|y-y_n\|\xrightarrow{n\to\infty} 0$ but how do I get to $\lvert\langle x,y\rangle-\langle x_n,y_n\rangle \rvert\longrightarrow 0$?","In a Hilbert space $H$ with inner product and associated norm, why would if $\|x-x_n\| \longrightarrow 0$ and $\|y-y_n\| \longrightarrow 0$ also $\langle x_n,y_n\rangle \longrightarrow\langle x,y\rangle$? I understand that by Cauchy-Schwarz $\lvert\langle x-x_n,y-y_n\rangle\rvert \leq \|x-x_n\|\cdot\|y-y_n\|\xrightarrow{n\to\infty} 0$ but how do I get to $\lvert\langle x,y\rangle-\langle x_n,y_n\rangle \rvert\longrightarrow 0$?",,"['functional-analysis', 'hilbert-spaces', 'inner-products']"
60,Exercise: Application of Hahn-Banach Theorem,Exercise: Application of Hahn-Banach Theorem,,"I'm working on this exercise (not homework) and I would gladly welcome some hints for how to solve it! Exercise: Let $\{x_1,\dots,x_n\}$ be a set of linearly independent elements of a normed vector space $X$. Let $c_1,\dots,c_n \in \mathbb{C}$. Show that there exists $f\in X^\ast$ such that $f(x_i)=c_i$. My idea: I consider $M = span\{x_1,...,x_n\}$, which is a subspace of $X$. Any $x\in M$ can be written $x=\sum_1^n \lambda_k x_k$, for some $\lambda_1,...,\lambda_n \in \mathbb{C}$. Define $f:M \rightarrow \mathbb{C}$ by $f(x_i)=c_i$ for $i=1,...,n$. Then $$f(x) = \sum_1^n \lambda_k f(x_k) = \sum_1^n \lambda_k c_k.$$ If I can find a semi-norm $p:X \rightarrow \mathbb{R}$ such that $|f(x)| \leq p(x)$ for any $x \in M$, then by Hahn-Banach Theorem we would be done. Thanks in advance!","I'm working on this exercise (not homework) and I would gladly welcome some hints for how to solve it! Exercise: Let $\{x_1,\dots,x_n\}$ be a set of linearly independent elements of a normed vector space $X$. Let $c_1,\dots,c_n \in \mathbb{C}$. Show that there exists $f\in X^\ast$ such that $f(x_i)=c_i$. My idea: I consider $M = span\{x_1,...,x_n\}$, which is a subspace of $X$. Any $x\in M$ can be written $x=\sum_1^n \lambda_k x_k$, for some $\lambda_1,...,\lambda_n \in \mathbb{C}$. Define $f:M \rightarrow \mathbb{C}$ by $f(x_i)=c_i$ for $i=1,...,n$. Then $$f(x) = \sum_1^n \lambda_k f(x_k) = \sum_1^n \lambda_k c_k.$$ If I can find a semi-norm $p:X \rightarrow \mathbb{R}$ such that $|f(x)| \leq p(x)$ for any $x \in M$, then by Hahn-Banach Theorem we would be done. Thanks in advance!",,['functional-analysis']
61,Are operator and mapping the same concept?,Are operator and mapping the same concept?,,"I was wondering what differences and relations are between a mapping and an operator generally? For topological vector spaces or functional analysis, it seems like an operator and a mapping are the same concept, doesn't it? What differences are between an operator and an operation? Is an operation a mapping from $X^n$ to $X$ for some set $X$ and some $n \in \mathbb{N}$? Thanks and regards!","I was wondering what differences and relations are between a mapping and an operator generally? For topological vector spaces or functional analysis, it seems like an operator and a mapping are the same concept, doesn't it? What differences are between an operator and an operation? Is an operation a mapping from $X^n$ to $X$ for some set $X$ and some $n \in \mathbb{N}$? Thanks and regards!",,"['functional-analysis', 'elementary-set-theory', 'topological-vector-spaces']"
62,Origin of the name 'test functions',Origin of the name 'test functions',,"This is a very simple question really: where did the name 'test functions', used nowadays when speaking of infinitely differentiable and compactly supported functions, come from? More to the point: is there a mathematical reason these functions are called that way?","This is a very simple question really: where did the name 'test functions', used nowadays when speaking of infinitely differentiable and compactly supported functions, come from? More to the point: is there a mathematical reason these functions are called that way?",,"['functional-analysis', 'terminology', 'math-history', 'partial-differential-equations', 'distribution-theory']"
63,Metric and Topological structures induced by a norm,Metric and Topological structures induced by a norm,,"While proving that some normed spaces were complete, two questions came to my mind. They relate the topological and the metric structures induced by a norm. Is it possible to find two equivalent norms $\|\cdot\|_1$ and $\|\cdot\|_2$ on a vector space $V \ $ such that $(V \ ,\|\cdot\|_1)$ is complete and $(V \ ,\|\cdot\|_2)$ is not? Is there a vector space $V \ $ and two non-equivalent norms such that $V \ $ is complete relative to both? Here I'm assuming $V \ $ a vector space over a subfield of $\mathbb{C}$ . Also I know that the answer is no if we only consider finite-dimensional vector spaces. [Edit: I'm considering two norms equivalent if they define the same topology. I think it's the usual notion Jonas referred in his comment.]","While proving that some normed spaces were complete, two questions came to my mind. They relate the topological and the metric structures induced by a norm. Is it possible to find two equivalent norms and on a vector space such that is complete and is not? Is there a vector space and two non-equivalent norms such that is complete relative to both? Here I'm assuming a vector space over a subfield of . Also I know that the answer is no if we only consider finite-dimensional vector spaces. [Edit: I'm considering two norms equivalent if they define the same topology. I think it's the usual notion Jonas referred in his comment.]","\|\cdot\|_1 \|\cdot\|_2 V \  (V \ ,\|\cdot\|_1) (V \ ,\|\cdot\|_2) V \  V \  V \  \mathbb{C}","['analysis', 'functional-analysis']"
64,Criteria of compactness of an operator,Criteria of compactness of an operator,,"Suppose $K$ is a linear operator in a separable Hilbert space $H$ such that for any Hilbert basis $\{e_i\}$ of $H$ we have $\lim_{i,j \to \infty} (Ke_i,e_j) = 0$. Is it true that $K$ is compact? Thanks in advance for any help.","Suppose $K$ is a linear operator in a separable Hilbert space $H$ such that for any Hilbert basis $\{e_i\}$ of $H$ we have $\lim_{i,j \to \infty} (Ke_i,e_j) = 0$. Is it true that $K$ is compact? Thanks in advance for any help.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'compact-operators']"
65,Show compactness with Arzelà–Ascoli,Show compactness with Arzelà–Ascoli,,"To say it directly: I never worked with the sentence of Arzelà Ascoli, therefore this thread. I heard that one can often use it to show the compactness of operators. For example let $T\colon C([0,1])\to C([0,1])$ be a linear operator, defined by $$ (Tf)(x)=\int\limits_0^1 k(x,y)f(y)\, dy, k\colon [0,1]\times [0,1]\to\mathbb{R} \mbox{ continuous}. $$ Can anybody explain me how I can here use Arzelà Ascoli to show the compactness of T? It would be great if you could explain it slowly and not to short and complicated. Remember, that I want to learn how one can apply this sentence to show compactness and I never saw it before. Thank you!","To say it directly: I never worked with the sentence of Arzelà Ascoli, therefore this thread. I heard that one can often use it to show the compactness of operators. For example let $T\colon C([0,1])\to C([0,1])$ be a linear operator, defined by $$ (Tf)(x)=\int\limits_0^1 k(x,y)f(y)\, dy, k\colon [0,1]\times [0,1]\to\mathbb{R} \mbox{ continuous}. $$ Can anybody explain me how I can here use Arzelà Ascoli to show the compactness of T? It would be great if you could explain it slowly and not to short and complicated. Remember, that I want to learn how one can apply this sentence to show compactness and I never saw it before. Thank you!",,['functional-analysis']
66,Every Hilbert-Schmidt is an integral operator?,Every Hilbert-Schmidt is an integral operator?,,"Let $(X,\mu)$ be a $\sigma$-finite measure space. If $K\in\mathcal{L}^2(X\times X,\mu\times\mu)$ then the map $A_K:\mathcal{L}^2(X,\mu)\to\mathcal{L}^2(X,\mu)$ defined by\begin{equation} A_Kf(x)=\int_XK(x,y)f(y)d\mu(y) \end{equation} is Hilbert-Schmidt. But Arveson (Proposition 2.8.6) says this $K\mapsto A_K$ is an isomorphism from $\mathcal{L}^2(X\times X,\mu\times\mu)$ to the space of Hilbert-Schmidt operators on $\mathcal{L}^2(X,\mu)$. So in particular this map is onto. I do not know how to prove this. I tried to focus on the easiest case $X=[0,1]$ but still got no progress. Can someone give a hint? Thanks!","Let $(X,\mu)$ be a $\sigma$-finite measure space. If $K\in\mathcal{L}^2(X\times X,\mu\times\mu)$ then the map $A_K:\mathcal{L}^2(X,\mu)\to\mathcal{L}^2(X,\mu)$ defined by\begin{equation} A_Kf(x)=\int_XK(x,y)f(y)d\mu(y) \end{equation} is Hilbert-Schmidt. But Arveson (Proposition 2.8.6) says this $K\mapsto A_K$ is an isomorphism from $\mathcal{L}^2(X\times X,\mu\times\mu)$ to the space of Hilbert-Schmidt operators on $\mathcal{L}^2(X,\mu)$. So in particular this map is onto. I do not know how to prove this. I tried to focus on the easiest case $X=[0,1]$ but still got no progress. Can someone give a hint? Thanks!",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
67,"Function in $H^1$, but not continuous","Function in , but not continuous",H^1,"By the Sobolev embedding theorem, if $\Omega$ is bounded, $H^s(\Omega)\subset C(\Omega)$ for $s>1$, in $\mathbb R^2$. Where I can find a counterexample (if one exists) for the case $s=1$? I mean a discontinuous function ($n=2$),  that belongs to $H^1$.","By the Sobolev embedding theorem, if $\Omega$ is bounded, $H^s(\Omega)\subset C(\Omega)$ for $s>1$, in $\mathbb R^2$. Where I can find a counterexample (if one exists) for the case $s=1$? I mean a discontinuous function ($n=2$),  that belongs to $H^1$.",,"['functional-analysis', 'functions', 'sobolev-spaces', 'examples-counterexamples']"
68,Schauder basis for a separable Banach space,Schauder basis for a separable Banach space,,"It is known that if a Banach space $X$ has a Schauder basis, then $X$ is separable. On the other hand P. Enflo showed that there exist a separable Banach space without Schauder basis. If $X$ is a separable Banach space, then we can find a increasing sequence of finite dimensional subspaces $X_n\subset X$ such that $\cup X_n$ is dense in $X$, hence, we can find a sequence $(x_n)$, such that $x_1,...,x_k$ is a basis of $X_k$ for all $k$. My question is: What is a necessary condition (and maybe sufficient) in order to show that $(x_k)$ is a Schauder basis for $X$?","It is known that if a Banach space $X$ has a Schauder basis, then $X$ is separable. On the other hand P. Enflo showed that there exist a separable Banach space without Schauder basis. If $X$ is a separable Banach space, then we can find a increasing sequence of finite dimensional subspaces $X_n\subset X$ such that $\cup X_n$ is dense in $X$, hence, we can find a sequence $(x_n)$, such that $x_1,...,x_k$ is a basis of $X_k$ for all $k$. My question is: What is a necessary condition (and maybe sufficient) in order to show that $(x_k)$ is a Schauder basis for $X$?",,"['functional-analysis', 'banach-spaces']"
69,Two exercises in functional analysis.,Two exercises in functional analysis.,,"I have met two questions which, after some attempts have I have yet been able to solve nor find any available solutions online. Could anyone please offer me some insights? Let $ H $ be a Hilbert space over $\mathbb{C}$ and $T \in B(H,H)$ an unitary operator. For $ n \in \mathbb{N} $ set $$ S_n : = \frac {1}{n}( I + T + ... + T^{n-1} ) .$$ Show that $S_{n}v \longrightarrow P_{M}v $ as $ n \rightarrow \infty $ where $ P_{M} $ is the orthogonal projection onto the subspace $ \text{Ker}(I - T) $. Let $E$ be a normed vector space over $\mathbb{K}$, let $M \subseteq E $ be a subset and suppose that $ \sup_{ v \in M} |f(v)| < \infty $ for a all functional $f \in B(E, \mathbb{K})$. Show that $M$ is bounded. From what I have heard the second question is not meant to be difficult. However as $E$ is not complete there is not much theorem I could work with. I thought maybe by working with the Banach space $ B(E,\mathbb{K}) $ but came to no result. I'm still a noob in FA so any help would be much appreciated! Thanks!","I have met two questions which, after some attempts have I have yet been able to solve nor find any available solutions online. Could anyone please offer me some insights? Let $ H $ be a Hilbert space over $\mathbb{C}$ and $T \in B(H,H)$ an unitary operator. For $ n \in \mathbb{N} $ set $$ S_n : = \frac {1}{n}( I + T + ... + T^{n-1} ) .$$ Show that $S_{n}v \longrightarrow P_{M}v $ as $ n \rightarrow \infty $ where $ P_{M} $ is the orthogonal projection onto the subspace $ \text{Ker}(I - T) $. Let $E$ be a normed vector space over $\mathbb{K}$, let $M \subseteq E $ be a subset and suppose that $ \sup_{ v \in M} |f(v)| < \infty $ for a all functional $f \in B(E, \mathbb{K})$. Show that $M$ is bounded. From what I have heard the second question is not meant to be difficult. However as $E$ is not complete there is not much theorem I could work with. I thought maybe by working with the Banach space $ B(E,\mathbb{K}) $ but came to no result. I'm still a noob in FA so any help would be much appreciated! Thanks!",,['functional-analysis']
70,Strength of $\sf ZF$+The weak topology on every Banach space is Hausdorff,Strength of +The weak topology on every Banach space is Hausdorff,\sf ZF,"Most functional analysis books prove that Zorn's Lemma$\implies$Hahn-Banach$\implies$""The weak topology on every Banach space is Hausdorff"", however it is known that the Hahn-Banach theorem can be proved from the Boolean Prime Ideal theorem, which is strictly weaker than $\sf ZL$, and that $\sf ZF+HB$ is strictly weaker than $\sf ZF+BPI$. Let $\sf WH$ be the assertion ""The weak topology on every Banach space is Hausdorff"", what's the relation between $\sf ZF$,$\sf ZF+WH$ and $\sf ZF+HB$?","Most functional analysis books prove that Zorn's Lemma$\implies$Hahn-Banach$\implies$""The weak topology on every Banach space is Hausdorff"", however it is known that the Hahn-Banach theorem can be proved from the Boolean Prime Ideal theorem, which is strictly weaker than $\sf ZL$, and that $\sf ZF+HB$ is strictly weaker than $\sf ZF+BPI$. Let $\sf WH$ be the assertion ""The weak topology on every Banach space is Hausdorff"", what's the relation between $\sf ZF$,$\sf ZF+WH$ and $\sf ZF+HB$?",,"['functional-analysis', 'set-theory', 'axiom-of-choice']"
71,Every finite-dimension subspace of $\mathcal{X}$ is closed.,Every finite-dimension subspace of  is closed.,\mathcal{X},"Background Information: (Folland)Theorem 5.8 - Let $\mathcal{X}$ be a normed vector space. a.) If $M$ is a closed subspace of $\mathcal{X}$ and $x\in \mathcal{X}\setminus M$ , there exists $f\in\mathcal{X}^*$ such that $f(x)\neq 0$ and $f(M) = \{0\}$ . In fact, if $\delta = \inf_{y\in M}\|x - y\|$ , $f$ can be taken to satisfy $\|f\| = 1$ and $f(x) = \delta$ . Question: Let $\mathcal{X}$ be a normed vector space. a.) If $M$ is a closed subspace and $x\in\mathcal{X}\setminus M$ then $M + \mathbb{C}x$ is closed. (Use Theorem 5.8a.)). b.) Every finite-dimensional subspace of $\mathcal{X}$ is closed. Proof a.) - Let $M$ be a proper closed subspace of $X$ and let $x\in X\setminus M$ . There existts $f\in X^*$ such that $f(x)\neq 0$ and $f(M) = \{0\}$ . Let $\{u_n + a_nx \}_{1}^{\infty}$ be a sequence in $M + Kx$ that converges to $y\in X$ . Then $$f(y) = \lim\limits_{n\rightarrow \infty}f(u_n + a_n x) = \lim\limits_{n\rightarrow \infty} a_nf(x)$$ since $f$ is continuous, so $\{a_n\}_{1}^{\infty}$ converges to $a:= f(y)/f(x)$ , which implies that $\{a_nx \}_{1}^{\infty}$ converges to $ax$ . Therefore $$\{u_n\}_{1}^{\infty} = \{(u_n + a_nx) - a_nx\}_{1}^{\infty} \to  (y - ax)$$ which lies in $M$ because $M$ is closed. It follows that $y\in M + Kx$ , which shows that $M + Kx$ is closed. Proof b.) - I have spent a considerable amount of time thinking about this but I am not sure how to proceed or how to show this result. Any hints or suggestions are greatly appreciated.","Background Information: (Folland)Theorem 5.8 - Let be a normed vector space. a.) If is a closed subspace of and , there exists such that and . In fact, if , can be taken to satisfy and . Question: Let be a normed vector space. a.) If is a closed subspace and then is closed. (Use Theorem 5.8a.)). b.) Every finite-dimensional subspace of is closed. Proof a.) - Let be a proper closed subspace of and let . There existts such that and . Let be a sequence in that converges to . Then since is continuous, so converges to , which implies that converges to . Therefore which lies in because is closed. It follows that , which shows that is closed. Proof b.) - I have spent a considerable amount of time thinking about this but I am not sure how to proceed or how to show this result. Any hints or suggestions are greatly appreciated.",\mathcal{X} M \mathcal{X} x\in \mathcal{X}\setminus M f\in\mathcal{X}^* f(x)\neq 0 f(M) = \{0\} \delta = \inf_{y\in M}\|x - y\| f \|f\| = 1 f(x) = \delta \mathcal{X} M x\in\mathcal{X}\setminus M M + \mathbb{C}x \mathcal{X} M X x\in X\setminus M f\in X^* f(x)\neq 0 f(M) = \{0\} \{u_n + a_nx \}_{1}^{\infty} M + Kx y\in X f(y) = \lim\limits_{n\rightarrow \infty}f(u_n + a_n x) = \lim\limits_{n\rightarrow \infty} a_nf(x) f \{a_n\}_{1}^{\infty} a:= f(y)/f(x) \{a_nx \}_{1}^{\infty} ax \{u_n\}_{1}^{\infty} = \{(u_n + a_nx) - a_nx\}_{1}^{\infty} \to  (y - ax) M M y\in M + Kx M + Kx,['functional-analysis']
72,Resolvent: Definition,Resolvent: Definition,,"Given a Banach space $E$ . Consider linear operators: $$T:E\supset\mathcal{D}(T)\to E:\quad T(\kappa x+\lambda y)=\kappa T(x)+\lambda T(y)$$ (No other assumptions on the operator!) Denote for shorthand: $$R_\lambda:\mathcal{R}_\lambda\to\mathcal{D}_\lambda:\quad R_\lambda:=(\lambda-T)^{-1}$$ The standard definition for the resolvent set: $$\rho(T):=\{\lambda\in\mathbb{C}:\mathcal{N}_\lambda=(0),\mathcal{R}_\lambda=E,\|R_\lambda \|<\infty\}$$ An alternative definition for the resolvent set: $$\rho(T):=\{\lambda\in\mathbb{C}:\mathcal{N}_\lambda=(0),\overline{\mathcal{R}_\lambda}=E,\|R_\lambda\|<\infty\}$$ (See Werner or Weidmann resp. Kubrusly or Kreyszig.) Do these definitions really agree? Clearly for closed operators they do.",Given a Banach space . Consider linear operators: (No other assumptions on the operator!) Denote for shorthand: The standard definition for the resolvent set: An alternative definition for the resolvent set: (See Werner or Weidmann resp. Kubrusly or Kreyszig.) Do these definitions really agree? Clearly for closed operators they do.,"E T:E\supset\mathcal{D}(T)\to E:\quad T(\kappa x+\lambda y)=\kappa T(x)+\lambda T(y) R_\lambda:\mathcal{R}_\lambda\to\mathcal{D}_\lambda:\quad R_\lambda:=(\lambda-T)^{-1} \rho(T):=\{\lambda\in\mathbb{C}:\mathcal{N}_\lambda=(0),\mathcal{R}_\lambda=E,\|R_\lambda \|<\infty\} \rho(T):=\{\lambda\in\mathbb{C}:\mathcal{N}_\lambda=(0),\overline{\mathcal{R}_\lambda}=E,\|R_\lambda\|<\infty\}","['functional-analysis', 'operator-theory', 'banach-spaces', 'spectral-theory']"
73,Extension of character in Banach algebras,Extension of character in Banach algebras,,"Let $A$ be a Banach algebra. The continuous linear functional $\phi:A\to\Bbb{C}$ is called character if it is non-zero multiplicative function i.e., for every $a,b\in A$ we have $\phi(ab)=\phi(a)\phi(b)$. The set of all character is shown by $\sigma(A)$. Now suppose that $A,B$ are Banach algebra such that $A$ is ideal of $B$. Let $\phi\in\sigma(A)$. Is there a $\psi\in\sigma(B)$ such that for all $a\in A, \psi(a)=\phi(a)$? If it exists, is it unique? If it doesn't exists ever, under which conditions it exists?","Let $A$ be a Banach algebra. The continuous linear functional $\phi:A\to\Bbb{C}$ is called character if it is non-zero multiplicative function i.e., for every $a,b\in A$ we have $\phi(ab)=\phi(a)\phi(b)$. The set of all character is shown by $\sigma(A)$. Now suppose that $A,B$ are Banach algebra such that $A$ is ideal of $B$. Let $\phi\in\sigma(A)$. Is there a $\psi\in\sigma(B)$ such that for all $a\in A, \psi(a)=\phi(a)$? If it exists, is it unique? If it doesn't exists ever, under which conditions it exists?",,"['functional-analysis', 'harmonic-analysis', 'banach-algebras', 'c-star-algebras']"
74,"If $A$ and $B$ are compact, then so is $A+B$.","If  and  are compact, then so is .",A B A+B,"This is an exercise in Chapter 1 from Rudin's Functional Analysis . Prove the following: Let $X$ be a topological vector space. If $A$ and $B$ are compact subsets of $X$, so is $A+B$. My guess: Let $\cup V_{\alpha}$ be an open covering of $A+B$, if we can somehow split each $V_{\alpha}$ into two parts \begin{equation} V_{\alpha}=W_{\alpha}+U_{\alpha} \end{equation} with \begin{equation} \cup W_{\alpha}\supset A, \cup U_{\alpha}\supset B \end{equation} then we can easily pass the compactness of $A$ and $B$ to $A+B$. However, I cannot find such a way to split $V_{\alpha}$. I admit this is the only nontrivial part of this problem. Any hint would be helpful. Thanks!","This is an exercise in Chapter 1 from Rudin's Functional Analysis . Prove the following: Let $X$ be a topological vector space. If $A$ and $B$ are compact subsets of $X$, so is $A+B$. My guess: Let $\cup V_{\alpha}$ be an open covering of $A+B$, if we can somehow split each $V_{\alpha}$ into two parts \begin{equation} V_{\alpha}=W_{\alpha}+U_{\alpha} \end{equation} with \begin{equation} \cup W_{\alpha}\supset A, \cup U_{\alpha}\supset B \end{equation} then we can easily pass the compactness of $A$ and $B$ to $A+B$. However, I cannot find such a way to split $V_{\alpha}$. I admit this is the only nontrivial part of this problem. Any hint would be helpful. Thanks!",,"['functional-analysis', 'compactness', 'topological-vector-spaces', 'sumset']"
75,On the weak closure,On the weak closure,,"Let $\lbrace e_n \rbrace$ for the standard unit vectors in $l_2$. I want to show that $0$ is in weak closure of $\lbrace\sqrt{n}e_n\rbrace$ but no subsequence of $\lbrace \sqrt{n}e_n\rbrace$ weakly converges to 0. For the second assertion, I have the following answer. If $\lbrace \sqrt{n_k}e_{n_k}\rbrace$ be weakly convergent subsequence, then it must be norm-bounded. However, $\| \sqrt{n_k}e_{n_k}\|=\sqrt{n_k}\to \infty$ as $k\to \infty$ which is a contradiction. However, for the first assertion, I cannot figure it out that the difference between the condition that 0 lies in weak closure of sequence and the condition that there is a subsequence weakly converges to 0. Thanks.","Let $\lbrace e_n \rbrace$ for the standard unit vectors in $l_2$. I want to show that $0$ is in weak closure of $\lbrace\sqrt{n}e_n\rbrace$ but no subsequence of $\lbrace \sqrt{n}e_n\rbrace$ weakly converges to 0. For the second assertion, I have the following answer. If $\lbrace \sqrt{n_k}e_{n_k}\rbrace$ be weakly convergent subsequence, then it must be norm-bounded. However, $\| \sqrt{n_k}e_{n_k}\|=\sqrt{n_k}\to \infty$ as $k\to \infty$ which is a contradiction. However, for the first assertion, I cannot figure it out that the difference between the condition that 0 lies in weak closure of sequence and the condition that there is a subsequence weakly converges to 0. Thanks.",,"['functional-analysis', 'banach-spaces']"
76,"Suppose $\phi$ is a weak solution of $\Delta \phi = f \in \mathcal{H}^1$. Then $\phi\in W^{2,1}$",Suppose  is a weak solution of . Then,"\phi \Delta \phi = f \in \mathcal{H}^1 \phi\in W^{2,1}","I'm trying to prove the statement in the title in as simple a way as possible.  It is Theorem 3.2.9 in Helein's book ""Harmonic maps, conservation laws, and moving frames"", although it is not proved there.  The statement is as follows. Suppose $\phi\in\mathbb{R}^m$ is a weak solution of $\Delta \phi = f \in \mathcal{H}^1$, where $\mathcal{H}^1$ is the standard Hardy space on $\mathbb{R}^m$.  Then   $$ \Big\lVert\frac{\partial^2\phi}{\partial x^\alpha \partial x^\beta}\Big\rVert_{L^1(\mathbb{R}^m)} \le C\lVert f \rVert_{\mathcal{H}^1(\mathbb{R}^m)}. $$ My idea is to use convolution with the kernel of the Laplacian, and then differentiate, estimate in $L^1$ and somehow interpolate between the $\mathcal H^1$ and $BMO$ norms.  Then since the kernel of the Laplacian is in $BMO$, I am finished.  However there are two problems with my proof:  I don't know how to prove that one can interpolate a convolution between $\mathcal H^1$ and $BMO$ (atomic decomposition?) and I don't know how to prove that the kernel of the Laplacian is in $BMO$. Does anyone have either a better way to prove this theorem, or a way to fix up my proof?  Thanks!","I'm trying to prove the statement in the title in as simple a way as possible.  It is Theorem 3.2.9 in Helein's book ""Harmonic maps, conservation laws, and moving frames"", although it is not proved there.  The statement is as follows. Suppose $\phi\in\mathbb{R}^m$ is a weak solution of $\Delta \phi = f \in \mathcal{H}^1$, where $\mathcal{H}^1$ is the standard Hardy space on $\mathbb{R}^m$.  Then   $$ \Big\lVert\frac{\partial^2\phi}{\partial x^\alpha \partial x^\beta}\Big\rVert_{L^1(\mathbb{R}^m)} \le C\lVert f \rVert_{\mathcal{H}^1(\mathbb{R}^m)}. $$ My idea is to use convolution with the kernel of the Laplacian, and then differentiate, estimate in $L^1$ and somehow interpolate between the $\mathcal H^1$ and $BMO$ norms.  Then since the kernel of the Laplacian is in $BMO$, I am finished.  However there are two problems with my proof:  I don't know how to prove that one can interpolate a convolution between $\mathcal H^1$ and $BMO$ (atomic decomposition?) and I don't know how to prove that the kernel of the Laplacian is in $BMO$. Does anyone have either a better way to prove this theorem, or a way to fix up my proof?  Thanks!",,"['functional-analysis', 'partial-differential-equations', 'harmonic-analysis', 'poissons-equation', 'hardy-spaces']"
77,What is the functional derivative?,What is the functional derivative?,,"I do not understand, if the functional derivative is a function a generalized function (distribution) a functional itself something different (see Euler-Lagrange) To clarify my question, I have seen multiple instances of functional derivative definitions Functionals When the Functional gets Taylor expanded (here using a ""good"" $\eta(x)$ ) we get $$F[y(x)+\epsilon \eta(x)] = F[y(x)] + \frac{dF[y(x) + \epsilon \eta(x)]}{d\epsilon}\Big|_{\epsilon=0}\cdot \epsilon + ...$$ as I understood, the term on the RHS is the functional derivative. But since the LHS is a functional and the RHS is a functional + a real number ( $\epsilon$ ) times the functional derivative, I conclude that the functional derivative must also be a functional. Functions/Distributions The english wikipedia page [2] states, that the functional derivative is defined as $$\int{\frac{\delta F}{\delta \rho} (x)\phi(x)dx}=\frac{dF[\rho(x) + \epsilon \phi(x)]}{d\epsilon}\Big|_{\epsilon=0}$$ notice that the RHS is equivalent to the functional derivative defined above. However, it is $$\frac{\delta F}{\delta \rho} (x)$$ that is defined to be the functional derivative, and not the RHS (as I concluded above). Therefore I may as well assume that the functional derivative is a function/distribution. Something else The solution to the Euler-Lagrange Equation (one dimensional for simplicity) given an Energy Functional $J[y] = \int_{a}^{b}{L(x,y,y')}$ is $$\frac{\delta J}{\delta y} = \frac{dL}{dy} - \frac{d}{dx}(\frac{dL}{dy'}) = 0$$ here, $\frac{\delta J}{\delta y}$ is supposedly the fractional derivative of the integral, which has to be stationary. RHS tells me that the functiona derivative is a differential equation - which has a function as a solution - but I am now completely unsure what the functional derivative in itself actualy is. I have seen multiple viewpoints, each and every one cluttering my intuition even more. For instance the wikipedia article claims that $\frac{\delta F}{\delta \rho} (x)$ has to be seen as a ""gradient"" (which is a vector in multivariate calculus), while $\int{\frac{\delta F}{\delta \rho} (x)\phi(x)dx}$ has to be thought of like a directional derivative (which is the inner product of the gradient and the direction vector). But since there are no bounds on the integral the ""directional derivative"" is also a function, or am I mistaken? [1] http://lab.sentef.org/wp-content/uploads/2016/11/Tutorial_02.pdf page 4 [2] https://en.wikipedia.org/wiki/Functional_derivative","I do not understand, if the functional derivative is a function a generalized function (distribution) a functional itself something different (see Euler-Lagrange) To clarify my question, I have seen multiple instances of functional derivative definitions Functionals When the Functional gets Taylor expanded (here using a ""good"" ) we get as I understood, the term on the RHS is the functional derivative. But since the LHS is a functional and the RHS is a functional + a real number ( ) times the functional derivative, I conclude that the functional derivative must also be a functional. Functions/Distributions The english wikipedia page [2] states, that the functional derivative is defined as notice that the RHS is equivalent to the functional derivative defined above. However, it is that is defined to be the functional derivative, and not the RHS (as I concluded above). Therefore I may as well assume that the functional derivative is a function/distribution. Something else The solution to the Euler-Lagrange Equation (one dimensional for simplicity) given an Energy Functional is here, is supposedly the fractional derivative of the integral, which has to be stationary. RHS tells me that the functiona derivative is a differential equation - which has a function as a solution - but I am now completely unsure what the functional derivative in itself actualy is. I have seen multiple viewpoints, each and every one cluttering my intuition even more. For instance the wikipedia article claims that has to be seen as a ""gradient"" (which is a vector in multivariate calculus), while has to be thought of like a directional derivative (which is the inner product of the gradient and the direction vector). But since there are no bounds on the integral the ""directional derivative"" is also a function, or am I mistaken? [1] http://lab.sentef.org/wp-content/uploads/2016/11/Tutorial_02.pdf page 4 [2] https://en.wikipedia.org/wiki/Functional_derivative","\eta(x) F[y(x)+\epsilon \eta(x)] = F[y(x)] + \frac{dF[y(x) + \epsilon \eta(x)]}{d\epsilon}\Big|_{\epsilon=0}\cdot \epsilon + ... \epsilon \int{\frac{\delta F}{\delta \rho} (x)\phi(x)dx}=\frac{dF[\rho(x) + \epsilon \phi(x)]}{d\epsilon}\Big|_{\epsilon=0} \frac{\delta F}{\delta \rho} (x) J[y] = \int_{a}^{b}{L(x,y,y')} \frac{\delta J}{\delta y} = \frac{dL}{dy} - \frac{d}{dx}(\frac{dL}{dy'}) = 0 \frac{\delta J}{\delta y} \frac{\delta F}{\delta \rho} (x) \int{\frac{\delta F}{\delta \rho} (x)\phi(x)dx}","['functional-analysis', 'calculus-of-variations']"
78,Is the function characterized by $f(\alpha x+(1-\alpha) y) \le f^{\alpha}(\alpha x)f^{1-\alpha}(y)$ convex?,Is the function characterized by  convex?,f(\alpha x+(1-\alpha) y) \le f^{\alpha}(\alpha x)f^{1-\alpha}(y),"Is a non-negative function $f(x)$ convex ? If for $x  \ge y$ it satisfies for any $\alpha \in [0,1]$. \begin{align} f(\alpha x+(1-\alpha) y) \le f^{\alpha}(\alpha x)f^{1-\alpha}(y)  \ \text{       eq.1} \end{align} This is very reminiscent of the log-convexity which is defined as \begin{align} f(\alpha x+(1-\alpha) y) \le f^{\alpha}( x)f^{1-\alpha}(y). \end{align} Extra Hypothesis we can add: There exist a log-convex function $g(x)$ such that $f(x) \le g(x)$ and such that \begin{align} f(\alpha x+(1-\alpha) y)  \le     g^\alpha(x)f^{1-\alpha}(y). \end{align} $f(x)$ is a decreasing function of $x$. A little back ground: I am trying to show that if $f$ satisfies eq.$1$ then it is continuous .  The property that came to my mind is that if $f$ is convex then it is continuos on the open set. The condition in eq.$1$ is very similar to log-convexity (recall log-convexity implies convexity) and the hope is that it implies convexity. Thank you for any help and suggestions, in advance.","Is a non-negative function $f(x)$ convex ? If for $x  \ge y$ it satisfies for any $\alpha \in [0,1]$. \begin{align} f(\alpha x+(1-\alpha) y) \le f^{\alpha}(\alpha x)f^{1-\alpha}(y)  \ \text{       eq.1} \end{align} This is very reminiscent of the log-convexity which is defined as \begin{align} f(\alpha x+(1-\alpha) y) \le f^{\alpha}( x)f^{1-\alpha}(y). \end{align} Extra Hypothesis we can add: There exist a log-convex function $g(x)$ such that $f(x) \le g(x)$ and such that \begin{align} f(\alpha x+(1-\alpha) y)  \le     g^\alpha(x)f^{1-\alpha}(y). \end{align} $f(x)$ is a decreasing function of $x$. A little back ground: I am trying to show that if $f$ satisfies eq.$1$ then it is continuous .  The property that came to my mind is that if $f$ is convex then it is continuos on the open set. The condition in eq.$1$ is very similar to log-convexity (recall log-convexity implies convexity) and the hope is that it implies convexity. Thank you for any help and suggestions, in advance.",,"['functional-analysis', 'convex-analysis']"
79,$\ell_\infty$ is a Grothendieck space,is a Grothendieck space,\ell_\infty,"The problem I am considering stated formally is this: Show that if a sequence in $\ell_\infty^*$ is weak*-convergent, then it is also weakly convergent. We may reduce this to the case where the sequence is weak$^*$-null, and show that it is weakly null. This is a special case of a result of Grothendieck from the 50's.  It is an internal characterization of what is now called a Grothendieck space. A Banach space $X$ is Grothendieck if every weak$^*$-convergent sequence in $X^*$ is weakly convergent. In his ""resume,"" Grothendieck proves that $C(K)$ for $K$ an extremally disconnected (also called Stonian) compact space satisfies this property.  Since we can represent $\ell_\infty$ as $C(\beta\mathbb{N})$, the space of continuous functions on the Stone-Cech compactification of the natural numbers (which is Stonian), it satisfies this property. So my questions are 1) If you know the general technique to show this property for $C(K)$ spaces as mentioned above could you give me a brief indication, and also 2) Is there something in this particular example that might make it easier to deal with than general $C(K)$? Either way I assume we have to be able to either work blindly with elements of $\ell_\infty^{**}$ since we can't well characterize it, or there may be some other way to show weak convergence.  (Or I also think we can say in more modern language that $\ell_\infty^{**}$ whatever it is is a von Neumann algebra if that is helpful at all).","The problem I am considering stated formally is this: Show that if a sequence in $\ell_\infty^*$ is weak*-convergent, then it is also weakly convergent. We may reduce this to the case where the sequence is weak$^*$-null, and show that it is weakly null. This is a special case of a result of Grothendieck from the 50's.  It is an internal characterization of what is now called a Grothendieck space. A Banach space $X$ is Grothendieck if every weak$^*$-convergent sequence in $X^*$ is weakly convergent. In his ""resume,"" Grothendieck proves that $C(K)$ for $K$ an extremally disconnected (also called Stonian) compact space satisfies this property.  Since we can represent $\ell_\infty$ as $C(\beta\mathbb{N})$, the space of continuous functions on the Stone-Cech compactification of the natural numbers (which is Stonian), it satisfies this property. So my questions are 1) If you know the general technique to show this property for $C(K)$ spaces as mentioned above could you give me a brief indication, and also 2) Is there something in this particular example that might make it easier to deal with than general $C(K)$? Either way I assume we have to be able to either work blindly with elements of $\ell_\infty^{**}$ since we can't well characterize it, or there may be some other way to show weak convergence.  (Or I also think we can say in more modern language that $\ell_\infty^{**}$ whatever it is is a von Neumann algebra if that is helpful at all).",,"['functional-analysis', 'banach-spaces', 'weak-convergence', 'von-neumann-algebras']"
80,Algebraically flavoured functional analysis book,Algebraically flavoured functional analysis book,,"I'm looking for a book on functional analysis that would suit someone who is more algebraically/geometrically oriented and seeks to learn the subject with the goal of using it later for geometric analysis and/or topological k-theory (and maybe noncommutative geometry in the far future). What would be a good book fitting this description? I have the relevant background in basic measure theory, complex analysis and linear algebra.","I'm looking for a book on functional analysis that would suit someone who is more algebraically/geometrically oriented and seeks to learn the subject with the goal of using it later for geometric analysis and/or topological k-theory (and maybe noncommutative geometry in the far future). What would be a good book fitting this description? I have the relevant background in basic measure theory, complex analysis and linear algebra.",,"['functional-analysis', 'reference-request', 'book-recommendation']"
81,Incorrect proof of Hahn Banach Theorem,Incorrect proof of Hahn Banach Theorem,,"What is wrong with the following trivial proof of the Hahn Banach Theorem? Hahn Banach Theorem: Let $V$ is a real normed vector space and $U$ a subspace.  Then if $\phi : U \rightarrow \mathbb{R}$ is a linear functional bounded by $C>0$, then there exists an extension of $\phi$, $\phi ': V\rightarrow \mathbb{R}$, also linear and bounded by $C$. ""Proof"" : Since $V/U$ has a basis (by the axiom of choice), it seems we can lift it to get a complimentary subspace $W \subset V$ such that $V= W \oplus U$ (as vector spaces).  Then just define $\phi'(w+u)=\phi (u)$. But this can't be right….","What is wrong with the following trivial proof of the Hahn Banach Theorem? Hahn Banach Theorem: Let $V$ is a real normed vector space and $U$ a subspace.  Then if $\phi : U \rightarrow \mathbb{R}$ is a linear functional bounded by $C>0$, then there exists an extension of $\phi$, $\phi ': V\rightarrow \mathbb{R}$, also linear and bounded by $C$. ""Proof"" : Since $V/U$ has a basis (by the axiom of choice), it seems we can lift it to get a complimentary subspace $W \subset V$ such that $V= W \oplus U$ (as vector spaces).  Then just define $\phi'(w+u)=\phi (u)$. But this can't be right….",,"['functional-analysis', 'analysis', 'fake-proofs']"
82,there exists a sequence $x_n$ such that $\| x_n \|=1$ and $x_n$ converges weakly to $0$.,there exists a sequence  such that  and  converges weakly to .,x_n \| x_n \|=1 x_n 0,"Let $X$ be a reflexive Banach space of infinite dimension. a) Prove that there exists a sequence $x_n$ such that $\| x_n \|=1$ and $x_n$ converges weakly to $0$. b) Let $x_n$ be a sequence such that $\forall f \in X' \quad \exists \lim\limits_{n\to\infty} f(x_n)<\infty$ .Prove that $x_n$ converges weakly. c) Find a Banach space non riflexive where b is false. My idea: the weak closure of $S^1$ is the closed unit ball, thus $0\in$ the weak closure of $S^1$. But to prove that there exists a sequence in $S^1$ that converges weakly to 0 we must prove that the weak topology is metrizzable.Is it always true in riflexive spaces? I would appreciate any idea on the solution.Thank you in advance.","Let $X$ be a reflexive Banach space of infinite dimension. a) Prove that there exists a sequence $x_n$ such that $\| x_n \|=1$ and $x_n$ converges weakly to $0$. b) Let $x_n$ be a sequence such that $\forall f \in X' \quad \exists \lim\limits_{n\to\infty} f(x_n)<\infty$ .Prove that $x_n$ converges weakly. c) Find a Banach space non riflexive where b is false. My idea: the weak closure of $S^1$ is the closed unit ball, thus $0\in$ the weak closure of $S^1$. But to prove that there exists a sequence in $S^1$ that converges weakly to 0 we must prove that the weak topology is metrizzable.Is it always true in riflexive spaces? I would appreciate any idea on the solution.Thank you in advance.",,['functional-analysis']
83,How to prove that a bounded linear operator is compact?,How to prove that a bounded linear operator is compact?,,"I encountered a homework problem that says: If $A$ is a bounded linear operator from $X$ to $Y$. And $K$ is a compact operator from $X$ to $Y$, where $X$ and $Y$ are both Banach spaces, and Ran$(A)\subset$ Ran$(K)$. Then $A$ is also a compact operator. I tried to use the definition of a compact operator to solve this one. (Indeed, the professor only covered the definition of compact operator in class and said that it would be enough for the homework problems.) Here's what I did. I started by choosing a bounded sequence $x_n$ in X and since A is bounded, $A(x_n)$ is also bounded. And from the assumption that $R(A)\subset R(K)$, I conclude that there exist $y_n\in X$, s.t. $K(y_n)=A(x_n)$. Now if I can somehow prove that $y_n$ is bounded in X, I can easily prove the problem by using the compactness of K. But this is exactly the place where I am stuck. Please help me out. Am I going along the right path? Also, I had another problem saying that: If X is infinitely dimensional and K is an compact operator and is one to one, then I-K must not be compact. I proved this one, but didn't really use the assumption that K is one to one. I looked over and over again but couldn't nd where I made the mistake. Here's what I did: Choose any sequence in X that is of norm 1. Then suppose I-K is compact. It follows there must exists a subsequence $x_{n_k}$ that $(I-K)(x_{n_k})$ converges. And since K is compact, there exists a sub-subsequence $x_{n_{k_j}}$ that $K(x_{n_{k_j}})$. Now I claim that in fact $x_{n_{k_j}}$ converges in X. Indeed, $x_{n_{k_j}}=(I-K)(x_{n_{k_j}})+K(x_{n_{k_j}})$. Hence, for any sequence on the unit sphere, I've found a subsequence that converges. This means the unit sphere is compact, which contradicts with X being infinitely dimensional. Did I do something wrong?","I encountered a homework problem that says: If $A$ is a bounded linear operator from $X$ to $Y$. And $K$ is a compact operator from $X$ to $Y$, where $X$ and $Y$ are both Banach spaces, and Ran$(A)\subset$ Ran$(K)$. Then $A$ is also a compact operator. I tried to use the definition of a compact operator to solve this one. (Indeed, the professor only covered the definition of compact operator in class and said that it would be enough for the homework problems.) Here's what I did. I started by choosing a bounded sequence $x_n$ in X and since A is bounded, $A(x_n)$ is also bounded. And from the assumption that $R(A)\subset R(K)$, I conclude that there exist $y_n\in X$, s.t. $K(y_n)=A(x_n)$. Now if I can somehow prove that $y_n$ is bounded in X, I can easily prove the problem by using the compactness of K. But this is exactly the place where I am stuck. Please help me out. Am I going along the right path? Also, I had another problem saying that: If X is infinitely dimensional and K is an compact operator and is one to one, then I-K must not be compact. I proved this one, but didn't really use the assumption that K is one to one. I looked over and over again but couldn't nd where I made the mistake. Here's what I did: Choose any sequence in X that is of norm 1. Then suppose I-K is compact. It follows there must exists a subsequence $x_{n_k}$ that $(I-K)(x_{n_k})$ converges. And since K is compact, there exists a sub-subsequence $x_{n_{k_j}}$ that $K(x_{n_{k_j}})$. Now I claim that in fact $x_{n_{k_j}}$ converges in X. Indeed, $x_{n_{k_j}}=(I-K)(x_{n_{k_j}})+K(x_{n_{k_j}})$. Hence, for any sequence on the unit sphere, I've found a subsequence that converges. This means the unit sphere is compact, which contradicts with X being infinitely dimensional. Did I do something wrong?",,"['functional-analysis', 'compact-operators']"
84,Baker Campbell Hausdorff formula for unbounded operators,Baker Campbell Hausdorff formula for unbounded operators,,"Baker Campbell Hausdorff formula says that for elements $X,Y$ of a Lie algebra we have $$e^Xe^Y=\exp(X+Y+\frac12[X,Y]+...),$$ which for $[X,Y]$ being central reduces to $$e^Xe^Y=\exp(X+Y+\frac12[X,Y]).$$ As I am not an expert in Lie algebras, I was wondering if this setup is suitable to say that thus a formula like this holds when $X,Y$ are unbounded operators with common core such that $[X,Y]=i$. If so, I would be grateful for the reference to a proof in that particular case. Motivation: An important identity in quantum mechanics is the decomposition of the Weyl operator as an exponential of position and momentum operators: $$W(z_1,...,z_n)=\exp(-i\sqrt{2}\sum_{j}(x_jp_j-y_jq_j)).$$ When I was trying to prove this in an explicit way (straight from the definition of the Weyl operator), there comes a point when I need to use the BCH formula. Since for unbounded operators I cannot use the usual expressions for exponential (as a sum of a convergent series), this worries me slightly.","Baker Campbell Hausdorff formula says that for elements $X,Y$ of a Lie algebra we have $$e^Xe^Y=\exp(X+Y+\frac12[X,Y]+...),$$ which for $[X,Y]$ being central reduces to $$e^Xe^Y=\exp(X+Y+\frac12[X,Y]).$$ As I am not an expert in Lie algebras, I was wondering if this setup is suitable to say that thus a formula like this holds when $X,Y$ are unbounded operators with common core such that $[X,Y]=i$. If so, I would be grateful for the reference to a proof in that particular case. Motivation: An important identity in quantum mechanics is the decomposition of the Weyl operator as an exponential of position and momentum operators: $$W(z_1,...,z_n)=\exp(-i\sqrt{2}\sum_{j}(x_jp_j-y_jq_j)).$$ When I was trying to prove this in an explicit way (straight from the definition of the Weyl operator), there comes a point when I need to use the BCH formula. Since for unbounded operators I cannot use the usual expressions for exponential (as a sum of a convergent series), this worries me slightly.",,"['functional-analysis', 'reference-request', 'lie-algebras', 'quantum-mechanics', 'unbounded-operators']"
85,Ideals of the algebra of all bounded linear operators on $\ell_p \oplus \ell_q$,Ideals of the algebra of all bounded linear operators on,\ell_p \oplus \ell_q,Let $\mathcal{L}(X)$ be the algebra of all bounded linear operators from $X$ to $X$ for Banach space $X$. I need to show that $\mathcal{L}(\ell_p \oplus \ell_q)$ for $p \neq q$ contains at least two nontrivial closed two-sided ideals.,Let $\mathcal{L}(X)$ be the algebra of all bounded linear operators from $X$ to $X$ for Banach space $X$. I need to show that $\mathcal{L}(\ell_p \oplus \ell_q)$ for $p \neq q$ contains at least two nontrivial closed two-sided ideals.,,"['functional-analysis', 'banach-spaces', 'ideals', 'lp-spaces']"
86,"Calculate the operator norm of $A: L^2[0,1] \to L^2[0,1]$ defined by $(Af)(x):=i\int_0^x f(t)\,dt-\frac{i}{2} \int_0^1 f(t) \,dt$",Calculate the operator norm of  defined by,"A: L^2[0,1] \to L^2[0,1] (Af)(x):=i\int_0^x f(t)\,dt-\frac{i}{2} \int_0^1 f(t) \,dt","I want to calculate the operator norm of the operator $A: L^2[0,1] \to L^2[0,1]$ which is defined by $$(Af)(x):=i\int\limits_0^x f(t)\,dt-\frac{i}{2} \int\limits_0^1 f(t)\, dt$$ I've already shown that this operator is compact and selfadjoint. I think maybe this helps me calculating the operator norm. Maybe through spectral theorem for compact self adjoint operators. I also know that for integral operators of the form $$(Kf)(x)=\int\limits_0^1 k(x,t) f(t)\,dt$$ the inequality $\Vert K \Vert \leq \Vert k \Vert{}_{L^2}$ holds. For $$(Af)(x)=i\int\limits_0^x f(t)\,dt-\frac{i}{2} \int\limits_0^1 f(t) \,dt = \int\limits_0^1 i\,\left(1_{[0,x]}(t)-\frac{1}{2}\right)f(t)\,dt$$ this gives me an upper bound: $$\Vert A \Vert \leq \left\Vert  i~1_{[0,x]}-\frac{i}{2} \right\Vert{}_{L^2}=\frac{1}{2}$$ Can someone help me?",I want to calculate the operator norm of the operator which is defined by I've already shown that this operator is compact and selfadjoint. I think maybe this helps me calculating the operator norm. Maybe through spectral theorem for compact self adjoint operators. I also know that for integral operators of the form the inequality holds. For this gives me an upper bound: Can someone help me?,"A: L^2[0,1] \to L^2[0,1] (Af)(x):=i\int\limits_0^x f(t)\,dt-\frac{i}{2} \int\limits_0^1 f(t)\, dt (Kf)(x)=\int\limits_0^1 k(x,t) f(t)\,dt \Vert K \Vert \leq \Vert k \Vert{}_{L^2} (Af)(x)=i\int\limits_0^x f(t)\,dt-\frac{i}{2} \int\limits_0^1 f(t) \,dt = \int\limits_0^1 i\,\left(1_{[0,x]}(t)-\frac{1}{2}\right)f(t)\,dt \Vert A \Vert \leq \left\Vert  i~1_{[0,x]}-\frac{i}{2} \right\Vert{}_{L^2}=\frac{1}{2}","['functional-analysis', 'operator-theory', 'compact-operators', 'self-adjoint-operators']"
87,"Space of linear, continuous, hyperbolic functions is open, dense in the set of invertible functions","Space of linear, continuous, hyperbolic functions is open, dense in the set of invertible functions",,"Let $(X,||\cdot||)$ be a Banach space on $\mathbb{C}$ and $\mathcal{L}(X)$ the set of linear, continuous functions from $X$ to itself. For $T\in\mathcal{L}(X)$, define the norm $||T||_{\mathcal{L}(X)}:=\sup_{v\neq 0}\frac{||T(v)||}{||v||}$ and the continuous spectrum $\sigma(T):=\{\lambda\in\mathbb{C}\mid A-\lambda I\,\text{ has no inverse}\}$. Define the sets:   $$GL(X):=\{T\in\mathcal{L}(X)\mid T\text{ is invertible}\}$$   $$\mathcal{H}(X):=\{T\in GL(X)\mid T\text{ is hyperbolic}\}$$   (where hyperbolic means $|\lambda|\neq 1$ for all $\lambda\in\sigma(T)$) Prove that: (1) $GL(X)\subset\mathcal{L}(X)$ is open and (2) $\mathcal{H}(X)$ is open, dense in $GL(X)$. (1) Take $A\in GL(X)$ and the open ball $B_r(A)$, where $r:=1/||A^{-1}||$. If $B\in B_r(A)$, then $||I-BA^{-1}||\leq||A-B||\cdot||A^{-1}||<r||A^{-1}||=1$. The series $\sum_{n=0}^\infty(I-BA^{-1})^n$ is therefore convergent, so $BA^{-1}$ is invertible with $(BA^{-1})^{-1}=(I-(I-BA^{-1}))^{-1}=\sum_{n=0}^\infty(I-BA^{-1})^n$. Therefore, $B$ is invertible $\Rightarrow B_r(A)\subset GL(X)$. $_\blacksquare$ (2) We prove $GL(X)\setminus\mathcal{H}(X)$ is closed in $GL(X)$. If $\{A_n\}_{n\in\mathbb{N}}\subset GL(X)\setminus\mathcal{H}(X)$ a Cauchy sequence converging to $A\in GL(X)$, we need to prove $A\notin \mathcal{H}(X)$. By definition, for all $n$ there is $\lambda_n\in \mathbb{C}$ such that $|\lambda_n|=1$ and $A_n-\lambda_nI\notin GL(X)$. Since $\mathbb{S}^1:=\{\lambda\in\mathbb{C}\mid |\lambda|=1\}$ is compact, there is a convergent subsequence $\{\lambda_{i_n}\}_{n\in\mathbb{N}}$ converging to $\lambda\in\mathbb{S}^1$, so $\lim_{n\to\infty} A_{i_n}-\lambda_{i_n}I=$ $A-\lambda I$. Since $A_{i_n}-\lambda_{i_n} I\notin GL(X)$ (which is open), $A-\lambda I\notin GL(X)$, so $A\in GL(X)\setminus\mathcal{H}(X)$. To prove $\mathcal{H}(X)$ is dense in $GL(X)$, my idea is this: let $A\in GL(X)\setminus\mathcal{H}(X)$ and $\epsilon>0$ arbitrary, then there exist $z\in\mathbb{C}$ with $|z|<\epsilon$ such that $A+zI\in\mathcal{H}(X)$. I feel like this could work, but I don't know how to guarantee $\sigma(A+zI)\cap\mathbb{S}^1=\emptyset$.","Let $(X,||\cdot||)$ be a Banach space on $\mathbb{C}$ and $\mathcal{L}(X)$ the set of linear, continuous functions from $X$ to itself. For $T\in\mathcal{L}(X)$, define the norm $||T||_{\mathcal{L}(X)}:=\sup_{v\neq 0}\frac{||T(v)||}{||v||}$ and the continuous spectrum $\sigma(T):=\{\lambda\in\mathbb{C}\mid A-\lambda I\,\text{ has no inverse}\}$. Define the sets:   $$GL(X):=\{T\in\mathcal{L}(X)\mid T\text{ is invertible}\}$$   $$\mathcal{H}(X):=\{T\in GL(X)\mid T\text{ is hyperbolic}\}$$   (where hyperbolic means $|\lambda|\neq 1$ for all $\lambda\in\sigma(T)$) Prove that: (1) $GL(X)\subset\mathcal{L}(X)$ is open and (2) $\mathcal{H}(X)$ is open, dense in $GL(X)$. (1) Take $A\in GL(X)$ and the open ball $B_r(A)$, where $r:=1/||A^{-1}||$. If $B\in B_r(A)$, then $||I-BA^{-1}||\leq||A-B||\cdot||A^{-1}||<r||A^{-1}||=1$. The series $\sum_{n=0}^\infty(I-BA^{-1})^n$ is therefore convergent, so $BA^{-1}$ is invertible with $(BA^{-1})^{-1}=(I-(I-BA^{-1}))^{-1}=\sum_{n=0}^\infty(I-BA^{-1})^n$. Therefore, $B$ is invertible $\Rightarrow B_r(A)\subset GL(X)$. $_\blacksquare$ (2) We prove $GL(X)\setminus\mathcal{H}(X)$ is closed in $GL(X)$. If $\{A_n\}_{n\in\mathbb{N}}\subset GL(X)\setminus\mathcal{H}(X)$ a Cauchy sequence converging to $A\in GL(X)$, we need to prove $A\notin \mathcal{H}(X)$. By definition, for all $n$ there is $\lambda_n\in \mathbb{C}$ such that $|\lambda_n|=1$ and $A_n-\lambda_nI\notin GL(X)$. Since $\mathbb{S}^1:=\{\lambda\in\mathbb{C}\mid |\lambda|=1\}$ is compact, there is a convergent subsequence $\{\lambda_{i_n}\}_{n\in\mathbb{N}}$ converging to $\lambda\in\mathbb{S}^1$, so $\lim_{n\to\infty} A_{i_n}-\lambda_{i_n}I=$ $A-\lambda I$. Since $A_{i_n}-\lambda_{i_n} I\notin GL(X)$ (which is open), $A-\lambda I\notin GL(X)$, so $A\in GL(X)\setminus\mathcal{H}(X)$. To prove $\mathcal{H}(X)$ is dense in $GL(X)$, my idea is this: let $A\in GL(X)\setminus\mathcal{H}(X)$ and $\epsilon>0$ arbitrary, then there exist $z\in\mathbb{C}$ with $|z|<\epsilon$ such that $A+zI\in\mathcal{H}(X)$. I feel like this could work, but I don't know how to guarantee $\sigma(A+zI)\cap\mathbb{S}^1=\emptyset$.",,"['functional-analysis', 'dynamical-systems', 'banach-spaces', 'spectral-theory']"
88,"Is the complex Banach space $C([0,1])$ dual to any Banach Space?",Is the complex Banach space  dual to any Banach Space?,"C([0,1])","I've been able to show that the extreme points of $C([0,1])$ are the continuous functions that take values on the unit circle. However, I'm not sure how to reason from here as to whether or not it is the dual to any Banach space. Any hints? The standard approach I've been using to show things are not dual to any space has been to use Krein-Milman and Alaoglu to argue by contradiction, but I don't know what the closed convex hull of unitary complex functions is.","I've been able to show that the extreme points of $C([0,1])$ are the continuous functions that take values on the unit circle. However, I'm not sure how to reason from here as to whether or not it is the dual to any Banach space. Any hints? The standard approach I've been using to show things are not dual to any space has been to use Krein-Milman and Alaoglu to argue by contradiction, but I don't know what the closed convex hull of unitary complex functions is.",,['functional-analysis']
89,Supremum of Banach Spaces,Supremum of Banach Spaces,,"Let $X$ be a linear space with a family of complete norms $(\| \circ \|_I)_{I \in \mathcal{I}}$ on $X$, i.e. for every $I \in \mathcal{I}$ the tuple $(X,\|\circ\|_I)$ is a Banach space. Now define $$\| x \|_\infty := \sup_{I \in \mathcal{I}} \| x \|_I \in [0,\infty]$$ for every $x \in X$ and $X_\infty = \{ x \in X ~:~ \|x\|_\infty < \infty \}$. It is easy to see that $(X_\infty,\|\circ\|_\infty)$ is a normed space. In particular, $X_\infty$ is a linear space. Is $(X_\infty,\|\circ\|_\infty)$ a Banach space, i.e. is it complete? My guess would be negative, but I can't come up with an (counter-)example. What I have tried so far: It is easy to see that if $X$ is finite-dimensional and $\mathcal{I}$ is finite, then $(X_\infty,\|\circ\|_\infty)$ is again complete. Therefore I asumme that either I have to find many ""incompatible"" norms on a finite-dimensional space, or only ""a few"" norms on a ""complicated"" space. I would appreciate hints for either direction.","Let $X$ be a linear space with a family of complete norms $(\| \circ \|_I)_{I \in \mathcal{I}}$ on $X$, i.e. for every $I \in \mathcal{I}$ the tuple $(X,\|\circ\|_I)$ is a Banach space. Now define $$\| x \|_\infty := \sup_{I \in \mathcal{I}} \| x \|_I \in [0,\infty]$$ for every $x \in X$ and $X_\infty = \{ x \in X ~:~ \|x\|_\infty < \infty \}$. It is easy to see that $(X_\infty,\|\circ\|_\infty)$ is a normed space. In particular, $X_\infty$ is a linear space. Is $(X_\infty,\|\circ\|_\infty)$ a Banach space, i.e. is it complete? My guess would be negative, but I can't come up with an (counter-)example. What I have tried so far: It is easy to see that if $X$ is finite-dimensional and $\mathcal{I}$ is finite, then $(X_\infty,\|\circ\|_\infty)$ is again complete. Therefore I asumme that either I have to find many ""incompatible"" norms on a finite-dimensional space, or only ""a few"" norms on a ""complicated"" space. I would appreciate hints for either direction.",,"['functional-analysis', 'banach-spaces', 'locally-convex-spaces']"
90,Isomorphic matrix algebras with non-isomorphic C*-algebras,Isomorphic matrix algebras with non-isomorphic C*-algebras,,"Let $A$ and $B$ be two $C^{\ast}$ -algebras such that their matrix algebras, $M_2(A)$ and $M_2(B)$ , are $\ast$ -isomorphic $C^\ast$ -algebras. Question 1 : Are $A$ and $B$ isomorphic $C^\ast$ -algebras? In a related case, let $X$ and $Y$ be locally compact topological spaces. Question 2 : Are there non-homeomorphic $X$ and $Y$ such that $M_2\big(C_0(X)\big)$ and $M_2\big(C_0(Y)\big)$ are $\ast$ -isomorphic $C^\ast$ -algebras? It is obvious that ""2"" is not a forced condition.","Let and be two -algebras such that their matrix algebras, and , are -isomorphic -algebras. Question 1 : Are and isomorphic -algebras? In a related case, let and be locally compact topological spaces. Question 2 : Are there non-homeomorphic and such that and are -isomorphic -algebras? It is obvious that ""2"" is not a forced condition.",A B C^{\ast} M_2(A) M_2(B) \ast C^\ast A B C^\ast X Y X Y M_2\big(C_0(X)\big) M_2\big(C_0(Y)\big) \ast C^\ast,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
91,Are GNS representations the way to build physical Hilbert spaces?,Are GNS representations the way to build physical Hilbert spaces?,,"Consider a separable $C^*$ algebra $\mathcal A$. The space of states is also separable in the weak* topology, let $S$ be a countable dense subset. Denoting with $H_\omega$ the GNS representation of a state $\omega$ we retrieve a representation of $\mathcal A$ on the Hilbert space $H(S)=\bigoplus_{\omega\in S}H_\omega$. This representation is isometric and $H$ is separable. In the context of quantum mechanics we have built a candidate for the physical Hilbert space just by knowing an algebra of observables. This construction however depends on how we chose our set $S$. My question is: Are the representations of $\mathcal A$ on $H(S)$ and $H(S')$ unitarily equivalent for any two dense countable subsets $S,S'$ of the state space of $\mathcal A$?","Consider a separable $C^*$ algebra $\mathcal A$. The space of states is also separable in the weak* topology, let $S$ be a countable dense subset. Denoting with $H_\omega$ the GNS representation of a state $\omega$ we retrieve a representation of $\mathcal A$ on the Hilbert space $H(S)=\bigoplus_{\omega\in S}H_\omega$. This representation is isometric and $H$ is separable. In the context of quantum mechanics we have built a candidate for the physical Hilbert space just by knowing an algebra of observables. This construction however depends on how we chose our set $S$. My question is: Are the representations of $\mathcal A$ on $H(S)$ and $H(S')$ unitarily equivalent for any two dense countable subsets $S,S'$ of the state space of $\mathcal A$?",,"['functional-analysis', 'mathematical-physics', 'c-star-algebras', 'quantum-mechanics', 'quantum-field-theory']"
92,Integral operator is bounded on $L^p$ if it maps $L^p$ to itself,Integral operator is bounded on  if it maps  to itself,L^p L^p,"Here is a homework excercise. Let $(X,\Omega,\mu)$ be a $\sigma$ -finite measure space, $1\leq p <\infty.$ and suppose that $k:X\times X\rightarrow \mathbb{C}$ is an $\Omega \times \Omega$ measurable function such that for $f\in L^p(\mu)$ we have $k(x,\cdot)f(\cdot)\in L^1(\mu),a.e.x$ and $(Kf)(x)=\int k(x,y)f(y)d{\mu(y)}$ defines an element $Kf$ of $L^p(\mu)$ . Show that $K:L^p(\mu)\rightarrow L^p(\mu)$ is a bounded operator. I think we can use the Closed Graph Theorem. suppose that $f_n\rightarrow 0,Kf_n\rightarrow g$ in $L^p$ ,we only need to prove $g=0$ in $L^p$ . Since $Kf_n\rightarrow g$ in $L^p$ , then without loss of generality, we can get $Kf_n(x)\rightarrow g(x)$ a.e. Then I want to show $Kf_n(x)\rightarrow 0$ a.e. using $f_n\rightarrow 0$ in $L^p$ . But I need to prove that $k(x,\cdot)\in L^q(\mu)$ a.e. $x$ ( $1/p+1/q=1$ ). How to prove $k(x,\cdot)\in L^q(\mu)$ a.e. $x$ ?","Here is a homework excercise. Let be a -finite measure space, and suppose that is an measurable function such that for we have and defines an element of . Show that is a bounded operator. I think we can use the Closed Graph Theorem. suppose that in ,we only need to prove in . Since in , then without loss of generality, we can get a.e. Then I want to show a.e. using in . But I need to prove that a.e. ( ). How to prove a.e. ?","(X,\Omega,\mu) \sigma 1\leq p <\infty. k:X\times X\rightarrow \mathbb{C} \Omega \times \Omega f\in L^p(\mu) k(x,\cdot)f(\cdot)\in L^1(\mu),a.e.x (Kf)(x)=\int k(x,y)f(y)d{\mu(y)} Kf L^p(\mu) K:L^p(\mu)\rightarrow L^p(\mu) f_n\rightarrow 0,Kf_n\rightarrow g L^p g=0 L^p Kf_n\rightarrow g L^p Kf_n(x)\rightarrow g(x) Kf_n(x)\rightarrow 0 f_n\rightarrow 0 L^p k(x,\cdot)\in L^q(\mu) x 1/p+1/q=1 k(x,\cdot)\in L^q(\mu) x","['functional-analysis', 'lp-spaces', 'integral-operators']"
93,Converse of a fixed-point theorem,Converse of a fixed-point theorem,,"I'm having some trouble furnishing a proof here. Let $(E, d)$ be a metric space such that any $k$-Lipschitz function has a fixed point for $0 < k < 1$. Does it follow, then, that $E$ is complete?","I'm having some trouble furnishing a proof here. Let $(E, d)$ be a metric space such that any $k$-Lipschitz function has a fixed point for $0 < k < 1$. Does it follow, then, that $E$ is complete?",,"['functional-analysis', 'metric-spaces', 'fixed-point-theorems']"
94,Are most linear operators invertible?,Are most linear operators invertible?,,"Are most matrices invertible? discusses this question for matrices. All the answers implicitly used the (unique) vector topology on the space of $n \times n$ matrices. But my understanding (correct me if I'm wrong) is that infinite-dimensional linear operators can have multiple vector norms which induce inequivalent topologies, so the question becomes trickier. My (not entirely precise) question is, for an infinite-dimensional vector space, is the set of isomorphisms a dense open set under every ""reasonable"" operator topology? Under every operator norm topology induced by a ""reasonable"" norm on the vector space? My intuition says yes, but I'd be curious if anyone can make the words ""reasonable"" more precise. (I assume that there's no natural way to generalize the Lebesgue-measure sense of ""almost all matrices are invertible"" to the infinite-dimensional case, due to the absence of an inifinite-dimensional Lebesgue measure , but correct me if I'm wrong.)","Are most matrices invertible? discusses this question for matrices. All the answers implicitly used the (unique) vector topology on the space of $n \times n$ matrices. But my understanding (correct me if I'm wrong) is that infinite-dimensional linear operators can have multiple vector norms which induce inequivalent topologies, so the question becomes trickier. My (not entirely precise) question is, for an infinite-dimensional vector space, is the set of isomorphisms a dense open set under every ""reasonable"" operator topology? Under every operator norm topology induced by a ""reasonable"" norm on the vector space? My intuition says yes, but I'd be curious if anyone can make the words ""reasonable"" more precise. (I assume that there's no natural way to generalize the Lebesgue-measure sense of ""almost all matrices are invertible"" to the infinite-dimensional case, due to the absence of an inifinite-dimensional Lebesgue measure , but correct me if I'm wrong.)",,"['functional-analysis', 'measure-theory', 'inverse', 'topological-vector-spaces']"
95,Does $L^p$ have a basis for which the Pythagorean identity with exponent $p$ holds?,Does  have a basis for which the Pythagorean identity with exponent  holds?,L^p p,"In the $\ell^p$ spaces with $1\leq p<\infty$, let $\{e_n\}$ be the standard basis.  If $x=\sum_{n=1}^\infty a_ne_n$ is in $\ell^p$, then for any $k$ we can write $$||x||^p=\sum_{n=1}^k |a_n|^p+\sum_{n=k+1}^\infty |a_n|^p=||h||^p+||g||^p$$ where $h\in$ span$\{e_1,\ldots,e_k\}$ and $g\in$ span$\{e_{k+1},e_{k+2},\ldots\}$. My question is whether a similar equality holds in the $L^p[0,1]$ spaces for $1\leq p<\infty$? Some internet searching brought me to a sequence of functions $\{f_n\}$ called the Franklin System that turns out to be an orthonormal basis for $L^2[0,1]$. Also, the $\{f_n\}$ are a Schauder basis for $L^p[0,1]$. So can a similar computation be carried out for $f\in L^p[0,1]$? That is, for every $k$ do we have the equality $||f||^p=||h||^p+||g||^p$, where $h\in$ span$\{f_1,\ldots,f_k\}$ and $g\in$ span$\{f_{k+1},f_{k+2},\ldots\}$? Or is there another basis for $L^p[0,1]$ for which this equality holds? Thank you.","In the $\ell^p$ spaces with $1\leq p<\infty$, let $\{e_n\}$ be the standard basis.  If $x=\sum_{n=1}^\infty a_ne_n$ is in $\ell^p$, then for any $k$ we can write $$||x||^p=\sum_{n=1}^k |a_n|^p+\sum_{n=k+1}^\infty |a_n|^p=||h||^p+||g||^p$$ where $h\in$ span$\{e_1,\ldots,e_k\}$ and $g\in$ span$\{e_{k+1},e_{k+2},\ldots\}$. My question is whether a similar equality holds in the $L^p[0,1]$ spaces for $1\leq p<\infty$? Some internet searching brought me to a sequence of functions $\{f_n\}$ called the Franklin System that turns out to be an orthonormal basis for $L^2[0,1]$. Also, the $\{f_n\}$ are a Schauder basis for $L^p[0,1]$. So can a similar computation be carried out for $f\in L^p[0,1]$? That is, for every $k$ do we have the equality $||f||^p=||h||^p+||g||^p$, where $h\in$ span$\{f_1,\ldots,f_k\}$ and $g\in$ span$\{f_{k+1},f_{k+2},\ldots\}$? Or is there another basis for $L^p[0,1]$ for which this equality holds? Thank you.",,"['functional-analysis', 'banach-spaces', 'lp-spaces']"
96,Growth of Tychonov's Counterexample for Heat Equation Uniqueness,Growth of Tychonov's Counterexample for Heat Equation Uniqueness,,"Define a function $\varphi$ on $\mathbb{R}_{+}$ by $$\varphi(t):=\begin{cases}e^{-1/t^{2}}, & {t>0}\\ 0, & {t\leq 0}\end{cases}\tag{1}$$ It is well-known that $\varphi$ is $C^{\infty}(\overline{\mathbb{R}}_{+})$ and $\varphi^{(k)}(0)=0$ for all integers $k\geq 0$. Tychonoff famously showed that the function $u:\mathbb{R}_{+}\times\mathbb{R}\rightarrow\mathbb{R}$ defined by $$u(t,x):=\sum_{k=0}^{\infty}\dfrac{\varphi^{(k)}(t)}{(2k)!}x^{2k}, \qquad (t,x)\in\mathbb{R}_{+}\times\mathbb{R}\tag{2}$$ belongs to $C^{\infty}(\mathbb{R}_{+}\times\mathbb{R})$ and satisfies the Cauchy problem $$\begin{cases}\partial_{t}u-\Delta u=0 & {(t,x)\in\mathbb{R}_{+}\times\mathbb{R}},\\ u(0,\cdot)=0 & {}\end{cases}\tag{3}$$ Question. Motivated by this question , I am trying to show that for $t>0$ fixed,   $u(t,\cdot)$ does not define a tempered distribution. I am looking for   a ""lower bound"" on the growth of $u$ for $t>0$ fixed which I can use   to construct a sequence of test functions   $\varphi_{m}\in\mathcal{S}(\mathbb{R}^{n})$ which tend to zero in the   Schwartz topology but $$\left|\langle{u(t,\cdot),\varphi_{m}}\rangle\right|=\left|\int_{\mathbb{R}^{n}}u(t,x)\varphi_{m}(x)dx\right|\geq c,\quad\forall m\in\mathbb{N}\tag{4}$$ for some $c>0$. I know that the function $u$ does not satisfy the growth condition $$\sup_{0\leq t\leq T}\left|u(x,t)\right|\leq Ae^{c\left|x\right|^{2}},\quad\forall x\in\mathbb{R}^{n}\tag{5}$$ where $T>0$ is fixed and $A,c>0$ are constants depending on $T$; however, I fail to see how this helps in the task described above. Edit: Einar Rødland has presented some graphical evidence to suggest that for fixed $t>0$, $u(t,\cdot)$ is ""well-behaved"" and defines a tempered distribution. I am seeking a proof of disproof of this conjecture. Note that a ""wild solution"" can be ""well-behaved"" for $t>0$ fixed. For example, in this paper , the authors present an example of nonuniqueness for the Cauchy problem which is continuous on $\mathbb{R}\times [0,\infty)$ and satisfies $$\left|u(x,t)\right|\leq C e^{\epsilon/t},\qquad (x,t)\in\mathbb{R}\times\mathbb{R}_{+}$$ where $C=C(\epsilon)$, for any $\epsilon>0$. Also, at the end of the paper the authors remark that all other (i.e. besides theirs) nonuniqueness solutions are unbounded in $x$, which would seem to contradict Einar's suggestion.","Define a function $\varphi$ on $\mathbb{R}_{+}$ by $$\varphi(t):=\begin{cases}e^{-1/t^{2}}, & {t>0}\\ 0, & {t\leq 0}\end{cases}\tag{1}$$ It is well-known that $\varphi$ is $C^{\infty}(\overline{\mathbb{R}}_{+})$ and $\varphi^{(k)}(0)=0$ for all integers $k\geq 0$. Tychonoff famously showed that the function $u:\mathbb{R}_{+}\times\mathbb{R}\rightarrow\mathbb{R}$ defined by $$u(t,x):=\sum_{k=0}^{\infty}\dfrac{\varphi^{(k)}(t)}{(2k)!}x^{2k}, \qquad (t,x)\in\mathbb{R}_{+}\times\mathbb{R}\tag{2}$$ belongs to $C^{\infty}(\mathbb{R}_{+}\times\mathbb{R})$ and satisfies the Cauchy problem $$\begin{cases}\partial_{t}u-\Delta u=0 & {(t,x)\in\mathbb{R}_{+}\times\mathbb{R}},\\ u(0,\cdot)=0 & {}\end{cases}\tag{3}$$ Question. Motivated by this question , I am trying to show that for $t>0$ fixed,   $u(t,\cdot)$ does not define a tempered distribution. I am looking for   a ""lower bound"" on the growth of $u$ for $t>0$ fixed which I can use   to construct a sequence of test functions   $\varphi_{m}\in\mathcal{S}(\mathbb{R}^{n})$ which tend to zero in the   Schwartz topology but $$\left|\langle{u(t,\cdot),\varphi_{m}}\rangle\right|=\left|\int_{\mathbb{R}^{n}}u(t,x)\varphi_{m}(x)dx\right|\geq c,\quad\forall m\in\mathbb{N}\tag{4}$$ for some $c>0$. I know that the function $u$ does not satisfy the growth condition $$\sup_{0\leq t\leq T}\left|u(x,t)\right|\leq Ae^{c\left|x\right|^{2}},\quad\forall x\in\mathbb{R}^{n}\tag{5}$$ where $T>0$ is fixed and $A,c>0$ are constants depending on $T$; however, I fail to see how this helps in the task described above. Edit: Einar Rødland has presented some graphical evidence to suggest that for fixed $t>0$, $u(t,\cdot)$ is ""well-behaved"" and defines a tempered distribution. I am seeking a proof of disproof of this conjecture. Note that a ""wild solution"" can be ""well-behaved"" for $t>0$ fixed. For example, in this paper , the authors present an example of nonuniqueness for the Cauchy problem which is continuous on $\mathbb{R}\times [0,\infty)$ and satisfies $$\left|u(x,t)\right|\leq C e^{\epsilon/t},\qquad (x,t)\in\mathbb{R}\times\mathbb{R}_{+}$$ where $C=C(\epsilon)$, for any $\epsilon>0$. Also, at the end of the paper the authors remark that all other (i.e. besides theirs) nonuniqueness solutions are unbounded in $x$, which would seem to contradict Einar's suggestion.",,"['functional-analysis', 'partial-differential-equations', 'fourier-analysis', 'distribution-theory']"
97,Differences between $-\Delta: H_0^1(\Omega)\to H^{-1}(\Omega)$ and $-\Delta: H^2(\Omega)\cap H_0^1(\Omega)\to L^2(\Omega)$,Differences between  and,-\Delta: H_0^1(\Omega)\to H^{-1}(\Omega) -\Delta: H^2(\Omega)\cap H_0^1(\Omega)\to L^2(\Omega),"I'll try to explain what I want to know: Let $\Omega\subset\mathbb{R}^n$ be a bounded domain. When we look to $-\Delta: H^2(\Omega)\cap H_0^1(\Omega)\to L^2(\Omega)$, the meaning of $-\Delta$ is precisely ""the sum of second partial derivatives with Dirichlet boundary conditions"" since the partial (weak) derivatives of a $ H^2(\Omega)$ exist and lie on $L^2(\Omega)$. So when we say ""let's solve $-\Delta u=f$ !"" this equation means what it means. To solve this we can define the weak problem ""find an $u\in H_0^1(\Omega)$ such that $\langle \nabla u, \nabla v\rangle_0=\langle f,v\rangle_0$ for all $v\in H_0^1(\Omega)$"", solve it applying Riesz Representation Theorem and then use regularity theory to show that $u\in H^2(\Omega)$. It's not the case with $-\Delta: H_0^1(\Omega)\to H^{-1}(\Omega)$. What's the meaning of $-\Delta u$ for $u\in H_0^1(\Omega)$?","I'll try to explain what I want to know: Let $\Omega\subset\mathbb{R}^n$ be a bounded domain. When we look to $-\Delta: H^2(\Omega)\cap H_0^1(\Omega)\to L^2(\Omega)$, the meaning of $-\Delta$ is precisely ""the sum of second partial derivatives with Dirichlet boundary conditions"" since the partial (weak) derivatives of a $ H^2(\Omega)$ exist and lie on $L^2(\Omega)$. So when we say ""let's solve $-\Delta u=f$ !"" this equation means what it means. To solve this we can define the weak problem ""find an $u\in H_0^1(\Omega)$ such that $\langle \nabla u, \nabla v\rangle_0=\langle f,v\rangle_0$ for all $v\in H_0^1(\Omega)$"", solve it applying Riesz Representation Theorem and then use regularity theory to show that $u\in H^2(\Omega)$. It's not the case with $-\Delta: H_0^1(\Omega)\to H^{-1}(\Omega)$. What's the meaning of $-\Delta u$ for $u\in H_0^1(\Omega)$?",,"['analysis', 'functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
98,Elementary applications of Krein-Milman,Elementary applications of Krein-Milman,,"Recall that the Krein-Milman theorem asserts that a compact convex set in a LCTVS is the closed convex hull of its extreme points.  This has lots of applications to areas of mathematics that use analysis: the existence of pure states in C*-algebra theory, the existence of irreducible representations of groups, the existence of ergodic measures... I'm interested in applications of the theorem which are very easy to state but hard to achieve any other way.  When I say ""very easy to state"" I mean the result should be expressible in the language of elementary Banach space or Hilbert space theory - no C*-algebras, representation theory, or measures.  For an example of what I have in mind, the Krein-Milman theorem implies that $C[0,1]$ is not the dual of any Banach space.  If anyone knows an application of Krein-Milman to the theory of Fourier series, that would be ideal. Edit: (t.b.) A version of this question now is on MathOverflow and already has a few answers.","Recall that the Krein-Milman theorem asserts that a compact convex set in a LCTVS is the closed convex hull of its extreme points.  This has lots of applications to areas of mathematics that use analysis: the existence of pure states in C*-algebra theory, the existence of irreducible representations of groups, the existence of ergodic measures... I'm interested in applications of the theorem which are very easy to state but hard to achieve any other way.  When I say ""very easy to state"" I mean the result should be expressible in the language of elementary Banach space or Hilbert space theory - no C*-algebras, representation theory, or measures.  For an example of what I have in mind, the Krein-Milman theorem implies that $C[0,1]$ is not the dual of any Banach space.  If anyone knows an application of Krein-Milman to the theory of Fourier series, that would be ideal. Edit: (t.b.) A version of this question now is on MathOverflow and already has a few answers.",,"['functional-analysis', 'convex-analysis', 'locally-convex-spaces']"
99,What plays the role of the identity for the generalized convolution associated to the Fourier-Bessel transform?,What plays the role of the identity for the generalized convolution associated to the Fourier-Bessel transform?,,"In traditional Fourier theory, the Dirac delta plays the role of an ""identity"" for the $L^1$ algebra with respect to the usual convolution. The convolution is traditionally built out of group structures by translating by group elements. The Fourier-Bessel transform of $f\in L^1(\mathbb{R}^+)$ is given by $$\mathcal{F}_{\nu}f(y) = \int_{\mathbb{R}^+} j_{\nu}(2\pi xy)f(x)\,d\mu_{\nu}(x),$$ where $-\frac{1}{2} < \nu$, $d\mu_{\nu}(x) = \frac{2\pi^{\nu+1}}{\Gamma(\nu+1)} x^{2\nu+1}\,dx$, and $j_{\nu}(x) = 2^{\nu} \Gamma(\nu+1)x^{-\nu}J_{\nu}(x)$. (Here $J_{\nu}$ is the Bessel function of the first kind.) The Fourier-Bessel transform has a notion of translation associated to it which is not generated by a group; instead, the translation is given by $$T_y^{\nu} f(x) = \frac{\Gamma(\nu+1)}{\sqrt{\pi}\Gamma\left(\nu+\frac{1}{2}\right)} \int_{-1}^1 f\left(\sqrt{x^2-2\alpha xy + y^2}\right)(1-\alpha^2)^{\nu-\frac{1}{2}} \,d\nu.$$ With this generalized translation, a generalized convolution can be defined: $$ (f\ast_{\nu} g)(y) = \int_{\mathbb{R}^+} T_y^{\nu}f(x)g(x)\,d\mu_{\nu}(x).$$ The generalized translation and convolution share many properties with the usual (Fourier) translation and convolution operators: $$ T_y^{\nu} (j_{\nu}(\lambda x)) = j_{\nu}(\lambda x) j_{\nu}(\lambda y) \tag{1} $$ $$ \mathcal{F}_{\nu}(T_y^{\nu}f)(x) = j_{\nu}(2\pi xy) \mathcal{F}_{\nu}f(x) \tag{2} $$ $$ \mathcal{F}_{\nu}(f\ast_{\nu} g) = \mathcal{F}_{\nu}f \cdot \mathcal{F}_{\nu} g \tag{3} $$ $$ f\ast_{\nu} g = g\ast_{\nu} f \tag{4}$$ The first is analogous to the property that $e^{-i\omega(t-t')} = e^{-i\omega t}e^{-i\omega t'}$. The second is analogous to the property that $\mathcal{F}(f(\cdot - t)) = e^{-i\omega t}\mathcal{F}f$. The third is analogous to the usual convolution theorem. The last is a statement of the commutativity of convolution. With the numerous analogues, it is natural to consider what plays the role of the Dirac delta for the generalized convolution for the Fourier-Bessel transform. The usual Dirac delta is not an identity for the generalized convolution. To see this, let's see what the generalized translation of the Dirac delta is. $$T_y^{\nu}\delta(x) = \frac{\Gamma(\nu+1)}{\sqrt{\pi} \Gamma \left(\nu+ \frac{1}{2}\right)}\int_{-1}^1 \delta\left(\sqrt{x^2-2\alpha xy+y^2}  \right)(1-\alpha^2)^{\nu-\frac{1}{2}}\,d\alpha.$$ (This is of course meant as a distributional integral.) The Dirac delta has the following property: $$\delta(g(z)) = \sum_{z_0}\frac{\delta(z-z_0)}{g'(z_0)},$$ where the $z_0$ are the zeroes of $g$. Here $g(\alpha) = \sqrt{x^2-2\alpha xy+y^2}$. $g(\alpha) = 0$ when $\alpha = \frac{x^2+y^2}{2xy}$. Moreover, $g'(\alpha) = -\frac{xy}{g(\alpha)}$ and so $$\delta\left(\sqrt{x^2-2\alpha xy+y^2}\right) = -\frac{g\left(\frac{x^2 +y^2}{2xy}\right)}{xy}\delta\left(\alpha - \frac{x^2+y^2}{2xy}\right) = 0.$$ The generalized translation of the Dirac delta actually vanishes! This is more or less because $\frac{1}{g'} \propto g$. With standard translation operators, by definition we have $$\delta \ast f = \langle \delta_y,f\rangle = f(y),$$ Replacing this with the generalized translation, this would read $$\delta\ast_{\nu} f = \langle T_y^{\nu}\delta, f\rangle \stackrel{?}{=} f(y).$$ However the above analysis shows that $\langle T_y^{\nu}\delta, f\rangle = 0$ since $T_y^{\nu}\delta$ is zero and so the Dirac delta is not the identity with regards to the generalized convolution. Since the usual Dirac delta is not an identity with regards to convolution, my question is: what is? I've thought about this for a while but nothing jumps out at me. I would think it's some sort of variation on the Dirac delta but it's not clear at all due to the nonlinear nature (in terms of coordinates) of the generalized translation. Much of this is based on this paper by Ghobber and Jaming.","In traditional Fourier theory, the Dirac delta plays the role of an ""identity"" for the $L^1$ algebra with respect to the usual convolution. The convolution is traditionally built out of group structures by translating by group elements. The Fourier-Bessel transform of $f\in L^1(\mathbb{R}^+)$ is given by $$\mathcal{F}_{\nu}f(y) = \int_{\mathbb{R}^+} j_{\nu}(2\pi xy)f(x)\,d\mu_{\nu}(x),$$ where $-\frac{1}{2} < \nu$, $d\mu_{\nu}(x) = \frac{2\pi^{\nu+1}}{\Gamma(\nu+1)} x^{2\nu+1}\,dx$, and $j_{\nu}(x) = 2^{\nu} \Gamma(\nu+1)x^{-\nu}J_{\nu}(x)$. (Here $J_{\nu}$ is the Bessel function of the first kind.) The Fourier-Bessel transform has a notion of translation associated to it which is not generated by a group; instead, the translation is given by $$T_y^{\nu} f(x) = \frac{\Gamma(\nu+1)}{\sqrt{\pi}\Gamma\left(\nu+\frac{1}{2}\right)} \int_{-1}^1 f\left(\sqrt{x^2-2\alpha xy + y^2}\right)(1-\alpha^2)^{\nu-\frac{1}{2}} \,d\nu.$$ With this generalized translation, a generalized convolution can be defined: $$ (f\ast_{\nu} g)(y) = \int_{\mathbb{R}^+} T_y^{\nu}f(x)g(x)\,d\mu_{\nu}(x).$$ The generalized translation and convolution share many properties with the usual (Fourier) translation and convolution operators: $$ T_y^{\nu} (j_{\nu}(\lambda x)) = j_{\nu}(\lambda x) j_{\nu}(\lambda y) \tag{1} $$ $$ \mathcal{F}_{\nu}(T_y^{\nu}f)(x) = j_{\nu}(2\pi xy) \mathcal{F}_{\nu}f(x) \tag{2} $$ $$ \mathcal{F}_{\nu}(f\ast_{\nu} g) = \mathcal{F}_{\nu}f \cdot \mathcal{F}_{\nu} g \tag{3} $$ $$ f\ast_{\nu} g = g\ast_{\nu} f \tag{4}$$ The first is analogous to the property that $e^{-i\omega(t-t')} = e^{-i\omega t}e^{-i\omega t'}$. The second is analogous to the property that $\mathcal{F}(f(\cdot - t)) = e^{-i\omega t}\mathcal{F}f$. The third is analogous to the usual convolution theorem. The last is a statement of the commutativity of convolution. With the numerous analogues, it is natural to consider what plays the role of the Dirac delta for the generalized convolution for the Fourier-Bessel transform. The usual Dirac delta is not an identity for the generalized convolution. To see this, let's see what the generalized translation of the Dirac delta is. $$T_y^{\nu}\delta(x) = \frac{\Gamma(\nu+1)}{\sqrt{\pi} \Gamma \left(\nu+ \frac{1}{2}\right)}\int_{-1}^1 \delta\left(\sqrt{x^2-2\alpha xy+y^2}  \right)(1-\alpha^2)^{\nu-\frac{1}{2}}\,d\alpha.$$ (This is of course meant as a distributional integral.) The Dirac delta has the following property: $$\delta(g(z)) = \sum_{z_0}\frac{\delta(z-z_0)}{g'(z_0)},$$ where the $z_0$ are the zeroes of $g$. Here $g(\alpha) = \sqrt{x^2-2\alpha xy+y^2}$. $g(\alpha) = 0$ when $\alpha = \frac{x^2+y^2}{2xy}$. Moreover, $g'(\alpha) = -\frac{xy}{g(\alpha)}$ and so $$\delta\left(\sqrt{x^2-2\alpha xy+y^2}\right) = -\frac{g\left(\frac{x^2 +y^2}{2xy}\right)}{xy}\delta\left(\alpha - \frac{x^2+y^2}{2xy}\right) = 0.$$ The generalized translation of the Dirac delta actually vanishes! This is more or less because $\frac{1}{g'} \propto g$. With standard translation operators, by definition we have $$\delta \ast f = \langle \delta_y,f\rangle = f(y),$$ Replacing this with the generalized translation, this would read $$\delta\ast_{\nu} f = \langle T_y^{\nu}\delta, f\rangle \stackrel{?}{=} f(y).$$ However the above analysis shows that $\langle T_y^{\nu}\delta, f\rangle = 0$ since $T_y^{\nu}\delta$ is zero and so the Dirac delta is not the identity with regards to the generalized convolution. Since the usual Dirac delta is not an identity with regards to convolution, my question is: what is? I've thought about this for a while but nothing jumps out at me. I would think it's some sort of variation on the Dirac delta but it's not clear at all due to the nonlinear nature (in terms of coordinates) of the generalized translation. Much of this is based on this paper by Ghobber and Jaming.",,"['functional-analysis', 'distribution-theory', 'convolution', 'integral-transforms']"
