,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Is the inclusion $C^1[0,1]\subset C[0,1]$ compact?",Is the inclusion  compact?,"C^1[0,1]\subset C[0,1]","I am working on this problem but i couldn't succeed . Consider the space $C^1[0,1]$ with the norm $$\|f\|=\max \{\|f\|_{C[0,1]}, \|f'\|_{C[0,1]}\},$$ I don't know if the inclusion map is compact, but my friend said it is . How do i show that the inclusion map from $$(C^1[0,1],\| .\|) \to (C[0,1],\| .\|)$$ is compact  ? Thanks .","I am working on this problem but i couldn't succeed . Consider the space $C^1[0,1]$ with the norm $$\|f\|=\max \{\|f\|_{C[0,1]}, \|f'\|_{C[0,1]}\},$$ I don't know if the inclusion map is compact, but my friend said it is . How do i show that the inclusion map from $$(C^1[0,1],\| .\|) \to (C[0,1],\| .\|)$$ is compact  ? Thanks .",,"['functional-analysis', 'banach-spaces', 'compact-operators']"
1,"Spectrum of the $\ell^{1}$ operator $A(x)=(x_{2}+x_{3}+x_{4}+ \dots,x_1,x_2,x_3,\dots)$",Spectrum of the  operator,"\ell^{1} A(x)=(x_{2}+x_{3}+x_{4}+ \dots,x_1,x_2,x_3,\dots)","Let $A\colon \ell^{1}\to \ell^{1}$ be defined by $$A(x)=(x_{2}+x_{3}+x_{4}+ \dots,x_1,x_2,x_3,\dots),$$ where $x\in\ell^1$ iff $\sum|x_k|<\infty$. Let $D$ be the closed unit disc in $\Bbb C$ and $\lambda_0=(1+\sqrt5)/2$. Show that $$\sigma(A)=D\cup\{\lambda_0\}.$$ I have managed to show that Eig$(A)=\{\lambda_0\}$ and $D\subset\sigma(a)$ so that $D\cup\{\lambda_0\}\subset\sigma(A)$. How can I prove the converse?","Let $A\colon \ell^{1}\to \ell^{1}$ be defined by $$A(x)=(x_{2}+x_{3}+x_{4}+ \dots,x_1,x_2,x_3,\dots),$$ where $x\in\ell^1$ iff $\sum|x_k|<\infty$. Let $D$ be the closed unit disc in $\Bbb C$ and $\lambda_0=(1+\sqrt5)/2$. Show that $$\sigma(A)=D\cup\{\lambda_0\}.$$ I have managed to show that Eig$(A)=\{\lambda_0\}$ and $D\subset\sigma(a)$ so that $D\cup\{\lambda_0\}\subset\sigma(A)$. How can I prove the converse?",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
2,Self adjoints and unitaries in a banach * algebra,Self adjoints and unitaries in a banach * algebra,,Are the spectra of self adjoints and unitaries in banach * algebras necessarily a subset of the reals and the unit circle respectively?  The proofs I know for C* algebras use the continuous functional calculus.,Are the spectra of self adjoints and unitaries in banach * algebras necessarily a subset of the reals and the unit circle respectively?  The proofs I know for C* algebras use the continuous functional calculus.,,"['analysis', 'functional-analysis']"
3,Local base of a topological vector space,Local base of a topological vector space,,"I would like to prove that if $B$ is local base for a topological vector space $X$, then every member of $B$ contains the closure of some member of $B$. I would appreciate if somebody can guide me through this problem.  I am still facing problems in understanding various primary concepts.","I would like to prove that if $B$ is local base for a topological vector space $X$, then every member of $B$ contains the closure of some member of $B$. I would appreciate if somebody can guide me through this problem.  I am still facing problems in understanding various primary concepts.",,"['functional-analysis', 'topological-vector-spaces']"
4,A normed space is locally compact iff its closed unit ball is compact.,A normed space is locally compact iff its closed unit ball is compact.,,"To prove that A normed space is locally compact if and only if its finite dimensional , I need to prove a lemma: A normed space is locally compact if and only if its closed unit ball is compact. One way implication seems to be easy i.e., if the closed unit ball is compact then normed space is locally compact. But I'm still not very clear. How to prove the lemma? As I understand (one of) the definition(s) of a locally compact metric space is:A metric space (X,d) is said to be locally compact if every x belongs to some open set A such that A is compact.","To prove that A normed space is locally compact if and only if its finite dimensional , I need to prove a lemma: A normed space is locally compact if and only if its closed unit ball is compact. One way implication seems to be easy i.e., if the closed unit ball is compact then normed space is locally compact. But I'm still not very clear. How to prove the lemma? As I understand (one of) the definition(s) of a locally compact metric space is:A metric space (X,d) is said to be locally compact if every x belongs to some open set A such that A is compact.",,"['functional-analysis', 'normed-spaces']"
5,Characterization of Hilbert spaces using orthogonal decomposition,Characterization of Hilbert spaces using orthogonal decomposition,,"Using the closest point property of Hilbert spaces we can prove that for any closed subspace $A \subset H$ we can decompose H as $$H = A \oplus A^{\bot}.$$ Is this property characterizing Hilbert spaces? Namely, if we have an inner product space H such that for every closed subspace $A \subset H$ we can write $$H = A \oplus A^{\bot}$$ then space is Hilbert? I've seen some specific cases, where the space was not complete and $H \neq A \oplus A^{\bot}$ for some closed $A$ ; for example for $H = c_{00}$ (space of sequences with finite support) with inner product inherited from $\ell^2$ and $A = \{ x \in c_{00}: \sum_{n=1}^{\infty} \frac{x_n}{n}=0\}$ so I wonder if we can generalize example like this and always find a closed subspace $A$ of an incomplete inner product space $H$ , such that $H \neq A \oplus A^{\bot}$ ? Or if there is a different way of approaching this question perhaps.","Using the closest point property of Hilbert spaces we can prove that for any closed subspace we can decompose H as Is this property characterizing Hilbert spaces? Namely, if we have an inner product space H such that for every closed subspace we can write then space is Hilbert? I've seen some specific cases, where the space was not complete and for some closed ; for example for (space of sequences with finite support) with inner product inherited from and so I wonder if we can generalize example like this and always find a closed subspace of an incomplete inner product space , such that ? Or if there is a different way of approaching this question perhaps.",A \subset H H = A \oplus A^{\bot}. A \subset H H = A \oplus A^{\bot} H \neq A \oplus A^{\bot} A H = c_{00} \ell^2 A = \{ x \in c_{00}: \sum_{n=1}^{\infty} \frac{x_n}{n}=0\} A H H \neq A \oplus A^{\bot},"['functional-analysis', 'hilbert-spaces']"
6,Is the limit of the spectral radius the spectral radius of the limit?,Is the limit of the spectral radius the spectral radius of the limit?,,"Let $A$ be an unital Banach algebra, $x \in A$ and $(x_n)$ a sequence in $A$ converging to $x$ . I want to show that $$ \lim\limits_n \rho (x_n) = \rho (x).$$ I can show that $$\limsup \rho(x_n) \leq \rho(x)$$ for every Banach algebra. In addition, if A is a commutative algebra, it's easy to prove that $$\liminf \rho(x_n) \geq \rho(x),$$ so the proposition it's true in commutative Banach algebras. Can we prove it when A is non commutative? If it's not, how can we show a counterexample? I've tried to build some counterxamples in the space of non-singular matrix, but nothing seems to work. My other idea is consider the Banach algebra of operators defined in some Hilbert/Banach space, but the spectral radius is a bit difficult to calculate. Anyone can help me? Thank you very much.","Let be an unital Banach algebra, and a sequence in converging to . I want to show that I can show that for every Banach algebra. In addition, if A is a commutative algebra, it's easy to prove that so the proposition it's true in commutative Banach algebras. Can we prove it when A is non commutative? If it's not, how can we show a counterexample? I've tried to build some counterxamples in the space of non-singular matrix, but nothing seems to work. My other idea is consider the Banach algebra of operators defined in some Hilbert/Banach space, but the spectral radius is a bit difficult to calculate. Anyone can help me? Thank you very much.","A x \in A (x_n) A x  \lim\limits_n \rho (x_n) = \rho (x). \limsup \rho(x_n) \leq \rho(x) \liminf \rho(x_n) \geq \rho(x),","['functional-analysis', 'operator-theory', 'operator-algebras', 'spectral-theory', 'banach-algebras']"
7,What functions can be represented as a series of eigenfunctions,What functions can be represented as a series of eigenfunctions,,"Consider the differential equation: $y'' = \lambda y$ with the boundary conditions $y(0) = y(2\pi) = 0$ . This equation has eigenfunctions $\mu_n(x) = \sin(\frac{nx}{2})$ with the corresponding eigenvalues $\lambda_n = -\frac{n^2}{4}$ for $n > 0$ Am I right, that certain functions f(x) satisfying the same boundary conditions as above can be represented as an infinite series $f(x) = \sum_1^\infty c_n \mu_n(x)$ with coefficients $c_n = \frac{\langle f,\mu_n \rangle}{\langle \mu_n, \mu_n \rangle}$ ? What conditions those certain functions need to satisfy? Can the previous claim be generalised for any set of eigenfunctions of some differential equation? I.E. suppose $Ly = \lambda y$ is a differential equation ( $L$ being the 2nd order differential operator) with boundary conditions $y(a) = y(b) = c$ . What functions can be represented as a weighted sum of the eigensolutions?","Consider the differential equation: with the boundary conditions . This equation has eigenfunctions with the corresponding eigenvalues for Am I right, that certain functions f(x) satisfying the same boundary conditions as above can be represented as an infinite series with coefficients ? What conditions those certain functions need to satisfy? Can the previous claim be generalised for any set of eigenfunctions of some differential equation? I.E. suppose is a differential equation ( being the 2nd order differential operator) with boundary conditions . What functions can be represented as a weighted sum of the eigensolutions?","y'' = \lambda y y(0) = y(2\pi) = 0 \mu_n(x) = \sin(\frac{nx}{2}) \lambda_n = -\frac{n^2}{4} n > 0 f(x) = \sum_1^\infty c_n \mu_n(x) c_n = \frac{\langle f,\mu_n \rangle}{\langle \mu_n, \mu_n \rangle} Ly = \lambda y L y(a) = y(b) = c","['functional-analysis', 'ordinary-differential-equations', 'fourier-series', 'eigenfunctions']"
8,Necessary and sufficient condition for two complete norms to be equivalent,Necessary and sufficient condition for two complete norms to be equivalent,,"Let $E$ be a normed vector space with two complete norms $\left \|\cdot \right \|_1$ and $\left \|\cdot \right \|_2$ . Prove that those norms are equivalent if and only if every Cauchy sequence with respect to one norm is also Cauchy with respect to the other. We only have to prove that $\text{id}:\left (E,\left \|\cdot \right \|_1\right )\to \left (E,\left \|\cdot \right \|_2\right )$ is continuous. Since both spaces are Banach, the open mapping theorem will guarantee that $\text{id}$ is a homeomorphism, and therefore the norms will be equivalent. So, I thought of closed graph. Suppose that there is a sequence $x_n$ which tends to $x$ in $\left \|\cdot \right \|_1$ , and $x_n=\text{id}(x_n)$ tends to $y$ in $\left \|\cdot \right \|_2$ . We want $y=\text{id}(x)=x$ . But this is not true in general: Banach space with respect to two norms must be Banach wrt the sum of the norms? Presumably the problem is that the example given previously does not satisfy the strong statement: ""for every Cauchy sequence with respect to one norm, is also Cauchy with respect to the other"". There is a suggestion: If $(a_n)_n\subset \mathbb{R}$ tends to $0$ , then there exists another sequence $(\varepsilon_n)_n\subset \mathbb{R}_{>0}$ such that $\varepsilon_n\to +\infty$ but $\varepsilon_na_n\to 0$ . But I cannot see how to make use of it. How would you solve the exercise? EDIT : This post has been marked as a duplicate, but I think that in an unfair way. The question equivalence of two definitions of norm equivalence: ""$|\cdot|_1=|\cdot|_2^\alpha$"" vs. ""being a Cauchy sequence is the same for both norms"" makes use of a knowledge that is more advanced with respect to the simpler knowledge that I am using here. I did not understand what they were talking about because I do not know anything about p-adic Analysis. Moreover, they use definitions of norm-equivalence that I am not familiarized with. This is an exercise given on a more basic subject, and our professors are no way interested on a solution like the one given in that post (providing that it really solves my problem, which I cannot assert since I do not understand it).","Let be a normed vector space with two complete norms and . Prove that those norms are equivalent if and only if every Cauchy sequence with respect to one norm is also Cauchy with respect to the other. We only have to prove that is continuous. Since both spaces are Banach, the open mapping theorem will guarantee that is a homeomorphism, and therefore the norms will be equivalent. So, I thought of closed graph. Suppose that there is a sequence which tends to in , and tends to in . We want . But this is not true in general: Banach space with respect to two norms must be Banach wrt the sum of the norms? Presumably the problem is that the example given previously does not satisfy the strong statement: ""for every Cauchy sequence with respect to one norm, is also Cauchy with respect to the other"". There is a suggestion: If tends to , then there exists another sequence such that but . But I cannot see how to make use of it. How would you solve the exercise? EDIT : This post has been marked as a duplicate, but I think that in an unfair way. The question equivalence of two definitions of norm equivalence: ""$|\cdot|_1=|\cdot|_2^\alpha$"" vs. ""being a Cauchy sequence is the same for both norms"" makes use of a knowledge that is more advanced with respect to the simpler knowledge that I am using here. I did not understand what they were talking about because I do not know anything about p-adic Analysis. Moreover, they use definitions of norm-equivalence that I am not familiarized with. This is an exercise given on a more basic subject, and our professors are no way interested on a solution like the one given in that post (providing that it really solves my problem, which I cannot assert since I do not understand it).","E \left \|\cdot \right \|_1 \left \|\cdot \right \|_2 \text{id}:\left (E,\left \|\cdot \right \|_1\right )\to \left (E,\left \|\cdot \right \|_2\right ) \text{id} x_n x \left \|\cdot \right \|_1 x_n=\text{id}(x_n) y \left \|\cdot \right \|_2 y=\text{id}(x)=x (a_n)_n\subset \mathbb{R} 0 (\varepsilon_n)_n\subset \mathbb{R}_{>0} \varepsilon_n\to +\infty \varepsilon_na_n\to 0","['functional-analysis', 'continuity', 'banach-spaces', 'normed-spaces']"
9,Is a harmonic function in $L^p(\mathbb{R}^2)$ equal to zero?,Is a harmonic function in  equal to zero?,L^p(\mathbb{R}^2),"Let $u :\mathbb{R}^2 \to \mathbb{R}$ be a smooth harmonic function ($\Delta u = 0$). Furthermore, suppose that $u \in L^p(\mathbb{R}^2)$, with $1 < p < \infty$. Does it follow that $u = 0$ everywhere? By the theorem of Liouville, this follows immediately if $u \in L^\infty(\mathbb{R}^2)$. For $u \in L^p(\mathbb{R}^2)$, this would also follow if we knew that $u$, for example, is uniformly continuous ($u$ is necessarily unbounded, find a sequence of points $x_k$ such that $u(x_k) \to \infty$, and apply the definition of uniform continuity in a neighbourhood of those points to get a contradiction with $u \in L^p(\mathbb{R}^2)$). The enemy seems therefore higher and narrower ``spikes'' going off to infinity. Any help would be much appreciated!","Let $u :\mathbb{R}^2 \to \mathbb{R}$ be a smooth harmonic function ($\Delta u = 0$). Furthermore, suppose that $u \in L^p(\mathbb{R}^2)$, with $1 < p < \infty$. Does it follow that $u = 0$ everywhere? By the theorem of Liouville, this follows immediately if $u \in L^\infty(\mathbb{R}^2)$. For $u \in L^p(\mathbb{R}^2)$, this would also follow if we knew that $u$, for example, is uniformly continuous ($u$ is necessarily unbounded, find a sequence of points $x_k$ such that $u(x_k) \to \infty$, and apply the definition of uniform continuity in a neighbourhood of those points to get a contradiction with $u \in L^p(\mathbb{R}^2)$). The enemy seems therefore higher and narrower ``spikes'' going off to infinity. Any help would be much appreciated!",,"['functional-analysis', 'partial-differential-equations', 'harmonic-functions']"
10,"On a manifold, is the $L^p$ space of vector fields complete?","On a manifold, is the  space of vector fields complete?",L^p,"If $(M,g)$ is a Riemannian manifold, let $\mathcal L^p(M)$ denote the set of vector fields $X$ whose norm $|X|$ is an $L^p(M)$ function. Is this complete? The usual proof fails miserably because of off-diagonal terms in the metric.","If $(M,g)$ is a Riemannian manifold, let $\mathcal L^p(M)$ denote the set of vector fields $X$ whose norm $|X|$ is an $L^p(M)$ function. Is this complete? The usual proof fails miserably because of off-diagonal terms in the metric.",,"['functional-analysis', 'partial-differential-equations', 'differential-topology', 'riemannian-geometry', 'lp-spaces']"
11,Why is the spectrum of an operator with compact resolvent countable and consists only of eigenvalues?,Why is the spectrum of an operator with compact resolvent countable and consists only of eigenvalues?,,"I'm trying to prove the following statement. Let $\mathcal H$ be a Hilbert space and $T: D \rightarrow \mathcal H$, $D \subset \mathcal H$, a linear operator. Let $\lambda_0 \in \rho(T)$ such that $(T - \lambda_0)^{-1}$ is a compact operator. Then $(T-\lambda)^{-1}$ is compact for each $\lambda \in \rho(T)$, $\sigma(T)$ consists only of a countable number of eigenvalues and doesn't have a limit point in $\mathbb C$. It was said that this follows from well known facts about the spectral theory of compact operators. Now, the notable facts that I recall are: (let $K$ be a compact operator) each non-zero spectral value of $K$ is also an eigenvalue, for non-zero eigenvalues of $K$, the dimension of their eigenspace is finite, $\sigma(K)$ is countable and its only limit point is 0. Unfortunately, I'm unable to cook up the desired conclusion from those properties alone. So I guess there is some missing link here. Can someone point me into the right direction?","I'm trying to prove the following statement. Let $\mathcal H$ be a Hilbert space and $T: D \rightarrow \mathcal H$, $D \subset \mathcal H$, a linear operator. Let $\lambda_0 \in \rho(T)$ such that $(T - \lambda_0)^{-1}$ is a compact operator. Then $(T-\lambda)^{-1}$ is compact for each $\lambda \in \rho(T)$, $\sigma(T)$ consists only of a countable number of eigenvalues and doesn't have a limit point in $\mathbb C$. It was said that this follows from well known facts about the spectral theory of compact operators. Now, the notable facts that I recall are: (let $K$ be a compact operator) each non-zero spectral value of $K$ is also an eigenvalue, for non-zero eigenvalues of $K$, the dimension of their eigenspace is finite, $\sigma(K)$ is countable and its only limit point is 0. Unfortunately, I'm unable to cook up the desired conclusion from those properties alone. So I guess there is some missing link here. Can someone point me into the right direction?",,"['functional-analysis', 'hilbert-spaces', 'spectral-theory', 'compact-operators']"
12,Is $X^*$ complete with weak*-topology,Is  complete with weak*-topology,X^*,"Suppose $X$ is a topological vector space, $X^*$ is its topological dual space. Let the topology of $X^*$ is weak*-topology, Is $X^*$ complete? Suppose $f_s$ is a Cauchy net in $X^*$, it is easy to see that $f=\lim f_s$ exists. We can prove that $f$ is linear, but I couldn't see if it is continuous.","Suppose $X$ is a topological vector space, $X^*$ is its topological dual space. Let the topology of $X^*$ is weak*-topology, Is $X^*$ complete? Suppose $f_s$ is a Cauchy net in $X^*$, it is easy to see that $f=\lim f_s$ exists. We can prove that $f$ is linear, but I couldn't see if it is continuous.",,['functional-analysis']
13,Proving the range of operator is closed,Proving the range of operator is closed,,"I have a hard time understand (2) of the Fredholm alternative in Evan's Appendix. To prove the image of $I-K$ is closed, what result from functional analysis is used? I am lost in understand the first sentence of the proof, up to equation (4). Could anyone explain to me what result in functional analysis is used? Which section in the relevant part of any functional analysis one shall study for? I believe that the result, i.e.  ""The range of $K$ is closed iff there exists a constant $c>0$ such that $\|Kx\|\ge c\|x\|$ for all $x\in X$ ($K$ is bounded below) is used. But I do not know if so, and where does this result come from, in functional analysis text. Please help.","I have a hard time understand (2) of the Fredholm alternative in Evan's Appendix. To prove the image of $I-K$ is closed, what result from functional analysis is used? I am lost in understand the first sentence of the proof, up to equation (4). Could anyone explain to me what result in functional analysis is used? Which section in the relevant part of any functional analysis one shall study for? I believe that the result, i.e.  ""The range of $K$ is closed iff there exists a constant $c>0$ such that $\|Kx\|\ge c\|x\|$ for all $x\in X$ ($K$ is bounded below) is used. But I do not know if so, and where does this result come from, in functional analysis text. Please help.",,"['functional-analysis', 'partial-differential-equations', 'regularity-theory-of-pdes']"
14,Prove of inequality under a Hilbert space.,Prove of inequality under a Hilbert space.,,"Let $x\neq y$ when $x,y\in H$ and H is a Hilbert space which satisfy $\|x\|=\|y\|=r$. Show that $\|\frac{x+y}{2}\|<r$. Actually in my question r=1 but as far as i could understand there is a way to prove this for any r. Is this true? I tried to go with showing that $\|tx+(1-t)y\|<r$ where $t=\frac{1}{2}$ to no avail. Am I in a good direction? can someone point out the trick?","Let $x\neq y$ when $x,y\in H$ and H is a Hilbert space which satisfy $\|x\|=\|y\|=r$. Show that $\|\frac{x+y}{2}\|<r$. Actually in my question r=1 but as far as i could understand there is a way to prove this for any r. Is this true? I tried to go with showing that $\|tx+(1-t)y\|<r$ where $t=\frac{1}{2}$ to no avail. Am I in a good direction? can someone point out the trick?",,"['functional-analysis', 'hilbert-spaces', 'normed-spaces']"
15,Not unique Hahn Banach extension,Not unique Hahn Banach extension,,"$G = \{(x_n) \in l_1: x_{2n+1} = 0, \forall n \in \mathbb{N} \}$ Let $f: G \to \mathbb{K}$ be a continuous linear functional, $f \neq 0$. Show that the Hahn Banach extension of $f$  is not unique. My attempt Let $g: l_1 \to \mathbb{K}$ be the Hahn Banach extension of $f$. We have: $$g(x_1,x_2,x_3,x_4, \cdots)= g(x_1,0,x_3,0, \cdots) + g(0,x_2,0,x_4, \cdots) =  g(x_1,0,x_3,0, \cdots) + f(0,x_2,0,x_4, \cdots) = \sum_{n=0}^{\infty} g(e_{2n+1})x_{2n+1} + f(0,x_2,0,x_4, \cdots) $$ I realised the following: if $g(e_{2n+1}) = 0, \forall n \geq 1$ and $g(e_1) = \|f\|$, then  $|g(e_n)| \leq \|f\| , \forall n \geq 0$ and $$\|g\| = \sup |g(e_n)| = \|f\|$$ Now, if  $g(e_{2n+1}) = 0, \forall n \geq 0, n \neq 1,$ and $g(e_3) = \|f\|$, then  $|g(e_n)| \leq \|f\| , \forall n \geq 0$ and $$\|g\| = \sup |g(e_n)| = \|f\|$$ Thus $g$ has at least two Hahn Banach extensions. Am I right?","$G = \{(x_n) \in l_1: x_{2n+1} = 0, \forall n \in \mathbb{N} \}$ Let $f: G \to \mathbb{K}$ be a continuous linear functional, $f \neq 0$. Show that the Hahn Banach extension of $f$  is not unique. My attempt Let $g: l_1 \to \mathbb{K}$ be the Hahn Banach extension of $f$. We have: $$g(x_1,x_2,x_3,x_4, \cdots)= g(x_1,0,x_3,0, \cdots) + g(0,x_2,0,x_4, \cdots) =  g(x_1,0,x_3,0, \cdots) + f(0,x_2,0,x_4, \cdots) = \sum_{n=0}^{\infty} g(e_{2n+1})x_{2n+1} + f(0,x_2,0,x_4, \cdots) $$ I realised the following: if $g(e_{2n+1}) = 0, \forall n \geq 1$ and $g(e_1) = \|f\|$, then  $|g(e_n)| \leq \|f\| , \forall n \geq 0$ and $$\|g\| = \sup |g(e_n)| = \|f\|$$ Now, if  $g(e_{2n+1}) = 0, \forall n \geq 0, n \neq 1,$ and $g(e_3) = \|f\|$, then  $|g(e_n)| \leq \|f\| , \forall n \geq 0$ and $$\|g\| = \sup |g(e_n)| = \|f\|$$ Thus $g$ has at least two Hahn Banach extensions. Am I right?",,"['functional-analysis', 'banach-spaces']"
16,"Given: self-adjoint, monotonic increasing sequence in $L(H)$ such that $\|T_n\|<C$. Why converges $(T_n)$ strongly to a self-adjoint $T\in L(H)$?","Given: self-adjoint, monotonic increasing sequence in  such that . Why converges  strongly to a self-adjoint ?",L(H) \|T_n\|<C (T_n) T\in L(H),"Let $H$ be a Hilbert space, $(T_n)\subseteq L(H)$ a sequence such that $T_n^\ast=T_n$ and $T_n\le T_{n+1}$ for all $n\in \mathbb{N}$. There exists a constant $C>0$ such that $\|T_n\|<C$ for all $n\in\mathbb{N}$. The claim is: then there exists a $T\in L(H)$ such that $T=T^*$ and such that $T_n\to T$ strong, $n\to\infty$. I stuck a little bit. My try: Let $n\in\mathbb{N}$. $T_n$ self-adjoint implies, that $\langle T_nx,x\rangle\in\mathbb{R}$ for all $n\in\mathbb{R}$, $x\in H$. So, the sequence $(\langle T_nx,x\rangle )$ is a real sequence which is monotonic increasing, because $\langle T_nx,x\rangle\le \langle T_{n+1}x,x\rangle$ for all $n\in\mathbb{N}$, and the sequence is bounded, because $|\langle T_nx,x\rangle |\le \|T_nx\|\|x\|\le C\|x\|^2$ for all $x\in H$. Therefore $(\langle T_nx,x\rangle )$ is convergent in $\mathbb{R}$. Now, how to continue? The next step I made is to prove that $(\langle T_nx,y\rangle )$ is convergent for all $x,y\in H$ with the polarization identity, but I did it wrong.. Could anybody help me to prove this, that $(\langle T_nx,y\rangle )$ is convergent for all $x,y\in H$ in $\mathbb{R}$? What I did next, if we know that $\lim\limits_{n\to\infty}\langle T_nx,y\rangle =:F(x,y)\in \mathbb{R}$ exists: It is $|F(x,y)|=\lim\limits_{n\to\infty}|\langle T_nx,y\rangle|\le C\|x\|\|y\|$ for all $x,y\in H$, therefore $$F_x:H\to\mathbb{C},\; y\mapsto \overline{F(x,y)}$$is a linear, bounded functional. The Riesz-Representationtheorem gives us, that there exists $Tx\in H$ such that $F_x(y)=\langle y,Tx\rangle=\overline{F(x,y)}$. If you conjugate both sides, we obtain $F(x,y)=\langle Tx,y\rangle$ for all $x,y\in H$. Then I proved that $T$ is linear and bounded and that $T$ is self-adjoint, there was no problem. But how to prove $\|T_nx-Tx\|\to 0$ for all $x\in H$, $n\to\infty$? But if you know an other proof, let me know it. I hope I did no mistakes. Regards Edit: My try with the polarization identity $\langle x,y\rangle =\frac{1}{4}(\|x+y\|^2-\|x-y\|^2+i\|x+iy\|^2-i\|x-iy\|^2)$ for $x,y$ of a complex Hilbert space $H$:  $\forall n\in\mathbb{N}$, $x,y\in H$, it is : $\langle T_nx,y\rangle =\frac{1}{4}(\|T_nx+y\|^2-\|T_nx-y\|^2)+\frac{i}{4}(\|T_nx+iy\|^2-\|T_nx-iy\|^2)=\frac{1}{4}(\langle T_nx+y,T_nx+y\rangle-\langle T_nx-y,T_nx-y\rangle)+\frac{i}{4}(\langle T_nx+iy,T_nx+iy\rangle-\langle T_nx-iy,T_nx-iy\rangle)$. Can I argue now, that all the summands converge, because $(\langle T_nx,x\rangle )$ converges for all $x\in H$?","Let $H$ be a Hilbert space, $(T_n)\subseteq L(H)$ a sequence such that $T_n^\ast=T_n$ and $T_n\le T_{n+1}$ for all $n\in \mathbb{N}$. There exists a constant $C>0$ such that $\|T_n\|<C$ for all $n\in\mathbb{N}$. The claim is: then there exists a $T\in L(H)$ such that $T=T^*$ and such that $T_n\to T$ strong, $n\to\infty$. I stuck a little bit. My try: Let $n\in\mathbb{N}$. $T_n$ self-adjoint implies, that $\langle T_nx,x\rangle\in\mathbb{R}$ for all $n\in\mathbb{R}$, $x\in H$. So, the sequence $(\langle T_nx,x\rangle )$ is a real sequence which is monotonic increasing, because $\langle T_nx,x\rangle\le \langle T_{n+1}x,x\rangle$ for all $n\in\mathbb{N}$, and the sequence is bounded, because $|\langle T_nx,x\rangle |\le \|T_nx\|\|x\|\le C\|x\|^2$ for all $x\in H$. Therefore $(\langle T_nx,x\rangle )$ is convergent in $\mathbb{R}$. Now, how to continue? The next step I made is to prove that $(\langle T_nx,y\rangle )$ is convergent for all $x,y\in H$ with the polarization identity, but I did it wrong.. Could anybody help me to prove this, that $(\langle T_nx,y\rangle )$ is convergent for all $x,y\in H$ in $\mathbb{R}$? What I did next, if we know that $\lim\limits_{n\to\infty}\langle T_nx,y\rangle =:F(x,y)\in \mathbb{R}$ exists: It is $|F(x,y)|=\lim\limits_{n\to\infty}|\langle T_nx,y\rangle|\le C\|x\|\|y\|$ for all $x,y\in H$, therefore $$F_x:H\to\mathbb{C},\; y\mapsto \overline{F(x,y)}$$is a linear, bounded functional. The Riesz-Representationtheorem gives us, that there exists $Tx\in H$ such that $F_x(y)=\langle y,Tx\rangle=\overline{F(x,y)}$. If you conjugate both sides, we obtain $F(x,y)=\langle Tx,y\rangle$ for all $x,y\in H$. Then I proved that $T$ is linear and bounded and that $T$ is self-adjoint, there was no problem. But how to prove $\|T_nx-Tx\|\to 0$ for all $x\in H$, $n\to\infty$? But if you know an other proof, let me know it. I hope I did no mistakes. Regards Edit: My try with the polarization identity $\langle x,y\rangle =\frac{1}{4}(\|x+y\|^2-\|x-y\|^2+i\|x+iy\|^2-i\|x-iy\|^2)$ for $x,y$ of a complex Hilbert space $H$:  $\forall n\in\mathbb{N}$, $x,y\in H$, it is : $\langle T_nx,y\rangle =\frac{1}{4}(\|T_nx+y\|^2-\|T_nx-y\|^2)+\frac{i}{4}(\|T_nx+iy\|^2-\|T_nx-iy\|^2)=\frac{1}{4}(\langle T_nx+y,T_nx+y\rangle-\langle T_nx-y,T_nx-y\rangle)+\frac{i}{4}(\langle T_nx+iy,T_nx+iy\rangle-\langle T_nx-iy,T_nx-iy\rangle)$. Can I argue now, that all the summands converge, because $(\langle T_nx,x\rangle )$ converges for all $x\in H$?",,['functional-analysis']
17,"Every closed subspace of ${\scr C}^0[a,b]$ of continuously differentiable functions must have finite dimension.",Every closed subspace of  of continuously differentiable functions must have finite dimension.,"{\scr C}^0[a,b]","If $F \subset {\scr C}^1[a,b] \subset {\scr C}^0[a,b]$, then $\dim F < +\infty,$ where $F$ is a closed subspace (in $ {\scr C}^0[a,b]$). I found this answer , which is very good and solves the problem, but how can we prove the assertion without using Ascoli-Arzelà in the end? We didn't cover equicontinuity, etc. Is there a more elementary proof of the result?","If $F \subset {\scr C}^1[a,b] \subset {\scr C}^0[a,b]$, then $\dim F < +\infty,$ where $F$ is a closed subspace (in $ {\scr C}^0[a,b]$). I found this answer , which is very good and solves the problem, but how can we prove the assertion without using Ascoli-Arzelà in the end? We didn't cover equicontinuity, etc. Is there a more elementary proof of the result?",,"['analysis', 'functional-analysis', 'banach-spaces']"
18,Why is $\partial_z\partial_{\bar z}=\frac14\left(\partial_r^2+\frac1r\partial_r+\frac1{r^2}\partial_{\theta}^2\right)$?,Why is ?,\partial_z\partial_{\bar z}=\frac14\left(\partial_r^2+\frac1r\partial_r+\frac1{r^2}\partial_{\theta}^2\right),"I have to show the identity I wrote in the title: it should be $\partial_z\partial_{\bar z}=\frac14\left(\partial_r^2+\frac1r\partial_r+\frac1{r^2}\partial_{\theta}^2\right)$ but some computation doesn't match with my book with these operators. We know that $\partial_z\partial_{\bar z}=\frac14(\partial_x^2+\partial_y^2)$. Then we pass to polar coordinates writing $x=r\cos\theta$ and $y=r\sin\theta$, from which, obviously we have $r=\sqrt{x^2+y^2}$ and $\theta=\arctan\frac yx$. We use than the chain rule to write $$ \partial_x=\frac{\partial r}{\partial x}\partial_r+\frac{\partial\theta}{\partial x}\partial_{\theta}=\cos\theta\partial_r-\frac{\sin\theta}{r}\partial_{\theta} $$ and $$ \partial_y=\frac{\partial r}{\partial y}\partial_r+\frac{\partial\theta}{\partial y}\partial_{\theta}=\sin\theta\partial_r+\frac{\cos\theta}{r}\partial_{\theta} $$ and till here all matches with my book. My problem comes now: I used the above cited $\partial_z\partial_{\bar z}=\frac14(\partial_x^2+\partial_y^2)$ but this gives me  $$ \partial_z\partial_{\bar z}=\frac14\left(\partial_r^2+\frac1{r^2}\partial_{\theta}^2\right) $$ because the ""crossed"" terms are equal and opposite: squaring $\partial_x$ the ""crossed"" term is $-\frac2r\cos\theta\sin\theta\partial_r\partial_{\theta}$, squaring $\partial_y$ the ""crossed"" term is $\frac2r\cos\theta\sin\theta\partial_r\partial_{\theta}$ hence in the sum they should vanish. Where is the error? EDIT: following Andrea's suggest, I wrote \begin{align*} \partial_x^2+\partial_y^2 &=\left(\cos\theta\partial_r-\frac{\sin\theta}{r}\partial_{\theta}\right)\left(\cos\theta\partial_r-\frac{\sin\theta}{r}\partial_{\theta}\right)+\\ &\;\;\;\;\;\,\left(\sin\theta\partial_r+\frac{\cos\theta}{r}\partial_{\theta}\right) \left(\sin\theta\partial_r+\frac{\cos\theta}{r}\partial_{\theta}\right)\\ &=\cos^2\theta\partial_r^2+\frac{\sin\theta}{r}\cos\theta\partial_{\theta} +\frac{\sin^2}{r}\partial_r+\cos\theta\frac{\sin\theta}{r^2}\partial_\theta+\\ &\;\;\;\;\;\;\sin^2\theta\partial_r^2-\frac{\cos\theta}{r}\sin\theta\partial_{\theta} +\frac{\cos^2}{r}\partial_r-\sin\theta\frac{\cos\theta}{r^2}\partial_\theta\\ =&\partial_r^2+\frac1r\partial_r \end{align*} which is false again! I checked several times but I cannot find where my mistake is! Many thanks!","I have to show the identity I wrote in the title: it should be $\partial_z\partial_{\bar z}=\frac14\left(\partial_r^2+\frac1r\partial_r+\frac1{r^2}\partial_{\theta}^2\right)$ but some computation doesn't match with my book with these operators. We know that $\partial_z\partial_{\bar z}=\frac14(\partial_x^2+\partial_y^2)$. Then we pass to polar coordinates writing $x=r\cos\theta$ and $y=r\sin\theta$, from which, obviously we have $r=\sqrt{x^2+y^2}$ and $\theta=\arctan\frac yx$. We use than the chain rule to write $$ \partial_x=\frac{\partial r}{\partial x}\partial_r+\frac{\partial\theta}{\partial x}\partial_{\theta}=\cos\theta\partial_r-\frac{\sin\theta}{r}\partial_{\theta} $$ and $$ \partial_y=\frac{\partial r}{\partial y}\partial_r+\frac{\partial\theta}{\partial y}\partial_{\theta}=\sin\theta\partial_r+\frac{\cos\theta}{r}\partial_{\theta} $$ and till here all matches with my book. My problem comes now: I used the above cited $\partial_z\partial_{\bar z}=\frac14(\partial_x^2+\partial_y^2)$ but this gives me  $$ \partial_z\partial_{\bar z}=\frac14\left(\partial_r^2+\frac1{r^2}\partial_{\theta}^2\right) $$ because the ""crossed"" terms are equal and opposite: squaring $\partial_x$ the ""crossed"" term is $-\frac2r\cos\theta\sin\theta\partial_r\partial_{\theta}$, squaring $\partial_y$ the ""crossed"" term is $\frac2r\cos\theta\sin\theta\partial_r\partial_{\theta}$ hence in the sum they should vanish. Where is the error? EDIT: following Andrea's suggest, I wrote \begin{align*} \partial_x^2+\partial_y^2 &=\left(\cos\theta\partial_r-\frac{\sin\theta}{r}\partial_{\theta}\right)\left(\cos\theta\partial_r-\frac{\sin\theta}{r}\partial_{\theta}\right)+\\ &\;\;\;\;\;\,\left(\sin\theta\partial_r+\frac{\cos\theta}{r}\partial_{\theta}\right) \left(\sin\theta\partial_r+\frac{\cos\theta}{r}\partial_{\theta}\right)\\ &=\cos^2\theta\partial_r^2+\frac{\sin\theta}{r}\cos\theta\partial_{\theta} +\frac{\sin^2}{r}\partial_r+\cos\theta\frac{\sin\theta}{r^2}\partial_\theta+\\ &\;\;\;\;\;\;\sin^2\theta\partial_r^2-\frac{\cos\theta}{r}\sin\theta\partial_{\theta} +\frac{\cos^2}{r}\partial_r-\sin\theta\frac{\cos\theta}{r^2}\partial_\theta\\ =&\partial_r^2+\frac1r\partial_r \end{align*} which is false again! I checked several times but I cannot find where my mistake is! Many thanks!",,"['complex-analysis', 'functional-analysis', 'operator-theory', 'coordinate-systems']"
19,Gelfand Naimark Theorem,Gelfand Naimark Theorem,,"The commutative Gelfand-Naimark theorem tells us that every unital commutative C* algebra is isometrically isomorphic to the space of continuous functions on its maximal ideal space. The non- commutative GNS construction, on the other hand, tells us that every C* algebra is isometrically embedded into a * subalgebra of $\mathfrak{B}(\mathbb{H})$ for some Hilbert space $\mathbb{H}$. My question is the following: how does the commutative case fit into the non commutative one? I could see that given a commutative C* algebra $C(X)$, where $X$ is a locally compact Hausdorff space, one can find a non zero positive linear functional $F$ on $C(X)$ such that $F(e)=1$, where $e$ is the identity function on $C(X)$. Then using Riesz Representation theorem, one can find a corresponding Borel $\sigma$ algebra on $X$ and a unique probability measure $\mu$ such that $F(f)=  \int f\,d\mu \quad \forall f\in C(X)$. From here it is easy to deduce that $C(X)$ is isometrically embedded into a * subalgebra of $\mathfrak{B}(\mathcal{L^2}(X,\mu))$ via multiplication operators. My question is: Is there a canonical way of finding such a probability measure? Clearly if we choose a different positive linear functional, we get a different probability measure. So is there some unique/ natural way of doing this? Also, is this where the Hahn-Hellinger theorem comes in? I would be grateful for some clarity on this, and also references if possible.","The commutative Gelfand-Naimark theorem tells us that every unital commutative C* algebra is isometrically isomorphic to the space of continuous functions on its maximal ideal space. The non- commutative GNS construction, on the other hand, tells us that every C* algebra is isometrically embedded into a * subalgebra of $\mathfrak{B}(\mathbb{H})$ for some Hilbert space $\mathbb{H}$. My question is the following: how does the commutative case fit into the non commutative one? I could see that given a commutative C* algebra $C(X)$, where $X$ is a locally compact Hausdorff space, one can find a non zero positive linear functional $F$ on $C(X)$ such that $F(e)=1$, where $e$ is the identity function on $C(X)$. Then using Riesz Representation theorem, one can find a corresponding Borel $\sigma$ algebra on $X$ and a unique probability measure $\mu$ such that $F(f)=  \int f\,d\mu \quad \forall f\in C(X)$. From here it is easy to deduce that $C(X)$ is isometrically embedded into a * subalgebra of $\mathfrak{B}(\mathcal{L^2}(X,\mu))$ via multiplication operators. My question is: Is there a canonical way of finding such a probability measure? Clearly if we choose a different positive linear functional, we get a different probability measure. So is there some unique/ natural way of doing this? Also, is this where the Hahn-Hellinger theorem comes in? I would be grateful for some clarity on this, and also references if possible.",,"['functional-analysis', 'operator-algebras']"
20,Counterexample for the stability of orthogonal projections,Counterexample for the stability of orthogonal projections,,"Let $V$ be a seperable Banach space, which is dense and continuously embedded in a Hilbert Space $H$. Let $(V_m)$ be a Galerkin scheme (See definition below) for $V$. Using the embedding we can regard the $(V_m)$ as subspaces of $H$. Then let $(P_m)$ be the orthogonal projections onto $(V_m)$. Using the embedding again, we can regard those as Operators in $V$. For certain choices of $V, H, (V_m)$ one can prove, that the series of orthogonal projections is stable in $V$. This means, that there is a constant $C$ such that $$||P_m || = \sup_{x \in V\backslash\{0\}} \frac{||P_m(x)||}{||x||} \leq C \ .$$ Proves for certain choices of $V,H,(V_m)$ can be found for example in a Paper of M. Crouzeix and V. Thomée ($V=L_p, H=L_2$) and more recently in a Paper of E. Emmrich and D. Siska (See Remark 3.8. and Lemma 4.2). Being fairly new to this subject, I am trying to figure out, why this property should not allways hold. So my question is if anyone can think of a nice counterexample, i.e. a set $V, H, (V_m)$ for which the property is not fullfilled. Update Definition of a Galerkin scheme Let $(V, || \cdot||)$, be a Banach space. A Galerkin scheme is a series $\{V_m\}$ of finite dimensional subspaces $V_m \subset V$ that fullfills $$\lim_{m \rightarrow \infty} \text{dist}(v,V_m) \rightarrow 0 \qquad \forall v \in V$$ Where the distance is defined as $$\text{dist}(v,V_m) := \inf_{w \in V_m} ||v-w||$$","Let $V$ be a seperable Banach space, which is dense and continuously embedded in a Hilbert Space $H$. Let $(V_m)$ be a Galerkin scheme (See definition below) for $V$. Using the embedding we can regard the $(V_m)$ as subspaces of $H$. Then let $(P_m)$ be the orthogonal projections onto $(V_m)$. Using the embedding again, we can regard those as Operators in $V$. For certain choices of $V, H, (V_m)$ one can prove, that the series of orthogonal projections is stable in $V$. This means, that there is a constant $C$ such that $$||P_m || = \sup_{x \in V\backslash\{0\}} \frac{||P_m(x)||}{||x||} \leq C \ .$$ Proves for certain choices of $V,H,(V_m)$ can be found for example in a Paper of M. Crouzeix and V. Thomée ($V=L_p, H=L_2$) and more recently in a Paper of E. Emmrich and D. Siska (See Remark 3.8. and Lemma 4.2). Being fairly new to this subject, I am trying to figure out, why this property should not allways hold. So my question is if anyone can think of a nice counterexample, i.e. a set $V, H, (V_m)$ for which the property is not fullfilled. Update Definition of a Galerkin scheme Let $(V, || \cdot||)$, be a Banach space. A Galerkin scheme is a series $\{V_m\}$ of finite dimensional subspaces $V_m \subset V$ that fullfills $$\lim_{m \rightarrow \infty} \text{dist}(v,V_m) \rightarrow 0 \qquad \forall v \in V$$ Where the distance is defined as $$\text{dist}(v,V_m) := \inf_{w \in V_m} ||v-w||$$",,"['functional-analysis', 'banach-spaces', 'hilbert-spaces']"
21,Relation between noncommutative geometry and functional analysis,Relation between noncommutative geometry and functional analysis,,"Recently I came across the subject of noncommutative geometry via my interest in functional analysis. My very little exposure to this subject gives me a sense that part of it is built on the theory of operator algebras and that together with many other tools/techniques are used to study geometric or topological problems. I couldn't help but ask (perhaps naively) whether things can go the other way, i.e. using tools in noncommutative geometry to study operator algebras (or even other objects that one would associate to functional analysis, such as operator spaces etc.). If anyone knows of such an approach, I would appreciate some descriptions or references.","Recently I came across the subject of noncommutative geometry via my interest in functional analysis. My very little exposure to this subject gives me a sense that part of it is built on the theory of operator algebras and that together with many other tools/techniques are used to study geometric or topological problems. I couldn't help but ask (perhaps naively) whether things can go the other way, i.e. using tools in noncommutative geometry to study operator algebras (or even other objects that one would associate to functional analysis, such as operator spaces etc.). If anyone knows of such an approach, I would appreciate some descriptions or references.",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'noncommutative-geometry']"
22,equivalence of norms,equivalence of norms,,"I would like a little help here: I have two defined norms over $C^{1}([0,1])$ : $\| A(f)\|=|f(0)|+\max_{x\in[0,1]}{|f'(x)|}$ $\| B(f)\|=\int_0^1|f(x)|dx+\max_{x\in[0,1]}{|f'(x)|}$ I already proved that $A,B$ are norms over $C^{1}([0,1])$ by showing that the usual axioms hold: zero vector has norm $0$, positive homogeneity and the triangle inequality (if it's not complete tell me please). The last thing that I need to show is the equivalence of those norms. How am I to do it? Thanks","I would like a little help here: I have two defined norms over $C^{1}([0,1])$ : $\| A(f)\|=|f(0)|+\max_{x\in[0,1]}{|f'(x)|}$ $\| B(f)\|=\int_0^1|f(x)|dx+\max_{x\in[0,1]}{|f'(x)|}$ I already proved that $A,B$ are norms over $C^{1}([0,1])$ by showing that the usual axioms hold: zero vector has norm $0$, positive homogeneity and the triangle inequality (if it's not complete tell me please). The last thing that I need to show is the equivalence of those norms. How am I to do it? Thanks",,"['functional-analysis', 'functions', 'normed-spaces']"
23,Norm equivalence Sobolev space,Norm equivalence Sobolev space,,"I have this problem: Let $k>0$ (integer) and $1 \leq p < \infty$. Show that the norms $$ \|u\|_{W^{k,p}(U)} = \bigg( \sum_{|\alpha|\leq k}\|D^{\alpha}u\|_{L^{p}(U)}^{p}\bigg)^{\frac{1}{p}} $$ and $$ \||u|\|_{W^{k,p}(U)} = \sum_{|\alpha|\leq k}\|D^{\alpha}u\|_{L^{p}(U)}$$ are equivalent norms on $W^{k,p}(U).$ So i have to show something like this: $ \beta|||u|||\leq||u||\leq\gamma|||u|||. $ I showed the second inequality. I looked for the powers $p$ of the norm ($p\geq 1$). So we have  $$ \big(\|u\|_{W^{k,p}(U)}\big)^p =\sum_{|\alpha|\leq k}\|D^{\alpha}u\|_{L^{p}(U)}^{p} \leq \bigg(\sum_{|\alpha|\leq k}\|D^{\alpha}u\|_{L^{p}(U)}\bigg)^p =  \big(\||u|\|_{W^{k,p}(U)}\big)^p  $$ as we know that $\sum_{i=1}^n a_i^{p} \leq \big(\sum_{i=1}^n a_i\big)^p$ (proof with the help of binomial theorem). Therefore $$ \|u\|_{W^{k,p}(U)} \leq 1 \cdot \||u|\|_{W^{k,p}(U)} $$ and $\gamma = 1.$ But the lower bound is troubling me. I would be really grateful for some tips.","I have this problem: Let $k>0$ (integer) and $1 \leq p < \infty$. Show that the norms $$ \|u\|_{W^{k,p}(U)} = \bigg( \sum_{|\alpha|\leq k}\|D^{\alpha}u\|_{L^{p}(U)}^{p}\bigg)^{\frac{1}{p}} $$ and $$ \||u|\|_{W^{k,p}(U)} = \sum_{|\alpha|\leq k}\|D^{\alpha}u\|_{L^{p}(U)}$$ are equivalent norms on $W^{k,p}(U).$ So i have to show something like this: $ \beta|||u|||\leq||u||\leq\gamma|||u|||. $ I showed the second inequality. I looked for the powers $p$ of the norm ($p\geq 1$). So we have  $$ \big(\|u\|_{W^{k,p}(U)}\big)^p =\sum_{|\alpha|\leq k}\|D^{\alpha}u\|_{L^{p}(U)}^{p} \leq \bigg(\sum_{|\alpha|\leq k}\|D^{\alpha}u\|_{L^{p}(U)}\bigg)^p =  \big(\||u|\|_{W^{k,p}(U)}\big)^p  $$ as we know that $\sum_{i=1}^n a_i^{p} \leq \big(\sum_{i=1}^n a_i\big)^p$ (proof with the help of binomial theorem). Therefore $$ \|u\|_{W^{k,p}(U)} \leq 1 \cdot \||u|\|_{W^{k,p}(U)} $$ and $\gamma = 1.$ But the lower bound is troubling me. I would be really grateful for some tips.",,"['functional-analysis', 'normed-spaces', 'lp-spaces']"
24,Banach spaces $X$ for which the subspace of adjoint operators has finite codimension in $X^*$,Banach spaces  for which the subspace of adjoint operators has finite codimension in,X X^*,"For a Banach space $X$, let $A \subseteq \mathcal{B}(X^*)$ denote the closed subspace of those operators $T : X^* \to X^*$ such that $T = S^*$ for some $S \in \mathcal{B}(X)$, that is, $T$ is the adjoint of some bounded linear operator on $X$. It can be shown that this condition is equivalent to $T$ being weak*-continuous. Certainly $A=\mathcal{B}(X^*)$ for a Hilbert space. Do there exist Banach spaces $X$ for which $A$ is of finite positive codimension in $\mathcal{B}(X^*)$, i.e. the quotient space $\mathcal{B}(X^*)/A$ is finite-dimensional (but nontrivial)?","For a Banach space $X$, let $A \subseteq \mathcal{B}(X^*)$ denote the closed subspace of those operators $T : X^* \to X^*$ such that $T = S^*$ for some $S \in \mathcal{B}(X)$, that is, $T$ is the adjoint of some bounded linear operator on $X$. It can be shown that this condition is equivalent to $T$ being weak*-continuous. Certainly $A=\mathcal{B}(X^*)$ for a Hilbert space. Do there exist Banach spaces $X$ for which $A$ is of finite positive codimension in $\mathcal{B}(X^*)$, i.e. the quotient space $\mathcal{B}(X^*)/A$ is finite-dimensional (but nontrivial)?",,"['functional-analysis', 'banach-spaces']"
25,Linear contraction on a Banach space,Linear contraction on a Banach space,,"Let $X$ be a Banach space with a norm $\|\cdot\|_1$ and $A$ be a linear operator on $X$ such that $\|A\|_1\leq 1$; $\|A^m\|_1<1$ for some $m\in \mathbb N$. Is that true that there is an equivalent norm $\|\cdot\|_2$ on $X$ such that $\|A\|_2<1$? If there exists such a norm, how can it be constructed? Here for operator we use associated (induced norm): given a norm $\|\cdot\|$ on $X,$ $$ \|B\| :=\sup\limits_{\|x\|=1}\|Bx\| $$ for any linear operator $B$.","Let $X$ be a Banach space with a norm $\|\cdot\|_1$ and $A$ be a linear operator on $X$ such that $\|A\|_1\leq 1$; $\|A^m\|_1<1$ for some $m\in \mathbb N$. Is that true that there is an equivalent norm $\|\cdot\|_2$ on $X$ such that $\|A\|_2<1$? If there exists such a norm, how can it be constructed? Here for operator we use associated (induced norm): given a norm $\|\cdot\|$ on $X,$ $$ \|B\| :=\sup\limits_{\|x\|=1}\|Bx\| $$ for any linear operator $B$.",,"['functional-analysis', 'banach-spaces']"
26,"Show that the real K-G equation, $(\Box + m^2)\phi=0$ is the EOM for the action $S=\frac12\int d^4x(\partial^\mu{\phi}\partial_\mu{\phi}-m^2\phi^2)$","Show that the real K-G equation,  is the EOM for the action",(\Box + m^2)\phi=0 S=\frac12\int d^4x(\partial^\mu{\phi}\partial_\mu{\phi}-m^2\phi^2),"This question concerns a real scalar field. Show that the real Klein-Gordon equation, $(\Box + m^2)\phi=0$ is the equation of motion, $\delta S[\phi(x)]/\delta\phi(x)=0$ , for the action $$S=\frac12\int d^4x\left(\partial^\mu{\phi}\partial_\mu{\phi}-m^2\phi^2\right)$$ by performing a functional variation. Here $\mu = 0,1,2,3$ , ( $3+1$ space-time dimensions). The Lagrangian density is $$\mathcal{L}=\mathcal{L}\left(\phi,\ \partial^\mu{\phi},\ \partial_\mu{\phi}\right)=\partial^\mu{\phi}\partial_\mu{\phi}-m^2\phi^2\tag{A}$$ Now since the change in functional variation $$\frac{\delta S[\phi(x)]}{\delta\phi(x)}=\lim_{\delta \phi\to 0}\left(\frac{S(\phi + \delta\phi)-S(\phi)}{\delta\phi}\right)=0$$ It follows that $S(\phi + \delta\phi)-S(\phi)$ must be zero for any $\delta\phi$ . The variation in the action, $S$ is therefore $$\delta{S[\phi]}=\frac12\int d^4x\left[\phi+\delta\phi,\ \partial^\mu{\phi}+\delta\left(\partial^\mu{\phi}\right),\ \partial_\mu{\phi}+\delta(\partial_\mu{\phi})\right]$$ and after Taylor expanding to first order in $\delta\phi$ becomes $$\delta{S[\phi(x)]}$$ $$=\int \frac{d^4x}{2} \left[\mathcal{L}\left(\phi, \partial^\mu{\phi}, \partial_\mu{\phi}\right)+\frac{\partial\mathcal{L}}{\partial \phi}\delta\phi+\frac{\partial\mathcal{L}}{\partial\left(\partial^\mu\phi\right)}\delta\left(\partial^\mu\phi\right)+\frac{\partial\mathcal{L}}{\partial\left(\partial_\mu\phi\right)}\delta\left(\partial_\mu\phi\right)-\mathcal{L}\left(\phi, \partial^\mu{\phi}, \partial_\mu{\phi}\right)\right]$$ $$=\frac12\int d^4x\left[-2m^2\phi\delta\phi+\partial_\mu{\phi}\delta\left(\partial^\mu\phi\right)+\partial^\mu{\phi}\delta\left(\partial_\mu\phi\right)\right]\tag{B}$$ This is as far as I can get and matches the first line of the solution. I will typeset this solution in exactly the same way as the author did to illustrate my confusion: Take the action $$S=\frac12\int d^4x\left(\partial^\mu{\phi}\partial_\mu{\phi}-m^2\phi^2\right)$$ Now we vary it; $$\delta{S} = \frac12\int d^4x\left[\left(\delta\partial^\mu\phi\right)\partial_\mu{\phi}+\partial^\mu{\phi}\delta\left(\partial_\mu\phi\right)-2m^2\phi\delta\phi\right]\tag{1}$$ $$= \frac12\int d^4x\left[\color{#085}{\left(\partial^\mu\delta\phi\right)\partial_\mu{\phi}}+\partial^\mu{\phi}\left(\partial_\mu\delta\phi\right)-2m^2\phi\delta\phi\right]\tag{2}$$ $$= \int d^4x\left[\partial^\mu\phi\partial_\mu{\delta\phi}-m^2\phi\delta\phi\right]\tag{3}$$ $$=\int d^4x \left[-\partial_\mu (\partial^\mu\phi)\delta\phi-m^2\phi\delta\phi\right]+\int d^4x \partial_{\mu}\left(\delta\phi\partial^\mu\phi\right)\tag{4}$$ and we drop the last term, the total divergence due to boundary conditions, so, $$\delta{S}=-\int d^4x \left(\partial^2\phi+m^2\phi\right)\delta\phi\tag{5}$$ Was it correct to have 3 arguments for the Lagrangian density in $(\mathrm{A})$ , namely to distinguish between the contravariant and covariant derivatives? What is the justification for commuting the $\delta$ past the derivative in going from $(1)$ to $(2)$ ? How did the author get from $(2)$ to $(3)$ ? It's almost as if the first term in the integrand of $(2)$ (marked green) has been forgotten about. To go from eqn. $(3)$ to $(4)$ I think integration by parts has been used to factor the $\delta\phi$ out, so integrating the first term of $(3)$ by parts gives $$\int\partial^\mu{\phi}\left(\partial_\mu\delta\phi\right)d^4x=\color{blue}{\left[\partial^\mu{\phi}\int\partial_\mu\left(\delta\phi\right) d^4x \right]}-\int\bigg(\partial_\mu(\partial^\mu\phi)\delta\phi\bigg) d^4x$$ This explains the negative sign for the first term in $(4)$ , but why does the boundary term (marked blue) not match the final term of equation $(4)$ ? I don't really understand why the final term of $(4)$ can be dropped, but a more pressing question I have is how $(5)$ was deduced from $(4)$ . Put another way, it was my understanding that the covariant derivative is such that $$\partial_\mu\equiv\frac{\partial}{\partial x^\mu}\tag{C}$$ and the contravariant derivative is defined as $$\partial^\mu\equiv\frac{\partial}{\partial x_\mu}\tag{D}$$ but the way it's written in going from $(4)$ to $(5)$ suggests that $$\partial_\mu(\partial^\mu\phi)\stackrel{\color{red}{\mathrm{?}}}{=}\partial^2\phi$$ But how can this possibly be true? Okay, so the $\mu$ index is summed over in accordance with the Einstein summation convention since it is a repeated (dummy) index, but by virtue of $(\mathrm{C})$ and $(\mathrm{D})$ without the $\mu$ index $\partial^2\phi$ does not tell me which variable the field, $\phi$ is being differentiated with respect to. Update: I've been given a good answer that addresses most of my questions nicely. The only part that still puzzles me is how the author was able to immediately write down eqn. $(1)$ in the solution. Is it blatantly obvious that the functional variation, $\delta{S} = \frac12\int d^4x\left[\left(\delta\partial^\mu\phi\right)\partial_\mu{\phi}+\partial^\mu{\phi}\delta\left(\partial_\mu\phi\right)-2m^2\phi\delta\phi\right]$ ? I had to go through several lines of logical reasoning to justify that equation, including a Taylor expansion. Closing remarks With the bounty time reaching its conclusion and my subsequent comments below one of the answers I know there may not be time to address these questions before the bounty ends. So I'll award the bounty regardless of whether I get a reply to these comments. I would just like to say a massive thanks to all those that took time and effort to write such great answers. I know I haven't been very good at keeping on top of this question, I just wish I had more time.","This question concerns a real scalar field. Show that the real Klein-Gordon equation, is the equation of motion, , for the action by performing a functional variation. Here , ( space-time dimensions). The Lagrangian density is Now since the change in functional variation It follows that must be zero for any . The variation in the action, is therefore and after Taylor expanding to first order in becomes This is as far as I can get and matches the first line of the solution. I will typeset this solution in exactly the same way as the author did to illustrate my confusion: Take the action Now we vary it; and we drop the last term, the total divergence due to boundary conditions, so, Was it correct to have 3 arguments for the Lagrangian density in , namely to distinguish between the contravariant and covariant derivatives? What is the justification for commuting the past the derivative in going from to ? How did the author get from to ? It's almost as if the first term in the integrand of (marked green) has been forgotten about. To go from eqn. to I think integration by parts has been used to factor the out, so integrating the first term of by parts gives This explains the negative sign for the first term in , but why does the boundary term (marked blue) not match the final term of equation ? I don't really understand why the final term of can be dropped, but a more pressing question I have is how was deduced from . Put another way, it was my understanding that the covariant derivative is such that and the contravariant derivative is defined as but the way it's written in going from to suggests that But how can this possibly be true? Okay, so the index is summed over in accordance with the Einstein summation convention since it is a repeated (dummy) index, but by virtue of and without the index does not tell me which variable the field, is being differentiated with respect to. Update: I've been given a good answer that addresses most of my questions nicely. The only part that still puzzles me is how the author was able to immediately write down eqn. in the solution. Is it blatantly obvious that the functional variation, ? I had to go through several lines of logical reasoning to justify that equation, including a Taylor expansion. Closing remarks With the bounty time reaching its conclusion and my subsequent comments below one of the answers I know there may not be time to address these questions before the bounty ends. So I'll award the bounty regardless of whether I get a reply to these comments. I would just like to say a massive thanks to all those that took time and effort to write such great answers. I know I haven't been very good at keeping on top of this question, I just wish I had more time.","(\Box + m^2)\phi=0 \delta S[\phi(x)]/\delta\phi(x)=0 S=\frac12\int d^4x\left(\partial^\mu{\phi}\partial_\mu{\phi}-m^2\phi^2\right) \mu = 0,1,2,3 3+1 \mathcal{L}=\mathcal{L}\left(\phi,\ \partial^\mu{\phi},\ \partial_\mu{\phi}\right)=\partial^\mu{\phi}\partial_\mu{\phi}-m^2\phi^2\tag{A} \frac{\delta S[\phi(x)]}{\delta\phi(x)}=\lim_{\delta \phi\to 0}\left(\frac{S(\phi + \delta\phi)-S(\phi)}{\delta\phi}\right)=0 S(\phi + \delta\phi)-S(\phi) \delta\phi S \delta{S[\phi]}=\frac12\int d^4x\left[\phi+\delta\phi,\ \partial^\mu{\phi}+\delta\left(\partial^\mu{\phi}\right),\ \partial_\mu{\phi}+\delta(\partial_\mu{\phi})\right] \delta\phi \delta{S[\phi(x)]} =\int \frac{d^4x}{2} \left[\mathcal{L}\left(\phi, \partial^\mu{\phi}, \partial_\mu{\phi}\right)+\frac{\partial\mathcal{L}}{\partial \phi}\delta\phi+\frac{\partial\mathcal{L}}{\partial\left(\partial^\mu\phi\right)}\delta\left(\partial^\mu\phi\right)+\frac{\partial\mathcal{L}}{\partial\left(\partial_\mu\phi\right)}\delta\left(\partial_\mu\phi\right)-\mathcal{L}\left(\phi, \partial^\mu{\phi}, \partial_\mu{\phi}\right)\right] =\frac12\int d^4x\left[-2m^2\phi\delta\phi+\partial_\mu{\phi}\delta\left(\partial^\mu\phi\right)+\partial^\mu{\phi}\delta\left(\partial_\mu\phi\right)\right]\tag{B} S=\frac12\int d^4x\left(\partial^\mu{\phi}\partial_\mu{\phi}-m^2\phi^2\right) \delta{S} = \frac12\int d^4x\left[\left(\delta\partial^\mu\phi\right)\partial_\mu{\phi}+\partial^\mu{\phi}\delta\left(\partial_\mu\phi\right)-2m^2\phi\delta\phi\right]\tag{1} = \frac12\int d^4x\left[\color{#085}{\left(\partial^\mu\delta\phi\right)\partial_\mu{\phi}}+\partial^\mu{\phi}\left(\partial_\mu\delta\phi\right)-2m^2\phi\delta\phi\right]\tag{2} = \int d^4x\left[\partial^\mu\phi\partial_\mu{\delta\phi}-m^2\phi\delta\phi\right]\tag{3} =\int d^4x \left[-\partial_\mu (\partial^\mu\phi)\delta\phi-m^2\phi\delta\phi\right]+\int d^4x \partial_{\mu}\left(\delta\phi\partial^\mu\phi\right)\tag{4} \delta{S}=-\int d^4x \left(\partial^2\phi+m^2\phi\right)\delta\phi\tag{5} (\mathrm{A}) \delta (1) (2) (2) (3) (2) (3) (4) \delta\phi (3) \int\partial^\mu{\phi}\left(\partial_\mu\delta\phi\right)d^4x=\color{blue}{\left[\partial^\mu{\phi}\int\partial_\mu\left(\delta\phi\right) d^4x \right]}-\int\bigg(\partial_\mu(\partial^\mu\phi)\delta\phi\bigg) d^4x (4) (4) (4) (5) (4) \partial_\mu\equiv\frac{\partial}{\partial x^\mu}\tag{C} \partial^\mu\equiv\frac{\partial}{\partial x_\mu}\tag{D} (4) (5) \partial_\mu(\partial^\mu\phi)\stackrel{\color{red}{\mathrm{?}}}{=}\partial^2\phi \mu (\mathrm{C}) (\mathrm{D}) \mu \partial^2\phi \phi (1) \delta{S} = \frac12\int d^4x\left[\left(\delta\partial^\mu\phi\right)\partial_\mu{\phi}+\partial^\mu{\phi}\delta\left(\partial_\mu\phi\right)-2m^2\phi\delta\phi\right]","['functional-analysis', 'proof-explanation', 'mathematical-physics', 'tensors', 'quantum-field-theory']"
27,Which Sobolev spaces are function spaces?,Which Sobolev spaces are function spaces?,,"Let us consider the Sobolev space $W^{s,p}(\mathbb R^n)$ , $s \in \mathbb R$ (I am most interested in the case $n=1$ ). If $s \geq 0$ , it embeds to $L^p(\mathbb R^n)$ , so its elements may be interpreted as functions (modulo redefinitions on sets of measure zero). If $s$ is sufficiently negative then not all elements of $W^{s,p}(\mathbb R^n)$ are functions, for example the Dirac's delta may belong to $W^{s,p}(\mathbb R^n)$ . I would like to ask if there is some range of negative $s$ for which all elements in $W^{s,p}(\mathbb R^n)$ are genuine functions (e.g. from $L^1_{\mathrm{loc}}(\mathbb R^n))$ .","Let us consider the Sobolev space , (I am most interested in the case ). If , it embeds to , so its elements may be interpreted as functions (modulo redefinitions on sets of measure zero). If is sufficiently negative then not all elements of are functions, for example the Dirac's delta may belong to . I would like to ask if there is some range of negative for which all elements in are genuine functions (e.g. from .","W^{s,p}(\mathbb R^n) s \in \mathbb R n=1 s \geq 0 L^p(\mathbb R^n) s W^{s,p}(\mathbb R^n) W^{s,p}(\mathbb R^n) s W^{s,p}(\mathbb R^n) L^1_{\mathrm{loc}}(\mathbb R^n))","['functional-analysis', 'analysis', 'measure-theory', 'sobolev-spaces', 'fractional-sobolev-spaces']"
28,Closed and open sets through a function between metric spaces,Closed and open sets through a function between metric spaces,,"My professor started an exercise in class with various points. He did not finish it though: he left some of the points as homework and said that he will finish the last one in class. I'm trying it and I would like to have some hints (not full answers, he is going to solve it anyway) and maybe some clarification. I shall write the previous point first, since the other starts from there: Let $(X, d_x)$ and $(\Bbb R, \vert \cdot \vert)$ be metric spaces where $\vert \cdot \vert $ is the absolute value function, let $f:X \to \Bbb R$ be a function between these two metric spaces. Let $ A= \{(x,y)  \in X\times \Bbb R \mid y\gt f(x)\} $ and $ B=\{(x,y)  \in X\times \Bbb R \mid y\ge f(x) \} $ . Show that, if $f$ is continuous, then $A$ is open and $B$ is closed. I managed to prove this, and I'm interested in the next request. Show that, in general, the converse is not true I interpeted it as : ""give an example of a non continuous function such that $A$ is open and $B$ is closed, thus showing that the fact that $A$ is open and $B$ is closed does not imply that $f$ must be continuous"" However, I'm having some problems finding such a function. I tried choosing $X=\Bbb R$ , but it seems to me that the only good candidate would be a step-like function, and this kind fails to induce both the closed and the open set at the same time, only one of the two. This makes me think that with $(X,d_x)=(\Bbb R,d_x)$ the double implication holds, but I did not try to prove this: does it? If yes, where should I look for finding such function? If no, what am I doing wrong in $\Bbb R$ ? In general, is my approach correct or I should use something else? Thank you. Edit: As we all suspected, and as the user Jochen kindly showed in one of the replies, with the phrase ""show that in general the converse is not true"" he meant that we had to assume only one of the two hypothesis (i.e. assuming either that $A$ is open or that $B$ is closed, not both at the sames time), and in that case using the step function mentioned above it becomes trivial.","My professor started an exercise in class with various points. He did not finish it though: he left some of the points as homework and said that he will finish the last one in class. I'm trying it and I would like to have some hints (not full answers, he is going to solve it anyway) and maybe some clarification. I shall write the previous point first, since the other starts from there: Let and be metric spaces where is the absolute value function, let be a function between these two metric spaces. Let and . Show that, if is continuous, then is open and is closed. I managed to prove this, and I'm interested in the next request. Show that, in general, the converse is not true I interpeted it as : ""give an example of a non continuous function such that is open and is closed, thus showing that the fact that is open and is closed does not imply that must be continuous"" However, I'm having some problems finding such a function. I tried choosing , but it seems to me that the only good candidate would be a step-like function, and this kind fails to induce both the closed and the open set at the same time, only one of the two. This makes me think that with the double implication holds, but I did not try to prove this: does it? If yes, where should I look for finding such function? If no, what am I doing wrong in ? In general, is my approach correct or I should use something else? Thank you. Edit: As we all suspected, and as the user Jochen kindly showed in one of the replies, with the phrase ""show that in general the converse is not true"" he meant that we had to assume only one of the two hypothesis (i.e. assuming either that is open or that is closed, not both at the sames time), and in that case using the step function mentioned above it becomes trivial.","(X, d_x) (\Bbb R, \vert \cdot \vert) \vert \cdot \vert  f:X \to \Bbb R  A= \{(x,y)  \in X\times \Bbb R \mid y\gt f(x)\}   B=\{(x,y)  \in X\times \Bbb R \mid y\ge f(x) \}  f A B A B A B f X=\Bbb R (X,d_x)=(\Bbb R,d_x) \Bbb R A B","['functional-analysis', 'functions', 'continuity', 'metric-spaces']"
29,"If $Y\subset X$ are Banach spaces such that $Y$ is dense in $X$, is it true that $X'$ is dense in $Y'$?","If  are Banach spaces such that  is dense in , is it true that  is dense in ?",Y\subset X Y X X' Y',"If $Y$ is a dense subspace of a Banach space $(X,\|\cdot\|_1)$ and $(Y,\|\cdot\|_2)$ is a Banach space such that the inclusion from $(Y,\|\cdot\|_2)$ into $(X,\|\cdot\|_1)$ is continuous, then it is well defined, linear, injective, and continuous in the dual norm topology the map: $$j:X'\to Y', f\mapsto f|_{Y},$$ where $X'$ is the topological dual of $(X,\|\cdot\|_1)$ and $Y'$ is the topological dual of $(Y,\|\cdot\|_2)$ . So, we can identify $X'$ as a subset of $Y'$ . Is it true that $X'$ is dense in $Y'$ in the norm topology? If not, is true that $X'$ is dense in $Y'$ at least in the weak* topology? Edit: in this question it is addressed the case where $(Y,\|\cdot\|_2)$ is reflexive, obtaining that in this case (thanks to Hahn-Banach theorem) $X'$ is dense in the norm topology of $Y'$ . In the answer to this question it is shown that counterexamples to density in norm topology exist if the reflexivity of $(Y,\|\cdot\|_2)$ is not assumed, e.g. by taking $(X,\|\cdot\|_1):=(l^2,\|\cdot\|_{l^2})$ and $(Y,\|\cdot\|_1):=(l^1,\|\cdot\|_{l^1})$ . However, in this counterexample $X'$ is still dense in the weak* topology of $Y'$ . So, it remains to answer only the following part of the original question: Is true that $X'$ is dense in $Y'$ in the weak* topology?","If is a dense subspace of a Banach space and is a Banach space such that the inclusion from into is continuous, then it is well defined, linear, injective, and continuous in the dual norm topology the map: where is the topological dual of and is the topological dual of . So, we can identify as a subset of . Is it true that is dense in in the norm topology? If not, is true that is dense in at least in the weak* topology? Edit: in this question it is addressed the case where is reflexive, obtaining that in this case (thanks to Hahn-Banach theorem) is dense in the norm topology of . In the answer to this question it is shown that counterexamples to density in norm topology exist if the reflexivity of is not assumed, e.g. by taking and . However, in this counterexample is still dense in the weak* topology of . So, it remains to answer only the following part of the original question: Is true that is dense in in the weak* topology?","Y (X,\|\cdot\|_1) (Y,\|\cdot\|_2) (Y,\|\cdot\|_2) (X,\|\cdot\|_1) j:X'\to Y', f\mapsto f|_{Y}, X' (X,\|\cdot\|_1) Y' (Y,\|\cdot\|_2) X' Y' X' Y' X' Y' (Y,\|\cdot\|_2) X' Y' (Y,\|\cdot\|_2) (X,\|\cdot\|_1):=(l^2,\|\cdot\|_{l^2}) (Y,\|\cdot\|_1):=(l^1,\|\cdot\|_{l^1}) X' Y' X' Y'","['functional-analysis', 'dual-spaces', 'weak-topology']"
30,"Multiplication operator by $x$ on $L^2(0,1)$ is isomorphic to its square",Multiplication operator by  on  is isomorphic to its square,"x L^2(0,1)","The following is Exercise II.8.7 from J. B. Conway's A Course in Functional Analysis . Let $A:L^2(0,1)\to L^2(0,1)$ be defined by $(Af)(x)=xf(x)$ for $f$ in $L^2(0,1)$ and $x$ in $(0,1)$ . Show that $A\cong A^2$ . Here $A\cong A^2$ means there is an unitary isomorphism $U:L^2(0,1)\to L^2(0,1)$ such that $UAU^{-1}=A^2$ . I guess I should construct an explicit isomorphism, because $A$ is not compact, and the author has not proved any structure theorem for non-compact operators yet. However, I don't know how I can find such an isomorphism. I understand that $L^2(0,1)$ has Hilbert basis $e^{2\pi inx}$ , and I computed the matrix of $A$ with respect to this basis, but I can't see how $A\cong A^2$ . Any hints will be appreciated!","The following is Exercise II.8.7 from J. B. Conway's A Course in Functional Analysis . Let be defined by for in and in . Show that . Here means there is an unitary isomorphism such that . I guess I should construct an explicit isomorphism, because is not compact, and the author has not proved any structure theorem for non-compact operators yet. However, I don't know how I can find such an isomorphism. I understand that has Hilbert basis , and I computed the matrix of with respect to this basis, but I can't see how . Any hints will be appreciated!","A:L^2(0,1)\to L^2(0,1) (Af)(x)=xf(x) f L^2(0,1) x (0,1) A\cong A^2 A\cong A^2 U:L^2(0,1)\to L^2(0,1) UAU^{-1}=A^2 A L^2(0,1) e^{2\pi inx} A A\cong A^2","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
31,What is the orthogonal complement of $H^1_0$ in $H^1$?,What is the orthogonal complement of  in ?,H^1_0 H^1,"Let $\Omega$ be a closed domain with smooth boundary in $\mathbb{R}^n$ . Let $H^1_0(\Omega)$ be the closure of compactly supported smooth functions under the norm $\|u\|_1 = \int_\Omega u^2 + |\nabla u|^2\ dx$ and let $H^1(\Omega)$ be the closure of smooth, continuous functions under the same norm. Any $H^1$ function which has nonvanishing trace cannot be approximated by any sequence of functions in $H^1_0$ . So $H^1_0$ is a closed subspace of the Hilbert space $(H^1, \|\cdot\|_1)$ , hence has an orthogonal complement. What is a generating set of the orthogonal complement of $H^1_0$ in $H^1$ ? Motivation is to get my hands on some concrete examples, rather than to just appeal to theorems that establish the existence of a right inverse to a trace operator. Of course if anyone has references, I'm happy to follow them up. I've skimmed through Gilbarg-Trudinger and Evans and found nothing, but maybe I'm looking in the wrong place.","Let be a closed domain with smooth boundary in . Let be the closure of compactly supported smooth functions under the norm and let be the closure of smooth, continuous functions under the same norm. Any function which has nonvanishing trace cannot be approximated by any sequence of functions in . So is a closed subspace of the Hilbert space , hence has an orthogonal complement. What is a generating set of the orthogonal complement of in ? Motivation is to get my hands on some concrete examples, rather than to just appeal to theorems that establish the existence of a right inverse to a trace operator. Of course if anyone has references, I'm happy to follow them up. I've skimmed through Gilbarg-Trudinger and Evans and found nothing, but maybe I'm looking in the wrong place.","\Omega \mathbb{R}^n H^1_0(\Omega) \|u\|_1 = \int_\Omega u^2 + |\nabla u|^2\ dx H^1(\Omega) H^1 H^1_0 H^1_0 (H^1, \|\cdot\|_1) H^1_0 H^1","['functional-analysis', 'sobolev-spaces', 'trace']"
32,Does there exist a infinite dimensional Banach subspace in every normed space?,Does there exist a infinite dimensional Banach subspace in every normed space?,,"We know that every normed space contains a separable subspace. Let $X$ a normed space. Suppose that Hamel's basis of $X$ is uncountable, $X$ isn't a reflexive and Banach space (see below). Does there exist an infinite dimensional Banach subspace $B$ of $X$? Remark: If $X$ is Banach take any infinite dimensional closed subspace in $X$,  and we have done. (Let $(x_{n})_{n}$  linearly independent  sequence, so  $S=\overline{ \langle (x_{n})_{n} \rangle}$ is a closed subspace in $X$, then $S$ is a Banach subspace of $X$). We have to show the question when $X$ isn't a Banach space. In particular, if $X$ isn't Banach, then $X$ isn't reflexive. (Suppose $X$ isn't Banach. If $X$ is reflexive , $J(X)=X''$, and $X''$ is Banach, then $X$ is Banach.) We have to show the question when $X$ isn't a reflexive and Banach space. If $X$ is normed space with Hamel's basis countable then $X$ can't have a subspace that is Banach in $X$. In fact, let $S$ a Banach subspace of $X$, then Hamel's basis of $S$ is uncountable, but Hamel's basis of $X$ is countable. An example of normed space with countable basis: ""Consider $c_{00}$, the space of the sequences $x=(x_{n})$ of real numbers which have only finitely many non-zero elements, with the norm $ \|x\|=\sup _{n}|x_{n}|$ . Its standard basis, consisting of the sequences having only one non-zero element, which is equal to 1, is a countable Hamel basis."" ( https://en.wikipedia.org/wiki/Basis_(linear_algebra) ) We have to show the question when Hamel's basis of $X$ is uncountable, and $X$ isn't a reflexive and Banach space.","We know that every normed space contains a separable subspace. Let $X$ a normed space. Suppose that Hamel's basis of $X$ is uncountable, $X$ isn't a reflexive and Banach space (see below). Does there exist an infinite dimensional Banach subspace $B$ of $X$? Remark: If $X$ is Banach take any infinite dimensional closed subspace in $X$,  and we have done. (Let $(x_{n})_{n}$  linearly independent  sequence, so  $S=\overline{ \langle (x_{n})_{n} \rangle}$ is a closed subspace in $X$, then $S$ is a Banach subspace of $X$). We have to show the question when $X$ isn't a Banach space. In particular, if $X$ isn't Banach, then $X$ isn't reflexive. (Suppose $X$ isn't Banach. If $X$ is reflexive , $J(X)=X''$, and $X''$ is Banach, then $X$ is Banach.) We have to show the question when $X$ isn't a reflexive and Banach space. If $X$ is normed space with Hamel's basis countable then $X$ can't have a subspace that is Banach in $X$. In fact, let $S$ a Banach subspace of $X$, then Hamel's basis of $S$ is uncountable, but Hamel's basis of $X$ is countable. An example of normed space with countable basis: ""Consider $c_{00}$, the space of the sequences $x=(x_{n})$ of real numbers which have only finitely many non-zero elements, with the norm $ \|x\|=\sup _{n}|x_{n}|$ . Its standard basis, consisting of the sequences having only one non-zero element, which is equal to 1, is a countable Hamel basis."" ( https://en.wikipedia.org/wiki/Basis_(linear_algebra) ) We have to show the question when Hamel's basis of $X$ is uncountable, and $X$ isn't a reflexive and Banach space.",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
33,"Linear transformation $T$ such that for every extension $\overline{T}$, $\|\overline{T}\|>\|T\|$.","Linear transformation  such that for every extension , .",T \overline{T} \|\overline{T}\|>\|T\|,"Let $E$ and $F$ be normed spaces such that $\dim F < \infty$, $G$ a subspace of $E$ and $T:G\rightarrow F$ a continuous linear map. I know that there exists a continuous linear extension $\overline{T}:E\rightarrow F$. Also, if $E$ is a Hilbert space, then $\overline{T}$ can be chosen in the way that $\|\overline{T}\|=\|T\|$. Problem: Find an example of $E$, $F$, $G$ and $T$ (like above) such that every continuous linear extension $\overline{T}$ has a greater norm, i.e. $\|\overline{T}\|>\|T\|$. Now, $F$ must be at least a 2-dimensional space, otherwise I could use Hahn-Banach to find an extension with equal norm.  My professor told me it could be done with $E$ of finite dimension. Of course, I tried to come up with an example of $E$ with a norm that doesn't satisfy the parallelogram law. For example, $E=\left(\mathbb{R}^3,\|\cdot\|_{\infty}\right)$ and $F=\left(\mathbb{R}^2,\|\cdot\|_1\right)$. But I couldn't prove that it works with any example I tried using those spaces. Can somebody help me to find an example and assure that it really has that property? EDIT: Apparently, it can't be done with $E$ of finite dimension nor with $F$ equipped with the $\sup$ norm, as @Hamza proved below.","Let $E$ and $F$ be normed spaces such that $\dim F < \infty$, $G$ a subspace of $E$ and $T:G\rightarrow F$ a continuous linear map. I know that there exists a continuous linear extension $\overline{T}:E\rightarrow F$. Also, if $E$ is a Hilbert space, then $\overline{T}$ can be chosen in the way that $\|\overline{T}\|=\|T\|$. Problem: Find an example of $E$, $F$, $G$ and $T$ (like above) such that every continuous linear extension $\overline{T}$ has a greater norm, i.e. $\|\overline{T}\|>\|T\|$. Now, $F$ must be at least a 2-dimensional space, otherwise I could use Hahn-Banach to find an extension with equal norm.  My professor told me it could be done with $E$ of finite dimension. Of course, I tried to come up with an example of $E$ with a norm that doesn't satisfy the parallelogram law. For example, $E=\left(\mathbb{R}^3,\|\cdot\|_{\infty}\right)$ and $F=\left(\mathbb{R}^2,\|\cdot\|_1\right)$. But I couldn't prove that it works with any example I tried using those spaces. Can somebody help me to find an example and assure that it really has that property? EDIT: Apparently, it can't be done with $E$ of finite dimension nor with $F$ equipped with the $\sup$ norm, as @Hamza proved below.",,"['functional-analysis', 'operator-theory', 'normed-spaces']"
34,Does an extension operator in Sobolev spaces commute with derivative operators?,Does an extension operator in Sobolev spaces commute with derivative operators?,,"Assume that $\Omega\subseteq \mathbb R^d$ is open and has a Lipschitz boundary. Let $\tau\geq0$. Then we know that there exists a linear operator $E:H^\tau(\Omega)\to H^\tau(\mathbb R^d)$ such that for all $u\in H^\tau(\Omega)$ we have $Eu = u$, on $\Omega$, $\|Eu\|_{H^\tau(\mathbb R^d)}\leq C_\tau \|u\|_{H^\tau(\Omega)}$, where $C_\tau$ is a constant independent of $u$. The same extension $E$ works for all $\tau$. This was proved by E.M. Stein in 1971 for integer $\tau$ and by R.A. DeVore and R.C. Sharpley in 1993 for real $\tau$. Now my question: Do $E$ and $D^\alpha$ (weak derivative operator of order $\alpha\in \mathbb N_0^d$ for $|\alpha|\leq \tau$) commute? This means that $$E(D^\alpha u) = D^\alpha(Eu),~~ for~ all~~ u\in H^{\tau}(\Omega)~~ and~~ |\alpha|\leq\tau.$$ If not, can such alternative extension be proved? Thank you for your consideration in advance.","Assume that $\Omega\subseteq \mathbb R^d$ is open and has a Lipschitz boundary. Let $\tau\geq0$. Then we know that there exists a linear operator $E:H^\tau(\Omega)\to H^\tau(\mathbb R^d)$ such that for all $u\in H^\tau(\Omega)$ we have $Eu = u$, on $\Omega$, $\|Eu\|_{H^\tau(\mathbb R^d)}\leq C_\tau \|u\|_{H^\tau(\Omega)}$, where $C_\tau$ is a constant independent of $u$. The same extension $E$ works for all $\tau$. This was proved by E.M. Stein in 1971 for integer $\tau$ and by R.A. DeVore and R.C. Sharpley in 1993 for real $\tau$. Now my question: Do $E$ and $D^\alpha$ (weak derivative operator of order $\alpha\in \mathbb N_0^d$ for $|\alpha|\leq \tau$) commute? This means that $$E(D^\alpha u) = D^\alpha(Eu),~~ for~ all~~ u\in H^{\tau}(\Omega)~~ and~~ |\alpha|\leq\tau.$$ If not, can such alternative extension be proved? Thank you for your consideration in advance.",,"['functional-analysis', 'sobolev-spaces', 'approximation-theory']"
35,Sufficient Condition for $f\in L^{1}(\mathbb{R}^{d})$ to belong to $L^{2}(\mathbb{R}^{d})$ in terms of its Fourier coefficients,Sufficient Condition for  to belong to  in terms of its Fourier coefficients,f\in L^{1}(\mathbb{R}^{d}) L^{2}(\mathbb{R}^{d}),"Question. Let $\left\{\varphi_{j}\right\}$ be a complete orthonormal system for $L^{2}(\mathbb{R}^{d})$ such that each $\varphi_{j}\in C_{b}(\mathbb{R}^{d})$ (the space of continuous, bounded functions). Let $f\geq 0\in L^{1}(\mathbb{R}^{d})$ and suppose that $$\sum_{j=1}^{\infty}\left|\langle{f,\varphi_{j}}\rangle\right|^{2}<\infty \tag{*}$$ Does it follow that $f\in L^{2}(\mathbb{R}^{d})$ and therefore $f=\sum_{j}\langle{f,\varphi_{j}}\rangle\varphi_{j}$? This question is motivated by the one asked here by someone else, but for which I have offered a bounty. I am trying to consider a simpler version of the problem in the linked question. I've tried playing around with approximation arguments (i.e. construct a sequence $f_{n}\in L^{2}(\mathbb{R}^{d})$ which converges to $f$ in some sense) but I run into problems in trying to use (*) to control $\left\|f_{n}\right\|_{L^{2}}$. For instance, if we could produce a sequence $f_{n}\rightarrow f$ in $L^{1}(\mathbb{R}^{d})$ such that $\sup_{n}\left\|f_{n}\right\|_{L^{2}}<\infty$, then there would exist $g\in L^{2}(\mathbb{R}^{d})$ and a subsequence $f_{n_{k}}\rightarrow g$ weakly in $L^{2}(\mathbb{R}^{d})$. It then follows that $f=g\in L^{2}(\mathbb{R}^{d})$. Any help would for this question, as well as the linked one, would be great. Update: The question linked to appears to have answered negatively by David C. Ullrich.","Question. Let $\left\{\varphi_{j}\right\}$ be a complete orthonormal system for $L^{2}(\mathbb{R}^{d})$ such that each $\varphi_{j}\in C_{b}(\mathbb{R}^{d})$ (the space of continuous, bounded functions). Let $f\geq 0\in L^{1}(\mathbb{R}^{d})$ and suppose that $$\sum_{j=1}^{\infty}\left|\langle{f,\varphi_{j}}\rangle\right|^{2}<\infty \tag{*}$$ Does it follow that $f\in L^{2}(\mathbb{R}^{d})$ and therefore $f=\sum_{j}\langle{f,\varphi_{j}}\rangle\varphi_{j}$? This question is motivated by the one asked here by someone else, but for which I have offered a bounty. I am trying to consider a simpler version of the problem in the linked question. I've tried playing around with approximation arguments (i.e. construct a sequence $f_{n}\in L^{2}(\mathbb{R}^{d})$ which converges to $f$ in some sense) but I run into problems in trying to use (*) to control $\left\|f_{n}\right\|_{L^{2}}$. For instance, if we could produce a sequence $f_{n}\rightarrow f$ in $L^{1}(\mathbb{R}^{d})$ such that $\sup_{n}\left\|f_{n}\right\|_{L^{2}}<\infty$, then there would exist $g\in L^{2}(\mathbb{R}^{d})$ and a subsequence $f_{n_{k}}\rightarrow g$ weakly in $L^{2}(\mathbb{R}^{d})$. It then follows that $f=g\in L^{2}(\mathbb{R}^{d})$. Any help would for this question, as well as the linked one, would be great. Update: The question linked to appears to have answered negatively by David C. Ullrich.",,"['functional-analysis', 'measure-theory', 'hilbert-spaces', 'orthonormal']"
36,"Show $ \langle Tx,x \rangle \in \Bbb R\ \forall x \in H\ \implies T$ is self-adjoint",Show  is self-adjoint," \langle Tx,x \rangle \in \Bbb R\ \forall x \in H\ \implies T","Show that a linear operator $T: H \to H$ is self adjoint if and only if $\langle Tx, x \rangle \in \Bbb R\ \forall x \in H$ . You may use that the equality that for all $x,y \in H$ $4\langle T(x),y \rangle = \langle T(x+y),x+y \rangle - \langle T(x-y),x-y \rangle + i\langle T(x+iy), x+iy \rangle -i\langle T(x-iy),x-iy \rangle$ without proof. I can show the forward implication quite easily: If $T$ is self adjoint, then $T = T^*$ so $ \langle Tx,x \rangle = \langle x,Tx \rangle = \overline{\langle Tx,x \rangle}$ Only real values are equal to their conjugate so this show $ \langle Tx,x \rangle \in \mathbb R$ for all $x \in H$ . However, I am having trouble showing the other direction holds. I've tried using the parallelogram identity and then equating real parts but to little avail. I am wondering how to go about this.","Show that a linear operator is self adjoint if and only if . You may use that the equality that for all without proof. I can show the forward implication quite easily: If is self adjoint, then so Only real values are equal to their conjugate so this show for all . However, I am having trouble showing the other direction holds. I've tried using the parallelogram identity and then equating real parts but to little avail. I am wondering how to go about this.","T: H \to H \langle Tx, x \rangle \in \Bbb R\ \forall x \in H x,y \in H 4\langle T(x),y \rangle = \langle T(x+y),x+y \rangle - \langle T(x-y),x-y \rangle + i\langle T(x+iy), x+iy \rangle -i\langle T(x-iy),x-iy \rangle T T = T^*  \langle Tx,x \rangle = \langle x,Tx \rangle = \overline{\langle Tx,x \rangle}  \langle Tx,x \rangle \in \mathbb R x \in H","['functional-analysis', 'hilbert-spaces', 'inner-products', 'adjoint-operators']"
37,Why is semi-norm special and preferred?,Why is semi-norm special and preferred?,,"One difference between semi-norm and norm is: ""It is possible for $\|v\| = 0$  for nonzero v, $\|\cdot\|$ being semi-norm"" I see some papers, and they use semi-norm directly. Why is semi-norm better than norm? Any simple example or concrete example?","One difference between semi-norm and norm is: ""It is possible for $\|v\| = 0$  for nonzero v, $\|\cdot\|$ being semi-norm"" I see some papers, and they use semi-norm directly. Why is semi-norm better than norm? Any simple example or concrete example?",,"['functional-analysis', 'normed-spaces']"
38,Closed subspace of a reflexive Banach space is reflexive,Closed subspace of a reflexive Banach space is reflexive,,"I'm studying Conway's functional Analysis by myself. In page 132 of his book, for showing every Closed subspace M of a reflexive Banach space X is reflexive, he says $\sigma(X,X^*)_{|_{M}}=\sigma(M,M^*)$. But I can not understand how it is. Please regard me.  Thanks in advance","I'm studying Conway's functional Analysis by myself. In page 132 of his book, for showing every Closed subspace M of a reflexive Banach space X is reflexive, he says $\sigma(X,X^*)_{|_{M}}=\sigma(M,M^*)$. But I can not understand how it is. Please regard me.  Thanks in advance",,"['functional-analysis', 'banach-spaces']"
39,How to make sense of Fourier series for a distribution?,How to make sense of Fourier series for a distribution?,,"In particular if I have an array of numbers say, $\{c_m\}_{m\in\mathbb{Z}^n}$. Under what conditions can we say that these are the Fourier coefficients of a distribution? [For examples Bessel's inequality ($\sum_{m\in\mathbb{Z}^n}|c_m|^2<\infty$) tells us these that these are the Fourier coefficients of an $L^2$ function.]","In particular if I have an array of numbers say, $\{c_m\}_{m\in\mathbb{Z}^n}$. Under what conditions can we say that these are the Fourier coefficients of a distribution? [For examples Bessel's inequality ($\sum_{m\in\mathbb{Z}^n}|c_m|^2<\infty$) tells us these that these are the Fourier coefficients of an $L^2$ function.]",,"['functional-analysis', 'measure-theory', 'fourier-analysis', 'fourier-series', 'distribution-theory']"
40,"$C^{1}[a,b]$ equipped with the norm given by $\lVert x\rVert _{\infty} = \sup_{t\in [0, 1]} \lvert x(t) \rvert$ is an incomplete normed space.",equipped with the norm given by  is an incomplete normed space.,"C^{1}[a,b] \lVert x\rVert _{\infty} = \sup_{t\in [0, 1]} \lvert x(t) \rvert","I have to show that the real linear space $C^{1}[a,b]$ of all continuously differential functions defined on $[0, 1]$ equipped with the norm given by $\lVert x\rVert _{\infty} = \sup_{t\in [0, 1]} \lvert x(t) \rvert$ is an incomplete normed space. I have taken sequence $\{x_{n}\} = \sqrt{t^2 +\frac{1}{n}}$ in $C^{1}[a,b]$. Please tell me whether my procedure to show that $\{x_{n}\}$ is Cauchy in $C^{1}[a,b]$ is correct or not. Here is my attempt. Let $n \geq m$ $\lVert x_n - x_m\rVert  = \lVert \sqrt{t^2 +\frac{1}{n}} - \sqrt{t^2 +\frac{1}{m}}\rVert   = \frac { \frac{1}{n} - \frac{1}{m}}{\sqrt{t^2 +\frac{1}{n}} + \sqrt{t^2 +\frac{1}{m}}}\leq \frac{1}{n} +  \frac{1}{m} \leq \frac{1}{2m}\leq \frac{1}{m} \leq \epsilon $ Further I have shown that $\{x_{n}\}$ converges pointwise to $x(t) =  \frac{1}{\sqrt n}$. But $x(t)$ is not differentiable at $t = 0$ and hence the proof. Also could anybody provide me any other example? Thanks.","I have to show that the real linear space $C^{1}[a,b]$ of all continuously differential functions defined on $[0, 1]$ equipped with the norm given by $\lVert x\rVert _{\infty} = \sup_{t\in [0, 1]} \lvert x(t) \rvert$ is an incomplete normed space. I have taken sequence $\{x_{n}\} = \sqrt{t^2 +\frac{1}{n}}$ in $C^{1}[a,b]$. Please tell me whether my procedure to show that $\{x_{n}\}$ is Cauchy in $C^{1}[a,b]$ is correct or not. Here is my attempt. Let $n \geq m$ $\lVert x_n - x_m\rVert  = \lVert \sqrt{t^2 +\frac{1}{n}} - \sqrt{t^2 +\frac{1}{m}}\rVert   = \frac { \frac{1}{n} - \frac{1}{m}}{\sqrt{t^2 +\frac{1}{n}} + \sqrt{t^2 +\frac{1}{m}}}\leq \frac{1}{n} +  \frac{1}{m} \leq \frac{1}{2m}\leq \frac{1}{m} \leq \epsilon $ Further I have shown that $\{x_{n}\}$ converges pointwise to $x(t) =  \frac{1}{\sqrt n}$. But $x(t)$ is not differentiable at $t = 0$ and hence the proof. Also could anybody provide me any other example? Thanks.",,"['functional-analysis', 'banach-spaces']"
41,Products in the category of normed linear spaces,Products in the category of normed linear spaces,,"I have tried to formulate the notion of products myself and this is what I came up with: Let $(X_i, |*|_i), i\in I$ be a collection of normed linear spaces and $f_i:Y\to X_i$ a collection of bounded linear maps, all index by the set $I$. As long as $I$ is a finit set we can factor all maps in the following way: $Y\overset{\triangle}{\to}\prod_{I}Y\overset{\prod_{i\in I} f_i}{\to}\prod_{i\in I}X_i\overset{p_i}{\to}X_i$ where the norm on the products is given by: $|x|=\underset{i\in I}{sup}(|x_i|_i)$ As can be seen this is a close relative to $l^\infty$. We can formulate the notion of coproducts in the dual way and get something similiar to $l^1$, but only with finit sums. $|x|=\sum_{i\in I}|x_i|_i$ I originally choose the supremum norm (on the product) so that it would work with infinite products, I am, however, no longer sure. I wanted to use the definiton above to illuminate the difference between the weak topology and weak convergence. To start I imagine we are in the following position: $X\overset{\triangle}{\to}\prod_{X'}X\overset{\prod_{\lambda\in X'} \lambda}{\to}\prod_{X'}\mathbb{R}\overset{p_i}{\to}\mathbb{R}$ The weak topology on $Y$ can be obtained as the coarsest topology where $(\prod_{\lambda\in X'}\lambda)\triangle$ is continuous with respect to the product topology in $\prod_{X'}\mathbb{R}$ while weak convergence correspondes to the product norm defined above, which correspondes to the box topology. Now for the objects this seem to be working out fairly well but it occurs to me that $(\prod_{\lambda\in X'}\lambda)\triangle$ need not be bounded, infact as long as X' isn't uniformly bounded it won't. So now I'm hoping that I did something wrong. I really want the category of normed vectorspaces to have infinit products and it makes me a bit sad to think it might not. Alternatively this is why the ideas of uniform boundedness are so important and I need to incorporate these somehow. I read about them but I honestly didnt get thier significanse at the time and I can't really see thier place in the big picture. Any help in that regard would also be very appreaciated. I apologice if the question is to vague to be a proper StackExchange question.","I have tried to formulate the notion of products myself and this is what I came up with: Let $(X_i, |*|_i), i\in I$ be a collection of normed linear spaces and $f_i:Y\to X_i$ a collection of bounded linear maps, all index by the set $I$. As long as $I$ is a finit set we can factor all maps in the following way: $Y\overset{\triangle}{\to}\prod_{I}Y\overset{\prod_{i\in I} f_i}{\to}\prod_{i\in I}X_i\overset{p_i}{\to}X_i$ where the norm on the products is given by: $|x|=\underset{i\in I}{sup}(|x_i|_i)$ As can be seen this is a close relative to $l^\infty$. We can formulate the notion of coproducts in the dual way and get something similiar to $l^1$, but only with finit sums. $|x|=\sum_{i\in I}|x_i|_i$ I originally choose the supremum norm (on the product) so that it would work with infinite products, I am, however, no longer sure. I wanted to use the definiton above to illuminate the difference between the weak topology and weak convergence. To start I imagine we are in the following position: $X\overset{\triangle}{\to}\prod_{X'}X\overset{\prod_{\lambda\in X'} \lambda}{\to}\prod_{X'}\mathbb{R}\overset{p_i}{\to}\mathbb{R}$ The weak topology on $Y$ can be obtained as the coarsest topology where $(\prod_{\lambda\in X'}\lambda)\triangle$ is continuous with respect to the product topology in $\prod_{X'}\mathbb{R}$ while weak convergence correspondes to the product norm defined above, which correspondes to the box topology. Now for the objects this seem to be working out fairly well but it occurs to me that $(\prod_{\lambda\in X'}\lambda)\triangle$ need not be bounded, infact as long as X' isn't uniformly bounded it won't. So now I'm hoping that I did something wrong. I really want the category of normed vectorspaces to have infinit products and it makes me a bit sad to think it might not. Alternatively this is why the ideas of uniform boundedness are so important and I need to incorporate these somehow. I read about them but I honestly didnt get thier significanse at the time and I can't really see thier place in the big picture. Any help in that regard would also be very appreaciated. I apologice if the question is to vague to be a proper StackExchange question.",,"['functional-analysis', 'category-theory']"
42,When is the composition operator assigned to a measure-preserving map unitary?,When is the composition operator assigned to a measure-preserving map unitary?,,"Let $(X,\mathcal{B},\mu)$ be a standard probability space, and let $T:X\rightarrow X$ be a measurable, measure-preserving transformation, i.e. for every $A\in\mathcal{B}$, $\mu(T^{-1}(A))=\mu(A)$. Consider the operator $U_T:L_2(\mu)\rightarrow L_2(\mu)$ given by $U_T (f)=f\circ T$. Clearly it is a linear isometry. My question is whether $U_T$ is unitary.","Let $(X,\mathcal{B},\mu)$ be a standard probability space, and let $T:X\rightarrow X$ be a measurable, measure-preserving transformation, i.e. for every $A\in\mathcal{B}$, $\mu(T^{-1}(A))=\mu(A)$. Consider the operator $U_T:L_2(\mu)\rightarrow L_2(\mu)$ given by $U_T (f)=f\circ T$. Clearly it is a linear isometry. My question is whether $U_T$ is unitary.",,"['functional-analysis', 'measure-theory', 'ergodic-theory']"
43,Does weak convergence in Sobolev spaces imply pointwise convergence?,Does weak convergence in Sobolev spaces imply pointwise convergence?,,"I encounter a problem when reading Struwe's book Variational Methods (4th ed). On page 38, it is assumed that  $\|u_m\|$ is a minimizing sequence for a functional $E$, i.e. $E(u_m)\rightharpoonup I$ in $L^p(\mathbb{R}^n)$, and then it assume in addition that $u_m\rightharpoonup u$ weakly in $H^{1,2}(\mathbb{R}^n)$ and pointwise almost everywhere. My question is why the pointwise convergence assumption is reasonable?  Since $\mathbb R^n$ is not compact, the embedding theorem is not obviously valid. Thanks in advance.","I encounter a problem when reading Struwe's book Variational Methods (4th ed). On page 38, it is assumed that  $\|u_m\|$ is a minimizing sequence for a functional $E$, i.e. $E(u_m)\rightharpoonup I$ in $L^p(\mathbb{R}^n)$, and then it assume in addition that $u_m\rightharpoonup u$ weakly in $H^{1,2}(\mathbb{R}^n)$ and pointwise almost everywhere. My question is why the pointwise convergence assumption is reasonable?  Since $\mathbb R^n$ is not compact, the embedding theorem is not obviously valid. Thanks in advance.",,"['functional-analysis', 'sobolev-spaces']"
44,Is this operator compact?,Is this operator compact?,,"Suppose ($x_n$) is a normalized, linearly independent,  sequence in a reflexive Banach space $X$, and $T$ is an injective, strictly singular,  bounded operator on $X$ such that $Tx_n\longrightarrow 0$. Does there exist a subsequence $(y_n)$ of $(x_n)$ such that $T$ restricted to the closed span of $(y_n)$ is compact? When $(x_n)$ is a basic sequence and $\sum||Tx_n||$ converges (so $Tx_n\longrightarrow 0$ fast enough), it is not hard to show that $T$ restricted to closed span of $(x_n)$ is indeed compact (without any need to assume that $T$ is strictly singular or $X$ is reflexive). An operator is called strictly singular if it is not an isomorphism when restricted to any infinite dimensional subspace. Compact operators are always strictly singular but not the other way around. However, strictly singular are compact in $l_p$  and $c_0$.","Suppose ($x_n$) is a normalized, linearly independent,  sequence in a reflexive Banach space $X$, and $T$ is an injective, strictly singular,  bounded operator on $X$ such that $Tx_n\longrightarrow 0$. Does there exist a subsequence $(y_n)$ of $(x_n)$ such that $T$ restricted to the closed span of $(y_n)$ is compact? When $(x_n)$ is a basic sequence and $\sum||Tx_n||$ converges (so $Tx_n\longrightarrow 0$ fast enough), it is not hard to show that $T$ restricted to closed span of $(x_n)$ is indeed compact (without any need to assume that $T$ is strictly singular or $X$ is reflexive). An operator is called strictly singular if it is not an isomorphism when restricted to any infinite dimensional subspace. Compact operators are always strictly singular but not the other way around. However, strictly singular are compact in $l_p$  and $c_0$.",,"['functional-analysis', 'banach-spaces', 'operator-theory']"
45,$\ell^1$ vs. continuous dual of $\ell^{\infty}$ in ZF+AD,vs. continuous dual of  in ZF+AD,\ell^1 \ell^{\infty},Let the base field be the real numbers or the complex numbers (I don't think it will matter). Let $(\ell^{\infty})'$ be the continuous dual of the Banach space $\ell^{\infty}$. Let $\: f : \ell^1 \to (\ell^{\infty})' \:$ be the obvious embedding. Does ZF+ AD prove that $f$ is surjective? Does ZF+ DC +AD prove that $f$ is surjective?,Let the base field be the real numbers or the complex numbers (I don't think it will matter). Let $(\ell^{\infty})'$ be the continuous dual of the Banach space $\ell^{\infty}$. Let $\: f : \ell^1 \to (\ell^{\infty})' \:$ be the obvious embedding. Does ZF+ AD prove that $f$ is surjective? Does ZF+ DC +AD prove that $f$ is surjective?,,['functional-analysis']
46,On the limits of weakly convergent subsequences,On the limits of weakly convergent subsequences,,"Let $\{ f_n \}$ be a sequence in a Hilbert space $L^2(\mathbb{R}^d)$. We say that this sequence converges weakly to an element $f \in L^2$ if $\langle f_n, g \rangle \to \langle f,g \rangle$ for every $g \in L^2$ (where $\langle \cdot,\cdot \rangle$ denotes the inner product on $L^2$). By definition, we are given that the weak limit $f$ is in $L^2$. However, suppose we know that a sequence ""formally"" converges weakly to a limit $f$ (i.e. $\langle f_n, g \rangle \to \langle f,g \rangle$ for every $g \in L^2$ for some $f$ which we don't necessarily know yet to be in $L^2$) . Does this, purely by the characteristics of weak convergence, directly imply that $f \in L^2$? I think you could also generalize this question to any Hilbert space, provided that taking the inner product of an element possibly not in the Hilbert space makes sense.","Let $\{ f_n \}$ be a sequence in a Hilbert space $L^2(\mathbb{R}^d)$. We say that this sequence converges weakly to an element $f \in L^2$ if $\langle f_n, g \rangle \to \langle f,g \rangle$ for every $g \in L^2$ (where $\langle \cdot,\cdot \rangle$ denotes the inner product on $L^2$). By definition, we are given that the weak limit $f$ is in $L^2$. However, suppose we know that a sequence ""formally"" converges weakly to a limit $f$ (i.e. $\langle f_n, g \rangle \to \langle f,g \rangle$ for every $g \in L^2$ for some $f$ which we don't necessarily know yet to be in $L^2$) . Does this, purely by the characteristics of weak convergence, directly imply that $f \in L^2$? I think you could also generalize this question to any Hilbert space, provided that taking the inner product of an element possibly not in the Hilbert space makes sense.",,['functional-analysis']
47,What is the derivative of the derivative?,What is the derivative of the derivative?,,"If we consider the derivative as a function from a function space to function space, then does it make sense to talk about the derivative of the derivative? In particular, if we consider $$D:C^\infty[\mathbb{R}]\to C^\infty[\mathbb{R}]$$ and arbitrary smooth function $f\in C^\infty[\mathbb{R}]$ , then can we reasonably ask if there is some other function on smooth real functions given by the following? $$\frac{d}{df}[Df]$$ I've tried to do this myself with limits, where we take an arbitrary smooth function $u$ that approaches the constant function of $0$ . In particular, I found that $$\lim_{u\to 0}\frac{D(f+u)-D(f)}{u}=\lim_{u\to 0}\frac{f'+u'-f'}{u}=\lim_{u\to 0}\frac{u'}{u}.$$ But I'm not sure if that approaches any particular value independent of $u$ 's path toward $0$ . However, plugging in $u = 0$ does indeed result in an indeterminant form, which leads me to suspect that there is a way of solving this. Instinctually, I think that this value should be $1$ both due to $D$ being considered linear, and applying L'Hopital's rule infinitely many times would result in $$\lim_{u\to 0}\frac{u'}{u} = \lim_{u\to 0}\lim_{n\to\infty}\frac{u^{(n+1)}}{u^{(n)}}=\lim_{u\to 0}\lim_{n\to\infty}\frac{u^{(n)}}{u^{(n)}}=\lim_{u\to 0}\lim_{n\to\infty}1=1$$ But this does not seem particularly rigorous. Does my question even make sense and if it is, is there a rigorous way of finding the solution? Edit: To add to the confusion, if we treat deriving with respect to a function as we do in $\mathbb{R}$ , we find that $$ \frac{d}{df}[Df] = \frac{df'}{dx}\frac{dx}{df}=\frac{f''}{f'}$$ Which I'm pretty sure is not quite the same as differentiating with respect to the function itself, but I don't fully understand why it would be different.","If we consider the derivative as a function from a function space to function space, then does it make sense to talk about the derivative of the derivative? In particular, if we consider and arbitrary smooth function , then can we reasonably ask if there is some other function on smooth real functions given by the following? I've tried to do this myself with limits, where we take an arbitrary smooth function that approaches the constant function of . In particular, I found that But I'm not sure if that approaches any particular value independent of 's path toward . However, plugging in does indeed result in an indeterminant form, which leads me to suspect that there is a way of solving this. Instinctually, I think that this value should be both due to being considered linear, and applying L'Hopital's rule infinitely many times would result in But this does not seem particularly rigorous. Does my question even make sense and if it is, is there a rigorous way of finding the solution? Edit: To add to the confusion, if we treat deriving with respect to a function as we do in , we find that Which I'm pretty sure is not quite the same as differentiating with respect to the function itself, but I don't fully understand why it would be different.",D:C^\infty[\mathbb{R}]\to C^\infty[\mathbb{R}] f\in C^\infty[\mathbb{R}] \frac{d}{df}[Df] u 0 \lim_{u\to 0}\frac{D(f+u)-D(f)}{u}=\lim_{u\to 0}\frac{f'+u'-f'}{u}=\lim_{u\to 0}\frac{u'}{u}. u 0 u = 0 1 D \lim_{u\to 0}\frac{u'}{u} = \lim_{u\to 0}\lim_{n\to\infty}\frac{u^{(n+1)}}{u^{(n)}}=\lim_{u\to 0}\lim_{n\to\infty}\frac{u^{(n)}}{u^{(n)}}=\lim_{u\to 0}\lim_{n\to\infty}1=1 \mathbb{R}  \frac{d}{df}[Df] = \frac{df'}{dx}\frac{dx}{df}=\frac{f''}{f'},"['functional-analysis', 'limits', 'derivatives', 'smooth-functions']"
48,How to define derivatives in Wasserstein space,How to define derivatives in Wasserstein space,,"Let $M$ be a Polish space equipped with a metric $d$ . Let $p\geq 1$ . The $p^{th}$ Wasserstein distance between $\mu,\nu \in \mathcal P_p(M)$ (the space of Borel measures on $M$ with finite $p$ moments) is $$ W_{p}(\mu, \nu):=\left(\inf _{\pi \in \Pi(\mu, \nu)} \int_{M \times M} d(x, y)^{p} \mathrm{d} \pi(x, y)\right)^{1 / p}.$$ $(P_p(M), W_{p})$ is a metric space called the $p^{th}$ Wasserstein space. How do we define a derivative of a functional $$F: (P_p(M), W_{p}) \rightarrow \mathbb R ?$$ The Wasserstein space is not a normed vector space, so the Fréchet derivative does not make sense. A particular functional I am interested in is $F(\mu)=W_{p}(\mu, \delta_0)$ . People do study gradient flows in Wasserstein spaces so a rigorous definition must exist. Is this related to metric derivatives ?","Let be a Polish space equipped with a metric . Let . The Wasserstein distance between (the space of Borel measures on with finite moments) is is a metric space called the Wasserstein space. How do we define a derivative of a functional The Wasserstein space is not a normed vector space, so the Fréchet derivative does not make sense. A particular functional I am interested in is . People do study gradient flows in Wasserstein spaces so a rigorous definition must exist. Is this related to metric derivatives ?","M d p\geq 1 p^{th} \mu,\nu \in \mathcal P_p(M) M p 
W_{p}(\mu, \nu):=\left(\inf _{\pi \in \Pi(\mu, \nu)} \int_{M \times M} d(x, y)^{p} \mathrm{d} \pi(x, y)\right)^{1 / p}. (P_p(M), W_{p}) p^{th} F: (P_p(M), W_{p}) \rightarrow \mathbb R ? F(\mu)=W_{p}(\mu, \delta_0)","['functional-analysis', 'probability-theory', 'measure-theory', 'derivatives', 'metric-spaces']"
49,derivative of the $L^p$-norm with respect to $p$,derivative of the -norm with respect to,L^p p,"Let $\Omega$ be a probability space (or a finite measure space) and $f : \Omega \to \mathbb{R}$ be a positive function of $L^p(\Omega)$ with $f>0$ . We suppose that $\|f\|_{L^1(\Omega)}=1$ . What is the derivative $\frac{d}{d p}|_{p=1} \|f\|_p$ at the point 1 of the function $p \mapsto \|f\|_p$ defined on $[1,+\infty)$ ? My feeling is that the answer is maybe $-\int_{\Omega} f\log f$ . Same question with $\ell^p$ instead of $L^p(\Omega)$ with a sequence $(a_k)$ of $\ell^1$ with $a_k >0$ for any $k$ and $\|a\|_{\ell^1}=1$ . I believe that there is a difference between the two cases since if $q<p$ we have $L^p \subset L^q$ in the first case and $\ell^q \subset \ell^p$ in the second case.",Let be a probability space (or a finite measure space) and be a positive function of with . We suppose that . What is the derivative at the point 1 of the function defined on ? My feeling is that the answer is maybe . Same question with instead of with a sequence of with for any and . I believe that there is a difference between the two cases since if we have in the first case and in the second case.,"\Omega f : \Omega \to \mathbb{R} L^p(\Omega) f>0 \|f\|_{L^1(\Omega)}=1 \frac{d}{d p}|_{p=1} \|f\|_p p \mapsto \|f\|_p [1,+\infty) -\int_{\Omega} f\log f \ell^p L^p(\Omega) (a_k) \ell^1 a_k >0 k \|a\|_{\ell^1}=1 q<p L^p \subset L^q \ell^q \subset \ell^p","['functional-analysis', 'measure-theory', 'derivatives', 'lp-spaces', 'entropy']"
50,Prove that linear operator A has a nonzero kernel.,Prove that linear operator A has a nonzero kernel.,,"H is a separable Hilbert space, E is an inseparable Hilbert space, A is a continuous linear operator from E to the space L (H) of continuous operators on H with an operator norm. $A:E\to L(H).$ Prove that A has a nonzero kernel. Please help","H is a separable Hilbert space, E is an inseparable Hilbert space, A is a continuous linear operator from E to the space L (H) of continuous operators on H with an operator norm. Prove that A has a nonzero kernel. Please help",A:E\to L(H).,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
51,"$T: L^2[0,1] \to L^2[0,1]$, $Tf(x)= \frac{1}{x}\int_{0}^x f(y)$, is a bounded but not compact operator.",", , is a bounded but not compact operator.","T: L^2[0,1] \to L^2[0,1] Tf(x)= \frac{1}{x}\int_{0}^x f(y)","To show that the image of $T$ lies in $L^2$ , and derive its bound, I tried the following: $$\|Tf\|_{2} = \left(\int|\int \frac{1}{x}f(y)dy|^2dx\right)^{\frac{1}{2}} \leq \int \sqrt{\int|\frac{1}{x}f(y)1_{[0,x]}(y)|^2dx}dy = \int_{0}^{1} \sqrt{ \frac{1}{y}-1 }|f(y)|.$$ Then probably using Holder's inequality, but this does not seem to work. Then to show it is not a compact operator, I want to construct a bounded sequence $f_n$ where $Tf_n$ does not have a convergent subsequence.","To show that the image of lies in , and derive its bound, I tried the following: Then probably using Holder's inequality, but this does not seem to work. Then to show it is not a compact operator, I want to construct a bounded sequence where does not have a convergent subsequence.","T L^2 \|Tf\|_{2} = \left(\int|\int \frac{1}{x}f(y)dy|^2dx\right)^{\frac{1}{2}} \leq \int \sqrt{\int|\frac{1}{x}f(y)1_{[0,x]}(y)|^2dx}dy = \int_{0}^{1} \sqrt{ \frac{1}{y}-1 }|f(y)|. f_n Tf_n","['functional-analysis', 'operator-theory', 'lp-spaces', 'compact-operators']"
52,Is weak operator topology (WOT) limit of unitary operators isometry?,Is weak operator topology (WOT) limit of unitary operators isometry?,,"Let $(U_{\alpha})$ be net of unitary operator in $B\mathcal{(H)}$ s.t. $U_{\alpha} \xrightarrow {\text{WOT}}V$.Can we conclude that V is an isometry? If it be not true give a counter example. Comments : I observe that if $U_{\alpha} \xrightarrow {\text{SOT}}V$ then V is necessarily isometry. But I could not able to justify the statement for weak operator topology case neither by proving nor by giving counter example. Notations : $U_{\alpha} \xrightarrow {\text{WOT}}V$ means $\langle U_{\alpha}x,y\rangle\rightarrow\langle Vx,y\rangle$ for all x,y $\in\mathcal{H}$, $U_{\alpha} \xrightarrow {\text{SOT}}V$ means $\Vert  U_{\alpha}x\Vert\rightarrow\Vert Vx\Vert$ for all x$\in \mathcal{H}$ and $\mathcal{H}$ is a Hilbert Space. Any comment regarding proving the statement or giving counter example is highly appreciated.Thanks in advance.","Let $(U_{\alpha})$ be net of unitary operator in $B\mathcal{(H)}$ s.t. $U_{\alpha} \xrightarrow {\text{WOT}}V$.Can we conclude that V is an isometry? If it be not true give a counter example. Comments : I observe that if $U_{\alpha} \xrightarrow {\text{SOT}}V$ then V is necessarily isometry. But I could not able to justify the statement for weak operator topology case neither by proving nor by giving counter example. Notations : $U_{\alpha} \xrightarrow {\text{WOT}}V$ means $\langle U_{\alpha}x,y\rangle\rightarrow\langle Vx,y\rangle$ for all x,y $\in\mathcal{H}$, $U_{\alpha} \xrightarrow {\text{SOT}}V$ means $\Vert  U_{\alpha}x\Vert\rightarrow\Vert Vx\Vert$ for all x$\in \mathcal{H}$ and $\mathcal{H}$ is a Hilbert Space. Any comment regarding proving the statement or giving counter example is highly appreciated.Thanks in advance.",,"['functional-analysis', 'operator-theory']"
53,"Is the dual to $C^1[0,1]$ separable?",Is the dual to  separable?,"C^1[0,1]","$C^1[0,1]$ is endowed with the norm $\|f\| = \sup_{t \in [0,1]}|f| + \sup_{t \in [0,1]}|f'| $. I need to check if its dual $(C^1[0,1])^*$ is separable (I hope it is not). I am asking for the answer and the idea of proof.","$C^1[0,1]$ is endowed with the norm $\|f\| = \sup_{t \in [0,1]}|f| + \sup_{t \in [0,1]}|f'| $. I need to check if its dual $(C^1[0,1])^*$ is separable (I hope it is not). I am asking for the answer and the idea of proof.",,"['functional-analysis', 'dual-spaces', 'separable-spaces']"
54,Norm of operator in a Hilbert space,Norm of operator in a Hilbert space,,"Consider a complex Hilbert space $H$ and an operator $T\in\mathcal{L}(H,H)$. Define $$\|T\|=\sup_{\|x\|=\|y\|=1}\lvert\langle Tx, y\rangle\rvert$$, $$\||T|\|=\sup_{\|x\|=1}\lvert\langle Tx,x\rangle\rvert$$ Can you find an example of a complex Hilbert space $H$ and an operator $T$ such that $\|T\|=2\||T|\|$. I've been thinking about it and I can't find it.","Consider a complex Hilbert space $H$ and an operator $T\in\mathcal{L}(H,H)$. Define $$\|T\|=\sup_{\|x\|=\|y\|=1}\lvert\langle Tx, y\rangle\rvert$$, $$\||T|\|=\sup_{\|x\|=1}\lvert\langle Tx,x\rangle\rvert$$ Can you find an example of a complex Hilbert space $H$ and an operator $T$ such that $\|T\|=2\||T|\|$. I've been thinking about it and I can't find it.",,"['functional-analysis', 'hilbert-spaces']"
55,Turning a semi-norm into a norm,Turning a semi-norm into a norm,,"Let $(F,\|\cdot\|)$ be a semi-normed space, such that the kernel $E$ of $\|\cdot\|$ is finitely dimensional. Then $F/ E$ is a normed space and $E$ has a unique Hausdorff locally convex topology, since it is finitely-dimensional. I want to generate a topology on $F$ from this data by identifying it with $F/E\oplus E$. Is there any canonical choice of this identification? Alternatively one can take an algebraic complement $H$ of $E$. Then $(H,\|\cdot\|)$ is a normed space, and taking an arbitrary norm on $E$ we get a norm on $F=E+H$. Off-course this norm depends on the choice of $H$, but perhaps all such norms are equivalent. Does the topology on $F$ constructed as above depends on the choice of $H$?","Let $(F,\|\cdot\|)$ be a semi-normed space, such that the kernel $E$ of $\|\cdot\|$ is finitely dimensional. Then $F/ E$ is a normed space and $E$ has a unique Hausdorff locally convex topology, since it is finitely-dimensional. I want to generate a topology on $F$ from this data by identifying it with $F/E\oplus E$. Is there any canonical choice of this identification? Alternatively one can take an algebraic complement $H$ of $E$. Then $(H,\|\cdot\|)$ is a normed space, and taking an arbitrary norm on $E$ we get a norm on $F=E+H$. Off-course this norm depends on the choice of $H$, but perhaps all such norms are equivalent. Does the topology on $F$ constructed as above depends on the choice of $H$?",,"['functional-analysis', 'normed-spaces', 'topological-vector-spaces']"
56,An Element in a C$^{*}$-algebra that is Almost a Projection is Close to a Projection,An Element in a C-algebra that is Almost a Projection is Close to a Projection,^{*},"Let $A$ be a C$^{*}$-algebra and let $\epsilon>0$ be given. I am trying to solve the following problem (Exercise 2.7. in Rordam's little blue book): Show that there exists a $\delta>0$ with the following property: If $a\in A$ and $\|a-a^{*}\|\leq\delta$ and $\|a-a^{2}\|\leq \delta$, then there is a projection $p$ such that $\|a-p\|\leq \epsilon$. Following the hint, we assume that $\epsilon <1/2$ and set $b=\frac{a+a^{*}}{2}$. Then, it is not hard to see that $\sigma(b)\subset[-\epsilon,\epsilon]\cup[1-\epsilon,1+\epsilon]$ provided that $\|b-b^{2}\|\leq\epsilon-\epsilon^{2}$. The hint suggests to put $p:= f(b)$ for some continuous function $f$. Since we are assuming $\epsilon<1/2$, $\sigma(b)$ is disconnected, so I was thinking to make $f$ identically $0$ on $[-\epsilon,\epsilon]$ and identically $1$ on $[1-\epsilon,1+\epsilon]$ or vice-versa. Then, by the Spectral Mapping Theorem, $p$ would be a projection. However, I'm not sure how to conclude that $\|a-p\|\leq \epsilon$, or if this is even the correct choice of $p$. Also, presumably the fact that $\|b-b^{2}\|\leq\epsilon-\epsilon^{2}$, which we make use of follows from our choice of $\delta$ and the definition of $b$. However, in proving this, I came up with a $\delta$ in terms of $a$, but the way the question is asked suggests that the same $\delta$ should hold for all $a$ satisfying $\|a-a^{*}\|,\|a-a^{2}\|\leq\delta$. Is it possible to choose the $\delta$ independent of $a$? Thank you very much!","Let $A$ be a C$^{*}$-algebra and let $\epsilon>0$ be given. I am trying to solve the following problem (Exercise 2.7. in Rordam's little blue book): Show that there exists a $\delta>0$ with the following property: If $a\in A$ and $\|a-a^{*}\|\leq\delta$ and $\|a-a^{2}\|\leq \delta$, then there is a projection $p$ such that $\|a-p\|\leq \epsilon$. Following the hint, we assume that $\epsilon <1/2$ and set $b=\frac{a+a^{*}}{2}$. Then, it is not hard to see that $\sigma(b)\subset[-\epsilon,\epsilon]\cup[1-\epsilon,1+\epsilon]$ provided that $\|b-b^{2}\|\leq\epsilon-\epsilon^{2}$. The hint suggests to put $p:= f(b)$ for some continuous function $f$. Since we are assuming $\epsilon<1/2$, $\sigma(b)$ is disconnected, so I was thinking to make $f$ identically $0$ on $[-\epsilon,\epsilon]$ and identically $1$ on $[1-\epsilon,1+\epsilon]$ or vice-versa. Then, by the Spectral Mapping Theorem, $p$ would be a projection. However, I'm not sure how to conclude that $\|a-p\|\leq \epsilon$, or if this is even the correct choice of $p$. Also, presumably the fact that $\|b-b^{2}\|\leq\epsilon-\epsilon^{2}$, which we make use of follows from our choice of $\delta$ and the definition of $b$. However, in proving this, I came up with a $\delta$ in terms of $a$, but the way the question is asked suggests that the same $\delta$ should hold for all $a$ satisfying $\|a-a^{*}\|,\|a-a^{2}\|\leq\delta$. Is it possible to choose the $\delta$ independent of $a$? Thank you very much!",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'spectral-theory', 'c-star-algebras']"
57,Is the Entropy a Function or a Functional? [duplicate],Is the Entropy a Function or a Functional? [duplicate],,"This question already has answers here : Difference between functional and function. (3 answers) Closed 7 years ago . As in the title, I was wondering whether the entropy of a system (it can be any entropy, from Boltzmann to Renyi etc, it is of no importance) is a function or a functional and why? Since it is mostly defined as: $$S(p)=\sum_{i}g(p_i) $$ for some $g$ that has to be continous etc then it has to be a functional. But then I see that $S_{BG}$ for example, which is defined as $S_{BG}=\sum_i p_i \log p_i$ just needs the value of each $p_i$ in order to be defined, right? The way I see it, it has to be a functional but it is not clear to me why. Also many authors mention the entropy as a function while others call it a functional. Thank you!","This question already has answers here : Difference between functional and function. (3 answers) Closed 7 years ago . As in the title, I was wondering whether the entropy of a system (it can be any entropy, from Boltzmann to Renyi etc, it is of no importance) is a function or a functional and why? Since it is mostly defined as: $$S(p)=\sum_{i}g(p_i) $$ for some $g$ that has to be continous etc then it has to be a functional. But then I see that $S_{BG}$ for example, which is defined as $S_{BG}=\sum_i p_i \log p_i$ just needs the value of each $p_i$ in order to be defined, right? The way I see it, it has to be a functional but it is not clear to me why. Also many authors mention the entropy as a function while others call it a functional. Thank you!",,"['functional-analysis', 'mathematical-physics', 'entropy', 'statistical-mechanics']"
58,"In $C([0,1],\mathbb{R})$, the sup norm and the $L^1$ norm are not equivalent.","In , the sup norm and the  norm are not equivalent.","C([0,1],\mathbb{R}) L^1","How does the proof here show that the two norms are not equivalent? We have that in the sup norm $f_n$ converges to $1$, and in the $L^1$ norm $f_n$ converges to $0$, but how does this mean that the two norms are not equivalent?","How does the proof here show that the two norms are not equivalent? We have that in the sup norm $f_n$ converges to $1$, and in the $L^1$ norm $f_n$ converges to $0$, but how does this mean that the two norms are not equivalent?",,"['analysis', 'functional-analysis']"
59,Geometric Interpretation of Weak Derivative,Geometric Interpretation of Weak Derivative,,"As we know, classic derivative $f'(x)$ of a function $f(x)$ can be interpreted as the rate of change of function $f$ in each point $x.$ How about weak derivative? Since it is defined through integral and therefore not relevant in sets of zero measure, what does it mean for a function to have weak derivative? What can the weak derivative of a function explains about its function?","As we know, classic derivative $f'(x)$ of a function $f(x)$ can be interpreted as the rate of change of function $f$ in each point $x.$ How about weak derivative? Since it is defined through integral and therefore not relevant in sets of zero measure, what does it mean for a function to have weak derivative? What can the weak derivative of a function explains about its function?",,"['functional-analysis', 'sobolev-spaces', 'weak-derivatives']"
60,Constructing a Banach space of cardinality $\beth_{\omega+1}$,Constructing a Banach space of cardinality,\beth_{\omega+1},"This is related to yesterday's question Constructing a vector space of dimension $\beth_\omega$ ; it's the next exercise (I.13.35 (a)) in Kunen's Set Theory . Let $B_0 = \ell^1$ and let $B_{n+1} = B_n^{**}$ be the continuous second dual of $B_n$, so that we can consider $B_n$ as a subset of $B_{n+1}$ in the usual way.  Let $B$ be the completion of $\bigcup_n B_n$.  Show that $|B| = \beth_{\omega+1}$. I have managed to solve part (b) of the exercise, which says that any Banach space $X$ with $|X| \ge \beth_\omega$ actually has $|X| \ge \beth_{\omega+1}$.  So it will be enough to show $|B| \ge \beth_\omega$ (though given the ordering of the parts of the exercise, this may not be what Kunen had in mind). Presumably we should try to show that $|B_{n+1}| \ge 2^{|B_n|}$ or something similar.  But when working with continuous duals, I don't see how to do that.  Additionally, each step of the induction is somehow going to have to use the fact that we started with $B_0 = \ell^1$, since if $B_0$ had been a reflexive space, this would never work.  We also have to rule out the possibility that one of the later $B_n$ turns out to be reflexive. Any suggestions are welcome.","This is related to yesterday's question Constructing a vector space of dimension $\beth_\omega$ ; it's the next exercise (I.13.35 (a)) in Kunen's Set Theory . Let $B_0 = \ell^1$ and let $B_{n+1} = B_n^{**}$ be the continuous second dual of $B_n$, so that we can consider $B_n$ as a subset of $B_{n+1}$ in the usual way.  Let $B$ be the completion of $\bigcup_n B_n$.  Show that $|B| = \beth_{\omega+1}$. I have managed to solve part (b) of the exercise, which says that any Banach space $X$ with $|X| \ge \beth_\omega$ actually has $|X| \ge \beth_{\omega+1}$.  So it will be enough to show $|B| \ge \beth_\omega$ (though given the ordering of the parts of the exercise, this may not be what Kunen had in mind). Presumably we should try to show that $|B_{n+1}| \ge 2^{|B_n|}$ or something similar.  But when working with continuous duals, I don't see how to do that.  Additionally, each step of the induction is somehow going to have to use the fact that we started with $B_0 = \ell^1$, since if $B_0$ had been a reflexive space, this would never work.  We also have to rule out the possibility that one of the later $B_n$ turns out to be reflexive. Any suggestions are welcome.",,"['functional-analysis', 'set-theory', 'banach-spaces', 'cardinals']"
61,Can differential forms be generalized to (separable) Banach spaces?,Can differential forms be generalized to (separable) Banach spaces?,,"This thought occurred to me earlier and I'm surprised I hadn't considered it previously. I get the feeling that no meaningful generalization can occur in a non-separable Banach space but on the surface it seems like a meaningful generalization can be had if the Banach space is separable. Even if it's possible, convergence and other issues likely severely complicate the matter.","This thought occurred to me earlier and I'm surprised I hadn't considered it previously. I get the feeling that no meaningful generalization can occur in a non-separable Banach space but on the surface it seems like a meaningful generalization can be had if the Banach space is separable. Even if it's possible, convergence and other issues likely severely complicate the matter.",,"['functional-analysis', 'differential-forms']"
62,Fractional Sobolev embedding into $L^\infty$,Fractional Sobolev embedding into,L^\infty,"Are there any $t\in(0,1)$, $p\in[1,\infty)$ such that $W^{t,p}(\mathbb{R})$ is continuously embedded into $L^\infty(\mathbb{R})$?  I have been looking several literatures, but I have not yet found this out. Also, I am not familiar with proofs for Sobolev spaces. Can anyone give a reference on whether it can or cannot be done? Thank you.","Are there any $t\in(0,1)$, $p\in[1,\infty)$ such that $W^{t,p}(\mathbb{R})$ is continuously embedded into $L^\infty(\mathbb{R})$?  I have been looking several literatures, but I have not yet found this out. Also, I am not familiar with proofs for Sobolev spaces. Can anyone give a reference on whether it can or cannot be done? Thank you.",,"['functional-analysis', 'sobolev-spaces', 'lp-spaces']"
63,Matrix Representation of Operators in Infinite Dimensional (Separable) Hilbert Spaces,Matrix Representation of Operators in Infinite Dimensional (Separable) Hilbert Spaces,,"Suppose we have a separable Hilbert space (thus with a countable basis) and that we to represent an operator in matrix form, i.e: $$A: H \rightarrow H \\ \; \; \; \; \; \;x \;\rightarrow \sum_{j \in \mathbb{N}}\left(\sum_{k \in \mathbb{N}} a(j,k)\cdot<x,e_k> \right)e_j$$ Given that the series of complex numbers $\sum_{k \in \mathbb{N}} a(j,k)\cdot<x,e_k>$ converges and that $\sum_{j \in \mathbb{N}}\left(\sum_{k \in \mathbb{N}} a(j,k)\cdot<x,e_k> \right)e_j$ converges in $H$ how do I prove without further assumptions that $A$ is a bounded operator? I can prove that for each $j \in \mathbb{N}$ the sucession $(a(j,k))_k \in l^2 (\mathbb{N},\mathbb{C})$  and that for each $k \in \mathbb{N}$ the sucession $(a(j,k))_j \in l^2 (\mathbb{N},\mathbb{C})$. However I always get to a point where I require that $\sum_{j \in \mathbb{N}}\sum_{k \in \mathbb{N}} \left |a(j,k) \right|^2 < \infty$ which is a condition that I can show to be necessary and sufficient for $A$ to be a Hilbert-Schmidt operator. Any help would be welcome.","Suppose we have a separable Hilbert space (thus with a countable basis) and that we to represent an operator in matrix form, i.e: $$A: H \rightarrow H \\ \; \; \; \; \; \;x \;\rightarrow \sum_{j \in \mathbb{N}}\left(\sum_{k \in \mathbb{N}} a(j,k)\cdot<x,e_k> \right)e_j$$ Given that the series of complex numbers $\sum_{k \in \mathbb{N}} a(j,k)\cdot<x,e_k>$ converges and that $\sum_{j \in \mathbb{N}}\left(\sum_{k \in \mathbb{N}} a(j,k)\cdot<x,e_k> \right)e_j$ converges in $H$ how do I prove without further assumptions that $A$ is a bounded operator? I can prove that for each $j \in \mathbb{N}$ the sucession $(a(j,k))_k \in l^2 (\mathbb{N},\mathbb{C})$  and that for each $k \in \mathbb{N}$ the sucession $(a(j,k))_j \in l^2 (\mathbb{N},\mathbb{C})$. However I always get to a point where I require that $\sum_{j \in \mathbb{N}}\sum_{k \in \mathbb{N}} \left |a(j,k) \right|^2 < \infty$ which is a condition that I can show to be necessary and sufficient for $A$ to be a Hilbert-Schmidt operator. Any help would be welcome.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
64,Various proofs of Hahn Banach theorem .,Various proofs of Hahn Banach theorem .,,"I have been seeing various versions of Hahn Banach theorem . There are few confusions that i would like to clarify .  1) In some proof they assume the existence of a sublinear functional and the functional $f$ must satisfy $\le$ condition to the sublinear functional $p$ . Does there always exist a sublinear functional ? In some proofs they don't say anything about the sublinear functional , is it wrong ? 2) I am not able to appreciate the induction , because it assumes the existence of the extension of linear functional and finally says that maximal element should be the Space itself ? I particularly have a problem in applying the first induction step. I would like to have some knowledge about my confusions and misunderstandings .  Thanks","I have been seeing various versions of Hahn Banach theorem . There are few confusions that i would like to clarify .  1) In some proof they assume the existence of a sublinear functional and the functional $f$ must satisfy $\le$ condition to the sublinear functional $p$ . Does there always exist a sublinear functional ? In some proofs they don't say anything about the sublinear functional , is it wrong ? 2) I am not able to appreciate the induction , because it assumes the existence of the extension of linear functional and finally says that maximal element should be the Space itself ? I particularly have a problem in applying the first induction step. I would like to have some knowledge about my confusions and misunderstandings .  Thanks",,['functional-analysis']
65,Show the Fourier transform is continuous in the Schwartz space $\mathcal S(\Bbb R)$,Show the Fourier transform is continuous in the Schwartz space,\mathcal S(\Bbb R),"Show the Fourier transform $\mathcal F$ is continuous in the Schwartz space $\mathcal S(\Bbb R)$. Use the standard $\mathcal S$-norms $$ \|f\|_{a,b}=\sup_{x \in \Bbb R} \left| x^af^{(b)}(x)\right|, \, a,b \in \Bbb Z_+. $$ Let $\{f_n\}$ be a sequence converging to $f$ in $\mathcal S$. To get the result, is it sufficient to show that $$ \lim_n \|\hat f_n\|_{a,b} =  \|\hat f\|_{a,b} $$ for any $a,b \in \Bbb Z_+$? This post prooves the result in another way.","Show the Fourier transform $\mathcal F$ is continuous in the Schwartz space $\mathcal S(\Bbb R)$. Use the standard $\mathcal S$-norms $$ \|f\|_{a,b}=\sup_{x \in \Bbb R} \left| x^af^{(b)}(x)\right|, \, a,b \in \Bbb Z_+. $$ Let $\{f_n\}$ be a sequence converging to $f$ in $\mathcal S$. To get the result, is it sufficient to show that $$ \lim_n \|\hat f_n\|_{a,b} =  \|\hat f\|_{a,b} $$ for any $a,b \in \Bbb Z_+$? This post prooves the result in another way.",,['functional-analysis']
66,"strange metric $d(x,y) = ||x|| + ||y||$ if $x\ne y$, $d(x,y) = 0$ if $x = y$.","strange metric  if ,  if .","d(x,y) = ||x|| + ||y|| x\ne y d(x,y) = 0 x = y","Let $d : \mathbb{R}^n \times \mathbb{R}^n \to [0, \infty]$ be defined by $$  d(x,y) = \left\{ \begin{array}{ll} 0 & : ~ x = y \\ ||x|| + ||y|| & : ~ x \ne y \end{array} \right. $$ where $||\cdot ||$ denotes the usual norm of $\mathbb{R}^n$. Show that $d$ is a metric. Draw the $\varepsilon$-Spheres $B_{\varepsilon}(x_0) := \{ x \in \mathbb{R}^2 ~|~ d(x,x_0) < \varepsilon \}$ for $x_0 = (0,0)$ and $x_0 = (1,1)$ and $\varepsilon = \frac{1}{2}, 1, \frac{3}{2}$. Characterize the open, closed and compact sets with respect to this metric. Is $(\mathbb{R}^n, d)$ complete? Number 1) is simple, for 2) I got: If $x_0 = (0,0)$ then $$ d(x,x_0)= \left\{ \begin{array}{ll}  0 & \textrm{ for } x = (0,0) \\ \sqrt{x^2 + y^2} & \textrm{ otherwise } \end{array} \right.  $$ and if $x_0 = (1,1)$ then $$   d(x,x_0) =  \left\{ \begin{array}{ll}  0 & \textrm{ for } x = (1,1) \\ \sqrt{2} + \sqrt{x^2 + y^2} & \textrm{ otherwise } \end{array} \right.  $$ and the pictures are simple spheres with the point $x_0$ in the sphere ($x_0 = (0,0)$) or isolated outside ($x_0 = (1,1)$). But with 3) I have my problems, i conjecture that  $$  B_{\varepsilon}(x) \quad \textrm{ is open iff } \quad ||x|| - \varepsilon > 0 $$ and going on I know that finite intersections of open sets are open, but then had I got all open sets by this construction? And what about the other properties, how can I characterize them, do you have any hints?","Let $d : \mathbb{R}^n \times \mathbb{R}^n \to [0, \infty]$ be defined by $$  d(x,y) = \left\{ \begin{array}{ll} 0 & : ~ x = y \\ ||x|| + ||y|| & : ~ x \ne y \end{array} \right. $$ where $||\cdot ||$ denotes the usual norm of $\mathbb{R}^n$. Show that $d$ is a metric. Draw the $\varepsilon$-Spheres $B_{\varepsilon}(x_0) := \{ x \in \mathbb{R}^2 ~|~ d(x,x_0) < \varepsilon \}$ for $x_0 = (0,0)$ and $x_0 = (1,1)$ and $\varepsilon = \frac{1}{2}, 1, \frac{3}{2}$. Characterize the open, closed and compact sets with respect to this metric. Is $(\mathbb{R}^n, d)$ complete? Number 1) is simple, for 2) I got: If $x_0 = (0,0)$ then $$ d(x,x_0)= \left\{ \begin{array}{ll}  0 & \textrm{ for } x = (0,0) \\ \sqrt{x^2 + y^2} & \textrm{ otherwise } \end{array} \right.  $$ and if $x_0 = (1,1)$ then $$   d(x,x_0) =  \left\{ \begin{array}{ll}  0 & \textrm{ for } x = (1,1) \\ \sqrt{2} + \sqrt{x^2 + y^2} & \textrm{ otherwise } \end{array} \right.  $$ and the pictures are simple spheres with the point $x_0$ in the sphere ($x_0 = (0,0)$) or isolated outside ($x_0 = (1,1)$). But with 3) I have my problems, i conjecture that  $$  B_{\varepsilon}(x) \quad \textrm{ is open iff } \quad ||x|| - \varepsilon > 0 $$ and going on I know that finite intersections of open sets are open, but then had I got all open sets by this construction? And what about the other properties, how can I characterize them, do you have any hints?",,"['analysis', 'functional-analysis']"
67,Bounded sets in Frechet spaces,Bounded sets in Frechet spaces,,"How can I show that, if a Frechet space is not normable then, there is no countable base of bounded sets. A collection $\Gamma$ of subsets of X is called a base for bounded sets, if for any bounded set C there is a $B_{0}$ such that C is contained in $B_{0}$ Mahmut çükübikyan","How can I show that, if a Frechet space is not normable then, there is no countable base of bounded sets. A collection $\Gamma$ of subsets of X is called a base for bounded sets, if for any bounded set C there is a $B_{0}$ such that C is contained in $B_{0}$ Mahmut çükübikyan",,['functional-analysis']
68,Why is the dual space of $H_0^1(\Omega)$ denoted $H^{-1}(\Omega)$?,Why is the dual space of  denoted ?,H_0^1(\Omega) H^{-1}(\Omega),"Why is the dual of the Sobolev space $H_0^1(\Omega)$ denoted $H^{-1}(\Omega)$ ? For a positive integer $k$, $H^k(\Omega)=W^{k,2}(\Omega)$. What is the motivation behind the $-1$ exponent?","Why is the dual of the Sobolev space $H_0^1(\Omega)$ denoted $H^{-1}(\Omega)$ ? For a positive integer $k$, $H^k(\Omega)=W^{k,2}(\Omega)$. What is the motivation behind the $-1$ exponent?",,"['functional-analysis', 'sobolev-spaces']"
69,How to find an integral kernel for poisson's equation in the upper half plane,How to find an integral kernel for poisson's equation in the upper half plane,,"In our lecture we have shown that $\forall f \in L^2(\mathbb{R}^n_+) $ there is a unique $ u $ in the Sobolev space $ H^2(\mathbb{R}^n_+) $ satisfying $ -\Delta u = f. $ Now in our exercise sheet we are asked to show that there is an integral kernel $ \Phi $ such that $ u(x) = \int_{\mathbb{R}^n} \ \Phi (x-y) \ f(y) \ dy $. Wikipedia tells me that there is an integral kernel and that it is of the form  \begin{equation*} \Phi(x) \ = \ const. \ \cdot \ \frac{x_n}{({\sum_{i = 1}^{n} x_i^2})^{n/2}} \end{equation*} So now to my question: How can you show that this is indeed an integral kernel for poisson's equation? In particular, how can you differentiate under the integral sign and ""take the Laplacian"" of $ \Phi $ at $ x - y = 0 $ ?  Moreover, do you know a priori that there has to be such an integral kernel? Thanks a lot in advance, I would really appreciate your help! Best regards Phil","In our lecture we have shown that $\forall f \in L^2(\mathbb{R}^n_+) $ there is a unique $ u $ in the Sobolev space $ H^2(\mathbb{R}^n_+) $ satisfying $ -\Delta u = f. $ Now in our exercise sheet we are asked to show that there is an integral kernel $ \Phi $ such that $ u(x) = \int_{\mathbb{R}^n} \ \Phi (x-y) \ f(y) \ dy $. Wikipedia tells me that there is an integral kernel and that it is of the form  \begin{equation*} \Phi(x) \ = \ const. \ \cdot \ \frac{x_n}{({\sum_{i = 1}^{n} x_i^2})^{n/2}} \end{equation*} So now to my question: How can you show that this is indeed an integral kernel for poisson's equation? In particular, how can you differentiate under the integral sign and ""take the Laplacian"" of $ \Phi $ at $ x - y = 0 $ ?  Moreover, do you know a priori that there has to be such an integral kernel? Thanks a lot in advance, I would really appreciate your help! Best regards Phil",,"['functional-analysis', 'partial-differential-equations']"
70,Continuity of semigroups on $L^2$ and $L^1$: Is this simple proof correct?,Continuity of semigroups on  and : Is this simple proof correct?,L^2 L^1,"Let $(X, \mu)$ be a $\sigma$-finite measure space, and $P_t$ a symmetric, Markovian, strongly continuous contraction semigroup on $L^2(X,\mu)$.  ( Markovian means that if $f \in L^2$ with $0 \le f \le 1$, then $0 \le P_t f \le 1$ $\mu$-a.e.  In particular $P_t$ is positivity-preserving.) I would like to show: Claim : $P_t$ is also a strongly continuous contraction semigroup on $L^1$. I have found two proofs of this by Silverstein: In his 1974 book Symmetric Markov processes ( MathSciNet ), there is a somewhat complicated proof (appended below), which appears to be using a generalization of conditional expectation to $\sigma$-finite measure spaces.  Then in Lemma 1.1 of this 1978 paper , there is a simpler proof, but it still uses some specialized uniform integrability results. My proof, which follows, is much simpler, which naturally makes me suspect it.  So I'd be interested in comments. EDIT: Since asking this question, I found that a proof, very similar to my proof below, appears in N. Bouleau and F. Hirsch, Dirichlet Forms and Analysis on Wiener Space ( MathSciNet ) at Propositions 2.2.1 and  2.4.2 Proof. Showing that $P_t$ extends to a contraction semigroup on $L^1$ is easy.  Note that $L^1 \cap L^2$ is dense in $L^1$.  Suppose $f \in L^2 \cap L^1$; we will show $||P_t f||_1 \le ||f||_1$, so that $P_t$ extends continuously to $L^1$.  By the Markovian property it suffices to consider $f \ge 0$.  Let $A_n$ be a sequence of sets with finite measure such that $A_n \uparrow X$; then for each $n$, $$\int_X (P_t f) 1_{A_n} = \int_X f P_t 1_{A_n} \le \int_X f = ||f||_1$$ since the Markovian property gives $P_t 1_{A_n} \le 1$.  (Edit: The first equality holds because $P_t$ is assumed to be symmetric.)  By monotone convergence, as $n \to \infty$ the right side goes to $\int_X P_t f = ||P_t f||_1$. Now we show the strong continuity.  First let $f \in L^2 \cap L^1$ with $f \ge 0$.  Let $t_n \downarrow 0$.  We have $P_{t_n} f \to f$ in $L^2$; passing to a subsequence we can assume $P_{t_n} f \to f$ a.e.  For each $n$ we have $|P_{t_n} f - f| \le P_{t_n} f + f$, so we mimic the proof of the dominated convergence theorem: $$\begin{align*}\int_X 2f &= \int \lim \left(f + P_{t_n} f - |P_{t_n} f - f|\right) \\\\ &\le \liminf \left( \int f + \int P_{t_n} f - \int |P_{t_n} f - f| \right)  && \text{(Fatou's lemma)}\\\\ &\le \liminf \left( 2 \int f - \int |P_{t_n} f - f| \right) && \text{since }||P_{t_n} f||_1 \le ||f||_1 \\\\ &= 2 \int f - \limsup \int |P_{t_n} f - f| \end{align*}$$ which, after rearranging, says $\limsup \int |P_{t_n} f - f| = 0$.  We have thus shown $P_t f \to f$ in $L^1$.  Taking positive and negative parts extends this to arbitrary $f \in L^1 \cap L^2$.  Extending to $f \in L^1$ is also easy since $L^2 \cap L^1$ is dense in $L^1$ and each $P_{t_n}$ is a contraction on $L^1$. QED Intuitively, Fatou's lemma says that $L^1$ convergence can only fail when the limiting function has too little mass (it can never have too much).  But the contraction property says that this does not happen. Here is Silverstein's 1974 proof, for reference.  The first line is cut off and says "" Lemma 1.3 .  For $f \in L^1(dx)$"".  (Edit: Incidentally, I'm not able to see why the claimed equality $\mathcal{F}_0 \mathcal{F}_t f(X_0) = P_t (1/P_t 1) P_t f (X_0)$ holds.)","Let $(X, \mu)$ be a $\sigma$-finite measure space, and $P_t$ a symmetric, Markovian, strongly continuous contraction semigroup on $L^2(X,\mu)$.  ( Markovian means that if $f \in L^2$ with $0 \le f \le 1$, then $0 \le P_t f \le 1$ $\mu$-a.e.  In particular $P_t$ is positivity-preserving.) I would like to show: Claim : $P_t$ is also a strongly continuous contraction semigroup on $L^1$. I have found two proofs of this by Silverstein: In his 1974 book Symmetric Markov processes ( MathSciNet ), there is a somewhat complicated proof (appended below), which appears to be using a generalization of conditional expectation to $\sigma$-finite measure spaces.  Then in Lemma 1.1 of this 1978 paper , there is a simpler proof, but it still uses some specialized uniform integrability results. My proof, which follows, is much simpler, which naturally makes me suspect it.  So I'd be interested in comments. EDIT: Since asking this question, I found that a proof, very similar to my proof below, appears in N. Bouleau and F. Hirsch, Dirichlet Forms and Analysis on Wiener Space ( MathSciNet ) at Propositions 2.2.1 and  2.4.2 Proof. Showing that $P_t$ extends to a contraction semigroup on $L^1$ is easy.  Note that $L^1 \cap L^2$ is dense in $L^1$.  Suppose $f \in L^2 \cap L^1$; we will show $||P_t f||_1 \le ||f||_1$, so that $P_t$ extends continuously to $L^1$.  By the Markovian property it suffices to consider $f \ge 0$.  Let $A_n$ be a sequence of sets with finite measure such that $A_n \uparrow X$; then for each $n$, $$\int_X (P_t f) 1_{A_n} = \int_X f P_t 1_{A_n} \le \int_X f = ||f||_1$$ since the Markovian property gives $P_t 1_{A_n} \le 1$.  (Edit: The first equality holds because $P_t$ is assumed to be symmetric.)  By monotone convergence, as $n \to \infty$ the right side goes to $\int_X P_t f = ||P_t f||_1$. Now we show the strong continuity.  First let $f \in L^2 \cap L^1$ with $f \ge 0$.  Let $t_n \downarrow 0$.  We have $P_{t_n} f \to f$ in $L^2$; passing to a subsequence we can assume $P_{t_n} f \to f$ a.e.  For each $n$ we have $|P_{t_n} f - f| \le P_{t_n} f + f$, so we mimic the proof of the dominated convergence theorem: $$\begin{align*}\int_X 2f &= \int \lim \left(f + P_{t_n} f - |P_{t_n} f - f|\right) \\\\ &\le \liminf \left( \int f + \int P_{t_n} f - \int |P_{t_n} f - f| \right)  && \text{(Fatou's lemma)}\\\\ &\le \liminf \left( 2 \int f - \int |P_{t_n} f - f| \right) && \text{since }||P_{t_n} f||_1 \le ||f||_1 \\\\ &= 2 \int f - \limsup \int |P_{t_n} f - f| \end{align*}$$ which, after rearranging, says $\limsup \int |P_{t_n} f - f| = 0$.  We have thus shown $P_t f \to f$ in $L^1$.  Taking positive and negative parts extends this to arbitrary $f \in L^1 \cap L^2$.  Extending to $f \in L^1$ is also easy since $L^2 \cap L^1$ is dense in $L^1$ and each $P_{t_n}$ is a contraction on $L^1$. QED Intuitively, Fatou's lemma says that $L^1$ convergence can only fail when the limiting function has too little mass (it can never have too much).  But the contraction property says that this does not happen. Here is Silverstein's 1974 proof, for reference.  The first line is cut off and says "" Lemma 1.3 .  For $f \in L^1(dx)$"".  (Edit: Incidentally, I'm not able to see why the claimed equality $\mathcal{F}_0 \mathcal{F}_t f(X_0) = P_t (1/P_t 1) P_t f (X_0)$ holds.)",,"['functional-analysis', 'semigroup-of-operators']"
71,Cutoff functions are not nice in their first derivative,Cutoff functions are not nice in their first derivative,,"This afternoon, while working out this answer by Nate Eldredge , I made some vain attempts at building cutoff functions of various kinds. Especially I was looking for the following. Can a sequence $\zeta_n \in C^\infty(-1, 1)$ s.t. $0 \le \zeta_n \le 1$ and $\zeta_n(0)=1, \zeta(-1)=\zeta(1)=0$; $\lVert \zeta_n-1\rVert_2 \to 0$; $\lVert \zeta'_n \rVert_2$ is bounded exist? Graphically I was looking for something like this: (in red the graph of $\zeta_n(x)=\exp(\frac{1/n}{x^2-1})$, in black the scaled graph of its first derivative). The task was to arrange things so that those black peaks stayed $L^2$-bounded. After many unsuccessful trials I've come to the conclusion that such a $\zeta_n$ cannot exist. In fact, it should be $H^1$-bounded and so, up to a subsequence, $H^1$-weakly convergent. This implies $L^2$-weak convergence and so we should have $\zeta_n \stackrel{H^1}{\rightharpoonup}1$. But now we observe that $\zeta_n \in H^1_0(-1, 1)$. $H^1_0(-1, 1)$ is a norm-closed subspace of $H^1(-1,1)$, and so - because of its convexity - it is also weakly closed. We have thus gotten the contradiction $1 \in H^1_0(-1, 1)$. Two questions: Is this reasoning correct? If 1. is affirmative, is there a more elementary way to see this? I've   got the strong feeling of using a   sledge-hammer to crack a nut. Thank you for your attention.","This afternoon, while working out this answer by Nate Eldredge , I made some vain attempts at building cutoff functions of various kinds. Especially I was looking for the following. Can a sequence $\zeta_n \in C^\infty(-1, 1)$ s.t. $0 \le \zeta_n \le 1$ and $\zeta_n(0)=1, \zeta(-1)=\zeta(1)=0$; $\lVert \zeta_n-1\rVert_2 \to 0$; $\lVert \zeta'_n \rVert_2$ is bounded exist? Graphically I was looking for something like this: (in red the graph of $\zeta_n(x)=\exp(\frac{1/n}{x^2-1})$, in black the scaled graph of its first derivative). The task was to arrange things so that those black peaks stayed $L^2$-bounded. After many unsuccessful trials I've come to the conclusion that such a $\zeta_n$ cannot exist. In fact, it should be $H^1$-bounded and so, up to a subsequence, $H^1$-weakly convergent. This implies $L^2$-weak convergence and so we should have $\zeta_n \stackrel{H^1}{\rightharpoonup}1$. But now we observe that $\zeta_n \in H^1_0(-1, 1)$. $H^1_0(-1, 1)$ is a norm-closed subspace of $H^1(-1,1)$, and so - because of its convexity - it is also weakly closed. We have thus gotten the contradiction $1 \in H^1_0(-1, 1)$. Two questions: Is this reasoning correct? If 1. is affirmative, is there a more elementary way to see this? I've   got the strong feeling of using a   sledge-hammer to crack a nut. Thank you for your attention.",,"['functional-analysis', 'functions', 'partial-differential-equations']"
72,Decomposition of a bounded Hilbert space operator,Decomposition of a bounded Hilbert space operator,,"I am trying to prove the following homework problem: Let $B$ be a positive operator on a Hilbert space $H$ with $\Vert B\Vert=1$ and $B$ is invertible. Try to prove that for each $\,T\in \mathfrak{B}(H,H)$ , there exists an $S\in\mathfrak B(H,H)\,$ such that $\,T=\frac{1}{2}(BS+SB)\,$ . I have tried to apply the polar decomposition of $T$ but seemingly in vain. Actually, I am wondering how the condition $\Vert B\Vert=1$ is used. Can somebody give me some hints on this problem?","I am trying to prove the following homework problem: Let be a positive operator on a Hilbert space with and is invertible. Try to prove that for each , there exists an such that . I have tried to apply the polar decomposition of but seemingly in vain. Actually, I am wondering how the condition is used. Can somebody give me some hints on this problem?","B H \Vert B\Vert=1 B \,T\in \mathfrak{B}(H,H) S\in\mathfrak B(H,H)\, \,T=\frac{1}{2}(BS+SB)\, T \Vert B\Vert=1","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
73,"When is an operator $T$ on $L^1(\mu)$ of the form $(Tf)(x)=\int\mu({\rm d}y)p(x,y)f(y)$?",When is an operator  on  of the form ?,"T L^1(\mu) (Tf)(x)=\int\mu({\rm d}y)p(x,y)f(y)","Let $(E,\mathcal E,\mu)$ be a $\sigma$ -finite measure space and $T\in\mathfrak L(\mathcal L^1(\mu))$ . I would like to know which conditions on $T$ would be sufficient to conclude that there is a (possibly signed) transition kernel $\kappa$ on $(E,\mathcal E)$ s.t. $$(Tf)(x)=\int\kappa(x,{\rm d}y)f(y)\;\;\;\text{for all }x\in E\text{ and }f\in\mathcal L^1(\mu).\tag1$$ On page 159 of Analysis of Heat Equations on Domains it is claimed that $$\left\|T\right\|_{\mathfrak L(L^1(\mu),\:L^\infty(\mu))}<\infty\tag2$$ is equivalent to $(1)$ with the additional claim that $\kappa$ has a density with respect to $\mu$ , i.e. $$\kappa(x,B)=\int_B\mu({\rm d}y)p(x,y)\;\;\;\text{for all }(x,B)\in E\times\mathcal E\tag3$$ for some $\mathcal E^{\otimes2}$ -measurable $p:E^2\to\mathbb R$ . How do we see this? And is there a weaker condition which at least implies the existence of a kernel $\kappa$ (which possibly has no density wrt $\mu$ )?","Let be a -finite measure space and . I would like to know which conditions on would be sufficient to conclude that there is a (possibly signed) transition kernel on s.t. On page 159 of Analysis of Heat Equations on Domains it is claimed that is equivalent to with the additional claim that has a density with respect to , i.e. for some -measurable . How do we see this? And is there a weaker condition which at least implies the existence of a kernel (which possibly has no density wrt )?","(E,\mathcal E,\mu) \sigma T\in\mathfrak L(\mathcal L^1(\mu)) T \kappa (E,\mathcal E) (Tf)(x)=\int\kappa(x,{\rm d}y)f(y)\;\;\;\text{for all }x\in E\text{ and }f\in\mathcal L^1(\mu).\tag1 \left\|T\right\|_{\mathfrak L(L^1(\mu),\:L^\infty(\mu))}<\infty\tag2 (1) \kappa \mu \kappa(x,B)=\int_B\mu({\rm d}y)p(x,y)\;\;\;\text{for all }(x,B)\in E\times\mathcal E\tag3 \mathcal E^{\otimes2} p:E^2\to\mathbb R \kappa \mu","['functional-analysis', 'measure-theory', 'operator-theory', 'lp-spaces', 'semigroup-of-operators']"
74,"If the dual of a topological vector space separates points, does it separate a point and a closed subspace?","If the dual of a topological vector space separates points, does it separate a point and a closed subspace?",,"The Hahn-Banach Theorem implies that if $X$ is a normed vector space, then the dual space $X^*$ , consisting of continuous linear functionals on $X$ , has the following two properties: $X^*$ separates points, i.e. if $x_1,x_2\in X$ with $x_1\neq x_2$ , then there exists an $f\in X^*$ such that $f(x_1)=0$ and $f(x_2)=1$ . $X^*$ separates points from closed subspaces, i.e. if $Y$ is a closed subspace of $X$ and $x_0\in X$ with $x_0\not\in Y$ , then there exists an $f\in X^*$ such that $f(Y)=\{0\}$ and $f(x_0)=1$ . But this answer shows that there are topological vector spaces which do not satisfy property 1.  And property 2 clearly implies property 1, so  such spaces satisfy neither one of the two properties. But my question is, if a topological vector space satisfies property 1, does it necessarily satisfy property 2?  To put it another way, are separating points and separating points from closed subspaces equivalent? If not, does anyone know of a counterexample?  It would have to be a topological vector space that isn't normable.","The Hahn-Banach Theorem implies that if is a normed vector space, then the dual space , consisting of continuous linear functionals on , has the following two properties: separates points, i.e. if with , then there exists an such that and . separates points from closed subspaces, i.e. if is a closed subspace of and with , then there exists an such that and . But this answer shows that there are topological vector spaces which do not satisfy property 1.  And property 2 clearly implies property 1, so  such spaces satisfy neither one of the two properties. But my question is, if a topological vector space satisfies property 1, does it necessarily satisfy property 2?  To put it another way, are separating points and separating points from closed subspaces equivalent? If not, does anyone know of a counterexample?  It would have to be a topological vector space that isn't normable.","X X^* X X^* x_1,x_2\in X x_1\neq x_2 f\in X^* f(x_1)=0 f(x_2)=1 X^* Y X x_0\in X x_0\not\in Y f\in X^* f(Y)=\{0\} f(x_0)=1","['functional-analysis', 'examples-counterexamples', 'normed-spaces', 'topological-vector-spaces', 'hahn-banach-theorem']"
75,Show that the $L^{p}$ norm $\|f\|_{L^{p}} := \big( \int^{b}_{a} |f(x)|^p\big)^{1/p}$ is not induced by a scalar product for $p \neq 2$.,Show that the  norm  is not induced by a scalar product for .,L^{p} \|f\|_{L^{p}} := \big( \int^{b}_{a} |f(x)|^p\big)^{1/p} p \neq 2,"On $X = C^0\big([a,b]\big)$ , for any $p \in \mathbb{R}$ , $p>1$ , we define the $L^p$ norm by, $$\|f\|_{L^{p}}:=\big(\int^{b}_{a}|f(x)|^{p}dx \big)^{1/p}.$$ Show that for $p\neq 2$ , this norm is not induced by a scalar product. My method of trying to prove this was to prove a contradiction to the parallelogram rule, $$  \|f+g\|^{2}_{p} + \|f-g\|^{2}_{p} = 2\|f\|^{2}_{p} + 2\|g\|^{2}_{p}, \tag{$1$}$$ where $f,g \in C^{0}([a,b])$ . So I defined the following functions; $$f(x):=\frac{a+b}{2}-x$$ $$g(x) := \begin{cases}\frac{a+b}{2}-x, \ \ for \ \ a \leq x \le \frac{a+b}{2}. \\ x-\frac{a+b}{2}, \ \ for \ \ \frac{a+b}{2} < x \le b \end{cases}$$ which gives $$f(x)+g(x) = \begin{cases} a+b-2x, \ \ & for \ \ a\le x \le \frac{a+b}{2}. \\ 0, & for \ \ \frac{a+b}{2} < x \le b\end{cases}$$ $$f(x)-g(x) = \begin{cases} 0, & for \ \ a \le x \le \frac{a+b}{2}. \\ 2x - (a+b), \ \ & for \ \ \frac{a+b}{2} < x \le b \end{cases}$$ Then I proceeded to calculate each term of the parallelogram rule, $$\|f+g\|^{2}_{p} = \bigg( \int^{\frac{a+b}{2}}_{a}|a+b-2x|^{p}\bigg)^{2/p} = \frac{(b-a)^{\frac{2(p+1)}{p}}}{(2(p+1))^{2/p}} $$ $$ \|f-g\|^{2}_{p} = \bigg( \int_{\frac{a+b}{2}}^{b}|2x- (a+b)|^{p}\bigg)^{2/p} = \frac{(b-a)^{\frac{2(p+1)}{p}}}{(2(p+1))^{2/p}}$$ $$2\|f\|^{2}_{p} = 2 \bigg( \int^{b}_{a}| \frac{a+b}{2}-x|^{p} dx \bigg)^{2/p} = 2 \cdot \frac{2^{2/p}(\frac{b-a}{2})^{\frac{2(p+1)}{p}}}{(p+1)^{2/p}} $$ $$\begin{align}2 \|g\|^{2}_{p}  & = 2 \bigg(\int^{\frac{a+b}{2}}_{a} |\frac{a+b}{2} - x|^{p} dx \ + \ \int^{b}_{\frac{a+b}{2}}|x- \frac{a+b}{2}|^{p} dx\bigg)^{2/p} \\  & =2 \cdot \frac{2^{2/p}(\frac{b-a}{2})^{\frac{2(p+1)}{p}}}{(p+1)^{2/p}} \end{align}$$ Plugging into $(1)$ we then get $$2 \cdot \frac{(b-a)^{\frac{2(p+1)}{p}}}{(2(p+1))^{2/p}} = 4 \cdot \frac{2^{2/p}(\frac{b-a}{2})^{\frac{2(p+1)}{p}}}{(p+1)^{2/p}}$$ which simplifies quite nicely to $$2^{p} = 4.$$ So the equality only holds for $p = 2$ . Is what i've done correct? is there another way of proving the question which is better?","On , for any , , we define the norm by, Show that for , this norm is not induced by a scalar product. My method of trying to prove this was to prove a contradiction to the parallelogram rule, where . So I defined the following functions; which gives Then I proceeded to calculate each term of the parallelogram rule, Plugging into we then get which simplifies quite nicely to So the equality only holds for . Is what i've done correct? is there another way of proving the question which is better?","X = C^0\big([a,b]\big) p \in \mathbb{R} p>1 L^p \|f\|_{L^{p}}:=\big(\int^{b}_{a}|f(x)|^{p}dx \big)^{1/p}. p\neq 2   \|f+g\|^{2}_{p} + \|f-g\|^{2}_{p} = 2\|f\|^{2}_{p} + 2\|g\|^{2}_{p}, \tag{1} f,g \in C^{0}([a,b]) f(x):=\frac{a+b}{2}-x g(x) := \begin{cases}\frac{a+b}{2}-x, \ \ for \ \ a \leq x \le \frac{a+b}{2}. \\
x-\frac{a+b}{2}, \ \ for \ \ \frac{a+b}{2} < x \le b \end{cases} f(x)+g(x) = \begin{cases} a+b-2x, \ \ & for \ \ a\le x \le \frac{a+b}{2}. \\ 0, & for \ \ \frac{a+b}{2} < x \le b\end{cases} f(x)-g(x) = \begin{cases} 0, & for \ \ a \le x \le \frac{a+b}{2}. \\
2x - (a+b), \ \ & for \ \ \frac{a+b}{2} < x \le b \end{cases} \|f+g\|^{2}_{p} = \bigg( \int^{\frac{a+b}{2}}_{a}|a+b-2x|^{p}\bigg)^{2/p} = \frac{(b-a)^{\frac{2(p+1)}{p}}}{(2(p+1))^{2/p}}   \|f-g\|^{2}_{p} = \bigg( \int_{\frac{a+b}{2}}^{b}|2x- (a+b)|^{p}\bigg)^{2/p} = \frac{(b-a)^{\frac{2(p+1)}{p}}}{(2(p+1))^{2/p}} 2\|f\|^{2}_{p} = 2 \bigg( \int^{b}_{a}| \frac{a+b}{2}-x|^{p} dx \bigg)^{2/p} = 2 \cdot \frac{2^{2/p}(\frac{b-a}{2})^{\frac{2(p+1)}{p}}}{(p+1)^{2/p}}  \begin{align}2 \|g\|^{2}_{p}  & = 2 \bigg(\int^{\frac{a+b}{2}}_{a} |\frac{a+b}{2} - x|^{p} dx \ + \ \int^{b}_{\frac{a+b}{2}}|x- \frac{a+b}{2}|^{p} dx\bigg)^{2/p} \\  & =2 \cdot \frac{2^{2/p}(\frac{b-a}{2})^{\frac{2(p+1)}{p}}}{(p+1)^{2/p}} \end{align} (1) 2 \cdot \frac{(b-a)^{\frac{2(p+1)}{p}}}{(2(p+1))^{2/p}} = 4 \cdot \frac{2^{2/p}(\frac{b-a}{2})^{\frac{2(p+1)}{p}}}{(p+1)^{2/p}} 2^{p} = 4. p = 2","['functional-analysis', 'proof-verification', 'normed-spaces', 'lp-spaces', 'inner-products']"
76,Confusion about definition of continuous spectrum,Confusion about definition of continuous spectrum,,"In discussions about the spectrum of hyperbolic surfaces, people seem to be interested in 'eigenvalues embedded in the continuous spectrum'. I am wondering which definition of the term 'continuous spectrum' is usually meant in this context? The reason I am asking this is because people seem to use different definitions for the term 'continuous spectrum'. Let me list three definitions I know about. Let $\mathcal{H}$ be a Hilbert space and $T:\mathcal{H}\supset \mathcal{D}(T)\rightarrow\mathcal{H}$ be a densely defined, self-adjoint, and closed operator. Then people refer to the following sets as continuous spectrum: \begin{align} \sigma_c(T):&=\lbrace{\lambda\in\mathbb{K}: Im(T-\lambda)\neq \overline{Im(T-\lambda)}\rbrace}\\ \sigma_c(T)':&=\lbrace{\lambda\in\mathbb{K}: ker(T-\lambda)=\lbrace{0\rbrace},\,\, Im(T-\lambda)\neq \mathcal{H},\,\,\overline{Im(T-\lambda)}=\mathcal{H}\rbrace}\\ \sigma_c(T)'':&=\sigma_{ess}(T)-\sigma_{p}(T), \end{align} where $\sigma_{ess}(T)$ is the essential spectrum and $\sigma_{p}(T)$ the point spectrum (=set of all eigenvalues). Moreover, there is also the notion of continuous spectrum coming from the spectral measure associated to $T$. I must admit that I do not understand that definition completely, because I do not know used to work with the spectral measure. I think it corresponds to the union of the 'absolutely continuous spectrum' and the 'singular spectrum', as defined on Wikipedia: https://en.wikipedia.org/wiki/Decomposition_of_spectrum_(functional_analysis) I have two questions, which causes me confusion: 1)Which of the above definitions are meant in the context stated at the beginning above? 2) How is the last notion of 'continuous spectrum' related to the other definitions? Is it maybe possible that the continuous spectrum coming from the spectral measure is equal to one of the above ones? I would very appreciate your help!","In discussions about the spectrum of hyperbolic surfaces, people seem to be interested in 'eigenvalues embedded in the continuous spectrum'. I am wondering which definition of the term 'continuous spectrum' is usually meant in this context? The reason I am asking this is because people seem to use different definitions for the term 'continuous spectrum'. Let me list three definitions I know about. Let $\mathcal{H}$ be a Hilbert space and $T:\mathcal{H}\supset \mathcal{D}(T)\rightarrow\mathcal{H}$ be a densely defined, self-adjoint, and closed operator. Then people refer to the following sets as continuous spectrum: \begin{align} \sigma_c(T):&=\lbrace{\lambda\in\mathbb{K}: Im(T-\lambda)\neq \overline{Im(T-\lambda)}\rbrace}\\ \sigma_c(T)':&=\lbrace{\lambda\in\mathbb{K}: ker(T-\lambda)=\lbrace{0\rbrace},\,\, Im(T-\lambda)\neq \mathcal{H},\,\,\overline{Im(T-\lambda)}=\mathcal{H}\rbrace}\\ \sigma_c(T)'':&=\sigma_{ess}(T)-\sigma_{p}(T), \end{align} where $\sigma_{ess}(T)$ is the essential spectrum and $\sigma_{p}(T)$ the point spectrum (=set of all eigenvalues). Moreover, there is also the notion of continuous spectrum coming from the spectral measure associated to $T$. I must admit that I do not understand that definition completely, because I do not know used to work with the spectral measure. I think it corresponds to the union of the 'absolutely continuous spectrum' and the 'singular spectrum', as defined on Wikipedia: https://en.wikipedia.org/wiki/Decomposition_of_spectrum_(functional_analysis) I have two questions, which causes me confusion: 1)Which of the above definitions are meant in the context stated at the beginning above? 2) How is the last notion of 'continuous spectrum' related to the other definitions? Is it maybe possible that the continuous spectrum coming from the spectral measure is equal to one of the above ones? I would very appreciate your help!",,"['functional-analysis', 'spectral-theory', 'hyperbolic-geometry', 'global-analysis']"
77,Explicit example of Hahn-Banach theorem on the finite dimensional space $\mathbb{R}^2$?,Explicit example of Hahn-Banach theorem on the finite dimensional space ?,\mathbb{R}^2,"The Hahn-Banach theorem allows us to extend linear functionals defined on a subspace of some vector space $V$ to the entire space. Is it possible to construct an explicit example of this in the finite dimensional case? For example, suppose $V = \mathbb{R}^2$ and $U=\mathbb{R} \subset V$. What would be a simple explicit example of the Hahn-Banach theorem, i.e. what are explicit expressions for $p:V \to \mathbb{R}$ is a sublinear function $\varphi: U \to \mathbb{R}$ is a linear functional on the linear subspace $U \subset V$ which is dominated by $p$ on $U$. The linear extension $\psi:V \to \mathbb{R}$ of $\varphi$ to the whole space such that \begin{align} \psi(x) = \varphi(x) \quad \forall x \in U, \\ \psi(x) = p(x) \quad \forall x \in V. \end{align}","The Hahn-Banach theorem allows us to extend linear functionals defined on a subspace of some vector space $V$ to the entire space. Is it possible to construct an explicit example of this in the finite dimensional case? For example, suppose $V = \mathbb{R}^2$ and $U=\mathbb{R} \subset V$. What would be a simple explicit example of the Hahn-Banach theorem, i.e. what are explicit expressions for $p:V \to \mathbb{R}$ is a sublinear function $\varphi: U \to \mathbb{R}$ is a linear functional on the linear subspace $U \subset V$ which is dominated by $p$ on $U$. The linear extension $\psi:V \to \mathbb{R}$ of $\varphi$ to the whole space such that \begin{align} \psi(x) = \varphi(x) \quad \forall x \in U, \\ \psi(x) = p(x) \quad \forall x \in V. \end{align}",,"['functional-analysis', 'vector-spaces']"
78,Extending an equality from a dense subspace - possible mistake in a proof.,Extending an equality from a dense subspace - possible mistake in a proof.,,"I am reading K.Gröchenig's Introduction to Time-Frequency Analysis , Theorem 3.2.1. and the proof seems to be incorrect as it is presented. The whole context is actually not important, but I will report it anyway. The map $$V_gf(x,\xi):=\int_{\mathbb{R}^d}f(t)\overline{g(t-x)}e^{-2\pi it\cdot \xi}dt,\qquad f,g\in L^2(\mathbb{R}^d) $$ is called the Short Time Fourier Transform (STFT) of window $g$. The theorem considered reads Let $f_1,f_2,g_1,g_2\in L^2(\mathbb{R}^d)$. Then $V_{g_j}f_j\in L^2(\mathbb{R}^{2d})$ for $j=1,2$ and   $$\left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle=\left\langle  f_1,f_2\right\rangle \overline{\left\langle  g_1,g_2\right\rangle}$$ The proof Gröchenig proposes is as follows. The equality above is first proved for $g_1,g_2\in (L^1\cap L^{\infty})(\mathbb{R}^d)$, which is dense in $L^2(\mathbb{R}^d)$ (this allows one to use Parseval's equality and Fubini's theorem). However, to extend the equality to $g_1,g_2\in L^2(\mathbb{R}^d)$, he proceeds as follows With $g_1\in L^1\cap L^{\infty}$ fixed, the mapping $g_2\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle$ is a linear functional that coincides with $\left\langle f_1,f_2\right\rangle \overline{\left\langle g_1,g_2\right\rangle}$ on the dense subspace $L^1\cap L^{\infty}$. It is therefore bounded and extends to all $g_2\in L^2(\mathbb{R}^d)$. Up to this point everything seems fine. But now: In the same way, for arbitrary $f_1,f_2$ and $g_2\in L^2(\mathbb{R}^d)$, the conjugate linear functional $g_1\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle $ equals $\left\langle f_1,f_2\right\rangle \overline{\left\langle g_1,g_2\right\rangle}$ on $L^1\cap L^{\infty}$ and extends to all of $L^2$. The orthogonality relations are therefore established for all $f_j,g_j\in L^2(\mathbb{R}^d)$. I believe that this proof is not correct. Reason: a priori the linear operator $g_2\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle$ is not bounded on $L^2(\mathbb{R}^d)$, as we do not even know if $V_{g_i}(f_i)\in L^2(\mathbb{R}^{2d})$ yet (it is part of the thesis), so the inner product might not even make sense. Therefore, even if we have extended the linear operator  $g_2\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle$ , which is bounded on $(L^1\cap L^{\infty})(\mathbb{R}^d)$, on the whole $L^2(\mathbb{R}^d)$, the resulting operator will not necessarily be still given by the expression $g_2\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle$. A priori, the operator $g_2\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle$  is unbounded on $L^2(\mathbb{R}^d)$ (despite being bounded on $(L^1\cap L^{\infty})(\mathbb{R}^d)$) and the extension we have just found is different - they only agree on $(L^1\cap L^{\infty})(\mathbb{R}^d)$. Hence we cannot deduce that the equality we are looking to prove is preserved by the extension. What do you think, MSE?","I am reading K.Gröchenig's Introduction to Time-Frequency Analysis , Theorem 3.2.1. and the proof seems to be incorrect as it is presented. The whole context is actually not important, but I will report it anyway. The map $$V_gf(x,\xi):=\int_{\mathbb{R}^d}f(t)\overline{g(t-x)}e^{-2\pi it\cdot \xi}dt,\qquad f,g\in L^2(\mathbb{R}^d) $$ is called the Short Time Fourier Transform (STFT) of window $g$. The theorem considered reads Let $f_1,f_2,g_1,g_2\in L^2(\mathbb{R}^d)$. Then $V_{g_j}f_j\in L^2(\mathbb{R}^{2d})$ for $j=1,2$ and   $$\left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle=\left\langle  f_1,f_2\right\rangle \overline{\left\langle  g_1,g_2\right\rangle}$$ The proof Gröchenig proposes is as follows. The equality above is first proved for $g_1,g_2\in (L^1\cap L^{\infty})(\mathbb{R}^d)$, which is dense in $L^2(\mathbb{R}^d)$ (this allows one to use Parseval's equality and Fubini's theorem). However, to extend the equality to $g_1,g_2\in L^2(\mathbb{R}^d)$, he proceeds as follows With $g_1\in L^1\cap L^{\infty}$ fixed, the mapping $g_2\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle$ is a linear functional that coincides with $\left\langle f_1,f_2\right\rangle \overline{\left\langle g_1,g_2\right\rangle}$ on the dense subspace $L^1\cap L^{\infty}$. It is therefore bounded and extends to all $g_2\in L^2(\mathbb{R}^d)$. Up to this point everything seems fine. But now: In the same way, for arbitrary $f_1,f_2$ and $g_2\in L^2(\mathbb{R}^d)$, the conjugate linear functional $g_1\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle $ equals $\left\langle f_1,f_2\right\rangle \overline{\left\langle g_1,g_2\right\rangle}$ on $L^1\cap L^{\infty}$ and extends to all of $L^2$. The orthogonality relations are therefore established for all $f_j,g_j\in L^2(\mathbb{R}^d)$. I believe that this proof is not correct. Reason: a priori the linear operator $g_2\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle$ is not bounded on $L^2(\mathbb{R}^d)$, as we do not even know if $V_{g_i}(f_i)\in L^2(\mathbb{R}^{2d})$ yet (it is part of the thesis), so the inner product might not even make sense. Therefore, even if we have extended the linear operator  $g_2\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle$ , which is bounded on $(L^1\cap L^{\infty})(\mathbb{R}^d)$, on the whole $L^2(\mathbb{R}^d)$, the resulting operator will not necessarily be still given by the expression $g_2\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle$. A priori, the operator $g_2\mapsto \left\langle V_{g_1}f_1,V_{g_2}f_2\right\rangle$  is unbounded on $L^2(\mathbb{R}^d)$ (despite being bounded on $(L^1\cap L^{\infty})(\mathbb{R}^d)$) and the extension we have just found is different - they only agree on $(L^1\cap L^{\infty})(\mathbb{R}^d)$. Hence we cannot deduce that the equality we are looking to prove is preserved by the extension. What do you think, MSE?",,"['functional-analysis', 'fourier-analysis', 'harmonic-analysis']"
79,Duhamel's principle for heat equation.,Duhamel's principle for heat equation.,,"A solution to the nonhomogeneous heat equation with $0$ initial data is $u:\Bbb R^n\times [0,\infty)\to \Bbb R$ solving   $$\begin{align} \partial_t u(x,t) - \Delta_xu(x,t) &= f(x,t) \\ u(x,0) &\equiv 0. \end{align}$$   The regularity of $f$ is unspecified for now. Recall the heat kernel $\Phi(x,t)=\frac 1{(4\pi t)^{n/2}}e^{-|x|^2/4t}$. The Duhamel's principle states that   $$ u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(x-y,t-s)f(y,s)dyds $$   solves our equation. In books I've read, e.g. Evans' PDE, assume quite a strict condition on the regularity of $f$. For example, in Evans' book he assumed that $f\in C^2_1(\Bbb R^n\times[0,\infty))$ and is compactly supported. Then the proof that $u$ really solves the heat equation or the smoothness of $u$ is shown by rewriting the formula as $$ u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(y,s)f(x-y,t-s)dyds $$ and differentiate under integral sign, e.g. $$ \partial_t u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(y,s)\partial_t f(x-y,t-s)dyds+\int_{\Bbb R^n}\Phi(y,t)f(x-y,0)dy. $$ To show smoothness of $u$, some even assume $f$ to be smooth. I can't help but feeling that this is a massive overkill. Some integrability condition on $f$ should suffice. What are some reasonable integrability conditions we can put on $f$ so that    $$ u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(x-y,t-s)f(y,s)dyds $$   works? What should we impose further to get higher regularity of $u$? Of course, if $f$ is really irregular we cannot expect $u$ to be regular. I just want to know how much regularity do we gain from the fact that $u$ solves heat equation.","A solution to the nonhomogeneous heat equation with $0$ initial data is $u:\Bbb R^n\times [0,\infty)\to \Bbb R$ solving   $$\begin{align} \partial_t u(x,t) - \Delta_xu(x,t) &= f(x,t) \\ u(x,0) &\equiv 0. \end{align}$$   The regularity of $f$ is unspecified for now. Recall the heat kernel $\Phi(x,t)=\frac 1{(4\pi t)^{n/2}}e^{-|x|^2/4t}$. The Duhamel's principle states that   $$ u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(x-y,t-s)f(y,s)dyds $$   solves our equation. In books I've read, e.g. Evans' PDE, assume quite a strict condition on the regularity of $f$. For example, in Evans' book he assumed that $f\in C^2_1(\Bbb R^n\times[0,\infty))$ and is compactly supported. Then the proof that $u$ really solves the heat equation or the smoothness of $u$ is shown by rewriting the formula as $$ u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(y,s)f(x-y,t-s)dyds $$ and differentiate under integral sign, e.g. $$ \partial_t u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(y,s)\partial_t f(x-y,t-s)dyds+\int_{\Bbb R^n}\Phi(y,t)f(x-y,0)dy. $$ To show smoothness of $u$, some even assume $f$ to be smooth. I can't help but feeling that this is a massive overkill. Some integrability condition on $f$ should suffice. What are some reasonable integrability conditions we can put on $f$ so that    $$ u(x,t)=\int_0^t\int_{\Bbb R^n} \Phi(x-y,t-s)f(y,s)dyds $$   works? What should we impose further to get higher regularity of $u$? Of course, if $f$ is really irregular we cannot expect $u$ to be regular. I just want to know how much regularity do we gain from the fact that $u$ solves heat equation.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'convolution', 'heat-equation']"
80,Proof of Hölder for Lorentz spaces (harmonic analysis),Proof of Hölder for Lorentz spaces (harmonic analysis),,"So I was thinking about the proof of Hölder's inequality for Lorentz spaces $$ \left\lVert fg\right\rVert_{p,q} \lesssim \left\lVert f\right\rVert_{p_1,q_1} \left\lVert g\right\rVert_{p_2,q_2} $$ where the exponents are positive and finite ($q$ can be infinite, but let's ignore that) and $1/q = 1/{q_1} + 1/{q_2}, 1/p = 1/{p_1} + 1/{p_2}$. We all know that a Lorentz function can be characterized in 2 ways: dyadic decomposition by height:  $f = \sum_n f_n$, $ 2^n <|f_n| \leq 2^{n+1}$, $f||_{p,q} \sim || \; \left\lVert f_n\right\rVert_{L^p} ||_{l^q_n}$ dyadic decomposition by width:  $f = \sum_n f_n$, where $ f^*(2^{n+1}) < |f_n| \leq f^*(2^n)$, and  $ \left\lVert f\right\rVert_{p,q} \sim \left\lVert  \left\lVert f_n\right\rVert_{L^p} \right\rVert_{l^q_n}$ where $f^*$ is the decreasing rearrangement of $f$. The standard proof of Holder for Lorentz spaces uses dyadic decomposition by width (as can be seen here , Theorem 6.9). So I guess my question really is: Can we use decomposition by height to tackle this one? I'd like to think that it's possible. I tried to adapt the width method but the supports wouldn't play nice. If it is not possible, I'd like to know how one can figure out which characterization is better for a particular problem. Is there anything in the inequality that suggests the width approach would be better than the height approach?","So I was thinking about the proof of Hölder's inequality for Lorentz spaces $$ \left\lVert fg\right\rVert_{p,q} \lesssim \left\lVert f\right\rVert_{p_1,q_1} \left\lVert g\right\rVert_{p_2,q_2} $$ where the exponents are positive and finite ($q$ can be infinite, but let's ignore that) and $1/q = 1/{q_1} + 1/{q_2}, 1/p = 1/{p_1} + 1/{p_2}$. We all know that a Lorentz function can be characterized in 2 ways: dyadic decomposition by height:  $f = \sum_n f_n$, $ 2^n <|f_n| \leq 2^{n+1}$, $f||_{p,q} \sim || \; \left\lVert f_n\right\rVert_{L^p} ||_{l^q_n}$ dyadic decomposition by width:  $f = \sum_n f_n$, where $ f^*(2^{n+1}) < |f_n| \leq f^*(2^n)$, and  $ \left\lVert f\right\rVert_{p,q} \sim \left\lVert  \left\lVert f_n\right\rVert_{L^p} \right\rVert_{l^q_n}$ where $f^*$ is the decreasing rearrangement of $f$. The standard proof of Holder for Lorentz spaces uses dyadic decomposition by width (as can be seen here , Theorem 6.9). So I guess my question really is: Can we use decomposition by height to tackle this one? I'd like to think that it's possible. I tried to adapt the width method but the supports wouldn't play nice. If it is not possible, I'd like to know how one can figure out which characterization is better for a particular problem. Is there anything in the inequality that suggests the width approach would be better than the height approach?",,"['functional-analysis', 'proof-explanation', 'alternative-proof', 'harmonic-analysis', 'holder-inequality']"
81,Hölder continuity definition through distributions.,Hölder continuity definition through distributions.,,"I am trying to prove that for a given Hölder parameter $\alpha \in (0, 1)$ and a distribution $f \in \mathcal{D}'(\mathbb{R}^d)$ the following are equivalent: $f \in C^{\alpha}$ For any $x$ there exists a polynomial $P_x$ such that $| \langle f - P_x, \phi_x^{\lambda} \rangle | \le C \lambda^{\alpha.}$ Where the latter estimate holds uniformly over all$x$ and $\phi \in \mathcal{D}$ with compact support in the unit ball, and: $$\phi_x^{\lambda}(\cdot) = \lambda^{-d} \phi\left( \frac{\cdot \ - \ x}{\lambda} \right)$$ Proving that the first implies the second is fairly easy. The other way around gives me some problems. The first step I took is to realize that we care only about the order zero term of $P_x,$ since all other terms vanish at a order higher than $\alpha.$ Here we assume that the polynomial is centered in $x.$ Then I would like to prove that $P_x(x) = g(x)$ defines a $\alpha$ - Hölder function. Thus we would get that $g \in \mathcal{D}'.$ Eventually I would like to prove that $g = f$ in $\mathcal{D}'.$ My problem is that I can't prove any implications between 2,3,4 nor any of 2,3,4 starting from 1. Any hints, help, suggestions?","I am trying to prove that for a given Hölder parameter $\alpha \in (0, 1)$ and a distribution $f \in \mathcal{D}'(\mathbb{R}^d)$ the following are equivalent: $f \in C^{\alpha}$ For any $x$ there exists a polynomial $P_x$ such that $| \langle f - P_x, \phi_x^{\lambda} \rangle | \le C \lambda^{\alpha.}$ Where the latter estimate holds uniformly over all$x$ and $\phi \in \mathcal{D}$ with compact support in the unit ball, and: $$\phi_x^{\lambda}(\cdot) = \lambda^{-d} \phi\left( \frac{\cdot \ - \ x}{\lambda} \right)$$ Proving that the first implies the second is fairly easy. The other way around gives me some problems. The first step I took is to realize that we care only about the order zero term of $P_x,$ since all other terms vanish at a order higher than $\alpha.$ Here we assume that the polynomial is centered in $x.$ Then I would like to prove that $P_x(x) = g(x)$ defines a $\alpha$ - Hölder function. Thus we would get that $g \in \mathcal{D}'.$ Eventually I would like to prove that $g = f$ in $\mathcal{D}'.$ My problem is that I can't prove any implications between 2,3,4 nor any of 2,3,4 starting from 1. Any hints, help, suggestions?",,"['functional-analysis', 'distribution-theory', 'holder-spaces', 'stochastic-pde']"
82,When is the space $L^\infty(\mu)$ finite-dimensional?,When is the space  finite-dimensional?,L^\infty(\mu),"There is a theorem that for a given $p\in [1,\infty)$ a space $L^p(\mu)$ is finite dimensional iff the set of values of $\mu$ is finite. Is a similar theorem for the space $L^\infty(\mu)$  for general positive measure $\mu$ ( finite or infinite)? Edit. Idea of the proof for $L^p(\mu)$ with $p\in [1,\infty)$. We show that if the set of values of $\mu$ is infinite then $dim L^p(\mu)=\infty$. There exists a sequence of pairwise disjoint measurable subsets of $X$ such that $0<\mu(P_n)<\infty$ with the property that the  following set is infinite $$ \{\mu(D): D \textrm{ is measurable, } D\subset X\setminus \bigcup_{k=1}^n P_k \} $$ For, we take measurable $D_1 $  be such that  $0< \mu (D_1)<\mu(X)$ and $D_2=X\setminus D_1$. Let $$ W_1=\{\mu(D): D \textrm{ is measurable}, D \subset D_1 \}, $$ $$ W_2=\{\mu(D): D \textrm{ is measurable} , D \subset D_2 \}. $$ At least one among the sets $W_1, W_2$ is infinite, since for arbitrary measurable $D$ we have $D=(D\cap D_1) \cup (D\cap D_2)$. Let $P_1=D_1$ if $W_1$ is finite and $P_2=D_2$ if $W_2$ is finite. Let pairwise disjoint measurable $P_1,...,P_n $  with the property $0<\mu(P_i)<\infty$ and such that the set $\{\mu(D): D \textrm{ is measurable}, D\subset X\setminus \bigcup_{k=1}^n P_k \}$ is infinite  be defined. Let $X_n=X\setminus \bigcup_{k=1}^n P_k$. Then there is a measurable  $E_1\subset X_n$ such that $0<\mu(E_1)<\mu(X_n)$. Let $E_2:=X_n\setminus E_1$. We put $$ V_1=\{\mu(D): D \textrm{ is measurable}, D \subset E_1 \}, $$ $$ V_2=\{\mu(D): D \textrm{ is measurable }, D \subset E_2 \}. $$ We define $P_{n+1}=E_1$ or $E_2$ depending on $V_1$ or $V_2$ is finite. The characteristic functions of sets $P_1, P_2,...$ are linearly independent. We show that if a set of values of $\mu$ is finite then $dim L^p(\mu)<\infty$. Let $x_1$ be a smallest positive finite value of measure  and let $\mu(D_1)=x_1$. Then $D_1$ is an atom. Next we take the smallest positive finite value $x_2$ of the measure on $X\setminus D_1$ and a set $D_2 \subset X\setminus D_1$ with $\mu(D_2)=x_2$-it is an atom, and so on. The procedure have to finish after finite many steps, say $n$ steps. On the set $X \setminus (D_1\cup...\cup D_n)$ the measure takes at most two values: zero and infinity, hence each function from $L^p(\mu)$ is zero a.a on this set. On arbitrary atom measurable function is constant a.a. (because it is true for measurable simple functions). Hence arbitrary function from $L^p(\mu)$ is equal a.a to linear combination of characteristic function of atoms $D_1,...,D_n$.","There is a theorem that for a given $p\in [1,\infty)$ a space $L^p(\mu)$ is finite dimensional iff the set of values of $\mu$ is finite. Is a similar theorem for the space $L^\infty(\mu)$  for general positive measure $\mu$ ( finite or infinite)? Edit. Idea of the proof for $L^p(\mu)$ with $p\in [1,\infty)$. We show that if the set of values of $\mu$ is infinite then $dim L^p(\mu)=\infty$. There exists a sequence of pairwise disjoint measurable subsets of $X$ such that $0<\mu(P_n)<\infty$ with the property that the  following set is infinite $$ \{\mu(D): D \textrm{ is measurable, } D\subset X\setminus \bigcup_{k=1}^n P_k \} $$ For, we take measurable $D_1 $  be such that  $0< \mu (D_1)<\mu(X)$ and $D_2=X\setminus D_1$. Let $$ W_1=\{\mu(D): D \textrm{ is measurable}, D \subset D_1 \}, $$ $$ W_2=\{\mu(D): D \textrm{ is measurable} , D \subset D_2 \}. $$ At least one among the sets $W_1, W_2$ is infinite, since for arbitrary measurable $D$ we have $D=(D\cap D_1) \cup (D\cap D_2)$. Let $P_1=D_1$ if $W_1$ is finite and $P_2=D_2$ if $W_2$ is finite. Let pairwise disjoint measurable $P_1,...,P_n $  with the property $0<\mu(P_i)<\infty$ and such that the set $\{\mu(D): D \textrm{ is measurable}, D\subset X\setminus \bigcup_{k=1}^n P_k \}$ is infinite  be defined. Let $X_n=X\setminus \bigcup_{k=1}^n P_k$. Then there is a measurable  $E_1\subset X_n$ such that $0<\mu(E_1)<\mu(X_n)$. Let $E_2:=X_n\setminus E_1$. We put $$ V_1=\{\mu(D): D \textrm{ is measurable}, D \subset E_1 \}, $$ $$ V_2=\{\mu(D): D \textrm{ is measurable }, D \subset E_2 \}. $$ We define $P_{n+1}=E_1$ or $E_2$ depending on $V_1$ or $V_2$ is finite. The characteristic functions of sets $P_1, P_2,...$ are linearly independent. We show that if a set of values of $\mu$ is finite then $dim L^p(\mu)<\infty$. Let $x_1$ be a smallest positive finite value of measure  and let $\mu(D_1)=x_1$. Then $D_1$ is an atom. Next we take the smallest positive finite value $x_2$ of the measure on $X\setminus D_1$ and a set $D_2 \subset X\setminus D_1$ with $\mu(D_2)=x_2$-it is an atom, and so on. The procedure have to finish after finite many steps, say $n$ steps. On the set $X \setminus (D_1\cup...\cup D_n)$ the measure takes at most two values: zero and infinity, hence each function from $L^p(\mu)$ is zero a.a on this set. On arbitrary atom measurable function is constant a.a. (because it is true for measurable simple functions). Hence arbitrary function from $L^p(\mu)$ is equal a.a to linear combination of characteristic function of atoms $D_1,...,D_n$.",,"['analysis', 'functional-analysis', 'measure-theory', 'lp-spaces']"
83,Error in Stein Shakarchi Exercise on $H^{1}(\mathbb{R})$ and $L\log L$,Error in Stein Shakarchi Exercise on  and,H^{1}(\mathbb{R}) L\log L,"In Stein and Shakarchi's Functional Analysis (Princeton Lectures in Analysis Vol. 4), the authors claim in Section 2 Exercise 17 that the function     $$f(x):=\dfrac{\chi_{|x|\leq 1/2}}{x(\log|x|)^{2}}$$ does not belong to the real Hardy space $H^{1}(\mathbb{R})$. Specifically, the authors write ""Consider the function $f$ defined by $f(x)=1/(x((\log x)^{2})$ for $0<x\leq 1/2$ and $f(x)=0$ if $x>1/2$, and extended to $x<0$ by $f(x)=-f(-x)$. Then $f$ is integrable on $\mathbb{R}$, with $\int f=0$, hence $f$ is a multiple of a 1-atom in the terminology of Section 5.2 Verify that $M(f)\geq c/(|x|\log|x|)$ for $|x|\leq 1/2$, hence $M(f)\notin L^{1}$, thus by Theorem 6.1 we know that $f\notin H_{r}^{1}$."" $H_{r}^{1}$ is their notation for the (atomic) real Hardy space. Theorem 6.1 refers to the $L^{1}$ boundedness of the maximal convolution operator $M(f)(x):=\sup_{t>0}|\Phi_{t}\ast f(x)|$ on $H_{r}^{1}$, where $\Phi$ is $C^{1}$ and compactly supported. This seems false. Decompose $f$ as     $$\sum_{j=2}^{\infty}f_{j},\quad f_{j}:=f\chi_{2^{-j}\leq |x| < 2^{-j+1}}$$ Then     $$\|f_{j}\|_{L^{\infty}}\leq \left(2^{-j}(\log|2^{-j+1}|)^{2}\right)^{-1}=\dfrac{2^{j}}{(j-1)^{2}(\log 2)^{2}}\leq c2^{-j}j^{-2}$$ By odd symmetry $\int f_{j}=0$ for all $j$. Since $|\left\{2^{-j}\leq x<2^{-j+1}\right\}|=2^{-j+1}$, we can define $\infty$-atoms $a_{j}$ by     $$a_{j}(x):=(2c)^{-1}j^{2}f_{j}$$ and write     $$f=\sum_{j}2cj^{-2}a_{j},$$ which belongs to $H^{1}(\mathbb{R})$. In fact, it seems that $f$ is precisely an example that the subspace of compactly supported $L\log L$ functions is properly contained in $H^{1}(\mathbb{R})$. Indeed, for $c>0$ sufficiently small     \begin{align*} 		\int_{-1/2}^{1/2}|f(x)|\log^{+}|f(x)|dx&=\int_{-c}^{c}\dfrac{1}{|x|(-\log|x|)}dx=\infty 	\end{align*} One can also see that $f\notin L\log L$, as the Hardy-Littlewood maximal function of $f$ is not integrable on a neighborhood of the origin. Returning to my original assertion, am I being silly here? Or is this indeed an error in the text.","In Stein and Shakarchi's Functional Analysis (Princeton Lectures in Analysis Vol. 4), the authors claim in Section 2 Exercise 17 that the function     $$f(x):=\dfrac{\chi_{|x|\leq 1/2}}{x(\log|x|)^{2}}$$ does not belong to the real Hardy space $H^{1}(\mathbb{R})$. Specifically, the authors write ""Consider the function $f$ defined by $f(x)=1/(x((\log x)^{2})$ for $0<x\leq 1/2$ and $f(x)=0$ if $x>1/2$, and extended to $x<0$ by $f(x)=-f(-x)$. Then $f$ is integrable on $\mathbb{R}$, with $\int f=0$, hence $f$ is a multiple of a 1-atom in the terminology of Section 5.2 Verify that $M(f)\geq c/(|x|\log|x|)$ for $|x|\leq 1/2$, hence $M(f)\notin L^{1}$, thus by Theorem 6.1 we know that $f\notin H_{r}^{1}$."" $H_{r}^{1}$ is their notation for the (atomic) real Hardy space. Theorem 6.1 refers to the $L^{1}$ boundedness of the maximal convolution operator $M(f)(x):=\sup_{t>0}|\Phi_{t}\ast f(x)|$ on $H_{r}^{1}$, where $\Phi$ is $C^{1}$ and compactly supported. This seems false. Decompose $f$ as     $$\sum_{j=2}^{\infty}f_{j},\quad f_{j}:=f\chi_{2^{-j}\leq |x| < 2^{-j+1}}$$ Then     $$\|f_{j}\|_{L^{\infty}}\leq \left(2^{-j}(\log|2^{-j+1}|)^{2}\right)^{-1}=\dfrac{2^{j}}{(j-1)^{2}(\log 2)^{2}}\leq c2^{-j}j^{-2}$$ By odd symmetry $\int f_{j}=0$ for all $j$. Since $|\left\{2^{-j}\leq x<2^{-j+1}\right\}|=2^{-j+1}$, we can define $\infty$-atoms $a_{j}$ by     $$a_{j}(x):=(2c)^{-1}j^{2}f_{j}$$ and write     $$f=\sum_{j}2cj^{-2}a_{j},$$ which belongs to $H^{1}(\mathbb{R})$. In fact, it seems that $f$ is precisely an example that the subspace of compactly supported $L\log L$ functions is properly contained in $H^{1}(\mathbb{R})$. Indeed, for $c>0$ sufficiently small     \begin{align*} 		\int_{-1/2}^{1/2}|f(x)|\log^{+}|f(x)|dx&=\int_{-c}^{c}\dfrac{1}{|x|(-\log|x|)}dx=\infty 	\end{align*} One can also see that $f\notin L\log L$, as the Hardy-Littlewood maximal function of $f$ is not integrable on a neighborhood of the origin. Returning to my original assertion, am I being silly here? Or is this indeed an error in the text.",,"['functional-analysis', 'harmonic-analysis', 'hardy-spaces']"
84,Generalized Fourier series in $L^2$ that do not converge pointwise a.e.,Generalized Fourier series in  that do not converge pointwise a.e.,L^2,"For a Hilbert space $L^2$ we have the notion of an orthonormal basis $\{f_j\}$ being a sequence of orthonormal elements such that any element $f$ in $L^2$ can be approximated by partial sums in terms of this basis $$f = \sum_{j=1}^\infty \langle f, f_j \rangle f_j$$ Here the sum converges wrt the $L^2$ norm.  This is what I mean by generalized Fourier series. I have been reading about Carleson's Theorem that says specifically for Fourier series, the series converges pointwise almost everywhere to the approximated function.  I have also read that this is not true for a general orthonormal basis.  I was hoping someone would be able to provide me with an example demonstrating that statement on a finite measure space, maybe $L^2([0,1])$: A function whose partial sums in terms of the basis do not convergence pointwise almost everywhere.","For a Hilbert space $L^2$ we have the notion of an orthonormal basis $\{f_j\}$ being a sequence of orthonormal elements such that any element $f$ in $L^2$ can be approximated by partial sums in terms of this basis $$f = \sum_{j=1}^\infty \langle f, f_j \rangle f_j$$ Here the sum converges wrt the $L^2$ norm.  This is what I mean by generalized Fourier series. I have been reading about Carleson's Theorem that says specifically for Fourier series, the series converges pointwise almost everywhere to the approximated function.  I have also read that this is not true for a general orthonormal basis.  I was hoping someone would be able to provide me with an example demonstrating that statement on a finite measure space, maybe $L^2([0,1])$: A function whose partial sums in terms of the basis do not convergence pointwise almost everywhere.",,"['functional-analysis', 'hilbert-spaces', 'fourier-series']"
85,Open neighbourhoods in topological vector spaces,Open neighbourhoods in topological vector spaces,,"It is well known that each open ball in a Banach space is homeomorphic to the whole space. Can we extend this to topological vector spaces? In other words, does every non-void open set in a non-discrete, Hausdorff topological vector space contain a set that is homeomorphic to the whole space? What if we assume local convexity?","It is well known that each open ball in a Banach space is homeomorphic to the whole space. Can we extend this to topological vector spaces? In other words, does every non-void open set in a non-discrete, Hausdorff topological vector space contain a set that is homeomorphic to the whole space? What if we assume local convexity?",,"['functional-analysis', 'topological-vector-spaces']"
86,"Why are ""not bounded"" operators not everywhere defined?","Why are ""not bounded"" operators not everywhere defined?",,"Let $X, Y$ be Banach spaces, $\mathcal{D}(T)$ a subspace of $X$, and $T\colon X\to  Y$ a linear map. Such a $T$ is commonly called an unbounded linear operator , where unbounded just means that the domain $\mathcal{D}(T)$ is possibly a strict subspace of $X$. I am confused by all the general questions flying around this definition and ask for some clarification. Is there a general argument why we consider such operators which are not defined on the whole space? In other words, I am interested in the following statement: Statement. $\mathcal{D}(T)=X$ $\Rightarrow$ $T$ is bounded, or equivalently, $T$ is not bounded $\Rightarrow$ $\mathcal{D}(T)\neq X$. In this context it might be interesting to look at the closed graph theorem: And operator defined on all of $X$ is bounded if and only if it is closed. Therefore it makes sense to ask whether there exist operators defined on all of $X$ which are not bounded. There are many specific cases when this definition comes in handy. For example, differential operators are often first defined on a small class of functions (e.g. compactly supported, smooth functions) and can then be extended to larger domains. But here I am really considering any spaces and operators. Of course, it would be interesting to know whether and how this changes when we restrict $X, Y$ to be Hilbert spaces.","Let $X, Y$ be Banach spaces, $\mathcal{D}(T)$ a subspace of $X$, and $T\colon X\to  Y$ a linear map. Such a $T$ is commonly called an unbounded linear operator , where unbounded just means that the domain $\mathcal{D}(T)$ is possibly a strict subspace of $X$. I am confused by all the general questions flying around this definition and ask for some clarification. Is there a general argument why we consider such operators which are not defined on the whole space? In other words, I am interested in the following statement: Statement. $\mathcal{D}(T)=X$ $\Rightarrow$ $T$ is bounded, or equivalently, $T$ is not bounded $\Rightarrow$ $\mathcal{D}(T)\neq X$. In this context it might be interesting to look at the closed graph theorem: And operator defined on all of $X$ is bounded if and only if it is closed. Therefore it makes sense to ask whether there exist operators defined on all of $X$ which are not bounded. There are many specific cases when this definition comes in handy. For example, differential operators are often first defined on a small class of functions (e.g. compactly supported, smooth functions) and can then be extended to larger domains. But here I am really considering any spaces and operators. Of course, it would be interesting to know whether and how this changes when we restrict $X, Y$ to be Hilbert spaces.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'banach-spaces']"
87,$L^p$-space inclusions,-space inclusions,L^p,"Let $1\leq p<q<\infty$ . Which of the following inclusions are true? $L^p(0,1)\subset L^q(0,1)$ $L^q(0,1)\subset L^p(0,1)$ $L^p(0,\infty)\subset L^q(0,\infty)$ $L^q(0,\infty)\subset L^q(0,\infty)$ I already know that 1. is false (consider $f(x)=1/\sqrt{x}$ with $p=1$ , $q=2$ ) and 2. holds, which can be shown using the Hölder-inequality. Now I'm not sure about 3. and 4. I think 3. doesn't hold either, but cannot think of an example to show this. Finally 4. I think is wrong either, since as far as I know the inclusion $L^q(\Omega)\subset L^p(\Omega)$ only holds if $\lambda(\Omega)<\infty$ . But again, I cannot think of a counter-example for this either. Can anyone think of good examples for this? (Or correct my answer if I'm wrong) Thanks!","Let . Which of the following inclusions are true? I already know that 1. is false (consider with , ) and 2. holds, which can be shown using the Hölder-inequality. Now I'm not sure about 3. and 4. I think 3. doesn't hold either, but cannot think of an example to show this. Finally 4. I think is wrong either, since as far as I know the inclusion only holds if . But again, I cannot think of a counter-example for this either. Can anyone think of good examples for this? (Or correct my answer if I'm wrong) Thanks!","1\leq p<q<\infty L^p(0,1)\subset L^q(0,1) L^q(0,1)\subset L^p(0,1) L^p(0,\infty)\subset L^q(0,\infty) L^q(0,\infty)\subset L^q(0,\infty) f(x)=1/\sqrt{x} p=1 q=2 L^q(\Omega)\subset L^p(\Omega) \lambda(\Omega)<\infty","['functional-analysis', 'measure-theory', 'lebesgue-integral', 'lp-spaces']"
88,Operator with invertible adjoint,Operator with invertible adjoint,,"Let $X, Y$ be normed spaces and $T : X \to Y$ bounded and linear, such that its adjoint $T^* : X^* \to Y^*$ is boundedly invertible. If $X$ and $Y$ are Banach spaces, then $T$ is also boundedly invertible, see, e.g., the answer here: Show $T$ is invertible if $T'$ is invertible where $T\in B(X)$, $T'\in B(X')$ However, I suspect that this is not true if $X$ or $Y$ are not complete. Is there a simple example for such a non-invertible $T$ with invertible $T^*$? Edit: I found some simple examples in case $X$ is not complete: Let $X$ be a dense, proper subspace of an reflexive space $Z$. Let $T = i_{X}: X \to X^{**} = Z^{**}$ and $S = i_{X^*} : X^*=Z^* \to X^{***}=Z^{***} $ be the canonical embeddings into the biduals. Then, one can show $T^* = S^{-1}$. Hence, $T^*$ is invertible, but $T$ is not. Therefore, only the case $X$ complete, $Y$ not complete is left. If I do not miss something, we get that $T$ is (not necessarily boundedly) invertible in this case.","Let $X, Y$ be normed spaces and $T : X \to Y$ bounded and linear, such that its adjoint $T^* : X^* \to Y^*$ is boundedly invertible. If $X$ and $Y$ are Banach spaces, then $T$ is also boundedly invertible, see, e.g., the answer here: Show $T$ is invertible if $T'$ is invertible where $T\in B(X)$, $T'\in B(X')$ However, I suspect that this is not true if $X$ or $Y$ are not complete. Is there a simple example for such a non-invertible $T$ with invertible $T^*$? Edit: I found some simple examples in case $X$ is not complete: Let $X$ be a dense, proper subspace of an reflexive space $Z$. Let $T = i_{X}: X \to X^{**} = Z^{**}$ and $S = i_{X^*} : X^*=Z^* \to X^{***}=Z^{***} $ be the canonical embeddings into the biduals. Then, one can show $T^* = S^{-1}$. Hence, $T^*$ is invertible, but $T$ is not. Therefore, only the case $X$ complete, $Y$ not complete is left. If I do not miss something, we get that $T$ is (not necessarily boundedly) invertible in this case.",,"['functional-analysis', 'examples-counterexamples']"
89,Is there a nonnormal operator with spectrum strictly continuous?,Is there a nonnormal operator with spectrum strictly continuous?,,"Let $H$ be an infinite dimensional separable Hilbert space. Definition : An operator $A \in B(H)$ is normal if $AA^{*} = A^{*}A$. Definition : The spectrum $\sigma(A)$ of $A \in B(H)$, is the set of all $\lambda \in \mathbb{C}$ such that $A - \lambda I$ is not bijective. It decomposes as follows: - Point spectrum : $\sigma_{p}(A) = \{\lambda \in \mathbb{C} : A - \lambda I \text{ not injective}   \}$ - Continuous spectrum : $\sigma_{c}(A) = \{\lambda \in \mathbb{C} : A - \lambda I \ \text{ injective with a dense nonclosed range}   \}$ - Residual spectrum : $\sigma_{r}(A) = \{\lambda \in \mathbb{C} : A - \lambda I \ \text{ injective with a nondense range}   \}$ Examples : Let $S$ be the bilateral shift defined on $H = l^{2}(\mathbb{Z})$ by $S.e_{n} = e_{n+1} $. Its spectrum is strictly continuous :   $\sigma(S) = \sigma_{c}(S) = \mathbb{S}^{1}$. It's also a unitary operator ($SS^{*} = S^{*}S = I$), so a fortiori a normal operator. Let $T$ be the unilateral shift defined on $H = l^{2}(\mathbb{N})$ by $T.e_{n} = e_{n+1} $. Its spectrum is not strictly continuous because $0 \in \sigma_{r}(T)$. It's a nonnormal operator because $[T^{*},T].e_{0} = e_{0}$. Is there a nonnormal operator with spectrum strictly continuous ? Bonus questions : Can we exclude the compact operators ? How classify these operators ?","Let $H$ be an infinite dimensional separable Hilbert space. Definition : An operator $A \in B(H)$ is normal if $AA^{*} = A^{*}A$. Definition : The spectrum $\sigma(A)$ of $A \in B(H)$, is the set of all $\lambda \in \mathbb{C}$ such that $A - \lambda I$ is not bijective. It decomposes as follows: - Point spectrum : $\sigma_{p}(A) = \{\lambda \in \mathbb{C} : A - \lambda I \text{ not injective}   \}$ - Continuous spectrum : $\sigma_{c}(A) = \{\lambda \in \mathbb{C} : A - \lambda I \ \text{ injective with a dense nonclosed range}   \}$ - Residual spectrum : $\sigma_{r}(A) = \{\lambda \in \mathbb{C} : A - \lambda I \ \text{ injective with a nondense range}   \}$ Examples : Let $S$ be the bilateral shift defined on $H = l^{2}(\mathbb{Z})$ by $S.e_{n} = e_{n+1} $. Its spectrum is strictly continuous :   $\sigma(S) = \sigma_{c}(S) = \mathbb{S}^{1}$. It's also a unitary operator ($SS^{*} = S^{*}S = I$), so a fortiori a normal operator. Let $T$ be the unilateral shift defined on $H = l^{2}(\mathbb{N})$ by $T.e_{n} = e_{n+1} $. Its spectrum is not strictly continuous because $0 \in \sigma_{r}(T)$. It's a nonnormal operator because $[T^{*},T].e_{0} = e_{0}$. Is there a nonnormal operator with spectrum strictly continuous ? Bonus questions : Can we exclude the compact operators ? How classify these operators ?",,"['functional-analysis', 'operator-theory']"
90,Traces on separable simple $C^{\ast}$- algebras,Traces on separable simple - algebras,C^{\ast},"What is an example of a separable, simple $C^{\ast}$-algebra that admits two different tracial states? EDIT: Julien has pointed to a number of avenues to answer this question. If anyone has an electronic copy of the paper of Longo he links to in the comment below, please post a summary of the argument. It would be nice to have access to a nice simple construction as advertised in the abstract of that paper.","What is an example of a separable, simple $C^{\ast}$-algebra that admits two different tracial states? EDIT: Julien has pointed to a number of avenues to answer this question. If anyone has an electronic copy of the paper of Longo he links to in the comment below, please post a summary of the argument. It would be nice to have access to a nice simple construction as advertised in the abstract of that paper.",,"['functional-analysis', 'reference-request', 'operator-algebras']"
91,existence of a minimizer for functional,existence of a minimizer for functional,,"My problem is the following: Show that the mapping $u \rightarrow ||\nabla u||^2 + (fu,u)$ has a minimum $u$ in $M:=\{ w \in H^1(\Omega): ||w||=1\}$ .  The function $f$ is in $L^\infty$. I dont see how to start here. What is needed for a proof? Thanks for every hint! James T.","My problem is the following: Show that the mapping $u \rightarrow ||\nabla u||^2 + (fu,u)$ has a minimum $u$ in $M:=\{ w \in H^1(\Omega): ||w||=1\}$ .  The function $f$ is in $L^\infty$. I dont see how to start here. What is needed for a proof? Thanks for every hint! James T.",,"['functional-analysis', 'calculus-of-variations']"
92,Locally integrable functions,Locally integrable functions,,"Formulation: Let $v\in L^1_\text{loc}(\mathbb{R}^3)$ and $f \in H^1(\mathbb{R}^3)$ such that  \begin{equation}   \int f^2 v_+ = \int f^2 v_- = +\infty. \end{equation} Here, $v_- = \max(0,-f)$, $v_+ = \max(0,f)$, i.e., the negative and positive parts of $v=v_+ - v_-$, respectively. Question: Does $g\in H^1(\mathbb{R}^3)$ exist, such that  \begin{equation}   \int g^2 v_+ < \infty, \quad \int g^2 v_- = +\infty \quad ? \end{equation} Some thoughts: Let $S_\pm$ be the supports of $v_\pm$, respectively. One can easily find $g\in L^2$ such that the last equation holds, simply multiply $f$ with the characteristic function of $S_-$. The intuitive approach is then by some smoothing of this function by a mollifier, or using a bump function to force the support of $g$ away from $S_+$. However, the supports of $S_\pm$ can be quite complicated: for example, fat Cantor-like sets. Thus, a bump function technique or a mollifier may ""accidentally"" fill out any of $S_\pm$. My motivation: The problem comes from my original research on the mathematical foundations of Density Functional Theory (DFT) in physics and chemistry. Here, $f^2$ is proportional to the probability density of finding an electron at a space point, and $v$ is the potential energy field of the environmentn. $\int f^2 v$ is the total potential energy for the system's state. The original $f$ gives a meaningless ""$\infty-\infty$"" result, but for certain reasons, we are out of the woods if there is some $other$ density $g$ with the prescribed property. Edit: Removed claim that $S_\pm$ must be unbounded. This does not follow from the stated assumptions.","Formulation: Let $v\in L^1_\text{loc}(\mathbb{R}^3)$ and $f \in H^1(\mathbb{R}^3)$ such that  \begin{equation}   \int f^2 v_+ = \int f^2 v_- = +\infty. \end{equation} Here, $v_- = \max(0,-f)$, $v_+ = \max(0,f)$, i.e., the negative and positive parts of $v=v_+ - v_-$, respectively. Question: Does $g\in H^1(\mathbb{R}^3)$ exist, such that  \begin{equation}   \int g^2 v_+ < \infty, \quad \int g^2 v_- = +\infty \quad ? \end{equation} Some thoughts: Let $S_\pm$ be the supports of $v_\pm$, respectively. One can easily find $g\in L^2$ such that the last equation holds, simply multiply $f$ with the characteristic function of $S_-$. The intuitive approach is then by some smoothing of this function by a mollifier, or using a bump function to force the support of $g$ away from $S_+$. However, the supports of $S_\pm$ can be quite complicated: for example, fat Cantor-like sets. Thus, a bump function technique or a mollifier may ""accidentally"" fill out any of $S_\pm$. My motivation: The problem comes from my original research on the mathematical foundations of Density Functional Theory (DFT) in physics and chemistry. Here, $f^2$ is proportional to the probability density of finding an electron at a space point, and $v$ is the potential energy field of the environmentn. $\int f^2 v$ is the total potential energy for the system's state. The original $f$ gives a meaningless ""$\infty-\infty$"" result, but for certain reasons, we are out of the woods if there is some $other$ density $g$ with the prescribed property. Edit: Removed claim that $S_\pm$ must be unbounded. This does not follow from the stated assumptions.",,"['analysis', 'functional-analysis']"
93,"Rainwater theorem, convergence of nets, initial topology","Rainwater theorem, convergence of nets, initial topology",,"I've stumbled upon a result called Rainwater's theorem a few times, it seems to be a very useful result in connection with weak convergence in Banach spaces. Rainwater's theorem. Let $X$ be a Banach space, let $\{x_n\}$ be a bounded sequence in $X$ and $x \in X$. If $f(x_n)\to f(x)$ for every $f\in\operatorname{Ext}(B_{X^*})$, then $x_n \overset{w}\to x$. The symbol $x_n \overset{w}\to x$ denotes the convergence in weak topology .  By $B_{X^*}$ we denote the unit ball of the dual $X^*$ (with respect to the usual operator norm ) and $\operatorname{Ext}(B_{X^*})$ is the set of all extreme points of this set. See e.g. Corollary 3.137, p.140 in Banach Space Theory: The Basis for Linear and Nonlinear Analysis by Marián Fabian, Petr Habala, Petr Hájek, Vicente Montesinos, Václav Zizler. In particular, if we apply the above to the space $C(K)$, where $K$ is compact, we get the following result (Corollary 3.138) in the same book. Corollary. Let $K$ be a compact topological space. Let $\{f_n\}$ be a bounded   sequence in $C(K)$ and $f\in C(K)$. Then, if $f_n\to f$ pointwise, we have $f_n \overset{w}\to f$. Weak convergence of a sequence in $X$ means, by definition, that $f(x_n)\to f(x)$ for each $f\in X^*$. Rainwater's theorem essentially says that there is a smaller set of functionals we need to check - namely the set $\operatorname{Ext}(B_{X^*})$. It is quite natural to ask whether the same is true for nets. Let $(x_\sigma)_{\sigma\in\Sigma}$ be a net in a Banach space $X$ and let $x\in X$. Is it true that $x_\sigma \overset{w}\to x$ if and only if $f(x_\sigma)\to f(x)$ for every $f\in\operatorname{Ext}(B_{X^*})$? The weak topology is precisely the initial topology on $X$ w.r.t. all linear continuous functionals. Again, it is natural to ask whether we can replace $X^*$ by a smaller set. In this way we get a reformulation of the above question. Is the weak topology on $X$ the initial topology w.r.t. $\operatorname{Ext}(B_{X^*})$? If the answer to the above questions is negative, I would like to know whether they hold at least for $C(K)$. If $(f_\sigma)_{\sigma\in\Sigma}$ is a net in $C(K)$ and let $f\in C(K)$. Is it true that $f_\sigma$ converges to $f$ weakly if and only if it converges pointwise? Is the weak topology on $C(K)$ the same as the initial topology w.r.t. the maps $f\mapsto f(x)$ for $x\in K$ (i.e. the evaluations at all points of $K$)?","I've stumbled upon a result called Rainwater's theorem a few times, it seems to be a very useful result in connection with weak convergence in Banach spaces. Rainwater's theorem. Let $X$ be a Banach space, let $\{x_n\}$ be a bounded sequence in $X$ and $x \in X$. If $f(x_n)\to f(x)$ for every $f\in\operatorname{Ext}(B_{X^*})$, then $x_n \overset{w}\to x$. The symbol $x_n \overset{w}\to x$ denotes the convergence in weak topology .  By $B_{X^*}$ we denote the unit ball of the dual $X^*$ (with respect to the usual operator norm ) and $\operatorname{Ext}(B_{X^*})$ is the set of all extreme points of this set. See e.g. Corollary 3.137, p.140 in Banach Space Theory: The Basis for Linear and Nonlinear Analysis by Marián Fabian, Petr Habala, Petr Hájek, Vicente Montesinos, Václav Zizler. In particular, if we apply the above to the space $C(K)$, where $K$ is compact, we get the following result (Corollary 3.138) in the same book. Corollary. Let $K$ be a compact topological space. Let $\{f_n\}$ be a bounded   sequence in $C(K)$ and $f\in C(K)$. Then, if $f_n\to f$ pointwise, we have $f_n \overset{w}\to f$. Weak convergence of a sequence in $X$ means, by definition, that $f(x_n)\to f(x)$ for each $f\in X^*$. Rainwater's theorem essentially says that there is a smaller set of functionals we need to check - namely the set $\operatorname{Ext}(B_{X^*})$. It is quite natural to ask whether the same is true for nets. Let $(x_\sigma)_{\sigma\in\Sigma}$ be a net in a Banach space $X$ and let $x\in X$. Is it true that $x_\sigma \overset{w}\to x$ if and only if $f(x_\sigma)\to f(x)$ for every $f\in\operatorname{Ext}(B_{X^*})$? The weak topology is precisely the initial topology on $X$ w.r.t. all linear continuous functionals. Again, it is natural to ask whether we can replace $X^*$ by a smaller set. In this way we get a reformulation of the above question. Is the weak topology on $X$ the initial topology w.r.t. $\operatorname{Ext}(B_{X^*})$? If the answer to the above questions is negative, I would like to know whether they hold at least for $C(K)$. If $(f_\sigma)_{\sigma\in\Sigma}$ is a net in $C(K)$ and let $f\in C(K)$. Is it true that $f_\sigma$ converges to $f$ weakly if and only if it converges pointwise? Is the weak topology on $C(K)$ the same as the initial topology w.r.t. the maps $f\mapsto f(x)$ for $x\in K$ (i.e. the evaluations at all points of $K$)?",,"['functional-analysis', 'banach-spaces', 'examples-counterexamples', 'locally-convex-spaces']"
94,Weak-* continuity of the adjoint map on a $W^*$-algebra,Weak-* continuity of the adjoint map on a -algebra,W^*,"Let $\mathcal{M}$ be a $W^*$-algebra, i.e. a $C^*$-algebra with a Banach space predual $\mathcal{M}_*$.  I'm trying to show that the adjoint map $x \mapsto x^*$ on $\mathcal{M}$ is weak-* (aka $\sigma$-weakly) continuous. Chapter 1.7 of Sakai's $C^*$-Algebra and $W^*$-Algebras starts by proving that the real-linear subspace $\mathcal{M}^s$ of self-adjoint elements is weak-* closed.  Later (in 1.7.2 as well as 1.7.8) he asserts that this, plus the fact that $\mathcal{M}^s \cap i \mathcal{M}^s = \{0\}$ and $\mathcal{M}^s + i \mathcal{M}^s = \mathcal{M}$, imply that the adjoint map is weak-* continuous.  I'm afraid I don't quite follow. We know that $\mathcal{M}$ is the algebraic direct sum of the weak-* closed, real-linear subspaces $\mathcal{M}^s$ and $i \mathcal{M}^s$.  However, not every algebraic complement is a topological complement.  I don't know of many sufficient conditions for algebraic complements to automatically be topological.  One is that the space in question be Fréchet, but if $\mathcal{M}_*$ is infinite-dimensional then $\mathcal{M}$ cannot be weak-* Fréchet. The restriction of the adjoint map to the unit ball of $\mathcal{M}$ is continuous: If $x_\nu + i y_\nu \to x+iy$ is a convergent net in the unit ball with $x,y,x_\nu, y_\nu$ self-adjoint, then $x_\nu, y_\nu, x, y$ are also in the unit ball; given any subnet, there exists (by Alaoglu) a sub-subnet for which $x_\nu$ converges weak-* to some $\tilde{x}$ in the unit ball, and a sub-sub-subnet for which $y_\nu$ also converges weak-* to some $\tilde{y}$ in the unit ball.  (I'm using the same notation for all subnets instead of writing things like $x_{\nu_{\mu_{\eta_\zeta}}}$.)  Because $\mathcal{M}^s$ is weak-* closed, it follows that $\tilde{x}$ and $\tilde{y}$ are self-adjoint, and since the sub-sub-subnet $x_\nu + i y_\nu$ converges to both $x+iy$ and $\tilde{x} + i\tilde{y}$, it follows that $\tilde{x} = x$ and $\tilde{y} = y$.  Then (for this same sub-sub-subnet) one has $x_\nu - i y_\nu \to x-iy$.  Since every subnet of $x_\nu - i y_\nu$ has a further subnet converging to $x-iy$, we have $x_\nu - i y_\nu \to x-iy$. Not sure how to finish given the above remarks on the unit ball.  Given a weak-* convergent net $m_\nu \to 0$, the above would immediately imply $m_\nu^* \to 0$ weak-* as well if we made the additional assumption that the net $m_\nu$ is eventually bounded...but not all weak-* convergent nets are.  Or, for any weak-* closed convex set $F \subset \mathcal{M}$, let $F_r$ denote the intersection of $F$ with the ball of radius $r$, and we then get that $F_r^*$ is weak-* closed; by Krein-Smulyan, it follows that $F^*$ is weak-* closed.  However, most closed sets aren't convex. Of course, one approach would be to (without using continuity of the adjoint) develop the theory of $W^*$-algebras far enough to get a representation theorem, then use the ultraweak continuity of the adjoint map on $B(H)$.  I'd really rather have something more direct, though!  I have a feeling I'm overlooking something obvious.","Let $\mathcal{M}$ be a $W^*$-algebra, i.e. a $C^*$-algebra with a Banach space predual $\mathcal{M}_*$.  I'm trying to show that the adjoint map $x \mapsto x^*$ on $\mathcal{M}$ is weak-* (aka $\sigma$-weakly) continuous. Chapter 1.7 of Sakai's $C^*$-Algebra and $W^*$-Algebras starts by proving that the real-linear subspace $\mathcal{M}^s$ of self-adjoint elements is weak-* closed.  Later (in 1.7.2 as well as 1.7.8) he asserts that this, plus the fact that $\mathcal{M}^s \cap i \mathcal{M}^s = \{0\}$ and $\mathcal{M}^s + i \mathcal{M}^s = \mathcal{M}$, imply that the adjoint map is weak-* continuous.  I'm afraid I don't quite follow. We know that $\mathcal{M}$ is the algebraic direct sum of the weak-* closed, real-linear subspaces $\mathcal{M}^s$ and $i \mathcal{M}^s$.  However, not every algebraic complement is a topological complement.  I don't know of many sufficient conditions for algebraic complements to automatically be topological.  One is that the space in question be Fréchet, but if $\mathcal{M}_*$ is infinite-dimensional then $\mathcal{M}$ cannot be weak-* Fréchet. The restriction of the adjoint map to the unit ball of $\mathcal{M}$ is continuous: If $x_\nu + i y_\nu \to x+iy$ is a convergent net in the unit ball with $x,y,x_\nu, y_\nu$ self-adjoint, then $x_\nu, y_\nu, x, y$ are also in the unit ball; given any subnet, there exists (by Alaoglu) a sub-subnet for which $x_\nu$ converges weak-* to some $\tilde{x}$ in the unit ball, and a sub-sub-subnet for which $y_\nu$ also converges weak-* to some $\tilde{y}$ in the unit ball.  (I'm using the same notation for all subnets instead of writing things like $x_{\nu_{\mu_{\eta_\zeta}}}$.)  Because $\mathcal{M}^s$ is weak-* closed, it follows that $\tilde{x}$ and $\tilde{y}$ are self-adjoint, and since the sub-sub-subnet $x_\nu + i y_\nu$ converges to both $x+iy$ and $\tilde{x} + i\tilde{y}$, it follows that $\tilde{x} = x$ and $\tilde{y} = y$.  Then (for this same sub-sub-subnet) one has $x_\nu - i y_\nu \to x-iy$.  Since every subnet of $x_\nu - i y_\nu$ has a further subnet converging to $x-iy$, we have $x_\nu - i y_\nu \to x-iy$. Not sure how to finish given the above remarks on the unit ball.  Given a weak-* convergent net $m_\nu \to 0$, the above would immediately imply $m_\nu^* \to 0$ weak-* as well if we made the additional assumption that the net $m_\nu$ is eventually bounded...but not all weak-* convergent nets are.  Or, for any weak-* closed convex set $F \subset \mathcal{M}$, let $F_r$ denote the intersection of $F$ with the ball of radius $r$, and we then get that $F_r^*$ is weak-* closed; by Krein-Smulyan, it follows that $F^*$ is weak-* closed.  However, most closed sets aren't convex. Of course, one approach would be to (without using continuity of the adjoint) develop the theory of $W^*$-algebras far enough to get a representation theorem, then use the ultraweak continuity of the adjoint map on $B(H)$.  I'd really rather have something more direct, though!  I have a feeling I'm overlooking something obvious.",,"['functional-analysis', 'banach-spaces', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
95,Constructing a countable family of seminorms in a metrizable LCS.,Constructing a countable family of seminorms in a metrizable LCS.,,"Here's some context before my question. Let $\mathbb{V}$ be a topological vector space, which is Hausdorff and such that its topology is generated by some arbitrary family of seminorms $\{\rho_{\alpha}\}_{\alpha \in I}$; this means that $\mathbb{V}$ is locally convex. Now, if $I$ turns out to be countable (or if we can reduce the family $\{\rho_{\alpha}\}_{\alpha \in I}$ to a countable one, while keeping the same topology in $\mathbb{V}$), we can define a metric in $\mathbb{V}$ by $$d(u, v) = \sum_{i = 1}^{\infty} \frac{1}{2^i} \frac{\rho_i(u - v)}{1 + \rho_i(u - v)},$$ where $\{\rho_i\}_{i \in \mathbb{N}}$ is some enumeration of $\{\rho_{\alpha}\}_{\alpha \in I}$, so that its topology is metrizable. I've been told that the converse is also true, which leads to my question. QUESTION : Let $\mathbb{V}$ be a topological vector space having a metrizable topology, generated by some metric $d$. How can I prove that $\mathbb{V}$ admits a countable family of seminorms generating its topology? Also, do I need to impose the condition that $d$ is translation invariant (since this happens in the above construction)? Thanks.","Here's some context before my question. Let $\mathbb{V}$ be a topological vector space, which is Hausdorff and such that its topology is generated by some arbitrary family of seminorms $\{\rho_{\alpha}\}_{\alpha \in I}$; this means that $\mathbb{V}$ is locally convex. Now, if $I$ turns out to be countable (or if we can reduce the family $\{\rho_{\alpha}\}_{\alpha \in I}$ to a countable one, while keeping the same topology in $\mathbb{V}$), we can define a metric in $\mathbb{V}$ by $$d(u, v) = \sum_{i = 1}^{\infty} \frac{1}{2^i} \frac{\rho_i(u - v)}{1 + \rho_i(u - v)},$$ where $\{\rho_i\}_{i \in \mathbb{N}}$ is some enumeration of $\{\rho_{\alpha}\}_{\alpha \in I}$, so that its topology is metrizable. I've been told that the converse is also true, which leads to my question. QUESTION : Let $\mathbb{V}$ be a topological vector space having a metrizable topology, generated by some metric $d$. How can I prove that $\mathbb{V}$ admits a countable family of seminorms generating its topology? Also, do I need to impose the condition that $d$ is translation invariant (since this happens in the above construction)? Thanks.",,"['functional-analysis', 'topological-vector-spaces', 'locally-convex-spaces']"
96,"Solve $f(x) = \lambda \int\limits_{0}^1(\max(x,t)+xt)f(t)dt$",Solve,"f(x) = \lambda \int\limits_{0}^1(\max(x,t)+xt)f(t)dt","I need to solve this: $\ f(x) = \lambda \int\limits_{0}^1(\max(x,t)+xt)f(t)dt$. Rewriting it as: $\ f(x) = \lambda(\int\limits_0^x x(t+1)f(t)dt + \int\limits_x^1 t(x+1) f(t)dt)$. 1st derivative: \begin{align*} f'(x) &= \lambda\left(\int\limits_0^x (1+t)f(t)dt  + x(1+x)f(x) - xf(x) + \int\limits_x^1 tf(t)dt -  x^2f(x)\right)\\ &=\lambda\left(\int\limits_0^x f(t)dt + \int\limits_0^x tf(t)dt +  \int\limits_x^1 tf(t)dt\right)\\ &=\lambda\left(\int\limits_0^1 tf(t)dt + \int\limits_0^x f(t)dt\right) \end{align*} 2nd derivative: $\ f''(x) = \lambda f(x)$ so $f(x) = c_1 e^{\sqrt{\lambda}x} + c_2 e^{-\sqrt{\lambda}x}$ How can I find $c_1$ and $c_2$?","I need to solve this: $\ f(x) = \lambda \int\limits_{0}^1(\max(x,t)+xt)f(t)dt$. Rewriting it as: $\ f(x) = \lambda(\int\limits_0^x x(t+1)f(t)dt + \int\limits_x^1 t(x+1) f(t)dt)$. 1st derivative: \begin{align*} f'(x) &= \lambda\left(\int\limits_0^x (1+t)f(t)dt  + x(1+x)f(x) - xf(x) + \int\limits_x^1 tf(t)dt -  x^2f(x)\right)\\ &=\lambda\left(\int\limits_0^x f(t)dt + \int\limits_0^x tf(t)dt +  \int\limits_x^1 tf(t)dt\right)\\ &=\lambda\left(\int\limits_0^1 tf(t)dt + \int\limits_0^x f(t)dt\right) \end{align*} 2nd derivative: $\ f''(x) = \lambda f(x)$ so $f(x) = c_1 e^{\sqrt{\lambda}x} + c_2 e^{-\sqrt{\lambda}x}$ How can I find $c_1$ and $c_2$?",,"['functional-analysis', 'integral-equations']"
97,Orthonormal basis in Hilbert space,Orthonormal basis in Hilbert space,,I am reading a book about functional analysis and there is one thing I really don't understand. Let $\mathcal{H}$ be a Hilbert space. And $U \subset \mathcal{H}$ a closed subspace. Is it possible to choose an orthonormal basis $\{e_{i}\}_{i=1}^{\infty}$ such that there exists a subsequence of the $e_{i}$'s that span $U$ ?,I am reading a book about functional analysis and there is one thing I really don't understand. Let $\mathcal{H}$ be a Hilbert space. And $U \subset \mathcal{H}$ a closed subspace. Is it possible to choose an orthonormal basis $\{e_{i}\}_{i=1}^{\infty}$ such that there exists a subsequence of the $e_{i}$'s that span $U$ ?,,"['functional-analysis', 'hilbert-spaces']"
98,Can a sequence of trace class operators $\rho_{n} \in B(H)$ converge to a multiplication operator under trace norm?,Can a sequence of trace class operators  converge to a multiplication operator under trace norm?,\rho_{n} \in B(H),"Let $H$ be some infinite dimensional $Hilbert$ space. Now, let $B(H)$ be the set of all bounded linear operator over $H$ and let $seq :=\{\rho_{n}\}_{n=1}^{\infty}$ be a sequence of trace class operators in $B(H)$ , the trace class operators form an ideal over $B(H)$ . - My first question is this . Under what conditions, if any, does the sequence $seq$ converge to a multiplication operator under the trace norm $\| A\|_{1} : Tr(|A|)= Tr(\sqrt{A^{\dagger}A} )$ . - My second question is a more specific version of the first . If the dynamics are generated by a contracting semigroup, i.e. $$\rho_{n} = L_{n}\rho_{0}$$ where $L_{n}$ are contracting linear maps, does the limit $\lim_{n\rightarrow \infty}\|\rho_{n}\|_{1}$ exists always? If so, what is the limiting operator and is it still trace class? - My third question is essentially the second but for a particular case. I have been working with the following operator. For $\psi(x) \in H = L^{2}(\mathbb{R})$ and $\sigma_{t}\in B(H)$ is defined as follows. $$\sigma_{t}\psi(x) := \int_{\mathbb{R}} e^{-t(x-y)^{2}}K(x,y)\psi(y)dy$$ . Where $K(x,y) \in L^{2}(\mathbb{R}^{2})$ is a $Hilbert-Schmidt$ kernel. Note tha for $t=0$ this is a very tame integral transform. I am worried about the behviour as $t\rightarrow \infty$ in the trace norm sense. i.e. if the limit of $\sigma_{t}$ exists under $\| \|_{1}$ , say $\sigma_{\infty}$ , what is it?  I am guessing that it should be some multiplication operator. $\lim_{t\rightarrow \infty}\|\sigma_{t}\|_{1} = ?  .$ Thank you very much for your help.","Let be some infinite dimensional space. Now, let be the set of all bounded linear operator over and let be a sequence of trace class operators in , the trace class operators form an ideal over . - My first question is this . Under what conditions, if any, does the sequence converge to a multiplication operator under the trace norm . - My second question is a more specific version of the first . If the dynamics are generated by a contracting semigroup, i.e. where are contracting linear maps, does the limit exists always? If so, what is the limiting operator and is it still trace class? - My third question is essentially the second but for a particular case. I have been working with the following operator. For and is defined as follows. . Where is a kernel. Note tha for this is a very tame integral transform. I am worried about the behviour as in the trace norm sense. i.e. if the limit of exists under , say , what is it?  I am guessing that it should be some multiplication operator. Thank you very much for your help.","H Hilbert B(H) H seq :=\{\rho_{n}\}_{n=1}^{\infty} B(H) B(H) seq \| A\|_{1} : Tr(|A|)= Tr(\sqrt{A^{\dagger}A}
) \rho_{n} = L_{n}\rho_{0} L_{n} \lim_{n\rightarrow \infty}\|\rho_{n}\|_{1} \psi(x) \in H = L^{2}(\mathbb{R}) \sigma_{t}\in B(H) \sigma_{t}\psi(x) := \int_{\mathbb{R}} e^{-t(x-y)^{2}}K(x,y)\psi(y)dy K(x,y) \in L^{2}(\mathbb{R}^{2}) Hilbert-Schmidt t=0 t\rightarrow \infty \sigma_{t} \| \|_{1} \sigma_{\infty} \lim_{t\rightarrow \infty}\|\sigma_{t}\|_{1} = ?  .","['functional-analysis', 'physics', 'mathematical-physics', 'quantum-mechanics']"
99,On some Hahn-Banach equivalents,On some Hahn-Banach equivalents,,"This question is about some equivalents of the Hahn-Banach theorem in $\textsf{ZF}$ set theory. As far as I know, the definitive reference for this sort of thing is Howard & Rubin's Consequences of the Axiom of Choice , which I refer to below. (The Hahn-Banach theorem is ""Form 52"" in the book.) The starting point of my questions about this topic is the following equivalent of Hahn-Banach: [52D] Let $\mathcal B_0$ be a subalgebra of a Boolean algebra $\mathcal B$ , and let $m_0$ be a real-valued finitely additive probability measure defined on $\mathcal B_0$ . Then there is a real-valued finitely additive probability measure $m$ that is an extension of $m_0$ from $\mathcal B_0$ to $\mathcal B$ , and the range of $m$ is contained within the closed convex hull of $m_0$ . The first question I had is: To what extent are abstract Boolean algebras necessary in [52D]? In particular, if we require only that [52D] hold for Boolean algebras of subsets, as in [52?] below, does the equivalence with Hahn-Banach still hold? In case you are tempted to appeal to Stone's representation theorem here, note that that theorem is stronger than Hahn-Banach, so we are not free to invoke it. There are known measure-theoretic equivalents of Hahn-Banach that don't require abstract Boolean algebras. For instance: [52C] For every nonempty set $X$ and every proper ideal $\mathcal I$ over the powerset of $X$ , there is a real-valued finitely additive probability measure $m$ defined on every subset of $X$ such that $m(I)=0$ for every $I \in \mathcal I$ . Now, [52C] is clearly implied by the conjunction of [A] For every nonempty set $X$ and every proper ideal $\mathcal I$ over the powerset of $X$ , there is a real-valued finitely additive probability measure $m$ defined on $\mathcal A(\mathcal I)$ such that $m(I)=0$ for every $I \in \mathcal I$ , where $\mathcal A(\mathcal I)$ is the algebra of subsets of $X$ generated by $\mathcal I$ and [52?] For every set $X$ , every algebra $\mathcal A_0$ of subsets of $X$ , and every real-valued finitely additive probability measure $m_0$ on $\mathcal A_0$ , there is a real-valued finitely additive probability measure $m$ that is an extension of $m_0$ from $\mathcal A_0$ to the powerset of $X$ . But it seems to me that [A] is a theorem of $\textsf{ZF}$ . Indeed, every set in $\mathcal A(\mathcal I)$ is of the form $$\bigcup_{i=1}^n\bigcap_{j=1}^{m_i}A_{ij},$$ where every $A_{ij}$ is in $\mathcal I$ or its complement is. Thus, setting $m(I)=0$ for all $I \in \mathcal I$ uniquely determines a 0-1 valued probability measure on $\mathcal A(\mathcal I)$ . If that's right, then [52?] implies [52C]. And clearly [52D] implies [52?]. So [52?] is actually equivalent to Hahn-Banach, even though it looks quite a bit weaker than [52D]. Final questions: Is this reasoning correct? If so, is there a reference for this result (it seems very likely that it's been noticed before, if true)?","This question is about some equivalents of the Hahn-Banach theorem in set theory. As far as I know, the definitive reference for this sort of thing is Howard & Rubin's Consequences of the Axiom of Choice , which I refer to below. (The Hahn-Banach theorem is ""Form 52"" in the book.) The starting point of my questions about this topic is the following equivalent of Hahn-Banach: [52D] Let be a subalgebra of a Boolean algebra , and let be a real-valued finitely additive probability measure defined on . Then there is a real-valued finitely additive probability measure that is an extension of from to , and the range of is contained within the closed convex hull of . The first question I had is: To what extent are abstract Boolean algebras necessary in [52D]? In particular, if we require only that [52D] hold for Boolean algebras of subsets, as in [52?] below, does the equivalence with Hahn-Banach still hold? In case you are tempted to appeal to Stone's representation theorem here, note that that theorem is stronger than Hahn-Banach, so we are not free to invoke it. There are known measure-theoretic equivalents of Hahn-Banach that don't require abstract Boolean algebras. For instance: [52C] For every nonempty set and every proper ideal over the powerset of , there is a real-valued finitely additive probability measure defined on every subset of such that for every . Now, [52C] is clearly implied by the conjunction of [A] For every nonempty set and every proper ideal over the powerset of , there is a real-valued finitely additive probability measure defined on such that for every , where is the algebra of subsets of generated by and [52?] For every set , every algebra of subsets of , and every real-valued finitely additive probability measure on , there is a real-valued finitely additive probability measure that is an extension of from to the powerset of . But it seems to me that [A] is a theorem of . Indeed, every set in is of the form where every is in or its complement is. Thus, setting for all uniquely determines a 0-1 valued probability measure on . If that's right, then [52?] implies [52C]. And clearly [52D] implies [52?]. So [52?] is actually equivalent to Hahn-Banach, even though it looks quite a bit weaker than [52D]. Final questions: Is this reasoning correct? If so, is there a reference for this result (it seems very likely that it's been noticed before, if true)?","\textsf{ZF} \mathcal B_0 \mathcal B m_0 \mathcal B_0 m m_0 \mathcal B_0 \mathcal B m m_0 X \mathcal I X m X m(I)=0 I \in \mathcal I X \mathcal I X m \mathcal A(\mathcal I) m(I)=0 I \in \mathcal I \mathcal A(\mathcal I) X \mathcal I X \mathcal A_0 X m_0 \mathcal A_0 m m_0 \mathcal A_0 X \textsf{ZF} \mathcal A(\mathcal I) \bigcup_{i=1}^n\bigcap_{j=1}^{m_i}A_{ij}, A_{ij} \mathcal I m(I)=0 I \in \mathcal I \mathcal A(\mathcal I)","['functional-analysis', 'measure-theory', 'set-theory', 'axiom-of-choice', 'hahn-banach-theorem']"
