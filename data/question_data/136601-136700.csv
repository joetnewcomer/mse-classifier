,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,DE solution's uniqueness and convexity,DE solution's uniqueness and convexity,,"I am lost and don't know how to prove the following: If $M$ is a positive definite symmetric square matrix and if $\overrightarrow {v}(t)$ is a solution of: $$\overrightarrow {v'}(t) = M\overrightarrow {v}(t),\qquad t\in[0,T]$$ Then, 1) $\phi(t) = \ln(\|\overrightarrow {v(t)}\|^2) $ is a convex funciton, 2) Solution of the differential equation is unique.","I am lost and don't know how to prove the following: If $M$ is a positive definite symmetric square matrix and if $\overrightarrow {v}(t)$ is a solution of: $$\overrightarrow {v'}(t) = M\overrightarrow {v}(t),\qquad t\in[0,T]$$ Then, 1) $\phi(t) = \ln(\|\overrightarrow {v(t)}\|^2) $ is a convex funciton, 2) Solution of the differential equation is unique.",,"['matrices', 'analysis', 'ordinary-differential-equations', 'convex-analysis', 'normed-spaces']"
1,how to show that all solutions tend to zero?,how to show that all solutions tend to zero?,,"Here is our nonlinear first order ode: \begin{equation*} y'(t) +2y(t)+y^3(t)=e^{-t} . \end{equation*} We want to show that all solutions tend to zero as $t$ goes to infinity. Attempt: Multiply both side by $y$. Then we will have: \begin{equation*} (1/2)(y^2)'=-2y^2-y^4+ye^{-t}, \\ (1/2)(y^2)'\le ye^{-t}. \end{equation*} After this, I think Grönwall's inequality may help but we are not sure of $y\le y^2$. If this was the case: \begin{equation*} (1/2)(y^2)'\le y^2e^{-t} \end{equation*} then by Grönwall: $y=0$. However $y=0$ also does not satisfy the ode anyway.","Here is our nonlinear first order ode: \begin{equation*} y'(t) +2y(t)+y^3(t)=e^{-t} . \end{equation*} We want to show that all solutions tend to zero as $t$ goes to infinity. Attempt: Multiply both side by $y$. Then we will have: \begin{equation*} (1/2)(y^2)'=-2y^2-y^4+ye^{-t}, \\ (1/2)(y^2)'\le ye^{-t}. \end{equation*} After this, I think Grönwall's inequality may help but we are not sure of $y\le y^2$. If this was the case: \begin{equation*} (1/2)(y^2)'\le y^2e^{-t} \end{equation*} then by Grönwall: $y=0$. However $y=0$ also does not satisfy the ode anyway.",,['ordinary-differential-equations']
2,Backwards heat equation (stability analysis),Backwards heat equation (stability analysis),,"Problem Consider the backwards heat equation of the form    $$ \left\{ \begin{aligned} u_{t} &= \lambda^2 u_{xx}, & x\in[0,L], \quad t\in[0,T]\\ u(0,t) &= u(L,t) = 0 \\ u(x,T) &= f(x), \end{aligned} \right.\tag{*}\label{*}$$   Establish whether solution is unique and analyze its stability. Attempt of proving uniqueness My attempt to prove uniqueness is provided in this post . Attempt of ( dis )proving stability The general solution of $\eqref{*}$ is of the form  $$ u(x,t) = \sum_{m=1}^{\infty} A_m \sin\bigg( \frac{\pi m }{L}\,x\bigg) \exp \Bigg(\!\!-\!\bigg(\frac{\pi m }{L}\bigg)^2  \lambda^2 \big(T -t \big) \Bigg)\\ A_m =  \frac{2}{L} \int_0^L \sin \!\bigg( \frac{\pi m }{L}\,x\bigg)\, f(x)\,dx $$ I think the solution is not stable in $L^p$ sense, so I need to come up with a good counterexample of the sequence of initial data  $f_n(x)\to f(x)$ converging in $L_p$, so that it would not be difficult to show that corresponding solutions do not converge in $L_p$. Could anyone propose such an example?","Problem Consider the backwards heat equation of the form    $$ \left\{ \begin{aligned} u_{t} &= \lambda^2 u_{xx}, & x\in[0,L], \quad t\in[0,T]\\ u(0,t) &= u(L,t) = 0 \\ u(x,T) &= f(x), \end{aligned} \right.\tag{*}\label{*}$$   Establish whether solution is unique and analyze its stability. Attempt of proving uniqueness My attempt to prove uniqueness is provided in this post . Attempt of ( dis )proving stability The general solution of $\eqref{*}$ is of the form  $$ u(x,t) = \sum_{m=1}^{\infty} A_m \sin\bigg( \frac{\pi m }{L}\,x\bigg) \exp \Bigg(\!\!-\!\bigg(\frac{\pi m }{L}\bigg)^2  \lambda^2 \big(T -t \big) \Bigg)\\ A_m =  \frac{2}{L} \int_0^L \sin \!\bigg( \frac{\pi m }{L}\,x\bigg)\, f(x)\,dx $$ I think the solution is not stable in $L^p$ sense, so I need to come up with a good counterexample of the sequence of initial data  $f_n(x)\to f(x)$ converging in $L_p$, so that it would not be difficult to show that corresponding solutions do not converge in $L_p$. Could anyone propose such an example?",,"['calculus', 'analysis', 'ordinary-differential-equations', 'partial-differential-equations', 'convergence-divergence']"
3,Prove that the normal to a quadratic curve passes through a specific point,Prove that the normal to a quadratic curve passes through a specific point,,"I've been asked to prove that the normal to the curve $y=2x^2 - 3x^{-1/2}$ at the point $(1,-1)$ passes through the point $(12,3)$. $\frac{dy}{dx} = 4x + \frac{3}{2}x^{-3/2}$ Hence, at the point $(1,-1)$, the gradient of the tangent $=\frac{11}{2}$ Therefore, the gradient of the normal at that point$=-\frac{2}{11}$ So, the equation for the normal is $$y+1=-\frac{2}{11}(x-1)$$ $$11y=-2x-9$$ However, when I substitute the value $12$ in for $x$ I get $y=-3$, rather than $3$, so that equation can't be right. What have I done wrong?","I've been asked to prove that the normal to the curve $y=2x^2 - 3x^{-1/2}$ at the point $(1,-1)$ passes through the point $(12,3)$. $\frac{dy}{dx} = 4x + \frac{3}{2}x^{-3/2}$ Hence, at the point $(1,-1)$, the gradient of the tangent $=\frac{11}{2}$ Therefore, the gradient of the normal at that point$=-\frac{2}{11}$ So, the equation for the normal is $$y+1=-\frac{2}{11}(x-1)$$ $$11y=-2x-9$$ However, when I substitute the value $12$ in for $x$ I get $y=-3$, rather than $3$, so that equation can't be right. What have I done wrong?",,"['ordinary-differential-equations', 'differential-geometry', 'curves']"
4,Find equation of tangent line using differential equation: dy/dx = x(y^1/3),Find equation of tangent line using differential equation: dy/dx = x(y^1/3),,"The expression $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = x\sqrt[3]{y}$ gives the slope at any point on the graph of the function $f(x)$ where $f(2) = 8$. a. Write the equation of the tangent line to $f(x)$ at point $(2,8)$. Since $\frac{\mathrm{d}y}{\mathrm{d}x}$ gives the slope of the tangent line at any point, can I just plug and chug $(2,8)$ into the differential equation, and then use that slope in the point-slope formula? This would give: $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = (2)(\sqrt[3]{8})$ $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = 4$ $y - 8 = 4(x - 2)\\ y = 4(x - 2) + 8$ ... could anyone verify that? b. Write an expression for $f(x)$ in terms of $x$. I got: $x = \sqrt{3y^\frac 23 + C}$, where $C$ is a constant of integration. Not quite sure whether this is correct or not. c. What is the domain of $f(x)$? I have no idea how to begin answering this question. Could it be all real numbers, since the domain of the differential equation seems to be all real numbers? d. What is the minimum value of $f(x)$? I think I have to set $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = 1$, but then what? Is it $x = 0, y = 0$?","The expression $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = x\sqrt[3]{y}$ gives the slope at any point on the graph of the function $f(x)$ where $f(2) = 8$. a. Write the equation of the tangent line to $f(x)$ at point $(2,8)$. Since $\frac{\mathrm{d}y}{\mathrm{d}x}$ gives the slope of the tangent line at any point, can I just plug and chug $(2,8)$ into the differential equation, and then use that slope in the point-slope formula? This would give: $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = (2)(\sqrt[3]{8})$ $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = 4$ $y - 8 = 4(x - 2)\\ y = 4(x - 2) + 8$ ... could anyone verify that? b. Write an expression for $f(x)$ in terms of $x$. I got: $x = \sqrt{3y^\frac 23 + C}$, where $C$ is a constant of integration. Not quite sure whether this is correct or not. c. What is the domain of $f(x)$? I have no idea how to begin answering this question. Could it be all real numbers, since the domain of the differential equation seems to be all real numbers? d. What is the minimum value of $f(x)$? I think I have to set $\displaystyle\frac{\mathrm{d}y}{\mathrm{d}x} = 1$, but then what? Is it $x = 0, y = 0$?",,"['calculus', 'integration', 'ordinary-differential-equations', 'derivatives']"
5,Initial Value problem and showing that $ x(t_n) - x_n = 1/2ht_ne^{tn} + O(h^2)$,Initial Value problem and showing that, x(t_n) - x_n = 1/2ht_ne^{tn} + O(h^2),"I have a question which I can't for the life of me figure out.  The questions starts by giving $$x'(t) = x(t), x(0) = 1, x(t) = e^t$$ So they give you the solution and basically ask you to apply the Euler method with step size $h$ to show $$x_n = (1+h)^{t_n/h} , t_n = nh , ~~ n = 0,1....$$ Now I have gotten this out quite simply however, the next part asks use the formula $$log(1+h) = h - 1/2h^2 + O(h^3)$$ to show that $$ x(t_n) - x_n = 1/2ht_ne^{tn} + O(h^2)$$ Now I have tried a couple of different options and i feel it should be easier than it is. The furthest I can sort of get is $$x_n =e^{t_n(1 - 1/2h+O(h^2))}$$ (but I have so many different types of solutions and maybe working with Taylor series) any help would be greatly appreciated","I have a question which I can't for the life of me figure out.  The questions starts by giving $$x'(t) = x(t), x(0) = 1, x(t) = e^t$$ So they give you the solution and basically ask you to apply the Euler method with step size $h$ to show $$x_n = (1+h)^{t_n/h} , t_n = nh , ~~ n = 0,1....$$ Now I have gotten this out quite simply however, the next part asks use the formula $$log(1+h) = h - 1/2h^2 + O(h^3)$$ to show that $$ x(t_n) - x_n = 1/2ht_ne^{tn} + O(h^2)$$ Now I have tried a couple of different options and i feel it should be easier than it is. The furthest I can sort of get is $$x_n =e^{t_n(1 - 1/2h+O(h^2))}$$ (but I have so many different types of solutions and maybe working with Taylor series) any help would be greatly appreciated",,['ordinary-differential-equations']
6,I need a Hint on this Differential equation,I need a Hint on this Differential equation,,"Let $f$ and $g$ be two real functions, and we have  $$ (f*g)(t)= \int_0^tf(s)g(t-s) \, ds $$ we have the following equation  $$y'+ay=f(t) $$ where a is a constant and f is a function  -/ prove that if $$ g(t)=e^{-at}, $$ then $$ y =f*g$$ is a solution to the equation verifing $$ y(0)=0.$$ by jsut replacing y in the equation as $$ \int_0^t f(s)g(t-s) \, ds $$ does that mean that $$ y' = f(s)g(t-s)$$ if so we will have  $$ f(s)g(t-s) +a \int_0^t f(s)g(t-s)ds=f(t) $$ and by replacing g with $$ g(t)=e^{-at}, $$  then we have  $$ f(s) e^{-a(t-s)}+a \int_0^t f(s) e^{-a(t-s)} =f(t) $$ How Do we solve this ?","Let $f$ and $g$ be two real functions, and we have  $$ (f*g)(t)= \int_0^tf(s)g(t-s) \, ds $$ we have the following equation  $$y'+ay=f(t) $$ where a is a constant and f is a function  -/ prove that if $$ g(t)=e^{-at}, $$ then $$ y =f*g$$ is a solution to the equation verifing $$ y(0)=0.$$ by jsut replacing y in the equation as $$ \int_0^t f(s)g(t-s) \, ds $$ does that mean that $$ y' = f(s)g(t-s)$$ if so we will have  $$ f(s)g(t-s) +a \int_0^t f(s)g(t-s)ds=f(t) $$ and by replacing g with $$ g(t)=e^{-at}, $$  then we have  $$ f(s) e^{-a(t-s)}+a \int_0^t f(s) e^{-a(t-s)} =f(t) $$ How Do we solve this ?",,"['real-analysis', 'ordinary-differential-equations', 'definite-integrals']"
7,Finding all functions f(y) such that a differential equation becomes exact,Finding all functions f(y) such that a differential equation becomes exact,,"Can somebody help me with this question? Find all functions f(y) for which the differential equation becomes exact: $$ x^2 + \frac {f(y)}{xy} + ln |xy| \frac {dy}{dx} = 0 $$ If I set $P(x,y)=x^2 + \frac{f(y)}{xy}$ and $Q(x,y)= ln |xy|$, I get $\frac{\partial P}{\partial y}=\frac{f'(y)}{xy}-\frac{f(y)}{xy^2}$ and $\frac{\partial Q}{\partial x}=\frac {1}{x}$. The differential equation is exact when $\frac{\partial P}{\partial y}=\frac{\partial Q}{\partial x}$. How do I go about finding all equations f(y)?","Can somebody help me with this question? Find all functions f(y) for which the differential equation becomes exact: $$ x^2 + \frac {f(y)}{xy} + ln |xy| \frac {dy}{dx} = 0 $$ If I set $P(x,y)=x^2 + \frac{f(y)}{xy}$ and $Q(x,y)= ln |xy|$, I get $\frac{\partial P}{\partial y}=\frac{f'(y)}{xy}-\frac{f(y)}{xy^2}$ and $\frac{\partial Q}{\partial x}=\frac {1}{x}$. The differential equation is exact when $\frac{\partial P}{\partial y}=\frac{\partial Q}{\partial x}$. How do I go about finding all equations f(y)?",,['ordinary-differential-equations']
8,"Regarding ""Two Singular Diffusion Problems"" by William Feller","Regarding ""Two Singular Diffusion Problems"" by William Feller",,"I'm currently reading the research paper, Two Singular Diffusion Problems , by William Feller (1950). However, I don't understand how Feller derived the solution $(3.5)$ given equation $(3.4)$ in his research paper. More specifically, I don't understand how Feller solved $$dt=\frac{d\omega}{f(t)-cs\omega} \implies \frac{d\omega}{dt}=f(t)-cs\omega,$$ where $$\text{This is equation (3.4)}\,\,\,\,\,\,\,\,\,\,\,\,\,\, e^{-bt}\frac{as-b}{s}=C_1 \implies s=\frac{be^{-bt}}{ae^{-bt}-C_1},$$ and $a, b, C_1$ are constants with $b\neq0$ to get the solution$$\text{This is equation (3.5)}\,\,\,\,\,\,\,\,\,\,\,\, \omega = \left|C_1 - ae^{-bt}\right|^{c/a}\left\{C_2 + \int_{0}^{t}{\frac{f(\tau)d\tau}{\left|C_1 - ae^{-b\tau}\right|^{c/a}}}\right\},$$ where $C_2$ is a constant as well. Please note that I have already verified this is true by differentiating it (and using the Fundamental Theorem of Calculus ) but I don't understand how Feller derived it originally. Can someone please explain to me in details or give me some hints regarding this? Any help will be greatly appreciated.","I'm currently reading the research paper, Two Singular Diffusion Problems , by William Feller (1950). However, I don't understand how Feller derived the solution $(3.5)$ given equation $(3.4)$ in his research paper. More specifically, I don't understand how Feller solved $$dt=\frac{d\omega}{f(t)-cs\omega} \implies \frac{d\omega}{dt}=f(t)-cs\omega,$$ where $$\text{This is equation (3.4)}\,\,\,\,\,\,\,\,\,\,\,\,\,\, e^{-bt}\frac{as-b}{s}=C_1 \implies s=\frac{be^{-bt}}{ae^{-bt}-C_1},$$ and $a, b, C_1$ are constants with $b\neq0$ to get the solution$$\text{This is equation (3.5)}\,\,\,\,\,\,\,\,\,\,\,\, \omega = \left|C_1 - ae^{-bt}\right|^{c/a}\left\{C_2 + \int_{0}^{t}{\frac{f(\tau)d\tau}{\left|C_1 - ae^{-b\tau}\right|^{c/a}}}\right\},$$ where $C_2$ is a constant as well. Please note that I have already verified this is true by differentiating it (and using the Fundamental Theorem of Calculus ) but I don't understand how Feller derived it originally. Can someone please explain to me in details or give me some hints regarding this? Any help will be greatly appreciated.",,"['ordinary-differential-equations', 'stochastic-processes', 'stochastic-calculus', 'finance', 'statistical-mechanics']"
9,How to Separate Charpit Equations,How to Separate Charpit Equations,,"I've been attempting to solve this non-linear PDE $$4\Omega x^2 y^2 \frac{\partial z}{\partial y} -x^2 y (\frac{\partial z}{\partial x})^2 + 2x^2 y^2 E-N^2=0$$ using Charpit's method.  The variables $\Omega$, $E$, and $N$ are constants.  I've derived the relation between Charpit's auxillary equations, $$\frac{x}{N^2}dp=-\frac{y}{N^2}dq=-\frac{1}{x^2 y p}dx=\frac{1}{2\Omega x^2 y^2} dy$$ but I have been unable to separate these to obtain the second function relating $p$ and $q$.  Most of the examples I have seen are separated very easily with terms such as $$\frac{dp}{p}=\frac{dq}{q}$$ or something similar.  Could anyone please help? EDIT:  A little background on Charpit's method and the Method of Characteristics... We begin by defining the primary non-linear PDE $$F(x,y,z,p,q)=4\Omega x^2 y^2 \frac{\partial z}{\partial y} -x^2 y (\frac{\partial z}{\partial x})^2 + 2x^2 y^2 E-N^2=0$$ Then, by expanding the total derivatives $$\frac{dF}{dx}=0$$ and $$\frac{dF}{dy}=0$$ in terms of partial derivatives, along with the definitions $$\frac{dx}{dt}\equiv\frac{\partial F}{\partial p}$$ and $$\frac{dy}{dt}\equiv\frac{\partial F}{\partial q}$$ we get the five Charpit Equations: $$\frac{dx}{dt}=\frac{\partial F}{\partial p}\\ \frac{dy}{dt}=\frac{\partial F}{\partial q}\\ \frac{dp}{dt}=-\frac{\partial F}{\partial x}-p\frac{\partial F}{\partial z}\\ \frac{dq}{dt}=-\frac{\partial F}{\partial y}-q\frac{\partial F}{\partial z}\\ \frac{dz}{dt}=p\frac{dx}{dt}+q\frac{dy}{dt}$$ By eliminating $dt$ they can all be set equal to each other (see Charpit's auxillary equations mentioned above), and any two (or more) can be used to integrate a total derivative relating $p$ and $q$.  This new relation is then substituted into the original differential equation, which can then be written as $$dz=p(x,y)dx+q(x,y)dy$$ which is a total differential which can be directly integrated to find the solution z=z(x,y).","I've been attempting to solve this non-linear PDE $$4\Omega x^2 y^2 \frac{\partial z}{\partial y} -x^2 y (\frac{\partial z}{\partial x})^2 + 2x^2 y^2 E-N^2=0$$ using Charpit's method.  The variables $\Omega$, $E$, and $N$ are constants.  I've derived the relation between Charpit's auxillary equations, $$\frac{x}{N^2}dp=-\frac{y}{N^2}dq=-\frac{1}{x^2 y p}dx=\frac{1}{2\Omega x^2 y^2} dy$$ but I have been unable to separate these to obtain the second function relating $p$ and $q$.  Most of the examples I have seen are separated very easily with terms such as $$\frac{dp}{p}=\frac{dq}{q}$$ or something similar.  Could anyone please help? EDIT:  A little background on Charpit's method and the Method of Characteristics... We begin by defining the primary non-linear PDE $$F(x,y,z,p,q)=4\Omega x^2 y^2 \frac{\partial z}{\partial y} -x^2 y (\frac{\partial z}{\partial x})^2 + 2x^2 y^2 E-N^2=0$$ Then, by expanding the total derivatives $$\frac{dF}{dx}=0$$ and $$\frac{dF}{dy}=0$$ in terms of partial derivatives, along with the definitions $$\frac{dx}{dt}\equiv\frac{\partial F}{\partial p}$$ and $$\frac{dy}{dt}\equiv\frac{\partial F}{\partial q}$$ we get the five Charpit Equations: $$\frac{dx}{dt}=\frac{\partial F}{\partial p}\\ \frac{dy}{dt}=\frac{\partial F}{\partial q}\\ \frac{dp}{dt}=-\frac{\partial F}{\partial x}-p\frac{\partial F}{\partial z}\\ \frac{dq}{dt}=-\frac{\partial F}{\partial y}-q\frac{\partial F}{\partial z}\\ \frac{dz}{dt}=p\frac{dx}{dt}+q\frac{dy}{dt}$$ By eliminating $dt$ they can all be set equal to each other (see Charpit's auxillary equations mentioned above), and any two (or more) can be used to integrate a total derivative relating $p$ and $q$.  This new relation is then substituted into the original differential equation, which can then be written as $$dz=p(x,y)dx+q(x,y)dy$$ which is a total differential which can be directly integrated to find the solution z=z(x,y).",,"['ordinary-differential-equations', 'partial-differential-equations']"
10,A trick to find a solution for : $ydx + (x+x^2y^4)dy = 0$,A trick to find a solution for :,ydx + (x+x^2y^4)dy = 0,"In the first part of my question I already proved that if $P(x,y)dx + Q(x,y)dy = 0$ is an exact equation and its solution is $F(x,y)=c$, then for each differentiable function $\mu(t)$ we get that the following equation is also exact: $$\mu(F(x,y))P(x,y)dx+\mu(F(x,y))Q(x,y)dy = 0 $$ Then, second part says: Let $P(x,y)dx+Q(x,y)dy=0$ be an exact equation, and let $F(x,y)=c$ be its solution, which applies $\nabla F = (P,Q)$. now lets take a  look at:  $$Pdx + (Q+Q_1)dy=0$$ which is not exact, and we suggest to find an integration factor of the form $\mu = \mu(F(x,y))$. Use this way to find a solution for: $$ydx + (x+x^2y^4)dy = 0$$ so, I thought that what we really need to deal with is:  $$\mu(F(x,y))P(x,y)dx+\mu(F(x,y))(Q_1 + Q)dy = 0 $$ And I marked $\widetilde{Q}(x,y)= \mu(F(x,y))(Q_1 + Q) $ And also marked: $\widetilde{P}(x,y)= \mu(F(x,y))P(x,y) $ and then I wanted to prove that the follow partial derivatives are equal: $$\widetilde{P_y}^\prime(x,y)= \widetilde{Q_x}^\prime(x,y)$$ then, here comes the uncertain part of my solution, I derived the upper equation in this way: $\frac{du}{dt}\frac{dF}{dy}P(x,y) +  P_y^\prime$$\mu(F(x,y))$ = $\frac{dy}{dt}\frac{dF}{dx}(Q_1+Q) + (Q_1+Q)_x ^\prime\mu(F(x,y)) $ and I all could get from here by some calculations is: $P_y^\prime$ = $ (Q_1)_{x} ^\prime + Q_x^\prime$ $\widetilde{F}_y ^\prime$$P(x,y)$= $\widetilde{F}_x ^\prime$$(Q_1 + Q)$ And what I mean by $\widetilde{F}_y ^\prime$ and $\widetilde{F}_x ^\prime$ is the solution of the $new$ equation. for somehow, I got stuck here, how do I continue ? and if there are mistakes what are they? Any kind of help would be appreciated.","In the first part of my question I already proved that if $P(x,y)dx + Q(x,y)dy = 0$ is an exact equation and its solution is $F(x,y)=c$, then for each differentiable function $\mu(t)$ we get that the following equation is also exact: $$\mu(F(x,y))P(x,y)dx+\mu(F(x,y))Q(x,y)dy = 0 $$ Then, second part says: Let $P(x,y)dx+Q(x,y)dy=0$ be an exact equation, and let $F(x,y)=c$ be its solution, which applies $\nabla F = (P,Q)$. now lets take a  look at:  $$Pdx + (Q+Q_1)dy=0$$ which is not exact, and we suggest to find an integration factor of the form $\mu = \mu(F(x,y))$. Use this way to find a solution for: $$ydx + (x+x^2y^4)dy = 0$$ so, I thought that what we really need to deal with is:  $$\mu(F(x,y))P(x,y)dx+\mu(F(x,y))(Q_1 + Q)dy = 0 $$ And I marked $\widetilde{Q}(x,y)= \mu(F(x,y))(Q_1 + Q) $ And also marked: $\widetilde{P}(x,y)= \mu(F(x,y))P(x,y) $ and then I wanted to prove that the follow partial derivatives are equal: $$\widetilde{P_y}^\prime(x,y)= \widetilde{Q_x}^\prime(x,y)$$ then, here comes the uncertain part of my solution, I derived the upper equation in this way: $\frac{du}{dt}\frac{dF}{dy}P(x,y) +  P_y^\prime$$\mu(F(x,y))$ = $\frac{dy}{dt}\frac{dF}{dx}(Q_1+Q) + (Q_1+Q)_x ^\prime\mu(F(x,y)) $ and I all could get from here by some calculations is: $P_y^\prime$ = $ (Q_1)_{x} ^\prime + Q_x^\prime$ $\widetilde{F}_y ^\prime$$P(x,y)$= $\widetilde{F}_x ^\prime$$(Q_1 + Q)$ And what I mean by $\widetilde{F}_y ^\prime$ and $\widetilde{F}_x ^\prime$ is the solution of the $new$ equation. for somehow, I got stuck here, how do I continue ? and if there are mistakes what are they? Any kind of help would be appreciated.",,"['ordinary-differential-equations', 'partial-derivative']"
11,Viable method to solving this first order system of linear DE?,Viable method to solving this first order system of linear DE?,,Given the following system of differential equations \begin{align} \frac{dy}{dt} &= x \\ \\ \frac{dx}{dt} &= y \end{align} is the following operation allowed? \begin{align} \frac{\dfrac{dy}{dt}}{\dfrac{dx}{dt}}  &= \frac{x}{y} \\\\ \frac{dy}{dx} &= \frac{x}{y} \end{align},Given the following system of differential equations \begin{align} \frac{dy}{dt} &= x \\ \\ \frac{dx}{dt} &= y \end{align} is the following operation allowed? \begin{align} \frac{\dfrac{dy}{dt}}{\dfrac{dx}{dt}}  &= \frac{x}{y} \\\\ \frac{dy}{dx} &= \frac{x}{y} \end{align},,['ordinary-differential-equations']
12,Lipschitz condition not satisfied,Lipschitz condition not satisfied,,"To show there is no contradiction to existence and uniqueness $\displaystyle\frac{|f(x,u)-f(x,v)|}{|u-v|}= \displaystyle\frac{|x||u^{1/2}-v^{1/2}|}{|u-v|}=\frac{|x|}{u^{1/2}+v^{1/2}}$ I understand that for small $u$ and $v$ the above expression is unbounded. However, what is this actually saying? i.e does this imply $y$ is not lipschitz at $y=0$? If so why is this?","To show there is no contradiction to existence and uniqueness $\displaystyle\frac{|f(x,u)-f(x,v)|}{|u-v|}= \displaystyle\frac{|x||u^{1/2}-v^{1/2}|}{|u-v|}=\frac{|x|}{u^{1/2}+v^{1/2}}$ I understand that for small $u$ and $v$ the above expression is unbounded. However, what is this actually saying? i.e does this imply $y$ is not lipschitz at $y=0$? If so why is this?",,['ordinary-differential-equations']
13,Solutions of the constant coefficient Helmholtz equation via the Fourier transform,Solutions of the constant coefficient Helmholtz equation via the Fourier transform,,"When $f$ is a rapidly decaying Schwartz function,  $$ g(x) = \frac{1}{2\lambda} \int_{\mathbb{R}} \sin \left(2\lambda\left|x-y\right|\right) f(y)\ dy $$ is an element of $C^\infty\left(\mathbb{R}\right)$ and a solution of the Helmholtz equation $$ y''(t) + \lambda^2 y(t) = f(t). \tag{1} $$ Moreover, the Fourier transform of $g$ is the tempered distribution which is the principal value of  $$ \frac{\widehat{f}(\xi)}{\lambda^2-\xi^2}. \tag{2} $$ If we assume only that $f$ is in $L^1\left(\mathbb{R}\right)$, then $g$ is still an element of $C^\infty\left(\mathbb{R}\right)$ and it is still a solution of (1) (this follows easily from the dominated convergence theorem).  However, it is not clear to me that (2) is defined (the Fourier transform might not be Lipschitz continous, in which case the principal value integral might not exist). I am not sure that (2) is not defined.  Is it the case that if $f$ is the Fourier transform of a $L^1\left(\mathbb{R}\right)$ function then  $$ \lim_{\epsilon\to 0} \int_{|x|>\epsilon} \frac{f(x)}{x}\ dx \tag{3} $$ must exist?  It is easy to construct an example of a continuous function $f(x)$ for which (3) does not exist -- for example, $$ f(x) = \frac{\mbox{sign}(x)}{1+|\log(x)|}. $$ I have not, however, been able to construct such a function and show that it is the image of an integrable function under the Fourier transform. Assuming that (2) does not define a tempered distribution for all $f \in L^1\left(\mathbb{R}\right)$, is there some other way of interpreting (2)?  Clearly, one could obtain the Fourier transform of g as a limit of some tempered distributions.  For instance, let $$ \phi(x) = \frac{1}{2\lambda i} \exp\left(\lambda i |x|\right) $$ so that $g$ is the real part of $\phi*f$.  Also, let  $$ \phi_t (x) = \frac{1}{2(\lambda+i t) i} \exp((\lambda+i t) i |x|). $$ Since $\phi_t * f $ converges to $\phi *f$ in the space of tempered distributions (in fact, it converges in $L^\infty\left(\mathbb{R}\right)$), $$ \frac{\widehat{f}(\xi)}{(\lambda +i t)^2 - \xi^2}=\widehat{\phi_t} \widehat{f} = \widehat{\phi_t*f} \to \widehat{\phi *f } \ \ \ \mbox{as} \ \ t \to 0 $$ in the space of tempered distributions.  And we can, of course, recover $\widehat{g}$ from $\widehat{\phi *f}$. This is deeply unsatisfying to me for some reason --- perhaps because $g$ is defined as a convolution and I very much wish to interpret it as a product of Fourier transforms.","When $f$ is a rapidly decaying Schwartz function,  $$ g(x) = \frac{1}{2\lambda} \int_{\mathbb{R}} \sin \left(2\lambda\left|x-y\right|\right) f(y)\ dy $$ is an element of $C^\infty\left(\mathbb{R}\right)$ and a solution of the Helmholtz equation $$ y''(t) + \lambda^2 y(t) = f(t). \tag{1} $$ Moreover, the Fourier transform of $g$ is the tempered distribution which is the principal value of  $$ \frac{\widehat{f}(\xi)}{\lambda^2-\xi^2}. \tag{2} $$ If we assume only that $f$ is in $L^1\left(\mathbb{R}\right)$, then $g$ is still an element of $C^\infty\left(\mathbb{R}\right)$ and it is still a solution of (1) (this follows easily from the dominated convergence theorem).  However, it is not clear to me that (2) is defined (the Fourier transform might not be Lipschitz continous, in which case the principal value integral might not exist). I am not sure that (2) is not defined.  Is it the case that if $f$ is the Fourier transform of a $L^1\left(\mathbb{R}\right)$ function then  $$ \lim_{\epsilon\to 0} \int_{|x|>\epsilon} \frac{f(x)}{x}\ dx \tag{3} $$ must exist?  It is easy to construct an example of a continuous function $f(x)$ for which (3) does not exist -- for example, $$ f(x) = \frac{\mbox{sign}(x)}{1+|\log(x)|}. $$ I have not, however, been able to construct such a function and show that it is the image of an integrable function under the Fourier transform. Assuming that (2) does not define a tempered distribution for all $f \in L^1\left(\mathbb{R}\right)$, is there some other way of interpreting (2)?  Clearly, one could obtain the Fourier transform of g as a limit of some tempered distributions.  For instance, let $$ \phi(x) = \frac{1}{2\lambda i} \exp\left(\lambda i |x|\right) $$ so that $g$ is the real part of $\phi*f$.  Also, let  $$ \phi_t (x) = \frac{1}{2(\lambda+i t) i} \exp((\lambda+i t) i |x|). $$ Since $\phi_t * f $ converges to $\phi *f$ in the space of tempered distributions (in fact, it converges in $L^\infty\left(\mathbb{R}\right)$), $$ \frac{\widehat{f}(\xi)}{(\lambda +i t)^2 - \xi^2}=\widehat{\phi_t} \widehat{f} = \widehat{\phi_t*f} \to \widehat{\phi *f } \ \ \ \mbox{as} \ \ t \to 0 $$ in the space of tempered distributions.  And we can, of course, recover $\widehat{g}$ from $\widehat{\phi *f}$. This is deeply unsatisfying to me for some reason --- perhaps because $g$ is defined as a convolution and I very much wish to interpret it as a product of Fourier transforms.",,"['real-analysis', 'ordinary-differential-equations', 'harmonic-analysis']"
14,Solution of Second Order Differential Equation with non-constant coeffecient,Solution of Second Order Differential Equation with non-constant coeffecient,,"How do we solve the differential equation $y''-2(\sin x)y'-(\cos x-\sin^2x)y=0$ IVP: $y\left(\dfrac{\pi}{2}\right)=0$ , $ y'\left(\dfrac{\pi}{2}\right)=1$ ? Its neither constant coeffecient, nor $Cauchy-Euler$. I really don't know how to proceed. We need to find the value of $y(0)$","How do we solve the differential equation $y''-2(\sin x)y'-(\cos x-\sin^2x)y=0$ IVP: $y\left(\dfrac{\pi}{2}\right)=0$ , $ y'\left(\dfrac{\pi}{2}\right)=1$ ? Its neither constant coeffecient, nor $Cauchy-Euler$. I really don't know how to proceed. We need to find the value of $y(0)$",,['ordinary-differential-equations']
15,Laplace Transform of an Piecewise Function,Laplace Transform of an Piecewise Function,,"Write $f(t) = \begin{cases} 5,& \mbox{if} \quad 0 \leq t \lt 3 \\ -4,& \mbox{if} \quad 3 \leq t \lt 7 \\ 0,& \mbox{if} \quad t \geq 7    \end{cases}$ as a unit step function and find the Laplace transform. Workings: The unit step function is $f(t) = 5 + u(t-3)(-9) + u(t-7)(4)$ $f(t) = 5 - 9u(t-3) + 4u(t-7)$ The Laplace transform would then be: $\mathcal L \{f(t)\} = \mathcal L \{5\} - 9 \mathcal L \{u(t-3)\} + 4 \mathcal L \{u(t-4)\}$ $\mathcal L \{f(t)\} = \frac{5}{s} - \frac{9e^{-3s}}{s} - \frac{e^{-4s}}{s}$ I'm not sure if this is correct. Any help will be appreciated.","Write $f(t) = \begin{cases} 5,& \mbox{if} \quad 0 \leq t \lt 3 \\ -4,& \mbox{if} \quad 3 \leq t \lt 7 \\ 0,& \mbox{if} \quad t \geq 7    \end{cases}$ as a unit step function and find the Laplace transform. Workings: The unit step function is $f(t) = 5 + u(t-3)(-9) + u(t-7)(4)$ $f(t) = 5 - 9u(t-3) + 4u(t-7)$ The Laplace transform would then be: $\mathcal L \{f(t)\} = \mathcal L \{5\} - 9 \mathcal L \{u(t-3)\} + 4 \mathcal L \{u(t-4)\}$ $\mathcal L \{f(t)\} = \frac{5}{s} - \frac{9e^{-3s}}{s} - \frac{e^{-4s}}{s}$ I'm not sure if this is correct. Any help will be appreciated.",,"['ordinary-differential-equations', 'laplace-transform']"
16,Calculate Wronksian of Second Order Differential Equation,Calculate Wronksian of Second Order Differential Equation,,Use variation of parameters to find a particular solution to: $\frac{d^{2}y}{dx^{x}} + 2 \frac{dy}{dx} + y = \frac{1}{x^{4}e^{4}}.$ There are no solutions given so finding a wronskian that way is nil. But since it is still in the order $p(x)y'' + q(x)y' + r(x)y = g(x)$ I think there is still a way to calculate a Wronskian. I have not worked with second order differential equations before and some hints/tips/help would be appreciated.,Use variation of parameters to find a particular solution to: $\frac{d^{2}y}{dx^{x}} + 2 \frac{dy}{dx} + y = \frac{1}{x^{4}e^{4}}.$ There are no solutions given so finding a wronskian that way is nil. But since it is still in the order $p(x)y'' + q(x)y' + r(x)y = g(x)$ I think there is still a way to calculate a Wronskian. I have not worked with second order differential equations before and some hints/tips/help would be appreciated.,,['ordinary-differential-equations']
17,Solving a second Order ODE of a catenary curve,Solving a second Order ODE of a catenary curve,,Given the second order ODE of a catenary curve $$y''=a\sqrt{1+(y')^2}$$ With initial conditions $y(0)=0$ and $y'(0)=0$ The equation was first rewritten as $2y''y'''=2a^{2}y'y''$ and then dividing both sides by $$2y''$$ and letting $z=y'$ we would get the equation $$z''=a^2z$$ intital conditions $z(0)=0$ and $z'(0)=a$ I came across this question while i was reading the following article. http://www.emis.de/journals/BAMV/conten/vol12/juangil.pdf I couldn't fully understand what the article meant such as how did they form the Differential equation of the Caterny curve and how did they managed to solve the differential equation. Could anyone Please explain. Thanks,Given the second order ODE of a catenary curve $$y''=a\sqrt{1+(y')^2}$$ With initial conditions $y(0)=0$ and $y'(0)=0$ The equation was first rewritten as $2y''y'''=2a^{2}y'y''$ and then dividing both sides by $$2y''$$ and letting $z=y'$ we would get the equation $$z''=a^2z$$ intital conditions $z(0)=0$ and $z'(0)=a$ I came across this question while i was reading the following article. http://www.emis.de/journals/BAMV/conten/vol12/juangil.pdf I couldn't fully understand what the article meant such as how did they form the Differential equation of the Caterny curve and how did they managed to solve the differential equation. Could anyone Please explain. Thanks,,['ordinary-differential-equations']
18,"Show that assumptions of theorem hold, determine the solution","Show that assumptions of theorem hold, determine the solution",,"Consider the initial value problem $$\left\{\begin{matrix} y'(t)=\sqrt{|y|}, 0 \leq t \leq 2\\  y(0)=1 \end{matrix}\right. \tag 1$$ Show that for this problem the assumptions of the following theorem hold: ""Let $c>0$ and $f \in C([a,b] \times [y_0-c, y_0+c])$. If $f$ satisfies at $[a,b] \times [y_0-c, y_0+c])$ the Lipschitz condition in respect to $y$, uniformly in respect of $t$, that means that: $$\exists L \geq 0: \forall t \in [a,b] \ \forall y_1, y_2 \in [y_0-c,y_0+c]: \\ |f(t,y_1)-f(t,y_2)| \leq L |y_1-y_2|$$ then the initial value problem $\left\{\begin{matrix} y'(t)=f(t,y(t)) &, a \leq t \leq b \\  y(a)=y_0 &  \end{matrix}\right.$ is solved uniquely at least at the interval $[a,b']$ where with $A=\max_{a \leq t \leq b, y_0-c \leq y \leq y_0+c} |f(t,y)|$ we have that $b'=\min \{ b, a+ \frac{c}{A}\}$. "" for appropriate $c$ and $L$. Determine the solution $y$ with the method of seperation of variables. I tried the following: $$f(t)=\sqrt{|y|}$$ $$\frac{\partial{f}}{\partial{y}}(t, y(t))=\frac{1}{2 \sqrt{|y|}} \leq M \Rightarrow \frac{1}{2M} \leq \sqrt{|y|} \Rightarrow y \geq \frac{1}{4M}$$ $$y(0)-c=1-c=\frac{1}{4M} \Rightarrow c=1-\frac{1}{4M}$$ Then $(1)$ is solved uniquely, at least at the interval $[0,b']$ where $A=\max_{0 \leq t \leq 2, \frac{1}{4M} \leq y \leq 2-\frac{1}{4M}} |\sqrt{|y|}|=\sqrt{2-\frac{1}{4M}}$ $$b'=\min \{ 2, \frac{1-\frac{1}{4M}}{\sqrt{2-\frac{1}{4M}}}\}=\frac{1-\frac{1}{4M}}{\sqrt{2-\frac{1}{4M}}}$$ $$L=M$$ $$\frac{dy}{dt}=\sqrt{|y|} \Rightarrow \frac{dy}{2\sqrt{y}}=\frac{dt}{2} \Rightarrow \sqrt{y}=\frac{1}{2}t+c$$ $$y(0)=1 \Rightarrow c=1$$ So: $$\sqrt{y}=\frac{1}{2}t+1 \Rightarrow y=\left(  \frac{1}{2}t+1\right)^2=\frac{1}{4}t^2+t+1$$ Is it right or have I done something wrong?","Consider the initial value problem $$\left\{\begin{matrix} y'(t)=\sqrt{|y|}, 0 \leq t \leq 2\\  y(0)=1 \end{matrix}\right. \tag 1$$ Show that for this problem the assumptions of the following theorem hold: ""Let $c>0$ and $f \in C([a,b] \times [y_0-c, y_0+c])$. If $f$ satisfies at $[a,b] \times [y_0-c, y_0+c])$ the Lipschitz condition in respect to $y$, uniformly in respect of $t$, that means that: $$\exists L \geq 0: \forall t \in [a,b] \ \forall y_1, y_2 \in [y_0-c,y_0+c]: \\ |f(t,y_1)-f(t,y_2)| \leq L |y_1-y_2|$$ then the initial value problem $\left\{\begin{matrix} y'(t)=f(t,y(t)) &, a \leq t \leq b \\  y(a)=y_0 &  \end{matrix}\right.$ is solved uniquely at least at the interval $[a,b']$ where with $A=\max_{a \leq t \leq b, y_0-c \leq y \leq y_0+c} |f(t,y)|$ we have that $b'=\min \{ b, a+ \frac{c}{A}\}$. "" for appropriate $c$ and $L$. Determine the solution $y$ with the method of seperation of variables. I tried the following: $$f(t)=\sqrt{|y|}$$ $$\frac{\partial{f}}{\partial{y}}(t, y(t))=\frac{1}{2 \sqrt{|y|}} \leq M \Rightarrow \frac{1}{2M} \leq \sqrt{|y|} \Rightarrow y \geq \frac{1}{4M}$$ $$y(0)-c=1-c=\frac{1}{4M} \Rightarrow c=1-\frac{1}{4M}$$ Then $(1)$ is solved uniquely, at least at the interval $[0,b']$ where $A=\max_{0 \leq t \leq 2, \frac{1}{4M} \leq y \leq 2-\frac{1}{4M}} |\sqrt{|y|}|=\sqrt{2-\frac{1}{4M}}$ $$b'=\min \{ 2, \frac{1-\frac{1}{4M}}{\sqrt{2-\frac{1}{4M}}}\}=\frac{1-\frac{1}{4M}}{\sqrt{2-\frac{1}{4M}}}$$ $$L=M$$ $$\frac{dy}{dt}=\sqrt{|y|} \Rightarrow \frac{dy}{2\sqrt{y}}=\frac{dt}{2} \Rightarrow \sqrt{y}=\frac{1}{2}t+c$$ $$y(0)=1 \Rightarrow c=1$$ So: $$\sqrt{y}=\frac{1}{2}t+1 \Rightarrow y=\left(  \frac{1}{2}t+1\right)^2=\frac{1}{4}t^2+t+1$$ Is it right or have I done something wrong?",,"['ordinary-differential-equations', 'numerical-methods']"
19,Method of characteristics,Method of characteristics,,"Given the equation $y^2 u_x + x  u_y = \sin(u^2)$ with initial condition $u(x,0) = x$, determine the values of $u_x$, $ u_y$, $u_{xx}$, $u_{yy}$, $u_{xy}$, $u_{yx}$ on the $x$-axis. I tried the following: $$\begin{cases} \frac{dx}{dt} = y^2 \\\\ \frac{dy}{dt} = x \\\\ \frac{dz}{dt} = \sin(z^2) \end{cases}$$ However, the first two coupled ODEs are really difficult to solve. So I assume there is an easier way to do this.","Given the equation $y^2 u_x + x  u_y = \sin(u^2)$ with initial condition $u(x,0) = x$, determine the values of $u_x$, $ u_y$, $u_{xx}$, $u_{yy}$, $u_{xy}$, $u_{yx}$ on the $x$-axis. I tried the following: $$\begin{cases} \frac{dx}{dt} = y^2 \\\\ \frac{dy}{dt} = x \\\\ \frac{dz}{dt} = \sin(z^2) \end{cases}$$ However, the first two coupled ODEs are really difficult to solve. So I assume there is an easier way to do this.",,"['ordinary-differential-equations', 'partial-differential-equations']"
20,Reference request: Good lower division ODE textbook that combines with linear algebra?,Reference request: Good lower division ODE textbook that combines with linear algebra?,,"I am taking an ODE course and the prof kept on making references to linear algebra. However my book (Dennis G Zill - Intro to Differential Equations) only contains algorithms to compute different solutions to ODE. I cannot see the differential equation-linear algebra connection so I kept on coming here to ask stupid questions as to how the basis in linear algebra is similar to that of a basis for a function, so and so forth. There are so many important theorems in linear algebra, but how it extends to function is totally not clear for me. If you know a textbook that somehow works the rank-nullity theorem for vectors and matrices into those of functions then I would be very happy! Thanks","I am taking an ODE course and the prof kept on making references to linear algebra. However my book (Dennis G Zill - Intro to Differential Equations) only contains algorithms to compute different solutions to ODE. I cannot see the differential equation-linear algebra connection so I kept on coming here to ask stupid questions as to how the basis in linear algebra is similar to that of a basis for a function, so and so forth. There are so many important theorems in linear algebra, but how it extends to function is totally not clear for me. If you know a textbook that somehow works the rank-nullity theorem for vectors and matrices into those of functions then I would be very happy! Thanks",,"['linear-algebra', 'analysis', 'functional-analysis', 'ordinary-differential-equations', 'reference-request']"
21,Find the general solution of the differential equation,Find the general solution of the differential equation,,"It has been a long time (years) since I have worked with differential equations and I just want to check to make sure that my method is ok and also I had a few questions. Find the general solution of the differential equation. $$\frac{dy}{dt}+ycost=0$$ $$a(t)=cost$$ $$y(t)=Ce^{-\int a(t) dt}$$ $$y(t)=Ce^{-\int cost dt}$$ $$y(t)=Ce^{-sint }$$ $$y(t)=\frac{C}{e^{sint}}$$ $$\frac{dy}{dt}+\frac{2t}{1+t^2}y=\frac{1}{1+t^2}$$ $$a(t)=\frac{2t}{1+t^2}$$ $$μ(t)=e^{\int a(t)dt}$$ $$μ(t)=e^{\int \frac{2t}{1+t^2}dt}$$ Then doing a u substitution with $u=1+t^2$ and $du=2tdt$ (Would $μ(t)$ become $μ(u)$ or just $μ$ when I am doing the u substitution? $$μ(t)=e^{\int \frac{1}{u}du}$$ $$μ(t)=e^{ln|u|}$$ $$μ(t)=|u|$$ (Do I need to keep the absolute value signs here?) Resubstitute $1+t^2$ in for u: $$μ(t)=|1+t^2|$$ Multiply both sides of the original equation by $μ(t)$: $$μ(t)[\frac{dy}{dt}+\frac{2t}{1+t^2}y]=μ(t)[\frac{1}{1+t^2}]$$ $$|1+t^2|[\frac{dy}{dt}+\frac{2t}{1+t^2}y]=|1+t^2|[\frac{1}{1+t^2}]$$ $$\frac{d}{dt}(1+t^2)y=1$$ $$(1+t^2)y=\int dt$$ $$(1+t^2)y=t + C$$ $$y=\frac{t}{1+t^2} + C$$ So I just need to use the $μ(t)$ method when the original equation has a right hand side not equal to 0 (is a nonhomogeneous differential equation, right?)","It has been a long time (years) since I have worked with differential equations and I just want to check to make sure that my method is ok and also I had a few questions. Find the general solution of the differential equation. $$\frac{dy}{dt}+ycost=0$$ $$a(t)=cost$$ $$y(t)=Ce^{-\int a(t) dt}$$ $$y(t)=Ce^{-\int cost dt}$$ $$y(t)=Ce^{-sint }$$ $$y(t)=\frac{C}{e^{sint}}$$ $$\frac{dy}{dt}+\frac{2t}{1+t^2}y=\frac{1}{1+t^2}$$ $$a(t)=\frac{2t}{1+t^2}$$ $$μ(t)=e^{\int a(t)dt}$$ $$μ(t)=e^{\int \frac{2t}{1+t^2}dt}$$ Then doing a u substitution with $u=1+t^2$ and $du=2tdt$ (Would $μ(t)$ become $μ(u)$ or just $μ$ when I am doing the u substitution? $$μ(t)=e^{\int \frac{1}{u}du}$$ $$μ(t)=e^{ln|u|}$$ $$μ(t)=|u|$$ (Do I need to keep the absolute value signs here?) Resubstitute $1+t^2$ in for u: $$μ(t)=|1+t^2|$$ Multiply both sides of the original equation by $μ(t)$: $$μ(t)[\frac{dy}{dt}+\frac{2t}{1+t^2}y]=μ(t)[\frac{1}{1+t^2}]$$ $$|1+t^2|[\frac{dy}{dt}+\frac{2t}{1+t^2}y]=|1+t^2|[\frac{1}{1+t^2}]$$ $$\frac{d}{dt}(1+t^2)y=1$$ $$(1+t^2)y=\int dt$$ $$(1+t^2)y=t + C$$ $$y=\frac{t}{1+t^2} + C$$ So I just need to use the $μ(t)$ method when the original equation has a right hand side not equal to 0 (is a nonhomogeneous differential equation, right?)",,['ordinary-differential-equations']
22,Showing that $y''+xy'+y=0$ is exact and then finding the general solution,Showing that  is exact and then finding the general solution,y''+xy'+y=0,We can use the condition $P''(x)-Q'(x)+R(x)=0$ to show that $y''+xy'+y=0$ is exact. I was told that I will need to integrate the equation once then apply the appropriate first order method. I have tried to integrate but got lost with all the variables.,We can use the condition $P''(x)-Q'(x)+R(x)=0$ to show that $y''+xy'+y=0$ is exact. I was told that I will need to integrate the equation once then apply the appropriate first order method. I have tried to integrate but got lost with all the variables.,,['ordinary-differential-equations']
23,Newton's method to solve implicit Runge-Kutta-method,Newton's method to solve implicit Runge-Kutta-method,,"I'm having a bit of a problem to solve an initial value problem by employing an implicit s-step Runge-Kutta method (and Newton's method). More precisely, I don't know how to employ Newton's method in this case. The initial value problem is pretty standard: \begin{equation*} y'(t) = f(t,y(t)), \quad y(t_0) = 0 =:y_0 \in \mathbb R^n, \quad f: \mathbb R \times \mathbb R^n \to \mathbb R. \end{equation*} I'm also given $f'$ (the Jacobian of $f$)  and a discrete time grid $(t_0, \ldots, t_N)$ as well as the Butcher tableau regarding the Runge-Kutta method: \begin{equation*} \begin{array}{c|c}   c&A \\ \hline &b   \end{array}, \quad c \in \mathbb R^s, A \in \mathbb R^{s,s}, b \in \mathbb R^{1,s}. \end{equation*} Now I have to calculate the $k_i$ such that I can calculate $y_1 = y_0 + \sum_{i=1}^s b_ik_i.$ Since $A$ isn't necessarily a strictly lower triangular matrix, or even triangular at all, I have to solve a set of linear (or nonlinear) equations to calculate the $k_i$. So my first system of equations reads as follows: \begin{align*} k_1 &= f\left(t_0+c_1h,y_0+h\sum_{i=1}^sa_{1i}k_1\right)\\ k_2 &= f\left(t_0+c_2h,y_0+h\sum_{i=1}^sa_{2i}k_1\right)\\ &\,\,\vdots\\ k_s &= f\left(t_0+c_sh,y_0+h\sum_{i=1}^sa_{si}k_1\right), \end{align*} with $h := t_1 - t_0$. To solve this system, I have to use Newton's method. That's the part where I'm stuck. My current idea is this: Let $K := (k_1, \ldots, k_s)^T$ and define \begin{equation*} F : \mathbb R^{s\cdot n} \to \mathbb R^{s \cdot n}, \quad K \mapsto \begin{pmatrix} f_1(K)-k_1\\ f_2(K)-k_2\\ \vdots\\ f_s(K)-k_s \end{pmatrix} \end{equation*} with \begin{equation*} f_j(K) = f\left(t_0+c_jh,y_0+h\sum_{i=1}^s a_{ji}k_i \right). \end{equation*} Then I would start, as suggested in the assignment, with $k_1 = k_2 = \ldots = k_s = 0$ to find a $\tilde{K}$ such that $F(\tilde{K}) = 0$ via Newton's method, which would solve the system of equations and thusly allow me to calculate $y_1$. Then I could do the same for $y_2, y_3, \ldots$. I do however need the Jacobian of my function $F$ and I'm inadept to calculate it simply given the Jacobian of $ f $ I'm presented with. I suppose it'd look like this: \begin{align*} J_F(K) &= \begin{pmatrix} \frac{\partial f_1-k_1}{\partial k_1} (K)&  \frac{\partial f_1-k_1}{\partial k_2} (K)& \cdots &  \frac{\partial f_1-k_1}{\partial k_s}(K)\\ \frac{\partial f_2-k_2}{\partial k_1}(K)&  \frac{\partial f_2-k_2}{\partial k_2} (K) & \cdots &  \frac{\partial f_2-k_2}{\partial k_s}(K)\\ \vdots & & \ddots & \vdots\\ \frac{\partial f_s-k_s}{\partial k_1} (K)& \cdots & & \frac{\partial f_s-k_s}{\partial k_s}(K) \end{pmatrix} \\&= \begin{pmatrix} \left(\frac{\partial f_1}{\partial k_1}-1\right) (K)&  \frac{\partial f_1}{\partial k_2} (K)& \cdots &  \frac{\partial f_1}{\partial k_s}(K)\\ \frac{\partial f_2}{\partial k_1}(K)&  \left(\frac{\partial f_2}{\partial k_2}-1\right) (K) & \cdots &  \frac{\partial f_2}{\partial k_s}(K)\\ \vdots & & \ddots & \vdots\\ \frac{\partial f_s}{\partial k_1} (K)& \cdots & & \left(\frac{\partial f_s}{\partial k_s}-1\right)(K) \end{pmatrix}. \end{align*} Note: I do not know which function I'm given, nor do I know which Runge-Kutta method I actually have to solve. I'm writing a program in MATLAB and get these information fed as part of the assignment. Moreover, the solving of the problem is slightly urgent.","I'm having a bit of a problem to solve an initial value problem by employing an implicit s-step Runge-Kutta method (and Newton's method). More precisely, I don't know how to employ Newton's method in this case. The initial value problem is pretty standard: \begin{equation*} y'(t) = f(t,y(t)), \quad y(t_0) = 0 =:y_0 \in \mathbb R^n, \quad f: \mathbb R \times \mathbb R^n \to \mathbb R. \end{equation*} I'm also given $f'$ (the Jacobian of $f$)  and a discrete time grid $(t_0, \ldots, t_N)$ as well as the Butcher tableau regarding the Runge-Kutta method: \begin{equation*} \begin{array}{c|c}   c&A \\ \hline &b   \end{array}, \quad c \in \mathbb R^s, A \in \mathbb R^{s,s}, b \in \mathbb R^{1,s}. \end{equation*} Now I have to calculate the $k_i$ such that I can calculate $y_1 = y_0 + \sum_{i=1}^s b_ik_i.$ Since $A$ isn't necessarily a strictly lower triangular matrix, or even triangular at all, I have to solve a set of linear (or nonlinear) equations to calculate the $k_i$. So my first system of equations reads as follows: \begin{align*} k_1 &= f\left(t_0+c_1h,y_0+h\sum_{i=1}^sa_{1i}k_1\right)\\ k_2 &= f\left(t_0+c_2h,y_0+h\sum_{i=1}^sa_{2i}k_1\right)\\ &\,\,\vdots\\ k_s &= f\left(t_0+c_sh,y_0+h\sum_{i=1}^sa_{si}k_1\right), \end{align*} with $h := t_1 - t_0$. To solve this system, I have to use Newton's method. That's the part where I'm stuck. My current idea is this: Let $K := (k_1, \ldots, k_s)^T$ and define \begin{equation*} F : \mathbb R^{s\cdot n} \to \mathbb R^{s \cdot n}, \quad K \mapsto \begin{pmatrix} f_1(K)-k_1\\ f_2(K)-k_2\\ \vdots\\ f_s(K)-k_s \end{pmatrix} \end{equation*} with \begin{equation*} f_j(K) = f\left(t_0+c_jh,y_0+h\sum_{i=1}^s a_{ji}k_i \right). \end{equation*} Then I would start, as suggested in the assignment, with $k_1 = k_2 = \ldots = k_s = 0$ to find a $\tilde{K}$ such that $F(\tilde{K}) = 0$ via Newton's method, which would solve the system of equations and thusly allow me to calculate $y_1$. Then I could do the same for $y_2, y_3, \ldots$. I do however need the Jacobian of my function $F$ and I'm inadept to calculate it simply given the Jacobian of $ f $ I'm presented with. I suppose it'd look like this: \begin{align*} J_F(K) &= \begin{pmatrix} \frac{\partial f_1-k_1}{\partial k_1} (K)&  \frac{\partial f_1-k_1}{\partial k_2} (K)& \cdots &  \frac{\partial f_1-k_1}{\partial k_s}(K)\\ \frac{\partial f_2-k_2}{\partial k_1}(K)&  \frac{\partial f_2-k_2}{\partial k_2} (K) & \cdots &  \frac{\partial f_2-k_2}{\partial k_s}(K)\\ \vdots & & \ddots & \vdots\\ \frac{\partial f_s-k_s}{\partial k_1} (K)& \cdots & & \frac{\partial f_s-k_s}{\partial k_s}(K) \end{pmatrix} \\&= \begin{pmatrix} \left(\frac{\partial f_1}{\partial k_1}-1\right) (K)&  \frac{\partial f_1}{\partial k_2} (K)& \cdots &  \frac{\partial f_1}{\partial k_s}(K)\\ \frac{\partial f_2}{\partial k_1}(K)&  \left(\frac{\partial f_2}{\partial k_2}-1\right) (K) & \cdots &  \frac{\partial f_2}{\partial k_s}(K)\\ \vdots & & \ddots & \vdots\\ \frac{\partial f_s}{\partial k_1} (K)& \cdots & & \left(\frac{\partial f_s}{\partial k_s}-1\right)(K) \end{pmatrix}. \end{align*} Note: I do not know which function I'm given, nor do I know which Runge-Kutta method I actually have to solve. I'm writing a program in MATLAB and get these information fed as part of the assignment. Moreover, the solving of the problem is slightly urgent.",,"['ordinary-differential-equations', 'numerical-methods']"
24,Laplace equation in a rectangle; a non-symmetric solution,Laplace equation in a rectangle; a non-symmetric solution,,"Consider Laplace's equation in a rectangle with specified boundary conditions. This problem is solved when $\epsilon_1 = \epsilon_2$ in the following link . $$ \nabla \cdot \epsilon \nabla V=0$$ What if the $\epsilon_1$ and $\epsilon_2$ be different. We can still use the fact that at $x=a/2$, $V$ would be constant. However, its value is not $(V_1+V_2)/2$ since the symmetry is broken. Can we use the continuity of $dV/dx$ to find the value of V at $x=a/2$?","Consider Laplace's equation in a rectangle with specified boundary conditions. This problem is solved when $\epsilon_1 = \epsilon_2$ in the following link . $$ \nabla \cdot \epsilon \nabla V=0$$ What if the $\epsilon_1$ and $\epsilon_2$ be different. We can still use the fact that at $x=a/2$, $V$ would be constant. However, its value is not $(V_1+V_2)/2$ since the symmetry is broken. Can we use the continuity of $dV/dx$ to find the value of V at $x=a/2$?",,"['ordinary-differential-equations', 'derivatives', 'partial-differential-equations']"
25,Voltera equation,Voltera equation,,Consider the Voltera integral equation: $$ψ(x)=e^{-x}\cos(x)-\int_{0}^{x}e^{-(x-t)}\cos(x)ψ(t)dt$$ How can I solve this equation by converting it to a differential equation?  The solution is $$\psi(x)=\frac{\cos(x)}{e^{x+\sin(x)}}$$ I mean $$\psi(x)=\cos(x)e^{-(x+\sin(x))}$$,Consider the Voltera integral equation: $$ψ(x)=e^{-x}\cos(x)-\int_{0}^{x}e^{-(x-t)}\cos(x)ψ(t)dt$$ How can I solve this equation by converting it to a differential equation?  The solution is $$\psi(x)=\frac{\cos(x)}{e^{x+\sin(x)}}$$ I mean $$\psi(x)=\cos(x)e^{-(x+\sin(x))}$$,,"['ordinary-differential-equations', 'integral-equations']"
26,IVP of second order linear ODE,IVP of second order linear ODE,,"Bumps are often built into roads to discourage speeding. Consider a   crude model of the vertical motion $y(t)$ of a car encountering the   speed bump with the speed $V$ is given by $$y(t)=0   \qquad\text{for}\;  t \leq -L/(2V)$$ $$my''+ky= \begin{cases} F_0\cos(\pi Vt/L) &   \text{for}\, |t|<L/(2V)\\ 0                          & \text{for}\,t  \geq L/(2V) \end{cases}$$ Taking $m=k=1, L=\pi,$ and $F_0 =1$ in   appropriate units, solve $y(t)$. It reduces to solving $y''+y=\cos(Vt)$. The usual method of undetermined coefficients applies and I get the following, which check with that from Wolfram Alpha: $$y(t)= \begin{cases} \frac{\cos(Vt)}{1-V^2}+A \cos t + B\sin t &  \text{if}\, V \neq 1\\ \frac{t \sin t}{2} +A \cos t + B\sin t         & \text{if}\,V = 1 \end{cases}.$$ When I check the solution provided by the book, I find this: $$y(t)= \begin{cases} \frac{2V \cos (\pi / 2V)}{V^2-1} \sin t &  \text{if}\, V \neq 1\\ \frac{\pi}{2} \sin t         & \text{if}\,V = 1 \end{cases}.$$ I cannot proceed to find these solutions. I tried substituting $t=-\frac{\pi}{2V}$, but I have two unknowns. What am I missing here? Thanks in advance.","Bumps are often built into roads to discourage speeding. Consider a   crude model of the vertical motion $y(t)$ of a car encountering the   speed bump with the speed $V$ is given by $$y(t)=0   \qquad\text{for}\;  t \leq -L/(2V)$$ $$my''+ky= \begin{cases} F_0\cos(\pi Vt/L) &   \text{for}\, |t|<L/(2V)\\ 0                          & \text{for}\,t  \geq L/(2V) \end{cases}$$ Taking $m=k=1, L=\pi,$ and $F_0 =1$ in   appropriate units, solve $y(t)$. It reduces to solving $y''+y=\cos(Vt)$. The usual method of undetermined coefficients applies and I get the following, which check with that from Wolfram Alpha: $$y(t)= \begin{cases} \frac{\cos(Vt)}{1-V^2}+A \cos t + B\sin t &  \text{if}\, V \neq 1\\ \frac{t \sin t}{2} +A \cos t + B\sin t         & \text{if}\,V = 1 \end{cases}.$$ When I check the solution provided by the book, I find this: $$y(t)= \begin{cases} \frac{2V \cos (\pi / 2V)}{V^2-1} \sin t &  \text{if}\, V \neq 1\\ \frac{\pi}{2} \sin t         & \text{if}\,V = 1 \end{cases}.$$ I cannot proceed to find these solutions. I tried substituting $t=-\frac{\pi}{2V}$, but I have two unknowns. What am I missing here? Thanks in advance.",,['ordinary-differential-equations']
27,"example which does not satify Lipschitz condition, but has a unique solution","example which does not satify Lipschitz condition, but has a unique solution",,"$$y'=1+\sqrt y\\y(0)=0 $$   Show that this IVP does not satisfy Lipschitz condition, but has a unique solution. I have shown the first way, like this: Let $f(x,y)=1+\sqrt y $. Then $\frac {|f(x,y_1)-f(x,0)|}{|y_1-0|}=|\frac{1}{\sqrt y_1}| \rightarrow \infty $ as $y_1\rightarrow 0 $. How to show the uniqueness part? Please help.","$$y'=1+\sqrt y\\y(0)=0 $$   Show that this IVP does not satisfy Lipschitz condition, but has a unique solution. I have shown the first way, like this: Let $f(x,y)=1+\sqrt y $. Then $\frac {|f(x,y_1)-f(x,0)|}{|y_1-0|}=|\frac{1}{\sqrt y_1}| \rightarrow \infty $ as $y_1\rightarrow 0 $. How to show the uniqueness part? Please help.",,['ordinary-differential-equations']
28,Prove the energy is constant in a PDE?,Prove the energy is constant in a PDE?,,"I calculated the $$ \begin{align} \frac{dE(t)}{2\,dt} & = \int_\Omega u_tu_{tt}+DuDu_t+u^3u_t\,dx \\ & =\int_\Omega [u_t(u_{tt}-\Delta u)+u^3u_t] \, dx+\int_{\partial \Omega} u_t \frac{\partial u}{\partial v} \, ds = \int_{\partial \Omega} u_t \frac{\partial u}{\partial v} \, ds \end{align} $$ However, I don't know how to prove $$\int_{\partial \Omega} u_t \frac{\partial u}{\partial v}ds$$ is zero by the conditions given in the problem? Can anyone help me about this? Thanks so much! Can anyone help me explain why $u_t\cong 0$ on $\partial \Omega$? Thanks so much!:)","I calculated the $$ \begin{align} \frac{dE(t)}{2\,dt} & = \int_\Omega u_tu_{tt}+DuDu_t+u^3u_t\,dx \\ & =\int_\Omega [u_t(u_{tt}-\Delta u)+u^3u_t] \, dx+\int_{\partial \Omega} u_t \frac{\partial u}{\partial v} \, ds = \int_{\partial \Omega} u_t \frac{\partial u}{\partial v} \, ds \end{align} $$ However, I don't know how to prove $$\int_{\partial \Omega} u_t \frac{\partial u}{\partial v}ds$$ is zero by the conditions given in the problem? Can anyone help me about this? Thanks so much! Can anyone help me explain why $u_t\cong 0$ on $\partial \Omega$? Thanks so much!:)",,"['analysis', 'ordinary-differential-equations', 'partial-differential-equations']"
29,Two ways of finding a Potential of a Vector Field,Two ways of finding a Potential of a Vector Field,,"If $\vec{F}(x,y)$ is a conservative vector field and we want to find a function $V$ such that $\nabla(V)=\vec{F}$, then one way to do it is to take an arbitrary point $(x_0,y_0)$ and then define $V(x,y)$ to be the line integral of $\vec{F}$ along an arbitrary curve $C$ from $(x_0,y_0)$ to $(x,y)$.  ($V$ is well-defined because the line integral is path-independent.) But there's another way to find a potential of a conservative vector field: you use the fact that $\frac{\partial V}{\partial x} = F_x$ to conclude that $V(x,y)$ must be of the form $\int_a^x F_x(u,y) du + G(y)$, and similarly $\frac{\partial V}{\partial y} = F_y$ implies that $V(x,y)$ must be of the form $\int_b^y F_y(x,v) du + H(x)$.  So you find functions $G(y)$ and $H(x)$ such that $\int_a^x F_x(u,y) du + G(y) = \int_b^y F_y(x,v) du + H(x)$ My question is, how do the two methods produce the same result?  Specifically, given a function $V$ constructed using the first method, how can you find a function $G(y)$ corresponding to it?  For any specific vector field $\vec{F}(x,y)$ you can just find it by inspection, but is it possible to come up with a general expression for it in terms of the line integral of $F$?  Similarly, is there a general expression for $H(x)$? I think it's probably most convenient to let $x_0 = a$ and $y_0 = b$.","If $\vec{F}(x,y)$ is a conservative vector field and we want to find a function $V$ such that $\nabla(V)=\vec{F}$, then one way to do it is to take an arbitrary point $(x_0,y_0)$ and then define $V(x,y)$ to be the line integral of $\vec{F}$ along an arbitrary curve $C$ from $(x_0,y_0)$ to $(x,y)$.  ($V$ is well-defined because the line integral is path-independent.) But there's another way to find a potential of a conservative vector field: you use the fact that $\frac{\partial V}{\partial x} = F_x$ to conclude that $V(x,y)$ must be of the form $\int_a^x F_x(u,y) du + G(y)$, and similarly $\frac{\partial V}{\partial y} = F_y$ implies that $V(x,y)$ must be of the form $\int_b^y F_y(x,v) du + H(x)$.  So you find functions $G(y)$ and $H(x)$ such that $\int_a^x F_x(u,y) du + G(y) = \int_b^y F_y(x,v) du + H(x)$ My question is, how do the two methods produce the same result?  Specifically, given a function $V$ constructed using the first method, how can you find a function $G(y)$ corresponding to it?  For any specific vector field $\vec{F}(x,y)$ you can just find it by inspection, but is it possible to come up with a general expression for it in terms of the line integral of $F$?  Similarly, is there a general expression for $H(x)$? I think it's probably most convenient to let $x_0 = a$ and $y_0 = b$.",,"['ordinary-differential-equations', 'multivariable-calculus', 'vector-fields']"
30,Diffusion-Reaction PDE - radial coordinate,Diffusion-Reaction PDE - radial coordinate,,"I am trying to obtain an expression for the concentration $C$ based on this stationary equation : $\frac{\partial C}{\partial t} = \frac{1}{r} \frac{d}{dr} \left(r \frac{\partial C}{\partial r}\right) - \frac{k}{D} C = 0 $ Being in cylindrical/radial coordinate, I can't simplify the $r$, which would make the calculation more easy. I tried to resolve this in Mathematica. Analytical solution can be obtained based on Bessel's functions, to which I'm not really used. Can someone help me to manually get to these analytical solution ? NB : problem quite similar to this one (I think) : Reaction-diffusion PDE in cylindrical coordinates - Green's function method","I am trying to obtain an expression for the concentration $C$ based on this stationary equation : $\frac{\partial C}{\partial t} = \frac{1}{r} \frac{d}{dr} \left(r \frac{\partial C}{\partial r}\right) - \frac{k}{D} C = 0 $ Being in cylindrical/radial coordinate, I can't simplify the $r$, which would make the calculation more easy. I tried to resolve this in Mathematica. Analytical solution can be obtained based on Bessel's functions, to which I'm not really used. Can someone help me to manually get to these analytical solution ? NB : problem quite similar to this one (I think) : Reaction-diffusion PDE in cylindrical coordinates - Green's function method",,"['ordinary-differential-equations', 'partial-differential-equations']"
31,Differential equation,Differential equation,,"$$x^2(x^2+1)y''-2x^3y'+2(x^2-1)y=0$$ Anyway my tutor assumes that one of the solutions must be $y=x^2$, yet I can't seem to prove this, I tried using $y=x^n$ but I can't seem to get an answer that cancels down. I know soon as I get this solution I can use Abel's forumla to get the other solution. Any help appreciated.","$$x^2(x^2+1)y''-2x^3y'+2(x^2-1)y=0$$ Anyway my tutor assumes that one of the solutions must be $y=x^2$, yet I can't seem to prove this, I tried using $y=x^n$ but I can't seem to get an answer that cancels down. I know soon as I get this solution I can use Abel's forumla to get the other solution. Any help appreciated.",,['ordinary-differential-equations']
32,Find a differential equation for which a series is a solution,Find a differential equation for which a series is a solution,,"This is just a general question. Given a power series in one real variable, is it always possible to find a differential equation for which the series is a solution? If not, when is it possible?","This is just a general question. Given a power series in one real variable, is it always possible to find a differential equation for which the series is a solution? If not, when is it possible?",,"['real-analysis', 'ordinary-differential-equations']"
33,Differential equation with a unknown function $g$ but a known solution.,Differential equation with a unknown function  but a known solution.,g,"Say we have an equation $y'+g(x)y=3x, x>0$. We know one solution to this FDE: $y(x) = x^2$ How can we know if there's a solution which satisfies $y(1) = 2$? Questions I'd like answered Q1: First and foremost, how do I go about solving the problem I have listed? Q2: If I understand correctly, this is a first-order linear ordinary differential equation . However, is there any known term for the problem I have, where you have an unknown function $g(x)$. Q3: Is $g(x)$ to be considered a coefficient for our differential equation (where we are searching for $y$).","Say we have an equation $y'+g(x)y=3x, x>0$. We know one solution to this FDE: $y(x) = x^2$ How can we know if there's a solution which satisfies $y(1) = 2$? Questions I'd like answered Q1: First and foremost, how do I go about solving the problem I have listed? Q2: If I understand correctly, this is a first-order linear ordinary differential equation . However, is there any known term for the problem I have, where you have an unknown function $g(x)$. Q3: Is $g(x)$ to be considered a coefficient for our differential equation (where we are searching for $y$).",,"['calculus', 'integration', 'ordinary-differential-equations']"
34,Use Laplace Transform to solve the following IVP:,Use Laplace Transform to solve the following IVP:,,"I know that this is a somewhat simple problem but I have been having trouble coming up with the little ""tricks"" that help with Laplace. The problem is: $y''+2y' +5y = e^{-t}\sin(2t)$ where $y(0) = 2, y'(0) = -1$ Attempt at Solution $(s^2+2s+5)Y = \frac{2}{(s+1)^2+4} + (s+2)(2) + 1(-1)$ $Y = \frac{2}{(s^2+2s+5)^2}+\frac{2s+3}{s2+2s+5}$ $Y = \frac{2}{(s^2+2s+5)^2}+2(\frac{s+1}{s^2+2s+5})+\frac{1}{s^2+2s+5}$ $Y = \frac{2}{(s^2+2s+5)^2}+\frac{1}{2}\sin(2t)+2e^{-t}\cos(2t)$ And I am stuck here. The answer given in the book is as follows: Y = $\frac{5}{8}e^{-t}\sin(2t)+2e^{-t}\cos(2t)-\frac{1}{4}te^{-t}\cos(2t)$ Any help would be greatly appreciated.","I know that this is a somewhat simple problem but I have been having trouble coming up with the little ""tricks"" that help with Laplace. The problem is: $y''+2y' +5y = e^{-t}\sin(2t)$ where $y(0) = 2, y'(0) = -1$ Attempt at Solution $(s^2+2s+5)Y = \frac{2}{(s+1)^2+4} + (s+2)(2) + 1(-1)$ $Y = \frac{2}{(s^2+2s+5)^2}+\frac{2s+3}{s2+2s+5}$ $Y = \frac{2}{(s^2+2s+5)^2}+2(\frac{s+1}{s^2+2s+5})+\frac{1}{s^2+2s+5}$ $Y = \frac{2}{(s^2+2s+5)^2}+\frac{1}{2}\sin(2t)+2e^{-t}\cos(2t)$ And I am stuck here. The answer given in the book is as follows: Y = $\frac{5}{8}e^{-t}\sin(2t)+2e^{-t}\cos(2t)-\frac{1}{4}te^{-t}\cos(2t)$ Any help would be greatly appreciated.",,"['ordinary-differential-equations', 'laplace-transform']"
35,Integral form of this IVP,Integral form of this IVP,,"How do I show that the following initial value problem $$ xu''+u'+xu=0,\quad  u(0)=1,\quad u'(0)=0 $$ has the following integral form: $$ u(x)=1+\int_{0}^{x} t\ln(t/x)u(t)\,dt $$ I am stuck because if I divide both sides of both ODE by $x$ $$ u'+\frac{1}{x}u+u=0 $$ $\frac{1}{x}$ is undefined at $0$.","How do I show that the following initial value problem $$ xu''+u'+xu=0,\quad  u(0)=1,\quad u'(0)=0 $$ has the following integral form: $$ u(x)=1+\int_{0}^{x} t\ln(t/x)u(t)\,dt $$ I am stuck because if I divide both sides of both ODE by $x$ $$ u'+\frac{1}{x}u+u=0 $$ $\frac{1}{x}$ is undefined at $0$.",,"['analysis', 'ordinary-differential-equations', 'integral-equations']"
36,what is the order and the degree of the given diff. equation?,what is the order and the degree of the given diff. equation?,,the given diff. equation is $$y=1+ \frac{dy}{dx}+\frac{1}{2!}\left(\frac{dy}{dx}\right)^2+\cdots+\frac{1}{n!}\left(\frac{dy}{dx}\right)^n$$ it is given that the order is $1$ and the degree is also $1$. But how it happens because the the highest order $1$ has degree is $n$. so how the given degree is possible?,the given diff. equation is $$y=1+ \frac{dy}{dx}+\frac{1}{2!}\left(\frac{dy}{dx}\right)^2+\cdots+\frac{1}{n!}\left(\frac{dy}{dx}\right)^n$$ it is given that the order is $1$ and the degree is also $1$. But how it happens because the the highest order $1$ has degree is $n$. so how the given degree is possible?,,['ordinary-differential-equations']
37,"Second order differential equation at an ordinary point, Frobenius method","Second order differential equation at an ordinary point, Frobenius method",,Given the eq: $$(x+2)y''-xy'+(1-x^2)y=0 ; \quad X_0=1$$ I get to this step after deriving the derivatives of the $\sum_0^\infty A_n(x-1)^n$ : $$(1+(x-1))\left[ \sum_{n=2}^{\infty} (n(n-1)A_n(x-1)^{n-2}\right]-(1+(x-1))\left[\sum_{n=1}^{\infty} A_nn(x-1)^{n-1}\right] + (1-x^2)\left(\sum_{n=0}^{\infty}A_n(x-1)^n\right)=0$$ After distributing through what I could: $\sum n(n-1)A_n(x-1)^{n-2} +\sum n(n-1)A_n(x-1)^{n-1}-\sum A_nn(x-1)^{n-1}-\sum A_n(x-1)^n+(1-x^2)\cdot \sum A_n(x-1)^n =0$ I don't understand how to distribute through the last piece $(1-x^2)$ as I do for the first piece where I substituted $(1+(x-1))$ to make it possible. How would I go about solving the rest? Help is appreciated; thanks in advance.,Given the eq: $$(x+2)y''-xy'+(1-x^2)y=0 ; \quad X_0=1$$ I get to this step after deriving the derivatives of the $\sum_0^\infty A_n(x-1)^n$ : $$(1+(x-1))\left[ \sum_{n=2}^{\infty} (n(n-1)A_n(x-1)^{n-2}\right]-(1+(x-1))\left[\sum_{n=1}^{\infty} A_nn(x-1)^{n-1}\right] + (1-x^2)\left(\sum_{n=0}^{\infty}A_n(x-1)^n\right)=0$$ After distributing through what I could: $\sum n(n-1)A_n(x-1)^{n-2} +\sum n(n-1)A_n(x-1)^{n-1}-\sum A_nn(x-1)^{n-1}-\sum A_n(x-1)^n+(1-x^2)\cdot \sum A_n(x-1)^n =0$ I don't understand how to distribute through the last piece $(1-x^2)$ as I do for the first piece where I substituted $(1+(x-1))$ to make it possible. How would I go about solving the rest? Help is appreciated; thanks in advance.,,['ordinary-differential-equations']
38,Solving a system of Differential Equations: arbitrary constants,Solving a system of Differential Equations: arbitrary constants,,"For a research project I am carrying out I am required to solve the system: $\frac{dp}{dt} = -lp $, $ \frac{dc}{dt} = lp - kc $ with initial conditions $p(0) = p_0 $ and $c(0) = 0 $.  Here, $p,c$ denote concentrations and $l,k$ are reaction rates. I believe that I have solved the system to reach a solution  $$ c(t) = (\alpha + \frac{\beta}{l - k})e^{-kt} - \frac{lp_0}{l-k}e^{-lt}  $$ where $\alpha, \beta$ are arbitrary constants. I am quite sure (barring any typos!) that this solves the system however I can't seem to get rid of the two arbitrary constants. I don't know if I need another initial condition or am missing some relation between the two constants? Since this is a Pharmacokinetics problem, I was able to find a relation between $ \alpha$ and $\beta$ by considering the half life. However, this resulted in something like: $$ \alpha = \frac{((lp_0)^p - \beta^k)^{1/k}}{l-k} $$ which didn't seem to help. Any help or feedback would be appreciated.","For a research project I am carrying out I am required to solve the system: $\frac{dp}{dt} = -lp $, $ \frac{dc}{dt} = lp - kc $ with initial conditions $p(0) = p_0 $ and $c(0) = 0 $.  Here, $p,c$ denote concentrations and $l,k$ are reaction rates. I believe that I have solved the system to reach a solution  $$ c(t) = (\alpha + \frac{\beta}{l - k})e^{-kt} - \frac{lp_0}{l-k}e^{-lt}  $$ where $\alpha, \beta$ are arbitrary constants. I am quite sure (barring any typos!) that this solves the system however I can't seem to get rid of the two arbitrary constants. I don't know if I need another initial condition or am missing some relation between the two constants? Since this is a Pharmacokinetics problem, I was able to find a relation between $ \alpha$ and $\beta$ by considering the half life. However, this resulted in something like: $$ \alpha = \frac{((lp_0)^p - \beta^k)^{1/k}}{l-k} $$ which didn't seem to help. Any help or feedback would be appreciated.",,"['calculus', 'ordinary-differential-equations']"
39,Show stable node or spiral cannot occur,Show stable node or spiral cannot occur,,"If I have the equation: $$\ddot{x} + f(\dot{x}) + g(x) = 0$$ where $f$ is even and $f$ and $g$ are both smooth, how do I show that the equilibrium points cannot be stable nodes or spirals? What I've done so far is: $$\dot{x} = y$$ $$\dot{y} = F(x,y) = -f(y) - g(x)$$ I can try to take the Jacobian at the fixed points $$J = \begin{pmatrix} 0 & 1 \\ \frac{\partial F}{\partial x} & \frac{\partial F}{\partial y} \end{pmatrix}$$ but without knowing the values of $\frac{\partial F}{\partial x}$ or $\frac{\partial F}{\partial y}$ I can't tell what type of fixed points can occur. My best guess is that, based on the information in the question, there must be some restriction on the values $\frac{\partial F}{\partial x}$ or $\frac{\partial F}{\partial y}$ can take, which would then rule out the possibility of stable nodes or spirals. However, I can't seem to find any such restrictions. Any help would be appreciated!","If I have the equation: $$\ddot{x} + f(\dot{x}) + g(x) = 0$$ where $f$ is even and $f$ and $g$ are both smooth, how do I show that the equilibrium points cannot be stable nodes or spirals? What I've done so far is: $$\dot{x} = y$$ $$\dot{y} = F(x,y) = -f(y) - g(x)$$ I can try to take the Jacobian at the fixed points $$J = \begin{pmatrix} 0 & 1 \\ \frac{\partial F}{\partial x} & \frac{\partial F}{\partial y} \end{pmatrix}$$ but without knowing the values of $\frac{\partial F}{\partial x}$ or $\frac{\partial F}{\partial y}$ I can't tell what type of fixed points can occur. My best guess is that, based on the information in the question, there must be some restriction on the values $\frac{\partial F}{\partial x}$ or $\frac{\partial F}{\partial y}$ can take, which would then rule out the possibility of stable nodes or spirals. However, I can't seem to find any such restrictions. Any help would be appreciated!",,['ordinary-differential-equations']
40,How do you solve a 2nd order differential equation of the form $v = v' - v'' +C^t +D^{t+E}$,How do you solve a 2nd order differential equation of the form,v = v' - v'' +C^t +D^{t+E},"I've been working on an economic simulator for a game I've been making and in order to simulate the velocity of money, I created the differential equation of the form $v = v' -v'' + C^t + D^{t+E}$. However, after creating it, I realized that I didn't actually know how to solve it (the most advanced course in mathematics I have taken is Calculus BC), and neither Wolfram Alpha nor Sage seem to be able to use a method to either solve or approximate the solution. Thanks for any help in advance!","I've been working on an economic simulator for a game I've been making and in order to simulate the velocity of money, I created the differential equation of the form $v = v' -v'' + C^t + D^{t+E}$. However, after creating it, I realized that I didn't actually know how to solve it (the most advanced course in mathematics I have taken is Calculus BC), and neither Wolfram Alpha nor Sage seem to be able to use a method to either solve or approximate the solution. Thanks for any help in advance!",,['ordinary-differential-equations']
41,Number of solutions of an IVP,Number of solutions of an IVP,,"$\dfrac{dy}{dx}=60y^{\dfrac{2}{5}}$ ,$x\gt 0$ ,$y(0)=0$ has 1.a unique solution. 2.two solutions. 3.no solution. 4.infinite number of solutions. Here f(x,y)=$60y^{\dfrac{2}{5}}$ does not satisfy Lipschitz's condition, so I can't give any conclusion about the uniqueness of the solution. how can I get all possible solutions?","$\dfrac{dy}{dx}=60y^{\dfrac{2}{5}}$ ,$x\gt 0$ ,$y(0)=0$ has 1.a unique solution. 2.two solutions. 3.no solution. 4.infinite number of solutions. Here f(x,y)=$60y^{\dfrac{2}{5}}$ does not satisfy Lipschitz's condition, so I can't give any conclusion about the uniqueness of the solution. how can I get all possible solutions?",,['ordinary-differential-equations']
42,Periodic solutions of this systems,Periodic solutions of this systems,,"I need to prove that the system of differential equations $$ \dot x  = y  \\  \dot y  = 1+x^2-(1-x)y $$  doesn't contain periodic solutions. I know the Bendixon criteria (that is to have div no sign changing), but, the divergence of this system is $x-1$, and I can´t sure that this will never change the sign (at $x=1$ there will be a change). How can I do that?","I need to prove that the system of differential equations $$ \dot x  = y  \\  \dot y  = 1+x^2-(1-x)y $$  doesn't contain periodic solutions. I know the Bendixon criteria (that is to have div no sign changing), but, the divergence of this system is $x-1$, and I can´t sure that this will never change the sign (at $x=1$ there will be a change). How can I do that?",,"['analysis', 'ordinary-differential-equations', 'systems-of-equations']"
43,How do we find $u(x)$?,How do we find ?,u(x),"I want to know how to find $u(x)$ in the below question: $$u''(x)+{e^u}^{(x)} = 0\\ x \in[0,1]\\u(0) = u(1) = 0$$ Please explain briefly how this was done?? Thanks!!","I want to know how to find $u(x)$ in the below question: $$u''(x)+{e^u}^{(x)} = 0\\ x \in[0,1]\\u(0) = u(1) = 0$$ Please explain briefly how this was done?? Thanks!!",,"['integration', 'ordinary-differential-equations']"
44,Writing solution to an arbitrary ODE with arbitrary initial values as the sum of a power series?,Writing solution to an arbitrary ODE with arbitrary initial values as the sum of a power series?,,How can we solve for $y$ with these arbitrary initial values and polynomials? How would we write the solution as a power series?,How can we solve for $y$ with these arbitrary initial values and polynomials? How would we write the solution as a power series?,,"['calculus', 'ordinary-differential-equations', 'polynomials', 'convergence-divergence', 'power-series']"
45,Solving a non linear second order differential equation [closed],Solving a non linear second order differential equation [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How do I go about solving a nonlinear ordinary equation that is of second order? Such as  $$y'' + ay^3 = 0$$  where $a$ is a constant.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How do I go about solving a nonlinear ordinary equation that is of second order? Such as  $$y'' + ay^3 = 0$$  where $a$ is a constant.",,['ordinary-differential-equations']
46,Repairing solutions in ODE,Repairing solutions in ODE,,"Recently I encounter something interesting that I hope to hear from your opinions: Suppose we are given a ODE $\frac{dy}{dx}=y$, with no initial condition. Naively, we divide both sides by $y$ and use the separation of variables. (This is a very typical mistake that many high school students will commit, I myself did commit such an error back then :P) We will get a general solution: $y=A\exp(x)$. We can plot the trajectories out by varying the value of $A$. If the initial condition is to be $y(0)=0$, then again, naively we substitute into the $y=A\exp(x)$, hence yielding $A=0$, which means $y$ is identically equals to $0$. I know the naive steps involved are incorrect, especially the one that involves division by $y$ throughout. But at the end of the day, the general solution seems to have the ability of ""repairing"" this mistake by allowing $A=0$. However, when the ODE changes to the following: $\frac{dy}{dx}=y(y-1)$. Then I encounter difficulty in ""repairing"" the solution. According to my working, the general solution is $y=\frac{1}{1-A\exp(x)}$. I can ""repair"" the mistake made for initial condition $y(0)=1$ by setting $A=0$, but I cannot ""repair"" the result for the initial condition $y(0)=0$. I have a hunch that these might be related to the attracting/repelling orbits/trajectories. From the plotting of the trajectories for these two questions, I notice that those trajectories that I can ""repair"" the solution are repelling trajectories. Perhaps I am thinking too much. Thank you for your suggestion.","Recently I encounter something interesting that I hope to hear from your opinions: Suppose we are given a ODE $\frac{dy}{dx}=y$, with no initial condition. Naively, we divide both sides by $y$ and use the separation of variables. (This is a very typical mistake that many high school students will commit, I myself did commit such an error back then :P) We will get a general solution: $y=A\exp(x)$. We can plot the trajectories out by varying the value of $A$. If the initial condition is to be $y(0)=0$, then again, naively we substitute into the $y=A\exp(x)$, hence yielding $A=0$, which means $y$ is identically equals to $0$. I know the naive steps involved are incorrect, especially the one that involves division by $y$ throughout. But at the end of the day, the general solution seems to have the ability of ""repairing"" this mistake by allowing $A=0$. However, when the ODE changes to the following: $\frac{dy}{dx}=y(y-1)$. Then I encounter difficulty in ""repairing"" the solution. According to my working, the general solution is $y=\frac{1}{1-A\exp(x)}$. I can ""repair"" the mistake made for initial condition $y(0)=1$ by setting $A=0$, but I cannot ""repair"" the result for the initial condition $y(0)=0$. I have a hunch that these might be related to the attracting/repelling orbits/trajectories. From the plotting of the trajectories for these two questions, I notice that those trajectories that I can ""repair"" the solution are repelling trajectories. Perhaps I am thinking too much. Thank you for your suggestion.",,"['ordinary-differential-equations', 'dynamical-systems']"
47,Finding function $f(x)$,Finding function,f(x),How do we find the function(s) $f(x)$ given that $$f(x)=\int_{0}^{x} te^tf(x-t) \ \mathrm{d}t$$ My Try : I first used the property $\int_{0}^{a}g(x) \ \mathrm{d}x=\int_{0}^{a}g(a-x) \ \mathrm{d}x$ and then differentiated to find that $$f'(x)=f(x)-e^x\int_{0}^{x}e^{-t}f(t) \ \mathrm{d}t$$ Then I differentiated again to find that $$f''(x)=2f'(x)-2f(x)$$ I entered this differential equation into wolfram alpha and it returned $f(x)=c_1e^x\sin x+c_2e^x\cos x$ But I don't think that this satisfies the given initial condition. Please help me out. Hints or answers appreciated. Thank you.,How do we find the function(s) $f(x)$ given that $$f(x)=\int_{0}^{x} te^tf(x-t) \ \mathrm{d}t$$ My Try : I first used the property $\int_{0}^{a}g(x) \ \mathrm{d}x=\int_{0}^{a}g(a-x) \ \mathrm{d}x$ and then differentiated to find that $$f'(x)=f(x)-e^x\int_{0}^{x}e^{-t}f(t) \ \mathrm{d}t$$ Then I differentiated again to find that $$f''(x)=2f'(x)-2f(x)$$ I entered this differential equation into wolfram alpha and it returned $f(x)=c_1e^x\sin x+c_2e^x\cos x$ But I don't think that this satisfies the given initial condition. Please help me out. Hints or answers appreciated. Thank you.,,"['ordinary-differential-equations', 'integral-equations']"
48,Need Help setting up a unusual related rates problem (Calc AB),Need Help setting up a unusual related rates problem (Calc AB),,"Currently I am doing a project in my calculus class where we create a related rate problem relating to 2 ideas pulled out of a hat and solve it(mine was a student(s) bored in class and souls). Being a kind of weird combination, the problem I came up with is: A student is sitting in one of the most boring classes in history. The class is so boring, that causes the students soul to be sucked out of his body. Every minute, the student loses 4 soul pieces per boredom level. Starting at a level of 0 boredom, the student becomes more and more bored at a rate of 5 boredom levels per minute. If the student's soul is made of 1000 soul pieces, what rate is the student loosing his soul when he has 700 soul pieces remaining? Originally, I thought I could simply solve this problem using a Pythagorean theorem setup where one side would the total souls, one side would be the boredom [the prime being the rate of it increasing], and my hypotenuse being the lost souls [the prime being the rate of it being lost]. When I started doing the work itself, I got stuck because there was no way to find my base value of the boredom side. My teacher told me that I had to change something in my problem and not use a Pythagorean theorem setup (Because there was no way of proving it was a triangle problem in the first place). Any ideas on what I should change in my problem and what type of problem it would be (shadow, volume, expanding area, etc)? I think I would have to treat this problem just like a velocity problem.","Currently I am doing a project in my calculus class where we create a related rate problem relating to 2 ideas pulled out of a hat and solve it(mine was a student(s) bored in class and souls). Being a kind of weird combination, the problem I came up with is: A student is sitting in one of the most boring classes in history. The class is so boring, that causes the students soul to be sucked out of his body. Every minute, the student loses 4 soul pieces per boredom level. Starting at a level of 0 boredom, the student becomes more and more bored at a rate of 5 boredom levels per minute. If the student's soul is made of 1000 soul pieces, what rate is the student loosing his soul when he has 700 soul pieces remaining? Originally, I thought I could simply solve this problem using a Pythagorean theorem setup where one side would the total souls, one side would be the boredom [the prime being the rate of it increasing], and my hypotenuse being the lost souls [the prime being the rate of it being lost]. When I started doing the work itself, I got stuck because there was no way to find my base value of the boredom side. My teacher told me that I had to change something in my problem and not use a Pythagorean theorem setup (Because there was no way of proving it was a triangle problem in the first place). Any ideas on what I should change in my problem and what type of problem it would be (shadow, volume, expanding area, etc)? I think I would have to treat this problem just like a velocity problem.",,"['calculus', 'ordinary-differential-equations']"
49,Simple Example of Method of Characteristics,Simple Example of Method of Characteristics,,"To find the general solution of an equation such as $u_{x} - yu_{y} = 0$, it is clear by the method of characteristics that the characteristic curves satisfy $dx = -\frac{dy}{y}$ and so we get the relation that $u$ depends only on the constant $k = ye^{x}$ on these curves. It seems to me that it is more useful (for nonhomogeneous problems) to approach this by parametrizing the curve with respect to a new variable. I want to get comfortable with such an approach, but I'm not sure how to proceed. Here is what I tried: By parametrizing the curve with respect to a new variable $t$, I want to solve this problem through the system of equations: \begin{cases} \frac{dx}{dt} = 1 \\ \frac{dy}{dt} = -y \\ \frac{dz}{dt} = 0 \end{cases} giving me a curve $(x(t), y(t), z(t))$ with $x(t) = t + c_{1}$, $y(t) = c_{2}e^{-t}$, and $z(t) = c_{3}$ for some constants. By redefining new constants, I can identify $x$ with $t$ and substitute it into the expression for $y(t)$. At this point, I'm wondering what I do next to infer that $u$ is constant on these curves and depends only on the constant $k = ye^{x}$?","To find the general solution of an equation such as $u_{x} - yu_{y} = 0$, it is clear by the method of characteristics that the characteristic curves satisfy $dx = -\frac{dy}{y}$ and so we get the relation that $u$ depends only on the constant $k = ye^{x}$ on these curves. It seems to me that it is more useful (for nonhomogeneous problems) to approach this by parametrizing the curve with respect to a new variable. I want to get comfortable with such an approach, but I'm not sure how to proceed. Here is what I tried: By parametrizing the curve with respect to a new variable $t$, I want to solve this problem through the system of equations: \begin{cases} \frac{dx}{dt} = 1 \\ \frac{dy}{dt} = -y \\ \frac{dz}{dt} = 0 \end{cases} giving me a curve $(x(t), y(t), z(t))$ with $x(t) = t + c_{1}$, $y(t) = c_{2}e^{-t}$, and $z(t) = c_{3}$ for some constants. By redefining new constants, I can identify $x$ with $t$ and substitute it into the expression for $y(t)$. At this point, I'm wondering what I do next to infer that $u$ is constant on these curves and depends only on the constant $k = ye^{x}$?",,"['ordinary-differential-equations', 'partial-differential-equations']"
50,General form for finding tangent that intersects a point not on the curve,General form for finding tangent that intersects a point not on the curve,,"Particular cases of this problem have previously been addressed here and here , but I'm interested in the general case of the following problem: Given a function $f(x)$ and a point $P = (x_0, y_0)$, find all tangents to $f(x)$ that pass through $P$. I tried to work on this on my own, and using point-slope form of lines I found: $$f(x) - y_0 = f'(x)(x - x_0)$$ Replacing $f(x)$ with $y$ and $f'(x)$ with $y'$: $$y - y_0 = y' (x - x_0)$$ $$y' = \frac{y - y_0}{x - x_0}$$ Trying to get it into the friendly form of a first-order linear differential equation: $$y' - \frac{y}{x - x_0} = -\frac{y_0}{x - x_0}$$ $$y' + \frac{y}{x_0 - x} = \frac{y_0}{x_0 - x}$$ But when I worked this out, I found $y = y_0$, which doesn't seem right, but my differential equation skills are admittedly very rusty. How do I find the tangents through $P$? What properties of $f(x)$ and $P$ make a solution unique or nonexistent? Where could I learn more about this problem?","Particular cases of this problem have previously been addressed here and here , but I'm interested in the general case of the following problem: Given a function $f(x)$ and a point $P = (x_0, y_0)$, find all tangents to $f(x)$ that pass through $P$. I tried to work on this on my own, and using point-slope form of lines I found: $$f(x) - y_0 = f'(x)(x - x_0)$$ Replacing $f(x)$ with $y$ and $f'(x)$ with $y'$: $$y - y_0 = y' (x - x_0)$$ $$y' = \frac{y - y_0}{x - x_0}$$ Trying to get it into the friendly form of a first-order linear differential equation: $$y' - \frac{y}{x - x_0} = -\frac{y_0}{x - x_0}$$ $$y' + \frac{y}{x_0 - x} = \frac{y_0}{x_0 - x}$$ But when I worked this out, I found $y = y_0$, which doesn't seem right, but my differential equation skills are admittedly very rusty. How do I find the tangents through $P$? What properties of $f(x)$ and $P$ make a solution unique or nonexistent? Where could I learn more about this problem?",,"['calculus', 'ordinary-differential-equations']"
51,Solving Nonlinear second order ODE,Solving Nonlinear second order ODE,,"I want to know how to solve this nonlinear second order ODE. This example is based on the option pricing under the CEV model. $$ \frac{1}{2}\sigma^2(x)u''(x)+\mu u'(x)-Cu(x)=-g(x) $$ where $\mu, C$ are constant, $g(x)=max(x-K,0)/\lambda$. How to get solutions of above pde???","I want to know how to solve this nonlinear second order ODE. This example is based on the option pricing under the CEV model. $$ \frac{1}{2}\sigma^2(x)u''(x)+\mu u'(x)-Cu(x)=-g(x) $$ where $\mu, C$ are constant, $g(x)=max(x-K,0)/\lambda$. How to get solutions of above pde???",,"['calculus', 'ordinary-differential-equations']"
52,Second order equation. [closed],Second order equation. [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question (i)Show that the ODE $$y''+[b'(x)/b(x)]y'-[a^2/b^2(x)] y=0$$ has a pair of linearly independant solutions that are reciprocals, where $a$ is a constant and $b(x)$ is a function of x. Find them in terms of $a$ and $b(x)$. (ii)If the ODE $$y''+p(x)y'+2y=0$$ has solutions $y$ and $y^2$, find $y$ and find $p(x)$. Find both the possibilities.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question (i)Show that the ODE $$y''+[b'(x)/b(x)]y'-[a^2/b^2(x)] y=0$$ has a pair of linearly independant solutions that are reciprocals, where $a$ is a constant and $b(x)$ is a function of x. Find them in terms of $a$ and $b(x)$. (ii)If the ODE $$y''+p(x)y'+2y=0$$ has solutions $y$ and $y^2$, find $y$ and find $p(x)$. Find both the possibilities.",,['ordinary-differential-equations']
53,Differential Equation Word Problem involving y=Ce^(xk) (y=y'),Differential Equation Word Problem involving y=Ce^(xk) (y=y'),,"""The rate of change of y is proportional to y. Write and solve the differential equation that models the verbal statement."" This part of the problem is easy. My work is such: $y'=ky$ $\frac{dy}{dx} = ky$ $dy = ky dx$ $\frac{dy}{y} = k dx$ Then by integrating, I get: $y = e^{kx + c}$, where $c$ is some constant Which can also be written as: $y = e^{kx} e^c$ $y = ce^{kx}$ The next part is rather confusing though: ""Use this statement to find the value of y when x=10, if it satisfies when x=0, y=2, and when x=4, y=8"" How can you find a particular solution of this differential equation when you are missing information about c, k, and y? If it helps, I just started Calculus 2. Thank you for your time in advance.","""The rate of change of y is proportional to y. Write and solve the differential equation that models the verbal statement."" This part of the problem is easy. My work is such: $y'=ky$ $\frac{dy}{dx} = ky$ $dy = ky dx$ $\frac{dy}{y} = k dx$ Then by integrating, I get: $y = e^{kx + c}$, where $c$ is some constant Which can also be written as: $y = e^{kx} e^c$ $y = ce^{kx}$ The next part is rather confusing though: ""Use this statement to find the value of y when x=10, if it satisfies when x=0, y=2, and when x=4, y=8"" How can you find a particular solution of this differential equation when you are missing information about c, k, and y? If it helps, I just started Calculus 2. Thank you for your time in advance.",,"['calculus', 'ordinary-differential-equations', 'differential']"
54,Uniqueness of solution to linear first-order ODE with singular points,Uniqueness of solution to linear first-order ODE with singular points,,"I want to solve a linear first-order ODE for $y(x)$, $x\in[0,1]$, $$ \gamma(x)y'-ay=-a\gamma(x),\quad y(0)=0, $$ where $\gamma(x)$ is a known function with $\gamma(0)=0$, and $a>0$ is a known constant. Because $\gamma(0)=0$ makes $x=0$ a singular point, does this ODE have unique solution if additional condition $y'(0)=1$ is given? If yes, how to prove it (or is there any existing theorem showing this)? Some background of my question: $F(x)$ and $f(x)$ are the distribution function and density function of random variable $X$ on support $[0,1]$. Let $y(x)=F(x)/f(x)$ and function $\gamma(x)=\frac{y(x)}{1+y'(x)/a}$ is known. I want to get the distribution of $X$ by figuring out function $y(x)$.","I want to solve a linear first-order ODE for $y(x)$, $x\in[0,1]$, $$ \gamma(x)y'-ay=-a\gamma(x),\quad y(0)=0, $$ where $\gamma(x)$ is a known function with $\gamma(0)=0$, and $a>0$ is a known constant. Because $\gamma(0)=0$ makes $x=0$ a singular point, does this ODE have unique solution if additional condition $y'(0)=1$ is given? If yes, how to prove it (or is there any existing theorem showing this)? Some background of my question: $F(x)$ and $f(x)$ are the distribution function and density function of random variable $X$ on support $[0,1]$. Let $y(x)=F(x)/f(x)$ and function $\gamma(x)=\frac{y(x)}{1+y'(x)/a}$ is known. I want to get the distribution of $X$ by figuring out function $y(x)$.",,['ordinary-differential-equations']
55,"nonlinear, nonhomogeneous ODE 1. order","nonlinear, nonhomogeneous ODE 1. order",,"Solve $x'(t)-\dfrac{a}{t}x(t)=b(t),~a=const,~x(0)=0$. Homogeneous Solution: $\dfrac{x'(t)}{x(t)}=\dfrac{a}{t}\quad|\int\\ \ln(x(t))=a\ln(t)+c,~c=const\quad| e\\ x(t)=t^ae^c$ Is that correct? No clue how to figure the particular solution or the general solution respectively. edit: Thanks  @agha for the helpfull comment. I try to write down the entire solution. With a slighty different Noation. Let $t\in[0,t_f]$ $$(1)~ x'(t) - \dfrac{a}{t}x(t) = b(t)$$ $$(2)~ x_h(t) = Kt^a$$ Particular Solution: $$x_s(t) = c(t)t^a~\text{with}~ x'(t) = c'(t)t^a + c(t)at^{a-1}$$ Substitute in (1) $$c'(t)t^a + c(t)at^{a-1} - \dfrac{a}{t}c(t)t^a = b(t)$$ $$c'(t) = \dfrac{b(t)}{t^a}\quad |\int{}$$ $$c(t) = \int{\dfrac{b(t)}{t^a}dt} + K'$$ It follows for $x_s(t)$ $$(3)~ x_s(t) = \left(\int{\dfrac{b(t)}{t^a}dt} + K'\right)t^a$$ The general solution reads (2)+(3), i.e. $$(4)~ x(t) = Kt^a + \left(\int{\dfrac{b(t)}{t^a}dt} + K'\right)t^a = \left(\int{\dfrac{b(t)}{t^a}dt} + K''\right)t^a\\ \text{where}~ K''=K+K'$$ With the initial conditon $x(0)=0$ we might identify $K''$  $$(5)~ x(0) = 0 = \int{\dfrac{b(t)}{t^a}dt}\bigg|_{t_f} + K''\\ K'' = -\int{\dfrac{b(t)}{t^a}dt}\bigg|_{t_f}$$ Thus the solution reads: $$(6)~x(t) = \left(\int{\dfrac{b(t)}{t^a}dt} - \int{\dfrac{b(t)}{t^a}dt}\bigg|_{t_f}\right)t^a$$ Am I right?","Solve $x'(t)-\dfrac{a}{t}x(t)=b(t),~a=const,~x(0)=0$. Homogeneous Solution: $\dfrac{x'(t)}{x(t)}=\dfrac{a}{t}\quad|\int\\ \ln(x(t))=a\ln(t)+c,~c=const\quad| e\\ x(t)=t^ae^c$ Is that correct? No clue how to figure the particular solution or the general solution respectively. edit: Thanks  @agha for the helpfull comment. I try to write down the entire solution. With a slighty different Noation. Let $t\in[0,t_f]$ $$(1)~ x'(t) - \dfrac{a}{t}x(t) = b(t)$$ $$(2)~ x_h(t) = Kt^a$$ Particular Solution: $$x_s(t) = c(t)t^a~\text{with}~ x'(t) = c'(t)t^a + c(t)at^{a-1}$$ Substitute in (1) $$c'(t)t^a + c(t)at^{a-1} - \dfrac{a}{t}c(t)t^a = b(t)$$ $$c'(t) = \dfrac{b(t)}{t^a}\quad |\int{}$$ $$c(t) = \int{\dfrac{b(t)}{t^a}dt} + K'$$ It follows for $x_s(t)$ $$(3)~ x_s(t) = \left(\int{\dfrac{b(t)}{t^a}dt} + K'\right)t^a$$ The general solution reads (2)+(3), i.e. $$(4)~ x(t) = Kt^a + \left(\int{\dfrac{b(t)}{t^a}dt} + K'\right)t^a = \left(\int{\dfrac{b(t)}{t^a}dt} + K''\right)t^a\\ \text{where}~ K''=K+K'$$ With the initial conditon $x(0)=0$ we might identify $K''$  $$(5)~ x(0) = 0 = \int{\dfrac{b(t)}{t^a}dt}\bigg|_{t_f} + K''\\ K'' = -\int{\dfrac{b(t)}{t^a}dt}\bigg|_{t_f}$$ Thus the solution reads: $$(6)~x(t) = \left(\int{\dfrac{b(t)}{t^a}dt} - \int{\dfrac{b(t)}{t^a}dt}\bigg|_{t_f}\right)t^a$$ Am I right?",,['ordinary-differential-equations']
56,How many solutions does the ODE $u'=\frac{4tu}{u^2+t^2}$ have?,How many solutions does the ODE  have?,u'=\frac{4tu}{u^2+t^2},"Given the problem: $$ \left\{ \begin{aligned} u^\prime(t) & = \frac{4 t u(t)}{u^2(t)+t^2}  &&\text{ for } t\in(0,a)\\ u(0) & = 0  &&\text{ for } t=0 \end{aligned} \right. $$ Now I need to show that this ODE has infinitely many solutions. However, I cannot find any non-trivial. Has anyone a hint how to get a right solution.","Given the problem: $$ \left\{ \begin{aligned} u^\prime(t) & = \frac{4 t u(t)}{u^2(t)+t^2}  &&\text{ for } t\in(0,a)\\ u(0) & = 0  &&\text{ for } t=0 \end{aligned} \right. $$ Now I need to show that this ODE has infinitely many solutions. However, I cannot find any non-trivial. Has anyone a hint how to get a right solution.",,['ordinary-differential-equations']
57,Why does the substitution $y=vx^m$ solve an Isobaric ODE?,Why does the substitution  solve an Isobaric ODE?,y=vx^m,"I'd like to know how the substitution $y=vx^m$ makes the equation $\dfrac{\mathrm{d}y}{\mathrm{d}x}=\dfrac{A(x,y)}{B(x,y)}$ separable. I am aware that the equation $f(x,y)$ is called isobaric if $f(tx, t^m y)=t^{m-1}f(x,y)$ for some value of $m$.","I'd like to know how the substitution $y=vx^m$ makes the equation $\dfrac{\mathrm{d}y}{\mathrm{d}x}=\dfrac{A(x,y)}{B(x,y)}$ separable. I am aware that the equation $f(x,y)$ is called isobaric if $f(tx, t^m y)=t^{m-1}f(x,y)$ for some value of $m$.",,['ordinary-differential-equations']
58,Integrable combinations - I can't seem to arrive at the given answer,Integrable combinations - I can't seem to arrive at the given answer,,"I need help! I can't seem to arrive at the answer given in our textbook. I'm new here, so I really need help. The instruction says that I need to solve this D.E by recognizing integrable combinations. $$ y(x^4 e^{xy} - y^2) \, dx + x(x^4e^{xy} + y^2) \, dy = 0  $$ when $x = 1$, $y = 0$. And I can't seem to arrive this answer: $$ y^2 = x^2(1 - e^{xy}) $$ Here is my sol'n:","I need help! I can't seem to arrive at the answer given in our textbook. I'm new here, so I really need help. The instruction says that I need to solve this D.E by recognizing integrable combinations. $$ y(x^4 e^{xy} - y^2) \, dx + x(x^4e^{xy} + y^2) \, dy = 0  $$ when $x = 1$, $y = 0$. And I can't seem to arrive this answer: $$ y^2 = x^2(1 - e^{xy}) $$ Here is my sol'n:",,"['calculus', 'integration', 'ordinary-differential-equations', 'derivatives']"
59,Showing $y_1$ or $y_2$ are not polynomials,Showing  or  are not polynomials,y_1 y_2,proof that $y_1$ or $y_2$ are not a polynomial for any $n$ $$ y_1(x)=1-\frac{n(n+1)}{2!}x^2+\frac{(n-2)n(n+1)(n+3)}{4!}x^4-+\cdots$$ $$ y_2(x)=x-\frac{(n-1)(n+2)}{3!}x^3+\frac{(n-3)(n-1)(n+2)(n+4)}{5!}x^5-+\cdots$$ also can be seen as $$ y_1(x)=1+\sum_{s=1}^{\infty}(-1)^s \frac{n(n-2)\cdots(n-2s+2)\cdot(n+1)(n+3)\cdots(n+2s-1)}{(2s)!}x^{2s}$$ $$ y_2(x)=x+\sum_{s=1}^{\infty}(-1)^s \frac{(n-1)(n-3)\cdots(n-2s+1)\cdot(n+2)(n+3)\cdots(n+2s)}{(2s+1)!}x^{2s+1}$$ the linear combination of $y_1$ and $y_2$ are solution of the legendre equation. I've been unable to demonstrate this,proof that $y_1$ or $y_2$ are not a polynomial for any $n$ $$ y_1(x)=1-\frac{n(n+1)}{2!}x^2+\frac{(n-2)n(n+1)(n+3)}{4!}x^4-+\cdots$$ $$ y_2(x)=x-\frac{(n-1)(n+2)}{3!}x^3+\frac{(n-3)(n-1)(n+2)(n+4)}{5!}x^5-+\cdots$$ also can be seen as $$ y_1(x)=1+\sum_{s=1}^{\infty}(-1)^s \frac{n(n-2)\cdots(n-2s+2)\cdot(n+1)(n+3)\cdots(n+2s-1)}{(2s)!}x^{2s}$$ $$ y_2(x)=x+\sum_{s=1}^{\infty}(-1)^s \frac{(n-1)(n-3)\cdots(n-2s+1)\cdot(n+2)(n+3)\cdots(n+2s)}{(2s+1)!}x^{2s+1}$$ the linear combination of $y_1$ and $y_2$ are solution of the legendre equation. I've been unable to demonstrate this,,"['linear-algebra', 'ordinary-differential-equations', 'power-series', 'legendre-polynomials']"
60,Symbolic solution to a nonlinear ordinary differential equation problem,Symbolic solution to a nonlinear ordinary differential equation problem,,"Suppose $y=y(x)$ is infinite continuous in $\mathbb{R}$, and $y(-1)=0$, how can we obtain the analytic solution in closed form to the following nonlinear ordinary differential equation: $$ \left((x-10)^2+y^2\right)\left(x^2+y^2y'^2+2xyy'+2yy'+2x+1\right)=\left(x^2+y^2\right)\left(x^2+y^2y'^2+2 x y y'-20y y'-20x+100\right) $$ The resulted solution should be in implicit form.  Is there any general approach in solving such kind of ODE's? Update: What I am asking is actually: is it possible to establish ellipse equation from only one of its properties as shown in the figure below. The light rays from one fixed point $F_1$ being reflected by the curve always focus on another fixed point $F_2$ and vice versa. Suppose we don't know the curve is ellipse, then is it possible for us to obtain ellipse formulation only from the above relationship when being given $F_1$, $F_2$ and a point $A$ or $B$ on the curve? I think the key now becomes how to establish the nonlinear ordinary equations or nonlinear systems to solve in polarized coordinate frame or just Descartes' frame. What should I do?","Suppose $y=y(x)$ is infinite continuous in $\mathbb{R}$, and $y(-1)=0$, how can we obtain the analytic solution in closed form to the following nonlinear ordinary differential equation: $$ \left((x-10)^2+y^2\right)\left(x^2+y^2y'^2+2xyy'+2yy'+2x+1\right)=\left(x^2+y^2\right)\left(x^2+y^2y'^2+2 x y y'-20y y'-20x+100\right) $$ The resulted solution should be in implicit form.  Is there any general approach in solving such kind of ODE's? Update: What I am asking is actually: is it possible to establish ellipse equation from only one of its properties as shown in the figure below. The light rays from one fixed point $F_1$ being reflected by the curve always focus on another fixed point $F_2$ and vice versa. Suppose we don't know the curve is ellipse, then is it possible for us to obtain ellipse formulation only from the above relationship when being given $F_1$, $F_2$ and a point $A$ or $B$ on the curve? I think the key now becomes how to establish the nonlinear ordinary equations or nonlinear systems to solve in polarized coordinate frame or just Descartes' frame. What should I do?",,"['ordinary-differential-equations', 'symbolic-computation']"
61,Solve a non-homogeneous ODE when the right-hand side is a solution to the homogeneous ODE?,Solve a non-homogeneous ODE when the right-hand side is a solution to the homogeneous ODE?,,"Assume I have a second-degree ordinary differential equation $$ u_1(x) f + u_2(x) f' + u_3(x) f'' = g(x), $$ where $g$ solves the corresponding homogeneous equation, i.e. $$ u_1(x) g + u_2(x) g' + u_3(x) g'' = 0. $$ Is there a way to solve for $f$? Is there a solution at all? The specific question (in case there is no general solution): I need to solve  $$ (\lambda+r)f - rxf' - \frac{\sigma^2}{2}x^2 f'' = x^{\alpha-\beta}, $$ for $\lambda, r, \sigma > 0$, where $\alpha$ and $\beta$ have been chosen such that $x^{\alpha-\beta}$ is a solution to the homogeneous ODE, i.e. $$ x^{\alpha-\beta} \left(\lambda+r - r(\alpha-\beta) - \frac{\sigma^2}{2}(\alpha-\beta)(\alpha-\beta-1)\right) = 0. $$ I have tried to plug in on the right-hand side and have also looked at the variable-coefficients method, but that did not work out. Solution: The reduction-of-order approach worked very well. Thanks for your comments!","Assume I have a second-degree ordinary differential equation $$ u_1(x) f + u_2(x) f' + u_3(x) f'' = g(x), $$ where $g$ solves the corresponding homogeneous equation, i.e. $$ u_1(x) g + u_2(x) g' + u_3(x) g'' = 0. $$ Is there a way to solve for $f$? Is there a solution at all? The specific question (in case there is no general solution): I need to solve  $$ (\lambda+r)f - rxf' - \frac{\sigma^2}{2}x^2 f'' = x^{\alpha-\beta}, $$ for $\lambda, r, \sigma > 0$, where $\alpha$ and $\beta$ have been chosen such that $x^{\alpha-\beta}$ is a solution to the homogeneous ODE, i.e. $$ x^{\alpha-\beta} \left(\lambda+r - r(\alpha-\beta) - \frac{\sigma^2}{2}(\alpha-\beta)(\alpha-\beta-1)\right) = 0. $$ I have tried to plug in on the right-hand side and have also looked at the variable-coefficients method, but that did not work out. Solution: The reduction-of-order approach worked very well. Thanks for your comments!",,['ordinary-differential-equations']
62,Solving some inhomogeneous differential equations,Solving some inhomogeneous differential equations,,"I am currently reviewing some differential equations and ran into a couple of problems with the problems shown below particularly in the form of the particular solution for the equations. I haven't done this stuff in a couple years so I am pretty rusty. $u""-u'=6 +e^{2t}$ This one is giving me issues because the guess for the particular solution $(a + b e^{2t})$ loses the constant coefficient in the derivatives, and multiplying by $t$ (in case the homogeneous solution matches the particular form guess, which in this case it doesn't) , doesn't seem to work either. $u'+ u = 4e^{-t}$ This equation does have a matching particular/homogeneous solution, but when we multiply by $t$ for another unique solution it yields no positive results. Let me know what you think. Thanks","I am currently reviewing some differential equations and ran into a couple of problems with the problems shown below particularly in the form of the particular solution for the equations. I haven't done this stuff in a couple years so I am pretty rusty. $u""-u'=6 +e^{2t}$ This one is giving me issues because the guess for the particular solution $(a + b e^{2t})$ loses the constant coefficient in the derivatives, and multiplying by $t$ (in case the homogeneous solution matches the particular form guess, which in this case it doesn't) , doesn't seem to work either. $u'+ u = 4e^{-t}$ This equation does have a matching particular/homogeneous solution, but when we multiply by $t$ for another unique solution it yields no positive results. Let me know what you think. Thanks",,"['calculus', 'ordinary-differential-equations']"
63,Insightful books on differential equations?,Insightful books on differential equations?,,"What are some recommendations for insightful books on differential equations and difference equations? These books don't need to be in the format of a textbook, and don't need to provide the same topics as a textbook on ODEs might. After reading such a book, one should be somewhat in awe of the subject. They shouldn't be pop-science-y however. See this question for inspiration on what answers should look like .","What are some recommendations for insightful books on differential equations and difference equations? These books don't need to be in the format of a textbook, and don't need to provide the same topics as a textbook on ODEs might. After reading such a book, one should be somewhat in awe of the subject. They shouldn't be pop-science-y however. See this question for inspiration on what answers should look like .",,"['ordinary-differential-equations', 'reference-request', 'book-recommendation']"
64,Finite Difference Discretization of Darcy's law and solving with Picard method,Finite Difference Discretization of Darcy's law and solving with Picard method,,"I am trying to discretize Darcy's Law using finite differences and then solving the resulting linear system of equations with the Picard method. So far only in 1D and the steady-state (no time derivatives). Darcy's law reads: $$C(h)\frac{\partial h}{\partial t} = \nabla\cdot\left(K(h)\nabla h\right) + \frac{\partial K(h)}{\partial z}$$ the left hand side is zero, since I am (so far) only interested in the steady state. Using finite differences with $K$ and $h$ values located at the cell centers, I get: $$0=\frac{K_{i+1/2}\left(\frac{h_{i+1}-h_{i}}{dz}\right)-K_{i-1/2}\left(\frac{h_{i}-h_{i-1}}{dz}\right)}{dz} + \frac{K_{i+1}-K_{i-1}}{2dz}$$ now I replace $K_{i+1/2}$ and $K_{i-1/2}$ by interpolation terms: $$0=\frac{\frac{K_{i}+K_{i+1}}{2}\left(\frac{h_{i+1}-h_{i}}{dz}\right)-\frac{K_{i}+K_{i-1}}{2}\left(\frac{h_{i}-h_{i-1}}{dz}\right)}{dz} + \frac{K_{i+1}-K_{i-1}}{2dz}$$ and simplify it to: $$0=\frac{1}{2dz^2}\left[h_{i-1}\left(K_{i-1}+K_i\right)-h_i\left(K_{i-1}+K_i+K_{i+1}\right)+h_{i+1}\left(K_i+K_{i+1}\right)+K_{i+1}dz-K_{i-1}dz\right]$$ I believe that until here things are okay, correct me if I'm wrong. Now I transform the above equation into a linear system of equations. At the top (between $h_N$ and $h_{N+1}$) there are Dirichlet boundary conditions with $h_{N+1/2}=h_B$ and at the bottom (between $h_0$ and $h_1$) there are neumann boundary conditions $\nabla h_{1/2}=0$: $$\frac{1}{2dz^2} \begin{bmatrix}   -1       & 1       & 0       & 0      & \dots  & 0       & 0       & 0       & 0       \\   c_{i-1} & c_i     & c_{i+1} & 0       & \dots  & 0       & 0       & 0       & 0       \\   0       & c_{i-1} & c_i     & c_{i+1} & \ddots & 0       & 0       & 0       & 0       \\   0       & 0       & c_{i-1} & c_i     & \ddots & 0       & 0       & 0       & 0       \\   \vdots  & \vdots  & \ddots  & \ddots  & \ddots & \ddots  & \ddots  & \vdots  & \vdots  \\   0       & 0       & 0       & 0       & \ddots & c_i     & c_{i+1} & 0       & 0       \\   0       & 0       & 0       & 0       & \ddots & c_{i-1} & c_i     & c_{i+1} & 0       \\   0       & 0       & 0       & 0       & \dots  & 0       & c_{i-1} & c_i     & c_{i+1} \\   0       & 0       & 0       & 0       & \dots  & 0       & 0       & 1       & 1       \\ \end{bmatrix} \begin{bmatrix}   h_0\\   h_1\\   h_2\\   h_3\\   \vdots\\   h_{N-2}\\   h_{N-1}\\   h_{N}\\   h_{N+1} \end{bmatrix} +\frac{1}{2dz} \begin{bmatrix}   0\\   K_2-K_0\\   K_3-K_1\\   K_4-K_2\\   \vdots\\   K_{N-2}-K_{N-4}\\   K_{N-1}-K_{N-3}\\   K_{N}-K_{N-2}\\   0 \end{bmatrix} = \begin{bmatrix}   0\\   0\\   0\\   0\\   \vdots\\   0\\   0\\   0\\   h_Bdz^2 \end{bmatrix} $$ with $c_i = -K_{i-1}-K_i-K_{i+1}$, $c_{i+1}=K_i+K_{i+1}$ and $c_{i-1} = K_{i-1}+K_i$. $h_N$ referes to top most cell and $h_0$ to bottom most cell. The boundary of the domain is located between $h_0$ and $h_1$ and $h_N$ and $h_{N+1}$. This is there I'm not so sure anymore. Did I get the matrix right? And then how to get from here to solving it using the Picard method, which as far as I understand is only good for first-order ODEs and not second-order as Darcy's Eq. is.","I am trying to discretize Darcy's Law using finite differences and then solving the resulting linear system of equations with the Picard method. So far only in 1D and the steady-state (no time derivatives). Darcy's law reads: $$C(h)\frac{\partial h}{\partial t} = \nabla\cdot\left(K(h)\nabla h\right) + \frac{\partial K(h)}{\partial z}$$ the left hand side is zero, since I am (so far) only interested in the steady state. Using finite differences with $K$ and $h$ values located at the cell centers, I get: $$0=\frac{K_{i+1/2}\left(\frac{h_{i+1}-h_{i}}{dz}\right)-K_{i-1/2}\left(\frac{h_{i}-h_{i-1}}{dz}\right)}{dz} + \frac{K_{i+1}-K_{i-1}}{2dz}$$ now I replace $K_{i+1/2}$ and $K_{i-1/2}$ by interpolation terms: $$0=\frac{\frac{K_{i}+K_{i+1}}{2}\left(\frac{h_{i+1}-h_{i}}{dz}\right)-\frac{K_{i}+K_{i-1}}{2}\left(\frac{h_{i}-h_{i-1}}{dz}\right)}{dz} + \frac{K_{i+1}-K_{i-1}}{2dz}$$ and simplify it to: $$0=\frac{1}{2dz^2}\left[h_{i-1}\left(K_{i-1}+K_i\right)-h_i\left(K_{i-1}+K_i+K_{i+1}\right)+h_{i+1}\left(K_i+K_{i+1}\right)+K_{i+1}dz-K_{i-1}dz\right]$$ I believe that until here things are okay, correct me if I'm wrong. Now I transform the above equation into a linear system of equations. At the top (between $h_N$ and $h_{N+1}$) there are Dirichlet boundary conditions with $h_{N+1/2}=h_B$ and at the bottom (between $h_0$ and $h_1$) there are neumann boundary conditions $\nabla h_{1/2}=0$: $$\frac{1}{2dz^2} \begin{bmatrix}   -1       & 1       & 0       & 0      & \dots  & 0       & 0       & 0       & 0       \\   c_{i-1} & c_i     & c_{i+1} & 0       & \dots  & 0       & 0       & 0       & 0       \\   0       & c_{i-1} & c_i     & c_{i+1} & \ddots & 0       & 0       & 0       & 0       \\   0       & 0       & c_{i-1} & c_i     & \ddots & 0       & 0       & 0       & 0       \\   \vdots  & \vdots  & \ddots  & \ddots  & \ddots & \ddots  & \ddots  & \vdots  & \vdots  \\   0       & 0       & 0       & 0       & \ddots & c_i     & c_{i+1} & 0       & 0       \\   0       & 0       & 0       & 0       & \ddots & c_{i-1} & c_i     & c_{i+1} & 0       \\   0       & 0       & 0       & 0       & \dots  & 0       & c_{i-1} & c_i     & c_{i+1} \\   0       & 0       & 0       & 0       & \dots  & 0       & 0       & 1       & 1       \\ \end{bmatrix} \begin{bmatrix}   h_0\\   h_1\\   h_2\\   h_3\\   \vdots\\   h_{N-2}\\   h_{N-1}\\   h_{N}\\   h_{N+1} \end{bmatrix} +\frac{1}{2dz} \begin{bmatrix}   0\\   K_2-K_0\\   K_3-K_1\\   K_4-K_2\\   \vdots\\   K_{N-2}-K_{N-4}\\   K_{N-1}-K_{N-3}\\   K_{N}-K_{N-2}\\   0 \end{bmatrix} = \begin{bmatrix}   0\\   0\\   0\\   0\\   \vdots\\   0\\   0\\   0\\   h_Bdz^2 \end{bmatrix} $$ with $c_i = -K_{i-1}-K_i-K_{i+1}$, $c_{i+1}=K_i+K_{i+1}$ and $c_{i-1} = K_{i-1}+K_i$. $h_N$ referes to top most cell and $h_0$ to bottom most cell. The boundary of the domain is located between $h_0$ and $h_1$ and $h_N$ and $h_{N+1}$. This is there I'm not so sure anymore. Did I get the matrix right? And then how to get from here to solving it using the Picard method, which as far as I understand is only good for first-order ODEs and not second-order as Darcy's Eq. is.",,"['ordinary-differential-equations', 'numerical-methods', 'fluid-dynamics']"
65,How to determine the eigenvectors for this matrix,How to determine the eigenvectors for this matrix,,"I have the matrix $$\left( \begin{array}{ccc} -\alpha & \beta \\ \beta/K &  -\alpha/K \end{array} \right)$$ for which the eigenvalues are $$\lambda_{1,2}=-\dfrac{\alpha}{2}-\dfrac{\beta}{2K}\pm\dfrac{\sqrt{(K\alpha-\beta)^2+4K\alpha\beta }}{2K}$$ I have a problem with finding the eigenvectors. It seems that the eigenvectors are zero vectors but then eigenvectors cannot be zero. What am I missing?","I have the matrix $$\left( \begin{array}{ccc} -\alpha & \beta \\ \beta/K &  -\alpha/K \end{array} \right)$$ for which the eigenvalues are $$\lambda_{1,2}=-\dfrac{\alpha}{2}-\dfrac{\beta}{2K}\pm\dfrac{\sqrt{(K\alpha-\beta)^2+4K\alpha\beta }}{2K}$$ I have a problem with finding the eigenvectors. It seems that the eigenvectors are zero vectors but then eigenvectors cannot be zero. What am I missing?",,"['linear-algebra', 'ordinary-differential-equations', 'systems-of-equations']"
66,Second-order non-linear ODE,Second-order non-linear ODE,,"$2tx'-x=lnx'$ I differentiated both sides with respect to x: $x'+2tx''=\frac {x''}{x'}$ Substituting $p=x'$, $p+2tp'=\frac{p'}{p}$ But I have no clue what can I do from here on. EDIT: $t$ is the non-dependent variable.","$2tx'-x=lnx'$ I differentiated both sides with respect to x: $x'+2tx''=\frac {x''}{x'}$ Substituting $p=x'$, $p+2tp'=\frac{p'}{p}$ But I have no clue what can I do from here on. EDIT: $t$ is the non-dependent variable.",,['ordinary-differential-equations']
67,Solve $y'(t) + 6y(t) = 2x(t)$ for impulse response using differential method,Solve  for impulse response using differential method,y'(t) + 6y(t) = 2x(t),$\dfrac{dy}{dt} + 6y(t) = 2x(t)$  $\to$ $\dfrac{dh}{dt} + 6\delta(t) = 2\delta(t)$ zero initial conditions solving for roots $e^{st}(s+6)=0$ $s= -6 \to  h=C_1e^{-6t}$ I want to solve for $C_1$ Is it $h(0)=$ the other side of the equation at t=0 in this case  $2\delta(0)$?,$\dfrac{dy}{dt} + 6y(t) = 2x(t)$  $\to$ $\dfrac{dh}{dt} + 6\delta(t) = 2\delta(t)$ zero initial conditions solving for roots $e^{st}(s+6)=0$ $s= -6 \to  h=C_1e^{-6t}$ I want to solve for $C_1$ Is it $h(0)=$ the other side of the equation at t=0 in this case  $2\delta(0)$?,,['ordinary-differential-equations']
68,How to express $z'(t)$ and $w'(t)$ in terms of $z(t)$ and $w(t)$?,How to express  and  in terms of  and ?,z'(t) w'(t) z(t) w(t),"I have these functions: $x' (t) = −5x(t) + 2 y(t)$ $y' (t) = 2x(t) − 2y(t)$ where $x(0)=10$ and $y(0)=0$ I am also given these 2 functions: $z(t) = x(t) + 2y(t)$ $w(t) = −2x(t) + y(t)$ First question is to express $z'(t)$ and $w'(t)$ in terms of $x'(t)$ and $y'(t)$ so: $z'(t) = x'(t) + 2y'(t)$ $w'(t) = -2x'(t) + y'(t)$ Easy enough. I am then asked to express $z'(t)$ and $w'(t)$ in terms of $z(t)$ and $w(t)$, but I don't know how to do that! Can I get some pointers? Thanks!","I have these functions: $x' (t) = −5x(t) + 2 y(t)$ $y' (t) = 2x(t) − 2y(t)$ where $x(0)=10$ and $y(0)=0$ I am also given these 2 functions: $z(t) = x(t) + 2y(t)$ $w(t) = −2x(t) + y(t)$ First question is to express $z'(t)$ and $w'(t)$ in terms of $x'(t)$ and $y'(t)$ so: $z'(t) = x'(t) + 2y'(t)$ $w'(t) = -2x'(t) + y'(t)$ Easy enough. I am then asked to express $z'(t)$ and $w'(t)$ in terms of $z(t)$ and $w(t)$, but I don't know how to do that! Can I get some pointers? Thanks!",,"['ordinary-differential-equations', 'derivatives', 'systems-of-equations']"
69,Finding the exact solution of a differential equation,Finding the exact solution of a differential equation,,"Let $y=f(x)$. Is it possible to find an exact solution of the following differential equation?: \begin{equation} \ddot y+2\dot y-5xy=e^{-2x}\nonumber \end{equation} Many thanks in advance, -- Cesar","Let $y=f(x)$. Is it possible to find an exact solution of the following differential equation?: \begin{equation} \ddot y+2\dot y-5xy=e^{-2x}\nonumber \end{equation} Many thanks in advance, -- Cesar",,['ordinary-differential-equations']
70,Linear Differential Equations of higher order,Linear Differential Equations of higher order,,"I am studying the basics of linear differential equations. $$\displaystyle \frac{d^ny}{dx^n}+k_1\frac{d^{n-1}y}{dx^{n-1}}+k_2\frac{d^{n-2}y}{dx^{n-2}}+\cdots+k_ny=X$$ First the complementary function is found via $$\displaystyle \frac{d^ny}{dx^n}+k_1\frac{d^{n-1}y}{dx^{n-1}}+k_2\frac{d^{n-2}y}{dx^{n-2}}+\cdots+k_ny=0$$ Then the particular integral is found using $$\displaystyle \frac{d^ny}{dx^n}+k_1\frac{d^{n-1}y}{dx^{n-1}}+k_2\frac{d^{n-2}y}{dx^{n-2}}+\cdots+k_ny=X$$ I did not understand the logic or derivation behind this. Its not like I have another way to solve them, but can anyone help in explaing the intuition behind this.","I am studying the basics of linear differential equations. $$\displaystyle \frac{d^ny}{dx^n}+k_1\frac{d^{n-1}y}{dx^{n-1}}+k_2\frac{d^{n-2}y}{dx^{n-2}}+\cdots+k_ny=X$$ First the complementary function is found via $$\displaystyle \frac{d^ny}{dx^n}+k_1\frac{d^{n-1}y}{dx^{n-1}}+k_2\frac{d^{n-2}y}{dx^{n-2}}+\cdots+k_ny=0$$ Then the particular integral is found using $$\displaystyle \frac{d^ny}{dx^n}+k_1\frac{d^{n-1}y}{dx^{n-1}}+k_2\frac{d^{n-2}y}{dx^{n-2}}+\cdots+k_ny=X$$ I did not understand the logic or derivation behind this. Its not like I have another way to solve them, but can anyone help in explaing the intuition behind this.",,['ordinary-differential-equations']
71,Explicit solution of a second order differential equation,Explicit solution of a second order differential equation,,"Let $y:[0,1]\mapsto \mathbb{R}$. I'd like to know the existence of the explicit solution of the differential equation $$ y^{\prime\prime}-xy^\prime-x^2y=3x-x^3 $$ with the boundary conditions $y(0)=y(1)=0$. I had tried to substitute $x=e^t$ but I could not change to the linear form. Could anyone give me a suggestion?","Let $y:[0,1]\mapsto \mathbb{R}$. I'd like to know the existence of the explicit solution of the differential equation $$ y^{\prime\prime}-xy^\prime-x^2y=3x-x^3 $$ with the boundary conditions $y(0)=y(1)=0$. I had tried to substitute $x=e^t$ but I could not change to the linear form. Could anyone give me a suggestion?",,"['ordinary-differential-equations', 'boundary-value-problem']"
72,Find the general solution to the ODE...,Find the general solution to the ODE...,,"I've been attempting to solve this ODE the past few days: $$(1): [e^{-x^2}u'(x)]' = u(x) + xu'(x).$$ What I did was differentiate the left hand side and move things around a bit to obtain $$(2):e^{-x^2}u''(x) - [2x*e^{-x^2} + x]u'(x) - u(x) = 0.$$ We can see that we are dealing with a homogenous second-order linear differential equation. The problem: I simply just don't know how to solve this. Observing the equation, Cauchy-Euler is not possible. Since we're not dealing with constant coefficients, Principle of Superposition doesn't work as is. And, since this equation is homogenous, we cannot use the method of Undetermined Coefficients or Variation on Parameters. I've attempted to to use v-substitution on (1), setting v(x)=u'(x),  but this just hit dead ends. I came to a solution that I realized was absolutely preposterous (I had forgotten v was a function of x and integrated incorrectly so I got a very wonky answer). Anyone able to give a hand?","I've been attempting to solve this ODE the past few days: $$(1): [e^{-x^2}u'(x)]' = u(x) + xu'(x).$$ What I did was differentiate the left hand side and move things around a bit to obtain $$(2):e^{-x^2}u''(x) - [2x*e^{-x^2} + x]u'(x) - u(x) = 0.$$ We can see that we are dealing with a homogenous second-order linear differential equation. The problem: I simply just don't know how to solve this. Observing the equation, Cauchy-Euler is not possible. Since we're not dealing with constant coefficients, Principle of Superposition doesn't work as is. And, since this equation is homogenous, we cannot use the method of Undetermined Coefficients or Variation on Parameters. I've attempted to to use v-substitution on (1), setting v(x)=u'(x),  but this just hit dead ends. I came to a solution that I realized was absolutely preposterous (I had forgotten v was a function of x and integrated incorrectly so I got a very wonky answer). Anyone able to give a hand?",,['ordinary-differential-equations']
73,Point transformation of ODEs,Point transformation of ODEs,,"I am trying to understand a passage in the introduction to this book , which deals with algorithmical procedures to analytically solve ODEs. Specifically, I do not understand how the ODE  $$ y''(y+x) + y'(y'-1)=0, \quad y=y(x)$$ (formula (1.1) in the linked page) is transformed into  $$ 2v'' u + (v')^2 - 1 =0 \quad v=v(u)$$ by the point transformation  $$ x=u+v \qquad y=u-v.$$ This should be easy. However, the fact that the transformation is not fiber-preserving is confusing to me. (By fiber-preserving I mean that the independent variable $x$ is not a function of the independent variable $u$ alone). Also, the given reference is in German and I cannot read that language. EDIT . I found a good explanation of the theoretical aspects of this kind of transformations in Olver's book Applications of Lie groups to differential equations , §2.2 ""Groups and differential equations"".","I am trying to understand a passage in the introduction to this book , which deals with algorithmical procedures to analytically solve ODEs. Specifically, I do not understand how the ODE  $$ y''(y+x) + y'(y'-1)=0, \quad y=y(x)$$ (formula (1.1) in the linked page) is transformed into  $$ 2v'' u + (v')^2 - 1 =0 \quad v=v(u)$$ by the point transformation  $$ x=u+v \qquad y=u-v.$$ This should be easy. However, the fact that the transformation is not fiber-preserving is confusing to me. (By fiber-preserving I mean that the independent variable $x$ is not a function of the independent variable $u$ alone). Also, the given reference is in German and I cannot read that language. EDIT . I found a good explanation of the theoretical aspects of this kind of transformations in Olver's book Applications of Lie groups to differential equations , §2.2 ""Groups and differential equations"".",,"['ordinary-differential-equations', 'coordinate-systems']"
74,Leading order approximation to differential equation,Leading order approximation to differential equation,,"Find a leading order approximation to the solution of $\epsilon y'' + 2 y' + e^y = 0$, $y(0)=y(1)=0$ as $\epsilon \to 0$. I know there is a boundary layer near $x=0$ and not at $x=1$ so I can impose the boundary condition at $x=1$. But the $e^y$ term is confusing me... when I substitute in an series approximation for $y$ and then taylor expand the $e^y$ term, I keep getting $y=0$ as the outer approximation because of the infinite series for $e^y$. Could anyone help me with a  solution to this problem? Thanks","Find a leading order approximation to the solution of $\epsilon y'' + 2 y' + e^y = 0$, $y(0)=y(1)=0$ as $\epsilon \to 0$. I know there is a boundary layer near $x=0$ and not at $x=1$ so I can impose the boundary condition at $x=1$. But the $e^y$ term is confusing me... when I substitute in an series approximation for $y$ and then taylor expand the $e^y$ term, I keep getting $y=0$ as the outer approximation because of the infinite series for $e^y$. Could anyone help me with a  solution to this problem? Thanks",,"['ordinary-differential-equations', 'asymptotics', 'perturbation-theory']"
75,Problem on Solving Stochastic Differential Equation,Problem on Solving Stochastic Differential Equation,,"Let $(Xt)$ be a solution to the equation $dX_t = aX_t dt + \sqrt{(1+X_t^2)} dW_t$ where $W_t$ is a Brownian motion process at time t Let $Y = F(X_t)$ for a certain function $F$. Find $F$ for which $(Y_t) solves the equation $dY_t = f(Y_t) dt + dW_t$ where the drift term f should be explicitly determined. You may use the fact that $$ \int \frac{1}{\sqrt{1+x^2}}dx\ = ln (x + \sqrt{1+x^2}). $$ My attempt $dY_t = dF(X_t)$ Applying ito's formula we obtain. $dF(X_t) = F'(X_t) dX_t + 1/2 F''(X_t)(dX_t)^2$ Substituting $dX_t$ and $(dX_t)^2$ $dF(X_t) = F'(X_t) (aX_tdt + \sqrt{1+X^2_t} dW_t) + \frac{1}{2} F''(X_t)(1+X^2_t)dt$ $dF(X_t) = F'(X_t)(aX_t + \frac{1}{2} F''(X_t)(1+X^2_t)) dt + F'(X_t)\sqrt{1+X^2_t} dW_t$ Equating coefficients for $dW_t$ $F'(X_t)\sqrt{1+X^2_t} = 1$ $F(X_t) = \int \frac{1}{\sqrt{1+X_t^2}}dx$ $F(X_t) = ln (X_t + \sqrt{1+X_t^2}) + C$, where C is a constant Now my question is ; Can we find this constant? If not, is the answer above correct for $F(x) $ now after equating the coefficients of $dt$, the drift term f is $f(Y_t) = f(F(X_t)) = aX_t + \frac{1}{2} F''(X_t)(1+X^2_t)$ Question ; How can I find the function f?","Let $(Xt)$ be a solution to the equation $dX_t = aX_t dt + \sqrt{(1+X_t^2)} dW_t$ where $W_t$ is a Brownian motion process at time t Let $Y = F(X_t)$ for a certain function $F$. Find $F$ for which $(Y_t) solves the equation $dY_t = f(Y_t) dt + dW_t$ where the drift term f should be explicitly determined. You may use the fact that $$ \int \frac{1}{\sqrt{1+x^2}}dx\ = ln (x + \sqrt{1+x^2}). $$ My attempt $dY_t = dF(X_t)$ Applying ito's formula we obtain. $dF(X_t) = F'(X_t) dX_t + 1/2 F''(X_t)(dX_t)^2$ Substituting $dX_t$ and $(dX_t)^2$ $dF(X_t) = F'(X_t) (aX_tdt + \sqrt{1+X^2_t} dW_t) + \frac{1}{2} F''(X_t)(1+X^2_t)dt$ $dF(X_t) = F'(X_t)(aX_t + \frac{1}{2} F''(X_t)(1+X^2_t)) dt + F'(X_t)\sqrt{1+X^2_t} dW_t$ Equating coefficients for $dW_t$ $F'(X_t)\sqrt{1+X^2_t} = 1$ $F(X_t) = \int \frac{1}{\sqrt{1+X_t^2}}dx$ $F(X_t) = ln (X_t + \sqrt{1+X_t^2}) + C$, where C is a constant Now my question is ; Can we find this constant? If not, is the answer above correct for $F(x) $ now after equating the coefficients of $dt$, the drift term f is $f(Y_t) = f(F(X_t)) = aX_t + \frac{1}{2} F''(X_t)(1+X^2_t)$ Question ; How can I find the function f?",,"['ordinary-differential-equations', 'stochastic-processes', 'stochastic-calculus']"
76,Showing that a sequence of Picard iterates converges,Showing that a sequence of Picard iterates converges,,"I have a sequence of functions: $$y_{n}(x) = 1 + \int \limits_0^x 1 + t^2 + y_{n-1}^2(t)\,\mathrm dt$$ With $y_0 = 1$. I'm trying to show that this converges in a box $-1 \le x \le 1$ and $-10 \le y \le 10$. However when I try to show this converges in this box, the bound on the integral gives $|y-1| \le xM$ where $M$ is the maximum of $1 + t^2 + y^2$ in the box, however this maximum is $102$ so the iterates only converge in the box when $|y-1| \le 102$ but this isn't true? Am I missing something obvious here? Thanks","I have a sequence of functions: $$y_{n}(x) = 1 + \int \limits_0^x 1 + t^2 + y_{n-1}^2(t)\,\mathrm dt$$ With $y_0 = 1$. I'm trying to show that this converges in a box $-1 \le x \le 1$ and $-10 \le y \le 10$. However when I try to show this converges in this box, the bound on the integral gives $|y-1| \le xM$ where $M$ is the maximum of $1 + t^2 + y^2$ in the box, however this maximum is $102$ so the iterates only converge in the box when $|y-1| \le 102$ but this isn't true? Am I missing something obvious here? Thanks",,"['ordinary-differential-equations', 'integral-equations']"
77,Homogeneous differential equation general solution,Homogeneous differential equation general solution,,Consider the homogeneous differential equation $$\cfrac{ds}{dt}=\cfrac{2s^2}{s^2+t^2}$$ Find the general solution $s(t)$ of this equation and the solution that satisfies the initial condition $s(0)=1$. I don't seem to be able to separate these equations or rearrange them into a linear form,Consider the homogeneous differential equation $$\cfrac{ds}{dt}=\cfrac{2s^2}{s^2+t^2}$$ Find the general solution $s(t)$ of this equation and the solution that satisfies the initial condition $s(0)=1$. I don't seem to be able to separate these equations or rearrange them into a linear form,,['ordinary-differential-equations']
78,Black Derman & Toy Model,Black Derman & Toy Model,,"The BDT model is given by $$d(\ln\,r)=\left(\theta(t)-\frac {d(\ln\sigma(t)}{dt}\ln r\right)\,dt+\sigma(t) \, dW.$$ How can one rewrite the BDT model as $dr=A\,dt+B\, dW$, using It$\hat o$?","The BDT model is given by $$d(\ln\,r)=\left(\theta(t)-\frac {d(\ln\sigma(t)}{dt}\ln r\right)\,dt+\sigma(t) \, dW.$$ How can one rewrite the BDT model as $dr=A\,dt+B\, dW$, using It$\hat o$?",,"['ordinary-differential-equations', 'stochastic-calculus']"
79,First Order Non-Linear Equations,First Order Non-Linear Equations,,please ; How can solve ODE. $$(1+y^2)+(x-e^{tan^{-1}y})\frac {dy}{dx}=0$$ These my attempt $$ let\space u=tan^{-1}y      $$ $$  y= tanu$$ $$\frac{dy}{dx}= sec^{2}u \frac{du}{dx}$$ $$(1+tan^{2}u)+(x-e^{u})\sec^{2}u\frac{du}{dx}=0$$ $$(sec^{2}u)+(x-e^{u})\sec^{2}u\frac{du}{dx}=0$$ $$(x-e^{u})\frac{du}{dx}=-1$$ This non-Linear ODE how can solved it?? please,please ; How can solve ODE. $$(1+y^2)+(x-e^{tan^{-1}y})\frac {dy}{dx}=0$$ These my attempt $$ let\space u=tan^{-1}y      $$ $$  y= tanu$$ $$\frac{dy}{dx}= sec^{2}u \frac{du}{dx}$$ $$(1+tan^{2}u)+(x-e^{u})\sec^{2}u\frac{du}{dx}=0$$ $$(sec^{2}u)+(x-e^{u})\sec^{2}u\frac{du}{dx}=0$$ $$(x-e^{u})\frac{du}{dx}=-1$$ This non-Linear ODE how can solved it?? please,,['ordinary-differential-equations']
80,"$y''+2y'+5y=0$, initial value problem with Laplace transform?",", initial value problem with Laplace transform?",y''+2y'+5y=0,"here is the question: $$ {\rm y}''\left(t\right) + 2\,{\rm y}'\left(t\right) + 5\,{\rm y}\left(t\right) = 0; \qquad\qquad {\rm y}\left(0\right) = 2\,,\quad {\rm y}'\left(0\right) = -1. $$ $\mathcal{L} (y''(t)) = s^2y(s) -s y(0) -y'(0)$ $\mathcal{L} (+2y'(t)) = 2(sy(s) -y(0))$ $\mathcal{L} (5y(t)) = 5y(s)$ I find that $y(t)=\dfrac{2s+3}{s^{2}+2s+5}$ It is irreducible, so I write the transform as a function of $\varepsilon = s + 1$. $y(t)=\dfrac{2\varepsilon+1}{\varepsilon^2+4}$ I apply fraction by parts then use laplace transform table and find the result: $y(t)=e^{-t} (2\cos{2t}+\sin{2t})$, but the result has $\frac{1}{2}$ before $\sin{2t}$. What am I missing here? Where does the $\frac{1}{2}$ come from?","here is the question: $$ {\rm y}''\left(t\right) + 2\,{\rm y}'\left(t\right) + 5\,{\rm y}\left(t\right) = 0; \qquad\qquad {\rm y}\left(0\right) = 2\,,\quad {\rm y}'\left(0\right) = -1. $$ $\mathcal{L} (y''(t)) = s^2y(s) -s y(0) -y'(0)$ $\mathcal{L} (+2y'(t)) = 2(sy(s) -y(0))$ $\mathcal{L} (5y(t)) = 5y(s)$ I find that $y(t)=\dfrac{2s+3}{s^{2}+2s+5}$ It is irreducible, so I write the transform as a function of $\varepsilon = s + 1$. $y(t)=\dfrac{2\varepsilon+1}{\varepsilon^2+4}$ I apply fraction by parts then use laplace transform table and find the result: $y(t)=e^{-t} (2\cos{2t}+\sin{2t})$, but the result has $\frac{1}{2}$ before $\sin{2t}$. What am I missing here? Where does the $\frac{1}{2}$ come from?",,"['ordinary-differential-equations', 'laplace-transform']"
81,Initial Value Problem for $y''+xy'+x^2y=0$,Initial Value Problem for,y''+xy'+x^2y=0,"Does anyone have a solution for the initial value problem: $$y''+xy'+x^2y=0, y(0)=1, y'(0)=1 ?$$ I try power series solution but I have trouble finding a pattern for the general term of the series.","Does anyone have a solution for the initial value problem: $$y''+xy'+x^2y=0, y(0)=1, y'(0)=1 ?$$ I try power series solution but I have trouble finding a pattern for the general term of the series.",,['ordinary-differential-equations']
82,Fundamental matrix in ODE,Fundamental matrix in ODE,,Let $A(t)$ a matrix $n \times n$ of continuous functions in an interval $I\subseteq\mathbb{R}$. If for all $t$ $$\left[\int_{to}^tA(s)ds  \right]A(t) = A(t)\left[\int_{to}^tA(s)ds\right].$$ Show that $\displaystyle \phi(t)= e^{\large{\int _{t_0}^tA(s)ds}}$ is a fundamental matrix of $x' = A(t)x$.,Let $A(t)$ a matrix $n \times n$ of continuous functions in an interval $I\subseteq\mathbb{R}$. If for all $t$ $$\left[\int_{to}^tA(s)ds  \right]A(t) = A(t)\left[\int_{to}^tA(s)ds\right].$$ Show that $\displaystyle \phi(t)= e^{\large{\int _{t_0}^tA(s)ds}}$ is a fundamental matrix of $x' = A(t)x$.,,['ordinary-differential-equations']
83,Homogenous Linear ODE with constant coefficients,Homogenous Linear ODE with constant coefficients,,How do you factor the following Homogenous Linear ODE with constant coefficients and what is the general solution: $$L[f] = \left(\frac{\mathrm{d}}{\mathrm{d}x} +1\right)\left(\frac{\mathrm{d}}{\mathrm{d}x} +1\right)\left(\frac{\mathrm{d}^2 f}{\mathrm{d}x^2} + 4f\right) = 0$$,How do you factor the following Homogenous Linear ODE with constant coefficients and what is the general solution: $$L[f] = \left(\frac{\mathrm{d}}{\mathrm{d}x} +1\right)\left(\frac{\mathrm{d}}{\mathrm{d}x} +1\right)\left(\frac{\mathrm{d}^2 f}{\mathrm{d}x^2} + 4f\right) = 0$$,,['ordinary-differential-equations']
84,Linear Systems ODE,Linear Systems ODE,,Suppose that the square matrix $A$ has a negative eigenvalue. Show that the linear system $x' = Ax$ has at least one nontrivial solution $x(t)$ that satisfies $$\lim_{t\to\infty}x(t)=0$$,Suppose that the square matrix $A$ has a negative eigenvalue. Show that the linear system $x' = Ax$ has at least one nontrivial solution $x(t)$ that satisfies $$\lim_{t\to\infty}x(t)=0$$,,['ordinary-differential-equations']
85,Solving a certain differential equation when assuming a surface of revolution is minimal,Solving a certain differential equation when assuming a surface of revolution is minimal,,"The problem is the following: Consider the surface of revolution $$ \textbf{q} (t, \mu) = (r(t)\cos(\mu),r(t)\sin(\mu),t) $$ If $\textbf{q}$ is minimal, then $r(t) = a\cosh(t)+b\sinh(t)$ for $a,b$ constants. I'll skip the calculations. I've equated the mean curvature and $0$ and obtained the relation $$ 1+\dot{r}^2 = r\ddot{r} $$ where each is understood to be a function of $t$. It's been a while since I've taken a class on differential equations, but since I ""know"" the solution, my plan was to check $r = \cosh(t)$ and $r = \sinh(t)$ are solutions to the above, and then conclude a linear combination of them is also a solution. However, $\cosh(t)$ worked fine, but I cannot really get $\sinh(t)$ to work the same. I get $$ 1+\dot{r}^2 = 1 + \cosh(t)^2 = 2 + \sinh(t)^2 \ne \sinh(t)^2 $$ is there perhaps an identity I'm not recalling/don't know? I also tried ""guessing"" $r(t) = a\cosh(t)+b\sinh(t)$, but that didn't work out too well either. Any suggestions? Edit: The ""solution"" to check in the book was incorrect, which was kind of clear anyway since $\sinh(t)$ wasn't working.","The problem is the following: Consider the surface of revolution $$ \textbf{q} (t, \mu) = (r(t)\cos(\mu),r(t)\sin(\mu),t) $$ If $\textbf{q}$ is minimal, then $r(t) = a\cosh(t)+b\sinh(t)$ for $a,b$ constants. I'll skip the calculations. I've equated the mean curvature and $0$ and obtained the relation $$ 1+\dot{r}^2 = r\ddot{r} $$ where each is understood to be a function of $t$. It's been a while since I've taken a class on differential equations, but since I ""know"" the solution, my plan was to check $r = \cosh(t)$ and $r = \sinh(t)$ are solutions to the above, and then conclude a linear combination of them is also a solution. However, $\cosh(t)$ worked fine, but I cannot really get $\sinh(t)$ to work the same. I get $$ 1+\dot{r}^2 = 1 + \cosh(t)^2 = 2 + \sinh(t)^2 \ne \sinh(t)^2 $$ is there perhaps an identity I'm not recalling/don't know? I also tried ""guessing"" $r(t) = a\cosh(t)+b\sinh(t)$, but that didn't work out too well either. Any suggestions? Edit: The ""solution"" to check in the book was incorrect, which was kind of clear anyway since $\sinh(t)$ wasn't working.",,"['ordinary-differential-equations', 'differential-geometry', 'minimal-surfaces']"
86,Nonlinear PDE from Riemannian Geometry,Nonlinear PDE from Riemannian Geometry,,"I am wondering if anyone knows an approach to finding solutions to the following PDE: $-e^{-2u}\Delta u=\alpha$. Here $u=u(x,y)$ is an unknown real-valued function of 2 variables and $\alpha$ is a constant. I'd be happy to see a solution on any connected open subset of the plane. I have 2 basic observations to get us started. The first is that we can reduce to a nonlinear second order ODE by looking for functions of the radius $r$ (or maybe $r^2$ to avoid square roots). Second, the left hand side shows up if one calculates $\Delta (e^{-2u})$. Looking at the result of the substitution, I'm not sure if this helps. For context, the quantity on the left side of the equation above is the sectional or Gauss curvature of a metric which is conformal by the factor $e^{2u}$ to the standard Euclidean metric on the plane. Thus solving the above would be a simple way to give examples of constant curvature metrics in two dimensions.","I am wondering if anyone knows an approach to finding solutions to the following PDE: $-e^{-2u}\Delta u=\alpha$. Here $u=u(x,y)$ is an unknown real-valued function of 2 variables and $\alpha$ is a constant. I'd be happy to see a solution on any connected open subset of the plane. I have 2 basic observations to get us started. The first is that we can reduce to a nonlinear second order ODE by looking for functions of the radius $r$ (or maybe $r^2$ to avoid square roots). Second, the left hand side shows up if one calculates $\Delta (e^{-2u})$. Looking at the result of the substitution, I'm not sure if this helps. For context, the quantity on the left side of the equation above is the sectional or Gauss curvature of a metric which is conformal by the factor $e^{2u}$ to the standard Euclidean metric on the plane. Thus solving the above would be a simple way to give examples of constant curvature metrics in two dimensions.",,"['ordinary-differential-equations', 'partial-differential-equations', 'riemannian-geometry']"
87,Variation of parameters for 2nd order ODE [closed],Variation of parameters for 2nd order ODE [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 5 years ago . Improve this question http://en.wikipedia.org/wiki/Variation_of_parameters describes the general solution to a second order system under ""General Second Order Equation.""  What does it mean when the forcing function $f$ is not $C^1$?  Does that just mean that the assumption of the form of the particular solution is wrong? (We know from general theory that there exists a unique solution per initial condition on $u$ and its first derivative.)","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 5 years ago . Improve this question http://en.wikipedia.org/wiki/Variation_of_parameters describes the general solution to a second order system under ""General Second Order Equation.""  What does it mean when the forcing function $f$ is not $C^1$?  Does that just mean that the assumption of the form of the particular solution is wrong? (We know from general theory that there exists a unique solution per initial condition on $u$ and its first derivative.)",,['ordinary-differential-equations']
88,Solve: $\frac{d^2x}{dt^2}+\Bigl(\frac{d^2y}{dt^2}\Bigr)^2=0$,Solve:,\frac{d^2x}{dt^2}+\Bigl(\frac{d^2y}{dt^2}\Bigr)^2=0,We have the following coupled Diferential equation: $\dfrac{d^2x}{dt^2}=-\left(\dfrac{y}{x}\right)^2$ $\dfrac{d^2y}{dt^2}=\dfrac{y}{x}$ Then find the solution $x$ and $y$ in terms of $t$ . What we have that $\dfrac{d^2x}{dt^2}+\left(\dfrac{d^2y}{dt^2}\right)^2=0$ Now how to solve this equation. Please help. Thanks in advance!,We have the following coupled Diferential equation: $\dfrac{d^2x}{dt^2}=-\left(\dfrac{y}{x}\right)^2$ $\dfrac{d^2y}{dt^2}=\dfrac{y}{x}$ Then find the solution $x$ and $y$ in terms of $t$ . What we have that $\dfrac{d^2x}{dt^2}+\left(\dfrac{d^2y}{dt^2}\right)^2=0$ Now how to solve this equation. Please help. Thanks in advance!,,"['ordinary-differential-equations', 'systems-of-equations']"
89,"Solution to the ""cubic"" Helmholtz equation","Solution to the ""cubic"" Helmholtz equation",,"What is known about the solutions of the differential equation in three-dimensions $$ \nabla^2 \phi = -\kappa^2 (\phi  + (1/3!)\phi^3) $$ Without the cubic term, this gives a linear operator $\mathcal{L} = \nabla^2 + \kappa^2$. In this case I can get a solution via the Green's function $G=\exp{(i\kappa r)}(4\pi r)^{-1}$. In my equation however, the presence of $\phi^3$ does not give me a linear operator. Is anything known about the solution to this equation? Context : The Poisson-Boltzmann equation can be put into the functional form of $\nabla^2 \phi = -\kappa^2 \sinh \phi$. Expanding sinh to first order gives the Helmholtz equation as mentioned above. The second order term is zero and the third order term gives the equation in question.","What is known about the solutions of the differential equation in three-dimensions $$ \nabla^2 \phi = -\kappa^2 (\phi  + (1/3!)\phi^3) $$ Without the cubic term, this gives a linear operator $\mathcal{L} = \nabla^2 + \kappa^2$. In this case I can get a solution via the Green's function $G=\exp{(i\kappa r)}(4\pi r)^{-1}$. In my equation however, the presence of $\phi^3$ does not give me a linear operator. Is anything known about the solution to this equation? Context : The Poisson-Boltzmann equation can be put into the functional form of $\nabla^2 \phi = -\kappa^2 \sinh \phi$. Expanding sinh to first order gives the Helmholtz equation as mentioned above. The second order term is zero and the third order term gives the equation in question.",,"['ordinary-differential-equations', 'partial-differential-equations', 'physics', 'mathematical-physics']"
90,Understanding basic stochastic differential equations,Understanding basic stochastic differential equations,,"This is from a physics course in economics, the literature provides a bare minimum of mathematical explanations. I am trying to understand how to work with stochastic differential equations given in exercises. Any explanation of how to approach would be appreciated. I am assuming this is very easy, but since the given literature is unreadable for me, I have no idea. Assume that the time evolution of two stock prices $S_1$ and $S_2$ are   described by the two following Wiener process, $$dS_1 = \sigma_1\epsilon\sqrt{dt}\\ dS_2  = \sigma_2\epsilon\sqrt{dt} + \sigma_0\epsilon_0\sqrt{dt},$$ where $\sigma_0, \sigma_1, \sigma_2$ are volatilities, $\epsilon_0$   and $\epsilon$ are independent , normally distributed random numbers   with variance one. Furthermore, assume that $S_1(0) = S_2(0) = 0$. 1. If $\sigma_2 = 0$, what is the correlation between S_1(t) and S_2(t)? 2. Calculate the variance and the correlation between the two following portfolios $$F_1 = S_1 \\ F_2 = \sigma_2S_1 - \sigma_1S_2 $$ Assuming $\sigma_2 = 0$ yields $dS_2 = \sigma_0\epsilon_0 \sqrt{dt}$. They provide no proper definition of the correlation, but from what I have seen in an example, it seems to be given by the moment $\langle S_1 S_2\rangle$. How is this integral derived from the given information? Do we compute $$\langle dS_1dS_2 \rangle = \sigma_0\sigma_1\langle\epsilon_0\epsilon dt\rangle = \sigma_0\sigma_1\langle\epsilon_0\rangle\langle\epsilon\rangle dt ?$$ Where would we go from here? 2.. Itôs formula seems to be the key. Again, they do not provide a proper definition, but I'm guessing the approach is the following. Let $f(x,t) = x$ and define $F_1 = f(S_1, t)$ and $F_2 = \sigma_2f(S_1,t) - \sigma_1f(S_2, t)$. We should get the following $$dF_1 = \sigma_1\epsilon\sqrt{dt} \\ dF_2 = \sigma_2dS_1 - \sigma_1dS_2 = -\sigma_0\sigma_1\epsilon_0\sqrt{dt}.$$ Any suggestions? As of writing I just got my hands on a copy of Oksendal's ""Stochastic differential equations"" which I hope will have an approach that I am more comfortable with.","This is from a physics course in economics, the literature provides a bare minimum of mathematical explanations. I am trying to understand how to work with stochastic differential equations given in exercises. Any explanation of how to approach would be appreciated. I am assuming this is very easy, but since the given literature is unreadable for me, I have no idea. Assume that the time evolution of two stock prices $S_1$ and $S_2$ are   described by the two following Wiener process, $$dS_1 = \sigma_1\epsilon\sqrt{dt}\\ dS_2  = \sigma_2\epsilon\sqrt{dt} + \sigma_0\epsilon_0\sqrt{dt},$$ where $\sigma_0, \sigma_1, \sigma_2$ are volatilities, $\epsilon_0$   and $\epsilon$ are independent , normally distributed random numbers   with variance one. Furthermore, assume that $S_1(0) = S_2(0) = 0$. 1. If $\sigma_2 = 0$, what is the correlation between S_1(t) and S_2(t)? 2. Calculate the variance and the correlation between the two following portfolios $$F_1 = S_1 \\ F_2 = \sigma_2S_1 - \sigma_1S_2 $$ Assuming $\sigma_2 = 0$ yields $dS_2 = \sigma_0\epsilon_0 \sqrt{dt}$. They provide no proper definition of the correlation, but from what I have seen in an example, it seems to be given by the moment $\langle S_1 S_2\rangle$. How is this integral derived from the given information? Do we compute $$\langle dS_1dS_2 \rangle = \sigma_0\sigma_1\langle\epsilon_0\epsilon dt\rangle = \sigma_0\sigma_1\langle\epsilon_0\rangle\langle\epsilon\rangle dt ?$$ Where would we go from here? 2.. Itôs formula seems to be the key. Again, they do not provide a proper definition, but I'm guessing the approach is the following. Let $f(x,t) = x$ and define $F_1 = f(S_1, t)$ and $F_2 = \sigma_2f(S_1,t) - \sigma_1f(S_2, t)$. We should get the following $$dF_1 = \sigma_1\epsilon\sqrt{dt} \\ dF_2 = \sigma_2dS_1 - \sigma_1dS_2 = -\sigma_0\sigma_1\epsilon_0\sqrt{dt}.$$ Any suggestions? As of writing I just got my hands on a copy of Oksendal's ""Stochastic differential equations"" which I hope will have an approach that I am more comfortable with.",,"['ordinary-differential-equations', 'stochastic-processes', 'finance', 'economics']"
91,"find a 4th order linear, non-homo ODE whose general solution:","find a 4th order linear, non-homo ODE whose general solution:",,"How to find a fourth order, linear, not homogenous ODE with general solution: $y=c_1+c_2 x+c_3 e^{2x}\cos x+c_4e^{2x}\sin x-x e^{-x}$? Is there a specific method? I feel like it is guesswork to a certain degree. I can tell some parts such as the $c_1$ term will originally have had to be some sort of degree $4$ polynomial, and the $\sin,\cos$ terms will be some linear combination  $a\cos +b\sin$ (I think)  as well. but the other ones aren't as obvious to me. Any help would be appreicated. thank you!","How to find a fourth order, linear, not homogenous ODE with general solution: $y=c_1+c_2 x+c_3 e^{2x}\cos x+c_4e^{2x}\sin x-x e^{-x}$? Is there a specific method? I feel like it is guesswork to a certain degree. I can tell some parts such as the $c_1$ term will originally have had to be some sort of degree $4$ polynomial, and the $\sin,\cos$ terms will be some linear combination  $a\cos +b\sin$ (I think)  as well. but the other ones aren't as obvious to me. Any help would be appreicated. thank you!",,['ordinary-differential-equations']
92,Seperation of variables justification?,Seperation of variables justification?,,"I haven't found a similar question on Math SE, but I may not have looked enough because I find it hard to believe someone hasn't already asked this. Anyways, here goes: I'm studying mathematics, but one of the courses is a course on physics. So, since my university chooses not to give courses on differential equations until we have a solid knowledge of Algebra, Geometry, Analysis, Topology, etc., the physics course includes a small supplement on ODE's. To my dismay though, one of the first things we learned was that we could solve $$\frac{dy}{dx}=f(y)g(x)$$ By multiplying by $dx$ on both sides, dividing by $f(y )$ and integrating on the left with respect to $x$, and on the right with respect to $x$. I have no clue how this even makes sense as $dy/dx$ and $dx$ or $dy$ in an integral are just notations. Could someone elaborate a justification for this process? As a side note, is there any way to discuss these things intrinsically? Or is it like calculus where we always talk about $f(x)$ and use the canonical basis?","I haven't found a similar question on Math SE, but I may not have looked enough because I find it hard to believe someone hasn't already asked this. Anyways, here goes: I'm studying mathematics, but one of the courses is a course on physics. So, since my university chooses not to give courses on differential equations until we have a solid knowledge of Algebra, Geometry, Analysis, Topology, etc., the physics course includes a small supplement on ODE's. To my dismay though, one of the first things we learned was that we could solve $$\frac{dy}{dx}=f(y)g(x)$$ By multiplying by $dx$ on both sides, dividing by $f(y )$ and integrating on the left with respect to $x$, and on the right with respect to $x$. I have no clue how this even makes sense as $dy/dx$ and $dx$ or $dy$ in an integral are just notations. Could someone elaborate a justification for this process? As a side note, is there any way to discuss these things intrinsically? Or is it like calculus where we always talk about $f(x)$ and use the canonical basis?",,"['calculus', 'ordinary-differential-equations', 'notation']"
93,What ODE book has good exercises?,What ODE book has good exercises?,,"What book has good exercises for ODE? I would say I am just starting to study the subject rigorously, but I am pretty well-versed at math more broadly. I am reading the intro-level book by Coddington, but I find the exercises mechanical and not creative. For me, examples of books with great exercises are Spivak's Calculus , Friedberg's Linear Algebra , Strang's Linear Algebra , Artin's Algebra , Courant's Intro to Calculus and Analysis , Dummit and Foote's Abstract Algebra , the Stein/Shakarchi texts on analysis, Ahlfors' Complex Analysis .","What book has good exercises for ODE? I would say I am just starting to study the subject rigorously, but I am pretty well-versed at math more broadly. I am reading the intro-level book by Coddington, but I find the exercises mechanical and not creative. For me, examples of books with great exercises are Spivak's Calculus , Friedberg's Linear Algebra , Strang's Linear Algebra , Artin's Algebra , Courant's Intro to Calculus and Analysis , Dummit and Foote's Abstract Algebra , the Stein/Shakarchi texts on analysis, Ahlfors' Complex Analysis .",,"['ordinary-differential-equations', 'reference-request']"
94,Periodic solutions to ODEs,Periodic solutions to ODEs,,"I have the second order ODE $\dfrac{d^2x}{dt^2}-\bigg(\dfrac{dx}{dt}\bigg)^2 + x^2 - x = 0$. I have transformed it into a plane autonomous system, and then the question asks: By considering symmetries of the ODEs, or otherwise, determine if there are periodic orbits of the original ODE. I'm really confused with this part. I don't know what symmetries I'm supposed to be exploiting. I tried using the Bendixson-Dulac theorem, but I couldn't make that work. Could anyone point me in the right direction with this? Thanks","I have the second order ODE $\dfrac{d^2x}{dt^2}-\bigg(\dfrac{dx}{dt}\bigg)^2 + x^2 - x = 0$. I have transformed it into a plane autonomous system, and then the question asks: By considering symmetries of the ODEs, or otherwise, determine if there are periodic orbits of the original ODE. I'm really confused with this part. I don't know what symmetries I'm supposed to be exploiting. I tried using the Bendixson-Dulac theorem, but I couldn't make that work. Could anyone point me in the right direction with this? Thanks",,['ordinary-differential-equations']
95,Is this a singular point? And why?,Is this a singular point? And why?,,"I'm trying to solve this ODE $$x'' + \frac{2}{t} x' + x = 0$$ by series expansion around $t_0=0.$ I know it's very simple, but I'm kind of not sure whether this is a singular point or an ordinary one. Several things confuse me. First of all, is the point considered singular only if it's a zero of the leading term? And also, when I try solving it as an ordinary point, assuming $$x(t)=\sum\limits_{k=0}^\infty c_k t^k, $$ I conclude that all the odd terms in the recurrent relation vanish, so I get only one solution, that can't be right... I'm not quite comfortable with these concepts because I don't really get the motivation for some definitions, such as the singular point, so I would appreciate a clear and meaningful explanation.","I'm trying to solve this ODE $$x'' + \frac{2}{t} x' + x = 0$$ by series expansion around $t_0=0.$ I know it's very simple, but I'm kind of not sure whether this is a singular point or an ordinary one. Several things confuse me. First of all, is the point considered singular only if it's a zero of the leading term? And also, when I try solving it as an ordinary point, assuming $$x(t)=\sum\limits_{k=0}^\infty c_k t^k, $$ I conclude that all the odd terms in the recurrent relation vanish, so I get only one solution, that can't be right... I'm not quite comfortable with these concepts because I don't really get the motivation for some definitions, such as the singular point, so I would appreciate a clear and meaningful explanation.",,['ordinary-differential-equations']
96,Why are Galerkin methods/FEMs used for solving PDEs and rather not ODEs?,Why are Galerkin methods/FEMs used for solving PDEs and rather not ODEs?,,"I have not yet understood Galerkin methods and in general not the structural differences between ODEs and PDEs (of course I know the basics but not why PDEs ist so much different except that they contain partial derivatives w.r.t. several variables).  For instance, I don't understand why and what it means that ODEs can only be a finite-dimensional approximation of PDEs. I guess, it is related that I don't understand why Galerkin methods or related methods are used for PDEs but never for ODEs (or are there any examples)? Thanks in advance. I am very new to the theory of solving PDEs.","I have not yet understood Galerkin methods and in general not the structural differences between ODEs and PDEs (of course I know the basics but not why PDEs ist so much different except that they contain partial derivatives w.r.t. several variables).  For instance, I don't understand why and what it means that ODEs can only be a finite-dimensional approximation of PDEs. I guess, it is related that I don't understand why Galerkin methods or related methods are used for PDEs but never for ODEs (or are there any examples)? Thanks in advance. I am very new to the theory of solving PDEs.",,"['ordinary-differential-equations', 'numerical-methods']"
97,Dynamical system equilibrium point increment,Dynamical system equilibrium point increment,,"I am reading through the dynamical systems theory and there is an example of a Mass-Spring system. The state equations are given by $\displaystyle \frac{d x_1}{dx}(t) = x_2(t)$ $\displaystyle \frac{d x_2}{dx}(t) = \frac{-k}{m}x_1(t)+\frac{f(t)}{m}$ Then we find the equilibrium point by setting $\displaystyle 0 = x_2(t)$ $\displaystyle 0 = \frac{-k}{m}x_1(t)+\frac{f(t)}{m}$ Which gives as result $x_{eq} = \left[ \begin{array}{c} x_{1} \\ x_{2} \\ \end{array} \right] = \left[ \begin{array}{c} f/k \\ 0 \\ \end{array} \right]$ Finally, the book defines the increment with respect to the equilibrium point $\Delta x(t) = x(t) - x_{eq}$. Substracting equation (1,3) and (2,4) the result is $\displaystyle \frac{d \Delta x_1}{dx}(t) = \Delta x_2(t)$ $\displaystyle \frac{d \Delta x_2}{dx}(t) = \frac{-k}{m}\Delta x_1(t)$ So far so good, but for the next step they get ""the general solution, parametrized by the initial state"" as $\displaystyle \Delta x_1(t) = \Delta x_1(0) cos(\omega t) + \frac{\Delta x_2(0)}{\omega} sin(\omega t)$ $\displaystyle \Delta x_2(t) = -\Delta x_1(0) \omega sin(\omega t) + \Delta x_2(0)cos(\omega t)$ This result I don't understand where does it comes from, could someone give me a hint?","I am reading through the dynamical systems theory and there is an example of a Mass-Spring system. The state equations are given by $\displaystyle \frac{d x_1}{dx}(t) = x_2(t)$ $\displaystyle \frac{d x_2}{dx}(t) = \frac{-k}{m}x_1(t)+\frac{f(t)}{m}$ Then we find the equilibrium point by setting $\displaystyle 0 = x_2(t)$ $\displaystyle 0 = \frac{-k}{m}x_1(t)+\frac{f(t)}{m}$ Which gives as result $x_{eq} = \left[ \begin{array}{c} x_{1} \\ x_{2} \\ \end{array} \right] = \left[ \begin{array}{c} f/k \\ 0 \\ \end{array} \right]$ Finally, the book defines the increment with respect to the equilibrium point $\Delta x(t) = x(t) - x_{eq}$. Substracting equation (1,3) and (2,4) the result is $\displaystyle \frac{d \Delta x_1}{dx}(t) = \Delta x_2(t)$ $\displaystyle \frac{d \Delta x_2}{dx}(t) = \frac{-k}{m}\Delta x_1(t)$ So far so good, but for the next step they get ""the general solution, parametrized by the initial state"" as $\displaystyle \Delta x_1(t) = \Delta x_1(0) cos(\omega t) + \frac{\Delta x_2(0)}{\omega} sin(\omega t)$ $\displaystyle \Delta x_2(t) = -\Delta x_1(0) \omega sin(\omega t) + \Delta x_2(0)cos(\omega t)$ This result I don't understand where does it comes from, could someone give me a hint?",,"['ordinary-differential-equations', 'dynamical-systems', 'systems-of-equations']"
98,Stability of $\dot{x}=-A(t)x$,Stability of,\dot{x}=-A(t)x,"I already have an ODE of $A(t)$, that is $\dot{A}=-G(A(t)-A^*)$, where $G$ and $A^*$ are constant positive definite matrices. Thus I can deduce that $A(t)$ exponentially converge to $A^*$. Now I take $(A^*-A(t))$ as an input to the dynamic system $\dot{x}=-A(t)x$. By changing the system to $\dot{x}=-A^*x+(A^*-A(t))x$, hopefully $x$ can be proved to converge to $0$ by the theory of input-to-state-stability. However, when I try to show that $f(t,x,A^*-A(t))=-A^*x+(A^*-A(t))x$ is Lipschitz in $(x,A^*-A(t))$, that is $\Vert f(t,x,A^*-A(t))-f(t,x,0) \Vert = \Vert (A^*-A(t))x \Vert \le L\Vert A^*-A(t) \Vert$, I have probelm in showing that $x$ is uniformly bounded in $t$ (that is, $\Vert x \Vert \le L$ ). I hope that there is any theory and tools that can help me solve this problem.","I already have an ODE of $A(t)$, that is $\dot{A}=-G(A(t)-A^*)$, where $G$ and $A^*$ are constant positive definite matrices. Thus I can deduce that $A(t)$ exponentially converge to $A^*$. Now I take $(A^*-A(t))$ as an input to the dynamic system $\dot{x}=-A(t)x$. By changing the system to $\dot{x}=-A^*x+(A^*-A(t))x$, hopefully $x$ can be proved to converge to $0$ by the theory of input-to-state-stability. However, when I try to show that $f(t,x,A^*-A(t))=-A^*x+(A^*-A(t))x$ is Lipschitz in $(x,A^*-A(t))$, that is $\Vert f(t,x,A^*-A(t))-f(t,x,0) \Vert = \Vert (A^*-A(t))x \Vert \le L\Vert A^*-A(t) \Vert$, I have probelm in showing that $x$ is uniformly bounded in $t$ (that is, $\Vert x \Vert \le L$ ). I hope that there is any theory and tools that can help me solve this problem.",,"['ordinary-differential-equations', 'dynamical-systems', 'control-theory']"
99,Solving $f'''+\frac{n+1}{2}ff''-nf'^2+n=0$ with $n=e^\pi$,Solving  with,f'''+\frac{n+1}{2}ff''-nf'^2+n=0 n=e^\pi,How do I solve $$f'''+\frac{n+1}{2}ff''-nf'^2+n=0$$ with $n=e^\pi$ or arbitrary $n$? This equation occurs in my model for the time evolution of the value of Bitcoin.,How do I solve $$f'''+\frac{n+1}{2}ff''-nf'^2+n=0$$ with $n=e^\pi$ or arbitrary $n$? This equation occurs in my model for the time evolution of the value of Bitcoin.,,"['ordinary-differential-equations', 'mathematical-modeling']"
