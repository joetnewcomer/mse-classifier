,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"For an integral curve on a smooth manifold, can the interval on which it is defined be non-open?","For an integral curve on a smooth manifold, can the interval on which it is defined be non-open?",,"I'm studying Professor Lee's Introduction to Smooth Manifolds (Second Edition) and Introduction to Riemannian Manifolds (Second Edition), (ISM and IRM, respectively). In ISM Chapter 3 section Velocity Vectors of Curves on page 68, he defines the domain of a curve to be an interval $J$ , most of the time open, but sometimes with one or two endpoints. The rest of the section (defining velocity vectors of smooth curves) makes perfect sense with any kind of interval $J$ . Then we get to ISM Chapter 9, the section on Integral Curves on page 206, in which we deal with ""differentiable"" (I assume that is to be taken to be the same as smooth) curves, but no mention is made of what kind of interval they are defined on. But that's fine; I can deal with them being defined on intervals with zero, one or two endpoints, up until page 212 when a maximal integral curve is defined as ""one that cannot be extended to an integral curve on any larger open interval (emphasis added)"". This is followed by the Fundamental Theorem on Flows , in which property (a) states that $$\theta^{(p)}\colon\mathscr{D}^{(p)}\to M$$ is the ""unique smooth maximal integral curve of $V$ starting at $p$ ."" [In this context, $\mathscr{D}^{(p)}$ is an open interval.] So now I have a question. The definition of maximal integral curve and the theorem work fine if integral curves are defined only on open intervals. But if they can be defined on intervals with one or two endpoints, then I imagine there could be a problem where there were two different integral curves, one defined on an open interval and one defined on that interval plus an endpoint, say, having the same values on the open interval, but not being extendable any further. Then both curves would have to be considered to be maximal, thus breaking uniqueness. So here's the question finally. This theorem is for smooth manifolds without boundary. Is that sufficient to show that what I just described can't happen? I know of two ways that an integral curve might not be extendable: if it blows up at the endpoint or if it runs into the boundary. If there is no boundary and if it can be extended to an endpoint, then it is not blowing up at the endpoint, and it can be extended further (waving hands furiously here). So is there any other way that an integral curve can be prevented from extending? If not, can I safely assume that maximal integral curves (into smooth manifolds without boundary) are necessarily defined on open intervals? The reason I mentioned IRM is I also would like to know if assuming that maximal integral curves are always defined on open intervals will get me into trouble in IRM.","I'm studying Professor Lee's Introduction to Smooth Manifolds (Second Edition) and Introduction to Riemannian Manifolds (Second Edition), (ISM and IRM, respectively). In ISM Chapter 3 section Velocity Vectors of Curves on page 68, he defines the domain of a curve to be an interval , most of the time open, but sometimes with one or two endpoints. The rest of the section (defining velocity vectors of smooth curves) makes perfect sense with any kind of interval . Then we get to ISM Chapter 9, the section on Integral Curves on page 206, in which we deal with ""differentiable"" (I assume that is to be taken to be the same as smooth) curves, but no mention is made of what kind of interval they are defined on. But that's fine; I can deal with them being defined on intervals with zero, one or two endpoints, up until page 212 when a maximal integral curve is defined as ""one that cannot be extended to an integral curve on any larger open interval (emphasis added)"". This is followed by the Fundamental Theorem on Flows , in which property (a) states that is the ""unique smooth maximal integral curve of starting at ."" [In this context, is an open interval.] So now I have a question. The definition of maximal integral curve and the theorem work fine if integral curves are defined only on open intervals. But if they can be defined on intervals with one or two endpoints, then I imagine there could be a problem where there were two different integral curves, one defined on an open interval and one defined on that interval plus an endpoint, say, having the same values on the open interval, but not being extendable any further. Then both curves would have to be considered to be maximal, thus breaking uniqueness. So here's the question finally. This theorem is for smooth manifolds without boundary. Is that sufficient to show that what I just described can't happen? I know of two ways that an integral curve might not be extendable: if it blows up at the endpoint or if it runs into the boundary. If there is no boundary and if it can be extended to an endpoint, then it is not blowing up at the endpoint, and it can be extended further (waving hands furiously here). So is there any other way that an integral curve can be prevented from extending? If not, can I safely assume that maximal integral curves (into smooth manifolds without boundary) are necessarily defined on open intervals? The reason I mentioned IRM is I also would like to know if assuming that maximal integral curves are always defined on open intervals will get me into trouble in IRM.",J J \theta^{(p)}\colon\mathscr{D}^{(p)}\to M V p \mathscr{D}^{(p)},"['differential-geometry', 'smooth-manifolds']"
1,How do I deal with the basis in the proof of Lemma 1.10 in Introduction to smooth manifolds by John Lee?,How do I deal with the basis in the proof of Lemma 1.10 in Introduction to smooth manifolds by John Lee?,,"This is Lemma 1.10 in Introduction to smooth manifolds by John Lee , 2nd edition. Lemma 1.10. Every topological manifold has a countable basis of precompact coordinate balls. Proof . Let $M$ be a topological $n$ -manifold. First we consider the special case in which $M$ can be covered by a single chart. Suppose $\varphi: M \to \hat U \subseteq \mathbb{R}^n$ is a global coordinate map, and let $\mathscr{B}$ be the collection of all open balls $B_r(x)\subseteq  \mathbb{R}^n$ such that $r$ is rational, $x$ has rational coordinates, and $B_{r'}(x)\subseteq  \hat U$ for some $r' > r$ . Each such ball is precompact in $\hat U$ , and it is easy to check that $\mathscr{B}$ is a countable basis for the topology of $\hat U$ . Because $\varphi$ is a homeomorphism, it follows that the collection of sets of the form $ \varphi^{-1}(B)$ for $ B \in \mathscr{B}$ is a countable basis for the topology of $M$ ; consisting of precompact coordinate balls, with the restrictions of $\varphi$ as coordinate maps. My question is about checking  that the $ \varphi^{-1}(B)$ for $ B \in \mathscr{B}$ are a countable basis for the topology of $M$ First of all is it correct that to prove that a set is a basis of a topology it suffices to prove that the any element of the topology is a union of element of basis elements? According to wikipedia the following is the definition. But I think I have read proofs were they just do as I described. Are they equivalent definitions? About the question I guess I can prove it like this: Let $\mathscr{B}$ be a basis for the topology of $\hat U$ . Let $U \in \tau_M$ , then $ \varphi(U) \in \tau_{\hat U}$ , because $\varphi$ is a homeomorphism  and $\varphi(U)=\bigcup_{i \in I}B_i,  B_i \in \mathscr{B}  \implies U = \varphi^{-1}(\bigcup_{i \in I}B_i)=\bigcup_{i \in I}\varphi^{-1}(B_i) $ and since I have written any open set of $\tau_M$ as union of elements of $\{\varphi^{-1}(B):, B \in  \mathscr{B} \}$ , this last set is a basis for $\tau_M$ . Is this correct? Thank you!","This is Lemma 1.10 in Introduction to smooth manifolds by John Lee , 2nd edition. Lemma 1.10. Every topological manifold has a countable basis of precompact coordinate balls. Proof . Let be a topological -manifold. First we consider the special case in which can be covered by a single chart. Suppose is a global coordinate map, and let be the collection of all open balls such that is rational, has rational coordinates, and for some . Each such ball is precompact in , and it is easy to check that is a countable basis for the topology of . Because is a homeomorphism, it follows that the collection of sets of the form for is a countable basis for the topology of ; consisting of precompact coordinate balls, with the restrictions of as coordinate maps. My question is about checking  that the for are a countable basis for the topology of First of all is it correct that to prove that a set is a basis of a topology it suffices to prove that the any element of the topology is a union of element of basis elements? According to wikipedia the following is the definition. But I think I have read proofs were they just do as I described. Are they equivalent definitions? About the question I guess I can prove it like this: Let be a basis for the topology of . Let , then , because is a homeomorphism  and and since I have written any open set of as union of elements of , this last set is a basis for . Is this correct? Thank you!","M n M \varphi: M \to \hat U \subseteq \mathbb{R}^n \mathscr{B} B_r(x)\subseteq  \mathbb{R}^n r x B_{r'}(x)\subseteq  \hat U r' > r \hat U \mathscr{B} \hat U \varphi  \varphi^{-1}(B)  B \in \mathscr{B} M \varphi  \varphi^{-1}(B)  B \in \mathscr{B} M \mathscr{B} \hat U U \in \tau_M  \varphi(U) \in \tau_{\hat U} \varphi \varphi(U)=\bigcup_{i \in I}B_i,  B_i \in \mathscr{B}  \implies U = \varphi^{-1}(\bigcup_{i \in I}B_i)=\bigcup_{i \in I}\varphi^{-1}(B_i)  \tau_M \{\varphi^{-1}(B):, B \in  \mathscr{B} \} \tau_M","['general-topology', 'differential-geometry', 'manifolds']"
2,Can a smooth manifold be embedded into its tangent bundle?,Can a smooth manifold be embedded into its tangent bundle?,,"Given a smooth $n$ -dimensional manifold $M$ , one can always find an immersion into its tangent bundle $TM$ by looking at the zero-section, i.e. the map that sends $p\in M$ to $(p,0)\in TM$ . One can see this is an immersion for example by writing everything in local coordinates and checking that this is locally an inclusion. Can it be proved that this is also an embedding? (i.e. a homeomorphism onto its image). It seems intuitively clear to me that this should be true because ""the tangent bundle has a copy of $M$ inside"" but I can't find a way to prove or disprove it. Could you help me?","Given a smooth -dimensional manifold , one can always find an immersion into its tangent bundle by looking at the zero-section, i.e. the map that sends to . One can see this is an immersion for example by writing everything in local coordinates and checking that this is locally an inclusion. Can it be proved that this is also an embedding? (i.e. a homeomorphism onto its image). It seems intuitively clear to me that this should be true because ""the tangent bundle has a copy of inside"" but I can't find a way to prove or disprove it. Could you help me?","n M TM p\in M (p,0)\in TM M","['differential-geometry', 'smooth-manifolds', 'submanifold', 'tangent-bundle']"
3,(Pseudo-)tensor densities as sections of bundles,(Pseudo-)tensor densities as sections of bundles,,In the wiki article on tensor densities ( https://en.wikipedia.org/wiki/Tensor_density ) it is mentioned that this notion may be understood in terms of sections of tensor product of the density bundle with tensor bundles. I would like to clarify if I am correct in thinking that (due to the determinant in transition functions being/not being taken with absoulte value) this only works for pseudotensor densities -- tensor densities are instead sections of tensor product of just the determinant bundle with tensor bundles?,In the wiki article on tensor densities ( https://en.wikipedia.org/wiki/Tensor_density ) it is mentioned that this notion may be understood in terms of sections of tensor product of the density bundle with tensor bundles. I would like to clarify if I am correct in thinking that (due to the determinant in transition functions being/not being taken with absoulte value) this only works for pseudotensor densities -- tensor densities are instead sections of tensor product of just the determinant bundle with tensor bundles?,,"['differential-geometry', 'tensors']"
4,Gradient of a higher Lie derivative of a composite function,Gradient of a higher Lie derivative of a composite function,,"Although there are some formulations of the gradient of the $k$ -th Lie derivative of a function composition $g\circ h$ with respect to $\bf x$ on the vector field $\bf f$ in the literature, I am trying to prove the following pattern for any $k$ . $$ \nabla L_{\bf f}^k(g\circ h) \stackrel{?}{=}\sum_{i=0}^{k}{k \choose i}L_{\bf f}^{k-i}(g'\circ h) \nabla L_{\bf f}^ih $$ This pattern is the second and more reasonable one I came up with after being able to write down the following equalities using brute force. \begin{align} \frac{\partial L_\mathbf{f}(g\circ h)}{\partial x_i}=&     \frac{\partial g}{\partial h}\frac{\partial L_\mathbf{f}h}{\partial x_i}+L_\mathbf{f}(\frac{\partial g}{\partial h})\frac{\partial h}{\partial x_i}\\ \frac{\partial L_\mathbf{f}^2(g\circ h)}{\partial x_i}=&     \frac{\partial g}{\partial h}\frac{\partial L_\mathbf{f}^2h}{\partial x_i}+L_\mathbf{f}^2(\frac{\partial g}{\partial h})\frac{\partial h}{\partial x_i}+2L_\mathbf{f}(\frac{\partial g}{\partial h})\frac{\partial L_\mathbf{f}h}{\partial x_i}\\ \frac{\partial L_\mathbf{f}^3(g\circ h)}{\partial x_i}=&     \frac{\partial g}{\partial h}\frac{\partial L_\mathbf{f}^3h}{\partial x_i}+L_\mathbf{f}^3(\frac{\partial g}{\partial h})\frac{\partial h}{\partial x_i}+3L_\mathbf{f}^2(\frac{\partial g}{\partial h})\frac{\partial L_\mathbf{f}h}{\partial x_i}+3L_\mathbf{f}(\frac{\partial g}{\partial h})\frac{\partial L_\mathbf{f}^2h}{\partial x_i}&& \end{align} I would appreciate any help to show that the conjecture above is true/false. Notation $\nabla$ is the gradient operator such that \begin{align}     \nabla \phi = \left(         \begin{matrix}             \frac{\partial \phi}{\partial x_1}&             \frac{\partial \phi}{\partial x_2}&             \cdots&             \frac{\partial \phi}{\partial x_n}         \end{matrix}         \right)^\top,\nonumber \end{align} for some function $\phi:\mathbb{ R}\rightarrow\mathbb{ R}$ with respect to a coordinate system $(x_1, x_2, \dots, x_n)$ . The Lie derivative of a function $h:\mathbb{ R}^n\rightarrow \mathbb{ R}$ with respect to a vector field $f:\mathbb{ R}^n\rightarrow \mathbb{ R}^n$ is \begin{align}     L_{\bf f}(h) := \nabla h \cdot f\,. \nonumber \end{align} One can calculate the $k$ -th Lie derivative of $h$ recursively via \begin{align}     L^k_{\bf f}(h)=L_{\bf f}L^{k-1}_{\bf f}(h)\,.\nonumber \end{align} We use $g\circ h$ to denote the composition of the functions $h:\mathbb{ R}^n\rightarrow \mathbb{ R}$ and $g:\mathbb{ R}\rightarrow \mathbb{ R}$ . We assume that $g$ , $h$ , and the vector-valued function $f$ are at least $k$ times differentiable. We use $g'$ or $g^{(1)}$ to denote the first derivative of $g$ with respect to $h$ . The $j$ -th derivative of $g$ is $g^{(j)}$ and $g^{(0)}=g$ . The expression $g'\circ h$ has the same meaning as the expression $\partial g/\partial h$ .","Although there are some formulations of the gradient of the -th Lie derivative of a function composition with respect to on the vector field in the literature, I am trying to prove the following pattern for any . This pattern is the second and more reasonable one I came up with after being able to write down the following equalities using brute force. I would appreciate any help to show that the conjecture above is true/false. Notation is the gradient operator such that for some function with respect to a coordinate system . The Lie derivative of a function with respect to a vector field is One can calculate the -th Lie derivative of recursively via We use to denote the composition of the functions and . We assume that , , and the vector-valued function are at least times differentiable. We use or to denote the first derivative of with respect to . The -th derivative of is and . The expression has the same meaning as the expression .","k g\circ h \bf x \bf f k 
\nabla L_{\bf f}^k(g\circ h) \stackrel{?}{=}\sum_{i=0}^{k}{k \choose i}L_{\bf f}^{k-i}(g'\circ h) \nabla L_{\bf f}^ih
 \begin{align}
\frac{\partial L_\mathbf{f}(g\circ h)}{\partial x_i}=&     \frac{\partial g}{\partial h}\frac{\partial L_\mathbf{f}h}{\partial x_i}+L_\mathbf{f}(\frac{\partial g}{\partial h})\frac{\partial h}{\partial x_i}\\
\frac{\partial L_\mathbf{f}^2(g\circ h)}{\partial x_i}=&     \frac{\partial g}{\partial h}\frac{\partial L_\mathbf{f}^2h}{\partial x_i}+L_\mathbf{f}^2(\frac{\partial g}{\partial h})\frac{\partial h}{\partial x_i}+2L_\mathbf{f}(\frac{\partial g}{\partial h})\frac{\partial L_\mathbf{f}h}{\partial x_i}\\
\frac{\partial L_\mathbf{f}^3(g\circ h)}{\partial x_i}=&     \frac{\partial g}{\partial h}\frac{\partial L_\mathbf{f}^3h}{\partial x_i}+L_\mathbf{f}^3(\frac{\partial g}{\partial h})\frac{\partial h}{\partial x_i}+3L_\mathbf{f}^2(\frac{\partial g}{\partial h})\frac{\partial L_\mathbf{f}h}{\partial x_i}+3L_\mathbf{f}(\frac{\partial g}{\partial h})\frac{\partial L_\mathbf{f}^2h}{\partial x_i}&&
\end{align} \nabla \begin{align}
    \nabla \phi = \left(
        \begin{matrix}
            \frac{\partial \phi}{\partial x_1}&
            \frac{\partial \phi}{\partial x_2}&
            \cdots&
            \frac{\partial \phi}{\partial x_n}
        \end{matrix}
        \right)^\top,\nonumber
\end{align} \phi:\mathbb{ R}\rightarrow\mathbb{ R} (x_1, x_2, \dots, x_n) h:\mathbb{ R}^n\rightarrow \mathbb{ R} f:\mathbb{ R}^n\rightarrow \mathbb{ R}^n \begin{align}
    L_{\bf f}(h) := \nabla h \cdot f\,. \nonumber
\end{align} k h \begin{align}
    L^k_{\bf f}(h)=L_{\bf f}L^{k-1}_{\bf f}(h)\,.\nonumber
\end{align} g\circ h h:\mathbb{ R}^n\rightarrow \mathbb{ R} g:\mathbb{ R}\rightarrow \mathbb{ R} g h f k g' g^{(1)} g h j g g^{(j)} g^{(0)}=g g'\circ h \partial g/\partial h","['combinatorics', 'differential-geometry', 'lie-algebras', 'lie-derivative']"
5,Hodge star operator : inner product of $k$-forms independent of orthogonal frames,Hodge star operator : inner product of -forms independent of orthogonal frames,k,"I'm trying to work out John Lee's Introduction to Smooth Manifolds problem 16-18 about the definition of Hodge star operator, but mainly subproblem (a), I can prove the rest of them assuming the property of (a). Problem (a) asks you to prove that for each $k=1,\cdots n$ , the Riemannian metric $g$ uniquely determines an inner product on $\Lambda^k T^*_p M$ which satisfies $$\langle \omega^1 \wedge \cdots \wedge \omega^k, \tau^1 \wedge \cdots\tau^k \rangle=\mathrm{det}(\langle(\omega^i)^\sharp,(\tau^j)^\sharp\rangle)$$ where $\omega^1, \cdots, \omega^k,\tau^1, \cdots, \tau^k$ are covectors at $p$ . The hint is to define inner product locally by declaring $\{\varepsilon^I|_p :I$ is increasing $\}$ to be an orthonormal frame, whenever $(\varepsilon^i)$ is the coframe dual to a local orthonormal frame. Here is what I tried following the hint: Every $k$ -form locally can be uniquely written as $\alpha=\sum_{I \nearrow}a_I\varepsilon^I$ where $I$ is an increasing multi-index of length $k$ . If we have another $k$ -form $\beta=\sum_{I \nearrow}b_I\varepsilon^I$ , we define $$\langle\alpha,\beta\rangle=\sum_{I \nearrow}a_Ib_I$$ We must prove the above definition is independent of the choice of coframe: If $(\varepsilon^i)$ and $(\eta^i)$ are two coframes, each of which is dual to an orthonormal frame, $\alpha=\sum_{I \nearrow}a_I\varepsilon^I=\sum_{I \nearrow}a_I^\prime\eta^I$ , $\beta=\sum_{I \nearrow}b_I\varepsilon^I=\sum_{I \nearrow}b_I^\prime\eta^I$ , then $\sum_{I \nearrow}a_Ib_I=\sum_{I \nearrow}a_I^\prime b_I^\prime$ . Suppose $$(\varepsilon^1,\cdots,\varepsilon^n)=(\eta^1,\cdots,\eta^n)\begin{pmatrix} q^1_1 & \cdots   & q^n_1 \\ \vdots  & &\vdots \\q^1_n &\cdots &q^n_n\end{pmatrix}$$ where the matrix $Q=(q^j_i)$ is orthogonal, therefore $\varepsilon^k=\eta^i q^k_i$ . Substituting $\varepsilon=\varepsilon^{i_1}\wedge\cdots\wedge\varepsilon^{i_k}$ , we have $$\alpha = \sum_{I \nearrow}a_I^\prime\eta^I=\sum_{I \nearrow}a_I(\sum^n_{j=1}\eta^j q^{i_1}_j\wedge\cdots \wedge \sum^n_{j=1}\eta^j q^{i_k}_j)$$ Fix an multi-index $L=(l_1,\cdots, l_k)$ and compare the coefficients of $\eta^L$ , we have $$a_L^\prime=(\sum_{I \nearrow}a_I \sum_{\sigma \in S_k}(-1)^{\mathrm{sgn}\sigma}q^{i_{\sigma(1)}}_{l_1}\cdots q^{i_{\sigma(k)}}_{l_k})=\sum_{I \nearrow}a_I Q(L,I)$$ where $Q(L,I)$ denotes the minor of $Q$ of row $L$ and column $I$ . By the same argument we have $b_L^\prime=\sum_{I \nearrow}b_I Q(L,I)$ . So finally what we have to prove is (if I did't make calculation mistakes) given an orthogonal matrix $Q$ and real numbers $a_I,b_I$ , $$\sum_{I \nearrow} a_I b_I=\sum_{(I \nearrow}(\sum_{J \nearrow}a_J Q(I,J))(\sum_{J \nearrow}b_J Q(I,J)))$$ which seems like a tricky linear algebra problem. Do you have any ideas about this, or just give another approach. Thanks in advance.","I'm trying to work out John Lee's Introduction to Smooth Manifolds problem 16-18 about the definition of Hodge star operator, but mainly subproblem (a), I can prove the rest of them assuming the property of (a). Problem (a) asks you to prove that for each , the Riemannian metric uniquely determines an inner product on which satisfies where are covectors at . The hint is to define inner product locally by declaring is increasing to be an orthonormal frame, whenever is the coframe dual to a local orthonormal frame. Here is what I tried following the hint: Every -form locally can be uniquely written as where is an increasing multi-index of length . If we have another -form , we define We must prove the above definition is independent of the choice of coframe: If and are two coframes, each of which is dual to an orthonormal frame, , , then . Suppose where the matrix is orthogonal, therefore . Substituting , we have Fix an multi-index and compare the coefficients of , we have where denotes the minor of of row and column . By the same argument we have . So finally what we have to prove is (if I did't make calculation mistakes) given an orthogonal matrix and real numbers , which seems like a tricky linear algebra problem. Do you have any ideas about this, or just give another approach. Thanks in advance.","k=1,\cdots n g \Lambda^k T^*_p M \langle \omega^1 \wedge \cdots \wedge \omega^k, \tau^1 \wedge \cdots\tau^k \rangle=\mathrm{det}(\langle(\omega^i)^\sharp,(\tau^j)^\sharp\rangle) \omega^1, \cdots, \omega^k,\tau^1, \cdots, \tau^k p \{\varepsilon^I|_p :I \} (\varepsilon^i) k \alpha=\sum_{I \nearrow}a_I\varepsilon^I I k k \beta=\sum_{I \nearrow}b_I\varepsilon^I \langle\alpha,\beta\rangle=\sum_{I \nearrow}a_Ib_I (\varepsilon^i) (\eta^i) \alpha=\sum_{I \nearrow}a_I\varepsilon^I=\sum_{I \nearrow}a_I^\prime\eta^I \beta=\sum_{I \nearrow}b_I\varepsilon^I=\sum_{I \nearrow}b_I^\prime\eta^I \sum_{I \nearrow}a_Ib_I=\sum_{I \nearrow}a_I^\prime b_I^\prime (\varepsilon^1,\cdots,\varepsilon^n)=(\eta^1,\cdots,\eta^n)\begin{pmatrix} q^1_1 & \cdots 
 & q^n_1 \\ \vdots 
& &\vdots \\q^1_n &\cdots &q^n_n\end{pmatrix} Q=(q^j_i) \varepsilon^k=\eta^i q^k_i \varepsilon=\varepsilon^{i_1}\wedge\cdots\wedge\varepsilon^{i_k} \alpha = \sum_{I \nearrow}a_I^\prime\eta^I=\sum_{I \nearrow}a_I(\sum^n_{j=1}\eta^j q^{i_1}_j\wedge\cdots \wedge \sum^n_{j=1}\eta^j q^{i_k}_j) L=(l_1,\cdots, l_k) \eta^L a_L^\prime=(\sum_{I \nearrow}a_I \sum_{\sigma \in S_k}(-1)^{\mathrm{sgn}\sigma}q^{i_{\sigma(1)}}_{l_1}\cdots q^{i_{\sigma(k)}}_{l_k})=\sum_{I \nearrow}a_I Q(L,I) Q(L,I) Q L I b_L^\prime=\sum_{I \nearrow}b_I Q(L,I) Q a_I,b_I \sum_{I \nearrow} a_I b_I=\sum_{(I \nearrow}(\sum_{J \nearrow}a_J Q(I,J))(\sum_{J \nearrow}b_J Q(I,J)))","['linear-algebra', 'matrices', 'differential-geometry', 'manifolds', 'exterior-algebra']"
6,Can any two points in the plane be assigned continuously a path between them that is transversal to two circles?,Can any two points in the plane be assigned continuously a path between them that is transversal to two circles?,,"More formally, I'm interested in continous functions $$\Gamma : \mathbb{R}^2\times \mathbb{R}^2 \to ([0,1] \to \mathbb{R}^2)$$ such that $\Gamma(p,q)(0)=p$ and $\Gamma(p,q)(1)=q$ , with the additional condition that for every $(p,q)\in \mathbb{R}^2\times \mathbb{R}^2$ , we have that $\Gamma(p,q) \pitchfork X$ , where $X$ is two circles of radius 1 centered in $(-2,0)$ and $(2,0)$ . For the transversality condition to make sense, we require that $\Gamma(p,q)$ is smooth. It can be seen that when $X$ is just one circle, this can be done, by composing the path that takes $p$ to the origin, and then goes back to $q$ . Sadly, the same trick can't be applied to the two circles, at least as far as I can see. I suspect there is no function that satisfies these requirements, but I have not been able to show this. I'm interested in this as it's a special case of topological complexity , and may give a strictly greater upper bound. Edit: I'm assuming the compact open topology on $[0,1] \to \mathbb{R}^2$ .","More formally, I'm interested in continous functions such that and , with the additional condition that for every , we have that , where is two circles of radius 1 centered in and . For the transversality condition to make sense, we require that is smooth. It can be seen that when is just one circle, this can be done, by composing the path that takes to the origin, and then goes back to . Sadly, the same trick can't be applied to the two circles, at least as far as I can see. I suspect there is no function that satisfies these requirements, but I have not been able to show this. I'm interested in this as it's a special case of topological complexity , and may give a strictly greater upper bound. Edit: I'm assuming the compact open topology on .","\Gamma : \mathbb{R}^2\times \mathbb{R}^2 \to ([0,1] \to \mathbb{R}^2) \Gamma(p,q)(0)=p \Gamma(p,q)(1)=q (p,q)\in \mathbb{R}^2\times \mathbb{R}^2 \Gamma(p,q) \pitchfork X X (-2,0) (2,0) \Gamma(p,q) X p q [0,1] \to \mathbb{R}^2","['differential-geometry', 'differential-topology']"
7,Covariant Derivative of Matrix Times Vector,Covariant Derivative of Matrix Times Vector,,"Good evening! I was wondering if one could prove some sort of ""product rule"" for the covariant derivative by using parallel transport: Let $(M,g)$ be a Riemannian manifold, then it is known that a connection $\nabla$ is uniquely characterized by its parallel transport via $$(\nabla_\xi X)_x = \left.\frac{d}{d t}\right|_{t=0} P^\gamma_{t,0}(X(\gamma(t))) = \lim\limits_{t\rightarrow 0} \frac{P_{t,0}^\gamma (X(\gamma(t))) - X(x)}{t},$$ where $P_{t,0}^\gamma$ denotes the (reverse) parallel transport of a vector field $X\in \Gamma TM$ along the geodesic $\gamma:\mathbb{R}\longrightarrow M$ with $\gamma(0)=x$ and $\dot\gamma(0)=\xi$ for a $\xi\in T_x M$ , $x\in M$ . Now, for a $J\in \Gamma\operatorname{End}(TM)$ , my idea was to insert a useful zero like in the proof of the regular product rule: \begin{align*}(\nabla_\xi JX)_x &= \lim\limits_{t\rightarrow 0} \frac{P_{t,0}^\gamma (J(\gamma(t))X(\gamma(t))) - J(x)X(x)}{t}\\ &= \lim\limits_{t\rightarrow 0} \frac{P_{t,0}^\gamma (J(\gamma(t))X(\gamma(t))) - J(x)P_{t,0}^\gamma(X(\gamma(t)))+J(x)P_{t,0}^\gamma(X(\gamma(t))) -J(x)X(x)}{t}\\ &= \lim\limits_{t\rightarrow 0} \frac{[P_{t,0}^\gamma (J(\gamma(t))X(\gamma(t))) - J(x)P_{t,0}^\gamma(X(\gamma(t)))]+J(x)[P_{t,0}^\gamma(X(\gamma(t))) -X(x)]}{t}\\ &= \lim\limits_{t\rightarrow 0} \frac{[P_{t,0}^\gamma (J(\gamma(t))X(\gamma(t))) - J(x)P_{t,0}^\gamma(X(\gamma(t)))]}{t}+J(x)(\nabla_\xi X)(x) \end{align*} However, even though the right term is exactly what one wants, I don't see how the term on the left can be brought into the form $$\lim\limits_{t\rightarrow 0} \frac{[P_{t,0}^\gamma (J(\gamma(t))) - J(x)]}{t}X(x) = (\nabla_\xi J)_x X(x).$$ So, was my idea just useless? Or does anyone see a way to save this attempt?","Good evening! I was wondering if one could prove some sort of ""product rule"" for the covariant derivative by using parallel transport: Let be a Riemannian manifold, then it is known that a connection is uniquely characterized by its parallel transport via where denotes the (reverse) parallel transport of a vector field along the geodesic with and for a , . Now, for a , my idea was to insert a useful zero like in the proof of the regular product rule: However, even though the right term is exactly what one wants, I don't see how the term on the left can be brought into the form So, was my idea just useless? Or does anyone see a way to save this attempt?","(M,g) \nabla (\nabla_\xi X)_x = \left.\frac{d}{d t}\right|_{t=0} P^\gamma_{t,0}(X(\gamma(t))) = \lim\limits_{t\rightarrow 0} \frac{P_{t,0}^\gamma (X(\gamma(t))) - X(x)}{t}, P_{t,0}^\gamma X\in \Gamma TM \gamma:\mathbb{R}\longrightarrow M \gamma(0)=x \dot\gamma(0)=\xi \xi\in T_x M x\in M J\in \Gamma\operatorname{End}(TM) \begin{align*}(\nabla_\xi JX)_x &= \lim\limits_{t\rightarrow 0} \frac{P_{t,0}^\gamma (J(\gamma(t))X(\gamma(t))) - J(x)X(x)}{t}\\
&= \lim\limits_{t\rightarrow 0} \frac{P_{t,0}^\gamma (J(\gamma(t))X(\gamma(t))) - J(x)P_{t,0}^\gamma(X(\gamma(t)))+J(x)P_{t,0}^\gamma(X(\gamma(t))) -J(x)X(x)}{t}\\
&= \lim\limits_{t\rightarrow 0} \frac{[P_{t,0}^\gamma (J(\gamma(t))X(\gamma(t))) - J(x)P_{t,0}^\gamma(X(\gamma(t)))]+J(x)[P_{t,0}^\gamma(X(\gamma(t))) -X(x)]}{t}\\
&= \lim\limits_{t\rightarrow 0} \frac{[P_{t,0}^\gamma (J(\gamma(t))X(\gamma(t))) - J(x)P_{t,0}^\gamma(X(\gamma(t)))]}{t}+J(x)(\nabla_\xi X)(x)
\end{align*} \lim\limits_{t\rightarrow 0} \frac{[P_{t,0}^\gamma (J(\gamma(t))) - J(x)]}{t}X(x) = (\nabla_\xi J)_x X(x).","['differential-geometry', 'riemannian-geometry']"
8,"Showing that $k^*(H_f)\lrcorner k^*\sigma=k^*(H_f\lrcorner\sigma)$for symplectomorphism $k$, contraction $\lrcorner$ and symplectic product $\sigma$","Showing that for symplectomorphism , contraction  and symplectic product",k^*(H_f)\lrcorner k^*\sigma=k^*(H_f\lrcorner\sigma) k \lrcorner \sigma,"Showing that $k^*(H_f)\lrcorner k^*\sigma=k^*(H_f\lrcorner\sigma)$ for symplectomorphism $k$ , contraction $\lrcorner$ and symplectic product $\sigma$ Definitions: Let $f:\mathbb{R}^n\to \mathbb{R}^n$ be a smooth mapping and $Jf$ be the Jacobian of $f$ . Then if $\nu$ is an $m$ -form on $\mathbb{R}^n$ , the pullback of $\nu$ by $f$ is defined as $(f^*\nu)(w) = \nu(Jf w_1,\dots,Jf w_m)$ for $w \in (\mathbb{R}^n)^m$ . Let $\alpha = (x, \xi), \beta = (y, \nu) \in \mathbb{R}^{2n}$ . Then the symplectic product between $\alpha$ and $\beta$ is defined as $\sigma(\alpha, \beta) = \left<\xi, y\right> - \left<\nu, x\right>$ . Let $k:\mathbb{R}^{2n}\to \mathbb{R}^{2n}$ . Then $k$ is said to be a symplectomorphism , if $k^*\sigma = \sigma$ . Let $\nu$ is a differential $m$ -form and $X$ be a vector field. Then, the contraction of $\nu$ by $X$ is defined as the $(m-1)$ -form $(X\lrcorner \nu)(w) = \nu(X, w), w \in (\mathbb{R}^n)^{m-1}$ . Let $f$ be a smooth function defined on $\mathbb{R}^{2n}$ . Then the Hamiltonian vector field $H_f$ is a vector field such that $\forall w \in \mathbb{R}^{2n}:\sigma(w, H_f) = df(w)$ where $d$ is the differential 1-form. Preamble: I am trying to understand an intermediary step in a proof for Jacobi's theorem, that is $H_f = k_*(H_{k^*}f)$ , where one needs the equality $k^*(H_f)\lrcorner k^*\sigma = k^*(H_f\lrcorner \sigma)$ . If I write out the LHS I get $(k^*(H_f)\lrcorner k^*\sigma)(w) = k^*\sigma(k^*(H_f), w) = \sigma(k^*(H_f), w) = -\sigma(w, H_f \circ Jk)$ ( $\sigma$ is antisymmetric), where I am not sure how to either ""move"" the $Jk$ or argue why $H_f \circ Jk$ is necessarily a Hamiltonian vector field. The RHS evaluates nicely to $(k^*(H_f\lrcorner \sigma))(w) = (H_f\lrcorner \sigma)(Jk w) = \sigma(H_f, Jk w) = -\sigma(Jk w, H_f) = -df(Jk w)$ . Question: Is there a neat way to show the equality $k^*(H_f)\lrcorner k^*\sigma=k^*(H_f\lrcorner\sigma)$ ? If there is, what is it? My current approach radiates guess-and-check ness rather than intelligent observations.","Showing that for symplectomorphism , contraction and symplectic product Definitions: Let be a smooth mapping and be the Jacobian of . Then if is an -form on , the pullback of by is defined as for . Let . Then the symplectic product between and is defined as . Let . Then is said to be a symplectomorphism , if . Let is a differential -form and be a vector field. Then, the contraction of by is defined as the -form . Let be a smooth function defined on . Then the Hamiltonian vector field is a vector field such that where is the differential 1-form. Preamble: I am trying to understand an intermediary step in a proof for Jacobi's theorem, that is , where one needs the equality . If I write out the LHS I get ( is antisymmetric), where I am not sure how to either ""move"" the or argue why is necessarily a Hamiltonian vector field. The RHS evaluates nicely to . Question: Is there a neat way to show the equality ? If there is, what is it? My current approach radiates guess-and-check ness rather than intelligent observations.","k^*(H_f)\lrcorner k^*\sigma=k^*(H_f\lrcorner\sigma) k \lrcorner \sigma f:\mathbb{R}^n\to \mathbb{R}^n Jf f \nu m \mathbb{R}^n \nu f (f^*\nu)(w) = \nu(Jf w_1,\dots,Jf w_m) w \in (\mathbb{R}^n)^m \alpha = (x, \xi), \beta = (y, \nu) \in \mathbb{R}^{2n} \alpha \beta \sigma(\alpha, \beta) = \left<\xi, y\right> - \left<\nu, x\right> k:\mathbb{R}^{2n}\to \mathbb{R}^{2n} k k^*\sigma = \sigma \nu m X \nu X (m-1) (X\lrcorner \nu)(w) = \nu(X, w), w \in (\mathbb{R}^n)^{m-1} f \mathbb{R}^{2n} H_f \forall w \in \mathbb{R}^{2n}:\sigma(w, H_f) = df(w) d H_f = k_*(H_{k^*}f) k^*(H_f)\lrcorner k^*\sigma = k^*(H_f\lrcorner \sigma) (k^*(H_f)\lrcorner k^*\sigma)(w) = k^*\sigma(k^*(H_f), w) = \sigma(k^*(H_f), w) = -\sigma(w, H_f \circ Jk) \sigma Jk H_f \circ Jk (k^*(H_f\lrcorner \sigma))(w) = (H_f\lrcorner \sigma)(Jk w) = \sigma(H_f, Jk w) = -\sigma(Jk w, H_f) = -df(Jk w) k^*(H_f)\lrcorner k^*\sigma=k^*(H_f\lrcorner\sigma)","['linear-algebra', 'differential-geometry', 'differential-forms', 'symplectic-geometry', 'symplectic-linear-algebra']"
9,Curvature of an Embedded Curve,Curvature of an Embedded Curve,,"If one has a a compact Riemannian surface $\Sigma$ (ie. a Riemannian manifold of dimension $2$ ), the Ricci curvature can be written as $R_{ij} = \frac{1}{2} R g_{ij}$ . In other words, the curvature can be expressed by one single function.  The scalar curvature is equal to double the Gaussian curvature $K$ , so one can also re-write $R_{ij} = K g_{ij}$ . Does this mean that the curvature of a smooth embedded close curve in $\Sigma$ is also determined by the Gaussian curvature $K$ for the surface by Gauss-Bonnet theorem?","If one has a a compact Riemannian surface (ie. a Riemannian manifold of dimension ), the Ricci curvature can be written as . In other words, the curvature can be expressed by one single function.  The scalar curvature is equal to double the Gaussian curvature , so one can also re-write . Does this mean that the curvature of a smooth embedded close curve in is also determined by the Gaussian curvature for the surface by Gauss-Bonnet theorem?",\Sigma 2 R_{ij} = \frac{1}{2} R g_{ij} K R_{ij} = K g_{ij} \Sigma K,"['differential-geometry', 'curves', 'surfaces', 'curvature']"
10,How to find points on a curve whose tangent line pass through a specified point?,How to find points on a curve whose tangent line pass through a specified point?,,"Now we have a compact closed simple smooth curve in $\Bbb R^2$ and the curve's bounding box is known. But the curve is given implicitly by a signed distance function $f(x, y)$ . Note that we don't have a global formula for $f(x, y)$ , but we can sample $f(x, y)$ at arbitrary points. definition of signed distance function can be found here The question is: Given a point $P$ , how can we find all the points on the curve whose tangent line pass through $P$ . Can you give me an algorithm for this process? Here is an illustration. Points on the red curve whose tangent line pass through $P$ are $A, B, C, D$ .","Now we have a compact closed simple smooth curve in and the curve's bounding box is known. But the curve is given implicitly by a signed distance function . Note that we don't have a global formula for , but we can sample at arbitrary points. definition of signed distance function can be found here The question is: Given a point , how can we find all the points on the curve whose tangent line pass through . Can you give me an algorithm for this process? Here is an illustration. Points on the red curve whose tangent line pass through are .","\Bbb R^2 f(x, y) f(x, y) f(x, y) P P P A, B, C, D","['differential-geometry', 'partial-differential-equations', 'numerical-methods', 'computer-science', 'plane-curves']"
11,Does a differential-geometry-isometry map a (sub)vector space to a (sub)vector space?,Does a differential-geometry-isometry map a (sub)vector space to a (sub)vector space?,,"Given an isometric embedding of the tangent bundle $TM$ of a Riemannian manifold with Sasaki metric into $ℝ^N$ with standard metric. My intuition tells me that the vector spaces $T_pM$ ( $p ∈ M$ ) are mapped to affine sub spaces of $ℝ^N$ but cannot find a rigourous proof. Can you help? Additional thoughts : The existence of the isometric embedding is guaranteed by the Nash embedding theorem. It is unclear to me though how this embedding looks like (see my other question ). Here isometry does not mean that the distance function is preserved (that would be isometry in the metric space sense) but the Riemannian metric is preserved: $⟨dι_v A, dι_v B⟩_{ℝ^N} = ⟨A, B⟩_{G_s}$ for any $v ∈ TM$ , $A, B ∈ T_vTM$ , $ι$ is the isometric embedding. The Sasaki metric restricted to $T_pM$ is what one would expect: the vertical part of $T_vTM$ ( $v ∈ T_pM$ ) can be identified with $T_pM$ but answer my question one probably has to be very careful how to exploit this identification.","Given an isometric embedding of the tangent bundle of a Riemannian manifold with Sasaki metric into with standard metric. My intuition tells me that the vector spaces ( ) are mapped to affine sub spaces of but cannot find a rigourous proof. Can you help? Additional thoughts : The existence of the isometric embedding is guaranteed by the Nash embedding theorem. It is unclear to me though how this embedding looks like (see my other question ). Here isometry does not mean that the distance function is preserved (that would be isometry in the metric space sense) but the Riemannian metric is preserved: for any , , is the isometric embedding. The Sasaki metric restricted to is what one would expect: the vertical part of ( ) can be identified with but answer my question one probably has to be very careful how to exploit this identification.","TM ℝ^N T_pM p ∈ M ℝ^N ⟨dι_v A, dι_v B⟩_{ℝ^N} = ⟨A, B⟩_{G_s} v ∈ TM A, B ∈ T_vTM ι T_pM T_vTM v ∈ T_pM T_pM",['differential-geometry']
12,Applications of Partition of Unity,Applications of Partition of Unity,,"Theorem that I have to prove: Let $M$ be a smooth manifold, $f\colon M\to\mathbb{R}^n$ be a continuous map and let $S\subseteq M$ be a closed subset of $M$ such that the restriction $f_{|S}\colon S\to\mathbb R^n$ is smooth (this means that for all $p\in S$ there exists a neighbourhood $U_p$ of $p$ and a smooth map $g_p\colon U_p\to\mathbb{R}^n$ such that $g_{p|U_p\cap S}=f_{|U_p\cap S}$ ). Let $\epsilon\colon M\to (0,+\infty)$ be a continuous map. Then, there exists a smooth map $g\colon M\to\mathbb{R}^n$ such that $g(x)=f(x)\quad\forall x\in S$ $\lVert {g(x)-f(x)} \rVert<\epsilon(x)\quad\forall x\in S$ In order to prove it I have to prove the fact that: Fact 1: $\forall p\in M\quad\exists U_p$ neoighbourhood of $p$ , $g_p\colon U_p\to\mathbb R^n$ such that $g_p(x)=f(x)\qquad\forall x\in U_p\cap S\\ ||{g_p(x)-f(x)}||<\epsilon(x)\qquad\forall x\in U_p$ . My task is to use the following fact $0$ that is a consequence of theorem of partition of unity. Fact 0: if $f\colon S\to\mathbb{R}^n$ is a smooth map, where $S\subseteq M$ is closed, then there exists a smooth map $F\colon M\to\mathbb{R}^n$ such that $F_{|S}=f$ . Can anyone help me by proving FACT 1, please?","Theorem that I have to prove: Let be a smooth manifold, be a continuous map and let be a closed subset of such that the restriction is smooth (this means that for all there exists a neighbourhood of and a smooth map such that ). Let be a continuous map. Then, there exists a smooth map such that In order to prove it I have to prove the fact that: Fact 1: neoighbourhood of , such that . My task is to use the following fact that is a consequence of theorem of partition of unity. Fact 0: if is a smooth map, where is closed, then there exists a smooth map such that . Can anyone help me by proving FACT 1, please?","M f\colon M\to\mathbb{R}^n S\subseteq M M f_{|S}\colon S\to\mathbb R^n p\in S U_p p g_p\colon U_p\to\mathbb{R}^n g_{p|U_p\cap S}=f_{|U_p\cap S} \epsilon\colon M\to (0,+\infty) g\colon M\to\mathbb{R}^n g(x)=f(x)\quad\forall x\in S \lVert {g(x)-f(x)} \rVert<\epsilon(x)\quad\forall x\in S \forall p\in M\quad\exists U_p p g_p\colon U_p\to\mathbb R^n g_p(x)=f(x)\qquad\forall x\in U_p\cap S\\
||{g_p(x)-f(x)}||<\epsilon(x)\qquad\forall x\in U_p 0 f\colon S\to\mathbb{R}^n S\subseteq M F\colon M\to\mathbb{R}^n F_{|S}=f","['differential-geometry', 'smooth-manifolds', 'approximation', 'smooth-functions']"
13,local expresssion of the Hessian operator,local expresssion of the Hessian operator,,"I was reading Lee's IRM book, in page 328,there is a local expression for Hessian operator that I can't work it out. Which shows in the normal coordinate (geodesics coordinate) the Hessian operator for distance function inside this neiborhood has the form: $$\mathscr{H}_{r}=g^{i j}\left(\partial_{j} \partial_{k} r-\Gamma_{j k}^{m} \partial_{m} r\right) \partial_{i} \otimes d x^{k}$$ I try to prove it as follows but fails, first we can assume $\mathscr{H}_r = \omega^i_k \partial_i\otimes dx^k$ , then $\mathscr{H}_r(\partial_k) = \omega_k^i \partial_i$ , so $$\omega^i_k g_{ij} = g(\omega_k^i\partial_i, \partial_j)=g(\mathscr{H}_r(\partial_k),\partial_j) = Hess\ r(\partial_k,\partial_j) = g(\nabla_{\partial_k}\nabla r,\partial_j) = g(\nabla_{\partial_k}((\partial^mr) \partial_m)),\partial_j) \tag{*}$$ where $\partial^mr$ denote the $m$ -th component of the $\nabla r$ , Now we need to expand the last term using product rule: $$g(\partial_k(\partial^mr)\partial_m,\partial_j) + g(\partial^mr\nabla_{\partial_k}\partial_m, \partial_j) = \partial_k(\partial^mr)g(\partial_m,\partial_j) + \partial^mr\Gamma^{l}_{km}g(\partial_l,\partial_j) = \partial_k(\partial^mr)g_{mj}+\partial^mr\Gamma^{l}_{km} g_{lj}.$$ So $$\omega^i_k  g_{ij}= \partial_k(\partial^mr)g_{mj}+\partial^mr\Gamma^{l}_{km} g_{lj}$$ So $$\omega^i_k = g^{ij}(\partial_k(\partial^mr)g_{mj}+\partial^mr\Gamma^{l}_{km} g_{lj})$$ Not the desired expression $$\omega^i_k=g^{i j}\left(\partial_{j} \partial_{k} r-\Gamma_{j k}^{m} \partial_{m} r\right)$$ I have tried many times to prove this identity, I am not sure where went wrong? To get minus sign in the second expression , it seems more reasonable to expand the last terms in (*) using metric compatibility condition. But Still seems not clear, the main problem is $g^{ij}$ and $g_{nm}$ in the expression will cancel out.","I was reading Lee's IRM book, in page 328,there is a local expression for Hessian operator that I can't work it out. Which shows in the normal coordinate (geodesics coordinate) the Hessian operator for distance function inside this neiborhood has the form: I try to prove it as follows but fails, first we can assume , then , so where denote the -th component of the , Now we need to expand the last term using product rule: So So Not the desired expression I have tried many times to prove this identity, I am not sure where went wrong? To get minus sign in the second expression , it seems more reasonable to expand the last terms in (*) using metric compatibility condition. But Still seems not clear, the main problem is and in the expression will cancel out.","\mathscr{H}_{r}=g^{i j}\left(\partial_{j} \partial_{k} r-\Gamma_{j k}^{m} \partial_{m} r\right) \partial_{i} \otimes d x^{k} \mathscr{H}_r = \omega^i_k \partial_i\otimes dx^k \mathscr{H}_r(\partial_k) = \omega_k^i \partial_i \omega^i_k g_{ij} = g(\omega_k^i\partial_i, \partial_j)=g(\mathscr{H}_r(\partial_k),\partial_j) = Hess\ r(\partial_k,\partial_j) = g(\nabla_{\partial_k}\nabla r,\partial_j) = g(\nabla_{\partial_k}((\partial^mr) \partial_m)),\partial_j) \tag{*} \partial^mr m \nabla r g(\partial_k(\partial^mr)\partial_m,\partial_j) + g(\partial^mr\nabla_{\partial_k}\partial_m, \partial_j) = \partial_k(\partial^mr)g(\partial_m,\partial_j) + \partial^mr\Gamma^{l}_{km}g(\partial_l,\partial_j) = \partial_k(\partial^mr)g_{mj}+\partial^mr\Gamma^{l}_{km} g_{lj}. \omega^i_k  g_{ij}= \partial_k(\partial^mr)g_{mj}+\partial^mr\Gamma^{l}_{km} g_{lj} \omega^i_k = g^{ij}(\partial_k(\partial^mr)g_{mj}+\partial^mr\Gamma^{l}_{km} g_{lj}) \omega^i_k=g^{i j}\left(\partial_{j} \partial_{k} r-\Gamma_{j k}^{m} \partial_{m} r\right) g^{ij} g_{nm}","['differential-geometry', 'riemannian-geometry']"
14,"""Winding number"" of the map $g: T^{2n+1} \to U(N)$","""Winding number"" of the map",g: T^{2n+1} \to U(N),"For $n\in \mathbb Z_+$ , let $T^{2n+1}$ be the torus and $U(N)$ be the unitary group, where $N$ is sufficiently large. A physics paper on topological insulators claims the following: For a map $g: T^{2n+1} \to U(N)$ , we can associate an integer-valued winding number defined as $$  \frac{(-1)^n n!}{(2n+1)!} \left(\frac{i}{2\pi}\right)^{n+1} \int_{T^{2n+1}} \mathrm{Tr}\left( (g^{-1} dg)^{2n+1}\right) \in \mathbb Z.$$ Why is it integer-valued? How can we interpret the above quantity as the winding number? (The dimensions of $T^{2n+1}$ and $U(N)$ are different, but what I know from the de Rham cohomology theory is that the degree of map is defined for two connected and compact manifolds with the same dimension.) Is the above invariant related to the fact that $\pi_{2n+1}(U(N)) \simeq \mathbb Z$ ? (The physics paper also mentions this fact, but not explicitly states how the above invariant is related to $\pi_{2n+1}(U(N))$ .) Is the above formula valid if we replace the domain of $g$ to $S^{2n+1}$ ?","For , let be the torus and be the unitary group, where is sufficiently large. A physics paper on topological insulators claims the following: For a map , we can associate an integer-valued winding number defined as Why is it integer-valued? How can we interpret the above quantity as the winding number? (The dimensions of and are different, but what I know from the de Rham cohomology theory is that the degree of map is defined for two connected and compact manifolds with the same dimension.) Is the above invariant related to the fact that ? (The physics paper also mentions this fact, but not explicitly states how the above invariant is related to .) Is the above formula valid if we replace the domain of to ?",n\in \mathbb Z_+ T^{2n+1} U(N) N g: T^{2n+1} \to U(N)   \frac{(-1)^n n!}{(2n+1)!} \left(\frac{i}{2\pi}\right)^{n+1} \int_{T^{2n+1}} \mathrm{Tr}\left( (g^{-1} dg)^{2n+1}\right) \in \mathbb Z. T^{2n+1} U(N) \pi_{2n+1}(U(N)) \simeq \mathbb Z \pi_{2n+1}(U(N)) g S^{2n+1},"['differential-geometry', 'algebraic-topology', 'winding-number']"
15,Hyperboloid of one sheet has only one closed geodesic,Hyperboloid of one sheet has only one closed geodesic,,"Let $S : x^2+y^2-z^2 = 1 $ be the hyperboloid of one sheet. We know that there exists a closed geodesic, namely the unit circle $\{(\cos\theta, \sin\theta,0) , \theta \in [0,2\pi]\}$ , since it is the locus of fixed points of the reflection along the $xy$ plane . The claim of uniqueness should follow from Clairaut's relation, however I can't see why that is. In fact, the problem can be solved in a more general case; A surface of revolution with negative gaussian curvature has at most one simple closed geodesic. Can anyone enlighten me on how this follows from Clairaut's relation?","Let be the hyperboloid of one sheet. We know that there exists a closed geodesic, namely the unit circle , since it is the locus of fixed points of the reflection along the plane . The claim of uniqueness should follow from Clairaut's relation, however I can't see why that is. In fact, the problem can be solved in a more general case; A surface of revolution with negative gaussian curvature has at most one simple closed geodesic. Can anyone enlighten me on how this follows from Clairaut's relation?","S : x^2+y^2-z^2 = 1  \{(\cos\theta, \sin\theta,0) , \theta \in [0,2\pi]\} xy",['differential-geometry']
16,Is the set of functions on a compact manifold a Hilbert space?,Is the set of functions on a compact manifold a Hilbert space?,,"Let $M$ be a smooth compact manifold without boundary and let $\omega \in \Omega_M^{\mathrm{top}}$ be a volume form. Let $C^k(M, \mathbb{R})$ be the set of functions $M \to \mathbb{R}$ whose first $k$ derivatives exist and are continuous. We may then endow $C^k(M, \mathbb{R})$ with an inner-product $$\langle f, g \rangle := \int_M fg \omega.$$ Question: Is $(C^k(M, \mathbb{R}), \langle \cdot, \cdot\rangle)$ a Hilbert space for some choice of $k$ ? Does the answer change for some specific $\omega$ (e.g. coming from a Riemannian metric)?",Let be a smooth compact manifold without boundary and let be a volume form. Let be the set of functions whose first derivatives exist and are continuous. We may then endow with an inner-product Question: Is a Hilbert space for some choice of ? Does the answer change for some specific (e.g. coming from a Riemannian metric)?,"M \omega \in \Omega_M^{\mathrm{top}} C^k(M, \mathbb{R}) M \to \mathbb{R} k C^k(M, \mathbb{R}) \langle f, g \rangle := \int_M fg \omega. (C^k(M, \mathbb{R}), \langle \cdot, \cdot\rangle) k \omega","['real-analysis', 'differential-geometry', 'smooth-manifolds']"
17,Lie Derivative on Vector Bundles,Lie Derivative on Vector Bundles,,"I (a physicist) am trying to understand more about the foundations of differential geometry. I am having some trouble disentangling the difference between the Lie derivative and the covaraint derivative. Let $E$ be a bundle over $M$ . If we wish to compare an object $W_q$ in the fiber $F_q$ over $q$ to an object $W_p$ in the fiber $F_p$ over $p$ , we require an isomorphism from $E_q$ to $E_p$ . This could be provided by the flow generated by a vector field $X$ , such that $q = \phi_t(p)$ and $p = \phi_t^{-1}(q) = \phi_{-t}(q)$ . Provided we can find $$ (\phi_{-t})_*: \pi^{-1}[q] \to \pi^{-1}[p], $$ then $$ (\phi_{-t})_* W_{\phi_t(p)} \in \pi^{-1}[p] $$ is, for small $t$ , a curve in $\pi^{-1}[p]$ . We can differentiate this curve at $t=0$ , giving us an object in $T_p(\pi^{-1}[p]) = T_p W_p$ . This is intuitvely the Lie derivative for the bundle $E$ . It sounds to me like the Lie derivative then lives in the vertical subspace tangent to a given fiber. However, when considering the connection on a vector bundle, we also use such constructions when dealing with the lifts of curves and parallel transport. Actually, the vertical subspace in this regard has the property that $$ \pi_* V_p = 0. $$ But since the Lie derivative of two vector fields is again another vector field, I don't see how this property can be reconciled with the Lie derivative living in the vertical subspace over a fiber. I am wondering whether the condition applies only after we define a connection and parallel transport, and isn't generally true, or whether I am mistaken about where the Lie derivative ""lives"". However, if we do have a connection, can the Lie derivative still be defined? Reference used: https://cefns.nau.edu/~schulz/lieder.pdf","I (a physicist) am trying to understand more about the foundations of differential geometry. I am having some trouble disentangling the difference between the Lie derivative and the covaraint derivative. Let be a bundle over . If we wish to compare an object in the fiber over to an object in the fiber over , we require an isomorphism from to . This could be provided by the flow generated by a vector field , such that and . Provided we can find then is, for small , a curve in . We can differentiate this curve at , giving us an object in . This is intuitvely the Lie derivative for the bundle . It sounds to me like the Lie derivative then lives in the vertical subspace tangent to a given fiber. However, when considering the connection on a vector bundle, we also use such constructions when dealing with the lifts of curves and parallel transport. Actually, the vertical subspace in this regard has the property that But since the Lie derivative of two vector fields is again another vector field, I don't see how this property can be reconciled with the Lie derivative living in the vertical subspace over a fiber. I am wondering whether the condition applies only after we define a connection and parallel transport, and isn't generally true, or whether I am mistaken about where the Lie derivative ""lives"". However, if we do have a connection, can the Lie derivative still be defined? Reference used: https://cefns.nau.edu/~schulz/lieder.pdf","E M W_q F_q q W_p F_p p E_q E_p X q = \phi_t(p) p = \phi_t^{-1}(q) = \phi_{-t}(q) 
(\phi_{-t})_*: \pi^{-1}[q] \to \pi^{-1}[p],
 
(\phi_{-t})_* W_{\phi_t(p)} \in \pi^{-1}[p]
 t \pi^{-1}[p] t=0 T_p(\pi^{-1}[p]) = T_p W_p E 
\pi_* V_p = 0.
","['differential-geometry', 'vector-bundles', 'lie-derivative']"
18,There is no cover from $\mathbb{R}^3$ to $SO(3)$,There is no cover from  to,\mathbb{R}^3 SO(3),"I'm working with dynamical system defined on $SO(3)$ and have to deal with the issue of ""gimbal lock"" (or similar) in all coordinate charts that I've found so far. It seems that this is a necessary issue, however I'm at a loss finding a convincing argument why it always has to occur. Ideally I would be able to find a surjective (and likely not bijective) differentiable map from $\mathbb{R}^3$ to $SO(3)$ . What is the reason which prohibits such map to exist? Edits as result of comments: Suppose I find $f : \mathbb{R}^3 \to SO(3)$ sufficiently nice. Then I can pullback vector field describing dynamics from $SO(3)$ to $\mathbb{R}^3$ and study it (numerically) in an easier topology without loss of generality. Demanding that $f$ is differentiable covering is certainly sufficient but likely not necessary.","I'm working with dynamical system defined on and have to deal with the issue of ""gimbal lock"" (or similar) in all coordinate charts that I've found so far. It seems that this is a necessary issue, however I'm at a loss finding a convincing argument why it always has to occur. Ideally I would be able to find a surjective (and likely not bijective) differentiable map from to . What is the reason which prohibits such map to exist? Edits as result of comments: Suppose I find sufficiently nice. Then I can pullback vector field describing dynamics from to and study it (numerically) in an easier topology without loss of generality. Demanding that is differentiable covering is certainly sufficient but likely not necessary.",SO(3) \mathbb{R}^3 SO(3) f : \mathbb{R}^3 \to SO(3) SO(3) \mathbb{R}^3 f,"['general-topology', 'differential-geometry', 'differential-topology']"
19,two different version differential Bianchi identity,two different version differential Bianchi identity,,"There are two different version of differential Bianchi identities,one use the (0,4) curvature tensor: $$\nabla Rm(X,Y,Z,V,W) + \nabla Rm(X,Y,V,W,Z) + \nabla Rm(X,Y,W,Z,V) = 0\tag{1}$$ another use (1,3) curvature endomorphism : $$\left(\nabla_{X} R\right)(Y, Z)W+\left(\nabla_{Y} R\right)(Z, X)W+\left(\nabla_{Z} R\right)(X, Y)W=0\tag{2}$$ I try to show these two are the same.I try to deduce (2) from (1). first since $Rm = R^\flat$ ,hence (1) is equivalent to: $$(\nabla R)^\flat(X,Y,Z,V,W) + (\nabla R)^\flat(X,Y,V,W,Z) + (\nabla R)^\flat(X,Y,W,Z,V) = 0$$ where we use $\nabla$ commute with musical isomorphism. which implies: $$\langle(\nabla_VR)(X,Y)Z,W\rangle+\langle(\nabla_WR)(X,Y)V,Z\rangle+\langle(\nabla_ZR)(X,Y)W,V\rangle = 0$$ at this point I don't know how to preceed,maybe we need to use symmetry of curvature tensor at this step?","There are two different version of differential Bianchi identities,one use the (0,4) curvature tensor: another use (1,3) curvature endomorphism : I try to show these two are the same.I try to deduce (2) from (1). first since ,hence (1) is equivalent to: where we use commute with musical isomorphism. which implies: at this point I don't know how to preceed,maybe we need to use symmetry of curvature tensor at this step?","\nabla Rm(X,Y,Z,V,W) + \nabla Rm(X,Y,V,W,Z) + \nabla Rm(X,Y,W,Z,V) = 0\tag{1} \left(\nabla_{X} R\right)(Y, Z)W+\left(\nabla_{Y} R\right)(Z, X)W+\left(\nabla_{Z} R\right)(X, Y)W=0\tag{2} Rm = R^\flat (\nabla R)^\flat(X,Y,Z,V,W) + (\nabla R)^\flat(X,Y,V,W,Z) + (\nabla R)^\flat(X,Y,W,Z,V) = 0 \nabla \langle(\nabla_VR)(X,Y)Z,W\rangle+\langle(\nabla_WR)(X,Y)V,Z\rangle+\langle(\nabla_ZR)(X,Y)W,V\rangle = 0","['differential-geometry', 'riemannian-geometry']"
20,"Where is the ""covariance"" in a covariant derivative","Where is the ""covariance"" in a covariant derivative",,"I have the following definition of a covariant derivative. Consider a general fibre bundle $E \rightarrow M$ with a connection given by a parallel transport, i.e. along a path $\gamma$ in $M$ we have a transport $\Gamma(\gamma)^t_s : E_{\gamma(s)} \rightarrow E_{\gamma(t)}$ with a covariant derivative $\nabla_{\dot{\gamma}(0)} \sigma(x) := \frac{d}{d t}\mid_{t=0}(\Gamma(\gamma)^t_0)^{-1} \circ \sigma \circ \gamma(t)$ . My question is, what does ""covariant"" refer to in the name covariant derivatrive? I have two main guesses: It reflects the fact that local forms of the covariant derivative ""commute"" with the transition maps of the bundle - but it is pretty obvious as the derivative is defined globally and its local expressions are defined so that it makes sens. It is purely historical and stems from the fact that the above covariant derivative is a generalisation of the covariant derivative of a metric connection which ""vector field component"" changes covariantly.","I have the following definition of a covariant derivative. Consider a general fibre bundle with a connection given by a parallel transport, i.e. along a path in we have a transport with a covariant derivative . My question is, what does ""covariant"" refer to in the name covariant derivatrive? I have two main guesses: It reflects the fact that local forms of the covariant derivative ""commute"" with the transition maps of the bundle - but it is pretty obvious as the derivative is defined globally and its local expressions are defined so that it makes sens. It is purely historical and stems from the fact that the above covariant derivative is a generalisation of the covariant derivative of a metric connection which ""vector field component"" changes covariantly.",E \rightarrow M \gamma M \Gamma(\gamma)^t_s : E_{\gamma(s)} \rightarrow E_{\gamma(t)} \nabla_{\dot{\gamma}(0)} \sigma(x) := \frac{d}{d t}\mid_{t=0}(\Gamma(\gamma)^t_0)^{-1} \circ \sigma \circ \gamma(t),"['differential-geometry', 'connections']"
21,What are irreducible $n$-times antisymmetrized representations?,What are irreducible -times antisymmetrized representations?,n,"I came across the following statement while reading a string theory textbook: if $\boldsymbol{16}_s$ and $\boldsymbol{16}_c$ are the are respectively spinor and conjugate spinor representationsof $Spin(10)$ , we have the Clebsch-Gordan decomposition $$\boldsymbol{16}_s\otimes\boldsymbol{16}_c = [0]\oplus[2]\oplus[4]$$ where $[n]$ denotes the irreducible $n$ -times antisymmetrized representation of $Spin(10)$ , which from a field theoretic point of view correspond to $n$ -forms. I don't understand what exactly are those antisymmetrized representations. What is the general definition ? In what way does it corresponds to forms ?","I came across the following statement while reading a string theory textbook: if and are the are respectively spinor and conjugate spinor representationsof , we have the Clebsch-Gordan decomposition where denotes the irreducible -times antisymmetrized representation of , which from a field theoretic point of view correspond to -forms. I don't understand what exactly are those antisymmetrized representations. What is the general definition ? In what way does it corresponds to forms ?",\boldsymbol{16}_s \boldsymbol{16}_c Spin(10) \boldsymbol{16}_s\otimes\boldsymbol{16}_c = [0]\oplus[2]\oplus[4] [n] n Spin(10) n,"['differential-geometry', 'representation-theory', 'differential-forms', 'spin-geometry']"
22,"Application of unexpected theorem ""all closed manifolds are a quotient of $\Bbb B^n$""!","Application of unexpected theorem ""all closed manifolds are a quotient of ""!",\Bbb B^n,"Recently just accidentally I read a corollary in Lee's Introduction to Riemannian manifolds which surprised me: Corollary 10.35 ( LEE- IRM ). Every compact, connected, smooth $n$ -manifold is homeomorphic to a quotient space of $\overline{\Bbb B}^n$ by an equivalence relation that identifies only points on the boundary. To me this result is so much well-set and less in assumptions and restrictions. But has this result any application? I mean how this can help in differential geometry theorems as well as its face shows that it is so powerful? My second questions is this: Can one produce all closed smooth $n$ -manifolds by equivalence relations on $\partial \overline{\Bbb B}^n\simeq \Bbb S^{n-1}$ that come from some group actions? I mean can one represent or identify that equivalence relations by some (topological) group actions?","Recently just accidentally I read a corollary in Lee's Introduction to Riemannian manifolds which surprised me: Corollary 10.35 ( LEE- IRM ). Every compact, connected, smooth -manifold is homeomorphic to a quotient space of by an equivalence relation that identifies only points on the boundary. To me this result is so much well-set and less in assumptions and restrictions. But has this result any application? I mean how this can help in differential geometry theorems as well as its face shows that it is so powerful? My second questions is this: Can one produce all closed smooth -manifolds by equivalence relations on that come from some group actions? I mean can one represent or identify that equivalence relations by some (topological) group actions?",n \overline{\Bbb B}^n n \partial \overline{\Bbb B}^n\simeq \Bbb S^{n-1},"['differential-geometry', 'riemannian-geometry', 'differential-topology', 'smooth-manifolds']"
23,Third derivative of $r(t)$ in Serret-Frenet TNB frame,Third derivative of  in Serret-Frenet TNB frame,r(t),"I obtained the formula by differentiating it as follows where $s$ denotes the arc length parameter. $T=\frac{dr}{ds}=\frac{dr}{dt}\frac{dt}{ds}  \Leftrightarrow r'=s'T \\ r'' = s''T +s'T'\\\frac{dT}{dt}=\frac{dT}{ds}\frac{ds}{dt}=s'\kappa N \\ \therefore r''= s''T+(s')^2\kappa N \\ r'''=s'''T+s''T'+2s's''\kappa N+(s')^2\kappa 'N+(s')^2\kappa \frac{dN}{dt} \\ \frac{dN}{dt}=\frac{dN}{ds}\frac{ds}{dt} =(-\kappa T+\tau B)s'\\r'''=(s'''-(s')^3\kappa ^2)T+(3s’s''\kappa+(s')^2\kappa')N+(s')^3\kappa\tau B $ However, the coefficient of $N$ of $r'''$ is slightly different from deriving the formula of the torsion of a curve 's second answer (answered by Chappers). It's too late to comment on that thread, so please forgive me for posting a question along with my solution. Is there anything wrong with my solution?","I obtained the formula by differentiating it as follows where denotes the arc length parameter. However, the coefficient of of is slightly different from deriving the formula of the torsion of a curve 's second answer (answered by Chappers). It's too late to comment on that thread, so please forgive me for posting a question along with my solution. Is there anything wrong with my solution?","s T=\frac{dr}{ds}=\frac{dr}{dt}\frac{dt}{ds}  \Leftrightarrow r'=s'T \\ r'' = s''T +s'T'\\\frac{dT}{dt}=\frac{dT}{ds}\frac{ds}{dt}=s'\kappa N \\ \therefore r''= s''T+(s')^2\kappa N \\ r'''=s'''T+s''T'+2s's''\kappa N+(s')^2\kappa 'N+(s')^2\kappa \frac{dN}{dt} \\ \frac{dN}{dt}=\frac{dN}{ds}\frac{ds}{dt} =(-\kappa T+\tau B)s'\\r'''=(s'''-(s')^3\kappa ^2)T+(3s’s''\kappa+(s')^2\kappa')N+(s')^3\kappa\tau B
 N r'''","['calculus', 'differential-geometry', 'curves']"
24,Relation between the two spin structures of $S^1$,Relation between the two spin structures of,S^1,"I know that $S^1$ has two spin structures $s$ and $t$ , corresponding to its two double covers. I am trying to understand which diffeomorphism $f \colon S^1 \rightarrow S^1$ sends $s$ to $t$ , i.e. $f^*(s)=t$ . I am thinking about spin structures as cohomology classes in $H^1(E(M);\mathbb{Z}/2\mathbb{Z})$ , where $E(M)$ is the tangent frame bundle on $M$ . Any help would be appreciated: I guess that my problem depends on my poor understanding of spin structures.","I know that has two spin structures and , corresponding to its two double covers. I am trying to understand which diffeomorphism sends to , i.e. . I am thinking about spin structures as cohomology classes in , where is the tangent frame bundle on . Any help would be appreciated: I guess that my problem depends on my poor understanding of spin structures.",S^1 s t f \colon S^1 \rightarrow S^1 s t f^*(s)=t H^1(E(M);\mathbb{Z}/2\mathbb{Z}) E(M) M,"['differential-geometry', 'lie-groups', 'principal-bundles', 'spin-geometry']"
25,Integrability of Symplectic structures,Integrability of Symplectic structures,,"A symplectic structure on even dimensional manifold is a non-degenerate closed two form and I understood integrability of symplectic structure is closedness as a differential 2-form which comes from involutivity of symplectic vector fields by Frobenius theorem. However, in my calculation of Lie derivative of semi symplectic form $ \omega$ which means merely non-degenerate 2-form with Lie bracket $[X, Y]$ of two symplectic vector fields $X$ and $Y$ is zero without d closed condition. My question is that did I misunderstand of the notion of integrability of symplectic structures in the sense of Frobenius, or mistake in the following calculation? Assume that $0=\mathcal{L}_X\omega, \ 0= \mathcal{L}_Y\omega$ , since $X$ and $Y$ are symplectic. We now compute $\mathcal{L}_{[X, Y]}\omega$ using a formula $\mathcal{L}_{[X, Y]}=\mathcal{L}_X \mathcal{L}_Y -\mathcal{L}_Y\mathcal{L}_X$ . \begin{align} \mathcal{L}_{[X, Y]}\omega & = (\mathcal{L}_X \mathcal{L}_Y -\mathcal{L}_Y\mathcal{L}_X)\omega \\ & = 0. \\ \end{align} Now $\mathcal{L}_{[X, Y]}\omega$ vanished, it implies that $[X, Y]$ is also symplectic without using d-closed condition. How should I use d-closed condition to confirm integrability of symplectic structures?","A symplectic structure on even dimensional manifold is a non-degenerate closed two form and I understood integrability of symplectic structure is closedness as a differential 2-form which comes from involutivity of symplectic vector fields by Frobenius theorem. However, in my calculation of Lie derivative of semi symplectic form which means merely non-degenerate 2-form with Lie bracket of two symplectic vector fields and is zero without d closed condition. My question is that did I misunderstand of the notion of integrability of symplectic structures in the sense of Frobenius, or mistake in the following calculation? Assume that , since and are symplectic. We now compute using a formula . Now vanished, it implies that is also symplectic without using d-closed condition. How should I use d-closed condition to confirm integrability of symplectic structures?"," \omega [X, Y] X Y 0=\mathcal{L}_X\omega, \ 0= \mathcal{L}_Y\omega X Y \mathcal{L}_{[X, Y]}\omega \mathcal{L}_{[X, Y]}=\mathcal{L}_X \mathcal{L}_Y -\mathcal{L}_Y\mathcal{L}_X \begin{align}
\mathcal{L}_{[X, Y]}\omega & = (\mathcal{L}_X \mathcal{L}_Y -\mathcal{L}_Y\mathcal{L}_X)\omega \\
& = 0. \\
\end{align} \mathcal{L}_{[X, Y]}\omega [X, Y]","['differential-geometry', 'symplectic-geometry']"
26,When a local isometric immersion become global?,When a local isometric immersion become global?,,"I have a question that I have not been able to answer clearly. When a local isometric immersion become global? For example, I know the following result, if $\phi:M\to N$ be a differentiable mapping and $g$ a metric in $N$ , then $\phi^*g$ is a metric in $M$ if and only if $\phi$ is a immersion (isometric). But that only assures me a local isometric immersion, for example of a pseudosphere and the hyperbolic plane $\mathbb H^2$ , as only one horocircle can be immersed but not the entire hyperbolic plane. But in turn, for example Rozendorn uses this same fact to prove that $\mathbb H^2$ is isometrically immersed in $\mathbb R^5$ with a non-injective immersion. In his article he only explicitly gives such a immersion and the idea is to use the result above, after that he concludes that it is a global immersion. I feel a bit tied in my hands with this and I don't know how to get out. I would appreciate some clarification, thank you. I thought that the definition of immersion was only one, I'm sorry if there are more so: A differentiable map $\phi:M\to N$ is an immersion if the differential $d\phi_p$ is non-singular for all $p$ .","I have a question that I have not been able to answer clearly. When a local isometric immersion become global? For example, I know the following result, if be a differentiable mapping and a metric in , then is a metric in if and only if is a immersion (isometric). But that only assures me a local isometric immersion, for example of a pseudosphere and the hyperbolic plane , as only one horocircle can be immersed but not the entire hyperbolic plane. But in turn, for example Rozendorn uses this same fact to prove that is isometrically immersed in with a non-injective immersion. In his article he only explicitly gives such a immersion and the idea is to use the result above, after that he concludes that it is a global immersion. I feel a bit tied in my hands with this and I don't know how to get out. I would appreciate some clarification, thank you. I thought that the definition of immersion was only one, I'm sorry if there are more so: A differentiable map is an immersion if the differential is non-singular for all .",\phi:M\to N g N \phi^*g M \phi \mathbb H^2 \mathbb H^2 \mathbb R^5 \phi:M\to N d\phi_p p,"['differential-geometry', 'riemannian-geometry', 'hyperbolic-geometry', 'isometry']"
27,explicit relation between interior derivative and alternation operation,explicit relation between interior derivative and alternation operation,,"Let $X$ be a vector field, $L_X$ the Lie derivative, $i_X$ the interior derivative, $A$ the alternation operation (that assign for each covariant tensor field $K$ , a differential form $AK$ ). The definitions I am following are: $$(AK)(X_1,\cdots, X_r)=  \frac{1}{r!}\sum_{\sigma\in S_r}{\rm sgn}(\sigma)K(X_{\sigma(1)},\cdots,X_{\sigma(r)}) $$ $$L_X(\omega)(X_1,\cdots,X_k)=X(\omega(X_1,\cdots,X_k)) -\sum_{i=1}^k \omega(X_1,\cdots, [X,X_i],\cdots, X_k),$$ $$(i_X\omega)(X_1,\cdots, X_{k-1})=k\omega(X,X_1,\cdots,X_{k-1}),$$ for $X_i\in \mathfrak{X}(M)$ ; $1\leq i\leq k$ . It is easy to see that the operators $L_X$ and $A$ commute with each other; that is, for a covariant tensor field $K$ , we have $$L_X(AK)=A(L_XK).$$ This commutativity condition fails in case of $i_X$ and $A$ . Let $K$ be a covariant tensor field of degree $r$ . Let $X_2,\cdots,X_r$ be vector fields on $M$ . We have $$\begin{align}i_{X_1}(AK)(X_2,\cdots,X_r)=&r (AK)(X_1,X_2,\cdots,X_r)\\ =&r\frac{1}{r!}\sum_{\sigma\in S_r}{\rm sgn}(\sigma) K(X_{\sigma(1)},\cdots,X_{\sigma(r)})\\  =&r\frac{1}{r!}\sum_{\sigma\in S_r|\sigma(1)=1}{\rm sgn}(\sigma) K(X_{\sigma(1)},\cdots,X_{\sigma(r)})+r\frac{1}{r!}\sum_{\sigma\in S_r|\sigma(1)\neq1}{\rm sgn}(\sigma) K(X_{\sigma(1)},\cdots,X_{\sigma(r)})\\  =&\frac{1}{(r-1)!}\sum_{\sigma\in S_{r-1}}{\rm sgn}(\sigma) K(X_1,X_{\sigma(2)},\cdots,X_{\sigma(r)})+({\rm something})\\ =&\frac{1}{(r-1)!}\sum_{\sigma\in S_{r-1}}{\rm sgn}(\sigma) i_{X_1}K(X_{\sigma(2)},\cdots,X_{\sigma(r)})+({\rm something})\\ =&A(i_{X_1}K)(X_2,\cdots,X_r)+({\rm something}) \end{align}$$ So, $i_X$ and $A$ does not really commute. We have $$i_X(AK)(X_1,\cdots,X_r)=A(i_XK)(X_1,\cdots,X_r)+({\rm something})$$ I am trying to see if there is a nice expression for the ``something"" part. It would just be an appropriate rearrangement of terms, but, I am not able to do it in a clever way. Any help is appreciated.","Let be a vector field, the Lie derivative, the interior derivative, the alternation operation (that assign for each covariant tensor field , a differential form ). The definitions I am following are: for ; . It is easy to see that the operators and commute with each other; that is, for a covariant tensor field , we have This commutativity condition fails in case of and . Let be a covariant tensor field of degree . Let be vector fields on . We have So, and does not really commute. We have I am trying to see if there is a nice expression for the ``something"" part. It would just be an appropriate rearrangement of terms, but, I am not able to do it in a clever way. Any help is appreciated.","X L_X i_X A K AK (AK)(X_1,\cdots, X_r)=
 \frac{1}{r!}\sum_{\sigma\in S_r}{\rm sgn}(\sigma)K(X_{\sigma(1)},\cdots,X_{\sigma(r)})  L_X(\omega)(X_1,\cdots,X_k)=X(\omega(X_1,\cdots,X_k))
-\sum_{i=1}^k \omega(X_1,\cdots, [X,X_i],\cdots, X_k), (i_X\omega)(X_1,\cdots, X_{k-1})=k\omega(X,X_1,\cdots,X_{k-1}), X_i\in \mathfrak{X}(M) 1\leq i\leq k L_X A K L_X(AK)=A(L_XK). i_X A K r X_2,\cdots,X_r M \begin{align}i_{X_1}(AK)(X_2,\cdots,X_r)=&r (AK)(X_1,X_2,\cdots,X_r)\\
=&r\frac{1}{r!}\sum_{\sigma\in S_r}{\rm sgn}(\sigma) K(X_{\sigma(1)},\cdots,X_{\sigma(r)})\\ 
=&r\frac{1}{r!}\sum_{\sigma\in S_r|\sigma(1)=1}{\rm sgn}(\sigma) K(X_{\sigma(1)},\cdots,X_{\sigma(r)})+r\frac{1}{r!}\sum_{\sigma\in S_r|\sigma(1)\neq1}{\rm sgn}(\sigma) K(X_{\sigma(1)},\cdots,X_{\sigma(r)})\\ 
=&\frac{1}{(r-1)!}\sum_{\sigma\in S_{r-1}}{\rm sgn}(\sigma) K(X_1,X_{\sigma(2)},\cdots,X_{\sigma(r)})+({\rm something})\\
=&\frac{1}{(r-1)!}\sum_{\sigma\in S_{r-1}}{\rm sgn}(\sigma) i_{X_1}K(X_{\sigma(2)},\cdots,X_{\sigma(r)})+({\rm something})\\
=&A(i_{X_1}K)(X_2,\cdots,X_r)+({\rm something})
\end{align} i_X A i_X(AK)(X_1,\cdots,X_r)=A(i_XK)(X_1,\cdots,X_r)+({\rm something})",['differential-geometry']
28,Ricci flow that expands the negative curvature part of the manifold and contracts the positive curvature part?,Ricci flow that expands the negative curvature part of the manifold and contracts the positive curvature part?,,"Hamilton's program for proving the Poincaré conjecture involves first putting a Riemannian metric on the unknown simply connected closed 3-manifold. The basic idea is to try to ""improve"" this metric; for example, if the metric can be improved enough so that it has constant positive curvature, then according to classical results in Riemannian geometry, it must be the 3-sphere. Hamilton prescribed the ""Ricci flow equations"" for improving the metric; $$\partial {t}g_{ij}=-2R_{ij} $$ where g is the metric and R its Ricci curvature, and one hopes that as the time t increases the manifold becomes easier to understand. Then I read from Wikipedia said: Ricci flow expands the negative curvature part of the manifold and contracts the positive curvature part. Why contracts the positive curvature part? If we want to flow to 3-sphere, should not we consider to use the Ricci flow that contracts the negative curvature part and expands the positive curvature part? here is the link of the quoted text https://en.wikipedia.org/wiki/Poincaré_conjecture#Ricci_flow_with_surgery","Hamilton's program for proving the Poincaré conjecture involves first putting a Riemannian metric on the unknown simply connected closed 3-manifold. The basic idea is to try to ""improve"" this metric; for example, if the metric can be improved enough so that it has constant positive curvature, then according to classical results in Riemannian geometry, it must be the 3-sphere. Hamilton prescribed the ""Ricci flow equations"" for improving the metric; where g is the metric and R its Ricci curvature, and one hopes that as the time t increases the manifold becomes easier to understand. Then I read from Wikipedia said: Ricci flow expands the negative curvature part of the manifold and contracts the positive curvature part. Why contracts the positive curvature part? If we want to flow to 3-sphere, should not we consider to use the Ricci flow that contracts the negative curvature part and expands the positive curvature part? here is the link of the quoted text https://en.wikipedia.org/wiki/Poincaré_conjecture#Ricci_flow_with_surgery",\partial {t}g_{ij}=-2R_{ij} ,"['differential-geometry', 'riemannian-geometry', 'differential-topology', 'geometric-topology', 'curvature']"
29,Volume of Lie groups and homogeneous manifolds with respect to Riemannian volume forms,Volume of Lie groups and homogeneous manifolds with respect to Riemannian volume forms,,"(Motivations / background below, but the question is self contained.) Question Suppose $G$ is a compact Lie group and $K$ a closed subgroup. Let $X=G/K$ the corresponding homogeneous manifold (to be concrete: we quotient by multiplication on the right by $K$ , namely elements of $X$ are cosets $[g]=gK$ ). Suppose also that $G$ is equipped with a bi-invariant Riemannian metric $\gamma$ . Let $\Omega_G$ be the associated volume form. (In coordinates $\gamma=\gamma_{ij}(x)dx^idx^j\Rightarrow\Omega_G=\sqrt{\det\gamma_{ij}(x)}dx^1\wedge...\wedge dx^n$ .) The restricted Riemann metric $\gamma|_K$ induces a volume form $\Omega_K$ on $K$ . Moreover $\gamma$ induces an invariant Riemannian metric on $X$ ; the way I see this is because $T_{[g]}X \simeq T_gG / T_g(g.K)\simeq(T_g(g.K))^{\perp_\gamma}$ (where $g.K$ is the orbit of $g$ under right multiplication by $K$ and the superscript $\perp_\gamma$ denotes the orthogonal subspace with respect to $\gamma$ ) so that we can define the metric on $T_{[g]}X$ by restricting $\gamma$ to $(T_g(g.K))^{\perp_\gamma}$ . What I would like to prove (or disprove?) is that $$ (\star)\qquad\qquad\int_G\Omega_G=\int_X\Omega_X\int_K\Omega_K, $$ or even some version for integration of functions on $G$ if possible. (Maybe I need some version of the ""coarea formula""?) Motivations / Background Let $\mathcal U_n$ be the real Lie group of unitary matrices of size $n$ and let $\mathcal H_n$ be the real vector space of Hermitian matrices of size $n$ . We can define the bi-invariant Riemannian metric $\gamma_U^{(n)}(M,N)=tr(MN^\dagger)$ on $\mathcal U_n\ni U$ where $M,N\in T_U\mathcal U_n=\sqrt{-1} U \mathcal H_n$ . I would like to take $G=\mathcal U_n$ and $K=\mathcal U_{n-1}$ ; the latter is embedded via $i:K\to G:U\mapsto \begin{pmatrix}1 & 0 \\ 0 & U\end{pmatrix}$ which is isometric, namely $i^*\gamma^{(n)}=\gamma^{(n-1)}$ . The quotient $X=G/K$ is diffeomorphic to $S^{2n-1}\subset\mathbb C^n$ via $f:[U]\mapsto Ue_1$ (i.e. via the map $f$ sending $[U]\in X$ to the first column of $U$ , which is a norm 1 vector in $\mathbb C^n$ ). It also seems to me that $\Omega_X$ , as defined above, is $2^{n-1}\Omega_{S^{2n-1}}$ (namely $\Omega_X=2^{n-1}f^*\Omega_{S^{2n-1}}$ ), where $\Omega_{S^m}$ is the standard volume form on the sphere. Finally, the factorization property $(\star)$ above, along with the standard identity $Vol(S^{m-1})=2\pi^{m/2}/\Gamma(m/2)$ , would imply that $$ Vol(\mathcal U_n)=Vol(\mathcal U_{n-1})Vol(X)=Vol(\mathcal U_{n-1})2^{n-1} Vol(S^{2n-1})=Vol(\mathcal U_{n-1})\frac{(2\pi)^n}{(n-1)!}. $$ Together with the initial value $Vol(\mathcal U_1)=2\pi$ (which can be computed directly) this argument seems to provide the correct value for $Vol(\mathcal U_n)=\frac{(2\pi)^{n(n+1)/2}}{1!\cdots (n-1)!}$ (with respect to the present normalization of the Haar measure), but I am still puzzled by the equality $(\star)$ above.","(Motivations / background below, but the question is self contained.) Question Suppose is a compact Lie group and a closed subgroup. Let the corresponding homogeneous manifold (to be concrete: we quotient by multiplication on the right by , namely elements of are cosets ). Suppose also that is equipped with a bi-invariant Riemannian metric . Let be the associated volume form. (In coordinates .) The restricted Riemann metric induces a volume form on . Moreover induces an invariant Riemannian metric on ; the way I see this is because (where is the orbit of under right multiplication by and the superscript denotes the orthogonal subspace with respect to ) so that we can define the metric on by restricting to . What I would like to prove (or disprove?) is that or even some version for integration of functions on if possible. (Maybe I need some version of the ""coarea formula""?) Motivations / Background Let be the real Lie group of unitary matrices of size and let be the real vector space of Hermitian matrices of size . We can define the bi-invariant Riemannian metric on where . I would like to take and ; the latter is embedded via which is isometric, namely . The quotient is diffeomorphic to via (i.e. via the map sending to the first column of , which is a norm 1 vector in ). It also seems to me that , as defined above, is (namely ), where is the standard volume form on the sphere. Finally, the factorization property above, along with the standard identity , would imply that Together with the initial value (which can be computed directly) this argument seems to provide the correct value for (with respect to the present normalization of the Haar measure), but I am still puzzled by the equality above.","G K X=G/K K X [g]=gK G \gamma \Omega_G \gamma=\gamma_{ij}(x)dx^idx^j\Rightarrow\Omega_G=\sqrt{\det\gamma_{ij}(x)}dx^1\wedge...\wedge dx^n \gamma|_K \Omega_K K \gamma X T_{[g]}X \simeq T_gG / T_g(g.K)\simeq(T_g(g.K))^{\perp_\gamma} g.K g K \perp_\gamma \gamma T_{[g]}X \gamma (T_g(g.K))^{\perp_\gamma} 
(\star)\qquad\qquad\int_G\Omega_G=\int_X\Omega_X\int_K\Omega_K,
 G \mathcal U_n n \mathcal H_n n \gamma_U^{(n)}(M,N)=tr(MN^\dagger) \mathcal U_n\ni U M,N\in T_U\mathcal U_n=\sqrt{-1} U \mathcal H_n G=\mathcal U_n K=\mathcal U_{n-1} i:K\to G:U\mapsto \begin{pmatrix}1 & 0 \\ 0 & U\end{pmatrix} i^*\gamma^{(n)}=\gamma^{(n-1)} X=G/K S^{2n-1}\subset\mathbb C^n f:[U]\mapsto Ue_1 f [U]\in X U \mathbb C^n \Omega_X 2^{n-1}\Omega_{S^{2n-1}} \Omega_X=2^{n-1}f^*\Omega_{S^{2n-1}} \Omega_{S^m} (\star) Vol(S^{m-1})=2\pi^{m/2}/\Gamma(m/2) 
Vol(\mathcal U_n)=Vol(\mathcal U_{n-1})Vol(X)=Vol(\mathcal U_{n-1})2^{n-1} Vol(S^{2n-1})=Vol(\mathcal U_{n-1})\frac{(2\pi)^n}{(n-1)!}.
 Vol(\mathcal U_1)=2\pi Vol(\mathcal U_n)=\frac{(2\pi)^{n(n+1)/2}}{1!\cdots (n-1)!} (\star)","['differential-geometry', 'lie-groups', 'volume', 'haar-measure']"
30,Reference request: Allard's regularity Theorem for smooth submanifolds,Reference request: Allard's regularity Theorem for smooth submanifolds,,"Allard's regularity Theorem (Theorem 5.2, https://web.stanford.edu/class/math285/ts-gmt.pdf ) asserts that a varifold can be locally written as a graph. Moreover, it gives a lower bound on the size of the domain in which this is possible. The size depends on the size of subsets of varifolds where balls approximate the size of Euclidean balls of the same dimension. I am not well versed in geometric measure theory and would like this Theorem for submanifolds of Euclidean space but I can't find it formulated anywhere. The abstract in this paper ( https://arxiv.org/pdf/1311.3963.pdf ) says the following: ""In the special case when V is a smooth manifold translates to the following: If $\omega^{-1} \rho^{-n}Area(V \cap B_{\rho}(x))$ is sufficiently close to 1 and the unit normal of V satisfies a $C^{0,\alpha}$ estimate, then $ V \cap B_{\rho}(x)$ is the graph of a $C^{1,\alpha}$ function with estimates."" I would like a theorem of the following form. Suppose $V$ is a closed smooth submanifold of $\mathbb{R}^n$ such that the second fundamental form of $V$ is bounded by $C$ and its derivatives by $C^2$ with positive injectivity radius $r_V$ . Then there is a radius $R(C,r_V)>0$ such that for any $p \in V$ there is a function $u_p$ $$ B_R(p) \cap V = graph(u_p) $$ where $B_R(p)\subset \mathbb{R}^n$ Edit: For anyone interested, I found the answer to my question in Theorem 3.8 of https://people.math.sc.edu/howard/Notes/schur.pdf","Allard's regularity Theorem (Theorem 5.2, https://web.stanford.edu/class/math285/ts-gmt.pdf ) asserts that a varifold can be locally written as a graph. Moreover, it gives a lower bound on the size of the domain in which this is possible. The size depends on the size of subsets of varifolds where balls approximate the size of Euclidean balls of the same dimension. I am not well versed in geometric measure theory and would like this Theorem for submanifolds of Euclidean space but I can't find it formulated anywhere. The abstract in this paper ( https://arxiv.org/pdf/1311.3963.pdf ) says the following: ""In the special case when V is a smooth manifold translates to the following: If is sufficiently close to 1 and the unit normal of V satisfies a estimate, then is the graph of a function with estimates."" I would like a theorem of the following form. Suppose is a closed smooth submanifold of such that the second fundamental form of is bounded by and its derivatives by with positive injectivity radius . Then there is a radius such that for any there is a function where Edit: For anyone interested, I found the answer to my question in Theorem 3.8 of https://people.math.sc.edu/howard/Notes/schur.pdf","\omega^{-1} \rho^{-n}Area(V \cap B_{\rho}(x)) C^{0,\alpha}  V \cap B_{\rho}(x) C^{1,\alpha} V \mathbb{R}^n V C C^2 r_V R(C,r_V)>0 p \in V u_p 
B_R(p) \cap V = graph(u_p)
 B_R(p)\subset \mathbb{R}^n","['differential-geometry', 'geometric-measure-theory', 'submanifold']"
31,Show that the Ricci form of a Kähler metric is closed (using the second Bianchi identity),Show that the Ricci form of a Kähler metric is closed (using the second Bianchi identity),,"Let $g = (g_{i \overline{j}})$ be a Kähler metric. The Ricci form $\rho$ is a closed real $(1,1)$ -form, which can locally be written as $$\rho = i \partial \overline{\partial} \log (\det(g)),$$ and from this local expression, we see that $d \rho =0$ . I want a proof of $d \rho =0$ directly from the second Bianchi identity. To this end, let $R_{i\overline{j} k \overline{\ell}}$ denote the Riemannian curvature tensor of $g$ . The Ricci curvature is given by $$\text{Ric}_{i \overline{j}} = g^{k \overline{\ell}} R_{i \overline{j}k\overline{\ell}}.$$ Hence, we can write $\rho = i \sum_{i,j} \text{Ric}_{i\overline{j}} dz_i \wedge d\overline{z}_j$ , and we want to show that $$d \rho = i \sum_{\alpha, i,j} \nabla_{\alpha} \text{Ric}_{i \overline{j}} dz_{\alpha} \wedge dz_i \wedge d\overline{z}_j + \nabla_{\overline{\alpha}} \text{Ric}_{i\overline{j}} d\overline{z}_{\alpha} \wedge dz_i \wedge d\overline{z}_j =0.$$ The second Bianchi identity can be expressed as $\nabla_m R_{i\overline{j}k\overline{\ell}} = \nabla_i R_{m \overline{j} k \overline{\ell}}$ . Therefore, $$\nabla_{\alpha} \text{Ric}_{i\overline{j}} = g^{k\overline{\ell}} \nabla_{\alpha} R_{i\overline{j}k\overline{\ell}}=g^{k\overline{\ell}}\nabla_iR_{\alpha\overline{j}k\overline{\ell}}= \nabla_i \text{Ric}_{\alpha\overline{j}},$$ and similarly, $$\nabla_{\overline{\alpha}} \text{Ric}_{i\overline{j}}=\nabla_{\overline{j}}\text{Ric}_{i\overline{\alpha}}.$$ At this point, I suspect that I want to use the skew-symmetry of the wedge product. But I can't see it.","Let be a Kähler metric. The Ricci form is a closed real -form, which can locally be written as and from this local expression, we see that . I want a proof of directly from the second Bianchi identity. To this end, let denote the Riemannian curvature tensor of . The Ricci curvature is given by Hence, we can write , and we want to show that The second Bianchi identity can be expressed as . Therefore, and similarly, At this point, I suspect that I want to use the skew-symmetry of the wedge product. But I can't see it.","g = (g_{i \overline{j}}) \rho (1,1) \rho = i \partial \overline{\partial} \log (\det(g)), d \rho =0 d \rho =0 R_{i\overline{j} k \overline{\ell}} g \text{Ric}_{i \overline{j}} = g^{k \overline{\ell}} R_{i \overline{j}k\overline{\ell}}. \rho = i \sum_{i,j} \text{Ric}_{i\overline{j}} dz_i \wedge d\overline{z}_j d \rho = i \sum_{\alpha, i,j} \nabla_{\alpha} \text{Ric}_{i \overline{j}} dz_{\alpha} \wedge dz_i \wedge d\overline{z}_j + \nabla_{\overline{\alpha}} \text{Ric}_{i\overline{j}} d\overline{z}_{\alpha} \wedge dz_i \wedge d\overline{z}_j =0. \nabla_m R_{i\overline{j}k\overline{\ell}} = \nabla_i R_{m \overline{j} k \overline{\ell}} \nabla_{\alpha} \text{Ric}_{i\overline{j}} = g^{k\overline{\ell}} \nabla_{\alpha} R_{i\overline{j}k\overline{\ell}}=g^{k\overline{\ell}}\nabla_iR_{\alpha\overline{j}k\overline{\ell}}= \nabla_i \text{Ric}_{\alpha\overline{j}}, \nabla_{\overline{\alpha}} \text{Ric}_{i\overline{j}}=\nabla_{\overline{j}}\text{Ric}_{i\overline{\alpha}}.","['differential-geometry', 'riemannian-geometry']"
32,On connectivity of Lie subgroups,On connectivity of Lie subgroups,,"Here we assume that all manifolds are second-countable. Let $ G $ be a Lie group and $ H $ be its Lie subgroup. That is, $ H $ is a subgroup of $ G $ equipped with a differential structure with which $ H $ is a Lie group and the inclusion map $ \iota\colon H \to G $ is an immersion. Let $ H' $ denote $ H $ as a topological subspace of $ G $ . Note that the topology of $ H $ is generally different from that of $ H' $ . I am thinking about the relationship between the following four conditions: $ H $ is connected; $ H $ is path-connected; $ H' $ is connected; $ H' $ is path-connected. Here is what I understood: 1 and 2 are equivalent since $ H $ is a manifold. 1 (or, equivalently, 2) implies 3 and 4 since a continuous image of a connected (resp. path-connected) is connected (resp. path-connected). 3 does not imply 1. To see this, let $ G = \mathbb{T}^2 = \mathbb{R}^2/\mathbb{Z}^2 $ and $$ H = \{(x, \sqrt{2} x) + \mathbb{Z}^2 \mid x \in \mathbb{R}\} \cup \{(x + 1/2, \sqrt{2} x) + \mathbb{Z}^2 \mid x \in \mathbb{R}\}. $$ Then $ H $ is a Lie subgroup of $ G $ which is isomorphic to $ \mathbb{R} \times \mathbb{Z}/2\mathbb{Z} $ , but $ H' \subseteq G $ is connected. 4 implies 3 (generality from General Topology), but the converse is not true as the above example shows. Now my question is: Does 4 imply 1? That is, if the subspace $ H' \subseteq G $ is path-connected, is the Lie group $ H $ (path-)connected? Remark. Without second-countability, there are trivial counterexamples such as $ (\mathbb{R}, \text{discrete}) \to (\mathbb{R}, \text{usual}) $ .","Here we assume that all manifolds are second-countable. Let be a Lie group and be its Lie subgroup. That is, is a subgroup of equipped with a differential structure with which is a Lie group and the inclusion map is an immersion. Let denote as a topological subspace of . Note that the topology of is generally different from that of . I am thinking about the relationship between the following four conditions: is connected; is path-connected; is connected; is path-connected. Here is what I understood: 1 and 2 are equivalent since is a manifold. 1 (or, equivalently, 2) implies 3 and 4 since a continuous image of a connected (resp. path-connected) is connected (resp. path-connected). 3 does not imply 1. To see this, let and Then is a Lie subgroup of which is isomorphic to , but is connected. 4 implies 3 (generality from General Topology), but the converse is not true as the above example shows. Now my question is: Does 4 imply 1? That is, if the subspace is path-connected, is the Lie group (path-)connected? Remark. Without second-countability, there are trivial counterexamples such as ."," G   H   H   G   H   \iota\colon H \to G   H'   H   G   H   H'   H   H   H'   H'   H   G = \mathbb{T}^2 = \mathbb{R}^2/\mathbb{Z}^2   H = \{(x, \sqrt{2} x) + \mathbb{Z}^2 \mid x \in \mathbb{R}\} \cup \{(x + 1/2, \sqrt{2} x) + \mathbb{Z}^2 \mid x \in \mathbb{R}\}.   H   G   \mathbb{R} \times \mathbb{Z}/2\mathbb{Z}   H' \subseteq G   H' \subseteq G   H   (\mathbb{R}, \text{discrete}) \to (\mathbb{R}, \text{usual}) ","['differential-geometry', 'lie-groups', 'smooth-manifolds']"
33,derivation of surface gradient,derivation of surface gradient,,"Suppose the surface S is parameterized as $\textbf{x}=(x_1(u_1,u_2),x_2(u_1, u_2), x_3(u_1,u_2))$ ,  then the surface gradient $\nabla_{S}$ of a scalar function $p(x_1,x_2,x_3)$ on $S$ is defined as, $$\tag{1} \nabla_S p = \sum_{i,j=1}^{2}g^{ij}\frac{\partial p}{\partial u_i}\frac{\partial \textbf{x}}{\partial u_j}\hspace{2cm} $$ where $g^{ij}$ is the (i,j)th entry of the inverse of the matrix $G$ given by $$G_{ij}=\frac{\partial\textbf{x}}{\partial u_i}\cdot\frac{\partial\textbf{x}}{\partial u_j},i,j=1,2$$ From this definition, we have the following formula, \begin{equation} \tag{2} \nabla_{S}p=\textbf{n}\times\nabla p\times \textbf{n}\hspace{2cm} \end{equation} where $\nabla p$ is the standard gradient in 3D, $\textbf{n}$ is the unit normal vector on $S$ . I have no idea how the surface gradient $\nabla_S p $ $(1)$ is defined. I try to understand this  by deriving $(1)$ from equation $(2)$ , but this seems rather tedious. Can anyone  give a detailed derivation of $(1)$ ? Thanks!","Suppose the surface S is parameterized as ,  then the surface gradient of a scalar function on is defined as, where is the (i,j)th entry of the inverse of the matrix given by From this definition, we have the following formula, where is the standard gradient in 3D, is the unit normal vector on . I have no idea how the surface gradient is defined. I try to understand this  by deriving from equation , but this seems rather tedious. Can anyone  give a detailed derivation of ? Thanks!","\textbf{x}=(x_1(u_1,u_2),x_2(u_1, u_2), x_3(u_1,u_2)) \nabla_{S} p(x_1,x_2,x_3) S \tag{1} \nabla_S p = \sum_{i,j=1}^{2}g^{ij}\frac{\partial p}{\partial u_i}\frac{\partial \textbf{x}}{\partial u_j}\hspace{2cm}  g^{ij} G G_{ij}=\frac{\partial\textbf{x}}{\partial u_i}\cdot\frac{\partial\textbf{x}}{\partial u_j},i,j=1,2 \begin{equation}
\tag{2} \nabla_{S}p=\textbf{n}\times\nabla p\times \textbf{n}\hspace{2cm}
\end{equation} \nabla p \textbf{n} S \nabla_S p  (1) (1) (2) (1)","['differential-geometry', 'vector-analysis']"
34,Relationship between the covector $(df)_p$ and the differential $df_p$ of $f$ at $p$,Relationship between the covector  and the differential  of  at,(df)_p df_p f p,"Let $M$ be a smooth manifold and let $f\in C^\infty(M)$ . The differential of $f$ at $p\in M$ is the linear map $df_p:T_p M\to T_{f(p)}\mathbb{R}$ defined by $$df_p(v)(g)=v(g\circ f),$$ where $v$ is a derivation in $T_p M$ and $g\in C^\infty(\mathbb{R})$ . On the other hand, given $f\in C^\infty(M)$ , we can obtain a smooth covector field $df$ on $M$ by defining $$(df)_p(v)=vf$$ for $p\in M$ and $v\in T_p M$ . Some people claim that $(df)_p$ and $df_p$ are actually the same thing, by identifying $T_{f(p)}\mathbb{R}$ with $\mathbb{R}$ . But I would like to cast a doubt on it. Let $g\in C^\infty(\mathbb{R})$ . If the claim is true, we should be able to see that $$D_{(df)_p(v)}\Big|_{f(p)}g:=\frac{d}{dt}\Big|_{t=0}g(f(p)+t(df)_p(v))=v(g\circ f),$$ in which I try to go through $\mathbb{R}\cong\mathbb{R}_{f(p)}\cong T_{f(p)}\mathbb{R}$ . But I ended up with $$\frac{d}{dt}\Big|_{t=0}g(f(p)+t(df)_p(v))=g'(f(p))(vf).$$ What seems to be the problem in between my calculation? Thank you.","Let be a smooth manifold and let . The differential of at is the linear map defined by where is a derivation in and . On the other hand, given , we can obtain a smooth covector field on by defining for and . Some people claim that and are actually the same thing, by identifying with . But I would like to cast a doubt on it. Let . If the claim is true, we should be able to see that in which I try to go through . But I ended up with What seems to be the problem in between my calculation? Thank you.","M f\in C^\infty(M) f p\in M df_p:T_p M\to T_{f(p)}\mathbb{R} df_p(v)(g)=v(g\circ f), v T_p M g\in C^\infty(\mathbb{R}) f\in C^\infty(M) df M (df)_p(v)=vf p\in M v\in T_p M (df)_p df_p T_{f(p)}\mathbb{R} \mathbb{R} g\in C^\infty(\mathbb{R}) D_{(df)_p(v)}\Big|_{f(p)}g:=\frac{d}{dt}\Big|_{t=0}g(f(p)+t(df)_p(v))=v(g\circ f), \mathbb{R}\cong\mathbb{R}_{f(p)}\cong T_{f(p)}\mathbb{R} \frac{d}{dt}\Big|_{t=0}g(f(p)+t(df)_p(v))=g'(f(p))(vf).","['differential-geometry', 'smooth-manifolds', 'differential-forms']"
35,Tangent basis to Ellipsoid,Tangent basis to Ellipsoid,,"I have an ellipsoid centered at $0$ (the contour of a Gaussian distribution centered at $0$ with covariance matrix $\Sigma=\Lambda^{-1}$ ) $$ x^\top \Lambda x = \gamma $$ and I know that the gradient at a point is given by $$ g(x) = -\Lambda x $$ Is there an expression for the tangent at a point? All I know is that $t(x)^\top g(x) = 0$ . In practice the tangent plane will be a hyperplane so there will be many vectors to choose from. However, I am looking for a tangent basis","I have an ellipsoid centered at (the contour of a Gaussian distribution centered at with covariance matrix ) and I know that the gradient at a point is given by Is there an expression for the tangent at a point? All I know is that . In practice the tangent plane will be a hyperplane so there will be many vectors to choose from. However, I am looking for a tangent basis","0 0 \Sigma=\Lambda^{-1} 
x^\top \Lambda x = \gamma
 
g(x) = -\Lambda x
 t(x)^\top g(x) = 0","['geometry', 'differential-geometry', 'analytic-geometry', 'tangent-spaces', 'ellipsoids']"
36,Why smooth section of vector bundle $F\to M$ is $\Gamma(TM) \times \Gamma(TM) \to \Gamma(NM)$,Why smooth section of vector bundle  is,F\to M \Gamma(TM) \times \Gamma(TM) \to \Gamma(NM),"Let $M\subset \tilde{M}$ be the embedded Riemann submanifold,We can construct the vector bundle $F\to M$ where each fiber is bilinear map $T_pM\times T_pM \to N_pM$ ,which is a smooth vector bundle. The question is why the smooth section of this bundle is $\Gamma(TM) \times \Gamma(TM) \to \Gamma(NM)$ where $NM$ is normal bundle of $M$ ,and $\Gamma$ means smooth section of the corresponding vector bundle. Let's make the theorem more clear,we have the following charaterization lemma: Let $B$ be a rough section of vector bundle $F$ then we can define the map $B(X,Y)(p) = B_p(X_p,Y_p)\in N_pM$ then $B$ is a smooth section of $F$ if and only if $B(X,Y)(p)$ is a smooth section of $NM$ for each smooth vector field $X,Y$","Let be the embedded Riemann submanifold,We can construct the vector bundle where each fiber is bilinear map ,which is a smooth vector bundle. The question is why the smooth section of this bundle is where is normal bundle of ,and means smooth section of the corresponding vector bundle. Let's make the theorem more clear,we have the following charaterization lemma: Let be a rough section of vector bundle then we can define the map then is a smooth section of if and only if is a smooth section of for each smooth vector field","M\subset \tilde{M} F\to M T_pM\times T_pM \to N_pM \Gamma(TM) \times \Gamma(TM) \to \Gamma(NM) NM M \Gamma B F B(X,Y)(p) = B_p(X_p,Y_p)\in N_pM B F B(X,Y)(p) NM X,Y","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
37,symplectic geometry: help showing the cotangent lift of an action to a symplectic manifold is a symplectic action,symplectic geometry: help showing the cotangent lift of an action to a symplectic manifold is a symplectic action,,"I am following da Silva's lectures on symplectic geometry. She defines the lift of a diffeomorphism as follows: Let $X_1$ and $X_2$ be $n$ -dimensional manifolds with cotangent bundles $M_1=T^*X_1$ and $M_2=T^*X_2$ and suppose $f:X_1 \rightarrow X_2$ is a diffeomorphism. Then the lift $f_\#:M_1 \rightarrow M_2$ is defined $$f_\#(p_1) = p_2 = (x_2, \xi_2) = (f(x_1), \xi_2) $$ where $\xi_1 = (f_{x_1})^*\xi_2 = \xi_{2}\circ df_{x_1}$ and $\xi_2 \in (T^*X_2)_{f(x_1)}$ $f_\#\rvert_{T^*X_1}$ is therefore the inverse map of $(f_{x_1})^*$ and so $\xi_2 = [(f_{x_1})^*]^{-1}\xi_1 = (f^{-1}_{x_1})^*$ Now let $(M, \omega)$ be the symplectic manifold obtained by equipping the tangent bundle $M=T^*N$ with the canonical 2-form $\omega = \sum_i dx^i \wedge d\xi^i$ and let the Lie Group G act on N: $$\psi: G \rightarrow \text{Diff(M)}, \quad g \rightarrow \psi_g \\ $$ I am trying to prove the contangent lift of the action is symplectic (and hamiltonian) We must have $$(\psi_g)_\#(p) = (\psi_g)_\#(x, \xi) = (\psi_g(x), (\psi_g^{-1})^*(\xi)) = (\psi_g(x), (\psi_{g^{-1}})^*(\xi)) $$ This must preserve the symplectic form, i.e. $$((f_\#)^*\omega)_p (u, v) = \omega_{f_\#(p)}(df_p(u), df_p(v)) $$ I am unsure what to do from here. I can see the symplectic form takes in two coordinates that transform in seemingly inverse ways. Could someone point me in the right direction ? It would also help if anyone spots any errors in the way I state the problem, I have studied physics so far and am slightly out my depth with the mathematics. EDIT: Solution using tautological one-form (this method is in da Silva's notes) We want to show $(f_\#)^*\alpha_2 = \alpha_1$ The tautological form on $M_1$ , $M_2$ is defined: $$(\alpha_1)_{p_1} = \pi^*_{p_1}\xi_1, \quad \quad (\alpha_2)_{p_2} = \pi^*_{p_2}\xi_2$$ So we have $$\begin{align}(f_\#)^*_{p_1}(\alpha_2)_{p_2} &= (f_\#)^*_{p_1}\pi^*_{p_2}(\xi_2)] \\ &= (\pi_2 \circ f_\#)^*_{p_1} \xi_2 \\ &= (f \circ \pi_1)^*_{p_1} \xi_2 \quad\quad \text{(The lift is constructed as such)} \\ &= (\pi_1)^*_{p_1}f^*_{x_1}\xi_2 \\ &= (\pi_1)^*_{p_1}\xi_1 \quad\quad \text{(By definition of the lift)}\\ &= (\alpha_1)_{p_1} \end{align} $$ Therefore $f_\#$ preserves the tautological form as well as $d\alpha_1$ , the canonical 2-form which is symplectic on $M_1$ Therefore the lift of the diffeomorphism $\psi_g:X_1 \rightarrow X_2$ is: $(\psi_\#)_g:M_1 \rightarrow M_2$ and it is a symplectomorphism. The lift of the action $\psi_\#$ is therefore symplectic. It can also be shown the action is hamiltonian. It seems obvious since we are preserving the tautological one-form, although I'm not sure on the proof.","I am following da Silva's lectures on symplectic geometry. She defines the lift of a diffeomorphism as follows: Let and be -dimensional manifolds with cotangent bundles and and suppose is a diffeomorphism. Then the lift is defined where and is therefore the inverse map of and so Now let be the symplectic manifold obtained by equipping the tangent bundle with the canonical 2-form and let the Lie Group G act on N: I am trying to prove the contangent lift of the action is symplectic (and hamiltonian) We must have This must preserve the symplectic form, i.e. I am unsure what to do from here. I can see the symplectic form takes in two coordinates that transform in seemingly inverse ways. Could someone point me in the right direction ? It would also help if anyone spots any errors in the way I state the problem, I have studied physics so far and am slightly out my depth with the mathematics. EDIT: Solution using tautological one-form (this method is in da Silva's notes) We want to show The tautological form on , is defined: So we have Therefore preserves the tautological form as well as , the canonical 2-form which is symplectic on Therefore the lift of the diffeomorphism is: and it is a symplectomorphism. The lift of the action is therefore symplectic. It can also be shown the action is hamiltonian. It seems obvious since we are preserving the tautological one-form, although I'm not sure on the proof.","X_1 X_2 n M_1=T^*X_1 M_2=T^*X_2 f:X_1 \rightarrow X_2 f_\#:M_1 \rightarrow M_2 f_\#(p_1) = p_2 = (x_2, \xi_2) = (f(x_1), \xi_2)
 \xi_1 = (f_{x_1})^*\xi_2 = \xi_{2}\circ df_{x_1} \xi_2 \in (T^*X_2)_{f(x_1)} f_\#\rvert_{T^*X_1} (f_{x_1})^* \xi_2 = [(f_{x_1})^*]^{-1}\xi_1 = (f^{-1}_{x_1})^* (M, \omega) M=T^*N \omega = \sum_i dx^i \wedge d\xi^i \psi: G \rightarrow \text{Diff(M)}, \quad g \rightarrow \psi_g \\
 (\psi_g)_\#(p) = (\psi_g)_\#(x, \xi) = (\psi_g(x), (\psi_g^{-1})^*(\xi)) = (\psi_g(x), (\psi_{g^{-1}})^*(\xi))
 ((f_\#)^*\omega)_p (u, v) = \omega_{f_\#(p)}(df_p(u), df_p(v))
 (f_\#)^*\alpha_2 = \alpha_1 M_1 M_2 (\alpha_1)_{p_1} = \pi^*_{p_1}\xi_1, \quad \quad (\alpha_2)_{p_2} = \pi^*_{p_2}\xi_2 \begin{align}(f_\#)^*_{p_1}(\alpha_2)_{p_2} &= (f_\#)^*_{p_1}\pi^*_{p_2}(\xi_2)] \\
&= (\pi_2 \circ f_\#)^*_{p_1} \xi_2 \\
&= (f \circ \pi_1)^*_{p_1} \xi_2 \quad\quad \text{(The lift is constructed as such)} \\
&= (\pi_1)^*_{p_1}f^*_{x_1}\xi_2 \\
&= (\pi_1)^*_{p_1}\xi_1 \quad\quad \text{(By definition of the lift)}\\
&= (\alpha_1)_{p_1}
\end{align}
 f_\# d\alpha_1 M_1 \psi_g:X_1 \rightarrow X_2 (\psi_\#)_g:M_1 \rightarrow M_2 \psi_\#","['differential-geometry', 'manifolds', 'group-actions', 'symplectic-geometry', 'co-tangent-space']"
38,Showing $\Delta(\Omega^p M)=d(\Omega^{p-1}M)\oplus \delta(\Omega^{p+1}M)$ [duplicate],Showing  [duplicate],\Delta(\Omega^p M)=d(\Omega^{p-1}M)\oplus \delta(\Omega^{p+1}M),"This question already has an answer here : Solvability of Poisson's equation for $p$-forms directly from Hodge decomposition (1 answer) Closed 2 years ago . Let $M$ be a compact Riemannian manifold, $*$ be the Hodge star operation, $d$ the exterior derivative, $\delta$ the codifferential $(\delta\omega=(-1)^{n(k+1)+1} *d*\omega$ where $n=\dim M$ and $k=\deg \omega$ ), and $\Delta=d\delta+\delta d $ the Laplacian operator. How can we show that $\Delta(\Omega^p M)=d(\Omega^{p-1}M)\oplus \delta(\Omega^{p+1}M)$ ? (Here $\Omega^pM$ denotes the space of $p$ -forms on $M$ .) To show this, we have to show the followings: $d(\Omega^{p-1}M)\subset \Delta(\Omega^pM)$ and $\delta(\Omega^{p+1}M)\subset \Delta(\Omega^pM)$ , $d(\Omega^{p-1}M)\cap \delta(\Omega^{p+1}M)=0$ , and $d(\Omega^{p-1}M)+\delta(\Omega^{p+1}M)=\Delta(\Omega^pM)$ . The third one is obvious by definition of $\Delta$ . The second one follows from the fact that they are orthogonal. But how can we show 1?","This question already has an answer here : Solvability of Poisson's equation for $p$-forms directly from Hodge decomposition (1 answer) Closed 2 years ago . Let be a compact Riemannian manifold, be the Hodge star operation, the exterior derivative, the codifferential where and ), and the Laplacian operator. How can we show that ? (Here denotes the space of -forms on .) To show this, we have to show the followings: and , , and . The third one is obvious by definition of . The second one follows from the fact that they are orthogonal. But how can we show 1?",M * d \delta (\delta\omega=(-1)^{n(k+1)+1} *d*\omega n=\dim M k=\deg \omega \Delta=d\delta+\delta d  \Delta(\Omega^p M)=d(\Omega^{p-1}M)\oplus \delta(\Omega^{p+1}M) \Omega^pM p M d(\Omega^{p-1}M)\subset \Delta(\Omega^pM) \delta(\Omega^{p+1}M)\subset \Delta(\Omega^pM) d(\Omega^{p-1}M)\cap \delta(\Omega^{p+1}M)=0 d(\Omega^{p-1}M)+\delta(\Omega^{p+1}M)=\Delta(\Omega^pM) \Delta,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'differential-forms', 'hodge-theory']"
39,Do Carmo's discussion of how $|b'(s)|$ measures how rapidly a curve pulls away from the osculating plane at $s$,Do Carmo's discussion of how  measures how rapidly a curve pulls away from the osculating plane at,|b'(s)| s,"I am reading Do Carmo's Differential Geometry of Curves and Surface s, and a passage on page $18$ is confusing me. He writes: In what fallows we shall restrict ourselves to curves $\alpha(s)$ parametrized by arc length without singular points of order $1$ . We shall denote $t(s) = \alpha'(s)$ , the unit tangent vector of $\alpha$ at $s$ . Thus $t'(s) = k(s)n(s)$ (where $k(s)$ is the curvature of $\alpha$ ). The unit vector $b(s) = t(s) \times n(s)$ is normal to the osculating plane and will be called the binormal vector at $x$ . Since $b(s)$ is a unit vector, the length of $|b'(s)|$ measures the rate of change of the neighboring osculating planes with the osculating plane at $s$ ; that is, $b'(s)$ measures how rapidly the curve pulls away from the osculating plane at $s$ in a neighborhood of $s$ . I see that because $t(s), b(s)$ are both of norm $1$ and perpendicular that their cross product has length $1$ . I am not sure why since $b(s)$ is a unit vector, that the length $|b'(s)$ | mesasures how rapdidly the curve pulls away from the osculating plane at $s$ . How does the norm of $b'(s)$ play into things? If I look at what $b'(s)$ is, well its $\frac{d}{dt} (t(s) \times n(s)) = \frac{dt}{ds}\times n(s) + t(s) \times \frac{dn}{ds} $ , and well from here I'm not really sure how to proceed. Any insights appreciated.","I am reading Do Carmo's Differential Geometry of Curves and Surface s, and a passage on page is confusing me. He writes: In what fallows we shall restrict ourselves to curves parametrized by arc length without singular points of order . We shall denote , the unit tangent vector of at . Thus (where is the curvature of ). The unit vector is normal to the osculating plane and will be called the binormal vector at . Since is a unit vector, the length of measures the rate of change of the neighboring osculating planes with the osculating plane at ; that is, measures how rapidly the curve pulls away from the osculating plane at in a neighborhood of . I see that because are both of norm and perpendicular that their cross product has length . I am not sure why since is a unit vector, that the length | mesasures how rapdidly the curve pulls away from the osculating plane at . How does the norm of play into things? If I look at what is, well its , and well from here I'm not really sure how to proceed. Any insights appreciated.","18 \alpha(s) 1 t(s) = \alpha'(s) \alpha s t'(s) = k(s)n(s) k(s) \alpha b(s) = t(s) \times n(s) x b(s) |b'(s)| s b'(s) s s t(s), b(s) 1 1 b(s) |b'(s) s b'(s) b'(s) \frac{d}{dt} (t(s) \times n(s)) = \frac{dt}{ds}\times n(s) + t(s) \times \frac{dn}{ds} ",['differential-geometry']
40,Poisson bracket and co-adjoint orbits for $sl(2)$,Poisson bracket and co-adjoint orbits for,sl(2),"So I am trying to do this problem from Peter Olver's book Application of Lie groups to differential equations and I am wondering if somebody could check my work because I am not really sure about it and I am trying to really understand this material by testing myself. So to start off for the Lie-Poisson bracket I am pretty convinced this is not correct because it just doesn't look right. So for $sl(2)$ I used the basis matrices $$ A_1 = \begin{bmatrix} 0 \;\; 1 \\ 0 \;\; 0 \end{bmatrix} A_2 = \begin{bmatrix} 1  \;\;\;\;\;\; 0 \\ 0 \;\; -1 \end{bmatrix}  A_3 = \begin{bmatrix} 0 \;\; 0 \\ 1 \;\; 0 \end{bmatrix}$$ Then I used this definition for the Poisson bracket So I calculated all the structure constants with respect to my basis by using the Lie-brack of the matrices and I got $$\{F,H\} = (2x^3,x^2,2x^1) \cdot \nabla F \times \nabla H$$ where $\nabla F = (\frac{dF}{dx^1}, \frac{dF}{dx^2}, \frac{dF}{dx^3})$ now this just feels very wrong... perhaps what is meant by the question is the poisson bracket on $sl(2)^*$ ? which might be what I calculated... I am not sure. Now for the co-adjoint orbits, I first computed the adjoint map and then looked at the dual of that map to find the co-adjoint map and orbits. So what I did was took $X = \begin{bmatrix} a \;\; b \\ c \;\; d \end{bmatrix}  \in SL(2) \implies ad-bc = 1$ then $$Ad_X(A_1) = XA_1X^{-1} = a^2 \cdot A_1 -ac \cdot A_2 -c^2\cdot A_3$$ $$ Ad_X(A_2) = XA_2X^{-1} = -2ab \cdot A_1 + (ad+bc) \cdot A_2 + 2dc\cdot A_3 $$ $$Ad_X(A_3) = XA_3X^{-1} = -b^2 \cdot A_1 +bd \cdot A_2 +d^2\cdot A_3$$ So the matrix representation of $Ad_X$ is $$ R= \begin{bmatrix}a^2 \;\;\;\; -2ab \;\;\;\; -b^2 \\ -ac \;\;\;\; ab+bc \;\;\;\; bd \\ -c^2 \;\;\;\; 2dc \;\;\;\; d^2 \end{bmatrix}$$ And so then the matrix representation $Ad_X^*$ is $(R^{-1})^T$ which I got to be $$ (R^{-1})^T= \begin{bmatrix}d^2 \;\;\;\; cd \;\;\;\; -c^2 \\ 2bd \;\;\;\; ab+bc \;\;\;\; -2ac \\ -b^2 \;\;\;\; -ab \;\;\;\; a^2 \end{bmatrix}$$ but then I am kind of confused as to how to even think about the orbits here. If I take $A \in sl(2) \implies A = xA_1 + y A_2 + zA_3$ so then $$Ad_X^*(A) = \begin{bmatrix}d^2 \;\;\;\; cd \;\;\;\; -c^2 \\ 2bd \;\;\;\; ab+bc \;\;\;\; -2ac \\ -b^2 \;\;\;\; -ab \;\;\;\; a^2 \end{bmatrix} \cdot \begin{bmatrix} x \\ y \\ z\\  \end{bmatrix} = \begin{bmatrix} xd^2 +ycd -zc^2 \\ x2bd + yad+ybc -2zac \\ -xb^2 -yab + za^2 \end{bmatrix}$$ this is the basis representation with respect to $A_1,A_2,A_3$ but I am not really sure what this gives me... it doesn't look obvious to me, and I cannot seem to find any solution on the web so I am wondering if I made a mistake or if this is just the final answer and I cannot see what it represents.","So I am trying to do this problem from Peter Olver's book Application of Lie groups to differential equations and I am wondering if somebody could check my work because I am not really sure about it and I am trying to really understand this material by testing myself. So to start off for the Lie-Poisson bracket I am pretty convinced this is not correct because it just doesn't look right. So for I used the basis matrices Then I used this definition for the Poisson bracket So I calculated all the structure constants with respect to my basis by using the Lie-brack of the matrices and I got where now this just feels very wrong... perhaps what is meant by the question is the poisson bracket on ? which might be what I calculated... I am not sure. Now for the co-adjoint orbits, I first computed the adjoint map and then looked at the dual of that map to find the co-adjoint map and orbits. So what I did was took then So the matrix representation of is And so then the matrix representation is which I got to be but then I am kind of confused as to how to even think about the orbits here. If I take so then this is the basis representation with respect to but I am not really sure what this gives me... it doesn't look obvious to me, and I cannot seem to find any solution on the web so I am wondering if I made a mistake or if this is just the final answer and I cannot see what it represents.","sl(2)  A_1 = \begin{bmatrix} 0 \;\; 1
\\ 0 \;\; 0
\end{bmatrix}
A_2 = \begin{bmatrix} 1  \;\;\;\;\;\; 0
\\ 0 \;\; -1
\end{bmatrix} 
A_3 = \begin{bmatrix} 0 \;\; 0
\\ 1 \;\; 0
\end{bmatrix} \{F,H\} = (2x^3,x^2,2x^1) \cdot \nabla F \times \nabla H \nabla F = (\frac{dF}{dx^1}, \frac{dF}{dx^2}, \frac{dF}{dx^3}) sl(2)^* X = \begin{bmatrix} a \;\; b
\\ c \;\; d
\end{bmatrix}  \in SL(2) \implies ad-bc = 1 Ad_X(A_1) = XA_1X^{-1} = a^2 \cdot A_1 -ac \cdot A_2 -c^2\cdot A_3  Ad_X(A_2) = XA_2X^{-1} = -2ab \cdot A_1 + (ad+bc) \cdot A_2 + 2dc\cdot A_3  Ad_X(A_3) = XA_3X^{-1} = -b^2 \cdot A_1 +bd \cdot A_2 +d^2\cdot A_3 Ad_X  R= \begin{bmatrix}a^2 \;\;\;\; -2ab \;\;\;\; -b^2 \\
-ac \;\;\;\; ab+bc \;\;\;\; bd \\
-c^2 \;\;\;\; 2dc \;\;\;\; d^2
\end{bmatrix} Ad_X^* (R^{-1})^T  (R^{-1})^T= \begin{bmatrix}d^2 \;\;\;\; cd \;\;\;\; -c^2 \\
2bd \;\;\;\; ab+bc \;\;\;\; -2ac \\
-b^2 \;\;\;\; -ab \;\;\;\; a^2
\end{bmatrix} A \in sl(2) \implies A = xA_1 + y A_2 + zA_3 Ad_X^*(A) = \begin{bmatrix}d^2 \;\;\;\; cd \;\;\;\; -c^2 \\
2bd \;\;\;\; ab+bc \;\;\;\; -2ac \\
-b^2 \;\;\;\; -ab \;\;\;\; a^2
\end{bmatrix} \cdot \begin{bmatrix} x \\ y \\ z\\ 
\end{bmatrix} = \begin{bmatrix} xd^2 +ycd -zc^2 \\ x2bd + yad+ybc -2zac \\ -xb^2 -yab + za^2
\end{bmatrix} A_1,A_2,A_3","['differential-geometry', 'lie-algebras', 'symplectic-geometry', 'adjoint-operators', 'poisson-geometry']"
41,Trying to write the bundle structure for $\Lambda^2(T^*(\mathbb P^3\times \mathbb P^3))$,Trying to write the bundle structure for,\Lambda^2(T^*(\mathbb P^3\times \mathbb P^3)),"I'm trying to find an atlas and in general the bundle structure for $\Lambda^2(T^*(\mathbb P^3\times \mathbb P^3))$ respect to, for example, the local chart $(U_{01},\psi_{01})$ , where $$U_{01}:=\{((x^0:x^1:x^2:x^3),(y^0:y^1:y^2:y^3))\in\mathbb P^3\times \mathbb P^3|x^0\ne 0,y^1\ne 0\}$$ and $\psi_{01}:U_{01}\subset\mathbb P^3\times \mathbb P^3\to\mathbb R^3\times \mathbb R^3$ is the standard chart that divides for the non-zero component. In particular I was trying to build the bundle structure for $\Lambda^2(T^*(\mathbb P^3\times \mathbb P^3))$ starting from $T^*(\mathbb P^3\times \mathbb P^3)$ and I did this: Could you tell me if it's correct? How could I ""extend"" this idea to build a smooth structure for $\Lambda^2(T^*(\mathbb P^3\times \mathbb P^3))$ ? Thank you in advance.","I'm trying to find an atlas and in general the bundle structure for respect to, for example, the local chart , where and is the standard chart that divides for the non-zero component. In particular I was trying to build the bundle structure for starting from and I did this: Could you tell me if it's correct? How could I ""extend"" this idea to build a smooth structure for ? Thank you in advance.","\Lambda^2(T^*(\mathbb P^3\times \mathbb P^3)) (U_{01},\psi_{01}) U_{01}:=\{((x^0:x^1:x^2:x^3),(y^0:y^1:y^2:y^3))\in\mathbb P^3\times \mathbb P^3|x^0\ne 0,y^1\ne 0\} \psi_{01}:U_{01}\subset\mathbb P^3\times \mathbb P^3\to\mathbb R^3\times \mathbb R^3 \Lambda^2(T^*(\mathbb P^3\times \mathbb P^3)) T^*(\mathbb P^3\times \mathbb P^3) \Lambda^2(T^*(\mathbb P^3\times \mathbb P^3))","['differential-geometry', 'differential-forms', 'projective-geometry', 'tangent-bundle']"
42,period of the curvature and the period of the corresponding curve $\frac1{2\pi}\int_0^{\rho_k}k(s)\mathrm ds\in\Bbb Z$,period of the curvature and the period of the corresponding curve,\frac1{2\pi}\int_0^{\rho_k}k(s)\mathrm ds\in\Bbb Z,"The paper "" When Is a Periodic Function the Curvature of a Closed Plane Curve?"", May 2008 The American Mathematical Monthly 115(5):405-414 The paper says: A Closed Plane Curve, when the (minimum) period of the (signed) curvature and the period of the corresponding curve do not coincide, if and only if $$\frac1{2\pi}\int_0^{\rho_k}k(s)\mathrm ds\in\Bbb Q-\Bbb Z$$ where $\rho_k$ is the (minimum) period of the signed curvature. Please refer to Proposition 2.1 and   the beginning of part 4 of the paper：if $\frac1{2\pi}\int_0^{\rho_k}k(s)\mathrm ds\in Z$ , then in this case the (minimum) period of the curvature and the period of the corresponding curve would coincide if the latter eventually closes up. But the paper dones't prove this. How to show the claim is correct? Thanks the paper : Wherher take a look at it, doesn't affect the topic here When Is a Periodic Function the Curvature of a Closed Plane Curve?","The paper "" When Is a Periodic Function the Curvature of a Closed Plane Curve?"", May 2008 The American Mathematical Monthly 115(5):405-414 The paper says: A Closed Plane Curve, when the (minimum) period of the (signed) curvature and the period of the corresponding curve do not coincide, if and only if where is the (minimum) period of the signed curvature. Please refer to Proposition 2.1 and   the beginning of part 4 of the paper：if , then in this case the (minimum) period of the curvature and the period of the corresponding curve would coincide if the latter eventually closes up. But the paper dones't prove this. How to show the claim is correct? Thanks the paper : Wherher take a look at it, doesn't affect the topic here When Is a Periodic Function the Curvature of a Closed Plane Curve?",\frac1{2\pi}\int_0^{\rho_k}k(s)\mathrm ds\in\Bbb Q-\Bbb Z \rho_k \frac1{2\pi}\int_0^{\rho_k}k(s)\mathrm ds\in Z,"['differential-geometry', 'curvature', 'plane-curves']"
43,Intersection of sphere of radius c and a general ellipsoid,Intersection of sphere of radius c and a general ellipsoid,,"Question: Given the ellipsoid $$E:\ \ \frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}=1, \ \  0 < a < c < b,$$ let $\pmb{\alpha}$ denotes the intersection of $E\ $ with the sphere $$S^2(c): \ \ x^2 + y^2 +z^2 =c^2.$$ Show that $\pmb{\alpha}$ is the union [of the traces] of two regular curves $\pmb{\alpha_1}$ and $\pmb{\alpha_2}$ . Parametrise either curve and compute its torsion, $\tau$ . Attempts : I've not gotten past the first part. I've found that a local parametrisation for $E$ is $\mathbf{x}(u,v)=(a\cos u \sin v,\ b \sin u \sin v,\ c \ \cos v)$ which hasn't really made a difference in my confusion. In both the books I have and on related questions found on this site, the intersection seems to be given specifically for the unit sphere and I'm not sure how to extend the theory to a general sphere. Further, any computation I do seems to return the solution $a=b=c=1$ which clearly contradicts the fact that $0 < a < c < b$ .","Question: Given the ellipsoid let denotes the intersection of with the sphere Show that is the union [of the traces] of two regular curves and . Parametrise either curve and compute its torsion, . Attempts : I've not gotten past the first part. I've found that a local parametrisation for is which hasn't really made a difference in my confusion. In both the books I have and on related questions found on this site, the intersection seems to be given specifically for the unit sphere and I'm not sure how to extend the theory to a general sphere. Further, any computation I do seems to return the solution which clearly contradicts the fact that .","E:\ \ \frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}=1, \ \  0 < a < c < b, \pmb{\alpha} E\  S^2(c): \ \ x^2 + y^2 +z^2 =c^2. \pmb{\alpha} \pmb{\alpha_1} \pmb{\alpha_2} \tau E \mathbf{x}(u,v)=(a\cos u \sin v,\ b \sin u \sin v,\ c \ \cos v) a=b=c=1 0 < a < c < b","['differential-geometry', 'spheres', 'ellipsoids']"
44,Parameterization of the Hawaiian Earring,Parameterization of the Hawaiian Earring,,"I've been trying to find a way to parameterize the Hawaiian Earring, i.e. to find a parametric function $[0,1]\to\mathbb{H}$ . I  would like this function to be continuous and differentiable. So far I only know that I can express a circle of radius $\frac{1}{n}$ for $n\in\mathbb{N}$ as $$t\mapsto \frac{1}{n}(\cos(2t\pi)+1,\sin(2t\pi))$$ but am struggling with finding a way to somehow cover all $n$ 's with just one function. I think that I should somehow express $n$ as $n(t)$ , which would be a step function on smaller and smaller parts of the $[0,1]$ interval, but am very much stuck on how to do such a thing. Would this kind of approach work for this? If so, any hints on how to proceed? Or should I be thinking about this in some other way? Thanks for any help.","I've been trying to find a way to parameterize the Hawaiian Earring, i.e. to find a parametric function . I  would like this function to be continuous and differentiable. So far I only know that I can express a circle of radius for as but am struggling with finding a way to somehow cover all 's with just one function. I think that I should somehow express as , which would be a step function on smaller and smaller parts of the interval, but am very much stuck on how to do such a thing. Would this kind of approach work for this? If so, any hints on how to proceed? Or should I be thinking about this in some other way? Thanks for any help.","[0,1]\to\mathbb{H} \frac{1}{n} n\in\mathbb{N} t\mapsto \frac{1}{n}(\cos(2t\pi)+1,\sin(2t\pi)) n n n(t) [0,1]","['real-analysis', 'differential-geometry']"
45,Gauss Bonnet Theorem for half a cone,Gauss Bonnet Theorem for half a cone,,"Let $S \subset \mathbb{R}^3$ be given by $$ S = \{ (x,y,z) \in \mathbb{R}^3 \, : \, x^2+y^2=z^2 , \quad y \ge0, 0\le z \le 1 \}. $$ Verify the Gauss Bonnet Theorem, by computing $\int_S K\, dA$ and $\int_{\partial S} \kappa_g \, ds $ . Computation of $\int_S K \, dA$ : The surface (minus the pointy end) is a local isometry of a plane so the Gauss curvature $K$ is everywhere $0$ , so this integral contributes nothing. I think this can also be found easily via $K = (LN-M^2)/(EG-F^2) = 0 $ via parametrizing the half-cone. Computation of $\int_{\partial S} \kappa_g \, ds $ : The meridians of the cone are geodesics and have zero geodesic curvature, so the meridians don't contribute. The other boundary of the half-cone is the semi-circle parametrized by $\alpha(t) = (\cos(t), \sin(t), 1)$ for $ t \in (0, \pi)$ . To find the geodesic curvature $\kappa_g$ on the cone, one computes the Gauss map $N \circ \alpha(t) = (\cos(t), \sin(t), -1)/\sqrt{2}$ and then use the formula $$ \kappa_g = \frac{1}{|| \alpha'||^3} (\alpha' \times \alpha'') \cdot (N \circ(\alpha)) = \frac{-1}{\sqrt{2}} $$ Note: I am aware more careful analysis of tangent direction is required to determine the sign - but I'm quite sure it's $1/\sqrt{2}$ up to $\pm$ . The length of the semi-circle is $\pi$ , making this integral $\pm \pi/\sqrt{2}$ . And then finally the Euler Characteristic of the half-cone is $1$ . (Homeomorphic to a disc). But then it doesn't add up with the Gauss Bonnet theorem: $$ \int_S K \, dA + \int_{\partial S} \kappa_g \, ds + \sum_{i=1}^n \theta_i = 2 \pi \chi(S) $$ $$ \implies 0  \pm \frac{\pi}{\sqrt{2}} +  \sum_{i=1}^n \theta_i = 2 \pi$$ And I can't see any way the exterior angles (given by $\sum_{i=1}^n \theta_i$ ) can make this work. By my computation, we have three right-angles, giving this sum to be $3 \pi /2$ which can't cancel the $1/\sqrt{2}$ . There must be an error somewhere. Any insight or help is greatly appreciated!","Let be given by Verify the Gauss Bonnet Theorem, by computing and . Computation of : The surface (minus the pointy end) is a local isometry of a plane so the Gauss curvature is everywhere , so this integral contributes nothing. I think this can also be found easily via via parametrizing the half-cone. Computation of : The meridians of the cone are geodesics and have zero geodesic curvature, so the meridians don't contribute. The other boundary of the half-cone is the semi-circle parametrized by for . To find the geodesic curvature on the cone, one computes the Gauss map and then use the formula Note: I am aware more careful analysis of tangent direction is required to determine the sign - but I'm quite sure it's up to . The length of the semi-circle is , making this integral . And then finally the Euler Characteristic of the half-cone is . (Homeomorphic to a disc). But then it doesn't add up with the Gauss Bonnet theorem: And I can't see any way the exterior angles (given by ) can make this work. By my computation, we have three right-angles, giving this sum to be which can't cancel the . There must be an error somewhere. Any insight or help is greatly appreciated!","S \subset \mathbb{R}^3  S = \{ (x,y,z) \in \mathbb{R}^3 \, : \, x^2+y^2=z^2 , \quad y \ge0, 0\le z \le 1 \}.  \int_S K\, dA \int_{\partial S} \kappa_g \, ds  \int_S K \, dA K 0 K = (LN-M^2)/(EG-F^2) = 0  \int_{\partial S} \kappa_g \, ds  \alpha(t) = (\cos(t), \sin(t), 1)  t \in (0, \pi) \kappa_g N \circ \alpha(t) = (\cos(t), \sin(t), -1)/\sqrt{2}  \kappa_g = \frac{1}{|| \alpha'||^3} (\alpha' \times \alpha'') \cdot (N \circ(\alpha)) = \frac{-1}{\sqrt{2}}  1/\sqrt{2} \pm \pi \pm \pi/\sqrt{2} 1  \int_S K \, dA + \int_{\partial S} \kappa_g \, ds + \sum_{i=1}^n \theta_i = 2 \pi \chi(S)   \implies 0  \pm \frac{\pi}{\sqrt{2}} +  \sum_{i=1}^n \theta_i = 2 \pi \sum_{i=1}^n \theta_i 3 \pi /2 1/\sqrt{2}","['differential-geometry', 'riemannian-geometry', 'surfaces', 'geodesic']"
46,Pushforward from Flag variety,Pushforward from Flag variety,,"Consider a vector space $V$ and some $n,n+1\leqslant\dim V$ . Let $F\subset G(n,V)\times G(n+1,V)$ be the Flag variety (where $G(n,V)$ is the Grassmannian of $n$ -dimensional subspaces of $V$ ), i.e. the subvariety of couples $(W,W')$ such that $W\subset W'$ . We have projections from $F$ to both $G(n,V)$ and $G(n+1,V)$ . I can show that the projection to $G(n,V)$ is just the projectivization $P(Q)$ , where $Q$ is the universal quotient bundle on $G(n,V)$ . Is there a way to describe the second projection, i.e. $\pi:F\rightarrow G(n+1,V)$ , and more specifically, what is the pushforward $\pi_{\ast}(\mathcal{O})$ of the structure sheaf? Is $\pi$ just the projectivization $P(S)$ , where $S$ is the universal subbundle on $G(n+1,V)$ so $\pi_{\ast}(O)=O$ ?","Consider a vector space and some . Let be the Flag variety (where is the Grassmannian of -dimensional subspaces of ), i.e. the subvariety of couples such that . We have projections from to both and . I can show that the projection to is just the projectivization , where is the universal quotient bundle on . Is there a way to describe the second projection, i.e. , and more specifically, what is the pushforward of the structure sheaf? Is just the projectivization , where is the universal subbundle on so ?","V n,n+1\leqslant\dim V F\subset G(n,V)\times G(n+1,V) G(n,V) n V (W,W') W\subset W' F G(n,V) G(n+1,V) G(n,V) P(Q) Q G(n,V) \pi:F\rightarrow G(n+1,V) \pi_{\ast}(\mathcal{O}) \pi P(S) S G(n+1,V) \pi_{\ast}(O)=O","['differential-geometry', 'algebraic-geometry', 'grassmannian']"
47,Defining curvature via osculating circles,Defining curvature via osculating circles,,"I am trying to figure out a geometrically accessible definition for the curvature of a smooth plane curve $c:I \to \mathbb{R}^2$ where $I$ is an interval and $c' \neq 0$ everywhere. My plan is to define the curvature via the osculating circle so that the definition might take the following form: if the osculating circle at a point $c(t_0)$ exists and has radius $r$ , define the curvature as $\kappa(t_0):=1/r$ . If the circle doesn't exist (for example, if $c$ is a straight line), define $\kappa(t_0):=0$ . Moreover, I want to do all this without assuming that $c$ is a unit-speed parametrization. Question: Does anyone know how such a definition of the curvature could look like in mathematically precise terms? It is important that the definition is mathematically precise. I also plan to compare the above definition with the more common definition which uses the Frenet frame and show that both definitions yield the same function $\kappa:I \to \mathbb{R}$ up to sign. So, a robust definition is wanted. My attempts and problems: First of all, we need a precise definition of the osculating circle and a precise and useful criterion when it exists. Here is where I already stuck. I tried to work with something like this: For $h>0$ , let $M(t_0,h)$ the center of the circle through the three points $c(t_0-h)$ , $c(t_0)$ and $c(t_0+h)$ , presupposed they are not located on a straight line. The osculating circle at $c(t_0)$ could then be ""defined"" as the circle with center $M$ and radius $r$ where $$M:= \lim_{h \to 0} M(t_0,h),\phantom{aaa}r:=\Vert M-c(t_0)\Vert$$ In order for this definition to work, we must ensure that for sufficiently small $h>0$ , the three points $c(t_0 \pm h), c(t_0)$ are not collinear. Otherwise, the points $M(t_0,h)$ do not exist as $h \to 0$ and it makes no sense to talk about their limit. So, we may at least require some condition like this: $\phantom{aa}$ There is a sequence $(h_n)_{n\in \mathbb{N}}$ with $h_n \to 0$ and all $h_n >0$ such that for each $n$ , the points $\phantom{aai}$$c(t_0 \pm h_n), c(t_0)$ are not collinear. But using only this condition, I have no idea how to prove that the limit $\lim_{h \to 0} M(t_0,h)$ exists which is also necessary in order to show that the definition makes sense. Needless to say that all this should be done without referring to the curvature since I want to use the osculating circles to define the curvature and avoid circularity. Remark: During the past days, I already posted some related questions. However, they might have been unclear or to narrowly focused on particular details so that answers didn't really help me. (However, thank you for all the answers.) Some users suggested that I formulate a new question to put all this into a broader context so that the people here get a better idea of what I am trying to achieve and why I have all the questions. I hope this post clarifies the things a bit.","I am trying to figure out a geometrically accessible definition for the curvature of a smooth plane curve where is an interval and everywhere. My plan is to define the curvature via the osculating circle so that the definition might take the following form: if the osculating circle at a point exists and has radius , define the curvature as . If the circle doesn't exist (for example, if is a straight line), define . Moreover, I want to do all this without assuming that is a unit-speed parametrization. Question: Does anyone know how such a definition of the curvature could look like in mathematically precise terms? It is important that the definition is mathematically precise. I also plan to compare the above definition with the more common definition which uses the Frenet frame and show that both definitions yield the same function up to sign. So, a robust definition is wanted. My attempts and problems: First of all, we need a precise definition of the osculating circle and a precise and useful criterion when it exists. Here is where I already stuck. I tried to work with something like this: For , let the center of the circle through the three points , and , presupposed they are not located on a straight line. The osculating circle at could then be ""defined"" as the circle with center and radius where In order for this definition to work, we must ensure that for sufficiently small , the three points are not collinear. Otherwise, the points do not exist as and it makes no sense to talk about their limit. So, we may at least require some condition like this: There is a sequence with and all such that for each , the points are not collinear. But using only this condition, I have no idea how to prove that the limit exists which is also necessary in order to show that the definition makes sense. Needless to say that all this should be done without referring to the curvature since I want to use the osculating circles to define the curvature and avoid circularity. Remark: During the past days, I already posted some related questions. However, they might have been unclear or to narrowly focused on particular details so that answers didn't really help me. (However, thank you for all the answers.) Some users suggested that I formulate a new question to put all this into a broader context so that the people here get a better idea of what I am trying to achieve and why I have all the questions. I hope this post clarifies the things a bit.","c:I \to \mathbb{R}^2 I c' \neq 0 c(t_0) r \kappa(t_0):=1/r c \kappa(t_0):=0 c \kappa:I \to \mathbb{R} h>0 M(t_0,h) c(t_0-h) c(t_0) c(t_0+h) c(t_0) M r M:= \lim_{h \to 0} M(t_0,h),\phantom{aaa}r:=\Vert M-c(t_0)\Vert h>0 c(t_0 \pm h), c(t_0) M(t_0,h) h \to 0 \phantom{aa} (h_n)_{n\in \mathbb{N}} h_n \to 0 h_n >0 n \phantom{aai}c(t_0 \pm h_n), c(t_0) \lim_{h \to 0} M(t_0,h)","['differential-geometry', 'curves', 'curvature', 'osculating-circle']"
48,Is $TM$ a manifold with or without boundary when $M$ is a manifold with boundary?,Is  a manifold with or without boundary when  is a manifold with boundary?,TM M,"I am working on manifolds with boundary . Assume $(E, \pi)$ is a vector bundle over a manifold with boundary $M$ , for example $TM$ or $T^*M$ . If $\phi : \pi^{-1}(\mathcal{U}) \to \mathcal{U} \times \mathbb{R}^m$ is a vector bundle chart of $E$ and $\varphi : \mathcal{U} \to \mathbb{R}^n$ is a chart (with boundary) of the manifold $M$ , then we can (can we?) induce a manifold chart on $E$ : $$ \xi : \pi^{-1}(\mathcal{U}) \to \varphi(\mathcal{U}) \times \mathbb{R}^m : x \mapsto (\varphi(\pi(x)), t_{\pi(x)}^{-1}(x)) $$ where $t_p : \mathbb{R}^m \to \pi^{-1}(p)$ is the isomorphism between the vector space $\mathbb{R}^m$ and the fiber $\pi^{-1}(p)$ ( $t_p(v) := \varphi^{-1}(p, v)$ ). When $M$ is a manifold without boundary, we can then collect all the charts built in this way into an atlas and induce a manifold structure on $E$ . When $M$ is a manifold without boundary, is the construction above valid? Is $E$ equipped with this manifold structure a manifold with or without boundary? In other words, if $M$ is a manifold with boundary, is $TM$ a manifold with or without boundary?","I am working on manifolds with boundary . Assume is a vector bundle over a manifold with boundary , for example or . If is a vector bundle chart of and is a chart (with boundary) of the manifold , then we can (can we?) induce a manifold chart on : where is the isomorphism between the vector space and the fiber ( ). When is a manifold without boundary, we can then collect all the charts built in this way into an atlas and induce a manifold structure on . When is a manifold without boundary, is the construction above valid? Is equipped with this manifold structure a manifold with or without boundary? In other words, if is a manifold with boundary, is a manifold with or without boundary?","(E, \pi) M TM T^*M \phi : \pi^{-1}(\mathcal{U}) \to \mathcal{U} \times \mathbb{R}^m E \varphi : \mathcal{U} \to \mathbb{R}^n M E 
\xi : \pi^{-1}(\mathcal{U}) \to \varphi(\mathcal{U}) \times \mathbb{R}^m : x \mapsto (\varphi(\pi(x)), t_{\pi(x)}^{-1}(x))
 t_p : \mathbb{R}^m \to \pi^{-1}(p) \mathbb{R}^m \pi^{-1}(p) t_p(v) := \varphi^{-1}(p, v) M E M E M TM","['differential-geometry', 'vector-bundles', 'tangent-bundle']"
49,"If the geodesic curvature of a simple closed spherical curve is monotonic, then it is constant","If the geodesic curvature of a simple closed spherical curve is monotonic, then it is constant",,"Let $\gamma$ be a simple closed curve in the unit sphere $\mathbb{S}^{2} \subset \mathbb{R}^{3}$ . I wish to understand how the property of being simple and closed affects the geodesic curvature of $\gamma$ . Clearly, the geodesic curvature can be constant (e.g., geodesics are simple and closed). In general, I suppose that being simple and closed must result in a minimum number of critical points of the geodesic curvature. In fact, my question is the following. If the geodesic curvature $\kappa_{g}$ of $\gamma$ is nonconstant, does it then follow that its derivative $\kappa_{g}'$ changes sign at least once? Hints on how to prove/disprove this statement would also be helpful.","Let be a simple closed curve in the unit sphere . I wish to understand how the property of being simple and closed affects the geodesic curvature of . Clearly, the geodesic curvature can be constant (e.g., geodesics are simple and closed). In general, I suppose that being simple and closed must result in a minimum number of critical points of the geodesic curvature. In fact, my question is the following. If the geodesic curvature of is nonconstant, does it then follow that its derivative changes sign at least once? Hints on how to prove/disprove this statement would also be helpful.",\gamma \mathbb{S}^{2} \subset \mathbb{R}^{3} \gamma \kappa_{g} \gamma \kappa_{g}',"['differential-geometry', 'riemannian-geometry']"
50,Using quotient to show that a map $\mathbb{RP}^2\rightarrow\mathbb{R}^3$ is an immersion at all but six points,Using quotient to show that a map  is an immersion at all but six points,\mathbb{RP}^2\rightarrow\mathbb{R}^3,"We want to show that $\phi:\mathbb{RP}^2\rightarrow \mathbb{R}^3$ given by $\phi([x,y,z])=\frac{(yz,xz,xy)}{x^2+y^2+z^2}$ is an immersion at all but 6 points. Recall that a map $f$ is an immersion at $x$ if the matrix $Df|_x$ is injective. We know that $\mathbb{RP}^2$ can be given by the quotient map $q:\mathbb{R}^3-\{0\}\rightarrow\mathbb{RP}^2$ by identifying one dimensional subspaces of $\mathbb{R}^3$ . I believe that we have a natural map $(\phi\circ q)(x,y,z)=\frac{(yz,xz,xy)}{x^2+y^2+z^2}$ . I think that the points where $\phi\circ q$ fails to be an immersion correspond to the points where $\phi$ fails to be an immersion. Then I wrote down the Jacobian of $D(\phi\circ q)|_{(x,y,z)}$ in hopes of obtaining $6$ one-dimensional subspaces where the matrix was non-injective, that is, has zero determinant. However, setting the determinant to be zero, I obtained the equation $xyz(-x^2+y^2+z^2)(x^2-y^2+z^2)(x^2+y^2-z^2)=0$ , which in fact gives us three two-dimensional subspaces and $3$ cone-shapes in $\mathbb{R}^3$ . This does not seem to correspond to $6$ points in $\mathbb{RP}^2$ . What am I misunderstanding here? This was a ""simple"" question in a qualifying topology/geometry exam, so I do not believe the solution is too involved.","We want to show that given by is an immersion at all but 6 points. Recall that a map is an immersion at if the matrix is injective. We know that can be given by the quotient map by identifying one dimensional subspaces of . I believe that we have a natural map . I think that the points where fails to be an immersion correspond to the points where fails to be an immersion. Then I wrote down the Jacobian of in hopes of obtaining one-dimensional subspaces where the matrix was non-injective, that is, has zero determinant. However, setting the determinant to be zero, I obtained the equation , which in fact gives us three two-dimensional subspaces and cone-shapes in . This does not seem to correspond to points in . What am I misunderstanding here? This was a ""simple"" question in a qualifying topology/geometry exam, so I do not believe the solution is too involved.","\phi:\mathbb{RP}^2\rightarrow \mathbb{R}^3 \phi([x,y,z])=\frac{(yz,xz,xy)}{x^2+y^2+z^2} f x Df|_x \mathbb{RP}^2 q:\mathbb{R}^3-\{0\}\rightarrow\mathbb{RP}^2 \mathbb{R}^3 (\phi\circ q)(x,y,z)=\frac{(yz,xz,xy)}{x^2+y^2+z^2} \phi\circ q \phi D(\phi\circ q)|_{(x,y,z)} 6 xyz(-x^2+y^2+z^2)(x^2-y^2+z^2)(x^2+y^2-z^2)=0 3 \mathbb{R}^3 6 \mathbb{RP}^2","['differential-geometry', 'differential-topology', 'quotient-spaces', 'jacobian']"
51,Reference request for 3-manifold,Reference request for 3-manifold,,"I am asking a soft question. I am planning to learn $3$ -manifold using the book ""Geometry and topology of three-manifolds"" by William Thurston. I want to know how much of Riemannian geometry, Algebraic topology, Smooth manifolds, Complex Geometry do I need to learn $3$ - manifold. Also, I am looking for references of $3$ -manifolds which contain exercises as I noticed that  William Thurston's contain does not contain exercises. Also, it will be very much appreciatable if you also advise on book recommendations of $3$ -manifolds. Please advise me. Thanking in advance.","I am asking a soft question. I am planning to learn -manifold using the book ""Geometry and topology of three-manifolds"" by William Thurston. I want to know how much of Riemannian geometry, Algebraic topology, Smooth manifolds, Complex Geometry do I need to learn - manifold. Also, I am looking for references of -manifolds which contain exercises as I noticed that  William Thurston's contain does not contain exercises. Also, it will be very much appreciatable if you also advise on book recommendations of -manifolds. Please advise me. Thanking in advance.",3 3 3 3,"['differential-geometry', 'reference-request']"
52,Section 4.3 Page 26 in Loring Tu's Differential Geometry,Section 4.3 Page 26 in Loring Tu's Differential Geometry,,"On Section 4.3, Page 26 in Loring Tu's Differential Geometry : The underlined part is what I cannot understand. Why is $\dfrac{dV}{dt}$ in general not defined? What does ""a canonical frame of vector fields"" exactly mean? I got confused at this point, and I hope someone could explain it explicitly for me.","On Section 4.3, Page 26 in Loring Tu's Differential Geometry : The underlined part is what I cannot understand. Why is in general not defined? What does ""a canonical frame of vector fields"" exactly mean? I got confused at this point, and I hope someone could explain it explicitly for me.",\dfrac{dV}{dt},"['differential-geometry', 'smooth-manifolds']"
53,Ovaloid is orientable,Ovaloid is orientable,,"Given a compact, connected regular surface $S$ in Euclidean space which has everywhere positive gaussian curvature = an ovaloid. It is a theorem of Hadamard that ovaloids are diffeomorphic to the sphere (discussed in Klingenberg), but the proof of this follows the proof of their orientability = that there exists a continuous, unit normal field defined globally on $S$ . Unfortunately, there is no proof of this in doCarmo (as far as I can tell) and the proof in Klingenberg is said to be obvious, but the details are not explained. (He says the second order surface approximating $S$ near any point is an elliptic paraboloid, but it is not explained how to define the unit normal field globally) Does anyone know a full proof of this theorem? Ovaloids were extensively studied by Blaschke in his book (kreis und kugel), unfortunately I do not speak German. I would be extremely grateful for any references on ovaloids in English (but only classical differential geometry)","Given a compact, connected regular surface in Euclidean space which has everywhere positive gaussian curvature = an ovaloid. It is a theorem of Hadamard that ovaloids are diffeomorphic to the sphere (discussed in Klingenberg), but the proof of this follows the proof of their orientability = that there exists a continuous, unit normal field defined globally on . Unfortunately, there is no proof of this in doCarmo (as far as I can tell) and the proof in Klingenberg is said to be obvious, but the details are not explained. (He says the second order surface approximating near any point is an elliptic paraboloid, but it is not explained how to define the unit normal field globally) Does anyone know a full proof of this theorem? Ovaloids were extensively studied by Blaschke in his book (kreis und kugel), unfortunately I do not speak German. I would be extremely grateful for any references on ovaloids in English (but only classical differential geometry)",S S S,['differential-geometry']
54,Every embedding gives rise to an embedded submanifold?,Every embedding gives rise to an embedded submanifold?,,"I call regular (or embedded) submanifold of a manifold $M$ a subset $i:X \subset M$ endowed with a submanifold structure such that the inclusion map $i$ is an embedding. I call embedding an immersion that is also an homeomorphism onto its image. I call immersion a smooth map of constant rank equal to the dimension of its domain. It can be proven that a smooth constant rank map is injective only if its rank is equal to the dimension of its domain. Hence any smooth constant rank injective map must be an immmersion. An inclusion is homeomorphic onto its image iff on $X$ I have the subspace topology. Moreover, since the inclusion is injective, to prove it is an immersion it suffices to show that it is smooth and of constant rank. Hence, I can rephrase the definition of submanifold as: A submanifold $X \subset M$ is a subset of $M$ endowed with the subspace topology and with a manifold structure such that the inclusion $i:X \subset M$ is smooth and of constant rank. question 1 Is this rephrasing correct? question 2 If so, what is an example of an inclusion which is not smooth? What is an example of an inclusion which is not of constant rank? question 3 I read that for any embedding $f:N \to M,$ we have that $f(N)\subset M$ is a regular submanifold of $M.$ I understand that if we factorize $f$ as $$N\xrightarrow{\tilde{f}}f(N)\xrightarrow{i}M$$ I have that $f$ smooth of constant rank $\implies$ $\tilde{f}$ smooth of constant rank, because I am just changing the codomain. But how to show that this must imply $i$ smooth of constant rank too? I believe we should have a statement of the form $h \circ g$ smooth of constant rank and $g$ smooth of constant rank $\implies$ $h$ smooth of constant rank. Is this correct?","I call regular (or embedded) submanifold of a manifold a subset endowed with a submanifold structure such that the inclusion map is an embedding. I call embedding an immersion that is also an homeomorphism onto its image. I call immersion a smooth map of constant rank equal to the dimension of its domain. It can be proven that a smooth constant rank map is injective only if its rank is equal to the dimension of its domain. Hence any smooth constant rank injective map must be an immmersion. An inclusion is homeomorphic onto its image iff on I have the subspace topology. Moreover, since the inclusion is injective, to prove it is an immersion it suffices to show that it is smooth and of constant rank. Hence, I can rephrase the definition of submanifold as: A submanifold is a subset of endowed with the subspace topology and with a manifold structure such that the inclusion is smooth and of constant rank. question 1 Is this rephrasing correct? question 2 If so, what is an example of an inclusion which is not smooth? What is an example of an inclusion which is not of constant rank? question 3 I read that for any embedding we have that is a regular submanifold of I understand that if we factorize as I have that smooth of constant rank smooth of constant rank, because I am just changing the codomain. But how to show that this must imply smooth of constant rank too? I believe we should have a statement of the form smooth of constant rank and smooth of constant rank smooth of constant rank. Is this correct?","M i:X \subset M i X X \subset M M i:X \subset M f:N \to M, f(N)\subset M M. f N\xrightarrow{\tilde{f}}f(N)\xrightarrow{i}M f \implies \tilde{f} i h \circ g g \implies h","['differential-geometry', 'manifolds', 'differential-topology', 'submanifold']"
55,"If $p \in U\subseteq M$ is an open subset, then $C^\infty_p(U) = C^\infty_p(M)$.","If  is an open subset, then .",p \in U\subseteq M C^\infty_p(U) = C^\infty_p(M),"Let $M$ be a (smooth) manifold and $p \in M$ . We define $C^\infty_p(M)$ to be the set of equivalence classes of smooth functions $M \to \mathbb{R}$ that are identified when they agree on some  neighborhood of $p$ . In Tu's book ""Introduction to manifolds"", p87, I read that if $U$ is an open subset of $M$ containing $p$ , then $$C_p^\infty(M) = C_p^\infty(U)$$ Questions : Evidently, this is not a strict equality because on the right we have (classes of) functions $U \to \mathbb{R}$ and on the left we have functions $M \to \mathbb{R}$ . Hence, I guess that they mean that there is a canonical isomorphism (of $\mathbb{R}$ -algebras) $$C_p^\infty(M) \to C_p^\infty(U): f \mapsto f\vert_U$$ Clearly this is injective, because if $f$ and $g$ agree on $U$ , then they are in the same class so $f= g$ in $C_p^\infty(M)$ . Why is this mapping surjective? Don't we need that a smooth function $U \to \mathbb{R}$ can be smoothly extended to a smooth function $M \to \mathbb{R}$ for this?","Let be a (smooth) manifold and . We define to be the set of equivalence classes of smooth functions that are identified when they agree on some  neighborhood of . In Tu's book ""Introduction to manifolds"", p87, I read that if is an open subset of containing , then Questions : Evidently, this is not a strict equality because on the right we have (classes of) functions and on the left we have functions . Hence, I guess that they mean that there is a canonical isomorphism (of -algebras) Clearly this is injective, because if and agree on , then they are in the same class so in . Why is this mapping surjective? Don't we need that a smooth function can be smoothly extended to a smooth function for this?",M p \in M C^\infty_p(M) M \to \mathbb{R} p U M p C_p^\infty(M) = C_p^\infty(U) U \to \mathbb{R} M \to \mathbb{R} \mathbb{R} C_p^\infty(M) \to C_p^\infty(U): f \mapsto f\vert_U f g U f= g C_p^\infty(M) U \to \mathbb{R} M \to \mathbb{R},"['differential-geometry', 'smooth-manifolds']"
56,The curvature of a tangent to a curve considered as a curve in its own right,The curvature of a tangent to a curve considered as a curve in its own right,,"Suppose we have a curve $c:I \rightarrow \mathbb{R^3}$ that is parametrised with respect to arc length. We then consider $T,B,N$ (tangent, binormal and normal) as curve in there own right each defined at a time $t$ . The task is to express the curvature of the curve $T$ in terms of the curvature and torsion of the orginal curve $c$ . I am struggling to do this. So far I have: $$ \begin{align*} \kappa_T &= \frac{\|T' \times T''\|}{\|T'\|^3} \\ &=\frac{\|T' \times T''\|}{\kappa^3}\\ &=\frac{\|c'' \times c'''\|}{\kappa^3}. \end{align*} $$ I need a expression for that top product, I am trying to link it to the alternative formula for torsion given by: $$ \tau = \frac{\det(c'(t),c''(t),c'''(t)}{\|c' \times c''\|^2}. $$ Any help welcome :)","Suppose we have a curve that is parametrised with respect to arc length. We then consider (tangent, binormal and normal) as curve in there own right each defined at a time . The task is to express the curvature of the curve in terms of the curvature and torsion of the orginal curve . I am struggling to do this. So far I have: I need a expression for that top product, I am trying to link it to the alternative formula for torsion given by: Any help welcome :)","c:I \rightarrow \mathbb{R^3} T,B,N t T c 
\begin{align*}
\kappa_T &= \frac{\|T' \times T''\|}{\|T'\|^3} \\
&=\frac{\|T' \times T''\|}{\kappa^3}\\
&=\frac{\|c'' \times c'''\|}{\kappa^3}.
\end{align*}
 
\tau = \frac{\det(c'(t),c''(t),c'''(t)}{\|c' \times c''\|^2}.
","['differential-geometry', 'curves', 'curvature']"
57,"Given first fundamental form, provide an example of its surface","Given first fundamental form, provide an example of its surface",,"How to find surface of this first fundamental form (not a plane)? I know it may sound stupid, but my few attempts got me $(u,v,0)$ , but it is plane. Is there any algorithm, I could not find any.","How to find surface of this first fundamental form (not a plane)? I know it may sound stupid, but my few attempts got me , but it is plane. Is there any algorithm, I could not find any.","(u,v,0)","['differential-geometry', 'surfaces']"
58,Proof that $S^1$ is a manifold using projections,Proof that  is a manifold using projections,S^1,"I'm trying to understand what seems like it should be a simple proof in Spivak's text on differential geometry. In order to show that the circle, $S^1$ , is indeed a manifold, he projects $S^1 \setminus \{(0,1)\}$ onto $\Bbb{R} \times \{-1\}$ , as described in this image: I can intuitively see how this gives a homeomorphism between $S^1 \setminus \{(0,1)\}$ and $\Bbb{R} \times \{-1\}$ . Next, he says that the point $(0,1)$ can be handled similarly by projecting it on $\Bbb{R} \times \{1\}$ . How does this projection work? Is the point $(0,1)$ just sent to itself? My bigger question is, how are these two arguments combined to show that $S^1$ is indeed a 1-manifold? The first part shows ""most"" of $S^1$ being homeomorphic to $\Bbb{R}^1,$ and the second part shows the ""rest"" of $S^1$ being homeomorphic to... something? Then what? For reference, here's the definition of manifold in the text: A manifold is a metric space $M$ with the following property: If $x \in M,$ then there is some neighborhood $U$ of $x$ and some integer $n \ge 0$ such that $U$ is homeomorphic to $\mathbb{R}^n.$","I'm trying to understand what seems like it should be a simple proof in Spivak's text on differential geometry. In order to show that the circle, , is indeed a manifold, he projects onto , as described in this image: I can intuitively see how this gives a homeomorphism between and . Next, he says that the point can be handled similarly by projecting it on . How does this projection work? Is the point just sent to itself? My bigger question is, how are these two arguments combined to show that is indeed a 1-manifold? The first part shows ""most"" of being homeomorphic to and the second part shows the ""rest"" of being homeomorphic to... something? Then what? For reference, here's the definition of manifold in the text: A manifold is a metric space with the following property: If then there is some neighborhood of and some integer such that is homeomorphic to","S^1 S^1 \setminus \{(0,1)\} \Bbb{R} \times \{-1\} S^1 \setminus \{(0,1)\} \Bbb{R} \times \{-1\} (0,1) \Bbb{R} \times \{1\} (0,1) S^1 S^1 \Bbb{R}^1, S^1 M x \in M, U x n \ge 0 U \mathbb{R}^n.","['differential-geometry', 'manifolds']"
59,Differential geometry in graph theory,Differential geometry in graph theory,,"is there a free book or publication with some applications of differential geometry (especially 2-manifolds) in graph theory. At that moment I know that graph which are not planar on plane, can be planar on manifolds. But that does not use differential geometry, only treats manifolds as subsets of R^3. I know that every class of graphs which is closed under taking minors, is defined by finite subset of ""forbidden"" minors (it is powerful Robertson-Seymour theorem). I need to write an essay for difgeo course and I thought about something like that, but I can't see anything in my range. I mean something that uses curves, 2-manifolds, easy tensors (in particular metrics). E. g. where I can find a proof that every graph Kn is planar on manifold being sphere with big enough number of ears (torus is sphere with 1 ear) - maybe it would be cool part.","is there a free book or publication with some applications of differential geometry (especially 2-manifolds) in graph theory. At that moment I know that graph which are not planar on plane, can be planar on manifolds. But that does not use differential geometry, only treats manifolds as subsets of R^3. I know that every class of graphs which is closed under taking minors, is defined by finite subset of ""forbidden"" minors (it is powerful Robertson-Seymour theorem). I need to write an essay for difgeo course and I thought about something like that, but I can't see anything in my range. I mean something that uses curves, 2-manifolds, easy tensors (in particular metrics). E. g. where I can find a proof that every graph Kn is planar on manifold being sphere with big enough number of ears (torus is sphere with 1 ear) - maybe it would be cool part.",,"['differential-geometry', 'graph-theory', 'planar-graphs']"
60,curve with constant curvature,curve with constant curvature,,"Let $\gamma$ : $I\twoheadrightarrow C\subset \mathbb{R}^2$ be a plane curve with constant curvature $\kappa>0$ . Show that $C$ is part of a circle with radius $\kappa^{-1}$ . How to start this question, I don't have any clue.","Let : be a plane curve with constant curvature . Show that is part of a circle with radius . How to start this question, I don't have any clue.",\gamma I\twoheadrightarrow C\subset \mathbb{R}^2 \kappa>0 C \kappa^{-1},['calculus']
61,Serge Lang's projection,Serge Lang's projection,,"This question is a follow-up to Identity up to isomorphism treated as identity in proof . I thought that with all the kind help given there, now I would be able to work out the sketch of a proof given by Lang for the corollary dual to the one in the above thread, and to eliminate his assumptions of identity based on an identity up to isomorphism there, too. But I can't. Here is the problem: In ""Fundamentals of Differential Geometry"", 1999, pp.18-19, Serge Lang gives the following definition: And then this corollary to the inverse mapping theorem: First of all, some clarifications: Morphism means $ C^p$ map, local isomorphism means local $ C^p$ diffeomorphism, toplinear isomorphism can be considered to be a linear isomorphism here. Furthermore, I understand to be $ V_1 \subseteq E_1 $ and $ V_2 \subseteq E_2 $ , and the local inverse h, which Lang refers to, to be $ \varphi^{-1} $ , and not the inverse of the derivative, as Lang's wording implies. Again, what I don't see is how $ \varphi^{-1} $ satisfies the requirement of the corollary. In order to eliminate the identification $ E_2=F $ in the proof, let instead be $ \varphi: E_1 \times E_2 \rightarrow E_1 \times F $ . Then introduce the $ C^p $ diffeomorphism $ g: E_1 \times E_2 \rightarrow E_1 \times F: \quad (x_1,x_2) \mapsto (id_1, D_2f(a_1,a_2))[x_1,x_2] $ and replace $ h:=\varphi^{-1} $ by the $ C^p $ diffeomorphism $ h \circ g: E_1 \times E_2 \rightarrow E_1 \times E_2 $ . But with this, how does the resulting map $ f \circ h \circ g: E_1 \times E_2 \rightarrow F $ factor into an ordinary projection $ V_1 \times V_2 \rightarrow V_2 $ and a linear isomorphism $ V_2 \rightarrow W(0) \subseteq F $ with an open neighborhood W? Can we state the local map $ \varphi^{-1} $ explicitly? Is it $ \varphi^{-1}(x_1,y) = (x_1, pr_2 \circ f^{-1}(y)) $ for $ y \in F $ ? Clearly $ \varphi^{-1}(\varphi(x_1,x_2))= \varphi^{-1}(x_1,f(x_1,x_2)) = (x_1,x_2) $ . But the other way around does not resolve properly: $ \varphi(\varphi^{-1}(x_1,y))= \varphi(x_1, pr_2 \circ f^{-1}(y)) =(x_1,f(x_1,pr_2 \circ f^{-1}(y)) $ . And by the way, can we take f to be locally invertible, too? Evaluating the composition $ f \circ h \circ g $ seems to lead nowhere $ f(h(g(x_1,x_2))) = f(h(x_1,D_2f(a_1,a_2)[x_2])) = f(x_1,pr_2 \circ f^{-1}(D_2f(a_1,a_2)[x_2])) $ . So, how to proceed? Where is the error, or what is the necessary idea? I thought about explicitly introducing the projection $ pr_2: E_1 \times E_2 \rightarrow E_2 \equiv (\{0\} \times E_2) \subseteq (E_1 \times E_2) $ at the beginning of the composition: $ f \circ h \circ g \circ pr_2 $ , but unfortunately the projection is no $ C^p $ -diffeomorphism.","This question is a follow-up to Identity up to isomorphism treated as identity in proof . I thought that with all the kind help given there, now I would be able to work out the sketch of a proof given by Lang for the corollary dual to the one in the above thread, and to eliminate his assumptions of identity based on an identity up to isomorphism there, too. But I can't. Here is the problem: In ""Fundamentals of Differential Geometry"", 1999, pp.18-19, Serge Lang gives the following definition: And then this corollary to the inverse mapping theorem: First of all, some clarifications: Morphism means map, local isomorphism means local diffeomorphism, toplinear isomorphism can be considered to be a linear isomorphism here. Furthermore, I understand to be and , and the local inverse h, which Lang refers to, to be , and not the inverse of the derivative, as Lang's wording implies. Again, what I don't see is how satisfies the requirement of the corollary. In order to eliminate the identification in the proof, let instead be . Then introduce the diffeomorphism and replace by the diffeomorphism . But with this, how does the resulting map factor into an ordinary projection and a linear isomorphism with an open neighborhood W? Can we state the local map explicitly? Is it for ? Clearly . But the other way around does not resolve properly: . And by the way, can we take f to be locally invertible, too? Evaluating the composition seems to lead nowhere . So, how to proceed? Where is the error, or what is the necessary idea? I thought about explicitly introducing the projection at the beginning of the composition: , but unfortunately the projection is no -diffeomorphism."," C^p  C^p  V_1 \subseteq E_1   V_2 \subseteq E_2   \varphi^{-1}   \varphi^{-1}   E_2=F   \varphi: E_1 \times E_2 \rightarrow E_1 \times F   C^p   g: E_1 \times E_2 \rightarrow E_1 \times F: \quad (x_1,x_2) \mapsto (id_1, D_2f(a_1,a_2))[x_1,x_2]   h:=\varphi^{-1}   C^p   h \circ g: E_1 \times E_2 \rightarrow E_1 \times E_2   f \circ h \circ g: E_1 \times E_2 \rightarrow F   V_1 \times V_2 \rightarrow V_2   V_2 \rightarrow W(0) \subseteq F   \varphi^{-1}   \varphi^{-1}(x_1,y) = (x_1, pr_2 \circ f^{-1}(y))   y \in F   \varphi^{-1}(\varphi(x_1,x_2))= \varphi^{-1}(x_1,f(x_1,x_2)) = (x_1,x_2)   \varphi(\varphi^{-1}(x_1,y))= \varphi(x_1, pr_2 \circ f^{-1}(y)) =(x_1,f(x_1,pr_2 \circ f^{-1}(y))   f \circ h \circ g   f(h(g(x_1,x_2))) = f(h(x_1,D_2f(a_1,a_2)[x_2])) = f(x_1,pr_2 \circ f^{-1}(D_2f(a_1,a_2)[x_2]))   pr_2: E_1 \times E_2 \rightarrow E_2 \equiv (\{0\} \times E_2) \subseteq (E_1 \times E_2)   f \circ h \circ g \circ pr_2   C^p ","['differential-geometry', 'banach-spaces', 'inverse-function-theorem']"
62,Plane of symmetry and geodesics in surfaces,Plane of symmetry and geodesics in surfaces,,"Let $(M,n)$ be an oriented regular surface of $\mathbb{R}^{3}$ such that the intersection of $M$ with the plane $\Pi:=\{(x,y,z) \in \mathbb{R}^{3}:z=0\}$ is the image of a curve parametrized by arc length $\alpha$ . I am trying to prove that if $\varphi:M \rightarrow M$ defined by $\varphi (x,y,z)=(x,y,−z)$ is an isometry of M then the curve $\alpha$ must be a geodesic of M. I would like to prove that the normal vector $n \circ \alpha(t)$ is orthogonal to the vector $e_3 = (0,0,1)$ (for any $t \in \operatorname{dom}(\alpha)$ ). I know that the vector $n \circ \alpha(t)$ is an eigenvector of the linear transformation $R: \mathbb{R}^{3} \rightarrow \mathbb{R}^{3}$ given by $R(x,y,z)=(x,y,−z)$ , but I don't know how to prove that the tangent space $T_{\alpha(t)}M$ can't be the vector space $\operatorname{span}\{e_1,e_2\}$ . I also know that the hypothesis $M \cap \Pi$ equal to the image of a curve is important and necessary. I have tried many things but I'm not making any progress. So I would really appreciate any help.","Let be an oriented regular surface of such that the intersection of with the plane is the image of a curve parametrized by arc length . I am trying to prove that if defined by is an isometry of M then the curve must be a geodesic of M. I would like to prove that the normal vector is orthogonal to the vector (for any ). I know that the vector is an eigenvector of the linear transformation given by , but I don't know how to prove that the tangent space can't be the vector space . I also know that the hypothesis equal to the image of a curve is important and necessary. I have tried many things but I'm not making any progress. So I would really appreciate any help.","(M,n) \mathbb{R}^{3} M \Pi:=\{(x,y,z) \in \mathbb{R}^{3}:z=0\} \alpha \varphi:M \rightarrow M \varphi (x,y,z)=(x,y,−z) \alpha n \circ \alpha(t) e_3 = (0,0,1) t \in \operatorname{dom}(\alpha) n \circ \alpha(t) R: \mathbb{R}^{3} \rightarrow \mathbb{R}^{3} R(x,y,z)=(x,y,−z) T_{\alpha(t)}M \operatorname{span}\{e_1,e_2\} M \cap \Pi","['differential-geometry', 'surfaces', 'geodesic', 'orientation']"
63,Pair of orthogonal directions is a submanifold,Pair of orthogonal directions is a submanifold,,"I would like to ask something i don't understand. In my textbook of manifolds, it says that the subset $M$ of $\mathbb R P^{n} \times\mathbb R P^{n} $ , made from the pairs $(D,D')$ of the orthogonal directions of $\mathbb R^{n+1}-\{0\}$ , is a submanifold of the manifold $\mathbb R P^{n} \times\mathbb R P^{n} $ . So, I thought of something, based on what the inner product function that Nick wrote on his answer, but I'm not sure about it. (thinking of $\mathbb R P^{n} $ as $S^{n}$ by identifying the antipodal points). Let $g:\mathbb R P^{n}\times\mathbb R P^{n}\to\mathbb R$ , with $f=g\circ \pi$ , where $f:S^{n}\times S^{n}\to\mathbb R$ is the inner product function, and $\pi:S^{n}\times S^{n}\to\mathbb R P^{n} \times \mathbb R P^{n} $ is the projection map. Then, $M=g^{−1}(0)$ , and because $f$ is a submersion, so is $g$ . So $M$ will be a submanifold of $\mathbb R P^{n} \times\mathbb R P^{n} $ . What do you think about it?? Thank you in advance!","I would like to ask something i don't understand. In my textbook of manifolds, it says that the subset of , made from the pairs of the orthogonal directions of , is a submanifold of the manifold . So, I thought of something, based on what the inner product function that Nick wrote on his answer, but I'm not sure about it. (thinking of as by identifying the antipodal points). Let , with , where is the inner product function, and is the projection map. Then, , and because is a submersion, so is . So will be a submanifold of . What do you think about it?? Thank you in advance!","M \mathbb R P^{n} \times\mathbb R P^{n}  (D,D') \mathbb R^{n+1}-\{0\} \mathbb R P^{n} \times\mathbb R P^{n}  \mathbb R P^{n}  S^{n} g:\mathbb R P^{n}\times\mathbb R P^{n}\to\mathbb R f=g\circ \pi f:S^{n}\times S^{n}\to\mathbb R \pi:S^{n}\times S^{n}\to\mathbb R P^{n} \times \mathbb R P^{n}  M=g^{−1}(0) f g M \mathbb R P^{n} \times\mathbb R P^{n} ","['differential-geometry', 'manifolds', 'smooth-manifolds', 'projective-space', 'submanifold']"
64,"If $f:M\to \Bbb R$ is smooth and $f^{-1}(0)$ is a compact regular level set, then each $t\in (-\epsilon,\epsilon)$ is a regular value of $f$","If  is smooth and  is a compact regular level set, then each  is a regular value of","f:M\to \Bbb R f^{-1}(0) t\in (-\epsilon,\epsilon) f","Let $M$ be a smooth manifold and $f:M\to \Bbb R$ a smooth function. Suppose $0\in \Bbb R$ is a regular value of $f$ , so that $f^{-1}(0)$ is an embedded submanifold of $M$ . Also suppose that $f^{-1}(0)$ is compact. My goal is to show that $t$ is a regular value of $f$ for sufficiently small $|t|$ . My attempt: For each point $p\in f^{-1}(0)$ , $f$ is a submersion at $p$ , so $f$ is a submersion in a neighborhood $U_p\subset M$ of $p$ . Now $\{U_p\}_{p\in f^{-1}(0)}$ is an open cover of the compact set $f^{-1}(0)$ , so there must exist finitely many points $p_1,\dots,p_n\in f^{-1}(0)$ so that $f^{-1}(0)\subset U_{p_1}\cup \cdots \cup U_{p_n}=:U$ . Also $f$ is a submersion in $U$ . I would be done if I can show that $U$ contains $f^{-1}(-\epsilon,\epsilon)$ for some $\epsilon>0$ , but I can't show this. Should I need a different approach? Thanks in advance.","Let be a smooth manifold and a smooth function. Suppose is a regular value of , so that is an embedded submanifold of . Also suppose that is compact. My goal is to show that is a regular value of for sufficiently small . My attempt: For each point , is a submersion at , so is a submersion in a neighborhood of . Now is an open cover of the compact set , so there must exist finitely many points so that . Also is a submersion in . I would be done if I can show that contains for some , but I can't show this. Should I need a different approach? Thanks in advance.","M f:M\to \Bbb R 0\in \Bbb R f f^{-1}(0) M f^{-1}(0) t f |t| p\in f^{-1}(0) f p f U_p\subset M p \{U_p\}_{p\in f^{-1}(0)} f^{-1}(0) p_1,\dots,p_n\in f^{-1}(0) f^{-1}(0)\subset U_{p_1}\cup \cdots \cup U_{p_n}=:U f U U f^{-1}(-\epsilon,\epsilon) \epsilon>0","['differential-geometry', 'smooth-manifolds', 'smooth-functions']"
65,Defining Lie bracket intuitively looking at commuting flows,Defining Lie bracket intuitively looking at commuting flows,,"I'm reading ""Control Theory from the Geometric Viewpoint"" of Agrachev. He comments: ""It is natural to suggest that a lower-order term in the Taylor expansion of $(1.12)$ at $t = s = 0$ is responsible for commuting properties of flows of the vector fields VI, V2 at the point q."" Why is this natural? And why is it clear that non-mixed first and second order derivatives are useless? I wrote taylor's expansion and it wasn't clear to me: $$\gamma(t,s)= \gamma(0,0)+V_2(q)s+\frac{\partial^2 \gamma }{\partial s \partial t}(0,0)ts+ V_2(P_2(q))s$$","I'm reading ""Control Theory from the Geometric Viewpoint"" of Agrachev. He comments: ""It is natural to suggest that a lower-order term in the Taylor expansion of at is responsible for commuting properties of flows of the vector fields VI, V2 at the point q."" Why is this natural? And why is it clear that non-mixed first and second order derivatives are useless? I wrote taylor's expansion and it wasn't clear to me:","(1.12) t = s = 0 \gamma(t,s)= \gamma(0,0)+V_2(q)s+\frac{\partial^2 \gamma }{\partial s \partial t}(0,0)ts+ V_2(P_2(q))s","['differential-geometry', 'lie-groups', 'control-theory', 'linear-control']"
66,Does a flat partial connection promote to a flat connection?,Does a flat partial connection promote to a flat connection?,,"Let $M$ be a contact manifold (with globally defined contact form, for simplicity) of dimension $2n+1 \ge 5$ . So $H$ is a rank $2n$ subbundle of $TM$ and $[H,H] = TM$ . A partial connection with respect to $H$ on a vector bundle $E$ is a map $\Gamma(E) \to \Gamma(H^* \otimes E)$ satisfying the Leibniz rule in the sense \begin{align} \nabla fs = df|_H \otimes s + f\nabla s. \end{align} Let $L \le T^*M$ be the annihilator of the contact distribution. Then there is a canonical injective vector bundle homomorphism (the Levi map) $L \hookrightarrow \Lambda^2T^*M$ given by $\alpha \mapsto d\alpha|_H$ and the image consists of non-degenerate skew-forms. In particular there is a rank 3 subbundle of $\Lambda^2H^*$ , call it $\Lambda^2_\perp H^*$ consisting of forms trace free with respect to the image of the Levi map. There is an equivalence class of full connections $[\tilde{\nabla}]$ on E which extend $\nabla$ . The (partial) curvature of a partial connection can be defined by choosing such a representative and projecting the curvature $\Lambda^2 \otimes \operatorname{End}(E) \to \Lambda^2_\perp H^* \otimes \operatorname{End}(E)$ . Furthermore in https://arxiv.org/abs/0910.5519 it is easily shown that there is a unique representative connection in $[\tilde{\nabla}]$ such that the projection $\Lambda^2 \otimes \operatorname{End}(E) \to L \otimes \operatorname{End}(E)$ vanishes. Accordingly a connection with vanishing partial curvature has a unique lift $\tilde{\nabla}$ such that \begin{align} \tilde{\nabla}_X\tilde{\nabla}_Ys - \tilde{\nabla}_Y\tilde{\nabla}_Xs - \tilde{\nabla}_{[X,Y]}s = 0 \ \ \ \forall X,Y \in H. \end{align} My instinct tells me the maximal non-integrability of H means that $\tilde{\nabla}$ must be flat, but I can't prove this for myself or find a source. It is definitely sometimes true. For example one can define the obvious flat partial connection with respect to a trivialisation $\{e_i\}$ of $E$ \begin{align} \nabla s = d s^{i}|_H \otimes e_i \end{align} and this has canonical representative \begin{align} \tilde{\nabla} s = d s^{i} \otimes e_i, \end{align} which is flat. So there is no general obstruction to this being true. So my question is:  Is it possible to show that $\tilde{\nabla}$ must be flat, and if not, are there conditions one can enforce on $\nabla$ for this to be true?","Let be a contact manifold (with globally defined contact form, for simplicity) of dimension . So is a rank subbundle of and . A partial connection with respect to on a vector bundle is a map satisfying the Leibniz rule in the sense Let be the annihilator of the contact distribution. Then there is a canonical injective vector bundle homomorphism (the Levi map) given by and the image consists of non-degenerate skew-forms. In particular there is a rank 3 subbundle of , call it consisting of forms trace free with respect to the image of the Levi map. There is an equivalence class of full connections on E which extend . The (partial) curvature of a partial connection can be defined by choosing such a representative and projecting the curvature . Furthermore in https://arxiv.org/abs/0910.5519 it is easily shown that there is a unique representative connection in such that the projection vanishes. Accordingly a connection with vanishing partial curvature has a unique lift such that My instinct tells me the maximal non-integrability of H means that must be flat, but I can't prove this for myself or find a source. It is definitely sometimes true. For example one can define the obvious flat partial connection with respect to a trivialisation of and this has canonical representative which is flat. So there is no general obstruction to this being true. So my question is:  Is it possible to show that must be flat, and if not, are there conditions one can enforce on for this to be true?","M 2n+1 \ge 5 H 2n TM [H,H] = TM H E \Gamma(E) \to \Gamma(H^* \otimes E) \begin{align}
\nabla fs = df|_H \otimes s + f\nabla s.
\end{align} L \le T^*M L \hookrightarrow \Lambda^2T^*M \alpha \mapsto d\alpha|_H \Lambda^2H^* \Lambda^2_\perp H^* [\tilde{\nabla}] \nabla \Lambda^2 \otimes \operatorname{End}(E) \to \Lambda^2_\perp H^* \otimes \operatorname{End}(E) [\tilde{\nabla}] \Lambda^2 \otimes \operatorname{End}(E) \to L \otimes \operatorname{End}(E) \tilde{\nabla} \begin{align}
\tilde{\nabla}_X\tilde{\nabla}_Ys - \tilde{\nabla}_Y\tilde{\nabla}_Xs - \tilde{\nabla}_{[X,Y]}s = 0 \ \ \ \forall X,Y \in H.
\end{align} \tilde{\nabla} \{e_i\} E \begin{align}
\nabla s = d s^{i}|_H \otimes e_i
\end{align} \begin{align}
\tilde{\nabla} s = d s^{i} \otimes e_i,
\end{align} \tilde{\nabla} \nabla","['differential-geometry', 'curvature', 'connections']"
67,prove that $S^1$ is smooth submanifold of $\mathbb{R}^2$ using the definition with diffeomorphism,prove that  is smooth submanifold of  using the definition with diffeomorphism,S^1 \mathbb{R}^2,"I'm tring to prove that the unit circle $$S^1=\{(x_1,x_2)\in\mathbb{R}^2\text{ such that }x_1^2+x_2^2=1\}$$ is an embedded submanifold of $\mathbb{R}^2$ using the following Characterization: A nonempty subset $M \subset\mathbb{R}^n$ is an m-manifold iff: For every $p\in M$ , there are two open sets $O,W\subset\mathbb{R}^n$ with $0_n\in O$ and $p ∈ M ∩ W$ , and a smooth diffeomorphism $ϕ: O → W$ , such that $ϕ(0_n) = p$ and $$ϕ(O ∩ (\mathbb{R}^m × {0_{n−m}})) = M ∩ W$$ . My attempt: lets fix $a\in S^1$ , there exists a unique $\theta_0\in[0,2\pi)$ such that $a=(cos(\theta_0),sin(\theta_0))$ and let $\phi$ be the diffeomorphism \begin{array}{cccc} \phi : & (0,\infty)\times(\theta_0-\pi,\theta_0+\pi) & \longrightarrow & \mathbb{R}^2\backslash D_{\theta_0+\pi}\\ ~~ & (r,\theta) & \mapsto &(rcos(\theta),rsin(\theta))   \end{array} where $D_{\theta_0+\pi}$ is the half line at the origin with polar angle $\theta_0$ From here i dont know how to proceed. Should i modify this map or use as it is? and who are the two open sets of the charactrization?","I'm tring to prove that the unit circle is an embedded submanifold of using the following Characterization: A nonempty subset is an m-manifold iff: For every , there are two open sets with and , and a smooth diffeomorphism , such that and . My attempt: lets fix , there exists a unique such that and let be the diffeomorphism where is the half line at the origin with polar angle From here i dont know how to proceed. Should i modify this map or use as it is? and who are the two open sets of the charactrization?","S^1=\{(x_1,x_2)\in\mathbb{R}^2\text{ such that }x_1^2+x_2^2=1\} \mathbb{R}^2 M \subset\mathbb{R}^n p\in M O,W\subset\mathbb{R}^n 0_n\in O p ∈ M ∩ W ϕ: O → W ϕ(0_n) = p ϕ(O ∩ (\mathbb{R}^m × {0_{n−m}})) = M ∩ W a\in S^1 \theta_0\in[0,2\pi) a=(cos(\theta_0),sin(\theta_0)) \phi \begin{array}{cccc}
\phi : & (0,\infty)\times(\theta_0-\pi,\theta_0+\pi) & \longrightarrow & \mathbb{R}^2\backslash D_{\theta_0+\pi}\\
~~ & (r,\theta) & \mapsto &(rcos(\theta),rsin(\theta))  
\end{array} D_{\theta_0+\pi} \theta_0","['differential-geometry', 'submanifold']"
68,Find the total Gaussian curvature of a surface in $\mathbb{R}^3$,Find the total Gaussian curvature of a surface in,\mathbb{R}^3,"The surface is defined by $$z^2=-(x^2+y^2-16)((x-2)^2+y^2-1)((x+2)^2+y^2-1).$$ How would I get the total Gaussian curvature? I'm aware of that if the surface is represented by $X=(x,y,z)$ , then the Gaussian curvature is $$k=\frac{LM-N^2}{EG-F^2}$$ where $E=X_x\cdot X_x,\, F=X_x\cdot X_y,\, G=X_y\cdot X_y$ and $L=X_{xx}\cdot n,\, M= X_{xy}\cdot n,\, N=X_{yy}\cdot n$ . Here $$n=\frac{X_x\times X_y}{|X_x\times X_y|},$$ the unit normal vector. But the calculation is extremely overwhelming, because of the square power of $z$ . Is there an other way other than just calculating everything? And my definition of the total curvature is the surface integral of Gaussian curvature $\int_S k\,dA$ , where $S$ is the surface defined above. Is my definition correct?","The surface is defined by How would I get the total Gaussian curvature? I'm aware of that if the surface is represented by , then the Gaussian curvature is where and . Here the unit normal vector. But the calculation is extremely overwhelming, because of the square power of . Is there an other way other than just calculating everything? And my definition of the total curvature is the surface integral of Gaussian curvature , where is the surface defined above. Is my definition correct?","z^2=-(x^2+y^2-16)((x-2)^2+y^2-1)((x+2)^2+y^2-1). X=(x,y,z) k=\frac{LM-N^2}{EG-F^2} E=X_x\cdot X_x,\, F=X_x\cdot X_y,\, G=X_y\cdot X_y L=X_{xx}\cdot n,\, M= X_{xy}\cdot n,\, N=X_{yy}\cdot n n=\frac{X_x\times X_y}{|X_x\times X_y|}, z \int_S k\,dA S","['differential-geometry', 'curvature']"
69,"Are we allowed to define a symmetric (1,1) tensor in the following way?","Are we allowed to define a symmetric (1,1) tensor in the following way?",,"I've recently stumbled accross the following task: ""is it possible to define a symmetric and antisymmetric (1,1) tensor?"". This is in context of relativity, so we have a metric $g$ at our disposal. Moreover, anything I say here should be applicable beyond the context of relativity, on any manifold equipped with a metric. And we recall how (anti)symmetricity of a (0,2) tensor $M$ is defined. Two vectors $V$ and $W$ are considered and the following is demanded $$ M (V, W) = \pm M (W, V) $$ (plus for symmetric and minus for antisymmetric) or, in indices (by plugging in $\partial_\mu$ and $\partial_\nu$ ) $$ M_{\mu\nu} = \pm M_{\nu\mu} $$ Or similarly for tensor (2,0) we'd get $M^{\mu\nu} = \pm M^{\nu\mu}$ (in that case we are plugging in two one-forms) Now I cannot do that with a tensor (1,1) because I cannot simply flip the arguments, but I can do the ""next best thing"" (hence, we start thinking about how we can define an analogous property for a mixed tensor). First, we take a covector $\tilde{A}$ and a vector $V$ and since we have a metric at our disposal, we can map the covector $\tilde{A}$ to a vector $A$ as $A = g^{-1} (\tilde{A}, \, \cdot \,)$ and map vector $V$ to covector as $\tilde{V} = g (V, \, \cdot \,)$ , or in components $$ \begin{aligned} \tilde{A} &= A_\mu \mathrm{d} x^\mu \\ V &= V^\mu \partial_\mu \end{aligned} \;\, \begin{aligned} &\to \\ &\to \end{aligned} \quad \begin{aligned} A &= A^\mu \partial_\mu \\ \tilde{V} &= V_\mu \mathrm{d} x^\mu \end{aligned} $$ Now we can do the ""next best thing"" for a (1,1) mixed tensor and demand, that an ""(anti)symmetric (1,1) tensor to satisfy"" $$ M (\tilde{A} ; V) = \pm M (\tilde{V} ; A) $$ (again, plus for symmetric, minus for antisymmetric) Which translates to $$ M^\mu_{\;\; \nu} = \pm g^{\mu \rho} g_{\nu \sigma} M^\sigma_{\;\; \rho} $$ and if we unwrap the $g$ 's, $$ M^\mu_{\;\; \nu} = \pm M_\nu^{\:\,\mu} $$ which would be in a complete agreement with how a (2, 0) tensor $M^{\mu \nu}$ was symmetric, because if we take a tensor satisfying $M^{\mu \nu} = M^{\nu \mu}$ and simply drop an index by using the metric $$ g_{\sigma \nu} M^{\mu \sigma} = g_{\sigma \nu} M^{\sigma \mu} $$ we get the same answer $$ M^\mu_{\;\; \nu} = M_\nu^{\:\,\mu} $$ You can of course verify certain properties and little identities, that are analogous to (2,0) tensors. For example, for a general (1,1) tensor, the (anti)symmetrization would correspond to $$ (M^{(S)})^\mu_{\;\; \nu} = \frac{1}{2} \left( M^\mu_{\;\; \nu} + M_\nu^{\:\,\mu} \right) \quad \quad (M^{(A)})^\mu_{\;\; \nu} = \frac{1}{2} \left( M^\mu_{\;\; \nu} - M_\nu^{\:\,\mu} \right) $$ Contracting a symmetric and antisymmetric tensor gives zero $$ S^\mu_{\;\; \nu} A^\nu_{\;\,\mu} = 0 $$ Contracting a general and (anti)symmetric tensor only ""reacts"" with the (anti)symmetric part of the first tensor $$ M^\mu_{\;\; \nu} S^\nu_{\;\; \mu} = (M^{(S)})^\mu_{\;\; \nu} S^\nu_{\;\; \mu} \quad \quad M^\mu_{\;\; \nu} A^\nu_{\;\; \mu} = (M^{(A)})^\mu_{\;\; \nu} A^\nu_{\;\; \mu} $$ The ""official"" answer (book, professor, grader, ...) is that this is not possible and when I present this line of thinking I get a vague ""you cannot do that"" or answers that stray from my definitions (like ""you cannot swap indices like that"", which I would understand if I did $M^\mu_{\;\;\nu} + M^\nu_{\;\; \mu}$ however that's not what I'm doing here), or even answers that indicate that the person might not understand differential geometry, like "" $M^\mu_{\;\; \nu}$ is identically equal to $M_\nu^{\;\mu}$ , so what you call antisymmetric part, is always zero"". Which part of my reasoning is icky? The professor pointed out to me that in $M (\tilde{A} ; V) = M (\tilde{V} ; A)$ the objects fed to the tensor on the left-hand side are different from the objects fed to the tensor on the right-hand side, but that's part of my definition (*) . Is there something logically wrong with this? I'd like someone versed in this topic to give me clear reasons why this is a no-no approach. (*) And if this is the only objection, I find it rather weak. If this was the way people are thinking in mathematics, they would never define more general concepts stemming from simpler concepts, because they would never get past this kind of sentiment. A negative number? Have you ever seen minus two cows? A root of two? I've never had a root of two goats, what kind of nonsense is that? A factorial of a complex number? Come on, you cannot have $\pi + 2i$ numbers of people to divide $3-i$ marbles between, what will you come up with next? A fractional derivative? That doesn't make any sense! How do I write it as a d $y$ /d $x$ ? I thought that in mathematics, we look for a useful way to generalize concepts that are already known to us, even if it means to go a bit beyond what seems ""common sense"" at the first sight. Edit: I have two more ways to think about this now that I recall more details from the course of differential geometry. First way, the metric provides a canonical isomorphism, so if we can define a concept of a symmetric (2,0) tensor, we can also define this concept on (1,1) tensors by mapping the corresponding (2,0) tensor to a (1,1) tensor by the musical isomorphism. Let $M$ be an (anti)symmetric tensor of rank (2,0), then (in indices), the corresponding (1,1) tensor is $$ M^\mu_{\;\;\nu} = g_{\nu \sigma} M^{\mu \sigma} $$ Second way, let $\left\langle \;, \; \right\rangle$ denote the inner product. Moreover, let's observe, that any tensor of the type (1,1) that has been fed a vector now provides a natural mapping from the cotangent space to $\mathbb{R}$ , $$ M : T^*M \otimes T M \to \mathbb{R} \quad \quad \implies M (\; ; V) : T^*M \to \mathbb{R} $$ therefore, such object is a vector. We can then combine this with the inner product and define (anti)symmetric tensor of the rank (1,1) as follows $$ \left\langle M ( \;\cdot\; ; V), W \right\rangle = \pm \left\langle V, M (\;\cdot\; ; W) \right\rangle $$ This way, the objects $V$ and $W$ enter the equation in a very symmetric way, so the complaint from before does not hold. This is, by the way, analogous to how we would conclude that a Laplacian is a ""symmetric (1,1) tensor""/operator. First, a Laplacian acts on a function and spits out another function, so if we somehow understand functions to be ""vectors"" of a certain space, then Laplacian maps every vector to another vector, therefore, is a (1,1) tensor. The inner product can be defined as an integral, i.e. $$ \left\langle \varphi, \psi \right\rangle = \int \mathrm{d}^3 x \, \varphi (x) \, \psi (x) $$ and under certain conditions (we consider certain class of functions), the following is true for any two ""vectors"" $\varphi$ , $\psi$ and the operator $\Delta$ $$ \left\langle \Delta \varphi, \psi \right\rangle = \left\langle \varphi, \Delta \psi \right\rangle $$","I've recently stumbled accross the following task: ""is it possible to define a symmetric and antisymmetric (1,1) tensor?"". This is in context of relativity, so we have a metric at our disposal. Moreover, anything I say here should be applicable beyond the context of relativity, on any manifold equipped with a metric. And we recall how (anti)symmetricity of a (0,2) tensor is defined. Two vectors and are considered and the following is demanded (plus for symmetric and minus for antisymmetric) or, in indices (by plugging in and ) Or similarly for tensor (2,0) we'd get (in that case we are plugging in two one-forms) Now I cannot do that with a tensor (1,1) because I cannot simply flip the arguments, but I can do the ""next best thing"" (hence, we start thinking about how we can define an analogous property for a mixed tensor). First, we take a covector and a vector and since we have a metric at our disposal, we can map the covector to a vector as and map vector to covector as , or in components Now we can do the ""next best thing"" for a (1,1) mixed tensor and demand, that an ""(anti)symmetric (1,1) tensor to satisfy"" (again, plus for symmetric, minus for antisymmetric) Which translates to and if we unwrap the 's, which would be in a complete agreement with how a (2, 0) tensor was symmetric, because if we take a tensor satisfying and simply drop an index by using the metric we get the same answer You can of course verify certain properties and little identities, that are analogous to (2,0) tensors. For example, for a general (1,1) tensor, the (anti)symmetrization would correspond to Contracting a symmetric and antisymmetric tensor gives zero Contracting a general and (anti)symmetric tensor only ""reacts"" with the (anti)symmetric part of the first tensor The ""official"" answer (book, professor, grader, ...) is that this is not possible and when I present this line of thinking I get a vague ""you cannot do that"" or answers that stray from my definitions (like ""you cannot swap indices like that"", which I would understand if I did however that's not what I'm doing here), or even answers that indicate that the person might not understand differential geometry, like "" is identically equal to , so what you call antisymmetric part, is always zero"". Which part of my reasoning is icky? The professor pointed out to me that in the objects fed to the tensor on the left-hand side are different from the objects fed to the tensor on the right-hand side, but that's part of my definition (*) . Is there something logically wrong with this? I'd like someone versed in this topic to give me clear reasons why this is a no-no approach. (*) And if this is the only objection, I find it rather weak. If this was the way people are thinking in mathematics, they would never define more general concepts stemming from simpler concepts, because they would never get past this kind of sentiment. A negative number? Have you ever seen minus two cows? A root of two? I've never had a root of two goats, what kind of nonsense is that? A factorial of a complex number? Come on, you cannot have numbers of people to divide marbles between, what will you come up with next? A fractional derivative? That doesn't make any sense! How do I write it as a d /d ? I thought that in mathematics, we look for a useful way to generalize concepts that are already known to us, even if it means to go a bit beyond what seems ""common sense"" at the first sight. Edit: I have two more ways to think about this now that I recall more details from the course of differential geometry. First way, the metric provides a canonical isomorphism, so if we can define a concept of a symmetric (2,0) tensor, we can also define this concept on (1,1) tensors by mapping the corresponding (2,0) tensor to a (1,1) tensor by the musical isomorphism. Let be an (anti)symmetric tensor of rank (2,0), then (in indices), the corresponding (1,1) tensor is Second way, let denote the inner product. Moreover, let's observe, that any tensor of the type (1,1) that has been fed a vector now provides a natural mapping from the cotangent space to , therefore, such object is a vector. We can then combine this with the inner product and define (anti)symmetric tensor of the rank (1,1) as follows This way, the objects and enter the equation in a very symmetric way, so the complaint from before does not hold. This is, by the way, analogous to how we would conclude that a Laplacian is a ""symmetric (1,1) tensor""/operator. First, a Laplacian acts on a function and spits out another function, so if we somehow understand functions to be ""vectors"" of a certain space, then Laplacian maps every vector to another vector, therefore, is a (1,1) tensor. The inner product can be defined as an integral, i.e. and under certain conditions (we consider certain class of functions), the following is true for any two ""vectors"" , and the operator","g M V W 
M (V, W) = \pm M (W, V)
 \partial_\mu \partial_\nu 
M_{\mu\nu} = \pm M_{\nu\mu}
 M^{\mu\nu} = \pm M^{\nu\mu} \tilde{A} V \tilde{A} A A = g^{-1} (\tilde{A}, \, \cdot \,) V \tilde{V} = g (V, \, \cdot \,) 
\begin{aligned}
\tilde{A} &= A_\mu \mathrm{d} x^\mu \\
V &= V^\mu \partial_\mu
\end{aligned}
\;\,
\begin{aligned}
&\to \\
&\to
\end{aligned}
\quad
\begin{aligned}
A &= A^\mu \partial_\mu \\
\tilde{V} &= V_\mu \mathrm{d} x^\mu
\end{aligned}
 
M (\tilde{A} ; V) = \pm M (\tilde{V} ; A)
 
M^\mu_{\;\; \nu} = \pm g^{\mu \rho} g_{\nu \sigma} M^\sigma_{\;\; \rho}
 g 
M^\mu_{\;\; \nu} = \pm M_\nu^{\:\,\mu}
 M^{\mu \nu} M^{\mu \nu} = M^{\nu \mu} 
g_{\sigma \nu} M^{\mu \sigma} = g_{\sigma \nu} M^{\sigma \mu}
 
M^\mu_{\;\; \nu} = M_\nu^{\:\,\mu}
 
(M^{(S)})^\mu_{\;\; \nu} = \frac{1}{2} \left( M^\mu_{\;\; \nu} + M_\nu^{\:\,\mu} \right) \quad \quad (M^{(A)})^\mu_{\;\; \nu} = \frac{1}{2} \left( M^\mu_{\;\; \nu} - M_\nu^{\:\,\mu} \right)
 
S^\mu_{\;\; \nu} A^\nu_{\;\,\mu} = 0
 
M^\mu_{\;\; \nu} S^\nu_{\;\; \mu} = (M^{(S)})^\mu_{\;\; \nu} S^\nu_{\;\; \mu} \quad \quad M^\mu_{\;\; \nu} A^\nu_{\;\; \mu} = (M^{(A)})^\mu_{\;\; \nu} A^\nu_{\;\; \mu}
 M^\mu_{\;\;\nu} + M^\nu_{\;\; \mu} M^\mu_{\;\; \nu} M_\nu^{\;\mu} M (\tilde{A} ; V) = M (\tilde{V} ; A) \pi + 2i 3-i y x M 
M^\mu_{\;\;\nu} = g_{\nu \sigma} M^{\mu \sigma}
 \left\langle \;, \; \right\rangle \mathbb{R} 
M : T^*M \otimes T M \to \mathbb{R} \quad \quad \implies M (\; ; V) : T^*M \to \mathbb{R}
 
\left\langle M ( \;\cdot\; ; V), W \right\rangle = \pm \left\langle V, M (\;\cdot\; ; W) \right\rangle
 V W 
\left\langle \varphi, \psi \right\rangle = \int \mathrm{d}^3 x \, \varphi (x) \, \psi (x)
 \varphi \psi \Delta 
\left\langle \Delta \varphi, \psi \right\rangle = \left\langle \varphi, \Delta \psi \right\rangle
","['differential-geometry', 'tensors']"
70,Lie groupoid associated to an incomplete vector field,Lie groupoid associated to an incomplete vector field,,"Let $M$ be a smooth manifold and $X \in \mathfrak{X}(M)$ be a vector field. If $X$ is complete, its flow defines a group action $\Bbb R \circlearrowright M$ via $t \cdot x \doteq \Phi_X(t,x)$ . This gives us an action groupoid $\mathcal{G} \rightrightarrows M$ , where $$\mathcal{G} = \{(t,x,y) \in \Bbb R \times M \times M \mid x = \Phi_X(t,y)\},$$ with ${\sf s}(t,x,y) = y$ , ${\sf t}(t,x,y) = x$ , $M \hookrightarrow \Bbb R \times M \times M$ via $x \mapsto (0,x,x)$ and the operation is $(t,x,y)\cdot (s,y,z) = (t+s,x,z)$ , everything standard here. In Exercise 1.9 of Eckhard Meinrenken's notes , he wants to consider the case where $X$ is not complete, and the flow domain is just an open set $U \subseteq \Bbb R \times M$ (containing $\{0\} \times M$ ). The exercise asks us to show that $U$ can be turned into a Lie groupoid $U\rightrightarrows \Bbb R$ instead, apparently unrelated to the action groupoid described above. It's completely unclear to me how to go about this. First because we're changing the manifold of units. Second because there doesn't seem to be a natural way to embed $\Bbb R \hookrightarrow U$ . Third because things will go wrong with the operation above, since for $x \in M$ with $(t,x),(s,x) \in U$ , one might not have $(t+s,x) \in U$ (duh). Naively writing $$U = \bigsqcup_{x \in M} (a_x,b_x)$$ and trying to define the source and target maps by relating $t$ in $(t,x)$ with $a_x$ and $b_x$ also seems bad, since we could have $a_x = -\infty$ and/or $b_x = +\infty$ even with $X$ incomplete. Can you give me some ideas? I don't care for a full solution, I'm doing this for fun. If you tell me how to embed $\Bbb R \hookrightarrow U$ I'd say I already have a decent chance of figuring out the rest on my own. I don't know.","Let be a smooth manifold and be a vector field. If is complete, its flow defines a group action via . This gives us an action groupoid , where with , , via and the operation is , everything standard here. In Exercise 1.9 of Eckhard Meinrenken's notes , he wants to consider the case where is not complete, and the flow domain is just an open set (containing ). The exercise asks us to show that can be turned into a Lie groupoid instead, apparently unrelated to the action groupoid described above. It's completely unclear to me how to go about this. First because we're changing the manifold of units. Second because there doesn't seem to be a natural way to embed . Third because things will go wrong with the operation above, since for with , one might not have (duh). Naively writing and trying to define the source and target maps by relating in with and also seems bad, since we could have and/or even with incomplete. Can you give me some ideas? I don't care for a full solution, I'm doing this for fun. If you tell me how to embed I'd say I already have a decent chance of figuring out the rest on my own. I don't know.","M X \in \mathfrak{X}(M) X \Bbb R \circlearrowright M t \cdot x \doteq \Phi_X(t,x) \mathcal{G} \rightrightarrows M \mathcal{G} = \{(t,x,y) \in \Bbb R \times M \times M \mid x = \Phi_X(t,y)\}, {\sf s}(t,x,y) = y {\sf t}(t,x,y) = x M \hookrightarrow \Bbb R \times M \times M x \mapsto (0,x,x) (t,x,y)\cdot (s,y,z) = (t+s,x,z) X U \subseteq \Bbb R \times M \{0\} \times M U U\rightrightarrows \Bbb R \Bbb R \hookrightarrow U x \in M (t,x),(s,x) \in U (t+s,x) \in U U = \bigsqcup_{x \in M} (a_x,b_x) t (t,x) a_x b_x a_x = -\infty b_x = +\infty X \Bbb R \hookrightarrow U","['differential-geometry', 'vector-fields', 'lie-groupoids']"
71,Does a geodesically convex surface lie on one side of its tangent space?,Does a geodesically convex surface lie on one side of its tangent space?,,"A subset $B$ of $\mathbb{R}^{3}$ is convex if, for every two points $p,q \in B$ , the straight-line segment connecting $p$ and $q$ is entirely contained in $B$ . A smooth surface $S$ in $\mathbb{R}^{3}$ is convex if it lies on the boundary of a convex set. It is well-known that a characteristic property of convex surfaces is the following: Property 1 : For each point $p \in S$ , the surface $S$ lies on one side of the tangent space $T_{p}S$ , i.e., $S$ is contained in one of the two half-spaces defined by $T_{p}S$ . The notion of convexity can be extended to the case where the ambient manifold is an arbitrary Riemannian $3$ -manifold $M$ as follows: A subset $B$ of $M$ is geodesically convex if, for every two points $p,q \in B$ , there is a unique minimizing  geodesic which connects $p$ and $q$ and is entirely contained in $B$ . A smooth surface $S$ in $M$ is convex if it lies on the boundary of a convex set. My question is: Does a geodesically convex surface in $M$ satisfy an analogue of Property 1? A meaningful analogue of Property 1 could be that $\exp(T_{p}S) \cap  S =\{p\}$ for all $p \in S$ .","A subset of is convex if, for every two points , the straight-line segment connecting and is entirely contained in . A smooth surface in is convex if it lies on the boundary of a convex set. It is well-known that a characteristic property of convex surfaces is the following: Property 1 : For each point , the surface lies on one side of the tangent space , i.e., is contained in one of the two half-spaces defined by . The notion of convexity can be extended to the case where the ambient manifold is an arbitrary Riemannian -manifold as follows: A subset of is geodesically convex if, for every two points , there is a unique minimizing  geodesic which connects and and is entirely contained in . A smooth surface in is convex if it lies on the boundary of a convex set. My question is: Does a geodesically convex surface in satisfy an analogue of Property 1? A meaningful analogue of Property 1 could be that for all .","B \mathbb{R}^{3} p,q \in B p q B S \mathbb{R}^{3} p \in S S T_{p}S S T_{p}S 3 M B M p,q \in B p q B S M M \exp(T_{p}S) \cap 
S =\{p\} p \in S","['differential-geometry', 'riemannian-geometry']"
72,Restriction of local diffeomorphism to a neighbourhood of a submanifold is injective,Restriction of local diffeomorphism to a neighbourhood of a submanifold is injective,,"Question. Let $\varphi : M \to N$ be a local diffeomorphism of smooth manifolds and $S \subset M$ a smooth submanifold such that $\varphi|_S: S \to N$ is an embedding. Is there a neighbourhood $U$ of $S$ in $M$ such that $\varphi|_U$ is injective? My guess is that we can achieve this by taking a neighbourhood $U$ which deformation retracts onto $S$ . This can be done, for example, by taking a tubular neighbourhood, i.e. a diffeomorphism from a neighbourhood of the zero section in the normal bundle of $S$ to a neighbourhood of $S$ in $M$ , and contracting by scalar multiplication. Then, there is perhaps an argument using path liftings, but I'm unsure how to do this. If $\varphi(p) = \varphi(q)$ , we could maybe argue that there is a path from $p$ to $q$ which maps to a contractible loop in $N$ and somehow use this to show that $p = q$ ? Since $\varphi$ is a priori not a covering map, I'm not sure if this is a good approach.","Question. Let be a local diffeomorphism of smooth manifolds and a smooth submanifold such that is an embedding. Is there a neighbourhood of in such that is injective? My guess is that we can achieve this by taking a neighbourhood which deformation retracts onto . This can be done, for example, by taking a tubular neighbourhood, i.e. a diffeomorphism from a neighbourhood of the zero section in the normal bundle of to a neighbourhood of in , and contracting by scalar multiplication. Then, there is perhaps an argument using path liftings, but I'm unsure how to do this. If , we could maybe argue that there is a path from to which maps to a contractible loop in and somehow use this to show that ? Since is a priori not a covering map, I'm not sure if this is a good approach.",\varphi : M \to N S \subset M \varphi|_S: S \to N U S M \varphi|_U U S S S M \varphi(p) = \varphi(q) p q N p = q \varphi,"['general-topology', 'differential-geometry', 'algebraic-topology', 'smooth-manifolds']"
73,A smooth function $h: M \to \mathbb{R}$ from Partitions of Unity with $| h (x) - g (x) | <\epsilon$ for all $ x \in M​$.,A smooth function  from Partitions of Unity with  for all .,h: M \to \mathbb{R} | h (x) - g (x) | <\epsilon  x \in M​,"Let $ M $ a smooth manifold, $g: M \to \mathbb {R}$ any continuous function and $\epsilon> 0$ . Prove there is a smooth function $h: M \to \mathbb{R}$ with $| h (x) - g (x) | <\epsilon$ for all $ x \in M​​$ . In general, the idea is consider a partition of unity subordinate to coverage $ \{U_x: x \ in M ​​\}$ with $U_x = \{y \in M: | g (x) -g (y) | <\epsilon \}$ , but how do i build the $h$ function? My proof stars considering $f_x: M \to \mathbb{R}$ with $f_x (g) = | g (x) -g (y) |$ , so if $g$ is contiuous then $f_x$ is continuous. Now take $U_x = f^{- 1}_x ((- \infty, \epsilon)) \subset M $ an open set. Then $ U = \{U_x: x \in M ​​\} $ is an open cover of M, and exists a partition of unity $ \{\phi_x: x \in M ​​\} $ subordinate to $ U $ , where $$ \phi_x: M \to \Bbb R $$ $$ 0 \le \phi_x \le 1 $$ $$ \text{supp} (\phi_x) \subset U_x $$ $$ \sum_ {x \in M} \phi_x = 1 $$ Let $ h = \displaystyle \sum_ {x \in M} g(x) \cdot \phi_x $ smooth, then as $ g(x) $ is constant, we have $ g(x) \cdot \phi_x: M \to \Bbb R $ is smooth. but I don't know how to prove that $ | h (y) - g (y) | <\epsilon$ for all $y\in M ​​$ .","Let a smooth manifold, any continuous function and . Prove there is a smooth function with for all . In general, the idea is consider a partition of unity subordinate to coverage with , but how do i build the function? My proof stars considering with , so if is contiuous then is continuous. Now take an open set. Then is an open cover of M, and exists a partition of unity subordinate to , where Let smooth, then as is constant, we have is smooth. but I don't know how to prove that for all ."," M  g: M \to \mathbb {R} \epsilon> 0 h: M \to \mathbb{R} | h (x) - g (x) | <\epsilon  x \in M​​  \{U_x: x \ in M ​​\} U_x = \{y \in M: | g (x) -g (y) | <\epsilon \} h f_x: M \to \mathbb{R} f_x (g) = | g (x) -g (y) | g f_x U_x = f^{- 1}_x ((- \infty, \epsilon)) \subset M   U = \{U_x: x \in M ​​\}   \{\phi_x: x \in M ​​\}   U   \phi_x: M \to \Bbb R   0 \le \phi_x \le 1   \text{supp} (\phi_x) \subset U_x   \sum_ {x \in M} \phi_x = 1   h = \displaystyle \sum_ {x \in M} g(x) \cdot \phi_x   g(x)   g(x) \cdot \phi_x: M \to \Bbb R   | h (y) - g (y) | <\epsilon y\in M ​​","['differential-geometry', 'manifolds', 'smooth-manifolds']"
74,Intuition behind Non-Trivial Tangent Bundle,Intuition behind Non-Trivial Tangent Bundle,,"I am fairly new to the notion of tangent bundle and vector bundles in general , and as a first glance intuitively I though that well for any manifold $M$ we would have that $TM\cong M\times \mathbb{R}^m$ . As I looked more into the matter I found cases were this is not true however I can't have a good intuition behind the fact as to why this is not true . I would appreciate if someone could enlighten me on what can fail so that we dot not have that diffeomorphism without using very heavy machinery . I am just trying to understand the idea behind why this cannot be true in general .I guess the problem is that we only know that locally the tangent space at a point is the same as $\mathbb{R}^m$ and the problem would to do this globally but I am having trouble seeing where it fails. Thanks in advance.","I am fairly new to the notion of tangent bundle and vector bundles in general , and as a first glance intuitively I though that well for any manifold we would have that . As I looked more into the matter I found cases were this is not true however I can't have a good intuition behind the fact as to why this is not true . I would appreciate if someone could enlighten me on what can fail so that we dot not have that diffeomorphism without using very heavy machinery . I am just trying to understand the idea behind why this cannot be true in general .I guess the problem is that we only know that locally the tangent space at a point is the same as and the problem would to do this globally but I am having trouble seeing where it fails. Thanks in advance.",M TM\cong M\times \mathbb{R}^m \mathbb{R}^m,"['differential-geometry', 'tangent-bundle']"
75,Integral Manifolds of the Symplectic Foliation,Integral Manifolds of the Symplectic Foliation,,"Let $(M,\pi)$ be a Poisson manifold. Denote by $\pi^*:T^*M \rightarrow TM$ , the induced bundle map. In the simple case, where the Poisson bivector is of constant rank, we obtain a smooth regular foliation of M, i.e. $Im\pi^*$ , whose leaves are actually symplectic submanifolds. In the case that $\pi$ is not of constant rank, we obtain a (singular) symplectic foliation of the underlying manifold. I am trying to figure out the details of this foliation. The construction of the leaves for the singular foliation is the following: First one observes that the distribution $Im(\pi^{*})$ has integral manifolds. Let $x\in M$ and $\big(U,(p_i,q^i,x^s)\big)$ be the Darboux-Weinstein coordinates centered at $x$ . Then, the submanifold $S=\{x^s=0\}$ is an integral submanifold containing x. The second step is to show that the integral manifolds of $Im(\pi^*)$ are actually weakly embedded submanifolds and that the connected components of the intersection of two integral manifolds are also integral manifolds. Lastly, for a point $x_0 \in M$ we take the union of all integral manifolds containing it, and use a gluing lemma for weakly embedded submanifolds to show that this union is the maximal integral manifold containing $x_0$ , i.e the symplectic leaf of the foliation that contains $x_0$ . In order to prove the second step, we use the following lemma: Lemma : Let N be an integral manifold, $x\in N$ and $\big(U,(p_i,q^i,x^s)\big)$ the Darboux-Weinstein coordinates at $x$ . Then the following hold: i)The connected components of $N \cap U$ are contained in the slices $\{x^s=constant\}$ . ii) If $N'$ is another integral manifolds containing $x$ then the connected component of $N\cap N'$ containg $x$ is an integral manifold. I am stack at the two arguments that prove the Lemma: For i) it is  claimed that it suffices to show that $N\cap \{x^s=constant\}$ is both open and closed in $N\cap U$ . I do not see why this is sufficient. Then, it is claimed that ii) follows from i) since the slices $\{x^s=const.\}$ and integral manifolds have the same dimension. My intuition on this tells me that we are fine, since the tangent spaces at the intersection overlap nicely but what is the smooth manifold structure on $N \cap N'$ ? Any help to clear things out is deeply appreciated!","Let be a Poisson manifold. Denote by , the induced bundle map. In the simple case, where the Poisson bivector is of constant rank, we obtain a smooth regular foliation of M, i.e. , whose leaves are actually symplectic submanifolds. In the case that is not of constant rank, we obtain a (singular) symplectic foliation of the underlying manifold. I am trying to figure out the details of this foliation. The construction of the leaves for the singular foliation is the following: First one observes that the distribution has integral manifolds. Let and be the Darboux-Weinstein coordinates centered at . Then, the submanifold is an integral submanifold containing x. The second step is to show that the integral manifolds of are actually weakly embedded submanifolds and that the connected components of the intersection of two integral manifolds are also integral manifolds. Lastly, for a point we take the union of all integral manifolds containing it, and use a gluing lemma for weakly embedded submanifolds to show that this union is the maximal integral manifold containing , i.e the symplectic leaf of the foliation that contains . In order to prove the second step, we use the following lemma: Lemma : Let N be an integral manifold, and the Darboux-Weinstein coordinates at . Then the following hold: i)The connected components of are contained in the slices . ii) If is another integral manifolds containing then the connected component of containg is an integral manifold. I am stack at the two arguments that prove the Lemma: For i) it is  claimed that it suffices to show that is both open and closed in . I do not see why this is sufficient. Then, it is claimed that ii) follows from i) since the slices and integral manifolds have the same dimension. My intuition on this tells me that we are fine, since the tangent spaces at the intersection overlap nicely but what is the smooth manifold structure on ? Any help to clear things out is deeply appreciated!","(M,\pi) \pi^*:T^*M \rightarrow TM Im\pi^* \pi Im(\pi^{*}) x\in M \big(U,(p_i,q^i,x^s)\big) x S=\{x^s=0\} Im(\pi^*) x_0 \in M x_0 x_0 x\in N \big(U,(p_i,q^i,x^s)\big) x N \cap U \{x^s=constant\} N' x N\cap N' x N\cap \{x^s=constant\} N\cap U \{x^s=const.\} N \cap N'","['differential-geometry', 'symplectic-geometry', 'poisson-geometry']"
76,Guillemin&Pollack - Showing that the normal bundle is a manifold,Guillemin&Pollack - Showing that the normal bundle is a manifold,,"This is a question about the proposition in p.71 of Guillemin&Pollack - Differential Topology. Proposition. If $Y\subset \Bbb R^M$ then $N(Y)$ is a manifold of dimension $M$ and the projection $\sigma:N(Y)\to Y$ is a submersion. Here $Y$ is an embedded submanifold in $\Bbb R^M$ and $N(Y)\subset Y\times \Bbb R^M$ is the total space of the normal bundle. Proof. (given in the book) Define $Y$ locally by equations: around any given point of $Y$ , find an open set $\tilde{U}$ of $\Bbb R^M$ and a submersion $\phi:\tilde{U}\to \Bbb R^k$ ( $k=\text{codim}Y$ ) such that $U=Y\cap \tilde{U}=\phi^{-1}(0)$ . The set $N(U)$ equals $N(Y)\cap (U\times \Bbb R^M)$ , thus is open in $N(Y)$ . For each $y\in U$ , $d\phi_y:\Bbb R^M\to \Bbb R^k$ is surjective and has kernel $T_yY$ . Therefore its transpose maps $\Bbb R^k$ isomorphically onto $N_yY$ . The map $\psi:U\times \Bbb R^k\to N(U)$ , defined by $\psi(y,v)=(y,(d\phi_y)^tv)$ , is thus bijective, and it is easy to check that it is an embedding of $U\times \Bbb R^k$ into $Y\times \Bbb R^m$ . ~~ How can we show that $\psi$ is an embedding? In this book an embedding means a map which is proper injective immersion. But it is quite clear that it suffices to show that the map $\psi$ is a diffeomorphism onto its image, which is a weaker condition than being an embedding. Also, it is clear from the text that $\psi$ is a smooth bijection (onto $N(U)$ ). However it doesn't seem easy to me to show that its inverse is also smooth. Thanks in advance.","This is a question about the proposition in p.71 of Guillemin&Pollack - Differential Topology. Proposition. If then is a manifold of dimension and the projection is a submersion. Here is an embedded submanifold in and is the total space of the normal bundle. Proof. (given in the book) Define locally by equations: around any given point of , find an open set of and a submersion ( ) such that . The set equals , thus is open in . For each , is surjective and has kernel . Therefore its transpose maps isomorphically onto . The map , defined by , is thus bijective, and it is easy to check that it is an embedding of into . ~~ How can we show that is an embedding? In this book an embedding means a map which is proper injective immersion. But it is quite clear that it suffices to show that the map is a diffeomorphism onto its image, which is a weaker condition than being an embedding. Also, it is clear from the text that is a smooth bijection (onto ). However it doesn't seem easy to me to show that its inverse is also smooth. Thanks in advance.","Y\subset \Bbb R^M N(Y) M \sigma:N(Y)\to Y Y \Bbb R^M N(Y)\subset Y\times \Bbb R^M Y Y \tilde{U} \Bbb R^M \phi:\tilde{U}\to \Bbb R^k k=\text{codim}Y U=Y\cap \tilde{U}=\phi^{-1}(0) N(U) N(Y)\cap (U\times \Bbb R^M) N(Y) y\in U d\phi_y:\Bbb R^M\to \Bbb R^k T_yY \Bbb R^k N_yY \psi:U\times \Bbb R^k\to N(U) \psi(y,v)=(y,(d\phi_y)^tv) U\times \Bbb R^k Y\times \Bbb R^m \psi \psi \psi N(U)","['differential-geometry', 'proof-explanation', 'differential-topology', 'smooth-manifolds', 'vector-bundles']"
77,Calculate the curvature of torus using the shape operator and check the Gauss-Bonnet theorem $\iint_{S} K(\vec{r}) d S=4 \pi(1-g)$,Calculate the curvature of torus using the shape operator and check the Gauss-Bonnet theorem,\iint_{S} K(\vec{r}) d S=4 \pi(1-g),"I am trying to check the Gauss-Bonnet theorem which says $$\iint_{S} K(\vec{r}) d S=4 \pi(1-g),$$ where $g$ is the genus. For a torus, $g=1$ . I am given a hint that I can get $K$ from the shape operator $$A(\vec{X})=-\left(X^{1} \hat{N}_{1}+X^{2} \hat{N}_{2}\right)$$ $$K\left(\vec{r}\left(u_{1}, u_{2}\right)\right)=\operatorname{det}\left([A]_{B}^{B}\right)$$ while $B$ is the basis for a tangent plane. I think my main problem is to derive the curvature for the torus.","I am trying to check the Gauss-Bonnet theorem which says where is the genus. For a torus, . I am given a hint that I can get from the shape operator while is the basis for a tangent plane. I think my main problem is to derive the curvature for the torus.","\iint_{S} K(\vec{r}) d S=4 \pi(1-g), g g=1 K A(\vec{X})=-\left(X^{1} \hat{N}_{1}+X^{2} \hat{N}_{2}\right) K\left(\vec{r}\left(u_{1}, u_{2}\right)\right)=\operatorname{det}\left([A]_{B}^{B}\right) B","['differential-geometry', 'curvature']"
78,Definition of the tangential gradient,Definition of the tangential gradient,,"Let $d\in\mathbb N$ and $M\subseteq\mathbb R^d$ be bounded and open such that $\partial M$ is of class $C^1$ (i.e. a $(d-1)$ -dimensional embedded $C^1$ -submanifold of $\mathbb R^d$ ). If $f:\partial M\to\mathbb R$ is $C^1$ -differentiable, we can find the following definition of the ""tangential gradient"" of $f$ in Shapes and Geometries: Metrics, Analysis, Differential Calculus, and Optimization, Second Edition (p. 492) $^1$ : Why is it important to consider a $C^1$ -extension $F$ of $f$ on a tubular neighborhood (or even on that specific one)? Why can't we take any $C^1$ -extension of $f$ , i.e. any $\tilde f\in C^1(O)$ , where $O$ is an $\mathbb R^d$ -open neighborhood of $\partial M$ , with $$f=\left.\tilde f\right|_{\partial M}?\tag1$$ Is it needed to show that $g(F)$ is well-defined, i.e. independent of the choice of $F$ ? In any case, how can we show that it actually is well-defined? EDIT : Meanwhile, I've found others references which consider arbitrary $C^1$ -extensions. But it's still not clear to me why the definition of the tangential gradient is independent of the choice of the extension. $^1$","Let and be bounded and open such that is of class (i.e. a -dimensional embedded -submanifold of ). If is -differentiable, we can find the following definition of the ""tangential gradient"" of in Shapes and Geometries: Metrics, Analysis, Differential Calculus, and Optimization, Second Edition (p. 492) : Why is it important to consider a -extension of on a tubular neighborhood (or even on that specific one)? Why can't we take any -extension of , i.e. any , where is an -open neighborhood of , with Is it needed to show that is well-defined, i.e. independent of the choice of ? In any case, how can we show that it actually is well-defined? EDIT : Meanwhile, I've found others references which consider arbitrary -extensions. But it's still not clear to me why the definition of the tangential gradient is independent of the choice of the extension.",d\in\mathbb N M\subseteq\mathbb R^d \partial M C^1 (d-1) C^1 \mathbb R^d f:\partial M\to\mathbb R C^1 f ^1 C^1 F f C^1 f \tilde f\in C^1(O) O \mathbb R^d \partial M f=\left.\tilde f\right|_{\partial M}?\tag1 g(F) F C^1 ^1,"['differential-geometry', 'differential-topology', 'vector-analysis', 'smooth-manifolds', 'tangent-spaces']"
79,If the boundary of a manifold is $C^2$ then the distance to it is also $C^2$ in a neighborhood of the boundary.,If the boundary of a manifold is  then the distance to it is also  in a neighborhood of the boundary.,C^2 C^2,"This question comes from the the local property of pseudoconvexity. Pseudoconvexity is is determined by the behaviour of the function of distance to the boundary. In fact it is determined by the differentially geometric property of the boundary in the view of Levi form . As in Demailly's note on complex analytic geometry , assume the boundary of an open set $\Omega \subset \mathbb{C}^n$ has $C^2$ boundary. In order to generate Levi form we should make sure $\delta(z) = \mathrm{d}(x, \mathsf{C}\Omega)$ is also $C^2$ . But how can I make sure this is actually $C^2$ . One of my thought is using tubular neighbourhood. Locally the map $(x , t) \mapsto x+vt$ where $v$ is the unit normal vector is a diffeomorphism satisfying the nearing point on the boundary to $x+vt$ is $x$ . But if the boundary is $C^2$ , this map seems to be $C^1$ and so is the inverse $\pi$ of the map. And $\delta(z) = |\pi(z) - z|$ is also $C^1$ .","This question comes from the the local property of pseudoconvexity. Pseudoconvexity is is determined by the behaviour of the function of distance to the boundary. In fact it is determined by the differentially geometric property of the boundary in the view of Levi form . As in Demailly's note on complex analytic geometry , assume the boundary of an open set has boundary. In order to generate Levi form we should make sure is also . But how can I make sure this is actually . One of my thought is using tubular neighbourhood. Locally the map where is the unit normal vector is a diffeomorphism satisfying the nearing point on the boundary to is . But if the boundary is , this map seems to be and so is the inverse of the map. And is also .","\Omega \subset \mathbb{C}^n C^2 \delta(z) = \mathrm{d}(x, \mathsf{C}\Omega) C^2 C^2 (x , t) \mapsto x+vt v x+vt x C^2 C^1 \pi \delta(z) = |\pi(z) - z| C^1","['differential-geometry', 'complex-geometry']"
80,The minimizers of energy and length of a curve,The minimizers of energy and length of a curve,,"Assume S is a regular surface with a Riemannian metric $g$ . The energy of a curve $c: [0,a] \to S$ is defined as : $$ E(c) = \frac{1}{2} \int_0^a g_{c(t)}(\dot c(t),\dot c(t))\mathsf{dt} $$ This is quite similar to the definition of the length in terms of the defining functions i.e.: $$L(c) = \int_0^a \sqrt{g_{c(t)} (\dot c(t), \dot c(t) )}\mathsf{dt}$$ The Lemma 2.3 in Chapter 9 of Riemannian Geometry by Do Carmo is: About the formula $$aE(\gamma)=(L(\gamma))^2\leq (L(c))^2\leq aE(c),$$ the author has proved the inequality: $$(L(c))^2\leq aE(c)$$ using the Schwarz inequality. The question is: why $aE(\gamma)=(L(\gamma))^2$ ?",Assume S is a regular surface with a Riemannian metric . The energy of a curve is defined as : This is quite similar to the definition of the length in terms of the defining functions i.e.: The Lemma 2.3 in Chapter 9 of Riemannian Geometry by Do Carmo is: About the formula the author has proved the inequality: using the Schwarz inequality. The question is: why ?,"g c: [0,a] \to S  E(c) = \frac{1}{2} \int_0^a g_{c(t)}(\dot c(t),\dot c(t))\mathsf{dt}  L(c) = \int_0^a \sqrt{g_{c(t)} (\dot c(t), \dot c(t) )}\mathsf{dt} aE(\gamma)=(L(\gamma))^2\leq (L(c))^2\leq aE(c), (L(c))^2\leq aE(c) aE(\gamma)=(L(\gamma))^2","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'geodesic']"
81,Standard and second forms of Euler equation giving different results,Standard and second forms of Euler equation giving different results,,"Consider the conical surface $z=h(1-\rho/a)$ , $\rho = \sqrt{x^2+y^2}$ generated by the revolution around the z axis of the straight line $ z = h(1-y/a)$ , $y\geq 0$ . We wish to find the geodesic curve  between the points $A$ and $B$ ( see figure below) a) Using cylindrical coordinates $(\rho,\varphi,z)$ with $\varphi = arctan (y/x)$ ,obtain the linear functionals $f(\varphi,\varphi';\rho)$ and $g(\rho,\rho';\varphi)$ that must be minimized to find the geodesic.It will be useful to define $\beta = \sqrt{1+(h/a)^2}$ . b) Using the standard form of the Euler equation for the most convenient functional ( $f$ or $g$ ), find the differential equation that relates $(\rho,\varphi)$ and its general solution. c) Verify that the equation of item b can also be obtained using the Second form of the Euler equation applied to $f$ or $g$ I found on item a, $f= \sqrt{\beta^2+\rho^2\varphi'^2}$ and on item b using the standard Euler equation: $\frac{d}{d\rho}(\frac{\partial f}{\partial \varphi'} )- \frac{\partial f}{\partial \varphi} = 0$ ,the differential equation: $\varphi' = \frac{c \beta}{\rho\sqrt{\rho^2 -c^2}}$ , where $c$ is a constant But when I try to use the second form of the Euler equation (item c): $\frac{\partial f}{\partial \varphi} - \frac{d}{d\varphi}(f - \varphi'\frac{\partial f }{\partial \varphi'}) = 0$ , which since $\frac{\partial f}{\partial \varphi}  = 0$ , is the same as $f- \varphi'\frac{\partial f }{\partial \varphi'}= c$ ,I get: $\varphi' = \frac{\beta\sqrt{\beta^2-c^2}}{c\rho}$ . What am I doing wrong ? Any hints or help will be appreciated.","Consider the conical surface , generated by the revolution around the z axis of the straight line , . We wish to find the geodesic curve  between the points and ( see figure below) a) Using cylindrical coordinates with ,obtain the linear functionals and that must be minimized to find the geodesic.It will be useful to define . b) Using the standard form of the Euler equation for the most convenient functional ( or ), find the differential equation that relates and its general solution. c) Verify that the equation of item b can also be obtained using the Second form of the Euler equation applied to or I found on item a, and on item b using the standard Euler equation: ,the differential equation: , where is a constant But when I try to use the second form of the Euler equation (item c): , which since , is the same as ,I get: . What am I doing wrong ? Any hints or help will be appreciated.","z=h(1-\rho/a) \rho = \sqrt{x^2+y^2}  z = h(1-y/a) y\geq 0 A B (\rho,\varphi,z) \varphi = arctan (y/x) f(\varphi,\varphi';\rho) g(\rho,\rho';\varphi) \beta = \sqrt{1+(h/a)^2} f g (\rho,\varphi) f g f= \sqrt{\beta^2+\rho^2\varphi'^2} \frac{d}{d\rho}(\frac{\partial f}{\partial \varphi'} )- \frac{\partial f}{\partial \varphi} = 0 \varphi' = \frac{c \beta}{\rho\sqrt{\rho^2 -c^2}} c \frac{\partial f}{\partial \varphi} - \frac{d}{d\varphi}(f - \varphi'\frac{\partial f }{\partial \varphi'}) = 0 \frac{\partial f}{\partial \varphi}  = 0 f- \varphi'\frac{\partial f }{\partial \varphi'}= c \varphi' = \frac{\beta\sqrt{\beta^2-c^2}}{c\rho}","['calculus', 'differential-geometry', 'physics', 'calculus-of-variations', 'euler-lagrange-equation']"
82,Lagrangian Torus of a symplectic manifold,Lagrangian Torus of a symplectic manifold,,"Suppose $(M,\omega)$ is a $2n$ -dimensional symplectic manifold. Consider the $n$ -torus $\mathbb{T}^n=\mathbb{R}^n/\mathbb{Z}^n.$ Then $\mathbb{T}^n$ is a Lagrangian submanifold of the symplectic $2n$ -torus $\mathbb{T}^{2n}$ , equipped with the unique symplectic form that pulls back to the canonical symplectic form on $\mathbb{R} ^{2n}$ . Now, how does it follow that there exists a Lagrangian submanifold of $M$ that is diffeomorphic to $\mathbb{T}^{n}$ ?","Suppose is a -dimensional symplectic manifold. Consider the -torus Then is a Lagrangian submanifold of the symplectic -torus , equipped with the unique symplectic form that pulls back to the canonical symplectic form on . Now, how does it follow that there exists a Lagrangian submanifold of that is diffeomorphic to ?","(M,\omega) 2n n \mathbb{T}^n=\mathbb{R}^n/\mathbb{Z}^n. \mathbb{T}^n 2n \mathbb{T}^{2n} \mathbb{R} ^{2n} M \mathbb{T}^{n}","['differential-geometry', 'symplectic-geometry', 'submanifold']"
83,Smooth Sylvester's law of inertia,Smooth Sylvester's law of inertia,,"Let $Q(x)$ be a smooth symetric matrix with constant signature $(p,q,k)$ where $x$ belong in $\mathbb{R}^n$ and $p+q+k=m$ . Question: Locally around $x_0$ , does an invertible matrix $P(x)$ of size $m$ exists such that, $$ P^T(x) Q(x) P(x) = \begin{pmatrix} Id_p &0&0\\0&-Id_q&0\\ 0&0&0_k\end{pmatrix} $$ /!\ I do not require that $P(x)$ is the jacobian of some diffeormorphism. Proposition of Proof: If $Q(x_0)$ is invertible and all its eignevalue are simple, then this property is locally preserved. Hence the basis of orthonormal vectors depend smoothly on the point. If $Q(x_0)$ has a multiple eigenvalue, then locally the eigen hypersurface can split into multiple eigen hypersurfacesof smaller dimension. However because the bilinear form asociated with $Q$ is symmetric the vectors spanning the multiple smaller hypersurfaces will converge to a basis of the eigenhypersurface. Hence the transformation is still smooth. If $det(Q(x_0))=0$ , then locally we have $\mathbb{R}^n=\ker Q \oplus^{\perp}rg(Q)$ . The kernel of $Q$ is determined by a set of equations, by the implicit functions theorem we can express the vector spanning this kernel by smooth functions. As the image of $Q$ is orthogonal to the kernel, then it is also spanned by smooth functions and we can express $Q$ in this subspace and repeat the previous argument.","Let be a smooth symetric matrix with constant signature where belong in and . Question: Locally around , does an invertible matrix of size exists such that, /!\ I do not require that is the jacobian of some diffeormorphism. Proposition of Proof: If is invertible and all its eignevalue are simple, then this property is locally preserved. Hence the basis of orthonormal vectors depend smoothly on the point. If has a multiple eigenvalue, then locally the eigen hypersurface can split into multiple eigen hypersurfacesof smaller dimension. However because the bilinear form asociated with is symmetric the vectors spanning the multiple smaller hypersurfaces will converge to a basis of the eigenhypersurface. Hence the transformation is still smooth. If , then locally we have . The kernel of is determined by a set of equations, by the implicit functions theorem we can express the vector spanning this kernel by smooth functions. As the image of is orthogonal to the kernel, then it is also spanned by smooth functions and we can express in this subspace and repeat the previous argument.","Q(x) (p,q,k) x \mathbb{R}^n p+q+k=m x_0 P(x) m 
P^T(x) Q(x) P(x) = \begin{pmatrix} Id_p &0&0\\0&-Id_q&0\\ 0&0&0_k\end{pmatrix}
 P(x) Q(x_0) Q(x_0) Q det(Q(x_0))=0 \mathbb{R}^n=\ker Q \oplus^{\perp}rg(Q) Q Q Q","['real-analysis', 'differential-geometry', 'matrix-calculus', 'bilinear-form', 'smooth-functions']"
84,Questions on a proof in do Carmo's Riemannian Geometry - Computations with Lie groups and Lie algebras,Questions on a proof in do Carmo's Riemannian Geometry - Computations with Lie groups and Lie algebras,,"I am a little confused with making computations with Lie groups and Lie algebras, and would appreciate very much any help with the following questions. In page 44 of my Brazilian edition of do Carmo's Riemannian Geometry, he states that if a Lie group $G$ has a bi-invariant metric, the inner product that the metric induces on the Lie algebra $\mathcal G$ satisfies $$ \langle [U, X], V \rangle = - \langle U, [V, X] \rangle. $$ He argues in the following way: For every $a \in G$ , the automorphism $R_{a^{-1}}L_a: G \longrightarrow G$ is a diffeomorphism that leaves $e$ fixed.  Therefore, the differential $d(R_{a^{-1}}L_a) = Ad(a): \mathcal G \longrightarrow \mathcal G$ is a linear map. First question: the differential above is at $e$ , right? He proceeds: Explicitly, $$ Ad(a)Y = dR_{a^{-1}} dL_a Y = dR_{a^{-1}}Y \quad \forall Y \in \mathcal G $$ Second question: Here, the differential $dR_{a^{-1}}$ is computed at $a$ , right? So it should be $$ d(R_{a^{-1}})_a (dL_a)_e Y(e) = d(R_{a^{-1}})_aY(a). $$ He now argues that if $x_t$ is the flow of $X \in \mathcal G$ then $$ [Y, X] = \lim_{t \to 0} \frac1t (dx_t(Y) - Y). $$ Third question: Shouldn't it be $$ [Y, X] = \lim_{t \to 0} \frac1t (dx_t(Y) - Y)x_t ? $$ Following, he claims that since $X$ is left-invariant, then $L_y \circ x_t = x_t \circ L_y$ Why does it hold? He then concludes the proof, but the remaining of it I think I can understand Thanks in advance and kind regards.","I am a little confused with making computations with Lie groups and Lie algebras, and would appreciate very much any help with the following questions. In page 44 of my Brazilian edition of do Carmo's Riemannian Geometry, he states that if a Lie group has a bi-invariant metric, the inner product that the metric induces on the Lie algebra satisfies He argues in the following way: For every , the automorphism is a diffeomorphism that leaves fixed.  Therefore, the differential is a linear map. First question: the differential above is at , right? He proceeds: Explicitly, Second question: Here, the differential is computed at , right? So it should be He now argues that if is the flow of then Third question: Shouldn't it be Following, he claims that since is left-invariant, then Why does it hold? He then concludes the proof, but the remaining of it I think I can understand Thanks in advance and kind regards.","G \mathcal G 
\langle [U, X], V \rangle = - \langle U, [V, X] \rangle.
 a \in G R_{a^{-1}}L_a: G \longrightarrow G e d(R_{a^{-1}}L_a) = Ad(a): \mathcal G \longrightarrow \mathcal G e 
Ad(a)Y = dR_{a^{-1}} dL_a Y = dR_{a^{-1}}Y \quad \forall Y \in \mathcal G
 dR_{a^{-1}} a 
d(R_{a^{-1}})_a (dL_a)_e Y(e) = d(R_{a^{-1}})_aY(a).
 x_t X \in \mathcal G 
[Y, X] = \lim_{t \to 0} \frac1t (dx_t(Y) - Y).
 
[Y, X] = \lim_{t \to 0} \frac1t (dx_t(Y) - Y)x_t ?
 X L_y \circ x_t = x_t \circ L_y","['differential-geometry', 'lie-groups', 'riemannian-geometry', 'lie-algebras']"
85,Canonical lifting of vector fields,Canonical lifting of vector fields,,"Consider a compact Kahler manifold $M$ of complex dimension $n$ and a holomorphic vector field $X$ defined on it. Let $L$ be the line bundle $\Lambda^nT^{1,0}M$ . Then is there a canonical way of lifting $X$ to another vector field $X^* $ on $L$ ? In general, is there such a procedure by which we can canonically lift vector fields on a manifold to other vector bundles defined on the same manifold?","Consider a compact Kahler manifold of complex dimension and a holomorphic vector field defined on it. Let be the line bundle . Then is there a canonical way of lifting to another vector field on ? In general, is there such a procedure by which we can canonically lift vector fields on a manifold to other vector bundles defined on the same manifold?","M n X L \Lambda^nT^{1,0}M X X^*  L","['differential-geometry', 'complex-geometry', 'vector-bundles', 'vector-fields', 'kahler-manifolds']"
86,"Regarding equivalent definitions of Euclidean Submanifolds in Gallot, Hulin and Lafontaine's book Riemannian Geometry","Regarding equivalent definitions of Euclidean Submanifolds in Gallot, Hulin and Lafontaine's book Riemannian Geometry",,"In the book Riemannian Geometry by Gallot, Hulin and Lafontaine, a proposition which characterises equivalent definitions of submanifolds is given as follows: 1.3 Proposition The following are equivalent: i) $M$ is a $C^p$ submanifold of dimension $n$ of $\mathbb{R}^{n+k}$ . ii) For any $x$ in $M$ , there exist open neighbourhoods $U$ and $V$ of $x$ and $0$ in $\mathbb{R}^{n+k}$ respectively, and a $C^p$ diffeomorphism $f : U\to V$ such that $f(U \cap M)=V \cap (R^n \times \{0\})$ . iii) For any $x$ in $M$ , there exist a neighbourhood $U$ of $x$ in $\mathbb{R}^{n+k}$ , a neighbourhood $\Omega$ of $0$ in $\mathbb{R}^n$ , and a $C^p$ map $g: \Omega \to \mathbb{R}^{n+k}$ such that $( \Omega, g)$ is a local parametrization of $M \cap U$ around $x$ (that is $g$ is an homeomorphism from $\Omega$ onto $M \cap U$ and $g'(0)$ is injective). I am trying to show that iii) implies ii) and I think that I am nearly there except I am having trouble with the following detail. I will first summarise my problem and then fill in the details. In brief, my main problem in going from iii) to ii) is that to make my proof work I seemed to also require that $g(0)=x$ . (Whereas in contrast the authors have just required that $g$ is an homeomorphism from $\Omega$ onto $M \cap U$ and $g'(0)$ is injective). The details of what I attempted are as follows: (Attempted) Proof that iii) $\implies$ ii). Fix $x \in M$ and let $M \subseteq \mathbb{R}^{n+k}$ satisfy the conditions of iii). Therefore we have a neighbourhood $W$ of $x$ in $\mathbb{R}^{n+k}$ , a neighbourhood $\Omega$ of $0$ in $\mathbb{R}^n$ , and a $C^p$ map $g: \Omega \to \mathbb{R}^{n+k}$ such that $g$ is an homeomorphism from $\Omega$ onto $M \cap W$ and $g'(0)$ is injective. Since the Jacobian matrix $g'(0)$ or $Dg$ (at $0$ ), which has $n+k$ rows and $n$ columns, is injective    (in this case rank $n$ ), that means that all of its $n$ columns are linearly independent. Therefore we could 'complete' or 'fill out' this matrix up to a full square matrix which has rank $n+k$ (i.e. nonsingular). The filled out matrix is: \begin{bmatrix}     \frac{\partial g_1}{\partial x_1} & \frac{\partial g_1}{\partial x_2} & \dots \frac{\partial g_1}{\partial x_n} & a_{11} & \dots  & a_{1k} \\ \frac{\partial g_2}{\partial x_1} & \frac{\partial g_2}{\partial x_2} & \dots \frac{\partial g_2}{\partial x_n} & a_{21} & \dots  & a_{2k} \\ \frac{\partial g_3}{\partial x_1} & \frac{\partial g_3}{\partial x_2} & \dots \frac{\partial g_3}{\partial x_n} & a_{31} & \dots  & a_{3k} \\    \vdots & \vdots & \vdots &\vdots & \dots & \vdots \\ \frac{\partial g_n}{\partial x_1} & \frac{\partial g_n}{\partial x_2} & \dots \frac{\partial g_n}{\partial x_n} & a_{n1} & \dots  & a_{nk} \\     \vdots & \vdots & \vdots &\vdots & \dots & \vdots \\ \frac{\partial g_{n+k}}{\partial x_1} & \frac{\partial g_{n+k}}{\partial x_2} & \dots \frac{\partial g_{n+k}}{\partial x_n} & a_{(n+k)1} & \dots  & a_{(n+k)k} \end{bmatrix} With this in mind we can define a new function $h : \Omega \times \mathbb{R}^k \to \mathbb{R}^{n+k}$ by: $h_1=g_1(x_1,x_2,...,x_n) + a_{11} x_{n+1} + a_{12} x_{n+2} + ... + a_{1k} x_{n+k}$ etc. Then $Dh$ at $0$ is just the matrix above. Therefore, by the inverse function theorem, there is a neighbourhood $V$ of $0$ such that $h$ carries $V$ in a one to one fashion onto an open set $U$ of $\mathbb{R}^{n+k}$ and we can guarantee that $h(0)$ (which is equal to $g(0)$ ) is in $U$ . This is where I think my problem arises. Although the original $W$ contained $x$ , I can't seem to guarantee that $U$ contains $x$ because the whole process to show that $U$ exists has relied upon the inverse function theorem, which could return a smaller open set than $W$ . Therefore I am not certain I am on the correct track, but apart from this little detail, if I could assume that $g(0)=x$ , I think this would all work. Help would be much appreciated as I am attempting to self-learn with no mathematical contacts at the moment.","In the book Riemannian Geometry by Gallot, Hulin and Lafontaine, a proposition which characterises equivalent definitions of submanifolds is given as follows: 1.3 Proposition The following are equivalent: i) is a submanifold of dimension of . ii) For any in , there exist open neighbourhoods and of and in respectively, and a diffeomorphism such that . iii) For any in , there exist a neighbourhood of in , a neighbourhood of in , and a map such that is a local parametrization of around (that is is an homeomorphism from onto and is injective). I am trying to show that iii) implies ii) and I think that I am nearly there except I am having trouble with the following detail. I will first summarise my problem and then fill in the details. In brief, my main problem in going from iii) to ii) is that to make my proof work I seemed to also require that . (Whereas in contrast the authors have just required that is an homeomorphism from onto and is injective). The details of what I attempted are as follows: (Attempted) Proof that iii) ii). Fix and let satisfy the conditions of iii). Therefore we have a neighbourhood of in , a neighbourhood of in , and a map such that is an homeomorphism from onto and is injective. Since the Jacobian matrix or (at ), which has rows and columns, is injective    (in this case rank ), that means that all of its columns are linearly independent. Therefore we could 'complete' or 'fill out' this matrix up to a full square matrix which has rank (i.e. nonsingular). The filled out matrix is: With this in mind we can define a new function by: etc. Then at is just the matrix above. Therefore, by the inverse function theorem, there is a neighbourhood of such that carries in a one to one fashion onto an open set of and we can guarantee that (which is equal to ) is in . This is where I think my problem arises. Although the original contained , I can't seem to guarantee that contains because the whole process to show that exists has relied upon the inverse function theorem, which could return a smaller open set than . Therefore I am not certain I am on the correct track, but apart from this little detail, if I could assume that , I think this would all work. Help would be much appreciated as I am attempting to self-learn with no mathematical contacts at the moment.","M C^p n \mathbb{R}^{n+k} x M U V x 0 \mathbb{R}^{n+k} C^p f : U\to V f(U \cap M)=V \cap (R^n \times \{0\}) x M U x \mathbb{R}^{n+k} \Omega 0 \mathbb{R}^n C^p g: \Omega \to \mathbb{R}^{n+k} ( \Omega, g) M \cap U x g \Omega M \cap U g'(0) g(0)=x g \Omega M \cap U g'(0) \implies x \in M M \subseteq \mathbb{R}^{n+k} W x \mathbb{R}^{n+k} \Omega 0 \mathbb{R}^n C^p g: \Omega \to \mathbb{R}^{n+k} g \Omega M \cap W g'(0) g'(0) Dg 0 n+k n n n n+k \begin{bmatrix}
    \frac{\partial g_1}{\partial x_1} & \frac{\partial g_1}{\partial x_2} & \dots \frac{\partial g_1}{\partial x_n} & a_{11} & \dots  & a_{1k} \\
\frac{\partial g_2}{\partial x_1} & \frac{\partial g_2}{\partial x_2} & \dots \frac{\partial g_2}{\partial x_n} & a_{21} & \dots  & a_{2k} \\
\frac{\partial g_3}{\partial x_1} & \frac{\partial g_3}{\partial x_2} & \dots \frac{\partial g_3}{\partial x_n} & a_{31} & \dots  & a_{3k} \\
   \vdots & \vdots & \vdots &\vdots & \dots & \vdots \\
\frac{\partial g_n}{\partial x_1} & \frac{\partial g_n}{\partial x_2} & \dots \frac{\partial g_n}{\partial x_n} & a_{n1} & \dots  & a_{nk} \\
    \vdots & \vdots & \vdots &\vdots & \dots & \vdots \\
\frac{\partial g_{n+k}}{\partial x_1} & \frac{\partial g_{n+k}}{\partial x_2} & \dots \frac{\partial g_{n+k}}{\partial x_n} & a_{(n+k)1} & \dots  & a_{(n+k)k}
\end{bmatrix} h : \Omega \times \mathbb{R}^k \to \mathbb{R}^{n+k} h_1=g_1(x_1,x_2,...,x_n) + a_{11} x_{n+1} + a_{12} x_{n+2} + ... + a_{1k} x_{n+k} Dh 0 V 0 h V U \mathbb{R}^{n+k} h(0) g(0) U W x U x U W g(0)=x","['differential-geometry', 'manifolds', 'riemannian-geometry', 'differential']"
87,Compatibility conditions for Maurer-Cartan forms on a homogeneous space,Compatibility conditions for Maurer-Cartan forms on a homogeneous space,,"I am reading Maurer-Cartan forms on a homogeneous space and am  unable to show that $\theta_V=Ad(h_{UV}^{-1})\theta_U+(h_{UV})^*\omega_H$ . Notation : We are considering $G \to G/H$ as a homogeneous H-space, where $G$ is a Lie group, and $H$ is a closed subgroup. $\omega $ is the Maurer-cartan form. For intersecting open sets $U$ and $V$ , we have sections $s_U : U \to G$ and $s_V : V \to G/H$ . Further $\theta_U=s_U^*\omega$ and $\theta_V=s_V^*\omega$ ; on the overlap $U \cap V$ , we have $h_{UV}=s_V \circ s_U^{-1}$ . Here is my attempt :  Let $X\in T_x (G/H)$ . We need to show that $\theta_V(X)=Ad(h_{UV}^{-1})\theta_U(X)+(h_{UV})^*\omega_H(X)$ . Let $c(t)$ be a curve starting at $x \in G/H$ i.e. $c(0)=x$ with tangent vector $c'(0)=X$ . Then $\theta_V(X)= (s_V^*(\omega))(X)=\omega((s_V)_*(X))=\omega((h_{UV}\circ s_U)_*(X))=\omega(\frac{d}{dt}|_{t=0}(h_{UV}(c(t))\cdot s_U(c(t)))$ . But am unable to further simplify this to obtain R.H.S. Kindly help. Thanks a lot !","I am reading Maurer-Cartan forms on a homogeneous space and am  unable to show that . Notation : We are considering as a homogeneous H-space, where is a Lie group, and is a closed subgroup. is the Maurer-cartan form. For intersecting open sets and , we have sections and . Further and ; on the overlap , we have . Here is my attempt :  Let . We need to show that . Let be a curve starting at i.e. with tangent vector . Then . But am unable to further simplify this to obtain R.H.S. Kindly help. Thanks a lot !",\theta_V=Ad(h_{UV}^{-1})\theta_U+(h_{UV})^*\omega_H G \to G/H G H \omega  U V s_U : U \to G s_V : V \to G/H \theta_U=s_U^*\omega \theta_V=s_V^*\omega U \cap V h_{UV}=s_V \circ s_U^{-1} X\in T_x (G/H) \theta_V(X)=Ad(h_{UV}^{-1})\theta_U(X)+(h_{UV})^*\omega_H(X) c(t) x \in G/H c(0)=x c'(0)=X \theta_V(X)= (s_V^*(\omega))(X)=\omega((s_V)_*(X))=\omega((h_{UV}\circ s_U)_*(X))=\omega(\frac{d}{dt}|_{t=0}(h_{UV}(c(t))\cdot s_U(c(t))),['differential-geometry']
88,Differential of a linear map between matrix spaces,Differential of a linear map between matrix spaces,,"This bit of text comes from Lee's Introduction to Smooth Manifolds. I don't see why (8.15) holds. Note first of all that Lee assumes the Einstein summation convention, while I will not in my formulation. I would think that we have $$ A^L\vert_X=\sum_{i=1}^n\sum_{j=1}^n X^i_j A^i_j\frac\partial{\partial X^i_j}\bigg\vert_X, $$ instead of $$ A^L\vert_X=\sum_{k=1}^n\sum_{i=1}^n\sum_{j=1}^n X^i_j A^j_k\frac\partial{\partial X^i_k}\bigg\vert_X, $$ since I think it holds that $$ d(L_X)_{I_n}\left(\frac\partial{\partial X^i_j}\bigg\vert_{I_n}\right)=X^i_j\frac\partial{\partial X^i_j}\bigg\vert_X. $$ I argued this using the coordinate reprsentation of the differential, which is given for an arbitrary smooth map $F\colon M\to N$ by $$ dF_p\left(\frac\partial{\partial x^i}\bigg\vert_p\right)=\frac{\partial\hat F^i}{\partial x^j}\bigg\vert_{\hat p}\frac\partial{\partial y^j}\bigg\vert_{F(p)}, $$ where $(x^i)$ are local coordinates for some open $U\ni p$ , and $(y^i)$ are local coordinates for some open $V\ni F(p)$ . Hence, if we take $(E^i_j)$ as our basis for $\operatorname M_n(\mathbb R)$ , then $E^i_j$ is mapped by $L_X$ to $X^j_i$ . And therefore $$ \frac{\partial(L_X)^i_j}{\partial x^k_l}=\delta_{ik}\delta_{jl} X^j_i. $$ Note that also here, I don't assume Einstein summation convention. So I don't see why (8.15) holds... could someone clarify?","This bit of text comes from Lee's Introduction to Smooth Manifolds. I don't see why (8.15) holds. Note first of all that Lee assumes the Einstein summation convention, while I will not in my formulation. I would think that we have instead of since I think it holds that I argued this using the coordinate reprsentation of the differential, which is given for an arbitrary smooth map by where are local coordinates for some open , and are local coordinates for some open . Hence, if we take as our basis for , then is mapped by to . And therefore Note that also here, I don't assume Einstein summation convention. So I don't see why (8.15) holds... could someone clarify?","
A^L\vert_X=\sum_{i=1}^n\sum_{j=1}^n X^i_j A^i_j\frac\partial{\partial X^i_j}\bigg\vert_X,
 
A^L\vert_X=\sum_{k=1}^n\sum_{i=1}^n\sum_{j=1}^n X^i_j A^j_k\frac\partial{\partial X^i_k}\bigg\vert_X,
 
d(L_X)_{I_n}\left(\frac\partial{\partial X^i_j}\bigg\vert_{I_n}\right)=X^i_j\frac\partial{\partial X^i_j}\bigg\vert_X.
 F\colon M\to N 
dF_p\left(\frac\partial{\partial x^i}\bigg\vert_p\right)=\frac{\partial\hat F^i}{\partial x^j}\bigg\vert_{\hat p}\frac\partial{\partial y^j}\bigg\vert_{F(p)},
 (x^i) U\ni p (y^i) V\ni F(p) (E^i_j) \operatorname M_n(\mathbb R) E^i_j L_X X^j_i 
\frac{\partial(L_X)^i_j}{\partial x^k_l}=\delta_{ik}\delta_{jl} X^j_i.
",['differential-geometry']
89,Intuition behind orientation of a surface,Intuition behind orientation of a surface,,"Let $S\subseteq \mathbb{R}^3$ be a smooth surface. Suppose $\phi: U\rightarrow S$ is a (local) parametrization for $S$ , where $U \subseteq \mathbb{R}^2$ is an open set. Then $\phi(U)$ has a standard orientation, that is, given $p\in\phi(U)$ ( $p=\phi(x_0)$ , $x_0 \in U$ ) the orientation of $T_pS$ is defined to be the orientation given by the basis $\{d\phi(x_0)(e_1),d\phi(x_0)(e_2)\}$ ( $\{e_1,e_2\}$ being the standard basis of $\mathbb{R}^2$ ). I would like to understand how this definition implies that if $p, q \in S$ are close, than the orientations for $T_pS$ and $T_qS$ are ""similar"", without referring to normal vectors. I guess the problem is how to formalise this ""similarity"". We're trying to extend the concept of orientation from vector spaces to a piece of $S$ . However is $p\neq q \in S$ then $T_pS$ and $T_q S$ are different vector spaces, so it doesn't make much sense to compare the orientations of two respective basis. One idea I had is to ""slide"" $T_qS$ to $T_pS$ along the surface $S$ to be able to compare two respective basis. This argument will only work when $\phi(U)$ is connected, i.e. only when $U$ is connected (as $\phi$ is a homeomorphism onto $\phi(u)$ ), but this is not a big issue because if $\phi(U)$ is not connected than it doesn't make much sense (to me) to talk about a ""global"" orientation of disconnected pieces. So I can suppose $U$ and $\phi(U)$ are connected. Since we're working in euclidean spaces then it means that $U$ and $\phi(U)$ are path connected, so there exists a path $\gamma$ in $U$ that lifts to a path from $p$ to $q$ in $S$ . However this path need not be smooth, so it might not behave well for this purposes. So I cannot come up with a canonical way of ""sliding"", hence I'm stuck here, provided this is a good idea. Do you know how to go on from here or an alternative explanation?","Let be a smooth surface. Suppose is a (local) parametrization for , where is an open set. Then has a standard orientation, that is, given ( , ) the orientation of is defined to be the orientation given by the basis ( being the standard basis of ). I would like to understand how this definition implies that if are close, than the orientations for and are ""similar"", without referring to normal vectors. I guess the problem is how to formalise this ""similarity"". We're trying to extend the concept of orientation from vector spaces to a piece of . However is then and are different vector spaces, so it doesn't make much sense to compare the orientations of two respective basis. One idea I had is to ""slide"" to along the surface to be able to compare two respective basis. This argument will only work when is connected, i.e. only when is connected (as is a homeomorphism onto ), but this is not a big issue because if is not connected than it doesn't make much sense (to me) to talk about a ""global"" orientation of disconnected pieces. So I can suppose and are connected. Since we're working in euclidean spaces then it means that and are path connected, so there exists a path in that lifts to a path from to in . However this path need not be smooth, so it might not behave well for this purposes. So I cannot come up with a canonical way of ""sliding"", hence I'm stuck here, provided this is a good idea. Do you know how to go on from here or an alternative explanation?","S\subseteq \mathbb{R}^3 \phi: U\rightarrow S S U \subseteq \mathbb{R}^2 \phi(U) p\in\phi(U) p=\phi(x_0) x_0 \in U T_pS \{d\phi(x_0)(e_1),d\phi(x_0)(e_2)\} \{e_1,e_2\} \mathbb{R}^2 p, q \in S T_pS T_qS S p\neq q \in S T_pS T_q S T_qS T_pS S \phi(U) U \phi \phi(u) \phi(U) U \phi(U) U \phi(U) \gamma U p q S","['differential-geometry', 'manifolds', 'smooth-manifolds', 'surfaces']"
90,Question on the differences in the definitions of what a tensor is,Question on the differences in the definitions of what a tensor is,,"Below are the common definitions of tensor. a. ""a tensor is a quantity which transforms according to a definite law under the change of the coordinate system"". b. ""a tensor is a multilinear function which takes vectors and duals and produces a scalar"" Questions: How are these two definitions related? That is, how can we start with one of definitions and arrive at the other? What is the significance of being ""multilinear""? If we have a function of vectors & duals producing a scalar which is not multilinear, what breaks down? The way I have so far understood a tensor is as follows. Multiple vectors might act on each point in space and produce a result. Tensor is a way of describing the whole phenomena. But again, I could not relate this to the definitions. Why ""invariance under coordinate change"" or ""mulitlinearity"" are required here?","Below are the common definitions of tensor. a. ""a tensor is a quantity which transforms according to a definite law under the change of the coordinate system"". b. ""a tensor is a multilinear function which takes vectors and duals and produces a scalar"" Questions: How are these two definitions related? That is, how can we start with one of definitions and arrive at the other? What is the significance of being ""multilinear""? If we have a function of vectors & duals producing a scalar which is not multilinear, what breaks down? The way I have so far understood a tensor is as follows. Multiple vectors might act on each point in space and produce a result. Tensor is a way of describing the whole phenomena. But again, I could not relate this to the definitions. Why ""invariance under coordinate change"" or ""mulitlinearity"" are required here?",,"['linear-algebra', 'differential-geometry', 'tensors', 'multilinear-algebra', 'general-relativity']"
91,Using the linearization of scalar curvature operator to obtain the contracted second Bianchi identity,Using the linearization of scalar curvature operator to obtain the contracted second Bianchi identity,,"I'm reading the book ""The Ricci Flow: An Introduction"" and I'm at the part where the authors prove the Bianchi identities using the diffeomorphism invariance of the curvature. I'm stuck on some computations from the paragraph below: Consider the scalar curvature operator $g \mapsto R_g$ and it's linearization $DR_g$ defined by $$D R_{g}(h)=-g^{i j} g^{k \ell}\left(\nabla_{i} \nabla_{j} h_{k \ell}-\nabla_{i} \nabla_{k} h_{j \ell}+R_{i k} h_{j \ell}\right)  \ \ \ \ \ (1)$$ for any $2$ tensor $h$ . Substituting $$h_{i j}=\left(\mathcal{L}_{X} g\right)_{i j}=\nabla_{i} X_{j}+\nabla_{j} X_{i}$$ (where $X$ is an arbitrary vector field) and commuting covariant derivatives yields $$\begin{align} D R_{g}\left(\mathcal{L}_{X} g\right) &=-2 \Delta \nabla_{i} X^{i}-2 R_{i j} \nabla^{i} X^{j}+\nabla^{i} \nabla_{j} \nabla_{i} X^{j}+\nabla_{i} \nabla_{j} \nabla^{j} X^{i}   \ \ (2)\\ &=2 X^{i} \nabla^{j} R_{i j} \ \ (3) \end{align}$$ I don't understand how to go from $(1)$ to $(2)$ . Commuting derivatives, we get (where I'm using the obvious notation $\nabla_{j, k} = \nabla_j \nabla_k$ ): $$\nabla_{j, k} X_{\ell} - \nabla_{k, j} X_{\ell} = R_{jks}^{\ell} X^{s}$$ and with some work we can substitute $h = \mathcal{L}_{X} g$ into $(1)$ and obtain: $$DR_g(h) = -g^{ij}g^{kl}\left( \nabla_{i}   \left(R_{jks}^{\ell} X^{s} \right)-  \nabla_{i}\left(R_{j{\ell}s}^{k} X^{s}\right)  +R_{i k} h_{j \ell}\right) $$ but I still can't get from here to $(2)$ . Nor can I see how $(3)$ follows from $(2)$ . I've been stuck at this for a while now and would really appreciate some help.","I'm reading the book ""The Ricci Flow: An Introduction"" and I'm at the part where the authors prove the Bianchi identities using the diffeomorphism invariance of the curvature. I'm stuck on some computations from the paragraph below: Consider the scalar curvature operator and it's linearization defined by for any tensor . Substituting (where is an arbitrary vector field) and commuting covariant derivatives yields I don't understand how to go from to . Commuting derivatives, we get (where I'm using the obvious notation ): and with some work we can substitute into and obtain: but I still can't get from here to . Nor can I see how follows from . I've been stuck at this for a while now and would really appreciate some help.","g \mapsto R_g DR_g D R_{g}(h)=-g^{i j} g^{k \ell}\left(\nabla_{i} \nabla_{j} h_{k \ell}-\nabla_{i} \nabla_{k} h_{j \ell}+R_{i k} h_{j \ell}\right)  \ \ \ \ \ (1) 2 h h_{i j}=\left(\mathcal{L}_{X} g\right)_{i j}=\nabla_{i} X_{j}+\nabla_{j} X_{i} X \begin{align}
D R_{g}\left(\mathcal{L}_{X} g\right) &=-2 \Delta \nabla_{i} X^{i}-2 R_{i j} \nabla^{i} X^{j}+\nabla^{i} \nabla_{j} \nabla_{i} X^{j}+\nabla_{i} \nabla_{j} \nabla^{j} X^{i}   \ \ (2)\\
&=2 X^{i} \nabla^{j} R_{i j} \ \ (3)
\end{align} (1) (2) \nabla_{j, k} = \nabla_j \nabla_k \nabla_{j, k} X_{\ell} - \nabla_{k, j} X_{\ell} = R_{jks}^{\ell} X^{s} h = \mathcal{L}_{X} g (1) DR_g(h) = -g^{ij}g^{kl}\left( \nabla_{i}   \left(R_{jks}^{\ell} X^{s} \right)-  \nabla_{i}\left(R_{j{\ell}s}^{k} X^{s}\right)  +R_{i k} h_{j \ell}\right)  (2) (3) (2)","['geometry', 'differential-geometry', 'manifolds', 'riemannian-geometry', 'ricci-flow']"
92,Calculating the tangent space of the manifold of probability measures on a finite set,Calculating the tangent space of the manifold of probability measures on a finite set,,"Let $I$ be a finite set, $\mathcal{F}(I):= \{I\to\mathcal{R}\}$ the vector space of functions on $I$ with basis $e_i$ , where $e_i(i)=1, e_i(j) = 0 (i \neq j)$ . Let $\mathcal{S}(I)$ be the corresponding dual space and $\{\delta^i\}_i$ the respective dual basis. Consider $\mathcal{P}_+:= \{ \sum_{i\in I} \mu_i \delta^i  \mid \mu_i>0, \sum\mu_i=1 \}$ . In the book that I'm reading the authors say the tangent space in a point $\mu \in \mathcal{P}_+$ is obsviously $\mathcal{S}_0(I):=\{\sum_{i \in I} \mu_i \delta^i \mid \sum \mu_i = 0\}$ . Why is that ? I think in order to calculate the tangent space we would calculate the image of the differential of $\varphi: (\mu_1,...,\mu_{s-1})\to \sum_{i=1}^{s-1}\mu^i\delta^i+(1-\sum_{i=1}^{s-1}\mu_i)\delta^s$ , but I'm not sure how to do this. Can some one help? Of course $\mathcal{S}_0(I)$ has the correct dimension and so it is at least isomorphic to the tangent space but whats special about it ?","Let be a finite set, the vector space of functions on with basis , where . Let be the corresponding dual space and the respective dual basis. Consider . In the book that I'm reading the authors say the tangent space in a point is obsviously . Why is that ? I think in order to calculate the tangent space we would calculate the image of the differential of , but I'm not sure how to do this. Can some one help? Of course has the correct dimension and so it is at least isomorphic to the tangent space but whats special about it ?","I \mathcal{F}(I):= \{I\to\mathcal{R}\} I e_i e_i(i)=1, e_i(j) = 0 (i \neq j) \mathcal{S}(I) \{\delta^i\}_i \mathcal{P}_+:= \{ \sum_{i\in I} \mu_i \delta^i  \mid \mu_i>0, \sum\mu_i=1 \} \mu \in \mathcal{P}_+ \mathcal{S}_0(I):=\{\sum_{i \in I} \mu_i \delta^i \mid \sum \mu_i = 0\} \varphi: (\mu_1,...,\mu_{s-1})\to \sum_{i=1}^{s-1}\mu^i\delta^i+(1-\sum_{i=1}^{s-1}\mu_i)\delta^s \mathcal{S}_0(I)","['differential-geometry', 'tangent-spaces', 'information-geometry']"
93,Existence of a minimal radius when a map fails to be a diffeomorphism,Existence of a minimal radius when a map fails to be a diffeomorphism,,"Let $D \subseteq \mathbb{R}^2$ be the closed unit disk. Let $f:D \to D$ a smooth map with everywhere invertible differential. For each $t \in (0,1]$ let $D_t$ denote the closed disk with radius $t$ . Question: Suppose that $f$ is not a diffeomorphism on $D$ .   Does there exist a minimal $t \in (0,1]$ such that the restriction $f|_{D_t}$ is not a diffeomorphism onto its image? Does the answer change if we replace $D_t$ by the open disk with radius $t$ ? (If not, does the critical value of $t$ change?) Note that the set $A=\{ t \in (0,1] \, | \, f|_{D_t} \text{is a diffeomorphism onto its image} \}$ is clearly ""closed down"", i.e. $\,$ $(y \in A \, \text{  and  }\, 0<x<y) \Rightarrow x \in A$ . Writing $\sup A=s$ , we then must have $A=(0,s)$ or $A=(0,s]$ . An equivalent formulation of the question would then be to prove that $A$ is an open set, or $s \notin A$ . (Then $s$ would be the required minimal $t$ ). My immediate approach (assuming we are talking about open disks, actually) was the following: Note that the restriction of $f$ to an open subset of $\text{int}(D)$ is a diffeomorphism onto its image if and only if it is injective (due to the inverse function theorem). Now, take $s_n \searrow s$ ; we know that $f|_{D_{s_n}}$ is not injective- so there exist $x_n \neq y_n \in D_{s_n}$ such that $f(x_n)=f(y_n)$ . By compactness we can assume that $x_n \to x,y_n \to y$ . If $x \neq y$ we are done since $x,y \in D_s$ . But I don't see any reason to exclude the possibility $x=y$ .","Let be the closed unit disk. Let a smooth map with everywhere invertible differential. For each let denote the closed disk with radius . Question: Suppose that is not a diffeomorphism on .   Does there exist a minimal such that the restriction is not a diffeomorphism onto its image? Does the answer change if we replace by the open disk with radius ? (If not, does the critical value of change?) Note that the set is clearly ""closed down"", i.e. . Writing , we then must have or . An equivalent formulation of the question would then be to prove that is an open set, or . (Then would be the required minimal ). My immediate approach (assuming we are talking about open disks, actually) was the following: Note that the restriction of to an open subset of is a diffeomorphism onto its image if and only if it is injective (due to the inverse function theorem). Now, take ; we know that is not injective- so there exist such that . By compactness we can assume that . If we are done since . But I don't see any reason to exclude the possibility .","D \subseteq \mathbb{R}^2 f:D \to D t \in (0,1] D_t t f D t \in (0,1] f|_{D_t} D_t t t A=\{ t \in (0,1] \, | \, f|_{D_t} \text{is a diffeomorphism onto its image} \} \, (y \in A \, \text{  and  }\, 0<x<y) \Rightarrow x \in A \sup A=s A=(0,s) A=(0,s] A s \notin A s t f \text{int}(D) s_n \searrow s f|_{D_{s_n}} x_n \neq y_n \in D_{s_n} f(x_n)=f(y_n) x_n \to x,y_n \to y x \neq y x,y \in D_s x=y","['real-analysis', 'differential-geometry', 'differential-topology', 'smooth-manifolds', 'singularity']"
94,Discrete and cocompact subgroups of isometries of $\mathbb{R}^n$,Discrete and cocompact subgroups of isometries of,\mathbb{R}^n,"Question 1. Let $G$ be a subgroup of isometries of $\mathbb{R}^n$ that acts discretely and cocompactly (i.e., $\mathbb{R}^n/G$ is compact). Then there exists a finite index subgroup $\mathbb{Z}^n\subset G$ . This appears as the final part of the Cheeger–Gromoll structure theorem for nonnegative Ricci curvature, Theorem 7.3.11 in Riemannian Geometry (Third Edition) by Peter Petersen. The proof there goes like this: Let $\mathbb{R}^n$ be the normal subgroup of translations. The author says that $G\cap\mathbb{R}^n$ is a finitely generated abelian group with finite index in $G$ that acts discretely and cocompactly on $\mathbb{R}^n$ . However, I don't see why this is true. In fact, I think $G\cap\mathbb{R}^n$ may well be the identity. Question 2. If moreover $G$ acts freely, then $G=\mathbb{Z}^n$ and $\mathbb{R}^n/G$ is a flat torus. Again this is content of Corollary 7.3.15 in that book, whose proof I cannot understand. So how do I prove the above facts? And by the way, are there any books on discrete isometry groups? Edit: There is something wrong about the second statement. It is required that the first Betti number of $\mathbb{R}^n/G$ should be $n$ . (Otherwise you could have things like the Klein bottle.) Then the proof in the book works.","Question 1. Let be a subgroup of isometries of that acts discretely and cocompactly (i.e., is compact). Then there exists a finite index subgroup . This appears as the final part of the Cheeger–Gromoll structure theorem for nonnegative Ricci curvature, Theorem 7.3.11 in Riemannian Geometry (Third Edition) by Peter Petersen. The proof there goes like this: Let be the normal subgroup of translations. The author says that is a finitely generated abelian group with finite index in that acts discretely and cocompactly on . However, I don't see why this is true. In fact, I think may well be the identity. Question 2. If moreover acts freely, then and is a flat torus. Again this is content of Corollary 7.3.15 in that book, whose proof I cannot understand. So how do I prove the above facts? And by the way, are there any books on discrete isometry groups? Edit: There is something wrong about the second statement. It is required that the first Betti number of should be . (Otherwise you could have things like the Klein bottle.) Then the proof in the book works.",G \mathbb{R}^n \mathbb{R}^n/G \mathbb{Z}^n\subset G \mathbb{R}^n G\cap\mathbb{R}^n G \mathbb{R}^n G\cap\mathbb{R}^n G G=\mathbb{Z}^n \mathbb{R}^n/G \mathbb{R}^n/G n,"['group-theory', 'differential-geometry', 'riemannian-geometry', 'isometry']"
95,Lie derivative of vector fields and flows of vector fields: Is this formula right?,Lie derivative of vector fields and flows of vector fields: Is this formula right?,,"In the lecture we have defined the Lie derivative as $$\mathcal{L}_{X}Y:=\frac{\mathrm{d}}{\mathrm{d}t}\bigg\vert_{t=0}\Phi_{t}^{\ast}Y$$ where $X,Y\in\mathfrak{X}(\mathcal{M})$ are vector fields on a manifold $\mathcal{M}$ and $\Phi$ is the flow of X. My goal is now to plug in the definition of the pull-back in order to rewrite this formula without the pull-back....I am often confused with the different definition and notations in diffgeo and therefore I would be fine if someone can say if the following is correct: (1) The push-forward of a tangent vector (viewed as a derivation) is for a function $f:\mathcal{M}\to \mathcal{N}$ between two manifolds and a tagent vector $v\in T_{p}\mathcal{M}$ defined as $$f_{\ast}v:=\mathrm{d}_{p}f(v)$$ or in other words: for some function $h\in C^{\infty}(N)$ : $$(f_{\ast}v)(h):=[\mathrm{d}_{p}f(v)](h):=v(h\circ f).$$ (2) For a vector field $X\in\mathfrak{X}(M)$ , the push-forward is defined pointwise: $$(f_{\ast}X)_{q}:=\mathrm{d}_{f^{-1}(q)}(X_{f^{-1}(q)})$$ for some $q\in\mathcal{N}$ , where we have to require that f is a diffeomorphism. (3) Therefore we find with the flow $\Phi_{t}:\mathcal{M}\to \mathcal{M}$ for $p\in\mathcal{M}$ and $f\in C^{\infty}(\mathcal{M})$ : $$(\Phi_{t}^{\ast}Y)_{p}(f):=(\Phi^{-1}_{t\ast}Y)_{p}(f)=[\mathrm{d}_{\Phi_{t}(p)}\Phi_{t}^{-1}(Y_{\Phi_{t}(p)})](f)=Y_{\Phi_{t}(p)}(f\circ \Phi_{t}^{-1})$$ (4) Using that $\Phi^{-1}_{t}=\Phi_{-t}$ this yields the formula: $$(\mathcal{L}_{X}(Y))_{p}(f)=\frac{\mathrm{d}}{\mathrm{d}t}\bigg\vert_{t=0}Y_{\Phi_{t}(p)}(f\circ \Phi_{-t}) $$ If we now view vector fields as derivation on $C^{\infty}(\mathcal{M})$ , namely $X:C^{\infty}(\mathcal{M})\to C^{\infty}(\mathcal{M})$ instead of $X:\mathcal{M}\to T\mathcal{M}$ , this can also be written as: $$(\mathcal{L}_{X}(Y))(f)=\frac{\mathrm{d}}{\mathrm{d}t}\bigg\vert_{t=0}Y(f\circ\Phi_{-t})\circ\Phi_{t}$$ Are the steps and the final formula right?","In the lecture we have defined the Lie derivative as where are vector fields on a manifold and is the flow of X. My goal is now to plug in the definition of the pull-back in order to rewrite this formula without the pull-back....I am often confused with the different definition and notations in diffgeo and therefore I would be fine if someone can say if the following is correct: (1) The push-forward of a tangent vector (viewed as a derivation) is for a function between two manifolds and a tagent vector defined as or in other words: for some function : (2) For a vector field , the push-forward is defined pointwise: for some , where we have to require that f is a diffeomorphism. (3) Therefore we find with the flow for and : (4) Using that this yields the formula: If we now view vector fields as derivation on , namely instead of , this can also be written as: Are the steps and the final formula right?","\mathcal{L}_{X}Y:=\frac{\mathrm{d}}{\mathrm{d}t}\bigg\vert_{t=0}\Phi_{t}^{\ast}Y X,Y\in\mathfrak{X}(\mathcal{M}) \mathcal{M} \Phi f:\mathcal{M}\to \mathcal{N} v\in T_{p}\mathcal{M} f_{\ast}v:=\mathrm{d}_{p}f(v) h\in C^{\infty}(N) (f_{\ast}v)(h):=[\mathrm{d}_{p}f(v)](h):=v(h\circ f). X\in\mathfrak{X}(M) (f_{\ast}X)_{q}:=\mathrm{d}_{f^{-1}(q)}(X_{f^{-1}(q)}) q\in\mathcal{N} \Phi_{t}:\mathcal{M}\to \mathcal{M} p\in\mathcal{M} f\in C^{\infty}(\mathcal{M}) (\Phi_{t}^{\ast}Y)_{p}(f):=(\Phi^{-1}_{t\ast}Y)_{p}(f)=[\mathrm{d}_{\Phi_{t}(p)}\Phi_{t}^{-1}(Y_{\Phi_{t}(p)})](f)=Y_{\Phi_{t}(p)}(f\circ \Phi_{t}^{-1}) \Phi^{-1}_{t}=\Phi_{-t} (\mathcal{L}_{X}(Y))_{p}(f)=\frac{\mathrm{d}}{\mathrm{d}t}\bigg\vert_{t=0}Y_{\Phi_{t}(p)}(f\circ \Phi_{-t})  C^{\infty}(\mathcal{M}) X:C^{\infty}(\mathcal{M})\to C^{\infty}(\mathcal{M}) X:\mathcal{M}\to T\mathcal{M} (\mathcal{L}_{X}(Y))(f)=\frac{\mathrm{d}}{\mathrm{d}t}\bigg\vert_{t=0}Y(f\circ\Phi_{-t})\circ\Phi_{t}","['differential-geometry', 'vector-fields', 'lie-derivative']"
96,Prove this partition of the plane is not a foliation,Prove this partition of the plane is not a foliation,,"Let us define a partition of the plane as follows: for the points $(x_0,y_0)$ with $y_0\leq0$ we have leaves that are straight lines ( $y=y_0$ ) and for $y_0>0$ we have leaves $e^{x+\operatorname{ln}y_0-x_0}$ . This is indeed a partition. But I am being asked whether it is a foliation. A rank $k$ foliation is a collection $\{L_\alpha\}_{\alpha\in A}$ of leaves of a connected immersed submanifold such that it forms a partition of that manifold and for every point of the manifold there exists a chart $(U,\phi=(x_1,\ldots,x_n)$ such that $U\cap L_\alpha$ is a countable union of slices $\{x_{k+1}=\text{ constant},\ldots,x_n=\text{ constant}\}$ or empty. Now I do not believe the given partition is a foliation and that the problem lies on the $y=0$ line. When we take a chart around $(x_0,0)$ we have leaves which are lines and leaves which are exponential curves, which will contradict the continuity of $\phi$ the homeomorphism of the chart, I think. But I do not know how to rigorously prove this. edit: The Frobenius theorem tells us that there exists a bijection between foliations and involutive distributions which maps a foliation to a distribution $D$ , where $D_p := T_pL_\alpha$ for all $p\in \mathbb{R}^2$ , where $L_\alpha$ is the leaf through $p$ .  A distribution on $\mathbb{R}^2$ is a subbundle of $T\mathbb{R}^2$ . Lemma 10.32 of Lee gives us a good criterium for subbundles. It says that in our case, we have a subbundle if and only if for every $p\in \mathbb{R}^2$ there exists a neighborhood $U$ on which there exists sections $\sigma_1,\ldots,\sigma_m: U\rightarrow T\mathbb{R}^2$ with the property that $\sigma_1(q),\ldots,\sigma_m(q)$ form a basis for $D_q$ at each $q\in U$ . The tangent space to a leaf at a point $(x,y)$ will be a straight line with slope $y$ if $y>0$ and slope $0$ if $y\leq 0$ . They are linear spaces of dimension $1$ . What we wanted to show is that for a neighborhood around $(0,0)$ (or some other point on $y=0$ ), there is no smooth section such that the above property holds. I believe a continuous section always exists, but I am not sure how to show whether it is smooth or not.","Let us define a partition of the plane as follows: for the points with we have leaves that are straight lines ( ) and for we have leaves . This is indeed a partition. But I am being asked whether it is a foliation. A rank foliation is a collection of leaves of a connected immersed submanifold such that it forms a partition of that manifold and for every point of the manifold there exists a chart such that is a countable union of slices or empty. Now I do not believe the given partition is a foliation and that the problem lies on the line. When we take a chart around we have leaves which are lines and leaves which are exponential curves, which will contradict the continuity of the homeomorphism of the chart, I think. But I do not know how to rigorously prove this. edit: The Frobenius theorem tells us that there exists a bijection between foliations and involutive distributions which maps a foliation to a distribution , where for all , where is the leaf through .  A distribution on is a subbundle of . Lemma 10.32 of Lee gives us a good criterium for subbundles. It says that in our case, we have a subbundle if and only if for every there exists a neighborhood on which there exists sections with the property that form a basis for at each . The tangent space to a leaf at a point will be a straight line with slope if and slope if . They are linear spaces of dimension . What we wanted to show is that for a neighborhood around (or some other point on ), there is no smooth section such that the above property holds. I believe a continuous section always exists, but I am not sure how to show whether it is smooth or not.","(x_0,y_0) y_0\leq0 y=y_0 y_0>0 e^{x+\operatorname{ln}y_0-x_0} k \{L_\alpha\}_{\alpha\in A} (U,\phi=(x_1,\ldots,x_n) U\cap L_\alpha \{x_{k+1}=\text{ constant},\ldots,x_n=\text{ constant}\} y=0 (x_0,0) \phi D D_p := T_pL_\alpha p\in \mathbb{R}^2 L_\alpha p \mathbb{R}^2 T\mathbb{R}^2 p\in \mathbb{R}^2 U \sigma_1,\ldots,\sigma_m: U\rightarrow T\mathbb{R}^2 \sigma_1(q),\ldots,\sigma_m(q) D_q q\in U (x,y) y y>0 0 y\leq 0 1 (0,0) y=0","['differential-geometry', 'foliations']"
97,Wrapping a Christmas Tree with Even Spacing and Constant Slope,Wrapping a Christmas Tree with Even Spacing and Constant Slope,,"Last week, when I was wrapping strings of beads around my Christmas tree, I initially had the following design in mind: I wanted each pass around the tree to be evenly spaced (e.g. exactly one foot below each part of the string would be another part of the string), and I wanted the slope of the string to be constant (with the exception of the vertex of the tree, since slope isn't defined there). I quickly realized that this was mathematically impossible, since a constant slope along the entire string of beads would imply increased spacing between each pass down the tree due to the tree's increasing diameter at lower heights. That said, if we only look at the points at which the string of beads intersects a given ray down the side of the tree, then it is possible for the string to be at the same spacing and slope for each point on that ray by flattening or steepening the string in that neighborhood. My intuition says that this cannot apply to all rays at once, no matter how varied or strange we make the path, but I'm struggling to prove why that is. My thought is that flattening or steepening the string around whatever point we're looking at has to be compensated for in other neighborhoods, but I'm not sure how to formalize this. Any ideas?","Last week, when I was wrapping strings of beads around my Christmas tree, I initially had the following design in mind: I wanted each pass around the tree to be evenly spaced (e.g. exactly one foot below each part of the string would be another part of the string), and I wanted the slope of the string to be constant (with the exception of the vertex of the tree, since slope isn't defined there). I quickly realized that this was mathematically impossible, since a constant slope along the entire string of beads would imply increased spacing between each pass down the tree due to the tree's increasing diameter at lower heights. That said, if we only look at the points at which the string of beads intersects a given ray down the side of the tree, then it is possible for the string to be at the same spacing and slope for each point on that ray by flattening or steepening the string in that neighborhood. My intuition says that this cannot apply to all rays at once, no matter how varied or strange we make the path, but I'm struggling to prove why that is. My thought is that flattening or steepening the string around whatever point we're looking at has to be compensated for in other neighborhoods, but I'm not sure how to formalize this. Any ideas?",,['differential-geometry']
98,Calculate geodesics on SE(3),Calculate geodesics on SE(3),,"I want wo calculate geodesics on SE(3). I'm not sure if my definition of a Riemannian metric on this manifold is correct. Any comments on my construction will be helpful thank you in advance. I know, that for SE(3) ist is not true, that oneparametersubgroups are geodesics https://mathoverflow.net/questions/81590/one-parameter-subgroup-and-geodesics-on-lie-group?rq=1 Here my thoughts: To be able to talk about geodesics we have to define a Riemanian metric on SE(3). A Riemanian metric is in each point on the manifold a skalarproduct. For the identity element I can define a skalarprodukt by setting $g_{e}\left((v_{1},w_{1}),(v_{2},w_{2})\right):=\begin{pmatrix} v_{1} & w_{1} \end{pmatrix}\begin{pmatrix} A & B\\ B^\top & C \\ \end{pmatrix}\begin{pmatrix} v_{2} \\ w_{2} \end{pmatrix}$ where $(v_{1},w_{1}),(v_{2},w_{2})\in T_{e}G$ and $w$ the coordinates corresponding to the Rotation and $v$ the coordinates corresponding to the translation. I can use Left translation $L_{p}:x\mapsto px$ in order to define a Riemanian metric from this scalarproduct on the whole SE(3) by using the pullback $g_{p}((v_{1},w_{1}),(v_{2},w_{2})):=g_{e}(dL_{p^{-1}}((v_{1},w_{1})),dL_{p^{-1}}((v_{2},w_{2})))$ In order to calculate the geodesics I have to solve the second order differential equation called geodesic equation. Therefore I have to calculate the Christoffel symbols, therefore I have to calculate the coefficients of the metric $g_{ij}$ for any $p\in SE(3)$ . For $p=e=Id$ I already know by definition $(g_{e})_{ij}=\begin{pmatrix} A & B\\ B^\top & C \\ \end{pmatrix}$ I tried to use this article Pull-back metric to calculate the coefficients of the pullback metric: This calculation looked as follows I use canonical coordinates on SE(3) that means local coordinates around the identity look like $x^{k}:=pr^{k}\circ \log$ where log is the Liegrouplogarithm and $pr^k$ the Projektion on the k-th coordinate. Around any other point, the local coordinates look like $y^{k}:=pr^{k}\circ \log\circ L_{p^{-1}}$ it holds $(g_{p})_{ij}=g_{p}(e_{i},e_{j}) =g_{e}(d_{p}L_{p^{-1}}(e_{i}),d_{p}L_{p^{-1}}(e_{j})) =\frac{\partial (x^{k}\circ L_{p^{-1}})}{\partial y^{i}}\frac{\partial (x^{r}\circ L_{p^{-1}})}{\partial y^{j}}g_{e}(e_{k},e_{r}).$ Calculation of the derivatives: $\frac{\partial (x^{k}\circ L_{p^{-1}})}{\partial y^{i}}=\partial_{i}\left(x^{k}\circ L_{p^{-1}}\circ y^{-1}\right)=\partial_{i}\left(pr^{k}\circ \log\circ L_{p^{-1}}\circ L_{p}\circ \exp\right)=\delta_{ik}.$ inserting $(g_{p})_{ij}=\delta^{ik}\delta^{jr}(g_{e})_{kr}=(g_{e})_{ij}$ That would mean the coefficients are constant. Therefore the Christoffelsymbols would be zero, since for the calculation of the Christoffelsymbols I have to calculate the derivatives of g_{ij}. Then the geodesic equation would simplify to c''=0 that means the geodesics are one parameter subgroubs and this is wrong. Does anyone see my mistake?  Thanks a lot!","I want wo calculate geodesics on SE(3). I'm not sure if my definition of a Riemannian metric on this manifold is correct. Any comments on my construction will be helpful thank you in advance. I know, that for SE(3) ist is not true, that oneparametersubgroups are geodesics https://mathoverflow.net/questions/81590/one-parameter-subgroup-and-geodesics-on-lie-group?rq=1 Here my thoughts: To be able to talk about geodesics we have to define a Riemanian metric on SE(3). A Riemanian metric is in each point on the manifold a skalarproduct. For the identity element I can define a skalarprodukt by setting where and the coordinates corresponding to the Rotation and the coordinates corresponding to the translation. I can use Left translation in order to define a Riemanian metric from this scalarproduct on the whole SE(3) by using the pullback In order to calculate the geodesics I have to solve the second order differential equation called geodesic equation. Therefore I have to calculate the Christoffel symbols, therefore I have to calculate the coefficients of the metric for any . For I already know by definition I tried to use this article Pull-back metric to calculate the coefficients of the pullback metric: This calculation looked as follows I use canonical coordinates on SE(3) that means local coordinates around the identity look like where log is the Liegrouplogarithm and the Projektion on the k-th coordinate. Around any other point, the local coordinates look like it holds Calculation of the derivatives: inserting That would mean the coefficients are constant. Therefore the Christoffelsymbols would be zero, since for the calculation of the Christoffelsymbols I have to calculate the derivatives of g_{ij}. Then the geodesic equation would simplify to c''=0 that means the geodesics are one parameter subgroubs and this is wrong. Does anyone see my mistake?  Thanks a lot!","g_{e}\left((v_{1},w_{1}),(v_{2},w_{2})\right):=\begin{pmatrix} v_{1} & w_{1} \end{pmatrix}\begin{pmatrix} A & B\\ B^\top & C \\ \end{pmatrix}\begin{pmatrix} v_{2} \\ w_{2} \end{pmatrix} (v_{1},w_{1}),(v_{2},w_{2})\in T_{e}G w v L_{p}:x\mapsto px g_{p}((v_{1},w_{1}),(v_{2},w_{2})):=g_{e}(dL_{p^{-1}}((v_{1},w_{1})),dL_{p^{-1}}((v_{2},w_{2}))) g_{ij} p\in SE(3) p=e=Id (g_{e})_{ij}=\begin{pmatrix} A & B\\ B^\top & C \\ \end{pmatrix} x^{k}:=pr^{k}\circ \log pr^k y^{k}:=pr^{k}\circ \log\circ L_{p^{-1}} (g_{p})_{ij}=g_{p}(e_{i},e_{j})
=g_{e}(d_{p}L_{p^{-1}}(e_{i}),d_{p}L_{p^{-1}}(e_{j}))
=\frac{\partial (x^{k}\circ L_{p^{-1}})}{\partial y^{i}}\frac{\partial (x^{r}\circ L_{p^{-1}})}{\partial y^{j}}g_{e}(e_{k},e_{r}). \frac{\partial (x^{k}\circ L_{p^{-1}})}{\partial y^{i}}=\partial_{i}\left(x^{k}\circ L_{p^{-1}}\circ y^{-1}\right)=\partial_{i}\left(pr^{k}\circ \log\circ L_{p^{-1}}\circ L_{p}\circ \exp\right)=\delta_{ik}. (g_{p})_{ij}=\delta^{ik}\delta^{jr}(g_{e})_{kr}=(g_{e})_{ij}","['geometry', 'differential-geometry', 'lie-groups', 'geodesic']"
99,Representing a unit speed curve on a general surface in terms of its Frenet Frame,Representing a unit speed curve on a general surface in terms of its Frenet Frame,,"This question grew out of a research project in which I am an active participant, a project which curiously enough requires a hefty dose of the theory of curves and surfaces in $\Bbb R^3$ . I needn't go into more detail here. One of my colleagues in said endeavor noticed that a previous answer of mine, given in response to a question by Helen Waters, presented results which were very illuminating to his own work.  The question to which I  refer is: Representing a unit speed curve on a sphere in terms of its Frenet Frame . In point of fact, similar questions have been posed more than once here on math.stackexchange.com; but this particular one became the object of my colleague's attention, discovered by googling around. In the course of our work it became clear that a generalization of this question and its answer is also of significant importance to us.  I pose the generalized question here, and present my answer below. A unit speed curve $\alpha(s)$ , where $s$ as usual denotes arc-length, which lies on a sphere of radius $r$ centered at a point $c \in \Bbb R^3$ satisfies an equation of the form $(\alpha(s) - c) \cdot (\alpha(s) - c) = r^2; \tag 1$ if we differentiate this equation with respect to $s$ and recall that the unit tangent vector $T(s)$ to $\alpha(s)$ is given by $T(s) = \dot \alpha(s), \tag 2$ we obtain $T(s) \cdot (\alpha(s) - c) = 0; \tag 3$ successive differentiation of this formula with respect to $s$ yields the results of the answer to the cited question; the engaged reader my consult it to see the details. As indicated in the title, I seek here to broaden the result given in the above link to more general, not-necessarily spherical surfaces.  To this end we note that, just as a patch on the sphere of radius $r$ centered at $c \in \Bbb R^3$ may be represented as as a $2$ -parameter vector function $\mathbf r(u, v) \in \Bbb R^3$ such that $(\mathbf r(u, v) - c) \cdot (\mathbf r(u, v) - c) = r^2, \tag 4$ so a general surface patch $\mathcal S$ in $\Bbb R^3$ may be represented by a vector function $\mathbf r(u, v)$ , but sans the constraint (4).  When (4) no longer applies, we may consider the role of $\delta(s)$ , where $\delta^2(s) = \mathbf r(u(s), v(s)) \cdot \mathbf r(u(s), v(s)) = \alpha(s) \cdot \alpha(s) \tag 5$ is the squared magnitude of $\mathbf r(s)$ , i.e., $\delta(s)$ is the distance of $\alpha(s)$ from the coordinate origin $O$ ; here $(u(s), v(s))$ is the path $\alpha(s)$ takes in terms of the patch coordinates $u$ and $v$ . Seen from this point of view, what I wish to ask becomes: The Question: Given a surface patch $\mathcal S$ specified by a vector function $\mathbf r(u, v)$ of two parameters $u$ and $v$ , and a unit speed curve $\alpha(s)$ with differentiable non-vanishing curvature and non-vanishing torsion in $\mathcal S$ , express $\alpha(s) = \mathbf r(u(s), v(s)) \tag 6$ in terms of the Frenet Frame of $\alpha(s)$ and the function $\delta(s)$ .","This question grew out of a research project in which I am an active participant, a project which curiously enough requires a hefty dose of the theory of curves and surfaces in . I needn't go into more detail here. One of my colleagues in said endeavor noticed that a previous answer of mine, given in response to a question by Helen Waters, presented results which were very illuminating to his own work.  The question to which I  refer is: Representing a unit speed curve on a sphere in terms of its Frenet Frame . In point of fact, similar questions have been posed more than once here on math.stackexchange.com; but this particular one became the object of my colleague's attention, discovered by googling around. In the course of our work it became clear that a generalization of this question and its answer is also of significant importance to us.  I pose the generalized question here, and present my answer below. A unit speed curve , where as usual denotes arc-length, which lies on a sphere of radius centered at a point satisfies an equation of the form if we differentiate this equation with respect to and recall that the unit tangent vector to is given by we obtain successive differentiation of this formula with respect to yields the results of the answer to the cited question; the engaged reader my consult it to see the details. As indicated in the title, I seek here to broaden the result given in the above link to more general, not-necessarily spherical surfaces.  To this end we note that, just as a patch on the sphere of radius centered at may be represented as as a -parameter vector function such that so a general surface patch in may be represented by a vector function , but sans the constraint (4).  When (4) no longer applies, we may consider the role of , where is the squared magnitude of , i.e., is the distance of from the coordinate origin ; here is the path takes in terms of the patch coordinates and . Seen from this point of view, what I wish to ask becomes: The Question: Given a surface patch specified by a vector function of two parameters and , and a unit speed curve with differentiable non-vanishing curvature and non-vanishing torsion in , express in terms of the Frenet Frame of and the function .","\Bbb R^3 \alpha(s) s r c \in \Bbb R^3 (\alpha(s) - c) \cdot (\alpha(s) - c) = r^2; \tag 1 s T(s) \alpha(s) T(s) = \dot \alpha(s), \tag 2 T(s) \cdot (\alpha(s) - c) = 0; \tag 3 s r c \in \Bbb R^3 2 \mathbf r(u, v) \in \Bbb R^3 (\mathbf r(u, v) - c) \cdot (\mathbf r(u, v) - c) = r^2, \tag 4 \mathcal S \Bbb R^3 \mathbf r(u, v) \delta(s) \delta^2(s) = \mathbf r(u(s), v(s)) \cdot \mathbf r(u(s), v(s)) = \alpha(s) \cdot \alpha(s) \tag 5 \mathbf r(s) \delta(s) \alpha(s) O (u(s), v(s)) \alpha(s) u v \mathcal S \mathbf r(u, v) u v \alpha(s) \mathcal S \alpha(s) = \mathbf r(u(s), v(s)) \tag 6 \alpha(s) \delta(s)","['differential-geometry', 'surfaces', 'curves']"
