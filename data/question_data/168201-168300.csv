,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Finding center of larger cloud of points?,Finding center of larger cloud of points?,,"First of all, excuse the abstract wording of the title. I don't know the proper term for the concept I want to find, which is part of my problem I guess. I've got a cloud of points (in my case it's 3d points, but it shouldn't matter). They are placed in such a way that most of them are in a general area, but with groups of outliers. Take this picture as an example: I would like to find a value that gives me the center point of the big cloud of points, so to speak. That is, an equivalent of the average that isn't affected by the outliers. But there is an important detail: the bigger cloud should be defined as the larger cloud in size, not the cloud with most points. In the sample image, for example, it is possible that one of the clouds in the lower right has a larger number of points than the large cloud in the left, yet the one in the left should be the chosen cloud. The problem is that I don't know first hand how many outliers there will be or how far they are going to be from each other, so it's hard to define which points will ""form a cloud"". The reason for my question is that I'm basically trying to center a 3d model in a computer application.  Using just the denser area isn't valid, since it could represent just a small object that's modeled with high accuracy due to being round.","First of all, excuse the abstract wording of the title. I don't know the proper term for the concept I want to find, which is part of my problem I guess. I've got a cloud of points (in my case it's 3d points, but it shouldn't matter). They are placed in such a way that most of them are in a general area, but with groups of outliers. Take this picture as an example: I would like to find a value that gives me the center point of the big cloud of points, so to speak. That is, an equivalent of the average that isn't affected by the outliers. But there is an important detail: the bigger cloud should be defined as the larger cloud in size, not the cloud with most points. In the sample image, for example, it is possible that one of the clouds in the lower right has a larger number of points than the large cloud in the left, yet the one in the left should be the chosen cloud. The problem is that I don't know first hand how many outliers there will be or how far they are going to be from each other, so it's hard to define which points will ""form a cloud"". The reason for my question is that I'm basically trying to center a 3d model in a computer application.  Using just the denser area isn't valid, since it could represent just a small object that's modeled with high accuracy due to being round.",,"['geometry', 'statistics', '3d']"
1,Expected number of steps to walk through points by multiple walkers,Expected number of steps to walk through points by multiple walkers,,"Suppose there are $m$ points. A walker can visit the points in any order, but it will not visit a point twice. There are $n$ walkers, and their starting points are randomly chosen. After $k$ steps, each point is visited at least once by any of the walkers. What is the expected number of $k$? Some assumptions: a walker doesn't know the visited points of other walkers multiple walkers can be at the same position Additional question: What if walkers are capable of knowing the visited points of others after they have chosen their random starting points? (so the first assumption doesn't hold anymore)","Suppose there are $m$ points. A walker can visit the points in any order, but it will not visit a point twice. There are $n$ walkers, and their starting points are randomly chosen. After $k$ steps, each point is visited at least once by any of the walkers. What is the expected number of $k$? Some assumptions: a walker doesn't know the visited points of other walkers multiple walkers can be at the same position Additional question: What if walkers are capable of knowing the visited points of others after they have chosen their random starting points? (so the first assumption doesn't hold anymore)",,"['probability', 'statistics']"
2,"Given a joint moment generating function, find $P(X<Y)$","Given a joint moment generating function, find",P(X<Y),"Let random variables $X$ and $Y$ have joint MGF: $$M(t_1,t_2) = 1/2e^{t_1+t_2} + 1/4e^{2t_1+t_2} + 1/12e^{t_2} + 1/6e^{4t_1+3t_2}$$  I now need to find $P(X<Y)$. I know how to find the moments as I had to find $V[X]$ for part of this problem, but I am not quite sure how to figure out probability from this.","Let random variables $X$ and $Y$ have joint MGF: $$M(t_1,t_2) = 1/2e^{t_1+t_2} + 1/4e^{2t_1+t_2} + 1/12e^{t_2} + 1/6e^{4t_1+3t_2}$$  I now need to find $P(X<Y)$. I know how to find the moments as I had to find $V[X]$ for part of this problem, but I am not quite sure how to figure out probability from this.",,"['probability', 'statistics', 'random-variables', 'expectation', 'moment-generating-functions']"
3,Estimating number of values between a range spanning several classes in a histogram,Estimating number of values between a range spanning several classes in a histogram,,"I have been struggling with this topic for ages, and my exam is on Wednesday. I understand how to construct and read a histogram, but I cannot wrap my head around questions where you are asked to find the number of objects within a range that differs from the class widths in the question. For example, the table might be as follows: $$ \begin{array}{c|r} Class & \text{Frequency} \\ \hline 4 - 6 & 6 \\ 7 - 8 & 12 \\ 9 & 21 \\ 10 - 12 & 45 \\ 13 - 15 & 9 \\ 16 - 20 & 5 \\ \end{array} $$ The question given is to estimate the number of values between 8.5 and 13.5. I'm not looking for a solution to the problem, I just need to understand how to answer it. I've tried looking for an explanation, but what I came across only explained how to draw the histogram.","I have been struggling with this topic for ages, and my exam is on Wednesday. I understand how to construct and read a histogram, but I cannot wrap my head around questions where you are asked to find the number of objects within a range that differs from the class widths in the question. For example, the table might be as follows: $$ \begin{array}{c|r} Class & \text{Frequency} \\ \hline 4 - 6 & 6 \\ 7 - 8 & 12 \\ 9 & 21 \\ 10 - 12 & 45 \\ 13 - 15 & 9 \\ 16 - 20 & 5 \\ \end{array} $$ The question given is to estimate the number of values between 8.5 and 13.5. I'm not looking for a solution to the problem, I just need to understand how to answer it. I've tried looking for an explanation, but what I came across only explained how to draw the histogram.",,['statistics']
4,ANOVA test real-life application,ANOVA test real-life application,,"What are the real-life application of ANOVA test ?I used to solve question during my college day and never understood the real life application. Thanks,","What are the real-life application of ANOVA test ?I used to solve question during my college day and never understood the real life application. Thanks,",,['statistics']
5,Proving equality of mean between ANOVA with 2 levels and t-test,Proving equality of mean between ANOVA with 2 levels and t-test,,I want to prove that there is an equality of the ANOVA with 2 levels and t-test. So: From the t-test we know that: $$t=\frac{\overline{x}_1-\overline{x}_2}{\sqrt{\frac{S_1^2}{n_1}-\frac{S_1^2}{n_1}}} \sim t(n_1+n_2-2)$$ And we know for a fact that if a statistic is t-distributed => $\mu=0$. Now for ANOVA with 2 levels we should have a null hypothesis: $$H_0:\mu_0=\mu_1$$ And I guess from this hypothesis we should get something out but I have no idea. Can someone please show me a prove that this statement is true ?,I want to prove that there is an equality of the ANOVA with 2 levels and t-test. So: From the t-test we know that: $$t=\frac{\overline{x}_1-\overline{x}_2}{\sqrt{\frac{S_1^2}{n_1}-\frac{S_1^2}{n_1}}} \sim t(n_1+n_2-2)$$ And we know for a fact that if a statistic is t-distributed => $\mu=0$. Now for ANOVA with 2 levels we should have a null hypothesis: $$H_0:\mu_0=\mu_1$$ And I guess from this hypothesis we should get something out but I have no idea. Can someone please show me a prove that this statement is true ?,,"['statistics', 'hypothesis-testing', 'fisher-information']"
6,ANOVA F-test results in p-value being 1,ANOVA F-test results in p-value being 1,,"In one of the statistics exercises I have tried to solve, I have to show that the means of the observations in four groups aren't equal. I read that a t-test can only be used to compare means for two groups and that a solution would be to make an ANOVA which includes an F-test. The result of my F-test ended up being approximately 62. Since this is far away from 1, it indicates there is a difference in the means. However, I would like to know whether 62 sounds legit? (I know you haven't seen the exercise). Furthermore, how can I calculate the p-value by myself? I tried to calculate the p-value in Excel but that results in value 1 and I don't know if that is correct. Of course, 1 is much bigger than my statistical significance 0,05.","In one of the statistics exercises I have tried to solve, I have to show that the means of the observations in four groups aren't equal. I read that a t-test can only be used to compare means for two groups and that a solution would be to make an ANOVA which includes an F-test. The result of my F-test ended up being approximately 62. Since this is far away from 1, it indicates there is a difference in the means. However, I would like to know whether 62 sounds legit? (I know you haven't seen the exercise). Furthermore, how can I calculate the p-value by myself? I tried to calculate the p-value in Excel but that results in value 1 and I don't know if that is correct. Of course, 1 is much bigger than my statistical significance 0,05.",,"['statistics', 'means', 'variance', 'descriptive-statistics']"
7,Probability Distribution of a standard normal distribution with absolute value,Probability Distribution of a standard normal distribution with absolute value,,"Z is a standard normal and we have to prove that \begin{equation} P(|z| \geq s) \leq {\sqrt{\frac{2}{\pi}}} {\frac{e^{\frac{-s^{2}}{2}}}{s}}\end{equation} As far as I understand I have to use the formula for distribution function of a standard normal random variable, but I do not know how to deal with the ≥ inequality in the probability function as I have only seen examples with the ≤  inequality.","Z is a standard normal and we have to prove that \begin{equation} P(|z| \geq s) \leq {\sqrt{\frac{2}{\pi}}} {\frac{e^{\frac{-s^{2}}{2}}}{s}}\end{equation} As far as I understand I have to use the formula for distribution function of a standard normal random variable, but I do not know how to deal with the ≥ inequality in the probability function as I have only seen examples with the ≤  inequality.",,"['statistics', 'normal-distribution']"
8,Showing that $\hat \theta$ is a minimum variance unbiased estimator of $\theta$,Showing that  is a minimum variance unbiased estimator of,\hat \theta \theta,"Let $X_1,X_2,\ldots,X_n$ be a random sample from a $\operatorname{Poisson}(\theta)$ distribution with probability function $$ P(X = x) = \frac {\theta^xe^{-\theta}}{x!} $$ Show that $\hat \theta$ is the minimum variance unbiased estimator of $\theta$ i.e. that is unbiased and attains the Cramer–Rao bound. My attempt: Showing that $\hat \theta$ is unbiased is easy; $$ E[\hat \theta] = \theta $$ $$ \hat \theta = \bar X $$ $$\operatorname E[\bar X] = \operatorname E\left[ \frac{1}{n} \sum_{i=1}^n X_i \right] = \frac{1}{n} E\left[\sum_{i=1}^n X_i\right] = \frac{1}{n}n\theta = \theta $$ Now to show that the variance attains the Cramer-Rao Bound is what I'm having trouble with. $$\operatorname{Var}(\hat \theta) = \frac{1}{E[(\frac{d\ell(\theta)}{d\theta})^2]} $$ $$\operatorname{Var}(\hat \theta) = \frac{1}{E[(\frac{\sum_{i=0}^n(x_i)}{\theta} - n)^2]}  $$ And now I'm not sure how to expand this further. Is the square of a sum just itself?","Let $X_1,X_2,\ldots,X_n$ be a random sample from a $\operatorname{Poisson}(\theta)$ distribution with probability function $$ P(X = x) = \frac {\theta^xe^{-\theta}}{x!} $$ Show that $\hat \theta$ is the minimum variance unbiased estimator of $\theta$ i.e. that is unbiased and attains the Cramer–Rao bound. My attempt: Showing that $\hat \theta$ is unbiased is easy; $$ E[\hat \theta] = \theta $$ $$ \hat \theta = \bar X $$ $$\operatorname E[\bar X] = \operatorname E\left[ \frac{1}{n} \sum_{i=1}^n X_i \right] = \frac{1}{n} E\left[\sum_{i=1}^n X_i\right] = \frac{1}{n}n\theta = \theta $$ Now to show that the variance attains the Cramer-Rao Bound is what I'm having trouble with. $$\operatorname{Var}(\hat \theta) = \frac{1}{E[(\frac{d\ell(\theta)}{d\theta})^2]} $$ $$\operatorname{Var}(\hat \theta) = \frac{1}{E[(\frac{\sum_{i=0}^n(x_i)}{\theta} - n)^2]}  $$ And now I'm not sure how to expand this further. Is the square of a sum just itself?",,['statistics']
9,Finding E[1/X] from E[X],Finding E[1/X] from E[X],,"Is there a shortcut?  I already have E[X] where X=Y+1, thus I can separate it into E[Y]+E[1], and for Y, it's number of tries is n, and the probability p.","Is there a shortcut?  I already have E[X] where X=Y+1, thus I can separate it into E[Y]+E[1], and for Y, it's number of tries is n, and the probability p.",,['statistics']
10,Normal distribution problem with 2 normal distributions?,Normal distribution problem with 2 normal distributions?,,"I have this problem: A professor of statistics noticed that the marks in his course are normally distributed. He also noticed that his morning classes average 70% with a standard deviation of 13% on their final exams. His afternoon classes average 79% with a standard deviation of 9%. What is the probability that a randomly selected student in the morning class has a higher final exam mark than a randomly selected student from an afternoon class? I've been trying to solve this problem myself for quite awhile and not really sure what is wrong with my approach. I let the morning class = X1 and the afternoon class = X2. So E(X1) = 70, σ(X1) = 13, E(X2) = 79, and σ(X2) = 9. Then I let the variable Y = X1-X2, and since X1 and X2 are both normally distributed, then Y will be as well. So I have the following for Y: $$E(Y) = E(X_1)-E(X_2) = 70-79 = -9$$ $$σ(Y) = \sqrt{σ(X_1)^2 + σ(X_2)^2} = \sqrt{13^2+9^2} = \sqrt{250}$$ In oder to find the probability that a randmly selected student in the morning class has a higher final exam mark than one from the afternoon class, we want P(X1 > X2) = P(X1 - X2 > 0) = P(Y > 0). So I converted this to z-score... $$Z = \frac{X-E(Y)}σ = \frac{0-(-9)}{\sqrt{250}} = \frac 9{\sqrt{250}} \approx 0.57$$ So that we are looking for P(Z > 0.57) or 1-P(Z$\leq$0.57). I looked at my z-score table and found my answer to be 0.2843 , which is marked as wrong. I've tried doing different things for rounding etc., and still can't seem to find the right answer. Any insight is greatly appreciated - maybe I made some dumb error that I can't seem to see. Thank you! :)","I have this problem: A professor of statistics noticed that the marks in his course are normally distributed. He also noticed that his morning classes average 70% with a standard deviation of 13% on their final exams. His afternoon classes average 79% with a standard deviation of 9%. What is the probability that a randomly selected student in the morning class has a higher final exam mark than a randomly selected student from an afternoon class? I've been trying to solve this problem myself for quite awhile and not really sure what is wrong with my approach. I let the morning class = X1 and the afternoon class = X2. So E(X1) = 70, σ(X1) = 13, E(X2) = 79, and σ(X2) = 9. Then I let the variable Y = X1-X2, and since X1 and X2 are both normally distributed, then Y will be as well. So I have the following for Y: $$E(Y) = E(X_1)-E(X_2) = 70-79 = -9$$ $$σ(Y) = \sqrt{σ(X_1)^2 + σ(X_2)^2} = \sqrt{13^2+9^2} = \sqrt{250}$$ In oder to find the probability that a randmly selected student in the morning class has a higher final exam mark than one from the afternoon class, we want P(X1 > X2) = P(X1 - X2 > 0) = P(Y > 0). So I converted this to z-score... $$Z = \frac{X-E(Y)}σ = \frac{0-(-9)}{\sqrt{250}} = \frac 9{\sqrt{250}} \approx 0.57$$ So that we are looking for P(Z > 0.57) or 1-P(Z$\leq$0.57). I looked at my z-score table and found my answer to be 0.2843 , which is marked as wrong. I've tried doing different things for rounding etc., and still can't seem to find the right answer. Any insight is greatly appreciated - maybe I made some dumb error that I can't seem to see. Thank you! :)",,"['statistics', 'normal-distribution']"
11,How does a uniform distribution have a mean?,How does a uniform distribution have a mean?,,"I believe a continuous uniform distribution over an interval $[a,b]$ to be the probability distribution describing an equally likely chance for any outcome on $[a,b]$. Other than by mathematical definition, how can I see that the avg/mean/expected value is $\frac{a+b}{2}$? Isn't the mean an indicator of likelihood? Or is it just that 'expected value' is poor terminology for the uniform distribution? For example: if I had a probability distribution shaped like an upward parabola (over a relatively large interval, where the vertex was a the center of the distribution, then the mean would be dead center of the interval but a very inaccurate indicator of what value you could expect to see during an experiment. Is this right? I'm looking for some intuition here, because it doesn't make sense to me that some process can be completely random yet have an average value, especially when I think of an extremely large $|b-a|$.","I believe a continuous uniform distribution over an interval $[a,b]$ to be the probability distribution describing an equally likely chance for any outcome on $[a,b]$. Other than by mathematical definition, how can I see that the avg/mean/expected value is $\frac{a+b}{2}$? Isn't the mean an indicator of likelihood? Or is it just that 'expected value' is poor terminology for the uniform distribution? For example: if I had a probability distribution shaped like an upward parabola (over a relatively large interval, where the vertex was a the center of the distribution, then the mean would be dead center of the interval but a very inaccurate indicator of what value you could expect to see during an experiment. Is this right? I'm looking for some intuition here, because it doesn't make sense to me that some process can be completely random yet have an average value, especially when I think of an extremely large $|b-a|$.",,"['statistics', 'probability-distributions', 'random-variables', 'random', 'uniform-distribution']"
12,Maximum A Priori Estimate of Beta-Bernoulli,Maximum A Priori Estimate of Beta-Bernoulli,,"Suppose I have a d-dimensional vector $x$ whose components $x_i$ are each i.i.d. Bernoulli with some $\theta_i$. $\theta$ is then the vector of parameters and $$ p(x|\theta) = \prod_{i=1}^d\theta_i^{x_i}(1-\theta_i)^{(1 - x_i)} $$ I have a dataset of vectors (all i.i.d) like $x$ - basically each vector is a black and white image where the pixels are either labelled 0 or 1. I want to estimate $\theta$ with the Maximum A Priori (MAP) method with a $Beta(2, 2)$ prior for each $\theta_i$. So far what I have is this, ignoring normalization constants: $$ p(\theta|x) \propto p(x|\theta)p(\theta) $$ $$ p(\theta|x) \propto \prod_{i=1}^d\theta_i^{x_i}(1-\theta_i)^{(1 - x_i)} \theta_i(1-\theta_i)  $$ $$ p(\theta|x) \propto \prod_{i=1}^d\theta_i^{x_i +1}(1-\theta_i)^{(2 - x_i)}  $$ The expression inside the product is another Beta distribution in disguise so $$ p(\theta|x) \propto \prod_{i=1}^d Beta(x_i + 2, 3 - x_i) $$ At this point I choose the mode for each individual Beta distribution, which is $$\frac{x_i + 1}3$$ and so the MAP estimate is $$p(\theta|x) \propto \prod_{i=1}^d \frac{x_i + 1}3$$ That's only using one vector from my dataset though. How do I extend it to include all the data? I don't know how to get the mode of a product of a product.","Suppose I have a d-dimensional vector $x$ whose components $x_i$ are each i.i.d. Bernoulli with some $\theta_i$. $\theta$ is then the vector of parameters and $$ p(x|\theta) = \prod_{i=1}^d\theta_i^{x_i}(1-\theta_i)^{(1 - x_i)} $$ I have a dataset of vectors (all i.i.d) like $x$ - basically each vector is a black and white image where the pixels are either labelled 0 or 1. I want to estimate $\theta$ with the Maximum A Priori (MAP) method with a $Beta(2, 2)$ prior for each $\theta_i$. So far what I have is this, ignoring normalization constants: $$ p(\theta|x) \propto p(x|\theta)p(\theta) $$ $$ p(\theta|x) \propto \prod_{i=1}^d\theta_i^{x_i}(1-\theta_i)^{(1 - x_i)} \theta_i(1-\theta_i)  $$ $$ p(\theta|x) \propto \prod_{i=1}^d\theta_i^{x_i +1}(1-\theta_i)^{(2 - x_i)}  $$ The expression inside the product is another Beta distribution in disguise so $$ p(\theta|x) \propto \prod_{i=1}^d Beta(x_i + 2, 3 - x_i) $$ At this point I choose the mode for each individual Beta distribution, which is $$\frac{x_i + 1}3$$ and so the MAP estimate is $$p(\theta|x) \propto \prod_{i=1}^d \frac{x_i + 1}3$$ That's only using one vector from my dataset though. How do I extend it to include all the data? I don't know how to get the mode of a product of a product.",,"['probability', 'statistics']"
13,Cramer Rao lower bound in Cauchy distribution,Cramer Rao lower bound in Cauchy distribution,,I need to calculate the Cramer Rao lower bound of variance for the parameter $\theta$ of the distribution $$f(x)=\frac{1}{\pi(1+(x-\theta)^2)}$$ How do I proceed I have calculated $$4 E\frac{(X-\theta)^2}{1+X^2+\theta^2-2X\theta}$$ Can somebody help,I need to calculate the Cramer Rao lower bound of variance for the parameter $\theta$ of the distribution $$f(x)=\frac{1}{\pi(1+(x-\theta)^2)}$$ How do I proceed I have calculated $$4 E\frac{(X-\theta)^2}{1+X^2+\theta^2-2X\theta}$$ Can somebody help,,"['statistics', 'probability-distributions', 'statistical-inference', 'expected-value']"
14,Confidence interval for parameter,Confidence interval for parameter,,"$X_1, X_2, \dots, X_n$ - i.i.d observations $X_1 = \xi + \eta$ where $\xi \sim N(\theta^2, \theta^2+1)$, $\eta = \begin{cases} 0, & 1/2 \\ 4\theta, & 1/2 \end{cases}$, $\xi$ and $\eta$ are independent. Find $\alpha$-confidence interval. The first that I need to do is to find some estimate for $\theta$. The only one that I find is $(5\overline{X} - S^2 +1)/10$ but it is difficult to find distribution. Is it possible to do something else?","$X_1, X_2, \dots, X_n$ - i.i.d observations $X_1 = \xi + \eta$ where $\xi \sim N(\theta^2, \theta^2+1)$, $\eta = \begin{cases} 0, & 1/2 \\ 4\theta, & 1/2 \end{cases}$, $\xi$ and $\eta$ are independent. Find $\alpha$-confidence interval. The first that I need to do is to find some estimate for $\theta$. The only one that I find is $(5\overline{X} - S^2 +1)/10$ but it is difficult to find distribution. Is it possible to do something else?",,"['statistics', 'confidence-interval']"
15,How do I combine standard deviations from 2 groups?,How do I combine standard deviations from 2 groups?,,"I am abstracting data from a research study. I do not know the individual values within each group. But I have 2 groups. One with a population of 149, a mean of 37.3 and an SD of 12.8. My other group has a population of 669, a mean of 38.4 and an SD of 13.4. How do I combine the standard deviations?","I am abstracting data from a research study. I do not know the individual values within each group. But I have 2 groups. One with a population of 149, a mean of 37.3 and an SD of 12.8. My other group has a population of 669, a mean of 38.4 and an SD of 13.4. How do I combine the standard deviations?",,"['statistics', 'standard-deviation']"
16,Chi square and gamma distribution.,Chi square and gamma distribution.,,"I have studied the intuiton of the gamma distribution and have understood the following: Let us suppose that we want to study the probability of waiting time until the $\alpha$-th event occurs. Let $W$ be the corresponding ramdon value. Then we want to calculate $F(w)=P(W\leq w)=1-P(W>w)$. Now, the waiting time $W$ is greater than some value $w$ only if there are fewer than $α$ events in the interval $[0,w]$. That is: $$ \begin{align} F(w)  & = 1 − P(\text{fewer than $α$ events in $[0,w]$)} \\ & = 1 − P(\text{0 events or 1 event or … or $(α−1)$ events in $[0,w]$)} \end{align} $$ Then one can use the Poisson distribution with mean $\lambda w$ to obtain $$F(w)=1-\sum\limits_{k=0}^{\alpha-1} \dfrac{(\lambda w)^k e^{-\lambda w}}{k!}$$ Calculating the first derivation and doing some simplifications with $\lambda=1/\theta$, this leads to $$f(w)=\frac 1 {\Gamma(\alpha) \theta^\alpha} e^{-w/\theta} w^{\alpha-1}$$ where $\alpha$ can now be used as a real positive number. So in a way the Gamma distributions gives the posibility of that $\alpha$ events occur until some determined time. Thus, $\theta$ is the mean waiting time until the first event, and $\alpha$ is the number of events for which you are waiting to occur. That I would like to know it the following: Is there any geometric/intuitive way to know why the Chi squared distriution takes the values $\theta=2$ and $\alpha=r/2$ as a special case of the gamma distribution? What does make these values special and important/interesting? If this is not the right way to lighten the Chi square distribution: Is there a geometric/intuitive way to understand the Chi Square distribution as a sum of squares from normal distributed ramdom variables? Why Is the sum of this squares interesting/special? Maybe there are more technical than geometrical reasons for the approach of the Chi square distribution, but I would feel more confortable to gain an inside of what this distributions does insteed of where it can be use for... Thank you in advance for any help!","I have studied the intuiton of the gamma distribution and have understood the following: Let us suppose that we want to study the probability of waiting time until the $\alpha$-th event occurs. Let $W$ be the corresponding ramdon value. Then we want to calculate $F(w)=P(W\leq w)=1-P(W>w)$. Now, the waiting time $W$ is greater than some value $w$ only if there are fewer than $α$ events in the interval $[0,w]$. That is: $$ \begin{align} F(w)  & = 1 − P(\text{fewer than $α$ events in $[0,w]$)} \\ & = 1 − P(\text{0 events or 1 event or … or $(α−1)$ events in $[0,w]$)} \end{align} $$ Then one can use the Poisson distribution with mean $\lambda w$ to obtain $$F(w)=1-\sum\limits_{k=0}^{\alpha-1} \dfrac{(\lambda w)^k e^{-\lambda w}}{k!}$$ Calculating the first derivation and doing some simplifications with $\lambda=1/\theta$, this leads to $$f(w)=\frac 1 {\Gamma(\alpha) \theta^\alpha} e^{-w/\theta} w^{\alpha-1}$$ where $\alpha$ can now be used as a real positive number. So in a way the Gamma distributions gives the posibility of that $\alpha$ events occur until some determined time. Thus, $\theta$ is the mean waiting time until the first event, and $\alpha$ is the number of events for which you are waiting to occur. That I would like to know it the following: Is there any geometric/intuitive way to know why the Chi squared distriution takes the values $\theta=2$ and $\alpha=r/2$ as a special case of the gamma distribution? What does make these values special and important/interesting? If this is not the right way to lighten the Chi square distribution: Is there a geometric/intuitive way to understand the Chi Square distribution as a sum of squares from normal distributed ramdom variables? Why Is the sum of this squares interesting/special? Maybe there are more technical than geometrical reasons for the approach of the Chi square distribution, but I would feel more confortable to gain an inside of what this distributions does insteed of where it can be use for... Thank you in advance for any help!",,"['probability', 'statistics', 'gamma-distribution', 'chi-squared']"
17,Two-sample test for ordinal data.,Two-sample test for ordinal data.,,I have a question in a survey X that can be rated between 1 and 10 (ordinal). The answers can be split in group A and group B. I want to know if the mean of group A's answers significantly differ from groups B rating. Which test is the best one to do so and how can I do this with SPSS? Thank you very much for your help!,I have a question in a survey X that can be rated between 1 and 10 (ordinal). The answers can be split in group A and group B. I want to know if the mean of group A's answers significantly differ from groups B rating. Which test is the best one to do so and how can I do this with SPSS? Thank you very much for your help!,,"['statistics', 'correlation', 'hypothesis-testing']"
18,minimal number of samples for confidence interval,minimal number of samples for confidence interval,,TV show producers want to estimate the show's rating (in percentage). What should be the minimal size of the sample for confidence of $90\%$ and confidence interval length $= 6\%$? So basing on the length formula: $$n = \frac {z_{1-\alpha/2}^2\sigma^2}{d^2} \simeq \frac{1.644^2\sigma ^2}{36}$$ Is that what I'm expected to present? the variance is unknown so obviously I can't produce a numerical result.,TV show producers want to estimate the show's rating (in percentage). What should be the minimal size of the sample for confidence of $90\%$ and confidence interval length $= 6\%$? So basing on the length formula: $$n = \frac {z_{1-\alpha/2}^2\sigma^2}{d^2} \simeq \frac{1.644^2\sigma ^2}{36}$$ Is that what I'm expected to present? the variance is unknown so obviously I can't produce a numerical result.,,['statistics']
19,Monty Hall extension,Monty Hall extension,,"Lets explore an extension of the monty hall problem. Assume the usual scenario with two goats and one car. Also assume that there are two types of hosts, and you do not know which type your host is. Host type A is the standard host that gives you a choice to switch. Host type B only gives you a choice if you choose the right door at the beginning, otherwise he reveals that you have lost immediately. You know that host A appears with probability P(A), and host B with probability 1-P(A) what does P(A) have to be so there is no dominant strategy if you have been given the choice? My first attempt is to state that the probability of winning P(W) has to be 1/2 if you always switch, so there is no dominant strategy. Thus P(W)=P(W|A) P(A) + P(W|B) (1-P(A))=1/2 Note that  P(W|B)=0 if you always switch. Hence P(A)= P(W)/P(W|A)=1/2/2/3=3/4 Is this correct? I cannot take away the feeling that the fact that you have a choice gives you new information that should change the problem, but I may be simply over thinking everything.","Lets explore an extension of the monty hall problem. Assume the usual scenario with two goats and one car. Also assume that there are two types of hosts, and you do not know which type your host is. Host type A is the standard host that gives you a choice to switch. Host type B only gives you a choice if you choose the right door at the beginning, otherwise he reveals that you have lost immediately. You know that host A appears with probability P(A), and host B with probability 1-P(A) what does P(A) have to be so there is no dominant strategy if you have been given the choice? My first attempt is to state that the probability of winning P(W) has to be 1/2 if you always switch, so there is no dominant strategy. Thus P(W)=P(W|A) P(A) + P(W|B) (1-P(A))=1/2 Note that  P(W|B)=0 if you always switch. Hence P(A)= P(W)/P(W|A)=1/2/2/3=3/4 Is this correct? I cannot take away the feeling that the fact that you have a choice gives you new information that should change the problem, but I may be simply over thinking everything.",,"['statistics', 'monty-hall']"
20,Proof for Maximum Likelihood Estimation,Proof for Maximum Likelihood Estimation,,"I can follow the steps but I don't really understand what it wants to say. The whole equation is done to prove the inequality, what does inequality say?","I can follow the steps but I don't really understand what it wants to say. The whole equation is done to prove the inequality, what does inequality say?",,"['statistics', 'maximum-likelihood']"
21,Testing a Random Number Generator for Randomness,Testing a Random Number Generator for Randomness,,"I created a random number generator (numbers from 0-100 exclusive) and was looking for a way to test for randomness, is there a statistical test that would help me with this and how would I use it?","I created a random number generator (numbers from 0-100 exclusive) and was looking for a way to test for randomness, is there a statistical test that would help me with this and how would I use it?",,"['statistics', 'random', 'simulation']"
22,Probability Question: Independence,Probability Question: Independence,,"My stats prof posted an answer but it doesn't make sense. Please help! $A$, $B$, $C$ are mutually independent. Prove $A$ and $B^c ∪ C$ are independent? ($B^c$ = $B$ complement) My stats professor posted this answer, but I don't get where he got the first line in the proof. Shouldn't it be $P(A \cap (B^c \cup C))$?  Would really appreciate it if anyone could explain. Thank you so much! Proof:  $$P(A∪(B^c ∩C))=P((A∩B^c)∪(A∩C)) $$ $$= P(AB^c) + P(AC) − P(AB^cC) $$ $$= P(A)P(B^c) + P(A)P(C) − P(A)P(B^c)P(C),\text{ because they are mutually independent.}$$ $$= P(A)(P(B^c) + P(C) − P(B^cC)) $$ $$=P(A)P(B^c ∪C) $$ Thus, $A$ and $B^c ∪ C$ are independent.","My stats prof posted an answer but it doesn't make sense. Please help! $A$, $B$, $C$ are mutually independent. Prove $A$ and $B^c ∪ C$ are independent? ($B^c$ = $B$ complement) My stats professor posted this answer, but I don't get where he got the first line in the proof. Shouldn't it be $P(A \cap (B^c \cup C))$?  Would really appreciate it if anyone could explain. Thank you so much! Proof:  $$P(A∪(B^c ∩C))=P((A∩B^c)∪(A∩C)) $$ $$= P(AB^c) + P(AC) − P(AB^cC) $$ $$= P(A)P(B^c) + P(A)P(C) − P(A)P(B^c)P(C),\text{ because they are mutually independent.}$$ $$= P(A)(P(B^c) + P(C) − P(B^cC)) $$ $$=P(A)P(B^c ∪C) $$ Thus, $A$ and $B^c ∪ C$ are independent.",,"['probability', 'statistics', 'independence']"
23,Hypothesis test for a population proportion,Hypothesis test for a population proportion,,"$H_0: $ the probability that a person has the characteristic A = $0.05$ $H_1: $ the probability that a person has the characteristic A $­\neq 0.05$ I take a sample of size $500$ and find that $40$ people ($0.08$) have the characteristic A. I want to test the null hypothesis with $\alpha = 0.01$. First, I would have to find the sample's variance, which is $\dfrac{1}{500-1}(0.08-0.05)^2 = 0.0000018$, so the standard deviation is $0.00134$. The discriminating function would be Student's T fonction. The observed T is $\dfrac{0.08-0.05}{0.00134}*\sqrt{500} = 499$. That means that the critical $\alpha$ value would be incredibly small. That seems a bit extreme, did I go wrong somewhere?","$H_0: $ the probability that a person has the characteristic A = $0.05$ $H_1: $ the probability that a person has the characteristic A $­\neq 0.05$ I take a sample of size $500$ and find that $40$ people ($0.08$) have the characteristic A. I want to test the null hypothesis with $\alpha = 0.01$. First, I would have to find the sample's variance, which is $\dfrac{1}{500-1}(0.08-0.05)^2 = 0.0000018$, so the standard deviation is $0.00134$. The discriminating function would be Student's T fonction. The observed T is $\dfrac{0.08-0.05}{0.00134}*\sqrt{500} = 499$. That means that the critical $\alpha$ value would be incredibly small. That seems a bit extreme, did I go wrong somewhere?",,"['statistics', 'binomial-distribution', 'hypothesis-testing']"
24,"Estimator of $\theta$, uniform distribution $(\theta, \theta +1)$","Estimator of , uniform distribution","\theta (\theta, \theta +1)","I would like to ask you, if somebody helps me to solve one statistics problem. I have $X_1, ..., X_n$  a sample of independent random variables with uniform distribution $(\theta, \theta +1)$ I have an estimator $\hat{\theta}_n=\max$ $X_i -1$ for $1 \le i \le n$, and I should find if it is unbiased and consistent, I found, that it is consistent but I think that it is biased. I find density of my estimator: $f_Y(y)=n(y+1-\theta)^{(n-1)}$, where $y=\max$ $X_i$, but I am not sure, if it is correct, because if I calculate $E(\hat{\theta}_n)$, the result was quite strange. The last step, which I should do, is following: how should I change $\hat{\theta}_n$ to make it unbiased. I think that I have to substract 1, but then I am not sure. Please, can somebody check if I calculate the density correctly and how I can find an unbiased estimator (I cannot use MLE)? Thank you","I would like to ask you, if somebody helps me to solve one statistics problem. I have $X_1, ..., X_n$  a sample of independent random variables with uniform distribution $(\theta, \theta +1)$ I have an estimator $\hat{\theta}_n=\max$ $X_i -1$ for $1 \le i \le n$, and I should find if it is unbiased and consistent, I found, that it is consistent but I think that it is biased. I find density of my estimator: $f_Y(y)=n(y+1-\theta)^{(n-1)}$, where $y=\max$ $X_i$, but I am not sure, if it is correct, because if I calculate $E(\hat{\theta}_n)$, the result was quite strange. The last step, which I should do, is following: how should I change $\hat{\theta}_n$ to make it unbiased. I think that I have to substract 1, but then I am not sure. Please, can somebody check if I calculate the density correctly and how I can find an unbiased estimator (I cannot use MLE)? Thank you",,"['probability', 'statistics', 'uniform-distribution', 'estimation', 'parameter-estimation']"
25,Linear regression: how does multicollinearity inflate variance of estimators,Linear regression: how does multicollinearity inflate variance of estimators,,"Suppose I have a multiple linear regression model $Y_i = \beta_0 + \beta_1 * X_{i1} + ... \beta_p * X_{ip} + \epsilon_i$ where $\epsilon_i \sim N(0, \sigma^2)$ and $Cov(\epsilon_i, \epsilon_j) = 0$ for $i \neq j$. If two of the predictors are correlated, then that will inflate the variance of the coefficient estimates, leading to invalid inferences. In the MLR setting, the variance of the least squares estimator $\hat{\beta}$ is $\sigma^2(X'X)^{-1}$. Can someone give me some mathematical intuition as to why $\sigma^2(X'X)^{-1}$ will inflate/become unstable if there's multicollinearity?","Suppose I have a multiple linear regression model $Y_i = \beta_0 + \beta_1 * X_{i1} + ... \beta_p * X_{ip} + \epsilon_i$ where $\epsilon_i \sim N(0, \sigma^2)$ and $Cov(\epsilon_i, \epsilon_j) = 0$ for $i \neq j$. If two of the predictors are correlated, then that will inflate the variance of the coefficient estimates, leading to invalid inferences. In the MLR setting, the variance of the least squares estimator $\hat{\beta}$ is $\sigma^2(X'X)^{-1}$. Can someone give me some mathematical intuition as to why $\sigma^2(X'X)^{-1}$ will inflate/become unstable if there's multicollinearity?",,"['statistics', 'statistical-inference', 'regression', 'variance']"
26,Why is chi-square statistic not dimensionless?,Why is chi-square statistic not dimensionless?,,"I figure, if I measure something in meters, and then take a chi-square from it to test a hypothesis, the value I get will be in meters too. But that doesn't make sense: by simply switching to kilometers, I'd get a 1000 times smaller value. Or is it only supposed to be used with dimensionless quantities to begin with? For example, if I am using poll data (yes, Presidential) to test a hypothesis, should I use percentages as inputs or actual numbers of people that voted? It seems that the latter would make more sense (if a poll includes two people, and both vote one way, it's 100%, but doesn't mean very much), but brings the question of units into the picture (if I count people in thousands, rather than in persons, I'd get a very different result).","I figure, if I measure something in meters, and then take a chi-square from it to test a hypothesis, the value I get will be in meters too. But that doesn't make sense: by simply switching to kilometers, I'd get a 1000 times smaller value. Or is it only supposed to be used with dimensionless quantities to begin with? For example, if I am using poll data (yes, Presidential) to test a hypothesis, should I use percentages as inputs or actual numbers of people that voted? It seems that the latter would make more sense (if a poll includes two people, and both vote one way, it's 100%, but doesn't mean very much), but brings the question of units into the picture (if I count people in thousands, rather than in persons, I'd get a very different result).",,['statistics']
27,Find the probability that the hand contain at least two cards of the same rank.,Find the probability that the hand contain at least two cards of the same rank.,,"5 cards are randomly selected (without replacement) from a standard deck of 52 playing cards (13 ranks: 2, 3, 4, ..., 10, J, Q, K, A, and 4 suits: S, H, D, C). Find the probability that the hand contain at least two cards of the same rank (e.g. {2, 2, 6, A, Q}, {J, J, K, 4, J}, {8, 8, A, A, 6}, ...). I know that I can use $$1 - \frac{\binom{13}{5}\binom{4}{1}^5}{\binom{52}{5}}$$ Is there any other way to do this if I don't want to use $1 -$ (something).","5 cards are randomly selected (without replacement) from a standard deck of 52 playing cards (13 ranks: 2, 3, 4, ..., 10, J, Q, K, A, and 4 suits: S, H, D, C). Find the probability that the hand contain at least two cards of the same rank (e.g. {2, 2, 6, A, Q}, {J, J, K, 4, J}, {8, 8, A, A, 6}, ...). I know that I can use $$1 - \frac{\binom{13}{5}\binom{4}{1}^5}{\binom{52}{5}}$$ Is there any other way to do this if I don't want to use $1 -$ (something).",,"['probability', 'statistics', 'poker']"
28,How many ways can a group of friends order food?,How many ways can a group of friends order food?,,"If $10$ people have dinner together, how many   different ways can three(people) order chicken, four order steak and   three orders lobster? So for this question would this be a permutation with similar objects or a partition with different items. If so I know one uses the formula. $$\frac{n!}{n_{1}!n_{2}!n_{k}} = \frac{10!}{3!*4!*3!} =4200 \text{ ways }$$ Would this be the correct answer?","If $10$ people have dinner together, how many   different ways can three(people) order chicken, four order steak and   three orders lobster? So for this question would this be a permutation with similar objects or a partition with different items. If so I know one uses the formula. $$\frac{n!}{n_{1}!n_{2}!n_{k}} = \frac{10!}{3!*4!*3!} =4200 \text{ ways }$$ Would this be the correct answer?",,"['probability', 'statistics', 'permutations']"
29,Best strategy for minimizing cost of coin-flipping game,Best strategy for minimizing cost of coin-flipping game,,"The Problem You are required to flip your own coin $n$ times, and count $h$ the number of times it comes up heads, with a target head count of $t$, where $t$ is an integer $ \le \frac{n}{2}$.  If $h$ undershoots the target number, then you are penalized $t - h$ points.  If you overshoot, you are penalized $k(h - t)$ points where $k$ is a real $ \ge 1$.  You get to choose the exact probability your coin comes up heads, $p$.  What is the optimal $p$ to choose to minimize your expected cost for a given $n$, $t$, and $k$? What I've figured out When $k=1$ the obvious strategy is to choose $p = \frac{t}{n}$.  When $t$ is very small and $k$ is very large, I think the best strategy might be to choose $p=0$ and accept the fixed cost of $t$. Generally, though, there will be some $p = \frac{t}{n} - \epsilon$ that minimizes expected cost. The probability of flipping $i$ heads is $\dfrac{\binom{n}{i}}{2^n}p^i(1-p)^{n-i}$, so the exact expected cost of any $p$ can be calculated as $$\sum_{i=0}^{t-1} \left((t-i)\dfrac{\binom{n}{i}}{2^n}p^i(1-p)^{n-i}\right) + k\sum_{i=t+1}^{n} \left((i-t)\frac{\binom{n}{i}}{2^n}p^i(1-p)^{n-i}\right)$$ which is impractical to calculate for large n and doesn't give me a reasonable intuition for a closed form answer for $p$. My intuition is that you just need to choose p so that $k$(probability of undershoot)(expected magnitude of undershoot) = (probability of overshoot)(expected magnitude of overshoot), but I don't have the chops to prove that.","The Problem You are required to flip your own coin $n$ times, and count $h$ the number of times it comes up heads, with a target head count of $t$, where $t$ is an integer $ \le \frac{n}{2}$.  If $h$ undershoots the target number, then you are penalized $t - h$ points.  If you overshoot, you are penalized $k(h - t)$ points where $k$ is a real $ \ge 1$.  You get to choose the exact probability your coin comes up heads, $p$.  What is the optimal $p$ to choose to minimize your expected cost for a given $n$, $t$, and $k$? What I've figured out When $k=1$ the obvious strategy is to choose $p = \frac{t}{n}$.  When $t$ is very small and $k$ is very large, I think the best strategy might be to choose $p=0$ and accept the fixed cost of $t$. Generally, though, there will be some $p = \frac{t}{n} - \epsilon$ that minimizes expected cost. The probability of flipping $i$ heads is $\dfrac{\binom{n}{i}}{2^n}p^i(1-p)^{n-i}$, so the exact expected cost of any $p$ can be calculated as $$\sum_{i=0}^{t-1} \left((t-i)\dfrac{\binom{n}{i}}{2^n}p^i(1-p)^{n-i}\right) + k\sum_{i=t+1}^{n} \left((i-t)\frac{\binom{n}{i}}{2^n}p^i(1-p)^{n-i}\right)$$ which is impractical to calculate for large n and doesn't give me a reasonable intuition for a closed form answer for $p$. My intuition is that you just need to choose p so that $k$(probability of undershoot)(expected magnitude of undershoot) = (probability of overshoot)(expected magnitude of overshoot), but I don't have the chops to prove that.",,"['probability', 'statistics', 'optimization']"
30,what am i doing wrong here? calculating standard deviation,what am i doing wrong here? calculating standard deviation,,"I keep getting 2.02 for the standard deviation but the answer is 0.28?   I'm not sure what I'm doing wrong, I even followed a step-by-step way   to calculate it and I'm stilling get it wrong haha :^(","I keep getting 2.02 for the standard deviation but the answer is 0.28?   I'm not sure what I'm doing wrong, I even followed a step-by-step way   to calculate it and I'm stilling get it wrong haha :^(",,['statistics']
31,Assessing a distribution from multiple samples of its mean,Assessing a distribution from multiple samples of its mean,,"I face a random variable whose distribution I don't know. Someone draws a sample of k observations from a population and tells me their average. He repeats the process m times. I assume m is in order of magnitude of hundreds. If 1 < k < 20, What can I tell about the population variance? What about other lower moments? If k=1, I can trivially draw the emplirical distribution. What is the closest analoug for 1 < k < 20?","I face a random variable whose distribution I don't know. Someone draws a sample of k observations from a population and tells me their average. He repeats the process m times. I assume m is in order of magnitude of hundreds. If 1 < k < 20, What can I tell about the population variance? What about other lower moments? If k=1, I can trivially draw the emplirical distribution. What is the closest analoug for 1 < k < 20?",,"['statistics', 'probability-distributions']"
32,Maximum likelihood estimator for translated uniform distribution,Maximum likelihood estimator for translated uniform distribution,,"Let $\theta\gt 0$ and $X_1, ..., X_n$ be independently and identically distributed with probability densitiy function $f_\theta(x) = \frac{1}{2\theta} \chi_{x\in[-\theta,\theta]}$, where $\chi$ is the indicator function.   What is the maximum likelihood estimator for $\theta$? This came up while studying for an exam and I would like some verification on my work: I compute the product likelihood function first: $p_x(\theta)=\Pi_{i=1}^nf_\theta(x_i)=\frac{1}{(2\theta)^n}\Pi_{i=1}^n\chi_{x_i\in[-\theta,\theta]}=\frac{1}{(2\theta)^n}\chi_{\theta\ge \max|x_i|}$. Now in the case of $\max|x_i|=0$ the function has no maximizer. This can be ignored since the case has probability $0$. On the other hand if $\max|x_i|\gt0$ we see that $p$ is strictly decreasing in $\theta$ and therefore $\hat\theta=\max|x_i|$ is the unique maximizer and therefore the wanted estimator.","Let $\theta\gt 0$ and $X_1, ..., X_n$ be independently and identically distributed with probability densitiy function $f_\theta(x) = \frac{1}{2\theta} \chi_{x\in[-\theta,\theta]}$, where $\chi$ is the indicator function.   What is the maximum likelihood estimator for $\theta$? This came up while studying for an exam and I would like some verification on my work: I compute the product likelihood function first: $p_x(\theta)=\Pi_{i=1}^nf_\theta(x_i)=\frac{1}{(2\theta)^n}\Pi_{i=1}^n\chi_{x_i\in[-\theta,\theta]}=\frac{1}{(2\theta)^n}\chi_{\theta\ge \max|x_i|}$. Now in the case of $\max|x_i|=0$ the function has no maximizer. This can be ignored since the case has probability $0$. On the other hand if $\max|x_i|\gt0$ we see that $p$ is strictly decreasing in $\theta$ and therefore $\hat\theta=\max|x_i|$ is the unique maximizer and therefore the wanted estimator.",,"['statistics', 'proof-verification', 'maximum-likelihood']"
33,Should principles be proved? [closed],Should principles be proved? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question I was wondering if one needed to prove principles. E.g., likelihood or condionality principles in Stats. Thank you!","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question I was wondering if one needed to prove principles. E.g., likelihood or condionality principles in Stats. Thank you!",,['statistics']
34,l1 regularization mathematical explanation,l1 regularization mathematical explanation,,"I somewhat understand what l1 regularization is, however, the mathematical formula and how to use it are confusing me. I'm not really sure what a regularization term is and how I could apply it to a data set. All the explanations I have found online are very mathematically dense and I was hoping someone here could provide an intuitive explanation/example. I have only taken intro level Linear Algebra and Statistics courses. EDIT: To clarify, what I'm asking is if there is someone that could explain the problem: Minimize $\|Ax - b\|_2 + \gamma\|x\|_1$. I understand that the first term is the residual and that the second term is the regularization term. However, I'm not sure what the second term does or how to use it. For example, if I had a signal and wanted to reduce the noise, how would I go about selecting a $\gamma$ value? I know this is really vague, I just can't find any examples online.","I somewhat understand what l1 regularization is, however, the mathematical formula and how to use it are confusing me. I'm not really sure what a regularization term is and how I could apply it to a data set. All the explanations I have found online are very mathematically dense and I was hoping someone here could provide an intuitive explanation/example. I have only taken intro level Linear Algebra and Statistics courses. EDIT: To clarify, what I'm asking is if there is someone that could explain the problem: Minimize $\|Ax - b\|_2 + \gamma\|x\|_1$. I understand that the first term is the residual and that the second term is the regularization term. However, I'm not sure what the second term does or how to use it. For example, if I had a signal and wanted to reduce the noise, how would I go about selecting a $\gamma$ value? I know this is really vague, I just can't find any examples online.",,"['statistics', 'signal-processing']"
35,Finding the ACF of a VAR(1) model,Finding the ACF of a VAR(1) model,,"I want to know the first order autocorrelation of a VAR(1) model. That can be calculated as follows $\rho(1)=\frac{\gamma(1)}{\gamma(0)}$ where $\gamma(1)$ denotes the covariance and $\gamma(0)$ denotes the variance. A VAR(1) model can be described as follows: $$r_t=c+\Gamma r_{t-1}+\varepsilon_t$$ with $\varepsilon_t \sim N(0,\Sigma)$. Furthermore, $r_t$, $r_{t-1}$ and $\varepsilon_t$ all are a $N\times 1$ vector and the parameter matrix $\Gamma$ is a $N\times N$ matrix. Taking the variance of $r_t$ gives us $\gamma(0) = Var(r_t) = Var(c+\Gamma r_{t-1}+\varepsilon_t)=\Gamma\times Var(r_{t-1})\times \Gamma' + \Sigma$. So this gives us $\gamma(0) = \Gamma\times \gamma(0)\times \Gamma' + \Sigma$. For $\gamma(1)$ I get $\gamma(1)=cov(r_t,r_{t-1})=cov(c+\Gamma r_{t-1}+\varepsilon_t,r_{t-1})=\Gamma cov(r_{t-1},r_{t-1})=\Gamma \gamma(0)$. I just do not know how to implement the last part, i.e. $\rho(1)=\frac{\gamma(1)}{\gamma(0)}$, because of the matrices. I hope someone can help me with that? I do know that the $\rho(1)$ of an AR(1) model is simply $\phi$ (i.e. the parameter of the lagged variable in an AR(1) model, see Finding the ACF of AR(1) process for instance). For its multivariate case, I also want to know the autocorrelation coefficient, hence this question.","I want to know the first order autocorrelation of a VAR(1) model. That can be calculated as follows $\rho(1)=\frac{\gamma(1)}{\gamma(0)}$ where $\gamma(1)$ denotes the covariance and $\gamma(0)$ denotes the variance. A VAR(1) model can be described as follows: $$r_t=c+\Gamma r_{t-1}+\varepsilon_t$$ with $\varepsilon_t \sim N(0,\Sigma)$. Furthermore, $r_t$, $r_{t-1}$ and $\varepsilon_t$ all are a $N\times 1$ vector and the parameter matrix $\Gamma$ is a $N\times N$ matrix. Taking the variance of $r_t$ gives us $\gamma(0) = Var(r_t) = Var(c+\Gamma r_{t-1}+\varepsilon_t)=\Gamma\times Var(r_{t-1})\times \Gamma' + \Sigma$. So this gives us $\gamma(0) = \Gamma\times \gamma(0)\times \Gamma' + \Sigma$. For $\gamma(1)$ I get $\gamma(1)=cov(r_t,r_{t-1})=cov(c+\Gamma r_{t-1}+\varepsilon_t,r_{t-1})=\Gamma cov(r_{t-1},r_{t-1})=\Gamma \gamma(0)$. I just do not know how to implement the last part, i.e. $\rho(1)=\frac{\gamma(1)}{\gamma(0)}$, because of the matrices. I hope someone can help me with that? I do know that the $\rho(1)$ of an AR(1) model is simply $\phi$ (i.e. the parameter of the lagged variable in an AR(1) model, see Finding the ACF of AR(1) process for instance). For its multivariate case, I also want to know the autocorrelation coefficient, hence this question.",,"['probability', 'statistics', 'time-series', 'vector-auto-regression']"
36,"For $X_1,X_2, \cdots,X_n$ ~ Poisson($\lambda$), find UMVU estimator for $\lambda^k$ ($k=1,2$,...)","For  ~ Poisson(), find UMVU estimator for  (,...)","X_1,X_2, \cdots,X_n \lambda \lambda^k k=1,2","I have some questions about this problem as I'm reviewing for a qual. Our TA provided us with a solution, but I don't understand what is going on: So it looks like they are trying to find an estimator $\delta(X)$ so that $E[\delta(X)] = g(\theta)$ ($g(\theta)$ is what we're trying to estimate). So I see they start with writing that out but I'm not sure why they are using $\gamma$ (for $n\lambda$ instead of $\lambda$). Then I'm wondering how they got the equality: $$\sum_{t=0}^\infty \frac{\gamma^t}{t!}\delta(t) = \sum_{t=0}^\infty \frac{\gamma^t}{t!}\gamma^k?$$ It's like they just got rid of the $e^{-\gamma}$. So my two questions are: 1) Why are they using $\gamma = n\lambda$ instead of just $\lambda$? 2) Where did the equality above come from? The rest of the problem makes sense assuming the equality is true!","I have some questions about this problem as I'm reviewing for a qual. Our TA provided us with a solution, but I don't understand what is going on: So it looks like they are trying to find an estimator $\delta(X)$ so that $E[\delta(X)] = g(\theta)$ ($g(\theta)$ is what we're trying to estimate). So I see they start with writing that out but I'm not sure why they are using $\gamma$ (for $n\lambda$ instead of $\lambda$). Then I'm wondering how they got the equality: $$\sum_{t=0}^\infty \frac{\gamma^t}{t!}\delta(t) = \sum_{t=0}^\infty \frac{\gamma^t}{t!}\gamma^k?$$ It's like they just got rid of the $e^{-\gamma}$. So my two questions are: 1) Why are they using $\gamma = n\lambda$ instead of just $\lambda$? 2) Where did the equality above come from? The rest of the problem makes sense assuming the equality is true!",,"['statistics', 'parameter-estimation']"
37,Prove that if $X_2$ has a uniform distribution then $X_1 \oplus_2 X_2$ too,Prove that if  has a uniform distribution then  too,X_2 X_1 \oplus_2 X_2,"Assume we have two independent random variables $X_1$, $X_2$ with values in the set $Z_2 = {0,1}$. Prove that if $X_2$ has a uniform distribution then $X_1 \oplus_2 X_2$ has also the uniform distribution. (Used in ""coin tossing by phone""). I know from a theorem that this is true and that the uniform probability distribution will be $P(y=0)=1/2$ and $P(y=0)=1/2$. But I don't know how to prove it. Any idea? Thanks for your help.","Assume we have two independent random variables $X_1$, $X_2$ with values in the set $Z_2 = {0,1}$. Prove that if $X_2$ has a uniform distribution then $X_1 \oplus_2 X_2$ has also the uniform distribution. (Used in ""coin tossing by phone""). I know from a theorem that this is true and that the uniform probability distribution will be $P(y=0)=1/2$ and $P(y=0)=1/2$. But I don't know how to prove it. Any idea? Thanks for your help.",,"['number-theory', 'statistics', 'cryptography']"
38,Is there an interpretation of the hyper skewness?,Is there an interpretation of the hyper skewness?,,"Let $X$ be a random variable. The standardized $n$th moment of $X$ is defined as $$\frac{E[(X-\mathbb{E}[X])^n]}{\mbox{Var}[X]^{n/2}}. $$ Special cases are the skewness ($k=3$) and the kurtosis $k=4$. The skewness is a measure for the asymmetry of a distribution while the kurtosis measures how peaked the distribution is. In my financial engineering project, I have to work with $k=5$ which is referred to as hyper skewness . As a benchmark, it is common to consider the normal distribution which has zero skewness and kurtosis equal to three. However, the hyper skewness of the normal distribution is also equal to zero, so at first sight it does not tell anything more about the distribution. I was wondering if there is a useful interpretation of the hyper skewness? Does someone know any literature about this feature? If there is no any available literature then I can perhaps compute the hyper skewness for a variety of distributions and try to find an interpretation. However, some known literature would spare me some time. Thanks in advance!","Let $X$ be a random variable. The standardized $n$th moment of $X$ is defined as $$\frac{E[(X-\mathbb{E}[X])^n]}{\mbox{Var}[X]^{n/2}}. $$ Special cases are the skewness ($k=3$) and the kurtosis $k=4$. The skewness is a measure for the asymmetry of a distribution while the kurtosis measures how peaked the distribution is. In my financial engineering project, I have to work with $k=5$ which is referred to as hyper skewness . As a benchmark, it is common to consider the normal distribution which has zero skewness and kurtosis equal to three. However, the hyper skewness of the normal distribution is also equal to zero, so at first sight it does not tell anything more about the distribution. I was wondering if there is a useful interpretation of the hyper skewness? Does someone know any literature about this feature? If there is no any available literature then I can perhaps compute the hyper skewness for a variety of distributions and try to find an interpretation. However, some known literature would spare me some time. Thanks in advance!",,"['probability', 'statistics', 'finance']"
39,"Computing the ""Mean Value"" of a Point Sample From an Arbitrary Manifold","Computing the ""Mean Value"" of a Point Sample From an Arbitrary Manifold",,"A friend of mine noticed that taking the ""mean"" of two points on the circle isn't as easy as just computing the arithmetic mean of their arguments: If one point has argument $-3.13$ radians and one point has argument $3.13$, the mean value of the arguments is zero, while it would be more intuitive to have the ""mean"" around (roughly) $3.14$. Of course, zero is also a suitable mean value for good reasons, but $3.14$ feels closer visually, because it minimizes the distances to the sample points. Also, note that means may not be unique, as two antipodal points have two visually appealing candidates for means. Needless to say, this problem can be solved algorithmically, which I have done with an ad-hoc $n\log(n)$ algorithm, but that is out of scope for this post (so I'll pull a Fermat and leave that as an exercise for the ambitious reader). What I wonder is instead how one can go about generalizing this notion of ""taking means"" to points sampled from arbitrary manifolds. By manifolds, I mean Riemannian manifolds specifically, to have a local metric available. If any other type of manifold would work just as well or better, feel free to comment. So what I want is some way to, given a sample of points $\{p_1,\ldots,p_n\}$ on a manifold $M$, compute another point $p \in M$ that minimizes the sum of the deviations between the actual sample and $p$, where the deviations are computed as (oriented?) geodesic distances along M . Or something of the sort, at least, sorry if this is a vague formulation. Intuitively, I can imagine a lot of nonlinear optimization, optimal control theory and possibly calculus of variations coming into play, but I can only speculate at this point. Are there any references out there where I can read up on how to compute these ""means""?","A friend of mine noticed that taking the ""mean"" of two points on the circle isn't as easy as just computing the arithmetic mean of their arguments: If one point has argument $-3.13$ radians and one point has argument $3.13$, the mean value of the arguments is zero, while it would be more intuitive to have the ""mean"" around (roughly) $3.14$. Of course, zero is also a suitable mean value for good reasons, but $3.14$ feels closer visually, because it minimizes the distances to the sample points. Also, note that means may not be unique, as two antipodal points have two visually appealing candidates for means. Needless to say, this problem can be solved algorithmically, which I have done with an ad-hoc $n\log(n)$ algorithm, but that is out of scope for this post (so I'll pull a Fermat and leave that as an exercise for the ambitious reader). What I wonder is instead how one can go about generalizing this notion of ""taking means"" to points sampled from arbitrary manifolds. By manifolds, I mean Riemannian manifolds specifically, to have a local metric available. If any other type of manifold would work just as well or better, feel free to comment. So what I want is some way to, given a sample of points $\{p_1,\ldots,p_n\}$ on a manifold $M$, compute another point $p \in M$ that minimizes the sum of the deviations between the actual sample and $p$, where the deviations are computed as (oriented?) geodesic distances along M . Or something of the sort, at least, sorry if this is a vague formulation. Intuitively, I can imagine a lot of nonlinear optimization, optimal control theory and possibly calculus of variations coming into play, but I can only speculate at this point. Are there any references out there where I can read up on how to compute these ""means""?",,"['statistics', 'soft-question', 'riemannian-geometry', 'calculus-of-variations', 'optimal-control']"
40,"How to calculate Probability of ""Ranking""?","How to calculate Probability of ""Ranking""?",,"I took a course with other 10 students. After the final exam, the professor reported statistical result of scores to us: 1. The range of score: 46~98; 2. The average score: 73.3; 3 The S.D of score: 14.3; I got 81, without any further information, how do I know the probabilities for me to be ranked in the 2nd place or the last 2nd place? If you happen to find the similar question to this on other sites with a reasonable answer, I'd like to know. Or if you can incorporate your own code in whatever language, I'll appreciate your answer very much!","I took a course with other 10 students. After the final exam, the professor reported statistical result of scores to us: 1. The range of score: 46~98; 2. The average score: 73.3; 3 The S.D of score: 14.3; I got 81, without any further information, how do I know the probabilities for me to be ranked in the 2nd place or the last 2nd place? If you happen to find the similar question to this on other sites with a reasonable answer, I'd like to know. Or if you can incorporate your own code in whatever language, I'll appreciate your answer very much!",,"['probability', 'statistics']"
41,co-variance between a sample from normal distribution and the sample mean?,co-variance between a sample from normal distribution and the sample mean?,,"$X_1$ is a sample from a normal distribution with mean$=\mu$ and variance $= 1$. The joint distribution of $X_1$ and the sample mean is bivariate normal. I need to find the conditional distribution of $X_1$ given the sample mean.  To do this I need to calculate the co-variance between $X_1$ and the sample mean.  By doing some simulations I know that that co-variance between $X_1$ and the sample mean is $\frac{1}{n}$, but I'm not sure how to prove it.  How do you prove that the co-variance between $X_1$ and the sample mean is $\frac{1}{n}$?","$X_1$ is a sample from a normal distribution with mean$=\mu$ and variance $= 1$. The joint distribution of $X_1$ and the sample mean is bivariate normal. I need to find the conditional distribution of $X_1$ given the sample mean.  To do this I need to calculate the co-variance between $X_1$ and the sample mean.  By doing some simulations I know that that co-variance between $X_1$ and the sample mean is $\frac{1}{n}$, but I'm not sure how to prove it.  How do you prove that the co-variance between $X_1$ and the sample mean is $\frac{1}{n}$?",,"['probability', 'statistics', 'covariance', 'bivariate-distributions']"
42,Why do we like sticking random variables into their own distributions?,Why do we like sticking random variables into their own distributions?,,"Let $X$ be a random variable taking values in the set $S$. It has some distribution $f(s)$. Often in statistics, we are interested in the real valued random variable $f(X)$. Here are some examples: The value ${\bf E}(\log \frac{1}{f(X)})$ is called entropy and is very important in information theory. If we have a family of distributions $f(s,\theta)$ where $\theta \in \Theta$ is a parameter, then ${\bf E}[(d_{\theta} \log f(X,\theta))^2]$ is called the Fisher information metric which shows up in the Cramer-Rao bound and other places. These examples are enough to convince me that $f(X)$ is extremely fundamental, but without foresight, $f(X)$ seems like a strange object to consider. Is there any way to motivate $f(X)$, where $f$ is the distrubution of $X$ without saying things like ""noisy channel coding theorem"" or ""Cramer-Rao bound""?","Let $X$ be a random variable taking values in the set $S$. It has some distribution $f(s)$. Often in statistics, we are interested in the real valued random variable $f(X)$. Here are some examples: The value ${\bf E}(\log \frac{1}{f(X)})$ is called entropy and is very important in information theory. If we have a family of distributions $f(s,\theta)$ where $\theta \in \Theta$ is a parameter, then ${\bf E}[(d_{\theta} \log f(X,\theta))^2]$ is called the Fisher information metric which shows up in the Cramer-Rao bound and other places. These examples are enough to convince me that $f(X)$ is extremely fundamental, but without foresight, $f(X)$ seems like a strange object to consider. Is there any way to motivate $f(X)$, where $f$ is the distrubution of $X$ without saying things like ""noisy channel coding theorem"" or ""Cramer-Rao bound""?",,"['probability', 'statistics', 'information-theory']"
43,Converting Permutations to Combinations: Simple Stats in Practise,Converting Permutations to Combinations: Simple Stats in Practise,,"In a popular text book there is a question that has bothered me that I am sure is very simple for others and I'm just missing something..... So image $100$ songs and we have $10$ as Beatles songs. We want to pick $5$ songs where only the last one we pick is a Beatles song. The probability of that happening expressed as a permutation is ... $\dfrac{ (90 * 89 * 88 * 87) * 10 }{ 100 * 99 * 98 * 97 * 96 } = \dfrac{ P(4,90) * 10 }{ P(5,100) }$. This makes sense to me. But then they translate it to a combination to show us another way of thinking about it. $\dfrac{C(95,9)}{C(100,10)}$ This part is hard for me to grasp. Initially I thought that it describes the chance that $9$ would appear in $90$ if there are $10$ in $100$. That got clarified by a friend of mine when he explained it actually is a sort of logical implication because the last Beatles song will never be in the 95 set so the probability of $9$ in $95$ should somewhat match the probability of $1$ in the last $5$. So here is my REAL question... How is it that the combination also expresses the last song being the beatles song as opposed to it being one of the first four. If there is any clarification that is needed please let me know!! I would really love to answer this question. I'm doing this out of deep interest for the game of Mathematics.","In a popular text book there is a question that has bothered me that I am sure is very simple for others and I'm just missing something..... So image $100$ songs and we have $10$ as Beatles songs. We want to pick $5$ songs where only the last one we pick is a Beatles song. The probability of that happening expressed as a permutation is ... $\dfrac{ (90 * 89 * 88 * 87) * 10 }{ 100 * 99 * 98 * 97 * 96 } = \dfrac{ P(4,90) * 10 }{ P(5,100) }$. This makes sense to me. But then they translate it to a combination to show us another way of thinking about it. $\dfrac{C(95,9)}{C(100,10)}$ This part is hard for me to grasp. Initially I thought that it describes the chance that $9$ would appear in $90$ if there are $10$ in $100$. That got clarified by a friend of mine when he explained it actually is a sort of logical implication because the last Beatles song will never be in the 95 set so the probability of $9$ in $95$ should somewhat match the probability of $1$ in the last $5$. So here is my REAL question... How is it that the combination also expresses the last song being the beatles song as opposed to it being one of the first four. If there is any clarification that is needed please let me know!! I would really love to answer this question. I'm doing this out of deep interest for the game of Mathematics.",,"['combinatorics', 'statistics', 'permutations']"
44,What is the difference between ANOVA and ANCOVA?,What is the difference between ANOVA and ANCOVA?,,"In the context of using only experiment data for ANOVA analysis, ANCOVA offers post hoc statistical control. Is this a valid conclusion and why?","In the context of using only experiment data for ANOVA analysis, ANCOVA offers post hoc statistical control. Is this a valid conclusion and why?",,"['statistics', 'statistical-inference']"
45,Statistics of the product of two white noise Fourier amplitudes,Statistics of the product of two white noise Fourier amplitudes,,"Consider two sequences of random numbers \begin{align} A &= \{a_0, a_1, \ldots a_N\} \\ B &= \{b_0, b_1, \ldots b_N\} \, . \end{align} where each $a$ and $b$ value is independently drawn from a Gaussian distribution $$G_\sigma(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left[ -\frac{x^2}{2 \sigma^2}\right] \, .$$ Suppose we compute the discrete Fourier transform of each sequence \begin{align} \tilde{A}_k &\equiv \sum_{n=0}^{N-1} a_n \exp\left[-i 2 \pi n k / N \right] \\ \tilde{B}_k &\equiv \sum_{n=0}^{N-1} b_n \exp\left[-i 2 \pi n k / N \right] \, . \end{align} What is the statistical distribution of $$\tilde{C}_k \equiv \tilde{A}_k \tilde{B}_k^* \, ?$$ Attempt Using the fact that the distribution of a sum of random variables is the convolution of the distributions of the things being summed, we can find that $\tilde{A}_k$ is a complex number whose real and imaginary parts are independent and both Gaussian distributed with standard deviation $\sigma \sqrt{2N}$. Then, using the rules for transformation of random variables (and the convolution rule again) we can find that the distribution of the square of the radius $$r^2 \equiv (\text{Re} \tilde{A}_k)^2 + (\text{Im} \tilde{A}_k)^2$$ is $$P_{r^2}(\alpha) = \frac{1}{\sigma^2 N} \exp \left[ -\alpha/\sigma^2 N \right] \qquad (\alpha > 0) \, .$$ Again using transformation rules we find the distribution of the radius $$P_r(r) = \left( \frac{2}{\sigma^2 N} \right) r \exp\left[-r^2 / \sigma^2 N \right] \qquad (r > 0) \, .$$ Note that from this we can compute $\langle r \rangle = \sigma \sqrt{\pi N} / 2$. The statistics of $\tilde{B}_k$ are obviously the same as the statistics of $\tilde{A}_k$. Now we consider $\tilde{C}_k \equiv \tilde{A}_k \tilde{B}_k$. The phase of $\tilde{C}_k$ is the sum of the phases of $\tilde{A}_k$ and $\tilde{B}_k$. As the phases of $\tilde{A}_k$ and $\tilde{B}_k$ are both uniformly distributed over $[0,\pi)$, it's obvious that the phase of $\tilde{C}_k$ is also uniformly distributed over that range. The radius is the interesting part. The radius of the product is the product of the radii. Fortunately, we know that the product of two random variables $Z=XY$ follows the distribution $$P_Z(z) = \int_{-\infty}^\infty P_X(x) P_Y(z/x) \frac{1}{|x|}dx \, .$$ Therefore, the distribution of the radius of $\tilde{C}_k$ is \begin{align} P_{|\tilde{C}_k|}(z) &= \int_{-\infty}^\infty P_r(r) P_r(z/r) \frac{dr}{|r|} \\ &= \int_0^\infty P_r(r) P_r(z/r) \frac{dr}{r} \\ &= \left( \frac{2}{\sigma^2 N} \right)^2 z \int_0^\infty \exp \left[ - \frac{ r^2 + (z/r)^2 }{\sigma^2 N} \right] \frac{dr}{r} \, . \end{align} I have not been able to solve this integral. However, we can find the average value of $|\tilde{C}_k|$: \begin{align} \langle |\tilde{C}_k| \rangle &= \int_0^\infty z P_{|\tilde{C}_k|}(z) \, dz \\ &= \left( \frac{2}{\sigma^2 N}\right)^2 \int_0^\infty \int_0^\infty dz \, dr \, \frac{z^2}{r} \exp \left(-\left(r^2 + (z/r)^2 \right)/(\sigma^2 N) \right) \\ &= \left( \frac{2}{\sigma^2 N}\right)^2 \frac{\sqrt{\pi}}{4} (\sigma^2 N)^{3/2} \int_0^\infty dr \, r^2 \exp \left( -r^2 / \sigma^2 N \right) \\ &= \frac{\pi}{4} \sigma^2 N \, . \end{align} which, interestingly, is exactly the square of $\langle r \rangle$ for either $\tilde{A}_k$ or $\tilde{B}_k$. This is better than nothing, but the full distribution remains to be found.","Consider two sequences of random numbers \begin{align} A &= \{a_0, a_1, \ldots a_N\} \\ B &= \{b_0, b_1, \ldots b_N\} \, . \end{align} where each $a$ and $b$ value is independently drawn from a Gaussian distribution $$G_\sigma(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left[ -\frac{x^2}{2 \sigma^2}\right] \, .$$ Suppose we compute the discrete Fourier transform of each sequence \begin{align} \tilde{A}_k &\equiv \sum_{n=0}^{N-1} a_n \exp\left[-i 2 \pi n k / N \right] \\ \tilde{B}_k &\equiv \sum_{n=0}^{N-1} b_n \exp\left[-i 2 \pi n k / N \right] \, . \end{align} What is the statistical distribution of $$\tilde{C}_k \equiv \tilde{A}_k \tilde{B}_k^* \, ?$$ Attempt Using the fact that the distribution of a sum of random variables is the convolution of the distributions of the things being summed, we can find that $\tilde{A}_k$ is a complex number whose real and imaginary parts are independent and both Gaussian distributed with standard deviation $\sigma \sqrt{2N}$. Then, using the rules for transformation of random variables (and the convolution rule again) we can find that the distribution of the square of the radius $$r^2 \equiv (\text{Re} \tilde{A}_k)^2 + (\text{Im} \tilde{A}_k)^2$$ is $$P_{r^2}(\alpha) = \frac{1}{\sigma^2 N} \exp \left[ -\alpha/\sigma^2 N \right] \qquad (\alpha > 0) \, .$$ Again using transformation rules we find the distribution of the radius $$P_r(r) = \left( \frac{2}{\sigma^2 N} \right) r \exp\left[-r^2 / \sigma^2 N \right] \qquad (r > 0) \, .$$ Note that from this we can compute $\langle r \rangle = \sigma \sqrt{\pi N} / 2$. The statistics of $\tilde{B}_k$ are obviously the same as the statistics of $\tilde{A}_k$. Now we consider $\tilde{C}_k \equiv \tilde{A}_k \tilde{B}_k$. The phase of $\tilde{C}_k$ is the sum of the phases of $\tilde{A}_k$ and $\tilde{B}_k$. As the phases of $\tilde{A}_k$ and $\tilde{B}_k$ are both uniformly distributed over $[0,\pi)$, it's obvious that the phase of $\tilde{C}_k$ is also uniformly distributed over that range. The radius is the interesting part. The radius of the product is the product of the radii. Fortunately, we know that the product of two random variables $Z=XY$ follows the distribution $$P_Z(z) = \int_{-\infty}^\infty P_X(x) P_Y(z/x) \frac{1}{|x|}dx \, .$$ Therefore, the distribution of the radius of $\tilde{C}_k$ is \begin{align} P_{|\tilde{C}_k|}(z) &= \int_{-\infty}^\infty P_r(r) P_r(z/r) \frac{dr}{|r|} \\ &= \int_0^\infty P_r(r) P_r(z/r) \frac{dr}{r} \\ &= \left( \frac{2}{\sigma^2 N} \right)^2 z \int_0^\infty \exp \left[ - \frac{ r^2 + (z/r)^2 }{\sigma^2 N} \right] \frac{dr}{r} \, . \end{align} I have not been able to solve this integral. However, we can find the average value of $|\tilde{C}_k|$: \begin{align} \langle |\tilde{C}_k| \rangle &= \int_0^\infty z P_{|\tilde{C}_k|}(z) \, dz \\ &= \left( \frac{2}{\sigma^2 N}\right)^2 \int_0^\infty \int_0^\infty dz \, dr \, \frac{z^2}{r} \exp \left(-\left(r^2 + (z/r)^2 \right)/(\sigma^2 N) \right) \\ &= \left( \frac{2}{\sigma^2 N}\right)^2 \frac{\sqrt{\pi}}{4} (\sigma^2 N)^{3/2} \int_0^\infty dr \, r^2 \exp \left( -r^2 / \sigma^2 N \right) \\ &= \frac{\pi}{4} \sigma^2 N \, . \end{align} which, interestingly, is exactly the square of $\langle r \rangle$ for either $\tilde{A}_k$ or $\tilde{B}_k$. This is better than nothing, but the full distribution remains to be found.",,"['statistics', 'fourier-analysis', 'noise']"
46,Difference operator: Proof by induction that $\Delta^k (X_t)= k!a_k+\Delta^k (Y_t)$,Difference operator: Proof by induction that,\Delta^k (X_t)= k!a_k+\Delta^k (Y_t),"Hello I am having issues with the following exercise. I have to prove that $$\Delta^k (X_t)= k!a_k+\Delta^k (Y_t)$$ where $X_t = m_t +Y_t=\sum_{j=0}^ka_jt^j+Y_t$ for $t \in \mathbb {Z}$. Note: $\Delta$ is the backward difference operator: $\Delta X_t = X_t - X_{t-1}$,  $\Delta^{j} X_t = \Delta(\Delta^{j-1} X_tX_t)$, $\Delta^{0} X_t = X_t$ etc. Basis step:  I have managed to show this for k=1. Induction step: I assume that it holds  for k and show that it holds for k+1.  However, for some reason I just cannot figure out how to write it up for $k+1$ and show that it also holds. I can show it if I choose $k$ to be a certain number say 2 or 3 etc. but not for $k+1$. What I have so far $$\Delta^{k+1} (X_t)=\Delta(\Delta^{k} (X_t) ) = \Delta \left(k!a_k+\Delta^k (Y_t)\right)$$ where I used the assumption that it holds for k. But how do I continue from here?  What do I do with $k!a_k$ if I multiply with $\Delta$? UPDATE: I also tried the following  $$\Delta^{k+1} (X_t)=\Delta^{k}(\Delta (X_t) ) = \Delta^{k}(X_{t}- X_{t-1} )= \Delta^{k}X_t - \Delta^{k}X_{t-1} = \Delta^{k}\left((m_t + Y_t) - (m_{t-1} + Y_{t-1})\right) = \Delta^{k+1}m_t + \Delta^{k+1}Y_t $$ But what about $$\Delta^{k+1}m_t$$ I order to finish the prove I have to show that $$\Delta^{k+1}m_t= (k+1)!a_{k+1}$$ Again I managed to do this for the basis step and I assume it holds for k. But same problem as before: I cannot figure out how to do it for k+1. Hope some one can help.  I am stuck. Best Husky","Hello I am having issues with the following exercise. I have to prove that $$\Delta^k (X_t)= k!a_k+\Delta^k (Y_t)$$ where $X_t = m_t +Y_t=\sum_{j=0}^ka_jt^j+Y_t$ for $t \in \mathbb {Z}$. Note: $\Delta$ is the backward difference operator: $\Delta X_t = X_t - X_{t-1}$,  $\Delta^{j} X_t = \Delta(\Delta^{j-1} X_tX_t)$, $\Delta^{0} X_t = X_t$ etc. Basis step:  I have managed to show this for k=1. Induction step: I assume that it holds  for k and show that it holds for k+1.  However, for some reason I just cannot figure out how to write it up for $k+1$ and show that it also holds. I can show it if I choose $k$ to be a certain number say 2 or 3 etc. but not for $k+1$. What I have so far $$\Delta^{k+1} (X_t)=\Delta(\Delta^{k} (X_t) ) = \Delta \left(k!a_k+\Delta^k (Y_t)\right)$$ where I used the assumption that it holds for k. But how do I continue from here?  What do I do with $k!a_k$ if I multiply with $\Delta$? UPDATE: I also tried the following  $$\Delta^{k+1} (X_t)=\Delta^{k}(\Delta (X_t) ) = \Delta^{k}(X_{t}- X_{t-1} )= \Delta^{k}X_t - \Delta^{k}X_{t-1} = \Delta^{k}\left((m_t + Y_t) - (m_{t-1} + Y_{t-1})\right) = \Delta^{k+1}m_t + \Delta^{k+1}Y_t $$ But what about $$\Delta^{k+1}m_t$$ I order to finish the prove I have to show that $$\Delta^{k+1}m_t= (k+1)!a_{k+1}$$ Again I managed to do this for the basis step and I assume it holds for k. But same problem as before: I cannot figure out how to do it for k+1. Hope some one can help.  I am stuck. Best Husky",,"['statistics', 'proof-writing', 'induction', 'time-series', 'finite-differences']"
47,Mathematical approach to Poisson Process problem,Mathematical approach to Poisson Process problem,,"We have a poisson process that has an arrival rate of $\lambda$. If the arrival counter doesn't count certain arrivals at random (with a probability $p$), then how do I go about showing that the arrival process is still Poisson and finding the new arrival rate? Intuitively it makes sense because the arrivals are independent and random, but I'm not sure how to mathematically approach the problem.","We have a poisson process that has an arrival rate of $\lambda$. If the arrival counter doesn't count certain arrivals at random (with a probability $p$), then how do I go about showing that the arrival process is still Poisson and finding the new arrival rate? Intuitively it makes sense because the arrivals are independent and random, but I'm not sure how to mathematically approach the problem.",,"['statistics', 'poisson-distribution', 'poissons-equation', 'poisson-process']"
48,Why is Logistic Distribution called logistic?,Why is Logistic Distribution called logistic?,,"What is logistic about Logistic Distribution, in a common sense way? What is the lexical rationale of the name, not just pure math definition?","What is logistic about Logistic Distribution, in a common sense way? What is the lexical rationale of the name, not just pure math definition?",,"['statistics', 'soft-question']"
49,Convergence in probability of different uniform distribution R.V.s,Convergence in probability of different uniform distribution R.V.s,,"A question in my book is as follows: Suppose $X_n$ is uniformly distributed on the set of points $\{1/n, 2/n, \ldots, 1 \}$. Does $X_n \xrightarrow{P} X$, where $X$ is   $\mathcal{U}(0,1)$? The solution the book gives says From the information given, one cannot tell whether $X_n$ converges in   probability to $X$ because the joint distribution of $X_n$ and $X$ has   not been defined. I don't see why this joint distribution is not defined. I know that the joint distribution is required in order to subtract random variables as required in the definition of convergence in probability, yet I don't see why these random variables do not have a joint distribution. Can someone explain this to me?","A question in my book is as follows: Suppose $X_n$ is uniformly distributed on the set of points $\{1/n, 2/n, \ldots, 1 \}$. Does $X_n \xrightarrow{P} X$, where $X$ is   $\mathcal{U}(0,1)$? The solution the book gives says From the information given, one cannot tell whether $X_n$ converges in   probability to $X$ because the joint distribution of $X_n$ and $X$ has   not been defined. I don't see why this joint distribution is not defined. I know that the joint distribution is required in order to subtract random variables as required in the definition of convergence in probability, yet I don't see why these random variables do not have a joint distribution. Can someone explain this to me?",,"['statistics', 'convergence-divergence']"
50,"Is ""non-random parameter estimation"" the same thing as maximum likelihood estimation?","Is ""non-random parameter estimation"" the same thing as maximum likelihood estimation?",,"In one book and a few papers, mostly on navigational tracking, I have found reference to the method of ""non-random parameter estimation"" but this term is not on the Wikipedia and not in a lot of standard texts. It seems to be similar, however, to maximum likelihood estimation which is a standard method found in every tracking and navigation text. Are these two terms referring to the same thing? For example, in ""Estimation with Applications to Tracking and Navigation"" by Bar-Shalom, he writes ""A common method of estimating nonrandom parameters is the maximum likelihood method that maximizes the likelihood function (2.2.2-2). This yields the maximum likelihood estimator (MLE) ...."" So, from this language I am guessing when other authors speak of ""non-random parameter estimation"" they are talking about the MLE. Is that right?","In one book and a few papers, mostly on navigational tracking, I have found reference to the method of ""non-random parameter estimation"" but this term is not on the Wikipedia and not in a lot of standard texts. It seems to be similar, however, to maximum likelihood estimation which is a standard method found in every tracking and navigation text. Are these two terms referring to the same thing? For example, in ""Estimation with Applications to Tracking and Navigation"" by Bar-Shalom, he writes ""A common method of estimating nonrandom parameters is the maximum likelihood method that maximizes the likelihood function (2.2.2-2). This yields the maximum likelihood estimator (MLE) ...."" So, from this language I am guessing when other authors speak of ""non-random parameter estimation"" they are talking about the MLE. Is that right?",,"['statistics', 'estimation', 'parameter-estimation']"
51,"According to Chebyshev's rule, how many observations should lie within one and a half standard deviations of the mean?","According to Chebyshev's rule, how many observations should lie within one and a half standard deviations of the mean?",,"Using the formula : $p = 1 - k^{-2}$ I calculated that $p = 1 - 1.5^{-2} = 0.56$ , which equals to $56\%$. Because I have $24$ data points I go ahead and solve the number of points is $56\%$ of $24$: \begin{equation} \frac{56 * 24}{100} = 13.44 \end{equation} which is approximately 13, which was my final answer. For some reason this is not the final answer therefore my answer 13 is wrong. What did I do wrong?","Using the formula : $p = 1 - k^{-2}$ I calculated that $p = 1 - 1.5^{-2} = 0.56$ , which equals to $56\%$. Because I have $24$ data points I go ahead and solve the number of points is $56\%$ of $24$: \begin{equation} \frac{56 * 24}{100} = 13.44 \end{equation} which is approximately 13, which was my final answer. For some reason this is not the final answer therefore my answer 13 is wrong. What did I do wrong?",,"['statistics', 'statistical-inference', 'standard-deviation', 'descriptive-statistics', 'stationary-processes']"
52,Calculating chance level accuracy,Calculating chance level accuracy,,"I have the following problem from computational neuroscience (presented here if you are interested in the main source): For 126 subjects, the brain activity in 268 regions of the brain is measured (one time series per region). Then a correlation matrix is computed out of this measured time series (i.e. a symmetric 268 * 268 matrix). The same thing is done on two days, so we have 2 such matrices for each subject. Now, we take iteratively one matrix of one particular subject from day 1 (""target matrix""), and compute the correlation between this matrix and all the 126 matrices of day 2. The highest correlation value between the target matrix and the matrices of day 2 is used to identify the matrix from day 2 which belongs to the same subject who's correlation matrix (from day 1) we are using as the ""target matrix"".This process is done 126 times (i.e. at each iteration, another person's day 1 matrix is used as the target matrix). I have the two following questions now: (1) Are these trials (finding the subject from the target matrix also on day 2) dependent from each other? If so, why? (2) How can we calculate chance level accuracy, i.e. if it would be pure guessing to pick out the correct matrix from day 2, what number of correct guesses can we expect? Is there any way to determine that? Thanks","I have the following problem from computational neuroscience (presented here if you are interested in the main source): For 126 subjects, the brain activity in 268 regions of the brain is measured (one time series per region). Then a correlation matrix is computed out of this measured time series (i.e. a symmetric 268 * 268 matrix). The same thing is done on two days, so we have 2 such matrices for each subject. Now, we take iteratively one matrix of one particular subject from day 1 (""target matrix""), and compute the correlation between this matrix and all the 126 matrices of day 2. The highest correlation value between the target matrix and the matrices of day 2 is used to identify the matrix from day 2 which belongs to the same subject who's correlation matrix (from day 1) we are using as the ""target matrix"".This process is done 126 times (i.e. at each iteration, another person's day 1 matrix is used as the target matrix). I have the two following questions now: (1) Are these trials (finding the subject from the target matrix also on day 2) dependent from each other? If so, why? (2) How can we calculate chance level accuracy, i.e. if it would be pure guessing to pick out the correct matrix from day 2, what number of correct guesses can we expect? Is there any way to determine that? Thanks",,"['matrices', 'statistics']"
53,"If 300 contestants line up to play this game, what is the > approximate probability that at least 150 of them win?","If 300 contestants line up to play this game, what is the > approximate probability that at least 150 of them win?",,"Problem: On a game show contestants play a game by putting mini-golf balls from   a five yard distance. Every contestant gets three chances to make a   put. Assume that every contestant has an equal chance of 0.2 of   sinking a ball. The game is won, if at least one of the three balls   can be sunk. (a) What is the probability that a contestant wins this game? Which distribution are you using and what are the parameters? (b) How many contestants do you expect to see on average until the third one wins? Which distribution are you using and what are the parameters? I have a X-Bin(3,0.2) then, P(win the game)=3C1 *0.2 (1-0.2)^2 + 3c2 * 0.2 * (1-0.2)^1 +3c2 * 0.2 ($$)^0=0.488 Point b): NB(3, 0.488) then E(y)=3/0.488=6.25 I need help with this this point: (c) If 300 contestants line up to play this game, what is the   approximate probability that at least 150 of them win? I need to use normal? How? the book said the answer is 0.360","Problem: On a game show contestants play a game by putting mini-golf balls from   a five yard distance. Every contestant gets three chances to make a   put. Assume that every contestant has an equal chance of 0.2 of   sinking a ball. The game is won, if at least one of the three balls   can be sunk. (a) What is the probability that a contestant wins this game? Which distribution are you using and what are the parameters? (b) How many contestants do you expect to see on average until the third one wins? Which distribution are you using and what are the parameters? I have a X-Bin(3,0.2) then, P(win the game)=3C1 *0.2 (1-0.2)^2 + 3c2 * 0.2 * (1-0.2)^1 +3c2 * 0.2 ($$)^0=0.488 Point b): NB(3, 0.488) then E(y)=3/0.488=6.25 I need help with this this point: (c) If 300 contestants line up to play this game, what is the   approximate probability that at least 150 of them win? I need to use normal? How? the book said the answer is 0.360",,"['probability', 'statistics']"
54,Showing a statistic is not complete,Showing a statistic is not complete,,"Show that the order statistics from an i.i.d sample from the family of   all symmetric distributions on the line with known center of symmetry   are not complete. So without loss of generality, I can assume that the center of symmetry is along the origin by just reshifting the distribution. So let $f_\theta(x)$ be a distribution with symmetry along $x=0$. Let $X_1, \cdots, X_n$ be an i.i.d sample from $f_\theta$ and $X_{(1)}, \cdots, X_{(n)}$ be the order statistics I need to show that there exists some nonzero $\delta(X_{(1)}, \cdots, X_{(n)})$ so that $E_\theta\left[\delta(X_{(1)}, \cdots, X_{(n)}) \right] = 0$ But I'm unsure how to proceed. I would imagine that when integrating $\delta$ over a symmetric distribution, I should be able to exploit the symmetry to have $\delta \neq 0$ but the integral will be.","Show that the order statistics from an i.i.d sample from the family of   all symmetric distributions on the line with known center of symmetry   are not complete. So without loss of generality, I can assume that the center of symmetry is along the origin by just reshifting the distribution. So let $f_\theta(x)$ be a distribution with symmetry along $x=0$. Let $X_1, \cdots, X_n$ be an i.i.d sample from $f_\theta$ and $X_{(1)}, \cdots, X_{(n)}$ be the order statistics I need to show that there exists some nonzero $\delta(X_{(1)}, \cdots, X_{(n)})$ so that $E_\theta\left[\delta(X_{(1)}, \cdots, X_{(n)}) \right] = 0$ But I'm unsure how to proceed. I would imagine that when integrating $\delta$ over a symmetric distribution, I should be able to exploit the symmetry to have $\delta \neq 0$ but the integral will be.",,"['statistics', 'probability-distributions', 'order-statistics']"
55,"Probability that two independent samples, each one without repetition, share K elements","Probability that two independent samples, each one without repetition, share K elements",,"Consider the following experiment: Population of size $N$. Two independent samples, each one without replacements . Samples have different number of trials, let's say $n_1$ and $n_2$. What's the probability that these samples share exactly $K$ elements? Please note that I say ""share"" in any order, not ""match"".","Consider the following experiment: Population of size $N$. Two independent samples, each one without replacements . Samples have different number of trials, let's say $n_1$ and $n_2$. What's the probability that these samples share exactly $K$ elements? Please note that I say ""share"" in any order, not ""match"".",,"['probability', 'combinatorics', 'statistics']"
56,Sign table in $2^k$ factorial experiment,Sign table in  factorial experiment,2^k,"I have a factorial experiment with four factors $\{A,B,C,D\}$ ($k=4$) , just to ilustrate the case with $k=3$, the signal table is \begin{matrix} & I & A & B & C & AB & AC & BC & ABC\\ (1) & +1 & -1 & -1 & -1 & +1 & +1 & +1 & -1\\ a & +1 & +1 & -1 & -1 & -1 & -1 & +1 & +1\\ b & +1 & -1 & +1 & -1 & -1 & +1 & -1 & +1\\ ab & +1 & +1 & +1 & -1 & +1 & -1 & -1 & -1\\ c & +1 & -1 & -1 & +1 & +1 & -1 & -1 & +1\\ ac & +1 & +1 & -1 & +1 & -1 & +1 & -1 & -1\\ bc & +1 & -1 & +1 & +1 & -1 & -1 & +1 & -1\\ abc & +1 & +1 & +1 & +1 & +1 & +1 & +1 & +1\\ \end{matrix} I know this is just a signal table with produtcts of $+ $and $-$, but is there any quick way to assemble it without having to look at the signs? I would like to know it, because with the table is easier and faster to calculate the contrasts, otherwise I would have to do $$A=(a-1)(b+1)(c+1)(d+1)$$ $$B=(a+1)(b-1)(c+1)(d+1)$$ $$.....$$ $$ABCD=(a-1)(b-1)(c-1)(d-1)$$ Is there any easier way to assemble this table? As I need to make the table a hand to study for the exam, I was looking at it and I saw a few things about the contrasts $(A,B,C,D)$: $+1$ in which the letter appears $(AB,AC,BC,AD,BD,CD)$: $+1$ in $(1)$, in the rows where the pair appears and in the rows where one or two of the letters does not belong to the pair appears $(ABC,ABD,ACD,BCD)$:$+1$ in rows which appears each letter of triple alone, row in which the triple appears and rows where the letter does not belong to triple appears (only in pairs) $ABCD$: $+1$ in all pairs and $ABCD$","I have a factorial experiment with four factors $\{A,B,C,D\}$ ($k=4$) , just to ilustrate the case with $k=3$, the signal table is \begin{matrix} & I & A & B & C & AB & AC & BC & ABC\\ (1) & +1 & -1 & -1 & -1 & +1 & +1 & +1 & -1\\ a & +1 & +1 & -1 & -1 & -1 & -1 & +1 & +1\\ b & +1 & -1 & +1 & -1 & -1 & +1 & -1 & +1\\ ab & +1 & +1 & +1 & -1 & +1 & -1 & -1 & -1\\ c & +1 & -1 & -1 & +1 & +1 & -1 & -1 & +1\\ ac & +1 & +1 & -1 & +1 & -1 & +1 & -1 & -1\\ bc & +1 & -1 & +1 & +1 & -1 & -1 & +1 & -1\\ abc & +1 & +1 & +1 & +1 & +1 & +1 & +1 & +1\\ \end{matrix} I know this is just a signal table with produtcts of $+ $and $-$, but is there any quick way to assemble it without having to look at the signs? I would like to know it, because with the table is easier and faster to calculate the contrasts, otherwise I would have to do $$A=(a-1)(b+1)(c+1)(d+1)$$ $$B=(a+1)(b-1)(c+1)(d+1)$$ $$.....$$ $$ABCD=(a-1)(b-1)(c-1)(d-1)$$ Is there any easier way to assemble this table? As I need to make the table a hand to study for the exam, I was looking at it and I saw a few things about the contrasts $(A,B,C,D)$: $+1$ in which the letter appears $(AB,AC,BC,AD,BD,CD)$: $+1$ in $(1)$, in the rows where the pair appears and in the rows where one or two of the letters does not belong to the pair appears $(ABC,ABD,ACD,BCD)$:$+1$ in rows which appears each letter of triple alone, row in which the triple appears and rows where the letter does not belong to triple appears (only in pairs) $ABCD$: $+1$ in all pairs and $ABCD$",,"['combinatorics', 'statistics']"
57,"$\lim\limits_{A \to \infty} (1 - \frac{c}{A})^{N-1}$, $N \sim \mathrm{Poisson}(\lambda A)$",",",\lim\limits_{A \to \infty} (1 - \frac{c}{A})^{N-1} N \sim \mathrm{Poisson}(\lambda A),"Given $N \sim \mathrm{Poisson}(\lambda A)$, what will be $(1 - \frac{c}{A})^{N-1}$, where $c$ is a constant, when $A \to \infty$? Will it converge into a distribution or a constant? And what is it? Here is a try: From @zhoraster, $N$ is distributed as $P_1 + \dots + P_A$, where $P_k$ are iid $\mathrm{Poisson}(\lambda)$. By the law of large numbers, $\frac{N}{A} \to \lambda$, $n\to\infty$, in probability. $$ (1 - \frac{c}{A})^{N-1}  = \left((1 - \frac{c}{A})^{\frac{A}{c}} \right)^\frac{c(N-1)}{A}  = \exp\left(\frac{c(N-1)}{A} \log\left((1 - \frac{c}{A})^{\frac{A}{c}} \right)\right) $$ Since we have  $\lim_\limits{A \to \infty} (1 - \frac{c}{A})^{\frac{A}{c}} = e^{-1}$ and $\frac{N}{A} \to \lambda$ as $A \to \infty$. We can obtain $$\lim_{A \to \infty}\frac{c(N-1)}{A} = \lambda c$$ And  $$ \lim_{A \to \infty} \log\left((1 - \frac{c}{A})^{\frac{A}{c}} \right) = -1 $$ Thus,  $$ \lim_{A \to \infty} \left(\frac{c(N-1)}{A} \log\left((1 - \frac{c}{A})^{\frac{A}{c}}\right)\right)  = -\lambda c $$ $$ \lim_{A \to \infty}(1 - \frac{c}{A})^{N-1} = e^{-\lambda c} $$ However, I am not sure if steps are rigorous enough because $A$ can be any positive real number but not necessary a positive integer. Any correction and suggestion is welcome. Thanks!","Given $N \sim \mathrm{Poisson}(\lambda A)$, what will be $(1 - \frac{c}{A})^{N-1}$, where $c$ is a constant, when $A \to \infty$? Will it converge into a distribution or a constant? And what is it? Here is a try: From @zhoraster, $N$ is distributed as $P_1 + \dots + P_A$, where $P_k$ are iid $\mathrm{Poisson}(\lambda)$. By the law of large numbers, $\frac{N}{A} \to \lambda$, $n\to\infty$, in probability. $$ (1 - \frac{c}{A})^{N-1}  = \left((1 - \frac{c}{A})^{\frac{A}{c}} \right)^\frac{c(N-1)}{A}  = \exp\left(\frac{c(N-1)}{A} \log\left((1 - \frac{c}{A})^{\frac{A}{c}} \right)\right) $$ Since we have  $\lim_\limits{A \to \infty} (1 - \frac{c}{A})^{\frac{A}{c}} = e^{-1}$ and $\frac{N}{A} \to \lambda$ as $A \to \infty$. We can obtain $$\lim_{A \to \infty}\frac{c(N-1)}{A} = \lambda c$$ And  $$ \lim_{A \to \infty} \log\left((1 - \frac{c}{A})^{\frac{A}{c}} \right) = -1 $$ Thus,  $$ \lim_{A \to \infty} \left(\frac{c(N-1)}{A} \log\left((1 - \frac{c}{A})^{\frac{A}{c}}\right)\right)  = -\lambda c $$ $$ \lim_{A \to \infty}(1 - \frac{c}{A})^{N-1} = e^{-\lambda c} $$ However, I am not sure if steps are rigorous enough because $A$ can be any positive real number but not necessary a positive integer. Any correction and suggestion is welcome. Thanks!",,"['probability', 'statistics', 'self-learning', 'poisson-distribution']"
58,Is the p-value the probability that your null hypothesis is true?,Is the p-value the probability that your null hypothesis is true?,,"I know that the p-value is the probability that the measurement takes a value that is at least as unlikely under the null hypothesis as the observed value. Furthermore, the null hypothesis is rejected if and only if the p-value of the observation is smaller than the signification level. My question is: Is the p-value then the probability that your null hypothesis is true? Why (not)? Edit: I do not think it is, but I can not properly explain why.","I know that the p-value is the probability that the measurement takes a value that is at least as unlikely under the null hypothesis as the observed value. Furthermore, the null hypothesis is rejected if and only if the p-value of the observation is smaller than the signification level. My question is: Is the p-value then the probability that your null hypothesis is true? Why (not)? Edit: I do not think it is, but I can not properly explain why.",,[]
59,"Gambler's Ruin variant: each bet is for 1/k dollars, what happens to probability of winning as k approaches infinity?","Gambler's Ruin variant: each bet is for 1/k dollars, what happens to probability of winning as k approaches infinity?",,"I am trying to a solve a variant on the Gambler's Ruin problem, in which two gamblers $A$ and $B$ make a series of bets until one of the gamblers goes bankrupt. $A$ starts out with $i$ dollars, B with $N-i$ dollars. The probability of A winning a bet is given by $p$, with $0 < p < 1$. Each bet is for $\frac{1}{k}$ dollars, with $k$ a positive integer. The problem asks us to find the probability that $A$ wins the game, and to determine what happens to this as $k \rightarrow \infty$. I know that the probability of $A$ winning in the normal gambler's ruin problem (i.e. when $k=1$) if $A$ starts out with $i$ dollars is $\frac{1-(\frac{q}{p})^i}{1-(\frac{q}{p})^n}$. My intuition is that the probability that $A$ wins the game approaches $0$ as $k \rightarrow \infty$ in this particular problem, but I am unsure of how to show this algebraically.","I am trying to a solve a variant on the Gambler's Ruin problem, in which two gamblers $A$ and $B$ make a series of bets until one of the gamblers goes bankrupt. $A$ starts out with $i$ dollars, B with $N-i$ dollars. The probability of A winning a bet is given by $p$, with $0 < p < 1$. Each bet is for $\frac{1}{k}$ dollars, with $k$ a positive integer. The problem asks us to find the probability that $A$ wins the game, and to determine what happens to this as $k \rightarrow \infty$. I know that the probability of $A$ winning in the normal gambler's ruin problem (i.e. when $k=1$) if $A$ starts out with $i$ dollars is $\frac{1-(\frac{q}{p})^i}{1-(\frac{q}{p})^n}$. My intuition is that the probability that $A$ wins the game approaches $0$ as $k \rightarrow \infty$ in this particular problem, but I am unsure of how to show this algebraically.",,"['probability', 'statistics', 'gambling']"
60,Finite Population Correction on sample size,Finite Population Correction on sample size,,"Estimate of percent of an infected species is accurate to within $\pm 0.04%$ with $95\%$ CI Between $15\%$ and $35\%$ of the population are infected Size of the population is between $1100$ and $2300$ Calculate the sample size. My calculations: For $15\%$ , $n = 306$ For $35\%$, $n = 546$ Since population is between $1100$ and $2300$ , finite population correction is required. How can I determine the sample size adjusted by finite population correction? Do I have to take the weighted average of the smaller and greater $n$?  Or should I simply use the larger $n$?","Estimate of percent of an infected species is accurate to within $\pm 0.04%$ with $95\%$ CI Between $15\%$ and $35\%$ of the population are infected Size of the population is between $1100$ and $2300$ Calculate the sample size. My calculations: For $15\%$ , $n = 306$ For $35\%$, $n = 546$ Since population is between $1100$ and $2300$ , finite population correction is required. How can I determine the sample size adjusted by finite population correction? Do I have to take the weighted average of the smaller and greater $n$?  Or should I simply use the larger $n$?",,['statistics']
61,Probability of $7$ tails in a row twice in $100$ coin flips,Probability of  tails in a row twice in  coin flips,7 100,"The starting point for my problem was the chance of having a $7$ tails in a row if you flip a coin $100$ times. I found this excellent explanation of calculating it: http://www.leancrew.com/all-this/2009/06/stochasticity/ My question: What is the chance of having (at least) $7$ tails occurring (at least) two times in a $100$ coin flip sequence? In general: $s$ is a sequence of length $n$ and $r$ is the number of repetitions, what are the odds that I found at least $r$ repetition of sequence $s$ in a sequence $S$ that has a length of $N$.","The starting point for my problem was the chance of having a $7$ tails in a row if you flip a coin $100$ times. I found this excellent explanation of calculating it: http://www.leancrew.com/all-this/2009/06/stochasticity/ My question: What is the chance of having (at least) $7$ tails occurring (at least) two times in a $100$ coin flip sequence? In general: $s$ is a sequence of length $n$ and $r$ is the number of repetitions, what are the odds that I found at least $r$ repetition of sequence $s$ in a sequence $S$ that has a length of $N$.",,"['probability', 'statistics']"
62,How can the variance of data be represented as this product of the principal direction and the covariance matrix?,How can the variance of data be represented as this product of the principal direction and the covariance matrix?,,"I am coming from reading the selected answer to this question . I have a question about the following bit: It’s not hard to show that if the covariance matrix of the original data points $x_i$ was $\Sigma$ , the variance of the new data points is just $u^T \Sigma u$ . I have been playing around with projecting two dimensional data for random variables $(x_1,x_2)$ onto the horizontal axis corresponding to $x_1$ . As expected, with $u$ being in the direction of the horizontal axis, the result is $u^T \Sigma u = \operatorname{var}[x_1]$ since we are only taking into account $x_1$ . However, when setting $u$ to be in direction of the identity line, the result is $$u^T \Sigma u = \operatorname{var}[x_1] + \operatorname{var}[x_1] + 2\operatorname{cov}[x_1,x_2].$$ I don’t know much about statistics and don’t understand how this represents the variance of the data when projected onto the identity line. Is there a more formal proof for why the quoted bit is true? An intuitive explanation of the result would be appreciated as well. Edit: My question is why $u^T \Sigma u$ is the variance of the new data points as stated in the question linked above.","I am coming from reading the selected answer to this question . I have a question about the following bit: It’s not hard to show that if the covariance matrix of the original data points was , the variance of the new data points is just . I have been playing around with projecting two dimensional data for random variables onto the horizontal axis corresponding to . As expected, with being in the direction of the horizontal axis, the result is since we are only taking into account . However, when setting to be in direction of the identity line, the result is I don’t know much about statistics and don’t understand how this represents the variance of the data when projected onto the identity line. Is there a more formal proof for why the quoted bit is true? An intuitive explanation of the result would be appreciated as well. Edit: My question is why is the variance of the new data points as stated in the question linked above.","x_i \Sigma u^T \Sigma u (x_1,x_2) x_1 u u^T \Sigma u = \operatorname{var}[x_1] x_1 u u^T \Sigma u = \operatorname{var}[x_1] + \operatorname{var}[x_1] + 2\operatorname{cov}[x_1,x_2]. u^T \Sigma u","['matrices', 'statistics', 'eigenvalues-eigenvectors', 'covariance']"
63,Which test should I use for hypothesis testing with a small sample size?,Which test should I use for hypothesis testing with a small sample size?,,"I've run a test with one control and one experiment group, and am questioning myself on whether or not I've used the right test (or if significance can even be calculated on the following sample sizes). The data is as follows: The control cohort (A) had 63 people see the treatment and 1 person performed the action (1.59%) The Experiment cohort (B) had 64 people see the treatment and 9 people performed the action (14.1%) I used a z-test for two population proportions (this equation: http://www.socscistatistics.com/tests/ztest/ ) to compare the two proportions. It says that the number of people who performed the action in B is a statistically significant increase over the number of people who performed the action in A with a p-value of 0.00453. However I wanted to make sure that: a) I'm using the right test -- I know t-tests are sometimes better tests to use when samples sizes are small b) Statistical significance can even be determined on such a small sample Any help or guidance would be great - thanks!","I've run a test with one control and one experiment group, and am questioning myself on whether or not I've used the right test (or if significance can even be calculated on the following sample sizes). The data is as follows: The control cohort (A) had 63 people see the treatment and 1 person performed the action (1.59%) The Experiment cohort (B) had 64 people see the treatment and 9 people performed the action (14.1%) I used a z-test for two population proportions (this equation: http://www.socscistatistics.com/tests/ztest/ ) to compare the two proportions. It says that the number of people who performed the action in B is a statistically significant increase over the number of people who performed the action in A with a p-value of 0.00453. However I wanted to make sure that: a) I'm using the right test -- I know t-tests are sometimes better tests to use when samples sizes are small b) Statistical significance can even be determined on such a small sample Any help or guidance would be great - thanks!",,"['statistics', 'statistical-inference']"
64,Estimating variance of estimator of bernoulli process,Estimating variance of estimator of bernoulli process,,"The maximum likelihood estimate of a Bernoulli process is simply given by $\hat{\theta}=\frac{\sum X_i}{N}$, where N is the total number of bernoulli trial and $X_i$ is the outcome of each trial. This is an unbiased estimator and the variance of this estimator can be easily computed to be $Var(\hat{\theta}) = \frac{\theta(1-\theta)}{N}$. However, the actual $\theta$ is unknown. So how do we estimate the variance of the estimator then ? Also, I would like an unbiased estimate of this variance.  Its possible that this question has already been asked. If someone can give a pointer that would be great. Thanks.","The maximum likelihood estimate of a Bernoulli process is simply given by $\hat{\theta}=\frac{\sum X_i}{N}$, where N is the total number of bernoulli trial and $X_i$ is the outcome of each trial. This is an unbiased estimator and the variance of this estimator can be easily computed to be $Var(\hat{\theta}) = \frac{\theta(1-\theta)}{N}$. However, the actual $\theta$ is unknown. So how do we estimate the variance of the estimator then ? Also, I would like an unbiased estimate of this variance.  Its possible that this question has already been asked. If someone can give a pointer that would be great. Thanks.",,"['statistics', 'statistical-inference', 'parameter-estimation']"
65,How to quantify how much my data resembles a linear relationship?,How to quantify how much my data resembles a linear relationship?,,"I have a bunch of data points in Excel for different test subjects that are each represented by unique colors in the following graph: I wish to quantify in Excel what seems obvious to my eyes, that the orange data set is linear, whereas most of the other datasets appear to be non-linear, perhaps quadratic in form.  It appears that the Coefficient of determination may do what I want, but that seems more like a statistical method, perhaps there is another method better suited to the data shown here that appears more of a quadratic form versus a linear form.  How can I quantify this relationship that seems so obvious to one's eye when viewing the data points?","I have a bunch of data points in Excel for different test subjects that are each represented by unique colors in the following graph: I wish to quantify in Excel what seems obvious to my eyes, that the orange data set is linear, whereas most of the other datasets appear to be non-linear, perhaps quadratic in form.  It appears that the Coefficient of determination may do what I want, but that seems more like a statistical method, perhaps there is another method better suited to the data shown here that appears more of a quadratic form versus a linear form.  How can I quantify this relationship that seems so obvious to one's eye when viewing the data points?",,"['statistics', 'quadratics', 'curves']"
66,Covariance of 1-D random process is $n\times n$!!!!,Covariance of 1-D random process is !!!!,n\times n,"I'm reading a tutorial on stochastic processes. There is an example in the tutorial as follows: General Moving Average random process given as $X[n]=\frac{(U[n]+U[n-1])}{2}$ where $E[U[n]]=\mu$ and $var(U[n]) = {σ^2}_U$ and the   $U[n]$'s are uncorrelated. As you see $X[n]$ is a 1-D random variable Then the example is solved in the following way: $[C_X]_{ij}=E[(X[i]-E[X[i]])(X[j]-E[X[j]])]\qquad i=0,1,\dots,N-1;j=0,1,\dots,N-1.$ $\begin{align} X[n]-E[X[n]]&=\frac{1}{2}(U[n]+U[n-1])-\frac{1}{2}(\mu+\mu)\\ &=\frac{1}{2}[(U[n]-\mu)+(U[n-1]-\mu)]\\ &=\frac{1}{2}[\overline U[n]+\overline U[n-1]] \end{align}$ $\begin{align} [C_X]_{ij}&=\frac{1}{4}E[(\overline U[i]+\overline U[i-1])(\overline U[j]+\overline U[j-1])]\\ &=\frac{1}{4}(E[\overline U[i]\overline U[j]]+E[\overline U[i]\overline U[j-1]]+E[\overline U[i-1]\overline U[j]]+E[\overline U[i-1]\overline U[j-1]])   \end{align}$ $[C_X]_{ij}=\frac{1}{4}(\sigma^2_U\delta[j-i]+\sigma^2_U\delta[j-i-1]+\sigma^2_U\delta[j-i+1]+\sigma^2_U\delta[j-i]).$ $C_X=\begin{bmatrix}\frac{\sigma^2_U}{2}&\frac{\sigma^2_U}{2}&0&0&\dots & 0&0&0\\ \frac{\sigma^2_U}{4}&\frac{\sigma^2_U}{2}&\frac{\sigma^2_U}{4}&0&\dots &0&0&0\\ \vdots &\vdots &\vdots& \vdots&\vdots &\vdots &\vdots& \vdots\\ 0&0&0&0&\cdots &\frac{\sigma^2_U}{4}&\frac{\sigma^2_U}{2}&\frac{\sigma^2_U}{4}\\ 0&0&0&0&\cdots &0&\frac{\sigma^2_U}{4}&\frac{\sigma^2_U}{2}\end{bmatrix}$ So why $C_X$ is $n\times n$ inspite of $X[n]$ being 1-dimensional?","I'm reading a tutorial on stochastic processes. There is an example in the tutorial as follows: General Moving Average random process given as $X[n]=\frac{(U[n]+U[n-1])}{2}$ where $E[U[n]]=\mu$ and $var(U[n]) = {σ^2}_U$ and the   $U[n]$'s are uncorrelated. As you see $X[n]$ is a 1-D random variable Then the example is solved in the following way: $[C_X]_{ij}=E[(X[i]-E[X[i]])(X[j]-E[X[j]])]\qquad i=0,1,\dots,N-1;j=0,1,\dots,N-1.$ $\begin{align} X[n]-E[X[n]]&=\frac{1}{2}(U[n]+U[n-1])-\frac{1}{2}(\mu+\mu)\\ &=\frac{1}{2}[(U[n]-\mu)+(U[n-1]-\mu)]\\ &=\frac{1}{2}[\overline U[n]+\overline U[n-1]] \end{align}$ $\begin{align} [C_X]_{ij}&=\frac{1}{4}E[(\overline U[i]+\overline U[i-1])(\overline U[j]+\overline U[j-1])]\\ &=\frac{1}{4}(E[\overline U[i]\overline U[j]]+E[\overline U[i]\overline U[j-1]]+E[\overline U[i-1]\overline U[j]]+E[\overline U[i-1]\overline U[j-1]])   \end{align}$ $[C_X]_{ij}=\frac{1}{4}(\sigma^2_U\delta[j-i]+\sigma^2_U\delta[j-i-1]+\sigma^2_U\delta[j-i+1]+\sigma^2_U\delta[j-i]).$ $C_X=\begin{bmatrix}\frac{\sigma^2_U}{2}&\frac{\sigma^2_U}{2}&0&0&\dots & 0&0&0\\ \frac{\sigma^2_U}{4}&\frac{\sigma^2_U}{2}&\frac{\sigma^2_U}{4}&0&\dots &0&0&0\\ \vdots &\vdots &\vdots& \vdots&\vdots &\vdots &\vdots& \vdots\\ 0&0&0&0&\cdots &\frac{\sigma^2_U}{4}&\frac{\sigma^2_U}{2}&\frac{\sigma^2_U}{4}\\ 0&0&0&0&\cdots &0&\frac{\sigma^2_U}{4}&\frac{\sigma^2_U}{2}\end{bmatrix}$ So why $C_X$ is $n\times n$ inspite of $X[n]$ being 1-dimensional?",,"['statistics', 'stochastic-processes', 'random-variables', 'correlation', 'covariance']"
67,Show that $Y = \sum_{i=1}^n Y_i$ is distributed as $\chi _{2n}^2$.,Show that  is distributed as .,Y = \sum_{i=1}^n Y_i \chi _{2n}^2,"The Statement of the Problem: Suppose that $X_1,\ldots, X_n$ is a random sample from the $U(0,1)$ distribution and $$ Y_i = -2\log X_i. $$ Show that $Y = \sum_{i=1}^n Y_i$ is distributed as $\chi _{2n}^2$. Where I Am: Ok. So, I've got some dots that I can't seem to connect. Upon consideration of the cdf of $Y_i$... $$P(Y_i < x) = P(-2\log X_i < x) = P(\log X_i > -\frac{1}{2}x) = P(X_i > e^{-x/2}) = 1- P(X_i < e^{-x/2})$$ [EDITED MATERIAL BEGINS HERE] So, we see that $$ P(Y_i < x ) = 1 - P(X_i < e^{-x/2}) = 1 - F_{X_i}(e^{-x/2}) $$ and because $X_i \sim U(0,1)$ $$ 1 - F_{X_i}(e^{-x/2}) = 1 - \frac{e^{-x/2}-0}{1-0} = 1 - e^{-x/2} $$ which is the cdf of a chi-squared r.v. with $2$ degrees of freedom. Therefore $$ Y_i \sim \chi_{2}^2 $$ [EDITED MATERIAL ENDS HERE] Here, I feel like I'm getting close to the special case of the cdf of a chi-squared r.v. in which $k=2$, i.e. $$ F(x;2) = 1-e^{-x/2} \qquad \text{(thanks Wikipedia)}. $$ However, I assume it's not the case that $$ P(X_i > e^{-x/2}) = P(X_i < 1 - e^{-x/2}). \quad (*)$$ Or is that actually true? And, if it is, does that suffice to show that, indeed, $$ X_{i} \sim \chi _{2}^2? $$ I'm aware that $$ X \sim U(0,1) \implies -2\log(X) \sim \chi _{2}^2 \qquad \text{(thanks again Wikipedia)}$$ But, I don't know if this has sufficiently shown that. Finally, I know that the sum of independent chi-squared r.v.'s is also has a chi-squared distribution. From this property, it's clear that I have a sum of $n$ independent chi-squared r.v.'s, each with $2$ degrees of freedom, meaning, of course, that $$ Y \sim \chi _{2n}^2$$ completing the proof. So, yeah, it's just mostly putting this together into a coherent proof without relying too much on properties given by Wikipedia. Any help, of course, would be appreciated. Thanks!","The Statement of the Problem: Suppose that $X_1,\ldots, X_n$ is a random sample from the $U(0,1)$ distribution and $$ Y_i = -2\log X_i. $$ Show that $Y = \sum_{i=1}^n Y_i$ is distributed as $\chi _{2n}^2$. Where I Am: Ok. So, I've got some dots that I can't seem to connect. Upon consideration of the cdf of $Y_i$... $$P(Y_i < x) = P(-2\log X_i < x) = P(\log X_i > -\frac{1}{2}x) = P(X_i > e^{-x/2}) = 1- P(X_i < e^{-x/2})$$ [EDITED MATERIAL BEGINS HERE] So, we see that $$ P(Y_i < x ) = 1 - P(X_i < e^{-x/2}) = 1 - F_{X_i}(e^{-x/2}) $$ and because $X_i \sim U(0,1)$ $$ 1 - F_{X_i}(e^{-x/2}) = 1 - \frac{e^{-x/2}-0}{1-0} = 1 - e^{-x/2} $$ which is the cdf of a chi-squared r.v. with $2$ degrees of freedom. Therefore $$ Y_i \sim \chi_{2}^2 $$ [EDITED MATERIAL ENDS HERE] Here, I feel like I'm getting close to the special case of the cdf of a chi-squared r.v. in which $k=2$, i.e. $$ F(x;2) = 1-e^{-x/2} \qquad \text{(thanks Wikipedia)}. $$ However, I assume it's not the case that $$ P(X_i > e^{-x/2}) = P(X_i < 1 - e^{-x/2}). \quad (*)$$ Or is that actually true? And, if it is, does that suffice to show that, indeed, $$ X_{i} \sim \chi _{2}^2? $$ I'm aware that $$ X \sim U(0,1) \implies -2\log(X) \sim \chi _{2}^2 \qquad \text{(thanks again Wikipedia)}$$ But, I don't know if this has sufficiently shown that. Finally, I know that the sum of independent chi-squared r.v.'s is also has a chi-squared distribution. From this property, it's clear that I have a sum of $n$ independent chi-squared r.v.'s, each with $2$ degrees of freedom, meaning, of course, that $$ Y \sim \chi _{2n}^2$$ completing the proof. So, yeah, it's just mostly putting this together into a coherent proof without relying too much on properties given by Wikipedia. Any help, of course, would be appreciated. Thanks!",,"['probability', 'statistics']"
68,Statistics books with motivation and historical tidbits about the development of the concepts?,Statistics books with motivation and historical tidbits about the development of the concepts?,,"I've seen some questions asking books on statistics. I'm looking something a little different, I'm specifically looking for a book in statistics that teaches the important concepts well and also speaks a little about the motivation of the concepts and the history of their development. I'm looking for something Stillwell-Like.","I've seen some questions asking books on statistics. I'm looking something a little different, I'm specifically looking for a book in statistics that teaches the important concepts well and also speaks a little about the motivation of the concepts and the history of their development. I'm looking for something Stillwell-Like.",,"['statistics', 'reference-request']"
69,What to call & how to compute errors in a very asymmetric sample,What to call & how to compute errors in a very asymmetric sample,,"Consider the following sample $\{1.25,1.5,1.75,2.0,2.25,2.5,2.75,10.\}$. Mean is $\mu=3.$, standard deviation is $\sigma\approx 2.69$. I am wondering how to compute and what to call error bars in the context of this sample. Using the standard error ($\mu \pm \sigma$) will obviously not be very useful as it would comprise the complete sample except for one outlier. Using 1st and 4th quartile $[1.75,2.5]$ describes the sample much better but seems odd to use for plotting error bars as well as the mean is not inside this interval. One could use the mean deviation of all upper (above the mean) and all lower (below the mean) observations, which would give $[2.,10.]$, but there does not seem to be a proper name for this concept (discussed here ). I tend to favor this option but have trouble referring to what is plotted in a convenient way (calling it ""mean deviation"", ""standard deviation"", ""standard errors"", or ""mean errors"" is just plain wrong; calling it ""errors"" or ""upper/lower errors"" seems unspecific and also seems to imply some kind of estimation which is not involved; calling it ""upper/lower deviation"" is unspecific and readers would likely assume it to refer to something like the standard deviation). How are error bars usually computed for such a sample and what are they then usually referred to (other than ""error bars"")?","Consider the following sample $\{1.25,1.5,1.75,2.0,2.25,2.5,2.75,10.\}$. Mean is $\mu=3.$, standard deviation is $\sigma\approx 2.69$. I am wondering how to compute and what to call error bars in the context of this sample. Using the standard error ($\mu \pm \sigma$) will obviously not be very useful as it would comprise the complete sample except for one outlier. Using 1st and 4th quartile $[1.75,2.5]$ describes the sample much better but seems odd to use for plotting error bars as well as the mean is not inside this interval. One could use the mean deviation of all upper (above the mean) and all lower (below the mean) observations, which would give $[2.,10.]$, but there does not seem to be a proper name for this concept (discussed here ). I tend to favor this option but have trouble referring to what is plotted in a convenient way (calling it ""mean deviation"", ""standard deviation"", ""standard errors"", or ""mean errors"" is just plain wrong; calling it ""errors"" or ""upper/lower errors"" seems unspecific and also seems to imply some kind of estimation which is not involved; calling it ""upper/lower deviation"" is unspecific and readers would likely assume it to refer to something like the standard deviation). How are error bars usually computed for such a sample and what are they then usually referred to (other than ""error bars"")?",,"['statistics', 'standard-deviation']"
70,Can any function of the second moment of a random variable be recovered from its quantile function?,Can any function of the second moment of a random variable be recovered from its quantile function?,,"Summary of question It is known that the expected value of a random variable can be obtained from integrating its survival function. This is easily restated in terms of the quantile function as: $$ \int_0^\infty S(x)\;dx = \int_0^1F^{-1}(x) $$ whose equivalence can be seen graphically as integrating over the same area. This is useful, as when dealing with empirical or stochastically generated CDFs, layer loss statistics can be estimated directly off of the empirical quantile/CDF. It would be useful to be able to extract layer loss variance information in a similar way. Is there any similar relationship or method to extract higher moments, limited or unlimited, from the quantile function? Detailed question Background It is a known property that given a random variable $X$ with density $f(x)$, cumulative distribution function (CDF) $F(x)$, survival function $S(x)$, and quantile function $F^{-1}(x)$, there is the following relationship between S(x) and E(X): $$ E(X) = \int_0^\infty xf(x)\;dx = \int_0^\infty S(x)\;dx = \int_0^1F^{-1}(x)\;dx $$ The last form, obtained by solving for the area in terms of y instead of x, is particurlarly convenient when forced to estimate these calculations in tabular formal (like Excel). Somewhat less known is that what we call the ""layer loss cost"" or the amount of the random variable that pierces a threshold but is capped by a limit is also recoverable from the survival function. Let $E(X\wedge A)$ be defined as the limited expected value of $X$ capped at $A$, or: $$ E(X\wedge A) = \int_0^A xf(x)\;dx + A\int_A^\infty f(x)\;dx $$ Given random variable $Y$, the loss in the layer between $A$ and $B$, defined as $\min(B-A, \max(0, X - A))$, or equvalently $\textrm{median}(0, B-A, X-A)$, the following relationship also holds: $$ \begin{align} E(Y) &= E(X\wedge B) - E(X\wedge A)\\ &= \int_A^B (x - A)f(x)\;dx + (B-A) \int_B^\infty f(x)\;dx\\ &= \int_A^B S(x)\;dx \end{align} $$ So it can be said that the CDF/survival function encodes information about the first moment (limited and unlimited) which can be relatively easy to extract. Proof for first moment Both relationships are usually proved by integration by parts, and can be proved generally without recourse to the specific form of the distribution at hand. $$ \begin{align} E(Y) &= \int_A^B (x - A)f(x)\;dx + (B-A) \int_B^\infty f(x)\;dx\\ &= \int_A^Bxf(x)\;dx - A \int_A^Bf(x)\;dx + (B - A)S(B)\\ &= \int_A^Bxf(x)\;dx - A\left[S(A) - S(B)\right] + BS(B) - AS(B)\\ &= \int_A^Bxf(x)\;dx - AS(A) + AS(B) + BS(B) - AS(B) \end{align} $$ Now to focus on the first term. Using the fact that $S(x) = 1 - F(x)$ we have $$ \frac{d}{dx}S(x) = -f(x) $$ So using integration by parts, we can let $u = x, du = 1, dv = f(x), v = -S(x)$ and state generally that: $$ \begin{align} \int_A^B xf(x)\;dx &= -xS(x)\bigg\vert_A^B + \int_A^B S(x) dx\\ &= \int_A^B S(x)\;dx - BS(B) + AS(A) \end{align} $$ Substituting the above in the original question we get $$ \begin{align} E(Y) = \int_A^B S(x)\;dx &- BS(B) + AS(A) \\ &- AS(A) + AS(B) + BS(B) - AS(B) \end{align} $$ All the non-integral terms cancel, leaving us with $E(Y) = \int_A^B S(x)\;dx\;\blacksquare$. Attempt for second moment I am interested in the variance of the random variable $Y$ as defined above. The most starightforward way to approach this would be to calculate $E(Y^2)$ and the subtract $E(Y)^2$ as obtained from the quantile function per above. This could be stated as: $$ E(Y^2) = \int_A^B (x - A)^2 f(x)\;dx + (B-A)^2\int_B^\infty f(x)\;dx $$ Expanding the terms, engaging in some algebraic manipulation and cancellation, and using the result from above for the first moment, we get (if I have not made a mistake): $$ \int_A^B x^2 f(x)\;dx - 2A\overbrace{\int_A^BS(x)\;dx}^{\textrm{Can use } F^{-1}(x)} - A^2S(A) + B^2S(B) $$ At this point I am stuck, since to use integration by parts to handle the first term would require knowing the antiderivative of the general survival function, which I don't know, nor do I know how to convert that into using the quantile function, as could be done for the survival function itself. Specific problem Using the same integration by parts technique on $\int_A^B x^2 f(x)\;dx$, the term $$ \int_A^B x S(x)\;dx $$ arises, and I do not know how to proceed from there. Recap As mentioned in the summary, often I will have an ground-up (0 to infinity) empirical distribution function for a random variable representing a loss severity, and I am interested not only in the expected loss in a layer but the variance of said loss, so being able to extract the second moment from the ECDF/quantile table would be very helpful. Thank you. Updated with Answer For completeness sake, for unlimited moments, just as: $$ E(X) = \int_0^\infty S(x)\;dx $$ the corresponding formula for the second moment is: $$ E(X^2) = 2\int_0^\infty xS(x)\;dx $$ And for layer values $Y$ as defined above, just as $$ E(Y) = \int_A^B S(x)\;dx $$ the second moment of $Y$ can be recovered as: $$ E(Y^2) = 2\int_A^B (x-A)S(x)\;dx $$ Updated with more complete and elegant answer to the general (non-layered) case See this question for a closed form answer for getting the moments of a distribution through integrating its quantile function, as well as the solution to $\int_0^\infty xS(x)dx$.","Summary of question It is known that the expected value of a random variable can be obtained from integrating its survival function. This is easily restated in terms of the quantile function as: $$ \int_0^\infty S(x)\;dx = \int_0^1F^{-1}(x) $$ whose equivalence can be seen graphically as integrating over the same area. This is useful, as when dealing with empirical or stochastically generated CDFs, layer loss statistics can be estimated directly off of the empirical quantile/CDF. It would be useful to be able to extract layer loss variance information in a similar way. Is there any similar relationship or method to extract higher moments, limited or unlimited, from the quantile function? Detailed question Background It is a known property that given a random variable $X$ with density $f(x)$, cumulative distribution function (CDF) $F(x)$, survival function $S(x)$, and quantile function $F^{-1}(x)$, there is the following relationship between S(x) and E(X): $$ E(X) = \int_0^\infty xf(x)\;dx = \int_0^\infty S(x)\;dx = \int_0^1F^{-1}(x)\;dx $$ The last form, obtained by solving for the area in terms of y instead of x, is particurlarly convenient when forced to estimate these calculations in tabular formal (like Excel). Somewhat less known is that what we call the ""layer loss cost"" or the amount of the random variable that pierces a threshold but is capped by a limit is also recoverable from the survival function. Let $E(X\wedge A)$ be defined as the limited expected value of $X$ capped at $A$, or: $$ E(X\wedge A) = \int_0^A xf(x)\;dx + A\int_A^\infty f(x)\;dx $$ Given random variable $Y$, the loss in the layer between $A$ and $B$, defined as $\min(B-A, \max(0, X - A))$, or equvalently $\textrm{median}(0, B-A, X-A)$, the following relationship also holds: $$ \begin{align} E(Y) &= E(X\wedge B) - E(X\wedge A)\\ &= \int_A^B (x - A)f(x)\;dx + (B-A) \int_B^\infty f(x)\;dx\\ &= \int_A^B S(x)\;dx \end{align} $$ So it can be said that the CDF/survival function encodes information about the first moment (limited and unlimited) which can be relatively easy to extract. Proof for first moment Both relationships are usually proved by integration by parts, and can be proved generally without recourse to the specific form of the distribution at hand. $$ \begin{align} E(Y) &= \int_A^B (x - A)f(x)\;dx + (B-A) \int_B^\infty f(x)\;dx\\ &= \int_A^Bxf(x)\;dx - A \int_A^Bf(x)\;dx + (B - A)S(B)\\ &= \int_A^Bxf(x)\;dx - A\left[S(A) - S(B)\right] + BS(B) - AS(B)\\ &= \int_A^Bxf(x)\;dx - AS(A) + AS(B) + BS(B) - AS(B) \end{align} $$ Now to focus on the first term. Using the fact that $S(x) = 1 - F(x)$ we have $$ \frac{d}{dx}S(x) = -f(x) $$ So using integration by parts, we can let $u = x, du = 1, dv = f(x), v = -S(x)$ and state generally that: $$ \begin{align} \int_A^B xf(x)\;dx &= -xS(x)\bigg\vert_A^B + \int_A^B S(x) dx\\ &= \int_A^B S(x)\;dx - BS(B) + AS(A) \end{align} $$ Substituting the above in the original question we get $$ \begin{align} E(Y) = \int_A^B S(x)\;dx &- BS(B) + AS(A) \\ &- AS(A) + AS(B) + BS(B) - AS(B) \end{align} $$ All the non-integral terms cancel, leaving us with $E(Y) = \int_A^B S(x)\;dx\;\blacksquare$. Attempt for second moment I am interested in the variance of the random variable $Y$ as defined above. The most starightforward way to approach this would be to calculate $E(Y^2)$ and the subtract $E(Y)^2$ as obtained from the quantile function per above. This could be stated as: $$ E(Y^2) = \int_A^B (x - A)^2 f(x)\;dx + (B-A)^2\int_B^\infty f(x)\;dx $$ Expanding the terms, engaging in some algebraic manipulation and cancellation, and using the result from above for the first moment, we get (if I have not made a mistake): $$ \int_A^B x^2 f(x)\;dx - 2A\overbrace{\int_A^BS(x)\;dx}^{\textrm{Can use } F^{-1}(x)} - A^2S(A) + B^2S(B) $$ At this point I am stuck, since to use integration by parts to handle the first term would require knowing the antiderivative of the general survival function, which I don't know, nor do I know how to convert that into using the quantile function, as could be done for the survival function itself. Specific problem Using the same integration by parts technique on $\int_A^B x^2 f(x)\;dx$, the term $$ \int_A^B x S(x)\;dx $$ arises, and I do not know how to proceed from there. Recap As mentioned in the summary, often I will have an ground-up (0 to infinity) empirical distribution function for a random variable representing a loss severity, and I am interested not only in the expected loss in a layer but the variance of said loss, so being able to extract the second moment from the ECDF/quantile table would be very helpful. Thank you. Updated with Answer For completeness sake, for unlimited moments, just as: $$ E(X) = \int_0^\infty S(x)\;dx $$ the corresponding formula for the second moment is: $$ E(X^2) = 2\int_0^\infty xS(x)\;dx $$ And for layer values $Y$ as defined above, just as $$ E(Y) = \int_A^B S(x)\;dx $$ the second moment of $Y$ can be recovered as: $$ E(Y^2) = 2\int_A^B (x-A)S(x)\;dx $$ Updated with more complete and elegant answer to the general (non-layered) case See this question for a closed form answer for getting the moments of a distribution through integrating its quantile function, as well as the solution to $\int_0^\infty xS(x)dx$.",,"['probability', 'statistics', 'actuarial-science']"
71,Generalized linear combination of probability density functions,Generalized linear combination of probability density functions,,"I am working with linear non-unity combinations of independent variables in the equation form of: $$Y_i=\sum_{j=1}^N a_{ij} X_j ~~~~\forall~ a_{ij} \in \mathbb{R}, a_{ij}\neq 1$$ I am aware of the convolution solution for the simplified unity case: $$Y=X_1+X_2 \rightarrow f_Y(z)=\int_{-\infty}^{\infty}f_{X_1}(x)f_{X_2}(z-x)dx$$ Since convolution is a linear operation, I could conceivably extend this solution to any number of unity weights. My question is this, how do I handle the non-unity weighting factors? I have some sample plots showing how the solution obviously shifts. I'm using a normal distribution and an f-distribution. Below is the equation example showing the non-unity weighting factor. $$Y=5\cdot f(x,dfn=5,dfd=18)+1\cdot \mathrm{norm}(x,\mu=0,\sigma=0.1)$$ For the record, I don't want a specific case solution (as in, don't solve the above). I am content with sets of integrals and related, since I know that there cannot be a single analytic form. Thanks a lot for the help, and if I missed something on here that deals with the non-unity weights, please let me know. I have found several on unity weights, but those don't seem to help. By the way, this is my first question, LOL. :)","I am working with linear non-unity combinations of independent variables in the equation form of: $$Y_i=\sum_{j=1}^N a_{ij} X_j ~~~~\forall~ a_{ij} \in \mathbb{R}, a_{ij}\neq 1$$ I am aware of the convolution solution for the simplified unity case: $$Y=X_1+X_2 \rightarrow f_Y(z)=\int_{-\infty}^{\infty}f_{X_1}(x)f_{X_2}(z-x)dx$$ Since convolution is a linear operation, I could conceivably extend this solution to any number of unity weights. My question is this, how do I handle the non-unity weighting factors? I have some sample plots showing how the solution obviously shifts. I'm using a normal distribution and an f-distribution. Below is the equation example showing the non-unity weighting factor. $$Y=5\cdot f(x,dfn=5,dfd=18)+1\cdot \mathrm{norm}(x,\mu=0,\sigma=0.1)$$ For the record, I don't want a specific case solution (as in, don't solve the above). I am content with sets of integrals and related, since I know that there cannot be a single analytic form. Thanks a lot for the help, and if I missed something on here that deals with the non-unity weights, please let me know. I have found several on unity weights, but those don't seem to help. By the way, this is my first question, LOL. :)",,"['calculus', 'statistics']"
72,Measuring incoming communication in a Markov Model,Measuring incoming communication in a Markov Model,,"Given a standard Markov Chain on discrete time and finite statespace, represented by a matrix $M$, with $\sum_{j=1}^d m_{ij}=1$. I have a certain absorbing state k, where the incoming communication is very interesting, so i wish to measure that somehow . Calculating $(I-T)^{-1}$ is not possible due to numerical issues. Until now i have just calculated $e_n=\sum_{i=1}^d m^n_{ik}-m^n_{kk}$. Where $m^n_{ij}$ is the i,j entry in $M^n$ for different $n$ values. For example we could have $$M=\left(\begin{array}{c} 0.5 & 0.3 & 0.2 \\0.1 & 0.4 & 0.5  \\ 0 & 0 & 1  \end{array}\right).$$ where we are interested in the communication to state 3. (The real matrix is very large). We would get $e_1=0.2+0.5=0.7.$ My question is: Is there a better way to describe incoming communication to a state, than the column sum? If not, how do i interpret it then? If not, what can you suggest?","Given a standard Markov Chain on discrete time and finite statespace, represented by a matrix $M$, with $\sum_{j=1}^d m_{ij}=1$. I have a certain absorbing state k, where the incoming communication is very interesting, so i wish to measure that somehow . Calculating $(I-T)^{-1}$ is not possible due to numerical issues. Until now i have just calculated $e_n=\sum_{i=1}^d m^n_{ik}-m^n_{kk}$. Where $m^n_{ij}$ is the i,j entry in $M^n$ for different $n$ values. For example we could have $$M=\left(\begin{array}{c} 0.5 & 0.3 & 0.2 \\0.1 & 0.4 & 0.5  \\ 0 & 0 & 1  \end{array}\right).$$ where we are interested in the communication to state 3. (The real matrix is very large). We would get $e_1=0.2+0.5=0.7.$ My question is: Is there a better way to describe incoming communication to a state, than the column sum? If not, how do i interpret it then? If not, what can you suggest?",,"['probability', 'statistics', 'markov-chains']"
73,(Uniformly) Most Powerful test,(Uniformly) Most Powerful test,,"I'm having trouble to find a UMP test after finding a MP test. Consider one observation $X$ from CDF $F_\theta(x) = x^\theta$ where $x \in [0, 1]$ and $\theta > 0$. I found the MP test for testing $H_0: \theta = 1$ against $H_1: \theta = 2$ with significance level $\alpha=0.05$ using the Neyman Pearson lemma: $$\lambda_{\theta_0, \theta_1}(x) = \frac{f_{\theta_0}}{f_{\theta_1}}= \cdots = \frac{1}{2x}$$ Reject $H_0$ if $\lambda_{\theta_0, \theta_1}(x)\leq\frac{1}{c}$, hence if $X\geq \tilde{c}$, where $\tilde{c} = 0.95$. Now I'm asked to find the UMP test for testing $H_0: \theta \in [\frac{1}{2}, 1]$ against $H_1: \theta=2$ for significance level $\alpha = 0.05$. How to proceed?","I'm having trouble to find a UMP test after finding a MP test. Consider one observation $X$ from CDF $F_\theta(x) = x^\theta$ where $x \in [0, 1]$ and $\theta > 0$. I found the MP test for testing $H_0: \theta = 1$ against $H_1: \theta = 2$ with significance level $\alpha=0.05$ using the Neyman Pearson lemma: $$\lambda_{\theta_0, \theta_1}(x) = \frac{f_{\theta_0}}{f_{\theta_1}}= \cdots = \frac{1}{2x}$$ Reject $H_0$ if $\lambda_{\theta_0, \theta_1}(x)\leq\frac{1}{c}$, hence if $X\geq \tilde{c}$, where $\tilde{c} = 0.95$. Now I'm asked to find the UMP test for testing $H_0: \theta \in [\frac{1}{2}, 1]$ against $H_1: \theta=2$ for significance level $\alpha = 0.05$. How to proceed?",,"['statistics', 'statistical-inference', 'hypothesis-testing']"
74,"Evaluating $E[\max(X,Y)]$",Evaluating,"E[\max(X,Y)]","Let X and Y be positive independent random variables, and $$W=\max(X,Y)$$ Define the CDFs of X and Y as $F(x)$ and $G(y)$, respectively. $$\Pr(W\le w)=\Pr(X\le w)\Pr(Y\le w)=F(w)G(w)$$ $$E[W]=\int_0^{\infty}wF(w)g(w)dw+\int_0^{\infty}wf(w)G(w)dw$$ In an earlier post the second answer says that ""if X and Y are independent with uniform distribution on $(0,1)$, then $E[W]=2/3$.""  I am having trouble seeing how this is so.  Please spell it out for me. In particular, I am having trouble seeing how an integral like $$\int_0^{\infty}wF(w)g(w)dw$$ can be evaluated since $F(w)$ is itself an integral.  If $F(w)$ is the normal CDF, for example, it is already intractable.  So it seems to me that integrating something with $F(w)$ in it must be super duper intractable.","Let X and Y be positive independent random variables, and $$W=\max(X,Y)$$ Define the CDFs of X and Y as $F(x)$ and $G(y)$, respectively. $$\Pr(W\le w)=\Pr(X\le w)\Pr(Y\le w)=F(w)G(w)$$ $$E[W]=\int_0^{\infty}wF(w)g(w)dw+\int_0^{\infty}wf(w)G(w)dw$$ In an earlier post the second answer says that ""if X and Y are independent with uniform distribution on $(0,1)$, then $E[W]=2/3$.""  I am having trouble seeing how this is so.  Please spell it out for me. In particular, I am having trouble seeing how an integral like $$\int_0^{\infty}wF(w)g(w)dw$$ can be evaluated since $F(w)$ is itself an integral.  If $F(w)$ is the normal CDF, for example, it is already intractable.  So it seems to me that integrating something with $F(w)$ in it must be super duper intractable.",,"['probability', 'statistics', 'probability-distributions']"
75,why does the squared norm projection of a standard normal follow a chi squared distribution,why does the squared norm projection of a standard normal follow a chi squared distribution,,"Let $Z \sim \mathcal{N} ({\bf 0}, I_d)$ be a $d$-dimensional multivariate normal RV, $n$ be a unit vector where all components are non-zero, then $Z$ projected on to the plane normal to $n$ is $Z - \langle n, Z \rangle n = (I_d - n n^T) Z$. Our lecture notes say that $\| (I_d - n n^T) Z \|^2$ is a chi-squared distribution with $d - 1$ degrees of freedom due to $Z$ being invariant under rotations, but I cannot see why the chi-squared distribution claim follows.","Let $Z \sim \mathcal{N} ({\bf 0}, I_d)$ be a $d$-dimensional multivariate normal RV, $n$ be a unit vector where all components are non-zero, then $Z$ projected on to the plane normal to $n$ is $Z - \langle n, Z \rangle n = (I_d - n n^T) Z$. Our lecture notes say that $\| (I_d - n n^T) Z \|^2$ is a chi-squared distribution with $d - 1$ degrees of freedom due to $Z$ being invariant under rotations, but I cannot see why the chi-squared distribution claim follows.",,"['probability', 'statistics']"
76,Estimate number of songs a radio station has [duplicate],Estimate number of songs a radio station has [duplicate],,"This question already has answers here : Estimate total song ('coupon') number by number of repeats (3 answers) Closed 9 years ago . Imagine the following problem: You listen to a radio station and take notes how often was each song played. How can you estimate based on your notes (e.g. 30 songs played once, 2 played twice, one song three times) how many songs has the radio station available when we assume all the songs are played with a uniform distribution?","This question already has answers here : Estimate total song ('coupon') number by number of repeats (3 answers) Closed 9 years ago . Imagine the following problem: You listen to a radio station and take notes how often was each song played. How can you estimate based on your notes (e.g. 30 songs played once, 2 played twice, one song three times) how many songs has the radio station available when we assume all the songs are played with a uniform distribution?",,"['probability', 'statistics', 'estimation', 'experimental-mathematics']"
77,Confidence Interval for Pareto Distribution,Confidence Interval for Pareto Distribution,,"A random variable is said to have probability density function $$f_X(x)=\frac{\alpha k^\alpha}{x^{\alpha +1}},\quad  \alpha , k>0 \; \text{ and }\; x>k.$$ 1. Compute the MLE estimators $\widehat \alpha $ and $ \widehat k$ for $\alpha$ and k. I figured they are $$\widehat \alpha = \frac{n}{\sum_i \text{ln}\frac{x_i}{\widehat k}} \quad\text{ while } \quad \widehat k=\text{min}_{i} \; x_i$$Correct me if I'm wrong. Derive an 95% confidence interval for $k$. Hint: Consider the distribution of the random variable $k/􏰁\widehat k$. I don't get the point of the hint. Is it to figure out the critical value $(CV)$ to substitute in the expression $$k= \widehat  k\pm CV se(\widehat k) \quad \text{where} \quad se(\widehat k)=\frac{1}{\sqrt{I_n(\widehat k)}}\quad \text{where }\quad I_n{(\widehat k)\; \text{is the Fisher Information at}\; \widehat k.}$$ If so, how do I answer this question.I feel I'll be able to get $I_n(\widehat k)$ but how do i get $CV$. Or what are other alternative methods.","A random variable is said to have probability density function $$f_X(x)=\frac{\alpha k^\alpha}{x^{\alpha +1}},\quad  \alpha , k>0 \; \text{ and }\; x>k.$$ 1. Compute the MLE estimators $\widehat \alpha $ and $ \widehat k$ for $\alpha$ and k. I figured they are $$\widehat \alpha = \frac{n}{\sum_i \text{ln}\frac{x_i}{\widehat k}} \quad\text{ while } \quad \widehat k=\text{min}_{i} \; x_i$$Correct me if I'm wrong. Derive an 95% confidence interval for $k$. Hint: Consider the distribution of the random variable $k/􏰁\widehat k$. I don't get the point of the hint. Is it to figure out the critical value $(CV)$ to substitute in the expression $$k= \widehat  k\pm CV se(\widehat k) \quad \text{where} \quad se(\widehat k)=\frac{1}{\sqrt{I_n(\widehat k)}}\quad \text{where }\quad I_n{(\widehat k)\; \text{is the Fisher Information at}\; \widehat k.}$$ If so, how do I answer this question.I feel I'll be able to get $I_n(\widehat k)$ but how do i get $CV$. Or what are other alternative methods.",,"['statistics', 'probability-distributions', 'statistical-inference', 'parameter-estimation', 'confidence-interval']"
78,Approximate th Probability of a Sum of 16 Independent Uniform R.V.s,Approximate th Probability of a Sum of 16 Independent Uniform R.V.s,,"This question has to do with the Central Limit Theorem, uniform random variables, and cumulative distribution functions, I believe, but I'm not quite sure how to apply them all in the proper way. Q: Approximate the probability that the sum of 16 independent uniform (0, 1) random variables exceeds 10. Sample size = 10 I suppose I want P( Z > 10), where we use a CDF here. In my class I was given an example of this, but in that example we were given the standard deviation (which was divided by the square root of the sample size). However, I'm not sure how to apply it in this case. A google search didn't give me the answer I wanted, so I'm hoping someone here can clarify. TL;DR: How can I apply the central limit theorem here to solve this particular problem?","This question has to do with the Central Limit Theorem, uniform random variables, and cumulative distribution functions, I believe, but I'm not quite sure how to apply them all in the proper way. Q: Approximate the probability that the sum of 16 independent uniform (0, 1) random variables exceeds 10. Sample size = 10 I suppose I want P( Z > 10), where we use a CDF here. In my class I was given an example of this, but in that example we were given the standard deviation (which was divided by the square root of the sample size). However, I'm not sure how to apply it in this case. A google search didn't give me the answer I wanted, so I'm hoping someone here can clarify. TL;DR: How can I apply the central limit theorem here to solve this particular problem?",,"['probability', 'statistics', 'central-limit-theorem']"
79,"What is the maximum value of the sum $\sum_{i=1}^L(\bar{x}-x_i)$, in this specific case.","What is the maximum value of the sum , in this specific case.",\sum_{i=1}^L(\bar{x}-x_i),"Let $x_i$ be a positive real variable, with $i=1,2,...,K$. We denote by $\bar{x}$ the average value of the values $x_1, x_2,...,x_K$. Let $a=\min_i x_i$ and $b=\max_i x_i$, then $x_i \in [a,b]$. My question: what is the maximum value of the sum \begin{equation*} \sum_{i=1}^L (\bar{x}-x_i),  \end{equation*} for $L\le K$.","Let $x_i$ be a positive real variable, with $i=1,2,...,K$. We denote by $\bar{x}$ the average value of the values $x_1, x_2,...,x_K$. Let $a=\min_i x_i$ and $b=\max_i x_i$, then $x_i \in [a,b]$. My question: what is the maximum value of the sum \begin{equation*} \sum_{i=1}^L (\bar{x}-x_i),  \end{equation*} for $L\le K$.",,"['statistics', 'optimization', 'summation', 'average', 'standard-deviation']"
80,Bivariate Probability question,Bivariate Probability question,,"Let $X$ be the time (in minutes) that John spends waiting for a bus on his way home from uni, and let$ Y$ be the time he spends waiting for a train. $X$ and  $  Y$ have joint density function,$$f_{X,Y}(x,y)=0.01e^{-0.1(x+y)}\quad x>0,y>0$$ i) Determine the probability that John has to wait less than half an hour in total. I did $\int_{0}^{30} 0.01e^{-0.1z} dz \approx 0.09 $ ii) Find the expected time that John spends waiting for a bus. Is it $\int_{-\infty}^{\infty}x\; f_{X}(x) dx $ or can I somehow infer this from the exponential distribution. iii) Find $f_{Y}(y)$ . I am pretty confident this is $\int_{-\infty}^{\infty} 0.01e^{-0.1(x+y)} dx $ iv) Find $f_{Y|X} (y|x)$. Is this just the joint density divided by marginal density of X? v) Are X and Y independent? Give reasons. I wanted to know if I'm on the right track as I have no solutions to these problems.","Let $X$ be the time (in minutes) that John spends waiting for a bus on his way home from uni, and let$ Y$ be the time he spends waiting for a train. $X$ and  $  Y$ have joint density function,$$f_{X,Y}(x,y)=0.01e^{-0.1(x+y)}\quad x>0,y>0$$ i) Determine the probability that John has to wait less than half an hour in total. I did $\int_{0}^{30} 0.01e^{-0.1z} dz \approx 0.09 $ ii) Find the expected time that John spends waiting for a bus. Is it $\int_{-\infty}^{\infty}x\; f_{X}(x) dx $ or can I somehow infer this from the exponential distribution. iii) Find $f_{Y}(y)$ . I am pretty confident this is $\int_{-\infty}^{\infty} 0.01e^{-0.1(x+y)} dx $ iv) Find $f_{Y|X} (y|x)$. Is this just the joint density divided by marginal density of X? v) Are X and Y independent? Give reasons. I wanted to know if I'm on the right track as I have no solutions to these problems.",,"['probability', 'statistics']"
81,How to interpret p-value in this problem.,How to interpret p-value in this problem.,,"The following is the question in particular, I got this question wrong. However nothing I run across explains why it is wrong. I answered C because with a p-value of 0.087 we don't have an ""unusual"" enough outcome to reject the null though the correct terminology would be ""extreme"". Thank you for your time. Use the following information to answer the question. A janitor at a large office building believes that his supply of light bulbs has too many defective bulbs. The janitor's null hypothesis is that the supply of light bulbs has a defect rate of p = 0.07 (the light bulb manufacturer's stated defect rate). Suppose he does a hypothesis test with a significance level of 0.05. Symbolically, the null and alternative hypothesis are as follows: H0: p = 0.07 and The janitor calculates a p-value for the hypothesis test of approximately 0.087. Choose the correct interpretation for the p-value. A) The p-value tells us that the true population rate of defective light bulbs is approximately 0.087. B) None of these C) The p-value tells us that if the defect rate is 0.07, then the probability that the janitor will have 27 defective light bulbs out of 300 is approximately 0.087. At a significance level of 0.05, this would not be an unusual outcome. D) The p-value tells us that the probability of concluding that the defect rate is equal to 0.07, when in fact it is greater than 0.07, is approximately 0.087.","The following is the question in particular, I got this question wrong. However nothing I run across explains why it is wrong. I answered C because with a p-value of 0.087 we don't have an ""unusual"" enough outcome to reject the null though the correct terminology would be ""extreme"". Thank you for your time. Use the following information to answer the question. A janitor at a large office building believes that his supply of light bulbs has too many defective bulbs. The janitor's null hypothesis is that the supply of light bulbs has a defect rate of p = 0.07 (the light bulb manufacturer's stated defect rate). Suppose he does a hypothesis test with a significance level of 0.05. Symbolically, the null and alternative hypothesis are as follows: H0: p = 0.07 and The janitor calculates a p-value for the hypothesis test of approximately 0.087. Choose the correct interpretation for the p-value. A) The p-value tells us that the true population rate of defective light bulbs is approximately 0.087. B) None of these C) The p-value tells us that if the defect rate is 0.07, then the probability that the janitor will have 27 defective light bulbs out of 300 is approximately 0.087. At a significance level of 0.05, this would not be an unusual outcome. D) The p-value tells us that the probability of concluding that the defect rate is equal to 0.07, when in fact it is greater than 0.07, is approximately 0.087.",,['statistics']
82,Probability Question: What percentage of the bag of balls is marked?,Probability Question: What percentage of the bag of balls is marked?,,"In a bag of reds and black balls, $30\%$ were red, and $90\%$ of the black balls and $80\%$ of the red balls are marked balls. What percentage of the bag of balls is marked? I thought I would have to use: Let $A = \text{marked red balls},$ $B = \text{marked black balls}.$ $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ But the answer is simply $0.8\times0.3 + 0.7\times0.9$. How come we don't have to take $P(A \cap B)$ into consideration?","In a bag of reds and black balls, $30\%$ were red, and $90\%$ of the black balls and $80\%$ of the red balls are marked balls. What percentage of the bag of balls is marked? I thought I would have to use: Let $A = \text{marked red balls},$ $B = \text{marked black balls}.$ $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ But the answer is simply $0.8\times0.3 + 0.7\times0.9$. How come we don't have to take $P(A \cap B)$ into consideration?",,"['probability', 'statistics']"
83,How to calculate MISE - Mean Integrated Squared Error?,How to calculate MISE - Mean Integrated Squared Error?,,"I might have misunderstood something, but it seems like taking a definite integral from expectation or expectation from definite integral. But the first stage will return a number in both cases. I thought that integral under expectation is indefinite, but it looks like just a ""notation"" in many places, because further digging brings negative answer - for example: see § 2.2.4 here But I have only one variable - $x$, and estimated $\hat{f}(x,h)$ and theoretical $f(x)$ functions. Can anyone explain me how to calculate $MISE(h) = E \int_{\mathbb{R}}(\hat{f}(x,h)-f(x))^2dx$ ? I see that there are some further manipulations involving the structure of kernel, but I just want to perform a simple computation in Wolfram having two functions, like MISE[ h_ ]:=NIntegrate[ NExpectation [ ...]... ]","I might have misunderstood something, but it seems like taking a definite integral from expectation or expectation from definite integral. But the first stage will return a number in both cases. I thought that integral under expectation is indefinite, but it looks like just a ""notation"" in many places, because further digging brings negative answer - for example: see § 2.2.4 here But I have only one variable - $x$, and estimated $\hat{f}(x,h)$ and theoretical $f(x)$ functions. Can anyone explain me how to calculate $MISE(h) = E \int_{\mathbb{R}}(\hat{f}(x,h)-f(x))^2dx$ ? I see that there are some further manipulations involving the structure of kernel, but I just want to perform a simple computation in Wolfram having two functions, like MISE[ h_ ]:=NIntegrate[ NExpectation [ ...]... ]",,"['probability', 'statistics']"
84,Integrate two sets of Data and check similarity,Integrate two sets of Data and check similarity,,"I have the following CSV Data I used Excel Charts to plot the Data I want to compare these Data with other Data, in another word i want to comapre 2 curves and check the similarity between them in my case $$ y = f(x) = \text{Value | x=Time} $$ i found the following formula $$ \% \text{ error} = \frac{\sum{||{f(x)-g(x)}}||}{\sum\sqrt{(x_{i+1}-x_{i})^2+(y_{i+1}-y_{i})^2}} $$ is this Formula correct ? are $x_{i} \text{ and } y_{i}$ the Value or simply the Indices that are in my case Time ? what if the both functions have different x or Time but they have/follow the same trend ? i'm using python for programming","I have the following CSV Data I used Excel Charts to plot the Data I want to compare these Data with other Data, in another word i want to comapre 2 curves and check the similarity between them in my case $$ y = f(x) = \text{Value | x=Time} $$ i found the following formula $$ \% \text{ error} = \frac{\sum{||{f(x)-g(x)}}||}{\sum\sqrt{(x_{i+1}-x_{i})^2+(y_{i+1}-y_{i})^2}} $$ is this Formula correct ? are $x_{i} \text{ and } y_{i}$ the Value or simply the Indices that are in my case Time ? what if the both functions have different x or Time but they have/follow the same trend ? i'm using python for programming",,"['integration', 'statistics', 'dynamic-programming']"
85,95% Confidence Intervals,95% Confidence Intervals,,"I was solving this problem from a textbook In a random sample of three pupils, $x_i$ is the mark of the $i$ th pupil in a test on volcanoes and $y_i$ is the mark of the $i$ th pupil in a test on glaciers. All three pupils sit both tests. It is believed that the difference between the results in these two tests follows a normal distribution with variance $16$ marks. If the mean mark on the volcano test was $23$ and the man mark for the glacier test was $30$ , find a $95\%$ confidence interval for the improvement in marks from the volcano test to the glacier test. My attempt was, letting the desired distribution be $\overline{Y-X}$ . We know that the mean is $\overline{y-x} = \bar{y} - \bar{x} = 30-23= 7$ . Standard deviation is given as $16$ , $\Phi^{-1}(0.975) = 1.959$ , and number of samples is $n=3$ . Hence average improvement, $\mu$ , would lie in the interval, $$ \bar{x} - 1.959 \frac{4}{\sqrt{3}} < \mu  < \bar{x} + 1.959 \frac{4}{\sqrt{3}}$$ giving our confidence interval $[ 2.478, 11.524 ]$ . However, the actual interval from the textbook is $ [ -11.1, 25.1 ] $ May someone explain why? Thank you so much!","I was solving this problem from a textbook In a random sample of three pupils, is the mark of the th pupil in a test on volcanoes and is the mark of the th pupil in a test on glaciers. All three pupils sit both tests. It is believed that the difference between the results in these two tests follows a normal distribution with variance marks. If the mean mark on the volcano test was and the man mark for the glacier test was , find a confidence interval for the improvement in marks from the volcano test to the glacier test. My attempt was, letting the desired distribution be . We know that the mean is . Standard deviation is given as , , and number of samples is . Hence average improvement, , would lie in the interval, giving our confidence interval . However, the actual interval from the textbook is May someone explain why? Thank you so much!","x_i i y_i i 16 23 30 95\% \overline{Y-X} \overline{y-x} = \bar{y} - \bar{x} = 30-23= 7 16 \Phi^{-1}(0.975) = 1.959 n=3 \mu  \bar{x} - 1.959 \frac{4}{\sqrt{3}} < \mu  < \bar{x} + 1.959 \frac{4}{\sqrt{3}} [ 2.478, 11.524 ]  [ -11.1, 25.1 ] ","['probability', 'statistics', 'probability-distributions', 'standard-deviation', 'means']"
86,distance function between histograms accounting for bucket distance,distance function between histograms accounting for bucket distance,,"I'm trying to find a good distance measure for histograms that has the following properties: if histogram A and B have high values in buckets further apart, they're more different than if they had high values close together it should take into account similarity, therefore the distance between histogram A and B should be higher than the distance between histograms A1 and B1 built adding a bucket ad the end with the same height in A1 and B1. the distance between two buckets is linear and circular, meaning that the first and last bucket are considered next to each other since probably I wasn't very clear, I'll give you some context.. first with bucket I mean a single bar of the histogram (bucket because it's basically an interval, and the height of the bar is defined as the count of element in a set that fall in that bucket). In my case, buckets are the hours of the day (that's why 23 and 0 should be considered distance 1), and the height of the bars represents how many events I had in that hour. If something is not clear, please comment and I'll try to explain better.","I'm trying to find a good distance measure for histograms that has the following properties: if histogram A and B have high values in buckets further apart, they're more different than if they had high values close together it should take into account similarity, therefore the distance between histogram A and B should be higher than the distance between histograms A1 and B1 built adding a bucket ad the end with the same height in A1 and B1. the distance between two buckets is linear and circular, meaning that the first and last bucket are considered next to each other since probably I wasn't very clear, I'll give you some context.. first with bucket I mean a single bar of the histogram (bucket because it's basically an interval, and the height of the bar is defined as the count of element in a set that fall in that bucket). In my case, buckets are the hours of the day (that's why 23 and 0 should be considered distance 1), and the height of the bars represents how many events I had in that hour. If something is not clear, please comment and I'll try to explain better.",,"['statistics', 'probability-distributions']"
87,R (Stats) - Read anova table and prove Ha,R (Stats) - Read anova table and prove Ha,,"Don't down-vote me for not including more context--You don't need it (unless you're curious for more info). I have a dataset and have the following output in the anova table: (the stats are based on this study: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC164340/ ) I understand that the F value is the test statistic and Pr(>F) denotes the associated p-value. Using this data, I've been asked to ""report the conclusion at the 0.05 significance level for Ho : no difference..."" Do we reject Ho because of the significantly small p-value? After doing a little research, I've found that statisticians look down on making decisions as to the significance of studies/results solely based on the p-value. Is there some other comparison that can/should be made, or should our decision solely be based on the p-value?","Don't down-vote me for not including more context--You don't need it (unless you're curious for more info). I have a dataset and have the following output in the anova table: (the stats are based on this study: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC164340/ ) I understand that the F value is the test statistic and Pr(>F) denotes the associated p-value. Using this data, I've been asked to ""report the conclusion at the 0.05 significance level for Ho : no difference..."" Do we reject Ho because of the significantly small p-value? After doing a little research, I've found that statisticians look down on making decisions as to the significance of studies/results solely based on the p-value. Is there some other comparison that can/should be made, or should our decision solely be based on the p-value?",,"['probability', 'statistics']"
88,What is the optimal strategy for this made-up casino game?,What is the optimal strategy for this made-up casino game?,,"Part 1: Let's say I walk into a casino with 100 dollars in my wallet. I sit down to play a game where my payoff or loss each round is a X dollars, where X is a continuous random variable uniformly distributed between [-2, 2]. However, because I'm friends with the manager, he gives me a special deal. If X < -1, I only lose a dollars instead of losing anywhere between a and 2a dollars, as I rightfully would. (Note that the random variable is deliberately [-2, 2] instead of [-1, 2], in order that the initial determination of the random variable will have an EV of 0.) The random variable X is redetermined every round. The one choice I get to make is the value of the constant a , which is fixed forever once I choose it. If I want to maximize the amount of cash in my wallet at the end of 50 rounds (and implicit in this question is the need to avoid going bust), what value should I pick for a ? Part 2: Everything is the same, but instead of the payout or loss each round being a X dollars, it is now a (X+ b ). Let's say b = 0.1, so my payout or loss every round will be a * [-1.9, 2.1]. The special deal with my buddy the manager is still on for any X < -1, so I only lose a dollars instead of anywhere between a and 1.9a dollars. How does my selection of a change?","Part 1: Let's say I walk into a casino with 100 dollars in my wallet. I sit down to play a game where my payoff or loss each round is a X dollars, where X is a continuous random variable uniformly distributed between [-2, 2]. However, because I'm friends with the manager, he gives me a special deal. If X < -1, I only lose a dollars instead of losing anywhere between a and 2a dollars, as I rightfully would. (Note that the random variable is deliberately [-2, 2] instead of [-1, 2], in order that the initial determination of the random variable will have an EV of 0.) The random variable X is redetermined every round. The one choice I get to make is the value of the constant a , which is fixed forever once I choose it. If I want to maximize the amount of cash in my wallet at the end of 50 rounds (and implicit in this question is the need to avoid going bust), what value should I pick for a ? Part 2: Everything is the same, but instead of the payout or loss each round being a X dollars, it is now a (X+ b ). Let's say b = 0.1, so my payout or loss every round will be a * [-1.9, 2.1]. The special deal with my buddy the manager is still on for any X < -1, so I only lose a dollars instead of anywhere between a and 1.9a dollars. How does my selection of a change?",,"['statistics', 'optimization']"
89,Selecting a type of distribution for a problem,Selecting a type of distribution for a problem,,"""Among 30 raffle tickets six are winners. Felicia buys 10 tickets. Find the probability that she got three winners."" This problem ask me to first identify a random variable and describe its distribution before doing any computations. I'm having trouble determine which kind of distribution should I use for it. Please help, thanks!","""Among 30 raffle tickets six are winners. Felicia buys 10 tickets. Find the probability that she got three winners."" This problem ask me to first identify a random variable and describe its distribution before doing any computations. I'm having trouble determine which kind of distribution should I use for it. Please help, thanks!",,"['probability', 'statistics', 'probability-distributions']"
90,How can you normalize two data sets to the same scale?,How can you normalize two data sets to the same scale?,,"I have two data sets, one that ranges from 0-200, and another that ranges from ~400-~2500. I would like to compare the two according to a score from 0-10. I remember about normalizing from a statistics class that I took that in order to normalize you need to find the z-score which depends on the population mean and standard deviation (which I have). But I don't remember what to do with that z-score, or how to normalize both of these data sets down to a 0-10 scale so that they can be scaled down and compared against each other. Anyone remember how to do this?","I have two data sets, one that ranges from 0-200, and another that ranges from ~400-~2500. I would like to compare the two according to a score from 0-10. I remember about normalizing from a statistics class that I took that in order to normalize you need to find the z-score which depends on the population mean and standard deviation (which I have). But I don't remember what to do with that z-score, or how to normalize both of these data sets down to a 0-10 scale so that they can be scaled down and compared against each other. Anyone remember how to do this?",,"['statistics', 'normal-distribution']"
91,Finding the Probability of a Sequence of Numbers in Materials Testing,Finding the Probability of a Sequence of Numbers in Materials Testing,,"There are $n$ numbers on a wheel. For this example, let's say $n = 20$. You are going to spin $x$ times. For this example, let's say $x = 7$. The chances of spinning the same number all 7 times is $\left(\frac{1}{n}\right)^x$ or 1 in 1,280,000,000 for this example. For materials testing, the smaller the probability, the more likely someone cheated. What formula can I use to find the probability of having the same number occur 4 times and a different number occur 3 times? Or the odds that 7 different numbers will occur? Or the odds that 3 numbers are the same, 2 numbers are the same, 2 more numbers are the same? etc. The numbers do not have to be in order or consecutive and all 20 numbers can occur each spin. My thought is this is a complex equation that can simply be solved. Also, what are the odds that all 7 numbers are in the bottom half, bottom quarter, middle quarter, etc. of the numbers? Please note: This sounds similar to roulette, but I promise this isn't roulette. I just know roulette terminology more than probability. Thanks for the help!","There are $n$ numbers on a wheel. For this example, let's say $n = 20$. You are going to spin $x$ times. For this example, let's say $x = 7$. The chances of spinning the same number all 7 times is $\left(\frac{1}{n}\right)^x$ or 1 in 1,280,000,000 for this example. For materials testing, the smaller the probability, the more likely someone cheated. What formula can I use to find the probability of having the same number occur 4 times and a different number occur 3 times? Or the odds that 7 different numbers will occur? Or the odds that 3 numbers are the same, 2 numbers are the same, 2 more numbers are the same? etc. The numbers do not have to be in order or consecutive and all 20 numbers can occur each spin. My thought is this is a complex equation that can simply be solved. Also, what are the odds that all 7 numbers are in the bottom half, bottom quarter, middle quarter, etc. of the numbers? Please note: This sounds similar to roulette, but I promise this isn't roulette. I just know roulette terminology more than probability. Thanks for the help!",,"['probability', 'statistics']"
92,Why is $\sqrt{n}/n$ a acceptable proportion of outliers?,Why is  a acceptable proportion of outliers?,\sqrt{n}/n,"Recently I found a paper which stated that $\sqrt{n}/n$ is the maximal acceptable proportion of outliers for n given data points. Unfortunately they only quote a book, which is quite out of my price range: http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0471930946.html Unfortunately I couldn't find anything conclusive through a google search and I hope that somebody here may point me in the right direction or at least towards an affordable book or paper, which explains the matter.","Recently I found a paper which stated that $\sqrt{n}/n$ is the maximal acceptable proportion of outliers for n given data points. Unfortunately they only quote a book, which is quite out of my price range: http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0471930946.html Unfortunately I couldn't find anything conclusive through a google search and I hope that somebody here may point me in the right direction or at least towards an affordable book or paper, which explains the matter.",,['statistics']
93,Calculating the probability of winning roulette after x bets,Calculating the probability of winning roulette after x bets,,"I'm going through all of my homeworks to study for my final and I'm getting hung up on this one problem I never figured out... A roulette wheel has 38 slots, numbered 0, 00, and 1 through 36. If you bet 1 on a specified number, you either win 35 if the roulette ball lands on that number or lose 1 if it does not. If you continually make such bets, approximate the probability that (a) you are winning after 34 bets; (b) you are winning after 1,000 bets; (c) you are winning after 100,000 bets. So i get the idea is to figure out the mean and variance so that I can let X be estimated by a normal distribution, I got the correct values and checked them with the solutions, but theres one thing I'm confused about. Even though the solution calculates the expected value of the winnings E(W) = (35)(1/38) + (-1)(37/38) = -0.0526, it uses a different value for the mean in the calculation of the Z score. It used 1 - (37/38)^34 = 0.596 .. This is different than any other problem I've seen before, I was just hoping someone could explain why you use this value as opposed to the expected value E(W), and what exactly this value means. Thanks.","I'm going through all of my homeworks to study for my final and I'm getting hung up on this one problem I never figured out... A roulette wheel has 38 slots, numbered 0, 00, and 1 through 36. If you bet 1 on a specified number, you either win 35 if the roulette ball lands on that number or lose 1 if it does not. If you continually make such bets, approximate the probability that (a) you are winning after 34 bets; (b) you are winning after 1,000 bets; (c) you are winning after 100,000 bets. So i get the idea is to figure out the mean and variance so that I can let X be estimated by a normal distribution, I got the correct values and checked them with the solutions, but theres one thing I'm confused about. Even though the solution calculates the expected value of the winnings E(W) = (35)(1/38) + (-1)(37/38) = -0.0526, it uses a different value for the mean in the calculation of the Z score. It used 1 - (37/38)^34 = 0.596 .. This is different than any other problem I've seen before, I was just hoping someone could explain why you use this value as opposed to the expected value E(W), and what exactly this value means. Thanks.",,"['probability', 'statistics', 'normal-distribution', 'central-limit-theorem']"
94,$55$ of registered voters favor incumbent mayor. Find probability that the race ends in a tie.,of registered voters favor incumbent mayor. Find probability that the race ends in a tie.,55,"Fifty-five percent of the registered voters in Sheridanville favor their incumbent mayor in her bid for re-election. If four hundred voters go to the polls, approximate the probability that: (a) the race ends in a tie. Attempt: For part (a) given $n = 400$ and $p = 0.55$ and $(1-p) = 0.45$ we recognized this is a binomial representation. Thus if the race ends in a tie, then $X = k = 200$. Thus $P(X = k = 200) = \binom{400}{200}(0.55)^{200}(0.45)^{400-200}$.  However, I don't know how to simplify, when I plug in the value for a calculator I get error since it is to big. The answer is $0.0053$ (b) the challenger scores an upset victory Attempt: For part b) we  have $P(X < 200) = {\Sigma_{k = 0}^{199} }{\binom{400}{k}(0.55^k)(0.45^{400 - k}}$. The answer is $0.0197$ at the back of the book. can someone please help me simplify or if someone knows a better way to approach it? Any feedback/help would be appreciated. Thanks in advance.","Fifty-five percent of the registered voters in Sheridanville favor their incumbent mayor in her bid for re-election. If four hundred voters go to the polls, approximate the probability that: (a) the race ends in a tie. Attempt: For part (a) given $n = 400$ and $p = 0.55$ and $(1-p) = 0.45$ we recognized this is a binomial representation. Thus if the race ends in a tie, then $X = k = 200$. Thus $P(X = k = 200) = \binom{400}{200}(0.55)^{200}(0.45)^{400-200}$.  However, I don't know how to simplify, when I plug in the value for a calculator I get error since it is to big. The answer is $0.0053$ (b) the challenger scores an upset victory Attempt: For part b) we  have $P(X < 200) = {\Sigma_{k = 0}^{199} }{\binom{400}{k}(0.55^k)(0.45^{400 - k}}$. The answer is $0.0197$ at the back of the book. can someone please help me simplify or if someone knows a better way to approach it? Any feedback/help would be appreciated. Thanks in advance.",,"['probability', 'statistics']"
95,Trouble with Example for Convergence in Distribution,Trouble with Example for Convergence in Distribution,,"I am a bit confused by an example used to illustrate the concept of ""convergence in distribution"" Intuitively, this makes sense, since if we choose a large number of points from the distribution of $X$, the distributions for $X$ and $X_n$ will appear the same. However, the formal definition for convergence in distribution says: and in the given example, it doesn't seem that the sequence of cdfs converge pointwise for any non-zero value of $x$. At $X=1$ for example, the cdfs of the odd $n$ converge (trivially) to $F(-1)$ while the cdfs for even $n$ converge to $F(1)$. Thanks, Matt","I am a bit confused by an example used to illustrate the concept of ""convergence in distribution"" Intuitively, this makes sense, since if we choose a large number of points from the distribution of $X$, the distributions for $X$ and $X_n$ will appear the same. However, the formal definition for convergence in distribution says: and in the given example, it doesn't seem that the sequence of cdfs converge pointwise for any non-zero value of $x$. At $X=1$ for example, the cdfs of the odd $n$ converge (trivially) to $F(-1)$ while the cdfs for even $n$ converge to $F(1)$. Thanks, Matt",,"['probability', 'statistics', 'convergence-divergence']"
96,The Largest Gap,The Largest Gap,,"If I have an X amount of randomly generated positive numbers, what type of algorithm could I run to find the following: Precisely where the largest difference exists between two of the numbers? How much is that difference? Where does the smallest gap exist? How much is that difference? Generate a list of all differences and how many occurrences there are of each difference It has been a while since I have taken any sort of math class, so pardon the potentially inaccurate tags. Ideally I'm looking for a way to generate a list of all the differences, and then place those differences into a descending order. Once the list of all the differences into a descending order is created, we still need to be able to identify where in the original set of numbers, each particular difference takes place.","If I have an X amount of randomly generated positive numbers, what type of algorithm could I run to find the following: Precisely where the largest difference exists between two of the numbers? How much is that difference? Where does the smallest gap exist? How much is that difference? Generate a list of all differences and how many occurrences there are of each difference It has been a while since I have taken any sort of math class, so pardon the potentially inaccurate tags. Ideally I'm looking for a way to generate a list of all the differences, and then place those differences into a descending order. Once the list of all the differences into a descending order is created, we still need to be able to identify where in the original set of numbers, each particular difference takes place.",,"['statistics', 'algorithms', 'descriptive-statistics']"
97,fantasy basketball model,fantasy basketball model,,"i'm creating a fantasy basketball model (could be used in other games too) where we can project how well a player will do against another team even when the player hasn't played against a certain team before. i have a statistics question about what i'm trying to do. i have broken down each team into the 5 positions and have compiled data for how many fantasy points/minute a team gives up to their opposition in that position. so for example, the Lakers give up .984 fantasy points a minute to opposing teams centers which is above average (league average is .925). i have also compiled how many points every player in the league scores on average per minute. for example dwight howard, a center for the Rockets, scores on average 1.111 fantasy points/minute which is way above average (the league average is still .925) now the tricky part where i need help is when i combine the two numbers. i'm trying to see if Player X plays vs Defense Y, how many points should i expect from that player assuming he plays a constant amount of minutes. so in this hypothetical example let's say i'm trying to project Howard's points vs the Lakers assuming he plays 30 minutes that game what i've thought of is finding the deviation about the mean for each player relative to the average of all the other players' points/minute and then figuring out the deviation about the mean of how many points/minute an opposing team gives up to each specific position. the problem with this is i dont know what to do next. i'm trying to find a way to use this data to create a somewhat accurate projection assuming i know how many minutes a player is going to play. i feel like this would involve a non-linear curve where top players and top defensive teams would be extremely effective while average players and defensive teams would produce marginal results and poor players and defensive teams would would give bad results. any ideas on how i can further my model specifically with evaluating a player vs defense for position considering i know both of their averages vs the entire league? thanks in advance i've been thinking about this and playing with this for the last week!","i'm creating a fantasy basketball model (could be used in other games too) where we can project how well a player will do against another team even when the player hasn't played against a certain team before. i have a statistics question about what i'm trying to do. i have broken down each team into the 5 positions and have compiled data for how many fantasy points/minute a team gives up to their opposition in that position. so for example, the Lakers give up .984 fantasy points a minute to opposing teams centers which is above average (league average is .925). i have also compiled how many points every player in the league scores on average per minute. for example dwight howard, a center for the Rockets, scores on average 1.111 fantasy points/minute which is way above average (the league average is still .925) now the tricky part where i need help is when i combine the two numbers. i'm trying to see if Player X plays vs Defense Y, how many points should i expect from that player assuming he plays a constant amount of minutes. so in this hypothetical example let's say i'm trying to project Howard's points vs the Lakers assuming he plays 30 minutes that game what i've thought of is finding the deviation about the mean for each player relative to the average of all the other players' points/minute and then figuring out the deviation about the mean of how many points/minute an opposing team gives up to each specific position. the problem with this is i dont know what to do next. i'm trying to find a way to use this data to create a somewhat accurate projection assuming i know how many minutes a player is going to play. i feel like this would involve a non-linear curve where top players and top defensive teams would be extremely effective while average players and defensive teams would produce marginal results and poor players and defensive teams would would give bad results. any ideas on how i can further my model specifically with evaluating a player vs defense for position considering i know both of their averages vs the entire league? thanks in advance i've been thinking about this and playing with this for the last week!",,"['statistics', 'mathematical-modeling', 'nonlinear-optimization', 'standard-deviation']"
98,concept of one-tailed hypothesis testing,concept of one-tailed hypothesis testing,,"When we assume that the null hypothesis is true in one-tailed test for mean, we assume that the population mean is equal that value indicated in the hypotheses.  Why do we not assume some other value for the population mean also allowable under the null hypothesis?","When we assume that the null hypothesis is true in one-tailed test for mean, we assume that the population mean is equal that value indicated in the hypotheses.  Why do we not assume some other value for the population mean also allowable under the null hypothesis?",,['statistics']
99,Matrix form for Weighted Least Squares,Matrix form for Weighted Least Squares,,"If we have the following weighted least-squares regression, with $\hat{\beta} = (X'WX)^{-1}X'WY$ How can we express the squared errors, MSE and the fitted values in matrix form? These are the OLS equivalent: $Squared Error_i = (\hat{y}_i - y_i )^2$ $Mean Squared Error(MSE) = \Sigma(\hat{y}_i - y_i)^2/(N-p)$ $Fitted Value_i = \hat{y}_i=  \hat{\beta} * x_i$ Thank you!","If we have the following weighted least-squares regression, with $\hat{\beta} = (X'WX)^{-1}X'WY$ How can we express the squared errors, MSE and the fitted values in matrix form? These are the OLS equivalent: $Squared Error_i = (\hat{y}_i - y_i )^2$ $Mean Squared Error(MSE) = \Sigma(\hat{y}_i - y_i)^2/(N-p)$ $Fitted Value_i = \hat{y}_i=  \hat{\beta} * x_i$ Thank you!",,"['statistics', 'regression']"
