,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Second fundamental theorem of calculus on the unit sphere,Second fundamental theorem of calculus on the unit sphere,,"Without being so sure, the second fundamental theorem of calculus can be written in the following form: Let $f \in {\cal C}^1(\mathbb{R}^n)$. Then, for all $x, y \in \mathbb{R}^n$, we have    \begin{align} f(y) = f(x) + \int_0^1 \langle \nabla f(x + \tau(y-x)), y-x \rangle d \tau, \end{align}   where $\nabla f(x)$ denotes the gradient of $f(x)$. A use case of this formulation can be found in Nesterov's book (Introductory Lectures on Convex Programming) (Lemma 1.2.3). I was wondering if there is form of this equation for the case where $x$ and $y$ live on the unit sphere $\mathbb{S}^{n-1} \subset \mathbb{R}^n$. I am guessing that the formula would contain geodesics, but I couldn't find a solution online.","Without being so sure, the second fundamental theorem of calculus can be written in the following form: Let $f \in {\cal C}^1(\mathbb{R}^n)$. Then, for all $x, y \in \mathbb{R}^n$, we have    \begin{align} f(y) = f(x) + \int_0^1 \langle \nabla f(x + \tau(y-x)), y-x \rangle d \tau, \end{align}   where $\nabla f(x)$ denotes the gradient of $f(x)$. A use case of this formulation can be found in Nesterov's book (Introductory Lectures on Convex Programming) (Lemma 1.2.3). I was wondering if there is form of this equation for the case where $x$ and $y$ live on the unit sphere $\mathbb{S}^{n-1} \subset \mathbb{R}^n$. I am guessing that the formula would contain geodesics, but I couldn't find a solution online.",,['differential-geometry']
1,The hopf fibration is a submersion.,The hopf fibration is a submersion.,,"Let $F:\mathbb{S}^{3}\to \mathbb{S}^{2}$, where $F(x,y,u,v)=(2.(xu+yv),2.(xv-yu),,u^{2}+v^{2}-x^{2}-y^{2})$. A submersion has a rank equal to dimension of codomain, then the work is prove that $rank F=2$. In my notes the author prove that there exists a minor with ordem $3$ with determinant non-zero, but i don't understand this, because in my definition i should prove that there exist a minor with order two with non-zero determinant and every minor with order $3$ has determinant zero. Lastly, there exists a way to prove that $F$ is a submersion without calculate the Jacobian?","Let $F:\mathbb{S}^{3}\to \mathbb{S}^{2}$, where $F(x,y,u,v)=(2.(xu+yv),2.(xv-yu),,u^{2}+v^{2}-x^{2}-y^{2})$. A submersion has a rank equal to dimension of codomain, then the work is prove that $rank F=2$. In my notes the author prove that there exists a minor with ordem $3$ with determinant non-zero, but i don't understand this, because in my definition i should prove that there exist a minor with order two with non-zero determinant and every minor with order $3$ has determinant zero. Lastly, there exists a way to prove that $F$ is a submersion without calculate the Jacobian?",,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'spheres']"
2,Confusion over what indices to contract when deriving Ricci curvature from the curvature tensor?,Confusion over what indices to contract when deriving Ricci curvature from the curvature tensor?,,"My question here is just an example of a more general problem I'm having of working in local coordinates, so any help would be appreciated. I am told that $\mathrm{Ric}_{ij}=g^{kl}R_{iklj}$, where $R_{iklj}$ are the components of the curvature tensor $R$. Here $R$ is considered as a $(0,4)$-tensor, related to $R$ considered as a $(1,3)$-tensor by \begin{equation}R(X,Y,Z,W)=g(R(X,Y)Z,W)\end{equation} I am slightly confused as to how to obtain $\mathrm{Ric}_{ij}=g^{kl}R_{iklj}$, given the definition of Ricci curvature I've been given: \begin{equation} \mathrm{Ric}(v,w)=\mathrm{trace}(x\mapsto R(x,v)w). \end{equation} It seems to me that first I want to convert $R$ from its $(0,4)$ form to its $(1,3)$ form, but with $R=R_{iklj}\sigma^i\otimes\sigma^k\otimes\sigma^l\otimes\sigma^j$ I'm not sure which of the factors I should be converting? Suppose for instance I take the second factor, so \begin{equation} \sigma^k\rightarrow g^{ks} E_s  \end{equation} (this is by the usual isomorphism between $TM$ and $T^*M$ on a Riemannian manifold, where $E_i$ is our frame and $\sigma^i$ our coframe). Thus we obtain a $(1,3)$-tensor  \begin{equation} \begin{split} R & = g^{ks}R_{iklj}\sigma^i \otimes E_s \otimes \sigma^l \otimes \sigma^j \\ &= {R_i^{~~s}}_{lj}\,\sigma^i \otimes E_s \otimes \sigma^l \otimes \sigma^j \end{split} \end{equation} Even if this is the correct choice to make, in order to obtain the Ricci tensor (considered as a $(0,2)$-tensor) I must now contract the $E_s$ factor with one of the $\sigma$ factors. Again, I am not sure which factor I should be contracting with to obtain the Ricci tensor. Choosing the $\sigma^l$ factor I obtain \begin{equation} 	S = S_{ij}\sigma^i\otimes \sigma^j 	\end{equation}     where $S_{ij} = {R_i^{~~s}}_{sj}$. Is this tensor $S$ the Ricci tensor? Does $S_{ij}=g^{kl}R_{iklj}$? How am I to know what choices to make (when working in coordinates as above) when changing tensor types/performing contractions, from the definitions I've been given that are not in coordinates? Thanks in advance.","My question here is just an example of a more general problem I'm having of working in local coordinates, so any help would be appreciated. I am told that $\mathrm{Ric}_{ij}=g^{kl}R_{iklj}$, where $R_{iklj}$ are the components of the curvature tensor $R$. Here $R$ is considered as a $(0,4)$-tensor, related to $R$ considered as a $(1,3)$-tensor by \begin{equation}R(X,Y,Z,W)=g(R(X,Y)Z,W)\end{equation} I am slightly confused as to how to obtain $\mathrm{Ric}_{ij}=g^{kl}R_{iklj}$, given the definition of Ricci curvature I've been given: \begin{equation} \mathrm{Ric}(v,w)=\mathrm{trace}(x\mapsto R(x,v)w). \end{equation} It seems to me that first I want to convert $R$ from its $(0,4)$ form to its $(1,3)$ form, but with $R=R_{iklj}\sigma^i\otimes\sigma^k\otimes\sigma^l\otimes\sigma^j$ I'm not sure which of the factors I should be converting? Suppose for instance I take the second factor, so \begin{equation} \sigma^k\rightarrow g^{ks} E_s  \end{equation} (this is by the usual isomorphism between $TM$ and $T^*M$ on a Riemannian manifold, where $E_i$ is our frame and $\sigma^i$ our coframe). Thus we obtain a $(1,3)$-tensor  \begin{equation} \begin{split} R & = g^{ks}R_{iklj}\sigma^i \otimes E_s \otimes \sigma^l \otimes \sigma^j \\ &= {R_i^{~~s}}_{lj}\,\sigma^i \otimes E_s \otimes \sigma^l \otimes \sigma^j \end{split} \end{equation} Even if this is the correct choice to make, in order to obtain the Ricci tensor (considered as a $(0,2)$-tensor) I must now contract the $E_s$ factor with one of the $\sigma$ factors. Again, I am not sure which factor I should be contracting with to obtain the Ricci tensor. Choosing the $\sigma^l$ factor I obtain \begin{equation} 	S = S_{ij}\sigma^i\otimes \sigma^j 	\end{equation}     where $S_{ij} = {R_i^{~~s}}_{sj}$. Is this tensor $S$ the Ricci tensor? Does $S_{ij}=g^{kl}R_{iklj}$? How am I to know what choices to make (when working in coordinates as above) when changing tensor types/performing contractions, from the definitions I've been given that are not in coordinates? Thanks in advance.",,"['differential-geometry', 'riemannian-geometry', 'tensor-products', 'tensors', 'curvature']"
3,Give an example of a smooth distribution $D$ of dimension 1 which is not globally generated by only one vector field.,Give an example of a smooth distribution  of dimension 1 which is not globally generated by only one vector field.,D,"The question is as follows: Give an example of a smooth distribution $D$ of dimension 1 which is not globally generated by only one vector field. $\textbf{Some definitions:}$ The easiest way to introduce the notion of distribution $\Delta$ on a manifold $N$ is to consider a mapping assigning to each point $p$ of $N$ a subspace $\Delta(p)$ of the tangent space $T_pN$ to $N$ at $p$. Now if we assume for each point $p$ of $N$ there exist a neighborhood $U$ of $p$ and a set of smooth vector fields defined on $U$, denoted $\{ \tau_i \mid i \in I \}$, with the property that $\Delta(q) = \{ \tau_i(q): i \in I \}$ for all $q \in U$. Such an object will be called a smooth distribution on $N$. I do not know what  ""globally generated by only one vector field"" means? Can someone help me to understand this and to give me an example? Thanks!","The question is as follows: Give an example of a smooth distribution $D$ of dimension 1 which is not globally generated by only one vector field. $\textbf{Some definitions:}$ The easiest way to introduce the notion of distribution $\Delta$ on a manifold $N$ is to consider a mapping assigning to each point $p$ of $N$ a subspace $\Delta(p)$ of the tangent space $T_pN$ to $N$ at $p$. Now if we assume for each point $p$ of $N$ there exist a neighborhood $U$ of $p$ and a set of smooth vector fields defined on $U$, denoted $\{ \tau_i \mid i \in I \}$, with the property that $\Delta(q) = \{ \tau_i(q): i \in I \}$ for all $q \in U$. Such an object will be called a smooth distribution on $N$. I do not know what  ""globally generated by only one vector field"" means? Can someone help me to understand this and to give me an example? Thanks!",,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
4,Outward-pointing vector field on Projective space,Outward-pointing vector field on Projective space,,"Lee Smooth Manifolds problem 8-4 says that for every manifold with boundary there exists a smooth vector field that is outward-pointing when restricted to the boundary. Now if our manifold is $M=\mathbb{R}P^2\times [0,1)$, there should be some smooth outward pointing vector field on $\partial M=\mathbb{R}P^2$. My questions are, why does this not determine an orientation for $\mathbb{R}P^2$, and what does this vector field ""look"" like (pictures welcome) when restricted to $\mathbb{R}P^2$? If you can provide an explicit example of such a vector field that would be much appreciated. Thanks for your help!","Lee Smooth Manifolds problem 8-4 says that for every manifold with boundary there exists a smooth vector field that is outward-pointing when restricted to the boundary. Now if our manifold is $M=\mathbb{R}P^2\times [0,1)$, there should be some smooth outward pointing vector field on $\partial M=\mathbb{R}P^2$. My questions are, why does this not determine an orientation for $\mathbb{R}P^2$, and what does this vector field ""look"" like (pictures welcome) when restricted to $\mathbb{R}P^2$? If you can provide an explicit example of such a vector field that would be much appreciated. Thanks for your help!",,"['differential-geometry', 'manifolds', 'vector-fields', 'orientation']"
5,Tangent space as the set of all derivations,Tangent space as the set of all derivations,,"I am trying to get a grip on the concept of derivations at a point on a manifold by working out some concrete examples. Let $M$ be a smooth manifold with or without boundary, and let $p \in M$ . A linear map $v : C^{\infty}(M) \to \mathbb{R}$ is called a derivation at $p$ if it satisfies $$v(fg) = f(p)v(g) + g(p)v(f)$$ The set of all derivations of $C^{\infty}(M)$ at $p$ is denoted by $T_pM$ and is a vector space called the tangent space to $M$ at $p$ . Now let's look at an example; from single-variable calculus. Take $M = \mathbb{R}$ and $f(x) =\sin(x)$ and $p = \pi$ . We have $f'(p) = \cos(p) = -1$ . Now let's look at the general definition above, and note that for any $a \in \mathbb{R}^n$ , the $n$ derivations $$\frac{\partial}{\partial x^i}|_{a} \ \text{ defined by } \ \frac{\partial}{\partial x^i}|_{a}f = \frac{\partial f}{\partial x^i}(a)$$ for $i \in \{1, .., n\} $ form a basis for $T_a(\mathbb{R}^n)$ and has dimension $n$ . So pick $v \in T_p(\mathbb{R}^1)$ , since $v$ is a linear-combination of basis elements in a vector space of dimension $1$ , we have $v = c \cdot \frac{\partial}{\partial x}|_{p}$ for some $c \in \mathbb{R}$ . So $v(f)  = c \cdot \frac{\partial f}{\partial x}|_{p} = c\cdot \frac{d f}{d x}|_{p} = c\cdot cos(\pi) = -c$ for some $c \in \mathbb{R}$ But we need $v(f) = -1$ , for the computation from the general definition and usual calculus to coincide. Have I done anything wrong here? Shouldn't $v(f) = -1$ ?","I am trying to get a grip on the concept of derivations at a point on a manifold by working out some concrete examples. Let be a smooth manifold with or without boundary, and let . A linear map is called a derivation at if it satisfies The set of all derivations of at is denoted by and is a vector space called the tangent space to at . Now let's look at an example; from single-variable calculus. Take and and . We have . Now let's look at the general definition above, and note that for any , the derivations for form a basis for and has dimension . So pick , since is a linear-combination of basis elements in a vector space of dimension , we have for some . So for some But we need , for the computation from the general definition and usual calculus to coincide. Have I done anything wrong here? Shouldn't ?","M p \in M v : C^{\infty}(M) \to \mathbb{R} p v(fg) = f(p)v(g) + g(p)v(f) C^{\infty}(M) p T_pM M p M = \mathbb{R} f(x) =\sin(x) p = \pi f'(p) = \cos(p) = -1 a \in \mathbb{R}^n n \frac{\partial}{\partial x^i}|_{a} \ \text{ defined by } \ \frac{\partial}{\partial x^i}|_{a}f = \frac{\partial f}{\partial x^i}(a) i \in \{1, .., n\}  T_a(\mathbb{R}^n) n v \in T_p(\mathbb{R}^1) v 1 v = c \cdot \frac{\partial}{\partial x}|_{p} c \in \mathbb{R} v(f)  = c \cdot \frac{\partial f}{\partial x}|_{p} = c\cdot \frac{d f}{d x}|_{p} = c\cdot cos(\pi) = -c c \in \mathbb{R} v(f) = -1 v(f) = -1","['differential-geometry', 'smooth-manifolds']"
6,A question on the proof of induced metric from Riemannian metric,A question on the proof of induced metric from Riemannian metric,,"The following Picture is the proof of "" distance function on Riemannian manifold is a metric "". How the author deduced that length of any curve from $p$ to the boundary of given ball is at least $r/\lambda_0$? Thanks.","The following Picture is the proof of "" distance function on Riemannian manifold is a metric "". How the author deduced that length of any curve from $p$ to the boundary of given ball is at least $r/\lambda_0$? Thanks.",,"['differential-geometry', 'metric-spaces', 'riemannian-geometry']"
7,"Turns of closed path $\lambda$ around origin is related to area of paralelogram $\lambda(t), \lambda'(t)$",Turns of closed path  around origin is related to area of paralelogram,"\lambda \lambda(t), \lambda'(t)","Given the closed path $\lambda:[a,b]\to\mathbb{R^2}-\{0\}$, $C^1$,   call $A(t)$ the 'oriented area' of the paralelogram determined by the   vectors $\lambda(t)$ and $\lambda'(t)$ for each $t\in [a,b]$. Show   that the number of turns that $\lambda$ does arount he origin is: $$n(\lambda, 0) = \frac{1}{2\pi} \int_a^b \frac{A(t)}{|\lambda(t)|^2}\  dt$$ The oriented area of a paralelogram such that its sides are given by vectros $v,w\in \mathbb{R^2}$, in this order, is positive when the rotation is from $v\to w$ by the least anti-clockwise angle, negative otherwise, and $0$ is the vectors are linearly dependent As I understood, for each $t$, we have one $\lambda(t)$ and $\lambda'(t)$. We must consider the paralelogram formed by these $2$ vectors for each $t$ and call $A(t)$ its area in the point $t$. But I honestly can't see a relation from this to turns around the origin.","Given the closed path $\lambda:[a,b]\to\mathbb{R^2}-\{0\}$, $C^1$,   call $A(t)$ the 'oriented area' of the paralelogram determined by the   vectors $\lambda(t)$ and $\lambda'(t)$ for each $t\in [a,b]$. Show   that the number of turns that $\lambda$ does arount he origin is: $$n(\lambda, 0) = \frac{1}{2\pi} \int_a^b \frac{A(t)}{|\lambda(t)|^2}\  dt$$ The oriented area of a paralelogram such that its sides are given by vectros $v,w\in \mathbb{R^2}$, in this order, is positive when the rotation is from $v\to w$ by the least anti-clockwise angle, negative otherwise, and $0$ is the vectors are linearly dependent As I understood, for each $t$, we have one $\lambda(t)$ and $\lambda'(t)$. We must consider the paralelogram formed by these $2$ vectors for each $t$ and call $A(t)$ its area in the point $t$. But I honestly can't see a relation from this to turns around the origin.",,"['calculus', 'real-analysis', 'integration', 'differential-geometry']"
8,Find Christoffel Coefficients,Find Christoffel Coefficients,,"Evaluate the Christoffel coefficients of the following surface of revolution: $$X(\theta,s)=(r(s)\cos\theta,r(s)\sin\theta,z(s))$$ So we first start with finding the mertic $X_{\theta}=(-r\sin\theta,r\cos\theta,0)$ $X_{s}=(r'\cos\theta,r'\sin\theta,z')$ $g_{11}=<X_{\theta},X_{\theta}>=r^2\sin^2\theta+r^2\cos^\theta=r^2(\sin^2\theta+\cos^\theta)=r^2$ $g_{12}=g_{21}=<X_{\theta},X_{s}>-rr'\sin\theta \cos\theta+rr'\sin\theta \cos\theta=0$ $g_{22}=<X_{s},X_{s}>=(r')^2\cos^2\theta+(r')^2\sin^2\theta+(z')^2=(r')^2(\cos^2\theta+\sin^2\theta)+(z')^2=(r')^2+(z')^2$ So we get $$g_{ij}=\begin{pmatrix}r^2 & 0\\0 & (r')^2+(z')^2\end{pmatrix}$$ Now in the book I saw that $(r')^2+(z')^2=1$ why is that? can we say that all surface of revolution have the same metric? $$g_{ij}=\begin{pmatrix}r^2 & 0\\0 & 1\end{pmatrix}?$$ Now we have to find $$g_{ij,\theta}=\begin{pmatrix}0 & 0\\0 & 0\end{pmatrix}$$ and $$g_{ij,s}= \begin{pmatrix}2r^2r' & 0\\0 & 0\end{pmatrix}$$ and $$g^{ij}=\frac{1}{r^2}\begin{pmatrix}1 & 0\\0 & r^2\end{pmatrix}$$ Now how do I calculate Christoffel coefficients?",Evaluate the Christoffel coefficients of the following surface of revolution: So we first start with finding the mertic So we get Now in the book I saw that why is that? can we say that all surface of revolution have the same metric? Now we have to find and and Now how do I calculate Christoffel coefficients?,"X(\theta,s)=(r(s)\cos\theta,r(s)\sin\theta,z(s)) X_{\theta}=(-r\sin\theta,r\cos\theta,0) X_{s}=(r'\cos\theta,r'\sin\theta,z') g_{11}=<X_{\theta},X_{\theta}>=r^2\sin^2\theta+r^2\cos^\theta=r^2(\sin^2\theta+\cos^\theta)=r^2 g_{12}=g_{21}=<X_{\theta},X_{s}>-rr'\sin\theta \cos\theta+rr'\sin\theta \cos\theta=0 g_{22}=<X_{s},X_{s}>=(r')^2\cos^2\theta+(r')^2\sin^2\theta+(z')^2=(r')^2(\cos^2\theta+\sin^2\theta)+(z')^2=(r')^2+(z')^2 g_{ij}=\begin{pmatrix}r^2 & 0\\0 & (r')^2+(z')^2\end{pmatrix} (r')^2+(z')^2=1 g_{ij}=\begin{pmatrix}r^2 & 0\\0 & 1\end{pmatrix}? g_{ij,\theta}=\begin{pmatrix}0 & 0\\0 & 0\end{pmatrix} g_{ij,s}= \begin{pmatrix}2r^2r' & 0\\0 & 0\end{pmatrix} g^{ij}=\frac{1}{r^2}\begin{pmatrix}1 & 0\\0 & r^2\end{pmatrix}","['differential-geometry', 'riemannian-geometry', 'surfaces']"
9,"Find $g:\mathbb{R}^m\to V$ such that $g(x)\notin\mathrm{span}\{f_1(x),\ldots,f_k(x)\}$ for all $x\in\mathbb{R}^m$.",Find  such that  for all .,"g:\mathbb{R}^m\to V g(x)\notin\mathrm{span}\{f_1(x),\ldots,f_k(x)\} x\in\mathbb{R}^m","Let $V$ be an $n$-dimensional real vector space and let $$f_1,\ldots,f_k:\mathbb{R}^m\to V$$ be $k<n$ smooth functions. It is intuitively obvious that we can always find a smooth function $g:\mathbb{R}^m\to V$ such that  $$g(x)\notin\mathrm{span}\{f_1(x),\ldots,f_k(x)\}$$ for all $x\in\mathbb{R}^m$. Yet, I can't find a way to prove it. Can anyone help?","Let $V$ be an $n$-dimensional real vector space and let $$f_1,\ldots,f_k:\mathbb{R}^m\to V$$ be $k<n$ smooth functions. It is intuitively obvious that we can always find a smooth function $g:\mathbb{R}^m\to V$ such that  $$g(x)\notin\mathrm{span}\{f_1(x),\ldots,f_k(x)\}$$ for all $x\in\mathbb{R}^m$. Yet, I can't find a way to prove it. Can anyone help?",,"['real-analysis', 'linear-algebra', 'differential-geometry', 'smooth-manifolds']"
10,Two smooth bounded connected domains in $\Bbb R^d$ with the same boundary are identical,Two smooth bounded connected domains in  with the same boundary are identical,\Bbb R^d,"Let $\Omega_1,\Omega_2\subset\Bbb R^d$ be two connected opens such that $\overline{\Omega_1}$ and $\overline{\Omega_2}$ are smooth bounded connected manifolds with boundary. Then I suspect that if $\partial\Omega_1=\partial\Omega_2$, then $\Omega_1=\Omega_2$, however, I don't see how to prove this. Is the correct to solution to put some normal vector field on the boundaries and use that?","Let $\Omega_1,\Omega_2\subset\Bbb R^d$ be two connected opens such that $\overline{\Omega_1}$ and $\overline{\Omega_2}$ are smooth bounded connected manifolds with boundary. Then I suspect that if $\partial\Omega_1=\partial\Omega_2$, then $\Omega_1=\Omega_2$, however, I don't see how to prove this. Is the correct to solution to put some normal vector field on the boundaries and use that?",,"['real-analysis', 'differential-geometry', 'manifolds']"
11,Prove curves are the geodesics,Prove curves are the geodesics,,"Prove that the ellipsoid $\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}=1$ always has at least three geodesics. I think these three geodesics should be cross sections of ${(x,y,0)}$, ${(x,0,z)}$ and ${(0,y,z)}$ with our ellipsoid. And I want prove that the geodesic curvature is zero on these curves. The formula I want to use is $s'k_{g}=(T\times T')N$. So all I have to prove is that $T'//N$. And $N=({\frac{2x}{a^{2}}},\frac{2y}{b^{2}},\frac{2z}{c^{2}})$. But $T'$ is not very easy to get.","Prove that the ellipsoid $\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}=1$ always has at least three geodesics. I think these three geodesics should be cross sections of ${(x,y,0)}$, ${(x,0,z)}$ and ${(0,y,z)}$ with our ellipsoid. And I want prove that the geodesic curvature is zero on these curves. The formula I want to use is $s'k_{g}=(T\times T')N$. So all I have to prove is that $T'//N$. And $N=({\frac{2x}{a^{2}}},\frac{2y}{b^{2}},\frac{2z}{c^{2}})$. But $T'$ is not very easy to get.",,['differential-geometry']
12,How to show that the map $\pi: z\mapsto ziz^*$ is onto $S^2$?,How to show that the map  is onto ?,\pi: z\mapsto ziz^* S^2,"We identify $S^3$ with the unit quaternions and $S^2$ the unit pure quaternions, and the conjugate of $z=a+bi+cj+dk$ is defined as $z^*=a-bi-cj-dk$. Then we consider the map $$\pi:S^3\ni z\mapsto ziz^*\in S^2.$$ The reason why $\pi$ maps into $S^2$ is given in this answer , but I'm stuck as to how to show it is surjective (in fact, a surjective submersion)? Thanks to @Xipan Xiao's comment now I understand why $\pi$ is surjective: in fact for each $p\in S^2$ we can pick $\tilde q=\cos(\theta/2)+q\sin(\theta/2)\in S^3,\, q=e_1\times p/\|e_1\times p\|\in S^2$ so that $p=\tilde qi\tilde q^*$. However, I'm still quite at a loss how to show $\pi$ is a submersion ? Can we possibly avoid explicitly expanding the quaternions and using the stereographical projection charts to compute the Jacobian?","We identify $S^3$ with the unit quaternions and $S^2$ the unit pure quaternions, and the conjugate of $z=a+bi+cj+dk$ is defined as $z^*=a-bi-cj-dk$. Then we consider the map $$\pi:S^3\ni z\mapsto ziz^*\in S^2.$$ The reason why $\pi$ maps into $S^2$ is given in this answer , but I'm stuck as to how to show it is surjective (in fact, a surjective submersion)? Thanks to @Xipan Xiao's comment now I understand why $\pi$ is surjective: in fact for each $p\in S^2$ we can pick $\tilde q=\cos(\theta/2)+q\sin(\theta/2)\in S^3,\, q=e_1\times p/\|e_1\times p\|\in S^2$ so that $p=\tilde qi\tilde q^*$. However, I'm still quite at a loss how to show $\pi$ is a submersion ? Can we possibly avoid explicitly expanding the quaternions and using the stereographical projection charts to compute the Jacobian?",,"['differential-geometry', 'algebraic-topology', 'quaternions', 'hopf-fibration']"
13,"What is meant by ""The Levi-Civita Connection is an $\mathfrak{so}(n)$-Valued 1-form""?","What is meant by ""The Levi-Civita Connection is an -Valued 1-form""?",\mathfrak{so}(n),"this is a statement that I've seen around, and I thought it's time that I understand it. I know that the LCC is locally given by a matrix $ \omega = (\omega_i^j)$ of 1-forms in a preferred frame $e_i$, so that $$ \nabla f_ie_i  =   df_i \otimes e_i + f_i \omega_i^j \otimes e_j   $$ for any local smooth functions $f_i$. Then, $\omega$ is a matrix representing a linear map on each tangent space. Now, ""$\nabla$ is an $\mathfrak{so}(n)$-valued 1-form"" suggests to me that each $(\nabla v)|_p$ is in $\mathfrak{so}(T_pM)$ , but I know that this is only true for $v$ a Killing field. But perhaps I'm getting confused between $\nabla$ as an object and its representation $\omega$ in a particular frame. So, my next guess is that it means that, in some choices of local frame $e_i$, the matrix $\omega_i^j(v)$ is skew-symmetric for any $v$. Orthormal frame is the probable condition. But this would mean, in particular, that each $\nabla e_i$ is skew-symmetric, since if $v = e_i$, there are no nonconstant components of $v$ to worry about, and '$\nabla = \omega$'. Then again, we'd be at the statement that all the $e_i$ are (local) Killing fields, which is just rubbish - on a generic Riemannian manifold, there are no nontrivial local Killing fields, if I remember right. So, what does ""$\omega$ is $\mathfrak{so}$-valued"" mean? Any help would be massively appreciated.","this is a statement that I've seen around, and I thought it's time that I understand it. I know that the LCC is locally given by a matrix $ \omega = (\omega_i^j)$ of 1-forms in a preferred frame $e_i$, so that $$ \nabla f_ie_i  =   df_i \otimes e_i + f_i \omega_i^j \otimes e_j   $$ for any local smooth functions $f_i$. Then, $\omega$ is a matrix representing a linear map on each tangent space. Now, ""$\nabla$ is an $\mathfrak{so}(n)$-valued 1-form"" suggests to me that each $(\nabla v)|_p$ is in $\mathfrak{so}(T_pM)$ , but I know that this is only true for $v$ a Killing field. But perhaps I'm getting confused between $\nabla$ as an object and its representation $\omega$ in a particular frame. So, my next guess is that it means that, in some choices of local frame $e_i$, the matrix $\omega_i^j(v)$ is skew-symmetric for any $v$. Orthormal frame is the probable condition. But this would mean, in particular, that each $\nabla e_i$ is skew-symmetric, since if $v = e_i$, there are no nonconstant components of $v$ to worry about, and '$\nabla = \omega$'. Then again, we'd be at the statement that all the $e_i$ are (local) Killing fields, which is just rubbish - on a generic Riemannian manifold, there are no nontrivial local Killing fields, if I remember right. So, what does ""$\omega$ is $\mathfrak{so}$-valued"" mean? Any help would be massively appreciated.",,"['differential-geometry', 'riemannian-geometry', 'connections']"
14,Curve shortening flow of a $C^1$ curve,Curve shortening flow of a  curve,C^1,"I am reading something which says that a closed and embedded $C^1$ curve immediately becomes smooth under the curve shortening flow. I am familiar with this result for $C^2$ curves, but was under the impression curve shortening flow isn't necessarily even defined for $C^1$ curves, since the curvature may not be continuous. Could someone perhaps cite this result for $C^1$ curves, or explain what I've misunderstood? Thanks","I am reading something which says that a closed and embedded $C^1$ curve immediately becomes smooth under the curve shortening flow. I am familiar with this result for $C^2$ curves, but was under the impression curve shortening flow isn't necessarily even defined for $C^1$ curves, since the curvature may not be continuous. Could someone perhaps cite this result for $C^1$ curves, or explain what I've misunderstood? Thanks",,"['differential-geometry', 'reference-request', 'partial-differential-equations', 'plane-curves', 'mean-curvature-flows']"
15,Irreducible Components of Higher Order Tensors,Irreducible Components of Higher Order Tensors,,"In Richard Hamilton's first paper on the Ricci Flow, there's a proposition (Lemma 11.6; see page 34 of this document https://projecteuclid.org/download/pdf_1/euclid.jdg/1214436922 ) who's proof involves taking the tensor $\nabla Rc$ and splitting it into certain components: $$\nabla_iR_{jk}=E_{ijk}+F_{ijk} $$ The essential point is that $F$ is trace-free with respect to any two indices. So $F$ is to $\nabla Rc$ what the Weyl curvature tensor is to the Riemann curvature tensor. (I imagine Hamilton had something like this analogy in mind when thinking this through.) One can reason in an ad hoc way as follows: Based on the traces of $\nabla Rc$ and the symmetry of the $jk$ indices, one can guess that $$E_{ijk}=a\nabla_iRg_{jk}+b(\nabla_jRg_{ik}+\nabla_kRg_{ij})$$ and solve for the constants $a$ and $b$ using that $F$ should be trace-free. My question is whether there is a well-established procedure or theorem which tells you how any 3-tensor, or even k-tensor, breaks up into these more fundamental components. For example, I'm certainly aware of how this works for a 2-tensor: $$a_{ij}=\textstyle\frac{tr(a)}{n}g_{ij}+ [\textstyle\frac{1}{2}(a_{ij}+a_{ji})-\textstyle\frac{tr(a)}{n}g_{ij}]+\textstyle\frac{1}{2}(a_{ij}-a_{ji})$$ and that these components are irreducible in the sense of the representation theory of the orthogonal group on tensors. (It's my suspicion that the decomposition $E+F$ above is not irreducible in this sense, as I would naively expect more symmetries at the level of indices.)","In Richard Hamilton's first paper on the Ricci Flow, there's a proposition (Lemma 11.6; see page 34 of this document https://projecteuclid.org/download/pdf_1/euclid.jdg/1214436922 ) who's proof involves taking the tensor $\nabla Rc$ and splitting it into certain components: $$\nabla_iR_{jk}=E_{ijk}+F_{ijk} $$ The essential point is that $F$ is trace-free with respect to any two indices. So $F$ is to $\nabla Rc$ what the Weyl curvature tensor is to the Riemann curvature tensor. (I imagine Hamilton had something like this analogy in mind when thinking this through.) One can reason in an ad hoc way as follows: Based on the traces of $\nabla Rc$ and the symmetry of the $jk$ indices, one can guess that $$E_{ijk}=a\nabla_iRg_{jk}+b(\nabla_jRg_{ik}+\nabla_kRg_{ij})$$ and solve for the constants $a$ and $b$ using that $F$ should be trace-free. My question is whether there is a well-established procedure or theorem which tells you how any 3-tensor, or even k-tensor, breaks up into these more fundamental components. For example, I'm certainly aware of how this works for a 2-tensor: $$a_{ij}=\textstyle\frac{tr(a)}{n}g_{ij}+ [\textstyle\frac{1}{2}(a_{ij}+a_{ji})-\textstyle\frac{tr(a)}{n}g_{ij}]+\textstyle\frac{1}{2}(a_{ij}-a_{ji})$$ and that these components are irreducible in the sense of the representation theory of the orthogonal group on tensors. (It's my suspicion that the decomposition $E+F$ above is not irreducible in this sense, as I would naively expect more symmetries at the level of indices.)",,"['differential-geometry', 'representation-theory', 'riemannian-geometry']"
16,"For a lie group $G$ with bi-invariant metric, and left-invariant fields $X,U,V$, $\langle [U,X],V\rangle = -\langle U,[V,X]\rangle$","For a lie group  with bi-invariant metric, and left-invariant fields ,","G X,U,V \langle [U,X],V\rangle = -\langle U,[V,X]\rangle","Specifically, I'm somewhat confused by the answer to this question here , which I reproduce below: Let $g$ denote the metric of $G$. The right invariance of $g$ guarantees that   $$R^*_{\exp (tX)}g=g,  \forall t \in \mathbb{R}. $$   On the other hand, $t\to R_{exp(tX)}$ is the flow of X, we have $\mathcal{L}_Xg=0$, where $\mathcal{L}_Xg$ denotes the Lie derivative of $g$ in the direction X.    $$(\mathcal{L}_Xg)(U,V)=X(g(U,V))-g(\mathcal{L}_XU,V)-g(U,\mathcal{L}_YZ) \\ =-\langle[X,U],V\rangle-\langle U,[X,V]\rangle$$ where we use the invariance of $g$ at last equal to conclude that $g(U,V)$, seen as function of $G$, is constant in each connected component of $G$. My question is, why can we assume that $\mathcal{L}_X g = 0$?","Specifically, I'm somewhat confused by the answer to this question here , which I reproduce below: Let $g$ denote the metric of $G$. The right invariance of $g$ guarantees that   $$R^*_{\exp (tX)}g=g,  \forall t \in \mathbb{R}. $$   On the other hand, $t\to R_{exp(tX)}$ is the flow of X, we have $\mathcal{L}_Xg=0$, where $\mathcal{L}_Xg$ denotes the Lie derivative of $g$ in the direction X.    $$(\mathcal{L}_Xg)(U,V)=X(g(U,V))-g(\mathcal{L}_XU,V)-g(U,\mathcal{L}_YZ) \\ =-\langle[X,U],V\rangle-\langle U,[X,V]\rangle$$ where we use the invariance of $g$ at last equal to conclude that $g(U,V)$, seen as function of $G$, is constant in each connected component of $G$. My question is, why can we assume that $\mathcal{L}_X g = 0$?",,"['differential-geometry', 'lie-groups', 'riemannian-geometry']"
17,Uniqueness of differentiable structure,Uniqueness of differentiable structure,,"I'm trying to solve the following question: Let $F:M\longrightarrow N$ be a bijective map. Prove that, if M is an $n$-dimensional differentiable manifold, then $N$ admits a unique differentiable structure making $F$ a diffeomorphism. I think that the differentiable structure we are looking for would be given by the atlas $A=\{(F(U_a), F|_{U_a})\}_{a\in T}$, where $T$ is the topology induced in N by F, forcing $F$ to be a homeomorphism. But how can I prove the uniqueness?","I'm trying to solve the following question: Let $F:M\longrightarrow N$ be a bijective map. Prove that, if M is an $n$-dimensional differentiable manifold, then $N$ admits a unique differentiable structure making $F$ a diffeomorphism. I think that the differentiable structure we are looking for would be given by the atlas $A=\{(F(U_a), F|_{U_a})\}_{a\in T}$, where $T$ is the topology induced in N by F, forcing $F$ to be a homeomorphism. But how can I prove the uniqueness?",,['differential-geometry']
18,Differential forms and homogeneous functions,Differential forms and homogeneous functions,,"The question is: Let be g: $\mathbb{R}^{3}  \rightarrow  \mathbb{R}$ homogeneous of degree k, i.e, $g(tx,ty,tz) = t^{k}g(x,y,z), t>0$ and $(x,y,z) \in \mathbb{R}^{3}$. a) Prove that $xg_{x} + yg_{y} + zg_{z} = kg$ (The Euler's relation). This part is ok ! but: b) Let be $ w = adx + bdy + cdz $ where a, b and c are homogeneous of degree k and $dw = 0$ . Show that $w = df$ where $$ f = \frac{xa + yb + zc}{k+1}$$ The hint is : notice that $dw=0$ implies $ b_{x} = a_{y} , c_{x} = a_{z} , b_{z} = c_{y}$ (Partial Derivaties) and apply Euler's relation. Well, i tried to do the follow: $$ df = \frac{1}{k+1} d(xa + yb + zc) = $$ (omitting the denominator) $d(xa) + d(yb) + d(zc),$ and $d(xa) = \sum  \frac{\partial xa}{\partial x_{i}}dx_{i} = adx + a_{xx}dx + a_{xy}dy + a_{xz}dz$ $d(yb) = \sum  \frac{\partial yb}{\partial x_{i}}= bdy + b_{yx}dx + b_{yy}dy + b_{yz}dz$ $d(zc) = cdz + c_{zx}dx + c_{zy}dy + c_{zz}dz$ Is this alright ?  Now, how can i use the hint ? Thank's !","The question is: Let be g: $\mathbb{R}^{3}  \rightarrow  \mathbb{R}$ homogeneous of degree k, i.e, $g(tx,ty,tz) = t^{k}g(x,y,z), t>0$ and $(x,y,z) \in \mathbb{R}^{3}$. a) Prove that $xg_{x} + yg_{y} + zg_{z} = kg$ (The Euler's relation). This part is ok ! but: b) Let be $ w = adx + bdy + cdz $ where a, b and c are homogeneous of degree k and $dw = 0$ . Show that $w = df$ where $$ f = \frac{xa + yb + zc}{k+1}$$ The hint is : notice that $dw=0$ implies $ b_{x} = a_{y} , c_{x} = a_{z} , b_{z} = c_{y}$ (Partial Derivaties) and apply Euler's relation. Well, i tried to do the follow: $$ df = \frac{1}{k+1} d(xa + yb + zc) = $$ (omitting the denominator) $d(xa) + d(yb) + d(zc),$ and $d(xa) = \sum  \frac{\partial xa}{\partial x_{i}}dx_{i} = adx + a_{xx}dx + a_{xy}dy + a_{xz}dz$ $d(yb) = \sum  \frac{\partial yb}{\partial x_{i}}= bdy + b_{yx}dx + b_{yy}dy + b_{yz}dz$ $d(zc) = cdz + c_{zx}dx + c_{zy}dy + c_{zz}dz$ Is this alright ?  Now, how can i use the hint ? Thank's !",,"['differential-geometry', 'differential-forms', 'differential']"
19,Orientable manifold using definition.,Orientable manifold using definition.,,"I'm reading the Do Carmo book in the section of the orientable surfaces, but I still don't understand the idea of orientability , because the examples he uses to clarify the concept doesn't use explicitely the definition he gives, so I want to ask you if anyone could explain me with an example using the definition he uses for orientability The definition he uses is: A regular surface $S$ is called orientable if it is possible to cover it with a family of coordinate neighborhoods in such way that if point $p\in S$ belongs to two neighborhoods of this family, then the change of coordinates has positive Jacobian at $p$. The choice of such family is called an orientation of $S$ and $S$, in this case, is called oriented . EDIT: The examples Do Carmo gives are these ones: A surface which is the graph of a differentiable function (cf. Sec. 2-2, Prop. I) is an orientable surface. In fact, all surfaces which can be covered by one coordinate neighborhood are trivially orientable. The sphere is an orientable surface. Instead of proceeding to a direct calculation, let us resort to a general argument. The sphere can be covered by two coordinate neighborhoods, with parameters $(u, v)$ (using stereographic projection) and $(\overline{u}, \overline{v})$, in such a way that the intersection W of these neighborhoods (the sphere minus two points) is a connected set. Fix a point $p$ in $W$. If the Jacobian of the coordinate change at $p$ is negative, we interchange $u$  and $v$ in the first system, and the Jacobian becomes positive. Since the Jacobian is different from zero in $W$ and positive at $p\in W$, it follows from the connectedness of $W$ that the Jacobian is everywhere positive. There exists, therefore, a family of coordinate neighborhoods satisfying Def. I, and so the sphere is orientable.","I'm reading the Do Carmo book in the section of the orientable surfaces, but I still don't understand the idea of orientability , because the examples he uses to clarify the concept doesn't use explicitely the definition he gives, so I want to ask you if anyone could explain me with an example using the definition he uses for orientability The definition he uses is: A regular surface $S$ is called orientable if it is possible to cover it with a family of coordinate neighborhoods in such way that if point $p\in S$ belongs to two neighborhoods of this family, then the change of coordinates has positive Jacobian at $p$. The choice of such family is called an orientation of $S$ and $S$, in this case, is called oriented . EDIT: The examples Do Carmo gives are these ones: A surface which is the graph of a differentiable function (cf. Sec. 2-2, Prop. I) is an orientable surface. In fact, all surfaces which can be covered by one coordinate neighborhood are trivially orientable. The sphere is an orientable surface. Instead of proceeding to a direct calculation, let us resort to a general argument. The sphere can be covered by two coordinate neighborhoods, with parameters $(u, v)$ (using stereographic projection) and $(\overline{u}, \overline{v})$, in such a way that the intersection W of these neighborhoods (the sphere minus two points) is a connected set. Fix a point $p$ in $W$. If the Jacobian of the coordinate change at $p$ is negative, we interchange $u$  and $v$ in the first system, and the Jacobian becomes positive. Since the Jacobian is different from zero in $W$ and positive at $p\in W$, it follows from the connectedness of $W$ that the Jacobian is everywhere positive. There exists, therefore, a family of coordinate neighborhoods satisfying Def. I, and so the sphere is orientable.",,"['differential-geometry', 'intuition', 'orientation']"
20,Proof of Killing's Equation,Proof of Killing's Equation,,"The problem: I am trying to prove that, for a Riemannian manifold $(M,\langle\ , \ \rangle)$, $X \in \Gamma(TM)$ is a Killing field (i.e. one for which $\langle u,v \rangle_{p \in M} = \langle (d \phi^X_{t})_{\phi^{X}(t, p)} (u), (d \phi^X_{t})_{\phi^{X}(t, p)} (v)  \rangle_{\phi^{X}(t, p)}$, where $\phi^{X}_{t} = \phi^{X}(t,) $ is the local flow of $X$) if $\forall Y,Z \in \Gamma(TM)$ $$ \langle \nabla_Y X, Z \rangle + \langle \nabla_Z X, Y \rangle = 0, $$ where $\nabla$ is the Levi-Civita connection. My work so far: By using the compatibility and torsion-freeness of the connection, it is easy to reduce this assumption to $$ X \langle Y,Z \rangle = \langle [X,Z],Y \rangle + \langle [X,Y],Z \rangle. $$ Then, if we choose $Y,Z$ such that $Y(p) = u$, $Z(p) = v$, and remembering that $X(p) = \frac{d}{dt}\Big|_{t=0} \phi^{X}(t,p)$, our LHS evaluated at $p$ becomes $$ \frac{d}{dt} \Big|_{t=0} \langle Y(\phi^{X}(t, p)), Z(\phi^{X}(t, p)) \rangle_{\phi^{X}(t, p)}. $$ Our RHS at $p$ becomes $$ \langle [X,Z](p),Y(p) \rangle_p + \langle [X,Y](p),Z(p) \rangle_p . $$ At this point I start looking at the definition of the Lie bracket: $$ [X,Y](p) = \frac{d}{dt}\Big|_{t=0} d \phi^X_{-t}(Y(\phi^X(t,p))), $$ so our RHS becomes $$ \langle \frac{d}{dt}\Big|_{t=0} d \phi^X_{-t}(Z(\phi^X(t,p))), Y(p) \rangle_p + \langle \frac{d}{dt}\Big|_{t=0} d \phi^X_{-t}(Y(\phi^X(t,p))) , Z(p) \rangle_p,$$ but I am having a hard time completing the proof. My hunch is that we want to show the RHS at $p$ is zero (I could be wrong here). Any hints or pointers would be very welcome. Apologies if my notation is a bit untidy. There is also probably a much easier way to do this, so any hints away from my solution are also welcome.","The problem: I am trying to prove that, for a Riemannian manifold $(M,\langle\ , \ \rangle)$, $X \in \Gamma(TM)$ is a Killing field (i.e. one for which $\langle u,v \rangle_{p \in M} = \langle (d \phi^X_{t})_{\phi^{X}(t, p)} (u), (d \phi^X_{t})_{\phi^{X}(t, p)} (v)  \rangle_{\phi^{X}(t, p)}$, where $\phi^{X}_{t} = \phi^{X}(t,) $ is the local flow of $X$) if $\forall Y,Z \in \Gamma(TM)$ $$ \langle \nabla_Y X, Z \rangle + \langle \nabla_Z X, Y \rangle = 0, $$ where $\nabla$ is the Levi-Civita connection. My work so far: By using the compatibility and torsion-freeness of the connection, it is easy to reduce this assumption to $$ X \langle Y,Z \rangle = \langle [X,Z],Y \rangle + \langle [X,Y],Z \rangle. $$ Then, if we choose $Y,Z$ such that $Y(p) = u$, $Z(p) = v$, and remembering that $X(p) = \frac{d}{dt}\Big|_{t=0} \phi^{X}(t,p)$, our LHS evaluated at $p$ becomes $$ \frac{d}{dt} \Big|_{t=0} \langle Y(\phi^{X}(t, p)), Z(\phi^{X}(t, p)) \rangle_{\phi^{X}(t, p)}. $$ Our RHS at $p$ becomes $$ \langle [X,Z](p),Y(p) \rangle_p + \langle [X,Y](p),Z(p) \rangle_p . $$ At this point I start looking at the definition of the Lie bracket: $$ [X,Y](p) = \frac{d}{dt}\Big|_{t=0} d \phi^X_{-t}(Y(\phi^X(t,p))), $$ so our RHS becomes $$ \langle \frac{d}{dt}\Big|_{t=0} d \phi^X_{-t}(Z(\phi^X(t,p))), Y(p) \rangle_p + \langle \frac{d}{dt}\Big|_{t=0} d \phi^X_{-t}(Y(\phi^X(t,p))) , Z(p) \rangle_p,$$ but I am having a hard time completing the proof. My hunch is that we want to show the RHS at $p$ is zero (I could be wrong here). Any hints or pointers would be very welcome. Apologies if my notation is a bit untidy. There is also probably a much easier way to do this, so any hints away from my solution are also welcome.",,"['differential-geometry', 'riemannian-geometry', 'isometry', 'lie-derivative']"
21,Definition of submanifold.,Definition of submanifold.,,"In my textbook, submanifold is defined as follows: If $X$ and $Y$ are both manifolds in $\mathbb{R}^n$ and $Y\subset X,$ then $Y$ is a submanifold of $X.$ I think that the topology of $X$ and $Y$ should not be irrelevant and some sort of condition such as ""the topology of $Y$ is the subspace topology"" is needed. In addition, I think that not only such a topological condition, but also a condition which is relevant to the smooth structures of $X$ and $Y$ is needed. What is the correct definition of submanifold?","In my textbook, submanifold is defined as follows: If $X$ and $Y$ are both manifolds in $\mathbb{R}^n$ and $Y\subset X,$ then $Y$ is a submanifold of $X.$ I think that the topology of $X$ and $Y$ should not be irrelevant and some sort of condition such as ""the topology of $Y$ is the subspace topology"" is needed. In addition, I think that not only such a topological condition, but also a condition which is relevant to the smooth structures of $X$ and $Y$ is needed. What is the correct definition of submanifold?",,['differential-geometry']
22,Connection on Tautological Bundle over $\mathbb{C}P^1$.,Connection on Tautological Bundle over .,\mathbb{C}P^1,"I'm trying to compute the Chern-class of the bundle $$\gamma = \{(c,\ell): c \in \ell \} \subseteq \mathbb{C}^2 \times \mathbb{C}P^1$$ over $\mathbb{C}P^1$. I'm running into a problem defining an affine connection on this bundle. Any tips? So far I've tried to use the bundle $\mathbb{C}^2 \times \mathbb{C}P^1$. I don't see a natural way to take a derivative of a section of this bundle over $\mathbb{C}P^1$. And yes, this computation is easy via topological argument, but I'm interested in the Chern-Weil computation.","I'm trying to compute the Chern-class of the bundle $$\gamma = \{(c,\ell): c \in \ell \} \subseteq \mathbb{C}^2 \times \mathbb{C}P^1$$ over $\mathbb{C}P^1$. I'm running into a problem defining an affine connection on this bundle. Any tips? So far I've tried to use the bundle $\mathbb{C}^2 \times \mathbb{C}P^1$. I don't see a natural way to take a derivative of a section of this bundle over $\mathbb{C}P^1$. And yes, this computation is easy via topological argument, but I'm interested in the Chern-Weil computation.",,"['differential-geometry', 'algebraic-topology', 'characteristic-classes']"
23,illustrative book of differential geometry,illustrative book of differential geometry,,"I look for a book of differential geometry which emphasizes the illustration of the modern basic concepts and theorems and their ""geometric aspects"" (such as smooth manifolds, differential forms, coordinatefree Integration, orientation, geodesics, Riemannian metrics, curvature,...) to examples rather than developing new concepts and theorems. Especially (counter)examples who may motivated the modern basics are my key interest. If you know some algebraic geometry literature, I look for a similar book as ""Geometry of Schemes"" by Eisenbud and Harris but now for differential geometry.","I look for a book of differential geometry which emphasizes the illustration of the modern basic concepts and theorems and their ""geometric aspects"" (such as smooth manifolds, differential forms, coordinatefree Integration, orientation, geodesics, Riemannian metrics, curvature,...) to examples rather than developing new concepts and theorems. Especially (counter)examples who may motivated the modern basics are my key interest. If you know some algebraic geometry literature, I look for a similar book as ""Geometry of Schemes"" by Eisenbud and Harris but now for differential geometry.",,"['differential-geometry', 'reference-request', 'differential-topology']"
24,Tangent space of Jets pace,Tangent space of Jets pace,,"I would like to understand what the tangent space of a jet space is. For example if I have a map $f:X \to Y$, where $X$ and $Y$ are manifolds and I have the k-jet extension $j^kf(x):X \to J^k_x(X,Y)$ which can be understood a section into the jet space, then how can I picture $T_{j^kf(x)}J^k(X,Y)$. Intuitively I would say that this should be related with the space $J^{k-1}(X,Y)$ but I can't get my head around this. If somebody knows a good source for this topic I would be really thankful.","I would like to understand what the tangent space of a jet space is. For example if I have a map $f:X \to Y$, where $X$ and $Y$ are manifolds and I have the k-jet extension $j^kf(x):X \to J^k_x(X,Y)$ which can be understood a section into the jet space, then how can I picture $T_{j^kf(x)}J^k(X,Y)$. Intuitively I would say that this should be related with the space $J^{k-1}(X,Y)$ but I can't get my head around this. If somebody knows a good source for this topic I would be really thankful.",,"['differential-geometry', 'differential-topology', 'jet-bundles']"
25,Product of symplectic manifold is symplectic,Product of symplectic manifold is symplectic,,"Assume ($M_1,\omega_1 $) and ($M_2,\omega_2)$ are symplectic manifolds. Consider $M_1\times M_2$. I want to show this is also symplectic manifold. Let $p_1, p_2$ denote the projections. Then what I need is $p_1^*(\omega_1)^n \wedge p_2^*(\omega_2)^n$ is non-zero. I am stuck here. I guess $p_1^*(\omega_1 ^n)$ and $p_2^*(\omega_2 ^n)$ are both nonzero since $\omega_i ^n$ is nonzero by non degeneracy of $\omega_i$ and $p_i$ is submersion. But how do I know $p_1^*(\omega_1)^n \wedge p_2^*(\omega_2)^n$ is non-zero?","Assume ($M_1,\omega_1 $) and ($M_2,\omega_2)$ are symplectic manifolds. Consider $M_1\times M_2$. I want to show this is also symplectic manifold. Let $p_1, p_2$ denote the projections. Then what I need is $p_1^*(\omega_1)^n \wedge p_2^*(\omega_2)^n$ is non-zero. I am stuck here. I guess $p_1^*(\omega_1 ^n)$ and $p_2^*(\omega_2 ^n)$ are both nonzero since $\omega_i ^n$ is nonzero by non degeneracy of $\omega_i$ and $p_i$ is submersion. But how do I know $p_1^*(\omega_1)^n \wedge p_2^*(\omega_2)^n$ is non-zero?",,"['differential-geometry', 'manifolds', 'symplectic-geometry']"
26,The Whitney sphere immersion,The Whitney sphere immersion,,"The standard unit sphere $S^n = \{ (x,y) \in \mathbb R^n \times \mathbb R  \mid \lvert x \rvert^2 + y^2  = 1\}$ can be immersed inside $\mathbb C^n$ through the formula $(x,y) \mapsto (1+iy)x$. This is a Lagrangian immersion with a double point at the poles $(0,\pm 1)$. In the special case $n = 1$, this yields a figure 8 in the plane. What is an easy way to see that this formula does indeed yield an immersion? The case $n = 1$ is easy enough, but things get ugly for arbitrary $n$. I've tried using generalized spherical coordinates, but the matrix of the differential in these coordinates is nasty, and it's unclear to me why it has maximal rank. Alternatively, viewed as a map $\mathbb R^{n+1} \to \mathbb R^{2n}$, the immersion has a nice enough differential, but these rectangular coordinates are not adapted to the tangent bundle of the sphere.","The standard unit sphere $S^n = \{ (x,y) \in \mathbb R^n \times \mathbb R  \mid \lvert x \rvert^2 + y^2  = 1\}$ can be immersed inside $\mathbb C^n$ through the formula $(x,y) \mapsto (1+iy)x$. This is a Lagrangian immersion with a double point at the poles $(0,\pm 1)$. In the special case $n = 1$, this yields a figure 8 in the plane. What is an easy way to see that this formula does indeed yield an immersion? The case $n = 1$ is easy enough, but things get ugly for arbitrary $n$. I've tried using generalized spherical coordinates, but the matrix of the differential in these coordinates is nasty, and it's unclear to me why it has maximal rank. Alternatively, viewed as a map $\mathbb R^{n+1} \to \mathbb R^{2n}$, the immersion has a nice enough differential, but these rectangular coordinates are not adapted to the tangent bundle of the sphere.",,"['differential-geometry', 'differential-topology', 'symplectic-geometry']"
27,Weak Whitney embedding theorem,Weak Whitney embedding theorem,,"I am currently reading Shigeyuki Morita's ""Geometry of Differential Forms"" and I have found one of his proofs to be a little bit on the difficult side. On page 36 he states the theorem "" An arbitrary compact $\textit{C} \ ^\infty$ manifold M can be embedded into $R^N$ for sufficiently large N"". The way he goes about proving the theorem goes as follows. He uses a finite collection of coordinate neighborhoods $\big\{(U_i,\phi_i)\big\}_{i=1}^r$ such that each $\phi_i:U\to R^n$ is an open disk $D(2)$ of radius 2 with center at the origin, and if we put $V_i=\phi_{i}^{-1}(D(1))$, $\big\{V_i\big\}_{i=1}^r$ is already a covering of M. Do not worry about the existence of such an atlas, it follows form the paracompactness of all manifolds and the fact that M itself is compact. Now he next defines for each $i$ a $C^\infty$ map $f_i:M\to S^n$ with the following two conditions: (i) the restriction of $f_i$ to $V_i$ is a diffeomorphism from $V_i$ onto the southern hemisphere $\big\{x\in S^n: x_{n+1} < 0\big\}$ of $S^n$ and (ii) $f_i$ maps the complement of $V_i$ to the northern hemisphere. He asks the reader to provide the map but I can't figure out how to construct such a map. A diffeomorphism from $V_i$ to the southern hemisphere is simple but I can't find a function which satisfies property (ii) as well as property (i). Any help is greatly appreciated!","I am currently reading Shigeyuki Morita's ""Geometry of Differential Forms"" and I have found one of his proofs to be a little bit on the difficult side. On page 36 he states the theorem "" An arbitrary compact $\textit{C} \ ^\infty$ manifold M can be embedded into $R^N$ for sufficiently large N"". The way he goes about proving the theorem goes as follows. He uses a finite collection of coordinate neighborhoods $\big\{(U_i,\phi_i)\big\}_{i=1}^r$ such that each $\phi_i:U\to R^n$ is an open disk $D(2)$ of radius 2 with center at the origin, and if we put $V_i=\phi_{i}^{-1}(D(1))$, $\big\{V_i\big\}_{i=1}^r$ is already a covering of M. Do not worry about the existence of such an atlas, it follows form the paracompactness of all manifolds and the fact that M itself is compact. Now he next defines for each $i$ a $C^\infty$ map $f_i:M\to S^n$ with the following two conditions: (i) the restriction of $f_i$ to $V_i$ is a diffeomorphism from $V_i$ onto the southern hemisphere $\big\{x\in S^n: x_{n+1} < 0\big\}$ of $S^n$ and (ii) $f_i$ maps the complement of $V_i$ to the northern hemisphere. He asks the reader to provide the map but I can't figure out how to construct such a map. A diffeomorphism from $V_i$ to the southern hemisphere is simple but I can't find a function which satisfies property (ii) as well as property (i). Any help is greatly appreciated!",,"['differential-geometry', 'differential-topology']"
28,How to induce a metric on $S^3$ from the transitive group action of $SO(4)$?,How to induce a metric on  from the transitive group action of ?,S^3 SO(4),"Picture below is from the Tao's blogs , I understand the Killing form as  $$ B(x,y)=\operatorname{trace}(\operatorname{ad}(x)\operatorname{ad}(y)) $$ $SO(4)$ is the group acting on $S^3$. I don't understand the content above red line.","Picture below is from the Tao's blogs , I understand the Killing form as  $$ B(x,y)=\operatorname{trace}(\operatorname{ad}(x)\operatorname{ad}(y)) $$ $SO(4)$ is the group acting on $S^3$. I don't understand the content above red line.",,"['differential-geometry', 'lie-groups', 'lie-algebras', 'riemannian-geometry']"
29,Is this reasoning correct? Connection with torsion on SO(3),Is this reasoning correct? Connection with torsion on SO(3),,"Let say I'm in $SO(3)$. In the tangent space at the identity I define a inner product, i.e. $$g_{0}\left(X,\,Y\right)=\frac{1}{2}\mbox{Tr}\left(X^{T}Y\right),$$ Then I define a leftinvariant metric defined  for every point $R$ in $SO(3)$ through the left action, i.e. $$g\left(X,\,Y\right)=g_{0}\left(L_{R^{-1}*}\left(X\right),\,L_{R^{-1}*}\left(Y\right)\right).$$ It's clearly left invariant by construction. Now let's say I take the following base $\left\{\left(E_{1}\right)_{R},...,\left(E_{n}\right)_{R}\right\} $ for the point of the tangent space in $R$ where $$\left(E_{1}\right)_{R}=L_{R*}\left(\left(E_{1}\right)_{\mathbb{1}}\right)$$  where of course $\left\{ \left(E_{1}\right)_{\mathbb{1}},...,\left(E_{n}\right)_{\mathbb{1}}\right\} $ is the canonical base at the identity. Now it should be that  $$g\left(\left(E_{i}\right)_{R},\,\left(E_{j}\right)_{R}\right)	=	\frac{1}{2}\mbox{Tr}\left(\left(R\left(E_{i}\right)_{\mathbb{1}}\right)^{T}\left(R^{-1}\right)^{T}\left(R^{-1}\right)\left(R\left(E_{j}\right)_{\mathbb{1}}\right)\right)= 	g\left(\left(E_{i}\right)_{\mathbb{1}},\,\left(E_{j}\right)_{\mathbb{1}}\right),$$ So that the coefficient of the metric in the base given by $ \left\{ \left(E_{1}\right)_{R},...,\left(E_{n}\right)_{R}\right\}$ are constant. Being that the Christoffel Symbols are identically zero and I have that $\nabla_{X}Y$ is nothing else that the partial derivative in the point. Defining the torsion $$T\left(X,Y\right)=\nabla_{X}Y-\nabla_{Y}X-\left[X,Y\right].$$ I then have $$T\left(X,Y\right)=-\left[X,Y\right],$$ and therefore in the base  $\left\{ \left(E_{1}\right)_{R},...,\left(E_{n}\right)_{R}\right\}$  the coefficient of the tensor of torsion are $$T_{bc}^{a}=-\epsilon_{bc}^{a},$$ where in general since it works for every Lie Group the coefficient should be che structure constante of the lie algebra for the specific base choosen. Is this reasoning right? What did I get wrong? I found in a book the same construction to find the Curvature of the Levi-Civita connection and so -since the Levi-Civita Connection has zero torsion- I'm quite sure I've done something wrong somewhere....","Let say I'm in $SO(3)$. In the tangent space at the identity I define a inner product, i.e. $$g_{0}\left(X,\,Y\right)=\frac{1}{2}\mbox{Tr}\left(X^{T}Y\right),$$ Then I define a leftinvariant metric defined  for every point $R$ in $SO(3)$ through the left action, i.e. $$g\left(X,\,Y\right)=g_{0}\left(L_{R^{-1}*}\left(X\right),\,L_{R^{-1}*}\left(Y\right)\right).$$ It's clearly left invariant by construction. Now let's say I take the following base $\left\{\left(E_{1}\right)_{R},...,\left(E_{n}\right)_{R}\right\} $ for the point of the tangent space in $R$ where $$\left(E_{1}\right)_{R}=L_{R*}\left(\left(E_{1}\right)_{\mathbb{1}}\right)$$  where of course $\left\{ \left(E_{1}\right)_{\mathbb{1}},...,\left(E_{n}\right)_{\mathbb{1}}\right\} $ is the canonical base at the identity. Now it should be that  $$g\left(\left(E_{i}\right)_{R},\,\left(E_{j}\right)_{R}\right)	=	\frac{1}{2}\mbox{Tr}\left(\left(R\left(E_{i}\right)_{\mathbb{1}}\right)^{T}\left(R^{-1}\right)^{T}\left(R^{-1}\right)\left(R\left(E_{j}\right)_{\mathbb{1}}\right)\right)= 	g\left(\left(E_{i}\right)_{\mathbb{1}},\,\left(E_{j}\right)_{\mathbb{1}}\right),$$ So that the coefficient of the metric in the base given by $ \left\{ \left(E_{1}\right)_{R},...,\left(E_{n}\right)_{R}\right\}$ are constant. Being that the Christoffel Symbols are identically zero and I have that $\nabla_{X}Y$ is nothing else that the partial derivative in the point. Defining the torsion $$T\left(X,Y\right)=\nabla_{X}Y-\nabla_{Y}X-\left[X,Y\right].$$ I then have $$T\left(X,Y\right)=-\left[X,Y\right],$$ and therefore in the base  $\left\{ \left(E_{1}\right)_{R},...,\left(E_{n}\right)_{R}\right\}$  the coefficient of the tensor of torsion are $$T_{bc}^{a}=-\epsilon_{bc}^{a},$$ where in general since it works for every Lie Group the coefficient should be che structure constante of the lie algebra for the specific base choosen. Is this reasoning right? What did I get wrong? I found in a book the same construction to find the Curvature of the Levi-Civita connection and so -since the Levi-Civita Connection has zero torsion- I'm quite sure I've done something wrong somewhere....",,"['differential-geometry', 'lie-groups', 'lie-algebras', 'riemannian-geometry']"
30,Closed connected integral submanifold is maximal,Closed connected integral submanifold is maximal,,"I'm having some problems to prove the following assertion: Let $\mathscr{D}$ be an involutive distribution of dimension $k$ in a   manifold $N$. Let $(M,\varphi)$ be a integral connected submanifold,   such that $\varphi(M)\subseteq N$ is a closed subset. Show that $M$ is   a maximal connected integral submanifold of $\mathscr{D}$ (a leaf ,   say). I've tried using the local version of Frobenius Theorem (each involutive distribution is integrable and locally its integral connected submanifolds are slices). However, the problem talks of something that is rather global (?), and I can't manage to complete the idea. I'd thank any kind of help.","I'm having some problems to prove the following assertion: Let $\mathscr{D}$ be an involutive distribution of dimension $k$ in a   manifold $N$. Let $(M,\varphi)$ be a integral connected submanifold,   such that $\varphi(M)\subseteq N$ is a closed subset. Show that $M$ is   a maximal connected integral submanifold of $\mathscr{D}$ (a leaf ,   say). I've tried using the local version of Frobenius Theorem (each involutive distribution is integrable and locally its integral connected submanifolds are slices). However, the problem talks of something that is rather global (?), and I can't manage to complete the idea. I'd thank any kind of help.",,['differential-geometry']
31,"Let $X$ be a plane curve over $\mathbb{C}$ defined by an irreducible polynomial $f\in\mathbb{C}[z,w]$. Then $X$ is connected in $\mathbb{C}^2$.",Let  be a plane curve over  defined by an irreducible polynomial . Then  is connected in .,"X \mathbb{C} f\in\mathbb{C}[z,w] X \mathbb{C}^2","Under the Zariski topology, this is true by basic Algebraic Geometry. However, I was wondering about how to prove this for the metric topology on $\mathbb{C}$. In Algebraic Curves and Riemann Surfaces by Miranda, this is stated as a fact, with a reference to Shafarevich (without giving page number). However, I can't quite see any obvious way to prove this. More formally, we let $f(z,w)\in\mathbb{C}[z,w]$ be an irreducible polynomial, and we define $X=\{(z,w)\in\mathbb{C}^2\mid f(z,w)=0\}$, and give $X\subset\mathbb{C}^2$ the subspace topology. I wish to prove that given disjoint closed sets $X_1$ and $X_2$ s.t. $X=X_1\cup X_2$, either $X_1=\emptyset$ or $X_2=\emptyset$. I'm struggling to find the connection between the Zariski topology and the metric topology.","Under the Zariski topology, this is true by basic Algebraic Geometry. However, I was wondering about how to prove this for the metric topology on $\mathbb{C}$. In Algebraic Curves and Riemann Surfaces by Miranda, this is stated as a fact, with a reference to Shafarevich (without giving page number). However, I can't quite see any obvious way to prove this. More formally, we let $f(z,w)\in\mathbb{C}[z,w]$ be an irreducible polynomial, and we define $X=\{(z,w)\in\mathbb{C}^2\mid f(z,w)=0\}$, and give $X\subset\mathbb{C}^2$ the subspace topology. I wish to prove that given disjoint closed sets $X_1$ and $X_2$ s.t. $X=X_1\cup X_2$, either $X_1=\emptyset$ or $X_2=\emptyset$. I'm struggling to find the connection between the Zariski topology and the metric topology.",,"['algebraic-geometry', 'differential-geometry', 'riemann-surfaces']"
32,Motivation behind notation for tangent space,Motivation behind notation for tangent space,,"The notes I am reading cover differential geometry at only a very basic level (say around Do Carmo's Differential Geometry of Curves and Surfaces ), so I apologize in advance if this question would be considered incredibly misguided for anyone with a substantial knowledge of the subject. Here is the definition of tangent space which I have: Let $M \subset \mathbb{R}^n$ be open. Then $TM := M \times \mathbb{R}^n$ is called the tangent bundle of $M$. For $p \in M$, $T_pM := \{ p \} \times \mathbb{R}^n$ is called the tangent space of $M$ at $p$. $\dots$ If now $f: M \subset \mathbb{R}^n \to \mathbb{R}^m$ smooth, then we consider the differential of $f$ to be a map $df: TM \to T\mathbb{R}^m,$ and $d_p f:T_p M \to T_{f(p)}\mathbb{R}^m$. $\dots$ Let $S \subset \mathbb{R}^3$ be an embedded surface, $q \in S$ be a point of $S$, and $f: U \to \mathbb{R}^3$ be a parametrization of $S$ such that $f(p)=q$. The tangent space of $S$ at $q$ is defined to be $T_q S := (d_p f)(T_p U) \subset T_{f(p)} \mathbb{R}^3$ and the tangent bundle $TS \subset T\mathbb{R}^3$ of $S$ is $TS := \bigcup\limits_{q \in S} T_q S$. My question: Why the notation $T_pU$? The $U$ here does not provide any useful information about the nature of the object. All it says is that $p \in U$, which seems almost redundant. The most important aspect of the definition is that $T_p U \simeq \mathbb{R}^n$, but this is impossible to deduce from the notation $T_pU$. I find it very difficult to understand any discussion of tangent spaces using this notation unless ample context about the ambient spaces is given nearby, which it usually isn't. Why would anyone care more about $p \in U$ than the fact that $T_p U \simeq \mathbb{R}^n$? What am I missing?","The notes I am reading cover differential geometry at only a very basic level (say around Do Carmo's Differential Geometry of Curves and Surfaces ), so I apologize in advance if this question would be considered incredibly misguided for anyone with a substantial knowledge of the subject. Here is the definition of tangent space which I have: Let $M \subset \mathbb{R}^n$ be open. Then $TM := M \times \mathbb{R}^n$ is called the tangent bundle of $M$. For $p \in M$, $T_pM := \{ p \} \times \mathbb{R}^n$ is called the tangent space of $M$ at $p$. $\dots$ If now $f: M \subset \mathbb{R}^n \to \mathbb{R}^m$ smooth, then we consider the differential of $f$ to be a map $df: TM \to T\mathbb{R}^m,$ and $d_p f:T_p M \to T_{f(p)}\mathbb{R}^m$. $\dots$ Let $S \subset \mathbb{R}^3$ be an embedded surface, $q \in S$ be a point of $S$, and $f: U \to \mathbb{R}^3$ be a parametrization of $S$ such that $f(p)=q$. The tangent space of $S$ at $q$ is defined to be $T_q S := (d_p f)(T_p U) \subset T_{f(p)} \mathbb{R}^3$ and the tangent bundle $TS \subset T\mathbb{R}^3$ of $S$ is $TS := \bigcup\limits_{q \in S} T_q S$. My question: Why the notation $T_pU$? The $U$ here does not provide any useful information about the nature of the object. All it says is that $p \in U$, which seems almost redundant. The most important aspect of the definition is that $T_p U \simeq \mathbb{R}^n$, but this is impossible to deduce from the notation $T_pU$. I find it very difficult to understand any discussion of tangent spaces using this notation unless ample context about the ambient spaces is given nearby, which it usually isn't. Why would anyone care more about $p \in U$ than the fact that $T_p U \simeq \mathbb{R}^n$? What am I missing?",,"['differential-geometry', 'soft-question', 'notation', 'terminology']"
33,Finding all $2$-forms in the right half-plane that are invariant under glide transformations,Finding all -forms in the right half-plane that are invariant under glide transformations,2,"I'm trying to find all 2-forms $\omega$ that are invariant under glide transformations in the right half-plane, $X = \{ (x,y) \in \mathbb{R}^2 : x > 0\}$. To do this, we can write the vector field corresponding to such transformations as $V = x \frac{\partial}{\partial x} - y \frac{\partial}{\partial y}$. Now I'd like to solve $\mathcal{L}_X\omega = 0$ for $\omega$. We can write an arbitrary $2$-form on $X$ as $$\omega = a(x,y) \textrm{d}x \wedge \textrm{d}y$$ and then we can use the usual rules of the Lie derivative to find that the equation becomes $$x\frac{\partial a}{\partial x} = y\frac{\partial a}{\partial y}.$$ The only solution I can find to this equation (by looking for a separable solution) is $a(x,y) = c(\log(x)+\log(y))$. My difficulty is, $log(y)$ is not even defined everywhere on this manifold so how can this be the solution?","I'm trying to find all 2-forms $\omega$ that are invariant under glide transformations in the right half-plane, $X = \{ (x,y) \in \mathbb{R}^2 : x > 0\}$. To do this, we can write the vector field corresponding to such transformations as $V = x \frac{\partial}{\partial x} - y \frac{\partial}{\partial y}$. Now I'd like to solve $\mathcal{L}_X\omega = 0$ for $\omega$. We can write an arbitrary $2$-form on $X$ as $$\omega = a(x,y) \textrm{d}x \wedge \textrm{d}y$$ and then we can use the usual rules of the Lie derivative to find that the equation becomes $$x\frac{\partial a}{\partial x} = y\frac{\partial a}{\partial y}.$$ The only solution I can find to this equation (by looking for a separable solution) is $a(x,y) = c(\log(x)+\log(y))$. My difficulty is, $log(y)$ is not even defined everywhere on this manifold so how can this be the solution?",,"['differential-geometry', 'differential-topology', 'differential-forms', 'smooth-manifolds', 'lie-derivative']"
34,The curvature is equal to the derivative of the angle between the curve and the x-axis?,The curvature is equal to the derivative of the angle between the curve and the x-axis?,,"I'm trying to prove that if $\vec{x}:I\rightarrow\mathbb{R}^2$ is a curve parametrized by arc length and $\theta(t)$ is the angle between the tangent line to $\vec{x}$ at point $t$ and the $x$ axis, then $\kappa=\theta'$, where $\kappa$ denotes the curvature. I know that for a curve in $\mathbb{R}^2$, the curvature is given by $\kappa=\frac{1}{|\vec{x}'|^3}det(\vec{x}'\vec{x}'')$. I also know that the tangent line to $\vec{x}$ at point $\alpha\in\mathbb{R}$ is given by $y(t)=\vec{x}(\alpha)+t\vec{x}'$. I can picture the problem, but can't write the solutions. Any ideas?","I'm trying to prove that if $\vec{x}:I\rightarrow\mathbb{R}^2$ is a curve parametrized by arc length and $\theta(t)$ is the angle between the tangent line to $\vec{x}$ at point $t$ and the $x$ axis, then $\kappa=\theta'$, where $\kappa$ denotes the curvature. I know that for a curve in $\mathbb{R}^2$, the curvature is given by $\kappa=\frac{1}{|\vec{x}'|^3}det(\vec{x}'\vec{x}'')$. I also know that the tangent line to $\vec{x}$ at point $\alpha\in\mathbb{R}$ is given by $y(t)=\vec{x}(\alpha)+t\vec{x}'$. I can picture the problem, but can't write the solutions. Any ideas?",,['differential-geometry']
35,Frank Warner's definition of the Hodge star,Frank Warner's definition of the Hodge star,,"Frank Warner's book, chapter 2, excercise 13 states the following: If $V$ is an oriented inner product space ($n$ dimensional) there is a linear map $\ast \colon \Lambda (V) \to \Lambda (V)$, called star, which is well-defined by the requirement that for any orthonormal basis $e_1,\dots,e_n$ of $V$ (in particular, for any re-ordering of a given basis),   $\ast(1) = \pm e_1 \wedge \dots \wedge e_n$, $\ast(e_1 \wedge \dots \wedge e_n) = \pm 1$, $\ast(e_1 \wedge \dots \wedge e_k) = \pm e_{k+1} \wedge \dots \wedge e_n$, where one takes ""+"" if $e_1 \wedge \dots \wedge e_n$ lies on the component of $\Lambda^n(V)-\{0\}$ determined by the orientation and ""-"" otherwise. Observe that $\ast\colon \Lambda^k(V) \to \Lambda^{n-k}(V)$. Prove that on $\Lambda^k(V)$, $\ast\ast = (-1)^{k(n-k)}$. A prior part of that exercise was to show that if we have an ONB $e_1,\dots,e_n$ of $V$ then the corresponding basis of $\Lambda(V)$ is orthonormal (after extending the inner product to $\Lambda(V)$ in the usual way), which I already accomplished. But now I'm having trouble with his definition of $\ast$. How can I calculate $\ast$ on all other basis elements, i.e. $\ast(e_{i_1}\wedge \dots \wedge e_{i_k})$? What exactly does he mean with ""for any re-ordering of a given basis""? Or is there any other way to prove the claim? Clarification: I know how the $\ast$ acts on general elements from many other sources, my question here is, if the claim follows by only knowing $\ast(e_1 \wedge \dots \wedge e_k) = e_{k+1} \wedge \dots \wedge e_n$ if my basis has the ""right"" orientation. Edit: For a solution see below.","Frank Warner's book, chapter 2, excercise 13 states the following: If $V$ is an oriented inner product space ($n$ dimensional) there is a linear map $\ast \colon \Lambda (V) \to \Lambda (V)$, called star, which is well-defined by the requirement that for any orthonormal basis $e_1,\dots,e_n$ of $V$ (in particular, for any re-ordering of a given basis),   $\ast(1) = \pm e_1 \wedge \dots \wedge e_n$, $\ast(e_1 \wedge \dots \wedge e_n) = \pm 1$, $\ast(e_1 \wedge \dots \wedge e_k) = \pm e_{k+1} \wedge \dots \wedge e_n$, where one takes ""+"" if $e_1 \wedge \dots \wedge e_n$ lies on the component of $\Lambda^n(V)-\{0\}$ determined by the orientation and ""-"" otherwise. Observe that $\ast\colon \Lambda^k(V) \to \Lambda^{n-k}(V)$. Prove that on $\Lambda^k(V)$, $\ast\ast = (-1)^{k(n-k)}$. A prior part of that exercise was to show that if we have an ONB $e_1,\dots,e_n$ of $V$ then the corresponding basis of $\Lambda(V)$ is orthonormal (after extending the inner product to $\Lambda(V)$ in the usual way), which I already accomplished. But now I'm having trouble with his definition of $\ast$. How can I calculate $\ast$ on all other basis elements, i.e. $\ast(e_{i_1}\wedge \dots \wedge e_{i_k})$? What exactly does he mean with ""for any re-ordering of a given basis""? Or is there any other way to prove the claim? Clarification: I know how the $\ast$ acts on general elements from many other sources, my question here is, if the claim follows by only knowing $\ast(e_1 \wedge \dots \wedge e_k) = e_{k+1} \wedge \dots \wedge e_n$ if my basis has the ""right"" orientation. Edit: For a solution see below.",,"['differential-geometry', 'inner-products', 'differential-forms', 'exterior-algebra', 'hodge-theory']"
36,Riemannian metric given in polar coordinates,Riemannian metric given in polar coordinates,,"the Riemannian metric of the euclidean plane is given in polar coordinates as \begin{align*} ds^2=dr^2+r^2d\theta^2. \end{align*} Consider more generally, \begin{align*} ds^2=dr^2+\psi(r)^2d\theta^2, \end{align*} where $\psi>0$ is a smooth function. It seems to me a very natural question to ask what happens if the function $\psi$ changes. Is it possible to 'tell' what kind of Riemannian manifold correspond to such a metric if we choose different functions $\psi$ ( e.g. $\psi^2(r)=r,r^3,r^4,.. etc.)$ For example, if we choose $\psi(x)^2=\sinh(x)^2$ we 'obtain' the hyperbolic plane, i.e. the hyperbolic metric in polar coordinates is equal to the corresponding metric. Do other choices of $\psi$ have some significant meaning, or are there maybe well known examples which can be found in some literature? Best regards","the Riemannian metric of the euclidean plane is given in polar coordinates as \begin{align*} ds^2=dr^2+r^2d\theta^2. \end{align*} Consider more generally, \begin{align*} ds^2=dr^2+\psi(r)^2d\theta^2, \end{align*} where $\psi>0$ is a smooth function. It seems to me a very natural question to ask what happens if the function $\psi$ changes. Is it possible to 'tell' what kind of Riemannian manifold correspond to such a metric if we choose different functions $\psi$ ( e.g. $\psi^2(r)=r,r^3,r^4,.. etc.)$ For example, if we choose $\psi(x)^2=\sinh(x)^2$ we 'obtain' the hyperbolic plane, i.e. the hyperbolic metric in polar coordinates is equal to the corresponding metric. Do other choices of $\psi$ have some significant meaning, or are there maybe well known examples which can be found in some literature? Best regards",,"['differential-geometry', 'differential-topology', 'riemannian-geometry', 'polar-coordinates']"
37,Some very basic geometry problem basis,Some very basic geometry problem basis,,"I am studying  Riemannian geometry and have some very basic background for differential geometry.In differential geometry, I only know about thing in $\mathbb{R}^3 $ or $\mathbb{R}^2$ , when it comes to some abstract space , my books use  $\dfrac{\partial}{\partial x_i} $ and $dx_i$ to denote the basis of tangent space and the cotangent space. I don't know what is the meaning of $\dfrac{\partial}{\partial x_i} $, because I think it is a differential operator rather than a basis element , what is the meaning of $\dfrac{\partial}{\partial x_i} $ at some point $p$? May I have some reference book or material for this basic thing? Thank you so much","I am studying  Riemannian geometry and have some very basic background for differential geometry.In differential geometry, I only know about thing in $\mathbb{R}^3 $ or $\mathbb{R}^2$ , when it comes to some abstract space , my books use  $\dfrac{\partial}{\partial x_i} $ and $dx_i$ to denote the basis of tangent space and the cotangent space. I don't know what is the meaning of $\dfrac{\partial}{\partial x_i} $, because I think it is a differential operator rather than a basis element , what is the meaning of $\dfrac{\partial}{\partial x_i} $ at some point $p$? May I have some reference book or material for this basic thing? Thank you so much",,"['differential-geometry', 'reference-request', 'book-recommendation']"
38,Does stereographic projection preserve or reverse orientation?,Does stereographic projection preserve or reverse orientation?,,"Let $S^n\subset\mathbb{R}^{n+1}$ denote the standard unit sphere with normal bundle $\nu$, let $N=(0,\dots,0,1)$ and $S=(0,\dots,0,-1)$.  Then there are two sterographic projections $$\sigma_+\colon S^n-S\to\mathbb{R}^n $$ and $$\sigma_-\colon S^n-N\to\mathbb{R}^n$$ Both of these maps are homeomorphisms and they form an atlas for the standard smooth structure on $S^n$.  I'm interested in how they should induce the standard orientation on $S^n$.  (Here I orient $S^n$ by putting the standard orientation on $T S^n \oplus \nu\cong T\mathbb{R}^{n+1}|_{S^n}$ and orient $\nu$ by declaring that the outward-pointing direction is positive.) Let $v\in S^{n-1}\subset S^n$ so that $\sigma_+^{-1}\circ \sigma_-(v)=v$, and let $B=\{b_1,\dots,b_n\}$ be a positively-oriented orthonormal basis for $T_vS^n$ where $b_1$ points along the great circle from $N$ to $S$.  Geometrically, it seems like $D_v (\sigma_+^{-1}\circ \sigma_-) (b_i)=-b_1$ if $i= 1$ and $b_i$ otherwise, suggesting that the transition function is orientation reversing, and hence exactly one of $\sigma_+$ and $\sigma_-$ is orientation reversing.  My question is which one reverses orientation and which preserves? I haven't succeeded in computing anything in terms of the formulas for stereographic projection.  The Jacobean matrix I get in the 2-dimensional case for $\sigma_+$ or $\sigma_-$ is $2\times 3$ so I don't know how I'm supposed to interpret its ""determinant"". (I should point out that in general my experiences with differential geometry have been very, very, very bad, and I'm much more topologically minded.  In particular my definition for an orientation of a vector bundle is a Thom class.)","Let $S^n\subset\mathbb{R}^{n+1}$ denote the standard unit sphere with normal bundle $\nu$, let $N=(0,\dots,0,1)$ and $S=(0,\dots,0,-1)$.  Then there are two sterographic projections $$\sigma_+\colon S^n-S\to\mathbb{R}^n $$ and $$\sigma_-\colon S^n-N\to\mathbb{R}^n$$ Both of these maps are homeomorphisms and they form an atlas for the standard smooth structure on $S^n$.  I'm interested in how they should induce the standard orientation on $S^n$.  (Here I orient $S^n$ by putting the standard orientation on $T S^n \oplus \nu\cong T\mathbb{R}^{n+1}|_{S^n}$ and orient $\nu$ by declaring that the outward-pointing direction is positive.) Let $v\in S^{n-1}\subset S^n$ so that $\sigma_+^{-1}\circ \sigma_-(v)=v$, and let $B=\{b_1,\dots,b_n\}$ be a positively-oriented orthonormal basis for $T_vS^n$ where $b_1$ points along the great circle from $N$ to $S$.  Geometrically, it seems like $D_v (\sigma_+^{-1}\circ \sigma_-) (b_i)=-b_1$ if $i= 1$ and $b_i$ otherwise, suggesting that the transition function is orientation reversing, and hence exactly one of $\sigma_+$ and $\sigma_-$ is orientation reversing.  My question is which one reverses orientation and which preserves? I haven't succeeded in computing anything in terms of the formulas for stereographic projection.  The Jacobean matrix I get in the 2-dimensional case for $\sigma_+$ or $\sigma_-$ is $2\times 3$ so I don't know how I'm supposed to interpret its ""determinant"". (I should point out that in general my experiences with differential geometry have been very, very, very bad, and I'm much more topologically minded.  In particular my definition for an orientation of a vector bundle is a Thom class.)",,"['differential-geometry', 'smooth-manifolds', 'vector-bundles', 'differential', 'orientation']"
39,Injective immersion that is not trajectory of any flow,Injective immersion that is not trajectory of any flow,,"Let $M$ be a compact manifold of dimension $m \geq 2$ . Show that there exists an injective immersion of $\mathbb{R}$ in $M$ , whose image is not the trajectory of any flow. I know how to do it for $M=\mathbb R^2$ (of course this is not compact!). I just take $\gamma:\mathbb R\rightarrow \mathbb{R}^2$ defined by $\gamma(t)=(e^{-t},\sin t)$ . From an easy computation this is clearly an injective immersion. Suppose by contradiction, $\gamma$ is the flow line of the global flow on $\mathbb{R}^2$ then let $\Phi: \mathbb{R} \times \mathbb{R}^2\rightarrow \mathbb{R}^2$ and let $\Phi(t,x)=\varphi_t(x)$ . Then we know that $\dot\gamma(t)=(d\varphi)_{\gamma(t)}(\dot\gamma(0)).$ If we take $t_n=n\pi$ we get that $\lim_{n \rightarrow \infty}\dot\gamma(t_n)=(d\varphi)_{(0,0)}(\dot\gamma(0))$ and on the other hand $\lim_{n \rightarrow \infty}\dot\gamma(t_n)=\lim(e^{-n\pi},\cos n\pi)$ which does not have a limit. Contradiction. It is clear that we can generalize for $\mathbb{R}^n$ . But how do we do it for $M$ compact? Thank you.","Let be a compact manifold of dimension . Show that there exists an injective immersion of in , whose image is not the trajectory of any flow. I know how to do it for (of course this is not compact!). I just take defined by . From an easy computation this is clearly an injective immersion. Suppose by contradiction, is the flow line of the global flow on then let and let . Then we know that If we take we get that and on the other hand which does not have a limit. Contradiction. It is clear that we can generalize for . But how do we do it for compact? Thank you.","M m \geq 2 \mathbb{R} M M=\mathbb R^2 \gamma:\mathbb R\rightarrow \mathbb{R}^2 \gamma(t)=(e^{-t},\sin t) \gamma \mathbb{R}^2 \Phi: \mathbb{R} \times \mathbb{R}^2\rightarrow \mathbb{R}^2 \Phi(t,x)=\varphi_t(x) \dot\gamma(t)=(d\varphi)_{\gamma(t)}(\dot\gamma(0)). t_n=n\pi \lim_{n \rightarrow \infty}\dot\gamma(t_n)=(d\varphi)_{(0,0)}(\dot\gamma(0)) \lim_{n \rightarrow \infty}\dot\gamma(t_n)=\lim(e^{-n\pi},\cos n\pi) \mathbb{R}^n M","['differential-geometry', 'differential-topology']"
40,First order PDE system on a complete Riemannian manifold,First order PDE system on a complete Riemannian manifold,,"Let $X_1, X_2$ be two orthogonal everywhere non-zero vector fields on a complete Riemannian manifold $M$. Can one always solve the solve the system $$X \phi = 1, Y\phi = 0,$$  $$X\psi = 0, Y\psi = 1 ?$$ where $\phi, \psi \in C_0^\infty (M)$? I am not too sure this can be done always, but may be there are good sufficient conditions known for such linear systems?","Let $X_1, X_2$ be two orthogonal everywhere non-zero vector fields on a complete Riemannian manifold $M$. Can one always solve the solve the system $$X \phi = 1, Y\phi = 0,$$  $$X\psi = 0, Y\psi = 1 ?$$ where $\phi, \psi \in C_0^\infty (M)$? I am not too sure this can be done always, but may be there are good sufficient conditions known for such linear systems?",,"['differential-geometry', 'reference-request', 'partial-differential-equations', 'differential-topology', 'partial-derivative']"
41,One-parameter subgroups and Lie bracket,One-parameter subgroups and Lie bracket,,"Suppose that $G$ is a Lie group. It is easy to prove that given $X \in Lie(G)$ there exists a unique one-parameter subgroup $\phi_X : \mathbb{R} \to G$ such that $\dot{\phi}(0)=X$. My question is: given $X,Y \in Lie(G)$, is it possible to describe the one-parameter subgroup $\phi_{[X,Y]}$ in function of $\phi_X$ and $\phi_Y$?","Suppose that $G$ is a Lie group. It is easy to prove that given $X \in Lie(G)$ there exists a unique one-parameter subgroup $\phi_X : \mathbb{R} \to G$ such that $\dot{\phi}(0)=X$. My question is: given $X,Y \in Lie(G)$, is it possible to describe the one-parameter subgroup $\phi_{[X,Y]}$ in function of $\phi_X$ and $\phi_Y$?",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
42,On irreducible orientable manifolds,On irreducible orientable manifolds,,"The assumption on a $3$-manifold of being orientable and irreducible, and containing an embedded projective plane, automatically implies that the manifold is diffeormorphic to $\mathbb{RP^3}$? I'm not asking for a proof of this, this is obviously not a trivial result. I think it may be a consequence of a strong theorem in 3-dimensional topology, like Alexander's or the Sphere Theorem, it's just that I can't find it. Could you give me some reference, or any idea in this direction?","The assumption on a $3$-manifold of being orientable and irreducible, and containing an embedded projective plane, automatically implies that the manifold is diffeormorphic to $\mathbb{RP^3}$? I'm not asking for a proof of this, this is obviously not a trivial result. I think it may be a consequence of a strong theorem in 3-dimensional topology, like Alexander's or the Sphere Theorem, it's just that I can't find it. Could you give me some reference, or any idea in this direction?",,"['differential-geometry', 'algebraic-topology']"
43,Computing the Lie derivative of a metric,Computing the Lie derivative of a metric,,"Suppose $g$ is a Riemannian metric on a manifold, and $X$ is a smooth vector field. Show that $$(\mathcal{L}_Xg)_{ij} = \nabla_iX_j + \nabla_jX_i$$ I've been able to obtain that $$(\mathcal{L}_Xg)(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^j} ) = g(\nabla_{\frac{\partial}{\partial x^i}}X, \frac{\partial}{\partial x^j}) + g(\frac{\partial}{\partial x^i}, \nabla_{\frac{\partial}{\partial x^j}}X)$$ but when I expand this in local coordinates I get a bunch of pesky $g_{ij}$ terms that I can't make disappear. It also seems somewhat odd to me that the Lie derivative of a metric yields an answer that is a sum of derivatives of component functions of $X$. This makes it seem like the Lie Derivative of a metric is not dependent on the metric. Maybe I have misunderstood the author's notation, but I would like to see an explicit computation from my step to the final answer, as most sources I've found seem to gloss over it.","Suppose $g$ is a Riemannian metric on a manifold, and $X$ is a smooth vector field. Show that $$(\mathcal{L}_Xg)_{ij} = \nabla_iX_j + \nabla_jX_i$$ I've been able to obtain that $$(\mathcal{L}_Xg)(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^j} ) = g(\nabla_{\frac{\partial}{\partial x^i}}X, \frac{\partial}{\partial x^j}) + g(\frac{\partial}{\partial x^i}, \nabla_{\frac{\partial}{\partial x^j}}X)$$ but when I expand this in local coordinates I get a bunch of pesky $g_{ij}$ terms that I can't make disappear. It also seems somewhat odd to me that the Lie derivative of a metric yields an answer that is a sum of derivatives of component functions of $X$. This makes it seem like the Lie Derivative of a metric is not dependent on the metric. Maybe I have misunderstood the author's notation, but I would like to see an explicit computation from my step to the final answer, as most sources I've found seem to gloss over it.",,"['differential-geometry', 'riemannian-geometry']"
44,Natural Isomorphism between $T_1^1(V)$ and End$(V)$,Natural Isomorphism between  and End,T_1^1(V) (V),"I'm a little stuck on showing that there is a natural isomorphism between the $\mathbb{R}$ vector space of $(1,1)$ tensors, and the $\mathbb{R}$ space of of linear maps $T:V\to V$. The hint is define the map $\phi:$End$(V)\to T_1^1(V)$ by $(\phi A)(\omega, X)=\omega(AX).$ I can show that this map is linear and injective, but I'm having trouble proving it's surjective without introducing a basis for $V$.","I'm a little stuck on showing that there is a natural isomorphism between the $\mathbb{R}$ vector space of $(1,1)$ tensors, and the $\mathbb{R}$ space of of linear maps $T:V\to V$. The hint is define the map $\phi:$End$(V)\to T_1^1(V)$ by $(\phi A)(\omega, X)=\omega(AX).$ I can show that this map is linear and injective, but I'm having trouble proving it's surjective without introducing a basis for $V$.",,"['differential-geometry', 'self-learning', 'tensors']"
45,Advanced introduction to riemmanian geometry,Advanced introduction to riemmanian geometry,,"After some time of studying differential geometry/topology while avoiding riemmanian geometry I find mysef at a wierd position. I'd like to read a book that contains an introduction to riemannian geometry that assumes familiarity with basic differential geometry/topology (transversality and degree, vector and tensor bundles, differential forms and integration, lie groups etc.). But instead of it going deaper into rimannian geometry (comparison theorem and other geometric analysis stuff) i'd like it to cover some advanced matirial on differential geometry as well. Ideally it would contain a (not too brief) introduction to these concepts: Basics of riemannian geometry (affine connection, metric tensor, gauss bonnet, curvature forms and tensors, jacobi fields) Connection and curvature on fibre bundles Holonomy and folliations Jet bundles Differential operators (Laplacian, and Dirac) Is there such a book? Is it too much to ask for in one book?","After some time of studying differential geometry/topology while avoiding riemmanian geometry I find mysef at a wierd position. I'd like to read a book that contains an introduction to riemannian geometry that assumes familiarity with basic differential geometry/topology (transversality and degree, vector and tensor bundles, differential forms and integration, lie groups etc.). But instead of it going deaper into rimannian geometry (comparison theorem and other geometric analysis stuff) i'd like it to cover some advanced matirial on differential geometry as well. Ideally it would contain a (not too brief) introduction to these concepts: Basics of riemannian geometry (affine connection, metric tensor, gauss bonnet, curvature forms and tensors, jacobi fields) Connection and curvature on fibre bundles Holonomy and folliations Jet bundles Differential operators (Laplacian, and Dirac) Is there such a book? Is it too much to ask for in one book?",,"['differential-geometry', 'riemannian-geometry', 'book-recommendation']"
46,Determinant structure of symplectic matrix,Determinant structure of symplectic matrix,,"I want to show that if $\lambda$ is a real eigenvalue of a symplectic matrix $A$ then its char poly is of the form $\det(A-\mu id) = (\lambda-\mu)(\frac{1}{\lambda}-\mu) \det(\hat{A}- \mu id) $ where $\hat{A}$ is again a symplectic matrix. My proof goes like this: First, we take the eigenvector $e_1$ to the eigenvalue $\lambda$. We can extend this vector to a symplectic basis $e_1,f_1,e_2,f_2,\ldots,f_n$ satisfying the canonical conditions on such a basis with symplectic form $\omega.$ With respect to this basis, the first column of $A$ is $(\lambda,0,\ldots,0)^T$ by the eigenvector property. The entry $(2,2)$ of the matrix is given by $\omega(e_1,f_1) = \frac{1}{\lambda} \omega(e_1,Af_1) = \frac{1}{\lambda} \omega(e_1,f_1) = \frac{1}{\lambda}.$ Moreover, all other entries in the second row are zero( besides the entry $(2,2)$) as for any $k \in \operatorname{span}\{{f_1}\}^{\perp}.$ $$\omega(e_1,Ak) = \frac{1}{\lambda} \omega(Ae_1,Ak) =  \frac{1}{\lambda} \omega(e_1,k) = 0.$$ Thus, we can calculate the determinant of $A-\mu id$ in this basis by first expanding with respect to the first column. Since the only non zero entry is $(\lambda-\mu)$ we only get one term. Then we calculate the determinant of the submatrix with entries $(2,\ldots,n)\times(2,\ldots,n).$ We expand this determinant with respect to the second row. Here, the only non-zero entry is $(2,2).$ This one is $\frac{1}{\lambda-\mu}.$ So we indeed end up with something of the form $\det(A-\mu id) = (\lambda-\mu)(\frac{1}{\lambda}-\mu) \det(\hat{A}- \mu id) .$ But now the big question is: Why is the submatrix $\hat{A}$ corresponding to the entries $(3,\ldots,n)\times(3,\ldots,n)$ of $A$ again symplectic?","I want to show that if $\lambda$ is a real eigenvalue of a symplectic matrix $A$ then its char poly is of the form $\det(A-\mu id) = (\lambda-\mu)(\frac{1}{\lambda}-\mu) \det(\hat{A}- \mu id) $ where $\hat{A}$ is again a symplectic matrix. My proof goes like this: First, we take the eigenvector $e_1$ to the eigenvalue $\lambda$. We can extend this vector to a symplectic basis $e_1,f_1,e_2,f_2,\ldots,f_n$ satisfying the canonical conditions on such a basis with symplectic form $\omega.$ With respect to this basis, the first column of $A$ is $(\lambda,0,\ldots,0)^T$ by the eigenvector property. The entry $(2,2)$ of the matrix is given by $\omega(e_1,f_1) = \frac{1}{\lambda} \omega(e_1,Af_1) = \frac{1}{\lambda} \omega(e_1,f_1) = \frac{1}{\lambda}.$ Moreover, all other entries in the second row are zero( besides the entry $(2,2)$) as for any $k \in \operatorname{span}\{{f_1}\}^{\perp}.$ $$\omega(e_1,Ak) = \frac{1}{\lambda} \omega(Ae_1,Ak) =  \frac{1}{\lambda} \omega(e_1,k) = 0.$$ Thus, we can calculate the determinant of $A-\mu id$ in this basis by first expanding with respect to the first column. Since the only non zero entry is $(\lambda-\mu)$ we only get one term. Then we calculate the determinant of the submatrix with entries $(2,\ldots,n)\times(2,\ldots,n).$ We expand this determinant with respect to the second row. Here, the only non-zero entry is $(2,2).$ This one is $\frac{1}{\lambda-\mu}.$ So we indeed end up with something of the form $\det(A-\mu id) = (\lambda-\mu)(\frac{1}{\lambda}-\mu) \det(\hat{A}- \mu id) .$ But now the big question is: Why is the submatrix $\hat{A}$ corresponding to the entries $(3,\ldots,n)\times(3,\ldots,n)$ of $A$ again symplectic?",,"['linear-algebra', 'differential-geometry', 'differential-topology', 'symplectic-geometry', 'symplectic-linear-algebra']"
47,Definition of a complex fiber,Definition of a complex fiber,,"We define a real hypersurface as a subset $M\subset\Bbb C^n$ which is locally defined as the zero-locus of some $r\in\mathcal C^2(\Omega,\Bbb R)$ ($\Omega\subseteq\Bbb C^n$ open). Then let $z_0\in M$. If $\Bbb C^n$ was $\Bbb R^n$, we can easily see that such an $M$ is a $(n-1)$-dimensional variety. I hope in complex case it works as well. Allowing us to think that real facts works also here (and I'm well aware that this could be strongly wrong, but the only source I have is hyper-cryptic, so I hope in the good heart of someone of you!), we know the definition of tangent space to $M$ at $z_0$ (or the fiber of $z_0$): in the real case it was $\ker \Delta r(z_0)$, now my book says that it is ""the space of vectors othogonal to $\partial r(z_0)$ under hermitian product"", and denotes this with $T_{z_0}^{\Bbb C}M$. I obviously deduced that $$ T_{z_0}^{\Bbb C}M:=\{z\in\Bbb C^n\;:\;z\cdot\overline{\partial r(z_0)}=0\} $$ where $\partial r(z_0)=(\partial_{z_1}r(z_0),\dots,\partial_{z_n}r(z_0))$. But this can't be right because of something I found after (it deals with the well definition of the signature of the Levi form of $M$, and it would be really long to write: I think the important is to say that at this point I reached a contradiction). The way to avoid contradictions, is to define $T_{z_0}^{\Bbb C}M$ as $\{z\in\Bbb C^n\;:\;z\cdot\partial r(z_0)=0\}$. But this doesn't seem ""the orthogonal to $\partial r(z_0)$ under hermitian product""! Can someone help me? Many thanks!","We define a real hypersurface as a subset $M\subset\Bbb C^n$ which is locally defined as the zero-locus of some $r\in\mathcal C^2(\Omega,\Bbb R)$ ($\Omega\subseteq\Bbb C^n$ open). Then let $z_0\in M$. If $\Bbb C^n$ was $\Bbb R^n$, we can easily see that such an $M$ is a $(n-1)$-dimensional variety. I hope in complex case it works as well. Allowing us to think that real facts works also here (and I'm well aware that this could be strongly wrong, but the only source I have is hyper-cryptic, so I hope in the good heart of someone of you!), we know the definition of tangent space to $M$ at $z_0$ (or the fiber of $z_0$): in the real case it was $\ker \Delta r(z_0)$, now my book says that it is ""the space of vectors othogonal to $\partial r(z_0)$ under hermitian product"", and denotes this with $T_{z_0}^{\Bbb C}M$. I obviously deduced that $$ T_{z_0}^{\Bbb C}M:=\{z\in\Bbb C^n\;:\;z\cdot\overline{\partial r(z_0)}=0\} $$ where $\partial r(z_0)=(\partial_{z_1}r(z_0),\dots,\partial_{z_n}r(z_0))$. But this can't be right because of something I found after (it deals with the well definition of the signature of the Levi form of $M$, and it would be really long to write: I think the important is to say that at this point I reached a contradiction). The way to avoid contradictions, is to define $T_{z_0}^{\Bbb C}M$ as $\{z\in\Bbb C^n\;:\;z\cdot\partial r(z_0)=0\}$. But this doesn't seem ""the orthogonal to $\partial r(z_0)$ under hermitian product""! Can someone help me? Many thanks!",,"['differential-geometry', 'complex-geometry', 'several-complex-variables']"
48,Sanity check: smooth structure of tangent bundle,Sanity check: smooth structure of tangent bundle,,"Let $M$ be a smooth $n$ manifold and let $TM$ denote its tangent bundle $$ TM = \bigsqcup_{x \in M} \{(x,T_x M)\}$$ I am trying to put a smooth structure (atlas) on $TM$ using the atlas on $M$. But I'm a bit confused and could do with some help: Say, $(x,T_x M)$ is a given point in the tangent bundle. So my goal is to find an open set containing $(x,T_x M)$ and a smoth diffeomorphism $\psi$ from this open set to an open set in $\mathbb R^{2n}$. Let $(U,\varphi)$ be a chart on $M$ such that $x \in U$. I want to use this chart to construct a chart $\psi$ on $TM$: First I need to think about the domain of $\psi$. It seems to me that it should look like $U \times$ some open set $V$ where the elements of $V$ are tangent spaces $T_x M$. And this is where I am confused: Where exactly would such an open set   $V$ live? There seems to be no space consisting of points of the form   $T_x M$. What am I doing wrong?","Let $M$ be a smooth $n$ manifold and let $TM$ denote its tangent bundle $$ TM = \bigsqcup_{x \in M} \{(x,T_x M)\}$$ I am trying to put a smooth structure (atlas) on $TM$ using the atlas on $M$. But I'm a bit confused and could do with some help: Say, $(x,T_x M)$ is a given point in the tangent bundle. So my goal is to find an open set containing $(x,T_x M)$ and a smoth diffeomorphism $\psi$ from this open set to an open set in $\mathbb R^{2n}$. Let $(U,\varphi)$ be a chart on $M$ such that $x \in U$. I want to use this chart to construct a chart $\psi$ on $TM$: First I need to think about the domain of $\psi$. It seems to me that it should look like $U \times$ some open set $V$ where the elements of $V$ are tangent spaces $T_x M$. And this is where I am confused: Where exactly would such an open set   $V$ live? There seems to be no space consisting of points of the form   $T_x M$. What am I doing wrong?",,['differential-geometry']
49,Find the parametric equation of the curve to be the intersection of the paraboloid $z=x^{2}+y^{2}$ and the plane $y=z$,Find the parametric equation of the curve to be the intersection of the paraboloid  and the plane,z=x^{2}+y^{2} y=z,"A space-curve $C$ is defined to be the intersection of the paraboloid $z=x^{2}+y^{2}$ and the plane $y=z$. How should one try to find the parametric equation of the curve? It seems natural to let $x=(t-t^{2})^{\frac{1}{2}}$, $y=t$, z=$t$. However, rearranging the equations I got $\frac{1}{4}=x^{2}+\left ( y-\frac{1}{2} \right )^{2}$, which calls for the substitution $x=\cos(t)$, $y=\frac{1}{2}+\sin(t)$, $z=\frac{1}{2}+\sin(t)$. Which one do you suggest? Any tips on generalizing parametrization?","A space-curve $C$ is defined to be the intersection of the paraboloid $z=x^{2}+y^{2}$ and the plane $y=z$. How should one try to find the parametric equation of the curve? It seems natural to let $x=(t-t^{2})^{\frac{1}{2}}$, $y=t$, z=$t$. However, rearranging the equations I got $\frac{1}{4}=x^{2}+\left ( y-\frac{1}{2} \right )^{2}$, which calls for the substitution $x=\cos(t)$, $y=\frac{1}{2}+\sin(t)$, $z=\frac{1}{2}+\sin(t)$. Which one do you suggest? Any tips on generalizing parametrization?",,"['differential-geometry', 'curves']"
50,Exterior derivative = infinitesimal change in differential form?,Exterior derivative = infinitesimal change in differential form?,,"For simplicity I'll work in $M=\mathbf R^2$. Given $f\in C^\infty(M)=\Omega^0(M)$, its exterior derivative $df$ is a 1-form that eats a tangent vector and spits out the best linear approximation of (the change in) $f$ if we walk along the direction specified by that vector. In other words, given a point $(x,y)\in M$ and a tangent vector $(dx,dy)\in T_{(x,y)}M$, our 1-form $df=\displaystyle\frac{\partial f}{\partial x}\,dx+\frac{\partial f}{\partial y}\,dy$ eats $(x,y,dx,dy)\in TM$ and spits out a real number that's supposed to be the infinitesimal change in $f$. The part I never really wrapped my head around is the exterior derivative of higher forms. In coordinates, it's usually defined to be $d(g\,dx+h\,dy)=dg\wedge dx+dh\wedge dy$ (and analogously for higher forms). Question: Can I interpret this to be the ""infinitesimal change in $\omega=g\,dx+h\,dy$""? Thus, instead of thinking of $d:\Omega^k(M)\to\Omega^{k+1}(M)$, can I think of $d\omega$ as eating a tangent vector and spitting out the infinitesimal change in $\omega$? Paraphrased: Does $X\lrcorner\, d\omega$ represent the infinitesimal change in $\omega$ in the direction $X$? I've noted that $X\lrcorner\,d\omega$ is ""half"" of Cartan's magic formula, which is also supposed to represent the infinitesimal change in $\omega$ if we flow along $X$, and this just completely confused me. At this point, I'm not even sure I know what I mean by ""infinitesimal change in $\omega$"" anymore. Is there any hope in trying to understand things the way I'm currently trying to, or should I just abandon this altogether and just live with the axioms?","For simplicity I'll work in $M=\mathbf R^2$. Given $f\in C^\infty(M)=\Omega^0(M)$, its exterior derivative $df$ is a 1-form that eats a tangent vector and spits out the best linear approximation of (the change in) $f$ if we walk along the direction specified by that vector. In other words, given a point $(x,y)\in M$ and a tangent vector $(dx,dy)\in T_{(x,y)}M$, our 1-form $df=\displaystyle\frac{\partial f}{\partial x}\,dx+\frac{\partial f}{\partial y}\,dy$ eats $(x,y,dx,dy)\in TM$ and spits out a real number that's supposed to be the infinitesimal change in $f$. The part I never really wrapped my head around is the exterior derivative of higher forms. In coordinates, it's usually defined to be $d(g\,dx+h\,dy)=dg\wedge dx+dh\wedge dy$ (and analogously for higher forms). Question: Can I interpret this to be the ""infinitesimal change in $\omega=g\,dx+h\,dy$""? Thus, instead of thinking of $d:\Omega^k(M)\to\Omega^{k+1}(M)$, can I think of $d\omega$ as eating a tangent vector and spitting out the infinitesimal change in $\omega$? Paraphrased: Does $X\lrcorner\, d\omega$ represent the infinitesimal change in $\omega$ in the direction $X$? I've noted that $X\lrcorner\,d\omega$ is ""half"" of Cartan's magic formula, which is also supposed to represent the infinitesimal change in $\omega$ if we flow along $X$, and this just completely confused me. At this point, I'm not even sure I know what I mean by ""infinitesimal change in $\omega$"" anymore. Is there any hope in trying to understand things the way I'm currently trying to, or should I just abandon this altogether and just live with the axioms?",,['differential-geometry']
51,Does intrinsic mean existing regardless of some bigger space?,Does intrinsic mean existing regardless of some bigger space?,,"How is the arc-length of a regular parametrized curve in a surface $S\subset\mathbb{R}^3$ intrinsic? Let $\bf{x}\rm(u,v)$ be a parametrization of $S$. Letting $E,F,G$ denote the coefficients of the first fundamental form, the arc length of a curve $\alpha:U\to S$ is said to be intrinsic because it can be computed with knowledge of only these coefficients as $$\int_0^t\sqrt{E(u^\prime)^2+2Fu^\prime v^\prime +G(v^\prime)^2}.$$But an ant living on the surface could not compute this value since $E,F,G$ are computed using points described by $3$-coordinates. The $3^{\text{rd}}$ coordinate does not exist to the ant. If one lived in $\mathbb{R}^2$ (or a surface which they think is $\mathbb{R}^2$), and did not know of the existence of $\mathbb{R}^3$, they would have no way to compute this value. Would they? I understand intrinsic meaning invariant under isometries, but I don't see how an intrinsic property can be computed or can exist without reference to some bigger space. To compute the Gaussian curvature at a point, you explicitly use the fact that the point is described by $3$ coordinates.","How is the arc-length of a regular parametrized curve in a surface $S\subset\mathbb{R}^3$ intrinsic? Let $\bf{x}\rm(u,v)$ be a parametrization of $S$. Letting $E,F,G$ denote the coefficients of the first fundamental form, the arc length of a curve $\alpha:U\to S$ is said to be intrinsic because it can be computed with knowledge of only these coefficients as $$\int_0^t\sqrt{E(u^\prime)^2+2Fu^\prime v^\prime +G(v^\prime)^2}.$$But an ant living on the surface could not compute this value since $E,F,G$ are computed using points described by $3$-coordinates. The $3^{\text{rd}}$ coordinate does not exist to the ant. If one lived in $\mathbb{R}^2$ (or a surface which they think is $\mathbb{R}^2$), and did not know of the existence of $\mathbb{R}^3$, they would have no way to compute this value. Would they? I understand intrinsic meaning invariant under isometries, but I don't see how an intrinsic property can be computed or can exist without reference to some bigger space. To compute the Gaussian curvature at a point, you explicitly use the fact that the point is described by $3$ coordinates.",,"['differential-geometry', 'surfaces', 'curvature', 'curves']"
52,Universal property of the tensor product,Universal property of the tensor product,,"Assume $\Phi:V_1^*\times ...\times V_k^* \rightarrow L(V_1,...,V_k;\mathbb{R})$ is a multilinear map. $$\Phi (w^1,...,w^k)(v_1,...,v_k)=w^1(v_1)...w^k(v_k)$$ By the universal property of the tensor product this descends to a linear map $\tilde{\Phi}: V_1^*\otimes ... \otimes V_k^* \rightarrow L(V_1,...,V_k;\mathbb{R})$ $$\tilde{\Phi}(w^1 \otimes ... \otimes w^k)(v_1,...,v_k)=w^1(v_1)...w^k(v_k)$$ And now I hate myself for asking, but how is it we conclude that $\tilde{\Phi}$ is an isomorphism, s.t. $V_1^*\otimes ... \otimes V_k^* \overset{\sim}{=} L(V_1,...,V_k;\mathbb{R})$","Assume $\Phi:V_1^*\times ...\times V_k^* \rightarrow L(V_1,...,V_k;\mathbb{R})$ is a multilinear map. $$\Phi (w^1,...,w^k)(v_1,...,v_k)=w^1(v_1)...w^k(v_k)$$ By the universal property of the tensor product this descends to a linear map $\tilde{\Phi}: V_1^*\otimes ... \otimes V_k^* \rightarrow L(V_1,...,V_k;\mathbb{R})$ $$\tilde{\Phi}(w^1 \otimes ... \otimes w^k)(v_1,...,v_k)=w^1(v_1)...w^k(v_k)$$ And now I hate myself for asking, but how is it we conclude that $\tilde{\Phi}$ is an isomorphism, s.t. $V_1^*\otimes ... \otimes V_k^* \overset{\sim}{=} L(V_1,...,V_k;\mathbb{R})$",,"['differential-geometry', 'tensor-products', 'tensors']"
53,"If a composition of two maps is smooth, as well as one of the maps, then so is the other.","If a composition of two maps is smooth, as well as one of the maps, then so is the other.",,"Let $M$, $N$, and $K$ be smooth manifolds, and consider the maps $g:M\to N$, and $f:N\to L$. Assume that the composition $f\circ g$ is smooth. If any of $f$ and $g$ is smooth can we conclude that the other is also smooth? In particular, is $f$ smooth if $g$ is a smooth surjection? Is any of the preceding statements a case of a categorical theorem? What conditions should $f$ and $g$ satisfy for the first statement to hold true? What conditions should $f$ and $g$ satisfy for the second statement to be true?","Let $M$, $N$, and $K$ be smooth manifolds, and consider the maps $g:M\to N$, and $f:N\to L$. Assume that the composition $f\circ g$ is smooth. If any of $f$ and $g$ is smooth can we conclude that the other is also smooth? In particular, is $f$ smooth if $g$ is a smooth surjection? Is any of the preceding statements a case of a categorical theorem? What conditions should $f$ and $g$ satisfy for the first statement to hold true? What conditions should $f$ and $g$ satisfy for the second statement to be true?",,"['differential-geometry', 'category-theory', 'smooth-manifolds', 'function-and-relation-composition']"
54,Exercise 2.3 Lee's Riemmanian Manifolds,Exercise 2.3 Lee's Riemmanian Manifolds,,"Statement: Suppose $M\subseteq \tilde{M}$ is an embedded submanifold. a)If $f$ is any smooth function on $M$, show that $f$ can be extended to a smooth function on $\tilde{M}$ whose restriction to $M$ is $f$. Question: So I'm wondering if there is some mistake in the statement, since there seems to be a simple counterexample, namely $f:(0,1)\rightarrow\mathbb{R}$, where $f(x)=\frac{1}{x}$. If it is a simple oversight, how should the question be reworded? I have been able to prove it assuming $f$ is a smooth function on some closed sub manifold, but I am unsure if that was the intended question.","Statement: Suppose $M\subseteq \tilde{M}$ is an embedded submanifold. a)If $f$ is any smooth function on $M$, show that $f$ can be extended to a smooth function on $\tilde{M}$ whose restriction to $M$ is $f$. Question: So I'm wondering if there is some mistake in the statement, since there seems to be a simple counterexample, namely $f:(0,1)\rightarrow\mathbb{R}$, where $f(x)=\frac{1}{x}$. If it is a simple oversight, how should the question be reworded? I have been able to prove it assuming $f$ is a smooth function on some closed sub manifold, but I am unsure if that was the intended question.",,"['differential-geometry', 'smooth-manifolds']"
55,Derivative of exponential maps in Lie group $G$ and the adjoint operator on its Lie algebra,Derivative of exponential maps in Lie group  and the adjoint operator on its Lie algebra,G,"Let $G$ be a (not necessarily compact, probably even infinite dimensional) Lie group, and $g$  be its Lie algebra. Let $V,W\in g$. Consider $J(t):=(Dexp)_{tV}(tW)$ be the result of differential of the Lie group exponential map $exp:g\to G$ at $tV$ acting on $tW$. Can we express $J(t)$ in terms of the adjoint operator $ad$ on $g$, defined by $ad_X(Y)=[X,Y]$. I'd really appreciate a detailed answer if possible. In my case $G$ is a certain subgroup of diffeomorphism group of a manifold, and $g$ is a subspace of vector fields on that manifold. But I don't think this piece of information will be necessary. Also, how can we relate the derivative of the Lie group exponential map $exp:g\to G$ in terms of the above adjoint operator? Thank you!","Let $G$ be a (not necessarily compact, probably even infinite dimensional) Lie group, and $g$  be its Lie algebra. Let $V,W\in g$. Consider $J(t):=(Dexp)_{tV}(tW)$ be the result of differential of the Lie group exponential map $exp:g\to G$ at $tV$ acting on $tW$. Can we express $J(t)$ in terms of the adjoint operator $ad$ on $g$, defined by $ad_X(Y)=[X,Y]$. I'd really appreciate a detailed answer if possible. In my case $G$ is a certain subgroup of diffeomorphism group of a manifold, and $g$ is a subspace of vector fields on that manifold. But I don't think this piece of information will be necessary. Also, how can we relate the derivative of the Lie group exponential map $exp:g\to G$ in terms of the above adjoint operator? Thank you!",,"['differential-geometry', 'lie-groups', 'lie-algebras', 'lie-derivative']"
56,a question about undergraduate-level differential geometry(Gauss-Bonnet theorem),a question about undergraduate-level differential geometry(Gauss-Bonnet theorem),,"Let $S\subset R^3$ be a regular surface homeomorphic to a sphere. Let $\alpha\subset S $ be a simple closed geodesic in S,let A and B be a regions of S which have $\alpha$ as a common boundary. Let N:$S->S^2$ be the Gauss map of S. prove that N(A) and N(B) have the same area. My thoughts: I think I need to use Gauss-Bonnet theorem,since the curve $\alpha$ can be mapped into a sphere,and the mapped the curve should be smooth(But I am not sure whether it is still geodesic),so use Gauss-Bonnet Theorem, we have $$\iint_{N(A)}Kds+\int_{0}^lk_{g}ds=2\pi X(s)$$,where X(s) is the Euler-poincare characteristic of a regular surface. if the geodesic curvature $k_{g}$=0,I can know that the area of N(A) should be $2\pi$,since the Gaussian curvature k=1 in the unit sphere,but I have no idea whether the geodesic curve in the original surface is still be geodesic in the sphere. Any help?","Let $S\subset R^3$ be a regular surface homeomorphic to a sphere. Let $\alpha\subset S $ be a simple closed geodesic in S,let A and B be a regions of S which have $\alpha$ as a common boundary. Let N:$S->S^2$ be the Gauss map of S. prove that N(A) and N(B) have the same area. My thoughts: I think I need to use Gauss-Bonnet theorem,since the curve $\alpha$ can be mapped into a sphere,and the mapped the curve should be smooth(But I am not sure whether it is still geodesic),so use Gauss-Bonnet Theorem, we have $$\iint_{N(A)}Kds+\int_{0}^lk_{g}ds=2\pi X(s)$$,where X(s) is the Euler-poincare characteristic of a regular surface. if the geodesic curvature $k_{g}$=0,I can know that the area of N(A) should be $2\pi$,since the Gaussian curvature k=1 in the unit sphere,but I have no idea whether the geodesic curve in the original surface is still be geodesic in the sphere. Any help?",,"['real-analysis', 'differential-geometry', 'riemannian-geometry']"
57,The Poincaré dual of a space-time curve,The Poincaré dual of a space-time curve,,"We have a smooth space-time curve defined by $f:C{\mapsto}M$, where $M$ is a typical curved space-time manifold. ${\eta}^{(4)}$ is the volume 4-form defined on $M$ and ${\varepsilon}^{(1)}$ is the (non-degenerate) volume 1-form induced on $C$. As usual, both forms are defined by the space-time metric. Making  reasonable assumptions about the curve, how does one find its Poincaré dual, denoted by the closed 3-form ${\beta}$.","We have a smooth space-time curve defined by $f:C{\mapsto}M$, where $M$ is a typical curved space-time manifold. ${\eta}^{(4)}$ is the volume 4-form defined on $M$ and ${\varepsilon}^{(1)}$ is the (non-degenerate) volume 1-form induced on $C$. As usual, both forms are defined by the space-time metric. Making  reasonable assumptions about the curve, how does one find its Poincaré dual, denoted by the closed 3-form ${\beta}$.",,"['differential-geometry', 'algebraic-topology', 'mathematical-physics']"
58,How do I understand constraints on high order derivatives of the Gauss Map?,How do I understand constraints on high order derivatives of the Gauss Map?,,"I'm trying to understand the constraints resulting from differentiating an unit normal field $N$ on a surface $S$ in $\mathbb{R}^3$.  If I write the unit-length constraint at a point $p \in S$, I have:  $$\langle N(p), N(p) \rangle = 1$$ Here, the angle brackets correspond to the standard dot product in $\mathbb{R}^3$. (For notational simplicity, I'll leave out the $p$ from now on.)  I can take a directional derivative of this equation in the direction $\vec{v} \in T_p S$ to get: $$ \langle D_\vec{v} N, N \rangle + \langle N, D_{\vec{v}} N \rangle = 0  $$ This shows that the image of the differential of the Gauss Map lies in $T_p (S)$. I can continue along this analysis, taking more and more directional derivatives to get constraints on the higher derivatives, e.g if $\vec{u} \in T_p (S)$ $$ \langle D_{\vec{u}} (D_\vec{v} N), N \rangle + \langle  D_\vec{v} N, D_\vec{u} N \rangle + \langle  D_\vec{u} N, D_\vec{v} N \rangle + \langle N, D_{\vec{u}}(D_{\vec{v}} N)\rangle = 0 $$ I would like to think of this process in tensorial terms -- that is, terms like $D_{\vec{u}} (D_\vec{v} N)$ can be considered as a $(1, 2)$ tensor.  So, let me write $D_{\vec{u}} (D_\vec{v} N)$ as $D^2 N$ and so on. For example, if I take $m$ derivatives, I will get terms such as T = $\langle D^i N, D^j N \rangle$ where $i + j = m$. I believe I can think of $T$ as a $(0, m)$ tensor, where I place the first $i$ inputs into the $D^i N$ and the next $j$ inputs into the $D^j N$.  To be more precise, I think I need to consider $D^i N$ as a (1, i) tensor and $D^j N$ as a (1, j) tensor and then the dot product forms some kind of contraction. My question involves how to represent these terms via arrays and computation. How do I represent a single term like $T$ as a m-dimensional array that can take in $m$ vectors?  For now, I would just like to verify (via code and a given surface, so I can calculate derivatives of the normal field of any order) that if I sum up the L.H.S of each equation, I will get 0.  But how do I express these tensors correctly? I do not want to choose my directions (like $\vec{v}, \vec{u}$) explicitly, but instead write the tensor formulations as arrays of numbers in a tangent plane basis.  So, when I sum up all the terms, I should get a m-dimensional array of zeros. I think I need to be careful, as there is an ordering of inputs that notation like $D^i N$ hides.   That is, there will be multiple terms involved of the same order derivatives, but involving different input vectors.  For example, if my first three inputs are $\{\vec{v}, \vec{u}, \vec{w}\}$, I don't think I can consider the tensor $\langle D_\vec{u} (D_\vec{v} N), D_\vec{w} N \rangle$ as equal to the tensor $\langle D_\vec{w} (D_\vec{v} N), D_\vec{u} N \rangle$.  Thus, I believe I will need to rearrange dimensions of these arrays in a proper fashion.  But I don't know what ""proper"" is. I apologize if this writeup is unclear; please ask for clarification if needed.  And thank you so much for any enlightenment you can give me!  Even a suitable reference would be much appreciated! EDIT: To be more precise about my confusion:  Suppose I take $n$ derivatives.  I will have terms like $D^i N$, with $i < n$.  Although an individual $D^i N$ is a $2 \times 2 \cdots \times 2 \times 3$ array, with $i + 1$ total dimensions, I need to ""embed"" it as a $n + 1$ dimensional array in order to dot product it or sum it with the various other terms in the equation.  This is because the different $D^i N$ terms are tensors acting on different sets of input vectors.  So, to combine these different tensors, I need to place them all in the same space -- the space of $(1, n)$ tensors. If I know my normal field and surface completely, this should just be a matter of bookkeeping.  I believe I just pad certain dimensions (corresponding to the unused inputs) of the arrays with copies of the rows from the dimensions of the used inputs.  In this fashion, these tensors will be independent of the set of $n - i$ unused inputs. Is this correct?","I'm trying to understand the constraints resulting from differentiating an unit normal field $N$ on a surface $S$ in $\mathbb{R}^3$.  If I write the unit-length constraint at a point $p \in S$, I have:  $$\langle N(p), N(p) \rangle = 1$$ Here, the angle brackets correspond to the standard dot product in $\mathbb{R}^3$. (For notational simplicity, I'll leave out the $p$ from now on.)  I can take a directional derivative of this equation in the direction $\vec{v} \in T_p S$ to get: $$ \langle D_\vec{v} N, N \rangle + \langle N, D_{\vec{v}} N \rangle = 0  $$ This shows that the image of the differential of the Gauss Map lies in $T_p (S)$. I can continue along this analysis, taking more and more directional derivatives to get constraints on the higher derivatives, e.g if $\vec{u} \in T_p (S)$ $$ \langle D_{\vec{u}} (D_\vec{v} N), N \rangle + \langle  D_\vec{v} N, D_\vec{u} N \rangle + \langle  D_\vec{u} N, D_\vec{v} N \rangle + \langle N, D_{\vec{u}}(D_{\vec{v}} N)\rangle = 0 $$ I would like to think of this process in tensorial terms -- that is, terms like $D_{\vec{u}} (D_\vec{v} N)$ can be considered as a $(1, 2)$ tensor.  So, let me write $D_{\vec{u}} (D_\vec{v} N)$ as $D^2 N$ and so on. For example, if I take $m$ derivatives, I will get terms such as T = $\langle D^i N, D^j N \rangle$ where $i + j = m$. I believe I can think of $T$ as a $(0, m)$ tensor, where I place the first $i$ inputs into the $D^i N$ and the next $j$ inputs into the $D^j N$.  To be more precise, I think I need to consider $D^i N$ as a (1, i) tensor and $D^j N$ as a (1, j) tensor and then the dot product forms some kind of contraction. My question involves how to represent these terms via arrays and computation. How do I represent a single term like $T$ as a m-dimensional array that can take in $m$ vectors?  For now, I would just like to verify (via code and a given surface, so I can calculate derivatives of the normal field of any order) that if I sum up the L.H.S of each equation, I will get 0.  But how do I express these tensors correctly? I do not want to choose my directions (like $\vec{v}, \vec{u}$) explicitly, but instead write the tensor formulations as arrays of numbers in a tangent plane basis.  So, when I sum up all the terms, I should get a m-dimensional array of zeros. I think I need to be careful, as there is an ordering of inputs that notation like $D^i N$ hides.   That is, there will be multiple terms involved of the same order derivatives, but involving different input vectors.  For example, if my first three inputs are $\{\vec{v}, \vec{u}, \vec{w}\}$, I don't think I can consider the tensor $\langle D_\vec{u} (D_\vec{v} N), D_\vec{w} N \rangle$ as equal to the tensor $\langle D_\vec{w} (D_\vec{v} N), D_\vec{u} N \rangle$.  Thus, I believe I will need to rearrange dimensions of these arrays in a proper fashion.  But I don't know what ""proper"" is. I apologize if this writeup is unclear; please ask for clarification if needed.  And thank you so much for any enlightenment you can give me!  Even a suitable reference would be much appreciated! EDIT: To be more precise about my confusion:  Suppose I take $n$ derivatives.  I will have terms like $D^i N$, with $i < n$.  Although an individual $D^i N$ is a $2 \times 2 \cdots \times 2 \times 3$ array, with $i + 1$ total dimensions, I need to ""embed"" it as a $n + 1$ dimensional array in order to dot product it or sum it with the various other terms in the equation.  This is because the different $D^i N$ terms are tensors acting on different sets of input vectors.  So, to combine these different tensors, I need to place them all in the same space -- the space of $(1, n)$ tensors. If I know my normal field and surface completely, this should just be a matter of bookkeeping.  I believe I just pad certain dimensions (corresponding to the unused inputs) of the arrays with copies of the rows from the dimensions of the used inputs.  In this fashion, these tensors will be independent of the set of $n - i$ unused inputs. Is this correct?",,"['differential-geometry', 'tensors']"
59,Finding critical values of a function on an embedded surface,Finding critical values of a function on an embedded surface,,"Prior to the problem, we have already shown that $\Sigma=\{x_1x_2^2+x_2x_3^2+x_3x_1^2=1\}\subset\mathbb{R}^3$ is an embedded hypersurface and that the function $f:\Sigma\rightarrow\mathbb{R};(x_1,x_2,x_3)\mapsto x_1$ is surjective. The problem asks to find the critical values of $f$. If we had a ""nice"" global coordinate chart on $\Sigma$, which is 2-dimensional, we could calculate the differential of $f$ in these coordinates and find out where it vanishes. The canonical coordinates inherited from $\mathbb{R}^3$ are however 3-dimensional and not appropriate for this purpose. Therefore, we tried to use the following trick: Define $F:\mathbb{R}^3\rightarrow\mathbb{R};F(x_1,x_2,x_3)=x_1x_2^2+x_2x_3^2+x_3x_1^2$ and $E_a:=\{(a,x_2,x_3)\in\mathbb{R}^3|x_2,x_3\in\mathbb{R}\}$ for some $a\in\mathbb{R}$. We claim that the critical points of $f$ are exactly the critical points of $F|_{E_a}$ which also lie in $\Sigma$. Assuming this claim to be true, we calculated \begin{equation} d(F|_{E_a})_{(x_2,x_3)}=\begin{pmatrix}x_3^2+2ax_2&&2x_2x_3+a^2\end{pmatrix} \end{equation} If $a=0$, then $d(F|_{E_a})_{(x_2,x_3)}=0$ implies $x_3=0$ and $x_2$ is arbitrary, but this triple does not lie on $\Sigma$. If $a\neq 0$, $d(F|_{E_a})_{(x_2,x_3)}=0$ implies $x_3=a$ and $x_2=-a/2$, then $(a,-a/2,a)\in\Sigma$ implies $a=\sqrt[3]4$. Hence, $\sqrt[3]4$ is the only critical value of $f$. The question is: Is the claim correct? If yes, how can we prove it? If no, how can we solve the original problem?","Prior to the problem, we have already shown that $\Sigma=\{x_1x_2^2+x_2x_3^2+x_3x_1^2=1\}\subset\mathbb{R}^3$ is an embedded hypersurface and that the function $f:\Sigma\rightarrow\mathbb{R};(x_1,x_2,x_3)\mapsto x_1$ is surjective. The problem asks to find the critical values of $f$. If we had a ""nice"" global coordinate chart on $\Sigma$, which is 2-dimensional, we could calculate the differential of $f$ in these coordinates and find out where it vanishes. The canonical coordinates inherited from $\mathbb{R}^3$ are however 3-dimensional and not appropriate for this purpose. Therefore, we tried to use the following trick: Define $F:\mathbb{R}^3\rightarrow\mathbb{R};F(x_1,x_2,x_3)=x_1x_2^2+x_2x_3^2+x_3x_1^2$ and $E_a:=\{(a,x_2,x_3)\in\mathbb{R}^3|x_2,x_3\in\mathbb{R}\}$ for some $a\in\mathbb{R}$. We claim that the critical points of $f$ are exactly the critical points of $F|_{E_a}$ which also lie in $\Sigma$. Assuming this claim to be true, we calculated \begin{equation} d(F|_{E_a})_{(x_2,x_3)}=\begin{pmatrix}x_3^2+2ax_2&&2x_2x_3+a^2\end{pmatrix} \end{equation} If $a=0$, then $d(F|_{E_a})_{(x_2,x_3)}=0$ implies $x_3=0$ and $x_2$ is arbitrary, but this triple does not lie on $\Sigma$. If $a\neq 0$, $d(F|_{E_a})_{(x_2,x_3)}=0$ implies $x_3=a$ and $x_2=-a/2$, then $(a,-a/2,a)\in\Sigma$ implies $a=\sqrt[3]4$. Hence, $\sqrt[3]4$ is the only critical value of $f$. The question is: Is the claim correct? If yes, how can we prove it? If no, how can we solve the original problem?",,"['differential-geometry', 'smooth-manifolds']"
60,What is the exterior algebra?,What is the exterior algebra?,,"I am learning differential geometry, and I have difficulty understanding the construction of the exterior algebra of an $n$-dimensional vector space $V$. We have the wedge product $$\wedge:\Lambda^k(V^\ast)\times\Lambda^l(V^\ast)\to\Lambda^{k+l}(V^\ast)$$ defined as $$\omega\wedge\eta=\frac{(k+l)!}{k!l!}\operatorname{Alt}(\omega\otimes\eta)$$ and that's all right. Then one just define the exterior algebra to be the direct sum $$\Lambda(V^\ast)=\bigoplus_{k=0}^n\Lambda^k(V^\ast),$$ and that is supposed to be an algebra. But $\wedge$ is defined only on $\Lambda^k(V^\ast)\times\Lambda^l(V^\ast)$, so how does it act on a general element? Component wise? Question: If $(\omega_0,\ldots,\omega_n)\in\Lambda(V^*)$ and $(\eta_0,\ldots,\eta_n)\in\Lambda(V^*)$, what is $$(\omega_0,\ldots,\omega_n)\wedge(\eta_0,\ldots,\eta_n)?$$","I am learning differential geometry, and I have difficulty understanding the construction of the exterior algebra of an $n$-dimensional vector space $V$. We have the wedge product $$\wedge:\Lambda^k(V^\ast)\times\Lambda^l(V^\ast)\to\Lambda^{k+l}(V^\ast)$$ defined as $$\omega\wedge\eta=\frac{(k+l)!}{k!l!}\operatorname{Alt}(\omega\otimes\eta)$$ and that's all right. Then one just define the exterior algebra to be the direct sum $$\Lambda(V^\ast)=\bigoplus_{k=0}^n\Lambda^k(V^\ast),$$ and that is supposed to be an algebra. But $\wedge$ is defined only on $\Lambda^k(V^\ast)\times\Lambda^l(V^\ast)$, so how does it act on a general element? Component wise? Question: If $(\omega_0,\ldots,\omega_n)\in\Lambda(V^*)$ and $(\eta_0,\ldots,\eta_n)\in\Lambda(V^*)$, what is $$(\omega_0,\ldots,\omega_n)\wedge(\eta_0,\ldots,\eta_n)?$$",,"['differential-geometry', 'exterior-algebra']"
61,Stokes theorem for manifolds with corners,Stokes theorem for manifolds with corners,,"I wonder if you could recommend a chapter or a paper on Stokes theorem for manifolds with corners. I've found one here http://math.stanford.edu/~conrad/diffgeomPage/handouts.html (the third one from the bottom). The statement is: Let $(M, \mu)$ be an oriented manifold with corners and with constant dimension $n \ge 1$. Choose a compactly supported $\omega \in \Omega_{n-1}(M)$ and give $\partial (M_{\le 1})$ the induuced orientation $\partial \mu$ as the boundary of the manifold-with-boundary $M_{n \le 1}$. Then $\omega$ is absolutely integrable on $\partial (M_{\le 1})$ and $\int_{M} d \omega = \int_{\partial M_{\le 1}} \omega$ But while proving the theorem, the author explains how to prove the theorem above copying the proof of the Stokes theorem for manifolds with boundary and the problem is that I cannot find that proof on his website. Do you know any other papers or books where (maybe other version of ) the theorem is proved?","I wonder if you could recommend a chapter or a paper on Stokes theorem for manifolds with corners. I've found one here http://math.stanford.edu/~conrad/diffgeomPage/handouts.html (the third one from the bottom). The statement is: Let $(M, \mu)$ be an oriented manifold with corners and with constant dimension $n \ge 1$. Choose a compactly supported $\omega \in \Omega_{n-1}(M)$ and give $\partial (M_{\le 1})$ the induuced orientation $\partial \mu$ as the boundary of the manifold-with-boundary $M_{n \le 1}$. Then $\omega$ is absolutely integrable on $\partial (M_{\le 1})$ and $\int_{M} d \omega = \int_{\partial M_{\le 1}} \omega$ But while proving the theorem, the author explains how to prove the theorem above copying the proof of the Stokes theorem for manifolds with boundary and the problem is that I cannot find that proof on his website. Do you know any other papers or books where (maybe other version of ) the theorem is proved?",,"['real-analysis', 'integration', 'differential-geometry', 'smooth-manifolds']"
62,Lifting an $\mathbb{RP}^{n-1}$-valued map to an $S^{n-1}$-valued map.,Lifting an -valued map to an -valued map.,\mathbb{RP}^{n-1} S^{n-1},"Let $M$ be a smooth manifold and assume that for each $v\in M$, I have a vector $v(m)\in\mathbb{R}\setminus\{0\}$ with some property and this vector is unique up to multiple : further, it depends smoothly on $m$. I would like to define a smooth map $F: M\to S^{n-1}$ that sends $m$ to a representative unit vector with the required property. Under which conditions can this be done? I understand that it is a lifting problem: I want to lift a smooth map $f: M\to\mathbb{RP}^{n-1}$ to a map $F: M\to S^{n-1}$. If necessary, I can assume that $\mathrm{dim}\, M<n-1$ but I'm not sure if it is sufficient. Then $f(M)$ has ""lower dimension"" then $n-1$ and I can assume that it aviods a point, but I can hardly assume that it aviods the whole $\mathbb{RP}^{n-2}$ (in which case I could define a global section on $\mathbb{RP}^{n-1}\setminus\mathbb{RP}^{n-2}\to S^{n-1}$).. Any hint please?","Let $M$ be a smooth manifold and assume that for each $v\in M$, I have a vector $v(m)\in\mathbb{R}\setminus\{0\}$ with some property and this vector is unique up to multiple : further, it depends smoothly on $m$. I would like to define a smooth map $F: M\to S^{n-1}$ that sends $m$ to a representative unit vector with the required property. Under which conditions can this be done? I understand that it is a lifting problem: I want to lift a smooth map $f: M\to\mathbb{RP}^{n-1}$ to a map $F: M\to S^{n-1}$. If necessary, I can assume that $\mathrm{dim}\, M<n-1$ but I'm not sure if it is sufficient. Then $f(M)$ has ""lower dimension"" then $n-1$ and I can assume that it aviods a point, but I can hardly assume that it aviods the whole $\mathbb{RP}^{n-2}$ (in which case I could define a global section on $\mathbb{RP}^{n-1}\setminus\mathbb{RP}^{n-2}\to S^{n-1}$).. Any hint please?",,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
63,When is a curve parametrizable?,When is a curve parametrizable?,,Is there a way in general to tell whether a given curve is parametrizable?,Is there a way in general to tell whether a given curve is parametrizable?,,['differential-geometry']
64,Differentiable manifolds that allow isometric transition maps.,Differentiable manifolds that allow isometric transition maps.,,"What is the class of differentiable n-dimensional manifolds that allow a differential structure, in which all transition maps are isometric? Note that isometric must be overlapping pieces of charts only; however, mapping from charts to manifold can be arbitrary non-linear function. I know such manifolds exist. For example: Trivial example: a graph of a differentiable function is such manifold. A circle: I can construct an atlas of two charts: upper and lower parts that overlap by $\varepsilon$. Since charts overlap by intervals of equal length $\varepsilon$, I can build isometric transition map. A 2D torus ($\mathbb{T}^2$): I can build 4 charts that overlap by small rectangles. These rectangles can be made isometric to one another. Also, places where all 4 charts overlap can be made isometric as well. This construction seems to fail for a 2D sphere. So, I'm wondering which class of n-dimensional differentiable manifolds satisfies given constraints on differential structure? EDIT: In mathematical terms: Which differentiable manifolds allow   differential structure   $\big\{\big(\phi_\alpha, U_\alpha\big)\big\}_{\alpha \in \mathcal{A}}$   such that: $\forall \alpha, \beta \in \mathcal{A}$,    if $U_\alpha \bigcap U_\beta \not= \emptyset$, then the restriction   $\phi_\alpha \circ \phi^{-1}_\beta\big|_{\phi_\beta (U_\alpha \cap U_\beta)}$   is an isometric map between sets $\phi_\beta (U_\alpha \cap U_\beta)$ and   $\phi_\alpha (U_\alpha \cap U_\beta)$ in $\mathbb{R}^n$? Note that neither $\phi_\alpha$ nor $\phi_\beta$ need not be   isometric maps. Also note that $U_\alpha$ and $U_\beta$ need not be   isometric to each other as well.","What is the class of differentiable n-dimensional manifolds that allow a differential structure, in which all transition maps are isometric? Note that isometric must be overlapping pieces of charts only; however, mapping from charts to manifold can be arbitrary non-linear function. I know such manifolds exist. For example: Trivial example: a graph of a differentiable function is such manifold. A circle: I can construct an atlas of two charts: upper and lower parts that overlap by $\varepsilon$. Since charts overlap by intervals of equal length $\varepsilon$, I can build isometric transition map. A 2D torus ($\mathbb{T}^2$): I can build 4 charts that overlap by small rectangles. These rectangles can be made isometric to one another. Also, places where all 4 charts overlap can be made isometric as well. This construction seems to fail for a 2D sphere. So, I'm wondering which class of n-dimensional differentiable manifolds satisfies given constraints on differential structure? EDIT: In mathematical terms: Which differentiable manifolds allow   differential structure   $\big\{\big(\phi_\alpha, U_\alpha\big)\big\}_{\alpha \in \mathcal{A}}$   such that: $\forall \alpha, \beta \in \mathcal{A}$,    if $U_\alpha \bigcap U_\beta \not= \emptyset$, then the restriction   $\phi_\alpha \circ \phi^{-1}_\beta\big|_{\phi_\beta (U_\alpha \cap U_\beta)}$   is an isometric map between sets $\phi_\beta (U_\alpha \cap U_\beta)$ and   $\phi_\alpha (U_\alpha \cap U_\beta)$ in $\mathbb{R}^n$? Note that neither $\phi_\alpha$ nor $\phi_\beta$ need not be   isometric maps. Also note that $U_\alpha$ and $U_\beta$ need not be   isometric to each other as well.",,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
65,Moving frame in a semi-Riemannian manifold,Moving frame in a semi-Riemannian manifold,,"Can someone point me some reference for the moving frame theory in semi-Riemannian manifolds, using differential forms? In special, I'm looking for a version of Cartan's structural equations. I've already looked the references given in this answer , but it is not exactly what I'm looking for. I also took a look in O'Neill's ""The Geometry of Kerr Black Holes"", but it wasn't helpful to me: the way he defines the connection forms $\omega_{ij}$ is different than the way he defines them in his first book Elementary Differential Geometry (indices swapped, and something more, it seems). I managed to adapt the connection equations, and his expression for the connection forms $\omega = dA \cdot A^t$ (page $91$), with some changes, but I'm failing to get the structural equations (page $95$). My level of background is more or less of this book. I'm not familiar with tensors. Just more or less with differential forms. If someone knows any text who does something like that, it would help me a lot. Thanks.","Can someone point me some reference for the moving frame theory in semi-Riemannian manifolds, using differential forms? In special, I'm looking for a version of Cartan's structural equations. I've already looked the references given in this answer , but it is not exactly what I'm looking for. I also took a look in O'Neill's ""The Geometry of Kerr Black Holes"", but it wasn't helpful to me: the way he defines the connection forms $\omega_{ij}$ is different than the way he defines them in his first book Elementary Differential Geometry (indices swapped, and something more, it seems). I managed to adapt the connection equations, and his expression for the connection forms $\omega = dA \cdot A^t$ (page $91$), with some changes, but I'm failing to get the structural equations (page $95$). My level of background is more or less of this book. I'm not familiar with tensors. Just more or less with differential forms. If someone knows any text who does something like that, it would help me a lot. Thanks.",,"['reference-request', 'differential-geometry', 'differential-forms', 'book-recommendation', 'semi-riemannian-geometry']"
66,A question on self-dual differential 2-forms,A question on self-dual differential 2-forms,,"This question is from Lemma 2 in Derdzinski's paper . Let $$\omega=e_1\wedge e_2+e_3\wedge e_4, \eta=e_1\wedge e_3+e_4\wedge e_2, \theta=e_1\wedge e_4+e_2\wedge e_3$$ be a basis for self-dual two-forms on a four-manifold, where $\{e_1,e_2,e_3,e_4\}$ is an orthonormal basis of the tangent space. Derdzinski said that $$\omega^2=\eta^2=\theta^2=-id,\ \omega\eta=\theta=-\eta\omega.$$ I was wondering what $\omega^2=-id$ and $\omega\eta=\theta$ mean? Is this wedge product or other operation? Thank you very much.","This question is from Lemma 2 in Derdzinski's paper . Let $$\omega=e_1\wedge e_2+e_3\wedge e_4, \eta=e_1\wedge e_3+e_4\wedge e_2, \theta=e_1\wedge e_4+e_2\wedge e_3$$ be a basis for self-dual two-forms on a four-manifold, where $\{e_1,e_2,e_3,e_4\}$ is an orthonormal basis of the tangent space. Derdzinski said that $$\omega^2=\eta^2=\theta^2=-id,\ \omega\eta=\theta=-\eta\omega.$$ I was wondering what $\omega^2=-id$ and $\omega\eta=\theta$ mean? Is this wedge product or other operation? Thank you very much.",,"['differential-geometry', 'riemannian-geometry', 'differential-forms']"
67,Special reference for differential geometry,Special reference for differential geometry,,"I am not entirely sure how to formulate the question, but here it is. I am looking to start a self study on general relativity, and of course I need a good grasp on semi-riemannian geometry (I am currently using O' Neill's book). However, when I was still looking for references, I recall reading an answer here, in this site, which said something along the lines of ""choose a book without those damn Christoffel symbols"" (though I can't really find it again). The question was about differential geometry books, without any mention to G.R. Now, I've seen how Christoffel symbols are important in general relativity, and a friend of mine who has already studied it a little deeper said he doesn't really know how to  get around them. So, I guess my question is: is there a way to work on the theory of G.R. without those symbols or, more importantly, is there a book that does such a treatment? (sorry about this very odd question; I asked here on MathSX because I'm looking for something like O' Neill, a math book with references to physics)","I am not entirely sure how to formulate the question, but here it is. I am looking to start a self study on general relativity, and of course I need a good grasp on semi-riemannian geometry (I am currently using O' Neill's book). However, when I was still looking for references, I recall reading an answer here, in this site, which said something along the lines of ""choose a book without those damn Christoffel symbols"" (though I can't really find it again). The question was about differential geometry books, without any mention to G.R. Now, I've seen how Christoffel symbols are important in general relativity, and a friend of mine who has already studied it a little deeper said he doesn't really know how to  get around them. So, I guess my question is: is there a way to work on the theory of G.R. without those symbols or, more importantly, is there a book that does such a treatment? (sorry about this very odd question; I asked here on MathSX because I'm looking for something like O' Neill, a math book with references to physics)",,"['reference-request', 'differential-geometry', 'general-relativity']"
68,Differential Geometry Intuition Question,Differential Geometry Intuition Question,,"Apologies if I get the notation wrong. Still learning this stuff. Suppose I have a 2 dimensional Riemannian manifold $\mathcal{M}$ that is covered by a single chart: $\phi: \mathcal{M} \rightarrow \mathbb{R}^2$ (or alternatively, let's just think about a single chart). I can think of this manifold as just the plane that is stretched out in some places and/or shrunk in other places (or directions) depending on the metric $g$. I understand enough calculus and physics to know what to do when someone hands me some metric that depends upon coordinates, say $g = g_{xx}(x,y) dx^2+g_{xy}(x,y) dx dy+ g_{yy}(x,y) dy^2$ So that in that chart, I can do calculations (find the length, etc). But I still struggle with intuition. So here's my question: Suppose I have some rectangle in the plane with some such metric prescribed. Can I think of this (for the 2D case) as just just like a topographic map? If not, how is the changing metric different from the bumps and valleys of such a map? Any example to help me understand this better will be very much appreciated.","Apologies if I get the notation wrong. Still learning this stuff. Suppose I have a 2 dimensional Riemannian manifold $\mathcal{M}$ that is covered by a single chart: $\phi: \mathcal{M} \rightarrow \mathbb{R}^2$ (or alternatively, let's just think about a single chart). I can think of this manifold as just the plane that is stretched out in some places and/or shrunk in other places (or directions) depending on the metric $g$. I understand enough calculus and physics to know what to do when someone hands me some metric that depends upon coordinates, say $g = g_{xx}(x,y) dx^2+g_{xy}(x,y) dx dy+ g_{yy}(x,y) dy^2$ So that in that chart, I can do calculations (find the length, etc). But I still struggle with intuition. So here's my question: Suppose I have some rectangle in the plane with some such metric prescribed. Can I think of this (for the 2D case) as just just like a topographic map? If not, how is the changing metric different from the bumps and valleys of such a map? Any example to help me understand this better will be very much appreciated.",,"['differential-geometry', 'intuition']"
69,quotient by a group that acts almost freely,quotient by a group that acts almost freely,,"How can I show that if a compact lie group G acts almost freely  and smoothly on a manifold M, then M/G is Hausdorff? (an action is almost free if $G_x$ is finite for all x $\in$ M)","How can I show that if a compact lie group G acts almost freely  and smoothly on a manifold M, then M/G is Hausdorff? (an action is almost free if $G_x$ is finite for all x $\in$ M)",,"['differential-geometry', 'manifolds', 'lie-groups', 'group-actions']"
70,Relation between the integral of geodesic curvature and Gaussian Curvature,Relation between the integral of geodesic curvature and Gaussian Curvature,,"I need help with an exam question: Let $S$ be a regular oriented surface such that for any simple, closed, and positively oriented curve in $S$ the value of the integral of the geodesic curvature along this curve is always the same( that is, independent of the curve). What can be said about the Gaussian curvature of $S$? I thought about using the Gauss-Bonnet Theorem: $$\int_C \kappa_g(s) ds + \iint_R K d\sigma + \sum_{l=1}^p\theta_l = 2\pi\chi(R)$$ Since the $\int_C \kappa_g(s) ds$ is always the same, for any curve. Then for a geodesic, the curvature is zero, so $\int_C \kappa_g(s) ds = 0$. So, I can assume that if the integral of the geodesic curvature is always the same, then it must be zero. Is it correct to assume that? If that is correct, where do I go from there?","I need help with an exam question: Let $S$ be a regular oriented surface such that for any simple, closed, and positively oriented curve in $S$ the value of the integral of the geodesic curvature along this curve is always the same( that is, independent of the curve). What can be said about the Gaussian curvature of $S$? I thought about using the Gauss-Bonnet Theorem: $$\int_C \kappa_g(s) ds + \iint_R K d\sigma + \sum_{l=1}^p\theta_l = 2\pi\chi(R)$$ Since the $\int_C \kappa_g(s) ds$ is always the same, for any curve. Then for a geodesic, the curvature is zero, so $\int_C \kappa_g(s) ds = 0$. So, I can assume that if the integral of the geodesic curvature is always the same, then it must be zero. Is it correct to assume that? If that is correct, where do I go from there?",,['differential-geometry']
71,Natural connection on tautological bundle over real Grassmannian,Natural connection on tautological bundle over real Grassmannian,,"Let me get to the point immediately: Is there a natural connection on the tautological vector bundle over a Grassmannian (of a real vector space equipped with an inner product)? In a paper I'm reading there is a smooth 1-parameter family of $k$-dimensional subspaces $W_t$ of a vector space $V$. From this, we need to get a 1-parameter family of injections $\phi_t : W_0 \to V$ such that the image of $\phi_t$ is $W_t$, and such that $\phi_0$ is the inclusion of $W_0$. In other words, we need to identify all the $W_t$ with the initial subspace $W_0$. I have no trouble setting up such an identification (in an explicit way using projections and charts on Grassmannians, and small steps of the parameter $t$), but I'm looking for a natural way, mostly because I want to do these things for vector bundles later). I figured one way would be to have a connection on the tautological vector bundle of $k$-planes in $V$ and identify $W_0$ with $W_t$ using parallel transport along the path $\phi_t$. There is an inner product on $V$.","Let me get to the point immediately: Is there a natural connection on the tautological vector bundle over a Grassmannian (of a real vector space equipped with an inner product)? In a paper I'm reading there is a smooth 1-parameter family of $k$-dimensional subspaces $W_t$ of a vector space $V$. From this, we need to get a 1-parameter family of injections $\phi_t : W_0 \to V$ such that the image of $\phi_t$ is $W_t$, and such that $\phi_0$ is the inclusion of $W_0$. In other words, we need to identify all the $W_t$ with the initial subspace $W_0$. I have no trouble setting up such an identification (in an explicit way using projections and charts on Grassmannians, and small steps of the parameter $t$), but I'm looking for a natural way, mostly because I want to do these things for vector bundles later). I figured one way would be to have a connection on the tautological vector bundle of $k$-planes in $V$ and identify $W_0$ with $W_t$ using parallel transport along the path $\phi_t$. There is an inner product on $V$.",,['differential-geometry']
72,"If $\Gamma^k_{ij}(p)=0$, then $\nabla_{E_i}E_j (p)=0?$","If , then",\Gamma^k_{ij}(p)=0 \nabla_{E_i}E_j (p)=0?,"I'm having the same problem as it was questioned here. I can't get throught the step where I need to show that $\nabla_{E_i}E_j (p)=0$. It only leads to $$ \nabla_{E_i}E_j(p)=\sum_{lk}^n a_{il}(0)\dfrac{\partial b_jk}{\partial x_l}(0)\partial x_k(p) $$ which I can't show that equals zero. On the linked question, there is also the indication that $\nabla_{E_i}E_j (E_k)=\Gamma^k_{ij}$. This could lead that $\nabla_{E_i}E_j (E_k)(p)=\Gamma^k_{ij}(p)=0$, but $\nabla_{E_i}E_j (E_k)(p)$ is not equal to $\nabla_{E_i}E_j (p)$ which is the one I need. Can someone help me?","I'm having the same problem as it was questioned here. I can't get throught the step where I need to show that $\nabla_{E_i}E_j (p)=0$. It only leads to $$ \nabla_{E_i}E_j(p)=\sum_{lk}^n a_{il}(0)\dfrac{\partial b_jk}{\partial x_l}(0)\partial x_k(p) $$ which I can't show that equals zero. On the linked question, there is also the indication that $\nabla_{E_i}E_j (E_k)=\Gamma^k_{ij}$. This could lead that $\nabla_{E_i}E_j (E_k)(p)=\Gamma^k_{ij}(p)=0$, but $\nabla_{E_i}E_j (E_k)(p)$ is not equal to $\nabla_{E_i}E_j (p)$ which is the one I need. Can someone help me?",,"['differential-geometry', 'riemannian-geometry']"
73,Question about Hopf-Rinow theorem,Question about Hopf-Rinow theorem,,"I'm studying Hopf-Rinow theorem and I don't see a step in the proof. Could someone help me, please? (Definition) Let's $(M, \langle,\rangle)$ an ANII(axiom numerability 2) and Hausdorff Riemannian manifold. If $M$ is connected and $p,q \in M$. We define: $$d_L:M\times M \longrightarrow [0,\infty)$$ $$(p,q)\longmapsto inf\{l(C)\}$$ where C is a piecewise differentiable curve joining $p$ and $q$ and $l$ is the length of the curve. I've proved that $d_L$ is a distance and that the topology induced by $d_L$ is the original topology on $M$. Considering  $(M, \langle,\rangle)$ an ANII and Hausdorff Riemannian manifold. If $M$ is connected and $p \in M$. Then prove that the following statements are equivalent: (a) If $A$ is a closed and bounded subset of $M$ then $A$ is compact. (b) $\exists \{K_n\}_{n\in \mathbb{N}}, K_n \subset M$ compact and $K_n \subset K_{n+1}, \forall n \in \mathbb{N}$ and $\bigcup_n K_n=M$ with the following property: If $(q_n)_{ n \in \mathbb{N}}\subset M$ sequence / $(q_n)\notin K_n, \forall n \in \mathbb{N}\Rightarrow lim_{n\rightarrow \infty} d_L(q_n,p)=\infty$. Thanks.","I'm studying Hopf-Rinow theorem and I don't see a step in the proof. Could someone help me, please? (Definition) Let's $(M, \langle,\rangle)$ an ANII(axiom numerability 2) and Hausdorff Riemannian manifold. If $M$ is connected and $p,q \in M$. We define: $$d_L:M\times M \longrightarrow [0,\infty)$$ $$(p,q)\longmapsto inf\{l(C)\}$$ where C is a piecewise differentiable curve joining $p$ and $q$ and $l$ is the length of the curve. I've proved that $d_L$ is a distance and that the topology induced by $d_L$ is the original topology on $M$. Considering  $(M, \langle,\rangle)$ an ANII and Hausdorff Riemannian manifold. If $M$ is connected and $p \in M$. Then prove that the following statements are equivalent: (a) If $A$ is a closed and bounded subset of $M$ then $A$ is compact. (b) $\exists \{K_n\}_{n\in \mathbb{N}}, K_n \subset M$ compact and $K_n \subset K_{n+1}, \forall n \in \mathbb{N}$ and $\bigcup_n K_n=M$ with the following property: If $(q_n)_{ n \in \mathbb{N}}\subset M$ sequence / $(q_n)\notin K_n, \forall n \in \mathbb{N}\Rightarrow lim_{n\rightarrow \infty} d_L(q_n,p)=\infty$. Thanks.",,"['differential-geometry', 'riemannian-geometry']"
74,Is this counter-intuitive result actually correct?,Is this counter-intuitive result actually correct?,,"I was trying to calculate the surface area of part of a sphere. The result seems counter-intuitive. I have found that the surface area of a sphere increases linearly. Consider the circle, centre $(r,0)$ and radius $r>0$. This has equation $(x-r)^2 + y^2 = r^2$. For $y>0$, we can write $y$ as a function of $x$. Direct calculation shows that $y(x) = \sqrt{2rx-x^2}$ for all $0 < x < 2r$. The usual formula for rotating the graph of a curve (given as a function of $x$) around the $x$-axis to find the surface area of revolution is $$A = 2\pi \int_{x_1}^{x_2} y\sqrt{1+(y')^2} \, \mathrm{d}x$$ In my case, I have the limits $x_1=0$ and $x_2=h \le 2r$. We have $$\begin{eqnarray*} A &=& 2\pi \int_0^h \sqrt{2rx-x^2}\sqrt{1+\frac{(r-x)^2}{2rx-x^2}} \, \mathrm{d}x \\ \\ \\ &=&2\pi\int_0^h \sqrt{2rx-x^2}\sqrt{\frac{r^2}{2rx-x^2}} \, \mathrm{d}x \\ \\ \\ &=&2\pi\int_0^h r\, \mathrm{d}x \\ \\ \\ &=&2\pi r h \end{eqnarray*}$$ This gives two correct results: when $h=0$ we have $A=0$ and when $h=2r$ we have $A=4\pi r^2$. However, it seems counter-intuitive that the area should be a linear function in $h$. For example, let $B(a,b)$ be the ""belt"" bounded by $x=a$ and $x=b$. Two belts of the same width should have different surface areas depending on how close their centres are to $x=r$. Surely?","I was trying to calculate the surface area of part of a sphere. The result seems counter-intuitive. I have found that the surface area of a sphere increases linearly. Consider the circle, centre $(r,0)$ and radius $r>0$. This has equation $(x-r)^2 + y^2 = r^2$. For $y>0$, we can write $y$ as a function of $x$. Direct calculation shows that $y(x) = \sqrt{2rx-x^2}$ for all $0 < x < 2r$. The usual formula for rotating the graph of a curve (given as a function of $x$) around the $x$-axis to find the surface area of revolution is $$A = 2\pi \int_{x_1}^{x_2} y\sqrt{1+(y')^2} \, \mathrm{d}x$$ In my case, I have the limits $x_1=0$ and $x_2=h \le 2r$. We have $$\begin{eqnarray*} A &=& 2\pi \int_0^h \sqrt{2rx-x^2}\sqrt{1+\frac{(r-x)^2}{2rx-x^2}} \, \mathrm{d}x \\ \\ \\ &=&2\pi\int_0^h \sqrt{2rx-x^2}\sqrt{\frac{r^2}{2rx-x^2}} \, \mathrm{d}x \\ \\ \\ &=&2\pi\int_0^h r\, \mathrm{d}x \\ \\ \\ &=&2\pi r h \end{eqnarray*}$$ This gives two correct results: when $h=0$ we have $A=0$ and when $h=2r$ we have $A=4\pi r^2$. However, it seems counter-intuitive that the area should be a linear function in $h$. For example, let $B(a,b)$ be the ""belt"" bounded by $x=a$ and $x=b$. Two belts of the same width should have different surface areas depending on how close their centres are to $x=r$. Surely?",,"['differential-geometry', 'definite-integrals']"
75,Expression for Laplace-Beltrami on sphere?,Expression for Laplace-Beltrami on sphere?,,Is there a good expression for the Laplace-Beltrami on a function $u$ on a sphere or a circle of radius $R>0$ in terms of the Laplacian on ambient space? There is a formula on Wikipedia for the unit sphere: $$\Delta_{S^{n-1}}f(x) = \Delta f(x/|x|).$$ How about sphere of radius $R$?,Is there a good expression for the Laplace-Beltrami on a function $u$ on a sphere or a circle of radius $R>0$ in terms of the Laplacian on ambient space? There is a formula on Wikipedia for the unit sphere: $$\Delta_{S^{n-1}}f(x) = \Delta f(x/|x|).$$ How about sphere of radius $R$?,,"['differential-geometry', 'manifolds']"
76,Derivations are determined by their values on linear functions,Derivations are determined by their values on linear functions,,How are derivations of the $\mathbb R$ algebra of germs of differentiable real functions on a manifold completely determined by their values in germs of linear functions? Are derivations of more general algebras of functions determined similarly? Does this result have an anologue for derivations of abstract algebras?,How are derivations of the $\mathbb R$ algebra of germs of differentiable real functions on a manifold completely determined by their values in germs of linear functions? Are derivations of more general algebras of functions determined similarly? Does this result have an anologue for derivations of abstract algebras?,,"['algebraic-geometry', 'differential-geometry']"
77,Is it possible a trivial fiber bundle with nonzero holonomy?,Is it possible a trivial fiber bundle with nonzero holonomy?,,Let $P\rightarrow M$ be a principal bundle with structure group $G$. Suppose that the bundle is trivial $M\times G$; is it possible to have a nonzero holonomy along some closed trajectory on $M$ for some connection form?,Let $P\rightarrow M$ be a principal bundle with structure group $G$. Suppose that the bundle is trivial $M\times G$; is it possible to have a nonzero holonomy along some closed trajectory on $M$ for some connection form?,,"['differential-geometry', 'algebraic-topology']"
78,Boundary of unit square is not a smooth submanifold of $\mathbb{R}^2$?,Boundary of unit square is not a smooth submanifold of ?,\mathbb{R}^2,"I've read some of the answers to related questions to this, but this is an idea I've been grappling with for a while and still can't fully get my head around. $\mathbb{S}^1$ is a smooth manifold, and so we can induce a natural smooth structure on the boundary of the unit square, $\partial I$ by some homeomorphism (specifically I am thinking of $\frac{|| \cdot ||_\infty}{|| \cdot ||_2}$). But then intuitively, the unit square should not be a smoothly embedded submanifold of $\mathbb{R}^2$ - so where exactly does this procedure fail in providing a suitable smooth structure on $\partial I$, which makes it as such? By definition we need to provide an injective immersion which is also a topological embedding. But isn't the topology induced by the homoemorphism from $\mathbb{S}^1$ precisely the same as the subspace topology induced from $\mathbb{R}^2$? So the inclusion map is a topological embedding. It is obviously injective - so I surmise the immersion criteria must fail, but I cannot see (rigorously) why this is so! Thanks in advance for any help.","I've read some of the answers to related questions to this, but this is an idea I've been grappling with for a while and still can't fully get my head around. $\mathbb{S}^1$ is a smooth manifold, and so we can induce a natural smooth structure on the boundary of the unit square, $\partial I$ by some homeomorphism (specifically I am thinking of $\frac{|| \cdot ||_\infty}{|| \cdot ||_2}$). But then intuitively, the unit square should not be a smoothly embedded submanifold of $\mathbb{R}^2$ - so where exactly does this procedure fail in providing a suitable smooth structure on $\partial I$, which makes it as such? By definition we need to provide an injective immersion which is also a topological embedding. But isn't the topology induced by the homoemorphism from $\mathbb{S}^1$ precisely the same as the subspace topology induced from $\mathbb{R}^2$? So the inclusion map is a topological embedding. It is obviously injective - so I surmise the immersion criteria must fail, but I cannot see (rigorously) why this is so! Thanks in advance for any help.",,"['differential-geometry', 'smooth-manifolds']"
79,Why does the universal cover of $GL^+_n$ not admit finite-dimensional representations?,Why does the universal cover of  not admit finite-dimensional representations?,GL^+_n,"Let $GL^+_n \subset \mathbb{R}^{n \times n}$ be the subgroup of real matrices with positive determinant and $\widetilde{GL}^+_n$ be its universal cover. Why does $\widetilde{GL}^+_n$ not admit finite-dimensional representations? I would be happy with a proof or a reference. This question is relevant in spin geometry. Normally, one uses $Spin_n$, which is the universal cover of $SO_n$ (if $n \geq 3$), and a finite-dimensional representation $\rho:Spin_n \to GL(V)$ to construct the spinor bundle of a Riemannian spin manifold $(M,g)$ with spin structure $\Theta^g: Spin^g M \to SO^g M$ via $\Sigma^g M := Spin^g \times _{\rho} V$. In texts like [1], the authors work with a topological spin structure $\widetilde{GL}^+ M \to GL^+ M$ up to the point where one has to construct the spinor bundle. I like this approach, which is why I would like to better understand why this part of the construction fails. Unfortunately, I do not know much about representation theory besides what is mentioned in [1]. [1] Bär, Gauduchon, Moroianu: Generlized cylinders in Semi-Riemannian and Spin Geometry EDIT: One should require the representations to be faithful.","Let $GL^+_n \subset \mathbb{R}^{n \times n}$ be the subgroup of real matrices with positive determinant and $\widetilde{GL}^+_n$ be its universal cover. Why does $\widetilde{GL}^+_n$ not admit finite-dimensional representations? I would be happy with a proof or a reference. This question is relevant in spin geometry. Normally, one uses $Spin_n$, which is the universal cover of $SO_n$ (if $n \geq 3$), and a finite-dimensional representation $\rho:Spin_n \to GL(V)$ to construct the spinor bundle of a Riemannian spin manifold $(M,g)$ with spin structure $\Theta^g: Spin^g M \to SO^g M$ via $\Sigma^g M := Spin^g \times _{\rho} V$. In texts like [1], the authors work with a topological spin structure $\widetilde{GL}^+ M \to GL^+ M$ up to the point where one has to construct the spinor bundle. I like this approach, which is why I would like to better understand why this part of the construction fails. Unfortunately, I do not know much about representation theory besides what is mentioned in [1]. [1] Bär, Gauduchon, Moroianu: Generlized cylinders in Semi-Riemannian and Spin Geometry EDIT: One should require the representations to be faithful.",,"['reference-request', 'differential-geometry', 'representation-theory', 'spin-geometry']"
80,Arbitrary dimensional object with constant ratio of volume to containing hyper cube's volume?,Arbitrary dimensional object with constant ratio of volume to containing hyper cube's volume?,,"Let me introduce what I need by giving an example which is not working: n-sphere with radius 1 and respective hypercube with edges of length 2. The ratio reaches already in 10th dimension a level of less than 1%. My question essentially is whether a geometric object G with following features exists : The hyper-cube containing G is canonically defined for all dimensions with edges of length L and center is the 0. G is contained in above hyper-cube for all dimensions. The ratio of the G's volume and the hyper-cubes volume is constant over all dimensions. Calculating whether a point chosen from the hyper-cube uniformly at random is contained in G is canonical. (in other words: the calculation can be written down as a single formula depending on the number of dimensions and of course L and the point) Any path along the surface of G is differentiable. The volume ratio should be either adjustable or between .2 and .8. (point 5 is maybe not correctly formulated. I want to make sure that G is not ""edgy""/""weird"" (sorry for these terms). Maybe it is the same as when I request G to be Riemann integrable) I need such an object to generate a sample data set from an arbitrary dimensional space to benchmark performance of SVMs (and other ML algorithms) over dimensionality of input space.","Let me introduce what I need by giving an example which is not working: n-sphere with radius 1 and respective hypercube with edges of length 2. The ratio reaches already in 10th dimension a level of less than 1%. My question essentially is whether a geometric object G with following features exists : The hyper-cube containing G is canonically defined for all dimensions with edges of length L and center is the 0. G is contained in above hyper-cube for all dimensions. The ratio of the G's volume and the hyper-cubes volume is constant over all dimensions. Calculating whether a point chosen from the hyper-cube uniformly at random is contained in G is canonical. (in other words: the calculation can be written down as a single formula depending on the number of dimensions and of course L and the point) Any path along the surface of G is differentiable. The volume ratio should be either adjustable or between .2 and .8. (point 5 is maybe not correctly formulated. I want to make sure that G is not ""edgy""/""weird"" (sorry for these terms). Maybe it is the same as when I request G to be Riemann integrable) I need such an object to generate a sample data set from an arbitrary dimensional space to benchmark performance of SVMs (and other ML algorithms) over dimensionality of input space.",,['differential-geometry']
81,Confusing definition of Jacobi field,Confusing definition of Jacobi field,,"Let $\mathcal{M}$ be $n$-dimensional Riemannian manifold. In wikipedia article I've found that a vector field $J$ along a geodesic $\gamma$ is said to be a Jacobi field if it satisfies the Jacobi equation: $$\frac{D^2}{dt^2}J(t)+R(J(t),\dot\gamma(t))\dot\gamma(t)=0,$$ where $D$ denotes the covariant derivative with respect to the Levi-Civita connection, $R$ the Riemann curvature tensor, $\dot\gamma(t)=d\gamma(t)/dt$ the tangent vector field, and $t$ is the parameter of the geodesic. What confuses me is the fact that to be able to compute $R(J(t),\dot\gamma(t))\dot\gamma(t)$ the vector field $\dot\gamma(t)$ should have values in some neighbourhood of $\gamma(t)$ (at least on curve $\alpha(s) : (-\epsilon, \epsilon) \to \mathcal{M}$, that is any curve with  $(d\alpha /ds )(0)=J(t)$), but it doesn't in common case. Of course, we can extend it, but not in a unique way, so the equation above doesn't make sense for me. Where am I wrong?","Let $\mathcal{M}$ be $n$-dimensional Riemannian manifold. In wikipedia article I've found that a vector field $J$ along a geodesic $\gamma$ is said to be a Jacobi field if it satisfies the Jacobi equation: $$\frac{D^2}{dt^2}J(t)+R(J(t),\dot\gamma(t))\dot\gamma(t)=0,$$ where $D$ denotes the covariant derivative with respect to the Levi-Civita connection, $R$ the Riemann curvature tensor, $\dot\gamma(t)=d\gamma(t)/dt$ the tangent vector field, and $t$ is the parameter of the geodesic. What confuses me is the fact that to be able to compute $R(J(t),\dot\gamma(t))\dot\gamma(t)$ the vector field $\dot\gamma(t)$ should have values in some neighbourhood of $\gamma(t)$ (at least on curve $\alpha(s) : (-\epsilon, \epsilon) \to \mathcal{M}$, that is any curve with  $(d\alpha /ds )(0)=J(t)$), but it doesn't in common case. Of course, we can extend it, but not in a unique way, so the equation above doesn't make sense for me. Where am I wrong?",,"['differential-geometry', 'riemannian-geometry']"
82,The Definition of Convex Surface,The Definition of Convex Surface,,"Let $\Sigma$ be a $C^{\infty}$ compact surface in $R^3$ . (1)If the tangent space of every point lies the same side of $\Sigma$ , we call $\Sigma$ convex surface. (2)If the Guass Curvature $K>0$ , we call $\Sigma$ ovaloid. (3)If $\Sigma$ is homeomorphic to $S^2$ , and the union of interior of $\Sigma$ and $\Sigma$ is convex, we call it a (3)-surface. What is the relationship between convex surface and ovaloid? How is the situation in higher dimension? In $R^n$ , if $S$ is a compact convex set, then the boundary of $S$ is homeomorphic to a sphere. So is the definition (3) equal to the definition (1)?","Let be a compact surface in . (1)If the tangent space of every point lies the same side of , we call convex surface. (2)If the Guass Curvature , we call ovaloid. (3)If is homeomorphic to , and the union of interior of and is convex, we call it a (3)-surface. What is the relationship between convex surface and ovaloid? How is the situation in higher dimension? In , if is a compact convex set, then the boundary of is homeomorphic to a sphere. So is the definition (3) equal to the definition (1)?",\Sigma C^{\infty} R^3 \Sigma \Sigma K>0 \Sigma \Sigma S^2 \Sigma \Sigma R^n S S,['differential-geometry']
83,Reference request for differential geometry/quantum chaos text,Reference request for differential geometry/quantum chaos text,,"I'm looking for a differential-geometry based exposition of chaos theory and quantum chaos. Ideally, it would start with the Hamiltonian formalism (on symplectic manifolds) and discuss as many of the following as possible: Liouville integrable systems ""orbits"" of a system definitions of when a system is mixing/chaotic/""Anosov"" mathematical formulation of correspondence principle (Egorov theorem) Perhaps it would be somewhat like the book Chaos in Classical and Quantum Mechanics by Martin C. Gutzwiller, only more formal and focusing on quantum chaos. I would love to look at any references that are even tangentially related. Thanks in advance!","I'm looking for a differential-geometry based exposition of chaos theory and quantum chaos. Ideally, it would start with the Hamiltonian formalism (on symplectic manifolds) and discuss as many of the following as possible: Liouville integrable systems ""orbits"" of a system definitions of when a system is mixing/chaotic/""Anosov"" mathematical formulation of correspondence principle (Egorov theorem) Perhaps it would be somewhat like the book Chaos in Classical and Quantum Mechanics by Martin C. Gutzwiller, only more formal and focusing on quantum chaos. I would love to look at any references that are even tangentially related. Thanks in advance!",,"['reference-request', 'differential-geometry', 'dynamical-systems', 'quantum-mechanics']"
84,Length of a Continuous Curve,Length of a Continuous Curve,,"Let f be a bounded real valued function on [a,b], then define the length of the curve L(f) as follows: \begin{equation}\tag{1} L(f)=sup\sum\limits_{i=1}^{n}\sqrt{ (x_i-x_{i-1})^2+(f(x_i)-f(x_{i-1}))^2},  \end{equation} where sup is taken over all partitions of [a,b]. The question is to show, L(f) is equal to \begin{equation}\tag{2} \lim\limits_{max|x_i-x_{i-1}|\to 0}\sum\limits_{i=1}^{n}\sqrt {(x_i-x_{i-1})^2+(f(x_i)-f(x_{i-1}))^2} \end{equation} for continuous functions. I know when $max|x_i-x_{i-1}|\to 0$, we get finer partitions so that $(1)\leq(2)$ because if we pick any partition and then let $max|x_i-x_{i-1}|\to0$ then we get a greater sum due to triangle inequality.(I guess what I said is true and does not require continuity.) I could not show  $(2)\leq(1)$ and could not use the continuity. In a finite sum, we can switch $\sum$ and limit but as $max|x_i-x_{i-1}|\to0$ we get an infinite sum so switching may fail. I got stuck. P.S. I have read ( Determining the Length of a Curve Using Partitions ) but I did not understand ""there is a sequence $(Q_n)_{n\geq0}$ of partitions with (3) holds"" which was stated in the answer. If you refer to that question, please tell me why (3) holds. I thought that (3) is the same as what we want to show in that question. Probably, I missed an easy detail. Thanks in advance for any help.","Let f be a bounded real valued function on [a,b], then define the length of the curve L(f) as follows: \begin{equation}\tag{1} L(f)=sup\sum\limits_{i=1}^{n}\sqrt{ (x_i-x_{i-1})^2+(f(x_i)-f(x_{i-1}))^2},  \end{equation} where sup is taken over all partitions of [a,b]. The question is to show, L(f) is equal to \begin{equation}\tag{2} \lim\limits_{max|x_i-x_{i-1}|\to 0}\sum\limits_{i=1}^{n}\sqrt {(x_i-x_{i-1})^2+(f(x_i)-f(x_{i-1}))^2} \end{equation} for continuous functions. I know when $max|x_i-x_{i-1}|\to 0$, we get finer partitions so that $(1)\leq(2)$ because if we pick any partition and then let $max|x_i-x_{i-1}|\to0$ then we get a greater sum due to triangle inequality.(I guess what I said is true and does not require continuity.) I could not show  $(2)\leq(1)$ and could not use the continuity. In a finite sum, we can switch $\sum$ and limit but as $max|x_i-x_{i-1}|\to0$ we get an infinite sum so switching may fail. I got stuck. P.S. I have read ( Determining the Length of a Curve Using Partitions ) but I did not understand ""there is a sequence $(Q_n)_{n\geq0}$ of partitions with (3) holds"" which was stated in the answer. If you refer to that question, please tell me why (3) holds. I thought that (3) is the same as what we want to show in that question. Probably, I missed an easy detail. Thanks in advance for any help.",,['differential-geometry']
85,"For sphere $S^2$, the conjugate locus of each any point in $S^2$ reduces to a single point.","For sphere , the conjugate locus of each any point in  reduces to a single point.",S^2 S^2,"The problem is: For sphere $S^2\subset\Bbb{R}^3$, the conjugate locus of each point in $S^2\subset\Bbb{R}^3$ reduces to a single point. I can prove that any point is conjugate to it's antipodal point. But I can't prove that other points aren't conjugate with with each other. Any reference or sketch of proof will be interesting. Thanks in advance. My tries: There's a proposition in my book ( Differential Geometry of Curves and Surfaces Manfredo P. do carmo ) which says: PROPOSITION 5 . Let $p, q \in S$ be two points of $S$ and let $\gamma ':[0,1] \to S$ be a geodesic joining $p = \gamma '(0)$ to $q = \exp_p(l\gamma '(0))$. Then $q$ is conjugate to $p$ relative to $\gamma$ if and only if $v = l\gamma '(0)$ is a critical point of $\exp_p:T_p(S) \to S$. In this way I need calculate $(d \exp_p)_v(w)$ to observe for which $v,w$ we have $(d \exp_p)_v(w)=0$.","The problem is: For sphere $S^2\subset\Bbb{R}^3$, the conjugate locus of each point in $S^2\subset\Bbb{R}^3$ reduces to a single point. I can prove that any point is conjugate to it's antipodal point. But I can't prove that other points aren't conjugate with with each other. Any reference or sketch of proof will be interesting. Thanks in advance. My tries: There's a proposition in my book ( Differential Geometry of Curves and Surfaces Manfredo P. do carmo ) which says: PROPOSITION 5 . Let $p, q \in S$ be two points of $S$ and let $\gamma ':[0,1] \to S$ be a geodesic joining $p = \gamma '(0)$ to $q = \exp_p(l\gamma '(0))$. Then $q$ is conjugate to $p$ relative to $\gamma$ if and only if $v = l\gamma '(0)$ is a critical point of $\exp_p:T_p(S) \to S$. In this way I need calculate $(d \exp_p)_v(w)$ to observe for which $v,w$ we have $(d \exp_p)_v(w)=0$.",,"['reference-request', 'differential-geometry']"
86,When can a manifold be curvature free?,When can a manifold be curvature free?,,"Recall that in a Riemannian manifold (or pseudo Riemannian) there is always the unique Levi-Civita connexion that annuls the torsion. There are also manifolds (not needfully Riemannian) which are curvature free, thus the deviation from Euclideanhood is encoded wholly in the torsion tensor. Question 1: Are there known sufficient, or necessary, or both necessary and sufficient conditions conditions for a curvature-free connexion (weaken assumptions to e.g. a Finsler manifold if need be) to be defined? Question 2: Are there known sufficient, or necessary, or both necessary and sufficient conditions conditions that rule out a curvature-free connexion? Question 3: Now, one thing that is bending my mind is: what happens to the holonomy group if we can have a curvature-free connexion? Obviously the holonomy group is trivial for a curvature free manifold. This seems to imply to me that somehow all connexions for that manifold must be curvature free, because there is no way to ""continuously deform"" a Lie group from the trivial group to a nontrivial one. Is this right? If not, how does the holonmy group ""jump"" from being trivial to something nontrivial?","Recall that in a Riemannian manifold (or pseudo Riemannian) there is always the unique Levi-Civita connexion that annuls the torsion. There are also manifolds (not needfully Riemannian) which are curvature free, thus the deviation from Euclideanhood is encoded wholly in the torsion tensor. Question 1: Are there known sufficient, or necessary, or both necessary and sufficient conditions conditions for a curvature-free connexion (weaken assumptions to e.g. a Finsler manifold if need be) to be defined? Question 2: Are there known sufficient, or necessary, or both necessary and sufficient conditions conditions that rule out a curvature-free connexion? Question 3: Now, one thing that is bending my mind is: what happens to the holonomy group if we can have a curvature-free connexion? Obviously the holonomy group is trivial for a curvature free manifold. This seems to imply to me that somehow all connexions for that manifold must be curvature free, because there is no way to ""continuously deform"" a Lie group from the trivial group to a nontrivial one. Is this right? If not, how does the holonmy group ""jump"" from being trivial to something nontrivial?",,"['differential-geometry', 'manifolds']"
87,Question on (Brouwer) degree of smooth functions,Question on (Brouwer) degree of smooth functions,,"Given smooth maps $f:M\to N$ and $g:N\to W$ (between closed, compact, oriented, $n$-manifolds), I want to show that $\text{deg}(g\circ f)=\text{deg}(g)\text{deg}(f)$ (Brouwer degree). I know, given, a regular point $x\in M$, that $sign\ d(g\circ f)_x= (sign\ dg_{f(x)})(sign\ df_x)$, but I'm not sure how I can extend that fact, or if that is even the right direction. The Brouwer degree is defined as follows (Milnor): Let $f:M\to N$ be a smooth map (between closed, compact, oriented n-manifolds) and $p\in M$ a regular point of $f$ such that $df_x:T_xM\to T_{f(x)}N$ is a linear isomorphism. Define $sign\ df_x$ to be $\pm 1$, depending on whether $df_x$ preserves or reverses orientation. Then, for any regular value $q\in N$  $\text{deg}(f,q)=\sum_{p\in f^{-1}(q)} sign\ df_x$. Since, in fact, $\text{deg}(f,q)=\text{deg}(f,r)$ for any two regular values $q,r\in N$, $\text{deg}(f,q)$ is just called the (Brouwer) degree of $f$.","Given smooth maps $f:M\to N$ and $g:N\to W$ (between closed, compact, oriented, $n$-manifolds), I want to show that $\text{deg}(g\circ f)=\text{deg}(g)\text{deg}(f)$ (Brouwer degree). I know, given, a regular point $x\in M$, that $sign\ d(g\circ f)_x= (sign\ dg_{f(x)})(sign\ df_x)$, but I'm not sure how I can extend that fact, or if that is even the right direction. The Brouwer degree is defined as follows (Milnor): Let $f:M\to N$ be a smooth map (between closed, compact, oriented n-manifolds) and $p\in M$ a regular point of $f$ such that $df_x:T_xM\to T_{f(x)}N$ is a linear isomorphism. Define $sign\ df_x$ to be $\pm 1$, depending on whether $df_x$ preserves or reverses orientation. Then, for any regular value $q\in N$  $\text{deg}(f,q)=\sum_{p\in f^{-1}(q)} sign\ df_x$. Since, in fact, $\text{deg}(f,q)=\text{deg}(f,r)$ for any two regular values $q,r\in N$, $\text{deg}(f,q)$ is just called the (Brouwer) degree of $f$.",,"['differential-geometry', 'smooth-manifolds']"
88,Definition of divergence of a tensor,Definition of divergence of a tensor,,"How do you formally define the divergence of an arbitrary $(p,q)$ tensor? And what does it geometrically signify?","How do you formally define the divergence of an arbitrary $(p,q)$ tensor? And what does it geometrically signify?",,"['differential-geometry', 'tensors']"
89,"Why is the priemage of a regular value of $F(x,v)=df_x(v)$ finite?",Why is the priemage of a regular value of  finite?,"F(x,v)=df_x(v)","This comes up as part of a larger issue of showing a compact $n$-dimensional manifold can be immersed in $\mathbb{R}^{2n-1}$ except at finitely many points. Suppose $X$ is a compact, $n$-dimensional manifold. Let $f\colon X\to\mathbb{R}^{2n}$ be an immersion. Say you have a map $F\colon T(X)\to\mathbb{R}^{2n}$ given by $F(x,v)=df_x(v)$, with a regular value $a$. I'm interested in why the preimage $F^{-1}(a)$ is necessarily finite. After this, I think I have an idea to show $X$ can be immersed into $\mathbb{R}^{2n-1}$ except on $F^{-1}(a)$. So I think it suffices to show that $a$ has only finitely many preimages in $\{(x,v):|v|\leq 1\}$ in the tangent bundle $T(X)$. Towards the contrary, suppose there are infinitely many preimages $(x_i,v_i)$. By compactness, there is a convergent sequence such that $x_i\to x$ and $v_i/|v_i|\to w$. Apparently this implies $df_x(w)=0$, but how does this give a contradiction? By linearity, I find the equation $$ F(x_i,v_i/|v_i|)=df_{x_i}(v_i/|v_i|)=a/|v_i| $$ Is the idea that we can without loss of generality assume that $|v_i|\to\infty$, so as $i\to\infty$, $df_x(w)=0$? But why does that show $F^{-1}(a)$ is finite? Thank you.","This comes up as part of a larger issue of showing a compact $n$-dimensional manifold can be immersed in $\mathbb{R}^{2n-1}$ except at finitely many points. Suppose $X$ is a compact, $n$-dimensional manifold. Let $f\colon X\to\mathbb{R}^{2n}$ be an immersion. Say you have a map $F\colon T(X)\to\mathbb{R}^{2n}$ given by $F(x,v)=df_x(v)$, with a regular value $a$. I'm interested in why the preimage $F^{-1}(a)$ is necessarily finite. After this, I think I have an idea to show $X$ can be immersed into $\mathbb{R}^{2n-1}$ except on $F^{-1}(a)$. So I think it suffices to show that $a$ has only finitely many preimages in $\{(x,v):|v|\leq 1\}$ in the tangent bundle $T(X)$. Towards the contrary, suppose there are infinitely many preimages $(x_i,v_i)$. By compactness, there is a convergent sequence such that $x_i\to x$ and $v_i/|v_i|\to w$. Apparently this implies $df_x(w)=0$, but how does this give a contradiction? By linearity, I find the equation $$ F(x_i,v_i/|v_i|)=df_{x_i}(v_i/|v_i|)=a/|v_i| $$ Is the idea that we can without loss of generality assume that $|v_i|\to\infty$, so as $i\to\infty$, $df_x(w)=0$? But why does that show $F^{-1}(a)$ is finite? Thank you.",,"['differential-geometry', 'differential-topology']"
90,Every holomorphic map between Kähler manifolds is harmonic,Every holomorphic map between Kähler manifolds is harmonic,,"I was reading the Wikipedia article on harmonic maps and saw the following statement in the 'examples' section: Every holomorphic map between Kähler manifolds is harmonic. I am not that familiar with harmonic maps, so I haven't been able to figure out why this is true. A quick google search didn't provide me the answer either. Is there a simple explanation for why this is true? If not, does anyone know of a reference for this fact?","I was reading the Wikipedia article on harmonic maps and saw the following statement in the 'examples' section: Every holomorphic map between Kähler manifolds is harmonic. I am not that familiar with harmonic maps, so I haven't been able to figure out why this is true. A quick google search didn't provide me the answer either. Is there a simple explanation for why this is true? If not, does anyone know of a reference for this fact?",,"['reference-request', 'differential-geometry', 'riemannian-geometry', 'complex-geometry', 'kahler-manifolds']"
91,example of a non differentiable manifold,example of a non differentiable manifold,,"Take the manifold: The graph of $|x|$ on $(-1,1)$, with the induced topology from $\mathbb{R}^2$. This is a topological manifold, which is homeomorphic to $(-1,1)$ by projection. Is it a differentiable manifold? I believe it is, because we can take an atlas with only the projection, and then we will have only one transition map which is the identity, and therefore differentiable. But I'm not sure I get the definition of a differentiable manifold right... Thanks!","Take the manifold: The graph of $|x|$ on $(-1,1)$, with the induced topology from $\mathbb{R}^2$. This is a topological manifold, which is homeomorphic to $(-1,1)$ by projection. Is it a differentiable manifold? I believe it is, because we can take an atlas with only the projection, and then we will have only one transition map which is the identity, and therefore differentiable. But I'm not sure I get the definition of a differentiable manifold right... Thanks!",,"['differential-geometry', 'manifolds']"
92,second fundamental form of a surface given by regular values,second fundamental form of a surface given by regular values,,"Consider the differentiable function $f:\mathbb R^3 \to \mathbb R$. Consider the regular surface given by $ f(x,y,z)=a$ where $a$ is a regular value of $f$. Prove that the second fundamental form of the surface is given by: $$ \text{II} \left( v \right) = \frac{{Hess\left( f \right)\left( {v,v} \right)}} {{\left| {\left| {\nabla f} \right|} \right|}} $$ I only proved that the normal vector is given by $$ N  = \frac{{ \pm \nabla f}} {{\left| {\left| {\nabla f} \right|} \right|}} $$ This is clearly if we consider a curve $( x(t),y(t),z(t))$ lying on the surface. We have that $ f( x(t),y(t),z(t)) = a$ , that implies that $$ \left( {\nabla f} \right) \cdot \left( {x\left( t \right),y\left( t \right),z\left( t \right)} \right) = f_x x' + f_y y' + f_z z' = 0 $$ So one way to do it , it's computing the Jacobian matrix of N$ but I think that that there is a more ""smart"" way to do it","Consider the differentiable function $f:\mathbb R^3 \to \mathbb R$. Consider the regular surface given by $ f(x,y,z)=a$ where $a$ is a regular value of $f$. Prove that the second fundamental form of the surface is given by: $$ \text{II} \left( v \right) = \frac{{Hess\left( f \right)\left( {v,v} \right)}} {{\left| {\left| {\nabla f} \right|} \right|}} $$ I only proved that the normal vector is given by $$ N  = \frac{{ \pm \nabla f}} {{\left| {\left| {\nabla f} \right|} \right|}} $$ This is clearly if we consider a curve $( x(t),y(t),z(t))$ lying on the surface. We have that $ f( x(t),y(t),z(t)) = a$ , that implies that $$ \left( {\nabla f} \right) \cdot \left( {x\left( t \right),y\left( t \right),z\left( t \right)} \right) = f_x x' + f_y y' + f_z z' = 0 $$ So one way to do it , it's computing the Jacobian matrix of N$ but I think that that there is a more ""smart"" way to do it",,['differential-geometry']
93,Local Reparametrization of Surface using known Vector Field (Differential Geometry),Local Reparametrization of Surface using known Vector Field (Differential Geometry),,"I need help with the following problem: ""Let $X$ be a vector field defined on surface $S$, and $p \in S$ such that $X(p) \neq 0$. Prove that there exists a local parametrization $\phi \colon U \to S$ with $U$ an open set of $\mathbb{R}^2$ such that $X|_{\phi(U)} = \phi_1$ where $\phi_1$ is the derivative of the parametrization with respect to it's first parameter."" I intuitively imagine I need to use the vector field in a creative way to satisfy the condition requiered. In a way I think I need something like $$ \phi(s,t)=\int_0^s \int_0^t X(s,t) ds dt $$ But that doesn't really work.  I was wondering if anyone could guide me to the good parametrization so I can complete the rest...","I need help with the following problem: ""Let $X$ be a vector field defined on surface $S$, and $p \in S$ such that $X(p) \neq 0$. Prove that there exists a local parametrization $\phi \colon U \to S$ with $U$ an open set of $\mathbb{R}^2$ such that $X|_{\phi(U)} = \phi_1$ where $\phi_1$ is the derivative of the parametrization with respect to it's first parameter."" I intuitively imagine I need to use the vector field in a creative way to satisfy the condition requiered. In a way I think I need something like $$ \phi(s,t)=\int_0^s \int_0^t X(s,t) ds dt $$ But that doesn't really work.  I was wondering if anyone could guide me to the good parametrization so I can complete the rest...",,['differential-geometry']
94,Symplectic Form Preserved by Orthogonal Transformation,Symplectic Form Preserved by Orthogonal Transformation,,"I'm trying to prove that the symplectic form $$\omega = d(\cos\theta) \wedge d\phi$$ is preserved by the action of $SO(3)$ on $S^2$ where $\phi$ and $\theta$ are spherical polars. Now $SO(3)$ simply acts by $$\theta \mapsto \theta + \epsilon, \ \phi \mapsto \phi + \delta$$ and writing this diffeomorphism as $F:S^2 \to S^2$ I compute $$F^*(\omega) = d(\cos(\theta + \epsilon))\wedge d(\phi + \delta) = \cos(\epsilon) d(\cos\theta)\wedge d\phi - \sin(\epsilon) d(\sin \theta)\wedge d \phi$$ Is this correct? It doesn't seem like the form is invariant under $SO(3)$. Perhaps it's only meant to be a local symplectomorphism though. Am I allowed to claim that it is a local symplectomorphism because it gives the right result in the limit as $\epsilon \to 0$? I think that would be right, because it would mean that the Lie derivative vanishes. Thanks in advance!","I'm trying to prove that the symplectic form $$\omega = d(\cos\theta) \wedge d\phi$$ is preserved by the action of $SO(3)$ on $S^2$ where $\phi$ and $\theta$ are spherical polars. Now $SO(3)$ simply acts by $$\theta \mapsto \theta + \epsilon, \ \phi \mapsto \phi + \delta$$ and writing this diffeomorphism as $F:S^2 \to S^2$ I compute $$F^*(\omega) = d(\cos(\theta + \epsilon))\wedge d(\phi + \delta) = \cos(\epsilon) d(\cos\theta)\wedge d\phi - \sin(\epsilon) d(\sin \theta)\wedge d \phi$$ Is this correct? It doesn't seem like the form is invariant under $SO(3)$. Perhaps it's only meant to be a local symplectomorphism though. Am I allowed to claim that it is a local symplectomorphism because it gives the right result in the limit as $\epsilon \to 0$? I think that would be right, because it would mean that the Lie derivative vanishes. Thanks in advance!",,"['differential-geometry', 'lie-groups', 'differential-forms', 'symplectic-geometry']"
95,Determining the embedding space:,Determining the embedding space:,,I have seen a lot of discussion of alternate geometries for example on a sphere or hyperbolic saddle as opposed to a plane: Has anyone consider the notion of that plane or hyperbolic saddle itself being embedded on a 4-sphere or 4-saddle and once again that 4-saddle itself embedded on a higher dimensional analog? What effect does this have on geometry locally?,I have seen a lot of discussion of alternate geometries for example on a sphere or hyperbolic saddle as opposed to a plane: Has anyone consider the notion of that plane or hyperbolic saddle itself being embedded on a 4-sphere or 4-saddle and once again that 4-saddle itself embedded on a higher dimensional analog? What effect does this have on geometry locally?,,"['differential-geometry', 'algebraic-topology', 'euclidean-geometry', 'curvature']"
96,Is this distribution involutive?,Is this distribution involutive?,,"For two days I've been trying to show the following: Let $G$ be a Lie group with Lie algebra $\mathfrak{g}$ and consider the smooth distribution $$F=\{F_p=DR_p(e)\mathfrak{h}; p\in G\},$$ where $\mathfrak{h}\subseteq \mathfrak{g}$ is a Lie subalgebra and $R_p:G\rightarrow G$, $a\mapsto ap$, is the right translation. Show that $F$ is involutive. My definition of an involutive distribution is: Let $X, Y\in \mathfrak{X}(G)$ be smooth fields such that $X(p), Y(p)\in F_p$ for all $p\in G$. We say $F$ is involutive if $[X(p), Y(p)]\in F_p$ for all $p\in G$. Can anyone help me? What I thought up till now is: Suppose $\mathfrak{h}$ is a Lie subalgebra. If $F$ were not involutive there would exist smooth fields $X, Y\in \mathfrak{X}(G)$ such that $$X(p), Y(p)\in F_p$$ for all $p\in G$ but $$[X(q), Y(q)]\not\in F_q$$ for some $q\in G$ . In particular, $X(e), Y(e)\in F_e=\mathfrak{h}$, hence, $$[X(e), Y(e)]\in \mathfrak{h}$$ for $\mathfrak{h}$ is a Lie subalgebra. Now I'd like to conclude $$[X(q), Y(q)]=DR_q(e)h$$ for some $h\in \mathfrak{h}$  for getting a contradiction. I'm conjecturing $h=[X(e), Y(e)]$, so that it would suffice proving $$DR_q(e)[X(e), Y(e)]=[X(q), Y(q)],$$ but I don't know if that is true.","For two days I've been trying to show the following: Let $G$ be a Lie group with Lie algebra $\mathfrak{g}$ and consider the smooth distribution $$F=\{F_p=DR_p(e)\mathfrak{h}; p\in G\},$$ where $\mathfrak{h}\subseteq \mathfrak{g}$ is a Lie subalgebra and $R_p:G\rightarrow G$, $a\mapsto ap$, is the right translation. Show that $F$ is involutive. My definition of an involutive distribution is: Let $X, Y\in \mathfrak{X}(G)$ be smooth fields such that $X(p), Y(p)\in F_p$ for all $p\in G$. We say $F$ is involutive if $[X(p), Y(p)]\in F_p$ for all $p\in G$. Can anyone help me? What I thought up till now is: Suppose $\mathfrak{h}$ is a Lie subalgebra. If $F$ were not involutive there would exist smooth fields $X, Y\in \mathfrak{X}(G)$ such that $$X(p), Y(p)\in F_p$$ for all $p\in G$ but $$[X(q), Y(q)]\not\in F_q$$ for some $q\in G$ . In particular, $X(e), Y(e)\in F_e=\mathfrak{h}$, hence, $$[X(e), Y(e)]\in \mathfrak{h}$$ for $\mathfrak{h}$ is a Lie subalgebra. Now I'd like to conclude $$[X(q), Y(q)]=DR_q(e)h$$ for some $h\in \mathfrak{h}$  for getting a contradiction. I'm conjecturing $h=[X(e), Y(e)]$, so that it would suffice proving $$DR_q(e)[X(e), Y(e)]=[X(q), Y(q)],$$ but I don't know if that is true.",,"['differential-geometry', 'manifolds', 'lie-groups', 'lie-algebras']"
97,Vector Bundle Doubt..,Vector Bundle Doubt..,,"Well I have a doubt about a rank $k$ vector bundle. My definition of vector bundle is: A rank $k$ vector bundle is a triple $(\pi, E, M)$ where $E$ and $M$ are smooth manifolds and $\pi:E\rightarrow M$ is a smooth submersion, which satisfies: (i) for every $p\in M$ the fiber $F_p=\pi^{-1}(p)$ is a $k$-vector space. (ii) given $p\in M$ there is an open set $U\subseteq M$ containing $p$ and a diffeomorphism $\phi:\pi^{-1}(U)\rightarrow U\times \mathbb R^k$ such that $\textrm{pr}_1\circ \phi=\pi$. (iii) For every $q\in U$ the map $\phi_q:E_q\rightarrow \mathbb R^k$, $e\mapsto (\textrm{pr}_2\circ \phi)(e)$, is a linear isomorphism.. My doubt is: If I have $\pi^{-1}(U)=E$ and $U=M$ in $(ii)$ and I consider $\phi^{-1}:M\times \mathbb R^k\rightarrow E$ can I say $\phi^{-1}(p, \cdot)=\phi_p^{-1}$?","Well I have a doubt about a rank $k$ vector bundle. My definition of vector bundle is: A rank $k$ vector bundle is a triple $(\pi, E, M)$ where $E$ and $M$ are smooth manifolds and $\pi:E\rightarrow M$ is a smooth submersion, which satisfies: (i) for every $p\in M$ the fiber $F_p=\pi^{-1}(p)$ is a $k$-vector space. (ii) given $p\in M$ there is an open set $U\subseteq M$ containing $p$ and a diffeomorphism $\phi:\pi^{-1}(U)\rightarrow U\times \mathbb R^k$ such that $\textrm{pr}_1\circ \phi=\pi$. (iii) For every $q\in U$ the map $\phi_q:E_q\rightarrow \mathbb R^k$, $e\mapsto (\textrm{pr}_2\circ \phi)(e)$, is a linear isomorphism.. My doubt is: If I have $\pi^{-1}(U)=E$ and $U=M$ in $(ii)$ and I consider $\phi^{-1}:M\times \mathbb R^k\rightarrow E$ can I say $\phi^{-1}(p, \cdot)=\phi_p^{-1}$?",,"['differential-geometry', 'manifolds', 'vector-bundles']"
98,Smooth Structure of the Torus,Smooth Structure of the Torus,,"Consider the torus $T^2=S^1\times S^1$(where $S^1$ is the unit circle   centered at $0$ in $\mathbb C$). Define a smooth structure on $S^1$ and $T^2$.  ($\checkmark$) Let $f:T^2 \rightarrow S^1$ be defined as $f(z,w)=zw$. Compute the rank of $f$ at each point. ($\checkmark$) Let $N=f^{-1}(1)$. Is $N$ a submanifold of $T^2$? Describe $N$. ( ? ) Consider $g:S^1 \rightarrow T^2$ defined as $g(z)=(z,z)$. Is this function an immersion? Is the image an immersed submanifold,   embedding, regular submanifold? ( ? ) Despite ""knowing"" all the definitions of the question, I am not used to solve such differential geometry questions. I have very few thoughts on it but exactly need help. Any hints, ""more than hint""s or solutions will surely be appreciated. Edit : I more or less did the first part by writing out their charts etc. and the second part by finding out coordinate functions and this way formulating $f$ and then computing its rank. However, I still lack for some help to understand the latter two (submanifold issues) clearly.","Consider the torus $T^2=S^1\times S^1$(where $S^1$ is the unit circle   centered at $0$ in $\mathbb C$). Define a smooth structure on $S^1$ and $T^2$.  ($\checkmark$) Let $f:T^2 \rightarrow S^1$ be defined as $f(z,w)=zw$. Compute the rank of $f$ at each point. ($\checkmark$) Let $N=f^{-1}(1)$. Is $N$ a submanifold of $T^2$? Describe $N$. ( ? ) Consider $g:S^1 \rightarrow T^2$ defined as $g(z)=(z,z)$. Is this function an immersion? Is the image an immersed submanifold,   embedding, regular submanifold? ( ? ) Despite ""knowing"" all the definitions of the question, I am not used to solve such differential geometry questions. I have very few thoughts on it but exactly need help. Any hints, ""more than hint""s or solutions will surely be appreciated. Edit : I more or less did the first part by writing out their charts etc. and the second part by finding out coordinate functions and this way formulating $f$ and then computing its rank. However, I still lack for some help to understand the latter two (submanifold issues) clearly.",,"['differential-geometry', 'manifolds']"
99,Different definitions of handle attachment,Different definitions of handle attachment,,"This is an extremely technical question about handle attachments.  I am asking why two definitions are equivalent.  My question appears in the second to last paragraph after I've described the two procedures whose equivalence I want to prove. In the book ""Differential Manifolds"" by Antoni Kosinski, the following procedure is given for attaching two smooth n-manifolds $N_1, N_2$ along submanifolds of their boundaries: Let $E := E' \oplus \mathbb{R}^{\geq 0}$ be the ""upper half"" of a rank n-m riemannian vector bundle over a smooth m- manifold $M$ and let $\phi_i : E \rightarrow N_i$   be imbeddings extending imbeddings $E' \rightarrow \partial N_i$. Now if $\alpha$ is any orientation reversing diffeomorphism $(0,\infty) \rightarrow (0, \infty )$, we make the following identifications:  $x \rightarrow \phi_2\{ \alpha (|\phi_1^{-1}(x)|) \frac{ \phi_1^{-1}(x)}{|\phi_1^{-1}(x)|}\}$ when $x \in \phi_1 (E- M)$ ( I.e. $x$ is an element of the first tubular neighborhood minus the zero section) The quotient space of $N_1 - \phi_1 (M) \sqcup N_2 -\phi_2 (M)$ under this identification is then the desired manifold. Kosinski then says that ""attaching a handle"" to a manifold N is just a special case of the above when $N_1 = N$ and $N_2 = \mathbb{D}^n$ but his definition is a bit different:  Let $n= \lambda + \mu$ and write $x \in \mathbb{D}^n$ as $x = (x_\lambda, x_\mu)$. For $0\leq \epsilon < 1$,  Let $T(\epsilon)  := \{ x \in \mathbb{D}^n : |x_\lambda|^2 > \epsilon \}$ .  Now the analogue of the involution map $\alpha$ in the above paragraph is the map $\beta : T(\epsilon)-S^{\lambda-1} \rightarrow T(\epsilon)-S^{\lambda-1}$ given by $(x_\lambda, x_\mu) \mapsto (\frac{x_\lambda}{|x_\lambda|} (1- |x_\lambda|^2 + \epsilon)^{1/2}, x_\mu \frac{(|x_\lambda|^2-\epsilon)^{1/2} }{(1-|x_\lambda|^2)^{1/2}})$. Which is not as mysterious as it might appear because it is just the composition of the obvious diffeomorphism $\psi: \mathbb{D}^n - S^{\lambda -1} \rightarrow (\mathbb{D}^{\lambda}-S^{\lambda-1}) \times \mathbb{D}^{\mu}$ followed by an involution in the $\lambda$ coordinate followed by the inverse of $\psi$. Now to attach a $\lambda$ handle to a manifold $N$, we choose an imbedding $h: T(\epsilon), \partial T(\epsilon) \rightarrow N, \partial N$ and then identify $x \in T(\epsilon)-S^{\lambda-1}$ with $h\beta (x)$. And finally, the quotient of $N-h(S^{\lambda -1}) \sqcup \mathbb{D}^n - S^{\lambda -1}$ under this identification is the desired handle attachment. Phew! Ok here's my question: What is the vector bundle structure $\phi: E' \oplus \mathbb{R}^{\geq 0} \rightarrow T(\epsilon)$ which makes the second definition equivalent to the first?  More to the point, why should one exist at all? I have been thinking about this for a long time and I have no idea what it should be. I think I know what $\phi |_{E'}$ should be but I have no idea how to extend it in such a way that the involutions $\alpha$ and $\beta$ will ""line up."" Thank you for reading such an appallingly technical question. More thoughts:  What really stumps me is the following.  If the two involutions are to ""line up,""  each ray emanating from the origin in (a fiber of) $E$ should be mapped to a set of the form $\psi^{-1} \{(t x_{\lambda},x_\mu ) : \epsilon < t^2 < 1 \}$ for fixed $x_\lambda \in S^{\lambda -1}$ and $x_\mu \in \mathbb{D}^{\mu}$ and where $\psi$ is define as above. But these latter sets seem to be elliptical arcs whose closures will not be transversal to the boundary ($S^{n-1}$).  Whereas most rays emanating from the origin in (fibers of) $E$ $do$ meet the boundary transversely!... :(","This is an extremely technical question about handle attachments.  I am asking why two definitions are equivalent.  My question appears in the second to last paragraph after I've described the two procedures whose equivalence I want to prove. In the book ""Differential Manifolds"" by Antoni Kosinski, the following procedure is given for attaching two smooth n-manifolds $N_1, N_2$ along submanifolds of their boundaries: Let $E := E' \oplus \mathbb{R}^{\geq 0}$ be the ""upper half"" of a rank n-m riemannian vector bundle over a smooth m- manifold $M$ and let $\phi_i : E \rightarrow N_i$   be imbeddings extending imbeddings $E' \rightarrow \partial N_i$. Now if $\alpha$ is any orientation reversing diffeomorphism $(0,\infty) \rightarrow (0, \infty )$, we make the following identifications:  $x \rightarrow \phi_2\{ \alpha (|\phi_1^{-1}(x)|) \frac{ \phi_1^{-1}(x)}{|\phi_1^{-1}(x)|}\}$ when $x \in \phi_1 (E- M)$ ( I.e. $x$ is an element of the first tubular neighborhood minus the zero section) The quotient space of $N_1 - \phi_1 (M) \sqcup N_2 -\phi_2 (M)$ under this identification is then the desired manifold. Kosinski then says that ""attaching a handle"" to a manifold N is just a special case of the above when $N_1 = N$ and $N_2 = \mathbb{D}^n$ but his definition is a bit different:  Let $n= \lambda + \mu$ and write $x \in \mathbb{D}^n$ as $x = (x_\lambda, x_\mu)$. For $0\leq \epsilon < 1$,  Let $T(\epsilon)  := \{ x \in \mathbb{D}^n : |x_\lambda|^2 > \epsilon \}$ .  Now the analogue of the involution map $\alpha$ in the above paragraph is the map $\beta : T(\epsilon)-S^{\lambda-1} \rightarrow T(\epsilon)-S^{\lambda-1}$ given by $(x_\lambda, x_\mu) \mapsto (\frac{x_\lambda}{|x_\lambda|} (1- |x_\lambda|^2 + \epsilon)^{1/2}, x_\mu \frac{(|x_\lambda|^2-\epsilon)^{1/2} }{(1-|x_\lambda|^2)^{1/2}})$. Which is not as mysterious as it might appear because it is just the composition of the obvious diffeomorphism $\psi: \mathbb{D}^n - S^{\lambda -1} \rightarrow (\mathbb{D}^{\lambda}-S^{\lambda-1}) \times \mathbb{D}^{\mu}$ followed by an involution in the $\lambda$ coordinate followed by the inverse of $\psi$. Now to attach a $\lambda$ handle to a manifold $N$, we choose an imbedding $h: T(\epsilon), \partial T(\epsilon) \rightarrow N, \partial N$ and then identify $x \in T(\epsilon)-S^{\lambda-1}$ with $h\beta (x)$. And finally, the quotient of $N-h(S^{\lambda -1}) \sqcup \mathbb{D}^n - S^{\lambda -1}$ under this identification is the desired handle attachment. Phew! Ok here's my question: What is the vector bundle structure $\phi: E' \oplus \mathbb{R}^{\geq 0} \rightarrow T(\epsilon)$ which makes the second definition equivalent to the first?  More to the point, why should one exist at all? I have been thinking about this for a long time and I have no idea what it should be. I think I know what $\phi |_{E'}$ should be but I have no idea how to extend it in such a way that the involutions $\alpha$ and $\beta$ will ""line up."" Thank you for reading such an appallingly technical question. More thoughts:  What really stumps me is the following.  If the two involutions are to ""line up,""  each ray emanating from the origin in (a fiber of) $E$ should be mapped to a set of the form $\psi^{-1} \{(t x_{\lambda},x_\mu ) : \epsilon < t^2 < 1 \}$ for fixed $x_\lambda \in S^{\lambda -1}$ and $x_\mu \in \mathbb{D}^{\mu}$ and where $\psi$ is define as above. But these latter sets seem to be elliptical arcs whose closures will not be transversal to the boundary ($S^{n-1}$).  Whereas most rays emanating from the origin in (fibers of) $E$ $do$ meet the boundary transversely!... :(",,"['differential-geometry', 'manifolds', 'differential-topology']"
